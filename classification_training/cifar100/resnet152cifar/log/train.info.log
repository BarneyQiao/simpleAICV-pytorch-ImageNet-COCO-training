2022-07-17 00:56:30 - network: resnet152cifar
2022-07-17 00:56:30 - num_classes: 100
2022-07-17 00:56:30 - input_image_size: 32
2022-07-17 00:56:30 - trained_model_path: 
2022-07-17 00:56:30 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-07-17 00:56:30 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-07-17 00:56:30 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f43562a6790>
2022-07-17 00:56:30 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f43562a6a90>
2022-07-17 00:56:30 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f43562a6b80>
2022-07-17 00:56:30 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f43562a6bb0>
2022-07-17 00:56:30 - seed: 0
2022-07-17 00:56:30 - batch_size: 128
2022-07-17 00:56:30 - num_workers: 16
2022-07-17 00:56:30 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2022-07-17 00:56:30 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2022-07-17 00:56:30 - epochs: 200
2022-07-17 00:56:30 - print_interval: 50
2022-07-17 00:56:30 - accumulation_steps: 1
2022-07-17 00:56:30 - sync_bn: False
2022-07-17 00:56:30 - apex: True
2022-07-17 00:56:30 - use_ema_model: False
2022-07-17 00:56:30 - ema_model_decay: 0.9999
2022-07-17 00:56:30 - gpus_type: NVIDIA RTX A5000
2022-07-17 00:56:30 - gpus_num: 1
2022-07-17 00:56:30 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f43562b29b0>
2022-07-17 00:56:31 - --------------------parameters--------------------
2022-07-17 00:56:31 - name: conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer1.0.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer1.0.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer1.0.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer1.0.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer1.0.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer1.0.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer1.0.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer1.0.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer1.0.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer1.0.downsample_conv.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer1.0.downsample_conv.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer1.0.downsample_conv.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer1.1.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer1.1.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer1.1.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer1.1.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer1.1.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer1.1.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer1.1.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer1.1.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer1.1.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer1.2.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer1.2.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer1.2.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer1.2.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer1.2.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer1.2.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer1.2.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer1.2.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer1.2.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.0.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.0.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.0.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.0.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.0.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.0.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.0.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.0.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.0.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.1.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.1.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.1.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.1.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.1.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.1.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.1.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.1.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.1.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.2.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.2.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.2.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.2.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.2.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.2.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.2.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.2.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.2.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.3.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.3.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.3.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.3.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.3.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.3.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.3.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.3.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.3.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.4.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.4.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.4.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.4.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.4.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.4.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.4.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.4.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.4.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.5.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.5.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.5.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.5.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.5.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.5.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.5.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.5.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.5.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.6.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.6.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.6.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.6.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.6.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.6.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.6.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.6.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.6.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.7.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.7.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.7.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.7.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.7.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.7.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer2.7.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer2.7.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer2.7.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.0.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.0.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.0.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.0.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.0.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.0.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.0.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.0.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.0.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.1.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.1.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.1.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.1.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.1.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.1.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.1.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.1.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.1.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.2.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.2.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.2.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.2.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.2.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.2.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.2.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.2.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.2.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.3.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.3.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.3.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.3.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.3.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.3.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.3.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.3.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.3.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.4.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.4.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.4.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.4.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.4.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.4.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.4.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.4.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.4.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.5.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.5.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.5.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.5.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.5.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.5.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.5.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.5.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.5.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.6.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.6.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.6.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.6.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.6.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.6.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.6.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.6.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.6.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.7.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.7.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.7.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.7.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.7.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.7.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.7.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.7.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.7.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.8.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.8.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.8.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.8.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.8.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.8.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.8.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.8.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.8.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.9.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.9.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.9.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.9.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.9.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.9.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.9.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.9.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.9.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.10.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.10.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.10.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.10.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.10.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.10.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.10.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.10.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.10.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.11.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.11.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.11.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.11.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.11.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.11.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.11.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.11.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.11.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.12.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.12.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.12.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.12.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.12.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.12.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.12.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.12.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.12.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.13.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.13.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.13.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.13.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.13.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.13.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.13.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.13.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.13.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.14.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.14.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.14.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.14.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.14.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.14.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.14.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.14.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.14.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.15.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.15.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.15.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.15.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.15.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.15.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.15.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.15.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.15.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.16.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.16.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.16.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.16.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.16.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.16.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.16.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.16.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.16.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.17.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.17.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.17.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.17.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.17.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.17.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.17.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.17.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.17.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.18.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.18.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.18.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.18.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.18.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.18.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.18.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.18.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.18.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.19.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.19.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.19.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.19.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.19.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.19.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.19.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.19.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.19.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.20.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.20.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.20.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.20.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.20.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.20.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.20.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.20.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.20.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.21.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.21.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.21.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.21.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.21.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.21.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.21.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.21.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.21.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.22.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.22.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.22.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.22.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.22.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.22.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.22.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.22.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.22.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.23.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.23.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.23.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.23.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.23.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.23.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.23.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.23.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.23.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.24.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.24.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.24.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.24.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.24.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.24.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.24.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.24.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.24.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.25.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.25.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.25.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.25.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.25.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.25.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.25.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.25.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.25.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.26.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.26.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.26.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.26.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.26.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.26.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.26.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.26.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.26.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.27.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.27.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.27.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.27.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.27.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.27.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.27.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.27.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.27.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.28.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.28.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.28.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.28.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.28.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.28.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.28.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.28.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.28.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.29.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.29.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.29.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.29.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.29.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.29.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.29.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.29.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.29.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.30.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.30.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.30.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.30.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.30.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.30.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.30.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.30.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.30.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.31.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.31.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.31.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.31.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.31.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.31.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.31.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.31.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.31.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.32.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.32.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.32.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.32.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.32.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.32.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.32.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.32.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.32.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.33.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.33.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.33.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.33.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.33.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.33.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.33.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.33.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.33.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.34.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.34.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.34.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.34.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.34.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.34.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.34.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.34.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.34.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.35.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.35.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.35.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.35.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.35.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.35.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer3.35.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer3.35.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer3.35.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer4.0.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer4.0.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer4.0.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer4.0.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer4.0.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer4.0.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer4.0.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer4.0.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer4.0.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer4.1.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer4.1.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer4.1.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer4.1.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer4.1.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer4.1.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer4.1.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer4.1.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer4.1.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer4.2.conv1.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer4.2.conv1.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer4.2.conv1.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer4.2.conv2.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer4.2.conv2.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer4.2.conv2.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: layer4.2.conv3.layer.0.weight, grad: True
2022-07-17 00:56:31 - name: layer4.2.conv3.layer.1.weight, grad: True
2022-07-17 00:56:31 - name: layer4.2.conv3.layer.1.bias, grad: True
2022-07-17 00:56:31 - name: fc.weight, grad: True
2022-07-17 00:56:31 - name: fc.bias, grad: True
2022-07-17 00:56:31 - --------------------buffers--------------------
2022-07-17 00:56:31 - name: conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer1.0.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer1.0.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer1.0.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer1.0.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer1.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer1.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer1.0.downsample_conv.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer1.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer1.1.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer1.1.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer1.1.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer1.1.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer1.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer1.2.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer1.2.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer1.2.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer1.2.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer1.2.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer1.2.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer1.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.0.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.0.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.0.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.0.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.1.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.1.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.1.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.1.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.2.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.2.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.2.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.2.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.2.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.2.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.3.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.3.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.3.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.3.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.3.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.3.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.3.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.4.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.4.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.4.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.4.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.4.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.4.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.4.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.4.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.4.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.5.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.5.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.5.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.5.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.5.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.5.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.5.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.5.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.5.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.6.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.6.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.6.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.6.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.6.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.6.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.6.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.6.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.6.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.7.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.7.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.7.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.7.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.7.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.7.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer2.7.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer2.7.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer2.7.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.0.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.0.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.0.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.0.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.1.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.1.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.1.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.1.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.2.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.2.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.2.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.2.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.2.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.2.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.3.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.3.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.3.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.3.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.3.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.3.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.3.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.4.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.4.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.4.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.4.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.4.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.4.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.4.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.5.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.5.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.5.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.5.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.5.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.5.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.5.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.6.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.6.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.6.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.6.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.6.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.6.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.6.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.6.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.6.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.7.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.7.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.7.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.7.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.7.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.7.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.7.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.7.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.7.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.8.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.8.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.8.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.8.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.8.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.8.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.8.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.8.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.8.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.9.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.9.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.9.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.9.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.9.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.9.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.9.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.9.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.9.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.10.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.10.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.10.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.10.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.10.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.10.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.10.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.10.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.10.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.11.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.11.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.11.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.11.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.11.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.11.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.11.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.11.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.11.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.12.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.12.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.12.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.12.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.12.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.12.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.12.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.12.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.12.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.13.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.13.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.13.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.13.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.13.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.13.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.13.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.13.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.13.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.14.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.14.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.14.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.14.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.14.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.14.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.14.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.14.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.14.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.15.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.15.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.15.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.15.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.15.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.15.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.15.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.15.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.15.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.16.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.16.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.16.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.16.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.16.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.16.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.16.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.16.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.16.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.17.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.17.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.17.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.17.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.17.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.17.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.17.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.17.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.17.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.18.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.18.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.18.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.18.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.18.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.18.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.18.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.18.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.18.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.19.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.19.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.19.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.19.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.19.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.19.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.19.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.19.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.19.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.20.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.20.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.20.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.20.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.20.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.20.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.20.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.20.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.20.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.21.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.21.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.21.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.21.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.21.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.21.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.21.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.21.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.21.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.22.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.22.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.22.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.22.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.22.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.22.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.22.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.22.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.22.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.23.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.23.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.23.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.23.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.23.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.23.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.23.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.23.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.23.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.24.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.24.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.24.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.24.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.24.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.24.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.24.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.24.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.24.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.25.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.25.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.25.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.25.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.25.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.25.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.25.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.25.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.25.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.26.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.26.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.26.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.26.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.26.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.26.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.26.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.26.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.26.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.27.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.27.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.27.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.27.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.27.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.27.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.27.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.27.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.27.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.28.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.28.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.28.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.28.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.28.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.28.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.28.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.28.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.28.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.29.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.29.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.29.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.29.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.29.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.29.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.29.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.29.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.29.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.30.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.30.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.30.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.30.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.30.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.30.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.30.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.30.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.30.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.31.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.31.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.31.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.31.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.31.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.31.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.31.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.31.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.31.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.32.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.32.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.32.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.32.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.32.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.32.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.32.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.32.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.32.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.33.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.33.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.33.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.33.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.33.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.33.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.33.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.33.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.33.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.34.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.34.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.34.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.34.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.34.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.34.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.34.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.34.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.34.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.35.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.35.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.35.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.35.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.35.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.35.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer3.35.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer3.35.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer3.35.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer4.0.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer4.0.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer4.0.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer4.0.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer4.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer4.1.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer4.1.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer4.1.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer4.1.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer4.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer4.2.conv1.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer4.2.conv1.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer4.2.conv2.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer4.2.conv2.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - name: layer4.2.conv3.layer.1.running_mean, grad: False
2022-07-17 00:56:31 - name: layer4.2.conv3.layer.1.running_var, grad: False
2022-07-17 00:56:31 - name: layer4.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-17 00:56:31 - -----------no weight decay layers--------------
2022-07-17 00:56:31 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.3.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.3.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.3.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.3.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.3.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.3.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.4.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.4.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.4.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.4.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.4.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.4.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.5.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.5.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.5.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.5.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.5.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.5.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.6.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.6.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.6.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.6.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.6.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.6.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.7.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.7.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.7.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.7.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.7.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.7.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.3.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.3.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.3.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.3.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.3.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.3.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.4.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.4.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.4.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.4.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.4.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.4.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.5.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.5.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.5.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.5.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.5.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.5.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.6.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.6.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.6.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.6.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.6.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.6.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.7.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.7.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.7.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.7.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.7.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.7.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.8.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.8.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.8.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.8.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.8.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.8.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.9.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.9.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.9.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.9.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.9.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.9.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.10.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.10.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.10.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.10.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.10.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.10.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.11.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.11.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.11.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.11.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.11.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.11.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.12.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.12.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.12.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.12.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.12.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.12.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.13.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.13.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.13.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.13.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.13.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.13.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.14.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.14.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.14.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.14.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.14.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.14.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.15.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.15.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.15.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.15.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.15.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.15.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.16.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.16.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.16.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.16.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.16.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.16.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.17.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.17.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.17.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.17.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.17.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.17.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.18.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.18.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.18.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.18.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.18.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.18.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.19.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.19.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.19.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.19.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.19.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.19.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.20.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.20.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.20.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.20.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.20.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.20.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.21.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.21.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.21.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.21.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.21.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.21.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.22.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.22.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.22.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.22.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.22.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.22.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.23.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.23.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.23.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.23.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.23.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.23.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.24.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.24.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.24.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.24.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.24.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.24.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.25.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.25.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.25.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.25.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.25.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.25.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.26.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.26.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.26.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.26.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.26.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.26.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.27.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.27.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.27.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.27.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.27.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.27.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.28.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.28.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.28.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.28.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.28.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.28.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.29.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.29.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.29.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.29.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.29.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.29.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.30.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.30.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.30.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.30.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.30.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.30.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.31.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.31.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.31.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.31.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.31.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.31.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.32.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.32.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.32.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.32.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.32.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.32.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.33.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.33.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.33.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.33.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.33.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.33.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.34.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.34.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.34.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.34.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.34.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.34.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.35.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.35.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.35.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.35.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.35.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.35.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 00:56:31 - -------------weight decay layers---------------
2022-07-17 00:56:31 - name: conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.0.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.1.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.2.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.2.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer1.2.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.0.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.1.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.2.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.2.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.2.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.3.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.3.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.3.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.4.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.4.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.4.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.5.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.5.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.5.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.6.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.6.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.6.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.7.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.7.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer2.7.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.0.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.1.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.2.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.2.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.2.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.3.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.3.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.3.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.4.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.4.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.4.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.5.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.5.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.5.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.6.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.6.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.6.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.7.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.7.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.7.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.8.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.8.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.8.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.9.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.9.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.9.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.10.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.10.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.10.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.11.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.11.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.11.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.12.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.12.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.12.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.13.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.13.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.13.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.14.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.14.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.14.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.15.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.15.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.15.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.16.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.16.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.16.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.17.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.17.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.17.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.18.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.18.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.18.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.19.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.19.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.19.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.20.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.20.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.20.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.21.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.21.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.21.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.22.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.22.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.22.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.23.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.23.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.23.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.24.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.24.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.24.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.25.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.25.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.25.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.26.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.26.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.26.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.27.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.27.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.27.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.28.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.28.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.28.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.29.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.29.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.29.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.30.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.30.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.30.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.31.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.31.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.31.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.32.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.32.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.32.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.33.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.33.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.33.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.34.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.34.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.34.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.35.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.35.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer3.35.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.0.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.1.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.2.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.2.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: layer4.2.conv3.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 00:56:31 - epoch 001 lr: 0.100000
2022-07-17 00:56:42 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.5644
2022-07-17 00:56:51 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.5976
2022-07-17 00:57:00 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 4.5967
2022-07-17 00:57:08 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 4.5728
2022-07-17 00:57:17 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 4.5425
2022-07-17 00:57:26 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 4.5488
2022-07-17 00:57:35 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 4.4185
2022-07-17 00:57:43 - train: epoch 001, train_loss: 4.7017
2022-07-17 00:57:50 - eval: epoch: 001, acc1: 3.170%, acc5: 12.370%, test_loss: 4.3757, per_image_load_time: 0.334ms, per_image_inference_time: 0.298ms
2022-07-17 00:57:51 - until epoch: 001, best_acc1: 3.170%
2022-07-17 00:57:51 - epoch 002 lr: 0.100000
2022-07-17 00:58:03 - train: epoch 0002, iter [00050, 00390], lr: 0.100000, loss: 4.3306
2022-07-17 00:58:12 - train: epoch 0002, iter [00100, 00390], lr: 0.100000, loss: 4.3626
2022-07-17 00:58:21 - train: epoch 0002, iter [00150, 00390], lr: 0.100000, loss: 4.1810
2022-07-17 00:58:30 - train: epoch 0002, iter [00200, 00390], lr: 0.100000, loss: 4.2013
2022-07-17 00:58:39 - train: epoch 0002, iter [00250, 00390], lr: 0.100000, loss: 4.0909
2022-07-17 00:58:48 - train: epoch 0002, iter [00300, 00390], lr: 0.100000, loss: 4.1168
2022-07-17 00:58:57 - train: epoch 0002, iter [00350, 00390], lr: 0.100000, loss: 3.9396
2022-07-17 00:59:05 - train: epoch 002, train_loss: 4.1875
2022-07-17 00:59:11 - eval: epoch: 002, acc1: 6.470%, acc5: 24.560%, test_loss: 4.0025, per_image_load_time: 0.275ms, per_image_inference_time: 0.305ms
2022-07-17 00:59:13 - until epoch: 002, best_acc1: 6.470%
2022-07-17 00:59:13 - epoch 003 lr: 0.100000
2022-07-17 00:59:25 - train: epoch 0003, iter [00050, 00390], lr: 0.100000, loss: 4.0171
2022-07-17 00:59:34 - train: epoch 0003, iter [00100, 00390], lr: 0.100000, loss: 3.9085
2022-07-17 00:59:43 - train: epoch 0003, iter [00150, 00390], lr: 0.100000, loss: 4.0882
2022-07-17 00:59:52 - train: epoch 0003, iter [00200, 00390], lr: 0.100000, loss: 3.7970
2022-07-17 01:00:01 - train: epoch 0003, iter [00250, 00390], lr: 0.100000, loss: 4.1182
2022-07-17 01:00:10 - train: epoch 0003, iter [00300, 00390], lr: 0.100000, loss: 4.0172
2022-07-17 01:00:19 - train: epoch 0003, iter [00350, 00390], lr: 0.100000, loss: 3.9456
2022-07-17 01:00:27 - train: epoch 003, train_loss: 3.9328
2022-07-17 01:00:33 - eval: epoch: 003, acc1: 10.010%, acc5: 33.210%, test_loss: 3.7765, per_image_load_time: 0.291ms, per_image_inference_time: 0.312ms
2022-07-17 01:00:34 - until epoch: 003, best_acc1: 10.010%
2022-07-17 01:00:34 - epoch 004 lr: 0.100000
2022-07-17 01:00:46 - train: epoch 0004, iter [00050, 00390], lr: 0.100000, loss: 3.8469
2022-07-17 01:00:56 - train: epoch 0004, iter [00100, 00390], lr: 0.100000, loss: 3.7993
2022-07-17 01:01:05 - train: epoch 0004, iter [00150, 00390], lr: 0.100000, loss: 3.7422
2022-07-17 01:01:14 - train: epoch 0004, iter [00200, 00390], lr: 0.100000, loss: 3.6884
2022-07-17 01:01:23 - train: epoch 0004, iter [00250, 00390], lr: 0.100000, loss: 3.6222
2022-07-17 01:01:32 - train: epoch 0004, iter [00300, 00390], lr: 0.100000, loss: 3.6496
2022-07-17 01:01:41 - train: epoch 0004, iter [00350, 00390], lr: 0.100000, loss: 3.3461
2022-07-17 01:01:48 - train: epoch 004, train_loss: 3.6627
2022-07-17 01:01:56 - eval: epoch: 004, acc1: 15.680%, acc5: 42.640%, test_loss: 3.5019, per_image_load_time: 0.378ms, per_image_inference_time: 0.303ms
2022-07-17 01:01:57 - until epoch: 004, best_acc1: 15.680%
2022-07-17 01:01:57 - epoch 005 lr: 0.100000
2022-07-17 01:02:09 - train: epoch 0005, iter [00050, 00390], lr: 0.100000, loss: 3.5834
2022-07-17 01:02:24 - train: epoch 0005, iter [00100, 00390], lr: 0.100000, loss: 3.1546
2022-07-17 01:02:40 - train: epoch 0005, iter [00150, 00390], lr: 0.100000, loss: 3.2912
2022-07-17 01:02:52 - train: epoch 0005, iter [00200, 00390], lr: 0.100000, loss: 3.5219
2022-07-17 01:03:06 - train: epoch 0005, iter [00250, 00390], lr: 0.100000, loss: 3.3699
2022-07-17 01:03:21 - train: epoch 0005, iter [00300, 00390], lr: 0.100000, loss: 3.2104
2022-07-17 01:03:34 - train: epoch 0005, iter [00350, 00390], lr: 0.100000, loss: 3.0756
2022-07-17 01:03:45 - train: epoch 005, train_loss: 3.3738
2022-07-17 01:03:52 - eval: epoch: 005, acc1: 21.720%, acc5: 50.980%, test_loss: 3.2255, per_image_load_time: 0.289ms, per_image_inference_time: 0.324ms
2022-07-17 01:03:53 - until epoch: 005, best_acc1: 21.720%
2022-07-17 01:03:53 - epoch 006 lr: 0.100000
2022-07-17 01:04:10 - train: epoch 0006, iter [00050, 00390], lr: 0.100000, loss: 3.3873
2022-07-17 01:04:24 - train: epoch 0006, iter [00100, 00390], lr: 0.100000, loss: 3.0537
2022-07-17 01:04:39 - train: epoch 0006, iter [00150, 00390], lr: 0.100000, loss: 3.0595
2022-07-17 01:04:53 - train: epoch 0006, iter [00200, 00390], lr: 0.100000, loss: 2.9356
2022-07-17 01:05:06 - train: epoch 0006, iter [00250, 00390], lr: 0.100000, loss: 3.0025
2022-07-17 01:05:20 - train: epoch 0006, iter [00300, 00390], lr: 0.100000, loss: 2.8868
2022-07-17 01:05:35 - train: epoch 0006, iter [00350, 00390], lr: 0.100000, loss: 2.9693
2022-07-17 01:05:44 - train: epoch 006, train_loss: 3.1184
2022-07-17 01:05:51 - eval: epoch: 006, acc1: 25.740%, acc5: 56.950%, test_loss: 2.9486, per_image_load_time: 0.310ms, per_image_inference_time: 0.332ms
2022-07-17 01:05:52 - until epoch: 006, best_acc1: 25.740%
2022-07-17 01:05:52 - epoch 007 lr: 0.100000
2022-07-17 01:06:10 - train: epoch 0007, iter [00050, 00390], lr: 0.100000, loss: 3.0224
2022-07-17 01:06:22 - train: epoch 0007, iter [00100, 00390], lr: 0.100000, loss: 2.9758
2022-07-17 01:06:34 - train: epoch 0007, iter [00150, 00390], lr: 0.100000, loss: 2.9478
2022-07-17 01:06:48 - train: epoch 0007, iter [00200, 00390], lr: 0.100000, loss: 2.7347
2022-07-17 01:07:03 - train: epoch 0007, iter [00250, 00390], lr: 0.100000, loss: 2.6743
2022-07-17 01:07:13 - train: epoch 0007, iter [00300, 00390], lr: 0.100000, loss: 2.5093
2022-07-17 01:07:27 - train: epoch 0007, iter [00350, 00390], lr: 0.100000, loss: 2.8607
2022-07-17 01:07:39 - train: epoch 007, train_loss: 2.8972
2022-07-17 01:07:46 - eval: epoch: 007, acc1: 29.310%, acc5: 60.790%, test_loss: 2.7883, per_image_load_time: 0.321ms, per_image_inference_time: 0.332ms
2022-07-17 01:07:48 - until epoch: 007, best_acc1: 29.310%
2022-07-17 01:07:48 - epoch 008 lr: 0.100000
2022-07-17 01:08:01 - train: epoch 0008, iter [00050, 00390], lr: 0.100000, loss: 2.9251
2022-07-17 01:08:16 - train: epoch 0008, iter [00100, 00390], lr: 0.100000, loss: 2.6005
2022-07-17 01:08:30 - train: epoch 0008, iter [00150, 00390], lr: 0.100000, loss: 2.7003
2022-07-17 01:08:42 - train: epoch 0008, iter [00200, 00390], lr: 0.100000, loss: 2.4380
2022-07-17 01:08:56 - train: epoch 0008, iter [00250, 00390], lr: 0.100000, loss: 2.5124
2022-07-17 01:09:10 - train: epoch 0008, iter [00300, 00390], lr: 0.100000, loss: 2.6617
2022-07-17 01:09:24 - train: epoch 0008, iter [00350, 00390], lr: 0.100000, loss: 2.7411
2022-07-17 01:09:33 - train: epoch 008, train_loss: 2.6818
2022-07-17 01:09:40 - eval: epoch: 008, acc1: 32.610%, acc5: 64.410%, test_loss: 2.6263, per_image_load_time: 0.279ms, per_image_inference_time: 0.333ms
2022-07-17 01:09:41 - until epoch: 008, best_acc1: 32.610%
2022-07-17 01:09:41 - epoch 009 lr: 0.100000
2022-07-17 01:09:58 - train: epoch 0009, iter [00050, 00390], lr: 0.100000, loss: 2.3240
2022-07-17 01:10:10 - train: epoch 0009, iter [00100, 00390], lr: 0.100000, loss: 2.5661
2022-07-17 01:10:22 - train: epoch 0009, iter [00150, 00390], lr: 0.100000, loss: 2.3356
2022-07-17 01:10:37 - train: epoch 0009, iter [00200, 00390], lr: 0.100000, loss: 2.6051
2022-07-17 01:10:52 - train: epoch 0009, iter [00250, 00390], lr: 0.100000, loss: 2.4683
2022-07-17 01:11:01 - train: epoch 0009, iter [00300, 00390], lr: 0.100000, loss: 2.4401
2022-07-17 01:11:16 - train: epoch 0009, iter [00350, 00390], lr: 0.100000, loss: 2.6969
2022-07-17 01:11:28 - train: epoch 009, train_loss: 2.4962
2022-07-17 01:11:35 - eval: epoch: 009, acc1: 37.240%, acc5: 70.060%, test_loss: 2.3872, per_image_load_time: 0.293ms, per_image_inference_time: 0.330ms
2022-07-17 01:11:36 - until epoch: 009, best_acc1: 37.240%
2022-07-17 01:11:36 - epoch 010 lr: 0.100000
2022-07-17 01:11:51 - train: epoch 0010, iter [00050, 00390], lr: 0.100000, loss: 2.7369
2022-07-17 01:12:05 - train: epoch 0010, iter [00100, 00390], lr: 0.100000, loss: 2.5322
2022-07-17 01:12:20 - train: epoch 0010, iter [00150, 00390], lr: 0.100000, loss: 2.1407
2022-07-17 01:12:31 - train: epoch 0010, iter [00200, 00390], lr: 0.100000, loss: 2.5104
2022-07-17 01:12:45 - train: epoch 0010, iter [00250, 00390], lr: 0.100000, loss: 2.2800
2022-07-17 01:12:59 - train: epoch 0010, iter [00300, 00390], lr: 0.100000, loss: 2.2328
2022-07-17 01:13:12 - train: epoch 0010, iter [00350, 00390], lr: 0.100000, loss: 2.2397
2022-07-17 01:13:21 - train: epoch 010, train_loss: 2.3381
2022-07-17 01:13:28 - eval: epoch: 010, acc1: 40.480%, acc5: 72.050%, test_loss: 2.2676, per_image_load_time: 0.310ms, per_image_inference_time: 0.331ms
2022-07-17 01:13:30 - until epoch: 010, best_acc1: 40.480%
2022-07-17 01:13:30 - epoch 011 lr: 0.100000
2022-07-17 01:13:48 - train: epoch 0011, iter [00050, 00390], lr: 0.100000, loss: 2.3529
2022-07-17 01:13:59 - train: epoch 0011, iter [00100, 00390], lr: 0.100000, loss: 2.0185
2022-07-17 01:14:13 - train: epoch 0011, iter [00150, 00390], lr: 0.100000, loss: 2.3414
2022-07-17 01:14:27 - train: epoch 0011, iter [00200, 00390], lr: 0.100000, loss: 2.0528
2022-07-17 01:14:40 - train: epoch 0011, iter [00250, 00390], lr: 0.100000, loss: 2.0849
2022-07-17 01:14:52 - train: epoch 0011, iter [00300, 00390], lr: 0.100000, loss: 1.9079
2022-07-17 01:15:07 - train: epoch 0011, iter [00350, 00390], lr: 0.100000, loss: 1.9641
2022-07-17 01:15:19 - train: epoch 011, train_loss: 2.1909
2022-07-17 01:15:27 - eval: epoch: 011, acc1: 43.310%, acc5: 74.630%, test_loss: nan, per_image_load_time: 0.360ms, per_image_inference_time: 0.350ms
2022-07-17 01:15:28 - until epoch: 011, best_acc1: 43.310%
2022-07-17 01:15:28 - epoch 012 lr: 0.100000
2022-07-17 01:15:46 - train: epoch 0012, iter [00050, 00390], lr: 0.100000, loss: 1.9203
2022-07-17 01:16:01 - train: epoch 0012, iter [00100, 00390], lr: 0.100000, loss: 2.3098
2022-07-17 01:16:13 - train: epoch 0012, iter [00150, 00390], lr: 0.100000, loss: 2.1280
2022-07-17 01:16:26 - train: epoch 0012, iter [00200, 00390], lr: 0.100000, loss: 2.2600
2022-07-17 01:16:40 - train: epoch 0012, iter [00250, 00390], lr: 0.100000, loss: 2.0597
2022-07-17 01:16:55 - train: epoch 0012, iter [00300, 00390], lr: 0.100000, loss: 2.2656
2022-07-17 01:17:06 - train: epoch 0012, iter [00350, 00390], lr: 0.100000, loss: 1.8112
2022-07-17 01:17:19 - train: epoch 012, train_loss: 2.0521
2022-07-17 01:17:25 - eval: epoch: 012, acc1: 46.480%, acc5: 78.170%, test_loss: 2.0078, per_image_load_time: 0.236ms, per_image_inference_time: 0.334ms
2022-07-17 01:17:26 - until epoch: 012, best_acc1: 46.480%
2022-07-17 01:17:26 - epoch 013 lr: 0.100000
2022-07-17 01:17:41 - train: epoch 0013, iter [00050, 00390], lr: 0.100000, loss: 1.9832
2022-07-17 01:17:54 - train: epoch 0013, iter [00100, 00390], lr: 0.100000, loss: 2.1054
2022-07-17 01:18:09 - train: epoch 0013, iter [00150, 00390], lr: 0.100000, loss: 2.2542
2022-07-17 01:18:22 - train: epoch 0013, iter [00200, 00390], lr: 0.100000, loss: 2.0428
2022-07-17 01:18:34 - train: epoch 0013, iter [00250, 00390], lr: 0.100000, loss: 2.1804
2022-07-17 01:18:49 - train: epoch 0013, iter [00300, 00390], lr: 0.100000, loss: 1.9744
2022-07-17 01:19:04 - train: epoch 0013, iter [00350, 00390], lr: 0.100000, loss: 1.7859
2022-07-17 01:19:12 - train: epoch 013, train_loss: 1.9457
2022-07-17 01:19:19 - eval: epoch: 013, acc1: 47.480%, acc5: 78.650%, test_loss: 2.0505, per_image_load_time: 0.336ms, per_image_inference_time: 0.336ms
2022-07-17 01:19:20 - until epoch: 013, best_acc1: 47.480%
2022-07-17 01:19:20 - epoch 014 lr: 0.100000
2022-07-17 01:19:38 - train: epoch 0014, iter [00050, 00390], lr: 0.100000, loss: 1.7887
2022-07-17 01:19:50 - train: epoch 0014, iter [00100, 00390], lr: 0.100000, loss: 1.7588
2022-07-17 01:20:04 - train: epoch 0014, iter [00150, 00390], lr: 0.100000, loss: 1.7742
2022-07-17 01:20:19 - train: epoch 0014, iter [00200, 00390], lr: 0.100000, loss: 1.9708
2022-07-17 01:20:32 - train: epoch 0014, iter [00250, 00390], lr: 0.100000, loss: 1.7269
2022-07-17 01:20:45 - train: epoch 0014, iter [00300, 00390], lr: 0.100000, loss: 1.9690
2022-07-17 01:20:59 - train: epoch 0014, iter [00350, 00390], lr: 0.100000, loss: 1.7950
2022-07-17 01:21:11 - train: epoch 014, train_loss: 1.8700
2022-07-17 01:21:18 - eval: epoch: 014, acc1: 49.110%, acc5: 80.240%, test_loss: 1.8668, per_image_load_time: 0.302ms, per_image_inference_time: 0.332ms
2022-07-17 01:21:19 - until epoch: 014, best_acc1: 49.110%
2022-07-17 01:21:19 - epoch 015 lr: 0.100000
2022-07-17 01:21:38 - train: epoch 0015, iter [00050, 00390], lr: 0.100000, loss: 1.1636
2022-07-17 01:21:53 - train: epoch 0015, iter [00100, 00390], lr: 0.100000, loss: 2.0971
2022-07-17 01:22:04 - train: epoch 0015, iter [00150, 00390], lr: 0.100000, loss: 1.9933
2022-07-17 01:22:17 - train: epoch 0015, iter [00200, 00390], lr: 0.100000, loss: 2.0309
2022-07-17 01:22:32 - train: epoch 0015, iter [00250, 00390], lr: 0.100000, loss: 1.8263
2022-07-17 01:22:45 - train: epoch 0015, iter [00300, 00390], lr: 0.100000, loss: 1.7376
2022-07-17 01:22:58 - train: epoch 0015, iter [00350, 00390], lr: 0.100000, loss: 1.7912
2022-07-17 01:23:10 - train: epoch 015, train_loss: 1.7818
2022-07-17 01:23:19 - eval: epoch: 015, acc1: 50.260%, acc5: 80.650%, test_loss: 1.8177, per_image_load_time: 0.398ms, per_image_inference_time: 0.347ms
2022-07-17 01:23:20 - until epoch: 015, best_acc1: 50.260%
2022-07-17 01:23:20 - epoch 016 lr: 0.100000
2022-07-17 01:23:35 - train: epoch 0016, iter [00050, 00390], lr: 0.100000, loss: 1.8427
2022-07-17 01:23:49 - train: epoch 0016, iter [00100, 00390], lr: 0.100000, loss: 1.7168
2022-07-17 01:24:04 - train: epoch 0016, iter [00150, 00390], lr: 0.100000, loss: 1.9765
2022-07-17 01:24:15 - train: epoch 0016, iter [00200, 00390], lr: 0.100000, loss: 1.8526
2022-07-17 01:24:29 - train: epoch 0016, iter [00250, 00390], lr: 0.100000, loss: 1.5668
2022-07-17 01:24:44 - train: epoch 0016, iter [00300, 00390], lr: 0.100000, loss: 1.6879
2022-07-17 01:24:57 - train: epoch 0016, iter [00350, 00390], lr: 0.100000, loss: 1.5348
2022-07-17 01:25:07 - train: epoch 016, train_loss: 1.6997
2022-07-17 01:25:14 - eval: epoch: 016, acc1: 50.800%, acc5: 81.880%, test_loss: 1.7823, per_image_load_time: 0.266ms, per_image_inference_time: 0.355ms
2022-07-17 01:25:15 - until epoch: 016, best_acc1: 50.800%
2022-07-17 01:25:15 - epoch 017 lr: 0.100000
2022-07-17 01:25:32 - train: epoch 0017, iter [00050, 00390], lr: 0.100000, loss: 1.5281
2022-07-17 01:25:43 - train: epoch 0017, iter [00100, 00390], lr: 0.100000, loss: 1.8387
2022-07-17 01:25:57 - train: epoch 0017, iter [00150, 00390], lr: 0.100000, loss: 1.4629
2022-07-17 01:26:12 - train: epoch 0017, iter [00200, 00390], lr: 0.100000, loss: 1.5310
2022-07-17 01:26:24 - train: epoch 0017, iter [00250, 00390], lr: 0.100000, loss: 1.6335
2022-07-17 01:26:39 - train: epoch 0017, iter [00300, 00390], lr: 0.100000, loss: 1.9215
2022-07-17 01:26:53 - train: epoch 0017, iter [00350, 00390], lr: 0.100000, loss: 1.2983
2022-07-17 01:27:04 - train: epoch 017, train_loss: 1.6465
2022-07-17 01:27:12 - eval: epoch: 017, acc1: 52.760%, acc5: 82.490%, test_loss: nan, per_image_load_time: 0.402ms, per_image_inference_time: 0.335ms
2022-07-17 01:27:13 - until epoch: 017, best_acc1: 52.760%
2022-07-17 01:27:13 - epoch 018 lr: 0.100000
2022-07-17 01:27:31 - train: epoch 0018, iter [00050, 00390], lr: 0.100000, loss: 1.4075
2022-07-17 01:27:45 - train: epoch 0018, iter [00100, 00390], lr: 0.100000, loss: 1.5036
2022-07-17 01:27:56 - train: epoch 0018, iter [00150, 00390], lr: 0.100000, loss: 1.6678
2022-07-17 01:28:12 - train: epoch 0018, iter [00200, 00390], lr: 0.100000, loss: 1.4347
2022-07-17 01:28:27 - train: epoch 0018, iter [00250, 00390], lr: 0.100000, loss: 1.7247
2022-07-17 01:28:37 - train: epoch 0018, iter [00300, 00390], lr: 0.100000, loss: 1.6479
2022-07-17 01:28:51 - train: epoch 0018, iter [00350, 00390], lr: 0.100000, loss: 1.8569
2022-07-17 01:29:04 - train: epoch 018, train_loss: 1.5995
2022-07-17 01:29:11 - eval: epoch: 018, acc1: 50.680%, acc5: 81.670%, test_loss: nan, per_image_load_time: 0.323ms, per_image_inference_time: 0.349ms
2022-07-17 01:29:12 - until epoch: 018, best_acc1: 52.760%
2022-07-17 01:29:12 - epoch 019 lr: 0.100000
2022-07-17 01:29:27 - train: epoch 0019, iter [00050, 00390], lr: 0.100000, loss: 1.5776
2022-07-17 01:29:42 - train: epoch 0019, iter [00100, 00390], lr: 0.100000, loss: 1.4062
2022-07-17 01:29:56 - train: epoch 0019, iter [00150, 00390], lr: 0.100000, loss: 1.7898
2022-07-17 01:30:07 - train: epoch 0019, iter [00200, 00390], lr: 0.100000, loss: 1.5817
2022-07-17 01:30:22 - train: epoch 0019, iter [00250, 00390], lr: 0.100000, loss: 1.6527
2022-07-17 01:30:37 - train: epoch 0019, iter [00300, 00390], lr: 0.100000, loss: 1.6423
2022-07-17 01:30:48 - train: epoch 0019, iter [00350, 00390], lr: 0.100000, loss: 1.4130
2022-07-17 01:30:59 - train: epoch 019, train_loss: 1.5470
2022-07-17 01:31:07 - eval: epoch: 019, acc1: 52.910%, acc5: 82.740%, test_loss: 1.7640, per_image_load_time: 0.386ms, per_image_inference_time: 0.337ms
2022-07-17 01:31:08 - until epoch: 019, best_acc1: 52.910%
2022-07-17 01:31:08 - epoch 020 lr: 0.100000
2022-07-17 01:31:25 - train: epoch 0020, iter [00050, 00390], lr: 0.100000, loss: 1.5212
2022-07-17 01:31:36 - train: epoch 0020, iter [00100, 00390], lr: 0.100000, loss: 1.4866
2022-07-17 01:31:51 - train: epoch 0020, iter [00150, 00390], lr: 0.100000, loss: 1.6176
2022-07-17 01:32:06 - train: epoch 0020, iter [00200, 00390], lr: 0.100000, loss: 1.4785
2022-07-17 01:32:17 - train: epoch 0020, iter [00250, 00390], lr: 0.100000, loss: 1.5203
2022-07-17 01:32:31 - train: epoch 0020, iter [00300, 00390], lr: 0.100000, loss: 1.3760
2022-07-17 01:32:46 - train: epoch 0020, iter [00350, 00390], lr: 0.100000, loss: 1.3018
2022-07-17 01:32:58 - train: epoch 020, train_loss: 1.4945
2022-07-17 01:33:05 - eval: epoch: 020, acc1: 50.780%, acc5: 80.980%, test_loss: nan, per_image_load_time: 0.316ms, per_image_inference_time: 0.335ms
2022-07-17 01:33:05 - until epoch: 020, best_acc1: 52.910%
2022-07-17 01:33:05 - epoch 021 lr: 0.100000
2022-07-17 01:33:23 - train: epoch 0021, iter [00050, 00390], lr: 0.100000, loss: 1.7153
2022-07-17 01:33:37 - train: epoch 0021, iter [00100, 00390], lr: 0.100000, loss: 1.5554
2022-07-17 01:33:48 - train: epoch 0021, iter [00150, 00390], lr: 0.100000, loss: 1.5577
2022-07-17 01:34:03 - train: epoch 0021, iter [00200, 00390], lr: 0.100000, loss: 1.8022
2022-07-17 01:34:18 - train: epoch 0021, iter [00250, 00390], lr: 0.100000, loss: 1.6684
2022-07-17 01:34:29 - train: epoch 0021, iter [00300, 00390], lr: 0.100000, loss: 1.5411
2022-07-17 01:34:45 - train: epoch 0021, iter [00350, 00390], lr: 0.100000, loss: 1.5533
2022-07-17 01:34:57 - train: epoch 021, train_loss: 1.5136
2022-07-17 01:35:04 - eval: epoch: 021, acc1: 54.040%, acc5: 83.370%, test_loss: 1.7332, per_image_load_time: 0.319ms, per_image_inference_time: 0.308ms
2022-07-17 01:35:05 - until epoch: 021, best_acc1: 54.040%
2022-07-17 01:35:05 - epoch 022 lr: 0.100000
2022-07-17 01:35:23 - train: epoch 0022, iter [00050, 00390], lr: 0.100000, loss: 1.6461
2022-07-17 01:35:37 - train: epoch 0022, iter [00100, 00390], lr: 0.100000, loss: 1.4842
2022-07-17 01:35:51 - train: epoch 0022, iter [00150, 00390], lr: 0.100000, loss: 1.4625
2022-07-17 01:36:05 - train: epoch 0022, iter [00200, 00390], lr: 0.100000, loss: 1.9090
2022-07-17 01:36:19 - train: epoch 0022, iter [00250, 00390], lr: 0.100000, loss: 1.4619
2022-07-17 01:36:33 - train: epoch 0022, iter [00300, 00390], lr: 0.100000, loss: 1.5352
2022-07-17 01:36:45 - train: epoch 0022, iter [00350, 00390], lr: 0.100000, loss: 1.4329
2022-07-17 01:36:57 - train: epoch 022, train_loss: 1.4492
2022-07-17 01:37:04 - eval: epoch: 022, acc1: 56.530%, acc5: 84.810%, test_loss: 1.5831, per_image_load_time: 0.312ms, per_image_inference_time: 0.336ms
2022-07-17 01:37:05 - until epoch: 022, best_acc1: 56.530%
2022-07-17 01:37:05 - epoch 023 lr: 0.100000
2022-07-17 01:37:19 - train: epoch 0023, iter [00050, 00390], lr: 0.100000, loss: 1.2561
2022-07-17 01:37:33 - train: epoch 0023, iter [00100, 00390], lr: 0.100000, loss: 1.2869
2022-07-17 01:37:48 - train: epoch 0023, iter [00150, 00390], lr: 0.100000, loss: 1.3937
2022-07-17 01:38:00 - train: epoch 0023, iter [00200, 00390], lr: 0.100000, loss: 1.5204
2022-07-17 01:38:12 - train: epoch 0023, iter [00250, 00390], lr: 0.100000, loss: 1.3749
2022-07-17 01:38:27 - train: epoch 0023, iter [00300, 00390], lr: 0.100000, loss: 1.5577
2022-07-17 01:38:42 - train: epoch 0023, iter [00350, 00390], lr: 0.100000, loss: 1.6501
2022-07-17 01:38:50 - train: epoch 023, train_loss: 1.4752
2022-07-17 01:38:57 - eval: epoch: 023, acc1: 48.970%, acc5: 79.800%, test_loss: 1.9578, per_image_load_time: 0.297ms, per_image_inference_time: 0.364ms
2022-07-17 01:38:58 - until epoch: 023, best_acc1: 56.530%
2022-07-17 01:38:58 - epoch 024 lr: 0.100000
2022-07-17 01:39:16 - train: epoch 0024, iter [00050, 00390], lr: 0.100000, loss: 1.3734
2022-07-17 01:39:29 - train: epoch 0024, iter [00100, 00390], lr: 0.100000, loss: 1.4288
2022-07-17 01:39:42 - train: epoch 0024, iter [00150, 00390], lr: 0.100000, loss: 1.4760
2022-07-17 01:39:57 - train: epoch 0024, iter [00200, 00390], lr: 0.100000, loss: 1.6516
2022-07-17 01:40:10 - train: epoch 0024, iter [00250, 00390], lr: 0.100000, loss: 1.5052
2022-07-17 01:40:22 - train: epoch 0024, iter [00300, 00390], lr: 0.100000, loss: 1.3898
2022-07-17 01:40:37 - train: epoch 0024, iter [00350, 00390], lr: 0.100000, loss: 1.5343
2022-07-17 01:40:49 - train: epoch 024, train_loss: 1.4593
2022-07-17 01:40:57 - eval: epoch: 024, acc1: 56.350%, acc5: 84.420%, test_loss: 2.2288, per_image_load_time: 0.345ms, per_image_inference_time: 0.327ms
2022-07-17 01:40:57 - until epoch: 024, best_acc1: 56.530%
2022-07-17 01:40:57 - epoch 025 lr: 0.100000
2022-07-17 01:41:15 - train: epoch 0025, iter [00050, 00390], lr: 0.100000, loss: 1.3928
2022-07-17 01:41:30 - train: epoch 0025, iter [00100, 00390], lr: 0.100000, loss: 1.2017
2022-07-17 01:41:42 - train: epoch 0025, iter [00150, 00390], lr: 0.100000, loss: 1.5390
2022-07-17 01:41:55 - train: epoch 0025, iter [00200, 00390], lr: 0.100000, loss: 1.5099
2022-07-17 01:42:10 - train: epoch 0025, iter [00250, 00390], lr: 0.100000, loss: 1.3032
2022-07-17 01:42:24 - train: epoch 0025, iter [00300, 00390], lr: 0.100000, loss: 1.5778
2022-07-17 01:42:35 - train: epoch 0025, iter [00350, 00390], lr: 0.100000, loss: 1.3711
2022-07-17 01:42:47 - train: epoch 025, train_loss: 1.3666
2022-07-17 01:42:54 - eval: epoch: 025, acc1: 56.150%, acc5: 85.350%, test_loss: 1.6081, per_image_load_time: 0.285ms, per_image_inference_time: 0.336ms
2022-07-17 01:42:55 - until epoch: 025, best_acc1: 56.530%
2022-07-17 01:42:55 - epoch 026 lr: 0.100000
2022-07-17 01:43:09 - train: epoch 0026, iter [00050, 00390], lr: 0.100000, loss: 1.2686
2022-07-17 01:43:23 - train: epoch 0026, iter [00100, 00390], lr: 0.100000, loss: 1.1804
2022-07-17 01:43:38 - train: epoch 0026, iter [00150, 00390], lr: 0.100000, loss: 1.4688
2022-07-17 01:43:51 - train: epoch 0026, iter [00200, 00390], lr: 0.100000, loss: 1.2872
2022-07-17 01:44:03 - train: epoch 0026, iter [00250, 00390], lr: 0.100000, loss: 1.3982
2022-07-17 01:44:18 - train: epoch 0026, iter [00300, 00390], lr: 0.100000, loss: 1.5319
2022-07-17 01:44:32 - train: epoch 0026, iter [00350, 00390], lr: 0.100000, loss: 1.5705
2022-07-17 01:44:41 - train: epoch 026, train_loss: 1.3766
2022-07-17 01:44:47 - eval: epoch: 026, acc1: 52.410%, acc5: 79.490%, test_loss: 3.7052, per_image_load_time: 0.268ms, per_image_inference_time: 0.329ms
2022-07-17 01:44:48 - until epoch: 026, best_acc1: 56.530%
2022-07-17 01:44:48 - epoch 027 lr: 0.100000
2022-07-17 01:45:06 - train: epoch 0027, iter [00050, 00390], lr: 0.100000, loss: 1.3101
2022-07-17 01:45:19 - train: epoch 0027, iter [00100, 00390], lr: 0.100000, loss: 1.3360
2022-07-17 01:45:32 - train: epoch 0027, iter [00150, 00390], lr: 0.100000, loss: 1.0543
2022-07-17 01:45:47 - train: epoch 0027, iter [00200, 00390], lr: 0.100000, loss: 1.5296
2022-07-17 01:46:00 - train: epoch 0027, iter [00250, 00390], lr: 0.100000, loss: 1.5265
2022-07-17 01:46:12 - train: epoch 0027, iter [00300, 00390], lr: 0.100000, loss: 1.5298
2022-07-17 01:46:27 - train: epoch 0027, iter [00350, 00390], lr: 0.100000, loss: 1.6308
2022-07-17 01:46:39 - train: epoch 027, train_loss: 1.3307
2022-07-17 01:46:46 - eval: epoch: 027, acc1: 57.880%, acc5: 85.950%, test_loss: 1.5010, per_image_load_time: 0.328ms, per_image_inference_time: 0.320ms
2022-07-17 01:46:47 - until epoch: 027, best_acc1: 57.880%
2022-07-17 01:46:47 - epoch 028 lr: 0.100000
2022-07-17 01:47:06 - train: epoch 0028, iter [00050, 00390], lr: 0.100000, loss: 1.5353
2022-07-17 01:47:21 - train: epoch 0028, iter [00100, 00390], lr: 0.100000, loss: 1.3172
2022-07-17 01:47:33 - train: epoch 0028, iter [00150, 00390], lr: 0.100000, loss: 1.2703
2022-07-17 01:47:45 - train: epoch 0028, iter [00200, 00390], lr: 0.100000, loss: 1.3623
2022-07-17 01:48:00 - train: epoch 0028, iter [00250, 00390], lr: 0.100000, loss: 1.3371
2022-07-17 01:48:14 - train: epoch 0028, iter [00300, 00390], lr: 0.100000, loss: 1.0297
2022-07-17 01:48:26 - train: epoch 0028, iter [00350, 00390], lr: 0.100000, loss: 1.3319
2022-07-17 01:48:38 - train: epoch 028, train_loss: 1.2883
2022-07-17 01:48:45 - eval: epoch: 028, acc1: 57.790%, acc5: 86.140%, test_loss: 1.5173, per_image_load_time: 0.278ms, per_image_inference_time: 0.330ms
2022-07-17 01:48:45 - until epoch: 028, best_acc1: 57.880%
2022-07-17 01:48:45 - epoch 029 lr: 0.100000
2022-07-17 01:49:00 - train: epoch 0029, iter [00050, 00390], lr: 0.100000, loss: 1.2391
2022-07-17 01:49:14 - train: epoch 0029, iter [00100, 00390], lr: 0.100000, loss: 1.3137
2022-07-17 01:49:29 - train: epoch 0029, iter [00150, 00390], lr: 0.100000, loss: 1.3994
2022-07-17 01:49:41 - train: epoch 0029, iter [00200, 00390], lr: 0.100000, loss: 1.2601
2022-07-17 01:49:54 - train: epoch 0029, iter [00250, 00390], lr: 0.100000, loss: 1.3125
2022-07-17 01:50:10 - train: epoch 0029, iter [00300, 00390], lr: 0.100000, loss: 1.2890
2022-07-17 01:50:23 - train: epoch 0029, iter [00350, 00390], lr: 0.100000, loss: 1.0644
2022-07-17 01:50:32 - train: epoch 029, train_loss: 1.2870
2022-07-17 01:50:39 - eval: epoch: 029, acc1: 56.260%, acc5: 85.560%, test_loss: 1.5865, per_image_load_time: 0.286ms, per_image_inference_time: 0.330ms
2022-07-17 01:50:39 - until epoch: 029, best_acc1: 57.880%
2022-07-17 01:50:39 - epoch 030 lr: 0.100000
2022-07-17 01:50:58 - train: epoch 0030, iter [00050, 00390], lr: 0.100000, loss: 1.2804
2022-07-17 01:51:09 - train: epoch 0030, iter [00100, 00390], lr: 0.100000, loss: 1.0938
2022-07-17 01:51:23 - train: epoch 0030, iter [00150, 00390], lr: 0.100000, loss: 1.2948
2022-07-17 01:51:38 - train: epoch 0030, iter [00200, 00390], lr: 0.100000, loss: 1.2108
2022-07-17 01:51:51 - train: epoch 0030, iter [00250, 00390], lr: 0.100000, loss: 1.2101
2022-07-17 01:52:04 - train: epoch 0030, iter [00300, 00390], lr: 0.100000, loss: 1.1673
2022-07-17 01:52:18 - train: epoch 0030, iter [00350, 00390], lr: 0.100000, loss: 1.3194
2022-07-17 01:52:30 - train: epoch 030, train_loss: 1.2660
2022-07-17 01:52:37 - eval: epoch: 030, acc1: 57.360%, acc5: 85.740%, test_loss: 1.5604, per_image_load_time: 0.329ms, per_image_inference_time: 0.341ms
2022-07-17 01:52:38 - until epoch: 030, best_acc1: 57.880%
2022-07-17 01:52:38 - epoch 031 lr: 0.100000
2022-07-17 01:52:57 - train: epoch 0031, iter [00050, 00390], lr: 0.100000, loss: 1.2071
2022-07-17 01:53:11 - train: epoch 0031, iter [00100, 00390], lr: 0.100000, loss: 1.2925
2022-07-17 01:53:24 - train: epoch 0031, iter [00150, 00390], lr: 0.100000, loss: 1.3096
2022-07-17 01:53:37 - train: epoch 0031, iter [00200, 00390], lr: 0.100000, loss: 1.5241
2022-07-17 01:53:52 - train: epoch 0031, iter [00250, 00390], lr: 0.100000, loss: 1.1564
2022-07-17 01:54:05 - train: epoch 0031, iter [00300, 00390], lr: 0.100000, loss: 1.3339
2022-07-17 01:54:17 - train: epoch 0031, iter [00350, 00390], lr: 0.100000, loss: 1.1919
2022-07-17 01:54:29 - train: epoch 031, train_loss: 1.2299
2022-07-17 01:54:36 - eval: epoch: 031, acc1: 56.950%, acc5: 85.120%, test_loss: 1.5661, per_image_load_time: 0.346ms, per_image_inference_time: 0.336ms
2022-07-17 01:54:37 - until epoch: 031, best_acc1: 57.880%
2022-07-17 01:54:37 - epoch 032 lr: 0.100000
2022-07-17 01:54:52 - train: epoch 0032, iter [00050, 00390], lr: 0.100000, loss: 1.3989
2022-07-17 01:55:07 - train: epoch 0032, iter [00100, 00390], lr: 0.100000, loss: 1.0933
2022-07-17 01:55:21 - train: epoch 0032, iter [00150, 00390], lr: 0.100000, loss: 1.1607
2022-07-17 01:55:34 - train: epoch 0032, iter [00200, 00390], lr: 0.100000, loss: 1.3391
2022-07-17 01:55:47 - train: epoch 0032, iter [00250, 00390], lr: 0.100000, loss: 1.3037
2022-07-17 01:56:02 - train: epoch 0032, iter [00300, 00390], lr: 0.100000, loss: 1.2365
2022-07-17 01:56:15 - train: epoch 0032, iter [00350, 00390], lr: 0.100000, loss: 1.0541
2022-07-17 01:56:25 - train: epoch 032, train_loss: 1.2312
2022-07-17 01:56:32 - eval: epoch: 032, acc1: 59.030%, acc5: 86.140%, test_loss: 1.5132, per_image_load_time: 0.266ms, per_image_inference_time: 0.353ms
2022-07-17 01:56:33 - until epoch: 032, best_acc1: 59.030%
2022-07-17 01:56:33 - epoch 033 lr: 0.100000
2022-07-17 01:56:51 - train: epoch 0033, iter [00050, 00390], lr: 0.100000, loss: 1.0725
2022-07-17 01:57:01 - train: epoch 0033, iter [00100, 00390], lr: 0.100000, loss: 1.0917
2022-07-17 01:57:15 - train: epoch 0033, iter [00150, 00390], lr: 0.100000, loss: 1.2116
2022-07-17 01:57:30 - train: epoch 0033, iter [00200, 00390], lr: 0.100000, loss: 1.2048
2022-07-17 01:57:42 - train: epoch 0033, iter [00250, 00390], lr: 0.100000, loss: 1.1738
2022-07-17 01:57:54 - train: epoch 0033, iter [00300, 00390], lr: 0.100000, loss: 1.3210
2022-07-17 01:58:09 - train: epoch 0033, iter [00350, 00390], lr: 0.100000, loss: 1.2324
2022-07-17 01:58:22 - train: epoch 033, train_loss: 1.1965
2022-07-17 01:58:30 - eval: epoch: 033, acc1: 59.730%, acc5: 86.140%, test_loss: 2.2731, per_image_load_time: 0.391ms, per_image_inference_time: 0.349ms
2022-07-17 01:58:31 - until epoch: 033, best_acc1: 59.730%
2022-07-17 01:58:31 - epoch 034 lr: 0.100000
2022-07-17 01:58:49 - train: epoch 0034, iter [00050, 00390], lr: 0.100000, loss: 1.1149
2022-07-17 01:59:04 - train: epoch 0034, iter [00100, 00390], lr: 0.100000, loss: 1.0555
2022-07-17 01:59:15 - train: epoch 0034, iter [00150, 00390], lr: 0.100000, loss: 1.2508
2022-07-17 01:59:29 - train: epoch 0034, iter [00200, 00390], lr: 0.100000, loss: 0.9858
2022-07-17 01:59:44 - train: epoch 0034, iter [00250, 00390], lr: 0.100000, loss: 1.2362
2022-07-17 01:59:57 - train: epoch 0034, iter [00300, 00390], lr: 0.100000, loss: 1.2981
2022-07-17 02:00:09 - train: epoch 0034, iter [00350, 00390], lr: 0.100000, loss: 1.2067
2022-07-17 02:00:21 - train: epoch 034, train_loss: 1.1790
2022-07-17 02:00:28 - eval: epoch: 034, acc1: 56.360%, acc5: 83.740%, test_loss: 1.7042, per_image_load_time: 0.302ms, per_image_inference_time: 0.335ms
2022-07-17 02:00:29 - until epoch: 034, best_acc1: 59.730%
2022-07-17 02:00:29 - epoch 035 lr: 0.100000
2022-07-17 02:00:43 - train: epoch 0035, iter [00050, 00390], lr: 0.100000, loss: 1.0225
2022-07-17 02:00:57 - train: epoch 0035, iter [00100, 00390], lr: 0.100000, loss: 1.0552
2022-07-17 02:01:12 - train: epoch 0035, iter [00150, 00390], lr: 0.100000, loss: 1.1659
2022-07-17 02:01:24 - train: epoch 0035, iter [00200, 00390], lr: 0.100000, loss: 1.1362
2022-07-17 02:01:36 - train: epoch 0035, iter [00250, 00390], lr: 0.100000, loss: 1.3778
2022-07-17 02:01:51 - train: epoch 0035, iter [00300, 00390], lr: 0.100000, loss: 1.0421
2022-07-17 02:02:05 - train: epoch 0035, iter [00350, 00390], lr: 0.100000, loss: 1.3558
2022-07-17 02:02:14 - train: epoch 035, train_loss: 1.1785
2022-07-17 02:02:22 - eval: epoch: 035, acc1: 59.180%, acc5: 86.040%, test_loss: 1.5837, per_image_load_time: 0.381ms, per_image_inference_time: 0.346ms
2022-07-17 02:02:22 - until epoch: 035, best_acc1: 59.730%
2022-07-17 02:02:22 - epoch 036 lr: 0.100000
2022-07-17 02:02:40 - train: epoch 0036, iter [00050, 00390], lr: 0.100000, loss: 1.2013
2022-07-17 02:02:53 - train: epoch 0036, iter [00100, 00390], lr: 0.100000, loss: 1.0124
2022-07-17 02:03:06 - train: epoch 0036, iter [00150, 00390], lr: 0.100000, loss: 1.0219
2022-07-17 02:03:21 - train: epoch 0036, iter [00200, 00390], lr: 0.100000, loss: 1.0186
2022-07-17 02:03:34 - train: epoch 0036, iter [00250, 00390], lr: 0.100000, loss: 1.0346
2022-07-17 02:03:46 - train: epoch 0036, iter [00300, 00390], lr: 0.100000, loss: 1.1607
2022-07-17 02:04:00 - train: epoch 0036, iter [00350, 00390], lr: 0.100000, loss: 1.3227
2022-07-17 02:04:13 - train: epoch 036, train_loss: 1.1463
2022-07-17 02:04:21 - eval: epoch: 036, acc1: 58.040%, acc5: 86.120%, test_loss: 1.7227, per_image_load_time: 0.429ms, per_image_inference_time: 0.355ms
2022-07-17 02:04:22 - until epoch: 036, best_acc1: 59.730%
2022-07-17 02:04:22 - epoch 037 lr: 0.100000
2022-07-17 02:04:41 - train: epoch 0037, iter [00050, 00390], lr: 0.100000, loss: 1.0685
2022-07-17 02:04:55 - train: epoch 0037, iter [00100, 00390], lr: 0.100000, loss: 1.1615
2022-07-17 02:05:08 - train: epoch 0037, iter [00150, 00390], lr: 0.100000, loss: 0.9950
2022-07-17 02:05:21 - train: epoch 0037, iter [00200, 00390], lr: 0.100000, loss: 1.3679
2022-07-17 02:05:35 - train: epoch 0037, iter [00250, 00390], lr: 0.100000, loss: 1.2921
2022-07-17 02:05:49 - train: epoch 0037, iter [00300, 00390], lr: 0.100000, loss: 1.5336
2022-07-17 02:06:01 - train: epoch 0037, iter [00350, 00390], lr: 0.100000, loss: 1.1074
2022-07-17 02:06:14 - train: epoch 037, train_loss: 1.1648
2022-07-17 02:06:21 - eval: epoch: 037, acc1: 59.890%, acc5: 86.620%, test_loss: 1.6066, per_image_load_time: 0.319ms, per_image_inference_time: 0.339ms
2022-07-17 02:06:22 - until epoch: 037, best_acc1: 59.890%
2022-07-17 02:06:22 - epoch 038 lr: 0.100000
2022-07-17 02:06:36 - train: epoch 0038, iter [00050, 00390], lr: 0.100000, loss: 0.8860
2022-07-17 02:06:50 - train: epoch 0038, iter [00100, 00390], lr: 0.100000, loss: 0.9411
2022-07-17 02:07:04 - train: epoch 0038, iter [00150, 00390], lr: 0.100000, loss: 1.2493
2022-07-17 02:07:17 - train: epoch 0038, iter [00200, 00390], lr: 0.100000, loss: 1.0141
2022-07-17 02:07:29 - train: epoch 0038, iter [00250, 00390], lr: 0.100000, loss: 1.2613
2022-07-17 02:07:44 - train: epoch 0038, iter [00300, 00390], lr: 0.100000, loss: 1.4535
2022-07-17 02:07:59 - train: epoch 0038, iter [00350, 00390], lr: 0.100000, loss: 1.4055
2022-07-17 02:08:07 - train: epoch 038, train_loss: 1.1454
2022-07-17 02:08:14 - eval: epoch: 038, acc1: 59.420%, acc5: 86.860%, test_loss: 1.4857, per_image_load_time: 0.303ms, per_image_inference_time: 0.332ms
2022-07-17 02:08:15 - until epoch: 038, best_acc1: 59.890%
2022-07-17 02:08:15 - epoch 039 lr: 0.100000
2022-07-17 02:08:32 - train: epoch 0039, iter [00050, 00390], lr: 0.100000, loss: 1.1878
2022-07-17 02:08:45 - train: epoch 0039, iter [00100, 00390], lr: 0.100000, loss: 1.2387
2022-07-17 02:08:58 - train: epoch 0039, iter [00150, 00390], lr: 0.100000, loss: 1.2074
2022-07-17 02:09:14 - train: epoch 0039, iter [00200, 00390], lr: 0.100000, loss: 1.1121
2022-07-17 02:09:27 - train: epoch 0039, iter [00250, 00390], lr: 0.100000, loss: 1.0223
2022-07-17 02:09:39 - train: epoch 0039, iter [00300, 00390], lr: 0.100000, loss: 1.0574
2022-07-17 02:09:54 - train: epoch 0039, iter [00350, 00390], lr: 0.100000, loss: 1.1968
2022-07-17 02:10:06 - train: epoch 039, train_loss: 1.1243
2022-07-17 02:10:12 - eval: epoch: 039, acc1: 59.910%, acc5: 87.240%, test_loss: 1.4844, per_image_load_time: 0.279ms, per_image_inference_time: 0.317ms
2022-07-17 02:10:13 - until epoch: 039, best_acc1: 59.910%
2022-07-17 02:10:13 - epoch 040 lr: 0.100000
2022-07-17 02:10:31 - train: epoch 0040, iter [00050, 00390], lr: 0.100000, loss: 1.1667
2022-07-17 02:10:47 - train: epoch 0040, iter [00100, 00390], lr: 0.100000, loss: 0.7962
2022-07-17 02:10:59 - train: epoch 0040, iter [00150, 00390], lr: 0.100000, loss: 1.1709
2022-07-17 02:11:12 - train: epoch 0040, iter [00200, 00390], lr: 0.100000, loss: 1.3527
2022-07-17 02:11:27 - train: epoch 0040, iter [00250, 00390], lr: 0.100000, loss: 1.3572
2022-07-17 02:11:40 - train: epoch 0040, iter [00300, 00390], lr: 0.100000, loss: 0.9586
2022-07-17 02:11:51 - train: epoch 0040, iter [00350, 00390], lr: 0.100000, loss: 1.4128
2022-07-17 02:12:04 - train: epoch 040, train_loss: 1.1146
2022-07-17 02:12:11 - eval: epoch: 040, acc1: 59.710%, acc5: 87.290%, test_loss: 1.5063, per_image_load_time: 0.320ms, per_image_inference_time: 0.335ms
2022-07-17 02:12:12 - until epoch: 040, best_acc1: 59.910%
2022-07-17 02:12:12 - epoch 041 lr: 0.100000
2022-07-17 02:12:26 - train: epoch 0041, iter [00050, 00390], lr: 0.100000, loss: 0.9460
2022-07-17 02:12:40 - train: epoch 0041, iter [00100, 00390], lr: 0.100000, loss: 0.9502
2022-07-17 02:12:55 - train: epoch 0041, iter [00150, 00390], lr: 0.100000, loss: 1.1655
2022-07-17 02:13:07 - train: epoch 0041, iter [00200, 00390], lr: 0.100000, loss: 1.0127
2022-07-17 02:13:19 - train: epoch 0041, iter [00250, 00390], lr: 0.100000, loss: 1.3121
2022-07-17 02:13:34 - train: epoch 0041, iter [00300, 00390], lr: 0.100000, loss: 1.4277
2022-07-17 02:13:49 - train: epoch 0041, iter [00350, 00390], lr: 0.100000, loss: 1.2824
2022-07-17 02:13:58 - train: epoch 041, train_loss: 1.1487
2022-07-17 02:14:05 - eval: epoch: 041, acc1: 60.490%, acc5: 86.550%, test_loss: 1.4414, per_image_load_time: 0.287ms, per_image_inference_time: 0.321ms
2022-07-17 02:14:06 - until epoch: 041, best_acc1: 60.490%
2022-07-17 02:14:06 - epoch 042 lr: 0.100000
2022-07-17 02:14:24 - train: epoch 0042, iter [00050, 00390], lr: 0.100000, loss: 0.9573
2022-07-17 02:14:36 - train: epoch 0042, iter [00100, 00390], lr: 0.100000, loss: 1.0851
2022-07-17 02:14:49 - train: epoch 0042, iter [00150, 00390], lr: 0.100000, loss: 1.0069
2022-07-17 02:15:04 - train: epoch 0042, iter [00200, 00390], lr: 0.100000, loss: 1.1569
2022-07-17 02:15:16 - train: epoch 0042, iter [00250, 00390], lr: 0.100000, loss: 1.2881
2022-07-17 02:15:30 - train: epoch 0042, iter [00300, 00390], lr: 0.100000, loss: 0.9310
2022-07-17 02:15:45 - train: epoch 0042, iter [00350, 00390], lr: 0.100000, loss: 1.1437
2022-07-17 02:15:57 - train: epoch 042, train_loss: 1.1132
2022-07-17 02:16:05 - eval: epoch: 042, acc1: 59.190%, acc5: 87.010%, test_loss: 1.5459, per_image_load_time: 0.367ms, per_image_inference_time: 0.344ms
2022-07-17 02:16:05 - until epoch: 042, best_acc1: 60.490%
2022-07-17 02:16:05 - epoch 043 lr: 0.100000
2022-07-17 02:16:23 - train: epoch 0043, iter [00050, 00390], lr: 0.100000, loss: 0.9963
2022-07-17 02:16:38 - train: epoch 0043, iter [00100, 00390], lr: 0.100000, loss: 1.2097
2022-07-17 02:16:50 - train: epoch 0043, iter [00150, 00390], lr: 0.100000, loss: 1.1017
2022-07-17 02:17:03 - train: epoch 0043, iter [00200, 00390], lr: 0.100000, loss: 1.2118
2022-07-17 02:17:18 - train: epoch 0043, iter [00250, 00390], lr: 0.100000, loss: 1.1984
2022-07-17 02:17:31 - train: epoch 0043, iter [00300, 00390], lr: 0.100000, loss: 1.0236
2022-07-17 02:17:43 - train: epoch 0043, iter [00350, 00390], lr: 0.100000, loss: 1.1576
2022-07-17 02:17:55 - train: epoch 043, train_loss: 1.1081
2022-07-17 02:18:02 - eval: epoch: 043, acc1: 58.980%, acc5: 86.600%, test_loss: 1.5150, per_image_load_time: 0.285ms, per_image_inference_time: 0.334ms
2022-07-17 02:18:03 - until epoch: 043, best_acc1: 60.490%
2022-07-17 02:18:03 - epoch 044 lr: 0.100000
2022-07-17 02:18:17 - train: epoch 0044, iter [00050, 00390], lr: 0.100000, loss: 1.3551
2022-07-17 02:18:31 - train: epoch 0044, iter [00100, 00390], lr: 0.100000, loss: 1.3617
2022-07-17 02:18:47 - train: epoch 0044, iter [00150, 00390], lr: 0.100000, loss: 0.9168
2022-07-17 02:18:59 - train: epoch 0044, iter [00200, 00390], lr: 0.100000, loss: 1.1018
2022-07-17 02:19:12 - train: epoch 0044, iter [00250, 00390], lr: 0.100000, loss: 1.2990
2022-07-17 02:19:27 - train: epoch 0044, iter [00300, 00390], lr: 0.100000, loss: 1.1265
2022-07-17 02:19:40 - train: epoch 0044, iter [00350, 00390], lr: 0.100000, loss: 0.8729
2022-07-17 02:19:49 - train: epoch 044, train_loss: 1.1328
2022-07-17 02:19:56 - eval: epoch: 044, acc1: 62.110%, acc5: 88.530%, test_loss: 1.3896, per_image_load_time: 0.309ms, per_image_inference_time: 0.327ms
2022-07-17 02:19:57 - until epoch: 044, best_acc1: 62.110%
2022-07-17 02:19:57 - epoch 045 lr: 0.100000
2022-07-17 02:20:15 - train: epoch 0045, iter [00050, 00390], lr: 0.100000, loss: 1.0230
2022-07-17 02:20:26 - train: epoch 0045, iter [00100, 00390], lr: 0.100000, loss: 1.0927
2022-07-17 02:20:40 - train: epoch 0045, iter [00150, 00390], lr: 0.100000, loss: 1.0622
2022-07-17 02:20:55 - train: epoch 0045, iter [00200, 00390], lr: 0.100000, loss: 1.0710
2022-07-17 02:21:08 - train: epoch 0045, iter [00250, 00390], lr: 0.100000, loss: 0.9463
2022-07-17 02:21:21 - train: epoch 0045, iter [00300, 00390], lr: 0.100000, loss: 1.0628
2022-07-17 02:21:35 - train: epoch 0045, iter [00350, 00390], lr: 0.100000, loss: 1.2851
2022-07-17 02:21:47 - train: epoch 045, train_loss: 1.1117
2022-07-17 02:21:56 - eval: epoch: 045, acc1: 60.250%, acc5: 86.780%, test_loss: 1.5547, per_image_load_time: 0.413ms, per_image_inference_time: 0.379ms
2022-07-17 02:21:57 - until epoch: 045, best_acc1: 62.110%
2022-07-17 02:21:57 - epoch 046 lr: 0.100000
2022-07-17 02:22:16 - train: epoch 0046, iter [00050, 00390], lr: 0.100000, loss: 0.7862
2022-07-17 02:22:31 - train: epoch 0046, iter [00100, 00390], lr: 0.100000, loss: 0.8575
2022-07-17 02:22:41 - train: epoch 0046, iter [00150, 00390], lr: 0.100000, loss: 0.9340
2022-07-17 02:22:56 - train: epoch 0046, iter [00200, 00390], lr: 0.100000, loss: 1.1661
2022-07-17 02:23:11 - train: epoch 0046, iter [00250, 00390], lr: 0.100000, loss: 0.9421
2022-07-17 02:23:23 - train: epoch 0046, iter [00300, 00390], lr: 0.100000, loss: 0.7617
2022-07-17 02:23:36 - train: epoch 0046, iter [00350, 00390], lr: 0.100000, loss: 1.1181
2022-07-17 02:23:48 - train: epoch 046, train_loss: 1.0580
2022-07-17 02:23:55 - eval: epoch: 046, acc1: 61.380%, acc5: 88.230%, test_loss: 1.3854, per_image_load_time: 0.294ms, per_image_inference_time: 0.352ms
2022-07-17 02:23:56 - until epoch: 046, best_acc1: 62.110%
2022-07-17 02:23:56 - epoch 047 lr: 0.100000
2022-07-17 02:24:08 - train: epoch 0047, iter [00050, 00390], lr: 0.100000, loss: 0.9915
2022-07-17 02:24:23 - train: epoch 0047, iter [00100, 00390], lr: 0.100000, loss: 0.8736
2022-07-17 02:24:38 - train: epoch 0047, iter [00150, 00390], lr: 0.100000, loss: 1.0349
2022-07-17 02:24:50 - train: epoch 0047, iter [00200, 00390], lr: 0.100000, loss: 1.0114
2022-07-17 02:25:04 - train: epoch 0047, iter [00250, 00390], lr: 0.100000, loss: 0.7981
2022-07-17 02:25:18 - train: epoch 0047, iter [00300, 00390], lr: 0.100000, loss: 1.0242
2022-07-17 02:25:31 - train: epoch 0047, iter [00350, 00390], lr: 0.100000, loss: 1.2980
2022-07-17 02:25:41 - train: epoch 047, train_loss: 1.0585
2022-07-17 02:25:48 - eval: epoch: 047, acc1: 60.980%, acc5: 87.390%, test_loss: 1.4457, per_image_load_time: 0.292ms, per_image_inference_time: 0.340ms
2022-07-17 02:25:48 - until epoch: 047, best_acc1: 62.110%
2022-07-17 02:25:48 - epoch 048 lr: 0.100000
2022-07-17 02:26:07 - train: epoch 0048, iter [00050, 00390], lr: 0.100000, loss: 1.0415
2022-07-17 02:26:18 - train: epoch 0048, iter [00100, 00390], lr: 0.100000, loss: 0.9095
2022-07-17 02:26:31 - train: epoch 0048, iter [00150, 00390], lr: 0.100000, loss: 0.9529
2022-07-17 02:26:47 - train: epoch 0048, iter [00200, 00390], lr: 0.100000, loss: 0.9467
2022-07-17 02:26:59 - train: epoch 0048, iter [00250, 00390], lr: 0.100000, loss: 1.1287
2022-07-17 02:27:11 - train: epoch 0048, iter [00300, 00390], lr: 0.100000, loss: 1.0668
2022-07-17 02:27:26 - train: epoch 0048, iter [00350, 00390], lr: 0.100000, loss: 1.3063
2022-07-17 02:27:38 - train: epoch 048, train_loss: 1.0616
2022-07-17 02:27:46 - eval: epoch: 048, acc1: 57.920%, acc5: 83.790%, test_loss: nan, per_image_load_time: 0.382ms, per_image_inference_time: 0.339ms
2022-07-17 02:27:47 - until epoch: 048, best_acc1: 62.110%
2022-07-17 02:27:47 - epoch 049 lr: 0.100000
2022-07-17 02:28:04 - train: epoch 0049, iter [00050, 00390], lr: 0.100000, loss: 1.2821
2022-07-17 02:28:19 - train: epoch 0049, iter [00100, 00390], lr: 0.100000, loss: 0.9439
2022-07-17 02:28:32 - train: epoch 0049, iter [00150, 00390], lr: 0.100000, loss: 1.1921
2022-07-17 02:28:46 - train: epoch 0049, iter [00200, 00390], lr: 0.100000, loss: 1.2725
2022-07-17 02:29:00 - train: epoch 0049, iter [00250, 00390], lr: 0.100000, loss: 1.1415
2022-07-17 02:29:13 - train: epoch 0049, iter [00300, 00390], lr: 0.100000, loss: 1.0393
2022-07-17 02:29:25 - train: epoch 0049, iter [00350, 00390], lr: 0.100000, loss: 1.0593
2022-07-17 02:29:38 - train: epoch 049, train_loss: 1.0444
2022-07-17 02:29:45 - eval: epoch: 049, acc1: 60.780%, acc5: 88.080%, test_loss: 1.4295, per_image_load_time: 0.307ms, per_image_inference_time: 0.325ms
2022-07-17 02:29:45 - until epoch: 049, best_acc1: 62.110%
2022-07-17 02:29:45 - epoch 050 lr: 0.100000
2022-07-17 02:29:59 - train: epoch 0050, iter [00050, 00390], lr: 0.100000, loss: 0.9597
2022-07-17 02:30:14 - train: epoch 0050, iter [00100, 00390], lr: 0.100000, loss: 0.7941
2022-07-17 02:30:30 - train: epoch 0050, iter [00150, 00390], lr: 0.100000, loss: 0.9920
2022-07-17 02:30:41 - train: epoch 0050, iter [00200, 00390], lr: 0.100000, loss: 0.8720
2022-07-17 02:30:54 - train: epoch 0050, iter [00250, 00390], lr: 0.100000, loss: 0.9892
2022-07-17 02:31:09 - train: epoch 0050, iter [00300, 00390], lr: 0.100000, loss: 0.9576
2022-07-17 02:31:22 - train: epoch 0050, iter [00350, 00390], lr: 0.100000, loss: 1.0278
2022-07-17 02:31:33 - train: epoch 050, train_loss: 1.0215
2022-07-17 02:31:40 - eval: epoch: 050, acc1: 60.810%, acc5: 87.180%, test_loss: 1.4437, per_image_load_time: 0.311ms, per_image_inference_time: 0.337ms
2022-07-17 02:31:41 - until epoch: 050, best_acc1: 62.110%
2022-07-17 02:31:41 - epoch 051 lr: 0.100000
2022-07-17 02:31:58 - train: epoch 0051, iter [00050, 00390], lr: 0.100000, loss: 1.0257
2022-07-17 02:32:09 - train: epoch 0051, iter [00100, 00390], lr: 0.100000, loss: 0.8433
2022-07-17 02:32:22 - train: epoch 0051, iter [00150, 00390], lr: 0.100000, loss: 0.9928
2022-07-17 02:32:37 - train: epoch 0051, iter [00200, 00390], lr: 0.100000, loss: 1.1044
2022-07-17 02:32:50 - train: epoch 0051, iter [00250, 00390], lr: 0.100000, loss: 1.0826
2022-07-17 02:33:02 - train: epoch 0051, iter [00300, 00390], lr: 0.100000, loss: 0.9086
2022-07-17 02:33:17 - train: epoch 0051, iter [00350, 00390], lr: 0.100000, loss: 0.9794
2022-07-17 02:33:29 - train: epoch 051, train_loss: 1.0218
2022-07-17 02:33:36 - eval: epoch: 051, acc1: 59.380%, acc5: 86.700%, test_loss: 1.5010, per_image_load_time: 0.329ms, per_image_inference_time: 0.337ms
2022-07-17 02:33:37 - until epoch: 051, best_acc1: 62.110%
2022-07-17 02:33:37 - epoch 052 lr: 0.100000
2022-07-17 02:33:55 - train: epoch 0052, iter [00050, 00390], lr: 0.100000, loss: 1.0034
2022-07-17 02:34:09 - train: epoch 0052, iter [00100, 00390], lr: 0.100000, loss: 0.8929
2022-07-17 02:34:22 - train: epoch 0052, iter [00150, 00390], lr: 0.100000, loss: 1.1631
2022-07-17 02:34:34 - train: epoch 0052, iter [00200, 00390], lr: 0.100000, loss: 1.0483
2022-07-17 02:34:50 - train: epoch 0052, iter [00250, 00390], lr: 0.100000, loss: 0.8373
2022-07-17 02:35:03 - train: epoch 0052, iter [00300, 00390], lr: 0.100000, loss: 1.0208
2022-07-17 02:35:16 - train: epoch 0052, iter [00350, 00390], lr: 0.100000, loss: 0.9003
2022-07-17 02:35:28 - train: epoch 052, train_loss: 1.0187
2022-07-17 02:35:35 - eval: epoch: 052, acc1: 60.720%, acc5: 87.840%, test_loss: 1.5129, per_image_load_time: 0.304ms, per_image_inference_time: 0.337ms
2022-07-17 02:35:36 - until epoch: 052, best_acc1: 62.110%
2022-07-17 02:35:36 - epoch 053 lr: 0.100000
2022-07-17 02:35:49 - train: epoch 0053, iter [00050, 00390], lr: 0.100000, loss: 0.9009
2022-07-17 02:36:03 - train: epoch 0053, iter [00100, 00390], lr: 0.100000, loss: 0.8093
2022-07-17 02:36:18 - train: epoch 0053, iter [00150, 00390], lr: 0.100000, loss: 0.9076
2022-07-17 02:36:31 - train: epoch 0053, iter [00200, 00390], lr: 0.100000, loss: 0.9249
2022-07-17 02:36:43 - train: epoch 0053, iter [00250, 00390], lr: 0.100000, loss: 0.9211
2022-07-17 02:36:58 - train: epoch 0053, iter [00300, 00390], lr: 0.100000, loss: 0.8960
2022-07-17 02:37:12 - train: epoch 0053, iter [00350, 00390], lr: 0.100000, loss: 1.0096
2022-07-17 02:37:20 - train: epoch 053, train_loss: 1.0039
2022-07-17 02:37:27 - eval: epoch: 053, acc1: 59.850%, acc5: 87.520%, test_loss: 1.5295, per_image_load_time: 0.267ms, per_image_inference_time: 0.324ms
2022-07-17 02:37:28 - until epoch: 053, best_acc1: 62.110%
2022-07-17 02:37:28 - epoch 054 lr: 0.100000
2022-07-17 02:37:45 - train: epoch 0054, iter [00050, 00390], lr: 0.100000, loss: 0.9620
2022-07-17 02:37:59 - train: epoch 0054, iter [00100, 00390], lr: 0.100000, loss: 0.9814
2022-07-17 02:38:13 - train: epoch 0054, iter [00150, 00390], lr: 0.100000, loss: 0.7834
2022-07-17 02:38:27 - train: epoch 0054, iter [00200, 00390], lr: 0.100000, loss: 1.1125
2022-07-17 02:38:41 - train: epoch 0054, iter [00250, 00390], lr: 0.100000, loss: 1.0178
2022-07-17 02:38:52 - train: epoch 0054, iter [00300, 00390], lr: 0.100000, loss: 1.0013
2022-07-17 02:39:07 - train: epoch 0054, iter [00350, 00390], lr: 0.100000, loss: 0.9045
2022-07-17 02:39:20 - train: epoch 054, train_loss: 1.0068
2022-07-17 02:39:26 - eval: epoch: 054, acc1: 39.220%, acc5: 64.340%, test_loss: 9.3173, per_image_load_time: 0.312ms, per_image_inference_time: 0.326ms
2022-07-17 02:39:27 - until epoch: 054, best_acc1: 62.110%
2022-07-17 02:39:27 - epoch 055 lr: 0.100000
2022-07-17 02:39:45 - train: epoch 0055, iter [00050, 00390], lr: 0.100000, loss: 1.0834
2022-07-17 02:40:00 - train: epoch 0055, iter [00100, 00390], lr: 0.100000, loss: 0.9941
2022-07-17 02:40:12 - train: epoch 0055, iter [00150, 00390], lr: 0.100000, loss: 0.9945
2022-07-17 02:40:25 - train: epoch 0055, iter [00200, 00390], lr: 0.100000, loss: 1.0827
2022-07-17 02:40:39 - train: epoch 0055, iter [00250, 00390], lr: 0.100000, loss: 1.0367
2022-07-17 02:40:53 - train: epoch 0055, iter [00300, 00390], lr: 0.100000, loss: 0.9416
2022-07-17 02:41:06 - train: epoch 0055, iter [00350, 00390], lr: 0.100000, loss: 0.8713
2022-07-17 02:41:18 - train: epoch 055, train_loss: 1.0258
2022-07-17 02:41:25 - eval: epoch: 055, acc1: 62.950%, acc5: 88.720%, test_loss: 1.3616, per_image_load_time: 0.283ms, per_image_inference_time: 0.331ms
2022-07-17 02:41:26 - until epoch: 055, best_acc1: 62.950%
2022-07-17 02:41:26 - epoch 056 lr: 0.100000
2022-07-17 02:41:40 - train: epoch 0056, iter [00050, 00390], lr: 0.100000, loss: 1.1484
2022-07-17 02:41:55 - train: epoch 0056, iter [00100, 00390], lr: 0.100000, loss: 0.9200
2022-07-17 02:42:09 - train: epoch 0056, iter [00150, 00390], lr: 0.100000, loss: 1.0030
2022-07-17 02:42:21 - train: epoch 0056, iter [00200, 00390], lr: 0.100000, loss: 1.0740
2022-07-17 02:42:35 - train: epoch 0056, iter [00250, 00390], lr: 0.100000, loss: 0.8468
2022-07-17 02:42:50 - train: epoch 0056, iter [00300, 00390], lr: 0.100000, loss: 1.3036
2022-07-17 02:43:03 - train: epoch 0056, iter [00350, 00390], lr: 0.100000, loss: 1.0702
2022-07-17 02:43:12 - train: epoch 056, train_loss: 0.9916
2022-07-17 02:43:19 - eval: epoch: 056, acc1: 60.410%, acc5: 86.470%, test_loss: 1.5081, per_image_load_time: 0.302ms, per_image_inference_time: 0.330ms
2022-07-17 02:43:20 - until epoch: 056, best_acc1: 62.950%
2022-07-17 02:43:20 - epoch 057 lr: 0.100000
2022-07-17 02:43:37 - train: epoch 0057, iter [00050, 00390], lr: 0.100000, loss: 1.0166
2022-07-17 02:43:48 - train: epoch 0057, iter [00100, 00390], lr: 0.100000, loss: 1.0061
2022-07-17 02:44:02 - train: epoch 0057, iter [00150, 00390], lr: 0.100000, loss: 0.8846
2022-07-17 02:44:16 - train: epoch 0057, iter [00200, 00390], lr: 0.100000, loss: 1.0198
2022-07-17 02:44:30 - train: epoch 0057, iter [00250, 00390], lr: 0.100000, loss: 1.1533
2022-07-17 02:44:42 - train: epoch 0057, iter [00300, 00390], lr: 0.100000, loss: 1.0642
2022-07-17 02:44:57 - train: epoch 0057, iter [00350, 00390], lr: 0.100000, loss: 1.0629
2022-07-17 02:45:09 - train: epoch 057, train_loss: 0.9918
2022-07-17 02:45:16 - eval: epoch: 057, acc1: 59.100%, acc5: 85.630%, test_loss: 1.5864, per_image_load_time: 0.317ms, per_image_inference_time: 0.344ms
2022-07-17 02:45:17 - until epoch: 057, best_acc1: 62.950%
2022-07-17 02:45:17 - epoch 058 lr: 0.100000
2022-07-17 02:45:36 - train: epoch 0058, iter [00050, 00390], lr: 0.100000, loss: 0.8945
2022-07-17 02:45:51 - train: epoch 0058, iter [00100, 00390], lr: 0.100000, loss: 0.8455
2022-07-17 02:46:03 - train: epoch 0058, iter [00150, 00390], lr: 0.100000, loss: 1.0035
2022-07-17 02:46:17 - train: epoch 0058, iter [00200, 00390], lr: 0.100000, loss: 1.0719
2022-07-17 02:46:32 - train: epoch 0058, iter [00250, 00390], lr: 0.100000, loss: 1.0303
2022-07-17 02:46:44 - train: epoch 0058, iter [00300, 00390], lr: 0.100000, loss: 1.1217
2022-07-17 02:46:57 - train: epoch 0058, iter [00350, 00390], lr: 0.100000, loss: 1.1628
2022-07-17 02:47:09 - train: epoch 058, train_loss: 0.9920
2022-07-17 02:47:16 - eval: epoch: 058, acc1: 60.720%, acc5: 87.740%, test_loss: 1.4368, per_image_load_time: 0.302ms, per_image_inference_time: 0.323ms
2022-07-17 02:47:17 - until epoch: 058, best_acc1: 62.950%
2022-07-17 02:47:17 - epoch 059 lr: 0.100000
2022-07-17 02:47:31 - train: epoch 0059, iter [00050, 00390], lr: 0.100000, loss: 0.8516
2022-07-17 02:47:46 - train: epoch 0059, iter [00100, 00390], lr: 0.100000, loss: 0.8126
2022-07-17 02:48:00 - train: epoch 0059, iter [00150, 00390], lr: 0.100000, loss: 0.9583
2022-07-17 02:48:12 - train: epoch 0059, iter [00200, 00390], lr: 0.100000, loss: 1.2083
2022-07-17 02:48:25 - train: epoch 0059, iter [00250, 00390], lr: 0.100000, loss: 1.2666
2022-07-17 02:48:40 - train: epoch 0059, iter [00300, 00390], lr: 0.100000, loss: 0.9832
2022-07-17 02:48:53 - train: epoch 0059, iter [00350, 00390], lr: 0.100000, loss: 1.2584
2022-07-17 02:49:02 - train: epoch 059, train_loss: 0.9723
2022-07-17 02:49:09 - eval: epoch: 059, acc1: 62.520%, acc5: 88.810%, test_loss: 1.3431, per_image_load_time: 0.299ms, per_image_inference_time: 0.347ms
2022-07-17 02:49:10 - until epoch: 059, best_acc1: 62.950%
2022-07-17 02:49:10 - epoch 060 lr: 0.100000
2022-07-17 02:49:28 - train: epoch 0060, iter [00050, 00390], lr: 0.100000, loss: 0.9570
2022-07-17 02:49:39 - train: epoch 0060, iter [00100, 00390], lr: 0.100000, loss: 1.1273
2022-07-17 02:49:53 - train: epoch 0060, iter [00150, 00390], lr: 0.100000, loss: 0.7308
2022-07-17 02:50:08 - train: epoch 0060, iter [00200, 00390], lr: 0.100000, loss: 0.8521
2022-07-17 02:50:21 - train: epoch 0060, iter [00250, 00390], lr: 0.100000, loss: 0.9384
2022-07-17 02:50:33 - train: epoch 0060, iter [00300, 00390], lr: 0.100000, loss: 0.9330
2022-07-17 02:50:48 - train: epoch 0060, iter [00350, 00390], lr: 0.100000, loss: 1.0177
2022-07-17 02:51:00 - train: epoch 060, train_loss: 0.9792
2022-07-17 02:51:08 - eval: epoch: 060, acc1: 61.510%, acc5: 88.150%, test_loss: 1.4221, per_image_load_time: 0.426ms, per_image_inference_time: 0.356ms
2022-07-17 02:51:09 - until epoch: 060, best_acc1: 62.950%
2022-07-17 02:51:09 - epoch 061 lr: 0.020000
2022-07-17 02:51:28 - train: epoch 0061, iter [00050, 00390], lr: 0.020000, loss: 0.5583
2022-07-17 02:51:43 - train: epoch 0061, iter [00100, 00390], lr: 0.020000, loss: 0.4971
2022-07-17 02:51:54 - train: epoch 0061, iter [00150, 00390], lr: 0.020000, loss: 0.5265
2022-07-17 02:52:07 - train: epoch 0061, iter [00200, 00390], lr: 0.020000, loss: 0.6137
2022-07-17 02:52:22 - train: epoch 0061, iter [00250, 00390], lr: 0.020000, loss: 0.3709
2022-07-17 02:52:36 - train: epoch 0061, iter [00300, 00390], lr: 0.020000, loss: 0.3685
2022-07-17 02:52:47 - train: epoch 0061, iter [00350, 00390], lr: 0.020000, loss: 0.3732
2022-07-17 02:52:59 - train: epoch 061, train_loss: 0.5188
2022-07-17 02:53:06 - eval: epoch: 061, acc1: 73.940%, acc5: 93.520%, test_loss: 0.9407, per_image_load_time: 0.280ms, per_image_inference_time: 0.347ms
2022-07-17 02:53:07 - until epoch: 061, best_acc1: 73.940%
2022-07-17 02:53:07 - epoch 062 lr: 0.020000
2022-07-17 02:53:21 - train: epoch 0062, iter [00050, 00390], lr: 0.020000, loss: 0.2337
2022-07-17 02:53:34 - train: epoch 0062, iter [00100, 00390], lr: 0.020000, loss: 0.3776
2022-07-17 02:53:49 - train: epoch 0062, iter [00150, 00390], lr: 0.020000, loss: 0.3351
2022-07-17 02:54:03 - train: epoch 0062, iter [00200, 00390], lr: 0.020000, loss: 0.2776
2022-07-17 02:54:15 - train: epoch 0062, iter [00250, 00390], lr: 0.020000, loss: 0.3581
2022-07-17 02:54:30 - train: epoch 0062, iter [00300, 00390], lr: 0.020000, loss: 0.2289
2022-07-17 02:54:45 - train: epoch 0062, iter [00350, 00390], lr: 0.020000, loss: 0.3538
2022-07-17 02:54:53 - train: epoch 062, train_loss: 0.3732
2022-07-17 02:55:01 - eval: epoch: 062, acc1: 73.810%, acc5: 93.400%, test_loss: 1.0208, per_image_load_time: 0.342ms, per_image_inference_time: 0.337ms
2022-07-17 02:55:01 - until epoch: 062, best_acc1: 73.940%
2022-07-17 02:55:01 - epoch 063 lr: 0.020000
2022-07-17 02:55:19 - train: epoch 0063, iter [00050, 00390], lr: 0.020000, loss: 0.3222
2022-07-17 02:55:32 - train: epoch 0063, iter [00100, 00390], lr: 0.020000, loss: 0.2493
2022-07-17 02:55:45 - train: epoch 0063, iter [00150, 00390], lr: 0.020000, loss: 0.1924
2022-07-17 02:56:00 - train: epoch 0063, iter [00200, 00390], lr: 0.020000, loss: 0.3445
2022-07-17 02:56:14 - train: epoch 0063, iter [00250, 00390], lr: 0.020000, loss: 0.3756
2022-07-17 02:56:26 - train: epoch 0063, iter [00300, 00390], lr: 0.020000, loss: 0.3293
2022-07-17 02:56:40 - train: epoch 0063, iter [00350, 00390], lr: 0.020000, loss: 0.3172
2022-07-17 02:56:52 - train: epoch 063, train_loss: 0.3114
2022-07-17 02:56:59 - eval: epoch: 063, acc1: 74.140%, acc5: 93.880%, test_loss: 0.9756, per_image_load_time: 0.294ms, per_image_inference_time: 0.345ms
2022-07-17 02:57:00 - until epoch: 063, best_acc1: 74.140%
2022-07-17 02:57:00 - epoch 064 lr: 0.020000
2022-07-17 02:57:19 - train: epoch 0064, iter [00050, 00390], lr: 0.020000, loss: 0.1612
2022-07-17 02:57:34 - train: epoch 0064, iter [00100, 00390], lr: 0.020000, loss: 0.2535
2022-07-17 02:57:45 - train: epoch 0064, iter [00150, 00390], lr: 0.020000, loss: 0.3002
2022-07-17 02:57:59 - train: epoch 0064, iter [00200, 00390], lr: 0.020000, loss: 0.3592
2022-07-17 02:58:13 - train: epoch 0064, iter [00250, 00390], lr: 0.020000, loss: 0.3596
2022-07-17 02:58:27 - train: epoch 0064, iter [00300, 00390], lr: 0.020000, loss: 0.2729
2022-07-17 02:58:38 - train: epoch 0064, iter [00350, 00390], lr: 0.020000, loss: 0.3112
2022-07-17 02:58:50 - train: epoch 064, train_loss: 0.2731
2022-07-17 02:58:58 - eval: epoch: 064, acc1: 73.720%, acc5: 93.890%, test_loss: 0.9890, per_image_load_time: 0.320ms, per_image_inference_time: 0.330ms
2022-07-17 02:58:58 - until epoch: 064, best_acc1: 74.140%
2022-07-17 02:58:58 - epoch 065 lr: 0.020000
2022-07-17 02:59:12 - train: epoch 0065, iter [00050, 00390], lr: 0.020000, loss: 0.2230
2022-07-17 02:59:25 - train: epoch 0065, iter [00100, 00390], lr: 0.020000, loss: 0.3132
2022-07-17 02:59:40 - train: epoch 0065, iter [00150, 00390], lr: 0.020000, loss: 0.2091
2022-07-17 02:59:53 - train: epoch 0065, iter [00200, 00390], lr: 0.020000, loss: 0.3062
2022-07-17 03:00:05 - train: epoch 0065, iter [00250, 00390], lr: 0.020000, loss: 0.2738
2022-07-17 03:00:20 - train: epoch 0065, iter [00300, 00390], lr: 0.020000, loss: 0.2546
2022-07-17 03:00:35 - train: epoch 0065, iter [00350, 00390], lr: 0.020000, loss: 0.3698
2022-07-17 03:00:43 - train: epoch 065, train_loss: 0.2436
2022-07-17 03:00:50 - eval: epoch: 065, acc1: 73.900%, acc5: 93.700%, test_loss: 1.0039, per_image_load_time: 0.273ms, per_image_inference_time: 0.326ms
2022-07-17 03:00:51 - until epoch: 065, best_acc1: 74.140%
2022-07-17 03:00:51 - epoch 066 lr: 0.020000
2022-07-17 03:01:08 - train: epoch 0066, iter [00050, 00390], lr: 0.020000, loss: 0.1812
2022-07-17 03:01:20 - train: epoch 0066, iter [00100, 00390], lr: 0.020000, loss: 0.1548
2022-07-17 03:01:32 - train: epoch 0066, iter [00150, 00390], lr: 0.020000, loss: 0.2644
2022-07-17 03:01:47 - train: epoch 0066, iter [00200, 00390], lr: 0.020000, loss: 0.1565
2022-07-17 03:02:02 - train: epoch 0066, iter [00250, 00390], lr: 0.020000, loss: 0.2356
2022-07-17 03:02:13 - train: epoch 0066, iter [00300, 00390], lr: 0.020000, loss: 0.2293
2022-07-17 03:02:28 - train: epoch 0066, iter [00350, 00390], lr: 0.020000, loss: 0.2272
2022-07-17 03:02:40 - train: epoch 066, train_loss: 0.2218
2022-07-17 03:02:47 - eval: epoch: 066, acc1: 73.810%, acc5: 93.730%, test_loss: 1.0243, per_image_load_time: 0.341ms, per_image_inference_time: 0.311ms
2022-07-17 03:02:48 - until epoch: 066, best_acc1: 74.140%
2022-07-17 03:02:48 - epoch 067 lr: 0.020000
2022-07-17 03:03:05 - train: epoch 0067, iter [00050, 00390], lr: 0.020000, loss: 0.1913
2022-07-17 03:03:20 - train: epoch 0067, iter [00100, 00390], lr: 0.020000, loss: 0.1721
2022-07-17 03:03:34 - train: epoch 0067, iter [00150, 00390], lr: 0.020000, loss: 0.1688
2022-07-17 03:03:48 - train: epoch 0067, iter [00200, 00390], lr: 0.020000, loss: 0.1614
2022-07-17 03:04:02 - train: epoch 0067, iter [00250, 00390], lr: 0.020000, loss: 0.1785
2022-07-17 03:04:15 - train: epoch 0067, iter [00300, 00390], lr: 0.020000, loss: 0.1760
2022-07-17 03:04:27 - train: epoch 0067, iter [00350, 00390], lr: 0.020000, loss: 0.2139
2022-07-17 03:04:40 - train: epoch 067, train_loss: 0.2046
2022-07-17 03:04:47 - eval: epoch: 067, acc1: 73.330%, acc5: 93.330%, test_loss: 1.0479, per_image_load_time: 0.315ms, per_image_inference_time: 0.331ms
2022-07-17 03:04:47 - until epoch: 067, best_acc1: 74.140%
2022-07-17 03:04:47 - epoch 068 lr: 0.020000
2022-07-17 03:05:02 - train: epoch 0068, iter [00050, 00390], lr: 0.020000, loss: 0.2144
2022-07-17 03:05:15 - train: epoch 0068, iter [00100, 00390], lr: 0.020000, loss: 0.1088
2022-07-17 03:05:30 - train: epoch 0068, iter [00150, 00390], lr: 0.020000, loss: 0.1560
2022-07-17 03:05:43 - train: epoch 0068, iter [00200, 00390], lr: 0.020000, loss: 0.2022
2022-07-17 03:05:55 - train: epoch 0068, iter [00250, 00390], lr: 0.020000, loss: 0.2221
2022-07-17 03:06:09 - train: epoch 0068, iter [00300, 00390], lr: 0.020000, loss: 0.1341
2022-07-17 03:06:25 - train: epoch 0068, iter [00350, 00390], lr: 0.020000, loss: 0.2331
2022-07-17 03:06:33 - train: epoch 068, train_loss: 0.1921
2022-07-17 03:06:40 - eval: epoch: 068, acc1: 73.030%, acc5: 93.160%, test_loss: 1.1502, per_image_load_time: 0.347ms, per_image_inference_time: 0.326ms
2022-07-17 03:06:41 - until epoch: 068, best_acc1: 74.140%
2022-07-17 03:06:41 - epoch 069 lr: 0.020000
2022-07-17 03:06:59 - train: epoch 0069, iter [00050, 00390], lr: 0.020000, loss: 0.1379
2022-07-17 03:07:12 - train: epoch 0069, iter [00100, 00390], lr: 0.020000, loss: 0.1339
2022-07-17 03:07:25 - train: epoch 0069, iter [00150, 00390], lr: 0.020000, loss: 0.1963
2022-07-17 03:07:40 - train: epoch 0069, iter [00200, 00390], lr: 0.020000, loss: 0.1859
2022-07-17 03:07:53 - train: epoch 0069, iter [00250, 00390], lr: 0.020000, loss: 0.1865
2022-07-17 03:08:04 - train: epoch 0069, iter [00300, 00390], lr: 0.020000, loss: 0.2335
2022-07-17 03:08:20 - train: epoch 0069, iter [00350, 00390], lr: 0.020000, loss: 0.1725
2022-07-17 03:08:32 - train: epoch 069, train_loss: 0.1920
2022-07-17 03:08:40 - eval: epoch: 069, acc1: 72.610%, acc5: 92.580%, test_loss: 1.3559, per_image_load_time: 0.378ms, per_image_inference_time: 0.339ms
2022-07-17 03:08:40 - until epoch: 069, best_acc1: 74.140%
2022-07-17 03:08:40 - epoch 070 lr: 0.020000
2022-07-17 03:08:58 - train: epoch 0070, iter [00050, 00390], lr: 0.020000, loss: 0.0868
2022-07-17 03:09:13 - train: epoch 0070, iter [00100, 00390], lr: 0.020000, loss: 0.1887
2022-07-17 03:09:25 - train: epoch 0070, iter [00150, 00390], lr: 0.020000, loss: 0.2195
2022-07-17 03:09:37 - train: epoch 0070, iter [00200, 00390], lr: 0.020000, loss: 0.1612
2022-07-17 03:09:51 - train: epoch 0070, iter [00250, 00390], lr: 0.020000, loss: 0.2061
2022-07-17 03:10:06 - train: epoch 0070, iter [00300, 00390], lr: 0.020000, loss: 0.2183
2022-07-17 03:10:16 - train: epoch 0070, iter [00350, 00390], lr: 0.020000, loss: 0.2084
2022-07-17 03:10:28 - train: epoch 070, train_loss: 0.1886
2022-07-17 03:10:35 - eval: epoch: 070, acc1: 71.960%, acc5: 92.370%, test_loss: 1.2464, per_image_load_time: 0.303ms, per_image_inference_time: 0.328ms
2022-07-17 03:10:35 - until epoch: 070, best_acc1: 74.140%
2022-07-17 03:10:35 - epoch 071 lr: 0.020000
2022-07-17 03:10:51 - train: epoch 0071, iter [00050, 00390], lr: 0.020000, loss: 0.1325
2022-07-17 03:11:03 - train: epoch 0071, iter [00100, 00390], lr: 0.020000, loss: 0.1341
2022-07-17 03:11:18 - train: epoch 0071, iter [00150, 00390], lr: 0.020000, loss: 0.1801
2022-07-17 03:11:32 - train: epoch 0071, iter [00200, 00390], lr: 0.020000, loss: 0.1900
2022-07-17 03:11:43 - train: epoch 0071, iter [00250, 00390], lr: 0.020000, loss: 0.1881
2022-07-17 03:11:59 - train: epoch 0071, iter [00300, 00390], lr: 0.020000, loss: 0.2277
2022-07-17 03:12:13 - train: epoch 0071, iter [00350, 00390], lr: 0.020000, loss: 0.1721
2022-07-17 03:12:23 - train: epoch 071, train_loss: 0.1822
2022-07-17 03:12:30 - eval: epoch: 071, acc1: 72.010%, acc5: 93.000%, test_loss: 1.1644, per_image_load_time: 0.305ms, per_image_inference_time: 0.319ms
2022-07-17 03:12:31 - until epoch: 071, best_acc1: 74.140%
2022-07-17 03:12:31 - epoch 072 lr: 0.020000
2022-07-17 03:12:48 - train: epoch 0072, iter [00050, 00390], lr: 0.020000, loss: 0.1017
2022-07-17 03:13:02 - train: epoch 0072, iter [00100, 00390], lr: 0.020000, loss: 0.1555
2022-07-17 03:13:14 - train: epoch 0072, iter [00150, 00390], lr: 0.020000, loss: 0.2288
2022-07-17 03:13:29 - train: epoch 0072, iter [00200, 00390], lr: 0.020000, loss: 0.1726
2022-07-17 03:13:44 - train: epoch 0072, iter [00250, 00390], lr: 0.020000, loss: 0.1671
2022-07-17 03:13:56 - train: epoch 0072, iter [00300, 00390], lr: 0.020000, loss: 0.1025
2022-07-17 03:14:11 - train: epoch 0072, iter [00350, 00390], lr: 0.020000, loss: 0.1813
2022-07-17 03:14:23 - train: epoch 072, train_loss: 0.2002
2022-07-17 03:14:30 - eval: epoch: 072, acc1: 71.920%, acc5: 92.750%, test_loss: 1.1598, per_image_load_time: 0.341ms, per_image_inference_time: 0.319ms
2022-07-17 03:14:31 - until epoch: 072, best_acc1: 74.140%
2022-07-17 03:14:31 - epoch 073 lr: 0.020000
2022-07-17 03:14:49 - train: epoch 0073, iter [00050, 00390], lr: 0.020000, loss: 0.1418
2022-07-17 03:15:04 - train: epoch 0073, iter [00100, 00390], lr: 0.020000, loss: 0.1580
2022-07-17 03:15:16 - train: epoch 0073, iter [00150, 00390], lr: 0.020000, loss: 0.2116
2022-07-17 03:15:29 - train: epoch 0073, iter [00200, 00390], lr: 0.020000, loss: 0.3162
2022-07-17 03:15:44 - train: epoch 0073, iter [00250, 00390], lr: 0.020000, loss: 0.2168
2022-07-17 03:15:57 - train: epoch 0073, iter [00300, 00390], lr: 0.020000, loss: 0.2047
2022-07-17 03:16:08 - train: epoch 0073, iter [00350, 00390], lr: 0.020000, loss: 0.2647
2022-07-17 03:16:21 - train: epoch 073, train_loss: 0.1943
2022-07-17 03:16:28 - eval: epoch: 073, acc1: 72.090%, acc5: 92.460%, test_loss: 1.1981, per_image_load_time: 0.313ms, per_image_inference_time: 0.333ms
2022-07-17 03:16:28 - until epoch: 073, best_acc1: 74.140%
2022-07-17 03:16:28 - epoch 074 lr: 0.020000
2022-07-17 03:16:44 - train: epoch 0074, iter [00050, 00390], lr: 0.020000, loss: 0.1879
2022-07-17 03:16:57 - train: epoch 0074, iter [00100, 00390], lr: 0.020000, loss: 0.1267
2022-07-17 03:17:12 - train: epoch 0074, iter [00150, 00390], lr: 0.020000, loss: 0.3096
2022-07-17 03:17:25 - train: epoch 0074, iter [00200, 00390], lr: 0.020000, loss: 0.2534
2022-07-17 03:17:37 - train: epoch 0074, iter [00250, 00390], lr: 0.020000, loss: 0.1366
2022-07-17 03:17:52 - train: epoch 0074, iter [00300, 00390], lr: 0.020000, loss: 0.1167
2022-07-17 03:18:07 - train: epoch 0074, iter [00350, 00390], lr: 0.020000, loss: 0.2145
2022-07-17 03:18:15 - train: epoch 074, train_loss: 0.2099
2022-07-17 03:18:22 - eval: epoch: 074, acc1: 69.670%, acc5: 91.300%, test_loss: 1.3365, per_image_load_time: 0.318ms, per_image_inference_time: 0.326ms
2022-07-17 03:18:23 - until epoch: 074, best_acc1: 74.140%
2022-07-17 03:18:23 - epoch 075 lr: 0.020000
2022-07-17 03:18:41 - train: epoch 0075, iter [00050, 00390], lr: 0.020000, loss: 0.2091
2022-07-17 03:18:54 - train: epoch 0075, iter [00100, 00390], lr: 0.020000, loss: 0.2709
2022-07-17 03:19:07 - train: epoch 0075, iter [00150, 00390], lr: 0.020000, loss: 0.2295
2022-07-17 03:19:22 - train: epoch 0075, iter [00200, 00390], lr: 0.020000, loss: 0.2604
2022-07-17 03:19:36 - train: epoch 0075, iter [00250, 00390], lr: 0.020000, loss: 0.2001
2022-07-17 03:19:49 - train: epoch 0075, iter [00300, 00390], lr: 0.020000, loss: 0.1544
2022-07-17 03:20:04 - train: epoch 0075, iter [00350, 00390], lr: 0.020000, loss: 0.2569
2022-07-17 03:20:16 - train: epoch 075, train_loss: 0.2105
2022-07-17 03:20:23 - eval: epoch: 075, acc1: 72.270%, acc5: 92.510%, test_loss: 1.1673, per_image_load_time: 0.349ms, per_image_inference_time: 0.356ms
2022-07-17 03:20:24 - until epoch: 075, best_acc1: 74.140%
2022-07-17 03:20:24 - epoch 076 lr: 0.020000
2022-07-17 03:20:42 - train: epoch 0076, iter [00050, 00390], lr: 0.020000, loss: 0.2357
2022-07-17 03:20:57 - train: epoch 0076, iter [00100, 00390], lr: 0.020000, loss: 0.1898
2022-07-17 03:21:08 - train: epoch 0076, iter [00150, 00390], lr: 0.020000, loss: 0.1363
2022-07-17 03:21:22 - train: epoch 0076, iter [00200, 00390], lr: 0.020000, loss: 0.1785
2022-07-17 03:21:37 - train: epoch 0076, iter [00250, 00390], lr: 0.020000, loss: 0.1572
2022-07-17 03:21:49 - train: epoch 0076, iter [00300, 00390], lr: 0.020000, loss: 0.3681
2022-07-17 03:22:01 - train: epoch 0076, iter [00350, 00390], lr: 0.020000, loss: 0.2693
2022-07-17 03:22:13 - train: epoch 076, train_loss: 0.2065
2022-07-17 03:22:20 - eval: epoch: 076, acc1: 71.120%, acc5: 91.850%, test_loss: 1.2231, per_image_load_time: 0.287ms, per_image_inference_time: 0.334ms
2022-07-17 03:22:21 - until epoch: 076, best_acc1: 74.140%
2022-07-17 03:22:21 - epoch 077 lr: 0.020000
2022-07-17 03:22:35 - train: epoch 0077, iter [00050, 00390], lr: 0.020000, loss: 0.1374
2022-07-17 03:22:48 - train: epoch 0077, iter [00100, 00390], lr: 0.020000, loss: 0.2474
2022-07-17 03:23:03 - train: epoch 0077, iter [00150, 00390], lr: 0.020000, loss: 0.1960
2022-07-17 03:23:16 - train: epoch 0077, iter [00200, 00390], lr: 0.020000, loss: 0.2206
2022-07-17 03:23:29 - train: epoch 0077, iter [00250, 00390], lr: 0.020000, loss: 0.1986
2022-07-17 03:23:43 - train: epoch 0077, iter [00300, 00390], lr: 0.020000, loss: 0.2600
2022-07-17 03:23:57 - train: epoch 0077, iter [00350, 00390], lr: 0.020000, loss: 0.2279
2022-07-17 03:24:06 - train: epoch 077, train_loss: 0.2076
2022-07-17 03:24:13 - eval: epoch: 077, acc1: 71.460%, acc5: 92.030%, test_loss: 1.2323, per_image_load_time: 0.299ms, per_image_inference_time: 0.336ms
2022-07-17 03:24:14 - until epoch: 077, best_acc1: 74.140%
2022-07-17 03:24:14 - epoch 078 lr: 0.020000
2022-07-17 03:24:32 - train: epoch 0078, iter [00050, 00390], lr: 0.020000, loss: 0.2095
2022-07-17 03:24:43 - train: epoch 0078, iter [00100, 00390], lr: 0.020000, loss: 0.1244
2022-07-17 03:24:57 - train: epoch 0078, iter [00150, 00390], lr: 0.020000, loss: 0.2579
2022-07-17 03:25:12 - train: epoch 0078, iter [00200, 00390], lr: 0.020000, loss: 0.1521
2022-07-17 03:25:24 - train: epoch 0078, iter [00250, 00390], lr: 0.020000, loss: 0.2156
2022-07-17 03:25:36 - train: epoch 0078, iter [00300, 00390], lr: 0.020000, loss: 0.1839
2022-07-17 03:25:51 - train: epoch 0078, iter [00350, 00390], lr: 0.020000, loss: 0.2458
2022-07-17 03:26:04 - train: epoch 078, train_loss: 0.2116
2022-07-17 03:26:12 - eval: epoch: 078, acc1: 71.710%, acc5: 92.510%, test_loss: 1.1743, per_image_load_time: 0.402ms, per_image_inference_time: 0.348ms
2022-07-17 03:26:12 - until epoch: 078, best_acc1: 74.140%
2022-07-17 03:26:12 - epoch 079 lr: 0.020000
2022-07-17 03:26:30 - train: epoch 0079, iter [00050, 00390], lr: 0.020000, loss: 0.1954
2022-07-17 03:26:45 - train: epoch 0079, iter [00100, 00390], lr: 0.020000, loss: 0.2372
2022-07-17 03:26:57 - train: epoch 0079, iter [00150, 00390], lr: 0.020000, loss: 0.2983
2022-07-17 03:27:10 - train: epoch 0079, iter [00200, 00390], lr: 0.020000, loss: 0.1715
2022-07-17 03:27:25 - train: epoch 0079, iter [00250, 00390], lr: 0.020000, loss: 0.3039
2022-07-17 03:27:39 - train: epoch 0079, iter [00300, 00390], lr: 0.020000, loss: 0.2713
2022-07-17 03:27:51 - train: epoch 0079, iter [00350, 00390], lr: 0.020000, loss: 0.2876
2022-07-17 03:28:03 - train: epoch 079, train_loss: 0.2187
2022-07-17 03:28:10 - eval: epoch: 079, acc1: 70.920%, acc5: 92.320%, test_loss: 1.2386, per_image_load_time: 0.257ms, per_image_inference_time: 0.325ms
2022-07-17 03:28:10 - until epoch: 079, best_acc1: 74.140%
2022-07-17 03:28:10 - epoch 080 lr: 0.020000
2022-07-17 03:28:24 - train: epoch 0080, iter [00050, 00390], lr: 0.020000, loss: 0.2445
2022-07-17 03:28:33 - train: epoch 0080, iter [00100, 00390], lr: 0.020000, loss: 0.2693
2022-07-17 03:28:42 - train: epoch 0080, iter [00150, 00390], lr: 0.020000, loss: 0.2078
2022-07-17 03:28:51 - train: epoch 0080, iter [00200, 00390], lr: 0.020000, loss: 0.2844
2022-07-17 03:29:01 - train: epoch 0080, iter [00250, 00390], lr: 0.020000, loss: 0.3256
2022-07-17 03:29:09 - train: epoch 0080, iter [00300, 00390], lr: 0.020000, loss: 0.3064
2022-07-17 03:29:19 - train: epoch 0080, iter [00350, 00390], lr: 0.020000, loss: 0.3500
2022-07-17 03:29:27 - train: epoch 080, train_loss: 0.2309
2022-07-17 03:29:34 - eval: epoch: 080, acc1: 69.850%, acc5: 91.880%, test_loss: 1.2655, per_image_load_time: 0.328ms, per_image_inference_time: 0.306ms
2022-07-17 03:29:34 - until epoch: 080, best_acc1: 74.140%
2022-07-17 03:29:34 - epoch 081 lr: 0.020000
2022-07-17 03:29:47 - train: epoch 0081, iter [00050, 00390], lr: 0.020000, loss: 0.1824
2022-07-17 03:29:56 - train: epoch 0081, iter [00100, 00390], lr: 0.020000, loss: 0.2660
2022-07-17 03:30:06 - train: epoch 0081, iter [00150, 00390], lr: 0.020000, loss: 0.1906
2022-07-17 03:30:15 - train: epoch 0081, iter [00200, 00390], lr: 0.020000, loss: 0.2059
2022-07-17 03:30:25 - train: epoch 0081, iter [00250, 00390], lr: 0.020000, loss: 0.1900
2022-07-17 03:30:34 - train: epoch 0081, iter [00300, 00390], lr: 0.020000, loss: 0.2491
2022-07-17 03:30:44 - train: epoch 0081, iter [00350, 00390], lr: 0.020000, loss: 0.2346
2022-07-17 03:30:52 - train: epoch 081, train_loss: 0.2363
2022-07-17 03:30:58 - eval: epoch: 081, acc1: 69.310%, acc5: 91.360%, test_loss: 1.3393, per_image_load_time: 0.292ms, per_image_inference_time: 0.301ms
2022-07-17 03:30:59 - until epoch: 081, best_acc1: 74.140%
2022-07-17 03:30:59 - epoch 082 lr: 0.020000
2022-07-17 03:31:11 - train: epoch 0082, iter [00050, 00390], lr: 0.020000, loss: 0.1963
2022-07-17 03:31:20 - train: epoch 0082, iter [00100, 00390], lr: 0.020000, loss: 0.1759
2022-07-17 03:31:30 - train: epoch 0082, iter [00150, 00390], lr: 0.020000, loss: 0.1818
2022-07-17 03:31:39 - train: epoch 0082, iter [00200, 00390], lr: 0.020000, loss: 0.1604
2022-07-17 03:31:48 - train: epoch 0082, iter [00250, 00390], lr: 0.020000, loss: 0.2397
2022-07-17 03:31:57 - train: epoch 0082, iter [00300, 00390], lr: 0.020000, loss: 0.2128
2022-07-17 03:32:06 - train: epoch 0082, iter [00350, 00390], lr: 0.020000, loss: 0.2422
2022-07-17 03:32:13 - train: epoch 082, train_loss: 0.2131
2022-07-17 03:32:22 - eval: epoch: 082, acc1: 70.920%, acc5: 92.090%, test_loss: 1.2520, per_image_load_time: 0.514ms, per_image_inference_time: 0.298ms
2022-07-17 03:32:23 - until epoch: 082, best_acc1: 74.140%
2022-07-17 03:32:23 - epoch 083 lr: 0.020000
2022-07-17 03:32:37 - train: epoch 0083, iter [00050, 00390], lr: 0.020000, loss: 0.1811
2022-07-17 03:32:46 - train: epoch 0083, iter [00100, 00390], lr: 0.020000, loss: 0.2358
2022-07-17 03:32:55 - train: epoch 0083, iter [00150, 00390], lr: 0.020000, loss: 0.2016
2022-07-17 03:33:04 - train: epoch 0083, iter [00200, 00390], lr: 0.020000, loss: 0.2005
2022-07-17 03:33:13 - train: epoch 0083, iter [00250, 00390], lr: 0.020000, loss: 0.2916
2022-07-17 03:33:22 - train: epoch 0083, iter [00300, 00390], lr: 0.020000, loss: 0.2111
2022-07-17 03:33:31 - train: epoch 0083, iter [00350, 00390], lr: 0.020000, loss: 0.2812
2022-07-17 03:33:39 - train: epoch 083, train_loss: 0.2205
2022-07-17 03:33:47 - eval: epoch: 083, acc1: 70.910%, acc5: 91.990%, test_loss: 1.2495, per_image_load_time: 0.526ms, per_image_inference_time: 0.304ms
2022-07-17 03:33:48 - until epoch: 083, best_acc1: 74.140%
2022-07-17 03:33:48 - epoch 084 lr: 0.020000
2022-07-17 03:34:02 - train: epoch 0084, iter [00050, 00390], lr: 0.020000, loss: 0.1904
2022-07-17 03:34:11 - train: epoch 0084, iter [00100, 00390], lr: 0.020000, loss: 0.2366
2022-07-17 03:34:21 - train: epoch 0084, iter [00150, 00390], lr: 0.020000, loss: 0.1836
2022-07-17 03:34:30 - train: epoch 0084, iter [00200, 00390], lr: 0.020000, loss: 0.2062
2022-07-17 03:34:39 - train: epoch 0084, iter [00250, 00390], lr: 0.020000, loss: 0.2159
2022-07-17 03:34:48 - train: epoch 0084, iter [00300, 00390], lr: 0.020000, loss: 0.3186
2022-07-17 03:34:57 - train: epoch 0084, iter [00350, 00390], lr: 0.020000, loss: 0.1806
2022-07-17 03:35:05 - train: epoch 084, train_loss: 0.2220
2022-07-17 03:35:13 - eval: epoch: 084, acc1: 69.740%, acc5: 91.240%, test_loss: 1.3155, per_image_load_time: 0.478ms, per_image_inference_time: 0.296ms
2022-07-17 03:35:14 - until epoch: 084, best_acc1: 74.140%
2022-07-17 03:35:14 - epoch 085 lr: 0.020000
2022-07-17 03:35:27 - train: epoch 0085, iter [00050, 00390], lr: 0.020000, loss: 0.1359
2022-07-17 03:35:36 - train: epoch 0085, iter [00100, 00390], lr: 0.020000, loss: 0.1812
2022-07-17 03:35:45 - train: epoch 0085, iter [00150, 00390], lr: 0.020000, loss: 0.2884
2022-07-17 03:35:54 - train: epoch 0085, iter [00200, 00390], lr: 0.020000, loss: 0.1294
2022-07-17 03:36:03 - train: epoch 0085, iter [00250, 00390], lr: 0.020000, loss: 0.2090
2022-07-17 03:36:12 - train: epoch 0085, iter [00300, 00390], lr: 0.020000, loss: 0.1609
2022-07-17 03:36:21 - train: epoch 0085, iter [00350, 00390], lr: 0.020000, loss: 0.3296
2022-07-17 03:36:28 - train: epoch 085, train_loss: 0.2143
2022-07-17 03:36:36 - eval: epoch: 085, acc1: 71.290%, acc5: 92.250%, test_loss: 1.2151, per_image_load_time: 0.469ms, per_image_inference_time: 0.293ms
2022-07-17 03:36:37 - until epoch: 085, best_acc1: 74.140%
2022-07-17 03:36:37 - epoch 086 lr: 0.020000
2022-07-17 03:36:50 - train: epoch 0086, iter [00050, 00390], lr: 0.020000, loss: 0.1169
2022-07-17 03:36:59 - train: epoch 0086, iter [00100, 00390], lr: 0.020000, loss: 0.1999
2022-07-17 03:37:08 - train: epoch 0086, iter [00150, 00390], lr: 0.020000, loss: 0.2382
2022-07-17 03:37:18 - train: epoch 0086, iter [00200, 00390], lr: 0.020000, loss: 0.2499
2022-07-17 03:37:27 - train: epoch 0086, iter [00250, 00390], lr: 0.020000, loss: 0.1473
2022-07-17 03:37:36 - train: epoch 0086, iter [00300, 00390], lr: 0.020000, loss: 0.1592
2022-07-17 03:37:45 - train: epoch 0086, iter [00350, 00390], lr: 0.020000, loss: 0.2131
2022-07-17 03:37:53 - train: epoch 086, train_loss: 0.2084
2022-07-17 03:38:01 - eval: epoch: 086, acc1: 70.280%, acc5: 91.960%, test_loss: 1.2959, per_image_load_time: 0.468ms, per_image_inference_time: 0.294ms
2022-07-17 03:38:01 - until epoch: 086, best_acc1: 74.140%
2022-07-17 03:38:01 - epoch 087 lr: 0.020000
2022-07-17 03:38:16 - train: epoch 0087, iter [00050, 00390], lr: 0.020000, loss: 0.1951
2022-07-17 03:38:25 - train: epoch 0087, iter [00100, 00390], lr: 0.020000, loss: 0.2235
2022-07-17 03:38:34 - train: epoch 0087, iter [00150, 00390], lr: 0.020000, loss: 0.1537
2022-07-17 03:38:43 - train: epoch 0087, iter [00200, 00390], lr: 0.020000, loss: 0.1045
2022-07-17 03:38:52 - train: epoch 0087, iter [00250, 00390], lr: 0.020000, loss: 0.2737
2022-07-17 03:39:01 - train: epoch 0087, iter [00300, 00390], lr: 0.020000, loss: 0.3258
2022-07-17 03:39:10 - train: epoch 0087, iter [00350, 00390], lr: 0.020000, loss: 0.1945
2022-07-17 03:39:17 - train: epoch 087, train_loss: 0.2134
2022-07-17 03:39:26 - eval: epoch: 087, acc1: 71.080%, acc5: 92.520%, test_loss: 1.2156, per_image_load_time: 0.480ms, per_image_inference_time: 0.298ms
2022-07-17 03:39:26 - until epoch: 087, best_acc1: 74.140%
2022-07-17 03:39:26 - epoch 088 lr: 0.020000
2022-07-17 03:39:40 - train: epoch 0088, iter [00050, 00390], lr: 0.020000, loss: 0.1991
2022-07-17 03:39:49 - train: epoch 0088, iter [00100, 00390], lr: 0.020000, loss: 0.1705
2022-07-17 03:39:58 - train: epoch 0088, iter [00150, 00390], lr: 0.020000, loss: 0.2505
2022-07-17 03:40:07 - train: epoch 0088, iter [00200, 00390], lr: 0.020000, loss: 0.2099
2022-07-17 03:40:16 - train: epoch 0088, iter [00250, 00390], lr: 0.020000, loss: 0.1984
2022-07-17 03:40:25 - train: epoch 0088, iter [00300, 00390], lr: 0.020000, loss: 0.3699
2022-07-17 03:40:34 - train: epoch 0088, iter [00350, 00390], lr: 0.020000, loss: 0.1905
2022-07-17 03:40:41 - train: epoch 088, train_loss: 0.2133
2022-07-17 03:40:51 - eval: epoch: 088, acc1: 70.650%, acc5: 91.950%, test_loss: 1.2900, per_image_load_time: 0.572ms, per_image_inference_time: 0.302ms
2022-07-17 03:40:51 - until epoch: 088, best_acc1: 74.140%
2022-07-17 03:40:51 - epoch 089 lr: 0.020000
2022-07-17 03:41:06 - train: epoch 0089, iter [00050, 00390], lr: 0.020000, loss: 0.1606
2022-07-17 03:41:14 - train: epoch 0089, iter [00100, 00390], lr: 0.020000, loss: 0.1750
2022-07-17 03:41:24 - train: epoch 0089, iter [00150, 00390], lr: 0.020000, loss: 0.1619
2022-07-17 03:41:32 - train: epoch 0089, iter [00200, 00390], lr: 0.020000, loss: 0.2291
2022-07-17 03:41:41 - train: epoch 0089, iter [00250, 00390], lr: 0.020000, loss: 0.2614
2022-07-17 03:41:50 - train: epoch 0089, iter [00300, 00390], lr: 0.020000, loss: 0.2381
2022-07-17 03:42:00 - train: epoch 0089, iter [00350, 00390], lr: 0.020000, loss: 0.1848
2022-07-17 03:42:08 - train: epoch 089, train_loss: 0.2073
2022-07-17 03:42:16 - eval: epoch: 089, acc1: 70.000%, acc5: 90.840%, test_loss: nan, per_image_load_time: 0.525ms, per_image_inference_time: 0.300ms
2022-07-17 03:42:17 - until epoch: 089, best_acc1: 74.140%
2022-07-17 03:42:17 - epoch 090 lr: 0.020000
2022-07-17 03:42:31 - train: epoch 0090, iter [00050, 00390], lr: 0.020000, loss: 0.2472
2022-07-17 03:42:40 - train: epoch 0090, iter [00100, 00390], lr: 0.020000, loss: 0.3272
2022-07-17 03:42:49 - train: epoch 0090, iter [00150, 00390], lr: 0.020000, loss: 0.2389
2022-07-17 03:42:58 - train: epoch 0090, iter [00200, 00390], lr: 0.020000, loss: 0.3149
2022-07-17 03:43:07 - train: epoch 0090, iter [00250, 00390], lr: 0.020000, loss: 0.1269
2022-07-17 03:43:16 - train: epoch 0090, iter [00300, 00390], lr: 0.020000, loss: 0.1898
2022-07-17 03:43:25 - train: epoch 0090, iter [00350, 00390], lr: 0.020000, loss: 0.1540
2022-07-17 03:43:33 - train: epoch 090, train_loss: 0.2022
2022-07-17 03:43:41 - eval: epoch: 090, acc1: 70.320%, acc5: 90.960%, test_loss: 1.3497, per_image_load_time: 0.480ms, per_image_inference_time: 0.318ms
2022-07-17 03:43:42 - until epoch: 090, best_acc1: 74.140%
2022-07-17 03:43:42 - epoch 091 lr: 0.020000
2022-07-17 03:43:56 - train: epoch 0091, iter [00050, 00390], lr: 0.020000, loss: 0.1126
2022-07-17 03:44:05 - train: epoch 0091, iter [00100, 00390], lr: 0.020000, loss: 0.1289
2022-07-17 03:44:14 - train: epoch 0091, iter [00150, 00390], lr: 0.020000, loss: 0.1647
2022-07-17 03:44:23 - train: epoch 0091, iter [00200, 00390], lr: 0.020000, loss: 0.1856
2022-07-17 03:44:32 - train: epoch 0091, iter [00250, 00390], lr: 0.020000, loss: 0.3080
2022-07-17 03:44:41 - train: epoch 0091, iter [00300, 00390], lr: 0.020000, loss: 0.1962
2022-07-17 03:44:50 - train: epoch 0091, iter [00350, 00390], lr: 0.020000, loss: 0.2015
2022-07-17 03:44:57 - train: epoch 091, train_loss: 0.2018
2022-07-17 03:45:06 - eval: epoch: 091, acc1: 70.450%, acc5: 91.820%, test_loss: 1.2443, per_image_load_time: 0.521ms, per_image_inference_time: 0.303ms
2022-07-17 03:45:07 - until epoch: 091, best_acc1: 74.140%
2022-07-17 03:45:07 - epoch 092 lr: 0.020000
2022-07-17 03:45:21 - train: epoch 0092, iter [00050, 00390], lr: 0.020000, loss: 0.1526
2022-07-17 03:45:30 - train: epoch 0092, iter [00100, 00390], lr: 0.020000, loss: 0.1718
2022-07-17 03:45:39 - train: epoch 0092, iter [00150, 00390], lr: 0.020000, loss: 0.1291
2022-07-17 03:45:48 - train: epoch 0092, iter [00200, 00390], lr: 0.020000, loss: 0.2059
2022-07-17 03:45:57 - train: epoch 0092, iter [00250, 00390], lr: 0.020000, loss: 0.1653
2022-07-17 03:46:06 - train: epoch 0092, iter [00300, 00390], lr: 0.020000, loss: 0.2280
2022-07-17 03:46:14 - train: epoch 0092, iter [00350, 00390], lr: 0.020000, loss: 0.2482
2022-07-17 03:46:22 - train: epoch 092, train_loss: 0.2052
2022-07-17 03:46:30 - eval: epoch: 092, acc1: 68.990%, acc5: 90.990%, test_loss: 1.4679, per_image_load_time: 0.441ms, per_image_inference_time: 0.302ms
2022-07-17 03:46:31 - until epoch: 092, best_acc1: 74.140%
2022-07-17 03:46:31 - epoch 093 lr: 0.020000
2022-07-17 03:46:46 - train: epoch 0093, iter [00050, 00390], lr: 0.020000, loss: 0.1999
2022-07-17 03:46:55 - train: epoch 0093, iter [00100, 00390], lr: 0.020000, loss: 0.1585
2022-07-17 03:47:04 - train: epoch 0093, iter [00150, 00390], lr: 0.020000, loss: 0.2262
2022-07-17 03:47:13 - train: epoch 0093, iter [00200, 00390], lr: 0.020000, loss: 0.3453
2022-07-17 03:47:22 - train: epoch 0093, iter [00250, 00390], lr: 0.020000, loss: 0.1951
2022-07-17 03:47:31 - train: epoch 0093, iter [00300, 00390], lr: 0.020000, loss: 0.1969
2022-07-17 03:47:40 - train: epoch 0093, iter [00350, 00390], lr: 0.020000, loss: 0.1883
2022-07-17 03:47:48 - train: epoch 093, train_loss: 0.2112
2022-07-17 03:47:56 - eval: epoch: 093, acc1: 71.020%, acc5: 91.880%, test_loss: 1.2703, per_image_load_time: 0.501ms, per_image_inference_time: 0.296ms
2022-07-17 03:47:57 - until epoch: 093, best_acc1: 74.140%
2022-07-17 03:47:57 - epoch 094 lr: 0.020000
2022-07-17 03:48:10 - train: epoch 0094, iter [00050, 00390], lr: 0.020000, loss: 0.1223
2022-07-17 03:48:19 - train: epoch 0094, iter [00100, 00390], lr: 0.020000, loss: 0.2280
2022-07-17 03:48:29 - train: epoch 0094, iter [00150, 00390], lr: 0.020000, loss: 0.1669
2022-07-17 03:48:38 - train: epoch 0094, iter [00200, 00390], lr: 0.020000, loss: 0.1862
2022-07-17 03:48:47 - train: epoch 0094, iter [00250, 00390], lr: 0.020000, loss: 0.1837
2022-07-17 03:48:56 - train: epoch 0094, iter [00300, 00390], lr: 0.020000, loss: 0.2524
2022-07-17 03:49:05 - train: epoch 0094, iter [00350, 00390], lr: 0.020000, loss: 0.2857
2022-07-17 03:49:12 - train: epoch 094, train_loss: 0.2120
2022-07-17 03:49:21 - eval: epoch: 094, acc1: 70.770%, acc5: 92.130%, test_loss: 1.2772, per_image_load_time: 0.477ms, per_image_inference_time: 0.302ms
2022-07-17 03:49:21 - until epoch: 094, best_acc1: 74.140%
2022-07-17 03:49:21 - epoch 095 lr: 0.020000
2022-07-17 03:49:35 - train: epoch 0095, iter [00050, 00390], lr: 0.020000, loss: 0.2511
2022-07-17 03:49:44 - train: epoch 0095, iter [00100, 00390], lr: 0.020000, loss: 0.1993
2022-07-17 03:49:54 - train: epoch 0095, iter [00150, 00390], lr: 0.020000, loss: 0.1815
2022-07-17 03:50:03 - train: epoch 0095, iter [00200, 00390], lr: 0.020000, loss: 0.2365
2022-07-17 03:50:12 - train: epoch 0095, iter [00250, 00390], lr: 0.020000, loss: 0.2785
2022-07-17 03:50:21 - train: epoch 0095, iter [00300, 00390], lr: 0.020000, loss: 0.1890
2022-07-17 03:50:30 - train: epoch 0095, iter [00350, 00390], lr: 0.020000, loss: 0.1802
2022-07-17 03:50:37 - train: epoch 095, train_loss: 0.2015
2022-07-17 03:50:46 - eval: epoch: 095, acc1: 68.560%, acc5: 91.010%, test_loss: 1.4154, per_image_load_time: 0.493ms, per_image_inference_time: 0.304ms
2022-07-17 03:50:46 - until epoch: 095, best_acc1: 74.140%
2022-07-17 03:50:46 - epoch 096 lr: 0.020000
2022-07-17 03:51:01 - train: epoch 0096, iter [00050, 00390], lr: 0.020000, loss: 0.1595
2022-07-17 03:51:10 - train: epoch 0096, iter [00100, 00390], lr: 0.020000, loss: 0.1721
2022-07-17 03:51:19 - train: epoch 0096, iter [00150, 00390], lr: 0.020000, loss: 0.2113
2022-07-17 03:51:28 - train: epoch 0096, iter [00200, 00390], lr: 0.020000, loss: 0.1571
2022-07-17 03:51:37 - train: epoch 0096, iter [00250, 00390], lr: 0.020000, loss: 0.2307
2022-07-17 03:51:46 - train: epoch 0096, iter [00300, 00390], lr: 0.020000, loss: 0.2963
2022-07-17 03:51:56 - train: epoch 0096, iter [00350, 00390], lr: 0.020000, loss: 0.1789
2022-07-17 03:52:03 - train: epoch 096, train_loss: 0.1953
2022-07-17 03:52:12 - eval: epoch: 096, acc1: 70.630%, acc5: 91.600%, test_loss: 1.3290, per_image_load_time: 0.508ms, per_image_inference_time: 0.301ms
2022-07-17 03:52:12 - until epoch: 096, best_acc1: 74.140%
2022-07-17 03:52:12 - epoch 097 lr: 0.020000
2022-07-17 03:52:27 - train: epoch 0097, iter [00050, 00390], lr: 0.020000, loss: 0.2058
2022-07-17 03:52:36 - train: epoch 0097, iter [00100, 00390], lr: 0.020000, loss: 0.0871
2022-07-17 03:52:44 - train: epoch 0097, iter [00150, 00390], lr: 0.020000, loss: 0.1032
2022-07-17 03:52:53 - train: epoch 0097, iter [00200, 00390], lr: 0.020000, loss: 0.1984
2022-07-17 03:53:03 - train: epoch 0097, iter [00250, 00390], lr: 0.020000, loss: 0.1556
2022-07-17 03:53:12 - train: epoch 0097, iter [00300, 00390], lr: 0.020000, loss: 0.2007
2022-07-17 03:53:21 - train: epoch 0097, iter [00350, 00390], lr: 0.020000, loss: 0.2633
2022-07-17 03:53:29 - train: epoch 097, train_loss: 0.1993
2022-07-17 03:53:37 - eval: epoch: 097, acc1: 70.060%, acc5: 91.380%, test_loss: 1.3177, per_image_load_time: 0.498ms, per_image_inference_time: 0.291ms
2022-07-17 03:53:38 - until epoch: 097, best_acc1: 74.140%
2022-07-17 03:53:38 - epoch 098 lr: 0.020000
2022-07-17 03:53:52 - train: epoch 0098, iter [00050, 00390], lr: 0.020000, loss: 0.1592
2022-07-17 03:54:01 - train: epoch 0098, iter [00100, 00390], lr: 0.020000, loss: 0.1397
2022-07-17 03:54:11 - train: epoch 0098, iter [00150, 00390], lr: 0.020000, loss: 0.1498
2022-07-17 03:54:20 - train: epoch 0098, iter [00200, 00390], lr: 0.020000, loss: 0.2299
2022-07-17 03:54:29 - train: epoch 0098, iter [00250, 00390], lr: 0.020000, loss: 0.2031
2022-07-17 03:54:38 - train: epoch 0098, iter [00300, 00390], lr: 0.020000, loss: 0.2579
2022-07-17 03:54:47 - train: epoch 0098, iter [00350, 00390], lr: 0.020000, loss: 0.2308
2022-07-17 03:54:54 - train: epoch 098, train_loss: 0.2029
2022-07-17 03:55:03 - eval: epoch: 098, acc1: 70.250%, acc5: 92.070%, test_loss: 1.3273, per_image_load_time: 0.490ms, per_image_inference_time: 0.309ms
2022-07-17 03:55:03 - until epoch: 098, best_acc1: 74.140%
2022-07-17 03:55:03 - epoch 099 lr: 0.020000
2022-07-17 03:55:17 - train: epoch 0099, iter [00050, 00390], lr: 0.020000, loss: 0.2035
2022-07-17 03:55:26 - train: epoch 0099, iter [00100, 00390], lr: 0.020000, loss: 0.1889
2022-07-17 03:55:35 - train: epoch 0099, iter [00150, 00390], lr: 0.020000, loss: 0.1602
2022-07-17 03:55:44 - train: epoch 0099, iter [00200, 00390], lr: 0.020000, loss: 0.1784
2022-07-17 03:55:53 - train: epoch 0099, iter [00250, 00390], lr: 0.020000, loss: 0.1792
2022-07-17 03:56:02 - train: epoch 0099, iter [00300, 00390], lr: 0.020000, loss: 0.2064
2022-07-17 03:56:11 - train: epoch 0099, iter [00350, 00390], lr: 0.020000, loss: 0.1650
2022-07-17 03:56:19 - train: epoch 099, train_loss: 0.1984
2022-07-17 03:56:28 - eval: epoch: 099, acc1: 70.150%, acc5: 91.790%, test_loss: 1.2851, per_image_load_time: 0.522ms, per_image_inference_time: 0.295ms
2022-07-17 03:56:28 - until epoch: 099, best_acc1: 74.140%
2022-07-17 03:56:28 - epoch 100 lr: 0.020000
2022-07-17 03:56:43 - train: epoch 0100, iter [00050, 00390], lr: 0.020000, loss: 0.1542
2022-07-17 03:56:52 - train: epoch 0100, iter [00100, 00390], lr: 0.020000, loss: 0.1397
2022-07-17 03:57:01 - train: epoch 0100, iter [00150, 00390], lr: 0.020000, loss: 0.2139
2022-07-17 03:57:10 - train: epoch 0100, iter [00200, 00390], lr: 0.020000, loss: 0.2766
2022-07-17 03:57:19 - train: epoch 0100, iter [00250, 00390], lr: 0.020000, loss: 0.1974
2022-07-17 03:57:28 - train: epoch 0100, iter [00300, 00390], lr: 0.020000, loss: 0.1832
2022-07-17 03:57:37 - train: epoch 0100, iter [00350, 00390], lr: 0.020000, loss: 0.2011
2022-07-17 03:57:45 - train: epoch 100, train_loss: 0.1890
2022-07-17 03:57:53 - eval: epoch: 100, acc1: 69.710%, acc5: 91.910%, test_loss: 1.3174, per_image_load_time: 0.470ms, per_image_inference_time: 0.291ms
2022-07-17 03:57:54 - until epoch: 100, best_acc1: 74.140%
2022-07-17 03:57:54 - epoch 101 lr: 0.020000
2022-07-17 03:58:08 - train: epoch 0101, iter [00050, 00390], lr: 0.020000, loss: 0.1593
2022-07-17 03:58:17 - train: epoch 0101, iter [00100, 00390], lr: 0.020000, loss: 0.2222
2022-07-17 03:58:26 - train: epoch 0101, iter [00150, 00390], lr: 0.020000, loss: 0.2542
2022-07-17 03:58:36 - train: epoch 0101, iter [00200, 00390], lr: 0.020000, loss: 0.2408
2022-07-17 03:58:45 - train: epoch 0101, iter [00250, 00390], lr: 0.020000, loss: 0.1909
2022-07-17 03:58:54 - train: epoch 0101, iter [00300, 00390], lr: 0.020000, loss: 0.2001
2022-07-17 03:59:03 - train: epoch 0101, iter [00350, 00390], lr: 0.020000, loss: 0.1724
2022-07-17 03:59:11 - train: epoch 101, train_loss: 0.2029
2022-07-17 03:59:19 - eval: epoch: 101, acc1: 70.440%, acc5: 91.600%, test_loss: 1.2765, per_image_load_time: 0.518ms, per_image_inference_time: 0.305ms
2022-07-17 03:59:20 - until epoch: 101, best_acc1: 74.140%
2022-07-17 03:59:20 - epoch 102 lr: 0.020000
2022-07-17 03:59:34 - train: epoch 0102, iter [00050, 00390], lr: 0.020000, loss: 0.1066
2022-07-17 03:59:43 - train: epoch 0102, iter [00100, 00390], lr: 0.020000, loss: 0.2536
2022-07-17 03:59:52 - train: epoch 0102, iter [00150, 00390], lr: 0.020000, loss: 0.1773
2022-07-17 04:00:01 - train: epoch 0102, iter [00200, 00390], lr: 0.020000, loss: 0.1657
2022-07-17 04:00:10 - train: epoch 0102, iter [00250, 00390], lr: 0.020000, loss: 0.1560
2022-07-17 04:00:19 - train: epoch 0102, iter [00300, 00390], lr: 0.020000, loss: 0.1150
2022-07-17 04:00:28 - train: epoch 0102, iter [00350, 00390], lr: 0.020000, loss: 0.2331
2022-07-17 04:00:36 - train: epoch 102, train_loss: 0.1891
2022-07-17 04:00:44 - eval: epoch: 102, acc1: 70.300%, acc5: 91.730%, test_loss: 1.3361, per_image_load_time: 0.461ms, per_image_inference_time: 0.302ms
2022-07-17 04:00:45 - until epoch: 102, best_acc1: 74.140%
2022-07-17 04:00:45 - epoch 103 lr: 0.020000
2022-07-17 04:00:59 - train: epoch 0103, iter [00050, 00390], lr: 0.020000, loss: 0.1377
2022-07-17 04:01:08 - train: epoch 0103, iter [00100, 00390], lr: 0.020000, loss: 0.2212
2022-07-17 04:01:17 - train: epoch 0103, iter [00150, 00390], lr: 0.020000, loss: 0.2273
2022-07-17 04:01:26 - train: epoch 0103, iter [00200, 00390], lr: 0.020000, loss: 0.1661
2022-07-17 04:01:35 - train: epoch 0103, iter [00250, 00390], lr: 0.020000, loss: 0.1945
2022-07-17 04:01:44 - train: epoch 0103, iter [00300, 00390], lr: 0.020000, loss: 0.1859
2022-07-17 04:01:52 - train: epoch 0103, iter [00350, 00390], lr: 0.020000, loss: 0.2394
2022-07-17 04:02:00 - train: epoch 103, train_loss: 0.1931
2022-07-17 04:02:08 - eval: epoch: 103, acc1: 70.330%, acc5: 91.660%, test_loss: 1.3272, per_image_load_time: 0.492ms, per_image_inference_time: 0.295ms
2022-07-17 04:02:09 - until epoch: 103, best_acc1: 74.140%
2022-07-17 04:02:09 - epoch 104 lr: 0.020000
2022-07-17 04:02:24 - train: epoch 0104, iter [00050, 00390], lr: 0.020000, loss: 0.1537
2022-07-17 04:02:33 - train: epoch 0104, iter [00100, 00390], lr: 0.020000, loss: 0.2225
2022-07-17 04:02:42 - train: epoch 0104, iter [00150, 00390], lr: 0.020000, loss: 0.2799
2022-07-17 04:02:51 - train: epoch 0104, iter [00200, 00390], lr: 0.020000, loss: 0.2254
2022-07-17 04:03:00 - train: epoch 0104, iter [00250, 00390], lr: 0.020000, loss: 0.1565
2022-07-17 04:03:09 - train: epoch 0104, iter [00300, 00390], lr: 0.020000, loss: 0.2522
2022-07-17 04:03:18 - train: epoch 0104, iter [00350, 00390], lr: 0.020000, loss: 0.3054
2022-07-17 04:03:25 - train: epoch 104, train_loss: 0.1941
2022-07-17 04:03:34 - eval: epoch: 104, acc1: 69.530%, acc5: 91.250%, test_loss: 1.3619, per_image_load_time: 0.515ms, per_image_inference_time: 0.296ms
2022-07-17 04:03:35 - until epoch: 104, best_acc1: 74.140%
2022-07-17 04:03:35 - epoch 105 lr: 0.020000
2022-07-17 04:03:49 - train: epoch 0105, iter [00050, 00390], lr: 0.020000, loss: 0.2071
2022-07-17 04:03:58 - train: epoch 0105, iter [00100, 00390], lr: 0.020000, loss: 0.2608
2022-07-17 04:04:07 - train: epoch 0105, iter [00150, 00390], lr: 0.020000, loss: 0.1215
2022-07-17 04:04:16 - train: epoch 0105, iter [00200, 00390], lr: 0.020000, loss: 0.1761
2022-07-17 04:04:25 - train: epoch 0105, iter [00250, 00390], lr: 0.020000, loss: 0.2531
2022-07-17 04:04:34 - train: epoch 0105, iter [00300, 00390], lr: 0.020000, loss: 0.2998
2022-07-17 04:04:43 - train: epoch 0105, iter [00350, 00390], lr: 0.020000, loss: 0.2490
2022-07-17 04:04:50 - train: epoch 105, train_loss: 0.1980
2022-07-17 04:04:59 - eval: epoch: 105, acc1: 70.180%, acc5: 91.450%, test_loss: 1.3541, per_image_load_time: 0.516ms, per_image_inference_time: 0.294ms
2022-07-17 04:04:59 - until epoch: 105, best_acc1: 74.140%
2022-07-17 04:04:59 - epoch 106 lr: 0.020000
2022-07-17 04:05:14 - train: epoch 0106, iter [00050, 00390], lr: 0.020000, loss: 0.2346
2022-07-17 04:05:23 - train: epoch 0106, iter [00100, 00390], lr: 0.020000, loss: 0.1348
2022-07-17 04:05:32 - train: epoch 0106, iter [00150, 00390], lr: 0.020000, loss: 0.2653
2022-07-17 04:05:41 - train: epoch 0106, iter [00200, 00390], lr: 0.020000, loss: 0.1228
2022-07-17 04:05:50 - train: epoch 0106, iter [00250, 00390], lr: 0.020000, loss: 0.2623
2022-07-17 04:05:58 - train: epoch 0106, iter [00300, 00390], lr: 0.020000, loss: 0.1978
2022-07-17 04:06:07 - train: epoch 0106, iter [00350, 00390], lr: 0.020000, loss: 0.2339
2022-07-17 04:06:15 - train: epoch 106, train_loss: 0.1935
2022-07-17 04:06:23 - eval: epoch: 106, acc1: 69.730%, acc5: 91.520%, test_loss: 1.3124, per_image_load_time: 0.495ms, per_image_inference_time: 0.295ms
2022-07-17 04:06:24 - until epoch: 106, best_acc1: 74.140%
2022-07-17 04:06:24 - epoch 107 lr: 0.020000
2022-07-17 04:06:39 - train: epoch 0107, iter [00050, 00390], lr: 0.020000, loss: 0.1632
2022-07-17 04:06:48 - train: epoch 0107, iter [00100, 00390], lr: 0.020000, loss: 0.2690
2022-07-17 04:06:57 - train: epoch 0107, iter [00150, 00390], lr: 0.020000, loss: 0.2528
2022-07-17 04:07:06 - train: epoch 0107, iter [00200, 00390], lr: 0.020000, loss: 0.3307
2022-07-17 04:07:16 - train: epoch 0107, iter [00250, 00390], lr: 0.020000, loss: 0.2853
2022-07-17 04:07:25 - train: epoch 0107, iter [00300, 00390], lr: 0.020000, loss: 0.2221
2022-07-17 04:07:34 - train: epoch 0107, iter [00350, 00390], lr: 0.020000, loss: 0.2650
2022-07-17 04:07:42 - train: epoch 107, train_loss: 0.2175
2022-07-17 04:07:50 - eval: epoch: 107, acc1: 69.190%, acc5: 91.300%, test_loss: 1.3801, per_image_load_time: 0.508ms, per_image_inference_time: 0.294ms
2022-07-17 04:07:51 - until epoch: 107, best_acc1: 74.140%
2022-07-17 04:07:51 - epoch 108 lr: 0.020000
2022-07-17 04:08:04 - train: epoch 0108, iter [00050, 00390], lr: 0.020000, loss: 0.2106
2022-07-17 04:08:13 - train: epoch 0108, iter [00100, 00390], lr: 0.020000, loss: 0.2950
2022-07-17 04:08:23 - train: epoch 0108, iter [00150, 00390], lr: 0.020000, loss: 0.1625
2022-07-17 04:08:32 - train: epoch 0108, iter [00200, 00390], lr: 0.020000, loss: 0.1429
2022-07-17 04:08:41 - train: epoch 0108, iter [00250, 00390], lr: 0.020000, loss: 0.1964
2022-07-17 04:08:50 - train: epoch 0108, iter [00300, 00390], lr: 0.020000, loss: 0.2560
2022-07-17 04:08:59 - train: epoch 0108, iter [00350, 00390], lr: 0.020000, loss: 0.2827
2022-07-17 04:09:06 - train: epoch 108, train_loss: 0.2074
2022-07-17 04:09:15 - eval: epoch: 108, acc1: 69.380%, acc5: 90.960%, test_loss: 1.3920, per_image_load_time: 0.516ms, per_image_inference_time: 0.296ms
2022-07-17 04:09:15 - until epoch: 108, best_acc1: 74.140%
2022-07-17 04:09:15 - epoch 109 lr: 0.020000
2022-07-17 04:09:30 - train: epoch 0109, iter [00050, 00390], lr: 0.020000, loss: 0.2790
2022-07-17 04:09:39 - train: epoch 0109, iter [00100, 00390], lr: 0.020000, loss: 0.2294
2022-07-17 04:09:48 - train: epoch 0109, iter [00150, 00390], lr: 0.020000, loss: 0.1278
2022-07-17 04:09:57 - train: epoch 0109, iter [00200, 00390], lr: 0.020000, loss: 0.1079
2022-07-17 04:10:06 - train: epoch 0109, iter [00250, 00390], lr: 0.020000, loss: 0.1985
2022-07-17 04:10:15 - train: epoch 0109, iter [00300, 00390], lr: 0.020000, loss: 0.2812
2022-07-17 04:10:24 - train: epoch 0109, iter [00350, 00390], lr: 0.020000, loss: 0.2592
2022-07-17 04:10:32 - train: epoch 109, train_loss: 0.2053
2022-07-17 04:10:40 - eval: epoch: 109, acc1: 70.320%, acc5: 91.410%, test_loss: 1.3131, per_image_load_time: 0.522ms, per_image_inference_time: 0.303ms
2022-07-17 04:10:41 - until epoch: 109, best_acc1: 74.140%
2022-07-17 04:10:41 - epoch 110 lr: 0.020000
2022-07-17 04:10:55 - train: epoch 0110, iter [00050, 00390], lr: 0.020000, loss: 0.1296
2022-07-17 04:11:04 - train: epoch 0110, iter [00100, 00390], lr: 0.020000, loss: 0.2183
2022-07-17 04:11:13 - train: epoch 0110, iter [00150, 00390], lr: 0.020000, loss: 0.1240
2022-07-17 04:11:23 - train: epoch 0110, iter [00200, 00390], lr: 0.020000, loss: 0.1676
2022-07-17 04:11:32 - train: epoch 0110, iter [00250, 00390], lr: 0.020000, loss: 0.2130
2022-07-17 04:11:41 - train: epoch 0110, iter [00300, 00390], lr: 0.020000, loss: 0.1850
2022-07-17 04:11:50 - train: epoch 0110, iter [00350, 00390], lr: 0.020000, loss: 0.2110
2022-07-17 04:11:57 - train: epoch 110, train_loss: 0.1951
2022-07-17 04:12:06 - eval: epoch: 110, acc1: 70.290%, acc5: 91.570%, test_loss: 1.3577, per_image_load_time: 0.549ms, per_image_inference_time: 0.296ms
2022-07-17 04:12:07 - until epoch: 110, best_acc1: 74.140%
2022-07-17 04:12:07 - epoch 111 lr: 0.020000
2022-07-17 04:12:21 - train: epoch 0111, iter [00050, 00390], lr: 0.020000, loss: 0.1312
2022-07-17 04:12:30 - train: epoch 0111, iter [00100, 00390], lr: 0.020000, loss: 0.2740
2022-07-17 04:12:40 - train: epoch 0111, iter [00150, 00390], lr: 0.020000, loss: 0.2370
2022-07-17 04:12:49 - train: epoch 0111, iter [00200, 00390], lr: 0.020000, loss: 0.1894
2022-07-17 04:12:58 - train: epoch 0111, iter [00250, 00390], lr: 0.020000, loss: 0.3466
2022-07-17 04:13:07 - train: epoch 0111, iter [00300, 00390], lr: 0.020000, loss: 0.1863
2022-07-17 04:13:16 - train: epoch 0111, iter [00350, 00390], lr: 0.020000, loss: 0.2162
2022-07-17 04:13:23 - train: epoch 111, train_loss: 0.1990
2022-07-17 04:13:32 - eval: epoch: 111, acc1: 70.600%, acc5: 91.320%, test_loss: 1.3006, per_image_load_time: 0.524ms, per_image_inference_time: 0.312ms
2022-07-17 04:13:33 - until epoch: 111, best_acc1: 74.140%
2022-07-17 04:13:33 - epoch 112 lr: 0.020000
2022-07-17 04:13:47 - train: epoch 0112, iter [00050, 00390], lr: 0.020000, loss: 0.1388
2022-07-17 04:13:56 - train: epoch 0112, iter [00100, 00390], lr: 0.020000, loss: 0.1448
2022-07-17 04:14:05 - train: epoch 0112, iter [00150, 00390], lr: 0.020000, loss: 0.2761
2022-07-17 04:14:14 - train: epoch 0112, iter [00200, 00390], lr: 0.020000, loss: 0.2722
2022-07-17 04:14:22 - train: epoch 0112, iter [00250, 00390], lr: 0.020000, loss: 0.2226
2022-07-17 04:14:32 - train: epoch 0112, iter [00300, 00390], lr: 0.020000, loss: 0.3088
2022-07-17 04:14:41 - train: epoch 0112, iter [00350, 00390], lr: 0.020000, loss: 0.2202
2022-07-17 04:14:49 - train: epoch 112, train_loss: 0.1993
2022-07-17 04:14:57 - eval: epoch: 112, acc1: 67.620%, acc5: 90.070%, test_loss: 1.3985, per_image_load_time: 0.505ms, per_image_inference_time: 0.298ms
2022-07-17 04:14:58 - until epoch: 112, best_acc1: 74.140%
2022-07-17 04:14:58 - epoch 113 lr: 0.020000
2022-07-17 04:15:12 - train: epoch 0113, iter [00050, 00390], lr: 0.020000, loss: 0.2160
2022-07-17 04:15:21 - train: epoch 0113, iter [00100, 00390], lr: 0.020000, loss: 0.2236
2022-07-17 04:15:30 - train: epoch 0113, iter [00150, 00390], lr: 0.020000, loss: 0.0628
2022-07-17 04:15:39 - train: epoch 0113, iter [00200, 00390], lr: 0.020000, loss: 0.1280
2022-07-17 04:15:48 - train: epoch 0113, iter [00250, 00390], lr: 0.020000, loss: 0.2420
2022-07-17 04:15:57 - train: epoch 0113, iter [00300, 00390], lr: 0.020000, loss: 0.1622
2022-07-17 04:16:06 - train: epoch 0113, iter [00350, 00390], lr: 0.020000, loss: 0.2226
2022-07-17 04:16:14 - train: epoch 113, train_loss: 0.1890
2022-07-17 04:16:22 - eval: epoch: 113, acc1: 71.350%, acc5: 91.990%, test_loss: 1.2819, per_image_load_time: 0.468ms, per_image_inference_time: 0.298ms
2022-07-17 04:16:22 - until epoch: 113, best_acc1: 74.140%
2022-07-17 04:16:22 - epoch 114 lr: 0.020000
2022-07-17 04:16:37 - train: epoch 0114, iter [00050, 00390], lr: 0.020000, loss: 0.1097
2022-07-17 04:16:46 - train: epoch 0114, iter [00100, 00390], lr: 0.020000, loss: 0.2132
2022-07-17 04:16:54 - train: epoch 0114, iter [00150, 00390], lr: 0.020000, loss: 0.1649
2022-07-17 04:17:03 - train: epoch 0114, iter [00200, 00390], lr: 0.020000, loss: 0.1537
2022-07-17 04:17:12 - train: epoch 0114, iter [00250, 00390], lr: 0.020000, loss: 0.2611
2022-07-17 04:17:21 - train: epoch 0114, iter [00300, 00390], lr: 0.020000, loss: 0.2821
2022-07-17 04:17:30 - train: epoch 0114, iter [00350, 00390], lr: 0.020000, loss: 0.1674
2022-07-17 04:17:38 - train: epoch 114, train_loss: 0.1811
2022-07-17 04:17:46 - eval: epoch: 114, acc1: 70.470%, acc5: 91.330%, test_loss: 1.3307, per_image_load_time: 0.521ms, per_image_inference_time: 0.299ms
2022-07-17 04:17:47 - until epoch: 114, best_acc1: 74.140%
2022-07-17 04:17:47 - epoch 115 lr: 0.020000
2022-07-17 04:18:01 - train: epoch 0115, iter [00050, 00390], lr: 0.020000, loss: 0.1341
2022-07-17 04:18:09 - train: epoch 0115, iter [00100, 00390], lr: 0.020000, loss: 0.1406
2022-07-17 04:18:18 - train: epoch 0115, iter [00150, 00390], lr: 0.020000, loss: 0.1470
2022-07-17 04:18:27 - train: epoch 0115, iter [00200, 00390], lr: 0.020000, loss: 0.1671
2022-07-17 04:18:36 - train: epoch 0115, iter [00250, 00390], lr: 0.020000, loss: 0.1130
2022-07-17 04:18:45 - train: epoch 0115, iter [00300, 00390], lr: 0.020000, loss: 0.2550
2022-07-17 04:18:54 - train: epoch 0115, iter [00350, 00390], lr: 0.020000, loss: 0.2131
2022-07-17 04:19:01 - train: epoch 115, train_loss: 0.1808
2022-07-17 04:19:10 - eval: epoch: 115, acc1: 70.070%, acc5: 91.710%, test_loss: 1.3470, per_image_load_time: 0.552ms, per_image_inference_time: 0.294ms
2022-07-17 04:19:11 - until epoch: 115, best_acc1: 74.140%
2022-07-17 04:19:11 - epoch 116 lr: 0.020000
2022-07-17 04:19:25 - train: epoch 0116, iter [00050, 00390], lr: 0.020000, loss: 0.2838
2022-07-17 04:19:34 - train: epoch 0116, iter [00100, 00390], lr: 0.020000, loss: 0.1023
2022-07-17 04:19:43 - train: epoch 0116, iter [00150, 00390], lr: 0.020000, loss: 0.1863
2022-07-17 04:19:52 - train: epoch 0116, iter [00200, 00390], lr: 0.020000, loss: 0.1918
2022-07-17 04:20:01 - train: epoch 0116, iter [00250, 00390], lr: 0.020000, loss: 0.1549
2022-07-17 04:20:10 - train: epoch 0116, iter [00300, 00390], lr: 0.020000, loss: 0.1547
2022-07-17 04:20:19 - train: epoch 0116, iter [00350, 00390], lr: 0.020000, loss: 0.3804
2022-07-17 04:20:26 - train: epoch 116, train_loss: 0.1876
2022-07-17 04:20:35 - eval: epoch: 116, acc1: 69.900%, acc5: 90.780%, test_loss: 1.3727, per_image_load_time: 0.517ms, per_image_inference_time: 0.295ms
2022-07-17 04:20:35 - until epoch: 116, best_acc1: 74.140%
2022-07-17 04:20:35 - epoch 117 lr: 0.020000
2022-07-17 04:20:50 - train: epoch 0117, iter [00050, 00390], lr: 0.020000, loss: 0.1624
2022-07-17 04:20:59 - train: epoch 0117, iter [00100, 00390], lr: 0.020000, loss: 0.2386
2022-07-17 04:21:08 - train: epoch 0117, iter [00150, 00390], lr: 0.020000, loss: 0.0790
2022-07-17 04:21:17 - train: epoch 0117, iter [00200, 00390], lr: 0.020000, loss: 0.2487
2022-07-17 04:21:26 - train: epoch 0117, iter [00250, 00390], lr: 0.020000, loss: 0.1750
2022-07-17 04:21:35 - train: epoch 0117, iter [00300, 00390], lr: 0.020000, loss: 0.2733
2022-07-17 04:21:44 - train: epoch 0117, iter [00350, 00390], lr: 0.020000, loss: 0.1683
2022-07-17 04:21:51 - train: epoch 117, train_loss: 0.1852
2022-07-17 04:21:59 - eval: epoch: 117, acc1: 70.620%, acc5: 91.660%, test_loss: 1.3316, per_image_load_time: 0.506ms, per_image_inference_time: 0.295ms
2022-07-17 04:22:00 - until epoch: 117, best_acc1: 74.140%
2022-07-17 04:22:00 - epoch 118 lr: 0.020000
2022-07-17 04:22:14 - train: epoch 0118, iter [00050, 00390], lr: 0.020000, loss: 0.1954
2022-07-17 04:22:23 - train: epoch 0118, iter [00100, 00390], lr: 0.020000, loss: 0.1678
2022-07-17 04:22:32 - train: epoch 0118, iter [00150, 00390], lr: 0.020000, loss: 0.1422
2022-07-17 04:22:40 - train: epoch 0118, iter [00200, 00390], lr: 0.020000, loss: 0.0966
2022-07-17 04:22:49 - train: epoch 0118, iter [00250, 00390], lr: 0.020000, loss: 0.0970
2022-07-17 04:22:58 - train: epoch 0118, iter [00300, 00390], lr: 0.020000, loss: 0.1068
2022-07-17 04:23:07 - train: epoch 0118, iter [00350, 00390], lr: 0.020000, loss: 0.2103
2022-07-17 04:23:14 - train: epoch 118, train_loss: 0.1825
2022-07-17 04:23:23 - eval: epoch: 118, acc1: 70.470%, acc5: 91.770%, test_loss: 1.3103, per_image_load_time: 0.552ms, per_image_inference_time: 0.297ms
2022-07-17 04:23:24 - until epoch: 118, best_acc1: 74.140%
2022-07-17 04:23:24 - epoch 119 lr: 0.020000
2022-07-17 04:23:37 - train: epoch 0119, iter [00050, 00390], lr: 0.020000, loss: 0.0948
2022-07-17 04:23:46 - train: epoch 0119, iter [00100, 00390], lr: 0.020000, loss: 0.1771
2022-07-17 04:23:55 - train: epoch 0119, iter [00150, 00390], lr: 0.020000, loss: 0.1943
2022-07-17 04:24:04 - train: epoch 0119, iter [00200, 00390], lr: 0.020000, loss: 0.1786
2022-07-17 04:24:13 - train: epoch 0119, iter [00250, 00390], lr: 0.020000, loss: 0.0877
2022-07-17 04:24:22 - train: epoch 0119, iter [00300, 00390], lr: 0.020000, loss: 0.2331
2022-07-17 04:24:31 - train: epoch 0119, iter [00350, 00390], lr: 0.020000, loss: 0.2027
2022-07-17 04:24:39 - train: epoch 119, train_loss: 0.1792
2022-07-17 04:24:47 - eval: epoch: 119, acc1: 69.690%, acc5: 91.230%, test_loss: 1.3522, per_image_load_time: 0.515ms, per_image_inference_time: 0.297ms
2022-07-17 04:24:48 - until epoch: 119, best_acc1: 74.140%
2022-07-17 04:24:48 - epoch 120 lr: 0.020000
2022-07-17 04:25:01 - train: epoch 0120, iter [00050, 00390], lr: 0.020000, loss: 0.1106
2022-07-17 04:25:10 - train: epoch 0120, iter [00100, 00390], lr: 0.020000, loss: 0.2048
2022-07-17 04:25:19 - train: epoch 0120, iter [00150, 00390], lr: 0.020000, loss: 0.1674
2022-07-17 04:25:28 - train: epoch 0120, iter [00200, 00390], lr: 0.020000, loss: 0.1211
2022-07-17 04:25:37 - train: epoch 0120, iter [00250, 00390], lr: 0.020000, loss: 0.1955
2022-07-17 04:25:46 - train: epoch 0120, iter [00300, 00390], lr: 0.020000, loss: 0.2023
2022-07-17 04:25:55 - train: epoch 0120, iter [00350, 00390], lr: 0.020000, loss: 0.1256
2022-07-17 04:26:03 - train: epoch 120, train_loss: 0.1905
2022-07-17 04:26:11 - eval: epoch: 120, acc1: 70.150%, acc5: 90.940%, test_loss: 1.3719, per_image_load_time: 0.519ms, per_image_inference_time: 0.294ms
2022-07-17 04:26:12 - until epoch: 120, best_acc1: 74.140%
2022-07-17 04:26:12 - epoch 121 lr: 0.004000
2022-07-17 04:26:26 - train: epoch 0121, iter [00050, 00390], lr: 0.004000, loss: 0.0521
2022-07-17 04:26:35 - train: epoch 0121, iter [00100, 00390], lr: 0.004000, loss: 0.0711
2022-07-17 04:26:44 - train: epoch 0121, iter [00150, 00390], lr: 0.004000, loss: 0.0977
2022-07-17 04:26:53 - train: epoch 0121, iter [00200, 00390], lr: 0.004000, loss: 0.0395
2022-07-17 04:27:02 - train: epoch 0121, iter [00250, 00390], lr: 0.004000, loss: 0.0419
2022-07-17 04:27:10 - train: epoch 0121, iter [00300, 00390], lr: 0.004000, loss: 0.0483
2022-07-17 04:27:19 - train: epoch 0121, iter [00350, 00390], lr: 0.004000, loss: 0.0242
2022-07-17 04:27:27 - train: epoch 121, train_loss: 0.0665
2022-07-17 04:27:35 - eval: epoch: 121, acc1: 75.260%, acc5: 93.390%, test_loss: 1.1650, per_image_load_time: 0.476ms, per_image_inference_time: 0.296ms
2022-07-17 04:27:36 - until epoch: 121, best_acc1: 75.260%
2022-07-17 04:27:36 - epoch 122 lr: 0.004000
2022-07-17 04:27:49 - train: epoch 0122, iter [00050, 00390], lr: 0.004000, loss: 0.0116
2022-07-17 04:27:58 - train: epoch 0122, iter [00100, 00390], lr: 0.004000, loss: 0.0188
2022-07-17 04:28:07 - train: epoch 0122, iter [00150, 00390], lr: 0.004000, loss: 0.0144
2022-07-17 04:28:16 - train: epoch 0122, iter [00200, 00390], lr: 0.004000, loss: 0.0178
2022-07-17 04:28:25 - train: epoch 0122, iter [00250, 00390], lr: 0.004000, loss: 0.0214
2022-07-17 04:28:34 - train: epoch 0122, iter [00300, 00390], lr: 0.004000, loss: 0.0317
2022-07-17 04:28:43 - train: epoch 0122, iter [00350, 00390], lr: 0.004000, loss: 0.0399
2022-07-17 04:28:50 - train: epoch 122, train_loss: 0.0283
2022-07-17 04:28:59 - eval: epoch: 122, acc1: 75.660%, acc5: 93.660%, test_loss: 1.1819, per_image_load_time: 0.555ms, per_image_inference_time: 0.298ms
2022-07-17 04:29:00 - until epoch: 122, best_acc1: 75.660%
2022-07-17 04:29:00 - epoch 123 lr: 0.004000
2022-07-17 04:29:15 - train: epoch 0123, iter [00050, 00390], lr: 0.004000, loss: 0.0115
2022-07-17 04:29:24 - train: epoch 0123, iter [00100, 00390], lr: 0.004000, loss: 0.0145
2022-07-17 04:29:32 - train: epoch 0123, iter [00150, 00390], lr: 0.004000, loss: 0.0123
2022-07-17 04:29:41 - train: epoch 0123, iter [00200, 00390], lr: 0.004000, loss: 0.0186
2022-07-17 04:29:50 - train: epoch 0123, iter [00250, 00390], lr: 0.004000, loss: 0.0245
2022-07-17 04:29:59 - train: epoch 0123, iter [00300, 00390], lr: 0.004000, loss: 0.0172
2022-07-17 04:30:08 - train: epoch 0123, iter [00350, 00390], lr: 0.004000, loss: 0.0078
2022-07-17 04:30:15 - train: epoch 123, train_loss: 0.0204
2022-07-17 04:30:24 - eval: epoch: 123, acc1: 75.730%, acc5: 93.880%, test_loss: 1.1979, per_image_load_time: 0.542ms, per_image_inference_time: 0.305ms
2022-07-17 04:30:25 - until epoch: 123, best_acc1: 75.730%
2022-07-17 04:30:25 - epoch 124 lr: 0.004000
2022-07-17 04:30:39 - train: epoch 0124, iter [00050, 00390], lr: 0.004000, loss: 0.0101
2022-07-17 04:30:48 - train: epoch 0124, iter [00100, 00390], lr: 0.004000, loss: 0.0078
2022-07-17 04:30:57 - train: epoch 0124, iter [00150, 00390], lr: 0.004000, loss: 0.0425
2022-07-17 04:31:06 - train: epoch 0124, iter [00200, 00390], lr: 0.004000, loss: 0.0205
2022-07-17 04:31:15 - train: epoch 0124, iter [00250, 00390], lr: 0.004000, loss: 0.0121
2022-07-17 04:31:24 - train: epoch 0124, iter [00300, 00390], lr: 0.004000, loss: 0.0310
2022-07-17 04:31:33 - train: epoch 0124, iter [00350, 00390], lr: 0.004000, loss: 0.0228
2022-07-17 04:31:41 - train: epoch 124, train_loss: 0.0164
2022-07-17 04:31:49 - eval: epoch: 124, acc1: 75.940%, acc5: 93.800%, test_loss: 1.1963, per_image_load_time: 0.469ms, per_image_inference_time: 0.288ms
2022-07-17 04:31:50 - until epoch: 124, best_acc1: 75.940%
2022-07-17 04:31:50 - epoch 125 lr: 0.004000
2022-07-17 04:32:04 - train: epoch 0125, iter [00050, 00390], lr: 0.004000, loss: 0.0150
2022-07-17 04:32:12 - train: epoch 0125, iter [00100, 00390], lr: 0.004000, loss: 0.0159
2022-07-17 04:32:21 - train: epoch 0125, iter [00150, 00390], lr: 0.004000, loss: 0.0078
2022-07-17 04:32:30 - train: epoch 0125, iter [00200, 00390], lr: 0.004000, loss: 0.0275
2022-07-17 04:32:39 - train: epoch 0125, iter [00250, 00390], lr: 0.004000, loss: 0.0081
2022-07-17 04:32:48 - train: epoch 0125, iter [00300, 00390], lr: 0.004000, loss: 0.0220
2022-07-17 04:32:57 - train: epoch 0125, iter [00350, 00390], lr: 0.004000, loss: 0.0054
2022-07-17 04:33:05 - train: epoch 125, train_loss: 0.0135
2022-07-17 04:33:13 - eval: epoch: 125, acc1: 75.990%, acc5: 94.060%, test_loss: 1.1985, per_image_load_time: 0.495ms, per_image_inference_time: 0.297ms
2022-07-17 04:33:14 - until epoch: 125, best_acc1: 75.990%
2022-07-17 04:33:14 - epoch 126 lr: 0.004000
2022-07-17 04:33:27 - train: epoch 0126, iter [00050, 00390], lr: 0.004000, loss: 0.0116
2022-07-17 04:33:36 - train: epoch 0126, iter [00100, 00390], lr: 0.004000, loss: 0.0104
2022-07-17 04:33:45 - train: epoch 0126, iter [00150, 00390], lr: 0.004000, loss: 0.0097
2022-07-17 04:33:54 - train: epoch 0126, iter [00200, 00390], lr: 0.004000, loss: 0.0062
2022-07-17 04:34:03 - train: epoch 0126, iter [00250, 00390], lr: 0.004000, loss: 0.0073
2022-07-17 04:34:11 - train: epoch 0126, iter [00300, 00390], lr: 0.004000, loss: 0.0074
2022-07-17 04:34:21 - train: epoch 0126, iter [00350, 00390], lr: 0.004000, loss: 0.0052
2022-07-17 04:34:28 - train: epoch 126, train_loss: 0.0111
2022-07-17 04:34:37 - eval: epoch: 126, acc1: 76.250%, acc5: 93.890%, test_loss: 1.2077, per_image_load_time: 0.574ms, per_image_inference_time: 0.297ms
2022-07-17 04:34:38 - until epoch: 126, best_acc1: 76.250%
2022-07-17 04:34:38 - epoch 127 lr: 0.004000
2022-07-17 04:34:53 - train: epoch 0127, iter [00050, 00390], lr: 0.004000, loss: 0.0121
2022-07-17 04:35:02 - train: epoch 0127, iter [00100, 00390], lr: 0.004000, loss: 0.0066
2022-07-17 04:35:11 - train: epoch 0127, iter [00150, 00390], lr: 0.004000, loss: 0.0063
2022-07-17 04:35:20 - train: epoch 0127, iter [00200, 00390], lr: 0.004000, loss: 0.0051
2022-07-17 04:35:29 - train: epoch 0127, iter [00250, 00390], lr: 0.004000, loss: 0.0096
2022-07-17 04:35:38 - train: epoch 0127, iter [00300, 00390], lr: 0.004000, loss: 0.0090
2022-07-17 04:35:47 - train: epoch 0127, iter [00350, 00390], lr: 0.004000, loss: 0.0071
2022-07-17 04:35:54 - train: epoch 127, train_loss: 0.0104
2022-07-17 04:36:03 - eval: epoch: 127, acc1: 76.340%, acc5: 94.000%, test_loss: 1.2173, per_image_load_time: 0.545ms, per_image_inference_time: 0.305ms
2022-07-17 04:36:04 - until epoch: 127, best_acc1: 76.340%
2022-07-17 04:36:04 - epoch 128 lr: 0.004000
2022-07-17 04:36:19 - train: epoch 0128, iter [00050, 00390], lr: 0.004000, loss: 0.0029
2022-07-17 04:36:28 - train: epoch 0128, iter [00100, 00390], lr: 0.004000, loss: 0.0055
2022-07-17 04:36:37 - train: epoch 0128, iter [00150, 00390], lr: 0.004000, loss: 0.0078
2022-07-17 04:36:46 - train: epoch 0128, iter [00200, 00390], lr: 0.004000, loss: 0.0152
2022-07-17 04:36:56 - train: epoch 0128, iter [00250, 00390], lr: 0.004000, loss: 0.0157
2022-07-17 04:37:05 - train: epoch 0128, iter [00300, 00390], lr: 0.004000, loss: 0.0037
2022-07-17 04:37:14 - train: epoch 0128, iter [00350, 00390], lr: 0.004000, loss: 0.0061
2022-07-17 04:37:22 - train: epoch 128, train_loss: 0.0090
2022-07-17 04:37:31 - eval: epoch: 128, acc1: 76.060%, acc5: 93.900%, test_loss: 1.2200, per_image_load_time: 0.558ms, per_image_inference_time: 0.295ms
2022-07-17 04:37:32 - until epoch: 128, best_acc1: 76.340%
2022-07-17 04:37:32 - epoch 129 lr: 0.004000
2022-07-17 04:37:47 - train: epoch 0129, iter [00050, 00390], lr: 0.004000, loss: 0.0050
2022-07-17 04:37:56 - train: epoch 0129, iter [00100, 00390], lr: 0.004000, loss: 0.0024
2022-07-17 04:38:05 - train: epoch 0129, iter [00150, 00390], lr: 0.004000, loss: 0.0036
2022-07-17 04:38:15 - train: epoch 0129, iter [00200, 00390], lr: 0.004000, loss: 0.0069
2022-07-17 04:38:24 - train: epoch 0129, iter [00250, 00390], lr: 0.004000, loss: 0.0070
2022-07-17 04:38:33 - train: epoch 0129, iter [00300, 00390], lr: 0.004000, loss: 0.0071
2022-07-17 04:38:43 - train: epoch 0129, iter [00350, 00390], lr: 0.004000, loss: 0.0042
2022-07-17 04:38:51 - train: epoch 129, train_loss: 0.0083
2022-07-17 04:38:59 - eval: epoch: 129, acc1: 76.460%, acc5: 93.950%, test_loss: 1.2215, per_image_load_time: 0.497ms, per_image_inference_time: 0.293ms
2022-07-17 04:39:00 - until epoch: 129, best_acc1: 76.460%
2022-07-17 04:39:00 - epoch 130 lr: 0.004000
2022-07-17 04:39:15 - train: epoch 0130, iter [00050, 00390], lr: 0.004000, loss: 0.0127
2022-07-17 04:39:24 - train: epoch 0130, iter [00100, 00390], lr: 0.004000, loss: 0.0045
2022-07-17 04:39:33 - train: epoch 0130, iter [00150, 00390], lr: 0.004000, loss: 0.0056
2022-07-17 04:39:43 - train: epoch 0130, iter [00200, 00390], lr: 0.004000, loss: 0.0132
2022-07-17 04:39:52 - train: epoch 0130, iter [00250, 00390], lr: 0.004000, loss: 0.0072
2022-07-17 04:40:01 - train: epoch 0130, iter [00300, 00390], lr: 0.004000, loss: 0.0047
2022-07-17 04:40:09 - train: epoch 0130, iter [00350, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 04:40:17 - train: epoch 130, train_loss: 0.0085
2022-07-17 04:40:25 - eval: epoch: 130, acc1: 76.200%, acc5: 93.920%, test_loss: 1.2223, per_image_load_time: 0.431ms, per_image_inference_time: 0.310ms
2022-07-17 04:40:26 - until epoch: 130, best_acc1: 76.460%
2022-07-17 04:40:26 - epoch 131 lr: 0.004000
2022-07-17 04:40:40 - train: epoch 0131, iter [00050, 00390], lr: 0.004000, loss: 0.0158
2022-07-17 04:40:49 - train: epoch 0131, iter [00100, 00390], lr: 0.004000, loss: 0.0019
2022-07-17 04:40:58 - train: epoch 0131, iter [00150, 00390], lr: 0.004000, loss: 0.0085
2022-07-17 04:41:07 - train: epoch 0131, iter [00200, 00390], lr: 0.004000, loss: 0.0040
2022-07-17 04:41:16 - train: epoch 0131, iter [00250, 00390], lr: 0.004000, loss: 0.0247
2022-07-17 04:41:25 - train: epoch 0131, iter [00300, 00390], lr: 0.004000, loss: 0.0078
2022-07-17 04:41:34 - train: epoch 0131, iter [00350, 00390], lr: 0.004000, loss: 0.0288
2022-07-17 04:41:41 - train: epoch 131, train_loss: 0.0079
2022-07-17 04:41:50 - eval: epoch: 131, acc1: 76.330%, acc5: 94.050%, test_loss: 1.2245, per_image_load_time: 0.544ms, per_image_inference_time: 0.299ms
2022-07-17 04:41:51 - until epoch: 131, best_acc1: 76.460%
2022-07-17 04:41:51 - epoch 132 lr: 0.004000
2022-07-17 04:42:05 - train: epoch 0132, iter [00050, 00390], lr: 0.004000, loss: 0.0068
2022-07-17 04:42:14 - train: epoch 0132, iter [00100, 00390], lr: 0.004000, loss: 0.0031
2022-07-17 04:42:23 - train: epoch 0132, iter [00150, 00390], lr: 0.004000, loss: 0.0093
2022-07-17 04:42:32 - train: epoch 0132, iter [00200, 00390], lr: 0.004000, loss: 0.0047
2022-07-17 04:42:41 - train: epoch 0132, iter [00250, 00390], lr: 0.004000, loss: 0.0036
2022-07-17 04:42:50 - train: epoch 0132, iter [00300, 00390], lr: 0.004000, loss: 0.0023
2022-07-17 04:42:59 - train: epoch 0132, iter [00350, 00390], lr: 0.004000, loss: 0.0048
2022-07-17 04:43:07 - train: epoch 132, train_loss: 0.0064
2022-07-17 04:43:16 - eval: epoch: 132, acc1: 76.320%, acc5: 94.070%, test_loss: 1.2269, per_image_load_time: 0.478ms, per_image_inference_time: 0.313ms
2022-07-17 04:43:16 - until epoch: 132, best_acc1: 76.460%
2022-07-17 04:43:16 - epoch 133 lr: 0.004000
2022-07-17 04:43:31 - train: epoch 0133, iter [00050, 00390], lr: 0.004000, loss: 0.0056
2022-07-17 04:43:40 - train: epoch 0133, iter [00100, 00390], lr: 0.004000, loss: 0.0050
2022-07-17 04:43:48 - train: epoch 0133, iter [00150, 00390], lr: 0.004000, loss: 0.0053
2022-07-17 04:43:57 - train: epoch 0133, iter [00200, 00390], lr: 0.004000, loss: 0.0171
2022-07-17 04:44:06 - train: epoch 0133, iter [00250, 00390], lr: 0.004000, loss: 0.0053
2022-07-17 04:44:15 - train: epoch 0133, iter [00300, 00390], lr: 0.004000, loss: 0.0050
2022-07-17 04:44:24 - train: epoch 0133, iter [00350, 00390], lr: 0.004000, loss: 0.0055
2022-07-17 04:44:32 - train: epoch 133, train_loss: 0.0063
2022-07-17 04:44:41 - eval: epoch: 133, acc1: 76.400%, acc5: 94.110%, test_loss: 1.2257, per_image_load_time: 0.543ms, per_image_inference_time: 0.297ms
2022-07-17 04:44:41 - until epoch: 133, best_acc1: 76.460%
2022-07-17 04:44:41 - epoch 134 lr: 0.004000
2022-07-17 04:44:56 - train: epoch 0134, iter [00050, 00390], lr: 0.004000, loss: 0.0086
2022-07-17 04:45:04 - train: epoch 0134, iter [00100, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 04:45:13 - train: epoch 0134, iter [00150, 00390], lr: 0.004000, loss: 0.0046
2022-07-17 04:45:22 - train: epoch 0134, iter [00200, 00390], lr: 0.004000, loss: 0.0025
2022-07-17 04:45:31 - train: epoch 0134, iter [00250, 00390], lr: 0.004000, loss: 0.0039
2022-07-17 04:45:40 - train: epoch 0134, iter [00300, 00390], lr: 0.004000, loss: 0.0030
2022-07-17 04:45:49 - train: epoch 0134, iter [00350, 00390], lr: 0.004000, loss: 0.0070
2022-07-17 04:45:57 - train: epoch 134, train_loss: 0.0061
2022-07-17 04:46:04 - eval: epoch: 134, acc1: 76.550%, acc5: 94.120%, test_loss: 1.2167, per_image_load_time: 0.427ms, per_image_inference_time: 0.294ms
2022-07-17 04:46:05 - until epoch: 134, best_acc1: 76.550%
2022-07-17 04:46:05 - epoch 135 lr: 0.004000
2022-07-17 04:46:20 - train: epoch 0135, iter [00050, 00390], lr: 0.004000, loss: 0.0103
2022-07-17 04:46:29 - train: epoch 0135, iter [00100, 00390], lr: 0.004000, loss: 0.0194
2022-07-17 04:46:38 - train: epoch 0135, iter [00150, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 04:46:47 - train: epoch 0135, iter [00200, 00390], lr: 0.004000, loss: 0.0135
2022-07-17 04:46:56 - train: epoch 0135, iter [00250, 00390], lr: 0.004000, loss: 0.0081
2022-07-17 04:47:05 - train: epoch 0135, iter [00300, 00390], lr: 0.004000, loss: 0.0057
2022-07-17 04:47:14 - train: epoch 0135, iter [00350, 00390], lr: 0.004000, loss: 0.0010
2022-07-17 04:47:21 - train: epoch 135, train_loss: 0.0061
2022-07-17 04:47:30 - eval: epoch: 135, acc1: 76.440%, acc5: 94.130%, test_loss: 1.2195, per_image_load_time: 0.545ms, per_image_inference_time: 0.290ms
2022-07-17 04:47:31 - until epoch: 135, best_acc1: 76.550%
2022-07-17 04:47:31 - epoch 136 lr: 0.004000
2022-07-17 04:47:44 - train: epoch 0136, iter [00050, 00390], lr: 0.004000, loss: 0.0018
2022-07-17 04:47:53 - train: epoch 0136, iter [00100, 00390], lr: 0.004000, loss: 0.0028
2022-07-17 04:48:02 - train: epoch 0136, iter [00150, 00390], lr: 0.004000, loss: 0.0030
2022-07-17 04:48:11 - train: epoch 0136, iter [00200, 00390], lr: 0.004000, loss: 0.0016
2022-07-17 04:48:21 - train: epoch 0136, iter [00250, 00390], lr: 0.004000, loss: 0.0032
2022-07-17 04:48:30 - train: epoch 0136, iter [00300, 00390], lr: 0.004000, loss: 0.0118
2022-07-17 04:48:39 - train: epoch 0136, iter [00350, 00390], lr: 0.004000, loss: 0.0064
2022-07-17 04:48:46 - train: epoch 136, train_loss: 0.0061
2022-07-17 04:48:55 - eval: epoch: 136, acc1: 76.350%, acc5: 94.150%, test_loss: 1.2257, per_image_load_time: 0.534ms, per_image_inference_time: 0.299ms
2022-07-17 04:48:56 - until epoch: 136, best_acc1: 76.550%
2022-07-17 04:48:56 - epoch 137 lr: 0.004000
2022-07-17 04:49:10 - train: epoch 0137, iter [00050, 00390], lr: 0.004000, loss: 0.0023
2022-07-17 04:49:19 - train: epoch 0137, iter [00100, 00390], lr: 0.004000, loss: 0.0040
2022-07-17 04:49:28 - train: epoch 0137, iter [00150, 00390], lr: 0.004000, loss: 0.0025
2022-07-17 04:49:37 - train: epoch 0137, iter [00200, 00390], lr: 0.004000, loss: 0.0097
2022-07-17 04:49:45 - train: epoch 0137, iter [00250, 00390], lr: 0.004000, loss: 0.0036
2022-07-17 04:49:54 - train: epoch 0137, iter [00300, 00390], lr: 0.004000, loss: 0.0037
2022-07-17 04:50:03 - train: epoch 0137, iter [00350, 00390], lr: 0.004000, loss: 0.0128
2022-07-17 04:50:11 - train: epoch 137, train_loss: 0.0054
2022-07-17 04:50:20 - eval: epoch: 137, acc1: 76.370%, acc5: 94.100%, test_loss: 1.2305, per_image_load_time: 0.540ms, per_image_inference_time: 0.299ms
2022-07-17 04:50:21 - until epoch: 137, best_acc1: 76.550%
2022-07-17 04:50:21 - epoch 138 lr: 0.004000
2022-07-17 04:50:35 - train: epoch 0138, iter [00050, 00390], lr: 0.004000, loss: 0.0026
2022-07-17 04:50:44 - train: epoch 0138, iter [00100, 00390], lr: 0.004000, loss: 0.0020
2022-07-17 04:50:53 - train: epoch 0138, iter [00150, 00390], lr: 0.004000, loss: 0.0034
2022-07-17 04:51:02 - train: epoch 0138, iter [00200, 00390], lr: 0.004000, loss: 0.0109
2022-07-17 04:51:11 - train: epoch 0138, iter [00250, 00390], lr: 0.004000, loss: 0.0062
2022-07-17 04:51:20 - train: epoch 0138, iter [00300, 00390], lr: 0.004000, loss: 0.0131
2022-07-17 04:51:29 - train: epoch 0138, iter [00350, 00390], lr: 0.004000, loss: 0.0014
2022-07-17 04:51:37 - train: epoch 138, train_loss: 0.0054
2022-07-17 04:51:45 - eval: epoch: 138, acc1: 76.430%, acc5: 94.010%, test_loss: 1.2317, per_image_load_time: 0.527ms, per_image_inference_time: 0.293ms
2022-07-17 04:51:46 - until epoch: 138, best_acc1: 76.550%
2022-07-17 04:51:46 - epoch 139 lr: 0.004000
2022-07-17 04:52:00 - train: epoch 0139, iter [00050, 00390], lr: 0.004000, loss: 0.0102
2022-07-17 04:52:09 - train: epoch 0139, iter [00100, 00390], lr: 0.004000, loss: 0.0156
2022-07-17 04:52:18 - train: epoch 0139, iter [00150, 00390], lr: 0.004000, loss: 0.0139
2022-07-17 04:52:27 - train: epoch 0139, iter [00200, 00390], lr: 0.004000, loss: 0.0016
2022-07-17 04:52:36 - train: epoch 0139, iter [00250, 00390], lr: 0.004000, loss: 0.0024
2022-07-17 04:52:45 - train: epoch 0139, iter [00300, 00390], lr: 0.004000, loss: 0.0036
2022-07-17 04:52:54 - train: epoch 0139, iter [00350, 00390], lr: 0.004000, loss: 0.0020
2022-07-17 04:53:02 - train: epoch 139, train_loss: 0.0052
2022-07-17 04:53:10 - eval: epoch: 139, acc1: 76.570%, acc5: 93.890%, test_loss: 1.2325, per_image_load_time: 0.437ms, per_image_inference_time: 0.302ms
2022-07-17 04:53:11 - until epoch: 139, best_acc1: 76.570%
2022-07-17 04:53:11 - epoch 140 lr: 0.004000
2022-07-17 04:53:24 - train: epoch 0140, iter [00050, 00390], lr: 0.004000, loss: 0.0026
2022-07-17 04:53:33 - train: epoch 0140, iter [00100, 00390], lr: 0.004000, loss: 0.0059
2022-07-17 04:53:42 - train: epoch 0140, iter [00150, 00390], lr: 0.004000, loss: 0.0048
2022-07-17 04:53:51 - train: epoch 0140, iter [00200, 00390], lr: 0.004000, loss: 0.0039
2022-07-17 04:54:00 - train: epoch 0140, iter [00250, 00390], lr: 0.004000, loss: 0.0012
2022-07-17 04:54:09 - train: epoch 0140, iter [00300, 00390], lr: 0.004000, loss: 0.0030
2022-07-17 04:54:19 - train: epoch 0140, iter [00350, 00390], lr: 0.004000, loss: 0.0019
2022-07-17 04:54:26 - train: epoch 140, train_loss: 0.0043
2022-07-17 04:54:35 - eval: epoch: 140, acc1: 76.500%, acc5: 93.960%, test_loss: 1.2291, per_image_load_time: 0.515ms, per_image_inference_time: 0.292ms
2022-07-17 04:54:35 - until epoch: 140, best_acc1: 76.570%
2022-07-17 04:54:35 - epoch 141 lr: 0.004000
2022-07-17 04:54:50 - train: epoch 0141, iter [00050, 00390], lr: 0.004000, loss: 0.0067
2022-07-17 04:54:59 - train: epoch 0141, iter [00100, 00390], lr: 0.004000, loss: 0.0016
2022-07-17 04:55:08 - train: epoch 0141, iter [00150, 00390], lr: 0.004000, loss: 0.0101
2022-07-17 04:55:17 - train: epoch 0141, iter [00200, 00390], lr: 0.004000, loss: 0.0031
2022-07-17 04:55:26 - train: epoch 0141, iter [00250, 00390], lr: 0.004000, loss: 0.0066
2022-07-17 04:55:35 - train: epoch 0141, iter [00300, 00390], lr: 0.004000, loss: 0.0021
2022-07-17 04:55:43 - train: epoch 0141, iter [00350, 00390], lr: 0.004000, loss: 0.0102
2022-07-17 04:55:51 - train: epoch 141, train_loss: 0.0047
2022-07-17 04:56:00 - eval: epoch: 141, acc1: 76.650%, acc5: 94.070%, test_loss: 1.2362, per_image_load_time: 0.560ms, per_image_inference_time: 0.288ms
2022-07-17 04:56:01 - until epoch: 141, best_acc1: 76.650%
2022-07-17 04:56:01 - epoch 142 lr: 0.004000
2022-07-17 04:56:15 - train: epoch 0142, iter [00050, 00390], lr: 0.004000, loss: 0.0062
2022-07-17 04:56:24 - train: epoch 0142, iter [00100, 00390], lr: 0.004000, loss: 0.0022
2022-07-17 04:56:33 - train: epoch 0142, iter [00150, 00390], lr: 0.004000, loss: 0.0045
2022-07-17 04:56:42 - train: epoch 0142, iter [00200, 00390], lr: 0.004000, loss: 0.0081
2022-07-17 04:56:51 - train: epoch 0142, iter [00250, 00390], lr: 0.004000, loss: 0.0013
2022-07-17 04:57:00 - train: epoch 0142, iter [00300, 00390], lr: 0.004000, loss: 0.0026
2022-07-17 04:57:09 - train: epoch 0142, iter [00350, 00390], lr: 0.004000, loss: 0.0017
2022-07-17 04:57:17 - train: epoch 142, train_loss: 0.0042
2022-07-17 04:57:26 - eval: epoch: 142, acc1: 76.530%, acc5: 93.940%, test_loss: 1.2332, per_image_load_time: 0.529ms, per_image_inference_time: 0.300ms
2022-07-17 04:57:26 - until epoch: 142, best_acc1: 76.650%
2022-07-17 04:57:26 - epoch 143 lr: 0.004000
2022-07-17 04:57:40 - train: epoch 0143, iter [00050, 00390], lr: 0.004000, loss: 0.0022
2022-07-17 04:57:49 - train: epoch 0143, iter [00100, 00390], lr: 0.004000, loss: 0.0032
2022-07-17 04:57:59 - train: epoch 0143, iter [00150, 00390], lr: 0.004000, loss: 0.0036
2022-07-17 04:58:07 - train: epoch 0143, iter [00200, 00390], lr: 0.004000, loss: 0.0023
2022-07-17 04:58:16 - train: epoch 0143, iter [00250, 00390], lr: 0.004000, loss: 0.0015
2022-07-17 04:58:25 - train: epoch 0143, iter [00300, 00390], lr: 0.004000, loss: 0.0019
2022-07-17 04:58:34 - train: epoch 0143, iter [00350, 00390], lr: 0.004000, loss: 0.0048
2022-07-17 04:58:42 - train: epoch 143, train_loss: 0.0048
2022-07-17 04:58:51 - eval: epoch: 143, acc1: 76.600%, acc5: 94.000%, test_loss: 1.2322, per_image_load_time: 0.519ms, per_image_inference_time: 0.300ms
2022-07-17 04:58:51 - until epoch: 143, best_acc1: 76.650%
2022-07-17 04:58:51 - epoch 144 lr: 0.004000
2022-07-17 04:59:06 - train: epoch 0144, iter [00050, 00390], lr: 0.004000, loss: 0.0063
2022-07-17 04:59:15 - train: epoch 0144, iter [00100, 00390], lr: 0.004000, loss: 0.0036
2022-07-17 04:59:24 - train: epoch 0144, iter [00150, 00390], lr: 0.004000, loss: 0.0039
2022-07-17 04:59:33 - train: epoch 0144, iter [00200, 00390], lr: 0.004000, loss: 0.0060
2022-07-17 04:59:42 - train: epoch 0144, iter [00250, 00390], lr: 0.004000, loss: 0.0569
2022-07-17 04:59:51 - train: epoch 0144, iter [00300, 00390], lr: 0.004000, loss: 0.0040
2022-07-17 05:00:00 - train: epoch 0144, iter [00350, 00390], lr: 0.004000, loss: 0.0023
2022-07-17 05:00:07 - train: epoch 144, train_loss: 0.0042
2022-07-17 05:00:17 - eval: epoch: 144, acc1: 76.740%, acc5: 94.080%, test_loss: 1.2258, per_image_load_time: 0.570ms, per_image_inference_time: 0.300ms
2022-07-17 05:00:18 - until epoch: 144, best_acc1: 76.740%
2022-07-17 05:00:18 - epoch 145 lr: 0.004000
2022-07-17 05:00:32 - train: epoch 0145, iter [00050, 00390], lr: 0.004000, loss: 0.0029
2022-07-17 05:00:41 - train: epoch 0145, iter [00100, 00390], lr: 0.004000, loss: 0.0034
2022-07-17 05:00:50 - train: epoch 0145, iter [00150, 00390], lr: 0.004000, loss: 0.0039
2022-07-17 05:00:59 - train: epoch 0145, iter [00200, 00390], lr: 0.004000, loss: 0.0025
2022-07-17 05:01:08 - train: epoch 0145, iter [00250, 00390], lr: 0.004000, loss: 0.0024
2022-07-17 05:01:17 - train: epoch 0145, iter [00300, 00390], lr: 0.004000, loss: 0.0018
2022-07-17 05:01:26 - train: epoch 0145, iter [00350, 00390], lr: 0.004000, loss: 0.0011
2022-07-17 05:01:33 - train: epoch 145, train_loss: 0.0043
2022-07-17 05:01:42 - eval: epoch: 145, acc1: 76.500%, acc5: 94.070%, test_loss: 1.2116, per_image_load_time: 0.517ms, per_image_inference_time: 0.297ms
2022-07-17 05:01:43 - until epoch: 145, best_acc1: 76.740%
2022-07-17 05:01:43 - epoch 146 lr: 0.004000
2022-07-17 05:01:57 - train: epoch 0146, iter [00050, 00390], lr: 0.004000, loss: 0.0084
2022-07-17 05:02:06 - train: epoch 0146, iter [00100, 00390], lr: 0.004000, loss: 0.0017
2022-07-17 05:02:15 - train: epoch 0146, iter [00150, 00390], lr: 0.004000, loss: 0.0041
2022-07-17 05:02:24 - train: epoch 0146, iter [00200, 00390], lr: 0.004000, loss: 0.0037
2022-07-17 05:02:33 - train: epoch 0146, iter [00250, 00390], lr: 0.004000, loss: 0.0026
2022-07-17 05:02:42 - train: epoch 0146, iter [00300, 00390], lr: 0.004000, loss: 0.0055
2022-07-17 05:02:51 - train: epoch 0146, iter [00350, 00390], lr: 0.004000, loss: 0.0030
2022-07-17 05:02:58 - train: epoch 146, train_loss: 0.0044
2022-07-17 05:03:07 - eval: epoch: 146, acc1: 76.740%, acc5: 94.010%, test_loss: 1.2267, per_image_load_time: 0.551ms, per_image_inference_time: 0.292ms
2022-07-17 05:03:08 - until epoch: 146, best_acc1: 76.740%
2022-07-17 05:03:08 - epoch 147 lr: 0.004000
2022-07-17 05:03:22 - train: epoch 0147, iter [00050, 00390], lr: 0.004000, loss: 0.0058
2022-07-17 05:03:31 - train: epoch 0147, iter [00100, 00390], lr: 0.004000, loss: 0.0012
2022-07-17 05:03:40 - train: epoch 0147, iter [00150, 00390], lr: 0.004000, loss: 0.0018
2022-07-17 05:03:49 - train: epoch 0147, iter [00200, 00390], lr: 0.004000, loss: 0.0032
2022-07-17 05:03:58 - train: epoch 0147, iter [00250, 00390], lr: 0.004000, loss: 0.0031
2022-07-17 05:04:07 - train: epoch 0147, iter [00300, 00390], lr: 0.004000, loss: 0.0022
2022-07-17 05:04:16 - train: epoch 0147, iter [00350, 00390], lr: 0.004000, loss: 0.0023
2022-07-17 05:04:24 - train: epoch 147, train_loss: 0.0038
2022-07-17 05:04:32 - eval: epoch: 147, acc1: 76.790%, acc5: 94.000%, test_loss: 1.2128, per_image_load_time: 0.519ms, per_image_inference_time: 0.295ms
2022-07-17 05:04:33 - until epoch: 147, best_acc1: 76.790%
2022-07-17 05:04:33 - epoch 148 lr: 0.004000
2022-07-17 05:04:47 - train: epoch 0148, iter [00050, 00390], lr: 0.004000, loss: 0.0014
2022-07-17 05:04:56 - train: epoch 0148, iter [00100, 00390], lr: 0.004000, loss: 0.0119
2022-07-17 05:05:05 - train: epoch 0148, iter [00150, 00390], lr: 0.004000, loss: 0.0014
2022-07-17 05:05:14 - train: epoch 0148, iter [00200, 00390], lr: 0.004000, loss: 0.0024
2022-07-17 05:05:23 - train: epoch 0148, iter [00250, 00390], lr: 0.004000, loss: 0.0016
2022-07-17 05:05:32 - train: epoch 0148, iter [00300, 00390], lr: 0.004000, loss: 0.0025
2022-07-17 05:05:41 - train: epoch 0148, iter [00350, 00390], lr: 0.004000, loss: 0.0028
2022-07-17 05:05:49 - train: epoch 148, train_loss: 0.0042
2022-07-17 05:05:57 - eval: epoch: 148, acc1: 76.730%, acc5: 93.980%, test_loss: 1.2268, per_image_load_time: 0.547ms, per_image_inference_time: 0.292ms
2022-07-17 05:05:58 - until epoch: 148, best_acc1: 76.790%
2022-07-17 05:05:58 - epoch 149 lr: 0.004000
2022-07-17 05:06:12 - train: epoch 0149, iter [00050, 00390], lr: 0.004000, loss: 0.0025
2022-07-17 05:06:22 - train: epoch 0149, iter [00100, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 05:06:30 - train: epoch 0149, iter [00150, 00390], lr: 0.004000, loss: 0.0040
2022-07-17 05:06:39 - train: epoch 0149, iter [00200, 00390], lr: 0.004000, loss: 0.0023
2022-07-17 05:06:48 - train: epoch 0149, iter [00250, 00390], lr: 0.004000, loss: 0.0023
2022-07-17 05:06:57 - train: epoch 0149, iter [00300, 00390], lr: 0.004000, loss: 0.0020
2022-07-17 05:07:06 - train: epoch 0149, iter [00350, 00390], lr: 0.004000, loss: 0.0025
2022-07-17 05:07:13 - train: epoch 149, train_loss: 0.0037
2022-07-17 05:07:22 - eval: epoch: 149, acc1: 76.730%, acc5: 93.980%, test_loss: 1.2236, per_image_load_time: 0.494ms, per_image_inference_time: 0.300ms
2022-07-17 05:07:23 - until epoch: 149, best_acc1: 76.790%
2022-07-17 05:07:23 - epoch 150 lr: 0.004000
2022-07-17 05:07:37 - train: epoch 0150, iter [00050, 00390], lr: 0.004000, loss: 0.0046
2022-07-17 05:07:46 - train: epoch 0150, iter [00100, 00390], lr: 0.004000, loss: 0.0015
2022-07-17 05:07:55 - train: epoch 0150, iter [00150, 00390], lr: 0.004000, loss: 0.0055
2022-07-17 05:08:04 - train: epoch 0150, iter [00200, 00390], lr: 0.004000, loss: 0.0019
2022-07-17 05:08:13 - train: epoch 0150, iter [00250, 00390], lr: 0.004000, loss: 0.0032
2022-07-17 05:08:22 - train: epoch 0150, iter [00300, 00390], lr: 0.004000, loss: 0.0023
2022-07-17 05:08:31 - train: epoch 0150, iter [00350, 00390], lr: 0.004000, loss: 0.0142
2022-07-17 05:08:38 - train: epoch 150, train_loss: 0.0037
2022-07-17 05:08:47 - eval: epoch: 150, acc1: 76.710%, acc5: 93.970%, test_loss: 1.2231, per_image_load_time: 0.492ms, per_image_inference_time: 0.293ms
2022-07-17 05:08:47 - until epoch: 150, best_acc1: 76.790%
2022-07-17 05:08:47 - epoch 151 lr: 0.004000
2022-07-17 05:09:02 - train: epoch 0151, iter [00050, 00390], lr: 0.004000, loss: 0.0051
2022-07-17 05:09:11 - train: epoch 0151, iter [00100, 00390], lr: 0.004000, loss: 0.0030
2022-07-17 05:09:20 - train: epoch 0151, iter [00150, 00390], lr: 0.004000, loss: 0.0095
2022-07-17 05:09:29 - train: epoch 0151, iter [00200, 00390], lr: 0.004000, loss: 0.0318
2022-07-17 05:09:38 - train: epoch 0151, iter [00250, 00390], lr: 0.004000, loss: 0.0023
2022-07-17 05:09:47 - train: epoch 0151, iter [00300, 00390], lr: 0.004000, loss: 0.0020
2022-07-17 05:09:55 - train: epoch 0151, iter [00350, 00390], lr: 0.004000, loss: 0.0012
2022-07-17 05:10:03 - train: epoch 151, train_loss: 0.0037
2022-07-17 05:10:12 - eval: epoch: 151, acc1: 76.710%, acc5: 93.950%, test_loss: 1.2252, per_image_load_time: 0.530ms, per_image_inference_time: 0.302ms
2022-07-17 05:10:12 - until epoch: 151, best_acc1: 76.790%
2022-07-17 05:10:12 - epoch 152 lr: 0.004000
2022-07-17 05:10:27 - train: epoch 0152, iter [00050, 00390], lr: 0.004000, loss: 0.0016
2022-07-17 05:10:36 - train: epoch 0152, iter [00100, 00390], lr: 0.004000, loss: 0.0010
2022-07-17 05:10:45 - train: epoch 0152, iter [00150, 00390], lr: 0.004000, loss: 0.0073
2022-07-17 05:10:54 - train: epoch 0152, iter [00200, 00390], lr: 0.004000, loss: 0.0022
2022-07-17 05:11:03 - train: epoch 0152, iter [00250, 00390], lr: 0.004000, loss: 0.0024
2022-07-17 05:11:12 - train: epoch 0152, iter [00300, 00390], lr: 0.004000, loss: 0.0035
2022-07-17 05:11:21 - train: epoch 0152, iter [00350, 00390], lr: 0.004000, loss: 0.0032
2022-07-17 05:11:28 - train: epoch 152, train_loss: 0.0038
2022-07-17 05:11:37 - eval: epoch: 152, acc1: 76.580%, acc5: 93.880%, test_loss: 1.2236, per_image_load_time: 0.517ms, per_image_inference_time: 0.288ms
2022-07-17 05:11:38 - until epoch: 152, best_acc1: 76.790%
2022-07-17 05:11:38 - epoch 153 lr: 0.004000
2022-07-17 05:11:51 - train: epoch 0153, iter [00050, 00390], lr: 0.004000, loss: 0.0041
2022-07-17 05:12:00 - train: epoch 0153, iter [00100, 00390], lr: 0.004000, loss: 0.0009
2022-07-17 05:12:09 - train: epoch 0153, iter [00150, 00390], lr: 0.004000, loss: 0.0025
2022-07-17 05:12:18 - train: epoch 0153, iter [00200, 00390], lr: 0.004000, loss: 0.0031
2022-07-17 05:12:27 - train: epoch 0153, iter [00250, 00390], lr: 0.004000, loss: 0.0025
2022-07-17 05:12:36 - train: epoch 0153, iter [00300, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 05:12:45 - train: epoch 0153, iter [00350, 00390], lr: 0.004000, loss: 0.0007
2022-07-17 05:12:53 - train: epoch 153, train_loss: 0.0039
2022-07-17 05:13:01 - eval: epoch: 153, acc1: 76.690%, acc5: 93.860%, test_loss: 1.2208, per_image_load_time: 0.499ms, per_image_inference_time: 0.294ms
2022-07-17 05:13:02 - until epoch: 153, best_acc1: 76.790%
2022-07-17 05:13:02 - epoch 154 lr: 0.004000
2022-07-17 05:13:16 - train: epoch 0154, iter [00050, 00390], lr: 0.004000, loss: 0.0011
2022-07-17 05:13:25 - train: epoch 0154, iter [00100, 00390], lr: 0.004000, loss: 0.0020
2022-07-17 05:13:34 - train: epoch 0154, iter [00150, 00390], lr: 0.004000, loss: 0.0021
2022-07-17 05:13:43 - train: epoch 0154, iter [00200, 00390], lr: 0.004000, loss: 0.0028
2022-07-17 05:13:51 - train: epoch 0154, iter [00250, 00390], lr: 0.004000, loss: 0.0021
2022-07-17 05:14:00 - train: epoch 0154, iter [00300, 00390], lr: 0.004000, loss: 0.0030
2022-07-17 05:14:09 - train: epoch 0154, iter [00350, 00390], lr: 0.004000, loss: 0.0021
2022-07-17 05:14:17 - train: epoch 154, train_loss: 0.0037
2022-07-17 05:14:26 - eval: epoch: 154, acc1: 76.670%, acc5: 93.980%, test_loss: 1.2169, per_image_load_time: 0.570ms, per_image_inference_time: 0.290ms
2022-07-17 05:14:26 - until epoch: 154, best_acc1: 76.790%
2022-07-17 05:14:26 - epoch 155 lr: 0.004000
2022-07-17 05:14:41 - train: epoch 0155, iter [00050, 00390], lr: 0.004000, loss: 0.0020
2022-07-17 05:14:49 - train: epoch 0155, iter [00100, 00390], lr: 0.004000, loss: 0.0011
2022-07-17 05:14:58 - train: epoch 0155, iter [00150, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 05:15:07 - train: epoch 0155, iter [00200, 00390], lr: 0.004000, loss: 0.0021
2022-07-17 05:15:16 - train: epoch 0155, iter [00250, 00390], lr: 0.004000, loss: 0.0064
2022-07-17 05:15:25 - train: epoch 0155, iter [00300, 00390], lr: 0.004000, loss: 0.0030
2022-07-17 05:15:34 - train: epoch 0155, iter [00350, 00390], lr: 0.004000, loss: 0.0015
2022-07-17 05:15:42 - train: epoch 155, train_loss: 0.0036
2022-07-17 05:15:50 - eval: epoch: 155, acc1: 76.780%, acc5: 93.990%, test_loss: 1.2150, per_image_load_time: 0.495ms, per_image_inference_time: 0.293ms
2022-07-17 05:15:51 - until epoch: 155, best_acc1: 76.790%
2022-07-17 05:15:51 - epoch 156 lr: 0.004000
2022-07-17 05:16:05 - train: epoch 0156, iter [00050, 00390], lr: 0.004000, loss: 0.0028
2022-07-17 05:16:14 - train: epoch 0156, iter [00100, 00390], lr: 0.004000, loss: 0.0007
2022-07-17 05:16:23 - train: epoch 0156, iter [00150, 00390], lr: 0.004000, loss: 0.0030
2022-07-17 05:16:32 - train: epoch 0156, iter [00200, 00390], lr: 0.004000, loss: 0.0011
2022-07-17 05:16:41 - train: epoch 0156, iter [00250, 00390], lr: 0.004000, loss: 0.0335
2022-07-17 05:16:50 - train: epoch 0156, iter [00300, 00390], lr: 0.004000, loss: 0.0129
2022-07-17 05:16:58 - train: epoch 0156, iter [00350, 00390], lr: 0.004000, loss: 0.0017
2022-07-17 05:17:06 - train: epoch 156, train_loss: 0.0038
2022-07-17 05:17:15 - eval: epoch: 156, acc1: 76.710%, acc5: 94.010%, test_loss: 1.2282, per_image_load_time: 0.512ms, per_image_inference_time: 0.305ms
2022-07-17 05:17:15 - until epoch: 156, best_acc1: 76.790%
2022-07-17 05:17:15 - epoch 157 lr: 0.004000
2022-07-17 05:17:29 - train: epoch 0157, iter [00050, 00390], lr: 0.004000, loss: 0.0206
2022-07-17 05:17:38 - train: epoch 0157, iter [00100, 00390], lr: 0.004000, loss: 0.0214
2022-07-17 05:17:47 - train: epoch 0157, iter [00150, 00390], lr: 0.004000, loss: 0.0020
2022-07-17 05:17:56 - train: epoch 0157, iter [00200, 00390], lr: 0.004000, loss: 0.0012
2022-07-17 05:18:05 - train: epoch 0157, iter [00250, 00390], lr: 0.004000, loss: 0.0042
2022-07-17 05:18:14 - train: epoch 0157, iter [00300, 00390], lr: 0.004000, loss: 0.0019
2022-07-17 05:18:23 - train: epoch 0157, iter [00350, 00390], lr: 0.004000, loss: 0.0046
2022-07-17 05:18:30 - train: epoch 157, train_loss: 0.0031
2022-07-17 05:18:39 - eval: epoch: 157, acc1: 76.770%, acc5: 94.030%, test_loss: 1.2160, per_image_load_time: 0.556ms, per_image_inference_time: 0.297ms
2022-07-17 05:18:40 - until epoch: 157, best_acc1: 76.790%
2022-07-17 05:18:40 - epoch 158 lr: 0.004000
2022-07-17 05:18:54 - train: epoch 0158, iter [00050, 00390], lr: 0.004000, loss: 0.0016
2022-07-17 05:19:03 - train: epoch 0158, iter [00100, 00390], lr: 0.004000, loss: 0.0011
2022-07-17 05:19:12 - train: epoch 0158, iter [00150, 00390], lr: 0.004000, loss: 0.0016
2022-07-17 05:19:21 - train: epoch 0158, iter [00200, 00390], lr: 0.004000, loss: 0.0065
2022-07-17 05:19:30 - train: epoch 0158, iter [00250, 00390], lr: 0.004000, loss: 0.0012
2022-07-17 05:19:39 - train: epoch 0158, iter [00300, 00390], lr: 0.004000, loss: 0.0026
2022-07-17 05:19:48 - train: epoch 0158, iter [00350, 00390], lr: 0.004000, loss: 0.0025
2022-07-17 05:19:55 - train: epoch 158, train_loss: 0.0035
2022-07-17 05:20:04 - eval: epoch: 158, acc1: 76.640%, acc5: 93.880%, test_loss: 1.2181, per_image_load_time: 0.537ms, per_image_inference_time: 0.298ms
2022-07-17 05:20:05 - until epoch: 158, best_acc1: 76.790%
2022-07-17 05:20:05 - epoch 159 lr: 0.004000
2022-07-17 05:20:19 - train: epoch 0159, iter [00050, 00390], lr: 0.004000, loss: 0.0009
2022-07-17 05:20:28 - train: epoch 0159, iter [00100, 00390], lr: 0.004000, loss: 0.0026
2022-07-17 05:20:36 - train: epoch 0159, iter [00150, 00390], lr: 0.004000, loss: 0.0007
2022-07-17 05:20:45 - train: epoch 0159, iter [00200, 00390], lr: 0.004000, loss: 0.0013
2022-07-17 05:20:54 - train: epoch 0159, iter [00250, 00390], lr: 0.004000, loss: 0.0181
2022-07-17 05:21:03 - train: epoch 0159, iter [00300, 00390], lr: 0.004000, loss: 0.0017
2022-07-17 05:21:12 - train: epoch 0159, iter [00350, 00390], lr: 0.004000, loss: 0.0017
2022-07-17 05:21:19 - train: epoch 159, train_loss: 0.0032
2022-07-17 05:21:27 - eval: epoch: 159, acc1: 76.730%, acc5: 93.910%, test_loss: 1.2160, per_image_load_time: 0.436ms, per_image_inference_time: 0.296ms
2022-07-17 05:21:28 - until epoch: 159, best_acc1: 76.790%
2022-07-17 05:21:28 - epoch 160 lr: 0.004000
2022-07-17 05:21:42 - train: epoch 0160, iter [00050, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 05:21:51 - train: epoch 0160, iter [00100, 00390], lr: 0.004000, loss: 0.0034
2022-07-17 05:22:00 - train: epoch 0160, iter [00150, 00390], lr: 0.004000, loss: 0.0020
2022-07-17 05:22:09 - train: epoch 0160, iter [00200, 00390], lr: 0.004000, loss: 0.0020
2022-07-17 05:22:18 - train: epoch 0160, iter [00250, 00390], lr: 0.004000, loss: 0.0019
2022-07-17 05:22:27 - train: epoch 0160, iter [00300, 00390], lr: 0.004000, loss: 0.0013
2022-07-17 05:22:36 - train: epoch 0160, iter [00350, 00390], lr: 0.004000, loss: 0.0036
2022-07-17 05:22:44 - train: epoch 160, train_loss: 0.0031
2022-07-17 05:22:52 - eval: epoch: 160, acc1: 76.620%, acc5: 94.020%, test_loss: 1.2259, per_image_load_time: 0.473ms, per_image_inference_time: 0.293ms
2022-07-17 05:22:53 - until epoch: 160, best_acc1: 76.790%
2022-07-17 05:22:53 - epoch 161 lr: 0.000800
2022-07-17 05:23:05 - train: epoch 0161, iter [00050, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 05:23:14 - train: epoch 0161, iter [00100, 00390], lr: 0.000800, loss: 0.0071
2022-07-17 05:23:23 - train: epoch 0161, iter [00150, 00390], lr: 0.000800, loss: 0.0009
2022-07-17 05:23:32 - train: epoch 0161, iter [00200, 00390], lr: 0.000800, loss: 0.0006
2022-07-17 05:23:41 - train: epoch 0161, iter [00250, 00390], lr: 0.000800, loss: 0.0016
2022-07-17 05:23:50 - train: epoch 0161, iter [00300, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 05:23:59 - train: epoch 0161, iter [00350, 00390], lr: 0.000800, loss: 0.0082
2022-07-17 05:24:06 - train: epoch 161, train_loss: 0.0029
2022-07-17 05:24:15 - eval: epoch: 161, acc1: 76.860%, acc5: 94.020%, test_loss: 1.2182, per_image_load_time: 0.490ms, per_image_inference_time: 0.298ms
2022-07-17 05:24:16 - until epoch: 161, best_acc1: 76.860%
2022-07-17 05:24:16 - epoch 162 lr: 0.000800
2022-07-17 05:24:30 - train: epoch 0162, iter [00050, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 05:24:39 - train: epoch 0162, iter [00100, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 05:24:48 - train: epoch 0162, iter [00150, 00390], lr: 0.000800, loss: 0.0035
2022-07-17 05:24:57 - train: epoch 0162, iter [00200, 00390], lr: 0.000800, loss: 0.0114
2022-07-17 05:25:06 - train: epoch 0162, iter [00250, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 05:25:15 - train: epoch 0162, iter [00300, 00390], lr: 0.000800, loss: 0.0034
2022-07-17 05:25:24 - train: epoch 0162, iter [00350, 00390], lr: 0.000800, loss: 0.0007
2022-07-17 05:25:31 - train: epoch 162, train_loss: 0.0027
2022-07-17 05:25:39 - eval: epoch: 162, acc1: 76.860%, acc5: 93.970%, test_loss: 1.2051, per_image_load_time: 0.475ms, per_image_inference_time: 0.296ms
2022-07-17 05:25:40 - until epoch: 162, best_acc1: 76.860%
2022-07-17 05:25:40 - epoch 163 lr: 0.000800
2022-07-17 05:25:55 - train: epoch 0163, iter [00050, 00390], lr: 0.000800, loss: 0.0126
2022-07-17 05:26:04 - train: epoch 0163, iter [00100, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 05:26:13 - train: epoch 0163, iter [00150, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 05:26:21 - train: epoch 0163, iter [00200, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 05:26:30 - train: epoch 0163, iter [00250, 00390], lr: 0.000800, loss: 0.0026
2022-07-17 05:26:39 - train: epoch 0163, iter [00300, 00390], lr: 0.000800, loss: 0.0010
2022-07-17 05:26:48 - train: epoch 0163, iter [00350, 00390], lr: 0.000800, loss: 0.0036
2022-07-17 05:26:55 - train: epoch 163, train_loss: 0.0025
2022-07-17 05:27:04 - eval: epoch: 163, acc1: 76.880%, acc5: 94.080%, test_loss: 1.2061, per_image_load_time: 0.515ms, per_image_inference_time: 0.300ms
2022-07-17 05:27:05 - until epoch: 163, best_acc1: 76.880%
2022-07-17 05:27:05 - epoch 164 lr: 0.000800
2022-07-17 05:27:19 - train: epoch 0164, iter [00050, 00390], lr: 0.000800, loss: 0.0067
2022-07-17 05:27:28 - train: epoch 0164, iter [00100, 00390], lr: 0.000800, loss: 0.0016
2022-07-17 05:27:37 - train: epoch 0164, iter [00150, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 05:27:46 - train: epoch 0164, iter [00200, 00390], lr: 0.000800, loss: 0.0010
2022-07-17 05:27:55 - train: epoch 0164, iter [00250, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 05:28:04 - train: epoch 0164, iter [00300, 00390], lr: 0.000800, loss: 0.0036
2022-07-17 05:28:13 - train: epoch 0164, iter [00350, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 05:28:21 - train: epoch 164, train_loss: 0.0027
2022-07-17 05:28:27 - eval: epoch: 164, acc1: 77.010%, acc5: 94.060%, test_loss: 1.2075, per_image_load_time: 0.293ms, per_image_inference_time: 0.294ms
2022-07-17 05:28:28 - until epoch: 164, best_acc1: 77.010%
2022-07-17 05:28:28 - epoch 165 lr: 0.000800
2022-07-17 05:28:42 - train: epoch 0165, iter [00050, 00390], lr: 0.000800, loss: 0.0005
2022-07-17 05:28:51 - train: epoch 0165, iter [00100, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 05:29:00 - train: epoch 0165, iter [00150, 00390], lr: 0.000800, loss: 0.0043
2022-07-17 05:29:09 - train: epoch 0165, iter [00200, 00390], lr: 0.000800, loss: 0.0080
2022-07-17 05:29:19 - train: epoch 0165, iter [00250, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 05:29:28 - train: epoch 0165, iter [00300, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 05:29:37 - train: epoch 0165, iter [00350, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 05:29:45 - train: epoch 165, train_loss: 0.0027
2022-07-17 05:29:51 - eval: epoch: 165, acc1: 76.920%, acc5: 94.040%, test_loss: 1.2067, per_image_load_time: 0.309ms, per_image_inference_time: 0.293ms
2022-07-17 05:29:52 - until epoch: 165, best_acc1: 77.010%
2022-07-17 05:29:52 - epoch 166 lr: 0.000800
2022-07-17 05:30:03 - train: epoch 0166, iter [00050, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 05:30:13 - train: epoch 0166, iter [00100, 00390], lr: 0.000800, loss: 0.0007
2022-07-17 05:30:22 - train: epoch 0166, iter [00150, 00390], lr: 0.000800, loss: 0.0048
2022-07-17 05:30:31 - train: epoch 0166, iter [00200, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 05:30:40 - train: epoch 0166, iter [00250, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 05:30:49 - train: epoch 0166, iter [00300, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 05:30:58 - train: epoch 0166, iter [00350, 00390], lr: 0.000800, loss: 0.0022
2022-07-17 05:31:06 - train: epoch 166, train_loss: 0.0025
2022-07-17 05:31:12 - eval: epoch: 166, acc1: 76.880%, acc5: 94.090%, test_loss: 1.2031, per_image_load_time: 0.262ms, per_image_inference_time: 0.296ms
2022-07-17 05:31:13 - until epoch: 166, best_acc1: 77.010%
2022-07-17 05:31:13 - epoch 167 lr: 0.000800
2022-07-17 05:31:25 - train: epoch 0167, iter [00050, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 05:31:34 - train: epoch 0167, iter [00100, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 05:31:43 - train: epoch 0167, iter [00150, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 05:31:52 - train: epoch 0167, iter [00200, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 05:32:01 - train: epoch 0167, iter [00250, 00390], lr: 0.000800, loss: 0.0046
2022-07-17 05:32:10 - train: epoch 0167, iter [00300, 00390], lr: 0.000800, loss: 0.0025
2022-07-17 05:32:19 - train: epoch 0167, iter [00350, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 05:32:27 - train: epoch 167, train_loss: 0.0025
2022-07-17 05:32:33 - eval: epoch: 167, acc1: 76.910%, acc5: 94.160%, test_loss: 1.2014, per_image_load_time: 0.268ms, per_image_inference_time: 0.292ms
2022-07-17 05:32:34 - until epoch: 167, best_acc1: 77.010%
2022-07-17 05:32:34 - epoch 168 lr: 0.000800
2022-07-17 05:32:45 - train: epoch 0168, iter [00050, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 05:32:54 - train: epoch 0168, iter [00100, 00390], lr: 0.000800, loss: 0.0015
2022-07-17 05:33:04 - train: epoch 0168, iter [00150, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 05:33:13 - train: epoch 0168, iter [00200, 00390], lr: 0.000800, loss: 0.0034
2022-07-17 05:33:22 - train: epoch 0168, iter [00250, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 05:33:31 - train: epoch 0168, iter [00300, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 05:33:40 - train: epoch 0168, iter [00350, 00390], lr: 0.000800, loss: 0.0023
2022-07-17 05:33:48 - train: epoch 168, train_loss: 0.0024
2022-07-17 05:33:54 - eval: epoch: 168, acc1: 76.720%, acc5: 94.090%, test_loss: 1.2013, per_image_load_time: 0.305ms, per_image_inference_time: 0.292ms
2022-07-17 05:33:55 - until epoch: 168, best_acc1: 77.010%
2022-07-17 05:33:55 - epoch 169 lr: 0.000800
2022-07-17 05:34:07 - train: epoch 0169, iter [00050, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 05:34:16 - train: epoch 0169, iter [00100, 00390], lr: 0.000800, loss: 0.0033
2022-07-17 05:34:25 - train: epoch 0169, iter [00150, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 05:34:34 - train: epoch 0169, iter [00200, 00390], lr: 0.000800, loss: 0.0006
2022-07-17 05:34:44 - train: epoch 0169, iter [00250, 00390], lr: 0.000800, loss: 0.0033
2022-07-17 05:34:53 - train: epoch 0169, iter [00300, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 05:35:02 - train: epoch 0169, iter [00350, 00390], lr: 0.000800, loss: 0.0010
2022-07-17 05:35:09 - train: epoch 169, train_loss: 0.0022
2022-07-17 05:35:16 - eval: epoch: 169, acc1: 76.970%, acc5: 94.020%, test_loss: 1.2021, per_image_load_time: 0.320ms, per_image_inference_time: 0.293ms
2022-07-17 05:35:17 - until epoch: 169, best_acc1: 77.010%
2022-07-17 05:35:17 - epoch 170 lr: 0.000800
2022-07-17 05:35:29 - train: epoch 0170, iter [00050, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 05:35:38 - train: epoch 0170, iter [00100, 00390], lr: 0.000800, loss: 0.0015
2022-07-17 05:35:47 - train: epoch 0170, iter [00150, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 05:35:57 - train: epoch 0170, iter [00200, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 05:36:06 - train: epoch 0170, iter [00250, 00390], lr: 0.000800, loss: 0.0058
2022-07-17 05:36:15 - train: epoch 0170, iter [00300, 00390], lr: 0.000800, loss: 0.0007
2022-07-17 05:36:24 - train: epoch 0170, iter [00350, 00390], lr: 0.000800, loss: 0.0026
2022-07-17 05:36:32 - train: epoch 170, train_loss: 0.0025
2022-07-17 05:36:38 - eval: epoch: 170, acc1: 76.960%, acc5: 94.060%, test_loss: 1.2024, per_image_load_time: 0.327ms, per_image_inference_time: 0.291ms
2022-07-17 05:36:39 - until epoch: 170, best_acc1: 77.010%
2022-07-17 05:36:39 - epoch 171 lr: 0.000800
2022-07-17 05:36:51 - train: epoch 0171, iter [00050, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 05:37:00 - train: epoch 0171, iter [00100, 00390], lr: 0.000800, loss: 0.0022
2022-07-17 05:37:09 - train: epoch 0171, iter [00150, 00390], lr: 0.000800, loss: 0.0022
2022-07-17 05:37:18 - train: epoch 0171, iter [00200, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 05:37:27 - train: epoch 0171, iter [00250, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 05:37:37 - train: epoch 0171, iter [00300, 00390], lr: 0.000800, loss: 0.0016
2022-07-17 05:37:46 - train: epoch 0171, iter [00350, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 05:37:54 - train: epoch 171, train_loss: 0.0023
2022-07-17 05:37:59 - eval: epoch: 171, acc1: 76.810%, acc5: 94.100%, test_loss: 1.2050, per_image_load_time: 0.247ms, per_image_inference_time: 0.298ms
2022-07-17 05:38:00 - until epoch: 171, best_acc1: 77.010%
2022-07-17 05:38:00 - epoch 172 lr: 0.000800
2022-07-17 05:38:13 - train: epoch 0172, iter [00050, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 05:38:21 - train: epoch 0172, iter [00100, 00390], lr: 0.000800, loss: 0.0206
2022-07-17 05:38:30 - train: epoch 0172, iter [00150, 00390], lr: 0.000800, loss: 0.0024
2022-07-17 05:38:39 - train: epoch 0172, iter [00200, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 05:38:48 - train: epoch 0172, iter [00250, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 05:38:57 - train: epoch 0172, iter [00300, 00390], lr: 0.000800, loss: 0.0062
2022-07-17 05:39:06 - train: epoch 0172, iter [00350, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 05:39:14 - train: epoch 172, train_loss: 0.0022
2022-07-17 05:39:21 - eval: epoch: 172, acc1: 77.090%, acc5: 94.000%, test_loss: 1.1996, per_image_load_time: 0.387ms, per_image_inference_time: 0.298ms
2022-07-17 05:39:22 - until epoch: 172, best_acc1: 77.090%
2022-07-17 05:39:22 - epoch 173 lr: 0.000800
2022-07-17 05:39:34 - train: epoch 0173, iter [00050, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 05:39:43 - train: epoch 0173, iter [00100, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 05:39:52 - train: epoch 0173, iter [00150, 00390], lr: 0.000800, loss: 0.0016
2022-07-17 05:40:00 - train: epoch 0173, iter [00200, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 05:40:09 - train: epoch 0173, iter [00250, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 05:40:18 - train: epoch 0173, iter [00300, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 05:40:27 - train: epoch 0173, iter [00350, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 05:40:34 - train: epoch 173, train_loss: 0.0023
2022-07-17 05:40:40 - eval: epoch: 173, acc1: 77.030%, acc5: 94.070%, test_loss: 1.1990, per_image_load_time: 0.277ms, per_image_inference_time: 0.292ms
2022-07-17 05:40:41 - until epoch: 173, best_acc1: 77.090%
2022-07-17 05:40:41 - epoch 174 lr: 0.000800
2022-07-17 05:40:53 - train: epoch 0174, iter [00050, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 05:41:02 - train: epoch 0174, iter [00100, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 05:41:11 - train: epoch 0174, iter [00150, 00390], lr: 0.000800, loss: 0.0024
2022-07-17 05:41:20 - train: epoch 0174, iter [00200, 00390], lr: 0.000800, loss: 0.0016
2022-07-17 05:41:28 - train: epoch 0174, iter [00250, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 05:41:37 - train: epoch 0174, iter [00300, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 05:41:46 - train: epoch 0174, iter [00350, 00390], lr: 0.000800, loss: 0.0015
2022-07-17 05:41:54 - train: epoch 174, train_loss: 0.0023
2022-07-17 05:42:00 - eval: epoch: 174, acc1: 77.090%, acc5: 94.030%, test_loss: 1.1996, per_image_load_time: 0.325ms, per_image_inference_time: 0.293ms
2022-07-17 05:42:01 - until epoch: 174, best_acc1: 77.090%
2022-07-17 05:42:01 - epoch 175 lr: 0.000800
2022-07-17 05:42:13 - train: epoch 0175, iter [00050, 00390], lr: 0.000800, loss: 0.0029
2022-07-17 05:42:22 - train: epoch 0175, iter [00100, 00390], lr: 0.000800, loss: 0.0041
2022-07-17 05:42:30 - train: epoch 0175, iter [00150, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 05:42:39 - train: epoch 0175, iter [00200, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 05:42:48 - train: epoch 0175, iter [00250, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 05:42:57 - train: epoch 0175, iter [00300, 00390], lr: 0.000800, loss: 0.0022
2022-07-17 05:43:06 - train: epoch 0175, iter [00350, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 05:43:13 - train: epoch 175, train_loss: 0.0022
2022-07-17 05:43:20 - eval: epoch: 175, acc1: 76.840%, acc5: 94.060%, test_loss: 1.1966, per_image_load_time: 0.352ms, per_image_inference_time: 0.293ms
2022-07-17 05:43:21 - until epoch: 175, best_acc1: 77.090%
2022-07-17 05:43:21 - epoch 176 lr: 0.000800
2022-07-17 05:43:33 - train: epoch 0176, iter [00050, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 05:43:41 - train: epoch 0176, iter [00100, 00390], lr: 0.000800, loss: 0.0096
2022-07-17 05:43:50 - train: epoch 0176, iter [00150, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 05:43:59 - train: epoch 0176, iter [00200, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 05:44:08 - train: epoch 0176, iter [00250, 00390], lr: 0.000800, loss: 0.0009
2022-07-17 05:44:16 - train: epoch 0176, iter [00300, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 05:44:25 - train: epoch 0176, iter [00350, 00390], lr: 0.000800, loss: 0.0010
2022-07-17 05:44:32 - train: epoch 176, train_loss: 0.0021
2022-07-17 05:44:39 - eval: epoch: 176, acc1: 77.090%, acc5: 93.970%, test_loss: 1.2005, per_image_load_time: 0.344ms, per_image_inference_time: 0.292ms
2022-07-17 05:44:40 - until epoch: 176, best_acc1: 77.090%
2022-07-17 05:44:40 - epoch 177 lr: 0.000800
2022-07-17 05:44:52 - train: epoch 0177, iter [00050, 00390], lr: 0.000800, loss: 0.0010
2022-07-17 05:45:00 - train: epoch 0177, iter [00100, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 05:45:09 - train: epoch 0177, iter [00150, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 05:45:18 - train: epoch 0177, iter [00200, 00390], lr: 0.000800, loss: 0.0160
2022-07-17 05:45:27 - train: epoch 0177, iter [00250, 00390], lr: 0.000800, loss: 0.0075
2022-07-17 05:45:36 - train: epoch 0177, iter [00300, 00390], lr: 0.000800, loss: 0.0069
2022-07-17 05:45:45 - train: epoch 0177, iter [00350, 00390], lr: 0.000800, loss: 0.0077
2022-07-17 05:45:52 - train: epoch 177, train_loss: 0.0022
2022-07-17 05:45:58 - eval: epoch: 177, acc1: 76.880%, acc5: 94.000%, test_loss: 1.1967, per_image_load_time: 0.295ms, per_image_inference_time: 0.299ms
2022-07-17 05:45:59 - until epoch: 177, best_acc1: 77.090%
2022-07-17 05:45:59 - epoch 178 lr: 0.000800
2022-07-17 05:46:11 - train: epoch 0178, iter [00050, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 05:46:20 - train: epoch 0178, iter [00100, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 05:46:28 - train: epoch 0178, iter [00150, 00390], lr: 0.000800, loss: 0.0015
2022-07-17 05:46:37 - train: epoch 0178, iter [00200, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 05:46:46 - train: epoch 0178, iter [00250, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 05:46:55 - train: epoch 0178, iter [00300, 00390], lr: 0.000800, loss: 0.0024
2022-07-17 05:47:04 - train: epoch 0178, iter [00350, 00390], lr: 0.000800, loss: 0.0010
2022-07-17 05:47:11 - train: epoch 178, train_loss: 0.0021
2022-07-17 05:47:17 - eval: epoch: 178, acc1: 76.930%, acc5: 94.100%, test_loss: 1.2023, per_image_load_time: 0.261ms, per_image_inference_time: 0.293ms
2022-07-17 05:47:18 - until epoch: 178, best_acc1: 77.090%
2022-07-17 05:47:18 - epoch 179 lr: 0.000800
2022-07-17 05:47:29 - train: epoch 0179, iter [00050, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 05:47:38 - train: epoch 0179, iter [00100, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 05:47:47 - train: epoch 0179, iter [00150, 00390], lr: 0.000800, loss: 0.0076
2022-07-17 05:47:56 - train: epoch 0179, iter [00200, 00390], lr: 0.000800, loss: 0.0028
2022-07-17 05:48:05 - train: epoch 0179, iter [00250, 00390], lr: 0.000800, loss: 0.0006
2022-07-17 05:48:14 - train: epoch 0179, iter [00300, 00390], lr: 0.000800, loss: 0.0043
2022-07-17 05:48:23 - train: epoch 0179, iter [00350, 00390], lr: 0.000800, loss: 0.0029
2022-07-17 05:48:30 - train: epoch 179, train_loss: 0.0021
2022-07-17 05:48:36 - eval: epoch: 179, acc1: 76.970%, acc5: 94.030%, test_loss: 1.2044, per_image_load_time: 0.246ms, per_image_inference_time: 0.302ms
2022-07-17 05:48:37 - until epoch: 179, best_acc1: 77.090%
2022-07-17 05:48:37 - epoch 180 lr: 0.000800
2022-07-17 05:48:48 - train: epoch 0180, iter [00050, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 05:48:57 - train: epoch 0180, iter [00100, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 05:49:05 - train: epoch 0180, iter [00150, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 05:49:14 - train: epoch 0180, iter [00200, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 05:49:23 - train: epoch 0180, iter [00250, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 05:49:32 - train: epoch 0180, iter [00300, 00390], lr: 0.000800, loss: 0.0044
2022-07-17 05:49:41 - train: epoch 0180, iter [00350, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 05:49:48 - train: epoch 180, train_loss: 0.0021
2022-07-17 05:49:54 - eval: epoch: 180, acc1: 76.820%, acc5: 94.030%, test_loss: 1.2008, per_image_load_time: 0.265ms, per_image_inference_time: 0.294ms
2022-07-17 05:49:55 - until epoch: 180, best_acc1: 77.090%
2022-07-17 05:49:55 - epoch 181 lr: 0.000800
2022-07-17 05:50:07 - train: epoch 0181, iter [00050, 00390], lr: 0.000800, loss: 0.0114
2022-07-17 05:50:15 - train: epoch 0181, iter [00100, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 05:50:24 - train: epoch 0181, iter [00150, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 05:50:32 - train: epoch 0181, iter [00200, 00390], lr: 0.000800, loss: 0.0006
2022-07-17 05:50:41 - train: epoch 0181, iter [00250, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 05:50:50 - train: epoch 0181, iter [00300, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 05:50:59 - train: epoch 0181, iter [00350, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 05:51:06 - train: epoch 181, train_loss: 0.0020
2022-07-17 05:51:12 - eval: epoch: 181, acc1: 77.030%, acc5: 94.110%, test_loss: 1.1971, per_image_load_time: 0.324ms, per_image_inference_time: 0.289ms
2022-07-17 05:51:13 - until epoch: 181, best_acc1: 77.090%
2022-07-17 05:51:13 - epoch 182 lr: 0.000800
2022-07-17 05:51:25 - train: epoch 0182, iter [00050, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 05:51:34 - train: epoch 0182, iter [00100, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 05:51:43 - train: epoch 0182, iter [00150, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 05:51:51 - train: epoch 0182, iter [00200, 00390], lr: 0.000800, loss: 0.0026
2022-07-17 05:52:00 - train: epoch 0182, iter [00250, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 05:52:09 - train: epoch 0182, iter [00300, 00390], lr: 0.000800, loss: 0.0130
2022-07-17 05:52:18 - train: epoch 0182, iter [00350, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 05:52:25 - train: epoch 182, train_loss: 0.0023
2022-07-17 05:52:31 - eval: epoch: 182, acc1: 77.030%, acc5: 94.040%, test_loss: 1.1981, per_image_load_time: 0.241ms, per_image_inference_time: 0.296ms
2022-07-17 05:52:32 - until epoch: 182, best_acc1: 77.090%
2022-07-17 05:52:32 - epoch 183 lr: 0.000800
2022-07-17 05:52:44 - train: epoch 0183, iter [00050, 00390], lr: 0.000800, loss: 0.0028
2022-07-17 05:52:53 - train: epoch 0183, iter [00100, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 05:53:02 - train: epoch 0183, iter [00150, 00390], lr: 0.000800, loss: 0.0007
2022-07-17 05:53:10 - train: epoch 0183, iter [00200, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 05:53:19 - train: epoch 0183, iter [00250, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 05:53:28 - train: epoch 0183, iter [00300, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 05:53:37 - train: epoch 0183, iter [00350, 00390], lr: 0.000800, loss: 0.0026
2022-07-17 05:53:45 - train: epoch 183, train_loss: 0.0022
2022-07-17 05:53:51 - eval: epoch: 183, acc1: 77.000%, acc5: 93.970%, test_loss: 1.1979, per_image_load_time: 0.317ms, per_image_inference_time: 0.294ms
2022-07-17 05:53:52 - until epoch: 183, best_acc1: 77.090%
2022-07-17 05:53:52 - epoch 184 lr: 0.000800
2022-07-17 05:54:04 - train: epoch 0184, iter [00050, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 05:54:13 - train: epoch 0184, iter [00100, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 05:54:22 - train: epoch 0184, iter [00150, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 05:54:31 - train: epoch 0184, iter [00200, 00390], lr: 0.000800, loss: 0.0010
2022-07-17 05:54:39 - train: epoch 0184, iter [00250, 00390], lr: 0.000800, loss: 0.0057
2022-07-17 05:54:48 - train: epoch 0184, iter [00300, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 05:54:57 - train: epoch 0184, iter [00350, 00390], lr: 0.000800, loss: 0.0029
2022-07-17 05:55:04 - train: epoch 184, train_loss: 0.0022
2022-07-17 05:55:11 - eval: epoch: 184, acc1: 76.920%, acc5: 94.030%, test_loss: 1.1998, per_image_load_time: 0.318ms, per_image_inference_time: 0.297ms
2022-07-17 05:55:11 - until epoch: 184, best_acc1: 77.090%
2022-07-17 05:55:11 - epoch 185 lr: 0.000800
2022-07-17 05:55:24 - train: epoch 0185, iter [00050, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 05:55:33 - train: epoch 0185, iter [00100, 00390], lr: 0.000800, loss: 0.0101
2022-07-17 05:55:41 - train: epoch 0185, iter [00150, 00390], lr: 0.000800, loss: 0.0032
2022-07-17 05:55:50 - train: epoch 0185, iter [00200, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 05:55:59 - train: epoch 0185, iter [00250, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 05:56:08 - train: epoch 0185, iter [00300, 00390], lr: 0.000800, loss: 0.0010
2022-07-17 05:56:17 - train: epoch 0185, iter [00350, 00390], lr: 0.000800, loss: 0.0034
2022-07-17 05:56:25 - train: epoch 185, train_loss: 0.0021
2022-07-17 05:56:31 - eval: epoch: 185, acc1: 76.970%, acc5: 94.090%, test_loss: 1.1939, per_image_load_time: 0.317ms, per_image_inference_time: 0.291ms
2022-07-17 05:56:32 - until epoch: 185, best_acc1: 77.090%
2022-07-17 05:56:32 - epoch 186 lr: 0.000800
2022-07-17 05:56:44 - train: epoch 0186, iter [00050, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 05:56:53 - train: epoch 0186, iter [00100, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 05:57:02 - train: epoch 0186, iter [00150, 00390], lr: 0.000800, loss: 0.0081
2022-07-17 05:57:10 - train: epoch 0186, iter [00200, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 05:57:19 - train: epoch 0186, iter [00250, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 05:57:28 - train: epoch 0186, iter [00300, 00390], lr: 0.000800, loss: 0.0031
2022-07-17 05:57:37 - train: epoch 0186, iter [00350, 00390], lr: 0.000800, loss: 0.0054
2022-07-17 05:57:44 - train: epoch 186, train_loss: 0.0021
2022-07-17 05:57:50 - eval: epoch: 186, acc1: 77.080%, acc5: 94.080%, test_loss: 1.1938, per_image_load_time: 0.288ms, per_image_inference_time: 0.288ms
2022-07-17 05:57:51 - until epoch: 186, best_acc1: 77.090%
2022-07-17 05:57:51 - epoch 187 lr: 0.000800
2022-07-17 05:58:02 - train: epoch 0187, iter [00050, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 05:58:11 - train: epoch 0187, iter [00100, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 05:58:20 - train: epoch 0187, iter [00150, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 05:58:28 - train: epoch 0187, iter [00200, 00390], lr: 0.000800, loss: 0.0015
2022-07-17 05:58:37 - train: epoch 0187, iter [00250, 00390], lr: 0.000800, loss: 0.0006
2022-07-17 05:58:46 - train: epoch 0187, iter [00300, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 05:58:55 - train: epoch 0187, iter [00350, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 05:59:02 - train: epoch 187, train_loss: 0.0019
2022-07-17 05:59:08 - eval: epoch: 187, acc1: 77.060%, acc5: 94.170%, test_loss: 1.1959, per_image_load_time: 0.243ms, per_image_inference_time: 0.295ms
2022-07-17 05:59:08 - until epoch: 187, best_acc1: 77.090%
2022-07-17 05:59:08 - epoch 188 lr: 0.000800
2022-07-17 05:59:20 - train: epoch 0188, iter [00050, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 05:59:29 - train: epoch 0188, iter [00100, 00390], lr: 0.000800, loss: 0.0010
2022-07-17 05:59:38 - train: epoch 0188, iter [00150, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 05:59:47 - train: epoch 0188, iter [00200, 00390], lr: 0.000800, loss: 0.0009
2022-07-17 05:59:55 - train: epoch 0188, iter [00250, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 06:00:04 - train: epoch 0188, iter [00300, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 06:00:13 - train: epoch 0188, iter [00350, 00390], lr: 0.000800, loss: 0.0006
2022-07-17 06:00:20 - train: epoch 188, train_loss: 0.0020
2022-07-17 06:00:27 - eval: epoch: 188, acc1: 76.940%, acc5: 94.190%, test_loss: 1.1958, per_image_load_time: 0.308ms, per_image_inference_time: 0.293ms
2022-07-17 06:00:27 - until epoch: 188, best_acc1: 77.090%
2022-07-17 06:00:27 - epoch 189 lr: 0.000800
2022-07-17 06:00:39 - train: epoch 0189, iter [00050, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 06:00:48 - train: epoch 0189, iter [00100, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 06:00:57 - train: epoch 0189, iter [00150, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 06:01:06 - train: epoch 0189, iter [00200, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 06:01:14 - train: epoch 0189, iter [00250, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 06:01:23 - train: epoch 0189, iter [00300, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 06:01:32 - train: epoch 0189, iter [00350, 00390], lr: 0.000800, loss: 0.0016
2022-07-17 06:01:39 - train: epoch 189, train_loss: 0.0020
2022-07-17 06:01:46 - eval: epoch: 189, acc1: 77.010%, acc5: 94.190%, test_loss: 1.1928, per_image_load_time: 0.329ms, per_image_inference_time: 0.294ms
2022-07-17 06:01:47 - until epoch: 189, best_acc1: 77.090%
2022-07-17 06:01:47 - epoch 190 lr: 0.000800
2022-07-17 06:01:58 - train: epoch 0190, iter [00050, 00390], lr: 0.000800, loss: 0.0010
2022-07-17 06:02:07 - train: epoch 0190, iter [00100, 00390], lr: 0.000800, loss: 0.0015
2022-07-17 06:02:16 - train: epoch 0190, iter [00150, 00390], lr: 0.000800, loss: 0.0036
2022-07-17 06:02:25 - train: epoch 0190, iter [00200, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 06:02:33 - train: epoch 0190, iter [00250, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 06:02:42 - train: epoch 0190, iter [00300, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 06:02:51 - train: epoch 0190, iter [00350, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 06:02:58 - train: epoch 190, train_loss: 0.0021
2022-07-17 06:03:04 - eval: epoch: 190, acc1: 76.970%, acc5: 94.140%, test_loss: 1.1928, per_image_load_time: 0.299ms, per_image_inference_time: 0.285ms
2022-07-17 06:03:05 - until epoch: 190, best_acc1: 77.090%
2022-07-17 06:03:05 - epoch 191 lr: 0.000800
2022-07-17 06:03:17 - train: epoch 0191, iter [00050, 00390], lr: 0.000800, loss: 0.0016
2022-07-17 06:03:26 - train: epoch 0191, iter [00100, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 06:03:35 - train: epoch 0191, iter [00150, 00390], lr: 0.000800, loss: 0.0009
2022-07-17 06:03:44 - train: epoch 0191, iter [00200, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 06:03:53 - train: epoch 0191, iter [00250, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 06:04:01 - train: epoch 0191, iter [00300, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 06:04:10 - train: epoch 0191, iter [00350, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 06:04:18 - train: epoch 191, train_loss: 0.0021
2022-07-17 06:04:24 - eval: epoch: 191, acc1: 77.060%, acc5: 94.150%, test_loss: 1.1946, per_image_load_time: 0.253ms, per_image_inference_time: 0.288ms
2022-07-17 06:04:24 - until epoch: 191, best_acc1: 77.090%
2022-07-17 06:04:24 - epoch 192 lr: 0.000800
2022-07-17 06:04:36 - train: epoch 0192, iter [00050, 00390], lr: 0.000800, loss: 0.0009
2022-07-17 06:04:44 - train: epoch 0192, iter [00100, 00390], lr: 0.000800, loss: 0.0009
2022-07-17 06:04:53 - train: epoch 0192, iter [00150, 00390], lr: 0.000800, loss: 0.0015
2022-07-17 06:05:02 - train: epoch 0192, iter [00200, 00390], lr: 0.000800, loss: 0.0010
2022-07-17 06:05:11 - train: epoch 0192, iter [00250, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 06:05:20 - train: epoch 0192, iter [00300, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 06:05:29 - train: epoch 0192, iter [00350, 00390], lr: 0.000800, loss: 0.0007
2022-07-17 06:05:36 - train: epoch 192, train_loss: 0.0020
2022-07-17 06:05:42 - eval: epoch: 192, acc1: 76.960%, acc5: 94.170%, test_loss: 1.1909, per_image_load_time: 0.251ms, per_image_inference_time: 0.292ms
2022-07-17 06:05:42 - until epoch: 192, best_acc1: 77.090%
2022-07-17 06:05:42 - epoch 193 lr: 0.000800
2022-07-17 06:05:54 - train: epoch 0193, iter [00050, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 06:06:03 - train: epoch 0193, iter [00100, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 06:06:12 - train: epoch 0193, iter [00150, 00390], lr: 0.000800, loss: 0.0015
2022-07-17 06:06:21 - train: epoch 0193, iter [00200, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 06:06:30 - train: epoch 0193, iter [00250, 00390], lr: 0.000800, loss: 0.0016
2022-07-17 06:06:39 - train: epoch 0193, iter [00300, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 06:06:47 - train: epoch 0193, iter [00350, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 06:06:55 - train: epoch 193, train_loss: 0.0020
2022-07-17 06:07:00 - eval: epoch: 193, acc1: 77.160%, acc5: 94.090%, test_loss: 1.1864, per_image_load_time: 0.241ms, per_image_inference_time: 0.291ms
2022-07-17 06:07:01 - until epoch: 193, best_acc1: 77.160%
2022-07-17 06:07:01 - epoch 194 lr: 0.000800
2022-07-17 06:07:15 - train: epoch 0194, iter [00050, 00390], lr: 0.000800, loss: 0.0005
2022-07-17 06:07:24 - train: epoch 0194, iter [00100, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 06:07:33 - train: epoch 0194, iter [00150, 00390], lr: 0.000800, loss: 0.0097
2022-07-17 06:07:42 - train: epoch 0194, iter [00200, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 06:07:51 - train: epoch 0194, iter [00250, 00390], lr: 0.000800, loss: 0.0015
2022-07-17 06:08:00 - train: epoch 0194, iter [00300, 00390], lr: 0.000800, loss: 0.0065
2022-07-17 06:08:09 - train: epoch 0194, iter [00350, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 06:08:16 - train: epoch 194, train_loss: 0.0019
2022-07-17 06:08:23 - eval: epoch: 194, acc1: 76.960%, acc5: 94.170%, test_loss: 1.1924, per_image_load_time: 0.374ms, per_image_inference_time: 0.295ms
2022-07-17 06:08:24 - until epoch: 194, best_acc1: 77.160%
2022-07-17 06:08:24 - epoch 195 lr: 0.000800
2022-07-17 06:08:36 - train: epoch 0195, iter [00050, 00390], lr: 0.000800, loss: 0.0010
2022-07-17 06:08:45 - train: epoch 0195, iter [00100, 00390], lr: 0.000800, loss: 0.0009
2022-07-17 06:08:54 - train: epoch 0195, iter [00150, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 06:09:02 - train: epoch 0195, iter [00200, 00390], lr: 0.000800, loss: 0.0010
2022-07-17 06:09:11 - train: epoch 0195, iter [00250, 00390], lr: 0.000800, loss: 0.0026
2022-07-17 06:09:20 - train: epoch 0195, iter [00300, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 06:09:29 - train: epoch 0195, iter [00350, 00390], lr: 0.000800, loss: 0.0010
2022-07-17 06:09:36 - train: epoch 195, train_loss: 0.0020
2022-07-17 06:09:42 - eval: epoch: 195, acc1: 77.000%, acc5: 94.070%, test_loss: 1.1860, per_image_load_time: 0.309ms, per_image_inference_time: 0.292ms
2022-07-17 06:09:43 - until epoch: 195, best_acc1: 77.160%
2022-07-17 06:09:43 - epoch 196 lr: 0.000800
2022-07-17 06:09:55 - train: epoch 0196, iter [00050, 00390], lr: 0.000800, loss: 0.0022
2022-07-17 06:10:04 - train: epoch 0196, iter [00100, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 06:10:13 - train: epoch 0196, iter [00150, 00390], lr: 0.000800, loss: 0.0123
2022-07-17 06:10:21 - train: epoch 0196, iter [00200, 00390], lr: 0.000800, loss: 0.0033
2022-07-17 06:10:30 - train: epoch 0196, iter [00250, 00390], lr: 0.000800, loss: 0.0028
2022-07-17 06:10:39 - train: epoch 0196, iter [00300, 00390], lr: 0.000800, loss: 0.0015
2022-07-17 06:10:48 - train: epoch 0196, iter [00350, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 06:10:55 - train: epoch 196, train_loss: 0.0022
2022-07-17 06:11:01 - eval: epoch: 196, acc1: 77.040%, acc5: 94.110%, test_loss: 1.1856, per_image_load_time: 0.263ms, per_image_inference_time: 0.295ms
2022-07-17 06:11:02 - until epoch: 196, best_acc1: 77.160%
2022-07-17 06:11:02 - epoch 197 lr: 0.000800
2022-07-17 06:11:13 - train: epoch 0197, iter [00050, 00390], lr: 0.000800, loss: 0.0015
2022-07-17 06:11:22 - train: epoch 0197, iter [00100, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 06:11:31 - train: epoch 0197, iter [00150, 00390], lr: 0.000800, loss: 0.0042
2022-07-17 06:11:39 - train: epoch 0197, iter [00200, 00390], lr: 0.000800, loss: 0.0007
2022-07-17 06:11:48 - train: epoch 0197, iter [00250, 00390], lr: 0.000800, loss: 0.0005
2022-07-17 06:11:57 - train: epoch 0197, iter [00300, 00390], lr: 0.000800, loss: 0.0009
2022-07-17 06:12:06 - train: epoch 0197, iter [00350, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 06:12:13 - train: epoch 197, train_loss: 0.0021
2022-07-17 06:12:19 - eval: epoch: 197, acc1: 77.100%, acc5: 94.190%, test_loss: 1.1886, per_image_load_time: 0.239ms, per_image_inference_time: 0.293ms
2022-07-17 06:12:20 - until epoch: 197, best_acc1: 77.160%
2022-07-17 06:12:20 - epoch 198 lr: 0.000800
2022-07-17 06:12:31 - train: epoch 0198, iter [00050, 00390], lr: 0.000800, loss: 0.0015
2022-07-17 06:12:40 - train: epoch 0198, iter [00100, 00390], lr: 0.000800, loss: 0.0059
2022-07-17 06:12:49 - train: epoch 0198, iter [00150, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 06:12:58 - train: epoch 0198, iter [00200, 00390], lr: 0.000800, loss: 0.0081
2022-07-17 06:13:07 - train: epoch 0198, iter [00250, 00390], lr: 0.000800, loss: 0.0034
2022-07-17 06:13:16 - train: epoch 0198, iter [00300, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 06:13:25 - train: epoch 0198, iter [00350, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 06:13:32 - train: epoch 198, train_loss: 0.0019
2022-07-17 06:13:39 - eval: epoch: 198, acc1: 76.940%, acc5: 94.100%, test_loss: 1.1933, per_image_load_time: 0.413ms, per_image_inference_time: 0.290ms
2022-07-17 06:13:40 - until epoch: 198, best_acc1: 77.160%
2022-07-17 06:13:40 - epoch 199 lr: 0.000800
2022-07-17 06:13:52 - train: epoch 0199, iter [00050, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 06:14:01 - train: epoch 0199, iter [00100, 00390], lr: 0.000800, loss: 0.0009
2022-07-17 06:14:10 - train: epoch 0199, iter [00150, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 06:14:19 - train: epoch 0199, iter [00200, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 06:14:28 - train: epoch 0199, iter [00250, 00390], lr: 0.000800, loss: 0.0009
2022-07-17 06:14:37 - train: epoch 0199, iter [00300, 00390], lr: 0.000800, loss: 0.0137
2022-07-17 06:14:45 - train: epoch 0199, iter [00350, 00390], lr: 0.000800, loss: 0.0026
2022-07-17 06:14:53 - train: epoch 199, train_loss: 0.0021
2022-07-17 06:14:58 - eval: epoch: 199, acc1: 77.070%, acc5: 94.170%, test_loss: 1.1894, per_image_load_time: 0.244ms, per_image_inference_time: 0.293ms
2022-07-17 06:14:59 - until epoch: 199, best_acc1: 77.160%
2022-07-17 06:14:59 - epoch 200 lr: 0.000800
2022-07-17 06:15:11 - train: epoch 0200, iter [00050, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 06:15:20 - train: epoch 0200, iter [00100, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 06:15:29 - train: epoch 0200, iter [00150, 00390], lr: 0.000800, loss: 0.0035
2022-07-17 06:15:38 - train: epoch 0200, iter [00200, 00390], lr: 0.000800, loss: 0.0013
2022-07-17 06:15:47 - train: epoch 0200, iter [00250, 00390], lr: 0.000800, loss: 0.0015
2022-07-17 06:15:56 - train: epoch 0200, iter [00300, 00390], lr: 0.000800, loss: 0.0008
2022-07-17 06:16:04 - train: epoch 0200, iter [00350, 00390], lr: 0.000800, loss: 0.0011
2022-07-17 06:16:12 - train: epoch 200, train_loss: 0.0020
2022-07-17 06:16:18 - eval: epoch: 200, acc1: 76.870%, acc5: 94.220%, test_loss: 1.1887, per_image_load_time: 0.310ms, per_image_inference_time: 0.294ms
2022-07-17 06:16:19 - until epoch: 200, best_acc1: 77.160%
2022-07-17 06:16:19 - train done. model: resnet152cifar, train time: 5.287 hours, best_acc1: 77.160%
