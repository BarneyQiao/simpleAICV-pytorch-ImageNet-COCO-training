2022-03-20 17:39:35 - network: resnet152cifar
2022-03-20 17:39:35 - num_classes: 100
2022-03-20 17:39:35 - input_image_size: 32
2022-03-20 17:39:35 - trained_model_path: 
2022-03-20 17:39:35 - criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-03-20 17:39:35 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f54300598e0>
2022-03-20 17:39:35 - val_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f5430059be0>
2022-03-20 17:39:35 - collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f5430059cd0>
2022-03-20 17:39:35 - seed: 0
2022-03-20 17:39:35 - batch_size: 128
2022-03-20 17:39:35 - num_workers: 16
2022-03-20 17:39:35 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005})
2022-03-20 17:39:35 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2022-03-20 17:39:35 - epochs: 200
2022-03-20 17:39:35 - print_interval: 50
2022-03-20 17:39:35 - distributed: True
2022-03-20 17:39:35 - sync_bn: False
2022-03-20 17:39:35 - apex: True
2022-03-20 17:39:35 - gpus_type: NVIDIA GeForce RTX 3090
2022-03-20 17:39:35 - gpus_num: 1
2022-03-20 17:39:35 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f541b9b0eb0>
2022-03-20 17:39:35 - --------------------parameters--------------------
2022-03-20 17:39:35 - name: conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer1.0.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer1.0.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer1.0.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer1.0.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer1.0.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer1.0.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer1.0.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer1.0.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer1.0.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer1.0.downsample_conv.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer1.0.downsample_conv.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer1.0.downsample_conv.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer1.1.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer1.1.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer1.1.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer1.1.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer1.1.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer1.1.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer1.1.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer1.1.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer1.1.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer1.2.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer1.2.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer1.2.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer1.2.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer1.2.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer1.2.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer1.2.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer1.2.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer1.2.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.0.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.0.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.0.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.0.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.0.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.0.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.0.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.0.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.0.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.1.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.1.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.1.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.1.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.1.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.1.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.1.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.1.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.1.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.2.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.2.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.2.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.2.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.2.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.2.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.2.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.2.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.2.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.3.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.3.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.3.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.3.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.3.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.3.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.3.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.3.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.3.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.4.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.4.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.4.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.4.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.4.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.4.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.4.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.4.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.4.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.5.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.5.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.5.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.5.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.5.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.5.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.5.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.5.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.5.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.6.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.6.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.6.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.6.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.6.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.6.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.6.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.6.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.6.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.7.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.7.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.7.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.7.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.7.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.7.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer2.7.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer2.7.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer2.7.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.0.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.0.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.0.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.0.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.0.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.0.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.0.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.0.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.0.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.1.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.1.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.1.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.1.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.1.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.1.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.1.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.1.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.1.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.2.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.2.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.2.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.2.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.2.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.2.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.2.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.2.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.2.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.3.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.3.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.3.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.3.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.3.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.3.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.3.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.3.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.3.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.4.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.4.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.4.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.4.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.4.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.4.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.4.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.4.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.4.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.5.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.5.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.5.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.5.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.5.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.5.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.5.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.5.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.5.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.6.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.6.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.6.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.6.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.6.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.6.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.6.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.6.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.6.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.7.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.7.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.7.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.7.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.7.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.7.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.7.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.7.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.7.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.8.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.8.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.8.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.8.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.8.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.8.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.8.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.8.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.8.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.9.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.9.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.9.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.9.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.9.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.9.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.9.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.9.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.9.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.10.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.10.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.10.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.10.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.10.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.10.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.10.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.10.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.10.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.11.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.11.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.11.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.11.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.11.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.11.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.11.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.11.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.11.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.12.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.12.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.12.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.12.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.12.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.12.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.12.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.12.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.12.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.13.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.13.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.13.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.13.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.13.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.13.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.13.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.13.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.13.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.14.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.14.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.14.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.14.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.14.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.14.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.14.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.14.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.14.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.15.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.15.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.15.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.15.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.15.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.15.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.15.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.15.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.15.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.16.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.16.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.16.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.16.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.16.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.16.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.16.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.16.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.16.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.17.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.17.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.17.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.17.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.17.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.17.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.17.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.17.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.17.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.18.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.18.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.18.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.18.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.18.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.18.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.18.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.18.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.18.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.19.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.19.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.19.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.19.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.19.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.19.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.19.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.19.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.19.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.20.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.20.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.20.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.20.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.20.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.20.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.20.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.20.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.20.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.21.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.21.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.21.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.21.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.21.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.21.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.21.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.21.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.21.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.22.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.22.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.22.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.22.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.22.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.22.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.22.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.22.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.22.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.23.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.23.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.23.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.23.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.23.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.23.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.23.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.23.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.23.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.24.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.24.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.24.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.24.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.24.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.24.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.24.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.24.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.24.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.25.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.25.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.25.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.25.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.25.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.25.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.25.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.25.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.25.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.26.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.26.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.26.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.26.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.26.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.26.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.26.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.26.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.26.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.27.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.27.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.27.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.27.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.27.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.27.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.27.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.27.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.27.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.28.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.28.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.28.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.28.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.28.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.28.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.28.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.28.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.28.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.29.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.29.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.29.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.29.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.29.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.29.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.29.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.29.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.29.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.30.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.30.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.30.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.30.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.30.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.30.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.30.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.30.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.30.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.31.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.31.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.31.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.31.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.31.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.31.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.31.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.31.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.31.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.32.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.32.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.32.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.32.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.32.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.32.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.32.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.32.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.32.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.33.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.33.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.33.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.33.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.33.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.33.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.33.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.33.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.33.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.34.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.34.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.34.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.34.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.34.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.34.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.34.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.34.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.34.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.35.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.35.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.35.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.35.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.35.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.35.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer3.35.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer3.35.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer3.35.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer4.0.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer4.0.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer4.0.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer4.0.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer4.0.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer4.0.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer4.0.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer4.0.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer4.0.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer4.1.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer4.1.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer4.1.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer4.1.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer4.1.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer4.1.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer4.1.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer4.1.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer4.1.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer4.2.conv1.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer4.2.conv1.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer4.2.conv1.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer4.2.conv2.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer4.2.conv2.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer4.2.conv2.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: layer4.2.conv3.layer.0.weight, grad: True
2022-03-20 17:39:35 - name: layer4.2.conv3.layer.1.weight, grad: True
2022-03-20 17:39:35 - name: layer4.2.conv3.layer.1.bias, grad: True
2022-03-20 17:39:35 - name: fc.weight, grad: True
2022-03-20 17:39:35 - name: fc.bias, grad: True
2022-03-20 17:39:35 - --------------------buffers--------------------
2022-03-20 17:39:35 - name: conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer1.0.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer1.0.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer1.0.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer1.0.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer1.0.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer1.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer1.0.downsample_conv.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer1.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer1.1.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer1.1.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer1.1.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer1.1.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer1.1.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer1.2.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer1.2.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer1.2.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer1.2.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer1.2.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer1.2.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer1.2.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.0.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.0.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.0.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.0.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.0.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.1.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.1.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.1.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.1.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.1.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.2.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.2.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.2.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.2.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.2.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.2.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.2.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.3.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.3.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.3.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.3.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.3.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.3.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.3.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.4.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.4.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.4.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.4.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.4.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.4.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.4.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.4.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.4.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.5.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.5.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.5.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.5.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.5.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.5.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.5.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.5.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.5.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.6.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.6.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.6.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.6.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.6.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.6.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.6.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.6.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.6.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.7.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.7.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.7.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.7.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.7.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.7.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer2.7.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer2.7.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer2.7.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.0.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.0.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.0.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.0.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.0.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.1.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.1.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.1.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.1.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.1.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.2.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.2.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.2.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.2.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.2.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.2.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.2.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.3.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.3.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.3.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.3.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.3.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.3.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.3.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.4.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.4.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.4.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.4.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.4.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.4.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.4.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.5.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.5.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.5.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.5.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.5.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.5.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.5.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.6.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.6.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.6.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.6.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.6.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.6.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.6.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.6.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.6.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.7.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.7.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.7.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.7.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.7.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.7.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.7.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.7.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.7.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.8.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.8.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.8.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.8.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.8.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.8.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.8.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.8.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.8.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.9.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.9.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.9.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.9.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.9.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.9.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.9.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.9.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.9.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.10.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.10.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.10.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.10.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.10.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.10.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.10.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.10.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.10.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.11.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.11.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.11.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.11.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.11.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.11.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.11.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.11.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.11.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.12.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.12.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.12.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.12.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.12.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.12.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.12.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.12.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.12.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.13.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.13.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.13.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.13.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.13.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.13.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.13.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.13.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.13.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.14.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.14.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.14.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.14.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.14.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.14.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.14.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.14.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.14.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.15.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.15.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.15.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.15.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.15.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.15.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.15.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.15.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.15.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.16.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.16.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.16.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.16.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.16.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.16.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.16.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.16.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.16.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.17.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.17.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.17.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.17.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.17.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.17.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.17.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.17.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.17.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.18.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.18.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.18.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.18.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.18.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.18.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.18.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.18.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.18.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.19.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.19.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.19.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.19.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.19.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.19.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.19.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.19.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.19.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.20.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.20.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.20.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.20.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.20.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.20.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.20.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.20.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.20.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.21.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.21.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.21.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.21.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.21.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.21.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.21.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.21.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.21.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.22.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.22.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.22.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.22.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.22.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.22.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.22.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.22.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.22.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.23.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.23.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.23.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.23.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.23.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.23.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.23.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.23.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.23.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.24.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.24.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.24.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.24.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.24.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.24.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.24.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.24.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.24.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.25.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.25.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.25.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.25.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.25.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.25.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.25.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.25.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.25.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.26.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.26.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.26.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.26.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.26.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.26.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.26.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.26.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.26.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.27.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.27.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.27.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.27.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.27.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.27.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.27.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.27.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.27.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.28.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.28.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.28.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.28.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.28.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.28.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.28.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.28.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.28.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.29.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.29.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.29.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.29.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.29.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.29.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.29.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.29.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.29.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.30.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.30.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.30.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.30.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.30.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.30.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.30.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.30.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.30.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.31.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.31.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.31.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.31.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.31.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.31.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.31.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.31.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.31.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.32.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.32.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.32.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.32.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.32.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.32.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.32.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.32.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.32.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.33.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.33.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.33.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.33.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.33.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.33.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.33.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.33.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.33.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.34.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.34.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.34.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.34.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.34.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.34.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.34.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.34.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.34.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.35.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.35.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.35.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.35.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.35.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.35.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer3.35.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer3.35.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer3.35.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer4.0.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer4.0.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer4.0.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer4.0.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer4.0.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer4.1.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer4.1.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer4.1.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer4.1.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer4.1.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer4.2.conv1.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer4.2.conv1.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer4.2.conv2.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer4.2.conv2.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - name: layer4.2.conv3.layer.1.running_mean, grad: False
2022-03-20 17:39:35 - name: layer4.2.conv3.layer.1.running_var, grad: False
2022-03-20 17:39:35 - name: layer4.2.conv3.layer.1.num_batches_tracked, grad: False
2022-03-20 17:39:35 - epoch 001 lr: 0.1
2022-03-20 17:39:49 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 5.8232
2022-03-20 17:40:01 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.5969
2022-03-20 17:40:12 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 4.5691
2022-03-20 17:40:23 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 4.5613
2022-03-20 17:40:35 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 4.5497
2022-03-20 17:40:46 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 4.5129
2022-03-20 17:40:57 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 4.4981
2022-03-20 17:41:06 - train: epoch 001, train_loss: 4.7659
2022-03-20 17:41:14 - eval: epoch: 001, acc1: 2.280%, acc5: 10.190%, test_loss: 4.4544, per_image_load_time: 0.298ms, per_image_inference_time: 0.450ms
2022-03-20 17:41:15 - until epoch: 001, best_acc1: 2.280%
2022-03-20 17:41:15 - epoch 002 lr: 0.1
2022-03-20 17:41:30 - train: epoch 0002, iter [00050, 00390], lr: 0.100000, loss: 4.4113
2022-03-20 17:41:41 - train: epoch 0002, iter [00100, 00390], lr: 0.100000, loss: 4.3897
2022-03-20 17:41:52 - train: epoch 0002, iter [00150, 00390], lr: 0.100000, loss: 4.2119
2022-03-20 17:42:03 - train: epoch 0002, iter [00200, 00390], lr: 0.100000, loss: 4.2770
2022-03-20 17:42:15 - train: epoch 0002, iter [00250, 00390], lr: 0.100000, loss: 4.1336
2022-03-20 17:42:26 - train: epoch 0002, iter [00300, 00390], lr: 0.100000, loss: 4.2152
2022-03-20 17:42:37 - train: epoch 0002, iter [00350, 00390], lr: 0.100000, loss: 4.0807
2022-03-20 17:42:47 - train: epoch 002, train_loss: 4.2705
2022-03-20 17:42:55 - eval: epoch: 002, acc1: 5.360%, acc5: 21.120%, test_loss: 4.1098, per_image_load_time: 0.299ms, per_image_inference_time: 0.434ms
2022-03-20 17:42:57 - until epoch: 002, best_acc1: 5.360%
2022-03-20 17:42:57 - epoch 003 lr: 0.1
2022-03-20 17:43:11 - train: epoch 0003, iter [00050, 00390], lr: 0.100000, loss: 4.0866
2022-03-20 17:43:23 - train: epoch 0003, iter [00100, 00390], lr: 0.100000, loss: 4.0372
2022-03-20 17:43:34 - train: epoch 0003, iter [00150, 00390], lr: 0.100000, loss: 4.0930
2022-03-20 17:43:46 - train: epoch 0003, iter [00200, 00390], lr: 0.100000, loss: 3.9324
2022-03-20 17:43:57 - train: epoch 0003, iter [00250, 00390], lr: 0.100000, loss: 4.1629
2022-03-20 17:44:09 - train: epoch 0003, iter [00300, 00390], lr: 0.100000, loss: 4.0401
2022-03-20 17:44:21 - train: epoch 0003, iter [00350, 00390], lr: 0.100000, loss: 4.0284
2022-03-20 17:44:31 - train: epoch 003, train_loss: 3.9955
2022-03-20 17:44:39 - eval: epoch: 003, acc1: 8.420%, acc5: 29.180%, test_loss: 3.8989, per_image_load_time: 0.305ms, per_image_inference_time: 0.420ms
2022-03-20 17:44:41 - until epoch: 003, best_acc1: 8.420%
2022-03-20 17:44:41 - epoch 004 lr: 0.1
2022-03-20 17:44:56 - train: epoch 0004, iter [00050, 00390], lr: 0.100000, loss: 3.8765
2022-03-20 17:45:07 - train: epoch 0004, iter [00100, 00390], lr: 0.100000, loss: 3.8680
2022-03-20 17:45:19 - train: epoch 0004, iter [00150, 00390], lr: 0.100000, loss: 3.8330
2022-03-20 17:45:30 - train: epoch 0004, iter [00200, 00390], lr: 0.100000, loss: 3.7414
2022-03-20 17:45:42 - train: epoch 0004, iter [00250, 00390], lr: 0.100000, loss: 3.6002
2022-03-20 17:45:53 - train: epoch 0004, iter [00300, 00390], lr: 0.100000, loss: 3.7287
2022-03-20 17:46:04 - train: epoch 0004, iter [00350, 00390], lr: 0.100000, loss: 3.4130
2022-03-20 17:46:14 - train: epoch 004, train_loss: 3.7208
2022-03-20 17:46:21 - eval: epoch: 004, acc1: 13.150%, acc5: 38.410%, test_loss: 3.6377, per_image_load_time: 0.296ms, per_image_inference_time: 0.403ms
2022-03-20 17:46:24 - until epoch: 004, best_acc1: 13.150%
2022-03-20 17:46:24 - epoch 005 lr: 0.1
2022-03-20 17:46:38 - train: epoch 0005, iter [00050, 00390], lr: 0.100000, loss: 3.5873
2022-03-20 17:46:50 - train: epoch 0005, iter [00100, 00390], lr: 0.100000, loss: 3.2375
2022-03-20 17:47:01 - train: epoch 0005, iter [00150, 00390], lr: 0.100000, loss: 3.3565
2022-03-20 17:47:13 - train: epoch 0005, iter [00200, 00390], lr: 0.100000, loss: 3.3969
2022-03-20 17:47:24 - train: epoch 0005, iter [00250, 00390], lr: 0.100000, loss: 3.2833
2022-03-20 17:47:35 - train: epoch 0005, iter [00300, 00390], lr: 0.100000, loss: 3.2737
2022-03-20 17:47:47 - train: epoch 0005, iter [00350, 00390], lr: 0.100000, loss: 3.1890
2022-03-20 17:47:56 - train: epoch 005, train_loss: 3.4172
2022-03-20 17:48:03 - eval: epoch: 005, acc1: 18.920%, acc5: 47.710%, test_loss: 3.3037, per_image_load_time: 0.304ms, per_image_inference_time: 0.421ms
2022-03-20 17:48:06 - until epoch: 005, best_acc1: 18.920%
2022-03-20 17:48:06 - epoch 006 lr: 0.1
2022-03-20 17:48:20 - train: epoch 0006, iter [00050, 00390], lr: 0.100000, loss: 3.3741
2022-03-20 17:48:32 - train: epoch 0006, iter [00100, 00390], lr: 0.100000, loss: 3.0911
2022-03-20 17:48:44 - train: epoch 0006, iter [00150, 00390], lr: 0.100000, loss: 3.1178
2022-03-20 17:48:55 - train: epoch 0006, iter [00200, 00390], lr: 0.100000, loss: 2.8803
2022-03-20 17:49:07 - train: epoch 0006, iter [00250, 00390], lr: 0.100000, loss: 3.1328
2022-03-20 17:49:18 - train: epoch 0006, iter [00300, 00390], lr: 0.100000, loss: 2.9806
2022-03-20 17:49:29 - train: epoch 0006, iter [00350, 00390], lr: 0.100000, loss: 2.9964
2022-03-20 17:49:39 - train: epoch 006, train_loss: 3.1731
2022-03-20 17:49:46 - eval: epoch: 006, acc1: 24.680%, acc5: 54.240%, test_loss: 3.0432, per_image_load_time: 0.293ms, per_image_inference_time: 0.409ms
2022-03-20 17:49:48 - until epoch: 006, best_acc1: 24.680%
2022-03-20 17:49:48 - epoch 007 lr: 0.1
2022-03-20 17:50:03 - train: epoch 0007, iter [00050, 00390], lr: 0.100000, loss: 3.0865
2022-03-20 17:50:14 - train: epoch 0007, iter [00100, 00390], lr: 0.100000, loss: 3.0011
2022-03-20 17:50:25 - train: epoch 0007, iter [00150, 00390], lr: 0.100000, loss: 3.0345
2022-03-20 17:50:36 - train: epoch 0007, iter [00200, 00390], lr: 0.100000, loss: 2.7873
2022-03-20 17:50:48 - train: epoch 0007, iter [00250, 00390], lr: 0.100000, loss: 2.9391
2022-03-20 17:50:59 - train: epoch 0007, iter [00300, 00390], lr: 0.100000, loss: 2.5106
2022-03-20 17:51:10 - train: epoch 0007, iter [00350, 00390], lr: 0.100000, loss: 2.8539
2022-03-20 17:51:20 - train: epoch 007, train_loss: 2.9508
2022-03-20 17:51:28 - eval: epoch: 007, acc1: 29.050%, acc5: 59.620%, test_loss: 2.8089, per_image_load_time: 0.299ms, per_image_inference_time: 0.413ms
2022-03-20 17:51:30 - until epoch: 007, best_acc1: 29.050%
2022-03-20 17:51:30 - epoch 008 lr: 0.1
2022-03-20 17:51:45 - train: epoch 0008, iter [00050, 00390], lr: 0.100000, loss: 2.9995
2022-03-20 17:51:56 - train: epoch 0008, iter [00100, 00390], lr: 0.100000, loss: 2.7481
2022-03-20 17:52:08 - train: epoch 0008, iter [00150, 00390], lr: 0.100000, loss: 2.7049
2022-03-20 17:52:19 - train: epoch 0008, iter [00200, 00390], lr: 0.100000, loss: 2.5635
2022-03-20 17:52:30 - train: epoch 0008, iter [00250, 00390], lr: 0.100000, loss: 2.4953
2022-03-20 17:52:41 - train: epoch 0008, iter [00300, 00390], lr: 0.100000, loss: 2.6762
2022-03-20 17:52:53 - train: epoch 0008, iter [00350, 00390], lr: 0.100000, loss: 2.6842
2022-03-20 17:53:02 - train: epoch 008, train_loss: 2.7351
2022-03-20 17:53:10 - eval: epoch: 008, acc1: 31.840%, acc5: 63.110%, test_loss: 2.7041, per_image_load_time: 0.288ms, per_image_inference_time: 0.422ms
2022-03-20 17:53:12 - until epoch: 008, best_acc1: 31.840%
2022-03-20 17:53:12 - epoch 009 lr: 0.1
2022-03-20 17:53:27 - train: epoch 0009, iter [00050, 00390], lr: 0.100000, loss: 2.4766
2022-03-20 17:53:38 - train: epoch 0009, iter [00100, 00390], lr: 0.100000, loss: 2.5978
2022-03-20 17:53:49 - train: epoch 0009, iter [00150, 00390], lr: 0.100000, loss: 2.3711
2022-03-20 17:54:01 - train: epoch 0009, iter [00200, 00390], lr: 0.100000, loss: 2.5477
2022-03-20 17:54:12 - train: epoch 0009, iter [00250, 00390], lr: 0.100000, loss: 2.5859
2022-03-20 17:54:23 - train: epoch 0009, iter [00300, 00390], lr: 0.100000, loss: 2.4082
2022-03-20 17:54:35 - train: epoch 0009, iter [00350, 00390], lr: 0.100000, loss: 2.7061
2022-03-20 17:54:44 - train: epoch 009, train_loss: 2.5472
2022-03-20 17:54:52 - eval: epoch: 009, acc1: 34.300%, acc5: 67.060%, test_loss: 2.6475, per_image_load_time: 0.310ms, per_image_inference_time: 0.408ms
2022-03-20 17:54:54 - until epoch: 009, best_acc1: 34.300%
2022-03-20 17:54:54 - epoch 010 lr: 0.1
2022-03-20 17:55:09 - train: epoch 0010, iter [00050, 00390], lr: 0.100000, loss: 2.7201
2022-03-20 17:55:20 - train: epoch 0010, iter [00100, 00390], lr: 0.100000, loss: 2.6065
2022-03-20 17:55:31 - train: epoch 0010, iter [00150, 00390], lr: 0.100000, loss: 2.2480
2022-03-20 17:55:42 - train: epoch 0010, iter [00200, 00390], lr: 0.100000, loss: 2.5710
2022-03-20 17:55:54 - train: epoch 0010, iter [00250, 00390], lr: 0.100000, loss: 2.3520
2022-03-20 17:56:05 - train: epoch 0010, iter [00300, 00390], lr: 0.100000, loss: 2.2130
2022-03-20 17:56:17 - train: epoch 0010, iter [00350, 00390], lr: 0.100000, loss: 2.1962
2022-03-20 17:56:26 - train: epoch 010, train_loss: 2.3744
2022-03-20 17:56:33 - eval: epoch: 010, acc1: 37.890%, acc5: 70.500%, test_loss: 2.3871, per_image_load_time: 0.285ms, per_image_inference_time: 0.406ms
2022-03-20 17:56:36 - until epoch: 010, best_acc1: 37.890%
2022-03-20 17:56:36 - epoch 011 lr: 0.1
2022-03-20 17:56:50 - train: epoch 0011, iter [00050, 00390], lr: 0.100000, loss: 2.3163
2022-03-20 17:57:01 - train: epoch 0011, iter [00100, 00390], lr: 0.100000, loss: 1.9616
2022-03-20 17:57:12 - train: epoch 0011, iter [00150, 00390], lr: 0.100000, loss: 2.3251
2022-03-20 17:57:23 - train: epoch 0011, iter [00200, 00390], lr: 0.100000, loss: 2.1407
2022-03-20 17:57:34 - train: epoch 0011, iter [00250, 00390], lr: 0.100000, loss: 2.1654
2022-03-20 17:57:46 - train: epoch 0011, iter [00300, 00390], lr: 0.100000, loss: 2.0674
2022-03-20 17:57:57 - train: epoch 0011, iter [00350, 00390], lr: 0.100000, loss: 2.0349
2022-03-20 17:58:06 - train: epoch 011, train_loss: 2.2097
2022-03-20 17:58:14 - eval: epoch: 011, acc1: 40.590%, acc5: 73.280%, test_loss: 2.7387, per_image_load_time: 0.319ms, per_image_inference_time: 0.441ms
2022-03-20 17:58:17 - until epoch: 011, best_acc1: 40.590%
2022-03-20 17:58:17 - epoch 012 lr: 0.1
2022-03-20 17:58:31 - train: epoch 0012, iter [00050, 00390], lr: 0.100000, loss: 1.9947
2022-03-20 17:58:42 - train: epoch 0012, iter [00100, 00390], lr: 0.100000, loss: 2.4409
2022-03-20 17:58:54 - train: epoch 0012, iter [00150, 00390], lr: 0.100000, loss: 2.1640
2022-03-20 17:59:05 - train: epoch 0012, iter [00200, 00390], lr: 0.100000, loss: 2.1815
2022-03-20 17:59:16 - train: epoch 0012, iter [00250, 00390], lr: 0.100000, loss: 2.0564
2022-03-20 17:59:28 - train: epoch 0012, iter [00300, 00390], lr: 0.100000, loss: 2.2716
2022-03-20 17:59:39 - train: epoch 0012, iter [00350, 00390], lr: 0.100000, loss: 1.9369
2022-03-20 17:59:48 - train: epoch 012, train_loss: 2.0845
2022-03-20 17:59:56 - eval: epoch: 012, acc1: 41.220%, acc5: 74.650%, test_loss: 2.1947, per_image_load_time: 0.296ms, per_image_inference_time: 0.407ms
2022-03-20 17:59:58 - until epoch: 012, best_acc1: 41.220%
2022-03-20 17:59:58 - epoch 013 lr: 0.1
2022-03-20 18:00:12 - train: epoch 0013, iter [00050, 00390], lr: 0.100000, loss: 2.0426
2022-03-20 18:00:23 - train: epoch 0013, iter [00100, 00390], lr: 0.100000, loss: 1.9698
2022-03-20 18:00:35 - train: epoch 0013, iter [00150, 00390], lr: 0.100000, loss: 2.1988
2022-03-20 18:00:46 - train: epoch 0013, iter [00200, 00390], lr: 0.100000, loss: 2.0111
2022-03-20 18:00:57 - train: epoch 0013, iter [00250, 00390], lr: 0.100000, loss: 2.0810
2022-03-20 18:01:08 - train: epoch 0013, iter [00300, 00390], lr: 0.100000, loss: 2.0402
2022-03-20 18:01:19 - train: epoch 0013, iter [00350, 00390], lr: 0.100000, loss: 1.6780
2022-03-20 18:01:29 - train: epoch 013, train_loss: 1.9834
2022-03-20 18:01:36 - eval: epoch: 013, acc1: 45.480%, acc5: 77.680%, test_loss: 2.0720, per_image_load_time: 0.285ms, per_image_inference_time: 0.414ms
2022-03-20 18:01:39 - until epoch: 013, best_acc1: 45.480%
2022-03-20 18:01:39 - epoch 014 lr: 0.1
2022-03-20 18:01:53 - train: epoch 0014, iter [00050, 00390], lr: 0.100000, loss: 1.8749
2022-03-20 18:02:05 - train: epoch 0014, iter [00100, 00390], lr: 0.100000, loss: 1.7323
2022-03-20 18:02:16 - train: epoch 0014, iter [00150, 00390], lr: 0.100000, loss: 1.8421
2022-03-20 18:02:27 - train: epoch 0014, iter [00200, 00390], lr: 0.100000, loss: 2.0120
2022-03-20 18:02:38 - train: epoch 0014, iter [00250, 00390], lr: 0.100000, loss: 1.8759
2022-03-20 18:02:50 - train: epoch 0014, iter [00300, 00390], lr: 0.100000, loss: 1.9365
2022-03-20 18:03:01 - train: epoch 0014, iter [00350, 00390], lr: 0.100000, loss: 1.9128
2022-03-20 18:03:10 - train: epoch 014, train_loss: 1.8796
2022-03-20 18:03:17 - eval: epoch: 014, acc1: 42.720%, acc5: 75.320%, test_loss: 3.5599, per_image_load_time: 0.291ms, per_image_inference_time: 0.405ms
2022-03-20 18:03:18 - until epoch: 014, best_acc1: 45.480%
2022-03-20 18:03:18 - epoch 015 lr: 0.1
2022-03-20 18:03:33 - train: epoch 0015, iter [00050, 00390], lr: 0.100000, loss: 1.4237
2022-03-20 18:03:45 - train: epoch 0015, iter [00100, 00390], lr: 0.100000, loss: 2.0587
2022-03-20 18:03:56 - train: epoch 0015, iter [00150, 00390], lr: 0.100000, loss: 1.9246
2022-03-20 18:04:07 - train: epoch 0015, iter [00200, 00390], lr: 0.100000, loss: 2.0651
2022-03-20 18:04:18 - train: epoch 0015, iter [00250, 00390], lr: 0.100000, loss: 1.8401
2022-03-20 18:04:29 - train: epoch 0015, iter [00300, 00390], lr: 0.100000, loss: 1.6415
2022-03-20 18:04:41 - train: epoch 0015, iter [00350, 00390], lr: 0.100000, loss: 1.7891
2022-03-20 18:04:51 - train: epoch 015, train_loss: 1.8008
2022-03-20 18:04:59 - eval: epoch: 015, acc1: 43.540%, acc5: 76.650%, test_loss: 2.4043, per_image_load_time: 0.292ms, per_image_inference_time: 0.421ms
2022-03-20 18:05:00 - until epoch: 015, best_acc1: 45.480%
2022-03-20 18:05:00 - epoch 016 lr: 0.1
2022-03-20 18:05:14 - train: epoch 0016, iter [00050, 00390], lr: 0.100000, loss: 1.9013
2022-03-20 18:05:26 - train: epoch 0016, iter [00100, 00390], lr: 0.100000, loss: 1.7817
2022-03-20 18:05:37 - train: epoch 0016, iter [00150, 00390], lr: 0.100000, loss: 1.9025
2022-03-20 18:05:48 - train: epoch 0016, iter [00200, 00390], lr: 0.100000, loss: 1.9280
2022-03-20 18:05:59 - train: epoch 0016, iter [00250, 00390], lr: 0.100000, loss: 1.6358
2022-03-20 18:06:10 - train: epoch 0016, iter [00300, 00390], lr: 0.100000, loss: 1.8646
2022-03-20 18:06:22 - train: epoch 0016, iter [00350, 00390], lr: 0.100000, loss: 1.6464
2022-03-20 18:06:31 - train: epoch 016, train_loss: 1.7314
2022-03-20 18:06:39 - eval: epoch: 016, acc1: 49.370%, acc5: 80.820%, test_loss: 1.8657, per_image_load_time: 0.276ms, per_image_inference_time: 0.454ms
2022-03-20 18:06:41 - until epoch: 016, best_acc1: 49.370%
2022-03-20 18:06:41 - epoch 017 lr: 0.1
2022-03-20 18:06:56 - train: epoch 0017, iter [00050, 00390], lr: 0.100000, loss: 1.6667
2022-03-20 18:07:07 - train: epoch 0017, iter [00100, 00390], lr: 0.100000, loss: 2.0581
2022-03-20 18:07:18 - train: epoch 0017, iter [00150, 00390], lr: 0.100000, loss: 1.4495
2022-03-20 18:07:29 - train: epoch 0017, iter [00200, 00390], lr: 0.100000, loss: 1.5705
2022-03-20 18:07:41 - train: epoch 0017, iter [00250, 00390], lr: 0.100000, loss: 1.7548
2022-03-20 18:07:52 - train: epoch 0017, iter [00300, 00390], lr: 0.100000, loss: 1.9112
2022-03-20 18:08:03 - train: epoch 0017, iter [00350, 00390], lr: 0.100000, loss: 1.4045
2022-03-20 18:08:12 - train: epoch 017, train_loss: 1.6845
2022-03-20 18:08:19 - eval: epoch: 017, acc1: 41.780%, acc5: 72.660%, test_loss: 3.1145, per_image_load_time: 0.281ms, per_image_inference_time: 0.397ms
2022-03-20 18:08:21 - until epoch: 017, best_acc1: 49.370%
2022-03-20 18:08:21 - epoch 018 lr: 0.1
2022-03-20 18:08:35 - train: epoch 0018, iter [00050, 00390], lr: 0.100000, loss: 1.6988
2022-03-20 18:08:46 - train: epoch 0018, iter [00100, 00390], lr: 0.100000, loss: 1.5660
2022-03-20 18:08:56 - train: epoch 0018, iter [00150, 00390], lr: 0.100000, loss: 1.8584
2022-03-20 18:09:07 - train: epoch 0018, iter [00200, 00390], lr: 0.100000, loss: 1.5634
2022-03-20 18:09:18 - train: epoch 0018, iter [00250, 00390], lr: 0.100000, loss: 1.8424
2022-03-20 18:09:29 - train: epoch 0018, iter [00300, 00390], lr: 0.100000, loss: 1.6965
2022-03-20 18:09:40 - train: epoch 0018, iter [00350, 00390], lr: 0.100000, loss: 1.7439
2022-03-20 18:09:49 - train: epoch 018, train_loss: 1.6479
2022-03-20 18:09:56 - eval: epoch: 018, acc1: 43.450%, acc5: 74.840%, test_loss: 2.1629, per_image_load_time: 0.275ms, per_image_inference_time: 0.402ms
2022-03-20 18:09:57 - until epoch: 018, best_acc1: 49.370%
2022-03-20 18:09:57 - epoch 019 lr: 0.1
2022-03-20 18:10:11 - train: epoch 0019, iter [00050, 00390], lr: 0.100000, loss: 1.5158
2022-03-20 18:10:22 - train: epoch 0019, iter [00100, 00390], lr: 0.100000, loss: 1.5302
2022-03-20 18:10:33 - train: epoch 0019, iter [00150, 00390], lr: 0.100000, loss: 1.8704
2022-03-20 18:10:44 - train: epoch 0019, iter [00200, 00390], lr: 0.100000, loss: 1.6973
2022-03-20 18:10:56 - train: epoch 0019, iter [00250, 00390], lr: 0.100000, loss: 1.5306
2022-03-20 18:11:08 - train: epoch 0019, iter [00300, 00390], lr: 0.100000, loss: 1.6708
2022-03-20 18:11:19 - train: epoch 0019, iter [00350, 00390], lr: 0.100000, loss: 1.4172
2022-03-20 18:11:28 - train: epoch 019, train_loss: 1.5921
2022-03-20 18:11:35 - eval: epoch: 019, acc1: 48.590%, acc5: 78.610%, test_loss: 1.9542, per_image_load_time: 0.275ms, per_image_inference_time: 0.400ms
2022-03-20 18:11:37 - until epoch: 019, best_acc1: 49.370%
2022-03-20 18:11:37 - epoch 020 lr: 0.1
2022-03-20 18:11:51 - train: epoch 0020, iter [00050, 00390], lr: 0.100000, loss: 1.7002
2022-03-20 18:12:02 - train: epoch 0020, iter [00100, 00390], lr: 0.100000, loss: 1.5317
2022-03-20 18:12:13 - train: epoch 0020, iter [00150, 00390], lr: 0.100000, loss: 1.6531
2022-03-20 18:12:25 - train: epoch 0020, iter [00200, 00390], lr: 0.100000, loss: 1.5555
2022-03-20 18:12:36 - train: epoch 0020, iter [00250, 00390], lr: 0.100000, loss: 1.4952
2022-03-20 18:12:47 - train: epoch 0020, iter [00300, 00390], lr: 0.100000, loss: 1.5434
2022-03-20 18:12:58 - train: epoch 0020, iter [00350, 00390], lr: 0.100000, loss: 1.4311
2022-03-20 18:13:07 - train: epoch 020, train_loss: 1.5433
2022-03-20 18:13:15 - eval: epoch: 020, acc1: 49.560%, acc5: 80.440%, test_loss: 1.8806, per_image_load_time: 0.326ms, per_image_inference_time: 0.415ms
2022-03-20 18:13:18 - until epoch: 020, best_acc1: 49.560%
2022-03-20 18:13:18 - epoch 021 lr: 0.1
2022-03-20 18:13:32 - train: epoch 0021, iter [00050, 00390], lr: 0.100000, loss: 1.6457
2022-03-20 18:13:43 - train: epoch 0021, iter [00100, 00390], lr: 0.100000, loss: 1.6670
2022-03-20 18:13:54 - train: epoch 0021, iter [00150, 00390], lr: 0.100000, loss: 1.6451
2022-03-20 18:14:05 - train: epoch 0021, iter [00200, 00390], lr: 0.100000, loss: 1.7200
2022-03-20 18:14:16 - train: epoch 0021, iter [00250, 00390], lr: 0.100000, loss: 1.6266
2022-03-20 18:14:27 - train: epoch 0021, iter [00300, 00390], lr: 0.100000, loss: 1.5038
2022-03-20 18:14:39 - train: epoch 0021, iter [00350, 00390], lr: 0.100000, loss: 1.5670
2022-03-20 18:14:48 - train: epoch 021, train_loss: 1.5208
2022-03-20 18:14:55 - eval: epoch: 021, acc1: 52.010%, acc5: 81.540%, test_loss: 1.7712, per_image_load_time: 0.280ms, per_image_inference_time: 0.403ms
2022-03-20 18:14:57 - until epoch: 021, best_acc1: 52.010%
2022-03-20 18:14:57 - epoch 022 lr: 0.1
2022-03-20 18:15:11 - train: epoch 0022, iter [00050, 00390], lr: 0.100000, loss: 1.4892
2022-03-20 18:15:22 - train: epoch 0022, iter [00100, 00390], lr: 0.100000, loss: 1.5573
2022-03-20 18:15:33 - train: epoch 0022, iter [00150, 00390], lr: 0.100000, loss: 1.4230
2022-03-20 18:15:44 - train: epoch 0022, iter [00200, 00390], lr: 0.100000, loss: 1.8738
2022-03-20 18:15:55 - train: epoch 0022, iter [00250, 00390], lr: 0.100000, loss: 1.5265
2022-03-20 18:16:06 - train: epoch 0022, iter [00300, 00390], lr: 0.100000, loss: 1.5231
2022-03-20 18:16:18 - train: epoch 0022, iter [00350, 00390], lr: 0.100000, loss: 1.5374
2022-03-20 18:16:27 - train: epoch 022, train_loss: 1.4884
2022-03-20 18:16:35 - eval: epoch: 022, acc1: 52.680%, acc5: 82.490%, test_loss: 1.7111, per_image_load_time: 0.302ms, per_image_inference_time: 0.404ms
2022-03-20 18:16:37 - until epoch: 022, best_acc1: 52.680%
2022-03-20 18:16:37 - epoch 023 lr: 0.1
2022-03-20 18:16:52 - train: epoch 0023, iter [00050, 00390], lr: 0.100000, loss: 1.2248
2022-03-20 18:17:03 - train: epoch 0023, iter [00100, 00390], lr: 0.100000, loss: 1.3703
2022-03-20 18:17:14 - train: epoch 0023, iter [00150, 00390], lr: 0.100000, loss: 1.5393
2022-03-20 18:17:25 - train: epoch 0023, iter [00200, 00390], lr: 0.100000, loss: 1.5508
2022-03-20 18:17:36 - train: epoch 0023, iter [00250, 00390], lr: 0.100000, loss: 1.4165
2022-03-20 18:17:47 - train: epoch 0023, iter [00300, 00390], lr: 0.100000, loss: 1.5129
2022-03-20 18:17:58 - train: epoch 0023, iter [00350, 00390], lr: 0.100000, loss: 1.2511
2022-03-20 18:18:08 - train: epoch 023, train_loss: 1.4677
2022-03-20 18:18:15 - eval: epoch: 023, acc1: 51.410%, acc5: 81.380%, test_loss: 1.7916, per_image_load_time: 0.284ms, per_image_inference_time: 0.395ms
2022-03-20 18:18:17 - until epoch: 023, best_acc1: 52.680%
2022-03-20 18:18:17 - epoch 024 lr: 0.1
2022-03-20 18:18:31 - train: epoch 0024, iter [00050, 00390], lr: 0.100000, loss: 1.3405
2022-03-20 18:18:42 - train: epoch 0024, iter [00100, 00390], lr: 0.100000, loss: 1.3773
2022-03-20 18:18:53 - train: epoch 0024, iter [00150, 00390], lr: 0.100000, loss: 1.3881
2022-03-20 18:19:04 - train: epoch 0024, iter [00200, 00390], lr: 0.100000, loss: 1.6134
2022-03-20 18:19:16 - train: epoch 0024, iter [00250, 00390], lr: 0.100000, loss: 1.5465
2022-03-20 18:19:27 - train: epoch 0024, iter [00300, 00390], lr: 0.100000, loss: 1.2809
2022-03-20 18:19:38 - train: epoch 0024, iter [00350, 00390], lr: 0.100000, loss: 1.5242
2022-03-20 18:19:47 - train: epoch 024, train_loss: 1.4364
2022-03-20 18:19:55 - eval: epoch: 024, acc1: 49.960%, acc5: 79.530%, test_loss: 1.9321, per_image_load_time: 0.278ms, per_image_inference_time: 0.407ms
2022-03-20 18:19:56 - until epoch: 024, best_acc1: 52.680%
2022-03-20 18:19:56 - epoch 025 lr: 0.1
2022-03-20 18:20:11 - train: epoch 0025, iter [00050, 00390], lr: 0.100000, loss: 1.3547
2022-03-20 18:20:22 - train: epoch 0025, iter [00100, 00390], lr: 0.100000, loss: 1.2829
2022-03-20 18:20:33 - train: epoch 0025, iter [00150, 00390], lr: 0.100000, loss: 1.5220
2022-03-20 18:20:44 - train: epoch 0025, iter [00200, 00390], lr: 0.100000, loss: 1.4723
2022-03-20 18:20:54 - train: epoch 0025, iter [00250, 00390], lr: 0.100000, loss: 1.4215
2022-03-20 18:21:05 - train: epoch 0025, iter [00300, 00390], lr: 0.100000, loss: 1.5988
2022-03-20 18:21:16 - train: epoch 0025, iter [00350, 00390], lr: 0.100000, loss: 1.4324
2022-03-20 18:21:26 - train: epoch 025, train_loss: 1.4103
2022-03-20 18:21:33 - eval: epoch: 025, acc1: 47.260%, acc5: 78.830%, test_loss: 2.0994, per_image_load_time: 0.282ms, per_image_inference_time: 0.416ms
2022-03-20 18:21:35 - until epoch: 025, best_acc1: 52.680%
2022-03-20 18:21:35 - epoch 026 lr: 0.1
2022-03-20 18:21:49 - train: epoch 0026, iter [00050, 00390], lr: 0.100000, loss: 1.2697
2022-03-20 18:22:00 - train: epoch 0026, iter [00100, 00390], lr: 0.100000, loss: 1.3249
2022-03-20 18:22:12 - train: epoch 0026, iter [00150, 00390], lr: 0.100000, loss: 1.4238
2022-03-20 18:22:23 - train: epoch 0026, iter [00200, 00390], lr: 0.100000, loss: 1.5081
2022-03-20 18:22:35 - train: epoch 0026, iter [00250, 00390], lr: 0.100000, loss: 1.2810
2022-03-20 18:22:47 - train: epoch 0026, iter [00300, 00390], lr: 0.100000, loss: 1.4598
2022-03-20 18:22:58 - train: epoch 0026, iter [00350, 00390], lr: 0.100000, loss: 1.6738
2022-03-20 18:23:07 - train: epoch 026, train_loss: 1.3925
2022-03-20 18:23:14 - eval: epoch: 026, acc1: 56.650%, acc5: 84.600%, test_loss: 1.5934, per_image_load_time: 0.292ms, per_image_inference_time: 0.410ms
2022-03-20 18:23:17 - until epoch: 026, best_acc1: 56.650%
2022-03-20 18:23:17 - epoch 027 lr: 0.1
2022-03-20 18:23:31 - train: epoch 0027, iter [00050, 00390], lr: 0.100000, loss: 1.2902
2022-03-20 18:23:42 - train: epoch 0027, iter [00100, 00390], lr: 0.100000, loss: 1.3846
2022-03-20 18:23:53 - train: epoch 0027, iter [00150, 00390], lr: 0.100000, loss: 1.1559
2022-03-20 18:24:04 - train: epoch 0027, iter [00200, 00390], lr: 0.100000, loss: 1.5731
2022-03-20 18:24:16 - train: epoch 0027, iter [00250, 00390], lr: 0.100000, loss: 1.5558
2022-03-20 18:24:28 - train: epoch 0027, iter [00300, 00390], lr: 0.100000, loss: 1.3878
2022-03-20 18:24:39 - train: epoch 0027, iter [00350, 00390], lr: 0.100000, loss: 1.6356
2022-03-20 18:24:48 - train: epoch 027, train_loss: 1.3688
2022-03-20 18:24:55 - eval: epoch: 027, acc1: 54.220%, acc5: 83.770%, test_loss: 1.6658, per_image_load_time: 0.287ms, per_image_inference_time: 0.425ms
2022-03-20 18:24:57 - until epoch: 027, best_acc1: 56.650%
2022-03-20 18:24:57 - epoch 028 lr: 0.1
2022-03-20 18:25:11 - train: epoch 0028, iter [00050, 00390], lr: 0.100000, loss: 1.7062
2022-03-20 18:25:22 - train: epoch 0028, iter [00100, 00390], lr: 0.100000, loss: 1.3806
2022-03-20 18:25:33 - train: epoch 0028, iter [00150, 00390], lr: 0.100000, loss: 1.3290
2022-03-20 18:25:44 - train: epoch 0028, iter [00200, 00390], lr: 0.100000, loss: 1.4650
2022-03-20 18:25:55 - train: epoch 0028, iter [00250, 00390], lr: 0.100000, loss: 1.3422
2022-03-20 18:26:07 - train: epoch 0028, iter [00300, 00390], lr: 0.100000, loss: 1.1678
2022-03-20 18:26:18 - train: epoch 0028, iter [00350, 00390], lr: 0.100000, loss: 1.4099
2022-03-20 18:26:28 - train: epoch 028, train_loss: 1.3535
2022-03-20 18:26:36 - eval: epoch: 028, acc1: 51.950%, acc5: 82.640%, test_loss: 1.8245, per_image_load_time: 0.310ms, per_image_inference_time: 0.429ms
2022-03-20 18:26:37 - until epoch: 028, best_acc1: 56.650%
2022-03-20 18:26:37 - epoch 029 lr: 0.1
2022-03-20 18:26:52 - train: epoch 0029, iter [00050, 00390], lr: 0.100000, loss: 1.2610
2022-03-20 18:27:03 - train: epoch 0029, iter [00100, 00390], lr: 0.100000, loss: 1.4460
2022-03-20 18:27:14 - train: epoch 0029, iter [00150, 00390], lr: 0.100000, loss: 1.3431
2022-03-20 18:27:26 - train: epoch 0029, iter [00200, 00390], lr: 0.100000, loss: 1.3521
2022-03-20 18:27:37 - train: epoch 0029, iter [00250, 00390], lr: 0.100000, loss: 1.2329
2022-03-20 18:27:48 - train: epoch 0029, iter [00300, 00390], lr: 0.100000, loss: 1.3969
2022-03-20 18:27:59 - train: epoch 0029, iter [00350, 00390], lr: 0.100000, loss: 1.1139
2022-03-20 18:28:08 - train: epoch 029, train_loss: 1.3422
2022-03-20 18:28:16 - eval: epoch: 029, acc1: 53.780%, acc5: 83.340%, test_loss: 1.6881, per_image_load_time: 0.271ms, per_image_inference_time: 0.406ms
2022-03-20 18:28:17 - until epoch: 029, best_acc1: 56.650%
2022-03-20 18:28:17 - epoch 030 lr: 0.1
2022-03-20 18:28:31 - train: epoch 0030, iter [00050, 00390], lr: 0.100000, loss: 1.3420
2022-03-20 18:28:42 - train: epoch 0030, iter [00100, 00390], lr: 0.100000, loss: 1.1967
2022-03-20 18:28:53 - train: epoch 0030, iter [00150, 00390], lr: 0.100000, loss: 1.1439
2022-03-20 18:29:04 - train: epoch 0030, iter [00200, 00390], lr: 0.100000, loss: 1.1503
2022-03-20 18:29:14 - train: epoch 0030, iter [00250, 00390], lr: 0.100000, loss: 1.3440
2022-03-20 18:29:25 - train: epoch 0030, iter [00300, 00390], lr: 0.100000, loss: 1.2690
2022-03-20 18:29:36 - train: epoch 0030, iter [00350, 00390], lr: 0.100000, loss: 1.2125
2022-03-20 18:29:46 - train: epoch 030, train_loss: 1.3443
2022-03-20 18:29:53 - eval: epoch: 030, acc1: 53.070%, acc5: 83.540%, test_loss: 1.7177, per_image_load_time: 0.275ms, per_image_inference_time: 0.394ms
2022-03-20 18:29:54 - until epoch: 030, best_acc1: 56.650%
2022-03-20 18:29:54 - epoch 031 lr: 0.1
2022-03-20 18:30:09 - train: epoch 0031, iter [00050, 00390], lr: 0.100000, loss: 1.3150
2022-03-20 18:30:20 - train: epoch 0031, iter [00100, 00390], lr: 0.100000, loss: 1.3198
2022-03-20 18:30:32 - train: epoch 0031, iter [00150, 00390], lr: 0.100000, loss: 1.3863
2022-03-20 18:30:43 - train: epoch 0031, iter [00200, 00390], lr: 0.100000, loss: 1.5315
2022-03-20 18:30:55 - train: epoch 0031, iter [00250, 00390], lr: 0.100000, loss: 1.3112
2022-03-20 18:31:06 - train: epoch 0031, iter [00300, 00390], lr: 0.100000, loss: 1.3949
2022-03-20 18:31:18 - train: epoch 0031, iter [00350, 00390], lr: 0.100000, loss: 1.3459
2022-03-20 18:31:27 - train: epoch 031, train_loss: 1.3187
2022-03-20 18:31:35 - eval: epoch: 031, acc1: 51.840%, acc5: 82.230%, test_loss: 1.7782, per_image_load_time: 0.293ms, per_image_inference_time: 0.417ms
2022-03-20 18:31:36 - until epoch: 031, best_acc1: 56.650%
2022-03-20 18:31:36 - epoch 032 lr: 0.1
2022-03-20 18:31:51 - train: epoch 0032, iter [00050, 00390], lr: 0.100000, loss: 1.5090
2022-03-20 18:32:02 - train: epoch 0032, iter [00100, 00390], lr: 0.100000, loss: 1.2509
2022-03-20 18:32:13 - train: epoch 0032, iter [00150, 00390], lr: 0.100000, loss: 1.2408
2022-03-20 18:32:25 - train: epoch 0032, iter [00200, 00390], lr: 0.100000, loss: 1.4441
2022-03-20 18:32:36 - train: epoch 0032, iter [00250, 00390], lr: 0.100000, loss: 1.5369
2022-03-20 18:32:47 - train: epoch 0032, iter [00300, 00390], lr: 0.100000, loss: 1.4723
2022-03-20 18:32:58 - train: epoch 0032, iter [00350, 00390], lr: 0.100000, loss: 1.1161
2022-03-20 18:33:08 - train: epoch 032, train_loss: 1.3172
2022-03-20 18:33:15 - eval: epoch: 032, acc1: 55.410%, acc5: 84.270%, test_loss: 1.6594, per_image_load_time: 0.302ms, per_image_inference_time: 0.409ms
2022-03-20 18:33:17 - until epoch: 032, best_acc1: 56.650%
2022-03-20 18:33:17 - epoch 033 lr: 0.1
2022-03-20 18:33:31 - train: epoch 0033, iter [00050, 00390], lr: 0.100000, loss: 1.1661
2022-03-20 18:33:42 - train: epoch 0033, iter [00100, 00390], lr: 0.100000, loss: 1.1157
2022-03-20 18:33:53 - train: epoch 0033, iter [00150, 00390], lr: 0.100000, loss: 1.4190
2022-03-20 18:34:04 - train: epoch 0033, iter [00200, 00390], lr: 0.100000, loss: 1.4273
2022-03-20 18:34:15 - train: epoch 0033, iter [00250, 00390], lr: 0.100000, loss: 1.2138
2022-03-20 18:34:27 - train: epoch 0033, iter [00300, 00390], lr: 0.100000, loss: 1.3671
2022-03-20 18:34:38 - train: epoch 0033, iter [00350, 00390], lr: 0.100000, loss: 1.2200
2022-03-20 18:34:47 - train: epoch 033, train_loss: 1.3002
2022-03-20 18:34:54 - eval: epoch: 033, acc1: 56.200%, acc5: 85.210%, test_loss: 1.5976, per_image_load_time: 0.275ms, per_image_inference_time: 0.406ms
2022-03-20 18:34:56 - until epoch: 033, best_acc1: 56.650%
2022-03-20 18:34:56 - epoch 034 lr: 0.1
2022-03-20 18:35:09 - train: epoch 0034, iter [00050, 00390], lr: 0.100000, loss: 1.3338
2022-03-20 18:35:20 - train: epoch 0034, iter [00100, 00390], lr: 0.100000, loss: 1.1779
2022-03-20 18:35:32 - train: epoch 0034, iter [00150, 00390], lr: 0.100000, loss: 1.3161
2022-03-20 18:35:43 - train: epoch 0034, iter [00200, 00390], lr: 0.100000, loss: 1.1500
2022-03-20 18:35:54 - train: epoch 0034, iter [00250, 00390], lr: 0.100000, loss: 1.2355
2022-03-20 18:36:05 - train: epoch 0034, iter [00300, 00390], lr: 0.100000, loss: 1.3944
2022-03-20 18:36:16 - train: epoch 0034, iter [00350, 00390], lr: 0.100000, loss: 1.3203
2022-03-20 18:36:26 - train: epoch 034, train_loss: 1.2832
2022-03-20 18:36:34 - eval: epoch: 034, acc1: 52.640%, acc5: 80.810%, test_loss: 1.8123, per_image_load_time: 0.285ms, per_image_inference_time: 0.436ms
2022-03-20 18:36:35 - until epoch: 034, best_acc1: 56.650%
2022-03-20 18:36:35 - epoch 035 lr: 0.1
2022-03-20 18:36:50 - train: epoch 0035, iter [00050, 00390], lr: 0.100000, loss: 0.9668
2022-03-20 18:37:00 - train: epoch 0035, iter [00100, 00390], lr: 0.100000, loss: 1.2346
2022-03-20 18:37:11 - train: epoch 0035, iter [00150, 00390], lr: 0.100000, loss: 1.2809
2022-03-20 18:37:22 - train: epoch 0035, iter [00200, 00390], lr: 0.100000, loss: 1.1356
2022-03-20 18:37:33 - train: epoch 0035, iter [00250, 00390], lr: 0.100000, loss: 1.3916
2022-03-20 18:37:44 - train: epoch 0035, iter [00300, 00390], lr: 0.100000, loss: 1.3635
2022-03-20 18:37:55 - train: epoch 0035, iter [00350, 00390], lr: 0.100000, loss: 1.5509
2022-03-20 18:38:05 - train: epoch 035, train_loss: 1.2669
2022-03-20 18:38:12 - eval: epoch: 035, acc1: 53.330%, acc5: 82.770%, test_loss: 1.7196, per_image_load_time: 0.281ms, per_image_inference_time: 0.408ms
2022-03-20 18:38:14 - until epoch: 035, best_acc1: 56.650%
2022-03-20 18:38:14 - epoch 036 lr: 0.1
2022-03-20 18:38:28 - train: epoch 0036, iter [00050, 00390], lr: 0.100000, loss: 1.3413
2022-03-20 18:38:39 - train: epoch 0036, iter [00100, 00390], lr: 0.100000, loss: 1.2354
2022-03-20 18:38:50 - train: epoch 0036, iter [00150, 00390], lr: 0.100000, loss: 1.1885
2022-03-20 18:39:01 - train: epoch 0036, iter [00200, 00390], lr: 0.100000, loss: 1.0708
2022-03-20 18:39:13 - train: epoch 0036, iter [00250, 00390], lr: 0.100000, loss: 1.1802
2022-03-20 18:39:25 - train: epoch 0036, iter [00300, 00390], lr: 0.100000, loss: 1.2984
2022-03-20 18:39:36 - train: epoch 0036, iter [00350, 00390], lr: 0.100000, loss: 1.3195
2022-03-20 18:39:46 - train: epoch 036, train_loss: 1.2651
2022-03-20 18:39:54 - eval: epoch: 036, acc1: 55.610%, acc5: 83.830%, test_loss: 1.6648, per_image_load_time: 0.311ms, per_image_inference_time: 0.427ms
2022-03-20 18:39:55 - until epoch: 036, best_acc1: 56.650%
2022-03-20 18:39:55 - epoch 037 lr: 0.1
2022-03-20 18:40:10 - train: epoch 0037, iter [00050, 00390], lr: 0.100000, loss: 1.2405
2022-03-20 18:40:22 - train: epoch 0037, iter [00100, 00390], lr: 0.100000, loss: 1.3460
2022-03-20 18:40:32 - train: epoch 0037, iter [00150, 00390], lr: 0.100000, loss: 1.0805
2022-03-20 18:40:44 - train: epoch 0037, iter [00200, 00390], lr: 0.100000, loss: 1.4655
2022-03-20 18:40:55 - train: epoch 0037, iter [00250, 00390], lr: 0.100000, loss: 1.4168
2022-03-20 18:41:06 - train: epoch 0037, iter [00300, 00390], lr: 0.100000, loss: 1.4969
2022-03-20 18:41:18 - train: epoch 0037, iter [00350, 00390], lr: 0.100000, loss: 1.2373
2022-03-20 18:41:27 - train: epoch 037, train_loss: 1.2586
2022-03-20 18:41:35 - eval: epoch: 037, acc1: 57.400%, acc5: 86.320%, test_loss: 1.5521, per_image_load_time: 0.328ms, per_image_inference_time: 0.455ms
2022-03-20 18:41:38 - until epoch: 037, best_acc1: 57.400%
2022-03-20 18:41:38 - epoch 038 lr: 0.1
2022-03-20 18:41:52 - train: epoch 0038, iter [00050, 00390], lr: 0.100000, loss: 0.8904
2022-03-20 18:42:03 - train: epoch 0038, iter [00100, 00390], lr: 0.100000, loss: 1.1061
2022-03-20 18:42:14 - train: epoch 0038, iter [00150, 00390], lr: 0.100000, loss: 1.3911
2022-03-20 18:42:26 - train: epoch 0038, iter [00200, 00390], lr: 0.100000, loss: 1.1784
2022-03-20 18:42:37 - train: epoch 0038, iter [00250, 00390], lr: 0.100000, loss: 1.3340
2022-03-20 18:42:48 - train: epoch 0038, iter [00300, 00390], lr: 0.100000, loss: 1.4067
2022-03-20 18:43:00 - train: epoch 0038, iter [00350, 00390], lr: 0.100000, loss: 1.4518
2022-03-20 18:43:09 - train: epoch 038, train_loss: 1.2355
2022-03-20 18:43:17 - eval: epoch: 038, acc1: 56.150%, acc5: 86.140%, test_loss: 1.6512, per_image_load_time: 0.310ms, per_image_inference_time: 0.408ms
2022-03-20 18:43:19 - until epoch: 038, best_acc1: 57.400%
2022-03-20 18:43:19 - epoch 039 lr: 0.1
2022-03-20 18:43:33 - train: epoch 0039, iter [00050, 00390], lr: 0.100000, loss: 1.3396
2022-03-20 18:43:45 - train: epoch 0039, iter [00100, 00390], lr: 0.100000, loss: 1.4484
2022-03-20 18:43:56 - train: epoch 0039, iter [00150, 00390], lr: 0.100000, loss: 1.2528
2022-03-20 18:44:07 - train: epoch 0039, iter [00200, 00390], lr: 0.100000, loss: 1.1253
2022-03-20 18:44:19 - train: epoch 0039, iter [00250, 00390], lr: 0.100000, loss: 1.2421
2022-03-20 18:44:30 - train: epoch 0039, iter [00300, 00390], lr: 0.100000, loss: 1.1148
2022-03-20 18:44:41 - train: epoch 0039, iter [00350, 00390], lr: 0.100000, loss: 1.3554
2022-03-20 18:44:51 - train: epoch 039, train_loss: 1.2352
2022-03-20 18:44:59 - eval: epoch: 039, acc1: 55.190%, acc5: 85.110%, test_loss: 1.6799, per_image_load_time: 0.347ms, per_image_inference_time: 0.428ms
2022-03-20 18:45:01 - until epoch: 039, best_acc1: 57.400%
2022-03-20 18:45:01 - epoch 040 lr: 0.1
2022-03-20 18:45:16 - train: epoch 0040, iter [00050, 00390], lr: 0.100000, loss: 1.3093
2022-03-20 18:45:27 - train: epoch 0040, iter [00100, 00390], lr: 0.100000, loss: 0.8642
2022-03-20 18:45:39 - train: epoch 0040, iter [00150, 00390], lr: 0.100000, loss: 1.2731
2022-03-20 18:45:50 - train: epoch 0040, iter [00200, 00390], lr: 0.100000, loss: 1.4706
2022-03-20 18:46:01 - train: epoch 0040, iter [00250, 00390], lr: 0.100000, loss: 1.5450
2022-03-20 18:46:12 - train: epoch 0040, iter [00300, 00390], lr: 0.100000, loss: 1.1828
2022-03-20 18:46:24 - train: epoch 0040, iter [00350, 00390], lr: 0.100000, loss: 1.5380
2022-03-20 18:46:33 - train: epoch 040, train_loss: 1.2390
2022-03-20 18:46:41 - eval: epoch: 040, acc1: 54.160%, acc5: 83.190%, test_loss: 1.6850, per_image_load_time: 0.333ms, per_image_inference_time: 0.402ms
2022-03-20 18:46:41 - until epoch: 040, best_acc1: 57.400%
2022-03-20 18:46:41 - epoch 041 lr: 0.1
2022-03-20 18:46:56 - train: epoch 0041, iter [00050, 00390], lr: 0.100000, loss: 0.9314
2022-03-20 18:47:07 - train: epoch 0041, iter [00100, 00390], lr: 0.100000, loss: 1.1010
2022-03-20 18:47:19 - train: epoch 0041, iter [00150, 00390], lr: 0.100000, loss: 1.3514
2022-03-20 18:47:30 - train: epoch 0041, iter [00200, 00390], lr: 0.100000, loss: 1.2351
2022-03-20 18:47:41 - train: epoch 0041, iter [00250, 00390], lr: 0.100000, loss: 1.4434
2022-03-20 18:47:52 - train: epoch 0041, iter [00300, 00390], lr: 0.100000, loss: 1.2434
2022-03-20 18:48:03 - train: epoch 0041, iter [00350, 00390], lr: 0.100000, loss: 1.3301
2022-03-20 18:48:12 - train: epoch 041, train_loss: 1.2189
2022-03-20 18:48:20 - eval: epoch: 041, acc1: 55.960%, acc5: 84.970%, test_loss: 1.6283, per_image_load_time: 0.325ms, per_image_inference_time: 0.413ms
2022-03-20 18:48:22 - until epoch: 041, best_acc1: 57.400%
2022-03-20 18:48:22 - epoch 042 lr: 0.1
2022-03-20 18:48:37 - train: epoch 0042, iter [00050, 00390], lr: 0.100000, loss: 1.0038
2022-03-20 18:48:48 - train: epoch 0042, iter [00100, 00390], lr: 0.100000, loss: 1.1878
2022-03-20 18:48:59 - train: epoch 0042, iter [00150, 00390], lr: 0.100000, loss: 1.2420
2022-03-20 18:49:10 - train: epoch 0042, iter [00200, 00390], lr: 0.100000, loss: 1.0005
2022-03-20 18:49:21 - train: epoch 0042, iter [00250, 00390], lr: 0.100000, loss: 1.3481
2022-03-20 18:49:32 - train: epoch 0042, iter [00300, 00390], lr: 0.100000, loss: 1.1013
2022-03-20 18:49:43 - train: epoch 0042, iter [00350, 00390], lr: 0.100000, loss: 1.1185
2022-03-20 18:49:53 - train: epoch 042, train_loss: 1.2124
2022-03-20 18:50:01 - eval: epoch: 042, acc1: 54.190%, acc5: 84.220%, test_loss: 1.7014, per_image_load_time: 0.335ms, per_image_inference_time: 0.404ms
2022-03-20 18:50:02 - until epoch: 042, best_acc1: 57.400%
2022-03-20 18:50:02 - epoch 043 lr: 0.1
2022-03-20 18:50:17 - train: epoch 0043, iter [00050, 00390], lr: 0.100000, loss: 1.0910
2022-03-20 18:50:28 - train: epoch 0043, iter [00100, 00390], lr: 0.100000, loss: 1.1718
2022-03-20 18:50:39 - train: epoch 0043, iter [00150, 00390], lr: 0.100000, loss: 1.1467
2022-03-20 18:50:50 - train: epoch 0043, iter [00200, 00390], lr: 0.100000, loss: 1.4867
2022-03-20 18:51:01 - train: epoch 0043, iter [00250, 00390], lr: 0.100000, loss: 1.3808
2022-03-20 18:51:12 - train: epoch 0043, iter [00300, 00390], lr: 0.100000, loss: 1.2251
2022-03-20 18:51:23 - train: epoch 0043, iter [00350, 00390], lr: 0.100000, loss: 1.2679
2022-03-20 18:51:33 - train: epoch 043, train_loss: 1.2111
2022-03-20 18:51:41 - eval: epoch: 043, acc1: 58.320%, acc5: 86.180%, test_loss: 1.5202, per_image_load_time: 0.329ms, per_image_inference_time: 0.406ms
2022-03-20 18:51:43 - until epoch: 043, best_acc1: 58.320%
2022-03-20 18:51:43 - epoch 044 lr: 0.1
2022-03-20 18:51:57 - train: epoch 0044, iter [00050, 00390], lr: 0.100000, loss: 1.1597
2022-03-20 18:52:09 - train: epoch 0044, iter [00100, 00390], lr: 0.100000, loss: 1.3589
2022-03-20 18:52:20 - train: epoch 0044, iter [00150, 00390], lr: 0.100000, loss: 1.1549
2022-03-20 18:52:31 - train: epoch 0044, iter [00200, 00390], lr: 0.100000, loss: 1.0726
2022-03-20 18:52:42 - train: epoch 0044, iter [00250, 00390], lr: 0.100000, loss: 1.3585
2022-03-20 18:52:53 - train: epoch 0044, iter [00300, 00390], lr: 0.100000, loss: 1.0687
2022-03-20 18:53:04 - train: epoch 0044, iter [00350, 00390], lr: 0.100000, loss: 1.0173
2022-03-20 18:53:13 - train: epoch 044, train_loss: 1.2037
2022-03-20 18:53:21 - eval: epoch: 044, acc1: 56.190%, acc5: 84.100%, test_loss: 1.6642, per_image_load_time: 0.331ms, per_image_inference_time: 0.417ms
2022-03-20 18:53:23 - until epoch: 044, best_acc1: 58.320%
2022-03-20 18:53:23 - epoch 045 lr: 0.1
2022-03-20 18:53:37 - train: epoch 0045, iter [00050, 00390], lr: 0.100000, loss: 1.0857
2022-03-20 18:53:48 - train: epoch 0045, iter [00100, 00390], lr: 0.100000, loss: 1.1606
2022-03-20 18:53:59 - train: epoch 0045, iter [00150, 00390], lr: 0.100000, loss: 1.1563
2022-03-20 18:54:10 - train: epoch 0045, iter [00200, 00390], lr: 0.100000, loss: 1.2552
2022-03-20 18:54:21 - train: epoch 0045, iter [00250, 00390], lr: 0.100000, loss: 0.9913
2022-03-20 18:54:33 - train: epoch 0045, iter [00300, 00390], lr: 0.100000, loss: 1.1577
2022-03-20 18:54:44 - train: epoch 0045, iter [00350, 00390], lr: 0.100000, loss: 1.4438
2022-03-20 18:54:53 - train: epoch 045, train_loss: 1.1986
2022-03-20 18:55:01 - eval: epoch: 045, acc1: 50.410%, acc5: 83.110%, test_loss: 1.9272, per_image_load_time: 0.336ms, per_image_inference_time: 0.402ms
2022-03-20 18:55:03 - until epoch: 045, best_acc1: 58.320%
2022-03-20 18:55:03 - epoch 046 lr: 0.1
2022-03-20 18:55:17 - train: epoch 0046, iter [00050, 00390], lr: 0.100000, loss: 1.0827
2022-03-20 18:55:28 - train: epoch 0046, iter [00100, 00390], lr: 0.100000, loss: 1.1289
2022-03-20 18:55:39 - train: epoch 0046, iter [00150, 00390], lr: 0.100000, loss: 0.9712
2022-03-20 18:55:51 - train: epoch 0046, iter [00200, 00390], lr: 0.100000, loss: 1.2041
2022-03-20 18:56:02 - train: epoch 0046, iter [00250, 00390], lr: 0.100000, loss: 1.0391
2022-03-20 18:56:13 - train: epoch 0046, iter [00300, 00390], lr: 0.100000, loss: 0.8778
2022-03-20 18:56:24 - train: epoch 0046, iter [00350, 00390], lr: 0.100000, loss: 1.0728
2022-03-20 18:56:33 - train: epoch 046, train_loss: 1.1948
2022-03-20 18:56:41 - eval: epoch: 046, acc1: 57.300%, acc5: 85.130%, test_loss: 1.5669, per_image_load_time: 0.334ms, per_image_inference_time: 0.410ms
2022-03-20 18:56:43 - until epoch: 046, best_acc1: 58.320%
2022-03-20 18:56:43 - epoch 047 lr: 0.1
2022-03-20 18:56:58 - train: epoch 0047, iter [00050, 00390], lr: 0.100000, loss: 1.1203
2022-03-20 18:57:09 - train: epoch 0047, iter [00100, 00390], lr: 0.100000, loss: 1.0710
2022-03-20 18:57:20 - train: epoch 0047, iter [00150, 00390], lr: 0.100000, loss: 1.1041
2022-03-20 18:57:31 - train: epoch 0047, iter [00200, 00390], lr: 0.100000, loss: 1.1053
2022-03-20 18:57:42 - train: epoch 0047, iter [00250, 00390], lr: 0.100000, loss: 1.1105
2022-03-20 18:57:54 - train: epoch 0047, iter [00300, 00390], lr: 0.100000, loss: 1.1441
2022-03-20 18:58:05 - train: epoch 0047, iter [00350, 00390], lr: 0.100000, loss: 1.1266
2022-03-20 18:58:14 - train: epoch 047, train_loss: 1.1804
2022-03-20 18:58:22 - eval: epoch: 047, acc1: 57.810%, acc5: 85.990%, test_loss: 1.5445, per_image_load_time: 0.327ms, per_image_inference_time: 0.411ms
2022-03-20 18:58:24 - until epoch: 047, best_acc1: 58.320%
2022-03-20 18:58:24 - epoch 048 lr: 0.1
2022-03-20 18:58:38 - train: epoch 0048, iter [00050, 00390], lr: 0.100000, loss: 1.2632
2022-03-20 18:58:49 - train: epoch 0048, iter [00100, 00390], lr: 0.100000, loss: 0.9634
2022-03-20 18:59:01 - train: epoch 0048, iter [00150, 00390], lr: 0.100000, loss: 1.1393
2022-03-20 18:59:12 - train: epoch 0048, iter [00200, 00390], lr: 0.100000, loss: 1.2086
2022-03-20 18:59:23 - train: epoch 0048, iter [00250, 00390], lr: 0.100000, loss: 1.3250
2022-03-20 18:59:34 - train: epoch 0048, iter [00300, 00390], lr: 0.100000, loss: 1.1459
2022-03-20 18:59:45 - train: epoch 0048, iter [00350, 00390], lr: 0.100000, loss: 1.3754
2022-03-20 18:59:54 - train: epoch 048, train_loss: 1.1849
2022-03-20 19:00:02 - eval: epoch: 048, acc1: 54.810%, acc5: 83.970%, test_loss: 1.6750, per_image_load_time: 0.336ms, per_image_inference_time: 0.402ms
2022-03-20 19:00:04 - until epoch: 048, best_acc1: 58.320%
2022-03-20 19:00:04 - epoch 049 lr: 0.1
2022-03-20 19:00:18 - train: epoch 0049, iter [00050, 00390], lr: 0.100000, loss: 1.3608
2022-03-20 19:00:30 - train: epoch 0049, iter [00100, 00390], lr: 0.100000, loss: 1.1886
2022-03-20 19:00:41 - train: epoch 0049, iter [00150, 00390], lr: 0.100000, loss: 1.3154
2022-03-20 19:00:52 - train: epoch 0049, iter [00200, 00390], lr: 0.100000, loss: 1.3048
2022-03-20 19:01:03 - train: epoch 0049, iter [00250, 00390], lr: 0.100000, loss: 1.2061
2022-03-20 19:01:14 - train: epoch 0049, iter [00300, 00390], lr: 0.100000, loss: 1.1612
2022-03-20 19:01:25 - train: epoch 0049, iter [00350, 00390], lr: 0.100000, loss: 0.9823
2022-03-20 19:01:35 - train: epoch 049, train_loss: 1.1700
2022-03-20 19:01:43 - eval: epoch: 049, acc1: 54.520%, acc5: 83.530%, test_loss: 1.7028, per_image_load_time: 0.346ms, per_image_inference_time: 0.416ms
2022-03-20 19:01:45 - until epoch: 049, best_acc1: 58.320%
2022-03-20 19:01:45 - epoch 050 lr: 0.1
2022-03-20 19:01:59 - train: epoch 0050, iter [00050, 00390], lr: 0.100000, loss: 1.1159
2022-03-20 19:02:10 - train: epoch 0050, iter [00100, 00390], lr: 0.100000, loss: 0.9446
2022-03-20 19:02:21 - train: epoch 0050, iter [00150, 00390], lr: 0.100000, loss: 1.2399
2022-03-20 19:02:32 - train: epoch 0050, iter [00200, 00390], lr: 0.100000, loss: 1.0877
2022-03-20 19:02:43 - train: epoch 0050, iter [00250, 00390], lr: 0.100000, loss: 1.1250
2022-03-20 19:02:54 - train: epoch 0050, iter [00300, 00390], lr: 0.100000, loss: 1.0362
2022-03-20 19:03:06 - train: epoch 0050, iter [00350, 00390], lr: 0.100000, loss: 1.2603
2022-03-20 19:03:15 - train: epoch 050, train_loss: 1.1714
2022-03-20 19:03:22 - eval: epoch: 050, acc1: 55.250%, acc5: 83.450%, test_loss: 1.6831, per_image_load_time: 0.312ms, per_image_inference_time: 0.408ms
2022-03-20 19:03:24 - until epoch: 050, best_acc1: 58.320%
2022-03-20 19:03:24 - epoch 051 lr: 0.1
2022-03-20 19:03:39 - train: epoch 0051, iter [00050, 00390], lr: 0.100000, loss: 1.2146
2022-03-20 19:03:50 - train: epoch 0051, iter [00100, 00390], lr: 0.100000, loss: 1.1898
2022-03-20 19:04:01 - train: epoch 0051, iter [00150, 00390], lr: 0.100000, loss: 1.0559
2022-03-20 19:04:12 - train: epoch 0051, iter [00200, 00390], lr: 0.100000, loss: 1.2336
2022-03-20 19:04:23 - train: epoch 0051, iter [00250, 00390], lr: 0.100000, loss: 1.1246
2022-03-20 19:04:34 - train: epoch 0051, iter [00300, 00390], lr: 0.100000, loss: 1.1940
2022-03-20 19:04:45 - train: epoch 0051, iter [00350, 00390], lr: 0.100000, loss: 1.0336
2022-03-20 19:04:54 - train: epoch 051, train_loss: 1.1717
2022-03-20 19:05:02 - eval: epoch: 051, acc1: 58.000%, acc5: 86.330%, test_loss: 1.5231, per_image_load_time: 0.332ms, per_image_inference_time: 0.407ms
2022-03-20 19:05:03 - until epoch: 051, best_acc1: 58.320%
2022-03-20 19:05:03 - epoch 052 lr: 0.1
2022-03-20 19:05:18 - train: epoch 0052, iter [00050, 00390], lr: 0.100000, loss: 1.3093
2022-03-20 19:05:29 - train: epoch 0052, iter [00100, 00390], lr: 0.100000, loss: 1.1538
2022-03-20 19:05:40 - train: epoch 0052, iter [00150, 00390], lr: 0.100000, loss: 1.1475
2022-03-20 19:05:51 - train: epoch 0052, iter [00200, 00390], lr: 0.100000, loss: 1.2488
2022-03-20 19:06:02 - train: epoch 0052, iter [00250, 00390], lr: 0.100000, loss: 1.0194
2022-03-20 19:06:13 - train: epoch 0052, iter [00300, 00390], lr: 0.100000, loss: 1.2270
2022-03-20 19:06:25 - train: epoch 0052, iter [00350, 00390], lr: 0.100000, loss: 1.1239
2022-03-20 19:06:34 - train: epoch 052, train_loss: 1.1685
2022-03-20 19:06:42 - eval: epoch: 052, acc1: 58.110%, acc5: 86.110%, test_loss: 1.5517, per_image_load_time: 0.310ms, per_image_inference_time: 0.403ms
2022-03-20 19:06:43 - until epoch: 052, best_acc1: 58.320%
2022-03-20 19:06:43 - epoch 053 lr: 0.1
2022-03-20 19:06:58 - train: epoch 0053, iter [00050, 00390], lr: 0.100000, loss: 1.0232
2022-03-20 19:07:09 - train: epoch 0053, iter [00100, 00390], lr: 0.100000, loss: 0.8745
2022-03-20 19:07:20 - train: epoch 0053, iter [00150, 00390], lr: 0.100000, loss: 1.1062
2022-03-20 19:07:31 - train: epoch 0053, iter [00200, 00390], lr: 0.100000, loss: 1.1925
2022-03-20 19:07:43 - train: epoch 0053, iter [00250, 00390], lr: 0.100000, loss: 1.1454
2022-03-20 19:07:54 - train: epoch 0053, iter [00300, 00390], lr: 0.100000, loss: 1.0673
2022-03-20 19:08:05 - train: epoch 0053, iter [00350, 00390], lr: 0.100000, loss: 1.0804
2022-03-20 19:08:14 - train: epoch 053, train_loss: 1.1500
2022-03-20 19:08:22 - eval: epoch: 053, acc1: 57.110%, acc5: 86.090%, test_loss: 1.5611, per_image_load_time: 0.314ms, per_image_inference_time: 0.417ms
2022-03-20 19:08:24 - until epoch: 053, best_acc1: 58.320%
2022-03-20 19:08:24 - epoch 054 lr: 0.1
2022-03-20 19:08:38 - train: epoch 0054, iter [00050, 00390], lr: 0.100000, loss: 1.1142
2022-03-20 19:08:49 - train: epoch 0054, iter [00100, 00390], lr: 0.100000, loss: 1.1327
2022-03-20 19:09:00 - train: epoch 0054, iter [00150, 00390], lr: 0.100000, loss: 0.9042
2022-03-20 19:09:12 - train: epoch 0054, iter [00200, 00390], lr: 0.100000, loss: 1.3768
2022-03-20 19:09:23 - train: epoch 0054, iter [00250, 00390], lr: 0.100000, loss: 1.1654
2022-03-20 19:09:34 - train: epoch 0054, iter [00300, 00390], lr: 0.100000, loss: 1.1564
2022-03-20 19:09:45 - train: epoch 0054, iter [00350, 00390], lr: 0.100000, loss: 1.2331
2022-03-20 19:09:54 - train: epoch 054, train_loss: 1.1543
2022-03-20 19:10:02 - eval: epoch: 054, acc1: 56.200%, acc5: 84.440%, test_loss: 1.6552, per_image_load_time: 0.342ms, per_image_inference_time: 0.417ms
2022-03-20 19:10:04 - until epoch: 054, best_acc1: 58.320%
2022-03-20 19:10:04 - epoch 055 lr: 0.1
2022-03-20 19:10:18 - train: epoch 0055, iter [00050, 00390], lr: 0.100000, loss: 1.3216
2022-03-20 19:10:29 - train: epoch 0055, iter [00100, 00390], lr: 0.100000, loss: 1.1858
2022-03-20 19:10:40 - train: epoch 0055, iter [00150, 00390], lr: 0.100000, loss: 1.2524
2022-03-20 19:10:51 - train: epoch 0055, iter [00200, 00390], lr: 0.100000, loss: 1.2519
2022-03-20 19:11:02 - train: epoch 0055, iter [00250, 00390], lr: 0.100000, loss: 1.1950
2022-03-20 19:11:13 - train: epoch 0055, iter [00300, 00390], lr: 0.100000, loss: 1.1807
2022-03-20 19:11:24 - train: epoch 0055, iter [00350, 00390], lr: 0.100000, loss: 1.2451
2022-03-20 19:11:34 - train: epoch 055, train_loss: 1.1547
2022-03-20 19:11:41 - eval: epoch: 055, acc1: 60.420%, acc5: 86.920%, test_loss: 1.4594, per_image_load_time: 0.336ms, per_image_inference_time: 0.412ms
2022-03-20 19:11:44 - until epoch: 055, best_acc1: 60.420%
2022-03-20 19:11:44 - epoch 056 lr: 0.1
2022-03-20 19:11:59 - train: epoch 0056, iter [00050, 00390], lr: 0.100000, loss: 1.2386
2022-03-20 19:12:09 - train: epoch 0056, iter [00100, 00390], lr: 0.100000, loss: 1.0834
2022-03-20 19:12:21 - train: epoch 0056, iter [00150, 00390], lr: 0.100000, loss: 1.1072
2022-03-20 19:12:32 - train: epoch 0056, iter [00200, 00390], lr: 0.100000, loss: 1.1490
2022-03-20 19:12:43 - train: epoch 0056, iter [00250, 00390], lr: 0.100000, loss: 1.0239
2022-03-20 19:12:54 - train: epoch 0056, iter [00300, 00390], lr: 0.100000, loss: 1.4398
2022-03-20 19:13:05 - train: epoch 0056, iter [00350, 00390], lr: 0.100000, loss: 1.1722
2022-03-20 19:13:15 - train: epoch 056, train_loss: 1.1430
2022-03-20 19:13:23 - eval: epoch: 056, acc1: 56.670%, acc5: 84.370%, test_loss: 1.6409, per_image_load_time: 0.333ms, per_image_inference_time: 0.406ms
2022-03-20 19:13:24 - until epoch: 056, best_acc1: 60.420%
2022-03-20 19:13:24 - epoch 057 lr: 0.1
2022-03-20 19:13:39 - train: epoch 0057, iter [00050, 00390], lr: 0.100000, loss: 1.0901
2022-03-20 19:13:51 - train: epoch 0057, iter [00100, 00390], lr: 0.100000, loss: 1.2555
2022-03-20 19:14:02 - train: epoch 0057, iter [00150, 00390], lr: 0.100000, loss: 1.0515
2022-03-20 19:14:13 - train: epoch 0057, iter [00200, 00390], lr: 0.100000, loss: 1.1345
2022-03-20 19:14:24 - train: epoch 0057, iter [00250, 00390], lr: 0.100000, loss: 1.1814
2022-03-20 19:14:35 - train: epoch 0057, iter [00300, 00390], lr: 0.100000, loss: 1.2434
2022-03-20 19:14:47 - train: epoch 0057, iter [00350, 00390], lr: 0.100000, loss: 1.0568
2022-03-20 19:14:56 - train: epoch 057, train_loss: 1.1422
2022-03-20 19:15:04 - eval: epoch: 057, acc1: 51.880%, acc5: 82.170%, test_loss: 1.8362, per_image_load_time: 0.338ms, per_image_inference_time: 0.419ms
2022-03-20 19:15:06 - until epoch: 057, best_acc1: 60.420%
2022-03-20 19:15:06 - epoch 058 lr: 0.1
2022-03-20 19:15:20 - train: epoch 0058, iter [00050, 00390], lr: 0.100000, loss: 1.0742
2022-03-20 19:15:32 - train: epoch 0058, iter [00100, 00390], lr: 0.100000, loss: 0.9730
2022-03-20 19:15:43 - train: epoch 0058, iter [00150, 00390], lr: 0.100000, loss: 1.0856
2022-03-20 19:15:54 - train: epoch 0058, iter [00200, 00390], lr: 0.100000, loss: 1.2073
2022-03-20 19:16:05 - train: epoch 0058, iter [00250, 00390], lr: 0.100000, loss: 1.2049
2022-03-20 19:16:16 - train: epoch 0058, iter [00300, 00390], lr: 0.100000, loss: 1.3528
2022-03-20 19:16:27 - train: epoch 0058, iter [00350, 00390], lr: 0.100000, loss: 1.3510
2022-03-20 19:16:37 - train: epoch 058, train_loss: 1.1418
2022-03-20 19:16:45 - eval: epoch: 058, acc1: 57.070%, acc5: 85.650%, test_loss: 1.5883, per_image_load_time: 0.331ms, per_image_inference_time: 0.413ms
2022-03-20 19:16:46 - until epoch: 058, best_acc1: 60.420%
2022-03-20 19:16:46 - epoch 059 lr: 0.1
2022-03-20 19:17:01 - train: epoch 0059, iter [00050, 00390], lr: 0.100000, loss: 1.1805
2022-03-20 19:17:12 - train: epoch 0059, iter [00100, 00390], lr: 0.100000, loss: 1.1040
2022-03-20 19:17:23 - train: epoch 0059, iter [00150, 00390], lr: 0.100000, loss: 1.0460
2022-03-20 19:17:34 - train: epoch 0059, iter [00200, 00390], lr: 0.100000, loss: 1.3472
2022-03-20 19:17:45 - train: epoch 0059, iter [00250, 00390], lr: 0.100000, loss: 1.3758
2022-03-20 19:17:56 - train: epoch 0059, iter [00300, 00390], lr: 0.100000, loss: 1.2389
2022-03-20 19:18:07 - train: epoch 0059, iter [00350, 00390], lr: 0.100000, loss: 1.4840
2022-03-20 19:18:17 - train: epoch 059, train_loss: 1.1399
2022-03-20 19:18:25 - eval: epoch: 059, acc1: 56.970%, acc5: 84.830%, test_loss: 1.6177, per_image_load_time: 0.352ms, per_image_inference_time: 0.427ms
2022-03-20 19:18:27 - until epoch: 059, best_acc1: 60.420%
2022-03-20 19:18:27 - epoch 060 lr: 0.1
2022-03-20 19:18:41 - train: epoch 0060, iter [00050, 00390], lr: 0.100000, loss: 1.1109
2022-03-20 19:18:52 - train: epoch 0060, iter [00100, 00390], lr: 0.100000, loss: 1.1461
2022-03-20 19:19:04 - train: epoch 0060, iter [00150, 00390], lr: 0.100000, loss: 1.0280
2022-03-20 19:19:15 - train: epoch 0060, iter [00200, 00390], lr: 0.100000, loss: 1.0795
2022-03-20 19:19:26 - train: epoch 0060, iter [00250, 00390], lr: 0.100000, loss: 1.1325
2022-03-20 19:19:37 - train: epoch 0060, iter [00300, 00390], lr: 0.100000, loss: 1.0571
2022-03-20 19:19:48 - train: epoch 0060, iter [00350, 00390], lr: 0.100000, loss: 1.2298
2022-03-20 19:19:58 - train: epoch 060, train_loss: 1.1345
2022-03-20 19:20:05 - eval: epoch: 060, acc1: 59.290%, acc5: 86.890%, test_loss: 1.4802, per_image_load_time: 0.333ms, per_image_inference_time: 0.412ms
2022-03-20 19:20:07 - until epoch: 060, best_acc1: 60.420%
2022-03-20 19:20:07 - epoch 061 lr: 0.020000000000000004
2022-03-20 19:20:22 - train: epoch 0061, iter [00050, 00390], lr: 0.020000, loss: 0.6212
2022-03-20 19:20:33 - train: epoch 0061, iter [00100, 00390], lr: 0.020000, loss: 0.5943
2022-03-20 19:20:44 - train: epoch 0061, iter [00150, 00390], lr: 0.020000, loss: 0.7022
2022-03-20 19:20:55 - train: epoch 0061, iter [00200, 00390], lr: 0.020000, loss: 0.7388
2022-03-20 19:21:06 - train: epoch 0061, iter [00250, 00390], lr: 0.020000, loss: 0.4749
2022-03-20 19:21:17 - train: epoch 0061, iter [00300, 00390], lr: 0.020000, loss: 0.4952
2022-03-20 19:21:29 - train: epoch 0061, iter [00350, 00390], lr: 0.020000, loss: 0.5785
2022-03-20 19:21:38 - train: epoch 061, train_loss: 0.6552
2022-03-20 19:21:46 - eval: epoch: 061, acc1: 74.150%, acc5: 93.810%, test_loss: 0.8984, per_image_load_time: 0.338ms, per_image_inference_time: 0.404ms
2022-03-20 19:21:48 - until epoch: 061, best_acc1: 74.150%
2022-03-20 19:21:48 - epoch 062 lr: 0.020000000000000004
2022-03-20 19:22:03 - train: epoch 0062, iter [00050, 00390], lr: 0.020000, loss: 0.4084
2022-03-20 19:22:14 - train: epoch 0062, iter [00100, 00390], lr: 0.020000, loss: 0.5106
2022-03-20 19:22:25 - train: epoch 0062, iter [00150, 00390], lr: 0.020000, loss: 0.5109
2022-03-20 19:22:36 - train: epoch 0062, iter [00200, 00390], lr: 0.020000, loss: 0.3809
2022-03-20 19:22:47 - train: epoch 0062, iter [00250, 00390], lr: 0.020000, loss: 0.5239
2022-03-20 19:22:58 - train: epoch 0062, iter [00300, 00390], lr: 0.020000, loss: 0.3932
2022-03-20 19:23:10 - train: epoch 0062, iter [00350, 00390], lr: 0.020000, loss: 0.5692
2022-03-20 19:23:19 - train: epoch 062, train_loss: 0.5169
2022-03-20 19:23:27 - eval: epoch: 062, acc1: 73.960%, acc5: 93.880%, test_loss: 0.9142, per_image_load_time: 0.339ms, per_image_inference_time: 0.403ms
2022-03-20 19:23:27 - until epoch: 062, best_acc1: 74.150%
2022-03-20 19:23:27 - epoch 063 lr: 0.020000000000000004
2022-03-20 19:23:42 - train: epoch 0063, iter [00050, 00390], lr: 0.020000, loss: 0.4731
2022-03-20 19:23:53 - train: epoch 0063, iter [00100, 00390], lr: 0.020000, loss: 0.4232
2022-03-20 19:24:04 - train: epoch 0063, iter [00150, 00390], lr: 0.020000, loss: 0.3658
2022-03-20 19:24:15 - train: epoch 0063, iter [00200, 00390], lr: 0.020000, loss: 0.4511
2022-03-20 19:24:27 - train: epoch 0063, iter [00250, 00390], lr: 0.020000, loss: 0.6054
2022-03-20 19:24:38 - train: epoch 0063, iter [00300, 00390], lr: 0.020000, loss: 0.5368
2022-03-20 19:24:49 - train: epoch 0063, iter [00350, 00390], lr: 0.020000, loss: 0.4672
2022-03-20 19:24:58 - train: epoch 063, train_loss: 0.4510
2022-03-20 19:25:06 - eval: epoch: 063, acc1: 74.030%, acc5: 94.230%, test_loss: 0.9159, per_image_load_time: 0.340ms, per_image_inference_time: 0.403ms
2022-03-20 19:25:07 - until epoch: 063, best_acc1: 74.150%
2022-03-20 19:25:07 - epoch 064 lr: 0.020000000000000004
2022-03-20 19:25:22 - train: epoch 0064, iter [00050, 00390], lr: 0.020000, loss: 0.2798
2022-03-20 19:25:34 - train: epoch 0064, iter [00100, 00390], lr: 0.020000, loss: 0.3420
2022-03-20 19:25:45 - train: epoch 0064, iter [00150, 00390], lr: 0.020000, loss: 0.5067
2022-03-20 19:25:56 - train: epoch 0064, iter [00200, 00390], lr: 0.020000, loss: 0.4276
2022-03-20 19:26:07 - train: epoch 0064, iter [00250, 00390], lr: 0.020000, loss: 0.4512
2022-03-20 19:26:18 - train: epoch 0064, iter [00300, 00390], lr: 0.020000, loss: 0.4324
2022-03-20 19:26:29 - train: epoch 0064, iter [00350, 00390], lr: 0.020000, loss: 0.3953
2022-03-20 19:26:39 - train: epoch 064, train_loss: 0.4130
2022-03-20 19:26:47 - eval: epoch: 064, acc1: 73.660%, acc5: 93.780%, test_loss: 0.9503, per_image_load_time: 0.354ms, per_image_inference_time: 0.404ms
2022-03-20 19:26:48 - until epoch: 064, best_acc1: 74.150%
2022-03-20 19:26:48 - epoch 065 lr: 0.020000000000000004
2022-03-20 19:27:03 - train: epoch 0065, iter [00050, 00390], lr: 0.020000, loss: 0.3640
2022-03-20 19:27:14 - train: epoch 0065, iter [00100, 00390], lr: 0.020000, loss: 0.4545
2022-03-20 19:27:25 - train: epoch 0065, iter [00150, 00390], lr: 0.020000, loss: 0.4198
2022-03-20 19:27:36 - train: epoch 0065, iter [00200, 00390], lr: 0.020000, loss: 0.4515
2022-03-20 19:27:48 - train: epoch 0065, iter [00250, 00390], lr: 0.020000, loss: 0.4254
2022-03-20 19:27:59 - train: epoch 0065, iter [00300, 00390], lr: 0.020000, loss: 0.4786
2022-03-20 19:28:10 - train: epoch 0065, iter [00350, 00390], lr: 0.020000, loss: 0.4887
2022-03-20 19:28:19 - train: epoch 065, train_loss: 0.3867
2022-03-20 19:28:27 - eval: epoch: 065, acc1: 73.010%, acc5: 93.550%, test_loss: 1.0093, per_image_load_time: 0.342ms, per_image_inference_time: 0.394ms
2022-03-20 19:28:28 - until epoch: 065, best_acc1: 74.150%
2022-03-20 19:28:28 - epoch 066 lr: 0.020000000000000004
2022-03-20 19:28:43 - train: epoch 0066, iter [00050, 00390], lr: 0.020000, loss: 0.3513
2022-03-20 19:28:54 - train: epoch 0066, iter [00100, 00390], lr: 0.020000, loss: 0.2722
2022-03-20 19:29:05 - train: epoch 0066, iter [00150, 00390], lr: 0.020000, loss: 0.3840
2022-03-20 19:29:17 - train: epoch 0066, iter [00200, 00390], lr: 0.020000, loss: 0.2800
2022-03-20 19:29:28 - train: epoch 0066, iter [00250, 00390], lr: 0.020000, loss: 0.3856
2022-03-20 19:29:39 - train: epoch 0066, iter [00300, 00390], lr: 0.020000, loss: 0.3284
2022-03-20 19:29:50 - train: epoch 0066, iter [00350, 00390], lr: 0.020000, loss: 0.4322
2022-03-20 19:29:59 - train: epoch 066, train_loss: 0.3714
2022-03-20 19:30:07 - eval: epoch: 066, acc1: 73.340%, acc5: 93.530%, test_loss: 0.9903, per_image_load_time: 0.337ms, per_image_inference_time: 0.415ms
2022-03-20 19:30:08 - until epoch: 066, best_acc1: 74.150%
2022-03-20 19:30:08 - epoch 067 lr: 0.020000000000000004
2022-03-20 19:30:23 - train: epoch 0067, iter [00050, 00390], lr: 0.020000, loss: 0.3971
2022-03-20 19:30:34 - train: epoch 0067, iter [00100, 00390], lr: 0.020000, loss: 0.3199
2022-03-20 19:30:45 - train: epoch 0067, iter [00150, 00390], lr: 0.020000, loss: 0.3286
2022-03-20 19:30:56 - train: epoch 0067, iter [00200, 00390], lr: 0.020000, loss: 0.2533
2022-03-20 19:31:07 - train: epoch 0067, iter [00250, 00390], lr: 0.020000, loss: 0.4030
2022-03-20 19:31:18 - train: epoch 0067, iter [00300, 00390], lr: 0.020000, loss: 0.3678
2022-03-20 19:31:29 - train: epoch 0067, iter [00350, 00390], lr: 0.020000, loss: 0.3284
2022-03-20 19:31:38 - train: epoch 067, train_loss: 0.3590
2022-03-20 19:31:46 - eval: epoch: 067, acc1: 72.860%, acc5: 93.140%, test_loss: 1.0250, per_image_load_time: 0.339ms, per_image_inference_time: 0.413ms
2022-03-20 19:31:48 - until epoch: 067, best_acc1: 74.150%
2022-03-20 19:31:48 - epoch 068 lr: 0.020000000000000004
2022-03-20 19:32:02 - train: epoch 0068, iter [00050, 00390], lr: 0.020000, loss: 0.2675
2022-03-20 19:32:14 - train: epoch 0068, iter [00100, 00390], lr: 0.020000, loss: 0.2149
2022-03-20 19:32:25 - train: epoch 0068, iter [00150, 00390], lr: 0.020000, loss: 0.2986
2022-03-20 19:32:36 - train: epoch 0068, iter [00200, 00390], lr: 0.020000, loss: 0.4334
2022-03-20 19:32:47 - train: epoch 0068, iter [00250, 00390], lr: 0.020000, loss: 0.3123
2022-03-20 19:32:58 - train: epoch 0068, iter [00300, 00390], lr: 0.020000, loss: 0.2731
2022-03-20 19:33:09 - train: epoch 0068, iter [00350, 00390], lr: 0.020000, loss: 0.4963
2022-03-20 19:33:18 - train: epoch 068, train_loss: 0.3501
2022-03-20 19:33:26 - eval: epoch: 068, acc1: 71.990%, acc5: 92.750%, test_loss: 1.0903, per_image_load_time: 0.344ms, per_image_inference_time: 0.412ms
2022-03-20 19:33:28 - until epoch: 068, best_acc1: 74.150%
2022-03-20 19:33:28 - epoch 069 lr: 0.020000000000000004
2022-03-20 19:33:42 - train: epoch 0069, iter [00050, 00390], lr: 0.020000, loss: 0.2582
2022-03-20 19:33:54 - train: epoch 0069, iter [00100, 00390], lr: 0.020000, loss: 0.2457
2022-03-20 19:34:05 - train: epoch 0069, iter [00150, 00390], lr: 0.020000, loss: 0.3075
2022-03-20 19:34:16 - train: epoch 0069, iter [00200, 00390], lr: 0.020000, loss: 0.3700
2022-03-20 19:34:27 - train: epoch 0069, iter [00250, 00390], lr: 0.020000, loss: 0.3403
2022-03-20 19:34:38 - train: epoch 0069, iter [00300, 00390], lr: 0.020000, loss: 0.3520
2022-03-20 19:34:49 - train: epoch 0069, iter [00350, 00390], lr: 0.020000, loss: 0.2951
2022-03-20 19:34:59 - train: epoch 069, train_loss: 0.3474
2022-03-20 19:35:07 - eval: epoch: 069, acc1: 70.990%, acc5: 92.570%, test_loss: 1.1157, per_image_load_time: 0.357ms, per_image_inference_time: 0.410ms
2022-03-20 19:35:08 - until epoch: 069, best_acc1: 74.150%
2022-03-20 19:35:08 - epoch 070 lr: 0.020000000000000004
2022-03-20 19:35:23 - train: epoch 0070, iter [00050, 00390], lr: 0.020000, loss: 0.2934
2022-03-20 19:35:34 - train: epoch 0070, iter [00100, 00390], lr: 0.020000, loss: 0.3985
2022-03-20 19:35:45 - train: epoch 0070, iter [00150, 00390], lr: 0.020000, loss: 0.4015
2022-03-20 19:35:56 - train: epoch 0070, iter [00200, 00390], lr: 0.020000, loss: 0.3045
2022-03-20 19:36:08 - train: epoch 0070, iter [00250, 00390], lr: 0.020000, loss: 0.2850
2022-03-20 19:36:19 - train: epoch 0070, iter [00300, 00390], lr: 0.020000, loss: 0.3596
2022-03-20 19:36:30 - train: epoch 0070, iter [00350, 00390], lr: 0.020000, loss: 0.3384
2022-03-20 19:36:39 - train: epoch 070, train_loss: 0.3502
2022-03-20 19:36:47 - eval: epoch: 070, acc1: 69.580%, acc5: 92.300%, test_loss: 1.2004, per_image_load_time: 0.333ms, per_image_inference_time: 0.404ms
2022-03-20 19:36:48 - until epoch: 070, best_acc1: 74.150%
2022-03-20 19:36:48 - epoch 071 lr: 0.020000000000000004
2022-03-20 19:37:03 - train: epoch 0071, iter [00050, 00390], lr: 0.020000, loss: 0.3035
2022-03-20 19:37:14 - train: epoch 0071, iter [00100, 00390], lr: 0.020000, loss: 0.2705
2022-03-20 19:37:25 - train: epoch 0071, iter [00150, 00390], lr: 0.020000, loss: 0.2969
2022-03-20 19:37:36 - train: epoch 0071, iter [00200, 00390], lr: 0.020000, loss: 0.3983
2022-03-20 19:37:47 - train: epoch 0071, iter [00250, 00390], lr: 0.020000, loss: 0.3340
2022-03-20 19:37:59 - train: epoch 0071, iter [00300, 00390], lr: 0.020000, loss: 0.5005
2022-03-20 19:38:10 - train: epoch 0071, iter [00350, 00390], lr: 0.020000, loss: 0.3755
2022-03-20 19:38:19 - train: epoch 071, train_loss: 0.3467
2022-03-20 19:38:27 - eval: epoch: 071, acc1: 70.490%, acc5: 92.440%, test_loss: 1.1378, per_image_load_time: 0.338ms, per_image_inference_time: 0.413ms
2022-03-20 19:38:29 - until epoch: 071, best_acc1: 74.150%
2022-03-20 19:38:29 - epoch 072 lr: 0.020000000000000004
2022-03-20 19:38:43 - train: epoch 0072, iter [00050, 00390], lr: 0.020000, loss: 0.3641
2022-03-20 19:38:54 - train: epoch 0072, iter [00100, 00390], lr: 0.020000, loss: 0.4186
2022-03-20 19:39:05 - train: epoch 0072, iter [00150, 00390], lr: 0.020000, loss: 0.3505
2022-03-20 19:39:16 - train: epoch 0072, iter [00200, 00390], lr: 0.020000, loss: 0.2753
2022-03-20 19:39:27 - train: epoch 0072, iter [00250, 00390], lr: 0.020000, loss: 0.3088
2022-03-20 19:39:38 - train: epoch 0072, iter [00300, 00390], lr: 0.020000, loss: 0.2291
2022-03-20 19:39:50 - train: epoch 0072, iter [00350, 00390], lr: 0.020000, loss: 0.4750
2022-03-20 19:39:59 - train: epoch 072, train_loss: 0.3520
2022-03-20 19:40:06 - eval: epoch: 072, acc1: 69.540%, acc5: 91.350%, test_loss: 1.2145, per_image_load_time: 0.315ms, per_image_inference_time: 0.395ms
2022-03-20 19:40:08 - until epoch: 072, best_acc1: 74.150%
2022-03-20 19:40:08 - epoch 073 lr: 0.020000000000000004
2022-03-20 19:40:23 - train: epoch 0073, iter [00050, 00390], lr: 0.020000, loss: 0.2706
2022-03-20 19:40:34 - train: epoch 0073, iter [00100, 00390], lr: 0.020000, loss: 0.2762
2022-03-20 19:40:45 - train: epoch 0073, iter [00150, 00390], lr: 0.020000, loss: 0.4263
2022-03-20 19:40:56 - train: epoch 0073, iter [00200, 00390], lr: 0.020000, loss: 0.3813
2022-03-20 19:41:08 - train: epoch 0073, iter [00250, 00390], lr: 0.020000, loss: 0.3606
2022-03-20 19:41:19 - train: epoch 0073, iter [00300, 00390], lr: 0.020000, loss: 0.4189
2022-03-20 19:41:30 - train: epoch 0073, iter [00350, 00390], lr: 0.020000, loss: 0.3896
2022-03-20 19:41:39 - train: epoch 073, train_loss: 0.3530
2022-03-20 19:41:47 - eval: epoch: 073, acc1: 70.320%, acc5: 92.240%, test_loss: 1.1522, per_image_load_time: 0.339ms, per_image_inference_time: 0.406ms
2022-03-20 19:41:48 - until epoch: 073, best_acc1: 74.150%
2022-03-20 19:41:48 - epoch 074 lr: 0.020000000000000004
2022-03-20 19:42:03 - train: epoch 0074, iter [00050, 00390], lr: 0.020000, loss: 0.3144
2022-03-20 19:42:15 - train: epoch 0074, iter [00100, 00390], lr: 0.020000, loss: 0.3404
2022-03-20 19:42:26 - train: epoch 0074, iter [00150, 00390], lr: 0.020000, loss: 0.4123
2022-03-20 19:42:37 - train: epoch 0074, iter [00200, 00390], lr: 0.020000, loss: 0.3181
2022-03-20 19:42:47 - train: epoch 0074, iter [00250, 00390], lr: 0.020000, loss: 0.3809
2022-03-20 19:42:58 - train: epoch 0074, iter [00300, 00390], lr: 0.020000, loss: 0.3331
2022-03-20 19:43:09 - train: epoch 0074, iter [00350, 00390], lr: 0.020000, loss: 0.3450
2022-03-20 19:43:19 - train: epoch 074, train_loss: 0.3497
2022-03-20 19:43:27 - eval: epoch: 074, acc1: 69.480%, acc5: 91.490%, test_loss: 1.1932, per_image_load_time: 0.354ms, per_image_inference_time: 0.416ms
2022-03-20 19:43:28 - until epoch: 074, best_acc1: 74.150%
2022-03-20 19:43:28 - epoch 075 lr: 0.020000000000000004
2022-03-20 19:43:43 - train: epoch 0075, iter [00050, 00390], lr: 0.020000, loss: 0.4338
2022-03-20 19:43:54 - train: epoch 0075, iter [00100, 00390], lr: 0.020000, loss: 0.3170
2022-03-20 19:44:07 - train: epoch 0075, iter [00150, 00390], lr: 0.020000, loss: 0.3897
2022-03-20 19:44:19 - train: epoch 0075, iter [00200, 00390], lr: 0.020000, loss: 0.3454
2022-03-20 19:44:30 - train: epoch 0075, iter [00250, 00390], lr: 0.020000, loss: 0.3665
2022-03-20 19:44:41 - train: epoch 0075, iter [00300, 00390], lr: 0.020000, loss: 0.2840
2022-03-20 19:44:53 - train: epoch 0075, iter [00350, 00390], lr: 0.020000, loss: 0.5153
2022-03-20 19:45:03 - train: epoch 075, train_loss: 0.3383
2022-03-20 19:45:10 - eval: epoch: 075, acc1: 70.180%, acc5: 92.230%, test_loss: 1.1568, per_image_load_time: 0.331ms, per_image_inference_time: 0.399ms
2022-03-20 19:45:12 - until epoch: 075, best_acc1: 74.150%
2022-03-20 19:45:12 - epoch 076 lr: 0.020000000000000004
2022-03-20 19:45:27 - train: epoch 0076, iter [00050, 00390], lr: 0.020000, loss: 0.3177
2022-03-20 19:45:38 - train: epoch 0076, iter [00100, 00390], lr: 0.020000, loss: 0.3506
2022-03-20 19:45:49 - train: epoch 0076, iter [00150, 00390], lr: 0.020000, loss: 0.2813
2022-03-20 19:46:00 - train: epoch 0076, iter [00200, 00390], lr: 0.020000, loss: 0.3253
2022-03-20 19:46:11 - train: epoch 0076, iter [00250, 00390], lr: 0.020000, loss: 0.3276
2022-03-20 19:46:22 - train: epoch 0076, iter [00300, 00390], lr: 0.020000, loss: 0.4549
2022-03-20 19:46:33 - train: epoch 0076, iter [00350, 00390], lr: 0.020000, loss: 0.4596
2022-03-20 19:46:42 - train: epoch 076, train_loss: 0.3456
2022-03-20 19:46:50 - eval: epoch: 076, acc1: 69.830%, acc5: 91.380%, test_loss: 1.1981, per_image_load_time: 0.339ms, per_image_inference_time: 0.406ms
2022-03-20 19:46:52 - until epoch: 076, best_acc1: 74.150%
2022-03-20 19:46:52 - epoch 077 lr: 0.020000000000000004
2022-03-20 19:47:06 - train: epoch 0077, iter [00050, 00390], lr: 0.020000, loss: 0.2363
2022-03-20 19:47:17 - train: epoch 0077, iter [00100, 00390], lr: 0.020000, loss: 0.3328
2022-03-20 19:47:29 - train: epoch 0077, iter [00150, 00390], lr: 0.020000, loss: 0.3069
2022-03-20 19:47:40 - train: epoch 0077, iter [00200, 00390], lr: 0.020000, loss: 0.3977
2022-03-20 19:47:51 - train: epoch 0077, iter [00250, 00390], lr: 0.020000, loss: 0.3443
2022-03-20 19:48:02 - train: epoch 0077, iter [00300, 00390], lr: 0.020000, loss: 0.4480
2022-03-20 19:48:13 - train: epoch 0077, iter [00350, 00390], lr: 0.020000, loss: 0.4494
2022-03-20 19:48:23 - train: epoch 077, train_loss: 0.3490
2022-03-20 19:48:31 - eval: epoch: 077, acc1: 68.050%, acc5: 90.900%, test_loss: 1.2481, per_image_load_time: 0.313ms, per_image_inference_time: 0.415ms
2022-03-20 19:48:32 - until epoch: 077, best_acc1: 74.150%
2022-03-20 19:48:32 - epoch 078 lr: 0.020000000000000004
2022-03-20 19:48:47 - train: epoch 0078, iter [00050, 00390], lr: 0.020000, loss: 0.3180
2022-03-20 19:48:58 - train: epoch 0078, iter [00100, 00390], lr: 0.020000, loss: 0.2269
2022-03-20 19:49:09 - train: epoch 0078, iter [00150, 00390], lr: 0.020000, loss: 0.4090
2022-03-20 19:49:21 - train: epoch 0078, iter [00200, 00390], lr: 0.020000, loss: 0.2765
2022-03-20 19:49:32 - train: epoch 0078, iter [00250, 00390], lr: 0.020000, loss: 0.3416
2022-03-20 19:49:43 - train: epoch 0078, iter [00300, 00390], lr: 0.020000, loss: 0.4059
2022-03-20 19:49:54 - train: epoch 0078, iter [00350, 00390], lr: 0.020000, loss: 0.2676
2022-03-20 19:50:03 - train: epoch 078, train_loss: 0.3451
2022-03-20 19:50:11 - eval: epoch: 078, acc1: 70.520%, acc5: 92.010%, test_loss: 1.1475, per_image_load_time: 0.320ms, per_image_inference_time: 0.410ms
2022-03-20 19:50:13 - until epoch: 078, best_acc1: 74.150%
2022-03-20 19:50:13 - epoch 079 lr: 0.020000000000000004
2022-03-20 19:50:28 - train: epoch 0079, iter [00050, 00390], lr: 0.020000, loss: 0.2656
2022-03-20 19:50:39 - train: epoch 0079, iter [00100, 00390], lr: 0.020000, loss: 0.2726
2022-03-20 19:50:51 - train: epoch 0079, iter [00150, 00390], lr: 0.020000, loss: 0.3609
2022-03-20 19:51:02 - train: epoch 0079, iter [00200, 00390], lr: 0.020000, loss: 0.2867
2022-03-20 19:51:13 - train: epoch 0079, iter [00250, 00390], lr: 0.020000, loss: 0.4038
2022-03-20 19:51:24 - train: epoch 0079, iter [00300, 00390], lr: 0.020000, loss: 0.5368
2022-03-20 19:51:35 - train: epoch 0079, iter [00350, 00390], lr: 0.020000, loss: 0.5017
2022-03-20 19:51:45 - train: epoch 079, train_loss: 0.3388
2022-03-20 19:51:53 - eval: epoch: 079, acc1: 69.370%, acc5: 91.240%, test_loss: 1.2395, per_image_load_time: 0.316ms, per_image_inference_time: 0.417ms
2022-03-20 19:51:54 - until epoch: 079, best_acc1: 74.150%
2022-03-20 19:51:54 - epoch 080 lr: 0.020000000000000004
2022-03-20 19:52:08 - train: epoch 0080, iter [00050, 00390], lr: 0.020000, loss: 0.3317
2022-03-20 19:52:19 - train: epoch 0080, iter [00100, 00390], lr: 0.020000, loss: 0.4551
2022-03-20 19:52:30 - train: epoch 0080, iter [00150, 00390], lr: 0.020000, loss: 0.4293
2022-03-20 19:52:42 - train: epoch 0080, iter [00200, 00390], lr: 0.020000, loss: 0.3238
2022-03-20 19:52:53 - train: epoch 0080, iter [00250, 00390], lr: 0.020000, loss: 0.3670
2022-03-20 19:53:04 - train: epoch 0080, iter [00300, 00390], lr: 0.020000, loss: 0.4112
2022-03-20 19:53:15 - train: epoch 0080, iter [00350, 00390], lr: 0.020000, loss: 0.5101
2022-03-20 19:53:24 - train: epoch 080, train_loss: 0.3474
2022-03-20 19:53:32 - eval: epoch: 080, acc1: 71.210%, acc5: 92.340%, test_loss: 1.1340, per_image_load_time: 0.335ms, per_image_inference_time: 0.408ms
2022-03-20 19:53:34 - until epoch: 080, best_acc1: 74.150%
2022-03-20 19:53:34 - epoch 081 lr: 0.020000000000000004
2022-03-20 19:53:48 - train: epoch 0081, iter [00050, 00390], lr: 0.020000, loss: 0.4201
2022-03-20 19:53:59 - train: epoch 0081, iter [00100, 00390], lr: 0.020000, loss: 0.2726
2022-03-20 19:54:10 - train: epoch 0081, iter [00150, 00390], lr: 0.020000, loss: 0.2888
2022-03-20 19:54:22 - train: epoch 0081, iter [00200, 00390], lr: 0.020000, loss: 0.3056
2022-03-20 19:54:33 - train: epoch 0081, iter [00250, 00390], lr: 0.020000, loss: 0.2713
2022-03-20 19:54:44 - train: epoch 0081, iter [00300, 00390], lr: 0.020000, loss: 0.3401
2022-03-20 19:54:55 - train: epoch 0081, iter [00350, 00390], lr: 0.020000, loss: 0.3367
2022-03-20 19:55:04 - train: epoch 081, train_loss: 0.3309
2022-03-20 19:55:12 - eval: epoch: 081, acc1: 68.390%, acc5: 91.390%, test_loss: 1.2468, per_image_load_time: 0.331ms, per_image_inference_time: 0.428ms
2022-03-20 19:55:14 - until epoch: 081, best_acc1: 74.150%
2022-03-20 19:55:14 - epoch 082 lr: 0.020000000000000004
2022-03-20 19:55:30 - train: epoch 0082, iter [00050, 00390], lr: 0.020000, loss: 0.2030
2022-03-20 19:55:41 - train: epoch 0082, iter [00100, 00390], lr: 0.020000, loss: 0.2735
2022-03-20 19:55:52 - train: epoch 0082, iter [00150, 00390], lr: 0.020000, loss: 0.3191
2022-03-20 19:56:03 - train: epoch 0082, iter [00200, 00390], lr: 0.020000, loss: 0.4267
2022-03-20 19:56:14 - train: epoch 0082, iter [00250, 00390], lr: 0.020000, loss: 0.3522
2022-03-20 19:56:25 - train: epoch 0082, iter [00300, 00390], lr: 0.020000, loss: 0.3369
2022-03-20 19:56:37 - train: epoch 0082, iter [00350, 00390], lr: 0.020000, loss: 0.5247
2022-03-20 19:56:46 - train: epoch 082, train_loss: 0.3306
2022-03-20 19:56:54 - eval: epoch: 082, acc1: 68.970%, acc5: 91.270%, test_loss: 1.2597, per_image_load_time: 0.333ms, per_image_inference_time: 0.402ms
2022-03-20 19:56:55 - until epoch: 082, best_acc1: 74.150%
2022-03-20 19:56:55 - epoch 083 lr: 0.020000000000000004
2022-03-20 19:57:10 - train: epoch 0083, iter [00050, 00390], lr: 0.020000, loss: 0.3217
2022-03-20 19:57:21 - train: epoch 0083, iter [00100, 00390], lr: 0.020000, loss: 0.3506
2022-03-20 19:57:32 - train: epoch 0083, iter [00150, 00390], lr: 0.020000, loss: 0.2675
2022-03-20 19:57:43 - train: epoch 0083, iter [00200, 00390], lr: 0.020000, loss: 0.2490
2022-03-20 19:57:54 - train: epoch 0083, iter [00250, 00390], lr: 0.020000, loss: 0.4554
2022-03-20 19:58:05 - train: epoch 0083, iter [00300, 00390], lr: 0.020000, loss: 0.3585
2022-03-20 19:58:16 - train: epoch 0083, iter [00350, 00390], lr: 0.020000, loss: 0.4452
2022-03-20 19:58:25 - train: epoch 083, train_loss: 0.3221
2022-03-20 19:58:33 - eval: epoch: 083, acc1: 68.950%, acc5: 91.370%, test_loss: 1.2302, per_image_load_time: 0.332ms, per_image_inference_time: 0.397ms
2022-03-20 19:58:34 - until epoch: 083, best_acc1: 74.150%
2022-03-20 19:58:34 - epoch 084 lr: 0.020000000000000004
2022-03-20 19:58:49 - train: epoch 0084, iter [00050, 00390], lr: 0.020000, loss: 0.4059
2022-03-20 19:59:00 - train: epoch 0084, iter [00100, 00390], lr: 0.020000, loss: 0.2609
2022-03-20 19:59:11 - train: epoch 0084, iter [00150, 00390], lr: 0.020000, loss: 0.3127
2022-03-20 19:59:22 - train: epoch 0084, iter [00200, 00390], lr: 0.020000, loss: 0.2299
2022-03-20 19:59:33 - train: epoch 0084, iter [00250, 00390], lr: 0.020000, loss: 0.2504
2022-03-20 19:59:44 - train: epoch 0084, iter [00300, 00390], lr: 0.020000, loss: 0.5328
2022-03-20 19:59:55 - train: epoch 0084, iter [00350, 00390], lr: 0.020000, loss: 0.3595
2022-03-20 20:00:04 - train: epoch 084, train_loss: 0.3190
2022-03-20 20:00:12 - eval: epoch: 084, acc1: 69.180%, acc5: 91.370%, test_loss: 1.2748, per_image_load_time: 0.376ms, per_image_inference_time: 0.403ms
2022-03-20 20:00:14 - until epoch: 084, best_acc1: 74.150%
2022-03-20 20:00:14 - epoch 085 lr: 0.020000000000000004
2022-03-20 20:00:28 - train: epoch 0085, iter [00050, 00390], lr: 0.020000, loss: 0.2163
2022-03-20 20:00:39 - train: epoch 0085, iter [00100, 00390], lr: 0.020000, loss: 0.2776
2022-03-20 20:00:50 - train: epoch 0085, iter [00150, 00390], lr: 0.020000, loss: 0.3404
2022-03-20 20:01:01 - train: epoch 0085, iter [00200, 00390], lr: 0.020000, loss: 0.2341
2022-03-20 20:01:12 - train: epoch 0085, iter [00250, 00390], lr: 0.020000, loss: 0.2619
2022-03-20 20:01:23 - train: epoch 0085, iter [00300, 00390], lr: 0.020000, loss: 0.3073
2022-03-20 20:01:34 - train: epoch 0085, iter [00350, 00390], lr: 0.020000, loss: 0.4250
2022-03-20 20:01:43 - train: epoch 085, train_loss: 0.3275
2022-03-20 20:01:51 - eval: epoch: 085, acc1: 69.000%, acc5: 91.460%, test_loss: 1.2163, per_image_load_time: 0.326ms, per_image_inference_time: 0.396ms
2022-03-20 20:01:52 - until epoch: 085, best_acc1: 74.150%
2022-03-20 20:01:52 - epoch 086 lr: 0.020000000000000004
2022-03-20 20:02:06 - train: epoch 0086, iter [00050, 00390], lr: 0.020000, loss: 0.2666
2022-03-20 20:02:17 - train: epoch 0086, iter [00100, 00390], lr: 0.020000, loss: 0.2238
2022-03-20 20:02:28 - train: epoch 0086, iter [00150, 00390], lr: 0.020000, loss: 0.2645
2022-03-20 20:02:39 - train: epoch 0086, iter [00200, 00390], lr: 0.020000, loss: 0.5219
2022-03-20 20:02:50 - train: epoch 0086, iter [00250, 00390], lr: 0.020000, loss: 0.2975
2022-03-20 20:03:01 - train: epoch 0086, iter [00300, 00390], lr: 0.020000, loss: 0.2758
2022-03-20 20:03:12 - train: epoch 0086, iter [00350, 00390], lr: 0.020000, loss: 0.3653
2022-03-20 20:03:21 - train: epoch 086, train_loss: 0.3181
2022-03-20 20:03:30 - eval: epoch: 086, acc1: 69.070%, acc5: 91.380%, test_loss: 1.2407, per_image_load_time: 0.370ms, per_image_inference_time: 0.404ms
2022-03-20 20:03:31 - until epoch: 086, best_acc1: 74.150%
2022-03-20 20:03:31 - epoch 087 lr: 0.020000000000000004
2022-03-20 20:03:46 - train: epoch 0087, iter [00050, 00390], lr: 0.020000, loss: 0.2336
2022-03-20 20:03:57 - train: epoch 0087, iter [00100, 00390], lr: 0.020000, loss: 0.2699
2022-03-20 20:04:08 - train: epoch 0087, iter [00150, 00390], lr: 0.020000, loss: 0.2886
2022-03-20 20:04:19 - train: epoch 0087, iter [00200, 00390], lr: 0.020000, loss: 0.3145
2022-03-20 20:04:30 - train: epoch 0087, iter [00250, 00390], lr: 0.020000, loss: 0.3246
2022-03-20 20:04:41 - train: epoch 0087, iter [00300, 00390], lr: 0.020000, loss: 0.4193
2022-03-20 20:04:52 - train: epoch 0087, iter [00350, 00390], lr: 0.020000, loss: 0.3597
2022-03-20 20:05:01 - train: epoch 087, train_loss: 0.3230
2022-03-20 20:05:09 - eval: epoch: 087, acc1: 68.310%, acc5: 90.640%, test_loss: 1.2658, per_image_load_time: 0.335ms, per_image_inference_time: 0.398ms
2022-03-20 20:05:10 - until epoch: 087, best_acc1: 74.150%
2022-03-20 20:05:10 - epoch 088 lr: 0.020000000000000004
2022-03-20 20:05:25 - train: epoch 0088, iter [00050, 00390], lr: 0.020000, loss: 0.2680
2022-03-20 20:05:36 - train: epoch 0088, iter [00100, 00390], lr: 0.020000, loss: 0.3206
2022-03-20 20:05:47 - train: epoch 0088, iter [00150, 00390], lr: 0.020000, loss: 0.3872
2022-03-20 20:05:58 - train: epoch 0088, iter [00200, 00390], lr: 0.020000, loss: 0.4509
2022-03-20 20:06:09 - train: epoch 0088, iter [00250, 00390], lr: 0.020000, loss: 0.2891
2022-03-20 20:06:20 - train: epoch 0088, iter [00300, 00390], lr: 0.020000, loss: 0.4310
2022-03-20 20:06:31 - train: epoch 0088, iter [00350, 00390], lr: 0.020000, loss: 0.3748
2022-03-20 20:06:40 - train: epoch 088, train_loss: 0.3170
2022-03-20 20:06:48 - eval: epoch: 088, acc1: 69.240%, acc5: 91.160%, test_loss: 1.2328, per_image_load_time: 0.339ms, per_image_inference_time: 0.413ms
2022-03-20 20:06:49 - until epoch: 088, best_acc1: 74.150%
2022-03-20 20:06:49 - epoch 089 lr: 0.020000000000000004
2022-03-20 20:07:04 - train: epoch 0089, iter [00050, 00390], lr: 0.020000, loss: 0.2913
2022-03-20 20:07:15 - train: epoch 0089, iter [00100, 00390], lr: 0.020000, loss: 0.1826
2022-03-20 20:07:26 - train: epoch 0089, iter [00150, 00390], lr: 0.020000, loss: 0.2539
2022-03-20 20:07:37 - train: epoch 0089, iter [00200, 00390], lr: 0.020000, loss: 0.3542
2022-03-20 20:07:48 - train: epoch 0089, iter [00250, 00390], lr: 0.020000, loss: 0.4877
2022-03-20 20:07:59 - train: epoch 0089, iter [00300, 00390], lr: 0.020000, loss: 0.3464
2022-03-20 20:08:10 - train: epoch 0089, iter [00350, 00390], lr: 0.020000, loss: 0.2881
2022-03-20 20:08:20 - train: epoch 089, train_loss: 0.3082
2022-03-20 20:08:28 - eval: epoch: 089, acc1: 68.680%, acc5: 90.730%, test_loss: 1.3272, per_image_load_time: 0.338ms, per_image_inference_time: 0.409ms
2022-03-20 20:08:29 - until epoch: 089, best_acc1: 74.150%
2022-03-20 20:08:29 - epoch 090 lr: 0.020000000000000004
2022-03-20 20:08:44 - train: epoch 0090, iter [00050, 00390], lr: 0.020000, loss: 0.2412
2022-03-20 20:08:55 - train: epoch 0090, iter [00100, 00390], lr: 0.020000, loss: 0.2625
2022-03-20 20:09:06 - train: epoch 0090, iter [00150, 00390], lr: 0.020000, loss: 0.2628
2022-03-20 20:09:17 - train: epoch 0090, iter [00200, 00390], lr: 0.020000, loss: 0.3590
2022-03-20 20:09:28 - train: epoch 0090, iter [00250, 00390], lr: 0.020000, loss: 0.3154
2022-03-20 20:09:39 - train: epoch 0090, iter [00300, 00390], lr: 0.020000, loss: 0.3164
2022-03-20 20:09:50 - train: epoch 0090, iter [00350, 00390], lr: 0.020000, loss: 0.3035
2022-03-20 20:09:59 - train: epoch 090, train_loss: 0.3222
2022-03-20 20:10:07 - eval: epoch: 090, acc1: 69.590%, acc5: 91.470%, test_loss: 1.2110, per_image_load_time: 0.315ms, per_image_inference_time: 0.413ms
2022-03-20 20:10:09 - until epoch: 090, best_acc1: 74.150%
2022-03-20 20:10:09 - epoch 091 lr: 0.020000000000000004
2022-03-20 20:10:23 - train: epoch 0091, iter [00050, 00390], lr: 0.020000, loss: 0.2539
2022-03-20 20:10:35 - train: epoch 0091, iter [00100, 00390], lr: 0.020000, loss: 0.2126
2022-03-20 20:10:46 - train: epoch 0091, iter [00150, 00390], lr: 0.020000, loss: 0.2594
2022-03-20 20:10:57 - train: epoch 0091, iter [00200, 00390], lr: 0.020000, loss: 0.2116
2022-03-20 20:11:08 - train: epoch 0091, iter [00250, 00390], lr: 0.020000, loss: 0.4481
2022-03-20 20:11:19 - train: epoch 0091, iter [00300, 00390], lr: 0.020000, loss: 0.3172
2022-03-20 20:11:30 - train: epoch 0091, iter [00350, 00390], lr: 0.020000, loss: 0.2908
2022-03-20 20:11:39 - train: epoch 091, train_loss: 0.2981
2022-03-20 20:11:47 - eval: epoch: 091, acc1: 68.960%, acc5: 91.420%, test_loss: 1.2522, per_image_load_time: 0.349ms, per_image_inference_time: 0.407ms
2022-03-20 20:11:49 - until epoch: 091, best_acc1: 74.150%
2022-03-20 20:11:49 - epoch 092 lr: 0.020000000000000004
2022-03-20 20:12:04 - train: epoch 0092, iter [00050, 00390], lr: 0.020000, loss: 0.3277
2022-03-20 20:12:15 - train: epoch 0092, iter [00100, 00390], lr: 0.020000, loss: 0.1892
2022-03-20 20:12:26 - train: epoch 0092, iter [00150, 00390], lr: 0.020000, loss: 0.1836
2022-03-20 20:12:37 - train: epoch 0092, iter [00200, 00390], lr: 0.020000, loss: 0.2825
2022-03-20 20:12:48 - train: epoch 0092, iter [00250, 00390], lr: 0.020000, loss: 0.3573
2022-03-20 20:12:59 - train: epoch 0092, iter [00300, 00390], lr: 0.020000, loss: 0.3233
2022-03-20 20:13:10 - train: epoch 0092, iter [00350, 00390], lr: 0.020000, loss: 0.3808
2022-03-20 20:13:19 - train: epoch 092, train_loss: 0.3025
2022-03-20 20:13:27 - eval: epoch: 092, acc1: 68.260%, acc5: 90.510%, test_loss: 1.3232, per_image_load_time: 0.334ms, per_image_inference_time: 0.409ms
2022-03-20 20:13:29 - until epoch: 092, best_acc1: 74.150%
2022-03-20 20:13:29 - epoch 093 lr: 0.020000000000000004
2022-03-20 20:13:43 - train: epoch 0093, iter [00050, 00390], lr: 0.020000, loss: 0.2602
2022-03-20 20:13:54 - train: epoch 0093, iter [00100, 00390], lr: 0.020000, loss: 0.3149
2022-03-20 20:14:06 - train: epoch 0093, iter [00150, 00390], lr: 0.020000, loss: 0.2837
2022-03-20 20:14:17 - train: epoch 0093, iter [00200, 00390], lr: 0.020000, loss: 0.2641
2022-03-20 20:14:28 - train: epoch 0093, iter [00250, 00390], lr: 0.020000, loss: 0.3120
2022-03-20 20:14:39 - train: epoch 0093, iter [00300, 00390], lr: 0.020000, loss: 0.2951
2022-03-20 20:14:50 - train: epoch 0093, iter [00350, 00390], lr: 0.020000, loss: 0.2033
2022-03-20 20:15:00 - train: epoch 093, train_loss: 0.2931
2022-03-20 20:15:08 - eval: epoch: 093, acc1: 69.680%, acc5: 91.350%, test_loss: 1.2256, per_image_load_time: 0.346ms, per_image_inference_time: 0.413ms
2022-03-20 20:15:08 - until epoch: 093, best_acc1: 74.150%
2022-03-20 20:15:08 - epoch 094 lr: 0.020000000000000004
2022-03-20 20:15:23 - train: epoch 0094, iter [00050, 00390], lr: 0.020000, loss: 0.1997
2022-03-20 20:15:34 - train: epoch 0094, iter [00100, 00390], lr: 0.020000, loss: 0.3402
2022-03-20 20:15:45 - train: epoch 0094, iter [00150, 00390], lr: 0.020000, loss: 0.2681
2022-03-20 20:15:56 - train: epoch 0094, iter [00200, 00390], lr: 0.020000, loss: 0.1834
2022-03-20 20:16:07 - train: epoch 0094, iter [00250, 00390], lr: 0.020000, loss: 0.2035
2022-03-20 20:16:18 - train: epoch 0094, iter [00300, 00390], lr: 0.020000, loss: 0.2671
2022-03-20 20:16:29 - train: epoch 0094, iter [00350, 00390], lr: 0.020000, loss: 0.3132
2022-03-20 20:16:39 - train: epoch 094, train_loss: 0.2855
2022-03-20 20:16:47 - eval: epoch: 094, acc1: 69.450%, acc5: 90.980%, test_loss: 1.2822, per_image_load_time: 0.332ms, per_image_inference_time: 0.408ms
2022-03-20 20:16:48 - until epoch: 094, best_acc1: 74.150%
2022-03-20 20:16:48 - epoch 095 lr: 0.020000000000000004
2022-03-20 20:17:03 - train: epoch 0095, iter [00050, 00390], lr: 0.020000, loss: 0.2266
2022-03-20 20:17:14 - train: epoch 0095, iter [00100, 00390], lr: 0.020000, loss: 0.2833
2022-03-20 20:17:25 - train: epoch 0095, iter [00150, 00390], lr: 0.020000, loss: 0.2720
2022-03-20 20:17:36 - train: epoch 0095, iter [00200, 00390], lr: 0.020000, loss: 0.3176
2022-03-20 20:17:48 - train: epoch 0095, iter [00250, 00390], lr: 0.020000, loss: 0.3873
2022-03-20 20:17:59 - train: epoch 0095, iter [00300, 00390], lr: 0.020000, loss: 0.2542
2022-03-20 20:18:10 - train: epoch 0095, iter [00350, 00390], lr: 0.020000, loss: 0.3653
2022-03-20 20:18:19 - train: epoch 095, train_loss: 0.2976
2022-03-20 20:18:27 - eval: epoch: 095, acc1: 68.840%, acc5: 90.990%, test_loss: 1.2950, per_image_load_time: 0.337ms, per_image_inference_time: 0.398ms
2022-03-20 20:18:29 - until epoch: 095, best_acc1: 74.150%
2022-03-20 20:18:29 - epoch 096 lr: 0.020000000000000004
2022-03-20 20:18:43 - train: epoch 0096, iter [00050, 00390], lr: 0.020000, loss: 0.2991
2022-03-20 20:18:55 - train: epoch 0096, iter [00100, 00390], lr: 0.020000, loss: 0.2032
2022-03-20 20:19:06 - train: epoch 0096, iter [00150, 00390], lr: 0.020000, loss: 0.2556
2022-03-20 20:19:17 - train: epoch 0096, iter [00200, 00390], lr: 0.020000, loss: 0.2696
2022-03-20 20:19:28 - train: epoch 0096, iter [00250, 00390], lr: 0.020000, loss: 0.2503
2022-03-20 20:19:41 - train: epoch 0096, iter [00300, 00390], lr: 0.020000, loss: 0.3818
2022-03-20 20:19:52 - train: epoch 0096, iter [00350, 00390], lr: 0.020000, loss: 0.3155
2022-03-20 20:20:02 - train: epoch 096, train_loss: 0.2873
2022-03-20 20:20:10 - eval: epoch: 096, acc1: 68.840%, acc5: 90.820%, test_loss: 1.2990, per_image_load_time: 0.356ms, per_image_inference_time: 0.409ms
2022-03-20 20:20:11 - until epoch: 096, best_acc1: 74.150%
2022-03-20 20:20:11 - epoch 097 lr: 0.020000000000000004
2022-03-20 20:20:26 - train: epoch 0097, iter [00050, 00390], lr: 0.020000, loss: 0.1787
2022-03-20 20:20:37 - train: epoch 0097, iter [00100, 00390], lr: 0.020000, loss: 0.2130
2022-03-20 20:20:48 - train: epoch 0097, iter [00150, 00390], lr: 0.020000, loss: 0.2338
2022-03-20 20:20:59 - train: epoch 0097, iter [00200, 00390], lr: 0.020000, loss: 0.2571
2022-03-20 20:21:10 - train: epoch 0097, iter [00250, 00390], lr: 0.020000, loss: 0.2640
2022-03-20 20:21:21 - train: epoch 0097, iter [00300, 00390], lr: 0.020000, loss: 0.1934
2022-03-20 20:21:33 - train: epoch 0097, iter [00350, 00390], lr: 0.020000, loss: 0.3213
2022-03-20 20:21:42 - train: epoch 097, train_loss: 0.2832
2022-03-20 20:21:50 - eval: epoch: 097, acc1: 68.100%, acc5: 90.640%, test_loss: 1.3461, per_image_load_time: 0.327ms, per_image_inference_time: 0.421ms
2022-03-20 20:21:51 - until epoch: 097, best_acc1: 74.150%
2022-03-20 20:21:51 - epoch 098 lr: 0.020000000000000004
2022-03-20 20:22:06 - train: epoch 0098, iter [00050, 00390], lr: 0.020000, loss: 0.1482
2022-03-20 20:22:17 - train: epoch 0098, iter [00100, 00390], lr: 0.020000, loss: 0.2055
2022-03-20 20:22:28 - train: epoch 0098, iter [00150, 00390], lr: 0.020000, loss: 0.1391
2022-03-20 20:22:40 - train: epoch 0098, iter [00200, 00390], lr: 0.020000, loss: 0.3153
2022-03-20 20:22:51 - train: epoch 0098, iter [00250, 00390], lr: 0.020000, loss: 0.3787
2022-03-20 20:23:02 - train: epoch 0098, iter [00300, 00390], lr: 0.020000, loss: 0.2405
2022-03-20 20:23:13 - train: epoch 0098, iter [00350, 00390], lr: 0.020000, loss: 0.3243
2022-03-20 20:23:22 - train: epoch 098, train_loss: 0.2794
2022-03-20 20:23:30 - eval: epoch: 098, acc1: 68.730%, acc5: 90.470%, test_loss: 1.3038, per_image_load_time: 0.330ms, per_image_inference_time: 0.394ms
2022-03-20 20:23:31 - until epoch: 098, best_acc1: 74.150%
2022-03-20 20:23:31 - epoch 099 lr: 0.020000000000000004
2022-03-20 20:23:46 - train: epoch 0099, iter [00050, 00390], lr: 0.020000, loss: 0.2572
2022-03-20 20:23:57 - train: epoch 0099, iter [00100, 00390], lr: 0.020000, loss: 0.2252
2022-03-20 20:24:09 - train: epoch 0099, iter [00150, 00390], lr: 0.020000, loss: 0.2686
2022-03-20 20:24:20 - train: epoch 0099, iter [00200, 00390], lr: 0.020000, loss: 0.2907
2022-03-20 20:24:31 - train: epoch 0099, iter [00250, 00390], lr: 0.020000, loss: 0.3972
2022-03-20 20:24:42 - train: epoch 0099, iter [00300, 00390], lr: 0.020000, loss: 0.2957
2022-03-20 20:24:53 - train: epoch 0099, iter [00350, 00390], lr: 0.020000, loss: 0.2901
2022-03-20 20:25:02 - train: epoch 099, train_loss: 0.2946
2022-03-20 20:25:10 - eval: epoch: 099, acc1: 68.670%, acc5: 91.040%, test_loss: 1.2842, per_image_load_time: 0.336ms, per_image_inference_time: 0.417ms
2022-03-20 20:25:12 - until epoch: 099, best_acc1: 74.150%
2022-03-20 20:25:12 - epoch 100 lr: 0.020000000000000004
2022-03-20 20:25:26 - train: epoch 0100, iter [00050, 00390], lr: 0.020000, loss: 0.3716
2022-03-20 20:25:38 - train: epoch 0100, iter [00100, 00390], lr: 0.020000, loss: 0.1823
2022-03-20 20:25:49 - train: epoch 0100, iter [00150, 00390], lr: 0.020000, loss: 0.2157
2022-03-20 20:25:59 - train: epoch 0100, iter [00200, 00390], lr: 0.020000, loss: 0.4193
2022-03-20 20:26:11 - train: epoch 0100, iter [00250, 00390], lr: 0.020000, loss: 0.2911
2022-03-20 20:26:22 - train: epoch 0100, iter [00300, 00390], lr: 0.020000, loss: 0.3378
2022-03-20 20:26:33 - train: epoch 0100, iter [00350, 00390], lr: 0.020000, loss: 0.3951
2022-03-20 20:26:42 - train: epoch 100, train_loss: 0.2849
2022-03-20 20:26:50 - eval: epoch: 100, acc1: 67.470%, acc5: 90.130%, test_loss: 1.3871, per_image_load_time: 0.331ms, per_image_inference_time: 0.406ms
2022-03-20 20:26:52 - until epoch: 100, best_acc1: 74.150%
2022-03-20 20:26:52 - epoch 101 lr: 0.020000000000000004
2022-03-20 20:27:06 - train: epoch 0101, iter [00050, 00390], lr: 0.020000, loss: 0.1978
2022-03-20 20:27:17 - train: epoch 0101, iter [00100, 00390], lr: 0.020000, loss: 0.1739
2022-03-20 20:27:29 - train: epoch 0101, iter [00150, 00390], lr: 0.020000, loss: 0.3231
2022-03-20 20:27:40 - train: epoch 0101, iter [00200, 00390], lr: 0.020000, loss: 0.3572
2022-03-20 20:27:51 - train: epoch 0101, iter [00250, 00390], lr: 0.020000, loss: 0.3131
2022-03-20 20:28:02 - train: epoch 0101, iter [00300, 00390], lr: 0.020000, loss: 0.4227
2022-03-20 20:28:13 - train: epoch 0101, iter [00350, 00390], lr: 0.020000, loss: 0.1871
2022-03-20 20:28:22 - train: epoch 101, train_loss: 0.2815
2022-03-20 20:28:30 - eval: epoch: 101, acc1: 68.960%, acc5: 90.990%, test_loss: 1.2763, per_image_load_time: 0.335ms, per_image_inference_time: 0.412ms
2022-03-20 20:28:32 - until epoch: 101, best_acc1: 74.150%
2022-03-20 20:28:32 - epoch 102 lr: 0.020000000000000004
2022-03-20 20:28:47 - train: epoch 0102, iter [00050, 00390], lr: 0.020000, loss: 0.2538
2022-03-20 20:28:58 - train: epoch 0102, iter [00100, 00390], lr: 0.020000, loss: 0.3005
2022-03-20 20:29:09 - train: epoch 0102, iter [00150, 00390], lr: 0.020000, loss: 0.2811
2022-03-20 20:29:20 - train: epoch 0102, iter [00200, 00390], lr: 0.020000, loss: 0.2504
2022-03-20 20:29:32 - train: epoch 0102, iter [00250, 00390], lr: 0.020000, loss: 0.3090
2022-03-20 20:29:43 - train: epoch 0102, iter [00300, 00390], lr: 0.020000, loss: 0.2703
2022-03-20 20:29:54 - train: epoch 0102, iter [00350, 00390], lr: 0.020000, loss: 0.3181
2022-03-20 20:30:03 - train: epoch 102, train_loss: 0.2723
2022-03-20 20:30:11 - eval: epoch: 102, acc1: 69.900%, acc5: 91.500%, test_loss: 1.2364, per_image_load_time: 0.343ms, per_image_inference_time: 0.414ms
2022-03-20 20:30:13 - until epoch: 102, best_acc1: 74.150%
2022-03-20 20:30:13 - epoch 103 lr: 0.020000000000000004
2022-03-20 20:30:27 - train: epoch 0103, iter [00050, 00390], lr: 0.020000, loss: 0.2304
2022-03-20 20:30:38 - train: epoch 0103, iter [00100, 00390], lr: 0.020000, loss: 0.2900
2022-03-20 20:30:49 - train: epoch 0103, iter [00150, 00390], lr: 0.020000, loss: 0.2412
2022-03-20 20:31:01 - train: epoch 0103, iter [00200, 00390], lr: 0.020000, loss: 0.2726
2022-03-20 20:31:12 - train: epoch 0103, iter [00250, 00390], lr: 0.020000, loss: 0.3167
2022-03-20 20:31:23 - train: epoch 0103, iter [00300, 00390], lr: 0.020000, loss: 0.3604
2022-03-20 20:31:34 - train: epoch 0103, iter [00350, 00390], lr: 0.020000, loss: 0.3533
2022-03-20 20:31:43 - train: epoch 103, train_loss: 0.2802
2022-03-20 20:31:51 - eval: epoch: 103, acc1: 68.550%, acc5: 90.700%, test_loss: 1.3000, per_image_load_time: 0.333ms, per_image_inference_time: 0.406ms
2022-03-20 20:31:53 - until epoch: 103, best_acc1: 74.150%
2022-03-20 20:31:53 - epoch 104 lr: 0.020000000000000004
2022-03-20 20:32:08 - train: epoch 0104, iter [00050, 00390], lr: 0.020000, loss: 0.1643
2022-03-20 20:32:19 - train: epoch 0104, iter [00100, 00390], lr: 0.020000, loss: 0.2502
2022-03-20 20:32:30 - train: epoch 0104, iter [00150, 00390], lr: 0.020000, loss: 0.2849
2022-03-20 20:32:41 - train: epoch 0104, iter [00200, 00390], lr: 0.020000, loss: 0.3301
2022-03-20 20:32:52 - train: epoch 0104, iter [00250, 00390], lr: 0.020000, loss: 0.2255
2022-03-20 20:33:03 - train: epoch 0104, iter [00300, 00390], lr: 0.020000, loss: 0.3330
2022-03-20 20:33:14 - train: epoch 0104, iter [00350, 00390], lr: 0.020000, loss: 0.3873
2022-03-20 20:33:24 - train: epoch 104, train_loss: 0.2799
2022-03-20 20:33:32 - eval: epoch: 104, acc1: 69.010%, acc5: 91.100%, test_loss: 1.2539, per_image_load_time: 0.341ms, per_image_inference_time: 0.406ms
2022-03-20 20:33:33 - until epoch: 104, best_acc1: 74.150%
2022-03-20 20:33:33 - epoch 105 lr: 0.020000000000000004
2022-03-20 20:33:48 - train: epoch 0105, iter [00050, 00390], lr: 0.020000, loss: 0.2572
2022-03-20 20:33:59 - train: epoch 0105, iter [00100, 00390], lr: 0.020000, loss: 0.3267
2022-03-20 20:34:10 - train: epoch 0105, iter [00150, 00390], lr: 0.020000, loss: 0.2154
2022-03-20 20:34:21 - train: epoch 0105, iter [00200, 00390], lr: 0.020000, loss: 0.3244
2022-03-20 20:34:33 - train: epoch 0105, iter [00250, 00390], lr: 0.020000, loss: 0.2902
2022-03-20 20:34:44 - train: epoch 0105, iter [00300, 00390], lr: 0.020000, loss: 0.1915
2022-03-20 20:34:55 - train: epoch 0105, iter [00350, 00390], lr: 0.020000, loss: 0.3548
2022-03-20 20:35:04 - train: epoch 105, train_loss: 0.2755
2022-03-20 20:35:12 - eval: epoch: 105, acc1: 68.970%, acc5: 91.010%, test_loss: 1.2926, per_image_load_time: 0.332ms, per_image_inference_time: 0.411ms
2022-03-20 20:35:14 - until epoch: 105, best_acc1: 74.150%
2022-03-20 20:35:14 - epoch 106 lr: 0.020000000000000004
2022-03-20 20:35:28 - train: epoch 0106, iter [00050, 00390], lr: 0.020000, loss: 0.2999
2022-03-20 20:35:39 - train: epoch 0106, iter [00100, 00390], lr: 0.020000, loss: 0.2657
2022-03-20 20:35:50 - train: epoch 0106, iter [00150, 00390], lr: 0.020000, loss: 0.2002
2022-03-20 20:36:01 - train: epoch 0106, iter [00200, 00390], lr: 0.020000, loss: 0.2267
2022-03-20 20:36:12 - train: epoch 0106, iter [00250, 00390], lr: 0.020000, loss: 0.2185
2022-03-20 20:36:23 - train: epoch 0106, iter [00300, 00390], lr: 0.020000, loss: 0.2301
2022-03-20 20:36:34 - train: epoch 0106, iter [00350, 00390], lr: 0.020000, loss: 0.2042
2022-03-20 20:36:43 - train: epoch 106, train_loss: 0.2547
2022-03-20 20:36:51 - eval: epoch: 106, acc1: 68.560%, acc5: 91.010%, test_loss: 1.3482, per_image_load_time: 0.333ms, per_image_inference_time: 0.415ms
2022-03-20 20:36:53 - until epoch: 106, best_acc1: 74.150%
2022-03-20 20:36:53 - epoch 107 lr: 0.020000000000000004
2022-03-20 20:37:07 - train: epoch 0107, iter [00050, 00390], lr: 0.020000, loss: 0.3397
2022-03-20 20:37:18 - train: epoch 0107, iter [00100, 00390], lr: 0.020000, loss: 0.1975
2022-03-20 20:37:29 - train: epoch 0107, iter [00150, 00390], lr: 0.020000, loss: 0.3480
2022-03-20 20:37:40 - train: epoch 0107, iter [00200, 00390], lr: 0.020000, loss: 0.2588
2022-03-20 20:37:51 - train: epoch 0107, iter [00250, 00390], lr: 0.020000, loss: 0.2639
2022-03-20 20:38:02 - train: epoch 0107, iter [00300, 00390], lr: 0.020000, loss: 0.2854
2022-03-20 20:38:13 - train: epoch 0107, iter [00350, 00390], lr: 0.020000, loss: 0.3079
2022-03-20 20:38:22 - train: epoch 107, train_loss: 0.2686
2022-03-20 20:38:30 - eval: epoch: 107, acc1: 69.210%, acc5: 90.790%, test_loss: 1.2721, per_image_load_time: 0.334ms, per_image_inference_time: 0.399ms
2022-03-20 20:38:32 - until epoch: 107, best_acc1: 74.150%
2022-03-20 20:38:32 - epoch 108 lr: 0.020000000000000004
2022-03-20 20:38:46 - train: epoch 0108, iter [00050, 00390], lr: 0.020000, loss: 0.2551
2022-03-20 20:38:57 - train: epoch 0108, iter [00100, 00390], lr: 0.020000, loss: 0.2329
2022-03-20 20:39:08 - train: epoch 0108, iter [00150, 00390], lr: 0.020000, loss: 0.1583
2022-03-20 20:39:19 - train: epoch 0108, iter [00200, 00390], lr: 0.020000, loss: 0.2522
2022-03-20 20:39:30 - train: epoch 0108, iter [00250, 00390], lr: 0.020000, loss: 0.3191
2022-03-20 20:39:41 - train: epoch 0108, iter [00300, 00390], lr: 0.020000, loss: 0.3642
2022-03-20 20:39:52 - train: epoch 0108, iter [00350, 00390], lr: 0.020000, loss: 0.2327
2022-03-20 20:40:01 - train: epoch 108, train_loss: 0.2657
2022-03-20 20:40:09 - eval: epoch: 108, acc1: 69.190%, acc5: 91.160%, test_loss: 1.3069, per_image_load_time: 0.338ms, per_image_inference_time: 0.413ms
2022-03-20 20:40:11 - until epoch: 108, best_acc1: 74.150%
2022-03-20 20:40:11 - epoch 109 lr: 0.020000000000000004
2022-03-20 20:40:25 - train: epoch 0109, iter [00050, 00390], lr: 0.020000, loss: 0.3935
2022-03-20 20:40:36 - train: epoch 0109, iter [00100, 00390], lr: 0.020000, loss: 0.3310
2022-03-20 20:40:47 - train: epoch 0109, iter [00150, 00390], lr: 0.020000, loss: 0.2820
2022-03-20 20:40:58 - train: epoch 0109, iter [00200, 00390], lr: 0.020000, loss: 0.2411
2022-03-20 20:41:09 - train: epoch 0109, iter [00250, 00390], lr: 0.020000, loss: 0.2534
2022-03-20 20:41:20 - train: epoch 0109, iter [00300, 00390], lr: 0.020000, loss: 0.3100
2022-03-20 20:41:31 - train: epoch 0109, iter [00350, 00390], lr: 0.020000, loss: 0.2787
2022-03-20 20:41:41 - train: epoch 109, train_loss: 0.2726
2022-03-20 20:41:48 - eval: epoch: 109, acc1: 68.510%, acc5: 90.580%, test_loss: 1.2992, per_image_load_time: 0.334ms, per_image_inference_time: 0.401ms
2022-03-20 20:41:50 - until epoch: 109, best_acc1: 74.150%
2022-03-20 20:41:50 - epoch 110 lr: 0.020000000000000004
2022-03-20 20:42:04 - train: epoch 0110, iter [00050, 00390], lr: 0.020000, loss: 0.2875
2022-03-20 20:42:16 - train: epoch 0110, iter [00100, 00390], lr: 0.020000, loss: 0.2427
2022-03-20 20:42:27 - train: epoch 0110, iter [00150, 00390], lr: 0.020000, loss: 0.2590
2022-03-20 20:42:38 - train: epoch 0110, iter [00200, 00390], lr: 0.020000, loss: 0.3234
2022-03-20 20:42:49 - train: epoch 0110, iter [00250, 00390], lr: 0.020000, loss: 0.3178
2022-03-20 20:43:01 - train: epoch 0110, iter [00300, 00390], lr: 0.020000, loss: 0.2996
2022-03-20 20:43:12 - train: epoch 0110, iter [00350, 00390], lr: 0.020000, loss: 0.2865
2022-03-20 20:43:21 - train: epoch 110, train_loss: 0.2661
2022-03-20 20:43:29 - eval: epoch: 110, acc1: 70.000%, acc5: 91.540%, test_loss: 1.2373, per_image_load_time: 0.338ms, per_image_inference_time: 0.414ms
2022-03-20 20:43:31 - until epoch: 110, best_acc1: 74.150%
2022-03-20 20:43:31 - epoch 111 lr: 0.020000000000000004
2022-03-20 20:43:46 - train: epoch 0111, iter [00050, 00390], lr: 0.020000, loss: 0.1269
2022-03-20 20:43:57 - train: epoch 0111, iter [00100, 00390], lr: 0.020000, loss: 0.2881
2022-03-20 20:44:09 - train: epoch 0111, iter [00150, 00390], lr: 0.020000, loss: 0.2118
2022-03-20 20:44:20 - train: epoch 0111, iter [00200, 00390], lr: 0.020000, loss: 0.2213
2022-03-20 20:44:31 - train: epoch 0111, iter [00250, 00390], lr: 0.020000, loss: 0.2946
2022-03-20 20:44:42 - train: epoch 0111, iter [00300, 00390], lr: 0.020000, loss: 0.3345
2022-03-20 20:44:54 - train: epoch 0111, iter [00350, 00390], lr: 0.020000, loss: 0.2763
2022-03-20 20:45:03 - train: epoch 111, train_loss: 0.2538
2022-03-20 20:45:12 - eval: epoch: 111, acc1: 69.000%, acc5: 90.910%, test_loss: 1.2756, per_image_load_time: 0.369ms, per_image_inference_time: 0.413ms
2022-03-20 20:45:13 - until epoch: 111, best_acc1: 74.150%
2022-03-20 20:45:13 - epoch 112 lr: 0.020000000000000004
2022-03-20 20:45:28 - train: epoch 0112, iter [00050, 00390], lr: 0.020000, loss: 0.1799
2022-03-20 20:45:39 - train: epoch 0112, iter [00100, 00390], lr: 0.020000, loss: 0.1833
2022-03-20 20:45:50 - train: epoch 0112, iter [00150, 00390], lr: 0.020000, loss: 0.3254
2022-03-20 20:46:01 - train: epoch 0112, iter [00200, 00390], lr: 0.020000, loss: 0.2068
2022-03-20 20:46:13 - train: epoch 0112, iter [00250, 00390], lr: 0.020000, loss: 0.2682
2022-03-20 20:46:24 - train: epoch 0112, iter [00300, 00390], lr: 0.020000, loss: 0.3042
2022-03-20 20:46:35 - train: epoch 0112, iter [00350, 00390], lr: 0.020000, loss: 0.3834
2022-03-20 20:46:45 - train: epoch 112, train_loss: 0.2680
2022-03-20 20:46:53 - eval: epoch: 112, acc1: 68.650%, acc5: 90.760%, test_loss: 1.3139, per_image_load_time: 0.339ms, per_image_inference_time: 0.403ms
2022-03-20 20:46:54 - until epoch: 112, best_acc1: 74.150%
2022-03-20 20:46:54 - epoch 113 lr: 0.020000000000000004
2022-03-20 20:47:09 - train: epoch 0113, iter [00050, 00390], lr: 0.020000, loss: 0.2964
2022-03-20 20:47:20 - train: epoch 0113, iter [00100, 00390], lr: 0.020000, loss: 0.2732
2022-03-20 20:47:32 - train: epoch 0113, iter [00150, 00390], lr: 0.020000, loss: 0.2020
2022-03-20 20:47:43 - train: epoch 0113, iter [00200, 00390], lr: 0.020000, loss: 0.2410
2022-03-20 20:47:54 - train: epoch 0113, iter [00250, 00390], lr: 0.020000, loss: 0.2934
2022-03-20 20:48:06 - train: epoch 0113, iter [00300, 00390], lr: 0.020000, loss: 0.2515
2022-03-20 20:48:17 - train: epoch 0113, iter [00350, 00390], lr: 0.020000, loss: 0.4182
2022-03-20 20:48:27 - train: epoch 113, train_loss: 0.2641
2022-03-20 20:48:35 - eval: epoch: 113, acc1: 66.390%, acc5: 89.450%, test_loss: 1.4156, per_image_load_time: 0.296ms, per_image_inference_time: 0.441ms
2022-03-20 20:48:36 - until epoch: 113, best_acc1: 74.150%
2022-03-20 20:48:36 - epoch 114 lr: 0.020000000000000004
2022-03-20 20:48:51 - train: epoch 0114, iter [00050, 00390], lr: 0.020000, loss: 0.1684
2022-03-20 20:49:02 - train: epoch 0114, iter [00100, 00390], lr: 0.020000, loss: 0.1287
2022-03-20 20:49:14 - train: epoch 0114, iter [00150, 00390], lr: 0.020000, loss: 0.2081
2022-03-20 20:49:25 - train: epoch 0114, iter [00200, 00390], lr: 0.020000, loss: 0.1642
2022-03-20 20:49:37 - train: epoch 0114, iter [00250, 00390], lr: 0.020000, loss: 0.1540
2022-03-20 20:49:49 - train: epoch 0114, iter [00300, 00390], lr: 0.020000, loss: 0.2831
2022-03-20 20:50:00 - train: epoch 0114, iter [00350, 00390], lr: 0.020000, loss: 0.2507
2022-03-20 20:50:10 - train: epoch 114, train_loss: 0.2470
2022-03-20 20:50:18 - eval: epoch: 114, acc1: 67.910%, acc5: 90.320%, test_loss: 1.3326, per_image_load_time: 0.332ms, per_image_inference_time: 0.409ms
2022-03-20 20:50:19 - until epoch: 114, best_acc1: 74.150%
2022-03-20 20:50:19 - epoch 115 lr: 0.020000000000000004
2022-03-20 20:50:34 - train: epoch 0115, iter [00050, 00390], lr: 0.020000, loss: 0.3080
2022-03-20 20:50:46 - train: epoch 0115, iter [00100, 00390], lr: 0.020000, loss: 0.3117
2022-03-20 20:50:57 - train: epoch 0115, iter [00150, 00390], lr: 0.020000, loss: 0.2653
2022-03-20 20:51:09 - train: epoch 0115, iter [00200, 00390], lr: 0.020000, loss: 0.2979
2022-03-20 20:51:20 - train: epoch 0115, iter [00250, 00390], lr: 0.020000, loss: 0.2481
2022-03-20 20:51:32 - train: epoch 0115, iter [00300, 00390], lr: 0.020000, loss: 0.3888
2022-03-20 20:51:43 - train: epoch 0115, iter [00350, 00390], lr: 0.020000, loss: 0.3484
2022-03-20 20:51:53 - train: epoch 115, train_loss: 0.2673
2022-03-20 20:52:01 - eval: epoch: 115, acc1: 68.660%, acc5: 90.540%, test_loss: 1.3416, per_image_load_time: 0.315ms, per_image_inference_time: 0.413ms
2022-03-20 20:52:02 - until epoch: 115, best_acc1: 74.150%
2022-03-20 20:52:02 - epoch 116 lr: 0.020000000000000004
2022-03-20 20:52:17 - train: epoch 0116, iter [00050, 00390], lr: 0.020000, loss: 0.3257
2022-03-20 20:52:29 - train: epoch 0116, iter [00100, 00390], lr: 0.020000, loss: 0.2546
2022-03-20 20:52:40 - train: epoch 0116, iter [00150, 00390], lr: 0.020000, loss: 0.1890
2022-03-20 20:52:51 - train: epoch 0116, iter [00200, 00390], lr: 0.020000, loss: 0.3519
2022-03-20 20:53:03 - train: epoch 0116, iter [00250, 00390], lr: 0.020000, loss: 0.2645
2022-03-20 20:53:14 - train: epoch 0116, iter [00300, 00390], lr: 0.020000, loss: 0.2356
2022-03-20 20:53:26 - train: epoch 0116, iter [00350, 00390], lr: 0.020000, loss: 0.2620
2022-03-20 20:53:35 - train: epoch 116, train_loss: 0.2658
2022-03-20 20:53:43 - eval: epoch: 116, acc1: 68.440%, acc5: 90.150%, test_loss: 1.3549, per_image_load_time: 0.320ms, per_image_inference_time: 0.407ms
2022-03-20 20:53:44 - until epoch: 116, best_acc1: 74.150%
2022-03-20 20:53:44 - epoch 117 lr: 0.020000000000000004
2022-03-20 20:54:00 - train: epoch 0117, iter [00050, 00390], lr: 0.020000, loss: 0.2381
2022-03-20 20:54:11 - train: epoch 0117, iter [00100, 00390], lr: 0.020000, loss: 0.2413
2022-03-20 20:54:23 - train: epoch 0117, iter [00150, 00390], lr: 0.020000, loss: 0.1524
2022-03-20 20:54:35 - train: epoch 0117, iter [00200, 00390], lr: 0.020000, loss: 0.3908
2022-03-20 20:54:46 - train: epoch 0117, iter [00250, 00390], lr: 0.020000, loss: 0.2375
2022-03-20 20:54:58 - train: epoch 0117, iter [00300, 00390], lr: 0.020000, loss: 0.2860
2022-03-20 20:55:10 - train: epoch 0117, iter [00350, 00390], lr: 0.020000, loss: 0.1976
2022-03-20 20:55:19 - train: epoch 117, train_loss: 0.2601
2022-03-20 20:55:27 - eval: epoch: 117, acc1: 68.350%, acc5: 90.290%, test_loss: 1.3895, per_image_load_time: 0.282ms, per_image_inference_time: 0.424ms
2022-03-20 20:55:28 - until epoch: 117, best_acc1: 74.150%
2022-03-20 20:55:28 - epoch 118 lr: 0.020000000000000004
2022-03-20 20:55:43 - train: epoch 0118, iter [00050, 00390], lr: 0.020000, loss: 0.3993
2022-03-20 20:55:54 - train: epoch 0118, iter [00100, 00390], lr: 0.020000, loss: 0.1933
2022-03-20 20:56:05 - train: epoch 0118, iter [00150, 00390], lr: 0.020000, loss: 0.2295
2022-03-20 20:56:16 - train: epoch 0118, iter [00200, 00390], lr: 0.020000, loss: 0.2192
2022-03-20 20:56:27 - train: epoch 0118, iter [00250, 00390], lr: 0.020000, loss: 0.1969
2022-03-20 20:56:39 - train: epoch 0118, iter [00300, 00390], lr: 0.020000, loss: 0.2222
2022-03-20 20:56:50 - train: epoch 0118, iter [00350, 00390], lr: 0.020000, loss: 0.2478
2022-03-20 20:56:59 - train: epoch 118, train_loss: 0.2585
2022-03-20 20:57:07 - eval: epoch: 118, acc1: 69.430%, acc5: 90.490%, test_loss: 1.3388, per_image_load_time: 0.328ms, per_image_inference_time: 0.406ms
2022-03-20 20:57:08 - until epoch: 118, best_acc1: 74.150%
2022-03-20 20:57:08 - epoch 119 lr: 0.020000000000000004
2022-03-20 20:57:22 - train: epoch 0119, iter [00050, 00390], lr: 0.020000, loss: 0.1954
2022-03-20 20:57:33 - train: epoch 0119, iter [00100, 00390], lr: 0.020000, loss: 0.2352
2022-03-20 20:57:44 - train: epoch 0119, iter [00150, 00390], lr: 0.020000, loss: 0.1798
2022-03-20 20:57:56 - train: epoch 0119, iter [00200, 00390], lr: 0.020000, loss: 0.1629
2022-03-20 20:58:07 - train: epoch 0119, iter [00250, 00390], lr: 0.020000, loss: 0.2011
2022-03-20 20:58:18 - train: epoch 0119, iter [00300, 00390], lr: 0.020000, loss: 0.2192
2022-03-20 20:58:29 - train: epoch 0119, iter [00350, 00390], lr: 0.020000, loss: 0.2387
2022-03-20 20:58:38 - train: epoch 119, train_loss: 0.2470
2022-03-20 20:58:46 - eval: epoch: 119, acc1: 69.090%, acc5: 91.010%, test_loss: 1.2766, per_image_load_time: 0.294ms, per_image_inference_time: 0.463ms
2022-03-20 20:58:48 - until epoch: 119, best_acc1: 74.150%
2022-03-20 20:58:48 - epoch 120 lr: 0.020000000000000004
2022-03-20 20:59:02 - train: epoch 0120, iter [00050, 00390], lr: 0.020000, loss: 0.2566
2022-03-20 20:59:13 - train: epoch 0120, iter [00100, 00390], lr: 0.020000, loss: 0.1780
2022-03-20 20:59:25 - train: epoch 0120, iter [00150, 00390], lr: 0.020000, loss: 0.2684
2022-03-20 20:59:38 - train: epoch 0120, iter [00200, 00390], lr: 0.020000, loss: 0.2452
2022-03-20 20:59:49 - train: epoch 0120, iter [00250, 00390], lr: 0.020000, loss: 0.2121
2022-03-20 21:00:00 - train: epoch 0120, iter [00300, 00390], lr: 0.020000, loss: 0.2859
2022-03-20 21:00:12 - train: epoch 0120, iter [00350, 00390], lr: 0.020000, loss: 0.2775
2022-03-20 21:00:21 - train: epoch 120, train_loss: 0.2503
2022-03-20 21:00:29 - eval: epoch: 120, acc1: 69.770%, acc5: 91.260%, test_loss: 1.2728, per_image_load_time: 0.339ms, per_image_inference_time: 0.432ms
2022-03-20 21:00:31 - until epoch: 120, best_acc1: 74.150%
2022-03-20 21:00:31 - epoch 121 lr: 0.004000000000000001
2022-03-20 21:00:46 - train: epoch 0121, iter [00050, 00390], lr: 0.004000, loss: 0.0675
2022-03-20 21:00:57 - train: epoch 0121, iter [00100, 00390], lr: 0.004000, loss: 0.0874
2022-03-20 21:01:09 - train: epoch 0121, iter [00150, 00390], lr: 0.004000, loss: 0.0793
2022-03-20 21:01:22 - train: epoch 0121, iter [00200, 00390], lr: 0.004000, loss: 0.0449
2022-03-20 21:01:34 - train: epoch 0121, iter [00250, 00390], lr: 0.004000, loss: 0.0477
2022-03-20 21:01:46 - train: epoch 0121, iter [00300, 00390], lr: 0.004000, loss: 0.0731
2022-03-20 21:01:57 - train: epoch 0121, iter [00350, 00390], lr: 0.004000, loss: 0.0281
2022-03-20 21:02:07 - train: epoch 121, train_loss: 0.0904
2022-03-20 21:02:14 - eval: epoch: 121, acc1: 76.810%, acc5: 94.370%, test_loss: 0.9443, per_image_load_time: 0.323ms, per_image_inference_time: 0.401ms
2022-03-20 21:02:17 - until epoch: 121, best_acc1: 76.810%
2022-03-20 21:02:17 - epoch 122 lr: 0.004000000000000001
2022-03-20 21:02:32 - train: epoch 0122, iter [00050, 00390], lr: 0.004000, loss: 0.0327
2022-03-20 21:02:43 - train: epoch 0122, iter [00100, 00390], lr: 0.004000, loss: 0.0405
2022-03-20 21:02:54 - train: epoch 0122, iter [00150, 00390], lr: 0.004000, loss: 0.0447
2022-03-20 21:03:05 - train: epoch 0122, iter [00200, 00390], lr: 0.004000, loss: 0.0359
2022-03-20 21:03:16 - train: epoch 0122, iter [00250, 00390], lr: 0.004000, loss: 0.0394
2022-03-20 21:03:27 - train: epoch 0122, iter [00300, 00390], lr: 0.004000, loss: 0.0626
2022-03-20 21:03:39 - train: epoch 0122, iter [00350, 00390], lr: 0.004000, loss: 0.0609
2022-03-20 21:03:48 - train: epoch 122, train_loss: 0.0423
2022-03-20 21:03:56 - eval: epoch: 122, acc1: 77.340%, acc5: 94.210%, test_loss: 0.9382, per_image_load_time: 0.325ms, per_image_inference_time: 0.412ms
2022-03-20 21:03:58 - until epoch: 122, best_acc1: 77.340%
2022-03-20 21:03:58 - epoch 123 lr: 0.004000000000000001
2022-03-20 21:04:13 - train: epoch 0123, iter [00050, 00390], lr: 0.004000, loss: 0.0330
2022-03-20 21:04:24 - train: epoch 0123, iter [00100, 00390], lr: 0.004000, loss: 0.0242
2022-03-20 21:04:36 - train: epoch 0123, iter [00150, 00390], lr: 0.004000, loss: 0.0213
2022-03-20 21:04:47 - train: epoch 0123, iter [00200, 00390], lr: 0.004000, loss: 0.0156
2022-03-20 21:04:58 - train: epoch 0123, iter [00250, 00390], lr: 0.004000, loss: 0.0399
2022-03-20 21:05:09 - train: epoch 0123, iter [00300, 00390], lr: 0.004000, loss: 0.0242
2022-03-20 21:05:20 - train: epoch 0123, iter [00350, 00390], lr: 0.004000, loss: 0.0097
2022-03-20 21:05:30 - train: epoch 123, train_loss: 0.0327
2022-03-20 21:05:38 - eval: epoch: 123, acc1: 77.750%, acc5: 94.260%, test_loss: 0.9357, per_image_load_time: 0.342ms, per_image_inference_time: 0.421ms
2022-03-20 21:05:40 - until epoch: 123, best_acc1: 77.750%
2022-03-20 21:05:40 - epoch 124 lr: 0.004000000000000001
2022-03-20 21:05:55 - train: epoch 0124, iter [00050, 00390], lr: 0.004000, loss: 0.0156
2022-03-20 21:06:06 - train: epoch 0124, iter [00100, 00390], lr: 0.004000, loss: 0.0307
2022-03-20 21:06:17 - train: epoch 0124, iter [00150, 00390], lr: 0.004000, loss: 0.0310
2022-03-20 21:06:29 - train: epoch 0124, iter [00200, 00390], lr: 0.004000, loss: 0.0312
2022-03-20 21:06:40 - train: epoch 0124, iter [00250, 00390], lr: 0.004000, loss: 0.0446
2022-03-20 21:06:51 - train: epoch 0124, iter [00300, 00390], lr: 0.004000, loss: 0.0487
2022-03-20 21:07:03 - train: epoch 0124, iter [00350, 00390], lr: 0.004000, loss: 0.0422
2022-03-20 21:07:12 - train: epoch 124, train_loss: 0.0270
2022-03-20 21:07:20 - eval: epoch: 124, acc1: 77.370%, acc5: 94.230%, test_loss: 0.9366, per_image_load_time: 0.339ms, per_image_inference_time: 0.402ms
2022-03-20 21:07:21 - until epoch: 124, best_acc1: 77.750%
2022-03-20 21:07:21 - epoch 125 lr: 0.004000000000000001
2022-03-20 21:07:36 - train: epoch 0125, iter [00050, 00390], lr: 0.004000, loss: 0.0128
2022-03-20 21:07:48 - train: epoch 0125, iter [00100, 00390], lr: 0.004000, loss: 0.0212
2022-03-20 21:07:59 - train: epoch 0125, iter [00150, 00390], lr: 0.004000, loss: 0.0217
2022-03-20 21:08:10 - train: epoch 0125, iter [00200, 00390], lr: 0.004000, loss: 0.0473
2022-03-20 21:08:21 - train: epoch 0125, iter [00250, 00390], lr: 0.004000, loss: 0.0171
2022-03-20 21:08:32 - train: epoch 0125, iter [00300, 00390], lr: 0.004000, loss: 0.0220
2022-03-20 21:08:44 - train: epoch 0125, iter [00350, 00390], lr: 0.004000, loss: 0.0272
2022-03-20 21:08:53 - train: epoch 125, train_loss: 0.0239
2022-03-20 21:09:01 - eval: epoch: 125, acc1: 77.510%, acc5: 94.330%, test_loss: 0.9420, per_image_load_time: 0.360ms, per_image_inference_time: 0.432ms
2022-03-20 21:09:03 - until epoch: 125, best_acc1: 77.750%
2022-03-20 21:09:03 - epoch 126 lr: 0.004000000000000001
2022-03-20 21:09:17 - train: epoch 0126, iter [00050, 00390], lr: 0.004000, loss: 0.0115
2022-03-20 21:09:29 - train: epoch 0126, iter [00100, 00390], lr: 0.004000, loss: 0.0168
2022-03-20 21:09:40 - train: epoch 0126, iter [00150, 00390], lr: 0.004000, loss: 0.0165
2022-03-20 21:09:51 - train: epoch 0126, iter [00200, 00390], lr: 0.004000, loss: 0.0143
2022-03-20 21:10:02 - train: epoch 0126, iter [00250, 00390], lr: 0.004000, loss: 0.0142
2022-03-20 21:10:14 - train: epoch 0126, iter [00300, 00390], lr: 0.004000, loss: 0.0107
2022-03-20 21:10:25 - train: epoch 0126, iter [00350, 00390], lr: 0.004000, loss: 0.0121
2022-03-20 21:10:34 - train: epoch 126, train_loss: 0.0208
2022-03-20 21:10:42 - eval: epoch: 126, acc1: 77.820%, acc5: 94.440%, test_loss: 0.9417, per_image_load_time: 0.343ms, per_image_inference_time: 0.400ms
2022-03-20 21:10:44 - until epoch: 126, best_acc1: 77.820%
2022-03-20 21:10:44 - epoch 127 lr: 0.004000000000000001
2022-03-20 21:10:59 - train: epoch 0127, iter [00050, 00390], lr: 0.004000, loss: 0.0182
2022-03-20 21:11:10 - train: epoch 0127, iter [00100, 00390], lr: 0.004000, loss: 0.0105
2022-03-20 21:11:21 - train: epoch 0127, iter [00150, 00390], lr: 0.004000, loss: 0.0187
2022-03-20 21:11:32 - train: epoch 0127, iter [00200, 00390], lr: 0.004000, loss: 0.0149
2022-03-20 21:11:44 - train: epoch 0127, iter [00250, 00390], lr: 0.004000, loss: 0.0189
2022-03-20 21:11:55 - train: epoch 0127, iter [00300, 00390], lr: 0.004000, loss: 0.0285
2022-03-20 21:12:06 - train: epoch 0127, iter [00350, 00390], lr: 0.004000, loss: 0.0172
2022-03-20 21:12:16 - train: epoch 127, train_loss: 0.0191
2022-03-20 21:12:24 - eval: epoch: 127, acc1: 77.890%, acc5: 94.410%, test_loss: 0.9347, per_image_load_time: 0.363ms, per_image_inference_time: 0.400ms
2022-03-20 21:12:26 - until epoch: 127, best_acc1: 77.890%
2022-03-20 21:12:26 - epoch 128 lr: 0.004000000000000001
2022-03-20 21:12:41 - train: epoch 0128, iter [00050, 00390], lr: 0.004000, loss: 0.0127
2022-03-20 21:12:52 - train: epoch 0128, iter [00100, 00390], lr: 0.004000, loss: 0.0231
2022-03-20 21:13:04 - train: epoch 0128, iter [00150, 00390], lr: 0.004000, loss: 0.0137
2022-03-20 21:13:15 - train: epoch 0128, iter [00200, 00390], lr: 0.004000, loss: 0.0159
2022-03-20 21:13:26 - train: epoch 0128, iter [00250, 00390], lr: 0.004000, loss: 0.0352
2022-03-20 21:13:37 - train: epoch 0128, iter [00300, 00390], lr: 0.004000, loss: 0.0098
2022-03-20 21:13:48 - train: epoch 0128, iter [00350, 00390], lr: 0.004000, loss: 0.0181
2022-03-20 21:13:58 - train: epoch 128, train_loss: 0.0180
2022-03-20 21:14:06 - eval: epoch: 128, acc1: 77.960%, acc5: 94.330%, test_loss: 0.9358, per_image_load_time: 0.328ms, per_image_inference_time: 0.398ms
2022-03-20 21:14:08 - until epoch: 128, best_acc1: 77.960%
2022-03-20 21:14:08 - epoch 129 lr: 0.004000000000000001
2022-03-20 21:14:23 - train: epoch 0129, iter [00050, 00390], lr: 0.004000, loss: 0.0139
2022-03-20 21:14:34 - train: epoch 0129, iter [00100, 00390], lr: 0.004000, loss: 0.0080
2022-03-20 21:14:45 - train: epoch 0129, iter [00150, 00390], lr: 0.004000, loss: 0.0162
2022-03-20 21:14:57 - train: epoch 0129, iter [00200, 00390], lr: 0.004000, loss: 0.0106
2022-03-20 21:15:08 - train: epoch 0129, iter [00250, 00390], lr: 0.004000, loss: 0.0231
2022-03-20 21:15:19 - train: epoch 0129, iter [00300, 00390], lr: 0.004000, loss: 0.0122
2022-03-20 21:15:30 - train: epoch 0129, iter [00350, 00390], lr: 0.004000, loss: 0.0123
2022-03-20 21:15:40 - train: epoch 129, train_loss: 0.0167
2022-03-20 21:15:48 - eval: epoch: 129, acc1: 77.960%, acc5: 94.410%, test_loss: 0.9302, per_image_load_time: 0.333ms, per_image_inference_time: 0.403ms
2022-03-20 21:15:49 - until epoch: 129, best_acc1: 77.960%
2022-03-20 21:15:49 - epoch 130 lr: 0.004000000000000001
2022-03-20 21:16:04 - train: epoch 0130, iter [00050, 00390], lr: 0.004000, loss: 0.0142
2022-03-20 21:16:15 - train: epoch 0130, iter [00100, 00390], lr: 0.004000, loss: 0.0130
2022-03-20 21:16:26 - train: epoch 0130, iter [00150, 00390], lr: 0.004000, loss: 0.0096
2022-03-20 21:16:37 - train: epoch 0130, iter [00200, 00390], lr: 0.004000, loss: 0.0267
2022-03-20 21:16:49 - train: epoch 0130, iter [00250, 00390], lr: 0.004000, loss: 0.0195
2022-03-20 21:17:00 - train: epoch 0130, iter [00300, 00390], lr: 0.004000, loss: 0.0081
2022-03-20 21:17:11 - train: epoch 0130, iter [00350, 00390], lr: 0.004000, loss: 0.0228
2022-03-20 21:17:21 - train: epoch 130, train_loss: 0.0165
2022-03-20 21:17:28 - eval: epoch: 130, acc1: 77.890%, acc5: 94.590%, test_loss: 0.9257, per_image_load_time: 0.340ms, per_image_inference_time: 0.411ms
2022-03-20 21:17:30 - until epoch: 130, best_acc1: 77.960%
2022-03-20 21:17:30 - epoch 131 lr: 0.004000000000000001
2022-03-20 21:17:45 - train: epoch 0131, iter [00050, 00390], lr: 0.004000, loss: 0.0457
2022-03-20 21:17:57 - train: epoch 0131, iter [00100, 00390], lr: 0.004000, loss: 0.0069
2022-03-20 21:18:08 - train: epoch 0131, iter [00150, 00390], lr: 0.004000, loss: 0.0167
2022-03-20 21:18:19 - train: epoch 0131, iter [00200, 00390], lr: 0.004000, loss: 0.0096
2022-03-20 21:18:31 - train: epoch 0131, iter [00250, 00390], lr: 0.004000, loss: 0.0132
2022-03-20 21:18:42 - train: epoch 0131, iter [00300, 00390], lr: 0.004000, loss: 0.0080
2022-03-20 21:18:53 - train: epoch 0131, iter [00350, 00390], lr: 0.004000, loss: 0.0109
2022-03-20 21:19:03 - train: epoch 131, train_loss: 0.0153
2022-03-20 21:19:11 - eval: epoch: 131, acc1: 77.760%, acc5: 94.490%, test_loss: 0.9285, per_image_load_time: 0.340ms, per_image_inference_time: 0.428ms
2022-03-20 21:19:13 - until epoch: 131, best_acc1: 77.960%
2022-03-20 21:19:13 - epoch 132 lr: 0.004000000000000001
2022-03-20 21:19:28 - train: epoch 0132, iter [00050, 00390], lr: 0.004000, loss: 0.0147
2022-03-20 21:19:39 - train: epoch 0132, iter [00100, 00390], lr: 0.004000, loss: 0.0217
2022-03-20 21:19:50 - train: epoch 0132, iter [00150, 00390], lr: 0.004000, loss: 0.0119
2022-03-20 21:20:02 - train: epoch 0132, iter [00200, 00390], lr: 0.004000, loss: 0.0128
2022-03-20 21:20:14 - train: epoch 0132, iter [00250, 00390], lr: 0.004000, loss: 0.0089
2022-03-20 21:20:25 - train: epoch 0132, iter [00300, 00390], lr: 0.004000, loss: 0.0095
2022-03-20 21:20:36 - train: epoch 0132, iter [00350, 00390], lr: 0.004000, loss: 0.0114
2022-03-20 21:20:46 - train: epoch 132, train_loss: 0.0140
2022-03-20 21:20:54 - eval: epoch: 132, acc1: 78.020%, acc5: 94.590%, test_loss: 0.9299, per_image_load_time: 0.322ms, per_image_inference_time: 0.426ms
2022-03-20 21:20:56 - until epoch: 132, best_acc1: 78.020%
2022-03-20 21:20:56 - epoch 133 lr: 0.004000000000000001
2022-03-20 21:21:11 - train: epoch 0133, iter [00050, 00390], lr: 0.004000, loss: 0.0112
2022-03-20 21:21:22 - train: epoch 0133, iter [00100, 00390], lr: 0.004000, loss: 0.0084
2022-03-20 21:21:34 - train: epoch 0133, iter [00150, 00390], lr: 0.004000, loss: 0.0151
2022-03-20 21:21:45 - train: epoch 0133, iter [00200, 00390], lr: 0.004000, loss: 0.0156
2022-03-20 21:21:56 - train: epoch 0133, iter [00250, 00390], lr: 0.004000, loss: 0.0118
2022-03-20 21:22:08 - train: epoch 0133, iter [00300, 00390], lr: 0.004000, loss: 0.0161
2022-03-20 21:22:19 - train: epoch 0133, iter [00350, 00390], lr: 0.004000, loss: 0.0331
2022-03-20 21:22:28 - train: epoch 133, train_loss: 0.0140
2022-03-20 21:22:36 - eval: epoch: 133, acc1: 78.120%, acc5: 94.510%, test_loss: 0.9260, per_image_load_time: 0.344ms, per_image_inference_time: 0.399ms
2022-03-20 21:22:38 - until epoch: 133, best_acc1: 78.120%
2022-03-20 21:22:38 - epoch 134 lr: 0.004000000000000001
2022-03-20 21:22:53 - train: epoch 0134, iter [00050, 00390], lr: 0.004000, loss: 0.0186
2022-03-20 21:23:04 - train: epoch 0134, iter [00100, 00390], lr: 0.004000, loss: 0.0088
2022-03-20 21:23:15 - train: epoch 0134, iter [00150, 00390], lr: 0.004000, loss: 0.0102
2022-03-20 21:23:26 - train: epoch 0134, iter [00200, 00390], lr: 0.004000, loss: 0.0115
2022-03-20 21:23:38 - train: epoch 0134, iter [00250, 00390], lr: 0.004000, loss: 0.0153
2022-03-20 21:23:49 - train: epoch 0134, iter [00300, 00390], lr: 0.004000, loss: 0.0097
2022-03-20 21:24:00 - train: epoch 0134, iter [00350, 00390], lr: 0.004000, loss: 0.0177
2022-03-20 21:24:09 - train: epoch 134, train_loss: 0.0139
2022-03-20 21:24:18 - eval: epoch: 134, acc1: 78.120%, acc5: 94.570%, test_loss: 0.9267, per_image_load_time: 0.382ms, per_image_inference_time: 0.422ms
2022-03-20 21:24:19 - until epoch: 134, best_acc1: 78.120%
2022-03-20 21:24:19 - epoch 135 lr: 0.004000000000000001
2022-03-20 21:24:34 - train: epoch 0135, iter [00050, 00390], lr: 0.004000, loss: 0.0083
2022-03-20 21:24:45 - train: epoch 0135, iter [00100, 00390], lr: 0.004000, loss: 0.0269
2022-03-20 21:24:56 - train: epoch 0135, iter [00150, 00390], lr: 0.004000, loss: 0.0207
2022-03-20 21:25:07 - train: epoch 0135, iter [00200, 00390], lr: 0.004000, loss: 0.0117
2022-03-20 21:25:18 - train: epoch 0135, iter [00250, 00390], lr: 0.004000, loss: 0.0241
2022-03-20 21:25:30 - train: epoch 0135, iter [00300, 00390], lr: 0.004000, loss: 0.0116
2022-03-20 21:25:41 - train: epoch 0135, iter [00350, 00390], lr: 0.004000, loss: 0.0067
2022-03-20 21:25:51 - train: epoch 135, train_loss: 0.0133
2022-03-20 21:25:58 - eval: epoch: 135, acc1: 77.820%, acc5: 94.360%, test_loss: 0.9276, per_image_load_time: 0.337ms, per_image_inference_time: 0.410ms
2022-03-20 21:26:00 - until epoch: 135, best_acc1: 78.120%
2022-03-20 21:26:00 - epoch 136 lr: 0.004000000000000001
2022-03-20 21:26:15 - train: epoch 0136, iter [00050, 00390], lr: 0.004000, loss: 0.0101
2022-03-20 21:26:26 - train: epoch 0136, iter [00100, 00390], lr: 0.004000, loss: 0.0086
2022-03-20 21:26:38 - train: epoch 0136, iter [00150, 00390], lr: 0.004000, loss: 0.0153
2022-03-20 21:26:50 - train: epoch 0136, iter [00200, 00390], lr: 0.004000, loss: 0.0076
2022-03-20 21:27:01 - train: epoch 0136, iter [00250, 00390], lr: 0.004000, loss: 0.0117
2022-03-20 21:27:12 - train: epoch 0136, iter [00300, 00390], lr: 0.004000, loss: 0.0118
2022-03-20 21:27:24 - train: epoch 0136, iter [00350, 00390], lr: 0.004000, loss: 0.0148
2022-03-20 21:27:34 - train: epoch 136, train_loss: 0.0130
2022-03-20 21:27:42 - eval: epoch: 136, acc1: 77.980%, acc5: 94.450%, test_loss: 0.9209, per_image_load_time: 0.358ms, per_image_inference_time: 0.420ms
2022-03-20 21:27:44 - until epoch: 136, best_acc1: 78.120%
2022-03-20 21:27:44 - epoch 137 lr: 0.004000000000000001
2022-03-20 21:27:58 - train: epoch 0137, iter [00050, 00390], lr: 0.004000, loss: 0.0073
2022-03-20 21:28:10 - train: epoch 0137, iter [00100, 00390], lr: 0.004000, loss: 0.0072
2022-03-20 21:28:21 - train: epoch 0137, iter [00150, 00390], lr: 0.004000, loss: 0.0126
2022-03-20 21:28:33 - train: epoch 0137, iter [00200, 00390], lr: 0.004000, loss: 0.0120
2022-03-20 21:28:44 - train: epoch 0137, iter [00250, 00390], lr: 0.004000, loss: 0.0121
2022-03-20 21:28:55 - train: epoch 0137, iter [00300, 00390], lr: 0.004000, loss: 0.0062
2022-03-20 21:29:07 - train: epoch 0137, iter [00350, 00390], lr: 0.004000, loss: 0.0161
2022-03-20 21:29:17 - train: epoch 137, train_loss: 0.0123
2022-03-20 21:29:25 - eval: epoch: 137, acc1: 78.020%, acc5: 94.620%, test_loss: 0.9226, per_image_load_time: 0.334ms, per_image_inference_time: 0.410ms
2022-03-20 21:29:26 - until epoch: 137, best_acc1: 78.120%
2022-03-20 21:29:26 - epoch 138 lr: 0.004000000000000001
2022-03-20 21:29:41 - train: epoch 0138, iter [00050, 00390], lr: 0.004000, loss: 0.0075
2022-03-20 21:29:53 - train: epoch 0138, iter [00100, 00390], lr: 0.004000, loss: 0.0115
2022-03-20 21:30:05 - train: epoch 0138, iter [00150, 00390], lr: 0.004000, loss: 0.0075
2022-03-20 21:30:17 - train: epoch 0138, iter [00200, 00390], lr: 0.004000, loss: 0.0432
2022-03-20 21:30:28 - train: epoch 0138, iter [00250, 00390], lr: 0.004000, loss: 0.0133
2022-03-20 21:30:40 - train: epoch 0138, iter [00300, 00390], lr: 0.004000, loss: 0.0130
2022-03-20 21:30:51 - train: epoch 0138, iter [00350, 00390], lr: 0.004000, loss: 0.0076
2022-03-20 21:31:01 - train: epoch 138, train_loss: 0.0127
2022-03-20 21:31:09 - eval: epoch: 138, acc1: 77.960%, acc5: 94.490%, test_loss: 0.9194, per_image_load_time: 0.317ms, per_image_inference_time: 0.418ms
2022-03-20 21:31:10 - until epoch: 138, best_acc1: 78.120%
2022-03-20 21:31:10 - epoch 139 lr: 0.004000000000000001
2022-03-20 21:31:25 - train: epoch 0139, iter [00050, 00390], lr: 0.004000, loss: 0.0103
2022-03-20 21:31:37 - train: epoch 0139, iter [00100, 00390], lr: 0.004000, loss: 0.0174
2022-03-20 21:31:48 - train: epoch 0139, iter [00150, 00390], lr: 0.004000, loss: 0.0331
2022-03-20 21:31:59 - train: epoch 0139, iter [00200, 00390], lr: 0.004000, loss: 0.0121
2022-03-20 21:32:11 - train: epoch 0139, iter [00250, 00390], lr: 0.004000, loss: 0.0056
2022-03-20 21:32:23 - train: epoch 0139, iter [00300, 00390], lr: 0.004000, loss: 0.0110
2022-03-20 21:32:35 - train: epoch 0139, iter [00350, 00390], lr: 0.004000, loss: 0.0143
2022-03-20 21:32:45 - train: epoch 139, train_loss: 0.0118
2022-03-20 21:32:53 - eval: epoch: 139, acc1: 78.090%, acc5: 94.440%, test_loss: 0.9134, per_image_load_time: 0.354ms, per_image_inference_time: 0.420ms
2022-03-20 21:32:54 - until epoch: 139, best_acc1: 78.120%
2022-03-20 21:32:54 - epoch 140 lr: 0.004000000000000001
2022-03-20 21:33:09 - train: epoch 0140, iter [00050, 00390], lr: 0.004000, loss: 0.0192
2022-03-20 21:33:21 - train: epoch 0140, iter [00100, 00390], lr: 0.004000, loss: 0.0054
2022-03-20 21:33:32 - train: epoch 0140, iter [00150, 00390], lr: 0.004000, loss: 0.0178
2022-03-20 21:33:44 - train: epoch 0140, iter [00200, 00390], lr: 0.004000, loss: 0.0184
2022-03-20 21:33:55 - train: epoch 0140, iter [00250, 00390], lr: 0.004000, loss: 0.0110
2022-03-20 21:34:06 - train: epoch 0140, iter [00300, 00390], lr: 0.004000, loss: 0.0120
2022-03-20 21:34:17 - train: epoch 0140, iter [00350, 00390], lr: 0.004000, loss: 0.0099
2022-03-20 21:34:27 - train: epoch 140, train_loss: 0.0117
2022-03-20 21:34:35 - eval: epoch: 140, acc1: 78.160%, acc5: 94.410%, test_loss: 0.9187, per_image_load_time: 0.334ms, per_image_inference_time: 0.412ms
2022-03-20 21:34:37 - until epoch: 140, best_acc1: 78.160%
2022-03-20 21:34:37 - epoch 141 lr: 0.004000000000000001
2022-03-20 21:34:52 - train: epoch 0141, iter [00050, 00390], lr: 0.004000, loss: 0.0103
2022-03-20 21:35:03 - train: epoch 0141, iter [00100, 00390], lr: 0.004000, loss: 0.0077
2022-03-20 21:35:15 - train: epoch 0141, iter [00150, 00390], lr: 0.004000, loss: 0.0090
2022-03-20 21:35:26 - train: epoch 0141, iter [00200, 00390], lr: 0.004000, loss: 0.0101
2022-03-20 21:35:37 - train: epoch 0141, iter [00250, 00390], lr: 0.004000, loss: 0.0107
2022-03-20 21:35:49 - train: epoch 0141, iter [00300, 00390], lr: 0.004000, loss: 0.0087
2022-03-20 21:36:00 - train: epoch 0141, iter [00350, 00390], lr: 0.004000, loss: 0.0063
2022-03-20 21:36:10 - train: epoch 141, train_loss: 0.0108
2022-03-20 21:36:18 - eval: epoch: 141, acc1: 78.090%, acc5: 94.480%, test_loss: 0.9111, per_image_load_time: 0.363ms, per_image_inference_time: 0.413ms
2022-03-20 21:36:20 - until epoch: 141, best_acc1: 78.160%
2022-03-20 21:36:20 - epoch 142 lr: 0.004000000000000001
2022-03-20 21:36:35 - train: epoch 0142, iter [00050, 00390], lr: 0.004000, loss: 0.0040
2022-03-20 21:36:46 - train: epoch 0142, iter [00100, 00390], lr: 0.004000, loss: 0.0111
2022-03-20 21:36:58 - train: epoch 0142, iter [00150, 00390], lr: 0.004000, loss: 0.0105
2022-03-20 21:37:09 - train: epoch 0142, iter [00200, 00390], lr: 0.004000, loss: 0.0113
2022-03-20 21:37:20 - train: epoch 0142, iter [00250, 00390], lr: 0.004000, loss: 0.0077
2022-03-20 21:37:31 - train: epoch 0142, iter [00300, 00390], lr: 0.004000, loss: 0.0086
2022-03-20 21:37:43 - train: epoch 0142, iter [00350, 00390], lr: 0.004000, loss: 0.0097
2022-03-20 21:37:52 - train: epoch 142, train_loss: 0.0116
2022-03-20 21:38:00 - eval: epoch: 142, acc1: 78.220%, acc5: 94.520%, test_loss: 0.9094, per_image_load_time: 0.342ms, per_image_inference_time: 0.416ms
2022-03-20 21:38:02 - until epoch: 142, best_acc1: 78.220%
2022-03-20 21:38:02 - epoch 143 lr: 0.004000000000000001
2022-03-20 21:38:18 - train: epoch 0143, iter [00050, 00390], lr: 0.004000, loss: 0.0084
2022-03-20 21:38:29 - train: epoch 0143, iter [00100, 00390], lr: 0.004000, loss: 0.0136
2022-03-20 21:38:41 - train: epoch 0143, iter [00150, 00390], lr: 0.004000, loss: 0.0164
2022-03-20 21:38:52 - train: epoch 0143, iter [00200, 00390], lr: 0.004000, loss: 0.0109
2022-03-20 21:39:04 - train: epoch 0143, iter [00250, 00390], lr: 0.004000, loss: 0.0066
2022-03-20 21:39:15 - train: epoch 0143, iter [00300, 00390], lr: 0.004000, loss: 0.0096
2022-03-20 21:39:27 - train: epoch 0143, iter [00350, 00390], lr: 0.004000, loss: 0.0116
2022-03-20 21:39:36 - train: epoch 143, train_loss: 0.0116
2022-03-20 21:39:44 - eval: epoch: 143, acc1: 78.350%, acc5: 94.560%, test_loss: 0.8992, per_image_load_time: 0.334ms, per_image_inference_time: 0.409ms
2022-03-20 21:39:47 - until epoch: 143, best_acc1: 78.350%
2022-03-20 21:39:47 - epoch 144 lr: 0.004000000000000001
2022-03-20 21:40:01 - train: epoch 0144, iter [00050, 00390], lr: 0.004000, loss: 0.0100
2022-03-20 21:40:13 - train: epoch 0144, iter [00100, 00390], lr: 0.004000, loss: 0.0082
2022-03-20 21:40:24 - train: epoch 0144, iter [00150, 00390], lr: 0.004000, loss: 0.0196
2022-03-20 21:40:35 - train: epoch 0144, iter [00200, 00390], lr: 0.004000, loss: 0.0158
2022-03-20 21:40:46 - train: epoch 0144, iter [00250, 00390], lr: 0.004000, loss: 0.0445
2022-03-20 21:40:58 - train: epoch 0144, iter [00300, 00390], lr: 0.004000, loss: 0.0108
2022-03-20 21:41:09 - train: epoch 0144, iter [00350, 00390], lr: 0.004000, loss: 0.0095
2022-03-20 21:41:19 - train: epoch 144, train_loss: 0.0112
2022-03-20 21:41:27 - eval: epoch: 144, acc1: 78.280%, acc5: 94.400%, test_loss: 0.9020, per_image_load_time: 0.345ms, per_image_inference_time: 0.415ms
2022-03-20 21:41:29 - until epoch: 144, best_acc1: 78.350%
2022-03-20 21:41:29 - epoch 145 lr: 0.004000000000000001
2022-03-20 21:41:44 - train: epoch 0145, iter [00050, 00390], lr: 0.004000, loss: 0.0101
2022-03-20 21:41:55 - train: epoch 0145, iter [00100, 00390], lr: 0.004000, loss: 0.0122
2022-03-20 21:42:06 - train: epoch 0145, iter [00150, 00390], lr: 0.004000, loss: 0.0086
2022-03-20 21:42:18 - train: epoch 0145, iter [00200, 00390], lr: 0.004000, loss: 0.0080
2022-03-20 21:42:29 - train: epoch 0145, iter [00250, 00390], lr: 0.004000, loss: 0.0058
2022-03-20 21:42:40 - train: epoch 0145, iter [00300, 00390], lr: 0.004000, loss: 0.0071
2022-03-20 21:42:52 - train: epoch 0145, iter [00350, 00390], lr: 0.004000, loss: 0.0079
2022-03-20 21:43:01 - train: epoch 145, train_loss: 0.0115
2022-03-20 21:43:09 - eval: epoch: 145, acc1: 78.150%, acc5: 94.590%, test_loss: 0.9036, per_image_load_time: 0.328ms, per_image_inference_time: 0.404ms
2022-03-20 21:43:11 - until epoch: 145, best_acc1: 78.350%
2022-03-20 21:43:11 - epoch 146 lr: 0.004000000000000001
2022-03-20 21:43:25 - train: epoch 0146, iter [00050, 00390], lr: 0.004000, loss: 0.0165
2022-03-20 21:43:36 - train: epoch 0146, iter [00100, 00390], lr: 0.004000, loss: 0.0081
2022-03-20 21:43:48 - train: epoch 0146, iter [00150, 00390], lr: 0.004000, loss: 0.0173
2022-03-20 21:43:59 - train: epoch 0146, iter [00200, 00390], lr: 0.004000, loss: 0.0134
2022-03-20 21:44:10 - train: epoch 0146, iter [00250, 00390], lr: 0.004000, loss: 0.0096
2022-03-20 21:44:22 - train: epoch 0146, iter [00300, 00390], lr: 0.004000, loss: 0.0109
2022-03-20 21:44:33 - train: epoch 0146, iter [00350, 00390], lr: 0.004000, loss: 0.0071
2022-03-20 21:44:42 - train: epoch 146, train_loss: 0.0111
2022-03-20 21:44:50 - eval: epoch: 146, acc1: 77.970%, acc5: 94.470%, test_loss: 0.9125, per_image_load_time: 0.336ms, per_image_inference_time: 0.416ms
2022-03-20 21:44:51 - until epoch: 146, best_acc1: 78.350%
2022-03-20 21:44:51 - epoch 147 lr: 0.004000000000000001
2022-03-20 21:45:06 - train: epoch 0147, iter [00050, 00390], lr: 0.004000, loss: 0.0090
2022-03-20 21:45:17 - train: epoch 0147, iter [00100, 00390], lr: 0.004000, loss: 0.0069
2022-03-20 21:45:28 - train: epoch 0147, iter [00150, 00390], lr: 0.004000, loss: 0.0131
2022-03-20 21:45:40 - train: epoch 0147, iter [00200, 00390], lr: 0.004000, loss: 0.0082
2022-03-20 21:45:51 - train: epoch 0147, iter [00250, 00390], lr: 0.004000, loss: 0.0126
2022-03-20 21:46:02 - train: epoch 0147, iter [00300, 00390], lr: 0.004000, loss: 0.0113
2022-03-20 21:46:14 - train: epoch 0147, iter [00350, 00390], lr: 0.004000, loss: 0.0100
2022-03-20 21:46:23 - train: epoch 147, train_loss: 0.0108
2022-03-20 21:46:31 - eval: epoch: 147, acc1: 78.220%, acc5: 94.540%, test_loss: 0.9058, per_image_load_time: 0.332ms, per_image_inference_time: 0.404ms
2022-03-20 21:46:33 - until epoch: 147, best_acc1: 78.350%
2022-03-20 21:46:33 - epoch 148 lr: 0.004000000000000001
2022-03-20 21:46:47 - train: epoch 0148, iter [00050, 00390], lr: 0.004000, loss: 0.0130
2022-03-20 21:46:59 - train: epoch 0148, iter [00100, 00390], lr: 0.004000, loss: 0.0126
2022-03-20 21:47:11 - train: epoch 0148, iter [00150, 00390], lr: 0.004000, loss: 0.0059
2022-03-20 21:47:23 - train: epoch 0148, iter [00200, 00390], lr: 0.004000, loss: 0.0052
2022-03-20 21:47:34 - train: epoch 0148, iter [00250, 00390], lr: 0.004000, loss: 0.0124
2022-03-20 21:47:46 - train: epoch 0148, iter [00300, 00390], lr: 0.004000, loss: 0.0076
2022-03-20 21:47:58 - train: epoch 0148, iter [00350, 00390], lr: 0.004000, loss: 0.0186
2022-03-20 21:48:08 - train: epoch 148, train_loss: 0.0106
2022-03-20 21:48:16 - eval: epoch: 148, acc1: 78.270%, acc5: 94.650%, test_loss: 0.9088, per_image_load_time: 0.341ms, per_image_inference_time: 0.412ms
2022-03-20 21:48:17 - until epoch: 148, best_acc1: 78.350%
2022-03-20 21:48:17 - epoch 149 lr: 0.004000000000000001
2022-03-20 21:48:32 - train: epoch 0149, iter [00050, 00390], lr: 0.004000, loss: 0.0074
2022-03-20 21:48:44 - train: epoch 0149, iter [00100, 00390], lr: 0.004000, loss: 0.0094
2022-03-20 21:48:55 - train: epoch 0149, iter [00150, 00390], lr: 0.004000, loss: 0.0153
2022-03-20 21:49:07 - train: epoch 0149, iter [00200, 00390], lr: 0.004000, loss: 0.0141
2022-03-20 21:49:19 - train: epoch 0149, iter [00250, 00390], lr: 0.004000, loss: 0.0154
2022-03-20 21:49:31 - train: epoch 0149, iter [00300, 00390], lr: 0.004000, loss: 0.0063
2022-03-20 21:49:43 - train: epoch 0149, iter [00350, 00390], lr: 0.004000, loss: 0.0076
2022-03-20 21:49:53 - train: epoch 149, train_loss: 0.0111
2022-03-20 21:50:01 - eval: epoch: 149, acc1: 77.980%, acc5: 94.490%, test_loss: 0.9036, per_image_load_time: 0.341ms, per_image_inference_time: 0.397ms
2022-03-20 21:50:02 - until epoch: 149, best_acc1: 78.350%
2022-03-20 21:50:02 - epoch 150 lr: 0.004000000000000001
2022-03-20 21:50:17 - train: epoch 0150, iter [00050, 00390], lr: 0.004000, loss: 0.0063
2022-03-20 21:50:29 - train: epoch 0150, iter [00100, 00390], lr: 0.004000, loss: 0.0132
2022-03-20 21:50:40 - train: epoch 0150, iter [00150, 00390], lr: 0.004000, loss: 0.0081
2022-03-20 21:50:51 - train: epoch 0150, iter [00200, 00390], lr: 0.004000, loss: 0.0192
2022-03-20 21:51:03 - train: epoch 0150, iter [00250, 00390], lr: 0.004000, loss: 0.0121
2022-03-20 21:51:14 - train: epoch 0150, iter [00300, 00390], lr: 0.004000, loss: 0.0056
2022-03-20 21:51:26 - train: epoch 0150, iter [00350, 00390], lr: 0.004000, loss: 0.0168
2022-03-20 21:51:35 - train: epoch 150, train_loss: 0.0110
2022-03-20 21:51:43 - eval: epoch: 150, acc1: 78.070%, acc5: 94.520%, test_loss: 0.8968, per_image_load_time: 0.368ms, per_image_inference_time: 0.410ms
2022-03-20 21:51:45 - until epoch: 150, best_acc1: 78.350%
2022-03-20 21:51:45 - epoch 151 lr: 0.004000000000000001
2022-03-20 21:51:59 - train: epoch 0151, iter [00050, 00390], lr: 0.004000, loss: 0.0092
2022-03-20 21:52:11 - train: epoch 0151, iter [00100, 00390], lr: 0.004000, loss: 0.0081
2022-03-20 21:52:22 - train: epoch 0151, iter [00150, 00390], lr: 0.004000, loss: 0.0147
2022-03-20 21:52:34 - train: epoch 0151, iter [00200, 00390], lr: 0.004000, loss: 0.0344
2022-03-20 21:52:45 - train: epoch 0151, iter [00250, 00390], lr: 0.004000, loss: 0.0080
2022-03-20 21:52:57 - train: epoch 0151, iter [00300, 00390], lr: 0.004000, loss: 0.0084
2022-03-20 21:53:08 - train: epoch 0151, iter [00350, 00390], lr: 0.004000, loss: 0.0080
2022-03-20 21:53:18 - train: epoch 151, train_loss: 0.0108
2022-03-20 21:53:25 - eval: epoch: 151, acc1: 78.140%, acc5: 94.580%, test_loss: 0.9036, per_image_load_time: 0.329ms, per_image_inference_time: 0.405ms
2022-03-20 21:53:27 - until epoch: 151, best_acc1: 78.350%
2022-03-20 21:53:27 - epoch 152 lr: 0.004000000000000001
2022-03-20 21:53:42 - train: epoch 0152, iter [00050, 00390], lr: 0.004000, loss: 0.0108
2022-03-20 21:53:53 - train: epoch 0152, iter [00100, 00390], lr: 0.004000, loss: 0.0122
2022-03-20 21:54:04 - train: epoch 0152, iter [00150, 00390], lr: 0.004000, loss: 0.0053
2022-03-20 21:54:16 - train: epoch 0152, iter [00200, 00390], lr: 0.004000, loss: 0.0102
2022-03-20 21:54:27 - train: epoch 0152, iter [00250, 00390], lr: 0.004000, loss: 0.0093
2022-03-20 21:54:39 - train: epoch 0152, iter [00300, 00390], lr: 0.004000, loss: 0.0074
2022-03-20 21:54:50 - train: epoch 0152, iter [00350, 00390], lr: 0.004000, loss: 0.0115
2022-03-20 21:54:59 - train: epoch 152, train_loss: 0.0108
2022-03-20 21:55:07 - eval: epoch: 152, acc1: 78.220%, acc5: 94.440%, test_loss: 0.8982, per_image_load_time: 0.290ms, per_image_inference_time: 0.421ms
2022-03-20 21:55:09 - until epoch: 152, best_acc1: 78.350%
2022-03-20 21:55:09 - epoch 153 lr: 0.004000000000000001
2022-03-20 21:55:23 - train: epoch 0153, iter [00050, 00390], lr: 0.004000, loss: 0.0066
2022-03-20 21:55:35 - train: epoch 0153, iter [00100, 00390], lr: 0.004000, loss: 0.0063
2022-03-20 21:55:46 - train: epoch 0153, iter [00150, 00390], lr: 0.004000, loss: 0.0108
2022-03-20 21:55:58 - train: epoch 0153, iter [00200, 00390], lr: 0.004000, loss: 0.0092
2022-03-20 21:56:09 - train: epoch 0153, iter [00250, 00390], lr: 0.004000, loss: 0.0106
2022-03-20 21:56:20 - train: epoch 0153, iter [00300, 00390], lr: 0.004000, loss: 0.0101
2022-03-20 21:56:31 - train: epoch 0153, iter [00350, 00390], lr: 0.004000, loss: 0.0057
2022-03-20 21:56:41 - train: epoch 153, train_loss: 0.0109
2022-03-20 21:56:49 - eval: epoch: 153, acc1: 78.230%, acc5: 94.520%, test_loss: 0.8962, per_image_load_time: 0.336ms, per_image_inference_time: 0.409ms
2022-03-20 21:56:51 - until epoch: 153, best_acc1: 78.350%
2022-03-20 21:56:51 - epoch 154 lr: 0.004000000000000001
2022-03-20 21:57:05 - train: epoch 0154, iter [00050, 00390], lr: 0.004000, loss: 0.0168
2022-03-20 21:57:16 - train: epoch 0154, iter [00100, 00390], lr: 0.004000, loss: 0.0084
2022-03-20 21:57:27 - train: epoch 0154, iter [00150, 00390], lr: 0.004000, loss: 0.0087
2022-03-20 21:57:38 - train: epoch 0154, iter [00200, 00390], lr: 0.004000, loss: 0.0227
2022-03-20 21:57:50 - train: epoch 0154, iter [00250, 00390], lr: 0.004000, loss: 0.0086
2022-03-20 21:58:01 - train: epoch 0154, iter [00300, 00390], lr: 0.004000, loss: 0.0059
2022-03-20 21:58:12 - train: epoch 0154, iter [00350, 00390], lr: 0.004000, loss: 0.0082
2022-03-20 21:58:21 - train: epoch 154, train_loss: 0.0106
2022-03-20 21:58:29 - eval: epoch: 154, acc1: 78.230%, acc5: 94.500%, test_loss: 0.8917, per_image_load_time: 0.329ms, per_image_inference_time: 0.405ms
2022-03-20 21:58:30 - until epoch: 154, best_acc1: 78.350%
2022-03-20 21:58:30 - epoch 155 lr: 0.004000000000000001
2022-03-20 21:58:45 - train: epoch 0155, iter [00050, 00390], lr: 0.004000, loss: 0.0084
2022-03-20 21:58:56 - train: epoch 0155, iter [00100, 00390], lr: 0.004000, loss: 0.0082
2022-03-20 21:59:07 - train: epoch 0155, iter [00150, 00390], lr: 0.004000, loss: 0.0062
2022-03-20 21:59:18 - train: epoch 0155, iter [00200, 00390], lr: 0.004000, loss: 0.0115
2022-03-20 21:59:29 - train: epoch 0155, iter [00250, 00390], lr: 0.004000, loss: 0.0118
2022-03-20 21:59:40 - train: epoch 0155, iter [00300, 00390], lr: 0.004000, loss: 0.0062
2022-03-20 21:59:51 - train: epoch 0155, iter [00350, 00390], lr: 0.004000, loss: 0.0083
2022-03-20 22:00:01 - train: epoch 155, train_loss: 0.0107
2022-03-20 22:00:08 - eval: epoch: 155, acc1: 78.280%, acc5: 94.290%, test_loss: 0.8931, per_image_load_time: 0.324ms, per_image_inference_time: 0.407ms
2022-03-20 22:00:10 - until epoch: 155, best_acc1: 78.350%
2022-03-20 22:00:10 - epoch 156 lr: 0.004000000000000001
2022-03-20 22:00:24 - train: epoch 0156, iter [00050, 00390], lr: 0.004000, loss: 0.0076
2022-03-20 22:00:35 - train: epoch 0156, iter [00100, 00390], lr: 0.004000, loss: 0.0058
2022-03-20 22:00:46 - train: epoch 0156, iter [00150, 00390], lr: 0.004000, loss: 0.0134
2022-03-20 22:00:57 - train: epoch 0156, iter [00200, 00390], lr: 0.004000, loss: 0.0069
2022-03-20 22:01:08 - train: epoch 0156, iter [00250, 00390], lr: 0.004000, loss: 0.0314
2022-03-20 22:01:19 - train: epoch 0156, iter [00300, 00390], lr: 0.004000, loss: 0.0127
2022-03-20 22:01:30 - train: epoch 0156, iter [00350, 00390], lr: 0.004000, loss: 0.0055
2022-03-20 22:01:39 - train: epoch 156, train_loss: 0.0113
2022-03-20 22:01:47 - eval: epoch: 156, acc1: 78.180%, acc5: 94.530%, test_loss: 0.8937, per_image_load_time: 0.336ms, per_image_inference_time: 0.418ms
2022-03-20 22:01:48 - until epoch: 156, best_acc1: 78.350%
2022-03-20 22:01:48 - epoch 157 lr: 0.004000000000000001
2022-03-20 22:02:02 - train: epoch 0157, iter [00050, 00390], lr: 0.004000, loss: 0.0174
2022-03-20 22:02:13 - train: epoch 0157, iter [00100, 00390], lr: 0.004000, loss: 0.0212
2022-03-20 22:02:24 - train: epoch 0157, iter [00150, 00390], lr: 0.004000, loss: 0.0118
2022-03-20 22:02:35 - train: epoch 0157, iter [00200, 00390], lr: 0.004000, loss: 0.0076
2022-03-20 22:02:46 - train: epoch 0157, iter [00250, 00390], lr: 0.004000, loss: 0.0064
2022-03-20 22:02:57 - train: epoch 0157, iter [00300, 00390], lr: 0.004000, loss: 0.0119
2022-03-20 22:03:08 - train: epoch 0157, iter [00350, 00390], lr: 0.004000, loss: 0.0106
2022-03-20 22:03:18 - train: epoch 157, train_loss: 0.0105
2022-03-20 22:03:26 - eval: epoch: 157, acc1: 78.070%, acc5: 94.390%, test_loss: 0.8867, per_image_load_time: 0.340ms, per_image_inference_time: 0.403ms
2022-03-20 22:03:27 - until epoch: 157, best_acc1: 78.350%
2022-03-20 22:03:27 - epoch 158 lr: 0.004000000000000001
2022-03-20 22:03:42 - train: epoch 0158, iter [00050, 00390], lr: 0.004000, loss: 0.0109
2022-03-20 22:03:53 - train: epoch 0158, iter [00100, 00390], lr: 0.004000, loss: 0.0103
2022-03-20 22:04:04 - train: epoch 0158, iter [00150, 00390], lr: 0.004000, loss: 0.0085
2022-03-20 22:04:15 - train: epoch 0158, iter [00200, 00390], lr: 0.004000, loss: 0.0159
2022-03-20 22:04:26 - train: epoch 0158, iter [00250, 00390], lr: 0.004000, loss: 0.0105
2022-03-20 22:04:37 - train: epoch 0158, iter [00300, 00390], lr: 0.004000, loss: 0.0157
2022-03-20 22:04:48 - train: epoch 0158, iter [00350, 00390], lr: 0.004000, loss: 0.0119
2022-03-20 22:04:57 - train: epoch 158, train_loss: 0.0107
2022-03-20 22:05:05 - eval: epoch: 158, acc1: 78.170%, acc5: 94.430%, test_loss: 0.8925, per_image_load_time: 0.332ms, per_image_inference_time: 0.411ms
2022-03-20 22:05:07 - until epoch: 158, best_acc1: 78.350%
2022-03-20 22:05:07 - epoch 159 lr: 0.004000000000000001
2022-03-20 22:05:21 - train: epoch 0159, iter [00050, 00390], lr: 0.004000, loss: 0.0084
2022-03-20 22:05:32 - train: epoch 0159, iter [00100, 00390], lr: 0.004000, loss: 0.0176
2022-03-20 22:05:43 - train: epoch 0159, iter [00150, 00390], lr: 0.004000, loss: 0.0084
2022-03-20 22:05:54 - train: epoch 0159, iter [00200, 00390], lr: 0.004000, loss: 0.0094
2022-03-20 22:06:05 - train: epoch 0159, iter [00250, 00390], lr: 0.004000, loss: 0.0358
2022-03-20 22:06:16 - train: epoch 0159, iter [00300, 00390], lr: 0.004000, loss: 0.0076
2022-03-20 22:06:28 - train: epoch 0159, iter [00350, 00390], lr: 0.004000, loss: 0.0086
2022-03-20 22:06:37 - train: epoch 159, train_loss: 0.0109
2022-03-20 22:06:44 - eval: epoch: 159, acc1: 78.150%, acc5: 94.270%, test_loss: 0.8928, per_image_load_time: 0.313ms, per_image_inference_time: 0.394ms
2022-03-20 22:06:45 - until epoch: 159, best_acc1: 78.350%
2022-03-20 22:06:45 - epoch 160 lr: 0.004000000000000001
2022-03-20 22:07:00 - train: epoch 0160, iter [00050, 00390], lr: 0.004000, loss: 0.0079
2022-03-20 22:07:11 - train: epoch 0160, iter [00100, 00390], lr: 0.004000, loss: 0.0093
2022-03-20 22:07:22 - train: epoch 0160, iter [00150, 00390], lr: 0.004000, loss: 0.0060
2022-03-20 22:07:33 - train: epoch 0160, iter [00200, 00390], lr: 0.004000, loss: 0.0065
2022-03-20 22:07:44 - train: epoch 0160, iter [00250, 00390], lr: 0.004000, loss: 0.0062
2022-03-20 22:07:55 - train: epoch 0160, iter [00300, 00390], lr: 0.004000, loss: 0.0236
2022-03-20 22:08:06 - train: epoch 0160, iter [00350, 00390], lr: 0.004000, loss: 0.0067
2022-03-20 22:08:16 - train: epoch 160, train_loss: 0.0108
2022-03-20 22:08:23 - eval: epoch: 160, acc1: 77.940%, acc5: 94.550%, test_loss: 0.8949, per_image_load_time: 0.334ms, per_image_inference_time: 0.410ms
2022-03-20 22:08:25 - until epoch: 160, best_acc1: 78.350%
2022-03-20 22:08:25 - epoch 161 lr: 0.0008000000000000003
2022-03-20 22:08:40 - train: epoch 0161, iter [00050, 00390], lr: 0.000800, loss: 0.0080
2022-03-20 22:08:51 - train: epoch 0161, iter [00100, 00390], lr: 0.000800, loss: 0.0106
2022-03-20 22:09:02 - train: epoch 0161, iter [00150, 00390], lr: 0.000800, loss: 0.0078
2022-03-20 22:09:13 - train: epoch 0161, iter [00200, 00390], lr: 0.000800, loss: 0.0074
2022-03-20 22:09:24 - train: epoch 0161, iter [00250, 00390], lr: 0.000800, loss: 0.0100
2022-03-20 22:09:35 - train: epoch 0161, iter [00300, 00390], lr: 0.000800, loss: 0.0092
2022-03-20 22:09:46 - train: epoch 0161, iter [00350, 00390], lr: 0.000800, loss: 0.0223
2022-03-20 22:09:56 - train: epoch 161, train_loss: 0.0100
2022-03-20 22:10:04 - eval: epoch: 161, acc1: 78.220%, acc5: 94.510%, test_loss: 0.8926, per_image_load_time: 0.341ms, per_image_inference_time: 0.402ms
2022-03-20 22:10:05 - until epoch: 161, best_acc1: 78.350%
2022-03-20 22:10:05 - epoch 162 lr: 0.0008000000000000003
2022-03-20 22:10:20 - train: epoch 0162, iter [00050, 00390], lr: 0.000800, loss: 0.0099
2022-03-20 22:10:31 - train: epoch 0162, iter [00100, 00390], lr: 0.000800, loss: 0.0067
2022-03-20 22:10:42 - train: epoch 0162, iter [00150, 00390], lr: 0.000800, loss: 0.0074
2022-03-20 22:10:53 - train: epoch 0162, iter [00200, 00390], lr: 0.000800, loss: 0.0106
2022-03-20 22:11:04 - train: epoch 0162, iter [00250, 00390], lr: 0.000800, loss: 0.0085
2022-03-20 22:11:15 - train: epoch 0162, iter [00300, 00390], lr: 0.000800, loss: 0.0105
2022-03-20 22:11:26 - train: epoch 0162, iter [00350, 00390], lr: 0.000800, loss: 0.0085
2022-03-20 22:11:35 - train: epoch 162, train_loss: 0.0097
2022-03-20 22:11:43 - eval: epoch: 162, acc1: 78.250%, acc5: 94.570%, test_loss: 0.8876, per_image_load_time: 0.332ms, per_image_inference_time: 0.401ms
2022-03-20 22:11:43 - until epoch: 162, best_acc1: 78.350%
2022-03-20 22:11:43 - epoch 163 lr: 0.0008000000000000003
2022-03-20 22:11:58 - train: epoch 0163, iter [00050, 00390], lr: 0.000800, loss: 0.0139
2022-03-20 22:12:09 - train: epoch 0163, iter [00100, 00390], lr: 0.000800, loss: 0.0070
2022-03-20 22:12:20 - train: epoch 0163, iter [00150, 00390], lr: 0.000800, loss: 0.0080
2022-03-20 22:12:31 - train: epoch 0163, iter [00200, 00390], lr: 0.000800, loss: 0.0091
2022-03-20 22:12:42 - train: epoch 0163, iter [00250, 00390], lr: 0.000800, loss: 0.0118
2022-03-20 22:12:53 - train: epoch 0163, iter [00300, 00390], lr: 0.000800, loss: 0.0054
2022-03-20 22:13:04 - train: epoch 0163, iter [00350, 00390], lr: 0.000800, loss: 0.0128
2022-03-20 22:13:14 - train: epoch 163, train_loss: 0.0096
2022-03-20 22:13:22 - eval: epoch: 163, acc1: 78.400%, acc5: 94.580%, test_loss: 0.8855, per_image_load_time: 0.325ms, per_image_inference_time: 0.406ms
2022-03-20 22:13:24 - until epoch: 163, best_acc1: 78.400%
2022-03-20 22:13:24 - epoch 164 lr: 0.0008000000000000003
2022-03-20 22:13:38 - train: epoch 0164, iter [00050, 00390], lr: 0.000800, loss: 0.0086
2022-03-20 22:13:49 - train: epoch 0164, iter [00100, 00390], lr: 0.000800, loss: 0.0123
2022-03-20 22:14:00 - train: epoch 0164, iter [00150, 00390], lr: 0.000800, loss: 0.0085
2022-03-20 22:14:11 - train: epoch 0164, iter [00200, 00390], lr: 0.000800, loss: 0.0048
2022-03-20 22:14:22 - train: epoch 0164, iter [00250, 00390], lr: 0.000800, loss: 0.0050
2022-03-20 22:14:33 - train: epoch 0164, iter [00300, 00390], lr: 0.000800, loss: 0.0098
2022-03-20 22:14:44 - train: epoch 0164, iter [00350, 00390], lr: 0.000800, loss: 0.0078
2022-03-20 22:14:53 - train: epoch 164, train_loss: 0.0094
2022-03-20 22:15:01 - eval: epoch: 164, acc1: 78.330%, acc5: 94.630%, test_loss: 0.8824, per_image_load_time: 0.333ms, per_image_inference_time: 0.403ms
2022-03-20 22:15:03 - until epoch: 164, best_acc1: 78.400%
2022-03-20 22:15:03 - epoch 165 lr: 0.0008000000000000003
2022-03-20 22:15:17 - train: epoch 0165, iter [00050, 00390], lr: 0.000800, loss: 0.0059
2022-03-20 22:15:28 - train: epoch 0165, iter [00100, 00390], lr: 0.000800, loss: 0.0059
2022-03-20 22:15:39 - train: epoch 0165, iter [00150, 00390], lr: 0.000800, loss: 0.0139
2022-03-20 22:15:51 - train: epoch 0165, iter [00200, 00390], lr: 0.000800, loss: 0.0067
2022-03-20 22:16:02 - train: epoch 0165, iter [00250, 00390], lr: 0.000800, loss: 0.0071
2022-03-20 22:16:13 - train: epoch 0165, iter [00300, 00390], lr: 0.000800, loss: 0.0100
2022-03-20 22:16:24 - train: epoch 0165, iter [00350, 00390], lr: 0.000800, loss: 0.0076
2022-03-20 22:16:34 - train: epoch 165, train_loss: 0.0093
2022-03-20 22:16:42 - eval: epoch: 165, acc1: 78.360%, acc5: 94.600%, test_loss: 0.8848, per_image_load_time: 0.334ms, per_image_inference_time: 0.408ms
2022-03-20 22:16:43 - until epoch: 165, best_acc1: 78.400%
2022-03-20 22:16:43 - epoch 166 lr: 0.0008000000000000003
2022-03-20 22:16:58 - train: epoch 0166, iter [00050, 00390], lr: 0.000800, loss: 0.0067
2022-03-20 22:17:09 - train: epoch 0166, iter [00100, 00390], lr: 0.000800, loss: 0.0076
2022-03-20 22:17:20 - train: epoch 0166, iter [00150, 00390], lr: 0.000800, loss: 0.0140
2022-03-20 22:17:31 - train: epoch 0166, iter [00200, 00390], lr: 0.000800, loss: 0.0066
2022-03-20 22:17:42 - train: epoch 0166, iter [00250, 00390], lr: 0.000800, loss: 0.0068
2022-03-20 22:17:53 - train: epoch 0166, iter [00300, 00390], lr: 0.000800, loss: 0.0088
2022-03-20 22:18:04 - train: epoch 0166, iter [00350, 00390], lr: 0.000800, loss: 0.0126
2022-03-20 22:18:13 - train: epoch 166, train_loss: 0.0092
2022-03-20 22:18:21 - eval: epoch: 166, acc1: 78.610%, acc5: 94.590%, test_loss: 0.8838, per_image_load_time: 0.338ms, per_image_inference_time: 0.405ms
2022-03-20 22:18:23 - until epoch: 166, best_acc1: 78.610%
2022-03-20 22:18:23 - epoch 167 lr: 0.0008000000000000003
2022-03-20 22:18:38 - train: epoch 0167, iter [00050, 00390], lr: 0.000800, loss: 0.0086
2022-03-20 22:18:49 - train: epoch 0167, iter [00100, 00390], lr: 0.000800, loss: 0.0109
2022-03-20 22:19:00 - train: epoch 0167, iter [00150, 00390], lr: 0.000800, loss: 0.0046
2022-03-20 22:19:11 - train: epoch 0167, iter [00200, 00390], lr: 0.000800, loss: 0.0107
2022-03-20 22:19:22 - train: epoch 0167, iter [00250, 00390], lr: 0.000800, loss: 0.0080
2022-03-20 22:19:33 - train: epoch 0167, iter [00300, 00390], lr: 0.000800, loss: 0.0076
2022-03-20 22:19:44 - train: epoch 0167, iter [00350, 00390], lr: 0.000800, loss: 0.0082
2022-03-20 22:19:53 - train: epoch 167, train_loss: 0.0089
2022-03-20 22:20:01 - eval: epoch: 167, acc1: 78.350%, acc5: 94.520%, test_loss: 0.8807, per_image_load_time: 0.332ms, per_image_inference_time: 0.434ms
2022-03-20 22:20:03 - until epoch: 167, best_acc1: 78.610%
2022-03-20 22:20:03 - epoch 168 lr: 0.0008000000000000003
2022-03-20 22:20:17 - train: epoch 0168, iter [00050, 00390], lr: 0.000800, loss: 0.0045
2022-03-20 22:20:28 - train: epoch 0168, iter [00100, 00390], lr: 0.000800, loss: 0.0089
2022-03-20 22:20:39 - train: epoch 0168, iter [00150, 00390], lr: 0.000800, loss: 0.0119
2022-03-20 22:20:51 - train: epoch 0168, iter [00200, 00390], lr: 0.000800, loss: 0.0063
2022-03-20 22:21:02 - train: epoch 0168, iter [00250, 00390], lr: 0.000800, loss: 0.0072
2022-03-20 22:21:13 - train: epoch 0168, iter [00300, 00390], lr: 0.000800, loss: 0.0099
2022-03-20 22:21:24 - train: epoch 0168, iter [00350, 00390], lr: 0.000800, loss: 0.0087
2022-03-20 22:21:33 - train: epoch 168, train_loss: 0.0089
2022-03-20 22:21:41 - eval: epoch: 168, acc1: 78.380%, acc5: 94.580%, test_loss: 0.8839, per_image_load_time: 0.339ms, per_image_inference_time: 0.404ms
2022-03-20 22:21:43 - until epoch: 168, best_acc1: 78.610%
2022-03-20 22:21:43 - epoch 169 lr: 0.0008000000000000003
2022-03-20 22:21:57 - train: epoch 0169, iter [00050, 00390], lr: 0.000800, loss: 0.0058
2022-03-20 22:22:08 - train: epoch 0169, iter [00100, 00390], lr: 0.000800, loss: 0.0089
2022-03-20 22:22:19 - train: epoch 0169, iter [00150, 00390], lr: 0.000800, loss: 0.0144
2022-03-20 22:22:30 - train: epoch 0169, iter [00200, 00390], lr: 0.000800, loss: 0.0086
2022-03-20 22:22:41 - train: epoch 0169, iter [00250, 00390], lr: 0.000800, loss: 0.0131
2022-03-20 22:22:52 - train: epoch 0169, iter [00300, 00390], lr: 0.000800, loss: 0.0079
2022-03-20 22:23:03 - train: epoch 0169, iter [00350, 00390], lr: 0.000800, loss: 0.0096
2022-03-20 22:23:12 - train: epoch 169, train_loss: 0.0088
2022-03-20 22:23:20 - eval: epoch: 169, acc1: 78.450%, acc5: 94.580%, test_loss: 0.8824, per_image_load_time: 0.306ms, per_image_inference_time: 0.413ms
2022-03-20 22:23:22 - until epoch: 169, best_acc1: 78.610%
2022-03-20 22:23:22 - epoch 170 lr: 0.0008000000000000003
2022-03-20 22:23:36 - train: epoch 0170, iter [00050, 00390], lr: 0.000800, loss: 0.0099
2022-03-20 22:23:47 - train: epoch 0170, iter [00100, 00390], lr: 0.000800, loss: 0.0099
2022-03-20 22:23:58 - train: epoch 0170, iter [00150, 00390], lr: 0.000800, loss: 0.0097
2022-03-20 22:24:09 - train: epoch 0170, iter [00200, 00390], lr: 0.000800, loss: 0.0046
2022-03-20 22:24:20 - train: epoch 0170, iter [00250, 00390], lr: 0.000800, loss: 0.0110
2022-03-20 22:24:31 - train: epoch 0170, iter [00300, 00390], lr: 0.000800, loss: 0.0063
2022-03-20 22:24:42 - train: epoch 0170, iter [00350, 00390], lr: 0.000800, loss: 0.0065
2022-03-20 22:24:52 - train: epoch 170, train_loss: 0.0090
2022-03-20 22:24:59 - eval: epoch: 170, acc1: 78.550%, acc5: 94.640%, test_loss: 0.8790, per_image_load_time: 0.335ms, per_image_inference_time: 0.393ms
2022-03-20 22:25:01 - until epoch: 170, best_acc1: 78.610%
2022-03-20 22:25:01 - epoch 171 lr: 0.0008000000000000003
2022-03-20 22:25:16 - train: epoch 0171, iter [00050, 00390], lr: 0.000800, loss: 0.0043
2022-03-20 22:25:27 - train: epoch 0171, iter [00100, 00390], lr: 0.000800, loss: 0.0110
2022-03-20 22:25:38 - train: epoch 0171, iter [00150, 00390], lr: 0.000800, loss: 0.0093
2022-03-20 22:25:49 - train: epoch 0171, iter [00200, 00390], lr: 0.000800, loss: 0.0057
2022-03-20 22:26:00 - train: epoch 0171, iter [00250, 00390], lr: 0.000800, loss: 0.0056
2022-03-20 22:26:11 - train: epoch 0171, iter [00300, 00390], lr: 0.000800, loss: 0.0076
2022-03-20 22:26:22 - train: epoch 0171, iter [00350, 00390], lr: 0.000800, loss: 0.0082
2022-03-20 22:26:31 - train: epoch 171, train_loss: 0.0089
2022-03-20 22:26:39 - eval: epoch: 171, acc1: 78.420%, acc5: 94.590%, test_loss: 0.8873, per_image_load_time: 0.331ms, per_image_inference_time: 0.405ms
2022-03-20 22:26:40 - until epoch: 171, best_acc1: 78.610%
2022-03-20 22:26:40 - epoch 172 lr: 0.0008000000000000003
2022-03-20 22:26:55 - train: epoch 0172, iter [00050, 00390], lr: 0.000800, loss: 0.0091
2022-03-20 22:27:06 - train: epoch 0172, iter [00100, 00390], lr: 0.000800, loss: 0.0194
2022-03-20 22:27:17 - train: epoch 0172, iter [00150, 00390], lr: 0.000800, loss: 0.0110
2022-03-20 22:27:28 - train: epoch 0172, iter [00200, 00390], lr: 0.000800, loss: 0.0082
2022-03-20 22:27:38 - train: epoch 0172, iter [00250, 00390], lr: 0.000800, loss: 0.0096
2022-03-20 22:27:50 - train: epoch 0172, iter [00300, 00390], lr: 0.000800, loss: 0.0192
2022-03-20 22:28:01 - train: epoch 0172, iter [00350, 00390], lr: 0.000800, loss: 0.0087
2022-03-20 22:28:10 - train: epoch 172, train_loss: 0.0089
2022-03-20 22:28:18 - eval: epoch: 172, acc1: 78.540%, acc5: 94.480%, test_loss: 0.8839, per_image_load_time: 0.328ms, per_image_inference_time: 0.393ms
2022-03-20 22:28:19 - until epoch: 172, best_acc1: 78.610%
2022-03-20 22:28:19 - epoch 173 lr: 0.0008000000000000003
2022-03-20 22:28:33 - train: epoch 0173, iter [00050, 00390], lr: 0.000800, loss: 0.0063
2022-03-20 22:28:44 - train: epoch 0173, iter [00100, 00390], lr: 0.000800, loss: 0.0088
2022-03-20 22:28:55 - train: epoch 0173, iter [00150, 00390], lr: 0.000800, loss: 0.0073
2022-03-20 22:29:06 - train: epoch 0173, iter [00200, 00390], lr: 0.000800, loss: 0.0073
2022-03-20 22:29:18 - train: epoch 0173, iter [00250, 00390], lr: 0.000800, loss: 0.0072
2022-03-20 22:29:29 - train: epoch 0173, iter [00300, 00390], lr: 0.000800, loss: 0.0061
2022-03-20 22:29:40 - train: epoch 0173, iter [00350, 00390], lr: 0.000800, loss: 0.0165
2022-03-20 22:29:49 - train: epoch 173, train_loss: 0.0088
2022-03-20 22:29:57 - eval: epoch: 173, acc1: 78.680%, acc5: 94.500%, test_loss: 0.8822, per_image_load_time: 0.340ms, per_image_inference_time: 0.397ms
2022-03-20 22:29:59 - until epoch: 173, best_acc1: 78.680%
2022-03-20 22:29:59 - epoch 174 lr: 0.0008000000000000003
2022-03-20 22:30:13 - train: epoch 0174, iter [00050, 00390], lr: 0.000800, loss: 0.0062
2022-03-20 22:30:25 - train: epoch 0174, iter [00100, 00390], lr: 0.000800, loss: 0.0090
2022-03-20 22:30:36 - train: epoch 0174, iter [00150, 00390], lr: 0.000800, loss: 0.0065
2022-03-20 22:30:47 - train: epoch 0174, iter [00200, 00390], lr: 0.000800, loss: 0.0253
2022-03-20 22:30:58 - train: epoch 0174, iter [00250, 00390], lr: 0.000800, loss: 0.0090
2022-03-20 22:31:09 - train: epoch 0174, iter [00300, 00390], lr: 0.000800, loss: 0.0051
2022-03-20 22:31:20 - train: epoch 0174, iter [00350, 00390], lr: 0.000800, loss: 0.0058
2022-03-20 22:31:29 - train: epoch 174, train_loss: 0.0086
2022-03-20 22:31:37 - eval: epoch: 174, acc1: 78.540%, acc5: 94.590%, test_loss: 0.8805, per_image_load_time: 0.291ms, per_image_inference_time: 0.401ms
2022-03-20 22:31:38 - until epoch: 174, best_acc1: 78.680%
2022-03-20 22:31:38 - epoch 175 lr: 0.0008000000000000003
2022-03-20 22:31:53 - train: epoch 0175, iter [00050, 00390], lr: 0.000800, loss: 0.0081
2022-03-20 22:32:04 - train: epoch 0175, iter [00100, 00390], lr: 0.000800, loss: 0.0091
2022-03-20 22:32:15 - train: epoch 0175, iter [00150, 00390], lr: 0.000800, loss: 0.0058
2022-03-20 22:32:26 - train: epoch 0175, iter [00200, 00390], lr: 0.000800, loss: 0.0138
2022-03-20 22:32:37 - train: epoch 0175, iter [00250, 00390], lr: 0.000800, loss: 0.0146
2022-03-20 22:32:48 - train: epoch 0175, iter [00300, 00390], lr: 0.000800, loss: 0.0090
2022-03-20 22:32:59 - train: epoch 0175, iter [00350, 00390], lr: 0.000800, loss: 0.0118
2022-03-20 22:33:08 - train: epoch 175, train_loss: 0.0088
2022-03-20 22:33:16 - eval: epoch: 175, acc1: 78.410%, acc5: 94.590%, test_loss: 0.8803, per_image_load_time: 0.332ms, per_image_inference_time: 0.408ms
2022-03-20 22:33:18 - until epoch: 175, best_acc1: 78.680%
2022-03-20 22:33:18 - epoch 176 lr: 0.0008000000000000003
2022-03-20 22:33:32 - train: epoch 0176, iter [00050, 00390], lr: 0.000800, loss: 0.0105
2022-03-20 22:33:43 - train: epoch 0176, iter [00100, 00390], lr: 0.000800, loss: 0.0117
2022-03-20 22:33:54 - train: epoch 0176, iter [00150, 00390], lr: 0.000800, loss: 0.0079
2022-03-20 22:34:05 - train: epoch 0176, iter [00200, 00390], lr: 0.000800, loss: 0.0059
2022-03-20 22:34:17 - train: epoch 0176, iter [00250, 00390], lr: 0.000800, loss: 0.0083
2022-03-20 22:34:28 - train: epoch 0176, iter [00300, 00390], lr: 0.000800, loss: 0.0090
2022-03-20 22:34:39 - train: epoch 0176, iter [00350, 00390], lr: 0.000800, loss: 0.0094
2022-03-20 22:34:48 - train: epoch 176, train_loss: 0.0088
2022-03-20 22:34:56 - eval: epoch: 176, acc1: 78.490%, acc5: 94.720%, test_loss: 0.8821, per_image_load_time: 0.348ms, per_image_inference_time: 0.402ms
2022-03-20 22:34:57 - until epoch: 176, best_acc1: 78.680%
2022-03-20 22:34:57 - epoch 177 lr: 0.0008000000000000003
2022-03-20 22:35:12 - train: epoch 0177, iter [00050, 00390], lr: 0.000800, loss: 0.0061
2022-03-20 22:35:23 - train: epoch 0177, iter [00100, 00390], lr: 0.000800, loss: 0.0072
2022-03-20 22:35:35 - train: epoch 0177, iter [00150, 00390], lr: 0.000800, loss: 0.0101
2022-03-20 22:35:46 - train: epoch 0177, iter [00200, 00390], lr: 0.000800, loss: 0.0193
2022-03-20 22:35:57 - train: epoch 0177, iter [00250, 00390], lr: 0.000800, loss: 0.0108
2022-03-20 22:36:08 - train: epoch 0177, iter [00300, 00390], lr: 0.000800, loss: 0.0127
2022-03-20 22:36:19 - train: epoch 0177, iter [00350, 00390], lr: 0.000800, loss: 0.0106
2022-03-20 22:36:28 - train: epoch 177, train_loss: 0.0089
2022-03-20 22:36:36 - eval: epoch: 177, acc1: 78.550%, acc5: 94.570%, test_loss: 0.8829, per_image_load_time: 0.341ms, per_image_inference_time: 0.395ms
2022-03-20 22:36:37 - until epoch: 177, best_acc1: 78.680%
2022-03-20 22:36:37 - epoch 178 lr: 0.0008000000000000003
2022-03-20 22:36:52 - train: epoch 0178, iter [00050, 00390], lr: 0.000800, loss: 0.0084
2022-03-20 22:37:03 - train: epoch 0178, iter [00100, 00390], lr: 0.000800, loss: 0.0103
2022-03-20 22:37:14 - train: epoch 0178, iter [00150, 00390], lr: 0.000800, loss: 0.0065
2022-03-20 22:37:25 - train: epoch 0178, iter [00200, 00390], lr: 0.000800, loss: 0.0100
2022-03-20 22:37:36 - train: epoch 0178, iter [00250, 00390], lr: 0.000800, loss: 0.0100
2022-03-20 22:37:47 - train: epoch 0178, iter [00300, 00390], lr: 0.000800, loss: 0.0052
2022-03-20 22:37:58 - train: epoch 0178, iter [00350, 00390], lr: 0.000800, loss: 0.0138
2022-03-20 22:38:08 - train: epoch 178, train_loss: 0.0088
2022-03-20 22:38:15 - eval: epoch: 178, acc1: 78.620%, acc5: 94.620%, test_loss: 0.8783, per_image_load_time: 0.340ms, per_image_inference_time: 0.394ms
2022-03-20 22:38:17 - until epoch: 178, best_acc1: 78.680%
2022-03-20 22:38:17 - epoch 179 lr: 0.0008000000000000003
2022-03-20 22:38:31 - train: epoch 0179, iter [00050, 00390], lr: 0.000800, loss: 0.0116
2022-03-20 22:38:42 - train: epoch 0179, iter [00100, 00390], lr: 0.000800, loss: 0.0095
2022-03-20 22:38:53 - train: epoch 0179, iter [00150, 00390], lr: 0.000800, loss: 0.0139
2022-03-20 22:39:04 - train: epoch 0179, iter [00200, 00390], lr: 0.000800, loss: 0.0084
2022-03-20 22:39:15 - train: epoch 0179, iter [00250, 00390], lr: 0.000800, loss: 0.0108
2022-03-20 22:39:26 - train: epoch 0179, iter [00300, 00390], lr: 0.000800, loss: 0.0114
2022-03-20 22:39:37 - train: epoch 0179, iter [00350, 00390], lr: 0.000800, loss: 0.0064
2022-03-20 22:39:46 - train: epoch 179, train_loss: 0.0089
2022-03-20 22:39:54 - eval: epoch: 179, acc1: 78.470%, acc5: 94.600%, test_loss: 0.8830, per_image_load_time: 0.346ms, per_image_inference_time: 0.395ms
2022-03-20 22:39:56 - until epoch: 179, best_acc1: 78.680%
2022-03-20 22:39:56 - epoch 180 lr: 0.0008000000000000003
2022-03-20 22:40:10 - train: epoch 0180, iter [00050, 00390], lr: 0.000800, loss: 0.0070
2022-03-20 22:40:21 - train: epoch 0180, iter [00100, 00390], lr: 0.000800, loss: 0.0109
2022-03-20 22:40:32 - train: epoch 0180, iter [00150, 00390], lr: 0.000800, loss: 0.0084
2022-03-20 22:40:43 - train: epoch 0180, iter [00200, 00390], lr: 0.000800, loss: 0.0115
2022-03-20 22:40:54 - train: epoch 0180, iter [00250, 00390], lr: 0.000800, loss: 0.0110
2022-03-20 22:41:05 - train: epoch 0180, iter [00300, 00390], lr: 0.000800, loss: 0.0158
2022-03-20 22:41:16 - train: epoch 0180, iter [00350, 00390], lr: 0.000800, loss: 0.0072
2022-03-20 22:41:25 - train: epoch 180, train_loss: 0.0089
2022-03-20 22:41:32 - eval: epoch: 180, acc1: 78.610%, acc5: 94.630%, test_loss: 0.8791, per_image_load_time: 0.321ms, per_image_inference_time: 0.394ms
2022-03-20 22:41:34 - until epoch: 180, best_acc1: 78.680%
2022-03-20 22:41:34 - epoch 181 lr: 0.0008000000000000003
2022-03-20 22:41:48 - train: epoch 0181, iter [00050, 00390], lr: 0.000800, loss: 0.0164
2022-03-20 22:41:59 - train: epoch 0181, iter [00100, 00390], lr: 0.000800, loss: 0.0088
2022-03-20 22:42:10 - train: epoch 0181, iter [00150, 00390], lr: 0.000800, loss: 0.0094
2022-03-20 22:42:21 - train: epoch 0181, iter [00200, 00390], lr: 0.000800, loss: 0.0044
2022-03-20 22:42:32 - train: epoch 0181, iter [00250, 00390], lr: 0.000800, loss: 0.0103
2022-03-20 22:42:43 - train: epoch 0181, iter [00300, 00390], lr: 0.000800, loss: 0.0087
2022-03-20 22:42:54 - train: epoch 0181, iter [00350, 00390], lr: 0.000800, loss: 0.0123
2022-03-20 22:43:03 - train: epoch 181, train_loss: 0.0084
2022-03-20 22:43:11 - eval: epoch: 181, acc1: 78.530%, acc5: 94.570%, test_loss: 0.8803, per_image_load_time: 0.339ms, per_image_inference_time: 0.409ms
2022-03-20 22:43:13 - until epoch: 181, best_acc1: 78.680%
2022-03-20 22:43:13 - epoch 182 lr: 0.0008000000000000003
2022-03-20 22:43:27 - train: epoch 0182, iter [00050, 00390], lr: 0.000800, loss: 0.0101
2022-03-20 22:43:39 - train: epoch 0182, iter [00100, 00390], lr: 0.000800, loss: 0.0073
2022-03-20 22:43:50 - train: epoch 0182, iter [00150, 00390], lr: 0.000800, loss: 0.0073
2022-03-20 22:44:00 - train: epoch 0182, iter [00200, 00390], lr: 0.000800, loss: 0.0073
2022-03-20 22:44:11 - train: epoch 0182, iter [00250, 00390], lr: 0.000800, loss: 0.0085
2022-03-20 22:44:22 - train: epoch 0182, iter [00300, 00390], lr: 0.000800, loss: 0.0192
2022-03-20 22:44:33 - train: epoch 0182, iter [00350, 00390], lr: 0.000800, loss: 0.0086
2022-03-20 22:44:42 - train: epoch 182, train_loss: 0.0087
2022-03-20 22:44:50 - eval: epoch: 182, acc1: 78.700%, acc5: 94.680%, test_loss: 0.8777, per_image_load_time: 0.331ms, per_image_inference_time: 0.409ms
2022-03-20 22:44:52 - until epoch: 182, best_acc1: 78.700%
2022-03-20 22:44:52 - epoch 183 lr: 0.0008000000000000003
2022-03-20 22:45:07 - train: epoch 0183, iter [00050, 00390], lr: 0.000800, loss: 0.0075
2022-03-20 22:45:18 - train: epoch 0183, iter [00100, 00390], lr: 0.000800, loss: 0.0061
2022-03-20 22:45:29 - train: epoch 0183, iter [00150, 00390], lr: 0.000800, loss: 0.0096
2022-03-20 22:45:40 - train: epoch 0183, iter [00200, 00390], lr: 0.000800, loss: 0.0094
2022-03-20 22:45:51 - train: epoch 0183, iter [00250, 00390], lr: 0.000800, loss: 0.0070
2022-03-20 22:46:02 - train: epoch 0183, iter [00300, 00390], lr: 0.000800, loss: 0.0142
2022-03-20 22:46:13 - train: epoch 0183, iter [00350, 00390], lr: 0.000800, loss: 0.0077
2022-03-20 22:46:22 - train: epoch 183, train_loss: 0.0090
2022-03-20 22:46:30 - eval: epoch: 183, acc1: 78.610%, acc5: 94.620%, test_loss: 0.8804, per_image_load_time: 0.332ms, per_image_inference_time: 0.411ms
2022-03-20 22:46:32 - until epoch: 183, best_acc1: 78.700%
2022-03-20 22:46:32 - epoch 184 lr: 0.0008000000000000003
2022-03-20 22:46:46 - train: epoch 0184, iter [00050, 00390], lr: 0.000800, loss: 0.0119
2022-03-20 22:46:57 - train: epoch 0184, iter [00100, 00390], lr: 0.000800, loss: 0.0053
2022-03-20 22:47:08 - train: epoch 0184, iter [00150, 00390], lr: 0.000800, loss: 0.0061
2022-03-20 22:47:19 - train: epoch 0184, iter [00200, 00390], lr: 0.000800, loss: 0.0068
2022-03-20 22:47:30 - train: epoch 0184, iter [00250, 00390], lr: 0.000800, loss: 0.0074
2022-03-20 22:47:41 - train: epoch 0184, iter [00300, 00390], lr: 0.000800, loss: 0.0075
2022-03-20 22:47:52 - train: epoch 0184, iter [00350, 00390], lr: 0.000800, loss: 0.0115
2022-03-20 22:48:01 - train: epoch 184, train_loss: 0.0090
2022-03-20 22:48:09 - eval: epoch: 184, acc1: 78.480%, acc5: 94.730%, test_loss: 0.8777, per_image_load_time: 0.339ms, per_image_inference_time: 0.412ms
2022-03-20 22:48:11 - until epoch: 184, best_acc1: 78.700%
2022-03-20 22:48:11 - epoch 185 lr: 0.0008000000000000003
2022-03-20 22:48:25 - train: epoch 0185, iter [00050, 00390], lr: 0.000800, loss: 0.0050
2022-03-20 22:48:36 - train: epoch 0185, iter [00100, 00390], lr: 0.000800, loss: 0.0185
2022-03-20 22:48:47 - train: epoch 0185, iter [00150, 00390], lr: 0.000800, loss: 0.0093
2022-03-20 22:48:58 - train: epoch 0185, iter [00200, 00390], lr: 0.000800, loss: 0.0093
2022-03-20 22:49:09 - train: epoch 0185, iter [00250, 00390], lr: 0.000800, loss: 0.0047
2022-03-20 22:49:20 - train: epoch 0185, iter [00300, 00390], lr: 0.000800, loss: 0.0084
2022-03-20 22:49:31 - train: epoch 0185, iter [00350, 00390], lr: 0.000800, loss: 0.0134
2022-03-20 22:49:40 - train: epoch 185, train_loss: 0.0089
2022-03-20 22:49:48 - eval: epoch: 185, acc1: 78.560%, acc5: 94.660%, test_loss: 0.8774, per_image_load_time: 0.335ms, per_image_inference_time: 0.446ms
2022-03-20 22:49:50 - until epoch: 185, best_acc1: 78.700%
2022-03-20 22:49:50 - epoch 186 lr: 0.0008000000000000003
2022-03-20 22:50:04 - train: epoch 0186, iter [00050, 00390], lr: 0.000800, loss: 0.0083
2022-03-20 22:50:15 - train: epoch 0186, iter [00100, 00390], lr: 0.000800, loss: 0.0061
2022-03-20 22:50:26 - train: epoch 0186, iter [00150, 00390], lr: 0.000800, loss: 0.0122
2022-03-20 22:50:37 - train: epoch 0186, iter [00200, 00390], lr: 0.000800, loss: 0.0047
2022-03-20 22:50:47 - train: epoch 0186, iter [00250, 00390], lr: 0.000800, loss: 0.0098
2022-03-20 22:50:58 - train: epoch 0186, iter [00300, 00390], lr: 0.000800, loss: 0.0091
2022-03-20 22:51:09 - train: epoch 0186, iter [00350, 00390], lr: 0.000800, loss: 0.0124
2022-03-20 22:51:18 - train: epoch 186, train_loss: 0.0088
2022-03-20 22:51:26 - eval: epoch: 186, acc1: 78.520%, acc5: 94.620%, test_loss: 0.8781, per_image_load_time: 0.338ms, per_image_inference_time: 0.401ms
2022-03-20 22:51:27 - until epoch: 186, best_acc1: 78.700%
2022-03-20 22:51:27 - epoch 187 lr: 0.0008000000000000003
2022-03-20 22:51:42 - train: epoch 0187, iter [00050, 00390], lr: 0.000800, loss: 0.0058
2022-03-20 22:51:53 - train: epoch 0187, iter [00100, 00390], lr: 0.000800, loss: 0.0064
2022-03-20 22:52:04 - train: epoch 0187, iter [00150, 00390], lr: 0.000800, loss: 0.0087
2022-03-20 22:52:15 - train: epoch 0187, iter [00200, 00390], lr: 0.000800, loss: 0.0086
2022-03-20 22:52:26 - train: epoch 0187, iter [00250, 00390], lr: 0.000800, loss: 0.0090
2022-03-20 22:52:37 - train: epoch 0187, iter [00300, 00390], lr: 0.000800, loss: 0.0104
2022-03-20 22:52:48 - train: epoch 0187, iter [00350, 00390], lr: 0.000800, loss: 0.0097
2022-03-20 22:52:58 - train: epoch 187, train_loss: 0.0087
2022-03-20 22:53:06 - eval: epoch: 187, acc1: 78.600%, acc5: 94.680%, test_loss: 0.8795, per_image_load_time: 0.338ms, per_image_inference_time: 0.404ms
2022-03-20 22:53:07 - until epoch: 187, best_acc1: 78.700%
2022-03-20 22:53:07 - epoch 188 lr: 0.0008000000000000003
2022-03-20 22:53:23 - train: epoch 0188, iter [00050, 00390], lr: 0.000800, loss: 0.0126
2022-03-20 22:53:34 - train: epoch 0188, iter [00100, 00390], lr: 0.000800, loss: 0.0067
2022-03-20 22:53:46 - train: epoch 0188, iter [00150, 00390], lr: 0.000800, loss: 0.0047
2022-03-20 22:53:57 - train: epoch 0188, iter [00200, 00390], lr: 0.000800, loss: 0.0108
2022-03-20 22:54:09 - train: epoch 0188, iter [00250, 00390], lr: 0.000800, loss: 0.0076
2022-03-20 22:54:20 - train: epoch 0188, iter [00300, 00390], lr: 0.000800, loss: 0.0089
2022-03-20 22:54:32 - train: epoch 0188, iter [00350, 00390], lr: 0.000800, loss: 0.0070
2022-03-20 22:54:41 - train: epoch 188, train_loss: 0.0087
2022-03-20 22:54:49 - eval: epoch: 188, acc1: 78.470%, acc5: 94.690%, test_loss: 0.8767, per_image_load_time: 0.332ms, per_image_inference_time: 0.407ms
2022-03-20 22:54:51 - until epoch: 188, best_acc1: 78.700%
2022-03-20 22:54:51 - epoch 189 lr: 0.0008000000000000003
2022-03-20 22:55:06 - train: epoch 0189, iter [00050, 00390], lr: 0.000800, loss: 0.0098
2022-03-20 22:55:17 - train: epoch 0189, iter [00100, 00390], lr: 0.000800, loss: 0.0060
2022-03-20 22:55:28 - train: epoch 0189, iter [00150, 00390], lr: 0.000800, loss: 0.0069
2022-03-20 22:55:40 - train: epoch 0189, iter [00200, 00390], lr: 0.000800, loss: 0.0098
2022-03-20 22:55:51 - train: epoch 0189, iter [00250, 00390], lr: 0.000800, loss: 0.0086
2022-03-20 22:56:03 - train: epoch 0189, iter [00300, 00390], lr: 0.000800, loss: 0.0093
2022-03-20 22:56:14 - train: epoch 0189, iter [00350, 00390], lr: 0.000800, loss: 0.0082
2022-03-20 22:56:24 - train: epoch 189, train_loss: 0.0087
2022-03-20 22:56:31 - eval: epoch: 189, acc1: 78.440%, acc5: 94.560%, test_loss: 0.8793, per_image_load_time: 0.296ms, per_image_inference_time: 0.432ms
2022-03-20 22:56:33 - until epoch: 189, best_acc1: 78.700%
2022-03-20 22:56:33 - epoch 190 lr: 0.0008000000000000003
2022-03-20 22:56:47 - train: epoch 0190, iter [00050, 00390], lr: 0.000800, loss: 0.0060
2022-03-20 22:56:58 - train: epoch 0190, iter [00100, 00390], lr: 0.000800, loss: 0.0080
2022-03-20 22:57:09 - train: epoch 0190, iter [00150, 00390], lr: 0.000800, loss: 0.0095
2022-03-20 22:57:20 - train: epoch 0190, iter [00200, 00390], lr: 0.000800, loss: 0.0068
2022-03-20 22:57:31 - train: epoch 0190, iter [00250, 00390], lr: 0.000800, loss: 0.0138
2022-03-20 22:57:42 - train: epoch 0190, iter [00300, 00390], lr: 0.000800, loss: 0.0070
2022-03-20 22:57:53 - train: epoch 0190, iter [00350, 00390], lr: 0.000800, loss: 0.0064
2022-03-20 22:58:04 - train: epoch 190, train_loss: 0.0087
2022-03-20 22:58:11 - eval: epoch: 190, acc1: 78.490%, acc5: 94.660%, test_loss: 0.8794, per_image_load_time: 0.320ms, per_image_inference_time: 0.410ms
2022-03-20 22:58:13 - until epoch: 190, best_acc1: 78.700%
2022-03-20 22:58:13 - epoch 191 lr: 0.0008000000000000003
2022-03-20 22:58:28 - train: epoch 0191, iter [00050, 00390], lr: 0.000800, loss: 0.0058
2022-03-20 22:58:39 - train: epoch 0191, iter [00100, 00390], lr: 0.000800, loss: 0.0069
2022-03-20 22:58:50 - train: epoch 0191, iter [00150, 00390], lr: 0.000800, loss: 0.0094
2022-03-20 22:59:01 - train: epoch 0191, iter [00200, 00390], lr: 0.000800, loss: 0.0068
2022-03-20 22:59:12 - train: epoch 0191, iter [00250, 00390], lr: 0.000800, loss: 0.0090
2022-03-20 22:59:23 - train: epoch 0191, iter [00300, 00390], lr: 0.000800, loss: 0.0090
2022-03-20 22:59:34 - train: epoch 0191, iter [00350, 00390], lr: 0.000800, loss: 0.0063
2022-03-20 22:59:43 - train: epoch 191, train_loss: 0.0088
2022-03-20 22:59:51 - eval: epoch: 191, acc1: 78.640%, acc5: 94.570%, test_loss: 0.8798, per_image_load_time: 0.344ms, per_image_inference_time: 0.397ms
2022-03-20 22:59:53 - until epoch: 191, best_acc1: 78.700%
2022-03-20 22:59:53 - epoch 192 lr: 0.0008000000000000003
2022-03-20 23:00:07 - train: epoch 0192, iter [00050, 00390], lr: 0.000800, loss: 0.0056
2022-03-20 23:00:18 - train: epoch 0192, iter [00100, 00390], lr: 0.000800, loss: 0.0082
2022-03-20 23:00:29 - train: epoch 0192, iter [00150, 00390], lr: 0.000800, loss: 0.0085
2022-03-20 23:00:40 - train: epoch 0192, iter [00200, 00390], lr: 0.000800, loss: 0.0074
2022-03-20 23:00:51 - train: epoch 0192, iter [00250, 00390], lr: 0.000800, loss: 0.0091
2022-03-20 23:01:02 - train: epoch 0192, iter [00300, 00390], lr: 0.000800, loss: 0.0059
2022-03-20 23:01:14 - train: epoch 0192, iter [00350, 00390], lr: 0.000800, loss: 0.0056
2022-03-20 23:01:23 - train: epoch 192, train_loss: 0.0086
2022-03-20 23:01:30 - eval: epoch: 192, acc1: 78.430%, acc5: 94.690%, test_loss: 0.8745, per_image_load_time: 0.327ms, per_image_inference_time: 0.396ms
2022-03-20 23:01:31 - until epoch: 192, best_acc1: 78.700%
2022-03-20 23:01:31 - epoch 193 lr: 0.0008000000000000003
2022-03-20 23:01:46 - train: epoch 0193, iter [00050, 00390], lr: 0.000800, loss: 0.0057
2022-03-20 23:01:57 - train: epoch 0193, iter [00100, 00390], lr: 0.000800, loss: 0.0057
2022-03-20 23:02:08 - train: epoch 0193, iter [00150, 00390], lr: 0.000800, loss: 0.0107
2022-03-20 23:02:19 - train: epoch 0193, iter [00200, 00390], lr: 0.000800, loss: 0.0104
2022-03-20 23:02:30 - train: epoch 0193, iter [00250, 00390], lr: 0.000800, loss: 0.0095
2022-03-20 23:02:41 - train: epoch 0193, iter [00300, 00390], lr: 0.000800, loss: 0.0122
2022-03-20 23:02:52 - train: epoch 0193, iter [00350, 00390], lr: 0.000800, loss: 0.0164
2022-03-20 23:03:01 - train: epoch 193, train_loss: 0.0089
2022-03-20 23:03:09 - eval: epoch: 193, acc1: 78.430%, acc5: 94.540%, test_loss: 0.8794, per_image_load_time: 0.324ms, per_image_inference_time: 0.407ms
2022-03-20 23:03:09 - until epoch: 193, best_acc1: 78.700%
2022-03-20 23:03:09 - epoch 194 lr: 0.0008000000000000003
2022-03-20 23:03:24 - train: epoch 0194, iter [00050, 00390], lr: 0.000800, loss: 0.0052
2022-03-20 23:03:35 - train: epoch 0194, iter [00100, 00390], lr: 0.000800, loss: 0.0088
2022-03-20 23:03:46 - train: epoch 0194, iter [00150, 00390], lr: 0.000800, loss: 0.0161
2022-03-20 23:03:57 - train: epoch 0194, iter [00200, 00390], lr: 0.000800, loss: 0.0052
2022-03-20 23:04:08 - train: epoch 0194, iter [00250, 00390], lr: 0.000800, loss: 0.0066
2022-03-20 23:04:19 - train: epoch 0194, iter [00300, 00390], lr: 0.000800, loss: 0.0182
2022-03-20 23:04:31 - train: epoch 0194, iter [00350, 00390], lr: 0.000800, loss: 0.0088
2022-03-20 23:04:40 - train: epoch 194, train_loss: 0.0085
2022-03-20 23:04:47 - eval: epoch: 194, acc1: 78.530%, acc5: 94.640%, test_loss: 0.8774, per_image_load_time: 0.320ms, per_image_inference_time: 0.406ms
2022-03-20 23:04:49 - until epoch: 194, best_acc1: 78.700%
2022-03-20 23:04:49 - epoch 195 lr: 0.0008000000000000003
2022-03-20 23:05:04 - train: epoch 0195, iter [00050, 00390], lr: 0.000800, loss: 0.0048
2022-03-20 23:05:15 - train: epoch 0195, iter [00100, 00390], lr: 0.000800, loss: 0.0050
2022-03-20 23:05:26 - train: epoch 0195, iter [00150, 00390], lr: 0.000800, loss: 0.0093
2022-03-20 23:05:38 - train: epoch 0195, iter [00200, 00390], lr: 0.000800, loss: 0.0061
2022-03-20 23:05:49 - train: epoch 0195, iter [00250, 00390], lr: 0.000800, loss: 0.0101
2022-03-20 23:06:00 - train: epoch 0195, iter [00300, 00390], lr: 0.000800, loss: 0.0110
2022-03-20 23:06:12 - train: epoch 0195, iter [00350, 00390], lr: 0.000800, loss: 0.0081
2022-03-20 23:06:21 - train: epoch 195, train_loss: 0.0087
2022-03-20 23:06:28 - eval: epoch: 195, acc1: 78.650%, acc5: 94.640%, test_loss: 0.8782, per_image_load_time: 0.328ms, per_image_inference_time: 0.406ms
2022-03-20 23:06:30 - until epoch: 195, best_acc1: 78.700%
2022-03-20 23:06:30 - epoch 196 lr: 0.0008000000000000003
2022-03-20 23:06:46 - train: epoch 0196, iter [00050, 00390], lr: 0.000800, loss: 0.0060
2022-03-20 23:06:57 - train: epoch 0196, iter [00100, 00390], lr: 0.000800, loss: 0.0111
2022-03-20 23:07:08 - train: epoch 0196, iter [00150, 00390], lr: 0.000800, loss: 0.0135
2022-03-20 23:07:20 - train: epoch 0196, iter [00200, 00390], lr: 0.000800, loss: 0.0091
2022-03-20 23:07:32 - train: epoch 0196, iter [00250, 00390], lr: 0.000800, loss: 0.0101
2022-03-20 23:07:43 - train: epoch 0196, iter [00300, 00390], lr: 0.000800, loss: 0.0069
2022-03-20 23:07:54 - train: epoch 0196, iter [00350, 00390], lr: 0.000800, loss: 0.0079
2022-03-20 23:08:04 - train: epoch 196, train_loss: 0.0090
2022-03-20 23:08:11 - eval: epoch: 196, acc1: 78.490%, acc5: 94.650%, test_loss: 0.8768, per_image_load_time: 0.279ms, per_image_inference_time: 0.412ms
2022-03-20 23:08:13 - until epoch: 196, best_acc1: 78.700%
2022-03-20 23:08:13 - epoch 197 lr: 0.0008000000000000003
2022-03-20 23:08:27 - train: epoch 0197, iter [00050, 00390], lr: 0.000800, loss: 0.0049
2022-03-20 23:08:39 - train: epoch 0197, iter [00100, 00390], lr: 0.000800, loss: 0.0112
2022-03-20 23:08:50 - train: epoch 0197, iter [00150, 00390], lr: 0.000800, loss: 0.0056
2022-03-20 23:09:01 - train: epoch 0197, iter [00200, 00390], lr: 0.000800, loss: 0.0070
2022-03-20 23:09:12 - train: epoch 0197, iter [00250, 00390], lr: 0.000800, loss: 0.0057
2022-03-20 23:09:23 - train: epoch 0197, iter [00300, 00390], lr: 0.000800, loss: 0.0066
2022-03-20 23:09:34 - train: epoch 0197, iter [00350, 00390], lr: 0.000800, loss: 0.0083
2022-03-20 23:09:44 - train: epoch 197, train_loss: 0.0087
2022-03-20 23:09:51 - eval: epoch: 197, acc1: 78.570%, acc5: 94.740%, test_loss: 0.8777, per_image_load_time: 0.316ms, per_image_inference_time: 0.407ms
2022-03-20 23:09:53 - until epoch: 197, best_acc1: 78.700%
2022-03-20 23:09:53 - epoch 198 lr: 0.0008000000000000003
2022-03-20 23:10:07 - train: epoch 0198, iter [00050, 00390], lr: 0.000800, loss: 0.0067
2022-03-20 23:10:18 - train: epoch 0198, iter [00100, 00390], lr: 0.000800, loss: 0.0095
2022-03-20 23:10:29 - train: epoch 0198, iter [00150, 00390], lr: 0.000800, loss: 0.0056
2022-03-20 23:10:40 - train: epoch 0198, iter [00200, 00390], lr: 0.000800, loss: 0.0110
2022-03-20 23:10:52 - train: epoch 0198, iter [00250, 00390], lr: 0.000800, loss: 0.0078
2022-03-20 23:11:05 - train: epoch 0198, iter [00300, 00390], lr: 0.000800, loss: 0.0063
2022-03-20 23:11:17 - train: epoch 0198, iter [00350, 00390], lr: 0.000800, loss: 0.0108
2022-03-20 23:11:27 - train: epoch 198, train_loss: 0.0086
2022-03-20 23:11:34 - eval: epoch: 198, acc1: 78.500%, acc5: 94.720%, test_loss: 0.8775, per_image_load_time: 0.286ms, per_image_inference_time: 0.392ms
2022-03-20 23:11:36 - until epoch: 198, best_acc1: 78.700%
2022-03-20 23:11:36 - epoch 199 lr: 0.0008000000000000003
2022-03-20 23:11:49 - train: epoch 0199, iter [00050, 00390], lr: 0.000800, loss: 0.0058
2022-03-20 23:12:00 - train: epoch 0199, iter [00100, 00390], lr: 0.000800, loss: 0.0073
2022-03-20 23:12:11 - train: epoch 0199, iter [00150, 00390], lr: 0.000800, loss: 0.0129
2022-03-20 23:12:22 - train: epoch 0199, iter [00200, 00390], lr: 0.000800, loss: 0.0056
2022-03-20 23:12:33 - train: epoch 0199, iter [00250, 00390], lr: 0.000800, loss: 0.0075
2022-03-20 23:12:44 - train: epoch 0199, iter [00300, 00390], lr: 0.000800, loss: 0.0268
2022-03-20 23:12:54 - train: epoch 0199, iter [00350, 00390], lr: 0.000800, loss: 0.0096
2022-03-20 23:13:04 - train: epoch 199, train_loss: 0.0088
2022-03-20 23:13:11 - eval: epoch: 199, acc1: 78.460%, acc5: 94.640%, test_loss: 0.8810, per_image_load_time: 0.297ms, per_image_inference_time: 0.413ms
2022-03-20 23:13:13 - until epoch: 199, best_acc1: 78.700%
2022-03-20 23:13:13 - epoch 200 lr: 0.0008000000000000003
2022-03-20 23:13:26 - train: epoch 0200, iter [00050, 00390], lr: 0.000800, loss: 0.0071
2022-03-20 23:13:37 - train: epoch 0200, iter [00100, 00390], lr: 0.000800, loss: 0.0167
2022-03-20 23:13:48 - train: epoch 0200, iter [00150, 00390], lr: 0.000800, loss: 0.0102
2022-03-20 23:13:59 - train: epoch 0200, iter [00200, 00390], lr: 0.000800, loss: 0.0069
2022-03-20 23:14:10 - train: epoch 0200, iter [00250, 00390], lr: 0.000800, loss: 0.0064
2022-03-20 23:14:21 - train: epoch 0200, iter [00300, 00390], lr: 0.000800, loss: 0.0063
2022-03-20 23:14:32 - train: epoch 0200, iter [00350, 00390], lr: 0.000800, loss: 0.0121
2022-03-20 23:14:41 - train: epoch 200, train_loss: 0.0086
2022-03-20 23:14:48 - eval: epoch: 200, acc1: 78.520%, acc5: 94.680%, test_loss: 0.8763, per_image_load_time: 0.290ms, per_image_inference_time: 0.409ms
2022-03-20 23:14:50 - until epoch: 200, best_acc1: 78.700%
2022-03-20 23:14:50 - train done. model: resnet152cifar, train time: 5.495 hours, best_acc1: 78.700%
