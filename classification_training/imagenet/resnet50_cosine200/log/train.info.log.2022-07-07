2022-07-07 07:41:32 - train: epoch 0098, iter [03000, 05004], lr: 0.053943, loss: 1.4983
2022-07-07 07:42:05 - train: epoch 0098, iter [03100, 05004], lr: 0.053927, loss: 1.5758
2022-07-07 07:42:39 - train: epoch 0098, iter [03200, 05004], lr: 0.053911, loss: 1.3275
2022-07-07 07:43:12 - train: epoch 0098, iter [03300, 05004], lr: 0.053895, loss: 1.4888
2022-07-07 07:43:46 - train: epoch 0098, iter [03400, 05004], lr: 0.053879, loss: 1.7201
2022-07-07 07:44:21 - train: epoch 0098, iter [03500, 05004], lr: 0.053863, loss: 1.6317
2022-07-07 07:44:55 - train: epoch 0098, iter [03600, 05004], lr: 0.053847, loss: 1.9322
2022-07-07 07:45:29 - train: epoch 0098, iter [03700, 05004], lr: 0.053831, loss: 1.6615
2022-07-07 07:46:02 - train: epoch 0098, iter [03800, 05004], lr: 0.053815, loss: 1.6434
2022-07-07 07:46:37 - train: epoch 0098, iter [03900, 05004], lr: 0.053799, loss: 1.5600
2022-07-07 07:47:11 - train: epoch 0098, iter [04000, 05004], lr: 0.053783, loss: 1.6188
2022-07-07 07:47:45 - train: epoch 0098, iter [04100, 05004], lr: 0.053767, loss: 1.8215
2022-07-07 07:48:19 - train: epoch 0098, iter [04200, 05004], lr: 0.053751, loss: 1.6247
2022-07-07 07:48:53 - train: epoch 0098, iter [04300, 05004], lr: 0.053735, loss: 1.5012
2022-07-07 07:49:27 - train: epoch 0098, iter [04400, 05004], lr: 0.053719, loss: 2.0082
2022-07-07 07:50:01 - train: epoch 0098, iter [04500, 05004], lr: 0.053703, loss: 1.7737
2022-07-07 07:50:36 - train: epoch 0098, iter [04600, 05004], lr: 0.053687, loss: 1.6806
2022-07-07 07:51:09 - train: epoch 0098, iter [04700, 05004], lr: 0.053671, loss: 1.6428
2022-07-07 07:51:44 - train: epoch 0098, iter [04800, 05004], lr: 0.053654, loss: 1.4678
2022-07-07 07:52:17 - train: epoch 0098, iter [04900, 05004], lr: 0.053638, loss: 1.6324
2022-07-07 07:52:50 - train: epoch 0098, iter [05000, 05004], lr: 0.053622, loss: 1.6770
2022-07-07 07:52:51 - train: epoch 098, train_loss: 1.6074
2022-07-07 07:54:06 - eval: epoch: 098, acc1: 64.218%, acc5: 86.144%, test_loss: 1.4909, per_image_load_time: 0.700ms, per_image_inference_time: 0.464ms
2022-07-07 07:54:06 - until epoch: 098, best_acc1: 65.240%
2022-07-07 07:54:06 - epoch 099 lr: 0.053622
2022-07-07 07:54:46 - train: epoch 0099, iter [00100, 05004], lr: 0.053606, loss: 1.3413
2022-07-07 07:55:19 - train: epoch 0099, iter [00200, 05004], lr: 0.053590, loss: 1.4621
2022-07-07 07:55:53 - train: epoch 0099, iter [00300, 05004], lr: 0.053574, loss: 1.4549
2022-07-07 07:56:27 - train: epoch 0099, iter [00400, 05004], lr: 0.053558, loss: 1.6459
2022-07-07 07:56:59 - train: epoch 0099, iter [00500, 05004], lr: 0.053541, loss: 1.7608
2022-07-07 07:57:33 - train: epoch 0099, iter [00600, 05004], lr: 0.053525, loss: 1.4935
2022-07-07 07:58:07 - train: epoch 0099, iter [00700, 05004], lr: 0.053509, loss: 1.6377
2022-07-07 07:58:41 - train: epoch 0099, iter [00800, 05004], lr: 0.053493, loss: 1.5252
2022-07-07 07:59:14 - train: epoch 0099, iter [00900, 05004], lr: 0.053477, loss: 1.5308
2022-07-07 07:59:47 - train: epoch 0099, iter [01000, 05004], lr: 0.053461, loss: 1.6177
2022-07-07 08:00:21 - train: epoch 0099, iter [01100, 05004], lr: 0.053445, loss: 1.7000
2022-07-07 08:00:56 - train: epoch 0099, iter [01200, 05004], lr: 0.053429, loss: 1.5207
2022-07-07 08:01:29 - train: epoch 0099, iter [01300, 05004], lr: 0.053413, loss: 1.6393
2022-07-07 08:02:02 - train: epoch 0099, iter [01400, 05004], lr: 0.053397, loss: 1.6740
2022-07-07 08:02:36 - train: epoch 0099, iter [01500, 05004], lr: 0.053381, loss: 1.4232
2022-07-07 08:03:10 - train: epoch 0099, iter [01600, 05004], lr: 0.053365, loss: 1.7961
2022-07-07 08:03:43 - train: epoch 0099, iter [01700, 05004], lr: 0.053349, loss: 1.5658
2022-07-07 08:04:18 - train: epoch 0099, iter [01800, 05004], lr: 0.053333, loss: 1.6715
2022-07-07 08:04:51 - train: epoch 0099, iter [01900, 05004], lr: 0.053317, loss: 1.6411
2022-07-07 08:05:25 - train: epoch 0099, iter [02000, 05004], lr: 0.053301, loss: 1.4000
2022-07-07 08:05:59 - train: epoch 0099, iter [02100, 05004], lr: 0.053284, loss: 1.4401
2022-07-07 08:06:33 - train: epoch 0099, iter [02200, 05004], lr: 0.053268, loss: 1.6926
2022-07-07 08:07:07 - train: epoch 0099, iter [02300, 05004], lr: 0.053252, loss: 1.6187
2022-07-07 08:07:41 - train: epoch 0099, iter [02400, 05004], lr: 0.053236, loss: 1.7508
2022-07-07 08:08:15 - train: epoch 0099, iter [02500, 05004], lr: 0.053220, loss: 1.5374
2022-07-07 08:08:49 - train: epoch 0099, iter [02600, 05004], lr: 0.053204, loss: 1.4272
2022-07-07 08:09:22 - train: epoch 0099, iter [02700, 05004], lr: 0.053188, loss: 1.6913
2022-07-07 08:09:56 - train: epoch 0099, iter [02800, 05004], lr: 0.053172, loss: 1.7947
2022-07-07 08:10:31 - train: epoch 0099, iter [02900, 05004], lr: 0.053156, loss: 1.6793
2022-07-07 08:11:04 - train: epoch 0099, iter [03000, 05004], lr: 0.053140, loss: 1.7324
2022-07-07 08:11:38 - train: epoch 0099, iter [03100, 05004], lr: 0.053124, loss: 1.5486
2022-07-07 08:12:12 - train: epoch 0099, iter [03200, 05004], lr: 0.053108, loss: 1.7592
2022-07-07 08:12:45 - train: epoch 0099, iter [03300, 05004], lr: 0.053092, loss: 1.5248
2022-07-07 08:13:19 - train: epoch 0099, iter [03400, 05004], lr: 0.053076, loss: 1.5986
2022-07-07 08:13:53 - train: epoch 0099, iter [03500, 05004], lr: 0.053060, loss: 1.7177
2022-07-07 08:14:27 - train: epoch 0099, iter [03600, 05004], lr: 0.053044, loss: 1.5761
2022-07-07 08:15:00 - train: epoch 0099, iter [03700, 05004], lr: 0.053027, loss: 1.4553
2022-07-07 08:15:34 - train: epoch 0099, iter [03800, 05004], lr: 0.053011, loss: 1.5956
2022-07-07 08:16:08 - train: epoch 0099, iter [03900, 05004], lr: 0.052995, loss: 1.6413
2022-07-07 08:16:42 - train: epoch 0099, iter [04000, 05004], lr: 0.052979, loss: 1.7371
2022-07-07 08:17:16 - train: epoch 0099, iter [04100, 05004], lr: 0.052963, loss: 1.5184
2022-07-07 08:17:49 - train: epoch 0099, iter [04200, 05004], lr: 0.052947, loss: 1.6561
2022-07-07 08:18:23 - train: epoch 0099, iter [04300, 05004], lr: 0.052931, loss: 1.5742
2022-07-07 08:18:57 - train: epoch 0099, iter [04400, 05004], lr: 0.052915, loss: 1.7229
2022-07-07 08:19:31 - train: epoch 0099, iter [04500, 05004], lr: 0.052899, loss: 1.7226
2022-07-07 08:20:05 - train: epoch 0099, iter [04600, 05004], lr: 0.052883, loss: 1.8663
2022-07-07 08:20:39 - train: epoch 0099, iter [04700, 05004], lr: 0.052867, loss: 1.5847
2022-07-07 08:21:13 - train: epoch 0099, iter [04800, 05004], lr: 0.052851, loss: 1.7955
2022-07-07 08:21:46 - train: epoch 0099, iter [04900, 05004], lr: 0.052835, loss: 1.5136
2022-07-07 08:22:19 - train: epoch 0099, iter [05000, 05004], lr: 0.052819, loss: 1.6919
2022-07-07 08:22:20 - train: epoch 099, train_loss: 1.6022
2022-07-07 08:23:35 - eval: epoch: 099, acc1: 65.218%, acc5: 87.032%, test_loss: 1.4284, per_image_load_time: 0.798ms, per_image_inference_time: 0.497ms
2022-07-07 08:23:35 - until epoch: 099, best_acc1: 65.240%
2022-07-07 08:23:35 - epoch 100 lr: 0.052818
2022-07-07 08:24:14 - train: epoch 0100, iter [00100, 05004], lr: 0.052802, loss: 1.4684
2022-07-07 08:24:48 - train: epoch 0100, iter [00200, 05004], lr: 0.052786, loss: 1.5572
2022-07-07 08:25:20 - train: epoch 0100, iter [00300, 05004], lr: 0.052770, loss: 1.4501
2022-07-07 08:25:55 - train: epoch 0100, iter [00400, 05004], lr: 0.052754, loss: 1.2508
2022-07-07 08:26:28 - train: epoch 0100, iter [00500, 05004], lr: 0.052738, loss: 1.6925
2022-07-07 08:27:02 - train: epoch 0100, iter [00600, 05004], lr: 0.052721, loss: 1.9411
2022-07-07 08:27:36 - train: epoch 0100, iter [00700, 05004], lr: 0.052705, loss: 1.4074
2022-07-07 08:28:10 - train: epoch 0100, iter [00800, 05004], lr: 0.052689, loss: 1.6985
2022-07-07 08:28:43 - train: epoch 0100, iter [00900, 05004], lr: 0.052673, loss: 1.3941
2022-07-07 08:29:16 - train: epoch 0100, iter [01000, 05004], lr: 0.052657, loss: 1.6186
2022-07-07 08:29:51 - train: epoch 0100, iter [01100, 05004], lr: 0.052641, loss: 1.4256
2022-07-07 08:30:24 - train: epoch 0100, iter [01200, 05004], lr: 0.052625, loss: 1.6666
2022-07-07 08:30:58 - train: epoch 0100, iter [01300, 05004], lr: 0.052609, loss: 1.6896
2022-07-07 08:31:32 - train: epoch 0100, iter [01400, 05004], lr: 0.052593, loss: 1.6511
2022-07-07 08:32:05 - train: epoch 0100, iter [01500, 05004], lr: 0.052577, loss: 1.5630
2022-07-07 08:32:39 - train: epoch 0100, iter [01600, 05004], lr: 0.052561, loss: 1.4730
2022-07-07 08:33:13 - train: epoch 0100, iter [01700, 05004], lr: 0.052545, loss: 1.5116
2022-07-07 08:33:47 - train: epoch 0100, iter [01800, 05004], lr: 0.052529, loss: 1.6190
2022-07-07 08:34:20 - train: epoch 0100, iter [01900, 05004], lr: 0.052512, loss: 1.4888
2022-07-07 08:34:55 - train: epoch 0100, iter [02000, 05004], lr: 0.052496, loss: 1.5509
2022-07-07 08:35:28 - train: epoch 0100, iter [02100, 05004], lr: 0.052480, loss: 1.5534
2022-07-07 08:36:02 - train: epoch 0100, iter [02200, 05004], lr: 0.052464, loss: 1.6930
2022-07-07 08:36:36 - train: epoch 0100, iter [02300, 05004], lr: 0.052448, loss: 1.5914
2022-07-07 08:37:10 - train: epoch 0100, iter [02400, 05004], lr: 0.052432, loss: 1.6806
2022-07-07 08:37:44 - train: epoch 0100, iter [02500, 05004], lr: 0.052416, loss: 1.5988
2022-07-07 08:38:18 - train: epoch 0100, iter [02600, 05004], lr: 0.052400, loss: 1.6416
2022-07-07 08:38:51 - train: epoch 0100, iter [02700, 05004], lr: 0.052384, loss: 1.5459
2022-07-07 08:39:24 - train: epoch 0100, iter [02800, 05004], lr: 0.052368, loss: 1.6400
2022-07-07 08:39:58 - train: epoch 0100, iter [02900, 05004], lr: 0.052352, loss: 1.7842
2022-07-07 08:40:33 - train: epoch 0100, iter [03000, 05004], lr: 0.052336, loss: 1.4929
2022-07-07 08:41:07 - train: epoch 0100, iter [03100, 05004], lr: 0.052320, loss: 1.5255
2022-07-07 08:41:39 - train: epoch 0100, iter [03200, 05004], lr: 0.052303, loss: 1.7728
2022-07-07 08:42:13 - train: epoch 0100, iter [03300, 05004], lr: 0.052287, loss: 1.8178
2022-07-07 08:42:48 - train: epoch 0100, iter [03400, 05004], lr: 0.052271, loss: 1.7982
2022-07-07 08:43:23 - train: epoch 0100, iter [03500, 05004], lr: 0.052255, loss: 1.4436
2022-07-07 08:43:57 - train: epoch 0100, iter [03600, 05004], lr: 0.052239, loss: 1.5548
2022-07-07 08:44:30 - train: epoch 0100, iter [03700, 05004], lr: 0.052223, loss: 1.5568
2022-07-07 08:45:04 - train: epoch 0100, iter [03800, 05004], lr: 0.052207, loss: 1.5175
2022-07-07 08:45:38 - train: epoch 0100, iter [03900, 05004], lr: 0.052191, loss: 1.7444
2022-07-07 08:46:13 - train: epoch 0100, iter [04000, 05004], lr: 0.052175, loss: 1.5343
2022-07-07 08:46:46 - train: epoch 0100, iter [04100, 05004], lr: 0.052159, loss: 1.6924
2022-07-07 08:47:20 - train: epoch 0100, iter [04200, 05004], lr: 0.052143, loss: 1.6676
2022-07-07 08:47:54 - train: epoch 0100, iter [04300, 05004], lr: 0.052127, loss: 1.5451
2022-07-07 08:48:28 - train: epoch 0100, iter [04400, 05004], lr: 0.052110, loss: 1.7675
2022-07-07 08:49:02 - train: epoch 0100, iter [04500, 05004], lr: 0.052094, loss: 1.5129
2022-07-07 08:49:36 - train: epoch 0100, iter [04600, 05004], lr: 0.052078, loss: 1.5213
2022-07-07 08:50:10 - train: epoch 0100, iter [04700, 05004], lr: 0.052062, loss: 1.6298
2022-07-07 08:50:44 - train: epoch 0100, iter [04800, 05004], lr: 0.052046, loss: 1.3209
2022-07-07 08:51:18 - train: epoch 0100, iter [04900, 05004], lr: 0.052030, loss: 1.6302
2022-07-07 08:51:50 - train: epoch 0100, iter [05000, 05004], lr: 0.052014, loss: 1.6603
2022-07-07 08:51:51 - train: epoch 100, train_loss: 1.5948
2022-07-07 08:53:06 - eval: epoch: 100, acc1: 63.538%, acc5: 85.908%, test_loss: 1.5011, per_image_load_time: 1.345ms, per_image_inference_time: 0.500ms
2022-07-07 08:53:06 - until epoch: 100, best_acc1: 65.240%
2022-07-07 08:53:06 - epoch 101 lr: 0.052013
2022-07-07 08:53:45 - train: epoch 0101, iter [00100, 05004], lr: 0.051997, loss: 1.4015
2022-07-07 08:54:19 - train: epoch 0101, iter [00200, 05004], lr: 0.051981, loss: 1.4248
2022-07-07 08:54:52 - train: epoch 0101, iter [00300, 05004], lr: 0.051965, loss: 1.3060
2022-07-07 08:55:26 - train: epoch 0101, iter [00400, 05004], lr: 0.051949, loss: 1.5284
2022-07-07 08:55:59 - train: epoch 0101, iter [00500, 05004], lr: 0.051933, loss: 1.4458
2022-07-07 08:56:33 - train: epoch 0101, iter [00600, 05004], lr: 0.051917, loss: 1.5113
2022-07-07 08:57:07 - train: epoch 0101, iter [00700, 05004], lr: 0.051901, loss: 1.7035
2022-07-07 08:57:40 - train: epoch 0101, iter [00800, 05004], lr: 0.051885, loss: 1.6417
2022-07-07 08:58:14 - train: epoch 0101, iter [00900, 05004], lr: 0.051869, loss: 1.6521
2022-07-07 08:58:48 - train: epoch 0101, iter [01000, 05004], lr: 0.051852, loss: 1.6787
2022-07-07 08:59:21 - train: epoch 0101, iter [01100, 05004], lr: 0.051836, loss: 1.6198
2022-07-07 08:59:55 - train: epoch 0101, iter [01200, 05004], lr: 0.051820, loss: 1.4072
2022-07-07 09:00:29 - train: epoch 0101, iter [01300, 05004], lr: 0.051804, loss: 1.8706
2022-07-07 09:01:01 - train: epoch 0101, iter [01400, 05004], lr: 0.051788, loss: 1.4793
2022-07-07 09:01:36 - train: epoch 0101, iter [01500, 05004], lr: 0.051772, loss: 1.4864
2022-07-07 09:02:10 - train: epoch 0101, iter [01600, 05004], lr: 0.051756, loss: 1.4410
2022-07-07 09:02:43 - train: epoch 0101, iter [01700, 05004], lr: 0.051740, loss: 1.3964
2022-07-07 09:03:17 - train: epoch 0101, iter [01800, 05004], lr: 0.051724, loss: 1.7626
2022-07-07 09:03:51 - train: epoch 0101, iter [01900, 05004], lr: 0.051708, loss: 1.3601
2022-07-07 09:04:25 - train: epoch 0101, iter [02000, 05004], lr: 0.051692, loss: 1.5050
2022-07-07 09:04:58 - train: epoch 0101, iter [02100, 05004], lr: 0.051675, loss: 1.6738
2022-07-07 09:05:33 - train: epoch 0101, iter [02200, 05004], lr: 0.051659, loss: 1.4139
2022-07-07 09:06:06 - train: epoch 0101, iter [02300, 05004], lr: 0.051643, loss: 1.5623
2022-07-07 09:06:41 - train: epoch 0101, iter [02400, 05004], lr: 0.051627, loss: 1.6193
2022-07-07 09:07:15 - train: epoch 0101, iter [02500, 05004], lr: 0.051611, loss: 1.6879
2022-07-07 09:07:49 - train: epoch 0101, iter [02600, 05004], lr: 0.051595, loss: 1.6413
2022-07-07 09:08:23 - train: epoch 0101, iter [02700, 05004], lr: 0.051579, loss: 1.7618
2022-07-07 09:08:56 - train: epoch 0101, iter [02800, 05004], lr: 0.051563, loss: 1.5906
2022-07-07 09:09:31 - train: epoch 0101, iter [02900, 05004], lr: 0.051547, loss: 1.7847
2022-07-07 09:10:05 - train: epoch 0101, iter [03000, 05004], lr: 0.051531, loss: 1.7201
2022-07-07 09:10:38 - train: epoch 0101, iter [03100, 05004], lr: 0.051515, loss: 1.7959
2022-07-07 09:11:12 - train: epoch 0101, iter [03200, 05004], lr: 0.051498, loss: 1.7048
2022-07-07 09:11:46 - train: epoch 0101, iter [03300, 05004], lr: 0.051482, loss: 1.6837
2022-07-07 09:12:20 - train: epoch 0101, iter [03400, 05004], lr: 0.051466, loss: 1.5089
2022-07-07 09:12:54 - train: epoch 0101, iter [03500, 05004], lr: 0.051450, loss: 1.3243
2022-07-07 09:13:27 - train: epoch 0101, iter [03600, 05004], lr: 0.051434, loss: 1.7163
2022-07-07 09:14:01 - train: epoch 0101, iter [03700, 05004], lr: 0.051418, loss: 1.7444
2022-07-07 09:14:34 - train: epoch 0101, iter [03800, 05004], lr: 0.051402, loss: 1.6399
2022-07-07 09:15:09 - train: epoch 0101, iter [03900, 05004], lr: 0.051386, loss: 1.7349
2022-07-07 09:15:43 - train: epoch 0101, iter [04000, 05004], lr: 0.051370, loss: 1.6032
2022-07-07 09:16:17 - train: epoch 0101, iter [04100, 05004], lr: 0.051354, loss: 1.5642
2022-07-07 09:16:50 - train: epoch 0101, iter [04200, 05004], lr: 0.051338, loss: 1.6499
2022-07-07 09:17:25 - train: epoch 0101, iter [04300, 05004], lr: 0.051321, loss: 1.5513
2022-07-07 09:17:58 - train: epoch 0101, iter [04400, 05004], lr: 0.051305, loss: 1.5613
2022-07-07 09:18:33 - train: epoch 0101, iter [04500, 05004], lr: 0.051289, loss: 1.8301
2022-07-07 09:19:06 - train: epoch 0101, iter [04600, 05004], lr: 0.051273, loss: 1.7248
2022-07-07 09:19:40 - train: epoch 0101, iter [04700, 05004], lr: 0.051257, loss: 1.6026
2022-07-07 09:20:14 - train: epoch 0101, iter [04800, 05004], lr: 0.051241, loss: 1.6147
2022-07-07 09:20:48 - train: epoch 0101, iter [04900, 05004], lr: 0.051225, loss: 1.4698
2022-07-07 09:21:20 - train: epoch 0101, iter [05000, 05004], lr: 0.051209, loss: 1.5297
2022-07-07 09:21:21 - train: epoch 101, train_loss: 1.5871
2022-07-07 09:22:37 - eval: epoch: 101, acc1: 65.380%, acc5: 87.206%, test_loss: 1.4218, per_image_load_time: 0.618ms, per_image_inference_time: 0.451ms
2022-07-07 09:22:37 - until epoch: 101, best_acc1: 65.380%
2022-07-07 09:22:37 - epoch 102 lr: 0.051208
2022-07-07 09:23:16 - train: epoch 0102, iter [00100, 05004], lr: 0.051192, loss: 1.6431
2022-07-07 09:23:51 - train: epoch 0102, iter [00200, 05004], lr: 0.051176, loss: 1.4053
2022-07-07 09:24:23 - train: epoch 0102, iter [00300, 05004], lr: 0.051160, loss: 1.4891
2022-07-07 09:24:57 - train: epoch 0102, iter [00400, 05004], lr: 0.051144, loss: 1.4992
2022-07-07 09:25:31 - train: epoch 0102, iter [00500, 05004], lr: 0.051128, loss: 1.6217
2022-07-07 09:26:04 - train: epoch 0102, iter [00600, 05004], lr: 0.051112, loss: 1.3907
2022-07-07 09:26:38 - train: epoch 0102, iter [00700, 05004], lr: 0.051096, loss: 1.5327
2022-07-07 09:27:12 - train: epoch 0102, iter [00800, 05004], lr: 0.051079, loss: 1.5893
2022-07-07 09:27:46 - train: epoch 0102, iter [00900, 05004], lr: 0.051063, loss: 1.4973
2022-07-07 09:28:19 - train: epoch 0102, iter [01000, 05004], lr: 0.051047, loss: 1.7173
2022-07-07 09:28:53 - train: epoch 0102, iter [01100, 05004], lr: 0.051031, loss: 1.4731
2022-07-07 09:29:27 - train: epoch 0102, iter [01200, 05004], lr: 0.051015, loss: 1.8346
2022-07-07 09:30:01 - train: epoch 0102, iter [01300, 05004], lr: 0.050999, loss: 1.6841
2022-07-07 09:30:35 - train: epoch 0102, iter [01400, 05004], lr: 0.050983, loss: 1.6614
2022-07-07 09:31:08 - train: epoch 0102, iter [01500, 05004], lr: 0.050967, loss: 1.5482
2022-07-07 09:31:42 - train: epoch 0102, iter [01600, 05004], lr: 0.050951, loss: 1.8725
2022-07-07 09:32:16 - train: epoch 0102, iter [01700, 05004], lr: 0.050935, loss: 1.4866
2022-07-07 09:32:50 - train: epoch 0102, iter [01800, 05004], lr: 0.050918, loss: 1.6912
2022-07-07 09:33:24 - train: epoch 0102, iter [01900, 05004], lr: 0.050902, loss: 1.6215
2022-07-07 09:33:58 - train: epoch 0102, iter [02000, 05004], lr: 0.050886, loss: 1.5033
2022-07-07 09:34:32 - train: epoch 0102, iter [02100, 05004], lr: 0.050870, loss: 1.4334
2022-07-07 09:35:06 - train: epoch 0102, iter [02200, 05004], lr: 0.050854, loss: 1.4733
2022-07-07 09:35:39 - train: epoch 0102, iter [02300, 05004], lr: 0.050838, loss: 1.5549
2022-07-07 09:36:13 - train: epoch 0102, iter [02400, 05004], lr: 0.050822, loss: 1.7142
2022-07-07 09:36:47 - train: epoch 0102, iter [02500, 05004], lr: 0.050806, loss: 1.5983
2022-07-07 09:37:20 - train: epoch 0102, iter [02600, 05004], lr: 0.050790, loss: 1.5205
2022-07-07 09:37:54 - train: epoch 0102, iter [02700, 05004], lr: 0.050774, loss: 1.8393
2022-07-07 09:38:28 - train: epoch 0102, iter [02800, 05004], lr: 0.050758, loss: 1.6140
2022-07-07 09:39:01 - train: epoch 0102, iter [02900, 05004], lr: 0.050741, loss: 1.5966
2022-07-07 09:39:35 - train: epoch 0102, iter [03000, 05004], lr: 0.050725, loss: 1.5550
2022-07-07 09:40:08 - train: epoch 0102, iter [03100, 05004], lr: 0.050709, loss: 1.4574
2022-07-07 09:40:41 - train: epoch 0102, iter [03200, 05004], lr: 0.050693, loss: 1.4164
2022-07-07 09:41:15 - train: epoch 0102, iter [03300, 05004], lr: 0.050677, loss: 1.6220
2022-07-07 09:41:49 - train: epoch 0102, iter [03400, 05004], lr: 0.050661, loss: 1.5573
2022-07-07 09:42:22 - train: epoch 0102, iter [03500, 05004], lr: 0.050645, loss: 1.5385
2022-07-07 09:42:56 - train: epoch 0102, iter [03600, 05004], lr: 0.050629, loss: 1.6960
2022-07-07 09:43:30 - train: epoch 0102, iter [03700, 05004], lr: 0.050613, loss: 1.6338
2022-07-07 09:44:03 - train: epoch 0102, iter [03800, 05004], lr: 0.050597, loss: 1.6407
2022-07-07 09:44:37 - train: epoch 0102, iter [03900, 05004], lr: 0.050580, loss: 1.6803
2022-07-07 09:45:11 - train: epoch 0102, iter [04000, 05004], lr: 0.050564, loss: 1.4591
2022-07-07 09:45:44 - train: epoch 0102, iter [04100, 05004], lr: 0.050548, loss: 1.5097
2022-07-07 09:46:18 - train: epoch 0102, iter [04200, 05004], lr: 0.050532, loss: 1.9373
2022-07-07 09:46:51 - train: epoch 0102, iter [04300, 05004], lr: 0.050516, loss: 1.5223
2022-07-07 09:47:25 - train: epoch 0102, iter [04400, 05004], lr: 0.050500, loss: 1.5188
2022-07-07 09:47:58 - train: epoch 0102, iter [04500, 05004], lr: 0.050484, loss: 1.7621
2022-07-07 09:48:32 - train: epoch 0102, iter [04600, 05004], lr: 0.050468, loss: 1.7976
2022-07-07 09:49:06 - train: epoch 0102, iter [04700, 05004], lr: 0.050452, loss: 1.6299
2022-07-07 09:49:40 - train: epoch 0102, iter [04800, 05004], lr: 0.050436, loss: 1.8054
2022-07-07 09:50:14 - train: epoch 0102, iter [04900, 05004], lr: 0.050420, loss: 1.6969
2022-07-07 09:50:46 - train: epoch 0102, iter [05000, 05004], lr: 0.050403, loss: 1.4982
2022-07-07 09:50:47 - train: epoch 102, train_loss: 1.5792
2022-07-07 09:52:02 - eval: epoch: 102, acc1: 64.792%, acc5: 86.690%, test_loss: 1.4493, per_image_load_time: 1.428ms, per_image_inference_time: 0.460ms
2022-07-07 09:52:02 - until epoch: 102, best_acc1: 65.380%
2022-07-07 09:52:02 - epoch 103 lr: 0.050403
2022-07-07 09:52:42 - train: epoch 0103, iter [00100, 05004], lr: 0.050387, loss: 1.3947
2022-07-07 09:53:17 - train: epoch 0103, iter [00200, 05004], lr: 0.050371, loss: 1.5539
2022-07-07 09:53:49 - train: epoch 0103, iter [00300, 05004], lr: 0.050354, loss: 1.4817
2022-07-07 09:54:23 - train: epoch 0103, iter [00400, 05004], lr: 0.050338, loss: 1.7475
2022-07-07 09:54:56 - train: epoch 0103, iter [00500, 05004], lr: 0.050322, loss: 1.4129
2022-07-07 09:55:30 - train: epoch 0103, iter [00600, 05004], lr: 0.050306, loss: 1.3659
2022-07-07 09:56:04 - train: epoch 0103, iter [00700, 05004], lr: 0.050290, loss: 1.5955
2022-07-07 09:56:37 - train: epoch 0103, iter [00800, 05004], lr: 0.050274, loss: 1.5061
2022-07-07 09:57:11 - train: epoch 0103, iter [00900, 05004], lr: 0.050258, loss: 1.4319
2022-07-07 09:57:44 - train: epoch 0103, iter [01000, 05004], lr: 0.050242, loss: 1.4456
2022-07-07 09:58:18 - train: epoch 0103, iter [01100, 05004], lr: 0.050226, loss: 1.5962
2022-07-07 09:58:51 - train: epoch 0103, iter [01200, 05004], lr: 0.050210, loss: 1.4971
2022-07-07 09:59:24 - train: epoch 0103, iter [01300, 05004], lr: 0.050193, loss: 1.7156
2022-07-07 09:59:58 - train: epoch 0103, iter [01400, 05004], lr: 0.050177, loss: 1.5686
2022-07-07 10:00:32 - train: epoch 0103, iter [01500, 05004], lr: 0.050161, loss: 1.7949
2022-07-07 10:01:05 - train: epoch 0103, iter [01600, 05004], lr: 0.050145, loss: 1.2320
2022-07-07 10:01:39 - train: epoch 0103, iter [01700, 05004], lr: 0.050129, loss: 1.5346
2022-07-07 10:02:13 - train: epoch 0103, iter [01800, 05004], lr: 0.050113, loss: 1.3473
2022-07-07 10:02:47 - train: epoch 0103, iter [01900, 05004], lr: 0.050097, loss: 1.3861
2022-07-07 10:03:20 - train: epoch 0103, iter [02000, 05004], lr: 0.050081, loss: 1.3721
2022-07-07 10:03:54 - train: epoch 0103, iter [02100, 05004], lr: 0.050065, loss: 1.5864
2022-07-07 10:04:28 - train: epoch 0103, iter [02200, 05004], lr: 0.050049, loss: 1.5923
2022-07-07 10:05:02 - train: epoch 0103, iter [02300, 05004], lr: 0.050033, loss: 1.5322
2022-07-07 10:05:35 - train: epoch 0103, iter [02400, 05004], lr: 0.050016, loss: 1.6439
2022-07-07 10:06:10 - train: epoch 0103, iter [02500, 05004], lr: 0.050000, loss: 1.6045
2022-07-07 10:06:43 - train: epoch 0103, iter [02600, 05004], lr: 0.049984, loss: 1.4389
2022-07-07 10:07:17 - train: epoch 0103, iter [02700, 05004], lr: 0.049968, loss: 1.5897
2022-07-07 10:07:51 - train: epoch 0103, iter [02800, 05004], lr: 0.049952, loss: 1.2756
2022-07-07 10:08:24 - train: epoch 0103, iter [02900, 05004], lr: 0.049936, loss: 1.5239
2022-07-07 10:08:57 - train: epoch 0103, iter [03000, 05004], lr: 0.049920, loss: 1.7452
2022-07-07 10:09:31 - train: epoch 0103, iter [03100, 05004], lr: 0.049904, loss: 1.5808
2022-07-07 10:10:05 - train: epoch 0103, iter [03200, 05004], lr: 0.049888, loss: 1.4454
2022-07-07 10:10:39 - train: epoch 0103, iter [03300, 05004], lr: 0.049872, loss: 1.5829
2022-07-07 10:11:12 - train: epoch 0103, iter [03400, 05004], lr: 0.049855, loss: 1.5475
2022-07-07 10:11:46 - train: epoch 0103, iter [03500, 05004], lr: 0.049839, loss: 1.6890
2022-07-07 10:12:19 - train: epoch 0103, iter [03600, 05004], lr: 0.049823, loss: 1.4987
2022-07-07 10:12:53 - train: epoch 0103, iter [03700, 05004], lr: 0.049807, loss: 1.4863
2022-07-07 10:13:27 - train: epoch 0103, iter [03800, 05004], lr: 0.049791, loss: 1.5291
2022-07-07 10:14:01 - train: epoch 0103, iter [03900, 05004], lr: 0.049775, loss: 1.5671
2022-07-07 10:14:34 - train: epoch 0103, iter [04000, 05004], lr: 0.049759, loss: 1.5551
2022-07-07 10:15:08 - train: epoch 0103, iter [04100, 05004], lr: 0.049743, loss: 1.5531
2022-07-07 10:15:41 - train: epoch 0103, iter [04200, 05004], lr: 0.049727, loss: 1.6623
2022-07-07 10:16:15 - train: epoch 0103, iter [04300, 05004], lr: 0.049711, loss: 1.6873
2022-07-07 10:16:49 - train: epoch 0103, iter [04400, 05004], lr: 0.049694, loss: 1.7194
2022-07-07 10:17:23 - train: epoch 0103, iter [04500, 05004], lr: 0.049678, loss: 1.6733
2022-07-07 10:17:56 - train: epoch 0103, iter [04600, 05004], lr: 0.049662, loss: 1.7868
2022-07-07 10:18:30 - train: epoch 0103, iter [04700, 05004], lr: 0.049646, loss: 1.4680
2022-07-07 10:19:04 - train: epoch 0103, iter [04800, 05004], lr: 0.049630, loss: 1.9028
2022-07-07 10:19:38 - train: epoch 0103, iter [04900, 05004], lr: 0.049614, loss: 1.4773
2022-07-07 10:20:11 - train: epoch 0103, iter [05000, 05004], lr: 0.049598, loss: 1.5692
2022-07-07 10:20:12 - train: epoch 103, train_loss: 1.5738
2022-07-07 10:21:27 - eval: epoch: 103, acc1: 64.074%, acc5: 86.144%, test_loss: 1.4845, per_image_load_time: 2.079ms, per_image_inference_time: 0.445ms
2022-07-07 10:21:27 - until epoch: 103, best_acc1: 65.380%
2022-07-07 10:21:27 - epoch 104 lr: 0.049597
2022-07-07 10:22:07 - train: epoch 0104, iter [00100, 05004], lr: 0.049581, loss: 1.4763
2022-07-07 10:22:40 - train: epoch 0104, iter [00200, 05004], lr: 0.049565, loss: 1.3798
2022-07-07 10:23:14 - train: epoch 0104, iter [00300, 05004], lr: 0.049549, loss: 1.7426
2022-07-07 10:23:47 - train: epoch 0104, iter [00400, 05004], lr: 0.049533, loss: 1.6086
2022-07-07 10:24:21 - train: epoch 0104, iter [00500, 05004], lr: 0.049517, loss: 1.4814
2022-07-07 10:24:54 - train: epoch 0104, iter [00600, 05004], lr: 0.049501, loss: 1.6827
2022-07-07 10:25:29 - train: epoch 0104, iter [00700, 05004], lr: 0.049485, loss: 1.7521
2022-07-07 10:26:02 - train: epoch 0104, iter [00800, 05004], lr: 0.049468, loss: 1.4819
2022-07-07 10:26:36 - train: epoch 0104, iter [00900, 05004], lr: 0.049452, loss: 1.4314
2022-07-07 10:27:10 - train: epoch 0104, iter [01000, 05004], lr: 0.049436, loss: 1.5549
2022-07-07 10:27:44 - train: epoch 0104, iter [01100, 05004], lr: 0.049420, loss: 1.5310
2022-07-07 10:28:17 - train: epoch 0104, iter [01200, 05004], lr: 0.049404, loss: 1.5260
2022-07-07 10:28:52 - train: epoch 0104, iter [01300, 05004], lr: 0.049388, loss: 1.4767
2022-07-07 10:29:25 - train: epoch 0104, iter [01400, 05004], lr: 0.049372, loss: 1.5417
2022-07-07 10:29:59 - train: epoch 0104, iter [01500, 05004], lr: 0.049356, loss: 1.6931
2022-07-07 10:30:32 - train: epoch 0104, iter [01600, 05004], lr: 0.049340, loss: 1.3796
2022-07-07 10:31:06 - train: epoch 0104, iter [01700, 05004], lr: 0.049324, loss: 1.4735
2022-07-07 10:31:40 - train: epoch 0104, iter [01800, 05004], lr: 0.049307, loss: 1.6789
2022-07-07 10:32:14 - train: epoch 0104, iter [01900, 05004], lr: 0.049291, loss: 1.3681
2022-07-07 10:32:48 - train: epoch 0104, iter [02000, 05004], lr: 0.049275, loss: 1.5356
2022-07-07 10:33:21 - train: epoch 0104, iter [02100, 05004], lr: 0.049259, loss: 1.3899
2022-07-07 10:33:55 - train: epoch 0104, iter [02200, 05004], lr: 0.049243, loss: 1.6314
2022-07-07 10:34:29 - train: epoch 0104, iter [02300, 05004], lr: 0.049227, loss: 1.5991
2022-07-07 10:35:03 - train: epoch 0104, iter [02400, 05004], lr: 0.049211, loss: 1.7215
2022-07-07 10:35:37 - train: epoch 0104, iter [02500, 05004], lr: 0.049195, loss: 1.5700
2022-07-07 10:36:10 - train: epoch 0104, iter [02600, 05004], lr: 0.049179, loss: 1.5403
2022-07-07 10:36:43 - train: epoch 0104, iter [02700, 05004], lr: 0.049163, loss: 1.6503
2022-07-07 10:37:18 - train: epoch 0104, iter [02800, 05004], lr: 0.049147, loss: 1.6391
2022-07-07 10:37:51 - train: epoch 0104, iter [02900, 05004], lr: 0.049130, loss: 1.7457
2022-07-07 10:38:25 - train: epoch 0104, iter [03000, 05004], lr: 0.049114, loss: 1.7006
2022-07-07 10:38:58 - train: epoch 0104, iter [03100, 05004], lr: 0.049098, loss: 1.5289
2022-07-07 10:39:33 - train: epoch 0104, iter [03200, 05004], lr: 0.049082, loss: 1.5995
2022-07-07 10:40:06 - train: epoch 0104, iter [03300, 05004], lr: 0.049066, loss: 1.7641
2022-07-07 10:40:40 - train: epoch 0104, iter [03400, 05004], lr: 0.049050, loss: 1.4020
2022-07-07 10:41:14 - train: epoch 0104, iter [03500, 05004], lr: 0.049034, loss: 1.5272
2022-07-07 10:41:47 - train: epoch 0104, iter [03600, 05004], lr: 0.049018, loss: 1.5745
2022-07-07 10:42:21 - train: epoch 0104, iter [03700, 05004], lr: 0.049002, loss: 1.5820
2022-07-07 10:42:55 - train: epoch 0104, iter [03800, 05004], lr: 0.048986, loss: 1.3102
2022-07-07 10:43:29 - train: epoch 0104, iter [03900, 05004], lr: 0.048969, loss: 1.5236
2022-07-07 10:44:03 - train: epoch 0104, iter [04000, 05004], lr: 0.048953, loss: 1.3799
2022-07-07 10:44:36 - train: epoch 0104, iter [04100, 05004], lr: 0.048937, loss: 1.4562
2022-07-07 10:45:09 - train: epoch 0104, iter [04200, 05004], lr: 0.048921, loss: 1.5072
2022-07-07 10:45:43 - train: epoch 0104, iter [04300, 05004], lr: 0.048905, loss: 1.4234
2022-07-07 10:46:17 - train: epoch 0104, iter [04400, 05004], lr: 0.048889, loss: 1.4832
2022-07-07 10:46:51 - train: epoch 0104, iter [04500, 05004], lr: 0.048873, loss: 1.8350
2022-07-07 10:47:24 - train: epoch 0104, iter [04600, 05004], lr: 0.048857, loss: 1.4959
2022-07-07 10:47:58 - train: epoch 0104, iter [04700, 05004], lr: 0.048841, loss: 1.5338
2022-07-07 10:48:32 - train: epoch 0104, iter [04800, 05004], lr: 0.048825, loss: 1.6269
2022-07-07 10:49:07 - train: epoch 0104, iter [04900, 05004], lr: 0.048809, loss: 1.5079
2022-07-07 10:49:39 - train: epoch 0104, iter [05000, 05004], lr: 0.048792, loss: 1.6046
2022-07-07 10:49:40 - train: epoch 104, train_loss: 1.5651
2022-07-07 10:50:55 - eval: epoch: 104, acc1: 60.736%, acc5: 83.880%, test_loss: 1.6441, per_image_load_time: 1.680ms, per_image_inference_time: 0.475ms
2022-07-07 10:50:55 - until epoch: 104, best_acc1: 65.380%
2022-07-07 10:50:55 - epoch 105 lr: 0.048792
2022-07-07 10:51:34 - train: epoch 0105, iter [00100, 05004], lr: 0.048776, loss: 1.5853
2022-07-07 10:52:08 - train: epoch 0105, iter [00200, 05004], lr: 0.048760, loss: 1.7285
2022-07-07 10:52:42 - train: epoch 0105, iter [00300, 05004], lr: 0.048744, loss: 1.6073
2022-07-07 10:53:14 - train: epoch 0105, iter [00400, 05004], lr: 0.048727, loss: 1.5870
2022-07-07 10:53:48 - train: epoch 0105, iter [00500, 05004], lr: 0.048711, loss: 1.5232
2022-07-07 10:54:21 - train: epoch 0105, iter [00600, 05004], lr: 0.048695, loss: 1.6975
2022-07-07 10:54:54 - train: epoch 0105, iter [00700, 05004], lr: 0.048679, loss: 1.4606
2022-07-07 10:55:28 - train: epoch 0105, iter [00800, 05004], lr: 0.048663, loss: 1.5755
2022-07-07 10:56:02 - train: epoch 0105, iter [00900, 05004], lr: 0.048647, loss: 1.4984
2022-07-07 10:56:35 - train: epoch 0105, iter [01000, 05004], lr: 0.048631, loss: 1.4255
2022-07-07 10:57:09 - train: epoch 0105, iter [01100, 05004], lr: 0.048615, loss: 1.7760
2022-07-07 10:57:43 - train: epoch 0105, iter [01200, 05004], lr: 0.048599, loss: 1.5685
2022-07-07 10:58:16 - train: epoch 0105, iter [01300, 05004], lr: 0.048583, loss: 1.4291
2022-07-07 10:58:50 - train: epoch 0105, iter [01400, 05004], lr: 0.048567, loss: 1.6733
2022-07-07 10:59:24 - train: epoch 0105, iter [01500, 05004], lr: 0.048550, loss: 1.5280
2022-07-07 10:59:57 - train: epoch 0105, iter [01600, 05004], lr: 0.048534, loss: 1.1954
2022-07-07 11:00:31 - train: epoch 0105, iter [01700, 05004], lr: 0.048518, loss: 1.5201
2022-07-07 11:01:05 - train: epoch 0105, iter [01800, 05004], lr: 0.048502, loss: 1.5590
2022-07-07 11:01:39 - train: epoch 0105, iter [01900, 05004], lr: 0.048486, loss: 1.6720
2022-07-07 11:02:12 - train: epoch 0105, iter [02000, 05004], lr: 0.048470, loss: 1.5078
2022-07-07 11:02:46 - train: epoch 0105, iter [02100, 05004], lr: 0.048454, loss: 1.6214
2022-07-07 11:03:20 - train: epoch 0105, iter [02200, 05004], lr: 0.048438, loss: 1.7679
2022-07-07 11:03:54 - train: epoch 0105, iter [02300, 05004], lr: 0.048422, loss: 1.4790
2022-07-07 11:04:28 - train: epoch 0105, iter [02400, 05004], lr: 0.048406, loss: 1.6011
2022-07-07 11:05:01 - train: epoch 0105, iter [02500, 05004], lr: 0.048390, loss: 1.4377
2022-07-07 11:05:35 - train: epoch 0105, iter [02600, 05004], lr: 0.048373, loss: 1.4947
2022-07-07 11:06:09 - train: epoch 0105, iter [02700, 05004], lr: 0.048357, loss: 1.9049
2022-07-07 11:06:42 - train: epoch 0105, iter [02800, 05004], lr: 0.048341, loss: 1.8642
2022-07-07 11:07:16 - train: epoch 0105, iter [02900, 05004], lr: 0.048325, loss: 1.6556
2022-07-07 11:07:50 - train: epoch 0105, iter [03000, 05004], lr: 0.048309, loss: 1.6104
2022-07-07 11:08:24 - train: epoch 0105, iter [03100, 05004], lr: 0.048293, loss: 1.6813
2022-07-07 11:08:58 - train: epoch 0105, iter [03200, 05004], lr: 0.048277, loss: 1.9491
2022-07-07 11:09:32 - train: epoch 0105, iter [03300, 05004], lr: 0.048261, loss: 1.3333
2022-07-07 11:10:05 - train: epoch 0105, iter [03400, 05004], lr: 0.048245, loss: 1.3907
2022-07-07 11:10:39 - train: epoch 0105, iter [03500, 05004], lr: 0.048229, loss: 1.6579
2022-07-07 11:11:12 - train: epoch 0105, iter [03600, 05004], lr: 0.048213, loss: 1.5759
2022-07-07 11:11:46 - train: epoch 0105, iter [03700, 05004], lr: 0.048196, loss: 1.4936
2022-07-07 11:12:20 - train: epoch 0105, iter [03800, 05004], lr: 0.048180, loss: 1.7006
2022-07-07 11:12:54 - train: epoch 0105, iter [03900, 05004], lr: 0.048164, loss: 1.6136
2022-07-07 11:13:28 - train: epoch 0105, iter [04000, 05004], lr: 0.048148, loss: 1.5783
2022-07-07 11:14:01 - train: epoch 0105, iter [04100, 05004], lr: 0.048132, loss: 1.3327
2022-07-07 11:14:35 - train: epoch 0105, iter [04200, 05004], lr: 0.048116, loss: 1.5864
2022-07-07 11:15:09 - train: epoch 0105, iter [04300, 05004], lr: 0.048100, loss: 1.8106
2022-07-07 11:15:43 - train: epoch 0105, iter [04400, 05004], lr: 0.048084, loss: 1.4720
2022-07-07 11:16:17 - train: epoch 0105, iter [04500, 05004], lr: 0.048068, loss: 1.9166
2022-07-07 11:16:50 - train: epoch 0105, iter [04600, 05004], lr: 0.048052, loss: 1.5660
2022-07-07 11:17:24 - train: epoch 0105, iter [04700, 05004], lr: 0.048036, loss: 1.6043
2022-07-07 11:17:58 - train: epoch 0105, iter [04800, 05004], lr: 0.048020, loss: 1.6601
2022-07-07 11:18:31 - train: epoch 0105, iter [04900, 05004], lr: 0.048003, loss: 1.5945
2022-07-07 11:19:03 - train: epoch 0105, iter [05000, 05004], lr: 0.047987, loss: 1.3797
2022-07-07 11:19:04 - train: epoch 105, train_loss: 1.5608
2022-07-07 11:20:19 - eval: epoch: 105, acc1: 65.376%, acc5: 87.228%, test_loss: 1.4191, per_image_load_time: 2.014ms, per_image_inference_time: 0.482ms
2022-07-07 11:20:19 - until epoch: 105, best_acc1: 65.380%
2022-07-07 11:20:19 - epoch 106 lr: 0.047987
2022-07-07 11:20:58 - train: epoch 0106, iter [00100, 05004], lr: 0.047971, loss: 1.3263
2022-07-07 11:21:32 - train: epoch 0106, iter [00200, 05004], lr: 0.047955, loss: 1.3527
2022-07-07 11:22:05 - train: epoch 0106, iter [00300, 05004], lr: 0.047938, loss: 1.3063
2022-07-07 11:22:39 - train: epoch 0106, iter [00400, 05004], lr: 0.047922, loss: 1.6290
2022-07-07 11:23:12 - train: epoch 0106, iter [00500, 05004], lr: 0.047906, loss: 1.6722
2022-07-07 11:23:46 - train: epoch 0106, iter [00600, 05004], lr: 0.047890, loss: 1.5101
2022-07-07 11:24:19 - train: epoch 0106, iter [00700, 05004], lr: 0.047874, loss: 1.5359
2022-07-07 11:24:53 - train: epoch 0106, iter [00800, 05004], lr: 0.047858, loss: 1.3904
2022-07-07 11:25:26 - train: epoch 0106, iter [00900, 05004], lr: 0.047842, loss: 1.7399
2022-07-07 11:25:59 - train: epoch 0106, iter [01000, 05004], lr: 0.047826, loss: 1.7820
2022-07-07 11:26:33 - train: epoch 0106, iter [01100, 05004], lr: 0.047810, loss: 1.3282
2022-07-07 11:27:08 - train: epoch 0106, iter [01200, 05004], lr: 0.047794, loss: 1.3724
2022-07-07 11:27:41 - train: epoch 0106, iter [01300, 05004], lr: 0.047778, loss: 1.5212
2022-07-07 11:28:15 - train: epoch 0106, iter [01400, 05004], lr: 0.047762, loss: 1.5826
2022-07-07 11:28:49 - train: epoch 0106, iter [01500, 05004], lr: 0.047745, loss: 1.5035
2022-07-07 11:29:22 - train: epoch 0106, iter [01600, 05004], lr: 0.047729, loss: 1.5529
2022-07-07 11:29:56 - train: epoch 0106, iter [01700, 05004], lr: 0.047713, loss: 1.5177
2022-07-07 11:30:29 - train: epoch 0106, iter [01800, 05004], lr: 0.047697, loss: 1.3880
2022-07-07 11:31:04 - train: epoch 0106, iter [01900, 05004], lr: 0.047681, loss: 1.4833
2022-07-07 11:31:37 - train: epoch 0106, iter [02000, 05004], lr: 0.047665, loss: 1.4455
2022-07-07 11:32:11 - train: epoch 0106, iter [02100, 05004], lr: 0.047649, loss: 1.5024
2022-07-07 11:32:44 - train: epoch 0106, iter [02200, 05004], lr: 0.047633, loss: 1.5662
2022-07-07 11:33:18 - train: epoch 0106, iter [02300, 05004], lr: 0.047617, loss: 1.4627
2022-07-07 11:33:52 - train: epoch 0106, iter [02400, 05004], lr: 0.047601, loss: 1.6390
2022-07-07 11:34:26 - train: epoch 0106, iter [02500, 05004], lr: 0.047585, loss: 1.5653
2022-07-07 11:34:59 - train: epoch 0106, iter [02600, 05004], lr: 0.047569, loss: 1.2203
2022-07-07 11:35:33 - train: epoch 0106, iter [02700, 05004], lr: 0.047552, loss: 1.5485
2022-07-07 11:36:06 - train: epoch 0106, iter [02800, 05004], lr: 0.047536, loss: 1.5535
2022-07-07 11:36:40 - train: epoch 0106, iter [02900, 05004], lr: 0.047520, loss: 1.3588
2022-07-07 11:37:13 - train: epoch 0106, iter [03000, 05004], lr: 0.047504, loss: 1.7642
2022-07-07 11:37:47 - train: epoch 0106, iter [03100, 05004], lr: 0.047488, loss: 1.4838
2022-07-07 11:38:21 - train: epoch 0106, iter [03200, 05004], lr: 0.047472, loss: 1.3479
2022-07-07 11:38:55 - train: epoch 0106, iter [03300, 05004], lr: 0.047456, loss: 1.5284
2022-07-07 11:39:29 - train: epoch 0106, iter [03400, 05004], lr: 0.047440, loss: 1.4600
2022-07-07 11:40:03 - train: epoch 0106, iter [03500, 05004], lr: 0.047424, loss: 1.4556
2022-07-07 11:40:36 - train: epoch 0106, iter [03600, 05004], lr: 0.047408, loss: 1.4433
2022-07-07 11:41:10 - train: epoch 0106, iter [03700, 05004], lr: 0.047392, loss: 1.7530
2022-07-07 11:41:44 - train: epoch 0106, iter [03800, 05004], lr: 0.047376, loss: 1.7563
2022-07-07 11:42:18 - train: epoch 0106, iter [03900, 05004], lr: 0.047360, loss: 1.7995
2022-07-07 11:42:51 - train: epoch 0106, iter [04000, 05004], lr: 0.047343, loss: 1.5222
2022-07-07 11:43:25 - train: epoch 0106, iter [04100, 05004], lr: 0.047327, loss: 1.5979
2022-07-07 11:43:59 - train: epoch 0106, iter [04200, 05004], lr: 0.047311, loss: 1.3979
2022-07-07 11:44:33 - train: epoch 0106, iter [04300, 05004], lr: 0.047295, loss: 1.1865
2022-07-07 11:45:07 - train: epoch 0106, iter [04400, 05004], lr: 0.047279, loss: 1.5986
2022-07-07 11:45:40 - train: epoch 0106, iter [04500, 05004], lr: 0.047263, loss: 1.7461
2022-07-07 11:46:13 - train: epoch 0106, iter [04600, 05004], lr: 0.047247, loss: 1.8043
2022-07-07 11:46:47 - train: epoch 0106, iter [04700, 05004], lr: 0.047231, loss: 1.5277
2022-07-07 11:47:21 - train: epoch 0106, iter [04800, 05004], lr: 0.047215, loss: 1.6360
2022-07-07 11:47:54 - train: epoch 0106, iter [04900, 05004], lr: 0.047199, loss: 1.4558
2022-07-07 11:48:27 - train: epoch 0106, iter [05000, 05004], lr: 0.047183, loss: 1.7017
2022-07-07 11:48:28 - train: epoch 106, train_loss: 1.5527
2022-07-07 11:49:42 - eval: epoch: 106, acc1: 64.296%, acc5: 86.160%, test_loss: 1.4912, per_image_load_time: 2.123ms, per_image_inference_time: 0.458ms
2022-07-07 11:49:43 - until epoch: 106, best_acc1: 65.380%
2022-07-07 11:49:43 - epoch 107 lr: 0.047182
2022-07-07 11:50:22 - train: epoch 0107, iter [00100, 05004], lr: 0.047166, loss: 1.3404
2022-07-07 11:50:55 - train: epoch 0107, iter [00200, 05004], lr: 0.047150, loss: 1.6153
2022-07-07 11:51:29 - train: epoch 0107, iter [00300, 05004], lr: 0.047134, loss: 1.5725
2022-07-07 11:52:02 - train: epoch 0107, iter [00400, 05004], lr: 0.047118, loss: 1.4874
2022-07-07 11:52:36 - train: epoch 0107, iter [00500, 05004], lr: 0.047102, loss: 1.3954
2022-07-07 11:53:09 - train: epoch 0107, iter [00600, 05004], lr: 0.047086, loss: 1.2984
2022-07-07 11:53:43 - train: epoch 0107, iter [00700, 05004], lr: 0.047070, loss: 1.4720
2022-07-07 11:54:16 - train: epoch 0107, iter [00800, 05004], lr: 0.047054, loss: 1.2658
2022-07-07 11:54:50 - train: epoch 0107, iter [00900, 05004], lr: 0.047037, loss: 1.6143
2022-07-07 11:55:23 - train: epoch 0107, iter [01000, 05004], lr: 0.047021, loss: 1.5512
2022-07-07 11:55:57 - train: epoch 0107, iter [01100, 05004], lr: 0.047005, loss: 1.7003
2022-07-07 11:56:30 - train: epoch 0107, iter [01200, 05004], lr: 0.046989, loss: 1.5452
2022-07-07 11:57:04 - train: epoch 0107, iter [01300, 05004], lr: 0.046973, loss: 1.4489
2022-07-07 11:57:38 - train: epoch 0107, iter [01400, 05004], lr: 0.046957, loss: 1.4887
2022-07-07 11:58:10 - train: epoch 0107, iter [01500, 05004], lr: 0.046941, loss: 1.5396
2022-07-07 11:58:44 - train: epoch 0107, iter [01600, 05004], lr: 0.046925, loss: 1.4572
2022-07-07 11:59:18 - train: epoch 0107, iter [01700, 05004], lr: 0.046909, loss: 1.4753
2022-07-07 11:59:51 - train: epoch 0107, iter [01800, 05004], lr: 0.046893, loss: 1.6305
2022-07-07 12:00:25 - train: epoch 0107, iter [01900, 05004], lr: 0.046877, loss: 1.6535
2022-07-07 12:00:58 - train: epoch 0107, iter [02000, 05004], lr: 0.046861, loss: 1.3971
2022-07-07 12:01:32 - train: epoch 0107, iter [02100, 05004], lr: 0.046845, loss: 1.5166
2022-07-07 12:02:05 - train: epoch 0107, iter [02200, 05004], lr: 0.046829, loss: 1.5397
2022-07-07 12:02:39 - train: epoch 0107, iter [02300, 05004], lr: 0.046813, loss: 1.5561
2022-07-07 12:03:12 - train: epoch 0107, iter [02400, 05004], lr: 0.046796, loss: 1.5945
2022-07-07 12:03:46 - train: epoch 0107, iter [02500, 05004], lr: 0.046780, loss: 1.5642
2022-07-07 12:04:19 - train: epoch 0107, iter [02600, 05004], lr: 0.046764, loss: 1.6655
2022-07-07 12:04:53 - train: epoch 0107, iter [02700, 05004], lr: 0.046748, loss: 1.6091
2022-07-07 12:05:27 - train: epoch 0107, iter [02800, 05004], lr: 0.046732, loss: 1.6055
2022-07-07 12:06:01 - train: epoch 0107, iter [02900, 05004], lr: 0.046716, loss: 1.5556
2022-07-07 12:06:35 - train: epoch 0107, iter [03000, 05004], lr: 0.046700, loss: 1.5936
2022-07-07 12:07:09 - train: epoch 0107, iter [03100, 05004], lr: 0.046684, loss: 1.7436
2022-07-07 12:07:43 - train: epoch 0107, iter [03200, 05004], lr: 0.046668, loss: 1.4226
2022-07-07 12:08:16 - train: epoch 0107, iter [03300, 05004], lr: 0.046652, loss: 1.6137
2022-07-07 12:08:50 - train: epoch 0107, iter [03400, 05004], lr: 0.046636, loss: 1.3873
2022-07-07 12:09:24 - train: epoch 0107, iter [03500, 05004], lr: 0.046620, loss: 1.4054
2022-07-07 12:09:58 - train: epoch 0107, iter [03600, 05004], lr: 0.046604, loss: 1.6460
2022-07-07 12:10:31 - train: epoch 0107, iter [03700, 05004], lr: 0.046588, loss: 1.5301
2022-07-07 12:11:05 - train: epoch 0107, iter [03800, 05004], lr: 0.046572, loss: 1.4838
2022-07-07 12:11:39 - train: epoch 0107, iter [03900, 05004], lr: 0.046556, loss: 1.4185
2022-07-07 12:12:13 - train: epoch 0107, iter [04000, 05004], lr: 0.046539, loss: 1.6811
2022-07-07 12:12:47 - train: epoch 0107, iter [04100, 05004], lr: 0.046523, loss: 1.5323
2022-07-07 12:13:20 - train: epoch 0107, iter [04200, 05004], lr: 0.046507, loss: 1.7082
2022-07-07 12:13:55 - train: epoch 0107, iter [04300, 05004], lr: 0.046491, loss: 1.6096
2022-07-07 12:14:28 - train: epoch 0107, iter [04400, 05004], lr: 0.046475, loss: 1.5427
2022-07-07 12:15:02 - train: epoch 0107, iter [04500, 05004], lr: 0.046459, loss: 1.4900
2022-07-07 12:15:36 - train: epoch 0107, iter [04600, 05004], lr: 0.046443, loss: 1.4303
2022-07-07 12:16:11 - train: epoch 0107, iter [04700, 05004], lr: 0.046427, loss: 1.5745
2022-07-07 12:16:44 - train: epoch 0107, iter [04800, 05004], lr: 0.046411, loss: 1.6037
2022-07-07 12:17:18 - train: epoch 0107, iter [04900, 05004], lr: 0.046395, loss: 1.3057
2022-07-07 12:17:51 - train: epoch 0107, iter [05000, 05004], lr: 0.046379, loss: 1.3999
2022-07-07 12:17:52 - train: epoch 107, train_loss: 1.5450
2022-07-07 12:19:07 - eval: epoch: 107, acc1: 62.644%, acc5: 85.106%, test_loss: 1.5612, per_image_load_time: 2.076ms, per_image_inference_time: 0.460ms
2022-07-07 12:19:07 - until epoch: 107, best_acc1: 65.380%
2022-07-07 12:19:07 - epoch 108 lr: 0.046378
2022-07-07 12:19:46 - train: epoch 0108, iter [00100, 05004], lr: 0.046362, loss: 1.3633
2022-07-07 12:20:20 - train: epoch 0108, iter [00200, 05004], lr: 0.046346, loss: 1.2272
2022-07-07 12:20:53 - train: epoch 0108, iter [00300, 05004], lr: 0.046330, loss: 1.5512
2022-07-07 12:21:27 - train: epoch 0108, iter [00400, 05004], lr: 0.046314, loss: 1.8027
2022-07-07 12:22:00 - train: epoch 0108, iter [00500, 05004], lr: 0.046298, loss: 1.3422
2022-07-07 12:22:34 - train: epoch 0108, iter [00600, 05004], lr: 0.046282, loss: 1.6855
2022-07-07 12:23:07 - train: epoch 0108, iter [00700, 05004], lr: 0.046266, loss: 1.5628
2022-07-07 12:23:41 - train: epoch 0108, iter [00800, 05004], lr: 0.046250, loss: 1.5589
2022-07-07 12:24:14 - train: epoch 0108, iter [00900, 05004], lr: 0.046234, loss: 1.6097
2022-07-07 12:24:47 - train: epoch 0108, iter [01000, 05004], lr: 0.046218, loss: 1.4301
2022-07-07 12:25:20 - train: epoch 0108, iter [01100, 05004], lr: 0.046202, loss: 1.6756
2022-07-07 12:25:54 - train: epoch 0108, iter [01200, 05004], lr: 0.046186, loss: 1.5856
2022-07-07 12:26:28 - train: epoch 0108, iter [01300, 05004], lr: 0.046170, loss: 1.4856
2022-07-07 12:27:00 - train: epoch 0108, iter [01400, 05004], lr: 0.046154, loss: 1.6257
2022-07-07 12:27:34 - train: epoch 0108, iter [01500, 05004], lr: 0.046137, loss: 1.6864
2022-07-07 12:28:08 - train: epoch 0108, iter [01600, 05004], lr: 0.046121, loss: 1.5683
2022-07-07 12:28:42 - train: epoch 0108, iter [01700, 05004], lr: 0.046105, loss: 1.6913
2022-07-07 12:29:15 - train: epoch 0108, iter [01800, 05004], lr: 0.046089, loss: 1.4415
2022-07-07 12:29:48 - train: epoch 0108, iter [01900, 05004], lr: 0.046073, loss: 1.6632
2022-07-07 12:30:22 - train: epoch 0108, iter [02000, 05004], lr: 0.046057, loss: 1.6828
2022-07-07 12:30:55 - train: epoch 0108, iter [02100, 05004], lr: 0.046041, loss: 1.5540
2022-07-07 12:31:29 - train: epoch 0108, iter [02200, 05004], lr: 0.046025, loss: 1.5648
2022-07-07 12:32:03 - train: epoch 0108, iter [02300, 05004], lr: 0.046009, loss: 1.5046
2022-07-07 12:32:36 - train: epoch 0108, iter [02400, 05004], lr: 0.045993, loss: 1.7416
2022-07-07 12:33:11 - train: epoch 0108, iter [02500, 05004], lr: 0.045977, loss: 1.8638
2022-07-07 12:33:45 - train: epoch 0108, iter [02600, 05004], lr: 0.045961, loss: 1.7362
2022-07-07 12:34:18 - train: epoch 0108, iter [02700, 05004], lr: 0.045945, loss: 1.6690
2022-07-07 12:34:52 - train: epoch 0108, iter [02800, 05004], lr: 0.045929, loss: 1.6668
2022-07-07 12:35:25 - train: epoch 0108, iter [02900, 05004], lr: 0.045913, loss: 1.5743
2022-07-07 12:35:59 - train: epoch 0108, iter [03000, 05004], lr: 0.045897, loss: 1.5455
2022-07-07 12:36:33 - train: epoch 0108, iter [03100, 05004], lr: 0.045881, loss: 1.4695
2022-07-07 12:37:07 - train: epoch 0108, iter [03200, 05004], lr: 0.045865, loss: 1.4236
2022-07-07 12:37:41 - train: epoch 0108, iter [03300, 05004], lr: 0.045849, loss: 1.3648
2022-07-07 12:38:15 - train: epoch 0108, iter [03400, 05004], lr: 0.045833, loss: 1.7203
2022-07-07 12:38:49 - train: epoch 0108, iter [03500, 05004], lr: 0.045817, loss: 1.5544
2022-07-07 12:39:23 - train: epoch 0108, iter [03600, 05004], lr: 0.045801, loss: 1.6375
2022-07-07 12:39:57 - train: epoch 0108, iter [03700, 05004], lr: 0.045784, loss: 1.5349
2022-07-07 12:40:31 - train: epoch 0108, iter [03800, 05004], lr: 0.045768, loss: 1.5757
2022-07-07 12:41:05 - train: epoch 0108, iter [03900, 05004], lr: 0.045752, loss: 1.6572
2022-07-07 12:41:39 - train: epoch 0108, iter [04000, 05004], lr: 0.045736, loss: 1.5541
2022-07-07 12:42:13 - train: epoch 0108, iter [04100, 05004], lr: 0.045720, loss: 1.5209
2022-07-07 12:42:46 - train: epoch 0108, iter [04200, 05004], lr: 0.045704, loss: 1.5145
2022-07-07 12:43:20 - train: epoch 0108, iter [04300, 05004], lr: 0.045688, loss: 1.5548
2022-07-07 12:43:53 - train: epoch 0108, iter [04400, 05004], lr: 0.045672, loss: 1.5239
2022-07-07 12:44:27 - train: epoch 0108, iter [04500, 05004], lr: 0.045656, loss: 1.7013
2022-07-07 12:45:00 - train: epoch 0108, iter [04600, 05004], lr: 0.045640, loss: 1.6536
2022-07-07 12:45:34 - train: epoch 0108, iter [04700, 05004], lr: 0.045624, loss: 1.5869
2022-07-07 12:46:08 - train: epoch 0108, iter [04800, 05004], lr: 0.045608, loss: 1.4681
2022-07-07 12:46:42 - train: epoch 0108, iter [04900, 05004], lr: 0.045592, loss: 1.6261
2022-07-07 12:47:15 - train: epoch 0108, iter [05000, 05004], lr: 0.045576, loss: 1.5326
2022-07-07 12:47:16 - train: epoch 108, train_loss: 1.5387
2022-07-07 12:48:32 - eval: epoch: 108, acc1: 64.830%, acc5: 86.690%, test_loss: 1.4461, per_image_load_time: 2.445ms, per_image_inference_time: 0.469ms
2022-07-07 12:48:32 - until epoch: 108, best_acc1: 65.380%
2022-07-07 12:48:32 - epoch 109 lr: 0.045575
2022-07-07 12:49:11 - train: epoch 0109, iter [00100, 05004], lr: 0.045559, loss: 1.4784
2022-07-07 12:49:45 - train: epoch 0109, iter [00200, 05004], lr: 0.045543, loss: 1.6100
2022-07-07 12:50:19 - train: epoch 0109, iter [00300, 05004], lr: 0.045527, loss: 1.4204
2022-07-07 12:50:52 - train: epoch 0109, iter [00400, 05004], lr: 0.045511, loss: 1.5591
2022-07-07 12:51:26 - train: epoch 0109, iter [00500, 05004], lr: 0.045495, loss: 1.6607
2022-07-07 12:51:59 - train: epoch 0109, iter [00600, 05004], lr: 0.045479, loss: 1.4308
2022-07-07 12:52:32 - train: epoch 0109, iter [00700, 05004], lr: 0.045463, loss: 1.3933
2022-07-07 12:53:06 - train: epoch 0109, iter [00800, 05004], lr: 0.045447, loss: 1.5874
2022-07-07 12:53:40 - train: epoch 0109, iter [00900, 05004], lr: 0.045431, loss: 1.4923
2022-07-07 12:54:14 - train: epoch 0109, iter [01000, 05004], lr: 0.045415, loss: 1.2524
2022-07-07 12:54:48 - train: epoch 0109, iter [01100, 05004], lr: 0.045399, loss: 1.3328
2022-07-07 12:55:21 - train: epoch 0109, iter [01200, 05004], lr: 0.045383, loss: 1.4389
2022-07-07 12:55:55 - train: epoch 0109, iter [01300, 05004], lr: 0.045367, loss: 1.3536
2022-07-07 12:56:29 - train: epoch 0109, iter [01400, 05004], lr: 0.045351, loss: 1.4367
2022-07-07 12:57:02 - train: epoch 0109, iter [01500, 05004], lr: 0.045335, loss: 1.6739
2022-07-07 12:57:36 - train: epoch 0109, iter [01600, 05004], lr: 0.045319, loss: 1.5265
2022-07-07 12:58:10 - train: epoch 0109, iter [01700, 05004], lr: 0.045303, loss: 1.6841
2022-07-07 12:58:43 - train: epoch 0109, iter [01800, 05004], lr: 0.045287, loss: 1.7332
2022-07-07 12:59:17 - train: epoch 0109, iter [01900, 05004], lr: 0.045271, loss: 1.5831
2022-07-07 12:59:50 - train: epoch 0109, iter [02000, 05004], lr: 0.045255, loss: 1.5587
2022-07-07 13:00:25 - train: epoch 0109, iter [02100, 05004], lr: 0.045239, loss: 1.4710
2022-07-07 13:00:58 - train: epoch 0109, iter [02200, 05004], lr: 0.045223, loss: 1.4136
2022-07-07 13:01:32 - train: epoch 0109, iter [02300, 05004], lr: 0.045207, loss: 1.4380
2022-07-07 13:02:06 - train: epoch 0109, iter [02400, 05004], lr: 0.045191, loss: 1.6279
2022-07-07 13:02:40 - train: epoch 0109, iter [02500, 05004], lr: 0.045175, loss: 1.4229
2022-07-07 13:03:13 - train: epoch 0109, iter [02600, 05004], lr: 0.045159, loss: 1.6074
2022-07-07 13:03:47 - train: epoch 0109, iter [02700, 05004], lr: 0.045143, loss: 1.4736
2022-07-07 13:04:21 - train: epoch 0109, iter [02800, 05004], lr: 0.045127, loss: 1.5498
2022-07-07 13:04:55 - train: epoch 0109, iter [02900, 05004], lr: 0.045111, loss: 1.4660
2022-07-07 13:05:29 - train: epoch 0109, iter [03000, 05004], lr: 0.045095, loss: 1.4185
2022-07-07 13:06:04 - train: epoch 0109, iter [03100, 05004], lr: 0.045078, loss: 1.5440
2022-07-07 13:06:37 - train: epoch 0109, iter [03200, 05004], lr: 0.045062, loss: 1.5011
2022-07-07 13:07:10 - train: epoch 0109, iter [03300, 05004], lr: 0.045046, loss: 1.7350
2022-07-07 13:07:44 - train: epoch 0109, iter [03400, 05004], lr: 0.045030, loss: 1.5266
2022-07-07 13:08:19 - train: epoch 0109, iter [03500, 05004], lr: 0.045014, loss: 1.6800
2022-07-07 13:08:52 - train: epoch 0109, iter [03600, 05004], lr: 0.044998, loss: 1.4437
2022-07-07 13:09:27 - train: epoch 0109, iter [03700, 05004], lr: 0.044982, loss: 1.2101
2022-07-07 13:09:59 - train: epoch 0109, iter [03800, 05004], lr: 0.044966, loss: 1.5806
2022-07-07 13:10:34 - train: epoch 0109, iter [03900, 05004], lr: 0.044950, loss: 1.6084
2022-07-07 13:11:08 - train: epoch 0109, iter [04000, 05004], lr: 0.044934, loss: 1.5489
2022-07-07 13:11:42 - train: epoch 0109, iter [04100, 05004], lr: 0.044918, loss: 1.5837
2022-07-07 13:12:15 - train: epoch 0109, iter [04200, 05004], lr: 0.044902, loss: 1.6292
2022-07-07 13:12:49 - train: epoch 0109, iter [04300, 05004], lr: 0.044886, loss: 1.5699
2022-07-07 13:13:23 - train: epoch 0109, iter [04400, 05004], lr: 0.044870, loss: 1.5024
2022-07-07 13:13:57 - train: epoch 0109, iter [04500, 05004], lr: 0.044854, loss: 1.4238
2022-07-07 13:14:31 - train: epoch 0109, iter [04600, 05004], lr: 0.044838, loss: 1.5337
2022-07-07 13:15:04 - train: epoch 0109, iter [04700, 05004], lr: 0.044822, loss: 1.4520
2022-07-07 13:15:39 - train: epoch 0109, iter [04800, 05004], lr: 0.044806, loss: 1.5754
2022-07-07 13:16:12 - train: epoch 0109, iter [04900, 05004], lr: 0.044790, loss: 1.4372
2022-07-07 13:16:44 - train: epoch 0109, iter [05000, 05004], lr: 0.044774, loss: 1.3077
2022-07-07 13:16:45 - train: epoch 109, train_loss: 1.5291
2022-07-07 13:18:00 - eval: epoch: 109, acc1: 64.498%, acc5: 86.388%, test_loss: 1.4756, per_image_load_time: 1.655ms, per_image_inference_time: 0.446ms
2022-07-07 13:18:00 - until epoch: 109, best_acc1: 65.380%
2022-07-07 13:18:00 - epoch 110 lr: 0.044773
2022-07-07 13:18:40 - train: epoch 0110, iter [00100, 05004], lr: 0.044758, loss: 1.1958
2022-07-07 13:19:14 - train: epoch 0110, iter [00200, 05004], lr: 0.044742, loss: 1.2850
2022-07-07 13:19:47 - train: epoch 0110, iter [00300, 05004], lr: 0.044726, loss: 1.7270
2022-07-07 13:20:21 - train: epoch 0110, iter [00400, 05004], lr: 0.044710, loss: 1.4256
2022-07-07 13:20:54 - train: epoch 0110, iter [00500, 05004], lr: 0.044694, loss: 1.4375
2022-07-07 13:21:28 - train: epoch 0110, iter [00600, 05004], lr: 0.044678, loss: 1.4973
2022-07-07 13:22:02 - train: epoch 0110, iter [00700, 05004], lr: 0.044662, loss: 1.5070
2022-07-07 13:22:35 - train: epoch 0110, iter [00800, 05004], lr: 0.044646, loss: 1.5664
2022-07-07 13:23:08 - train: epoch 0110, iter [00900, 05004], lr: 0.044630, loss: 1.4605
2022-07-07 13:23:42 - train: epoch 0110, iter [01000, 05004], lr: 0.044614, loss: 1.3663
2022-07-07 13:24:16 - train: epoch 0110, iter [01100, 05004], lr: 0.044598, loss: 1.8850
2022-07-07 13:24:49 - train: epoch 0110, iter [01200, 05004], lr: 0.044582, loss: 1.5763
2022-07-07 13:25:23 - train: epoch 0110, iter [01300, 05004], lr: 0.044565, loss: 1.4696
2022-07-07 13:25:57 - train: epoch 0110, iter [01400, 05004], lr: 0.044549, loss: 1.3307
2022-07-07 13:26:30 - train: epoch 0110, iter [01500, 05004], lr: 0.044533, loss: 1.6886
2022-07-07 13:27:04 - train: epoch 0110, iter [01600, 05004], lr: 0.044517, loss: 1.4475
2022-07-07 13:27:37 - train: epoch 0110, iter [01700, 05004], lr: 0.044501, loss: 1.4573
2022-07-07 13:28:12 - train: epoch 0110, iter [01800, 05004], lr: 0.044485, loss: 1.6030
2022-07-07 13:28:46 - train: epoch 0110, iter [01900, 05004], lr: 0.044469, loss: 1.6793
2022-07-07 13:29:20 - train: epoch 0110, iter [02000, 05004], lr: 0.044453, loss: 1.5241
2022-07-07 13:29:54 - train: epoch 0110, iter [02100, 05004], lr: 0.044437, loss: 1.5980
2022-07-07 13:30:27 - train: epoch 0110, iter [02200, 05004], lr: 0.044421, loss: 1.4004
2022-07-07 13:31:01 - train: epoch 0110, iter [02300, 05004], lr: 0.044406, loss: 1.5230
2022-07-07 13:31:35 - train: epoch 0110, iter [02400, 05004], lr: 0.044390, loss: 1.4944
2022-07-07 13:32:09 - train: epoch 0110, iter [02500, 05004], lr: 0.044374, loss: 1.5183
2022-07-07 13:32:43 - train: epoch 0110, iter [02600, 05004], lr: 0.044358, loss: 1.7147
2022-07-07 13:33:18 - train: epoch 0110, iter [02700, 05004], lr: 0.044342, loss: 1.4597
2022-07-07 13:33:52 - train: epoch 0110, iter [02800, 05004], lr: 0.044326, loss: 1.5474
2022-07-07 13:34:25 - train: epoch 0110, iter [02900, 05004], lr: 0.044310, loss: 1.6860
2022-07-07 13:34:59 - train: epoch 0110, iter [03000, 05004], lr: 0.044294, loss: 1.4014
2022-07-07 13:35:34 - train: epoch 0110, iter [03100, 05004], lr: 0.044278, loss: 1.5861
2022-07-07 13:36:08 - train: epoch 0110, iter [03200, 05004], lr: 0.044262, loss: 1.6514
2022-07-07 13:36:41 - train: epoch 0110, iter [03300, 05004], lr: 0.044246, loss: 1.4973
2022-07-07 13:37:16 - train: epoch 0110, iter [03400, 05004], lr: 0.044230, loss: 1.4650
2022-07-07 13:37:49 - train: epoch 0110, iter [03500, 05004], lr: 0.044214, loss: 1.8972
2022-07-07 13:38:23 - train: epoch 0110, iter [03600, 05004], lr: 0.044198, loss: 1.7661
2022-07-07 13:38:57 - train: epoch 0110, iter [03700, 05004], lr: 0.044182, loss: 1.6564
2022-07-07 13:39:30 - train: epoch 0110, iter [03800, 05004], lr: 0.044166, loss: 1.6197
2022-07-07 13:40:03 - train: epoch 0110, iter [03900, 05004], lr: 0.044150, loss: 1.6912
2022-07-07 13:40:37 - train: epoch 0110, iter [04000, 05004], lr: 0.044134, loss: 1.4847
2022-07-07 13:41:10 - train: epoch 0110, iter [04100, 05004], lr: 0.044118, loss: 1.6020
2022-07-07 13:41:44 - train: epoch 0110, iter [04200, 05004], lr: 0.044102, loss: 1.5367
2022-07-07 13:42:18 - train: epoch 0110, iter [04300, 05004], lr: 0.044086, loss: 1.3667
2022-07-07 13:42:51 - train: epoch 0110, iter [04400, 05004], lr: 0.044070, loss: 1.7963
2022-07-07 13:43:25 - train: epoch 0110, iter [04500, 05004], lr: 0.044054, loss: 1.5159
2022-07-07 13:43:58 - train: epoch 0110, iter [04600, 05004], lr: 0.044038, loss: 1.2872
2022-07-07 13:44:32 - train: epoch 0110, iter [04700, 05004], lr: 0.044022, loss: 1.6170
2022-07-07 13:45:05 - train: epoch 0110, iter [04800, 05004], lr: 0.044006, loss: 1.7910
2022-07-07 13:45:39 - train: epoch 0110, iter [04900, 05004], lr: 0.043990, loss: 1.5612
2022-07-07 13:46:11 - train: epoch 0110, iter [05000, 05004], lr: 0.043974, loss: 1.5556
2022-07-07 13:46:12 - train: epoch 110, train_loss: 1.5237
2022-07-07 13:47:26 - eval: epoch: 110, acc1: 65.228%, acc5: 87.088%, test_loss: 1.4321, per_image_load_time: 2.072ms, per_image_inference_time: 0.488ms
2022-07-07 13:47:27 - until epoch: 110, best_acc1: 65.380%
2022-07-07 13:47:27 - epoch 111 lr: 0.043973
2022-07-07 13:48:05 - train: epoch 0111, iter [00100, 05004], lr: 0.043957, loss: 1.3394
2022-07-07 13:48:39 - train: epoch 0111, iter [00200, 05004], lr: 0.043941, loss: 1.4014
2022-07-07 13:49:12 - train: epoch 0111, iter [00300, 05004], lr: 0.043925, loss: 1.5890
2022-07-07 13:49:46 - train: epoch 0111, iter [00400, 05004], lr: 0.043909, loss: 1.5113
2022-07-07 13:50:19 - train: epoch 0111, iter [00500, 05004], lr: 0.043893, loss: 1.4557
2022-07-07 13:50:53 - train: epoch 0111, iter [00600, 05004], lr: 0.043877, loss: 1.6480
2022-07-07 13:51:26 - train: epoch 0111, iter [00700, 05004], lr: 0.043861, loss: 1.5212
2022-07-07 13:52:00 - train: epoch 0111, iter [00800, 05004], lr: 0.043845, loss: 1.5028
2022-07-07 13:52:34 - train: epoch 0111, iter [00900, 05004], lr: 0.043829, loss: 1.4559
2022-07-07 13:53:07 - train: epoch 0111, iter [01000, 05004], lr: 0.043813, loss: 1.3010
2022-07-07 13:53:40 - train: epoch 0111, iter [01100, 05004], lr: 0.043797, loss: 1.5075
2022-07-07 13:54:14 - train: epoch 0111, iter [01200, 05004], lr: 0.043781, loss: 1.4672
2022-07-07 13:54:47 - train: epoch 0111, iter [01300, 05004], lr: 0.043765, loss: 1.5018
2022-07-07 13:55:21 - train: epoch 0111, iter [01400, 05004], lr: 0.043750, loss: 1.3382
2022-07-07 13:55:54 - train: epoch 0111, iter [01500, 05004], lr: 0.043734, loss: 1.4545
2022-07-07 13:56:28 - train: epoch 0111, iter [01600, 05004], lr: 0.043718, loss: 1.2898
2022-07-07 13:57:02 - train: epoch 0111, iter [01700, 05004], lr: 0.043702, loss: 1.5108
2022-07-07 13:57:35 - train: epoch 0111, iter [01800, 05004], lr: 0.043686, loss: 1.2685
2022-07-07 13:58:09 - train: epoch 0111, iter [01900, 05004], lr: 0.043670, loss: 1.5163
2022-07-07 13:58:43 - train: epoch 0111, iter [02000, 05004], lr: 0.043654, loss: 1.5225
2022-07-07 13:59:16 - train: epoch 0111, iter [02100, 05004], lr: 0.043638, loss: 1.8611
2022-07-07 13:59:50 - train: epoch 0111, iter [02200, 05004], lr: 0.043622, loss: 1.5614
2022-07-07 14:00:24 - train: epoch 0111, iter [02300, 05004], lr: 0.043606, loss: 1.3886
2022-07-07 14:00:59 - train: epoch 0111, iter [02400, 05004], lr: 0.043590, loss: 1.4500
2022-07-07 14:01:32 - train: epoch 0111, iter [02500, 05004], lr: 0.043574, loss: 1.4795
2022-07-07 14:02:06 - train: epoch 0111, iter [02600, 05004], lr: 0.043558, loss: 1.3142
2022-07-07 14:02:40 - train: epoch 0111, iter [02700, 05004], lr: 0.043542, loss: 1.6958
2022-07-07 14:03:14 - train: epoch 0111, iter [02800, 05004], lr: 0.043526, loss: 1.4791
2022-07-07 14:03:48 - train: epoch 0111, iter [02900, 05004], lr: 0.043510, loss: 1.3548
2022-07-07 14:04:21 - train: epoch 0111, iter [03000, 05004], lr: 0.043494, loss: 1.5927
2022-07-07 14:04:55 - train: epoch 0111, iter [03100, 05004], lr: 0.043478, loss: 1.4818
2022-07-07 14:05:28 - train: epoch 0111, iter [03200, 05004], lr: 0.043462, loss: 1.7015
2022-07-07 14:06:02 - train: epoch 0111, iter [03300, 05004], lr: 0.043446, loss: 1.6733
2022-07-07 14:06:35 - train: epoch 0111, iter [03400, 05004], lr: 0.043430, loss: 1.7251
2022-07-07 14:07:09 - train: epoch 0111, iter [03500, 05004], lr: 0.043414, loss: 1.7429
2022-07-07 14:07:43 - train: epoch 0111, iter [03600, 05004], lr: 0.043398, loss: 1.3422
2022-07-07 14:08:17 - train: epoch 0111, iter [03700, 05004], lr: 0.043382, loss: 1.5270
2022-07-07 14:08:50 - train: epoch 0111, iter [03800, 05004], lr: 0.043366, loss: 1.4661
2022-07-07 14:09:24 - train: epoch 0111, iter [03900, 05004], lr: 0.043350, loss: 1.4249
2022-07-07 14:09:58 - train: epoch 0111, iter [04000, 05004], lr: 0.043334, loss: 1.7770
2022-07-07 14:10:32 - train: epoch 0111, iter [04100, 05004], lr: 0.043319, loss: 1.8279
2022-07-07 14:11:05 - train: epoch 0111, iter [04200, 05004], lr: 0.043303, loss: 1.4762
2022-07-07 14:11:40 - train: epoch 0111, iter [04300, 05004], lr: 0.043287, loss: 1.5374
2022-07-07 14:12:14 - train: epoch 0111, iter [04400, 05004], lr: 0.043271, loss: 1.3900
2022-07-07 14:12:48 - train: epoch 0111, iter [04500, 05004], lr: 0.043255, loss: 1.4763
2022-07-07 14:13:21 - train: epoch 0111, iter [04600, 05004], lr: 0.043239, loss: 1.5427
2022-07-07 14:13:55 - train: epoch 0111, iter [04700, 05004], lr: 0.043223, loss: 1.5630
2022-07-07 14:14:28 - train: epoch 0111, iter [04800, 05004], lr: 0.043207, loss: 1.5025
2022-07-07 14:15:02 - train: epoch 0111, iter [04900, 05004], lr: 0.043191, loss: 1.5411
2022-07-07 14:15:34 - train: epoch 0111, iter [05000, 05004], lr: 0.043175, loss: 1.6442
2022-07-07 14:15:35 - train: epoch 111, train_loss: 1.5172
2022-07-07 14:16:50 - eval: epoch: 111, acc1: 65.002%, acc5: 86.776%, test_loss: 1.4333, per_image_load_time: 0.736ms, per_image_inference_time: 0.455ms
2022-07-07 14:16:50 - until epoch: 111, best_acc1: 65.380%
2022-07-07 14:16:50 - epoch 112 lr: 0.043174
2022-07-07 14:17:29 - train: epoch 0112, iter [00100, 05004], lr: 0.043158, loss: 1.4376
2022-07-07 14:18:03 - train: epoch 0112, iter [00200, 05004], lr: 0.043142, loss: 1.4772
2022-07-07 14:18:36 - train: epoch 0112, iter [00300, 05004], lr: 0.043126, loss: 1.2932
2022-07-07 14:19:10 - train: epoch 0112, iter [00400, 05004], lr: 0.043111, loss: 1.4353
2022-07-07 14:19:43 - train: epoch 0112, iter [00500, 05004], lr: 0.043095, loss: 1.5774
2022-07-07 14:20:15 - train: epoch 0112, iter [00600, 05004], lr: 0.043079, loss: 1.5558
2022-07-07 14:20:48 - train: epoch 0112, iter [00700, 05004], lr: 0.043063, loss: 1.6718
2022-07-07 14:21:21 - train: epoch 0112, iter [00800, 05004], lr: 0.043047, loss: 1.3232
2022-07-07 14:21:55 - train: epoch 0112, iter [00900, 05004], lr: 0.043031, loss: 1.2874
2022-07-07 14:22:28 - train: epoch 0112, iter [01000, 05004], lr: 0.043015, loss: 1.4880
2022-07-07 14:23:01 - train: epoch 0112, iter [01100, 05004], lr: 0.042999, loss: 1.4128
2022-07-07 14:23:35 - train: epoch 0112, iter [01200, 05004], lr: 0.042983, loss: 1.6840
2022-07-07 14:24:08 - train: epoch 0112, iter [01300, 05004], lr: 0.042967, loss: 1.5826
2022-07-07 14:24:41 - train: epoch 0112, iter [01400, 05004], lr: 0.042951, loss: 1.5375
2022-07-07 14:25:13 - train: epoch 0112, iter [01500, 05004], lr: 0.042935, loss: 1.7028
2022-07-07 14:25:46 - train: epoch 0112, iter [01600, 05004], lr: 0.042919, loss: 1.5829
2022-07-07 14:26:19 - train: epoch 0112, iter [01700, 05004], lr: 0.042903, loss: 1.5041
2022-07-07 14:26:52 - train: epoch 0112, iter [01800, 05004], lr: 0.042887, loss: 1.2448
2022-07-07 14:27:25 - train: epoch 0112, iter [01900, 05004], lr: 0.042871, loss: 1.2278
2022-07-07 14:27:58 - train: epoch 0112, iter [02000, 05004], lr: 0.042856, loss: 1.4030
2022-07-07 14:28:32 - train: epoch 0112, iter [02100, 05004], lr: 0.042840, loss: 1.5755
2022-07-07 14:29:04 - train: epoch 0112, iter [02200, 05004], lr: 0.042824, loss: 1.4166
2022-07-07 14:29:37 - train: epoch 0112, iter [02300, 05004], lr: 0.042808, loss: 1.3886
2022-07-07 14:30:09 - train: epoch 0112, iter [02400, 05004], lr: 0.042792, loss: 1.2574
2022-07-07 14:30:43 - train: epoch 0112, iter [02500, 05004], lr: 0.042776, loss: 1.4646
2022-07-07 14:31:16 - train: epoch 0112, iter [02600, 05004], lr: 0.042760, loss: 1.3223
2022-07-07 14:31:49 - train: epoch 0112, iter [02700, 05004], lr: 0.042744, loss: 1.5955
2022-07-07 14:32:23 - train: epoch 0112, iter [02800, 05004], lr: 0.042728, loss: 1.5764
2022-07-07 14:32:55 - train: epoch 0112, iter [02900, 05004], lr: 0.042712, loss: 1.7108
2022-07-07 14:33:29 - train: epoch 0112, iter [03000, 05004], lr: 0.042696, loss: 1.5858
2022-07-07 14:34:02 - train: epoch 0112, iter [03100, 05004], lr: 0.042680, loss: 1.5164
2022-07-07 14:34:35 - train: epoch 0112, iter [03200, 05004], lr: 0.042664, loss: 1.3599
2022-07-07 14:35:08 - train: epoch 0112, iter [03300, 05004], lr: 0.042648, loss: 1.4695
2022-07-07 14:35:42 - train: epoch 0112, iter [03400, 05004], lr: 0.042633, loss: 1.4380
2022-07-07 14:36:14 - train: epoch 0112, iter [03500, 05004], lr: 0.042617, loss: 1.3253
2022-07-07 14:36:48 - train: epoch 0112, iter [03600, 05004], lr: 0.042601, loss: 1.6476
2022-07-07 14:37:21 - train: epoch 0112, iter [03700, 05004], lr: 0.042585, loss: 1.6005
2022-07-07 14:37:55 - train: epoch 0112, iter [03800, 05004], lr: 0.042569, loss: 1.5697
2022-07-07 14:38:27 - train: epoch 0112, iter [03900, 05004], lr: 0.042553, loss: 1.4174
2022-07-07 14:39:01 - train: epoch 0112, iter [04000, 05004], lr: 0.042537, loss: 1.4568
2022-07-07 14:39:34 - train: epoch 0112, iter [04100, 05004], lr: 0.042521, loss: 1.4059
2022-07-07 14:40:07 - train: epoch 0112, iter [04200, 05004], lr: 0.042505, loss: 1.3628
2022-07-07 14:40:40 - train: epoch 0112, iter [04300, 05004], lr: 0.042489, loss: 1.5246
2022-07-07 14:41:13 - train: epoch 0112, iter [04400, 05004], lr: 0.042473, loss: 1.7798
2022-07-07 14:41:47 - train: epoch 0112, iter [04500, 05004], lr: 0.042457, loss: 1.3966
2022-07-07 14:42:20 - train: epoch 0112, iter [04600, 05004], lr: 0.042442, loss: 1.6828
2022-07-07 14:42:53 - train: epoch 0112, iter [04700, 05004], lr: 0.042426, loss: 1.4541
2022-07-07 14:43:27 - train: epoch 0112, iter [04800, 05004], lr: 0.042410, loss: 1.4503
2022-07-07 14:44:00 - train: epoch 0112, iter [04900, 05004], lr: 0.042394, loss: 1.3885
2022-07-07 14:44:32 - train: epoch 0112, iter [05000, 05004], lr: 0.042378, loss: 1.4256
2022-07-07 14:44:33 - train: epoch 112, train_loss: 1.5103
2022-07-07 14:45:48 - eval: epoch: 112, acc1: 65.406%, acc5: 87.096%, test_loss: 1.4262, per_image_load_time: 1.660ms, per_image_inference_time: 0.456ms
2022-07-07 14:45:48 - until epoch: 112, best_acc1: 65.406%
2022-07-07 14:45:48 - epoch 113 lr: 0.042377
2022-07-07 14:46:27 - train: epoch 0113, iter [00100, 05004], lr: 0.042361, loss: 1.6653
2022-07-07 14:47:01 - train: epoch 0113, iter [00200, 05004], lr: 0.042345, loss: 1.3623
2022-07-07 14:47:34 - train: epoch 0113, iter [00300, 05004], lr: 0.042330, loss: 1.3615
2022-07-07 14:48:08 - train: epoch 0113, iter [00400, 05004], lr: 0.042314, loss: 1.5104
2022-07-07 14:48:41 - train: epoch 0113, iter [00500, 05004], lr: 0.042298, loss: 1.6083
2022-07-07 14:49:15 - train: epoch 0113, iter [00600, 05004], lr: 0.042282, loss: 1.6476
2022-07-07 14:49:48 - train: epoch 0113, iter [00700, 05004], lr: 0.042266, loss: 1.4336
2022-07-07 14:50:21 - train: epoch 0113, iter [00800, 05004], lr: 0.042250, loss: 1.5420
2022-07-07 14:50:55 - train: epoch 0113, iter [00900, 05004], lr: 0.042234, loss: 1.3632
2022-07-07 14:51:28 - train: epoch 0113, iter [01000, 05004], lr: 0.042218, loss: 1.5713
2022-07-07 14:52:02 - train: epoch 0113, iter [01100, 05004], lr: 0.042202, loss: 1.5077
2022-07-07 14:52:37 - train: epoch 0113, iter [01200, 05004], lr: 0.042186, loss: 1.5587
2022-07-07 14:53:10 - train: epoch 0113, iter [01300, 05004], lr: 0.042170, loss: 1.3323
2022-07-07 14:53:43 - train: epoch 0113, iter [01400, 05004], lr: 0.042155, loss: 1.5148
2022-07-07 14:54:17 - train: epoch 0113, iter [01500, 05004], lr: 0.042139, loss: 1.5180
2022-07-07 14:54:51 - train: epoch 0113, iter [01600, 05004], lr: 0.042123, loss: 1.4869
2022-07-07 14:55:24 - train: epoch 0113, iter [01700, 05004], lr: 0.042107, loss: 1.3850
2022-07-07 14:55:58 - train: epoch 0113, iter [01800, 05004], lr: 0.042091, loss: 1.3040
2022-07-07 14:56:32 - train: epoch 0113, iter [01900, 05004], lr: 0.042075, loss: 1.4099
2022-07-07 14:57:05 - train: epoch 0113, iter [02000, 05004], lr: 0.042059, loss: 1.5830
2022-07-07 14:57:39 - train: epoch 0113, iter [02100, 05004], lr: 0.042043, loss: 1.7453
2022-07-07 14:58:13 - train: epoch 0113, iter [02200, 05004], lr: 0.042027, loss: 1.6607
2022-07-07 14:58:47 - train: epoch 0113, iter [02300, 05004], lr: 0.042012, loss: 1.4731
2022-07-07 14:59:21 - train: epoch 0113, iter [02400, 05004], lr: 0.041996, loss: 1.6124
2022-07-07 14:59:54 - train: epoch 0113, iter [02500, 05004], lr: 0.041980, loss: 1.5547
2022-07-07 15:00:28 - train: epoch 0113, iter [02600, 05004], lr: 0.041964, loss: 1.2087
2022-07-07 15:01:01 - train: epoch 0113, iter [02700, 05004], lr: 0.041948, loss: 1.4314
2022-07-07 15:01:35 - train: epoch 0113, iter [02800, 05004], lr: 0.041932, loss: 1.6306
2022-07-07 15:02:08 - train: epoch 0113, iter [02900, 05004], lr: 0.041916, loss: 1.5673
2022-07-07 15:02:42 - train: epoch 0113, iter [03000, 05004], lr: 0.041900, loss: 1.4703
2022-07-07 15:03:16 - train: epoch 0113, iter [03100, 05004], lr: 0.041884, loss: 1.2287
2022-07-07 15:03:50 - train: epoch 0113, iter [03200, 05004], lr: 0.041869, loss: 1.3601
2022-07-07 15:04:24 - train: epoch 0113, iter [03300, 05004], lr: 0.041853, loss: 1.5044
2022-07-07 15:04:56 - train: epoch 0113, iter [03400, 05004], lr: 0.041837, loss: 1.3564
2022-07-07 15:05:31 - train: epoch 0113, iter [03500, 05004], lr: 0.041821, loss: 1.5101
2022-07-07 15:06:04 - train: epoch 0113, iter [03600, 05004], lr: 0.041805, loss: 1.7719
2022-07-07 15:06:38 - train: epoch 0113, iter [03700, 05004], lr: 0.041789, loss: 1.2870
2022-07-07 15:07:11 - train: epoch 0113, iter [03800, 05004], lr: 0.041773, loss: 1.5911
2022-07-07 15:07:45 - train: epoch 0113, iter [03900, 05004], lr: 0.041757, loss: 1.6797
2022-07-07 15:08:19 - train: epoch 0113, iter [04000, 05004], lr: 0.041742, loss: 1.4362
2022-07-07 15:08:52 - train: epoch 0113, iter [04100, 05004], lr: 0.041726, loss: 1.6136
2022-07-07 15:09:26 - train: epoch 0113, iter [04200, 05004], lr: 0.041710, loss: 1.5212
2022-07-07 15:10:00 - train: epoch 0113, iter [04300, 05004], lr: 0.041694, loss: 1.3536
2022-07-07 15:10:34 - train: epoch 0113, iter [04400, 05004], lr: 0.041678, loss: 1.4931
2022-07-07 15:11:07 - train: epoch 0113, iter [04500, 05004], lr: 0.041662, loss: 1.4101
2022-07-07 15:11:41 - train: epoch 0113, iter [04600, 05004], lr: 0.041646, loss: 1.7351
2022-07-07 15:12:14 - train: epoch 0113, iter [04700, 05004], lr: 0.041630, loss: 1.4361
2022-07-07 15:12:49 - train: epoch 0113, iter [04800, 05004], lr: 0.041615, loss: 1.7202
2022-07-07 15:13:22 - train: epoch 0113, iter [04900, 05004], lr: 0.041599, loss: 1.3408
2022-07-07 15:13:55 - train: epoch 0113, iter [05000, 05004], lr: 0.041583, loss: 1.6656
2022-07-07 15:13:56 - train: epoch 113, train_loss: 1.5013
2022-07-07 15:15:10 - eval: epoch: 113, acc1: 66.598%, acc5: 87.862%, test_loss: 1.3642, per_image_load_time: 2.156ms, per_image_inference_time: 0.465ms
2022-07-07 15:15:11 - until epoch: 113, best_acc1: 66.598%
2022-07-07 15:15:11 - epoch 114 lr: 0.041582
2022-07-07 15:15:50 - train: epoch 0114, iter [00100, 05004], lr: 0.041566, loss: 1.4789
2022-07-07 15:16:24 - train: epoch 0114, iter [00200, 05004], lr: 0.041550, loss: 1.4424
2022-07-07 15:16:58 - train: epoch 0114, iter [00300, 05004], lr: 0.041535, loss: 1.4520
2022-07-07 15:17:31 - train: epoch 0114, iter [00400, 05004], lr: 0.041519, loss: 1.6125
2022-07-07 15:18:04 - train: epoch 0114, iter [00500, 05004], lr: 0.041503, loss: 1.3948
2022-07-07 15:18:38 - train: epoch 0114, iter [00600, 05004], lr: 0.041487, loss: 1.5991
2022-07-07 15:19:11 - train: epoch 0114, iter [00700, 05004], lr: 0.041471, loss: 1.4850
2022-07-07 15:19:45 - train: epoch 0114, iter [00800, 05004], lr: 0.041455, loss: 1.3880
2022-07-07 15:20:18 - train: epoch 0114, iter [00900, 05004], lr: 0.041439, loss: 1.3522
2022-07-07 15:20:51 - train: epoch 0114, iter [01000, 05004], lr: 0.041424, loss: 1.6211
2022-07-07 15:21:26 - train: epoch 0114, iter [01100, 05004], lr: 0.041408, loss: 1.3652
2022-07-07 15:21:59 - train: epoch 0114, iter [01200, 05004], lr: 0.041392, loss: 1.4412
2022-07-07 15:22:32 - train: epoch 0114, iter [01300, 05004], lr: 0.041376, loss: 1.3335
2022-07-07 15:23:06 - train: epoch 0114, iter [01400, 05004], lr: 0.041360, loss: 1.5648
2022-07-07 15:23:40 - train: epoch 0114, iter [01500, 05004], lr: 0.041344, loss: 1.4294
2022-07-07 15:24:13 - train: epoch 0114, iter [01600, 05004], lr: 0.041328, loss: 1.4347
2022-07-07 15:24:46 - train: epoch 0114, iter [01700, 05004], lr: 0.041313, loss: 1.2309
2022-07-07 15:25:21 - train: epoch 0114, iter [01800, 05004], lr: 0.041297, loss: 1.5368
2022-07-07 15:25:55 - train: epoch 0114, iter [01900, 05004], lr: 0.041281, loss: 1.2987
2022-07-07 15:26:28 - train: epoch 0114, iter [02000, 05004], lr: 0.041265, loss: 1.7274
2022-07-07 15:27:02 - train: epoch 0114, iter [02100, 05004], lr: 0.041249, loss: 1.4351
2022-07-07 15:27:36 - train: epoch 0114, iter [02200, 05004], lr: 0.041233, loss: 1.4667
2022-07-07 15:28:09 - train: epoch 0114, iter [02300, 05004], lr: 0.041217, loss: 1.6000
2022-07-07 15:28:43 - train: epoch 0114, iter [02400, 05004], lr: 0.041202, loss: 1.5533
2022-07-07 15:29:16 - train: epoch 0114, iter [02500, 05004], lr: 0.041186, loss: 1.3642
2022-07-07 15:29:50 - train: epoch 0114, iter [02600, 05004], lr: 0.041170, loss: 1.4213
2022-07-07 15:30:24 - train: epoch 0114, iter [02700, 05004], lr: 0.041154, loss: 1.4507
2022-07-07 15:30:58 - train: epoch 0114, iter [02800, 05004], lr: 0.041138, loss: 1.6351
2022-07-07 15:31:32 - train: epoch 0114, iter [02900, 05004], lr: 0.041122, loss: 1.4046
2022-07-07 15:32:06 - train: epoch 0114, iter [03000, 05004], lr: 0.041107, loss: 1.3353
2022-07-07 15:32:39 - train: epoch 0114, iter [03100, 05004], lr: 0.041091, loss: 1.7088
2022-07-07 15:33:14 - train: epoch 0114, iter [03200, 05004], lr: 0.041075, loss: 1.4977
2022-07-07 15:33:48 - train: epoch 0114, iter [03300, 05004], lr: 0.041059, loss: 1.7065
2022-07-07 15:34:22 - train: epoch 0114, iter [03400, 05004], lr: 0.041043, loss: 1.4682
2022-07-07 15:34:56 - train: epoch 0114, iter [03500, 05004], lr: 0.041027, loss: 1.3143
2022-07-07 15:35:29 - train: epoch 0114, iter [03600, 05004], lr: 0.041011, loss: 1.6234
2022-07-07 15:36:03 - train: epoch 0114, iter [03700, 05004], lr: 0.040996, loss: 1.4662
2022-07-07 15:36:37 - train: epoch 0114, iter [03800, 05004], lr: 0.040980, loss: 1.4987
2022-07-07 15:37:09 - train: epoch 0114, iter [03900, 05004], lr: 0.040964, loss: 1.5538
2022-07-07 15:37:42 - train: epoch 0114, iter [04000, 05004], lr: 0.040948, loss: 1.4066
2022-07-07 15:38:14 - train: epoch 0114, iter [04100, 05004], lr: 0.040932, loss: 1.3470
2022-07-07 15:38:47 - train: epoch 0114, iter [04200, 05004], lr: 0.040916, loss: 1.5743
2022-07-07 15:39:21 - train: epoch 0114, iter [04300, 05004], lr: 0.040901, loss: 1.4873
2022-07-07 15:39:55 - train: epoch 0114, iter [04400, 05004], lr: 0.040885, loss: 1.5769
2022-07-07 15:40:29 - train: epoch 0114, iter [04500, 05004], lr: 0.040869, loss: 1.6666
2022-07-07 15:41:03 - train: epoch 0114, iter [04600, 05004], lr: 0.040853, loss: 1.5144
2022-07-07 15:41:37 - train: epoch 0114, iter [04700, 05004], lr: 0.040837, loss: 1.4989
2022-07-07 15:42:11 - train: epoch 0114, iter [04800, 05004], lr: 0.040822, loss: 1.6873
2022-07-07 15:42:44 - train: epoch 0114, iter [04900, 05004], lr: 0.040806, loss: 1.4386
2022-07-07 15:43:16 - train: epoch 0114, iter [05000, 05004], lr: 0.040790, loss: 1.6309
2022-07-07 15:43:17 - train: epoch 114, train_loss: 1.4935
2022-07-07 15:44:32 - eval: epoch: 114, acc1: 62.962%, acc5: 85.096%, test_loss: 1.5503, per_image_load_time: 1.831ms, per_image_inference_time: 0.446ms
2022-07-07 15:44:33 - until epoch: 114, best_acc1: 66.598%
2022-07-07 15:44:33 - epoch 115 lr: 0.040789
2022-07-07 15:45:12 - train: epoch 0115, iter [00100, 05004], lr: 0.040773, loss: 1.4050
2022-07-07 15:45:45 - train: epoch 0115, iter [00200, 05004], lr: 0.040758, loss: 1.4341
2022-07-07 15:46:19 - train: epoch 0115, iter [00300, 05004], lr: 0.040742, loss: 1.4893
2022-07-07 15:46:52 - train: epoch 0115, iter [00400, 05004], lr: 0.040726, loss: 1.2196
2022-07-07 15:47:26 - train: epoch 0115, iter [00500, 05004], lr: 0.040710, loss: 1.3236
2022-07-07 15:48:00 - train: epoch 0115, iter [00600, 05004], lr: 0.040694, loss: 1.4695
2022-07-07 15:48:33 - train: epoch 0115, iter [00700, 05004], lr: 0.040679, loss: 1.4959
2022-07-07 15:49:07 - train: epoch 0115, iter [00800, 05004], lr: 0.040663, loss: 1.2235
2022-07-07 15:49:40 - train: epoch 0115, iter [00900, 05004], lr: 0.040647, loss: 1.5488
2022-07-07 15:50:14 - train: epoch 0115, iter [01000, 05004], lr: 0.040631, loss: 1.3227
2022-07-07 15:50:48 - train: epoch 0115, iter [01100, 05004], lr: 0.040615, loss: 1.2758
2022-07-07 15:51:22 - train: epoch 0115, iter [01200, 05004], lr: 0.040599, loss: 1.4849
2022-07-07 15:51:56 - train: epoch 0115, iter [01300, 05004], lr: 0.040584, loss: 1.3938
2022-07-07 15:52:30 - train: epoch 0115, iter [01400, 05004], lr: 0.040568, loss: 1.4568
2022-07-07 15:53:04 - train: epoch 0115, iter [01500, 05004], lr: 0.040552, loss: 1.6984
2022-07-07 15:53:37 - train: epoch 0115, iter [01600, 05004], lr: 0.040536, loss: 1.4458
2022-07-07 15:54:11 - train: epoch 0115, iter [01700, 05004], lr: 0.040520, loss: 1.4202
2022-07-07 15:54:45 - train: epoch 0115, iter [01800, 05004], lr: 0.040505, loss: 1.4578
2022-07-07 15:55:19 - train: epoch 0115, iter [01900, 05004], lr: 0.040489, loss: 1.4432
2022-07-07 15:55:53 - train: epoch 0115, iter [02000, 05004], lr: 0.040473, loss: 1.7119
2022-07-07 15:56:27 - train: epoch 0115, iter [02100, 05004], lr: 0.040457, loss: 1.3798
2022-07-07 15:57:01 - train: epoch 0115, iter [02200, 05004], lr: 0.040441, loss: 1.5502
2022-07-07 15:57:35 - train: epoch 0115, iter [02300, 05004], lr: 0.040426, loss: 1.6521
2022-07-07 15:58:09 - train: epoch 0115, iter [02400, 05004], lr: 0.040410, loss: 1.5982
2022-07-07 15:58:43 - train: epoch 0115, iter [02500, 05004], lr: 0.040394, loss: 1.4200
2022-07-07 15:59:16 - train: epoch 0115, iter [02600, 05004], lr: 0.040378, loss: 1.4299
2022-07-07 15:59:50 - train: epoch 0115, iter [02700, 05004], lr: 0.040362, loss: 1.2524
2022-07-07 16:00:23 - train: epoch 0115, iter [02800, 05004], lr: 0.040347, loss: 1.5435
2022-07-07 16:00:56 - train: epoch 0115, iter [02900, 05004], lr: 0.040331, loss: 1.3960
2022-07-07 16:01:31 - train: epoch 0115, iter [03000, 05004], lr: 0.040315, loss: 1.3211
2022-07-07 16:02:05 - train: epoch 0115, iter [03100, 05004], lr: 0.040299, loss: 1.6040
2022-07-07 16:02:38 - train: epoch 0115, iter [03200, 05004], lr: 0.040283, loss: 1.4941
2022-07-07 16:03:11 - train: epoch 0115, iter [03300, 05004], lr: 0.040268, loss: 1.4994
2022-07-07 16:03:45 - train: epoch 0115, iter [03400, 05004], lr: 0.040252, loss: 1.5315
2022-07-07 16:04:19 - train: epoch 0115, iter [03500, 05004], lr: 0.040236, loss: 1.3740
2022-07-07 16:04:53 - train: epoch 0115, iter [03600, 05004], lr: 0.040220, loss: 1.3956
2022-07-07 16:05:27 - train: epoch 0115, iter [03700, 05004], lr: 0.040204, loss: 1.3730
2022-07-07 16:06:00 - train: epoch 0115, iter [03800, 05004], lr: 0.040189, loss: 1.5074
2022-07-07 16:06:34 - train: epoch 0115, iter [03900, 05004], lr: 0.040173, loss: 1.3940
2022-07-07 16:07:08 - train: epoch 0115, iter [04000, 05004], lr: 0.040157, loss: 1.5221
2022-07-07 16:07:41 - train: epoch 0115, iter [04100, 05004], lr: 0.040141, loss: 1.4719
2022-07-07 16:08:15 - train: epoch 0115, iter [04200, 05004], lr: 0.040126, loss: 1.1986
2022-07-07 16:08:49 - train: epoch 0115, iter [04300, 05004], lr: 0.040110, loss: 1.4664
2022-07-07 16:09:23 - train: epoch 0115, iter [04400, 05004], lr: 0.040094, loss: 1.4940
2022-07-07 16:09:57 - train: epoch 0115, iter [04500, 05004], lr: 0.040078, loss: 1.5187
2022-07-07 16:10:30 - train: epoch 0115, iter [04600, 05004], lr: 0.040062, loss: 1.5972
2022-07-07 16:11:04 - train: epoch 0115, iter [04700, 05004], lr: 0.040047, loss: 1.4934
2022-07-07 16:11:38 - train: epoch 0115, iter [04800, 05004], lr: 0.040031, loss: 1.3135
2022-07-07 16:12:12 - train: epoch 0115, iter [04900, 05004], lr: 0.040015, loss: 1.6172
2022-07-07 16:12:45 - train: epoch 0115, iter [05000, 05004], lr: 0.039999, loss: 1.5362
2022-07-07 16:12:46 - train: epoch 115, train_loss: 1.4864
2022-07-07 16:14:01 - eval: epoch: 115, acc1: 66.126%, acc5: 87.418%, test_loss: 1.3870, per_image_load_time: 2.195ms, per_image_inference_time: 0.463ms
2022-07-07 16:14:01 - until epoch: 115, best_acc1: 66.598%
2022-07-07 16:14:01 - epoch 116 lr: 0.039999
2022-07-07 16:14:40 - train: epoch 0116, iter [00100, 05004], lr: 0.039983, loss: 1.3318
2022-07-07 16:15:14 - train: epoch 0116, iter [00200, 05004], lr: 0.039967, loss: 1.6166
2022-07-07 16:15:48 - train: epoch 0116, iter [00300, 05004], lr: 0.039951, loss: 1.3201
2022-07-07 16:16:20 - train: epoch 0116, iter [00400, 05004], lr: 0.039936, loss: 1.5577
2022-07-07 16:16:53 - train: epoch 0116, iter [00500, 05004], lr: 0.039920, loss: 1.6468
2022-07-07 16:17:26 - train: epoch 0116, iter [00600, 05004], lr: 0.039904, loss: 1.4127
2022-07-07 16:18:00 - train: epoch 0116, iter [00700, 05004], lr: 0.039888, loss: 1.6163
2022-07-07 16:18:33 - train: epoch 0116, iter [00800, 05004], lr: 0.039873, loss: 1.6270
2022-07-07 16:19:06 - train: epoch 0116, iter [00900, 05004], lr: 0.039857, loss: 1.6241
2022-07-07 16:19:39 - train: epoch 0116, iter [01000, 05004], lr: 0.039841, loss: 1.6094
2022-07-07 16:20:12 - train: epoch 0116, iter [01100, 05004], lr: 0.039825, loss: 1.3497
2022-07-07 16:20:45 - train: epoch 0116, iter [01200, 05004], lr: 0.039810, loss: 1.4295
2022-07-07 16:21:18 - train: epoch 0116, iter [01300, 05004], lr: 0.039794, loss: 1.6722
2022-07-07 16:21:52 - train: epoch 0116, iter [01400, 05004], lr: 0.039778, loss: 1.5519
2022-07-07 16:22:26 - train: epoch 0116, iter [01500, 05004], lr: 0.039762, loss: 1.3124
2022-07-07 16:22:59 - train: epoch 0116, iter [01600, 05004], lr: 0.039746, loss: 1.5152
2022-07-07 16:23:33 - train: epoch 0116, iter [01700, 05004], lr: 0.039731, loss: 1.4991
2022-07-07 16:24:07 - train: epoch 0116, iter [01800, 05004], lr: 0.039715, loss: 1.6915
2022-07-07 16:24:40 - train: epoch 0116, iter [01900, 05004], lr: 0.039699, loss: 1.3618
2022-07-07 16:25:14 - train: epoch 0116, iter [02000, 05004], lr: 0.039683, loss: 1.4083
2022-07-07 16:25:48 - train: epoch 0116, iter [02100, 05004], lr: 0.039668, loss: 1.5921
2022-07-07 16:26:22 - train: epoch 0116, iter [02200, 05004], lr: 0.039652, loss: 1.5185
2022-07-07 16:26:55 - train: epoch 0116, iter [02300, 05004], lr: 0.039636, loss: 1.6164
2022-07-07 16:27:29 - train: epoch 0116, iter [02400, 05004], lr: 0.039620, loss: 1.5071
2022-07-07 16:28:02 - train: epoch 0116, iter [02500, 05004], lr: 0.039605, loss: 1.2543
2022-07-07 16:28:36 - train: epoch 0116, iter [02600, 05004], lr: 0.039589, loss: 1.4158
2022-07-07 16:29:09 - train: epoch 0116, iter [02700, 05004], lr: 0.039573, loss: 1.5645
2022-07-07 16:29:43 - train: epoch 0116, iter [02800, 05004], lr: 0.039557, loss: 1.6797
2022-07-07 16:30:17 - train: epoch 0116, iter [02900, 05004], lr: 0.039542, loss: 1.7092
2022-07-07 16:30:51 - train: epoch 0116, iter [03000, 05004], lr: 0.039526, loss: 1.5202
2022-07-07 16:31:24 - train: epoch 0116, iter [03100, 05004], lr: 0.039510, loss: 1.6369
2022-07-07 16:31:58 - train: epoch 0116, iter [03200, 05004], lr: 0.039495, loss: 1.5994
2022-07-07 16:32:33 - train: epoch 0116, iter [03300, 05004], lr: 0.039479, loss: 1.6548
2022-07-07 16:33:05 - train: epoch 0116, iter [03400, 05004], lr: 0.039463, loss: 1.7014
2022-07-07 16:33:39 - train: epoch 0116, iter [03500, 05004], lr: 0.039447, loss: 1.6985
2022-07-07 16:34:12 - train: epoch 0116, iter [03600, 05004], lr: 0.039432, loss: 1.5941
2022-07-07 16:34:46 - train: epoch 0116, iter [03700, 05004], lr: 0.039416, loss: 1.4740
2022-07-07 16:35:20 - train: epoch 0116, iter [03800, 05004], lr: 0.039400, loss: 1.3120
2022-07-07 16:35:54 - train: epoch 0116, iter [03900, 05004], lr: 0.039384, loss: 1.5546
2022-07-07 16:36:28 - train: epoch 0116, iter [04000, 05004], lr: 0.039369, loss: 1.4587
2022-07-07 16:37:01 - train: epoch 0116, iter [04100, 05004], lr: 0.039353, loss: 1.6632
2022-07-07 16:37:35 - train: epoch 0116, iter [04200, 05004], lr: 0.039337, loss: 1.5210
2022-07-07 16:38:09 - train: epoch 0116, iter [04300, 05004], lr: 0.039321, loss: 1.5219
2022-07-07 16:38:42 - train: epoch 0116, iter [04400, 05004], lr: 0.039306, loss: 1.4028
2022-07-07 16:39:16 - train: epoch 0116, iter [04500, 05004], lr: 0.039290, loss: 1.4622
2022-07-07 16:39:49 - train: epoch 0116, iter [04600, 05004], lr: 0.039274, loss: 1.6754
2022-07-07 16:40:23 - train: epoch 0116, iter [04700, 05004], lr: 0.039259, loss: 1.5729
2022-07-07 16:40:58 - train: epoch 0116, iter [04800, 05004], lr: 0.039243, loss: 1.4107
2022-07-07 16:41:31 - train: epoch 0116, iter [04900, 05004], lr: 0.039227, loss: 1.3255
2022-07-07 16:42:03 - train: epoch 0116, iter [05000, 05004], lr: 0.039211, loss: 1.4201
2022-07-07 16:42:04 - train: epoch 116, train_loss: 1.4777
2022-07-07 16:43:19 - eval: epoch: 116, acc1: 66.482%, acc5: 87.740%, test_loss: 1.3681, per_image_load_time: 1.429ms, per_image_inference_time: 0.472ms
2022-07-07 16:43:19 - until epoch: 116, best_acc1: 66.598%
2022-07-07 16:43:19 - epoch 117 lr: 0.039211
2022-07-07 16:43:58 - train: epoch 0117, iter [00100, 05004], lr: 0.039195, loss: 1.6654
2022-07-07 16:44:32 - train: epoch 0117, iter [00200, 05004], lr: 0.039179, loss: 1.4203
2022-07-07 16:45:05 - train: epoch 0117, iter [00300, 05004], lr: 0.039164, loss: 1.5712
2022-07-07 16:45:38 - train: epoch 0117, iter [00400, 05004], lr: 0.039148, loss: 1.2185
2022-07-07 16:46:12 - train: epoch 0117, iter [00500, 05004], lr: 0.039132, loss: 1.3588
2022-07-07 16:46:45 - train: epoch 0117, iter [00600, 05004], lr: 0.039116, loss: 1.4366
2022-07-07 16:47:19 - train: epoch 0117, iter [00700, 05004], lr: 0.039101, loss: 1.4032
2022-07-07 16:47:52 - train: epoch 0117, iter [00800, 05004], lr: 0.039085, loss: 1.3192
2022-07-07 16:48:26 - train: epoch 0117, iter [00900, 05004], lr: 0.039069, loss: 1.1729
2022-07-07 16:48:59 - train: epoch 0117, iter [01000, 05004], lr: 0.039054, loss: 1.3971
2022-07-07 16:49:33 - train: epoch 0117, iter [01100, 05004], lr: 0.039038, loss: 1.3713
2022-07-07 16:50:07 - train: epoch 0117, iter [01200, 05004], lr: 0.039022, loss: 1.5265
2022-07-07 16:50:40 - train: epoch 0117, iter [01300, 05004], lr: 0.039007, loss: 1.4176
2022-07-07 16:51:13 - train: epoch 0117, iter [01400, 05004], lr: 0.038991, loss: 1.6927
2022-07-07 16:51:46 - train: epoch 0117, iter [01500, 05004], lr: 0.038975, loss: 1.5507
2022-07-07 16:52:19 - train: epoch 0117, iter [01600, 05004], lr: 0.038959, loss: 1.2431
2022-07-07 16:52:53 - train: epoch 0117, iter [01700, 05004], lr: 0.038944, loss: 1.4644
2022-07-07 16:53:26 - train: epoch 0117, iter [01800, 05004], lr: 0.038928, loss: 1.4055
2022-07-07 16:54:00 - train: epoch 0117, iter [01900, 05004], lr: 0.038912, loss: 1.3443
2022-07-07 16:54:32 - train: epoch 0117, iter [02000, 05004], lr: 0.038897, loss: 1.4639
2022-07-07 16:55:06 - train: epoch 0117, iter [02100, 05004], lr: 0.038881, loss: 1.3885
2022-07-07 16:55:40 - train: epoch 0117, iter [02200, 05004], lr: 0.038865, loss: 1.2703
2022-07-07 16:56:14 - train: epoch 0117, iter [02300, 05004], lr: 0.038850, loss: 1.4844
2022-07-07 16:56:47 - train: epoch 0117, iter [02400, 05004], lr: 0.038834, loss: 1.2746
2022-07-07 16:57:20 - train: epoch 0117, iter [02500, 05004], lr: 0.038818, loss: 1.5801
2022-07-07 16:57:55 - train: epoch 0117, iter [02600, 05004], lr: 0.038802, loss: 1.4022
2022-07-07 16:58:30 - train: epoch 0117, iter [02700, 05004], lr: 0.038787, loss: 1.3295
2022-07-07 16:59:03 - train: epoch 0117, iter [02800, 05004], lr: 0.038771, loss: 1.2485
2022-07-07 16:59:36 - train: epoch 0117, iter [02900, 05004], lr: 0.038755, loss: 1.4852
2022-07-07 17:00:10 - train: epoch 0117, iter [03000, 05004], lr: 0.038740, loss: 1.2832
2022-07-07 17:00:43 - train: epoch 0117, iter [03100, 05004], lr: 0.038724, loss: 1.4907
2022-07-07 17:01:17 - train: epoch 0117, iter [03200, 05004], lr: 0.038708, loss: 1.5547
2022-07-07 17:01:51 - train: epoch 0117, iter [03300, 05004], lr: 0.038693, loss: 1.5155
2022-07-07 17:02:24 - train: epoch 0117, iter [03400, 05004], lr: 0.038677, loss: 1.3239
2022-07-07 17:02:58 - train: epoch 0117, iter [03500, 05004], lr: 0.038661, loss: 1.6276
2022-07-07 17:03:31 - train: epoch 0117, iter [03600, 05004], lr: 0.038646, loss: 1.7768
2022-07-07 17:04:04 - train: epoch 0117, iter [03700, 05004], lr: 0.038630, loss: 1.4744
2022-07-07 17:04:38 - train: epoch 0117, iter [03800, 05004], lr: 0.038614, loss: 1.5541
2022-07-07 17:05:12 - train: epoch 0117, iter [03900, 05004], lr: 0.038599, loss: 1.3324
2022-07-07 17:05:45 - train: epoch 0117, iter [04000, 05004], lr: 0.038583, loss: 1.4283
2022-07-07 17:06:20 - train: epoch 0117, iter [04100, 05004], lr: 0.038567, loss: 1.5619
2022-07-07 17:06:53 - train: epoch 0117, iter [04200, 05004], lr: 0.038552, loss: 1.5900
2022-07-07 17:07:28 - train: epoch 0117, iter [04300, 05004], lr: 0.038536, loss: 1.3404
2022-07-07 17:08:01 - train: epoch 0117, iter [04400, 05004], lr: 0.038520, loss: 1.2841
2022-07-07 17:08:35 - train: epoch 0117, iter [04500, 05004], lr: 0.038505, loss: 1.5343
2022-07-07 17:09:08 - train: epoch 0117, iter [04600, 05004], lr: 0.038489, loss: 1.4969
2022-07-07 17:09:42 - train: epoch 0117, iter [04700, 05004], lr: 0.038473, loss: 1.6051
2022-07-07 17:10:15 - train: epoch 0117, iter [04800, 05004], lr: 0.038458, loss: 1.4921
2022-07-07 17:10:49 - train: epoch 0117, iter [04900, 05004], lr: 0.038442, loss: 1.6441
2022-07-07 17:11:22 - train: epoch 0117, iter [05000, 05004], lr: 0.038426, loss: 1.7095
2022-07-07 17:11:23 - train: epoch 117, train_loss: 1.4691
2022-07-07 17:12:38 - eval: epoch: 117, acc1: 66.282%, acc5: 87.622%, test_loss: 1.3827, per_image_load_time: 1.601ms, per_image_inference_time: 0.487ms
2022-07-07 17:12:38 - until epoch: 117, best_acc1: 66.598%
2022-07-07 17:12:38 - epoch 118 lr: 0.038426
2022-07-07 17:13:17 - train: epoch 0118, iter [00100, 05004], lr: 0.038410, loss: 1.3441
2022-07-07 17:13:51 - train: epoch 0118, iter [00200, 05004], lr: 0.038394, loss: 1.3138
2022-07-07 17:14:24 - train: epoch 0118, iter [00300, 05004], lr: 0.038379, loss: 1.5634
2022-07-07 17:14:58 - train: epoch 0118, iter [00400, 05004], lr: 0.038363, loss: 1.5368
2022-07-07 17:15:32 - train: epoch 0118, iter [00500, 05004], lr: 0.038347, loss: 1.3335
2022-07-07 17:16:05 - train: epoch 0118, iter [00600, 05004], lr: 0.038332, loss: 1.3571
2022-07-07 17:16:39 - train: epoch 0118, iter [00700, 05004], lr: 0.038316, loss: 1.4647
2022-07-07 17:17:12 - train: epoch 0118, iter [00800, 05004], lr: 0.038300, loss: 1.4592
2022-07-07 17:17:46 - train: epoch 0118, iter [00900, 05004], lr: 0.038285, loss: 1.4375
2022-07-07 17:18:19 - train: epoch 0118, iter [01000, 05004], lr: 0.038269, loss: 1.6337
2022-07-07 17:18:53 - train: epoch 0118, iter [01100, 05004], lr: 0.038253, loss: 1.5433
2022-07-07 17:19:25 - train: epoch 0118, iter [01200, 05004], lr: 0.038238, loss: 1.7328
2022-07-07 17:20:00 - train: epoch 0118, iter [01300, 05004], lr: 0.038222, loss: 1.5403
2022-07-07 17:20:33 - train: epoch 0118, iter [01400, 05004], lr: 0.038207, loss: 1.3583
2022-07-07 17:21:08 - train: epoch 0118, iter [01500, 05004], lr: 0.038191, loss: 1.4513
2022-07-07 17:21:40 - train: epoch 0118, iter [01600, 05004], lr: 0.038175, loss: 1.4050
2022-07-07 17:22:14 - train: epoch 0118, iter [01700, 05004], lr: 0.038160, loss: 1.5092
2022-07-07 17:22:48 - train: epoch 0118, iter [01800, 05004], lr: 0.038144, loss: 1.3671
2022-07-07 17:23:22 - train: epoch 0118, iter [01900, 05004], lr: 0.038128, loss: 1.6839
2022-07-07 17:23:56 - train: epoch 0118, iter [02000, 05004], lr: 0.038113, loss: 1.2780
2022-07-07 17:24:29 - train: epoch 0118, iter [02100, 05004], lr: 0.038097, loss: 1.3599
2022-07-07 17:25:02 - train: epoch 0118, iter [02200, 05004], lr: 0.038081, loss: 1.3133
2022-07-07 17:25:36 - train: epoch 0118, iter [02300, 05004], lr: 0.038066, loss: 1.3128
2022-07-07 17:26:10 - train: epoch 0118, iter [02400, 05004], lr: 0.038050, loss: 1.6199
2022-07-07 17:26:43 - train: epoch 0118, iter [02500, 05004], lr: 0.038035, loss: 1.6102
2022-07-07 17:27:17 - train: epoch 0118, iter [02600, 05004], lr: 0.038019, loss: 1.4032
2022-07-07 17:27:49 - train: epoch 0118, iter [02700, 05004], lr: 0.038003, loss: 1.5486
2022-07-07 17:28:23 - train: epoch 0118, iter [02800, 05004], lr: 0.037988, loss: 1.4256
2022-07-07 17:28:57 - train: epoch 0118, iter [02900, 05004], lr: 0.037972, loss: 1.5192
2022-07-07 17:29:31 - train: epoch 0118, iter [03000, 05004], lr: 0.037956, loss: 1.4132
2022-07-07 17:30:04 - train: epoch 0118, iter [03100, 05004], lr: 0.037941, loss: 1.6709
2022-07-07 17:30:37 - train: epoch 0118, iter [03200, 05004], lr: 0.037925, loss: 1.5348
2022-07-07 17:31:11 - train: epoch 0118, iter [03300, 05004], lr: 0.037910, loss: 1.4983
2022-07-07 17:31:45 - train: epoch 0118, iter [03400, 05004], lr: 0.037894, loss: 1.4722
2022-07-07 17:32:18 - train: epoch 0118, iter [03500, 05004], lr: 0.037878, loss: 1.4725
2022-07-07 17:32:52 - train: epoch 0118, iter [03600, 05004], lr: 0.037863, loss: 1.4895
2022-07-07 17:33:26 - train: epoch 0118, iter [03700, 05004], lr: 0.037847, loss: 1.4554
2022-07-07 17:34:00 - train: epoch 0118, iter [03800, 05004], lr: 0.037831, loss: 1.5369
2022-07-07 17:34:34 - train: epoch 0118, iter [03900, 05004], lr: 0.037816, loss: 1.5407
2022-07-07 17:35:07 - train: epoch 0118, iter [04000, 05004], lr: 0.037800, loss: 1.5211
2022-07-07 17:35:40 - train: epoch 0118, iter [04100, 05004], lr: 0.037785, loss: 1.5197
2022-07-07 17:36:13 - train: epoch 0118, iter [04200, 05004], lr: 0.037769, loss: 1.4717
2022-07-07 17:36:47 - train: epoch 0118, iter [04300, 05004], lr: 0.037753, loss: 1.2045
2022-07-07 17:37:20 - train: epoch 0118, iter [04400, 05004], lr: 0.037738, loss: 1.5088
2022-07-07 17:37:54 - train: epoch 0118, iter [04500, 05004], lr: 0.037722, loss: 1.4190
2022-07-07 17:38:27 - train: epoch 0118, iter [04600, 05004], lr: 0.037707, loss: 1.6054
2022-07-07 17:39:00 - train: epoch 0118, iter [04700, 05004], lr: 0.037691, loss: 1.3806
2022-07-07 17:39:35 - train: epoch 0118, iter [04800, 05004], lr: 0.037675, loss: 1.3269
2022-07-07 17:40:08 - train: epoch 0118, iter [04900, 05004], lr: 0.037660, loss: 1.4452
2022-07-07 17:40:40 - train: epoch 0118, iter [05000, 05004], lr: 0.037644, loss: 1.4363
2022-07-07 17:40:41 - train: epoch 118, train_loss: 1.4615
2022-07-07 17:41:55 - eval: epoch: 118, acc1: 67.014%, acc5: 88.176%, test_loss: 1.3466, per_image_load_time: 2.103ms, per_image_inference_time: 0.469ms
2022-07-07 17:41:55 - until epoch: 118, best_acc1: 67.014%
2022-07-07 17:41:55 - epoch 119 lr: 0.037643
2022-07-07 17:42:35 - train: epoch 0119, iter [00100, 05004], lr: 0.037628, loss: 1.5885
2022-07-07 17:43:07 - train: epoch 0119, iter [00200, 05004], lr: 0.037612, loss: 1.4245
2022-07-07 17:43:41 - train: epoch 0119, iter [00300, 05004], lr: 0.037597, loss: 1.4917
2022-07-07 17:44:14 - train: epoch 0119, iter [00400, 05004], lr: 0.037581, loss: 1.2088
2022-07-07 17:44:48 - train: epoch 0119, iter [00500, 05004], lr: 0.037566, loss: 1.3047
2022-07-07 17:45:22 - train: epoch 0119, iter [00600, 05004], lr: 0.037550, loss: 1.4444
2022-07-07 17:45:55 - train: epoch 0119, iter [00700, 05004], lr: 0.037534, loss: 1.4725
2022-07-07 17:46:27 - train: epoch 0119, iter [00800, 05004], lr: 0.037519, loss: 1.4405
2022-07-07 17:47:01 - train: epoch 0119, iter [00900, 05004], lr: 0.037503, loss: 1.5992
2022-07-07 17:47:34 - train: epoch 0119, iter [01000, 05004], lr: 0.037488, loss: 1.3028
2022-07-07 17:48:08 - train: epoch 0119, iter [01100, 05004], lr: 0.037472, loss: 1.5559
2022-07-07 17:48:40 - train: epoch 0119, iter [01200, 05004], lr: 0.037456, loss: 1.5054
2022-07-07 17:49:14 - train: epoch 0119, iter [01300, 05004], lr: 0.037441, loss: 1.4313
2022-07-07 17:49:48 - train: epoch 0119, iter [01400, 05004], lr: 0.037425, loss: 1.4318
2022-07-07 17:50:21 - train: epoch 0119, iter [01500, 05004], lr: 0.037410, loss: 1.3782
2022-07-07 17:50:55 - train: epoch 0119, iter [01600, 05004], lr: 0.037394, loss: 1.5367
2022-07-07 17:51:29 - train: epoch 0119, iter [01700, 05004], lr: 0.037379, loss: 1.4340
2022-07-07 17:52:02 - train: epoch 0119, iter [01800, 05004], lr: 0.037363, loss: 1.5218
2022-07-07 17:52:35 - train: epoch 0119, iter [01900, 05004], lr: 0.037347, loss: 1.4685
2022-07-07 17:53:09 - train: epoch 0119, iter [02000, 05004], lr: 0.037332, loss: 1.1857
2022-07-07 17:53:43 - train: epoch 0119, iter [02100, 05004], lr: 0.037316, loss: 1.5243
2022-07-07 17:54:16 - train: epoch 0119, iter [02200, 05004], lr: 0.037301, loss: 1.5223
2022-07-07 17:54:49 - train: epoch 0119, iter [02300, 05004], lr: 0.037285, loss: 1.2475
2022-07-07 17:55:22 - train: epoch 0119, iter [02400, 05004], lr: 0.037270, loss: 1.4026
2022-07-07 17:55:55 - train: epoch 0119, iter [02500, 05004], lr: 0.037254, loss: 1.6836
2022-07-07 17:56:29 - train: epoch 0119, iter [02600, 05004], lr: 0.037238, loss: 1.4399
2022-07-07 17:57:03 - train: epoch 0119, iter [02700, 05004], lr: 0.037223, loss: 1.4996
2022-07-07 17:57:36 - train: epoch 0119, iter [02800, 05004], lr: 0.037207, loss: 1.6761
2022-07-07 17:58:09 - train: epoch 0119, iter [02900, 05004], lr: 0.037192, loss: 1.4237
2022-07-07 17:58:42 - train: epoch 0119, iter [03000, 05004], lr: 0.037176, loss: 1.1157
2022-07-07 17:59:16 - train: epoch 0119, iter [03100, 05004], lr: 0.037161, loss: 1.3899
2022-07-07 17:59:50 - train: epoch 0119, iter [03200, 05004], lr: 0.037145, loss: 1.2860
2022-07-07 18:00:24 - train: epoch 0119, iter [03300, 05004], lr: 0.037129, loss: 1.3674
2022-07-07 18:00:58 - train: epoch 0119, iter [03400, 05004], lr: 0.037114, loss: 1.5462
2022-07-07 18:01:30 - train: epoch 0119, iter [03500, 05004], lr: 0.037098, loss: 1.3883
2022-07-07 18:02:04 - train: epoch 0119, iter [03600, 05004], lr: 0.037083, loss: 1.6263
2022-07-07 18:02:37 - train: epoch 0119, iter [03700, 05004], lr: 0.037067, loss: 1.6237
2022-07-07 18:03:11 - train: epoch 0119, iter [03800, 05004], lr: 0.037052, loss: 1.4000
2022-07-07 18:03:44 - train: epoch 0119, iter [03900, 05004], lr: 0.037036, loss: 1.8566
2022-07-07 18:04:18 - train: epoch 0119, iter [04000, 05004], lr: 0.037021, loss: 1.3763
2022-07-07 18:04:52 - train: epoch 0119, iter [04100, 05004], lr: 0.037005, loss: 1.7335
2022-07-07 18:05:26 - train: epoch 0119, iter [04200, 05004], lr: 0.036990, loss: 1.5073
2022-07-07 18:06:00 - train: epoch 0119, iter [04300, 05004], lr: 0.036974, loss: 1.3363
2022-07-07 18:06:33 - train: epoch 0119, iter [04400, 05004], lr: 0.036958, loss: 1.5241
2022-07-07 18:07:07 - train: epoch 0119, iter [04500, 05004], lr: 0.036943, loss: 1.5140
2022-07-07 18:07:41 - train: epoch 0119, iter [04600, 05004], lr: 0.036927, loss: 1.4742
2022-07-07 18:08:14 - train: epoch 0119, iter [04700, 05004], lr: 0.036912, loss: 1.3689
2022-07-07 18:08:49 - train: epoch 0119, iter [04800, 05004], lr: 0.036896, loss: 1.3747
2022-07-07 18:09:22 - train: epoch 0119, iter [04900, 05004], lr: 0.036881, loss: 1.7194
2022-07-07 18:09:54 - train: epoch 0119, iter [05000, 05004], lr: 0.036865, loss: 1.6255
2022-07-07 18:09:55 - train: epoch 119, train_loss: 1.4516
2022-07-07 18:11:10 - eval: epoch: 119, acc1: 65.012%, acc5: 86.740%, test_loss: 1.4400, per_image_load_time: 0.842ms, per_image_inference_time: 0.462ms
2022-07-07 18:11:11 - until epoch: 119, best_acc1: 67.014%
2022-07-07 18:11:11 - epoch 120 lr: 0.036864
2022-07-07 18:11:50 - train: epoch 0120, iter [00100, 05004], lr: 0.036849, loss: 1.3820
2022-07-07 18:12:23 - train: epoch 0120, iter [00200, 05004], lr: 0.036834, loss: 1.4225
2022-07-07 18:12:57 - train: epoch 0120, iter [00300, 05004], lr: 0.036818, loss: 1.4843
2022-07-07 18:13:30 - train: epoch 0120, iter [00400, 05004], lr: 0.036803, loss: 1.4663
2022-07-07 18:14:04 - train: epoch 0120, iter [00500, 05004], lr: 0.036787, loss: 1.2334
2022-07-07 18:14:37 - train: epoch 0120, iter [00600, 05004], lr: 0.036771, loss: 1.2847
2022-07-07 18:15:11 - train: epoch 0120, iter [00700, 05004], lr: 0.036756, loss: 1.4814
2022-07-07 18:15:45 - train: epoch 0120, iter [00800, 05004], lr: 0.036740, loss: 1.3614
2022-07-07 18:16:18 - train: epoch 0120, iter [00900, 05004], lr: 0.036725, loss: 1.3478
2022-07-07 18:16:51 - train: epoch 0120, iter [01000, 05004], lr: 0.036709, loss: 1.4073
2022-07-07 18:17:24 - train: epoch 0120, iter [01100, 05004], lr: 0.036694, loss: 1.4255
2022-07-07 18:17:58 - train: epoch 0120, iter [01200, 05004], lr: 0.036678, loss: 1.5506
2022-07-07 18:18:31 - train: epoch 0120, iter [01300, 05004], lr: 0.036663, loss: 1.3244
2022-07-07 18:19:04 - train: epoch 0120, iter [01400, 05004], lr: 0.036647, loss: 1.4559
2022-07-07 18:19:37 - train: epoch 0120, iter [01500, 05004], lr: 0.036632, loss: 1.4045
2022-07-07 18:20:11 - train: epoch 0120, iter [01600, 05004], lr: 0.036616, loss: 1.3701
2022-07-07 18:20:44 - train: epoch 0120, iter [01700, 05004], lr: 0.036601, loss: 1.4460
2022-07-07 18:21:18 - train: epoch 0120, iter [01800, 05004], lr: 0.036585, loss: 1.4898
2022-07-07 18:21:51 - train: epoch 0120, iter [01900, 05004], lr: 0.036570, loss: 1.6361
2022-07-07 18:22:25 - train: epoch 0120, iter [02000, 05004], lr: 0.036554, loss: 1.4570
2022-07-07 18:22:58 - train: epoch 0120, iter [02100, 05004], lr: 0.036539, loss: 1.5325
2022-07-07 18:23:31 - train: epoch 0120, iter [02200, 05004], lr: 0.036523, loss: 1.4056
2022-07-07 18:24:04 - train: epoch 0120, iter [02300, 05004], lr: 0.036508, loss: 1.3809
2022-07-07 18:24:39 - train: epoch 0120, iter [02400, 05004], lr: 0.036492, loss: 1.4578
2022-07-07 18:25:12 - train: epoch 0120, iter [02500, 05004], lr: 0.036477, loss: 1.6067
2022-07-07 18:25:46 - train: epoch 0120, iter [02600, 05004], lr: 0.036461, loss: 1.5681
2022-07-07 18:26:19 - train: epoch 0120, iter [02700, 05004], lr: 0.036446, loss: 1.6675
2022-07-07 18:26:53 - train: epoch 0120, iter [02800, 05004], lr: 0.036430, loss: 1.3625
2022-07-07 18:27:26 - train: epoch 0120, iter [02900, 05004], lr: 0.036415, loss: 1.1668
2022-07-07 18:27:59 - train: epoch 0120, iter [03000, 05004], lr: 0.036399, loss: 1.3513
2022-07-07 18:28:32 - train: epoch 0120, iter [03100, 05004], lr: 0.036384, loss: 1.3093
2022-07-07 18:29:07 - train: epoch 0120, iter [03200, 05004], lr: 0.036368, loss: 1.4641
2022-07-07 18:29:39 - train: epoch 0120, iter [03300, 05004], lr: 0.036353, loss: 1.3037
2022-07-07 18:30:14 - train: epoch 0120, iter [03400, 05004], lr: 0.036337, loss: 1.3778
2022-07-07 18:30:47 - train: epoch 0120, iter [03500, 05004], lr: 0.036322, loss: 1.4499
2022-07-07 18:31:22 - train: epoch 0120, iter [03600, 05004], lr: 0.036306, loss: 1.4397
2022-07-07 18:31:55 - train: epoch 0120, iter [03700, 05004], lr: 0.036291, loss: 1.2915
2022-07-07 18:32:29 - train: epoch 0120, iter [03800, 05004], lr: 0.036275, loss: 1.4585
2022-07-07 18:33:01 - train: epoch 0120, iter [03900, 05004], lr: 0.036260, loss: 1.3981
2022-07-07 18:33:35 - train: epoch 0120, iter [04000, 05004], lr: 0.036244, loss: 1.4433
2022-07-07 18:34:09 - train: epoch 0120, iter [04100, 05004], lr: 0.036229, loss: 1.6101
2022-07-07 18:34:42 - train: epoch 0120, iter [04200, 05004], lr: 0.036213, loss: 1.5994
2022-07-07 18:35:16 - train: epoch 0120, iter [04300, 05004], lr: 0.036198, loss: 1.5970
2022-07-07 18:35:50 - train: epoch 0120, iter [04400, 05004], lr: 0.036183, loss: 1.4364
2022-07-07 18:36:23 - train: epoch 0120, iter [04500, 05004], lr: 0.036167, loss: 1.5932
2022-07-07 18:36:57 - train: epoch 0120, iter [04600, 05004], lr: 0.036152, loss: 1.4064
2022-07-07 18:37:31 - train: epoch 0120, iter [04700, 05004], lr: 0.036136, loss: 1.5541
2022-07-07 18:38:04 - train: epoch 0120, iter [04800, 05004], lr: 0.036121, loss: 1.6447
2022-07-07 18:38:38 - train: epoch 0120, iter [04900, 05004], lr: 0.036105, loss: 1.5637
2022-07-07 18:39:10 - train: epoch 0120, iter [05000, 05004], lr: 0.036090, loss: 1.3726
2022-07-07 18:39:11 - train: epoch 120, train_loss: 1.4462
2022-07-07 18:40:26 - eval: epoch: 120, acc1: 64.854%, acc5: 86.632%, test_loss: 1.4467, per_image_load_time: 1.684ms, per_image_inference_time: 0.458ms
2022-07-07 18:40:26 - until epoch: 120, best_acc1: 67.014%
2022-07-07 18:40:26 - epoch 121 lr: 0.036089
2022-07-07 18:41:05 - train: epoch 0121, iter [00100, 05004], lr: 0.036074, loss: 1.5720
2022-07-07 18:41:39 - train: epoch 0121, iter [00200, 05004], lr: 0.036058, loss: 1.3671
2022-07-07 18:42:13 - train: epoch 0121, iter [00300, 05004], lr: 0.036043, loss: 1.4836
2022-07-07 18:42:47 - train: epoch 0121, iter [00400, 05004], lr: 0.036027, loss: 1.2442
2022-07-07 18:43:20 - train: epoch 0121, iter [00500, 05004], lr: 0.036012, loss: 1.5880
2022-07-07 18:43:53 - train: epoch 0121, iter [00600, 05004], lr: 0.035996, loss: 1.5909
2022-07-07 18:44:27 - train: epoch 0121, iter [00700, 05004], lr: 0.035981, loss: 1.2093
2022-07-07 18:45:00 - train: epoch 0121, iter [00800, 05004], lr: 0.035965, loss: 1.5997
2022-07-07 18:45:33 - train: epoch 0121, iter [00900, 05004], lr: 0.035950, loss: 1.3695
2022-07-07 18:46:08 - train: epoch 0121, iter [01000, 05004], lr: 0.035935, loss: 1.3929
2022-07-07 18:46:41 - train: epoch 0121, iter [01100, 05004], lr: 0.035919, loss: 1.1359
2022-07-07 18:47:15 - train: epoch 0121, iter [01200, 05004], lr: 0.035904, loss: 1.4163
2022-07-07 18:47:48 - train: epoch 0121, iter [01300, 05004], lr: 0.035888, loss: 1.4362
2022-07-07 18:48:21 - train: epoch 0121, iter [01400, 05004], lr: 0.035873, loss: 1.4635
2022-07-07 18:48:55 - train: epoch 0121, iter [01500, 05004], lr: 0.035857, loss: 1.3617
2022-07-07 18:49:28 - train: epoch 0121, iter [01600, 05004], lr: 0.035842, loss: 1.4309
2022-07-07 18:50:01 - train: epoch 0121, iter [01700, 05004], lr: 0.035826, loss: 1.3875
2022-07-07 18:50:35 - train: epoch 0121, iter [01800, 05004], lr: 0.035811, loss: 1.6092
2022-07-07 18:51:09 - train: epoch 0121, iter [01900, 05004], lr: 0.035796, loss: 1.4432
2022-07-07 18:51:43 - train: epoch 0121, iter [02000, 05004], lr: 0.035780, loss: 1.4451
2022-07-07 18:52:16 - train: epoch 0121, iter [02100, 05004], lr: 0.035765, loss: 1.5667
2022-07-07 18:52:50 - train: epoch 0121, iter [02200, 05004], lr: 0.035749, loss: 1.2188
2022-07-07 18:53:24 - train: epoch 0121, iter [02300, 05004], lr: 0.035734, loss: 1.2981
2022-07-07 18:53:58 - train: epoch 0121, iter [02400, 05004], lr: 0.035718, loss: 1.2314
2022-07-07 18:54:31 - train: epoch 0121, iter [02500, 05004], lr: 0.035703, loss: 1.2706
2022-07-07 18:55:05 - train: epoch 0121, iter [02600, 05004], lr: 0.035688, loss: 1.4669
2022-07-07 18:55:38 - train: epoch 0121, iter [02700, 05004], lr: 0.035672, loss: 1.5284
2022-07-07 18:56:12 - train: epoch 0121, iter [02800, 05004], lr: 0.035657, loss: 1.7968
2022-07-07 18:56:45 - train: epoch 0121, iter [02900, 05004], lr: 0.035641, loss: 1.5007
2022-07-07 18:57:19 - train: epoch 0121, iter [03000, 05004], lr: 0.035626, loss: 1.4076
2022-07-07 18:57:53 - train: epoch 0121, iter [03100, 05004], lr: 0.035610, loss: 1.2876
2022-07-07 18:58:26 - train: epoch 0121, iter [03200, 05004], lr: 0.035595, loss: 1.1874
2022-07-07 18:59:00 - train: epoch 0121, iter [03300, 05004], lr: 0.035580, loss: 1.6290
2022-07-07 18:59:34 - train: epoch 0121, iter [03400, 05004], lr: 0.035564, loss: 1.5201
2022-07-07 19:00:08 - train: epoch 0121, iter [03500, 05004], lr: 0.035549, loss: 1.3046
2022-07-07 19:00:41 - train: epoch 0121, iter [03600, 05004], lr: 0.035533, loss: 1.4025
2022-07-07 19:01:16 - train: epoch 0121, iter [03700, 05004], lr: 0.035518, loss: 1.4364
2022-07-07 19:01:49 - train: epoch 0121, iter [03800, 05004], lr: 0.035503, loss: 1.3890
2022-07-07 19:02:24 - train: epoch 0121, iter [03900, 05004], lr: 0.035487, loss: 1.3428
2022-07-07 19:02:58 - train: epoch 0121, iter [04000, 05004], lr: 0.035472, loss: 1.4274
2022-07-07 19:03:31 - train: epoch 0121, iter [04100, 05004], lr: 0.035456, loss: 1.3751
2022-07-07 19:04:05 - train: epoch 0121, iter [04200, 05004], lr: 0.035441, loss: 1.4021
2022-07-07 19:04:39 - train: epoch 0121, iter [04300, 05004], lr: 0.035426, loss: 1.3414
2022-07-07 19:05:13 - train: epoch 0121, iter [04400, 05004], lr: 0.035410, loss: 1.6720
2022-07-07 19:05:47 - train: epoch 0121, iter [04500, 05004], lr: 0.035395, loss: 1.4948
2022-07-07 19:06:21 - train: epoch 0121, iter [04600, 05004], lr: 0.035379, loss: 1.3344
2022-07-07 19:06:55 - train: epoch 0121, iter [04700, 05004], lr: 0.035364, loss: 1.5365
2022-07-07 19:07:29 - train: epoch 0121, iter [04800, 05004], lr: 0.035349, loss: 1.5160
2022-07-07 19:08:02 - train: epoch 0121, iter [04900, 05004], lr: 0.035333, loss: 1.2598
2022-07-07 19:08:35 - train: epoch 0121, iter [05000, 05004], lr: 0.035318, loss: 1.5429
2022-07-07 19:08:36 - train: epoch 121, train_loss: 1.4369
2022-07-07 19:09:51 - eval: epoch: 121, acc1: 66.520%, acc5: 87.812%, test_loss: 1.3627, per_image_load_time: 1.903ms, per_image_inference_time: 0.485ms
2022-07-07 19:09:51 - until epoch: 121, best_acc1: 67.014%
2022-07-07 19:09:51 - epoch 122 lr: 0.035317
2022-07-07 19:10:30 - train: epoch 0122, iter [00100, 05004], lr: 0.035302, loss: 1.4514
2022-07-07 19:11:04 - train: epoch 0122, iter [00200, 05004], lr: 0.035286, loss: 1.1335
2022-07-07 19:11:37 - train: epoch 0122, iter [00300, 05004], lr: 0.035271, loss: 1.2431
2022-07-07 19:12:10 - train: epoch 0122, iter [00400, 05004], lr: 0.035256, loss: 1.3798
2022-07-07 19:12:44 - train: epoch 0122, iter [00500, 05004], lr: 0.035240, loss: 1.3630
2022-07-07 19:13:18 - train: epoch 0122, iter [00600, 05004], lr: 0.035225, loss: 1.5440
2022-07-07 19:13:52 - train: epoch 0122, iter [00700, 05004], lr: 0.035210, loss: 1.2238
2022-07-07 19:14:25 - train: epoch 0122, iter [00800, 05004], lr: 0.035194, loss: 1.6448
2022-07-07 19:14:59 - train: epoch 0122, iter [00900, 05004], lr: 0.035179, loss: 1.4015
2022-07-07 19:15:32 - train: epoch 0122, iter [01000, 05004], lr: 0.035163, loss: 1.4212
2022-07-07 19:16:07 - train: epoch 0122, iter [01100, 05004], lr: 0.035148, loss: 1.3004
2022-07-07 19:16:40 - train: epoch 0122, iter [01200, 05004], lr: 0.035133, loss: 1.4575
2022-07-07 19:17:15 - train: epoch 0122, iter [01300, 05004], lr: 0.035117, loss: 1.2748
2022-07-07 19:17:49 - train: epoch 0122, iter [01400, 05004], lr: 0.035102, loss: 1.3433
2022-07-07 19:18:22 - train: epoch 0122, iter [01500, 05004], lr: 0.035087, loss: 1.5800
2022-07-07 19:18:56 - train: epoch 0122, iter [01600, 05004], lr: 0.035071, loss: 1.3149
2022-07-07 19:19:29 - train: epoch 0122, iter [01700, 05004], lr: 0.035056, loss: 1.4717
2022-07-07 19:20:03 - train: epoch 0122, iter [01800, 05004], lr: 0.035040, loss: 1.3176
2022-07-07 19:20:37 - train: epoch 0122, iter [01900, 05004], lr: 0.035025, loss: 1.4502
2022-07-07 19:21:11 - train: epoch 0122, iter [02000, 05004], lr: 0.035010, loss: 1.4774
2022-07-07 19:21:45 - train: epoch 0122, iter [02100, 05004], lr: 0.034994, loss: 1.4795
2022-07-07 19:22:19 - train: epoch 0122, iter [02200, 05004], lr: 0.034979, loss: 1.6897
2022-07-07 19:22:54 - train: epoch 0122, iter [02300, 05004], lr: 0.034964, loss: 1.5567
2022-07-07 19:23:26 - train: epoch 0122, iter [02400, 05004], lr: 0.034948, loss: 1.4841
2022-07-07 19:24:01 - train: epoch 0122, iter [02500, 05004], lr: 0.034933, loss: 1.4181
2022-07-07 19:24:35 - train: epoch 0122, iter [02600, 05004], lr: 0.034918, loss: 1.2632
2022-07-07 19:25:09 - train: epoch 0122, iter [02700, 05004], lr: 0.034902, loss: 1.4439
2022-07-07 19:25:43 - train: epoch 0122, iter [02800, 05004], lr: 0.034887, loss: 1.4400
2022-07-07 19:26:16 - train: epoch 0122, iter [02900, 05004], lr: 0.034872, loss: 1.3851
2022-07-07 19:26:50 - train: epoch 0122, iter [03000, 05004], lr: 0.034856, loss: 1.5590
2022-07-07 19:27:24 - train: epoch 0122, iter [03100, 05004], lr: 0.034841, loss: 1.3740
2022-07-07 19:27:58 - train: epoch 0122, iter [03200, 05004], lr: 0.034826, loss: 1.4852
2022-07-07 19:28:32 - train: epoch 0122, iter [03300, 05004], lr: 0.034810, loss: 1.1990
2022-07-07 19:29:06 - train: epoch 0122, iter [03400, 05004], lr: 0.034795, loss: 1.5305
2022-07-07 19:29:40 - train: epoch 0122, iter [03500, 05004], lr: 0.034780, loss: 1.5415
2022-07-07 19:30:14 - train: epoch 0122, iter [03600, 05004], lr: 0.034764, loss: 1.5294
2022-07-07 19:30:48 - train: epoch 0122, iter [03700, 05004], lr: 0.034749, loss: 1.4379
2022-07-07 19:31:22 - train: epoch 0122, iter [03800, 05004], lr: 0.034734, loss: 1.3247
2022-07-07 19:31:55 - train: epoch 0122, iter [03900, 05004], lr: 0.034718, loss: 1.4287
2022-07-07 19:32:30 - train: epoch 0122, iter [04000, 05004], lr: 0.034703, loss: 1.5138
2022-07-07 19:33:04 - train: epoch 0122, iter [04100, 05004], lr: 0.034688, loss: 1.2396
2022-07-07 19:33:37 - train: epoch 0122, iter [04200, 05004], lr: 0.034672, loss: 1.2840
2022-07-07 19:34:11 - train: epoch 0122, iter [04300, 05004], lr: 0.034657, loss: 1.3785
2022-07-07 19:34:44 - train: epoch 0122, iter [04400, 05004], lr: 0.034642, loss: 1.5902
2022-07-07 19:35:18 - train: epoch 0122, iter [04500, 05004], lr: 0.034626, loss: 1.3558
2022-07-07 19:35:51 - train: epoch 0122, iter [04600, 05004], lr: 0.034611, loss: 1.3613
2022-07-07 19:36:25 - train: epoch 0122, iter [04700, 05004], lr: 0.034596, loss: 1.4643
2022-07-07 19:37:00 - train: epoch 0122, iter [04800, 05004], lr: 0.034580, loss: 1.2523
2022-07-07 19:37:34 - train: epoch 0122, iter [04900, 05004], lr: 0.034565, loss: 1.3503
2022-07-07 19:38:06 - train: epoch 0122, iter [05000, 05004], lr: 0.034550, loss: 1.4466
2022-07-07 19:38:07 - train: epoch 122, train_loss: 1.4295
2022-07-07 19:39:21 - eval: epoch: 122, acc1: 64.760%, acc5: 86.480%, test_loss: 1.4598, per_image_load_time: 1.183ms, per_image_inference_time: 0.477ms
2022-07-07 19:39:21 - until epoch: 122, best_acc1: 67.014%
2022-07-07 19:39:21 - epoch 123 lr: 0.034549
2022-07-07 19:40:00 - train: epoch 0123, iter [00100, 05004], lr: 0.034534, loss: 1.3560
2022-07-07 19:40:34 - train: epoch 0123, iter [00200, 05004], lr: 0.034519, loss: 1.2834
2022-07-07 19:41:08 - train: epoch 0123, iter [00300, 05004], lr: 0.034503, loss: 1.2887
2022-07-07 19:41:41 - train: epoch 0123, iter [00400, 05004], lr: 0.034488, loss: 1.3670
2022-07-07 19:42:14 - train: epoch 0123, iter [00500, 05004], lr: 0.034473, loss: 1.2501
2022-07-07 19:42:48 - train: epoch 0123, iter [00600, 05004], lr: 0.034457, loss: 1.2891
2022-07-07 19:43:22 - train: epoch 0123, iter [00700, 05004], lr: 0.034442, loss: 1.3540
2022-07-07 19:43:56 - train: epoch 0123, iter [00800, 05004], lr: 0.034427, loss: 1.2833
2022-07-07 19:44:29 - train: epoch 0123, iter [00900, 05004], lr: 0.034411, loss: 1.2939
2022-07-07 19:45:03 - train: epoch 0123, iter [01000, 05004], lr: 0.034396, loss: 1.5429
2022-07-07 19:45:36 - train: epoch 0123, iter [01100, 05004], lr: 0.034381, loss: 1.2845
2022-07-07 19:46:10 - train: epoch 0123, iter [01200, 05004], lr: 0.034366, loss: 1.4036
2022-07-07 19:46:44 - train: epoch 0123, iter [01300, 05004], lr: 0.034350, loss: 1.2930
2022-07-07 19:47:17 - train: epoch 0123, iter [01400, 05004], lr: 0.034335, loss: 1.3917
2022-07-07 19:47:51 - train: epoch 0123, iter [01500, 05004], lr: 0.034320, loss: 1.3857
2022-07-07 19:48:24 - train: epoch 0123, iter [01600, 05004], lr: 0.034304, loss: 1.4708
2022-07-07 19:48:57 - train: epoch 0123, iter [01700, 05004], lr: 0.034289, loss: 1.4506
2022-07-07 19:49:31 - train: epoch 0123, iter [01800, 05004], lr: 0.034274, loss: 1.3914
2022-07-07 19:50:04 - train: epoch 0123, iter [01900, 05004], lr: 0.034259, loss: 1.4753
2022-07-07 19:50:38 - train: epoch 0123, iter [02000, 05004], lr: 0.034243, loss: 1.4078
2022-07-07 19:51:10 - train: epoch 0123, iter [02100, 05004], lr: 0.034228, loss: 1.6645
2022-07-07 19:51:45 - train: epoch 0123, iter [02200, 05004], lr: 0.034213, loss: 1.5273
2022-07-07 19:52:17 - train: epoch 0123, iter [02300, 05004], lr: 0.034197, loss: 1.5014
2022-07-07 19:52:51 - train: epoch 0123, iter [02400, 05004], lr: 0.034182, loss: 1.3787
2022-07-07 19:53:24 - train: epoch 0123, iter [02500, 05004], lr: 0.034167, loss: 1.4002
2022-07-07 19:53:58 - train: epoch 0123, iter [02600, 05004], lr: 0.034152, loss: 1.5646
2022-07-07 19:54:32 - train: epoch 0123, iter [02700, 05004], lr: 0.034136, loss: 1.5539
2022-07-07 19:55:05 - train: epoch 0123, iter [02800, 05004], lr: 0.034121, loss: 1.4686
2022-07-07 19:55:39 - train: epoch 0123, iter [02900, 05004], lr: 0.034106, loss: 1.5133
2022-07-07 19:56:11 - train: epoch 0123, iter [03000, 05004], lr: 0.034091, loss: 1.2578
2022-07-07 19:56:45 - train: epoch 0123, iter [03100, 05004], lr: 0.034075, loss: 1.4505
2022-07-07 19:57:19 - train: epoch 0123, iter [03200, 05004], lr: 0.034060, loss: 1.4354
2022-07-07 19:57:53 - train: epoch 0123, iter [03300, 05004], lr: 0.034045, loss: 1.3128
2022-07-07 19:58:26 - train: epoch 0123, iter [03400, 05004], lr: 0.034030, loss: 1.4945
2022-07-07 19:59:00 - train: epoch 0123, iter [03500, 05004], lr: 0.034014, loss: 1.2914
2022-07-07 19:59:33 - train: epoch 0123, iter [03600, 05004], lr: 0.033999, loss: 1.2624
2022-07-07 20:00:07 - train: epoch 0123, iter [03700, 05004], lr: 0.033984, loss: 1.2847
2022-07-07 20:00:40 - train: epoch 0123, iter [03800, 05004], lr: 0.033969, loss: 1.6451
2022-07-07 20:01:14 - train: epoch 0123, iter [03900, 05004], lr: 0.033953, loss: 1.2169
2022-07-07 20:01:47 - train: epoch 0123, iter [04000, 05004], lr: 0.033938, loss: 1.4700
2022-07-07 20:02:21 - train: epoch 0123, iter [04100, 05004], lr: 0.033923, loss: 1.5450
2022-07-07 20:02:54 - train: epoch 0123, iter [04200, 05004], lr: 0.033908, loss: 1.5345
2022-07-07 20:03:27 - train: epoch 0123, iter [04300, 05004], lr: 0.033892, loss: 1.6339
2022-07-07 20:04:02 - train: epoch 0123, iter [04400, 05004], lr: 0.033877, loss: 1.5113
2022-07-07 20:04:35 - train: epoch 0123, iter [04500, 05004], lr: 0.033862, loss: 1.3281
2022-07-07 20:05:09 - train: epoch 0123, iter [04600, 05004], lr: 0.033847, loss: 1.4334
2022-07-07 20:05:42 - train: epoch 0123, iter [04700, 05004], lr: 0.033831, loss: 1.3471
2022-07-07 20:06:15 - train: epoch 0123, iter [04800, 05004], lr: 0.033816, loss: 1.5231
2022-07-07 20:06:49 - train: epoch 0123, iter [04900, 05004], lr: 0.033801, loss: 1.3686
2022-07-07 20:07:21 - train: epoch 0123, iter [05000, 05004], lr: 0.033786, loss: 1.6689
2022-07-07 20:07:22 - train: epoch 123, train_loss: 1.4190
2022-07-07 20:08:37 - eval: epoch: 123, acc1: 65.762%, acc5: 87.132%, test_loss: 1.4143, per_image_load_time: 2.387ms, per_image_inference_time: 0.459ms
2022-07-07 20:08:37 - until epoch: 123, best_acc1: 67.014%
2022-07-07 20:08:37 - epoch 124 lr: 0.033785
2022-07-07 20:09:16 - train: epoch 0124, iter [00100, 05004], lr: 0.033770, loss: 1.1442
2022-07-07 20:09:48 - train: epoch 0124, iter [00200, 05004], lr: 0.033755, loss: 1.4545
2022-07-07 20:10:22 - train: epoch 0124, iter [00300, 05004], lr: 0.033739, loss: 1.2442
2022-07-07 20:10:56 - train: epoch 0124, iter [00400, 05004], lr: 0.033724, loss: 1.2545
2022-07-07 20:11:29 - train: epoch 0124, iter [00500, 05004], lr: 0.033709, loss: 1.3872
2022-07-07 20:12:02 - train: epoch 0124, iter [00600, 05004], lr: 0.033694, loss: 1.4006
2022-07-07 20:12:35 - train: epoch 0124, iter [00700, 05004], lr: 0.033679, loss: 1.5546
2022-07-07 20:13:09 - train: epoch 0124, iter [00800, 05004], lr: 0.033663, loss: 1.5099
2022-07-07 20:13:42 - train: epoch 0124, iter [00900, 05004], lr: 0.033648, loss: 1.4996
2022-07-07 20:14:16 - train: epoch 0124, iter [01000, 05004], lr: 0.033633, loss: 1.3493
2022-07-07 20:14:50 - train: epoch 0124, iter [01100, 05004], lr: 0.033618, loss: 1.5456
2022-07-07 20:15:24 - train: epoch 0124, iter [01200, 05004], lr: 0.033602, loss: 1.2386
2022-07-07 20:15:57 - train: epoch 0124, iter [01300, 05004], lr: 0.033587, loss: 1.3626
2022-07-07 20:16:31 - train: epoch 0124, iter [01400, 05004], lr: 0.033572, loss: 1.4674
2022-07-07 20:17:05 - train: epoch 0124, iter [01500, 05004], lr: 0.033557, loss: 1.3681
2022-07-07 20:17:38 - train: epoch 0124, iter [01600, 05004], lr: 0.033542, loss: 1.5140
2022-07-07 20:18:12 - train: epoch 0124, iter [01700, 05004], lr: 0.033526, loss: 1.2513
2022-07-07 20:18:45 - train: epoch 0124, iter [01800, 05004], lr: 0.033511, loss: 1.3850
2022-07-07 20:19:18 - train: epoch 0124, iter [01900, 05004], lr: 0.033496, loss: 1.7370
2022-07-07 20:19:51 - train: epoch 0124, iter [02000, 05004], lr: 0.033481, loss: 1.4978
2022-07-07 20:20:25 - train: epoch 0124, iter [02100, 05004], lr: 0.033466, loss: 1.4236
2022-07-07 20:21:00 - train: epoch 0124, iter [02200, 05004], lr: 0.033450, loss: 1.4291
2022-07-07 20:21:33 - train: epoch 0124, iter [02300, 05004], lr: 0.033435, loss: 1.5166
2022-07-07 20:22:07 - train: epoch 0124, iter [02400, 05004], lr: 0.033420, loss: 1.5273
2022-07-07 20:22:40 - train: epoch 0124, iter [02500, 05004], lr: 0.033405, loss: 1.3326
2022-07-07 20:23:13 - train: epoch 0124, iter [02600, 05004], lr: 0.033390, loss: 1.3149
2022-07-07 20:23:46 - train: epoch 0124, iter [02700, 05004], lr: 0.033375, loss: 1.4101
2022-07-07 20:24:21 - train: epoch 0124, iter [02800, 05004], lr: 0.033359, loss: 1.4397
2022-07-07 20:24:54 - train: epoch 0124, iter [02900, 05004], lr: 0.033344, loss: 1.3453
2022-07-07 20:25:27 - train: epoch 0124, iter [03000, 05004], lr: 0.033329, loss: 1.2642
2022-07-07 20:26:01 - train: epoch 0124, iter [03100, 05004], lr: 0.033314, loss: 1.4336
2022-07-07 20:26:34 - train: epoch 0124, iter [03200, 05004], lr: 0.033299, loss: 1.3000
2022-07-07 20:27:08 - train: epoch 0124, iter [03300, 05004], lr: 0.033283, loss: 1.3049
2022-07-07 20:27:41 - train: epoch 0124, iter [03400, 05004], lr: 0.033268, loss: 1.3640
2022-07-07 20:28:15 - train: epoch 0124, iter [03500, 05004], lr: 0.033253, loss: 1.3739
2022-07-07 20:28:48 - train: epoch 0124, iter [03600, 05004], lr: 0.033238, loss: 1.5142
2022-07-07 20:29:21 - train: epoch 0124, iter [03700, 05004], lr: 0.033223, loss: 1.4356
2022-07-07 20:29:55 - train: epoch 0124, iter [03800, 05004], lr: 0.033208, loss: 1.5021
2022-07-07 20:30:28 - train: epoch 0124, iter [03900, 05004], lr: 0.033192, loss: 1.3265
2022-07-07 20:31:01 - train: epoch 0124, iter [04000, 05004], lr: 0.033177, loss: 1.2881
2022-07-07 20:31:35 - train: epoch 0124, iter [04100, 05004], lr: 0.033162, loss: 1.5351
2022-07-07 20:32:09 - train: epoch 0124, iter [04200, 05004], lr: 0.033147, loss: 1.5066
2022-07-07 20:32:43 - train: epoch 0124, iter [04300, 05004], lr: 0.033132, loss: 1.3382
2022-07-07 20:33:17 - train: epoch 0124, iter [04400, 05004], lr: 0.033117, loss: 1.3406
2022-07-07 20:33:51 - train: epoch 0124, iter [04500, 05004], lr: 0.033102, loss: 1.3562
2022-07-07 20:34:24 - train: epoch 0124, iter [04600, 05004], lr: 0.033086, loss: 1.5509
2022-07-07 20:34:58 - train: epoch 0124, iter [04700, 05004], lr: 0.033071, loss: 1.2622
2022-07-07 20:35:32 - train: epoch 0124, iter [04800, 05004], lr: 0.033056, loss: 1.5771
2022-07-07 20:36:06 - train: epoch 0124, iter [04900, 05004], lr: 0.033041, loss: 1.1467
2022-07-07 20:36:39 - train: epoch 0124, iter [05000, 05004], lr: 0.033026, loss: 1.6029
2022-07-07 20:36:40 - train: epoch 124, train_loss: 1.4133
2022-07-07 20:37:54 - eval: epoch: 124, acc1: 67.074%, acc5: 88.156%, test_loss: 1.3365, per_image_load_time: 2.207ms, per_image_inference_time: 0.505ms
2022-07-07 20:37:54 - until epoch: 124, best_acc1: 67.074%
2022-07-07 20:37:54 - epoch 125 lr: 0.033025
2022-07-07 20:38:33 - train: epoch 0125, iter [00100, 05004], lr: 0.033010, loss: 1.1938
2022-07-07 20:39:06 - train: epoch 0125, iter [00200, 05004], lr: 0.032995, loss: 1.4736
2022-07-07 20:39:40 - train: epoch 0125, iter [00300, 05004], lr: 0.032980, loss: 1.2891
2022-07-07 20:40:14 - train: epoch 0125, iter [00400, 05004], lr: 0.032965, loss: 1.3990
2022-07-07 20:40:47 - train: epoch 0125, iter [00500, 05004], lr: 0.032950, loss: 1.5230
2022-07-07 20:41:20 - train: epoch 0125, iter [00600, 05004], lr: 0.032934, loss: 1.3197
2022-07-07 20:41:53 - train: epoch 0125, iter [00700, 05004], lr: 0.032919, loss: 1.2497
2022-07-07 20:42:27 - train: epoch 0125, iter [00800, 05004], lr: 0.032904, loss: 1.3967
2022-07-07 20:43:00 - train: epoch 0125, iter [00900, 05004], lr: 0.032889, loss: 1.4564
2022-07-07 20:43:33 - train: epoch 0125, iter [01000, 05004], lr: 0.032874, loss: 1.3449
2022-07-07 20:44:07 - train: epoch 0125, iter [01100, 05004], lr: 0.032859, loss: 1.4184
2022-07-07 20:44:41 - train: epoch 0125, iter [01200, 05004], lr: 0.032844, loss: 1.2891
2022-07-07 20:45:14 - train: epoch 0125, iter [01300, 05004], lr: 0.032829, loss: 1.2273
2022-07-07 20:45:48 - train: epoch 0125, iter [01400, 05004], lr: 0.032813, loss: 1.6282
2022-07-07 20:46:21 - train: epoch 0125, iter [01500, 05004], lr: 0.032798, loss: 1.4755
2022-07-07 20:46:55 - train: epoch 0125, iter [01600, 05004], lr: 0.032783, loss: 1.3086
2022-07-07 20:47:28 - train: epoch 0125, iter [01700, 05004], lr: 0.032768, loss: 1.3705
2022-07-07 20:48:02 - train: epoch 0125, iter [01800, 05004], lr: 0.032753, loss: 1.1972
2022-07-07 20:48:35 - train: epoch 0125, iter [01900, 05004], lr: 0.032738, loss: 1.3879
2022-07-07 20:49:09 - train: epoch 0125, iter [02000, 05004], lr: 0.032723, loss: 1.5015
2022-07-07 20:49:43 - train: epoch 0125, iter [02100, 05004], lr: 0.032708, loss: 1.3450
2022-07-07 20:50:16 - train: epoch 0125, iter [02200, 05004], lr: 0.032693, loss: 1.5831
2022-07-07 20:50:50 - train: epoch 0125, iter [02300, 05004], lr: 0.032677, loss: 1.2822
2022-07-07 20:51:24 - train: epoch 0125, iter [02400, 05004], lr: 0.032662, loss: 1.5303
2022-07-07 20:51:57 - train: epoch 0125, iter [02500, 05004], lr: 0.032647, loss: 1.4718
2022-07-07 20:52:31 - train: epoch 0125, iter [02600, 05004], lr: 0.032632, loss: 1.3949
2022-07-07 20:53:05 - train: epoch 0125, iter [02700, 05004], lr: 0.032617, loss: 1.4621
2022-07-07 20:53:38 - train: epoch 0125, iter [02800, 05004], lr: 0.032602, loss: 1.5404
2022-07-07 20:54:12 - train: epoch 0125, iter [02900, 05004], lr: 0.032587, loss: 1.3816
2022-07-07 20:54:46 - train: epoch 0125, iter [03000, 05004], lr: 0.032572, loss: 1.2736
2022-07-07 20:55:20 - train: epoch 0125, iter [03100, 05004], lr: 0.032557, loss: 1.6137
2022-07-07 20:55:53 - train: epoch 0125, iter [03200, 05004], lr: 0.032542, loss: 1.6783
2022-07-07 20:56:27 - train: epoch 0125, iter [03300, 05004], lr: 0.032527, loss: 1.4533
2022-07-07 20:57:01 - train: epoch 0125, iter [03400, 05004], lr: 0.032511, loss: 1.3438
2022-07-07 20:57:35 - train: epoch 0125, iter [03500, 05004], lr: 0.032496, loss: 1.4668
2022-07-07 20:58:09 - train: epoch 0125, iter [03600, 05004], lr: 0.032481, loss: 1.1842
2022-07-07 20:58:41 - train: epoch 0125, iter [03700, 05004], lr: 0.032466, loss: 1.4763
2022-07-07 20:59:16 - train: epoch 0125, iter [03800, 05004], lr: 0.032451, loss: 1.5060
2022-07-07 20:59:49 - train: epoch 0125, iter [03900, 05004], lr: 0.032436, loss: 1.4312
2022-07-07 21:00:22 - train: epoch 0125, iter [04000, 05004], lr: 0.032421, loss: 1.4496
2022-07-07 21:00:56 - train: epoch 0125, iter [04100, 05004], lr: 0.032406, loss: 1.3638
2022-07-07 21:01:30 - train: epoch 0125, iter [04200, 05004], lr: 0.032391, loss: 1.5083
2022-07-07 21:02:03 - train: epoch 0125, iter [04300, 05004], lr: 0.032376, loss: 1.2526
2022-07-07 21:02:36 - train: epoch 0125, iter [04400, 05004], lr: 0.032361, loss: 1.4229
2022-07-07 21:03:10 - train: epoch 0125, iter [04500, 05004], lr: 0.032346, loss: 1.7032
2022-07-07 21:03:43 - train: epoch 0125, iter [04600, 05004], lr: 0.032331, loss: 1.1510
2022-07-07 21:04:17 - train: epoch 0125, iter [04700, 05004], lr: 0.032316, loss: 1.4604
2022-07-07 21:04:50 - train: epoch 0125, iter [04800, 05004], lr: 0.032300, loss: 1.4624
2022-07-07 21:05:23 - train: epoch 0125, iter [04900, 05004], lr: 0.032285, loss: 1.5712
2022-07-07 21:05:56 - train: epoch 0125, iter [05000, 05004], lr: 0.032270, loss: 1.4216
2022-07-07 21:05:57 - train: epoch 125, train_loss: 1.4020
2022-07-07 21:07:12 - eval: epoch: 125, acc1: 66.882%, acc5: 87.860%, test_loss: 1.3571, per_image_load_time: 1.025ms, per_image_inference_time: 0.465ms
2022-07-07 21:07:12 - until epoch: 125, best_acc1: 67.074%
2022-07-07 21:07:12 - epoch 126 lr: 0.032270
2022-07-07 21:07:51 - train: epoch 0126, iter [00100, 05004], lr: 0.032255, loss: 1.2301
2022-07-07 21:08:24 - train: epoch 0126, iter [00200, 05004], lr: 0.032240, loss: 1.3110
2022-07-07 21:08:57 - train: epoch 0126, iter [00300, 05004], lr: 0.032225, loss: 1.2117
2022-07-07 21:09:30 - train: epoch 0126, iter [00400, 05004], lr: 0.032210, loss: 1.4526
2022-07-07 21:10:03 - train: epoch 0126, iter [00500, 05004], lr: 0.032195, loss: 1.1444
2022-07-07 21:10:36 - train: epoch 0126, iter [00600, 05004], lr: 0.032179, loss: 1.3744
2022-07-07 21:11:08 - train: epoch 0126, iter [00700, 05004], lr: 0.032164, loss: 1.2847
2022-07-07 21:11:42 - train: epoch 0126, iter [00800, 05004], lr: 0.032149, loss: 1.3496
2022-07-07 21:12:15 - train: epoch 0126, iter [00900, 05004], lr: 0.032134, loss: 1.4137
2022-07-07 21:12:50 - train: epoch 0126, iter [01000, 05004], lr: 0.032119, loss: 1.4498
2022-07-07 21:13:23 - train: epoch 0126, iter [01100, 05004], lr: 0.032104, loss: 1.3811
2022-07-07 21:13:57 - train: epoch 0126, iter [01200, 05004], lr: 0.032089, loss: 1.3007
2022-07-07 21:14:31 - train: epoch 0126, iter [01300, 05004], lr: 0.032074, loss: 1.6009
2022-07-07 21:15:04 - train: epoch 0126, iter [01400, 05004], lr: 0.032059, loss: 1.5198
2022-07-07 21:15:38 - train: epoch 0126, iter [01500, 05004], lr: 0.032044, loss: 1.3827
2022-07-07 21:16:12 - train: epoch 0126, iter [01600, 05004], lr: 0.032029, loss: 1.2495
2022-07-07 21:16:47 - train: epoch 0126, iter [01700, 05004], lr: 0.032014, loss: 1.3440
2022-07-07 21:17:20 - train: epoch 0126, iter [01800, 05004], lr: 0.031999, loss: 1.3766
2022-07-07 21:17:54 - train: epoch 0126, iter [01900, 05004], lr: 0.031984, loss: 1.2189
2022-07-07 21:18:27 - train: epoch 0126, iter [02000, 05004], lr: 0.031969, loss: 1.3885
2022-07-07 21:19:01 - train: epoch 0126, iter [02100, 05004], lr: 0.031954, loss: 1.3042
2022-07-07 21:19:35 - train: epoch 0126, iter [02200, 05004], lr: 0.031939, loss: 1.4839
2022-07-07 21:20:08 - train: epoch 0126, iter [02300, 05004], lr: 0.031924, loss: 1.5416
2022-07-07 21:20:42 - train: epoch 0126, iter [02400, 05004], lr: 0.031909, loss: 1.4036
2022-07-07 21:21:16 - train: epoch 0126, iter [02500, 05004], lr: 0.031894, loss: 1.8171
2022-07-07 21:21:50 - train: epoch 0126, iter [02600, 05004], lr: 0.031879, loss: 1.5597
2022-07-07 21:22:25 - train: epoch 0126, iter [02700, 05004], lr: 0.031864, loss: 1.2853
2022-07-07 21:22:58 - train: epoch 0126, iter [02800, 05004], lr: 0.031849, loss: 1.4735
2022-07-07 21:23:32 - train: epoch 0126, iter [02900, 05004], lr: 0.031834, loss: 1.5299
2022-07-07 21:24:06 - train: epoch 0126, iter [03000, 05004], lr: 0.031819, loss: 1.2817
2022-07-07 21:24:39 - train: epoch 0126, iter [03100, 05004], lr: 0.031804, loss: 1.4094
2022-07-07 21:25:13 - train: epoch 0126, iter [03200, 05004], lr: 0.031789, loss: 1.3373
2022-07-07 21:25:46 - train: epoch 0126, iter [03300, 05004], lr: 0.031774, loss: 1.3958
2022-07-07 21:26:21 - train: epoch 0126, iter [03400, 05004], lr: 0.031759, loss: 1.4047
2022-07-07 21:26:54 - train: epoch 0126, iter [03500, 05004], lr: 0.031744, loss: 1.3637
2022-07-07 21:27:28 - train: epoch 0126, iter [03600, 05004], lr: 0.031729, loss: 1.4604
2022-07-07 21:28:01 - train: epoch 0126, iter [03700, 05004], lr: 0.031714, loss: 1.3987
2022-07-07 21:28:34 - train: epoch 0126, iter [03800, 05004], lr: 0.031699, loss: 1.3743
2022-07-07 21:29:09 - train: epoch 0126, iter [03900, 05004], lr: 0.031684, loss: 1.3606
2022-07-07 21:29:43 - train: epoch 0126, iter [04000, 05004], lr: 0.031669, loss: 1.5168
2022-07-07 21:30:16 - train: epoch 0126, iter [04100, 05004], lr: 0.031654, loss: 1.4586
2022-07-07 21:30:49 - train: epoch 0126, iter [04200, 05004], lr: 0.031639, loss: 1.3389
2022-07-07 21:31:23 - train: epoch 0126, iter [04300, 05004], lr: 0.031624, loss: 1.3224
2022-07-07 21:31:57 - train: epoch 0126, iter [04400, 05004], lr: 0.031609, loss: 1.4572
2022-07-07 21:32:31 - train: epoch 0126, iter [04500, 05004], lr: 0.031594, loss: 1.3898
2022-07-07 21:33:05 - train: epoch 0126, iter [04600, 05004], lr: 0.031579, loss: 1.1672
2022-07-07 21:33:39 - train: epoch 0126, iter [04700, 05004], lr: 0.031564, loss: 1.5073
2022-07-07 21:34:11 - train: epoch 0126, iter [04800, 05004], lr: 0.031549, loss: 1.6418
2022-07-07 21:34:46 - train: epoch 0126, iter [04900, 05004], lr: 0.031534, loss: 1.5153
2022-07-07 21:35:19 - train: epoch 0126, iter [05000, 05004], lr: 0.031519, loss: 1.4873
2022-07-07 21:35:20 - train: epoch 126, train_loss: 1.3950
2022-07-07 21:36:35 - eval: epoch: 126, acc1: 66.464%, acc5: 87.724%, test_loss: 1.3676, per_image_load_time: 1.397ms, per_image_inference_time: 0.453ms
2022-07-07 21:36:35 - until epoch: 126, best_acc1: 67.074%
2022-07-07 21:36:35 - epoch 127 lr: 0.031519
2022-07-07 21:37:14 - train: epoch 0127, iter [00100, 05004], lr: 0.031504, loss: 1.4816
2022-07-07 21:37:47 - train: epoch 0127, iter [00200, 05004], lr: 0.031489, loss: 1.1060
2022-07-07 21:38:21 - train: epoch 0127, iter [00300, 05004], lr: 0.031474, loss: 1.3161
2022-07-07 21:38:54 - train: epoch 0127, iter [00400, 05004], lr: 0.031459, loss: 1.4950
2022-07-07 21:39:27 - train: epoch 0127, iter [00500, 05004], lr: 0.031444, loss: 1.4568
2022-07-07 21:40:01 - train: epoch 0127, iter [00600, 05004], lr: 0.031429, loss: 1.5461
2022-07-07 21:40:35 - train: epoch 0127, iter [00700, 05004], lr: 0.031414, loss: 1.4145
2022-07-07 21:41:08 - train: epoch 0127, iter [00800, 05004], lr: 0.031399, loss: 1.3006
2022-07-07 21:41:42 - train: epoch 0127, iter [00900, 05004], lr: 0.031384, loss: 1.1900
2022-07-07 21:42:17 - train: epoch 0127, iter [01000, 05004], lr: 0.031369, loss: 1.3330
2022-07-07 21:42:50 - train: epoch 0127, iter [01100, 05004], lr: 0.031354, loss: 1.3457
2022-07-07 21:43:23 - train: epoch 0127, iter [01200, 05004], lr: 0.031340, loss: 1.3937
2022-07-07 21:43:57 - train: epoch 0127, iter [01300, 05004], lr: 0.031325, loss: 1.3710
2022-07-07 21:44:31 - train: epoch 0127, iter [01400, 05004], lr: 0.031310, loss: 1.2433
2022-07-07 21:45:04 - train: epoch 0127, iter [01500, 05004], lr: 0.031295, loss: 1.3133
2022-07-07 21:45:38 - train: epoch 0127, iter [01600, 05004], lr: 0.031280, loss: 1.2255
2022-07-07 21:46:12 - train: epoch 0127, iter [01700, 05004], lr: 0.031265, loss: 1.2793
2022-07-07 21:46:45 - train: epoch 0127, iter [01800, 05004], lr: 0.031250, loss: 1.3628
2022-07-07 21:47:19 - train: epoch 0127, iter [01900, 05004], lr: 0.031235, loss: 1.3683
2022-07-07 21:47:53 - train: epoch 0127, iter [02000, 05004], lr: 0.031220, loss: 1.3499
2022-07-07 21:48:27 - train: epoch 0127, iter [02100, 05004], lr: 0.031205, loss: 1.4624
2022-07-07 21:49:01 - train: epoch 0127, iter [02200, 05004], lr: 0.031190, loss: 1.3803
2022-07-07 21:49:35 - train: epoch 0127, iter [02300, 05004], lr: 0.031175, loss: 1.2548
2022-07-07 21:50:07 - train: epoch 0127, iter [02400, 05004], lr: 0.031160, loss: 1.4642
2022-07-07 21:50:41 - train: epoch 0127, iter [02500, 05004], lr: 0.031146, loss: 1.2371
2022-07-07 21:51:15 - train: epoch 0127, iter [02600, 05004], lr: 0.031131, loss: 1.0780
2022-07-07 21:51:48 - train: epoch 0127, iter [02700, 05004], lr: 0.031116, loss: 1.2179
2022-07-07 21:52:22 - train: epoch 0127, iter [02800, 05004], lr: 0.031101, loss: 1.3202
2022-07-07 21:52:55 - train: epoch 0127, iter [02900, 05004], lr: 0.031086, loss: 1.4768
2022-07-07 21:53:28 - train: epoch 0127, iter [03000, 05004], lr: 0.031071, loss: 1.5470
2022-07-07 21:54:02 - train: epoch 0127, iter [03100, 05004], lr: 0.031056, loss: 1.4733
2022-07-07 21:54:36 - train: epoch 0127, iter [03200, 05004], lr: 0.031041, loss: 1.4214
2022-07-07 21:55:10 - train: epoch 0127, iter [03300, 05004], lr: 0.031026, loss: 1.5044
2022-07-07 21:55:43 - train: epoch 0127, iter [03400, 05004], lr: 0.031011, loss: 1.4668
2022-07-07 21:56:17 - train: epoch 0127, iter [03500, 05004], lr: 0.030997, loss: 1.4555
2022-07-07 21:56:51 - train: epoch 0127, iter [03600, 05004], lr: 0.030982, loss: 1.6379
2022-07-07 21:57:25 - train: epoch 0127, iter [03700, 05004], lr: 0.030967, loss: 1.5661
2022-07-07 21:57:58 - train: epoch 0127, iter [03800, 05004], lr: 0.030952, loss: 1.4087
2022-07-07 21:58:32 - train: epoch 0127, iter [03900, 05004], lr: 0.030937, loss: 1.2554
2022-07-07 21:59:05 - train: epoch 0127, iter [04000, 05004], lr: 0.030922, loss: 1.3071
2022-07-07 21:59:38 - train: epoch 0127, iter [04100, 05004], lr: 0.030907, loss: 1.3370
2022-07-07 22:00:12 - train: epoch 0127, iter [04200, 05004], lr: 0.030892, loss: 1.3116
2022-07-07 22:00:45 - train: epoch 0127, iter [04300, 05004], lr: 0.030878, loss: 1.4298
2022-07-07 22:01:19 - train: epoch 0127, iter [04400, 05004], lr: 0.030863, loss: 1.2448
2022-07-07 22:01:52 - train: epoch 0127, iter [04500, 05004], lr: 0.030848, loss: 1.5095
2022-07-07 22:02:26 - train: epoch 0127, iter [04600, 05004], lr: 0.030833, loss: 1.2773
2022-07-07 22:02:59 - train: epoch 0127, iter [04700, 05004], lr: 0.030818, loss: 1.3120
2022-07-07 22:03:32 - train: epoch 0127, iter [04800, 05004], lr: 0.030803, loss: 1.3655
2022-07-07 22:04:06 - train: epoch 0127, iter [04900, 05004], lr: 0.030788, loss: 1.3087
2022-07-07 22:04:38 - train: epoch 0127, iter [05000, 05004], lr: 0.030773, loss: 1.6088
2022-07-07 22:04:39 - train: epoch 127, train_loss: 1.3841
2022-07-07 22:05:54 - eval: epoch: 127, acc1: 67.308%, acc5: 88.224%, test_loss: 1.3328, per_image_load_time: 0.682ms, per_image_inference_time: 0.471ms
2022-07-07 22:05:54 - until epoch: 127, best_acc1: 67.308%
2022-07-07 22:05:54 - epoch 128 lr: 0.030773
2022-07-07 22:06:33 - train: epoch 0128, iter [00100, 05004], lr: 0.030758, loss: 1.3696
2022-07-07 22:07:06 - train: epoch 0128, iter [00200, 05004], lr: 0.030743, loss: 1.3842
2022-07-07 22:07:39 - train: epoch 0128, iter [00300, 05004], lr: 0.030728, loss: 1.3768
2022-07-07 22:08:12 - train: epoch 0128, iter [00400, 05004], lr: 0.030713, loss: 1.1140
2022-07-07 22:08:44 - train: epoch 0128, iter [00500, 05004], lr: 0.030699, loss: 1.3790
2022-07-07 22:09:18 - train: epoch 0128, iter [00600, 05004], lr: 0.030684, loss: 1.4032
2022-07-07 22:09:52 - train: epoch 0128, iter [00700, 05004], lr: 0.030669, loss: 1.4335
2022-07-07 22:10:24 - train: epoch 0128, iter [00800, 05004], lr: 0.030654, loss: 1.4487
2022-07-07 22:10:57 - train: epoch 0128, iter [00900, 05004], lr: 0.030639, loss: 1.2750
2022-07-07 22:11:30 - train: epoch 0128, iter [01000, 05004], lr: 0.030624, loss: 1.1991
2022-07-07 22:12:03 - train: epoch 0128, iter [01100, 05004], lr: 0.030610, loss: 1.3889
2022-07-07 22:12:37 - train: epoch 0128, iter [01200, 05004], lr: 0.030595, loss: 1.3547
2022-07-07 22:13:10 - train: epoch 0128, iter [01300, 05004], lr: 0.030580, loss: 1.3028
2022-07-07 22:13:42 - train: epoch 0128, iter [01400, 05004], lr: 0.030565, loss: 1.2858
2022-07-07 22:14:16 - train: epoch 0128, iter [01500, 05004], lr: 0.030550, loss: 1.5060
2022-07-07 22:14:49 - train: epoch 0128, iter [01600, 05004], lr: 0.030535, loss: 1.3563
2022-07-07 22:15:22 - train: epoch 0128, iter [01700, 05004], lr: 0.030521, loss: 1.2387
2022-07-07 22:15:55 - train: epoch 0128, iter [01800, 05004], lr: 0.030506, loss: 1.4063
2022-07-07 22:16:28 - train: epoch 0128, iter [01900, 05004], lr: 0.030491, loss: 1.2493
2022-07-07 22:17:01 - train: epoch 0128, iter [02000, 05004], lr: 0.030476, loss: 1.1924
2022-07-07 22:17:35 - train: epoch 0128, iter [02100, 05004], lr: 0.030461, loss: 1.5028
2022-07-07 22:18:09 - train: epoch 0128, iter [02200, 05004], lr: 0.030446, loss: 1.3630
2022-07-07 22:18:43 - train: epoch 0128, iter [02300, 05004], lr: 0.030432, loss: 1.2379
2022-07-07 22:19:16 - train: epoch 0128, iter [02400, 05004], lr: 0.030417, loss: 1.3195
2022-07-07 22:19:50 - train: epoch 0128, iter [02500, 05004], lr: 0.030402, loss: 1.5258
2022-07-07 22:20:22 - train: epoch 0128, iter [02600, 05004], lr: 0.030387, loss: 1.3674
2022-07-07 22:20:56 - train: epoch 0128, iter [02700, 05004], lr: 0.030372, loss: 1.1293
2022-07-07 22:21:29 - train: epoch 0128, iter [02800, 05004], lr: 0.030358, loss: 1.2747
2022-07-07 22:22:03 - train: epoch 0128, iter [02900, 05004], lr: 0.030343, loss: 1.5188
2022-07-07 22:22:37 - train: epoch 0128, iter [03000, 05004], lr: 0.030328, loss: 1.4928
2022-07-07 22:23:10 - train: epoch 0128, iter [03100, 05004], lr: 0.030313, loss: 1.2406
2022-07-07 22:23:43 - train: epoch 0128, iter [03200, 05004], lr: 0.030298, loss: 1.5474
2022-07-07 22:24:17 - train: epoch 0128, iter [03300, 05004], lr: 0.030284, loss: 1.4388
2022-07-07 22:24:50 - train: epoch 0128, iter [03400, 05004], lr: 0.030269, loss: 1.3869
2022-07-07 22:25:23 - train: epoch 0128, iter [03500, 05004], lr: 0.030254, loss: 1.5149
2022-07-07 22:25:57 - train: epoch 0128, iter [03600, 05004], lr: 0.030239, loss: 1.4884
2022-07-07 22:26:30 - train: epoch 0128, iter [03700, 05004], lr: 0.030224, loss: 1.3789
2022-07-07 22:27:04 - train: epoch 0128, iter [03800, 05004], lr: 0.030210, loss: 1.4285
2022-07-07 22:27:38 - train: epoch 0128, iter [03900, 05004], lr: 0.030195, loss: 1.3494
2022-07-07 22:28:11 - train: epoch 0128, iter [04000, 05004], lr: 0.030180, loss: 1.5498
2022-07-07 22:28:45 - train: epoch 0128, iter [04100, 05004], lr: 0.030165, loss: 1.5317
2022-07-07 22:29:18 - train: epoch 0128, iter [04200, 05004], lr: 0.030150, loss: 1.2384
2022-07-07 22:29:52 - train: epoch 0128, iter [04300, 05004], lr: 0.030136, loss: 1.5892
2022-07-07 22:30:25 - train: epoch 0128, iter [04400, 05004], lr: 0.030121, loss: 1.3019
2022-07-07 22:30:58 - train: epoch 0128, iter [04500, 05004], lr: 0.030106, loss: 1.5810
2022-07-07 22:31:32 - train: epoch 0128, iter [04600, 05004], lr: 0.030091, loss: 1.3587
2022-07-07 22:32:05 - train: epoch 0128, iter [04700, 05004], lr: 0.030077, loss: 1.4896
2022-07-07 22:32:38 - train: epoch 0128, iter [04800, 05004], lr: 0.030062, loss: 1.2924
2022-07-07 22:33:12 - train: epoch 0128, iter [04900, 05004], lr: 0.030047, loss: 1.4340
2022-07-07 22:33:45 - train: epoch 0128, iter [05000, 05004], lr: 0.030032, loss: 1.3758
2022-07-07 22:33:46 - train: epoch 128, train_loss: 1.3773
2022-07-07 22:35:00 - eval: epoch: 128, acc1: 68.790%, acc5: 89.012%, test_loss: 1.2660, per_image_load_time: 1.245ms, per_image_inference_time: 0.465ms
2022-07-07 22:35:00 - until epoch: 128, best_acc1: 68.790%
2022-07-07 22:35:00 - epoch 129 lr: 0.030032
2022-07-07 22:35:39 - train: epoch 0129, iter [00100, 05004], lr: 0.030017, loss: 1.1157
2022-07-07 22:36:12 - train: epoch 0129, iter [00200, 05004], lr: 0.030002, loss: 1.5809
2022-07-07 22:36:44 - train: epoch 0129, iter [00300, 05004], lr: 0.029988, loss: 1.2471
2022-07-07 22:37:17 - train: epoch 0129, iter [00400, 05004], lr: 0.029973, loss: 1.4150
2022-07-07 22:37:50 - train: epoch 0129, iter [00500, 05004], lr: 0.029958, loss: 1.2255
2022-07-07 22:38:23 - train: epoch 0129, iter [00600, 05004], lr: 0.029943, loss: 1.3025
2022-07-07 22:38:56 - train: epoch 0129, iter [00700, 05004], lr: 0.029929, loss: 1.3898
2022-07-07 22:39:30 - train: epoch 0129, iter [00800, 05004], lr: 0.029914, loss: 1.4451
2022-07-07 22:40:03 - train: epoch 0129, iter [00900, 05004], lr: 0.029899, loss: 1.3094
2022-07-07 22:40:36 - train: epoch 0129, iter [01000, 05004], lr: 0.029884, loss: 1.3089
2022-07-07 22:41:09 - train: epoch 0129, iter [01100, 05004], lr: 0.029870, loss: 1.3042
2022-07-07 22:41:43 - train: epoch 0129, iter [01200, 05004], lr: 0.029855, loss: 1.3667
2022-07-07 22:42:17 - train: epoch 0129, iter [01300, 05004], lr: 0.029840, loss: 1.2072
2022-07-07 22:42:50 - train: epoch 0129, iter [01400, 05004], lr: 0.029825, loss: 1.3258
2022-07-07 22:43:23 - train: epoch 0129, iter [01500, 05004], lr: 0.029811, loss: 1.1731
2022-07-07 22:43:57 - train: epoch 0129, iter [01600, 05004], lr: 0.029796, loss: 1.5692
2022-07-07 22:44:30 - train: epoch 0129, iter [01700, 05004], lr: 0.029781, loss: 1.4602
2022-07-07 22:45:03 - train: epoch 0129, iter [01800, 05004], lr: 0.029766, loss: 1.5488
2022-07-07 22:45:36 - train: epoch 0129, iter [01900, 05004], lr: 0.029752, loss: 1.2803
2022-07-07 22:46:11 - train: epoch 0129, iter [02000, 05004], lr: 0.029737, loss: 1.2683
2022-07-07 22:46:44 - train: epoch 0129, iter [02100, 05004], lr: 0.029722, loss: 1.4008
2022-07-07 22:47:17 - train: epoch 0129, iter [02200, 05004], lr: 0.029708, loss: 1.1779
2022-07-07 22:47:50 - train: epoch 0129, iter [02300, 05004], lr: 0.029693, loss: 1.3302
2022-07-07 22:48:24 - train: epoch 0129, iter [02400, 05004], lr: 0.029678, loss: 1.6573
2022-07-07 22:48:57 - train: epoch 0129, iter [02500, 05004], lr: 0.029663, loss: 1.5378
2022-07-07 22:49:31 - train: epoch 0129, iter [02600, 05004], lr: 0.029649, loss: 1.4032
2022-07-07 22:50:05 - train: epoch 0129, iter [02700, 05004], lr: 0.029634, loss: 1.2856
2022-07-07 22:50:38 - train: epoch 0129, iter [02800, 05004], lr: 0.029619, loss: 1.4237
2022-07-07 22:51:12 - train: epoch 0129, iter [02900, 05004], lr: 0.029605, loss: 1.2925
2022-07-07 22:51:45 - train: epoch 0129, iter [03000, 05004], lr: 0.029590, loss: 1.3299
2022-07-07 22:52:20 - train: epoch 0129, iter [03100, 05004], lr: 0.029575, loss: 1.3427
2022-07-07 22:52:52 - train: epoch 0129, iter [03200, 05004], lr: 0.029561, loss: 1.2768
2022-07-07 22:53:26 - train: epoch 0129, iter [03300, 05004], lr: 0.029546, loss: 1.3513
2022-07-07 22:53:59 - train: epoch 0129, iter [03400, 05004], lr: 0.029531, loss: 1.4703
2022-07-07 22:54:33 - train: epoch 0129, iter [03500, 05004], lr: 0.029517, loss: 1.1312
2022-07-07 22:55:06 - train: epoch 0129, iter [03600, 05004], lr: 0.029502, loss: 1.4030
2022-07-07 22:55:40 - train: epoch 0129, iter [03700, 05004], lr: 0.029487, loss: 1.3541
2022-07-07 22:56:15 - train: epoch 0129, iter [03800, 05004], lr: 0.029472, loss: 1.3387
2022-07-07 22:56:48 - train: epoch 0129, iter [03900, 05004], lr: 0.029458, loss: 1.2844
2022-07-07 22:57:21 - train: epoch 0129, iter [04000, 05004], lr: 0.029443, loss: 1.3339
2022-07-07 22:57:55 - train: epoch 0129, iter [04100, 05004], lr: 0.029428, loss: 1.5494
2022-07-07 22:58:29 - train: epoch 0129, iter [04200, 05004], lr: 0.029414, loss: 1.5842
2022-07-07 22:59:02 - train: epoch 0129, iter [04300, 05004], lr: 0.029399, loss: 1.5130
2022-07-07 22:59:35 - train: epoch 0129, iter [04400, 05004], lr: 0.029384, loss: 1.3445
2022-07-07 23:00:09 - train: epoch 0129, iter [04500, 05004], lr: 0.029370, loss: 1.3328
2022-07-07 23:00:43 - train: epoch 0129, iter [04600, 05004], lr: 0.029355, loss: 1.4142
2022-07-07 23:01:17 - train: epoch 0129, iter [04700, 05004], lr: 0.029340, loss: 1.4479
2022-07-07 23:01:50 - train: epoch 0129, iter [04800, 05004], lr: 0.029326, loss: 1.2675
2022-07-07 23:02:24 - train: epoch 0129, iter [04900, 05004], lr: 0.029311, loss: 1.3534
2022-07-07 23:02:56 - train: epoch 0129, iter [05000, 05004], lr: 0.029296, loss: 1.5781
2022-07-07 23:02:58 - train: epoch 129, train_loss: 1.3673
2022-07-07 23:04:11 - eval: epoch: 129, acc1: 68.398%, acc5: 88.708%, test_loss: 1.2823, per_image_load_time: 2.364ms, per_image_inference_time: 0.455ms
2022-07-07 23:04:11 - until epoch: 129, best_acc1: 68.790%
2022-07-07 23:04:11 - epoch 130 lr: 0.029296
2022-07-07 23:04:50 - train: epoch 0130, iter [00100, 05004], lr: 0.029281, loss: 1.2922
2022-07-07 23:05:24 - train: epoch 0130, iter [00200, 05004], lr: 0.029267, loss: 1.0851
2022-07-07 23:05:57 - train: epoch 0130, iter [00300, 05004], lr: 0.029252, loss: 1.4347
2022-07-07 23:06:29 - train: epoch 0130, iter [00400, 05004], lr: 0.029237, loss: 1.3267
2022-07-07 23:07:02 - train: epoch 0130, iter [00500, 05004], lr: 0.029223, loss: 1.3561
2022-07-07 23:07:34 - train: epoch 0130, iter [00600, 05004], lr: 0.029208, loss: 1.3972
2022-07-07 23:08:08 - train: epoch 0130, iter [00700, 05004], lr: 0.029193, loss: 1.4285
2022-07-07 23:08:41 - train: epoch 0130, iter [00800, 05004], lr: 0.029179, loss: 1.0837
2022-07-07 23:09:14 - train: epoch 0130, iter [00900, 05004], lr: 0.029164, loss: 1.5168
2022-07-07 23:09:47 - train: epoch 0130, iter [01000, 05004], lr: 0.029149, loss: 1.4600
2022-07-07 23:10:21 - train: epoch 0130, iter [01100, 05004], lr: 0.029135, loss: 1.2114
2022-07-07 23:10:55 - train: epoch 0130, iter [01200, 05004], lr: 0.029120, loss: 1.4625
2022-07-07 23:11:27 - train: epoch 0130, iter [01300, 05004], lr: 0.029106, loss: 1.5217
2022-07-07 23:12:01 - train: epoch 0130, iter [01400, 05004], lr: 0.029091, loss: 1.4166
2022-07-07 23:12:35 - train: epoch 0130, iter [01500, 05004], lr: 0.029076, loss: 1.1853
2022-07-07 23:13:08 - train: epoch 0130, iter [01600, 05004], lr: 0.029062, loss: 1.3192
2022-07-07 23:13:42 - train: epoch 0130, iter [01700, 05004], lr: 0.029047, loss: 1.1353
2022-07-07 23:14:16 - train: epoch 0130, iter [01800, 05004], lr: 0.029032, loss: 1.4142
2022-07-07 23:14:50 - train: epoch 0130, iter [01900, 05004], lr: 0.029018, loss: 1.3405
2022-07-07 23:15:23 - train: epoch 0130, iter [02000, 05004], lr: 0.029003, loss: 1.4462
2022-07-07 23:15:57 - train: epoch 0130, iter [02100, 05004], lr: 0.028989, loss: 1.6262
2022-07-07 23:16:30 - train: epoch 0130, iter [02200, 05004], lr: 0.028974, loss: 1.5196
2022-07-07 23:17:05 - train: epoch 0130, iter [02300, 05004], lr: 0.028959, loss: 1.4931
2022-07-07 23:17:37 - train: epoch 0130, iter [02400, 05004], lr: 0.028945, loss: 1.4044
2022-07-07 23:18:11 - train: epoch 0130, iter [02500, 05004], lr: 0.028930, loss: 1.4041
2022-07-07 23:18:45 - train: epoch 0130, iter [02600, 05004], lr: 0.028916, loss: 1.2360
2022-07-07 23:19:18 - train: epoch 0130, iter [02700, 05004], lr: 0.028901, loss: 1.6771
2022-07-07 23:19:52 - train: epoch 0130, iter [02800, 05004], lr: 0.028886, loss: 1.3556
2022-07-07 23:20:26 - train: epoch 0130, iter [02900, 05004], lr: 0.028872, loss: 1.5451
2022-07-07 23:20:59 - train: epoch 0130, iter [03000, 05004], lr: 0.028857, loss: 1.2667
2022-07-07 23:21:33 - train: epoch 0130, iter [03100, 05004], lr: 0.028843, loss: 1.4315
2022-07-07 23:22:06 - train: epoch 0130, iter [03200, 05004], lr: 0.028828, loss: 1.2336
2022-07-07 23:22:40 - train: epoch 0130, iter [03300, 05004], lr: 0.028814, loss: 1.3848
2022-07-07 23:23:14 - train: epoch 0130, iter [03400, 05004], lr: 0.028799, loss: 1.3033
2022-07-07 23:23:47 - train: epoch 0130, iter [03500, 05004], lr: 0.028784, loss: 1.2826
2022-07-07 23:24:21 - train: epoch 0130, iter [03600, 05004], lr: 0.028770, loss: 1.4899
2022-07-07 23:24:55 - train: epoch 0130, iter [03700, 05004], lr: 0.028755, loss: 1.3248
2022-07-07 23:25:28 - train: epoch 0130, iter [03800, 05004], lr: 0.028741, loss: 1.4574
2022-07-07 23:26:02 - train: epoch 0130, iter [03900, 05004], lr: 0.028726, loss: 1.2747
2022-07-07 23:26:35 - train: epoch 0130, iter [04000, 05004], lr: 0.028712, loss: 1.1700
2022-07-07 23:27:09 - train: epoch 0130, iter [04100, 05004], lr: 0.028697, loss: 1.4701
2022-07-07 23:27:42 - train: epoch 0130, iter [04200, 05004], lr: 0.028682, loss: 1.5110
2022-07-07 23:28:16 - train: epoch 0130, iter [04300, 05004], lr: 0.028668, loss: 1.4002
2022-07-07 23:28:49 - train: epoch 0130, iter [04400, 05004], lr: 0.028653, loss: 1.3704
2022-07-07 23:29:23 - train: epoch 0130, iter [04500, 05004], lr: 0.028639, loss: 1.4258
2022-07-07 23:29:58 - train: epoch 0130, iter [04600, 05004], lr: 0.028624, loss: 1.3188
2022-07-07 23:30:31 - train: epoch 0130, iter [04700, 05004], lr: 0.028610, loss: 1.5203
2022-07-07 23:31:06 - train: epoch 0130, iter [04800, 05004], lr: 0.028595, loss: 1.3367
2022-07-07 23:31:40 - train: epoch 0130, iter [04900, 05004], lr: 0.028580, loss: 1.1746
2022-07-07 23:32:12 - train: epoch 0130, iter [05000, 05004], lr: 0.028566, loss: 1.6108
2022-07-07 23:32:13 - train: epoch 130, train_loss: 1.3582
2022-07-07 23:33:27 - eval: epoch: 130, acc1: 66.706%, acc5: 87.986%, test_loss: 1.3585, per_image_load_time: 2.401ms, per_image_inference_time: 0.463ms
2022-07-07 23:33:27 - until epoch: 130, best_acc1: 68.790%
2022-07-07 23:33:27 - epoch 131 lr: 0.028565
2022-07-07 23:34:06 - train: epoch 0131, iter [00100, 05004], lr: 0.028551, loss: 1.1834
2022-07-07 23:34:38 - train: epoch 0131, iter [00200, 05004], lr: 0.028536, loss: 1.2727
2022-07-07 23:35:12 - train: epoch 0131, iter [00300, 05004], lr: 0.028522, loss: 1.1924
2022-07-07 23:35:44 - train: epoch 0131, iter [00400, 05004], lr: 0.028507, loss: 1.5538
2022-07-07 23:36:18 - train: epoch 0131, iter [00500, 05004], lr: 0.028493, loss: 1.2136
2022-07-07 23:36:51 - train: epoch 0131, iter [00600, 05004], lr: 0.028478, loss: 1.4214
2022-07-07 23:37:24 - train: epoch 0131, iter [00700, 05004], lr: 0.028464, loss: 1.4578
2022-07-07 23:37:58 - train: epoch 0131, iter [00800, 05004], lr: 0.028449, loss: 1.1972
2022-07-07 23:38:32 - train: epoch 0131, iter [00900, 05004], lr: 0.028435, loss: 1.3425
2022-07-07 23:39:05 - train: epoch 0131, iter [01000, 05004], lr: 0.028420, loss: 1.2739
2022-07-07 23:39:38 - train: epoch 0131, iter [01100, 05004], lr: 0.028406, loss: 1.3071
2022-07-07 23:40:11 - train: epoch 0131, iter [01200, 05004], lr: 0.028391, loss: 1.4292
2022-07-07 23:40:46 - train: epoch 0131, iter [01300, 05004], lr: 0.028376, loss: 1.4934
2022-07-07 23:41:18 - train: epoch 0131, iter [01400, 05004], lr: 0.028362, loss: 1.3399
2022-07-07 23:41:53 - train: epoch 0131, iter [01500, 05004], lr: 0.028347, loss: 1.4332
2022-07-07 23:42:26 - train: epoch 0131, iter [01600, 05004], lr: 0.028333, loss: 1.5457
2022-07-07 23:43:00 - train: epoch 0131, iter [01700, 05004], lr: 0.028318, loss: 1.4668
2022-07-07 23:43:33 - train: epoch 0131, iter [01800, 05004], lr: 0.028304, loss: 1.4701
2022-07-07 23:44:07 - train: epoch 0131, iter [01900, 05004], lr: 0.028289, loss: 1.2367
2022-07-07 23:44:39 - train: epoch 0131, iter [02000, 05004], lr: 0.028275, loss: 1.3534
2022-07-07 23:45:13 - train: epoch 0131, iter [02100, 05004], lr: 0.028260, loss: 1.5960
2022-07-07 23:45:46 - train: epoch 0131, iter [02200, 05004], lr: 0.028246, loss: 1.6028
2022-07-07 23:46:20 - train: epoch 0131, iter [02300, 05004], lr: 0.028231, loss: 1.5012
2022-07-07 23:46:54 - train: epoch 0131, iter [02400, 05004], lr: 0.028217, loss: 1.1307
2022-07-07 23:47:27 - train: epoch 0131, iter [02500, 05004], lr: 0.028202, loss: 1.3256
2022-07-07 23:48:01 - train: epoch 0131, iter [02600, 05004], lr: 0.028188, loss: 1.1176
2022-07-07 23:48:34 - train: epoch 0131, iter [02700, 05004], lr: 0.028174, loss: 1.4667
2022-07-07 23:49:08 - train: epoch 0131, iter [02800, 05004], lr: 0.028159, loss: 1.2466
2022-07-07 23:49:42 - train: epoch 0131, iter [02900, 05004], lr: 0.028145, loss: 1.3761
2022-07-07 23:50:16 - train: epoch 0131, iter [03000, 05004], lr: 0.028130, loss: 1.2153
2022-07-07 23:50:48 - train: epoch 0131, iter [03100, 05004], lr: 0.028116, loss: 1.4088
2022-07-07 23:51:22 - train: epoch 0131, iter [03200, 05004], lr: 0.028101, loss: 1.1990
2022-07-07 23:51:56 - train: epoch 0131, iter [03300, 05004], lr: 0.028087, loss: 1.5462
2022-07-07 23:52:30 - train: epoch 0131, iter [03400, 05004], lr: 0.028072, loss: 1.3412
2022-07-07 23:53:03 - train: epoch 0131, iter [03500, 05004], lr: 0.028058, loss: 1.3055
2022-07-07 23:53:37 - train: epoch 0131, iter [03600, 05004], lr: 0.028043, loss: 1.5452
2022-07-07 23:54:10 - train: epoch 0131, iter [03700, 05004], lr: 0.028029, loss: 1.3293
2022-07-07 23:54:44 - train: epoch 0131, iter [03800, 05004], lr: 0.028014, loss: 1.4056
2022-07-07 23:55:17 - train: epoch 0131, iter [03900, 05004], lr: 0.028000, loss: 1.2851
2022-07-07 23:55:52 - train: epoch 0131, iter [04000, 05004], lr: 0.027985, loss: 1.4112
2022-07-07 23:56:25 - train: epoch 0131, iter [04100, 05004], lr: 0.027971, loss: 1.2237
2022-07-07 23:56:59 - train: epoch 0131, iter [04200, 05004], lr: 0.027957, loss: 1.4126
2022-07-07 23:57:32 - train: epoch 0131, iter [04300, 05004], lr: 0.027942, loss: 1.4733
2022-07-07 23:58:06 - train: epoch 0131, iter [04400, 05004], lr: 0.027928, loss: 1.5378
2022-07-07 23:58:40 - train: epoch 0131, iter [04500, 05004], lr: 0.027913, loss: 1.3186
2022-07-07 23:59:13 - train: epoch 0131, iter [04600, 05004], lr: 0.027899, loss: 1.3099
2022-07-07 23:59:46 - train: epoch 0131, iter [04700, 05004], lr: 0.027884, loss: 1.2238
2022-07-08 00:00:20 - train: epoch 0131, iter [04800, 05004], lr: 0.027870, loss: 1.3542
2022-07-08 00:00:53 - train: epoch 0131, iter [04900, 05004], lr: 0.027855, loss: 1.4403
2022-07-08 00:01:26 - train: epoch 0131, iter [05000, 05004], lr: 0.027841, loss: 1.2798
2022-07-08 00:01:27 - train: epoch 131, train_loss: 1.3504
2022-07-08 00:02:41 - eval: epoch: 131, acc1: 67.124%, acc5: 88.316%, test_loss: 1.3309, per_image_load_time: 2.427ms, per_image_inference_time: 0.454ms
2022-07-08 00:02:42 - until epoch: 131, best_acc1: 68.790%
2022-07-08 00:02:42 - epoch 132 lr: 0.027840
2022-07-08 00:03:20 - train: epoch 0132, iter [00100, 05004], lr: 0.027826, loss: 1.2989
2022-07-08 00:03:54 - train: epoch 0132, iter [00200, 05004], lr: 0.027812, loss: 1.0407
2022-07-08 00:04:26 - train: epoch 0132, iter [00300, 05004], lr: 0.027797, loss: 1.5224
2022-07-08 00:04:59 - train: epoch 0132, iter [00400, 05004], lr: 0.027783, loss: 1.2055
2022-07-08 00:05:33 - train: epoch 0132, iter [00500, 05004], lr: 0.027768, loss: 1.3941
2022-07-08 00:06:06 - train: epoch 0132, iter [00600, 05004], lr: 0.027754, loss: 1.4683
2022-07-08 00:06:39 - train: epoch 0132, iter [00700, 05004], lr: 0.027739, loss: 1.1020
2022-07-08 00:07:13 - train: epoch 0132, iter [00800, 05004], lr: 0.027725, loss: 1.3111
2022-07-08 00:07:46 - train: epoch 0132, iter [00900, 05004], lr: 0.027711, loss: 1.2656
2022-07-08 00:08:20 - train: epoch 0132, iter [01000, 05004], lr: 0.027696, loss: 1.4130
2022-07-08 00:08:53 - train: epoch 0132, iter [01100, 05004], lr: 0.027682, loss: 1.3413
2022-07-08 00:09:26 - train: epoch 0132, iter [01200, 05004], lr: 0.027667, loss: 1.2716
2022-07-08 00:09:59 - train: epoch 0132, iter [01300, 05004], lr: 0.027653, loss: 1.0263
2022-07-08 00:10:33 - train: epoch 0132, iter [01400, 05004], lr: 0.027639, loss: 1.2691
2022-07-08 00:11:07 - train: epoch 0132, iter [01500, 05004], lr: 0.027624, loss: 1.5828
2022-07-08 00:11:40 - train: epoch 0132, iter [01600, 05004], lr: 0.027610, loss: 1.6126
2022-07-08 00:12:14 - train: epoch 0132, iter [01700, 05004], lr: 0.027595, loss: 1.3970
2022-07-08 00:12:48 - train: epoch 0132, iter [01800, 05004], lr: 0.027581, loss: 1.4463
2022-07-08 00:13:21 - train: epoch 0132, iter [01900, 05004], lr: 0.027567, loss: 1.1222
2022-07-08 00:13:55 - train: epoch 0132, iter [02000, 05004], lr: 0.027552, loss: 1.1547
2022-07-08 00:14:28 - train: epoch 0132, iter [02100, 05004], lr: 0.027538, loss: 1.4112
2022-07-08 00:15:02 - train: epoch 0132, iter [02200, 05004], lr: 0.027524, loss: 1.3273
2022-07-08 00:15:35 - train: epoch 0132, iter [02300, 05004], lr: 0.027509, loss: 1.5078
2022-07-08 00:16:08 - train: epoch 0132, iter [02400, 05004], lr: 0.027495, loss: 1.0881
2022-07-08 00:16:42 - train: epoch 0132, iter [02500, 05004], lr: 0.027480, loss: 1.4178
2022-07-08 00:17:16 - train: epoch 0132, iter [02600, 05004], lr: 0.027466, loss: 1.3782
2022-07-08 00:17:49 - train: epoch 0132, iter [02700, 05004], lr: 0.027452, loss: 1.4264
2022-07-08 00:18:23 - train: epoch 0132, iter [02800, 05004], lr: 0.027437, loss: 1.3972
2022-07-08 00:18:57 - train: epoch 0132, iter [02900, 05004], lr: 0.027423, loss: 1.2476
2022-07-08 00:19:30 - train: epoch 0132, iter [03000, 05004], lr: 0.027409, loss: 1.3358
2022-07-08 00:20:04 - train: epoch 0132, iter [03100, 05004], lr: 0.027394, loss: 1.4285
2022-07-08 00:20:37 - train: epoch 0132, iter [03200, 05004], lr: 0.027380, loss: 1.3949
2022-07-08 00:21:11 - train: epoch 0132, iter [03300, 05004], lr: 0.027365, loss: 1.4229
2022-07-08 00:21:45 - train: epoch 0132, iter [03400, 05004], lr: 0.027351, loss: 1.3052
2022-07-08 00:22:19 - train: epoch 0132, iter [03500, 05004], lr: 0.027337, loss: 1.3824
2022-07-08 00:22:52 - train: epoch 0132, iter [03600, 05004], lr: 0.027322, loss: 1.4327
2022-07-08 00:23:26 - train: epoch 0132, iter [03700, 05004], lr: 0.027308, loss: 1.4587
2022-07-08 00:23:59 - train: epoch 0132, iter [03800, 05004], lr: 0.027294, loss: 1.3151
2022-07-08 00:24:33 - train: epoch 0132, iter [03900, 05004], lr: 0.027279, loss: 1.3545
2022-07-08 00:25:07 - train: epoch 0132, iter [04000, 05004], lr: 0.027265, loss: 1.4283
2022-07-08 00:25:40 - train: epoch 0132, iter [04100, 05004], lr: 0.027251, loss: 1.4059
2022-07-08 00:26:15 - train: epoch 0132, iter [04200, 05004], lr: 0.027236, loss: 1.4482
2022-07-08 00:26:48 - train: epoch 0132, iter [04300, 05004], lr: 0.027222, loss: 1.4580
2022-07-08 00:27:21 - train: epoch 0132, iter [04400, 05004], lr: 0.027208, loss: 1.2097
2022-07-08 00:27:54 - train: epoch 0132, iter [04500, 05004], lr: 0.027193, loss: 1.3443
2022-07-08 00:28:27 - train: epoch 0132, iter [04600, 05004], lr: 0.027179, loss: 1.4290
2022-07-08 00:29:01 - train: epoch 0132, iter [04700, 05004], lr: 0.027165, loss: 1.4254
2022-07-08 00:29:34 - train: epoch 0132, iter [04800, 05004], lr: 0.027150, loss: 1.5111
2022-07-08 00:30:08 - train: epoch 0132, iter [04900, 05004], lr: 0.027136, loss: 1.5291
2022-07-08 00:30:40 - train: epoch 0132, iter [05000, 05004], lr: 0.027122, loss: 1.5444
2022-07-08 00:30:41 - train: epoch 132, train_loss: 1.3409
2022-07-08 00:31:55 - eval: epoch: 132, acc1: 67.264%, acc5: 88.266%, test_loss: 1.3274, per_image_load_time: 2.375ms, per_image_inference_time: 0.435ms
2022-07-08 00:31:55 - until epoch: 132, best_acc1: 68.790%
2022-07-08 00:31:55 - epoch 133 lr: 0.027121
2022-07-08 00:32:34 - train: epoch 0133, iter [00100, 05004], lr: 0.027107, loss: 1.0434
2022-07-08 00:33:07 - train: epoch 0133, iter [00200, 05004], lr: 0.027093, loss: 1.4610
2022-07-08 00:33:40 - train: epoch 0133, iter [00300, 05004], lr: 0.027078, loss: 1.2553
2022-07-08 00:34:13 - train: epoch 0133, iter [00400, 05004], lr: 0.027064, loss: 1.4059
2022-07-08 00:34:47 - train: epoch 0133, iter [00500, 05004], lr: 0.027050, loss: 1.2942
2022-07-08 00:35:20 - train: epoch 0133, iter [00600, 05004], lr: 0.027035, loss: 1.2206
2022-07-08 00:35:52 - train: epoch 0133, iter [00700, 05004], lr: 0.027021, loss: 1.2389
2022-07-08 00:36:26 - train: epoch 0133, iter [00800, 05004], lr: 0.027007, loss: 1.2112
2022-07-08 00:36:59 - train: epoch 0133, iter [00900, 05004], lr: 0.026992, loss: 1.4128
2022-07-08 00:37:33 - train: epoch 0133, iter [01000, 05004], lr: 0.026978, loss: 1.3808
2022-07-08 00:38:06 - train: epoch 0133, iter [01100, 05004], lr: 0.026964, loss: 1.3253
2022-07-08 00:38:40 - train: epoch 0133, iter [01200, 05004], lr: 0.026950, loss: 1.3592
2022-07-08 00:39:13 - train: epoch 0133, iter [01300, 05004], lr: 0.026935, loss: 1.3139
2022-07-08 00:39:47 - train: epoch 0133, iter [01400, 05004], lr: 0.026921, loss: 1.3766
2022-07-08 00:40:21 - train: epoch 0133, iter [01500, 05004], lr: 0.026907, loss: 1.4160
2022-07-08 00:40:54 - train: epoch 0133, iter [01600, 05004], lr: 0.026893, loss: 1.3698
2022-07-08 00:41:27 - train: epoch 0133, iter [01700, 05004], lr: 0.026878, loss: 1.7898
2022-07-08 00:42:00 - train: epoch 0133, iter [01800, 05004], lr: 0.026864, loss: 1.3366
2022-07-08 00:42:34 - train: epoch 0133, iter [01900, 05004], lr: 0.026850, loss: 1.2049
2022-07-08 00:43:08 - train: epoch 0133, iter [02000, 05004], lr: 0.026835, loss: 1.2182
2022-07-08 00:43:41 - train: epoch 0133, iter [02100, 05004], lr: 0.026821, loss: 1.6141
2022-07-08 00:44:14 - train: epoch 0133, iter [02200, 05004], lr: 0.026807, loss: 1.4895
2022-07-08 00:44:48 - train: epoch 0133, iter [02300, 05004], lr: 0.026793, loss: 1.2934
2022-07-08 00:45:22 - train: epoch 0133, iter [02400, 05004], lr: 0.026778, loss: 1.2543
2022-07-08 00:45:54 - train: epoch 0133, iter [02500, 05004], lr: 0.026764, loss: 1.3544
2022-07-08 00:46:28 - train: epoch 0133, iter [02600, 05004], lr: 0.026750, loss: 1.1108
2022-07-08 00:47:02 - train: epoch 0133, iter [02700, 05004], lr: 0.026736, loss: 1.5617
2022-07-08 00:47:36 - train: epoch 0133, iter [02800, 05004], lr: 0.026721, loss: 1.3689
2022-07-08 00:48:10 - train: epoch 0133, iter [02900, 05004], lr: 0.026707, loss: 1.1053
2022-07-08 00:48:43 - train: epoch 0133, iter [03000, 05004], lr: 0.026693, loss: 1.2203
2022-07-08 00:49:17 - train: epoch 0133, iter [03100, 05004], lr: 0.026679, loss: 1.2144
2022-07-08 00:49:50 - train: epoch 0133, iter [03200, 05004], lr: 0.026664, loss: 1.1650
2022-07-08 00:50:24 - train: epoch 0133, iter [03300, 05004], lr: 0.026650, loss: 1.2376
2022-07-08 00:50:57 - train: epoch 0133, iter [03400, 05004], lr: 0.026636, loss: 1.2983
2022-07-08 00:51:32 - train: epoch 0133, iter [03500, 05004], lr: 0.026622, loss: 1.3664
2022-07-08 00:52:05 - train: epoch 0133, iter [03600, 05004], lr: 0.026607, loss: 1.3871
2022-07-08 00:52:39 - train: epoch 0133, iter [03700, 05004], lr: 0.026593, loss: 1.3886
2022-07-08 00:53:12 - train: epoch 0133, iter [03800, 05004], lr: 0.026579, loss: 1.3947
2022-07-08 00:53:47 - train: epoch 0133, iter [03900, 05004], lr: 0.026565, loss: 1.2505
2022-07-08 00:54:20 - train: epoch 0133, iter [04000, 05004], lr: 0.026551, loss: 1.1683
2022-07-08 00:54:54 - train: epoch 0133, iter [04100, 05004], lr: 0.026536, loss: 1.2763
2022-07-08 00:55:28 - train: epoch 0133, iter [04200, 05004], lr: 0.026522, loss: 1.2607
2022-07-08 00:56:02 - train: epoch 0133, iter [04300, 05004], lr: 0.026508, loss: 1.4656
2022-07-08 00:56:35 - train: epoch 0133, iter [04400, 05004], lr: 0.026494, loss: 1.2195
2022-07-08 00:57:09 - train: epoch 0133, iter [04500, 05004], lr: 0.026480, loss: 1.2884
2022-07-08 00:57:42 - train: epoch 0133, iter [04600, 05004], lr: 0.026465, loss: 1.2162
2022-07-08 00:58:16 - train: epoch 0133, iter [04700, 05004], lr: 0.026451, loss: 1.2705
2022-07-08 00:58:51 - train: epoch 0133, iter [04800, 05004], lr: 0.026437, loss: 1.4504
2022-07-08 00:59:24 - train: epoch 0133, iter [04900, 05004], lr: 0.026423, loss: 1.4097
2022-07-08 00:59:56 - train: epoch 0133, iter [05000, 05004], lr: 0.026409, loss: 1.1926
2022-07-08 00:59:57 - train: epoch 133, train_loss: 1.3281
2022-07-08 01:01:12 - eval: epoch: 133, acc1: 67.906%, acc5: 88.552%, test_loss: 1.3066, per_image_load_time: 2.398ms, per_image_inference_time: 0.452ms
2022-07-08 01:01:12 - until epoch: 133, best_acc1: 68.790%
2022-07-08 01:01:12 - epoch 134 lr: 0.026408
2022-07-08 01:01:50 - train: epoch 0134, iter [00100, 05004], lr: 0.026394, loss: 1.0733
2022-07-08 01:02:24 - train: epoch 0134, iter [00200, 05004], lr: 0.026380, loss: 1.4095
2022-07-08 01:02:58 - train: epoch 0134, iter [00300, 05004], lr: 0.026365, loss: 1.3769
2022-07-08 01:03:31 - train: epoch 0134, iter [00400, 05004], lr: 0.026351, loss: 1.1948
2022-07-08 01:04:05 - train: epoch 0134, iter [00500, 05004], lr: 0.026337, loss: 1.2966
2022-07-08 01:04:39 - train: epoch 0134, iter [00600, 05004], lr: 0.026323, loss: 1.4237
2022-07-08 01:05:12 - train: epoch 0134, iter [00700, 05004], lr: 0.026309, loss: 1.3569
2022-07-08 01:05:46 - train: epoch 0134, iter [00800, 05004], lr: 0.026294, loss: 1.1308
2022-07-08 01:06:19 - train: epoch 0134, iter [00900, 05004], lr: 0.026280, loss: 1.2066
2022-07-08 01:06:53 - train: epoch 0134, iter [01000, 05004], lr: 0.026266, loss: 1.2724
2022-07-08 01:07:26 - train: epoch 0134, iter [01100, 05004], lr: 0.026252, loss: 1.2314
2022-07-08 01:08:00 - train: epoch 0134, iter [01200, 05004], lr: 0.026238, loss: 1.3182
2022-07-08 01:08:35 - train: epoch 0134, iter [01300, 05004], lr: 0.026224, loss: 1.3761
2022-07-08 01:09:08 - train: epoch 0134, iter [01400, 05004], lr: 0.026210, loss: 1.0032
2022-07-08 01:09:42 - train: epoch 0134, iter [01500, 05004], lr: 0.026195, loss: 1.2069
2022-07-08 01:10:16 - train: epoch 0134, iter [01600, 05004], lr: 0.026181, loss: 1.2950
2022-07-08 01:10:49 - train: epoch 0134, iter [01700, 05004], lr: 0.026167, loss: 1.3111
2022-07-08 01:11:22 - train: epoch 0134, iter [01800, 05004], lr: 0.026153, loss: 1.4548
2022-07-08 01:11:56 - train: epoch 0134, iter [01900, 05004], lr: 0.026139, loss: 1.3909
2022-07-08 01:12:29 - train: epoch 0134, iter [02000, 05004], lr: 0.026125, loss: 1.3141
2022-07-08 01:13:04 - train: epoch 0134, iter [02100, 05004], lr: 0.026110, loss: 1.3995
2022-07-08 01:13:38 - train: epoch 0134, iter [02200, 05004], lr: 0.026096, loss: 1.1616
2022-07-08 01:14:11 - train: epoch 0134, iter [02300, 05004], lr: 0.026082, loss: 1.2893
2022-07-08 01:14:44 - train: epoch 0134, iter [02400, 05004], lr: 0.026068, loss: 1.3244
2022-07-08 01:15:19 - train: epoch 0134, iter [02500, 05004], lr: 0.026054, loss: 1.3555
2022-07-08 01:15:52 - train: epoch 0134, iter [02600, 05004], lr: 0.026040, loss: 1.1945
2022-07-08 01:16:26 - train: epoch 0134, iter [02700, 05004], lr: 0.026026, loss: 1.1776
2022-07-08 01:17:00 - train: epoch 0134, iter [02800, 05004], lr: 0.026012, loss: 1.2806
2022-07-08 01:17:34 - train: epoch 0134, iter [02900, 05004], lr: 0.025997, loss: 1.4259
2022-07-08 01:18:07 - train: epoch 0134, iter [03000, 05004], lr: 0.025983, loss: 1.0892
2022-07-08 01:18:41 - train: epoch 0134, iter [03100, 05004], lr: 0.025969, loss: 1.3718
2022-07-08 01:19:15 - train: epoch 0134, iter [03200, 05004], lr: 0.025955, loss: 1.3140
2022-07-08 01:19:49 - train: epoch 0134, iter [03300, 05004], lr: 0.025941, loss: 1.3182
2022-07-08 01:20:22 - train: epoch 0134, iter [03400, 05004], lr: 0.025927, loss: 1.3120
2022-07-08 01:20:56 - train: epoch 0134, iter [03500, 05004], lr: 0.025913, loss: 1.2410
2022-07-08 01:21:29 - train: epoch 0134, iter [03600, 05004], lr: 0.025899, loss: 1.2840
2022-07-08 01:22:02 - train: epoch 0134, iter [03700, 05004], lr: 0.025885, loss: 1.4114
2022-07-08 01:22:36 - train: epoch 0134, iter [03800, 05004], lr: 0.025870, loss: 1.2404
2022-07-08 01:23:10 - train: epoch 0134, iter [03900, 05004], lr: 0.025856, loss: 1.4413
2022-07-08 01:23:44 - train: epoch 0134, iter [04000, 05004], lr: 0.025842, loss: 1.5790
2022-07-08 01:24:17 - train: epoch 0134, iter [04100, 05004], lr: 0.025828, loss: 1.4371
2022-07-08 01:24:50 - train: epoch 0134, iter [04200, 05004], lr: 0.025814, loss: 1.1510
2022-07-08 01:25:24 - train: epoch 0134, iter [04300, 05004], lr: 0.025800, loss: 1.3649
2022-07-08 01:25:58 - train: epoch 0134, iter [04400, 05004], lr: 0.025786, loss: 1.4740
2022-07-08 01:26:32 - train: epoch 0134, iter [04500, 05004], lr: 0.025772, loss: 1.4449
2022-07-08 01:27:06 - train: epoch 0134, iter [04600, 05004], lr: 0.025758, loss: 1.1844
2022-07-08 01:27:39 - train: epoch 0134, iter [04700, 05004], lr: 0.025744, loss: 1.2763
2022-07-08 01:28:12 - train: epoch 0134, iter [04800, 05004], lr: 0.025730, loss: 1.3868
2022-07-08 01:28:45 - train: epoch 0134, iter [04900, 05004], lr: 0.025715, loss: 1.2884
2022-07-08 01:29:18 - train: epoch 0134, iter [05000, 05004], lr: 0.025701, loss: 1.5082
2022-07-08 01:29:19 - train: epoch 134, train_loss: 1.3201
2022-07-08 01:30:33 - eval: epoch: 134, acc1: 69.200%, acc5: 89.388%, test_loss: 1.2460, per_image_load_time: 2.390ms, per_image_inference_time: 0.473ms
2022-07-08 01:30:34 - until epoch: 134, best_acc1: 69.200%
2022-07-08 01:30:34 - epoch 135 lr: 0.025701
2022-07-08 01:31:13 - train: epoch 0135, iter [00100, 05004], lr: 0.025687, loss: 1.1149
2022-07-08 01:31:46 - train: epoch 0135, iter [00200, 05004], lr: 0.025673, loss: 1.3895
2022-07-08 01:32:20 - train: epoch 0135, iter [00300, 05004], lr: 0.025659, loss: 1.3347
2022-07-08 01:32:54 - train: epoch 0135, iter [00400, 05004], lr: 0.025645, loss: 1.0796
2022-07-08 01:33:26 - train: epoch 0135, iter [00500, 05004], lr: 0.025631, loss: 1.4467
2022-07-08 01:33:59 - train: epoch 0135, iter [00600, 05004], lr: 0.025616, loss: 1.1528
2022-07-08 01:34:33 - train: epoch 0135, iter [00700, 05004], lr: 0.025602, loss: 1.4849
2022-07-08 01:35:06 - train: epoch 0135, iter [00800, 05004], lr: 0.025588, loss: 1.4702
2022-07-08 01:35:40 - train: epoch 0135, iter [00900, 05004], lr: 0.025574, loss: 1.2518
2022-07-08 01:36:13 - train: epoch 0135, iter [01000, 05004], lr: 0.025560, loss: 1.4001
2022-07-08 01:36:48 - train: epoch 0135, iter [01100, 05004], lr: 0.025546, loss: 1.1545
2022-07-08 01:37:21 - train: epoch 0135, iter [01200, 05004], lr: 0.025532, loss: 1.2425
2022-07-08 01:37:55 - train: epoch 0135, iter [01300, 05004], lr: 0.025518, loss: 1.3686
2022-07-08 01:38:29 - train: epoch 0135, iter [01400, 05004], lr: 0.025504, loss: 1.3722
2022-07-08 01:39:02 - train: epoch 0135, iter [01500, 05004], lr: 0.025490, loss: 1.3524
2022-07-08 01:39:36 - train: epoch 0135, iter [01600, 05004], lr: 0.025476, loss: 1.1791
2022-07-08 01:40:09 - train: epoch 0135, iter [01700, 05004], lr: 0.025462, loss: 1.6423
2022-07-08 01:40:43 - train: epoch 0135, iter [01800, 05004], lr: 0.025448, loss: 1.3579
2022-07-08 01:41:17 - train: epoch 0135, iter [01900, 05004], lr: 0.025434, loss: 1.1750
2022-07-08 01:41:50 - train: epoch 0135, iter [02000, 05004], lr: 0.025420, loss: 1.3741
2022-07-08 01:42:24 - train: epoch 0135, iter [02100, 05004], lr: 0.025406, loss: 1.3619
2022-07-08 01:42:57 - train: epoch 0135, iter [02200, 05004], lr: 0.025392, loss: 1.3071
2022-07-08 01:43:31 - train: epoch 0135, iter [02300, 05004], lr: 0.025378, loss: 1.3647
2022-07-08 01:44:05 - train: epoch 0135, iter [02400, 05004], lr: 0.025364, loss: 1.3182
2022-07-08 01:44:37 - train: epoch 0135, iter [02500, 05004], lr: 0.025350, loss: 1.4349
2022-07-08 01:45:11 - train: epoch 0135, iter [02600, 05004], lr: 0.025336, loss: 1.1619
2022-07-08 01:45:45 - train: epoch 0135, iter [02700, 05004], lr: 0.025322, loss: 1.6212
2022-07-08 01:46:19 - train: epoch 0135, iter [02800, 05004], lr: 0.025308, loss: 1.4093
2022-07-08 01:46:53 - train: epoch 0135, iter [02900, 05004], lr: 0.025294, loss: 1.4300
2022-07-08 01:47:26 - train: epoch 0135, iter [03000, 05004], lr: 0.025280, loss: 1.2109
2022-07-08 01:48:00 - train: epoch 0135, iter [03100, 05004], lr: 0.025266, loss: 1.3789
2022-07-08 01:48:33 - train: epoch 0135, iter [03200, 05004], lr: 0.025252, loss: 1.3549
2022-07-08 01:49:07 - train: epoch 0135, iter [03300, 05004], lr: 0.025238, loss: 1.4451
2022-07-08 01:49:41 - train: epoch 0135, iter [03400, 05004], lr: 0.025224, loss: 1.4149
2022-07-08 01:50:15 - train: epoch 0135, iter [03500, 05004], lr: 0.025210, loss: 1.5797
2022-07-08 01:50:48 - train: epoch 0135, iter [03600, 05004], lr: 0.025196, loss: 1.3381
2022-07-08 01:51:21 - train: epoch 0135, iter [03700, 05004], lr: 0.025182, loss: 1.3505
2022-07-08 01:51:55 - train: epoch 0135, iter [03800, 05004], lr: 0.025168, loss: 1.3341
2022-07-08 01:52:29 - train: epoch 0135, iter [03900, 05004], lr: 0.025154, loss: 1.1694
2022-07-08 01:53:02 - train: epoch 0135, iter [04000, 05004], lr: 0.025140, loss: 1.4369
2022-07-08 01:53:37 - train: epoch 0135, iter [04100, 05004], lr: 0.025126, loss: 1.6274
2022-07-08 01:54:11 - train: epoch 0135, iter [04200, 05004], lr: 0.025112, loss: 1.4904
2022-07-08 01:54:45 - train: epoch 0135, iter [04300, 05004], lr: 0.025098, loss: 1.5356
2022-07-08 01:55:18 - train: epoch 0135, iter [04400, 05004], lr: 0.025084, loss: 1.3789
2022-07-08 01:55:52 - train: epoch 0135, iter [04500, 05004], lr: 0.025070, loss: 1.2610
2022-07-08 01:56:25 - train: epoch 0135, iter [04600, 05004], lr: 0.025056, loss: 1.4049
2022-07-08 01:56:59 - train: epoch 0135, iter [04700, 05004], lr: 0.025042, loss: 1.1259
2022-07-08 01:57:33 - train: epoch 0135, iter [04800, 05004], lr: 0.025028, loss: 1.2686
2022-07-08 01:58:08 - train: epoch 0135, iter [04900, 05004], lr: 0.025015, loss: 1.2646
2022-07-08 01:58:39 - train: epoch 0135, iter [05000, 05004], lr: 0.025001, loss: 1.2437
2022-07-08 01:58:40 - train: epoch 135, train_loss: 1.3093
2022-07-08 01:59:55 - eval: epoch: 135, acc1: 69.028%, acc5: 89.228%, test_loss: 1.2699, per_image_load_time: 1.497ms, per_image_inference_time: 0.455ms
2022-07-08 01:59:55 - until epoch: 135, best_acc1: 69.200%
2022-07-08 01:59:55 - epoch 136 lr: 0.025000
2022-07-08 02:00:34 - train: epoch 0136, iter [00100, 05004], lr: 0.024986, loss: 1.0995
2022-07-08 02:01:07 - train: epoch 0136, iter [00200, 05004], lr: 0.024972, loss: 1.2234
2022-07-08 02:01:40 - train: epoch 0136, iter [00300, 05004], lr: 0.024958, loss: 1.3922
2022-07-08 02:02:13 - train: epoch 0136, iter [00400, 05004], lr: 0.024944, loss: 1.0564
2022-07-08 02:02:46 - train: epoch 0136, iter [00500, 05004], lr: 0.024930, loss: 1.1362
2022-07-08 02:03:20 - train: epoch 0136, iter [00600, 05004], lr: 0.024916, loss: 1.0341
2022-07-08 02:03:52 - train: epoch 0136, iter [00700, 05004], lr: 0.024902, loss: 1.4347
2022-07-08 02:04:27 - train: epoch 0136, iter [00800, 05004], lr: 0.024889, loss: 1.3647
2022-07-08 02:04:59 - train: epoch 0136, iter [00900, 05004], lr: 0.024875, loss: 1.3850
2022-07-08 02:05:33 - train: epoch 0136, iter [01000, 05004], lr: 0.024861, loss: 1.3028
2022-07-08 02:06:07 - train: epoch 0136, iter [01100, 05004], lr: 0.024847, loss: 1.1218
2022-07-08 02:06:41 - train: epoch 0136, iter [01200, 05004], lr: 0.024833, loss: 1.4029
2022-07-08 02:07:14 - train: epoch 0136, iter [01300, 05004], lr: 0.024819, loss: 1.3770
2022-07-08 02:07:48 - train: epoch 0136, iter [01400, 05004], lr: 0.024805, loss: 1.2770
2022-07-08 02:08:21 - train: epoch 0136, iter [01500, 05004], lr: 0.024791, loss: 1.3585
2022-07-08 02:08:54 - train: epoch 0136, iter [01600, 05004], lr: 0.024777, loss: 1.3453
2022-07-08 02:09:27 - train: epoch 0136, iter [01700, 05004], lr: 0.024763, loss: 1.2881
2022-07-08 02:10:01 - train: epoch 0136, iter [01800, 05004], lr: 0.024749, loss: 1.1921
2022-07-08 02:10:34 - train: epoch 0136, iter [01900, 05004], lr: 0.024736, loss: 1.1032
2022-07-08 02:11:08 - train: epoch 0136, iter [02000, 05004], lr: 0.024722, loss: 1.4041
2022-07-08 02:11:41 - train: epoch 0136, iter [02100, 05004], lr: 0.024708, loss: 1.2102
2022-07-08 02:12:15 - train: epoch 0136, iter [02200, 05004], lr: 0.024694, loss: 1.3455
2022-07-08 02:12:49 - train: epoch 0136, iter [02300, 05004], lr: 0.024680, loss: 1.4567
2022-07-08 02:13:22 - train: epoch 0136, iter [02400, 05004], lr: 0.024666, loss: 1.0805
2022-07-08 02:13:56 - train: epoch 0136, iter [02500, 05004], lr: 0.024652, loss: 1.4877
2022-07-08 02:14:30 - train: epoch 0136, iter [02600, 05004], lr: 0.024638, loss: 1.2702
2022-07-08 02:15:02 - train: epoch 0136, iter [02700, 05004], lr: 0.024625, loss: 1.1887
2022-07-08 02:15:37 - train: epoch 0136, iter [02800, 05004], lr: 0.024611, loss: 1.4222
2022-07-08 02:16:11 - train: epoch 0136, iter [02900, 05004], lr: 0.024597, loss: 1.1768
2022-07-08 02:16:44 - train: epoch 0136, iter [03000, 05004], lr: 0.024583, loss: 1.4281
2022-07-08 02:17:18 - train: epoch 0136, iter [03100, 05004], lr: 0.024569, loss: 1.0665
2022-07-08 02:17:52 - train: epoch 0136, iter [03200, 05004], lr: 0.024555, loss: 1.3998
2022-07-08 02:18:24 - train: epoch 0136, iter [03300, 05004], lr: 0.024541, loss: 1.2272
2022-07-08 02:18:59 - train: epoch 0136, iter [03400, 05004], lr: 0.024528, loss: 1.3444
2022-07-08 02:19:33 - train: epoch 0136, iter [03500, 05004], lr: 0.024514, loss: 1.3412
2022-07-08 02:20:06 - train: epoch 0136, iter [03600, 05004], lr: 0.024500, loss: 1.4964
2022-07-08 02:20:40 - train: epoch 0136, iter [03700, 05004], lr: 0.024486, loss: 1.2750
2022-07-08 02:21:14 - train: epoch 0136, iter [03800, 05004], lr: 0.024472, loss: 1.3703
2022-07-08 02:21:47 - train: epoch 0136, iter [03900, 05004], lr: 0.024458, loss: 1.3224
2022-07-08 02:22:21 - train: epoch 0136, iter [04000, 05004], lr: 0.024444, loss: 1.3598
2022-07-08 02:22:55 - train: epoch 0136, iter [04100, 05004], lr: 0.024431, loss: 1.2890
2022-07-08 02:23:28 - train: epoch 0136, iter [04200, 05004], lr: 0.024417, loss: 1.1879
2022-07-08 02:24:02 - train: epoch 0136, iter [04300, 05004], lr: 0.024403, loss: 1.1149
2022-07-08 02:24:36 - train: epoch 0136, iter [04400, 05004], lr: 0.024389, loss: 1.0410
2022-07-08 02:25:10 - train: epoch 0136, iter [04500, 05004], lr: 0.024375, loss: 1.5452
2022-07-08 02:25:44 - train: epoch 0136, iter [04600, 05004], lr: 0.024361, loss: 1.3673
2022-07-08 02:26:18 - train: epoch 0136, iter [04700, 05004], lr: 0.024348, loss: 1.2810
2022-07-08 02:26:51 - train: epoch 0136, iter [04800, 05004], lr: 0.024334, loss: 1.3693
2022-07-08 02:27:25 - train: epoch 0136, iter [04900, 05004], lr: 0.024320, loss: 1.4565
2022-07-08 02:27:57 - train: epoch 0136, iter [05000, 05004], lr: 0.024306, loss: 1.3901
2022-07-08 02:27:58 - train: epoch 136, train_loss: 1.3014
2022-07-08 02:29:12 - eval: epoch: 136, acc1: 67.280%, acc5: 87.980%, test_loss: 1.3411, per_image_load_time: 2.443ms, per_image_inference_time: 0.457ms
2022-07-08 02:29:13 - until epoch: 136, best_acc1: 69.200%
2022-07-08 02:29:13 - epoch 137 lr: 0.024306
2022-07-08 02:29:51 - train: epoch 0137, iter [00100, 05004], lr: 0.024292, loss: 0.9684
2022-07-08 02:30:26 - train: epoch 0137, iter [00200, 05004], lr: 0.024278, loss: 1.3465
2022-07-08 02:30:59 - train: epoch 0137, iter [00300, 05004], lr: 0.024264, loss: 1.1719
2022-07-08 02:31:32 - train: epoch 0137, iter [00400, 05004], lr: 0.024250, loss: 1.0938
2022-07-08 02:32:05 - train: epoch 0137, iter [00500, 05004], lr: 0.024237, loss: 1.2816
2022-07-08 02:32:39 - train: epoch 0137, iter [00600, 05004], lr: 0.024223, loss: 1.4158
2022-07-08 02:33:13 - train: epoch 0137, iter [00700, 05004], lr: 0.024209, loss: 1.3161
2022-07-08 02:33:46 - train: epoch 0137, iter [00800, 05004], lr: 0.024195, loss: 1.0696
2022-07-08 02:34:20 - train: epoch 0137, iter [00900, 05004], lr: 0.024181, loss: 1.3904
2022-07-08 02:34:54 - train: epoch 0137, iter [01000, 05004], lr: 0.024168, loss: 1.2350
2022-07-08 02:35:27 - train: epoch 0137, iter [01100, 05004], lr: 0.024154, loss: 1.3622
2022-07-08 02:36:01 - train: epoch 0137, iter [01200, 05004], lr: 0.024140, loss: 1.1098
2022-07-08 02:36:35 - train: epoch 0137, iter [01300, 05004], lr: 0.024126, loss: 0.9890
2022-07-08 02:37:08 - train: epoch 0137, iter [01400, 05004], lr: 0.024113, loss: 1.3802
2022-07-08 02:37:42 - train: epoch 0137, iter [01500, 05004], lr: 0.024099, loss: 1.5457
2022-07-08 02:38:16 - train: epoch 0137, iter [01600, 05004], lr: 0.024085, loss: 1.3538
2022-07-08 02:38:49 - train: epoch 0137, iter [01700, 05004], lr: 0.024071, loss: 1.2267
2022-07-08 02:39:23 - train: epoch 0137, iter [01800, 05004], lr: 0.024058, loss: 1.3704
2022-07-08 02:39:56 - train: epoch 0137, iter [01900, 05004], lr: 0.024044, loss: 1.1039
2022-07-08 02:40:31 - train: epoch 0137, iter [02000, 05004], lr: 0.024030, loss: 1.2616
2022-07-08 02:41:04 - train: epoch 0137, iter [02100, 05004], lr: 0.024016, loss: 1.2163
2022-07-08 02:41:38 - train: epoch 0137, iter [02200, 05004], lr: 0.024002, loss: 1.3028
2022-07-08 02:42:10 - train: epoch 0137, iter [02300, 05004], lr: 0.023989, loss: 1.1899
2022-07-08 02:42:46 - train: epoch 0137, iter [02400, 05004], lr: 0.023975, loss: 1.1692
2022-07-08 02:43:19 - train: epoch 0137, iter [02500, 05004], lr: 0.023961, loss: 1.1848
2022-07-08 02:43:52 - train: epoch 0137, iter [02600, 05004], lr: 0.023948, loss: 1.3215
2022-07-08 02:44:26 - train: epoch 0137, iter [02700, 05004], lr: 0.023934, loss: 1.1926
2022-07-08 02:45:00 - train: epoch 0137, iter [02800, 05004], lr: 0.023920, loss: 1.1466
2022-07-08 02:45:33 - train: epoch 0137, iter [02900, 05004], lr: 0.023906, loss: 1.2519
2022-07-08 02:46:07 - train: epoch 0137, iter [03000, 05004], lr: 0.023893, loss: 1.2691
2022-07-08 02:46:40 - train: epoch 0137, iter [03100, 05004], lr: 0.023879, loss: 1.4594
2022-07-08 02:47:14 - train: epoch 0137, iter [03200, 05004], lr: 0.023865, loss: 1.4043
2022-07-08 02:47:48 - train: epoch 0137, iter [03300, 05004], lr: 0.023851, loss: 1.2068
2022-07-08 02:48:21 - train: epoch 0137, iter [03400, 05004], lr: 0.023838, loss: 1.4339
2022-07-08 02:48:55 - train: epoch 0137, iter [03500, 05004], lr: 0.023824, loss: 1.2982
2022-07-08 02:49:28 - train: epoch 0137, iter [03600, 05004], lr: 0.023810, loss: 1.1422
2022-07-08 02:50:02 - train: epoch 0137, iter [03700, 05004], lr: 0.023797, loss: 1.5005
2022-07-08 02:50:36 - train: epoch 0137, iter [03800, 05004], lr: 0.023783, loss: 1.2679
2022-07-08 02:51:09 - train: epoch 0137, iter [03900, 05004], lr: 0.023769, loss: 1.4564
2022-07-08 02:51:43 - train: epoch 0137, iter [04000, 05004], lr: 0.023755, loss: 1.3024
2022-07-08 02:52:17 - train: epoch 0137, iter [04100, 05004], lr: 0.023742, loss: 1.2363
2022-07-08 02:52:51 - train: epoch 0137, iter [04200, 05004], lr: 0.023728, loss: 1.4597
2022-07-08 02:53:25 - train: epoch 0137, iter [04300, 05004], lr: 0.023714, loss: 1.3406
2022-07-08 02:53:59 - train: epoch 0137, iter [04400, 05004], lr: 0.023701, loss: 1.2514
2022-07-08 02:54:33 - train: epoch 0137, iter [04500, 05004], lr: 0.023687, loss: 1.3469
2022-07-08 02:55:07 - train: epoch 0137, iter [04600, 05004], lr: 0.023673, loss: 1.1768
2022-07-08 02:55:40 - train: epoch 0137, iter [04700, 05004], lr: 0.023660, loss: 1.2151
2022-07-08 02:56:14 - train: epoch 0137, iter [04800, 05004], lr: 0.023646, loss: 1.3880
2022-07-08 02:56:47 - train: epoch 0137, iter [04900, 05004], lr: 0.023632, loss: 1.2720
2022-07-08 02:57:20 - train: epoch 0137, iter [05000, 05004], lr: 0.023619, loss: 1.1821
2022-07-08 02:57:21 - train: epoch 137, train_loss: 1.2886
2022-07-08 02:58:36 - eval: epoch: 137, acc1: 69.804%, acc5: 89.484%, test_loss: 1.2391, per_image_load_time: 2.417ms, per_image_inference_time: 0.474ms
2022-07-08 02:58:36 - until epoch: 137, best_acc1: 69.804%
2022-07-08 02:58:36 - epoch 138 lr: 0.023618
2022-07-08 02:59:14 - train: epoch 0138, iter [00100, 05004], lr: 0.023604, loss: 1.0207
2022-07-08 02:59:48 - train: epoch 0138, iter [00200, 05004], lr: 0.023591, loss: 1.2724
2022-07-08 03:00:21 - train: epoch 0138, iter [00300, 05004], lr: 0.023577, loss: 1.3706
2022-07-08 03:00:54 - train: epoch 0138, iter [00400, 05004], lr: 0.023563, loss: 1.2740
2022-07-08 03:01:28 - train: epoch 0138, iter [00500, 05004], lr: 0.023550, loss: 1.1124
2022-07-08 03:02:01 - train: epoch 0138, iter [00600, 05004], lr: 0.023536, loss: 1.3478
2022-07-08 03:02:34 - train: epoch 0138, iter [00700, 05004], lr: 0.023522, loss: 1.1820
2022-07-08 03:03:09 - train: epoch 0138, iter [00800, 05004], lr: 0.023509, loss: 1.0437
2022-07-08 03:03:41 - train: epoch 0138, iter [00900, 05004], lr: 0.023495, loss: 1.3814
2022-07-08 03:04:15 - train: epoch 0138, iter [01000, 05004], lr: 0.023481, loss: 1.1195
2022-07-08 03:04:49 - train: epoch 0138, iter [01100, 05004], lr: 0.023468, loss: 1.3545
2022-07-08 03:05:23 - train: epoch 0138, iter [01200, 05004], lr: 0.023454, loss: 1.3342
2022-07-08 03:05:56 - train: epoch 0138, iter [01300, 05004], lr: 0.023440, loss: 1.2023
2022-07-08 03:06:29 - train: epoch 0138, iter [01400, 05004], lr: 0.023427, loss: 1.3153
2022-07-08 03:07:03 - train: epoch 0138, iter [01500, 05004], lr: 0.023413, loss: 1.2225
2022-07-08 03:07:37 - train: epoch 0138, iter [01600, 05004], lr: 0.023400, loss: 1.2752
2022-07-08 03:08:10 - train: epoch 0138, iter [01700, 05004], lr: 0.023386, loss: 1.2425
2022-07-08 03:08:44 - train: epoch 0138, iter [01800, 05004], lr: 0.023372, loss: 1.0770
2022-07-08 03:09:18 - train: epoch 0138, iter [01900, 05004], lr: 0.023359, loss: 1.3086
2022-07-08 03:09:51 - train: epoch 0138, iter [02000, 05004], lr: 0.023345, loss: 1.4490
2022-07-08 03:10:25 - train: epoch 0138, iter [02100, 05004], lr: 0.023331, loss: 1.2754
2022-07-08 03:10:58 - train: epoch 0138, iter [02200, 05004], lr: 0.023318, loss: 0.9663
2022-07-08 03:11:31 - train: epoch 0138, iter [02300, 05004], lr: 0.023304, loss: 1.1460
2022-07-08 03:12:05 - train: epoch 0138, iter [02400, 05004], lr: 0.023291, loss: 1.2027
2022-07-08 03:12:39 - train: epoch 0138, iter [02500, 05004], lr: 0.023277, loss: 1.1902
2022-07-08 03:13:12 - train: epoch 0138, iter [02600, 05004], lr: 0.023263, loss: 1.5446
2022-07-08 03:13:47 - train: epoch 0138, iter [02700, 05004], lr: 0.023250, loss: 1.2746
2022-07-08 03:14:20 - train: epoch 0138, iter [02800, 05004], lr: 0.023236, loss: 1.2688
2022-07-08 03:14:54 - train: epoch 0138, iter [02900, 05004], lr: 0.023223, loss: 1.3477
2022-07-08 03:15:27 - train: epoch 0138, iter [03000, 05004], lr: 0.023209, loss: 1.3003
2022-07-08 03:16:01 - train: epoch 0138, iter [03100, 05004], lr: 0.023195, loss: 1.4149
2022-07-08 03:16:34 - train: epoch 0138, iter [03200, 05004], lr: 0.023182, loss: 1.3224
2022-07-08 03:17:08 - train: epoch 0138, iter [03300, 05004], lr: 0.023168, loss: 1.3354
2022-07-08 03:17:42 - train: epoch 0138, iter [03400, 05004], lr: 0.023155, loss: 1.1880
2022-07-08 03:18:15 - train: epoch 0138, iter [03500, 05004], lr: 0.023141, loss: 1.2265
2022-07-08 03:18:49 - train: epoch 0138, iter [03600, 05004], lr: 0.023127, loss: 1.4343
2022-07-08 03:19:23 - train: epoch 0138, iter [03700, 05004], lr: 0.023114, loss: 1.3605
2022-07-08 03:19:56 - train: epoch 0138, iter [03800, 05004], lr: 0.023100, loss: 1.4336
2022-07-08 03:20:30 - train: epoch 0138, iter [03900, 05004], lr: 0.023087, loss: 1.3914
2022-07-08 03:21:04 - train: epoch 0138, iter [04000, 05004], lr: 0.023073, loss: 1.3329
2022-07-08 03:21:37 - train: epoch 0138, iter [04100, 05004], lr: 0.023060, loss: 1.1058
2022-07-08 03:22:11 - train: epoch 0138, iter [04200, 05004], lr: 0.023046, loss: 1.3497
2022-07-08 03:22:44 - train: epoch 0138, iter [04300, 05004], lr: 0.023033, loss: 1.2478
2022-07-08 03:23:18 - train: epoch 0138, iter [04400, 05004], lr: 0.023019, loss: 1.0553
2022-07-08 03:23:52 - train: epoch 0138, iter [04500, 05004], lr: 0.023005, loss: 1.2925
2022-07-08 03:24:26 - train: epoch 0138, iter [04600, 05004], lr: 0.022992, loss: 1.3841
2022-07-08 03:24:58 - train: epoch 0138, iter [04700, 05004], lr: 0.022978, loss: 1.0877
2022-07-08 03:25:32 - train: epoch 0138, iter [04800, 05004], lr: 0.022965, loss: 1.2667
2022-07-08 03:26:05 - train: epoch 0138, iter [04900, 05004], lr: 0.022951, loss: 1.3901
2022-07-08 03:26:38 - train: epoch 0138, iter [05000, 05004], lr: 0.022938, loss: 1.4491
2022-07-08 03:26:39 - train: epoch 138, train_loss: 1.2800
2022-07-08 03:27:52 - eval: epoch: 138, acc1: 69.876%, acc5: 89.692%, test_loss: 1.2204, per_image_load_time: 1.435ms, per_image_inference_time: 0.471ms
2022-07-08 03:27:53 - until epoch: 138, best_acc1: 69.876%
2022-07-08 03:27:53 - epoch 139 lr: 0.022937
2022-07-08 03:28:31 - train: epoch 0139, iter [00100, 05004], lr: 0.022924, loss: 1.1243
2022-07-08 03:29:05 - train: epoch 0139, iter [00200, 05004], lr: 0.022910, loss: 1.2212
2022-07-08 03:29:37 - train: epoch 0139, iter [00300, 05004], lr: 0.022897, loss: 1.0835
2022-07-08 03:30:11 - train: epoch 0139, iter [00400, 05004], lr: 0.022883, loss: 1.2077
2022-07-08 03:30:44 - train: epoch 0139, iter [00500, 05004], lr: 0.022870, loss: 1.2605
2022-07-08 03:31:18 - train: epoch 0139, iter [00600, 05004], lr: 0.022856, loss: 1.3215
2022-07-08 03:31:51 - train: epoch 0139, iter [00700, 05004], lr: 0.022842, loss: 1.2628
2022-07-08 03:32:25 - train: epoch 0139, iter [00800, 05004], lr: 0.022829, loss: 1.2717
2022-07-08 03:32:59 - train: epoch 0139, iter [00900, 05004], lr: 0.022815, loss: 1.3947
2022-07-08 03:33:33 - train: epoch 0139, iter [01000, 05004], lr: 0.022802, loss: 1.2393
2022-07-08 03:34:06 - train: epoch 0139, iter [01100, 05004], lr: 0.022788, loss: 1.2286
2022-07-08 03:34:40 - train: epoch 0139, iter [01200, 05004], lr: 0.022775, loss: 1.2536
2022-07-08 03:35:14 - train: epoch 0139, iter [01300, 05004], lr: 0.022761, loss: 1.1558
2022-07-08 03:35:47 - train: epoch 0139, iter [01400, 05004], lr: 0.022748, loss: 1.2610
2022-07-08 03:36:21 - train: epoch 0139, iter [01500, 05004], lr: 0.022734, loss: 1.3326
2022-07-08 03:36:54 - train: epoch 0139, iter [01600, 05004], lr: 0.022721, loss: 1.3440
2022-07-08 03:37:28 - train: epoch 0139, iter [01700, 05004], lr: 0.022707, loss: 1.0618
2022-07-08 03:38:01 - train: epoch 0139, iter [01800, 05004], lr: 0.022694, loss: 1.2317
2022-07-08 03:38:35 - train: epoch 0139, iter [01900, 05004], lr: 0.022680, loss: 1.6001
2022-07-08 03:39:09 - train: epoch 0139, iter [02000, 05004], lr: 0.022667, loss: 1.2567
2022-07-08 03:39:42 - train: epoch 0139, iter [02100, 05004], lr: 0.022654, loss: 1.3389
2022-07-08 03:40:15 - train: epoch 0139, iter [02200, 05004], lr: 0.022640, loss: 1.3812
2022-07-08 03:40:49 - train: epoch 0139, iter [02300, 05004], lr: 0.022627, loss: 1.2789
2022-07-08 03:41:22 - train: epoch 0139, iter [02400, 05004], lr: 0.022613, loss: 1.2488
2022-07-08 03:41:56 - train: epoch 0139, iter [02500, 05004], lr: 0.022600, loss: 1.3005
2022-07-08 03:42:29 - train: epoch 0139, iter [02600, 05004], lr: 0.022586, loss: 1.3271
2022-07-08 03:43:03 - train: epoch 0139, iter [02700, 05004], lr: 0.022573, loss: 1.2738
2022-07-08 03:43:36 - train: epoch 0139, iter [02800, 05004], lr: 0.022559, loss: 1.2652
2022-07-08 03:44:10 - train: epoch 0139, iter [02900, 05004], lr: 0.022546, loss: 1.2621
2022-07-08 03:44:43 - train: epoch 0139, iter [03000, 05004], lr: 0.022532, loss: 1.0325
2022-07-08 03:45:17 - train: epoch 0139, iter [03100, 05004], lr: 0.022519, loss: 1.4443
2022-07-08 03:45:50 - train: epoch 0139, iter [03200, 05004], lr: 0.022505, loss: 1.1412
2022-07-08 03:46:24 - train: epoch 0139, iter [03300, 05004], lr: 0.022492, loss: 1.3107
2022-07-08 03:46:57 - train: epoch 0139, iter [03400, 05004], lr: 0.022479, loss: 1.2041
2022-07-08 03:47:31 - train: epoch 0139, iter [03500, 05004], lr: 0.022465, loss: 1.3747
2022-07-08 03:48:04 - train: epoch 0139, iter [03600, 05004], lr: 0.022452, loss: 1.1698
2022-07-08 03:48:38 - train: epoch 0139, iter [03700, 05004], lr: 0.022438, loss: 1.3907
2022-07-08 03:49:12 - train: epoch 0139, iter [03800, 05004], lr: 0.022425, loss: 1.2787
2022-07-08 03:49:46 - train: epoch 0139, iter [03900, 05004], lr: 0.022411, loss: 1.2070
2022-07-08 03:50:20 - train: epoch 0139, iter [04000, 05004], lr: 0.022398, loss: 1.3365
2022-07-08 03:50:54 - train: epoch 0139, iter [04100, 05004], lr: 0.022385, loss: 1.3467
2022-07-08 03:51:27 - train: epoch 0139, iter [04200, 05004], lr: 0.022371, loss: 1.5780
2022-07-08 03:52:01 - train: epoch 0139, iter [04300, 05004], lr: 0.022358, loss: 1.2148
2022-07-08 03:52:35 - train: epoch 0139, iter [04400, 05004], lr: 0.022344, loss: 1.6112
2022-07-08 03:53:09 - train: epoch 0139, iter [04500, 05004], lr: 0.022331, loss: 1.3972
2022-07-08 03:53:42 - train: epoch 0139, iter [04600, 05004], lr: 0.022317, loss: 1.4153
2022-07-08 03:54:16 - train: epoch 0139, iter [04700, 05004], lr: 0.022304, loss: 1.2677
2022-07-08 03:54:50 - train: epoch 0139, iter [04800, 05004], lr: 0.022291, loss: 1.2900
2022-07-08 03:55:24 - train: epoch 0139, iter [04900, 05004], lr: 0.022277, loss: 1.3881
2022-07-08 03:55:56 - train: epoch 0139, iter [05000, 05004], lr: 0.022264, loss: 1.2353
2022-07-08 03:55:57 - train: epoch 139, train_loss: 1.2701
2022-07-08 03:57:11 - eval: epoch: 139, acc1: 68.272%, acc5: 88.654%, test_loss: 1.2931, per_image_load_time: 2.158ms, per_image_inference_time: 0.478ms
2022-07-08 03:57:12 - until epoch: 139, best_acc1: 69.876%
2022-07-08 03:57:12 - epoch 140 lr: 0.022263
2022-07-08 03:57:51 - train: epoch 0140, iter [00100, 05004], lr: 0.022250, loss: 1.1732
2022-07-08 03:58:24 - train: epoch 0140, iter [00200, 05004], lr: 0.022237, loss: 1.4886
2022-07-08 03:58:57 - train: epoch 0140, iter [00300, 05004], lr: 0.022223, loss: 1.1040
2022-07-08 03:59:31 - train: epoch 0140, iter [00400, 05004], lr: 0.022210, loss: 1.2256
2022-07-08 04:00:04 - train: epoch 0140, iter [00500, 05004], lr: 0.022196, loss: 1.1220
2022-07-08 04:00:38 - train: epoch 0140, iter [00600, 05004], lr: 0.022183, loss: 1.4163
2022-07-08 04:01:11 - train: epoch 0140, iter [00700, 05004], lr: 0.022170, loss: 1.0452
2022-07-08 04:01:45 - train: epoch 0140, iter [00800, 05004], lr: 0.022156, loss: 1.4650
2022-07-08 04:02:18 - train: epoch 0140, iter [00900, 05004], lr: 0.022143, loss: 1.4724
2022-07-08 04:02:52 - train: epoch 0140, iter [01000, 05004], lr: 0.022130, loss: 1.1935
2022-07-08 04:03:25 - train: epoch 0140, iter [01100, 05004], lr: 0.022116, loss: 1.2678
2022-07-08 04:04:00 - train: epoch 0140, iter [01200, 05004], lr: 0.022103, loss: 1.2136
2022-07-08 04:04:33 - train: epoch 0140, iter [01300, 05004], lr: 0.022089, loss: 1.3853
2022-07-08 04:05:06 - train: epoch 0140, iter [01400, 05004], lr: 0.022076, loss: 1.1492
2022-07-08 04:05:40 - train: epoch 0140, iter [01500, 05004], lr: 0.022063, loss: 1.3227
2022-07-08 04:06:14 - train: epoch 0140, iter [01600, 05004], lr: 0.022049, loss: 1.2475
2022-07-08 04:06:48 - train: epoch 0140, iter [01700, 05004], lr: 0.022036, loss: 1.1487
2022-07-08 04:07:22 - train: epoch 0140, iter [01800, 05004], lr: 0.022023, loss: 1.2158
2022-07-08 04:07:55 - train: epoch 0140, iter [01900, 05004], lr: 0.022009, loss: 1.4034
2022-07-08 04:08:29 - train: epoch 0140, iter [02000, 05004], lr: 0.021996, loss: 1.3699
2022-07-08 04:09:04 - train: epoch 0140, iter [02100, 05004], lr: 0.021983, loss: 1.3465
2022-07-08 04:09:37 - train: epoch 0140, iter [02200, 05004], lr: 0.021969, loss: 1.3486
2022-07-08 04:10:11 - train: epoch 0140, iter [02300, 05004], lr: 0.021956, loss: 0.9565
2022-07-08 04:10:44 - train: epoch 0140, iter [02400, 05004], lr: 0.021943, loss: 1.1957
2022-07-08 04:11:18 - train: epoch 0140, iter [02500, 05004], lr: 0.021929, loss: 1.2951
2022-07-08 04:11:52 - train: epoch 0140, iter [02600, 05004], lr: 0.021916, loss: 1.2494
2022-07-08 04:12:26 - train: epoch 0140, iter [02700, 05004], lr: 0.021903, loss: 1.0682
2022-07-08 04:13:00 - train: epoch 0140, iter [02800, 05004], lr: 0.021889, loss: 1.2527
2022-07-08 04:13:34 - train: epoch 0140, iter [02900, 05004], lr: 0.021876, loss: 1.2325
2022-07-08 04:14:08 - train: epoch 0140, iter [03000, 05004], lr: 0.021863, loss: 1.2408
2022-07-08 04:14:42 - train: epoch 0140, iter [03100, 05004], lr: 0.021850, loss: 1.2351
2022-07-08 04:15:16 - train: epoch 0140, iter [03200, 05004], lr: 0.021836, loss: 1.2500
2022-07-08 04:15:50 - train: epoch 0140, iter [03300, 05004], lr: 0.021823, loss: 1.3464
2022-07-08 04:16:23 - train: epoch 0140, iter [03400, 05004], lr: 0.021810, loss: 1.3384
2022-07-08 04:16:57 - train: epoch 0140, iter [03500, 05004], lr: 0.021796, loss: 1.2741
2022-07-08 04:17:30 - train: epoch 0140, iter [03600, 05004], lr: 0.021783, loss: 1.0816
2022-07-08 04:18:04 - train: epoch 0140, iter [03700, 05004], lr: 0.021770, loss: 1.1941
2022-07-08 04:18:39 - train: epoch 0140, iter [03800, 05004], lr: 0.021756, loss: 1.3802
2022-07-08 04:19:12 - train: epoch 0140, iter [03900, 05004], lr: 0.021743, loss: 1.3164
2022-07-08 04:19:45 - train: epoch 0140, iter [04000, 05004], lr: 0.021730, loss: 1.3678
2022-07-08 04:20:19 - train: epoch 0140, iter [04100, 05004], lr: 0.021717, loss: 1.2841
2022-07-08 04:20:53 - train: epoch 0140, iter [04200, 05004], lr: 0.021703, loss: 1.0183
2022-07-08 04:21:26 - train: epoch 0140, iter [04300, 05004], lr: 0.021690, loss: 1.5157
2022-07-08 04:22:00 - train: epoch 0140, iter [04400, 05004], lr: 0.021677, loss: 1.3500
2022-07-08 04:22:33 - train: epoch 0140, iter [04500, 05004], lr: 0.021664, loss: 1.2272
2022-07-08 04:23:08 - train: epoch 0140, iter [04600, 05004], lr: 0.021650, loss: 1.0688
2022-07-08 04:23:41 - train: epoch 0140, iter [04700, 05004], lr: 0.021637, loss: 1.2165
2022-07-08 04:24:14 - train: epoch 0140, iter [04800, 05004], lr: 0.021624, loss: 1.5223
2022-07-08 04:24:48 - train: epoch 0140, iter [04900, 05004], lr: 0.021611, loss: 1.2750
2022-07-08 04:25:21 - train: epoch 0140, iter [05000, 05004], lr: 0.021597, loss: 1.3729
2022-07-08 04:25:22 - train: epoch 140, train_loss: 1.2604
2022-07-08 04:26:36 - eval: epoch: 140, acc1: 69.862%, acc5: 89.848%, test_loss: 1.2192, per_image_load_time: 2.212ms, per_image_inference_time: 0.468ms
2022-07-08 04:26:36 - until epoch: 140, best_acc1: 69.876%
2022-07-08 04:26:36 - epoch 141 lr: 0.021597
2022-07-08 04:27:15 - train: epoch 0141, iter [00100, 05004], lr: 0.021584, loss: 1.1631
2022-07-08 04:27:48 - train: epoch 0141, iter [00200, 05004], lr: 0.021570, loss: 1.0977
2022-07-08 04:28:21 - train: epoch 0141, iter [00300, 05004], lr: 0.021557, loss: 1.4394
2022-07-08 04:28:54 - train: epoch 0141, iter [00400, 05004], lr: 0.021544, loss: 1.2327
2022-07-08 04:29:28 - train: epoch 0141, iter [00500, 05004], lr: 0.021531, loss: 1.0477
2022-07-08 04:30:02 - train: epoch 0141, iter [00600, 05004], lr: 0.021517, loss: 1.3689
2022-07-08 04:30:35 - train: epoch 0141, iter [00700, 05004], lr: 0.021504, loss: 1.2836
2022-07-08 04:31:08 - train: epoch 0141, iter [00800, 05004], lr: 0.021491, loss: 1.2296
2022-07-08 04:31:41 - train: epoch 0141, iter [00900, 05004], lr: 0.021478, loss: 1.1931
2022-07-08 04:32:15 - train: epoch 0141, iter [01000, 05004], lr: 0.021464, loss: 1.2005
2022-07-08 04:32:48 - train: epoch 0141, iter [01100, 05004], lr: 0.021451, loss: 1.2670
2022-07-08 04:33:22 - train: epoch 0141, iter [01200, 05004], lr: 0.021438, loss: 1.4535
2022-07-08 04:33:55 - train: epoch 0141, iter [01300, 05004], lr: 0.021425, loss: 1.3384
2022-07-08 04:34:29 - train: epoch 0141, iter [01400, 05004], lr: 0.021412, loss: 1.1326
2022-07-08 04:35:02 - train: epoch 0141, iter [01500, 05004], lr: 0.021398, loss: 1.3096
2022-07-08 04:35:36 - train: epoch 0141, iter [01600, 05004], lr: 0.021385, loss: 1.1639
2022-07-08 04:36:09 - train: epoch 0141, iter [01700, 05004], lr: 0.021372, loss: 1.0773
2022-07-08 04:36:43 - train: epoch 0141, iter [01800, 05004], lr: 0.021359, loss: 1.2404
2022-07-08 04:37:16 - train: epoch 0141, iter [01900, 05004], lr: 0.021346, loss: 1.1851
2022-07-08 04:37:51 - train: epoch 0141, iter [02000, 05004], lr: 0.021332, loss: 1.3129
2022-07-08 04:38:24 - train: epoch 0141, iter [02100, 05004], lr: 0.021319, loss: 1.1381
2022-07-08 04:38:57 - train: epoch 0141, iter [02200, 05004], lr: 0.021306, loss: 1.3346
2022-07-08 04:39:31 - train: epoch 0141, iter [02300, 05004], lr: 0.021293, loss: 1.1549
2022-07-08 04:40:05 - train: epoch 0141, iter [02400, 05004], lr: 0.021280, loss: 1.4242
2022-07-08 04:40:38 - train: epoch 0141, iter [02500, 05004], lr: 0.021266, loss: 1.5755
2022-07-08 04:41:12 - train: epoch 0141, iter [02600, 05004], lr: 0.021253, loss: 1.3794
2022-07-08 04:41:45 - train: epoch 0141, iter [02700, 05004], lr: 0.021240, loss: 1.1649
2022-07-08 04:42:19 - train: epoch 0141, iter [02800, 05004], lr: 0.021227, loss: 1.2128
2022-07-08 04:42:53 - train: epoch 0141, iter [02900, 05004], lr: 0.021214, loss: 1.2348
2022-07-08 04:43:26 - train: epoch 0141, iter [03000, 05004], lr: 0.021201, loss: 1.1391
2022-07-08 04:44:00 - train: epoch 0141, iter [03100, 05004], lr: 0.021187, loss: 1.3385
2022-07-08 04:44:33 - train: epoch 0141, iter [03200, 05004], lr: 0.021174, loss: 1.2548
2022-07-08 04:45:07 - train: epoch 0141, iter [03300, 05004], lr: 0.021161, loss: 1.3605
2022-07-08 04:45:41 - train: epoch 0141, iter [03400, 05004], lr: 0.021148, loss: 1.4376
2022-07-08 04:46:14 - train: epoch 0141, iter [03500, 05004], lr: 0.021135, loss: 1.3689
2022-07-08 04:46:47 - train: epoch 0141, iter [03600, 05004], lr: 0.021122, loss: 1.1334
2022-07-08 04:47:21 - train: epoch 0141, iter [03700, 05004], lr: 0.021109, loss: 1.2846
2022-07-08 04:47:55 - train: epoch 0141, iter [03800, 05004], lr: 0.021095, loss: 1.1751
2022-07-08 04:48:29 - train: epoch 0141, iter [03900, 05004], lr: 0.021082, loss: 1.2113
2022-07-08 04:49:02 - train: epoch 0141, iter [04000, 05004], lr: 0.021069, loss: 1.3856
2022-07-08 04:49:35 - train: epoch 0141, iter [04100, 05004], lr: 0.021056, loss: 1.2342
2022-07-08 04:50:10 - train: epoch 0141, iter [04200, 05004], lr: 0.021043, loss: 1.3252
2022-07-08 04:50:43 - train: epoch 0141, iter [04300, 05004], lr: 0.021030, loss: 1.4358
2022-07-08 04:51:16 - train: epoch 0141, iter [04400, 05004], lr: 0.021017, loss: 1.4537
2022-07-08 04:51:49 - train: epoch 0141, iter [04500, 05004], lr: 0.021004, loss: 1.2863
2022-07-08 04:52:24 - train: epoch 0141, iter [04600, 05004], lr: 0.020990, loss: 1.3277
2022-07-08 04:52:57 - train: epoch 0141, iter [04700, 05004], lr: 0.020977, loss: 1.4115
2022-07-08 04:53:31 - train: epoch 0141, iter [04800, 05004], lr: 0.020964, loss: 1.3794
2022-07-08 04:54:03 - train: epoch 0141, iter [04900, 05004], lr: 0.020951, loss: 1.3095
2022-07-08 04:54:36 - train: epoch 0141, iter [05000, 05004], lr: 0.020938, loss: 1.4338
2022-07-08 04:54:37 - train: epoch 141, train_loss: 1.2473
2022-07-08 04:55:52 - eval: epoch: 141, acc1: 69.668%, acc5: 89.556%, test_loss: 1.2309, per_image_load_time: 2.444ms, per_image_inference_time: 0.455ms
2022-07-08 04:55:53 - until epoch: 141, best_acc1: 69.876%
2022-07-08 04:55:53 - epoch 142 lr: 0.020937
2022-07-08 04:56:31 - train: epoch 0142, iter [00100, 05004], lr: 0.020924, loss: 1.3019
2022-07-08 04:57:05 - train: epoch 0142, iter [00200, 05004], lr: 0.020911, loss: 1.2043
2022-07-08 04:57:38 - train: epoch 0142, iter [00300, 05004], lr: 0.020898, loss: 1.1628
2022-07-08 04:58:12 - train: epoch 0142, iter [00400, 05004], lr: 0.020885, loss: 1.2441
2022-07-08 04:58:46 - train: epoch 0142, iter [00500, 05004], lr: 0.020872, loss: 1.1050
2022-07-08 04:59:19 - train: epoch 0142, iter [00600, 05004], lr: 0.020859, loss: 1.2933
2022-07-08 04:59:52 - train: epoch 0142, iter [00700, 05004], lr: 0.020846, loss: 1.2235
2022-07-08 05:00:27 - train: epoch 0142, iter [00800, 05004], lr: 0.020833, loss: 1.3268
2022-07-08 05:01:00 - train: epoch 0142, iter [00900, 05004], lr: 0.020820, loss: 1.1043
2022-07-08 05:01:33 - train: epoch 0142, iter [01000, 05004], lr: 0.020807, loss: 1.2968
2022-07-08 05:02:08 - train: epoch 0142, iter [01100, 05004], lr: 0.020794, loss: 1.0662
2022-07-08 05:02:41 - train: epoch 0142, iter [01200, 05004], lr: 0.020781, loss: 1.2966
2022-07-08 05:03:15 - train: epoch 0142, iter [01300, 05004], lr: 0.020767, loss: 1.1799
2022-07-08 05:03:48 - train: epoch 0142, iter [01400, 05004], lr: 0.020754, loss: 1.3093
2022-07-08 05:04:22 - train: epoch 0142, iter [01500, 05004], lr: 0.020741, loss: 1.2789
2022-07-08 05:04:56 - train: epoch 0142, iter [01600, 05004], lr: 0.020728, loss: 1.3186
2022-07-08 05:05:30 - train: epoch 0142, iter [01700, 05004], lr: 0.020715, loss: 1.1472
2022-07-08 05:06:03 - train: epoch 0142, iter [01800, 05004], lr: 0.020702, loss: 1.3698
2022-07-08 05:06:37 - train: epoch 0142, iter [01900, 05004], lr: 0.020689, loss: 1.1917
2022-07-08 05:07:10 - train: epoch 0142, iter [02000, 05004], lr: 0.020676, loss: 1.3826
2022-07-08 05:07:44 - train: epoch 0142, iter [02100, 05004], lr: 0.020663, loss: 1.1662
2022-07-08 05:08:18 - train: epoch 0142, iter [02200, 05004], lr: 0.020650, loss: 1.2956
2022-07-08 05:08:52 - train: epoch 0142, iter [02300, 05004], lr: 0.020637, loss: 1.2315
2022-07-08 05:09:26 - train: epoch 0142, iter [02400, 05004], lr: 0.020624, loss: 1.0576
2022-07-08 05:09:59 - train: epoch 0142, iter [02500, 05004], lr: 0.020611, loss: 1.2490
2022-07-08 05:10:33 - train: epoch 0142, iter [02600, 05004], lr: 0.020598, loss: 1.2429
2022-07-08 05:11:06 - train: epoch 0142, iter [02700, 05004], lr: 0.020585, loss: 1.2586
2022-07-08 05:11:40 - train: epoch 0142, iter [02800, 05004], lr: 0.020572, loss: 1.1095
2022-07-08 05:12:14 - train: epoch 0142, iter [02900, 05004], lr: 0.020559, loss: 1.0877
2022-07-08 05:12:48 - train: epoch 0142, iter [03000, 05004], lr: 0.020546, loss: 1.4550
2022-07-08 05:13:21 - train: epoch 0142, iter [03100, 05004], lr: 0.020533, loss: 1.3388
2022-07-08 05:13:54 - train: epoch 0142, iter [03200, 05004], lr: 0.020520, loss: 1.3589
2022-07-08 05:14:28 - train: epoch 0142, iter [03300, 05004], lr: 0.020507, loss: 1.2187
2022-07-08 05:15:01 - train: epoch 0142, iter [03400, 05004], lr: 0.020494, loss: 1.1965
2022-07-08 05:15:35 - train: epoch 0142, iter [03500, 05004], lr: 0.020481, loss: 1.2843
2022-07-08 05:16:09 - train: epoch 0142, iter [03600, 05004], lr: 0.020468, loss: 1.0535
2022-07-08 05:16:43 - train: epoch 0142, iter [03700, 05004], lr: 0.020455, loss: 1.3829
2022-07-08 05:17:17 - train: epoch 0142, iter [03800, 05004], lr: 0.020442, loss: 1.3230
2022-07-08 05:17:50 - train: epoch 0142, iter [03900, 05004], lr: 0.020429, loss: 1.2241
2022-07-08 05:18:23 - train: epoch 0142, iter [04000, 05004], lr: 0.020416, loss: 1.1112
2022-07-08 05:18:58 - train: epoch 0142, iter [04100, 05004], lr: 0.020403, loss: 1.2683
2022-07-08 05:19:32 - train: epoch 0142, iter [04200, 05004], lr: 0.020390, loss: 1.1644
2022-07-08 05:20:06 - train: epoch 0142, iter [04300, 05004], lr: 0.020377, loss: 1.0665
2022-07-08 05:20:39 - train: epoch 0142, iter [04400, 05004], lr: 0.020364, loss: 1.1208
2022-07-08 05:21:13 - train: epoch 0142, iter [04500, 05004], lr: 0.020351, loss: 1.2465
2022-07-08 05:21:47 - train: epoch 0142, iter [04600, 05004], lr: 0.020338, loss: 1.4022
2022-07-08 05:22:21 - train: epoch 0142, iter [04700, 05004], lr: 0.020325, loss: 1.4543
2022-07-08 05:22:54 - train: epoch 0142, iter [04800, 05004], lr: 0.020312, loss: 1.0860
2022-07-08 05:23:29 - train: epoch 0142, iter [04900, 05004], lr: 0.020299, loss: 1.3851
2022-07-08 05:24:01 - train: epoch 0142, iter [05000, 05004], lr: 0.020286, loss: 1.3091
2022-07-08 05:24:02 - train: epoch 142, train_loss: 1.2375
2022-07-08 05:25:17 - eval: epoch: 142, acc1: 70.690%, acc5: 90.172%, test_loss: 1.1941, per_image_load_time: 1.243ms, per_image_inference_time: 0.464ms
2022-07-08 05:25:17 - until epoch: 142, best_acc1: 70.690%
2022-07-08 05:25:17 - epoch 143 lr: 0.020286
2022-07-08 05:25:56 - train: epoch 0143, iter [00100, 05004], lr: 0.020273, loss: 1.1909
2022-07-08 05:26:30 - train: epoch 0143, iter [00200, 05004], lr: 0.020260, loss: 1.1365
2022-07-08 05:27:02 - train: epoch 0143, iter [00300, 05004], lr: 0.020247, loss: 1.0411
2022-07-08 05:27:35 - train: epoch 0143, iter [00400, 05004], lr: 0.020234, loss: 1.1993
2022-07-08 05:28:10 - train: epoch 0143, iter [00500, 05004], lr: 0.020221, loss: 1.3532
2022-07-08 05:28:43 - train: epoch 0143, iter [00600, 05004], lr: 0.020208, loss: 1.1752
2022-07-08 05:29:17 - train: epoch 0143, iter [00700, 05004], lr: 0.020195, loss: 1.1405
2022-07-08 05:29:50 - train: epoch 0143, iter [00800, 05004], lr: 0.020182, loss: 1.0747
2022-07-08 05:30:23 - train: epoch 0143, iter [00900, 05004], lr: 0.020169, loss: 1.2975
2022-07-08 05:30:58 - train: epoch 0143, iter [01000, 05004], lr: 0.020157, loss: 1.2967
2022-07-08 05:31:30 - train: epoch 0143, iter [01100, 05004], lr: 0.020144, loss: 1.0691
2022-07-08 05:32:05 - train: epoch 0143, iter [01200, 05004], lr: 0.020131, loss: 1.2921
2022-07-08 05:32:38 - train: epoch 0143, iter [01300, 05004], lr: 0.020118, loss: 1.2379
2022-07-08 05:33:12 - train: epoch 0143, iter [01400, 05004], lr: 0.020105, loss: 1.2589
2022-07-08 05:33:45 - train: epoch 0143, iter [01500, 05004], lr: 0.020092, loss: 1.2359
2022-07-08 05:34:18 - train: epoch 0143, iter [01600, 05004], lr: 0.020079, loss: 1.2863
2022-07-08 05:34:52 - train: epoch 0143, iter [01700, 05004], lr: 0.020066, loss: 1.2388
2022-07-08 05:35:26 - train: epoch 0143, iter [01800, 05004], lr: 0.020053, loss: 1.2241
2022-07-08 05:36:00 - train: epoch 0143, iter [01900, 05004], lr: 0.020040, loss: 1.0313
2022-07-08 05:36:33 - train: epoch 0143, iter [02000, 05004], lr: 0.020028, loss: 1.1428
2022-07-08 05:37:07 - train: epoch 0143, iter [02100, 05004], lr: 0.020015, loss: 1.2645
2022-07-08 05:37:41 - train: epoch 0143, iter [02200, 05004], lr: 0.020002, loss: 1.4042
2022-07-08 05:38:14 - train: epoch 0143, iter [02300, 05004], lr: 0.019989, loss: 1.3364
2022-07-08 05:38:48 - train: epoch 0143, iter [02400, 05004], lr: 0.019976, loss: 1.1776
2022-07-08 05:39:22 - train: epoch 0143, iter [02500, 05004], lr: 0.019963, loss: 1.2426
2022-07-08 05:39:55 - train: epoch 0143, iter [02600, 05004], lr: 0.019950, loss: 1.1702
2022-07-08 05:40:29 - train: epoch 0143, iter [02700, 05004], lr: 0.019937, loss: 1.3005
2022-07-08 05:41:03 - train: epoch 0143, iter [02800, 05004], lr: 0.019925, loss: 1.3509
2022-07-08 05:41:36 - train: epoch 0143, iter [02900, 05004], lr: 0.019912, loss: 1.3339
2022-07-08 05:42:11 - train: epoch 0143, iter [03000, 05004], lr: 0.019899, loss: 1.3221
2022-07-08 05:42:44 - train: epoch 0143, iter [03100, 05004], lr: 0.019886, loss: 1.0861
2022-07-08 05:43:18 - train: epoch 0143, iter [03200, 05004], lr: 0.019873, loss: 1.3390
2022-07-08 05:43:51 - train: epoch 0143, iter [03300, 05004], lr: 0.019860, loss: 1.2466
2022-07-08 05:44:24 - train: epoch 0143, iter [03400, 05004], lr: 0.019847, loss: 1.1564
2022-07-08 05:44:59 - train: epoch 0143, iter [03500, 05004], lr: 0.019835, loss: 1.2830
2022-07-08 05:45:32 - train: epoch 0143, iter [03600, 05004], lr: 0.019822, loss: 1.5211
2022-07-08 05:46:06 - train: epoch 0143, iter [03700, 05004], lr: 0.019809, loss: 1.3520
2022-07-08 05:46:40 - train: epoch 0143, iter [03800, 05004], lr: 0.019796, loss: 1.3107
2022-07-08 05:47:14 - train: epoch 0143, iter [03900, 05004], lr: 0.019783, loss: 0.9918
2022-07-08 05:47:47 - train: epoch 0143, iter [04000, 05004], lr: 0.019770, loss: 1.3926
2022-07-08 05:48:21 - train: epoch 0143, iter [04100, 05004], lr: 0.019758, loss: 1.3322
2022-07-08 05:48:54 - train: epoch 0143, iter [04200, 05004], lr: 0.019745, loss: 0.9979
2022-07-08 05:49:28 - train: epoch 0143, iter [04300, 05004], lr: 0.019732, loss: 1.4800
2022-07-08 05:50:00 - train: epoch 0143, iter [04400, 05004], lr: 0.019719, loss: 1.3414
2022-07-08 05:50:34 - train: epoch 0143, iter [04500, 05004], lr: 0.019706, loss: 1.2148
2022-07-08 05:51:08 - train: epoch 0143, iter [04600, 05004], lr: 0.019694, loss: 1.6749
2022-07-08 05:51:42 - train: epoch 0143, iter [04700, 05004], lr: 0.019681, loss: 1.2332
2022-07-08 05:52:16 - train: epoch 0143, iter [04800, 05004], lr: 0.019668, loss: 1.1836
2022-07-08 05:52:49 - train: epoch 0143, iter [04900, 05004], lr: 0.019655, loss: 0.9658
2022-07-08 05:53:22 - train: epoch 0143, iter [05000, 05004], lr: 0.019642, loss: 1.2699
2022-07-08 05:53:23 - train: epoch 143, train_loss: 1.2291
2022-07-08 05:54:38 - eval: epoch: 143, acc1: 68.228%, acc5: 88.906%, test_loss: 1.2838, per_image_load_time: 2.411ms, per_image_inference_time: 0.459ms
2022-07-08 05:54:38 - until epoch: 143, best_acc1: 70.690%
2022-07-08 05:54:38 - epoch 144 lr: 0.019642
2022-07-08 05:55:17 - train: epoch 0144, iter [00100, 05004], lr: 0.019629, loss: 1.0905
2022-07-08 05:55:50 - train: epoch 0144, iter [00200, 05004], lr: 0.019616, loss: 1.1811
2022-07-08 05:56:23 - train: epoch 0144, iter [00300, 05004], lr: 0.019604, loss: 1.1778
2022-07-08 05:56:56 - train: epoch 0144, iter [00400, 05004], lr: 0.019591, loss: 1.1391
2022-07-08 05:57:30 - train: epoch 0144, iter [00500, 05004], lr: 0.019578, loss: 1.3478
2022-07-08 05:58:03 - train: epoch 0144, iter [00600, 05004], lr: 0.019565, loss: 1.0715
2022-07-08 05:58:37 - train: epoch 0144, iter [00700, 05004], lr: 0.019552, loss: 1.1667
2022-07-08 05:59:09 - train: epoch 0144, iter [00800, 05004], lr: 0.019540, loss: 1.6180
2022-07-08 05:59:43 - train: epoch 0144, iter [00900, 05004], lr: 0.019527, loss: 1.0354
2022-07-08 06:00:17 - train: epoch 0144, iter [01000, 05004], lr: 0.019514, loss: 1.1922
2022-07-08 06:00:50 - train: epoch 0144, iter [01100, 05004], lr: 0.019501, loss: 1.4209
2022-07-08 06:01:23 - train: epoch 0144, iter [01200, 05004], lr: 0.019489, loss: 1.1404
2022-07-08 06:01:57 - train: epoch 0144, iter [01300, 05004], lr: 0.019476, loss: 1.3317
2022-07-08 06:02:30 - train: epoch 0144, iter [01400, 05004], lr: 0.019463, loss: 1.2095
2022-07-08 06:03:05 - train: epoch 0144, iter [01500, 05004], lr: 0.019450, loss: 1.2259
2022-07-08 06:03:38 - train: epoch 0144, iter [01600, 05004], lr: 0.019438, loss: 0.9949
2022-07-08 06:04:11 - train: epoch 0144, iter [01700, 05004], lr: 0.019425, loss: 1.0928
2022-07-08 06:04:44 - train: epoch 0144, iter [01800, 05004], lr: 0.019412, loss: 1.0529
2022-07-08 06:05:18 - train: epoch 0144, iter [01900, 05004], lr: 0.019399, loss: 1.1186
2022-07-08 06:05:52 - train: epoch 0144, iter [02000, 05004], lr: 0.019387, loss: 1.2079
2022-07-08 06:06:26 - train: epoch 0144, iter [02100, 05004], lr: 0.019374, loss: 1.1688
2022-07-08 06:06:59 - train: epoch 0144, iter [02200, 05004], lr: 0.019361, loss: 1.1858
2022-07-08 06:07:33 - train: epoch 0144, iter [02300, 05004], lr: 0.019349, loss: 0.9568
2022-07-08 06:08:07 - train: epoch 0144, iter [02400, 05004], lr: 0.019336, loss: 1.2276
2022-07-08 06:08:41 - train: epoch 0144, iter [02500, 05004], lr: 0.019323, loss: 1.0514
2022-07-08 06:09:15 - train: epoch 0144, iter [02600, 05004], lr: 0.019310, loss: 1.2705
2022-07-08 06:09:48 - train: epoch 0144, iter [02700, 05004], lr: 0.019298, loss: 0.9994
2022-07-08 06:10:21 - train: epoch 0144, iter [02800, 05004], lr: 0.019285, loss: 1.1930
2022-07-08 06:10:55 - train: epoch 0144, iter [02900, 05004], lr: 0.019272, loss: 1.1505
2022-07-08 06:11:29 - train: epoch 0144, iter [03000, 05004], lr: 0.019260, loss: 1.3891
2022-07-08 06:12:02 - train: epoch 0144, iter [03100, 05004], lr: 0.019247, loss: 1.1129
2022-07-08 06:12:36 - train: epoch 0144, iter [03200, 05004], lr: 0.019234, loss: 1.3026
2022-07-08 06:13:11 - train: epoch 0144, iter [03300, 05004], lr: 0.019221, loss: 1.2868
2022-07-08 06:13:43 - train: epoch 0144, iter [03400, 05004], lr: 0.019209, loss: 1.3691
2022-07-08 06:14:17 - train: epoch 0144, iter [03500, 05004], lr: 0.019196, loss: 1.3834
2022-07-08 06:14:51 - train: epoch 0144, iter [03600, 05004], lr: 0.019183, loss: 1.3162
2022-07-08 06:15:24 - train: epoch 0144, iter [03700, 05004], lr: 0.019171, loss: 1.2181
2022-07-08 06:15:58 - train: epoch 0144, iter [03800, 05004], lr: 0.019158, loss: 1.1358
2022-07-08 06:16:32 - train: epoch 0144, iter [03900, 05004], lr: 0.019145, loss: 1.0123
2022-07-08 06:17:06 - train: epoch 0144, iter [04000, 05004], lr: 0.019133, loss: 1.1525
2022-07-08 06:17:40 - train: epoch 0144, iter [04100, 05004], lr: 0.019120, loss: 1.4993
2022-07-08 06:18:14 - train: epoch 0144, iter [04200, 05004], lr: 0.019107, loss: 1.2322
2022-07-08 06:18:48 - train: epoch 0144, iter [04300, 05004], lr: 0.019095, loss: 1.2258
2022-07-08 06:19:21 - train: epoch 0144, iter [04400, 05004], lr: 0.019082, loss: 1.2422
2022-07-08 06:19:55 - train: epoch 0144, iter [04500, 05004], lr: 0.019069, loss: 1.0647
2022-07-08 06:20:29 - train: epoch 0144, iter [04600, 05004], lr: 0.019057, loss: 1.1348
2022-07-08 06:21:02 - train: epoch 0144, iter [04700, 05004], lr: 0.019044, loss: 1.1468
2022-07-08 06:21:37 - train: epoch 0144, iter [04800, 05004], lr: 0.019032, loss: 1.2919
2022-07-08 06:22:10 - train: epoch 0144, iter [04900, 05004], lr: 0.019019, loss: 1.3697
2022-07-08 06:22:43 - train: epoch 0144, iter [05000, 05004], lr: 0.019006, loss: 1.2451
2022-07-08 06:22:44 - train: epoch 144, train_loss: 1.2173
2022-07-08 06:23:58 - eval: epoch: 144, acc1: 70.620%, acc5: 90.146%, test_loss: 1.1866, per_image_load_time: 1.604ms, per_image_inference_time: 0.470ms
2022-07-08 06:23:58 - until epoch: 144, best_acc1: 70.690%
2022-07-08 06:23:58 - epoch 145 lr: 0.019006
2022-07-08 06:24:37 - train: epoch 0145, iter [00100, 05004], lr: 0.018993, loss: 1.0195
2022-07-08 06:25:10 - train: epoch 0145, iter [00200, 05004], lr: 0.018981, loss: 1.0195
2022-07-08 06:25:43 - train: epoch 0145, iter [00300, 05004], lr: 0.018968, loss: 1.2202
2022-07-08 06:26:16 - train: epoch 0145, iter [00400, 05004], lr: 0.018955, loss: 1.1695
2022-07-08 06:26:50 - train: epoch 0145, iter [00500, 05004], lr: 0.018943, loss: 1.4136
2022-07-08 06:27:24 - train: epoch 0145, iter [00600, 05004], lr: 0.018930, loss: 1.2351
2022-07-08 06:27:58 - train: epoch 0145, iter [00700, 05004], lr: 0.018917, loss: 1.3026
2022-07-08 06:28:30 - train: epoch 0145, iter [00800, 05004], lr: 0.018905, loss: 1.2453
2022-07-08 06:29:04 - train: epoch 0145, iter [00900, 05004], lr: 0.018892, loss: 1.0777
2022-07-08 06:29:38 - train: epoch 0145, iter [01000, 05004], lr: 0.018880, loss: 1.1934
2022-07-08 06:30:11 - train: epoch 0145, iter [01100, 05004], lr: 0.018867, loss: 1.2426
2022-07-08 06:30:46 - train: epoch 0145, iter [01200, 05004], lr: 0.018854, loss: 1.3091
2022-07-08 06:31:18 - train: epoch 0145, iter [01300, 05004], lr: 0.018842, loss: 1.3137
2022-07-08 06:31:52 - train: epoch 0145, iter [01400, 05004], lr: 0.018829, loss: 1.1406
2022-07-08 06:32:26 - train: epoch 0145, iter [01500, 05004], lr: 0.018817, loss: 1.4595
2022-07-08 06:32:58 - train: epoch 0145, iter [01600, 05004], lr: 0.018804, loss: 1.2112
2022-07-08 06:33:32 - train: epoch 0145, iter [01700, 05004], lr: 0.018792, loss: 1.4474
2022-07-08 06:34:06 - train: epoch 0145, iter [01800, 05004], lr: 0.018779, loss: 1.1767
2022-07-08 06:34:39 - train: epoch 0145, iter [01900, 05004], lr: 0.018766, loss: 1.2393
2022-07-08 06:35:13 - train: epoch 0145, iter [02000, 05004], lr: 0.018754, loss: 1.1659
2022-07-08 06:35:47 - train: epoch 0145, iter [02100, 05004], lr: 0.018741, loss: 1.3418
2022-07-08 06:36:21 - train: epoch 0145, iter [02200, 05004], lr: 0.018729, loss: 1.1730
2022-07-08 06:36:54 - train: epoch 0145, iter [02300, 05004], lr: 0.018716, loss: 1.3092
2022-07-08 06:37:28 - train: epoch 0145, iter [02400, 05004], lr: 0.018704, loss: 1.2912
2022-07-08 06:38:01 - train: epoch 0145, iter [02500, 05004], lr: 0.018691, loss: 1.0089
2022-07-08 06:38:35 - train: epoch 0145, iter [02600, 05004], lr: 0.018678, loss: 1.1807
2022-07-08 06:39:08 - train: epoch 0145, iter [02700, 05004], lr: 0.018666, loss: 1.2538
2022-07-08 06:39:42 - train: epoch 0145, iter [02800, 05004], lr: 0.018653, loss: 1.2851
2022-07-08 06:40:16 - train: epoch 0145, iter [02900, 05004], lr: 0.018641, loss: 1.3254
2022-07-08 06:40:49 - train: epoch 0145, iter [03000, 05004], lr: 0.018628, loss: 1.1324
2022-07-08 06:41:23 - train: epoch 0145, iter [03100, 05004], lr: 0.018616, loss: 1.3368
2022-07-08 06:41:56 - train: epoch 0145, iter [03200, 05004], lr: 0.018603, loss: 1.3685
2022-07-08 06:42:30 - train: epoch 0145, iter [03300, 05004], lr: 0.018591, loss: 1.3545
2022-07-08 06:43:04 - train: epoch 0145, iter [03400, 05004], lr: 0.018578, loss: 1.2533
2022-07-08 06:43:38 - train: epoch 0145, iter [03500, 05004], lr: 0.018566, loss: 1.0635
2022-07-08 06:44:11 - train: epoch 0145, iter [03600, 05004], lr: 0.018553, loss: 1.2823
2022-07-08 06:44:45 - train: epoch 0145, iter [03700, 05004], lr: 0.018541, loss: 1.0900
2022-07-08 06:45:19 - train: epoch 0145, iter [03800, 05004], lr: 0.018528, loss: 1.2484
2022-07-08 06:45:53 - train: epoch 0145, iter [03900, 05004], lr: 0.018516, loss: 1.2080
2022-07-08 06:46:25 - train: epoch 0145, iter [04000, 05004], lr: 0.018503, loss: 1.2073
2022-07-08 06:46:59 - train: epoch 0145, iter [04100, 05004], lr: 0.018491, loss: 1.2985
2022-07-08 06:47:33 - train: epoch 0145, iter [04200, 05004], lr: 0.018478, loss: 1.3779
2022-07-08 06:48:06 - train: epoch 0145, iter [04300, 05004], lr: 0.018466, loss: 1.1622
2022-07-08 06:48:39 - train: epoch 0145, iter [04400, 05004], lr: 0.018453, loss: 0.9718
2022-07-08 06:49:13 - train: epoch 0145, iter [04500, 05004], lr: 0.018441, loss: 1.1268
2022-07-08 06:49:47 - train: epoch 0145, iter [04600, 05004], lr: 0.018428, loss: 1.3340
2022-07-08 06:50:20 - train: epoch 0145, iter [04700, 05004], lr: 0.018416, loss: 1.2392
2022-07-08 06:50:54 - train: epoch 0145, iter [04800, 05004], lr: 0.018403, loss: 1.1448
2022-07-08 06:51:28 - train: epoch 0145, iter [04900, 05004], lr: 0.018391, loss: 1.3878
2022-07-08 06:52:00 - train: epoch 0145, iter [05000, 05004], lr: 0.018378, loss: 1.2098
2022-07-08 06:52:01 - train: epoch 145, train_loss: 1.2072
2022-07-08 06:53:16 - eval: epoch: 145, acc1: 69.052%, acc5: 89.442%, test_loss: 1.2574, per_image_load_time: 1.590ms, per_image_inference_time: 0.432ms
2022-07-08 06:53:16 - until epoch: 145, best_acc1: 70.690%
2022-07-08 06:53:16 - epoch 146 lr: 0.018378
2022-07-08 06:53:55 - train: epoch 0146, iter [00100, 05004], lr: 0.018365, loss: 0.9554
2022-07-08 06:54:28 - train: epoch 0146, iter [00200, 05004], lr: 0.018353, loss: 1.1368
2022-07-08 06:55:01 - train: epoch 0146, iter [00300, 05004], lr: 0.018340, loss: 1.1610
2022-07-08 06:55:34 - train: epoch 0146, iter [00400, 05004], lr: 0.018328, loss: 1.1847
2022-07-08 06:56:07 - train: epoch 0146, iter [00500, 05004], lr: 0.018315, loss: 1.0118
2022-07-08 06:56:41 - train: epoch 0146, iter [00600, 05004], lr: 0.018303, loss: 1.0587
2022-07-08 06:57:14 - train: epoch 0146, iter [00700, 05004], lr: 0.018291, loss: 1.2752
2022-07-08 06:57:48 - train: epoch 0146, iter [00800, 05004], lr: 0.018278, loss: 0.9905
2022-07-08 06:58:21 - train: epoch 0146, iter [00900, 05004], lr: 0.018266, loss: 1.0713
2022-07-08 06:58:55 - train: epoch 0146, iter [01000, 05004], lr: 0.018253, loss: 1.1780
2022-07-08 06:59:28 - train: epoch 0146, iter [01100, 05004], lr: 0.018241, loss: 1.0150
2022-07-08 07:00:02 - train: epoch 0146, iter [01200, 05004], lr: 0.018228, loss: 1.0124
2022-07-08 07:00:36 - train: epoch 0146, iter [01300, 05004], lr: 0.018216, loss: 1.0738
2022-07-08 07:01:09 - train: epoch 0146, iter [01400, 05004], lr: 0.018203, loss: 1.4434
2022-07-08 07:01:42 - train: epoch 0146, iter [01500, 05004], lr: 0.018191, loss: 1.1487
2022-07-08 07:02:16 - train: epoch 0146, iter [01600, 05004], lr: 0.018179, loss: 1.1716
2022-07-08 07:02:49 - train: epoch 0146, iter [01700, 05004], lr: 0.018166, loss: 1.2494
2022-07-08 07:03:23 - train: epoch 0146, iter [01800, 05004], lr: 0.018154, loss: 1.1207
2022-07-08 07:03:57 - train: epoch 0146, iter [01900, 05004], lr: 0.018141, loss: 1.0720
2022-07-08 07:04:30 - train: epoch 0146, iter [02000, 05004], lr: 0.018129, loss: 1.1374
2022-07-08 07:05:04 - train: epoch 0146, iter [02100, 05004], lr: 0.018117, loss: 1.0409
2022-07-08 07:05:37 - train: epoch 0146, iter [02200, 05004], lr: 0.018104, loss: 1.1398
2022-07-08 07:06:11 - train: epoch 0146, iter [02300, 05004], lr: 0.018092, loss: 1.0289
2022-07-08 07:06:45 - train: epoch 0146, iter [02400, 05004], lr: 0.018079, loss: 1.3612
2022-07-08 07:07:18 - train: epoch 0146, iter [02500, 05004], lr: 0.018067, loss: 1.2437
2022-07-08 07:07:52 - train: epoch 0146, iter [02600, 05004], lr: 0.018055, loss: 1.2633
2022-07-08 07:08:25 - train: epoch 0146, iter [02700, 05004], lr: 0.018042, loss: 1.1877
2022-07-08 07:08:58 - train: epoch 0146, iter [02800, 05004], lr: 0.018030, loss: 1.2544
2022-07-08 07:09:32 - train: epoch 0146, iter [02900, 05004], lr: 0.018017, loss: 1.2032
2022-07-08 07:10:05 - train: epoch 0146, iter [03000, 05004], lr: 0.018005, loss: 1.2495
2022-07-08 07:10:38 - train: epoch 0146, iter [03100, 05004], lr: 0.017993, loss: 1.2449
2022-07-08 07:11:12 - train: epoch 0146, iter [03200, 05004], lr: 0.017980, loss: 1.1818
2022-07-08 07:11:45 - train: epoch 0146, iter [03300, 05004], lr: 0.017968, loss: 1.2863
2022-07-08 07:12:18 - train: epoch 0146, iter [03400, 05004], lr: 0.017956, loss: 1.3388
2022-07-08 07:12:53 - train: epoch 0146, iter [03500, 05004], lr: 0.017943, loss: 1.1858
2022-07-08 07:13:26 - train: epoch 0146, iter [03600, 05004], lr: 0.017931, loss: 1.1557
2022-07-08 07:14:00 - train: epoch 0146, iter [03700, 05004], lr: 0.017919, loss: 1.2939
2022-07-08 07:14:33 - train: epoch 0146, iter [03800, 05004], lr: 0.017906, loss: 1.3062
2022-07-08 07:15:07 - train: epoch 0146, iter [03900, 05004], lr: 0.017894, loss: 1.3148
2022-07-08 07:15:40 - train: epoch 0146, iter [04000, 05004], lr: 0.017882, loss: 1.1723
2022-07-08 07:16:14 - train: epoch 0146, iter [04100, 05004], lr: 0.017869, loss: 1.0741
2022-07-08 07:16:48 - train: epoch 0146, iter [04200, 05004], lr: 0.017857, loss: 1.0349
2022-07-08 07:17:23 - train: epoch 0146, iter [04300, 05004], lr: 0.017845, loss: 1.3631
2022-07-08 07:17:55 - train: epoch 0146, iter [04400, 05004], lr: 0.017832, loss: 1.3076
2022-07-08 07:18:28 - train: epoch 0146, iter [04500, 05004], lr: 0.017820, loss: 1.0954
2022-07-08 07:19:02 - train: epoch 0146, iter [04600, 05004], lr: 0.017808, loss: 1.2394
2022-07-08 07:19:37 - train: epoch 0146, iter [04700, 05004], lr: 0.017795, loss: 1.1744
2022-07-08 07:20:09 - train: epoch 0146, iter [04800, 05004], lr: 0.017783, loss: 1.3291
2022-07-08 07:20:44 - train: epoch 0146, iter [04900, 05004], lr: 0.017771, loss: 1.5213
2022-07-08 07:21:16 - train: epoch 0146, iter [05000, 05004], lr: 0.017758, loss: 1.2618
2022-07-08 07:21:17 - train: epoch 146, train_loss: 1.1941
2022-07-08 07:22:30 - eval: epoch: 146, acc1: 71.284%, acc5: 90.736%, test_loss: 1.1555, per_image_load_time: 1.858ms, per_image_inference_time: 0.463ms
2022-07-08 07:22:31 - until epoch: 146, best_acc1: 71.284%
2022-07-08 07:22:31 - epoch 147 lr: 0.017758
2022-07-08 07:23:10 - train: epoch 0147, iter [00100, 05004], lr: 0.017746, loss: 1.1683
2022-07-08 07:23:42 - train: epoch 0147, iter [00200, 05004], lr: 0.017733, loss: 1.2046
2022-07-08 07:24:17 - train: epoch 0147, iter [00300, 05004], lr: 0.017721, loss: 1.2387
2022-07-08 07:24:50 - train: epoch 0147, iter [00400, 05004], lr: 0.017709, loss: 1.0686
2022-07-08 07:25:23 - train: epoch 0147, iter [00500, 05004], lr: 0.017696, loss: 1.2309
2022-07-08 07:25:57 - train: epoch 0147, iter [00600, 05004], lr: 0.017684, loss: 1.2539
2022-07-08 07:26:30 - train: epoch 0147, iter [00700, 05004], lr: 0.017672, loss: 1.0168
2022-07-08 07:27:04 - train: epoch 0147, iter [00800, 05004], lr: 0.017660, loss: 1.1835
2022-07-08 07:27:37 - train: epoch 0147, iter [00900, 05004], lr: 0.017647, loss: 1.2417
2022-07-08 07:28:10 - train: epoch 0147, iter [01000, 05004], lr: 0.017635, loss: 1.2499
2022-07-08 07:28:44 - train: epoch 0147, iter [01100, 05004], lr: 0.017623, loss: 1.0808
2022-07-08 07:29:18 - train: epoch 0147, iter [01200, 05004], lr: 0.017610, loss: 1.0774
2022-07-08 07:29:51 - train: epoch 0147, iter [01300, 05004], lr: 0.017598, loss: 1.4940
2022-07-08 07:30:25 - train: epoch 0147, iter [01400, 05004], lr: 0.017586, loss: 1.1756
2022-07-08 07:30:59 - train: epoch 0147, iter [01500, 05004], lr: 0.017574, loss: 1.2053
2022-07-08 07:31:33 - train: epoch 0147, iter [01600, 05004], lr: 0.017561, loss: 1.2829
2022-07-08 07:32:06 - train: epoch 0147, iter [01700, 05004], lr: 0.017549, loss: 1.3256
2022-07-08 07:32:40 - train: epoch 0147, iter [01800, 05004], lr: 0.017537, loss: 0.9963
2022-07-08 07:33:14 - train: epoch 0147, iter [01900, 05004], lr: 0.017525, loss: 1.1525
2022-07-08 07:33:48 - train: epoch 0147, iter [02000, 05004], lr: 0.017512, loss: 1.2561
2022-07-08 07:34:21 - train: epoch 0147, iter [02100, 05004], lr: 0.017500, loss: 1.1921
2022-07-08 07:34:55 - train: epoch 0147, iter [02200, 05004], lr: 0.017488, loss: 1.4020
2022-07-08 07:35:29 - train: epoch 0147, iter [02300, 05004], lr: 0.017476, loss: 1.2677
2022-07-08 07:36:02 - train: epoch 0147, iter [02400, 05004], lr: 0.017464, loss: 1.0412
2022-07-08 07:36:36 - train: epoch 0147, iter [02500, 05004], lr: 0.017451, loss: 1.3044
2022-07-08 07:37:09 - train: epoch 0147, iter [02600, 05004], lr: 0.017439, loss: 1.2660
2022-07-08 07:37:43 - train: epoch 0147, iter [02700, 05004], lr: 0.017427, loss: 1.2415
2022-07-08 07:38:17 - train: epoch 0147, iter [02800, 05004], lr: 0.017415, loss: 1.1087
2022-07-08 07:38:50 - train: epoch 0147, iter [02900, 05004], lr: 0.017402, loss: 1.1527
2022-07-08 07:39:24 - train: epoch 0147, iter [03000, 05004], lr: 0.017390, loss: 1.1067
2022-07-08 07:39:58 - train: epoch 0147, iter [03100, 05004], lr: 0.017378, loss: 1.1121
2022-07-08 07:40:32 - train: epoch 0147, iter [03200, 05004], lr: 0.017366, loss: 1.1477
2022-07-08 07:41:06 - train: epoch 0147, iter [03300, 05004], lr: 0.017354, loss: 1.2980
