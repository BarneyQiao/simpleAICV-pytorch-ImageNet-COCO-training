2022-02-23 22:41:53 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 0.8987
2022-02-23 22:42:26 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 0.9596
2022-02-23 22:42:59 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 0.7655
2022-02-23 22:43:31 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 0.9655
2022-02-23 22:44:04 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 0.7987
2022-02-23 22:44:37 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 0.7754
2022-02-23 22:45:09 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 0.8484
2022-02-23 22:45:42 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 0.7915
2022-02-23 22:46:15 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 0.8116
2022-02-23 22:46:48 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 0.7288
2022-02-23 22:47:20 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 0.8877
2022-02-23 22:47:53 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 0.8850
2022-02-23 22:48:26 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 0.7747
2022-02-23 22:48:59 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 0.9309
2022-02-23 22:49:31 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 0.9099
2022-02-23 22:50:04 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 0.5872
2022-02-23 22:50:36 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 0.8502
2022-02-23 22:51:09 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 0.9128
2022-02-23 22:51:42 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 0.9625
2022-02-23 22:52:15 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 0.7650
2022-02-23 22:52:47 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 0.8772
2022-02-23 22:53:20 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 0.7908
2022-02-23 22:53:53 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 0.8675
2022-02-23 22:54:26 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 0.8241
2022-02-23 22:54:59 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 0.8198
2022-02-23 22:55:32 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 0.7711
2022-02-23 22:56:05 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 0.7885
2022-02-23 22:56:38 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 0.9187
2022-02-23 22:57:11 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 0.7334
2022-02-23 22:57:44 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 0.8781
2022-02-23 22:58:18 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 0.8115
2022-02-23 22:58:51 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 0.9577
2022-02-23 22:59:25 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 0.8469
2022-02-23 22:59:58 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 0.9557
2022-02-23 23:00:32 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 1.0555
2022-02-23 23:01:05 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 0.7087
2022-02-23 23:01:39 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 0.8208
2022-02-23 23:02:13 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 0.7129
2022-02-23 23:02:47 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 0.9703
2022-02-23 23:03:21 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 0.7761
2022-02-23 23:03:24 - train: epoch 077, train_loss: 0.8529
2022-02-23 23:04:41 - eval: epoch: 077, acc1: 76.530%, acc5: 93.262%, test_loss: 0.9233, per_image_load_time: 1.819ms, per_image_inference_time: 0.584ms
2022-02-23 23:04:42 - until epoch: 077, best_acc1: 76.698%
2022-02-23 23:04:42 - epoch 078 lr: 0.0010000000000000002
2022-02-23 23:05:20 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 0.8781
2022-02-23 23:05:52 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 0.9426
2022-02-23 23:06:25 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 0.8698
2022-02-23 23:06:58 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 0.7493
2022-02-23 23:07:31 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 0.8426
2022-02-23 23:08:03 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 0.7699
2022-02-23 23:08:36 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 0.8751
2022-02-23 23:09:09 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 0.9464
2022-02-23 23:09:41 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 0.6699
2022-02-23 23:10:14 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 0.8709
2022-02-23 23:10:46 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 0.9058
2022-02-23 23:11:19 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 0.8764
2022-02-23 23:11:52 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 0.8160
2022-02-23 23:12:24 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 0.7751
2022-02-23 23:12:57 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 0.8931
2022-02-23 23:13:30 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 0.8740
2022-02-23 23:14:02 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 0.9368
2022-02-23 23:14:35 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 0.8299
2022-02-23 23:15:08 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 0.8083
2022-02-23 23:15:41 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 0.9294
2022-02-23 23:16:13 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 0.9295
2022-02-23 23:16:46 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 0.9688
2022-02-23 23:17:19 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 0.9389
2022-02-23 23:17:51 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 1.0014
2022-02-23 23:18:24 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 0.9373
2022-02-23 23:18:57 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 0.9375
2022-02-23 23:19:29 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 0.9336
2022-02-23 23:20:02 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 0.8561
2022-02-23 23:20:35 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 0.8910
2022-02-23 23:21:08 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 0.7594
2022-02-23 23:21:41 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 0.8173
2022-02-23 23:22:14 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 0.9287
2022-02-23 23:22:47 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 0.8531
2022-02-23 23:23:20 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 0.9168
2022-02-23 23:23:53 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 0.8386
2022-02-23 23:24:25 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 0.9615
2022-02-23 23:24:58 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 0.7005
2022-02-23 23:25:31 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 0.8204
2022-02-23 23:26:04 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 0.8544
2022-02-23 23:26:37 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 0.8548
2022-02-23 23:27:10 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 0.7906
2022-02-23 23:27:43 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 0.7068
2022-02-23 23:28:17 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 0.8431
2022-02-23 23:28:50 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 0.8260
2022-02-23 23:29:23 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 0.8897
2022-02-23 23:29:57 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 0.7384
2022-02-23 23:30:31 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 0.8330
2022-02-23 23:31:05 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 0.9649
2022-02-23 23:31:40 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 0.7694
2022-02-23 23:32:13 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 0.8108
2022-02-23 23:32:16 - train: epoch 078, train_loss: 0.8507
2022-02-23 23:33:34 - eval: epoch: 078, acc1: 76.614%, acc5: 93.274%, test_loss: 0.9208, per_image_load_time: 2.424ms, per_image_inference_time: 0.561ms
2022-02-23 23:33:35 - until epoch: 078, best_acc1: 76.698%
2022-02-23 23:33:35 - epoch 079 lr: 0.0010000000000000002
2022-02-23 23:34:14 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 0.8573
2022-02-23 23:34:47 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 0.7464
2022-02-23 23:35:19 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 0.8652
2022-02-23 23:35:51 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 0.8127
2022-02-23 23:36:23 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 0.7102
2022-02-23 23:36:56 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 0.7726
2022-02-23 23:37:28 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 0.7351
2022-02-23 23:38:00 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 1.0204
2022-02-23 23:38:32 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 0.9076
2022-02-23 23:39:04 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 0.8447
2022-02-23 23:39:36 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 0.7898
2022-02-23 23:40:09 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 0.9797
2022-02-23 23:40:41 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 0.8014
2022-02-23 23:41:14 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 0.8522
2022-02-23 23:41:46 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 0.8335
2022-02-23 23:42:19 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 0.6156
2022-02-23 23:42:52 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 0.7708
2022-02-23 23:43:25 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 0.8537
2022-02-23 23:43:58 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 0.8524
2022-02-23 23:44:30 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 0.9814
2022-02-23 23:45:03 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 0.7196
2022-02-23 23:45:36 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 0.9443
2022-02-23 23:46:08 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 0.7199
2022-02-23 23:46:41 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 0.7263
2022-02-23 23:47:14 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 0.8199
2022-02-23 23:47:47 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 0.6726
2022-02-23 23:48:20 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 0.6959
2022-02-23 23:48:53 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 0.8668
2022-02-23 23:49:26 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 0.9777
2022-02-23 23:49:58 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 0.9124
2022-02-23 23:50:30 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 0.6568
2022-02-23 23:51:03 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 0.9105
2022-02-23 23:51:35 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 0.8233
2022-02-23 23:52:08 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 0.8941
2022-02-23 23:52:41 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 0.9085
2022-02-23 23:53:14 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 0.5933
2022-02-23 23:53:47 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 0.9208
2022-02-23 23:54:20 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 0.8051
2022-02-23 23:54:52 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 0.8851
2022-02-23 23:55:25 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 0.7574
2022-02-23 23:55:59 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 1.0865
2022-02-23 23:56:32 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 0.8105
2022-02-23 23:57:05 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 0.7803
2022-02-23 23:57:38 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 0.9410
2022-02-23 23:58:11 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 0.7782
2022-02-23 23:58:44 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 0.9104
2022-02-23 23:59:18 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 0.7019
2022-02-23 23:59:52 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 0.9240
2022-02-24 00:00:26 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 0.8562
2022-02-24 00:00:59 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 0.8479
2022-02-24 00:01:02 - train: epoch 079, train_loss: 0.8460
2022-02-24 00:02:19 - eval: epoch: 079, acc1: 76.592%, acc5: 93.260%, test_loss: 0.9245, per_image_load_time: 2.388ms, per_image_inference_time: 0.573ms
2022-02-24 00:02:20 - until epoch: 079, best_acc1: 76.698%
2022-02-24 00:02:20 - epoch 080 lr: 0.0010000000000000002
2022-02-24 00:03:00 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 0.8004
2022-02-24 00:03:32 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 0.8533
2022-02-24 00:04:04 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 0.8131
2022-02-24 00:04:37 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 0.8444
2022-02-24 00:05:10 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 0.6181
2022-02-24 00:05:42 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 0.7726
2022-02-24 00:06:15 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 0.7611
2022-02-24 00:06:47 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 0.8030
2022-02-24 00:07:19 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 0.7773
2022-02-24 00:07:52 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 0.7623
2022-02-24 00:08:24 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 0.8754
2022-02-24 00:08:57 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 0.8333
2022-02-24 00:09:29 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 0.8138
2022-02-24 00:10:02 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 0.9356
2022-02-24 00:10:34 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 0.7037
2022-02-24 00:11:06 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 0.8997
2022-02-24 00:11:38 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 0.9432
2022-02-24 00:12:10 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 0.7440
2022-02-24 00:12:42 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 1.0674
2022-02-24 00:13:15 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 0.9098
2022-02-24 00:13:47 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 1.0148
2022-02-24 00:14:19 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 0.7961
2022-02-24 00:14:52 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 0.7650
2022-02-24 00:15:24 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 1.0047
2022-02-24 00:15:57 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 0.7871
2022-02-24 00:16:30 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 0.8033
2022-02-24 00:17:03 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 0.7555
2022-02-24 00:17:35 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 0.7384
2022-02-24 00:18:08 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 1.0046
2022-02-24 00:18:41 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 0.7365
2022-02-24 00:19:14 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 0.9384
2022-02-24 00:19:46 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 0.7389
2022-02-24 00:20:19 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 0.7905
2022-02-24 00:20:52 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 0.7694
2022-02-24 00:21:25 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 0.8308
2022-02-24 00:21:58 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 0.8375
2022-02-24 00:22:30 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 0.9083
2022-02-24 00:23:03 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 1.0741
2022-02-24 00:23:36 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 0.7431
2022-02-24 00:24:09 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 0.9292
2022-02-24 00:24:42 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 0.9800
2022-02-24 00:25:15 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 0.8105
2022-02-24 00:25:48 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 1.0285
2022-02-24 00:26:21 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 0.6761
2022-02-24 00:26:55 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 0.7154
2022-02-24 00:27:28 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 1.0420
2022-02-24 00:28:02 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 0.7599
2022-02-24 00:28:36 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 1.0407
2022-02-24 00:29:10 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 0.8895
2022-02-24 00:29:44 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 0.8158
2022-02-24 00:29:47 - train: epoch 080, train_loss: 0.8417
2022-02-24 00:31:05 - eval: epoch: 080, acc1: 76.530%, acc5: 93.282%, test_loss: 0.9242, per_image_load_time: 1.116ms, per_image_inference_time: 0.588ms
2022-02-24 00:31:06 - until epoch: 080, best_acc1: 76.698%
2022-02-24 00:31:06 - epoch 081 lr: 0.0010000000000000002
2022-02-24 00:31:44 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 0.6717
2022-02-24 00:32:16 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 0.8287
2022-02-24 00:32:48 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 0.8523
2022-02-24 00:33:21 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 0.8233
2022-02-24 00:33:54 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 0.9957
2022-02-24 00:34:27 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 0.7707
2022-02-24 00:34:59 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 0.9323
2022-02-24 00:35:32 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 0.8657
2022-02-24 00:36:04 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 0.7677
2022-02-24 00:36:37 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 1.0580
2022-02-24 00:37:09 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 0.7993
2022-02-24 00:37:42 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 0.8337
2022-02-24 00:38:14 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 0.9443
2022-02-24 00:38:47 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 0.7027
2022-02-24 00:39:19 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 0.9423
2022-02-24 00:39:52 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 0.8772
2022-02-24 00:40:25 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 0.7914
2022-02-24 00:40:58 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 0.7918
2022-02-24 00:41:31 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 0.7901
2022-02-24 00:42:03 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 0.7731
2022-02-24 00:42:36 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 1.0301
2022-02-24 00:43:09 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 0.8039
2022-02-24 00:43:41 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 0.7713
2022-02-24 00:44:14 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 0.8412
2022-02-24 00:44:47 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 0.8281
2022-02-24 00:45:20 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 0.9969
2022-02-24 00:45:53 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 0.9654
2022-02-24 00:46:26 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 0.7095
2022-02-24 00:46:59 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 0.7444
2022-02-24 00:47:32 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 0.8462
2022-02-24 00:48:05 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 0.6603
2022-02-24 00:48:39 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 0.8365
2022-02-24 00:49:12 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 0.7155
2022-02-24 00:49:45 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 0.8409
2022-02-24 00:50:18 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 0.9218
2022-02-24 00:50:52 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 0.7009
2022-02-24 00:51:25 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 0.9098
2022-02-24 00:51:58 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 0.7976
2022-02-24 00:52:31 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 0.9087
2022-02-24 00:53:05 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 0.8054
2022-02-24 00:53:38 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 0.7949
2022-02-24 00:54:11 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 0.9788
2022-02-24 00:54:45 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 0.9094
2022-02-24 00:55:19 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 0.8818
2022-02-24 00:55:52 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 0.8551
2022-02-24 00:56:26 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 0.8441
2022-02-24 00:57:00 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 0.9577
2022-02-24 00:57:35 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 0.8831
2022-02-24 00:58:09 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 0.8554
2022-02-24 00:58:44 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 0.7495
2022-02-24 00:58:47 - train: epoch 081, train_loss: 0.8372
2022-02-24 01:00:05 - eval: epoch: 081, acc1: 76.562%, acc5: 93.260%, test_loss: 0.9255, per_image_load_time: 2.396ms, per_image_inference_time: 0.560ms
2022-02-24 01:00:06 - until epoch: 081, best_acc1: 76.698%
2022-02-24 01:00:06 - epoch 082 lr: 0.0010000000000000002
2022-02-24 01:00:44 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 0.6962
2022-02-24 01:01:17 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 0.8471
2022-02-24 01:01:50 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 0.9384
2022-02-24 01:02:22 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 0.7575
2022-02-24 01:02:55 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 0.7978
2022-02-24 01:03:27 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 0.8041
2022-02-24 01:04:00 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 0.8845
2022-02-24 01:04:33 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 0.8354
2022-02-24 01:05:05 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 1.0579
2022-02-24 01:05:38 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 0.7481
2022-02-24 01:06:11 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 1.0269
2022-02-24 01:06:43 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 0.8915
2022-02-24 01:07:16 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 0.8673
2022-02-24 01:07:49 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 0.8334
2022-02-24 01:08:22 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 0.9098
2022-02-24 01:08:55 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 0.7972
2022-02-24 01:09:28 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 0.8142
2022-02-24 01:10:01 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 0.6191
2022-02-24 01:10:34 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 0.7190
2022-02-24 01:11:07 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 0.8750
2022-02-24 01:11:40 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 0.8190
2022-02-24 01:12:13 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 0.9476
2022-02-24 01:12:46 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 0.7913
2022-02-24 01:13:19 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 0.9000
2022-02-24 01:13:52 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 0.8428
2022-02-24 01:14:25 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 0.6724
2022-02-24 01:14:58 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 0.7541
2022-02-24 01:15:31 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 0.7366
2022-02-24 01:16:04 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 0.8044
2022-02-24 01:16:37 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 0.9076
2022-02-24 01:17:11 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 0.7638
2022-02-24 01:17:44 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 0.8835
2022-02-24 01:18:17 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 0.8118
2022-02-24 01:18:50 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 0.8881
2022-02-24 01:19:23 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 0.7766
2022-02-24 01:19:56 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 0.9173
2022-02-24 01:20:30 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 0.8306
2022-02-24 01:21:03 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 0.9766
2022-02-24 01:21:36 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 0.8462
2022-02-24 01:22:09 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 0.7274
2022-02-24 01:22:42 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 0.9351
2022-02-24 01:23:15 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 0.9241
2022-02-24 01:23:49 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 0.6536
2022-02-24 01:24:22 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 0.6965
2022-02-24 01:24:56 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 0.8133
2022-02-24 01:25:30 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 0.6946
2022-02-24 01:26:04 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 0.7512
2022-02-24 01:26:38 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 0.6953
2022-02-24 01:27:13 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 0.8870
2022-02-24 01:27:47 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 0.7184
2022-02-24 01:27:50 - train: epoch 082, train_loss: 0.8365
2022-02-24 01:29:08 - eval: epoch: 082, acc1: 76.646%, acc5: 93.208%, test_loss: 0.9244, per_image_load_time: 2.376ms, per_image_inference_time: 0.586ms
2022-02-24 01:29:09 - until epoch: 082, best_acc1: 76.698%
2022-02-24 01:29:09 - epoch 083 lr: 0.0010000000000000002
2022-02-24 01:29:47 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 0.6983
2022-02-24 01:30:19 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 0.7636
2022-02-24 01:30:52 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 0.8449
2022-02-24 01:31:25 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 0.8281
2022-02-24 01:31:57 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 0.8324
2022-02-24 01:32:29 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 0.7900
2022-02-24 01:33:02 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 0.8558
2022-02-24 01:33:35 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 0.7586
2022-02-24 01:34:08 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 1.0381
2022-02-24 01:34:40 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 0.8596
2022-02-24 01:35:12 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 0.9512
2022-02-24 01:35:45 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 0.7865
2022-02-24 01:36:17 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 0.8210
2022-02-24 01:36:50 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 0.9735
2022-02-24 01:37:23 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 0.9033
2022-02-24 01:37:55 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 0.8236
2022-02-24 01:38:28 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 0.9965
2022-02-24 01:39:01 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 0.9101
2022-02-24 01:39:33 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 0.7146
2022-02-24 01:40:06 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 0.5531
2022-02-24 01:40:39 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 0.6682
2022-02-24 01:41:11 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 0.8032
2022-02-24 01:41:44 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 0.9610
2022-02-24 01:42:17 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 0.6921
2022-02-24 01:42:50 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 0.6823
2022-02-24 01:43:23 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 0.7918
2022-02-24 01:43:56 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 0.6945
2022-02-24 01:44:29 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 0.7811
2022-02-24 01:45:02 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 0.8770
2022-02-24 01:45:35 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 0.8817
2022-02-24 01:46:08 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 0.9665
2022-02-24 01:46:41 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 0.8679
2022-02-24 01:47:14 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 0.9592
2022-02-24 01:47:47 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 0.6703
2022-02-24 01:48:21 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 0.8477
2022-02-24 01:48:54 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 0.8912
2022-02-24 01:49:27 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 0.7841
2022-02-24 01:50:01 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 0.8933
2022-02-24 01:50:34 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 0.8344
2022-02-24 01:51:08 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 0.9365
2022-02-24 01:51:41 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 0.8267
2022-02-24 01:52:14 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 0.7945
2022-02-24 01:52:48 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 0.8432
2022-02-24 01:53:21 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 0.7231
2022-02-24 01:53:56 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 0.9789
2022-02-24 01:54:29 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 0.9090
2022-02-24 01:55:04 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 1.0314
2022-02-24 01:55:38 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 1.0359
2022-02-24 01:56:13 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 0.8614
2022-02-24 01:56:46 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 0.8459
2022-02-24 01:56:49 - train: epoch 083, train_loss: 0.8338
2022-02-24 01:58:08 - eval: epoch: 083, acc1: 76.478%, acc5: 93.340%, test_loss: 0.9271, per_image_load_time: 1.384ms, per_image_inference_time: 0.570ms
2022-02-24 01:58:09 - until epoch: 083, best_acc1: 76.698%
2022-02-24 01:58:09 - epoch 084 lr: 0.0010000000000000002
2022-02-24 01:58:47 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 0.7748
2022-02-24 01:59:20 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 0.9554
2022-02-24 01:59:52 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 0.5881
2022-02-24 02:00:24 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 0.7868
2022-02-24 02:00:57 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 0.8457
2022-02-24 02:01:29 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 0.9636
2022-02-24 02:02:02 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 1.0038
2022-02-24 02:02:35 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 1.0113
2022-02-24 02:03:07 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 0.8017
2022-02-24 02:03:40 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 0.8598
2022-02-24 02:04:13 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 0.6145
2022-02-24 02:04:46 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 0.8865
2022-02-24 02:05:19 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 0.8856
2022-02-24 02:05:52 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 0.8747
2022-02-24 02:06:25 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 0.7855
2022-02-24 02:06:58 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 0.7652
2022-02-24 02:07:31 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 0.8476
2022-02-24 02:08:03 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 0.8381
2022-02-24 02:08:36 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 0.9306
2022-02-24 02:09:09 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 0.8696
2022-02-24 02:09:42 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 0.7407
2022-02-24 02:10:15 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 0.7683
2022-02-24 02:10:48 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 0.7695
2022-02-24 02:11:22 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 0.7956
2022-02-24 02:11:55 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 0.9889
2022-02-24 02:12:28 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 0.8680
2022-02-24 02:13:01 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 0.8806
2022-02-24 02:13:34 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 0.9192
2022-02-24 02:14:07 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 0.7898
2022-02-24 02:14:40 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 0.8997
2022-02-24 02:15:13 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 0.9059
2022-02-24 02:15:46 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 0.6846
2022-02-24 02:16:19 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 0.7627
2022-02-24 02:16:52 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 0.8816
2022-02-24 02:17:25 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 0.8460
2022-02-24 02:17:58 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 0.8527
2022-02-24 02:18:32 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 0.9611
2022-02-24 02:19:05 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 0.9532
2022-02-24 02:19:38 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 0.7004
2022-02-24 02:20:12 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 0.8138
2022-02-24 02:20:45 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 0.5785
2022-02-24 02:21:18 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 0.9569
2022-02-24 02:21:52 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 0.8226
2022-02-24 02:22:25 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 1.0520
2022-02-24 02:22:59 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 0.8304
2022-02-24 02:23:33 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 0.8993
2022-02-24 02:24:07 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 0.8901
2022-02-24 02:24:41 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 0.7268
2022-02-24 02:25:16 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 0.7620
2022-02-24 02:25:51 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 0.8735
2022-02-24 02:25:54 - train: epoch 084, train_loss: 0.8297
2022-02-24 02:27:10 - eval: epoch: 084, acc1: 76.338%, acc5: 93.278%, test_loss: 0.9284, per_image_load_time: 2.251ms, per_image_inference_time: 0.606ms
2022-02-24 02:27:11 - until epoch: 084, best_acc1: 76.698%
2022-02-24 02:27:11 - epoch 085 lr: 0.0010000000000000002
2022-02-24 02:27:49 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 0.7578
2022-02-24 02:28:21 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 0.7355
2022-02-24 02:28:54 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 0.8784
2022-02-24 02:29:26 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 0.9449
2022-02-24 02:29:58 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 0.8578
2022-02-24 02:30:31 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 0.8622
2022-02-24 02:31:03 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 0.8986
2022-02-24 02:31:36 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 0.7282
2022-02-24 02:32:08 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 0.8120
2022-02-24 02:32:41 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 0.7445
2022-02-24 02:33:14 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 0.8164
2022-02-24 02:33:46 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 0.8655
2022-02-24 02:34:19 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 0.7997
2022-02-24 02:34:52 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 0.7736
2022-02-24 02:35:25 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 0.6951
2022-02-24 02:35:58 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 0.8820
2022-02-24 02:36:31 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 1.0164
2022-02-24 02:37:03 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 0.6047
2022-02-24 02:37:36 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 0.8930
2022-02-24 02:38:09 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 0.7304
2022-02-24 02:38:42 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 0.6509
2022-02-24 02:39:15 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 0.9364
2022-02-24 02:39:47 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 0.8298
2022-02-24 02:40:20 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 0.8928
2022-02-24 02:40:54 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 0.9607
2022-02-24 02:41:27 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 0.9540
2022-02-24 02:42:00 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 0.6750
2022-02-24 02:42:33 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 0.8395
2022-02-24 02:43:06 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 0.7879
2022-02-24 02:43:39 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 0.9578
2022-02-24 02:44:12 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 0.7854
2022-02-24 02:44:45 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 0.9142
2022-02-24 02:45:18 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 0.7961
2022-02-24 02:45:51 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 0.7804
2022-02-24 02:46:24 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 0.8315
2022-02-24 02:46:58 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 0.8050
2022-02-24 02:47:31 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 0.7591
2022-02-24 02:48:04 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 0.8055
2022-02-24 02:48:37 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 0.9391
2022-02-24 02:49:11 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 0.8877
2022-02-24 02:49:44 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 1.0379
2022-02-24 02:50:18 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 0.8643
2022-02-24 02:50:51 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 0.7625
2022-02-24 02:51:25 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 0.6595
2022-02-24 02:51:59 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 0.9511
2022-02-24 02:52:33 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 0.8314
2022-02-24 02:53:07 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 0.9577
2022-02-24 02:53:42 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 0.7329
2022-02-24 02:54:17 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 0.8561
2022-02-24 02:54:52 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 0.7715
2022-02-24 02:54:55 - train: epoch 085, train_loss: 0.8269
2022-02-24 02:56:12 - eval: epoch: 085, acc1: 76.486%, acc5: 93.180%, test_loss: 0.9277, per_image_load_time: 2.349ms, per_image_inference_time: 0.608ms
2022-02-24 02:56:13 - until epoch: 085, best_acc1: 76.698%
2022-02-24 02:56:13 - epoch 086 lr: 0.0010000000000000002
2022-02-24 02:56:51 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 0.7049
2022-02-24 02:57:24 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 0.6997
2022-02-24 02:57:56 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 0.8438
2022-02-24 02:58:29 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 0.6866
2022-02-24 02:59:02 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 0.9165
2022-02-24 02:59:34 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 0.8483
2022-02-24 03:00:07 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 0.7716
2022-02-24 03:00:40 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 0.8144
2022-02-24 03:01:13 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 0.7002
2022-02-24 03:01:45 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 0.7943
2022-02-24 03:02:18 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 0.8600
2022-02-24 03:02:51 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 0.8884
2022-02-24 03:03:24 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 0.9336
2022-02-24 03:03:56 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 0.8510
2022-02-24 03:04:29 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 0.7960
2022-02-24 03:05:02 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 0.7824
2022-02-24 03:05:35 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 0.8330
2022-02-24 03:06:08 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 0.8034
2022-02-24 03:06:40 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 0.6283
2022-02-24 03:07:13 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 0.8265
2022-02-24 03:07:46 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 0.7280
2022-02-24 03:08:19 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 0.7403
2022-02-24 03:08:51 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 0.8583
2022-02-24 03:09:24 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 0.8163
2022-02-24 03:09:57 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 0.8992
2022-02-24 03:10:30 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 0.7862
2022-02-24 03:11:03 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 0.7679
2022-02-24 03:11:36 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 0.8587
2022-02-24 03:12:09 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 0.6988
2022-02-24 03:12:42 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 0.7689
2022-02-24 03:13:15 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 0.9519
2022-02-24 03:13:48 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 0.8327
2022-02-24 03:14:21 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 0.7600
2022-02-24 03:14:54 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 0.7230
2022-02-24 03:15:28 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 0.8571
2022-02-24 03:16:01 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 0.9744
2022-02-24 03:16:34 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 0.7593
2022-02-24 03:17:07 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 0.9014
2022-02-24 03:17:40 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 0.7566
2022-02-24 03:18:14 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 0.8265
2022-02-24 03:18:47 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 0.7434
2022-02-24 03:19:21 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 0.6735
2022-02-24 03:19:54 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 0.8169
2022-02-24 03:20:28 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 0.8371
2022-02-24 03:21:02 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 0.8387
2022-02-24 03:21:36 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 0.8429
2022-02-24 03:22:10 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 0.7854
2022-02-24 03:22:44 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 0.8903
2022-02-24 03:23:19 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 0.7585
2022-02-24 03:23:54 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 0.7639
2022-02-24 03:23:57 - train: epoch 086, train_loss: 0.8231
2022-02-24 03:25:15 - eval: epoch: 086, acc1: 76.416%, acc5: 93.204%, test_loss: 0.9314, per_image_load_time: 2.261ms, per_image_inference_time: 0.593ms
2022-02-24 03:25:16 - until epoch: 086, best_acc1: 76.698%
2022-02-24 03:25:16 - epoch 087 lr: 0.0010000000000000002
2022-02-24 03:25:54 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 0.8132
2022-02-24 03:26:26 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 0.8141
2022-02-24 03:26:59 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 0.8221
2022-02-24 03:27:31 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 0.7373
2022-02-24 03:28:03 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 0.7074
2022-02-24 03:28:36 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 0.8962
2022-02-24 03:29:09 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 0.6691
2022-02-24 03:29:42 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 0.6695
2022-02-24 03:30:14 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 0.8797
2022-02-24 03:30:47 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 0.6832
2022-02-24 03:31:20 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 0.8310
2022-02-24 03:31:53 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 0.9121
2022-02-24 03:32:25 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 0.9599
2022-02-24 03:32:58 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 0.6959
2022-02-24 03:33:31 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 0.8047
2022-02-24 03:34:03 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 0.8637
2022-02-24 03:34:36 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 0.9747
2022-02-24 03:35:09 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 0.8023
2022-02-24 03:35:42 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 1.0583
2022-02-24 03:36:15 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 0.8368
2022-02-24 03:36:48 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 0.8708
2022-02-24 03:37:21 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 0.7712
2022-02-24 03:37:54 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 0.9024
2022-02-24 03:38:27 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 1.0019
2022-02-24 03:39:00 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 0.8086
2022-02-24 03:39:33 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 0.7576
2022-02-24 03:40:06 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 0.8724
2022-02-24 03:40:40 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 0.8550
2022-02-24 03:41:13 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 0.8214
2022-02-24 03:41:46 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 0.7848
2022-02-24 03:42:19 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 0.7871
2022-02-24 03:42:52 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 0.7739
2022-02-24 03:43:25 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 0.8356
2022-02-24 03:43:58 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 0.7504
2022-02-24 03:44:32 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 0.7366
2022-02-24 03:45:04 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 0.7556
2022-02-24 03:45:38 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 0.7655
2022-02-24 03:46:10 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 0.8616
2022-02-24 03:46:43 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 1.0197
2022-02-24 03:47:17 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 0.7486
2022-02-24 03:47:50 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 0.7857
2022-02-24 03:48:24 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 0.8300
2022-02-24 03:48:57 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 0.8100
2022-02-24 03:49:30 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 0.7749
2022-02-24 03:50:04 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 0.6619
2022-02-24 03:50:38 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 0.8123
2022-02-24 03:51:12 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 0.7289
2022-02-24 03:51:47 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 0.8102
2022-02-24 03:52:21 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 0.9215
2022-02-24 03:52:56 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 0.7330
2022-02-24 03:52:59 - train: epoch 087, train_loss: 0.8173
2022-02-24 03:54:17 - eval: epoch: 087, acc1: 76.456%, acc5: 93.268%, test_loss: 0.9295, per_image_load_time: 2.402ms, per_image_inference_time: 0.559ms
2022-02-24 03:54:18 - until epoch: 087, best_acc1: 76.698%
2022-02-24 03:54:18 - epoch 088 lr: 0.0010000000000000002
2022-02-24 03:54:55 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 0.8180
2022-02-24 03:55:27 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 0.9112
2022-02-24 03:55:59 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 0.9312
2022-02-24 03:56:31 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 0.9703
2022-02-24 03:57:03 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 0.8945
2022-02-24 03:57:35 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 0.7840
2022-02-24 03:58:07 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 0.7614
2022-02-24 03:58:40 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 0.7824
2022-02-24 03:59:12 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 0.8595
2022-02-24 03:59:45 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 0.7933
2022-02-24 04:00:17 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 0.6982
2022-02-24 04:00:50 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 0.7844
2022-02-24 04:01:22 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 0.9276
2022-02-24 04:01:55 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 0.7649
2022-02-24 04:02:28 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 0.8368
2022-02-24 04:03:01 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 0.7063
2022-02-24 04:03:33 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 0.8579
2022-02-24 04:04:06 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 0.8300
2022-02-24 04:04:39 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 0.8255
2022-02-24 04:05:12 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 0.6807
2022-02-24 04:05:45 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 0.7607
2022-02-24 04:06:17 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 0.7350
2022-02-24 04:06:50 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 0.8428
2022-02-24 04:07:23 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 0.8244
2022-02-24 04:07:55 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 0.9687
2022-02-24 04:08:28 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 0.8018
2022-02-24 04:09:01 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 1.0689
2022-02-24 04:09:33 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 0.7329
2022-02-24 04:10:06 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 0.8173
2022-02-24 04:10:39 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 0.9762
2022-02-24 04:11:12 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 0.6744
2022-02-24 04:11:44 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 0.7635
2022-02-24 04:12:17 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 0.7932
2022-02-24 04:12:50 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 0.9362
2022-02-24 04:13:22 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 0.9307
2022-02-24 04:13:55 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 0.8799
2022-02-24 04:14:28 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 0.9070
2022-02-24 04:15:01 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 0.9218
2022-02-24 04:15:34 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 0.8328
2022-02-24 04:16:07 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 0.6378
2022-02-24 04:16:40 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 0.7632
2022-02-24 04:17:13 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 0.8118
2022-02-24 04:17:46 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 0.8486
2022-02-24 04:18:19 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 0.7212
2022-02-24 04:18:53 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 0.6920
2022-02-24 04:19:26 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 1.1341
2022-02-24 04:20:00 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 0.8838
2022-02-24 04:20:35 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 0.8828
2022-02-24 04:21:09 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 0.8929
2022-02-24 04:21:44 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 0.9160
2022-02-24 04:21:47 - train: epoch 088, train_loss: 0.8176
2022-02-24 04:23:05 - eval: epoch: 088, acc1: 76.416%, acc5: 93.302%, test_loss: 0.9342, per_image_load_time: 2.457ms, per_image_inference_time: 0.552ms
2022-02-24 04:23:06 - until epoch: 088, best_acc1: 76.698%
2022-02-24 04:23:06 - epoch 089 lr: 0.0010000000000000002
2022-02-24 04:23:45 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 1.0654
2022-02-24 04:24:17 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 0.8982
2022-02-24 04:24:50 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 0.8115
2022-02-24 04:25:22 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 0.7661
2022-02-24 04:25:54 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 0.9964
2022-02-24 04:26:27 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 0.9290
2022-02-24 04:27:00 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 0.7157
2022-02-24 04:27:32 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 0.8498
2022-02-24 04:28:04 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 0.8314
2022-02-24 04:28:37 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 0.8767
2022-02-24 04:29:10 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 0.6605
2022-02-24 04:29:42 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 0.8067
2022-02-24 04:30:15 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 0.7230
2022-02-24 04:30:48 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 1.0194
2022-02-24 04:31:21 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 0.8104
2022-02-24 04:31:54 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 0.6000
2022-02-24 04:32:27 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 0.8264
2022-02-24 04:32:59 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 0.7895
2022-02-24 04:33:32 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 0.6147
2022-02-24 04:34:05 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 0.7871
2022-02-24 04:34:38 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 0.9124
2022-02-24 04:35:10 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 0.9281
2022-02-24 04:35:43 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 0.8407
2022-02-24 04:36:16 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 0.8950
2022-02-24 04:36:48 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 0.8219
2022-02-24 04:37:21 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 0.7760
2022-02-24 04:37:55 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 0.8845
2022-02-24 04:38:28 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 0.8757
2022-02-24 04:39:01 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 0.7975
2022-02-24 04:39:34 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 0.7440
2022-02-24 04:40:06 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 0.6974
2022-02-24 04:40:39 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 0.8602
2022-02-24 04:41:12 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 0.9515
2022-02-24 04:41:45 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 0.7497
2022-02-24 04:42:19 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 0.5712
2022-02-24 04:42:52 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 0.7487
2022-02-24 04:43:25 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 1.0073
2022-02-24 04:43:58 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 0.8518
2022-02-24 04:44:32 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 1.0315
2022-02-24 04:45:05 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 0.8543
2022-02-24 04:45:39 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 0.8387
2022-02-24 04:46:12 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 0.7511
2022-02-24 04:46:46 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 0.7365
2022-02-24 04:47:19 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 0.7610
2022-02-24 04:47:53 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 0.5357
2022-02-24 04:48:27 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 0.9102
2022-02-24 04:49:01 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 0.8329
2022-02-24 04:49:36 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 0.9216
2022-02-24 04:50:11 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 0.7821
2022-02-24 04:50:45 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 0.5988
2022-02-24 04:50:48 - train: epoch 089, train_loss: 0.8138
2022-02-24 04:52:07 - eval: epoch: 089, acc1: 76.532%, acc5: 93.264%, test_loss: 0.9294, per_image_load_time: 2.368ms, per_image_inference_time: 0.587ms
2022-02-24 04:52:08 - until epoch: 089, best_acc1: 76.698%
2022-02-24 04:52:08 - epoch 090 lr: 0.0010000000000000002
2022-02-24 04:52:46 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 0.8690
2022-02-24 04:53:18 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 0.7920
2022-02-24 04:53:50 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 0.7825
2022-02-24 04:54:22 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 0.7128
2022-02-24 04:54:55 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 0.7354
2022-02-24 04:55:27 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 0.9187
2022-02-24 04:56:00 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 0.9065
2022-02-24 04:56:32 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 0.9390
2022-02-24 04:57:05 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 0.9998
2022-02-24 04:57:38 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 0.8128
2022-02-24 04:58:11 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 0.7545
2022-02-24 04:58:43 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 0.7515
2022-02-24 04:59:16 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 0.8388
2022-02-24 04:59:49 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 0.7752
2022-02-24 05:00:22 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 0.9915
2022-02-24 05:00:55 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 0.8233
2022-02-24 05:01:27 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 0.7868
2022-02-24 05:02:00 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 0.8512
2022-02-24 05:02:33 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 0.7100
2022-02-24 05:03:05 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 0.7288
2022-02-24 05:03:38 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 0.9285
2022-02-24 05:04:11 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 0.8290
2022-02-24 05:04:44 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 0.9517
2022-02-24 05:05:17 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 0.6340
2022-02-24 05:05:50 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 0.7847
2022-02-24 05:06:23 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 0.8561
2022-02-24 05:06:56 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 0.7944
2022-02-24 05:07:29 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 0.8142
2022-02-24 05:08:02 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 0.7891
2022-02-24 05:08:35 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 0.7642
2022-02-24 05:09:08 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 0.7588
2022-02-24 05:09:41 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 0.8441
2022-02-24 05:10:14 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 0.8831
2022-02-24 05:10:47 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 0.7178
2022-02-24 05:11:21 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 0.8365
2022-02-24 05:11:54 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 0.6838
2022-02-24 05:12:27 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 0.8768
2022-02-24 05:13:00 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 0.8302
2022-02-24 05:13:33 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 0.7234
2022-02-24 05:14:07 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 0.7136
2022-02-24 05:14:40 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 1.0246
2022-02-24 05:15:14 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 0.9032
2022-02-24 05:15:47 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 0.9139
2022-02-24 05:16:21 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 0.8834
2022-02-24 05:16:54 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 0.8773
2022-02-24 05:17:28 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 0.8360
2022-02-24 05:18:02 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 0.7107
2022-02-24 05:18:37 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 0.9178
2022-02-24 05:19:11 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 0.6535
2022-02-24 05:19:45 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 0.6840
2022-02-24 05:19:48 - train: epoch 090, train_loss: 0.8130
2022-02-24 05:21:04 - eval: epoch: 090, acc1: 76.354%, acc5: 93.210%, test_loss: 0.9345, per_image_load_time: 2.300ms, per_image_inference_time: 0.610ms
2022-02-24 05:21:05 - until epoch: 090, best_acc1: 76.698%
2022-02-24 05:21:05 - epoch 091 lr: 0.00010000000000000003
2022-02-24 05:21:43 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 0.7769
2022-02-24 05:22:16 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 0.8631
2022-02-24 05:22:48 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 0.8026
2022-02-24 05:23:21 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 0.9210
2022-02-24 05:23:53 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 0.7698
2022-02-24 05:24:26 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 1.0806
2022-02-24 05:24:58 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 0.8716
2022-02-24 05:25:31 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 0.7641
2022-02-24 05:26:04 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 0.8034
2022-02-24 05:26:37 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 0.7436
2022-02-24 05:27:09 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 0.5617
2022-02-24 05:27:42 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 0.9098
2022-02-24 05:28:15 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 0.7433
2022-02-24 05:28:48 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 0.8374
2022-02-24 05:29:21 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 0.8187
2022-02-24 05:29:54 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 0.8249
2022-02-24 05:30:27 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 0.9090
2022-02-24 05:31:01 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 0.7517
2022-02-24 05:31:33 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 0.7502
2022-02-24 05:32:06 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 0.7258
2022-02-24 05:32:39 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 0.6125
2022-02-24 05:33:12 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 0.7781
2022-02-24 05:33:45 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 0.8499
2022-02-24 05:34:18 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 0.6758
2022-02-24 05:34:51 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 0.8415
2022-02-24 05:35:24 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 0.7789
2022-02-24 05:35:57 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 0.7451
2022-02-24 05:36:30 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 0.7944
2022-02-24 05:37:03 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 0.9494
2022-02-24 05:37:36 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 0.8372
2022-02-24 05:38:09 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 0.7116
2022-02-24 05:38:42 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 0.9078
2022-02-24 05:39:15 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 0.7372
2022-02-24 05:39:48 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 0.7738
2022-02-24 05:40:21 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 0.8857
2022-02-24 05:40:54 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 0.7430
2022-02-24 05:41:27 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 0.8491
2022-02-24 05:42:01 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 0.7266
2022-02-24 05:42:34 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 0.8619
2022-02-24 05:43:07 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 0.8665
2022-02-24 05:43:41 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 0.8822
2022-02-24 05:44:14 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 0.7723
2022-02-24 05:44:48 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 0.6585
2022-02-24 05:45:21 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 0.6269
2022-02-24 05:45:55 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 0.6424
2022-02-24 05:46:29 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 0.8412
2022-02-24 05:47:03 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 0.9966
2022-02-24 05:47:38 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 0.8294
2022-02-24 05:48:12 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 0.7123
2022-02-24 05:48:47 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 0.7795
2022-02-24 05:48:50 - train: epoch 091, train_loss: 0.7776
2022-02-24 05:50:07 - eval: epoch: 091, acc1: 76.738%, acc5: 93.426%, test_loss: 0.9193, per_image_load_time: 2.288ms, per_image_inference_time: 0.612ms
2022-02-24 05:50:08 - until epoch: 091, best_acc1: 76.738%
2022-02-24 05:50:08 - epoch 092 lr: 0.00010000000000000003
2022-02-24 05:50:46 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 0.7832
2022-02-24 05:51:19 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 0.8021
2022-02-24 05:51:51 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 0.7082
2022-02-24 05:52:24 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 0.8306
2022-02-24 05:52:57 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 0.7926
2022-02-24 05:53:30 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 0.6821
2022-02-24 05:54:03 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 0.6436
2022-02-24 05:54:35 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 0.7725
2022-02-24 05:55:08 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 0.7253
2022-02-24 05:55:41 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 0.7728
2022-02-24 05:56:14 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 0.7013
2022-02-24 05:56:46 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 0.6767
2022-02-24 05:57:19 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 0.6829
2022-02-24 05:57:52 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 0.6323
2022-02-24 05:58:26 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 0.6808
2022-02-24 05:58:58 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 0.7500
2022-02-24 05:59:31 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 0.8272
2022-02-24 06:00:04 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 0.7006
2022-02-24 06:00:37 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 0.9650
2022-02-24 06:01:10 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 0.7755
2022-02-24 06:01:43 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 0.7209
2022-02-24 06:02:16 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 0.8365
2022-02-24 06:02:49 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 0.6751
2022-02-24 06:03:22 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 0.5465
2022-02-24 06:03:55 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 0.8360
2022-02-24 06:04:28 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 0.9197
2022-02-24 06:05:01 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 0.7040
2022-02-24 06:05:34 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 0.8328
2022-02-24 06:06:07 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 0.7558
2022-02-24 06:06:40 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 0.8266
2022-02-24 06:07:14 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 0.8589
2022-02-24 06:07:47 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 0.6909
2022-02-24 06:08:20 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 0.7874
2022-02-24 06:08:53 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 0.9144
2022-02-24 06:09:26 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 0.6323
2022-02-24 06:09:59 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 0.7290
2022-02-24 06:10:32 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 0.8418
2022-02-24 06:11:05 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 0.7787
2022-02-24 06:11:38 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 0.9771
2022-02-24 06:12:12 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 0.7310
2022-02-24 06:12:45 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 0.7307
2022-02-24 06:13:18 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 0.7082
2022-02-24 06:13:52 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 0.6257
2022-02-24 06:14:26 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 0.8762
2022-02-24 06:14:59 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 0.7713
2022-02-24 06:15:33 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 0.7621
2022-02-24 06:16:07 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 0.7104
2022-02-24 06:16:41 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 0.8893
2022-02-24 06:17:16 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 0.6591
2022-02-24 06:17:51 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 0.8128
2022-02-24 06:17:54 - train: epoch 092, train_loss: 0.7647
2022-02-24 06:19:12 - eval: epoch: 092, acc1: 76.758%, acc5: 93.452%, test_loss: 0.9164, per_image_load_time: 2.445ms, per_image_inference_time: 0.569ms
2022-02-24 06:19:13 - until epoch: 092, best_acc1: 76.758%
2022-02-24 06:19:13 - epoch 093 lr: 0.00010000000000000003
2022-02-24 06:19:51 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 0.8385
2022-02-24 06:20:23 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 0.6346
2022-02-24 06:20:55 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 0.8953
2022-02-24 06:21:28 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 0.6267
2022-02-24 06:22:00 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 0.7503
2022-02-24 06:22:32 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 0.8141
2022-02-24 06:23:04 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 0.6612
2022-02-24 06:23:37 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 0.7098
2022-02-24 06:24:09 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 0.7586
2022-02-24 06:24:41 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.5731
2022-02-24 06:25:14 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 0.6878
2022-02-24 06:25:46 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 0.8598
2022-02-24 06:26:19 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 0.6425
2022-02-24 06:26:51 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 0.7889
2022-02-24 06:27:24 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 0.7932
2022-02-24 06:27:56 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 0.7327
2022-02-24 06:28:29 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 0.7894
2022-02-24 06:29:02 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 0.6842
2022-02-24 06:29:34 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 0.7602
2022-02-24 06:30:07 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 0.5948
2022-02-24 06:30:40 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 0.6811
2022-02-24 06:31:13 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 0.9866
2022-02-24 06:31:46 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 0.6896
2022-02-24 06:32:19 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 0.7517
2022-02-24 06:32:52 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 0.9013
2022-02-24 06:33:25 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 0.8946
2022-02-24 06:33:57 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 0.6656
2022-02-24 06:34:30 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 0.8466
2022-02-24 06:35:03 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 0.6957
2022-02-24 06:35:36 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 0.8113
2022-02-24 06:36:08 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 0.7758
2022-02-24 06:36:41 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 0.5074
2022-02-24 06:37:14 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 0.6798
2022-02-24 06:37:47 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 0.7484
2022-02-24 06:38:20 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 0.7761
2022-02-24 06:38:53 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 0.7575
2022-02-24 06:39:26 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 0.8072
2022-02-24 06:39:59 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 0.7367
2022-02-24 06:40:32 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 0.9367
2022-02-24 06:41:05 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 0.8709
2022-02-24 06:41:38 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 0.8747
2022-02-24 06:42:12 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 0.8734
2022-02-24 06:42:45 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 0.8133
2022-02-24 06:43:19 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 0.7647
2022-02-24 06:43:52 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 0.6555
2022-02-24 06:44:26 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 0.7010
2022-02-24 06:45:00 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 0.7255
2022-02-24 06:45:35 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 0.6770
2022-02-24 06:46:09 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 0.8148
2022-02-24 06:46:44 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 0.9287
2022-02-24 06:46:47 - train: epoch 093, train_loss: 0.7607
2022-02-24 06:48:05 - eval: epoch: 093, acc1: 76.722%, acc5: 93.432%, test_loss: 0.9176, per_image_load_time: 2.382ms, per_image_inference_time: 0.596ms
2022-02-24 06:48:06 - until epoch: 093, best_acc1: 76.758%
2022-02-24 06:48:06 - epoch 094 lr: 0.00010000000000000003
2022-02-24 06:48:43 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 0.7935
2022-02-24 06:49:16 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 0.7748
2022-02-24 06:49:48 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 0.8007
2022-02-24 06:50:21 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 0.8208
2022-02-24 06:50:54 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 0.7452
2022-02-24 06:51:27 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 0.7224
2022-02-24 06:51:59 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 0.7403
2022-02-24 06:52:32 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 0.7861
2022-02-24 06:53:05 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 0.6316
2022-02-24 06:53:38 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 0.6580
2022-02-24 06:54:11 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 0.8634
2022-02-24 06:54:43 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 0.8055
2022-02-24 06:55:16 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 0.8223
2022-02-24 06:55:49 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 0.7655
2022-02-24 06:56:22 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 0.7231
2022-02-24 06:56:55 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 0.8937
2022-02-24 06:57:28 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 0.6904
2022-02-24 06:58:01 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 0.8573
2022-02-24 06:58:34 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 0.8087
2022-02-24 06:59:07 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 0.7086
2022-02-24 06:59:39 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 0.7010
2022-02-24 07:00:13 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 0.7218
2022-02-24 07:00:46 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 0.6973
2022-02-24 07:01:19 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 0.7218
2022-02-24 07:01:52 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 0.6634
2022-02-24 07:02:25 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 0.6801
2022-02-24 07:02:58 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 0.6545
2022-02-24 07:03:31 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 0.7714
2022-02-24 07:04:05 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 0.6740
2022-02-24 07:04:38 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 0.7478
2022-02-24 07:05:11 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 0.7510
2022-02-24 07:05:44 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 0.7734
2022-02-24 07:06:17 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 0.7204
2022-02-24 07:06:50 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 0.7518
2022-02-24 07:07:23 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 0.9611
2022-02-24 07:07:57 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 0.7725
2022-02-24 07:08:30 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 0.8176
2022-02-24 07:09:03 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 0.7016
2022-02-24 07:09:36 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 0.6472
2022-02-24 07:10:10 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 0.6752
2022-02-24 07:10:43 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 0.8477
2022-02-24 07:11:16 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 0.7871
2022-02-24 07:11:50 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 0.8316
2022-02-24 07:12:23 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 0.8185
2022-02-24 07:12:57 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 0.7187
2022-02-24 07:13:31 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 0.6811
2022-02-24 07:14:05 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 0.8796
2022-02-24 07:14:39 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 0.6964
2022-02-24 07:15:14 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 0.7871
2022-02-24 07:15:48 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 0.6056
2022-02-24 07:15:51 - train: epoch 094, train_loss: 0.7586
2022-02-24 07:17:09 - eval: epoch: 094, acc1: 76.764%, acc5: 93.466%, test_loss: 0.9169, per_image_load_time: 2.384ms, per_image_inference_time: 0.582ms
2022-02-24 07:17:10 - until epoch: 094, best_acc1: 76.764%
2022-02-24 07:17:10 - epoch 095 lr: 0.00010000000000000003
2022-02-24 07:17:49 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 0.8812
2022-02-24 07:18:21 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 0.7303
2022-02-24 07:18:53 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 0.7672
2022-02-24 07:19:26 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 0.8160
2022-02-24 07:19:58 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 0.8533
2022-02-24 07:20:31 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 0.8539
2022-02-24 07:21:03 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 0.7497
2022-02-24 07:21:36 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 0.8485
2022-02-24 07:22:09 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 0.8138
2022-02-24 07:22:42 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 0.8429
2022-02-24 07:23:14 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 0.6258
2022-02-24 07:23:47 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 0.7199
2022-02-24 07:24:19 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 0.7242
2022-02-24 07:24:52 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 0.7973
2022-02-24 07:25:25 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 0.6477
2022-02-24 07:25:58 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.7560
2022-02-24 07:26:30 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 0.8279
2022-02-24 07:27:03 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 0.7910
2022-02-24 07:27:36 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 0.8730
2022-02-24 07:28:09 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 0.6745
2022-02-24 07:28:42 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 0.5948
2022-02-24 07:29:15 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 0.6602
2022-02-24 07:29:48 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 0.8075
2022-02-24 07:30:21 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 0.8018
2022-02-24 07:30:54 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 0.7478
2022-02-24 07:31:27 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 0.6611
2022-02-24 07:32:00 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 0.7757
2022-02-24 07:32:33 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 0.6545
2022-02-24 07:33:06 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 0.7019
2022-02-24 07:33:39 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 0.8823
2022-02-24 07:34:12 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 0.8171
2022-02-24 07:34:45 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 0.7005
2022-02-24 07:35:18 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 0.7409
2022-02-24 07:35:51 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 0.7202
2022-02-24 07:36:24 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 0.7696
2022-02-24 07:36:57 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 0.5227
2022-02-24 07:37:30 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 0.6927
2022-02-24 07:38:03 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 0.8232
2022-02-24 07:38:36 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 0.6945
2022-02-24 07:39:09 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 0.6128
2022-02-24 07:39:42 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 0.6965
2022-02-24 07:40:16 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 0.7249
2022-02-24 07:40:49 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 0.8260
2022-02-24 07:41:23 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 0.9279
2022-02-24 07:41:56 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 0.6500
2022-02-24 07:42:30 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 0.7334
2022-02-24 07:43:04 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 0.7871
2022-02-24 07:43:39 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 0.6588
2022-02-24 07:44:13 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 0.6797
2022-02-24 07:44:47 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 0.7375
2022-02-24 07:44:50 - train: epoch 095, train_loss: 0.7560
2022-02-24 07:46:08 - eval: epoch: 095, acc1: 76.724%, acc5: 93.418%, test_loss: 0.9178, per_image_load_time: 2.364ms, per_image_inference_time: 0.575ms
2022-02-24 07:46:09 - until epoch: 095, best_acc1: 76.764%
2022-02-24 21:54:16 - epoch 096 lr: 0.00010000000000000003
2022-02-24 21:54:54 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 0.8262
2022-02-24 21:55:27 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 0.7174
2022-02-24 21:55:59 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 0.7369
2022-02-24 21:56:31 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 0.6678
2022-02-24 21:57:03 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 0.6785
2022-02-24 21:57:35 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 0.8171
2022-02-24 21:58:07 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 0.7658
2022-02-24 21:58:40 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 0.6819
2022-02-24 21:59:12 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 0.6845
2022-02-24 21:59:45 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 0.8128
2022-02-24 22:00:17 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 0.6366
2022-02-24 22:00:50 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 0.7723
2022-02-24 22:01:23 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 0.6154
2022-02-24 22:01:55 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 0.8703
2022-02-24 22:02:28 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 0.7228
2022-02-24 22:03:00 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 0.5607
2022-02-24 22:03:33 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 0.7361
2022-02-24 22:04:06 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 0.8004
2022-02-24 22:04:39 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 0.7230
2022-02-24 22:05:11 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 0.7025
2022-02-24 22:05:44 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 0.7578
2022-02-24 22:06:17 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.4907
2022-02-24 22:06:49 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 0.7217
2022-02-24 22:07:22 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 0.8046
2022-02-24 22:07:55 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 0.6626
2022-02-24 22:08:28 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 0.7544
2022-02-24 22:09:01 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 0.7872
2022-02-24 22:09:33 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 0.8439
2022-02-24 22:10:06 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 0.7405
2022-02-24 22:10:39 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 0.7454
2022-02-24 22:11:12 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 0.8709
2022-02-24 22:11:45 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 0.8698
2022-02-24 22:12:18 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 0.8251
2022-02-24 22:12:51 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 0.5449
2022-02-24 22:13:24 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 0.7663
2022-02-24 22:13:57 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 0.7521
2022-02-24 22:14:30 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 0.7585
2022-02-24 22:15:03 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 0.6991
2022-02-24 22:15:36 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 0.6915
2022-02-24 22:16:10 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 0.8247
2022-02-24 22:16:43 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 0.8072
2022-02-24 22:17:16 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 0.7330
2022-02-24 22:17:50 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.7086
2022-02-24 22:18:23 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 0.6395
2022-02-24 22:18:57 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 0.8842
2022-02-24 22:19:31 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 0.7998
2022-02-24 22:20:05 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 0.8570
2022-02-24 22:20:39 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 0.8356
2022-02-24 22:21:14 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 0.7495
2022-02-24 22:21:49 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 0.8868
2022-02-24 22:21:50 - train: epoch 096, train_loss: 0.7549
2022-02-24 22:23:07 - eval: epoch: 096, acc1: 76.734%, acc5: 93.438%, test_loss: 0.9173, per_image_load_time: 2.417ms, per_image_inference_time: 0.569ms
2022-02-24 22:23:08 - until epoch: 096, best_acc1: 76.764%
2022-02-24 22:23:08 - epoch 097 lr: 0.00010000000000000003
2022-02-24 22:23:46 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 0.7940
2022-02-24 22:24:19 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 0.8024
2022-02-24 22:24:51 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 0.7631
2022-02-24 22:25:23 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 0.8440
2022-02-24 22:25:56 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 0.7634
2022-02-24 22:26:28 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 0.7583
2022-02-24 22:27:01 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 0.7463
2022-02-24 22:27:33 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.6038
2022-02-24 22:28:06 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 0.7285
2022-02-24 22:28:38 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 0.8672
2022-02-24 22:29:11 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 0.7377
2022-02-24 22:29:44 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 0.9272
2022-02-24 22:30:17 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 0.6470
2022-02-24 22:30:49 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 0.6723
2022-02-24 22:31:22 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 0.6900
2022-02-24 22:31:55 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 0.6507
2022-02-24 22:32:28 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 0.7519
2022-02-24 22:33:01 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 0.8281
2022-02-24 22:33:33 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 0.7210
2022-02-24 22:34:06 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 0.7993
2022-02-24 22:34:39 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 0.7213
2022-02-24 22:35:12 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 0.6763
2022-02-24 22:35:45 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 0.8151
2022-02-24 22:36:17 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 0.7770
2022-02-24 22:36:50 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 0.7897
2022-02-24 22:37:23 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 0.8046
2022-02-24 22:37:56 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 0.6837
2022-02-24 22:38:29 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 0.7271
2022-02-24 22:39:02 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 0.6598
2022-02-24 22:39:35 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 0.7516
2022-02-24 22:40:08 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 0.6536
2022-02-24 22:40:41 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 0.8607
2022-02-24 22:41:14 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 0.8528
2022-02-24 22:41:47 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 0.7636
2022-02-24 22:42:20 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 0.8642
2022-02-24 22:42:53 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 0.7881
2022-02-24 22:43:26 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 0.5773
2022-02-24 22:43:59 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 0.7720
2022-02-24 22:44:32 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 0.7935
2022-02-24 22:45:05 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 0.7633
2022-02-24 22:45:38 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 0.8164
2022-02-24 22:46:12 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 0.6605
2022-02-24 22:46:45 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 0.7157
2022-02-24 22:47:19 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 0.7706
2022-02-24 22:47:53 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 0.8393
2022-02-24 22:48:27 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 0.9061
2022-02-24 22:49:01 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 0.7342
2022-02-24 22:49:36 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 0.5948
2022-02-24 22:50:11 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 0.7539
2022-02-24 22:50:46 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 0.6469
2022-02-24 22:50:48 - train: epoch 097, train_loss: 0.7539
2022-02-24 22:52:05 - eval: epoch: 097, acc1: 76.836%, acc5: 93.450%, test_loss: 0.9153, per_image_load_time: 2.410ms, per_image_inference_time: 0.590ms
2022-02-24 22:52:06 - until epoch: 097, best_acc1: 76.836%
2022-02-24 22:52:06 - epoch 098 lr: 0.00010000000000000003
2022-02-24 22:52:44 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 0.6115
2022-02-24 22:53:16 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 0.8110
2022-02-24 22:53:49 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 0.8369
2022-02-24 22:54:21 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 0.6898
2022-02-24 22:54:53 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 0.8657
2022-02-24 22:55:26 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 0.8503
2022-02-24 22:55:59 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 0.7321
2022-02-24 22:56:31 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 0.8524
2022-02-24 22:57:04 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 0.8182
2022-02-24 22:57:36 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 0.7759
2022-02-24 22:58:09 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 0.7502
2022-02-24 22:58:42 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 0.8795
2022-02-24 22:59:15 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 0.7121
2022-02-24 22:59:47 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 0.8420
2022-02-24 23:00:20 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 0.8449
2022-02-24 23:00:52 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 0.6636
2022-02-24 23:01:25 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 0.7791
2022-02-24 23:01:58 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 0.7185
2022-02-24 23:02:31 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 0.5721
2022-02-24 23:03:04 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 0.9765
2022-02-24 23:03:37 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 0.8583
2022-02-24 23:04:10 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 0.6485
2022-02-24 23:04:43 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 0.6588
2022-02-24 23:05:16 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 0.6482
2022-02-24 23:05:49 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 0.7511
2022-02-24 23:06:22 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 0.6373
2022-02-24 23:06:55 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 0.7544
2022-02-24 23:07:28 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 0.7811
2022-02-24 23:08:01 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 0.6275
2022-02-24 23:08:34 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 0.7883
2022-02-24 23:09:07 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 0.7511
2022-02-24 23:09:40 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 0.7782
2022-02-24 23:10:13 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 0.8537
2022-02-24 23:10:46 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 0.6380
2022-02-24 23:11:18 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 0.7147
2022-02-24 23:11:51 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 0.8017
2022-02-24 23:12:25 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 0.7142
2022-02-24 23:12:58 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 0.6674
2022-02-24 23:13:31 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 0.6308
2022-02-24 23:14:04 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 0.8219
2022-02-24 23:14:37 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 0.8619
2022-02-24 23:15:11 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 0.7613
2022-02-24 23:15:44 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 0.6359
2022-02-24 23:16:18 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 0.8436
2022-02-24 23:16:52 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 0.7003
2022-02-24 23:17:26 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 0.7122
2022-02-24 23:18:00 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 0.6747
2022-02-24 23:18:35 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 0.8169
2022-02-24 23:19:10 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 0.7856
2022-02-24 23:19:44 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 0.7518
2022-02-24 23:19:46 - train: epoch 098, train_loss: 0.7526
2022-02-24 23:21:03 - eval: epoch: 098, acc1: 76.754%, acc5: 93.456%, test_loss: 0.9172, per_image_load_time: 2.251ms, per_image_inference_time: 0.589ms
2022-02-24 23:21:04 - until epoch: 098, best_acc1: 76.836%
2022-02-24 23:21:04 - epoch 099 lr: 0.00010000000000000003
2022-02-24 23:21:43 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 0.8177
2022-02-24 23:22:15 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 0.6059
2022-02-24 23:22:47 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 0.6971
2022-02-24 23:23:20 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 0.7503
2022-02-24 23:23:52 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 0.6110
2022-02-24 23:24:25 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 0.7656
2022-02-24 23:24:57 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 0.8206
2022-02-24 23:25:30 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 0.6799
2022-02-24 23:26:03 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 0.8882
2022-02-24 23:26:35 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 0.7152
2022-02-24 23:27:08 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 0.6184
2022-02-24 23:27:41 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 0.5481
2022-02-24 23:28:14 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 0.6338
2022-02-24 23:28:47 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 0.7435
2022-02-24 23:29:20 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 0.7028
2022-02-24 23:29:53 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 0.7998
2022-02-24 23:30:26 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 0.6619
2022-02-24 23:30:58 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 0.7232
2022-02-24 23:31:31 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 0.8903
2022-02-24 23:32:04 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 0.6102
2022-02-24 23:32:37 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 0.7137
2022-02-24 23:33:10 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 0.7544
2022-02-24 23:33:42 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 0.8327
2022-02-24 23:34:15 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 0.8609
2022-02-24 23:34:48 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 0.6605
2022-02-24 23:35:21 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 0.7167
2022-02-24 23:35:55 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 0.7781
2022-02-24 23:36:28 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 0.7373
2022-02-24 23:37:01 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 0.7068
2022-02-24 23:37:34 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 0.8968
2022-02-24 23:38:07 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 0.6556
2022-02-24 23:38:40 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 0.6795
2022-02-24 23:39:13 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 0.7933
2022-02-24 23:39:46 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 0.8469
2022-02-24 23:40:19 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 0.7531
2022-02-24 23:40:52 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 0.6263
2022-02-24 23:41:25 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 0.6396
2022-02-24 23:41:58 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 0.7588
2022-02-24 23:42:32 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 0.9728
2022-02-24 23:43:05 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 0.6626
2022-02-24 23:43:39 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 0.6328
2022-02-24 23:44:12 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 0.8608
2022-02-24 23:44:46 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 0.7427
2022-02-24 23:45:20 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 0.8386
2022-02-24 23:45:54 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 0.7953
2022-02-24 23:46:28 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 0.8104
2022-02-24 23:47:03 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 0.7277
2022-02-24 23:47:38 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 0.7788
2022-02-24 23:48:12 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 0.8405
2022-02-24 23:48:47 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 0.8306
2022-02-24 23:48:49 - train: epoch 099, train_loss: 0.7502
2022-02-24 23:50:06 - eval: epoch: 099, acc1: 76.746%, acc5: 93.472%, test_loss: 0.9168, per_image_load_time: 2.424ms, per_image_inference_time: 0.571ms
2022-02-24 23:50:07 - until epoch: 099, best_acc1: 76.836%
2022-02-25 07:49:49 - epoch 100 lr: 0.00010000000000000003
2022-02-25 07:50:29 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 0.8499
2022-02-25 07:51:00 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 0.7035
2022-02-25 07:51:32 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 0.8760
2022-02-25 07:52:04 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 0.5785
2022-02-25 07:52:36 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 0.8281
2022-02-25 07:53:08 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 0.6602
2022-02-25 07:53:41 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 0.6350
2022-02-25 07:54:13 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 0.8525
2022-02-25 07:54:45 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 0.6702
2022-02-25 07:55:17 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 0.7393
2022-02-25 07:55:50 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 0.7137
2022-02-25 07:56:22 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 0.7612
2022-02-25 07:56:55 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 0.6899
2022-02-25 07:57:27 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 0.8031
2022-02-25 07:58:00 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 0.7549
2022-02-25 07:58:32 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 0.7649
2022-02-25 07:59:05 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 0.6241
2022-02-25 07:59:37 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 0.6598
2022-02-25 08:00:10 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 0.7052
2022-02-25 08:00:42 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 0.8101
2022-02-25 08:01:15 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 0.7806
2022-02-25 08:01:48 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 0.9064
2022-02-25 08:02:21 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 0.7132
2022-02-25 08:02:54 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 0.7733
2022-02-25 08:03:27 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 0.7313
2022-02-25 08:03:59 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 0.7334
2022-02-25 08:04:32 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 0.8229
2022-02-25 08:05:05 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 0.6879
2022-02-25 08:05:37 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 0.6532
2022-02-25 08:06:10 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 0.7410
2022-02-25 08:06:43 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 0.6555
2022-02-25 08:07:16 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 0.7526
2022-02-25 08:07:49 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 0.7177
2022-02-25 08:08:22 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 0.6727
2022-02-25 08:08:55 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 0.5936
2022-02-25 08:09:29 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 0.7363
2022-02-25 08:10:02 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 0.7355
2022-02-25 08:10:35 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 0.8846
2022-02-25 08:11:08 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 0.9028
2022-02-25 08:11:41 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 0.8085
2022-02-25 08:12:14 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 0.8504
2022-02-25 08:12:48 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 0.6858
2022-02-25 08:13:21 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 0.8071
2022-02-25 08:13:55 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 0.7173
2022-02-25 08:14:29 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 0.7356
2022-02-25 08:15:03 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 0.7936
2022-02-25 08:15:37 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 0.7843
2022-02-25 08:16:12 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 0.6718
2022-02-25 08:16:46 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 0.7587
2022-02-25 08:17:21 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 0.8566
2022-02-25 08:17:23 - train: epoch 100, train_loss: 0.7481
2022-02-25 08:18:38 - eval: epoch: 100, acc1: 76.704%, acc5: 93.474%, test_loss: 0.9186, per_image_load_time: 2.354ms, per_image_inference_time: 0.591ms
2022-02-25 08:18:39 - until epoch: 100, best_acc1: 76.836%
2022-02-25 08:31:02 - train done. model: darknet53, train time: 48.257 hours, best_acc1: 76.836%
