2022-07-11 22:38:45 - train: epoch 0051, iter [00500, 05004], lr: 0.010000, loss: 1.1268
2022-07-11 22:39:17 - train: epoch 0051, iter [00600, 05004], lr: 0.010000, loss: 1.1111
2022-07-11 22:39:50 - train: epoch 0051, iter [00700, 05004], lr: 0.010000, loss: 0.9319
2022-07-11 22:40:22 - train: epoch 0051, iter [00800, 05004], lr: 0.010000, loss: 1.2431
2022-07-11 22:40:55 - train: epoch 0051, iter [00900, 05004], lr: 0.010000, loss: 1.0037
2022-07-11 22:41:27 - train: epoch 0051, iter [01000, 05004], lr: 0.010000, loss: 1.3543
2022-07-11 22:41:59 - train: epoch 0051, iter [01100, 05004], lr: 0.010000, loss: 1.1502
2022-07-11 22:42:32 - train: epoch 0051, iter [01200, 05004], lr: 0.010000, loss: 0.9641
2022-07-11 22:43:05 - train: epoch 0051, iter [01300, 05004], lr: 0.010000, loss: 0.8673
2022-07-11 22:43:38 - train: epoch 0051, iter [01400, 05004], lr: 0.010000, loss: 0.9822
2022-07-11 22:44:11 - train: epoch 0051, iter [01500, 05004], lr: 0.010000, loss: 1.0725
2022-07-11 22:44:43 - train: epoch 0051, iter [01600, 05004], lr: 0.010000, loss: 1.0432
2022-07-11 22:45:16 - train: epoch 0051, iter [01700, 05004], lr: 0.010000, loss: 1.1746
2022-07-11 22:45:48 - train: epoch 0051, iter [01800, 05004], lr: 0.010000, loss: 1.1763
2022-07-11 22:46:21 - train: epoch 0051, iter [01900, 05004], lr: 0.010000, loss: 0.8803
2022-07-11 22:46:54 - train: epoch 0051, iter [02000, 05004], lr: 0.010000, loss: 1.0158
2022-07-11 22:47:26 - train: epoch 0051, iter [02100, 05004], lr: 0.010000, loss: 1.0790
2022-07-11 22:47:59 - train: epoch 0051, iter [02200, 05004], lr: 0.010000, loss: 1.1085
2022-07-11 22:48:31 - train: epoch 0051, iter [02300, 05004], lr: 0.010000, loss: 1.1175
2022-07-11 22:49:04 - train: epoch 0051, iter [02400, 05004], lr: 0.010000, loss: 1.2478
2022-07-11 22:49:36 - train: epoch 0051, iter [02500, 05004], lr: 0.010000, loss: 1.0418
2022-07-11 22:50:09 - train: epoch 0051, iter [02600, 05004], lr: 0.010000, loss: 1.0300
2022-07-11 22:50:42 - train: epoch 0051, iter [02700, 05004], lr: 0.010000, loss: 1.2035
2022-07-11 22:51:14 - train: epoch 0051, iter [02800, 05004], lr: 0.010000, loss: 1.0449
2022-07-11 22:51:47 - train: epoch 0051, iter [02900, 05004], lr: 0.010000, loss: 1.0581
2022-07-11 22:52:19 - train: epoch 0051, iter [03000, 05004], lr: 0.010000, loss: 1.0962
2022-07-11 22:52:52 - train: epoch 0051, iter [03100, 05004], lr: 0.010000, loss: 1.0379
2022-07-11 22:53:25 - train: epoch 0051, iter [03200, 05004], lr: 0.010000, loss: 1.0812
2022-07-11 22:53:57 - train: epoch 0051, iter [03300, 05004], lr: 0.010000, loss: 1.2137
2022-07-11 22:54:30 - train: epoch 0051, iter [03400, 05004], lr: 0.010000, loss: 1.2727
2022-07-11 22:55:03 - train: epoch 0051, iter [03500, 05004], lr: 0.010000, loss: 1.0454
2022-07-11 22:55:35 - train: epoch 0051, iter [03600, 05004], lr: 0.010000, loss: 1.0798
2022-07-11 22:56:08 - train: epoch 0051, iter [03700, 05004], lr: 0.010000, loss: 1.2408
2022-07-11 22:56:41 - train: epoch 0051, iter [03800, 05004], lr: 0.010000, loss: 1.1180
2022-07-11 22:57:13 - train: epoch 0051, iter [03900, 05004], lr: 0.010000, loss: 1.1558
2022-07-11 22:57:46 - train: epoch 0051, iter [04000, 05004], lr: 0.010000, loss: 1.0569
2022-07-11 22:58:19 - train: epoch 0051, iter [04100, 05004], lr: 0.010000, loss: 1.1312
2022-07-11 22:58:51 - train: epoch 0051, iter [04200, 05004], lr: 0.010000, loss: 1.4345
2022-07-11 22:59:24 - train: epoch 0051, iter [04300, 05004], lr: 0.010000, loss: 1.1184
2022-07-11 22:59:57 - train: epoch 0051, iter [04400, 05004], lr: 0.010000, loss: 1.1117
2022-07-11 23:00:30 - train: epoch 0051, iter [04500, 05004], lr: 0.010000, loss: 0.9910
2022-07-11 23:01:03 - train: epoch 0051, iter [04600, 05004], lr: 0.010000, loss: 1.1843
2022-07-11 23:01:36 - train: epoch 0051, iter [04700, 05004], lr: 0.010000, loss: 1.1919
2022-07-11 23:02:09 - train: epoch 0051, iter [04800, 05004], lr: 0.010000, loss: 1.0679
2022-07-11 23:02:41 - train: epoch 0051, iter [04900, 05004], lr: 0.010000, loss: 1.2311
2022-07-11 23:03:13 - train: epoch 0051, iter [05000, 05004], lr: 0.010000, loss: 1.0245
2022-07-11 23:03:15 - train: epoch 051, train_loss: 1.1214
2022-07-11 23:04:31 - eval: epoch: 051, acc1: 73.170%, acc5: 91.310%, test_loss: 1.0824, per_image_load_time: 2.348ms, per_image_inference_time: 0.591ms
2022-07-11 23:04:31 - until epoch: 051, best_acc1: 73.936%
2022-07-11 23:04:31 - epoch 052 lr: 0.010000
2022-07-11 23:05:11 - train: epoch 0052, iter [00100, 05004], lr: 0.010000, loss: 0.9665
2022-07-11 23:05:43 - train: epoch 0052, iter [00200, 05004], lr: 0.010000, loss: 1.1249
2022-07-11 23:06:16 - train: epoch 0052, iter [00300, 05004], lr: 0.010000, loss: 1.1761
2022-07-11 23:06:48 - train: epoch 0052, iter [00400, 05004], lr: 0.010000, loss: 1.1184
2022-07-11 23:07:21 - train: epoch 0052, iter [00500, 05004], lr: 0.010000, loss: 1.1494
2022-07-11 23:07:54 - train: epoch 0052, iter [00600, 05004], lr: 0.010000, loss: 0.9987
2022-07-11 23:08:26 - train: epoch 0052, iter [00700, 05004], lr: 0.010000, loss: 1.1474
2022-07-11 23:08:59 - train: epoch 0052, iter [00800, 05004], lr: 0.010000, loss: 1.1731
2022-07-11 23:09:32 - train: epoch 0052, iter [00900, 05004], lr: 0.010000, loss: 1.1333
2022-07-11 23:10:04 - train: epoch 0052, iter [01000, 05004], lr: 0.010000, loss: 1.1748
2022-07-11 23:10:37 - train: epoch 0052, iter [01100, 05004], lr: 0.010000, loss: 1.1675
2022-07-11 23:11:10 - train: epoch 0052, iter [01200, 05004], lr: 0.010000, loss: 0.9982
2022-07-11 23:11:42 - train: epoch 0052, iter [01300, 05004], lr: 0.010000, loss: 1.0282
2022-07-11 23:12:15 - train: epoch 0052, iter [01400, 05004], lr: 0.010000, loss: 1.3882
2022-07-11 23:12:47 - train: epoch 0052, iter [01500, 05004], lr: 0.010000, loss: 0.9889
2022-07-11 23:13:20 - train: epoch 0052, iter [01600, 05004], lr: 0.010000, loss: 1.0321
2022-07-11 23:13:53 - train: epoch 0052, iter [01700, 05004], lr: 0.010000, loss: 0.9692
2022-07-11 23:14:25 - train: epoch 0052, iter [01800, 05004], lr: 0.010000, loss: 1.0079
2022-07-11 23:14:58 - train: epoch 0052, iter [01900, 05004], lr: 0.010000, loss: 1.1912
2022-07-11 23:15:31 - train: epoch 0052, iter [02000, 05004], lr: 0.010000, loss: 1.0924
2022-07-11 23:16:03 - train: epoch 0052, iter [02100, 05004], lr: 0.010000, loss: 1.0434
2022-07-11 23:16:36 - train: epoch 0052, iter [02200, 05004], lr: 0.010000, loss: 1.1870
2022-07-11 23:17:08 - train: epoch 0052, iter [02300, 05004], lr: 0.010000, loss: 0.9918
2022-07-11 23:17:41 - train: epoch 0052, iter [02400, 05004], lr: 0.010000, loss: 0.9890
2022-07-11 23:18:13 - train: epoch 0052, iter [02500, 05004], lr: 0.010000, loss: 1.0755
2022-07-11 23:18:46 - train: epoch 0052, iter [02600, 05004], lr: 0.010000, loss: 0.9201
2022-07-11 23:19:18 - train: epoch 0052, iter [02700, 05004], lr: 0.010000, loss: 1.0359
2022-07-11 23:19:51 - train: epoch 0052, iter [02800, 05004], lr: 0.010000, loss: 1.0786
2022-07-11 23:20:24 - train: epoch 0052, iter [02900, 05004], lr: 0.010000, loss: 0.9754
2022-07-11 23:20:56 - train: epoch 0052, iter [03000, 05004], lr: 0.010000, loss: 1.1323
2022-07-11 23:21:29 - train: epoch 0052, iter [03100, 05004], lr: 0.010000, loss: 1.1612
2022-07-11 23:22:01 - train: epoch 0052, iter [03200, 05004], lr: 0.010000, loss: 1.2144
2022-07-11 23:22:34 - train: epoch 0052, iter [03300, 05004], lr: 0.010000, loss: 1.1725
2022-07-11 23:23:06 - train: epoch 0052, iter [03400, 05004], lr: 0.010000, loss: 1.1328
2022-07-11 23:23:39 - train: epoch 0052, iter [03500, 05004], lr: 0.010000, loss: 1.1802
2022-07-11 23:24:11 - train: epoch 0052, iter [03600, 05004], lr: 0.010000, loss: 1.2031
2022-07-11 23:24:44 - train: epoch 0052, iter [03700, 05004], lr: 0.010000, loss: 1.3163
2022-07-11 23:25:17 - train: epoch 0052, iter [03800, 05004], lr: 0.010000, loss: 0.9809
2022-07-11 23:25:49 - train: epoch 0052, iter [03900, 05004], lr: 0.010000, loss: 1.0864
2022-07-11 23:26:22 - train: epoch 0052, iter [04000, 05004], lr: 0.010000, loss: 1.2659
2022-07-11 23:26:55 - train: epoch 0052, iter [04100, 05004], lr: 0.010000, loss: 1.0236
2022-07-11 23:27:28 - train: epoch 0052, iter [04200, 05004], lr: 0.010000, loss: 1.0048
2022-07-11 23:28:01 - train: epoch 0052, iter [04300, 05004], lr: 0.010000, loss: 1.1180
2022-07-11 23:28:33 - train: epoch 0052, iter [04400, 05004], lr: 0.010000, loss: 1.1601
2022-07-11 23:29:06 - train: epoch 0052, iter [04500, 05004], lr: 0.010000, loss: 1.0796
2022-07-11 23:29:39 - train: epoch 0052, iter [04600, 05004], lr: 0.010000, loss: 1.2353
2022-07-11 23:30:12 - train: epoch 0052, iter [04700, 05004], lr: 0.010000, loss: 1.1497
2022-07-11 23:30:44 - train: epoch 0052, iter [04800, 05004], lr: 0.010000, loss: 0.9418
2022-07-11 23:31:17 - train: epoch 0052, iter [04900, 05004], lr: 0.010000, loss: 0.9743
2022-07-11 23:31:50 - train: epoch 0052, iter [05000, 05004], lr: 0.010000, loss: 1.1796
2022-07-11 23:31:51 - train: epoch 052, train_loss: 1.1179
2022-07-11 23:33:06 - eval: epoch: 052, acc1: 73.208%, acc5: 91.390%, test_loss: 1.0769, per_image_load_time: 2.239ms, per_image_inference_time: 0.570ms
2022-07-11 23:33:07 - until epoch: 052, best_acc1: 73.936%
2022-07-11 23:33:07 - epoch 053 lr: 0.010000
2022-07-11 23:33:46 - train: epoch 0053, iter [00100, 05004], lr: 0.010000, loss: 1.0751
2022-07-11 23:34:19 - train: epoch 0053, iter [00200, 05004], lr: 0.010000, loss: 1.2454
2022-07-11 23:34:51 - train: epoch 0053, iter [00300, 05004], lr: 0.010000, loss: 1.1185
2022-07-11 23:35:23 - train: epoch 0053, iter [00400, 05004], lr: 0.010000, loss: 1.1309
2022-07-11 23:35:56 - train: epoch 0053, iter [00500, 05004], lr: 0.010000, loss: 1.1911
2022-07-11 23:36:29 - train: epoch 0053, iter [00600, 05004], lr: 0.010000, loss: 1.0007
2022-07-11 23:37:01 - train: epoch 0053, iter [00700, 05004], lr: 0.010000, loss: 0.9448
2022-07-11 23:37:34 - train: epoch 0053, iter [00800, 05004], lr: 0.010000, loss: 1.1841
2022-07-11 23:38:07 - train: epoch 0053, iter [00900, 05004], lr: 0.010000, loss: 1.1220
2022-07-11 23:38:39 - train: epoch 0053, iter [01000, 05004], lr: 0.010000, loss: 1.0239
2022-07-11 23:39:12 - train: epoch 0053, iter [01100, 05004], lr: 0.010000, loss: 1.0579
2022-07-11 23:39:45 - train: epoch 0053, iter [01200, 05004], lr: 0.010000, loss: 1.0297
2022-07-11 23:40:17 - train: epoch 0053, iter [01300, 05004], lr: 0.010000, loss: 1.1998
2022-07-11 23:40:50 - train: epoch 0053, iter [01400, 05004], lr: 0.010000, loss: 1.4208
2022-07-11 23:41:23 - train: epoch 0053, iter [01500, 05004], lr: 0.010000, loss: 1.0617
2022-07-11 23:41:55 - train: epoch 0053, iter [01600, 05004], lr: 0.010000, loss: 1.4085
2022-07-11 23:42:28 - train: epoch 0053, iter [01700, 05004], lr: 0.010000, loss: 1.3478
2022-07-11 23:43:00 - train: epoch 0053, iter [01800, 05004], lr: 0.010000, loss: 1.2333
2022-07-11 23:43:33 - train: epoch 0053, iter [01900, 05004], lr: 0.010000, loss: 0.9283
2022-07-11 23:44:05 - train: epoch 0053, iter [02000, 05004], lr: 0.010000, loss: 1.0846
2022-07-11 23:44:37 - train: epoch 0053, iter [02100, 05004], lr: 0.010000, loss: 1.1169
2022-07-11 23:45:10 - train: epoch 0053, iter [02200, 05004], lr: 0.010000, loss: 1.0118
2022-07-11 23:45:43 - train: epoch 0053, iter [02300, 05004], lr: 0.010000, loss: 1.1354
2022-07-11 23:46:16 - train: epoch 0053, iter [02400, 05004], lr: 0.010000, loss: 1.0750
2022-07-11 23:46:49 - train: epoch 0053, iter [02500, 05004], lr: 0.010000, loss: 1.3961
2022-07-11 23:47:21 - train: epoch 0053, iter [02600, 05004], lr: 0.010000, loss: 1.1294
2022-07-11 23:47:54 - train: epoch 0053, iter [02700, 05004], lr: 0.010000, loss: 1.2761
2022-07-11 23:48:27 - train: epoch 0053, iter [02800, 05004], lr: 0.010000, loss: 1.2106
2022-07-11 23:48:59 - train: epoch 0053, iter [02900, 05004], lr: 0.010000, loss: 0.9922
2022-07-11 23:49:32 - train: epoch 0053, iter [03000, 05004], lr: 0.010000, loss: 0.9840
2022-07-11 23:50:04 - train: epoch 0053, iter [03100, 05004], lr: 0.010000, loss: 1.2801
2022-07-11 23:50:37 - train: epoch 0053, iter [03200, 05004], lr: 0.010000, loss: 1.3483
2022-07-11 23:51:09 - train: epoch 0053, iter [03300, 05004], lr: 0.010000, loss: 1.1047
2022-07-11 23:51:42 - train: epoch 0053, iter [03400, 05004], lr: 0.010000, loss: 1.1992
2022-07-11 23:52:14 - train: epoch 0053, iter [03500, 05004], lr: 0.010000, loss: 1.2069
2022-07-11 23:52:47 - train: epoch 0053, iter [03600, 05004], lr: 0.010000, loss: 1.2349
2022-07-11 23:53:20 - train: epoch 0053, iter [03700, 05004], lr: 0.010000, loss: 1.2252
2022-07-11 23:53:53 - train: epoch 0053, iter [03800, 05004], lr: 0.010000, loss: 1.1047
2022-07-11 23:54:25 - train: epoch 0053, iter [03900, 05004], lr: 0.010000, loss: 1.1727
2022-07-11 23:54:57 - train: epoch 0053, iter [04000, 05004], lr: 0.010000, loss: 1.2344
2022-07-11 23:55:30 - train: epoch 0053, iter [04100, 05004], lr: 0.010000, loss: 1.1634
2022-07-11 23:56:03 - train: epoch 0053, iter [04200, 05004], lr: 0.010000, loss: 1.2062
2022-07-11 23:56:35 - train: epoch 0053, iter [04300, 05004], lr: 0.010000, loss: 1.3123
2022-07-11 23:57:08 - train: epoch 0053, iter [04400, 05004], lr: 0.010000, loss: 1.0248
2022-07-11 23:57:41 - train: epoch 0053, iter [04500, 05004], lr: 0.010000, loss: 1.1970
2022-07-11 23:58:14 - train: epoch 0053, iter [04600, 05004], lr: 0.010000, loss: 0.9979
2022-07-11 23:58:46 - train: epoch 0053, iter [04700, 05004], lr: 0.010000, loss: 1.3897
2022-07-11 23:59:19 - train: epoch 0053, iter [04800, 05004], lr: 0.010000, loss: 1.3615
2022-07-11 23:59:51 - train: epoch 0053, iter [04900, 05004], lr: 0.010000, loss: 0.9713
2022-07-12 00:00:24 - train: epoch 0053, iter [05000, 05004], lr: 0.010000, loss: 1.0734
2022-07-12 00:00:25 - train: epoch 053, train_loss: 1.1155
2022-07-12 00:01:41 - eval: epoch: 053, acc1: 73.348%, acc5: 91.680%, test_loss: 1.0690, per_image_load_time: 2.238ms, per_image_inference_time: 0.578ms
2022-07-12 00:01:41 - until epoch: 053, best_acc1: 73.936%
2022-07-12 00:01:41 - epoch 054 lr: 0.010000
2022-07-12 00:02:20 - train: epoch 0054, iter [00100, 05004], lr: 0.010000, loss: 0.9098
2022-07-12 00:02:53 - train: epoch 0054, iter [00200, 05004], lr: 0.010000, loss: 1.4310
2022-07-12 00:03:25 - train: epoch 0054, iter [00300, 05004], lr: 0.010000, loss: 1.0814
2022-07-12 00:03:58 - train: epoch 0054, iter [00400, 05004], lr: 0.010000, loss: 0.9070
2022-07-12 00:04:30 - train: epoch 0054, iter [00500, 05004], lr: 0.010000, loss: 1.1766
2022-07-12 00:05:03 - train: epoch 0054, iter [00600, 05004], lr: 0.010000, loss: 0.9604
2022-07-12 00:05:36 - train: epoch 0054, iter [00700, 05004], lr: 0.010000, loss: 1.0679
2022-07-12 00:06:09 - train: epoch 0054, iter [00800, 05004], lr: 0.010000, loss: 1.2200
2022-07-12 00:06:42 - train: epoch 0054, iter [00900, 05004], lr: 0.010000, loss: 0.9891
2022-07-12 00:07:14 - train: epoch 0054, iter [01000, 05004], lr: 0.010000, loss: 0.9679
2022-07-12 00:07:48 - train: epoch 0054, iter [01100, 05004], lr: 0.010000, loss: 0.9085
2022-07-12 00:08:20 - train: epoch 0054, iter [01200, 05004], lr: 0.010000, loss: 1.2359
2022-07-12 00:08:53 - train: epoch 0054, iter [01300, 05004], lr: 0.010000, loss: 1.0381
2022-07-12 00:09:26 - train: epoch 0054, iter [01400, 05004], lr: 0.010000, loss: 1.1649
2022-07-12 00:09:58 - train: epoch 0054, iter [01500, 05004], lr: 0.010000, loss: 1.1703
2022-07-12 00:10:31 - train: epoch 0054, iter [01600, 05004], lr: 0.010000, loss: 0.7940
2022-07-12 00:11:04 - train: epoch 0054, iter [01700, 05004], lr: 0.010000, loss: 1.2180
2022-07-12 00:11:36 - train: epoch 0054, iter [01800, 05004], lr: 0.010000, loss: 1.0128
2022-07-12 00:12:09 - train: epoch 0054, iter [01900, 05004], lr: 0.010000, loss: 1.4312
2022-07-12 00:12:42 - train: epoch 0054, iter [02000, 05004], lr: 0.010000, loss: 1.2182
2022-07-12 00:13:14 - train: epoch 0054, iter [02100, 05004], lr: 0.010000, loss: 1.0174
2022-07-12 00:13:47 - train: epoch 0054, iter [02200, 05004], lr: 0.010000, loss: 1.0652
2022-07-12 00:14:20 - train: epoch 0054, iter [02300, 05004], lr: 0.010000, loss: 1.2213
2022-07-12 00:14:53 - train: epoch 0054, iter [02400, 05004], lr: 0.010000, loss: 0.9572
2022-07-12 00:15:26 - train: epoch 0054, iter [02500, 05004], lr: 0.010000, loss: 1.1586
2022-07-12 00:15:59 - train: epoch 0054, iter [02600, 05004], lr: 0.010000, loss: 1.0480
2022-07-12 00:16:32 - train: epoch 0054, iter [02700, 05004], lr: 0.010000, loss: 1.1777
2022-07-12 00:17:04 - train: epoch 0054, iter [02800, 05004], lr: 0.010000, loss: 1.4244
2022-07-12 00:17:37 - train: epoch 0054, iter [02900, 05004], lr: 0.010000, loss: 0.9776
2022-07-12 00:18:09 - train: epoch 0054, iter [03000, 05004], lr: 0.010000, loss: 1.2497
2022-07-12 00:18:42 - train: epoch 0054, iter [03100, 05004], lr: 0.010000, loss: 1.1610
2022-07-12 00:19:14 - train: epoch 0054, iter [03200, 05004], lr: 0.010000, loss: 1.2404
2022-07-12 00:19:47 - train: epoch 0054, iter [03300, 05004], lr: 0.010000, loss: 1.0459
2022-07-12 00:20:20 - train: epoch 0054, iter [03400, 05004], lr: 0.010000, loss: 1.1804
2022-07-12 00:20:53 - train: epoch 0054, iter [03500, 05004], lr: 0.010000, loss: 1.1476
2022-07-12 00:21:25 - train: epoch 0054, iter [03600, 05004], lr: 0.010000, loss: 1.0634
2022-07-12 00:21:58 - train: epoch 0054, iter [03700, 05004], lr: 0.010000, loss: 1.0089
2022-07-12 00:22:31 - train: epoch 0054, iter [03800, 05004], lr: 0.010000, loss: 1.1663
2022-07-12 00:23:03 - train: epoch 0054, iter [03900, 05004], lr: 0.010000, loss: 1.0441
2022-07-12 00:23:36 - train: epoch 0054, iter [04000, 05004], lr: 0.010000, loss: 1.0161
2022-07-12 00:24:09 - train: epoch 0054, iter [04100, 05004], lr: 0.010000, loss: 1.1246
2022-07-12 00:24:41 - train: epoch 0054, iter [04200, 05004], lr: 0.010000, loss: 1.1630
2022-07-12 00:25:14 - train: epoch 0054, iter [04300, 05004], lr: 0.010000, loss: 1.1974
2022-07-12 00:25:47 - train: epoch 0054, iter [04400, 05004], lr: 0.010000, loss: 1.0963
2022-07-12 00:26:20 - train: epoch 0054, iter [04500, 05004], lr: 0.010000, loss: 0.9415
2022-07-12 00:26:53 - train: epoch 0054, iter [04600, 05004], lr: 0.010000, loss: 1.1373
2022-07-12 00:27:25 - train: epoch 0054, iter [04700, 05004], lr: 0.010000, loss: 1.2277
2022-07-12 00:27:58 - train: epoch 0054, iter [04800, 05004], lr: 0.010000, loss: 1.3033
2022-07-12 00:28:32 - train: epoch 0054, iter [04900, 05004], lr: 0.010000, loss: 0.9914
2022-07-12 00:29:04 - train: epoch 0054, iter [05000, 05004], lr: 0.010000, loss: 1.2913
2022-07-12 00:29:06 - train: epoch 054, train_loss: 1.1153
2022-07-12 00:30:21 - eval: epoch: 054, acc1: 72.952%, acc5: 91.306%, test_loss: 1.0847, per_image_load_time: 2.188ms, per_image_inference_time: 0.587ms
2022-07-12 00:30:21 - until epoch: 054, best_acc1: 73.936%
2022-07-12 00:30:21 - epoch 055 lr: 0.010000
2022-07-12 00:31:01 - train: epoch 0055, iter [00100, 05004], lr: 0.010000, loss: 1.0270
2022-07-12 00:31:33 - train: epoch 0055, iter [00200, 05004], lr: 0.010000, loss: 0.9878
2022-07-12 00:32:06 - train: epoch 0055, iter [00300, 05004], lr: 0.010000, loss: 0.9339
2022-07-12 00:32:38 - train: epoch 0055, iter [00400, 05004], lr: 0.010000, loss: 1.0672
2022-07-12 00:33:10 - train: epoch 0055, iter [00500, 05004], lr: 0.010000, loss: 0.8816
2022-07-12 00:33:43 - train: epoch 0055, iter [00600, 05004], lr: 0.010000, loss: 1.0330
2022-07-12 00:34:15 - train: epoch 0055, iter [00700, 05004], lr: 0.010000, loss: 1.1477
2022-07-12 00:34:47 - train: epoch 0055, iter [00800, 05004], lr: 0.010000, loss: 0.9584
2022-07-12 00:35:20 - train: epoch 0055, iter [00900, 05004], lr: 0.010000, loss: 1.0822
2022-07-12 00:35:52 - train: epoch 0055, iter [01000, 05004], lr: 0.010000, loss: 1.1264
2022-07-12 00:36:25 - train: epoch 0055, iter [01100, 05004], lr: 0.010000, loss: 1.0442
2022-07-12 00:36:57 - train: epoch 0055, iter [01200, 05004], lr: 0.010000, loss: 1.2406
2022-07-12 00:37:30 - train: epoch 0055, iter [01300, 05004], lr: 0.010000, loss: 1.1909
2022-07-12 00:38:02 - train: epoch 0055, iter [01400, 05004], lr: 0.010000, loss: 0.9915
2022-07-12 00:38:35 - train: epoch 0055, iter [01500, 05004], lr: 0.010000, loss: 1.1539
2022-07-12 00:39:08 - train: epoch 0055, iter [01600, 05004], lr: 0.010000, loss: 1.2499
2022-07-12 00:39:40 - train: epoch 0055, iter [01700, 05004], lr: 0.010000, loss: 1.1822
2022-07-12 00:40:13 - train: epoch 0055, iter [01800, 05004], lr: 0.010000, loss: 1.1988
2022-07-12 00:40:45 - train: epoch 0055, iter [01900, 05004], lr: 0.010000, loss: 1.0882
2022-07-12 00:41:18 - train: epoch 0055, iter [02000, 05004], lr: 0.010000, loss: 1.1314
2022-07-12 00:41:50 - train: epoch 0055, iter [02100, 05004], lr: 0.010000, loss: 0.9760
2022-07-12 00:42:23 - train: epoch 0055, iter [02200, 05004], lr: 0.010000, loss: 1.2056
2022-07-12 00:42:56 - train: epoch 0055, iter [02300, 05004], lr: 0.010000, loss: 1.1119
2022-07-12 00:43:28 - train: epoch 0055, iter [02400, 05004], lr: 0.010000, loss: 1.0143
2022-07-12 00:44:01 - train: epoch 0055, iter [02500, 05004], lr: 0.010000, loss: 1.0675
2022-07-12 00:44:34 - train: epoch 0055, iter [02600, 05004], lr: 0.010000, loss: 1.0175
2022-07-12 00:45:06 - train: epoch 0055, iter [02700, 05004], lr: 0.010000, loss: 0.8332
2022-07-12 00:45:39 - train: epoch 0055, iter [02800, 05004], lr: 0.010000, loss: 1.0988
2022-07-12 00:46:11 - train: epoch 0055, iter [02900, 05004], lr: 0.010000, loss: 1.2372
2022-07-12 00:46:44 - train: epoch 0055, iter [03000, 05004], lr: 0.010000, loss: 1.0064
2022-07-12 00:47:17 - train: epoch 0055, iter [03100, 05004], lr: 0.010000, loss: 1.2245
2022-07-12 00:47:49 - train: epoch 0055, iter [03200, 05004], lr: 0.010000, loss: 1.0469
2022-07-12 00:48:22 - train: epoch 0055, iter [03300, 05004], lr: 0.010000, loss: 0.9533
2022-07-12 00:48:54 - train: epoch 0055, iter [03400, 05004], lr: 0.010000, loss: 1.0492
2022-07-12 00:49:27 - train: epoch 0055, iter [03500, 05004], lr: 0.010000, loss: 0.9459
2022-07-12 00:50:00 - train: epoch 0055, iter [03600, 05004], lr: 0.010000, loss: 1.1693
2022-07-12 00:50:33 - train: epoch 0055, iter [03700, 05004], lr: 0.010000, loss: 1.0768
2022-07-12 00:51:05 - train: epoch 0055, iter [03800, 05004], lr: 0.010000, loss: 1.2054
2022-07-12 00:51:38 - train: epoch 0055, iter [03900, 05004], lr: 0.010000, loss: 1.2916
2022-07-12 00:52:11 - train: epoch 0055, iter [04000, 05004], lr: 0.010000, loss: 1.1599
2022-07-12 00:52:43 - train: epoch 0055, iter [04100, 05004], lr: 0.010000, loss: 1.0691
2022-07-12 00:53:17 - train: epoch 0055, iter [04200, 05004], lr: 0.010000, loss: 1.1217
2022-07-12 00:53:49 - train: epoch 0055, iter [04300, 05004], lr: 0.010000, loss: 1.1956
2022-07-12 00:54:22 - train: epoch 0055, iter [04400, 05004], lr: 0.010000, loss: 1.3420
2022-07-12 00:54:55 - train: epoch 0055, iter [04500, 05004], lr: 0.010000, loss: 1.0810
2022-07-12 00:55:28 - train: epoch 0055, iter [04600, 05004], lr: 0.010000, loss: 1.2176
2022-07-12 00:56:01 - train: epoch 0055, iter [04700, 05004], lr: 0.010000, loss: 0.9700
2022-07-12 00:56:34 - train: epoch 0055, iter [04800, 05004], lr: 0.010000, loss: 1.1607
2022-07-12 00:57:07 - train: epoch 0055, iter [04900, 05004], lr: 0.010000, loss: 1.1584
2022-07-12 00:57:39 - train: epoch 0055, iter [05000, 05004], lr: 0.010000, loss: 1.2001
2022-07-12 00:57:41 - train: epoch 055, train_loss: 1.1099
2022-07-12 00:58:56 - eval: epoch: 055, acc1: 73.290%, acc5: 91.582%, test_loss: 1.0654, per_image_load_time: 2.292ms, per_image_inference_time: 0.590ms
2022-07-12 00:58:56 - until epoch: 055, best_acc1: 73.936%
2022-07-12 00:58:56 - epoch 056 lr: 0.010000
2022-07-12 00:59:36 - train: epoch 0056, iter [00100, 05004], lr: 0.010000, loss: 1.1470
2022-07-12 01:00:09 - train: epoch 0056, iter [00200, 05004], lr: 0.010000, loss: 1.2253
2022-07-12 01:00:41 - train: epoch 0056, iter [00300, 05004], lr: 0.010000, loss: 1.1175
2022-07-12 01:01:14 - train: epoch 0056, iter [00400, 05004], lr: 0.010000, loss: 0.9681
2022-07-12 01:01:47 - train: epoch 0056, iter [00500, 05004], lr: 0.010000, loss: 1.0655
2022-07-12 01:02:20 - train: epoch 0056, iter [00600, 05004], lr: 0.010000, loss: 1.1326
2022-07-12 01:02:52 - train: epoch 0056, iter [00700, 05004], lr: 0.010000, loss: 1.0970
2022-07-12 01:03:25 - train: epoch 0056, iter [00800, 05004], lr: 0.010000, loss: 1.3319
2022-07-12 01:03:58 - train: epoch 0056, iter [00900, 05004], lr: 0.010000, loss: 1.2133
2022-07-12 01:04:30 - train: epoch 0056, iter [01000, 05004], lr: 0.010000, loss: 1.1378
2022-07-12 01:05:03 - train: epoch 0056, iter [01100, 05004], lr: 0.010000, loss: 0.9902
2022-07-12 01:05:36 - train: epoch 0056, iter [01200, 05004], lr: 0.010000, loss: 0.9769
2022-07-12 01:06:09 - train: epoch 0056, iter [01300, 05004], lr: 0.010000, loss: 1.1972
2022-07-12 01:06:41 - train: epoch 0056, iter [01400, 05004], lr: 0.010000, loss: 1.0736
2022-07-12 01:07:14 - train: epoch 0056, iter [01500, 05004], lr: 0.010000, loss: 1.1647
2022-07-12 01:07:47 - train: epoch 0056, iter [01600, 05004], lr: 0.010000, loss: 0.9589
2022-07-12 01:08:20 - train: epoch 0056, iter [01700, 05004], lr: 0.010000, loss: 1.1965
2022-07-12 01:08:53 - train: epoch 0056, iter [01800, 05004], lr: 0.010000, loss: 1.2815
2022-07-12 01:09:26 - train: epoch 0056, iter [01900, 05004], lr: 0.010000, loss: 1.0651
2022-07-12 01:09:58 - train: epoch 0056, iter [02000, 05004], lr: 0.010000, loss: 1.0868
2022-07-12 01:10:31 - train: epoch 0056, iter [02100, 05004], lr: 0.010000, loss: 1.0867
2022-07-12 01:11:04 - train: epoch 0056, iter [02200, 05004], lr: 0.010000, loss: 1.1578
2022-07-12 01:11:36 - train: epoch 0056, iter [02300, 05004], lr: 0.010000, loss: 1.1855
2022-07-12 01:12:09 - train: epoch 0056, iter [02400, 05004], lr: 0.010000, loss: 1.1338
2022-07-12 01:12:42 - train: epoch 0056, iter [02500, 05004], lr: 0.010000, loss: 1.3148
2022-07-12 01:13:14 - train: epoch 0056, iter [02600, 05004], lr: 0.010000, loss: 1.0379
2022-07-12 01:13:47 - train: epoch 0056, iter [02700, 05004], lr: 0.010000, loss: 1.2035
2022-07-12 01:14:20 - train: epoch 0056, iter [02800, 05004], lr: 0.010000, loss: 1.0807
2022-07-12 01:14:53 - train: epoch 0056, iter [02900, 05004], lr: 0.010000, loss: 1.2726
2022-07-12 01:15:26 - train: epoch 0056, iter [03000, 05004], lr: 0.010000, loss: 1.2030
2022-07-12 01:15:59 - train: epoch 0056, iter [03100, 05004], lr: 0.010000, loss: 1.1038
2022-07-12 01:16:31 - train: epoch 0056, iter [03200, 05004], lr: 0.010000, loss: 1.0924
2022-07-12 01:17:04 - train: epoch 0056, iter [03300, 05004], lr: 0.010000, loss: 1.4201
2022-07-12 01:17:37 - train: epoch 0056, iter [03400, 05004], lr: 0.010000, loss: 1.1339
2022-07-12 01:18:09 - train: epoch 0056, iter [03500, 05004], lr: 0.010000, loss: 1.0333
2022-07-12 01:18:42 - train: epoch 0056, iter [03600, 05004], lr: 0.010000, loss: 0.9405
2022-07-12 01:19:14 - train: epoch 0056, iter [03700, 05004], lr: 0.010000, loss: 0.9493
2022-07-12 01:19:47 - train: epoch 0056, iter [03800, 05004], lr: 0.010000, loss: 0.9542
2022-07-12 01:20:19 - train: epoch 0056, iter [03900, 05004], lr: 0.010000, loss: 1.2717
2022-07-12 01:20:52 - train: epoch 0056, iter [04000, 05004], lr: 0.010000, loss: 1.1199
2022-07-12 01:21:25 - train: epoch 0056, iter [04100, 05004], lr: 0.010000, loss: 1.3374
2022-07-12 01:21:57 - train: epoch 0056, iter [04200, 05004], lr: 0.010000, loss: 1.0816
2022-07-12 01:22:30 - train: epoch 0056, iter [04300, 05004], lr: 0.010000, loss: 1.0159
2022-07-12 01:23:03 - train: epoch 0056, iter [04400, 05004], lr: 0.010000, loss: 1.1439
2022-07-12 01:23:35 - train: epoch 0056, iter [04500, 05004], lr: 0.010000, loss: 1.0860
2022-07-12 01:24:08 - train: epoch 0056, iter [04600, 05004], lr: 0.010000, loss: 1.1306
2022-07-12 01:24:41 - train: epoch 0056, iter [04700, 05004], lr: 0.010000, loss: 1.2184
2022-07-12 01:25:13 - train: epoch 0056, iter [04800, 05004], lr: 0.010000, loss: 1.2690
2022-07-12 01:25:46 - train: epoch 0056, iter [04900, 05004], lr: 0.010000, loss: 1.0350
2022-07-12 01:26:19 - train: epoch 0056, iter [05000, 05004], lr: 0.010000, loss: 1.2623
2022-07-12 01:26:20 - train: epoch 056, train_loss: 1.1052
2022-07-12 01:27:35 - eval: epoch: 056, acc1: 73.376%, acc5: 91.610%, test_loss: 1.0715, per_image_load_time: 2.136ms, per_image_inference_time: 0.582ms
2022-07-12 01:27:36 - until epoch: 056, best_acc1: 73.936%
2022-07-12 01:27:36 - epoch 057 lr: 0.010000
2022-07-12 01:28:15 - train: epoch 0057, iter [00100, 05004], lr: 0.010000, loss: 1.1785
2022-07-12 01:28:48 - train: epoch 0057, iter [00200, 05004], lr: 0.010000, loss: 1.0059
2022-07-12 01:29:21 - train: epoch 0057, iter [00300, 05004], lr: 0.010000, loss: 0.9146
2022-07-12 01:29:54 - train: epoch 0057, iter [00400, 05004], lr: 0.010000, loss: 0.9964
2022-07-12 01:30:27 - train: epoch 0057, iter [00500, 05004], lr: 0.010000, loss: 0.9165
2022-07-12 01:31:00 - train: epoch 0057, iter [00600, 05004], lr: 0.010000, loss: 1.2230
2022-07-12 01:31:33 - train: epoch 0057, iter [00700, 05004], lr: 0.010000, loss: 0.8588
2022-07-12 01:32:06 - train: epoch 0057, iter [00800, 05004], lr: 0.010000, loss: 1.0990
2022-07-12 01:32:39 - train: epoch 0057, iter [00900, 05004], lr: 0.010000, loss: 1.1848
2022-07-12 01:33:11 - train: epoch 0057, iter [01000, 05004], lr: 0.010000, loss: 1.0220
2022-07-12 01:33:44 - train: epoch 0057, iter [01100, 05004], lr: 0.010000, loss: 1.0145
2022-07-12 01:34:17 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 1.0228
2022-07-12 01:34:50 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 1.1532
2022-07-12 01:35:22 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 1.1624
2022-07-12 01:35:55 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 1.1359
2022-07-12 01:36:27 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 1.2136
2022-07-12 01:37:00 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 1.2995
2022-07-12 01:37:33 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 1.1787
2022-07-12 01:38:05 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 1.0434
2022-07-12 01:38:38 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 1.1366
2022-07-12 01:39:10 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 1.1200
2022-07-12 01:39:43 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 1.0768
2022-07-12 01:40:16 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 1.0351
2022-07-12 01:40:49 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 1.0245
2022-07-12 01:41:22 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 1.0568
2022-07-12 01:41:55 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 1.0351
2022-07-12 01:42:27 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 0.9791
2022-07-12 01:43:00 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 0.8508
2022-07-12 01:43:33 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 1.2497
2022-07-12 01:44:05 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 1.1508
2022-07-12 01:44:38 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 1.3479
2022-07-12 01:45:11 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 1.2420
2022-07-12 01:45:43 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 1.0304
2022-07-12 01:46:16 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 1.1157
2022-07-12 01:46:49 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 1.0854
2022-07-12 01:47:22 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 1.0836
2022-07-12 01:47:55 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 1.1040
2022-07-12 01:48:28 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 1.0776
2022-07-12 01:49:01 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 1.3077
2022-07-12 01:49:34 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 1.0813
2022-07-12 01:50:07 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 1.2352
2022-07-12 01:50:40 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 1.1423
2022-07-12 01:51:12 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 1.1372
2022-07-12 01:51:46 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 1.0458
2022-07-12 01:52:18 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 1.2666
2022-07-12 01:52:51 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 1.1309
2022-07-12 01:53:23 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 1.0274
2022-07-12 01:53:57 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 1.2908
2022-07-12 01:54:29 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 1.3607
2022-07-12 01:55:01 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 1.2855
2022-07-12 01:55:02 - train: epoch 057, train_loss: 1.1042
2022-07-12 01:56:17 - eval: epoch: 057, acc1: 73.038%, acc5: 91.482%, test_loss: 1.0860, per_image_load_time: 2.264ms, per_image_inference_time: 0.585ms
2022-07-12 01:56:17 - until epoch: 057, best_acc1: 73.936%
2022-07-12 01:56:17 - epoch 058 lr: 0.010000
2022-07-12 01:56:57 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 1.1092
2022-07-12 01:57:30 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 1.0222
2022-07-12 01:58:02 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 1.1739
2022-07-12 01:58:35 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 1.1195
2022-07-12 01:59:07 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 0.9455
2022-07-12 01:59:40 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 1.1426
2022-07-12 02:00:13 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 0.9923
2022-07-12 02:00:46 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 0.9525
2022-07-12 02:01:18 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 0.9762
2022-07-12 02:01:51 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 1.2060
2022-07-12 02:02:23 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 0.9101
2022-07-12 02:02:56 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 1.0320
2022-07-12 02:03:29 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 1.0910
2022-07-12 02:04:01 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 1.0374
2022-07-12 02:04:34 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 1.1500
2022-07-12 02:05:06 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 1.0215
2022-07-12 02:05:39 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 1.2732
2022-07-12 02:06:11 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 1.1714
2022-07-12 02:06:44 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 1.2767
2022-07-12 02:07:17 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 1.1285
2022-07-12 02:07:49 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 0.9957
2022-07-12 02:08:22 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 0.9426
2022-07-12 02:08:55 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 1.0432
2022-07-12 02:09:27 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 1.0883
2022-07-12 02:10:00 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 1.2061
2022-07-12 02:10:32 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 1.0610
2022-07-12 02:11:04 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 1.2839
2022-07-12 02:11:37 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 0.9236
2022-07-12 02:12:10 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 1.0412
2022-07-12 02:12:43 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 1.2719
2022-07-12 02:13:15 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 0.8893
2022-07-12 02:13:48 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 0.9544
2022-07-12 02:14:21 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 1.1321
2022-07-12 02:14:54 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 1.1107
2022-07-12 02:15:26 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 0.9614
2022-07-12 02:15:59 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 0.9811
2022-07-12 02:16:31 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 1.1492
2022-07-12 02:17:03 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 1.1747
2022-07-12 02:17:36 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 1.1910
2022-07-12 02:18:08 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 1.2323
2022-07-12 02:18:41 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 1.2020
2022-07-12 02:19:14 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 0.9778
2022-07-12 02:19:46 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 1.3219
2022-07-12 02:20:19 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 0.8757
2022-07-12 02:20:52 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 1.2665
2022-07-12 02:21:25 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 1.0611
2022-07-12 02:21:58 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 1.1133
2022-07-12 02:22:30 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 1.2447
2022-07-12 02:23:03 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 1.0728
2022-07-12 02:23:35 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 1.0784
2022-07-12 02:23:36 - train: epoch 058, train_loss: 1.0996
2022-07-12 02:24:52 - eval: epoch: 058, acc1: 73.448%, acc5: 91.598%, test_loss: 1.0696, per_image_load_time: 2.062ms, per_image_inference_time: 0.575ms
2022-07-12 02:24:52 - until epoch: 058, best_acc1: 73.936%
2022-07-12 02:24:52 - epoch 059 lr: 0.010000
2022-07-12 02:25:31 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 1.2391
2022-07-12 02:26:04 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 1.0439
2022-07-12 02:26:36 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 1.0225
2022-07-12 02:27:09 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 1.0961
2022-07-12 02:27:41 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 1.3606
2022-07-12 02:28:13 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 1.0700
2022-07-12 02:28:46 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 1.0412
2022-07-12 02:29:18 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 1.1417
2022-07-12 02:29:51 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 1.0611
2022-07-12 02:30:23 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 1.0495
2022-07-12 02:30:56 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 1.2466
2022-07-12 02:31:28 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 0.9310
2022-07-12 02:32:01 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 1.2592
2022-07-12 02:32:34 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 1.2142
2022-07-12 02:33:06 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 1.1605
2022-07-12 02:33:39 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 1.0626
2022-07-12 02:34:11 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 1.1134
2022-07-12 02:34:44 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 1.1232
2022-07-12 02:35:16 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 1.2183
2022-07-12 02:35:49 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 1.0554
2022-07-12 02:36:22 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 1.2300
2022-07-12 02:36:54 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 1.2780
2022-07-12 02:37:27 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 0.9929
2022-07-12 02:37:59 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 1.1510
2022-07-12 02:38:32 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 1.0747
2022-07-12 02:39:04 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 1.1214
2022-07-12 02:39:37 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 1.0356
2022-07-12 02:40:09 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 1.2225
2022-07-12 02:40:41 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 1.0615
2022-07-12 02:41:14 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 1.5147
2022-07-12 02:41:47 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 1.0151
2022-07-12 02:42:19 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 1.0263
2022-07-12 02:42:52 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 1.1751
2022-07-12 02:43:24 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 1.4510
2022-07-12 02:43:57 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 1.0733
2022-07-12 02:44:30 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 1.0090
2022-07-12 02:45:03 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 1.1032
2022-07-12 02:45:35 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 1.1627
2022-07-12 02:46:08 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 1.0437
2022-07-12 02:46:41 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 1.4039
2022-07-12 02:47:13 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 1.1595
2022-07-12 02:47:46 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 1.2601
2022-07-12 02:48:18 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 1.2092
2022-07-12 02:48:51 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 1.3260
2022-07-12 02:49:23 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 1.2523
2022-07-12 02:49:56 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 1.1045
2022-07-12 02:50:28 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 1.0397
2022-07-12 02:51:01 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 1.0137
2022-07-12 02:51:33 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 1.2604
2022-07-12 02:52:05 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 1.3130
2022-07-12 02:52:07 - train: epoch 059, train_loss: 1.0983
2022-07-12 02:53:22 - eval: epoch: 059, acc1: 73.048%, acc5: 91.392%, test_loss: 1.0859, per_image_load_time: 2.189ms, per_image_inference_time: 0.580ms
2022-07-12 02:53:22 - until epoch: 059, best_acc1: 73.936%
2022-07-12 02:53:22 - epoch 060 lr: 0.010000
2022-07-12 02:54:01 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 0.9307
2022-07-12 02:54:34 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 1.1568
2022-07-12 02:55:06 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 1.1145
2022-07-12 02:55:39 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 1.0524
2022-07-12 02:56:11 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 1.1691
2022-07-12 02:56:44 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 1.2315
2022-07-12 02:57:16 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 1.0663
2022-07-12 02:57:49 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 1.2251
2022-07-12 02:58:21 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 0.8891
2022-07-12 02:58:54 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 0.8872
2022-07-12 02:59:26 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 0.9589
2022-07-12 02:59:59 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 0.9117
2022-07-12 03:00:32 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 1.0708
2022-07-12 03:01:04 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 1.1276
2022-07-12 03:01:37 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 1.1015
2022-07-12 03:02:09 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 1.0628
2022-07-12 03:02:42 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 1.0626
2022-07-12 03:03:15 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 1.0892
2022-07-12 03:03:48 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 1.2270
2022-07-12 03:04:21 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 1.0326
2022-07-12 03:04:53 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 1.0745
2022-07-12 03:05:26 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 1.2025
2022-07-12 03:05:58 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 0.9764
2022-07-12 03:06:31 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 1.0966
2022-07-12 03:07:04 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 1.1257
2022-07-12 03:07:37 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 1.1736
2022-07-12 03:08:09 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 1.1709
2022-07-12 03:08:42 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 0.9632
2022-07-12 03:09:15 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 1.0892
2022-07-12 03:09:48 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 1.2993
2022-07-12 03:10:20 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 1.2338
2022-07-12 03:10:53 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 1.0334
2022-07-12 03:11:26 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 0.9359
2022-07-12 03:11:59 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 1.0594
2022-07-12 03:12:31 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 1.1387
2022-07-12 03:13:04 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 1.0256
2022-07-12 03:13:36 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 1.1314
2022-07-12 03:14:09 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 1.0931
2022-07-12 03:14:42 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 1.4451
2022-07-12 03:15:14 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 1.1000
2022-07-12 03:15:47 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 1.2747
2022-07-12 03:16:20 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 1.1789
2022-07-12 03:16:53 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 1.0579
2022-07-12 03:17:25 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 1.1605
2022-07-12 03:17:58 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 1.1303
2022-07-12 03:18:30 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 1.0743
2022-07-12 03:19:03 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 1.1109
2022-07-12 03:19:36 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 0.9703
2022-07-12 03:20:09 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 1.1468
2022-07-12 03:20:41 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 1.0880
2022-07-12 03:20:43 - train: epoch 060, train_loss: 1.0946
2022-07-12 03:21:58 - eval: epoch: 060, acc1: 73.384%, acc5: 91.684%, test_loss: 1.0714, per_image_load_time: 2.337ms, per_image_inference_time: 0.586ms
2022-07-12 03:21:58 - until epoch: 060, best_acc1: 73.936%
2022-07-12 03:21:58 - epoch 061 lr: 0.001000
2022-07-12 03:22:37 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 0.9957
2022-07-12 03:23:10 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 1.0301
2022-07-12 03:23:42 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 0.8515
2022-07-12 03:24:15 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 1.1513
2022-07-12 03:24:48 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 0.9839
2022-07-12 03:25:20 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 0.9665
2022-07-12 03:25:53 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 0.8333
2022-07-12 03:26:26 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 1.0737
2022-07-12 03:26:58 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 0.7897
2022-07-12 03:27:31 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 0.7707
2022-07-12 03:28:04 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 0.8095
2022-07-12 03:28:37 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 0.9207
2022-07-12 03:29:09 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 0.8300
2022-07-12 03:29:42 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 0.8381
2022-07-12 03:30:15 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 1.0073
2022-07-12 03:30:47 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 0.8476
2022-07-12 03:31:20 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 0.9793
2022-07-12 03:31:52 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 0.9892
2022-07-12 03:32:25 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 1.0258
2022-07-12 03:32:58 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 0.8065
2022-07-12 03:33:31 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 1.1634
2022-07-12 03:34:04 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 0.8108
2022-07-12 03:34:37 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 0.9568
2022-07-12 03:35:09 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 0.6661
2022-07-12 03:35:42 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 0.8372
2022-07-12 03:36:15 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 0.9137
2022-07-12 03:36:48 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 1.1270
2022-07-12 03:37:21 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 0.9241
2022-07-12 03:37:54 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 0.9788
2022-07-12 03:38:27 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 0.8083
2022-07-12 03:38:59 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 0.9829
2022-07-12 03:39:32 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 0.9336
2022-07-12 03:40:05 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 0.8740
2022-07-12 03:40:38 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 0.6996
2022-07-12 03:41:10 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 0.9628
2022-07-12 03:41:43 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 0.8944
2022-07-12 03:42:16 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 0.9778
2022-07-12 03:42:49 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 0.8998
2022-07-12 03:43:22 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 0.9378
2022-07-12 03:43:55 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 0.9852
2022-07-12 03:44:28 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 1.0534
2022-07-12 03:45:00 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 0.8080
2022-07-12 03:45:33 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 0.9274
2022-07-12 03:46:06 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 0.8846
2022-07-12 03:46:39 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 0.8706
2022-07-12 03:47:12 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 1.0091
2022-07-12 03:47:44 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 0.8859
2022-07-12 03:48:17 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 0.8909
2022-07-12 03:48:50 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 1.0097
2022-07-12 03:49:22 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 0.8840
2022-07-12 03:49:24 - train: epoch 061, train_loss: 0.9174
2022-07-12 03:50:39 - eval: epoch: 061, acc1: 76.052%, acc5: 92.912%, test_loss: 0.9547, per_image_load_time: 2.326ms, per_image_inference_time: 0.569ms
2022-07-12 03:50:40 - until epoch: 061, best_acc1: 76.052%
2022-07-12 03:50:40 - epoch 062 lr: 0.001000
2022-07-12 03:51:19 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 0.9463
2022-07-12 03:51:51 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 0.9382
2022-07-12 03:52:24 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 0.8248
2022-07-12 03:52:56 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 0.6915
2022-07-12 03:53:29 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 0.7242
2022-07-12 03:54:01 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 0.8332
2022-07-12 03:54:34 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 1.1406
2022-07-12 03:55:07 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 0.8650
2022-07-12 03:55:39 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 0.7694
2022-07-12 03:56:12 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 1.0268
2022-07-12 03:56:45 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 0.7695
2022-07-12 03:57:18 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 0.9974
2022-07-12 03:57:51 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 0.9147
2022-07-12 03:58:23 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 0.9164
2022-07-12 03:58:56 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 0.8743
2022-07-12 03:59:29 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 0.9001
2022-07-12 04:00:01 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 0.9296
2022-07-12 04:00:34 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 0.7905
2022-07-12 04:01:07 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 0.8018
2022-07-12 04:01:40 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 0.7485
2022-07-12 04:02:12 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 0.9782
2022-07-12 04:02:45 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 0.7524
2022-07-12 04:03:18 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 0.8799
2022-07-12 04:03:51 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 0.7879
2022-07-12 04:04:24 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 0.9208
2022-07-12 04:04:57 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 0.8008
2022-07-12 04:05:29 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 0.8290
2022-07-12 04:06:02 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 0.9136
2022-07-12 04:06:35 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 0.9748
2022-07-12 04:07:08 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 0.9247
2022-07-12 04:07:40 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 0.9055
2022-07-12 04:08:13 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 0.7714
2022-07-12 04:08:46 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 1.0371
2022-07-12 04:09:19 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 0.9822
2022-07-12 04:09:51 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 0.9669
2022-07-12 04:10:24 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 0.9383
2022-07-12 04:10:57 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 0.8032
2022-07-12 04:11:29 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 0.8647
2022-07-12 04:12:02 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 0.8348
2022-07-12 04:12:35 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 0.8142
2022-07-12 04:13:07 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 0.9101
2022-07-12 04:13:40 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 0.7178
2022-07-12 04:14:13 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 0.8397
2022-07-12 04:14:45 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 0.7703
2022-07-12 04:15:18 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 0.7570
2022-07-12 04:15:51 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 0.6799
2022-07-12 04:16:23 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 0.8488
2022-07-12 04:16:56 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 0.8399
2022-07-12 04:17:29 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 0.7877
2022-07-12 04:18:01 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 0.8585
2022-07-12 04:18:03 - train: epoch 062, train_loss: 0.8623
2022-07-12 04:19:18 - eval: epoch: 062, acc1: 76.258%, acc5: 93.028%, test_loss: 0.9433, per_image_load_time: 1.503ms, per_image_inference_time: 0.593ms
2022-07-12 04:19:19 - until epoch: 062, best_acc1: 76.258%
2022-07-12 04:19:19 - epoch 063 lr: 0.001000
2022-07-12 04:19:57 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 0.8529
2022-07-12 04:20:30 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 0.7469
2022-07-12 04:21:02 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 1.0085
2022-07-12 04:21:34 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 0.9522
2022-07-12 04:22:07 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 0.8050
2022-07-12 04:22:39 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 0.9125
2022-07-12 04:23:11 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 0.8356
2022-07-12 04:23:43 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 0.7908
2022-07-12 04:24:15 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 0.8948
2022-07-12 04:24:48 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 0.8988
2022-07-12 04:25:20 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 0.7539
2022-07-12 04:25:53 - train: epoch 0063, iter [01200, 05004], lr: 0.001000, loss: 0.7433
2022-07-12 04:26:25 - train: epoch 0063, iter [01300, 05004], lr: 0.001000, loss: 0.9106
2022-07-12 04:26:58 - train: epoch 0063, iter [01400, 05004], lr: 0.001000, loss: 1.1117
2022-07-12 04:27:30 - train: epoch 0063, iter [01500, 05004], lr: 0.001000, loss: 0.9649
2022-07-12 04:28:03 - train: epoch 0063, iter [01600, 05004], lr: 0.001000, loss: 0.8484
2022-07-12 04:28:35 - train: epoch 0063, iter [01700, 05004], lr: 0.001000, loss: 0.7333
2022-07-12 04:29:07 - train: epoch 0063, iter [01800, 05004], lr: 0.001000, loss: 0.9278
2022-07-12 04:29:39 - train: epoch 0063, iter [01900, 05004], lr: 0.001000, loss: 0.8348
2022-07-12 04:30:12 - train: epoch 0063, iter [02000, 05004], lr: 0.001000, loss: 0.8391
2022-07-12 04:30:44 - train: epoch 0063, iter [02100, 05004], lr: 0.001000, loss: 0.7519
2022-07-12 04:31:17 - train: epoch 0063, iter [02200, 05004], lr: 0.001000, loss: 1.0825
2022-07-12 04:31:49 - train: epoch 0063, iter [02300, 05004], lr: 0.001000, loss: 0.8504
2022-07-12 04:32:22 - train: epoch 0063, iter [02400, 05004], lr: 0.001000, loss: 0.9640
2022-07-12 04:32:54 - train: epoch 0063, iter [02500, 05004], lr: 0.001000, loss: 0.8362
2022-07-12 04:33:27 - train: epoch 0063, iter [02600, 05004], lr: 0.001000, loss: 0.7572
2022-07-12 04:33:59 - train: epoch 0063, iter [02700, 05004], lr: 0.001000, loss: 1.0170
2022-07-12 04:34:32 - train: epoch 0063, iter [02800, 05004], lr: 0.001000, loss: 0.8116
2022-07-12 04:35:05 - train: epoch 0063, iter [02900, 05004], lr: 0.001000, loss: 0.8485
2022-07-12 04:35:38 - train: epoch 0063, iter [03000, 05004], lr: 0.001000, loss: 0.9381
2022-07-12 04:36:11 - train: epoch 0063, iter [03100, 05004], lr: 0.001000, loss: 1.1390
2022-07-12 04:36:43 - train: epoch 0063, iter [03200, 05004], lr: 0.001000, loss: 0.9320
2022-07-12 04:37:15 - train: epoch 0063, iter [03300, 05004], lr: 0.001000, loss: 0.8314
2022-07-12 04:37:48 - train: epoch 0063, iter [03400, 05004], lr: 0.001000, loss: 0.6747
2022-07-12 04:38:20 - train: epoch 0063, iter [03500, 05004], lr: 0.001000, loss: 0.9308
2022-07-12 04:38:53 - train: epoch 0063, iter [03600, 05004], lr: 0.001000, loss: 0.7354
2022-07-12 04:39:26 - train: epoch 0063, iter [03700, 05004], lr: 0.001000, loss: 0.9410
2022-07-12 04:39:58 - train: epoch 0063, iter [03800, 05004], lr: 0.001000, loss: 1.0431
2022-07-12 04:40:31 - train: epoch 0063, iter [03900, 05004], lr: 0.001000, loss: 0.6023
2022-07-12 04:41:03 - train: epoch 0063, iter [04000, 05004], lr: 0.001000, loss: 0.6157
2022-07-12 04:41:36 - train: epoch 0063, iter [04100, 05004], lr: 0.001000, loss: 0.9703
2022-07-12 04:42:09 - train: epoch 0063, iter [04200, 05004], lr: 0.001000, loss: 0.8248
2022-07-12 04:42:42 - train: epoch 0063, iter [04300, 05004], lr: 0.001000, loss: 0.9639
2022-07-12 04:43:15 - train: epoch 0063, iter [04400, 05004], lr: 0.001000, loss: 0.8638
2022-07-12 04:43:47 - train: epoch 0063, iter [04500, 05004], lr: 0.001000, loss: 0.7795
2022-07-12 04:44:20 - train: epoch 0063, iter [04600, 05004], lr: 0.001000, loss: 0.7661
2022-07-12 04:44:52 - train: epoch 0063, iter [04700, 05004], lr: 0.001000, loss: 0.7541
2022-07-12 04:45:25 - train: epoch 0063, iter [04800, 05004], lr: 0.001000, loss: 0.7772
2022-07-12 04:45:58 - train: epoch 0063, iter [04900, 05004], lr: 0.001000, loss: 0.8377
2022-07-12 04:46:30 - train: epoch 0063, iter [05000, 05004], lr: 0.001000, loss: 0.8095
2022-07-12 04:46:31 - train: epoch 063, train_loss: 0.8402
2022-07-12 04:47:46 - eval: epoch: 063, acc1: 76.312%, acc5: 93.142%, test_loss: 0.9402, per_image_load_time: 2.091ms, per_image_inference_time: 0.576ms
2022-07-12 04:47:47 - until epoch: 063, best_acc1: 76.312%
2022-07-12 04:47:47 - epoch 064 lr: 0.001000
2022-07-12 04:48:26 - train: epoch 0064, iter [00100, 05004], lr: 0.001000, loss: 0.7821
2022-07-12 04:48:59 - train: epoch 0064, iter [00200, 05004], lr: 0.001000, loss: 0.9119
2022-07-12 04:49:31 - train: epoch 0064, iter [00300, 05004], lr: 0.001000, loss: 0.6465
2022-07-12 04:50:03 - train: epoch 0064, iter [00400, 05004], lr: 0.001000, loss: 0.9330
2022-07-12 04:50:36 - train: epoch 0064, iter [00500, 05004], lr: 0.001000, loss: 0.6902
2022-07-12 04:51:08 - train: epoch 0064, iter [00600, 05004], lr: 0.001000, loss: 0.9505
2022-07-12 04:51:41 - train: epoch 0064, iter [00700, 05004], lr: 0.001000, loss: 0.8671
2022-07-12 04:52:14 - train: epoch 0064, iter [00800, 05004], lr: 0.001000, loss: 0.7085
2022-07-12 04:52:46 - train: epoch 0064, iter [00900, 05004], lr: 0.001000, loss: 0.7823
2022-07-12 04:53:19 - train: epoch 0064, iter [01000, 05004], lr: 0.001000, loss: 0.8104
2022-07-12 04:53:51 - train: epoch 0064, iter [01100, 05004], lr: 0.001000, loss: 0.7455
2022-07-12 04:54:23 - train: epoch 0064, iter [01200, 05004], lr: 0.001000, loss: 0.6961
2022-07-12 04:54:56 - train: epoch 0064, iter [01300, 05004], lr: 0.001000, loss: 0.8458
2022-07-12 04:55:29 - train: epoch 0064, iter [01400, 05004], lr: 0.001000, loss: 1.0076
2022-07-12 04:56:02 - train: epoch 0064, iter [01500, 05004], lr: 0.001000, loss: 0.8431
2022-07-12 04:56:34 - train: epoch 0064, iter [01600, 05004], lr: 0.001000, loss: 0.6999
2022-07-12 04:57:07 - train: epoch 0064, iter [01700, 05004], lr: 0.001000, loss: 0.6791
2022-07-12 04:57:40 - train: epoch 0064, iter [01800, 05004], lr: 0.001000, loss: 0.7344
2022-07-12 04:58:12 - train: epoch 0064, iter [01900, 05004], lr: 0.001000, loss: 0.7147
2022-07-12 04:58:45 - train: epoch 0064, iter [02000, 05004], lr: 0.001000, loss: 0.7674
2022-07-12 04:59:18 - train: epoch 0064, iter [02100, 05004], lr: 0.001000, loss: 0.8699
2022-07-12 04:59:51 - train: epoch 0064, iter [02200, 05004], lr: 0.001000, loss: 0.8385
2022-07-12 05:00:23 - train: epoch 0064, iter [02300, 05004], lr: 0.001000, loss: 0.9452
2022-07-12 05:00:56 - train: epoch 0064, iter [02400, 05004], lr: 0.001000, loss: 0.7871
2022-07-12 05:01:29 - train: epoch 0064, iter [02500, 05004], lr: 0.001000, loss: 0.7113
2022-07-12 05:02:02 - train: epoch 0064, iter [02600, 05004], lr: 0.001000, loss: 0.6876
2022-07-12 05:02:34 - train: epoch 0064, iter [02700, 05004], lr: 0.001000, loss: 0.7825
2022-07-12 05:03:07 - train: epoch 0064, iter [02800, 05004], lr: 0.001000, loss: 0.7025
2022-07-12 05:03:40 - train: epoch 0064, iter [02900, 05004], lr: 0.001000, loss: 1.0161
2022-07-12 05:04:13 - train: epoch 0064, iter [03000, 05004], lr: 0.001000, loss: 0.8134
2022-07-12 05:04:46 - train: epoch 0064, iter [03100, 05004], lr: 0.001000, loss: 0.6630
2022-07-12 05:05:19 - train: epoch 0064, iter [03200, 05004], lr: 0.001000, loss: 0.8288
2022-07-12 05:05:51 - train: epoch 0064, iter [03300, 05004], lr: 0.001000, loss: 0.8337
2022-07-12 05:06:24 - train: epoch 0064, iter [03400, 05004], lr: 0.001000, loss: 0.9352
2022-07-12 05:06:57 - train: epoch 0064, iter [03500, 05004], lr: 0.001000, loss: 0.7170
2022-07-12 05:07:30 - train: epoch 0064, iter [03600, 05004], lr: 0.001000, loss: 0.7869
2022-07-12 05:08:03 - train: epoch 0064, iter [03700, 05004], lr: 0.001000, loss: 0.6320
2022-07-12 05:08:36 - train: epoch 0064, iter [03800, 05004], lr: 0.001000, loss: 0.9720
2022-07-12 05:09:09 - train: epoch 0064, iter [03900, 05004], lr: 0.001000, loss: 0.7666
2022-07-12 05:09:41 - train: epoch 0064, iter [04000, 05004], lr: 0.001000, loss: 0.6826
2022-07-12 05:10:14 - train: epoch 0064, iter [04100, 05004], lr: 0.001000, loss: 0.8605
2022-07-12 05:10:47 - train: epoch 0064, iter [04200, 05004], lr: 0.001000, loss: 0.7361
2022-07-12 05:11:19 - train: epoch 0064, iter [04300, 05004], lr: 0.001000, loss: 1.0253
2022-07-12 05:11:52 - train: epoch 0064, iter [04400, 05004], lr: 0.001000, loss: 0.8354
2022-07-12 05:12:25 - train: epoch 0064, iter [04500, 05004], lr: 0.001000, loss: 0.7550
2022-07-12 05:12:58 - train: epoch 0064, iter [04600, 05004], lr: 0.001000, loss: 1.0281
2022-07-12 05:13:30 - train: epoch 0064, iter [04700, 05004], lr: 0.001000, loss: 1.1135
2022-07-12 05:14:03 - train: epoch 0064, iter [04800, 05004], lr: 0.001000, loss: 0.7113
2022-07-12 05:14:36 - train: epoch 0064, iter [04900, 05004], lr: 0.001000, loss: 0.9950
2022-07-12 05:15:08 - train: epoch 0064, iter [05000, 05004], lr: 0.001000, loss: 0.6566
2022-07-12 05:15:10 - train: epoch 064, train_loss: 0.8256
2022-07-12 05:16:24 - eval: epoch: 064, acc1: 76.376%, acc5: 93.218%, test_loss: 0.9401, per_image_load_time: 1.874ms, per_image_inference_time: 0.586ms
2022-07-12 05:16:25 - until epoch: 064, best_acc1: 76.376%
2022-07-12 05:16:25 - epoch 065 lr: 0.001000
2022-07-12 05:17:04 - train: epoch 0065, iter [00100, 05004], lr: 0.001000, loss: 0.9325
2022-07-12 05:17:36 - train: epoch 0065, iter [00200, 05004], lr: 0.001000, loss: 0.7832
2022-07-12 05:18:08 - train: epoch 0065, iter [00300, 05004], lr: 0.001000, loss: 0.8567
2022-07-12 05:18:41 - train: epoch 0065, iter [00400, 05004], lr: 0.001000, loss: 0.9453
2022-07-12 05:19:13 - train: epoch 0065, iter [00500, 05004], lr: 0.001000, loss: 0.7127
2022-07-12 05:19:45 - train: epoch 0065, iter [00600, 05004], lr: 0.001000, loss: 0.8504
2022-07-12 05:20:17 - train: epoch 0065, iter [00700, 05004], lr: 0.001000, loss: 0.6518
2022-07-12 05:20:49 - train: epoch 0065, iter [00800, 05004], lr: 0.001000, loss: 0.7720
2022-07-12 05:21:22 - train: epoch 0065, iter [00900, 05004], lr: 0.001000, loss: 0.7528
2022-07-12 05:21:54 - train: epoch 0065, iter [01000, 05004], lr: 0.001000, loss: 0.7858
2022-07-12 05:22:27 - train: epoch 0065, iter [01100, 05004], lr: 0.001000, loss: 0.7982
2022-07-12 05:22:59 - train: epoch 0065, iter [01200, 05004], lr: 0.001000, loss: 1.0160
2022-07-12 05:23:32 - train: epoch 0065, iter [01300, 05004], lr: 0.001000, loss: 0.7993
2022-07-12 05:24:04 - train: epoch 0065, iter [01400, 05004], lr: 0.001000, loss: 0.6703
2022-07-12 05:24:36 - train: epoch 0065, iter [01500, 05004], lr: 0.001000, loss: 0.8322
2022-07-12 05:25:08 - train: epoch 0065, iter [01600, 05004], lr: 0.001000, loss: 0.7752
2022-07-12 05:25:41 - train: epoch 0065, iter [01700, 05004], lr: 0.001000, loss: 0.7445
2022-07-12 05:26:13 - train: epoch 0065, iter [01800, 05004], lr: 0.001000, loss: 0.7016
2022-07-12 05:26:45 - train: epoch 0065, iter [01900, 05004], lr: 0.001000, loss: 0.6957
2022-07-12 05:27:17 - train: epoch 0065, iter [02000, 05004], lr: 0.001000, loss: 0.7528
2022-07-12 05:27:49 - train: epoch 0065, iter [02100, 05004], lr: 0.001000, loss: 0.7533
2022-07-12 05:28:22 - train: epoch 0065, iter [02200, 05004], lr: 0.001000, loss: 0.9772
2022-07-12 05:28:54 - train: epoch 0065, iter [02300, 05004], lr: 0.001000, loss: 0.7845
2022-07-12 05:29:27 - train: epoch 0065, iter [02400, 05004], lr: 0.001000, loss: 0.7585
2022-07-12 05:29:59 - train: epoch 0065, iter [02500, 05004], lr: 0.001000, loss: 0.8359
2022-07-12 05:30:31 - train: epoch 0065, iter [02600, 05004], lr: 0.001000, loss: 0.8631
2022-07-12 05:31:03 - train: epoch 0065, iter [02700, 05004], lr: 0.001000, loss: 0.9112
2022-07-12 05:31:36 - train: epoch 0065, iter [02800, 05004], lr: 0.001000, loss: 0.7142
2022-07-12 05:32:08 - train: epoch 0065, iter [02900, 05004], lr: 0.001000, loss: 0.8467
2022-07-12 05:32:40 - train: epoch 0065, iter [03000, 05004], lr: 0.001000, loss: 0.7525
2022-07-12 05:33:12 - train: epoch 0065, iter [03100, 05004], lr: 0.001000, loss: 0.8802
2022-07-12 05:33:45 - train: epoch 0065, iter [03200, 05004], lr: 0.001000, loss: 0.9131
2022-07-12 05:34:18 - train: epoch 0065, iter [03300, 05004], lr: 0.001000, loss: 0.7925
2022-07-12 05:34:50 - train: epoch 0065, iter [03400, 05004], lr: 0.001000, loss: 0.6951
2022-07-12 05:35:22 - train: epoch 0065, iter [03500, 05004], lr: 0.001000, loss: 0.9870
2022-07-12 05:35:54 - train: epoch 0065, iter [03600, 05004], lr: 0.001000, loss: 0.8453
2022-07-12 05:36:27 - train: epoch 0065, iter [03700, 05004], lr: 0.001000, loss: 0.7580
2022-07-12 05:37:00 - train: epoch 0065, iter [03800, 05004], lr: 0.001000, loss: 0.6426
2022-07-12 05:37:32 - train: epoch 0065, iter [03900, 05004], lr: 0.001000, loss: 0.7665
2022-07-12 05:38:04 - train: epoch 0065, iter [04000, 05004], lr: 0.001000, loss: 0.8339
2022-07-12 05:38:37 - train: epoch 0065, iter [04100, 05004], lr: 0.001000, loss: 0.7353
2022-07-12 05:39:09 - train: epoch 0065, iter [04200, 05004], lr: 0.001000, loss: 0.8249
2022-07-12 05:39:42 - train: epoch 0065, iter [04300, 05004], lr: 0.001000, loss: 0.6890
2022-07-12 05:40:14 - train: epoch 0065, iter [04400, 05004], lr: 0.001000, loss: 0.7993
2022-07-12 05:40:47 - train: epoch 0065, iter [04500, 05004], lr: 0.001000, loss: 0.7416
2022-07-12 05:41:19 - train: epoch 0065, iter [04600, 05004], lr: 0.001000, loss: 0.7845
2022-07-12 05:41:52 - train: epoch 0065, iter [04700, 05004], lr: 0.001000, loss: 0.8190
2022-07-12 05:42:24 - train: epoch 0065, iter [04800, 05004], lr: 0.001000, loss: 0.6058
2022-07-12 05:42:57 - train: epoch 0065, iter [04900, 05004], lr: 0.001000, loss: 0.6979
2022-07-12 05:43:29 - train: epoch 0065, iter [05000, 05004], lr: 0.001000, loss: 0.8902
2022-07-12 05:43:30 - train: epoch 065, train_loss: 0.8119
2022-07-12 05:44:45 - eval: epoch: 065, acc1: 76.432%, acc5: 93.168%, test_loss: 0.9412, per_image_load_time: 1.952ms, per_image_inference_time: 0.586ms
2022-07-12 05:44:46 - until epoch: 065, best_acc1: 76.432%
2022-07-12 05:44:46 - epoch 066 lr: 0.001000
2022-07-12 05:45:25 - train: epoch 0066, iter [00100, 05004], lr: 0.001000, loss: 0.7313
2022-07-12 05:45:58 - train: epoch 0066, iter [00200, 05004], lr: 0.001000, loss: 0.9121
2022-07-12 05:46:30 - train: epoch 0066, iter [00300, 05004], lr: 0.001000, loss: 0.6052
2022-07-12 05:47:02 - train: epoch 0066, iter [00400, 05004], lr: 0.001000, loss: 0.6040
2022-07-12 05:47:34 - train: epoch 0066, iter [00500, 05004], lr: 0.001000, loss: 0.8694
2022-07-12 05:48:07 - train: epoch 0066, iter [00600, 05004], lr: 0.001000, loss: 0.7678
2022-07-12 05:48:39 - train: epoch 0066, iter [00700, 05004], lr: 0.001000, loss: 0.7390
2022-07-12 05:49:11 - train: epoch 0066, iter [00800, 05004], lr: 0.001000, loss: 1.0340
2022-07-12 05:49:43 - train: epoch 0066, iter [00900, 05004], lr: 0.001000, loss: 0.8798
2022-07-12 05:50:15 - train: epoch 0066, iter [01000, 05004], lr: 0.001000, loss: 0.9498
2022-07-12 05:50:47 - train: epoch 0066, iter [01100, 05004], lr: 0.001000, loss: 0.8244
2022-07-12 05:51:20 - train: epoch 0066, iter [01200, 05004], lr: 0.001000, loss: 0.8979
2022-07-12 05:51:52 - train: epoch 0066, iter [01300, 05004], lr: 0.001000, loss: 0.9264
2022-07-12 05:52:24 - train: epoch 0066, iter [01400, 05004], lr: 0.001000, loss: 0.6792
2022-07-12 05:52:57 - train: epoch 0066, iter [01500, 05004], lr: 0.001000, loss: 0.8983
2022-07-12 05:53:29 - train: epoch 0066, iter [01600, 05004], lr: 0.001000, loss: 0.8535
2022-07-12 05:54:01 - train: epoch 0066, iter [01700, 05004], lr: 0.001000, loss: 0.7411
2022-07-12 05:54:34 - train: epoch 0066, iter [01800, 05004], lr: 0.001000, loss: 0.7361
2022-07-12 05:55:06 - train: epoch 0066, iter [01900, 05004], lr: 0.001000, loss: 0.9285
2022-07-12 05:55:39 - train: epoch 0066, iter [02000, 05004], lr: 0.001000, loss: 0.9543
2022-07-12 05:56:11 - train: epoch 0066, iter [02100, 05004], lr: 0.001000, loss: 0.8022
2022-07-12 05:56:43 - train: epoch 0066, iter [02200, 05004], lr: 0.001000, loss: 0.7887
2022-07-12 05:57:16 - train: epoch 0066, iter [02300, 05004], lr: 0.001000, loss: 1.0058
2022-07-12 05:57:48 - train: epoch 0066, iter [02400, 05004], lr: 0.001000, loss: 0.6923
2022-07-12 05:58:20 - train: epoch 0066, iter [02500, 05004], lr: 0.001000, loss: 0.7580
2022-07-12 05:58:53 - train: epoch 0066, iter [02600, 05004], lr: 0.001000, loss: 0.6979
2022-07-12 05:59:25 - train: epoch 0066, iter [02700, 05004], lr: 0.001000, loss: 0.9361
2022-07-12 05:59:58 - train: epoch 0066, iter [02800, 05004], lr: 0.001000, loss: 0.9783
2022-07-12 06:00:30 - train: epoch 0066, iter [02900, 05004], lr: 0.001000, loss: 0.7520
2022-07-12 06:01:03 - train: epoch 0066, iter [03000, 05004], lr: 0.001000, loss: 0.7351
2022-07-12 06:01:36 - train: epoch 0066, iter [03100, 05004], lr: 0.001000, loss: 0.8989
2022-07-12 06:02:08 - train: epoch 0066, iter [03200, 05004], lr: 0.001000, loss: 0.6365
2022-07-12 06:02:41 - train: epoch 0066, iter [03300, 05004], lr: 0.001000, loss: 0.6892
2022-07-12 06:03:14 - train: epoch 0066, iter [03400, 05004], lr: 0.001000, loss: 0.8858
2022-07-12 06:03:47 - train: epoch 0066, iter [03500, 05004], lr: 0.001000, loss: 0.8892
2022-07-12 06:04:20 - train: epoch 0066, iter [03600, 05004], lr: 0.001000, loss: 0.9555
2022-07-12 06:04:53 - train: epoch 0066, iter [03700, 05004], lr: 0.001000, loss: 0.8336
2022-07-12 06:05:25 - train: epoch 0066, iter [03800, 05004], lr: 0.001000, loss: 0.6751
2022-07-12 06:05:58 - train: epoch 0066, iter [03900, 05004], lr: 0.001000, loss: 0.7309
2022-07-12 06:06:30 - train: epoch 0066, iter [04000, 05004], lr: 0.001000, loss: 0.9590
2022-07-12 06:07:03 - train: epoch 0066, iter [04100, 05004], lr: 0.001000, loss: 0.6094
2022-07-12 06:07:35 - train: epoch 0066, iter [04200, 05004], lr: 0.001000, loss: 0.6022
2022-07-12 06:08:07 - train: epoch 0066, iter [04300, 05004], lr: 0.001000, loss: 0.6318
2022-07-12 06:08:40 - train: epoch 0066, iter [04400, 05004], lr: 0.001000, loss: 0.7739
2022-07-12 06:09:13 - train: epoch 0066, iter [04500, 05004], lr: 0.001000, loss: 0.7958
2022-07-12 06:09:45 - train: epoch 0066, iter [04600, 05004], lr: 0.001000, loss: 0.9937
2022-07-12 06:10:18 - train: epoch 0066, iter [04700, 05004], lr: 0.001000, loss: 0.7028
2022-07-12 06:10:51 - train: epoch 0066, iter [04800, 05004], lr: 0.001000, loss: 0.7909
2022-07-12 06:11:24 - train: epoch 0066, iter [04900, 05004], lr: 0.001000, loss: 0.8498
2022-07-12 06:11:57 - train: epoch 0066, iter [05000, 05004], lr: 0.001000, loss: 0.7505
2022-07-12 06:11:58 - train: epoch 066, train_loss: 0.8022
2022-07-12 06:13:13 - eval: epoch: 066, acc1: 76.508%, acc5: 93.150%, test_loss: 0.9363, per_image_load_time: 2.161ms, per_image_inference_time: 0.588ms
2022-07-12 06:13:14 - until epoch: 066, best_acc1: 76.508%
2022-07-12 06:13:14 - epoch 067 lr: 0.001000
2022-07-12 06:13:53 - train: epoch 0067, iter [00100, 05004], lr: 0.001000, loss: 0.7190
2022-07-12 06:14:26 - train: epoch 0067, iter [00200, 05004], lr: 0.001000, loss: 0.7225
2022-07-12 06:14:58 - train: epoch 0067, iter [00300, 05004], lr: 0.001000, loss: 1.0983
2022-07-12 06:15:31 - train: epoch 0067, iter [00400, 05004], lr: 0.001000, loss: 0.8540
2022-07-12 06:16:03 - train: epoch 0067, iter [00500, 05004], lr: 0.001000, loss: 0.8055
2022-07-12 06:16:36 - train: epoch 0067, iter [00600, 05004], lr: 0.001000, loss: 0.7704
2022-07-12 06:17:09 - train: epoch 0067, iter [00700, 05004], lr: 0.001000, loss: 0.8428
2022-07-12 06:17:41 - train: epoch 0067, iter [00800, 05004], lr: 0.001000, loss: 0.8202
2022-07-12 06:18:14 - train: epoch 0067, iter [00900, 05004], lr: 0.001000, loss: 0.8352
2022-07-12 06:18:47 - train: epoch 0067, iter [01000, 05004], lr: 0.001000, loss: 0.6370
2022-07-12 06:19:19 - train: epoch 0067, iter [01100, 05004], lr: 0.001000, loss: 0.8313
2022-07-12 06:19:52 - train: epoch 0067, iter [01200, 05004], lr: 0.001000, loss: 0.8261
2022-07-12 06:20:25 - train: epoch 0067, iter [01300, 05004], lr: 0.001000, loss: 0.9905
2022-07-12 06:20:57 - train: epoch 0067, iter [01400, 05004], lr: 0.001000, loss: 0.8269
2022-07-12 06:21:30 - train: epoch 0067, iter [01500, 05004], lr: 0.001000, loss: 0.8566
2022-07-12 06:22:03 - train: epoch 0067, iter [01600, 05004], lr: 0.001000, loss: 0.7802
2022-07-12 06:22:36 - train: epoch 0067, iter [01700, 05004], lr: 0.001000, loss: 0.6569
2022-07-12 06:23:08 - train: epoch 0067, iter [01800, 05004], lr: 0.001000, loss: 0.9449
2022-07-12 06:23:41 - train: epoch 0067, iter [01900, 05004], lr: 0.001000, loss: 0.7154
2022-07-12 06:24:14 - train: epoch 0067, iter [02000, 05004], lr: 0.001000, loss: 0.9284
2022-07-12 06:24:46 - train: epoch 0067, iter [02100, 05004], lr: 0.001000, loss: 0.7191
2022-07-12 06:25:19 - train: epoch 0067, iter [02200, 05004], lr: 0.001000, loss: 0.8796
2022-07-12 06:25:51 - train: epoch 0067, iter [02300, 05004], lr: 0.001000, loss: 0.7390
2022-07-12 06:26:24 - train: epoch 0067, iter [02400, 05004], lr: 0.001000, loss: 0.7791
2022-07-12 06:26:56 - train: epoch 0067, iter [02500, 05004], lr: 0.001000, loss: 0.7070
2022-07-12 06:27:28 - train: epoch 0067, iter [02600, 05004], lr: 0.001000, loss: 0.7124
2022-07-12 06:28:01 - train: epoch 0067, iter [02700, 05004], lr: 0.001000, loss: 0.7146
2022-07-12 06:28:34 - train: epoch 0067, iter [02800, 05004], lr: 0.001000, loss: 0.9155
2022-07-12 06:29:06 - train: epoch 0067, iter [02900, 05004], lr: 0.001000, loss: 0.8032
2022-07-12 06:29:39 - train: epoch 0067, iter [03000, 05004], lr: 0.001000, loss: 0.7971
2022-07-12 06:30:11 - train: epoch 0067, iter [03100, 05004], lr: 0.001000, loss: 0.7093
2022-07-12 06:30:43 - train: epoch 0067, iter [03200, 05004], lr: 0.001000, loss: 0.9123
2022-07-12 06:31:16 - train: epoch 0067, iter [03300, 05004], lr: 0.001000, loss: 0.6420
2022-07-12 06:31:49 - train: epoch 0067, iter [03400, 05004], lr: 0.001000, loss: 0.7243
2022-07-12 06:32:22 - train: epoch 0067, iter [03500, 05004], lr: 0.001000, loss: 0.6836
2022-07-12 06:32:54 - train: epoch 0067, iter [03600, 05004], lr: 0.001000, loss: 0.7907
2022-07-12 06:33:27 - train: epoch 0067, iter [03700, 05004], lr: 0.001000, loss: 0.8608
2022-07-12 06:33:59 - train: epoch 0067, iter [03800, 05004], lr: 0.001000, loss: 0.7254
2022-07-12 06:34:31 - train: epoch 0067, iter [03900, 05004], lr: 0.001000, loss: 0.8350
2022-07-12 06:35:04 - train: epoch 0067, iter [04000, 05004], lr: 0.001000, loss: 0.9200
2022-07-12 06:35:37 - train: epoch 0067, iter [04100, 05004], lr: 0.001000, loss: 0.9235
2022-07-12 06:36:09 - train: epoch 0067, iter [04200, 05004], lr: 0.001000, loss: 0.9335
2022-07-12 06:36:42 - train: epoch 0067, iter [04300, 05004], lr: 0.001000, loss: 0.6991
2022-07-12 06:37:15 - train: epoch 0067, iter [04400, 05004], lr: 0.001000, loss: 0.7531
2022-07-12 06:37:47 - train: epoch 0067, iter [04500, 05004], lr: 0.001000, loss: 0.7818
2022-07-12 06:38:20 - train: epoch 0067, iter [04600, 05004], lr: 0.001000, loss: 0.6264
2022-07-12 06:38:53 - train: epoch 0067, iter [04700, 05004], lr: 0.001000, loss: 0.6959
2022-07-12 06:39:26 - train: epoch 0067, iter [04800, 05004], lr: 0.001000, loss: 0.5884
2022-07-12 06:39:58 - train: epoch 0067, iter [04900, 05004], lr: 0.001000, loss: 0.7647
2022-07-12 06:40:30 - train: epoch 0067, iter [05000, 05004], lr: 0.001000, loss: 0.8645
2022-07-12 06:40:32 - train: epoch 067, train_loss: 0.7942
2022-07-12 06:41:46 - eval: epoch: 067, acc1: 76.470%, acc5: 93.166%, test_loss: 0.9380, per_image_load_time: 1.974ms, per_image_inference_time: 0.582ms
2022-07-12 06:41:47 - until epoch: 067, best_acc1: 76.508%
2022-07-12 06:41:47 - epoch 068 lr: 0.001000
2022-07-12 06:42:27 - train: epoch 0068, iter [00100, 05004], lr: 0.001000, loss: 0.8402
2022-07-12 06:42:59 - train: epoch 0068, iter [00200, 05004], lr: 0.001000, loss: 0.8251
2022-07-12 06:43:31 - train: epoch 0068, iter [00300, 05004], lr: 0.001000, loss: 0.8545
2022-07-12 06:44:04 - train: epoch 0068, iter [00400, 05004], lr: 0.001000, loss: 0.7907
2022-07-12 06:44:36 - train: epoch 0068, iter [00500, 05004], lr: 0.001000, loss: 0.7993
2022-07-12 06:45:09 - train: epoch 0068, iter [00600, 05004], lr: 0.001000, loss: 0.8163
2022-07-12 06:45:41 - train: epoch 0068, iter [00700, 05004], lr: 0.001000, loss: 1.0682
2022-07-12 06:46:14 - train: epoch 0068, iter [00800, 05004], lr: 0.001000, loss: 0.7950
2022-07-12 06:46:47 - train: epoch 0068, iter [00900, 05004], lr: 0.001000, loss: 0.6986
2022-07-12 06:47:19 - train: epoch 0068, iter [01000, 05004], lr: 0.001000, loss: 0.8460
2022-07-12 06:47:52 - train: epoch 0068, iter [01100, 05004], lr: 0.001000, loss: 0.8514
2022-07-12 06:48:25 - train: epoch 0068, iter [01200, 05004], lr: 0.001000, loss: 0.7619
2022-07-12 06:48:57 - train: epoch 0068, iter [01300, 05004], lr: 0.001000, loss: 0.6479
2022-07-12 06:49:30 - train: epoch 0068, iter [01400, 05004], lr: 0.001000, loss: 0.7724
2022-07-12 06:50:03 - train: epoch 0068, iter [01500, 05004], lr: 0.001000, loss: 0.8610
2022-07-12 06:50:35 - train: epoch 0068, iter [01600, 05004], lr: 0.001000, loss: 0.8494
2022-07-12 06:51:08 - train: epoch 0068, iter [01700, 05004], lr: 0.001000, loss: 0.9465
2022-07-12 06:51:40 - train: epoch 0068, iter [01800, 05004], lr: 0.001000, loss: 0.8594
2022-07-12 06:52:13 - train: epoch 0068, iter [01900, 05004], lr: 0.001000, loss: 0.7551
2022-07-12 06:52:45 - train: epoch 0068, iter [02000, 05004], lr: 0.001000, loss: 0.7798
2022-07-12 06:53:18 - train: epoch 0068, iter [02100, 05004], lr: 0.001000, loss: 0.7472
2022-07-12 06:53:51 - train: epoch 0068, iter [02200, 05004], lr: 0.001000, loss: 0.8455
2022-07-12 06:54:23 - train: epoch 0068, iter [02300, 05004], lr: 0.001000, loss: 0.6531
2022-07-12 06:54:56 - train: epoch 0068, iter [02400, 05004], lr: 0.001000, loss: 0.8952
2022-07-12 06:55:28 - train: epoch 0068, iter [02500, 05004], lr: 0.001000, loss: 0.6969
2022-07-12 06:56:01 - train: epoch 0068, iter [02600, 05004], lr: 0.001000, loss: 0.8307
2022-07-12 06:56:33 - train: epoch 0068, iter [02700, 05004], lr: 0.001000, loss: 0.8549
2022-07-12 06:57:06 - train: epoch 0068, iter [02800, 05004], lr: 0.001000, loss: 0.9043
2022-07-12 06:57:39 - train: epoch 0068, iter [02900, 05004], lr: 0.001000, loss: 0.8479
2022-07-12 06:58:12 - train: epoch 0068, iter [03000, 05004], lr: 0.001000, loss: 0.9855
2022-07-12 06:58:44 - train: epoch 0068, iter [03100, 05004], lr: 0.001000, loss: 0.6621
2022-07-12 06:59:17 - train: epoch 0068, iter [03200, 05004], lr: 0.001000, loss: 0.8183
2022-07-12 06:59:50 - train: epoch 0068, iter [03300, 05004], lr: 0.001000, loss: 0.7646
2022-07-12 07:00:22 - train: epoch 0068, iter [03400, 05004], lr: 0.001000, loss: 0.7480
2022-07-12 07:00:55 - train: epoch 0068, iter [03500, 05004], lr: 0.001000, loss: 0.8797
2022-07-12 07:01:28 - train: epoch 0068, iter [03600, 05004], lr: 0.001000, loss: 0.7373
2022-07-12 07:02:01 - train: epoch 0068, iter [03700, 05004], lr: 0.001000, loss: 0.9290
2022-07-12 07:02:34 - train: epoch 0068, iter [03800, 05004], lr: 0.001000, loss: 0.8548
2022-07-12 07:03:07 - train: epoch 0068, iter [03900, 05004], lr: 0.001000, loss: 0.8002
2022-07-12 07:03:40 - train: epoch 0068, iter [04000, 05004], lr: 0.001000, loss: 0.8091
2022-07-12 07:04:13 - train: epoch 0068, iter [04100, 05004], lr: 0.001000, loss: 0.6785
2022-07-12 07:04:45 - train: epoch 0068, iter [04200, 05004], lr: 0.001000, loss: 0.9459
2022-07-12 07:05:18 - train: epoch 0068, iter [04300, 05004], lr: 0.001000, loss: 0.9708
2022-07-12 07:05:51 - train: epoch 0068, iter [04400, 05004], lr: 0.001000, loss: 0.7494
2022-07-12 07:06:24 - train: epoch 0068, iter [04500, 05004], lr: 0.001000, loss: 0.8277
2022-07-12 07:06:57 - train: epoch 0068, iter [04600, 05004], lr: 0.001000, loss: 0.9557
2022-07-12 07:07:30 - train: epoch 0068, iter [04700, 05004], lr: 0.001000, loss: 1.0377
2022-07-12 07:08:03 - train: epoch 0068, iter [04800, 05004], lr: 0.001000, loss: 0.9435
2022-07-12 07:08:35 - train: epoch 0068, iter [04900, 05004], lr: 0.001000, loss: 0.8836
2022-07-12 07:09:08 - train: epoch 0068, iter [05000, 05004], lr: 0.001000, loss: 0.7508
2022-07-12 07:09:09 - train: epoch 068, train_loss: 0.7859
2022-07-12 07:10:25 - eval: epoch: 068, acc1: 76.602%, acc5: 93.154%, test_loss: 0.9395, per_image_load_time: 2.232ms, per_image_inference_time: 0.588ms
2022-07-12 07:10:25 - until epoch: 068, best_acc1: 76.602%
2022-07-12 07:10:25 - epoch 069 lr: 0.001000
2022-07-12 07:11:04 - train: epoch 0069, iter [00100, 05004], lr: 0.001000, loss: 0.9075
2022-07-12 07:11:37 - train: epoch 0069, iter [00200, 05004], lr: 0.001000, loss: 0.8729
2022-07-12 07:12:09 - train: epoch 0069, iter [00300, 05004], lr: 0.001000, loss: 0.8667
2022-07-12 07:12:42 - train: epoch 0069, iter [00400, 05004], lr: 0.001000, loss: 0.7682
2022-07-12 07:13:14 - train: epoch 0069, iter [00500, 05004], lr: 0.001000, loss: 0.7198
2022-07-12 07:13:46 - train: epoch 0069, iter [00600, 05004], lr: 0.001000, loss: 0.6444
2022-07-12 07:14:19 - train: epoch 0069, iter [00700, 05004], lr: 0.001000, loss: 0.7357
2022-07-12 07:14:51 - train: epoch 0069, iter [00800, 05004], lr: 0.001000, loss: 0.7583
2022-07-12 07:15:24 - train: epoch 0069, iter [00900, 05004], lr: 0.001000, loss: 0.7344
2022-07-12 07:15:57 - train: epoch 0069, iter [01000, 05004], lr: 0.001000, loss: 0.8195
2022-07-12 07:16:29 - train: epoch 0069, iter [01100, 05004], lr: 0.001000, loss: 0.6934
2022-07-12 07:17:02 - train: epoch 0069, iter [01200, 05004], lr: 0.001000, loss: 0.8379
2022-07-12 07:17:34 - train: epoch 0069, iter [01300, 05004], lr: 0.001000, loss: 0.9287
2022-07-12 07:18:07 - train: epoch 0069, iter [01400, 05004], lr: 0.001000, loss: 0.9386
2022-07-12 07:18:39 - train: epoch 0069, iter [01500, 05004], lr: 0.001000, loss: 0.8074
2022-07-12 07:19:12 - train: epoch 0069, iter [01600, 05004], lr: 0.001000, loss: 0.8146
2022-07-12 07:19:45 - train: epoch 0069, iter [01700, 05004], lr: 0.001000, loss: 0.7006
2022-07-12 07:20:17 - train: epoch 0069, iter [01800, 05004], lr: 0.001000, loss: 0.6268
2022-07-12 07:20:49 - train: epoch 0069, iter [01900, 05004], lr: 0.001000, loss: 0.6773
2022-07-12 07:21:22 - train: epoch 0069, iter [02000, 05004], lr: 0.001000, loss: 0.5977
2022-07-12 07:21:55 - train: epoch 0069, iter [02100, 05004], lr: 0.001000, loss: 0.8524
2022-07-12 07:22:27 - train: epoch 0069, iter [02200, 05004], lr: 0.001000, loss: 0.8110
2022-07-12 07:22:59 - train: epoch 0069, iter [02300, 05004], lr: 0.001000, loss: 0.8592
2022-07-12 07:23:31 - train: epoch 0069, iter [02400, 05004], lr: 0.001000, loss: 0.9309
2022-07-12 07:24:04 - train: epoch 0069, iter [02500, 05004], lr: 0.001000, loss: 0.7939
2022-07-12 07:24:36 - train: epoch 0069, iter [02600, 05004], lr: 0.001000, loss: 0.8561
2022-07-12 07:25:09 - train: epoch 0069, iter [02700, 05004], lr: 0.001000, loss: 0.8635
2022-07-12 07:25:42 - train: epoch 0069, iter [02800, 05004], lr: 0.001000, loss: 0.9111
2022-07-12 07:26:14 - train: epoch 0069, iter [02900, 05004], lr: 0.001000, loss: 0.6782
2022-07-12 07:26:47 - train: epoch 0069, iter [03000, 05004], lr: 0.001000, loss: 0.7042
2022-07-12 07:27:20 - train: epoch 0069, iter [03100, 05004], lr: 0.001000, loss: 0.6329
2022-07-12 07:27:53 - train: epoch 0069, iter [03200, 05004], lr: 0.001000, loss: 0.7424
2022-07-12 07:28:25 - train: epoch 0069, iter [03300, 05004], lr: 0.001000, loss: 0.6225
2022-07-12 07:28:58 - train: epoch 0069, iter [03400, 05004], lr: 0.001000, loss: 0.7011
2022-07-12 07:29:31 - train: epoch 0069, iter [03500, 05004], lr: 0.001000, loss: 0.7309
2022-07-12 07:30:03 - train: epoch 0069, iter [03600, 05004], lr: 0.001000, loss: 0.7279
2022-07-12 07:30:36 - train: epoch 0069, iter [03700, 05004], lr: 0.001000, loss: 0.8777
2022-07-12 07:31:09 - train: epoch 0069, iter [03800, 05004], lr: 0.001000, loss: 0.8142
2022-07-12 07:31:42 - train: epoch 0069, iter [03900, 05004], lr: 0.001000, loss: 0.8632
2022-07-12 07:32:14 - train: epoch 0069, iter [04000, 05004], lr: 0.001000, loss: 0.8337
2022-07-12 07:32:47 - train: epoch 0069, iter [04100, 05004], lr: 0.001000, loss: 0.9435
2022-07-12 07:33:20 - train: epoch 0069, iter [04200, 05004], lr: 0.001000, loss: 0.6315
2022-07-12 07:33:52 - train: epoch 0069, iter [04300, 05004], lr: 0.001000, loss: 0.8197
2022-07-12 07:34:25 - train: epoch 0069, iter [04400, 05004], lr: 0.001000, loss: 0.7787
2022-07-12 07:34:58 - train: epoch 0069, iter [04500, 05004], lr: 0.001000, loss: 0.7166
2022-07-12 07:35:30 - train: epoch 0069, iter [04600, 05004], lr: 0.001000, loss: 0.9008
2022-07-12 07:36:03 - train: epoch 0069, iter [04700, 05004], lr: 0.001000, loss: 0.8358
2022-07-12 07:36:36 - train: epoch 0069, iter [04800, 05004], lr: 0.001000, loss: 0.6910
2022-07-12 07:37:09 - train: epoch 0069, iter [04900, 05004], lr: 0.001000, loss: 0.7466
2022-07-12 07:37:40 - train: epoch 0069, iter [05000, 05004], lr: 0.001000, loss: 0.8553
2022-07-12 07:37:42 - train: epoch 069, train_loss: 0.7778
2022-07-12 07:38:58 - eval: epoch: 069, acc1: 76.490%, acc5: 93.084%, test_loss: 0.9427, per_image_load_time: 2.258ms, per_image_inference_time: 0.584ms
2022-07-12 07:38:58 - until epoch: 069, best_acc1: 76.602%
2022-07-12 07:38:58 - epoch 070 lr: 0.001000
2022-07-12 07:39:38 - train: epoch 0070, iter [00100, 05004], lr: 0.001000, loss: 0.8965
2022-07-12 07:40:11 - train: epoch 0070, iter [00200, 05004], lr: 0.001000, loss: 0.9154
2022-07-12 07:40:44 - train: epoch 0070, iter [00300, 05004], lr: 0.001000, loss: 0.8271
2022-07-12 07:41:16 - train: epoch 0070, iter [00400, 05004], lr: 0.001000, loss: 0.7278
2022-07-12 07:41:49 - train: epoch 0070, iter [00500, 05004], lr: 0.001000, loss: 0.8073
2022-07-12 07:42:21 - train: epoch 0070, iter [00600, 05004], lr: 0.001000, loss: 0.6400
2022-07-12 07:42:53 - train: epoch 0070, iter [00700, 05004], lr: 0.001000, loss: 0.7237
2022-07-12 07:43:26 - train: epoch 0070, iter [00800, 05004], lr: 0.001000, loss: 0.7276
2022-07-12 07:43:58 - train: epoch 0070, iter [00900, 05004], lr: 0.001000, loss: 0.8781
2022-07-12 07:44:31 - train: epoch 0070, iter [01000, 05004], lr: 0.001000, loss: 0.6917
2022-07-12 07:45:03 - train: epoch 0070, iter [01100, 05004], lr: 0.001000, loss: 0.9393
2022-07-12 07:45:36 - train: epoch 0070, iter [01200, 05004], lr: 0.001000, loss: 0.5732
2022-07-12 07:46:08 - train: epoch 0070, iter [01300, 05004], lr: 0.001000, loss: 0.6941
2022-07-12 07:46:41 - train: epoch 0070, iter [01400, 05004], lr: 0.001000, loss: 0.8080
2022-07-12 07:47:13 - train: epoch 0070, iter [01500, 05004], lr: 0.001000, loss: 0.6733
2022-07-12 07:47:46 - train: epoch 0070, iter [01600, 05004], lr: 0.001000, loss: 0.7639
2022-07-12 07:48:19 - train: epoch 0070, iter [01700, 05004], lr: 0.001000, loss: 0.8122
2022-07-12 07:48:51 - train: epoch 0070, iter [01800, 05004], lr: 0.001000, loss: 0.7392
2022-07-12 07:49:24 - train: epoch 0070, iter [01900, 05004], lr: 0.001000, loss: 0.6989
2022-07-12 07:49:57 - train: epoch 0070, iter [02000, 05004], lr: 0.001000, loss: 0.7180
2022-07-12 07:50:29 - train: epoch 0070, iter [02100, 05004], lr: 0.001000, loss: 0.7780
2022-07-12 07:51:02 - train: epoch 0070, iter [02200, 05004], lr: 0.001000, loss: 0.8000
2022-07-12 07:51:35 - train: epoch 0070, iter [02300, 05004], lr: 0.001000, loss: 0.7771
2022-07-12 07:52:07 - train: epoch 0070, iter [02400, 05004], lr: 0.001000, loss: 0.9214
2022-07-12 07:52:40 - train: epoch 0070, iter [02500, 05004], lr: 0.001000, loss: 0.7971
2022-07-12 07:53:13 - train: epoch 0070, iter [02600, 05004], lr: 0.001000, loss: 0.7107
2022-07-12 07:53:45 - train: epoch 0070, iter [02700, 05004], lr: 0.001000, loss: 0.7711
2022-07-12 07:54:18 - train: epoch 0070, iter [02800, 05004], lr: 0.001000, loss: 0.8477
2022-07-12 07:54:50 - train: epoch 0070, iter [02900, 05004], lr: 0.001000, loss: 0.9806
2022-07-12 07:55:23 - train: epoch 0070, iter [03000, 05004], lr: 0.001000, loss: 0.6650
2022-07-12 07:55:56 - train: epoch 0070, iter [03100, 05004], lr: 0.001000, loss: 0.7654
2022-07-12 07:56:28 - train: epoch 0070, iter [03200, 05004], lr: 0.001000, loss: 0.9288
2022-07-12 07:57:01 - train: epoch 0070, iter [03300, 05004], lr: 0.001000, loss: 0.7107
2022-07-12 07:57:34 - train: epoch 0070, iter [03400, 05004], lr: 0.001000, loss: 0.8130
2022-07-12 07:58:07 - train: epoch 0070, iter [03500, 05004], lr: 0.001000, loss: 0.7107
2022-07-12 07:58:40 - train: epoch 0070, iter [03600, 05004], lr: 0.001000, loss: 0.8025
2022-07-12 07:59:12 - train: epoch 0070, iter [03700, 05004], lr: 0.001000, loss: 0.8153
2022-07-12 07:59:45 - train: epoch 0070, iter [03800, 05004], lr: 0.001000, loss: 0.7492
2022-07-12 08:00:17 - train: epoch 0070, iter [03900, 05004], lr: 0.001000, loss: 0.7276
2022-07-12 08:00:50 - train: epoch 0070, iter [04000, 05004], lr: 0.001000, loss: 0.5742
2022-07-12 08:01:22 - train: epoch 0070, iter [04100, 05004], lr: 0.001000, loss: 0.7262
2022-07-12 08:01:55 - train: epoch 0070, iter [04200, 05004], lr: 0.001000, loss: 0.8278
2022-07-12 08:02:28 - train: epoch 0070, iter [04300, 05004], lr: 0.001000, loss: 0.7206
2022-07-12 08:03:01 - train: epoch 0070, iter [04400, 05004], lr: 0.001000, loss: 0.8528
2022-07-12 08:03:33 - train: epoch 0070, iter [04500, 05004], lr: 0.001000, loss: 0.7805
2022-07-12 08:04:06 - train: epoch 0070, iter [04600, 05004], lr: 0.001000, loss: 0.8517
2022-07-12 08:04:39 - train: epoch 0070, iter [04700, 05004], lr: 0.001000, loss: 0.8735
2022-07-12 08:05:12 - train: epoch 0070, iter [04800, 05004], lr: 0.001000, loss: 0.7511
2022-07-12 08:05:45 - train: epoch 0070, iter [04900, 05004], lr: 0.001000, loss: 0.8195
2022-07-12 08:06:17 - train: epoch 0070, iter [05000, 05004], lr: 0.001000, loss: 0.7279
2022-07-12 08:06:18 - train: epoch 070, train_loss: 0.7733
2022-07-12 08:07:33 - eval: epoch: 070, acc1: 76.578%, acc5: 93.156%, test_loss: 0.9439, per_image_load_time: 2.234ms, per_image_inference_time: 0.581ms
2022-07-12 08:07:34 - until epoch: 070, best_acc1: 76.602%
2022-07-12 08:07:34 - epoch 071 lr: 0.001000
2022-07-12 08:08:12 - train: epoch 0071, iter [00100, 05004], lr: 0.001000, loss: 0.6263
2022-07-12 08:08:45 - train: epoch 0071, iter [00200, 05004], lr: 0.001000, loss: 0.7390
2022-07-12 08:09:18 - train: epoch 0071, iter [00300, 05004], lr: 0.001000, loss: 0.7081
2022-07-12 08:09:51 - train: epoch 0071, iter [00400, 05004], lr: 0.001000, loss: 0.7759
2022-07-12 08:10:23 - train: epoch 0071, iter [00500, 05004], lr: 0.001000, loss: 0.7371
2022-07-12 08:10:56 - train: epoch 0071, iter [00600, 05004], lr: 0.001000, loss: 0.8205
2022-07-12 08:11:28 - train: epoch 0071, iter [00700, 05004], lr: 0.001000, loss: 0.9134
2022-07-12 08:12:01 - train: epoch 0071, iter [00800, 05004], lr: 0.001000, loss: 0.6209
2022-07-12 08:12:34 - train: epoch 0071, iter [00900, 05004], lr: 0.001000, loss: 0.7581
2022-07-12 08:13:06 - train: epoch 0071, iter [01000, 05004], lr: 0.001000, loss: 0.8766
2022-07-12 08:13:39 - train: epoch 0071, iter [01100, 05004], lr: 0.001000, loss: 0.9071
2022-07-12 08:14:11 - train: epoch 0071, iter [01200, 05004], lr: 0.001000, loss: 0.7850
2022-07-12 08:14:44 - train: epoch 0071, iter [01300, 05004], lr: 0.001000, loss: 0.7310
2022-07-12 08:15:16 - train: epoch 0071, iter [01400, 05004], lr: 0.001000, loss: 0.8221
2022-07-12 08:15:49 - train: epoch 0071, iter [01500, 05004], lr: 0.001000, loss: 0.6030
2022-07-12 08:16:22 - train: epoch 0071, iter [01600, 05004], lr: 0.001000, loss: 0.8079
2022-07-12 08:16:54 - train: epoch 0071, iter [01700, 05004], lr: 0.001000, loss: 0.6815
2022-07-12 08:17:27 - train: epoch 0071, iter [01800, 05004], lr: 0.001000, loss: 0.8266
2022-07-12 08:17:59 - train: epoch 0071, iter [01900, 05004], lr: 0.001000, loss: 0.6423
2022-07-12 08:18:32 - train: epoch 0071, iter [02000, 05004], lr: 0.001000, loss: 0.8661
2022-07-12 08:19:05 - train: epoch 0071, iter [02100, 05004], lr: 0.001000, loss: 0.6537
2022-07-12 08:19:37 - train: epoch 0071, iter [02200, 05004], lr: 0.001000, loss: 0.7941
2022-07-12 08:20:10 - train: epoch 0071, iter [02300, 05004], lr: 0.001000, loss: 0.6960
2022-07-12 08:20:43 - train: epoch 0071, iter [02400, 05004], lr: 0.001000, loss: 0.6865
2022-07-12 08:21:16 - train: epoch 0071, iter [02500, 05004], lr: 0.001000, loss: 0.7901
2022-07-12 08:21:48 - train: epoch 0071, iter [02600, 05004], lr: 0.001000, loss: 0.7310
2022-07-12 08:22:21 - train: epoch 0071, iter [02700, 05004], lr: 0.001000, loss: 0.7720
2022-07-12 08:22:54 - train: epoch 0071, iter [02800, 05004], lr: 0.001000, loss: 0.8237
2022-07-12 08:23:27 - train: epoch 0071, iter [02900, 05004], lr: 0.001000, loss: 0.8152
2022-07-12 08:24:00 - train: epoch 0071, iter [03000, 05004], lr: 0.001000, loss: 0.7404
2022-07-12 08:24:33 - train: epoch 0071, iter [03100, 05004], lr: 0.001000, loss: 0.8102
2022-07-12 08:25:06 - train: epoch 0071, iter [03200, 05004], lr: 0.001000, loss: 0.6769
2022-07-12 08:25:38 - train: epoch 0071, iter [03300, 05004], lr: 0.001000, loss: 0.6369
2022-07-12 08:26:11 - train: epoch 0071, iter [03400, 05004], lr: 0.001000, loss: 0.6853
2022-07-12 08:26:44 - train: epoch 0071, iter [03500, 05004], lr: 0.001000, loss: 0.8023
2022-07-12 08:27:16 - train: epoch 0071, iter [03600, 05004], lr: 0.001000, loss: 0.8644
2022-07-12 08:27:49 - train: epoch 0071, iter [03700, 05004], lr: 0.001000, loss: 0.7899
2022-07-12 08:28:22 - train: epoch 0071, iter [03800, 05004], lr: 0.001000, loss: 0.7793
2022-07-12 08:28:55 - train: epoch 0071, iter [03900, 05004], lr: 0.001000, loss: 0.8383
2022-07-12 08:29:27 - train: epoch 0071, iter [04000, 05004], lr: 0.001000, loss: 0.9698
2022-07-12 08:30:00 - train: epoch 0071, iter [04100, 05004], lr: 0.001000, loss: 0.7470
2022-07-12 08:30:33 - train: epoch 0071, iter [04200, 05004], lr: 0.001000, loss: 0.8914
2022-07-12 08:31:05 - train: epoch 0071, iter [04300, 05004], lr: 0.001000, loss: 0.8597
2022-07-12 08:31:38 - train: epoch 0071, iter [04400, 05004], lr: 0.001000, loss: 0.7529
2022-07-12 08:32:11 - train: epoch 0071, iter [04500, 05004], lr: 0.001000, loss: 0.7082
2022-07-12 08:32:44 - train: epoch 0071, iter [04600, 05004], lr: 0.001000, loss: 0.8889
2022-07-12 08:33:17 - train: epoch 0071, iter [04700, 05004], lr: 0.001000, loss: 0.6562
2022-07-12 08:33:49 - train: epoch 0071, iter [04800, 05004], lr: 0.001000, loss: 0.6346
2022-07-12 08:34:22 - train: epoch 0071, iter [04900, 05004], lr: 0.001000, loss: 0.5679
2022-07-12 08:34:54 - train: epoch 0071, iter [05000, 05004], lr: 0.001000, loss: 0.6959
2022-07-12 08:34:56 - train: epoch 071, train_loss: 0.7657
2022-07-12 08:36:10 - eval: epoch: 071, acc1: 76.560%, acc5: 93.182%, test_loss: 0.9435, per_image_load_time: 2.045ms, per_image_inference_time: 0.587ms
2022-07-12 08:36:11 - until epoch: 071, best_acc1: 76.602%
2022-07-12 08:36:11 - epoch 072 lr: 0.001000
2022-07-12 08:36:50 - train: epoch 0072, iter [00100, 05004], lr: 0.001000, loss: 0.7976
2022-07-12 08:37:23 - train: epoch 0072, iter [00200, 05004], lr: 0.001000, loss: 0.6304
2022-07-12 08:37:55 - train: epoch 0072, iter [00300, 05004], lr: 0.001000, loss: 0.6987
2022-07-12 08:38:28 - train: epoch 0072, iter [00400, 05004], lr: 0.001000, loss: 0.7266
2022-07-12 08:39:01 - train: epoch 0072, iter [00500, 05004], lr: 0.001000, loss: 0.6364
2022-07-12 08:39:33 - train: epoch 0072, iter [00600, 05004], lr: 0.001000, loss: 0.7431
2022-07-12 08:40:05 - train: epoch 0072, iter [00700, 05004], lr: 0.001000, loss: 0.7359
2022-07-12 08:40:38 - train: epoch 0072, iter [00800, 05004], lr: 0.001000, loss: 0.8801
2022-07-12 08:41:10 - train: epoch 0072, iter [00900, 05004], lr: 0.001000, loss: 0.6569
2022-07-12 08:41:43 - train: epoch 0072, iter [01000, 05004], lr: 0.001000, loss: 0.7804
2022-07-12 08:42:16 - train: epoch 0072, iter [01100, 05004], lr: 0.001000, loss: 0.6866
2022-07-12 08:42:48 - train: epoch 0072, iter [01200, 05004], lr: 0.001000, loss: 0.6891
2022-07-12 08:43:21 - train: epoch 0072, iter [01300, 05004], lr: 0.001000, loss: 0.7900
2022-07-12 08:43:53 - train: epoch 0072, iter [01400, 05004], lr: 0.001000, loss: 0.7912
2022-07-12 08:44:26 - train: epoch 0072, iter [01500, 05004], lr: 0.001000, loss: 0.6821
2022-07-12 08:44:59 - train: epoch 0072, iter [01600, 05004], lr: 0.001000, loss: 0.9230
2022-07-12 08:45:31 - train: epoch 0072, iter [01700, 05004], lr: 0.001000, loss: 0.7196
2022-07-12 08:46:04 - train: epoch 0072, iter [01800, 05004], lr: 0.001000, loss: 0.6146
2022-07-12 08:46:36 - train: epoch 0072, iter [01900, 05004], lr: 0.001000, loss: 0.6984
2022-07-12 08:47:09 - train: epoch 0072, iter [02000, 05004], lr: 0.001000, loss: 0.8731
2022-07-12 08:47:41 - train: epoch 0072, iter [02100, 05004], lr: 0.001000, loss: 0.7725
2022-07-12 08:48:14 - train: epoch 0072, iter [02200, 05004], lr: 0.001000, loss: 0.7683
2022-07-12 08:48:46 - train: epoch 0072, iter [02300, 05004], lr: 0.001000, loss: 0.8205
2022-07-12 08:49:19 - train: epoch 0072, iter [02400, 05004], lr: 0.001000, loss: 0.7111
2022-07-12 08:49:51 - train: epoch 0072, iter [02500, 05004], lr: 0.001000, loss: 0.7105
2022-07-12 08:50:24 - train: epoch 0072, iter [02600, 05004], lr: 0.001000, loss: 0.6203
2022-07-12 08:50:56 - train: epoch 0072, iter [02700, 05004], lr: 0.001000, loss: 0.8022
2022-07-12 08:51:29 - train: epoch 0072, iter [02800, 05004], lr: 0.001000, loss: 0.8117
2022-07-12 08:52:02 - train: epoch 0072, iter [02900, 05004], lr: 0.001000, loss: 0.6838
2022-07-12 08:52:34 - train: epoch 0072, iter [03000, 05004], lr: 0.001000, loss: 0.7215
2022-07-12 08:53:07 - train: epoch 0072, iter [03100, 05004], lr: 0.001000, loss: 0.8789
2022-07-12 08:53:40 - train: epoch 0072, iter [03200, 05004], lr: 0.001000, loss: 0.7675
2022-07-12 08:54:13 - train: epoch 0072, iter [03300, 05004], lr: 0.001000, loss: 0.6698
2022-07-12 08:54:45 - train: epoch 0072, iter [03400, 05004], lr: 0.001000, loss: 0.7641
2022-07-12 08:55:18 - train: epoch 0072, iter [03500, 05004], lr: 0.001000, loss: 0.7868
2022-07-12 08:55:51 - train: epoch 0072, iter [03600, 05004], lr: 0.001000, loss: 0.6789
2022-07-12 08:56:23 - train: epoch 0072, iter [03700, 05004], lr: 0.001000, loss: 0.7709
2022-07-12 08:56:56 - train: epoch 0072, iter [03800, 05004], lr: 0.001000, loss: 0.8390
2022-07-12 08:57:28 - train: epoch 0072, iter [03900, 05004], lr: 0.001000, loss: 0.8644
2022-07-12 08:58:01 - train: epoch 0072, iter [04000, 05004], lr: 0.001000, loss: 0.7426
2022-07-12 08:58:34 - train: epoch 0072, iter [04100, 05004], lr: 0.001000, loss: 0.9008
2022-07-12 08:59:07 - train: epoch 0072, iter [04200, 05004], lr: 0.001000, loss: 0.7249
2022-07-12 08:59:39 - train: epoch 0072, iter [04300, 05004], lr: 0.001000, loss: 0.7810
2022-07-12 09:00:12 - train: epoch 0072, iter [04400, 05004], lr: 0.001000, loss: 0.7518
2022-07-12 09:00:45 - train: epoch 0072, iter [04500, 05004], lr: 0.001000, loss: 0.8429
2022-07-12 09:01:17 - train: epoch 0072, iter [04600, 05004], lr: 0.001000, loss: 0.8102
2022-07-12 09:01:50 - train: epoch 0072, iter [04700, 05004], lr: 0.001000, loss: 0.8155
2022-07-12 09:02:23 - train: epoch 0072, iter [04800, 05004], lr: 0.001000, loss: 0.8661
2022-07-12 09:02:56 - train: epoch 0072, iter [04900, 05004], lr: 0.001000, loss: 0.8998
2022-07-12 09:03:29 - train: epoch 0072, iter [05000, 05004], lr: 0.001000, loss: 0.8293
2022-07-12 09:03:30 - train: epoch 072, train_loss: 0.7619
2022-07-12 09:04:46 - eval: epoch: 072, acc1: 76.478%, acc5: 93.184%, test_loss: 0.9479, per_image_load_time: 2.318ms, per_image_inference_time: 0.593ms
2022-07-12 09:04:46 - until epoch: 072, best_acc1: 76.602%
2022-07-12 09:04:46 - epoch 073 lr: 0.001000
2022-07-12 09:05:26 - train: epoch 0073, iter [00100, 05004], lr: 0.001000, loss: 0.8986
2022-07-12 09:05:58 - train: epoch 0073, iter [00200, 05004], lr: 0.001000, loss: 0.7393
2022-07-12 09:06:31 - train: epoch 0073, iter [00300, 05004], lr: 0.001000, loss: 0.9023
2022-07-12 09:07:03 - train: epoch 0073, iter [00400, 05004], lr: 0.001000, loss: 0.5547
2022-07-12 09:07:36 - train: epoch 0073, iter [00500, 05004], lr: 0.001000, loss: 0.6532
2022-07-12 09:08:08 - train: epoch 0073, iter [00600, 05004], lr: 0.001000, loss: 0.6374
2022-07-12 09:08:41 - train: epoch 0073, iter [00700, 05004], lr: 0.001000, loss: 0.6783
2022-07-12 09:09:13 - train: epoch 0073, iter [00800, 05004], lr: 0.001000, loss: 0.6988
2022-07-12 09:09:46 - train: epoch 0073, iter [00900, 05004], lr: 0.001000, loss: 0.6146
2022-07-12 09:10:18 - train: epoch 0073, iter [01000, 05004], lr: 0.001000, loss: 0.6568
2022-07-12 09:10:50 - train: epoch 0073, iter [01100, 05004], lr: 0.001000, loss: 0.8115
2022-07-12 09:11:22 - train: epoch 0073, iter [01200, 05004], lr: 0.001000, loss: 0.7998
2022-07-12 09:11:55 - train: epoch 0073, iter [01300, 05004], lr: 0.001000, loss: 0.8112
2022-07-12 09:12:27 - train: epoch 0073, iter [01400, 05004], lr: 0.001000, loss: 0.6766
2022-07-12 09:13:00 - train: epoch 0073, iter [01500, 05004], lr: 0.001000, loss: 0.7108
2022-07-12 09:13:33 - train: epoch 0073, iter [01600, 05004], lr: 0.001000, loss: 0.8051
2022-07-12 09:14:06 - train: epoch 0073, iter [01700, 05004], lr: 0.001000, loss: 0.9462
2022-07-12 09:14:38 - train: epoch 0073, iter [01800, 05004], lr: 0.001000, loss: 0.6266
2022-07-12 09:15:11 - train: epoch 0073, iter [01900, 05004], lr: 0.001000, loss: 0.7703
2022-07-12 09:15:44 - train: epoch 0073, iter [02000, 05004], lr: 0.001000, loss: 0.6167
2022-07-12 09:16:17 - train: epoch 0073, iter [02100, 05004], lr: 0.001000, loss: 0.7089
2022-07-12 09:16:51 - train: epoch 0073, iter [02200, 05004], lr: 0.001000, loss: 0.9622
2022-07-12 09:17:24 - train: epoch 0073, iter [02300, 05004], lr: 0.001000, loss: 0.8433
2022-07-12 09:17:56 - train: epoch 0073, iter [02400, 05004], lr: 0.001000, loss: 0.7482
2022-07-12 09:18:29 - train: epoch 0073, iter [02500, 05004], lr: 0.001000, loss: 0.8636
2022-07-12 09:19:01 - train: epoch 0073, iter [02600, 05004], lr: 0.001000, loss: 0.8457
2022-07-12 09:19:34 - train: epoch 0073, iter [02700, 05004], lr: 0.001000, loss: 0.7773
2022-07-12 09:20:06 - train: epoch 0073, iter [02800, 05004], lr: 0.001000, loss: 0.8500
2022-07-12 09:20:38 - train: epoch 0073, iter [02900, 05004], lr: 0.001000, loss: 0.7568
2022-07-12 09:21:11 - train: epoch 0073, iter [03000, 05004], lr: 0.001000, loss: 0.6090
2022-07-12 09:21:43 - train: epoch 0073, iter [03100, 05004], lr: 0.001000, loss: 0.6851
2022-07-12 09:22:16 - train: epoch 0073, iter [03200, 05004], lr: 0.001000, loss: 0.7011
2022-07-12 09:22:49 - train: epoch 0073, iter [03300, 05004], lr: 0.001000, loss: 0.6549
2022-07-12 09:23:22 - train: epoch 0073, iter [03400, 05004], lr: 0.001000, loss: 0.7147
2022-07-12 09:23:54 - train: epoch 0073, iter [03500, 05004], lr: 0.001000, loss: 0.7685
2022-07-12 09:24:27 - train: epoch 0073, iter [03600, 05004], lr: 0.001000, loss: 0.7165
2022-07-12 09:25:00 - train: epoch 0073, iter [03700, 05004], lr: 0.001000, loss: 0.7958
2022-07-12 09:25:32 - train: epoch 0073, iter [03800, 05004], lr: 0.001000, loss: 0.9376
2022-07-12 09:26:05 - train: epoch 0073, iter [03900, 05004], lr: 0.001000, loss: 0.7631
2022-07-12 09:26:38 - train: epoch 0073, iter [04000, 05004], lr: 0.001000, loss: 0.7511
2022-07-12 09:27:10 - train: epoch 0073, iter [04100, 05004], lr: 0.001000, loss: 0.7241
2022-07-12 09:27:43 - train: epoch 0073, iter [04200, 05004], lr: 0.001000, loss: 0.7828
2022-07-12 09:28:16 - train: epoch 0073, iter [04300, 05004], lr: 0.001000, loss: 0.7512
2022-07-12 09:28:48 - train: epoch 0073, iter [04400, 05004], lr: 0.001000, loss: 0.7025
2022-07-12 09:29:21 - train: epoch 0073, iter [04500, 05004], lr: 0.001000, loss: 0.7633
2022-07-12 09:29:54 - train: epoch 0073, iter [04600, 05004], lr: 0.001000, loss: 0.8817
2022-07-12 09:30:27 - train: epoch 0073, iter [04700, 05004], lr: 0.001000, loss: 0.5957
2022-07-12 09:31:00 - train: epoch 0073, iter [04800, 05004], lr: 0.001000, loss: 0.8127
2022-07-12 09:31:33 - train: epoch 0073, iter [04900, 05004], lr: 0.001000, loss: 0.6219
2022-07-12 09:32:05 - train: epoch 0073, iter [05000, 05004], lr: 0.001000, loss: 0.8317
2022-07-12 09:32:06 - train: epoch 073, train_loss: 0.7571
2022-07-12 09:33:20 - eval: epoch: 073, acc1: 76.430%, acc5: 93.144%, test_loss: 0.9492, per_image_load_time: 2.153ms, per_image_inference_time: 0.569ms
2022-07-12 09:33:21 - until epoch: 073, best_acc1: 76.602%
2022-07-12 09:33:21 - epoch 074 lr: 0.001000
2022-07-12 09:34:00 - train: epoch 0074, iter [00100, 05004], lr: 0.001000, loss: 0.6527
2022-07-12 09:34:33 - train: epoch 0074, iter [00200, 05004], lr: 0.001000, loss: 0.8273
2022-07-12 09:35:05 - train: epoch 0074, iter [00300, 05004], lr: 0.001000, loss: 0.7878
2022-07-12 09:35:38 - train: epoch 0074, iter [00400, 05004], lr: 0.001000, loss: 0.8308
2022-07-12 09:36:11 - train: epoch 0074, iter [00500, 05004], lr: 0.001000, loss: 0.8109
2022-07-12 09:36:43 - train: epoch 0074, iter [00600, 05004], lr: 0.001000, loss: 0.7278
2022-07-12 09:37:16 - train: epoch 0074, iter [00700, 05004], lr: 0.001000, loss: 0.7395
2022-07-12 09:37:49 - train: epoch 0074, iter [00800, 05004], lr: 0.001000, loss: 0.9406
2022-07-12 09:38:22 - train: epoch 0074, iter [00900, 05004], lr: 0.001000, loss: 0.7658
2022-07-12 09:38:55 - train: epoch 0074, iter [01000, 05004], lr: 0.001000, loss: 0.6991
2022-07-12 09:39:27 - train: epoch 0074, iter [01100, 05004], lr: 0.001000, loss: 0.8522
2022-07-12 09:40:00 - train: epoch 0074, iter [01200, 05004], lr: 0.001000, loss: 0.6798
2022-07-12 09:40:33 - train: epoch 0074, iter [01300, 05004], lr: 0.001000, loss: 0.8283
2022-07-12 09:41:06 - train: epoch 0074, iter [01400, 05004], lr: 0.001000, loss: 0.6663
2022-07-12 09:41:39 - train: epoch 0074, iter [01500, 05004], lr: 0.001000, loss: 0.6800
2022-07-12 09:42:11 - train: epoch 0074, iter [01600, 05004], lr: 0.001000, loss: 0.5354
2022-07-12 09:42:44 - train: epoch 0074, iter [01700, 05004], lr: 0.001000, loss: 0.8223
2022-07-12 09:43:17 - train: epoch 0074, iter [01800, 05004], lr: 0.001000, loss: 1.0737
2022-07-12 09:43:49 - train: epoch 0074, iter [01900, 05004], lr: 0.001000, loss: 0.8453
2022-07-12 09:44:22 - train: epoch 0074, iter [02000, 05004], lr: 0.001000, loss: 0.5128
2022-07-12 09:44:55 - train: epoch 0074, iter [02100, 05004], lr: 0.001000, loss: 0.6665
2022-07-12 09:45:27 - train: epoch 0074, iter [02200, 05004], lr: 0.001000, loss: 1.0313
2022-07-12 09:46:00 - train: epoch 0074, iter [02300, 05004], lr: 0.001000, loss: 0.8382
2022-07-12 09:46:32 - train: epoch 0074, iter [02400, 05004], lr: 0.001000, loss: 0.7234
2022-07-12 09:47:05 - train: epoch 0074, iter [02500, 05004], lr: 0.001000, loss: 0.7798
2022-07-12 09:47:38 - train: epoch 0074, iter [02600, 05004], lr: 0.001000, loss: 0.5723
2022-07-12 09:48:10 - train: epoch 0074, iter [02700, 05004], lr: 0.001000, loss: 0.7063
2022-07-12 09:48:43 - train: epoch 0074, iter [02800, 05004], lr: 0.001000, loss: 0.9501
2022-07-12 09:49:16 - train: epoch 0074, iter [02900, 05004], lr: 0.001000, loss: 0.6708
2022-07-12 09:49:48 - train: epoch 0074, iter [03000, 05004], lr: 0.001000, loss: 0.8156
2022-07-12 09:50:21 - train: epoch 0074, iter [03100, 05004], lr: 0.001000, loss: 0.6809
2022-07-12 09:50:54 - train: epoch 0074, iter [03200, 05004], lr: 0.001000, loss: 0.7110
2022-07-12 09:51:27 - train: epoch 0074, iter [03300, 05004], lr: 0.001000, loss: 0.7139
2022-07-12 09:52:00 - train: epoch 0074, iter [03400, 05004], lr: 0.001000, loss: 0.7852
2022-07-12 09:52:33 - train: epoch 0074, iter [03500, 05004], lr: 0.001000, loss: 0.6450
2022-07-12 09:53:06 - train: epoch 0074, iter [03600, 05004], lr: 0.001000, loss: 0.7397
2022-07-12 09:53:38 - train: epoch 0074, iter [03700, 05004], lr: 0.001000, loss: 0.8031
2022-07-12 09:54:12 - train: epoch 0074, iter [03800, 05004], lr: 0.001000, loss: 0.7362
2022-07-12 09:54:44 - train: epoch 0074, iter [03900, 05004], lr: 0.001000, loss: 0.6179
2022-07-12 09:55:17 - train: epoch 0074, iter [04000, 05004], lr: 0.001000, loss: 0.6721
2022-07-12 09:55:50 - train: epoch 0074, iter [04100, 05004], lr: 0.001000, loss: 0.8834
2022-07-12 09:56:23 - train: epoch 0074, iter [04200, 05004], lr: 0.001000, loss: 0.7024
2022-07-12 09:56:56 - train: epoch 0074, iter [04300, 05004], lr: 0.001000, loss: 0.7227
2022-07-12 09:57:29 - train: epoch 0074, iter [04400, 05004], lr: 0.001000, loss: 0.6277
2022-07-12 09:58:02 - train: epoch 0074, iter [04500, 05004], lr: 0.001000, loss: 0.6682
2022-07-12 09:58:35 - train: epoch 0074, iter [04600, 05004], lr: 0.001000, loss: 0.8059
2022-07-12 09:59:08 - train: epoch 0074, iter [04700, 05004], lr: 0.001000, loss: 0.8282
2022-07-12 09:59:41 - train: epoch 0074, iter [04800, 05004], lr: 0.001000, loss: 0.8456
2022-07-12 10:00:14 - train: epoch 0074, iter [04900, 05004], lr: 0.001000, loss: 0.9457
2022-07-12 10:00:46 - train: epoch 0074, iter [05000, 05004], lr: 0.001000, loss: 0.7308
2022-07-12 10:00:47 - train: epoch 074, train_loss: 0.7510
2022-07-12 10:02:03 - eval: epoch: 074, acc1: 76.558%, acc5: 93.182%, test_loss: 0.9478, per_image_load_time: 2.270ms, per_image_inference_time: 0.575ms
2022-07-12 10:02:03 - until epoch: 074, best_acc1: 76.602%
2022-07-12 10:02:03 - epoch 075 lr: 0.001000
2022-07-12 10:02:43 - train: epoch 0075, iter [00100, 05004], lr: 0.001000, loss: 0.7533
2022-07-12 10:03:15 - train: epoch 0075, iter [00200, 05004], lr: 0.001000, loss: 0.7175
2022-07-12 10:03:48 - train: epoch 0075, iter [00300, 05004], lr: 0.001000, loss: 0.6831
2022-07-12 10:04:20 - train: epoch 0075, iter [00400, 05004], lr: 0.001000, loss: 0.7862
2022-07-12 10:04:52 - train: epoch 0075, iter [00500, 05004], lr: 0.001000, loss: 0.5981
2022-07-12 10:05:24 - train: epoch 0075, iter [00600, 05004], lr: 0.001000, loss: 0.7280
2022-07-12 10:05:57 - train: epoch 0075, iter [00700, 05004], lr: 0.001000, loss: 0.8246
2022-07-12 10:06:29 - train: epoch 0075, iter [00800, 05004], lr: 0.001000, loss: 0.8432
2022-07-12 10:07:02 - train: epoch 0075, iter [00900, 05004], lr: 0.001000, loss: 0.9194
2022-07-12 10:07:34 - train: epoch 0075, iter [01000, 05004], lr: 0.001000, loss: 0.6629
2022-07-12 10:08:07 - train: epoch 0075, iter [01100, 05004], lr: 0.001000, loss: 0.8098
2022-07-12 10:08:40 - train: epoch 0075, iter [01200, 05004], lr: 0.001000, loss: 0.6804
2022-07-12 10:09:12 - train: epoch 0075, iter [01300, 05004], lr: 0.001000, loss: 0.7434
2022-07-12 10:09:45 - train: epoch 0075, iter [01400, 05004], lr: 0.001000, loss: 0.7460
2022-07-12 10:10:17 - train: epoch 0075, iter [01500, 05004], lr: 0.001000, loss: 0.8853
2022-07-12 10:10:50 - train: epoch 0075, iter [01600, 05004], lr: 0.001000, loss: 0.5566
2022-07-12 10:11:22 - train: epoch 0075, iter [01700, 05004], lr: 0.001000, loss: 0.7075
2022-07-12 10:11:54 - train: epoch 0075, iter [01800, 05004], lr: 0.001000, loss: 0.6920
2022-07-12 10:12:27 - train: epoch 0075, iter [01900, 05004], lr: 0.001000, loss: 0.6604
2022-07-12 10:12:59 - train: epoch 0075, iter [02000, 05004], lr: 0.001000, loss: 0.8180
2022-07-12 10:13:32 - train: epoch 0075, iter [02100, 05004], lr: 0.001000, loss: 0.6687
2022-07-12 10:14:05 - train: epoch 0075, iter [02200, 05004], lr: 0.001000, loss: 0.7912
2022-07-12 10:14:37 - train: epoch 0075, iter [02300, 05004], lr: 0.001000, loss: 0.8316
2022-07-12 10:15:10 - train: epoch 0075, iter [02400, 05004], lr: 0.001000, loss: 0.7672
2022-07-12 10:15:42 - train: epoch 0075, iter [02500, 05004], lr: 0.001000, loss: 0.8979
2022-07-12 10:16:15 - train: epoch 0075, iter [02600, 05004], lr: 0.001000, loss: 0.7457
2022-07-12 10:16:48 - train: epoch 0075, iter [02700, 05004], lr: 0.001000, loss: 0.5935
2022-07-12 10:17:21 - train: epoch 0075, iter [02800, 05004], lr: 0.001000, loss: 0.6701
2022-07-12 10:17:53 - train: epoch 0075, iter [02900, 05004], lr: 0.001000, loss: 0.8425
2022-07-12 10:18:26 - train: epoch 0075, iter [03000, 05004], lr: 0.001000, loss: 0.8730
2022-07-12 10:18:59 - train: epoch 0075, iter [03100, 05004], lr: 0.001000, loss: 0.7680
2022-07-12 10:19:31 - train: epoch 0075, iter [03200, 05004], lr: 0.001000, loss: 0.7144
2022-07-12 10:20:04 - train: epoch 0075, iter [03300, 05004], lr: 0.001000, loss: 0.8067
2022-07-12 10:20:37 - train: epoch 0075, iter [03400, 05004], lr: 0.001000, loss: 0.5803
2022-07-12 10:21:10 - train: epoch 0075, iter [03500, 05004], lr: 0.001000, loss: 0.7010
2022-07-12 10:21:42 - train: epoch 0075, iter [03600, 05004], lr: 0.001000, loss: 0.6597
2022-07-12 10:22:15 - train: epoch 0075, iter [03700, 05004], lr: 0.001000, loss: 0.7825
2022-07-12 10:22:48 - train: epoch 0075, iter [03800, 05004], lr: 0.001000, loss: 0.6947
2022-07-12 10:23:20 - train: epoch 0075, iter [03900, 05004], lr: 0.001000, loss: 0.8728
2022-07-12 10:23:53 - train: epoch 0075, iter [04000, 05004], lr: 0.001000, loss: 0.7222
2022-07-12 10:24:26 - train: epoch 0075, iter [04100, 05004], lr: 0.001000, loss: 0.4617
2022-07-12 10:24:58 - train: epoch 0075, iter [04200, 05004], lr: 0.001000, loss: 0.7882
2022-07-12 10:25:31 - train: epoch 0075, iter [04300, 05004], lr: 0.001000, loss: 0.9751
2022-07-12 10:26:04 - train: epoch 0075, iter [04400, 05004], lr: 0.001000, loss: 0.6394
2022-07-12 10:26:37 - train: epoch 0075, iter [04500, 05004], lr: 0.001000, loss: 0.8456
2022-07-12 10:27:10 - train: epoch 0075, iter [04600, 05004], lr: 0.001000, loss: 0.6454
2022-07-12 10:27:43 - train: epoch 0075, iter [04700, 05004], lr: 0.001000, loss: 0.8213
2022-07-12 10:28:15 - train: epoch 0075, iter [04800, 05004], lr: 0.001000, loss: 0.8032
2022-07-12 10:28:48 - train: epoch 0075, iter [04900, 05004], lr: 0.001000, loss: 0.6843
2022-07-12 10:29:20 - train: epoch 0075, iter [05000, 05004], lr: 0.001000, loss: 0.8520
2022-07-12 10:29:22 - train: epoch 075, train_loss: 0.7475
2022-07-12 10:30:36 - eval: epoch: 075, acc1: 76.552%, acc5: 93.028%, test_loss: 0.9515, per_image_load_time: 1.840ms, per_image_inference_time: 0.586ms
2022-07-12 10:30:37 - until epoch: 075, best_acc1: 76.602%
2022-07-12 10:30:37 - epoch 076 lr: 0.001000
2022-07-12 10:31:16 - train: epoch 0076, iter [00100, 05004], lr: 0.001000, loss: 0.6459
2022-07-12 10:31:49 - train: epoch 0076, iter [00200, 05004], lr: 0.001000, loss: 0.7560
2022-07-12 10:32:21 - train: epoch 0076, iter [00300, 05004], lr: 0.001000, loss: 0.7986
2022-07-12 10:32:54 - train: epoch 0076, iter [00400, 05004], lr: 0.001000, loss: 0.8148
2022-07-12 10:33:27 - train: epoch 0076, iter [00500, 05004], lr: 0.001000, loss: 0.6987
2022-07-12 10:34:00 - train: epoch 0076, iter [00600, 05004], lr: 0.001000, loss: 0.7518
2022-07-12 10:34:32 - train: epoch 0076, iter [00700, 05004], lr: 0.001000, loss: 0.7550
2022-07-12 10:35:05 - train: epoch 0076, iter [00800, 05004], lr: 0.001000, loss: 0.6665
2022-07-12 10:35:38 - train: epoch 0076, iter [00900, 05004], lr: 0.001000, loss: 0.5626
2022-07-12 10:36:11 - train: epoch 0076, iter [01000, 05004], lr: 0.001000, loss: 0.6635
2022-07-12 10:36:43 - train: epoch 0076, iter [01100, 05004], lr: 0.001000, loss: 0.6179
2022-07-12 10:37:16 - train: epoch 0076, iter [01200, 05004], lr: 0.001000, loss: 0.6547
2022-07-12 10:37:49 - train: epoch 0076, iter [01300, 05004], lr: 0.001000, loss: 0.7438
2022-07-12 10:38:22 - train: epoch 0076, iter [01400, 05004], lr: 0.001000, loss: 0.6003
2022-07-12 10:38:55 - train: epoch 0076, iter [01500, 05004], lr: 0.001000, loss: 0.6317
2022-07-12 10:39:28 - train: epoch 0076, iter [01600, 05004], lr: 0.001000, loss: 0.7049
2022-07-12 10:40:00 - train: epoch 0076, iter [01700, 05004], lr: 0.001000, loss: 0.7196
2022-07-12 10:40:33 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 0.5268
2022-07-12 10:41:06 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 0.8262
2022-07-12 10:41:38 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 0.7669
2022-07-12 10:42:11 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 0.7696
2022-07-12 10:42:44 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 0.8986
2022-07-12 10:43:16 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 0.7233
2022-07-12 10:43:49 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 0.8345
2022-07-12 10:44:21 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 0.7210
2022-07-12 10:44:54 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 1.0048
2022-07-12 10:45:27 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 0.7831
2022-07-12 10:45:59 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 0.6963
2022-07-12 10:46:32 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 0.7237
2022-07-12 10:47:05 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 0.6598
2022-07-12 10:47:37 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 0.8078
2022-07-12 10:48:10 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 0.8193
2022-07-12 10:48:43 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 0.8321
2022-07-12 10:49:16 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 0.8076
2022-07-12 10:49:49 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 0.6964
2022-07-12 10:50:22 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 0.6457
2022-07-12 10:50:55 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 0.6864
2022-07-12 10:51:27 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 0.6487
2022-07-12 10:52:00 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 0.5752
2022-07-12 10:52:33 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 0.7611
2022-07-12 10:53:06 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 0.6195
2022-07-12 10:53:39 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 1.0029
2022-07-12 10:54:12 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 0.7288
2022-07-12 10:54:45 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 0.8655
2022-07-12 10:55:17 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 0.7113
2022-07-12 10:55:50 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 0.7116
2022-07-12 10:56:22 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 0.7791
2022-07-12 10:56:55 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 0.6579
2022-07-12 10:57:28 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 0.7122
2022-07-12 10:58:00 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 0.7695
2022-07-12 10:58:02 - train: epoch 076, train_loss: 0.7428
2022-07-12 10:59:17 - eval: epoch: 076, acc1: 76.430%, acc5: 93.042%, test_loss: 0.9553, per_image_load_time: 1.869ms, per_image_inference_time: 0.594ms
2022-07-12 10:59:18 - until epoch: 076, best_acc1: 76.602%
2022-07-12 10:59:18 - epoch 077 lr: 0.001000
2022-07-12 10:59:57 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 0.8174
2022-07-12 11:00:29 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 0.7925
2022-07-12 11:01:01 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 0.5943
2022-07-12 11:01:33 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 0.8586
2022-07-12 11:02:05 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 0.6447
2022-07-12 11:02:38 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 0.6138
2022-07-12 11:03:11 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 0.7060
2022-07-12 11:03:43 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 0.7758
2022-07-12 11:04:16 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 0.7656
2022-07-12 11:04:48 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 0.6166
2022-07-12 11:05:21 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 0.6784
2022-07-12 11:05:53 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 0.7475
2022-07-12 11:06:26 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 0.6142
2022-07-12 11:06:58 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 0.8787
2022-07-12 11:07:31 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 0.6537
2022-07-12 11:08:04 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 0.7646
2022-07-12 11:08:36 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 0.9176
2022-07-12 11:09:09 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 0.5926
2022-07-12 11:09:41 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 0.7466
2022-07-12 11:10:13 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 0.6256
2022-07-12 11:10:46 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 0.7069
2022-07-12 11:11:18 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 0.7615
2022-07-12 11:11:51 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 0.8151
2022-07-12 11:12:24 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 0.7189
2022-07-12 11:12:57 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 0.8963
2022-07-12 11:13:29 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 0.5702
2022-07-12 11:14:02 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 0.7760
2022-07-12 11:14:34 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 0.7726
2022-07-12 11:15:07 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 0.9995
2022-07-12 11:15:40 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 0.6585
2022-07-12 11:16:12 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 0.7403
2022-07-12 11:16:45 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 0.7802
2022-07-12 11:17:17 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 0.6931
2022-07-12 11:17:50 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 0.9136
2022-07-12 11:18:23 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 0.6771
2022-07-12 11:18:56 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 0.6699
2022-07-12 11:19:29 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 0.7680
2022-07-12 11:20:01 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 0.7535
2022-07-12 11:20:34 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 0.7919
2022-07-12 11:21:07 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 0.7332
2022-07-12 11:21:40 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 0.9830
2022-07-12 11:22:12 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 0.8387
2022-07-12 11:22:45 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 0.7364
2022-07-12 11:23:18 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 0.6722
2022-07-12 11:23:50 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 0.7283
2022-07-12 11:24:23 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 0.7668
2022-07-12 11:24:56 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 0.5039
2022-07-12 11:25:29 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 0.7975
2022-07-12 11:26:01 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 0.8068
2022-07-12 11:26:34 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 0.9227
2022-07-12 11:26:35 - train: epoch 077, train_loss: 0.7366
2022-07-12 11:27:50 - eval: epoch: 077, acc1: 76.458%, acc5: 93.134%, test_loss: 0.9518, per_image_load_time: 2.339ms, per_image_inference_time: 0.582ms
2022-07-12 11:27:51 - until epoch: 077, best_acc1: 76.602%
2022-07-12 11:27:51 - epoch 078 lr: 0.001000
2022-07-12 11:28:30 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 0.6522
2022-07-12 11:29:02 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 0.8199
2022-07-12 11:29:34 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 0.8418
2022-07-12 11:30:07 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 0.7817
2022-07-12 11:30:39 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 0.7594
2022-07-12 11:31:11 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 0.7624
2022-07-12 11:31:44 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 0.7233
2022-07-12 11:32:17 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 0.8087
2022-07-12 11:32:49 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 0.7436
2022-07-12 11:33:22 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 0.7817
2022-07-12 11:33:54 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 0.5489
2022-07-12 11:34:26 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 0.5419
2022-07-12 11:34:59 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 0.8047
2022-07-12 11:35:31 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 0.6261
2022-07-12 11:36:04 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 0.7320
2022-07-12 11:36:36 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 0.7834
2022-07-12 11:37:09 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 0.6894
2022-07-12 11:37:42 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 0.6729
2022-07-12 11:38:14 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 0.6220
2022-07-12 11:38:47 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 0.6128
2022-07-12 11:39:20 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 0.8738
2022-07-12 11:39:53 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 0.7431
2022-07-12 11:40:26 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 0.8673
2022-07-12 11:40:58 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 0.6806
2022-07-12 11:41:31 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 0.7333
2022-07-12 11:42:04 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 0.6505
2022-07-12 11:42:37 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 0.7248
2022-07-12 11:43:10 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 0.8102
2022-07-12 11:43:43 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 0.6007
2022-07-12 11:44:16 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 0.6397
2022-07-12 11:44:48 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 0.8213
2022-07-12 11:45:21 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 0.7108
2022-07-12 11:45:54 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 0.7918
2022-07-12 11:46:26 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 0.7525
2022-07-12 11:46:59 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 0.7629
2022-07-12 11:47:32 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 0.8402
2022-07-12 11:48:05 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 0.6286
2022-07-12 11:48:37 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 0.7546
2022-07-12 11:49:10 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 0.8029
2022-07-12 11:49:43 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 0.7020
2022-07-12 11:50:15 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 0.8753
2022-07-12 11:50:48 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 0.9202
2022-07-12 11:51:20 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 0.7372
2022-07-12 11:51:53 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 0.7033
2022-07-12 11:52:26 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 0.7558
2022-07-12 11:52:58 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 0.6770
2022-07-12 11:53:31 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 0.7604
2022-07-12 11:54:04 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 0.9282
2022-07-12 11:54:37 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 0.6993
2022-07-12 11:55:09 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 0.6854
2022-07-12 11:55:10 - train: epoch 078, train_loss: 0.7310
2022-07-12 11:56:25 - eval: epoch: 078, acc1: 76.426%, acc5: 93.058%, test_loss: 0.9585, per_image_load_time: 2.245ms, per_image_inference_time: 0.575ms
2022-07-12 11:56:26 - until epoch: 078, best_acc1: 76.602%
2022-07-12 11:56:26 - epoch 079 lr: 0.001000
2022-07-12 11:57:04 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 0.7292
2022-07-12 11:57:37 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 0.6907
2022-07-12 11:58:09 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 0.7349
2022-07-12 11:58:41 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 0.7375
2022-07-12 11:59:14 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 0.7809
2022-07-12 11:59:47 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 0.6850
2022-07-12 12:00:20 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 0.6366
2022-07-12 12:00:52 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 0.7176
2022-07-12 12:01:25 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 0.5811
2022-07-12 12:01:58 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 0.6416
2022-07-12 12:02:31 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 0.7881
2022-07-12 12:03:04 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 0.9531
2022-07-12 12:03:37 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 0.6797
2022-07-12 12:04:10 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 0.7090
2022-07-12 12:04:43 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 0.5698
2022-07-12 12:05:16 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 0.6610
2022-07-12 12:05:49 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 0.5571
2022-07-12 12:06:21 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 0.6552
2022-07-12 12:06:54 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 0.8092
2022-07-12 12:07:27 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 0.8701
2022-07-12 12:07:59 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 0.6781
2022-07-12 12:08:32 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 0.7782
2022-07-12 12:09:04 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 0.6627
2022-07-12 12:09:37 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 0.8308
2022-07-12 12:10:09 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 0.6849
2022-07-12 12:10:41 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 0.6659
2022-07-12 12:11:14 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 0.6654
2022-07-12 12:11:46 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 0.6780
2022-07-12 12:12:19 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 0.5673
2022-07-12 12:12:51 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 0.8277
2022-07-12 12:13:24 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 0.8121
2022-07-12 12:13:57 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 0.8854
2022-07-12 12:14:29 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 0.7045
2022-07-12 12:15:02 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 0.5891
2022-07-12 12:15:34 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 0.8733
2022-07-12 12:16:07 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 0.6432
2022-07-12 12:16:39 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 0.5758
2022-07-12 12:17:12 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 0.8714
2022-07-12 12:17:45 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 0.6185
2022-07-12 12:18:18 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 0.6078
2022-07-12 12:18:50 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 0.8663
2022-07-12 12:19:23 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 0.6191
2022-07-12 12:19:56 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 0.5615
2022-07-12 12:20:28 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 0.8232
2022-07-12 12:21:00 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 0.8949
2022-07-12 12:21:33 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 0.8971
2022-07-12 12:22:06 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 0.7657
2022-07-12 12:22:39 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 0.8400
2022-07-12 12:23:11 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 0.8510
2022-07-12 12:23:43 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 0.7325
2022-07-12 12:23:45 - train: epoch 079, train_loss: 0.7285
2022-07-12 12:25:00 - eval: epoch: 079, acc1: 76.384%, acc5: 93.074%, test_loss: 0.9613, per_image_load_time: 2.272ms, per_image_inference_time: 0.577ms
2022-07-12 12:25:00 - until epoch: 079, best_acc1: 76.602%
2022-07-12 12:25:00 - epoch 080 lr: 0.001000
2022-07-12 12:25:40 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 0.5610
2022-07-12 12:26:12 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 0.7595
2022-07-12 12:26:44 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 0.8573
2022-07-12 12:27:17 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 0.6051
2022-07-12 12:27:50 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 0.8409
2022-07-12 12:28:23 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 0.5654
2022-07-12 12:28:55 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 0.7063
2022-07-12 12:29:28 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 0.6347
2022-07-12 12:30:00 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 0.7051
2022-07-12 12:30:33 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 0.7112
2022-07-12 12:31:06 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 0.6731
2022-07-12 12:31:39 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 0.6872
2022-07-12 12:32:11 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 0.6941
2022-07-12 12:32:44 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 0.8101
2022-07-12 12:33:17 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 0.6118
2022-07-12 12:33:49 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 0.6919
2022-07-12 12:34:22 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 0.7433
2022-07-12 12:34:55 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 0.7924
2022-07-12 12:35:28 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 0.7249
2022-07-12 12:36:01 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 0.8607
2022-07-12 12:36:34 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 0.7164
2022-07-12 12:37:07 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 0.8070
2022-07-12 12:37:39 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 0.6948
2022-07-12 12:38:12 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 0.6710
2022-07-12 12:38:44 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 0.6983
2022-07-12 12:39:18 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 0.7171
2022-07-12 12:39:50 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 0.7637
2022-07-12 12:40:23 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 0.7353
2022-07-12 12:40:56 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 0.6671
2022-07-12 12:41:29 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 0.6602
2022-07-12 12:42:02 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 0.8552
2022-07-12 12:42:35 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 0.5128
2022-07-12 12:43:08 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 0.7161
2022-07-12 12:43:41 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 0.6863
2022-07-12 12:44:13 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 0.5687
2022-07-12 12:44:46 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 0.7615
2022-07-12 12:45:19 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 0.7062
2022-07-12 12:45:52 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 0.7010
2022-07-12 12:46:25 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 0.6855
2022-07-12 12:46:57 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 0.8792
2022-07-12 12:47:30 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 0.7375
2022-07-12 12:48:03 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 0.6663
2022-07-12 12:48:36 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 0.7954
2022-07-12 12:49:09 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 0.7385
2022-07-12 12:49:42 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 0.6224
2022-07-12 12:50:14 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 0.8124
2022-07-12 12:50:47 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 0.7641
2022-07-12 12:51:20 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 0.7673
2022-07-12 12:51:53 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 0.8385
2022-07-12 12:52:25 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 0.5434
2022-07-12 12:52:27 - train: epoch 080, train_loss: 0.7261
2022-07-12 12:53:42 - eval: epoch: 080, acc1: 76.448%, acc5: 93.068%, test_loss: 0.9614, per_image_load_time: 2.217ms, per_image_inference_time: 0.583ms
2022-07-12 12:53:42 - until epoch: 080, best_acc1: 76.602%
2022-07-12 12:53:42 - epoch 081 lr: 0.001000
2022-07-12 12:54:21 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 0.6128
2022-07-12 12:54:54 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 0.7701
2022-07-12 12:55:27 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 0.6502
2022-07-12 12:55:59 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 0.9317
2022-07-12 12:56:32 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 0.7379
2022-07-12 12:57:05 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 0.7566
2022-07-12 12:57:38 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 0.6689
2022-07-12 12:58:10 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 0.7816
2022-07-12 12:58:43 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 0.6381
2022-07-12 12:59:16 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 0.6587
2022-07-12 12:59:49 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 0.7623
2022-07-12 13:00:22 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 0.7232
2022-07-12 13:00:54 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 0.6286
2022-07-12 13:01:27 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 0.4495
2022-07-12 13:02:00 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 0.7071
2022-07-12 13:02:33 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 0.6620
2022-07-12 13:03:06 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 0.7513
2022-07-12 13:03:39 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 0.6607
2022-07-12 13:04:12 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 0.6731
2022-07-12 13:04:45 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 0.7647
2022-07-12 13:05:18 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 0.6658
2022-07-12 13:05:50 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 0.7510
2022-07-12 13:06:23 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 0.7040
2022-07-12 13:06:56 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 0.6837
2022-07-12 13:07:28 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 0.8602
2022-07-12 13:08:01 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 0.8849
2022-07-12 13:08:34 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 0.6765
2022-07-12 13:09:07 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 0.7288
2022-07-12 13:09:40 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 0.6806
2022-07-12 13:10:12 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 0.7089
2022-07-12 13:10:45 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 0.6142
2022-07-12 13:11:17 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 0.7543
2022-07-12 13:11:50 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 0.7352
2022-07-12 13:12:22 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 0.8017
2022-07-12 13:12:55 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 0.7222
2022-07-12 13:13:28 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 0.6176
2022-07-12 13:14:00 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 0.8192
2022-07-12 13:14:33 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 0.6553
2022-07-12 13:15:05 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 0.7772
2022-07-12 13:15:38 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 0.5448
2022-07-12 13:16:10 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 0.8165
2022-07-12 13:16:43 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 0.7547
2022-07-12 13:17:15 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 0.7226
2022-07-12 13:17:48 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 0.7888
2022-07-12 13:18:20 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 0.7580
2022-07-12 13:18:53 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 0.5788
2022-07-12 13:19:26 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 0.7715
2022-07-12 13:19:58 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 0.7738
2022-07-12 13:20:31 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 0.7733
2022-07-12 13:21:03 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 0.5545
2022-07-12 13:21:04 - train: epoch 081, train_loss: 0.7219
2022-07-12 13:22:20 - eval: epoch: 081, acc1: 76.360%, acc5: 93.102%, test_loss: 0.9621, per_image_load_time: 1.622ms, per_image_inference_time: 0.590ms
2022-07-12 13:22:20 - until epoch: 081, best_acc1: 76.602%
2022-07-12 13:22:20 - epoch 082 lr: 0.001000
2022-07-12 13:22:59 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 0.5712
2022-07-12 13:23:32 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 0.6384
2022-07-12 13:24:04 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 0.8353
2022-07-12 13:24:36 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 0.7837
2022-07-12 13:25:09 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 0.7491
2022-07-12 13:25:41 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 0.6127
2022-07-12 13:26:14 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 0.8208
2022-07-12 13:26:46 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 0.7191
2022-07-12 13:27:18 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 0.7780
2022-07-12 13:27:51 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 0.7559
2022-07-12 13:28:23 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 0.8253
2022-07-12 13:28:55 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 0.7889
2022-07-12 13:29:28 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 0.8215
2022-07-12 13:30:00 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 0.7652
2022-07-12 13:30:32 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 0.6302
2022-07-12 13:31:05 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 0.8484
2022-07-12 13:31:37 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 0.6780
2022-07-12 13:32:09 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 0.6786
2022-07-12 13:32:42 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 0.7077
2022-07-12 13:33:15 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 0.6337
2022-07-12 13:33:47 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 0.6566
2022-07-12 13:34:19 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 0.8344
2022-07-12 13:34:52 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 0.7311
2022-07-12 13:35:24 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 0.6886
2022-07-12 13:35:56 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 0.5855
2022-07-12 13:36:29 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 0.5966
2022-07-12 13:37:01 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 0.6774
2022-07-12 13:37:34 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 0.6460
2022-07-12 13:38:06 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 0.6869
2022-07-12 13:38:39 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 0.6903
2022-07-12 13:39:12 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 0.6226
2022-07-12 13:39:44 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 0.8762
2022-07-12 13:40:17 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 0.6724
2022-07-12 13:40:49 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 0.6082
2022-07-12 13:41:22 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 0.6382
2022-07-12 13:41:54 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 0.5241
2022-07-12 13:42:27 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 0.6838
2022-07-12 13:43:00 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 0.7649
2022-07-12 13:43:33 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 0.6870
2022-07-12 13:44:05 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 0.7708
2022-07-12 13:44:38 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 0.6557
2022-07-12 13:45:10 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 0.8200
2022-07-12 13:45:43 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 0.6228
2022-07-12 13:46:16 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 0.7316
2022-07-12 13:46:49 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 0.8189
2022-07-12 13:47:21 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 0.7203
2022-07-12 13:47:54 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 0.7088
2022-07-12 13:48:26 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 0.5942
2022-07-12 13:48:59 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 0.6574
2022-07-12 13:49:31 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 0.6952
2022-07-12 13:49:33 - train: epoch 082, train_loss: 0.7183
2022-07-12 13:50:48 - eval: epoch: 082, acc1: 76.390%, acc5: 93.022%, test_loss: 0.9636, per_image_load_time: 1.857ms, per_image_inference_time: 0.575ms
2022-07-12 13:50:48 - until epoch: 082, best_acc1: 76.602%
2022-07-12 13:50:48 - epoch 083 lr: 0.001000
2022-07-12 13:51:27 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 0.6107
2022-07-12 13:52:00 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 0.6584
2022-07-12 13:52:33 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 0.7513
2022-07-12 13:53:06 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 0.8710
2022-07-12 13:53:39 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 0.6764
2022-07-12 13:54:11 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 0.7160
2022-07-12 13:54:44 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 0.6261
2022-07-12 13:55:17 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 0.7327
2022-07-12 13:55:50 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 0.7442
2022-07-12 13:56:23 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 0.7933
2022-07-12 13:56:55 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 0.6502
2022-07-12 13:57:28 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 0.7110
2022-07-12 13:58:01 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 0.6003
2022-07-12 13:58:34 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 0.7722
2022-07-12 13:59:07 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 0.6411
2022-07-12 13:59:40 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 0.7057
2022-07-12 14:00:12 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 0.8141
2022-07-12 14:00:45 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 0.9146
2022-07-12 14:01:17 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 0.5608
2022-07-12 14:01:50 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 0.4965
2022-07-12 14:02:23 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 0.5747
2022-07-12 14:02:55 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 0.7280
2022-07-12 14:03:28 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 0.7424
2022-07-12 14:04:01 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 0.6802
2022-07-12 14:04:33 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 0.7114
2022-07-12 14:05:06 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 0.5873
2022-07-12 14:05:38 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 0.7152
2022-07-12 14:06:11 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 0.6584
2022-07-12 14:06:44 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 0.6972
2022-07-12 14:07:17 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 0.7576
2022-07-12 14:07:50 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 0.5694
2022-07-12 14:08:23 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 0.6542
2022-07-12 14:08:56 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 0.9314
2022-07-12 14:09:29 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 0.8313
2022-07-12 14:10:01 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 0.7820
2022-07-12 14:10:34 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 0.7624
2022-07-12 14:11:07 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 0.7595
2022-07-12 14:11:40 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 0.6680
2022-07-12 14:12:13 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 0.6787
2022-07-12 14:12:46 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 0.8193
2022-07-12 14:13:19 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 0.7289
2022-07-12 14:13:51 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 0.8747
2022-07-12 14:14:24 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 0.7133
2022-07-12 14:14:57 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 0.5580
2022-07-12 14:15:30 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 0.8420
2022-07-12 14:16:03 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 0.7919
2022-07-12 14:16:36 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 0.8015
2022-07-12 14:17:08 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 0.7794
2022-07-12 14:17:41 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 0.9295
2022-07-12 14:18:14 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 0.8513
2022-07-12 14:18:15 - train: epoch 083, train_loss: 0.7158
2022-07-12 14:19:31 - eval: epoch: 083, acc1: 76.452%, acc5: 92.972%, test_loss: 0.9661, per_image_load_time: 2.086ms, per_image_inference_time: 0.585ms
2022-07-12 14:19:31 - until epoch: 083, best_acc1: 76.602%
2022-07-12 14:19:31 - epoch 084 lr: 0.001000
2022-07-12 14:20:10 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 0.7277
2022-07-12 14:20:42 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 0.7614
2022-07-12 14:21:15 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 0.6018
2022-07-12 14:21:47 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 0.7407
2022-07-12 14:22:20 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 0.7128
2022-07-12 14:22:52 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 0.8209
2022-07-12 14:23:25 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 0.7216
2022-07-12 14:23:58 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 0.8068
2022-07-12 14:24:30 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 0.7215
2022-07-12 14:25:03 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 0.7060
2022-07-12 14:25:36 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 0.6472
2022-07-12 14:26:08 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 0.8769
2022-07-12 14:26:41 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 0.6157
2022-07-12 14:27:14 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 0.7159
2022-07-12 14:27:46 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 0.6335
2022-07-12 14:28:19 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 0.6613
2022-07-12 14:28:51 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 0.8076
2022-07-12 14:29:24 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 0.7204
2022-07-12 14:29:56 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 0.6981
2022-07-12 14:30:29 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 0.7586
2022-07-12 14:31:02 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 0.6527
2022-07-12 14:31:35 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 0.4674
2022-07-12 14:32:07 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 0.6057
2022-07-12 14:32:40 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 0.6845
2022-07-12 14:33:13 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 0.8600
2022-07-12 14:33:45 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 0.8334
2022-07-12 14:34:18 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 0.7669
2022-07-12 14:34:51 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 0.8329
2022-07-12 14:35:24 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 0.6851
2022-07-12 14:35:56 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 0.6532
2022-07-12 14:36:29 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 0.5682
2022-07-12 14:37:02 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 0.5745
2022-07-12 14:37:35 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 0.7090
2022-07-12 14:38:08 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 0.6221
2022-07-12 14:38:40 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 0.6039
2022-07-12 14:39:13 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 0.7171
2022-07-12 14:39:46 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 0.7652
2022-07-12 14:40:19 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 0.8033
2022-07-12 14:40:52 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 0.7921
2022-07-12 14:41:24 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 0.7912
2022-07-12 14:41:57 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 0.7439
2022-07-12 14:42:29 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 0.7762
2022-07-12 14:43:02 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 0.6985
2022-07-12 14:43:34 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 0.9346
2022-07-12 14:44:07 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 0.6495
2022-07-12 14:44:39 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 0.7308
2022-07-12 14:45:11 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 1.0297
2022-07-12 14:45:44 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 0.6447
2022-07-12 14:46:16 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 0.6217
2022-07-12 14:46:48 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 0.7595
2022-07-12 14:46:50 - train: epoch 084, train_loss: 0.7112
2022-07-12 14:48:05 - eval: epoch: 084, acc1: 76.304%, acc5: 93.058%, test_loss: 0.9705, per_image_load_time: 2.028ms, per_image_inference_time: 0.587ms
2022-07-12 14:48:05 - until epoch: 084, best_acc1: 76.602%
2022-07-12 14:48:05 - epoch 085 lr: 0.001000
2022-07-12 14:48:45 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 0.5626
2022-07-12 14:49:17 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 0.5797
2022-07-12 14:49:49 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 0.7988
2022-07-12 14:50:21 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 0.5726
2022-07-12 14:50:54 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 0.8284
2022-07-12 14:51:26 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 0.5560
2022-07-12 14:51:58 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 0.5758
2022-07-12 14:52:31 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 0.6740
2022-07-12 14:53:03 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 0.7266
2022-07-12 14:53:36 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 0.7387
2022-07-12 14:54:08 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 0.6678
2022-07-12 14:54:41 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 0.6434
2022-07-12 14:55:14 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 0.6467
2022-07-12 14:55:46 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 0.7767
2022-07-12 14:56:18 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 0.5843
2022-07-12 14:56:50 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 0.7269
2022-07-12 14:57:23 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 0.8499
2022-07-12 14:57:55 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 0.5968
2022-07-12 14:58:27 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 0.6237
2022-07-12 14:59:00 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 0.7249
2022-07-12 14:59:32 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 0.5392
2022-07-12 15:00:04 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 0.7233
2022-07-12 15:00:37 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 0.6501
2022-07-12 15:01:10 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 0.7381
2022-07-12 15:01:42 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 0.8821
2022-07-12 15:02:14 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 0.7756
2022-07-12 15:02:47 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 0.7160
2022-07-12 15:03:19 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 0.7606
2022-07-12 15:03:52 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 0.9014
2022-07-12 15:04:24 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 0.8693
2022-07-12 15:04:57 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 0.6591
2022-07-12 15:05:29 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 0.7138
2022-07-12 15:06:02 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 0.7499
2022-07-12 15:06:34 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 0.7591
2022-07-12 15:07:07 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 0.7494
2022-07-12 15:07:40 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 0.7545
2022-07-12 15:08:13 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 0.6796
2022-07-12 15:08:45 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 0.5962
2022-07-12 15:09:17 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 0.6554
2022-07-12 15:09:50 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 0.8999
2022-07-12 15:10:22 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 0.7559
2022-07-12 15:10:55 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 0.7671
2022-07-12 15:11:27 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 0.6692
2022-07-12 15:12:00 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 0.7205
2022-07-12 15:12:32 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 0.8529
2022-07-12 15:13:05 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 0.7402
2022-07-12 15:13:38 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 0.9236
2022-07-12 15:14:10 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 0.6599
2022-07-12 15:14:43 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 0.6911
2022-07-12 15:15:15 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 0.7315
2022-07-12 15:15:16 - train: epoch 085, train_loss: 0.7104
2022-07-12 15:16:31 - eval: epoch: 085, acc1: 76.270%, acc5: 93.062%, test_loss: 0.9733, per_image_load_time: 2.274ms, per_image_inference_time: 0.586ms
2022-07-12 15:16:31 - until epoch: 085, best_acc1: 76.602%
2022-07-12 15:16:31 - epoch 086 lr: 0.001000
2022-07-12 15:17:11 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 0.5816
2022-07-12 15:17:43 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 0.5953
2022-07-12 15:18:16 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 0.7731
2022-07-12 15:18:48 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 0.7145
2022-07-12 15:19:21 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 0.7203
2022-07-12 15:19:53 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 0.6868
2022-07-12 15:20:26 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 0.6454
2022-07-12 15:20:58 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 0.8374
2022-07-12 15:21:31 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 0.7693
2022-07-12 15:22:04 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 0.7205
2022-07-12 15:22:36 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 0.8065
2022-07-12 15:23:09 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 0.6412
2022-07-12 15:23:42 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 0.7682
2022-07-12 15:24:14 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 0.6101
2022-07-12 15:24:47 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 0.6272
2022-07-12 15:25:20 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 0.8079
2022-07-12 15:25:52 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 0.7873
2022-07-12 15:26:25 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 0.6321
2022-07-12 15:26:58 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 0.8487
2022-07-12 15:27:31 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 0.6682
2022-07-12 15:28:03 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 0.6324
2022-07-12 15:28:36 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 0.7154
2022-07-12 15:29:08 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 0.6373
2022-07-12 15:29:41 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 0.6500
2022-07-12 15:30:13 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 0.6242
2022-07-12 15:30:45 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 0.6931
2022-07-12 15:31:18 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 0.5947
2022-07-12 15:31:50 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 0.8282
2022-07-12 15:32:23 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 0.6455
2022-07-12 15:32:55 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 0.8044
2022-07-12 15:33:28 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 0.7674
2022-07-12 15:34:00 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 0.7831
2022-07-12 15:34:33 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 0.8528
2022-07-12 15:35:06 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 0.7459
2022-07-12 15:35:38 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 0.7320
2022-07-12 15:36:11 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 0.7461
2022-07-12 15:36:43 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 0.8236
2022-07-12 15:37:16 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 0.7452
2022-07-12 15:37:49 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 0.7305
2022-07-12 15:38:22 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 0.7331
2022-07-12 15:38:54 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 0.7245
2022-07-12 15:39:27 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 0.7837
2022-07-12 15:39:59 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 0.6588
2022-07-12 15:40:32 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 0.6705
2022-07-12 15:41:05 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 0.6300
2022-07-12 15:41:37 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 0.6973
2022-07-12 15:42:10 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 0.7084
2022-07-12 15:42:43 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 0.7206
2022-07-12 15:43:16 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 0.7521
2022-07-12 15:43:48 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 0.7357
2022-07-12 15:43:49 - train: epoch 086, train_loss: 0.7058
2022-07-12 15:45:05 - eval: epoch: 086, acc1: 76.322%, acc5: 92.982%, test_loss: 0.9752, per_image_load_time: 2.201ms, per_image_inference_time: 0.593ms
2022-07-12 15:45:05 - until epoch: 086, best_acc1: 76.602%
2022-07-12 15:45:05 - epoch 087 lr: 0.001000
2022-07-12 15:45:44 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 0.8126
2022-07-12 15:46:17 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 0.6187
2022-07-12 15:46:50 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 0.9421
2022-07-12 15:47:23 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 0.7956
2022-07-12 15:47:55 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 0.5507
2022-07-12 15:48:27 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 0.7124
2022-07-12 15:49:00 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 0.4825
2022-07-12 15:49:33 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 0.8512
2022-07-12 15:50:05 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 0.7868
2022-07-12 15:50:38 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 0.6098
2022-07-12 15:51:10 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 0.7010
2022-07-12 15:51:43 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 0.7361
2022-07-12 15:52:16 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 0.7282
2022-07-12 15:52:48 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 0.7284
2022-07-12 15:53:21 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 0.6790
2022-07-12 15:53:53 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 0.6196
2022-07-12 15:54:26 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 0.6588
2022-07-12 15:54:59 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 0.7606
2022-07-12 15:55:31 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 0.7884
2022-07-12 15:56:04 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 0.6964
2022-07-12 15:56:37 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 0.8040
2022-07-12 15:57:10 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 0.6258
2022-07-12 15:57:42 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 0.6972
2022-07-12 15:58:15 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 0.6823
2022-07-12 15:58:48 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 0.7061
2022-07-12 15:59:20 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 0.6815
2022-07-12 15:59:53 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 0.6235
2022-07-12 16:00:25 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 0.6466
2022-07-12 16:00:59 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 0.6093
2022-07-12 16:01:31 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 0.6410
2022-07-12 16:02:04 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 0.7485
2022-07-12 16:02:37 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 0.6423
2022-07-12 16:03:09 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 0.6820
2022-07-12 16:03:42 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 0.8004
2022-07-12 16:04:15 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 0.6661
2022-07-12 16:04:48 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 0.6481
2022-07-12 16:05:21 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 0.6448
2022-07-12 16:05:53 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 0.6549
2022-07-12 16:06:26 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 0.6850
2022-07-12 16:06:58 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 0.7661
2022-07-12 16:07:31 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 0.8165
2022-07-12 16:08:03 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 0.7240
2022-07-12 16:08:36 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 0.7712
2022-07-12 16:09:09 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 0.7189
2022-07-12 16:09:42 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 0.7517
2022-07-12 16:10:14 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 0.6688
2022-07-12 16:10:47 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 0.7300
2022-07-12 16:11:20 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 0.6601
2022-07-12 16:11:53 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 0.7377
2022-07-12 16:12:25 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 0.7108
2022-07-12 16:12:27 - train: epoch 087, train_loss: 0.7025
2022-07-12 16:13:42 - eval: epoch: 087, acc1: 76.288%, acc5: 92.980%, test_loss: 0.9729, per_image_load_time: 2.242ms, per_image_inference_time: 0.578ms
2022-07-12 16:13:43 - until epoch: 087, best_acc1: 76.602%
2022-07-12 16:13:43 - epoch 088 lr: 0.001000
2022-07-12 16:14:22 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 0.7256
2022-07-12 16:14:55 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 0.6645
2022-07-12 16:15:27 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 0.6774
2022-07-12 16:15:59 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 0.7289
2022-07-12 16:16:32 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 0.5623
2022-07-12 16:17:05 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 0.7049
2022-07-12 16:17:37 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 0.6700
2022-07-12 16:18:10 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 0.7199
2022-07-12 16:18:42 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 0.7420
2022-07-12 16:19:14 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 0.6697
2022-07-12 16:19:47 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 0.6851
2022-07-12 16:20:20 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 0.6207
2022-07-12 16:20:52 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 0.7662
2022-07-12 16:21:25 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 0.7037
2022-07-12 16:21:58 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 0.7013
2022-07-12 16:22:31 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 0.5905
2022-07-12 16:23:03 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 0.7267
2022-07-12 16:23:36 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 0.7312
2022-07-12 16:24:09 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 0.7185
2022-07-12 16:24:41 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 0.5843
2022-07-12 16:25:14 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 0.7667
2022-07-12 16:25:46 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 0.6430
2022-07-12 16:26:19 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 0.5604
2022-07-12 16:26:52 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 0.7038
2022-07-12 16:27:24 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 0.6910
2022-07-12 16:27:57 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 0.7607
2022-07-12 16:28:29 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 0.6812
2022-07-12 16:29:02 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 0.6721
2022-07-12 16:29:35 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 0.6428
2022-07-12 16:30:08 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 0.7761
2022-07-12 16:30:40 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 0.6554
2022-07-12 16:31:13 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 0.5971
2022-07-12 16:31:46 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 0.6383
2022-07-12 16:32:18 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 0.5499
2022-07-12 16:32:51 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 0.6633
2022-07-12 16:33:24 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 0.7971
2022-07-12 16:33:56 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 0.7159
2022-07-12 16:34:29 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 0.7222
2022-07-12 16:35:02 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 0.7890
2022-07-12 16:35:35 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 0.6174
2022-07-12 16:36:08 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 0.6733
2022-07-12 16:36:41 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 0.7657
2022-07-12 16:37:14 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 0.6262
2022-07-12 16:37:47 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 0.5973
2022-07-12 16:38:20 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 0.6448
2022-07-12 16:38:53 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 0.7487
2022-07-12 16:39:25 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 0.7105
2022-07-12 16:39:58 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 0.5409
2022-07-12 16:40:31 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 0.5254
2022-07-12 16:41:03 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 0.7187
2022-07-12 16:41:05 - train: epoch 088, train_loss: 0.6995
2022-07-12 16:42:20 - eval: epoch: 088, acc1: 76.302%, acc5: 93.004%, test_loss: 0.9780, per_image_load_time: 2.168ms, per_image_inference_time: 0.587ms
2022-07-12 16:42:20 - until epoch: 088, best_acc1: 76.602%
2022-07-12 16:42:20 - epoch 089 lr: 0.001000
2022-07-12 16:43:00 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 0.8018
2022-07-12 16:43:33 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 0.5420
2022-07-12 16:44:05 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 0.7502
2022-07-12 16:44:38 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 0.6513
2022-07-12 16:45:11 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 0.7986
2022-07-12 16:45:44 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 0.7294
2022-07-12 16:46:17 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 0.7838
2022-07-12 16:46:49 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 0.8025
2022-07-12 16:47:22 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 0.7568
2022-07-12 16:47:55 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 0.7595
2022-07-12 16:48:28 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 0.7172
2022-07-12 16:49:01 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 0.8576
2022-07-12 16:49:34 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 0.6923
2022-07-12 16:50:07 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 0.8222
2022-07-12 16:50:40 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 0.6941
2022-07-12 16:51:13 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 0.6766
2022-07-12 16:51:47 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 0.7415
2022-07-12 16:52:20 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 0.6340
2022-07-12 16:52:53 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 0.6653
2022-07-12 16:53:26 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 0.6535
2022-07-12 16:53:59 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 0.7612
2022-07-12 16:54:32 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 0.6739
2022-07-12 16:55:05 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 0.5627
2022-07-12 16:55:38 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 0.6947
2022-07-12 16:56:12 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 0.6600
2022-07-12 16:56:45 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 0.7046
2022-07-12 16:57:18 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 0.6074
2022-07-12 16:57:51 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 0.7284
2022-07-12 16:58:24 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 0.7175
2022-07-12 16:58:57 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 0.7185
2022-07-12 16:59:30 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 0.7116
2022-07-12 17:00:03 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 0.7989
2022-07-12 17:00:36 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 0.7574
2022-07-12 17:01:09 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 0.7136
2022-07-12 17:01:42 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 0.6558
2022-07-12 17:02:15 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 0.6623
2022-07-12 17:02:48 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 0.8421
2022-07-12 17:03:22 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 0.6434
2022-07-12 17:03:55 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 0.7085
2022-07-12 17:04:28 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 0.5606
2022-07-12 17:05:02 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 0.8222
2022-07-12 17:05:35 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 0.6113
2022-07-12 17:06:08 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 0.7294
2022-07-12 17:06:41 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 0.7040
2022-07-12 17:07:14 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 0.5975
2022-07-12 17:07:47 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 0.7239
2022-07-12 17:08:20 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 0.7537
2022-07-12 17:08:53 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 0.6929
2022-07-12 17:09:27 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 0.6657
2022-07-12 17:09:59 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 0.5101
2022-07-12 17:10:00 - train: epoch 089, train_loss: 0.6985
2022-07-12 17:11:16 - eval: epoch: 089, acc1: 76.186%, acc5: 92.966%, test_loss: 0.9735, per_image_load_time: 2.187ms, per_image_inference_time: 0.571ms
2022-07-12 17:11:16 - until epoch: 089, best_acc1: 76.602%
2022-07-12 17:11:16 - epoch 090 lr: 0.001000
2022-07-12 17:11:56 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 0.7504
2022-07-12 17:12:29 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 0.7281
2022-07-12 17:13:01 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 0.6749
2022-07-12 17:13:34 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 0.6325
2022-07-12 17:14:07 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 0.7252
2022-07-12 17:14:40 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 0.8061
2022-07-12 17:15:12 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 0.7460
2022-07-12 17:15:45 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 0.6305
2022-07-12 17:16:18 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 0.6021
2022-07-12 17:16:50 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 0.6009
2022-07-12 17:17:23 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 0.7826
2022-07-12 17:17:56 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 0.6643
2022-07-12 17:18:29 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 0.8383
2022-07-12 17:19:02 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 0.5879
2022-07-12 17:19:34 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 0.8288
2022-07-12 17:20:07 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 0.6530
2022-07-12 17:20:40 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 0.6303
2022-07-12 17:21:12 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 0.6326
2022-07-12 17:21:45 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 0.5985
2022-07-12 17:22:18 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 0.7621
2022-07-12 17:22:51 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 0.8490
2022-07-12 17:23:23 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 0.6714
2022-07-12 17:23:56 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 0.7637
2022-07-12 17:24:29 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 0.7303
2022-07-12 17:25:02 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 0.7759
2022-07-12 17:25:34 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 0.7513
2022-07-12 17:26:07 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 0.5706
2022-07-12 17:26:40 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 0.6865
2022-07-12 17:27:12 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 0.6545
2022-07-12 17:27:45 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 0.6827
2022-07-12 17:28:18 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 0.6731
2022-07-12 17:28:51 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 0.6080
2022-07-12 17:29:24 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 0.7761
2022-07-12 17:29:57 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 0.5853
2022-07-12 17:30:29 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 0.6587
2022-07-12 17:31:02 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 0.6723
2022-07-12 17:31:35 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 0.6296
2022-07-12 17:32:08 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 0.6761
2022-07-12 17:32:41 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 0.5683
2022-07-12 17:33:14 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 0.7564
2022-07-12 17:33:47 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 0.8099
2022-07-12 17:34:20 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 0.7102
2022-07-12 17:34:53 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 0.7797
2022-07-12 17:35:26 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 0.6841
2022-07-12 17:35:59 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 0.6371
2022-07-12 17:36:32 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 0.6621
2022-07-12 17:37:04 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 0.6664
2022-07-12 17:37:37 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 0.6586
2022-07-12 17:38:10 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 0.6287
2022-07-12 17:38:42 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 0.7543
2022-07-12 17:38:43 - train: epoch 090, train_loss: 0.6962
2022-07-12 17:39:58 - eval: epoch: 090, acc1: 76.166%, acc5: 92.986%, test_loss: 0.9805, per_image_load_time: 1.717ms, per_image_inference_time: 0.596ms
2022-07-12 17:39:58 - until epoch: 090, best_acc1: 76.602%
2022-07-12 17:39:58 - epoch 091 lr: 0.000100
2022-07-12 17:40:37 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 0.6547
2022-07-12 17:41:10 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 0.6199
2022-07-12 17:41:43 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 0.6058
2022-07-12 17:42:15 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 0.5708
2022-07-12 17:42:48 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 0.6246
2022-07-12 17:43:20 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 0.6892
2022-07-12 17:43:52 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 0.5647
2022-07-12 17:44:25 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 0.6021
2022-07-12 17:44:57 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 0.6928
2022-07-12 17:45:29 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 0.6154
2022-07-12 17:46:02 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 0.5942
2022-07-12 17:46:34 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 0.7842
2022-07-12 17:47:07 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 0.6542
2022-07-12 17:47:39 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 0.6732
2022-07-12 17:48:12 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 0.6349
2022-07-12 17:48:44 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 0.6737
2022-07-12 17:49:17 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 0.7254
2022-07-12 17:49:50 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 0.6494
2022-07-12 17:50:23 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 0.6499
2022-07-12 17:50:55 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 0.7020
2022-07-12 17:51:28 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 0.5218
2022-07-12 17:52:00 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 0.7369
2022-07-12 17:52:33 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 0.6792
2022-07-12 17:53:05 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 0.6142
2022-07-12 17:53:38 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 0.6196
2022-07-12 17:54:11 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 0.6223
2022-07-12 17:54:43 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 0.5510
2022-07-12 17:55:16 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 0.6914
2022-07-12 17:55:49 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 0.7835
2022-07-12 17:56:22 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 0.7352
2022-07-12 17:56:54 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 0.6133
2022-07-12 17:57:27 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 0.7278
2022-07-12 17:57:59 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 0.5619
2022-07-12 17:58:32 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 0.5751
2022-07-12 17:59:04 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 0.7579
2022-07-12 17:59:37 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 0.6270
2022-07-12 18:00:10 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 0.6588
2022-07-12 18:00:43 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 0.7264
2022-07-12 18:01:15 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 0.7127
2022-07-12 18:01:48 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 0.7499
2022-07-12 18:02:21 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 0.7490
2022-07-12 18:02:54 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 0.7116
2022-07-12 18:03:27 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 0.7607
2022-07-12 18:03:59 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 0.6161
2022-07-12 18:04:32 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 0.5503
2022-07-12 18:05:05 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 0.6267
2022-07-12 18:05:38 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 0.6864
2022-07-12 18:06:11 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 0.6974
2022-07-12 18:06:43 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 0.6573
2022-07-12 18:07:16 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 0.7652
2022-07-12 18:07:17 - train: epoch 091, train_loss: 0.6679
2022-07-12 18:08:33 - eval: epoch: 091, acc1: 76.372%, acc5: 93.140%, test_loss: 0.9693, per_image_load_time: 2.347ms, per_image_inference_time: 0.590ms
2022-07-12 18:08:33 - until epoch: 091, best_acc1: 76.602%
2022-07-12 18:08:33 - epoch 092 lr: 0.000100
2022-07-12 18:09:13 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 0.6799
2022-07-12 18:09:46 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 0.7251
2022-07-12 18:10:18 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 0.6089
2022-07-12 18:10:51 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 0.5107
2022-07-12 18:11:24 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 0.7393
2022-07-12 18:11:57 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 0.6713
2022-07-12 18:12:30 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 0.6680
2022-07-12 18:13:02 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 0.7324
2022-07-12 18:13:34 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 0.6320
2022-07-12 18:14:07 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 0.8974
2022-07-12 18:14:39 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 0.5497
2022-07-12 18:15:12 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 0.5812
2022-07-12 18:15:45 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 0.6885
2022-07-12 18:16:17 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 0.7191
2022-07-12 18:16:50 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 0.5280
2022-07-12 18:17:23 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 0.7137
2022-07-12 18:17:55 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 0.6785
2022-07-12 18:18:28 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 0.5850
2022-07-12 18:19:01 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 0.6098
2022-07-12 18:19:34 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 0.5903
2022-07-12 18:20:06 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 0.6009
2022-07-12 18:20:39 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 0.6963
2022-07-12 18:21:12 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 0.6507
2022-07-12 18:21:45 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 0.5768
2022-07-12 18:22:17 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 0.5963
2022-07-12 18:22:51 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 0.7399
2022-07-12 18:23:24 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 0.6404
2022-07-12 18:23:56 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 0.5626
2022-07-12 18:24:29 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 0.6481
2022-07-12 18:25:02 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 0.5432
2022-07-12 18:25:34 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 0.5653
2022-07-12 18:26:07 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 0.5456
2022-07-12 18:26:40 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 0.7165
2022-07-12 18:27:13 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 0.7294
2022-07-12 18:27:46 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 0.5919
2022-07-12 18:28:19 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 0.6039
2022-07-12 18:28:51 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 0.5189
2022-07-12 18:29:24 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 0.8228
2022-07-12 18:29:57 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 0.6262
2022-07-12 18:30:29 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 0.7752
2022-07-12 18:31:02 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 0.6512
2022-07-12 18:31:35 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 0.6525
2022-07-12 18:32:08 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 0.7234
2022-07-12 18:32:40 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 0.5380
2022-07-12 18:33:13 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 0.6613
2022-07-12 18:33:46 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 0.5924
2022-07-12 18:34:19 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 0.4532
2022-07-12 18:34:52 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 0.5507
2022-07-12 18:35:24 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 0.7129
2022-07-12 18:35:56 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 0.8028
2022-07-12 18:35:58 - train: epoch 092, train_loss: 0.6598
2022-07-12 18:37:13 - eval: epoch: 092, acc1: 76.442%, acc5: 93.114%, test_loss: 0.9679, per_image_load_time: 1.564ms, per_image_inference_time: 0.586ms
2022-07-12 18:37:13 - until epoch: 092, best_acc1: 76.602%
2022-07-12 18:37:13 - epoch 093 lr: 0.000100
2022-07-12 18:37:53 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 0.5488
2022-07-12 18:38:25 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 0.5789
2022-07-12 18:38:58 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 0.6184
2022-07-12 18:39:30 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 0.5660
2022-07-12 18:40:03 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 0.6439
2022-07-12 18:40:36 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 0.6651
2022-07-12 18:41:08 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 0.7516
2022-07-12 18:41:41 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 0.6108
2022-07-12 18:42:14 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 0.5639
2022-07-12 18:42:46 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.5951
2022-07-12 18:43:19 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 0.5646
2022-07-12 18:43:51 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 0.5012
2022-07-12 18:44:24 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 0.6795
2022-07-12 18:44:56 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 0.6815
2022-07-12 18:45:29 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 0.8699
2022-07-12 18:46:01 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 0.7259
2022-07-12 18:46:34 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 0.5392
2022-07-12 18:47:06 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 0.6582
2022-07-12 18:47:39 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 0.6514
2022-07-12 18:48:11 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 0.5601
2022-07-12 18:48:44 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 0.5916
2022-07-12 18:49:16 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 0.8744
2022-07-12 18:49:49 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 0.6389
2022-07-12 18:50:21 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 0.5898
2022-07-12 18:50:54 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 0.6304
2022-07-12 18:51:26 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 0.7176
2022-07-12 18:51:59 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 0.5802
2022-07-12 18:52:32 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 0.5934
2022-07-12 18:53:04 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 0.6213
2022-07-12 18:53:37 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 0.6118
2022-07-12 18:54:10 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 0.7720
2022-07-12 18:54:43 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 0.6161
2022-07-12 18:55:15 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 0.6920
2022-07-12 18:55:48 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 0.8547
2022-07-12 18:56:21 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 0.5508
2022-07-12 18:56:54 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 0.8217
2022-07-12 18:57:27 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 0.6136
2022-07-12 18:58:00 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 0.4593
2022-07-12 18:58:32 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 0.7627
2022-07-12 18:59:05 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 0.8636
2022-07-12 18:59:38 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 0.6798
2022-07-12 19:00:11 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 0.7043
2022-07-12 19:00:44 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 0.7629
2022-07-12 19:01:17 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 0.6626
2022-07-12 19:01:49 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 0.5827
2022-07-12 19:02:22 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 0.5377
2022-07-12 19:02:55 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 0.7592
2022-07-12 19:03:28 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 0.7014
2022-07-12 19:04:01 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 0.7433
2022-07-12 19:04:33 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 0.6707
2022-07-12 19:04:34 - train: epoch 093, train_loss: 0.6561
2022-07-12 19:05:50 - eval: epoch: 093, acc1: 76.490%, acc5: 93.086%, test_loss: 0.9666, per_image_load_time: 2.156ms, per_image_inference_time: 0.579ms
2022-07-12 19:05:50 - until epoch: 093, best_acc1: 76.602%
2022-07-12 19:05:50 - epoch 094 lr: 0.000100
2022-07-12 19:06:30 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 0.6077
2022-07-12 19:07:02 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 0.6683
2022-07-12 19:07:35 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 0.7255
2022-07-12 19:08:08 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 0.8295
2022-07-12 19:08:41 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 0.6365
2022-07-12 19:09:13 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 0.6157
2022-07-12 19:09:46 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 0.7493
2022-07-12 19:10:19 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 0.6053
2022-07-12 19:10:52 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 0.5767
2022-07-12 19:11:25 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 0.7462
2022-07-12 19:11:57 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 0.6218
2022-07-12 19:12:30 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 0.6398
2022-07-12 19:13:03 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 0.6380
2022-07-12 19:13:36 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 0.6863
2022-07-12 19:14:08 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 0.6837
2022-07-12 19:14:41 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 0.9383
2022-07-12 19:15:14 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 0.6029
2022-07-12 19:15:47 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 0.5913
2022-07-12 19:16:20 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 0.7423
2022-07-12 19:16:53 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 0.5788
2022-07-12 19:17:26 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 0.7139
2022-07-12 19:17:59 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 0.5332
2022-07-12 19:18:32 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 0.4740
2022-07-12 19:19:05 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 0.6293
2022-07-12 19:19:38 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 0.5152
2022-07-12 19:20:11 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 0.5369
2022-07-12 19:20:44 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 0.6188
2022-07-12 19:21:17 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 0.6387
2022-07-12 19:21:50 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 0.6953
2022-07-12 19:22:22 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 0.6004
2022-07-12 19:22:55 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 0.7895
2022-07-12 19:23:28 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 0.6812
2022-07-12 19:24:01 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 0.6884
2022-07-12 19:24:34 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 0.7197
2022-07-12 19:25:07 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 0.8104
2022-07-12 19:25:40 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 0.6878
2022-07-12 19:26:12 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 0.7906
2022-07-12 19:26:45 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 0.6842
2022-07-12 19:27:18 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 0.6073
2022-07-12 19:27:51 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 0.7426
2022-07-12 19:28:23 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 0.7859
2022-07-12 19:28:56 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 0.5529
2022-07-12 19:29:29 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 0.7343
2022-07-12 19:30:02 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 0.6925
2022-07-12 19:30:35 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 0.6642
2022-07-12 19:31:08 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 0.6736
2022-07-12 19:31:41 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 0.6499
2022-07-12 19:32:13 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 0.6427
2022-07-12 19:32:46 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 0.7098
2022-07-12 19:33:18 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 0.5648
2022-07-12 19:33:20 - train: epoch 094, train_loss: 0.6547
2022-07-12 19:34:35 - eval: epoch: 094, acc1: 76.508%, acc5: 93.154%, test_loss: 0.9670, per_image_load_time: 1.990ms, per_image_inference_time: 0.574ms
2022-07-12 19:34:35 - until epoch: 094, best_acc1: 76.602%
2022-07-12 19:34:35 - epoch 095 lr: 0.000100
2022-07-12 19:35:15 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 0.4843
2022-07-12 19:35:47 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 0.7938
2022-07-12 19:36:20 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 0.6030
2022-07-12 19:36:52 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 0.6349
2022-07-12 19:37:24 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 0.7449
2022-07-12 19:37:57 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 0.6720
2022-07-12 19:38:29 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 0.7187
2022-07-12 19:39:02 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 0.7177
2022-07-12 19:39:34 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 0.8751
2022-07-12 19:40:06 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 0.7043
2022-07-12 19:40:38 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 0.5398
2022-07-12 19:41:11 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 0.5100
2022-07-12 19:41:44 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 0.6485
2022-07-12 19:42:16 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 0.6913
2022-07-12 19:42:49 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 0.6989
2022-07-12 19:43:21 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.4022
2022-07-12 19:43:54 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 0.8311
2022-07-12 19:44:26 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 0.6877
2022-07-12 19:44:59 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 0.5831
2022-07-12 19:45:32 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 0.6419
2022-07-12 19:46:04 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 0.5707
2022-07-12 19:46:37 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 0.5662
2022-07-12 19:47:10 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 0.6354
2022-07-12 19:47:43 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 0.6676
2022-07-12 19:48:15 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 0.6073
2022-07-12 19:48:48 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 0.6639
2022-07-12 19:49:20 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 0.6894
2022-07-12 19:49:53 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 0.6491
2022-07-12 19:50:26 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 0.5814
2022-07-12 19:50:58 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 0.7276
2022-07-12 19:51:30 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 0.8070
2022-07-12 19:52:03 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 0.5803
2022-07-12 19:52:36 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 0.7288
2022-07-12 19:53:09 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 0.7035
2022-07-12 19:53:41 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 0.6218
2022-07-12 19:54:13 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 0.6039
2022-07-12 19:54:46 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 0.6588
2022-07-12 19:55:19 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 0.4984
2022-07-12 19:55:51 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 0.7227
2022-07-12 19:56:23 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 0.5046
2022-07-12 19:56:56 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 0.6740
2022-07-12 19:57:28 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 0.5778
2022-07-12 19:58:01 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 0.6211
2022-07-12 19:58:33 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 0.7494
2022-07-12 19:59:06 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 0.5555
2022-07-12 19:59:38 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 0.6323
2022-07-12 20:00:11 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 0.6463
2022-07-12 20:00:43 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 0.7785
2022-07-12 20:01:16 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 0.6556
2022-07-12 20:01:48 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 0.4952
2022-07-12 20:01:49 - train: epoch 095, train_loss: 0.6542
2022-07-12 20:03:04 - eval: epoch: 095, acc1: 76.490%, acc5: 93.108%, test_loss: 0.9683, per_image_load_time: 2.224ms, per_image_inference_time: 0.596ms
2022-07-12 20:03:05 - until epoch: 095, best_acc1: 76.602%
2022-07-12 20:03:05 - epoch 096 lr: 0.000100
2022-07-12 20:03:44 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 0.6774
2022-07-12 20:04:17 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 0.7933
2022-07-12 20:04:49 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 0.6835
2022-07-12 20:05:22 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 0.5184
2022-07-12 20:05:55 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 0.5879
2022-07-12 20:06:28 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 0.7153
2022-07-12 20:07:00 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 0.5005
2022-07-12 20:07:33 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 0.6339
2022-07-12 20:08:05 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 0.5446
2022-07-12 20:08:38 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 0.6322
2022-07-12 20:09:11 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 0.6549
2022-07-12 20:09:44 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 0.6279
2022-07-12 20:10:16 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 0.6045
2022-07-12 20:10:49 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 0.6138
2022-07-12 20:11:22 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 0.5852
2022-07-12 20:11:55 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 0.4696
2022-07-12 20:12:28 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 0.6827
2022-07-12 20:13:00 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 0.7255
2022-07-12 20:13:33 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 0.7405
2022-07-12 20:14:06 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 0.6037
2022-07-12 20:14:39 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 0.6390
2022-07-12 20:15:12 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.5117
2022-07-12 20:15:44 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 0.5047
2022-07-12 20:16:16 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 0.5642
2022-07-12 20:16:49 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 0.4984
2022-07-12 20:17:22 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 0.6853
2022-07-12 20:17:54 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 0.6633
2022-07-12 20:18:27 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 0.7359
2022-07-12 20:19:00 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 0.6407
2022-07-12 20:19:33 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 0.6584
2022-07-12 20:20:06 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 0.6135
2022-07-12 20:20:38 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 0.6371
2022-07-12 20:21:11 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 0.7903
2022-07-12 20:21:44 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 0.4519
2022-07-12 20:22:16 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 0.5195
2022-07-12 20:22:49 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 0.5800
2022-07-12 20:23:22 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 0.6811
2022-07-12 20:23:54 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 0.6868
2022-07-12 20:24:27 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 0.6048
2022-07-12 20:25:00 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 0.4918
2022-07-12 20:25:33 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 0.6242
2022-07-12 20:26:06 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 0.7040
2022-07-12 20:26:39 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.4075
2022-07-12 20:27:12 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 0.6558
2022-07-12 20:27:44 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 0.5220
2022-07-12 20:28:17 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 0.6651
2022-07-12 20:28:50 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 0.6290
2022-07-12 20:29:23 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 0.6744
2022-07-12 20:29:55 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 0.7646
2022-07-12 20:30:27 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 0.5986
2022-07-12 20:30:29 - train: epoch 096, train_loss: 0.6496
2022-07-12 20:31:44 - eval: epoch: 096, acc1: 76.442%, acc5: 93.152%, test_loss: 0.9671, per_image_load_time: 2.044ms, per_image_inference_time: 0.583ms
2022-07-12 20:31:44 - until epoch: 096, best_acc1: 76.602%
2022-07-12 20:31:44 - epoch 097 lr: 0.000100
2022-07-12 20:32:23 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 0.7271
2022-07-12 20:32:56 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 0.5254
2022-07-12 20:33:28 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 0.7294
2022-07-12 20:34:00 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 0.8929
2022-07-12 20:34:32 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 0.6303
2022-07-12 20:35:04 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 0.7875
2022-07-12 20:35:36 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 0.7007
2022-07-12 20:36:08 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.6207
2022-07-12 20:36:40 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 0.5843
2022-07-12 20:37:12 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 0.5225
2022-07-12 20:37:44 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 0.5866
2022-07-12 20:38:16 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 0.5518
2022-07-12 20:38:48 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 0.5081
2022-07-12 20:39:21 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 0.6393
2022-07-12 20:39:53 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 0.7278
2022-07-12 20:40:25 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 0.5735
2022-07-12 20:40:58 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 0.6693
2022-07-12 20:41:30 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 0.6603
2022-07-12 20:42:02 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 0.6290
2022-07-12 20:42:34 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 0.6192
2022-07-12 20:43:06 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 0.7653
2022-07-12 20:43:39 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 0.7806
2022-07-12 20:44:11 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 0.5467
2022-07-12 20:44:44 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 0.6479
2022-07-12 20:45:16 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 0.7646
2022-07-12 20:45:49 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 0.7107
2022-07-12 20:46:21 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 0.5524
2022-07-12 20:46:54 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 0.5688
2022-07-12 20:47:27 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 0.7300
2022-07-12 20:48:00 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 0.6867
2022-07-12 20:48:32 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 0.6417
2022-07-12 20:49:05 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 0.7376
2022-07-12 20:49:38 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 0.7232
2022-07-12 20:50:10 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 0.7510
2022-07-12 20:50:43 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 0.7452
2022-07-12 20:51:16 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 0.6012
2022-07-12 20:51:48 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 0.5278
2022-07-12 20:52:20 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 0.5669
2022-07-12 20:52:53 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 0.6669
2022-07-12 20:53:25 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 0.5664
2022-07-12 20:53:58 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 0.5815
2022-07-12 20:54:31 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 0.6638
2022-07-12 20:55:04 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 0.5333
2022-07-12 20:55:36 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 0.5955
2022-07-12 20:56:09 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 0.5706
2022-07-12 20:56:42 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 0.7941
2022-07-12 20:57:14 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 0.6828
2022-07-12 20:57:47 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 0.6483
2022-07-12 20:58:20 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 0.7940
2022-07-12 20:58:52 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 0.6821
2022-07-12 20:58:54 - train: epoch 097, train_loss: 0.6503
2022-07-12 21:00:09 - eval: epoch: 097, acc1: 76.562%, acc5: 93.104%, test_loss: 0.9649, per_image_load_time: 2.163ms, per_image_inference_time: 0.565ms
2022-07-12 21:00:09 - until epoch: 097, best_acc1: 76.602%
2022-07-12 21:00:09 - epoch 098 lr: 0.000100
2022-07-12 21:00:49 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 0.6664
2022-07-12 21:01:22 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 0.6271
2022-07-12 21:01:54 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 0.8362
2022-07-12 21:02:27 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 0.5238
2022-07-12 21:02:59 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 0.5983
2022-07-12 21:03:32 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 0.6636
2022-07-12 21:04:04 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 0.5511
2022-07-12 21:04:36 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 0.7402
2022-07-12 21:05:09 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 0.6490
2022-07-12 21:05:42 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 0.5738
2022-07-12 21:06:14 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 0.5080
2022-07-12 21:06:47 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 0.5598
2022-07-12 21:07:20 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 0.6863
2022-07-12 21:07:52 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 0.6616
2022-07-12 21:08:25 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 0.5411
2022-07-12 21:08:58 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 0.6447
2022-07-12 21:09:30 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 0.7173
2022-07-12 21:10:03 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 0.5464
2022-07-12 21:10:35 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 0.6126
2022-07-12 21:11:08 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 0.7603
2022-07-12 21:11:41 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 0.5767
2022-07-12 21:12:13 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 0.5772
2022-07-12 21:12:46 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 0.6644
2022-07-12 21:13:19 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 0.5556
2022-07-12 21:13:52 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 0.7441
2022-07-12 21:14:25 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 0.5691
2022-07-12 21:14:58 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 0.7130
2022-07-12 21:15:30 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 0.5245
2022-07-12 21:16:03 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 0.5702
2022-07-12 21:16:36 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 0.6366
2022-07-12 21:17:09 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 0.5122
2022-07-12 21:17:41 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 0.5184
2022-07-12 21:18:14 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 0.4885
2022-07-12 21:18:46 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 0.6429
2022-07-12 21:19:19 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 0.6607
2022-07-12 21:19:51 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 0.8533
2022-07-12 21:20:24 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 0.6689
2022-07-12 21:20:57 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 0.6834
2022-07-12 21:21:30 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 0.5837
2022-07-12 21:22:02 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 0.7265
2022-07-12 21:22:35 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 0.7444
2022-07-12 21:23:08 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 0.6196
2022-07-12 21:23:41 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 0.5321
2022-07-12 21:24:14 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 0.7304
2022-07-12 21:24:46 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 0.7178
2022-07-12 21:25:19 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 0.7644
2022-07-12 21:25:52 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 0.6850
2022-07-12 21:26:25 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 0.4240
2022-07-12 21:26:58 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 0.6263
2022-07-12 21:27:30 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 0.7537
2022-07-12 21:27:32 - train: epoch 098, train_loss: 0.6475
2022-07-12 21:28:47 - eval: epoch: 098, acc1: 76.494%, acc5: 93.104%, test_loss: 0.9655, per_image_load_time: 2.174ms, per_image_inference_time: 0.589ms
2022-07-12 21:28:47 - until epoch: 098, best_acc1: 76.602%
2022-07-12 21:28:47 - epoch 099 lr: 0.000100
2022-07-12 21:29:27 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 0.4551
2022-07-12 21:30:00 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 0.5885
2022-07-12 21:30:33 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 0.6380
2022-07-12 21:31:06 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 0.6637
2022-07-12 21:31:39 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 0.7049
2022-07-12 21:32:12 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 0.6145
2022-07-12 21:32:45 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 0.6867
2022-07-12 21:33:18 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 0.6659
2022-07-12 21:33:51 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 0.6222
2022-07-12 21:34:23 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 0.6695
2022-07-12 21:34:56 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 0.6276
2022-07-12 21:35:29 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 0.6529
2022-07-12 21:36:02 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 0.6761
2022-07-12 21:36:35 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 0.6961
2022-07-12 21:37:07 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 0.5536
2022-07-12 21:37:40 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 0.9154
2022-07-12 21:38:13 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 0.5551
2022-07-12 21:38:45 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 0.6382
2022-07-12 21:39:18 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 0.6397
2022-07-12 21:39:51 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 0.5798
2022-07-12 21:40:24 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 0.5077
2022-07-12 21:40:57 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 0.6902
2022-07-12 21:41:30 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 0.7236
2022-07-12 21:42:03 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 0.6592
2022-07-12 21:42:36 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 0.5631
2022-07-12 21:43:09 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 0.5791
2022-07-12 21:43:42 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 0.5962
2022-07-12 21:44:15 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 0.7773
2022-07-12 21:44:48 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 0.5873
2022-07-12 21:45:21 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 0.6963
2022-07-12 21:45:54 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 0.5535
2022-07-12 21:46:26 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 0.7178
2022-07-12 21:47:00 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 0.5427
2022-07-12 21:47:33 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 0.6551
2022-07-12 21:48:05 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 0.7545
2022-07-12 21:48:38 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 0.6153
2022-07-12 21:49:11 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 0.5067
2022-07-12 21:49:44 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 0.7880
2022-07-12 21:50:17 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 0.6899
2022-07-12 21:50:50 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 0.7224
2022-07-12 21:51:23 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 0.5726
2022-07-12 21:51:56 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 0.5425
2022-07-12 21:52:29 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 0.5931
2022-07-12 21:53:02 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 0.7210
2022-07-12 21:53:35 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 0.6787
2022-07-12 21:54:08 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 0.6935
2022-07-12 21:54:42 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 0.5423
2022-07-12 21:55:15 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 0.8060
2022-07-12 21:55:47 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 0.6397
2022-07-12 21:56:20 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 0.5826
2022-07-12 21:56:21 - train: epoch 099, train_loss: 0.6482
2022-07-12 21:57:37 - eval: epoch: 099, acc1: 76.524%, acc5: 93.108%, test_loss: 0.9666, per_image_load_time: 2.310ms, per_image_inference_time: 0.582ms
2022-07-12 21:57:37 - until epoch: 099, best_acc1: 76.602%
2022-07-12 21:57:37 - epoch 100 lr: 0.000100
2022-07-12 21:58:16 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 0.6236
2022-07-12 21:58:49 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 0.6907
2022-07-12 21:59:21 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 0.4902
2022-07-12 21:59:54 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 0.4580
2022-07-12 22:00:26 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 0.7360
2022-07-12 22:00:58 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 0.8816
2022-07-12 22:01:31 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 0.5906
2022-07-12 22:02:03 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 0.6721
2022-07-12 22:02:36 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 0.5041
2022-07-12 22:03:08 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 0.6061
2022-07-12 22:03:41 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 0.5821
2022-07-12 22:04:13 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 0.6628
2022-07-12 22:04:46 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 0.6766
2022-07-12 22:05:18 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 0.7331
2022-07-12 22:05:51 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 0.7015
2022-07-12 22:06:24 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 0.5513
2022-07-12 22:06:56 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 0.7519
2022-07-12 22:07:29 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 0.6824
2022-07-12 22:08:02 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 0.6017
2022-07-12 22:08:34 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 0.5595
2022-07-12 22:09:07 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 0.5204
2022-07-12 22:09:39 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 0.6755
2022-07-12 22:10:12 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 0.5992
2022-07-12 22:10:45 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 0.5793
2022-07-12 22:11:18 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 0.5760
2022-07-12 22:11:51 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 0.7130
2022-07-12 22:12:23 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 0.5738
2022-07-12 22:12:56 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 0.6022
2022-07-12 22:13:29 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 0.6810
2022-07-12 22:14:01 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 0.5573
2022-07-12 22:14:34 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 0.5607
2022-07-12 22:15:07 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 0.6823
2022-07-12 22:15:40 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 0.7534
2022-07-12 22:16:12 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 0.7115
2022-07-12 22:16:45 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 0.5281
2022-07-12 22:17:17 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 0.6408
2022-07-12 22:17:50 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 0.5877
2022-07-12 22:18:22 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 0.6772
2022-07-12 22:18:55 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 0.6868
2022-07-12 22:19:28 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 0.5455
2022-07-12 22:20:00 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 0.7338
2022-07-12 22:20:32 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 0.6379
2022-07-12 22:21:05 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 0.6572
2022-07-12 22:21:37 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 0.7491
2022-07-12 22:22:10 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 0.6628
2022-07-12 22:22:43 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 0.5346
2022-07-12 22:23:16 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 0.6240
2022-07-12 22:23:48 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 0.4869
2022-07-12 22:24:22 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 0.6111
2022-07-12 22:24:54 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 0.7330
2022-07-12 22:24:56 - train: epoch 100, train_loss: 0.6469
2022-07-12 22:26:10 - eval: epoch: 100, acc1: 76.408%, acc5: 93.168%, test_loss: 0.9689, per_image_load_time: 2.199ms, per_image_inference_time: 0.591ms
2022-07-12 22:26:11 - until epoch: 100, best_acc1: 76.602%
2022-07-12 22:26:11 - train done. model: darknet53, train time: 47.780 hours, best_acc1: 76.602%
