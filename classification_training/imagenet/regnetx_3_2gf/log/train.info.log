2022-08-09 00:00:04 - train: epoch 0089, iter [03800, 05004], lr: 0.006830, loss: 0.8233
2022-08-09 00:01:38 - train: epoch 0089, iter [03900, 05004], lr: 0.006806, loss: 0.7548
2022-08-09 00:03:12 - train: epoch 0089, iter [04000, 05004], lr: 0.006782, loss: 0.9958
2022-08-09 00:04:46 - train: epoch 0089, iter [04100, 05004], lr: 0.006758, loss: 0.8675
2022-08-09 00:06:20 - train: epoch 0089, iter [04200, 05004], lr: 0.006734, loss: 0.7363
2022-08-09 00:07:54 - train: epoch 0089, iter [04300, 05004], lr: 0.006710, loss: 0.8040
2022-08-09 00:09:28 - train: epoch 0089, iter [04400, 05004], lr: 0.006686, loss: 0.9810
2022-08-09 00:11:02 - train: epoch 0089, iter [04500, 05004], lr: 0.006663, loss: 0.6611
2022-08-09 00:12:37 - train: epoch 0089, iter [04600, 05004], lr: 0.006639, loss: 0.9346
2022-08-09 00:14:11 - train: epoch 0089, iter [04700, 05004], lr: 0.006615, loss: 0.9854
2022-08-09 00:15:45 - train: epoch 0089, iter [04800, 05004], lr: 0.006592, loss: 0.9396
2022-08-09 00:17:19 - train: epoch 0089, iter [04900, 05004], lr: 0.006568, loss: 0.8170
2022-08-09 00:18:53 - train: epoch 0089, iter [05000, 05004], lr: 0.006544, loss: 0.6799
2022-08-09 00:18:57 - train: epoch 089, train_loss: 0.8286
2022-08-09 00:21:03 - eval: epoch: 089, acc1: 76.310%, acc5: 93.138%, test_loss: 0.9569, per_image_load_time: 1.778ms, per_image_inference_time: 1.221ms
2022-08-09 00:21:03 - until epoch: 089, best_acc1: 76.310%
2022-08-09 00:21:03 - epoch 090 lr: 0.006543
2022-08-09 00:22:46 - train: epoch 0090, iter [00100, 05004], lr: 0.006520, loss: 0.7616
2022-08-09 00:24:20 - train: epoch 0090, iter [00200, 05004], lr: 0.006497, loss: 0.8680
2022-08-09 00:25:54 - train: epoch 0090, iter [00300, 05004], lr: 0.006473, loss: 0.7615
2022-08-09 00:27:28 - train: epoch 0090, iter [00400, 05004], lr: 0.006450, loss: 0.8345
2022-08-09 00:29:02 - train: epoch 0090, iter [00500, 05004], lr: 0.006426, loss: 0.8253
2022-08-09 00:30:36 - train: epoch 0090, iter [00600, 05004], lr: 0.006403, loss: 1.0260
2022-08-09 00:32:10 - train: epoch 0090, iter [00700, 05004], lr: 0.006380, loss: 0.6845
2022-08-09 00:33:44 - train: epoch 0090, iter [00800, 05004], lr: 0.006357, loss: 0.8154
2022-08-09 00:35:18 - train: epoch 0090, iter [00900, 05004], lr: 0.006334, loss: 0.7892
2022-08-09 00:36:52 - train: epoch 0090, iter [01000, 05004], lr: 0.006310, loss: 0.8347
2022-08-09 00:38:26 - train: epoch 0090, iter [01100, 05004], lr: 0.006287, loss: 0.8023
2022-08-09 00:40:00 - train: epoch 0090, iter [01200, 05004], lr: 0.006264, loss: 0.7501
2022-08-09 00:41:34 - train: epoch 0090, iter [01300, 05004], lr: 0.006241, loss: 0.7091
2022-08-09 00:43:08 - train: epoch 0090, iter [01400, 05004], lr: 0.006218, loss: 0.9334
2022-08-09 00:44:42 - train: epoch 0090, iter [01500, 05004], lr: 0.006195, loss: 0.9625
2022-08-09 00:46:16 - train: epoch 0090, iter [01600, 05004], lr: 0.006173, loss: 0.7857
2022-08-09 00:47:50 - train: epoch 0090, iter [01700, 05004], lr: 0.006150, loss: 0.6483
2022-08-09 00:49:24 - train: epoch 0090, iter [01800, 05004], lr: 0.006127, loss: 0.7903
2022-08-09 00:50:58 - train: epoch 0090, iter [01900, 05004], lr: 0.006104, loss: 0.7786
2022-08-09 00:52:32 - train: epoch 0090, iter [02000, 05004], lr: 0.006081, loss: 0.8976
2022-08-09 00:54:06 - train: epoch 0090, iter [02100, 05004], lr: 0.006059, loss: 0.8612
2022-08-09 00:55:40 - train: epoch 0090, iter [02200, 05004], lr: 0.006036, loss: 0.8239
2022-08-09 00:57:14 - train: epoch 0090, iter [02300, 05004], lr: 0.006014, loss: 0.8689
2022-08-09 00:58:48 - train: epoch 0090, iter [02400, 05004], lr: 0.005991, loss: 0.7543
2022-08-09 01:00:22 - train: epoch 0090, iter [02500, 05004], lr: 0.005969, loss: 0.6545
2022-08-09 01:01:56 - train: epoch 0090, iter [02600, 05004], lr: 0.005946, loss: 0.8393
2022-08-09 01:03:30 - train: epoch 0090, iter [02700, 05004], lr: 0.005924, loss: 0.8118
2022-08-09 01:05:04 - train: epoch 0090, iter [02800, 05004], lr: 0.005901, loss: 0.9681
2022-08-09 01:06:38 - train: epoch 0090, iter [02900, 05004], lr: 0.005879, loss: 0.6510
2022-08-09 01:08:12 - train: epoch 0090, iter [03000, 05004], lr: 0.005857, loss: 0.6958
2022-08-09 01:09:46 - train: epoch 0090, iter [03100, 05004], lr: 0.005834, loss: 0.7614
2022-08-09 01:11:20 - train: epoch 0090, iter [03200, 05004], lr: 0.005812, loss: 0.7603
2022-08-09 01:12:54 - train: epoch 0090, iter [03300, 05004], lr: 0.005790, loss: 0.9463
2022-08-09 01:14:28 - train: epoch 0090, iter [03400, 05004], lr: 0.005768, loss: 0.7709
2022-08-09 01:16:02 - train: epoch 0090, iter [03500, 05004], lr: 0.005746, loss: 0.6885
2022-08-09 01:17:36 - train: epoch 0090, iter [03600, 05004], lr: 0.005724, loss: 0.8535
2022-08-09 01:19:10 - train: epoch 0090, iter [03700, 05004], lr: 0.005702, loss: 0.8556
2022-08-09 01:20:44 - train: epoch 0090, iter [03800, 05004], lr: 0.005680, loss: 0.7557
2022-08-09 01:22:18 - train: epoch 0090, iter [03900, 05004], lr: 0.005658, loss: 0.6751
2022-08-09 01:23:52 - train: epoch 0090, iter [04000, 05004], lr: 0.005636, loss: 0.7668
2022-08-09 01:25:26 - train: epoch 0090, iter [04100, 05004], lr: 0.005614, loss: 0.9535
2022-08-09 01:27:00 - train: epoch 0090, iter [04200, 05004], lr: 0.005592, loss: 0.9297
2022-08-09 01:28:34 - train: epoch 0090, iter [04300, 05004], lr: 0.005570, loss: 0.7950
2022-08-09 01:30:09 - train: epoch 0090, iter [04400, 05004], lr: 0.005549, loss: 0.8805
2022-08-09 01:31:43 - train: epoch 0090, iter [04500, 05004], lr: 0.005527, loss: 0.8405
2022-08-09 01:33:17 - train: epoch 0090, iter [04600, 05004], lr: 0.005505, loss: 0.7282
2022-08-09 01:34:51 - train: epoch 0090, iter [04700, 05004], lr: 0.005484, loss: 0.7041
2022-08-09 01:36:25 - train: epoch 0090, iter [04800, 05004], lr: 0.005462, loss: 0.8260
2022-08-09 01:37:59 - train: epoch 0090, iter [04900, 05004], lr: 0.005441, loss: 0.6676
2022-08-09 01:39:33 - train: epoch 0090, iter [05000, 05004], lr: 0.005419, loss: 0.7728
2022-08-09 01:39:38 - train: epoch 090, train_loss: 0.8025
2022-08-09 01:41:40 - eval: epoch: 090, acc1: 76.642%, acc5: 93.196%, test_loss: 0.9586, per_image_load_time: 3.518ms, per_image_inference_time: 1.187ms
2022-08-09 01:41:40 - until epoch: 090, best_acc1: 76.642%
2022-08-09 01:41:40 - epoch 091 lr: 0.005418
2022-08-09 01:43:24 - train: epoch 0091, iter [00100, 05004], lr: 0.005397, loss: 0.7891
2022-08-09 01:44:58 - train: epoch 0091, iter [00200, 05004], lr: 0.005375, loss: 0.6851
2022-08-09 01:46:32 - train: epoch 0091, iter [00300, 05004], lr: 0.005354, loss: 0.8122
2022-08-09 01:48:06 - train: epoch 0091, iter [00400, 05004], lr: 0.005333, loss: 0.9297
2022-08-09 01:49:40 - train: epoch 0091, iter [00500, 05004], lr: 0.005312, loss: 0.7217
2022-08-09 01:51:14 - train: epoch 0091, iter [00600, 05004], lr: 0.005290, loss: 0.7935
2022-08-09 01:52:48 - train: epoch 0091, iter [00700, 05004], lr: 0.005269, loss: 0.9519
2022-08-09 01:54:21 - train: epoch 0091, iter [00800, 05004], lr: 0.005248, loss: 0.6920
2022-08-09 01:55:56 - train: epoch 0091, iter [00900, 05004], lr: 0.005227, loss: 0.8574
2022-08-09 01:57:30 - train: epoch 0091, iter [01000, 05004], lr: 0.005206, loss: 0.6659
2022-08-09 01:59:04 - train: epoch 0091, iter [01100, 05004], lr: 0.005185, loss: 0.5646
2022-08-09 02:00:38 - train: epoch 0091, iter [01200, 05004], lr: 0.005164, loss: 0.8571
2022-08-09 02:02:12 - train: epoch 0091, iter [01300, 05004], lr: 0.005143, loss: 0.6383
2022-08-09 02:03:46 - train: epoch 0091, iter [01400, 05004], lr: 0.005122, loss: 0.7170
2022-08-09 02:05:20 - train: epoch 0091, iter [01500, 05004], lr: 0.005101, loss: 0.8008
2022-08-09 02:06:54 - train: epoch 0091, iter [01600, 05004], lr: 0.005080, loss: 0.6812
2022-08-09 02:08:28 - train: epoch 0091, iter [01700, 05004], lr: 0.005059, loss: 0.6640
2022-08-09 02:10:02 - train: epoch 0091, iter [01800, 05004], lr: 0.005039, loss: 0.8647
2022-08-09 02:11:35 - train: epoch 0091, iter [01900, 05004], lr: 0.005018, loss: 0.8619
2022-08-09 02:13:09 - train: epoch 0091, iter [02000, 05004], lr: 0.004997, loss: 0.6400
2022-08-09 02:14:43 - train: epoch 0091, iter [02100, 05004], lr: 0.004977, loss: 0.6918
2022-08-09 02:16:17 - train: epoch 0091, iter [02200, 05004], lr: 0.004956, loss: 0.7598
2022-08-09 02:17:51 - train: epoch 0091, iter [02300, 05004], lr: 0.004936, loss: 0.8016
2022-08-09 02:19:25 - train: epoch 0091, iter [02400, 05004], lr: 0.004915, loss: 0.7560
2022-08-09 02:20:59 - train: epoch 0091, iter [02500, 05004], lr: 0.004895, loss: 0.8703
2022-08-09 02:22:33 - train: epoch 0091, iter [02600, 05004], lr: 0.004874, loss: 0.7885
2022-08-09 02:24:07 - train: epoch 0091, iter [02700, 05004], lr: 0.004854, loss: 0.6099
2022-08-09 02:25:41 - train: epoch 0091, iter [02800, 05004], lr: 0.004834, loss: 0.8298
2022-08-09 02:27:15 - train: epoch 0091, iter [02900, 05004], lr: 0.004813, loss: 0.9169
2022-08-09 02:28:49 - train: epoch 0091, iter [03000, 05004], lr: 0.004793, loss: 0.9164
2022-08-09 02:30:23 - train: epoch 0091, iter [03100, 05004], lr: 0.004773, loss: 0.7257
2022-08-09 02:31:57 - train: epoch 0091, iter [03200, 05004], lr: 0.004753, loss: 0.8063
2022-08-09 02:33:31 - train: epoch 0091, iter [03300, 05004], lr: 0.004733, loss: 0.7552
2022-08-09 02:35:05 - train: epoch 0091, iter [03400, 05004], lr: 0.004713, loss: 0.8676
2022-08-09 02:36:39 - train: epoch 0091, iter [03500, 05004], lr: 0.004693, loss: 0.7392
2022-08-09 02:38:13 - train: epoch 0091, iter [03600, 05004], lr: 0.004673, loss: 0.6632
2022-08-09 02:39:47 - train: epoch 0091, iter [03700, 05004], lr: 0.004653, loss: 0.7512
2022-08-09 02:41:21 - train: epoch 0091, iter [03800, 05004], lr: 0.004633, loss: 0.8901
2022-08-09 02:42:55 - train: epoch 0091, iter [03900, 05004], lr: 0.004613, loss: 0.6650
2022-08-09 02:44:29 - train: epoch 0091, iter [04000, 05004], lr: 0.004593, loss: 0.6870
2022-08-09 02:46:03 - train: epoch 0091, iter [04100, 05004], lr: 0.004573, loss: 0.8931
2022-08-09 02:47:37 - train: epoch 0091, iter [04200, 05004], lr: 0.004554, loss: 0.7434
2022-08-09 02:49:11 - train: epoch 0091, iter [04300, 05004], lr: 0.004534, loss: 0.6462
2022-08-09 02:50:45 - train: epoch 0091, iter [04400, 05004], lr: 0.004514, loss: 0.6435
2022-08-09 02:52:19 - train: epoch 0091, iter [04500, 05004], lr: 0.004495, loss: 0.9296
2022-08-09 02:53:53 - train: epoch 0091, iter [04600, 05004], lr: 0.004475, loss: 0.7939
2022-08-09 02:55:27 - train: epoch 0091, iter [04700, 05004], lr: 0.004456, loss: 0.8574
2022-08-09 02:57:01 - train: epoch 0091, iter [04800, 05004], lr: 0.004436, loss: 0.8525
2022-08-09 02:58:35 - train: epoch 0091, iter [04900, 05004], lr: 0.004417, loss: 0.7448
2022-08-09 03:00:09 - train: epoch 0091, iter [05000, 05004], lr: 0.004397, loss: 0.9308
2022-08-09 03:00:14 - train: epoch 091, train_loss: 0.7809
2022-08-09 03:02:18 - eval: epoch: 091, acc1: 76.812%, acc5: 93.308%, test_loss: 0.9465, per_image_load_time: 2.550ms, per_image_inference_time: 1.166ms
2022-08-09 03:02:19 - until epoch: 091, best_acc1: 76.812%
2022-08-09 03:02:19 - epoch 092 lr: 0.004396
2022-08-09 03:04:02 - train: epoch 0092, iter [00100, 05004], lr: 0.004377, loss: 0.6523
2022-08-09 03:05:36 - train: epoch 0092, iter [00200, 05004], lr: 0.004358, loss: 0.7182
2022-08-09 03:07:10 - train: epoch 0092, iter [00300, 05004], lr: 0.004338, loss: 0.8372
2022-08-09 03:08:44 - train: epoch 0092, iter [00400, 05004], lr: 0.004319, loss: 0.5333
2022-08-09 03:10:18 - train: epoch 0092, iter [00500, 05004], lr: 0.004300, loss: 0.7240
2022-08-09 03:11:52 - train: epoch 0092, iter [00600, 05004], lr: 0.004281, loss: 0.7995
2022-08-09 03:13:25 - train: epoch 0092, iter [00700, 05004], lr: 0.004262, loss: 0.6643
2022-08-09 03:14:59 - train: epoch 0092, iter [00800, 05004], lr: 0.004243, loss: 0.8284
2022-08-09 03:16:33 - train: epoch 0092, iter [00900, 05004], lr: 0.004224, loss: 0.7944
2022-08-09 03:18:07 - train: epoch 0092, iter [01000, 05004], lr: 0.004205, loss: 0.6478
2022-08-09 03:19:41 - train: epoch 0092, iter [01100, 05004], lr: 0.004186, loss: 0.7707
2022-08-09 03:21:15 - train: epoch 0092, iter [01200, 05004], lr: 0.004167, loss: 0.7337
2022-08-09 03:22:49 - train: epoch 0092, iter [01300, 05004], lr: 0.004148, loss: 0.6125
2022-08-09 03:24:23 - train: epoch 0092, iter [01400, 05004], lr: 0.004129, loss: 0.6739
2022-08-09 03:25:57 - train: epoch 0092, iter [01500, 05004], lr: 0.004110, loss: 0.7063
2022-08-09 03:27:30 - train: epoch 0092, iter [01600, 05004], lr: 0.004092, loss: 0.8005
2022-08-09 03:29:04 - train: epoch 0092, iter [01700, 05004], lr: 0.004073, loss: 0.8634
2022-08-09 03:30:38 - train: epoch 0092, iter [01800, 05004], lr: 0.004054, loss: 0.7459
2022-08-09 03:32:12 - train: epoch 0092, iter [01900, 05004], lr: 0.004036, loss: 0.6462
2022-08-09 03:33:46 - train: epoch 0092, iter [02000, 05004], lr: 0.004017, loss: 0.6217
2022-08-09 03:35:20 - train: epoch 0092, iter [02100, 05004], lr: 0.003999, loss: 0.8433
2022-08-09 03:36:54 - train: epoch 0092, iter [02200, 05004], lr: 0.003980, loss: 0.7474
2022-08-09 03:38:28 - train: epoch 0092, iter [02300, 05004], lr: 0.003962, loss: 0.6921
2022-08-09 03:40:02 - train: epoch 0092, iter [02400, 05004], lr: 0.003943, loss: 0.6489
2022-08-09 03:41:36 - train: epoch 0092, iter [02500, 05004], lr: 0.003925, loss: 0.7895
2022-08-09 03:43:10 - train: epoch 0092, iter [02600, 05004], lr: 0.003907, loss: 0.9477
2022-08-09 03:44:44 - train: epoch 0092, iter [02700, 05004], lr: 0.003888, loss: 0.8569
2022-08-09 03:46:17 - train: epoch 0092, iter [02800, 05004], lr: 0.003870, loss: 0.7968
2022-08-09 03:47:51 - train: epoch 0092, iter [02900, 05004], lr: 0.003852, loss: 0.7637
2022-08-09 03:49:25 - train: epoch 0092, iter [03000, 05004], lr: 0.003834, loss: 0.8520
2022-08-09 03:50:59 - train: epoch 0092, iter [03100, 05004], lr: 0.003816, loss: 0.7785
2022-08-09 03:52:33 - train: epoch 0092, iter [03200, 05004], lr: 0.003798, loss: 0.8384
2022-08-09 03:54:07 - train: epoch 0092, iter [03300, 05004], lr: 0.003780, loss: 0.8224
2022-08-09 03:55:41 - train: epoch 0092, iter [03400, 05004], lr: 0.003762, loss: 0.9186
2022-08-09 03:57:15 - train: epoch 0092, iter [03500, 05004], lr: 0.003744, loss: 0.7209
2022-08-09 03:58:49 - train: epoch 0092, iter [03600, 05004], lr: 0.003726, loss: 0.7475
2022-08-09 04:00:23 - train: epoch 0092, iter [03700, 05004], lr: 0.003708, loss: 0.7534
2022-08-09 04:01:57 - train: epoch 0092, iter [03800, 05004], lr: 0.003690, loss: 0.7732
2022-08-09 04:03:31 - train: epoch 0092, iter [03900, 05004], lr: 0.003672, loss: 0.6733
2022-08-09 04:05:05 - train: epoch 0092, iter [04000, 05004], lr: 0.003655, loss: 0.6445
2022-08-09 04:06:39 - train: epoch 0092, iter [04100, 05004], lr: 0.003637, loss: 0.6265
2022-08-09 04:08:13 - train: epoch 0092, iter [04200, 05004], lr: 0.003619, loss: 0.8607
2022-08-09 04:09:47 - train: epoch 0092, iter [04300, 05004], lr: 0.003602, loss: 0.7426
2022-08-09 04:11:21 - train: epoch 0092, iter [04400, 05004], lr: 0.003584, loss: 0.7828
2022-08-09 04:12:55 - train: epoch 0092, iter [04500, 05004], lr: 0.003567, loss: 0.7086
2022-08-09 04:14:30 - train: epoch 0092, iter [04600, 05004], lr: 0.003549, loss: 0.8709
2022-08-09 04:16:03 - train: epoch 0092, iter [04700, 05004], lr: 0.003532, loss: 0.6463
2022-08-09 04:17:37 - train: epoch 0092, iter [04800, 05004], lr: 0.003514, loss: 0.6819
2022-08-09 04:19:12 - train: epoch 0092, iter [04900, 05004], lr: 0.003497, loss: 0.6411
2022-08-09 04:20:46 - train: epoch 0092, iter [05000, 05004], lr: 0.003480, loss: 0.6511
2022-08-09 04:20:50 - train: epoch 092, train_loss: 0.7599
2022-08-09 04:22:53 - eval: epoch: 092, acc1: 77.054%, acc5: 93.386%, test_loss: 0.9441, per_image_load_time: 3.622ms, per_image_inference_time: 1.146ms
2022-08-09 04:22:53 - until epoch: 092, best_acc1: 77.054%
2022-08-09 04:22:53 - epoch 093 lr: 0.003479
2022-08-09 04:24:36 - train: epoch 0093, iter [00100, 05004], lr: 0.003462, loss: 0.6972
2022-08-09 04:26:10 - train: epoch 0093, iter [00200, 05004], lr: 0.003445, loss: 0.7360
2022-08-09 04:27:44 - train: epoch 0093, iter [00300, 05004], lr: 0.003427, loss: 0.7307
2022-08-09 04:29:18 - train: epoch 0093, iter [00400, 05004], lr: 0.003410, loss: 0.8150
2022-08-09 04:30:52 - train: epoch 0093, iter [00500, 05004], lr: 0.003393, loss: 0.8848
2022-08-09 04:32:26 - train: epoch 0093, iter [00600, 05004], lr: 0.003376, loss: 0.8287
2022-08-09 04:34:00 - train: epoch 0093, iter [00700, 05004], lr: 0.003359, loss: 0.7166
2022-08-09 04:35:34 - train: epoch 0093, iter [00800, 05004], lr: 0.003342, loss: 0.7545
2022-08-09 04:37:08 - train: epoch 0093, iter [00900, 05004], lr: 0.003325, loss: 0.6120
2022-08-09 04:38:43 - train: epoch 0093, iter [01000, 05004], lr: 0.003308, loss: 0.5698
2022-08-09 04:40:17 - train: epoch 0093, iter [01100, 05004], lr: 0.003292, loss: 0.7899
2022-08-09 04:41:51 - train: epoch 0093, iter [01200, 05004], lr: 0.003275, loss: 0.6446
2022-08-09 04:43:25 - train: epoch 0093, iter [01300, 05004], lr: 0.003258, loss: 0.7422
2022-08-09 04:44:59 - train: epoch 0093, iter [01400, 05004], lr: 0.003241, loss: 0.8204
2022-08-09 04:46:33 - train: epoch 0093, iter [01500, 05004], lr: 0.003225, loss: 0.8444
2022-08-09 04:48:07 - train: epoch 0093, iter [01600, 05004], lr: 0.003208, loss: 0.8987
2022-08-09 04:49:41 - train: epoch 0093, iter [01700, 05004], lr: 0.003191, loss: 0.7076
2022-08-09 04:51:15 - train: epoch 0093, iter [01800, 05004], lr: 0.003175, loss: 0.9395
2022-08-09 04:52:49 - train: epoch 0093, iter [01900, 05004], lr: 0.003158, loss: 0.7761
2022-08-09 04:54:23 - train: epoch 0093, iter [02000, 05004], lr: 0.003142, loss: 0.6255
2022-08-09 04:55:57 - train: epoch 0093, iter [02100, 05004], lr: 0.003126, loss: 0.7659
2022-08-09 04:57:31 - train: epoch 0093, iter [02200, 05004], lr: 0.003109, loss: 0.8018
2022-08-09 04:59:05 - train: epoch 0093, iter [02300, 05004], lr: 0.003093, loss: 0.6463
2022-08-09 05:00:39 - train: epoch 0093, iter [02400, 05004], lr: 0.003077, loss: 0.8256
2022-08-09 05:02:13 - train: epoch 0093, iter [02500, 05004], lr: 0.003060, loss: 0.8133
2022-08-09 05:03:47 - train: epoch 0093, iter [02600, 05004], lr: 0.003044, loss: 0.8717
2022-08-09 05:05:21 - train: epoch 0093, iter [02700, 05004], lr: 0.003028, loss: 0.7821
2022-08-09 05:06:55 - train: epoch 0093, iter [02800, 05004], lr: 0.003012, loss: 0.7539
2022-08-09 05:08:29 - train: epoch 0093, iter [02900, 05004], lr: 0.002996, loss: 0.7392
2022-08-09 05:10:03 - train: epoch 0093, iter [03000, 05004], lr: 0.002980, loss: 0.8006
2022-08-09 05:11:37 - train: epoch 0093, iter [03100, 05004], lr: 0.002964, loss: 0.8197
2022-08-09 05:13:12 - train: epoch 0093, iter [03200, 05004], lr: 0.002948, loss: 0.6625
2022-08-09 05:14:46 - train: epoch 0093, iter [03300, 05004], lr: 0.002932, loss: 0.8434
2022-08-09 05:16:20 - train: epoch 0093, iter [03400, 05004], lr: 0.002916, loss: 0.8472
2022-08-09 05:17:54 - train: epoch 0093, iter [03500, 05004], lr: 0.002900, loss: 0.8078
2022-08-09 05:19:28 - train: epoch 0093, iter [03600, 05004], lr: 0.002884, loss: 0.8454
2022-08-09 05:21:02 - train: epoch 0093, iter [03700, 05004], lr: 0.002869, loss: 0.7156
2022-08-09 05:22:36 - train: epoch 0093, iter [03800, 05004], lr: 0.002853, loss: 0.7653
2022-08-09 05:24:10 - train: epoch 0093, iter [03900, 05004], lr: 0.002837, loss: 0.7474
2022-08-09 05:25:44 - train: epoch 0093, iter [04000, 05004], lr: 0.002822, loss: 0.8996
2022-08-09 05:27:18 - train: epoch 0093, iter [04100, 05004], lr: 0.002806, loss: 0.7709
2022-08-09 05:28:53 - train: epoch 0093, iter [04200, 05004], lr: 0.002791, loss: 0.8783
2022-08-09 05:30:27 - train: epoch 0093, iter [04300, 05004], lr: 0.002775, loss: 0.9423
2022-08-09 05:32:01 - train: epoch 0093, iter [04400, 05004], lr: 0.002760, loss: 0.7328
2022-08-09 05:33:35 - train: epoch 0093, iter [04500, 05004], lr: 0.002744, loss: 0.6224
2022-08-09 05:35:09 - train: epoch 0093, iter [04600, 05004], lr: 0.002729, loss: 0.6386
2022-08-09 05:36:43 - train: epoch 0093, iter [04700, 05004], lr: 0.002714, loss: 0.9650
2022-08-09 05:38:17 - train: epoch 0093, iter [04800, 05004], lr: 0.002698, loss: 0.7488
2022-08-09 05:39:51 - train: epoch 0093, iter [04900, 05004], lr: 0.002683, loss: 0.8283
2022-08-09 05:41:26 - train: epoch 0093, iter [05000, 05004], lr: 0.002668, loss: 0.6316
2022-08-09 05:41:30 - train: epoch 093, train_loss: 0.7409
2022-08-09 05:43:33 - eval: epoch: 093, acc1: 77.128%, acc5: 93.388%, test_loss: 0.9376, per_image_load_time: 1.861ms, per_image_inference_time: 1.150ms
2022-08-09 05:43:33 - until epoch: 093, best_acc1: 77.128%
2022-08-09 05:43:33 - epoch 094 lr: 0.002667
2022-08-09 05:45:16 - train: epoch 0094, iter [00100, 05004], lr: 0.002652, loss: 0.9014
2022-08-09 05:46:50 - train: epoch 0094, iter [00200, 05004], lr: 0.002637, loss: 0.8059
2022-08-09 05:48:24 - train: epoch 0094, iter [00300, 05004], lr: 0.002622, loss: 0.8432
2022-08-09 05:49:58 - train: epoch 0094, iter [00400, 05004], lr: 0.002607, loss: 0.7165
2022-08-09 05:51:32 - train: epoch 0094, iter [00500, 05004], lr: 0.002592, loss: 0.7104
2022-08-09 05:53:06 - train: epoch 0094, iter [00600, 05004], lr: 0.002577, loss: 0.8181
2022-08-09 05:54:40 - train: epoch 0094, iter [00700, 05004], lr: 0.002562, loss: 0.6762
2022-08-09 05:56:14 - train: epoch 0094, iter [00800, 05004], lr: 0.002547, loss: 0.7344
2022-08-09 05:57:48 - train: epoch 0094, iter [00900, 05004], lr: 0.002533, loss: 0.6733
2022-08-09 05:59:22 - train: epoch 0094, iter [01000, 05004], lr: 0.002518, loss: 0.7058
2022-08-09 06:00:56 - train: epoch 0094, iter [01100, 05004], lr: 0.002503, loss: 0.8876
2022-08-09 06:02:30 - train: epoch 0094, iter [01200, 05004], lr: 0.002488, loss: 0.6255
2022-08-09 06:04:04 - train: epoch 0094, iter [01300, 05004], lr: 0.002474, loss: 0.7108
2022-08-09 06:05:38 - train: epoch 0094, iter [01400, 05004], lr: 0.002459, loss: 0.6252
2022-08-09 06:07:12 - train: epoch 0094, iter [01500, 05004], lr: 0.002445, loss: 0.7785
2022-08-09 06:08:46 - train: epoch 0094, iter [01600, 05004], lr: 0.002430, loss: 0.8374
2022-08-09 06:10:20 - train: epoch 0094, iter [01700, 05004], lr: 0.002416, loss: 0.8053
2022-08-09 06:11:54 - train: epoch 0094, iter [01800, 05004], lr: 0.002401, loss: 0.6540
2022-08-09 06:13:28 - train: epoch 0094, iter [01900, 05004], lr: 0.002387, loss: 0.6970
2022-08-09 06:15:02 - train: epoch 0094, iter [02000, 05004], lr: 0.002373, loss: 0.6526
2022-08-09 06:16:36 - train: epoch 0094, iter [02100, 05004], lr: 0.002358, loss: 0.6126
2022-08-09 06:18:10 - train: epoch 0094, iter [02200, 05004], lr: 0.002344, loss: 0.8088
2022-08-09 06:19:44 - train: epoch 0094, iter [02300, 05004], lr: 0.002330, loss: 0.6106
2022-08-09 06:21:18 - train: epoch 0094, iter [02400, 05004], lr: 0.002316, loss: 0.9495
2022-08-09 06:22:52 - train: epoch 0094, iter [02500, 05004], lr: 0.002302, loss: 0.6372
2022-08-09 06:24:26 - train: epoch 0094, iter [02600, 05004], lr: 0.002288, loss: 0.5606
2022-08-09 06:26:00 - train: epoch 0094, iter [02700, 05004], lr: 0.002273, loss: 0.4982
2022-08-09 06:27:34 - train: epoch 0094, iter [02800, 05004], lr: 0.002260, loss: 0.8488
2022-08-09 06:29:08 - train: epoch 0094, iter [02900, 05004], lr: 0.002246, loss: 0.7812
2022-08-09 06:30:42 - train: epoch 0094, iter [03000, 05004], lr: 0.002232, loss: 0.5910
2022-08-09 06:32:16 - train: epoch 0094, iter [03100, 05004], lr: 0.002218, loss: 0.7607
2022-08-09 06:33:51 - train: epoch 0094, iter [03200, 05004], lr: 0.002204, loss: 0.6723
2022-08-09 06:35:25 - train: epoch 0094, iter [03300, 05004], lr: 0.002190, loss: 0.7956
2022-08-09 06:36:59 - train: epoch 0094, iter [03400, 05004], lr: 0.002176, loss: 0.7740
2022-08-09 06:38:33 - train: epoch 0094, iter [03500, 05004], lr: 0.002163, loss: 0.7884
2022-08-09 06:40:07 - train: epoch 0094, iter [03600, 05004], lr: 0.002149, loss: 0.6824
2022-08-09 06:41:41 - train: epoch 0094, iter [03700, 05004], lr: 0.002136, loss: 0.6746
2022-08-09 06:43:15 - train: epoch 0094, iter [03800, 05004], lr: 0.002122, loss: 0.7009
2022-08-09 06:44:49 - train: epoch 0094, iter [03900, 05004], lr: 0.002108, loss: 0.7241
2022-08-09 06:46:23 - train: epoch 0094, iter [04000, 05004], lr: 0.002095, loss: 0.7578
2022-08-09 06:47:57 - train: epoch 0094, iter [04100, 05004], lr: 0.002082, loss: 0.8241
2022-08-09 06:49:31 - train: epoch 0094, iter [04200, 05004], lr: 0.002068, loss: 0.6368
2022-08-09 06:51:05 - train: epoch 0094, iter [04300, 05004], lr: 0.002055, loss: 0.7498
2022-08-09 06:52:39 - train: epoch 0094, iter [04400, 05004], lr: 0.002041, loss: 0.7924
2022-08-09 06:54:13 - train: epoch 0094, iter [04500, 05004], lr: 0.002028, loss: 0.8544
2022-08-09 06:55:47 - train: epoch 0094, iter [04600, 05004], lr: 0.002015, loss: 0.7725
2022-08-09 06:57:21 - train: epoch 0094, iter [04700, 05004], lr: 0.002002, loss: 0.8137
2022-08-09 06:58:55 - train: epoch 0094, iter [04800, 05004], lr: 0.001989, loss: 0.6062
2022-08-09 07:00:29 - train: epoch 0094, iter [04900, 05004], lr: 0.001976, loss: 0.7042
2022-08-09 07:02:03 - train: epoch 0094, iter [05000, 05004], lr: 0.001963, loss: 0.6177
2022-08-09 07:02:08 - train: epoch 094, train_loss: 0.7226
2022-08-09 07:04:10 - eval: epoch: 094, acc1: 77.220%, acc5: 93.474%, test_loss: 0.9358, per_image_load_time: 1.916ms, per_image_inference_time: 1.177ms
2022-08-09 07:04:10 - until epoch: 094, best_acc1: 77.220%
2022-08-09 07:04:10 - epoch 095 lr: 0.001962
2022-08-09 07:05:53 - train: epoch 0095, iter [00100, 05004], lr: 0.001949, loss: 0.8134
2022-08-09 07:07:27 - train: epoch 0095, iter [00200, 05004], lr: 0.001936, loss: 0.6682
2022-08-09 07:09:01 - train: epoch 0095, iter [00300, 05004], lr: 0.001923, loss: 0.7365
2022-08-09 07:10:35 - train: epoch 0095, iter [00400, 05004], lr: 0.001910, loss: 0.6183
2022-08-09 07:12:09 - train: epoch 0095, iter [00500, 05004], lr: 0.001897, loss: 0.6105
2022-08-09 07:13:43 - train: epoch 0095, iter [00600, 05004], lr: 0.001885, loss: 0.6711
2022-08-09 07:15:18 - train: epoch 0095, iter [00700, 05004], lr: 0.001872, loss: 0.7737
2022-08-09 07:16:52 - train: epoch 0095, iter [00800, 05004], lr: 0.001859, loss: 0.6266
2022-08-09 07:18:26 - train: epoch 0095, iter [00900, 05004], lr: 0.001846, loss: 0.7776
2022-08-09 07:20:00 - train: epoch 0095, iter [01000, 05004], lr: 0.001834, loss: 0.7665
2022-08-09 07:21:34 - train: epoch 0095, iter [01100, 05004], lr: 0.001821, loss: 0.7033
2022-08-09 07:23:08 - train: epoch 0095, iter [01200, 05004], lr: 0.001809, loss: 0.5925
2022-08-09 07:24:42 - train: epoch 0095, iter [01300, 05004], lr: 0.001796, loss: 0.5479
2022-08-09 07:26:16 - train: epoch 0095, iter [01400, 05004], lr: 0.001784, loss: 0.6884
2022-08-09 07:27:50 - train: epoch 0095, iter [01500, 05004], lr: 0.001771, loss: 0.7941
2022-08-09 07:29:24 - train: epoch 0095, iter [01600, 05004], lr: 0.001759, loss: 0.6742
2022-08-09 07:30:58 - train: epoch 0095, iter [01700, 05004], lr: 0.001747, loss: 0.6246
2022-08-09 07:32:32 - train: epoch 0095, iter [01800, 05004], lr: 0.001734, loss: 0.7867
2022-08-09 07:34:06 - train: epoch 0095, iter [01900, 05004], lr: 0.001722, loss: 0.6056
2022-08-09 07:35:40 - train: epoch 0095, iter [02000, 05004], lr: 0.001710, loss: 0.7469
2022-08-09 07:37:14 - train: epoch 0095, iter [02100, 05004], lr: 0.001698, loss: 0.6347
2022-08-09 07:38:48 - train: epoch 0095, iter [02200, 05004], lr: 0.001686, loss: 0.7012
2022-08-09 07:40:22 - train: epoch 0095, iter [02300, 05004], lr: 0.001674, loss: 0.7237
2022-08-09 07:41:56 - train: epoch 0095, iter [02400, 05004], lr: 0.001662, loss: 0.6866
2022-08-09 07:43:30 - train: epoch 0095, iter [02500, 05004], lr: 0.001650, loss: 0.6694
2022-08-09 07:45:04 - train: epoch 0095, iter [02600, 05004], lr: 0.001638, loss: 0.7154
2022-08-09 07:46:38 - train: epoch 0095, iter [02700, 05004], lr: 0.001626, loss: 0.5865
2022-08-09 07:48:12 - train: epoch 0095, iter [02800, 05004], lr: 0.001614, loss: 0.6991
2022-08-09 07:49:46 - train: epoch 0095, iter [02900, 05004], lr: 0.001602, loss: 0.6951
2022-08-09 07:51:20 - train: epoch 0095, iter [03000, 05004], lr: 0.001590, loss: 0.9359
2022-08-09 07:52:54 - train: epoch 0095, iter [03100, 05004], lr: 0.001579, loss: 0.8666
2022-08-09 07:54:28 - train: epoch 0095, iter [03200, 05004], lr: 0.001567, loss: 0.7585
2022-08-09 07:56:02 - train: epoch 0095, iter [03300, 05004], lr: 0.001555, loss: 0.7012
2022-08-09 07:57:36 - train: epoch 0095, iter [03400, 05004], lr: 0.001544, loss: 0.7162
2022-08-09 07:59:10 - train: epoch 0095, iter [03500, 05004], lr: 0.001532, loss: 0.8155
2022-08-09 08:00:44 - train: epoch 0095, iter [03600, 05004], lr: 0.001521, loss: 0.6703
2022-08-09 08:02:18 - train: epoch 0095, iter [03700, 05004], lr: 0.001509, loss: 0.7348
2022-08-09 08:03:52 - train: epoch 0095, iter [03800, 05004], lr: 0.001498, loss: 0.7054
2022-08-09 08:05:26 - train: epoch 0095, iter [03900, 05004], lr: 0.001487, loss: 0.6685
2022-08-09 08:07:00 - train: epoch 0095, iter [04000, 05004], lr: 0.001475, loss: 0.7162
2022-08-09 08:08:34 - train: epoch 0095, iter [04100, 05004], lr: 0.001464, loss: 0.6991
2022-08-09 08:10:08 - train: epoch 0095, iter [04200, 05004], lr: 0.001453, loss: 0.6508
2022-08-09 08:11:42 - train: epoch 0095, iter [04300, 05004], lr: 0.001442, loss: 0.8127
2022-08-09 08:13:16 - train: epoch 0095, iter [04400, 05004], lr: 0.001430, loss: 0.7822
2022-08-09 08:14:50 - train: epoch 0095, iter [04500, 05004], lr: 0.001419, loss: 0.5933
2022-08-09 08:16:24 - train: epoch 0095, iter [04600, 05004], lr: 0.001408, loss: 0.7014
2022-08-09 08:17:58 - train: epoch 0095, iter [04700, 05004], lr: 0.001397, loss: 0.6594
2022-08-09 08:19:32 - train: epoch 0095, iter [04800, 05004], lr: 0.001386, loss: 0.6174
2022-08-09 08:21:06 - train: epoch 0095, iter [04900, 05004], lr: 0.001375, loss: 0.6969
2022-08-09 08:22:40 - train: epoch 0095, iter [05000, 05004], lr: 0.001364, loss: 0.6261
2022-08-09 08:22:45 - train: epoch 095, train_loss: 0.7094
2022-08-09 08:24:50 - eval: epoch: 095, acc1: 77.404%, acc5: 93.490%, test_loss: 0.9275, per_image_load_time: 3.669ms, per_image_inference_time: 1.167ms
2022-08-09 08:24:51 - until epoch: 095, best_acc1: 77.404%
2022-08-09 08:24:51 - epoch 096 lr: 0.001364
2022-08-09 08:26:33 - train: epoch 0096, iter [00100, 05004], lr: 0.001353, loss: 0.7469
2022-08-09 08:28:07 - train: epoch 0096, iter [00200, 05004], lr: 0.001342, loss: 0.7022
2022-08-09 08:29:41 - train: epoch 0096, iter [00300, 05004], lr: 0.001331, loss: 0.6655
2022-08-09 08:31:15 - train: epoch 0096, iter [00400, 05004], lr: 0.001321, loss: 0.5857
2022-08-09 08:32:49 - train: epoch 0096, iter [00500, 05004], lr: 0.001310, loss: 0.7572
2022-08-09 08:34:23 - train: epoch 0096, iter [00600, 05004], lr: 0.001299, loss: 0.6972
2022-08-09 08:35:56 - train: epoch 0096, iter [00700, 05004], lr: 0.001289, loss: 0.7498
2022-08-09 08:37:30 - train: epoch 0096, iter [00800, 05004], lr: 0.001278, loss: 0.6818
2022-08-09 08:39:04 - train: epoch 0096, iter [00900, 05004], lr: 0.001268, loss: 0.7856
2022-08-09 08:40:38 - train: epoch 0096, iter [01000, 05004], lr: 0.001257, loss: 0.7001
2022-08-09 08:42:12 - train: epoch 0096, iter [01100, 05004], lr: 0.001247, loss: 0.7316
2022-08-09 08:43:46 - train: epoch 0096, iter [01200, 05004], lr: 0.001236, loss: 0.7532
2022-08-09 08:45:20 - train: epoch 0096, iter [01300, 05004], lr: 0.001226, loss: 0.7546
2022-08-09 08:46:54 - train: epoch 0096, iter [01400, 05004], lr: 0.001216, loss: 0.7170
2022-08-09 08:48:28 - train: epoch 0096, iter [01500, 05004], lr: 0.001206, loss: 0.7000
2022-08-09 08:50:02 - train: epoch 0096, iter [01600, 05004], lr: 0.001195, loss: 0.5423
2022-08-09 08:51:36 - train: epoch 0096, iter [01700, 05004], lr: 0.001185, loss: 0.6611
2022-08-09 08:53:10 - train: epoch 0096, iter [01800, 05004], lr: 0.001175, loss: 0.7643
2022-08-09 08:54:44 - train: epoch 0096, iter [01900, 05004], lr: 0.001165, loss: 0.7514
2022-08-09 08:56:18 - train: epoch 0096, iter [02000, 05004], lr: 0.001155, loss: 0.7175
2022-08-09 08:57:52 - train: epoch 0096, iter [02100, 05004], lr: 0.001145, loss: 0.6056
2022-08-09 08:59:26 - train: epoch 0096, iter [02200, 05004], lr: 0.001135, loss: 0.5586
2022-08-09 09:01:01 - train: epoch 0096, iter [02300, 05004], lr: 0.001125, loss: 0.6369
2022-08-09 09:02:35 - train: epoch 0096, iter [02400, 05004], lr: 0.001115, loss: 0.6690
2022-08-09 09:04:09 - train: epoch 0096, iter [02500, 05004], lr: 0.001105, loss: 0.6353
2022-08-09 09:05:43 - train: epoch 0096, iter [02600, 05004], lr: 0.001096, loss: 0.6550
2022-08-09 09:07:17 - train: epoch 0096, iter [02700, 05004], lr: 0.001086, loss: 0.7793
2022-08-09 09:08:51 - train: epoch 0096, iter [02800, 05004], lr: 0.001076, loss: 0.7667
2022-08-09 09:10:25 - train: epoch 0096, iter [02900, 05004], lr: 0.001067, loss: 0.7226
2022-08-09 09:11:59 - train: epoch 0096, iter [03000, 05004], lr: 0.001057, loss: 0.8437
2022-08-09 09:13:33 - train: epoch 0096, iter [03100, 05004], lr: 0.001047, loss: 0.7569
2022-08-09 09:15:07 - train: epoch 0096, iter [03200, 05004], lr: 0.001038, loss: 0.7185
2022-08-09 09:16:41 - train: epoch 0096, iter [03300, 05004], lr: 0.001028, loss: 0.7483
2022-08-09 09:18:16 - train: epoch 0096, iter [03400, 05004], lr: 0.001019, loss: 0.6645
2022-08-09 09:19:50 - train: epoch 0096, iter [03500, 05004], lr: 0.001010, loss: 0.6643
2022-08-09 09:21:24 - train: epoch 0096, iter [03600, 05004], lr: 0.001000, loss: 0.5380
2022-08-09 09:22:58 - train: epoch 0096, iter [03700, 05004], lr: 0.000991, loss: 0.7061
2022-08-09 09:24:32 - train: epoch 0096, iter [03800, 05004], lr: 0.000982, loss: 0.6263
2022-08-09 09:26:06 - train: epoch 0096, iter [03900, 05004], lr: 0.000972, loss: 0.7266
2022-08-09 09:27:40 - train: epoch 0096, iter [04000, 05004], lr: 0.000963, loss: 0.7947
2022-08-09 09:29:14 - train: epoch 0096, iter [04100, 05004], lr: 0.000954, loss: 0.8138
2022-08-09 09:30:48 - train: epoch 0096, iter [04200, 05004], lr: 0.000945, loss: 0.5875
2022-08-09 09:32:22 - train: epoch 0096, iter [04300, 05004], lr: 0.000936, loss: 0.5871
2022-08-09 09:33:56 - train: epoch 0096, iter [04400, 05004], lr: 0.000927, loss: 0.6251
2022-08-09 09:35:30 - train: epoch 0096, iter [04500, 05004], lr: 0.000918, loss: 0.6226
2022-08-09 09:37:04 - train: epoch 0096, iter [04600, 05004], lr: 0.000909, loss: 0.8072
2022-08-09 09:38:38 - train: epoch 0096, iter [04700, 05004], lr: 0.000900, loss: 0.5943
2022-08-09 09:40:12 - train: epoch 0096, iter [04800, 05004], lr: 0.000891, loss: 0.7431
2022-08-09 09:41:45 - train: epoch 0096, iter [04900, 05004], lr: 0.000883, loss: 0.6562
2022-08-09 09:43:19 - train: epoch 0096, iter [05000, 05004], lr: 0.000874, loss: 0.7524
2022-08-09 09:43:24 - train: epoch 096, train_loss: 0.6983
2022-08-09 09:45:27 - eval: epoch: 096, acc1: 77.450%, acc5: 93.530%, test_loss: 0.9275, per_image_load_time: 3.579ms, per_image_inference_time: 1.165ms
2022-08-09 09:45:27 - until epoch: 096, best_acc1: 77.450%
2022-08-09 09:45:27 - epoch 097 lr: 0.000874
2022-08-09 09:47:09 - train: epoch 0097, iter [00100, 05004], lr: 0.000865, loss: 0.7201
2022-08-09 09:48:43 - train: epoch 0097, iter [00200, 05004], lr: 0.000856, loss: 0.7932
2022-08-09 09:50:17 - train: epoch 0097, iter [00300, 05004], lr: 0.000848, loss: 0.8010
2022-08-09 09:51:51 - train: epoch 0097, iter [00400, 05004], lr: 0.000839, loss: 0.7227
2022-08-09 09:53:25 - train: epoch 0097, iter [00500, 05004], lr: 0.000831, loss: 0.6229
2022-08-09 09:54:59 - train: epoch 0097, iter [00600, 05004], lr: 0.000822, loss: 0.7583
2022-08-09 09:56:33 - train: epoch 0097, iter [00700, 05004], lr: 0.000814, loss: 0.6183
2022-08-09 09:58:07 - train: epoch 0097, iter [00800, 05004], lr: 0.000805, loss: 0.6979
2022-08-09 09:59:41 - train: epoch 0097, iter [00900, 05004], lr: 0.000797, loss: 0.7752
2022-08-09 10:01:15 - train: epoch 0097, iter [01000, 05004], lr: 0.000789, loss: 0.6628
2022-08-09 10:02:49 - train: epoch 0097, iter [01100, 05004], lr: 0.000780, loss: 0.6867
2022-08-09 10:04:23 - train: epoch 0097, iter [01200, 05004], lr: 0.000772, loss: 0.6052
2022-08-09 10:05:57 - train: epoch 0097, iter [01300, 05004], lr: 0.000764, loss: 0.6322
2022-08-09 10:07:31 - train: epoch 0097, iter [01400, 05004], lr: 0.000756, loss: 0.7593
2022-08-09 10:09:05 - train: epoch 0097, iter [01500, 05004], lr: 0.000748, loss: 0.6236
2022-08-09 10:10:39 - train: epoch 0097, iter [01600, 05004], lr: 0.000740, loss: 0.6772
2022-08-09 10:12:13 - train: epoch 0097, iter [01700, 05004], lr: 0.000732, loss: 0.6534
2022-08-09 10:13:47 - train: epoch 0097, iter [01800, 05004], lr: 0.000724, loss: 0.7874
2022-08-09 10:15:21 - train: epoch 0097, iter [01900, 05004], lr: 0.000716, loss: 0.5568
2022-08-09 10:16:55 - train: epoch 0097, iter [02000, 05004], lr: 0.000708, loss: 0.5889
2022-08-09 10:18:29 - train: epoch 0097, iter [02100, 05004], lr: 0.000700, loss: 0.7963
2022-08-09 10:20:03 - train: epoch 0097, iter [02200, 05004], lr: 0.000692, loss: 0.8450
2022-08-09 10:21:37 - train: epoch 0097, iter [02300, 05004], lr: 0.000685, loss: 0.6739
2022-08-09 10:23:11 - train: epoch 0097, iter [02400, 05004], lr: 0.000677, loss: 0.5453
2022-08-09 10:24:45 - train: epoch 0097, iter [02500, 05004], lr: 0.000669, loss: 0.8167
2022-08-09 10:26:19 - train: epoch 0097, iter [02600, 05004], lr: 0.000662, loss: 0.8636
2022-08-09 10:27:53 - train: epoch 0097, iter [02700, 05004], lr: 0.000654, loss: 0.5251
2022-08-09 10:29:27 - train: epoch 0097, iter [02800, 05004], lr: 0.000647, loss: 0.7313
2022-08-09 10:31:01 - train: epoch 0097, iter [02900, 05004], lr: 0.000639, loss: 0.7374
2022-08-09 10:32:35 - train: epoch 0097, iter [03000, 05004], lr: 0.000632, loss: 0.7767
2022-08-09 10:34:09 - train: epoch 0097, iter [03100, 05004], lr: 0.000624, loss: 0.8655
2022-08-09 10:35:43 - train: epoch 0097, iter [03200, 05004], lr: 0.000617, loss: 0.8263
2022-08-09 10:37:17 - train: epoch 0097, iter [03300, 05004], lr: 0.000610, loss: 0.8226
2022-08-09 10:38:51 - train: epoch 0097, iter [03400, 05004], lr: 0.000602, loss: 0.6710
2022-08-09 10:40:25 - train: epoch 0097, iter [03500, 05004], lr: 0.000595, loss: 0.6742
2022-08-09 10:41:59 - train: epoch 0097, iter [03600, 05004], lr: 0.000588, loss: 0.7468
2022-08-09 10:43:33 - train: epoch 0097, iter [03700, 05004], lr: 0.000581, loss: 0.5791
2022-08-09 10:45:07 - train: epoch 0097, iter [03800, 05004], lr: 0.000574, loss: 0.5495
2022-08-09 10:46:41 - train: epoch 0097, iter [03900, 05004], lr: 0.000567, loss: 0.6441
2022-08-09 10:48:15 - train: epoch 0097, iter [04000, 05004], lr: 0.000560, loss: 0.7583
2022-08-09 10:49:49 - train: epoch 0097, iter [04100, 05004], lr: 0.000553, loss: 0.6890
2022-08-09 10:51:23 - train: epoch 0097, iter [04200, 05004], lr: 0.000546, loss: 0.6028
2022-08-09 10:52:57 - train: epoch 0097, iter [04300, 05004], lr: 0.000539, loss: 0.4914
2022-08-09 10:54:31 - train: epoch 0097, iter [04400, 05004], lr: 0.000532, loss: 0.6471
2022-08-09 10:56:05 - train: epoch 0097, iter [04500, 05004], lr: 0.000525, loss: 0.7057
2022-08-09 10:57:39 - train: epoch 0097, iter [04600, 05004], lr: 0.000519, loss: 0.6998
2022-08-09 10:59:13 - train: epoch 0097, iter [04700, 05004], lr: 0.000512, loss: 0.7401
2022-08-09 11:00:47 - train: epoch 0097, iter [04800, 05004], lr: 0.000505, loss: 0.7678
2022-08-09 11:02:21 - train: epoch 0097, iter [04900, 05004], lr: 0.000499, loss: 0.7106
2022-08-09 11:03:55 - train: epoch 0097, iter [05000, 05004], lr: 0.000492, loss: 0.6362
2022-08-09 11:03:59 - train: epoch 097, train_loss: 0.6899
2022-08-09 11:06:03 - eval: epoch: 097, acc1: 77.486%, acc5: 93.554%, test_loss: 0.9247, per_image_load_time: 1.594ms, per_image_inference_time: 1.192ms
2022-08-09 11:06:03 - until epoch: 097, best_acc1: 77.486%
2022-08-09 11:06:03 - epoch 098 lr: 0.000492
2022-08-09 11:07:46 - train: epoch 0098, iter [00100, 05004], lr: 0.000485, loss: 0.6101
2022-08-09 11:09:20 - train: epoch 0098, iter [00200, 05004], lr: 0.000479, loss: 0.6415
2022-08-09 11:10:54 - train: epoch 0098, iter [00300, 05004], lr: 0.000472, loss: 0.8970
2022-08-09 11:12:28 - train: epoch 0098, iter [00400, 05004], lr: 0.000466, loss: 0.6384
2022-08-09 11:14:02 - train: epoch 0098, iter [00500, 05004], lr: 0.000460, loss: 0.7015
2022-08-09 11:15:36 - train: epoch 0098, iter [00600, 05004], lr: 0.000453, loss: 0.5586
2022-08-09 11:17:10 - train: epoch 0098, iter [00700, 05004], lr: 0.000447, loss: 0.7178
2022-08-09 11:18:44 - train: epoch 0098, iter [00800, 05004], lr: 0.000441, loss: 0.8724
2022-08-09 11:20:18 - train: epoch 0098, iter [00900, 05004], lr: 0.000435, loss: 0.5477
2022-08-09 11:21:52 - train: epoch 0098, iter [01000, 05004], lr: 0.000428, loss: 0.6559
2022-08-09 11:23:26 - train: epoch 0098, iter [01100, 05004], lr: 0.000422, loss: 0.6673
2022-08-09 11:25:00 - train: epoch 0098, iter [01200, 05004], lr: 0.000416, loss: 0.6020
2022-08-09 11:26:34 - train: epoch 0098, iter [01300, 05004], lr: 0.000410, loss: 0.5680
2022-08-09 11:28:08 - train: epoch 0098, iter [01400, 05004], lr: 0.000404, loss: 0.6353
2022-08-09 11:29:41 - train: epoch 0098, iter [01500, 05004], lr: 0.000398, loss: 0.6894
2022-08-09 11:31:15 - train: epoch 0098, iter [01600, 05004], lr: 0.000393, loss: 0.7964
2022-08-09 11:32:49 - train: epoch 0098, iter [01700, 05004], lr: 0.000387, loss: 0.7711
2022-08-09 11:34:23 - train: epoch 0098, iter [01800, 05004], lr: 0.000381, loss: 0.7233
2022-08-09 11:35:57 - train: epoch 0098, iter [01900, 05004], lr: 0.000375, loss: 0.4893
2022-08-09 11:37:31 - train: epoch 0098, iter [02000, 05004], lr: 0.000369, loss: 0.9333
2022-08-09 11:39:04 - train: epoch 0098, iter [02100, 05004], lr: 0.000364, loss: 0.6809
2022-08-09 11:40:38 - train: epoch 0098, iter [02200, 05004], lr: 0.000358, loss: 0.4451
2022-08-09 11:42:12 - train: epoch 0098, iter [02300, 05004], lr: 0.000353, loss: 0.5784
2022-08-09 11:43:46 - train: epoch 0098, iter [02400, 05004], lr: 0.000347, loss: 0.7006
2022-08-09 11:45:20 - train: epoch 0098, iter [02500, 05004], lr: 0.000342, loss: 0.8089
2022-08-09 11:46:54 - train: epoch 0098, iter [02600, 05004], lr: 0.000336, loss: 0.5264
2022-08-09 11:48:28 - train: epoch 0098, iter [02700, 05004], lr: 0.000331, loss: 0.7314
2022-08-09 11:50:02 - train: epoch 0098, iter [02800, 05004], lr: 0.000325, loss: 0.7214
2022-08-09 11:51:36 - train: epoch 0098, iter [02900, 05004], lr: 0.000320, loss: 0.5793
2022-08-09 11:53:09 - train: epoch 0098, iter [03000, 05004], lr: 0.000315, loss: 0.5990
2022-08-09 11:54:43 - train: epoch 0098, iter [03100, 05004], lr: 0.000310, loss: 0.7289
2022-08-09 11:56:17 - train: epoch 0098, iter [03200, 05004], lr: 0.000305, loss: 0.5868
2022-08-09 11:57:51 - train: epoch 0098, iter [03300, 05004], lr: 0.000299, loss: 0.5798
2022-08-09 11:59:25 - train: epoch 0098, iter [03400, 05004], lr: 0.000294, loss: 0.5822
2022-08-09 12:00:59 - train: epoch 0098, iter [03500, 05004], lr: 0.000289, loss: 0.8031
2022-08-09 12:02:33 - train: epoch 0098, iter [03600, 05004], lr: 0.000284, loss: 0.6331
2022-08-09 12:04:07 - train: epoch 0098, iter [03700, 05004], lr: 0.000279, loss: 0.7842
2022-08-09 12:05:41 - train: epoch 0098, iter [03800, 05004], lr: 0.000274, loss: 0.5232
2022-08-09 12:07:15 - train: epoch 0098, iter [03900, 05004], lr: 0.000270, loss: 0.6142
2022-08-09 12:08:49 - train: epoch 0098, iter [04000, 05004], lr: 0.000265, loss: 0.8123
2022-08-09 12:10:23 - train: epoch 0098, iter [04100, 05004], lr: 0.000260, loss: 0.7415
2022-08-09 12:11:57 - train: epoch 0098, iter [04200, 05004], lr: 0.000255, loss: 0.6400
2022-08-09 12:13:31 - train: epoch 0098, iter [04300, 05004], lr: 0.000250, loss: 0.5234
2022-08-09 12:15:05 - train: epoch 0098, iter [04400, 05004], lr: 0.000246, loss: 0.5273
2022-08-09 12:16:39 - train: epoch 0098, iter [04500, 05004], lr: 0.000241, loss: 0.6710
2022-08-09 12:18:12 - train: epoch 0098, iter [04600, 05004], lr: 0.000237, loss: 0.7323
2022-08-09 12:19:47 - train: epoch 0098, iter [04700, 05004], lr: 0.000232, loss: 0.7627
2022-08-09 12:21:21 - train: epoch 0098, iter [04800, 05004], lr: 0.000228, loss: 0.5050
2022-08-09 12:22:54 - train: epoch 0098, iter [04900, 05004], lr: 0.000223, loss: 0.7723
2022-08-09 12:24:28 - train: epoch 0098, iter [05000, 05004], lr: 0.000219, loss: 0.6191
2022-08-09 12:24:33 - train: epoch 098, train_loss: 0.6826
2022-08-09 12:26:36 - eval: epoch: 098, acc1: 77.532%, acc5: 93.496%, test_loss: 0.9252, per_image_load_time: 3.563ms, per_image_inference_time: 1.177ms
2022-08-09 12:26:36 - until epoch: 098, best_acc1: 77.532%
2022-08-09 12:26:36 - epoch 099 lr: 0.000219
2022-08-09 12:28:19 - train: epoch 0099, iter [00100, 05004], lr: 0.000214, loss: 0.6821
2022-08-09 12:29:53 - train: epoch 0099, iter [00200, 05004], lr: 0.000210, loss: 0.6030
2022-08-09 12:31:27 - train: epoch 0099, iter [00300, 05004], lr: 0.000206, loss: 0.6393
2022-08-09 12:33:01 - train: epoch 0099, iter [00400, 05004], lr: 0.000202, loss: 0.7291
2022-08-09 12:34:35 - train: epoch 0099, iter [00500, 05004], lr: 0.000197, loss: 0.6196
2022-08-09 12:36:09 - train: epoch 0099, iter [00600, 05004], lr: 0.000193, loss: 0.6428
2022-08-09 12:37:43 - train: epoch 0099, iter [00700, 05004], lr: 0.000189, loss: 0.8108
2022-08-09 12:39:16 - train: epoch 0099, iter [00800, 05004], lr: 0.000185, loss: 0.5918
2022-08-09 12:40:51 - train: epoch 0099, iter [00900, 05004], lr: 0.000181, loss: 0.6741
2022-08-09 12:42:24 - train: epoch 0099, iter [01000, 05004], lr: 0.000177, loss: 0.5349
2022-08-09 12:43:58 - train: epoch 0099, iter [01100, 05004], lr: 0.000173, loss: 0.7711
2022-08-09 12:45:32 - train: epoch 0099, iter [01200, 05004], lr: 0.000169, loss: 0.6236
2022-08-09 12:47:06 - train: epoch 0099, iter [01300, 05004], lr: 0.000166, loss: 0.6353
2022-08-09 12:48:40 - train: epoch 0099, iter [01400, 05004], lr: 0.000162, loss: 0.5344
2022-08-09 12:50:14 - train: epoch 0099, iter [01500, 05004], lr: 0.000158, loss: 0.4768
2022-08-09 12:51:48 - train: epoch 0099, iter [01600, 05004], lr: 0.000154, loss: 0.7711
2022-08-09 12:53:21 - train: epoch 0099, iter [01700, 05004], lr: 0.000151, loss: 0.5917
2022-08-09 12:54:55 - train: epoch 0099, iter [01800, 05004], lr: 0.000147, loss: 0.6493
2022-08-09 12:56:29 - train: epoch 0099, iter [01900, 05004], lr: 0.000144, loss: 0.6452
2022-08-09 12:58:03 - train: epoch 0099, iter [02000, 05004], lr: 0.000140, loss: 0.5975
2022-08-09 12:59:37 - train: epoch 0099, iter [02100, 05004], lr: 0.000137, loss: 0.7098
2022-08-09 13:01:11 - train: epoch 0099, iter [02200, 05004], lr: 0.000133, loss: 0.6177
2022-08-09 13:02:45 - train: epoch 0099, iter [02300, 05004], lr: 0.000130, loss: 0.6708
2022-08-09 13:04:19 - train: epoch 0099, iter [02400, 05004], lr: 0.000126, loss: 0.8243
2022-08-09 13:05:53 - train: epoch 0099, iter [02500, 05004], lr: 0.000123, loss: 0.6037
2022-08-09 13:07:26 - train: epoch 0099, iter [02600, 05004], lr: 0.000120, loss: 0.6157
2022-08-09 13:09:00 - train: epoch 0099, iter [02700, 05004], lr: 0.000117, loss: 0.7120
2022-08-09 13:10:34 - train: epoch 0099, iter [02800, 05004], lr: 0.000113, loss: 0.8074
2022-08-09 13:12:08 - train: epoch 0099, iter [02900, 05004], lr: 0.000110, loss: 0.6745
2022-08-09 13:13:42 - train: epoch 0099, iter [03000, 05004], lr: 0.000107, loss: 0.6621
2022-08-09 13:15:16 - train: epoch 0099, iter [03100, 05004], lr: 0.000104, loss: 0.6276
2022-08-09 13:16:49 - train: epoch 0099, iter [03200, 05004], lr: 0.000101, loss: 0.6960
2022-08-09 13:18:23 - train: epoch 0099, iter [03300, 05004], lr: 0.000098, loss: 0.7151
2022-08-09 13:19:57 - train: epoch 0099, iter [03400, 05004], lr: 0.000095, loss: 0.7960
2022-08-09 13:21:31 - train: epoch 0099, iter [03500, 05004], lr: 0.000092, loss: 0.7402
2022-08-09 13:23:05 - train: epoch 0099, iter [03600, 05004], lr: 0.000090, loss: 0.7060
2022-08-09 13:24:38 - train: epoch 0099, iter [03700, 05004], lr: 0.000087, loss: 0.5886
2022-08-09 13:26:12 - train: epoch 0099, iter [03800, 05004], lr: 0.000084, loss: 0.7519
2022-08-09 13:27:46 - train: epoch 0099, iter [03900, 05004], lr: 0.000081, loss: 0.6473
2022-08-09 13:29:20 - train: epoch 0099, iter [04000, 05004], lr: 0.000079, loss: 0.6219
2022-08-09 13:30:54 - train: epoch 0099, iter [04100, 05004], lr: 0.000076, loss: 0.5587
2022-08-09 13:32:28 - train: epoch 0099, iter [04200, 05004], lr: 0.000074, loss: 0.7211
2022-08-09 13:34:02 - train: epoch 0099, iter [04300, 05004], lr: 0.000071, loss: 0.6360
2022-08-09 13:35:36 - train: epoch 0099, iter [04400, 05004], lr: 0.000069, loss: 0.8211
2022-08-09 13:37:10 - train: epoch 0099, iter [04500, 05004], lr: 0.000066, loss: 0.7258
2022-08-09 13:38:44 - train: epoch 0099, iter [04600, 05004], lr: 0.000064, loss: 0.7328
2022-08-09 13:40:18 - train: epoch 0099, iter [04700, 05004], lr: 0.000062, loss: 0.7417
2022-08-09 13:41:52 - train: epoch 0099, iter [04800, 05004], lr: 0.000059, loss: 0.6905
2022-08-09 13:43:26 - train: epoch 0099, iter [04900, 05004], lr: 0.000057, loss: 0.8411
2022-08-09 13:45:00 - train: epoch 0099, iter [05000, 05004], lr: 0.000055, loss: 0.8326
2022-08-09 13:45:04 - train: epoch 099, train_loss: 0.6788
2022-08-09 13:47:08 - eval: epoch: 099, acc1: 77.506%, acc5: 93.518%, test_loss: 0.9251, per_image_load_time: 3.582ms, per_image_inference_time: 1.205ms
2022-08-09 13:47:09 - until epoch: 099, best_acc1: 77.532%
2022-08-09 13:47:09 - epoch 100 lr: 0.000055
2022-08-09 13:48:52 - train: epoch 0100, iter [00100, 05004], lr: 0.000053, loss: 0.6714
2022-08-09 13:50:26 - train: epoch 0100, iter [00200, 05004], lr: 0.000050, loss: 0.7365
2022-08-09 13:52:00 - train: epoch 0100, iter [00300, 05004], lr: 0.000048, loss: 0.7273
2022-08-09 13:53:34 - train: epoch 0100, iter [00400, 05004], lr: 0.000046, loss: 0.6158
2022-08-09 13:55:08 - train: epoch 0100, iter [00500, 05004], lr: 0.000044, loss: 0.7578
2022-08-09 13:56:42 - train: epoch 0100, iter [00600, 05004], lr: 0.000042, loss: 0.6098
2022-08-09 13:58:16 - train: epoch 0100, iter [00700, 05004], lr: 0.000040, loss: 0.5668
2022-08-09 13:59:50 - train: epoch 0100, iter [00800, 05004], lr: 0.000039, loss: 0.7751
2022-08-09 14:01:24 - train: epoch 0100, iter [00900, 05004], lr: 0.000037, loss: 0.5538
2022-08-09 14:02:58 - train: epoch 0100, iter [01000, 05004], lr: 0.000035, loss: 0.8218
2022-08-09 14:04:32 - train: epoch 0100, iter [01100, 05004], lr: 0.000033, loss: 0.6226
2022-08-09 14:06:06 - train: epoch 0100, iter [01200, 05004], lr: 0.000032, loss: 0.5931
2022-08-09 14:07:41 - train: epoch 0100, iter [01300, 05004], lr: 0.000030, loss: 0.7359
2022-08-09 14:09:14 - train: epoch 0100, iter [01400, 05004], lr: 0.000028, loss: 0.5706
2022-08-09 14:10:48 - train: epoch 0100, iter [01500, 05004], lr: 0.000027, loss: 0.6228
2022-08-09 14:12:22 - train: epoch 0100, iter [01600, 05004], lr: 0.000025, loss: 0.6541
2022-08-09 14:13:56 - train: epoch 0100, iter [01700, 05004], lr: 0.000024, loss: 0.5648
2022-08-09 14:15:30 - train: epoch 0100, iter [01800, 05004], lr: 0.000022, loss: 0.5297
2022-08-09 14:17:04 - train: epoch 0100, iter [01900, 05004], lr: 0.000021, loss: 0.6456
2022-08-09 14:18:38 - train: epoch 0100, iter [02000, 05004], lr: 0.000020, loss: 0.7009
2022-08-09 14:20:12 - train: epoch 0100, iter [02100, 05004], lr: 0.000018, loss: 0.6716
2022-08-09 14:21:46 - train: epoch 0100, iter [02200, 05004], lr: 0.000017, loss: 0.7756
2022-08-09 14:23:20 - train: epoch 0100, iter [02300, 05004], lr: 0.000016, loss: 0.8168
2022-08-09 14:24:54 - train: epoch 0100, iter [02400, 05004], lr: 0.000015, loss: 0.6369
2022-08-09 14:26:28 - train: epoch 0100, iter [02500, 05004], lr: 0.000014, loss: 0.7407
2022-08-09 14:28:02 - train: epoch 0100, iter [02600, 05004], lr: 0.000013, loss: 0.5224
2022-08-09 14:29:36 - train: epoch 0100, iter [02700, 05004], lr: 0.000012, loss: 0.6777
2022-08-09 14:31:10 - train: epoch 0100, iter [02800, 05004], lr: 0.000011, loss: 0.6515
2022-08-09 14:32:44 - train: epoch 0100, iter [02900, 05004], lr: 0.000010, loss: 0.7304
2022-08-09 14:34:18 - train: epoch 0100, iter [03000, 05004], lr: 0.000009, loss: 0.5946
2022-08-09 14:35:52 - train: epoch 0100, iter [03100, 05004], lr: 0.000008, loss: 0.5886
2022-08-09 14:37:26 - train: epoch 0100, iter [03200, 05004], lr: 0.000007, loss: 0.9395
2022-08-09 14:39:00 - train: epoch 0100, iter [03300, 05004], lr: 0.000006, loss: 0.7101
2022-08-09 14:40:34 - train: epoch 0100, iter [03400, 05004], lr: 0.000006, loss: 0.6368
2022-08-09 14:42:08 - train: epoch 0100, iter [03500, 05004], lr: 0.000005, loss: 0.6414
2022-08-09 14:43:42 - train: epoch 0100, iter [03600, 05004], lr: 0.000004, loss: 0.7439
2022-08-09 14:45:16 - train: epoch 0100, iter [03700, 05004], lr: 0.000004, loss: 0.8077
2022-08-09 14:46:50 - train: epoch 0100, iter [03800, 05004], lr: 0.000003, loss: 0.6567
2022-08-09 14:48:24 - train: epoch 0100, iter [03900, 05004], lr: 0.000003, loss: 0.5672
2022-08-09 14:49:58 - train: epoch 0100, iter [04000, 05004], lr: 0.000002, loss: 0.5358
2022-08-09 14:51:32 - train: epoch 0100, iter [04100, 05004], lr: 0.000002, loss: 0.7588
2022-08-09 14:53:06 - train: epoch 0100, iter [04200, 05004], lr: 0.000001, loss: 0.7194
2022-08-09 14:54:40 - train: epoch 0100, iter [04300, 05004], lr: 0.000001, loss: 0.7100
2022-08-09 14:56:14 - train: epoch 0100, iter [04400, 05004], lr: 0.000001, loss: 0.8285
2022-08-09 14:57:48 - train: epoch 0100, iter [04500, 05004], lr: 0.000001, loss: 0.6656
2022-08-09 14:59:22 - train: epoch 0100, iter [04600, 05004], lr: 0.000000, loss: 0.6095
2022-08-09 15:00:56 - train: epoch 0100, iter [04700, 05004], lr: 0.000000, loss: 0.7905
2022-08-09 15:02:30 - train: epoch 0100, iter [04800, 05004], lr: 0.000000, loss: 0.5931
2022-08-09 15:04:04 - train: epoch 0100, iter [04900, 05004], lr: 0.000000, loss: 0.6127
2022-08-09 15:05:38 - train: epoch 0100, iter [05000, 05004], lr: 0.000000, loss: 0.6843
2022-08-09 15:05:43 - train: epoch 100, train_loss: 0.6781
2022-08-09 15:07:47 - eval: epoch: 100, acc1: 77.494%, acc5: 93.542%, test_loss: 0.9252, per_image_load_time: 2.069ms, per_image_inference_time: 1.153ms
2022-08-09 15:07:47 - until epoch: 100, best_acc1: 77.532%
2022-08-09 15:07:47 - train done. model: RegNetX_3_2GF, train time: 134.331 hours, best_acc1: 77.532%
