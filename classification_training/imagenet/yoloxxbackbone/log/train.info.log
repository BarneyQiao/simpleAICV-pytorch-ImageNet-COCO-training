2022-03-21 08:06:55 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 1.2520
2022-03-21 08:07:33 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 0.9304
2022-03-21 08:08:11 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 0.9449
2022-03-21 08:08:49 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 1.0223
2022-03-21 08:09:27 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 0.8541
2022-03-21 08:10:05 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 1.0111
2022-03-21 08:10:43 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 1.1374
2022-03-21 08:11:22 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 1.1569
2022-03-21 08:12:00 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 1.0506
2022-03-21 08:12:38 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 1.2189
2022-03-21 08:13:16 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 0.9907
2022-03-21 08:13:54 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 1.0632
2022-03-21 08:14:32 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 1.2229
2022-03-21 08:15:10 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 0.9941
2022-03-21 08:15:48 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 0.9995
2022-03-21 08:16:27 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 1.0950
2022-03-21 08:17:05 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 1.1324
2022-03-21 08:17:42 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 1.0671
2022-03-21 08:18:21 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 0.9101
2022-03-21 08:18:59 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 0.8932
2022-03-21 08:19:37 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 1.1732
2022-03-21 08:19:39 - train: epoch 088, train_loss: 1.0720
2022-03-21 08:20:54 - eval: epoch: 088, acc1: 73.950%, acc5: 91.698%, test_loss: 1.0281, per_image_load_time: 2.248ms, per_image_inference_time: 0.719ms
2022-03-21 08:20:56 - until epoch: 088, best_acc1: 73.972%
2022-03-21 08:20:56 - epoch 089 lr: 0.0010000000000000002
2022-03-21 08:21:39 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 1.2896
2022-03-21 08:22:16 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 0.9229
2022-03-21 08:22:54 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 1.1118
2022-03-21 08:23:31 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 0.8840
2022-03-21 08:24:09 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 1.0829
2022-03-21 08:24:46 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 0.9781
2022-03-21 08:25:24 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 1.1242
2022-03-21 08:26:02 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 1.2329
2022-03-21 08:26:39 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 1.1489
2022-03-21 08:27:17 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 1.1713
2022-03-21 08:27:55 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 0.9730
2022-03-21 08:28:32 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 1.2103
2022-03-21 08:29:10 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 1.1365
2022-03-21 08:29:48 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 1.2102
2022-03-21 08:30:25 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 1.0335
2022-03-21 08:31:03 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 1.0279
2022-03-21 08:31:41 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 1.0231
2022-03-21 08:32:19 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 1.0854
2022-03-21 08:32:57 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 0.9395
2022-03-21 08:33:35 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 0.9890
2022-03-21 08:34:13 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 1.0789
2022-03-21 08:34:51 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 1.0893
2022-03-21 08:35:29 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 0.9567
2022-03-21 08:36:07 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 1.0926
2022-03-21 08:36:45 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 0.9970
2022-03-21 08:37:24 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 1.0871
2022-03-21 08:38:02 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 0.9447
2022-03-21 08:38:40 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 1.0560
2022-03-21 08:39:19 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 1.1145
2022-03-21 08:39:57 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 1.1270
2022-03-21 08:40:35 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 1.1729
2022-03-21 08:41:13 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 1.1979
2022-03-21 08:41:51 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 1.2303
2022-03-21 08:42:29 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 1.0747
2022-03-21 08:43:07 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 0.9104
2022-03-21 08:43:46 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 0.9737
2022-03-21 08:44:24 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 1.2063
2022-03-21 08:45:02 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 0.9568
2022-03-21 08:45:40 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 1.0892
2022-03-21 08:46:18 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 0.9843
2022-03-21 08:46:56 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 1.3369
2022-03-21 08:47:34 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 1.0783
2022-03-21 08:48:12 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 1.1095
2022-03-21 08:48:50 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 1.0539
2022-03-21 08:49:28 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 0.9543
2022-03-21 08:50:06 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 1.0430
2022-03-21 08:50:44 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 1.0206
2022-03-21 08:51:23 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 1.1058
2022-03-21 08:52:01 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 1.0368
2022-03-21 08:52:39 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 0.8424
2022-03-21 08:52:41 - train: epoch 089, train_loss: 1.0707
2022-03-21 08:53:57 - eval: epoch: 089, acc1: 73.904%, acc5: 91.676%, test_loss: 1.0313, per_image_load_time: 2.218ms, per_image_inference_time: 0.726ms
2022-03-21 08:53:58 - until epoch: 089, best_acc1: 73.972%
2022-03-21 08:53:58 - epoch 090 lr: 0.0010000000000000002
2022-03-21 08:54:42 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 1.0447
2022-03-21 08:55:19 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 1.1187
2022-03-21 08:55:56 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 1.0684
2022-03-21 08:56:34 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 0.9446
2022-03-21 08:57:11 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 1.1406
2022-03-21 08:57:49 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 1.1855
2022-03-21 08:58:26 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 1.0553
2022-03-21 08:59:03 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 0.9899
2022-03-21 08:59:41 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 1.0365
2022-03-21 09:00:18 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 0.9448
2022-03-21 09:00:56 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 1.0896
2022-03-21 09:01:33 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 1.1146
2022-03-21 09:02:11 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 1.2055
2022-03-21 09:02:49 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 0.9445
2022-03-21 09:03:27 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 1.3455
2022-03-21 09:04:04 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 1.0510
2022-03-21 09:04:42 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 0.9299
2022-03-21 09:05:20 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 1.0301
2022-03-21 09:05:57 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 0.9941
2022-03-21 09:06:35 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 1.1805
2022-03-21 09:07:13 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 1.1705
2022-03-21 09:07:51 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 1.0716
2022-03-21 09:08:29 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 1.1997
2022-03-21 09:09:07 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 1.0903
2022-03-21 09:09:45 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 1.1579
2022-03-21 09:10:22 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 1.1193
2022-03-21 09:11:00 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 0.9565
2022-03-21 09:11:38 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 1.0536
2022-03-21 09:12:16 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 0.9587
2022-03-21 09:12:53 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 1.0290
2022-03-21 09:13:31 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 0.9000
2022-03-21 09:14:09 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 1.0442
2022-03-21 09:14:47 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 1.2933
2022-03-21 09:15:24 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 0.9413
2022-03-21 09:16:02 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 1.0524
2022-03-21 09:16:40 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 1.0125
2022-03-21 09:17:17 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 1.0976
2022-03-21 09:17:55 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 1.1133
2022-03-21 09:18:33 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 0.9132
2022-03-21 09:19:10 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 1.0536
2022-03-21 09:19:48 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 1.2877
2022-03-21 09:20:26 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 1.1270
2022-03-21 09:21:03 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 1.1280
2022-03-21 09:21:41 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 0.9916
2022-03-21 09:22:19 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 1.0125
2022-03-21 09:22:57 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 1.0560
2022-03-21 09:23:34 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 1.0097
2022-03-21 09:24:12 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 1.1071
2022-03-21 09:24:50 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 1.0565
2022-03-21 09:25:28 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 0.9696
2022-03-21 09:25:30 - train: epoch 090, train_loss: 1.0681
2022-03-21 09:26:47 - eval: epoch: 090, acc1: 73.976%, acc5: 91.756%, test_loss: 1.0312, per_image_load_time: 2.280ms, per_image_inference_time: 0.729ms
2022-03-21 09:26:49 - until epoch: 090, best_acc1: 73.976%
2022-03-21 09:26:49 - epoch 091 lr: 0.00010000000000000003
2022-03-21 09:27:32 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 0.9489
2022-03-21 09:28:09 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 1.0806
2022-03-21 09:28:47 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 0.9457
2022-03-21 09:29:24 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 0.9037
2022-03-21 09:30:01 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 0.9946
2022-03-21 09:30:39 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 1.0868
2022-03-21 09:31:16 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 1.0027
2022-03-21 09:31:54 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 0.9050
2022-03-21 09:32:31 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 0.9891
2022-03-21 09:33:09 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 0.9924
2022-03-21 09:33:46 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 0.8574
2022-03-21 09:34:24 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 1.1178
2022-03-21 09:35:01 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 0.9605
2022-03-21 09:35:38 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 1.1351
2022-03-21 09:36:16 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 1.0113
2022-03-21 09:36:53 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 1.0519
2022-03-21 09:37:31 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 1.0999
2022-03-21 09:38:08 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 1.0143
2022-03-21 09:38:46 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 0.9917
2022-03-21 09:39:23 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 1.0087
2022-03-21 09:40:01 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 0.7852
2022-03-21 09:40:38 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 1.0719
2022-03-21 09:41:16 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 1.0975
2022-03-21 09:41:53 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 1.0240
2022-03-21 09:42:30 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 1.0359
2022-03-21 09:43:08 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 1.0578
2022-03-21 09:43:45 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 0.8485
2022-03-21 09:44:22 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 1.0483
2022-03-21 09:45:00 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 1.1020
2022-03-21 09:45:38 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 1.1346
2022-03-21 09:46:15 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 0.9384
2022-03-21 09:46:53 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 1.0679
2022-03-21 09:47:30 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 0.8615
2022-03-21 09:48:08 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 0.8628
2022-03-21 09:48:46 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 1.0678
2022-03-21 09:49:23 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 0.9602
2022-03-21 09:50:01 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 1.1124
2022-03-21 09:50:39 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 1.1152
2022-03-21 09:51:16 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 1.0089
2022-03-21 09:51:54 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 1.0920
2022-03-21 09:52:32 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 1.0635
2022-03-21 09:53:10 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 1.0967
2022-03-21 09:53:47 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 1.0574
2022-03-21 09:54:25 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 0.9790
2022-03-21 09:55:03 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 0.9108
2022-03-21 09:55:40 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 1.0668
2022-03-21 09:56:18 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 1.0795
2022-03-21 09:56:56 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 1.0995
2022-03-21 09:57:34 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 0.9841
2022-03-21 09:58:12 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 1.1730
2022-03-21 09:58:14 - train: epoch 091, train_loss: 1.0348
2022-03-21 09:59:28 - eval: epoch: 091, acc1: 74.348%, acc5: 91.984%, test_loss: 1.0122, per_image_load_time: 1.646ms, per_image_inference_time: 0.725ms
2022-03-21 09:59:30 - until epoch: 091, best_acc1: 74.348%
2022-03-21 09:59:30 - epoch 092 lr: 0.00010000000000000003
2022-03-21 10:00:13 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 1.0878
2022-03-21 10:00:50 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 1.1370
2022-03-21 10:01:28 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 0.9114
2022-03-21 10:02:05 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 0.9235
2022-03-21 10:02:42 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 1.0526
2022-03-21 10:03:20 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 1.0882
2022-03-21 10:03:57 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 1.0748
2022-03-21 10:04:35 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 1.1506
2022-03-21 10:05:12 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 1.0227
2022-03-21 10:05:49 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 1.1840
2022-03-21 10:06:27 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 0.9102
2022-03-21 10:07:04 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 0.9181
2022-03-21 10:07:42 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 0.9059
2022-03-21 10:08:19 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 1.0532
2022-03-21 10:08:57 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 0.9291
2022-03-21 10:09:34 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 0.9836
2022-03-21 10:10:12 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 1.0576
2022-03-21 10:10:49 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 0.9352
2022-03-21 10:11:27 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 0.9025
2022-03-21 10:12:04 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 0.9455
2022-03-21 10:12:42 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 1.0105
2022-03-21 10:13:20 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 1.0679
2022-03-21 10:13:57 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 0.9713
2022-03-21 10:14:35 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 0.9433
2022-03-21 10:15:13 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 0.9715
2022-03-21 10:15:51 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 1.1943
2022-03-21 10:16:28 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 0.9715
2022-03-21 10:17:06 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 0.8803
2022-03-21 10:17:44 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 1.0635
2022-03-21 10:18:22 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 0.8794
2022-03-21 10:18:59 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 0.9768
2022-03-21 10:19:37 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 0.9001
2022-03-21 10:20:14 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 1.0156
2022-03-21 10:20:52 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 1.1422
2022-03-21 10:21:29 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 0.9106
2022-03-21 10:22:07 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 1.0065
2022-03-21 10:22:44 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 0.8653
2022-03-21 10:23:22 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 1.2155
2022-03-21 10:24:00 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 1.0902
2022-03-21 10:24:37 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 1.0976
2022-03-21 10:25:15 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 0.8482
2022-03-21 10:25:52 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 1.0339
2022-03-21 10:26:30 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 1.0657
2022-03-21 10:27:08 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 0.8970
2022-03-21 10:27:45 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 1.0039
2022-03-21 10:28:23 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 0.9470
2022-03-21 10:29:01 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 0.7474
2022-03-21 10:29:39 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 0.8964
2022-03-21 10:30:16 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 1.0113
2022-03-21 10:30:54 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 1.1490
2022-03-21 10:30:56 - train: epoch 092, train_loss: 1.0253
2022-03-21 10:32:12 - eval: epoch: 092, acc1: 74.382%, acc5: 91.946%, test_loss: 1.0099, per_image_load_time: 2.142ms, per_image_inference_time: 0.725ms
2022-03-21 10:32:13 - until epoch: 092, best_acc1: 74.382%
2022-03-21 10:32:13 - epoch 093 lr: 0.00010000000000000003
2022-03-21 10:32:57 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 0.9660
2022-03-21 10:33:34 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 0.9076
2022-03-21 10:34:12 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 1.0223
2022-03-21 10:34:49 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 0.9868
2022-03-21 10:35:27 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 1.0524
2022-03-21 10:36:05 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 0.9116
2022-03-21 10:36:42 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 1.0509
2022-03-21 10:37:20 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 0.9304
2022-03-21 10:37:58 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 0.9947
2022-03-21 10:38:35 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.9525
2022-03-21 10:39:13 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 0.8827
2022-03-21 10:39:51 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 0.9541
2022-03-21 10:40:28 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 1.0020
2022-03-21 10:41:06 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 0.9962
2022-03-21 10:41:44 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 1.1861
2022-03-21 10:42:21 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 1.0020
2022-03-21 10:42:59 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 0.9935
2022-03-21 10:43:36 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 1.0512
2022-03-21 10:44:14 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 0.9648
2022-03-21 10:44:51 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 0.8778
2022-03-21 10:45:29 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 0.9348
2022-03-21 10:46:07 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 1.1885
2022-03-21 10:46:44 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 1.0996
2022-03-21 10:47:22 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 0.8815
2022-03-21 10:48:00 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 1.0830
2022-03-21 10:48:38 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 1.2176
2022-03-21 10:49:16 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 0.9801
2022-03-21 10:49:56 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 0.9767
2022-03-21 10:50:34 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 1.1020
2022-03-21 10:51:11 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 0.9340
2022-03-21 10:51:49 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 1.1773
2022-03-21 10:52:36 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 1.0112
2022-03-21 10:53:14 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 1.1114
2022-03-21 10:53:52 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 1.2556
2022-03-21 10:54:30 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 0.7673
2022-03-21 10:55:08 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 1.1420
2022-03-21 10:55:46 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 0.9505
2022-03-21 10:56:24 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 0.8228
2022-03-21 10:57:02 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 1.1186
2022-03-21 10:57:40 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 1.2229
2022-03-21 10:58:18 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 1.0487
2022-03-21 10:58:56 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 1.0406
2022-03-21 10:59:35 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 1.2143
2022-03-21 11:00:13 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 1.0019
2022-03-21 11:00:50 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 0.9479
2022-03-21 11:01:28 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 0.8388
2022-03-21 11:02:06 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 1.2695
2022-03-21 11:02:44 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 1.0049
2022-03-21 11:03:22 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 1.0355
2022-03-21 11:04:00 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 1.0695
2022-03-21 11:04:02 - train: epoch 093, train_loss: 1.0215
2022-03-21 11:05:19 - eval: epoch: 093, acc1: 74.376%, acc5: 91.964%, test_loss: 1.0082, per_image_load_time: 1.609ms, per_image_inference_time: 0.727ms
2022-03-21 11:05:20 - until epoch: 093, best_acc1: 74.382%
2022-03-21 11:05:20 - epoch 094 lr: 0.00010000000000000003
2022-03-21 11:06:04 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 1.0085
2022-03-21 11:06:41 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 1.0191
2022-03-21 11:07:19 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 1.0900
2022-03-21 11:07:56 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 1.1944
2022-03-21 11:08:33 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 0.9512
2022-03-21 11:09:11 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 0.9677
2022-03-21 11:09:48 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 1.0706
2022-03-21 11:10:25 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 0.9896
2022-03-21 11:11:03 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 0.9393
2022-03-21 11:11:40 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 1.1018
2022-03-21 11:12:18 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 1.1457
2022-03-21 11:12:55 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 1.0973
2022-03-21 11:13:32 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 0.9898
2022-03-21 11:14:10 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 0.9936
2022-03-21 11:14:47 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 1.1338
2022-03-21 11:15:25 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 1.3523
2022-03-21 11:16:02 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 0.9350
2022-03-21 11:16:39 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 0.9462
2022-03-21 11:17:17 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 1.0026
2022-03-21 11:17:55 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 0.8400
2022-03-21 11:18:32 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 1.0701
2022-03-21 11:19:10 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 0.9030
2022-03-21 11:19:47 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 0.8306
2022-03-21 11:20:25 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 1.0120
2022-03-21 11:21:02 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 0.9186
2022-03-21 11:21:40 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 0.9173
2022-03-21 11:22:18 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 0.9443
2022-03-21 11:22:55 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 1.0088
2022-03-21 11:23:33 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 1.0704
2022-03-21 11:24:10 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 0.9230
2022-03-21 11:24:48 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 1.1697
2022-03-21 11:25:25 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 1.0058
2022-03-21 11:26:03 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 1.0016
2022-03-21 11:26:40 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 1.1092
2022-03-21 11:27:18 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 1.2228
2022-03-21 11:27:56 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 1.1124
2022-03-21 11:28:33 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 1.2063
2022-03-21 11:29:11 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 0.9085
2022-03-21 11:29:48 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 0.9931
2022-03-21 11:30:26 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 1.1068
2022-03-21 11:31:03 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 1.3000
2022-03-21 11:31:41 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 0.8063
2022-03-21 11:32:18 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 1.1534
2022-03-21 11:32:56 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 1.1777
2022-03-21 11:33:34 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 1.0930
2022-03-21 11:34:14 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 1.0227
2022-03-21 11:34:52 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 1.0508
2022-03-21 11:35:45 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 1.0501
2022-03-21 11:36:30 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 0.9664
2022-03-21 11:37:10 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 0.8935
2022-03-21 11:37:12 - train: epoch 094, train_loss: 1.0196
2022-03-21 11:38:30 - eval: epoch: 094, acc1: 74.470%, acc5: 92.014%, test_loss: 1.0087, per_image_load_time: 1.064ms, per_image_inference_time: 0.739ms
2022-03-21 11:38:32 - until epoch: 094, best_acc1: 74.470%
2022-03-21 11:38:32 - epoch 095 lr: 0.00010000000000000003
2022-03-21 11:39:15 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 0.8553
2022-03-21 11:39:52 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 1.1725
2022-03-21 11:40:29 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 0.9512
2022-03-21 11:41:07 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 1.0653
2022-03-21 11:41:44 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 1.0985
2022-03-21 11:42:22 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 1.0415
2022-03-21 11:42:59 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 1.1594
2022-03-21 11:43:37 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 1.1757
2022-03-21 11:44:14 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 1.2814
2022-03-21 11:44:52 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 1.0674
2022-03-21 11:45:29 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 0.9003
2022-03-21 11:46:07 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 0.9132
2022-03-21 11:46:44 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 0.9661
2022-03-21 11:47:22 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 1.0107
2022-03-21 11:48:00 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 1.0553
2022-03-21 11:48:37 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.6934
2022-03-21 11:49:15 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 0.9578
2022-03-21 11:49:53 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 1.0267
2022-03-21 11:50:30 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 1.0013
2022-03-21 11:51:08 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 1.0697
2022-03-21 11:51:45 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 1.0112
2022-03-21 11:52:23 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 0.7738
2022-03-21 11:53:01 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 1.0192
2022-03-21 11:53:38 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 1.0625
2022-03-21 11:54:16 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 0.9370
2022-03-21 11:54:54 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 1.0306
2022-03-21 11:55:31 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 1.0481
2022-03-21 11:56:09 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 0.9555
2022-03-21 11:56:47 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 0.9545
2022-03-21 11:57:25 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 1.1648
2022-03-21 11:58:02 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 1.1428
2022-03-21 11:58:40 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 1.0024
2022-03-21 11:59:18 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 1.0864
2022-03-21 11:59:55 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 0.9673
2022-03-21 12:00:36 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 0.9565
2022-03-21 12:01:13 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 0.9463
2022-03-21 12:01:53 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 0.9708
2022-03-21 12:02:31 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 0.7976
2022-03-21 12:03:09 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 1.1094
2022-03-21 12:03:47 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 0.8603
2022-03-21 12:04:24 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 1.0480
2022-03-21 12:05:02 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 0.8741
2022-03-21 12:05:40 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 0.9986
2022-03-21 12:06:18 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 1.1443
2022-03-21 12:06:56 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 0.9087
2022-03-21 12:07:33 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 1.0164
2022-03-21 12:08:11 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 0.9836
2022-03-21 12:08:53 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 1.1108
2022-03-21 12:09:37 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 0.9575
2022-03-21 12:10:20 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 0.9522
2022-03-21 12:10:22 - train: epoch 095, train_loss: 1.0193
2022-03-21 12:11:39 - eval: epoch: 095, acc1: 74.380%, acc5: 91.990%, test_loss: 1.0076, per_image_load_time: 1.042ms, per_image_inference_time: 0.717ms
2022-03-21 12:11:40 - until epoch: 095, best_acc1: 74.470%
2022-03-21 12:11:40 - epoch 096 lr: 0.00010000000000000003
2022-03-21 12:12:24 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 1.0496
2022-03-21 12:13:01 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 1.1167
2022-03-21 12:13:39 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 1.0094
2022-03-21 12:14:16 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 0.8501
2022-03-21 12:14:54 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 1.0204
2022-03-21 12:15:31 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 1.1211
2022-03-21 12:16:09 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 0.8961
2022-03-21 12:16:47 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 0.9643
2022-03-21 12:17:24 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 0.9684
2022-03-21 12:18:02 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 0.9784
2022-03-21 12:18:39 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 1.1081
2022-03-21 12:19:17 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 1.0849
2022-03-21 12:19:55 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 1.0741
2022-03-21 12:20:33 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 0.9212
2022-03-21 12:21:10 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 0.9682
2022-03-21 12:21:48 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 0.7374
2022-03-21 12:22:26 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 1.0491
2022-03-21 12:23:04 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 1.0852
2022-03-21 12:23:41 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 1.1479
2022-03-21 12:24:19 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 0.9643
2022-03-21 12:24:57 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 1.0598
2022-03-21 12:25:34 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.7993
2022-03-21 12:26:19 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 0.9496
2022-03-21 12:26:57 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 0.9353
2022-03-21 12:27:34 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 0.9392
2022-03-21 12:28:12 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 0.9921
2022-03-21 12:28:50 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 1.0885
2022-03-21 12:29:27 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 1.1361
2022-03-21 12:30:05 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 0.9179
2022-03-21 12:30:43 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 1.0354
2022-03-21 12:31:21 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 1.0992
2022-03-21 12:31:59 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 1.0738
2022-03-21 12:32:37 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 1.1840
2022-03-21 12:33:14 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 0.8379
2022-03-21 12:33:52 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 0.9277
2022-03-21 12:34:30 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 0.9153
2022-03-21 12:35:17 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 1.0067
2022-03-21 12:36:01 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 1.0180
2022-03-21 12:36:45 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 1.0194
2022-03-21 12:37:40 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 0.8671
2022-03-21 12:38:26 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 0.9361
2022-03-21 12:39:11 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 0.9971
2022-03-21 12:40:01 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.7665
2022-03-21 12:40:39 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 1.0130
2022-03-21 12:41:23 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 0.9611
2022-03-21 12:42:15 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 0.9515
2022-03-21 12:42:52 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 1.0210
2022-03-21 12:43:30 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 1.1386
2022-03-21 12:44:08 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 1.1683
2022-03-21 12:44:46 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 0.9715
2022-03-21 12:44:48 - train: epoch 096, train_loss: 1.0166
2022-03-21 12:46:06 - eval: epoch: 096, acc1: 74.432%, acc5: 92.046%, test_loss: 1.0071, per_image_load_time: 1.447ms, per_image_inference_time: 0.705ms
2022-03-21 12:46:07 - until epoch: 096, best_acc1: 74.470%
2022-03-21 12:46:07 - epoch 097 lr: 0.00010000000000000003
2022-03-21 12:46:51 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 1.1081
2022-03-21 12:47:28 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 0.8441
2022-03-21 12:48:05 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 1.1110
2022-03-21 12:48:43 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 1.2250
2022-03-21 12:49:20 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 1.0318
2022-03-21 12:49:58 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 1.1091
2022-03-21 12:50:35 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 1.0372
2022-03-21 12:51:13 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.9102
2022-03-21 12:51:50 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 0.8986
2022-03-21 12:52:28 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 0.9654
2022-03-21 12:53:05 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 0.9472
2022-03-21 12:53:43 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 0.9561
2022-03-21 12:54:21 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 0.9116
2022-03-21 12:54:58 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 1.0346
2022-03-21 12:55:36 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 0.9605
2022-03-21 12:56:13 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 0.9788
2022-03-21 12:56:51 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 0.9597
2022-03-21 12:57:29 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 1.0477
2022-03-21 12:58:06 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 1.0649
2022-03-21 12:58:44 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 0.9366
2022-03-21 12:59:21 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 1.0325
2022-03-21 12:59:59 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 1.1682
2022-03-21 13:00:36 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 0.8754
2022-03-21 13:01:14 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 1.0536
2022-03-21 13:01:52 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 1.1188
2022-03-21 13:02:29 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 1.1786
2022-03-21 13:03:07 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 0.8662
2022-03-21 13:03:45 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 0.8923
2022-03-21 13:04:22 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 1.1611
2022-03-21 13:05:00 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 0.9410
2022-03-21 13:05:38 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 0.9241
2022-03-21 13:06:15 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 1.0928
2022-03-21 13:06:53 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 1.1162
2022-03-21 13:07:31 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 1.1826
2022-03-21 13:08:08 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 1.1373
2022-03-21 13:08:46 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 0.9625
2022-03-21 13:09:24 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 0.8443
2022-03-21 13:10:02 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 0.8201
2022-03-21 13:10:40 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 1.0035
2022-03-21 13:11:17 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 1.1091
2022-03-21 13:11:55 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 0.9584
2022-03-21 13:12:33 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 0.9443
2022-03-21 13:13:11 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 0.8837
2022-03-21 13:13:49 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 0.9864
2022-03-21 13:14:27 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 1.0235
2022-03-21 13:15:05 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 1.0794
2022-03-21 13:15:43 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 1.0030
2022-03-21 13:16:21 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 1.0744
2022-03-21 13:16:59 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 1.2219
2022-03-21 13:17:36 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 1.1252
2022-03-21 13:17:38 - train: epoch 097, train_loss: 1.0165
2022-03-21 13:18:55 - eval: epoch: 097, acc1: 74.454%, acc5: 92.020%, test_loss: 1.0047, per_image_load_time: 1.350ms, per_image_inference_time: 0.732ms
2022-03-21 13:18:57 - until epoch: 097, best_acc1: 74.470%
2022-03-21 13:18:57 - epoch 098 lr: 0.00010000000000000003
2022-03-21 13:19:40 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 1.0696
2022-03-21 13:20:18 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 1.1356
2022-03-21 13:20:55 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 1.2546
2022-03-21 13:21:33 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 0.9497
2022-03-21 13:22:11 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 0.9328
2022-03-21 13:22:48 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 1.0658
2022-03-21 13:23:26 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 0.9548
2022-03-21 13:24:04 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 1.0233
2022-03-21 13:24:42 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 0.9932
2022-03-21 13:25:19 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 0.8572
2022-03-21 13:25:57 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 0.8598
2022-03-21 13:26:35 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 0.9412
2022-03-21 13:27:13 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 1.1196
2022-03-21 13:27:51 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 1.0283
2022-03-21 13:28:28 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 0.9175
2022-03-21 13:29:06 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 1.0575
2022-03-21 13:29:44 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 0.9719
2022-03-21 13:30:22 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 0.9688
2022-03-21 13:30:59 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 0.8443
2022-03-21 13:31:37 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 1.1640
2022-03-21 13:32:15 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 0.9701
2022-03-21 13:32:52 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 0.9916
2022-03-21 13:33:30 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 0.9626
2022-03-21 13:34:08 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 0.9853
2022-03-21 13:34:45 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 1.1831
2022-03-21 13:35:23 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 0.9652
2022-03-21 13:36:01 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 1.0482
2022-03-21 13:36:39 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 0.9570
2022-03-21 13:37:16 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 0.9926
2022-03-21 13:37:54 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 0.9964
2022-03-21 13:38:32 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 0.9862
2022-03-21 13:39:09 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 0.9422
2022-03-21 13:39:47 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 0.8784
2022-03-21 13:40:25 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 1.0541
2022-03-21 13:41:03 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 0.9940
2022-03-21 13:41:41 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 1.2994
2022-03-21 13:42:18 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 1.0936
2022-03-21 13:42:56 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 1.0462
2022-03-21 13:43:34 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 1.0461
2022-03-21 13:44:12 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 1.1617
2022-03-21 13:44:50 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 1.1006
2022-03-21 13:45:28 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 1.0004
2022-03-21 13:46:06 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 0.8055
2022-03-21 13:46:44 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 1.2049
2022-03-21 13:47:22 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 1.1275
2022-03-21 13:48:00 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 1.0860
2022-03-21 13:48:38 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 0.9343
2022-03-21 13:49:16 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 0.7805
2022-03-21 13:49:54 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 1.0606
2022-03-21 13:50:32 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 1.0299
2022-03-21 13:50:34 - train: epoch 098, train_loss: 1.0137
2022-03-21 13:51:52 - eval: epoch: 098, acc1: 74.480%, acc5: 92.040%, test_loss: 1.0056, per_image_load_time: 1.898ms, per_image_inference_time: 0.723ms
2022-03-21 13:51:54 - until epoch: 098, best_acc1: 74.480%
2022-03-21 13:51:54 - epoch 099 lr: 0.00010000000000000003
2022-03-21 13:52:37 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 0.9004
2022-03-21 13:53:14 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 0.9087
2022-03-21 13:53:52 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 0.9919
2022-03-21 13:54:29 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 1.1436
2022-03-21 13:55:07 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 1.1311
2022-03-21 13:55:44 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 1.0198
2022-03-21 13:56:22 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 1.0334
2022-03-21 13:56:59 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 1.0250
2022-03-21 13:57:37 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 0.9832
2022-03-21 13:58:14 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 1.0703
2022-03-21 13:58:52 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 0.9805
2022-03-21 13:59:29 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 1.0004
2022-03-21 14:00:07 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 1.0663
2022-03-21 14:00:44 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 1.0569
2022-03-21 14:01:22 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 0.9253
2022-03-21 14:01:59 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 1.2125
2022-03-21 14:02:36 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 0.9062
2022-03-21 14:03:13 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 0.9872
2022-03-21 14:03:51 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 0.9731
2022-03-21 14:04:28 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 0.8820
2022-03-21 14:05:06 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 0.9620
2022-03-21 14:05:43 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 1.0813
2022-03-21 14:06:20 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 1.0579
2022-03-21 14:06:58 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 1.1112
2022-03-21 14:07:35 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 0.9269
2022-03-21 14:08:13 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 0.9575
2022-03-21 14:08:50 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 1.0017
2022-03-21 14:09:28 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 1.1578
2022-03-21 14:10:05 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 0.9561
2022-03-21 14:10:43 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 1.0136
2022-03-21 14:11:20 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 0.8307
2022-03-21 14:11:58 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 1.0540
2022-03-21 14:12:35 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 0.9139
2022-03-21 14:13:12 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 0.9638
2022-03-21 14:13:50 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 1.0323
2022-03-21 14:14:27 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 0.8913
2022-03-21 14:15:05 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 0.8637
2022-03-21 14:15:42 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 1.2111
2022-03-21 14:16:19 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 1.0612
2022-03-21 14:16:57 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 1.1510
2022-03-21 14:17:35 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 0.8330
2022-03-21 14:18:12 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 0.9413
2022-03-21 14:18:50 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 0.9838
2022-03-21 14:19:27 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 1.0680
2022-03-21 14:20:05 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 1.1065
2022-03-21 14:20:43 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 1.1884
2022-03-21 14:21:21 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 0.9524
2022-03-21 14:21:59 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 1.2366
2022-03-21 14:22:36 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 0.9892
2022-03-21 14:23:14 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 1.0394
2022-03-21 14:23:16 - train: epoch 099, train_loss: 1.0147
2022-03-21 14:24:33 - eval: epoch: 099, acc1: 74.466%, acc5: 92.038%, test_loss: 1.0060, per_image_load_time: 1.879ms, per_image_inference_time: 0.717ms
2022-03-21 14:24:34 - until epoch: 099, best_acc1: 74.480%
2022-03-21 14:24:34 - epoch 100 lr: 0.00010000000000000003
2022-03-21 14:25:18 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 0.9927
2022-03-21 14:25:55 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 1.0739
2022-03-21 14:26:33 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 0.9219
2022-03-21 14:27:10 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 0.7705
2022-03-21 14:27:48 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 1.0310
2022-03-21 14:28:25 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 1.1487
2022-03-21 14:29:02 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 0.8653
2022-03-21 14:29:40 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 1.0728
2022-03-21 14:30:18 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 0.8816
2022-03-21 14:30:55 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 1.0220
2022-03-21 14:31:33 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 0.9493
2022-03-21 14:32:10 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 1.0163
2022-03-21 14:32:48 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 1.0481
2022-03-21 14:33:26 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 1.0355
2022-03-21 14:34:04 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 1.0835
2022-03-21 14:34:41 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 0.9971
2022-03-21 14:35:19 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 1.0509
2022-03-21 14:35:57 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 1.0636
2022-03-21 14:36:35 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 0.9629
2022-03-21 14:37:13 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 1.0073
2022-03-21 14:37:51 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 0.8997
2022-03-21 14:38:29 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 1.1996
2022-03-21 14:39:06 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 1.0078
2022-03-21 14:39:44 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 0.9534
2022-03-21 14:40:22 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 1.0390
2022-03-21 14:41:00 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 1.0378
2022-03-21 14:41:38 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 0.9256
2022-03-21 14:42:16 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 1.0169
2022-03-21 14:42:54 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 1.1042
2022-03-21 14:43:32 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 0.9655
2022-03-21 14:44:10 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 0.9672
2022-03-21 14:44:48 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 1.1107
2022-03-21 14:45:26 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 1.1299
2022-03-21 14:46:04 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 1.1291
2022-03-21 14:46:42 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 0.8180
2022-03-21 14:47:20 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 1.0171
2022-03-21 14:47:58 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 0.9809
2022-03-21 14:48:36 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 1.0536
2022-03-21 14:49:14 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 1.0861
2022-03-21 14:49:52 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 0.9722
2022-03-21 14:50:30 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 1.1258
2022-03-21 14:51:08 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 1.0644
2022-03-21 14:51:46 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 1.0213
2022-03-21 14:52:24 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 1.2193
2022-03-21 14:53:02 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 1.0158
2022-03-21 14:53:40 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 0.7638
2022-03-21 14:54:18 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 1.0030
2022-03-21 14:54:56 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 0.8597
2022-03-21 14:55:34 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 0.9553
2022-03-21 14:56:12 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 1.1104
2022-03-21 14:56:14 - train: epoch 100, train_loss: 1.0133
2022-03-21 14:57:31 - eval: epoch: 100, acc1: 74.496%, acc5: 92.050%, test_loss: 1.0053, per_image_load_time: 1.769ms, per_image_inference_time: 0.725ms
2022-03-21 14:57:33 - until epoch: 100, best_acc1: 74.496%
2022-03-21 14:57:33 - train done. model: yoloxxbackbone, train time: 54.812 hours, best_acc1: 74.496%
