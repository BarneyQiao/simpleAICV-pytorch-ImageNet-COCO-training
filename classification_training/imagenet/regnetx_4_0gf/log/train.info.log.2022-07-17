2022-07-17 23:03:02 - train: epoch 0025, iter [03700, 05004], lr: 0.179440, loss: 1.8391
2022-07-17 23:05:20 - train: epoch 0025, iter [03800, 05004], lr: 0.179400, loss: 1.9392
2022-07-17 23:07:37 - train: epoch 0025, iter [03900, 05004], lr: 0.179360, loss: 1.8905
2022-07-17 23:09:54 - train: epoch 0025, iter [04000, 05004], lr: 0.179320, loss: 2.0552
2022-07-17 23:12:12 - train: epoch 0025, iter [04100, 05004], lr: 0.179280, loss: 2.1235
2022-07-17 23:14:29 - train: epoch 0025, iter [04200, 05004], lr: 0.179239, loss: 1.9533
2022-07-17 23:16:46 - train: epoch 0025, iter [04300, 05004], lr: 0.179199, loss: 1.7212
2022-07-17 23:19:04 - train: epoch 0025, iter [04400, 05004], lr: 0.179159, loss: 1.7691
2022-07-17 23:21:21 - train: epoch 0025, iter [04500, 05004], lr: 0.179118, loss: 1.9426
2022-07-17 23:23:37 - train: epoch 0025, iter [04600, 05004], lr: 0.179078, loss: 1.6403
2022-07-17 23:25:54 - train: epoch 0025, iter [04700, 05004], lr: 0.179037, loss: 1.6399
2022-07-17 23:28:11 - train: epoch 0025, iter [04800, 05004], lr: 0.178997, loss: 1.6271
2022-07-17 23:30:28 - train: epoch 0025, iter [04900, 05004], lr: 0.178956, loss: 1.8289
2022-07-17 23:32:45 - train: epoch 0025, iter [05000, 05004], lr: 0.178916, loss: 2.1071
2022-07-17 23:32:52 - train: epoch 025, train_loss: 1.8239
2022-07-17 23:34:59 - eval: epoch: 025, acc1: 61.974%, acc5: 85.028%, test_loss: 1.5812, per_image_load_time: 0.982ms, per_image_inference_time: 3.913ms
2022-07-17 23:34:59 - until epoch: 025, best_acc1: 62.722%
2022-07-17 23:34:59 - epoch 026 lr: 0.178914
2022-07-17 23:37:24 - train: epoch 0026, iter [00100, 05004], lr: 0.178873, loss: 1.6805
2022-07-17 23:39:41 - train: epoch 0026, iter [00200, 05004], lr: 0.178833, loss: 1.6947
2022-07-17 23:41:58 - train: epoch 0026, iter [00300, 05004], lr: 0.178792, loss: 1.8977
2022-07-17 23:44:15 - train: epoch 0026, iter [00400, 05004], lr: 0.178751, loss: 1.6878
2022-07-17 23:46:31 - train: epoch 0026, iter [00500, 05004], lr: 0.178711, loss: 1.7245
2022-07-17 23:48:48 - train: epoch 0026, iter [00600, 05004], lr: 0.178670, loss: 2.1926
2022-07-17 23:51:05 - train: epoch 0026, iter [00700, 05004], lr: 0.178629, loss: 1.8570
2022-07-17 23:53:22 - train: epoch 0026, iter [00800, 05004], lr: 0.178588, loss: 1.5751
2022-07-17 23:55:39 - train: epoch 0026, iter [00900, 05004], lr: 0.178547, loss: 1.7897
2022-07-17 23:57:56 - train: epoch 0026, iter [01000, 05004], lr: 0.178506, loss: 1.7576
2022-07-18 00:00:12 - train: epoch 0026, iter [01100, 05004], lr: 0.178465, loss: 1.7951
2022-07-18 00:02:29 - train: epoch 0026, iter [01200, 05004], lr: 0.178424, loss: 2.0780
2022-07-18 00:04:46 - train: epoch 0026, iter [01300, 05004], lr: 0.178383, loss: 1.6785
2022-07-18 00:07:03 - train: epoch 0026, iter [01400, 05004], lr: 0.178342, loss: 1.8609
2022-07-18 00:09:20 - train: epoch 0026, iter [01500, 05004], lr: 0.178301, loss: 1.5768
2022-07-18 00:11:37 - train: epoch 0026, iter [01600, 05004], lr: 0.178260, loss: 1.8308
2022-07-18 00:13:54 - train: epoch 0026, iter [01700, 05004], lr: 0.178219, loss: 1.7349
2022-07-18 00:16:11 - train: epoch 0026, iter [01800, 05004], lr: 0.178178, loss: 1.9924
2022-07-18 00:18:27 - train: epoch 0026, iter [01900, 05004], lr: 0.178137, loss: 1.9237
2022-07-18 00:20:44 - train: epoch 0026, iter [02000, 05004], lr: 0.178095, loss: 1.9092
2022-07-18 00:23:01 - train: epoch 0026, iter [02100, 05004], lr: 0.178054, loss: 1.9751
2022-07-18 00:25:18 - train: epoch 0026, iter [02200, 05004], lr: 0.178013, loss: 1.8177
2022-07-18 00:27:35 - train: epoch 0026, iter [02300, 05004], lr: 0.177971, loss: 1.8219
2022-07-18 00:29:52 - train: epoch 0026, iter [02400, 05004], lr: 0.177930, loss: 1.9118
2022-07-18 00:32:09 - train: epoch 0026, iter [02500, 05004], lr: 0.177889, loss: 1.8734
2022-07-18 00:34:26 - train: epoch 0026, iter [02600, 05004], lr: 0.177847, loss: 1.5987
2022-07-18 00:36:43 - train: epoch 0026, iter [02700, 05004], lr: 0.177806, loss: 1.9771
2022-07-18 00:39:00 - train: epoch 0026, iter [02800, 05004], lr: 0.177764, loss: 1.8167
2022-07-18 00:41:17 - train: epoch 0026, iter [02900, 05004], lr: 0.177722, loss: 1.9889
2022-07-18 00:43:34 - train: epoch 0026, iter [03000, 05004], lr: 0.177681, loss: 1.8674
2022-07-18 00:45:51 - train: epoch 0026, iter [03100, 05004], lr: 0.177639, loss: 1.8473
2022-07-18 00:48:08 - train: epoch 0026, iter [03200, 05004], lr: 0.177598, loss: 1.9538
2022-07-18 00:50:25 - train: epoch 0026, iter [03300, 05004], lr: 0.177556, loss: 1.9763
2022-07-18 00:52:42 - train: epoch 0026, iter [03400, 05004], lr: 0.177514, loss: 2.2299
2022-07-18 00:54:59 - train: epoch 0026, iter [03500, 05004], lr: 0.177472, loss: 1.8428
2022-07-18 00:57:16 - train: epoch 0026, iter [03600, 05004], lr: 0.177431, loss: 1.6987
2022-07-18 00:59:33 - train: epoch 0026, iter [03700, 05004], lr: 0.177389, loss: 1.7083
2022-07-18 01:01:50 - train: epoch 0026, iter [03800, 05004], lr: 0.177347, loss: 1.9711
2022-07-18 01:04:07 - train: epoch 0026, iter [03900, 05004], lr: 0.177305, loss: 1.9480
2022-07-18 01:06:24 - train: epoch 0026, iter [04000, 05004], lr: 0.177263, loss: 1.8719
2022-07-18 01:08:41 - train: epoch 0026, iter [04100, 05004], lr: 0.177221, loss: 1.8980
2022-07-18 01:10:58 - train: epoch 0026, iter [04200, 05004], lr: 0.177179, loss: 1.8387
2022-07-18 01:13:15 - train: epoch 0026, iter [04300, 05004], lr: 0.177137, loss: 1.9831
2022-07-18 01:15:32 - train: epoch 0026, iter [04400, 05004], lr: 0.177095, loss: 2.0264
2022-07-18 01:17:49 - train: epoch 0026, iter [04500, 05004], lr: 0.177053, loss: 1.9347
2022-07-18 01:20:06 - train: epoch 0026, iter [04600, 05004], lr: 0.177011, loss: 1.8404
2022-07-18 01:22:23 - train: epoch 0026, iter [04700, 05004], lr: 0.176969, loss: 1.7246
2022-07-18 01:24:40 - train: epoch 0026, iter [04800, 05004], lr: 0.176926, loss: 1.6843
2022-07-18 01:26:57 - train: epoch 0026, iter [04900, 05004], lr: 0.176884, loss: 1.8604
2022-07-18 01:29:14 - train: epoch 0026, iter [05000, 05004], lr: 0.176842, loss: 1.8831
2022-07-18 01:29:21 - train: epoch 026, train_loss: 1.8117
2022-07-18 01:31:30 - eval: epoch: 026, acc1: 62.792%, acc5: 85.578%, test_loss: 1.5383, per_image_load_time: 1.084ms, per_image_inference_time: 3.918ms
2022-07-18 01:31:30 - until epoch: 026, best_acc1: 62.792%
2022-07-18 01:31:30 - epoch 027 lr: 0.176840
2022-07-18 01:33:55 - train: epoch 0027, iter [00100, 05004], lr: 0.176798, loss: 1.8246
2022-07-18 01:36:12 - train: epoch 0027, iter [00200, 05004], lr: 0.176755, loss: 1.7157
2022-07-18 01:38:30 - train: epoch 0027, iter [00300, 05004], lr: 0.176713, loss: 1.9012
2022-07-18 01:40:47 - train: epoch 0027, iter [00400, 05004], lr: 0.176671, loss: 1.8051
2022-07-18 01:43:04 - train: epoch 0027, iter [00500, 05004], lr: 0.176628, loss: 1.7503
2022-07-18 01:45:21 - train: epoch 0027, iter [00600, 05004], lr: 0.176586, loss: 2.0357
2022-07-18 01:47:38 - train: epoch 0027, iter [00700, 05004], lr: 0.176543, loss: 1.7902
2022-07-18 01:49:55 - train: epoch 0027, iter [00800, 05004], lr: 0.176501, loss: 1.8525
2022-07-18 01:52:12 - train: epoch 0027, iter [00900, 05004], lr: 0.176458, loss: 1.7550
2022-07-18 01:54:29 - train: epoch 0027, iter [01000, 05004], lr: 0.176416, loss: 1.8050
2022-07-18 01:56:47 - train: epoch 0027, iter [01100, 05004], lr: 0.176373, loss: 1.7598
2022-07-18 01:59:04 - train: epoch 0027, iter [01200, 05004], lr: 0.176330, loss: 1.8504
2022-07-18 02:01:21 - train: epoch 0027, iter [01300, 05004], lr: 0.176287, loss: 1.9467
2022-07-18 02:03:38 - train: epoch 0027, iter [01400, 05004], lr: 0.176245, loss: 1.9710
2022-07-18 02:05:55 - train: epoch 0027, iter [01500, 05004], lr: 0.176202, loss: 1.9589
2022-07-18 02:08:12 - train: epoch 0027, iter [01600, 05004], lr: 0.176159, loss: 1.8101
2022-07-18 02:10:29 - train: epoch 0027, iter [01700, 05004], lr: 0.176116, loss: 1.6989
2022-07-18 02:12:46 - train: epoch 0027, iter [01800, 05004], lr: 0.176073, loss: 1.7110
2022-07-18 02:15:03 - train: epoch 0027, iter [01900, 05004], lr: 0.176031, loss: 1.9454
2022-07-18 02:17:20 - train: epoch 0027, iter [02000, 05004], lr: 0.175988, loss: 1.6228
2022-07-18 02:19:37 - train: epoch 0027, iter [02100, 05004], lr: 0.175945, loss: 1.8543
2022-07-18 02:21:54 - train: epoch 0027, iter [02200, 05004], lr: 0.175902, loss: 1.8804
2022-07-18 02:24:11 - train: epoch 0027, iter [02300, 05004], lr: 0.175859, loss: 1.9690
2022-07-18 02:26:29 - train: epoch 0027, iter [02400, 05004], lr: 0.175815, loss: 1.7159
2022-07-18 02:28:46 - train: epoch 0027, iter [02500, 05004], lr: 0.175772, loss: 1.8102
2022-07-18 02:31:03 - train: epoch 0027, iter [02600, 05004], lr: 0.175729, loss: 1.8783
2022-07-18 02:33:20 - train: epoch 0027, iter [02700, 05004], lr: 0.175686, loss: 1.8427
2022-07-18 02:35:37 - train: epoch 0027, iter [02800, 05004], lr: 0.175643, loss: 2.0055
2022-07-18 02:37:55 - train: epoch 0027, iter [02900, 05004], lr: 0.175600, loss: 2.1244
2022-07-18 02:40:12 - train: epoch 0027, iter [03000, 05004], lr: 0.175556, loss: 1.7170
2022-07-18 02:42:29 - train: epoch 0027, iter [03100, 05004], lr: 0.175513, loss: 1.7384
2022-07-18 02:44:46 - train: epoch 0027, iter [03200, 05004], lr: 0.175470, loss: 1.5951
2022-07-18 02:47:03 - train: epoch 0027, iter [03300, 05004], lr: 0.175426, loss: 2.0246
2022-07-18 02:49:21 - train: epoch 0027, iter [03400, 05004], lr: 0.175383, loss: 1.8020
2022-07-18 02:51:38 - train: epoch 0027, iter [03500, 05004], lr: 0.175339, loss: 1.8837
2022-07-18 02:53:55 - train: epoch 0027, iter [03600, 05004], lr: 0.175296, loss: 1.9154
2022-07-18 02:56:12 - train: epoch 0027, iter [03700, 05004], lr: 0.175252, loss: 1.7251
2022-07-18 02:58:29 - train: epoch 0027, iter [03800, 05004], lr: 0.175209, loss: 1.6013
2022-07-18 03:00:46 - train: epoch 0027, iter [03900, 05004], lr: 0.175165, loss: 1.8301
2022-07-18 03:03:04 - train: epoch 0027, iter [04000, 05004], lr: 0.175122, loss: 1.7885
2022-07-18 03:05:21 - train: epoch 0027, iter [04100, 05004], lr: 0.175078, loss: 1.9412
2022-07-18 03:07:38 - train: epoch 0027, iter [04200, 05004], lr: 0.175034, loss: 1.6362
2022-07-18 03:09:55 - train: epoch 0027, iter [04300, 05004], lr: 0.174991, loss: 1.8988
2022-07-18 03:12:12 - train: epoch 0027, iter [04400, 05004], lr: 0.174947, loss: 1.7358
2022-07-18 03:14:30 - train: epoch 0027, iter [04500, 05004], lr: 0.174903, loss: 1.7846
2022-07-18 03:16:47 - train: epoch 0027, iter [04600, 05004], lr: 0.174859, loss: 1.6661
2022-07-18 03:19:04 - train: epoch 0027, iter [04700, 05004], lr: 0.174816, loss: 1.9991
2022-07-18 03:21:21 - train: epoch 0027, iter [04800, 05004], lr: 0.174772, loss: 1.8233
2022-07-18 03:23:38 - train: epoch 0027, iter [04900, 05004], lr: 0.174728, loss: 1.5949
2022-07-18 03:25:55 - train: epoch 0027, iter [05000, 05004], lr: 0.174684, loss: 1.4134
2022-07-18 03:26:01 - train: epoch 027, train_loss: 1.7978
2022-07-18 03:28:11 - eval: epoch: 027, acc1: 62.994%, acc5: 85.836%, test_loss: 1.5204, per_image_load_time: 1.075ms, per_image_inference_time: 3.925ms
2022-07-18 03:28:11 - until epoch: 027, best_acc1: 62.994%
2022-07-18 03:28:11 - epoch 028 lr: 0.174682
2022-07-18 03:30:36 - train: epoch 0028, iter [00100, 05004], lr: 0.174638, loss: 1.6247
2022-07-18 03:32:52 - train: epoch 0028, iter [00200, 05004], lr: 0.174594, loss: 1.6555
2022-07-18 03:35:09 - train: epoch 0028, iter [00300, 05004], lr: 0.174550, loss: 1.7886
2022-07-18 03:37:26 - train: epoch 0028, iter [00400, 05004], lr: 0.174506, loss: 1.8951
2022-07-18 03:39:43 - train: epoch 0028, iter [00500, 05004], lr: 0.174462, loss: 1.6108
2022-07-18 03:42:00 - train: epoch 0028, iter [00600, 05004], lr: 0.174418, loss: 1.8536
2022-07-18 03:44:17 - train: epoch 0028, iter [00700, 05004], lr: 0.174374, loss: 1.9162
2022-07-18 03:46:34 - train: epoch 0028, iter [00800, 05004], lr: 0.174330, loss: 1.4660
2022-07-18 03:48:51 - train: epoch 0028, iter [00900, 05004], lr: 0.174285, loss: 1.7513
2022-07-18 03:51:08 - train: epoch 0028, iter [01000, 05004], lr: 0.174241, loss: 2.0215
2022-07-18 03:53:25 - train: epoch 0028, iter [01100, 05004], lr: 0.174197, loss: 1.6899
2022-07-18 03:55:42 - train: epoch 0028, iter [01200, 05004], lr: 0.174152, loss: 1.6165
2022-07-18 03:57:59 - train: epoch 0028, iter [01300, 05004], lr: 0.174108, loss: 1.6762
2022-07-18 04:00:16 - train: epoch 0028, iter [01400, 05004], lr: 0.174064, loss: 2.0046
2022-07-18 04:02:33 - train: epoch 0028, iter [01500, 05004], lr: 0.174019, loss: 1.6010
2022-07-18 04:04:50 - train: epoch 0028, iter [01600, 05004], lr: 0.173975, loss: 1.6565
2022-07-18 04:07:07 - train: epoch 0028, iter [01700, 05004], lr: 0.173930, loss: 1.8205
2022-07-18 04:09:24 - train: epoch 0028, iter [01800, 05004], lr: 0.173886, loss: 1.7391
2022-07-18 04:11:41 - train: epoch 0028, iter [01900, 05004], lr: 0.173841, loss: 1.9747
2022-07-18 04:13:58 - train: epoch 0028, iter [02000, 05004], lr: 0.173797, loss: 1.6683
2022-07-18 04:16:15 - train: epoch 0028, iter [02100, 05004], lr: 0.173752, loss: 1.8095
2022-07-18 04:18:32 - train: epoch 0028, iter [02200, 05004], lr: 0.173707, loss: 1.7992
2022-07-18 04:20:49 - train: epoch 0028, iter [02300, 05004], lr: 0.173663, loss: 1.8546
2022-07-18 04:23:06 - train: epoch 0028, iter [02400, 05004], lr: 0.173618, loss: 1.9332
2022-07-18 04:25:23 - train: epoch 0028, iter [02500, 05004], lr: 0.173573, loss: 1.6644
2022-07-18 04:27:40 - train: epoch 0028, iter [02600, 05004], lr: 0.173529, loss: 1.7896
2022-07-18 04:29:57 - train: epoch 0028, iter [02700, 05004], lr: 0.173484, loss: 1.8463
2022-07-18 04:32:14 - train: epoch 0028, iter [02800, 05004], lr: 0.173439, loss: 1.8396
2022-07-18 04:34:31 - train: epoch 0028, iter [02900, 05004], lr: 0.173394, loss: 1.8408
2022-07-18 04:36:48 - train: epoch 0028, iter [03000, 05004], lr: 0.173349, loss: 1.7912
2022-07-18 04:39:05 - train: epoch 0028, iter [03100, 05004], lr: 0.173304, loss: 1.8306
2022-07-18 04:41:22 - train: epoch 0028, iter [03200, 05004], lr: 0.173259, loss: 1.6058
2022-07-18 04:43:39 - train: epoch 0028, iter [03300, 05004], lr: 0.173214, loss: 1.8191
2022-07-18 04:45:56 - train: epoch 0028, iter [03400, 05004], lr: 0.173169, loss: 1.9529
2022-07-18 04:48:13 - train: epoch 0028, iter [03500, 05004], lr: 0.173124, loss: 1.7282
2022-07-18 04:50:30 - train: epoch 0028, iter [03600, 05004], lr: 0.173079, loss: 1.9009
2022-07-18 04:52:47 - train: epoch 0028, iter [03700, 05004], lr: 0.173034, loss: 1.7918
2022-07-18 04:55:04 - train: epoch 0028, iter [03800, 05004], lr: 0.172989, loss: 1.4645
2022-07-18 04:57:22 - train: epoch 0028, iter [03900, 05004], lr: 0.172944, loss: 1.8882
2022-07-18 04:59:39 - train: epoch 0028, iter [04000, 05004], lr: 0.172898, loss: 1.9714
2022-07-18 05:01:56 - train: epoch 0028, iter [04100, 05004], lr: 0.172853, loss: 1.6827
2022-07-18 05:04:13 - train: epoch 0028, iter [04200, 05004], lr: 0.172808, loss: 1.9224
2022-07-18 05:06:30 - train: epoch 0028, iter [04300, 05004], lr: 0.172762, loss: 1.8088
2022-07-18 05:08:47 - train: epoch 0028, iter [04400, 05004], lr: 0.172717, loss: 1.6479
2022-07-18 05:11:04 - train: epoch 0028, iter [04500, 05004], lr: 0.172672, loss: 1.7415
2022-07-18 05:13:22 - train: epoch 0028, iter [04600, 05004], lr: 0.172626, loss: 1.9402
2022-07-18 05:15:39 - train: epoch 0028, iter [04700, 05004], lr: 0.172581, loss: 1.9386
2022-07-18 05:17:56 - train: epoch 0028, iter [04800, 05004], lr: 0.172535, loss: 1.7414
2022-07-18 05:20:13 - train: epoch 0028, iter [04900, 05004], lr: 0.172490, loss: 1.6551
2022-07-18 05:22:30 - train: epoch 0028, iter [05000, 05004], lr: 0.172444, loss: 1.5175
2022-07-18 05:22:37 - train: epoch 028, train_loss: 1.7904
2022-07-18 05:24:44 - eval: epoch: 028, acc1: 63.004%, acc5: 85.672%, test_loss: 1.5321, per_image_load_time: 0.987ms, per_image_inference_time: 3.917ms
2022-07-18 05:24:44 - until epoch: 028, best_acc1: 63.004%
2022-07-18 05:24:44 - epoch 029 lr: 0.172442
2022-07-18 05:27:09 - train: epoch 0029, iter [00100, 05004], lr: 0.172397, loss: 1.7919
2022-07-18 05:29:26 - train: epoch 0029, iter [00200, 05004], lr: 0.172351, loss: 1.6036
2022-07-18 05:31:43 - train: epoch 0029, iter [00300, 05004], lr: 0.172306, loss: 2.0839
2022-07-18 05:34:00 - train: epoch 0029, iter [00400, 05004], lr: 0.172260, loss: 1.7980
2022-07-18 05:36:17 - train: epoch 0029, iter [00500, 05004], lr: 0.172214, loss: 1.7386
2022-07-18 05:38:34 - train: epoch 0029, iter [00600, 05004], lr: 0.172169, loss: 1.9771
2022-07-18 05:40:51 - train: epoch 0029, iter [00700, 05004], lr: 0.172123, loss: 1.5362
2022-07-18 05:43:08 - train: epoch 0029, iter [00800, 05004], lr: 0.172077, loss: 1.7132
2022-07-18 05:45:25 - train: epoch 0029, iter [00900, 05004], lr: 0.172031, loss: 1.9060
2022-07-18 05:47:41 - train: epoch 0029, iter [01000, 05004], lr: 0.171985, loss: 1.6556
2022-07-18 05:49:58 - train: epoch 0029, iter [01100, 05004], lr: 0.171939, loss: 1.7417
2022-07-18 05:52:15 - train: epoch 0029, iter [01200, 05004], lr: 0.171894, loss: 1.6488
2022-07-18 05:54:32 - train: epoch 0029, iter [01300, 05004], lr: 0.171848, loss: 1.7526
2022-07-18 05:56:49 - train: epoch 0029, iter [01400, 05004], lr: 0.171802, loss: 1.9499
2022-07-18 05:59:06 - train: epoch 0029, iter [01500, 05004], lr: 0.171756, loss: 1.9306
2022-07-18 06:01:23 - train: epoch 0029, iter [01600, 05004], lr: 0.171710, loss: 1.6056
2022-07-18 06:03:40 - train: epoch 0029, iter [01700, 05004], lr: 0.171664, loss: 1.7802
2022-07-18 06:05:57 - train: epoch 0029, iter [01800, 05004], lr: 0.171617, loss: 1.7533
2022-07-18 06:08:14 - train: epoch 0029, iter [01900, 05004], lr: 0.171571, loss: 1.6302
2022-07-18 06:10:31 - train: epoch 0029, iter [02000, 05004], lr: 0.171525, loss: 1.8642
2022-07-18 06:12:48 - train: epoch 0029, iter [02100, 05004], lr: 0.171479, loss: 1.7277
2022-07-18 06:15:05 - train: epoch 0029, iter [02200, 05004], lr: 0.171433, loss: 1.8795
2022-07-18 06:17:22 - train: epoch 0029, iter [02300, 05004], lr: 0.171386, loss: 1.9620
2022-07-18 06:19:39 - train: epoch 0029, iter [02400, 05004], lr: 0.171340, loss: 1.6944
2022-07-18 06:21:56 - train: epoch 0029, iter [02500, 05004], lr: 0.171294, loss: 1.6590
2022-07-18 06:24:13 - train: epoch 0029, iter [02600, 05004], lr: 0.171247, loss: 1.9323
2022-07-18 06:26:30 - train: epoch 0029, iter [02700, 05004], lr: 0.171201, loss: 1.7327
2022-07-18 06:28:47 - train: epoch 0029, iter [02800, 05004], lr: 0.171155, loss: 1.7616
2022-07-18 06:31:04 - train: epoch 0029, iter [02900, 05004], lr: 0.171108, loss: 1.7413
2022-07-18 06:33:21 - train: epoch 0029, iter [03000, 05004], lr: 0.171062, loss: 1.5940
2022-07-18 06:35:38 - train: epoch 0029, iter [03100, 05004], lr: 0.171015, loss: 1.7959
2022-07-18 06:37:55 - train: epoch 0029, iter [03200, 05004], lr: 0.170969, loss: 1.7868
2022-07-18 06:40:12 - train: epoch 0029, iter [03300, 05004], lr: 0.170922, loss: 1.6938
2022-07-18 06:42:29 - train: epoch 0029, iter [03400, 05004], lr: 0.170875, loss: 1.7094
2022-07-18 06:44:46 - train: epoch 0029, iter [03500, 05004], lr: 0.170829, loss: 1.8137
2022-07-18 06:47:03 - train: epoch 0029, iter [03600, 05004], lr: 0.170782, loss: 1.7062
2022-07-18 06:49:20 - train: epoch 0029, iter [03700, 05004], lr: 0.170735, loss: 1.8767
2022-07-18 06:51:37 - train: epoch 0029, iter [03800, 05004], lr: 0.170689, loss: 1.8220
2022-07-18 06:53:54 - train: epoch 0029, iter [03900, 05004], lr: 0.170642, loss: 1.7200
2022-07-18 06:56:10 - train: epoch 0029, iter [04000, 05004], lr: 0.170595, loss: 1.7357
2022-07-18 06:58:27 - train: epoch 0029, iter [04100, 05004], lr: 0.170548, loss: 1.8088
2022-07-18 07:00:44 - train: epoch 0029, iter [04200, 05004], lr: 0.170501, loss: 1.5580
2022-07-18 07:03:01 - train: epoch 0029, iter [04300, 05004], lr: 0.170455, loss: 1.7473
2022-07-18 07:05:18 - train: epoch 0029, iter [04400, 05004], lr: 0.170408, loss: 1.7284
2022-07-18 07:07:35 - train: epoch 0029, iter [04500, 05004], lr: 0.170361, loss: 1.8244
2022-07-18 07:09:52 - train: epoch 0029, iter [04600, 05004], lr: 0.170314, loss: 1.7803
2022-07-18 07:12:09 - train: epoch 0029, iter [04700, 05004], lr: 0.170267, loss: 1.5114
2022-07-18 07:14:25 - train: epoch 0029, iter [04800, 05004], lr: 0.170220, loss: 1.7732
2022-07-18 07:16:42 - train: epoch 0029, iter [04900, 05004], lr: 0.170173, loss: 1.9137
2022-07-18 07:18:59 - train: epoch 0029, iter [05000, 05004], lr: 0.170126, loss: 1.4185
2022-07-18 07:19:06 - train: epoch 029, train_loss: 1.7777
2022-07-18 07:21:18 - eval: epoch: 029, acc1: 63.158%, acc5: 85.834%, test_loss: 1.5213, per_image_load_time: 1.100ms, per_image_inference_time: 3.934ms
2022-07-18 07:21:18 - until epoch: 029, best_acc1: 63.158%
2022-07-18 07:21:18 - epoch 030 lr: 0.170123
2022-07-18 07:23:44 - train: epoch 0030, iter [00100, 05004], lr: 0.170077, loss: 1.6569
2022-07-18 07:26:01 - train: epoch 0030, iter [00200, 05004], lr: 0.170029, loss: 1.9401
2022-07-18 07:28:17 - train: epoch 0030, iter [00300, 05004], lr: 0.169982, loss: 1.6942
2022-07-18 07:30:34 - train: epoch 0030, iter [00400, 05004], lr: 0.169935, loss: 1.4494
2022-07-18 07:32:51 - train: epoch 0030, iter [00500, 05004], lr: 0.169888, loss: 1.8896
2022-07-18 07:35:08 - train: epoch 0030, iter [00600, 05004], lr: 0.169840, loss: 1.6758
2022-07-18 07:37:25 - train: epoch 0030, iter [00700, 05004], lr: 0.169793, loss: 1.8551
2022-07-18 07:39:42 - train: epoch 0030, iter [00800, 05004], lr: 0.169746, loss: 1.7660
2022-07-18 07:41:59 - train: epoch 0030, iter [00900, 05004], lr: 0.169698, loss: 1.7794
2022-07-18 07:44:16 - train: epoch 0030, iter [01000, 05004], lr: 0.169651, loss: 1.6732
2022-07-18 07:46:33 - train: epoch 0030, iter [01100, 05004], lr: 0.169604, loss: 1.7119
2022-07-18 07:48:50 - train: epoch 0030, iter [01200, 05004], lr: 0.169556, loss: 1.6955
2022-07-18 07:51:06 - train: epoch 0030, iter [01300, 05004], lr: 0.169509, loss: 1.5078
2022-07-18 07:53:23 - train: epoch 0030, iter [01400, 05004], lr: 0.169461, loss: 1.7419
2022-07-18 07:55:40 - train: epoch 0030, iter [01500, 05004], lr: 0.169414, loss: 1.8589
2022-07-18 07:57:57 - train: epoch 0030, iter [01600, 05004], lr: 0.169366, loss: 1.8258
2022-07-18 08:00:14 - train: epoch 0030, iter [01700, 05004], lr: 0.169318, loss: 1.9716
2022-07-18 08:02:31 - train: epoch 0030, iter [01800, 05004], lr: 0.169271, loss: 1.7191
2022-07-18 08:04:48 - train: epoch 0030, iter [01900, 05004], lr: 0.169223, loss: 1.9256
2022-07-18 08:07:05 - train: epoch 0030, iter [02000, 05004], lr: 0.169175, loss: 1.5944
2022-07-18 08:09:22 - train: epoch 0030, iter [02100, 05004], lr: 0.169128, loss: 1.9294
2022-07-18 08:11:39 - train: epoch 0030, iter [02200, 05004], lr: 0.169080, loss: 1.8274
2022-07-18 08:13:56 - train: epoch 0030, iter [02300, 05004], lr: 0.169032, loss: 1.8398
2022-07-18 08:16:13 - train: epoch 0030, iter [02400, 05004], lr: 0.168984, loss: 1.7996
2022-07-18 08:18:30 - train: epoch 0030, iter [02500, 05004], lr: 0.168936, loss: 1.5787
2022-07-18 08:20:47 - train: epoch 0030, iter [02600, 05004], lr: 0.168888, loss: 1.6255
2022-07-18 08:23:04 - train: epoch 0030, iter [02700, 05004], lr: 0.168840, loss: 2.0262
2022-07-18 08:25:20 - train: epoch 0030, iter [02800, 05004], lr: 0.168793, loss: 1.9354
2022-07-18 08:27:37 - train: epoch 0030, iter [02900, 05004], lr: 0.168745, loss: 1.7625
2022-07-18 08:29:54 - train: epoch 0030, iter [03000, 05004], lr: 0.168697, loss: 2.0179
2022-07-18 08:32:11 - train: epoch 0030, iter [03100, 05004], lr: 0.168649, loss: 1.7743
2022-07-18 08:34:28 - train: epoch 0030, iter [03200, 05004], lr: 0.168600, loss: 1.7563
2022-07-18 08:36:45 - train: epoch 0030, iter [03300, 05004], lr: 0.168552, loss: 2.0569
2022-07-18 08:39:02 - train: epoch 0030, iter [03400, 05004], lr: 0.168504, loss: 1.7034
2022-07-18 08:41:19 - train: epoch 0030, iter [03500, 05004], lr: 0.168456, loss: 1.6439
2022-07-18 08:43:36 - train: epoch 0030, iter [03600, 05004], lr: 0.168408, loss: 1.8680
2022-07-18 08:45:53 - train: epoch 0030, iter [03700, 05004], lr: 0.168360, loss: 1.7334
2022-07-18 08:48:10 - train: epoch 0030, iter [03800, 05004], lr: 0.168311, loss: 1.7018
2022-07-18 08:50:27 - train: epoch 0030, iter [03900, 05004], lr: 0.168263, loss: 1.7340
2022-07-18 08:52:44 - train: epoch 0030, iter [04000, 05004], lr: 0.168215, loss: 1.6245
2022-07-18 08:55:01 - train: epoch 0030, iter [04100, 05004], lr: 0.168166, loss: 1.8497
2022-07-18 08:57:18 - train: epoch 0030, iter [04200, 05004], lr: 0.168118, loss: 1.9525
2022-07-18 08:59:35 - train: epoch 0030, iter [04300, 05004], lr: 0.168070, loss: 1.7447
2022-07-18 09:01:52 - train: epoch 0030, iter [04400, 05004], lr: 0.168021, loss: 1.7515
2022-07-18 09:04:09 - train: epoch 0030, iter [04500, 05004], lr: 0.167973, loss: 1.6531
2022-07-18 09:06:26 - train: epoch 0030, iter [04600, 05004], lr: 0.167924, loss: 1.5163
2022-07-18 09:08:43 - train: epoch 0030, iter [04700, 05004], lr: 0.167876, loss: 1.7436
2022-07-18 09:11:01 - train: epoch 0030, iter [04800, 05004], lr: 0.167827, loss: 1.8451
2022-07-18 09:13:18 - train: epoch 0030, iter [04900, 05004], lr: 0.167779, loss: 1.6462
2022-07-18 09:15:35 - train: epoch 0030, iter [05000, 05004], lr: 0.167730, loss: 1.8573
2022-07-18 09:15:41 - train: epoch 030, train_loss: 1.7686
2022-07-18 09:17:49 - eval: epoch: 030, acc1: 63.186%, acc5: 85.752%, test_loss: 1.5326, per_image_load_time: 0.934ms, per_image_inference_time: 3.920ms
2022-07-18 09:17:49 - until epoch: 030, best_acc1: 63.186%
2022-07-18 09:17:49 - epoch 031 lr: 0.167728
2022-07-18 09:20:14 - train: epoch 0031, iter [00100, 05004], lr: 0.167680, loss: 1.9226
2022-07-18 09:22:31 - train: epoch 0031, iter [00200, 05004], lr: 0.167631, loss: 1.6935
2022-07-18 09:24:48 - train: epoch 0031, iter [00300, 05004], lr: 0.167582, loss: 1.6914
2022-07-18 09:27:05 - train: epoch 0031, iter [00400, 05004], lr: 0.167533, loss: 1.7101
2022-07-18 09:29:22 - train: epoch 0031, iter [00500, 05004], lr: 0.167485, loss: 1.7193
2022-07-18 09:31:39 - train: epoch 0031, iter [00600, 05004], lr: 0.167436, loss: 1.6650
2022-07-18 09:33:56 - train: epoch 0031, iter [00700, 05004], lr: 0.167387, loss: 1.7452
2022-07-18 09:36:13 - train: epoch 0031, iter [00800, 05004], lr: 0.167338, loss: 1.8899
2022-07-18 09:38:30 - train: epoch 0031, iter [00900, 05004], lr: 0.167289, loss: 1.7556
2022-07-18 09:40:47 - train: epoch 0031, iter [01000, 05004], lr: 0.167240, loss: 1.9492
2022-07-18 09:43:04 - train: epoch 0031, iter [01100, 05004], lr: 0.167192, loss: 1.6466
2022-07-18 09:45:21 - train: epoch 0031, iter [01200, 05004], lr: 0.167143, loss: 1.8088
2022-07-18 09:47:38 - train: epoch 0031, iter [01300, 05004], lr: 0.167094, loss: 1.5347
2022-07-18 09:49:55 - train: epoch 0031, iter [01400, 05004], lr: 0.167045, loss: 1.7719
2022-07-18 09:52:12 - train: epoch 0031, iter [01500, 05004], lr: 0.166996, loss: 1.9122
2022-07-18 09:54:29 - train: epoch 0031, iter [01600, 05004], lr: 0.166946, loss: 1.6040
2022-07-18 09:56:46 - train: epoch 0031, iter [01700, 05004], lr: 0.166897, loss: 1.5776
2022-07-18 09:59:02 - train: epoch 0031, iter [01800, 05004], lr: 0.166848, loss: 1.5361
2022-07-18 10:01:19 - train: epoch 0031, iter [01900, 05004], lr: 0.166799, loss: 1.4820
2022-07-18 10:03:36 - train: epoch 0031, iter [02000, 05004], lr: 0.166750, loss: 1.8256
2022-07-18 10:05:53 - train: epoch 0031, iter [02100, 05004], lr: 0.166701, loss: 1.6573
2022-07-18 10:08:10 - train: epoch 0031, iter [02200, 05004], lr: 0.166651, loss: 1.7095
2022-07-18 10:10:27 - train: epoch 0031, iter [02300, 05004], lr: 0.166602, loss: 1.5375
2022-07-18 10:12:43 - train: epoch 0031, iter [02400, 05004], lr: 0.166553, loss: 1.7908
2022-07-18 10:15:00 - train: epoch 0031, iter [02500, 05004], lr: 0.166503, loss: 1.6676
2022-07-18 10:17:17 - train: epoch 0031, iter [02600, 05004], lr: 0.166454, loss: 1.6578
2022-07-18 10:19:34 - train: epoch 0031, iter [02700, 05004], lr: 0.166405, loss: 1.9044
2022-07-18 10:21:50 - train: epoch 0031, iter [02800, 05004], lr: 0.166355, loss: 2.0516
2022-07-18 10:24:07 - train: epoch 0031, iter [02900, 05004], lr: 0.166306, loss: 1.7935
2022-07-18 10:26:24 - train: epoch 0031, iter [03000, 05004], lr: 0.166256, loss: 2.0523
2022-07-18 10:28:41 - train: epoch 0031, iter [03100, 05004], lr: 0.166207, loss: 1.8671
2022-07-18 10:30:57 - train: epoch 0031, iter [03200, 05004], lr: 0.166157, loss: 1.8412
2022-07-18 10:33:14 - train: epoch 0031, iter [03300, 05004], lr: 0.166108, loss: 1.8836
2022-07-18 10:35:31 - train: epoch 0031, iter [03400, 05004], lr: 0.166058, loss: 1.7289
2022-07-18 10:37:48 - train: epoch 0031, iter [03500, 05004], lr: 0.166008, loss: 1.9314
2022-07-18 10:40:04 - train: epoch 0031, iter [03600, 05004], lr: 0.165959, loss: 1.8220
2022-07-18 10:42:21 - train: epoch 0031, iter [03700, 05004], lr: 0.165909, loss: 1.7759
2022-07-18 10:44:38 - train: epoch 0031, iter [03800, 05004], lr: 0.165859, loss: 1.8982
2022-07-18 10:46:54 - train: epoch 0031, iter [03900, 05004], lr: 0.165810, loss: 1.8270
2022-07-18 10:49:11 - train: epoch 0031, iter [04000, 05004], lr: 0.165760, loss: 1.7000
2022-07-18 10:51:28 - train: epoch 0031, iter [04100, 05004], lr: 0.165710, loss: 1.7084
2022-07-18 10:53:45 - train: epoch 0031, iter [04200, 05004], lr: 0.165660, loss: 1.7584
2022-07-18 10:56:02 - train: epoch 0031, iter [04300, 05004], lr: 0.165610, loss: 1.6942
2022-07-18 10:58:18 - train: epoch 0031, iter [04400, 05004], lr: 0.165561, loss: 1.9893
2022-07-18 11:00:35 - train: epoch 0031, iter [04500, 05004], lr: 0.165511, loss: 1.6843
2022-07-18 11:02:52 - train: epoch 0031, iter [04600, 05004], lr: 0.165461, loss: 1.9301
2022-07-18 11:05:09 - train: epoch 0031, iter [04700, 05004], lr: 0.165411, loss: 1.6676
2022-07-18 11:07:26 - train: epoch 0031, iter [04800, 05004], lr: 0.165361, loss: 1.6867
2022-07-18 11:09:43 - train: epoch 0031, iter [04900, 05004], lr: 0.165311, loss: 1.7066
2022-07-18 11:11:59 - train: epoch 0031, iter [05000, 05004], lr: 0.165261, loss: 1.7744
2022-07-18 11:12:06 - train: epoch 031, train_loss: 1.7579
2022-07-18 11:14:16 - eval: epoch: 031, acc1: 63.300%, acc5: 86.058%, test_loss: 1.5107, per_image_load_time: 1.013ms, per_image_inference_time: 3.915ms
2022-07-18 11:14:16 - until epoch: 031, best_acc1: 63.300%
2022-07-18 11:14:16 - epoch 032 lr: 0.165258
2022-07-18 11:16:42 - train: epoch 0032, iter [00100, 05004], lr: 0.165208, loss: 1.6050
2022-07-18 11:18:58 - train: epoch 0032, iter [00200, 05004], lr: 0.165158, loss: 1.6861
2022-07-18 11:21:15 - train: epoch 0032, iter [00300, 05004], lr: 0.165108, loss: 1.5056
2022-07-18 11:23:32 - train: epoch 0032, iter [00400, 05004], lr: 0.165058, loss: 1.6624
2022-07-18 11:25:48 - train: epoch 0032, iter [00500, 05004], lr: 0.165008, loss: 1.7441
2022-07-18 11:28:05 - train: epoch 0032, iter [00600, 05004], lr: 0.164958, loss: 1.7142
2022-07-18 11:30:22 - train: epoch 0032, iter [00700, 05004], lr: 0.164907, loss: 1.6156
2022-07-18 11:32:38 - train: epoch 0032, iter [00800, 05004], lr: 0.164857, loss: 1.8424
2022-07-18 11:34:55 - train: epoch 0032, iter [00900, 05004], lr: 0.164807, loss: 1.8295
2022-07-18 11:37:12 - train: epoch 0032, iter [01000, 05004], lr: 0.164756, loss: 1.9629
2022-07-18 11:39:28 - train: epoch 0032, iter [01100, 05004], lr: 0.164706, loss: 1.8573
2022-07-18 11:41:45 - train: epoch 0032, iter [01200, 05004], lr: 0.164656, loss: 1.6886
2022-07-18 11:44:01 - train: epoch 0032, iter [01300, 05004], lr: 0.164605, loss: 1.6260
2022-07-18 11:46:18 - train: epoch 0032, iter [01400, 05004], lr: 0.164555, loss: 2.0516
2022-07-18 11:48:35 - train: epoch 0032, iter [01500, 05004], lr: 0.164504, loss: 1.5676
2022-07-18 11:50:52 - train: epoch 0032, iter [01600, 05004], lr: 0.164454, loss: 1.7815
2022-07-18 11:53:08 - train: epoch 0032, iter [01700, 05004], lr: 0.164403, loss: 1.7039
2022-07-18 11:55:25 - train: epoch 0032, iter [01800, 05004], lr: 0.164353, loss: 2.0713
2022-07-18 11:57:42 - train: epoch 0032, iter [01900, 05004], lr: 0.164302, loss: 1.6448
2022-07-18 11:59:59 - train: epoch 0032, iter [02000, 05004], lr: 0.164251, loss: 1.7051
2022-07-18 12:02:16 - train: epoch 0032, iter [02100, 05004], lr: 0.164201, loss: 1.4414
2022-07-18 12:04:32 - train: epoch 0032, iter [02200, 05004], lr: 0.164150, loss: 1.6609
2022-07-18 12:06:49 - train: epoch 0032, iter [02300, 05004], lr: 0.164099, loss: 1.7512
2022-07-18 12:09:06 - train: epoch 0032, iter [02400, 05004], lr: 0.164049, loss: 1.6946
2022-07-18 12:11:23 - train: epoch 0032, iter [02500, 05004], lr: 0.163998, loss: 1.8193
2022-07-18 12:13:40 - train: epoch 0032, iter [02600, 05004], lr: 0.163947, loss: 1.6718
2022-07-18 12:15:57 - train: epoch 0032, iter [02700, 05004], lr: 0.163896, loss: 1.6139
2022-07-18 12:18:14 - train: epoch 0032, iter [02800, 05004], lr: 0.163845, loss: 1.8372
2022-07-18 12:20:31 - train: epoch 0032, iter [02900, 05004], lr: 0.163795, loss: 1.6360
2022-07-18 12:22:48 - train: epoch 0032, iter [03000, 05004], lr: 0.163744, loss: 1.7483
2022-07-18 12:25:05 - train: epoch 0032, iter [03100, 05004], lr: 0.163693, loss: 1.7731
2022-07-18 12:27:21 - train: epoch 0032, iter [03200, 05004], lr: 0.163642, loss: 1.8894
2022-07-18 12:29:38 - train: epoch 0032, iter [03300, 05004], lr: 0.163591, loss: 1.7063
2022-07-18 12:31:55 - train: epoch 0032, iter [03400, 05004], lr: 0.163540, loss: 1.5746
2022-07-18 12:34:12 - train: epoch 0032, iter [03500, 05004], lr: 0.163489, loss: 1.7701
2022-07-18 12:36:29 - train: epoch 0032, iter [03600, 05004], lr: 0.163438, loss: 1.8200
2022-07-18 12:38:46 - train: epoch 0032, iter [03700, 05004], lr: 0.163387, loss: 1.9265
2022-07-18 12:41:03 - train: epoch 0032, iter [03800, 05004], lr: 0.163335, loss: 1.6022
2022-07-18 12:43:20 - train: epoch 0032, iter [03900, 05004], lr: 0.163284, loss: 1.7136
2022-07-18 12:45:37 - train: epoch 0032, iter [04000, 05004], lr: 0.163233, loss: 1.8140
2022-07-18 12:47:53 - train: epoch 0032, iter [04100, 05004], lr: 0.163182, loss: 1.6102
2022-07-18 12:50:10 - train: epoch 0032, iter [04200, 05004], lr: 0.163131, loss: 1.7796
2022-07-18 12:52:27 - train: epoch 0032, iter [04300, 05004], lr: 0.163079, loss: 2.0194
2022-07-18 12:54:44 - train: epoch 0032, iter [04400, 05004], lr: 0.163028, loss: 1.8241
2022-07-18 12:57:01 - train: epoch 0032, iter [04500, 05004], lr: 0.162977, loss: 1.7612
2022-07-18 12:59:18 - train: epoch 0032, iter [04600, 05004], lr: 0.162925, loss: 1.7923
2022-07-18 13:01:34 - train: epoch 0032, iter [04700, 05004], lr: 0.162874, loss: 1.7305
2022-07-18 13:03:51 - train: epoch 0032, iter [04800, 05004], lr: 0.162823, loss: 1.4407
2022-07-18 13:06:08 - train: epoch 0032, iter [04900, 05004], lr: 0.162771, loss: 1.5709
2022-07-18 13:08:24 - train: epoch 0032, iter [05000, 05004], lr: 0.162720, loss: 1.7511
2022-07-18 13:08:31 - train: epoch 032, train_loss: 1.7433
2022-07-18 13:10:43 - eval: epoch: 032, acc1: 63.764%, acc5: 86.094%, test_loss: 1.4999, per_image_load_time: 1.110ms, per_image_inference_time: 3.939ms
2022-07-18 13:10:44 - until epoch: 032, best_acc1: 63.764%
2022-07-18 13:10:44 - epoch 033 lr: 0.162717
2022-07-18 13:13:08 - train: epoch 0033, iter [00100, 05004], lr: 0.162666, loss: 1.5142
2022-07-18 13:15:25 - train: epoch 0033, iter [00200, 05004], lr: 0.162615, loss: 1.6486
2022-07-18 13:17:42 - train: epoch 0033, iter [00300, 05004], lr: 0.162563, loss: 1.6087
2022-07-18 13:19:59 - train: epoch 0033, iter [00400, 05004], lr: 0.162512, loss: 1.5155
2022-07-18 13:22:16 - train: epoch 0033, iter [00500, 05004], lr: 0.162460, loss: 1.7077
2022-07-18 13:24:33 - train: epoch 0033, iter [00600, 05004], lr: 0.162408, loss: 1.7105
2022-07-18 13:26:50 - train: epoch 0033, iter [00700, 05004], lr: 0.162357, loss: 1.8184
2022-07-18 13:29:07 - train: epoch 0033, iter [00800, 05004], lr: 0.162305, loss: 1.7383
2022-07-18 13:31:23 - train: epoch 0033, iter [00900, 05004], lr: 0.162253, loss: 1.8013
2022-07-18 13:33:40 - train: epoch 0033, iter [01000, 05004], lr: 0.162202, loss: 1.9599
2022-07-18 13:35:57 - train: epoch 0033, iter [01100, 05004], lr: 0.162150, loss: 1.5502
2022-07-18 13:38:14 - train: epoch 0033, iter [01200, 05004], lr: 0.162098, loss: 1.9011
2022-07-18 13:40:30 - train: epoch 0033, iter [01300, 05004], lr: 0.162046, loss: 1.6345
2022-07-18 13:42:47 - train: epoch 0033, iter [01400, 05004], lr: 0.161994, loss: 1.6626
2022-07-18 13:45:03 - train: epoch 0033, iter [01500, 05004], lr: 0.161942, loss: 1.9882
2022-07-18 13:47:20 - train: epoch 0033, iter [01600, 05004], lr: 0.161891, loss: 1.9804
2022-07-18 13:49:37 - train: epoch 0033, iter [01700, 05004], lr: 0.161839, loss: 1.7831
2022-07-18 13:51:53 - train: epoch 0033, iter [01800, 05004], lr: 0.161787, loss: 1.7837
2022-07-18 13:54:10 - train: epoch 0033, iter [01900, 05004], lr: 0.161735, loss: 1.7962
2022-07-18 13:56:27 - train: epoch 0033, iter [02000, 05004], lr: 0.161683, loss: 1.7587
2022-07-18 13:58:44 - train: epoch 0033, iter [02100, 05004], lr: 0.161631, loss: 1.7938
2022-07-18 14:01:00 - train: epoch 0033, iter [02200, 05004], lr: 0.161579, loss: 1.7293
2022-07-18 14:03:17 - train: epoch 0033, iter [02300, 05004], lr: 0.161527, loss: 1.5039
2022-07-18 14:05:34 - train: epoch 0033, iter [02400, 05004], lr: 0.161474, loss: 1.8323
2022-07-18 14:07:50 - train: epoch 0033, iter [02500, 05004], lr: 0.161422, loss: 1.7988
2022-07-18 14:10:07 - train: epoch 0033, iter [02600, 05004], lr: 0.161370, loss: 1.5244
2022-07-18 14:12:24 - train: epoch 0033, iter [02700, 05004], lr: 0.161318, loss: 1.7442
2022-07-18 14:14:41 - train: epoch 0033, iter [02800, 05004], lr: 0.161266, loss: 1.7449
2022-07-18 14:16:57 - train: epoch 0033, iter [02900, 05004], lr: 0.161213, loss: 1.7179
2022-07-18 14:19:14 - train: epoch 0033, iter [03000, 05004], lr: 0.161161, loss: 1.7743
2022-07-18 14:21:31 - train: epoch 0033, iter [03100, 05004], lr: 0.161109, loss: 1.7641
2022-07-18 14:23:48 - train: epoch 0033, iter [03200, 05004], lr: 0.161057, loss: 1.7744
2022-07-18 14:26:05 - train: epoch 0033, iter [03300, 05004], lr: 0.161004, loss: 1.8308
2022-07-18 14:28:22 - train: epoch 0033, iter [03400, 05004], lr: 0.160952, loss: 1.7743
2022-07-18 14:30:38 - train: epoch 0033, iter [03500, 05004], lr: 0.160899, loss: 1.7598
2022-07-18 14:32:55 - train: epoch 0033, iter [03600, 05004], lr: 0.160847, loss: 1.8406
2022-07-18 14:35:12 - train: epoch 0033, iter [03700, 05004], lr: 0.160795, loss: 1.6204
2022-07-18 14:37:29 - train: epoch 0033, iter [03800, 05004], lr: 0.160742, loss: 1.6909
2022-07-18 14:39:46 - train: epoch 0033, iter [03900, 05004], lr: 0.160690, loss: 2.1275
2022-07-18 14:42:03 - train: epoch 0033, iter [04000, 05004], lr: 0.160637, loss: 1.8156
2022-07-18 14:44:20 - train: epoch 0033, iter [04100, 05004], lr: 0.160584, loss: 1.7116
2022-07-18 14:46:37 - train: epoch 0033, iter [04200, 05004], lr: 0.160532, loss: 1.6198
2022-07-18 14:48:53 - train: epoch 0033, iter [04300, 05004], lr: 0.160479, loss: 1.9973
2022-07-18 14:51:10 - train: epoch 0033, iter [04400, 05004], lr: 0.160427, loss: 1.7938
2022-07-18 14:53:27 - train: epoch 0033, iter [04500, 05004], lr: 0.160374, loss: 2.0074
2022-07-18 14:55:44 - train: epoch 0033, iter [04600, 05004], lr: 0.160321, loss: 1.7731
2022-07-18 14:58:01 - train: epoch 0033, iter [04700, 05004], lr: 0.160269, loss: 1.7928
2022-07-18 15:00:18 - train: epoch 0033, iter [04800, 05004], lr: 0.160216, loss: 2.0695
2022-07-18 15:02:35 - train: epoch 0033, iter [04900, 05004], lr: 0.160163, loss: 1.5614
2022-07-18 15:04:52 - train: epoch 0033, iter [05000, 05004], lr: 0.160110, loss: 1.8400
2022-07-18 15:04:58 - train: epoch 033, train_loss: 1.7341
2022-07-18 15:07:06 - eval: epoch: 033, acc1: 63.720%, acc5: 86.124%, test_loss: 1.5024, per_image_load_time: 0.998ms, per_image_inference_time: 3.905ms
2022-07-18 15:07:06 - until epoch: 033, best_acc1: 63.764%
2022-07-18 15:07:06 - epoch 034 lr: 0.160108
2022-07-18 15:09:31 - train: epoch 0034, iter [00100, 05004], lr: 0.160055, loss: 1.6528
2022-07-18 15:11:48 - train: epoch 0034, iter [00200, 05004], lr: 0.160002, loss: 1.6033
2022-07-18 15:14:04 - train: epoch 0034, iter [00300, 05004], lr: 0.159950, loss: 1.5453
2022-07-18 15:16:21 - train: epoch 0034, iter [00400, 05004], lr: 0.159897, loss: 1.7633
2022-07-18 15:18:38 - train: epoch 0034, iter [00500, 05004], lr: 0.159844, loss: 1.5615
2022-07-18 15:20:54 - train: epoch 0034, iter [00600, 05004], lr: 0.159791, loss: 1.7777
2022-07-18 15:23:11 - train: epoch 0034, iter [00700, 05004], lr: 0.159738, loss: 1.5650
2022-07-18 15:25:28 - train: epoch 0034, iter [00800, 05004], lr: 0.159685, loss: 1.7757
2022-07-18 15:27:44 - train: epoch 0034, iter [00900, 05004], lr: 0.159632, loss: 1.8749
2022-07-18 15:30:01 - train: epoch 0034, iter [01000, 05004], lr: 0.159579, loss: 1.6717
2022-07-18 15:32:18 - train: epoch 0034, iter [01100, 05004], lr: 0.159526, loss: 1.8920
2022-07-18 15:34:35 - train: epoch 0034, iter [01200, 05004], lr: 0.159472, loss: 1.7269
2022-07-18 15:36:52 - train: epoch 0034, iter [01300, 05004], lr: 0.159419, loss: 1.6549
2022-07-18 15:39:08 - train: epoch 0034, iter [01400, 05004], lr: 0.159366, loss: 1.7176
2022-07-18 15:41:25 - train: epoch 0034, iter [01500, 05004], lr: 0.159313, loss: 1.8399
2022-07-18 15:43:42 - train: epoch 0034, iter [01600, 05004], lr: 0.159260, loss: 1.7891
2022-07-18 15:45:58 - train: epoch 0034, iter [01700, 05004], lr: 0.159206, loss: 1.7683
2022-07-18 15:48:15 - train: epoch 0034, iter [01800, 05004], lr: 0.159153, loss: 1.8361
2022-07-18 15:50:32 - train: epoch 0034, iter [01900, 05004], lr: 0.159100, loss: 1.9992
2022-07-18 15:52:49 - train: epoch 0034, iter [02000, 05004], lr: 0.159047, loss: 1.7041
2022-07-18 15:55:05 - train: epoch 0034, iter [02100, 05004], lr: 0.158993, loss: 1.7947
2022-07-18 15:57:22 - train: epoch 0034, iter [02200, 05004], lr: 0.158940, loss: 1.5490
2022-07-18 15:59:39 - train: epoch 0034, iter [02300, 05004], lr: 0.158886, loss: 1.7758
2022-07-18 16:01:56 - train: epoch 0034, iter [02400, 05004], lr: 0.158833, loss: 1.9379
2022-07-18 16:04:12 - train: epoch 0034, iter [02500, 05004], lr: 0.158780, loss: 1.8403
2022-07-18 16:06:29 - train: epoch 0034, iter [02600, 05004], lr: 0.158726, loss: 1.7542
2022-07-18 16:08:46 - train: epoch 0034, iter [02700, 05004], lr: 0.158673, loss: 1.6179
2022-07-18 16:11:03 - train: epoch 0034, iter [02800, 05004], lr: 0.158619, loss: 1.4750
2022-07-18 16:13:20 - train: epoch 0034, iter [02900, 05004], lr: 0.158566, loss: 1.6497
2022-07-18 16:15:37 - train: epoch 0034, iter [03000, 05004], lr: 0.158512, loss: 1.5928
2022-07-18 16:17:54 - train: epoch 0034, iter [03100, 05004], lr: 0.158458, loss: 1.6394
2022-07-18 16:20:11 - train: epoch 0034, iter [03200, 05004], lr: 0.158405, loss: 1.7558
2022-07-18 16:22:27 - train: epoch 0034, iter [03300, 05004], lr: 0.158351, loss: 1.7752
2022-07-18 16:24:44 - train: epoch 0034, iter [03400, 05004], lr: 0.158297, loss: 1.7048
2022-07-18 16:27:01 - train: epoch 0034, iter [03500, 05004], lr: 0.158244, loss: 1.5900
2022-07-18 16:29:18 - train: epoch 0034, iter [03600, 05004], lr: 0.158190, loss: 1.5885
2022-07-18 16:31:35 - train: epoch 0034, iter [03700, 05004], lr: 0.158136, loss: 1.6009
2022-07-18 16:33:52 - train: epoch 0034, iter [03800, 05004], lr: 0.158082, loss: 1.7133
2022-07-18 16:36:09 - train: epoch 0034, iter [03900, 05004], lr: 0.158029, loss: 1.9236
2022-07-18 16:38:26 - train: epoch 0034, iter [04000, 05004], lr: 0.157975, loss: 1.5301
2022-07-18 16:40:43 - train: epoch 0034, iter [04100, 05004], lr: 0.157921, loss: 1.7413
2022-07-18 16:42:59 - train: epoch 0034, iter [04200, 05004], lr: 0.157867, loss: 1.9231
2022-07-18 16:45:16 - train: epoch 0034, iter [04300, 05004], lr: 0.157813, loss: 1.7664
2022-07-18 16:47:33 - train: epoch 0034, iter [04400, 05004], lr: 0.157759, loss: 1.5798
2022-07-18 16:49:50 - train: epoch 0034, iter [04500, 05004], lr: 0.157705, loss: 1.8116
2022-07-18 16:52:07 - train: epoch 0034, iter [04600, 05004], lr: 0.157651, loss: 1.9501
2022-07-18 16:54:24 - train: epoch 0034, iter [04700, 05004], lr: 0.157597, loss: 1.8474
2022-07-18 16:56:41 - train: epoch 0034, iter [04800, 05004], lr: 0.157543, loss: 1.7787
2022-07-18 16:58:58 - train: epoch 0034, iter [04900, 05004], lr: 0.157489, loss: 1.8165
2022-07-18 17:01:15 - train: epoch 0034, iter [05000, 05004], lr: 0.157435, loss: 1.6758
2022-07-18 17:01:21 - train: epoch 034, train_loss: 1.7244
2022-07-18 17:03:28 - eval: epoch: 034, acc1: 64.182%, acc5: 86.696%, test_loss: 1.4779, per_image_load_time: 0.982ms, per_image_inference_time: 3.901ms
2022-07-18 17:03:28 - until epoch: 034, best_acc1: 64.182%
2022-07-18 17:03:28 - epoch 035 lr: 0.157432
2022-07-18 17:05:54 - train: epoch 0035, iter [00100, 05004], lr: 0.157379, loss: 1.6084
2022-07-18 17:08:11 - train: epoch 0035, iter [00200, 05004], lr: 0.157325, loss: 1.6572
2022-07-18 17:10:28 - train: epoch 0035, iter [00300, 05004], lr: 0.157270, loss: 1.7569
2022-07-18 17:12:45 - train: epoch 0035, iter [00400, 05004], lr: 0.157216, loss: 1.6176
2022-07-18 17:15:02 - train: epoch 0035, iter [00500, 05004], lr: 0.157162, loss: 1.6518
2022-07-18 17:17:18 - train: epoch 0035, iter [00600, 05004], lr: 0.157108, loss: 1.6913
2022-07-18 17:19:35 - train: epoch 0035, iter [00700, 05004], lr: 0.157054, loss: 1.6803
2022-07-18 17:21:52 - train: epoch 0035, iter [00800, 05004], lr: 0.156999, loss: 1.7100
2022-07-18 17:24:08 - train: epoch 0035, iter [00900, 05004], lr: 0.156945, loss: 1.7078
2022-07-18 17:26:25 - train: epoch 0035, iter [01000, 05004], lr: 0.156891, loss: 1.5009
2022-07-18 17:28:42 - train: epoch 0035, iter [01100, 05004], lr: 0.156836, loss: 1.7761
2022-07-18 17:30:59 - train: epoch 0035, iter [01200, 05004], lr: 0.156782, loss: 1.4313
2022-07-18 17:33:15 - train: epoch 0035, iter [01300, 05004], lr: 0.156727, loss: 1.6631
2022-07-18 17:35:32 - train: epoch 0035, iter [01400, 05004], lr: 0.156673, loss: 1.6704
2022-07-18 17:37:49 - train: epoch 0035, iter [01500, 05004], lr: 0.156619, loss: 1.7527
2022-07-18 17:40:06 - train: epoch 0035, iter [01600, 05004], lr: 0.156564, loss: 1.5756
2022-07-18 17:42:23 - train: epoch 0035, iter [01700, 05004], lr: 0.156510, loss: 1.7206
2022-07-18 17:44:39 - train: epoch 0035, iter [01800, 05004], lr: 0.156455, loss: 1.7090
2022-07-18 17:46:56 - train: epoch 0035, iter [01900, 05004], lr: 0.156400, loss: 1.7645
2022-07-18 17:49:13 - train: epoch 0035, iter [02000, 05004], lr: 0.156346, loss: 1.8903
2022-07-18 17:51:30 - train: epoch 0035, iter [02100, 05004], lr: 0.156291, loss: 1.7376
2022-07-18 17:53:46 - train: epoch 0035, iter [02200, 05004], lr: 0.156237, loss: 1.9182
2022-07-18 17:56:03 - train: epoch 0035, iter [02300, 05004], lr: 0.156182, loss: 1.8382
2022-07-18 17:58:20 - train: epoch 0035, iter [02400, 05004], lr: 0.156127, loss: 1.8153
2022-07-18 18:00:37 - train: epoch 0035, iter [02500, 05004], lr: 0.156073, loss: 1.6253
2022-07-18 18:02:54 - train: epoch 0035, iter [02600, 05004], lr: 0.156018, loss: 1.8240
2022-07-18 18:05:10 - train: epoch 0035, iter [02700, 05004], lr: 0.155963, loss: 1.7114
2022-07-18 18:07:27 - train: epoch 0035, iter [02800, 05004], lr: 0.155908, loss: 1.7723
2022-07-18 18:09:44 - train: epoch 0035, iter [02900, 05004], lr: 0.155854, loss: 1.7081
2022-07-18 18:12:01 - train: epoch 0035, iter [03000, 05004], lr: 0.155799, loss: 1.5001
2022-07-18 18:14:18 - train: epoch 0035, iter [03100, 05004], lr: 0.155744, loss: 1.7122
2022-07-18 18:16:35 - train: epoch 0035, iter [03200, 05004], lr: 0.155689, loss: 1.8307
2022-07-18 18:18:52 - train: epoch 0035, iter [03300, 05004], lr: 0.155634, loss: 1.7681
2022-07-18 18:21:09 - train: epoch 0035, iter [03400, 05004], lr: 0.155579, loss: 1.7148
2022-07-18 18:23:26 - train: epoch 0035, iter [03500, 05004], lr: 0.155524, loss: 1.4454
2022-07-18 18:25:43 - train: epoch 0035, iter [03600, 05004], lr: 0.155469, loss: 1.7067
2022-07-18 18:28:00 - train: epoch 0035, iter [03700, 05004], lr: 0.155414, loss: 1.5546
2022-07-18 18:30:17 - train: epoch 0035, iter [03800, 05004], lr: 0.155359, loss: 1.7534
2022-07-18 18:32:34 - train: epoch 0035, iter [03900, 05004], lr: 0.155304, loss: 1.6625
2022-07-18 18:34:51 - train: epoch 0035, iter [04000, 05004], lr: 0.155249, loss: 1.4693
2022-07-18 18:37:08 - train: epoch 0035, iter [04100, 05004], lr: 0.155194, loss: 1.8668
2022-07-18 18:39:25 - train: epoch 0035, iter [04200, 05004], lr: 0.155139, loss: 1.5104
2022-07-18 18:41:42 - train: epoch 0035, iter [04300, 05004], lr: 0.155084, loss: 1.7875
2022-07-18 18:43:59 - train: epoch 0035, iter [04400, 05004], lr: 0.155029, loss: 1.8235
2022-07-18 18:46:16 - train: epoch 0035, iter [04500, 05004], lr: 0.154973, loss: 1.7804
2022-07-18 18:48:33 - train: epoch 0035, iter [04600, 05004], lr: 0.154918, loss: 1.6273
2022-07-18 18:50:50 - train: epoch 0035, iter [04700, 05004], lr: 0.154863, loss: 1.8106
2022-07-18 18:53:07 - train: epoch 0035, iter [04800, 05004], lr: 0.154808, loss: 1.8029
2022-07-18 18:55:24 - train: epoch 0035, iter [04900, 05004], lr: 0.154752, loss: 1.5980
2022-07-18 18:57:41 - train: epoch 0035, iter [05000, 05004], lr: 0.154697, loss: 1.6543
2022-07-18 18:57:47 - train: epoch 035, train_loss: 1.7103
2022-07-18 18:59:57 - eval: epoch: 035, acc1: 64.776%, acc5: 87.010%, test_loss: 1.4455, per_image_load_time: 1.115ms, per_image_inference_time: 3.933ms
2022-07-18 18:59:57 - until epoch: 035, best_acc1: 64.776%
2022-07-18 18:59:57 - epoch 036 lr: 0.154694
2022-07-18 19:02:23 - train: epoch 0036, iter [00100, 05004], lr: 0.154639, loss: 1.6205
2022-07-18 19:04:39 - train: epoch 0036, iter [00200, 05004], lr: 0.154584, loss: 1.5730
2022-07-18 19:06:56 - train: epoch 0036, iter [00300, 05004], lr: 0.154529, loss: 1.5025
2022-07-18 19:09:13 - train: epoch 0036, iter [00400, 05004], lr: 0.154473, loss: 1.7175
2022-07-18 19:11:30 - train: epoch 0036, iter [00500, 05004], lr: 0.154418, loss: 1.6721
2022-07-18 19:13:47 - train: epoch 0036, iter [00600, 05004], lr: 0.154362, loss: 1.7025
2022-07-18 19:16:04 - train: epoch 0036, iter [00700, 05004], lr: 0.154307, loss: 1.4362
2022-07-18 19:18:21 - train: epoch 0036, iter [00800, 05004], lr: 0.154251, loss: 1.6400
2022-07-18 19:20:38 - train: epoch 0036, iter [00900, 05004], lr: 0.154196, loss: 1.6596
2022-07-18 19:22:55 - train: epoch 0036, iter [01000, 05004], lr: 0.154140, loss: 1.5659
2022-07-18 19:25:12 - train: epoch 0036, iter [01100, 05004], lr: 0.154085, loss: 1.6799
2022-07-18 19:27:28 - train: epoch 0036, iter [01200, 05004], lr: 0.154029, loss: 1.8647
2022-07-18 19:29:46 - train: epoch 0036, iter [01300, 05004], lr: 0.153974, loss: 1.6162
2022-07-18 19:32:02 - train: epoch 0036, iter [01400, 05004], lr: 0.153918, loss: 1.7973
2022-07-18 19:34:19 - train: epoch 0036, iter [01500, 05004], lr: 0.153862, loss: 1.7928
2022-07-18 19:36:36 - train: epoch 0036, iter [01600, 05004], lr: 0.153807, loss: 1.7328
2022-07-18 19:38:53 - train: epoch 0036, iter [01700, 05004], lr: 0.153751, loss: 1.6191
2022-07-18 19:41:10 - train: epoch 0036, iter [01800, 05004], lr: 0.153695, loss: 1.4953
2022-07-18 19:43:27 - train: epoch 0036, iter [01900, 05004], lr: 0.153639, loss: 1.7467
2022-07-18 19:45:43 - train: epoch 0036, iter [02000, 05004], lr: 0.153584, loss: 1.5953
2022-07-18 19:48:00 - train: epoch 0036, iter [02100, 05004], lr: 0.153528, loss: 1.6152
2022-07-18 19:50:17 - train: epoch 0036, iter [02200, 05004], lr: 0.153472, loss: 1.7009
2022-07-18 19:52:34 - train: epoch 0036, iter [02300, 05004], lr: 0.153416, loss: 1.7823
2022-07-18 19:54:51 - train: epoch 0036, iter [02400, 05004], lr: 0.153360, loss: 1.8151
2022-07-18 19:57:08 - train: epoch 0036, iter [02500, 05004], lr: 0.153304, loss: 1.6004
2022-07-18 19:59:25 - train: epoch 0036, iter [02600, 05004], lr: 0.153248, loss: 1.8691
2022-07-18 20:01:42 - train: epoch 0036, iter [02700, 05004], lr: 0.153192, loss: 1.4130
2022-07-18 20:03:59 - train: epoch 0036, iter [02800, 05004], lr: 0.153136, loss: 1.4971
2022-07-18 20:06:16 - train: epoch 0036, iter [02900, 05004], lr: 0.153080, loss: 1.6445
2022-07-18 20:08:34 - train: epoch 0036, iter [03000, 05004], lr: 0.153024, loss: 1.6407
2022-07-18 20:10:51 - train: epoch 0036, iter [03100, 05004], lr: 0.152968, loss: 1.8003
2022-07-18 20:13:08 - train: epoch 0036, iter [03200, 05004], lr: 0.152912, loss: 1.7490
2022-07-18 20:15:25 - train: epoch 0036, iter [03300, 05004], lr: 0.152856, loss: 1.5752
2022-07-18 20:17:42 - train: epoch 0036, iter [03400, 05004], lr: 0.152800, loss: 1.6206
2022-07-18 20:19:59 - train: epoch 0036, iter [03500, 05004], lr: 0.152744, loss: 1.7327
2022-07-18 20:22:16 - train: epoch 0036, iter [03600, 05004], lr: 0.152688, loss: 1.9799
2022-07-18 20:24:33 - train: epoch 0036, iter [03700, 05004], lr: 0.152632, loss: 1.5561
2022-07-18 20:26:50 - train: epoch 0036, iter [03800, 05004], lr: 0.152575, loss: 1.8138
2022-07-18 20:29:07 - train: epoch 0036, iter [03900, 05004], lr: 0.152519, loss: 1.7878
2022-07-18 20:31:24 - train: epoch 0036, iter [04000, 05004], lr: 0.152463, loss: 1.8061
2022-07-18 20:33:41 - train: epoch 0036, iter [04100, 05004], lr: 0.152407, loss: 1.7301
2022-07-18 20:35:58 - train: epoch 0036, iter [04200, 05004], lr: 0.152350, loss: 1.6763
2022-07-18 20:38:14 - train: epoch 0036, iter [04300, 05004], lr: 0.152294, loss: 1.4497
2022-07-18 20:40:31 - train: epoch 0036, iter [04400, 05004], lr: 0.152238, loss: 1.6355
2022-07-18 20:42:48 - train: epoch 0036, iter [04500, 05004], lr: 0.152181, loss: 1.6897
2022-07-18 20:45:05 - train: epoch 0036, iter [04600, 05004], lr: 0.152125, loss: 1.8045
2022-07-18 20:47:22 - train: epoch 0036, iter [04700, 05004], lr: 0.152069, loss: 1.6421
2022-07-18 20:49:39 - train: epoch 0036, iter [04800, 05004], lr: 0.152012, loss: 1.5893
2022-07-18 20:51:56 - train: epoch 0036, iter [04900, 05004], lr: 0.151956, loss: 1.6141
2022-07-18 20:54:13 - train: epoch 0036, iter [05000, 05004], lr: 0.151899, loss: 1.7396
2022-07-18 20:54:20 - train: epoch 036, train_loss: 1.6974
2022-07-18 20:56:28 - eval: epoch: 036, acc1: 64.970%, acc5: 86.958%, test_loss: 1.4442, per_image_load_time: 1.101ms, per_image_inference_time: 3.911ms
2022-07-18 20:56:28 - until epoch: 036, best_acc1: 64.970%
2022-07-18 20:56:28 - epoch 037 lr: 0.151896
2022-07-18 20:58:53 - train: epoch 0037, iter [00100, 05004], lr: 0.151840, loss: 1.6718
2022-07-18 21:01:09 - train: epoch 0037, iter [00200, 05004], lr: 0.151784, loss: 1.4869
2022-07-18 21:03:26 - train: epoch 0037, iter [00300, 05004], lr: 0.151727, loss: 1.4987
2022-07-18 21:05:43 - train: epoch 0037, iter [00400, 05004], lr: 0.151671, loss: 1.6240
2022-07-18 21:07:59 - train: epoch 0037, iter [00500, 05004], lr: 0.151614, loss: 1.5913
2022-07-18 21:10:16 - train: epoch 0037, iter [00600, 05004], lr: 0.151558, loss: 1.8375
2022-07-18 21:12:33 - train: epoch 0037, iter [00700, 05004], lr: 0.151501, loss: 1.5840
2022-07-18 21:14:49 - train: epoch 0037, iter [00800, 05004], lr: 0.151444, loss: 1.5177
2022-07-18 21:17:06 - train: epoch 0037, iter [00900, 05004], lr: 0.151388, loss: 1.8668
2022-07-18 21:19:23 - train: epoch 0037, iter [01000, 05004], lr: 0.151331, loss: 1.5792
2022-07-18 21:21:39 - train: epoch 0037, iter [01100, 05004], lr: 0.151274, loss: 1.7260
2022-07-18 21:23:56 - train: epoch 0037, iter [01200, 05004], lr: 0.151217, loss: 1.7419
2022-07-18 21:26:13 - train: epoch 0037, iter [01300, 05004], lr: 0.151161, loss: 1.4582
2022-07-18 21:28:29 - train: epoch 0037, iter [01400, 05004], lr: 0.151104, loss: 1.9328
2022-07-18 21:30:46 - train: epoch 0037, iter [01500, 05004], lr: 0.151047, loss: 1.6558
2022-07-18 21:33:03 - train: epoch 0037, iter [01600, 05004], lr: 0.150990, loss: 1.5161
2022-07-18 21:35:19 - train: epoch 0037, iter [01700, 05004], lr: 0.150933, loss: 1.6206
2022-07-18 21:37:36 - train: epoch 0037, iter [01800, 05004], lr: 0.150876, loss: 1.7499
2022-07-18 21:39:53 - train: epoch 0037, iter [01900, 05004], lr: 0.150820, loss: 1.7510
2022-07-18 21:42:09 - train: epoch 0037, iter [02000, 05004], lr: 0.150763, loss: 1.7048
2022-07-18 21:44:26 - train: epoch 0037, iter [02100, 05004], lr: 0.150706, loss: 1.5434
2022-07-18 21:46:43 - train: epoch 0037, iter [02200, 05004], lr: 0.150649, loss: 1.6328
2022-07-18 21:48:59 - train: epoch 0037, iter [02300, 05004], lr: 0.150592, loss: 1.7262
2022-07-18 21:51:16 - train: epoch 0037, iter [02400, 05004], lr: 0.150535, loss: 1.9156
2022-07-18 21:53:33 - train: epoch 0037, iter [02500, 05004], lr: 0.150478, loss: 1.6829
2022-07-18 21:55:50 - train: epoch 0037, iter [02600, 05004], lr: 0.150421, loss: 2.0346
2022-07-18 21:58:06 - train: epoch 0037, iter [02700, 05004], lr: 0.150364, loss: 1.6666
2022-07-18 22:00:23 - train: epoch 0037, iter [02800, 05004], lr: 0.150306, loss: 1.8922
2022-07-18 22:02:39 - train: epoch 0037, iter [02900, 05004], lr: 0.150249, loss: 1.7573
2022-07-18 22:04:56 - train: epoch 0037, iter [03000, 05004], lr: 0.150192, loss: 1.8042
2022-07-18 22:07:13 - train: epoch 0037, iter [03100, 05004], lr: 0.150135, loss: 1.6002
2022-07-18 22:09:30 - train: epoch 0037, iter [03200, 05004], lr: 0.150078, loss: 1.7017
2022-07-18 22:11:46 - train: epoch 0037, iter [03300, 05004], lr: 0.150021, loss: 1.4967
2022-07-18 22:14:03 - train: epoch 0037, iter [03400, 05004], lr: 0.149963, loss: 1.5179
2022-07-18 22:16:20 - train: epoch 0037, iter [03500, 05004], lr: 0.149906, loss: 1.6454
2022-07-18 22:18:37 - train: epoch 0037, iter [03600, 05004], lr: 0.149849, loss: 1.6061
2022-07-18 22:20:54 - train: epoch 0037, iter [03700, 05004], lr: 0.149792, loss: 1.7185
2022-07-18 22:23:11 - train: epoch 0037, iter [03800, 05004], lr: 0.149734, loss: 1.6521
2022-07-18 22:25:28 - train: epoch 0037, iter [03900, 05004], lr: 0.149677, loss: 1.7425
2022-07-18 22:27:45 - train: epoch 0037, iter [04000, 05004], lr: 0.149619, loss: 1.7247
2022-07-18 22:30:02 - train: epoch 0037, iter [04100, 05004], lr: 0.149562, loss: 1.7256
2022-07-18 22:32:20 - train: epoch 0037, iter [04200, 05004], lr: 0.149505, loss: 1.8906
2022-07-18 22:34:37 - train: epoch 0037, iter [04300, 05004], lr: 0.149447, loss: 1.8294
2022-07-18 22:36:54 - train: epoch 0037, iter [04400, 05004], lr: 0.149390, loss: 1.5955
2022-07-18 22:39:11 - train: epoch 0037, iter [04500, 05004], lr: 0.149332, loss: 1.6303
2022-07-18 22:41:28 - train: epoch 0037, iter [04600, 05004], lr: 0.149275, loss: 1.7870
2022-07-18 22:43:45 - train: epoch 0037, iter [04700, 05004], lr: 0.149217, loss: 1.7096
2022-07-18 22:46:02 - train: epoch 0037, iter [04800, 05004], lr: 0.149160, loss: 1.6186
2022-07-18 22:48:19 - train: epoch 0037, iter [04900, 05004], lr: 0.149102, loss: 1.7298
2022-07-18 22:50:36 - train: epoch 0037, iter [05000, 05004], lr: 0.149045, loss: 1.4216
2022-07-18 22:50:43 - train: epoch 037, train_loss: 1.6896
2022-07-18 22:52:55 - eval: epoch: 037, acc1: 65.234%, acc5: 87.360%, test_loss: 1.4216, per_image_load_time: 1.139ms, per_image_inference_time: 3.925ms
2022-07-18 22:52:55 - until epoch: 037, best_acc1: 65.234%
2022-07-18 22:52:55 - epoch 038 lr: 0.149042
2022-07-18 22:55:21 - train: epoch 0038, iter [00100, 05004], lr: 0.148985, loss: 1.6530
2022-07-18 22:57:38 - train: epoch 0038, iter [00200, 05004], lr: 0.148927, loss: 1.6884
2022-07-18 22:59:55 - train: epoch 0038, iter [00300, 05004], lr: 0.148869, loss: 1.4396
2022-07-18 23:02:12 - train: epoch 0038, iter [00400, 05004], lr: 0.148812, loss: 1.6089
