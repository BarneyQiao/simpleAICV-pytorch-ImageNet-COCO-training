2022-07-18 23:04:30 - train: epoch 0038, iter [00500, 05004], lr: 0.148754, loss: 1.4681
2022-07-18 23:06:47 - train: epoch 0038, iter [00600, 05004], lr: 0.148696, loss: 1.8146
2022-07-18 23:09:03 - train: epoch 0038, iter [00700, 05004], lr: 0.148639, loss: 1.5258
2022-07-18 23:11:20 - train: epoch 0038, iter [00800, 05004], lr: 0.148581, loss: 1.4783
2022-07-18 23:13:37 - train: epoch 0038, iter [00900, 05004], lr: 0.148523, loss: 1.6630
2022-07-18 23:15:54 - train: epoch 0038, iter [01000, 05004], lr: 0.148465, loss: 1.9064
2022-07-18 23:18:11 - train: epoch 0038, iter [01100, 05004], lr: 0.148408, loss: 1.8213
2022-07-18 23:20:28 - train: epoch 0038, iter [01200, 05004], lr: 0.148350, loss: 1.7403
2022-07-18 23:22:45 - train: epoch 0038, iter [01300, 05004], lr: 0.148292, loss: 1.4937
2022-07-18 23:25:02 - train: epoch 0038, iter [01400, 05004], lr: 0.148234, loss: 1.4507
2022-07-18 23:27:19 - train: epoch 0038, iter [01500, 05004], lr: 0.148176, loss: 1.5395
2022-07-18 23:29:35 - train: epoch 0038, iter [01600, 05004], lr: 0.148118, loss: 1.8130
2022-07-18 23:31:52 - train: epoch 0038, iter [01700, 05004], lr: 0.148060, loss: 1.7045
2022-07-18 23:34:09 - train: epoch 0038, iter [01800, 05004], lr: 0.148002, loss: 1.7007
2022-07-18 23:36:26 - train: epoch 0038, iter [01900, 05004], lr: 0.147944, loss: 1.5962
2022-07-18 23:38:43 - train: epoch 0038, iter [02000, 05004], lr: 0.147886, loss: 1.5710
2022-07-18 23:41:00 - train: epoch 0038, iter [02100, 05004], lr: 0.147828, loss: 1.7915
2022-07-18 23:43:17 - train: epoch 0038, iter [02200, 05004], lr: 0.147770, loss: 1.6390
2022-07-18 23:45:34 - train: epoch 0038, iter [02300, 05004], lr: 0.147712, loss: 1.8603
2022-07-18 23:47:51 - train: epoch 0038, iter [02400, 05004], lr: 0.147654, loss: 1.9250
2022-07-18 23:50:07 - train: epoch 0038, iter [02500, 05004], lr: 0.147596, loss: 1.5041
2022-07-18 23:52:24 - train: epoch 0038, iter [02600, 05004], lr: 0.147538, loss: 1.6827
2022-07-18 23:54:41 - train: epoch 0038, iter [02700, 05004], lr: 0.147480, loss: 1.7716
2022-07-18 23:56:58 - train: epoch 0038, iter [02800, 05004], lr: 0.147421, loss: 1.9920
2022-07-18 23:59:15 - train: epoch 0038, iter [02900, 05004], lr: 0.147363, loss: 1.9251
2022-07-19 00:01:31 - train: epoch 0038, iter [03000, 05004], lr: 0.147305, loss: 1.5726
2022-07-19 00:03:48 - train: epoch 0038, iter [03100, 05004], lr: 0.147247, loss: 1.6988
2022-07-19 00:06:05 - train: epoch 0038, iter [03200, 05004], lr: 0.147189, loss: 1.3765
2022-07-19 00:08:22 - train: epoch 0038, iter [03300, 05004], lr: 0.147130, loss: 1.5900
2022-07-19 00:10:39 - train: epoch 0038, iter [03400, 05004], lr: 0.147072, loss: 1.8447
2022-07-19 00:12:56 - train: epoch 0038, iter [03500, 05004], lr: 0.147014, loss: 1.5889
2022-07-19 00:15:12 - train: epoch 0038, iter [03600, 05004], lr: 0.146955, loss: 1.5691
2022-07-19 00:17:29 - train: epoch 0038, iter [03700, 05004], lr: 0.146897, loss: 1.5964
2022-07-19 00:19:46 - train: epoch 0038, iter [03800, 05004], lr: 0.146839, loss: 1.8029
2022-07-19 00:22:03 - train: epoch 0038, iter [03900, 05004], lr: 0.146780, loss: 1.4669
2022-07-19 00:24:20 - train: epoch 0038, iter [04000, 05004], lr: 0.146722, loss: 1.6614
2022-07-19 00:26:37 - train: epoch 0038, iter [04100, 05004], lr: 0.146663, loss: 1.6067
2022-07-19 00:28:54 - train: epoch 0038, iter [04200, 05004], lr: 0.146605, loss: 1.5553
2022-07-19 00:31:11 - train: epoch 0038, iter [04300, 05004], lr: 0.146546, loss: 1.8619
2022-07-19 00:33:27 - train: epoch 0038, iter [04400, 05004], lr: 0.146488, loss: 1.7258
2022-07-19 00:35:44 - train: epoch 0038, iter [04500, 05004], lr: 0.146429, loss: 1.7157
2022-07-19 00:38:01 - train: epoch 0038, iter [04600, 05004], lr: 0.146371, loss: 1.7234
2022-07-19 00:40:18 - train: epoch 0038, iter [04700, 05004], lr: 0.146312, loss: 1.7508
2022-07-19 00:42:35 - train: epoch 0038, iter [04800, 05004], lr: 0.146254, loss: 1.5599
2022-07-19 00:44:52 - train: epoch 0038, iter [04900, 05004], lr: 0.146195, loss: 1.5774
2022-07-19 00:47:09 - train: epoch 0038, iter [05000, 05004], lr: 0.146136, loss: 1.4639
2022-07-19 00:47:15 - train: epoch 038, train_loss: 1.6758
2022-07-19 00:49:20 - eval: epoch: 038, acc1: 64.902%, acc5: 86.994%, test_loss: 1.4460, per_image_load_time: 0.928ms, per_image_inference_time: 3.922ms
2022-07-19 00:49:21 - until epoch: 038, best_acc1: 65.234%
2022-07-19 00:49:21 - epoch 039 lr: 0.146134
2022-07-19 00:51:45 - train: epoch 0039, iter [00100, 05004], lr: 0.146075, loss: 1.5447
2022-07-19 00:54:02 - train: epoch 0039, iter [00200, 05004], lr: 0.146017, loss: 1.8328
2022-07-19 00:56:18 - train: epoch 0039, iter [00300, 05004], lr: 0.145958, loss: 1.4228
2022-07-19 00:58:35 - train: epoch 0039, iter [00400, 05004], lr: 0.145899, loss: 1.7906
2022-07-19 01:00:52 - train: epoch 0039, iter [00500, 05004], lr: 0.145841, loss: 1.5359
2022-07-19 01:03:09 - train: epoch 0039, iter [00600, 05004], lr: 0.145782, loss: 1.5515
2022-07-19 01:05:25 - train: epoch 0039, iter [00700, 05004], lr: 0.145723, loss: 1.9220
2022-07-19 01:07:42 - train: epoch 0039, iter [00800, 05004], lr: 0.145664, loss: 1.5906
2022-07-19 01:09:59 - train: epoch 0039, iter [00900, 05004], lr: 0.145606, loss: 1.5842
2022-07-19 01:12:15 - train: epoch 0039, iter [01000, 05004], lr: 0.145547, loss: 1.6618
2022-07-19 01:14:32 - train: epoch 0039, iter [01100, 05004], lr: 0.145488, loss: 1.7895
2022-07-19 01:16:49 - train: epoch 0039, iter [01200, 05004], lr: 0.145429, loss: 1.8512
2022-07-19 01:19:05 - train: epoch 0039, iter [01300, 05004], lr: 0.145370, loss: 1.6561
2022-07-19 01:21:22 - train: epoch 0039, iter [01400, 05004], lr: 0.145311, loss: 1.8696
2022-07-19 01:23:39 - train: epoch 0039, iter [01500, 05004], lr: 0.145252, loss: 1.6037
2022-07-19 01:25:55 - train: epoch 0039, iter [01600, 05004], lr: 0.145193, loss: 1.6445
2022-07-19 01:28:12 - train: epoch 0039, iter [01700, 05004], lr: 0.145134, loss: 1.5004
2022-07-19 01:30:29 - train: epoch 0039, iter [01800, 05004], lr: 0.145075, loss: 1.7647
2022-07-19 01:32:45 - train: epoch 0039, iter [01900, 05004], lr: 0.145016, loss: 1.4984
2022-07-19 01:35:02 - train: epoch 0039, iter [02000, 05004], lr: 0.144957, loss: 1.5693
2022-07-19 01:37:19 - train: epoch 0039, iter [02100, 05004], lr: 0.144898, loss: 1.8815
2022-07-19 01:39:36 - train: epoch 0039, iter [02200, 05004], lr: 0.144839, loss: 1.7932
2022-07-19 01:41:52 - train: epoch 0039, iter [02300, 05004], lr: 0.144780, loss: 2.0590
2022-07-19 01:44:09 - train: epoch 0039, iter [02400, 05004], lr: 0.144721, loss: 1.7280
2022-07-19 01:46:26 - train: epoch 0039, iter [02500, 05004], lr: 0.144662, loss: 1.7678
2022-07-19 01:48:42 - train: epoch 0039, iter [02600, 05004], lr: 0.144603, loss: 1.3449
2022-07-19 01:50:59 - train: epoch 0039, iter [02700, 05004], lr: 0.144544, loss: 1.6080
2022-07-19 01:53:16 - train: epoch 0039, iter [02800, 05004], lr: 0.144485, loss: 1.5882
2022-07-19 01:55:32 - train: epoch 0039, iter [02900, 05004], lr: 0.144425, loss: 1.5289
2022-07-19 01:57:49 - train: epoch 0039, iter [03000, 05004], lr: 0.144366, loss: 1.6839
2022-07-19 02:00:06 - train: epoch 0039, iter [03100, 05004], lr: 0.144307, loss: 1.4126
2022-07-19 02:02:23 - train: epoch 0039, iter [03200, 05004], lr: 0.144248, loss: 1.6919
2022-07-19 02:04:39 - train: epoch 0039, iter [03300, 05004], lr: 0.144188, loss: 1.8257
2022-07-19 02:06:56 - train: epoch 0039, iter [03400, 05004], lr: 0.144129, loss: 1.7729
2022-07-19 02:09:13 - train: epoch 0039, iter [03500, 05004], lr: 0.144070, loss: 1.9906
2022-07-19 02:11:29 - train: epoch 0039, iter [03600, 05004], lr: 0.144010, loss: 1.7913
2022-07-19 02:13:46 - train: epoch 0039, iter [03700, 05004], lr: 0.143951, loss: 1.5997
2022-07-19 02:16:03 - train: epoch 0039, iter [03800, 05004], lr: 0.143892, loss: 1.5495
2022-07-19 02:18:20 - train: epoch 0039, iter [03900, 05004], lr: 0.143832, loss: 1.6224
2022-07-19 02:20:36 - train: epoch 0039, iter [04000, 05004], lr: 0.143773, loss: 1.6046
2022-07-19 02:22:53 - train: epoch 0039, iter [04100, 05004], lr: 0.143714, loss: 1.8198
2022-07-19 02:25:10 - train: epoch 0039, iter [04200, 05004], lr: 0.143654, loss: 1.8496
2022-07-19 02:27:26 - train: epoch 0039, iter [04300, 05004], lr: 0.143595, loss: 1.6222
2022-07-19 02:29:43 - train: epoch 0039, iter [04400, 05004], lr: 0.143535, loss: 1.6749
2022-07-19 02:32:00 - train: epoch 0039, iter [04500, 05004], lr: 0.143476, loss: 1.4941
2022-07-19 02:34:16 - train: epoch 0039, iter [04600, 05004], lr: 0.143416, loss: 1.8076
2022-07-19 02:36:33 - train: epoch 0039, iter [04700, 05004], lr: 0.143357, loss: 1.6710
2022-07-19 02:38:50 - train: epoch 0039, iter [04800, 05004], lr: 0.143297, loss: 1.5621
2022-07-19 02:41:07 - train: epoch 0039, iter [04900, 05004], lr: 0.143237, loss: 1.6801
2022-07-19 02:43:23 - train: epoch 0039, iter [05000, 05004], lr: 0.143178, loss: 1.4878
2022-07-19 02:43:30 - train: epoch 039, train_loss: 1.6653
2022-07-19 02:45:37 - eval: epoch: 039, acc1: 65.226%, acc5: 87.210%, test_loss: 1.4283, per_image_load_time: 1.026ms, per_image_inference_time: 3.919ms
2022-07-19 02:45:37 - until epoch: 039, best_acc1: 65.234%
2022-07-19 02:45:37 - epoch 040 lr: 0.143175
2022-07-19 02:48:03 - train: epoch 0040, iter [00100, 05004], lr: 0.143116, loss: 1.8927
2022-07-19 02:50:20 - train: epoch 0040, iter [00200, 05004], lr: 0.143056, loss: 1.6768
2022-07-19 02:52:36 - train: epoch 0040, iter [00300, 05004], lr: 0.142997, loss: 1.7113
2022-07-19 02:54:53 - train: epoch 0040, iter [00400, 05004], lr: 0.142937, loss: 1.3312
2022-07-19 02:57:10 - train: epoch 0040, iter [00500, 05004], lr: 0.142877, loss: 1.6276
2022-07-19 02:59:27 - train: epoch 0040, iter [00600, 05004], lr: 0.142817, loss: 1.3988
2022-07-19 03:01:44 - train: epoch 0040, iter [00700, 05004], lr: 0.142758, loss: 1.5869
2022-07-19 03:04:00 - train: epoch 0040, iter [00800, 05004], lr: 0.142698, loss: 1.6472
2022-07-19 03:06:17 - train: epoch 0040, iter [00900, 05004], lr: 0.142638, loss: 1.8252
2022-07-19 03:08:34 - train: epoch 0040, iter [01000, 05004], lr: 0.142578, loss: 1.5246
2022-07-19 03:10:51 - train: epoch 0040, iter [01100, 05004], lr: 0.142519, loss: 1.3637
2022-07-19 03:13:07 - train: epoch 0040, iter [01200, 05004], lr: 0.142459, loss: 1.5649
2022-07-19 03:15:24 - train: epoch 0040, iter [01300, 05004], lr: 0.142399, loss: 1.5449
2022-07-19 03:17:41 - train: epoch 0040, iter [01400, 05004], lr: 0.142339, loss: 1.6455
2022-07-19 03:19:58 - train: epoch 0040, iter [01500, 05004], lr: 0.142279, loss: 1.6767
2022-07-19 03:22:15 - train: epoch 0040, iter [01600, 05004], lr: 0.142219, loss: 1.6366
2022-07-19 03:24:31 - train: epoch 0040, iter [01700, 05004], lr: 0.142159, loss: 1.5970
2022-07-19 03:26:48 - train: epoch 0040, iter [01800, 05004], lr: 0.142099, loss: 1.4704
2022-07-19 03:29:05 - train: epoch 0040, iter [01900, 05004], lr: 0.142039, loss: 1.5983
2022-07-19 03:31:22 - train: epoch 0040, iter [02000, 05004], lr: 0.141980, loss: 1.5792
2022-07-19 03:33:39 - train: epoch 0040, iter [02100, 05004], lr: 0.141920, loss: 1.6035
2022-07-19 03:35:56 - train: epoch 0040, iter [02200, 05004], lr: 0.141860, loss: 1.5484
2022-07-19 03:38:12 - train: epoch 0040, iter [02300, 05004], lr: 0.141799, loss: 1.6283
2022-07-19 03:40:29 - train: epoch 0040, iter [02400, 05004], lr: 0.141739, loss: 1.6570
2022-07-19 03:42:46 - train: epoch 0040, iter [02500, 05004], lr: 0.141679, loss: 1.7437
2022-07-19 03:45:03 - train: epoch 0040, iter [02600, 05004], lr: 0.141619, loss: 1.8896
2022-07-19 03:47:20 - train: epoch 0040, iter [02700, 05004], lr: 0.141559, loss: 1.7537
2022-07-19 03:49:37 - train: epoch 0040, iter [02800, 05004], lr: 0.141499, loss: 1.6730
2022-07-19 03:51:53 - train: epoch 0040, iter [02900, 05004], lr: 0.141439, loss: 1.9595
2022-07-19 03:54:10 - train: epoch 0040, iter [03000, 05004], lr: 0.141379, loss: 1.6910
2022-07-19 03:56:27 - train: epoch 0040, iter [03100, 05004], lr: 0.141319, loss: 1.7265
2022-07-19 03:58:44 - train: epoch 0040, iter [03200, 05004], lr: 0.141258, loss: 1.9370
2022-07-19 04:01:01 - train: epoch 0040, iter [03300, 05004], lr: 0.141198, loss: 1.8441
2022-07-19 04:03:18 - train: epoch 0040, iter [03400, 05004], lr: 0.141138, loss: 1.7300
2022-07-19 04:05:35 - train: epoch 0040, iter [03500, 05004], lr: 0.141078, loss: 1.7055
2022-07-19 04:07:52 - train: epoch 0040, iter [03600, 05004], lr: 0.141017, loss: 1.7462
2022-07-19 04:10:09 - train: epoch 0040, iter [03700, 05004], lr: 0.140957, loss: 1.5349
2022-07-19 04:12:26 - train: epoch 0040, iter [03800, 05004], lr: 0.140897, loss: 1.6520
2022-07-19 04:14:43 - train: epoch 0040, iter [03900, 05004], lr: 0.140837, loss: 1.6618
2022-07-19 04:17:00 - train: epoch 0040, iter [04000, 05004], lr: 0.140776, loss: 1.7579
2022-07-19 04:19:17 - train: epoch 0040, iter [04100, 05004], lr: 0.140716, loss: 1.6867
2022-07-19 04:21:33 - train: epoch 0040, iter [04200, 05004], lr: 0.140656, loss: 1.5558
2022-07-19 04:23:50 - train: epoch 0040, iter [04300, 05004], lr: 0.140595, loss: 1.5908
2022-07-19 04:26:07 - train: epoch 0040, iter [04400, 05004], lr: 0.140535, loss: 1.5685
2022-07-19 04:28:24 - train: epoch 0040, iter [04500, 05004], lr: 0.140474, loss: 1.4997
2022-07-19 04:30:41 - train: epoch 0040, iter [04600, 05004], lr: 0.140414, loss: 1.7963
2022-07-19 04:32:58 - train: epoch 0040, iter [04700, 05004], lr: 0.140353, loss: 1.6049
2022-07-19 04:35:15 - train: epoch 0040, iter [04800, 05004], lr: 0.140293, loss: 1.5394
2022-07-19 04:37:32 - train: epoch 0040, iter [04900, 05004], lr: 0.140232, loss: 1.4998
2022-07-19 04:39:49 - train: epoch 0040, iter [05000, 05004], lr: 0.140172, loss: 1.6047
2022-07-19 04:39:55 - train: epoch 040, train_loss: 1.6544
2022-07-19 04:42:03 - eval: epoch: 040, acc1: 64.680%, acc5: 86.802%, test_loss: 1.4582, per_image_load_time: 1.007ms, per_image_inference_time: 3.908ms
2022-07-19 04:42:03 - until epoch: 040, best_acc1: 65.234%
2022-07-19 04:42:03 - epoch 041 lr: 0.140169
2022-07-19 04:44:28 - train: epoch 0041, iter [00100, 05004], lr: 0.140109, loss: 2.1827
2022-07-19 04:46:45 - train: epoch 0041, iter [00200, 05004], lr: 0.140048, loss: 1.7414
2022-07-19 04:49:01 - train: epoch 0041, iter [00300, 05004], lr: 0.139988, loss: 1.6344
2022-07-19 04:51:18 - train: epoch 0041, iter [00400, 05004], lr: 0.139927, loss: 1.6438
2022-07-19 04:53:34 - train: epoch 0041, iter [00500, 05004], lr: 0.139867, loss: 1.4358
2022-07-19 04:55:51 - train: epoch 0041, iter [00600, 05004], lr: 0.139806, loss: 1.8359
2022-07-19 04:58:08 - train: epoch 0041, iter [00700, 05004], lr: 0.139745, loss: 1.5932
2022-07-19 05:00:24 - train: epoch 0041, iter [00800, 05004], lr: 0.139685, loss: 1.8082
2022-07-19 05:02:41 - train: epoch 0041, iter [00900, 05004], lr: 0.139624, loss: 1.3900
2022-07-19 05:04:58 - train: epoch 0041, iter [01000, 05004], lr: 0.139563, loss: 1.8481
2022-07-19 05:07:14 - train: epoch 0041, iter [01100, 05004], lr: 0.139503, loss: 1.5086
2022-07-19 05:09:31 - train: epoch 0041, iter [01200, 05004], lr: 0.139442, loss: 1.6379
2022-07-19 05:11:48 - train: epoch 0041, iter [01300, 05004], lr: 0.139381, loss: 1.4538
2022-07-19 05:14:04 - train: epoch 0041, iter [01400, 05004], lr: 0.139321, loss: 1.6392
2022-07-19 05:16:21 - train: epoch 0041, iter [01500, 05004], lr: 0.139260, loss: 1.8259
2022-07-19 05:18:38 - train: epoch 0041, iter [01600, 05004], lr: 0.139199, loss: 1.6282
2022-07-19 05:20:54 - train: epoch 0041, iter [01700, 05004], lr: 0.139138, loss: 1.7484
2022-07-19 05:23:11 - train: epoch 0041, iter [01800, 05004], lr: 0.139077, loss: 1.6351
2022-07-19 05:25:28 - train: epoch 0041, iter [01900, 05004], lr: 0.139017, loss: 1.8180
2022-07-19 05:27:44 - train: epoch 0041, iter [02000, 05004], lr: 0.138956, loss: 1.5389
2022-07-19 05:30:01 - train: epoch 0041, iter [02100, 05004], lr: 0.138895, loss: 1.4633
2022-07-19 05:32:18 - train: epoch 0041, iter [02200, 05004], lr: 0.138834, loss: 1.3683
2022-07-19 05:34:34 - train: epoch 0041, iter [02300, 05004], lr: 0.138773, loss: 1.6702
2022-07-19 05:36:51 - train: epoch 0041, iter [02400, 05004], lr: 0.138712, loss: 1.7423
2022-07-19 05:39:08 - train: epoch 0041, iter [02500, 05004], lr: 0.138651, loss: 1.6011
2022-07-19 05:41:24 - train: epoch 0041, iter [02600, 05004], lr: 0.138590, loss: 1.7794
2022-07-19 05:43:41 - train: epoch 0041, iter [02700, 05004], lr: 0.138529, loss: 1.6989
2022-07-19 05:45:58 - train: epoch 0041, iter [02800, 05004], lr: 0.138468, loss: 1.8617
2022-07-19 05:48:15 - train: epoch 0041, iter [02900, 05004], lr: 0.138407, loss: 1.7767
2022-07-19 05:50:32 - train: epoch 0041, iter [03000, 05004], lr: 0.138346, loss: 1.6217
2022-07-19 05:52:48 - train: epoch 0041, iter [03100, 05004], lr: 0.138285, loss: 1.9066
2022-07-19 05:55:05 - train: epoch 0041, iter [03200, 05004], lr: 0.138224, loss: 1.4070
2022-07-19 05:57:22 - train: epoch 0041, iter [03300, 05004], lr: 0.138163, loss: 1.4541
2022-07-19 05:59:38 - train: epoch 0041, iter [03400, 05004], lr: 0.138102, loss: 1.5657
2022-07-19 06:01:55 - train: epoch 0041, iter [03500, 05004], lr: 0.138041, loss: 1.4887
2022-07-19 06:04:12 - train: epoch 0041, iter [03600, 05004], lr: 0.137980, loss: 1.9035
2022-07-19 06:06:29 - train: epoch 0041, iter [03700, 05004], lr: 0.137919, loss: 1.5707
2022-07-19 06:08:45 - train: epoch 0041, iter [03800, 05004], lr: 0.137857, loss: 1.6617
2022-07-19 06:11:02 - train: epoch 0041, iter [03900, 05004], lr: 0.137796, loss: 1.6415
2022-07-19 06:13:19 - train: epoch 0041, iter [04000, 05004], lr: 0.137735, loss: 1.4829
2022-07-19 06:15:36 - train: epoch 0041, iter [04100, 05004], lr: 0.137674, loss: 1.8131
2022-07-19 06:17:53 - train: epoch 0041, iter [04200, 05004], lr: 0.137613, loss: 1.4140
2022-07-19 06:20:09 - train: epoch 0041, iter [04300, 05004], lr: 0.137551, loss: 1.5473
2022-07-19 06:22:26 - train: epoch 0041, iter [04400, 05004], lr: 0.137490, loss: 1.3928
2022-07-19 06:24:43 - train: epoch 0041, iter [04500, 05004], lr: 0.137429, loss: 1.7658
2022-07-19 06:26:59 - train: epoch 0041, iter [04600, 05004], lr: 0.137368, loss: 1.8195
2022-07-19 06:29:16 - train: epoch 0041, iter [04700, 05004], lr: 0.137306, loss: 1.6811
2022-07-19 06:31:33 - train: epoch 0041, iter [04800, 05004], lr: 0.137245, loss: 1.7348
2022-07-19 06:33:49 - train: epoch 0041, iter [04900, 05004], lr: 0.137184, loss: 1.5860
2022-07-19 06:36:06 - train: epoch 0041, iter [05000, 05004], lr: 0.137122, loss: 1.7829
2022-07-19 06:36:13 - train: epoch 041, train_loss: 1.6449
2022-07-19 06:38:20 - eval: epoch: 041, acc1: 65.802%, acc5: 87.528%, test_loss: 1.4045, per_image_load_time: 1.033ms, per_image_inference_time: 3.915ms
2022-07-19 06:38:21 - until epoch: 041, best_acc1: 65.802%
2022-07-19 06:38:21 - epoch 042 lr: 0.137119
2022-07-19 06:40:46 - train: epoch 0042, iter [00100, 05004], lr: 0.137058, loss: 1.4195
2022-07-19 06:43:02 - train: epoch 0042, iter [00200, 05004], lr: 0.136997, loss: 1.6209
2022-07-19 06:45:19 - train: epoch 0042, iter [00300, 05004], lr: 0.136936, loss: 1.6636
2022-07-19 06:47:36 - train: epoch 0042, iter [00400, 05004], lr: 0.136874, loss: 1.4572
2022-07-19 06:49:53 - train: epoch 0042, iter [00500, 05004], lr: 0.136813, loss: 1.5473
2022-07-19 06:52:10 - train: epoch 0042, iter [00600, 05004], lr: 0.136751, loss: 1.6642
2022-07-19 06:54:27 - train: epoch 0042, iter [00700, 05004], lr: 0.136690, loss: 1.6936
2022-07-19 06:56:44 - train: epoch 0042, iter [00800, 05004], lr: 0.136628, loss: 1.7002
2022-07-19 06:59:01 - train: epoch 0042, iter [00900, 05004], lr: 0.136567, loss: 1.6021
2022-07-19 07:01:17 - train: epoch 0042, iter [01000, 05004], lr: 0.136505, loss: 1.8694
2022-07-19 07:03:34 - train: epoch 0042, iter [01100, 05004], lr: 0.136444, loss: 1.4640
2022-07-19 07:05:51 - train: epoch 0042, iter [01200, 05004], lr: 0.136382, loss: 1.2854
2022-07-19 07:08:08 - train: epoch 0042, iter [01300, 05004], lr: 0.136321, loss: 1.7285
2022-07-19 07:10:24 - train: epoch 0042, iter [01400, 05004], lr: 0.136259, loss: 1.8313
2022-07-19 07:12:41 - train: epoch 0042, iter [01500, 05004], lr: 0.136197, loss: 1.6048
2022-07-19 07:14:58 - train: epoch 0042, iter [01600, 05004], lr: 0.136136, loss: 1.8186
2022-07-19 07:17:15 - train: epoch 0042, iter [01700, 05004], lr: 0.136074, loss: 1.5897
2022-07-19 07:19:32 - train: epoch 0042, iter [01800, 05004], lr: 0.136013, loss: 1.6194
2022-07-19 07:21:49 - train: epoch 0042, iter [01900, 05004], lr: 0.135951, loss: 1.7887
2022-07-19 07:24:05 - train: epoch 0042, iter [02000, 05004], lr: 0.135889, loss: 1.5122
2022-07-19 07:26:22 - train: epoch 0042, iter [02100, 05004], lr: 0.135828, loss: 1.3116
2022-07-19 07:28:39 - train: epoch 0042, iter [02200, 05004], lr: 0.135766, loss: 1.6156
2022-07-19 07:30:56 - train: epoch 0042, iter [02300, 05004], lr: 0.135704, loss: 1.5975
2022-07-19 07:33:13 - train: epoch 0042, iter [02400, 05004], lr: 0.135642, loss: 1.4887
2022-07-19 07:35:30 - train: epoch 0042, iter [02500, 05004], lr: 0.135581, loss: 1.7096
2022-07-19 07:37:46 - train: epoch 0042, iter [02600, 05004], lr: 0.135519, loss: 1.7237
2022-07-19 07:40:03 - train: epoch 0042, iter [02700, 05004], lr: 0.135457, loss: 1.5253
2022-07-19 07:42:20 - train: epoch 0042, iter [02800, 05004], lr: 0.135395, loss: 1.5203
2022-07-19 07:44:37 - train: epoch 0042, iter [02900, 05004], lr: 0.135333, loss: 1.7378
2022-07-19 07:46:54 - train: epoch 0042, iter [03000, 05004], lr: 0.135272, loss: 1.6106
2022-07-19 07:49:11 - train: epoch 0042, iter [03100, 05004], lr: 0.135210, loss: 1.4528
2022-07-19 07:51:28 - train: epoch 0042, iter [03200, 05004], lr: 0.135148, loss: 1.8088
2022-07-19 07:53:44 - train: epoch 0042, iter [03300, 05004], lr: 0.135086, loss: 1.8077
2022-07-19 07:56:01 - train: epoch 0042, iter [03400, 05004], lr: 0.135024, loss: 1.4117
2022-07-19 07:58:18 - train: epoch 0042, iter [03500, 05004], lr: 0.134962, loss: 1.7142
2022-07-19 08:00:35 - train: epoch 0042, iter [03600, 05004], lr: 0.134900, loss: 1.9440
2022-07-19 08:02:52 - train: epoch 0042, iter [03700, 05004], lr: 0.134838, loss: 1.9173
2022-07-19 08:05:09 - train: epoch 0042, iter [03800, 05004], lr: 0.134776, loss: 1.4509
2022-07-19 08:07:26 - train: epoch 0042, iter [03900, 05004], lr: 0.134714, loss: 1.6583
2022-07-19 08:09:42 - train: epoch 0042, iter [04000, 05004], lr: 0.134652, loss: 1.6705
2022-07-19 08:11:59 - train: epoch 0042, iter [04100, 05004], lr: 0.134590, loss: 1.7847
2022-07-19 08:14:16 - train: epoch 0042, iter [04200, 05004], lr: 0.134528, loss: 1.6251
2022-07-19 08:16:33 - train: epoch 0042, iter [04300, 05004], lr: 0.134466, loss: 1.5195
2022-07-19 08:18:50 - train: epoch 0042, iter [04400, 05004], lr: 0.134404, loss: 1.7977
2022-07-19 08:21:07 - train: epoch 0042, iter [04500, 05004], lr: 0.134342, loss: 1.5233
2022-07-19 08:23:24 - train: epoch 0042, iter [04600, 05004], lr: 0.134280, loss: 1.6470
2022-07-19 08:25:41 - train: epoch 0042, iter [04700, 05004], lr: 0.134218, loss: 1.6561
2022-07-19 08:27:58 - train: epoch 0042, iter [04800, 05004], lr: 0.134156, loss: 1.5524
2022-07-19 08:30:15 - train: epoch 0042, iter [04900, 05004], lr: 0.134094, loss: 1.7054
2022-07-19 08:32:32 - train: epoch 0042, iter [05000, 05004], lr: 0.134032, loss: 1.6531
2022-07-19 08:32:39 - train: epoch 042, train_loss: 1.6311
2022-07-19 08:34:46 - eval: epoch: 042, acc1: 65.296%, acc5: 87.158%, test_loss: 1.4412, per_image_load_time: 1.011ms, per_image_inference_time: 3.923ms
2022-07-19 08:34:46 - until epoch: 042, best_acc1: 65.802%
2022-07-19 08:34:46 - epoch 043 lr: 0.134029
2022-07-19 08:37:11 - train: epoch 0043, iter [00100, 05004], lr: 0.133967, loss: 1.9684
2022-07-19 08:39:28 - train: epoch 0043, iter [00200, 05004], lr: 0.133905, loss: 1.6329
2022-07-19 08:41:45 - train: epoch 0043, iter [00300, 05004], lr: 0.133843, loss: 1.5253
2022-07-19 08:44:03 - train: epoch 0043, iter [00400, 05004], lr: 0.133781, loss: 1.3918
2022-07-19 08:46:20 - train: epoch 0043, iter [00500, 05004], lr: 0.133718, loss: 1.4927
2022-07-19 08:48:37 - train: epoch 0043, iter [00600, 05004], lr: 0.133656, loss: 1.4687
2022-07-19 08:50:53 - train: epoch 0043, iter [00700, 05004], lr: 0.133594, loss: 1.6233
2022-07-19 08:53:10 - train: epoch 0043, iter [00800, 05004], lr: 0.133532, loss: 1.6427
2022-07-19 08:55:27 - train: epoch 0043, iter [00900, 05004], lr: 0.133469, loss: 1.4262
2022-07-19 08:57:43 - train: epoch 0043, iter [01000, 05004], lr: 0.133407, loss: 1.9300
2022-07-19 09:00:00 - train: epoch 0043, iter [01100, 05004], lr: 0.133345, loss: 1.6818
2022-07-19 09:02:18 - train: epoch 0043, iter [01200, 05004], lr: 0.133283, loss: 1.4717
2022-07-19 09:04:34 - train: epoch 0043, iter [01300, 05004], lr: 0.133220, loss: 1.6367
2022-07-19 09:06:52 - train: epoch 0043, iter [01400, 05004], lr: 0.133158, loss: 1.6777
2022-07-19 09:09:09 - train: epoch 0043, iter [01500, 05004], lr: 0.133096, loss: 1.4571
2022-07-19 09:11:27 - train: epoch 0043, iter [01600, 05004], lr: 0.133033, loss: 1.5787
2022-07-19 09:13:44 - train: epoch 0043, iter [01700, 05004], lr: 0.132971, loss: 1.6622
2022-07-19 09:16:01 - train: epoch 0043, iter [01800, 05004], lr: 0.132908, loss: 1.7849
2022-07-19 09:18:18 - train: epoch 0043, iter [01900, 05004], lr: 0.132846, loss: 1.7008
2022-07-19 09:20:35 - train: epoch 0043, iter [02000, 05004], lr: 0.132784, loss: 1.4728
2022-07-19 09:22:52 - train: epoch 0043, iter [02100, 05004], lr: 0.132721, loss: 1.5188
2022-07-19 09:25:09 - train: epoch 0043, iter [02200, 05004], lr: 0.132659, loss: 1.6041
2022-07-19 09:27:26 - train: epoch 0043, iter [02300, 05004], lr: 0.132596, loss: 1.8119
2022-07-19 09:29:43 - train: epoch 0043, iter [02400, 05004], lr: 0.132534, loss: 1.4448
2022-07-19 09:32:01 - train: epoch 0043, iter [02500, 05004], lr: 0.132471, loss: 1.6307
2022-07-19 09:34:18 - train: epoch 0043, iter [02600, 05004], lr: 0.132409, loss: 1.4812
2022-07-19 09:36:35 - train: epoch 0043, iter [02700, 05004], lr: 0.132346, loss: 1.7084
2022-07-19 09:38:53 - train: epoch 0043, iter [02800, 05004], lr: 0.132284, loss: 1.4961
2022-07-19 09:41:10 - train: epoch 0043, iter [02900, 05004], lr: 0.132221, loss: 1.5270
2022-07-19 09:43:27 - train: epoch 0043, iter [03000, 05004], lr: 0.132158, loss: 1.8652
2022-07-19 09:45:44 - train: epoch 0043, iter [03100, 05004], lr: 0.132096, loss: 1.8309
2022-07-19 09:48:01 - train: epoch 0043, iter [03200, 05004], lr: 0.132033, loss: 1.6665
2022-07-19 09:50:18 - train: epoch 0043, iter [03300, 05004], lr: 0.131971, loss: 1.6576
2022-07-19 09:52:35 - train: epoch 0043, iter [03400, 05004], lr: 0.131908, loss: 1.8028
2022-07-19 09:54:52 - train: epoch 0043, iter [03500, 05004], lr: 0.131845, loss: 1.6789
2022-07-19 09:57:09 - train: epoch 0043, iter [03600, 05004], lr: 0.131783, loss: 1.7598
2022-07-19 09:59:25 - train: epoch 0043, iter [03700, 05004], lr: 0.131720, loss: 1.4906
2022-07-19 10:01:42 - train: epoch 0043, iter [03800, 05004], lr: 0.131657, loss: 1.8164
2022-07-19 10:03:59 - train: epoch 0043, iter [03900, 05004], lr: 0.131595, loss: 1.6580
2022-07-19 10:06:16 - train: epoch 0043, iter [04000, 05004], lr: 0.131532, loss: 1.9442
2022-07-19 10:08:33 - train: epoch 0043, iter [04100, 05004], lr: 0.131469, loss: 1.8530
2022-07-19 10:10:50 - train: epoch 0043, iter [04200, 05004], lr: 0.131407, loss: 1.6167
2022-07-19 10:13:07 - train: epoch 0043, iter [04300, 05004], lr: 0.131344, loss: 1.7072
2022-07-19 10:15:23 - train: epoch 0043, iter [04400, 05004], lr: 0.131281, loss: 1.4910
2022-07-19 10:17:40 - train: epoch 0043, iter [04500, 05004], lr: 0.131218, loss: 1.5952
2022-07-19 10:19:57 - train: epoch 0043, iter [04600, 05004], lr: 0.131156, loss: 1.7276
2022-07-19 10:22:14 - train: epoch 0043, iter [04700, 05004], lr: 0.131093, loss: 1.7271
2022-07-19 10:24:31 - train: epoch 0043, iter [04800, 05004], lr: 0.131030, loss: 1.4627
2022-07-19 10:26:48 - train: epoch 0043, iter [04900, 05004], lr: 0.130967, loss: 1.6300
2022-07-19 10:29:05 - train: epoch 0043, iter [05000, 05004], lr: 0.130904, loss: 1.4740
2022-07-19 10:29:11 - train: epoch 043, train_loss: 1.6204
2022-07-19 10:31:20 - eval: epoch: 043, acc1: 65.286%, acc5: 87.290%, test_loss: 1.4278, per_image_load_time: 1.017ms, per_image_inference_time: 3.944ms
2022-07-19 10:31:20 - until epoch: 043, best_acc1: 65.802%
2022-07-19 10:31:20 - epoch 044 lr: 0.130901
2022-07-19 10:33:45 - train: epoch 0044, iter [00100, 05004], lr: 0.130839, loss: 1.6164
2022-07-19 10:36:02 - train: epoch 0044, iter [00200, 05004], lr: 0.130776, loss: 1.6518
2022-07-19 10:38:19 - train: epoch 0044, iter [00300, 05004], lr: 0.130713, loss: 1.7229
2022-07-19 10:40:36 - train: epoch 0044, iter [00400, 05004], lr: 0.130650, loss: 1.2853
2022-07-19 10:42:52 - train: epoch 0044, iter [00500, 05004], lr: 0.130587, loss: 1.4742
2022-07-19 10:45:09 - train: epoch 0044, iter [00600, 05004], lr: 0.130524, loss: 1.3758
2022-07-19 10:47:26 - train: epoch 0044, iter [00700, 05004], lr: 0.130461, loss: 1.4421
2022-07-19 10:49:42 - train: epoch 0044, iter [00800, 05004], lr: 0.130398, loss: 1.5970
2022-07-19 10:51:59 - train: epoch 0044, iter [00900, 05004], lr: 0.130335, loss: 1.6506
2022-07-19 10:54:16 - train: epoch 0044, iter [01000, 05004], lr: 0.130273, loss: 1.6659
2022-07-19 10:56:33 - train: epoch 0044, iter [01100, 05004], lr: 0.130210, loss: 1.4339
2022-07-19 10:58:50 - train: epoch 0044, iter [01200, 05004], lr: 0.130147, loss: 1.6327
2022-07-19 11:01:07 - train: epoch 0044, iter [01300, 05004], lr: 0.130084, loss: 1.6461
2022-07-19 11:03:24 - train: epoch 0044, iter [01400, 05004], lr: 0.130020, loss: 1.6689
2022-07-19 11:05:41 - train: epoch 0044, iter [01500, 05004], lr: 0.129957, loss: 1.7166
2022-07-19 11:07:57 - train: epoch 0044, iter [01600, 05004], lr: 0.129894, loss: 1.5880
2022-07-19 11:10:14 - train: epoch 0044, iter [01700, 05004], lr: 0.129831, loss: 1.5379
2022-07-19 11:12:31 - train: epoch 0044, iter [01800, 05004], lr: 0.129768, loss: 1.4786
2022-07-19 11:14:48 - train: epoch 0044, iter [01900, 05004], lr: 0.129705, loss: 1.9944
2022-07-19 11:17:05 - train: epoch 0044, iter [02000, 05004], lr: 0.129642, loss: 1.5960
2022-07-19 11:19:22 - train: epoch 0044, iter [02100, 05004], lr: 0.129579, loss: 1.8004
2022-07-19 11:21:39 - train: epoch 0044, iter [02200, 05004], lr: 0.129516, loss: 1.6718
2022-07-19 11:23:56 - train: epoch 0044, iter [02300, 05004], lr: 0.129453, loss: 1.4647
2022-07-19 11:26:13 - train: epoch 0044, iter [02400, 05004], lr: 0.129389, loss: 1.7134
2022-07-19 11:28:30 - train: epoch 0044, iter [02500, 05004], lr: 0.129326, loss: 1.6152
2022-07-19 11:30:47 - train: epoch 0044, iter [02600, 05004], lr: 0.129263, loss: 1.7114
2022-07-19 11:33:04 - train: epoch 0044, iter [02700, 05004], lr: 0.129200, loss: 1.4752
2022-07-19 11:35:21 - train: epoch 0044, iter [02800, 05004], lr: 0.129137, loss: 1.4687
2022-07-19 11:37:38 - train: epoch 0044, iter [02900, 05004], lr: 0.129073, loss: 1.2836
2022-07-19 11:39:55 - train: epoch 0044, iter [03000, 05004], lr: 0.129010, loss: 1.4648
2022-07-19 11:42:12 - train: epoch 0044, iter [03100, 05004], lr: 0.128947, loss: 1.6455
2022-07-19 11:44:29 - train: epoch 0044, iter [03200, 05004], lr: 0.128884, loss: 1.5248
2022-07-19 11:46:46 - train: epoch 0044, iter [03300, 05004], lr: 0.128820, loss: 1.6825
2022-07-19 11:49:03 - train: epoch 0044, iter [03400, 05004], lr: 0.128757, loss: 1.7982
2022-07-19 11:51:20 - train: epoch 0044, iter [03500, 05004], lr: 0.128694, loss: 1.5950
2022-07-19 11:53:37 - train: epoch 0044, iter [03600, 05004], lr: 0.128631, loss: 1.7545
2022-07-19 11:55:54 - train: epoch 0044, iter [03700, 05004], lr: 0.128567, loss: 1.7244
2022-07-19 11:58:11 - train: epoch 0044, iter [03800, 05004], lr: 0.128504, loss: 1.4384
2022-07-19 12:00:28 - train: epoch 0044, iter [03900, 05004], lr: 0.128441, loss: 1.4417
2022-07-19 12:02:44 - train: epoch 0044, iter [04000, 05004], lr: 0.128377, loss: 1.7746
2022-07-19 12:05:01 - train: epoch 0044, iter [04100, 05004], lr: 0.128314, loss: 1.6025
2022-07-19 12:07:18 - train: epoch 0044, iter [04200, 05004], lr: 0.128250, loss: 1.6851
2022-07-19 12:09:35 - train: epoch 0044, iter [04300, 05004], lr: 0.128187, loss: 1.5686
2022-07-19 12:11:52 - train: epoch 0044, iter [04400, 05004], lr: 0.128124, loss: 1.6568
2022-07-19 12:14:09 - train: epoch 0044, iter [04500, 05004], lr: 0.128060, loss: 1.7483
2022-07-19 12:16:25 - train: epoch 0044, iter [04600, 05004], lr: 0.127997, loss: 1.5860
2022-07-19 12:18:42 - train: epoch 0044, iter [04700, 05004], lr: 0.127933, loss: 1.8187
2022-07-19 12:20:59 - train: epoch 0044, iter [04800, 05004], lr: 0.127870, loss: 1.9099
2022-07-19 12:23:16 - train: epoch 0044, iter [04900, 05004], lr: 0.127806, loss: 1.6673
2022-07-19 12:25:33 - train: epoch 0044, iter [05000, 05004], lr: 0.127743, loss: 1.5001
2022-07-19 12:25:39 - train: epoch 044, train_loss: 1.6068
2022-07-19 12:27:43 - eval: epoch: 044, acc1: 66.366%, acc5: 87.912%, test_loss: 1.3699, per_image_load_time: 0.892ms, per_image_inference_time: 3.899ms
2022-07-19 12:27:44 - until epoch: 044, best_acc1: 66.366%
2022-07-19 12:27:44 - epoch 045 lr: 0.127740
2022-07-19 12:30:09 - train: epoch 0045, iter [00100, 05004], lr: 0.127677, loss: 1.4667
2022-07-19 12:32:25 - train: epoch 0045, iter [00200, 05004], lr: 0.127613, loss: 1.4110
2022-07-19 12:34:42 - train: epoch 0045, iter [00300, 05004], lr: 0.127550, loss: 1.6097
2022-07-19 12:36:59 - train: epoch 0045, iter [00400, 05004], lr: 0.127486, loss: 1.6423
2022-07-19 12:39:15 - train: epoch 0045, iter [00500, 05004], lr: 0.127423, loss: 1.6849
2022-07-19 12:41:32 - train: epoch 0045, iter [00600, 05004], lr: 0.127359, loss: 1.6613
2022-07-19 12:43:48 - train: epoch 0045, iter [00700, 05004], lr: 0.127296, loss: 1.4222
2022-07-19 12:46:05 - train: epoch 0045, iter [00800, 05004], lr: 0.127232, loss: 1.4477
2022-07-19 12:48:22 - train: epoch 0045, iter [00900, 05004], lr: 0.127168, loss: 1.4062
2022-07-19 12:50:39 - train: epoch 0045, iter [01000, 05004], lr: 0.127105, loss: 1.6056
2022-07-19 12:52:55 - train: epoch 0045, iter [01100, 05004], lr: 0.127041, loss: 1.6012
2022-07-19 12:55:12 - train: epoch 0045, iter [01200, 05004], lr: 0.126978, loss: 1.3912
2022-07-19 12:57:28 - train: epoch 0045, iter [01300, 05004], lr: 0.126914, loss: 1.6144
2022-07-19 12:59:45 - train: epoch 0045, iter [01400, 05004], lr: 0.126850, loss: 1.7693
2022-07-19 13:02:02 - train: epoch 0045, iter [01500, 05004], lr: 0.126787, loss: 1.4670
2022-07-19 13:04:19 - train: epoch 0045, iter [01600, 05004], lr: 0.126723, loss: 1.5109
2022-07-19 13:06:35 - train: epoch 0045, iter [01700, 05004], lr: 0.126659, loss: 1.4739
2022-07-19 13:08:52 - train: epoch 0045, iter [01800, 05004], lr: 0.126595, loss: 1.5658
2022-07-19 13:11:09 - train: epoch 0045, iter [01900, 05004], lr: 0.126532, loss: 1.4997
2022-07-19 13:13:25 - train: epoch 0045, iter [02000, 05004], lr: 0.126468, loss: 1.7700
2022-07-19 13:15:42 - train: epoch 0045, iter [02100, 05004], lr: 0.126404, loss: 1.7727
2022-07-19 13:17:59 - train: epoch 0045, iter [02200, 05004], lr: 0.126341, loss: 1.6308
2022-07-19 13:20:16 - train: epoch 0045, iter [02300, 05004], lr: 0.126277, loss: 1.5246
2022-07-19 13:22:33 - train: epoch 0045, iter [02400, 05004], lr: 0.126213, loss: 1.7106
2022-07-19 13:24:49 - train: epoch 0045, iter [02500, 05004], lr: 0.126149, loss: 1.4089
2022-07-19 13:27:06 - train: epoch 0045, iter [02600, 05004], lr: 0.126085, loss: 1.5179
2022-07-19 13:29:23 - train: epoch 0045, iter [02700, 05004], lr: 0.126022, loss: 1.5502
2022-07-19 13:31:40 - train: epoch 0045, iter [02800, 05004], lr: 0.125958, loss: 1.5091
2022-07-19 13:33:56 - train: epoch 0045, iter [02900, 05004], lr: 0.125894, loss: 1.5823
2022-07-19 13:36:13 - train: epoch 0045, iter [03000, 05004], lr: 0.125830, loss: 1.5289
2022-07-19 13:38:30 - train: epoch 0045, iter [03100, 05004], lr: 0.125766, loss: 1.6679
2022-07-19 13:40:47 - train: epoch 0045, iter [03200, 05004], lr: 0.125702, loss: 1.8162
2022-07-19 13:43:04 - train: epoch 0045, iter [03300, 05004], lr: 0.125639, loss: 1.6554
2022-07-19 13:45:21 - train: epoch 0045, iter [03400, 05004], lr: 0.125575, loss: 1.5399
2022-07-19 13:47:38 - train: epoch 0045, iter [03500, 05004], lr: 0.125511, loss: 1.9156
2022-07-19 13:49:54 - train: epoch 0045, iter [03600, 05004], lr: 0.125447, loss: 1.6960
2022-07-19 13:52:11 - train: epoch 0045, iter [03700, 05004], lr: 0.125383, loss: 1.4715
2022-07-19 13:54:28 - train: epoch 0045, iter [03800, 05004], lr: 0.125319, loss: 1.7774
2022-07-19 13:56:45 - train: epoch 0045, iter [03900, 05004], lr: 0.125255, loss: 1.8845
2022-07-19 13:59:02 - train: epoch 0045, iter [04000, 05004], lr: 0.125191, loss: 1.7070
2022-07-19 14:01:19 - train: epoch 0045, iter [04100, 05004], lr: 0.125127, loss: 1.5404
2022-07-19 14:03:36 - train: epoch 0045, iter [04200, 05004], lr: 0.125063, loss: 1.7088
2022-07-19 14:05:53 - train: epoch 0045, iter [04300, 05004], lr: 0.124999, loss: 1.7768
2022-07-19 14:08:10 - train: epoch 0045, iter [04400, 05004], lr: 0.124935, loss: 1.6909
2022-07-19 14:10:27 - train: epoch 0045, iter [04500, 05004], lr: 0.124871, loss: 1.5699
2022-07-19 14:12:44 - train: epoch 0045, iter [04600, 05004], lr: 0.124807, loss: 1.7620
2022-07-19 14:15:01 - train: epoch 0045, iter [04700, 05004], lr: 0.124743, loss: 1.4806
2022-07-19 14:17:18 - train: epoch 0045, iter [04800, 05004], lr: 0.124679, loss: 1.5469
2022-07-19 14:19:35 - train: epoch 0045, iter [04900, 05004], lr: 0.124615, loss: 1.7075
2022-07-19 14:21:52 - train: epoch 0045, iter [05000, 05004], lr: 0.124551, loss: 1.5575
2022-07-19 14:21:59 - train: epoch 045, train_loss: 1.5938
2022-07-19 14:24:05 - eval: epoch: 045, acc1: 66.398%, acc5: 87.980%, test_loss: 1.3622, per_image_load_time: 0.926ms, per_image_inference_time: 3.890ms
2022-07-19 14:24:05 - until epoch: 045, best_acc1: 66.398%
2022-07-19 14:24:05 - epoch 046 lr: 0.124548
2022-07-19 14:26:30 - train: epoch 0046, iter [00100, 05004], lr: 0.124484, loss: 1.3008
2022-07-19 14:28:46 - train: epoch 0046, iter [00200, 05004], lr: 0.124420, loss: 1.3840
2022-07-19 14:31:03 - train: epoch 0046, iter [00300, 05004], lr: 0.124356, loss: 1.5680
2022-07-19 14:33:20 - train: epoch 0046, iter [00400, 05004], lr: 0.124292, loss: 1.3972
2022-07-19 14:35:36 - train: epoch 0046, iter [00500, 05004], lr: 0.124228, loss: 1.5625
2022-07-19 14:37:53 - train: epoch 0046, iter [00600, 05004], lr: 0.124164, loss: 1.5367
2022-07-19 14:40:10 - train: epoch 0046, iter [00700, 05004], lr: 0.124100, loss: 1.3591
2022-07-19 14:42:26 - train: epoch 0046, iter [00800, 05004], lr: 0.124036, loss: 1.6907
2022-07-19 14:44:43 - train: epoch 0046, iter [00900, 05004], lr: 0.123972, loss: 1.4394
2022-07-19 14:46:59 - train: epoch 0046, iter [01000, 05004], lr: 0.123907, loss: 1.4882
2022-07-19 14:49:16 - train: epoch 0046, iter [01100, 05004], lr: 0.123843, loss: 1.5216
2022-07-19 14:51:33 - train: epoch 0046, iter [01200, 05004], lr: 0.123779, loss: 1.4313
2022-07-19 14:53:49 - train: epoch 0046, iter [01300, 05004], lr: 0.123715, loss: 1.5787
2022-07-19 14:56:06 - train: epoch 0046, iter [01400, 05004], lr: 0.123651, loss: 1.7241
2022-07-19 14:58:23 - train: epoch 0046, iter [01500, 05004], lr: 0.123586, loss: 1.6499
2022-07-19 15:00:39 - train: epoch 0046, iter [01600, 05004], lr: 0.123522, loss: 1.6434
2022-07-19 15:02:56 - train: epoch 0046, iter [01700, 05004], lr: 0.123458, loss: 1.5322
2022-07-19 15:05:12 - train: epoch 0046, iter [01800, 05004], lr: 0.123394, loss: 1.6022
2022-07-19 15:07:29 - train: epoch 0046, iter [01900, 05004], lr: 0.123329, loss: 1.4616
2022-07-19 15:09:46 - train: epoch 0046, iter [02000, 05004], lr: 0.123265, loss: 1.4202
2022-07-19 15:12:02 - train: epoch 0046, iter [02100, 05004], lr: 0.123201, loss: 1.6927
2022-07-19 15:14:19 - train: epoch 0046, iter [02200, 05004], lr: 0.123137, loss: 1.3670
2022-07-19 15:16:36 - train: epoch 0046, iter [02300, 05004], lr: 0.123072, loss: 1.6893
2022-07-19 15:18:52 - train: epoch 0046, iter [02400, 05004], lr: 0.123008, loss: 1.6053
2022-07-19 15:21:09 - train: epoch 0046, iter [02500, 05004], lr: 0.122944, loss: 1.5617
2022-07-19 15:23:26 - train: epoch 0046, iter [02600, 05004], lr: 0.122879, loss: 1.8719
2022-07-19 15:25:42 - train: epoch 0046, iter [02700, 05004], lr: 0.122815, loss: 1.3276
2022-07-19 15:27:59 - train: epoch 0046, iter [02800, 05004], lr: 0.122751, loss: 1.3111
2022-07-19 15:30:15 - train: epoch 0046, iter [02900, 05004], lr: 0.122686, loss: 1.7379
2022-07-19 15:32:32 - train: epoch 0046, iter [03000, 05004], lr: 0.122622, loss: 1.4021
2022-07-19 15:34:49 - train: epoch 0046, iter [03100, 05004], lr: 0.122558, loss: 1.3935
2022-07-19 15:37:05 - train: epoch 0046, iter [03200, 05004], lr: 0.122493, loss: 1.7050
2022-07-19 15:39:22 - train: epoch 0046, iter [03300, 05004], lr: 0.122429, loss: 1.7132
2022-07-19 15:41:39 - train: epoch 0046, iter [03400, 05004], lr: 0.122364, loss: 1.5346
2022-07-19 15:43:55 - train: epoch 0046, iter [03500, 05004], lr: 0.122300, loss: 1.6772
2022-07-19 15:46:12 - train: epoch 0046, iter [03600, 05004], lr: 0.122236, loss: 1.6761
2022-07-19 15:48:29 - train: epoch 0046, iter [03700, 05004], lr: 0.122171, loss: 1.4828
2022-07-19 15:50:46 - train: epoch 0046, iter [03800, 05004], lr: 0.122107, loss: 1.5142
2022-07-19 15:53:03 - train: epoch 0046, iter [03900, 05004], lr: 0.122042, loss: 1.4828
2022-07-19 15:55:20 - train: epoch 0046, iter [04000, 05004], lr: 0.121978, loss: 1.4297
2022-07-19 15:57:37 - train: epoch 0046, iter [04100, 05004], lr: 0.121913, loss: 1.6795
2022-07-19 15:59:54 - train: epoch 0046, iter [04200, 05004], lr: 0.121849, loss: 1.3639
2022-07-19 16:02:11 - train: epoch 0046, iter [04300, 05004], lr: 0.121784, loss: 1.8627
2022-07-19 16:04:28 - train: epoch 0046, iter [04400, 05004], lr: 0.121720, loss: 1.7837
2022-07-19 16:06:46 - train: epoch 0046, iter [04500, 05004], lr: 0.121655, loss: 1.3775
2022-07-19 16:09:03 - train: epoch 0046, iter [04600, 05004], lr: 0.121591, loss: 1.6838
2022-07-19 16:11:20 - train: epoch 0046, iter [04700, 05004], lr: 0.121526, loss: 1.4951
2022-07-19 16:13:37 - train: epoch 0046, iter [04800, 05004], lr: 0.121462, loss: 1.4656
2022-07-19 16:15:55 - train: epoch 0046, iter [04900, 05004], lr: 0.121397, loss: 1.7308
2022-07-19 16:18:12 - train: epoch 0046, iter [05000, 05004], lr: 0.121333, loss: 1.4615
2022-07-19 16:18:18 - train: epoch 046, train_loss: 1.5820
2022-07-19 16:20:33 - eval: epoch: 046, acc1: 66.696%, acc5: 87.944%, test_loss: 1.3654, per_image_load_time: 1.248ms, per_image_inference_time: 3.938ms
2022-07-19 16:20:33 - until epoch: 046, best_acc1: 66.696%
2022-07-19 16:20:33 - epoch 047 lr: 0.121329
2022-07-19 16:22:58 - train: epoch 0047, iter [00100, 05004], lr: 0.121265, loss: 1.5964
2022-07-19 16:25:15 - train: epoch 0047, iter [00200, 05004], lr: 0.121201, loss: 1.6208
2022-07-19 16:27:33 - train: epoch 0047, iter [00300, 05004], lr: 0.121136, loss: 1.4494
2022-07-19 16:29:50 - train: epoch 0047, iter [00400, 05004], lr: 0.121072, loss: 1.4133
2022-07-19 16:32:07 - train: epoch 0047, iter [00500, 05004], lr: 0.121007, loss: 1.4894
2022-07-19 16:34:24 - train: epoch 0047, iter [00600, 05004], lr: 0.120942, loss: 1.3629
2022-07-19 16:36:42 - train: epoch 0047, iter [00700, 05004], lr: 0.120878, loss: 1.5059
2022-07-19 16:38:59 - train: epoch 0047, iter [00800, 05004], lr: 0.120813, loss: 1.6323
2022-07-19 16:41:17 - train: epoch 0047, iter [00900, 05004], lr: 0.120749, loss: 1.7516
2022-07-19 16:43:35 - train: epoch 0047, iter [01000, 05004], lr: 0.120684, loss: 1.5894
2022-07-19 16:45:53 - train: epoch 0047, iter [01100, 05004], lr: 0.120619, loss: 1.6675
2022-07-19 16:48:11 - train: epoch 0047, iter [01200, 05004], lr: 0.120555, loss: 1.6688
2022-07-19 16:50:28 - train: epoch 0047, iter [01300, 05004], lr: 0.120490, loss: 1.5679
2022-07-19 16:52:46 - train: epoch 0047, iter [01400, 05004], lr: 0.120425, loss: 1.7049
2022-07-19 16:55:04 - train: epoch 0047, iter [01500, 05004], lr: 0.120360, loss: 1.6257
2022-07-19 16:57:22 - train: epoch 0047, iter [01600, 05004], lr: 0.120296, loss: 1.4586
2022-07-19 16:59:40 - train: epoch 0047, iter [01700, 05004], lr: 0.120231, loss: 1.4602
2022-07-19 17:01:58 - train: epoch 0047, iter [01800, 05004], lr: 0.120166, loss: 1.7198
2022-07-19 17:04:16 - train: epoch 0047, iter [01900, 05004], lr: 0.120102, loss: 1.4047
2022-07-19 17:06:33 - train: epoch 0047, iter [02000, 05004], lr: 0.120037, loss: 1.6720
2022-07-19 17:08:51 - train: epoch 0047, iter [02100, 05004], lr: 0.119972, loss: 1.7644
2022-07-19 17:11:09 - train: epoch 0047, iter [02200, 05004], lr: 0.119907, loss: 1.6099
2022-07-19 17:13:27 - train: epoch 0047, iter [02300, 05004], lr: 0.119843, loss: 1.7090
2022-07-19 17:15:46 - train: epoch 0047, iter [02400, 05004], lr: 0.119778, loss: 1.4404
2022-07-19 17:18:03 - train: epoch 0047, iter [02500, 05004], lr: 0.119713, loss: 1.6701
2022-07-19 17:20:21 - train: epoch 0047, iter [02600, 05004], lr: 0.119648, loss: 1.8286
2022-07-19 17:22:38 - train: epoch 0047, iter [02700, 05004], lr: 0.119583, loss: 1.4526
2022-07-19 17:24:56 - train: epoch 0047, iter [02800, 05004], lr: 0.119519, loss: 1.6428
2022-07-19 17:27:13 - train: epoch 0047, iter [02900, 05004], lr: 0.119454, loss: 1.4508
2022-07-19 17:29:31 - train: epoch 0047, iter [03000, 05004], lr: 0.119389, loss: 1.6222
2022-07-19 17:31:49 - train: epoch 0047, iter [03100, 05004], lr: 0.119324, loss: 1.5318
2022-07-19 17:34:06 - train: epoch 0047, iter [03200, 05004], lr: 0.119259, loss: 1.6733
2022-07-19 17:36:24 - train: epoch 0047, iter [03300, 05004], lr: 0.119194, loss: 1.3794
2022-07-19 17:38:41 - train: epoch 0047, iter [03400, 05004], lr: 0.119130, loss: 1.5110
2022-07-19 17:40:59 - train: epoch 0047, iter [03500, 05004], lr: 0.119065, loss: 1.7314
2022-07-19 17:43:17 - train: epoch 0047, iter [03600, 05004], lr: 0.119000, loss: 1.8187
2022-07-19 17:45:34 - train: epoch 0047, iter [03700, 05004], lr: 0.118935, loss: 1.5362
2022-07-19 17:47:52 - train: epoch 0047, iter [03800, 05004], lr: 0.118870, loss: 1.5474
2022-07-19 17:50:09 - train: epoch 0047, iter [03900, 05004], lr: 0.118805, loss: 1.7244
2022-07-19 17:52:26 - train: epoch 0047, iter [04000, 05004], lr: 0.118740, loss: 1.5625
2022-07-19 17:54:44 - train: epoch 0047, iter [04100, 05004], lr: 0.118675, loss: 1.6163
2022-07-19 17:57:01 - train: epoch 0047, iter [04200, 05004], lr: 0.118610, loss: 1.5476
2022-07-19 17:59:19 - train: epoch 0047, iter [04300, 05004], lr: 0.118545, loss: 1.6321
2022-07-19 18:01:36 - train: epoch 0047, iter [04400, 05004], lr: 0.118480, loss: 1.7469
2022-07-19 18:03:53 - train: epoch 0047, iter [04500, 05004], lr: 0.118416, loss: 1.5379
2022-07-19 18:06:11 - train: epoch 0047, iter [04600, 05004], lr: 0.118351, loss: 1.5306
2022-07-19 18:08:28 - train: epoch 0047, iter [04700, 05004], lr: 0.118286, loss: 1.6862
2022-07-19 18:10:46 - train: epoch 0047, iter [04800, 05004], lr: 0.118221, loss: 1.3660
2022-07-19 18:13:03 - train: epoch 0047, iter [04900, 05004], lr: 0.118156, loss: 1.6964
2022-07-19 18:15:20 - train: epoch 0047, iter [05000, 05004], lr: 0.118091, loss: 1.5380
2022-07-19 18:15:27 - train: epoch 047, train_loss: 1.5677
2022-07-19 18:17:31 - eval: epoch: 047, acc1: 66.716%, acc5: 88.076%, test_loss: 1.3496, per_image_load_time: 0.950ms, per_image_inference_time: 3.896ms
2022-07-19 18:17:31 - until epoch: 047, best_acc1: 66.716%
2022-07-19 18:17:31 - epoch 048 lr: 0.118087
2022-07-19 18:19:57 - train: epoch 0048, iter [00100, 05004], lr: 0.118023, loss: 1.6540
2022-07-19 18:22:14 - train: epoch 0048, iter [00200, 05004], lr: 0.117958, loss: 1.7217
2022-07-19 18:24:30 - train: epoch 0048, iter [00300, 05004], lr: 0.117893, loss: 1.5276
2022-07-19 18:26:47 - train: epoch 0048, iter [00400, 05004], lr: 0.117828, loss: 1.5039
2022-07-19 18:29:04 - train: epoch 0048, iter [00500, 05004], lr: 0.117763, loss: 1.4369
2022-07-19 18:31:22 - train: epoch 0048, iter [00600, 05004], lr: 0.117698, loss: 1.5341
2022-07-19 18:33:38 - train: epoch 0048, iter [00700, 05004], lr: 0.117633, loss: 1.6193
2022-07-19 18:35:55 - train: epoch 0048, iter [00800, 05004], lr: 0.117568, loss: 1.5959
2022-07-19 18:38:12 - train: epoch 0048, iter [00900, 05004], lr: 0.117503, loss: 1.7046
2022-07-19 18:40:30 - train: epoch 0048, iter [01000, 05004], lr: 0.117438, loss: 1.5138
2022-07-19 18:42:47 - train: epoch 0048, iter [01100, 05004], lr: 0.117373, loss: 1.7072
2022-07-19 18:45:04 - train: epoch 0048, iter [01200, 05004], lr: 0.117308, loss: 1.5596
2022-07-19 18:47:21 - train: epoch 0048, iter [01300, 05004], lr: 0.117242, loss: 1.5832
2022-07-19 18:49:38 - train: epoch 0048, iter [01400, 05004], lr: 0.117177, loss: 1.5392
2022-07-19 18:51:55 - train: epoch 0048, iter [01500, 05004], lr: 0.117112, loss: 1.5723
2022-07-19 18:54:12 - train: epoch 0048, iter [01600, 05004], lr: 0.117047, loss: 1.6942
2022-07-19 18:56:30 - train: epoch 0048, iter [01700, 05004], lr: 0.116982, loss: 1.5981
2022-07-19 18:58:47 - train: epoch 0048, iter [01800, 05004], lr: 0.116917, loss: 1.7659
2022-07-19 19:01:05 - train: epoch 0048, iter [01900, 05004], lr: 0.116852, loss: 1.4967
2022-07-19 19:03:22 - train: epoch 0048, iter [02000, 05004], lr: 0.116787, loss: 1.7332
2022-07-19 19:05:39 - train: epoch 0048, iter [02100, 05004], lr: 0.116721, loss: 1.6149
2022-07-19 19:07:57 - train: epoch 0048, iter [02200, 05004], lr: 0.116656, loss: 1.7721
2022-07-19 19:10:15 - train: epoch 0048, iter [02300, 05004], lr: 0.116591, loss: 1.5441
2022-07-19 19:12:32 - train: epoch 0048, iter [02400, 05004], lr: 0.116526, loss: 1.7749
2022-07-19 19:14:50 - train: epoch 0048, iter [02500, 05004], lr: 0.116461, loss: 1.6280
2022-07-19 19:17:07 - train: epoch 0048, iter [02600, 05004], lr: 0.116396, loss: 1.6157
2022-07-19 19:19:25 - train: epoch 0048, iter [02700, 05004], lr: 0.116330, loss: 1.7131
2022-07-19 19:21:42 - train: epoch 0048, iter [02800, 05004], lr: 0.116265, loss: 1.4753
2022-07-19 19:23:59 - train: epoch 0048, iter [02900, 05004], lr: 0.116200, loss: 1.7496
2022-07-19 19:26:17 - train: epoch 0048, iter [03000, 05004], lr: 0.116135, loss: 1.5733
2022-07-19 19:28:35 - train: epoch 0048, iter [03100, 05004], lr: 0.116070, loss: 1.7867
2022-07-19 19:30:52 - train: epoch 0048, iter [03200, 05004], lr: 0.116004, loss: 1.4550
2022-07-19 19:33:10 - train: epoch 0048, iter [03300, 05004], lr: 0.115939, loss: 1.6234
2022-07-19 19:35:27 - train: epoch 0048, iter [03400, 05004], lr: 0.115874, loss: 1.6862
2022-07-19 19:37:45 - train: epoch 0048, iter [03500, 05004], lr: 0.115809, loss: 1.8821
2022-07-19 19:40:02 - train: epoch 0048, iter [03600, 05004], lr: 0.115743, loss: 1.6960
2022-07-19 19:42:20 - train: epoch 0048, iter [03700, 05004], lr: 0.115678, loss: 1.6832
2022-07-19 19:44:37 - train: epoch 0048, iter [03800, 05004], lr: 0.115613, loss: 1.6076
2022-07-19 19:46:55 - train: epoch 0048, iter [03900, 05004], lr: 0.115547, loss: 1.3318
2022-07-19 19:49:12 - train: epoch 0048, iter [04000, 05004], lr: 0.115482, loss: 1.3874
2022-07-19 19:51:30 - train: epoch 0048, iter [04100, 05004], lr: 0.115417, loss: 1.7562
2022-07-19 19:53:48 - train: epoch 0048, iter [04200, 05004], lr: 0.115352, loss: 1.4323
2022-07-19 19:56:05 - train: epoch 0048, iter [04300, 05004], lr: 0.115286, loss: 1.5938
2022-07-19 19:58:23 - train: epoch 0048, iter [04400, 05004], lr: 0.115221, loss: 1.6447
2022-07-19 20:00:40 - train: epoch 0048, iter [04500, 05004], lr: 0.115156, loss: 1.7569
2022-07-19 20:02:58 - train: epoch 0048, iter [04600, 05004], lr: 0.115090, loss: 1.5006
2022-07-19 20:05:16 - train: epoch 0048, iter [04700, 05004], lr: 0.115025, loss: 1.5196
2022-07-19 20:07:33 - train: epoch 0048, iter [04800, 05004], lr: 0.114960, loss: 1.6047
2022-07-19 20:09:51 - train: epoch 0048, iter [04900, 05004], lr: 0.114894, loss: 1.5607
2022-07-19 20:12:09 - train: epoch 0048, iter [05000, 05004], lr: 0.114829, loss: 1.5411
2022-07-19 20:12:15 - train: epoch 048, train_loss: 1.5579
2022-07-19 20:14:27 - eval: epoch: 048, acc1: 67.470%, acc5: 88.524%, test_loss: 1.3227, per_image_load_time: 1.143ms, per_image_inference_time: 3.925ms
2022-07-19 20:14:27 - until epoch: 048, best_acc1: 67.470%
2022-07-19 20:14:27 - epoch 049 lr: 0.114826
2022-07-19 20:16:54 - train: epoch 0049, iter [00100, 05004], lr: 0.114761, loss: 1.6906
2022-07-19 20:19:11 - train: epoch 0049, iter [00200, 05004], lr: 0.114696, loss: 1.5018
2022-07-19 20:21:28 - train: epoch 0049, iter [00300, 05004], lr: 0.114630, loss: 1.5610
2022-07-19 20:23:44 - train: epoch 0049, iter [00400, 05004], lr: 0.114565, loss: 1.7081
2022-07-19 20:26:01 - train: epoch 0049, iter [00500, 05004], lr: 0.114500, loss: 1.6991
2022-07-19 20:28:18 - train: epoch 0049, iter [00600, 05004], lr: 0.114434, loss: 1.3675
2022-07-19 20:30:35 - train: epoch 0049, iter [00700, 05004], lr: 0.114369, loss: 1.5244
2022-07-19 20:32:53 - train: epoch 0049, iter [00800, 05004], lr: 0.114303, loss: 1.8682
2022-07-19 20:35:10 - train: epoch 0049, iter [00900, 05004], lr: 0.114238, loss: 1.4168
2022-07-19 20:37:27 - train: epoch 0049, iter [01000, 05004], lr: 0.114172, loss: 1.5183
2022-07-19 20:39:44 - train: epoch 0049, iter [01100, 05004], lr: 0.114107, loss: 1.4825
2022-07-19 20:42:00 - train: epoch 0049, iter [01200, 05004], lr: 0.114042, loss: 1.4259
2022-07-19 20:44:17 - train: epoch 0049, iter [01300, 05004], lr: 0.113976, loss: 1.6838
2022-07-19 20:46:34 - train: epoch 0049, iter [01400, 05004], lr: 0.113911, loss: 1.7411
2022-07-19 20:48:51 - train: epoch 0049, iter [01500, 05004], lr: 0.113845, loss: 1.5143
2022-07-19 20:51:07 - train: epoch 0049, iter [01600, 05004], lr: 0.113780, loss: 1.4732
2022-07-19 20:53:24 - train: epoch 0049, iter [01700, 05004], lr: 0.113714, loss: 1.5224
2022-07-19 20:55:41 - train: epoch 0049, iter [01800, 05004], lr: 0.113649, loss: 1.4575
2022-07-19 20:57:58 - train: epoch 0049, iter [01900, 05004], lr: 0.113583, loss: 1.4421
2022-07-19 21:00:15 - train: epoch 0049, iter [02000, 05004], lr: 0.113518, loss: 1.6240
2022-07-19 21:02:31 - train: epoch 0049, iter [02100, 05004], lr: 0.113453, loss: 1.4096
2022-07-19 21:04:48 - train: epoch 0049, iter [02200, 05004], lr: 0.113387, loss: 1.5268
2022-07-19 21:07:05 - train: epoch 0049, iter [02300, 05004], lr: 0.113322, loss: 1.4884
2022-07-19 21:09:22 - train: epoch 0049, iter [02400, 05004], lr: 0.113256, loss: 1.4515
2022-07-19 21:11:39 - train: epoch 0049, iter [02500, 05004], lr: 0.113191, loss: 1.5102
2022-07-19 21:13:56 - train: epoch 0049, iter [02600, 05004], lr: 0.113125, loss: 1.5110
2022-07-19 21:16:12 - train: epoch 0049, iter [02700, 05004], lr: 0.113059, loss: 1.6194
2022-07-19 21:18:29 - train: epoch 0049, iter [02800, 05004], lr: 0.112994, loss: 1.5740
2022-07-19 21:20:46 - train: epoch 0049, iter [02900, 05004], lr: 0.112928, loss: 1.5624
2022-07-19 21:23:03 - train: epoch 0049, iter [03000, 05004], lr: 0.112863, loss: 1.5809
2022-07-19 21:25:19 - train: epoch 0049, iter [03100, 05004], lr: 0.112797, loss: 1.6307
2022-07-19 21:27:36 - train: epoch 0049, iter [03200, 05004], lr: 0.112732, loss: 1.6951
2022-07-19 21:29:53 - train: epoch 0049, iter [03300, 05004], lr: 0.112666, loss: 1.5078
2022-07-19 21:32:10 - train: epoch 0049, iter [03400, 05004], lr: 0.112601, loss: 1.5892
2022-07-19 21:34:27 - train: epoch 0049, iter [03500, 05004], lr: 0.112535, loss: 1.7780
2022-07-19 21:36:44 - train: epoch 0049, iter [03600, 05004], lr: 0.112470, loss: 1.4474
2022-07-19 21:39:00 - train: epoch 0049, iter [03700, 05004], lr: 0.112404, loss: 1.4305
2022-07-19 21:41:17 - train: epoch 0049, iter [03800, 05004], lr: 0.112338, loss: 1.7680
2022-07-19 21:43:34 - train: epoch 0049, iter [03900, 05004], lr: 0.112273, loss: 1.6355
2022-07-19 21:45:51 - train: epoch 0049, iter [04000, 05004], lr: 0.112207, loss: 1.5068
2022-07-19 21:48:08 - train: epoch 0049, iter [04100, 05004], lr: 0.112142, loss: 1.3275
2022-07-19 21:50:25 - train: epoch 0049, iter [04200, 05004], lr: 0.112076, loss: 1.5759
2022-07-19 21:52:42 - train: epoch 0049, iter [04300, 05004], lr: 0.112010, loss: 1.6421
2022-07-19 21:54:58 - train: epoch 0049, iter [04400, 05004], lr: 0.111945, loss: 1.6096
2022-07-19 21:57:16 - train: epoch 0049, iter [04500, 05004], lr: 0.111879, loss: 1.3246
2022-07-19 21:59:33 - train: epoch 0049, iter [04600, 05004], lr: 0.111814, loss: 1.5151
2022-07-19 22:01:50 - train: epoch 0049, iter [04700, 05004], lr: 0.111748, loss: 1.8064
2022-07-19 22:04:07 - train: epoch 0049, iter [04800, 05004], lr: 0.111682, loss: 1.4263
2022-07-19 22:06:24 - train: epoch 0049, iter [04900, 05004], lr: 0.111617, loss: 1.5914
2022-07-19 22:08:41 - train: epoch 0049, iter [05000, 05004], lr: 0.111551, loss: 1.5107
2022-07-19 22:08:47 - train: epoch 049, train_loss: 1.5416
2022-07-19 22:10:54 - eval: epoch: 049, acc1: 67.402%, acc5: 88.206%, test_loss: 1.3311, per_image_load_time: 0.988ms, per_image_inference_time: 3.905ms
2022-07-19 22:10:55 - until epoch: 049, best_acc1: 67.470%
2022-07-19 22:10:55 - epoch 050 lr: 0.111548
2022-07-19 22:13:19 - train: epoch 0050, iter [00100, 05004], lr: 0.111483, loss: 1.5221
2022-07-19 22:15:36 - train: epoch 0050, iter [00200, 05004], lr: 0.111417, loss: 1.6049
2022-07-19 22:17:53 - train: epoch 0050, iter [00300, 05004], lr: 0.111352, loss: 1.3918
2022-07-19 22:20:10 - train: epoch 0050, iter [00400, 05004], lr: 0.111286, loss: 1.3211
2022-07-19 22:22:27 - train: epoch 0050, iter [00500, 05004], lr: 0.111220, loss: 1.4374
2022-07-19 22:24:44 - train: epoch 0050, iter [00600, 05004], lr: 0.111155, loss: 1.5861
2022-07-19 22:27:00 - train: epoch 0050, iter [00700, 05004], lr: 0.111089, loss: 1.3170
2022-07-19 22:29:17 - train: epoch 0050, iter [00800, 05004], lr: 0.111023, loss: 1.5113
2022-07-19 22:31:34 - train: epoch 0050, iter [00900, 05004], lr: 0.110957, loss: 1.4667
2022-07-19 22:33:51 - train: epoch 0050, iter [01000, 05004], lr: 0.110892, loss: 1.4718
2022-07-19 22:36:07 - train: epoch 0050, iter [01100, 05004], lr: 0.110826, loss: 1.5211
2022-07-19 22:38:24 - train: epoch 0050, iter [01200, 05004], lr: 0.110760, loss: 1.4120
2022-07-19 22:40:41 - train: epoch 0050, iter [01300, 05004], lr: 0.110695, loss: 1.3358
2022-07-19 22:42:58 - train: epoch 0050, iter [01400, 05004], lr: 0.110629, loss: 1.4847
2022-07-19 22:45:14 - train: epoch 0050, iter [01500, 05004], lr: 0.110563, loss: 1.4789
2022-07-19 22:47:31 - train: epoch 0050, iter [01600, 05004], lr: 0.110498, loss: 1.5852
2022-07-19 22:49:48 - train: epoch 0050, iter [01700, 05004], lr: 0.110432, loss: 1.3362
2022-07-19 22:52:05 - train: epoch 0050, iter [01800, 05004], lr: 0.110366, loss: 1.6395
2022-07-19 22:54:22 - train: epoch 0050, iter [01900, 05004], lr: 0.110300, loss: 1.4629
2022-07-19 22:56:39 - train: epoch 0050, iter [02000, 05004], lr: 0.110235, loss: 1.3209
2022-07-19 22:58:56 - train: epoch 0050, iter [02100, 05004], lr: 0.110169, loss: 1.5416
2022-07-19 23:01:13 - train: epoch 0050, iter [02200, 05004], lr: 0.110103, loss: 1.7245
2022-07-19 23:03:30 - train: epoch 0050, iter [02300, 05004], lr: 0.110037, loss: 1.6113
