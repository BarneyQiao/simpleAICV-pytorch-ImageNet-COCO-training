2022-07-16 23:02:14 - train: epoch 0013, iter [01800, 05004], lr: 0.197053, loss: 1.9063
2022-07-16 23:04:31 - train: epoch 0013, iter [01900, 05004], lr: 0.197037, loss: 2.1675
2022-07-16 23:06:48 - train: epoch 0013, iter [02000, 05004], lr: 0.197021, loss: 2.0940
2022-07-16 23:09:05 - train: epoch 0013, iter [02100, 05004], lr: 0.197005, loss: 2.2193
2022-07-16 23:11:22 - train: epoch 0013, iter [02200, 05004], lr: 0.196989, loss: 2.0516
2022-07-16 23:13:39 - train: epoch 0013, iter [02300, 05004], lr: 0.196973, loss: 2.0825
2022-07-16 23:15:56 - train: epoch 0013, iter [02400, 05004], lr: 0.196957, loss: 2.0300
2022-07-16 23:18:13 - train: epoch 0013, iter [02500, 05004], lr: 0.196940, loss: 1.9156
2022-07-16 23:20:30 - train: epoch 0013, iter [02600, 05004], lr: 0.196924, loss: 1.9607
2022-07-16 23:22:46 - train: epoch 0013, iter [02700, 05004], lr: 0.196908, loss: 2.0244
2022-07-16 23:25:03 - train: epoch 0013, iter [02800, 05004], lr: 0.196891, loss: 2.1422
2022-07-16 23:27:20 - train: epoch 0013, iter [02900, 05004], lr: 0.196875, loss: 2.1393
2022-07-16 23:29:37 - train: epoch 0013, iter [03000, 05004], lr: 0.196859, loss: 1.9173
2022-07-16 23:31:54 - train: epoch 0013, iter [03100, 05004], lr: 0.196842, loss: 1.7993
2022-07-16 23:34:11 - train: epoch 0013, iter [03200, 05004], lr: 0.196826, loss: 1.9120
2022-07-16 23:36:28 - train: epoch 0013, iter [03300, 05004], lr: 0.196809, loss: 1.9351
2022-07-16 23:38:44 - train: epoch 0013, iter [03400, 05004], lr: 0.196793, loss: 2.0062
2022-07-16 23:41:01 - train: epoch 0013, iter [03500, 05004], lr: 0.196776, loss: 2.0451
2022-07-16 23:43:18 - train: epoch 0013, iter [03600, 05004], lr: 0.196759, loss: 2.2529
2022-07-16 23:45:35 - train: epoch 0013, iter [03700, 05004], lr: 0.196743, loss: 1.8252
2022-07-16 23:47:52 - train: epoch 0013, iter [03800, 05004], lr: 0.196726, loss: 2.2513
2022-07-16 23:50:08 - train: epoch 0013, iter [03900, 05004], lr: 0.196709, loss: 2.0751
2022-07-16 23:52:25 - train: epoch 0013, iter [04000, 05004], lr: 0.196692, loss: 2.0624
2022-07-16 23:54:42 - train: epoch 0013, iter [04100, 05004], lr: 0.196675, loss: 1.8564
2022-07-16 23:56:59 - train: epoch 0013, iter [04200, 05004], lr: 0.196658, loss: 1.8721
2022-07-16 23:59:16 - train: epoch 0013, iter [04300, 05004], lr: 0.196641, loss: 1.9117
2022-07-17 00:01:32 - train: epoch 0013, iter [04400, 05004], lr: 0.196624, loss: 1.9368
2022-07-17 00:03:49 - train: epoch 0013, iter [04500, 05004], lr: 0.196607, loss: 1.9800
2022-07-17 00:06:06 - train: epoch 0013, iter [04600, 05004], lr: 0.196590, loss: 2.0875
2022-07-17 00:08:23 - train: epoch 0013, iter [04700, 05004], lr: 0.196573, loss: 1.9890
2022-07-17 00:10:40 - train: epoch 0013, iter [04800, 05004], lr: 0.196556, loss: 2.0957
2022-07-17 00:12:57 - train: epoch 0013, iter [04900, 05004], lr: 0.196539, loss: 2.1532
2022-07-17 00:15:14 - train: epoch 0013, iter [05000, 05004], lr: 0.196522, loss: 2.2634
2022-07-17 00:15:20 - train: epoch 013, train_loss: 2.0053
2022-07-17 00:17:35 - eval: epoch: 013, acc1: 59.204%, acc5: 83.120%, test_loss: 1.7233, per_image_load_time: 1.159ms, per_image_inference_time: 3.904ms
2022-07-17 00:17:35 - until epoch: 013, best_acc1: 59.204%
2022-07-17 00:17:35 - epoch 014 lr: 0.196521
2022-07-17 00:20:00 - train: epoch 0014, iter [00100, 05004], lr: 0.196504, loss: 2.0907
2022-07-17 00:22:17 - train: epoch 0014, iter [00200, 05004], lr: 0.196486, loss: 2.2155
2022-07-17 00:24:34 - train: epoch 0014, iter [00300, 05004], lr: 0.196469, loss: 1.8359
2022-07-17 00:26:50 - train: epoch 0014, iter [00400, 05004], lr: 0.196451, loss: 1.8617
2022-07-17 00:29:07 - train: epoch 0014, iter [00500, 05004], lr: 0.196434, loss: 1.8240
2022-07-17 00:31:23 - train: epoch 0014, iter [00600, 05004], lr: 0.196416, loss: 2.1273
2022-07-17 00:33:40 - train: epoch 0014, iter [00700, 05004], lr: 0.196399, loss: 1.7507
2022-07-17 00:35:56 - train: epoch 0014, iter [00800, 05004], lr: 0.196381, loss: 1.7974
2022-07-17 00:38:13 - train: epoch 0014, iter [00900, 05004], lr: 0.196364, loss: 1.9273
2022-07-17 00:40:30 - train: epoch 0014, iter [01000, 05004], lr: 0.196346, loss: 1.9746
2022-07-17 00:42:47 - train: epoch 0014, iter [01100, 05004], lr: 0.196328, loss: 1.8770
2022-07-17 00:45:03 - train: epoch 0014, iter [01200, 05004], lr: 0.196310, loss: 2.0787
2022-07-17 00:47:20 - train: epoch 0014, iter [01300, 05004], lr: 0.196293, loss: 2.1933
2022-07-17 00:49:37 - train: epoch 0014, iter [01400, 05004], lr: 0.196275, loss: 2.1394
2022-07-17 00:51:53 - train: epoch 0014, iter [01500, 05004], lr: 0.196257, loss: 2.0763
2022-07-17 00:54:10 - train: epoch 0014, iter [01600, 05004], lr: 0.196239, loss: 1.8851
2022-07-17 00:56:27 - train: epoch 0014, iter [01700, 05004], lr: 0.196221, loss: 2.0922
2022-07-17 00:58:44 - train: epoch 0014, iter [01800, 05004], lr: 0.196203, loss: 2.1976
2022-07-17 01:01:00 - train: epoch 0014, iter [01900, 05004], lr: 0.196185, loss: 1.8411
2022-07-17 01:03:17 - train: epoch 0014, iter [02000, 05004], lr: 0.196167, loss: 1.8532
2022-07-17 01:05:34 - train: epoch 0014, iter [02100, 05004], lr: 0.196149, loss: 2.0961
2022-07-17 01:07:50 - train: epoch 0014, iter [02200, 05004], lr: 0.196131, loss: 2.0267
2022-07-17 01:10:07 - train: epoch 0014, iter [02300, 05004], lr: 0.196112, loss: 1.8838
2022-07-17 01:12:24 - train: epoch 0014, iter [02400, 05004], lr: 0.196094, loss: 1.9500
2022-07-17 01:14:40 - train: epoch 0014, iter [02500, 05004], lr: 0.196076, loss: 1.8089
2022-07-17 01:16:57 - train: epoch 0014, iter [02600, 05004], lr: 0.196057, loss: 1.9444
2022-07-17 01:19:14 - train: epoch 0014, iter [02700, 05004], lr: 0.196039, loss: 1.9490
2022-07-17 01:21:31 - train: epoch 0014, iter [02800, 05004], lr: 0.196021, loss: 2.1145
2022-07-17 01:23:47 - train: epoch 0014, iter [02900, 05004], lr: 0.196002, loss: 2.0357
2022-07-17 01:26:04 - train: epoch 0014, iter [03000, 05004], lr: 0.195984, loss: 2.1219
2022-07-17 01:28:21 - train: epoch 0014, iter [03100, 05004], lr: 0.195965, loss: 1.8764
2022-07-17 01:30:37 - train: epoch 0014, iter [03200, 05004], lr: 0.195946, loss: 1.9992
2022-07-17 01:32:54 - train: epoch 0014, iter [03300, 05004], lr: 0.195928, loss: 1.9146
2022-07-17 01:35:11 - train: epoch 0014, iter [03400, 05004], lr: 0.195909, loss: 2.1620
2022-07-17 01:37:27 - train: epoch 0014, iter [03500, 05004], lr: 0.195890, loss: 2.0009
2022-07-17 01:39:44 - train: epoch 0014, iter [03600, 05004], lr: 0.195872, loss: 1.8187
2022-07-17 01:42:01 - train: epoch 0014, iter [03700, 05004], lr: 0.195853, loss: 1.9033
2022-07-17 01:44:18 - train: epoch 0014, iter [03800, 05004], lr: 0.195834, loss: 2.0253
2022-07-17 01:46:34 - train: epoch 0014, iter [03900, 05004], lr: 0.195815, loss: 2.0655
2022-07-17 01:48:51 - train: epoch 0014, iter [04000, 05004], lr: 0.195796, loss: 2.0524
2022-07-17 01:51:08 - train: epoch 0014, iter [04100, 05004], lr: 0.195777, loss: 1.8703
2022-07-17 01:53:24 - train: epoch 0014, iter [04200, 05004], lr: 0.195758, loss: 1.8553
2022-07-17 01:55:41 - train: epoch 0014, iter [04300, 05004], lr: 0.195739, loss: 1.8364
2022-07-17 01:57:58 - train: epoch 0014, iter [04400, 05004], lr: 0.195720, loss: 1.9336
2022-07-17 02:00:15 - train: epoch 0014, iter [04500, 05004], lr: 0.195701, loss: 2.0519
2022-07-17 02:02:31 - train: epoch 0014, iter [04600, 05004], lr: 0.195682, loss: 1.8218
2022-07-17 02:04:48 - train: epoch 0014, iter [04700, 05004], lr: 0.195662, loss: 1.9264
2022-07-17 02:07:05 - train: epoch 0014, iter [04800, 05004], lr: 0.195643, loss: 1.8638
2022-07-17 02:09:22 - train: epoch 0014, iter [04900, 05004], lr: 0.195624, loss: 2.0386
2022-07-17 02:11:38 - train: epoch 0014, iter [05000, 05004], lr: 0.195604, loss: 1.9756
2022-07-17 02:11:45 - train: epoch 014, train_loss: 1.9826
2022-07-17 02:14:00 - eval: epoch: 014, acc1: 59.570%, acc5: 83.390%, test_loss: 1.6991, per_image_load_time: 1.193ms, per_image_inference_time: 3.930ms
2022-07-17 02:14:00 - until epoch: 014, best_acc1: 59.570%
2022-07-17 02:14:00 - epoch 015 lr: 0.195603
2022-07-17 02:16:26 - train: epoch 0015, iter [00100, 05004], lr: 0.195584, loss: 1.6528
2022-07-17 02:18:42 - train: epoch 0015, iter [00200, 05004], lr: 0.195565, loss: 2.0279
2022-07-17 02:20:59 - train: epoch 0015, iter [00300, 05004], lr: 0.195545, loss: 2.0014
2022-07-17 02:23:16 - train: epoch 0015, iter [00400, 05004], lr: 0.195526, loss: 2.0228
2022-07-17 02:25:32 - train: epoch 0015, iter [00500, 05004], lr: 0.195506, loss: 1.9597
2022-07-17 02:27:49 - train: epoch 0015, iter [00600, 05004], lr: 0.195487, loss: 2.0818
2022-07-17 02:30:06 - train: epoch 0015, iter [00700, 05004], lr: 0.195467, loss: 1.8839
2022-07-17 02:32:22 - train: epoch 0015, iter [00800, 05004], lr: 0.195447, loss: 1.8132
2022-07-17 02:34:39 - train: epoch 0015, iter [00900, 05004], lr: 0.195427, loss: 2.0434
2022-07-17 02:36:55 - train: epoch 0015, iter [01000, 05004], lr: 0.195408, loss: 1.8431
2022-07-17 02:39:12 - train: epoch 0015, iter [01100, 05004], lr: 0.195388, loss: 1.8032
2022-07-17 02:41:29 - train: epoch 0015, iter [01200, 05004], lr: 0.195368, loss: 1.9388
2022-07-17 02:43:45 - train: epoch 0015, iter [01300, 05004], lr: 0.195348, loss: 2.1303
2022-07-17 02:46:02 - train: epoch 0015, iter [01400, 05004], lr: 0.195328, loss: 2.0227
2022-07-17 02:48:18 - train: epoch 0015, iter [01500, 05004], lr: 0.195308, loss: 1.9244
2022-07-17 02:50:35 - train: epoch 0015, iter [01600, 05004], lr: 0.195288, loss: 2.0878
2022-07-17 02:52:52 - train: epoch 0015, iter [01700, 05004], lr: 0.195268, loss: 2.0842
2022-07-17 02:55:09 - train: epoch 0015, iter [01800, 05004], lr: 0.195248, loss: 2.0383
2022-07-17 02:57:25 - train: epoch 0015, iter [01900, 05004], lr: 0.195228, loss: 1.9541
2022-07-17 02:59:42 - train: epoch 0015, iter [02000, 05004], lr: 0.195208, loss: 1.8956
2022-07-17 03:01:58 - train: epoch 0015, iter [02100, 05004], lr: 0.195187, loss: 1.8854
2022-07-17 03:04:15 - train: epoch 0015, iter [02200, 05004], lr: 0.195167, loss: 2.0857
2022-07-17 03:06:32 - train: epoch 0015, iter [02300, 05004], lr: 0.195147, loss: 1.7831
2022-07-17 03:08:48 - train: epoch 0015, iter [02400, 05004], lr: 0.195126, loss: 2.0186
2022-07-17 03:11:05 - train: epoch 0015, iter [02500, 05004], lr: 0.195106, loss: 2.1210
2022-07-17 03:13:22 - train: epoch 0015, iter [02600, 05004], lr: 0.195086, loss: 1.8530
2022-07-17 03:15:38 - train: epoch 0015, iter [02700, 05004], lr: 0.195065, loss: 1.9413
2022-07-17 03:17:55 - train: epoch 0015, iter [02800, 05004], lr: 0.195045, loss: 2.0372
2022-07-17 03:20:11 - train: epoch 0015, iter [02900, 05004], lr: 0.195024, loss: 2.0346
2022-07-17 03:22:28 - train: epoch 0015, iter [03000, 05004], lr: 0.195003, loss: 1.9939
2022-07-17 03:24:44 - train: epoch 0015, iter [03100, 05004], lr: 0.194983, loss: 2.0045
2022-07-17 03:27:01 - train: epoch 0015, iter [03200, 05004], lr: 0.194962, loss: 1.8776
2022-07-17 03:29:18 - train: epoch 0015, iter [03300, 05004], lr: 0.194941, loss: 1.8158
2022-07-17 03:31:34 - train: epoch 0015, iter [03400, 05004], lr: 0.194921, loss: 2.0536
2022-07-17 03:33:51 - train: epoch 0015, iter [03500, 05004], lr: 0.194900, loss: 2.1953
2022-07-17 03:36:08 - train: epoch 0015, iter [03600, 05004], lr: 0.194879, loss: 2.0791
2022-07-17 03:38:24 - train: epoch 0015, iter [03700, 05004], lr: 0.194858, loss: 1.8452
2022-07-17 03:40:41 - train: epoch 0015, iter [03800, 05004], lr: 0.194837, loss: 1.9512
2022-07-17 03:42:57 - train: epoch 0015, iter [03900, 05004], lr: 0.194816, loss: 2.1454
2022-07-17 03:45:14 - train: epoch 0015, iter [04000, 05004], lr: 0.194795, loss: 2.0611
2022-07-17 03:47:30 - train: epoch 0015, iter [04100, 05004], lr: 0.194774, loss: 1.7587
2022-07-17 03:49:47 - train: epoch 0015, iter [04200, 05004], lr: 0.194753, loss: 1.8125
2022-07-17 03:52:04 - train: epoch 0015, iter [04300, 05004], lr: 0.194732, loss: 1.8040
2022-07-17 03:54:20 - train: epoch 0015, iter [04400, 05004], lr: 0.194711, loss: 1.9632
2022-07-17 03:56:37 - train: epoch 0015, iter [04500, 05004], lr: 0.194689, loss: 1.8181
2022-07-17 03:58:53 - train: epoch 0015, iter [04600, 05004], lr: 0.194668, loss: 1.9958
2022-07-17 04:01:10 - train: epoch 0015, iter [04700, 05004], lr: 0.194647, loss: 2.0830
2022-07-17 04:03:27 - train: epoch 0015, iter [04800, 05004], lr: 0.194625, loss: 1.8738
2022-07-17 04:05:43 - train: epoch 0015, iter [04900, 05004], lr: 0.194604, loss: 1.9354
2022-07-17 04:08:00 - train: epoch 0015, iter [05000, 05004], lr: 0.194583, loss: 2.1395
2022-07-17 04:08:06 - train: epoch 015, train_loss: 1.9674
2022-07-17 04:10:21 - eval: epoch: 015, acc1: 59.964%, acc5: 83.528%, test_loss: 1.6868, per_image_load_time: 1.130ms, per_image_inference_time: 3.939ms
2022-07-17 04:10:21 - until epoch: 015, best_acc1: 59.964%
2022-07-17 04:10:21 - epoch 016 lr: 0.194582
2022-07-17 04:12:47 - train: epoch 0016, iter [00100, 05004], lr: 0.194560, loss: 1.8588
2022-07-17 04:15:04 - train: epoch 0016, iter [00200, 05004], lr: 0.194539, loss: 1.9433
2022-07-17 04:17:21 - train: epoch 0016, iter [00300, 05004], lr: 0.194517, loss: 1.9084
2022-07-17 04:19:37 - train: epoch 0016, iter [00400, 05004], lr: 0.194496, loss: 2.1451
2022-07-17 04:21:54 - train: epoch 0016, iter [00500, 05004], lr: 0.194474, loss: 1.7692
2022-07-17 04:24:11 - train: epoch 0016, iter [00600, 05004], lr: 0.194452, loss: 2.0215
2022-07-17 04:26:28 - train: epoch 0016, iter [00700, 05004], lr: 0.194431, loss: 1.8477
2022-07-17 04:28:44 - train: epoch 0016, iter [00800, 05004], lr: 0.194409, loss: 2.0185
2022-07-17 04:31:01 - train: epoch 0016, iter [00900, 05004], lr: 0.194387, loss: 2.0216
2022-07-17 04:33:18 - train: epoch 0016, iter [01000, 05004], lr: 0.194365, loss: 1.9562
2022-07-17 04:35:35 - train: epoch 0016, iter [01100, 05004], lr: 0.194343, loss: 2.0793
2022-07-17 04:37:52 - train: epoch 0016, iter [01200, 05004], lr: 0.194321, loss: 1.9487
2022-07-17 04:40:09 - train: epoch 0016, iter [01300, 05004], lr: 0.194299, loss: 1.9265
2022-07-17 04:42:26 - train: epoch 0016, iter [01400, 05004], lr: 0.194277, loss: 1.8910
2022-07-17 04:44:43 - train: epoch 0016, iter [01500, 05004], lr: 0.194255, loss: 2.1446
2022-07-17 04:47:00 - train: epoch 0016, iter [01600, 05004], lr: 0.194233, loss: 1.8832
2022-07-17 04:49:17 - train: epoch 0016, iter [01700, 05004], lr: 0.194211, loss: 1.9925
2022-07-17 04:51:34 - train: epoch 0016, iter [01800, 05004], lr: 0.194189, loss: 1.9689
2022-07-17 04:53:50 - train: epoch 0016, iter [01900, 05004], lr: 0.194167, loss: 1.9267
2022-07-17 04:56:07 - train: epoch 0016, iter [02000, 05004], lr: 0.194144, loss: 1.5373
2022-07-17 04:58:24 - train: epoch 0016, iter [02100, 05004], lr: 0.194122, loss: 1.8378
2022-07-17 05:00:41 - train: epoch 0016, iter [02200, 05004], lr: 0.194100, loss: 1.8553
2022-07-17 05:02:58 - train: epoch 0016, iter [02300, 05004], lr: 0.194077, loss: 2.1440
2022-07-17 05:05:14 - train: epoch 0016, iter [02400, 05004], lr: 0.194055, loss: 2.0686
2022-07-17 05:07:31 - train: epoch 0016, iter [02500, 05004], lr: 0.194032, loss: 1.8595
2022-07-17 05:09:48 - train: epoch 0016, iter [02600, 05004], lr: 0.194010, loss: 2.1706
2022-07-17 05:12:05 - train: epoch 0016, iter [02700, 05004], lr: 0.193987, loss: 1.9811
2022-07-17 05:14:22 - train: epoch 0016, iter [02800, 05004], lr: 0.193965, loss: 1.9572
2022-07-17 05:16:38 - train: epoch 0016, iter [02900, 05004], lr: 0.193942, loss: 1.9836
2022-07-17 05:18:55 - train: epoch 0016, iter [03000, 05004], lr: 0.193919, loss: 2.1450
2022-07-17 05:21:12 - train: epoch 0016, iter [03100, 05004], lr: 0.193897, loss: 2.1224
2022-07-17 05:23:29 - train: epoch 0016, iter [03200, 05004], lr: 0.193874, loss: 2.0560
2022-07-17 05:25:46 - train: epoch 0016, iter [03300, 05004], lr: 0.193851, loss: 2.0065
2022-07-17 05:28:03 - train: epoch 0016, iter [03400, 05004], lr: 0.193828, loss: 1.7214
2022-07-17 05:30:19 - train: epoch 0016, iter [03500, 05004], lr: 0.193805, loss: 2.1047
2022-07-17 05:32:36 - train: epoch 0016, iter [03600, 05004], lr: 0.193783, loss: 1.7529
2022-07-17 05:34:53 - train: epoch 0016, iter [03700, 05004], lr: 0.193760, loss: 1.9538
2022-07-17 05:37:10 - train: epoch 0016, iter [03800, 05004], lr: 0.193737, loss: 2.1185
2022-07-17 05:39:27 - train: epoch 0016, iter [03900, 05004], lr: 0.193714, loss: 1.9564
2022-07-17 05:41:44 - train: epoch 0016, iter [04000, 05004], lr: 0.193690, loss: 2.0312
2022-07-17 05:44:01 - train: epoch 0016, iter [04100, 05004], lr: 0.193667, loss: 1.8358
2022-07-17 05:46:18 - train: epoch 0016, iter [04200, 05004], lr: 0.193644, loss: 1.7550
2022-07-17 05:48:35 - train: epoch 0016, iter [04300, 05004], lr: 0.193621, loss: 1.8407
2022-07-17 05:50:51 - train: epoch 0016, iter [04400, 05004], lr: 0.193598, loss: 1.8569
2022-07-17 05:53:08 - train: epoch 0016, iter [04500, 05004], lr: 0.193574, loss: 1.9085
2022-07-17 05:55:25 - train: epoch 0016, iter [04600, 05004], lr: 0.193551, loss: 1.9305
2022-07-17 05:57:42 - train: epoch 0016, iter [04700, 05004], lr: 0.193528, loss: 2.0271
2022-07-17 05:59:59 - train: epoch 0016, iter [04800, 05004], lr: 0.193504, loss: 1.9743
2022-07-17 06:02:16 - train: epoch 0016, iter [04900, 05004], lr: 0.193481, loss: 2.0977
2022-07-17 06:04:33 - train: epoch 0016, iter [05000, 05004], lr: 0.193457, loss: 1.9991
2022-07-17 06:04:39 - train: epoch 016, train_loss: 1.9500
2022-07-17 06:06:53 - eval: epoch: 016, acc1: 59.964%, acc5: 83.680%, test_loss: 1.6719, per_image_load_time: 1.153ms, per_image_inference_time: 3.919ms
2022-07-17 06:06:53 - until epoch: 016, best_acc1: 59.964%
2022-07-17 06:06:53 - epoch 017 lr: 0.193456
2022-07-17 06:09:19 - train: epoch 0017, iter [00100, 05004], lr: 0.193433, loss: 1.9401
2022-07-17 06:11:35 - train: epoch 0017, iter [00200, 05004], lr: 0.193409, loss: 1.9932
2022-07-17 06:13:52 - train: epoch 0017, iter [00300, 05004], lr: 0.193386, loss: 2.0179
2022-07-17 06:16:09 - train: epoch 0017, iter [00400, 05004], lr: 0.193362, loss: 1.5997
2022-07-17 06:18:25 - train: epoch 0017, iter [00500, 05004], lr: 0.193338, loss: 2.0002
2022-07-17 06:20:42 - train: epoch 0017, iter [00600, 05004], lr: 0.193315, loss: 2.1436
2022-07-17 06:22:59 - train: epoch 0017, iter [00700, 05004], lr: 0.193291, loss: 1.8180
2022-07-17 06:25:15 - train: epoch 0017, iter [00800, 05004], lr: 0.193267, loss: 1.9281
2022-07-17 06:27:32 - train: epoch 0017, iter [00900, 05004], lr: 0.193243, loss: 1.8551
2022-07-17 06:29:48 - train: epoch 0017, iter [01000, 05004], lr: 0.193219, loss: 1.9754
2022-07-17 06:32:05 - train: epoch 0017, iter [01100, 05004], lr: 0.193195, loss: 2.1900
2022-07-17 06:34:21 - train: epoch 0017, iter [01200, 05004], lr: 0.193171, loss: 1.6455
2022-07-17 06:36:38 - train: epoch 0017, iter [01300, 05004], lr: 0.193147, loss: 2.1458
2022-07-17 06:38:55 - train: epoch 0017, iter [01400, 05004], lr: 0.193123, loss: 1.9569
2022-07-17 06:41:11 - train: epoch 0017, iter [01500, 05004], lr: 0.193099, loss: 1.6980
2022-07-17 06:43:28 - train: epoch 0017, iter [01600, 05004], lr: 0.193075, loss: 1.7489
2022-07-17 06:45:44 - train: epoch 0017, iter [01700, 05004], lr: 0.193051, loss: 1.8805
2022-07-17 06:48:01 - train: epoch 0017, iter [01800, 05004], lr: 0.193027, loss: 1.9067
2022-07-17 06:50:17 - train: epoch 0017, iter [01900, 05004], lr: 0.193002, loss: 2.0630
2022-07-17 06:52:34 - train: epoch 0017, iter [02000, 05004], lr: 0.192978, loss: 1.9585
2022-07-17 06:54:50 - train: epoch 0017, iter [02100, 05004], lr: 0.192954, loss: 1.9195
2022-07-17 06:57:07 - train: epoch 0017, iter [02200, 05004], lr: 0.192929, loss: 1.9028
2022-07-17 06:59:23 - train: epoch 0017, iter [02300, 05004], lr: 0.192905, loss: 1.8876
2022-07-17 07:01:40 - train: epoch 0017, iter [02400, 05004], lr: 0.192880, loss: 1.8641
2022-07-17 07:03:57 - train: epoch 0017, iter [02500, 05004], lr: 0.192856, loss: 1.9654
2022-07-17 07:06:13 - train: epoch 0017, iter [02600, 05004], lr: 0.192831, loss: 1.9209
2022-07-17 07:08:30 - train: epoch 0017, iter [02700, 05004], lr: 0.192807, loss: 2.1051
2022-07-17 07:10:46 - train: epoch 0017, iter [02800, 05004], lr: 0.192782, loss: 1.8136
2022-07-17 07:13:03 - train: epoch 0017, iter [02900, 05004], lr: 0.192757, loss: 2.3526
2022-07-17 07:15:20 - train: epoch 0017, iter [03000, 05004], lr: 0.192733, loss: 1.7398
2022-07-17 07:17:36 - train: epoch 0017, iter [03100, 05004], lr: 0.192708, loss: 2.1903
2022-07-17 07:19:53 - train: epoch 0017, iter [03200, 05004], lr: 0.192683, loss: 1.9185
2022-07-17 07:22:09 - train: epoch 0017, iter [03300, 05004], lr: 0.192658, loss: 2.0177
2022-07-17 07:24:26 - train: epoch 0017, iter [03400, 05004], lr: 0.192633, loss: 1.7080
2022-07-17 07:26:42 - train: epoch 0017, iter [03500, 05004], lr: 0.192609, loss: 2.0407
2022-07-17 07:28:59 - train: epoch 0017, iter [03600, 05004], lr: 0.192584, loss: 1.9766
2022-07-17 07:31:15 - train: epoch 0017, iter [03700, 05004], lr: 0.192559, loss: 1.8492
2022-07-17 07:33:32 - train: epoch 0017, iter [03800, 05004], lr: 0.192534, loss: 2.0352
2022-07-17 07:35:49 - train: epoch 0017, iter [03900, 05004], lr: 0.192509, loss: 1.8737
2022-07-17 07:38:05 - train: epoch 0017, iter [04000, 05004], lr: 0.192483, loss: 1.9134
2022-07-17 07:40:22 - train: epoch 0017, iter [04100, 05004], lr: 0.192458, loss: 1.7789
2022-07-17 07:42:38 - train: epoch 0017, iter [04200, 05004], lr: 0.192433, loss: 1.9197
2022-07-17 07:44:55 - train: epoch 0017, iter [04300, 05004], lr: 0.192408, loss: 2.0354
2022-07-17 07:47:11 - train: epoch 0017, iter [04400, 05004], lr: 0.192383, loss: 2.1488
2022-07-17 07:49:28 - train: epoch 0017, iter [04500, 05004], lr: 0.192357, loss: 1.9822
2022-07-17 07:51:45 - train: epoch 0017, iter [04600, 05004], lr: 0.192332, loss: 1.8790
2022-07-17 07:54:01 - train: epoch 0017, iter [04700, 05004], lr: 0.192306, loss: 1.9197
2022-07-17 07:56:18 - train: epoch 0017, iter [04800, 05004], lr: 0.192281, loss: 2.0410
2022-07-17 07:58:35 - train: epoch 0017, iter [04900, 05004], lr: 0.192256, loss: 2.1964
2022-07-17 08:00:51 - train: epoch 0017, iter [05000, 05004], lr: 0.192230, loss: 1.6214
2022-07-17 08:00:58 - train: epoch 017, train_loss: 1.9296
2022-07-17 08:03:11 - eval: epoch: 017, acc1: 60.398%, acc5: 84.050%, test_loss: 1.6519, per_image_load_time: 1.202ms, per_image_inference_time: 3.913ms
2022-07-17 08:03:12 - until epoch: 017, best_acc1: 60.398%
2022-07-17 08:03:12 - epoch 018 lr: 0.192229
2022-07-17 08:05:38 - train: epoch 0018, iter [00100, 05004], lr: 0.192203, loss: 1.8429
2022-07-17 08:07:54 - train: epoch 0018, iter [00200, 05004], lr: 0.192178, loss: 1.9550
2022-07-17 08:10:11 - train: epoch 0018, iter [00300, 05004], lr: 0.192152, loss: 1.9435
2022-07-17 08:12:28 - train: epoch 0018, iter [00400, 05004], lr: 0.192126, loss: 2.0840
2022-07-17 08:14:45 - train: epoch 0018, iter [00500, 05004], lr: 0.192101, loss: 1.9672
2022-07-17 08:17:01 - train: epoch 0018, iter [00600, 05004], lr: 0.192075, loss: 2.0191
2022-07-17 08:19:18 - train: epoch 0018, iter [00700, 05004], lr: 0.192049, loss: 1.7001
2022-07-17 08:21:34 - train: epoch 0018, iter [00800, 05004], lr: 0.192023, loss: 1.9982
2022-07-17 08:23:51 - train: epoch 0018, iter [00900, 05004], lr: 0.191997, loss: 2.0525
2022-07-17 08:26:08 - train: epoch 0018, iter [01000, 05004], lr: 0.191972, loss: 1.8892
2022-07-17 08:28:24 - train: epoch 0018, iter [01100, 05004], lr: 0.191946, loss: 1.8813
2022-07-17 08:30:41 - train: epoch 0018, iter [01200, 05004], lr: 0.191920, loss: 2.0450
2022-07-17 08:32:58 - train: epoch 0018, iter [01300, 05004], lr: 0.191894, loss: 2.1058
2022-07-17 08:35:14 - train: epoch 0018, iter [01400, 05004], lr: 0.191867, loss: 1.9268
2022-07-17 08:37:31 - train: epoch 0018, iter [01500, 05004], lr: 0.191841, loss: 1.8885
2022-07-17 08:39:48 - train: epoch 0018, iter [01600, 05004], lr: 0.191815, loss: 1.9104
2022-07-17 08:42:04 - train: epoch 0018, iter [01700, 05004], lr: 0.191789, loss: 1.8929
2022-07-17 08:44:21 - train: epoch 0018, iter [01800, 05004], lr: 0.191763, loss: 1.8190
2022-07-17 08:46:37 - train: epoch 0018, iter [01900, 05004], lr: 0.191736, loss: 1.8537
2022-07-17 08:48:54 - train: epoch 0018, iter [02000, 05004], lr: 0.191710, loss: 2.1977
2022-07-17 08:51:11 - train: epoch 0018, iter [02100, 05004], lr: 0.191684, loss: 2.1680
2022-07-17 08:53:28 - train: epoch 0018, iter [02200, 05004], lr: 0.191657, loss: 2.1186
2022-07-17 08:55:44 - train: epoch 0018, iter [02300, 05004], lr: 0.191631, loss: 1.9902
2022-07-17 08:58:01 - train: epoch 0018, iter [02400, 05004], lr: 0.191604, loss: 1.7729
2022-07-17 09:00:18 - train: epoch 0018, iter [02500, 05004], lr: 0.191578, loss: 1.6497
2022-07-17 09:02:34 - train: epoch 0018, iter [02600, 05004], lr: 0.191551, loss: 1.8465
2022-07-17 09:04:51 - train: epoch 0018, iter [02700, 05004], lr: 0.191525, loss: 2.0473
2022-07-17 09:07:08 - train: epoch 0018, iter [02800, 05004], lr: 0.191498, loss: 1.7687
2022-07-17 09:09:24 - train: epoch 0018, iter [02900, 05004], lr: 0.191471, loss: 1.7752
2022-07-17 09:11:41 - train: epoch 0018, iter [03000, 05004], lr: 0.191445, loss: 1.7533
2022-07-17 09:13:58 - train: epoch 0018, iter [03100, 05004], lr: 0.191418, loss: 2.2420
2022-07-17 09:16:14 - train: epoch 0018, iter [03200, 05004], lr: 0.191391, loss: 2.0400
2022-07-17 09:18:31 - train: epoch 0018, iter [03300, 05004], lr: 0.191364, loss: 1.7893
2022-07-17 09:20:48 - train: epoch 0018, iter [03400, 05004], lr: 0.191337, loss: 1.9184
2022-07-17 09:23:04 - train: epoch 0018, iter [03500, 05004], lr: 0.191310, loss: 2.0336
2022-07-17 09:25:21 - train: epoch 0018, iter [03600, 05004], lr: 0.191283, loss: 1.9857
2022-07-17 09:27:38 - train: epoch 0018, iter [03700, 05004], lr: 0.191256, loss: 2.2514
2022-07-17 09:29:54 - train: epoch 0018, iter [03800, 05004], lr: 0.191229, loss: 2.0278
2022-07-17 09:32:11 - train: epoch 0018, iter [03900, 05004], lr: 0.191202, loss: 2.1555
2022-07-17 09:34:28 - train: epoch 0018, iter [04000, 05004], lr: 0.191175, loss: 2.0035
2022-07-17 09:36:44 - train: epoch 0018, iter [04100, 05004], lr: 0.191148, loss: 2.0351
2022-07-17 09:39:01 - train: epoch 0018, iter [04200, 05004], lr: 0.191121, loss: 1.8726
2022-07-17 09:41:18 - train: epoch 0018, iter [04300, 05004], lr: 0.191094, loss: 1.6954
2022-07-17 09:43:35 - train: epoch 0018, iter [04400, 05004], lr: 0.191066, loss: 1.7485
2022-07-17 09:45:52 - train: epoch 0018, iter [04500, 05004], lr: 0.191039, loss: 1.9225
2022-07-17 09:48:08 - train: epoch 0018, iter [04600, 05004], lr: 0.191012, loss: 1.8705
2022-07-17 09:50:25 - train: epoch 0018, iter [04700, 05004], lr: 0.190984, loss: 2.1768
2022-07-17 09:52:42 - train: epoch 0018, iter [04800, 05004], lr: 0.190957, loss: 2.0927
2022-07-17 09:54:59 - train: epoch 0018, iter [04900, 05004], lr: 0.190929, loss: 2.0374
2022-07-17 09:57:15 - train: epoch 0018, iter [05000, 05004], lr: 0.190902, loss: 1.9453
2022-07-17 09:57:22 - train: epoch 018, train_loss: 1.9138
2022-07-17 09:59:35 - eval: epoch: 018, acc1: 60.296%, acc5: 83.996%, test_loss: 1.6547, per_image_load_time: 1.232ms, per_image_inference_time: 3.931ms
2022-07-17 09:59:35 - until epoch: 018, best_acc1: 60.398%
2022-07-17 09:59:35 - epoch 019 lr: 0.190900
2022-07-17 10:02:00 - train: epoch 0019, iter [00100, 05004], lr: 0.190873, loss: 1.6773
2022-07-17 10:04:16 - train: epoch 0019, iter [00200, 05004], lr: 0.190845, loss: 1.7496
2022-07-17 10:06:33 - train: epoch 0019, iter [00300, 05004], lr: 0.190818, loss: 1.9521
2022-07-17 10:08:50 - train: epoch 0019, iter [00400, 05004], lr: 0.190790, loss: 1.8443
2022-07-17 10:11:06 - train: epoch 0019, iter [00500, 05004], lr: 0.190762, loss: 1.7463
2022-07-17 10:13:23 - train: epoch 0019, iter [00600, 05004], lr: 0.190735, loss: 1.8015
2022-07-17 10:15:39 - train: epoch 0019, iter [00700, 05004], lr: 0.190707, loss: 1.5998
2022-07-17 10:17:56 - train: epoch 0019, iter [00800, 05004], lr: 0.190679, loss: 2.0553
2022-07-17 10:20:13 - train: epoch 0019, iter [00900, 05004], lr: 0.190651, loss: 1.8164
2022-07-17 10:22:29 - train: epoch 0019, iter [01000, 05004], lr: 0.190623, loss: 1.8063
2022-07-17 10:24:46 - train: epoch 0019, iter [01100, 05004], lr: 0.190595, loss: 1.9462
2022-07-17 10:27:03 - train: epoch 0019, iter [01200, 05004], lr: 0.190567, loss: 1.8026
2022-07-17 10:29:19 - train: epoch 0019, iter [01300, 05004], lr: 0.190539, loss: 2.0471
2022-07-17 10:31:36 - train: epoch 0019, iter [01400, 05004], lr: 0.190511, loss: 1.6161
2022-07-17 10:33:53 - train: epoch 0019, iter [01500, 05004], lr: 0.190483, loss: 1.8726
2022-07-17 10:36:09 - train: epoch 0019, iter [01600, 05004], lr: 0.190455, loss: 1.8498
2022-07-17 10:38:26 - train: epoch 0019, iter [01700, 05004], lr: 0.190427, loss: 1.9873
2022-07-17 10:40:42 - train: epoch 0019, iter [01800, 05004], lr: 0.190398, loss: 1.8752
2022-07-17 10:42:59 - train: epoch 0019, iter [01900, 05004], lr: 0.190370, loss: 2.1841
2022-07-17 10:45:16 - train: epoch 0019, iter [02000, 05004], lr: 0.190342, loss: 2.0646
2022-07-17 10:47:32 - train: epoch 0019, iter [02100, 05004], lr: 0.190314, loss: 1.6160
2022-07-17 10:49:49 - train: epoch 0019, iter [02200, 05004], lr: 0.190285, loss: 1.8718
2022-07-17 10:52:06 - train: epoch 0019, iter [02300, 05004], lr: 0.190257, loss: 1.9542
2022-07-17 10:54:22 - train: epoch 0019, iter [02400, 05004], lr: 0.190228, loss: 2.1250
2022-07-17 10:56:39 - train: epoch 0019, iter [02500, 05004], lr: 0.190200, loss: 1.9664
2022-07-17 10:58:56 - train: epoch 0019, iter [02600, 05004], lr: 0.190171, loss: 1.9169
2022-07-17 11:01:12 - train: epoch 0019, iter [02700, 05004], lr: 0.190143, loss: 1.8760
2022-07-17 11:03:29 - train: epoch 0019, iter [02800, 05004], lr: 0.190114, loss: 1.8770
2022-07-17 11:05:46 - train: epoch 0019, iter [02900, 05004], lr: 0.190085, loss: 1.9809
2022-07-17 11:08:02 - train: epoch 0019, iter [03000, 05004], lr: 0.190057, loss: 2.0827
2022-07-17 11:10:19 - train: epoch 0019, iter [03100, 05004], lr: 0.190028, loss: 1.8533
2022-07-17 11:12:36 - train: epoch 0019, iter [03200, 05004], lr: 0.189999, loss: 1.5930
2022-07-17 11:14:52 - train: epoch 0019, iter [03300, 05004], lr: 0.189970, loss: 1.8897
2022-07-17 11:17:09 - train: epoch 0019, iter [03400, 05004], lr: 0.189941, loss: 1.7123
2022-07-17 11:19:26 - train: epoch 0019, iter [03500, 05004], lr: 0.189912, loss: 2.0875
2022-07-17 11:21:43 - train: epoch 0019, iter [03600, 05004], lr: 0.189883, loss: 1.5588
2022-07-17 11:23:59 - train: epoch 0019, iter [03700, 05004], lr: 0.189854, loss: 2.0578
2022-07-17 11:26:16 - train: epoch 0019, iter [03800, 05004], lr: 0.189825, loss: 2.1885
2022-07-17 11:28:33 - train: epoch 0019, iter [03900, 05004], lr: 0.189796, loss: 1.8335
2022-07-17 11:30:50 - train: epoch 0019, iter [04000, 05004], lr: 0.189767, loss: 1.9081
2022-07-17 11:33:06 - train: epoch 0019, iter [04100, 05004], lr: 0.189738, loss: 2.1034
2022-07-17 11:35:23 - train: epoch 0019, iter [04200, 05004], lr: 0.189709, loss: 1.8535
2022-07-17 11:37:40 - train: epoch 0019, iter [04300, 05004], lr: 0.189680, loss: 1.9315
2022-07-17 11:39:57 - train: epoch 0019, iter [04400, 05004], lr: 0.189650, loss: 1.9672
2022-07-17 11:42:13 - train: epoch 0019, iter [04500, 05004], lr: 0.189621, loss: 2.0485
2022-07-17 11:44:30 - train: epoch 0019, iter [04600, 05004], lr: 0.189592, loss: 1.9908
2022-07-17 11:46:47 - train: epoch 0019, iter [04700, 05004], lr: 0.189562, loss: 1.8996
2022-07-17 11:49:04 - train: epoch 0019, iter [04800, 05004], lr: 0.189533, loss: 1.7859
2022-07-17 11:51:20 - train: epoch 0019, iter [04900, 05004], lr: 0.189504, loss: 1.8066
2022-07-17 11:53:37 - train: epoch 0019, iter [05000, 05004], lr: 0.189474, loss: 2.0613
2022-07-17 11:53:44 - train: epoch 019, train_loss: 1.9009
2022-07-17 11:55:57 - eval: epoch: 019, acc1: 59.810%, acc5: 83.478%, test_loss: 1.6868, per_image_load_time: 1.130ms, per_image_inference_time: 3.927ms
2022-07-17 11:55:58 - until epoch: 019, best_acc1: 60.398%
2022-07-17 11:55:58 - epoch 020 lr: 0.189473
2022-07-17 11:58:22 - train: epoch 0020, iter [00100, 05004], lr: 0.189443, loss: 1.8737
2022-07-17 12:00:39 - train: epoch 0020, iter [00200, 05004], lr: 0.189414, loss: 1.7350
2022-07-17 12:02:56 - train: epoch 0020, iter [00300, 05004], lr: 0.189384, loss: 2.0242
2022-07-17 12:05:12 - train: epoch 0020, iter [00400, 05004], lr: 0.189355, loss: 1.7368
2022-07-17 12:07:29 - train: epoch 0020, iter [00500, 05004], lr: 0.189325, loss: 1.7351
2022-07-17 12:09:46 - train: epoch 0020, iter [00600, 05004], lr: 0.189295, loss: 1.8233
2022-07-17 12:12:02 - train: epoch 0020, iter [00700, 05004], lr: 0.189265, loss: 1.5551
2022-07-17 12:14:19 - train: epoch 0020, iter [00800, 05004], lr: 0.189236, loss: 1.9692
2022-07-17 12:16:36 - train: epoch 0020, iter [00900, 05004], lr: 0.189206, loss: 2.0053
2022-07-17 12:18:53 - train: epoch 0020, iter [01000, 05004], lr: 0.189176, loss: 1.8182
2022-07-17 12:21:09 - train: epoch 0020, iter [01100, 05004], lr: 0.189146, loss: 1.6707
2022-07-17 12:23:26 - train: epoch 0020, iter [01200, 05004], lr: 0.189116, loss: 1.8488
2022-07-17 12:25:43 - train: epoch 0020, iter [01300, 05004], lr: 0.189086, loss: 1.9712
2022-07-17 12:28:00 - train: epoch 0020, iter [01400, 05004], lr: 0.189056, loss: 2.0189
2022-07-17 12:30:16 - train: epoch 0020, iter [01500, 05004], lr: 0.189026, loss: 2.0792
2022-07-17 12:32:33 - train: epoch 0020, iter [01600, 05004], lr: 0.188996, loss: 2.0340
2022-07-17 12:34:49 - train: epoch 0020, iter [01700, 05004], lr: 0.188966, loss: 1.8658
2022-07-17 12:37:06 - train: epoch 0020, iter [01800, 05004], lr: 0.188935, loss: 1.8107
2022-07-17 12:39:23 - train: epoch 0020, iter [01900, 05004], lr: 0.188905, loss: 1.8387
2022-07-17 12:41:39 - train: epoch 0020, iter [02000, 05004], lr: 0.188875, loss: 1.8937
2022-07-17 12:43:56 - train: epoch 0020, iter [02100, 05004], lr: 0.188845, loss: 2.0235
2022-07-17 12:46:13 - train: epoch 0020, iter [02200, 05004], lr: 0.188814, loss: 1.8507
2022-07-17 12:48:29 - train: epoch 0020, iter [02300, 05004], lr: 0.188784, loss: 1.8470
2022-07-17 12:50:46 - train: epoch 0020, iter [02400, 05004], lr: 0.188753, loss: 2.1502
2022-07-17 12:53:03 - train: epoch 0020, iter [02500, 05004], lr: 0.188723, loss: 1.8477
2022-07-17 12:55:19 - train: epoch 0020, iter [02600, 05004], lr: 0.188692, loss: 1.8434
2022-07-17 12:57:36 - train: epoch 0020, iter [02700, 05004], lr: 0.188662, loss: 1.8549
2022-07-17 12:59:53 - train: epoch 0020, iter [02800, 05004], lr: 0.188631, loss: 1.9090
2022-07-17 13:02:09 - train: epoch 0020, iter [02900, 05004], lr: 0.188601, loss: 2.1355
2022-07-17 13:04:26 - train: epoch 0020, iter [03000, 05004], lr: 0.188570, loss: 2.1346
2022-07-17 13:06:43 - train: epoch 0020, iter [03100, 05004], lr: 0.188539, loss: 1.9688
2022-07-17 13:08:59 - train: epoch 0020, iter [03200, 05004], lr: 0.188509, loss: 1.9802
2022-07-17 13:11:16 - train: epoch 0020, iter [03300, 05004], lr: 0.188478, loss: 1.8240
2022-07-17 13:13:33 - train: epoch 0020, iter [03400, 05004], lr: 0.188447, loss: 1.9169
2022-07-17 13:15:49 - train: epoch 0020, iter [03500, 05004], lr: 0.188416, loss: 1.5803
2022-07-17 13:18:06 - train: epoch 0020, iter [03600, 05004], lr: 0.188385, loss: 1.9651
2022-07-17 13:20:23 - train: epoch 0020, iter [03700, 05004], lr: 0.188354, loss: 1.9909
2022-07-17 13:22:40 - train: epoch 0020, iter [03800, 05004], lr: 0.188323, loss: 1.9955
2022-07-17 13:24:57 - train: epoch 0020, iter [03900, 05004], lr: 0.188292, loss: 2.1141
2022-07-17 13:27:13 - train: epoch 0020, iter [04000, 05004], lr: 0.188261, loss: 1.7047
2022-07-17 13:29:30 - train: epoch 0020, iter [04100, 05004], lr: 0.188230, loss: 1.9506
2022-07-17 13:31:47 - train: epoch 0020, iter [04200, 05004], lr: 0.188199, loss: 1.9082
2022-07-17 13:34:04 - train: epoch 0020, iter [04300, 05004], lr: 0.188168, loss: 2.0379
2022-07-17 13:36:21 - train: epoch 0020, iter [04400, 05004], lr: 0.188137, loss: 1.9899
2022-07-17 13:38:37 - train: epoch 0020, iter [04500, 05004], lr: 0.188105, loss: 1.8992
2022-07-17 13:40:54 - train: epoch 0020, iter [04600, 05004], lr: 0.188074, loss: 1.8368
2022-07-17 13:43:11 - train: epoch 0020, iter [04700, 05004], lr: 0.188043, loss: 1.6798
2022-07-17 13:45:28 - train: epoch 0020, iter [04800, 05004], lr: 0.188011, loss: 1.8009
2022-07-17 13:47:44 - train: epoch 0020, iter [04900, 05004], lr: 0.187980, loss: 1.8884
2022-07-17 13:50:01 - train: epoch 0020, iter [05000, 05004], lr: 0.187949, loss: 1.7278
2022-07-17 13:50:08 - train: epoch 020, train_loss: 1.8867
2022-07-17 13:52:17 - eval: epoch: 020, acc1: 60.998%, acc5: 84.050%, test_loss: 1.6502, per_image_load_time: 1.128ms, per_image_inference_time: 3.904ms
2022-07-17 13:52:18 - until epoch: 020, best_acc1: 60.998%
2022-07-17 13:52:18 - epoch 021 lr: 0.187947
2022-07-17 13:54:42 - train: epoch 0021, iter [00100, 05004], lr: 0.187916, loss: 1.9235
2022-07-17 13:56:59 - train: epoch 0021, iter [00200, 05004], lr: 0.187884, loss: 1.8300
2022-07-17 13:59:15 - train: epoch 0021, iter [00300, 05004], lr: 0.187853, loss: 1.6397
2022-07-17 14:01:32 - train: epoch 0021, iter [00400, 05004], lr: 0.187821, loss: 1.7070
2022-07-17 14:03:49 - train: epoch 0021, iter [00500, 05004], lr: 0.187790, loss: 1.7080
2022-07-17 14:06:05 - train: epoch 0021, iter [00600, 05004], lr: 0.187758, loss: 1.8622
2022-07-17 14:08:22 - train: epoch 0021, iter [00700, 05004], lr: 0.187726, loss: 1.7681
2022-07-17 14:10:39 - train: epoch 0021, iter [00800, 05004], lr: 0.187695, loss: 1.8032
2022-07-17 14:12:56 - train: epoch 0021, iter [00900, 05004], lr: 0.187663, loss: 1.8115
2022-07-17 14:15:12 - train: epoch 0021, iter [01000, 05004], lr: 0.187631, loss: 1.7536
2022-07-17 14:17:29 - train: epoch 0021, iter [01100, 05004], lr: 0.187599, loss: 1.7756
2022-07-17 14:19:46 - train: epoch 0021, iter [01200, 05004], lr: 0.187567, loss: 1.9535
2022-07-17 14:22:02 - train: epoch 0021, iter [01300, 05004], lr: 0.187535, loss: 1.7120
2022-07-17 14:24:19 - train: epoch 0021, iter [01400, 05004], lr: 0.187503, loss: 1.7352
2022-07-17 14:26:36 - train: epoch 0021, iter [01500, 05004], lr: 0.187471, loss: 1.8320
2022-07-17 14:28:53 - train: epoch 0021, iter [01600, 05004], lr: 0.187439, loss: 1.7161
2022-07-17 14:31:10 - train: epoch 0021, iter [01700, 05004], lr: 0.187407, loss: 1.8287
2022-07-17 14:33:26 - train: epoch 0021, iter [01800, 05004], lr: 0.187375, loss: 1.7008
2022-07-17 14:35:43 - train: epoch 0021, iter [01900, 05004], lr: 0.187343, loss: 2.0098
2022-07-17 14:38:00 - train: epoch 0021, iter [02000, 05004], lr: 0.187311, loss: 1.9458
2022-07-17 14:40:16 - train: epoch 0021, iter [02100, 05004], lr: 0.187278, loss: 1.8587
2022-07-17 14:42:33 - train: epoch 0021, iter [02200, 05004], lr: 0.187246, loss: 1.9641
2022-07-17 14:44:50 - train: epoch 0021, iter [02300, 05004], lr: 0.187214, loss: 1.8865
2022-07-17 14:47:07 - train: epoch 0021, iter [02400, 05004], lr: 0.187181, loss: 1.7744
2022-07-17 14:49:23 - train: epoch 0021, iter [02500, 05004], lr: 0.187149, loss: 1.8715
2022-07-17 14:51:40 - train: epoch 0021, iter [02600, 05004], lr: 0.187117, loss: 1.9285
2022-07-17 14:53:57 - train: epoch 0021, iter [02700, 05004], lr: 0.187084, loss: 1.9054
2022-07-17 14:56:14 - train: epoch 0021, iter [02800, 05004], lr: 0.187052, loss: 2.0269
2022-07-17 14:58:30 - train: epoch 0021, iter [02900, 05004], lr: 0.187019, loss: 1.7341
2022-07-17 15:00:47 - train: epoch 0021, iter [03000, 05004], lr: 0.186987, loss: 1.9220
2022-07-17 15:03:04 - train: epoch 0021, iter [03100, 05004], lr: 0.186954, loss: 1.8925
2022-07-17 15:05:21 - train: epoch 0021, iter [03200, 05004], lr: 0.186921, loss: 1.6500
2022-07-17 15:07:37 - train: epoch 0021, iter [03300, 05004], lr: 0.186889, loss: 2.1778
2022-07-17 15:09:54 - train: epoch 0021, iter [03400, 05004], lr: 0.186856, loss: 2.0203
2022-07-17 15:12:11 - train: epoch 0021, iter [03500, 05004], lr: 0.186823, loss: 1.9124
2022-07-17 15:14:28 - train: epoch 0021, iter [03600, 05004], lr: 0.186790, loss: 1.8898
2022-07-17 15:16:44 - train: epoch 0021, iter [03700, 05004], lr: 0.186757, loss: 1.7919
2022-07-17 15:19:01 - train: epoch 0021, iter [03800, 05004], lr: 0.186725, loss: 1.9591
2022-07-17 15:21:18 - train: epoch 0021, iter [03900, 05004], lr: 0.186692, loss: 1.8259
2022-07-17 15:23:35 - train: epoch 0021, iter [04000, 05004], lr: 0.186659, loss: 2.2348
2022-07-17 15:25:51 - train: epoch 0021, iter [04100, 05004], lr: 0.186626, loss: 1.8140
2022-07-17 15:28:08 - train: epoch 0021, iter [04200, 05004], lr: 0.186593, loss: 1.8869
2022-07-17 15:30:25 - train: epoch 0021, iter [04300, 05004], lr: 0.186560, loss: 1.8469
2022-07-17 15:32:42 - train: epoch 0021, iter [04400, 05004], lr: 0.186526, loss: 1.9378
2022-07-17 15:34:58 - train: epoch 0021, iter [04500, 05004], lr: 0.186493, loss: 1.8550
2022-07-17 15:37:15 - train: epoch 0021, iter [04600, 05004], lr: 0.186460, loss: 1.8727
2022-07-17 15:39:32 - train: epoch 0021, iter [04700, 05004], lr: 0.186427, loss: 2.0329
2022-07-17 15:41:49 - train: epoch 0021, iter [04800, 05004], lr: 0.186394, loss: 2.0736
2022-07-17 15:44:05 - train: epoch 0021, iter [04900, 05004], lr: 0.186360, loss: 1.8243
2022-07-17 15:46:22 - train: epoch 0021, iter [05000, 05004], lr: 0.186327, loss: 1.7833
2022-07-17 15:46:29 - train: epoch 021, train_loss: 1.8744
2022-07-17 15:48:40 - eval: epoch: 021, acc1: 61.200%, acc5: 84.590%, test_loss: 1.6103, per_image_load_time: 1.059ms, per_image_inference_time: 3.935ms
2022-07-17 15:48:40 - until epoch: 021, best_acc1: 61.200%
2022-07-17 15:48:40 - epoch 022 lr: 0.186325
2022-07-17 15:51:05 - train: epoch 0022, iter [00100, 05004], lr: 0.186292, loss: 1.4910
2022-07-17 15:53:22 - train: epoch 0022, iter [00200, 05004], lr: 0.186259, loss: 1.8240
2022-07-17 15:55:38 - train: epoch 0022, iter [00300, 05004], lr: 0.186225, loss: 1.8002
2022-07-17 15:57:55 - train: epoch 0022, iter [00400, 05004], lr: 0.186192, loss: 1.7369
2022-07-17 16:00:12 - train: epoch 0022, iter [00500, 05004], lr: 0.186158, loss: 1.8650
2022-07-17 16:02:29 - train: epoch 0022, iter [00600, 05004], lr: 0.186125, loss: 1.9339
2022-07-17 16:04:45 - train: epoch 0022, iter [00700, 05004], lr: 0.186091, loss: 2.0025
2022-07-17 16:07:02 - train: epoch 0022, iter [00800, 05004], lr: 0.186058, loss: 2.1024
2022-07-17 16:09:19 - train: epoch 0022, iter [00900, 05004], lr: 0.186024, loss: 1.8929
2022-07-17 16:11:36 - train: epoch 0022, iter [01000, 05004], lr: 0.185990, loss: 1.7782
2022-07-17 16:13:53 - train: epoch 0022, iter [01100, 05004], lr: 0.185956, loss: 1.9411
2022-07-17 16:16:09 - train: epoch 0022, iter [01200, 05004], lr: 0.185923, loss: 1.6201
2022-07-17 16:18:26 - train: epoch 0022, iter [01300, 05004], lr: 0.185889, loss: 1.8277
2022-07-17 16:20:43 - train: epoch 0022, iter [01400, 05004], lr: 0.185855, loss: 1.7039
2022-07-17 16:23:00 - train: epoch 0022, iter [01500, 05004], lr: 0.185821, loss: 1.9625
2022-07-17 16:25:16 - train: epoch 0022, iter [01600, 05004], lr: 0.185787, loss: 1.6169
2022-07-17 16:27:33 - train: epoch 0022, iter [01700, 05004], lr: 0.185753, loss: 1.8765
2022-07-17 16:29:50 - train: epoch 0022, iter [01800, 05004], lr: 0.185719, loss: 1.9471
2022-07-17 16:32:07 - train: epoch 0022, iter [01900, 05004], lr: 0.185685, loss: 1.7588
2022-07-17 16:34:24 - train: epoch 0022, iter [02000, 05004], lr: 0.185651, loss: 1.8331
2022-07-17 16:36:40 - train: epoch 0022, iter [02100, 05004], lr: 0.185617, loss: 1.8539
2022-07-17 16:38:57 - train: epoch 0022, iter [02200, 05004], lr: 0.185583, loss: 1.6669
2022-07-17 16:41:14 - train: epoch 0022, iter [02300, 05004], lr: 0.185548, loss: 2.0160
2022-07-17 16:43:31 - train: epoch 0022, iter [02400, 05004], lr: 0.185514, loss: 2.0344
2022-07-17 16:45:47 - train: epoch 0022, iter [02500, 05004], lr: 0.185480, loss: 1.9308
2022-07-17 16:48:04 - train: epoch 0022, iter [02600, 05004], lr: 0.185446, loss: 1.6606
2022-07-17 16:50:21 - train: epoch 0022, iter [02700, 05004], lr: 0.185411, loss: 1.7086
2022-07-17 16:52:38 - train: epoch 0022, iter [02800, 05004], lr: 0.185377, loss: 1.9547
2022-07-17 16:54:54 - train: epoch 0022, iter [02900, 05004], lr: 0.185342, loss: 1.7936
2022-07-17 16:57:11 - train: epoch 0022, iter [03000, 05004], lr: 0.185308, loss: 1.9880
2022-07-17 16:59:28 - train: epoch 0022, iter [03100, 05004], lr: 0.185274, loss: 1.9131
2022-07-17 17:01:44 - train: epoch 0022, iter [03200, 05004], lr: 0.185239, loss: 1.9693
2022-07-17 17:04:01 - train: epoch 0022, iter [03300, 05004], lr: 0.185204, loss: 1.9509
2022-07-17 17:06:18 - train: epoch 0022, iter [03400, 05004], lr: 0.185170, loss: 1.6508
2022-07-17 17:08:34 - train: epoch 0022, iter [03500, 05004], lr: 0.185135, loss: 2.0675
2022-07-17 17:10:51 - train: epoch 0022, iter [03600, 05004], lr: 0.185100, loss: 2.0053
2022-07-17 17:13:08 - train: epoch 0022, iter [03700, 05004], lr: 0.185066, loss: 1.8940
2022-07-17 17:15:25 - train: epoch 0022, iter [03800, 05004], lr: 0.185031, loss: 2.0181
2022-07-17 17:17:41 - train: epoch 0022, iter [03900, 05004], lr: 0.184996, loss: 1.7214
2022-07-17 17:19:58 - train: epoch 0022, iter [04000, 05004], lr: 0.184961, loss: 1.9152
2022-07-17 17:22:16 - train: epoch 0022, iter [04100, 05004], lr: 0.184926, loss: 1.6918
2022-07-17 17:24:33 - train: epoch 0022, iter [04200, 05004], lr: 0.184892, loss: 2.0056
2022-07-17 17:26:49 - train: epoch 0022, iter [04300, 05004], lr: 0.184857, loss: 1.9052
2022-07-17 17:29:06 - train: epoch 0022, iter [04400, 05004], lr: 0.184822, loss: 1.7732
2022-07-17 17:31:23 - train: epoch 0022, iter [04500, 05004], lr: 0.184787, loss: 1.7646
2022-07-17 17:33:40 - train: epoch 0022, iter [04600, 05004], lr: 0.184752, loss: 2.0813
2022-07-17 17:35:57 - train: epoch 0022, iter [04700, 05004], lr: 0.184716, loss: 2.0048
2022-07-17 17:38:15 - train: epoch 0022, iter [04800, 05004], lr: 0.184681, loss: 1.7454
2022-07-17 17:40:32 - train: epoch 0022, iter [04900, 05004], lr: 0.184646, loss: 1.7205
2022-07-17 17:42:49 - train: epoch 0022, iter [05000, 05004], lr: 0.184611, loss: 1.7818
2022-07-17 17:42:55 - train: epoch 022, train_loss: 1.8600
2022-07-17 17:44:59 - eval: epoch: 022, acc1: 61.696%, acc5: 84.842%, test_loss: 1.5993, per_image_load_time: 0.859ms, per_image_inference_time: 3.910ms
2022-07-17 17:44:59 - until epoch: 022, best_acc1: 61.696%
2022-07-17 17:44:59 - epoch 023 lr: 0.184609
2022-07-17 17:47:23 - train: epoch 0023, iter [00100, 05004], lr: 0.184574, loss: 1.7261
2022-07-17 17:49:40 - train: epoch 0023, iter [00200, 05004], lr: 0.184539, loss: 1.5827
2022-07-17 17:51:57 - train: epoch 0023, iter [00300, 05004], lr: 0.184504, loss: 1.7107
2022-07-17 17:54:14 - train: epoch 0023, iter [00400, 05004], lr: 0.184468, loss: 1.8324
2022-07-17 17:56:31 - train: epoch 0023, iter [00500, 05004], lr: 0.184433, loss: 1.9388
2022-07-17 17:58:48 - train: epoch 0023, iter [00600, 05004], lr: 0.184398, loss: 1.8487
2022-07-17 18:01:05 - train: epoch 0023, iter [00700, 05004], lr: 0.184362, loss: 1.6833
2022-07-17 18:03:21 - train: epoch 0023, iter [00800, 05004], lr: 0.184327, loss: 2.0300
2022-07-17 18:05:38 - train: epoch 0023, iter [00900, 05004], lr: 0.184291, loss: 1.7817
2022-07-17 18:07:55 - train: epoch 0023, iter [01000, 05004], lr: 0.184255, loss: 1.7688
2022-07-17 18:10:12 - train: epoch 0023, iter [01100, 05004], lr: 0.184220, loss: 2.0552
2022-07-17 18:12:29 - train: epoch 0023, iter [01200, 05004], lr: 0.184184, loss: 1.7953
2022-07-17 18:14:47 - train: epoch 0023, iter [01300, 05004], lr: 0.184148, loss: 1.8147
2022-07-17 18:17:04 - train: epoch 0023, iter [01400, 05004], lr: 0.184113, loss: 1.9436
2022-07-17 18:19:21 - train: epoch 0023, iter [01500, 05004], lr: 0.184077, loss: 1.7454
2022-07-17 18:21:38 - train: epoch 0023, iter [01600, 05004], lr: 0.184041, loss: 1.6352
2022-07-17 18:23:56 - train: epoch 0023, iter [01700, 05004], lr: 0.184005, loss: 1.7880
2022-07-17 18:26:13 - train: epoch 0023, iter [01800, 05004], lr: 0.183969, loss: 1.8183
2022-07-17 18:28:30 - train: epoch 0023, iter [01900, 05004], lr: 0.183934, loss: 2.1109
2022-07-17 18:30:48 - train: epoch 0023, iter [02000, 05004], lr: 0.183898, loss: 1.8184
2022-07-17 18:33:05 - train: epoch 0023, iter [02100, 05004], lr: 0.183862, loss: 2.0363
2022-07-17 18:35:22 - train: epoch 0023, iter [02200, 05004], lr: 0.183826, loss: 1.7153
2022-07-17 18:37:40 - train: epoch 0023, iter [02300, 05004], lr: 0.183790, loss: 1.8451
2022-07-17 18:39:57 - train: epoch 0023, iter [02400, 05004], lr: 0.183753, loss: 1.8015
2022-07-17 18:42:14 - train: epoch 0023, iter [02500, 05004], lr: 0.183717, loss: 1.8858
2022-07-17 18:44:32 - train: epoch 0023, iter [02600, 05004], lr: 0.183681, loss: 2.0785
2022-07-17 18:46:49 - train: epoch 0023, iter [02700, 05004], lr: 0.183645, loss: 1.8481
2022-07-17 18:49:06 - train: epoch 0023, iter [02800, 05004], lr: 0.183609, loss: 1.9557
2022-07-17 18:51:23 - train: epoch 0023, iter [02900, 05004], lr: 0.183572, loss: 1.7461
2022-07-17 18:53:40 - train: epoch 0023, iter [03000, 05004], lr: 0.183536, loss: 1.8533
2022-07-17 18:55:58 - train: epoch 0023, iter [03100, 05004], lr: 0.183500, loss: 2.0304
2022-07-17 18:58:15 - train: epoch 0023, iter [03200, 05004], lr: 0.183463, loss: 2.1100
2022-07-17 19:00:32 - train: epoch 0023, iter [03300, 05004], lr: 0.183427, loss: 1.8738
2022-07-17 19:02:49 - train: epoch 0023, iter [03400, 05004], lr: 0.183391, loss: 2.0681
2022-07-17 19:05:06 - train: epoch 0023, iter [03500, 05004], lr: 0.183354, loss: 1.8091
2022-07-17 19:07:23 - train: epoch 0023, iter [03600, 05004], lr: 0.183318, loss: 1.6769
2022-07-17 19:09:41 - train: epoch 0023, iter [03700, 05004], lr: 0.183281, loss: 1.8532
2022-07-17 19:11:58 - train: epoch 0023, iter [03800, 05004], lr: 0.183244, loss: 1.9120
2022-07-17 19:14:15 - train: epoch 0023, iter [03900, 05004], lr: 0.183208, loss: 1.8983
2022-07-17 19:16:32 - train: epoch 0023, iter [04000, 05004], lr: 0.183171, loss: 1.7641
2022-07-17 19:18:49 - train: epoch 0023, iter [04100, 05004], lr: 0.183134, loss: 1.6670
2022-07-17 19:21:06 - train: epoch 0023, iter [04200, 05004], lr: 0.183098, loss: 1.7394
2022-07-17 19:23:24 - train: epoch 0023, iter [04300, 05004], lr: 0.183061, loss: 1.8182
2022-07-17 19:25:41 - train: epoch 0023, iter [04400, 05004], lr: 0.183024, loss: 1.7852
2022-07-17 19:27:58 - train: epoch 0023, iter [04500, 05004], lr: 0.182987, loss: 1.7969
2022-07-17 19:30:15 - train: epoch 0023, iter [04600, 05004], lr: 0.182950, loss: 1.9653
2022-07-17 19:32:32 - train: epoch 0023, iter [04700, 05004], lr: 0.182913, loss: 1.6507
2022-07-17 19:34:49 - train: epoch 0023, iter [04800, 05004], lr: 0.182876, loss: 1.9437
2022-07-17 19:37:06 - train: epoch 0023, iter [04900, 05004], lr: 0.182839, loss: 1.7467
2022-07-17 19:39:24 - train: epoch 0023, iter [05000, 05004], lr: 0.182802, loss: 2.0393
2022-07-17 19:39:30 - train: epoch 023, train_loss: 1.8483
2022-07-17 19:41:40 - eval: epoch: 023, acc1: 61.902%, acc5: 85.030%, test_loss: 1.5768, per_image_load_time: 1.058ms, per_image_inference_time: 3.924ms
2022-07-17 19:41:40 - until epoch: 023, best_acc1: 61.902%
2022-07-17 19:41:40 - epoch 024 lr: 0.182801
2022-07-17 19:44:06 - train: epoch 0024, iter [00100, 05004], lr: 0.182764, loss: 1.7245
2022-07-17 19:46:23 - train: epoch 0024, iter [00200, 05004], lr: 0.182727, loss: 1.7957
2022-07-17 19:48:40 - train: epoch 0024, iter [00300, 05004], lr: 0.182690, loss: 1.7947
2022-07-17 19:50:57 - train: epoch 0024, iter [00400, 05004], lr: 0.182652, loss: 1.7368
2022-07-17 19:53:13 - train: epoch 0024, iter [00500, 05004], lr: 0.182615, loss: 1.9956
2022-07-17 19:55:30 - train: epoch 0024, iter [00600, 05004], lr: 0.182578, loss: 1.8672
2022-07-17 19:57:47 - train: epoch 0024, iter [00700, 05004], lr: 0.182541, loss: 1.7268
2022-07-17 20:00:04 - train: epoch 0024, iter [00800, 05004], lr: 0.182503, loss: 1.6583
2022-07-17 20:02:21 - train: epoch 0024, iter [00900, 05004], lr: 0.182466, loss: 1.7061
2022-07-17 20:04:38 - train: epoch 0024, iter [01000, 05004], lr: 0.182429, loss: 1.7510
2022-07-17 20:06:54 - train: epoch 0024, iter [01100, 05004], lr: 0.182391, loss: 1.5764
2022-07-17 20:09:11 - train: epoch 0024, iter [01200, 05004], lr: 0.182354, loss: 1.7468
2022-07-17 20:11:28 - train: epoch 0024, iter [01300, 05004], lr: 0.182316, loss: 1.8740
2022-07-17 20:13:45 - train: epoch 0024, iter [01400, 05004], lr: 0.182279, loss: 1.7848
2022-07-17 20:16:02 - train: epoch 0024, iter [01500, 05004], lr: 0.182241, loss: 2.0279
2022-07-17 20:18:19 - train: epoch 0024, iter [01600, 05004], lr: 0.182203, loss: 1.7076
2022-07-17 20:20:36 - train: epoch 0024, iter [01700, 05004], lr: 0.182166, loss: 1.6925
2022-07-17 20:22:53 - train: epoch 0024, iter [01800, 05004], lr: 0.182128, loss: 1.9606
2022-07-17 20:25:10 - train: epoch 0024, iter [01900, 05004], lr: 0.182090, loss: 1.6526
2022-07-17 20:27:26 - train: epoch 0024, iter [02000, 05004], lr: 0.182053, loss: 1.9377
2022-07-17 20:29:43 - train: epoch 0024, iter [02100, 05004], lr: 0.182015, loss: 1.8667
2022-07-17 20:32:00 - train: epoch 0024, iter [02200, 05004], lr: 0.181977, loss: 1.6970
2022-07-17 20:34:18 - train: epoch 0024, iter [02300, 05004], lr: 0.181939, loss: 1.9879
2022-07-17 20:36:35 - train: epoch 0024, iter [02400, 05004], lr: 0.181901, loss: 1.9756
2022-07-17 20:38:52 - train: epoch 0024, iter [02500, 05004], lr: 0.181863, loss: 2.0941
2022-07-17 20:41:09 - train: epoch 0024, iter [02600, 05004], lr: 0.181825, loss: 2.0348
2022-07-17 20:43:26 - train: epoch 0024, iter [02700, 05004], lr: 0.181787, loss: 2.1277
2022-07-17 20:45:43 - train: epoch 0024, iter [02800, 05004], lr: 0.181749, loss: 1.9388
2022-07-17 20:48:00 - train: epoch 0024, iter [02900, 05004], lr: 0.181711, loss: 1.7811
2022-07-17 20:50:18 - train: epoch 0024, iter [03000, 05004], lr: 0.181673, loss: 1.6383
2022-07-17 20:52:35 - train: epoch 0024, iter [03100, 05004], lr: 0.181635, loss: 1.9617
2022-07-17 20:54:52 - train: epoch 0024, iter [03200, 05004], lr: 0.181597, loss: 2.0513
2022-07-17 20:57:09 - train: epoch 0024, iter [03300, 05004], lr: 0.181558, loss: 1.6802
2022-07-17 20:59:26 - train: epoch 0024, iter [03400, 05004], lr: 0.181520, loss: 1.7013
2022-07-17 21:01:43 - train: epoch 0024, iter [03500, 05004], lr: 0.181482, loss: 1.8728
2022-07-17 21:04:00 - train: epoch 0024, iter [03600, 05004], lr: 0.181444, loss: 1.8236
2022-07-17 21:06:17 - train: epoch 0024, iter [03700, 05004], lr: 0.181405, loss: 1.7852
2022-07-17 21:08:34 - train: epoch 0024, iter [03800, 05004], lr: 0.181367, loss: 2.0087
2022-07-17 21:10:51 - train: epoch 0024, iter [03900, 05004], lr: 0.181328, loss: 1.7152
2022-07-17 21:13:08 - train: epoch 0024, iter [04000, 05004], lr: 0.181290, loss: 1.9226
2022-07-17 21:15:26 - train: epoch 0024, iter [04100, 05004], lr: 0.181251, loss: 1.8164
2022-07-17 21:17:43 - train: epoch 0024, iter [04200, 05004], lr: 0.181213, loss: 1.9548
2022-07-17 21:20:00 - train: epoch 0024, iter [04300, 05004], lr: 0.181174, loss: 1.9600
2022-07-17 21:22:17 - train: epoch 0024, iter [04400, 05004], lr: 0.181136, loss: 1.8675
2022-07-17 21:24:34 - train: epoch 0024, iter [04500, 05004], lr: 0.181097, loss: 1.6769
2022-07-17 21:26:51 - train: epoch 0024, iter [04600, 05004], lr: 0.181058, loss: 1.8636
2022-07-17 21:29:08 - train: epoch 0024, iter [04700, 05004], lr: 0.181020, loss: 1.8171
2022-07-17 21:31:26 - train: epoch 0024, iter [04800, 05004], lr: 0.180981, loss: 1.6121
2022-07-17 21:33:43 - train: epoch 0024, iter [04900, 05004], lr: 0.180942, loss: 1.8332
2022-07-17 21:36:00 - train: epoch 0024, iter [05000, 05004], lr: 0.180903, loss: 1.8906
2022-07-17 21:36:06 - train: epoch 024, train_loss: 1.8361
2022-07-17 21:38:18 - eval: epoch: 024, acc1: 62.722%, acc5: 85.392%, test_loss: 1.5599, per_image_load_time: 1.168ms, per_image_inference_time: 3.930ms
2022-07-17 21:38:19 - until epoch: 024, best_acc1: 62.722%
2022-07-17 21:38:19 - epoch 025 lr: 0.180901
2022-07-17 21:40:45 - train: epoch 0025, iter [00100, 05004], lr: 0.180863, loss: 1.7360
2022-07-17 21:43:03 - train: epoch 0025, iter [00200, 05004], lr: 0.180824, loss: 1.5782
2022-07-17 21:45:20 - train: epoch 0025, iter [00300, 05004], lr: 0.180785, loss: 1.7022
2022-07-17 21:47:38 - train: epoch 0025, iter [00400, 05004], lr: 0.180746, loss: 1.8415
2022-07-17 21:49:55 - train: epoch 0025, iter [00500, 05004], lr: 0.180707, loss: 1.6830
2022-07-17 21:52:12 - train: epoch 0025, iter [00600, 05004], lr: 0.180668, loss: 1.8186
2022-07-17 21:54:29 - train: epoch 0025, iter [00700, 05004], lr: 0.180629, loss: 1.8449
2022-07-17 21:56:46 - train: epoch 0025, iter [00800, 05004], lr: 0.180590, loss: 1.7591
2022-07-17 21:59:03 - train: epoch 0025, iter [00900, 05004], lr: 0.180551, loss: 1.5143
2022-07-17 22:01:20 - train: epoch 0025, iter [01000, 05004], lr: 0.180511, loss: 1.8741
2022-07-17 22:03:37 - train: epoch 0025, iter [01100, 05004], lr: 0.180472, loss: 1.6678
2022-07-17 22:05:54 - train: epoch 0025, iter [01200, 05004], lr: 0.180433, loss: 1.7473
2022-07-17 22:08:11 - train: epoch 0025, iter [01300, 05004], lr: 0.180394, loss: 1.6428
2022-07-17 22:10:27 - train: epoch 0025, iter [01400, 05004], lr: 0.180354, loss: 1.7221
2022-07-17 22:12:44 - train: epoch 0025, iter [01500, 05004], lr: 0.180315, loss: 1.8219
2022-07-17 22:15:02 - train: epoch 0025, iter [01600, 05004], lr: 0.180276, loss: 1.6279
2022-07-17 22:17:18 - train: epoch 0025, iter [01700, 05004], lr: 0.180236, loss: 1.8554
2022-07-17 22:19:35 - train: epoch 0025, iter [01800, 05004], lr: 0.180197, loss: 1.6237
2022-07-17 22:21:52 - train: epoch 0025, iter [01900, 05004], lr: 0.180157, loss: 1.7184
2022-07-17 22:24:09 - train: epoch 0025, iter [02000, 05004], lr: 0.180118, loss: 1.9694
2022-07-17 22:26:26 - train: epoch 0025, iter [02100, 05004], lr: 0.180078, loss: 1.7278
2022-07-17 22:28:43 - train: epoch 0025, iter [02200, 05004], lr: 0.180039, loss: 1.6430
2022-07-17 22:31:00 - train: epoch 0025, iter [02300, 05004], lr: 0.179999, loss: 1.6791
2022-07-17 22:33:17 - train: epoch 0025, iter [02400, 05004], lr: 0.179959, loss: 1.5756
2022-07-17 22:35:34 - train: epoch 0025, iter [02500, 05004], lr: 0.179920, loss: 1.9018
2022-07-17 22:37:51 - train: epoch 0025, iter [02600, 05004], lr: 0.179880, loss: 1.8488
2022-07-17 22:40:09 - train: epoch 0025, iter [02700, 05004], lr: 0.179840, loss: 1.9775
2022-07-17 22:42:26 - train: epoch 0025, iter [02800, 05004], lr: 0.179800, loss: 1.9108
2022-07-17 22:44:44 - train: epoch 0025, iter [02900, 05004], lr: 0.179760, loss: 1.8971
2022-07-17 22:47:01 - train: epoch 0025, iter [03000, 05004], lr: 0.179721, loss: 1.8885
2022-07-17 22:49:18 - train: epoch 0025, iter [03100, 05004], lr: 0.179681, loss: 1.6837
2022-07-17 22:51:35 - train: epoch 0025, iter [03200, 05004], lr: 0.179641, loss: 1.7292
2022-07-17 22:53:53 - train: epoch 0025, iter [03300, 05004], lr: 0.179601, loss: 1.6871
2022-07-17 22:56:10 - train: epoch 0025, iter [03400, 05004], lr: 0.179561, loss: 1.8668
2022-07-17 22:58:28 - train: epoch 0025, iter [03500, 05004], lr: 0.179521, loss: 1.6781
2022-07-17 23:00:45 - train: epoch 0025, iter [03600, 05004], lr: 0.179481, loss: 1.7791
