2022-07-22 23:08:02 - train: epoch 0087, iter [02900, 05004], lr: 0.009688, loss: 0.6518
2022-07-22 23:10:18 - train: epoch 0087, iter [03000, 05004], lr: 0.009659, loss: 0.7726
2022-07-22 23:12:35 - train: epoch 0087, iter [03100, 05004], lr: 0.009631, loss: 0.7855
2022-07-22 23:14:52 - train: epoch 0087, iter [03200, 05004], lr: 0.009603, loss: 0.7631
2022-07-22 23:17:09 - train: epoch 0087, iter [03300, 05004], lr: 0.009574, loss: 0.8151
2022-07-22 23:19:26 - train: epoch 0087, iter [03400, 05004], lr: 0.009546, loss: 0.7385
2022-07-22 23:21:42 - train: epoch 0087, iter [03500, 05004], lr: 0.009518, loss: 0.6624
2022-07-22 23:23:59 - train: epoch 0087, iter [03600, 05004], lr: 0.009490, loss: 0.7860
2022-07-22 23:26:16 - train: epoch 0087, iter [03700, 05004], lr: 0.009462, loss: 0.8671
2022-07-22 23:28:33 - train: epoch 0087, iter [03800, 05004], lr: 0.009434, loss: 0.7425
2022-07-22 23:30:49 - train: epoch 0087, iter [03900, 05004], lr: 0.009406, loss: 0.7013
2022-07-22 23:33:06 - train: epoch 0087, iter [04000, 05004], lr: 0.009378, loss: 0.8059
2022-07-22 23:35:23 - train: epoch 0087, iter [04100, 05004], lr: 0.009350, loss: 0.9207
2022-07-22 23:37:40 - train: epoch 0087, iter [04200, 05004], lr: 0.009322, loss: 0.7309
2022-07-22 23:39:57 - train: epoch 0087, iter [04300, 05004], lr: 0.009294, loss: 0.8240
2022-07-22 23:42:14 - train: epoch 0087, iter [04400, 05004], lr: 0.009266, loss: 0.7032
2022-07-22 23:44:31 - train: epoch 0087, iter [04500, 05004], lr: 0.009239, loss: 0.8284
2022-07-22 23:46:47 - train: epoch 0087, iter [04600, 05004], lr: 0.009211, loss: 0.9344
2022-07-22 23:49:04 - train: epoch 0087, iter [04700, 05004], lr: 0.009183, loss: 0.6710
2022-07-22 23:51:21 - train: epoch 0087, iter [04800, 05004], lr: 0.009156, loss: 0.7148
2022-07-22 23:53:38 - train: epoch 0087, iter [04900, 05004], lr: 0.009128, loss: 0.7946
2022-07-22 23:55:55 - train: epoch 0087, iter [05000, 05004], lr: 0.009100, loss: 0.6905
2022-07-22 23:56:01 - train: epoch 087, train_loss: 0.7686
2022-07-22 23:58:13 - eval: epoch: 087, acc1: 76.556%, acc5: 93.356%, test_loss: 0.9703, per_image_load_time: 1.183ms, per_image_inference_time: 3.914ms
2022-07-22 23:58:13 - until epoch: 087, best_acc1: 76.556%
2022-07-22 23:58:13 - epoch 088 lr: 0.009099
2022-07-23 00:00:39 - train: epoch 0088, iter [00100, 05004], lr: 0.009072, loss: 0.5999
2022-07-23 00:02:55 - train: epoch 0088, iter [00200, 05004], lr: 0.009044, loss: 0.6565
2022-07-23 00:05:12 - train: epoch 0088, iter [00300, 05004], lr: 0.009017, loss: 0.7850
2022-07-23 00:07:28 - train: epoch 0088, iter [00400, 05004], lr: 0.008989, loss: 0.7323
2022-07-23 00:09:45 - train: epoch 0088, iter [00500, 05004], lr: 0.008962, loss: 0.7631
2022-07-23 00:12:02 - train: epoch 0088, iter [00600, 05004], lr: 0.008935, loss: 0.8749
2022-07-23 00:14:19 - train: epoch 0088, iter [00700, 05004], lr: 0.008908, loss: 0.7848
2022-07-23 00:16:36 - train: epoch 0088, iter [00800, 05004], lr: 0.008880, loss: 0.7990
2022-07-23 00:18:52 - train: epoch 0088, iter [00900, 05004], lr: 0.008853, loss: 0.6981
2022-07-23 00:21:09 - train: epoch 0088, iter [01000, 05004], lr: 0.008826, loss: 0.6725
2022-07-23 00:23:26 - train: epoch 0088, iter [01100, 05004], lr: 0.008799, loss: 0.6966
2022-07-23 00:25:42 - train: epoch 0088, iter [01200, 05004], lr: 0.008772, loss: 0.8025
2022-07-23 00:27:59 - train: epoch 0088, iter [01300, 05004], lr: 0.008745, loss: 0.6871
2022-07-23 00:30:15 - train: epoch 0088, iter [01400, 05004], lr: 0.008718, loss: 0.7685
2022-07-23 00:32:32 - train: epoch 0088, iter [01500, 05004], lr: 0.008691, loss: 0.8172
2022-07-23 00:34:48 - train: epoch 0088, iter [01600, 05004], lr: 0.008664, loss: 0.5841
2022-07-23 00:37:05 - train: epoch 0088, iter [01700, 05004], lr: 0.008637, loss: 0.7967
2022-07-23 00:39:21 - train: epoch 0088, iter [01800, 05004], lr: 0.008610, loss: 0.7337
2022-07-23 00:41:38 - train: epoch 0088, iter [01900, 05004], lr: 0.008583, loss: 0.7686
2022-07-23 00:43:54 - train: epoch 0088, iter [02000, 05004], lr: 0.008556, loss: 0.6762
2022-07-23 00:46:11 - train: epoch 0088, iter [02100, 05004], lr: 0.008530, loss: 0.7266
2022-07-23 00:48:28 - train: epoch 0088, iter [02200, 05004], lr: 0.008503, loss: 0.7568
2022-07-23 00:50:44 - train: epoch 0088, iter [02300, 05004], lr: 0.008476, loss: 0.8759
2022-07-23 00:53:01 - train: epoch 0088, iter [02400, 05004], lr: 0.008450, loss: 0.7415
2022-07-23 00:55:17 - train: epoch 0088, iter [02500, 05004], lr: 0.008423, loss: 0.8477
2022-07-23 00:57:34 - train: epoch 0088, iter [02600, 05004], lr: 0.008397, loss: 0.7318
2022-07-23 00:59:50 - train: epoch 0088, iter [02700, 05004], lr: 0.008370, loss: 0.5544
2022-07-23 01:02:07 - train: epoch 0088, iter [02800, 05004], lr: 0.008344, loss: 0.7249
2022-07-23 01:04:23 - train: epoch 0088, iter [02900, 05004], lr: 0.008317, loss: 0.7154
2022-07-23 01:06:40 - train: epoch 0088, iter [03000, 05004], lr: 0.008291, loss: 0.8103
2022-07-23 01:08:56 - train: epoch 0088, iter [03100, 05004], lr: 0.008265, loss: 0.5846
2022-07-23 01:11:13 - train: epoch 0088, iter [03200, 05004], lr: 0.008238, loss: 0.6597
2022-07-23 01:13:29 - train: epoch 0088, iter [03300, 05004], lr: 0.008212, loss: 0.8073
2022-07-23 01:15:46 - train: epoch 0088, iter [03400, 05004], lr: 0.008186, loss: 0.6998
2022-07-23 01:18:03 - train: epoch 0088, iter [03500, 05004], lr: 0.008160, loss: 0.6935
2022-07-23 01:20:20 - train: epoch 0088, iter [03600, 05004], lr: 0.008134, loss: 0.7054
2022-07-23 01:22:36 - train: epoch 0088, iter [03700, 05004], lr: 0.008108, loss: 0.7888
2022-07-23 01:24:53 - train: epoch 0088, iter [03800, 05004], lr: 0.008081, loss: 0.7272
2022-07-23 01:27:10 - train: epoch 0088, iter [03900, 05004], lr: 0.008055, loss: 0.8329
2022-07-23 01:29:27 - train: epoch 0088, iter [04000, 05004], lr: 0.008029, loss: 0.8571
2022-07-23 01:31:43 - train: epoch 0088, iter [04100, 05004], lr: 0.008004, loss: 0.8354
2022-07-23 01:34:00 - train: epoch 0088, iter [04200, 05004], lr: 0.007978, loss: 0.8604
2022-07-23 01:36:17 - train: epoch 0088, iter [04300, 05004], lr: 0.007952, loss: 0.7742
2022-07-23 01:38:33 - train: epoch 0088, iter [04400, 05004], lr: 0.007926, loss: 0.5790
2022-07-23 01:40:50 - train: epoch 0088, iter [04500, 05004], lr: 0.007900, loss: 0.7639
2022-07-23 01:43:07 - train: epoch 0088, iter [04600, 05004], lr: 0.007875, loss: 0.9480
2022-07-23 01:45:23 - train: epoch 0088, iter [04700, 05004], lr: 0.007849, loss: 0.9520
2022-07-23 01:47:40 - train: epoch 0088, iter [04800, 05004], lr: 0.007823, loss: 0.6945
2022-07-23 01:49:57 - train: epoch 0088, iter [04900, 05004], lr: 0.007798, loss: 0.7428
2022-07-23 01:52:13 - train: epoch 0088, iter [05000, 05004], lr: 0.007772, loss: 0.8518
2022-07-23 01:52:20 - train: epoch 088, train_loss: 0.7434
2022-07-23 01:54:31 - eval: epoch: 088, acc1: 76.746%, acc5: 93.372%, test_loss: 0.9526, per_image_load_time: 1.014ms, per_image_inference_time: 3.908ms
2022-07-23 01:54:31 - until epoch: 088, best_acc1: 76.746%
2022-07-23 01:54:31 - epoch 089 lr: 0.007771
2022-07-23 01:56:56 - train: epoch 0089, iter [00100, 05004], lr: 0.007746, loss: 0.9517
2022-07-23 01:59:14 - train: epoch 0089, iter [00200, 05004], lr: 0.007720, loss: 0.6882
2022-07-23 02:01:31 - train: epoch 0089, iter [00300, 05004], lr: 0.007695, loss: 0.9693
2022-07-23 02:03:48 - train: epoch 0089, iter [00400, 05004], lr: 0.007669, loss: 0.6778
2022-07-23 02:06:05 - train: epoch 0089, iter [00500, 05004], lr: 0.007644, loss: 0.6811
2022-07-23 02:08:22 - train: epoch 0089, iter [00600, 05004], lr: 0.007618, loss: 0.7594
2022-07-23 02:10:39 - train: epoch 0089, iter [00700, 05004], lr: 0.007593, loss: 0.8822
2022-07-23 02:12:56 - train: epoch 0089, iter [00800, 05004], lr: 0.007568, loss: 0.6735
2022-07-23 02:15:13 - train: epoch 0089, iter [00900, 05004], lr: 0.007543, loss: 0.6758
2022-07-23 02:17:30 - train: epoch 0089, iter [01000, 05004], lr: 0.007518, loss: 0.6634
2022-07-23 02:19:47 - train: epoch 0089, iter [01100, 05004], lr: 0.007493, loss: 0.7152
2022-07-23 02:22:04 - train: epoch 0089, iter [01200, 05004], lr: 0.007467, loss: 0.8524
2022-07-23 02:24:21 - train: epoch 0089, iter [01300, 05004], lr: 0.007442, loss: 0.5438
2022-07-23 02:26:39 - train: epoch 0089, iter [01400, 05004], lr: 0.007417, loss: 0.8736
2022-07-23 02:28:56 - train: epoch 0089, iter [01500, 05004], lr: 0.007392, loss: 0.6788
2022-07-23 02:31:14 - train: epoch 0089, iter [01600, 05004], lr: 0.007368, loss: 0.5161
2022-07-23 02:33:31 - train: epoch 0089, iter [01700, 05004], lr: 0.007343, loss: 0.6862
2022-07-23 02:35:48 - train: epoch 0089, iter [01800, 05004], lr: 0.007318, loss: 0.7360
2022-07-23 02:38:05 - train: epoch 0089, iter [01900, 05004], lr: 0.007293, loss: 0.5894
2022-07-23 02:40:22 - train: epoch 0089, iter [02000, 05004], lr: 0.007268, loss: 0.6817
2022-07-23 02:42:39 - train: epoch 0089, iter [02100, 05004], lr: 0.007244, loss: 0.7491
2022-07-23 02:44:56 - train: epoch 0089, iter [02200, 05004], lr: 0.007219, loss: 0.7626
2022-07-23 02:47:13 - train: epoch 0089, iter [02300, 05004], lr: 0.007194, loss: 0.6765
2022-07-23 02:49:30 - train: epoch 0089, iter [02400, 05004], lr: 0.007170, loss: 0.8075
2022-07-23 02:51:48 - train: epoch 0089, iter [02500, 05004], lr: 0.007145, loss: 0.7937
2022-07-23 02:54:05 - train: epoch 0089, iter [02600, 05004], lr: 0.007121, loss: 0.6672
2022-07-23 02:56:22 - train: epoch 0089, iter [02700, 05004], lr: 0.007096, loss: 0.7052
2022-07-23 02:58:40 - train: epoch 0089, iter [02800, 05004], lr: 0.007072, loss: 0.5807
2022-07-23 03:00:57 - train: epoch 0089, iter [02900, 05004], lr: 0.007047, loss: 0.7048
2022-07-23 03:03:14 - train: epoch 0089, iter [03000, 05004], lr: 0.007023, loss: 0.7016
2022-07-23 03:05:31 - train: epoch 0089, iter [03100, 05004], lr: 0.006999, loss: 0.6141
2022-07-23 03:07:48 - train: epoch 0089, iter [03200, 05004], lr: 0.006974, loss: 0.7479
2022-07-23 03:10:06 - train: epoch 0089, iter [03300, 05004], lr: 0.006950, loss: 0.8672
2022-07-23 03:12:22 - train: epoch 0089, iter [03400, 05004], lr: 0.006926, loss: 0.6890
2022-07-23 03:14:39 - train: epoch 0089, iter [03500, 05004], lr: 0.006902, loss: 0.7705
2022-07-23 03:16:56 - train: epoch 0089, iter [03600, 05004], lr: 0.006878, loss: 0.6325
2022-07-23 03:19:13 - train: epoch 0089, iter [03700, 05004], lr: 0.006854, loss: 0.7867
2022-07-23 03:21:30 - train: epoch 0089, iter [03800, 05004], lr: 0.006830, loss: 0.6806
2022-07-23 03:23:46 - train: epoch 0089, iter [03900, 05004], lr: 0.006806, loss: 0.7404
2022-07-23 03:26:03 - train: epoch 0089, iter [04000, 05004], lr: 0.006782, loss: 0.7352
2022-07-23 03:28:20 - train: epoch 0089, iter [04100, 05004], lr: 0.006758, loss: 0.7229
2022-07-23 03:30:37 - train: epoch 0089, iter [04200, 05004], lr: 0.006734, loss: 0.7010
2022-07-23 03:32:54 - train: epoch 0089, iter [04300, 05004], lr: 0.006710, loss: 0.7845
2022-07-23 03:35:10 - train: epoch 0089, iter [04400, 05004], lr: 0.006686, loss: 0.6948
2022-07-23 03:37:27 - train: epoch 0089, iter [04500, 05004], lr: 0.006663, loss: 0.5902
2022-07-23 03:39:44 - train: epoch 0089, iter [04600, 05004], lr: 0.006639, loss: 0.7564
2022-07-23 03:42:00 - train: epoch 0089, iter [04700, 05004], lr: 0.006615, loss: 0.6572
2022-07-23 03:44:17 - train: epoch 0089, iter [04800, 05004], lr: 0.006592, loss: 0.7036
2022-07-23 03:46:34 - train: epoch 0089, iter [04900, 05004], lr: 0.006568, loss: 0.6470
2022-07-23 03:48:51 - train: epoch 0089, iter [05000, 05004], lr: 0.006544, loss: 0.6449
2022-07-23 03:48:57 - train: epoch 089, train_loss: 0.7183
2022-07-23 03:51:09 - eval: epoch: 089, acc1: 77.094%, acc5: 93.398%, test_loss: 0.9518, per_image_load_time: 1.111ms, per_image_inference_time: 3.903ms
2022-07-23 03:51:09 - until epoch: 089, best_acc1: 77.094%
2022-07-23 03:51:09 - epoch 090 lr: 0.006543
2022-07-23 03:53:35 - train: epoch 0090, iter [00100, 05004], lr: 0.006520, loss: 0.7716
2022-07-23 03:55:52 - train: epoch 0090, iter [00200, 05004], lr: 0.006497, loss: 0.7125
2022-07-23 03:58:09 - train: epoch 0090, iter [00300, 05004], lr: 0.006473, loss: 0.7009
2022-07-23 04:00:25 - train: epoch 0090, iter [00400, 05004], lr: 0.006450, loss: 0.6688
2022-07-23 04:02:42 - train: epoch 0090, iter [00500, 05004], lr: 0.006426, loss: 0.6698
2022-07-23 04:04:59 - train: epoch 0090, iter [00600, 05004], lr: 0.006403, loss: 0.9073
2022-07-23 04:07:16 - train: epoch 0090, iter [00700, 05004], lr: 0.006380, loss: 0.7260
2022-07-23 04:09:32 - train: epoch 0090, iter [00800, 05004], lr: 0.006357, loss: 0.7301
2022-07-23 04:11:49 - train: epoch 0090, iter [00900, 05004], lr: 0.006334, loss: 0.6484
2022-07-23 04:14:06 - train: epoch 0090, iter [01000, 05004], lr: 0.006310, loss: 0.5149
2022-07-23 04:16:23 - train: epoch 0090, iter [01100, 05004], lr: 0.006287, loss: 0.7180
2022-07-23 04:18:40 - train: epoch 0090, iter [01200, 05004], lr: 0.006264, loss: 0.6628
2022-07-23 04:20:56 - train: epoch 0090, iter [01300, 05004], lr: 0.006241, loss: 0.6700
2022-07-23 04:23:13 - train: epoch 0090, iter [01400, 05004], lr: 0.006218, loss: 0.5740
2022-07-23 04:25:30 - train: epoch 0090, iter [01500, 05004], lr: 0.006195, loss: 0.8108
2022-07-23 04:27:47 - train: epoch 0090, iter [01600, 05004], lr: 0.006173, loss: 0.8413
2022-07-23 04:30:04 - train: epoch 0090, iter [01700, 05004], lr: 0.006150, loss: 0.6598
2022-07-23 04:32:21 - train: epoch 0090, iter [01800, 05004], lr: 0.006127, loss: 0.7114
2022-07-23 04:34:37 - train: epoch 0090, iter [01900, 05004], lr: 0.006104, loss: 0.7176
2022-07-23 04:36:54 - train: epoch 0090, iter [02000, 05004], lr: 0.006081, loss: 0.6807
2022-07-23 04:39:11 - train: epoch 0090, iter [02100, 05004], lr: 0.006059, loss: 0.7919
2022-07-23 04:41:28 - train: epoch 0090, iter [02200, 05004], lr: 0.006036, loss: 0.6577
2022-07-23 04:43:44 - train: epoch 0090, iter [02300, 05004], lr: 0.006014, loss: 0.7596
2022-07-23 04:46:01 - train: epoch 0090, iter [02400, 05004], lr: 0.005991, loss: 0.7050
2022-07-23 04:48:18 - train: epoch 0090, iter [02500, 05004], lr: 0.005969, loss: 0.7375
2022-07-23 04:50:34 - train: epoch 0090, iter [02600, 05004], lr: 0.005946, loss: 0.6942
2022-07-23 04:52:51 - train: epoch 0090, iter [02700, 05004], lr: 0.005924, loss: 0.6167
2022-07-23 04:55:08 - train: epoch 0090, iter [02800, 05004], lr: 0.005901, loss: 0.6299
2022-07-23 04:57:25 - train: epoch 0090, iter [02900, 05004], lr: 0.005879, loss: 0.7242
2022-07-23 04:59:41 - train: epoch 0090, iter [03000, 05004], lr: 0.005857, loss: 0.5831
2022-07-23 05:01:58 - train: epoch 0090, iter [03100, 05004], lr: 0.005834, loss: 0.6482
2022-07-23 05:04:15 - train: epoch 0090, iter [03200, 05004], lr: 0.005812, loss: 0.6411
2022-07-23 05:06:31 - train: epoch 0090, iter [03300, 05004], lr: 0.005790, loss: 0.7581
2022-07-23 05:08:48 - train: epoch 0090, iter [03400, 05004], lr: 0.005768, loss: 0.6474
2022-07-23 05:11:05 - train: epoch 0090, iter [03500, 05004], lr: 0.005746, loss: 0.5726
2022-07-23 05:13:21 - train: epoch 0090, iter [03600, 05004], lr: 0.005724, loss: 0.6344
2022-07-23 05:15:38 - train: epoch 0090, iter [03700, 05004], lr: 0.005702, loss: 0.5793
2022-07-23 05:17:55 - train: epoch 0090, iter [03800, 05004], lr: 0.005680, loss: 0.7273
2022-07-23 05:20:12 - train: epoch 0090, iter [03900, 05004], lr: 0.005658, loss: 0.6770
2022-07-23 05:22:28 - train: epoch 0090, iter [04000, 05004], lr: 0.005636, loss: 0.6691
2022-07-23 05:24:45 - train: epoch 0090, iter [04100, 05004], lr: 0.005614, loss: 0.9514
2022-07-23 05:27:02 - train: epoch 0090, iter [04200, 05004], lr: 0.005592, loss: 0.7527
2022-07-23 05:29:18 - train: epoch 0090, iter [04300, 05004], lr: 0.005570, loss: 0.7266
2022-07-23 05:31:35 - train: epoch 0090, iter [04400, 05004], lr: 0.005549, loss: 0.7438
2022-07-23 05:33:51 - train: epoch 0090, iter [04500, 05004], lr: 0.005527, loss: 0.5507
2022-07-23 05:36:08 - train: epoch 0090, iter [04600, 05004], lr: 0.005505, loss: 0.6471
2022-07-23 05:38:25 - train: epoch 0090, iter [04700, 05004], lr: 0.005484, loss: 0.8282
2022-07-23 05:40:41 - train: epoch 0090, iter [04800, 05004], lr: 0.005462, loss: 0.6571
2022-07-23 05:42:58 - train: epoch 0090, iter [04900, 05004], lr: 0.005441, loss: 0.6011
2022-07-23 05:45:15 - train: epoch 0090, iter [05000, 05004], lr: 0.005419, loss: 0.6901
2022-07-23 05:45:21 - train: epoch 090, train_loss: 0.6906
2022-07-23 05:47:30 - eval: epoch: 090, acc1: 77.120%, acc5: 93.500%, test_loss: 0.9540, per_image_load_time: 0.946ms, per_image_inference_time: 3.896ms
2022-07-23 05:47:30 - until epoch: 090, best_acc1: 77.120%
2022-07-23 05:47:30 - epoch 091 lr: 0.005418
2022-07-23 05:49:56 - train: epoch 0091, iter [00100, 05004], lr: 0.005397, loss: 0.6047
2022-07-23 05:52:12 - train: epoch 0091, iter [00200, 05004], lr: 0.005375, loss: 0.6311
2022-07-23 05:54:29 - train: epoch 0091, iter [00300, 05004], lr: 0.005354, loss: 0.5756
2022-07-23 05:56:45 - train: epoch 0091, iter [00400, 05004], lr: 0.005333, loss: 0.6673
2022-07-23 05:59:01 - train: epoch 0091, iter [00500, 05004], lr: 0.005312, loss: 0.7642
2022-07-23 06:01:18 - train: epoch 0091, iter [00600, 05004], lr: 0.005290, loss: 0.6879
2022-07-23 06:03:35 - train: epoch 0091, iter [00700, 05004], lr: 0.005269, loss: 0.9343
2022-07-23 06:05:51 - train: epoch 0091, iter [00800, 05004], lr: 0.005248, loss: 0.5240
2022-07-23 06:08:08 - train: epoch 0091, iter [00900, 05004], lr: 0.005227, loss: 0.6387
2022-07-23 06:10:24 - train: epoch 0091, iter [01000, 05004], lr: 0.005206, loss: 0.5900
2022-07-23 06:12:41 - train: epoch 0091, iter [01100, 05004], lr: 0.005185, loss: 0.4775
2022-07-23 06:14:57 - train: epoch 0091, iter [01200, 05004], lr: 0.005164, loss: 0.8031
2022-07-23 06:17:14 - train: epoch 0091, iter [01300, 05004], lr: 0.005143, loss: 0.6201
2022-07-23 06:19:30 - train: epoch 0091, iter [01400, 05004], lr: 0.005122, loss: 0.5727
2022-07-23 06:21:47 - train: epoch 0091, iter [01500, 05004], lr: 0.005101, loss: 0.7432
2022-07-23 06:24:04 - train: epoch 0091, iter [01600, 05004], lr: 0.005080, loss: 0.5998
2022-07-23 06:26:20 - train: epoch 0091, iter [01700, 05004], lr: 0.005059, loss: 0.6403
2022-07-23 06:28:37 - train: epoch 0091, iter [01800, 05004], lr: 0.005039, loss: 0.7090
2022-07-23 06:30:53 - train: epoch 0091, iter [01900, 05004], lr: 0.005018, loss: 0.6412
2022-07-23 06:33:10 - train: epoch 0091, iter [02000, 05004], lr: 0.004997, loss: 0.6034
2022-07-23 06:35:27 - train: epoch 0091, iter [02100, 05004], lr: 0.004977, loss: 0.6016
2022-07-23 06:37:43 - train: epoch 0091, iter [02200, 05004], lr: 0.004956, loss: 0.6073
2022-07-23 06:40:00 - train: epoch 0091, iter [02300, 05004], lr: 0.004936, loss: 0.5944
2022-07-23 06:42:16 - train: epoch 0091, iter [02400, 05004], lr: 0.004915, loss: 0.5351
2022-07-23 06:44:33 - train: epoch 0091, iter [02500, 05004], lr: 0.004895, loss: 0.5879
2022-07-23 06:46:49 - train: epoch 0091, iter [02600, 05004], lr: 0.004874, loss: 0.6175
2022-07-23 06:49:06 - train: epoch 0091, iter [02700, 05004], lr: 0.004854, loss: 0.6010
2022-07-23 06:51:23 - train: epoch 0091, iter [02800, 05004], lr: 0.004834, loss: 0.6468
2022-07-23 06:53:39 - train: epoch 0091, iter [02900, 05004], lr: 0.004813, loss: 0.7992
2022-07-23 06:55:56 - train: epoch 0091, iter [03000, 05004], lr: 0.004793, loss: 0.6732
2022-07-23 06:58:12 - train: epoch 0091, iter [03100, 05004], lr: 0.004773, loss: 0.6872
2022-07-23 07:00:29 - train: epoch 0091, iter [03200, 05004], lr: 0.004753, loss: 0.7306
2022-07-23 07:02:45 - train: epoch 0091, iter [03300, 05004], lr: 0.004733, loss: 0.5106
2022-07-23 07:05:02 - train: epoch 0091, iter [03400, 05004], lr: 0.004713, loss: 0.6971
2022-07-23 07:07:18 - train: epoch 0091, iter [03500, 05004], lr: 0.004693, loss: 0.5730
2022-07-23 07:09:35 - train: epoch 0091, iter [03600, 05004], lr: 0.004673, loss: 0.6968
2022-07-23 07:11:52 - train: epoch 0091, iter [03700, 05004], lr: 0.004653, loss: 0.8384
2022-07-23 07:14:08 - train: epoch 0091, iter [03800, 05004], lr: 0.004633, loss: 0.8369
2022-07-23 07:16:25 - train: epoch 0091, iter [03900, 05004], lr: 0.004613, loss: 0.6917
2022-07-23 07:18:41 - train: epoch 0091, iter [04000, 05004], lr: 0.004593, loss: 0.6167
2022-07-23 07:20:58 - train: epoch 0091, iter [04100, 05004], lr: 0.004573, loss: 0.7614
2022-07-23 07:23:14 - train: epoch 0091, iter [04200, 05004], lr: 0.004554, loss: 0.7195
2022-07-23 07:25:31 - train: epoch 0091, iter [04300, 05004], lr: 0.004534, loss: 0.5964
2022-07-23 07:27:47 - train: epoch 0091, iter [04400, 05004], lr: 0.004514, loss: 0.6100
2022-07-23 07:30:04 - train: epoch 0091, iter [04500, 05004], lr: 0.004495, loss: 0.6568
2022-07-23 07:32:20 - train: epoch 0091, iter [04600, 05004], lr: 0.004475, loss: 0.6924
2022-07-23 07:34:37 - train: epoch 0091, iter [04700, 05004], lr: 0.004456, loss: 0.6239
2022-07-23 07:36:54 - train: epoch 0091, iter [04800, 05004], lr: 0.004436, loss: 0.5635
2022-07-23 07:39:10 - train: epoch 0091, iter [04900, 05004], lr: 0.004417, loss: 0.6438
2022-07-23 07:41:27 - train: epoch 0091, iter [05000, 05004], lr: 0.004397, loss: 0.7527
2022-07-23 07:41:34 - train: epoch 091, train_loss: 0.6701
2022-07-23 07:43:45 - eval: epoch: 091, acc1: 77.128%, acc5: 93.524%, test_loss: 0.9490, per_image_load_time: 1.059ms, per_image_inference_time: 3.932ms
2022-07-23 07:43:46 - until epoch: 091, best_acc1: 77.128%
2022-07-23 07:43:46 - epoch 092 lr: 0.004396
2022-07-23 07:46:10 - train: epoch 0092, iter [00100, 05004], lr: 0.004377, loss: 0.5277
2022-07-23 07:48:27 - train: epoch 0092, iter [00200, 05004], lr: 0.004358, loss: 0.6784
2022-07-23 07:50:44 - train: epoch 0092, iter [00300, 05004], lr: 0.004338, loss: 0.5212
2022-07-23 07:53:00 - train: epoch 0092, iter [00400, 05004], lr: 0.004319, loss: 0.6011
2022-07-23 07:55:17 - train: epoch 0092, iter [00500, 05004], lr: 0.004300, loss: 0.7306
2022-07-23 07:57:33 - train: epoch 0092, iter [00600, 05004], lr: 0.004281, loss: 0.5806
2022-07-23 07:59:50 - train: epoch 0092, iter [00700, 05004], lr: 0.004262, loss: 0.6146
2022-07-23 08:02:07 - train: epoch 0092, iter [00800, 05004], lr: 0.004243, loss: 0.5588
2022-07-23 08:04:24 - train: epoch 0092, iter [00900, 05004], lr: 0.004224, loss: 0.6915
2022-07-23 08:06:40 - train: epoch 0092, iter [01000, 05004], lr: 0.004205, loss: 0.6802
2022-07-23 08:08:57 - train: epoch 0092, iter [01100, 05004], lr: 0.004186, loss: 0.7352
2022-07-23 08:11:14 - train: epoch 0092, iter [01200, 05004], lr: 0.004167, loss: 0.6636
2022-07-23 08:13:31 - train: epoch 0092, iter [01300, 05004], lr: 0.004148, loss: 0.6432
2022-07-23 08:15:47 - train: epoch 0092, iter [01400, 05004], lr: 0.004129, loss: 0.6418
2022-07-23 08:18:04 - train: epoch 0092, iter [01500, 05004], lr: 0.004110, loss: 0.5594
2022-07-23 08:20:20 - train: epoch 0092, iter [01600, 05004], lr: 0.004092, loss: 0.5802
2022-07-23 08:22:37 - train: epoch 0092, iter [01700, 05004], lr: 0.004073, loss: 0.8278
2022-07-23 08:24:54 - train: epoch 0092, iter [01800, 05004], lr: 0.004054, loss: 0.6471
2022-07-23 08:27:10 - train: epoch 0092, iter [01900, 05004], lr: 0.004036, loss: 0.7287
2022-07-23 08:29:27 - train: epoch 0092, iter [02000, 05004], lr: 0.004017, loss: 0.6471
2022-07-23 08:31:44 - train: epoch 0092, iter [02100, 05004], lr: 0.003999, loss: 0.5436
2022-07-23 08:34:00 - train: epoch 0092, iter [02200, 05004], lr: 0.003980, loss: 0.5789
2022-07-23 08:36:17 - train: epoch 0092, iter [02300, 05004], lr: 0.003962, loss: 0.6364
2022-07-23 08:38:34 - train: epoch 0092, iter [02400, 05004], lr: 0.003943, loss: 0.5397
2022-07-23 08:40:51 - train: epoch 0092, iter [02500, 05004], lr: 0.003925, loss: 0.6844
2022-07-23 08:43:07 - train: epoch 0092, iter [02600, 05004], lr: 0.003907, loss: 0.6974
2022-07-23 08:45:24 - train: epoch 0092, iter [02700, 05004], lr: 0.003888, loss: 0.7371
2022-07-23 08:47:41 - train: epoch 0092, iter [02800, 05004], lr: 0.003870, loss: 0.5745
2022-07-23 08:49:58 - train: epoch 0092, iter [02900, 05004], lr: 0.003852, loss: 0.7775
2022-07-23 08:52:15 - train: epoch 0092, iter [03000, 05004], lr: 0.003834, loss: 0.6120
2022-07-23 08:54:31 - train: epoch 0092, iter [03100, 05004], lr: 0.003816, loss: 0.6676
2022-07-23 08:56:48 - train: epoch 0092, iter [03200, 05004], lr: 0.003798, loss: 0.5462
2022-07-23 08:59:05 - train: epoch 0092, iter [03300, 05004], lr: 0.003780, loss: 0.5792
2022-07-23 09:01:22 - train: epoch 0092, iter [03400, 05004], lr: 0.003762, loss: 0.7750
2022-07-23 09:03:39 - train: epoch 0092, iter [03500, 05004], lr: 0.003744, loss: 0.7097
2022-07-23 09:05:56 - train: epoch 0092, iter [03600, 05004], lr: 0.003726, loss: 0.5729
2022-07-23 09:08:13 - train: epoch 0092, iter [03700, 05004], lr: 0.003708, loss: 0.4434
2022-07-23 09:10:30 - train: epoch 0092, iter [03800, 05004], lr: 0.003690, loss: 0.8180
2022-07-23 09:12:47 - train: epoch 0092, iter [03900, 05004], lr: 0.003672, loss: 0.7947
2022-07-23 09:15:04 - train: epoch 0092, iter [04000, 05004], lr: 0.003655, loss: 0.5509
2022-07-23 09:17:21 - train: epoch 0092, iter [04100, 05004], lr: 0.003637, loss: 0.5639
2022-07-23 09:19:38 - train: epoch 0092, iter [04200, 05004], lr: 0.003619, loss: 0.6866
2022-07-23 09:21:55 - train: epoch 0092, iter [04300, 05004], lr: 0.003602, loss: 0.7313
2022-07-23 09:24:12 - train: epoch 0092, iter [04400, 05004], lr: 0.003584, loss: 0.8040
2022-07-23 09:26:29 - train: epoch 0092, iter [04500, 05004], lr: 0.003567, loss: 0.5570
2022-07-23 09:28:45 - train: epoch 0092, iter [04600, 05004], lr: 0.003549, loss: 0.5820
2022-07-23 09:31:02 - train: epoch 0092, iter [04700, 05004], lr: 0.003532, loss: 0.4781
2022-07-23 09:33:19 - train: epoch 0092, iter [04800, 05004], lr: 0.003514, loss: 0.7310
2022-07-23 09:35:35 - train: epoch 0092, iter [04900, 05004], lr: 0.003497, loss: 0.5925
2022-07-23 09:37:52 - train: epoch 0092, iter [05000, 05004], lr: 0.003480, loss: 0.6256
2022-07-23 09:37:59 - train: epoch 092, train_loss: 0.6474
2022-07-23 09:40:09 - eval: epoch: 092, acc1: 77.322%, acc5: 93.640%, test_loss: 0.9465, per_image_load_time: 1.061ms, per_image_inference_time: 3.928ms
2022-07-23 09:40:09 - until epoch: 092, best_acc1: 77.322%
2022-07-23 09:40:09 - epoch 093 lr: 0.003479
2022-07-23 09:42:35 - train: epoch 0093, iter [00100, 05004], lr: 0.003462, loss: 0.5790
2022-07-23 09:44:52 - train: epoch 0093, iter [00200, 05004], lr: 0.003445, loss: 0.5035
2022-07-23 09:47:09 - train: epoch 0093, iter [00300, 05004], lr: 0.003427, loss: 0.6075
2022-07-23 09:49:25 - train: epoch 0093, iter [00400, 05004], lr: 0.003410, loss: 0.6414
2022-07-23 09:51:42 - train: epoch 0093, iter [00500, 05004], lr: 0.003393, loss: 0.6814
2022-07-23 09:53:58 - train: epoch 0093, iter [00600, 05004], lr: 0.003376, loss: 0.6028
2022-07-23 09:56:15 - train: epoch 0093, iter [00700, 05004], lr: 0.003359, loss: 0.6355
2022-07-23 09:58:32 - train: epoch 0093, iter [00800, 05004], lr: 0.003342, loss: 0.5530
2022-07-23 10:00:49 - train: epoch 0093, iter [00900, 05004], lr: 0.003325, loss: 0.6584
2022-07-23 10:03:05 - train: epoch 0093, iter [01000, 05004], lr: 0.003308, loss: 0.5680
2022-07-23 10:05:22 - train: epoch 0093, iter [01100, 05004], lr: 0.003292, loss: 0.6790
2022-07-23 10:07:38 - train: epoch 0093, iter [01200, 05004], lr: 0.003275, loss: 0.6965
2022-07-23 10:09:55 - train: epoch 0093, iter [01300, 05004], lr: 0.003258, loss: 0.6275
2022-07-23 10:12:12 - train: epoch 0093, iter [01400, 05004], lr: 0.003241, loss: 0.6497
2022-07-23 10:14:29 - train: epoch 0093, iter [01500, 05004], lr: 0.003225, loss: 0.8116
2022-07-23 10:16:45 - train: epoch 0093, iter [01600, 05004], lr: 0.003208, loss: 0.6321
2022-07-23 10:19:02 - train: epoch 0093, iter [01700, 05004], lr: 0.003191, loss: 0.6471
2022-07-23 10:21:19 - train: epoch 0093, iter [01800, 05004], lr: 0.003175, loss: 0.6843
2022-07-23 10:23:36 - train: epoch 0093, iter [01900, 05004], lr: 0.003158, loss: 0.7132
2022-07-23 10:25:53 - train: epoch 0093, iter [02000, 05004], lr: 0.003142, loss: 0.5682
2022-07-23 10:28:10 - train: epoch 0093, iter [02100, 05004], lr: 0.003126, loss: 0.6283
2022-07-23 10:30:26 - train: epoch 0093, iter [02200, 05004], lr: 0.003109, loss: 0.8207
2022-07-23 10:32:43 - train: epoch 0093, iter [02300, 05004], lr: 0.003093, loss: 0.5395
2022-07-23 10:35:00 - train: epoch 0093, iter [02400, 05004], lr: 0.003077, loss: 0.5207
2022-07-23 10:37:17 - train: epoch 0093, iter [02500, 05004], lr: 0.003060, loss: 0.6544
2022-07-23 10:39:34 - train: epoch 0093, iter [02600, 05004], lr: 0.003044, loss: 0.6747
2022-07-23 10:41:50 - train: epoch 0093, iter [02700, 05004], lr: 0.003028, loss: 0.6376
2022-07-23 10:44:07 - train: epoch 0093, iter [02800, 05004], lr: 0.003012, loss: 0.5962
2022-07-23 10:46:24 - train: epoch 0093, iter [02900, 05004], lr: 0.002996, loss: 0.6132
2022-07-23 10:48:41 - train: epoch 0093, iter [03000, 05004], lr: 0.002980, loss: 0.6460
2022-07-23 10:50:57 - train: epoch 0093, iter [03100, 05004], lr: 0.002964, loss: 0.5121
2022-07-23 10:53:14 - train: epoch 0093, iter [03200, 05004], lr: 0.002948, loss: 0.6088
2022-07-23 10:55:31 - train: epoch 0093, iter [03300, 05004], lr: 0.002932, loss: 0.5398
2022-07-23 10:57:48 - train: epoch 0093, iter [03400, 05004], lr: 0.002916, loss: 0.6060
2022-07-23 11:00:05 - train: epoch 0093, iter [03500, 05004], lr: 0.002900, loss: 0.5220
2022-07-23 11:02:22 - train: epoch 0093, iter [03600, 05004], lr: 0.002884, loss: 0.7098
2022-07-23 11:04:39 - train: epoch 0093, iter [03700, 05004], lr: 0.002869, loss: 0.6048
2022-07-23 11:06:56 - train: epoch 0093, iter [03800, 05004], lr: 0.002853, loss: 0.6669
2022-07-23 11:09:13 - train: epoch 0093, iter [03900, 05004], lr: 0.002837, loss: 0.7023
2022-07-23 11:11:30 - train: epoch 0093, iter [04000, 05004], lr: 0.002822, loss: 0.7355
2022-07-23 11:13:47 - train: epoch 0093, iter [04100, 05004], lr: 0.002806, loss: 0.6080
2022-07-23 11:16:03 - train: epoch 0093, iter [04200, 05004], lr: 0.002791, loss: 0.5770
2022-07-23 11:18:20 - train: epoch 0093, iter [04300, 05004], lr: 0.002775, loss: 0.5939
2022-07-23 11:20:37 - train: epoch 0093, iter [04400, 05004], lr: 0.002760, loss: 0.5732
2022-07-23 11:22:54 - train: epoch 0093, iter [04500, 05004], lr: 0.002744, loss: 0.6202
2022-07-23 11:25:11 - train: epoch 0093, iter [04600, 05004], lr: 0.002729, loss: 0.5254
2022-07-23 11:27:28 - train: epoch 0093, iter [04700, 05004], lr: 0.002714, loss: 0.6550
2022-07-23 11:29:45 - train: epoch 0093, iter [04800, 05004], lr: 0.002698, loss: 0.6134
2022-07-23 11:32:02 - train: epoch 0093, iter [04900, 05004], lr: 0.002683, loss: 0.6430
2022-07-23 11:34:19 - train: epoch 0093, iter [05000, 05004], lr: 0.002668, loss: 0.6427
2022-07-23 11:34:25 - train: epoch 093, train_loss: 0.6293
2022-07-23 11:36:35 - eval: epoch: 093, acc1: 77.426%, acc5: 93.696%, test_loss: 0.9367, per_image_load_time: 1.041ms, per_image_inference_time: 3.911ms
2022-07-23 11:36:35 - until epoch: 093, best_acc1: 77.426%
2022-07-23 11:36:35 - epoch 094 lr: 0.002667
2022-07-23 11:39:01 - train: epoch 0094, iter [00100, 05004], lr: 0.002652, loss: 0.6406
2022-07-23 11:41:18 - train: epoch 0094, iter [00200, 05004], lr: 0.002637, loss: 0.5254
2022-07-23 11:43:36 - train: epoch 0094, iter [00300, 05004], lr: 0.002622, loss: 0.6846
2022-07-23 11:45:53 - train: epoch 0094, iter [00400, 05004], lr: 0.002607, loss: 0.8465
2022-07-23 11:48:11 - train: epoch 0094, iter [00500, 05004], lr: 0.002592, loss: 0.4610
2022-07-23 11:50:28 - train: epoch 0094, iter [00600, 05004], lr: 0.002577, loss: 0.7705
2022-07-23 11:52:45 - train: epoch 0094, iter [00700, 05004], lr: 0.002562, loss: 0.7737
2022-07-23 11:55:03 - train: epoch 0094, iter [00800, 05004], lr: 0.002547, loss: 0.6102
2022-07-23 11:57:20 - train: epoch 0094, iter [00900, 05004], lr: 0.002533, loss: 0.7378
2022-07-23 11:59:37 - train: epoch 0094, iter [01000, 05004], lr: 0.002518, loss: 0.6038
2022-07-23 12:01:54 - train: epoch 0094, iter [01100, 05004], lr: 0.002503, loss: 0.6075
2022-07-23 12:04:12 - train: epoch 0094, iter [01200, 05004], lr: 0.002488, loss: 0.5705
2022-07-23 12:06:29 - train: epoch 0094, iter [01300, 05004], lr: 0.002474, loss: 0.6771
2022-07-23 12:08:46 - train: epoch 0094, iter [01400, 05004], lr: 0.002459, loss: 0.5995
2022-07-23 12:11:03 - train: epoch 0094, iter [01500, 05004], lr: 0.002445, loss: 0.6097
2022-07-23 12:13:21 - train: epoch 0094, iter [01600, 05004], lr: 0.002430, loss: 0.7111
2022-07-23 12:15:38 - train: epoch 0094, iter [01700, 05004], lr: 0.002416, loss: 0.6066
2022-07-23 12:17:55 - train: epoch 0094, iter [01800, 05004], lr: 0.002401, loss: 0.6839
2022-07-23 12:20:13 - train: epoch 0094, iter [01900, 05004], lr: 0.002387, loss: 0.5877
2022-07-23 12:22:30 - train: epoch 0094, iter [02000, 05004], lr: 0.002373, loss: 0.6083
2022-07-23 12:24:48 - train: epoch 0094, iter [02100, 05004], lr: 0.002358, loss: 0.5928
2022-07-23 12:27:05 - train: epoch 0094, iter [02200, 05004], lr: 0.002344, loss: 0.6113
2022-07-23 12:29:22 - train: epoch 0094, iter [02300, 05004], lr: 0.002330, loss: 0.4989
2022-07-23 12:31:40 - train: epoch 0094, iter [02400, 05004], lr: 0.002316, loss: 0.5468
2022-07-23 12:33:57 - train: epoch 0094, iter [02500, 05004], lr: 0.002302, loss: 0.6117
2022-07-23 12:36:14 - train: epoch 0094, iter [02600, 05004], lr: 0.002288, loss: 0.6340
2022-07-23 12:38:31 - train: epoch 0094, iter [02700, 05004], lr: 0.002273, loss: 0.5479
2022-07-23 12:40:48 - train: epoch 0094, iter [02800, 05004], lr: 0.002260, loss: 0.6329
2022-07-23 12:43:06 - train: epoch 0094, iter [02900, 05004], lr: 0.002246, loss: 0.5769
2022-07-23 12:45:23 - train: epoch 0094, iter [03000, 05004], lr: 0.002232, loss: 0.6622
2022-07-23 12:47:41 - train: epoch 0094, iter [03100, 05004], lr: 0.002218, loss: 0.7093
2022-07-23 12:49:58 - train: epoch 0094, iter [03200, 05004], lr: 0.002204, loss: 0.5813
2022-07-23 12:52:15 - train: epoch 0094, iter [03300, 05004], lr: 0.002190, loss: 0.6003
2022-07-23 12:54:33 - train: epoch 0094, iter [03400, 05004], lr: 0.002176, loss: 0.4416
2022-07-23 12:56:50 - train: epoch 0094, iter [03500, 05004], lr: 0.002163, loss: 0.8013
2022-07-23 12:59:08 - train: epoch 0094, iter [03600, 05004], lr: 0.002149, loss: 0.6289
2022-07-23 13:01:25 - train: epoch 0094, iter [03700, 05004], lr: 0.002136, loss: 0.6860
2022-07-23 13:03:43 - train: epoch 0094, iter [03800, 05004], lr: 0.002122, loss: 0.6720
2022-07-23 13:06:00 - train: epoch 0094, iter [03900, 05004], lr: 0.002108, loss: 0.5997
2022-07-23 13:08:18 - train: epoch 0094, iter [04000, 05004], lr: 0.002095, loss: 0.7597
2022-07-23 13:10:35 - train: epoch 0094, iter [04100, 05004], lr: 0.002082, loss: 0.6672
2022-07-23 13:12:52 - train: epoch 0094, iter [04200, 05004], lr: 0.002068, loss: 0.6271
2022-07-23 13:15:09 - train: epoch 0094, iter [04300, 05004], lr: 0.002055, loss: 0.7319
2022-07-23 13:17:27 - train: epoch 0094, iter [04400, 05004], lr: 0.002041, loss: 0.7094
2022-07-23 13:19:44 - train: epoch 0094, iter [04500, 05004], lr: 0.002028, loss: 0.6323
2022-07-23 13:22:02 - train: epoch 0094, iter [04600, 05004], lr: 0.002015, loss: 0.6495
2022-07-23 13:24:19 - train: epoch 0094, iter [04700, 05004], lr: 0.002002, loss: 0.6634
2022-07-23 13:26:37 - train: epoch 0094, iter [04800, 05004], lr: 0.001989, loss: 0.5544
2022-07-23 13:28:55 - train: epoch 0094, iter [04900, 05004], lr: 0.001976, loss: 0.7282
2022-07-23 13:31:12 - train: epoch 0094, iter [05000, 05004], lr: 0.001963, loss: 0.6555
2022-07-23 13:31:19 - train: epoch 094, train_loss: 0.6116
2022-07-23 13:33:29 - eval: epoch: 094, acc1: 77.544%, acc5: 93.708%, test_loss: 0.9378, per_image_load_time: 1.230ms, per_image_inference_time: 3.894ms
2022-07-23 13:33:30 - until epoch: 094, best_acc1: 77.544%
2022-07-23 13:33:30 - epoch 095 lr: 0.001962
2022-07-23 13:35:56 - train: epoch 0095, iter [00100, 05004], lr: 0.001949, loss: 0.6867
2022-07-23 13:38:13 - train: epoch 0095, iter [00200, 05004], lr: 0.001936, loss: 0.7039
2022-07-23 13:40:30 - train: epoch 0095, iter [00300, 05004], lr: 0.001923, loss: 0.6345
2022-07-23 13:42:47 - train: epoch 0095, iter [00400, 05004], lr: 0.001910, loss: 0.4317
2022-07-23 13:45:04 - train: epoch 0095, iter [00500, 05004], lr: 0.001897, loss: 0.5425
2022-07-23 13:47:21 - train: epoch 0095, iter [00600, 05004], lr: 0.001885, loss: 0.4754
2022-07-23 13:49:38 - train: epoch 0095, iter [00700, 05004], lr: 0.001872, loss: 0.6282
2022-07-23 13:51:55 - train: epoch 0095, iter [00800, 05004], lr: 0.001859, loss: 0.5902
2022-07-23 13:54:12 - train: epoch 0095, iter [00900, 05004], lr: 0.001846, loss: 0.6540
2022-07-23 13:56:29 - train: epoch 0095, iter [01000, 05004], lr: 0.001834, loss: 0.5661
2022-07-23 13:58:46 - train: epoch 0095, iter [01100, 05004], lr: 0.001821, loss: 0.6102
2022-07-23 14:01:03 - train: epoch 0095, iter [01200, 05004], lr: 0.001809, loss: 0.4677
2022-07-23 14:03:20 - train: epoch 0095, iter [01300, 05004], lr: 0.001796, loss: 0.4675
2022-07-23 14:05:37 - train: epoch 0095, iter [01400, 05004], lr: 0.001784, loss: 0.4655
2022-07-23 14:07:54 - train: epoch 0095, iter [01500, 05004], lr: 0.001771, loss: 0.6596
2022-07-23 14:10:11 - train: epoch 0095, iter [01600, 05004], lr: 0.001759, loss: 0.4775
2022-07-23 14:12:28 - train: epoch 0095, iter [01700, 05004], lr: 0.001747, loss: 0.6428
2022-07-23 14:14:45 - train: epoch 0095, iter [01800, 05004], lr: 0.001734, loss: 0.5587
2022-07-23 14:17:03 - train: epoch 0095, iter [01900, 05004], lr: 0.001722, loss: 0.6420
2022-07-23 14:19:20 - train: epoch 0095, iter [02000, 05004], lr: 0.001710, loss: 0.7409
2022-07-23 14:21:37 - train: epoch 0095, iter [02100, 05004], lr: 0.001698, loss: 0.6846
2022-07-23 14:23:55 - train: epoch 0095, iter [02200, 05004], lr: 0.001686, loss: 0.4983
2022-07-23 14:26:12 - train: epoch 0095, iter [02300, 05004], lr: 0.001674, loss: 0.6308
2022-07-23 14:28:29 - train: epoch 0095, iter [02400, 05004], lr: 0.001662, loss: 0.5266
2022-07-23 14:30:46 - train: epoch 0095, iter [02500, 05004], lr: 0.001650, loss: 0.5244
2022-07-23 14:33:03 - train: epoch 0095, iter [02600, 05004], lr: 0.001638, loss: 0.6391
2022-07-23 14:35:20 - train: epoch 0095, iter [02700, 05004], lr: 0.001626, loss: 0.6420
2022-07-23 14:37:37 - train: epoch 0095, iter [02800, 05004], lr: 0.001614, loss: 0.5603
2022-07-23 14:39:54 - train: epoch 0095, iter [02900, 05004], lr: 0.001602, loss: 0.6236
2022-07-23 14:42:10 - train: epoch 0095, iter [03000, 05004], lr: 0.001590, loss: 0.6683
2022-07-23 14:44:27 - train: epoch 0095, iter [03100, 05004], lr: 0.001579, loss: 0.5744
2022-07-23 14:46:44 - train: epoch 0095, iter [03200, 05004], lr: 0.001567, loss: 0.5331
2022-07-23 14:49:02 - train: epoch 0095, iter [03300, 05004], lr: 0.001555, loss: 0.7118
2022-07-23 14:51:19 - train: epoch 0095, iter [03400, 05004], lr: 0.001544, loss: 0.6105
2022-07-23 14:53:36 - train: epoch 0095, iter [03500, 05004], lr: 0.001532, loss: 0.6158
2022-07-23 14:55:53 - train: epoch 0095, iter [03600, 05004], lr: 0.001521, loss: 0.4806
2022-07-23 14:58:11 - train: epoch 0095, iter [03700, 05004], lr: 0.001509, loss: 0.6170
2022-07-23 15:00:28 - train: epoch 0095, iter [03800, 05004], lr: 0.001498, loss: 0.4419
2022-07-23 15:02:45 - train: epoch 0095, iter [03900, 05004], lr: 0.001487, loss: 0.5317
2022-07-23 15:05:02 - train: epoch 0095, iter [04000, 05004], lr: 0.001475, loss: 0.5533
2022-07-23 15:07:20 - train: epoch 0095, iter [04100, 05004], lr: 0.001464, loss: 0.6091
2022-07-23 15:09:37 - train: epoch 0095, iter [04200, 05004], lr: 0.001453, loss: 0.5357
2022-07-23 15:11:54 - train: epoch 0095, iter [04300, 05004], lr: 0.001442, loss: 0.7015
2022-07-23 15:14:12 - train: epoch 0095, iter [04400, 05004], lr: 0.001430, loss: 0.6212
2022-07-23 15:16:29 - train: epoch 0095, iter [04500, 05004], lr: 0.001419, loss: 0.5846
2022-07-23 15:18:46 - train: epoch 0095, iter [04600, 05004], lr: 0.001408, loss: 0.5637
2022-07-23 15:21:03 - train: epoch 0095, iter [04700, 05004], lr: 0.001397, loss: 0.5715
2022-07-23 15:23:20 - train: epoch 0095, iter [04800, 05004], lr: 0.001386, loss: 0.5605
2022-07-23 15:25:37 - train: epoch 0095, iter [04900, 05004], lr: 0.001375, loss: 0.6761
2022-07-23 15:27:54 - train: epoch 0095, iter [05000, 05004], lr: 0.001364, loss: 0.5840
2022-07-23 15:28:01 - train: epoch 095, train_loss: 0.5977
2022-07-23 15:30:15 - eval: epoch: 095, acc1: 77.650%, acc5: 93.738%, test_loss: 0.9341, per_image_load_time: 1.227ms, per_image_inference_time: 3.905ms
2022-07-23 15:30:15 - until epoch: 095, best_acc1: 77.650%
2022-07-23 15:30:15 - epoch 096 lr: 0.001364
2022-07-23 15:32:41 - train: epoch 0096, iter [00100, 05004], lr: 0.001353, loss: 0.5445
2022-07-23 15:34:59 - train: epoch 0096, iter [00200, 05004], lr: 0.001342, loss: 0.5814
2022-07-23 15:37:16 - train: epoch 0096, iter [00300, 05004], lr: 0.001331, loss: 0.5903
2022-07-23 15:39:34 - train: epoch 0096, iter [00400, 05004], lr: 0.001321, loss: 0.6012
2022-07-23 15:41:51 - train: epoch 0096, iter [00500, 05004], lr: 0.001310, loss: 0.6433
2022-07-23 15:44:09 - train: epoch 0096, iter [00600, 05004], lr: 0.001299, loss: 0.5975
2022-07-23 15:46:26 - train: epoch 0096, iter [00700, 05004], lr: 0.001289, loss: 0.4266
2022-07-23 15:48:44 - train: epoch 0096, iter [00800, 05004], lr: 0.001278, loss: 0.4730
2022-07-23 15:51:01 - train: epoch 0096, iter [00900, 05004], lr: 0.001268, loss: 0.5669
2022-07-23 15:53:19 - train: epoch 0096, iter [01000, 05004], lr: 0.001257, loss: 0.6273
2022-07-23 15:55:37 - train: epoch 0096, iter [01100, 05004], lr: 0.001247, loss: 0.7281
2022-07-23 15:57:54 - train: epoch 0096, iter [01200, 05004], lr: 0.001236, loss: 0.4922
2022-07-23 16:00:12 - train: epoch 0096, iter [01300, 05004], lr: 0.001226, loss: 0.7125
2022-07-23 16:02:30 - train: epoch 0096, iter [01400, 05004], lr: 0.001216, loss: 0.5987
2022-07-23 16:04:48 - train: epoch 0096, iter [01500, 05004], lr: 0.001206, loss: 0.6587
2022-07-23 16:07:06 - train: epoch 0096, iter [01600, 05004], lr: 0.001195, loss: 0.4587
2022-07-23 16:09:24 - train: epoch 0096, iter [01700, 05004], lr: 0.001185, loss: 0.5501
2022-07-23 16:11:41 - train: epoch 0096, iter [01800, 05004], lr: 0.001175, loss: 0.5290
2022-07-23 16:13:59 - train: epoch 0096, iter [01900, 05004], lr: 0.001165, loss: 0.6489
2022-07-23 16:16:17 - train: epoch 0096, iter [02000, 05004], lr: 0.001155, loss: 0.5453
2022-07-23 16:18:35 - train: epoch 0096, iter [02100, 05004], lr: 0.001145, loss: 0.7177
2022-07-23 16:20:53 - train: epoch 0096, iter [02200, 05004], lr: 0.001135, loss: 0.4866
2022-07-23 16:23:10 - train: epoch 0096, iter [02300, 05004], lr: 0.001125, loss: 0.5112
2022-07-23 16:25:28 - train: epoch 0096, iter [02400, 05004], lr: 0.001115, loss: 0.6177
2022-07-23 16:27:46 - train: epoch 0096, iter [02500, 05004], lr: 0.001105, loss: 0.6445
2022-07-23 16:30:03 - train: epoch 0096, iter [02600, 05004], lr: 0.001096, loss: 0.6340
2022-07-23 16:32:21 - train: epoch 0096, iter [02700, 05004], lr: 0.001086, loss: 0.6343
2022-07-23 16:34:38 - train: epoch 0096, iter [02800, 05004], lr: 0.001076, loss: 0.6901
2022-07-23 16:36:56 - train: epoch 0096, iter [02900, 05004], lr: 0.001067, loss: 0.6273
2022-07-23 16:39:13 - train: epoch 0096, iter [03000, 05004], lr: 0.001057, loss: 0.6030
2022-07-23 16:41:31 - train: epoch 0096, iter [03100, 05004], lr: 0.001047, loss: 0.6047
2022-07-23 16:43:49 - train: epoch 0096, iter [03200, 05004], lr: 0.001038, loss: 0.6533
2022-07-23 16:46:06 - train: epoch 0096, iter [03300, 05004], lr: 0.001028, loss: 0.6081
2022-07-23 16:48:24 - train: epoch 0096, iter [03400, 05004], lr: 0.001019, loss: 0.5046
2022-07-23 16:50:41 - train: epoch 0096, iter [03500, 05004], lr: 0.001010, loss: 0.4060
2022-07-23 16:52:59 - train: epoch 0096, iter [03600, 05004], lr: 0.001000, loss: 0.5045
2022-07-23 16:55:16 - train: epoch 0096, iter [03700, 05004], lr: 0.000991, loss: 0.5179
2022-07-23 16:57:34 - train: epoch 0096, iter [03800, 05004], lr: 0.000982, loss: 0.6226
2022-07-23 16:59:51 - train: epoch 0096, iter [03900, 05004], lr: 0.000972, loss: 0.6208
2022-07-23 17:02:09 - train: epoch 0096, iter [04000, 05004], lr: 0.000963, loss: 0.5228
2022-07-23 17:04:27 - train: epoch 0096, iter [04100, 05004], lr: 0.000954, loss: 0.5873
2022-07-23 17:06:44 - train: epoch 0096, iter [04200, 05004], lr: 0.000945, loss: 0.5491
2022-07-23 17:09:02 - train: epoch 0096, iter [04300, 05004], lr: 0.000936, loss: 0.5597
2022-07-23 17:11:20 - train: epoch 0096, iter [04400, 05004], lr: 0.000927, loss: 0.6730
2022-07-23 17:13:38 - train: epoch 0096, iter [04500, 05004], lr: 0.000918, loss: 0.6468
2022-07-23 17:15:56 - train: epoch 0096, iter [04600, 05004], lr: 0.000909, loss: 0.6240
2022-07-23 17:18:13 - train: epoch 0096, iter [04700, 05004], lr: 0.000900, loss: 0.4996
2022-07-23 17:20:31 - train: epoch 0096, iter [04800, 05004], lr: 0.000891, loss: 0.7347
2022-07-23 17:22:49 - train: epoch 0096, iter [04900, 05004], lr: 0.000883, loss: 0.5818
2022-07-23 17:25:06 - train: epoch 0096, iter [05000, 05004], lr: 0.000874, loss: 0.5891
2022-07-23 17:25:13 - train: epoch 096, train_loss: 0.5880
2022-07-23 17:27:14 - eval: epoch: 096, acc1: 77.650%, acc5: 93.788%, test_loss: 0.9337, per_image_load_time: 0.821ms, per_image_inference_time: 3.884ms
2022-07-23 17:27:14 - until epoch: 096, best_acc1: 77.650%
2022-07-23 17:27:14 - epoch 097 lr: 0.000874
2022-07-23 17:29:40 - train: epoch 0097, iter [00100, 05004], lr: 0.000865, loss: 0.4625
2022-07-23 17:31:57 - train: epoch 0097, iter [00200, 05004], lr: 0.000856, loss: 0.6372
2022-07-23 17:34:14 - train: epoch 0097, iter [00300, 05004], lr: 0.000848, loss: 0.5850
2022-07-23 17:36:31 - train: epoch 0097, iter [00400, 05004], lr: 0.000839, loss: 0.6955
2022-07-23 17:38:49 - train: epoch 0097, iter [00500, 05004], lr: 0.000831, loss: 0.5700
2022-07-23 17:41:06 - train: epoch 0097, iter [00600, 05004], lr: 0.000822, loss: 0.5390
2022-07-23 17:43:23 - train: epoch 0097, iter [00700, 05004], lr: 0.000814, loss: 0.4943
2022-07-23 17:45:40 - train: epoch 0097, iter [00800, 05004], lr: 0.000805, loss: 0.4417
2022-07-23 17:47:57 - train: epoch 0097, iter [00900, 05004], lr: 0.000797, loss: 0.5565
2022-07-23 17:50:14 - train: epoch 0097, iter [01000, 05004], lr: 0.000789, loss: 0.5300
2022-07-23 17:52:31 - train: epoch 0097, iter [01100, 05004], lr: 0.000780, loss: 0.4457
2022-07-23 17:54:49 - train: epoch 0097, iter [01200, 05004], lr: 0.000772, loss: 0.7425
2022-07-23 17:57:06 - train: epoch 0097, iter [01300, 05004], lr: 0.000764, loss: 0.5190
2022-07-23 17:59:23 - train: epoch 0097, iter [01400, 05004], lr: 0.000756, loss: 0.6246
2022-07-23 18:01:40 - train: epoch 0097, iter [01500, 05004], lr: 0.000748, loss: 0.6402
2022-07-23 18:03:58 - train: epoch 0097, iter [01600, 05004], lr: 0.000740, loss: 0.4378
2022-07-23 18:06:15 - train: epoch 0097, iter [01700, 05004], lr: 0.000732, loss: 0.5323
2022-07-23 18:08:32 - train: epoch 0097, iter [01800, 05004], lr: 0.000724, loss: 0.6453
2022-07-23 18:10:50 - train: epoch 0097, iter [01900, 05004], lr: 0.000716, loss: 0.5682
2022-07-23 18:13:07 - train: epoch 0097, iter [02000, 05004], lr: 0.000708, loss: 0.5242
2022-07-23 18:15:25 - train: epoch 0097, iter [02100, 05004], lr: 0.000700, loss: 0.5984
2022-07-23 18:17:42 - train: epoch 0097, iter [02200, 05004], lr: 0.000692, loss: 0.5536
2022-07-23 18:20:00 - train: epoch 0097, iter [02300, 05004], lr: 0.000685, loss: 0.5452
2022-07-23 18:22:17 - train: epoch 0097, iter [02400, 05004], lr: 0.000677, loss: 0.5568
2022-07-23 18:24:34 - train: epoch 0097, iter [02500, 05004], lr: 0.000669, loss: 0.4760
2022-07-23 18:26:52 - train: epoch 0097, iter [02600, 05004], lr: 0.000662, loss: 0.6780
2022-07-23 18:29:09 - train: epoch 0097, iter [02700, 05004], lr: 0.000654, loss: 0.5442
2022-07-23 18:31:27 - train: epoch 0097, iter [02800, 05004], lr: 0.000647, loss: 0.6096
2022-07-23 18:33:45 - train: epoch 0097, iter [02900, 05004], lr: 0.000639, loss: 0.5563
2022-07-23 18:36:02 - train: epoch 0097, iter [03000, 05004], lr: 0.000632, loss: 0.5571
2022-07-23 18:38:20 - train: epoch 0097, iter [03100, 05004], lr: 0.000624, loss: 0.6144
2022-07-23 18:40:37 - train: epoch 0097, iter [03200, 05004], lr: 0.000617, loss: 0.7775
2022-07-23 18:42:55 - train: epoch 0097, iter [03300, 05004], lr: 0.000610, loss: 0.5171
2022-07-23 18:45:13 - train: epoch 0097, iter [03400, 05004], lr: 0.000602, loss: 0.5556
2022-07-23 18:47:30 - train: epoch 0097, iter [03500, 05004], lr: 0.000595, loss: 0.5442
2022-07-23 18:49:48 - train: epoch 0097, iter [03600, 05004], lr: 0.000588, loss: 0.4597
2022-07-23 18:52:06 - train: epoch 0097, iter [03700, 05004], lr: 0.000581, loss: 0.4692
2022-07-23 18:54:23 - train: epoch 0097, iter [03800, 05004], lr: 0.000574, loss: 0.5660
2022-07-23 18:56:41 - train: epoch 0097, iter [03900, 05004], lr: 0.000567, loss: 0.4909
2022-07-23 18:58:59 - train: epoch 0097, iter [04000, 05004], lr: 0.000560, loss: 0.4811
2022-07-23 19:01:16 - train: epoch 0097, iter [04100, 05004], lr: 0.000553, loss: 0.6326
2022-07-23 19:03:34 - train: epoch 0097, iter [04200, 05004], lr: 0.000546, loss: 0.5147
2022-07-23 19:05:52 - train: epoch 0097, iter [04300, 05004], lr: 0.000539, loss: 0.6228
2022-07-23 19:08:09 - train: epoch 0097, iter [04400, 05004], lr: 0.000532, loss: 0.6437
2022-07-23 19:10:27 - train: epoch 0097, iter [04500, 05004], lr: 0.000525, loss: 0.5523
2022-07-23 19:12:44 - train: epoch 0097, iter [04600, 05004], lr: 0.000519, loss: 0.5634
2022-07-23 19:15:02 - train: epoch 0097, iter [04700, 05004], lr: 0.000512, loss: 0.5342
2022-07-23 19:17:19 - train: epoch 0097, iter [04800, 05004], lr: 0.000505, loss: 0.5015
2022-07-23 19:19:37 - train: epoch 0097, iter [04900, 05004], lr: 0.000499, loss: 0.7436
2022-07-23 19:21:55 - train: epoch 0097, iter [05000, 05004], lr: 0.000492, loss: 0.5154
2022-07-23 19:22:01 - train: epoch 097, train_loss: 0.5806
2022-07-23 19:24:14 - eval: epoch: 097, acc1: 77.698%, acc5: 93.838%, test_loss: 0.9309, per_image_load_time: 1.049ms, per_image_inference_time: 3.903ms
2022-07-23 19:24:14 - until epoch: 097, best_acc1: 77.698%
2022-07-23 19:24:14 - epoch 098 lr: 0.000492
2022-07-23 19:26:39 - train: epoch 0098, iter [00100, 05004], lr: 0.000485, loss: 0.6865
2022-07-23 19:28:56 - train: epoch 0098, iter [00200, 05004], lr: 0.000479, loss: 0.5522
2022-07-23 19:31:13 - train: epoch 0098, iter [00300, 05004], lr: 0.000472, loss: 0.7173
2022-07-23 19:33:30 - train: epoch 0098, iter [00400, 05004], lr: 0.000466, loss: 0.4412
2022-07-23 19:35:47 - train: epoch 0098, iter [00500, 05004], lr: 0.000460, loss: 0.5847
2022-07-23 19:38:04 - train: epoch 0098, iter [00600, 05004], lr: 0.000453, loss: 0.4942
2022-07-23 19:40:21 - train: epoch 0098, iter [00700, 05004], lr: 0.000447, loss: 0.6056
2022-07-23 19:42:37 - train: epoch 0098, iter [00800, 05004], lr: 0.000441, loss: 0.6367
2022-07-23 19:44:54 - train: epoch 0098, iter [00900, 05004], lr: 0.000435, loss: 0.6696
2022-07-23 19:47:11 - train: epoch 0098, iter [01000, 05004], lr: 0.000428, loss: 0.4962
2022-07-23 19:49:29 - train: epoch 0098, iter [01100, 05004], lr: 0.000422, loss: 0.5353
2022-07-23 19:51:46 - train: epoch 0098, iter [01200, 05004], lr: 0.000416, loss: 0.6268
2022-07-23 19:54:03 - train: epoch 0098, iter [01300, 05004], lr: 0.000410, loss: 0.5287
2022-07-23 19:56:21 - train: epoch 0098, iter [01400, 05004], lr: 0.000404, loss: 0.5784
2022-07-23 19:58:38 - train: epoch 0098, iter [01500, 05004], lr: 0.000398, loss: 0.6164
2022-07-23 20:00:56 - train: epoch 0098, iter [01600, 05004], lr: 0.000393, loss: 0.6864
2022-07-23 20:03:13 - train: epoch 0098, iter [01700, 05004], lr: 0.000387, loss: 0.7137
2022-07-23 20:05:30 - train: epoch 0098, iter [01800, 05004], lr: 0.000381, loss: 0.5451
2022-07-23 20:07:47 - train: epoch 0098, iter [01900, 05004], lr: 0.000375, loss: 0.5579
2022-07-23 20:10:04 - train: epoch 0098, iter [02000, 05004], lr: 0.000369, loss: 0.6891
2022-07-23 20:12:21 - train: epoch 0098, iter [02100, 05004], lr: 0.000364, loss: 0.6361
2022-07-23 20:14:38 - train: epoch 0098, iter [02200, 05004], lr: 0.000358, loss: 0.5848
2022-07-23 20:16:55 - train: epoch 0098, iter [02300, 05004], lr: 0.000353, loss: 0.6189
2022-07-23 20:19:13 - train: epoch 0098, iter [02400, 05004], lr: 0.000347, loss: 0.4814
2022-07-23 20:21:30 - train: epoch 0098, iter [02500, 05004], lr: 0.000342, loss: 0.5730
2022-07-23 20:23:47 - train: epoch 0098, iter [02600, 05004], lr: 0.000336, loss: 0.5851
2022-07-23 20:26:04 - train: epoch 0098, iter [02700, 05004], lr: 0.000331, loss: 0.6250
2022-07-23 20:28:21 - train: epoch 0098, iter [02800, 05004], lr: 0.000325, loss: 0.6814
2022-07-23 20:30:38 - train: epoch 0098, iter [02900, 05004], lr: 0.000320, loss: 0.4591
2022-07-23 20:32:55 - train: epoch 0098, iter [03000, 05004], lr: 0.000315, loss: 0.6361
2022-07-23 20:35:12 - train: epoch 0098, iter [03100, 05004], lr: 0.000310, loss: 0.5925
2022-07-23 20:37:29 - train: epoch 0098, iter [03200, 05004], lr: 0.000305, loss: 0.5810
2022-07-23 20:39:46 - train: epoch 0098, iter [03300, 05004], lr: 0.000299, loss: 0.5171
2022-07-23 20:42:03 - train: epoch 0098, iter [03400, 05004], lr: 0.000294, loss: 0.5283
2022-07-23 20:44:20 - train: epoch 0098, iter [03500, 05004], lr: 0.000289, loss: 0.6263
2022-07-23 20:46:37 - train: epoch 0098, iter [03600, 05004], lr: 0.000284, loss: 0.6728
2022-07-23 20:48:54 - train: epoch 0098, iter [03700, 05004], lr: 0.000279, loss: 0.6429
2022-07-23 20:51:11 - train: epoch 0098, iter [03800, 05004], lr: 0.000274, loss: 0.5414
2022-07-23 20:53:28 - train: epoch 0098, iter [03900, 05004], lr: 0.000270, loss: 0.4677
2022-07-23 20:55:45 - train: epoch 0098, iter [04000, 05004], lr: 0.000265, loss: 0.6372
2022-07-23 20:58:02 - train: epoch 0098, iter [04100, 05004], lr: 0.000260, loss: 0.5245
2022-07-23 21:00:19 - train: epoch 0098, iter [04200, 05004], lr: 0.000255, loss: 0.4873
2022-07-23 21:02:36 - train: epoch 0098, iter [04300, 05004], lr: 0.000250, loss: 0.6415
2022-07-23 21:04:53 - train: epoch 0098, iter [04400, 05004], lr: 0.000246, loss: 0.6712
2022-07-23 21:07:11 - train: epoch 0098, iter [04500, 05004], lr: 0.000241, loss: 0.6646
2022-07-23 21:09:28 - train: epoch 0098, iter [04600, 05004], lr: 0.000237, loss: 0.5789
2022-07-23 21:11:45 - train: epoch 0098, iter [04700, 05004], lr: 0.000232, loss: 0.5461
2022-07-23 21:14:02 - train: epoch 0098, iter [04800, 05004], lr: 0.000228, loss: 0.5094
2022-07-23 21:16:19 - train: epoch 0098, iter [04900, 05004], lr: 0.000223, loss: 0.6231
2022-07-23 21:18:37 - train: epoch 0098, iter [05000, 05004], lr: 0.000219, loss: 0.6237
2022-07-23 21:18:43 - train: epoch 098, train_loss: 0.5729
2022-07-23 21:20:49 - eval: epoch: 098, acc1: 77.714%, acc5: 93.822%, test_loss: 0.9328, per_image_load_time: 0.987ms, per_image_inference_time: 3.902ms
2022-07-23 21:20:49 - until epoch: 098, best_acc1: 77.714%
2022-07-23 21:20:49 - epoch 099 lr: 0.000219
2022-07-23 21:23:15 - train: epoch 0099, iter [00100, 05004], lr: 0.000214, loss: 0.6295
2022-07-23 21:25:31 - train: epoch 0099, iter [00200, 05004], lr: 0.000210, loss: 0.6078
2022-07-23 21:27:48 - train: epoch 0099, iter [00300, 05004], lr: 0.000206, loss: 0.6083
2022-07-23 21:30:05 - train: epoch 0099, iter [00400, 05004], lr: 0.000202, loss: 0.4861
2022-07-23 21:32:22 - train: epoch 0099, iter [00500, 05004], lr: 0.000197, loss: 0.5654
2022-07-23 21:34:39 - train: epoch 0099, iter [00600, 05004], lr: 0.000193, loss: 0.5870
2022-07-23 21:36:56 - train: epoch 0099, iter [00700, 05004], lr: 0.000189, loss: 0.5492
2022-07-23 21:39:13 - train: epoch 0099, iter [00800, 05004], lr: 0.000185, loss: 0.7172
2022-07-23 21:41:30 - train: epoch 0099, iter [00900, 05004], lr: 0.000181, loss: 0.5811
2022-07-23 21:43:47 - train: epoch 0099, iter [01000, 05004], lr: 0.000177, loss: 0.5961
2022-07-23 21:46:04 - train: epoch 0099, iter [01100, 05004], lr: 0.000173, loss: 0.7110
2022-07-23 21:48:21 - train: epoch 0099, iter [01200, 05004], lr: 0.000169, loss: 0.6180
2022-07-23 21:50:38 - train: epoch 0099, iter [01300, 05004], lr: 0.000166, loss: 0.4816
2022-07-23 21:52:55 - train: epoch 0099, iter [01400, 05004], lr: 0.000162, loss: 0.5949
2022-07-23 21:55:12 - train: epoch 0099, iter [01500, 05004], lr: 0.000158, loss: 0.5692
2022-07-23 21:57:29 - train: epoch 0099, iter [01600, 05004], lr: 0.000154, loss: 0.6379
2022-07-23 21:59:46 - train: epoch 0099, iter [01700, 05004], lr: 0.000151, loss: 0.5187
2022-07-23 22:02:03 - train: epoch 0099, iter [01800, 05004], lr: 0.000147, loss: 0.5135
2022-07-23 22:04:20 - train: epoch 0099, iter [01900, 05004], lr: 0.000144, loss: 0.6935
2022-07-23 22:06:37 - train: epoch 0099, iter [02000, 05004], lr: 0.000140, loss: 0.5061
2022-07-23 22:08:54 - train: epoch 0099, iter [02100, 05004], lr: 0.000137, loss: 0.5693
2022-07-23 22:11:11 - train: epoch 0099, iter [02200, 05004], lr: 0.000133, loss: 0.4765
2022-07-23 22:13:28 - train: epoch 0099, iter [02300, 05004], lr: 0.000130, loss: 0.6834
2022-07-23 22:15:45 - train: epoch 0099, iter [02400, 05004], lr: 0.000126, loss: 0.6394
2022-07-23 22:18:03 - train: epoch 0099, iter [02500, 05004], lr: 0.000123, loss: 0.5559
2022-07-23 22:20:20 - train: epoch 0099, iter [02600, 05004], lr: 0.000120, loss: 0.6703
2022-07-23 22:22:37 - train: epoch 0099, iter [02700, 05004], lr: 0.000117, loss: 0.6360
2022-07-23 22:24:54 - train: epoch 0099, iter [02800, 05004], lr: 0.000113, loss: 0.7010
2022-07-23 22:27:11 - train: epoch 0099, iter [02900, 05004], lr: 0.000110, loss: 0.5235
2022-07-23 22:29:28 - train: epoch 0099, iter [03000, 05004], lr: 0.000107, loss: 0.6203
2022-07-23 22:31:45 - train: epoch 0099, iter [03100, 05004], lr: 0.000104, loss: 0.5984
2022-07-23 22:34:02 - train: epoch 0099, iter [03200, 05004], lr: 0.000101, loss: 0.5328
2022-07-23 22:36:19 - train: epoch 0099, iter [03300, 05004], lr: 0.000098, loss: 0.4204
2022-07-23 22:38:36 - train: epoch 0099, iter [03400, 05004], lr: 0.000095, loss: 0.6669
2022-07-23 22:40:53 - train: epoch 0099, iter [03500, 05004], lr: 0.000092, loss: 0.6619
2022-07-23 22:43:10 - train: epoch 0099, iter [03600, 05004], lr: 0.000090, loss: 0.5981
2022-07-23 22:45:27 - train: epoch 0099, iter [03700, 05004], lr: 0.000087, loss: 0.6605
2022-07-23 22:47:44 - train: epoch 0099, iter [03800, 05004], lr: 0.000084, loss: 0.6733
2022-07-23 22:50:01 - train: epoch 0099, iter [03900, 05004], lr: 0.000081, loss: 0.6242
2022-07-23 22:52:18 - train: epoch 0099, iter [04000, 05004], lr: 0.000079, loss: 0.6868
2022-07-23 22:54:35 - train: epoch 0099, iter [04100, 05004], lr: 0.000076, loss: 0.4999
2022-07-23 22:56:53 - train: epoch 0099, iter [04200, 05004], lr: 0.000074, loss: 0.4898
2022-07-23 22:59:10 - train: epoch 0099, iter [04300, 05004], lr: 0.000071, loss: 0.6335
2022-07-23 23:01:28 - train: epoch 0099, iter [04400, 05004], lr: 0.000069, loss: 0.7039
2022-07-23 23:03:46 - train: epoch 0099, iter [04500, 05004], lr: 0.000066, loss: 0.5840
2022-07-23 23:06:03 - train: epoch 0099, iter [04600, 05004], lr: 0.000064, loss: 0.5677
