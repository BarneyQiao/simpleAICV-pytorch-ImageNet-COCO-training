2022-07-19 23:05:48 - train: epoch 0050, iter [02400, 05004], lr: 0.109972, loss: 1.6329
2022-07-19 23:08:05 - train: epoch 0050, iter [02500, 05004], lr: 0.109906, loss: 1.3922
2022-07-19 23:10:22 - train: epoch 0050, iter [02600, 05004], lr: 0.109840, loss: 1.4797
2022-07-19 23:12:39 - train: epoch 0050, iter [02700, 05004], lr: 0.109774, loss: 1.8231
2022-07-19 23:14:56 - train: epoch 0050, iter [02800, 05004], lr: 0.109709, loss: 1.7075
2022-07-19 23:17:13 - train: epoch 0050, iter [02900, 05004], lr: 0.109643, loss: 1.7112
2022-07-19 23:19:30 - train: epoch 0050, iter [03000, 05004], lr: 0.109577, loss: 1.6258
2022-07-19 23:21:47 - train: epoch 0050, iter [03100, 05004], lr: 0.109511, loss: 1.4639
2022-07-19 23:24:04 - train: epoch 0050, iter [03200, 05004], lr: 0.109445, loss: 1.5355
2022-07-19 23:26:22 - train: epoch 0050, iter [03300, 05004], lr: 0.109380, loss: 1.4000
2022-07-19 23:28:39 - train: epoch 0050, iter [03400, 05004], lr: 0.109314, loss: 1.4577
2022-07-19 23:30:56 - train: epoch 0050, iter [03500, 05004], lr: 0.109248, loss: 1.4486
2022-07-19 23:33:13 - train: epoch 0050, iter [03600, 05004], lr: 0.109182, loss: 1.5013
2022-07-19 23:35:30 - train: epoch 0050, iter [03700, 05004], lr: 0.109116, loss: 1.9701
2022-07-19 23:37:47 - train: epoch 0050, iter [03800, 05004], lr: 0.109051, loss: 1.5834
2022-07-19 23:40:04 - train: epoch 0050, iter [03900, 05004], lr: 0.108985, loss: 1.3844
2022-07-19 23:42:22 - train: epoch 0050, iter [04000, 05004], lr: 0.108919, loss: 1.6139
2022-07-19 23:44:39 - train: epoch 0050, iter [04100, 05004], lr: 0.108853, loss: 1.6542
2022-07-19 23:46:56 - train: epoch 0050, iter [04200, 05004], lr: 0.108787, loss: 1.7017
2022-07-19 23:49:13 - train: epoch 0050, iter [04300, 05004], lr: 0.108721, loss: 1.5603
2022-07-19 23:51:30 - train: epoch 0050, iter [04400, 05004], lr: 0.108656, loss: 1.5578
2022-07-19 23:53:47 - train: epoch 0050, iter [04500, 05004], lr: 0.108590, loss: 1.7042
2022-07-19 23:56:04 - train: epoch 0050, iter [04600, 05004], lr: 0.108524, loss: 1.6181
2022-07-19 23:58:21 - train: epoch 0050, iter [04700, 05004], lr: 0.108458, loss: 1.6568
2022-07-20 00:00:37 - train: epoch 0050, iter [04800, 05004], lr: 0.108392, loss: 1.6604
2022-07-20 00:02:54 - train: epoch 0050, iter [04900, 05004], lr: 0.108326, loss: 1.4904
2022-07-20 00:05:11 - train: epoch 0050, iter [05000, 05004], lr: 0.108261, loss: 1.6939
2022-07-20 00:05:18 - train: epoch 050, train_loss: 1.5307
2022-07-20 00:07:22 - eval: epoch: 050, acc1: 67.424%, acc5: 88.580%, test_loss: 1.3332, per_image_load_time: 0.965ms, per_image_inference_time: 3.903ms
2022-07-20 00:07:22 - until epoch: 050, best_acc1: 67.470%
2022-07-20 00:07:22 - epoch 051 lr: 0.108257
2022-07-20 00:09:46 - train: epoch 0051, iter [00100, 05004], lr: 0.108192, loss: 1.7316
2022-07-20 00:12:03 - train: epoch 0051, iter [00200, 05004], lr: 0.108126, loss: 1.7098
2022-07-20 00:14:20 - train: epoch 0051, iter [00300, 05004], lr: 0.108060, loss: 1.4185
2022-07-20 00:16:36 - train: epoch 0051, iter [00400, 05004], lr: 0.107994, loss: 1.3810
2022-07-20 00:18:53 - train: epoch 0051, iter [00500, 05004], lr: 0.107929, loss: 1.4781
2022-07-20 00:21:10 - train: epoch 0051, iter [00600, 05004], lr: 0.107863, loss: 1.3103
2022-07-20 00:23:27 - train: epoch 0051, iter [00700, 05004], lr: 0.107797, loss: 1.4854
2022-07-20 00:25:44 - train: epoch 0051, iter [00800, 05004], lr: 0.107731, loss: 1.5544
2022-07-20 00:28:01 - train: epoch 0051, iter [00900, 05004], lr: 0.107665, loss: 1.4959
2022-07-20 00:30:18 - train: epoch 0051, iter [01000, 05004], lr: 0.107599, loss: 1.7989
2022-07-20 00:32:35 - train: epoch 0051, iter [01100, 05004], lr: 0.107533, loss: 1.6860
2022-07-20 00:34:52 - train: epoch 0051, iter [01200, 05004], lr: 0.107467, loss: 1.3841
2022-07-20 00:37:08 - train: epoch 0051, iter [01300, 05004], lr: 0.107401, loss: 1.3016
2022-07-20 00:39:25 - train: epoch 0051, iter [01400, 05004], lr: 0.107336, loss: 1.4412
2022-07-20 00:41:42 - train: epoch 0051, iter [01500, 05004], lr: 0.107270, loss: 1.5703
2022-07-20 00:43:59 - train: epoch 0051, iter [01600, 05004], lr: 0.107204, loss: 1.2892
2022-07-20 00:46:16 - train: epoch 0051, iter [01700, 05004], lr: 0.107138, loss: 1.5119
2022-07-20 00:48:33 - train: epoch 0051, iter [01800, 05004], lr: 0.107072, loss: 1.7175
2022-07-20 00:50:50 - train: epoch 0051, iter [01900, 05004], lr: 0.107006, loss: 1.3683
2022-07-20 00:53:07 - train: epoch 0051, iter [02000, 05004], lr: 0.106940, loss: 1.3414
2022-07-20 00:55:24 - train: epoch 0051, iter [02100, 05004], lr: 0.106874, loss: 1.3903
2022-07-20 00:57:41 - train: epoch 0051, iter [02200, 05004], lr: 0.106808, loss: 1.4319
2022-07-20 00:59:58 - train: epoch 0051, iter [02300, 05004], lr: 0.106742, loss: 1.5241
2022-07-20 01:02:15 - train: epoch 0051, iter [02400, 05004], lr: 0.106676, loss: 1.4706
2022-07-20 01:04:32 - train: epoch 0051, iter [02500, 05004], lr: 0.106610, loss: 1.5354
2022-07-20 01:06:49 - train: epoch 0051, iter [02600, 05004], lr: 0.106544, loss: 1.5256
2022-07-20 01:09:06 - train: epoch 0051, iter [02700, 05004], lr: 0.106478, loss: 1.3400
2022-07-20 01:11:23 - train: epoch 0051, iter [02800, 05004], lr: 0.106413, loss: 1.3210
2022-07-20 01:13:40 - train: epoch 0051, iter [02900, 05004], lr: 0.106347, loss: 1.4910
2022-07-20 01:15:57 - train: epoch 0051, iter [03000, 05004], lr: 0.106281, loss: 1.2359
2022-07-20 01:18:14 - train: epoch 0051, iter [03100, 05004], lr: 0.106215, loss: 1.4247
2022-07-20 01:20:31 - train: epoch 0051, iter [03200, 05004], lr: 0.106149, loss: 1.6537
2022-07-20 01:22:48 - train: epoch 0051, iter [03300, 05004], lr: 0.106083, loss: 1.6513
2022-07-20 01:25:05 - train: epoch 0051, iter [03400, 05004], lr: 0.106017, loss: 1.5150
2022-07-20 01:27:22 - train: epoch 0051, iter [03500, 05004], lr: 0.105951, loss: 1.6132
2022-07-20 01:29:38 - train: epoch 0051, iter [03600, 05004], lr: 0.105885, loss: 1.6262
2022-07-20 01:31:55 - train: epoch 0051, iter [03700, 05004], lr: 0.105819, loss: 1.6353
2022-07-20 01:34:12 - train: epoch 0051, iter [03800, 05004], lr: 0.105753, loss: 1.6931
2022-07-20 01:36:29 - train: epoch 0051, iter [03900, 05004], lr: 0.105687, loss: 1.5064
2022-07-20 01:38:46 - train: epoch 0051, iter [04000, 05004], lr: 0.105621, loss: 1.6454
2022-07-20 01:41:03 - train: epoch 0051, iter [04100, 05004], lr: 0.105555, loss: 1.4812
2022-07-20 01:43:20 - train: epoch 0051, iter [04200, 05004], lr: 0.105489, loss: 1.4992
2022-07-20 01:45:37 - train: epoch 0051, iter [04300, 05004], lr: 0.105423, loss: 1.3480
2022-07-20 01:47:54 - train: epoch 0051, iter [04400, 05004], lr: 0.105357, loss: 1.7331
2022-07-20 01:50:11 - train: epoch 0051, iter [04500, 05004], lr: 0.105291, loss: 1.3554
2022-07-20 01:52:28 - train: epoch 0051, iter [04600, 05004], lr: 0.105225, loss: 1.7182
2022-07-20 01:54:45 - train: epoch 0051, iter [04700, 05004], lr: 0.105159, loss: 1.4323
2022-07-20 01:57:02 - train: epoch 0051, iter [04800, 05004], lr: 0.105093, loss: 1.5960
2022-07-20 01:59:19 - train: epoch 0051, iter [04900, 05004], lr: 0.105027, loss: 1.4705
2022-07-20 02:01:36 - train: epoch 0051, iter [05000, 05004], lr: 0.104961, loss: 1.5592
2022-07-20 02:01:43 - train: epoch 051, train_loss: 1.5183
2022-07-20 02:03:47 - eval: epoch: 051, acc1: 67.764%, acc5: 88.792%, test_loss: 1.3116, per_image_load_time: 0.948ms, per_image_inference_time: 3.906ms
2022-07-20 02:03:48 - until epoch: 051, best_acc1: 67.764%
2022-07-20 02:03:48 - epoch 052 lr: 0.104958
2022-07-20 02:06:12 - train: epoch 0052, iter [00100, 05004], lr: 0.104892, loss: 1.3881
2022-07-20 02:08:29 - train: epoch 0052, iter [00200, 05004], lr: 0.104826, loss: 1.5678
2022-07-20 02:10:46 - train: epoch 0052, iter [00300, 05004], lr: 0.104760, loss: 1.3026
2022-07-20 02:13:03 - train: epoch 0052, iter [00400, 05004], lr: 0.104694, loss: 1.4214
2022-07-20 02:15:20 - train: epoch 0052, iter [00500, 05004], lr: 0.104628, loss: 1.5844
2022-07-20 02:17:36 - train: epoch 0052, iter [00600, 05004], lr: 0.104562, loss: 1.2746
2022-07-20 02:19:54 - train: epoch 0052, iter [00700, 05004], lr: 0.104496, loss: 1.5989
2022-07-20 02:22:10 - train: epoch 0052, iter [00800, 05004], lr: 0.104430, loss: 1.5265
2022-07-20 02:24:27 - train: epoch 0052, iter [00900, 05004], lr: 0.104364, loss: 1.4970
2022-07-20 02:26:44 - train: epoch 0052, iter [01000, 05004], lr: 0.104298, loss: 1.6573
2022-07-20 02:29:01 - train: epoch 0052, iter [01100, 05004], lr: 0.104232, loss: 1.5882
2022-07-20 02:31:18 - train: epoch 0052, iter [01200, 05004], lr: 0.104166, loss: 1.4532
2022-07-20 02:33:35 - train: epoch 0052, iter [01300, 05004], lr: 0.104100, loss: 1.4691
2022-07-20 02:35:52 - train: epoch 0052, iter [01400, 05004], lr: 0.104034, loss: 1.7888
2022-07-20 02:38:09 - train: epoch 0052, iter [01500, 05004], lr: 0.103968, loss: 1.4016
2022-07-20 02:40:26 - train: epoch 0052, iter [01600, 05004], lr: 0.103902, loss: 1.2436
2022-07-20 02:42:43 - train: epoch 0052, iter [01700, 05004], lr: 0.103836, loss: 1.4966
2022-07-20 02:44:59 - train: epoch 0052, iter [01800, 05004], lr: 0.103770, loss: 1.4657
2022-07-20 02:47:16 - train: epoch 0052, iter [01900, 05004], lr: 0.103704, loss: 1.3959
2022-07-20 02:49:33 - train: epoch 0052, iter [02000, 05004], lr: 0.103638, loss: 1.6300
2022-07-20 02:51:50 - train: epoch 0052, iter [02100, 05004], lr: 0.103572, loss: 1.4131
2022-07-20 02:54:07 - train: epoch 0052, iter [02200, 05004], lr: 0.103506, loss: 1.4598
2022-07-20 02:56:24 - train: epoch 0052, iter [02300, 05004], lr: 0.103440, loss: 1.3696
2022-07-20 02:58:41 - train: epoch 0052, iter [02400, 05004], lr: 0.103374, loss: 1.4140
2022-07-20 03:00:58 - train: epoch 0052, iter [02500, 05004], lr: 0.103308, loss: 1.3393
2022-07-20 03:03:15 - train: epoch 0052, iter [02600, 05004], lr: 0.103242, loss: 1.4702
2022-07-20 03:05:32 - train: epoch 0052, iter [02700, 05004], lr: 0.103176, loss: 1.6045
2022-07-20 03:07:49 - train: epoch 0052, iter [02800, 05004], lr: 0.103110, loss: 1.4990
2022-07-20 03:10:06 - train: epoch 0052, iter [02900, 05004], lr: 0.103043, loss: 1.4339
2022-07-20 03:12:23 - train: epoch 0052, iter [03000, 05004], lr: 0.102977, loss: 1.3950
2022-07-20 03:14:40 - train: epoch 0052, iter [03100, 05004], lr: 0.102911, loss: 1.6390
2022-07-20 03:16:57 - train: epoch 0052, iter [03200, 05004], lr: 0.102845, loss: 1.5906
2022-07-20 03:19:14 - train: epoch 0052, iter [03300, 05004], lr: 0.102779, loss: 1.4074
2022-07-20 03:21:31 - train: epoch 0052, iter [03400, 05004], lr: 0.102713, loss: 1.5141
2022-07-20 03:23:48 - train: epoch 0052, iter [03500, 05004], lr: 0.102647, loss: 1.6752
2022-07-20 03:26:05 - train: epoch 0052, iter [03600, 05004], lr: 0.102581, loss: 1.6992
2022-07-20 03:28:22 - train: epoch 0052, iter [03700, 05004], lr: 0.102515, loss: 1.6563
2022-07-20 03:30:39 - train: epoch 0052, iter [03800, 05004], lr: 0.102449, loss: 1.4058
2022-07-20 03:32:56 - train: epoch 0052, iter [03900, 05004], lr: 0.102383, loss: 1.5189
2022-07-20 03:35:14 - train: epoch 0052, iter [04000, 05004], lr: 0.102317, loss: 1.6321
2022-07-20 03:37:31 - train: epoch 0052, iter [04100, 05004], lr: 0.102251, loss: 1.3234
2022-07-20 03:39:48 - train: epoch 0052, iter [04200, 05004], lr: 0.102185, loss: 1.5674
2022-07-20 03:42:05 - train: epoch 0052, iter [04300, 05004], lr: 0.102119, loss: 1.6290
2022-07-20 03:44:22 - train: epoch 0052, iter [04400, 05004], lr: 0.102052, loss: 1.5154
2022-07-20 03:46:39 - train: epoch 0052, iter [04500, 05004], lr: 0.101986, loss: 1.3864
2022-07-20 03:48:56 - train: epoch 0052, iter [04600, 05004], lr: 0.101920, loss: 1.5255
2022-07-20 03:51:13 - train: epoch 0052, iter [04700, 05004], lr: 0.101854, loss: 1.5819
2022-07-20 03:53:30 - train: epoch 0052, iter [04800, 05004], lr: 0.101788, loss: 1.3118
2022-07-20 03:55:47 - train: epoch 0052, iter [04900, 05004], lr: 0.101722, loss: 1.4884
2022-07-20 03:58:04 - train: epoch 0052, iter [05000, 05004], lr: 0.101656, loss: 1.4627
2022-07-20 03:58:10 - train: epoch 052, train_loss: 1.5023
2022-07-20 04:00:16 - eval: epoch: 052, acc1: 67.744%, acc5: 88.550%, test_loss: 1.3157, per_image_load_time: 0.881ms, per_image_inference_time: 3.908ms
2022-07-20 04:00:16 - until epoch: 052, best_acc1: 67.764%
2022-07-20 04:00:16 - epoch 053 lr: 0.101653
2022-07-20 04:02:41 - train: epoch 0053, iter [00100, 05004], lr: 0.101587, loss: 1.6016
2022-07-20 04:04:57 - train: epoch 0053, iter [00200, 05004], lr: 0.101521, loss: 1.4190
2022-07-20 04:07:14 - train: epoch 0053, iter [00300, 05004], lr: 0.101455, loss: 1.4314
2022-07-20 04:09:30 - train: epoch 0053, iter [00400, 05004], lr: 0.101389, loss: 1.5519
2022-07-20 04:11:47 - train: epoch 0053, iter [00500, 05004], lr: 0.101323, loss: 1.5402
2022-07-20 04:14:04 - train: epoch 0053, iter [00600, 05004], lr: 0.101257, loss: 1.2406
2022-07-20 04:16:21 - train: epoch 0053, iter [00700, 05004], lr: 0.101191, loss: 1.5300
2022-07-20 04:18:37 - train: epoch 0053, iter [00800, 05004], lr: 0.101125, loss: 1.6185
2022-07-20 04:20:54 - train: epoch 0053, iter [00900, 05004], lr: 0.101059, loss: 1.4288
2022-07-20 04:23:11 - train: epoch 0053, iter [01000, 05004], lr: 0.100993, loss: 1.5752
2022-07-20 04:25:28 - train: epoch 0053, iter [01100, 05004], lr: 0.100927, loss: 1.4742
2022-07-20 04:27:44 - train: epoch 0053, iter [01200, 05004], lr: 0.100860, loss: 1.3172
2022-07-20 04:30:01 - train: epoch 0053, iter [01300, 05004], lr: 0.100794, loss: 1.4933
2022-07-20 04:32:18 - train: epoch 0053, iter [01400, 05004], lr: 0.100728, loss: 1.7524
2022-07-20 04:34:34 - train: epoch 0053, iter [01500, 05004], lr: 0.100662, loss: 1.5284
2022-07-20 04:36:51 - train: epoch 0053, iter [01600, 05004], lr: 0.100596, loss: 1.5644
2022-07-20 04:39:08 - train: epoch 0053, iter [01700, 05004], lr: 0.100530, loss: 1.6130
2022-07-20 04:41:24 - train: epoch 0053, iter [01800, 05004], lr: 0.100464, loss: 1.6834
2022-07-20 04:43:41 - train: epoch 0053, iter [01900, 05004], lr: 0.100398, loss: 1.3855
2022-07-20 04:45:58 - train: epoch 0053, iter [02000, 05004], lr: 0.100332, loss: 1.6602
2022-07-20 04:48:15 - train: epoch 0053, iter [02100, 05004], lr: 0.100266, loss: 1.5576
2022-07-20 04:50:31 - train: epoch 0053, iter [02200, 05004], lr: 0.100200, loss: 1.4626
2022-07-20 04:52:48 - train: epoch 0053, iter [02300, 05004], lr: 0.100133, loss: 1.4723
2022-07-20 04:55:05 - train: epoch 0053, iter [02400, 05004], lr: 0.100067, loss: 1.3470
2022-07-20 04:57:22 - train: epoch 0053, iter [02500, 05004], lr: 0.100001, loss: 1.5717
2022-07-20 04:59:38 - train: epoch 0053, iter [02600, 05004], lr: 0.099935, loss: 1.7313
2022-07-20 05:01:55 - train: epoch 0053, iter [02700, 05004], lr: 0.099869, loss: 1.7097
2022-07-20 05:04:12 - train: epoch 0053, iter [02800, 05004], lr: 0.099803, loss: 1.5309
2022-07-20 05:06:28 - train: epoch 0053, iter [02900, 05004], lr: 0.099737, loss: 1.3251
2022-07-20 05:08:45 - train: epoch 0053, iter [03000, 05004], lr: 0.099671, loss: 1.4423
2022-07-20 05:11:02 - train: epoch 0053, iter [03100, 05004], lr: 0.099605, loss: 1.7548
2022-07-20 05:13:18 - train: epoch 0053, iter [03200, 05004], lr: 0.099539, loss: 1.6106
2022-07-20 05:15:35 - train: epoch 0053, iter [03300, 05004], lr: 0.099473, loss: 1.4291
2022-07-20 05:17:52 - train: epoch 0053, iter [03400, 05004], lr: 0.099407, loss: 1.5043
2022-07-20 05:20:09 - train: epoch 0053, iter [03500, 05004], lr: 0.099340, loss: 1.3803
2022-07-20 05:22:25 - train: epoch 0053, iter [03600, 05004], lr: 0.099274, loss: 1.6919
2022-07-20 05:24:42 - train: epoch 0053, iter [03700, 05004], lr: 0.099208, loss: 1.5487
2022-07-20 05:26:59 - train: epoch 0053, iter [03800, 05004], lr: 0.099142, loss: 1.5781
2022-07-20 05:29:16 - train: epoch 0053, iter [03900, 05004], lr: 0.099076, loss: 1.7082
2022-07-20 05:31:33 - train: epoch 0053, iter [04000, 05004], lr: 0.099010, loss: 1.4731
2022-07-20 05:33:49 - train: epoch 0053, iter [04100, 05004], lr: 0.098944, loss: 1.7213
2022-07-20 05:36:06 - train: epoch 0053, iter [04200, 05004], lr: 0.098878, loss: 1.6628
2022-07-20 05:38:23 - train: epoch 0053, iter [04300, 05004], lr: 0.098812, loss: 1.5299
2022-07-20 05:40:40 - train: epoch 0053, iter [04400, 05004], lr: 0.098746, loss: 1.6062
2022-07-20 05:42:57 - train: epoch 0053, iter [04500, 05004], lr: 0.098680, loss: 1.5434
2022-07-20 05:45:13 - train: epoch 0053, iter [04600, 05004], lr: 0.098614, loss: 1.4358
2022-07-20 05:47:30 - train: epoch 0053, iter [04700, 05004], lr: 0.098547, loss: 1.3779
2022-07-20 05:49:47 - train: epoch 0053, iter [04800, 05004], lr: 0.098481, loss: 1.8149
2022-07-20 05:52:04 - train: epoch 0053, iter [04900, 05004], lr: 0.098415, loss: 1.5396
2022-07-20 05:54:21 - train: epoch 0053, iter [05000, 05004], lr: 0.098349, loss: 1.4350
2022-07-20 05:54:27 - train: epoch 053, train_loss: 1.4883
2022-07-20 05:56:35 - eval: epoch: 053, acc1: 68.278%, acc5: 88.882%, test_loss: 1.2955, per_image_load_time: 1.045ms, per_image_inference_time: 3.913ms
2022-07-20 05:56:35 - until epoch: 053, best_acc1: 68.278%
2022-07-20 05:56:35 - epoch 054 lr: 0.098346
2022-07-20 05:59:01 - train: epoch 0054, iter [00100, 05004], lr: 0.098281, loss: 1.3532
2022-07-20 06:01:18 - train: epoch 0054, iter [00200, 05004], lr: 0.098214, loss: 1.5600
2022-07-20 06:03:35 - train: epoch 0054, iter [00300, 05004], lr: 0.098148, loss: 1.6008
2022-07-20 06:05:52 - train: epoch 0054, iter [00400, 05004], lr: 0.098082, loss: 1.4565
2022-07-20 06:08:09 - train: epoch 0054, iter [00500, 05004], lr: 0.098016, loss: 1.4793
2022-07-20 06:10:25 - train: epoch 0054, iter [00600, 05004], lr: 0.097950, loss: 1.3039
2022-07-20 06:12:42 - train: epoch 0054, iter [00700, 05004], lr: 0.097884, loss: 1.4560
2022-07-20 06:14:59 - train: epoch 0054, iter [00800, 05004], lr: 0.097818, loss: 1.5458
2022-07-20 06:17:16 - train: epoch 0054, iter [00900, 05004], lr: 0.097752, loss: 1.2557
2022-07-20 06:19:33 - train: epoch 0054, iter [01000, 05004], lr: 0.097686, loss: 1.3484
2022-07-20 06:21:49 - train: epoch 0054, iter [01100, 05004], lr: 0.097620, loss: 1.4135
2022-07-20 06:24:06 - train: epoch 0054, iter [01200, 05004], lr: 0.097554, loss: 1.5569
2022-07-20 06:26:23 - train: epoch 0054, iter [01300, 05004], lr: 0.097488, loss: 1.4347
2022-07-20 06:28:40 - train: epoch 0054, iter [01400, 05004], lr: 0.097422, loss: 1.6305
2022-07-20 06:30:57 - train: epoch 0054, iter [01500, 05004], lr: 0.097356, loss: 1.4699
2022-07-20 06:33:13 - train: epoch 0054, iter [01600, 05004], lr: 0.097289, loss: 1.3097
2022-07-20 06:35:30 - train: epoch 0054, iter [01700, 05004], lr: 0.097223, loss: 1.3431
2022-07-20 06:37:47 - train: epoch 0054, iter [01800, 05004], lr: 0.097157, loss: 1.3742
2022-07-20 06:40:04 - train: epoch 0054, iter [01900, 05004], lr: 0.097091, loss: 1.5485
2022-07-20 06:42:20 - train: epoch 0054, iter [02000, 05004], lr: 0.097025, loss: 1.4596
2022-07-20 06:44:37 - train: epoch 0054, iter [02100, 05004], lr: 0.096959, loss: 1.3515
2022-07-20 06:46:54 - train: epoch 0054, iter [02200, 05004], lr: 0.096893, loss: 1.4041
2022-07-20 06:49:10 - train: epoch 0054, iter [02300, 05004], lr: 0.096827, loss: 1.2026
2022-07-20 06:51:27 - train: epoch 0054, iter [02400, 05004], lr: 0.096761, loss: 1.5303
2022-07-20 06:53:44 - train: epoch 0054, iter [02500, 05004], lr: 0.096695, loss: 1.5105
2022-07-20 06:56:01 - train: epoch 0054, iter [02600, 05004], lr: 0.096629, loss: 1.3483
2022-07-20 06:58:17 - train: epoch 0054, iter [02700, 05004], lr: 0.096563, loss: 1.3817
2022-07-20 07:00:34 - train: epoch 0054, iter [02800, 05004], lr: 0.096497, loss: 1.5356
2022-07-20 07:02:51 - train: epoch 0054, iter [02900, 05004], lr: 0.096431, loss: 1.4314
2022-07-20 07:05:07 - train: epoch 0054, iter [03000, 05004], lr: 0.096365, loss: 1.5835
2022-07-20 07:07:24 - train: epoch 0054, iter [03100, 05004], lr: 0.096299, loss: 1.5456
2022-07-20 07:09:41 - train: epoch 0054, iter [03200, 05004], lr: 0.096233, loss: 1.5488
2022-07-20 07:11:57 - train: epoch 0054, iter [03300, 05004], lr: 0.096167, loss: 1.3965
2022-07-20 07:14:14 - train: epoch 0054, iter [03400, 05004], lr: 0.096101, loss: 1.4056
2022-07-20 07:16:31 - train: epoch 0054, iter [03500, 05004], lr: 0.096035, loss: 1.3972
2022-07-20 07:18:48 - train: epoch 0054, iter [03600, 05004], lr: 0.095969, loss: 1.5440
2022-07-20 07:21:04 - train: epoch 0054, iter [03700, 05004], lr: 0.095902, loss: 1.4568
2022-07-20 07:23:21 - train: epoch 0054, iter [03800, 05004], lr: 0.095836, loss: 1.4003
2022-07-20 07:25:38 - train: epoch 0054, iter [03900, 05004], lr: 0.095770, loss: 1.3925
2022-07-20 07:27:55 - train: epoch 0054, iter [04000, 05004], lr: 0.095704, loss: 1.5275
2022-07-20 07:30:11 - train: epoch 0054, iter [04100, 05004], lr: 0.095638, loss: 1.4964
2022-07-20 07:32:28 - train: epoch 0054, iter [04200, 05004], lr: 0.095572, loss: 1.4288
2022-07-20 07:34:45 - train: epoch 0054, iter [04300, 05004], lr: 0.095506, loss: 1.5745
2022-07-20 07:37:02 - train: epoch 0054, iter [04400, 05004], lr: 0.095440, loss: 1.4891
2022-07-20 07:39:19 - train: epoch 0054, iter [04500, 05004], lr: 0.095374, loss: 1.3821
2022-07-20 07:41:35 - train: epoch 0054, iter [04600, 05004], lr: 0.095308, loss: 1.6121
2022-07-20 07:43:52 - train: epoch 0054, iter [04700, 05004], lr: 0.095242, loss: 1.6957
2022-07-20 07:46:09 - train: epoch 0054, iter [04800, 05004], lr: 0.095176, loss: 1.6466
2022-07-20 07:48:25 - train: epoch 0054, iter [04900, 05004], lr: 0.095110, loss: 1.4217
2022-07-20 07:50:42 - train: epoch 0054, iter [05000, 05004], lr: 0.095044, loss: 1.4964
2022-07-20 07:50:49 - train: epoch 054, train_loss: 1.4753
2022-07-20 07:52:55 - eval: epoch: 054, acc1: 68.224%, acc5: 88.830%, test_loss: 1.2972, per_image_load_time: 0.985ms, per_image_inference_time: 3.902ms
2022-07-20 07:52:55 - until epoch: 054, best_acc1: 68.278%
2022-07-20 07:52:55 - epoch 055 lr: 0.095041
2022-07-20 07:55:20 - train: epoch 0055, iter [00100, 05004], lr: 0.094976, loss: 1.3030
2022-07-20 07:57:37 - train: epoch 0055, iter [00200, 05004], lr: 0.094910, loss: 1.3325
2022-07-20 07:59:53 - train: epoch 0055, iter [00300, 05004], lr: 0.094844, loss: 1.2611
2022-07-20 08:02:10 - train: epoch 0055, iter [00400, 05004], lr: 0.094778, loss: 1.2448
2022-07-20 08:04:26 - train: epoch 0055, iter [00500, 05004], lr: 0.094712, loss: 1.1244
2022-07-20 08:06:43 - train: epoch 0055, iter [00600, 05004], lr: 0.094646, loss: 1.5175
2022-07-20 08:09:00 - train: epoch 0055, iter [00700, 05004], lr: 0.094580, loss: 1.4790
2022-07-20 08:11:16 - train: epoch 0055, iter [00800, 05004], lr: 0.094514, loss: 1.3595
2022-07-20 08:13:33 - train: epoch 0055, iter [00900, 05004], lr: 0.094448, loss: 1.4115
2022-07-20 08:15:49 - train: epoch 0055, iter [01000, 05004], lr: 0.094382, loss: 1.3382
2022-07-20 08:18:06 - train: epoch 0055, iter [01100, 05004], lr: 0.094316, loss: 1.3779
2022-07-20 08:20:22 - train: epoch 0055, iter [01200, 05004], lr: 0.094250, loss: 1.5029
2022-07-20 08:22:39 - train: epoch 0055, iter [01300, 05004], lr: 0.094184, loss: 1.6077
2022-07-20 08:24:55 - train: epoch 0055, iter [01400, 05004], lr: 0.094118, loss: 1.5413
2022-07-20 08:27:12 - train: epoch 0055, iter [01500, 05004], lr: 0.094052, loss: 1.4198
2022-07-20 08:29:29 - train: epoch 0055, iter [01600, 05004], lr: 0.093986, loss: 1.6200
2022-07-20 08:31:45 - train: epoch 0055, iter [01700, 05004], lr: 0.093920, loss: 1.4585
2022-07-20 08:34:02 - train: epoch 0055, iter [01800, 05004], lr: 0.093854, loss: 1.4130
2022-07-20 08:36:19 - train: epoch 0055, iter [01900, 05004], lr: 0.093788, loss: 1.5816
2022-07-20 08:38:35 - train: epoch 0055, iter [02000, 05004], lr: 0.093722, loss: 1.5372
2022-07-20 08:40:52 - train: epoch 0055, iter [02100, 05004], lr: 0.093656, loss: 1.2158
2022-07-20 08:43:09 - train: epoch 0055, iter [02200, 05004], lr: 0.093590, loss: 1.6223
2022-07-20 08:45:25 - train: epoch 0055, iter [02300, 05004], lr: 0.093524, loss: 1.4375
2022-07-20 08:47:42 - train: epoch 0055, iter [02400, 05004], lr: 0.093458, loss: 1.3363
2022-07-20 08:49:59 - train: epoch 0055, iter [02500, 05004], lr: 0.093392, loss: 1.5676
2022-07-20 08:52:15 - train: epoch 0055, iter [02600, 05004], lr: 0.093326, loss: 1.4561
2022-07-20 08:54:32 - train: epoch 0055, iter [02700, 05004], lr: 0.093260, loss: 1.5100
2022-07-20 08:56:49 - train: epoch 0055, iter [02800, 05004], lr: 0.093194, loss: 1.3764
2022-07-20 08:59:06 - train: epoch 0055, iter [02900, 05004], lr: 0.093129, loss: 1.5307
2022-07-20 09:01:22 - train: epoch 0055, iter [03000, 05004], lr: 0.093063, loss: 1.5003
2022-07-20 09:03:39 - train: epoch 0055, iter [03100, 05004], lr: 0.092997, loss: 1.6315
2022-07-20 09:05:56 - train: epoch 0055, iter [03200, 05004], lr: 0.092931, loss: 1.5587
2022-07-20 09:08:12 - train: epoch 0055, iter [03300, 05004], lr: 0.092865, loss: 1.3981
2022-07-20 09:10:29 - train: epoch 0055, iter [03400, 05004], lr: 0.092799, loss: 1.3409
2022-07-20 09:12:46 - train: epoch 0055, iter [03500, 05004], lr: 0.092733, loss: 1.2889
2022-07-20 09:15:02 - train: epoch 0055, iter [03600, 05004], lr: 0.092667, loss: 1.5862
2022-07-20 09:17:19 - train: epoch 0055, iter [03700, 05004], lr: 0.092601, loss: 1.3793
2022-07-20 09:19:36 - train: epoch 0055, iter [03800, 05004], lr: 0.092535, loss: 1.4930
2022-07-20 09:21:52 - train: epoch 0055, iter [03900, 05004], lr: 0.092469, loss: 1.7284
2022-07-20 09:24:09 - train: epoch 0055, iter [04000, 05004], lr: 0.092403, loss: 1.4727
2022-07-20 09:26:25 - train: epoch 0055, iter [04100, 05004], lr: 0.092338, loss: 1.4033
2022-07-20 09:28:42 - train: epoch 0055, iter [04200, 05004], lr: 0.092272, loss: 1.4716
2022-07-20 09:30:58 - train: epoch 0055, iter [04300, 05004], lr: 0.092206, loss: 1.5495
2022-07-20 09:33:15 - train: epoch 0055, iter [04400, 05004], lr: 0.092140, loss: 1.6406
2022-07-20 09:35:32 - train: epoch 0055, iter [04500, 05004], lr: 0.092074, loss: 1.4594
2022-07-20 09:37:48 - train: epoch 0055, iter [04600, 05004], lr: 0.092008, loss: 1.4835
2022-07-20 09:40:05 - train: epoch 0055, iter [04700, 05004], lr: 0.091942, loss: 1.3497
2022-07-20 09:42:22 - train: epoch 0055, iter [04800, 05004], lr: 0.091876, loss: 1.4207
2022-07-20 09:44:39 - train: epoch 0055, iter [04900, 05004], lr: 0.091811, loss: 1.3969
2022-07-20 09:46:55 - train: epoch 0055, iter [05000, 05004], lr: 0.091745, loss: 1.5062
2022-07-20 09:47:02 - train: epoch 055, train_loss: 1.4613
2022-07-20 09:49:17 - eval: epoch: 055, acc1: 68.972%, acc5: 89.548%, test_loss: 1.2501, per_image_load_time: 1.252ms, per_image_inference_time: 3.912ms
2022-07-20 09:49:18 - until epoch: 055, best_acc1: 68.972%
2022-07-20 09:49:18 - epoch 056 lr: 0.091741
2022-07-20 09:51:43 - train: epoch 0056, iter [00100, 05004], lr: 0.091676, loss: 1.3760
2022-07-20 09:54:00 - train: epoch 0056, iter [00200, 05004], lr: 0.091610, loss: 1.4309
2022-07-20 09:56:17 - train: epoch 0056, iter [00300, 05004], lr: 0.091545, loss: 1.2045
2022-07-20 09:58:34 - train: epoch 0056, iter [00400, 05004], lr: 0.091479, loss: 1.4446
2022-07-20 10:00:51 - train: epoch 0056, iter [00500, 05004], lr: 0.091413, loss: 1.3639
2022-07-20 10:03:07 - train: epoch 0056, iter [00600, 05004], lr: 0.091347, loss: 1.3831
2022-07-20 10:05:24 - train: epoch 0056, iter [00700, 05004], lr: 0.091281, loss: 1.6554
2022-07-20 10:07:41 - train: epoch 0056, iter [00800, 05004], lr: 0.091215, loss: 1.4501
2022-07-20 10:09:58 - train: epoch 0056, iter [00900, 05004], lr: 0.091149, loss: 1.5305
2022-07-20 10:12:15 - train: epoch 0056, iter [01000, 05004], lr: 0.091084, loss: 1.3780
2022-07-20 10:14:31 - train: epoch 0056, iter [01100, 05004], lr: 0.091018, loss: 1.2743
2022-07-20 10:16:48 - train: epoch 0056, iter [01200, 05004], lr: 0.090952, loss: 1.5440
2022-07-20 10:19:05 - train: epoch 0056, iter [01300, 05004], lr: 0.090886, loss: 1.5458
2022-07-20 10:21:22 - train: epoch 0056, iter [01400, 05004], lr: 0.090820, loss: 1.3119
2022-07-20 10:23:38 - train: epoch 0056, iter [01500, 05004], lr: 0.090755, loss: 1.7105
2022-07-20 10:25:56 - train: epoch 0056, iter [01600, 05004], lr: 0.090689, loss: 1.4438
2022-07-20 10:28:13 - train: epoch 0056, iter [01700, 05004], lr: 0.090623, loss: 1.4030
2022-07-20 10:30:30 - train: epoch 0056, iter [01800, 05004], lr: 0.090557, loss: 1.4502
2022-07-20 10:32:47 - train: epoch 0056, iter [01900, 05004], lr: 0.090491, loss: 1.5217
2022-07-20 10:35:04 - train: epoch 0056, iter [02000, 05004], lr: 0.090426, loss: 1.3227
2022-07-20 10:37:22 - train: epoch 0056, iter [02100, 05004], lr: 0.090360, loss: 1.6632
2022-07-20 10:39:39 - train: epoch 0056, iter [02200, 05004], lr: 0.090294, loss: 1.5243
2022-07-20 10:41:56 - train: epoch 0056, iter [02300, 05004], lr: 0.090228, loss: 1.5004
2022-07-20 10:44:13 - train: epoch 0056, iter [02400, 05004], lr: 0.090163, loss: 1.3755
2022-07-20 10:46:31 - train: epoch 0056, iter [02500, 05004], lr: 0.090097, loss: 1.6785
2022-07-20 10:48:48 - train: epoch 0056, iter [02600, 05004], lr: 0.090031, loss: 1.3684
2022-07-20 10:51:05 - train: epoch 0056, iter [02700, 05004], lr: 0.089965, loss: 1.3075
2022-07-20 10:53:22 - train: epoch 0056, iter [02800, 05004], lr: 0.089899, loss: 1.3445
2022-07-20 10:55:40 - train: epoch 0056, iter [02900, 05004], lr: 0.089834, loss: 1.3973
2022-07-20 10:57:57 - train: epoch 0056, iter [03000, 05004], lr: 0.089768, loss: 1.4798
2022-07-20 11:00:14 - train: epoch 0056, iter [03100, 05004], lr: 0.089702, loss: 1.3255
2022-07-20 11:02:31 - train: epoch 0056, iter [03200, 05004], lr: 0.089637, loss: 1.3401
2022-07-20 11:04:48 - train: epoch 0056, iter [03300, 05004], lr: 0.089571, loss: 1.5947
2022-07-20 11:07:06 - train: epoch 0056, iter [03400, 05004], lr: 0.089505, loss: 1.4164
2022-07-20 11:09:23 - train: epoch 0056, iter [03500, 05004], lr: 0.089439, loss: 1.3651
2022-07-20 11:11:40 - train: epoch 0056, iter [03600, 05004], lr: 0.089374, loss: 1.2930
2022-07-20 11:13:57 - train: epoch 0056, iter [03700, 05004], lr: 0.089308, loss: 1.5150
2022-07-20 11:16:15 - train: epoch 0056, iter [03800, 05004], lr: 0.089242, loss: 1.3033
2022-07-20 11:18:32 - train: epoch 0056, iter [03900, 05004], lr: 0.089177, loss: 1.5576
2022-07-20 11:20:49 - train: epoch 0056, iter [04000, 05004], lr: 0.089111, loss: 1.6234
2022-07-20 11:23:07 - train: epoch 0056, iter [04100, 05004], lr: 0.089045, loss: 1.4895
2022-07-20 11:25:24 - train: epoch 0056, iter [04200, 05004], lr: 0.088979, loss: 1.5065
2022-07-20 11:27:42 - train: epoch 0056, iter [04300, 05004], lr: 0.088914, loss: 1.4290
2022-07-20 11:29:59 - train: epoch 0056, iter [04400, 05004], lr: 0.088848, loss: 1.4372
2022-07-20 11:32:16 - train: epoch 0056, iter [04500, 05004], lr: 0.088782, loss: 1.5275
2022-07-20 11:34:33 - train: epoch 0056, iter [04600, 05004], lr: 0.088717, loss: 1.5014
2022-07-20 11:36:50 - train: epoch 0056, iter [04700, 05004], lr: 0.088651, loss: 1.5462
2022-07-20 11:39:08 - train: epoch 0056, iter [04800, 05004], lr: 0.088585, loss: 1.4513
2022-07-20 11:41:25 - train: epoch 0056, iter [04900, 05004], lr: 0.088520, loss: 1.4567
2022-07-20 11:43:42 - train: epoch 0056, iter [05000, 05004], lr: 0.088454, loss: 1.3321
2022-07-20 11:43:49 - train: epoch 056, train_loss: 1.4463
2022-07-20 11:46:01 - eval: epoch: 056, acc1: 68.752%, acc5: 89.206%, test_loss: 1.2647, per_image_load_time: 1.155ms, per_image_inference_time: 3.922ms
2022-07-20 11:46:01 - until epoch: 056, best_acc1: 68.972%
2022-07-20 11:46:01 - epoch 057 lr: 0.088451
2022-07-20 11:48:26 - train: epoch 0057, iter [00100, 05004], lr: 0.088386, loss: 1.2807
2022-07-20 11:50:43 - train: epoch 0057, iter [00200, 05004], lr: 0.088320, loss: 1.4131
2022-07-20 11:53:00 - train: epoch 0057, iter [00300, 05004], lr: 0.088255, loss: 1.3729
2022-07-20 11:55:17 - train: epoch 0057, iter [00400, 05004], lr: 0.088189, loss: 1.5999
2022-07-20 11:57:34 - train: epoch 0057, iter [00500, 05004], lr: 0.088123, loss: 1.3659
2022-07-20 11:59:51 - train: epoch 0057, iter [00600, 05004], lr: 0.088058, loss: 1.4527
2022-07-20 12:02:08 - train: epoch 0057, iter [00700, 05004], lr: 0.087992, loss: 1.2188
2022-07-20 12:04:25 - train: epoch 0057, iter [00800, 05004], lr: 0.087927, loss: 1.4889
2022-07-20 12:06:42 - train: epoch 0057, iter [00900, 05004], lr: 0.087861, loss: 1.4754
2022-07-20 12:08:59 - train: epoch 0057, iter [01000, 05004], lr: 0.087795, loss: 1.6306
2022-07-20 12:11:16 - train: epoch 0057, iter [01100, 05004], lr: 0.087730, loss: 1.3778
2022-07-20 12:13:33 - train: epoch 0057, iter [01200, 05004], lr: 0.087664, loss: 1.3959
2022-07-20 12:15:50 - train: epoch 0057, iter [01300, 05004], lr: 0.087599, loss: 1.3722
2022-07-20 12:18:07 - train: epoch 0057, iter [01400, 05004], lr: 0.087533, loss: 1.4139
2022-07-20 12:20:24 - train: epoch 0057, iter [01500, 05004], lr: 0.087467, loss: 1.5494
2022-07-20 12:22:41 - train: epoch 0057, iter [01600, 05004], lr: 0.087402, loss: 1.6019
2022-07-20 12:24:58 - train: epoch 0057, iter [01700, 05004], lr: 0.087336, loss: 1.5171
2022-07-20 12:27:15 - train: epoch 0057, iter [01800, 05004], lr: 0.087271, loss: 1.3604
2022-07-20 12:29:31 - train: epoch 0057, iter [01900, 05004], lr: 0.087205, loss: 1.4884
2022-07-20 12:31:48 - train: epoch 0057, iter [02000, 05004], lr: 0.087140, loss: 1.4152
2022-07-20 12:34:05 - train: epoch 0057, iter [02100, 05004], lr: 0.087074, loss: 1.2192
2022-07-20 12:36:22 - train: epoch 0057, iter [02200, 05004], lr: 0.087009, loss: 1.4094
2022-07-20 12:38:39 - train: epoch 0057, iter [02300, 05004], lr: 0.086943, loss: 1.2929
2022-07-20 12:40:56 - train: epoch 0057, iter [02400, 05004], lr: 0.086878, loss: 1.4893
2022-07-20 12:43:13 - train: epoch 0057, iter [02500, 05004], lr: 0.086812, loss: 1.4485
2022-07-20 12:45:29 - train: epoch 0057, iter [02600, 05004], lr: 0.086747, loss: 1.3836
2022-07-20 12:47:46 - train: epoch 0057, iter [02700, 05004], lr: 0.086681, loss: 1.4679
2022-07-20 12:50:03 - train: epoch 0057, iter [02800, 05004], lr: 0.086616, loss: 1.3685
2022-07-20 12:52:20 - train: epoch 0057, iter [02900, 05004], lr: 0.086550, loss: 1.4188
2022-07-20 12:54:37 - train: epoch 0057, iter [03000, 05004], lr: 0.086485, loss: 1.4383
2022-07-20 12:56:53 - train: epoch 0057, iter [03100, 05004], lr: 0.086419, loss: 1.6597
2022-07-20 12:59:10 - train: epoch 0057, iter [03200, 05004], lr: 0.086354, loss: 1.7073
2022-07-20 13:01:27 - train: epoch 0057, iter [03300, 05004], lr: 0.086288, loss: 1.4267
2022-07-20 13:03:44 - train: epoch 0057, iter [03400, 05004], lr: 0.086223, loss: 1.5469
2022-07-20 13:06:01 - train: epoch 0057, iter [03500, 05004], lr: 0.086157, loss: 1.6025
2022-07-20 13:08:18 - train: epoch 0057, iter [03600, 05004], lr: 0.086092, loss: 1.4175
2022-07-20 13:10:35 - train: epoch 0057, iter [03700, 05004], lr: 0.086026, loss: 1.3232
2022-07-20 13:12:52 - train: epoch 0057, iter [03800, 05004], lr: 0.085961, loss: 1.3477
2022-07-20 13:15:09 - train: epoch 0057, iter [03900, 05004], lr: 0.085896, loss: 1.5255
2022-07-20 13:17:26 - train: epoch 0057, iter [04000, 05004], lr: 0.085830, loss: 1.3913
2022-07-20 13:19:43 - train: epoch 0057, iter [04100, 05004], lr: 0.085765, loss: 1.5393
2022-07-20 13:22:00 - train: epoch 0057, iter [04200, 05004], lr: 0.085699, loss: 1.3676
2022-07-20 13:24:16 - train: epoch 0057, iter [04300, 05004], lr: 0.085634, loss: 1.1531
2022-07-20 13:26:33 - train: epoch 0057, iter [04400, 05004], lr: 0.085568, loss: 1.6316
2022-07-20 13:28:50 - train: epoch 0057, iter [04500, 05004], lr: 0.085503, loss: 1.6581
2022-07-20 13:31:07 - train: epoch 0057, iter [04600, 05004], lr: 0.085438, loss: 1.3365
2022-07-20 13:33:24 - train: epoch 0057, iter [04700, 05004], lr: 0.085372, loss: 1.3151
2022-07-20 13:35:41 - train: epoch 0057, iter [04800, 05004], lr: 0.085307, loss: 1.5538
2022-07-20 13:37:58 - train: epoch 0057, iter [04900, 05004], lr: 0.085242, loss: 1.6067
2022-07-20 13:40:15 - train: epoch 0057, iter [05000, 05004], lr: 0.085176, loss: 1.4943
2022-07-20 13:40:22 - train: epoch 057, train_loss: 1.4292
2022-07-20 13:42:36 - eval: epoch: 057, acc1: 69.212%, acc5: 89.456%, test_loss: 1.2522, per_image_load_time: 1.198ms, per_image_inference_time: 3.899ms
2022-07-20 13:42:36 - until epoch: 057, best_acc1: 69.212%
2022-07-20 13:42:36 - epoch 058 lr: 0.085173
2022-07-20 13:45:01 - train: epoch 0058, iter [00100, 05004], lr: 0.085108, loss: 1.4912
2022-07-20 13:47:18 - train: epoch 0058, iter [00200, 05004], lr: 0.085043, loss: 1.4248
2022-07-20 13:49:35 - train: epoch 0058, iter [00300, 05004], lr: 0.084978, loss: 1.2730
2022-07-20 13:51:51 - train: epoch 0058, iter [00400, 05004], lr: 0.084912, loss: 1.2624
2022-07-20 13:54:08 - train: epoch 0058, iter [00500, 05004], lr: 0.084847, loss: 1.2969
2022-07-20 13:56:25 - train: epoch 0058, iter [00600, 05004], lr: 0.084782, loss: 1.6161
2022-07-20 13:58:42 - train: epoch 0058, iter [00700, 05004], lr: 0.084716, loss: 1.3448
2022-07-20 14:00:58 - train: epoch 0058, iter [00800, 05004], lr: 0.084651, loss: 1.1931
2022-07-20 14:03:15 - train: epoch 0058, iter [00900, 05004], lr: 0.084586, loss: 1.3090
2022-07-20 14:05:32 - train: epoch 0058, iter [01000, 05004], lr: 0.084520, loss: 1.2965
2022-07-20 14:07:48 - train: epoch 0058, iter [01100, 05004], lr: 0.084455, loss: 1.2129
2022-07-20 14:10:05 - train: epoch 0058, iter [01200, 05004], lr: 0.084390, loss: 1.1737
2022-07-20 14:12:22 - train: epoch 0058, iter [01300, 05004], lr: 0.084325, loss: 1.6440
2022-07-20 14:14:38 - train: epoch 0058, iter [01400, 05004], lr: 0.084259, loss: 1.4474
2022-07-20 14:16:55 - train: epoch 0058, iter [01500, 05004], lr: 0.084194, loss: 1.4723
2022-07-20 14:19:12 - train: epoch 0058, iter [01600, 05004], lr: 0.084129, loss: 1.3719
2022-07-20 14:21:28 - train: epoch 0058, iter [01700, 05004], lr: 0.084064, loss: 1.5763
2022-07-20 14:23:45 - train: epoch 0058, iter [01800, 05004], lr: 0.083998, loss: 1.5704
2022-07-20 14:26:02 - train: epoch 0058, iter [01900, 05004], lr: 0.083933, loss: 1.4734
2022-07-20 14:28:19 - train: epoch 0058, iter [02000, 05004], lr: 0.083868, loss: 1.5476
2022-07-20 14:30:35 - train: epoch 0058, iter [02100, 05004], lr: 0.083803, loss: 1.3758
2022-07-20 14:32:52 - train: epoch 0058, iter [02200, 05004], lr: 0.083737, loss: 1.2996
2022-07-20 14:35:09 - train: epoch 0058, iter [02300, 05004], lr: 0.083672, loss: 1.4792
2022-07-20 14:37:25 - train: epoch 0058, iter [02400, 05004], lr: 0.083607, loss: 1.2821
2022-07-20 14:39:42 - train: epoch 0058, iter [02500, 05004], lr: 0.083542, loss: 1.5897
2022-07-20 14:41:59 - train: epoch 0058, iter [02600, 05004], lr: 0.083477, loss: 1.3515
2022-07-20 14:44:15 - train: epoch 0058, iter [02700, 05004], lr: 0.083411, loss: 1.6627
2022-07-20 14:46:32 - train: epoch 0058, iter [02800, 05004], lr: 0.083346, loss: 1.2737
2022-07-20 14:48:49 - train: epoch 0058, iter [02900, 05004], lr: 0.083281, loss: 1.4176
2022-07-20 14:51:06 - train: epoch 0058, iter [03000, 05004], lr: 0.083216, loss: 1.5682
2022-07-20 14:53:23 - train: epoch 0058, iter [03100, 05004], lr: 0.083151, loss: 1.4250
2022-07-20 14:55:39 - train: epoch 0058, iter [03200, 05004], lr: 0.083086, loss: 1.3291
2022-07-20 14:57:56 - train: epoch 0058, iter [03300, 05004], lr: 0.083021, loss: 1.5131
2022-07-20 15:00:13 - train: epoch 0058, iter [03400, 05004], lr: 0.082955, loss: 1.4888
2022-07-20 15:02:30 - train: epoch 0058, iter [03500, 05004], lr: 0.082890, loss: 1.3349
2022-07-20 15:04:47 - train: epoch 0058, iter [03600, 05004], lr: 0.082825, loss: 1.4749
2022-07-20 15:07:03 - train: epoch 0058, iter [03700, 05004], lr: 0.082760, loss: 1.2922
2022-07-20 15:09:20 - train: epoch 0058, iter [03800, 05004], lr: 0.082695, loss: 1.3425
2022-07-20 15:11:37 - train: epoch 0058, iter [03900, 05004], lr: 0.082630, loss: 1.4088
2022-07-20 15:13:54 - train: epoch 0058, iter [04000, 05004], lr: 0.082565, loss: 1.2166
2022-07-20 15:16:10 - train: epoch 0058, iter [04100, 05004], lr: 0.082500, loss: 1.3530
2022-07-20 15:18:27 - train: epoch 0058, iter [04200, 05004], lr: 0.082435, loss: 1.2755
2022-07-20 15:20:44 - train: epoch 0058, iter [04300, 05004], lr: 0.082370, loss: 1.6123
2022-07-20 15:23:01 - train: epoch 0058, iter [04400, 05004], lr: 0.082305, loss: 1.2754
2022-07-20 15:25:18 - train: epoch 0058, iter [04500, 05004], lr: 0.082240, loss: 1.3152
2022-07-20 15:27:35 - train: epoch 0058, iter [04600, 05004], lr: 0.082175, loss: 1.2442
2022-07-20 15:29:52 - train: epoch 0058, iter [04700, 05004], lr: 0.082110, loss: 1.3974
2022-07-20 15:32:09 - train: epoch 0058, iter [04800, 05004], lr: 0.082045, loss: 1.3978
2022-07-20 15:34:26 - train: epoch 0058, iter [04900, 05004], lr: 0.081980, loss: 1.3268
2022-07-20 15:36:43 - train: epoch 0058, iter [05000, 05004], lr: 0.081915, loss: 1.1095
2022-07-20 15:36:50 - train: epoch 058, train_loss: 1.4157
2022-07-20 15:39:06 - eval: epoch: 058, acc1: 69.532%, acc5: 89.642%, test_loss: 1.2446, per_image_load_time: 1.197ms, per_image_inference_time: 3.928ms
2022-07-20 15:39:06 - until epoch: 058, best_acc1: 69.532%
2022-07-20 15:39:06 - epoch 059 lr: 0.081911
2022-07-20 15:41:32 - train: epoch 0059, iter [00100, 05004], lr: 0.081847, loss: 1.3236
2022-07-20 15:43:49 - train: epoch 0059, iter [00200, 05004], lr: 0.081782, loss: 1.2062
2022-07-20 15:46:06 - train: epoch 0059, iter [00300, 05004], lr: 0.081717, loss: 1.4472
2022-07-20 15:48:23 - train: epoch 0059, iter [00400, 05004], lr: 0.081652, loss: 1.3804
2022-07-20 15:50:39 - train: epoch 0059, iter [00500, 05004], lr: 0.081587, loss: 1.2326
2022-07-20 15:52:56 - train: epoch 0059, iter [00600, 05004], lr: 0.081522, loss: 1.3574
2022-07-20 15:55:13 - train: epoch 0059, iter [00700, 05004], lr: 0.081457, loss: 1.2619
2022-07-20 15:57:30 - train: epoch 0059, iter [00800, 05004], lr: 0.081392, loss: 1.3934
2022-07-20 15:59:46 - train: epoch 0059, iter [00900, 05004], lr: 0.081327, loss: 1.3648
2022-07-20 16:02:03 - train: epoch 0059, iter [01000, 05004], lr: 0.081262, loss: 1.4419
2022-07-20 16:04:20 - train: epoch 0059, iter [01100, 05004], lr: 0.081197, loss: 1.6111
2022-07-20 16:06:37 - train: epoch 0059, iter [01200, 05004], lr: 0.081133, loss: 1.4000
2022-07-20 16:08:53 - train: epoch 0059, iter [01300, 05004], lr: 0.081068, loss: 1.6019
2022-07-20 16:11:10 - train: epoch 0059, iter [01400, 05004], lr: 0.081003, loss: 1.5697
2022-07-20 16:13:27 - train: epoch 0059, iter [01500, 05004], lr: 0.080938, loss: 1.2840
2022-07-20 16:15:44 - train: epoch 0059, iter [01600, 05004], lr: 0.080873, loss: 1.2792
2022-07-20 16:18:01 - train: epoch 0059, iter [01700, 05004], lr: 0.080808, loss: 1.6035
2022-07-20 16:20:18 - train: epoch 0059, iter [01800, 05004], lr: 0.080743, loss: 1.3060
2022-07-20 16:22:35 - train: epoch 0059, iter [01900, 05004], lr: 0.080678, loss: 1.2090
2022-07-20 16:24:53 - train: epoch 0059, iter [02000, 05004], lr: 0.080614, loss: 1.0766
2022-07-20 16:27:10 - train: epoch 0059, iter [02100, 05004], lr: 0.080549, loss: 1.2932
2022-07-20 16:29:27 - train: epoch 0059, iter [02200, 05004], lr: 0.080484, loss: 1.1999
2022-07-20 16:31:45 - train: epoch 0059, iter [02300, 05004], lr: 0.080419, loss: 1.2996
2022-07-20 16:34:02 - train: epoch 0059, iter [02400, 05004], lr: 0.080354, loss: 1.5687
2022-07-20 16:36:20 - train: epoch 0059, iter [02500, 05004], lr: 0.080290, loss: 1.5466
2022-07-20 16:38:37 - train: epoch 0059, iter [02600, 05004], lr: 0.080225, loss: 1.3809
2022-07-20 16:40:55 - train: epoch 0059, iter [02700, 05004], lr: 0.080160, loss: 1.3647
2022-07-20 16:43:12 - train: epoch 0059, iter [02800, 05004], lr: 0.080095, loss: 1.5638
2022-07-20 16:45:29 - train: epoch 0059, iter [02900, 05004], lr: 0.080031, loss: 1.3233
2022-07-20 16:47:47 - train: epoch 0059, iter [03000, 05004], lr: 0.079966, loss: 1.6449
2022-07-20 16:50:04 - train: epoch 0059, iter [03100, 05004], lr: 0.079901, loss: 1.2159
2022-07-20 16:52:21 - train: epoch 0059, iter [03200, 05004], lr: 0.079836, loss: 1.5191
2022-07-20 16:54:39 - train: epoch 0059, iter [03300, 05004], lr: 0.079772, loss: 1.2853
2022-07-20 16:56:56 - train: epoch 0059, iter [03400, 05004], lr: 0.079707, loss: 1.6867
2022-07-20 16:59:13 - train: epoch 0059, iter [03500, 05004], lr: 0.079642, loss: 1.2143
2022-07-20 17:01:31 - train: epoch 0059, iter [03600, 05004], lr: 0.079577, loss: 1.4796
2022-07-20 17:03:48 - train: epoch 0059, iter [03700, 05004], lr: 0.079513, loss: 1.5925
2022-07-20 17:06:06 - train: epoch 0059, iter [03800, 05004], lr: 0.079448, loss: 1.3270
2022-07-20 17:08:23 - train: epoch 0059, iter [03900, 05004], lr: 0.079383, loss: 1.3282
2022-07-20 17:10:40 - train: epoch 0059, iter [04000, 05004], lr: 0.079319, loss: 1.5939
2022-07-20 17:12:57 - train: epoch 0059, iter [04100, 05004], lr: 0.079254, loss: 1.2442
2022-07-20 17:15:15 - train: epoch 0059, iter [04200, 05004], lr: 0.079189, loss: 1.5760
2022-07-20 17:17:32 - train: epoch 0059, iter [04300, 05004], lr: 0.079125, loss: 1.4976
2022-07-20 17:19:49 - train: epoch 0059, iter [04400, 05004], lr: 0.079060, loss: 1.5360
2022-07-20 17:22:07 - train: epoch 0059, iter [04500, 05004], lr: 0.078996, loss: 1.6107
2022-07-20 17:24:24 - train: epoch 0059, iter [04600, 05004], lr: 0.078931, loss: 1.3776
2022-07-20 17:26:41 - train: epoch 0059, iter [04700, 05004], lr: 0.078866, loss: 1.5149
2022-07-20 17:28:58 - train: epoch 0059, iter [04800, 05004], lr: 0.078802, loss: 1.4582
2022-07-20 17:31:15 - train: epoch 0059, iter [04900, 05004], lr: 0.078737, loss: 1.4513
2022-07-20 17:33:32 - train: epoch 0059, iter [05000, 05004], lr: 0.078673, loss: 1.5345
2022-07-20 17:33:38 - train: epoch 059, train_loss: 1.4009
2022-07-20 17:35:46 - eval: epoch: 059, acc1: 69.336%, acc5: 89.598%, test_loss: 1.2351, per_image_load_time: 0.996ms, per_image_inference_time: 3.900ms
2022-07-20 17:35:46 - until epoch: 059, best_acc1: 69.532%
2022-07-20 17:35:46 - epoch 060 lr: 0.078669
2022-07-20 17:38:11 - train: epoch 0060, iter [00100, 05004], lr: 0.078605, loss: 1.2053
2022-07-20 17:40:28 - train: epoch 0060, iter [00200, 05004], lr: 0.078541, loss: 1.2735
2022-07-20 17:42:45 - train: epoch 0060, iter [00300, 05004], lr: 0.078476, loss: 1.3815
2022-07-20 17:45:01 - train: epoch 0060, iter [00400, 05004], lr: 0.078412, loss: 1.4402
2022-07-20 17:47:18 - train: epoch 0060, iter [00500, 05004], lr: 0.078347, loss: 1.5492
2022-07-20 17:49:34 - train: epoch 0060, iter [00600, 05004], lr: 0.078283, loss: 1.5111
2022-07-20 17:51:51 - train: epoch 0060, iter [00700, 05004], lr: 0.078218, loss: 1.4791
2022-07-20 17:54:08 - train: epoch 0060, iter [00800, 05004], lr: 0.078154, loss: 1.4264
2022-07-20 17:56:25 - train: epoch 0060, iter [00900, 05004], lr: 0.078089, loss: 1.2970
2022-07-20 17:58:43 - train: epoch 0060, iter [01000, 05004], lr: 0.078025, loss: 1.1133
2022-07-20 18:00:59 - train: epoch 0060, iter [01100, 05004], lr: 0.077960, loss: 1.3227
2022-07-20 18:03:16 - train: epoch 0060, iter [01200, 05004], lr: 0.077896, loss: 1.2328
2022-07-20 18:05:33 - train: epoch 0060, iter [01300, 05004], lr: 0.077831, loss: 1.3925
2022-07-20 18:07:50 - train: epoch 0060, iter [01400, 05004], lr: 0.077767, loss: 1.5140
2022-07-20 18:10:07 - train: epoch 0060, iter [01500, 05004], lr: 0.077703, loss: 1.3965
2022-07-20 18:12:23 - train: epoch 0060, iter [01600, 05004], lr: 0.077638, loss: 1.3123
2022-07-20 18:14:40 - train: epoch 0060, iter [01700, 05004], lr: 0.077574, loss: 1.3683
2022-07-20 18:16:57 - train: epoch 0060, iter [01800, 05004], lr: 0.077509, loss: 1.4883
2022-07-20 18:19:14 - train: epoch 0060, iter [01900, 05004], lr: 0.077445, loss: 1.4766
2022-07-20 18:21:30 - train: epoch 0060, iter [02000, 05004], lr: 0.077381, loss: 1.1135
2022-07-20 18:23:47 - train: epoch 0060, iter [02100, 05004], lr: 0.077316, loss: 1.5100
2022-07-20 18:26:03 - train: epoch 0060, iter [02200, 05004], lr: 0.077252, loss: 1.5394
2022-07-20 18:28:20 - train: epoch 0060, iter [02300, 05004], lr: 0.077188, loss: 1.4263
2022-07-20 18:30:37 - train: epoch 0060, iter [02400, 05004], lr: 0.077123, loss: 1.2797
2022-07-20 18:32:53 - train: epoch 0060, iter [02500, 05004], lr: 0.077059, loss: 1.3196
2022-07-20 18:35:10 - train: epoch 0060, iter [02600, 05004], lr: 0.076995, loss: 1.5904
2022-07-20 18:37:27 - train: epoch 0060, iter [02700, 05004], lr: 0.076930, loss: 1.3452
2022-07-20 18:39:44 - train: epoch 0060, iter [02800, 05004], lr: 0.076866, loss: 1.4010
2022-07-20 18:42:00 - train: epoch 0060, iter [02900, 05004], lr: 0.076802, loss: 1.4447
2022-07-20 18:44:17 - train: epoch 0060, iter [03000, 05004], lr: 0.076737, loss: 1.2839
2022-07-20 18:46:34 - train: epoch 0060, iter [03100, 05004], lr: 0.076673, loss: 1.4718
2022-07-20 18:48:50 - train: epoch 0060, iter [03200, 05004], lr: 0.076609, loss: 1.3828
2022-07-20 18:51:07 - train: epoch 0060, iter [03300, 05004], lr: 0.076545, loss: 1.1047
2022-07-20 18:53:24 - train: epoch 0060, iter [03400, 05004], lr: 0.076480, loss: 1.5602
2022-07-20 18:55:41 - train: epoch 0060, iter [03500, 05004], lr: 0.076416, loss: 1.5538
2022-07-20 18:57:57 - train: epoch 0060, iter [03600, 05004], lr: 0.076352, loss: 1.4162
2022-07-20 19:00:14 - train: epoch 0060, iter [03700, 05004], lr: 0.076288, loss: 1.4188
2022-07-20 19:02:31 - train: epoch 0060, iter [03800, 05004], lr: 0.076224, loss: 1.3477
2022-07-20 19:04:48 - train: epoch 0060, iter [03900, 05004], lr: 0.076159, loss: 1.4495
2022-07-20 19:07:05 - train: epoch 0060, iter [04000, 05004], lr: 0.076095, loss: 1.3021
2022-07-20 19:09:22 - train: epoch 0060, iter [04100, 05004], lr: 0.076031, loss: 1.6445
2022-07-20 19:11:39 - train: epoch 0060, iter [04200, 05004], lr: 0.075967, loss: 1.4625
2022-07-20 19:13:55 - train: epoch 0060, iter [04300, 05004], lr: 0.075903, loss: 1.1808
2022-07-20 19:16:12 - train: epoch 0060, iter [04400, 05004], lr: 0.075839, loss: 1.5053
2022-07-20 19:18:29 - train: epoch 0060, iter [04500, 05004], lr: 0.075774, loss: 1.4665
2022-07-20 19:20:45 - train: epoch 0060, iter [04600, 05004], lr: 0.075710, loss: 1.2841
2022-07-20 19:23:02 - train: epoch 0060, iter [04700, 05004], lr: 0.075646, loss: 1.2844
2022-07-20 19:25:19 - train: epoch 0060, iter [04800, 05004], lr: 0.075582, loss: 1.3404
2022-07-20 19:27:36 - train: epoch 0060, iter [04900, 05004], lr: 0.075518, loss: 1.3907
2022-07-20 19:29:52 - train: epoch 0060, iter [05000, 05004], lr: 0.075454, loss: 1.4839
2022-07-20 19:29:59 - train: epoch 060, train_loss: 1.3840
2022-07-20 19:32:07 - eval: epoch: 060, acc1: 69.956%, acc5: 89.946%, test_loss: 1.2173, per_image_load_time: 1.067ms, per_image_inference_time: 3.900ms
2022-07-20 19:32:08 - until epoch: 060, best_acc1: 69.956%
2022-07-20 19:32:08 - epoch 061 lr: 0.075451
2022-07-20 19:34:32 - train: epoch 0061, iter [00100, 05004], lr: 0.075387, loss: 1.1109
2022-07-20 19:36:49 - train: epoch 0061, iter [00200, 05004], lr: 0.075323, loss: 1.4665
2022-07-20 19:39:06 - train: epoch 0061, iter [00300, 05004], lr: 0.075259, loss: 1.1525
2022-07-20 19:41:22 - train: epoch 0061, iter [00400, 05004], lr: 0.075195, loss: 1.5021
2022-07-20 19:43:39 - train: epoch 0061, iter [00500, 05004], lr: 0.075131, loss: 1.3581
2022-07-20 19:45:56 - train: epoch 0061, iter [00600, 05004], lr: 0.075067, loss: 1.4530
2022-07-20 19:48:12 - train: epoch 0061, iter [00700, 05004], lr: 0.075003, loss: 1.2807
2022-07-20 19:50:29 - train: epoch 0061, iter [00800, 05004], lr: 0.074939, loss: 1.3268
2022-07-20 19:52:46 - train: epoch 0061, iter [00900, 05004], lr: 0.074875, loss: 1.4314
2022-07-20 19:55:02 - train: epoch 0061, iter [01000, 05004], lr: 0.074811, loss: 1.1137
2022-07-20 19:57:19 - train: epoch 0061, iter [01100, 05004], lr: 0.074747, loss: 1.1569
2022-07-20 19:59:36 - train: epoch 0061, iter [01200, 05004], lr: 0.074683, loss: 1.3011
2022-07-20 20:01:53 - train: epoch 0061, iter [01300, 05004], lr: 0.074620, loss: 1.1799
2022-07-20 20:04:09 - train: epoch 0061, iter [01400, 05004], lr: 0.074556, loss: 1.2516
2022-07-20 20:06:26 - train: epoch 0061, iter [01500, 05004], lr: 0.074492, loss: 1.5394
2022-07-20 20:08:43 - train: epoch 0061, iter [01600, 05004], lr: 0.074428, loss: 1.1699
2022-07-20 20:11:00 - train: epoch 0061, iter [01700, 05004], lr: 0.074364, loss: 1.4511
2022-07-20 20:13:17 - train: epoch 0061, iter [01800, 05004], lr: 0.074300, loss: 1.2897
2022-07-20 20:15:34 - train: epoch 0061, iter [01900, 05004], lr: 0.074236, loss: 1.7355
2022-07-20 20:17:51 - train: epoch 0061, iter [02000, 05004], lr: 0.074172, loss: 1.3286
2022-07-20 20:20:07 - train: epoch 0061, iter [02100, 05004], lr: 0.074109, loss: 1.7644
2022-07-20 20:22:24 - train: epoch 0061, iter [02200, 05004], lr: 0.074045, loss: 1.3301
2022-07-20 20:24:41 - train: epoch 0061, iter [02300, 05004], lr: 0.073981, loss: 1.3406
2022-07-20 20:26:58 - train: epoch 0061, iter [02400, 05004], lr: 0.073917, loss: 1.2351
2022-07-20 20:29:15 - train: epoch 0061, iter [02500, 05004], lr: 0.073853, loss: 1.3612
2022-07-20 20:31:32 - train: epoch 0061, iter [02600, 05004], lr: 0.073790, loss: 1.5354
2022-07-20 20:33:49 - train: epoch 0061, iter [02700, 05004], lr: 0.073726, loss: 1.6186
2022-07-20 20:36:06 - train: epoch 0061, iter [02800, 05004], lr: 0.073662, loss: 1.4053
2022-07-20 20:38:23 - train: epoch 0061, iter [02900, 05004], lr: 0.073598, loss: 1.5278
2022-07-20 20:40:40 - train: epoch 0061, iter [03000, 05004], lr: 0.073534, loss: 1.4074
2022-07-20 20:42:57 - train: epoch 0061, iter [03100, 05004], lr: 0.073471, loss: 1.3512
2022-07-20 20:45:14 - train: epoch 0061, iter [03200, 05004], lr: 0.073407, loss: 1.2913
2022-07-20 20:47:31 - train: epoch 0061, iter [03300, 05004], lr: 0.073343, loss: 1.2406
2022-07-20 20:49:48 - train: epoch 0061, iter [03400, 05004], lr: 0.073280, loss: 1.3953
2022-07-20 20:52:05 - train: epoch 0061, iter [03500, 05004], lr: 0.073216, loss: 1.4516
2022-07-20 20:54:21 - train: epoch 0061, iter [03600, 05004], lr: 0.073152, loss: 1.3782
2022-07-20 20:56:38 - train: epoch 0061, iter [03700, 05004], lr: 0.073089, loss: 1.3214
2022-07-20 20:58:55 - train: epoch 0061, iter [03800, 05004], lr: 0.073025, loss: 1.3644
2022-07-20 21:01:12 - train: epoch 0061, iter [03900, 05004], lr: 0.072961, loss: 1.3903
2022-07-20 21:03:29 - train: epoch 0061, iter [04000, 05004], lr: 0.072898, loss: 1.3509
2022-07-20 21:05:46 - train: epoch 0061, iter [04100, 05004], lr: 0.072834, loss: 1.6215
2022-07-20 21:08:03 - train: epoch 0061, iter [04200, 05004], lr: 0.072771, loss: 1.3002
2022-07-20 21:10:20 - train: epoch 0061, iter [04300, 05004], lr: 0.072707, loss: 1.5056
2022-07-20 21:12:37 - train: epoch 0061, iter [04400, 05004], lr: 0.072643, loss: 1.5560
2022-07-20 21:14:54 - train: epoch 0061, iter [04500, 05004], lr: 0.072580, loss: 1.4579
2022-07-20 21:17:11 - train: epoch 0061, iter [04600, 05004], lr: 0.072516, loss: 1.4221
2022-07-20 21:19:28 - train: epoch 0061, iter [04700, 05004], lr: 0.072453, loss: 1.3352
2022-07-20 21:21:45 - train: epoch 0061, iter [04800, 05004], lr: 0.072389, loss: 1.4605
2022-07-20 21:24:03 - train: epoch 0061, iter [04900, 05004], lr: 0.072326, loss: 1.4462
2022-07-20 21:26:20 - train: epoch 0061, iter [05000, 05004], lr: 0.072262, loss: 1.5901
2022-07-20 21:26:26 - train: epoch 061, train_loss: 1.3659
2022-07-20 21:28:34 - eval: epoch: 061, acc1: 69.262%, acc5: 89.662%, test_loss: 1.2459, per_image_load_time: 1.022ms, per_image_inference_time: 3.910ms
2022-07-20 21:28:34 - until epoch: 061, best_acc1: 69.956%
2022-07-20 21:28:34 - epoch 062 lr: 0.072259
2022-07-20 21:30:59 - train: epoch 0062, iter [00100, 05004], lr: 0.072196, loss: 1.4308
2022-07-20 21:33:16 - train: epoch 0062, iter [00200, 05004], lr: 0.072133, loss: 1.4797
2022-07-20 21:35:33 - train: epoch 0062, iter [00300, 05004], lr: 0.072069, loss: 1.3075
2022-07-20 21:37:50 - train: epoch 0062, iter [00400, 05004], lr: 0.072006, loss: 1.1341
2022-07-20 21:40:08 - train: epoch 0062, iter [00500, 05004], lr: 0.071942, loss: 1.4306
2022-07-20 21:42:24 - train: epoch 0062, iter [00600, 05004], lr: 0.071879, loss: 1.3412
2022-07-20 21:44:41 - train: epoch 0062, iter [00700, 05004], lr: 0.071816, loss: 1.3481
2022-07-20 21:46:59 - train: epoch 0062, iter [00800, 05004], lr: 0.071752, loss: 1.3080
2022-07-20 21:49:16 - train: epoch 0062, iter [00900, 05004], lr: 0.071689, loss: 1.4102
2022-07-20 21:51:33 - train: epoch 0062, iter [01000, 05004], lr: 0.071625, loss: 1.4889
2022-07-20 21:53:51 - train: epoch 0062, iter [01100, 05004], lr: 0.071562, loss: 1.2015
2022-07-20 21:56:09 - train: epoch 0062, iter [01200, 05004], lr: 0.071499, loss: 1.5296
2022-07-20 21:58:26 - train: epoch 0062, iter [01300, 05004], lr: 0.071435, loss: 1.3443
2022-07-20 22:00:43 - train: epoch 0062, iter [01400, 05004], lr: 0.071372, loss: 1.1592
2022-07-20 22:03:00 - train: epoch 0062, iter [01500, 05004], lr: 0.071309, loss: 1.3488
2022-07-20 22:05:18 - train: epoch 0062, iter [01600, 05004], lr: 0.071245, loss: 1.5694
2022-07-20 22:07:35 - train: epoch 0062, iter [01700, 05004], lr: 0.071182, loss: 1.5325
2022-07-20 22:09:52 - train: epoch 0062, iter [01800, 05004], lr: 0.071119, loss: 1.3165
2022-07-20 22:12:09 - train: epoch 0062, iter [01900, 05004], lr: 0.071056, loss: 1.2827
2022-07-20 22:14:26 - train: epoch 0062, iter [02000, 05004], lr: 0.070992, loss: 1.3450
2022-07-20 22:16:43 - train: epoch 0062, iter [02100, 05004], lr: 0.070929, loss: 1.5257
2022-07-20 22:19:00 - train: epoch 0062, iter [02200, 05004], lr: 0.070866, loss: 1.5105
2022-07-20 22:21:17 - train: epoch 0062, iter [02300, 05004], lr: 0.070803, loss: 1.3752
2022-07-20 22:23:34 - train: epoch 0062, iter [02400, 05004], lr: 0.070739, loss: 1.3893
2022-07-20 22:25:50 - train: epoch 0062, iter [02500, 05004], lr: 0.070676, loss: 1.5374
2022-07-20 22:28:07 - train: epoch 0062, iter [02600, 05004], lr: 0.070613, loss: 1.3327
2022-07-20 22:30:24 - train: epoch 0062, iter [02700, 05004], lr: 0.070550, loss: 1.3451
2022-07-20 22:32:41 - train: epoch 0062, iter [02800, 05004], lr: 0.070487, loss: 1.4686
2022-07-20 22:34:58 - train: epoch 0062, iter [02900, 05004], lr: 0.070424, loss: 1.2519
2022-07-20 22:37:15 - train: epoch 0062, iter [03000, 05004], lr: 0.070361, loss: 1.5255
2022-07-20 22:39:32 - train: epoch 0062, iter [03100, 05004], lr: 0.070297, loss: 1.6264
2022-07-20 22:41:48 - train: epoch 0062, iter [03200, 05004], lr: 0.070234, loss: 1.3788
2022-07-20 22:44:05 - train: epoch 0062, iter [03300, 05004], lr: 0.070171, loss: 1.2477
2022-07-20 22:46:22 - train: epoch 0062, iter [03400, 05004], lr: 0.070108, loss: 1.2664
2022-07-20 22:48:39 - train: epoch 0062, iter [03500, 05004], lr: 0.070045, loss: 1.4666
2022-07-20 22:50:55 - train: epoch 0062, iter [03600, 05004], lr: 0.069982, loss: 1.4916
2022-07-20 22:53:12 - train: epoch 0062, iter [03700, 05004], lr: 0.069919, loss: 1.2768
2022-07-20 22:55:29 - train: epoch 0062, iter [03800, 05004], lr: 0.069856, loss: 1.2239
2022-07-20 22:57:46 - train: epoch 0062, iter [03900, 05004], lr: 0.069793, loss: 1.4733
2022-07-20 23:00:03 - train: epoch 0062, iter [04000, 05004], lr: 0.069730, loss: 1.2008
2022-07-20 23:02:20 - train: epoch 0062, iter [04100, 05004], lr: 0.069667, loss: 1.4582
2022-07-20 23:04:37 - train: epoch 0062, iter [04200, 05004], lr: 0.069604, loss: 1.2334
