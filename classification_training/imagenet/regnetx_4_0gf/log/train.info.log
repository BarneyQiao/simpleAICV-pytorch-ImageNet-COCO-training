2022-07-23 23:08:21 - train: epoch 0099, iter [04700, 05004], lr: 0.000062, loss: 0.5988
2022-07-23 23:10:38 - train: epoch 0099, iter [04800, 05004], lr: 0.000059, loss: 0.5748
2022-07-23 23:12:55 - train: epoch 0099, iter [04900, 05004], lr: 0.000057, loss: 0.7170
2022-07-23 23:15:13 - train: epoch 0099, iter [05000, 05004], lr: 0.000055, loss: 0.5609
2022-07-23 23:15:19 - train: epoch 099, train_loss: 0.5695
2022-07-23 23:17:25 - eval: epoch: 099, acc1: 77.676%, acc5: 93.810%, test_loss: 0.9308, per_image_load_time: 0.995ms, per_image_inference_time: 3.913ms
2022-07-23 23:17:25 - until epoch: 099, best_acc1: 77.714%
2022-07-23 23:17:25 - epoch 100 lr: 0.000055
2022-07-23 23:19:50 - train: epoch 0100, iter [00100, 05004], lr: 0.000053, loss: 0.5088
2022-07-23 23:22:07 - train: epoch 0100, iter [00200, 05004], lr: 0.000050, loss: 0.7270
2022-07-23 23:24:25 - train: epoch 0100, iter [00300, 05004], lr: 0.000048, loss: 0.5093
2022-07-23 23:26:42 - train: epoch 0100, iter [00400, 05004], lr: 0.000046, loss: 0.6247
2022-07-23 23:28:59 - train: epoch 0100, iter [00500, 05004], lr: 0.000044, loss: 0.6322
2022-07-23 23:31:16 - train: epoch 0100, iter [00600, 05004], lr: 0.000042, loss: 0.5929
2022-07-23 23:33:33 - train: epoch 0100, iter [00700, 05004], lr: 0.000040, loss: 0.6386
2022-07-23 23:35:50 - train: epoch 0100, iter [00800, 05004], lr: 0.000039, loss: 0.4936
2022-07-23 23:38:07 - train: epoch 0100, iter [00900, 05004], lr: 0.000037, loss: 0.4359
2022-07-23 23:40:24 - train: epoch 0100, iter [01000, 05004], lr: 0.000035, loss: 0.5115
2022-07-23 23:42:41 - train: epoch 0100, iter [01100, 05004], lr: 0.000033, loss: 0.5603
2022-07-23 23:44:58 - train: epoch 0100, iter [01200, 05004], lr: 0.000032, loss: 0.5099
2022-07-23 23:47:15 - train: epoch 0100, iter [01300, 05004], lr: 0.000030, loss: 0.5401
2022-07-23 23:49:32 - train: epoch 0100, iter [01400, 05004], lr: 0.000028, loss: 0.6388
2022-07-23 23:51:50 - train: epoch 0100, iter [01500, 05004], lr: 0.000027, loss: 0.5047
2022-07-23 23:54:07 - train: epoch 0100, iter [01600, 05004], lr: 0.000025, loss: 0.4551
2022-07-23 23:56:24 - train: epoch 0100, iter [01700, 05004], lr: 0.000024, loss: 0.4915
2022-07-23 23:58:41 - train: epoch 0100, iter [01800, 05004], lr: 0.000022, loss: 0.4758
2022-07-24 00:00:58 - train: epoch 0100, iter [01900, 05004], lr: 0.000021, loss: 0.6899
2022-07-24 00:03:15 - train: epoch 0100, iter [02000, 05004], lr: 0.000020, loss: 0.6418
2022-07-24 00:05:32 - train: epoch 0100, iter [02100, 05004], lr: 0.000018, loss: 0.4967
2022-07-24 00:07:49 - train: epoch 0100, iter [02200, 05004], lr: 0.000017, loss: 0.6507
2022-07-24 00:10:06 - train: epoch 0100, iter [02300, 05004], lr: 0.000016, loss: 0.6199
2022-07-24 00:12:24 - train: epoch 0100, iter [02400, 05004], lr: 0.000015, loss: 0.6002
2022-07-24 00:14:41 - train: epoch 0100, iter [02500, 05004], lr: 0.000014, loss: 0.5707
2022-07-24 00:16:58 - train: epoch 0100, iter [02600, 05004], lr: 0.000013, loss: 0.4607
2022-07-24 00:19:16 - train: epoch 0100, iter [02700, 05004], lr: 0.000012, loss: 0.3464
2022-07-24 00:21:33 - train: epoch 0100, iter [02800, 05004], lr: 0.000011, loss: 0.4882
2022-07-24 00:23:51 - train: epoch 0100, iter [02900, 05004], lr: 0.000010, loss: 0.6079
2022-07-24 00:26:08 - train: epoch 0100, iter [03000, 05004], lr: 0.000009, loss: 0.6705
2022-07-24 00:28:25 - train: epoch 0100, iter [03100, 05004], lr: 0.000008, loss: 0.4889
2022-07-24 00:30:42 - train: epoch 0100, iter [03200, 05004], lr: 0.000007, loss: 0.5348
2022-07-24 00:32:59 - train: epoch 0100, iter [03300, 05004], lr: 0.000006, loss: 0.6065
2022-07-24 00:35:17 - train: epoch 0100, iter [03400, 05004], lr: 0.000006, loss: 0.6230
2022-07-24 00:37:35 - train: epoch 0100, iter [03500, 05004], lr: 0.000005, loss: 0.5051
2022-07-24 00:39:52 - train: epoch 0100, iter [03600, 05004], lr: 0.000004, loss: 0.5043
2022-07-24 00:42:10 - train: epoch 0100, iter [03700, 05004], lr: 0.000004, loss: 0.5199
2022-07-24 00:44:27 - train: epoch 0100, iter [03800, 05004], lr: 0.000003, loss: 0.5393
2022-07-24 00:46:45 - train: epoch 0100, iter [03900, 05004], lr: 0.000003, loss: 0.5045
2022-07-24 00:49:03 - train: epoch 0100, iter [04000, 05004], lr: 0.000002, loss: 0.4322
2022-07-24 00:51:20 - train: epoch 0100, iter [04100, 05004], lr: 0.000002, loss: 0.6300
2022-07-24 00:53:38 - train: epoch 0100, iter [04200, 05004], lr: 0.000001, loss: 0.5845
2022-07-24 00:55:56 - train: epoch 0100, iter [04300, 05004], lr: 0.000001, loss: 0.5407
2022-07-24 00:58:13 - train: epoch 0100, iter [04400, 05004], lr: 0.000001, loss: 0.6086
2022-07-24 01:00:31 - train: epoch 0100, iter [04500, 05004], lr: 0.000001, loss: 0.5445
2022-07-24 01:02:48 - train: epoch 0100, iter [04600, 05004], lr: 0.000000, loss: 0.5731
2022-07-24 01:05:06 - train: epoch 0100, iter [04700, 05004], lr: 0.000000, loss: 0.6772
2022-07-24 01:07:23 - train: epoch 0100, iter [04800, 05004], lr: 0.000000, loss: 0.4282
2022-07-24 01:09:41 - train: epoch 0100, iter [04900, 05004], lr: 0.000000, loss: 0.6043
2022-07-24 01:11:58 - train: epoch 0100, iter [05000, 05004], lr: 0.000000, loss: 0.5427
2022-07-24 01:12:05 - train: epoch 100, train_loss: 0.5672
2022-07-24 01:14:12 - eval: epoch: 100, acc1: 77.680%, acc5: 93.846%, test_loss: 0.9315, per_image_load_time: 1.028ms, per_image_inference_time: 3.927ms
2022-07-24 01:14:12 - until epoch: 100, best_acc1: 77.714%
2022-07-24 01:14:12 - train done. model: RegNetX_4_0GF, train time: 194.207 hours, best_acc1: 77.714%
