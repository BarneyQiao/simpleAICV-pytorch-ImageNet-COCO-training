2022-06-29 01:32:51 - train: epoch 0051, iter [04300, 05004], lr: 0.010000, loss: 1.0632
2022-06-29 01:33:23 - train: epoch 0051, iter [04400, 05004], lr: 0.010000, loss: 1.1378
2022-06-29 01:33:55 - train: epoch 0051, iter [04500, 05004], lr: 0.010000, loss: 0.9765
2022-06-29 01:34:27 - train: epoch 0051, iter [04600, 05004], lr: 0.010000, loss: 1.1747
2022-06-29 01:35:00 - train: epoch 0051, iter [04700, 05004], lr: 0.010000, loss: 1.0536
2022-06-29 01:35:32 - train: epoch 0051, iter [04800, 05004], lr: 0.010000, loss: 1.0496
2022-06-29 01:36:04 - train: epoch 0051, iter [04900, 05004], lr: 0.010000, loss: 1.1760
2022-06-29 01:36:36 - train: epoch 0051, iter [05000, 05004], lr: 0.010000, loss: 1.0036
2022-06-29 01:36:37 - train: epoch 051, train_loss: 1.0794
2022-06-29 01:37:51 - eval: epoch: 051, acc1: 72.876%, acc5: 91.372%, test_loss: 1.0850, per_image_load_time: 1.346ms, per_image_inference_time: 0.701ms
2022-06-29 01:37:52 - until epoch: 051, best_acc1: 73.678%
2022-06-29 01:37:52 - epoch 052 lr: 0.010000
2022-06-29 01:38:30 - train: epoch 0052, iter [00100, 05004], lr: 0.010000, loss: 0.9320
2022-06-29 01:39:01 - train: epoch 0052, iter [00200, 05004], lr: 0.010000, loss: 1.0684
2022-06-29 01:39:33 - train: epoch 0052, iter [00300, 05004], lr: 0.010000, loss: 1.2080
2022-06-29 01:40:04 - train: epoch 0052, iter [00400, 05004], lr: 0.010000, loss: 1.1638
2022-06-29 01:40:36 - train: epoch 0052, iter [00500, 05004], lr: 0.010000, loss: 1.1607
2022-06-29 01:41:09 - train: epoch 0052, iter [00600, 05004], lr: 0.010000, loss: 0.9657
2022-06-29 01:41:41 - train: epoch 0052, iter [00700, 05004], lr: 0.010000, loss: 1.1045
2022-06-29 01:42:12 - train: epoch 0052, iter [00800, 05004], lr: 0.010000, loss: 1.1252
2022-06-29 01:42:45 - train: epoch 0052, iter [00900, 05004], lr: 0.010000, loss: 1.1068
2022-06-29 01:43:17 - train: epoch 0052, iter [01000, 05004], lr: 0.010000, loss: 1.1688
2022-06-29 01:43:49 - train: epoch 0052, iter [01100, 05004], lr: 0.010000, loss: 1.0375
2022-06-29 01:44:21 - train: epoch 0052, iter [01200, 05004], lr: 0.010000, loss: 1.0246
2022-06-29 01:44:53 - train: epoch 0052, iter [01300, 05004], lr: 0.010000, loss: 1.0043
2022-06-29 01:45:25 - train: epoch 0052, iter [01400, 05004], lr: 0.010000, loss: 1.3378
2022-06-29 01:45:57 - train: epoch 0052, iter [01500, 05004], lr: 0.010000, loss: 0.9238
2022-06-29 01:46:29 - train: epoch 0052, iter [01600, 05004], lr: 0.010000, loss: 0.9299
2022-06-29 01:47:01 - train: epoch 0052, iter [01700, 05004], lr: 0.010000, loss: 0.9062
2022-06-29 01:47:33 - train: epoch 0052, iter [01800, 05004], lr: 0.010000, loss: 0.8505
2022-06-29 01:48:05 - train: epoch 0052, iter [01900, 05004], lr: 0.010000, loss: 1.1292
2022-06-29 01:48:37 - train: epoch 0052, iter [02000, 05004], lr: 0.010000, loss: 1.1354
2022-06-29 01:49:10 - train: epoch 0052, iter [02100, 05004], lr: 0.010000, loss: 0.9985
2022-06-29 01:49:42 - train: epoch 0052, iter [02200, 05004], lr: 0.010000, loss: 1.1548
2022-06-29 01:50:14 - train: epoch 0052, iter [02300, 05004], lr: 0.010000, loss: 0.9379
2022-06-29 01:50:45 - train: epoch 0052, iter [02400, 05004], lr: 0.010000, loss: 1.0249
2022-06-29 01:51:17 - train: epoch 0052, iter [02500, 05004], lr: 0.010000, loss: 1.1329
2022-06-29 01:51:49 - train: epoch 0052, iter [02600, 05004], lr: 0.010000, loss: 0.8794
2022-06-29 01:52:21 - train: epoch 0052, iter [02700, 05004], lr: 0.010000, loss: 1.0081
2022-06-29 01:52:53 - train: epoch 0052, iter [02800, 05004], lr: 0.010000, loss: 1.1151
2022-06-29 01:53:25 - train: epoch 0052, iter [02900, 05004], lr: 0.010000, loss: 0.9926
2022-06-29 01:53:57 - train: epoch 0052, iter [03000, 05004], lr: 0.010000, loss: 1.0591
2022-06-29 01:54:29 - train: epoch 0052, iter [03100, 05004], lr: 0.010000, loss: 1.0472
2022-06-29 01:55:01 - train: epoch 0052, iter [03200, 05004], lr: 0.010000, loss: 1.2154
2022-06-29 01:55:33 - train: epoch 0052, iter [03300, 05004], lr: 0.010000, loss: 1.1610
2022-06-29 01:56:05 - train: epoch 0052, iter [03400, 05004], lr: 0.010000, loss: 1.1793
2022-06-29 01:56:37 - train: epoch 0052, iter [03500, 05004], lr: 0.010000, loss: 1.1605
2022-06-29 01:57:10 - train: epoch 0052, iter [03600, 05004], lr: 0.010000, loss: 1.1390
2022-06-29 01:57:42 - train: epoch 0052, iter [03700, 05004], lr: 0.010000, loss: 1.2186
2022-06-29 01:58:14 - train: epoch 0052, iter [03800, 05004], lr: 0.010000, loss: 1.0522
2022-06-29 01:58:46 - train: epoch 0052, iter [03900, 05004], lr: 0.010000, loss: 1.0295
2022-06-29 01:59:18 - train: epoch 0052, iter [04000, 05004], lr: 0.010000, loss: 1.1767
2022-06-29 01:59:50 - train: epoch 0052, iter [04100, 05004], lr: 0.010000, loss: 1.0104
2022-06-29 02:00:22 - train: epoch 0052, iter [04200, 05004], lr: 0.010000, loss: 1.0109
2022-06-29 02:00:54 - train: epoch 0052, iter [04300, 05004], lr: 0.010000, loss: 1.0687
2022-06-29 02:01:26 - train: epoch 0052, iter [04400, 05004], lr: 0.010000, loss: 1.0813
2022-06-29 02:01:58 - train: epoch 0052, iter [04500, 05004], lr: 0.010000, loss: 1.0378
2022-06-29 02:02:30 - train: epoch 0052, iter [04600, 05004], lr: 0.010000, loss: 1.2170
2022-06-29 02:03:02 - train: epoch 0052, iter [04700, 05004], lr: 0.010000, loss: 1.0150
2022-06-29 02:03:34 - train: epoch 0052, iter [04800, 05004], lr: 0.010000, loss: 0.9286
2022-06-29 02:04:06 - train: epoch 0052, iter [04900, 05004], lr: 0.010000, loss: 1.0121
2022-06-29 02:04:38 - train: epoch 0052, iter [05000, 05004], lr: 0.010000, loss: 1.1018
2022-06-29 02:04:40 - train: epoch 052, train_loss: 1.0745
2022-06-29 02:05:53 - eval: epoch: 052, acc1: 72.442%, acc5: 91.052%, test_loss: 1.1032, per_image_load_time: 1.481ms, per_image_inference_time: 0.693ms
2022-06-29 02:05:54 - until epoch: 052, best_acc1: 73.678%
2022-06-29 02:05:54 - epoch 053 lr: 0.010000
2022-06-29 02:06:32 - train: epoch 0053, iter [00100, 05004], lr: 0.010000, loss: 0.9470
2022-06-29 02:07:04 - train: epoch 0053, iter [00200, 05004], lr: 0.010000, loss: 1.2277
2022-06-29 02:07:36 - train: epoch 0053, iter [00300, 05004], lr: 0.010000, loss: 1.0501
2022-06-29 02:08:07 - train: epoch 0053, iter [00400, 05004], lr: 0.010000, loss: 1.1691
2022-06-29 02:08:39 - train: epoch 0053, iter [00500, 05004], lr: 0.010000, loss: 1.1623
2022-06-29 02:09:11 - train: epoch 0053, iter [00600, 05004], lr: 0.010000, loss: 1.0491
2022-06-29 02:09:43 - train: epoch 0053, iter [00700, 05004], lr: 0.010000, loss: 0.9232
2022-06-29 02:10:15 - train: epoch 0053, iter [00800, 05004], lr: 0.010000, loss: 1.0892
2022-06-29 02:10:47 - train: epoch 0053, iter [00900, 05004], lr: 0.010000, loss: 1.0248
2022-06-29 02:11:19 - train: epoch 0053, iter [01000, 05004], lr: 0.010000, loss: 0.9596
2022-06-29 02:11:50 - train: epoch 0053, iter [01100, 05004], lr: 0.010000, loss: 1.0288
2022-06-29 02:12:22 - train: epoch 0053, iter [01200, 05004], lr: 0.010000, loss: 0.9803
2022-06-29 02:12:54 - train: epoch 0053, iter [01300, 05004], lr: 0.010000, loss: 1.1232
2022-06-29 02:13:26 - train: epoch 0053, iter [01400, 05004], lr: 0.010000, loss: 1.3108
2022-06-29 02:13:58 - train: epoch 0053, iter [01500, 05004], lr: 0.010000, loss: 1.0097
2022-06-29 02:14:29 - train: epoch 0053, iter [01600, 05004], lr: 0.010000, loss: 1.3304
2022-06-29 02:15:01 - train: epoch 0053, iter [01700, 05004], lr: 0.010000, loss: 1.2349
2022-06-29 02:15:33 - train: epoch 0053, iter [01800, 05004], lr: 0.010000, loss: 1.2039
2022-06-29 02:16:05 - train: epoch 0053, iter [01900, 05004], lr: 0.010000, loss: 0.9014
2022-06-29 02:16:36 - train: epoch 0053, iter [02000, 05004], lr: 0.010000, loss: 1.0002
2022-06-29 02:17:08 - train: epoch 0053, iter [02100, 05004], lr: 0.010000, loss: 1.0321
2022-06-29 02:17:40 - train: epoch 0053, iter [02200, 05004], lr: 0.010000, loss: 1.0404
2022-06-29 02:18:12 - train: epoch 0053, iter [02300, 05004], lr: 0.010000, loss: 1.0406
2022-06-29 02:18:44 - train: epoch 0053, iter [02400, 05004], lr: 0.010000, loss: 1.0903
2022-06-29 02:19:16 - train: epoch 0053, iter [02500, 05004], lr: 0.010000, loss: 1.2295
2022-06-29 02:19:48 - train: epoch 0053, iter [02600, 05004], lr: 0.010000, loss: 1.1053
2022-06-29 02:20:20 - train: epoch 0053, iter [02700, 05004], lr: 0.010000, loss: 1.2522
2022-06-29 02:20:52 - train: epoch 0053, iter [02800, 05004], lr: 0.010000, loss: 1.1530
2022-06-29 02:21:25 - train: epoch 0053, iter [02900, 05004], lr: 0.010000, loss: 0.9830
2022-06-29 02:21:56 - train: epoch 0053, iter [03000, 05004], lr: 0.010000, loss: 0.9249
2022-06-29 02:22:28 - train: epoch 0053, iter [03100, 05004], lr: 0.010000, loss: 1.2519
2022-06-29 02:23:00 - train: epoch 0053, iter [03200, 05004], lr: 0.010000, loss: 1.2950
2022-06-29 02:23:32 - train: epoch 0053, iter [03300, 05004], lr: 0.010000, loss: 1.0346
2022-06-29 02:24:05 - train: epoch 0053, iter [03400, 05004], lr: 0.010000, loss: 1.2265
2022-06-29 02:24:37 - train: epoch 0053, iter [03500, 05004], lr: 0.010000, loss: 1.1507
2022-06-29 02:25:09 - train: epoch 0053, iter [03600, 05004], lr: 0.010000, loss: 1.2473
2022-06-29 02:25:41 - train: epoch 0053, iter [03700, 05004], lr: 0.010000, loss: 1.2446
2022-06-29 02:26:13 - train: epoch 0053, iter [03800, 05004], lr: 0.010000, loss: 1.1155
2022-06-29 02:26:45 - train: epoch 0053, iter [03900, 05004], lr: 0.010000, loss: 1.1366
2022-06-29 02:27:17 - train: epoch 0053, iter [04000, 05004], lr: 0.010000, loss: 1.1446
2022-06-29 02:27:49 - train: epoch 0053, iter [04100, 05004], lr: 0.010000, loss: 1.1817
2022-06-29 02:28:22 - train: epoch 0053, iter [04200, 05004], lr: 0.010000, loss: 1.0904
2022-06-29 02:28:54 - train: epoch 0053, iter [04300, 05004], lr: 0.010000, loss: 1.3309
2022-06-29 02:29:26 - train: epoch 0053, iter [04400, 05004], lr: 0.010000, loss: 0.9980
2022-06-29 02:29:58 - train: epoch 0053, iter [04500, 05004], lr: 0.010000, loss: 1.1803
2022-06-29 02:30:30 - train: epoch 0053, iter [04600, 05004], lr: 0.010000, loss: 0.9998
2022-06-29 02:31:02 - train: epoch 0053, iter [04700, 05004], lr: 0.010000, loss: 1.2646
2022-06-29 02:31:34 - train: epoch 0053, iter [04800, 05004], lr: 0.010000, loss: 1.2517
2022-06-29 02:32:06 - train: epoch 0053, iter [04900, 05004], lr: 0.010000, loss: 0.9687
2022-06-29 02:32:38 - train: epoch 0053, iter [05000, 05004], lr: 0.010000, loss: 1.1039
2022-06-29 02:32:40 - train: epoch 053, train_loss: 1.0714
2022-06-29 02:33:53 - eval: epoch: 053, acc1: 72.880%, acc5: 91.338%, test_loss: 1.0885, per_image_load_time: 2.154ms, per_image_inference_time: 0.671ms
2022-06-29 02:33:54 - until epoch: 053, best_acc1: 73.678%
2022-06-29 02:33:54 - epoch 054 lr: 0.010000
2022-06-29 02:34:32 - train: epoch 0054, iter [00100, 05004], lr: 0.010000, loss: 0.9174
2022-06-29 02:35:03 - train: epoch 0054, iter [00200, 05004], lr: 0.010000, loss: 1.4514
2022-06-29 02:35:35 - train: epoch 0054, iter [00300, 05004], lr: 0.010000, loss: 1.0366
2022-06-29 02:36:06 - train: epoch 0054, iter [00400, 05004], lr: 0.010000, loss: 0.9094
2022-06-29 02:36:37 - train: epoch 0054, iter [00500, 05004], lr: 0.010000, loss: 1.0598
2022-06-29 02:37:09 - train: epoch 0054, iter [00600, 05004], lr: 0.010000, loss: 0.9254
2022-06-29 02:37:41 - train: epoch 0054, iter [00700, 05004], lr: 0.010000, loss: 1.1176
2022-06-29 02:38:13 - train: epoch 0054, iter [00800, 05004], lr: 0.010000, loss: 1.1896
2022-06-29 02:38:45 - train: epoch 0054, iter [00900, 05004], lr: 0.010000, loss: 0.9528
2022-06-29 02:39:17 - train: epoch 0054, iter [01000, 05004], lr: 0.010000, loss: 0.8925
2022-06-29 02:39:49 - train: epoch 0054, iter [01100, 05004], lr: 0.010000, loss: 0.9563
2022-06-29 02:40:21 - train: epoch 0054, iter [01200, 05004], lr: 0.010000, loss: 1.1207
2022-06-29 02:40:53 - train: epoch 0054, iter [01300, 05004], lr: 0.010000, loss: 0.9346
2022-06-29 02:41:24 - train: epoch 0054, iter [01400, 05004], lr: 0.010000, loss: 1.0681
2022-06-29 02:41:56 - train: epoch 0054, iter [01500, 05004], lr: 0.010000, loss: 1.0970
2022-06-29 02:42:28 - train: epoch 0054, iter [01600, 05004], lr: 0.010000, loss: 0.7837
2022-06-29 02:43:00 - train: epoch 0054, iter [01700, 05004], lr: 0.010000, loss: 1.0425
2022-06-29 02:43:32 - train: epoch 0054, iter [01800, 05004], lr: 0.010000, loss: 1.0577
2022-06-29 02:44:04 - train: epoch 0054, iter [01900, 05004], lr: 0.010000, loss: 1.3207
2022-06-29 02:44:36 - train: epoch 0054, iter [02000, 05004], lr: 0.010000, loss: 1.0989
2022-06-29 02:45:08 - train: epoch 0054, iter [02100, 05004], lr: 0.010000, loss: 0.9015
2022-06-29 02:45:40 - train: epoch 0054, iter [02200, 05004], lr: 0.010000, loss: 1.0300
2022-06-29 02:46:12 - train: epoch 0054, iter [02300, 05004], lr: 0.010000, loss: 1.1335
2022-06-29 02:46:44 - train: epoch 0054, iter [02400, 05004], lr: 0.010000, loss: 0.8737
2022-06-29 02:47:16 - train: epoch 0054, iter [02500, 05004], lr: 0.010000, loss: 1.0732
2022-06-29 02:47:48 - train: epoch 0054, iter [02600, 05004], lr: 0.010000, loss: 1.0220
2022-06-29 02:48:20 - train: epoch 0054, iter [02700, 05004], lr: 0.010000, loss: 1.1774
2022-06-29 02:48:52 - train: epoch 0054, iter [02800, 05004], lr: 0.010000, loss: 1.2784
2022-06-29 02:49:24 - train: epoch 0054, iter [02900, 05004], lr: 0.010000, loss: 1.0205
2022-06-29 02:49:55 - train: epoch 0054, iter [03000, 05004], lr: 0.010000, loss: 1.1443
2022-06-29 02:50:27 - train: epoch 0054, iter [03100, 05004], lr: 0.010000, loss: 1.0361
2022-06-29 02:50:59 - train: epoch 0054, iter [03200, 05004], lr: 0.010000, loss: 1.2548
2022-06-29 02:51:31 - train: epoch 0054, iter [03300, 05004], lr: 0.010000, loss: 0.9892
2022-06-29 02:52:03 - train: epoch 0054, iter [03400, 05004], lr: 0.010000, loss: 1.1558
2022-06-29 02:52:35 - train: epoch 0054, iter [03500, 05004], lr: 0.010000, loss: 1.2474
2022-06-29 02:53:07 - train: epoch 0054, iter [03600, 05004], lr: 0.010000, loss: 1.0706
2022-06-29 02:53:39 - train: epoch 0054, iter [03700, 05004], lr: 0.010000, loss: 1.0300
2022-06-29 02:54:11 - train: epoch 0054, iter [03800, 05004], lr: 0.010000, loss: 1.1049
2022-06-29 02:54:43 - train: epoch 0054, iter [03900, 05004], lr: 0.010000, loss: 1.0714
2022-06-29 02:55:14 - train: epoch 0054, iter [04000, 05004], lr: 0.010000, loss: 0.9519
2022-06-29 02:55:46 - train: epoch 0054, iter [04100, 05004], lr: 0.010000, loss: 1.0786
2022-06-29 02:56:18 - train: epoch 0054, iter [04200, 05004], lr: 0.010000, loss: 1.0483
2022-06-29 02:56:50 - train: epoch 0054, iter [04300, 05004], lr: 0.010000, loss: 1.0970
2022-06-29 02:57:22 - train: epoch 0054, iter [04400, 05004], lr: 0.010000, loss: 0.8687
2022-06-29 02:57:54 - train: epoch 0054, iter [04500, 05004], lr: 0.010000, loss: 0.9575
2022-06-29 02:58:26 - train: epoch 0054, iter [04600, 05004], lr: 0.010000, loss: 1.0818
2022-06-29 02:58:57 - train: epoch 0054, iter [04700, 05004], lr: 0.010000, loss: 1.1499
2022-06-29 02:59:29 - train: epoch 0054, iter [04800, 05004], lr: 0.010000, loss: 1.1964
2022-06-29 03:00:01 - train: epoch 0054, iter [04900, 05004], lr: 0.010000, loss: 0.9970
2022-06-29 03:00:33 - train: epoch 0054, iter [05000, 05004], lr: 0.010000, loss: 1.1051
2022-06-29 03:00:34 - train: epoch 054, train_loss: 1.0712
2022-06-29 03:01:47 - eval: epoch: 054, acc1: 72.556%, acc5: 91.168%, test_loss: 1.1029, per_image_load_time: 1.716ms, per_image_inference_time: 0.728ms
2022-06-29 03:01:48 - until epoch: 054, best_acc1: 73.678%
2022-06-29 03:01:48 - epoch 055 lr: 0.010000
2022-06-29 03:02:26 - train: epoch 0055, iter [00100, 05004], lr: 0.010000, loss: 0.9839
2022-06-29 03:02:57 - train: epoch 0055, iter [00200, 05004], lr: 0.010000, loss: 0.8598
2022-06-29 03:03:29 - train: epoch 0055, iter [00300, 05004], lr: 0.010000, loss: 0.8512
2022-06-29 03:04:01 - train: epoch 0055, iter [00400, 05004], lr: 0.010000, loss: 1.0315
2022-06-29 03:04:33 - train: epoch 0055, iter [00500, 05004], lr: 0.010000, loss: 0.8834
2022-06-29 03:05:04 - train: epoch 0055, iter [00600, 05004], lr: 0.010000, loss: 0.9856
2022-06-29 03:05:36 - train: epoch 0055, iter [00700, 05004], lr: 0.010000, loss: 1.0892
2022-06-29 03:06:08 - train: epoch 0055, iter [00800, 05004], lr: 0.010000, loss: 0.9328
2022-06-29 03:06:40 - train: epoch 0055, iter [00900, 05004], lr: 0.010000, loss: 1.0150
2022-06-29 03:07:12 - train: epoch 0055, iter [01000, 05004], lr: 0.010000, loss: 1.0723
2022-06-29 03:07:44 - train: epoch 0055, iter [01100, 05004], lr: 0.010000, loss: 1.0756
2022-06-29 03:08:16 - train: epoch 0055, iter [01200, 05004], lr: 0.010000, loss: 1.0788
2022-06-29 03:08:48 - train: epoch 0055, iter [01300, 05004], lr: 0.010000, loss: 1.1417
2022-06-29 03:09:20 - train: epoch 0055, iter [01400, 05004], lr: 0.010000, loss: 0.9985
2022-06-29 03:09:52 - train: epoch 0055, iter [01500, 05004], lr: 0.010000, loss: 1.0708
2022-06-29 03:10:24 - train: epoch 0055, iter [01600, 05004], lr: 0.010000, loss: 1.2299
2022-06-29 03:10:56 - train: epoch 0055, iter [01700, 05004], lr: 0.010000, loss: 1.1091
2022-06-29 03:11:28 - train: epoch 0055, iter [01800, 05004], lr: 0.010000, loss: 1.1507
2022-06-29 03:12:00 - train: epoch 0055, iter [01900, 05004], lr: 0.010000, loss: 1.0785
2022-06-29 03:12:32 - train: epoch 0055, iter [02000, 05004], lr: 0.010000, loss: 1.0019
2022-06-29 03:13:04 - train: epoch 0055, iter [02100, 05004], lr: 0.010000, loss: 0.9195
2022-06-29 03:13:37 - train: epoch 0055, iter [02200, 05004], lr: 0.010000, loss: 1.1570
2022-06-29 03:14:09 - train: epoch 0055, iter [02300, 05004], lr: 0.010000, loss: 1.0869
2022-06-29 03:14:41 - train: epoch 0055, iter [02400, 05004], lr: 0.010000, loss: 0.8971
2022-06-29 03:15:13 - train: epoch 0055, iter [02500, 05004], lr: 0.010000, loss: 1.0747
2022-06-29 03:15:45 - train: epoch 0055, iter [02600, 05004], lr: 0.010000, loss: 0.9718
2022-06-29 03:16:17 - train: epoch 0055, iter [02700, 05004], lr: 0.010000, loss: 0.9122
2022-06-29 03:16:49 - train: epoch 0055, iter [02800, 05004], lr: 0.010000, loss: 1.0140
2022-06-29 03:17:21 - train: epoch 0055, iter [02900, 05004], lr: 0.010000, loss: 1.1704
2022-06-29 03:17:53 - train: epoch 0055, iter [03000, 05004], lr: 0.010000, loss: 1.0099
2022-06-29 03:18:25 - train: epoch 0055, iter [03100, 05004], lr: 0.010000, loss: 1.2360
2022-06-29 03:18:57 - train: epoch 0055, iter [03200, 05004], lr: 0.010000, loss: 1.0207
2022-06-29 03:19:29 - train: epoch 0055, iter [03300, 05004], lr: 0.010000, loss: 0.8894
2022-06-29 03:20:01 - train: epoch 0055, iter [03400, 05004], lr: 0.010000, loss: 0.9838
2022-06-29 03:20:33 - train: epoch 0055, iter [03500, 05004], lr: 0.010000, loss: 0.9621
2022-06-29 03:21:05 - train: epoch 0055, iter [03600, 05004], lr: 0.010000, loss: 1.0879
2022-06-29 03:21:38 - train: epoch 0055, iter [03700, 05004], lr: 0.010000, loss: 1.0485
2022-06-29 03:22:10 - train: epoch 0055, iter [03800, 05004], lr: 0.010000, loss: 1.1603
2022-06-29 03:22:42 - train: epoch 0055, iter [03900, 05004], lr: 0.010000, loss: 1.2394
2022-06-29 03:23:13 - train: epoch 0055, iter [04000, 05004], lr: 0.010000, loss: 1.0185
2022-06-29 03:23:46 - train: epoch 0055, iter [04100, 05004], lr: 0.010000, loss: 1.0438
2022-06-29 03:24:18 - train: epoch 0055, iter [04200, 05004], lr: 0.010000, loss: 1.0108
2022-06-29 03:24:50 - train: epoch 0055, iter [04300, 05004], lr: 0.010000, loss: 1.1275
2022-06-29 03:25:22 - train: epoch 0055, iter [04400, 05004], lr: 0.010000, loss: 1.2662
2022-06-29 03:25:54 - train: epoch 0055, iter [04500, 05004], lr: 0.010000, loss: 1.1364
2022-06-29 03:26:26 - train: epoch 0055, iter [04600, 05004], lr: 0.010000, loss: 1.2040
2022-06-29 03:26:58 - train: epoch 0055, iter [04700, 05004], lr: 0.010000, loss: 0.9503
2022-06-29 03:27:30 - train: epoch 0055, iter [04800, 05004], lr: 0.010000, loss: 1.1458
2022-06-29 03:28:02 - train: epoch 0055, iter [04900, 05004], lr: 0.010000, loss: 1.1246
2022-06-29 03:28:34 - train: epoch 0055, iter [05000, 05004], lr: 0.010000, loss: 1.1703
2022-06-29 03:28:36 - train: epoch 055, train_loss: 1.0647
2022-06-29 03:29:49 - eval: epoch: 055, acc1: 72.530%, acc5: 91.170%, test_loss: 1.1037, per_image_load_time: 2.146ms, per_image_inference_time: 0.681ms
2022-06-29 03:29:50 - until epoch: 055, best_acc1: 73.678%
2022-06-29 03:29:50 - epoch 056 lr: 0.010000
2022-06-29 03:30:28 - train: epoch 0056, iter [00100, 05004], lr: 0.010000, loss: 1.1308
2022-06-29 03:30:59 - train: epoch 0056, iter [00200, 05004], lr: 0.010000, loss: 1.1621
2022-06-29 03:31:31 - train: epoch 0056, iter [00300, 05004], lr: 0.010000, loss: 1.0029
2022-06-29 03:32:03 - train: epoch 0056, iter [00400, 05004], lr: 0.010000, loss: 1.0452
2022-06-29 03:32:35 - train: epoch 0056, iter [00500, 05004], lr: 0.010000, loss: 1.0279
2022-06-29 03:33:07 - train: epoch 0056, iter [00600, 05004], lr: 0.010000, loss: 1.0845
2022-06-29 03:33:39 - train: epoch 0056, iter [00700, 05004], lr: 0.010000, loss: 1.1207
2022-06-29 03:34:10 - train: epoch 0056, iter [00800, 05004], lr: 0.010000, loss: 1.1885
2022-06-29 03:34:42 - train: epoch 0056, iter [00900, 05004], lr: 0.010000, loss: 1.0892
2022-06-29 03:35:14 - train: epoch 0056, iter [01000, 05004], lr: 0.010000, loss: 1.1123
2022-06-29 03:35:46 - train: epoch 0056, iter [01100, 05004], lr: 0.010000, loss: 0.9940
2022-06-29 03:36:18 - train: epoch 0056, iter [01200, 05004], lr: 0.010000, loss: 0.9961
2022-06-29 03:36:50 - train: epoch 0056, iter [01300, 05004], lr: 0.010000, loss: 1.1020
2022-06-29 03:37:22 - train: epoch 0056, iter [01400, 05004], lr: 0.010000, loss: 1.0683
2022-06-29 03:37:54 - train: epoch 0056, iter [01500, 05004], lr: 0.010000, loss: 1.2670
2022-06-29 03:38:26 - train: epoch 0056, iter [01600, 05004], lr: 0.010000, loss: 0.9246
2022-06-29 03:38:58 - train: epoch 0056, iter [01700, 05004], lr: 0.010000, loss: 1.1405
2022-06-29 03:39:30 - train: epoch 0056, iter [01800, 05004], lr: 0.010000, loss: 1.2933
2022-06-29 03:40:02 - train: epoch 0056, iter [01900, 05004], lr: 0.010000, loss: 1.0337
2022-06-29 03:40:34 - train: epoch 0056, iter [02000, 05004], lr: 0.010000, loss: 1.0667
2022-06-29 03:41:06 - train: epoch 0056, iter [02100, 05004], lr: 0.010000, loss: 1.0282
2022-06-29 03:41:38 - train: epoch 0056, iter [02200, 05004], lr: 0.010000, loss: 1.1352
2022-06-29 03:42:10 - train: epoch 0056, iter [02300, 05004], lr: 0.010000, loss: 1.1316
2022-06-29 03:42:42 - train: epoch 0056, iter [02400, 05004], lr: 0.010000, loss: 1.0124
2022-06-29 03:43:14 - train: epoch 0056, iter [02500, 05004], lr: 0.010000, loss: 1.1598
2022-06-29 03:43:46 - train: epoch 0056, iter [02600, 05004], lr: 0.010000, loss: 1.0493
2022-06-29 03:44:18 - train: epoch 0056, iter [02700, 05004], lr: 0.010000, loss: 1.0742
2022-06-29 03:44:50 - train: epoch 0056, iter [02800, 05004], lr: 0.010000, loss: 0.9624
2022-06-29 03:45:22 - train: epoch 0056, iter [02900, 05004], lr: 0.010000, loss: 1.2582
2022-06-29 03:45:54 - train: epoch 0056, iter [03000, 05004], lr: 0.010000, loss: 1.1548
2022-06-29 03:46:26 - train: epoch 0056, iter [03100, 05004], lr: 0.010000, loss: 1.0586
2022-06-29 03:46:58 - train: epoch 0056, iter [03200, 05004], lr: 0.010000, loss: 0.9499
2022-06-29 03:47:30 - train: epoch 0056, iter [03300, 05004], lr: 0.010000, loss: 1.2349
2022-06-29 03:48:02 - train: epoch 0056, iter [03400, 05004], lr: 0.010000, loss: 1.0272
2022-06-29 03:48:34 - train: epoch 0056, iter [03500, 05004], lr: 0.010000, loss: 1.0114
2022-06-29 03:49:06 - train: epoch 0056, iter [03600, 05004], lr: 0.010000, loss: 0.8895
2022-06-29 03:49:38 - train: epoch 0056, iter [03700, 05004], lr: 0.010000, loss: 1.0038
2022-06-29 03:50:10 - train: epoch 0056, iter [03800, 05004], lr: 0.010000, loss: 0.9879
2022-06-29 03:50:42 - train: epoch 0056, iter [03900, 05004], lr: 0.010000, loss: 1.2120
2022-06-29 03:51:14 - train: epoch 0056, iter [04000, 05004], lr: 0.010000, loss: 1.0071
2022-06-29 03:51:45 - train: epoch 0056, iter [04100, 05004], lr: 0.010000, loss: 1.2591
2022-06-29 03:52:17 - train: epoch 0056, iter [04200, 05004], lr: 0.010000, loss: 1.0669
2022-06-29 03:52:49 - train: epoch 0056, iter [04300, 05004], lr: 0.010000, loss: 1.0943
2022-06-29 03:53:21 - train: epoch 0056, iter [04400, 05004], lr: 0.010000, loss: 1.1726
2022-06-29 03:53:52 - train: epoch 0056, iter [04500, 05004], lr: 0.010000, loss: 1.0648
2022-06-29 03:54:25 - train: epoch 0056, iter [04600, 05004], lr: 0.010000, loss: 1.0500
2022-06-29 03:54:56 - train: epoch 0056, iter [04700, 05004], lr: 0.010000, loss: 1.1523
2022-06-29 03:55:28 - train: epoch 0056, iter [04800, 05004], lr: 0.010000, loss: 1.2206
2022-06-29 03:56:00 - train: epoch 0056, iter [04900, 05004], lr: 0.010000, loss: 1.0291
2022-06-29 03:56:32 - train: epoch 0056, iter [05000, 05004], lr: 0.010000, loss: 1.2525
2022-06-29 03:56:34 - train: epoch 056, train_loss: 1.0596
2022-06-29 03:57:47 - eval: epoch: 056, acc1: 71.294%, acc5: 90.392%, test_loss: 1.1640, per_image_load_time: 2.117ms, per_image_inference_time: 0.706ms
2022-06-29 03:57:47 - until epoch: 056, best_acc1: 73.678%
2022-06-29 03:57:47 - epoch 057 lr: 0.010000
2022-06-29 03:58:25 - train: epoch 0057, iter [00100, 05004], lr: 0.010000, loss: 1.0384
2022-06-29 03:58:57 - train: epoch 0057, iter [00200, 05004], lr: 0.010000, loss: 0.9434
2022-06-29 03:59:28 - train: epoch 0057, iter [00300, 05004], lr: 0.010000, loss: 0.8318
2022-06-29 04:00:00 - train: epoch 0057, iter [00400, 05004], lr: 0.010000, loss: 0.9903
2022-06-29 04:00:32 - train: epoch 0057, iter [00500, 05004], lr: 0.010000, loss: 0.8590
2022-06-29 04:01:04 - train: epoch 0057, iter [00600, 05004], lr: 0.010000, loss: 1.1995
2022-06-29 04:01:36 - train: epoch 0057, iter [00700, 05004], lr: 0.010000, loss: 0.8165
2022-06-29 04:02:07 - train: epoch 0057, iter [00800, 05004], lr: 0.010000, loss: 1.0664
2022-06-29 04:02:39 - train: epoch 0057, iter [00900, 05004], lr: 0.010000, loss: 1.0838
2022-06-29 04:03:11 - train: epoch 0057, iter [01000, 05004], lr: 0.010000, loss: 0.9863
2022-06-29 04:03:43 - train: epoch 0057, iter [01100, 05004], lr: 0.010000, loss: 0.9965
2022-06-29 04:04:15 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 0.9608
2022-06-29 04:04:46 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 1.0579
2022-06-29 04:05:18 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 1.0942
2022-06-29 04:05:50 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 1.1250
2022-06-29 04:06:22 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 1.1545
2022-06-29 04:06:53 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 1.2669
2022-06-29 04:07:25 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 1.1456
2022-06-29 04:07:57 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 1.0356
2022-06-29 04:08:29 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 1.0289
2022-06-29 04:09:01 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 1.1145
2022-06-29 04:09:33 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 1.0677
2022-06-29 04:10:05 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 0.9201
2022-06-29 04:10:36 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 0.9853
2022-06-29 04:11:08 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 1.0770
2022-06-29 04:11:40 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 0.9928
2022-06-29 04:12:12 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 0.8980
2022-06-29 04:12:44 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 0.8308
2022-06-29 04:13:15 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 1.1019
2022-06-29 04:13:47 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 1.1696
2022-06-29 04:14:19 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 1.2218
2022-06-29 04:14:51 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 1.2590
2022-06-29 04:15:23 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 1.0222
2022-06-29 04:15:55 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 1.0417
2022-06-29 04:16:27 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 1.0472
2022-06-29 04:16:59 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 1.0496
2022-06-29 04:17:31 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 1.1172
2022-06-29 04:18:03 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 0.9122
2022-06-29 04:18:35 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 1.2596
2022-06-29 04:19:07 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 1.0754
2022-06-29 04:19:39 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 1.1350
2022-06-29 04:20:11 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 1.0571
2022-06-29 04:20:43 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 1.0608
2022-06-29 04:21:15 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 1.0521
2022-06-29 04:21:47 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 1.1076
2022-06-29 04:22:19 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 1.0281
2022-06-29 04:22:51 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 0.9494
2022-06-29 04:23:23 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 1.1830
2022-06-29 04:23:56 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 1.2637
2022-06-29 04:24:27 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 1.1208
2022-06-29 04:24:29 - train: epoch 057, train_loss: 1.0577
2022-06-29 04:25:42 - eval: epoch: 057, acc1: 72.110%, acc5: 90.932%, test_loss: 1.1334, per_image_load_time: 1.341ms, per_image_inference_time: 0.699ms
2022-06-29 04:25:42 - until epoch: 057, best_acc1: 73.678%
2022-06-29 04:25:42 - epoch 058 lr: 0.010000
2022-06-29 04:26:20 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 0.9767
2022-06-29 04:26:52 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 0.9511
2022-06-29 04:27:24 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 1.0871
2022-06-29 04:27:56 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 1.1031
2022-06-29 04:28:27 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 0.9501
2022-06-29 04:28:59 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 1.1842
2022-06-29 04:29:31 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 1.0039
2022-06-29 04:30:03 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 0.9840
2022-06-29 04:30:34 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 0.9142
2022-06-29 04:31:06 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 1.0947
2022-06-29 04:31:38 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 0.9262
2022-06-29 04:32:09 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 0.9813
2022-06-29 04:32:41 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 1.0061
2022-06-29 04:33:13 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 1.0423
2022-06-29 04:33:45 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 1.0196
2022-06-29 04:34:17 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 1.0263
2022-06-29 04:34:49 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 1.2197
2022-06-29 04:35:21 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 1.1284
2022-06-29 04:35:53 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 1.2508
2022-06-29 04:36:25 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 1.0975
2022-06-29 04:36:57 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 0.9328
2022-06-29 04:37:29 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 0.8713
2022-06-29 04:38:01 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 1.0832
2022-06-29 04:38:33 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 1.0104
2022-06-29 04:39:05 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 1.2313
2022-06-29 04:39:37 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 0.9729
2022-06-29 04:40:09 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 1.0888
2022-06-29 04:40:41 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 0.9346
2022-06-29 04:41:12 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 1.0443
2022-06-29 04:41:44 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 1.1762
2022-06-29 04:42:16 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 0.9973
2022-06-29 04:42:47 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 0.8928
2022-06-29 04:43:19 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 1.0424
2022-06-29 04:43:51 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 1.0774
2022-06-29 04:44:22 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 1.0744
2022-06-29 04:44:54 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 0.9453
2022-06-29 04:45:26 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 1.0554
2022-06-29 04:45:57 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 1.1070
2022-06-29 04:46:29 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 1.0332
2022-06-29 04:47:01 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 1.2478
2022-06-29 04:47:33 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 1.1525
2022-06-29 04:48:04 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 0.9146
2022-06-29 04:48:36 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 1.3451
2022-06-29 04:49:08 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 0.8445
2022-06-29 04:49:40 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 1.1355
2022-06-29 04:50:12 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 0.9750
2022-06-29 04:50:44 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 1.0550
2022-06-29 04:51:16 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 1.1275
2022-06-29 04:51:48 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 1.0351
2022-06-29 04:52:20 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 1.0367
2022-06-29 04:52:21 - train: epoch 058, train_loss: 1.0525
2022-06-29 04:53:35 - eval: epoch: 058, acc1: 72.728%, acc5: 91.204%, test_loss: 1.1065, per_image_load_time: 2.146ms, per_image_inference_time: 0.682ms
2022-06-29 04:53:36 - until epoch: 058, best_acc1: 73.678%
2022-06-29 04:53:36 - epoch 059 lr: 0.010000
2022-06-29 04:54:13 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 1.1357
2022-06-29 04:54:45 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 1.0480
2022-06-29 04:55:16 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 1.0403
2022-06-29 04:55:48 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 1.1055
2022-06-29 04:56:20 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 1.2757
2022-06-29 04:56:52 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 0.9889
2022-06-29 04:57:24 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 0.9876
2022-06-29 04:57:57 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 1.1337
2022-06-29 04:58:29 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 1.0130
2022-06-29 04:59:00 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 0.9723
2022-06-29 04:59:33 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 1.2133
2022-06-29 05:00:05 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 0.9641
2022-06-29 05:00:37 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 1.1353
2022-06-29 05:01:09 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 1.1059
2022-06-29 05:01:40 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 1.2745
2022-06-29 05:02:12 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 1.0014
2022-06-29 05:02:44 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 0.9797
2022-06-29 05:03:16 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 1.0413
2022-06-29 05:03:48 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 1.1187
2022-06-29 05:04:20 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 0.9852
2022-06-29 05:04:52 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 1.1121
2022-06-29 05:05:23 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 1.1643
2022-06-29 05:05:55 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 0.9271
2022-06-29 05:06:27 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 1.1139
2022-06-29 05:06:59 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 1.0454
2022-06-29 05:07:31 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 1.0990
2022-06-29 05:08:03 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 1.0381
2022-06-29 05:08:35 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 1.2125
2022-06-29 05:09:07 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 0.9652
2022-06-29 05:09:38 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 1.4085
2022-06-29 05:10:10 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 1.0435
2022-06-29 05:10:42 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 1.0534
2022-06-29 05:11:14 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 1.1731
2022-06-29 05:11:46 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 1.4603
2022-06-29 05:12:18 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 1.0013
2022-06-29 05:12:50 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 0.9614
2022-06-29 05:13:22 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 0.9489
2022-06-29 05:13:55 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 1.1070
2022-06-29 05:14:27 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 1.0016
2022-06-29 05:14:58 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 1.3718
2022-06-29 05:15:30 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 1.0942
2022-06-29 05:16:02 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 1.1119
2022-06-29 05:16:34 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 1.1506
2022-06-29 05:17:06 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 1.3182
2022-06-29 05:17:38 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 1.1176
2022-06-29 05:18:09 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 1.0055
2022-06-29 05:18:41 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 1.0742
2022-06-29 05:19:13 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 0.9675
2022-06-29 05:19:45 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 1.2535
2022-06-29 05:20:17 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 1.2034
2022-06-29 05:20:18 - train: epoch 059, train_loss: 1.0515
2022-06-29 05:21:33 - eval: epoch: 059, acc1: 72.356%, acc5: 90.994%, test_loss: 1.1215, per_image_load_time: 1.710ms, per_image_inference_time: 0.690ms
2022-06-29 05:21:33 - until epoch: 059, best_acc1: 73.678%
2022-06-29 05:21:33 - epoch 060 lr: 0.010000
2022-06-29 05:22:11 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 0.8574
2022-06-29 05:22:43 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 1.0644
2022-06-29 05:23:14 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 1.0201
2022-06-29 05:23:46 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 1.0460
2022-06-29 05:24:18 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 1.1553
2022-06-29 05:24:50 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 1.1133
2022-06-29 05:25:22 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 1.0132
2022-06-29 05:25:54 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 1.1393
2022-06-29 05:26:26 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 0.8787
2022-06-29 05:26:58 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 0.8498
2022-06-29 05:27:30 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 0.8423
2022-06-29 05:28:03 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 0.9597
2022-06-29 05:28:35 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 0.9194
2022-06-29 05:29:07 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 1.0896
2022-06-29 05:29:39 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 1.0745
2022-06-29 05:30:11 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 1.0194
2022-06-29 05:30:43 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 0.9549
2022-06-29 05:31:15 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 1.1753
2022-06-29 05:31:48 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 1.1508
2022-06-29 05:32:20 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 0.9657
2022-06-29 05:32:52 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 1.0697
2022-06-29 05:33:24 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 1.0694
2022-06-29 05:33:55 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 0.9080
2022-06-29 05:34:27 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 0.9565
2022-06-29 05:34:59 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 1.0311
2022-06-29 05:35:31 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 1.1068
2022-06-29 05:36:03 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 1.0733
2022-06-29 05:36:35 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 0.8945
2022-06-29 05:37:07 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 1.1081
2022-06-29 05:37:39 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 1.2537
2022-06-29 05:38:11 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 1.0841
2022-06-29 05:38:43 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 1.0626
2022-06-29 05:39:15 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 0.8691
2022-06-29 05:39:47 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 0.9912
2022-06-29 05:40:19 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 1.0382
2022-06-29 05:40:51 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 0.9770
2022-06-29 05:41:23 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 1.0677
2022-06-29 05:41:55 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 1.1026
2022-06-29 05:42:27 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 1.4035
2022-06-29 05:42:58 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 1.1268
2022-06-29 05:43:30 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 1.1849
2022-06-29 05:44:02 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 1.1814
2022-06-29 05:44:34 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 1.0505
2022-06-29 05:45:06 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 1.1528
2022-06-29 05:45:38 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 1.0109
2022-06-29 05:46:10 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 0.9581
2022-06-29 05:46:42 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 1.0715
2022-06-29 05:47:14 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 0.9400
2022-06-29 05:47:45 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 1.0311
2022-06-29 05:48:17 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 1.0920
2022-06-29 05:48:19 - train: epoch 060, train_loss: 1.0478
2022-06-29 05:49:32 - eval: epoch: 060, acc1: 73.186%, acc5: 91.448%, test_loss: 1.0840, per_image_load_time: 1.791ms, per_image_inference_time: 0.694ms
2022-06-29 05:49:33 - until epoch: 060, best_acc1: 73.678%
2022-06-29 05:49:33 - epoch 061 lr: 0.001000
2022-06-29 05:50:10 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 0.9365
2022-06-29 05:50:42 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 1.0436
2022-06-29 05:51:13 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 0.8299
2022-06-29 05:51:45 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 1.1596
2022-06-29 05:52:18 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 0.9124
2022-06-29 05:52:49 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 0.9618
2022-06-29 05:53:21 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 0.7181
2022-06-29 05:53:53 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 0.9989
2022-06-29 05:54:25 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 0.7392
2022-06-29 05:54:57 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 0.7481
2022-06-29 05:55:29 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 0.8221
2022-06-29 05:56:01 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 0.8755
2022-06-29 05:56:33 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 0.8163
2022-06-29 05:57:05 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 0.7794
2022-06-29 05:57:36 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 1.0247
2022-06-29 05:58:08 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 0.7806
2022-06-29 05:58:40 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 0.9378
2022-06-29 05:59:11 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 0.9611
2022-06-29 05:59:43 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 0.9799
2022-06-29 06:00:15 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 0.8510
2022-06-29 06:00:47 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 1.1051
2022-06-29 06:01:20 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 0.7868
2022-06-29 06:01:52 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 0.8584
2022-06-29 06:02:23 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 0.6537
2022-06-29 06:02:55 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 0.8047
2022-06-29 06:03:27 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 0.9118
2022-06-29 06:03:59 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 1.0841
2022-06-29 06:04:31 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 0.8483
2022-06-29 06:05:03 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 0.9457
2022-06-29 06:05:35 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 0.7700
2022-06-29 06:06:06 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 0.9880
2022-06-29 06:06:38 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 0.8647
2022-06-29 06:07:10 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 0.8515
2022-06-29 06:07:41 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 0.7290
2022-06-29 06:08:13 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 0.8671
2022-06-29 06:08:45 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 0.8763
2022-06-29 06:09:17 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 0.9434
2022-06-29 06:09:48 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 0.9136
2022-06-29 06:10:20 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 0.9021
2022-06-29 06:10:52 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 0.8892
2022-06-29 06:11:24 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 0.9874
2022-06-29 06:11:56 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 0.8862
2022-06-29 06:12:28 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 0.9390
2022-06-29 06:12:59 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 0.7714
2022-06-29 06:13:31 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 0.7716
2022-06-29 06:14:03 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 0.8948
2022-06-29 06:14:35 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 0.7859
2022-06-29 06:15:07 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 0.8494
2022-06-29 06:15:39 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 1.0048
2022-06-29 06:16:10 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 0.8032
2022-06-29 06:16:12 - train: epoch 061, train_loss: 0.8707
2022-06-29 06:17:26 - eval: epoch: 061, acc1: 76.336%, acc5: 92.980%, test_loss: 0.9461, per_image_load_time: 2.131ms, per_image_inference_time: 0.679ms
2022-06-29 06:17:27 - until epoch: 061, best_acc1: 76.336%
2022-06-29 06:17:27 - epoch 062 lr: 0.001000
2022-06-29 06:18:04 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 0.9204
2022-06-29 06:18:36 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 0.8536
2022-06-29 06:19:08 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 0.7750
2022-06-29 06:19:39 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 0.7139
2022-06-29 06:20:11 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 0.7627
2022-06-29 06:20:43 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 0.7468
2022-06-29 06:21:14 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 1.0128
2022-06-29 06:21:46 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 0.7991
2022-06-29 06:22:18 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 0.6915
2022-06-29 06:22:50 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 0.9407
2022-06-29 06:23:22 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 0.7105
2022-06-29 06:23:54 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 1.0641
2022-06-29 06:24:26 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 0.8731
2022-06-29 06:24:59 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 0.8432
2022-06-29 06:25:31 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 0.8034
2022-06-29 06:26:03 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 0.9558
2022-06-29 06:26:35 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 0.9853
2022-06-29 06:27:07 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 0.7421
2022-06-29 06:27:40 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 0.8070
2022-06-29 06:28:12 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 0.7278
2022-06-29 06:28:44 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 0.9575
2022-06-29 06:29:16 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 0.7301
2022-06-29 06:29:48 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 0.8881
2022-06-29 06:30:20 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 0.7627
2022-06-29 06:30:52 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 0.7837
2022-06-29 06:31:24 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 0.7204
2022-06-29 06:31:57 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 0.7646
2022-06-29 06:32:28 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 0.9189
2022-06-29 06:33:00 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 0.9079
2022-06-29 06:33:32 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 0.9143
2022-06-29 06:34:04 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 0.8843
2022-06-29 06:34:36 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 0.6443
2022-06-29 06:35:08 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 0.9760
2022-06-29 06:35:40 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 0.9217
2022-06-29 06:36:13 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 0.8795
2022-06-29 06:36:44 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 0.8815
2022-06-29 06:37:17 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 0.7934
2022-06-29 06:37:49 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 0.8409
2022-06-29 06:38:21 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 0.7522
2022-06-29 06:38:54 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 0.7112
2022-06-29 06:39:26 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 0.8194
2022-06-29 06:39:58 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 0.7268
2022-06-29 06:40:30 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 0.7955
2022-06-29 06:41:02 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 0.7421
2022-06-29 06:41:34 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 0.6995
2022-06-29 06:42:06 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 0.6536
2022-06-29 06:42:39 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 0.7720
2022-06-29 06:43:11 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 0.7801
2022-06-29 06:43:43 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 0.7805
2022-06-29 06:44:14 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 0.8402
2022-06-29 06:44:16 - train: epoch 062, train_loss: 0.8191
2022-06-29 06:45:30 - eval: epoch: 062, acc1: 76.594%, acc5: 93.134%, test_loss: 0.9329, per_image_load_time: 1.405ms, per_image_inference_time: 0.704ms
2022-06-29 06:45:31 - until epoch: 062, best_acc1: 76.594%
2022-06-29 06:45:31 - epoch 063 lr: 0.001000
2022-06-29 06:46:08 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 0.8070
2022-06-29 06:46:40 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 0.7640
2022-06-29 06:47:11 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 0.9330
2022-06-29 06:47:43 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 0.8901
2022-06-29 06:48:14 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 0.7115
2022-06-29 06:48:45 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 0.8432
2022-06-29 06:49:17 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 0.7033
2022-06-29 06:49:48 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 0.7952
2022-06-29 06:50:20 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 0.8126
2022-06-29 06:50:52 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 0.9239
2022-06-29 06:51:23 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 0.7213
2022-06-29 06:51:55 - train: epoch 0063, iter [01200, 05004], lr: 0.001000, loss: 0.6699
2022-06-29 06:52:27 - train: epoch 0063, iter [01300, 05004], lr: 0.001000, loss: 0.9237
2022-06-29 06:52:59 - train: epoch 0063, iter [01400, 05004], lr: 0.001000, loss: 1.0213
2022-06-29 06:53:31 - train: epoch 0063, iter [01500, 05004], lr: 0.001000, loss: 0.9218
2022-06-29 06:54:03 - train: epoch 0063, iter [01600, 05004], lr: 0.001000, loss: 0.7628
2022-06-29 06:54:35 - train: epoch 0063, iter [01700, 05004], lr: 0.001000, loss: 0.6919
2022-06-29 06:55:07 - train: epoch 0063, iter [01800, 05004], lr: 0.001000, loss: 0.9173
2022-06-29 06:55:39 - train: epoch 0063, iter [01900, 05004], lr: 0.001000, loss: 0.8509
2022-06-29 06:56:11 - train: epoch 0063, iter [02000, 05004], lr: 0.001000, loss: 0.7069
2022-06-29 06:56:42 - train: epoch 0063, iter [02100, 05004], lr: 0.001000, loss: 0.7013
2022-06-29 06:57:14 - train: epoch 0063, iter [02200, 05004], lr: 0.001000, loss: 1.0398
2022-06-29 06:57:46 - train: epoch 0063, iter [02300, 05004], lr: 0.001000, loss: 0.8025
2022-06-29 06:58:18 - train: epoch 0063, iter [02400, 05004], lr: 0.001000, loss: 0.8860
2022-06-29 06:58:51 - train: epoch 0063, iter [02500, 05004], lr: 0.001000, loss: 0.7469
2022-06-29 06:59:23 - train: epoch 0063, iter [02600, 05004], lr: 0.001000, loss: 0.8703
2022-06-29 06:59:55 - train: epoch 0063, iter [02700, 05004], lr: 0.001000, loss: 0.9833
2022-06-29 07:00:27 - train: epoch 0063, iter [02800, 05004], lr: 0.001000, loss: 0.7688
2022-06-29 07:00:59 - train: epoch 0063, iter [02900, 05004], lr: 0.001000, loss: 0.8035
2022-06-29 07:01:31 - train: epoch 0063, iter [03000, 05004], lr: 0.001000, loss: 0.9354
2022-06-29 07:02:03 - train: epoch 0063, iter [03100, 05004], lr: 0.001000, loss: 1.0578
2022-06-29 07:02:34 - train: epoch 0063, iter [03200, 05004], lr: 0.001000, loss: 0.9297
2022-06-29 07:03:06 - train: epoch 0063, iter [03300, 05004], lr: 0.001000, loss: 0.8135
2022-06-29 07:03:38 - train: epoch 0063, iter [03400, 05004], lr: 0.001000, loss: 0.6743
2022-06-29 07:04:10 - train: epoch 0063, iter [03500, 05004], lr: 0.001000, loss: 0.8881
2022-06-29 07:04:42 - train: epoch 0063, iter [03600, 05004], lr: 0.001000, loss: 0.7195
2022-06-29 07:05:14 - train: epoch 0063, iter [03700, 05004], lr: 0.001000, loss: 0.9016
2022-06-29 07:05:46 - train: epoch 0063, iter [03800, 05004], lr: 0.001000, loss: 0.9830
2022-06-29 07:06:19 - train: epoch 0063, iter [03900, 05004], lr: 0.001000, loss: 0.6522
2022-06-29 07:06:51 - train: epoch 0063, iter [04000, 05004], lr: 0.001000, loss: 0.6915
2022-06-29 07:07:23 - train: epoch 0063, iter [04100, 05004], lr: 0.001000, loss: 0.9541
2022-06-29 07:07:55 - train: epoch 0063, iter [04200, 05004], lr: 0.001000, loss: 0.7734
2022-06-29 07:08:27 - train: epoch 0063, iter [04300, 05004], lr: 0.001000, loss: 0.8756
2022-06-29 07:08:58 - train: epoch 0063, iter [04400, 05004], lr: 0.001000, loss: 0.7852
2022-06-29 07:09:30 - train: epoch 0063, iter [04500, 05004], lr: 0.001000, loss: 0.7424
2022-06-29 07:10:02 - train: epoch 0063, iter [04600, 05004], lr: 0.001000, loss: 0.7337
2022-06-29 07:10:35 - train: epoch 0063, iter [04700, 05004], lr: 0.001000, loss: 0.6555
2022-06-29 07:11:07 - train: epoch 0063, iter [04800, 05004], lr: 0.001000, loss: 0.7623
2022-06-29 07:11:39 - train: epoch 0063, iter [04900, 05004], lr: 0.001000, loss: 0.7819
2022-06-29 07:12:11 - train: epoch 0063, iter [05000, 05004], lr: 0.001000, loss: 0.8155
2022-06-29 07:12:12 - train: epoch 063, train_loss: 0.7984
2022-06-29 07:13:26 - eval: epoch: 063, acc1: 76.864%, acc5: 93.222%, test_loss: 0.9286, per_image_load_time: 2.163ms, per_image_inference_time: 0.689ms
2022-06-29 07:13:27 - until epoch: 063, best_acc1: 76.864%
2022-06-29 07:13:27 - epoch 064 lr: 0.001000
2022-06-29 07:14:05 - train: epoch 0064, iter [00100, 05004], lr: 0.001000, loss: 0.8174
2022-06-29 07:14:37 - train: epoch 0064, iter [00200, 05004], lr: 0.001000, loss: 0.8364
2022-06-29 07:15:08 - train: epoch 0064, iter [00300, 05004], lr: 0.001000, loss: 0.5796
2022-06-29 07:15:40 - train: epoch 0064, iter [00400, 05004], lr: 0.001000, loss: 0.8462
2022-06-29 07:16:12 - train: epoch 0064, iter [00500, 05004], lr: 0.001000, loss: 0.7826
2022-06-29 07:16:43 - train: epoch 0064, iter [00600, 05004], lr: 0.001000, loss: 0.9621
2022-06-29 07:17:15 - train: epoch 0064, iter [00700, 05004], lr: 0.001000, loss: 0.9570
2022-06-29 07:17:47 - train: epoch 0064, iter [00800, 05004], lr: 0.001000, loss: 0.7087
2022-06-29 07:18:19 - train: epoch 0064, iter [00900, 05004], lr: 0.001000, loss: 0.8083
2022-06-29 07:18:51 - train: epoch 0064, iter [01000, 05004], lr: 0.001000, loss: 0.7229
2022-06-29 07:19:23 - train: epoch 0064, iter [01100, 05004], lr: 0.001000, loss: 0.6791
2022-06-29 07:19:54 - train: epoch 0064, iter [01200, 05004], lr: 0.001000, loss: 0.6827
2022-06-29 07:20:26 - train: epoch 0064, iter [01300, 05004], lr: 0.001000, loss: 0.7520
2022-06-29 07:20:59 - train: epoch 0064, iter [01400, 05004], lr: 0.001000, loss: 0.9806
2022-06-29 07:21:31 - train: epoch 0064, iter [01500, 05004], lr: 0.001000, loss: 0.7705
2022-06-29 07:22:03 - train: epoch 0064, iter [01600, 05004], lr: 0.001000, loss: 0.6768
2022-06-29 07:22:35 - train: epoch 0064, iter [01700, 05004], lr: 0.001000, loss: 0.7415
2022-06-29 07:23:07 - train: epoch 0064, iter [01800, 05004], lr: 0.001000, loss: 0.6899
2022-06-29 07:23:38 - train: epoch 0064, iter [01900, 05004], lr: 0.001000, loss: 0.6720
2022-06-29 07:24:10 - train: epoch 0064, iter [02000, 05004], lr: 0.001000, loss: 0.7602
2022-06-29 07:24:42 - train: epoch 0064, iter [02100, 05004], lr: 0.001000, loss: 0.8777
2022-06-29 07:25:14 - train: epoch 0064, iter [02200, 05004], lr: 0.001000, loss: 0.8336
2022-06-29 07:25:46 - train: epoch 0064, iter [02300, 05004], lr: 0.001000, loss: 0.9056
2022-06-29 07:26:18 - train: epoch 0064, iter [02400, 05004], lr: 0.001000, loss: 0.7234
2022-06-29 07:26:50 - train: epoch 0064, iter [02500, 05004], lr: 0.001000, loss: 0.6368
2022-06-29 07:27:22 - train: epoch 0064, iter [02600, 05004], lr: 0.001000, loss: 0.6650
2022-06-29 07:27:54 - train: epoch 0064, iter [02700, 05004], lr: 0.001000, loss: 0.7432
2022-06-29 07:28:26 - train: epoch 0064, iter [02800, 05004], lr: 0.001000, loss: 0.7484
2022-06-29 07:28:58 - train: epoch 0064, iter [02900, 05004], lr: 0.001000, loss: 0.8997
2022-06-29 07:29:30 - train: epoch 0064, iter [03000, 05004], lr: 0.001000, loss: 0.8285
2022-06-29 07:30:02 - train: epoch 0064, iter [03100, 05004], lr: 0.001000, loss: 0.6955
2022-06-29 07:30:34 - train: epoch 0064, iter [03200, 05004], lr: 0.001000, loss: 0.7611
2022-06-29 07:31:06 - train: epoch 0064, iter [03300, 05004], lr: 0.001000, loss: 0.7671
2022-06-29 07:31:38 - train: epoch 0064, iter [03400, 05004], lr: 0.001000, loss: 0.9600
2022-06-29 07:32:10 - train: epoch 0064, iter [03500, 05004], lr: 0.001000, loss: 0.6997
2022-06-29 07:32:42 - train: epoch 0064, iter [03600, 05004], lr: 0.001000, loss: 0.7254
2022-06-29 07:33:14 - train: epoch 0064, iter [03700, 05004], lr: 0.001000, loss: 0.6061
2022-06-29 07:33:46 - train: epoch 0064, iter [03800, 05004], lr: 0.001000, loss: 0.8461
2022-06-29 07:34:18 - train: epoch 0064, iter [03900, 05004], lr: 0.001000, loss: 0.6593
2022-06-29 07:34:50 - train: epoch 0064, iter [04000, 05004], lr: 0.001000, loss: 0.5902
2022-06-29 07:35:22 - train: epoch 0064, iter [04100, 05004], lr: 0.001000, loss: 0.7301
2022-06-29 07:35:54 - train: epoch 0064, iter [04200, 05004], lr: 0.001000, loss: 0.7347
2022-06-29 07:36:26 - train: epoch 0064, iter [04300, 05004], lr: 0.001000, loss: 0.8603
2022-06-29 07:36:59 - train: epoch 0064, iter [04400, 05004], lr: 0.001000, loss: 0.7503
2022-06-29 07:37:31 - train: epoch 0064, iter [04500, 05004], lr: 0.001000, loss: 0.6619
2022-06-29 07:38:03 - train: epoch 0064, iter [04600, 05004], lr: 0.001000, loss: 0.8797
2022-06-29 07:38:35 - train: epoch 0064, iter [04700, 05004], lr: 0.001000, loss: 1.0698
2022-06-29 07:39:06 - train: epoch 0064, iter [04800, 05004], lr: 0.001000, loss: 0.7238
2022-06-29 07:39:38 - train: epoch 0064, iter [04900, 05004], lr: 0.001000, loss: 0.9615
2022-06-29 07:40:10 - train: epoch 0064, iter [05000, 05004], lr: 0.001000, loss: 0.6938
2022-06-29 07:40:12 - train: epoch 064, train_loss: 0.7825
2022-06-29 07:41:26 - eval: epoch: 064, acc1: 76.840%, acc5: 93.250%, test_loss: 0.9242, per_image_load_time: 2.186ms, per_image_inference_time: 0.685ms
2022-06-29 07:41:26 - until epoch: 064, best_acc1: 76.864%
2022-06-29 07:41:26 - epoch 065 lr: 0.001000
2022-06-29 07:42:04 - train: epoch 0065, iter [00100, 05004], lr: 0.001000, loss: 0.8373
2022-06-29 07:42:36 - train: epoch 0065, iter [00200, 05004], lr: 0.001000, loss: 0.7151
2022-06-29 07:43:07 - train: epoch 0065, iter [00300, 05004], lr: 0.001000, loss: 0.7988
2022-06-29 07:43:39 - train: epoch 0065, iter [00400, 05004], lr: 0.001000, loss: 0.9044
2022-06-29 07:44:10 - train: epoch 0065, iter [00500, 05004], lr: 0.001000, loss: 0.7226
2022-06-29 07:44:42 - train: epoch 0065, iter [00600, 05004], lr: 0.001000, loss: 0.8721
2022-06-29 07:45:14 - train: epoch 0065, iter [00700, 05004], lr: 0.001000, loss: 0.6013
2022-06-29 07:45:46 - train: epoch 0065, iter [00800, 05004], lr: 0.001000, loss: 0.7922
2022-06-29 07:46:18 - train: epoch 0065, iter [00900, 05004], lr: 0.001000, loss: 0.7641
2022-06-29 07:46:50 - train: epoch 0065, iter [01000, 05004], lr: 0.001000, loss: 0.7565
2022-06-29 07:47:22 - train: epoch 0065, iter [01100, 05004], lr: 0.001000, loss: 0.8146
2022-06-29 07:47:54 - train: epoch 0065, iter [01200, 05004], lr: 0.001000, loss: 0.9491
2022-06-29 07:48:26 - train: epoch 0065, iter [01300, 05004], lr: 0.001000, loss: 0.7994
2022-06-29 07:48:58 - train: epoch 0065, iter [01400, 05004], lr: 0.001000, loss: 0.6098
2022-06-29 07:49:30 - train: epoch 0065, iter [01500, 05004], lr: 0.001000, loss: 0.7970
2022-06-29 07:50:02 - train: epoch 0065, iter [01600, 05004], lr: 0.001000, loss: 0.7260
2022-06-29 07:50:34 - train: epoch 0065, iter [01700, 05004], lr: 0.001000, loss: 0.7343
2022-06-29 07:51:06 - train: epoch 0065, iter [01800, 05004], lr: 0.001000, loss: 0.7390
2022-06-29 07:51:38 - train: epoch 0065, iter [01900, 05004], lr: 0.001000, loss: 0.6964
2022-06-29 07:52:10 - train: epoch 0065, iter [02000, 05004], lr: 0.001000, loss: 0.7616
2022-06-29 07:52:42 - train: epoch 0065, iter [02100, 05004], lr: 0.001000, loss: 0.7564
2022-06-29 07:53:15 - train: epoch 0065, iter [02200, 05004], lr: 0.001000, loss: 0.8748
2022-06-29 07:53:46 - train: epoch 0065, iter [02300, 05004], lr: 0.001000, loss: 0.6949
2022-06-29 07:54:19 - train: epoch 0065, iter [02400, 05004], lr: 0.001000, loss: 0.6999
2022-06-29 07:54:51 - train: epoch 0065, iter [02500, 05004], lr: 0.001000, loss: 0.7824
2022-06-29 07:55:23 - train: epoch 0065, iter [02600, 05004], lr: 0.001000, loss: 0.8090
2022-06-29 07:55:55 - train: epoch 0065, iter [02700, 05004], lr: 0.001000, loss: 0.7921
2022-06-29 07:56:27 - train: epoch 0065, iter [02800, 05004], lr: 0.001000, loss: 0.7486
2022-06-29 07:56:59 - train: epoch 0065, iter [02900, 05004], lr: 0.001000, loss: 0.8628
2022-06-29 07:57:31 - train: epoch 0065, iter [03000, 05004], lr: 0.001000, loss: 0.6911
2022-06-29 07:58:03 - train: epoch 0065, iter [03100, 05004], lr: 0.001000, loss: 0.8236
2022-06-29 07:58:35 - train: epoch 0065, iter [03200, 05004], lr: 0.001000, loss: 0.8644
2022-06-29 07:59:07 - train: epoch 0065, iter [03300, 05004], lr: 0.001000, loss: 0.6701
2022-06-29 07:59:39 - train: epoch 0065, iter [03400, 05004], lr: 0.001000, loss: 0.6581
2022-06-29 08:00:10 - train: epoch 0065, iter [03500, 05004], lr: 0.001000, loss: 0.9459
2022-06-29 08:00:42 - train: epoch 0065, iter [03600, 05004], lr: 0.001000, loss: 0.7410
2022-06-29 08:01:15 - train: epoch 0065, iter [03700, 05004], lr: 0.001000, loss: 0.7194
2022-06-29 08:01:47 - train: epoch 0065, iter [03800, 05004], lr: 0.001000, loss: 0.6288
2022-06-29 08:02:19 - train: epoch 0065, iter [03900, 05004], lr: 0.001000, loss: 0.7464
2022-06-29 08:02:51 - train: epoch 0065, iter [04000, 05004], lr: 0.001000, loss: 0.8105
2022-06-29 08:03:23 - train: epoch 0065, iter [04100, 05004], lr: 0.001000, loss: 0.6726
2022-06-29 08:03:55 - train: epoch 0065, iter [04200, 05004], lr: 0.001000, loss: 0.7887
2022-06-29 08:04:27 - train: epoch 0065, iter [04300, 05004], lr: 0.001000, loss: 0.6533
2022-06-29 08:04:59 - train: epoch 0065, iter [04400, 05004], lr: 0.001000, loss: 0.6958
2022-06-29 08:05:31 - train: epoch 0065, iter [04500, 05004], lr: 0.001000, loss: 0.7388
2022-06-29 08:06:04 - train: epoch 0065, iter [04600, 05004], lr: 0.001000, loss: 0.7611
2022-06-29 08:06:36 - train: epoch 0065, iter [04700, 05004], lr: 0.001000, loss: 0.8159
2022-06-29 08:07:08 - train: epoch 0065, iter [04800, 05004], lr: 0.001000, loss: 0.5812
2022-06-29 08:07:40 - train: epoch 0065, iter [04900, 05004], lr: 0.001000, loss: 0.6423
2022-06-29 08:08:11 - train: epoch 0065, iter [05000, 05004], lr: 0.001000, loss: 0.8437
2022-06-29 08:08:13 - train: epoch 065, train_loss: 0.7699
2022-06-29 08:09:26 - eval: epoch: 065, acc1: 76.908%, acc5: 93.252%, test_loss: 0.9248, per_image_load_time: 1.437ms, per_image_inference_time: 0.677ms
2022-06-29 08:09:27 - until epoch: 065, best_acc1: 76.908%
2022-06-29 08:09:27 - epoch 066 lr: 0.001000
2022-06-29 08:10:05 - train: epoch 0066, iter [00100, 05004], lr: 0.001000, loss: 0.6746
2022-06-29 08:10:37 - train: epoch 0066, iter [00200, 05004], lr: 0.001000, loss: 0.8431
2022-06-29 08:11:09 - train: epoch 0066, iter [00300, 05004], lr: 0.001000, loss: 0.6218
2022-06-29 08:11:41 - train: epoch 0066, iter [00400, 05004], lr: 0.001000, loss: 0.6188
2022-06-29 08:12:13 - train: epoch 0066, iter [00500, 05004], lr: 0.001000, loss: 0.8291
2022-06-29 08:12:45 - train: epoch 0066, iter [00600, 05004], lr: 0.001000, loss: 0.7702
2022-06-29 08:13:16 - train: epoch 0066, iter [00700, 05004], lr: 0.001000, loss: 0.7338
2022-06-29 08:13:48 - train: epoch 0066, iter [00800, 05004], lr: 0.001000, loss: 0.9777
2022-06-29 08:14:19 - train: epoch 0066, iter [00900, 05004], lr: 0.001000, loss: 0.8110
2022-06-29 08:14:51 - train: epoch 0066, iter [01000, 05004], lr: 0.001000, loss: 0.8802
2022-06-29 08:15:22 - train: epoch 0066, iter [01100, 05004], lr: 0.001000, loss: 0.8248
2022-06-29 08:15:54 - train: epoch 0066, iter [01200, 05004], lr: 0.001000, loss: 0.7918
2022-06-29 08:16:26 - train: epoch 0066, iter [01300, 05004], lr: 0.001000, loss: 0.7959
2022-06-29 08:16:58 - train: epoch 0066, iter [01400, 05004], lr: 0.001000, loss: 0.5790
2022-06-29 08:17:30 - train: epoch 0066, iter [01500, 05004], lr: 0.001000, loss: 0.7528
2022-06-29 08:18:02 - train: epoch 0066, iter [01600, 05004], lr: 0.001000, loss: 0.7175
2022-06-29 08:18:34 - train: epoch 0066, iter [01700, 05004], lr: 0.001000, loss: 0.7927
2022-06-29 08:19:07 - train: epoch 0066, iter [01800, 05004], lr: 0.001000, loss: 0.6766
2022-06-29 08:19:39 - train: epoch 0066, iter [01900, 05004], lr: 0.001000, loss: 0.9379
2022-06-29 08:20:11 - train: epoch 0066, iter [02000, 05004], lr: 0.001000, loss: 0.8743
2022-06-29 08:20:42 - train: epoch 0066, iter [02100, 05004], lr: 0.001000, loss: 0.6994
2022-06-29 08:21:14 - train: epoch 0066, iter [02200, 05004], lr: 0.001000, loss: 0.7734
2022-06-29 08:21:46 - train: epoch 0066, iter [02300, 05004], lr: 0.001000, loss: 0.9047
2022-06-29 08:22:18 - train: epoch 0066, iter [02400, 05004], lr: 0.001000, loss: 0.6600
2022-06-29 08:22:51 - train: epoch 0066, iter [02500, 05004], lr: 0.001000, loss: 0.7948
2022-06-29 08:23:22 - train: epoch 0066, iter [02600, 05004], lr: 0.001000, loss: 0.6413
2022-06-29 08:23:54 - train: epoch 0066, iter [02700, 05004], lr: 0.001000, loss: 0.8856
2022-06-29 08:24:26 - train: epoch 0066, iter [02800, 05004], lr: 0.001000, loss: 0.8750
2022-06-29 08:24:58 - train: epoch 0066, iter [02900, 05004], lr: 0.001000, loss: 0.7812
2022-06-29 08:25:30 - train: epoch 0066, iter [03000, 05004], lr: 0.001000, loss: 0.7382
2022-06-29 08:26:02 - train: epoch 0066, iter [03100, 05004], lr: 0.001000, loss: 0.8221
2022-06-29 08:26:35 - train: epoch 0066, iter [03200, 05004], lr: 0.001000, loss: 0.5546
2022-06-29 08:27:07 - train: epoch 0066, iter [03300, 05004], lr: 0.001000, loss: 0.6933
2022-06-29 08:27:39 - train: epoch 0066, iter [03400, 05004], lr: 0.001000, loss: 0.9585
2022-06-29 08:28:11 - train: epoch 0066, iter [03500, 05004], lr: 0.001000, loss: 0.7674
2022-06-29 08:28:43 - train: epoch 0066, iter [03600, 05004], lr: 0.001000, loss: 0.8031
2022-06-29 08:29:15 - train: epoch 0066, iter [03700, 05004], lr: 0.001000, loss: 0.7845
2022-06-29 08:29:47 - train: epoch 0066, iter [03800, 05004], lr: 0.001000, loss: 0.6190
2022-06-29 08:30:19 - train: epoch 0066, iter [03900, 05004], lr: 0.001000, loss: 0.6902
2022-06-29 08:30:51 - train: epoch 0066, iter [04000, 05004], lr: 0.001000, loss: 0.9701
2022-06-29 08:31:23 - train: epoch 0066, iter [04100, 05004], lr: 0.001000, loss: 0.6276
2022-06-29 08:31:55 - train: epoch 0066, iter [04200, 05004], lr: 0.001000, loss: 0.5739
2022-06-29 08:32:27 - train: epoch 0066, iter [04300, 05004], lr: 0.001000, loss: 0.6093
2022-06-29 08:32:59 - train: epoch 0066, iter [04400, 05004], lr: 0.001000, loss: 0.7575
2022-06-29 08:33:31 - train: epoch 0066, iter [04500, 05004], lr: 0.001000, loss: 0.7310
2022-06-29 08:34:03 - train: epoch 0066, iter [04600, 05004], lr: 0.001000, loss: 0.9324
2022-06-29 08:34:35 - train: epoch 0066, iter [04700, 05004], lr: 0.001000, loss: 0.6293
2022-06-29 08:35:07 - train: epoch 0066, iter [04800, 05004], lr: 0.001000, loss: 0.7520
2022-06-29 08:35:40 - train: epoch 0066, iter [04900, 05004], lr: 0.001000, loss: 0.7752
2022-06-29 08:36:11 - train: epoch 0066, iter [05000, 05004], lr: 0.001000, loss: 0.7355
2022-06-29 08:36:13 - train: epoch 066, train_loss: 0.7600
2022-06-29 08:37:27 - eval: epoch: 066, acc1: 76.832%, acc5: 93.336%, test_loss: 0.9202, per_image_load_time: 1.447ms, per_image_inference_time: 0.691ms
2022-06-29 08:37:28 - until epoch: 066, best_acc1: 76.908%
2022-06-29 08:37:28 - epoch 067 lr: 0.001000
2022-06-29 08:38:06 - train: epoch 0067, iter [00100, 05004], lr: 0.001000, loss: 0.6230
2022-06-29 08:38:38 - train: epoch 0067, iter [00200, 05004], lr: 0.001000, loss: 0.7229
2022-06-29 08:39:10 - train: epoch 0067, iter [00300, 05004], lr: 0.001000, loss: 1.0273
2022-06-29 08:39:42 - train: epoch 0067, iter [00400, 05004], lr: 0.001000, loss: 0.8611
2022-06-29 08:40:14 - train: epoch 0067, iter [00500, 05004], lr: 0.001000, loss: 0.8120
2022-06-29 08:40:46 - train: epoch 0067, iter [00600, 05004], lr: 0.001000, loss: 0.7154
2022-06-29 08:41:18 - train: epoch 0067, iter [00700, 05004], lr: 0.001000, loss: 0.7943
2022-06-29 08:41:50 - train: epoch 0067, iter [00800, 05004], lr: 0.001000, loss: 0.8502
2022-06-29 08:42:21 - train: epoch 0067, iter [00900, 05004], lr: 0.001000, loss: 0.7785
2022-06-29 08:42:53 - train: epoch 0067, iter [01000, 05004], lr: 0.001000, loss: 0.6333
2022-06-29 08:43:25 - train: epoch 0067, iter [01100, 05004], lr: 0.001000, loss: 0.7665
2022-06-29 08:43:57 - train: epoch 0067, iter [01200, 05004], lr: 0.001000, loss: 0.7660
2022-06-29 08:44:29 - train: epoch 0067, iter [01300, 05004], lr: 0.001000, loss: 0.8652
2022-06-29 08:45:01 - train: epoch 0067, iter [01400, 05004], lr: 0.001000, loss: 0.7638
2022-06-29 08:45:32 - train: epoch 0067, iter [01500, 05004], lr: 0.001000, loss: 0.8450
2022-06-29 08:46:04 - train: epoch 0067, iter [01600, 05004], lr: 0.001000, loss: 0.7244
2022-06-29 08:46:36 - train: epoch 0067, iter [01700, 05004], lr: 0.001000, loss: 0.6326
2022-06-29 08:47:07 - train: epoch 0067, iter [01800, 05004], lr: 0.001000, loss: 0.8864
2022-06-29 08:47:39 - train: epoch 0067, iter [01900, 05004], lr: 0.001000, loss: 0.6706
2022-06-29 08:48:11 - train: epoch 0067, iter [02000, 05004], lr: 0.001000, loss: 0.8484
2022-06-29 08:48:43 - train: epoch 0067, iter [02100, 05004], lr: 0.001000, loss: 0.5859
2022-06-29 08:49:15 - train: epoch 0067, iter [02200, 05004], lr: 0.001000, loss: 0.8653
2022-06-29 08:49:46 - train: epoch 0067, iter [02300, 05004], lr: 0.001000, loss: 0.7184
2022-06-29 08:50:18 - train: epoch 0067, iter [02400, 05004], lr: 0.001000, loss: 0.7935
2022-06-29 08:50:50 - train: epoch 0067, iter [02500, 05004], lr: 0.001000, loss: 0.6943
2022-06-29 08:51:22 - train: epoch 0067, iter [02600, 05004], lr: 0.001000, loss: 0.6384
2022-06-29 08:51:54 - train: epoch 0067, iter [02700, 05004], lr: 0.001000, loss: 0.6880
2022-06-29 08:52:26 - train: epoch 0067, iter [02800, 05004], lr: 0.001000, loss: 0.7967
2022-06-29 08:52:58 - train: epoch 0067, iter [02900, 05004], lr: 0.001000, loss: 0.7161
2022-06-29 08:53:30 - train: epoch 0067, iter [03000, 05004], lr: 0.001000, loss: 0.7131
2022-06-29 08:54:02 - train: epoch 0067, iter [03100, 05004], lr: 0.001000, loss: 0.6350
2022-06-29 08:54:34 - train: epoch 0067, iter [03200, 05004], lr: 0.001000, loss: 0.7984
2022-06-29 08:55:06 - train: epoch 0067, iter [03300, 05004], lr: 0.001000, loss: 0.6415
2022-06-29 08:55:37 - train: epoch 0067, iter [03400, 05004], lr: 0.001000, loss: 0.7001
2022-06-29 08:56:09 - train: epoch 0067, iter [03500, 05004], lr: 0.001000, loss: 0.6518
2022-06-29 08:56:41 - train: epoch 0067, iter [03600, 05004], lr: 0.001000, loss: 0.6921
2022-06-29 08:57:13 - train: epoch 0067, iter [03700, 05004], lr: 0.001000, loss: 0.8935
2022-06-29 08:57:45 - train: epoch 0067, iter [03800, 05004], lr: 0.001000, loss: 0.6953
2022-06-29 08:58:17 - train: epoch 0067, iter [03900, 05004], lr: 0.001000, loss: 0.7250
2022-06-29 08:58:49 - train: epoch 0067, iter [04000, 05004], lr: 0.001000, loss: 0.8187
2022-06-29 08:59:22 - train: epoch 0067, iter [04100, 05004], lr: 0.001000, loss: 0.8400
2022-06-29 08:59:54 - train: epoch 0067, iter [04200, 05004], lr: 0.001000, loss: 0.8803
2022-06-29 09:00:26 - train: epoch 0067, iter [04300, 05004], lr: 0.001000, loss: 0.6938
2022-06-29 09:00:58 - train: epoch 0067, iter [04400, 05004], lr: 0.001000, loss: 0.7942
2022-06-29 09:01:30 - train: epoch 0067, iter [04500, 05004], lr: 0.001000, loss: 0.6608
2022-06-29 09:02:02 - train: epoch 0067, iter [04600, 05004], lr: 0.001000, loss: 0.5825
2022-06-29 09:02:34 - train: epoch 0067, iter [04700, 05004], lr: 0.001000, loss: 0.6367
2022-06-29 09:03:06 - train: epoch 0067, iter [04800, 05004], lr: 0.001000, loss: 0.5727
2022-06-29 09:03:38 - train: epoch 0067, iter [04900, 05004], lr: 0.001000, loss: 0.7584
2022-06-29 09:04:10 - train: epoch 0067, iter [05000, 05004], lr: 0.001000, loss: 0.8115
2022-06-29 09:04:12 - train: epoch 067, train_loss: 0.7510
2022-06-29 09:05:26 - eval: epoch: 067, acc1: 76.858%, acc5: 93.358%, test_loss: 0.9246, per_image_load_time: 2.018ms, per_image_inference_time: 0.685ms
2022-06-29 09:05:26 - until epoch: 067, best_acc1: 76.908%
2022-06-29 09:05:26 - epoch 068 lr: 0.001000
2022-06-29 09:06:04 - train: epoch 0068, iter [00100, 05004], lr: 0.001000, loss: 0.7811
2022-06-29 09:06:36 - train: epoch 0068, iter [00200, 05004], lr: 0.001000, loss: 0.7900
2022-06-29 09:07:08 - train: epoch 0068, iter [00300, 05004], lr: 0.001000, loss: 0.7605
2022-06-29 09:07:39 - train: epoch 0068, iter [00400, 05004], lr: 0.001000, loss: 0.7650
2022-06-29 09:08:11 - train: epoch 0068, iter [00500, 05004], lr: 0.001000, loss: 0.7642
2022-06-29 09:08:43 - train: epoch 0068, iter [00600, 05004], lr: 0.001000, loss: 0.7704
2022-06-29 09:09:15 - train: epoch 0068, iter [00700, 05004], lr: 0.001000, loss: 0.9845
2022-06-29 09:09:47 - train: epoch 0068, iter [00800, 05004], lr: 0.001000, loss: 0.7205
2022-06-29 09:10:19 - train: epoch 0068, iter [00900, 05004], lr: 0.001000, loss: 0.6852
2022-06-29 09:10:51 - train: epoch 0068, iter [01000, 05004], lr: 0.001000, loss: 0.7316
2022-06-29 09:11:23 - train: epoch 0068, iter [01100, 05004], lr: 0.001000, loss: 0.8153
2022-06-29 09:11:55 - train: epoch 0068, iter [01200, 05004], lr: 0.001000, loss: 0.6347
2022-06-29 09:12:27 - train: epoch 0068, iter [01300, 05004], lr: 0.001000, loss: 0.5787
2022-06-29 09:12:59 - train: epoch 0068, iter [01400, 05004], lr: 0.001000, loss: 0.7627
2022-06-29 09:13:31 - train: epoch 0068, iter [01500, 05004], lr: 0.001000, loss: 0.8474
2022-06-29 09:14:03 - train: epoch 0068, iter [01600, 05004], lr: 0.001000, loss: 0.8082
2022-06-29 09:14:35 - train: epoch 0068, iter [01700, 05004], lr: 0.001000, loss: 0.9228
2022-06-29 09:15:07 - train: epoch 0068, iter [01800, 05004], lr: 0.001000, loss: 0.7996
2022-06-29 09:15:39 - train: epoch 0068, iter [01900, 05004], lr: 0.001000, loss: 0.7766
2022-06-29 09:16:11 - train: epoch 0068, iter [02000, 05004], lr: 0.001000, loss: 0.7404
2022-06-29 09:16:44 - train: epoch 0068, iter [02100, 05004], lr: 0.001000, loss: 0.6620
2022-06-29 09:17:16 - train: epoch 0068, iter [02200, 05004], lr: 0.001000, loss: 0.7952
2022-06-29 09:17:48 - train: epoch 0068, iter [02300, 05004], lr: 0.001000, loss: 0.7049
2022-06-29 09:18:20 - train: epoch 0068, iter [02400, 05004], lr: 0.001000, loss: 0.7854
2022-06-29 09:18:52 - train: epoch 0068, iter [02500, 05004], lr: 0.001000, loss: 0.6431
2022-06-29 09:19:24 - train: epoch 0068, iter [02600, 05004], lr: 0.001000, loss: 0.7528
2022-06-29 09:19:56 - train: epoch 0068, iter [02700, 05004], lr: 0.001000, loss: 0.7275
2022-06-29 09:20:28 - train: epoch 0068, iter [02800, 05004], lr: 0.001000, loss: 0.8966
2022-06-29 09:21:00 - train: epoch 0068, iter [02900, 05004], lr: 0.001000, loss: 0.8544
2022-06-29 09:21:31 - train: epoch 0068, iter [03000, 05004], lr: 0.001000, loss: 0.8858
2022-06-29 09:22:03 - train: epoch 0068, iter [03100, 05004], lr: 0.001000, loss: 0.6579
2022-06-29 09:22:35 - train: epoch 0068, iter [03200, 05004], lr: 0.001000, loss: 0.8020
2022-06-29 09:23:08 - train: epoch 0068, iter [03300, 05004], lr: 0.001000, loss: 0.7058
2022-06-29 09:23:40 - train: epoch 0068, iter [03400, 05004], lr: 0.001000, loss: 0.6284
2022-06-29 09:24:11 - train: epoch 0068, iter [03500, 05004], lr: 0.001000, loss: 0.7368
2022-06-29 09:24:43 - train: epoch 0068, iter [03600, 05004], lr: 0.001000, loss: 0.7181
2022-06-29 09:25:15 - train: epoch 0068, iter [03700, 05004], lr: 0.001000, loss: 0.8272
2022-06-29 09:25:47 - train: epoch 0068, iter [03800, 05004], lr: 0.001000, loss: 0.7905
2022-06-29 09:26:19 - train: epoch 0068, iter [03900, 05004], lr: 0.001000, loss: 0.7615
2022-06-29 09:26:51 - train: epoch 0068, iter [04000, 05004], lr: 0.001000, loss: 0.7593
2022-06-29 09:27:23 - train: epoch 0068, iter [04100, 05004], lr: 0.001000, loss: 0.6471
2022-06-29 09:27:55 - train: epoch 0068, iter [04200, 05004], lr: 0.001000, loss: 0.8331
2022-06-29 09:28:27 - train: epoch 0068, iter [04300, 05004], lr: 0.001000, loss: 0.9239
2022-06-29 09:28:59 - train: epoch 0068, iter [04400, 05004], lr: 0.001000, loss: 0.7303
2022-06-29 09:29:31 - train: epoch 0068, iter [04500, 05004], lr: 0.001000, loss: 0.6980
2022-06-29 09:30:03 - train: epoch 0068, iter [04600, 05004], lr: 0.001000, loss: 0.8647
2022-06-29 09:30:35 - train: epoch 0068, iter [04700, 05004], lr: 0.001000, loss: 1.0235
2022-06-29 09:31:07 - train: epoch 0068, iter [04800, 05004], lr: 0.001000, loss: 0.8177
2022-06-29 09:31:39 - train: epoch 0068, iter [04900, 05004], lr: 0.001000, loss: 0.8442
2022-06-29 09:32:10 - train: epoch 0068, iter [05000, 05004], lr: 0.001000, loss: 0.6553
2022-06-29 09:32:12 - train: epoch 068, train_loss: 0.7439
2022-06-29 09:33:26 - eval: epoch: 068, acc1: 77.052%, acc5: 93.268%, test_loss: 0.9227, per_image_load_time: 2.166ms, per_image_inference_time: 0.698ms
2022-06-29 09:33:27 - until epoch: 068, best_acc1: 77.052%
2022-06-29 09:33:27 - epoch 069 lr: 0.001000
2022-06-29 09:34:04 - train: epoch 0069, iter [00100, 05004], lr: 0.001000, loss: 0.8642
2022-06-29 09:34:36 - train: epoch 0069, iter [00200, 05004], lr: 0.001000, loss: 0.8381
2022-06-29 09:35:08 - train: epoch 0069, iter [00300, 05004], lr: 0.001000, loss: 0.8102
2022-06-29 09:35:40 - train: epoch 0069, iter [00400, 05004], lr: 0.001000, loss: 0.7160
2022-06-29 09:36:12 - train: epoch 0069, iter [00500, 05004], lr: 0.001000, loss: 0.6454
2022-06-29 09:36:44 - train: epoch 0069, iter [00600, 05004], lr: 0.001000, loss: 0.6841
2022-06-29 09:37:16 - train: epoch 0069, iter [00700, 05004], lr: 0.001000, loss: 0.7060
2022-06-29 09:37:48 - train: epoch 0069, iter [00800, 05004], lr: 0.001000, loss: 0.8055
2022-06-29 09:38:20 - train: epoch 0069, iter [00900, 05004], lr: 0.001000, loss: 0.7470
2022-06-29 09:38:51 - train: epoch 0069, iter [01000, 05004], lr: 0.001000, loss: 0.6732
2022-06-29 09:39:23 - train: epoch 0069, iter [01100, 05004], lr: 0.001000, loss: 0.7134
2022-06-29 09:39:55 - train: epoch 0069, iter [01200, 05004], lr: 0.001000, loss: 0.7486
2022-06-29 09:40:27 - train: epoch 0069, iter [01300, 05004], lr: 0.001000, loss: 0.8881
2022-06-29 09:40:58 - train: epoch 0069, iter [01400, 05004], lr: 0.001000, loss: 0.7940
2022-06-29 09:41:30 - train: epoch 0069, iter [01500, 05004], lr: 0.001000, loss: 0.7271
2022-06-29 09:42:02 - train: epoch 0069, iter [01600, 05004], lr: 0.001000, loss: 0.7825
2022-06-29 09:42:34 - train: epoch 0069, iter [01700, 05004], lr: 0.001000, loss: 0.6859
2022-06-29 09:43:06 - train: epoch 0069, iter [01800, 05004], lr: 0.001000, loss: 0.5911
2022-06-29 09:43:38 - train: epoch 0069, iter [01900, 05004], lr: 0.001000, loss: 0.6539
2022-06-29 09:44:10 - train: epoch 0069, iter [02000, 05004], lr: 0.001000, loss: 0.5079
2022-06-29 09:44:42 - train: epoch 0069, iter [02100, 05004], lr: 0.001000, loss: 0.8122
2022-06-29 09:45:13 - train: epoch 0069, iter [02200, 05004], lr: 0.001000, loss: 0.8569
2022-06-29 09:45:45 - train: epoch 0069, iter [02300, 05004], lr: 0.001000, loss: 0.7776
2022-06-29 09:46:17 - train: epoch 0069, iter [02400, 05004], lr: 0.001000, loss: 0.7767
2022-06-29 09:46:49 - train: epoch 0069, iter [02500, 05004], lr: 0.001000, loss: 0.7681
2022-06-29 09:47:21 - train: epoch 0069, iter [02600, 05004], lr: 0.001000, loss: 0.8809
2022-06-29 09:47:53 - train: epoch 0069, iter [02700, 05004], lr: 0.001000, loss: 0.9093
2022-06-29 09:48:25 - train: epoch 0069, iter [02800, 05004], lr: 0.001000, loss: 0.9525
2022-06-29 09:48:58 - train: epoch 0069, iter [02900, 05004], lr: 0.001000, loss: 0.5974
2022-06-29 09:49:30 - train: epoch 0069, iter [03000, 05004], lr: 0.001000, loss: 0.6020
2022-06-29 09:50:02 - train: epoch 0069, iter [03100, 05004], lr: 0.001000, loss: 0.6458
2022-06-29 09:50:34 - train: epoch 0069, iter [03200, 05004], lr: 0.001000, loss: 0.6865
2022-06-29 09:51:06 - train: epoch 0069, iter [03300, 05004], lr: 0.001000, loss: 0.6039
2022-06-29 09:51:38 - train: epoch 0069, iter [03400, 05004], lr: 0.001000, loss: 0.5929
2022-06-29 09:52:11 - train: epoch 0069, iter [03500, 05004], lr: 0.001000, loss: 0.6876
2022-06-29 09:52:43 - train: epoch 0069, iter [03600, 05004], lr: 0.001000, loss: 0.6574
2022-06-29 09:53:15 - train: epoch 0069, iter [03700, 05004], lr: 0.001000, loss: 0.8208
2022-06-29 09:53:47 - train: epoch 0069, iter [03800, 05004], lr: 0.001000, loss: 0.7881
2022-06-29 09:54:19 - train: epoch 0069, iter [03900, 05004], lr: 0.001000, loss: 0.8161
2022-06-29 09:54:51 - train: epoch 0069, iter [04000, 05004], lr: 0.001000, loss: 0.7643
2022-06-29 09:55:23 - train: epoch 0069, iter [04100, 05004], lr: 0.001000, loss: 0.8552
2022-06-29 09:55:55 - train: epoch 0069, iter [04200, 05004], lr: 0.001000, loss: 0.6589
2022-06-29 09:56:27 - train: epoch 0069, iter [04300, 05004], lr: 0.001000, loss: 0.7547
2022-06-29 09:56:59 - train: epoch 0069, iter [04400, 05004], lr: 0.001000, loss: 0.7697
2022-06-29 09:57:31 - train: epoch 0069, iter [04500, 05004], lr: 0.001000, loss: 0.7048
2022-06-29 09:58:03 - train: epoch 0069, iter [04600, 05004], lr: 0.001000, loss: 0.8779
2022-06-29 09:58:36 - train: epoch 0069, iter [04700, 05004], lr: 0.001000, loss: 0.7607
2022-06-29 09:59:08 - train: epoch 0069, iter [04800, 05004], lr: 0.001000, loss: 0.7384
2022-06-29 09:59:40 - train: epoch 0069, iter [04900, 05004], lr: 0.001000, loss: 0.7640
2022-06-29 10:00:11 - train: epoch 0069, iter [05000, 05004], lr: 0.001000, loss: 0.7485
2022-06-29 10:00:13 - train: epoch 069, train_loss: 0.7363
2022-06-29 10:01:27 - eval: epoch: 069, acc1: 77.022%, acc5: 93.288%, test_loss: 0.9261, per_image_load_time: 1.536ms, per_image_inference_time: 0.682ms
2022-06-29 10:01:28 - until epoch: 069, best_acc1: 77.052%
2022-06-29 10:01:28 - epoch 070 lr: 0.001000
2022-06-29 10:02:06 - train: epoch 0070, iter [00100, 05004], lr: 0.001000, loss: 0.7681
2022-06-29 10:02:37 - train: epoch 0070, iter [00200, 05004], lr: 0.001000, loss: 0.7785
2022-06-29 10:03:09 - train: epoch 0070, iter [00300, 05004], lr: 0.001000, loss: 0.7745
2022-06-29 10:03:41 - train: epoch 0070, iter [00400, 05004], lr: 0.001000, loss: 0.6522
2022-06-29 10:04:13 - train: epoch 0070, iter [00500, 05004], lr: 0.001000, loss: 0.7986
2022-06-29 10:04:44 - train: epoch 0070, iter [00600, 05004], lr: 0.001000, loss: 0.6663
2022-06-29 10:05:16 - train: epoch 0070, iter [00700, 05004], lr: 0.001000, loss: 0.7526
2022-06-29 10:05:47 - train: epoch 0070, iter [00800, 05004], lr: 0.001000, loss: 0.6494
2022-06-29 10:06:19 - train: epoch 0070, iter [00900, 05004], lr: 0.001000, loss: 0.8525
2022-06-29 10:06:51 - train: epoch 0070, iter [01000, 05004], lr: 0.001000, loss: 0.6821
2022-06-29 10:07:23 - train: epoch 0070, iter [01100, 05004], lr: 0.001000, loss: 0.9153
2022-06-29 10:07:55 - train: epoch 0070, iter [01200, 05004], lr: 0.001000, loss: 0.5664
2022-06-29 10:08:26 - train: epoch 0070, iter [01300, 05004], lr: 0.001000, loss: 0.6985
2022-06-29 10:08:58 - train: epoch 0070, iter [01400, 05004], lr: 0.001000, loss: 0.7213
2022-06-29 10:09:30 - train: epoch 0070, iter [01500, 05004], lr: 0.001000, loss: 0.6492
2022-06-29 10:10:02 - train: epoch 0070, iter [01600, 05004], lr: 0.001000, loss: 0.7421
2022-06-29 10:10:34 - train: epoch 0070, iter [01700, 05004], lr: 0.001000, loss: 0.8080
2022-06-29 10:11:06 - train: epoch 0070, iter [01800, 05004], lr: 0.001000, loss: 0.7049
2022-06-29 10:11:38 - train: epoch 0070, iter [01900, 05004], lr: 0.001000, loss: 0.7304
2022-06-29 10:12:10 - train: epoch 0070, iter [02000, 05004], lr: 0.001000, loss: 0.7320
2022-06-29 10:12:42 - train: epoch 0070, iter [02100, 05004], lr: 0.001000, loss: 0.7094
2022-06-29 10:13:14 - train: epoch 0070, iter [02200, 05004], lr: 0.001000, loss: 0.7940
2022-06-29 10:13:46 - train: epoch 0070, iter [02300, 05004], lr: 0.001000, loss: 0.6990
2022-06-29 10:14:18 - train: epoch 0070, iter [02400, 05004], lr: 0.001000, loss: 0.9440
2022-06-29 10:14:50 - train: epoch 0070, iter [02500, 05004], lr: 0.001000, loss: 0.7710
2022-06-29 10:15:21 - train: epoch 0070, iter [02600, 05004], lr: 0.001000, loss: 0.6732
2022-06-29 10:15:53 - train: epoch 0070, iter [02700, 05004], lr: 0.001000, loss: 0.6755
2022-06-29 10:16:25 - train: epoch 0070, iter [02800, 05004], lr: 0.001000, loss: 0.7883
2022-06-29 10:16:57 - train: epoch 0070, iter [02900, 05004], lr: 0.001000, loss: 0.8142
2022-06-29 10:17:29 - train: epoch 0070, iter [03000, 05004], lr: 0.001000, loss: 0.6097
2022-06-29 10:18:00 - train: epoch 0070, iter [03100, 05004], lr: 0.001000, loss: 0.6676
2022-06-29 10:18:32 - train: epoch 0070, iter [03200, 05004], lr: 0.001000, loss: 0.8812
2022-06-29 10:19:04 - train: epoch 0070, iter [03300, 05004], lr: 0.001000, loss: 0.6666
2022-06-29 10:19:36 - train: epoch 0070, iter [03400, 05004], lr: 0.001000, loss: 0.7436
2022-06-29 10:20:08 - train: epoch 0070, iter [03500, 05004], lr: 0.001000, loss: 0.7199
2022-06-29 10:20:40 - train: epoch 0070, iter [03600, 05004], lr: 0.001000, loss: 0.7643
2022-06-29 10:21:12 - train: epoch 0070, iter [03700, 05004], lr: 0.001000, loss: 0.6845
2022-06-29 10:21:44 - train: epoch 0070, iter [03800, 05004], lr: 0.001000, loss: 0.7259
2022-06-29 10:22:16 - train: epoch 0070, iter [03900, 05004], lr: 0.001000, loss: 0.6193
2022-06-29 10:22:47 - train: epoch 0070, iter [04000, 05004], lr: 0.001000, loss: 0.5861
2022-06-29 10:23:19 - train: epoch 0070, iter [04100, 05004], lr: 0.001000, loss: 0.6884
2022-06-29 10:23:51 - train: epoch 0070, iter [04200, 05004], lr: 0.001000, loss: 0.7349
2022-06-29 10:24:23 - train: epoch 0070, iter [04300, 05004], lr: 0.001000, loss: 0.7446
2022-06-29 10:24:55 - train: epoch 0070, iter [04400, 05004], lr: 0.001000, loss: 0.7468
2022-06-29 10:25:27 - train: epoch 0070, iter [04500, 05004], lr: 0.001000, loss: 0.7628
2022-06-29 10:25:59 - train: epoch 0070, iter [04600, 05004], lr: 0.001000, loss: 0.8307
2022-06-29 10:26:31 - train: epoch 0070, iter [04700, 05004], lr: 0.001000, loss: 0.8015
2022-06-29 10:27:03 - train: epoch 0070, iter [04800, 05004], lr: 0.001000, loss: 0.6976
2022-06-29 10:27:35 - train: epoch 0070, iter [04900, 05004], lr: 0.001000, loss: 0.7933
2022-06-29 10:28:07 - train: epoch 0070, iter [05000, 05004], lr: 0.001000, loss: 0.7253
2022-06-29 10:28:08 - train: epoch 070, train_loss: 0.7308
2022-06-29 10:29:22 - eval: epoch: 070, acc1: 77.088%, acc5: 93.330%, test_loss: 0.9203, per_image_load_time: 2.134ms, per_image_inference_time: 0.687ms
2022-06-29 10:29:23 - until epoch: 070, best_acc1: 77.088%
2022-06-29 10:29:23 - epoch 071 lr: 0.001000
2022-06-29 10:30:00 - train: epoch 0071, iter [00100, 05004], lr: 0.001000, loss: 0.6204
2022-06-29 10:30:32 - train: epoch 0071, iter [00200, 05004], lr: 0.001000, loss: 0.6750
2022-06-29 10:31:04 - train: epoch 0071, iter [00300, 05004], lr: 0.001000, loss: 0.6758
2022-06-29 10:31:36 - train: epoch 0071, iter [00400, 05004], lr: 0.001000, loss: 0.7189
2022-06-29 10:32:08 - train: epoch 0071, iter [00500, 05004], lr: 0.001000, loss: 0.7665
2022-06-29 10:32:39 - train: epoch 0071, iter [00600, 05004], lr: 0.001000, loss: 0.7797
2022-06-29 10:33:11 - train: epoch 0071, iter [00700, 05004], lr: 0.001000, loss: 0.8958
2022-06-29 10:33:42 - train: epoch 0071, iter [00800, 05004], lr: 0.001000, loss: 0.6330
2022-06-29 10:34:14 - train: epoch 0071, iter [00900, 05004], lr: 0.001000, loss: 0.7198
2022-06-29 10:34:46 - train: epoch 0071, iter [01000, 05004], lr: 0.001000, loss: 0.8252
2022-06-29 10:35:17 - train: epoch 0071, iter [01100, 05004], lr: 0.001000, loss: 0.8476
2022-06-29 10:35:49 - train: epoch 0071, iter [01200, 05004], lr: 0.001000, loss: 0.6625
2022-06-29 10:36:20 - train: epoch 0071, iter [01300, 05004], lr: 0.001000, loss: 0.7134
2022-06-29 10:36:52 - train: epoch 0071, iter [01400, 05004], lr: 0.001000, loss: 0.7963
2022-06-29 10:37:24 - train: epoch 0071, iter [01500, 05004], lr: 0.001000, loss: 0.5991
2022-06-29 10:37:56 - train: epoch 0071, iter [01600, 05004], lr: 0.001000, loss: 0.7362
2022-06-29 10:38:28 - train: epoch 0071, iter [01700, 05004], lr: 0.001000, loss: 0.7076
2022-06-29 10:39:00 - train: epoch 0071, iter [01800, 05004], lr: 0.001000, loss: 0.6937
2022-06-29 10:39:32 - train: epoch 0071, iter [01900, 05004], lr: 0.001000, loss: 0.6018
2022-06-29 10:40:04 - train: epoch 0071, iter [02000, 05004], lr: 0.001000, loss: 0.8282
2022-06-29 10:40:36 - train: epoch 0071, iter [02100, 05004], lr: 0.001000, loss: 0.5736
2022-06-29 10:41:08 - train: epoch 0071, iter [02200, 05004], lr: 0.001000, loss: 0.7026
2022-06-29 10:41:40 - train: epoch 0071, iter [02300, 05004], lr: 0.001000, loss: 0.5739
2022-06-29 10:42:13 - train: epoch 0071, iter [02400, 05004], lr: 0.001000, loss: 0.6271
2022-06-29 10:42:45 - train: epoch 0071, iter [02500, 05004], lr: 0.001000, loss: 0.7215
2022-06-29 10:43:17 - train: epoch 0071, iter [02600, 05004], lr: 0.001000, loss: 0.7499
2022-06-29 10:43:49 - train: epoch 0071, iter [02700, 05004], lr: 0.001000, loss: 0.7741
2022-06-29 10:44:21 - train: epoch 0071, iter [02800, 05004], lr: 0.001000, loss: 0.8321
2022-06-29 10:44:53 - train: epoch 0071, iter [02900, 05004], lr: 0.001000, loss: 0.7658
2022-06-29 10:45:25 - train: epoch 0071, iter [03000, 05004], lr: 0.001000, loss: 0.6733
2022-06-29 10:45:57 - train: epoch 0071, iter [03100, 05004], lr: 0.001000, loss: 0.7350
2022-06-29 10:46:29 - train: epoch 0071, iter [03200, 05004], lr: 0.001000, loss: 0.6215
2022-06-29 10:47:01 - train: epoch 0071, iter [03300, 05004], lr: 0.001000, loss: 0.5932
2022-06-29 10:47:33 - train: epoch 0071, iter [03400, 05004], lr: 0.001000, loss: 0.6776
2022-06-29 10:48:05 - train: epoch 0071, iter [03500, 05004], lr: 0.001000, loss: 0.8243
2022-06-29 10:48:37 - train: epoch 0071, iter [03600, 05004], lr: 0.001000, loss: 0.8416
2022-06-29 10:49:09 - train: epoch 0071, iter [03700, 05004], lr: 0.001000, loss: 0.7300
2022-06-29 10:49:42 - train: epoch 0071, iter [03800, 05004], lr: 0.001000, loss: 0.7334
2022-06-29 10:50:14 - train: epoch 0071, iter [03900, 05004], lr: 0.001000, loss: 0.8513
2022-06-29 10:50:46 - train: epoch 0071, iter [04000, 05004], lr: 0.001000, loss: 0.9332
2022-06-29 10:51:18 - train: epoch 0071, iter [04100, 05004], lr: 0.001000, loss: 0.7210
2022-06-29 10:51:50 - train: epoch 0071, iter [04200, 05004], lr: 0.001000, loss: 0.8091
2022-06-29 10:52:22 - train: epoch 0071, iter [04300, 05004], lr: 0.001000, loss: 0.7958
2022-06-29 10:52:54 - train: epoch 0071, iter [04400, 05004], lr: 0.001000, loss: 0.6876
2022-06-29 10:53:26 - train: epoch 0071, iter [04500, 05004], lr: 0.001000, loss: 0.6860
2022-06-29 10:53:58 - train: epoch 0071, iter [04600, 05004], lr: 0.001000, loss: 0.8077
2022-06-29 10:54:30 - train: epoch 0071, iter [04700, 05004], lr: 0.001000, loss: 0.5448
2022-06-29 10:55:03 - train: epoch 0071, iter [04800, 05004], lr: 0.001000, loss: 0.6026
2022-06-29 10:55:35 - train: epoch 0071, iter [04900, 05004], lr: 0.001000, loss: 0.5134
2022-06-29 10:56:06 - train: epoch 0071, iter [05000, 05004], lr: 0.001000, loss: 0.6243
2022-06-29 10:56:08 - train: epoch 071, train_loss: 0.7230
2022-06-29 10:57:22 - eval: epoch: 071, acc1: 77.118%, acc5: 93.404%, test_loss: 0.9190, per_image_load_time: 1.827ms, per_image_inference_time: 0.672ms
2022-06-29 10:57:23 - until epoch: 071, best_acc1: 77.118%
2022-06-29 10:57:23 - epoch 072 lr: 0.001000
2022-06-29 10:58:00 - train: epoch 0072, iter [00100, 05004], lr: 0.001000, loss: 0.7703
2022-06-29 10:58:31 - train: epoch 0072, iter [00200, 05004], lr: 0.001000, loss: 0.6244
2022-06-29 10:59:03 - train: epoch 0072, iter [00300, 05004], lr: 0.001000, loss: 0.6264
2022-06-29 10:59:35 - train: epoch 0072, iter [00400, 05004], lr: 0.001000, loss: 0.7097
2022-06-29 11:00:06 - train: epoch 0072, iter [00500, 05004], lr: 0.001000, loss: 0.7045
2022-06-29 11:00:38 - train: epoch 0072, iter [00600, 05004], lr: 0.001000, loss: 0.7163
2022-06-29 11:01:10 - train: epoch 0072, iter [00700, 05004], lr: 0.001000, loss: 0.6825
2022-06-29 11:01:41 - train: epoch 0072, iter [00800, 05004], lr: 0.001000, loss: 0.7800
2022-06-29 11:02:13 - train: epoch 0072, iter [00900, 05004], lr: 0.001000, loss: 0.5971
2022-06-29 11:02:45 - train: epoch 0072, iter [01000, 05004], lr: 0.001000, loss: 0.6761
2022-06-29 11:03:17 - train: epoch 0072, iter [01100, 05004], lr: 0.001000, loss: 0.6337
2022-06-29 11:03:49 - train: epoch 0072, iter [01200, 05004], lr: 0.001000, loss: 0.7218
2022-06-29 11:04:21 - train: epoch 0072, iter [01300, 05004], lr: 0.001000, loss: 0.7128
2022-06-29 11:04:53 - train: epoch 0072, iter [01400, 05004], lr: 0.001000, loss: 0.7913
2022-06-29 11:05:25 - train: epoch 0072, iter [01500, 05004], lr: 0.001000, loss: 0.6533
2022-06-29 11:05:57 - train: epoch 0072, iter [01600, 05004], lr: 0.001000, loss: 0.7989
2022-06-29 11:06:29 - train: epoch 0072, iter [01700, 05004], lr: 0.001000, loss: 0.6570
2022-06-29 11:07:01 - train: epoch 0072, iter [01800, 05004], lr: 0.001000, loss: 0.5559
2022-06-29 11:07:33 - train: epoch 0072, iter [01900, 05004], lr: 0.001000, loss: 0.6177
2022-06-29 11:08:05 - train: epoch 0072, iter [02000, 05004], lr: 0.001000, loss: 0.8468
2022-06-29 11:08:37 - train: epoch 0072, iter [02100, 05004], lr: 0.001000, loss: 0.7317
2022-06-29 11:09:10 - train: epoch 0072, iter [02200, 05004], lr: 0.001000, loss: 0.7538
2022-06-29 11:09:41 - train: epoch 0072, iter [02300, 05004], lr: 0.001000, loss: 0.7964
2022-06-29 11:10:13 - train: epoch 0072, iter [02400, 05004], lr: 0.001000, loss: 0.6021
2022-06-29 11:10:45 - train: epoch 0072, iter [02500, 05004], lr: 0.001000, loss: 0.6583
2022-06-29 11:11:17 - train: epoch 0072, iter [02600, 05004], lr: 0.001000, loss: 0.5641
2022-06-29 11:11:49 - train: epoch 0072, iter [02700, 05004], lr: 0.001000, loss: 0.8088
2022-06-29 11:12:21 - train: epoch 0072, iter [02800, 05004], lr: 0.001000, loss: 0.7371
2022-06-29 11:12:53 - train: epoch 0072, iter [02900, 05004], lr: 0.001000, loss: 0.6760
2022-06-29 11:13:25 - train: epoch 0072, iter [03000, 05004], lr: 0.001000, loss: 0.6653
2022-06-29 11:13:57 - train: epoch 0072, iter [03100, 05004], lr: 0.001000, loss: 0.8388
2022-06-29 11:14:30 - train: epoch 0072, iter [03200, 05004], lr: 0.001000, loss: 0.6639
2022-06-29 11:15:02 - train: epoch 0072, iter [03300, 05004], lr: 0.001000, loss: 0.6525
2022-06-29 11:15:34 - train: epoch 0072, iter [03400, 05004], lr: 0.001000, loss: 0.7055
2022-06-29 11:16:06 - train: epoch 0072, iter [03500, 05004], lr: 0.001000, loss: 0.7754
2022-06-29 11:16:38 - train: epoch 0072, iter [03600, 05004], lr: 0.001000, loss: 0.6826
2022-06-29 11:17:10 - train: epoch 0072, iter [03700, 05004], lr: 0.001000, loss: 0.6715
2022-06-29 11:17:42 - train: epoch 0072, iter [03800, 05004], lr: 0.001000, loss: 0.7321
2022-06-29 11:18:14 - train: epoch 0072, iter [03900, 05004], lr: 0.001000, loss: 0.8465
2022-06-29 11:18:46 - train: epoch 0072, iter [04000, 05004], lr: 0.001000, loss: 0.6433
2022-06-29 11:19:18 - train: epoch 0072, iter [04100, 05004], lr: 0.001000, loss: 0.8934
2022-06-29 11:19:50 - train: epoch 0072, iter [04200, 05004], lr: 0.001000, loss: 0.6610
2022-06-29 11:20:22 - train: epoch 0072, iter [04300, 05004], lr: 0.001000, loss: 0.7075
2022-06-29 11:20:54 - train: epoch 0072, iter [04400, 05004], lr: 0.001000, loss: 0.6377
2022-06-29 11:21:26 - train: epoch 0072, iter [04500, 05004], lr: 0.001000, loss: 0.8239
2022-06-29 11:21:57 - train: epoch 0072, iter [04600, 05004], lr: 0.001000, loss: 0.7586
2022-06-29 11:22:29 - train: epoch 0072, iter [04700, 05004], lr: 0.001000, loss: 0.7721
2022-06-29 11:23:01 - train: epoch 0072, iter [04800, 05004], lr: 0.001000, loss: 0.7993
2022-06-29 11:23:33 - train: epoch 0072, iter [04900, 05004], lr: 0.001000, loss: 0.8015
2022-06-29 11:24:05 - train: epoch 0072, iter [05000, 05004], lr: 0.001000, loss: 0.7137
2022-06-29 11:24:06 - train: epoch 072, train_loss: 0.7184
2022-06-29 11:25:20 - eval: epoch: 072, acc1: 77.038%, acc5: 93.378%, test_loss: 0.9213, per_image_load_time: 1.925ms, per_image_inference_time: 0.678ms
2022-06-29 11:25:21 - until epoch: 072, best_acc1: 77.118%
2022-06-29 11:25:21 - epoch 073 lr: 0.001000
2022-06-29 11:25:58 - train: epoch 0073, iter [00100, 05004], lr: 0.001000, loss: 0.8566
2022-06-29 11:26:30 - train: epoch 0073, iter [00200, 05004], lr: 0.001000, loss: 0.7340
2022-06-29 11:27:02 - train: epoch 0073, iter [00300, 05004], lr: 0.001000, loss: 0.8667
2022-06-29 11:27:34 - train: epoch 0073, iter [00400, 05004], lr: 0.001000, loss: 0.4674
2022-06-29 11:28:05 - train: epoch 0073, iter [00500, 05004], lr: 0.001000, loss: 0.6427
2022-06-29 11:28:37 - train: epoch 0073, iter [00600, 05004], lr: 0.001000, loss: 0.6256
2022-06-29 11:29:09 - train: epoch 0073, iter [00700, 05004], lr: 0.001000, loss: 0.7680
2022-06-29 11:29:41 - train: epoch 0073, iter [00800, 05004], lr: 0.001000, loss: 0.6325
2022-06-29 11:30:13 - train: epoch 0073, iter [00900, 05004], lr: 0.001000, loss: 0.5744
2022-06-29 11:30:45 - train: epoch 0073, iter [01000, 05004], lr: 0.001000, loss: 0.5454
2022-06-29 11:31:17 - train: epoch 0073, iter [01100, 05004], lr: 0.001000, loss: 0.7775
2022-06-29 11:31:49 - train: epoch 0073, iter [01200, 05004], lr: 0.001000, loss: 0.7507
2022-06-29 11:32:21 - train: epoch 0073, iter [01300, 05004], lr: 0.001000, loss: 0.6579
2022-06-29 11:32:52 - train: epoch 0073, iter [01400, 05004], lr: 0.001000, loss: 0.5647
2022-06-29 11:33:24 - train: epoch 0073, iter [01500, 05004], lr: 0.001000, loss: 0.6975
2022-06-29 11:33:56 - train: epoch 0073, iter [01600, 05004], lr: 0.001000, loss: 0.6742
2022-06-29 11:34:28 - train: epoch 0073, iter [01700, 05004], lr: 0.001000, loss: 0.8181
2022-06-29 11:35:00 - train: epoch 0073, iter [01800, 05004], lr: 0.001000, loss: 0.6120
2022-06-29 11:35:32 - train: epoch 0073, iter [01900, 05004], lr: 0.001000, loss: 0.7870
2022-06-29 11:36:04 - train: epoch 0073, iter [02000, 05004], lr: 0.001000, loss: 0.5657
2022-06-29 11:36:36 - train: epoch 0073, iter [02100, 05004], lr: 0.001000, loss: 0.7218
2022-06-29 11:37:08 - train: epoch 0073, iter [02200, 05004], lr: 0.001000, loss: 0.8523
2022-06-29 11:37:40 - train: epoch 0073, iter [02300, 05004], lr: 0.001000, loss: 0.7990
2022-06-29 11:38:12 - train: epoch 0073, iter [02400, 05004], lr: 0.001000, loss: 0.7350
2022-06-29 11:38:44 - train: epoch 0073, iter [02500, 05004], lr: 0.001000, loss: 0.7864
2022-06-29 11:39:16 - train: epoch 0073, iter [02600, 05004], lr: 0.001000, loss: 0.8159
2022-06-29 11:39:48 - train: epoch 0073, iter [02700, 05004], lr: 0.001000, loss: 0.7476
2022-06-29 11:40:20 - train: epoch 0073, iter [02800, 05004], lr: 0.001000, loss: 0.7612
2022-06-29 11:40:52 - train: epoch 0073, iter [02900, 05004], lr: 0.001000, loss: 0.7234
2022-06-29 11:41:24 - train: epoch 0073, iter [03000, 05004], lr: 0.001000, loss: 0.6202
2022-06-29 11:41:56 - train: epoch 0073, iter [03100, 05004], lr: 0.001000, loss: 0.6420
2022-06-29 11:42:28 - train: epoch 0073, iter [03200, 05004], lr: 0.001000, loss: 0.6323
2022-06-29 11:43:00 - train: epoch 0073, iter [03300, 05004], lr: 0.001000, loss: 0.6342
2022-06-29 11:43:32 - train: epoch 0073, iter [03400, 05004], lr: 0.001000, loss: 0.7209
2022-06-29 11:44:04 - train: epoch 0073, iter [03500, 05004], lr: 0.001000, loss: 0.7079
2022-06-29 11:44:36 - train: epoch 0073, iter [03600, 05004], lr: 0.001000, loss: 0.6856
2022-06-29 11:45:08 - train: epoch 0073, iter [03700, 05004], lr: 0.001000, loss: 0.7553
2022-06-29 11:45:40 - train: epoch 0073, iter [03800, 05004], lr: 0.001000, loss: 0.8848
2022-06-29 11:46:12 - train: epoch 0073, iter [03900, 05004], lr: 0.001000, loss: 0.6901
2022-06-29 11:46:44 - train: epoch 0073, iter [04000, 05004], lr: 0.001000, loss: 0.6416
2022-06-29 11:47:16 - train: epoch 0073, iter [04100, 05004], lr: 0.001000, loss: 0.7073
2022-06-29 11:47:48 - train: epoch 0073, iter [04200, 05004], lr: 0.001000, loss: 0.7291
2022-06-29 11:48:20 - train: epoch 0073, iter [04300, 05004], lr: 0.001000, loss: 0.7110
2022-06-29 11:48:52 - train: epoch 0073, iter [04400, 05004], lr: 0.001000, loss: 0.7527
2022-06-29 11:49:23 - train: epoch 0073, iter [04500, 05004], lr: 0.001000, loss: 0.6965
2022-06-29 11:49:55 - train: epoch 0073, iter [04600, 05004], lr: 0.001000, loss: 0.8098
2022-06-29 11:50:27 - train: epoch 0073, iter [04700, 05004], lr: 0.001000, loss: 0.5522
2022-06-29 11:50:59 - train: epoch 0073, iter [04800, 05004], lr: 0.001000, loss: 0.7548
2022-06-29 11:51:31 - train: epoch 0073, iter [04900, 05004], lr: 0.001000, loss: 0.6394
2022-06-29 11:52:02 - train: epoch 0073, iter [05000, 05004], lr: 0.001000, loss: 0.8081
2022-06-29 11:52:04 - train: epoch 073, train_loss: 0.7147
2022-06-29 11:53:18 - eval: epoch: 073, acc1: 76.918%, acc5: 93.376%, test_loss: 0.9249, per_image_load_time: 2.167ms, per_image_inference_time: 0.671ms
2022-06-29 11:53:19 - until epoch: 073, best_acc1: 77.118%
2022-06-29 11:53:19 - epoch 074 lr: 0.001000
2022-06-29 11:53:56 - train: epoch 0074, iter [00100, 05004], lr: 0.001000, loss: 0.6516
2022-06-29 11:54:28 - train: epoch 0074, iter [00200, 05004], lr: 0.001000, loss: 0.7549
2022-06-29 11:55:00 - train: epoch 0074, iter [00300, 05004], lr: 0.001000, loss: 0.8313
2022-06-29 11:55:31 - train: epoch 0074, iter [00400, 05004], lr: 0.001000, loss: 0.7512
2022-06-29 11:56:02 - train: epoch 0074, iter [00500, 05004], lr: 0.001000, loss: 0.7850
2022-06-29 11:56:34 - train: epoch 0074, iter [00600, 05004], lr: 0.001000, loss: 0.7081
2022-06-29 11:57:06 - train: epoch 0074, iter [00700, 05004], lr: 0.001000, loss: 0.7170
2022-06-29 11:57:38 - train: epoch 0074, iter [00800, 05004], lr: 0.001000, loss: 0.8634
2022-06-29 11:58:10 - train: epoch 0074, iter [00900, 05004], lr: 0.001000, loss: 0.6860
2022-06-29 11:58:42 - train: epoch 0074, iter [01000, 05004], lr: 0.001000, loss: 0.7249
2022-06-29 11:59:14 - train: epoch 0074, iter [01100, 05004], lr: 0.001000, loss: 0.7836
2022-06-29 11:59:46 - train: epoch 0074, iter [01200, 05004], lr: 0.001000, loss: 0.6553
2022-06-29 12:00:18 - train: epoch 0074, iter [01300, 05004], lr: 0.001000, loss: 0.8245
2022-06-29 12:00:50 - train: epoch 0074, iter [01400, 05004], lr: 0.001000, loss: 0.6265
2022-06-29 12:01:22 - train: epoch 0074, iter [01500, 05004], lr: 0.001000, loss: 0.6585
2022-06-29 12:01:53 - train: epoch 0074, iter [01600, 05004], lr: 0.001000, loss: 0.5393
2022-06-29 12:02:25 - train: epoch 0074, iter [01700, 05004], lr: 0.001000, loss: 0.7713
2022-06-29 12:02:57 - train: epoch 0074, iter [01800, 05004], lr: 0.001000, loss: 0.9930
2022-06-29 12:03:29 - train: epoch 0074, iter [01900, 05004], lr: 0.001000, loss: 0.8408
2022-06-29 12:04:02 - train: epoch 0074, iter [02000, 05004], lr: 0.001000, loss: 0.5571
2022-06-29 12:04:33 - train: epoch 0074, iter [02100, 05004], lr: 0.001000, loss: 0.6459
2022-06-29 12:05:05 - train: epoch 0074, iter [02200, 05004], lr: 0.001000, loss: 0.9614
2022-06-29 12:05:37 - train: epoch 0074, iter [02300, 05004], lr: 0.001000, loss: 0.7314
2022-06-29 12:06:09 - train: epoch 0074, iter [02400, 05004], lr: 0.001000, loss: 0.6725
2022-06-29 12:06:41 - train: epoch 0074, iter [02500, 05004], lr: 0.001000, loss: 0.7266
2022-06-29 12:07:13 - train: epoch 0074, iter [02600, 05004], lr: 0.001000, loss: 0.5672
2022-06-29 12:07:45 - train: epoch 0074, iter [02700, 05004], lr: 0.001000, loss: 0.6585
2022-06-29 12:08:17 - train: epoch 0074, iter [02800, 05004], lr: 0.001000, loss: 0.8597
2022-06-29 12:08:49 - train: epoch 0074, iter [02900, 05004], lr: 0.001000, loss: 0.6053
2022-06-29 12:09:21 - train: epoch 0074, iter [03000, 05004], lr: 0.001000, loss: 0.7667
2022-06-29 12:09:53 - train: epoch 0074, iter [03100, 05004], lr: 0.001000, loss: 0.6775
2022-06-29 12:10:25 - train: epoch 0074, iter [03200, 05004], lr: 0.001000, loss: 0.6505
2022-06-29 12:10:57 - train: epoch 0074, iter [03300, 05004], lr: 0.001000, loss: 0.7046
2022-06-29 12:11:29 - train: epoch 0074, iter [03400, 05004], lr: 0.001000, loss: 0.7926
2022-06-29 12:12:01 - train: epoch 0074, iter [03500, 05004], lr: 0.001000, loss: 0.5646
2022-06-29 12:12:33 - train: epoch 0074, iter [03600, 05004], lr: 0.001000, loss: 0.6962
2022-06-29 12:13:05 - train: epoch 0074, iter [03700, 05004], lr: 0.001000, loss: 0.7132
2022-06-29 12:13:37 - train: epoch 0074, iter [03800, 05004], lr: 0.001000, loss: 0.6906
2022-06-29 12:14:09 - train: epoch 0074, iter [03900, 05004], lr: 0.001000, loss: 0.5335
2022-06-29 12:14:41 - train: epoch 0074, iter [04000, 05004], lr: 0.001000, loss: 0.6205
2022-06-29 12:15:13 - train: epoch 0074, iter [04100, 05004], lr: 0.001000, loss: 0.8806
2022-06-29 12:15:45 - train: epoch 0074, iter [04200, 05004], lr: 0.001000, loss: 0.6806
2022-06-29 12:16:17 - train: epoch 0074, iter [04300, 05004], lr: 0.001000, loss: 0.6691
2022-06-29 12:16:49 - train: epoch 0074, iter [04400, 05004], lr: 0.001000, loss: 0.6116
2022-06-29 12:17:21 - train: epoch 0074, iter [04500, 05004], lr: 0.001000, loss: 0.6318
2022-06-29 12:17:53 - train: epoch 0074, iter [04600, 05004], lr: 0.001000, loss: 0.7233
2022-06-29 12:18:25 - train: epoch 0074, iter [04700, 05004], lr: 0.001000, loss: 0.7959
2022-06-29 12:18:57 - train: epoch 0074, iter [04800, 05004], lr: 0.001000, loss: 0.7258
2022-06-29 12:19:29 - train: epoch 0074, iter [04900, 05004], lr: 0.001000, loss: 0.8752
2022-06-29 12:20:01 - train: epoch 0074, iter [05000, 05004], lr: 0.001000, loss: 0.7083
2022-06-29 12:20:02 - train: epoch 074, train_loss: 0.7068
2022-06-29 12:21:17 - eval: epoch: 074, acc1: 77.132%, acc5: 93.366%, test_loss: 0.9212, per_image_load_time: 2.125ms, per_image_inference_time: 0.672ms
2022-06-29 12:21:18 - until epoch: 074, best_acc1: 77.132%
2022-06-29 12:21:18 - epoch 075 lr: 0.001000
2022-06-29 12:21:56 - train: epoch 0075, iter [00100, 05004], lr: 0.001000, loss: 0.7538
2022-06-29 12:22:27 - train: epoch 0075, iter [00200, 05004], lr: 0.001000, loss: 0.7142
2022-06-29 12:22:59 - train: epoch 0075, iter [00300, 05004], lr: 0.001000, loss: 0.6864
2022-06-29 12:23:31 - train: epoch 0075, iter [00400, 05004], lr: 0.001000, loss: 0.7445
2022-06-29 12:24:03 - train: epoch 0075, iter [00500, 05004], lr: 0.001000, loss: 0.5707
2022-06-29 12:24:34 - train: epoch 0075, iter [00600, 05004], lr: 0.001000, loss: 0.6436
2022-06-29 12:25:06 - train: epoch 0075, iter [00700, 05004], lr: 0.001000, loss: 0.7563
2022-06-29 12:25:38 - train: epoch 0075, iter [00800, 05004], lr: 0.001000, loss: 0.7847
2022-06-29 12:26:09 - train: epoch 0075, iter [00900, 05004], lr: 0.001000, loss: 0.9176
2022-06-29 12:26:41 - train: epoch 0075, iter [01000, 05004], lr: 0.001000, loss: 0.5669
2022-06-29 12:27:13 - train: epoch 0075, iter [01100, 05004], lr: 0.001000, loss: 0.7061
2022-06-29 12:27:45 - train: epoch 0075, iter [01200, 05004], lr: 0.001000, loss: 0.6522
2022-06-29 12:28:17 - train: epoch 0075, iter [01300, 05004], lr: 0.001000, loss: 0.6627
2022-06-29 12:28:49 - train: epoch 0075, iter [01400, 05004], lr: 0.001000, loss: 0.6865
2022-06-29 12:29:20 - train: epoch 0075, iter [01500, 05004], lr: 0.001000, loss: 0.8008
2022-06-29 12:29:52 - train: epoch 0075, iter [01600, 05004], lr: 0.001000, loss: 0.4891
2022-06-29 12:30:24 - train: epoch 0075, iter [01700, 05004], lr: 0.001000, loss: 0.6300
2022-06-29 12:30:56 - train: epoch 0075, iter [01800, 05004], lr: 0.001000, loss: 0.6787
2022-06-29 12:31:28 - train: epoch 0075, iter [01900, 05004], lr: 0.001000, loss: 0.5745
2022-06-29 12:32:00 - train: epoch 0075, iter [02000, 05004], lr: 0.001000, loss: 0.8106
2022-06-29 12:32:32 - train: epoch 0075, iter [02100, 05004], lr: 0.001000, loss: 0.6921
2022-06-29 12:33:04 - train: epoch 0075, iter [02200, 05004], lr: 0.001000, loss: 0.6890
2022-06-29 12:33:36 - train: epoch 0075, iter [02300, 05004], lr: 0.001000, loss: 0.8072
2022-06-29 12:34:08 - train: epoch 0075, iter [02400, 05004], lr: 0.001000, loss: 0.7497
2022-06-29 12:34:40 - train: epoch 0075, iter [02500, 05004], lr: 0.001000, loss: 0.8092
2022-06-29 12:35:12 - train: epoch 0075, iter [02600, 05004], lr: 0.001000, loss: 0.7411
2022-06-29 12:35:44 - train: epoch 0075, iter [02700, 05004], lr: 0.001000, loss: 0.5510
2022-06-29 12:36:16 - train: epoch 0075, iter [02800, 05004], lr: 0.001000, loss: 0.6215
2022-06-29 12:36:48 - train: epoch 0075, iter [02900, 05004], lr: 0.001000, loss: 0.7337
2022-06-29 12:37:20 - train: epoch 0075, iter [03000, 05004], lr: 0.001000, loss: 0.7861
2022-06-29 12:37:52 - train: epoch 0075, iter [03100, 05004], lr: 0.001000, loss: 0.7069
2022-06-29 12:38:24 - train: epoch 0075, iter [03200, 05004], lr: 0.001000, loss: 0.6612
2022-06-29 12:38:57 - train: epoch 0075, iter [03300, 05004], lr: 0.001000, loss: 0.8159
2022-06-29 12:39:29 - train: epoch 0075, iter [03400, 05004], lr: 0.001000, loss: 0.5356
2022-06-29 12:40:01 - train: epoch 0075, iter [03500, 05004], lr: 0.001000, loss: 0.6055
2022-06-29 12:40:33 - train: epoch 0075, iter [03600, 05004], lr: 0.001000, loss: 0.5836
2022-06-29 12:41:05 - train: epoch 0075, iter [03700, 05004], lr: 0.001000, loss: 0.7887
2022-06-29 12:41:37 - train: epoch 0075, iter [03800, 05004], lr: 0.001000, loss: 0.7223
2022-06-29 12:42:09 - train: epoch 0075, iter [03900, 05004], lr: 0.001000, loss: 0.7939
2022-06-29 12:42:41 - train: epoch 0075, iter [04000, 05004], lr: 0.001000, loss: 0.6627
2022-06-29 12:43:13 - train: epoch 0075, iter [04100, 05004], lr: 0.001000, loss: 0.4783
2022-06-29 12:43:45 - train: epoch 0075, iter [04200, 05004], lr: 0.001000, loss: 0.7892
2022-06-29 12:44:17 - train: epoch 0075, iter [04300, 05004], lr: 0.001000, loss: 0.8966
2022-06-29 12:44:49 - train: epoch 0075, iter [04400, 05004], lr: 0.001000, loss: 0.5831
2022-06-29 12:45:21 - train: epoch 0075, iter [04500, 05004], lr: 0.001000, loss: 0.7159
2022-06-29 12:45:53 - train: epoch 0075, iter [04600, 05004], lr: 0.001000, loss: 0.5815
2022-06-29 12:46:25 - train: epoch 0075, iter [04700, 05004], lr: 0.001000, loss: 0.8162
2022-06-29 12:46:57 - train: epoch 0075, iter [04800, 05004], lr: 0.001000, loss: 0.7179
2022-06-29 12:47:29 - train: epoch 0075, iter [04900, 05004], lr: 0.001000, loss: 0.6083
2022-06-29 12:48:01 - train: epoch 0075, iter [05000, 05004], lr: 0.001000, loss: 0.8247
2022-06-29 12:48:02 - train: epoch 075, train_loss: 0.7045
2022-06-29 12:49:16 - eval: epoch: 075, acc1: 77.024%, acc5: 93.386%, test_loss: 0.9253, per_image_load_time: 1.603ms, per_image_inference_time: 0.693ms
2022-06-29 12:49:17 - until epoch: 075, best_acc1: 77.132%
2022-06-29 12:49:17 - epoch 076 lr: 0.001000
2022-06-29 12:49:55 - train: epoch 0076, iter [00100, 05004], lr: 0.001000, loss: 0.6430
2022-06-29 12:50:26 - train: epoch 0076, iter [00200, 05004], lr: 0.001000, loss: 0.7421
2022-06-29 12:50:58 - train: epoch 0076, iter [00300, 05004], lr: 0.001000, loss: 0.7067
2022-06-29 12:51:30 - train: epoch 0076, iter [00400, 05004], lr: 0.001000, loss: 0.7231
2022-06-29 12:52:03 - train: epoch 0076, iter [00500, 05004], lr: 0.001000, loss: 0.7636
2022-06-29 12:52:35 - train: epoch 0076, iter [00600, 05004], lr: 0.001000, loss: 0.7239
2022-06-29 12:53:07 - train: epoch 0076, iter [00700, 05004], lr: 0.001000, loss: 0.6843
2022-06-29 12:53:39 - train: epoch 0076, iter [00800, 05004], lr: 0.001000, loss: 0.6877
2022-06-29 12:54:11 - train: epoch 0076, iter [00900, 05004], lr: 0.001000, loss: 0.5863
2022-06-29 12:54:43 - train: epoch 0076, iter [01000, 05004], lr: 0.001000, loss: 0.6067
2022-06-29 12:55:15 - train: epoch 0076, iter [01100, 05004], lr: 0.001000, loss: 0.6156
2022-06-29 12:55:47 - train: epoch 0076, iter [01200, 05004], lr: 0.001000, loss: 0.6200
2022-06-29 12:56:20 - train: epoch 0076, iter [01300, 05004], lr: 0.001000, loss: 0.7006
2022-06-29 12:56:52 - train: epoch 0076, iter [01400, 05004], lr: 0.001000, loss: 0.5527
2022-06-29 12:57:24 - train: epoch 0076, iter [01500, 05004], lr: 0.001000, loss: 0.5726
2022-06-29 12:57:56 - train: epoch 0076, iter [01600, 05004], lr: 0.001000, loss: 0.6814
2022-06-29 12:58:27 - train: epoch 0076, iter [01700, 05004], lr: 0.001000, loss: 0.6872
2022-06-29 12:58:59 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 0.5507
2022-06-29 12:59:31 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 0.8042
2022-06-29 13:00:03 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 0.7783
2022-06-29 13:00:35 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 0.7529
2022-06-29 13:01:07 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 0.8590
2022-06-29 13:01:39 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 0.6868
2022-06-29 13:02:11 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 0.7928
2022-06-29 13:02:43 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 0.7109
2022-06-29 13:03:15 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 0.9034
2022-06-29 13:03:47 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 0.7558
2022-06-29 13:04:19 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 0.6483
2022-06-29 13:04:51 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 0.6087
2022-06-29 13:05:23 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 0.6075
2022-06-29 13:05:55 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 0.7593
2022-06-29 13:06:26 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 0.7543
2022-06-29 13:06:58 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 0.7186
2022-06-29 13:07:30 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 0.7633
2022-06-29 13:08:02 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 0.5969
2022-06-29 13:08:34 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 0.6381
2022-06-29 13:09:06 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 0.5363
2022-06-29 13:09:38 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 0.5872
2022-06-29 13:10:10 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 0.5484
2022-06-29 13:10:42 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 0.7480
2022-06-29 13:11:14 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 0.6648
2022-06-29 13:11:46 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 0.9074
2022-06-29 13:12:18 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 0.6903
2022-06-29 13:12:50 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 0.8067
2022-06-29 13:13:22 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 0.6663
2022-06-29 13:13:54 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 0.6833
2022-06-29 13:14:26 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 0.7749
2022-06-29 13:14:58 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 0.6335
2022-06-29 13:15:30 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 0.6394
2022-06-29 13:16:02 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 0.7116
2022-06-29 13:16:03 - train: epoch 076, train_loss: 0.6997
2022-06-29 13:17:17 - eval: epoch: 076, acc1: 77.022%, acc5: 93.346%, test_loss: 0.9243, per_image_load_time: 2.153ms, per_image_inference_time: 0.692ms
2022-06-29 13:17:18 - until epoch: 076, best_acc1: 77.132%
2022-06-29 13:17:18 - epoch 077 lr: 0.001000
2022-06-29 13:17:56 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 0.7789
2022-06-29 13:18:27 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 0.7208
2022-06-29 13:18:59 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 0.5633
2022-06-29 13:19:30 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 0.8566
2022-06-29 13:20:02 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 0.5985
2022-06-29 13:20:33 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 0.5218
2022-06-29 13:21:05 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 0.6385
2022-06-29 13:21:36 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 0.8284
2022-06-29 13:22:09 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 0.8078
2022-06-29 13:22:41 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 0.6118
2022-06-29 13:23:12 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 0.6778
2022-06-29 13:23:45 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 0.6949
2022-06-29 13:24:17 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 0.4945
2022-06-29 13:24:48 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 0.8603
2022-06-29 13:25:21 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 0.6505
2022-06-29 13:25:52 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 0.6987
2022-06-29 13:26:24 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 0.9083
2022-06-29 13:26:56 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 0.5666
2022-06-29 13:27:28 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 0.7681
2022-06-29 13:28:00 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 0.5295
2022-06-29 13:28:32 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 0.6565
2022-06-29 13:29:04 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 0.7535
2022-06-29 13:29:36 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 0.8552
2022-06-29 13:30:09 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 0.6667
2022-06-29 13:30:41 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 0.8100
2022-06-29 13:31:13 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 0.5128
2022-06-29 13:31:45 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 0.7571
2022-06-29 13:32:16 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 0.7600
2022-06-29 13:32:48 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 0.9890
2022-06-29 13:33:20 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 0.5828
2022-06-29 13:33:52 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 0.7175
2022-06-29 13:34:24 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 0.8077
2022-06-29 13:34:56 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 0.6384
2022-06-29 13:35:28 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 0.8343
2022-06-29 13:36:00 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 0.5883
2022-06-29 13:36:32 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 0.6190
2022-06-29 13:37:04 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 0.7561
2022-06-29 13:37:36 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 0.7304
2022-06-29 13:38:08 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 0.7498
2022-06-29 13:38:39 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 0.6580
2022-06-29 13:39:11 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 0.8823
2022-06-29 13:39:43 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 0.7568
2022-06-29 13:40:15 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 0.6997
2022-06-29 13:40:47 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 0.7022
2022-06-29 13:41:19 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 0.7045
2022-06-29 13:41:51 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 0.6667
2022-06-29 13:42:23 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 0.5517
2022-06-29 13:42:55 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 0.7452
2022-06-29 13:43:27 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 0.8147
2022-06-29 13:43:59 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 0.9040
2022-06-29 13:44:01 - train: epoch 077, train_loss: 0.6935
2022-06-29 13:45:15 - eval: epoch: 077, acc1: 76.954%, acc5: 93.348%, test_loss: 0.9278, per_image_load_time: 2.204ms, per_image_inference_time: 0.673ms
2022-06-29 13:45:16 - until epoch: 077, best_acc1: 77.132%
2022-06-29 13:45:16 - epoch 078 lr: 0.001000
2022-06-29 13:45:54 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 0.6338
2022-06-29 13:46:25 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 0.8807
2022-06-29 13:46:56 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 0.8520
2022-06-29 13:47:28 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 0.7740
2022-06-29 13:48:00 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 0.6952
2022-06-29 13:48:31 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 0.7279
2022-06-29 13:49:03 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 0.7296
2022-06-29 13:49:35 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 0.7904
2022-06-29 13:50:06 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 0.7078
2022-06-29 13:50:38 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 0.7571
2022-06-29 13:51:10 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 0.5300
2022-06-29 13:51:42 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 0.5362
2022-06-29 13:52:13 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 0.8030
2022-06-29 13:52:45 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 0.5307
2022-06-29 13:53:17 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 0.6270
2022-06-29 13:53:49 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 0.7687
2022-06-29 13:54:20 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 0.6931
2022-06-29 13:54:53 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 0.6286
2022-06-29 13:55:25 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 0.6354
2022-06-29 13:55:57 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 0.6042
2022-06-29 13:56:28 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 0.8114
2022-06-29 13:57:01 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 0.5882
2022-06-29 13:57:33 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 0.7754
2022-06-29 13:58:05 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 0.6940
2022-06-29 13:58:37 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 0.7205
2022-06-29 13:59:09 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 0.6551
2022-06-29 13:59:41 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 0.5938
2022-06-29 14:00:12 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 0.7434
2022-06-29 14:00:45 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 0.6441
2022-06-29 14:01:16 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 0.5922
2022-06-29 14:01:48 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 0.7017
2022-06-29 14:02:20 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 0.6612
2022-06-29 14:02:52 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 0.7396
2022-06-29 14:03:24 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 0.7023
2022-06-29 14:03:56 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 0.7106
2022-06-29 14:04:28 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 0.7958
2022-06-29 14:05:00 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 0.6160
2022-06-29 14:05:32 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 0.7402
2022-06-29 14:06:04 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 0.7841
2022-06-29 14:06:36 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 0.5983
2022-06-29 14:07:08 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 0.7684
2022-06-29 14:07:40 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 0.8670
2022-06-29 14:08:11 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 0.7165
2022-06-29 14:08:43 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 0.6623
2022-06-29 14:09:15 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 0.7705
2022-06-29 14:09:47 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 0.6438
2022-06-29 14:10:18 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 0.6790
2022-06-29 14:10:50 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 0.8886
2022-06-29 14:11:22 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 0.6796
2022-06-29 14:11:53 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 0.6870
2022-06-29 14:11:55 - train: epoch 078, train_loss: 0.6874
2022-06-29 14:13:09 - eval: epoch: 078, acc1: 76.980%, acc5: 93.336%, test_loss: 0.9265, per_image_load_time: 2.112ms, per_image_inference_time: 0.681ms
2022-06-29 14:13:09 - until epoch: 078, best_acc1: 77.132%
2022-06-29 14:13:09 - epoch 079 lr: 0.001000
2022-06-29 14:13:47 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 0.6534
2022-06-29 14:14:19 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 0.6220
2022-06-29 14:14:51 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 0.7228
2022-06-29 14:15:22 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 0.6679
2022-06-29 14:15:54 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 0.7774
2022-06-29 14:16:26 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 0.7347
2022-06-29 14:16:58 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 0.6197
2022-06-29 14:17:29 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 0.7574
2022-06-29 14:18:02 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 0.6202
2022-06-29 14:18:33 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 0.6465
2022-06-29 14:19:05 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 0.7593
2022-06-29 14:19:38 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 0.9006
2022-06-29 14:20:10 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 0.6325
2022-06-29 14:20:42 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 0.6446
2022-06-29 14:21:14 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 0.5290
2022-06-29 14:21:46 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 0.6227
2022-06-29 14:22:18 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 0.5845
2022-06-29 14:22:50 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 0.5872
2022-06-29 14:23:22 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 0.7513
2022-06-29 14:23:54 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 0.8035
2022-06-29 14:24:26 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 0.5848
2022-06-29 14:24:58 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 0.7667
2022-06-29 14:25:30 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 0.6131
2022-06-29 14:26:01 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 0.7678
2022-06-29 14:26:33 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 0.6471
2022-06-29 14:27:05 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 0.6337
2022-06-29 14:27:37 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 0.5704
2022-06-29 14:28:09 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 0.6094
2022-06-29 14:28:40 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 0.6029
2022-06-29 14:29:13 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 0.7087
2022-06-29 14:29:45 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 0.7645
2022-06-29 14:30:16 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 0.8215
2022-06-29 14:30:48 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 0.6589
2022-06-29 14:31:20 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 0.5224
2022-06-29 14:31:52 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 0.8692
2022-06-29 14:32:24 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 0.5981
2022-06-29 14:32:56 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 0.6075
2022-06-29 14:33:28 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 0.7254
2022-06-29 14:34:00 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 0.6110
2022-06-29 14:34:32 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 0.5921
2022-06-29 14:35:04 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 0.8158
2022-06-29 14:35:36 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 0.6154
2022-06-29 14:36:09 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 0.5040
2022-06-29 14:36:40 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 0.7982
2022-06-29 14:37:12 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 0.7721
2022-06-29 14:37:44 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 0.8482
2022-06-29 14:38:16 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 0.7630
2022-06-29 14:38:48 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 0.7314
2022-06-29 14:39:20 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 0.8485
2022-06-29 14:39:51 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 0.6582
2022-06-29 14:39:53 - train: epoch 079, train_loss: 0.6851
2022-06-29 14:41:06 - eval: epoch: 079, acc1: 77.024%, acc5: 93.368%, test_loss: 0.9286, per_image_load_time: 1.785ms, per_image_inference_time: 0.695ms
2022-06-29 14:41:07 - until epoch: 079, best_acc1: 77.132%
2022-06-29 14:41:07 - epoch 080 lr: 0.001000
2022-06-29 14:41:44 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 0.5206
2022-06-29 14:42:16 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 0.6690
2022-06-29 14:42:48 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 0.7528
2022-06-29 14:43:19 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 0.5763
2022-06-29 14:43:51 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 0.8116
2022-06-29 14:44:23 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 0.5646
2022-06-29 14:44:55 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 0.7010
2022-06-29 14:45:27 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 0.6040
2022-06-29 14:45:58 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 0.7412
2022-06-29 14:46:30 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 0.5713
2022-06-29 14:47:02 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 0.7065
2022-06-29 14:47:34 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 0.5594
2022-06-29 14:48:06 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 0.6604
2022-06-29 14:48:38 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 0.7365
2022-06-29 14:49:10 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 0.6297
2022-06-29 14:49:42 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 0.6582
2022-06-29 14:50:14 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 0.7525
2022-06-29 14:50:46 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 0.7748
2022-06-29 14:51:18 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 0.6821
2022-06-29 14:51:50 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 0.7456
2022-06-29 14:52:22 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 0.6946
2022-06-29 14:52:54 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 0.7591
2022-06-29 14:53:26 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 0.6053
2022-06-29 14:53:58 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 0.6505
2022-06-29 14:54:30 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 0.6118
2022-06-29 14:55:02 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 0.6537
2022-06-29 14:55:34 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 0.8105
2022-06-29 14:56:07 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 0.7254
2022-06-29 14:56:38 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 0.5659
2022-06-29 14:57:11 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 0.6573
2022-06-29 14:57:43 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 0.7896
2022-06-29 14:58:14 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 0.5081
2022-06-29 14:58:47 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 0.6778
2022-06-29 14:59:19 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 0.7179
2022-06-29 14:59:51 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 0.5617
2022-06-29 15:00:23 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 0.6859
2022-06-29 15:00:55 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 0.6793
2022-06-29 15:01:27 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 0.7148
2022-06-29 15:01:59 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 0.6297
2022-06-29 15:02:31 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 0.7188
2022-06-29 15:03:03 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 0.7535
2022-06-29 15:03:35 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 0.6411
2022-06-29 15:04:06 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 0.7191
2022-06-29 15:04:38 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 0.7161
2022-06-29 15:05:11 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 0.5785
2022-06-29 15:05:43 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 0.7348
2022-06-29 15:06:14 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 0.7555
2022-06-29 15:06:47 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 0.7343
2022-06-29 15:07:19 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 0.7391
2022-06-29 15:07:51 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 0.4831
2022-06-29 15:07:52 - train: epoch 080, train_loss: 0.6820
2022-06-29 15:09:06 - eval: epoch: 080, acc1: 76.948%, acc5: 93.440%, test_loss: 0.9291, per_image_load_time: 2.141ms, per_image_inference_time: 0.684ms
2022-06-29 15:09:07 - until epoch: 080, best_acc1: 77.132%
2022-06-29 15:09:07 - epoch 081 lr: 0.001000
2022-06-29 15:09:45 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 0.6253
2022-06-29 15:10:16 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 0.7215
2022-06-29 15:10:47 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 0.5538
2022-06-29 15:11:19 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 0.7937
2022-06-29 15:11:51 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 0.7535
2022-06-29 15:12:24 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 0.6405
2022-06-29 15:12:56 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 0.6519
2022-06-29 15:13:28 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 0.7423
2022-06-29 15:13:59 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 0.6035
2022-06-29 15:14:32 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 0.6283
2022-06-29 15:15:03 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 0.7644
2022-06-29 15:15:35 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 0.6478
2022-06-29 15:16:07 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 0.6009
2022-06-29 15:16:40 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 0.4390
2022-06-29 15:17:12 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 0.6649
2022-06-29 15:17:44 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 0.6422
2022-06-29 15:18:16 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 0.7271
2022-06-29 15:18:49 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 0.5626
2022-06-29 15:19:21 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 0.6543
2022-06-29 15:19:53 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 0.6914
2022-06-29 15:20:25 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 0.6369
2022-06-29 15:20:58 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 0.7312
2022-06-29 15:21:30 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 0.6917
2022-06-29 15:22:02 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 0.7138
2022-06-29 15:22:34 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 0.7837
2022-06-29 15:23:06 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 0.7390
2022-06-29 15:23:38 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 0.6229
2022-06-29 15:24:10 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 0.6286
2022-06-29 15:24:42 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 0.6065
2022-06-29 15:25:14 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 0.6401
2022-06-29 15:25:46 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 0.6083
2022-06-29 15:26:18 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 0.6113
2022-06-29 15:26:50 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 0.7541
2022-06-29 15:27:22 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 0.7086
2022-06-29 15:27:53 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 0.7746
2022-06-29 15:28:26 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 0.6081
2022-06-29 15:28:58 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 0.7878
2022-06-29 15:29:30 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 0.5719
2022-06-29 15:30:02 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 0.6359
2022-06-29 15:30:34 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 0.4741
2022-06-29 15:31:06 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 0.7242
2022-06-29 15:31:38 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 0.6295
2022-06-29 15:32:10 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 0.7241
2022-06-29 15:32:42 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 0.8302
2022-06-29 15:33:14 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 0.6887
2022-06-29 15:33:46 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 0.5685
2022-06-29 15:34:19 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 0.7880
2022-06-29 15:34:50 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 0.7133
2022-06-29 15:35:22 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 0.7283
2022-06-29 15:35:54 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 0.5217
2022-06-29 15:35:56 - train: epoch 081, train_loss: 0.6785
2022-06-29 15:37:09 - eval: epoch: 081, acc1: 77.024%, acc5: 93.272%, test_loss: 0.9299, per_image_load_time: 2.100ms, per_image_inference_time: 0.681ms
2022-06-29 15:37:10 - until epoch: 081, best_acc1: 77.132%
2022-06-29 15:37:10 - epoch 082 lr: 0.001000
2022-06-29 15:37:48 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 0.5849
2022-06-29 15:38:19 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 0.6269
2022-06-29 15:38:51 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 0.7202
2022-06-29 15:39:22 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 0.7159
2022-06-29 15:39:54 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 0.7013
2022-06-29 15:40:25 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 0.5249
2022-06-29 15:40:57 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 0.7778
2022-06-29 15:41:29 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 0.7410
2022-06-29 15:42:00 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 0.7819
2022-06-29 15:42:32 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 0.7343
2022-06-29 15:43:04 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 0.8188
2022-06-29 15:43:35 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 0.6174
2022-06-29 15:44:07 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 0.7867
2022-06-29 15:44:39 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 0.7452
2022-06-29 15:45:11 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 0.6197
2022-06-29 15:45:43 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 0.7738
2022-06-29 15:46:15 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 0.5982
2022-06-29 15:46:46 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 0.6455
2022-06-29 15:47:18 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 0.6511
2022-06-29 15:47:50 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 0.6322
2022-06-29 15:48:22 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 0.5995
2022-06-29 15:48:54 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 0.7844
2022-06-29 15:49:26 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 0.6306
2022-06-29 15:49:57 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 0.6871
2022-06-29 15:50:29 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 0.5812
2022-06-29 15:51:01 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 0.5737
2022-06-29 15:51:33 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 0.5984
2022-06-29 15:52:05 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 0.5667
2022-06-29 15:52:37 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 0.6536
2022-06-29 15:53:09 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 0.5947
2022-06-29 15:53:41 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 0.5844
2022-06-29 15:54:13 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 0.8626
2022-06-29 15:54:45 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 0.6103
2022-06-29 15:55:17 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 0.6052
2022-06-29 15:55:49 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 0.6339
2022-06-29 15:56:22 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 0.5045
2022-06-29 15:56:53 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 0.6803
2022-06-29 15:57:25 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 0.8369
2022-06-29 15:57:57 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 0.7041
2022-06-29 15:58:29 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 0.7866
2022-06-29 15:59:01 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 0.6435
2022-06-29 15:59:33 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 0.8127
2022-06-29 16:00:05 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 0.5506
2022-06-29 16:00:37 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 0.7133
2022-06-29 16:01:09 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 0.7566
2022-06-29 16:01:41 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 0.7179
2022-06-29 16:02:13 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 0.6108
2022-06-29 16:02:45 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 0.5664
2022-06-29 16:03:17 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 0.5916
2022-06-29 16:03:49 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 0.6455
2022-06-29 16:03:50 - train: epoch 082, train_loss: 0.6734
2022-06-29 16:05:04 - eval: epoch: 082, acc1: 76.900%, acc5: 93.328%, test_loss: 0.9334, per_image_load_time: 2.099ms, per_image_inference_time: 0.674ms
2022-06-29 16:05:04 - until epoch: 082, best_acc1: 77.132%
2022-06-29 16:05:04 - epoch 083 lr: 0.001000
2022-06-29 16:05:42 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 0.5527
2022-06-29 16:06:14 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 0.5855
2022-06-29 16:06:45 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 0.6842
2022-06-29 16:07:16 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 0.8137
2022-06-29 16:07:48 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 0.6034
2022-06-29 16:08:19 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 0.5676
2022-06-29 16:08:51 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 0.5913
2022-06-29 16:09:23 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 0.6452
2022-06-29 16:09:55 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 0.7158
2022-06-29 16:10:27 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 0.7530
2022-06-29 16:10:59 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 0.5632
2022-06-29 16:11:31 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 0.6060
2022-06-29 16:12:02 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 0.5814
2022-06-29 16:12:34 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 0.7712
2022-06-29 16:13:06 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 0.5717
2022-06-29 16:13:38 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 0.6721
2022-06-29 16:14:10 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 0.8118
2022-06-29 16:14:42 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 0.8355
2022-06-29 16:15:13 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 0.5065
2022-06-29 16:15:45 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 0.4558
2022-06-29 16:16:17 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 0.6220
2022-06-29 16:16:49 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 0.6543
2022-06-29 16:17:21 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 0.6259
2022-06-29 16:17:52 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 0.6853
2022-06-29 16:18:24 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 0.6953
2022-06-29 16:18:56 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 0.5978
2022-06-29 16:19:28 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 0.6907
2022-06-29 16:20:00 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 0.5981
2022-06-29 16:20:32 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 0.6239
2022-06-29 16:21:04 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 0.6953
2022-06-29 16:21:36 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 0.5214
2022-06-29 16:22:08 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 0.6345
2022-06-29 16:22:40 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 0.8536
2022-06-29 16:23:12 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 0.7883
2022-06-29 16:23:44 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 0.7159
2022-06-29 16:24:16 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 0.7530
2022-06-29 16:24:48 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 0.7807
2022-06-29 16:25:20 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 0.6346
2022-06-29 16:25:52 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 0.6273
2022-06-29 16:26:23 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 0.7683
2022-06-29 16:26:55 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 0.6594
2022-06-29 16:27:27 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 0.7693
2022-06-29 16:27:59 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 0.6620
2022-06-29 16:28:31 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 0.5394
2022-06-29 16:29:02 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 0.7439
2022-06-29 16:29:34 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 0.7308
2022-06-29 16:30:06 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 0.7024
2022-06-29 16:30:37 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 0.7251
2022-06-29 16:31:09 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 0.8783
2022-06-29 16:31:41 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 0.8076
2022-06-29 16:31:43 - train: epoch 083, train_loss: 0.6705
2022-06-29 16:32:56 - eval: epoch: 083, acc1: 76.874%, acc5: 93.368%, test_loss: 0.9329, per_image_load_time: 1.999ms, per_image_inference_time: 0.703ms
2022-06-29 16:32:57 - until epoch: 083, best_acc1: 77.132%
2022-06-29 16:32:57 - epoch 084 lr: 0.001000
2022-06-29 16:33:34 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 0.6521
2022-06-29 16:34:06 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 0.7640
2022-06-29 16:34:38 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 0.5547
2022-06-29 16:35:10 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 0.6748
2022-06-29 16:35:41 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 0.6271
2022-06-29 16:36:13 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 0.7892
2022-06-29 16:36:45 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 0.6757
2022-06-29 16:37:17 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 0.7646
2022-06-29 16:37:49 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 0.6717
2022-06-29 16:38:21 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 0.6733
2022-06-29 16:38:53 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 0.6224
2022-06-29 16:39:25 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 0.8269
2022-06-29 16:39:57 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 0.5925
2022-06-29 16:40:28 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 0.6888
2022-06-29 16:41:00 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 0.6715
2022-06-29 16:41:33 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 0.5985
2022-06-29 16:42:04 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 0.6996
2022-06-29 16:42:36 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 0.7059
2022-06-29 16:43:08 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 0.7026
2022-06-29 16:43:40 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 0.7510
2022-06-29 16:44:12 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 0.6324
2022-06-29 16:44:44 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 0.5143
2022-06-29 16:45:16 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 0.5846
2022-06-29 16:45:49 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 0.5756
2022-06-29 16:46:21 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 0.7987
2022-06-29 16:46:53 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 0.7256
2022-06-29 16:47:25 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 0.6767
2022-06-29 16:47:57 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 0.8169
2022-06-29 16:48:29 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 0.6546
2022-06-29 16:49:01 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 0.6085
2022-06-29 16:49:33 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 0.6148
2022-06-29 16:50:05 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 0.5729
2022-06-29 16:50:38 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 0.7077
2022-06-29 16:51:10 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 0.6051
2022-06-29 16:51:42 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 0.4911
2022-06-29 16:52:14 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 0.6591
2022-06-29 16:52:45 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 0.6886
2022-06-29 16:53:18 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 0.8143
2022-06-29 16:53:50 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 0.7426
2022-06-29 16:54:22 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 0.7322
2022-06-29 16:54:54 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 0.7492
2022-06-29 16:55:27 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 0.7185
2022-06-29 16:55:59 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 0.6479
2022-06-29 16:56:31 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 0.8593
2022-06-29 16:57:03 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 0.6664
2022-06-29 16:57:35 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 0.7596
2022-06-29 16:58:07 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 1.0079
2022-06-29 16:58:39 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 0.5931
2022-06-29 16:59:11 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 0.6294
2022-06-29 16:59:43 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 0.7314
2022-06-29 16:59:44 - train: epoch 084, train_loss: 0.6666
2022-06-29 17:00:58 - eval: epoch: 084, acc1: 76.964%, acc5: 93.328%, test_loss: 0.9322, per_image_load_time: 1.793ms, per_image_inference_time: 0.690ms
2022-06-29 17:00:58 - until epoch: 084, best_acc1: 77.132%
2022-06-29 17:00:58 - epoch 085 lr: 0.001000
2022-06-29 17:01:36 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 0.5421
2022-06-29 17:02:07 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 0.5119
2022-06-29 17:02:39 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 0.7479
2022-06-29 17:03:11 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 0.6014
2022-06-29 17:03:43 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 0.8024
2022-06-29 17:04:14 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 0.5428
2022-06-29 17:04:46 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 0.6089
2022-06-29 17:05:18 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 0.7208
2022-06-29 17:05:49 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 0.6527
2022-06-29 17:06:21 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 0.6993
2022-06-29 17:06:53 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 0.6115
2022-06-29 17:07:25 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 0.6320
2022-06-29 17:07:57 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 0.6049
2022-06-29 17:08:28 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 0.7235
2022-06-29 17:09:00 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 0.5269
2022-06-29 17:09:32 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 0.6576
2022-06-29 17:10:03 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 0.7772
2022-06-29 17:10:35 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 0.6847
2022-06-29 17:11:07 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 0.6210
2022-06-29 17:11:39 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 0.7153
2022-06-29 17:12:10 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 0.5010
2022-06-29 17:12:42 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 0.7548
2022-06-29 17:13:14 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 0.5539
2022-06-29 17:13:46 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 0.6817
2022-06-29 17:14:18 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 0.8396
2022-06-29 17:14:50 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 0.6857
2022-06-29 17:15:22 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 0.6605
2022-06-29 17:15:54 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 0.7048
2022-06-29 17:16:25 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 0.8693
2022-06-29 17:16:57 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 0.8131
2022-06-29 17:17:29 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 0.6243
2022-06-29 17:18:01 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 0.6024
2022-06-29 17:18:33 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 0.6748
2022-06-29 17:19:05 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 0.7514
2022-06-29 17:19:38 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 0.6960
2022-06-29 17:20:10 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 0.6764
2022-06-29 17:20:42 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 0.5751
2022-06-29 17:21:13 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 0.5955
2022-06-29 17:21:45 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 0.6148
2022-06-29 17:22:17 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 0.8969
2022-06-29 17:22:49 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 0.7017
2022-06-29 17:23:21 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 0.8020
2022-06-29 17:23:53 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 0.7076
2022-06-29 17:24:25 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 0.6749
2022-06-29 17:24:57 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 0.8317
2022-06-29 17:25:29 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 0.6900
2022-06-29 17:26:01 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 0.8554
2022-06-29 17:26:32 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 0.5716
2022-06-29 17:27:04 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 0.6548
2022-06-29 17:27:36 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 0.7057
2022-06-29 17:27:38 - train: epoch 085, train_loss: 0.6654
2022-06-29 17:28:51 - eval: epoch: 085, acc1: 76.854%, acc5: 93.388%, test_loss: 0.9364, per_image_load_time: 1.997ms, per_image_inference_time: 0.682ms
2022-06-29 17:28:52 - until epoch: 085, best_acc1: 77.132%
2022-06-29 17:28:52 - epoch 086 lr: 0.001000
2022-06-29 17:29:30 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 0.5569
2022-06-29 17:30:02 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 0.5625
2022-06-29 17:30:33 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 0.7016
2022-06-29 17:31:05 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 0.7255
2022-06-29 17:31:37 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 0.6894
2022-06-29 17:32:09 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 0.6713
2022-06-29 17:32:41 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 0.5954
2022-06-29 17:33:12 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 0.7948
2022-06-29 17:33:44 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 0.7742
2022-06-29 17:34:16 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 0.6307
2022-06-29 17:34:48 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 0.7609
2022-06-29 17:35:19 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 0.5249
2022-06-29 17:35:51 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 0.7203
2022-06-29 17:36:23 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 0.5630
2022-06-29 17:36:55 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 0.5853
2022-06-29 17:37:27 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 0.6950
2022-06-29 17:37:59 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 0.5974
2022-06-29 17:38:31 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 0.6101
2022-06-29 17:39:03 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 0.7887
2022-06-29 17:39:35 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 0.6678
2022-06-29 17:40:06 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 0.6045
2022-06-29 17:40:38 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 0.6391
2022-06-29 17:41:10 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 0.5942
2022-06-29 17:41:42 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 0.5796
2022-06-29 17:42:14 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 0.6202
2022-06-29 17:42:45 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 0.7016
2022-06-29 17:43:17 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 0.5983
2022-06-29 17:43:49 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 0.8307
2022-06-29 17:44:21 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 0.5409
2022-06-29 17:44:53 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 0.7505
2022-06-29 17:45:25 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 0.6255
2022-06-29 17:45:57 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 0.6951
2022-06-29 17:46:29 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 0.6564
2022-06-29 17:47:01 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 0.7560
2022-06-29 17:47:33 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 0.6028
2022-06-29 17:48:05 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 0.7014
2022-06-29 17:48:38 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 0.8287
2022-06-29 17:49:10 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 0.6662
2022-06-29 17:49:42 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 0.7244
2022-06-29 17:50:15 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 0.6593
2022-06-29 17:50:47 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 0.6421
2022-06-29 17:51:19 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 0.7480
2022-06-29 17:51:51 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 0.6725
2022-06-29 17:52:23 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 0.6559
2022-06-29 17:52:55 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 0.6381
2022-06-29 17:53:28 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 0.6900
2022-06-29 17:54:00 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 0.6313
2022-06-29 17:54:32 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 0.6968
2022-06-29 17:55:04 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 0.7701
2022-06-29 17:55:36 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 0.6915
2022-06-29 17:55:37 - train: epoch 086, train_loss: 0.6603
2022-06-29 17:56:51 - eval: epoch: 086, acc1: 76.940%, acc5: 93.372%, test_loss: 0.9370, per_image_load_time: 1.819ms, per_image_inference_time: 0.692ms
2022-06-29 17:56:51 - until epoch: 086, best_acc1: 77.132%
2022-06-29 17:56:51 - epoch 087 lr: 0.001000
2022-06-29 17:57:29 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 0.7589
2022-06-29 17:58:00 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 0.5734
2022-06-29 17:58:31 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 0.9076
2022-06-29 17:59:03 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 0.7067
2022-06-29 17:59:35 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 0.4628
2022-06-29 18:00:07 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 0.7213
2022-06-29 18:00:39 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 0.4233
2022-06-29 18:01:11 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 0.7711
2022-06-29 18:01:42 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 0.7453
2022-06-29 18:02:15 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 0.5912
2022-06-29 18:02:46 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 0.7157
2022-06-29 18:03:18 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 0.6967
2022-06-29 18:03:50 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 0.6936
2022-06-29 18:04:22 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 0.6663
2022-06-29 18:04:54 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 0.6445
2022-06-29 18:05:27 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 0.5170
2022-06-29 18:05:59 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 0.6366
2022-06-29 18:06:31 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 0.6604
2022-06-29 18:07:03 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 0.7381
2022-06-29 18:07:35 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 0.6902
2022-06-29 18:08:06 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 0.8109
2022-06-29 18:08:38 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 0.5122
2022-06-29 18:09:11 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 0.7033
2022-06-29 18:09:42 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 0.6305
2022-06-29 18:10:14 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 0.5989
2022-06-29 18:10:46 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 0.7068
2022-06-29 18:11:18 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 0.6172
2022-06-29 18:11:50 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 0.5576
2022-06-29 18:12:22 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 0.5362
2022-06-29 18:12:54 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 0.6229
2022-06-29 18:13:26 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 0.6574
2022-06-29 18:13:58 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 0.5833
2022-06-29 18:14:30 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 0.6792
2022-06-29 18:15:02 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 0.7362
2022-06-29 18:15:35 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 0.5212
2022-06-29 18:16:06 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 0.6391
2022-06-29 18:16:39 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 0.5790
2022-06-29 18:17:11 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 0.6380
2022-06-29 18:17:43 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 0.6451
2022-06-29 18:18:15 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 0.6791
2022-06-29 18:18:47 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 0.7163
2022-06-29 18:19:19 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 0.7122
2022-06-29 18:19:52 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 0.7471
2022-06-29 18:20:24 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 0.6497
2022-06-29 18:20:56 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 0.7848
2022-06-29 18:21:28 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 0.6136
2022-06-29 18:22:00 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 0.6756
2022-06-29 18:22:32 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 0.6334
2022-06-29 18:23:05 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 0.6472
2022-06-29 18:23:36 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 0.6193
2022-06-29 18:23:38 - train: epoch 087, train_loss: 0.6568
2022-06-29 18:24:52 - eval: epoch: 087, acc1: 76.920%, acc5: 93.344%, test_loss: 0.9406, per_image_load_time: 2.116ms, per_image_inference_time: 0.688ms
2022-06-29 18:24:53 - until epoch: 087, best_acc1: 77.132%
2022-06-29 18:24:53 - epoch 088 lr: 0.001000
2022-06-29 18:25:30 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 0.6832
2022-06-29 18:26:02 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 0.4991
2022-06-29 18:26:33 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 0.7176
2022-06-29 18:27:05 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 0.6531
2022-06-29 18:27:37 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 0.5441
2022-06-29 18:28:08 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 0.7165
2022-06-29 18:28:40 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 0.5957
2022-06-29 18:29:12 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 0.6688
2022-06-29 18:29:43 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 0.6321
2022-06-29 18:30:15 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 0.6395
2022-06-29 18:30:47 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 0.6891
2022-06-29 18:31:19 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 0.5782
2022-06-29 18:31:51 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 0.6598
2022-06-29 18:32:23 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 0.6557
2022-06-29 18:32:54 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 0.6383
2022-06-29 18:33:26 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 0.5315
2022-06-29 18:33:59 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 0.6669
2022-06-29 18:34:30 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 0.6846
2022-06-29 18:35:02 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 0.6748
2022-06-29 18:35:34 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 0.5476
2022-06-29 18:36:06 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 0.7478
2022-06-29 18:36:38 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 0.6123
2022-06-29 18:37:09 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 0.5004
2022-06-29 18:37:41 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 0.5980
2022-06-29 18:38:13 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 0.6681
2022-06-29 18:38:45 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 0.6943
2022-06-29 18:39:17 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 0.6034
2022-06-29 18:39:49 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 0.6483
2022-06-29 18:40:20 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 0.5603
2022-06-29 18:40:53 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 0.7513
2022-06-29 18:41:25 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 0.6566
2022-06-29 18:41:57 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 0.5638
2022-06-29 18:42:29 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 0.6653
2022-06-29 18:43:01 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 0.5411
2022-06-29 18:43:33 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 0.6832
2022-06-29 18:44:05 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 0.7157
2022-06-29 18:44:37 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 0.6983
2022-06-29 18:45:09 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 0.6792
2022-06-29 18:45:41 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 0.6721
2022-06-29 18:46:13 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 0.5892
2022-06-29 18:46:45 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 0.6561
2022-06-29 18:47:17 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 0.7920
2022-06-29 18:47:49 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 0.6133
2022-06-29 18:48:21 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 0.5737
2022-06-29 18:48:53 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 0.6866
2022-06-29 18:49:25 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 0.7185
2022-06-29 18:49:57 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 0.6142
2022-06-29 18:50:29 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 0.5220
2022-06-29 18:51:01 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 0.4813
2022-06-29 18:51:33 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 0.7129
2022-06-29 18:51:34 - train: epoch 088, train_loss: 0.6538
2022-06-29 18:52:48 - eval: epoch: 088, acc1: 76.856%, acc5: 93.374%, test_loss: 0.9391, per_image_load_time: 2.121ms, per_image_inference_time: 0.691ms
2022-06-29 18:52:48 - until epoch: 088, best_acc1: 77.132%
2022-06-29 18:52:48 - epoch 089 lr: 0.001000
2022-06-29 18:53:26 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 0.7772
2022-06-29 18:53:58 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 0.5451
2022-06-29 18:54:29 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 0.6795
2022-06-29 18:55:01 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 0.6246
2022-06-29 18:55:32 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 0.6174
2022-06-29 18:56:04 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 0.6301
2022-06-29 18:56:36 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 0.7357
2022-06-29 18:57:08 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 0.7605
2022-06-29 18:57:40 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 0.6795
2022-06-29 18:58:12 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 0.7563
2022-06-29 18:58:44 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 0.6693
2022-06-29 18:59:16 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 0.7357
2022-06-29 18:59:48 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 0.6389
2022-06-29 19:00:20 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 0.7118
2022-06-29 19:00:52 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 0.6618
2022-06-29 19:01:24 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 0.6921
2022-06-29 19:01:56 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 0.6436
2022-06-29 19:02:28 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 0.5969
2022-06-29 19:03:00 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 0.5678
2022-06-29 19:03:33 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 0.5713
2022-06-29 19:04:05 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 0.7381
2022-06-29 19:04:36 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 0.6119
2022-06-29 19:05:09 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 0.5314
2022-06-29 19:05:41 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 0.6139
2022-06-29 19:06:13 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 0.5760
2022-06-29 19:06:45 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 0.7073
2022-06-29 19:07:17 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 0.5779
2022-06-29 19:07:49 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 0.6812
2022-06-29 19:08:21 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 0.7253
2022-06-29 19:08:53 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 0.7007
2022-06-29 19:09:25 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 0.6771
2022-06-29 19:09:57 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 0.7434
2022-06-29 19:10:29 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 0.7327
2022-06-29 19:11:01 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 0.6952
2022-06-29 19:11:33 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 0.5432
2022-06-29 19:12:05 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 0.5731
2022-06-29 19:12:37 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 0.8039
2022-06-29 19:13:09 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 0.5438
2022-06-29 19:13:41 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 0.6664
2022-06-29 19:14:13 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 0.5518
2022-06-29 19:14:46 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 0.8040
2022-06-29 19:15:18 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 0.6504
2022-06-29 19:15:50 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 0.7374
2022-06-29 19:16:22 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 0.6388
2022-06-29 19:16:54 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 0.6392
2022-06-29 19:17:26 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 0.6633
2022-06-29 19:17:58 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 0.7270
2022-06-29 19:18:30 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 0.7460
2022-06-29 19:19:03 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 0.6758
2022-06-29 19:19:34 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 0.4809
2022-06-29 19:19:36 - train: epoch 089, train_loss: 0.6529
2022-06-29 19:20:50 - eval: epoch: 089, acc1: 76.696%, acc5: 93.178%, test_loss: 0.9426, per_image_load_time: 2.139ms, per_image_inference_time: 0.676ms
2022-06-29 19:20:51 - until epoch: 089, best_acc1: 77.132%
2022-06-29 19:20:51 - epoch 090 lr: 0.001000
2022-06-29 19:21:29 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 0.6051
2022-06-29 19:22:00 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 0.7062
2022-06-29 19:22:32 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 0.6405
2022-06-29 19:23:04 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 0.6107
2022-06-29 19:23:35 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 0.7555
2022-06-29 19:24:07 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 0.7191
2022-06-29 19:24:39 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 0.7227
2022-06-29 19:25:12 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 0.5497
2022-06-29 19:25:44 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 0.5723
2022-06-29 19:26:16 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 0.5547
2022-06-29 19:26:48 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 0.6418
2022-06-29 19:27:19 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 0.6084
2022-06-29 19:27:51 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 0.7985
2022-06-29 19:28:23 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 0.5365
2022-06-29 19:28:55 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 0.7642
2022-06-29 19:29:27 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 0.5956
2022-06-29 19:29:59 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 0.5566
2022-06-29 19:30:31 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 0.5156
2022-06-29 19:31:03 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 0.5580
2022-06-29 19:31:35 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 0.6974
2022-06-29 19:32:07 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 0.7616
2022-06-29 19:32:39 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 0.6660
2022-06-29 19:33:11 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 0.7251
2022-06-29 19:33:44 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 0.6950
2022-06-29 19:34:16 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 0.6838
2022-06-29 19:34:48 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 0.7151
2022-06-29 19:35:20 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 0.6642
2022-06-29 19:35:52 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 0.6315
2022-06-29 19:36:24 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 0.5866
2022-06-29 19:36:56 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 0.6667
2022-06-29 19:37:29 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 0.6053
2022-06-29 19:38:00 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 0.5801
2022-06-29 19:38:32 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 0.7533
2022-06-29 19:39:04 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 0.5687
2022-06-29 19:39:36 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 0.6424
2022-06-29 19:40:08 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 0.6522
2022-06-29 19:40:40 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 0.5844
2022-06-29 19:41:12 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 0.6327
2022-06-29 19:41:45 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 0.4586
2022-06-29 19:42:17 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 0.7551
2022-06-29 19:42:49 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 0.7672
2022-06-29 19:43:21 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 0.6093
2022-06-29 19:43:53 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 0.7010
2022-06-29 19:44:26 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 0.6572
2022-06-29 19:44:57 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 0.6127
2022-06-29 19:45:30 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 0.6627
2022-06-29 19:46:02 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 0.6179
2022-06-29 19:46:34 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 0.6211
2022-06-29 19:47:06 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 0.5397
2022-06-29 19:47:38 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 0.6616
2022-06-29 19:47:39 - train: epoch 090, train_loss: 0.6493
2022-06-29 19:48:53 - eval: epoch: 090, acc1: 76.918%, acc5: 93.306%, test_loss: 0.9437, per_image_load_time: 1.379ms, per_image_inference_time: 0.685ms
2022-06-29 19:48:54 - until epoch: 090, best_acc1: 77.132%
2022-06-29 19:48:54 - epoch 091 lr: 0.000100
2022-06-29 19:49:32 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 0.6514
2022-06-29 19:50:03 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 0.5979
2022-06-29 19:50:35 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 0.5820
2022-06-29 19:51:07 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 0.4770
2022-06-29 19:51:39 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 0.5662
2022-06-29 19:52:11 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 0.6055
2022-06-29 19:52:43 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 0.5938
2022-06-29 19:53:15 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 0.5402
2022-06-29 19:53:47 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 0.6896
2022-06-29 19:54:18 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 0.6619
2022-06-29 19:54:50 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 0.5196
2022-06-29 19:55:22 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 0.7256
2022-06-29 19:55:54 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 0.5768
2022-06-29 19:56:26 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 0.6698
2022-06-29 19:56:58 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 0.6445
2022-06-29 19:57:30 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 0.6265
2022-06-29 19:58:02 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 0.6454
2022-06-29 19:58:34 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 0.6111
2022-06-29 19:59:06 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 0.5429
2022-06-29 19:59:38 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 0.6010
2022-06-29 20:00:10 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 0.5000
2022-06-29 20:00:42 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 0.6279
2022-06-29 20:01:14 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 0.6328
2022-06-29 20:01:46 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 0.5573
2022-06-29 20:02:17 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 0.5390
2022-06-29 20:02:49 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 0.6034
2022-06-29 20:03:21 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 0.4944
2022-06-29 20:03:53 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 0.5925
2022-06-29 20:04:25 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 0.6893
2022-06-29 20:04:57 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 0.7126
2022-06-29 20:05:29 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 0.5191
2022-06-29 20:06:00 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 0.6587
2022-06-29 20:06:32 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 0.5732
2022-06-29 20:07:04 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 0.5042
2022-06-29 20:07:36 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 0.6204
2022-06-29 20:08:08 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 0.5754
2022-06-29 20:08:40 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 0.5509
2022-06-29 20:09:12 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 0.6784
2022-06-29 20:09:44 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 0.6003
2022-06-29 20:10:17 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 0.6908
2022-06-29 20:10:49 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 0.6948
2022-06-29 20:11:21 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 0.6552
2022-06-29 20:11:53 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 0.6159
2022-06-29 20:12:25 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 0.5266
2022-06-29 20:12:57 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 0.5466
2022-06-29 20:13:29 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 0.6126
2022-06-29 20:14:01 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 0.6351
2022-06-29 20:14:33 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 0.5844
2022-06-29 20:15:05 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 0.6398
2022-06-29 20:15:37 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 0.7374
2022-06-29 20:15:38 - train: epoch 091, train_loss: 0.6254
2022-06-29 20:16:52 - eval: epoch: 091, acc1: 77.144%, acc5: 93.414%, test_loss: 0.9307, per_image_load_time: 1.813ms, per_image_inference_time: 0.695ms
2022-06-29 20:16:53 - until epoch: 091, best_acc1: 77.144%
2022-06-29 20:16:53 - epoch 092 lr: 0.000100
2022-06-29 20:17:30 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 0.5671
2022-06-29 20:18:03 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 0.6358
2022-06-29 20:18:34 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 0.5881
2022-06-29 20:19:06 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 0.4787
2022-06-29 20:19:38 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 0.6797
2022-06-29 20:20:10 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 0.6610
2022-06-29 20:20:42 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 0.5720
2022-06-29 20:21:14 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 0.6491
2022-06-29 20:21:46 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 0.6008
2022-06-29 20:22:18 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 0.7536
2022-06-29 20:22:50 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 0.5132
2022-06-29 20:23:22 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 0.5514
2022-06-29 20:23:53 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 0.5830
2022-06-29 20:24:25 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 0.6757
2022-06-29 20:24:57 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 0.5220
2022-06-29 20:25:29 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 0.5983
2022-06-29 20:26:01 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 0.6732
2022-06-29 20:26:32 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 0.5160
2022-06-29 20:27:04 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 0.5658
2022-06-29 20:27:36 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 0.5610
2022-06-29 20:28:08 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 0.6281
2022-06-29 20:28:40 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 0.6918
2022-06-29 20:29:12 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 0.6022
2022-06-29 20:29:44 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 0.5433
2022-06-29 20:30:16 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 0.5676
2022-06-29 20:30:48 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 0.7121
2022-06-29 20:31:19 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 0.6381
2022-06-29 20:31:51 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 0.5384
2022-06-29 20:32:23 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 0.6554
2022-06-29 20:32:55 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 0.4966
2022-06-29 20:33:28 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 0.5719
2022-06-29 20:34:00 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 0.4904
2022-06-29 20:34:32 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 0.6774
2022-06-29 20:35:04 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 0.7287
2022-06-29 20:35:36 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 0.5083
2022-06-29 20:36:08 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 0.5654
2022-06-29 20:36:40 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 0.4816
2022-06-29 20:37:12 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 0.7049
2022-06-29 20:37:44 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 0.6726
2022-06-29 20:38:16 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 0.6923
2022-06-29 20:38:48 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 0.5413
2022-06-29 20:39:20 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 0.6007
2022-06-29 20:39:52 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 0.6268
2022-06-29 20:40:24 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 0.5197
2022-06-29 20:40:56 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 0.5616
2022-06-29 20:41:28 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 0.5245
2022-06-29 20:42:01 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 0.3689
2022-06-29 20:42:33 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 0.5487
2022-06-29 20:43:05 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 0.6359
2022-06-29 20:43:37 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 0.7074
2022-06-29 20:43:39 - train: epoch 092, train_loss: 0.6186
2022-06-29 20:44:52 - eval: epoch: 092, acc1: 77.182%, acc5: 93.440%, test_loss: 0.9318, per_image_load_time: 1.631ms, per_image_inference_time: 0.687ms
2022-06-29 20:44:53 - until epoch: 092, best_acc1: 77.182%
2022-06-29 20:44:53 - epoch 093 lr: 0.000100
2022-06-29 20:45:30 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 0.5424
2022-06-29 20:46:02 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 0.5789
2022-06-29 20:46:34 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 0.5907
2022-06-29 20:47:06 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 0.5619
2022-06-29 20:47:38 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 0.5990
2022-06-29 20:48:10 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 0.6345
2022-06-29 20:48:42 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 0.6637
2022-06-29 20:49:14 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 0.6031
2022-06-29 20:49:46 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 0.5586
2022-06-29 20:50:18 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.5637
2022-06-29 20:50:50 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 0.5442
2022-06-29 20:51:22 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 0.5175
2022-06-29 20:51:54 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 0.6672
2022-06-29 20:52:25 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 0.6190
2022-06-29 20:52:57 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 0.7775
2022-06-29 20:53:29 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 0.6796
2022-06-29 20:54:01 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 0.5910
2022-06-29 20:54:33 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 0.5922
2022-06-29 20:55:05 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 0.5846
2022-06-29 20:55:37 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 0.4938
2022-06-29 20:56:09 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 0.5558
2022-06-29 20:56:41 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 0.7612
2022-06-29 20:57:13 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 0.6242
2022-06-29 20:57:44 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 0.5800
2022-06-29 20:58:16 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 0.6755
2022-06-29 20:58:48 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 0.6474
2022-06-29 20:59:20 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 0.5220
2022-06-29 20:59:52 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 0.5779
2022-06-29 21:00:24 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 0.5796
2022-06-29 21:00:56 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 0.6498
2022-06-29 21:01:28 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 0.7280
2022-06-29 21:02:00 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 0.5568
2022-06-29 21:02:32 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 0.6959
2022-06-29 21:03:04 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 0.7906
2022-06-29 21:03:36 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 0.4548
2022-06-29 21:04:08 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 0.7332
2022-06-29 21:04:40 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 0.5787
2022-06-29 21:05:12 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 0.4706
2022-06-29 21:05:44 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 0.6803
2022-06-29 21:06:16 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 0.7372
2022-06-29 21:06:48 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 0.6602
2022-06-29 21:07:20 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 0.6488
2022-06-29 21:07:51 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 0.7207
2022-06-29 21:08:23 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 0.5681
2022-06-29 21:08:55 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 0.5624
2022-06-29 21:09:27 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 0.4903
2022-06-29 21:09:59 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 0.7464
2022-06-29 21:10:31 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 0.6040
2022-06-29 21:11:03 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 0.7103
2022-06-29 21:11:35 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 0.5851
2022-06-29 21:11:36 - train: epoch 093, train_loss: 0.6150
2022-06-29 21:12:50 - eval: epoch: 093, acc1: 77.236%, acc5: 93.404%, test_loss: 0.9306, per_image_load_time: 1.537ms, per_image_inference_time: 0.693ms
2022-06-29 21:12:51 - until epoch: 093, best_acc1: 77.236%
2022-06-29 21:12:51 - epoch 094 lr: 0.000100
2022-06-29 21:13:28 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 0.5829
2022-06-29 21:14:00 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 0.5950
2022-06-29 21:14:32 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 0.6531
2022-06-29 21:15:04 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 0.7814
2022-06-29 21:15:36 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 0.5899
2022-06-29 21:16:08 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 0.5602
2022-06-29 21:16:40 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 0.6732
2022-06-29 21:17:12 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 0.5273
2022-06-29 21:17:44 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 0.5934
2022-06-29 21:18:15 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 0.7100
2022-06-29 21:18:47 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 0.6339
2022-06-29 21:19:19 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 0.6486
2022-06-29 21:19:51 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 0.6176
2022-06-29 21:20:23 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 0.5899
2022-06-29 21:20:54 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 0.7531
2022-06-29 21:21:26 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 0.9085
2022-06-29 21:21:58 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 0.5467
2022-06-29 21:22:30 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 0.5853
2022-06-29 21:23:02 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 0.6547
2022-06-29 21:23:33 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 0.5525
2022-06-29 21:24:05 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 0.7013
2022-06-29 21:24:37 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 0.5447
2022-06-29 21:25:10 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 0.4518
2022-06-29 21:25:42 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 0.6595
2022-06-29 21:26:14 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 0.5546
2022-06-29 21:26:46 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 0.4449
2022-06-29 21:27:18 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 0.5398
2022-06-29 21:27:50 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 0.6007
2022-06-29 21:28:23 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 0.6967
2022-06-29 21:28:55 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 0.5146
2022-06-29 21:29:26 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 0.7724
2022-06-29 21:29:58 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 0.5879
2022-06-29 21:30:31 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 0.6387
2022-06-29 21:31:02 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 0.6831
2022-06-29 21:31:35 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 0.7474
2022-06-29 21:32:07 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 0.5943
2022-06-29 21:32:39 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 0.6885
2022-06-29 21:33:11 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 0.6608
2022-06-29 21:33:44 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 0.5896
2022-06-29 21:34:15 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 0.7085
2022-06-29 21:34:47 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 0.7730
2022-06-29 21:35:19 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 0.5253
2022-06-29 21:35:51 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 0.7041
2022-06-29 21:36:23 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 0.6630
2022-06-29 21:36:56 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 0.6861
2022-06-29 21:37:28 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 0.6286
2022-06-29 21:38:00 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 0.6053
2022-06-29 21:38:32 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 0.5319
2022-06-29 21:39:05 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 0.5820
2022-06-29 21:39:36 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 0.5267
2022-06-29 21:39:38 - train: epoch 094, train_loss: 0.6144
2022-06-29 21:40:52 - eval: epoch: 094, acc1: 77.248%, acc5: 93.444%, test_loss: 0.9308, per_image_load_time: 2.090ms, per_image_inference_time: 0.692ms
2022-06-29 21:40:53 - until epoch: 094, best_acc1: 77.248%
2022-06-29 21:40:53 - epoch 095 lr: 0.000100
2022-06-29 21:41:30 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 0.4848
2022-06-29 21:42:01 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 0.7664
2022-06-29 21:42:33 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 0.5517
2022-06-29 21:43:04 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 0.6164
2022-06-29 21:43:36 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 0.6655
2022-06-29 21:44:08 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 0.6638
2022-06-29 21:44:39 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 0.7480
2022-06-29 21:45:11 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 0.7943
2022-06-29 21:45:43 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 0.8057
2022-06-29 21:46:15 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 0.6368
2022-06-29 21:46:47 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 0.5058
2022-06-29 21:47:19 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 0.4618
2022-06-29 21:47:51 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 0.5927
2022-06-29 21:48:23 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 0.6156
2022-06-29 21:48:55 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 0.5761
2022-06-29 21:49:27 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.4017
2022-06-29 21:49:58 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 0.7551
2022-06-29 21:50:30 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 0.6222
2022-06-29 21:51:02 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 0.5455
2022-06-29 21:51:34 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 0.6570
2022-06-29 21:52:06 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 0.6011
2022-06-29 21:52:38 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 0.4957
2022-06-29 21:53:10 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 0.5691
2022-06-29 21:53:42 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 0.6630
2022-06-29 21:54:14 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 0.5512
2022-06-29 21:54:46 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 0.5627
2022-06-29 21:55:18 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 0.6444
2022-06-29 21:55:50 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 0.5529
2022-06-29 21:56:22 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 0.5234
2022-06-29 21:56:54 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 0.7295
2022-06-29 21:57:26 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 0.7530
2022-06-29 21:57:58 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 0.5260
2022-06-29 21:58:30 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 0.7220
2022-06-29 21:59:03 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 0.6981
2022-06-29 21:59:35 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 0.5959
2022-06-29 22:00:07 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 0.5779
2022-06-29 22:00:39 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 0.6446
2022-06-29 22:01:11 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 0.4203
2022-06-29 22:01:43 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 0.6398
2022-06-29 22:02:15 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 0.4629
2022-06-29 22:02:47 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 0.6087
2022-06-29 22:03:20 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 0.5487
2022-06-29 22:03:52 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 0.5947
2022-06-29 22:04:24 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 0.6259
2022-06-29 22:04:56 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 0.5058
2022-06-29 22:05:28 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 0.6107
2022-06-29 22:06:00 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 0.6320
2022-06-29 22:06:32 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 0.6962
2022-06-29 22:07:04 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 0.5998
2022-06-29 22:07:35 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 0.4844
2022-06-29 22:07:37 - train: epoch 095, train_loss: 0.6141
2022-06-29 22:08:50 - eval: epoch: 095, acc1: 77.216%, acc5: 93.400%, test_loss: 0.9310, per_image_load_time: 1.920ms, per_image_inference_time: 0.700ms
2022-06-29 22:08:51 - until epoch: 095, best_acc1: 77.248%
2022-06-29 22:08:51 - epoch 096 lr: 0.000100
2022-06-29 22:09:29 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 0.6789
2022-06-29 22:10:00 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 0.6813
2022-06-29 22:10:32 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 0.6546
2022-06-29 22:11:04 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 0.5376
2022-06-29 22:11:36 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 0.6367
2022-06-29 22:12:07 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 0.6452
2022-06-29 22:12:39 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 0.4875
2022-06-29 22:13:11 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 0.5874
2022-06-29 22:13:43 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 0.5606
2022-06-29 22:14:15 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 0.5449
2022-06-29 22:14:46 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 0.6401
2022-06-29 22:15:19 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 0.6482
2022-06-29 22:15:50 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 0.6551
2022-06-29 22:16:22 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 0.5353
2022-06-29 22:16:54 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 0.5508
2022-06-29 22:17:27 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 0.4259
2022-06-29 22:17:59 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 0.6495
2022-06-29 22:18:31 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 0.6344
2022-06-29 22:19:03 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 0.7471
2022-06-29 22:19:34 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 0.5466
2022-06-29 22:20:06 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 0.6209
2022-06-29 22:20:38 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.4624
2022-06-29 22:21:10 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 0.5014
2022-06-29 22:21:42 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 0.5708
2022-06-29 22:22:14 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 0.5546
2022-06-29 22:22:46 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 0.5962
2022-06-29 22:23:19 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 0.6113
2022-06-29 22:23:51 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 0.6703
2022-06-29 22:24:23 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 0.5850
2022-06-29 22:24:56 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 0.5824
2022-06-29 22:25:28 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 0.6337
2022-06-29 22:26:00 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 0.5828
2022-06-29 22:26:32 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 0.6549
2022-06-29 22:27:04 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 0.3891
2022-06-29 22:27:36 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 0.5098
2022-06-29 22:28:09 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 0.4519
2022-06-29 22:28:41 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 0.5995
2022-06-29 22:29:13 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 0.6268
2022-06-29 22:29:45 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 0.5517
2022-06-29 22:30:17 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 0.4426
2022-06-29 22:30:49 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 0.6097
2022-06-29 22:31:21 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 0.6423
2022-06-29 22:31:53 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.3952
2022-06-29 22:32:26 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 0.6424
2022-06-29 22:32:58 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 0.5063
2022-06-29 22:33:30 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 0.6820
2022-06-29 22:34:02 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 0.5385
2022-06-29 22:34:34 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 0.6654
2022-06-29 22:35:06 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 0.7262
2022-06-29 22:35:38 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 0.6004
2022-06-29 22:35:39 - train: epoch 096, train_loss: 0.6107
2022-06-29 22:36:53 - eval: epoch: 096, acc1: 77.244%, acc5: 93.450%, test_loss: 0.9314, per_image_load_time: 2.048ms, per_image_inference_time: 0.672ms
2022-06-29 22:36:54 - until epoch: 096, best_acc1: 77.248%
2022-06-29 22:36:54 - epoch 097 lr: 0.000100
2022-06-29 22:37:31 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 0.6854
2022-06-29 22:38:03 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 0.4729
2022-06-29 22:38:35 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 0.6511
2022-06-29 22:39:07 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 0.7850
2022-06-29 22:39:38 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 0.6001
2022-06-29 22:40:10 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 0.7315
2022-06-29 22:40:41 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 0.6090
2022-06-29 22:41:13 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.5885
2022-06-29 22:41:44 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 0.5121
2022-06-29 22:42:16 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 0.5273
2022-06-29 22:42:48 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 0.5799
2022-06-29 22:43:20 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 0.6006
2022-06-29 22:43:52 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 0.5591
2022-06-29 22:44:24 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 0.5663
2022-06-29 22:44:55 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 0.6426
2022-06-29 22:45:27 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 0.6383
2022-06-29 22:45:59 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 0.5392
2022-06-29 22:46:31 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 0.5937
2022-06-29 22:47:03 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 0.6457
2022-06-29 22:47:34 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 0.5663
2022-06-29 22:48:06 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 0.7017
2022-06-29 22:48:37 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 0.7530
2022-06-29 22:49:09 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 0.5078
2022-06-29 22:49:41 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 0.5973
2022-06-29 22:50:13 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 0.7374
2022-06-29 22:50:45 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 0.6447
2022-06-29 22:51:17 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 0.5206
2022-06-29 22:51:48 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 0.5227
2022-06-29 22:52:21 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 0.7030
2022-06-29 22:52:52 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 0.5438
2022-06-29 22:53:24 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 0.6166
2022-06-29 22:53:56 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 0.6890
2022-06-29 22:54:28 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 0.6575
2022-06-29 22:55:00 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 0.7487
2022-06-29 22:55:31 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 0.6816
2022-06-29 22:56:04 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 0.5908
2022-06-29 22:56:36 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 0.5289
2022-06-29 22:57:08 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 0.5250
2022-06-29 22:57:39 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 0.6646
2022-06-29 22:58:11 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 0.5500
2022-06-29 22:58:43 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 0.5523
2022-06-29 22:59:15 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 0.6492
2022-06-29 22:59:47 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 0.4928
2022-06-29 23:00:18 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 0.5587
2022-06-29 23:00:50 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 0.5650
2022-06-29 23:01:22 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 0.8002
2022-06-29 23:01:54 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 0.6446
2022-06-29 23:02:26 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 0.6024
2022-06-29 23:02:58 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 0.7715
2022-06-29 23:03:30 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 0.6935
2022-06-29 23:03:31 - train: epoch 097, train_loss: 0.6102
2022-06-29 23:04:45 - eval: epoch: 097, acc1: 77.322%, acc5: 93.422%, test_loss: 0.9285, per_image_load_time: 2.016ms, per_image_inference_time: 0.707ms
2022-06-29 23:04:46 - until epoch: 097, best_acc1: 77.322%
2022-06-29 23:04:46 - epoch 098 lr: 0.000100
2022-06-29 23:05:24 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 0.6252
2022-06-29 23:05:55 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 0.6368
2022-06-29 23:06:27 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 0.8184
2022-06-29 23:06:58 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 0.5155
2022-06-29 23:07:30 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 0.6159
2022-06-29 23:08:02 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 0.6216
2022-06-29 23:08:34 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 0.5417
2022-06-29 23:09:06 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 0.6612
2022-06-29 23:09:37 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 0.6573
2022-06-29 23:10:09 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 0.5230
2022-06-29 23:10:41 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 0.5142
2022-06-29 23:11:13 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 0.4564
2022-06-29 23:11:45 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 0.7296
2022-06-29 23:12:17 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 0.5656
2022-06-29 23:12:48 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 0.5567
2022-06-29 23:13:20 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 0.6397
2022-06-29 23:13:51 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 0.6352
2022-06-29 23:14:23 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 0.5331
2022-06-29 23:14:55 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 0.5191
2022-06-29 23:15:26 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 0.7726
2022-06-29 23:15:58 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 0.5010
2022-06-29 23:16:30 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 0.4884
2022-06-29 23:17:01 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 0.6301
2022-06-29 23:17:33 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 0.6523
2022-06-29 23:18:05 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 0.7405
2022-06-29 23:18:37 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 0.6197
2022-06-29 23:19:09 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 0.6412
2022-06-29 23:19:41 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 0.5637
2022-06-29 23:20:13 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 0.5518
2022-06-29 23:20:45 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 0.5892
2022-06-29 23:21:17 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 0.5379
2022-06-29 23:21:49 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 0.5332
2022-06-29 23:22:21 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 0.5164
2022-06-29 23:22:52 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 0.6304
2022-06-29 23:23:24 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 0.5761
2022-06-29 23:23:56 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 0.7383
2022-06-29 23:24:28 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 0.6302
2022-06-29 23:25:00 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 0.6592
2022-06-29 23:25:32 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 0.5624
2022-06-29 23:26:05 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 0.6929
2022-06-29 23:26:37 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 0.6406
2022-06-29 23:27:09 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 0.5587
2022-06-29 23:27:41 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 0.4852
2022-06-29 23:28:13 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 0.6970
2022-06-29 23:28:45 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 0.7051
2022-06-29 23:29:17 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 0.7694
2022-06-29 23:29:50 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 0.6361
2022-06-29 23:30:22 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 0.4286
2022-06-29 23:30:54 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 0.6296
2022-06-29 23:31:26 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 0.7357
2022-06-29 23:31:28 - train: epoch 098, train_loss: 0.6073
2022-06-29 23:32:41 - eval: epoch: 098, acc1: 77.206%, acc5: 93.414%, test_loss: 0.9299, per_image_load_time: 2.115ms, per_image_inference_time: 0.679ms
2022-06-29 23:32:42 - until epoch: 098, best_acc1: 77.322%
2022-06-29 23:32:42 - epoch 099 lr: 0.000100
2022-06-29 23:33:20 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 0.4936
2022-06-29 23:33:51 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 0.4931
2022-06-29 23:34:22 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 0.5847
2022-06-29 23:34:54 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 0.6064
2022-06-29 23:35:25 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 0.7427
2022-06-29 23:35:56 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 0.5993
2022-06-29 23:36:28 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 0.6006
2022-06-29 23:37:00 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 0.6170
2022-06-29 23:37:31 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 0.5925
2022-06-29 23:38:03 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 0.6495
2022-06-29 23:38:35 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 0.5534
2022-06-29 23:39:08 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 0.5916
2022-06-29 23:39:40 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 0.7026
2022-06-29 23:40:12 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 0.6772
2022-06-29 23:40:44 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 0.5154
2022-06-29 23:41:16 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 0.9246
2022-06-29 23:41:48 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 0.5034
2022-06-29 23:42:20 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 0.6059
2022-06-29 23:42:52 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 0.6259
2022-06-29 23:43:25 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 0.5542
2022-06-29 23:43:57 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 0.5637
2022-06-29 23:44:29 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 0.6496
2022-06-29 23:45:01 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 0.6835
2022-06-29 23:45:34 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 0.6656
2022-06-29 23:46:06 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 0.5435
2022-06-29 23:46:38 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 0.4684
2022-06-29 23:47:10 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 0.5519
2022-06-29 23:47:42 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 0.7276
2022-06-29 23:48:14 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 0.5393
2022-06-29 23:48:46 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 0.6873
2022-06-29 23:49:19 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 0.5702
2022-06-29 23:49:51 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 0.6300
2022-06-29 23:50:23 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 0.4859
2022-06-29 23:50:55 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 0.6630
2022-06-29 23:51:28 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 0.6372
2022-06-29 23:52:00 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 0.5731
2022-06-29 23:52:32 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 0.4969
2022-06-29 23:53:04 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 0.8102
2022-06-29 23:53:36 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 0.6542
2022-06-29 23:54:08 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 0.6938
2022-06-29 23:54:41 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 0.4598
2022-06-29 23:55:13 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 0.5337
2022-06-29 23:55:45 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 0.6108
2022-06-29 23:56:17 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 0.6045
2022-06-29 23:56:49 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 0.7051
2022-06-29 23:57:21 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 0.6711
2022-06-29 23:57:54 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 0.4982
2022-06-29 23:58:26 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 0.7820
2022-06-29 23:58:58 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 0.6714
2022-06-29 23:59:30 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 0.5586
2022-06-29 23:59:32 - train: epoch 099, train_loss: 0.6076
2022-06-30 00:00:47 - eval: epoch: 099, acc1: 77.228%, acc5: 93.420%, test_loss: 0.9302, per_image_load_time: 2.178ms, per_image_inference_time: 0.676ms
2022-06-30 00:00:47 - until epoch: 099, best_acc1: 77.322%
2022-06-30 00:00:47 - epoch 100 lr: 0.000100
2022-06-30 00:01:25 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 0.5658
2022-06-30 00:01:56 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 0.7306
2022-06-30 00:02:28 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 0.5254
2022-06-30 00:03:00 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 0.4603
2022-06-30 00:03:32 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 0.6124
2022-06-30 00:04:04 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 0.8412
2022-06-30 00:04:36 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 0.5279
2022-06-30 00:05:08 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 0.6257
2022-06-30 00:05:40 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 0.4750
2022-06-30 00:06:12 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 0.6337
2022-06-30 00:06:43 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 0.5371
2022-06-30 00:07:15 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 0.6132
2022-06-30 00:07:47 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 0.6917
2022-06-30 00:08:19 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 0.5883
2022-06-30 00:08:51 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 0.6176
2022-06-30 00:09:23 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 0.5317
2022-06-30 00:09:55 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 0.6414
2022-06-30 00:10:27 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 0.7218
2022-06-30 00:10:59 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 0.5231
2022-06-30 00:11:31 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 0.5916
2022-06-30 00:12:04 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 0.4767
2022-06-30 00:12:36 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 0.6727
2022-06-30 00:13:08 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 0.5249
2022-06-30 00:13:40 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 0.5820
2022-06-30 00:14:12 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 0.5575
2022-06-30 00:14:44 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 0.6407
2022-06-30 00:15:16 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 0.5293
2022-06-30 00:15:48 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 0.6469
2022-06-30 00:16:20 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 0.6444
2022-06-30 00:16:52 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 0.4747
2022-06-30 00:17:24 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 0.5589
2022-06-30 00:17:56 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 0.6045
2022-06-30 00:18:28 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 0.6871
2022-06-30 00:19:00 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 0.7370
2022-06-30 00:19:32 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 0.5471
2022-06-30 00:20:04 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 0.6802
2022-06-30 00:20:36 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 0.5760
2022-06-30 00:21:08 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 0.6854
2022-06-30 00:21:40 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 0.6561
2022-06-30 00:22:12 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 0.5059
2022-06-30 00:22:44 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 0.6899
2022-06-30 00:23:16 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 0.5544
2022-06-30 00:23:48 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 0.5636
2022-06-30 00:24:20 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 0.6947
2022-06-30 00:24:53 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 0.5248
2022-06-30 00:25:25 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 0.5501
2022-06-30 00:25:57 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 0.6176
2022-06-30 00:26:29 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 0.4800
2022-06-30 00:27:01 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 0.5782
2022-06-30 00:27:33 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 0.6110
2022-06-30 00:27:35 - train: epoch 100, train_loss: 0.6069
2022-06-30 00:28:49 - eval: epoch: 100, acc1: 77.214%, acc5: 93.438%, test_loss: 0.9341, per_image_load_time: 2.095ms, per_image_inference_time: 0.680ms
2022-06-30 00:28:49 - until epoch: 100, best_acc1: 77.322%
2022-06-30 00:28:49 - train done. model: resnet101, train time: 46.920 hours, best_acc1: 77.322%
