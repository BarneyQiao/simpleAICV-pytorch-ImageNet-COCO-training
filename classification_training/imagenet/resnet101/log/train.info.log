2022-02-21 11:29:21 - train: epoch 0051, iter [03800, 05004], lr: 0.010000, loss: 1.2251
2022-02-21 11:29:54 - train: epoch 0051, iter [03900, 05004], lr: 0.010000, loss: 1.2985
2022-02-21 11:30:26 - train: epoch 0051, iter [04000, 05004], lr: 0.010000, loss: 1.1444
2022-02-21 11:30:58 - train: epoch 0051, iter [04100, 05004], lr: 0.010000, loss: 1.3742
2022-02-21 11:31:30 - train: epoch 0051, iter [04200, 05004], lr: 0.010000, loss: 1.4570
2022-02-21 11:32:02 - train: epoch 0051, iter [04300, 05004], lr: 0.010000, loss: 1.2193
2022-02-21 11:32:34 - train: epoch 0051, iter [04400, 05004], lr: 0.010000, loss: 1.2532
2022-02-21 11:33:06 - train: epoch 0051, iter [04500, 05004], lr: 0.010000, loss: 1.1131
2022-02-21 11:33:38 - train: epoch 0051, iter [04600, 05004], lr: 0.010000, loss: 1.3220
2022-02-21 11:34:11 - train: epoch 0051, iter [04700, 05004], lr: 0.010000, loss: 1.2665
2022-02-21 11:34:44 - train: epoch 0051, iter [04800, 05004], lr: 0.010000, loss: 1.1168
2022-02-21 11:35:17 - train: epoch 0051, iter [04900, 05004], lr: 0.010000, loss: 1.3707
2022-02-21 11:35:51 - train: epoch 0051, iter [05000, 05004], lr: 0.010000, loss: 1.0942
2022-02-21 11:35:54 - train: epoch 051, train_loss: 1.2285
2022-02-21 11:37:10 - eval: epoch: 051, acc1: 72.050%, acc5: 90.988%, test_loss: 1.1043, per_image_load_time: 1.907ms, per_image_inference_time: 0.736ms
2022-02-21 11:37:11 - until epoch: 051, best_acc1: 73.016%
2022-02-21 11:37:11 - epoch 052 lr: 0.010000000000000002
2022-02-21 11:37:48 - train: epoch 0052, iter [00100, 05004], lr: 0.010000, loss: 1.0751
2022-02-21 11:38:19 - train: epoch 0052, iter [00200, 05004], lr: 0.010000, loss: 1.2172
2022-02-21 11:38:51 - train: epoch 0052, iter [00300, 05004], lr: 0.010000, loss: 1.3028
2022-02-21 11:39:22 - train: epoch 0052, iter [00400, 05004], lr: 0.010000, loss: 1.2897
2022-02-21 11:39:55 - train: epoch 0052, iter [00500, 05004], lr: 0.010000, loss: 1.3205
2022-02-21 11:40:27 - train: epoch 0052, iter [00600, 05004], lr: 0.010000, loss: 1.1580
2022-02-21 11:40:59 - train: epoch 0052, iter [00700, 05004], lr: 0.010000, loss: 1.1940
2022-02-21 11:41:31 - train: epoch 0052, iter [00800, 05004], lr: 0.010000, loss: 1.2154
2022-02-21 11:42:03 - train: epoch 0052, iter [00900, 05004], lr: 0.010000, loss: 1.3194
2022-02-21 11:42:35 - train: epoch 0052, iter [01000, 05004], lr: 0.010000, loss: 1.4163
2022-02-21 11:43:07 - train: epoch 0052, iter [01100, 05004], lr: 0.010000, loss: 1.2346
2022-02-21 11:43:40 - train: epoch 0052, iter [01200, 05004], lr: 0.010000, loss: 1.1324
2022-02-21 11:44:12 - train: epoch 0052, iter [01300, 05004], lr: 0.010000, loss: 1.1491
2022-02-21 11:44:44 - train: epoch 0052, iter [01400, 05004], lr: 0.010000, loss: 1.4342
2022-02-21 11:45:16 - train: epoch 0052, iter [01500, 05004], lr: 0.010000, loss: 1.1071
2022-02-21 11:45:48 - train: epoch 0052, iter [01600, 05004], lr: 0.010000, loss: 1.1190
2022-02-21 11:46:21 - train: epoch 0052, iter [01700, 05004], lr: 0.010000, loss: 1.0497
2022-02-21 11:46:53 - train: epoch 0052, iter [01800, 05004], lr: 0.010000, loss: 1.0486
2022-02-21 11:47:25 - train: epoch 0052, iter [01900, 05004], lr: 0.010000, loss: 1.2818
2022-02-21 11:47:58 - train: epoch 0052, iter [02000, 05004], lr: 0.010000, loss: 1.3132
2022-02-21 11:48:30 - train: epoch 0052, iter [02100, 05004], lr: 0.010000, loss: 1.0914
2022-02-21 11:49:02 - train: epoch 0052, iter [02200, 05004], lr: 0.010000, loss: 1.3129
2022-02-21 11:49:34 - train: epoch 0052, iter [02300, 05004], lr: 0.010000, loss: 1.0153
2022-02-21 11:50:06 - train: epoch 0052, iter [02400, 05004], lr: 0.010000, loss: 1.1136
2022-02-21 11:50:37 - train: epoch 0052, iter [02500, 05004], lr: 0.010000, loss: 1.1524
2022-02-21 11:51:09 - train: epoch 0052, iter [02600, 05004], lr: 0.010000, loss: 1.0279
2022-02-21 11:51:42 - train: epoch 0052, iter [02700, 05004], lr: 0.010000, loss: 1.1752
2022-02-21 11:52:14 - train: epoch 0052, iter [02800, 05004], lr: 0.010000, loss: 1.1725
2022-02-21 11:52:47 - train: epoch 0052, iter [02900, 05004], lr: 0.010000, loss: 1.1085
2022-02-21 11:53:19 - train: epoch 0052, iter [03000, 05004], lr: 0.010000, loss: 1.1756
2022-02-21 11:53:51 - train: epoch 0052, iter [03100, 05004], lr: 0.010000, loss: 1.2550
2022-02-21 11:54:23 - train: epoch 0052, iter [03200, 05004], lr: 0.010000, loss: 1.3192
2022-02-21 11:54:55 - train: epoch 0052, iter [03300, 05004], lr: 0.010000, loss: 1.2913
2022-02-21 11:55:27 - train: epoch 0052, iter [03400, 05004], lr: 0.010000, loss: 1.3536
2022-02-21 11:55:59 - train: epoch 0052, iter [03500, 05004], lr: 0.010000, loss: 1.2548
2022-02-21 11:56:32 - train: epoch 0052, iter [03600, 05004], lr: 0.010000, loss: 1.3064
2022-02-21 11:57:04 - train: epoch 0052, iter [03700, 05004], lr: 0.010000, loss: 1.4097
2022-02-21 11:57:36 - train: epoch 0052, iter [03800, 05004], lr: 0.010000, loss: 1.1581
2022-02-21 11:58:09 - train: epoch 0052, iter [03900, 05004], lr: 0.010000, loss: 1.2084
2022-02-21 11:58:41 - train: epoch 0052, iter [04000, 05004], lr: 0.010000, loss: 1.4256
2022-02-21 11:59:13 - train: epoch 0052, iter [04100, 05004], lr: 0.010000, loss: 1.1298
2022-02-21 11:59:46 - train: epoch 0052, iter [04200, 05004], lr: 0.010000, loss: 1.1589
2022-02-21 12:00:18 - train: epoch 0052, iter [04300, 05004], lr: 0.010000, loss: 1.2993
2022-02-21 12:00:51 - train: epoch 0052, iter [04400, 05004], lr: 0.010000, loss: 1.2386
2022-02-21 12:01:23 - train: epoch 0052, iter [04500, 05004], lr: 0.010000, loss: 1.0865
2022-02-21 12:01:56 - train: epoch 0052, iter [04600, 05004], lr: 0.010000, loss: 1.4108
2022-02-21 12:02:29 - train: epoch 0052, iter [04700, 05004], lr: 0.010000, loss: 1.2202
2022-02-21 12:03:02 - train: epoch 0052, iter [04800, 05004], lr: 0.010000, loss: 1.1126
2022-02-21 12:03:35 - train: epoch 0052, iter [04900, 05004], lr: 0.010000, loss: 1.0653
2022-02-21 12:04:09 - train: epoch 0052, iter [05000, 05004], lr: 0.010000, loss: 1.3275
2022-02-21 12:04:12 - train: epoch 052, train_loss: 1.2232
2022-02-21 12:05:27 - eval: epoch: 052, acc1: 71.986%, acc5: 91.040%, test_loss: 1.1073, per_image_load_time: 1.278ms, per_image_inference_time: 0.728ms
2022-02-21 12:05:29 - until epoch: 052, best_acc1: 73.016%
2022-02-21 12:05:29 - epoch 053 lr: 0.010000000000000002
2022-02-21 12:06:06 - train: epoch 0053, iter [00100, 05004], lr: 0.010000, loss: 1.1597
2022-02-21 12:06:38 - train: epoch 0053, iter [00200, 05004], lr: 0.010000, loss: 1.4324
2022-02-21 12:07:09 - train: epoch 0053, iter [00300, 05004], lr: 0.010000, loss: 1.2165
2022-02-21 12:07:41 - train: epoch 0053, iter [00400, 05004], lr: 0.010000, loss: 1.2272
2022-02-21 12:08:13 - train: epoch 0053, iter [00500, 05004], lr: 0.010000, loss: 1.2815
2022-02-21 12:08:45 - train: epoch 0053, iter [00600, 05004], lr: 0.010000, loss: 1.1245
2022-02-21 12:09:17 - train: epoch 0053, iter [00700, 05004], lr: 0.010000, loss: 1.0822
2022-02-21 12:09:49 - train: epoch 0053, iter [00800, 05004], lr: 0.010000, loss: 1.3162
2022-02-21 12:10:21 - train: epoch 0053, iter [00900, 05004], lr: 0.010000, loss: 1.2201
2022-02-21 12:10:53 - train: epoch 0053, iter [01000, 05004], lr: 0.010000, loss: 1.1056
2022-02-21 12:11:25 - train: epoch 0053, iter [01100, 05004], lr: 0.010000, loss: 1.1607
2022-02-21 12:11:57 - train: epoch 0053, iter [01200, 05004], lr: 0.010000, loss: 1.2116
2022-02-21 12:12:28 - train: epoch 0053, iter [01300, 05004], lr: 0.010000, loss: 1.2537
2022-02-21 12:13:00 - train: epoch 0053, iter [01400, 05004], lr: 0.010000, loss: 1.3790
2022-02-21 12:13:33 - train: epoch 0053, iter [01500, 05004], lr: 0.010000, loss: 1.1720
2022-02-21 12:14:05 - train: epoch 0053, iter [01600, 05004], lr: 0.010000, loss: 1.4267
2022-02-21 12:14:37 - train: epoch 0053, iter [01700, 05004], lr: 0.010000, loss: 1.3900
2022-02-21 12:15:09 - train: epoch 0053, iter [01800, 05004], lr: 0.010000, loss: 1.3157
2022-02-21 12:15:41 - train: epoch 0053, iter [01900, 05004], lr: 0.010000, loss: 1.0440
2022-02-21 12:16:13 - train: epoch 0053, iter [02000, 05004], lr: 0.010000, loss: 1.2652
2022-02-21 12:16:45 - train: epoch 0053, iter [02100, 05004], lr: 0.010000, loss: 1.2137
2022-02-21 12:17:18 - train: epoch 0053, iter [02200, 05004], lr: 0.010000, loss: 1.1004
2022-02-21 12:17:50 - train: epoch 0053, iter [02300, 05004], lr: 0.010000, loss: 1.2250
2022-02-21 12:18:21 - train: epoch 0053, iter [02400, 05004], lr: 0.010000, loss: 1.3626
2022-02-21 12:18:54 - train: epoch 0053, iter [02500, 05004], lr: 0.010000, loss: 1.4501
2022-02-21 12:19:25 - train: epoch 0053, iter [02600, 05004], lr: 0.010000, loss: 1.2283
2022-02-21 12:19:57 - train: epoch 0053, iter [02700, 05004], lr: 0.010000, loss: 1.4507
2022-02-21 12:20:30 - train: epoch 0053, iter [02800, 05004], lr: 0.010000, loss: 1.3360
2022-02-21 12:21:02 - train: epoch 0053, iter [02900, 05004], lr: 0.010000, loss: 1.0862
2022-02-21 12:21:34 - train: epoch 0053, iter [03000, 05004], lr: 0.010000, loss: 1.0408
2022-02-21 12:22:06 - train: epoch 0053, iter [03100, 05004], lr: 0.010000, loss: 1.3760
2022-02-21 12:22:38 - train: epoch 0053, iter [03200, 05004], lr: 0.010000, loss: 1.4054
2022-02-21 12:23:10 - train: epoch 0053, iter [03300, 05004], lr: 0.010000, loss: 1.2293
2022-02-21 12:23:42 - train: epoch 0053, iter [03400, 05004], lr: 0.010000, loss: 1.3582
2022-02-21 12:24:14 - train: epoch 0053, iter [03500, 05004], lr: 0.010000, loss: 1.3125
2022-02-21 12:24:46 - train: epoch 0053, iter [03600, 05004], lr: 0.010000, loss: 1.3636
2022-02-21 12:25:18 - train: epoch 0053, iter [03700, 05004], lr: 0.010000, loss: 1.3759
2022-02-21 12:25:51 - train: epoch 0053, iter [03800, 05004], lr: 0.010000, loss: 1.1632
2022-02-21 12:26:23 - train: epoch 0053, iter [03900, 05004], lr: 0.010000, loss: 1.3596
2022-02-21 12:26:55 - train: epoch 0053, iter [04000, 05004], lr: 0.010000, loss: 1.3435
2022-02-21 12:27:27 - train: epoch 0053, iter [04100, 05004], lr: 0.010000, loss: 1.3090
2022-02-21 12:27:59 - train: epoch 0053, iter [04200, 05004], lr: 0.010000, loss: 1.3120
2022-02-21 12:28:32 - train: epoch 0053, iter [04300, 05004], lr: 0.010000, loss: 1.4963
2022-02-21 12:29:04 - train: epoch 0053, iter [04400, 05004], lr: 0.010000, loss: 1.2195
2022-02-21 12:29:37 - train: epoch 0053, iter [04500, 05004], lr: 0.010000, loss: 1.2462
2022-02-21 12:30:09 - train: epoch 0053, iter [04600, 05004], lr: 0.010000, loss: 1.1011
2022-02-21 12:30:42 - train: epoch 0053, iter [04700, 05004], lr: 0.010000, loss: 1.4063
2022-02-21 12:31:15 - train: epoch 0053, iter [04800, 05004], lr: 0.010000, loss: 1.3433
2022-02-21 12:31:48 - train: epoch 0053, iter [04900, 05004], lr: 0.010000, loss: 1.0762
2022-02-21 12:32:22 - train: epoch 0053, iter [05000, 05004], lr: 0.010000, loss: 1.1324
2022-02-21 12:32:25 - train: epoch 053, train_loss: 1.2218
2022-02-21 12:33:41 - eval: epoch: 053, acc1: 72.206%, acc5: 90.966%, test_loss: 1.1092, per_image_load_time: 2.178ms, per_image_inference_time: 0.706ms
2022-02-21 12:33:42 - until epoch: 053, best_acc1: 73.016%
2022-02-21 12:33:42 - epoch 054 lr: 0.010000000000000002
2022-02-21 12:34:19 - train: epoch 0054, iter [00100, 05004], lr: 0.010000, loss: 1.0749
2022-02-21 12:34:51 - train: epoch 0054, iter [00200, 05004], lr: 0.010000, loss: 1.5484
2022-02-21 12:35:23 - train: epoch 0054, iter [00300, 05004], lr: 0.010000, loss: 1.2155
2022-02-21 12:35:55 - train: epoch 0054, iter [00400, 05004], lr: 0.010000, loss: 0.9798
2022-02-21 12:36:27 - train: epoch 0054, iter [00500, 05004], lr: 0.010000, loss: 1.2768
2022-02-21 12:36:59 - train: epoch 0054, iter [00600, 05004], lr: 0.010000, loss: 1.1414
2022-02-21 12:37:31 - train: epoch 0054, iter [00700, 05004], lr: 0.010000, loss: 1.1828
2022-02-21 12:38:03 - train: epoch 0054, iter [00800, 05004], lr: 0.010000, loss: 1.3406
2022-02-21 12:38:35 - train: epoch 0054, iter [00900, 05004], lr: 0.010000, loss: 1.0657
2022-02-21 12:39:07 - train: epoch 0054, iter [01000, 05004], lr: 0.010000, loss: 1.0527
2022-02-21 12:39:39 - train: epoch 0054, iter [01100, 05004], lr: 0.010000, loss: 1.0291
2022-02-21 12:40:11 - train: epoch 0054, iter [01200, 05004], lr: 0.010000, loss: 1.3265
2022-02-21 12:40:43 - train: epoch 0054, iter [01300, 05004], lr: 0.010000, loss: 1.1590
2022-02-21 12:41:15 - train: epoch 0054, iter [01400, 05004], lr: 0.010000, loss: 1.1687
2022-02-21 12:41:47 - train: epoch 0054, iter [01500, 05004], lr: 0.010000, loss: 1.2236
2022-02-21 12:42:19 - train: epoch 0054, iter [01600, 05004], lr: 0.010000, loss: 0.9083
2022-02-21 12:42:51 - train: epoch 0054, iter [01700, 05004], lr: 0.010000, loss: 1.2252
2022-02-21 12:43:23 - train: epoch 0054, iter [01800, 05004], lr: 0.010000, loss: 1.1818
2022-02-21 12:43:56 - train: epoch 0054, iter [01900, 05004], lr: 0.010000, loss: 1.5164
2022-02-21 12:44:28 - train: epoch 0054, iter [02000, 05004], lr: 0.010000, loss: 1.2468
2022-02-21 12:44:59 - train: epoch 0054, iter [02100, 05004], lr: 0.010000, loss: 1.0489
2022-02-21 12:45:31 - train: epoch 0054, iter [02200, 05004], lr: 0.010000, loss: 1.1704
2022-02-21 12:46:03 - train: epoch 0054, iter [02300, 05004], lr: 0.010000, loss: 1.3635
2022-02-21 12:46:35 - train: epoch 0054, iter [02400, 05004], lr: 0.010000, loss: 1.1134
2022-02-21 12:47:07 - train: epoch 0054, iter [02500, 05004], lr: 0.010000, loss: 1.2424
2022-02-21 12:47:40 - train: epoch 0054, iter [02600, 05004], lr: 0.010000, loss: 1.1574
2022-02-21 12:48:12 - train: epoch 0054, iter [02700, 05004], lr: 0.010000, loss: 1.2515
2022-02-21 12:48:44 - train: epoch 0054, iter [02800, 05004], lr: 0.010000, loss: 1.5335
2022-02-21 12:49:16 - train: epoch 0054, iter [02900, 05004], lr: 0.010000, loss: 1.0724
2022-02-21 12:49:48 - train: epoch 0054, iter [03000, 05004], lr: 0.010000, loss: 1.2393
2022-02-21 12:50:20 - train: epoch 0054, iter [03100, 05004], lr: 0.010000, loss: 1.2314
2022-02-21 12:50:51 - train: epoch 0054, iter [03200, 05004], lr: 0.010000, loss: 1.3940
2022-02-21 12:51:23 - train: epoch 0054, iter [03300, 05004], lr: 0.010000, loss: 1.2362
2022-02-21 12:51:55 - train: epoch 0054, iter [03400, 05004], lr: 0.010000, loss: 1.2874
2022-02-21 12:52:27 - train: epoch 0054, iter [03500, 05004], lr: 0.010000, loss: 1.3006
2022-02-21 12:52:59 - train: epoch 0054, iter [03600, 05004], lr: 0.010000, loss: 1.1315
2022-02-21 12:53:31 - train: epoch 0054, iter [03700, 05004], lr: 0.010000, loss: 1.0897
2022-02-21 12:54:03 - train: epoch 0054, iter [03800, 05004], lr: 0.010000, loss: 1.2269
2022-02-21 12:54:35 - train: epoch 0054, iter [03900, 05004], lr: 0.010000, loss: 1.2385
2022-02-21 12:55:08 - train: epoch 0054, iter [04000, 05004], lr: 0.010000, loss: 1.0580
2022-02-21 12:55:40 - train: epoch 0054, iter [04100, 05004], lr: 0.010000, loss: 1.2123
2022-02-21 12:56:12 - train: epoch 0054, iter [04200, 05004], lr: 0.010000, loss: 1.2156
2022-02-21 12:56:44 - train: epoch 0054, iter [04300, 05004], lr: 0.010000, loss: 1.3116
2022-02-21 12:57:16 - train: epoch 0054, iter [04400, 05004], lr: 0.010000, loss: 1.0517
2022-02-21 12:57:49 - train: epoch 0054, iter [04500, 05004], lr: 0.010000, loss: 1.0180
2022-02-21 12:58:21 - train: epoch 0054, iter [04600, 05004], lr: 0.010000, loss: 1.2590
2022-02-21 12:58:54 - train: epoch 0054, iter [04700, 05004], lr: 0.010000, loss: 1.3653
2022-02-21 12:59:27 - train: epoch 0054, iter [04800, 05004], lr: 0.010000, loss: 1.4456
2022-02-21 13:00:01 - train: epoch 0054, iter [04900, 05004], lr: 0.010000, loss: 1.1632
2022-02-21 13:00:34 - train: epoch 0054, iter [05000, 05004], lr: 0.010000, loss: 1.2131
2022-02-21 13:00:37 - train: epoch 054, train_loss: 1.2223
2022-02-21 13:01:52 - eval: epoch: 054, acc1: 71.318%, acc5: 90.716%, test_loss: 1.1353, per_image_load_time: 2.154ms, per_image_inference_time: 0.697ms
2022-02-21 13:01:53 - until epoch: 054, best_acc1: 73.016%
2022-02-21 13:01:53 - epoch 055 lr: 0.010000000000000002
2022-02-21 13:02:31 - train: epoch 0055, iter [00100, 05004], lr: 0.010000, loss: 1.1877
2022-02-21 13:03:02 - train: epoch 0055, iter [00200, 05004], lr: 0.010000, loss: 1.0479
2022-02-21 13:03:34 - train: epoch 0055, iter [00300, 05004], lr: 0.010000, loss: 1.0111
2022-02-21 13:04:07 - train: epoch 0055, iter [00400, 05004], lr: 0.010000, loss: 1.2249
2022-02-21 13:04:39 - train: epoch 0055, iter [00500, 05004], lr: 0.010000, loss: 1.0170
2022-02-21 13:05:11 - train: epoch 0055, iter [00600, 05004], lr: 0.010000, loss: 1.0500
2022-02-21 13:05:44 - train: epoch 0055, iter [00700, 05004], lr: 0.010000, loss: 1.3125
2022-02-21 13:06:16 - train: epoch 0055, iter [00800, 05004], lr: 0.010000, loss: 1.0937
2022-02-21 13:06:49 - train: epoch 0055, iter [00900, 05004], lr: 0.010000, loss: 1.1655
2022-02-21 13:07:21 - train: epoch 0055, iter [01000, 05004], lr: 0.010000, loss: 1.2771
2022-02-21 13:07:53 - train: epoch 0055, iter [01100, 05004], lr: 0.010000, loss: 1.2346
2022-02-21 13:08:26 - train: epoch 0055, iter [01200, 05004], lr: 0.010000, loss: 1.2626
2022-02-21 13:08:59 - train: epoch 0055, iter [01300, 05004], lr: 0.010000, loss: 1.3176
2022-02-21 13:09:31 - train: epoch 0055, iter [01400, 05004], lr: 0.010000, loss: 1.1150
2022-02-21 13:10:03 - train: epoch 0055, iter [01500, 05004], lr: 0.010000, loss: 1.2398
2022-02-21 13:10:36 - train: epoch 0055, iter [01600, 05004], lr: 0.010000, loss: 1.4085
2022-02-21 13:11:08 - train: epoch 0055, iter [01700, 05004], lr: 0.010000, loss: 1.1996
2022-02-21 13:11:40 - train: epoch 0055, iter [01800, 05004], lr: 0.010000, loss: 1.3047
2022-02-21 13:12:13 - train: epoch 0055, iter [01900, 05004], lr: 0.010000, loss: 1.1970
2022-02-21 13:12:45 - train: epoch 0055, iter [02000, 05004], lr: 0.010000, loss: 1.1321
2022-02-21 13:13:17 - train: epoch 0055, iter [02100, 05004], lr: 0.010000, loss: 1.0161
2022-02-21 13:13:49 - train: epoch 0055, iter [02200, 05004], lr: 0.010000, loss: 1.2814
2022-02-21 13:14:22 - train: epoch 0055, iter [02300, 05004], lr: 0.010000, loss: 1.2068
2022-02-21 13:14:54 - train: epoch 0055, iter [02400, 05004], lr: 0.010000, loss: 1.1111
2022-02-21 13:15:26 - train: epoch 0055, iter [02500, 05004], lr: 0.010000, loss: 1.2575
2022-02-21 13:15:58 - train: epoch 0055, iter [02600, 05004], lr: 0.010000, loss: 1.0867
2022-02-21 13:16:31 - train: epoch 0055, iter [02700, 05004], lr: 0.010000, loss: 1.0666
2022-02-21 13:17:03 - train: epoch 0055, iter [02800, 05004], lr: 0.010000, loss: 1.2623
2022-02-21 13:17:35 - train: epoch 0055, iter [02900, 05004], lr: 0.010000, loss: 1.2587
2022-02-21 13:18:07 - train: epoch 0055, iter [03000, 05004], lr: 0.010000, loss: 1.0826
2022-02-21 13:18:39 - train: epoch 0055, iter [03100, 05004], lr: 0.010000, loss: 1.4037
2022-02-21 13:19:12 - train: epoch 0055, iter [03200, 05004], lr: 0.010000, loss: 1.1316
2022-02-21 13:19:44 - train: epoch 0055, iter [03300, 05004], lr: 0.010000, loss: 0.9814
2022-02-21 13:20:16 - train: epoch 0055, iter [03400, 05004], lr: 0.010000, loss: 1.1515
2022-02-21 13:20:48 - train: epoch 0055, iter [03500, 05004], lr: 0.010000, loss: 1.0486
2022-02-21 13:21:20 - train: epoch 0055, iter [03600, 05004], lr: 0.010000, loss: 1.1834
2022-02-21 13:21:53 - train: epoch 0055, iter [03700, 05004], lr: 0.010000, loss: 1.2547
2022-02-21 13:22:25 - train: epoch 0055, iter [03800, 05004], lr: 0.010000, loss: 1.2972
2022-02-21 13:22:57 - train: epoch 0055, iter [03900, 05004], lr: 0.010000, loss: 1.5091
2022-02-21 13:23:29 - train: epoch 0055, iter [04000, 05004], lr: 0.010000, loss: 1.2424
2022-02-21 13:24:02 - train: epoch 0055, iter [04100, 05004], lr: 0.010000, loss: 1.2082
2022-02-21 13:24:34 - train: epoch 0055, iter [04200, 05004], lr: 0.010000, loss: 1.1739
2022-02-21 13:25:07 - train: epoch 0055, iter [04300, 05004], lr: 0.010000, loss: 1.2603
2022-02-21 13:25:40 - train: epoch 0055, iter [04400, 05004], lr: 0.010000, loss: 1.4805
2022-02-21 13:26:13 - train: epoch 0055, iter [04500, 05004], lr: 0.010000, loss: 1.2279
2022-02-21 13:26:45 - train: epoch 0055, iter [04600, 05004], lr: 0.010000, loss: 1.3701
2022-02-21 13:27:18 - train: epoch 0055, iter [04700, 05004], lr: 0.010000, loss: 1.0477
2022-02-21 13:27:51 - train: epoch 0055, iter [04800, 05004], lr: 0.010000, loss: 1.2709
2022-02-21 13:28:25 - train: epoch 0055, iter [04900, 05004], lr: 0.010000, loss: 1.2016
2022-02-21 13:28:58 - train: epoch 0055, iter [05000, 05004], lr: 0.010000, loss: 1.3012
2022-02-21 13:29:01 - train: epoch 055, train_loss: 1.2170
2022-02-21 13:30:16 - eval: epoch: 055, acc1: 71.888%, acc5: 91.020%, test_loss: 1.1098, per_image_load_time: 1.822ms, per_image_inference_time: 0.737ms
2022-02-21 13:30:17 - until epoch: 055, best_acc1: 73.016%
2022-02-21 13:30:17 - epoch 056 lr: 0.010000000000000002
2022-02-21 13:30:55 - train: epoch 0056, iter [00100, 05004], lr: 0.010000, loss: 1.3340
2022-02-21 13:31:26 - train: epoch 0056, iter [00200, 05004], lr: 0.010000, loss: 1.3061
2022-02-21 13:31:58 - train: epoch 0056, iter [00300, 05004], lr: 0.010000, loss: 1.2029
2022-02-21 13:32:30 - train: epoch 0056, iter [00400, 05004], lr: 0.010000, loss: 1.2704
2022-02-21 13:33:02 - train: epoch 0056, iter [00500, 05004], lr: 0.010000, loss: 1.1227
2022-02-21 13:33:34 - train: epoch 0056, iter [00600, 05004], lr: 0.010000, loss: 1.1995
2022-02-21 13:34:06 - train: epoch 0056, iter [00700, 05004], lr: 0.010000, loss: 1.1903
2022-02-21 13:34:38 - train: epoch 0056, iter [00800, 05004], lr: 0.010000, loss: 1.3589
2022-02-21 13:35:10 - train: epoch 0056, iter [00900, 05004], lr: 0.010000, loss: 1.1778
2022-02-21 13:35:42 - train: epoch 0056, iter [01000, 05004], lr: 0.010000, loss: 1.2236
2022-02-21 13:36:14 - train: epoch 0056, iter [01100, 05004], lr: 0.010000, loss: 1.1280
2022-02-21 13:36:46 - train: epoch 0056, iter [01200, 05004], lr: 0.010000, loss: 1.0886
2022-02-21 13:37:18 - train: epoch 0056, iter [01300, 05004], lr: 0.010000, loss: 1.2344
2022-02-21 13:37:50 - train: epoch 0056, iter [01400, 05004], lr: 0.010000, loss: 1.1529
2022-02-21 13:38:23 - train: epoch 0056, iter [01500, 05004], lr: 0.010000, loss: 1.4422
2022-02-21 13:38:55 - train: epoch 0056, iter [01600, 05004], lr: 0.010000, loss: 1.1236
2022-02-21 13:39:27 - train: epoch 0056, iter [01700, 05004], lr: 0.010000, loss: 1.2651
2022-02-21 13:40:00 - train: epoch 0056, iter [01800, 05004], lr: 0.010000, loss: 1.4959
2022-02-21 13:40:32 - train: epoch 0056, iter [01900, 05004], lr: 0.010000, loss: 1.1885
2022-02-21 13:41:04 - train: epoch 0056, iter [02000, 05004], lr: 0.010000, loss: 1.2283
2022-02-21 13:41:36 - train: epoch 0056, iter [02100, 05004], lr: 0.010000, loss: 1.2552
2022-02-21 13:42:09 - train: epoch 0056, iter [02200, 05004], lr: 0.010000, loss: 1.3424
2022-02-21 13:42:41 - train: epoch 0056, iter [02300, 05004], lr: 0.010000, loss: 1.2950
2022-02-21 13:43:13 - train: epoch 0056, iter [02400, 05004], lr: 0.010000, loss: 1.2447
2022-02-21 13:43:46 - train: epoch 0056, iter [02500, 05004], lr: 0.010000, loss: 1.3591
2022-02-21 13:44:18 - train: epoch 0056, iter [02600, 05004], lr: 0.010000, loss: 1.1296
2022-02-21 13:44:51 - train: epoch 0056, iter [02700, 05004], lr: 0.010000, loss: 1.2427
2022-02-21 13:45:23 - train: epoch 0056, iter [02800, 05004], lr: 0.010000, loss: 1.1541
2022-02-21 13:45:55 - train: epoch 0056, iter [02900, 05004], lr: 0.010000, loss: 1.3772
2022-02-21 13:46:28 - train: epoch 0056, iter [03000, 05004], lr: 0.010000, loss: 1.3243
2022-02-21 13:47:00 - train: epoch 0056, iter [03100, 05004], lr: 0.010000, loss: 1.1385
2022-02-21 13:47:33 - train: epoch 0056, iter [03200, 05004], lr: 0.010000, loss: 1.0994
2022-02-21 13:48:05 - train: epoch 0056, iter [03300, 05004], lr: 0.010000, loss: 1.4228
2022-02-21 13:48:37 - train: epoch 0056, iter [03400, 05004], lr: 0.010000, loss: 1.0529
2022-02-21 13:49:09 - train: epoch 0056, iter [03500, 05004], lr: 0.010000, loss: 1.0711
2022-02-21 13:49:41 - train: epoch 0056, iter [03600, 05004], lr: 0.010000, loss: 0.9561
2022-02-21 13:50:14 - train: epoch 0056, iter [03700, 05004], lr: 0.010000, loss: 1.1541
2022-02-21 13:50:46 - train: epoch 0056, iter [03800, 05004], lr: 0.010000, loss: 1.0789
2022-02-21 13:51:18 - train: epoch 0056, iter [03900, 05004], lr: 0.010000, loss: 1.3953
2022-02-21 13:51:51 - train: epoch 0056, iter [04000, 05004], lr: 0.010000, loss: 1.1700
2022-02-21 13:52:23 - train: epoch 0056, iter [04100, 05004], lr: 0.010000, loss: 1.4406
2022-02-21 13:52:55 - train: epoch 0056, iter [04200, 05004], lr: 0.010000, loss: 1.2175
2022-02-21 13:53:27 - train: epoch 0056, iter [04300, 05004], lr: 0.010000, loss: 1.1935
2022-02-21 13:53:59 - train: epoch 0056, iter [04400, 05004], lr: 0.010000, loss: 1.3272
2022-02-21 13:54:32 - train: epoch 0056, iter [04500, 05004], lr: 0.010000, loss: 1.2389
2022-02-21 13:55:04 - train: epoch 0056, iter [04600, 05004], lr: 0.010000, loss: 1.1865
2022-02-21 13:55:37 - train: epoch 0056, iter [04700, 05004], lr: 0.010000, loss: 1.2659
2022-02-21 13:56:09 - train: epoch 0056, iter [04800, 05004], lr: 0.010000, loss: 1.3152
2022-02-21 13:56:43 - train: epoch 0056, iter [04900, 05004], lr: 0.010000, loss: 1.1268
2022-02-21 13:57:16 - train: epoch 0056, iter [05000, 05004], lr: 0.010000, loss: 1.2867
2022-02-21 13:57:19 - train: epoch 056, train_loss: 1.2120
2022-02-21 13:58:35 - eval: epoch: 056, acc1: 72.178%, acc5: 91.310%, test_loss: 1.0892, per_image_load_time: 1.752ms, per_image_inference_time: 0.727ms
2022-02-21 13:58:36 - until epoch: 056, best_acc1: 73.016%
2022-02-21 13:58:36 - epoch 057 lr: 0.010000000000000002
2022-02-21 13:59:14 - train: epoch 0057, iter [00100, 05004], lr: 0.010000, loss: 1.2141
2022-02-21 13:59:46 - train: epoch 0057, iter [00200, 05004], lr: 0.010000, loss: 1.1130
2022-02-21 14:00:18 - train: epoch 0057, iter [00300, 05004], lr: 0.010000, loss: 1.0576
2022-02-21 14:00:50 - train: epoch 0057, iter [00400, 05004], lr: 0.010000, loss: 1.2346
2022-02-21 14:01:22 - train: epoch 0057, iter [00500, 05004], lr: 0.010000, loss: 1.0113
2022-02-21 14:01:54 - train: epoch 0057, iter [00600, 05004], lr: 0.010000, loss: 1.4179
2022-02-21 14:02:26 - train: epoch 0057, iter [00700, 05004], lr: 0.010000, loss: 0.9722
2022-02-21 14:02:58 - train: epoch 0057, iter [00800, 05004], lr: 0.010000, loss: 1.2200
2022-02-21 14:03:30 - train: epoch 0057, iter [00900, 05004], lr: 0.010000, loss: 1.2866
2022-02-21 14:04:02 - train: epoch 0057, iter [01000, 05004], lr: 0.010000, loss: 1.1384
2022-02-21 14:04:34 - train: epoch 0057, iter [01100, 05004], lr: 0.010000, loss: 1.1174
2022-02-21 14:05:07 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 1.0799
2022-02-21 14:05:39 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 1.1179
2022-02-21 14:06:11 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 1.2588
2022-02-21 14:06:42 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 1.3177
2022-02-21 14:07:14 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 1.3940
2022-02-21 14:07:46 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 1.4098
2022-02-21 14:08:18 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 1.2629
2022-02-21 14:08:51 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 1.1465
2022-02-21 14:09:23 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 1.1858
2022-02-21 14:09:55 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 1.2256
2022-02-21 14:10:27 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 1.1805
2022-02-21 14:10:59 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 1.1043
2022-02-21 14:11:31 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 1.0760
2022-02-21 14:12:03 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 1.2722
2022-02-21 14:12:35 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 1.0604
2022-02-21 14:13:07 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 1.0054
2022-02-21 14:13:39 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 0.9159
2022-02-21 14:14:11 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 1.2866
2022-02-21 14:14:43 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 1.2738
2022-02-21 14:15:15 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 1.4370
2022-02-21 14:15:47 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 1.3715
2022-02-21 14:16:19 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 1.2290
2022-02-21 14:16:52 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 1.2740
2022-02-21 14:17:24 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 1.1931
2022-02-21 14:17:56 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 1.1316
2022-02-21 14:18:29 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 1.2135
2022-02-21 14:19:01 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 1.0927
2022-02-21 14:19:33 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 1.4208
2022-02-21 14:20:06 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 1.1761
2022-02-21 14:20:38 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 1.2870
2022-02-21 14:21:11 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 1.2550
2022-02-21 14:21:43 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 1.1854
2022-02-21 14:22:16 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 1.1933
2022-02-21 14:22:48 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 1.3336
2022-02-21 14:23:21 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 1.3112
2022-02-21 14:23:54 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 1.2013
2022-02-21 14:24:27 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 1.3773
2022-02-21 14:25:00 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 1.4234
2022-02-21 14:25:33 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 1.3409
2022-02-21 14:25:37 - train: epoch 057, train_loss: 1.2116
2022-02-21 14:26:52 - eval: epoch: 057, acc1: 72.270%, acc5: 91.024%, test_loss: 1.1097, per_image_load_time: 2.114ms, per_image_inference_time: 0.705ms
2022-02-21 14:26:53 - until epoch: 057, best_acc1: 73.016%
2022-02-21 14:26:53 - epoch 058 lr: 0.010000000000000002
2022-02-21 14:27:30 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 1.1747
2022-02-21 14:28:02 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 1.0464
2022-02-21 14:28:33 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 1.2693
2022-02-21 14:29:05 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 1.2198
2022-02-21 14:29:37 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 1.0080
2022-02-21 14:30:09 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 1.2875
2022-02-21 14:30:41 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 1.1913
2022-02-21 14:31:14 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 1.0618
2022-02-21 14:31:46 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 1.1507
2022-02-21 14:32:18 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 1.2178
2022-02-21 14:32:50 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 1.0135
2022-02-21 14:33:22 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 1.1358
2022-02-21 14:33:54 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 1.1513
2022-02-21 14:34:26 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 1.1792
2022-02-21 14:34:58 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 1.2732
2022-02-21 14:35:30 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 1.2370
2022-02-21 14:36:02 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 1.4111
2022-02-21 14:36:35 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 1.2820
2022-02-21 14:37:06 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 1.3491
2022-02-21 14:37:39 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 1.2488
2022-02-21 14:38:11 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 1.0618
2022-02-21 14:38:43 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 0.9992
2022-02-21 14:39:15 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 1.2649
2022-02-21 14:39:47 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 1.2328
2022-02-21 14:40:19 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 1.2959
2022-02-21 14:40:51 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 1.1095
2022-02-21 14:41:23 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 1.3364
2022-02-21 14:41:55 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 1.0433
2022-02-21 14:42:27 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 1.1685
2022-02-21 14:43:00 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 1.2492
2022-02-21 14:43:32 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 1.1004
2022-02-21 14:44:04 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 1.0765
2022-02-21 14:44:36 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 1.2208
2022-02-21 14:45:08 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 1.1587
2022-02-21 14:45:40 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 1.2475
2022-02-21 14:46:13 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 1.1134
2022-02-21 14:46:45 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 1.1281
2022-02-21 14:47:17 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 1.2628
2022-02-21 14:47:49 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 1.2778
2022-02-21 14:48:22 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 1.3298
2022-02-21 14:48:54 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 1.2684
2022-02-21 14:49:26 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 1.0566
2022-02-21 14:49:59 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 1.4176
2022-02-21 14:50:31 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 1.0214
2022-02-21 14:51:04 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 1.3236
2022-02-21 14:51:37 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 1.1443
2022-02-21 14:52:10 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 1.1944
2022-02-21 14:52:43 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 1.2741
2022-02-21 14:53:16 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 1.1369
2022-02-21 14:53:49 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 1.1843
2022-02-21 14:53:53 - train: epoch 058, train_loss: 1.2083
2022-02-21 14:55:08 - eval: epoch: 058, acc1: 72.654%, acc5: 91.320%, test_loss: 1.0860, per_image_load_time: 2.074ms, per_image_inference_time: 0.737ms
2022-02-21 14:55:09 - until epoch: 058, best_acc1: 73.016%
2022-02-21 14:55:09 - epoch 059 lr: 0.010000000000000002
2022-02-21 14:55:46 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 1.2802
2022-02-21 14:56:18 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 1.1908
2022-02-21 14:56:49 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 1.2336
2022-02-21 14:57:21 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 1.2015
2022-02-21 14:57:53 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 1.4710
2022-02-21 14:58:25 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 1.1302
2022-02-21 14:58:58 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 1.0931
2022-02-21 14:59:30 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 1.1798
2022-02-21 15:00:02 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 1.1934
2022-02-21 15:00:34 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 1.1423
2022-02-21 15:01:06 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 1.2955
2022-02-21 15:01:38 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 1.0510
2022-02-21 15:02:11 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 1.3141
2022-02-21 15:02:43 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 1.3599
2022-02-21 15:03:15 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 1.2910
2022-02-21 15:03:47 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 1.0802
2022-02-21 15:04:19 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 1.2172
2022-02-21 15:04:51 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 1.1739
2022-02-21 15:05:23 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 1.2342
2022-02-21 15:05:55 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 1.1434
2022-02-21 15:06:28 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 1.3354
2022-02-21 15:07:00 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 1.3712
2022-02-21 15:07:32 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 1.0882
2022-02-21 15:08:04 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 1.3251
2022-02-21 15:08:36 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 1.2297
2022-02-21 15:09:08 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 1.1826
2022-02-21 15:09:40 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 1.1351
2022-02-21 15:10:12 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 1.4287
2022-02-21 15:10:44 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 1.1478
2022-02-21 15:11:16 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 1.5808
2022-02-21 15:11:48 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 1.0909
2022-02-21 15:12:20 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 1.2391
2022-02-21 15:12:53 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 1.2244
2022-02-21 15:13:25 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 1.5176
2022-02-21 15:13:57 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 0.9822
2022-02-21 15:14:29 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 1.1539
2022-02-21 15:15:02 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 1.0854
2022-02-21 15:15:34 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 1.2244
2022-02-21 15:16:06 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 1.1240
2022-02-21 15:16:39 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 1.5263
2022-02-21 15:17:11 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 1.3651
2022-02-21 15:17:43 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 1.3380
2022-02-21 15:18:16 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 1.4135
2022-02-21 15:18:49 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 1.4787
2022-02-21 15:19:21 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 1.1656
2022-02-21 15:19:53 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 1.2748
2022-02-21 15:20:26 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 1.1450
2022-02-21 15:20:59 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 1.0912
2022-02-21 15:21:33 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 1.4630
2022-02-21 15:22:06 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 1.2563
2022-02-21 15:22:09 - train: epoch 059, train_loss: 1.2056
2022-02-21 15:23:24 - eval: epoch: 059, acc1: 71.798%, acc5: 90.854%, test_loss: 1.1170, per_image_load_time: 1.762ms, per_image_inference_time: 0.705ms
2022-02-21 15:23:25 - until epoch: 059, best_acc1: 73.016%
2022-02-21 15:23:25 - epoch 060 lr: 0.010000000000000002
2022-02-21 15:24:02 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 1.1012
2022-02-21 15:24:33 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 1.3450
2022-02-21 15:25:05 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 1.1927
2022-02-21 15:25:37 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 1.2214
2022-02-21 15:26:09 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 1.3743
2022-02-21 15:26:40 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 1.2302
2022-02-21 15:27:12 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 1.2543
2022-02-21 15:27:44 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 1.3699
2022-02-21 15:28:17 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 0.9931
2022-02-21 15:28:49 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 0.9904
2022-02-21 15:29:21 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 0.9272
2022-02-21 15:29:53 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 1.0697
2022-02-21 15:30:25 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 1.0547
2022-02-21 15:30:57 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 1.2202
2022-02-21 15:31:29 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 1.2368
2022-02-21 15:32:02 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 1.1955
2022-02-21 15:32:34 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 1.1619
2022-02-21 15:33:06 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 1.2685
2022-02-21 15:33:39 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 1.2208
2022-02-21 15:34:11 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 1.1058
2022-02-21 15:34:43 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 1.1729
2022-02-21 15:35:15 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 1.2423
2022-02-21 15:35:47 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 0.9985
2022-02-21 15:36:20 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 1.1749
2022-02-21 15:36:52 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 1.1973
2022-02-21 15:37:24 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 1.2564
2022-02-21 15:37:56 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 1.3234
2022-02-21 15:38:28 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 1.1391
2022-02-21 15:39:00 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 1.2126
2022-02-21 15:39:32 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 1.3550
2022-02-21 15:40:04 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 1.2396
2022-02-21 15:40:37 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 1.2489
2022-02-21 15:41:09 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 0.9715
2022-02-21 15:41:41 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 1.1817
2022-02-21 15:42:13 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 1.2479
2022-02-21 15:42:45 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 1.1448
2022-02-21 15:43:17 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 1.2187
2022-02-21 15:43:49 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 1.2519
2022-02-21 15:44:21 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 1.5972
2022-02-21 15:44:53 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 1.2878
2022-02-21 15:45:25 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 1.4378
2022-02-21 15:45:57 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 1.3697
2022-02-21 15:46:30 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 1.2223
2022-02-21 15:47:02 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 1.3805
2022-02-21 15:47:34 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 1.2069
2022-02-21 15:48:06 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 1.1755
2022-02-21 15:48:39 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 1.1929
2022-02-21 15:49:12 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 1.1086
2022-02-21 15:49:45 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 1.2439
2022-02-21 15:50:19 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 1.2501
2022-02-21 15:50:22 - train: epoch 060, train_loss: 1.2030
2022-02-21 15:51:37 - eval: epoch: 060, acc1: 71.528%, acc5: 90.814%, test_loss: 1.1252, per_image_load_time: 2.126ms, per_image_inference_time: 0.719ms
2022-02-21 15:51:38 - until epoch: 060, best_acc1: 73.016%
2022-02-21 15:51:38 - epoch 061 lr: 0.0010000000000000002
2022-02-21 15:52:15 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 1.0237
2022-02-21 15:52:46 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 1.1677
2022-02-21 15:53:18 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 0.8884
2022-02-21 15:53:50 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 1.2667
2022-02-21 15:54:22 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 1.0753
2022-02-21 15:54:54 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 1.0689
2022-02-21 15:55:26 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 0.8647
2022-02-21 15:55:58 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 1.0867
2022-02-21 15:56:30 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 0.9226
2022-02-21 15:57:03 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 0.8473
2022-02-21 15:57:35 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 0.9453
2022-02-21 15:58:07 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 0.9342
2022-02-21 15:58:39 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 0.9835
2022-02-21 15:59:11 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 0.8922
2022-02-21 15:59:43 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 1.1149
2022-02-21 16:00:15 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 0.8877
2022-02-21 16:00:47 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 1.0192
2022-02-21 16:01:19 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 0.9678
2022-02-21 16:01:51 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 1.1078
2022-02-21 16:02:23 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 0.9339
2022-02-21 16:02:55 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 1.2715
2022-02-21 16:03:27 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 0.8882
2022-02-21 16:03:59 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 1.0127
2022-02-21 16:04:31 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 0.7926
2022-02-21 16:05:03 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 0.8819
2022-02-21 16:05:34 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 1.0376
2022-02-21 16:06:07 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 1.1419
2022-02-21 16:06:39 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 0.9798
2022-02-21 16:07:11 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 1.1395
2022-02-21 16:07:43 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 0.9441
2022-02-21 16:08:15 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 1.0683
2022-02-21 16:08:46 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 1.0129
2022-02-21 16:09:19 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 0.9525
2022-02-21 16:09:51 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 0.7691
2022-02-21 16:10:23 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 0.9819
2022-02-21 16:10:55 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 0.9687
2022-02-21 16:11:28 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 1.0429
2022-02-21 16:12:00 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 0.9991
2022-02-21 16:12:32 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 1.0223
2022-02-21 16:13:04 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 0.9924
2022-02-21 16:13:37 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 1.1131
2022-02-21 16:14:09 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 0.9035
2022-02-21 16:14:41 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 0.9948
2022-02-21 16:15:13 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 0.9135
2022-02-21 16:15:45 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 0.9395
2022-02-21 16:16:18 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 1.0931
2022-02-21 16:16:50 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 0.9364
2022-02-21 16:17:23 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 1.0587
2022-02-21 16:17:56 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 1.1025
2022-02-21 16:18:29 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 1.0098
2022-02-21 16:18:32 - train: epoch 061, train_loss: 0.9916
2022-02-21 16:19:47 - eval: epoch: 061, acc1: 76.402%, acc5: 93.300%, test_loss: 0.9181, per_image_load_time: 1.926ms, per_image_inference_time: 0.724ms
2022-02-21 16:19:49 - until epoch: 061, best_acc1: 76.402%
2022-02-21 16:19:49 - epoch 062 lr: 0.0010000000000000002
2022-02-21 16:20:25 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 1.0333
2022-02-21 16:20:56 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 0.9610
2022-02-21 16:21:28 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 0.9254
2022-02-21 16:22:00 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 0.8488
2022-02-21 16:22:32 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 0.7887
2022-02-21 16:23:04 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 0.8982
2022-02-21 16:23:35 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 1.1783
2022-02-21 16:24:07 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 0.9134
2022-02-21 16:24:39 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 0.8344
2022-02-21 16:25:10 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 1.0839
2022-02-21 16:25:42 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 0.7622
2022-02-21 16:26:14 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 1.1309
2022-02-21 16:26:46 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 1.0409
2022-02-21 16:27:18 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 0.9297
2022-02-21 16:27:50 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 0.9848
2022-02-21 16:28:22 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 1.0416
2022-02-21 16:28:55 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 1.0591
2022-02-21 16:29:26 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 0.8456
2022-02-21 16:29:58 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 0.9560
2022-02-21 16:30:31 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 0.7957
2022-02-21 16:31:03 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 1.0838
2022-02-21 16:31:36 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 0.8420
2022-02-21 16:32:08 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 0.9583
2022-02-21 16:32:39 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 0.8615
2022-02-21 16:33:12 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 0.9935
2022-02-21 16:34:10 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 0.8445
2022-02-21 16:34:50 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 0.9199
2022-02-21 16:35:22 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 1.0441
2022-02-21 16:35:54 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 1.0252
2022-02-21 16:36:26 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 1.0364
2022-02-21 16:36:59 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 0.9738
2022-02-21 16:37:30 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 0.7931
2022-02-21 16:38:02 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 1.0397
2022-02-21 16:38:35 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 1.0370
2022-02-21 16:39:07 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 0.9990
2022-02-21 16:39:39 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 0.9609
2022-02-21 16:40:12 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 0.8832
2022-02-21 16:40:44 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 0.9499
2022-02-21 16:41:15 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 0.9006
2022-02-21 16:41:48 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 0.7291
2022-02-21 16:42:20 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 0.9233
2022-02-21 16:42:52 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 0.8404
2022-02-21 16:43:24 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 0.9026
2022-02-21 16:43:57 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 0.8321
2022-02-21 16:44:29 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 0.8227
2022-02-21 16:45:02 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 0.7517
2022-02-21 16:45:33 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 0.8402
2022-02-21 16:46:06 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 0.9052
2022-02-21 16:46:39 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 0.8568
2022-02-21 16:47:13 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 0.9432
2022-02-21 16:47:15 - train: epoch 062, train_loss: 0.9341
2022-02-21 16:48:31 - eval: epoch: 062, acc1: 76.692%, acc5: 93.376%, test_loss: 0.9061, per_image_load_time: 1.667ms, per_image_inference_time: 0.722ms
2022-02-21 16:48:32 - until epoch: 062, best_acc1: 76.692%
2022-02-21 16:48:32 - epoch 063 lr: 0.0010000000000000002
2022-02-21 16:49:08 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 0.8962
2022-02-21 16:49:40 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 0.8479
2022-02-21 16:50:13 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 1.0474
2022-02-21 16:50:45 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 0.9882
2022-02-21 16:51:16 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 0.8515
2022-02-21 16:51:48 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 1.0019
2022-02-21 16:52:20 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 0.8663
2022-02-21 16:52:52 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 0.9832
2022-02-21 16:53:25 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 0.9464
2022-02-21 16:53:57 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 1.0790
2022-02-21 16:54:30 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 0.8181
2022-02-21 16:55:02 - train: epoch 0063, iter [01200, 05004], lr: 0.001000, loss: 0.8110
2022-02-21 16:55:34 - train: epoch 0063, iter [01300, 05004], lr: 0.001000, loss: 1.0045
2022-02-21 16:56:07 - train: epoch 0063, iter [01400, 05004], lr: 0.001000, loss: 1.1539
2022-02-21 16:56:39 - train: epoch 0063, iter [01500, 05004], lr: 0.001000, loss: 0.9820
2022-02-21 16:57:11 - train: epoch 0063, iter [01600, 05004], lr: 0.001000, loss: 0.8549
2022-02-21 16:57:43 - train: epoch 0063, iter [01700, 05004], lr: 0.001000, loss: 0.8186
2022-02-21 16:58:16 - train: epoch 0063, iter [01800, 05004], lr: 0.001000, loss: 1.0048
2022-02-21 16:58:48 - train: epoch 0063, iter [01900, 05004], lr: 0.001000, loss: 0.9615
2022-02-21 16:59:20 - train: epoch 0063, iter [02000, 05004], lr: 0.001000, loss: 0.8323
2022-02-21 16:59:53 - train: epoch 0063, iter [02100, 05004], lr: 0.001000, loss: 0.7693
2022-02-21 17:00:25 - train: epoch 0063, iter [02200, 05004], lr: 0.001000, loss: 1.1746
2022-02-21 17:00:58 - train: epoch 0063, iter [02300, 05004], lr: 0.001000, loss: 0.9530
2022-02-21 17:01:30 - train: epoch 0063, iter [02400, 05004], lr: 0.001000, loss: 0.9446
2022-02-21 17:02:02 - train: epoch 0063, iter [02500, 05004], lr: 0.001000, loss: 0.8856
2022-02-21 17:02:35 - train: epoch 0063, iter [02600, 05004], lr: 0.001000, loss: 0.9081
2022-02-21 17:03:07 - train: epoch 0063, iter [02700, 05004], lr: 0.001000, loss: 1.0612
2022-02-21 17:03:39 - train: epoch 0063, iter [02800, 05004], lr: 0.001000, loss: 0.9155
2022-02-21 17:04:11 - train: epoch 0063, iter [02900, 05004], lr: 0.001000, loss: 0.9057
2022-02-21 17:04:43 - train: epoch 0063, iter [03000, 05004], lr: 0.001000, loss: 1.0261
2022-02-21 17:05:16 - train: epoch 0063, iter [03100, 05004], lr: 0.001000, loss: 1.1441
2022-02-21 17:05:48 - train: epoch 0063, iter [03200, 05004], lr: 0.001000, loss: 1.0728
2022-02-21 17:06:20 - train: epoch 0063, iter [03300, 05004], lr: 0.001000, loss: 0.9014
2022-02-21 17:06:53 - train: epoch 0063, iter [03400, 05004], lr: 0.001000, loss: 0.7579
2022-02-21 17:07:25 - train: epoch 0063, iter [03500, 05004], lr: 0.001000, loss: 1.0451
2022-02-21 17:07:57 - train: epoch 0063, iter [03600, 05004], lr: 0.001000, loss: 0.7757
2022-02-21 17:08:30 - train: epoch 0063, iter [03700, 05004], lr: 0.001000, loss: 1.0811
2022-02-21 17:09:02 - train: epoch 0063, iter [03800, 05004], lr: 0.001000, loss: 1.1431
2022-02-21 17:09:34 - train: epoch 0063, iter [03900, 05004], lr: 0.001000, loss: 0.6827
2022-02-21 17:10:07 - train: epoch 0063, iter [04000, 05004], lr: 0.001000, loss: 0.7282
2022-02-21 17:10:39 - train: epoch 0063, iter [04100, 05004], lr: 0.001000, loss: 1.0317
2022-02-21 17:11:11 - train: epoch 0063, iter [04200, 05004], lr: 0.001000, loss: 0.8812
2022-02-21 17:11:44 - train: epoch 0063, iter [04300, 05004], lr: 0.001000, loss: 1.0059
2022-02-21 17:12:16 - train: epoch 0063, iter [04400, 05004], lr: 0.001000, loss: 0.9166
2022-02-21 17:12:49 - train: epoch 0063, iter [04500, 05004], lr: 0.001000, loss: 0.8492
2022-02-21 17:13:22 - train: epoch 0063, iter [04600, 05004], lr: 0.001000, loss: 0.9023
2022-02-21 17:13:55 - train: epoch 0063, iter [04700, 05004], lr: 0.001000, loss: 0.7713
2022-02-21 17:14:28 - train: epoch 0063, iter [04800, 05004], lr: 0.001000, loss: 0.8620
2022-02-21 17:15:00 - train: epoch 0063, iter [04900, 05004], lr: 0.001000, loss: 0.8838
2022-02-21 17:18:04 - train: epoch 0063, iter [05000, 05004], lr: 0.001000, loss: 0.8862
2022-02-21 17:18:16 - train: epoch 063, train_loss: 0.9129
2022-02-21 17:19:31 - eval: epoch: 063, acc1: 76.892%, acc5: 93.618%, test_loss: 0.8961, per_image_load_time: 1.972ms, per_image_inference_time: 0.693ms
2022-02-21 17:19:33 - until epoch: 063, best_acc1: 76.892%
2022-02-21 17:19:33 - epoch 064 lr: 0.0010000000000000002
2022-02-21 17:20:10 - train: epoch 0064, iter [00100, 05004], lr: 0.001000, loss: 0.8821
2022-02-21 17:20:42 - train: epoch 0064, iter [00200, 05004], lr: 0.001000, loss: 1.0090
2022-02-21 17:21:14 - train: epoch 0064, iter [00300, 05004], lr: 0.001000, loss: 0.7010
2022-02-21 17:21:46 - train: epoch 0064, iter [00400, 05004], lr: 0.001000, loss: 0.9893
2022-02-21 17:22:18 - train: epoch 0064, iter [00500, 05004], lr: 0.001000, loss: 0.8275
2022-02-21 17:22:50 - train: epoch 0064, iter [00600, 05004], lr: 0.001000, loss: 1.0606
2022-02-21 17:23:22 - train: epoch 0064, iter [00700, 05004], lr: 0.001000, loss: 1.0191
2022-02-21 17:23:54 - train: epoch 0064, iter [00800, 05004], lr: 0.001000, loss: 0.8038
2022-02-21 17:24:26 - train: epoch 0064, iter [00900, 05004], lr: 0.001000, loss: 0.9222
2022-02-21 17:24:59 - train: epoch 0064, iter [01000, 05004], lr: 0.001000, loss: 0.8579
2022-02-21 17:25:31 - train: epoch 0064, iter [01100, 05004], lr: 0.001000, loss: 0.8186
2022-02-21 17:26:03 - train: epoch 0064, iter [01200, 05004], lr: 0.001000, loss: 0.8297
2022-02-21 17:26:36 - train: epoch 0064, iter [01300, 05004], lr: 0.001000, loss: 0.8443
2022-02-21 17:27:08 - train: epoch 0064, iter [01400, 05004], lr: 0.001000, loss: 1.1387
2022-02-21 17:27:41 - train: epoch 0064, iter [01500, 05004], lr: 0.001000, loss: 0.9166
2022-02-21 17:28:13 - train: epoch 0064, iter [01600, 05004], lr: 0.001000, loss: 0.8803
2022-02-21 17:28:45 - train: epoch 0064, iter [01700, 05004], lr: 0.001000, loss: 0.7661
2022-02-21 17:29:17 - train: epoch 0064, iter [01800, 05004], lr: 0.001000, loss: 0.7882
2022-02-21 17:29:50 - train: epoch 0064, iter [01900, 05004], lr: 0.001000, loss: 0.7734
2022-02-21 17:30:22 - train: epoch 0064, iter [02000, 05004], lr: 0.001000, loss: 0.8405
2022-02-21 17:30:54 - train: epoch 0064, iter [02100, 05004], lr: 0.001000, loss: 0.9453
2022-02-21 17:31:27 - train: epoch 0064, iter [02200, 05004], lr: 0.001000, loss: 0.9203
2022-02-21 17:31:59 - train: epoch 0064, iter [02300, 05004], lr: 0.001000, loss: 1.0410
2022-02-21 17:32:31 - train: epoch 0064, iter [02400, 05004], lr: 0.001000, loss: 0.8529
2022-02-21 17:33:03 - train: epoch 0064, iter [02500, 05004], lr: 0.001000, loss: 0.7536
2022-02-21 17:33:36 - train: epoch 0064, iter [02600, 05004], lr: 0.001000, loss: 0.8304
2022-02-21 17:34:09 - train: epoch 0064, iter [02700, 05004], lr: 0.001000, loss: 0.8511
2022-02-21 17:34:41 - train: epoch 0064, iter [02800, 05004], lr: 0.001000, loss: 0.7863
2022-02-21 17:35:13 - train: epoch 0064, iter [02900, 05004], lr: 0.001000, loss: 1.0876
2022-02-21 17:35:46 - train: epoch 0064, iter [03000, 05004], lr: 0.001000, loss: 0.9880
2022-02-21 17:36:18 - train: epoch 0064, iter [03100, 05004], lr: 0.001000, loss: 0.8082
2022-02-21 17:36:50 - train: epoch 0064, iter [03200, 05004], lr: 0.001000, loss: 0.9043
2022-02-21 17:37:22 - train: epoch 0064, iter [03300, 05004], lr: 0.001000, loss: 0.9434
2022-02-21 17:37:55 - train: epoch 0064, iter [03400, 05004], lr: 0.001000, loss: 1.0595
2022-02-21 17:38:27 - train: epoch 0064, iter [03500, 05004], lr: 0.001000, loss: 0.8275
2022-02-21 17:38:59 - train: epoch 0064, iter [03600, 05004], lr: 0.001000, loss: 0.7940
2022-02-21 17:39:31 - train: epoch 0064, iter [03700, 05004], lr: 0.001000, loss: 0.6916
2022-02-21 17:40:04 - train: epoch 0064, iter [03800, 05004], lr: 0.001000, loss: 1.0169
2022-02-21 17:40:36 - train: epoch 0064, iter [03900, 05004], lr: 0.001000, loss: 0.7963
2022-02-21 17:41:08 - train: epoch 0064, iter [04000, 05004], lr: 0.001000, loss: 0.7207
2022-02-21 17:41:41 - train: epoch 0064, iter [04100, 05004], lr: 0.001000, loss: 0.9342
2022-02-21 17:42:13 - train: epoch 0064, iter [04200, 05004], lr: 0.001000, loss: 0.8441
2022-02-21 17:42:46 - train: epoch 0064, iter [04300, 05004], lr: 0.001000, loss: 1.0806
2022-02-21 17:43:19 - train: epoch 0064, iter [04400, 05004], lr: 0.001000, loss: 0.8354
2022-02-21 17:43:52 - train: epoch 0064, iter [04500, 05004], lr: 0.001000, loss: 0.7863
2022-02-21 17:44:24 - train: epoch 0064, iter [04600, 05004], lr: 0.001000, loss: 1.0160
2022-02-21 17:44:57 - train: epoch 0064, iter [04700, 05004], lr: 0.001000, loss: 1.2176
2022-02-21 17:45:30 - train: epoch 0064, iter [04800, 05004], lr: 0.001000, loss: 0.8556
2022-02-21 17:46:04 - train: epoch 0064, iter [04900, 05004], lr: 0.001000, loss: 1.0630
2022-02-21 17:46:37 - train: epoch 0064, iter [05000, 05004], lr: 0.001000, loss: 0.7658
2022-02-21 17:46:41 - train: epoch 064, train_loss: 0.8977
2022-02-21 17:47:57 - eval: epoch: 064, acc1: 76.984%, acc5: 93.608%, test_loss: 0.8940, per_image_load_time: 1.813ms, per_image_inference_time: 0.716ms
2022-02-21 17:47:58 - until epoch: 064, best_acc1: 76.984%
2022-02-21 17:47:58 - epoch 065 lr: 0.0010000000000000002
2022-02-21 17:48:35 - train: epoch 0065, iter [00100, 05004], lr: 0.001000, loss: 0.9830
2022-02-21 17:49:07 - train: epoch 0065, iter [00200, 05004], lr: 0.001000, loss: 0.8272
2022-02-21 17:49:39 - train: epoch 0065, iter [00300, 05004], lr: 0.001000, loss: 0.8747
2022-02-21 17:50:10 - train: epoch 0065, iter [00400, 05004], lr: 0.001000, loss: 0.9746
2022-02-21 17:50:42 - train: epoch 0065, iter [00500, 05004], lr: 0.001000, loss: 0.8576
2022-02-21 17:51:14 - train: epoch 0065, iter [00600, 05004], lr: 0.001000, loss: 0.8759
2022-02-21 17:51:46 - train: epoch 0065, iter [00700, 05004], lr: 0.001000, loss: 0.7773
2022-02-21 17:52:18 - train: epoch 0065, iter [00800, 05004], lr: 0.001000, loss: 0.8818
2022-02-21 17:52:51 - train: epoch 0065, iter [00900, 05004], lr: 0.001000, loss: 0.8325
2022-02-21 17:53:23 - train: epoch 0065, iter [01000, 05004], lr: 0.001000, loss: 0.8478
2022-02-21 17:53:55 - train: epoch 0065, iter [01100, 05004], lr: 0.001000, loss: 0.9133
2022-02-21 17:54:28 - train: epoch 0065, iter [01200, 05004], lr: 0.001000, loss: 1.0906
2022-02-21 17:55:00 - train: epoch 0065, iter [01300, 05004], lr: 0.001000, loss: 0.9134
2022-02-21 17:55:32 - train: epoch 0065, iter [01400, 05004], lr: 0.001000, loss: 0.6453
2022-02-21 17:56:04 - train: epoch 0065, iter [01500, 05004], lr: 0.001000, loss: 0.8786
2022-02-21 17:56:36 - train: epoch 0065, iter [01600, 05004], lr: 0.001000, loss: 0.8639
2022-02-21 17:57:08 - train: epoch 0065, iter [01700, 05004], lr: 0.001000, loss: 0.8273
2022-02-21 17:57:40 - train: epoch 0065, iter [01800, 05004], lr: 0.001000, loss: 0.8174
2022-02-21 17:58:12 - train: epoch 0065, iter [01900, 05004], lr: 0.001000, loss: 0.7781
2022-02-21 17:58:44 - train: epoch 0065, iter [02000, 05004], lr: 0.001000, loss: 0.8593
2022-02-21 17:59:16 - train: epoch 0065, iter [02100, 05004], lr: 0.001000, loss: 0.8679
2022-02-21 17:59:48 - train: epoch 0065, iter [02200, 05004], lr: 0.001000, loss: 1.0018
2022-02-21 18:00:20 - train: epoch 0065, iter [02300, 05004], lr: 0.001000, loss: 0.8671
2022-02-21 18:00:52 - train: epoch 0065, iter [02400, 05004], lr: 0.001000, loss: 0.8393
2022-02-21 18:01:24 - train: epoch 0065, iter [02500, 05004], lr: 0.001000, loss: 0.9133
2022-02-21 18:01:56 - train: epoch 0065, iter [02600, 05004], lr: 0.001000, loss: 0.9948
2022-02-21 18:02:28 - train: epoch 0065, iter [02700, 05004], lr: 0.001000, loss: 0.9555
2022-02-21 18:03:00 - train: epoch 0065, iter [02800, 05004], lr: 0.001000, loss: 0.8034
2022-02-21 18:03:33 - train: epoch 0065, iter [02900, 05004], lr: 0.001000, loss: 0.9979
2022-02-21 18:04:04 - train: epoch 0065, iter [03000, 05004], lr: 0.001000, loss: 0.7479
2022-02-21 18:04:37 - train: epoch 0065, iter [03100, 05004], lr: 0.001000, loss: 0.9052
2022-02-21 18:05:09 - train: epoch 0065, iter [03200, 05004], lr: 0.001000, loss: 0.9921
2022-02-21 18:05:42 - train: epoch 0065, iter [03300, 05004], lr: 0.001000, loss: 0.7737
2022-02-21 18:06:14 - train: epoch 0065, iter [03400, 05004], lr: 0.001000, loss: 0.7367
2022-02-21 18:06:46 - train: epoch 0065, iter [03500, 05004], lr: 0.001000, loss: 1.0850
2022-02-21 18:07:18 - train: epoch 0065, iter [03600, 05004], lr: 0.001000, loss: 0.9487
2022-02-21 18:07:50 - train: epoch 0065, iter [03700, 05004], lr: 0.001000, loss: 0.7887
2022-02-21 18:08:23 - train: epoch 0065, iter [03800, 05004], lr: 0.001000, loss: 0.7461
2022-02-21 18:08:55 - train: epoch 0065, iter [03900, 05004], lr: 0.001000, loss: 0.9299
2022-02-21 18:09:27 - train: epoch 0065, iter [04000, 05004], lr: 0.001000, loss: 0.9435
2022-02-21 18:10:00 - train: epoch 0065, iter [04100, 05004], lr: 0.001000, loss: 0.7515
2022-02-21 18:10:32 - train: epoch 0065, iter [04200, 05004], lr: 0.001000, loss: 0.9463
2022-02-21 18:11:04 - train: epoch 0065, iter [04300, 05004], lr: 0.001000, loss: 0.7285
2022-02-21 18:11:37 - train: epoch 0065, iter [04400, 05004], lr: 0.001000, loss: 0.8022
2022-02-21 18:12:09 - train: epoch 0065, iter [04500, 05004], lr: 0.001000, loss: 0.8118
2022-02-21 18:12:41 - train: epoch 0065, iter [04600, 05004], lr: 0.001000, loss: 0.8680
2022-02-21 18:13:14 - train: epoch 0065, iter [04700, 05004], lr: 0.001000, loss: 0.9104
2022-02-21 18:13:47 - train: epoch 0065, iter [04800, 05004], lr: 0.001000, loss: 0.6471
2022-02-21 18:14:20 - train: epoch 0065, iter [04900, 05004], lr: 0.001000, loss: 0.7196
2022-02-21 18:14:53 - train: epoch 0065, iter [05000, 05004], lr: 0.001000, loss: 0.9617
2022-02-21 18:14:56 - train: epoch 065, train_loss: 0.8834
2022-02-21 18:16:12 - eval: epoch: 065, acc1: 77.184%, acc5: 93.670%, test_loss: 0.8902, per_image_load_time: 1.674ms, per_image_inference_time: 0.709ms
2022-02-21 18:16:14 - until epoch: 065, best_acc1: 77.184%
2022-02-21 18:16:14 - epoch 066 lr: 0.0010000000000000002
2022-02-21 18:16:51 - train: epoch 0066, iter [00100, 05004], lr: 0.001000, loss: 0.8066
2022-02-21 18:17:23 - train: epoch 0066, iter [00200, 05004], lr: 0.001000, loss: 1.0199
2022-02-21 18:17:55 - train: epoch 0066, iter [00300, 05004], lr: 0.001000, loss: 0.7223
2022-02-21 18:18:27 - train: epoch 0066, iter [00400, 05004], lr: 0.001000, loss: 0.6892
2022-02-21 18:18:59 - train: epoch 0066, iter [00500, 05004], lr: 0.001000, loss: 0.9789
2022-02-21 18:19:31 - train: epoch 0066, iter [00600, 05004], lr: 0.001000, loss: 0.8614
2022-02-21 18:20:03 - train: epoch 0066, iter [00700, 05004], lr: 0.001000, loss: 0.8364
2022-02-21 18:20:36 - train: epoch 0066, iter [00800, 05004], lr: 0.001000, loss: 1.0693
2022-02-21 18:21:08 - train: epoch 0066, iter [00900, 05004], lr: 0.001000, loss: 0.9757
2022-02-21 18:21:40 - train: epoch 0066, iter [01000, 05004], lr: 0.001000, loss: 0.9608
2022-02-21 18:22:13 - train: epoch 0066, iter [01100, 05004], lr: 0.001000, loss: 0.9051
2022-02-21 18:22:45 - train: epoch 0066, iter [01200, 05004], lr: 0.001000, loss: 1.0109
2022-02-21 18:23:17 - train: epoch 0066, iter [01300, 05004], lr: 0.001000, loss: 0.9856
2022-02-21 18:23:50 - train: epoch 0066, iter [01400, 05004], lr: 0.001000, loss: 0.7322
2022-02-21 18:24:22 - train: epoch 0066, iter [01500, 05004], lr: 0.001000, loss: 0.9308
2022-02-21 18:24:54 - train: epoch 0066, iter [01600, 05004], lr: 0.001000, loss: 0.8607
2022-02-21 18:25:27 - train: epoch 0066, iter [01700, 05004], lr: 0.001000, loss: 0.8913
2022-02-21 18:25:59 - train: epoch 0066, iter [01800, 05004], lr: 0.001000, loss: 0.8392
2022-02-21 18:26:31 - train: epoch 0066, iter [01900, 05004], lr: 0.001000, loss: 1.1404
2022-02-21 18:27:04 - train: epoch 0066, iter [02000, 05004], lr: 0.001000, loss: 1.0097
2022-02-21 18:27:35 - train: epoch 0066, iter [02100, 05004], lr: 0.001000, loss: 0.8986
2022-02-21 18:28:07 - train: epoch 0066, iter [02200, 05004], lr: 0.001000, loss: 0.8708
2022-02-21 18:28:39 - train: epoch 0066, iter [02300, 05004], lr: 0.001000, loss: 1.0561
2022-02-21 18:29:12 - train: epoch 0066, iter [02400, 05004], lr: 0.001000, loss: 0.7876
2022-02-21 18:29:44 - train: epoch 0066, iter [02500, 05004], lr: 0.001000, loss: 0.8244
2022-02-21 18:30:16 - train: epoch 0066, iter [02600, 05004], lr: 0.001000, loss: 0.7628
2022-02-21 18:30:48 - train: epoch 0066, iter [02700, 05004], lr: 0.001000, loss: 1.1060
2022-02-21 18:31:20 - train: epoch 0066, iter [02800, 05004], lr: 0.001000, loss: 0.9740
2022-02-21 18:31:52 - train: epoch 0066, iter [02900, 05004], lr: 0.001000, loss: 0.8183
2022-02-21 18:32:24 - train: epoch 0066, iter [03000, 05004], lr: 0.001000, loss: 0.7961
2022-02-21 18:32:56 - train: epoch 0066, iter [03100, 05004], lr: 0.001000, loss: 1.0377
2022-02-21 18:33:29 - train: epoch 0066, iter [03200, 05004], lr: 0.001000, loss: 0.7240
2022-02-21 18:34:01 - train: epoch 0066, iter [03300, 05004], lr: 0.001000, loss: 0.8339
2022-02-21 18:34:34 - train: epoch 0066, iter [03400, 05004], lr: 0.001000, loss: 1.0888
2022-02-21 18:35:06 - train: epoch 0066, iter [03500, 05004], lr: 0.001000, loss: 0.8867
2022-02-21 18:35:38 - train: epoch 0066, iter [03600, 05004], lr: 0.001000, loss: 0.9231
2022-02-21 18:36:10 - train: epoch 0066, iter [03700, 05004], lr: 0.001000, loss: 0.9518
2022-02-21 18:36:42 - train: epoch 0066, iter [03800, 05004], lr: 0.001000, loss: 0.7697
2022-02-21 18:37:14 - train: epoch 0066, iter [03900, 05004], lr: 0.001000, loss: 0.7402
2022-02-21 18:37:46 - train: epoch 0066, iter [04000, 05004], lr: 0.001000, loss: 1.0361
2022-02-21 18:38:18 - train: epoch 0066, iter [04100, 05004], lr: 0.001000, loss: 0.7957
2022-02-21 18:38:50 - train: epoch 0066, iter [04200, 05004], lr: 0.001000, loss: 0.6630
2022-02-21 18:39:23 - train: epoch 0066, iter [04300, 05004], lr: 0.001000, loss: 0.7711
2022-02-21 18:39:55 - train: epoch 0066, iter [04400, 05004], lr: 0.001000, loss: 0.9139
2022-02-21 18:40:28 - train: epoch 0066, iter [04500, 05004], lr: 0.001000, loss: 0.8719
2022-02-21 18:41:00 - train: epoch 0066, iter [04600, 05004], lr: 0.001000, loss: 1.0351
2022-02-21 18:41:33 - train: epoch 0066, iter [04700, 05004], lr: 0.001000, loss: 0.8210
2022-02-21 18:42:06 - train: epoch 0066, iter [04800, 05004], lr: 0.001000, loss: 0.9103
2022-02-21 18:42:40 - train: epoch 0066, iter [04900, 05004], lr: 0.001000, loss: 0.8878
2022-02-21 18:43:13 - train: epoch 0066, iter [05000, 05004], lr: 0.001000, loss: 0.8390
2022-02-21 18:43:16 - train: epoch 066, train_loss: 0.8743
2022-02-21 18:44:32 - eval: epoch: 066, acc1: 77.174%, acc5: 93.766%, test_loss: 0.8877, per_image_load_time: 2.220ms, per_image_inference_time: 0.722ms
2022-02-21 18:44:34 - until epoch: 066, best_acc1: 77.184%
2022-02-21 18:44:34 - epoch 067 lr: 0.0010000000000000002
2022-02-21 18:45:11 - train: epoch 0067, iter [00100, 05004], lr: 0.001000, loss: 0.7545
2022-02-21 18:45:43 - train: epoch 0067, iter [00200, 05004], lr: 0.001000, loss: 0.7849
2022-02-21 18:46:15 - train: epoch 0067, iter [00300, 05004], lr: 0.001000, loss: 1.1667
2022-02-21 18:46:47 - train: epoch 0067, iter [00400, 05004], lr: 0.001000, loss: 0.9563
2022-02-21 18:47:19 - train: epoch 0067, iter [00500, 05004], lr: 0.001000, loss: 0.8578
2022-02-21 18:47:51 - train: epoch 0067, iter [00600, 05004], lr: 0.001000, loss: 0.8129
2022-02-21 18:48:23 - train: epoch 0067, iter [00700, 05004], lr: 0.001000, loss: 0.9632
2022-02-21 18:48:55 - train: epoch 0067, iter [00800, 05004], lr: 0.001000, loss: 0.9756
2022-02-21 18:49:27 - train: epoch 0067, iter [00900, 05004], lr: 0.001000, loss: 0.9172
2022-02-21 18:49:58 - train: epoch 0067, iter [01000, 05004], lr: 0.001000, loss: 0.7262
2022-02-21 18:50:30 - train: epoch 0067, iter [01100, 05004], lr: 0.001000, loss: 0.8743
2022-02-21 18:51:02 - train: epoch 0067, iter [01200, 05004], lr: 0.001000, loss: 0.8430
2022-02-21 18:51:33 - train: epoch 0067, iter [01300, 05004], lr: 0.001000, loss: 1.0405
2022-02-21 18:52:05 - train: epoch 0067, iter [01400, 05004], lr: 0.001000, loss: 0.8739
2022-02-21 18:52:37 - train: epoch 0067, iter [01500, 05004], lr: 0.001000, loss: 0.9292
2022-02-21 18:53:09 - train: epoch 0067, iter [01600, 05004], lr: 0.001000, loss: 0.9928
2022-02-21 18:53:41 - train: epoch 0067, iter [01700, 05004], lr: 0.001000, loss: 0.7146
2022-02-21 18:54:13 - train: epoch 0067, iter [01800, 05004], lr: 0.001000, loss: 1.0576
2022-02-21 18:54:45 - train: epoch 0067, iter [01900, 05004], lr: 0.001000, loss: 0.7354
2022-02-21 18:55:17 - train: epoch 0067, iter [02000, 05004], lr: 0.001000, loss: 1.0619
2022-02-21 18:55:49 - train: epoch 0067, iter [02100, 05004], lr: 0.001000, loss: 0.7476
2022-02-21 18:56:21 - train: epoch 0067, iter [02200, 05004], lr: 0.001000, loss: 0.8946
2022-02-21 18:56:54 - train: epoch 0067, iter [02300, 05004], lr: 0.001000, loss: 0.8203
2022-02-21 18:57:26 - train: epoch 0067, iter [02400, 05004], lr: 0.001000, loss: 0.8429
2022-02-21 18:57:58 - train: epoch 0067, iter [02500, 05004], lr: 0.001000, loss: 0.7534
2022-02-21 18:58:30 - train: epoch 0067, iter [02600, 05004], lr: 0.001000, loss: 0.7377
2022-02-21 18:59:02 - train: epoch 0067, iter [02700, 05004], lr: 0.001000, loss: 0.7898
2022-02-21 18:59:35 - train: epoch 0067, iter [02800, 05004], lr: 0.001000, loss: 0.9479
2022-02-21 19:00:07 - train: epoch 0067, iter [02900, 05004], lr: 0.001000, loss: 0.8062
2022-02-21 19:00:39 - train: epoch 0067, iter [03000, 05004], lr: 0.001000, loss: 0.9538
2022-02-21 19:01:10 - train: epoch 0067, iter [03100, 05004], lr: 0.001000, loss: 0.6924
2022-02-21 19:01:42 - train: epoch 0067, iter [03200, 05004], lr: 0.001000, loss: 1.0184
2022-02-21 19:02:15 - train: epoch 0067, iter [03300, 05004], lr: 0.001000, loss: 0.7880
2022-02-21 19:02:46 - train: epoch 0067, iter [03400, 05004], lr: 0.001000, loss: 0.8892
2022-02-21 19:03:19 - train: epoch 0067, iter [03500, 05004], lr: 0.001000, loss: 0.7495
2022-02-21 19:03:51 - train: epoch 0067, iter [03600, 05004], lr: 0.001000, loss: 0.7973
2022-02-21 19:04:23 - train: epoch 0067, iter [03700, 05004], lr: 0.001000, loss: 0.9968
2022-02-21 19:04:55 - train: epoch 0067, iter [03800, 05004], lr: 0.001000, loss: 0.8460
2022-02-21 19:05:27 - train: epoch 0067, iter [03900, 05004], lr: 0.001000, loss: 0.8317
2022-02-21 19:05:59 - train: epoch 0067, iter [04000, 05004], lr: 0.001000, loss: 0.9396
2022-02-21 19:06:31 - train: epoch 0067, iter [04100, 05004], lr: 0.001000, loss: 0.9701
2022-02-21 19:07:03 - train: epoch 0067, iter [04200, 05004], lr: 0.001000, loss: 1.0078
2022-02-21 19:07:36 - train: epoch 0067, iter [04300, 05004], lr: 0.001000, loss: 0.7994
2022-02-21 19:08:08 - train: epoch 0067, iter [04400, 05004], lr: 0.001000, loss: 0.8682
2022-02-21 19:08:40 - train: epoch 0067, iter [04500, 05004], lr: 0.001000, loss: 0.8708
2022-02-21 19:09:13 - train: epoch 0067, iter [04600, 05004], lr: 0.001000, loss: 0.6066
2022-02-21 19:09:45 - train: epoch 0067, iter [04700, 05004], lr: 0.001000, loss: 0.8173
2022-02-21 19:10:18 - train: epoch 0067, iter [04800, 05004], lr: 0.001000, loss: 0.6492
2022-02-21 19:10:51 - train: epoch 0067, iter [04900, 05004], lr: 0.001000, loss: 0.8595
2022-02-21 19:11:24 - train: epoch 0067, iter [05000, 05004], lr: 0.001000, loss: 0.9854
2022-02-21 19:11:27 - train: epoch 067, train_loss: 0.8647
2022-02-21 19:12:43 - eval: epoch: 067, acc1: 77.084%, acc5: 93.718%, test_loss: 0.8886, per_image_load_time: 2.166ms, per_image_inference_time: 0.707ms
2022-02-21 19:12:44 - until epoch: 067, best_acc1: 77.184%
2022-02-21 19:12:44 - epoch 068 lr: 0.0010000000000000002
2022-02-21 19:13:22 - train: epoch 0068, iter [00100, 05004], lr: 0.001000, loss: 0.8856
2022-02-21 19:13:54 - train: epoch 0068, iter [00200, 05004], lr: 0.001000, loss: 0.9079
2022-02-21 19:14:26 - train: epoch 0068, iter [00300, 05004], lr: 0.001000, loss: 0.8987
2022-02-21 19:14:58 - train: epoch 0068, iter [00400, 05004], lr: 0.001000, loss: 0.9181
2022-02-21 19:15:29 - train: epoch 0068, iter [00500, 05004], lr: 0.001000, loss: 0.8917
2022-02-21 19:16:01 - train: epoch 0068, iter [00600, 05004], lr: 0.001000, loss: 0.8886
2022-02-21 19:16:33 - train: epoch 0068, iter [00700, 05004], lr: 0.001000, loss: 1.1093
2022-02-21 19:17:05 - train: epoch 0068, iter [00800, 05004], lr: 0.001000, loss: 0.8067
2022-02-21 19:17:37 - train: epoch 0068, iter [00900, 05004], lr: 0.001000, loss: 0.7463
2022-02-21 19:18:09 - train: epoch 0068, iter [01000, 05004], lr: 0.001000, loss: 0.8677
2022-02-21 19:18:41 - train: epoch 0068, iter [01100, 05004], lr: 0.001000, loss: 1.0301
2022-02-21 19:19:13 - train: epoch 0068, iter [01200, 05004], lr: 0.001000, loss: 0.8205
2022-02-21 19:19:45 - train: epoch 0068, iter [01300, 05004], lr: 0.001000, loss: 0.6682
2022-02-21 19:20:17 - train: epoch 0068, iter [01400, 05004], lr: 0.001000, loss: 0.8549
2022-02-21 19:20:49 - train: epoch 0068, iter [01500, 05004], lr: 0.001000, loss: 0.9987
2022-02-21 19:21:22 - train: epoch 0068, iter [01600, 05004], lr: 0.001000, loss: 0.9095
2022-02-21 19:21:54 - train: epoch 0068, iter [01700, 05004], lr: 0.001000, loss: 1.1031
2022-02-21 19:22:26 - train: epoch 0068, iter [01800, 05004], lr: 0.001000, loss: 0.9002
2022-02-21 19:22:58 - train: epoch 0068, iter [01900, 05004], lr: 0.001000, loss: 0.8977
2022-02-21 19:23:30 - train: epoch 0068, iter [02000, 05004], lr: 0.001000, loss: 0.8527
2022-02-21 19:24:02 - train: epoch 0068, iter [02100, 05004], lr: 0.001000, loss: 0.7987
2022-02-21 19:24:34 - train: epoch 0068, iter [02200, 05004], lr: 0.001000, loss: 0.9144
2022-02-21 19:25:06 - train: epoch 0068, iter [02300, 05004], lr: 0.001000, loss: 0.7362
2022-02-21 19:25:38 - train: epoch 0068, iter [02400, 05004], lr: 0.001000, loss: 0.9231
2022-02-21 19:26:10 - train: epoch 0068, iter [02500, 05004], lr: 0.001000, loss: 0.7635
2022-02-21 19:26:42 - train: epoch 0068, iter [02600, 05004], lr: 0.001000, loss: 0.8524
2022-02-21 19:27:14 - train: epoch 0068, iter [02700, 05004], lr: 0.001000, loss: 0.9256
2022-02-21 19:27:47 - train: epoch 0068, iter [02800, 05004], lr: 0.001000, loss: 1.0317
2022-02-21 19:28:19 - train: epoch 0068, iter [02900, 05004], lr: 0.001000, loss: 0.9062
2022-02-21 19:28:51 - train: epoch 0068, iter [03000, 05004], lr: 0.001000, loss: 1.0043
2022-02-21 19:29:23 - train: epoch 0068, iter [03100, 05004], lr: 0.001000, loss: 0.7281
2022-02-21 19:29:55 - train: epoch 0068, iter [03200, 05004], lr: 0.001000, loss: 0.9108
2022-02-21 19:30:27 - train: epoch 0068, iter [03300, 05004], lr: 0.001000, loss: 0.7751
2022-02-21 19:30:59 - train: epoch 0068, iter [03400, 05004], lr: 0.001000, loss: 0.7149
2022-02-21 19:31:31 - train: epoch 0068, iter [03500, 05004], lr: 0.001000, loss: 0.8868
2022-02-21 19:32:03 - train: epoch 0068, iter [03600, 05004], lr: 0.001000, loss: 0.7990
2022-02-21 19:32:36 - train: epoch 0068, iter [03700, 05004], lr: 0.001000, loss: 0.9713
2022-02-21 19:33:08 - train: epoch 0068, iter [03800, 05004], lr: 0.001000, loss: 0.9512
2022-02-21 19:33:40 - train: epoch 0068, iter [03900, 05004], lr: 0.001000, loss: 0.8401
2022-02-21 19:34:12 - train: epoch 0068, iter [04000, 05004], lr: 0.001000, loss: 0.8675
2022-02-21 19:34:44 - train: epoch 0068, iter [04100, 05004], lr: 0.001000, loss: 0.7514
2022-02-21 19:35:17 - train: epoch 0068, iter [04200, 05004], lr: 0.001000, loss: 1.0068
2022-02-21 19:35:49 - train: epoch 0068, iter [04300, 05004], lr: 0.001000, loss: 1.0109
2022-02-21 19:36:22 - train: epoch 0068, iter [04400, 05004], lr: 0.001000, loss: 0.8448
2022-02-21 19:36:54 - train: epoch 0068, iter [04500, 05004], lr: 0.001000, loss: 0.8841
2022-02-21 19:37:27 - train: epoch 0068, iter [04600, 05004], lr: 0.001000, loss: 0.9763
2022-02-21 19:37:59 - train: epoch 0068, iter [04700, 05004], lr: 0.001000, loss: 1.0837
2022-02-21 19:38:32 - train: epoch 0068, iter [04800, 05004], lr: 0.001000, loss: 1.0082
2022-02-21 19:39:05 - train: epoch 0068, iter [04900, 05004], lr: 0.001000, loss: 0.9861
2022-02-21 19:39:39 - train: epoch 0068, iter [05000, 05004], lr: 0.001000, loss: 0.8093
2022-02-21 19:39:42 - train: epoch 068, train_loss: 0.8570
2022-02-21 19:40:58 - eval: epoch: 068, acc1: 77.124%, acc5: 93.672%, test_loss: 0.8918, per_image_load_time: 2.209ms, per_image_inference_time: 0.699ms
2022-02-21 19:40:59 - until epoch: 068, best_acc1: 77.184%
2022-02-21 19:40:59 - epoch 069 lr: 0.0010000000000000002
2022-02-21 19:41:37 - train: epoch 0069, iter [00100, 05004], lr: 0.001000, loss: 0.9819
2022-02-21 19:42:08 - train: epoch 0069, iter [00200, 05004], lr: 0.001000, loss: 0.8749
2022-02-21 19:42:40 - train: epoch 0069, iter [00300, 05004], lr: 0.001000, loss: 0.9711
2022-02-21 19:43:12 - train: epoch 0069, iter [00400, 05004], lr: 0.001000, loss: 0.8288
2022-02-21 19:43:44 - train: epoch 0069, iter [00500, 05004], lr: 0.001000, loss: 0.7721
2022-02-21 19:44:17 - train: epoch 0069, iter [00600, 05004], lr: 0.001000, loss: 0.7435
2022-02-21 19:44:49 - train: epoch 0069, iter [00700, 05004], lr: 0.001000, loss: 0.8308
2022-02-21 19:45:21 - train: epoch 0069, iter [00800, 05004], lr: 0.001000, loss: 0.8728
2022-02-21 19:45:53 - train: epoch 0069, iter [00900, 05004], lr: 0.001000, loss: 0.8798
2022-02-21 19:46:26 - train: epoch 0069, iter [01000, 05004], lr: 0.001000, loss: 0.8439
2022-02-21 19:46:58 - train: epoch 0069, iter [01100, 05004], lr: 0.001000, loss: 0.8196
2022-02-21 19:47:30 - train: epoch 0069, iter [01200, 05004], lr: 0.001000, loss: 0.8534
2022-02-21 19:48:02 - train: epoch 0069, iter [01300, 05004], lr: 0.001000, loss: 1.0368
2022-02-21 19:48:35 - train: epoch 0069, iter [01400, 05004], lr: 0.001000, loss: 0.9000
2022-02-21 19:49:07 - train: epoch 0069, iter [01500, 05004], lr: 0.001000, loss: 0.8721
2022-02-21 19:49:39 - train: epoch 0069, iter [01600, 05004], lr: 0.001000, loss: 0.9464
2022-02-21 19:50:12 - train: epoch 0069, iter [01700, 05004], lr: 0.001000, loss: 0.7882
2022-02-21 19:50:43 - train: epoch 0069, iter [01800, 05004], lr: 0.001000, loss: 0.6885
2022-02-21 19:51:16 - train: epoch 0069, iter [01900, 05004], lr: 0.001000, loss: 0.7664
2022-02-21 19:51:48 - train: epoch 0069, iter [02000, 05004], lr: 0.001000, loss: 0.6557
2022-02-21 19:52:20 - train: epoch 0069, iter [02100, 05004], lr: 0.001000, loss: 0.9046
2022-02-21 19:52:52 - train: epoch 0069, iter [02200, 05004], lr: 0.001000, loss: 0.9067
2022-02-21 19:53:24 - train: epoch 0069, iter [02300, 05004], lr: 0.001000, loss: 0.9020
2022-02-21 19:53:55 - train: epoch 0069, iter [02400, 05004], lr: 0.001000, loss: 0.8798
2022-02-21 19:54:27 - train: epoch 0069, iter [02500, 05004], lr: 0.001000, loss: 0.8934
2022-02-21 19:55:00 - train: epoch 0069, iter [02600, 05004], lr: 0.001000, loss: 0.9173
2022-02-21 19:55:32 - train: epoch 0069, iter [02700, 05004], lr: 0.001000, loss: 1.0193
2022-02-21 19:56:04 - train: epoch 0069, iter [02800, 05004], lr: 0.001000, loss: 1.0353
2022-02-21 19:56:36 - train: epoch 0069, iter [02900, 05004], lr: 0.001000, loss: 0.7348
2022-02-21 19:57:08 - train: epoch 0069, iter [03000, 05004], lr: 0.001000, loss: 0.7544
2022-02-21 19:57:40 - train: epoch 0069, iter [03100, 05004], lr: 0.001000, loss: 0.7224
2022-02-21 19:58:12 - train: epoch 0069, iter [03200, 05004], lr: 0.001000, loss: 0.7777
2022-02-21 19:58:44 - train: epoch 0069, iter [03300, 05004], lr: 0.001000, loss: 0.7161
2022-02-21 19:59:16 - train: epoch 0069, iter [03400, 05004], lr: 0.001000, loss: 0.6885
2022-02-21 19:59:49 - train: epoch 0069, iter [03500, 05004], lr: 0.001000, loss: 0.7741
2022-02-21 20:00:21 - train: epoch 0069, iter [03600, 05004], lr: 0.001000, loss: 0.7652
2022-02-21 20:00:53 - train: epoch 0069, iter [03700, 05004], lr: 0.001000, loss: 0.9093
2022-02-21 20:01:25 - train: epoch 0069, iter [03800, 05004], lr: 0.001000, loss: 0.8988
2022-02-21 20:01:57 - train: epoch 0069, iter [03900, 05004], lr: 0.001000, loss: 0.9000
2022-02-21 20:02:30 - train: epoch 0069, iter [04000, 05004], lr: 0.001000, loss: 1.0016
2022-02-21 20:03:02 - train: epoch 0069, iter [04100, 05004], lr: 0.001000, loss: 0.9566
2022-02-21 20:03:34 - train: epoch 0069, iter [04200, 05004], lr: 0.001000, loss: 0.7304
2022-02-21 20:04:06 - train: epoch 0069, iter [04300, 05004], lr: 0.001000, loss: 0.8745
2022-02-21 20:04:39 - train: epoch 0069, iter [04400, 05004], lr: 0.001000, loss: 0.9328
2022-02-21 20:05:11 - train: epoch 0069, iter [04500, 05004], lr: 0.001000, loss: 0.8239
2022-02-21 20:05:43 - train: epoch 0069, iter [04600, 05004], lr: 0.001000, loss: 1.0031
2022-02-21 20:06:16 - train: epoch 0069, iter [04700, 05004], lr: 0.001000, loss: 0.8167
2022-02-21 20:06:49 - train: epoch 0069, iter [04800, 05004], lr: 0.001000, loss: 0.8118
2022-02-21 20:07:22 - train: epoch 0069, iter [04900, 05004], lr: 0.001000, loss: 0.8267
2022-02-21 20:07:55 - train: epoch 0069, iter [05000, 05004], lr: 0.001000, loss: 0.8899
2022-02-21 20:07:58 - train: epoch 069, train_loss: 0.8479
2022-02-21 20:09:14 - eval: epoch: 069, acc1: 77.088%, acc5: 93.722%, test_loss: 0.8885, per_image_load_time: 2.142ms, per_image_inference_time: 0.717ms
2022-02-21 20:09:15 - until epoch: 069, best_acc1: 77.184%
2022-02-21 20:09:15 - epoch 070 lr: 0.0010000000000000002
2022-02-21 20:09:53 - train: epoch 0070, iter [00100, 05004], lr: 0.001000, loss: 0.8719
2022-02-21 20:10:24 - train: epoch 0070, iter [00200, 05004], lr: 0.001000, loss: 0.9206
2022-02-21 20:10:56 - train: epoch 0070, iter [00300, 05004], lr: 0.001000, loss: 0.9229
2022-02-21 20:11:28 - train: epoch 0070, iter [00400, 05004], lr: 0.001000, loss: 0.7892
2022-02-21 20:12:00 - train: epoch 0070, iter [00500, 05004], lr: 0.001000, loss: 0.9754
2022-02-21 20:12:32 - train: epoch 0070, iter [00600, 05004], lr: 0.001000, loss: 0.7911
2022-02-21 20:13:03 - train: epoch 0070, iter [00700, 05004], lr: 0.001000, loss: 0.8523
2022-02-21 20:13:35 - train: epoch 0070, iter [00800, 05004], lr: 0.001000, loss: 0.8084
2022-02-21 20:14:07 - train: epoch 0070, iter [00900, 05004], lr: 0.001000, loss: 0.8685
2022-02-21 20:14:40 - train: epoch 0070, iter [01000, 05004], lr: 0.001000, loss: 0.8090
2022-02-21 20:15:12 - train: epoch 0070, iter [01100, 05004], lr: 0.001000, loss: 1.1317
2022-02-21 20:15:44 - train: epoch 0070, iter [01200, 05004], lr: 0.001000, loss: 0.6729
2022-02-21 20:16:16 - train: epoch 0070, iter [01300, 05004], lr: 0.001000, loss: 0.7466
2022-02-21 20:16:49 - train: epoch 0070, iter [01400, 05004], lr: 0.001000, loss: 0.8906
2022-02-21 20:17:21 - train: epoch 0070, iter [01500, 05004], lr: 0.001000, loss: 0.7865
2022-02-21 20:17:53 - train: epoch 0070, iter [01600, 05004], lr: 0.001000, loss: 0.8856
2022-02-21 20:18:26 - train: epoch 0070, iter [01700, 05004], lr: 0.001000, loss: 0.9756
2022-02-21 20:18:58 - train: epoch 0070, iter [01800, 05004], lr: 0.001000, loss: 0.7679
2022-02-21 20:19:31 - train: epoch 0070, iter [01900, 05004], lr: 0.001000, loss: 0.8780
2022-02-21 20:20:03 - train: epoch 0070, iter [02000, 05004], lr: 0.001000, loss: 0.8990
2022-02-21 20:20:35 - train: epoch 0070, iter [02100, 05004], lr: 0.001000, loss: 0.8420
2022-02-21 20:21:08 - train: epoch 0070, iter [02200, 05004], lr: 0.001000, loss: 0.8303
2022-02-21 20:21:40 - train: epoch 0070, iter [02300, 05004], lr: 0.001000, loss: 0.7949
2022-02-21 20:22:12 - train: epoch 0070, iter [02400, 05004], lr: 0.001000, loss: 0.9595
2022-02-21 20:22:45 - train: epoch 0070, iter [02500, 05004], lr: 0.001000, loss: 0.9129
2022-02-21 20:23:17 - train: epoch 0070, iter [02600, 05004], lr: 0.001000, loss: 0.7988
2022-02-21 20:23:50 - train: epoch 0070, iter [02700, 05004], lr: 0.001000, loss: 0.7988
2022-02-21 20:24:22 - train: epoch 0070, iter [02800, 05004], lr: 0.001000, loss: 0.9557
2022-02-21 20:24:54 - train: epoch 0070, iter [02900, 05004], lr: 0.001000, loss: 0.9714
2022-02-21 20:25:26 - train: epoch 0070, iter [03000, 05004], lr: 0.001000, loss: 0.7432
2022-02-21 20:25:58 - train: epoch 0070, iter [03100, 05004], lr: 0.001000, loss: 0.7787
2022-02-21 20:26:30 - train: epoch 0070, iter [03200, 05004], lr: 0.001000, loss: 0.9621
2022-02-21 20:27:03 - train: epoch 0070, iter [03300, 05004], lr: 0.001000, loss: 0.7989
2022-02-21 20:27:35 - train: epoch 0070, iter [03400, 05004], lr: 0.001000, loss: 0.8796
2022-02-21 20:28:08 - train: epoch 0070, iter [03500, 05004], lr: 0.001000, loss: 0.8797
2022-02-21 20:28:40 - train: epoch 0070, iter [03600, 05004], lr: 0.001000, loss: 0.9247
2022-02-21 20:29:12 - train: epoch 0070, iter [03700, 05004], lr: 0.001000, loss: 0.8197
2022-02-21 20:29:45 - train: epoch 0070, iter [03800, 05004], lr: 0.001000, loss: 0.8078
2022-02-21 20:30:17 - train: epoch 0070, iter [03900, 05004], lr: 0.001000, loss: 0.7378
2022-02-21 20:30:50 - train: epoch 0070, iter [04000, 05004], lr: 0.001000, loss: 0.7552
2022-02-21 20:31:22 - train: epoch 0070, iter [04100, 05004], lr: 0.001000, loss: 0.6886
2022-02-21 20:31:55 - train: epoch 0070, iter [04200, 05004], lr: 0.001000, loss: 0.8966
2022-02-21 20:32:27 - train: epoch 0070, iter [04300, 05004], lr: 0.001000, loss: 0.7738
2022-02-21 20:33:00 - train: epoch 0070, iter [04400, 05004], lr: 0.001000, loss: 0.9684
2022-02-21 20:33:33 - train: epoch 0070, iter [04500, 05004], lr: 0.001000, loss: 0.8145
2022-02-21 20:34:06 - train: epoch 0070, iter [04600, 05004], lr: 0.001000, loss: 0.9052
2022-02-21 20:34:38 - train: epoch 0070, iter [04700, 05004], lr: 0.001000, loss: 0.9827
2022-02-21 20:35:12 - train: epoch 0070, iter [04800, 05004], lr: 0.001000, loss: 0.7840
2022-02-21 20:35:45 - train: epoch 0070, iter [04900, 05004], lr: 0.001000, loss: 0.9023
2022-02-21 20:36:18 - train: epoch 0070, iter [05000, 05004], lr: 0.001000, loss: 0.7954
2022-02-21 20:36:22 - train: epoch 070, train_loss: 0.8427
2022-02-21 20:37:37 - eval: epoch: 070, acc1: 77.184%, acc5: 93.774%, test_loss: 0.8880, per_image_load_time: 1.959ms, per_image_inference_time: 0.733ms
2022-02-21 20:37:38 - until epoch: 070, best_acc1: 77.184%
2022-02-21 20:37:38 - epoch 071 lr: 0.0010000000000000002
2022-02-21 20:38:16 - train: epoch 0071, iter [00100, 05004], lr: 0.001000, loss: 0.7344
2022-02-21 20:38:48 - train: epoch 0071, iter [00200, 05004], lr: 0.001000, loss: 0.8958
2022-02-21 20:39:20 - train: epoch 0071, iter [00300, 05004], lr: 0.001000, loss: 0.7613
2022-02-21 20:39:51 - train: epoch 0071, iter [00400, 05004], lr: 0.001000, loss: 0.8545
2022-02-21 20:40:23 - train: epoch 0071, iter [00500, 05004], lr: 0.001000, loss: 0.7608
2022-02-21 20:40:56 - train: epoch 0071, iter [00600, 05004], lr: 0.001000, loss: 0.8487
2022-02-21 20:41:28 - train: epoch 0071, iter [00700, 05004], lr: 0.001000, loss: 1.0462
2022-02-21 20:42:00 - train: epoch 0071, iter [00800, 05004], lr: 0.001000, loss: 0.7822
2022-02-21 20:42:32 - train: epoch 0071, iter [00900, 05004], lr: 0.001000, loss: 0.8478
2022-02-21 20:43:04 - train: epoch 0071, iter [01000, 05004], lr: 0.001000, loss: 0.9143
2022-02-21 20:43:36 - train: epoch 0071, iter [01100, 05004], lr: 0.001000, loss: 1.0164
2022-02-21 20:44:08 - train: epoch 0071, iter [01200, 05004], lr: 0.001000, loss: 0.7853
2022-02-21 20:44:40 - train: epoch 0071, iter [01300, 05004], lr: 0.001000, loss: 0.8644
2022-02-21 20:45:12 - train: epoch 0071, iter [01400, 05004], lr: 0.001000, loss: 0.8432
2022-02-21 20:45:44 - train: epoch 0071, iter [01500, 05004], lr: 0.001000, loss: 0.6796
2022-02-21 20:46:17 - train: epoch 0071, iter [01600, 05004], lr: 0.001000, loss: 0.8652
2022-02-21 20:46:49 - train: epoch 0071, iter [01700, 05004], lr: 0.001000, loss: 0.8611
2022-02-21 20:47:21 - train: epoch 0071, iter [01800, 05004], lr: 0.001000, loss: 0.8760
2022-02-21 20:47:53 - train: epoch 0071, iter [01900, 05004], lr: 0.001000, loss: 0.7200
2022-02-21 20:48:25 - train: epoch 0071, iter [02000, 05004], lr: 0.001000, loss: 0.8953
2022-02-21 20:48:58 - train: epoch 0071, iter [02100, 05004], lr: 0.001000, loss: 0.6883
2022-02-21 20:49:29 - train: epoch 0071, iter [02200, 05004], lr: 0.001000, loss: 0.7863
2022-02-21 20:50:01 - train: epoch 0071, iter [02300, 05004], lr: 0.001000, loss: 0.6909
2022-02-21 20:50:33 - train: epoch 0071, iter [02400, 05004], lr: 0.001000, loss: 0.7480
2022-02-21 20:51:05 - train: epoch 0071, iter [02500, 05004], lr: 0.001000, loss: 0.7914
2022-02-21 20:51:38 - train: epoch 0071, iter [02600, 05004], lr: 0.001000, loss: 0.8260
2022-02-21 20:52:10 - train: epoch 0071, iter [02700, 05004], lr: 0.001000, loss: 0.8409
2022-02-21 20:52:42 - train: epoch 0071, iter [02800, 05004], lr: 0.001000, loss: 0.8801
2022-02-21 20:53:14 - train: epoch 0071, iter [02900, 05004], lr: 0.001000, loss: 0.8307
2022-02-21 20:53:46 - train: epoch 0071, iter [03000, 05004], lr: 0.001000, loss: 0.8057
2022-02-21 20:54:19 - train: epoch 0071, iter [03100, 05004], lr: 0.001000, loss: 0.8427
2022-02-21 20:54:51 - train: epoch 0071, iter [03200, 05004], lr: 0.001000, loss: 0.7674
2022-02-21 20:55:23 - train: epoch 0071, iter [03300, 05004], lr: 0.001000, loss: 0.7172
2022-02-21 20:55:55 - train: epoch 0071, iter [03400, 05004], lr: 0.001000, loss: 0.8389
2022-02-21 20:56:27 - train: epoch 0071, iter [03500, 05004], lr: 0.001000, loss: 0.9705
2022-02-21 20:56:59 - train: epoch 0071, iter [03600, 05004], lr: 0.001000, loss: 0.9884
2022-02-21 20:57:31 - train: epoch 0071, iter [03700, 05004], lr: 0.001000, loss: 0.8616
2022-02-21 20:58:03 - train: epoch 0071, iter [03800, 05004], lr: 0.001000, loss: 0.8728
2022-02-21 20:58:35 - train: epoch 0071, iter [03900, 05004], lr: 0.001000, loss: 0.9616
2022-02-21 20:59:07 - train: epoch 0071, iter [04000, 05004], lr: 0.001000, loss: 1.0007
2022-02-21 20:59:40 - train: epoch 0071, iter [04100, 05004], lr: 0.001000, loss: 0.8235
2022-02-21 21:00:12 - train: epoch 0071, iter [04200, 05004], lr: 0.001000, loss: 0.9434
2022-02-21 21:00:44 - train: epoch 0071, iter [04300, 05004], lr: 0.001000, loss: 0.9550
2022-02-21 21:01:17 - train: epoch 0071, iter [04400, 05004], lr: 0.001000, loss: 0.8310
2022-02-21 21:01:49 - train: epoch 0071, iter [04500, 05004], lr: 0.001000, loss: 0.7736
2022-02-21 21:02:21 - train: epoch 0071, iter [04600, 05004], lr: 0.001000, loss: 0.9339
2022-02-21 21:02:54 - train: epoch 0071, iter [04700, 05004], lr: 0.001000, loss: 0.6535
2022-02-21 21:03:27 - train: epoch 0071, iter [04800, 05004], lr: 0.001000, loss: 0.7224
2022-02-21 21:04:00 - train: epoch 0071, iter [04900, 05004], lr: 0.001000, loss: 0.6201
2022-02-21 21:04:33 - train: epoch 0071, iter [05000, 05004], lr: 0.001000, loss: 0.7155
2022-02-21 21:04:36 - train: epoch 071, train_loss: 0.8357
2022-02-21 21:05:52 - eval: epoch: 071, acc1: 77.238%, acc5: 93.744%, test_loss: 0.8857, per_image_load_time: 2.108ms, per_image_inference_time: 0.729ms
2022-02-21 21:05:53 - until epoch: 071, best_acc1: 77.238%
2022-02-21 21:05:53 - epoch 072 lr: 0.0010000000000000002
2022-02-21 21:06:30 - train: epoch 0072, iter [00100, 05004], lr: 0.001000, loss: 0.8443
2022-02-21 21:07:02 - train: epoch 0072, iter [00200, 05004], lr: 0.001000, loss: 0.7768
2022-02-21 21:07:33 - train: epoch 0072, iter [00300, 05004], lr: 0.001000, loss: 0.7117
2022-02-21 21:08:05 - train: epoch 0072, iter [00400, 05004], lr: 0.001000, loss: 0.8029
2022-02-21 21:08:37 - train: epoch 0072, iter [00500, 05004], lr: 0.001000, loss: 0.8261
2022-02-21 21:09:09 - train: epoch 0072, iter [00600, 05004], lr: 0.001000, loss: 0.8028
2022-02-21 21:09:41 - train: epoch 0072, iter [00700, 05004], lr: 0.001000, loss: 0.7880
2022-02-21 21:10:13 - train: epoch 0072, iter [00800, 05004], lr: 0.001000, loss: 0.9652
2022-02-21 21:10:45 - train: epoch 0072, iter [00900, 05004], lr: 0.001000, loss: 0.7022
2022-02-21 21:11:17 - train: epoch 0072, iter [01000, 05004], lr: 0.001000, loss: 0.7639
2022-02-21 21:11:49 - train: epoch 0072, iter [01100, 05004], lr: 0.001000, loss: 0.7877
2022-02-21 21:12:22 - train: epoch 0072, iter [01200, 05004], lr: 0.001000, loss: 0.8082
2022-02-21 21:12:54 - train: epoch 0072, iter [01300, 05004], lr: 0.001000, loss: 0.8535
2022-02-21 21:13:26 - train: epoch 0072, iter [01400, 05004], lr: 0.001000, loss: 0.9127
2022-02-21 21:13:59 - train: epoch 0072, iter [01500, 05004], lr: 0.001000, loss: 0.7522
2022-02-21 21:14:31 - train: epoch 0072, iter [01600, 05004], lr: 0.001000, loss: 0.9012
2022-02-21 21:15:03 - train: epoch 0072, iter [01700, 05004], lr: 0.001000, loss: 0.7694
2022-02-21 21:15:35 - train: epoch 0072, iter [01800, 05004], lr: 0.001000, loss: 0.6661
2022-02-21 21:16:08 - train: epoch 0072, iter [01900, 05004], lr: 0.001000, loss: 0.7643
2022-02-21 21:16:40 - train: epoch 0072, iter [02000, 05004], lr: 0.001000, loss: 0.9044
2022-02-21 21:17:12 - train: epoch 0072, iter [02100, 05004], lr: 0.001000, loss: 0.8141
2022-02-21 21:17:45 - train: epoch 0072, iter [02200, 05004], lr: 0.001000, loss: 0.9054
2022-02-21 21:18:17 - train: epoch 0072, iter [02300, 05004], lr: 0.001000, loss: 0.9752
2022-02-21 21:18:49 - train: epoch 0072, iter [02400, 05004], lr: 0.001000, loss: 0.7199
2022-02-21 21:19:21 - train: epoch 0072, iter [02500, 05004], lr: 0.001000, loss: 0.6961
2022-02-21 21:19:53 - train: epoch 0072, iter [02600, 05004], lr: 0.001000, loss: 0.7038
2022-02-21 21:20:26 - train: epoch 0072, iter [02700, 05004], lr: 0.001000, loss: 0.8248
2022-02-21 21:20:58 - train: epoch 0072, iter [02800, 05004], lr: 0.001000, loss: 0.9022
2022-02-21 21:21:30 - train: epoch 0072, iter [02900, 05004], lr: 0.001000, loss: 0.7731
2022-02-21 21:22:03 - train: epoch 0072, iter [03000, 05004], lr: 0.001000, loss: 0.7532
2022-02-21 21:22:35 - train: epoch 0072, iter [03100, 05004], lr: 0.001000, loss: 0.9770
2022-02-21 21:23:07 - train: epoch 0072, iter [03200, 05004], lr: 0.001000, loss: 0.8160
2022-02-21 21:23:39 - train: epoch 0072, iter [03300, 05004], lr: 0.001000, loss: 0.8137
2022-02-21 21:24:11 - train: epoch 0072, iter [03400, 05004], lr: 0.001000, loss: 0.8636
2022-02-21 21:24:44 - train: epoch 0072, iter [03500, 05004], lr: 0.001000, loss: 0.8731
2022-02-21 21:25:16 - train: epoch 0072, iter [03600, 05004], lr: 0.001000, loss: 0.7517
2022-02-21 21:25:48 - train: epoch 0072, iter [03700, 05004], lr: 0.001000, loss: 0.9515
2022-02-21 21:26:20 - train: epoch 0072, iter [03800, 05004], lr: 0.001000, loss: 0.7833
2022-02-21 21:26:52 - train: epoch 0072, iter [03900, 05004], lr: 0.001000, loss: 0.9254
2022-02-21 21:27:24 - train: epoch 0072, iter [04000, 05004], lr: 0.001000, loss: 0.7891
2022-02-21 21:27:57 - train: epoch 0072, iter [04100, 05004], lr: 0.001000, loss: 0.8818
2022-02-21 21:28:29 - train: epoch 0072, iter [04200, 05004], lr: 0.001000, loss: 0.8592
2022-02-21 21:29:01 - train: epoch 0072, iter [04300, 05004], lr: 0.001000, loss: 0.8384
2022-02-21 21:29:34 - train: epoch 0072, iter [04400, 05004], lr: 0.001000, loss: 0.6971
2022-02-21 21:30:07 - train: epoch 0072, iter [04500, 05004], lr: 0.001000, loss: 0.8752
2022-02-21 21:30:39 - train: epoch 0072, iter [04600, 05004], lr: 0.001000, loss: 0.8161
2022-02-21 21:31:12 - train: epoch 0072, iter [04700, 05004], lr: 0.001000, loss: 0.8671
2022-02-21 21:31:45 - train: epoch 0072, iter [04800, 05004], lr: 0.001000, loss: 0.9599
2022-02-21 21:32:18 - train: epoch 0072, iter [04900, 05004], lr: 0.001000, loss: 0.8610
2022-02-21 21:32:52 - train: epoch 0072, iter [05000, 05004], lr: 0.001000, loss: 0.7873
2022-02-21 21:32:55 - train: epoch 072, train_loss: 0.8300
2022-02-21 21:34:11 - eval: epoch: 072, acc1: 77.164%, acc5: 93.752%, test_loss: 0.8868, per_image_load_time: 2.106ms, per_image_inference_time: 0.757ms
2022-02-21 21:34:12 - until epoch: 072, best_acc1: 77.238%
2022-02-21 21:34:12 - epoch 073 lr: 0.0010000000000000002
2022-02-21 21:34:50 - train: epoch 0073, iter [00100, 05004], lr: 0.001000, loss: 1.0611
2022-02-21 21:35:22 - train: epoch 0073, iter [00200, 05004], lr: 0.001000, loss: 0.8218
2022-02-21 21:35:54 - train: epoch 0073, iter [00300, 05004], lr: 0.001000, loss: 1.0163
2022-02-21 21:36:26 - train: epoch 0073, iter [00400, 05004], lr: 0.001000, loss: 0.5707
2022-02-21 21:36:59 - train: epoch 0073, iter [00500, 05004], lr: 0.001000, loss: 0.7129
2022-02-21 21:37:32 - train: epoch 0073, iter [00600, 05004], lr: 0.001000, loss: 0.7325
2022-02-21 21:38:04 - train: epoch 0073, iter [00700, 05004], lr: 0.001000, loss: 0.8247
2022-02-21 21:38:37 - train: epoch 0073, iter [00800, 05004], lr: 0.001000, loss: 0.7067
2022-02-21 21:39:10 - train: epoch 0073, iter [00900, 05004], lr: 0.001000, loss: 0.6728
2022-02-21 21:39:42 - train: epoch 0073, iter [01000, 05004], lr: 0.001000, loss: 0.7114
2022-02-21 21:40:14 - train: epoch 0073, iter [01100, 05004], lr: 0.001000, loss: 0.8620
2022-02-21 21:40:47 - train: epoch 0073, iter [01200, 05004], lr: 0.001000, loss: 0.8226
2022-02-21 21:41:19 - train: epoch 0073, iter [01300, 05004], lr: 0.001000, loss: 0.8445
2022-02-21 21:41:52 - train: epoch 0073, iter [01400, 05004], lr: 0.001000, loss: 0.6771
2022-02-21 21:42:24 - train: epoch 0073, iter [01500, 05004], lr: 0.001000, loss: 0.7627
2022-02-21 21:42:57 - train: epoch 0073, iter [01600, 05004], lr: 0.001000, loss: 0.7934
2022-02-21 21:43:29 - train: epoch 0073, iter [01700, 05004], lr: 0.001000, loss: 1.0002
2022-02-21 21:44:01 - train: epoch 0073, iter [01800, 05004], lr: 0.001000, loss: 0.6650
2022-02-21 21:44:33 - train: epoch 0073, iter [01900, 05004], lr: 0.001000, loss: 0.8991
2022-02-21 21:45:05 - train: epoch 0073, iter [02000, 05004], lr: 0.001000, loss: 0.6219
2022-02-21 21:45:37 - train: epoch 0073, iter [02100, 05004], lr: 0.001000, loss: 0.8158
2022-02-21 21:46:09 - train: epoch 0073, iter [02200, 05004], lr: 0.001000, loss: 1.0071
2022-02-21 21:46:41 - train: epoch 0073, iter [02300, 05004], lr: 0.001000, loss: 0.9056
2022-02-21 21:47:13 - train: epoch 0073, iter [02400, 05004], lr: 0.001000, loss: 0.8114
2022-02-21 21:47:46 - train: epoch 0073, iter [02500, 05004], lr: 0.001000, loss: 0.9541
2022-02-21 21:48:18 - train: epoch 0073, iter [02600, 05004], lr: 0.001000, loss: 0.8809
2022-02-21 21:48:50 - train: epoch 0073, iter [02700, 05004], lr: 0.001000, loss: 0.8902
2022-02-21 21:49:22 - train: epoch 0073, iter [02800, 05004], lr: 0.001000, loss: 0.8530
2022-02-21 21:49:55 - train: epoch 0073, iter [02900, 05004], lr: 0.001000, loss: 0.8993
2022-02-21 21:50:27 - train: epoch 0073, iter [03000, 05004], lr: 0.001000, loss: 0.7040
2022-02-21 21:50:59 - train: epoch 0073, iter [03100, 05004], lr: 0.001000, loss: 0.7697
2022-02-21 21:51:32 - train: epoch 0073, iter [03200, 05004], lr: 0.001000, loss: 0.7765
2022-02-21 21:52:04 - train: epoch 0073, iter [03300, 05004], lr: 0.001000, loss: 0.7239
2022-02-21 21:52:36 - train: epoch 0073, iter [03400, 05004], lr: 0.001000, loss: 0.7971
2022-02-21 21:53:09 - train: epoch 0073, iter [03500, 05004], lr: 0.001000, loss: 0.8774
2022-02-21 21:53:41 - train: epoch 0073, iter [03600, 05004], lr: 0.001000, loss: 0.6885
2022-02-21 21:54:14 - train: epoch 0073, iter [03700, 05004], lr: 0.001000, loss: 0.8023
2022-02-21 21:54:46 - train: epoch 0073, iter [03800, 05004], lr: 0.001000, loss: 1.0115
2022-02-21 21:55:18 - train: epoch 0073, iter [03900, 05004], lr: 0.001000, loss: 0.8001
2022-02-21 21:55:51 - train: epoch 0073, iter [04000, 05004], lr: 0.001000, loss: 0.8298
2022-02-21 21:56:23 - train: epoch 0073, iter [04100, 05004], lr: 0.001000, loss: 0.7798
2022-02-21 21:56:55 - train: epoch 0073, iter [04200, 05004], lr: 0.001000, loss: 0.8124
2022-02-21 21:57:28 - train: epoch 0073, iter [04300, 05004], lr: 0.001000, loss: 0.8712
2022-02-21 21:58:00 - train: epoch 0073, iter [04400, 05004], lr: 0.001000, loss: 0.8852
2022-02-21 21:58:33 - train: epoch 0073, iter [04500, 05004], lr: 0.001000, loss: 0.7562
2022-02-21 21:59:06 - train: epoch 0073, iter [04600, 05004], lr: 0.001000, loss: 0.9916
2022-02-21 21:59:39 - train: epoch 0073, iter [04700, 05004], lr: 0.001000, loss: 0.6123
2022-02-21 22:00:12 - train: epoch 0073, iter [04800, 05004], lr: 0.001000, loss: 0.8512
2022-02-21 22:00:45 - train: epoch 0073, iter [04900, 05004], lr: 0.001000, loss: 0.7209
2022-02-21 22:01:19 - train: epoch 0073, iter [05000, 05004], lr: 0.001000, loss: 0.8853
2022-02-21 22:01:22 - train: epoch 073, train_loss: 0.8243
2022-02-21 22:02:37 - eval: epoch: 073, acc1: 77.180%, acc5: 93.736%, test_loss: 0.8889, per_image_load_time: 2.156ms, per_image_inference_time: 0.704ms
2022-02-21 22:02:38 - until epoch: 073, best_acc1: 77.238%
2022-02-21 22:02:38 - epoch 074 lr: 0.0010000000000000002
2022-02-21 22:03:15 - train: epoch 0074, iter [00100, 05004], lr: 0.001000, loss: 0.7348
2022-02-21 22:03:47 - train: epoch 0074, iter [00200, 05004], lr: 0.001000, loss: 0.8022
2022-02-21 22:04:19 - train: epoch 0074, iter [00300, 05004], lr: 0.001000, loss: 0.8738
2022-02-21 22:04:51 - train: epoch 0074, iter [00400, 05004], lr: 0.001000, loss: 0.8519
2022-02-21 22:05:23 - train: epoch 0074, iter [00500, 05004], lr: 0.001000, loss: 0.8917
2022-02-21 22:05:55 - train: epoch 0074, iter [00600, 05004], lr: 0.001000, loss: 0.8346
2022-02-21 22:06:27 - train: epoch 0074, iter [00700, 05004], lr: 0.001000, loss: 0.8294
2022-02-21 22:06:59 - train: epoch 0074, iter [00800, 05004], lr: 0.001000, loss: 0.9846
2022-02-21 22:07:32 - train: epoch 0074, iter [00900, 05004], lr: 0.001000, loss: 0.8371
2022-02-21 22:08:04 - train: epoch 0074, iter [01000, 05004], lr: 0.001000, loss: 0.8429
2022-02-21 22:08:36 - train: epoch 0074, iter [01100, 05004], lr: 0.001000, loss: 0.9280
2022-02-21 22:09:08 - train: epoch 0074, iter [01200, 05004], lr: 0.001000, loss: 0.7871
2022-02-21 22:09:40 - train: epoch 0074, iter [01300, 05004], lr: 0.001000, loss: 0.9216
2022-02-21 22:10:13 - train: epoch 0074, iter [01400, 05004], lr: 0.001000, loss: 0.7030
2022-02-21 22:10:45 - train: epoch 0074, iter [01500, 05004], lr: 0.001000, loss: 0.7710
2022-02-21 22:11:17 - train: epoch 0074, iter [01600, 05004], lr: 0.001000, loss: 0.6357
2022-02-21 22:11:49 - train: epoch 0074, iter [01700, 05004], lr: 0.001000, loss: 0.8894
2022-02-21 22:12:21 - train: epoch 0074, iter [01800, 05004], lr: 0.001000, loss: 1.1363
2022-02-21 22:12:53 - train: epoch 0074, iter [01900, 05004], lr: 0.001000, loss: 0.8697
2022-02-21 22:13:25 - train: epoch 0074, iter [02000, 05004], lr: 0.001000, loss: 0.6260
2022-02-21 22:13:58 - train: epoch 0074, iter [02100, 05004], lr: 0.001000, loss: 0.7902
2022-02-21 22:14:30 - train: epoch 0074, iter [02200, 05004], lr: 0.001000, loss: 1.0672
2022-02-21 22:15:02 - train: epoch 0074, iter [02300, 05004], lr: 0.001000, loss: 0.8608
2022-02-21 22:15:34 - train: epoch 0074, iter [02400, 05004], lr: 0.001000, loss: 0.7877
2022-02-21 22:16:06 - train: epoch 0074, iter [02500, 05004], lr: 0.001000, loss: 0.7908
2022-02-21 22:16:38 - train: epoch 0074, iter [02600, 05004], lr: 0.001000, loss: 0.6883
2022-02-21 22:17:10 - train: epoch 0074, iter [02700, 05004], lr: 0.001000, loss: 0.7091
2022-02-21 22:17:42 - train: epoch 0074, iter [02800, 05004], lr: 0.001000, loss: 1.0957
2022-02-21 22:18:15 - train: epoch 0074, iter [02900, 05004], lr: 0.001000, loss: 0.7345
2022-02-21 22:18:47 - train: epoch 0074, iter [03000, 05004], lr: 0.001000, loss: 0.8000
2022-02-21 22:19:19 - train: epoch 0074, iter [03100, 05004], lr: 0.001000, loss: 0.8298
2022-02-21 22:19:51 - train: epoch 0074, iter [03200, 05004], lr: 0.001000, loss: 0.8191
2022-02-21 22:20:23 - train: epoch 0074, iter [03300, 05004], lr: 0.001000, loss: 0.8242
2022-02-21 22:20:56 - train: epoch 0074, iter [03400, 05004], lr: 0.001000, loss: 0.8668
2022-02-21 22:21:28 - train: epoch 0074, iter [03500, 05004], lr: 0.001000, loss: 0.6517
2022-02-21 22:22:01 - train: epoch 0074, iter [03600, 05004], lr: 0.001000, loss: 0.8643
2022-02-21 22:22:33 - train: epoch 0074, iter [03700, 05004], lr: 0.001000, loss: 0.8427
2022-02-21 22:23:06 - train: epoch 0074, iter [03800, 05004], lr: 0.001000, loss: 0.7944
2022-02-21 22:23:38 - train: epoch 0074, iter [03900, 05004], lr: 0.001000, loss: 0.5884
2022-02-21 22:24:10 - train: epoch 0074, iter [04000, 05004], lr: 0.001000, loss: 0.7218
2022-02-21 22:24:43 - train: epoch 0074, iter [04100, 05004], lr: 0.001000, loss: 0.9959
2022-02-21 22:25:15 - train: epoch 0074, iter [04200, 05004], lr: 0.001000, loss: 0.7302
2022-02-21 22:25:48 - train: epoch 0074, iter [04300, 05004], lr: 0.001000, loss: 0.7542
2022-02-21 22:26:20 - train: epoch 0074, iter [04400, 05004], lr: 0.001000, loss: 0.6776
2022-02-21 22:26:53 - train: epoch 0074, iter [04500, 05004], lr: 0.001000, loss: 0.7061
2022-02-21 22:27:26 - train: epoch 0074, iter [04600, 05004], lr: 0.001000, loss: 0.8786
2022-02-21 22:27:59 - train: epoch 0074, iter [04700, 05004], lr: 0.001000, loss: 0.8881
2022-02-21 22:28:32 - train: epoch 0074, iter [04800, 05004], lr: 0.001000, loss: 0.8642
2022-02-21 22:29:06 - train: epoch 0074, iter [04900, 05004], lr: 0.001000, loss: 0.9886
2022-02-21 22:29:39 - train: epoch 0074, iter [05000, 05004], lr: 0.001000, loss: 0.8296
2022-02-21 22:29:42 - train: epoch 074, train_loss: 0.8183
2022-02-21 22:30:58 - eval: epoch: 074, acc1: 77.224%, acc5: 93.760%, test_loss: 0.8861, per_image_load_time: 2.178ms, per_image_inference_time: 0.707ms
2022-02-21 22:30:59 - until epoch: 074, best_acc1: 77.238%
2022-02-21 22:30:59 - epoch 075 lr: 0.0010000000000000002
2022-02-21 22:31:37 - train: epoch 0075, iter [00100, 05004], lr: 0.001000, loss: 0.8508
2022-02-21 22:32:08 - train: epoch 0075, iter [00200, 05004], lr: 0.001000, loss: 0.8361
2022-02-21 22:32:40 - train: epoch 0075, iter [00300, 05004], lr: 0.001000, loss: 0.8090
2022-02-21 22:33:12 - train: epoch 0075, iter [00400, 05004], lr: 0.001000, loss: 0.7803
2022-02-21 22:33:44 - train: epoch 0075, iter [00500, 05004], lr: 0.001000, loss: 0.6940
2022-02-21 22:34:16 - train: epoch 0075, iter [00600, 05004], lr: 0.001000, loss: 0.7399
2022-02-21 22:34:48 - train: epoch 0075, iter [00700, 05004], lr: 0.001000, loss: 0.8988
2022-02-21 22:35:20 - train: epoch 0075, iter [00800, 05004], lr: 0.001000, loss: 0.9257
2022-02-21 22:35:52 - train: epoch 0075, iter [00900, 05004], lr: 0.001000, loss: 0.9918
2022-02-21 22:36:24 - train: epoch 0075, iter [01000, 05004], lr: 0.001000, loss: 0.6270
2022-02-21 22:36:57 - train: epoch 0075, iter [01100, 05004], lr: 0.001000, loss: 0.8369
2022-02-21 22:37:28 - train: epoch 0075, iter [01200, 05004], lr: 0.001000, loss: 0.7145
2022-02-21 22:38:00 - train: epoch 0075, iter [01300, 05004], lr: 0.001000, loss: 0.7638
2022-02-21 22:38:31 - train: epoch 0075, iter [01400, 05004], lr: 0.001000, loss: 0.8883
2022-02-21 22:39:03 - train: epoch 0075, iter [01500, 05004], lr: 0.001000, loss: 0.9386
2022-02-21 22:39:35 - train: epoch 0075, iter [01600, 05004], lr: 0.001000, loss: 0.6019
2022-02-21 22:40:07 - train: epoch 0075, iter [01700, 05004], lr: 0.001000, loss: 0.7808
2022-02-21 22:40:39 - train: epoch 0075, iter [01800, 05004], lr: 0.001000, loss: 0.7818
2022-02-21 22:41:11 - train: epoch 0075, iter [01900, 05004], lr: 0.001000, loss: 0.7195
2022-02-21 22:41:43 - train: epoch 0075, iter [02000, 05004], lr: 0.001000, loss: 0.9980
2022-02-21 22:42:15 - train: epoch 0075, iter [02100, 05004], lr: 0.001000, loss: 0.7421
2022-02-21 22:42:47 - train: epoch 0075, iter [02200, 05004], lr: 0.001000, loss: 0.8686
2022-02-21 22:43:19 - train: epoch 0075, iter [02300, 05004], lr: 0.001000, loss: 0.8775
2022-02-21 22:43:50 - train: epoch 0075, iter [02400, 05004], lr: 0.001000, loss: 0.8574
2022-02-21 22:44:22 - train: epoch 0075, iter [02500, 05004], lr: 0.001000, loss: 0.8999
2022-02-21 22:44:54 - train: epoch 0075, iter [02600, 05004], lr: 0.001000, loss: 0.7790
2022-02-21 22:45:26 - train: epoch 0075, iter [02700, 05004], lr: 0.001000, loss: 0.5967
2022-02-21 22:45:59 - train: epoch 0075, iter [02800, 05004], lr: 0.001000, loss: 0.7764
2022-02-21 22:46:31 - train: epoch 0075, iter [02900, 05004], lr: 0.001000, loss: 0.8754
2022-02-21 22:47:03 - train: epoch 0075, iter [03000, 05004], lr: 0.001000, loss: 0.9952
2022-02-21 22:47:35 - train: epoch 0075, iter [03100, 05004], lr: 0.001000, loss: 0.8162
2022-02-21 22:48:07 - train: epoch 0075, iter [03200, 05004], lr: 0.001000, loss: 0.7692
2022-02-21 22:48:40 - train: epoch 0075, iter [03300, 05004], lr: 0.001000, loss: 0.8279
2022-02-21 22:49:12 - train: epoch 0075, iter [03400, 05004], lr: 0.001000, loss: 0.6441
2022-02-21 22:49:44 - train: epoch 0075, iter [03500, 05004], lr: 0.001000, loss: 0.7508
2022-02-21 22:50:16 - train: epoch 0075, iter [03600, 05004], lr: 0.001000, loss: 0.7376
2022-02-21 22:50:49 - train: epoch 0075, iter [03700, 05004], lr: 0.001000, loss: 0.7789
2022-02-21 22:51:21 - train: epoch 0075, iter [03800, 05004], lr: 0.001000, loss: 0.8764
2022-02-21 22:51:53 - train: epoch 0075, iter [03900, 05004], lr: 0.001000, loss: 0.9591
2022-02-21 22:52:25 - train: epoch 0075, iter [04000, 05004], lr: 0.001000, loss: 0.7815
2022-02-21 22:52:58 - train: epoch 0075, iter [04100, 05004], lr: 0.001000, loss: 0.6134
2022-02-21 22:53:30 - train: epoch 0075, iter [04200, 05004], lr: 0.001000, loss: 0.9268
2022-02-21 22:54:02 - train: epoch 0075, iter [04300, 05004], lr: 0.001000, loss: 0.9950
2022-02-21 22:54:34 - train: epoch 0075, iter [04400, 05004], lr: 0.001000, loss: 0.6337
2022-02-21 22:55:06 - train: epoch 0075, iter [04500, 05004], lr: 0.001000, loss: 0.8849
2022-02-21 22:55:39 - train: epoch 0075, iter [04600, 05004], lr: 0.001000, loss: 0.7338
2022-02-21 22:56:12 - train: epoch 0075, iter [04700, 05004], lr: 0.001000, loss: 0.8558
2022-02-21 22:56:44 - train: epoch 0075, iter [04800, 05004], lr: 0.001000, loss: 0.8667
2022-02-21 22:57:18 - train: epoch 0075, iter [04900, 05004], lr: 0.001000, loss: 0.6540
2022-02-21 22:57:51 - train: epoch 0075, iter [05000, 05004], lr: 0.001000, loss: 0.9186
2022-02-21 22:57:54 - train: epoch 075, train_loss: 0.8145
2022-02-21 22:59:10 - eval: epoch: 075, acc1: 77.272%, acc5: 93.758%, test_loss: 0.8856, per_image_load_time: 2.181ms, per_image_inference_time: 0.695ms
2022-02-21 22:59:12 - until epoch: 075, best_acc1: 77.272%
2022-02-21 22:59:12 - epoch 076 lr: 0.0010000000000000002
2022-02-21 22:59:49 - train: epoch 0076, iter [00100, 05004], lr: 0.001000, loss: 0.6724
2022-02-21 23:00:21 - train: epoch 0076, iter [00200, 05004], lr: 0.001000, loss: 0.7971
2022-02-21 23:00:53 - train: epoch 0076, iter [00300, 05004], lr: 0.001000, loss: 0.9086
2022-02-21 23:01:25 - train: epoch 0076, iter [00400, 05004], lr: 0.001000, loss: 0.8912
2022-02-21 23:01:58 - train: epoch 0076, iter [00500, 05004], lr: 0.001000, loss: 0.7892
2022-02-21 23:02:30 - train: epoch 0076, iter [00600, 05004], lr: 0.001000, loss: 0.7780
2022-02-21 23:03:02 - train: epoch 0076, iter [00700, 05004], lr: 0.001000, loss: 0.7970
2022-02-21 23:03:34 - train: epoch 0076, iter [00800, 05004], lr: 0.001000, loss: 0.8174
2022-02-21 23:04:07 - train: epoch 0076, iter [00900, 05004], lr: 0.001000, loss: 0.6237
2022-02-21 23:04:39 - train: epoch 0076, iter [01000, 05004], lr: 0.001000, loss: 0.5972
2022-02-21 23:05:11 - train: epoch 0076, iter [01100, 05004], lr: 0.001000, loss: 0.7114
2022-02-21 23:05:44 - train: epoch 0076, iter [01200, 05004], lr: 0.001000, loss: 0.8203
2022-02-21 23:06:16 - train: epoch 0076, iter [01300, 05004], lr: 0.001000, loss: 0.8070
2022-02-21 23:06:48 - train: epoch 0076, iter [01400, 05004], lr: 0.001000, loss: 0.7124
2022-02-21 23:07:21 - train: epoch 0076, iter [01500, 05004], lr: 0.001000, loss: 0.6557
2022-02-21 23:07:53 - train: epoch 0076, iter [01600, 05004], lr: 0.001000, loss: 0.8061
2022-02-21 23:08:25 - train: epoch 0076, iter [01700, 05004], lr: 0.001000, loss: 0.7350
2022-02-21 23:08:57 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 0.6461
2022-02-21 23:09:30 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 0.9273
2022-02-21 23:10:02 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 0.8442
2022-02-21 23:10:34 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 0.9354
2022-02-21 23:11:06 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 0.9714
2022-02-21 23:11:39 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 0.8136
2022-02-21 23:12:11 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 0.9283
2022-02-21 23:12:43 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 0.7860
2022-02-21 23:13:15 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 0.9266
2022-02-21 23:13:48 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 0.8542
2022-02-21 23:14:20 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 0.7164
2022-02-21 23:14:52 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 0.7695
2022-02-21 23:15:24 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 0.7937
2022-02-21 23:15:57 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 0.8723
2022-02-21 23:16:29 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 0.8210
2022-02-21 23:17:01 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 0.8786
2022-02-21 23:17:33 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 0.9409
2022-02-21 23:18:05 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 0.7226
2022-02-21 23:18:38 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 0.7901
2022-02-21 23:19:10 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 0.8147
2022-02-21 23:19:43 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 0.7113
2022-02-21 23:20:15 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 0.6519
2022-02-21 23:20:47 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 0.8376
2022-02-21 23:21:20 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 0.7284
2022-02-21 23:21:52 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 0.9312
2022-02-21 23:22:25 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 0.8219
2022-02-21 23:22:57 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 0.8336
2022-02-21 23:23:30 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 0.7313
2022-02-21 23:24:03 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 0.7161
2022-02-21 23:24:36 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 0.8405
2022-02-21 23:25:09 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 0.6637
2022-02-21 23:25:42 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 0.8299
2022-02-21 23:26:16 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 0.7955
2022-02-21 23:26:19 - train: epoch 076, train_loss: 0.8091
2022-02-21 23:27:34 - eval: epoch: 076, acc1: 77.316%, acc5: 93.774%, test_loss: 0.8847, per_image_load_time: 2.180ms, per_image_inference_time: 0.679ms
2022-02-21 23:27:36 - until epoch: 076, best_acc1: 77.316%
2022-02-21 23:27:36 - epoch 077 lr: 0.0010000000000000002
2022-02-21 23:28:13 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 0.8644
2022-02-21 23:28:44 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 0.8599
2022-02-21 23:29:16 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 0.6485
2022-02-21 23:29:48 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 0.8791
2022-02-21 23:30:20 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 0.7136
2022-02-21 23:30:53 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 0.5836
2022-02-21 23:31:25 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 0.7922
2022-02-21 23:31:57 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 0.9161
2022-02-21 23:32:29 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 0.9259
2022-02-21 23:33:01 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 0.6474
2022-02-21 23:33:34 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 0.7594
2022-02-21 23:34:06 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 0.7936
2022-02-21 23:34:39 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 0.6812
2022-02-21 23:35:11 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 0.9292
2022-02-21 23:35:43 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 0.6749
2022-02-21 23:36:15 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 0.7664
2022-02-21 23:36:48 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 0.9876
2022-02-21 23:37:20 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 0.7242
2022-02-21 23:37:52 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 0.8850
2022-02-21 23:38:24 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 0.6780
2022-02-21 23:38:56 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 0.7927
2022-02-21 23:39:29 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 0.8437
2022-02-21 23:40:01 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 0.9461
2022-02-21 23:40:33 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 0.7992
2022-02-21 23:41:06 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 0.9816
2022-02-21 23:41:38 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 0.5991
2022-02-21 23:42:10 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 0.8052
2022-02-21 23:42:42 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 0.8858
2022-02-21 23:43:14 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 0.9961
2022-02-21 23:43:47 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 0.7131
2022-02-21 23:44:19 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 0.8113
2022-02-21 23:44:51 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 0.8998
2022-02-21 23:45:24 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 0.7070
2022-02-21 23:45:56 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 0.9844
2022-02-21 23:46:28 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 0.7358
2022-02-21 23:47:01 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 0.7013
2022-02-21 23:47:33 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 0.8623
2022-02-21 23:48:05 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 0.8461
2022-02-21 23:48:37 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 0.9144
2022-02-21 23:49:10 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 0.8084
2022-02-21 23:49:42 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 0.9239
2022-02-21 23:50:14 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 0.8451
2022-02-21 23:50:47 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 0.7707
2022-02-21 23:51:19 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 0.7353
2022-02-21 23:51:52 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 0.8029
2022-02-21 23:52:24 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 0.7808
2022-02-21 23:52:57 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 0.6016
2022-02-21 23:53:30 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 0.8680
2022-02-21 23:54:04 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 0.9807
2022-02-21 23:54:37 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 0.9968
2022-02-21 23:54:40 - train: epoch 077, train_loss: 0.8015
2022-02-21 23:55:56 - eval: epoch: 077, acc1: 77.276%, acc5: 93.798%, test_loss: 0.8878, per_image_load_time: 2.157ms, per_image_inference_time: 0.709ms
2022-02-21 23:55:57 - until epoch: 077, best_acc1: 77.316%
2022-02-21 23:55:57 - epoch 078 lr: 0.0010000000000000002
2022-02-21 23:56:34 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 0.7242
2022-02-21 23:57:05 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 0.9397
2022-02-21 23:57:37 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 0.9284
2022-02-21 23:58:09 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 0.8618
2022-02-21 23:58:41 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 0.7974
2022-02-21 23:59:13 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 0.8348
2022-02-21 23:59:45 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 0.8262
2022-02-22 00:00:17 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 0.9320
2022-02-22 00:00:49 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 0.8551
2022-02-22 00:01:21 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 0.8525
2022-02-22 00:01:53 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 0.6248
2022-02-22 00:02:25 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 0.6189
2022-02-22 00:02:57 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 0.8556
2022-02-22 00:03:29 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 0.7309
2022-02-22 00:04:01 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 0.8091
2022-02-22 00:04:33 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 0.8560
2022-02-22 00:05:05 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 0.8060
2022-02-22 00:05:38 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 0.7804
2022-02-22 00:06:10 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 0.6551
2022-02-22 00:06:42 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 0.6661
2022-02-22 00:07:14 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 0.9832
2022-02-22 00:07:46 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 0.7162
2022-02-22 00:08:18 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 0.9415
2022-02-22 00:08:50 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 0.7633
2022-02-22 00:09:22 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 0.7230
2022-02-22 00:09:54 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 0.7247
2022-02-22 00:10:25 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 0.8036
2022-02-22 00:10:57 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 0.8219
2022-02-22 00:11:29 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 0.7077
2022-02-22 00:12:01 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 0.7246
2022-02-22 00:12:33 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 0.8861
2022-02-22 00:13:05 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 0.7728
2022-02-22 00:13:38 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 0.8467
2022-02-22 00:14:10 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 0.7342
2022-02-22 00:14:42 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 0.7924
2022-02-22 00:15:14 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 0.8425
2022-02-22 00:15:46 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 0.6123
2022-02-22 00:16:18 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 0.8162
2022-02-22 00:16:50 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 0.8242
2022-02-22 00:17:22 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 0.8186
2022-02-22 00:17:54 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 0.9030
2022-02-22 00:18:26 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 0.9354
2022-02-22 00:18:58 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 0.8173
2022-02-22 00:19:30 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 0.7544
2022-02-22 00:20:03 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 0.9407
2022-02-22 00:20:35 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 0.6771
2022-02-22 00:21:08 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 0.8102
2022-02-22 00:21:42 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 0.9066
2022-02-22 00:22:15 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 0.8304
2022-02-22 00:22:48 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 0.8310
2022-02-22 00:22:51 - train: epoch 078, train_loss: 0.7959
2022-02-22 00:24:07 - eval: epoch: 078, acc1: 77.182%, acc5: 93.844%, test_loss: 0.8895, per_image_load_time: 2.143ms, per_image_inference_time: 0.730ms
2022-02-22 00:24:08 - until epoch: 078, best_acc1: 77.316%
2022-02-22 00:24:08 - epoch 079 lr: 0.0010000000000000002
2022-02-22 00:24:45 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 0.8200
2022-02-22 00:25:16 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 0.7553
2022-02-22 00:25:48 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 0.8348
2022-02-22 00:26:20 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 0.8021
2022-02-22 00:26:52 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 0.8265
2022-02-22 00:27:24 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 0.7579
2022-02-22 00:27:56 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 0.7411
2022-02-22 00:28:29 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 0.8961
2022-02-22 00:29:01 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 0.6782
2022-02-22 00:29:33 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 0.6752
2022-02-22 00:30:05 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 0.8251
2022-02-22 00:30:37 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 1.0442
2022-02-22 00:31:09 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 0.6767
2022-02-22 00:31:41 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 0.7421
2022-02-22 00:32:13 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 0.6564
2022-02-22 00:32:45 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 0.7072
2022-02-22 00:33:17 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 0.6106
2022-02-22 00:33:49 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 0.7210
2022-02-22 00:34:21 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 0.8651
2022-02-22 00:34:53 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 0.8834
2022-02-22 00:35:25 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 0.6966
2022-02-22 00:35:57 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 0.8291
2022-02-22 00:36:29 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 0.7368
2022-02-22 00:37:01 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 0.8885
2022-02-22 00:37:33 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 0.7496
2022-02-22 00:38:04 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 0.8033
2022-02-22 00:38:37 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 0.6922
2022-02-22 00:39:08 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 0.7057
2022-02-22 00:39:40 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 0.6355
2022-02-22 00:40:12 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 0.9120
2022-02-22 00:40:44 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 0.8803
2022-02-22 00:41:16 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 1.0177
2022-02-22 00:41:48 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 0.7613
2022-02-22 00:42:20 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 0.6458
2022-02-22 00:42:52 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 1.0120
2022-02-22 00:43:24 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 0.7239
2022-02-22 00:43:56 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 0.6770
2022-02-22 00:44:28 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 0.8626
2022-02-22 00:45:00 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 0.6865
2022-02-22 00:45:32 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 0.6890
2022-02-22 00:46:05 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 0.9182
2022-02-22 00:46:37 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 0.6941
2022-02-22 00:47:09 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 0.5759
2022-02-22 00:47:41 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 0.9246
2022-02-22 00:48:14 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 0.9521
2022-02-22 00:48:46 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 0.9503
2022-02-22 00:49:19 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 0.8725
2022-02-22 00:49:52 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 0.8675
2022-02-22 00:50:25 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 0.9514
2022-02-22 00:50:58 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 0.6894
2022-02-22 00:51:01 - train: epoch 079, train_loss: 0.7935
2022-02-22 00:52:17 - eval: epoch: 079, acc1: 77.220%, acc5: 93.756%, test_loss: 0.8926, per_image_load_time: 2.148ms, per_image_inference_time: 0.748ms
2022-02-22 00:52:18 - until epoch: 079, best_acc1: 77.316%
2022-02-22 00:52:18 - epoch 080 lr: 0.0010000000000000002
2022-02-22 00:52:55 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 0.6733
2022-02-22 00:53:27 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 0.7327
2022-02-22 00:53:59 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 0.8190
2022-02-22 00:54:31 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 0.6916
2022-02-22 00:55:03 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 0.8745
2022-02-22 00:55:35 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 0.7120
2022-02-22 00:56:07 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 0.7469
2022-02-22 00:56:39 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 0.7131
2022-02-22 00:57:11 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 0.8294
2022-02-22 00:57:43 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 0.7385
2022-02-22 00:58:14 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 0.7285
2022-02-22 00:58:46 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 0.7083
2022-02-22 00:59:18 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 0.7345
2022-02-22 00:59:50 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 0.8443
2022-02-22 01:00:22 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 0.6920
2022-02-22 01:00:54 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 0.7454
2022-02-22 01:01:26 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 0.8476
2022-02-22 01:01:58 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 0.8682
2022-02-22 01:02:30 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 0.7693
2022-02-22 01:03:02 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 0.8911
2022-02-22 01:03:34 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 0.7629
2022-02-22 01:04:06 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 0.8810
2022-02-22 01:04:38 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 0.6090
2022-02-22 01:05:10 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 0.8031
2022-02-22 01:05:42 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 0.7539
2022-02-22 01:06:14 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 0.7858
2022-02-22 01:06:47 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 0.9087
2022-02-22 01:07:19 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 0.8980
2022-02-22 01:07:51 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 0.7397
2022-02-22 01:08:23 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 0.7498
2022-02-22 01:08:55 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 0.9534
2022-02-22 01:09:27 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 0.5959
2022-02-22 01:09:59 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 0.8054
2022-02-22 01:10:32 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 0.7504
2022-02-22 01:11:04 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 0.5983
2022-02-22 01:11:36 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 0.8104
2022-02-22 01:12:08 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 0.7235
2022-02-22 01:12:40 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 0.8067
2022-02-22 01:13:13 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 0.7661
2022-02-22 01:13:45 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 0.8788
2022-02-22 01:14:17 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 0.8514
2022-02-22 01:14:49 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 0.7783
2022-02-22 01:15:21 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 0.8274
2022-02-22 01:15:53 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 0.7637
2022-02-22 01:16:26 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 0.7247
2022-02-22 01:16:58 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 0.8379
2022-02-22 01:17:31 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 0.8101
2022-02-22 01:18:04 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 0.8862
2022-02-22 01:18:37 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 0.8580
2022-02-22 01:19:10 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 0.5747
2022-02-22 01:19:13 - train: epoch 080, train_loss: 0.7898
2022-02-22 01:20:29 - eval: epoch: 080, acc1: 77.266%, acc5: 93.754%, test_loss: 0.8913, per_image_load_time: 2.148ms, per_image_inference_time: 0.704ms
2022-02-22 01:20:30 - until epoch: 080, best_acc1: 77.316%
2022-02-22 01:20:30 - epoch 081 lr: 0.0010000000000000002
2022-02-22 01:21:07 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 0.6672
2022-02-22 01:21:39 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 0.8647
2022-02-22 01:22:11 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 0.6984
2022-02-22 01:22:43 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 0.8737
2022-02-22 01:23:15 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 0.8694
2022-02-22 01:23:47 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 0.7950
2022-02-22 01:24:19 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 0.7621
2022-02-22 01:24:51 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 0.9075
2022-02-22 01:25:23 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 0.6675
2022-02-22 01:25:55 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 0.7298
2022-02-22 01:26:27 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 0.7993
2022-02-22 01:26:59 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 0.7531
2022-02-22 01:27:31 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 0.7015
2022-02-22 01:28:03 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 0.5433
2022-02-22 01:28:36 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 0.8382
2022-02-22 01:29:08 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 0.6849
2022-02-22 01:29:40 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 0.8558
2022-02-22 01:30:12 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 0.6865
2022-02-22 01:30:44 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 0.7638
2022-02-22 01:31:16 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 0.8290
2022-02-22 01:31:48 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 0.7875
2022-02-22 01:32:20 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 0.8301
2022-02-22 01:32:52 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 0.6858
2022-02-22 01:33:24 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 0.7672
2022-02-22 01:33:56 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 0.9225
2022-02-22 01:34:29 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 0.8248
2022-02-22 01:35:01 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 0.7650
2022-02-22 01:35:33 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 0.6897
2022-02-22 01:36:06 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 0.7426
2022-02-22 01:36:38 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 0.7461
2022-02-22 01:37:10 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 0.6902
2022-02-22 01:37:42 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 0.7419
2022-02-22 01:38:15 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 0.8706
2022-02-22 01:38:47 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 0.8430
2022-02-22 01:39:19 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 0.9098
2022-02-22 01:39:52 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 0.6609
2022-02-22 01:40:24 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 0.8917
2022-02-22 01:40:56 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 0.6732
2022-02-22 01:41:29 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 0.7917
2022-02-22 01:42:01 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 0.6019
2022-02-22 01:42:34 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 0.8710
2022-02-22 01:43:06 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 0.7616
2022-02-22 01:43:38 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 0.7807
2022-02-22 01:44:11 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 0.9458
2022-02-22 01:44:43 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 0.7674
2022-02-22 01:45:16 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 0.7418
2022-02-22 01:45:49 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 0.8632
2022-02-22 01:46:22 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 0.8438
2022-02-22 01:46:55 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 0.7222
2022-02-22 01:47:29 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 0.5932
2022-02-22 01:47:31 - train: epoch 081, train_loss: 0.7858
2022-02-22 01:48:46 - eval: epoch: 081, acc1: 77.344%, acc5: 93.800%, test_loss: 0.8887, per_image_load_time: 2.110ms, per_image_inference_time: 0.689ms
2022-02-22 01:48:48 - until epoch: 081, best_acc1: 77.344%
2022-02-22 01:48:48 - epoch 082 lr: 0.0010000000000000002
2022-02-22 01:49:25 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 0.6036
2022-02-22 01:49:56 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 0.7111
2022-02-22 01:50:28 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 0.8324
2022-02-22 01:51:01 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 0.8549
2022-02-22 01:51:33 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 0.8131
2022-02-22 01:52:05 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 0.7022
2022-02-22 01:52:37 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 0.8870
2022-02-22 01:53:09 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 0.7848
2022-02-22 01:53:42 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 0.8158
2022-02-22 01:54:14 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 0.8510
2022-02-22 01:54:46 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 0.9321
2022-02-22 01:55:18 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 0.7758
2022-02-22 01:55:51 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 0.8908
2022-02-22 01:56:23 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 0.7578
2022-02-22 01:56:55 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 0.7451
2022-02-22 01:57:28 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 0.7655
2022-02-22 01:58:00 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 0.7062
2022-02-22 01:58:32 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 0.6740
2022-02-22 01:59:05 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 0.8240
2022-02-22 01:59:37 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 0.6841
2022-02-22 02:00:09 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 0.7488
2022-02-22 02:00:41 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 0.8605
2022-02-22 02:01:14 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 0.8008
2022-02-22 02:01:46 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 0.8975
2022-02-22 02:02:18 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 0.6937
2022-02-22 02:02:51 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 0.7731
2022-02-22 02:03:23 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 0.7147
2022-02-22 02:03:55 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 0.7470
2022-02-22 02:04:28 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 0.7615
2022-02-22 02:05:00 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 0.7559
2022-02-22 02:05:32 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 0.6869
2022-02-22 02:06:04 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 0.8666
2022-02-22 02:06:37 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 0.7114
2022-02-22 02:07:09 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 0.7254
2022-02-22 02:07:41 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 0.7150
2022-02-22 02:08:13 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 0.6373
2022-02-22 02:08:46 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 0.7629
2022-02-22 02:09:18 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 1.0147
2022-02-22 02:09:50 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 0.8011
2022-02-22 02:10:23 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 0.8802
2022-02-22 02:10:55 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 0.6940
2022-02-22 02:11:27 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 0.8640
2022-02-22 02:12:00 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 0.6237
2022-02-22 02:12:32 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 0.7430
2022-02-22 02:13:05 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 0.8094
2022-02-22 02:13:38 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 0.8843
2022-02-22 02:14:10 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 0.7050
2022-02-22 02:14:43 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 0.7435
2022-02-22 02:15:17 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 0.7167
2022-02-22 02:15:50 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 0.7908
2022-02-22 02:15:53 - train: epoch 082, train_loss: 0.7814
2022-02-22 02:17:08 - eval: epoch: 082, acc1: 77.190%, acc5: 93.758%, test_loss: 0.8911, per_image_load_time: 2.116ms, per_image_inference_time: 0.729ms
2022-02-22 02:17:09 - until epoch: 082, best_acc1: 77.344%
2022-02-22 02:17:09 - epoch 083 lr: 0.0010000000000000002
2022-02-22 02:17:47 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 0.6667
2022-02-22 02:18:18 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 0.6949
2022-02-22 02:18:51 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 0.7870
2022-02-22 02:19:23 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 0.9161
2022-02-22 02:19:55 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 0.6760
2022-02-22 02:20:27 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 0.7421
2022-02-22 02:20:59 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 0.6997
2022-02-22 02:21:31 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 0.7965
2022-02-22 02:22:03 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 0.8147
2022-02-22 02:22:35 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 0.8585
2022-02-22 02:23:08 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 0.7781
2022-02-22 02:23:40 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 0.7048
2022-02-22 02:24:12 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 0.6847
2022-02-22 02:24:44 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 0.8643
2022-02-22 02:25:17 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 0.6923
2022-02-22 02:25:49 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 0.7973
2022-02-22 02:26:21 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 0.8990
2022-02-22 02:26:54 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 0.9149
2022-02-22 02:27:26 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 0.6154
2022-02-22 02:27:58 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 0.5352
2022-02-22 02:28:30 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 0.6630
2022-02-22 02:29:03 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 0.7337
2022-02-22 02:29:35 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 0.7737
2022-02-22 02:30:07 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 0.8255
2022-02-22 02:30:39 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 0.8502
2022-02-22 02:31:12 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 0.6819
2022-02-22 02:31:44 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 0.8265
2022-02-22 02:32:16 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 0.7225
2022-02-22 02:32:48 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 0.7171
2022-02-22 02:33:20 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 0.8332
2022-02-22 02:33:52 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 0.7155
2022-02-22 02:34:25 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 0.6764
2022-02-22 02:34:57 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 1.0308
2022-02-22 02:35:29 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 0.8755
2022-02-22 02:36:01 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 0.8184
2022-02-22 02:36:34 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 0.8804
2022-02-22 02:37:06 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 0.7751
2022-02-22 02:37:38 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 0.6814
2022-02-22 02:38:10 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 0.7387
2022-02-22 02:38:43 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 0.9504
2022-02-22 02:39:15 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 0.7619
2022-02-22 02:39:47 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 0.8711
2022-02-22 02:40:19 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 0.7424
2022-02-22 02:40:52 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 0.5823
2022-02-22 02:41:24 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 0.8401
2022-02-22 02:41:57 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 0.9887
2022-02-22 02:42:30 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 0.9059
2022-02-22 02:43:02 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 0.8807
2022-02-22 02:43:36 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 0.9552
2022-02-22 02:44:09 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 0.8745
2022-02-22 02:44:12 - train: epoch 083, train_loss: 0.7775
2022-02-22 02:45:28 - eval: epoch: 083, acc1: 77.244%, acc5: 93.806%, test_loss: 0.8927, per_image_load_time: 2.120ms, per_image_inference_time: 0.726ms
2022-02-22 02:45:29 - until epoch: 083, best_acc1: 77.344%
2022-02-22 02:45:29 - epoch 084 lr: 0.0010000000000000002
2022-02-22 02:46:06 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 0.7337
2022-02-22 02:46:37 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 0.8687
2022-02-22 02:47:09 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 0.5999
2022-02-22 02:47:40 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 0.7376
2022-02-22 02:48:12 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 0.8148
2022-02-22 02:48:44 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 0.8802
2022-02-22 02:49:16 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 0.7599
2022-02-22 02:49:48 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 0.8282
2022-02-22 02:50:21 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 0.7814
2022-02-22 02:50:53 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 0.8095
2022-02-22 02:51:25 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 0.7664
2022-02-22 02:51:57 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 0.9760
2022-02-22 02:52:29 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 0.6945
2022-02-22 02:53:01 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 0.8754
2022-02-22 02:53:33 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 0.8068
2022-02-22 02:54:06 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 0.6875
2022-02-22 02:54:38 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 0.8398
2022-02-22 02:55:10 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 0.8455
2022-02-22 02:55:42 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 0.8086
2022-02-22 02:56:14 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 0.8387
2022-02-22 02:56:46 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 0.6912
2022-02-22 02:57:18 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 0.6275
2022-02-22 02:57:50 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 0.6771
2022-02-22 02:58:22 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 0.7081
2022-02-22 02:58:54 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 0.8537
2022-02-22 02:59:27 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 0.8707
2022-02-22 02:59:59 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 0.7633
2022-02-22 03:00:31 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 0.8672
2022-02-22 03:01:03 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 0.7319
2022-02-22 03:01:35 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 0.7787
2022-02-22 03:02:07 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 0.5826
2022-02-22 03:02:40 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 0.6010
2022-02-22 03:03:12 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 0.7635
2022-02-22 03:03:44 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 0.7081
2022-02-22 03:04:16 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 0.5899
2022-02-22 03:04:48 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 0.7260
2022-02-22 03:05:20 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 0.7880
2022-02-22 03:05:52 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 0.9395
2022-02-22 03:06:25 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 0.8651
2022-02-22 03:06:57 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 0.8289
2022-02-22 03:07:29 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 0.8657
2022-02-22 03:08:01 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 0.7959
2022-02-22 03:08:34 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 0.7327
2022-02-22 03:09:06 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 0.8979
2022-02-22 03:09:38 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 0.7719
2022-02-22 03:10:11 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 0.7446
2022-02-22 03:10:44 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 0.9931
2022-02-22 03:11:16 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 0.6895
2022-02-22 03:11:50 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 0.6481
2022-02-22 03:12:23 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 0.8898
2022-02-22 03:12:26 - train: epoch 084, train_loss: 0.7726
2022-02-22 03:13:42 - eval: epoch: 084, acc1: 77.216%, acc5: 93.708%, test_loss: 0.8960, per_image_load_time: 2.137ms, per_image_inference_time: 0.722ms
2022-02-22 03:13:43 - until epoch: 084, best_acc1: 77.344%
2022-02-22 03:13:43 - epoch 085 lr: 0.0010000000000000002
2022-02-22 03:14:20 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 0.6440
2022-02-22 03:14:51 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 0.5999
2022-02-22 03:15:23 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 0.8463
2022-02-22 03:15:55 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 0.6483
2022-02-22 03:16:27 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 0.9135
2022-02-22 03:16:59 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 0.6057
2022-02-22 03:17:31 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 0.6713
2022-02-22 03:18:03 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 0.7391
2022-02-22 03:18:35 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 0.7385
2022-02-22 03:19:06 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 0.8728
2022-02-22 03:19:39 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 0.6852
2022-02-22 03:20:11 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 0.6710
2022-02-22 03:20:43 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 0.7994
2022-02-22 03:21:15 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 0.8554
2022-02-22 03:21:48 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 0.5971
2022-02-22 03:22:20 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 0.8337
2022-02-22 03:22:52 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 0.8826
2022-02-22 03:23:24 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 0.6814
2022-02-22 03:23:56 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 0.6738
2022-02-22 03:24:28 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 0.7656
2022-02-22 03:25:01 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 0.6006
2022-02-22 03:25:33 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 0.8076
2022-02-22 03:26:05 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 0.6061
2022-02-22 03:26:37 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 0.8129
2022-02-22 03:27:09 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 0.9436
2022-02-22 03:27:41 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 0.8239
2022-02-22 03:28:13 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 0.7626
2022-02-22 03:28:46 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 0.8214
2022-02-22 03:29:18 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 0.9149
2022-02-22 03:29:50 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 0.8522
2022-02-22 03:30:22 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 0.7241
2022-02-22 03:30:54 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 0.7200
2022-02-22 03:31:27 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 0.8008
2022-02-22 03:31:59 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 0.8801
2022-02-22 03:32:31 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 0.7602
2022-02-22 03:33:03 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 0.8223
2022-02-22 03:33:35 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 0.6922
2022-02-22 03:34:08 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 0.6986
2022-02-22 03:34:40 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 0.7217
2022-02-22 03:35:12 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 0.9441
2022-02-22 03:35:44 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 0.7315
2022-02-22 03:36:17 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 0.9501
2022-02-22 03:36:49 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 0.7884
2022-02-22 03:37:21 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 0.7895
2022-02-22 03:37:54 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 0.8963
2022-02-22 03:38:27 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 0.8276
2022-02-22 03:38:59 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 0.9141
2022-02-22 03:39:32 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 0.6964
2022-02-22 03:40:06 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 0.7418
2022-02-22 03:40:39 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 0.7459
2022-02-22 03:40:42 - train: epoch 085, train_loss: 0.7720
2022-02-22 03:41:57 - eval: epoch: 085, acc1: 77.236%, acc5: 93.654%, test_loss: 0.8994, per_image_load_time: 1.523ms, per_image_inference_time: 0.742ms
2022-02-22 03:41:58 - until epoch: 085, best_acc1: 77.344%
2022-02-22 03:41:58 - epoch 086 lr: 0.0010000000000000002
2022-02-22 03:42:36 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 0.6875
2022-02-22 03:43:08 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 0.6617
2022-02-22 03:43:40 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 0.8156
2022-02-22 03:44:11 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 0.8490
2022-02-22 03:44:44 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 0.7729
2022-02-22 03:45:16 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 0.6997
2022-02-22 03:45:48 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 0.7036
2022-02-22 03:46:20 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 0.8398
2022-02-22 03:46:52 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 0.8462
2022-02-22 03:47:25 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 0.7261
2022-02-22 03:47:57 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 0.8338
2022-02-22 03:48:29 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 0.6938
2022-02-22 03:49:02 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 0.8360
2022-02-22 03:49:34 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 0.6612
2022-02-22 03:50:06 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 0.6248
2022-02-22 03:50:38 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 0.8047
2022-02-22 03:51:10 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 0.7318
2022-02-22 03:51:43 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 0.7154
2022-02-22 03:52:15 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 0.8598
2022-02-22 03:52:47 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 0.7390
2022-02-22 03:53:19 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 0.7023
2022-02-22 03:53:51 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 0.7953
2022-02-22 03:54:24 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 0.7393
2022-02-22 03:54:56 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 0.6665
2022-02-22 03:55:28 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 0.7289
2022-02-22 03:56:00 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 0.7710
2022-02-22 03:56:32 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 0.6552
2022-02-22 03:57:05 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 0.8656
2022-02-22 03:57:37 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 0.6230
2022-02-22 03:58:09 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 0.8481
2022-02-22 03:58:41 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 0.8028
2022-02-22 03:59:13 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 0.8672
2022-02-22 03:59:45 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 0.8315
2022-02-22 04:00:17 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 0.8727
2022-02-22 04:00:50 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 0.7512
2022-02-22 04:01:22 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 0.7982
2022-02-22 04:01:54 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 0.8321
2022-02-22 04:02:26 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 0.8339
2022-02-22 04:02:58 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 0.7920
2022-02-22 04:03:30 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 0.7742
2022-02-22 04:04:02 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 0.7448
2022-02-22 04:04:35 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 0.8120
2022-02-22 04:05:07 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 0.7875
2022-02-22 04:05:40 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 0.7898
2022-02-22 04:06:12 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 0.6826
2022-02-22 04:06:45 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 0.7385
2022-02-22 04:07:17 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 0.7255
2022-02-22 04:07:50 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 0.7728
2022-02-22 04:08:24 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 0.7847
2022-02-22 04:08:57 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 0.8093
2022-02-22 04:09:00 - train: epoch 086, train_loss: 0.7667
2022-02-22 04:10:16 - eval: epoch: 086, acc1: 77.192%, acc5: 93.624%, test_loss: 0.9016, per_image_load_time: 2.141ms, per_image_inference_time: 0.710ms
2022-02-22 04:10:17 - until epoch: 086, best_acc1: 77.344%
2022-02-22 04:10:17 - epoch 087 lr: 0.0010000000000000002
2022-02-22 04:10:54 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 0.8622
2022-02-22 04:11:25 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 0.6155
2022-02-22 04:11:56 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 0.8403
2022-02-22 04:12:28 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 0.8244
2022-02-22 04:12:59 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 0.5890
2022-02-22 04:13:31 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 0.7454
2022-02-22 04:14:03 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 0.5568
2022-02-22 04:14:36 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 0.8783
2022-02-22 04:15:08 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 0.8772
2022-02-22 04:15:40 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 0.6826
2022-02-22 04:16:12 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 0.8206
2022-02-22 04:16:44 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 0.7724
2022-02-22 04:17:16 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 0.7698
2022-02-22 04:17:48 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 0.7737
2022-02-22 04:18:20 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 0.7194
2022-02-22 04:18:52 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 0.6247
2022-02-22 04:19:25 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 0.9344
2022-02-22 04:19:57 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 0.7581
2022-02-22 04:20:29 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 0.7831
2022-02-22 04:21:01 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 0.7463
2022-02-22 04:21:33 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 0.8657
2022-02-22 04:22:05 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 0.7301
2022-02-22 04:22:37 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 0.7725
2022-02-22 04:23:09 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 0.8173
2022-02-22 04:23:41 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 0.7235
2022-02-22 04:24:13 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 0.8109
2022-02-22 04:24:45 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 0.6994
2022-02-22 04:25:17 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 0.5591
2022-02-22 04:25:50 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 0.6405
2022-02-22 04:26:22 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 0.8096
2022-02-22 04:26:54 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 0.7942
2022-02-22 04:27:26 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 0.7083
2022-02-22 04:27:58 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 0.7339
2022-02-22 04:28:30 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 0.8334
2022-02-22 04:29:02 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 0.6395
2022-02-22 04:29:34 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 0.6664
2022-02-22 04:30:06 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 0.7470
2022-02-22 04:30:38 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 0.7348
2022-02-22 04:31:10 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 0.7242
2022-02-22 04:31:42 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 0.8369
2022-02-22 04:32:14 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 0.8423
2022-02-22 04:32:47 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 0.8062
2022-02-22 04:33:19 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 0.8616
2022-02-22 04:33:51 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 0.8179
2022-02-22 04:34:23 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 0.8435
2022-02-22 04:34:56 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 0.7403
2022-02-22 04:35:28 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 0.7556
2022-02-22 04:36:01 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 0.7447
2022-02-22 04:36:34 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 0.7299
2022-02-22 04:37:07 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 0.7342
2022-02-22 04:37:11 - train: epoch 087, train_loss: 0.7621
2022-02-22 04:38:26 - eval: epoch: 087, acc1: 77.060%, acc5: 93.742%, test_loss: 0.8998, per_image_load_time: 2.112ms, per_image_inference_time: 0.716ms
2022-02-22 04:38:28 - until epoch: 087, best_acc1: 77.344%
2022-02-22 04:38:28 - epoch 088 lr: 0.0010000000000000002
2022-02-22 04:39:04 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 0.7795
2022-02-22 04:39:36 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 0.6631
2022-02-22 04:40:07 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 0.8433
2022-02-22 04:40:39 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 0.7660
2022-02-22 04:41:11 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 0.6517
2022-02-22 04:41:43 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 0.6999
2022-02-22 04:42:15 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 0.6994
2022-02-22 04:42:47 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 0.7523
2022-02-22 04:43:19 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 0.7670
2022-02-22 04:43:51 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 0.7422
2022-02-22 04:44:23 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 0.8069
2022-02-22 04:44:55 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 0.7301
2022-02-22 04:45:27 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 0.7761
2022-02-22 04:45:59 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 0.7343
2022-02-22 04:46:31 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 0.8298
2022-02-22 04:47:03 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 0.6003
2022-02-22 04:47:35 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 0.7992
2022-02-22 04:48:07 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 0.7647
2022-02-22 04:48:39 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 0.7438
2022-02-22 04:49:11 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 0.6489
2022-02-22 04:49:43 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 0.7635
2022-02-22 04:50:16 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 0.6296
2022-02-22 04:50:48 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 0.5601
2022-02-22 04:51:20 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 0.7152
2022-02-22 04:51:52 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 0.7749
2022-02-22 04:52:24 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 0.7692
2022-02-22 04:52:56 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 0.7883
2022-02-22 04:53:28 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 0.7124
2022-02-22 04:54:00 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 0.6644
2022-02-22 04:54:33 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 0.8491
2022-02-22 04:55:05 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 0.7563
2022-02-22 04:55:37 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 0.6200
2022-02-22 04:56:10 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 0.7583
2022-02-22 04:56:42 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 0.6387
2022-02-22 04:57:14 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 0.7319
2022-02-22 04:57:46 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 0.8054
2022-02-22 04:58:19 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 0.8784
2022-02-22 04:58:51 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 0.7439
2022-02-22 04:59:23 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 0.8570
2022-02-22 04:59:55 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 0.6949
2022-02-22 05:00:28 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 0.7103
2022-02-22 05:01:00 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 0.9033
2022-02-22 05:01:32 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 0.6579
2022-02-22 05:02:05 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 0.6808
2022-02-22 05:02:37 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 0.7442
2022-02-22 05:03:09 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 0.7986
2022-02-22 05:03:42 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 0.7416
2022-02-22 05:04:15 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 0.5982
2022-02-22 05:04:48 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 0.6020
2022-02-22 05:05:21 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 0.8472
2022-02-22 05:05:25 - train: epoch 088, train_loss: 0.7592
2022-02-22 05:06:40 - eval: epoch: 088, acc1: 77.048%, acc5: 93.614%, test_loss: 0.9047, per_image_load_time: 2.150ms, per_image_inference_time: 0.732ms
2022-02-22 05:06:41 - until epoch: 088, best_acc1: 77.344%
2022-02-22 05:06:41 - epoch 089 lr: 0.0010000000000000002
2022-02-22 05:07:19 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 0.8289
2022-02-22 05:07:51 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 0.6574
2022-02-22 05:08:22 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 0.7624
2022-02-22 05:08:54 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 0.6844
2022-02-22 05:09:26 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 0.8052
2022-02-22 05:09:58 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 0.7368
2022-02-22 05:10:30 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 0.8081
2022-02-22 05:11:02 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 0.8349
2022-02-22 05:11:34 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 0.7764
2022-02-22 05:12:06 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 0.8959
2022-02-22 05:12:39 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 0.7117
2022-02-22 05:13:11 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 0.8124
2022-02-22 05:13:43 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 0.7426
2022-02-22 05:14:15 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 0.8299
2022-02-22 05:14:47 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 0.7186
2022-02-22 05:15:19 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 0.7822
2022-02-22 05:15:52 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 0.8220
2022-02-22 05:16:24 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 0.7229
2022-02-22 05:16:56 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 0.7131
2022-02-22 05:17:28 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 0.6609
2022-02-22 05:18:00 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 0.8668
2022-02-22 05:18:32 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 0.7925
2022-02-22 05:19:05 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 0.6624
2022-02-22 05:19:37 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 0.7623
2022-02-22 05:20:09 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 0.6891
2022-02-22 05:20:41 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 0.7703
2022-02-22 05:21:13 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 0.6594
2022-02-22 05:21:46 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 0.7979
2022-02-22 05:22:18 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 0.7795
2022-02-22 05:22:50 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 0.7567
2022-02-22 05:23:22 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 0.7598
2022-02-22 05:23:54 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 0.8194
2022-02-22 05:24:27 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 0.8372
2022-02-22 05:24:59 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 0.7738
2022-02-22 05:25:32 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 0.6206
2022-02-22 05:26:04 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 0.6691
2022-02-22 05:26:36 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 0.9360
2022-02-22 05:27:08 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 0.6501
2022-02-22 05:27:41 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 0.8251
2022-02-22 05:28:13 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 0.6808
2022-02-22 05:28:45 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 0.9008
2022-02-22 05:29:18 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 0.7201
2022-02-22 05:29:50 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 0.8100
2022-02-22 05:30:23 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 0.6833
2022-02-22 05:30:56 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 0.6545
2022-02-22 05:31:28 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 0.7992
2022-02-22 05:32:01 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 0.8102
2022-02-22 05:32:34 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 0.7975
2022-02-22 05:33:08 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 0.7670
2022-02-22 05:33:41 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 0.5336
2022-02-22 05:33:45 - train: epoch 089, train_loss: 0.7579
2022-02-22 05:35:00 - eval: epoch: 089, acc1: 77.322%, acc5: 93.692%, test_loss: 0.8985, per_image_load_time: 2.108ms, per_image_inference_time: 0.726ms
2022-02-22 05:35:01 - until epoch: 089, best_acc1: 77.344%
2022-02-22 05:35:01 - epoch 090 lr: 0.0010000000000000002
2022-02-22 05:35:38 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 0.7324
2022-02-22 05:36:10 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 0.7962
2022-02-22 05:36:41 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 0.7542
2022-02-22 05:37:13 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 0.7130
2022-02-22 05:37:45 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 0.8097
2022-02-22 05:38:17 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 0.8435
2022-02-22 05:38:49 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 0.8010
2022-02-22 05:39:21 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 0.6446
2022-02-22 05:39:53 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 0.7206
2022-02-22 05:40:25 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 0.6904
2022-02-22 05:40:57 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 0.7813
2022-02-22 05:41:28 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 0.7636
2022-02-22 05:42:00 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 0.9754
2022-02-22 05:42:32 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 0.6186
2022-02-22 05:43:05 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 0.9317
2022-02-22 05:43:36 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 0.6702
2022-02-22 05:44:08 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 0.6274
2022-02-22 05:44:40 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 0.5905
2022-02-22 05:45:13 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 0.6272
2022-02-22 05:45:45 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 0.8452
2022-02-22 05:46:17 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 0.8993
2022-02-22 05:46:49 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 0.7645
2022-02-22 05:47:21 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 0.9061
2022-02-22 05:47:53 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 0.8108
2022-02-22 05:48:25 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 0.8139
2022-02-22 05:48:57 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 0.8105
2022-02-22 05:49:29 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 0.6780
2022-02-22 05:50:01 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 0.7419
2022-02-22 05:50:33 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 0.7158
2022-02-22 05:51:05 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 0.7620
2022-02-22 05:51:37 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 0.6884
2022-02-22 05:52:09 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 0.6618
2022-02-22 05:52:41 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 0.8494
2022-02-22 05:53:13 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 0.5891
2022-02-22 05:53:45 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 0.7458
2022-02-22 05:54:17 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 0.7399
2022-02-22 05:54:49 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 0.7406
2022-02-22 05:55:21 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 0.7930
2022-02-22 05:55:53 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 0.5857
2022-02-22 05:56:25 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 0.8108
2022-02-22 05:56:57 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 0.9159
2022-02-22 05:57:30 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 0.7025
2022-02-22 05:58:02 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 0.7934
2022-02-22 05:58:34 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 0.7356
2022-02-22 05:59:07 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 0.6739
2022-02-22 05:59:39 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 0.7172
2022-02-22 06:00:12 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 0.7535
2022-02-22 06:00:45 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 0.7342
2022-02-22 06:01:18 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 0.6235
2022-02-22 06:01:52 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 0.7327
2022-02-22 06:01:55 - train: epoch 090, train_loss: 0.7540
2022-02-22 06:03:10 - eval: epoch: 090, acc1: 77.178%, acc5: 93.786%, test_loss: 0.9052, per_image_load_time: 2.054ms, per_image_inference_time: 0.732ms
2022-02-22 06:03:11 - until epoch: 090, best_acc1: 77.344%
2022-02-22 06:03:11 - epoch 091 lr: 0.00010000000000000003
2022-02-22 06:03:48 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 0.6949
2022-02-22 06:04:20 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 0.7292
2022-02-22 06:04:52 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 0.6029
2022-02-22 06:05:23 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 0.5815
2022-02-22 06:05:55 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 0.6730
2022-02-22 06:06:27 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 0.7535
2022-02-22 06:06:59 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 0.6411
2022-02-22 06:07:31 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 0.6407
2022-02-22 06:08:03 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 0.7829
2022-02-22 06:08:35 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 0.7054
2022-02-22 06:09:07 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 0.5879
2022-02-22 06:09:39 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 0.8284
2022-02-22 06:10:12 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 0.7048
2022-02-22 06:10:44 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 0.7460
2022-02-22 06:11:16 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 0.6771
2022-02-22 06:11:48 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 0.6664
2022-02-22 06:12:20 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 0.7403
2022-02-22 06:12:53 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 0.6795
2022-02-22 06:13:25 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 0.5662
2022-02-22 06:13:57 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 0.7403
2022-02-22 06:14:29 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 0.6012
2022-02-22 06:15:01 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 0.7679
2022-02-22 06:15:33 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 0.7251
2022-02-22 06:16:06 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 0.6674
2022-02-22 06:16:38 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 0.6952
2022-02-22 06:17:10 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 0.7126
2022-02-22 06:17:43 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 0.6090
2022-02-22 06:18:15 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 0.7838
2022-02-22 06:18:47 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 0.8603
2022-02-22 06:19:19 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 0.8208
2022-02-22 06:19:51 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 0.6727
2022-02-22 06:20:23 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 0.7770
2022-02-22 06:20:56 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 0.6670
2022-02-22 06:21:28 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 0.6187
2022-02-22 06:22:00 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 0.7617
2022-02-22 06:22:32 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 0.6685
2022-02-22 06:23:04 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 0.7247
2022-02-22 06:23:36 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 0.7959
2022-02-22 06:24:09 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 0.6903
2022-02-22 06:24:41 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 0.7909
2022-02-22 06:25:13 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 0.7806
2022-02-22 06:25:45 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 0.7423
2022-02-22 06:26:17 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 0.7245
2022-02-22 06:26:50 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 0.6195
2022-02-22 06:27:22 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 0.5966
2022-02-22 06:27:54 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 0.6958
2022-02-22 06:28:27 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 0.7249
2022-02-22 06:29:00 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 0.7231
2022-02-22 06:29:33 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 0.7283
2022-02-22 06:30:07 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 0.8640
2022-02-22 06:30:10 - train: epoch 091, train_loss: 0.7212
2022-02-22 06:31:25 - eval: epoch: 091, acc1: 77.568%, acc5: 93.904%, test_loss: 0.8858, per_image_load_time: 1.774ms, per_image_inference_time: 0.723ms
2022-02-22 06:31:27 - until epoch: 091, best_acc1: 77.568%
2022-02-22 06:31:27 - epoch 092 lr: 0.00010000000000000003
2022-02-22 06:32:04 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 0.7146
2022-02-22 06:32:36 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 0.8062
2022-02-22 06:33:08 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 0.6331
2022-02-22 06:33:39 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 0.5426
2022-02-22 06:34:11 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 0.7436
2022-02-22 06:34:43 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 0.7422
2022-02-22 06:35:15 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 0.7198
2022-02-22 06:35:47 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 0.7511
2022-02-22 06:36:19 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 0.7172
2022-02-22 06:36:51 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 0.8544
2022-02-22 06:37:23 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 0.5682
2022-02-22 06:37:54 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 0.6804
2022-02-22 06:38:26 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 0.6480
2022-02-22 06:38:58 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 0.7250
2022-02-22 06:39:30 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 0.5764
2022-02-22 06:40:03 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 0.7342
2022-02-22 06:40:35 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 0.7414
2022-02-22 06:41:07 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 0.6673
2022-02-22 06:41:39 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 0.6524
2022-02-22 06:42:11 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 0.6581
2022-02-22 06:42:43 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 0.6687
2022-02-22 06:43:15 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 0.7221
2022-02-22 06:43:47 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 0.6020
2022-02-22 06:44:18 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 0.6869
2022-02-22 06:44:51 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 0.6536
2022-02-22 06:45:23 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 0.8065
2022-02-22 06:45:55 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 0.7105
2022-02-22 06:46:27 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 0.5765
2022-02-22 06:46:59 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 0.7184
2022-02-22 06:47:31 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 0.5991
2022-02-22 06:48:03 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 0.6970
2022-02-22 06:48:35 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 0.5534
2022-02-22 06:49:07 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 0.7683
2022-02-22 06:49:40 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 0.8589
2022-02-22 06:50:12 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 0.6185
2022-02-22 06:50:44 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 0.6922
2022-02-22 06:51:16 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 0.6040
2022-02-22 06:51:48 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 0.8799
2022-02-22 06:52:20 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 0.7005
2022-02-22 06:52:52 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 0.7588
2022-02-22 06:53:24 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 0.6265
2022-02-22 06:53:57 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 0.7002
2022-02-22 06:54:29 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 0.7708
2022-02-22 06:55:01 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 0.5369
2022-02-22 06:55:34 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 0.6550
2022-02-22 06:56:06 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 0.6337
2022-02-22 06:56:39 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 0.4873
2022-02-22 06:57:11 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 0.5845
2022-02-22 06:57:45 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 0.8010
2022-02-22 06:58:18 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 0.8076
2022-02-22 06:58:21 - train: epoch 092, train_loss: 0.7096
2022-02-22 06:59:35 - eval: epoch: 092, acc1: 77.514%, acc5: 93.898%, test_loss: 0.8855, per_image_load_time: 1.357ms, per_image_inference_time: 0.746ms
2022-02-22 06:59:36 - until epoch: 092, best_acc1: 77.568%
2022-02-22 06:59:36 - epoch 093 lr: 0.00010000000000000003
2022-02-22 07:00:14 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 0.5983
2022-02-22 07:00:46 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 0.6527
2022-02-22 07:01:17 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 0.6847
2022-02-22 07:01:49 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 0.6777
2022-02-22 07:02:20 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 0.7159
2022-02-22 07:02:52 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 0.6797
2022-02-22 07:03:24 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 0.6858
2022-02-22 07:03:56 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 0.5775
2022-02-22 07:04:28 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 0.7027
2022-02-22 07:04:59 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.6400
2022-02-22 07:05:32 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 0.5539
2022-02-22 07:06:04 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 0.5652
2022-02-22 07:06:36 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 0.7200
2022-02-22 07:07:08 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 0.7189
2022-02-22 07:07:40 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 0.8561
2022-02-22 07:08:12 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 0.7792
2022-02-22 07:08:44 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 0.6409
2022-02-22 07:09:16 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 0.7375
2022-02-22 07:09:48 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 0.6210
2022-02-22 07:10:20 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 0.6304
2022-02-22 07:10:52 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 0.6651
2022-02-22 07:11:24 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 0.7681
2022-02-22 07:11:56 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 0.7961
2022-02-22 07:12:28 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 0.5711
2022-02-22 07:13:00 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 0.7433
2022-02-22 07:13:32 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 0.7704
2022-02-22 07:14:05 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 0.6631
2022-02-22 07:14:37 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 0.6285
2022-02-22 07:15:09 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 0.7614
2022-02-22 07:15:41 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 0.7021
2022-02-22 07:16:13 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 0.8605
2022-02-22 07:16:45 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 0.5526
2022-02-22 07:17:17 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 0.8240
2022-02-22 07:17:49 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 0.9985
2022-02-22 07:18:21 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 0.5756
2022-02-22 07:18:53 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 0.8572
2022-02-22 07:19:25 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 0.6751
2022-02-22 07:19:57 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 0.5424
2022-02-22 07:20:29 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 0.8883
2022-02-22 07:21:01 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 0.8508
2022-02-22 07:21:33 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 0.6851
2022-02-22 07:22:05 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 0.7461
2022-02-22 07:22:37 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 0.8752
2022-02-22 07:23:09 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 0.6453
2022-02-22 07:23:41 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 0.7047
2022-02-22 07:24:14 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 0.5211
2022-02-22 07:24:46 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 0.8438
2022-02-22 07:25:19 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 0.6971
2022-02-22 07:25:52 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 0.8084
2022-02-22 07:26:25 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 0.7158
2022-02-22 07:26:29 - train: epoch 093, train_loss: 0.7054
2022-02-22 07:27:44 - eval: epoch: 093, acc1: 77.616%, acc5: 93.940%, test_loss: 0.8836, per_image_load_time: 1.070ms, per_image_inference_time: 0.737ms
2022-02-22 07:27:45 - until epoch: 093, best_acc1: 77.616%
2022-02-22 07:27:45 - epoch 094 lr: 0.00010000000000000003
2022-02-22 07:28:23 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 0.7007
2022-02-22 07:28:55 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 0.7010
2022-02-22 07:29:27 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 0.7727
2022-02-22 07:29:59 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 0.8809
2022-02-22 07:30:31 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 0.7049
2022-02-22 07:31:03 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 0.6092
2022-02-22 07:31:35 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 0.7224
2022-02-22 07:32:07 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 0.6226
2022-02-22 07:32:39 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 0.6547
2022-02-22 07:33:11 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 0.7143
2022-02-22 07:33:43 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 0.7294
2022-02-22 07:34:15 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 0.7246
2022-02-22 07:34:47 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 0.7224
2022-02-22 07:35:18 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 0.7184
2022-02-22 07:35:50 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 0.7995
2022-02-22 07:36:22 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 1.0902
2022-02-22 07:36:54 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 0.6762
2022-02-22 07:37:25 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 0.6783
2022-02-22 07:37:57 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 0.7464
2022-02-22 07:38:29 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 0.5739
2022-02-22 07:39:01 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 0.7120
2022-02-22 07:39:33 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 0.5912
2022-02-22 07:40:05 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 0.5103
2022-02-22 07:40:37 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 0.7229
2022-02-22 07:41:09 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 0.6242
2022-02-22 07:41:41 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 0.5524
2022-02-22 07:42:14 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 0.6685
2022-02-22 07:42:46 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 0.6886
2022-02-22 07:43:18 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 0.7337
2022-02-22 07:43:50 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 0.6007
2022-02-22 07:44:22 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 0.8517
2022-02-22 07:44:55 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 0.7243
2022-02-22 07:45:27 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 0.7023
2022-02-22 07:45:59 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 0.8728
2022-02-22 07:46:31 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 0.8091
2022-02-22 07:47:04 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 0.7511
2022-02-22 07:47:36 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 0.7906
2022-02-22 07:48:08 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 0.6593
2022-02-22 07:48:41 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 0.7078
2022-02-22 07:49:13 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 0.8325
2022-02-22 07:49:45 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 0.8905
2022-02-22 07:50:17 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 0.5909
2022-02-22 07:50:49 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 0.8020
2022-02-22 07:51:22 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 0.8047
2022-02-22 07:51:54 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 0.7531
2022-02-22 07:52:27 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 0.6750
2022-02-22 07:52:59 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 0.7373
2022-02-22 07:53:33 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 0.6747
2022-02-22 07:54:06 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 0.7268
2022-02-22 07:54:39 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 0.6004
2022-02-22 07:54:43 - train: epoch 094, train_loss: 0.7031
2022-02-22 07:55:58 - eval: epoch: 094, acc1: 77.700%, acc5: 93.918%, test_loss: 0.8836, per_image_load_time: 0.986ms, per_image_inference_time: 0.731ms
2022-02-22 07:55:59 - until epoch: 094, best_acc1: 77.700%
2022-02-22 22:41:23 - epoch 095 lr: 0.00010000000000000003
2022-02-22 22:42:03 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 0.7708
2022-02-22 22:42:34 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 0.6615
2022-02-22 22:43:05 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 0.7262
2022-02-22 22:43:37 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 0.7434
2022-02-22 22:44:08 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 0.7529
2022-02-22 22:44:39 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 0.7334
2022-02-22 22:45:11 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 0.6804
2022-02-22 22:45:42 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 0.7418
2022-02-22 22:46:13 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 0.8093
2022-02-22 22:46:45 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 0.7183
2022-02-22 22:47:16 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 0.6108
2022-02-22 22:47:47 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 0.6237
2022-02-22 22:48:19 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 0.5360
2022-02-22 22:48:50 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 0.6921
2022-02-22 22:49:21 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 0.7606
2022-02-22 22:49:53 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.5912
2022-02-22 22:50:24 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 0.8258
2022-02-22 22:50:56 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 0.7042
2022-02-22 22:51:27 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 0.7147
2022-02-22 22:51:58 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 0.6774
2022-02-22 22:52:30 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 0.7654
2022-02-22 22:53:02 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 0.6405
2022-02-22 22:53:33 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 0.8054
2022-02-22 22:54:05 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 0.6449
2022-02-22 22:54:36 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 0.7521
2022-02-22 22:55:08 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 0.6647
2022-02-22 22:55:39 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 0.7960
2022-02-22 22:56:11 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 0.7015
2022-02-22 22:56:43 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 0.6991
2022-02-22 22:57:15 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 0.9048
2022-02-22 22:57:46 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 0.5761
2022-02-22 22:58:18 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 0.5530
2022-02-22 22:58:50 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 0.7290
2022-02-22 22:59:22 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 0.6619
2022-02-22 22:59:53 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 0.8232
2022-02-22 23:00:25 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 0.6002
2022-02-22 23:00:57 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 0.7415
2022-02-22 23:01:28 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 0.5297
2022-02-22 23:02:00 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 0.6932
2022-02-22 23:02:32 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 0.5606
2022-02-22 23:03:04 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 0.7096
2022-02-22 23:03:36 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 0.8647
2022-02-22 23:04:08 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 0.6051
2022-02-22 23:04:41 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 0.6901
2022-02-22 23:05:13 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 0.5866
2022-02-22 23:05:46 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 0.7567
2022-02-22 23:06:19 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 0.6596
2022-02-22 23:06:52 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 0.6791
2022-02-22 23:07:25 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 0.6228
2022-02-22 23:07:58 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 0.6284
2022-02-22 23:08:00 - train: epoch 095, train_loss: 0.7000
2022-02-22 23:09:15 - eval: epoch: 095, acc1: 77.752%, acc5: 93.956%, test_loss: 0.8840, per_image_load_time: 2.149ms, per_image_inference_time: 0.648ms
2022-02-22 23:09:16 - until epoch: 095, best_acc1: 77.752%
2022-02-22 23:09:16 - epoch 096 lr: 0.00010000000000000003
2022-02-22 23:09:53 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 0.7584
2022-02-22 23:10:25 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 0.7586
2022-02-22 23:10:56 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 0.6188
2022-02-22 23:11:27 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 0.5164
2022-02-22 23:11:59 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 0.5687
2022-02-22 23:12:30 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 0.8033
2022-02-22 23:13:02 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 0.5772
2022-02-22 23:13:34 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 0.6325
2022-02-22 23:14:05 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 0.8279
2022-02-22 23:14:37 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 0.8839
2022-02-22 23:15:09 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 0.5911
2022-02-22 23:15:41 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 0.6937
2022-02-22 23:16:13 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 0.6534
2022-02-22 23:16:44 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 0.7468
2022-02-22 23:17:16 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 0.6374
2022-02-22 23:17:48 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 0.6679
2022-02-22 23:18:19 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 0.7952
2022-02-22 23:18:51 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 0.7673
2022-02-22 23:19:23 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 0.8313
2022-02-22 23:19:54 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 0.5914
2022-02-22 23:20:26 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 0.8400
2022-02-22 23:20:58 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.6785
2022-02-22 23:21:29 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 0.7289
2022-02-22 23:22:01 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 0.6783
2022-02-22 23:22:33 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 0.6321
2022-02-22 23:23:05 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 0.7229
2022-02-22 23:23:37 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 0.7209
2022-02-22 23:24:09 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 0.6187
2022-02-22 23:24:40 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 0.7198
2022-02-22 23:25:13 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 0.6325
2022-02-22 23:25:45 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 0.8747
2022-02-22 23:26:17 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 0.7717
2022-02-22 23:26:49 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 0.8632
2022-02-22 23:27:21 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 0.5755
2022-02-22 23:27:53 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 0.6622
2022-02-22 23:28:25 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 0.6571
2022-02-22 23:28:58 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 0.6622
2022-02-22 23:29:30 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 0.6723
2022-02-22 23:30:02 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 0.5886
2022-02-22 23:30:34 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 0.6504
2022-02-22 23:31:06 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 0.6031
2022-02-22 23:31:39 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 0.5594
2022-02-22 23:32:11 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.6708
2022-02-22 23:32:43 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 0.6059
2022-02-22 23:33:16 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 0.7547
2022-02-22 23:33:49 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 0.6850
2022-02-22 23:34:22 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 0.7588
2022-02-22 23:34:55 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 0.7145
2022-02-22 23:35:29 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 0.6358
2022-02-22 23:36:03 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 0.6402
2022-02-22 23:36:05 - train: epoch 096, train_loss: 0.6988
2022-02-22 23:37:20 - eval: epoch: 096, acc1: 77.696%, acc5: 93.978%, test_loss: 0.8829, per_image_load_time: 2.148ms, per_image_inference_time: 0.642ms
2022-02-22 23:37:21 - until epoch: 096, best_acc1: 77.752%
2022-02-22 23:37:21 - epoch 097 lr: 0.00010000000000000003
2022-02-22 23:37:59 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 0.7504
2022-02-22 23:38:30 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 0.6384
2022-02-22 23:39:01 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 0.7141
2022-02-22 23:39:32 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 0.8353
2022-02-22 23:40:04 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 0.8065
2022-02-22 23:40:35 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 0.6190
2022-02-22 23:41:06 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 0.5937
2022-02-22 23:41:37 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.5792
2022-02-22 23:42:09 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 0.7546
2022-02-22 23:42:40 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 0.6816
2022-02-22 23:43:12 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 0.6395
2022-02-22 23:43:44 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 0.8118
2022-02-22 23:44:15 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 0.6710
2022-02-22 23:44:47 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 0.6983
2022-02-22 23:45:19 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 0.5975
2022-02-22 23:45:50 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 0.7013
2022-02-22 23:46:22 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 0.6623
2022-02-22 23:46:53 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 0.8310
2022-02-22 23:47:25 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 0.4954
2022-02-22 23:47:57 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 0.7011
2022-02-22 23:48:28 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 0.7062
2022-02-22 23:49:00 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 0.6685
2022-02-22 23:49:31 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 0.7045
2022-02-22 23:50:03 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 0.7475
2022-02-22 23:50:35 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 0.7513
2022-02-22 23:51:06 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 0.6503
2022-02-22 23:51:38 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 0.6947
2022-02-22 23:52:10 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 0.6209
2022-02-22 23:52:42 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 0.6357
2022-02-22 23:53:13 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 0.6869
2022-02-22 23:53:45 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 0.6880
2022-02-22 23:54:17 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 0.6740
2022-02-22 23:54:49 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 0.8319
2022-02-22 23:55:20 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 0.7717
2022-02-22 23:55:52 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 0.5950
2022-02-22 23:56:24 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 0.8004
2022-02-22 23:56:55 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 0.5584
2022-02-22 23:57:27 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 0.6586
2022-02-22 23:57:58 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 0.6735
2022-02-22 23:58:30 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 0.8933
2022-02-22 23:59:02 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 0.6509
2022-02-22 23:59:34 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 0.7340
2022-02-23 00:00:06 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 0.5931
2022-02-23 00:00:39 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 0.5334
2022-02-23 00:01:11 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 0.6662
2022-02-23 00:01:44 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 0.5865
2022-02-23 00:02:17 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 0.5563
2022-02-23 00:02:50 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 0.6354
2022-02-23 00:03:24 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 0.7926
2022-02-23 00:03:58 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 0.5217
2022-02-23 00:04:00 - train: epoch 097, train_loss: 0.6959
2022-02-23 00:05:14 - eval: epoch: 097, acc1: 77.738%, acc5: 93.890%, test_loss: 0.8829, per_image_load_time: 2.242ms, per_image_inference_time: 0.670ms
2022-02-23 00:05:16 - until epoch: 097, best_acc1: 77.752%
2022-02-23 00:05:16 - epoch 098 lr: 0.00010000000000000003
2022-02-23 00:05:54 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 0.6630
2022-02-23 00:06:25 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 0.8936
2022-02-23 00:06:56 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 0.7531
2022-02-23 00:07:28 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 0.6660
2022-02-23 00:07:59 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 0.8248
2022-02-23 00:08:31 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 0.6178
2022-02-23 00:09:03 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 0.7451
2022-02-23 00:09:34 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 0.7884
2022-02-23 00:10:06 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 0.6723
2022-02-23 00:10:38 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 0.6216
2022-02-23 00:11:10 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 0.6246
2022-02-23 00:11:41 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 0.5444
2022-02-23 00:12:13 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 0.5835
2022-02-23 00:12:45 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 0.8020
2022-02-23 00:13:16 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 0.5686
2022-02-23 00:13:48 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 0.7007
2022-02-23 00:14:20 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 0.7139
2022-02-23 00:14:51 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 0.5962
2022-02-23 00:15:23 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 0.6269
2022-02-23 00:15:55 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 0.7140
2022-02-23 00:16:27 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 0.8490
2022-02-23 00:16:59 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 0.7746
2022-02-23 00:17:30 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 0.6683
2022-02-23 00:18:02 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 0.6422
2022-02-23 00:18:34 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 0.6623
2022-02-23 00:19:06 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 0.7778
2022-02-23 00:19:37 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 0.6699
2022-02-23 00:20:09 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 0.7817
2022-02-23 00:20:41 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 0.5750
2022-02-23 00:21:13 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 0.6326
2022-02-23 00:21:45 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 0.7273
2022-02-23 00:22:16 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 0.6097
2022-02-23 00:22:48 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 0.6024
2022-02-23 00:23:20 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 0.6153
2022-02-23 00:23:52 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 0.6846
2022-02-23 00:24:24 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 0.8182
2022-02-23 00:24:55 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 0.7776
2022-02-23 00:25:28 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 0.7049
2022-02-23 00:26:00 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 0.7101
2022-02-23 00:26:32 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 0.8379
2022-02-23 00:27:04 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 0.6613
2022-02-23 00:27:36 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 0.6342
2022-02-23 00:28:09 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 0.5667
2022-02-23 00:28:41 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 0.6170
2022-02-23 00:29:14 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 0.7415
2022-02-23 00:29:46 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 0.8437
2022-02-23 00:30:20 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 0.7092
2022-02-23 00:30:53 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 0.6077
2022-02-23 00:31:27 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 0.7098
2022-02-23 00:32:00 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 0.7396
2022-02-23 00:32:02 - train: epoch 098, train_loss: 0.6966
2022-02-23 00:33:16 - eval: epoch: 098, acc1: 77.624%, acc5: 93.898%, test_loss: 0.8840, per_image_load_time: 2.048ms, per_image_inference_time: 0.675ms
2022-02-23 00:33:17 - until epoch: 098, best_acc1: 77.752%
2022-02-23 00:33:17 - epoch 099 lr: 0.00010000000000000003
2022-02-23 00:33:55 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 0.6494
2022-02-23 00:34:26 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 0.6057
2022-02-23 00:34:57 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 0.6158
2022-02-23 00:35:29 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 0.6108
2022-02-23 00:36:01 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 0.7313
2022-02-23 00:36:33 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 0.6689
2022-02-23 00:37:04 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 0.8107
2022-02-23 00:37:36 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 0.4956
2022-02-23 00:38:08 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 0.5451
2022-02-23 00:38:40 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 0.6572
2022-02-23 00:39:12 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 0.6003
2022-02-23 00:39:44 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 0.5867
2022-02-23 00:40:16 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 0.7234
2022-02-23 00:40:48 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 0.6753
2022-02-23 00:41:20 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 0.6499
2022-02-23 00:41:52 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 0.7913
2022-02-23 00:42:23 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 0.6455
2022-02-23 00:42:55 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 0.5608
2022-02-23 00:43:27 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 0.8670
2022-02-23 00:43:59 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 0.6672
2022-02-23 00:44:31 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 0.7263
2022-02-23 00:45:03 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 0.7194
2022-02-23 00:45:35 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 0.5829
2022-02-23 00:46:07 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 0.7896
2022-02-23 00:46:39 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 0.7168
2022-02-23 00:47:11 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 0.7362
2022-02-23 00:47:42 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 0.8476
2022-02-23 00:48:15 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 0.6810
2022-02-23 00:48:47 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 0.7225
2022-02-23 00:49:19 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 0.7709
2022-02-23 00:49:51 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 0.6198
2022-02-23 00:50:22 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 0.8197
2022-02-23 00:50:54 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 0.6916
2022-02-23 00:51:27 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 0.7366
2022-02-23 00:51:59 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 0.7571
2022-02-23 00:52:31 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 0.6681
2022-02-23 00:53:03 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 0.6961
2022-02-23 00:53:35 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 0.8168
2022-02-23 00:54:07 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 0.7696
2022-02-23 00:54:39 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 0.7996
2022-02-23 00:55:11 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 0.5202
2022-02-23 00:55:44 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 0.8371
2022-02-23 00:56:16 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 0.8169
2022-02-23 00:56:49 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 0.6424
2022-02-23 00:57:22 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 0.7174
2022-02-23 00:57:55 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 0.7600
2022-02-23 00:58:28 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 0.7570
2022-02-23 00:59:02 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 0.6258
2022-02-23 00:59:36 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 0.8687
2022-02-23 01:00:10 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 0.7258
2022-02-23 01:00:11 - train: epoch 099, train_loss: 0.6920
2022-02-23 01:01:26 - eval: epoch: 099, acc1: 77.722%, acc5: 93.966%, test_loss: 0.8842, per_image_load_time: 0.809ms, per_image_inference_time: 0.691ms
2022-02-23 01:01:27 - until epoch: 099, best_acc1: 77.752%
2022-02-23 01:01:27 - epoch 100 lr: 0.00010000000000000003
2022-02-23 01:02:05 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 0.8018
2022-02-23 01:02:36 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 0.7631
2022-02-23 01:03:07 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 0.7244
2022-02-23 01:03:39 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 0.7690
2022-02-23 01:04:10 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 0.6520
2022-02-23 01:04:42 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 0.8780
2022-02-23 01:05:13 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 0.7223
2022-02-23 01:05:45 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 0.5894
2022-02-23 01:06:17 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 0.5728
2022-02-23 01:06:49 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 0.6536
2022-02-23 01:07:21 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 0.6900
2022-02-23 01:07:53 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 0.6941
2022-02-23 01:08:25 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 0.7443
2022-02-23 01:08:57 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 0.7281
2022-02-23 01:09:29 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 0.7248
2022-02-23 01:10:01 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 0.6727
2022-02-23 01:10:33 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 0.6934
2022-02-23 01:11:05 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 0.5525
2022-02-23 01:11:37 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 0.6228
2022-02-23 01:12:09 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 0.7306
2022-02-23 01:12:41 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 0.6834
2022-02-23 01:13:13 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 0.8414
2022-02-23 01:13:45 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 0.6876
2022-02-23 01:14:18 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 0.7061
2022-02-23 01:14:50 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 0.8140
2022-02-23 01:15:22 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 0.5982
2022-02-23 01:15:54 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 0.6913
2022-02-23 01:16:26 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 0.6768
2022-02-23 01:16:58 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 0.6867
2022-02-23 01:17:30 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 0.6085
2022-02-23 01:18:02 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 0.4442
2022-02-23 01:18:34 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 0.7873
2022-02-23 01:19:06 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 0.6038
2022-02-23 01:19:38 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 0.6911
2022-02-23 01:20:10 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 0.6677
2022-02-23 01:20:43 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 0.6797
2022-02-23 01:21:15 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 0.6809
2022-02-23 01:21:48 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 0.5755
2022-02-23 01:22:20 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 0.7323
2022-02-23 01:22:52 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 0.7155
2022-02-23 01:23:24 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 0.6513
2022-02-23 01:23:57 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 0.7863
2022-02-23 01:24:29 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 0.7175
2022-02-23 01:25:02 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 0.8609
2022-02-23 01:25:35 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 0.6971
2022-02-23 01:26:08 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 0.7351
2022-02-23 01:26:42 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 0.7876
2022-02-23 01:27:15 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 0.5110
2022-02-23 01:27:49 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 0.8326
2022-02-23 01:28:24 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 0.7553
2022-02-23 01:28:26 - train: epoch 100, train_loss: 0.6921
2022-02-23 01:29:40 - eval: epoch: 100, acc1: 77.686%, acc5: 93.908%, test_loss: 0.8847, per_image_load_time: 2.214ms, per_image_inference_time: 0.674ms
2022-02-23 01:29:41 - until epoch: 100, best_acc1: 77.752%
2022-02-23 06:06:46 - train done. model: resnet101, train time: 47.216 hours, best_acc1: 77.752%
