2022-02-24 06:09:53 - train: epoch 0047, iter [03800, 05004], lr: 0.010000, loss: 1.3493
2022-02-24 06:10:27 - train: epoch 0047, iter [03900, 05004], lr: 0.010000, loss: 1.3552
2022-02-24 06:11:02 - train: epoch 0047, iter [04000, 05004], lr: 0.010000, loss: 1.4112
2022-02-24 06:11:37 - train: epoch 0047, iter [04100, 05004], lr: 0.010000, loss: 1.3296
2022-02-24 06:12:11 - train: epoch 0047, iter [04200, 05004], lr: 0.010000, loss: 1.3628
2022-02-24 06:12:47 - train: epoch 0047, iter [04300, 05004], lr: 0.010000, loss: 1.1459
2022-02-24 06:13:21 - train: epoch 0047, iter [04400, 05004], lr: 0.010000, loss: 1.3174
2022-02-24 06:14:01 - train: epoch 0047, iter [04500, 05004], lr: 0.010000, loss: 1.4895
2022-02-24 06:14:42 - train: epoch 0047, iter [04600, 05004], lr: 0.010000, loss: 1.3119
2022-02-24 06:15:21 - train: epoch 0047, iter [04700, 05004], lr: 0.010000, loss: 1.4113
2022-02-24 06:16:05 - train: epoch 0047, iter [04800, 05004], lr: 0.010000, loss: 1.2277
2022-02-24 06:16:55 - train: epoch 0047, iter [04900, 05004], lr: 0.010000, loss: 1.4247
2022-02-24 06:17:46 - train: epoch 0047, iter [05000, 05004], lr: 0.010000, loss: 1.1938
2022-02-24 06:17:49 - train: epoch 047, train_loss: 1.3473
2022-02-24 06:19:12 - eval: epoch: 047, acc1: 71.706%, acc5: 90.638%, test_loss: 1.1272, per_image_load_time: 0.827ms, per_image_inference_time: 0.626ms
2022-02-24 06:19:13 - until epoch: 047, best_acc1: 72.062%
2022-02-24 06:19:13 - epoch 048 lr: 0.010000000000000002
2022-02-24 06:19:54 - train: epoch 0048, iter [00100, 05004], lr: 0.010000, loss: 1.4985
2022-02-24 06:20:27 - train: epoch 0048, iter [00200, 05004], lr: 0.010000, loss: 1.6802
2022-02-24 06:21:00 - train: epoch 0048, iter [00300, 05004], lr: 0.010000, loss: 1.3280
2022-02-24 06:21:33 - train: epoch 0048, iter [00400, 05004], lr: 0.010000, loss: 1.3123
2022-02-24 06:22:06 - train: epoch 0048, iter [00500, 05004], lr: 0.010000, loss: 1.2042
2022-02-24 06:22:40 - train: epoch 0048, iter [00600, 05004], lr: 0.010000, loss: 1.2914
2022-02-24 06:23:13 - train: epoch 0048, iter [00700, 05004], lr: 0.010000, loss: 1.3116
2022-02-24 06:23:47 - train: epoch 0048, iter [00800, 05004], lr: 0.010000, loss: 1.4382
2022-02-24 06:24:21 - train: epoch 0048, iter [00900, 05004], lr: 0.010000, loss: 1.4855
2022-02-24 06:24:54 - train: epoch 0048, iter [01000, 05004], lr: 0.010000, loss: 1.3915
2022-02-24 06:25:28 - train: epoch 0048, iter [01100, 05004], lr: 0.010000, loss: 1.3287
2022-02-24 06:26:01 - train: epoch 0048, iter [01200, 05004], lr: 0.010000, loss: 1.3924
2022-02-24 06:26:35 - train: epoch 0048, iter [01300, 05004], lr: 0.010000, loss: 1.1875
2022-02-24 06:27:08 - train: epoch 0048, iter [01400, 05004], lr: 0.010000, loss: 1.2256
2022-02-24 06:27:41 - train: epoch 0048, iter [01500, 05004], lr: 0.010000, loss: 1.3979
2022-02-24 06:28:15 - train: epoch 0048, iter [01600, 05004], lr: 0.010000, loss: 1.3818
2022-02-24 06:28:48 - train: epoch 0048, iter [01700, 05004], lr: 0.010000, loss: 1.4613
2022-02-24 06:29:22 - train: epoch 0048, iter [01800, 05004], lr: 0.010000, loss: 1.4178
2022-02-24 06:29:56 - train: epoch 0048, iter [01900, 05004], lr: 0.010000, loss: 1.3396
2022-02-24 06:30:29 - train: epoch 0048, iter [02000, 05004], lr: 0.010000, loss: 1.6177
2022-02-24 06:31:03 - train: epoch 0048, iter [02100, 05004], lr: 0.010000, loss: 1.3645
2022-02-24 06:31:37 - train: epoch 0048, iter [02200, 05004], lr: 0.010000, loss: 1.4977
2022-02-24 06:32:10 - train: epoch 0048, iter [02300, 05004], lr: 0.010000, loss: 1.2743
2022-02-24 06:32:44 - train: epoch 0048, iter [02400, 05004], lr: 0.010000, loss: 1.5042
2022-02-24 06:33:18 - train: epoch 0048, iter [02500, 05004], lr: 0.010000, loss: 1.4167
2022-02-24 06:33:51 - train: epoch 0048, iter [02600, 05004], lr: 0.010000, loss: 1.6019
2022-02-24 06:34:25 - train: epoch 0048, iter [02700, 05004], lr: 0.010000, loss: 1.5535
2022-02-24 06:34:59 - train: epoch 0048, iter [02800, 05004], lr: 0.010000, loss: 1.2238
2022-02-24 06:35:33 - train: epoch 0048, iter [02900, 05004], lr: 0.010000, loss: 1.4607
2022-02-24 06:36:06 - train: epoch 0048, iter [03000, 05004], lr: 0.010000, loss: 1.2584
2022-02-24 06:36:40 - train: epoch 0048, iter [03100, 05004], lr: 0.010000, loss: 1.3185
2022-02-24 06:37:13 - train: epoch 0048, iter [03200, 05004], lr: 0.010000, loss: 1.2200
2022-02-24 06:37:47 - train: epoch 0048, iter [03300, 05004], lr: 0.010000, loss: 1.4265
2022-02-24 06:38:21 - train: epoch 0048, iter [03400, 05004], lr: 0.010000, loss: 1.2652
2022-02-24 06:38:55 - train: epoch 0048, iter [03500, 05004], lr: 0.010000, loss: 1.6354
2022-02-24 06:39:30 - train: epoch 0048, iter [03600, 05004], lr: 0.010000, loss: 1.3925
2022-02-24 06:40:03 - train: epoch 0048, iter [03700, 05004], lr: 0.010000, loss: 1.4635
2022-02-24 06:40:38 - train: epoch 0048, iter [03800, 05004], lr: 0.010000, loss: 1.3063
2022-02-24 06:41:11 - train: epoch 0048, iter [03900, 05004], lr: 0.010000, loss: 1.4612
2022-02-24 06:41:46 - train: epoch 0048, iter [04000, 05004], lr: 0.010000, loss: 1.1363
2022-02-24 06:42:21 - train: epoch 0048, iter [04100, 05004], lr: 0.010000, loss: 1.5781
2022-02-24 06:42:55 - train: epoch 0048, iter [04200, 05004], lr: 0.010000, loss: 1.3005
2022-02-24 06:43:30 - train: epoch 0048, iter [04300, 05004], lr: 0.010000, loss: 1.3101
2022-02-24 06:44:06 - train: epoch 0048, iter [04400, 05004], lr: 0.010000, loss: 1.2646
2022-02-24 06:44:45 - train: epoch 0048, iter [04500, 05004], lr: 0.010000, loss: 1.3647
2022-02-24 06:45:22 - train: epoch 0048, iter [04600, 05004], lr: 0.010000, loss: 1.2289
2022-02-24 06:46:02 - train: epoch 0048, iter [04700, 05004], lr: 0.010000, loss: 1.4354
2022-02-24 06:46:49 - train: epoch 0048, iter [04800, 05004], lr: 0.010000, loss: 1.6039
2022-02-24 06:47:35 - train: epoch 0048, iter [04900, 05004], lr: 0.010000, loss: 1.4507
2022-02-24 06:48:12 - train: epoch 0048, iter [05000, 05004], lr: 0.010000, loss: 1.3466
2022-02-24 06:48:16 - train: epoch 048, train_loss: 1.3473
2022-02-24 06:49:48 - eval: epoch: 048, acc1: 71.390%, acc5: 90.610%, test_loss: 1.1333, per_image_load_time: 2.646ms, per_image_inference_time: 0.600ms
2022-02-24 06:49:49 - until epoch: 048, best_acc1: 72.062%
2022-02-24 06:49:49 - epoch 049 lr: 0.010000000000000002
2022-02-24 06:50:29 - train: epoch 0049, iter [00100, 05004], lr: 0.010000, loss: 1.4994
2022-02-24 06:51:02 - train: epoch 0049, iter [00200, 05004], lr: 0.010000, loss: 1.2956
2022-02-24 06:51:35 - train: epoch 0049, iter [00300, 05004], lr: 0.010000, loss: 1.3468
2022-02-24 06:52:09 - train: epoch 0049, iter [00400, 05004], lr: 0.010000, loss: 1.4147
2022-02-24 06:52:42 - train: epoch 0049, iter [00500, 05004], lr: 0.010000, loss: 1.2710
2022-02-24 06:53:15 - train: epoch 0049, iter [00600, 05004], lr: 0.010000, loss: 1.2654
2022-02-24 06:53:49 - train: epoch 0049, iter [00700, 05004], lr: 0.010000, loss: 1.4622
2022-02-24 06:54:23 - train: epoch 0049, iter [00800, 05004], lr: 0.010000, loss: 1.6448
2022-02-24 06:54:56 - train: epoch 0049, iter [00900, 05004], lr: 0.010000, loss: 1.2561
2022-02-24 06:55:30 - train: epoch 0049, iter [01000, 05004], lr: 0.010000, loss: 1.3264
2022-02-24 06:56:04 - train: epoch 0049, iter [01100, 05004], lr: 0.010000, loss: 1.2377
2022-02-24 06:56:38 - train: epoch 0049, iter [01200, 05004], lr: 0.010000, loss: 1.1056
2022-02-24 06:57:11 - train: epoch 0049, iter [01300, 05004], lr: 0.010000, loss: 1.4302
2022-02-24 06:57:45 - train: epoch 0049, iter [01400, 05004], lr: 0.010000, loss: 1.4299
2022-02-24 06:58:19 - train: epoch 0049, iter [01500, 05004], lr: 0.010000, loss: 1.2840
2022-02-24 06:58:53 - train: epoch 0049, iter [01600, 05004], lr: 0.010000, loss: 1.4293
2022-02-24 06:59:26 - train: epoch 0049, iter [01700, 05004], lr: 0.010000, loss: 1.4099
2022-02-24 07:00:00 - train: epoch 0049, iter [01800, 05004], lr: 0.010000, loss: 1.2088
2022-02-24 07:00:33 - train: epoch 0049, iter [01900, 05004], lr: 0.010000, loss: 1.2848
2022-02-24 07:01:07 - train: epoch 0049, iter [02000, 05004], lr: 0.010000, loss: 1.2571
2022-02-24 07:01:41 - train: epoch 0049, iter [02100, 05004], lr: 0.010000, loss: 1.2295
2022-02-24 07:02:14 - train: epoch 0049, iter [02200, 05004], lr: 0.010000, loss: 1.4111
2022-02-24 07:02:48 - train: epoch 0049, iter [02300, 05004], lr: 0.010000, loss: 1.2519
2022-02-24 07:03:22 - train: epoch 0049, iter [02400, 05004], lr: 0.010000, loss: 1.4324
2022-02-24 07:03:56 - train: epoch 0049, iter [02500, 05004], lr: 0.010000, loss: 1.3248
2022-02-24 07:04:29 - train: epoch 0049, iter [02600, 05004], lr: 0.010000, loss: 1.3229
2022-02-24 07:05:04 - train: epoch 0049, iter [02700, 05004], lr: 0.010000, loss: 1.2087
2022-02-24 07:05:37 - train: epoch 0049, iter [02800, 05004], lr: 0.010000, loss: 1.3564
2022-02-24 07:06:11 - train: epoch 0049, iter [02900, 05004], lr: 0.010000, loss: 1.3981
2022-02-24 07:06:45 - train: epoch 0049, iter [03000, 05004], lr: 0.010000, loss: 1.3030
2022-02-24 07:07:19 - train: epoch 0049, iter [03100, 05004], lr: 0.010000, loss: 1.4082
2022-02-24 07:07:53 - train: epoch 0049, iter [03200, 05004], lr: 0.010000, loss: 1.4607
2022-02-24 07:08:27 - train: epoch 0049, iter [03300, 05004], lr: 0.010000, loss: 1.3806
2022-02-24 07:09:02 - train: epoch 0049, iter [03400, 05004], lr: 0.010000, loss: 1.4958
2022-02-24 07:09:35 - train: epoch 0049, iter [03500, 05004], lr: 0.010000, loss: 1.4395
2022-02-24 07:10:10 - train: epoch 0049, iter [03600, 05004], lr: 0.010000, loss: 1.4945
2022-02-24 07:10:44 - train: epoch 0049, iter [03700, 05004], lr: 0.010000, loss: 1.2829
2022-02-24 07:11:18 - train: epoch 0049, iter [03800, 05004], lr: 0.010000, loss: 1.5071
2022-02-24 07:11:53 - train: epoch 0049, iter [03900, 05004], lr: 0.010000, loss: 1.5487
2022-02-24 07:12:27 - train: epoch 0049, iter [04000, 05004], lr: 0.010000, loss: 1.3250
2022-02-24 07:13:02 - train: epoch 0049, iter [04100, 05004], lr: 0.010000, loss: 1.2889
2022-02-24 07:13:36 - train: epoch 0049, iter [04200, 05004], lr: 0.010000, loss: 1.3610
2022-02-24 07:14:12 - train: epoch 0049, iter [04300, 05004], lr: 0.010000, loss: 1.6306
2022-02-24 07:14:46 - train: epoch 0049, iter [04400, 05004], lr: 0.010000, loss: 1.3329
2022-02-24 07:15:24 - train: epoch 0049, iter [04500, 05004], lr: 0.010000, loss: 1.3524
2022-02-24 07:16:06 - train: epoch 0049, iter [04600, 05004], lr: 0.010000, loss: 1.4785
2022-02-24 07:16:45 - train: epoch 0049, iter [04700, 05004], lr: 0.010000, loss: 1.5075
2022-02-24 07:17:28 - train: epoch 0049, iter [04800, 05004], lr: 0.010000, loss: 1.1902
2022-02-24 07:18:17 - train: epoch 0049, iter [04900, 05004], lr: 0.010000, loss: 1.2133
2022-02-24 07:19:08 - train: epoch 0049, iter [05000, 05004], lr: 0.010000, loss: 1.2771
2022-02-24 07:19:10 - train: epoch 049, train_loss: 1.3426
2022-02-24 07:20:45 - eval: epoch: 049, acc1: 71.612%, acc5: 90.592%, test_loss: 1.1325, per_image_load_time: 2.205ms, per_image_inference_time: 0.577ms
2022-02-24 07:20:45 - until epoch: 049, best_acc1: 72.062%
2022-02-24 07:20:45 - epoch 050 lr: 0.010000000000000002
2022-02-24 07:21:26 - train: epoch 0050, iter [00100, 05004], lr: 0.010000, loss: 1.4935
2022-02-24 07:22:00 - train: epoch 0050, iter [00200, 05004], lr: 0.010000, loss: 1.2432
2022-02-24 07:22:34 - train: epoch 0050, iter [00300, 05004], lr: 0.010000, loss: 1.2941
2022-02-24 07:23:08 - train: epoch 0050, iter [00400, 05004], lr: 0.010000, loss: 1.2102
2022-02-24 07:23:42 - train: epoch 0050, iter [00500, 05004], lr: 0.010000, loss: 1.3422
2022-02-24 07:24:16 - train: epoch 0050, iter [00600, 05004], lr: 0.010000, loss: 1.4010
2022-02-24 07:24:50 - train: epoch 0050, iter [00700, 05004], lr: 0.010000, loss: 1.1796
2022-02-24 07:25:24 - train: epoch 0050, iter [00800, 05004], lr: 0.010000, loss: 1.1547
2022-02-24 07:25:58 - train: epoch 0050, iter [00900, 05004], lr: 0.010000, loss: 1.1530
2022-02-24 07:26:33 - train: epoch 0050, iter [01000, 05004], lr: 0.010000, loss: 1.4118
2022-02-24 07:27:07 - train: epoch 0050, iter [01100, 05004], lr: 0.010000, loss: 1.4263
2022-02-24 07:27:41 - train: epoch 0050, iter [01200, 05004], lr: 0.010000, loss: 1.3736
2022-02-24 07:28:15 - train: epoch 0050, iter [01300, 05004], lr: 0.010000, loss: 1.2555
2022-02-24 07:28:50 - train: epoch 0050, iter [01400, 05004], lr: 0.010000, loss: 1.3805
2022-02-24 07:29:24 - train: epoch 0050, iter [01500, 05004], lr: 0.010000, loss: 1.3196
2022-02-24 07:29:58 - train: epoch 0050, iter [01600, 05004], lr: 0.010000, loss: 1.3501
2022-02-24 07:30:32 - train: epoch 0050, iter [01700, 05004], lr: 0.010000, loss: 1.4525
2022-02-24 07:31:06 - train: epoch 0050, iter [01800, 05004], lr: 0.010000, loss: 1.2541
2022-02-24 07:31:40 - train: epoch 0050, iter [01900, 05004], lr: 0.010000, loss: 1.3284
2022-02-24 07:32:14 - train: epoch 0050, iter [02000, 05004], lr: 0.010000, loss: 1.3207
2022-02-24 07:32:49 - train: epoch 0050, iter [02100, 05004], lr: 0.010000, loss: 1.1464
2022-02-24 07:33:23 - train: epoch 0050, iter [02200, 05004], lr: 0.010000, loss: 1.4073
2022-02-24 07:33:58 - train: epoch 0050, iter [02300, 05004], lr: 0.010000, loss: 1.2970
2022-02-24 07:34:33 - train: epoch 0050, iter [02400, 05004], lr: 0.010000, loss: 1.3088
2022-02-24 07:35:06 - train: epoch 0050, iter [02500, 05004], lr: 0.010000, loss: 1.3481
2022-02-24 07:35:41 - train: epoch 0050, iter [02600, 05004], lr: 0.010000, loss: 1.2549
2022-02-24 07:36:15 - train: epoch 0050, iter [02700, 05004], lr: 0.010000, loss: 1.4164
2022-02-24 07:36:50 - train: epoch 0050, iter [02800, 05004], lr: 0.010000, loss: 1.5005
2022-02-24 07:37:24 - train: epoch 0050, iter [02900, 05004], lr: 0.010000, loss: 1.4285
2022-02-24 07:37:59 - train: epoch 0050, iter [03000, 05004], lr: 0.010000, loss: 1.4335
2022-02-24 07:38:34 - train: epoch 0050, iter [03100, 05004], lr: 0.010000, loss: 1.3332
2022-02-24 07:39:08 - train: epoch 0050, iter [03200, 05004], lr: 0.010000, loss: 1.2902
2022-02-24 07:39:42 - train: epoch 0050, iter [03300, 05004], lr: 0.010000, loss: 1.3372
2022-02-24 07:40:16 - train: epoch 0050, iter [03400, 05004], lr: 0.010000, loss: 1.2414
2022-02-24 07:40:50 - train: epoch 0050, iter [03500, 05004], lr: 0.010000, loss: 1.3055
2022-02-24 07:41:25 - train: epoch 0050, iter [03600, 05004], lr: 0.010000, loss: 1.2389
2022-02-24 07:41:58 - train: epoch 0050, iter [03700, 05004], lr: 0.010000, loss: 1.3606
2022-02-24 07:42:34 - train: epoch 0050, iter [03800, 05004], lr: 0.010000, loss: 1.1563
2022-02-24 07:43:07 - train: epoch 0050, iter [03900, 05004], lr: 0.010000, loss: 1.2036
2022-02-24 07:43:43 - train: epoch 0050, iter [04000, 05004], lr: 0.010000, loss: 1.4498
2022-02-24 07:44:17 - train: epoch 0050, iter [04100, 05004], lr: 0.010000, loss: 1.2197
2022-02-24 07:44:52 - train: epoch 0050, iter [04200, 05004], lr: 0.010000, loss: 1.4020
2022-02-24 07:45:27 - train: epoch 0050, iter [04300, 05004], lr: 0.010000, loss: 1.3004
2022-02-24 07:46:03 - train: epoch 0050, iter [04400, 05004], lr: 0.010000, loss: 1.2302
2022-02-24 07:46:43 - train: epoch 0050, iter [04500, 05004], lr: 0.010000, loss: 1.2834
2022-02-24 07:47:23 - train: epoch 0050, iter [04600, 05004], lr: 0.010000, loss: 1.4158
2022-02-24 07:48:03 - train: epoch 0050, iter [04700, 05004], lr: 0.010000, loss: 1.3015
2022-02-24 07:48:50 - train: epoch 0050, iter [04800, 05004], lr: 0.010000, loss: 1.1012
2022-02-24 07:49:39 - train: epoch 0050, iter [04900, 05004], lr: 0.010000, loss: 1.2018
2022-02-24 07:50:27 - train: epoch 0050, iter [05000, 05004], lr: 0.010000, loss: 1.2662
2022-02-24 07:50:31 - train: epoch 050, train_loss: 1.3401
2022-02-24 07:52:02 - eval: epoch: 050, acc1: 71.458%, acc5: 90.522%, test_loss: 1.1391, per_image_load_time: 1.205ms, per_image_inference_time: 0.573ms
2022-02-24 07:52:02 - until epoch: 050, best_acc1: 72.062%
2022-02-24 07:52:02 - epoch 051 lr: 0.010000000000000002
2022-02-24 07:52:42 - train: epoch 0051, iter [00100, 05004], lr: 0.010000, loss: 1.5023
2022-02-24 07:53:16 - train: epoch 0051, iter [00200, 05004], lr: 0.010000, loss: 1.6051
2022-02-24 07:53:49 - train: epoch 0051, iter [00300, 05004], lr: 0.010000, loss: 1.4004
2022-02-24 07:54:23 - train: epoch 0051, iter [00400, 05004], lr: 0.010000, loss: 1.1777
2022-02-24 07:54:56 - train: epoch 0051, iter [00500, 05004], lr: 0.010000, loss: 1.4025
2022-02-24 07:55:29 - train: epoch 0051, iter [00600, 05004], lr: 0.010000, loss: 1.3252
2022-02-24 07:56:02 - train: epoch 0051, iter [00700, 05004], lr: 0.010000, loss: 1.2564
2022-02-24 07:56:36 - train: epoch 0051, iter [00800, 05004], lr: 0.010000, loss: 1.5558
2022-02-24 07:57:09 - train: epoch 0051, iter [00900, 05004], lr: 0.010000, loss: 1.2711
2022-02-24 07:57:43 - train: epoch 0051, iter [01000, 05004], lr: 0.010000, loss: 1.6302
2022-02-24 07:58:16 - train: epoch 0051, iter [01100, 05004], lr: 0.010000, loss: 1.4795
2022-02-24 07:58:50 - train: epoch 0051, iter [01200, 05004], lr: 0.010000, loss: 1.3137
2022-02-24 07:59:23 - train: epoch 0051, iter [01300, 05004], lr: 0.010000, loss: 1.0277
2022-02-24 07:59:57 - train: epoch 0051, iter [01400, 05004], lr: 0.010000, loss: 1.2434
2022-02-24 08:00:31 - train: epoch 0051, iter [01500, 05004], lr: 0.010000, loss: 1.2767
2022-02-24 08:01:04 - train: epoch 0051, iter [01600, 05004], lr: 0.010000, loss: 1.2547
2022-02-24 08:01:38 - train: epoch 0051, iter [01700, 05004], lr: 0.010000, loss: 1.4445
2022-02-24 08:02:11 - train: epoch 0051, iter [01800, 05004], lr: 0.010000, loss: 1.3909
2022-02-24 08:02:45 - train: epoch 0051, iter [01900, 05004], lr: 0.010000, loss: 1.1862
2022-02-24 08:03:19 - train: epoch 0051, iter [02000, 05004], lr: 0.010000, loss: 1.2901
2022-02-24 08:03:52 - train: epoch 0051, iter [02100, 05004], lr: 0.010000, loss: 1.3041
2022-02-24 08:04:26 - train: epoch 0051, iter [02200, 05004], lr: 0.010000, loss: 1.3961
2022-02-24 08:04:59 - train: epoch 0051, iter [02300, 05004], lr: 0.010000, loss: 1.3410
2022-02-24 08:05:33 - train: epoch 0051, iter [02400, 05004], lr: 0.010000, loss: 1.4346
2022-02-24 08:06:07 - train: epoch 0051, iter [02500, 05004], lr: 0.010000, loss: 1.2715
2022-02-24 08:06:41 - train: epoch 0051, iter [02600, 05004], lr: 0.010000, loss: 1.2364
2022-02-24 08:07:15 - train: epoch 0051, iter [02700, 05004], lr: 0.010000, loss: 1.3323
2022-02-24 08:07:49 - train: epoch 0051, iter [02800, 05004], lr: 0.010000, loss: 1.2095
2022-02-24 08:08:23 - train: epoch 0051, iter [02900, 05004], lr: 0.010000, loss: 1.2665
2022-02-24 08:08:56 - train: epoch 0051, iter [03000, 05004], lr: 0.010000, loss: 1.1896
2022-02-24 08:09:31 - train: epoch 0051, iter [03100, 05004], lr: 0.010000, loss: 1.2578
2022-02-24 08:10:05 - train: epoch 0051, iter [03200, 05004], lr: 0.010000, loss: 1.2531
2022-02-24 08:10:39 - train: epoch 0051, iter [03300, 05004], lr: 0.010000, loss: 1.4209
2022-02-24 08:11:13 - train: epoch 0051, iter [03400, 05004], lr: 0.010000, loss: 1.3582
2022-02-24 08:11:47 - train: epoch 0051, iter [03500, 05004], lr: 0.010000, loss: 1.3223
2022-02-24 08:12:21 - train: epoch 0051, iter [03600, 05004], lr: 0.010000, loss: 1.2992
2022-02-24 08:12:56 - train: epoch 0051, iter [03700, 05004], lr: 0.010000, loss: 1.4775
2022-02-24 08:13:31 - train: epoch 0051, iter [03800, 05004], lr: 0.010000, loss: 1.3264
2022-02-24 08:14:05 - train: epoch 0051, iter [03900, 05004], lr: 0.010000, loss: 1.3566
2022-02-24 08:14:40 - train: epoch 0051, iter [04000, 05004], lr: 0.010000, loss: 1.2767
2022-02-24 08:15:24 - train: epoch 0051, iter [04100, 05004], lr: 0.010000, loss: 1.4387
2022-02-24 08:15:59 - train: epoch 0051, iter [04200, 05004], lr: 0.010000, loss: 1.5523
2022-02-24 08:16:35 - train: epoch 0051, iter [04300, 05004], lr: 0.010000, loss: 1.2836
2022-02-24 08:17:09 - train: epoch 0051, iter [04400, 05004], lr: 0.010000, loss: 1.3678
2022-02-24 08:17:48 - train: epoch 0051, iter [04500, 05004], lr: 0.010000, loss: 1.1292
2022-02-24 08:18:30 - train: epoch 0051, iter [04600, 05004], lr: 0.010000, loss: 1.5053
2022-02-24 08:19:08 - train: epoch 0051, iter [04700, 05004], lr: 0.010000, loss: 1.4351
2022-02-24 08:19:51 - train: epoch 0051, iter [04800, 05004], lr: 0.010000, loss: 1.2634
2022-02-24 08:20:41 - train: epoch 0051, iter [04900, 05004], lr: 0.010000, loss: 1.4379
2022-02-24 08:21:32 - train: epoch 0051, iter [05000, 05004], lr: 0.010000, loss: 1.2708
2022-02-24 08:21:35 - train: epoch 051, train_loss: 1.3392
2022-02-24 08:23:00 - eval: epoch: 051, acc1: 71.280%, acc5: 90.600%, test_loss: 1.1391, per_image_load_time: 2.151ms, per_image_inference_time: 0.581ms
2022-02-24 08:23:00 - until epoch: 051, best_acc1: 72.062%
2022-02-24 08:23:00 - epoch 052 lr: 0.010000000000000002
2022-02-24 08:23:41 - train: epoch 0052, iter [00100, 05004], lr: 0.010000, loss: 1.1937
2022-02-24 08:24:14 - train: epoch 0052, iter [00200, 05004], lr: 0.010000, loss: 1.3494
2022-02-24 08:24:47 - train: epoch 0052, iter [00300, 05004], lr: 0.010000, loss: 1.3496
2022-02-24 08:25:21 - train: epoch 0052, iter [00400, 05004], lr: 0.010000, loss: 1.3811
2022-02-24 08:25:54 - train: epoch 0052, iter [00500, 05004], lr: 0.010000, loss: 1.4115
2022-02-24 08:26:28 - train: epoch 0052, iter [00600, 05004], lr: 0.010000, loss: 1.2591
2022-02-24 08:27:01 - train: epoch 0052, iter [00700, 05004], lr: 0.010000, loss: 1.3678
2022-02-24 08:27:35 - train: epoch 0052, iter [00800, 05004], lr: 0.010000, loss: 1.3080
2022-02-24 08:28:08 - train: epoch 0052, iter [00900, 05004], lr: 0.010000, loss: 1.3316
2022-02-24 08:28:42 - train: epoch 0052, iter [01000, 05004], lr: 0.010000, loss: 1.5653
2022-02-24 08:29:15 - train: epoch 0052, iter [01100, 05004], lr: 0.010000, loss: 1.3390
2022-02-24 08:29:48 - train: epoch 0052, iter [01200, 05004], lr: 0.010000, loss: 1.1961
2022-02-24 08:30:22 - train: epoch 0052, iter [01300, 05004], lr: 0.010000, loss: 1.2432
2022-02-24 08:30:55 - train: epoch 0052, iter [01400, 05004], lr: 0.010000, loss: 1.5008
2022-02-24 08:31:29 - train: epoch 0052, iter [01500, 05004], lr: 0.010000, loss: 1.2277
2022-02-24 08:32:03 - train: epoch 0052, iter [01600, 05004], lr: 0.010000, loss: 1.2318
2022-02-24 08:32:36 - train: epoch 0052, iter [01700, 05004], lr: 0.010000, loss: 1.2327
2022-02-24 08:33:10 - train: epoch 0052, iter [01800, 05004], lr: 0.010000, loss: 1.2097
2022-02-24 08:33:43 - train: epoch 0052, iter [01900, 05004], lr: 0.010000, loss: 1.3895
2022-02-24 08:34:18 - train: epoch 0052, iter [02000, 05004], lr: 0.010000, loss: 1.3565
2022-02-24 08:34:51 - train: epoch 0052, iter [02100, 05004], lr: 0.010000, loss: 1.1649
2022-02-24 08:35:25 - train: epoch 0052, iter [02200, 05004], lr: 0.010000, loss: 1.4418
2022-02-24 08:35:58 - train: epoch 0052, iter [02300, 05004], lr: 0.010000, loss: 1.1213
2022-02-24 08:36:32 - train: epoch 0052, iter [02400, 05004], lr: 0.010000, loss: 1.1550
2022-02-24 08:37:05 - train: epoch 0052, iter [02500, 05004], lr: 0.010000, loss: 1.3068
2022-02-24 08:37:39 - train: epoch 0052, iter [02600, 05004], lr: 0.010000, loss: 1.0987
2022-02-24 08:38:13 - train: epoch 0052, iter [02700, 05004], lr: 0.010000, loss: 1.2879
2022-02-24 08:38:46 - train: epoch 0052, iter [02800, 05004], lr: 0.010000, loss: 1.3280
2022-02-24 08:39:20 - train: epoch 0052, iter [02900, 05004], lr: 0.010000, loss: 1.1961
2022-02-24 08:39:54 - train: epoch 0052, iter [03000, 05004], lr: 0.010000, loss: 1.3728
2022-02-24 08:40:28 - train: epoch 0052, iter [03100, 05004], lr: 0.010000, loss: 1.3755
2022-02-24 08:41:02 - train: epoch 0052, iter [03200, 05004], lr: 0.010000, loss: 1.4172
2022-02-24 08:41:36 - train: epoch 0052, iter [03300, 05004], lr: 0.010000, loss: 1.4097
2022-02-24 08:42:10 - train: epoch 0052, iter [03400, 05004], lr: 0.010000, loss: 1.4281
2022-02-24 08:42:44 - train: epoch 0052, iter [03500, 05004], lr: 0.010000, loss: 1.4317
2022-02-24 08:43:18 - train: epoch 0052, iter [03600, 05004], lr: 0.010000, loss: 1.3976
2022-02-24 08:43:52 - train: epoch 0052, iter [03700, 05004], lr: 0.010000, loss: 1.5174
2022-02-24 08:44:26 - train: epoch 0052, iter [03800, 05004], lr: 0.010000, loss: 1.1652
2022-02-24 08:45:00 - train: epoch 0052, iter [03900, 05004], lr: 0.010000, loss: 1.2653
2022-02-24 08:45:35 - train: epoch 0052, iter [04000, 05004], lr: 0.010000, loss: 1.5152
2022-02-24 08:46:10 - train: epoch 0052, iter [04100, 05004], lr: 0.010000, loss: 1.2127
2022-02-24 08:46:45 - train: epoch 0052, iter [04200, 05004], lr: 0.010000, loss: 1.2366
2022-02-24 08:47:20 - train: epoch 0052, iter [04300, 05004], lr: 0.010000, loss: 1.3385
2022-02-24 08:47:54 - train: epoch 0052, iter [04400, 05004], lr: 0.010000, loss: 1.3735
2022-02-24 08:48:34 - train: epoch 0052, iter [04500, 05004], lr: 0.010000, loss: 1.1922
2022-02-24 08:49:13 - train: epoch 0052, iter [04600, 05004], lr: 0.010000, loss: 1.5370
2022-02-24 08:49:51 - train: epoch 0052, iter [04700, 05004], lr: 0.010000, loss: 1.3189
2022-02-24 08:50:37 - train: epoch 0052, iter [04800, 05004], lr: 0.010000, loss: 1.1997
2022-02-24 08:51:25 - train: epoch 0052, iter [04900, 05004], lr: 0.010000, loss: 1.1583
2022-02-24 08:52:06 - train: epoch 0052, iter [05000, 05004], lr: 0.010000, loss: 1.2884
2022-02-24 08:52:09 - train: epoch 052, train_loss: 1.3353
2022-02-24 08:53:33 - eval: epoch: 052, acc1: 71.268%, acc5: 90.706%, test_loss: 1.1362, per_image_load_time: 0.763ms, per_image_inference_time: 0.577ms
2022-02-24 08:53:34 - until epoch: 052, best_acc1: 72.062%
2022-02-24 08:53:34 - epoch 053 lr: 0.010000000000000002
2022-02-24 08:54:15 - train: epoch 0053, iter [00100, 05004], lr: 0.010000, loss: 1.3338
2022-02-24 08:54:48 - train: epoch 0053, iter [00200, 05004], lr: 0.010000, loss: 1.4816
2022-02-24 08:55:22 - train: epoch 0053, iter [00300, 05004], lr: 0.010000, loss: 1.2835
2022-02-24 08:55:55 - train: epoch 0053, iter [00400, 05004], lr: 0.010000, loss: 1.3940
2022-02-24 08:56:28 - train: epoch 0053, iter [00500, 05004], lr: 0.010000, loss: 1.5043
2022-02-24 08:57:02 - train: epoch 0053, iter [00600, 05004], lr: 0.010000, loss: 1.3525
2022-02-24 08:57:35 - train: epoch 0053, iter [00700, 05004], lr: 0.010000, loss: 1.1789
2022-02-24 08:58:08 - train: epoch 0053, iter [00800, 05004], lr: 0.010000, loss: 1.4415
2022-02-24 08:58:42 - train: epoch 0053, iter [00900, 05004], lr: 0.010000, loss: 1.2445
2022-02-24 08:59:15 - train: epoch 0053, iter [01000, 05004], lr: 0.010000, loss: 1.2856
2022-02-24 08:59:48 - train: epoch 0053, iter [01100, 05004], lr: 0.010000, loss: 1.2989
2022-02-24 09:00:22 - train: epoch 0053, iter [01200, 05004], lr: 0.010000, loss: 1.2889
2022-02-24 09:00:55 - train: epoch 0053, iter [01300, 05004], lr: 0.010000, loss: 1.3623
2022-02-24 09:01:29 - train: epoch 0053, iter [01400, 05004], lr: 0.010000, loss: 1.5101
2022-02-24 09:02:02 - train: epoch 0053, iter [01500, 05004], lr: 0.010000, loss: 1.3295
2022-02-24 09:02:36 - train: epoch 0053, iter [01600, 05004], lr: 0.010000, loss: 1.6237
2022-02-24 09:03:09 - train: epoch 0053, iter [01700, 05004], lr: 0.010000, loss: 1.4330
2022-02-24 09:03:43 - train: epoch 0053, iter [01800, 05004], lr: 0.010000, loss: 1.4509
2022-02-24 09:04:16 - train: epoch 0053, iter [01900, 05004], lr: 0.010000, loss: 1.0888
2022-02-24 09:04:50 - train: epoch 0053, iter [02000, 05004], lr: 0.010000, loss: 1.4061
2022-02-24 09:05:24 - train: epoch 0053, iter [02100, 05004], lr: 0.010000, loss: 1.3418
2022-02-24 09:05:58 - train: epoch 0053, iter [02200, 05004], lr: 0.010000, loss: 1.2250
2022-02-24 09:06:32 - train: epoch 0053, iter [02300, 05004], lr: 0.010000, loss: 1.3264
2022-02-24 09:07:05 - train: epoch 0053, iter [02400, 05004], lr: 0.010000, loss: 1.4015
2022-02-24 09:07:39 - train: epoch 0053, iter [02500, 05004], lr: 0.010000, loss: 1.6000
2022-02-24 09:08:13 - train: epoch 0053, iter [02600, 05004], lr: 0.010000, loss: 1.2834
2022-02-24 09:08:47 - train: epoch 0053, iter [02700, 05004], lr: 0.010000, loss: 1.5082
2022-02-24 09:09:22 - train: epoch 0053, iter [02800, 05004], lr: 0.010000, loss: 1.4228
2022-02-24 09:09:56 - train: epoch 0053, iter [02900, 05004], lr: 0.010000, loss: 1.1658
2022-02-24 09:10:31 - train: epoch 0053, iter [03000, 05004], lr: 0.010000, loss: 1.2133
2022-02-24 09:11:06 - train: epoch 0053, iter [03100, 05004], lr: 0.010000, loss: 1.4208
2022-02-24 09:11:42 - train: epoch 0053, iter [03200, 05004], lr: 0.010000, loss: 1.4858
2022-02-24 09:12:16 - train: epoch 0053, iter [03300, 05004], lr: 0.010000, loss: 1.3794
2022-02-24 09:12:52 - train: epoch 0053, iter [03400, 05004], lr: 0.010000, loss: 1.4158
2022-02-24 09:13:28 - train: epoch 0053, iter [03500, 05004], lr: 0.010000, loss: 1.3930
2022-02-24 09:14:02 - train: epoch 0053, iter [03600, 05004], lr: 0.010000, loss: 1.4159
2022-02-24 09:14:37 - train: epoch 0053, iter [03700, 05004], lr: 0.010000, loss: 1.5008
2022-02-24 09:15:12 - train: epoch 0053, iter [03800, 05004], lr: 0.010000, loss: 1.2529
2022-02-24 09:15:47 - train: epoch 0053, iter [03900, 05004], lr: 0.010000, loss: 1.4733
2022-02-24 09:16:22 - train: epoch 0053, iter [04000, 05004], lr: 0.010000, loss: 1.3417
2022-02-24 09:16:57 - train: epoch 0053, iter [04100, 05004], lr: 0.010000, loss: 1.3817
2022-02-24 09:17:33 - train: epoch 0053, iter [04200, 05004], lr: 0.010000, loss: 1.4212
2022-02-24 09:18:08 - train: epoch 0053, iter [04300, 05004], lr: 0.010000, loss: 1.5461
2022-02-24 09:18:45 - train: epoch 0053, iter [04400, 05004], lr: 0.010000, loss: 1.2682
2022-02-24 09:19:25 - train: epoch 0053, iter [04500, 05004], lr: 0.010000, loss: 1.4168
2022-02-24 09:20:04 - train: epoch 0053, iter [04600, 05004], lr: 0.010000, loss: 1.2507
2022-02-24 09:20:42 - train: epoch 0053, iter [04700, 05004], lr: 0.010000, loss: 1.5053
2022-02-24 09:21:25 - train: epoch 0053, iter [04800, 05004], lr: 0.010000, loss: 1.5325
2022-02-24 09:22:02 - train: epoch 0053, iter [04900, 05004], lr: 0.010000, loss: 1.2592
2022-02-24 09:22:45 - train: epoch 0053, iter [05000, 05004], lr: 0.010000, loss: 1.2975
2022-02-24 09:22:48 - train: epoch 053, train_loss: 1.3334
2022-02-24 09:24:18 - eval: epoch: 053, acc1: 71.812%, acc5: 90.992%, test_loss: 1.1192, per_image_load_time: 2.909ms, per_image_inference_time: 0.545ms
2022-02-24 09:24:18 - until epoch: 053, best_acc1: 72.062%
2022-02-24 09:24:18 - epoch 054 lr: 0.010000000000000002
2022-02-24 09:24:59 - train: epoch 0054, iter [00100, 05004], lr: 0.010000, loss: 1.1483
2022-02-24 09:25:32 - train: epoch 0054, iter [00200, 05004], lr: 0.010000, loss: 1.6974
2022-02-24 09:26:06 - train: epoch 0054, iter [00300, 05004], lr: 0.010000, loss: 1.3401
2022-02-24 09:26:39 - train: epoch 0054, iter [00400, 05004], lr: 0.010000, loss: 1.1726
2022-02-24 09:27:13 - train: epoch 0054, iter [00500, 05004], lr: 0.010000, loss: 1.3531
2022-02-24 09:27:46 - train: epoch 0054, iter [00600, 05004], lr: 0.010000, loss: 1.2438
2022-02-24 09:28:20 - train: epoch 0054, iter [00700, 05004], lr: 0.010000, loss: 1.4293
2022-02-24 09:28:54 - train: epoch 0054, iter [00800, 05004], lr: 0.010000, loss: 1.4492
2022-02-24 09:29:27 - train: epoch 0054, iter [00900, 05004], lr: 0.010000, loss: 1.1802
2022-02-24 09:30:01 - train: epoch 0054, iter [01000, 05004], lr: 0.010000, loss: 1.0773
2022-02-24 09:30:35 - train: epoch 0054, iter [01100, 05004], lr: 0.010000, loss: 1.2226
2022-02-24 09:31:08 - train: epoch 0054, iter [01200, 05004], lr: 0.010000, loss: 1.5267
2022-02-24 09:31:42 - train: epoch 0054, iter [01300, 05004], lr: 0.010000, loss: 1.2593
2022-02-24 09:32:15 - train: epoch 0054, iter [01400, 05004], lr: 0.010000, loss: 1.3468
2022-02-24 09:32:49 - train: epoch 0054, iter [01500, 05004], lr: 0.010000, loss: 1.3741
2022-02-24 09:33:23 - train: epoch 0054, iter [01600, 05004], lr: 0.010000, loss: 1.0190
2022-02-24 09:33:57 - train: epoch 0054, iter [01700, 05004], lr: 0.010000, loss: 1.3633
2022-02-24 09:34:31 - train: epoch 0054, iter [01800, 05004], lr: 0.010000, loss: 1.2602
2022-02-24 09:35:06 - train: epoch 0054, iter [01900, 05004], lr: 0.010000, loss: 1.5941
2022-02-24 09:35:41 - train: epoch 0054, iter [02000, 05004], lr: 0.010000, loss: 1.3168
2022-02-24 09:36:15 - train: epoch 0054, iter [02100, 05004], lr: 0.010000, loss: 1.2217
2022-02-24 09:36:49 - train: epoch 0054, iter [02200, 05004], lr: 0.010000, loss: 1.2925
2022-02-24 09:37:22 - train: epoch 0054, iter [02300, 05004], lr: 0.010000, loss: 1.3621
2022-02-24 09:37:56 - train: epoch 0054, iter [02400, 05004], lr: 0.010000, loss: 1.2654
2022-02-24 09:38:30 - train: epoch 0054, iter [02500, 05004], lr: 0.010000, loss: 1.3579
2022-02-24 09:39:04 - train: epoch 0054, iter [02600, 05004], lr: 0.010000, loss: 1.2724
2022-02-24 09:39:38 - train: epoch 0054, iter [02700, 05004], lr: 0.010000, loss: 1.3339
2022-02-24 09:40:11 - train: epoch 0054, iter [02800, 05004], lr: 0.010000, loss: 1.5447
2022-02-24 09:40:45 - train: epoch 0054, iter [02900, 05004], lr: 0.010000, loss: 1.1768
2022-02-24 09:41:19 - train: epoch 0054, iter [03000, 05004], lr: 0.010000, loss: 1.4071
2022-02-24 09:41:53 - train: epoch 0054, iter [03100, 05004], lr: 0.010000, loss: 1.2909
2022-02-24 09:42:27 - train: epoch 0054, iter [03200, 05004], lr: 0.010000, loss: 1.5136
2022-02-24 09:43:01 - train: epoch 0054, iter [03300, 05004], lr: 0.010000, loss: 1.3601
2022-02-24 09:43:34 - train: epoch 0054, iter [03400, 05004], lr: 0.010000, loss: 1.4117
2022-02-24 09:44:08 - train: epoch 0054, iter [03500, 05004], lr: 0.010000, loss: 1.4110
2022-02-24 09:44:42 - train: epoch 0054, iter [03600, 05004], lr: 0.010000, loss: 1.2525
2022-02-24 09:45:16 - train: epoch 0054, iter [03700, 05004], lr: 0.010000, loss: 1.2335
2022-02-24 09:45:51 - train: epoch 0054, iter [03800, 05004], lr: 0.010000, loss: 1.4125
2022-02-24 09:46:25 - train: epoch 0054, iter [03900, 05004], lr: 0.010000, loss: 1.3082
2022-02-24 09:47:00 - train: epoch 0054, iter [04000, 05004], lr: 0.010000, loss: 1.2028
2022-02-24 09:47:34 - train: epoch 0054, iter [04100, 05004], lr: 0.010000, loss: 1.3182
2022-02-24 09:48:09 - train: epoch 0054, iter [04200, 05004], lr: 0.010000, loss: 1.2919
2022-02-24 09:48:43 - train: epoch 0054, iter [04300, 05004], lr: 0.010000, loss: 1.3711
2022-02-24 09:49:19 - train: epoch 0054, iter [04400, 05004], lr: 0.010000, loss: 1.1886
2022-02-24 09:49:58 - train: epoch 0054, iter [04500, 05004], lr: 0.010000, loss: 1.1566
2022-02-24 09:50:35 - train: epoch 0054, iter [04600, 05004], lr: 0.010000, loss: 1.3955
2022-02-24 09:51:18 - train: epoch 0054, iter [04700, 05004], lr: 0.010000, loss: 1.4281
2022-02-24 09:52:04 - train: epoch 0054, iter [04800, 05004], lr: 0.010000, loss: 1.5089
2022-02-24 09:52:50 - train: epoch 0054, iter [04900, 05004], lr: 0.010000, loss: 1.2060
2022-02-24 09:53:30 - train: epoch 0054, iter [05000, 05004], lr: 0.010000, loss: 1.3898
2022-02-24 09:53:34 - train: epoch 054, train_loss: 1.3339
2022-02-24 09:55:09 - eval: epoch: 054, acc1: 71.030%, acc5: 90.512%, test_loss: 1.1489, per_image_load_time: 3.135ms, per_image_inference_time: 0.522ms
2022-02-24 09:55:09 - until epoch: 054, best_acc1: 72.062%
2022-02-24 09:55:09 - epoch 055 lr: 0.010000000000000002
2022-02-24 09:55:50 - train: epoch 0055, iter [00100, 05004], lr: 0.010000, loss: 1.3575
2022-02-24 09:56:23 - train: epoch 0055, iter [00200, 05004], lr: 0.010000, loss: 1.1958
2022-02-24 09:56:56 - train: epoch 0055, iter [00300, 05004], lr: 0.010000, loss: 1.1499
2022-02-24 09:57:30 - train: epoch 0055, iter [00400, 05004], lr: 0.010000, loss: 1.2420
2022-02-24 09:58:04 - train: epoch 0055, iter [00500, 05004], lr: 0.010000, loss: 1.1406
2022-02-24 09:58:37 - train: epoch 0055, iter [00600, 05004], lr: 0.010000, loss: 1.2245
2022-02-24 09:59:10 - train: epoch 0055, iter [00700, 05004], lr: 0.010000, loss: 1.3951
2022-02-24 09:59:44 - train: epoch 0055, iter [00800, 05004], lr: 0.010000, loss: 1.1417
2022-02-24 10:00:17 - train: epoch 0055, iter [00900, 05004], lr: 0.010000, loss: 1.3214
2022-02-24 10:00:51 - train: epoch 0055, iter [01000, 05004], lr: 0.010000, loss: 1.4068
2022-02-24 10:01:25 - train: epoch 0055, iter [01100, 05004], lr: 0.010000, loss: 1.2004
2022-02-24 10:01:59 - train: epoch 0055, iter [01200, 05004], lr: 0.010000, loss: 1.3210
2022-02-24 10:02:33 - train: epoch 0055, iter [01300, 05004], lr: 0.010000, loss: 1.4019
2022-02-24 10:03:08 - train: epoch 0055, iter [01400, 05004], lr: 0.010000, loss: 1.2879
2022-02-24 10:03:42 - train: epoch 0055, iter [01500, 05004], lr: 0.010000, loss: 1.3383
2022-02-24 10:04:17 - train: epoch 0055, iter [01600, 05004], lr: 0.010000, loss: 1.4680
2022-02-24 10:04:51 - train: epoch 0055, iter [01700, 05004], lr: 0.010000, loss: 1.4128
2022-02-24 10:05:24 - train: epoch 0055, iter [01800, 05004], lr: 0.010000, loss: 1.4392
2022-02-24 10:05:58 - train: epoch 0055, iter [01900, 05004], lr: 0.010000, loss: 1.3367
2022-02-24 10:06:31 - train: epoch 0055, iter [02000, 05004], lr: 0.010000, loss: 1.3756
2022-02-24 10:07:05 - train: epoch 0055, iter [02100, 05004], lr: 0.010000, loss: 1.1482
2022-02-24 10:07:39 - train: epoch 0055, iter [02200, 05004], lr: 0.010000, loss: 1.4424
2022-02-24 10:08:12 - train: epoch 0055, iter [02300, 05004], lr: 0.010000, loss: 1.2531
2022-02-24 10:08:46 - train: epoch 0055, iter [02400, 05004], lr: 0.010000, loss: 1.2583
2022-02-24 10:09:20 - train: epoch 0055, iter [02500, 05004], lr: 0.010000, loss: 1.3613
2022-02-24 10:09:54 - train: epoch 0055, iter [02600, 05004], lr: 0.010000, loss: 1.2909
2022-02-24 10:10:27 - train: epoch 0055, iter [02700, 05004], lr: 0.010000, loss: 1.1865
2022-02-24 10:11:01 - train: epoch 0055, iter [02800, 05004], lr: 0.010000, loss: 1.2869
2022-02-24 10:11:35 - train: epoch 0055, iter [02900, 05004], lr: 0.010000, loss: 1.4115
2022-02-24 10:12:09 - train: epoch 0055, iter [03000, 05004], lr: 0.010000, loss: 1.3060
2022-02-24 10:12:43 - train: epoch 0055, iter [03100, 05004], lr: 0.010000, loss: 1.4842
2022-02-24 10:13:16 - train: epoch 0055, iter [03200, 05004], lr: 0.010000, loss: 1.2876
2022-02-24 10:13:51 - train: epoch 0055, iter [03300, 05004], lr: 0.010000, loss: 1.1551
2022-02-24 10:14:25 - train: epoch 0055, iter [03400, 05004], lr: 0.010000, loss: 1.2521
2022-02-24 10:15:00 - train: epoch 0055, iter [03500, 05004], lr: 0.010000, loss: 1.1632
2022-02-24 10:15:33 - train: epoch 0055, iter [03600, 05004], lr: 0.010000, loss: 1.3277
2022-02-24 10:16:08 - train: epoch 0055, iter [03700, 05004], lr: 0.010000, loss: 1.3408
2022-02-24 10:16:42 - train: epoch 0055, iter [03800, 05004], lr: 0.010000, loss: 1.4412
2022-02-24 10:17:16 - train: epoch 0055, iter [03900, 05004], lr: 0.010000, loss: 1.6446
2022-02-24 10:17:53 - train: epoch 0055, iter [04000, 05004], lr: 0.010000, loss: 1.3659
2022-02-24 10:18:41 - train: epoch 0055, iter [04100, 05004], lr: 0.010000, loss: 1.3412
2022-02-24 10:19:19 - train: epoch 0055, iter [04200, 05004], lr: 0.010000, loss: 1.2801
2022-02-24 10:20:01 - train: epoch 0055, iter [04300, 05004], lr: 0.010000, loss: 1.4100
2022-02-24 10:20:36 - train: epoch 0055, iter [04400, 05004], lr: 0.010000, loss: 1.5267
2022-02-24 10:21:13 - train: epoch 0055, iter [04500, 05004], lr: 0.010000, loss: 1.3718
2022-02-24 10:21:54 - train: epoch 0055, iter [04600, 05004], lr: 0.010000, loss: 1.4194
2022-02-24 10:22:34 - train: epoch 0055, iter [04700, 05004], lr: 0.010000, loss: 1.1436
2022-02-24 10:23:37 - train: epoch 0055, iter [04800, 05004], lr: 0.010000, loss: 1.3781
2022-02-24 10:25:04 - train: epoch 0055, iter [04900, 05004], lr: 0.010000, loss: 1.3261
2022-02-24 10:25:49 - train: epoch 0055, iter [05000, 05004], lr: 0.010000, loss: 1.3311
2022-02-24 10:25:52 - train: epoch 055, train_loss: 1.3296
2022-02-24 10:27:30 - eval: epoch: 055, acc1: 71.136%, acc5: 90.516%, test_loss: 1.1423, per_image_load_time: 1.941ms, per_image_inference_time: 0.540ms
2022-02-24 10:27:31 - until epoch: 055, best_acc1: 72.062%
2022-02-24 10:27:31 - epoch 056 lr: 0.010000000000000002
2022-02-24 10:28:11 - train: epoch 0056, iter [00100, 05004], lr: 0.010000, loss: 1.3871
2022-02-24 10:28:44 - train: epoch 0056, iter [00200, 05004], lr: 0.010000, loss: 1.4928
2022-02-24 10:29:17 - train: epoch 0056, iter [00300, 05004], lr: 0.010000, loss: 1.3114
2022-02-24 10:29:51 - train: epoch 0056, iter [00400, 05004], lr: 0.010000, loss: 1.2472
2022-02-24 10:30:24 - train: epoch 0056, iter [00500, 05004], lr: 0.010000, loss: 1.2619
2022-02-24 10:30:57 - train: epoch 0056, iter [00600, 05004], lr: 0.010000, loss: 1.3406
2022-02-24 10:31:31 - train: epoch 0056, iter [00700, 05004], lr: 0.010000, loss: 1.3174
2022-02-24 10:32:04 - train: epoch 0056, iter [00800, 05004], lr: 0.010000, loss: 1.5279
2022-02-24 10:32:38 - train: epoch 0056, iter [00900, 05004], lr: 0.010000, loss: 1.4455
2022-02-24 10:33:11 - train: epoch 0056, iter [01000, 05004], lr: 0.010000, loss: 1.3152
2022-02-24 10:33:45 - train: epoch 0056, iter [01100, 05004], lr: 0.010000, loss: 1.2190
2022-02-24 10:34:18 - train: epoch 0056, iter [01200, 05004], lr: 0.010000, loss: 1.2371
2022-02-24 10:34:52 - train: epoch 0056, iter [01300, 05004], lr: 0.010000, loss: 1.4304
2022-02-24 10:35:25 - train: epoch 0056, iter [01400, 05004], lr: 0.010000, loss: 1.2615
2022-02-24 10:35:58 - train: epoch 0056, iter [01500, 05004], lr: 0.010000, loss: 1.5590
2022-02-24 10:36:32 - train: epoch 0056, iter [01600, 05004], lr: 0.010000, loss: 1.1790
2022-02-24 10:37:06 - train: epoch 0056, iter [01700, 05004], lr: 0.010000, loss: 1.4433
2022-02-24 10:37:39 - train: epoch 0056, iter [01800, 05004], lr: 0.010000, loss: 1.6777
2022-02-24 10:38:13 - train: epoch 0056, iter [01900, 05004], lr: 0.010000, loss: 1.3274
2022-02-24 10:38:46 - train: epoch 0056, iter [02000, 05004], lr: 0.010000, loss: 1.2309
2022-02-24 10:39:20 - train: epoch 0056, iter [02100, 05004], lr: 0.010000, loss: 1.3686
2022-02-24 10:39:53 - train: epoch 0056, iter [02200, 05004], lr: 0.010000, loss: 1.4619
2022-02-24 10:40:27 - train: epoch 0056, iter [02300, 05004], lr: 0.010000, loss: 1.4661
2022-02-24 10:41:01 - train: epoch 0056, iter [02400, 05004], lr: 0.010000, loss: 1.3288
2022-02-24 10:41:35 - train: epoch 0056, iter [02500, 05004], lr: 0.010000, loss: 1.5064
2022-02-24 10:42:08 - train: epoch 0056, iter [02600, 05004], lr: 0.010000, loss: 1.2688
2022-02-24 10:42:42 - train: epoch 0056, iter [02700, 05004], lr: 0.010000, loss: 1.3704
2022-02-24 10:43:16 - train: epoch 0056, iter [02800, 05004], lr: 0.010000, loss: 1.2402
2022-02-24 10:43:50 - train: epoch 0056, iter [02900, 05004], lr: 0.010000, loss: 1.4857
2022-02-24 10:44:26 - train: epoch 0056, iter [03000, 05004], lr: 0.010000, loss: 1.4038
2022-02-24 10:45:02 - train: epoch 0056, iter [03100, 05004], lr: 0.010000, loss: 1.2694
2022-02-24 10:45:36 - train: epoch 0056, iter [03200, 05004], lr: 0.010000, loss: 1.1849
2022-02-24 10:46:12 - train: epoch 0056, iter [03300, 05004], lr: 0.010000, loss: 1.5243
2022-02-24 10:46:46 - train: epoch 0056, iter [03400, 05004], lr: 0.010000, loss: 1.1484
2022-02-24 10:47:20 - train: epoch 0056, iter [03500, 05004], lr: 0.010000, loss: 1.2436
2022-02-24 10:47:55 - train: epoch 0056, iter [03600, 05004], lr: 0.010000, loss: 1.0723
2022-02-24 10:48:29 - train: epoch 0056, iter [03700, 05004], lr: 0.010000, loss: 1.1969
2022-02-24 10:49:04 - train: epoch 0056, iter [03800, 05004], lr: 0.010000, loss: 1.2413
2022-02-24 10:49:38 - train: epoch 0056, iter [03900, 05004], lr: 0.010000, loss: 1.5487
2022-02-24 10:50:13 - train: epoch 0056, iter [04000, 05004], lr: 0.010000, loss: 1.3148
2022-02-24 10:50:47 - train: epoch 0056, iter [04100, 05004], lr: 0.010000, loss: 1.5528
2022-02-24 10:51:22 - train: epoch 0056, iter [04200, 05004], lr: 0.010000, loss: 1.2886
2022-02-24 10:51:59 - train: epoch 0056, iter [04300, 05004], lr: 0.010000, loss: 1.3032
2022-02-24 10:52:33 - train: epoch 0056, iter [04400, 05004], lr: 0.010000, loss: 1.4076
2022-02-24 10:53:13 - train: epoch 0056, iter [04500, 05004], lr: 0.010000, loss: 1.3698
2022-02-24 10:53:53 - train: epoch 0056, iter [04600, 05004], lr: 0.010000, loss: 1.3770
2022-02-24 10:54:31 - train: epoch 0056, iter [04700, 05004], lr: 0.010000, loss: 1.3740
2022-02-24 10:55:18 - train: epoch 0056, iter [04800, 05004], lr: 0.010000, loss: 1.4426
2022-02-24 10:56:07 - train: epoch 0056, iter [04900, 05004], lr: 0.010000, loss: 1.3136
2022-02-24 10:57:00 - train: epoch 0056, iter [05000, 05004], lr: 0.010000, loss: 1.3560
2022-02-24 10:57:03 - train: epoch 056, train_loss: 1.3246
2022-02-24 10:58:26 - eval: epoch: 056, acc1: 71.640%, acc5: 90.652%, test_loss: 1.1294, per_image_load_time: 2.084ms, per_image_inference_time: 0.629ms
2022-02-24 10:58:26 - until epoch: 056, best_acc1: 72.062%
2022-02-24 10:58:26 - epoch 057 lr: 0.010000000000000002
2022-02-24 10:59:08 - train: epoch 0057, iter [00100, 05004], lr: 0.010000, loss: 1.4165
2022-02-24 10:59:41 - train: epoch 0057, iter [00200, 05004], lr: 0.010000, loss: 1.3052
2022-02-24 11:00:15 - train: epoch 0057, iter [00300, 05004], lr: 0.010000, loss: 1.1843
2022-02-24 11:00:48 - train: epoch 0057, iter [00400, 05004], lr: 0.010000, loss: 1.2681
2022-02-24 11:01:22 - train: epoch 0057, iter [00500, 05004], lr: 0.010000, loss: 1.1269
2022-02-24 11:01:56 - train: epoch 0057, iter [00600, 05004], lr: 0.010000, loss: 1.3991
2022-02-24 11:02:29 - train: epoch 0057, iter [00700, 05004], lr: 0.010000, loss: 1.1107
2022-02-24 11:03:02 - train: epoch 0057, iter [00800, 05004], lr: 0.010000, loss: 1.2655
2022-02-24 11:03:36 - train: epoch 0057, iter [00900, 05004], lr: 0.010000, loss: 1.3779
2022-02-24 11:04:10 - train: epoch 0057, iter [01000, 05004], lr: 0.010000, loss: 1.2115
2022-02-24 11:04:43 - train: epoch 0057, iter [01100, 05004], lr: 0.010000, loss: 1.1686
2022-02-24 11:05:17 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 1.2349
2022-02-24 11:05:50 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 1.3041
2022-02-24 11:06:24 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 1.3624
2022-02-24 11:06:58 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 1.4038
2022-02-24 11:07:31 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 1.4092
2022-02-24 11:08:05 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 1.5699
2022-02-24 11:08:38 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 1.4163
2022-02-24 11:09:12 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 1.1984
2022-02-24 11:09:46 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 1.3547
2022-02-24 11:10:20 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 1.3545
2022-02-24 11:10:54 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 1.4281
2022-02-24 11:11:27 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 1.3053
2022-02-24 11:12:01 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 1.1950
2022-02-24 11:12:34 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 1.2966
2022-02-24 11:13:08 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 1.2065
2022-02-24 11:13:42 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 1.1216
2022-02-24 11:14:15 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 1.0708
2022-02-24 11:14:50 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 1.3765
2022-02-24 11:15:23 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 1.4272
2022-02-24 11:15:58 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 1.4819
2022-02-24 11:16:31 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 1.4223
2022-02-24 11:17:05 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 1.3882
2022-02-24 11:17:40 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 1.2555
2022-02-24 11:18:14 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 1.3341
2022-02-24 11:18:49 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 1.2995
2022-02-24 11:19:23 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 1.2954
2022-02-24 11:19:58 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 1.3002
2022-02-24 11:20:32 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 1.5059
2022-02-24 11:21:07 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 1.2172
2022-02-24 11:21:42 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 1.3858
2022-02-24 11:22:17 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 1.4310
2022-02-24 11:22:53 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 1.2853
2022-02-24 11:23:28 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 1.3460
2022-02-24 11:24:10 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 1.4001
2022-02-24 11:25:24 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 1.5340
2022-02-24 11:26:29 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 1.1542
2022-02-24 11:27:06 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 1.5349
2022-02-24 11:27:53 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 1.5778
2022-02-24 11:28:45 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 1.5077
2022-02-24 11:28:48 - train: epoch 057, train_loss: 1.3244
2022-02-24 11:30:19 - eval: epoch: 057, acc1: 71.196%, acc5: 90.808%, test_loss: 1.1404, per_image_load_time: 1.057ms, per_image_inference_time: 0.583ms
2022-02-24 11:30:20 - until epoch: 057, best_acc1: 72.062%
2022-02-24 11:30:20 - epoch 058 lr: 0.010000000000000002
2022-02-24 11:31:00 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 1.3252
2022-02-24 11:31:34 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 1.1385
2022-02-24 11:32:07 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 1.3445
2022-02-24 11:32:40 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 1.2880
2022-02-24 11:33:14 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 1.1871
2022-02-24 11:33:47 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 1.4676
2022-02-24 11:34:21 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 1.2995
2022-02-24 11:34:54 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 1.2013
2022-02-24 11:35:29 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 1.1497
2022-02-24 11:36:02 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 1.3739
2022-02-24 11:36:36 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 1.2009
2022-02-24 11:37:10 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 1.2394
2022-02-24 11:37:43 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 1.3159
2022-02-24 11:38:17 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 1.3415
2022-02-24 11:38:51 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 1.3628
2022-02-24 11:39:25 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 1.2376
2022-02-24 11:39:58 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 1.4924
2022-02-24 11:40:32 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 1.3654
2022-02-24 11:41:06 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 1.4811
2022-02-24 11:41:40 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 1.3734
2022-02-24 11:42:15 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 1.2827
2022-02-24 11:42:48 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 1.0523
2022-02-24 11:43:23 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 1.2588
2022-02-24 11:43:57 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 1.3175
2022-02-24 11:44:31 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 1.4042
2022-02-24 11:45:05 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 1.2274
2022-02-24 11:45:38 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 1.4982
2022-02-24 11:46:13 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 1.1194
2022-02-24 11:46:47 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 1.3026
2022-02-24 11:47:22 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 1.4495
2022-02-24 11:47:56 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 1.1695
2022-02-24 11:48:30 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 1.1872
2022-02-24 11:49:04 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 1.3313
2022-02-24 11:49:39 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 1.1581
2022-02-24 11:50:13 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 1.2924
2022-02-24 11:50:47 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 1.2157
2022-02-24 11:51:23 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 1.3683
2022-02-24 11:51:57 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 1.3254
2022-02-24 11:52:32 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 1.3829
2022-02-24 11:53:07 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 1.4315
2022-02-24 11:53:41 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 1.3911
2022-02-24 11:54:16 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 1.1832
2022-02-24 11:55:04 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 1.5835
2022-02-24 11:55:38 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 1.1753
2022-02-24 11:56:19 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 1.3568
2022-02-24 11:56:59 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 1.3042
2022-02-24 11:57:37 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 1.3267
2022-02-24 11:58:24 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 1.4068
2022-02-24 11:59:12 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 1.2945
2022-02-24 11:59:58 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 1.2905
2022-02-24 12:00:02 - train: epoch 058, train_loss: 1.3213
2022-02-24 12:01:31 - eval: epoch: 058, acc1: 71.470%, acc5: 90.800%, test_loss: 1.1323, per_image_load_time: 0.886ms, per_image_inference_time: 0.540ms
2022-02-24 12:01:32 - until epoch: 058, best_acc1: 72.062%
2022-02-24 12:01:32 - epoch 059 lr: 0.010000000000000002
2022-02-24 12:02:12 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 1.3803
2022-02-24 12:02:46 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 1.2788
2022-02-24 12:03:19 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 1.2900
2022-02-24 12:03:52 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 1.3212
2022-02-24 12:04:26 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 1.4733
2022-02-24 12:04:59 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 1.2748
2022-02-24 12:05:33 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 1.2475
2022-02-24 12:06:06 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 1.3659
2022-02-24 12:06:40 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 1.2756
2022-02-24 12:07:13 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 1.2740
2022-02-24 12:07:46 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 1.4715
2022-02-24 12:08:20 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 1.1873
2022-02-24 12:08:54 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 1.4818
2022-02-24 12:09:27 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 1.4258
2022-02-24 12:10:00 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 1.4459
2022-02-24 12:10:34 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 1.3218
2022-02-24 12:11:07 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 1.4158
2022-02-24 12:11:41 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 1.2783
2022-02-24 12:12:15 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 1.3660
2022-02-24 12:12:48 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 1.2516
2022-02-24 12:13:22 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 1.5511
2022-02-24 12:13:55 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 1.4862
2022-02-24 12:14:29 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 1.2592
2022-02-24 12:15:03 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 1.4639
2022-02-24 12:15:37 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 1.3781
2022-02-24 12:16:10 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 1.3143
2022-02-24 12:16:44 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 1.2097
2022-02-24 12:17:17 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 1.5021
2022-02-24 12:17:51 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 1.2921
2022-02-24 12:18:25 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 1.7727
2022-02-24 12:18:59 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 1.1618
2022-02-24 12:19:33 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 1.2780
2022-02-24 12:20:07 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 1.3733
2022-02-24 12:20:41 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 1.6321
2022-02-24 12:21:16 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 1.1777
2022-02-24 12:21:50 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 1.2999
2022-02-24 12:22:24 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 1.1768
2022-02-24 12:22:58 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 1.3411
2022-02-24 12:23:33 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 1.1632
2022-02-24 12:24:08 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 1.6526
2022-02-24 12:24:42 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 1.3592
2022-02-24 12:25:17 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 1.4136
2022-02-24 12:25:52 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 1.4917
2022-02-24 12:26:29 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 1.5046
2022-02-24 12:27:07 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 1.3756
2022-02-24 12:27:44 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 1.3617
2022-02-24 12:28:28 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 1.3298
2022-02-24 12:29:15 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 1.2004
2022-02-24 12:29:56 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 1.4639
2022-02-24 12:30:42 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 1.4883
2022-02-24 12:30:45 - train: epoch 059, train_loss: 1.3199
2022-02-24 12:32:16 - eval: epoch: 059, acc1: 71.378%, acc5: 90.654%, test_loss: 1.1364, per_image_load_time: 1.083ms, per_image_inference_time: 0.581ms
2022-02-24 12:32:17 - until epoch: 059, best_acc1: 72.062%
2022-02-24 12:32:17 - epoch 060 lr: 0.010000000000000002
2022-02-24 12:32:57 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 1.2214
2022-02-24 12:33:30 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 1.3724
2022-02-24 12:34:03 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 1.3306
2022-02-24 12:34:37 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 1.3757
2022-02-24 12:35:10 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 1.5472
2022-02-24 12:35:44 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 1.4036
2022-02-24 12:36:18 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 1.3237
2022-02-24 12:36:52 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 1.4825
2022-02-24 12:37:25 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 1.1022
2022-02-24 12:37:59 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 1.0261
2022-02-24 12:38:32 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 1.1053
2022-02-24 12:39:06 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 1.2494
2022-02-24 12:39:39 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 1.3078
2022-02-24 12:40:13 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 1.2829
2022-02-24 12:40:46 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 1.2796
2022-02-24 12:41:20 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 1.2745
2022-02-24 12:41:54 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 1.3458
2022-02-24 12:42:28 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 1.3436
2022-02-24 12:43:02 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 1.4732
2022-02-24 12:43:35 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 1.2532
2022-02-24 12:44:11 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 1.3562
2022-02-24 12:44:45 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 1.4366
2022-02-24 12:45:20 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 1.1073
2022-02-24 12:45:54 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 1.3378
2022-02-24 12:46:27 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 1.2658
2022-02-24 12:47:01 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 1.4221
2022-02-24 12:47:35 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 1.3371
2022-02-24 12:48:09 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 1.1990
2022-02-24 12:48:43 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 1.3169
2022-02-24 12:49:17 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 1.5171
2022-02-24 12:49:51 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 1.3818
2022-02-24 12:50:25 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 1.2309
2022-02-24 12:50:58 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 1.1768
2022-02-24 12:51:33 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 1.4151
2022-02-24 12:52:07 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 1.3178
2022-02-24 12:52:42 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 1.3004
2022-02-24 12:53:15 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 1.2939
2022-02-24 12:53:50 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 1.3368
2022-02-24 12:54:24 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 1.6885
2022-02-24 12:54:59 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 1.3053
2022-02-24 12:55:34 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 1.5398
2022-02-24 12:56:09 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 1.3653
2022-02-24 12:56:45 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 1.2888
2022-02-24 12:57:19 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 1.4677
2022-02-24 12:57:57 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 1.2880
2022-02-24 12:58:37 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 1.2210
2022-02-24 12:59:15 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 1.3826
2022-02-24 13:00:02 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 1.1264
2022-02-24 13:00:50 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 1.3020
2022-02-24 13:01:38 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 1.3735
2022-02-24 13:01:41 - train: epoch 060, train_loss: 1.3154
2022-02-24 13:03:09 - eval: epoch: 060, acc1: 71.530%, acc5: 90.858%, test_loss: 1.1180, per_image_load_time: 2.460ms, per_image_inference_time: 0.577ms
2022-02-24 13:03:09 - until epoch: 060, best_acc1: 72.062%
2022-02-24 13:03:09 - epoch 061 lr: 0.0010000000000000002
2022-02-24 13:03:50 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 1.1183
2022-02-24 13:04:23 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 1.2320
2022-02-24 13:04:57 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 0.9569
2022-02-24 13:05:30 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 1.3525
2022-02-24 13:06:04 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 1.1772
2022-02-24 13:06:38 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 1.1267
2022-02-24 13:07:11 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 0.8975
2022-02-24 13:07:44 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 1.2192
2022-02-24 13:08:18 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 1.0410
2022-02-24 13:08:52 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 0.9751
2022-02-24 13:09:25 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 1.0316
2022-02-24 13:09:59 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 1.0667
2022-02-24 13:10:32 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 1.0953
2022-02-24 13:11:06 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 0.9996
2022-02-24 13:11:39 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 1.2071
2022-02-24 13:12:12 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 0.9668
2022-02-24 13:12:46 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 1.1558
2022-02-24 13:13:19 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 1.1498
2022-02-24 13:13:53 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 1.2205
2022-02-24 13:14:26 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 1.0738
2022-02-24 13:14:59 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 1.4502
2022-02-24 13:15:33 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 1.0187
2022-02-24 13:16:07 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 1.0746
2022-02-24 13:16:40 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 0.8518
2022-02-24 13:17:13 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 1.0000
2022-02-24 13:17:47 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 1.1560
2022-02-24 13:18:21 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 1.2478
2022-02-24 13:18:55 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 1.0956
2022-02-24 13:19:29 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 1.2701
2022-02-24 13:20:03 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 1.0265
2022-02-24 13:20:36 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 1.1687
2022-02-24 13:21:10 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 1.1180
2022-02-24 13:21:44 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 1.0660
2022-02-24 13:22:18 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 1.0136
2022-02-24 13:22:52 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 1.1328
2022-02-24 13:23:26 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 1.0707
2022-02-24 13:24:00 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 1.1882
2022-02-24 13:24:34 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 1.1031
2022-02-24 13:25:09 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 1.1010
2022-02-24 13:25:43 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 1.0904
2022-02-24 13:26:18 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 1.2922
2022-02-24 13:26:53 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 0.9839
2022-02-24 13:27:28 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 1.0842
2022-02-24 13:28:04 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 1.1141
2022-02-24 13:28:41 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 1.0944
2022-02-24 13:29:22 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 1.1803
2022-02-24 13:30:03 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 1.1221
2022-02-24 13:30:42 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 1.0093
2022-02-24 13:31:30 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 1.2224
2022-02-24 13:32:23 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 1.1312
2022-02-24 13:32:25 - train: epoch 061, train_loss: 1.1022
2022-02-24 13:34:02 - eval: epoch: 061, acc1: 75.842%, acc5: 92.870%, test_loss: 0.9432, per_image_load_time: 3.131ms, per_image_inference_time: 0.572ms
2022-02-24 13:34:03 - until epoch: 061, best_acc1: 75.842%
2022-02-24 13:34:03 - epoch 062 lr: 0.0010000000000000002
2022-02-24 13:34:44 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 1.1224
2022-02-24 13:35:17 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 1.2187
2022-02-24 13:35:51 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 0.9832
2022-02-24 13:36:24 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 0.8597
2022-02-24 13:36:58 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 0.9144
2022-02-24 13:37:31 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 1.0143
2022-02-24 13:38:05 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 1.2491
2022-02-24 13:38:38 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 1.0769
2022-02-24 13:39:11 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 0.9803
2022-02-24 13:39:45 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 1.2637
2022-02-24 13:40:19 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 0.9369
2022-02-24 13:40:52 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 1.2171
2022-02-24 13:41:26 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 1.1524
2022-02-24 13:41:59 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 1.0487
2022-02-24 13:42:32 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 1.0985
2022-02-24 13:43:06 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 1.1648
2022-02-24 13:43:39 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 1.1408
2022-02-24 13:44:13 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 0.9840
2022-02-24 13:44:47 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 1.0687
2022-02-24 13:45:22 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 0.9960
2022-02-24 13:45:56 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 1.2073
2022-02-24 13:46:30 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 0.9577
2022-02-24 13:47:04 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 1.0711
2022-02-24 13:47:38 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 0.9407
2022-02-24 13:48:12 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 1.1155
2022-02-24 13:48:45 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 0.9672
2022-02-24 13:49:20 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 1.0536
2022-02-24 13:49:53 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 1.1950
2022-02-24 13:50:27 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 1.1227
2022-02-24 13:51:01 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 1.1717
2022-02-24 13:51:34 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 1.1070
2022-02-24 13:52:08 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 0.8934
2022-02-24 13:52:42 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 1.1456
2022-02-24 13:53:17 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 1.1099
2022-02-24 13:53:51 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 1.0601
2022-02-24 13:54:25 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 1.1460
2022-02-24 13:54:59 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 1.0638
2022-02-24 13:55:33 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 1.0252
2022-02-24 13:56:08 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 1.0239
2022-02-24 13:56:42 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 0.8656
2022-02-24 13:57:18 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 1.0990
2022-02-24 13:57:52 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 0.8893
2022-02-24 13:58:28 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 1.0513
2022-02-24 13:59:03 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 1.0360
2022-02-24 13:59:41 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 0.8987
2022-02-24 14:00:24 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 0.8745
2022-02-24 14:01:03 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 1.0542
2022-02-24 14:01:46 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 1.0045
2022-02-24 14:02:35 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 0.9740
2022-02-24 14:03:27 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 0.9916
2022-02-24 14:03:30 - train: epoch 062, train_loss: 1.0487
2022-02-24 14:04:58 - eval: epoch: 062, acc1: 76.056%, acc5: 93.006%, test_loss: 0.9293, per_image_load_time: 2.203ms, per_image_inference_time: 0.591ms
2022-02-24 14:04:59 - until epoch: 062, best_acc1: 76.056%
2022-02-24 14:04:59 - epoch 063 lr: 0.0010000000000000002
2022-02-24 14:05:40 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 1.1003
2022-02-24 14:06:13 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 0.9424
2022-02-24 14:06:46 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 1.1979
2022-02-24 14:07:20 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 1.1257
2022-02-24 14:07:53 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 0.9553
2022-02-24 14:08:27 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 1.0712
2022-02-24 14:09:00 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 1.0238
2022-02-24 14:09:33 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 1.0307
2022-02-24 14:10:07 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 1.0723
2022-02-24 14:10:40 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 1.0849
2022-02-24 14:11:15 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 0.8831
2022-02-24 14:11:48 - train: epoch 0063, iter [01200, 05004], lr: 0.001000, loss: 0.9068
2022-02-24 14:12:22 - train: epoch 0063, iter [01300, 05004], lr: 0.001000, loss: 1.1006
2022-02-24 14:12:56 - train: epoch 0063, iter [01400, 05004], lr: 0.001000, loss: 1.3544
2022-02-24 14:13:30 - train: epoch 0063, iter [01500, 05004], lr: 0.001000, loss: 1.0845
2022-02-24 14:14:03 - train: epoch 0063, iter [01600, 05004], lr: 0.001000, loss: 1.0482
2022-02-24 14:14:37 - train: epoch 0063, iter [01700, 05004], lr: 0.001000, loss: 0.9857
2022-02-24 14:15:11 - train: epoch 0063, iter [01800, 05004], lr: 0.001000, loss: 1.1680
2022-02-24 14:15:44 - train: epoch 0063, iter [01900, 05004], lr: 0.001000, loss: 1.0608
2022-02-24 14:16:18 - train: epoch 0063, iter [02000, 05004], lr: 0.001000, loss: 0.9497
2022-02-24 14:16:51 - train: epoch 0063, iter [02100, 05004], lr: 0.001000, loss: 0.9379
2022-02-24 14:17:26 - train: epoch 0063, iter [02200, 05004], lr: 0.001000, loss: 1.3081
2022-02-24 14:17:59 - train: epoch 0063, iter [02300, 05004], lr: 0.001000, loss: 1.0997
2022-02-24 14:18:33 - train: epoch 0063, iter [02400, 05004], lr: 0.001000, loss: 1.2249
2022-02-24 14:19:07 - train: epoch 0063, iter [02500, 05004], lr: 0.001000, loss: 0.9583
2022-02-24 14:19:40 - train: epoch 0063, iter [02600, 05004], lr: 0.001000, loss: 0.9454
2022-02-24 14:20:15 - train: epoch 0063, iter [02700, 05004], lr: 0.001000, loss: 1.2744
2022-02-24 14:20:48 - train: epoch 0063, iter [02800, 05004], lr: 0.001000, loss: 1.0161
2022-02-24 14:21:23 - train: epoch 0063, iter [02900, 05004], lr: 0.001000, loss: 1.0387
2022-02-24 14:21:57 - train: epoch 0063, iter [03000, 05004], lr: 0.001000, loss: 1.1422
2022-02-24 14:22:30 - train: epoch 0063, iter [03100, 05004], lr: 0.001000, loss: 1.3593
2022-02-24 14:23:04 - train: epoch 0063, iter [03200, 05004], lr: 0.001000, loss: 1.1125
2022-02-24 14:23:38 - train: epoch 0063, iter [03300, 05004], lr: 0.001000, loss: 1.0231
2022-02-24 14:24:13 - train: epoch 0063, iter [03400, 05004], lr: 0.001000, loss: 0.8806
2022-02-24 14:24:47 - train: epoch 0063, iter [03500, 05004], lr: 0.001000, loss: 1.1445
2022-02-24 14:25:22 - train: epoch 0063, iter [03600, 05004], lr: 0.001000, loss: 0.9121
2022-02-24 14:25:56 - train: epoch 0063, iter [03700, 05004], lr: 0.001000, loss: 1.2054
2022-02-24 14:26:30 - train: epoch 0063, iter [03800, 05004], lr: 0.001000, loss: 1.2285
2022-02-24 14:27:05 - train: epoch 0063, iter [03900, 05004], lr: 0.001000, loss: 0.7117
2022-02-24 14:27:39 - train: epoch 0063, iter [04000, 05004], lr: 0.001000, loss: 0.8461
2022-02-24 14:28:15 - train: epoch 0063, iter [04100, 05004], lr: 0.001000, loss: 1.1439
2022-02-24 14:28:49 - train: epoch 0063, iter [04200, 05004], lr: 0.001000, loss: 0.9893
2022-02-24 14:29:25 - train: epoch 0063, iter [04300, 05004], lr: 0.001000, loss: 1.1181
2022-02-24 14:30:01 - train: epoch 0063, iter [04400, 05004], lr: 0.001000, loss: 1.0340
2022-02-24 14:30:40 - train: epoch 0063, iter [04500, 05004], lr: 0.001000, loss: 0.9696
2022-02-24 14:31:21 - train: epoch 0063, iter [04600, 05004], lr: 0.001000, loss: 1.0186
2022-02-24 14:32:00 - train: epoch 0063, iter [04700, 05004], lr: 0.001000, loss: 0.9488
2022-02-24 14:32:42 - train: epoch 0063, iter [04800, 05004], lr: 0.001000, loss: 0.9929
2022-02-24 14:33:32 - train: epoch 0063, iter [04900, 05004], lr: 0.001000, loss: 0.9865
2022-02-24 14:34:24 - train: epoch 0063, iter [05000, 05004], lr: 0.001000, loss: 0.9610
2022-02-24 14:34:27 - train: epoch 063, train_loss: 1.0294
2022-02-24 14:35:52 - eval: epoch: 063, acc1: 76.332%, acc5: 93.096%, test_loss: 0.9244, per_image_load_time: 2.615ms, per_image_inference_time: 0.562ms
2022-02-24 14:35:53 - until epoch: 063, best_acc1: 76.332%
2022-02-24 14:35:53 - epoch 064 lr: 0.0010000000000000002
2022-02-24 14:36:33 - train: epoch 0064, iter [00100, 05004], lr: 0.001000, loss: 0.9850
2022-02-24 14:37:07 - train: epoch 0064, iter [00200, 05004], lr: 0.001000, loss: 1.0714
2022-02-24 14:37:40 - train: epoch 0064, iter [00300, 05004], lr: 0.001000, loss: 0.8723
2022-02-24 14:38:13 - train: epoch 0064, iter [00400, 05004], lr: 0.001000, loss: 1.0674
2022-02-24 14:38:46 - train: epoch 0064, iter [00500, 05004], lr: 0.001000, loss: 0.9419
2022-02-24 14:39:20 - train: epoch 0064, iter [00600, 05004], lr: 0.001000, loss: 1.2536
2022-02-24 14:39:53 - train: epoch 0064, iter [00700, 05004], lr: 0.001000, loss: 1.1093
2022-02-24 14:40:26 - train: epoch 0064, iter [00800, 05004], lr: 0.001000, loss: 0.9000
2022-02-24 14:41:00 - train: epoch 0064, iter [00900, 05004], lr: 0.001000, loss: 0.9453
2022-02-24 14:41:34 - train: epoch 0064, iter [01000, 05004], lr: 0.001000, loss: 0.9960
2022-02-24 14:42:07 - train: epoch 0064, iter [01100, 05004], lr: 0.001000, loss: 0.9514
2022-02-24 14:42:41 - train: epoch 0064, iter [01200, 05004], lr: 0.001000, loss: 0.8372
2022-02-24 14:43:14 - train: epoch 0064, iter [01300, 05004], lr: 0.001000, loss: 0.9970
2022-02-24 14:43:47 - train: epoch 0064, iter [01400, 05004], lr: 0.001000, loss: 1.3008
2022-02-24 14:44:21 - train: epoch 0064, iter [01500, 05004], lr: 0.001000, loss: 1.0294
2022-02-24 14:44:54 - train: epoch 0064, iter [01600, 05004], lr: 0.001000, loss: 0.9955
2022-02-24 14:45:28 - train: epoch 0064, iter [01700, 05004], lr: 0.001000, loss: 0.8926
2022-02-24 14:46:02 - train: epoch 0064, iter [01800, 05004], lr: 0.001000, loss: 0.9254
2022-02-24 14:46:35 - train: epoch 0064, iter [01900, 05004], lr: 0.001000, loss: 0.9484
2022-02-24 14:47:08 - train: epoch 0064, iter [02000, 05004], lr: 0.001000, loss: 0.9156
2022-02-24 14:47:42 - train: epoch 0064, iter [02100, 05004], lr: 0.001000, loss: 1.0653
2022-02-24 14:48:17 - train: epoch 0064, iter [02200, 05004], lr: 0.001000, loss: 1.1035
2022-02-24 14:48:50 - train: epoch 0064, iter [02300, 05004], lr: 0.001000, loss: 1.1363
2022-02-24 14:49:24 - train: epoch 0064, iter [02400, 05004], lr: 0.001000, loss: 0.9868
2022-02-24 14:49:57 - train: epoch 0064, iter [02500, 05004], lr: 0.001000, loss: 0.9295
2022-02-24 14:50:31 - train: epoch 0064, iter [02600, 05004], lr: 0.001000, loss: 0.9260
2022-02-24 14:51:05 - train: epoch 0064, iter [02700, 05004], lr: 0.001000, loss: 0.9510
2022-02-24 14:51:38 - train: epoch 0064, iter [02800, 05004], lr: 0.001000, loss: 0.9043
2022-02-24 14:52:13 - train: epoch 0064, iter [02900, 05004], lr: 0.001000, loss: 1.2663
2022-02-24 14:52:46 - train: epoch 0064, iter [03000, 05004], lr: 0.001000, loss: 1.0699
2022-02-24 14:53:20 - train: epoch 0064, iter [03100, 05004], lr: 0.001000, loss: 0.8669
2022-02-24 14:53:54 - train: epoch 0064, iter [03200, 05004], lr: 0.001000, loss: 1.0530
2022-02-24 14:54:28 - train: epoch 0064, iter [03300, 05004], lr: 0.001000, loss: 1.0250
2022-02-24 14:55:02 - train: epoch 0064, iter [03400, 05004], lr: 0.001000, loss: 1.0959
2022-02-24 14:55:36 - train: epoch 0064, iter [03500, 05004], lr: 0.001000, loss: 0.9232
2022-02-24 14:56:11 - train: epoch 0064, iter [03600, 05004], lr: 0.001000, loss: 0.9660
2022-02-24 14:56:45 - train: epoch 0064, iter [03700, 05004], lr: 0.001000, loss: 0.7612
2022-02-24 14:57:19 - train: epoch 0064, iter [03800, 05004], lr: 0.001000, loss: 1.1505
2022-02-24 14:57:54 - train: epoch 0064, iter [03900, 05004], lr: 0.001000, loss: 0.9143
2022-02-24 14:58:29 - train: epoch 0064, iter [04000, 05004], lr: 0.001000, loss: 0.8928
2022-02-24 14:59:04 - train: epoch 0064, iter [04100, 05004], lr: 0.001000, loss: 1.0611
2022-02-24 14:59:46 - train: epoch 0064, iter [04200, 05004], lr: 0.001000, loss: 0.9809
2022-02-24 15:00:34 - train: epoch 0064, iter [04300, 05004], lr: 0.001000, loss: 1.1973
2022-02-24 15:01:22 - train: epoch 0064, iter [04400, 05004], lr: 0.001000, loss: 0.9667
2022-02-24 15:01:56 - train: epoch 0064, iter [04500, 05004], lr: 0.001000, loss: 0.9148
2022-02-24 15:02:43 - train: epoch 0064, iter [04600, 05004], lr: 0.001000, loss: 1.1859
2022-02-24 15:03:56 - train: epoch 0064, iter [04700, 05004], lr: 0.001000, loss: 1.3690
2022-02-24 15:04:57 - train: epoch 0064, iter [04800, 05004], lr: 0.001000, loss: 0.9980
2022-02-24 15:05:44 - train: epoch 0064, iter [04900, 05004], lr: 0.001000, loss: 1.2099
2022-02-24 15:06:24 - train: epoch 0064, iter [05000, 05004], lr: 0.001000, loss: 0.8832
2022-02-24 15:06:30 - train: epoch 064, train_loss: 1.0164
2022-02-24 15:07:55 - eval: epoch: 064, acc1: 76.310%, acc5: 93.164%, test_loss: 0.9185, per_image_load_time: 1.639ms, per_image_inference_time: 0.566ms
2022-02-24 15:07:56 - until epoch: 064, best_acc1: 76.332%
2022-02-24 15:07:56 - epoch 065 lr: 0.0010000000000000002
2022-02-24 15:08:36 - train: epoch 0065, iter [00100, 05004], lr: 0.001000, loss: 1.0930
2022-02-24 15:09:09 - train: epoch 0065, iter [00200, 05004], lr: 0.001000, loss: 1.0523
2022-02-24 15:09:42 - train: epoch 0065, iter [00300, 05004], lr: 0.001000, loss: 1.0172
2022-02-24 15:10:16 - train: epoch 0065, iter [00400, 05004], lr: 0.001000, loss: 1.1057
2022-02-24 15:10:49 - train: epoch 0065, iter [00500, 05004], lr: 0.001000, loss: 0.9304
2022-02-24 15:11:23 - train: epoch 0065, iter [00600, 05004], lr: 0.001000, loss: 1.1046
2022-02-24 15:11:56 - train: epoch 0065, iter [00700, 05004], lr: 0.001000, loss: 0.9253
2022-02-24 15:12:30 - train: epoch 0065, iter [00800, 05004], lr: 0.001000, loss: 0.9675
2022-02-24 15:13:04 - train: epoch 0065, iter [00900, 05004], lr: 0.001000, loss: 0.9900
2022-02-24 15:13:37 - train: epoch 0065, iter [01000, 05004], lr: 0.001000, loss: 0.9461
2022-02-24 15:14:11 - train: epoch 0065, iter [01100, 05004], lr: 0.001000, loss: 1.0068
2022-02-24 15:14:45 - train: epoch 0065, iter [01200, 05004], lr: 0.001000, loss: 1.1204
2022-02-24 15:15:19 - train: epoch 0065, iter [01300, 05004], lr: 0.001000, loss: 0.9197
2022-02-24 15:15:52 - train: epoch 0065, iter [01400, 05004], lr: 0.001000, loss: 0.8320
2022-02-24 15:16:26 - train: epoch 0065, iter [01500, 05004], lr: 0.001000, loss: 0.9869
2022-02-24 15:16:59 - train: epoch 0065, iter [01600, 05004], lr: 0.001000, loss: 0.9426
2022-02-24 15:17:34 - train: epoch 0065, iter [01700, 05004], lr: 0.001000, loss: 0.9891
2022-02-24 15:18:08 - train: epoch 0065, iter [01800, 05004], lr: 0.001000, loss: 0.9249
2022-02-24 15:18:42 - train: epoch 0065, iter [01900, 05004], lr: 0.001000, loss: 0.9177
2022-02-24 15:19:16 - train: epoch 0065, iter [02000, 05004], lr: 0.001000, loss: 0.9377
2022-02-24 15:19:50 - train: epoch 0065, iter [02100, 05004], lr: 0.001000, loss: 0.9376
2022-02-24 15:20:24 - train: epoch 0065, iter [02200, 05004], lr: 0.001000, loss: 1.1261
2022-02-24 15:20:57 - train: epoch 0065, iter [02300, 05004], lr: 0.001000, loss: 0.9193
2022-02-24 15:21:31 - train: epoch 0065, iter [02400, 05004], lr: 0.001000, loss: 0.9626
2022-02-24 15:22:04 - train: epoch 0065, iter [02500, 05004], lr: 0.001000, loss: 1.0028
2022-02-24 15:22:38 - train: epoch 0065, iter [02600, 05004], lr: 0.001000, loss: 1.1049
2022-02-24 15:23:12 - train: epoch 0065, iter [02700, 05004], lr: 0.001000, loss: 1.1003
2022-02-24 15:23:46 - train: epoch 0065, iter [02800, 05004], lr: 0.001000, loss: 0.9029
2022-02-24 15:24:19 - train: epoch 0065, iter [02900, 05004], lr: 0.001000, loss: 1.0745
2022-02-24 15:24:53 - train: epoch 0065, iter [03000, 05004], lr: 0.001000, loss: 0.9287
2022-02-24 15:25:27 - train: epoch 0065, iter [03100, 05004], lr: 0.001000, loss: 1.0833
2022-02-24 15:26:01 - train: epoch 0065, iter [03200, 05004], lr: 0.001000, loss: 1.0388
2022-02-24 15:26:35 - train: epoch 0065, iter [03300, 05004], lr: 0.001000, loss: 0.9081
2022-02-24 15:27:09 - train: epoch 0065, iter [03400, 05004], lr: 0.001000, loss: 0.8578
2022-02-24 15:27:42 - train: epoch 0065, iter [03500, 05004], lr: 0.001000, loss: 1.2466
2022-02-24 15:28:16 - train: epoch 0065, iter [03600, 05004], lr: 0.001000, loss: 1.0336
2022-02-24 15:28:51 - train: epoch 0065, iter [03700, 05004], lr: 0.001000, loss: 0.9316
2022-02-24 15:29:25 - train: epoch 0065, iter [03800, 05004], lr: 0.001000, loss: 0.8784
2022-02-24 15:30:09 - train: epoch 0065, iter [03900, 05004], lr: 0.001000, loss: 1.0137
2022-02-24 15:30:49 - train: epoch 0065, iter [04000, 05004], lr: 0.001000, loss: 1.1034
2022-02-24 15:31:31 - train: epoch 0065, iter [04100, 05004], lr: 0.001000, loss: 0.9230
2022-02-24 15:32:07 - train: epoch 0065, iter [04200, 05004], lr: 0.001000, loss: 1.0326
2022-02-24 15:32:45 - train: epoch 0065, iter [04300, 05004], lr: 0.001000, loss: 0.8903
2022-02-24 15:33:39 - train: epoch 0065, iter [04400, 05004], lr: 0.001000, loss: 1.0047
2022-02-24 15:34:31 - train: epoch 0065, iter [04500, 05004], lr: 0.001000, loss: 0.9354
2022-02-24 15:35:07 - train: epoch 0065, iter [04600, 05004], lr: 0.001000, loss: 0.9991
2022-02-24 15:35:51 - train: epoch 0065, iter [04700, 05004], lr: 0.001000, loss: 1.0418
2022-02-24 15:36:32 - train: epoch 0065, iter [04800, 05004], lr: 0.001000, loss: 0.7690
2022-02-24 15:37:14 - train: epoch 0065, iter [04900, 05004], lr: 0.001000, loss: 0.9712
2022-02-24 15:38:05 - train: epoch 0065, iter [05000, 05004], lr: 0.001000, loss: 1.0830
2022-02-24 15:38:08 - train: epoch 065, train_loss: 1.0051
2022-02-24 15:39:47 - eval: epoch: 065, acc1: 76.398%, acc5: 93.222%, test_loss: 0.9173, per_image_load_time: 3.221ms, per_image_inference_time: 0.582ms
2022-02-24 15:39:48 - until epoch: 065, best_acc1: 76.398%
2022-02-24 15:39:48 - epoch 066 lr: 0.0010000000000000002
2022-02-24 15:40:29 - train: epoch 0066, iter [00100, 05004], lr: 0.001000, loss: 0.8839
2022-02-24 15:41:02 - train: epoch 0066, iter [00200, 05004], lr: 0.001000, loss: 1.1057
2022-02-24 15:41:35 - train: epoch 0066, iter [00300, 05004], lr: 0.001000, loss: 0.8717
2022-02-24 15:42:09 - train: epoch 0066, iter [00400, 05004], lr: 0.001000, loss: 0.7627
2022-02-24 15:42:42 - train: epoch 0066, iter [00500, 05004], lr: 0.001000, loss: 1.0222
2022-02-24 15:43:15 - train: epoch 0066, iter [00600, 05004], lr: 0.001000, loss: 0.9637
2022-02-24 15:43:49 - train: epoch 0066, iter [00700, 05004], lr: 0.001000, loss: 0.9844
2022-02-24 15:44:22 - train: epoch 0066, iter [00800, 05004], lr: 0.001000, loss: 1.2439
2022-02-24 15:44:55 - train: epoch 0066, iter [00900, 05004], lr: 0.001000, loss: 1.0447
2022-02-24 15:45:29 - train: epoch 0066, iter [01000, 05004], lr: 0.001000, loss: 1.0710
2022-02-24 15:46:02 - train: epoch 0066, iter [01100, 05004], lr: 0.001000, loss: 1.0241
2022-02-24 15:46:35 - train: epoch 0066, iter [01200, 05004], lr: 0.001000, loss: 1.1258
2022-02-24 15:47:09 - train: epoch 0066, iter [01300, 05004], lr: 0.001000, loss: 1.0861
2022-02-24 15:47:42 - train: epoch 0066, iter [01400, 05004], lr: 0.001000, loss: 0.8419
2022-02-24 15:48:15 - train: epoch 0066, iter [01500, 05004], lr: 0.001000, loss: 1.0626
2022-02-24 15:48:49 - train: epoch 0066, iter [01600, 05004], lr: 0.001000, loss: 0.9910
2022-02-24 15:49:22 - train: epoch 0066, iter [01700, 05004], lr: 0.001000, loss: 0.9588
2022-02-24 15:49:55 - train: epoch 0066, iter [01800, 05004], lr: 0.001000, loss: 0.8575
2022-02-24 15:50:29 - train: epoch 0066, iter [01900, 05004], lr: 0.001000, loss: 1.2149
2022-02-24 15:51:02 - train: epoch 0066, iter [02000, 05004], lr: 0.001000, loss: 1.1489
2022-02-24 15:51:36 - train: epoch 0066, iter [02100, 05004], lr: 0.001000, loss: 1.0061
2022-02-24 15:52:09 - train: epoch 0066, iter [02200, 05004], lr: 0.001000, loss: 0.9876
2022-02-24 15:52:43 - train: epoch 0066, iter [02300, 05004], lr: 0.001000, loss: 1.1699
2022-02-24 15:53:16 - train: epoch 0066, iter [02400, 05004], lr: 0.001000, loss: 0.9276
2022-02-24 15:53:50 - train: epoch 0066, iter [02500, 05004], lr: 0.001000, loss: 0.9061
2022-02-24 15:54:23 - train: epoch 0066, iter [02600, 05004], lr: 0.001000, loss: 0.9388
2022-02-24 15:54:57 - train: epoch 0066, iter [02700, 05004], lr: 0.001000, loss: 1.2019
2022-02-24 15:55:30 - train: epoch 0066, iter [02800, 05004], lr: 0.001000, loss: 1.0984
2022-02-24 15:56:04 - train: epoch 0066, iter [02900, 05004], lr: 0.001000, loss: 0.8956
2022-02-24 15:56:38 - train: epoch 0066, iter [03000, 05004], lr: 0.001000, loss: 0.9596
2022-02-24 15:57:12 - train: epoch 0066, iter [03100, 05004], lr: 0.001000, loss: 1.1572
2022-02-24 15:57:46 - train: epoch 0066, iter [03200, 05004], lr: 0.001000, loss: 0.8374
2022-02-24 15:58:19 - train: epoch 0066, iter [03300, 05004], lr: 0.001000, loss: 0.9254
2022-02-24 15:58:53 - train: epoch 0066, iter [03400, 05004], lr: 0.001000, loss: 1.2116
2022-02-24 15:59:28 - train: epoch 0066, iter [03500, 05004], lr: 0.001000, loss: 1.0118
2022-02-24 16:00:01 - train: epoch 0066, iter [03600, 05004], lr: 0.001000, loss: 1.0486
2022-02-24 16:00:35 - train: epoch 0066, iter [03700, 05004], lr: 0.001000, loss: 1.0724
2022-02-24 16:01:09 - train: epoch 0066, iter [03800, 05004], lr: 0.001000, loss: 0.8755
2022-02-24 16:01:44 - train: epoch 0066, iter [03900, 05004], lr: 0.001000, loss: 0.9066
2022-02-24 16:02:19 - train: epoch 0066, iter [04000, 05004], lr: 0.001000, loss: 1.1523
2022-02-24 16:02:52 - train: epoch 0066, iter [04100, 05004], lr: 0.001000, loss: 0.8351
2022-02-24 16:03:28 - train: epoch 0066, iter [04200, 05004], lr: 0.001000, loss: 0.7822
2022-02-24 16:04:02 - train: epoch 0066, iter [04300, 05004], lr: 0.001000, loss: 0.8997
2022-02-24 16:04:38 - train: epoch 0066, iter [04400, 05004], lr: 0.001000, loss: 1.0211
2022-02-24 16:05:17 - train: epoch 0066, iter [04500, 05004], lr: 0.001000, loss: 1.0480
2022-02-24 16:05:55 - train: epoch 0066, iter [04600, 05004], lr: 0.001000, loss: 1.2137
2022-02-24 16:06:32 - train: epoch 0066, iter [04700, 05004], lr: 0.001000, loss: 0.9463
2022-02-24 16:07:16 - train: epoch 0066, iter [04800, 05004], lr: 0.001000, loss: 0.9585
2022-02-24 16:08:04 - train: epoch 0066, iter [04900, 05004], lr: 0.001000, loss: 1.0269
2022-02-24 16:08:52 - train: epoch 0066, iter [05000, 05004], lr: 0.001000, loss: 0.8999
2022-02-24 16:08:55 - train: epoch 066, train_loss: 0.9968
2022-02-24 16:10:34 - eval: epoch: 066, acc1: 76.534%, acc5: 93.204%, test_loss: 0.9117, per_image_load_time: 1.165ms, per_image_inference_time: 0.557ms
2022-02-24 16:10:35 - until epoch: 066, best_acc1: 76.534%
2022-02-24 16:10:35 - epoch 067 lr: 0.0010000000000000002
2022-02-24 16:11:15 - train: epoch 0067, iter [00100, 05004], lr: 0.001000, loss: 0.8813
2022-02-24 16:11:48 - train: epoch 0067, iter [00200, 05004], lr: 0.001000, loss: 0.9645
2022-02-24 16:12:22 - train: epoch 0067, iter [00300, 05004], lr: 0.001000, loss: 1.2840
2022-02-24 16:12:55 - train: epoch 0067, iter [00400, 05004], lr: 0.001000, loss: 1.0088
2022-02-24 16:13:28 - train: epoch 0067, iter [00500, 05004], lr: 0.001000, loss: 0.9737
2022-02-24 16:14:01 - train: epoch 0067, iter [00600, 05004], lr: 0.001000, loss: 0.9353
2022-02-24 16:14:33 - train: epoch 0067, iter [00700, 05004], lr: 0.001000, loss: 1.0649
2022-02-24 16:15:06 - train: epoch 0067, iter [00800, 05004], lr: 0.001000, loss: 1.0818
2022-02-24 16:15:39 - train: epoch 0067, iter [00900, 05004], lr: 0.001000, loss: 0.9460
2022-02-24 16:16:12 - train: epoch 0067, iter [01000, 05004], lr: 0.001000, loss: 0.7948
2022-02-24 16:16:45 - train: epoch 0067, iter [01100, 05004], lr: 0.001000, loss: 1.0465
2022-02-24 16:17:17 - train: epoch 0067, iter [01200, 05004], lr: 0.001000, loss: 0.9540
2022-02-24 16:17:50 - train: epoch 0067, iter [01300, 05004], lr: 0.001000, loss: 1.1494
2022-02-24 16:18:23 - train: epoch 0067, iter [01400, 05004], lr: 0.001000, loss: 0.9738
2022-02-24 16:18:55 - train: epoch 0067, iter [01500, 05004], lr: 0.001000, loss: 1.0294
2022-02-24 16:19:28 - train: epoch 0067, iter [01600, 05004], lr: 0.001000, loss: 1.0659
2022-02-24 16:20:01 - train: epoch 0067, iter [01700, 05004], lr: 0.001000, loss: 0.8919
2022-02-24 16:20:35 - train: epoch 0067, iter [01800, 05004], lr: 0.001000, loss: 1.1949
2022-02-24 16:21:09 - train: epoch 0067, iter [01900, 05004], lr: 0.001000, loss: 0.8527
2022-02-24 16:21:42 - train: epoch 0067, iter [02000, 05004], lr: 0.001000, loss: 1.2044
2022-02-24 16:22:14 - train: epoch 0067, iter [02100, 05004], lr: 0.001000, loss: 0.9308
2022-02-24 16:22:47 - train: epoch 0067, iter [02200, 05004], lr: 0.001000, loss: 1.0558
2022-02-24 16:23:20 - train: epoch 0067, iter [02300, 05004], lr: 0.001000, loss: 0.9127
2022-02-24 16:23:53 - train: epoch 0067, iter [02400, 05004], lr: 0.001000, loss: 0.9383
2022-02-24 16:24:26 - train: epoch 0067, iter [02500, 05004], lr: 0.001000, loss: 0.9053
2022-02-24 16:24:59 - train: epoch 0067, iter [02600, 05004], lr: 0.001000, loss: 0.8664
2022-02-24 16:25:34 - train: epoch 0067, iter [02700, 05004], lr: 0.001000, loss: 0.9397
2022-02-24 16:26:08 - train: epoch 0067, iter [02800, 05004], lr: 0.001000, loss: 1.0362
2022-02-24 16:26:42 - train: epoch 0067, iter [02900, 05004], lr: 0.001000, loss: 0.8865
2022-02-24 16:27:16 - train: epoch 0067, iter [03000, 05004], lr: 0.001000, loss: 0.9956
2022-02-24 16:27:49 - train: epoch 0067, iter [03100, 05004], lr: 0.001000, loss: 0.8520
2022-02-24 16:28:22 - train: epoch 0067, iter [03200, 05004], lr: 0.001000, loss: 1.1602
2022-02-24 16:28:56 - train: epoch 0067, iter [03300, 05004], lr: 0.001000, loss: 0.8279
2022-02-24 16:29:28 - train: epoch 0067, iter [03400, 05004], lr: 0.001000, loss: 1.0352
2022-02-24 16:30:02 - train: epoch 0067, iter [03500, 05004], lr: 0.001000, loss: 0.9182
2022-02-24 16:30:36 - train: epoch 0067, iter [03600, 05004], lr: 0.001000, loss: 0.9359
2022-02-24 16:31:10 - train: epoch 0067, iter [03700, 05004], lr: 0.001000, loss: 1.2216
2022-02-24 16:31:42 - train: epoch 0067, iter [03800, 05004], lr: 0.001000, loss: 1.0038
2022-02-24 16:32:16 - train: epoch 0067, iter [03900, 05004], lr: 0.001000, loss: 0.9908
2022-02-24 16:32:50 - train: epoch 0067, iter [04000, 05004], lr: 0.001000, loss: 1.1663
2022-02-24 16:33:24 - train: epoch 0067, iter [04100, 05004], lr: 0.001000, loss: 1.1705
2022-02-24 16:33:57 - train: epoch 0067, iter [04200, 05004], lr: 0.001000, loss: 1.1815
2022-02-24 16:34:32 - train: epoch 0067, iter [04300, 05004], lr: 0.001000, loss: 0.8770
2022-02-24 16:35:05 - train: epoch 0067, iter [04400, 05004], lr: 0.001000, loss: 0.9775
2022-02-24 16:35:42 - train: epoch 0067, iter [04500, 05004], lr: 0.001000, loss: 0.9327
2022-02-24 16:36:18 - train: epoch 0067, iter [04600, 05004], lr: 0.001000, loss: 0.7300
2022-02-24 16:36:56 - train: epoch 0067, iter [04700, 05004], lr: 0.001000, loss: 0.8668
2022-02-24 16:37:34 - train: epoch 0067, iter [04800, 05004], lr: 0.001000, loss: 0.7800
2022-02-24 16:38:09 - train: epoch 0067, iter [04900, 05004], lr: 0.001000, loss: 1.0076
2022-02-24 16:38:48 - train: epoch 0067, iter [05000, 05004], lr: 0.001000, loss: 1.0421
2022-02-24 16:38:51 - train: epoch 067, train_loss: 0.9898
2022-02-24 16:40:13 - eval: epoch: 067, acc1: 76.512%, acc5: 93.272%, test_loss: 0.9108, per_image_load_time: 2.504ms, per_image_inference_time: 0.582ms
2022-02-24 16:40:13 - until epoch: 067, best_acc1: 76.534%
2022-02-24 16:40:13 - epoch 068 lr: 0.0010000000000000002
2022-02-24 16:40:53 - train: epoch 0068, iter [00100, 05004], lr: 0.001000, loss: 1.0907
2022-02-24 16:41:26 - train: epoch 0068, iter [00200, 05004], lr: 0.001000, loss: 1.0889
2022-02-24 16:41:58 - train: epoch 0068, iter [00300, 05004], lr: 0.001000, loss: 1.0429
2022-02-24 16:42:31 - train: epoch 0068, iter [00400, 05004], lr: 0.001000, loss: 0.9476
2022-02-24 16:43:03 - train: epoch 0068, iter [00500, 05004], lr: 0.001000, loss: 0.9386
2022-02-24 16:43:36 - train: epoch 0068, iter [00600, 05004], lr: 0.001000, loss: 1.0371
2022-02-24 16:44:08 - train: epoch 0068, iter [00700, 05004], lr: 0.001000, loss: 1.2800
2022-02-24 16:44:41 - train: epoch 0068, iter [00800, 05004], lr: 0.001000, loss: 0.9352
2022-02-24 16:45:14 - train: epoch 0068, iter [00900, 05004], lr: 0.001000, loss: 0.8742
2022-02-24 16:45:46 - train: epoch 0068, iter [01000, 05004], lr: 0.001000, loss: 0.9602
2022-02-24 16:46:19 - train: epoch 0068, iter [01100, 05004], lr: 0.001000, loss: 1.1349
2022-02-24 16:46:52 - train: epoch 0068, iter [01200, 05004], lr: 0.001000, loss: 0.9112
2022-02-24 16:47:25 - train: epoch 0068, iter [01300, 05004], lr: 0.001000, loss: 0.8026
2022-02-24 16:47:57 - train: epoch 0068, iter [01400, 05004], lr: 0.001000, loss: 1.0025
2022-02-24 16:48:30 - train: epoch 0068, iter [01500, 05004], lr: 0.001000, loss: 1.0661
2022-02-24 16:49:03 - train: epoch 0068, iter [01600, 05004], lr: 0.001000, loss: 1.0118
2022-02-24 16:49:35 - train: epoch 0068, iter [01700, 05004], lr: 0.001000, loss: 1.1445
2022-02-24 16:50:08 - train: epoch 0068, iter [01800, 05004], lr: 0.001000, loss: 0.9887
2022-02-24 16:50:41 - train: epoch 0068, iter [01900, 05004], lr: 0.001000, loss: 0.9802
2022-02-24 16:51:14 - train: epoch 0068, iter [02000, 05004], lr: 0.001000, loss: 1.0140
2022-02-24 16:51:47 - train: epoch 0068, iter [02100, 05004], lr: 0.001000, loss: 0.9793
2022-02-24 16:52:21 - train: epoch 0068, iter [02200, 05004], lr: 0.001000, loss: 1.0242
2022-02-24 16:52:53 - train: epoch 0068, iter [02300, 05004], lr: 0.001000, loss: 0.8819
2022-02-24 16:53:26 - train: epoch 0068, iter [02400, 05004], lr: 0.001000, loss: 1.0569
2022-02-24 16:53:59 - train: epoch 0068, iter [02500, 05004], lr: 0.001000, loss: 0.9981
2022-02-24 16:54:33 - train: epoch 0068, iter [02600, 05004], lr: 0.001000, loss: 0.9525
2022-02-24 16:55:06 - train: epoch 0068, iter [02700, 05004], lr: 0.001000, loss: 1.0022
2022-02-24 16:55:39 - train: epoch 0068, iter [02800, 05004], lr: 0.001000, loss: 1.1652
2022-02-24 16:56:13 - train: epoch 0068, iter [02900, 05004], lr: 0.001000, loss: 1.0936
2022-02-24 16:56:46 - train: epoch 0068, iter [03000, 05004], lr: 0.001000, loss: 1.1642
2022-02-24 16:57:19 - train: epoch 0068, iter [03100, 05004], lr: 0.001000, loss: 0.8620
2022-02-24 16:57:53 - train: epoch 0068, iter [03200, 05004], lr: 0.001000, loss: 0.9868
2022-02-24 16:58:26 - train: epoch 0068, iter [03300, 05004], lr: 0.001000, loss: 0.9320
2022-02-24 16:58:59 - train: epoch 0068, iter [03400, 05004], lr: 0.001000, loss: 0.8556
2022-02-24 16:59:34 - train: epoch 0068, iter [03500, 05004], lr: 0.001000, loss: 1.0554
2022-02-24 17:00:08 - train: epoch 0068, iter [03600, 05004], lr: 0.001000, loss: 0.8897
2022-02-24 17:00:41 - train: epoch 0068, iter [03700, 05004], lr: 0.001000, loss: 1.0886
2022-02-24 17:01:15 - train: epoch 0068, iter [03800, 05004], lr: 0.001000, loss: 1.0977
2022-02-24 17:01:49 - train: epoch 0068, iter [03900, 05004], lr: 0.001000, loss: 1.0360
2022-02-24 17:02:24 - train: epoch 0068, iter [04000, 05004], lr: 0.001000, loss: 1.0301
2022-02-24 17:02:57 - train: epoch 0068, iter [04100, 05004], lr: 0.001000, loss: 0.7846
2022-02-24 17:03:31 - train: epoch 0068, iter [04200, 05004], lr: 0.001000, loss: 1.1538
2022-02-24 17:04:05 - train: epoch 0068, iter [04300, 05004], lr: 0.001000, loss: 1.0605
2022-02-24 17:04:40 - train: epoch 0068, iter [04400, 05004], lr: 0.001000, loss: 0.9442
2022-02-24 17:05:13 - train: epoch 0068, iter [04500, 05004], lr: 0.001000, loss: 1.0187
2022-02-24 17:05:48 - train: epoch 0068, iter [04600, 05004], lr: 0.001000, loss: 1.1630
2022-02-24 17:06:24 - train: epoch 0068, iter [04700, 05004], lr: 0.001000, loss: 1.2338
2022-02-24 17:07:02 - train: epoch 0068, iter [04800, 05004], lr: 0.001000, loss: 1.0499
2022-02-24 17:07:39 - train: epoch 0068, iter [04900, 05004], lr: 0.001000, loss: 1.1283
2022-02-24 17:08:17 - train: epoch 0068, iter [05000, 05004], lr: 0.001000, loss: 0.9671
2022-02-24 17:08:20 - train: epoch 068, train_loss: 0.9820
2022-02-24 17:09:41 - eval: epoch: 068, acc1: 76.526%, acc5: 93.374%, test_loss: 0.9079, per_image_load_time: 2.476ms, per_image_inference_time: 0.563ms
2022-02-24 17:09:42 - until epoch: 068, best_acc1: 76.534%
2022-02-24 17:09:42 - epoch 069 lr: 0.0010000000000000002
2022-02-24 17:10:21 - train: epoch 0069, iter [00100, 05004], lr: 0.001000, loss: 1.0798
2022-02-24 17:10:54 - train: epoch 0069, iter [00200, 05004], lr: 0.001000, loss: 1.0954
2022-02-24 17:11:26 - train: epoch 0069, iter [00300, 05004], lr: 0.001000, loss: 1.0959
2022-02-24 17:11:59 - train: epoch 0069, iter [00400, 05004], lr: 0.001000, loss: 1.0061
2022-02-24 17:12:32 - train: epoch 0069, iter [00500, 05004], lr: 0.001000, loss: 0.9178
2022-02-24 17:13:04 - train: epoch 0069, iter [00600, 05004], lr: 0.001000, loss: 0.8875
2022-02-24 17:13:37 - train: epoch 0069, iter [00700, 05004], lr: 0.001000, loss: 0.9087
2022-02-24 17:14:09 - train: epoch 0069, iter [00800, 05004], lr: 0.001000, loss: 0.9517
2022-02-24 17:14:42 - train: epoch 0069, iter [00900, 05004], lr: 0.001000, loss: 0.9234
2022-02-24 17:15:15 - train: epoch 0069, iter [01000, 05004], lr: 0.001000, loss: 0.9679
2022-02-24 17:15:47 - train: epoch 0069, iter [01100, 05004], lr: 0.001000, loss: 0.9657
2022-02-24 17:16:20 - train: epoch 0069, iter [01200, 05004], lr: 0.001000, loss: 0.9150
2022-02-24 17:16:53 - train: epoch 0069, iter [01300, 05004], lr: 0.001000, loss: 1.1820
2022-02-24 17:17:26 - train: epoch 0069, iter [01400, 05004], lr: 0.001000, loss: 1.0605
2022-02-24 17:17:58 - train: epoch 0069, iter [01500, 05004], lr: 0.001000, loss: 0.9719
2022-02-24 17:18:31 - train: epoch 0069, iter [01600, 05004], lr: 0.001000, loss: 0.9948
2022-02-24 17:19:04 - train: epoch 0069, iter [01700, 05004], lr: 0.001000, loss: 0.9016
2022-02-24 17:19:37 - train: epoch 0069, iter [01800, 05004], lr: 0.001000, loss: 0.7802
2022-02-24 17:20:09 - train: epoch 0069, iter [01900, 05004], lr: 0.001000, loss: 0.9146
2022-02-24 17:20:42 - train: epoch 0069, iter [02000, 05004], lr: 0.001000, loss: 0.7704
2022-02-24 17:21:15 - train: epoch 0069, iter [02100, 05004], lr: 0.001000, loss: 0.9844
2022-02-24 17:21:48 - train: epoch 0069, iter [02200, 05004], lr: 0.001000, loss: 1.0990
2022-02-24 17:22:20 - train: epoch 0069, iter [02300, 05004], lr: 0.001000, loss: 0.9315
2022-02-24 17:22:53 - train: epoch 0069, iter [02400, 05004], lr: 0.001000, loss: 1.0838
2022-02-24 17:23:26 - train: epoch 0069, iter [02500, 05004], lr: 0.001000, loss: 0.9944
2022-02-24 17:23:59 - train: epoch 0069, iter [02600, 05004], lr: 0.001000, loss: 1.0761
2022-02-24 17:24:32 - train: epoch 0069, iter [02700, 05004], lr: 0.001000, loss: 1.2097
2022-02-24 17:25:05 - train: epoch 0069, iter [02800, 05004], lr: 0.001000, loss: 1.1823
2022-02-24 17:25:38 - train: epoch 0069, iter [02900, 05004], lr: 0.001000, loss: 0.8886
2022-02-24 17:26:11 - train: epoch 0069, iter [03000, 05004], lr: 0.001000, loss: 0.8876
2022-02-24 17:26:44 - train: epoch 0069, iter [03100, 05004], lr: 0.001000, loss: 0.9071
2022-02-24 17:27:18 - train: epoch 0069, iter [03200, 05004], lr: 0.001000, loss: 0.9001
2022-02-24 17:27:51 - train: epoch 0069, iter [03300, 05004], lr: 0.001000, loss: 0.8672
2022-02-24 17:28:24 - train: epoch 0069, iter [03400, 05004], lr: 0.001000, loss: 0.8531
2022-02-24 17:28:57 - train: epoch 0069, iter [03500, 05004], lr: 0.001000, loss: 0.8880
2022-02-24 17:29:31 - train: epoch 0069, iter [03600, 05004], lr: 0.001000, loss: 0.8251
2022-02-24 17:30:05 - train: epoch 0069, iter [03700, 05004], lr: 0.001000, loss: 1.0591
2022-02-24 17:30:38 - train: epoch 0069, iter [03800, 05004], lr: 0.001000, loss: 1.0557
2022-02-24 17:31:12 - train: epoch 0069, iter [03900, 05004], lr: 0.001000, loss: 0.9900
2022-02-24 17:31:46 - train: epoch 0069, iter [04000, 05004], lr: 0.001000, loss: 1.0254
2022-02-24 17:32:20 - train: epoch 0069, iter [04100, 05004], lr: 0.001000, loss: 1.0903
2022-02-24 17:32:54 - train: epoch 0069, iter [04200, 05004], lr: 0.001000, loss: 0.8574
2022-02-24 17:33:27 - train: epoch 0069, iter [04300, 05004], lr: 0.001000, loss: 0.9712
2022-02-24 17:34:02 - train: epoch 0069, iter [04400, 05004], lr: 0.001000, loss: 0.9881
2022-02-24 17:34:37 - train: epoch 0069, iter [04500, 05004], lr: 0.001000, loss: 0.9089
2022-02-24 17:35:12 - train: epoch 0069, iter [04600, 05004], lr: 0.001000, loss: 1.1639
2022-02-24 17:35:47 - train: epoch 0069, iter [04700, 05004], lr: 0.001000, loss: 0.9573
2022-02-24 17:36:22 - train: epoch 0069, iter [04800, 05004], lr: 0.001000, loss: 0.9676
2022-02-24 17:36:59 - train: epoch 0069, iter [04900, 05004], lr: 0.001000, loss: 0.9045
2022-02-24 17:37:37 - train: epoch 0069, iter [05000, 05004], lr: 0.001000, loss: 0.9814
2022-02-24 17:37:40 - train: epoch 069, train_loss: 0.9752
2022-02-24 17:38:59 - eval: epoch: 069, acc1: 76.520%, acc5: 93.302%, test_loss: 0.9108, per_image_load_time: 1.612ms, per_image_inference_time: 0.587ms
2022-02-24 17:39:00 - until epoch: 069, best_acc1: 76.534%
2022-02-24 17:39:00 - epoch 070 lr: 0.0010000000000000002
2022-02-24 17:39:38 - train: epoch 0070, iter [00100, 05004], lr: 0.001000, loss: 1.0436
2022-02-24 17:40:11 - train: epoch 0070, iter [00200, 05004], lr: 0.001000, loss: 1.1355
2022-02-24 17:40:43 - train: epoch 0070, iter [00300, 05004], lr: 0.001000, loss: 1.1270
2022-02-24 17:41:16 - train: epoch 0070, iter [00400, 05004], lr: 0.001000, loss: 0.9397
2022-02-24 17:41:48 - train: epoch 0070, iter [00500, 05004], lr: 0.001000, loss: 1.0762
2022-02-24 17:42:21 - train: epoch 0070, iter [00600, 05004], lr: 0.001000, loss: 0.8979
2022-02-24 17:42:53 - train: epoch 0070, iter [00700, 05004], lr: 0.001000, loss: 0.9686
2022-02-24 17:43:26 - train: epoch 0070, iter [00800, 05004], lr: 0.001000, loss: 0.8490
2022-02-24 17:43:59 - train: epoch 0070, iter [00900, 05004], lr: 0.001000, loss: 1.0280
2022-02-24 17:44:31 - train: epoch 0070, iter [01000, 05004], lr: 0.001000, loss: 0.8460
2022-02-24 17:45:04 - train: epoch 0070, iter [01100, 05004], lr: 0.001000, loss: 1.2235
2022-02-24 17:45:36 - train: epoch 0070, iter [01200, 05004], lr: 0.001000, loss: 0.7843
2022-02-24 17:46:09 - train: epoch 0070, iter [01300, 05004], lr: 0.001000, loss: 0.8586
2022-02-24 17:46:41 - train: epoch 0070, iter [01400, 05004], lr: 0.001000, loss: 0.9789
2022-02-24 17:47:14 - train: epoch 0070, iter [01500, 05004], lr: 0.001000, loss: 0.9235
2022-02-24 17:47:46 - train: epoch 0070, iter [01600, 05004], lr: 0.001000, loss: 1.0016
2022-02-24 17:48:19 - train: epoch 0070, iter [01700, 05004], lr: 0.001000, loss: 1.0855
2022-02-24 17:48:51 - train: epoch 0070, iter [01800, 05004], lr: 0.001000, loss: 0.8548
2022-02-24 17:49:23 - train: epoch 0070, iter [01900, 05004], lr: 0.001000, loss: 0.9581
2022-02-24 17:49:56 - train: epoch 0070, iter [02000, 05004], lr: 0.001000, loss: 0.9779
2022-02-24 17:50:29 - train: epoch 0070, iter [02100, 05004], lr: 0.001000, loss: 1.0210
2022-02-24 17:51:01 - train: epoch 0070, iter [02200, 05004], lr: 0.001000, loss: 0.9786
2022-02-24 17:51:34 - train: epoch 0070, iter [02300, 05004], lr: 0.001000, loss: 0.9333
2022-02-24 17:52:07 - train: epoch 0070, iter [02400, 05004], lr: 0.001000, loss: 1.0823
2022-02-24 17:52:40 - train: epoch 0070, iter [02500, 05004], lr: 0.001000, loss: 0.9738
2022-02-24 17:53:13 - train: epoch 0070, iter [02600, 05004], lr: 0.001000, loss: 0.8984
2022-02-24 17:53:46 - train: epoch 0070, iter [02700, 05004], lr: 0.001000, loss: 0.9248
2022-02-24 17:54:19 - train: epoch 0070, iter [02800, 05004], lr: 0.001000, loss: 1.0702
2022-02-24 17:54:52 - train: epoch 0070, iter [02900, 05004], lr: 0.001000, loss: 1.1695
2022-02-24 17:55:25 - train: epoch 0070, iter [03000, 05004], lr: 0.001000, loss: 0.9590
2022-02-24 17:55:59 - train: epoch 0070, iter [03100, 05004], lr: 0.001000, loss: 0.9636
2022-02-24 17:56:32 - train: epoch 0070, iter [03200, 05004], lr: 0.001000, loss: 1.0337
2022-02-24 17:57:07 - train: epoch 0070, iter [03300, 05004], lr: 0.001000, loss: 0.9741
2022-02-24 17:57:41 - train: epoch 0070, iter [03400, 05004], lr: 0.001000, loss: 1.0400
2022-02-24 17:58:15 - train: epoch 0070, iter [03500, 05004], lr: 0.001000, loss: 0.9229
2022-02-24 17:58:49 - train: epoch 0070, iter [03600, 05004], lr: 0.001000, loss: 1.0240
2022-02-24 17:59:24 - train: epoch 0070, iter [03700, 05004], lr: 0.001000, loss: 1.0281
2022-02-24 17:59:58 - train: epoch 0070, iter [03800, 05004], lr: 0.001000, loss: 0.9291
2022-02-24 18:00:33 - train: epoch 0070, iter [03900, 05004], lr: 0.001000, loss: 0.8065
2022-02-24 18:01:06 - train: epoch 0070, iter [04000, 05004], lr: 0.001000, loss: 0.7753
2022-02-24 18:01:39 - train: epoch 0070, iter [04100, 05004], lr: 0.001000, loss: 0.9104
2022-02-24 18:02:12 - train: epoch 0070, iter [04200, 05004], lr: 0.001000, loss: 1.0134
2022-02-24 18:02:46 - train: epoch 0070, iter [04300, 05004], lr: 0.001000, loss: 0.9232
2022-02-24 18:03:20 - train: epoch 0070, iter [04400, 05004], lr: 0.001000, loss: 1.0747
2022-02-24 18:03:54 - train: epoch 0070, iter [04500, 05004], lr: 0.001000, loss: 0.9604
2022-02-24 18:04:29 - train: epoch 0070, iter [04600, 05004], lr: 0.001000, loss: 1.0796
2022-02-24 18:05:03 - train: epoch 0070, iter [04700, 05004], lr: 0.001000, loss: 1.0507
2022-02-24 18:05:39 - train: epoch 0070, iter [04800, 05004], lr: 0.001000, loss: 0.9767
2022-02-24 18:06:15 - train: epoch 0070, iter [04900, 05004], lr: 0.001000, loss: 1.0165
2022-02-24 18:06:50 - train: epoch 0070, iter [05000, 05004], lr: 0.001000, loss: 0.9193
2022-02-24 18:06:53 - train: epoch 070, train_loss: 0.9700
2022-02-24 18:08:15 - eval: epoch: 070, acc1: 76.630%, acc5: 93.354%, test_loss: 0.9065, per_image_load_time: 1.927ms, per_image_inference_time: 0.570ms
2022-02-24 18:08:17 - until epoch: 070, best_acc1: 76.630%
2022-02-24 18:08:17 - epoch 071 lr: 0.0010000000000000002
2022-02-24 18:08:56 - train: epoch 0071, iter [00100, 05004], lr: 0.001000, loss: 0.8602
2022-02-24 18:09:29 - train: epoch 0071, iter [00200, 05004], lr: 0.001000, loss: 0.9627
2022-02-24 18:10:01 - train: epoch 0071, iter [00300, 05004], lr: 0.001000, loss: 0.8488
2022-02-24 18:10:34 - train: epoch 0071, iter [00400, 05004], lr: 0.001000, loss: 0.9469
2022-02-24 18:11:07 - train: epoch 0071, iter [00500, 05004], lr: 0.001000, loss: 1.0107
2022-02-24 18:11:40 - train: epoch 0071, iter [00600, 05004], lr: 0.001000, loss: 1.0289
2022-02-24 18:12:13 - train: epoch 0071, iter [00700, 05004], lr: 0.001000, loss: 1.1269
2022-02-24 18:12:46 - train: epoch 0071, iter [00800, 05004], lr: 0.001000, loss: 0.9590
2022-02-24 18:13:20 - train: epoch 0071, iter [00900, 05004], lr: 0.001000, loss: 1.0125
2022-02-24 18:13:53 - train: epoch 0071, iter [01000, 05004], lr: 0.001000, loss: 1.0494
2022-02-24 18:14:26 - train: epoch 0071, iter [01100, 05004], lr: 0.001000, loss: 1.1086
2022-02-24 18:14:59 - train: epoch 0071, iter [01200, 05004], lr: 0.001000, loss: 0.9372
2022-02-24 18:15:32 - train: epoch 0071, iter [01300, 05004], lr: 0.001000, loss: 0.9633
2022-02-24 18:16:05 - train: epoch 0071, iter [01400, 05004], lr: 0.001000, loss: 0.9800
2022-02-24 18:16:38 - train: epoch 0071, iter [01500, 05004], lr: 0.001000, loss: 0.7296
2022-02-24 18:17:11 - train: epoch 0071, iter [01600, 05004], lr: 0.001000, loss: 1.0448
2022-02-24 18:17:44 - train: epoch 0071, iter [01700, 05004], lr: 0.001000, loss: 0.9527
2022-02-24 18:18:17 - train: epoch 0071, iter [01800, 05004], lr: 0.001000, loss: 1.0094
2022-02-24 18:18:50 - train: epoch 0071, iter [01900, 05004], lr: 0.001000, loss: 0.8597
2022-02-24 18:19:23 - train: epoch 0071, iter [02000, 05004], lr: 0.001000, loss: 1.0666
2022-02-24 18:19:56 - train: epoch 0071, iter [02100, 05004], lr: 0.001000, loss: 0.8529
2022-02-24 18:20:29 - train: epoch 0071, iter [02200, 05004], lr: 0.001000, loss: 0.8817
2022-02-24 18:21:02 - train: epoch 0071, iter [02300, 05004], lr: 0.001000, loss: 0.8276
2022-02-24 18:21:35 - train: epoch 0071, iter [02400, 05004], lr: 0.001000, loss: 0.9169
2022-02-24 18:22:08 - train: epoch 0071, iter [02500, 05004], lr: 0.001000, loss: 1.0400
2022-02-24 18:22:42 - train: epoch 0071, iter [02600, 05004], lr: 0.001000, loss: 0.8890
2022-02-24 18:23:15 - train: epoch 0071, iter [02700, 05004], lr: 0.001000, loss: 1.0232
2022-02-24 18:23:49 - train: epoch 0071, iter [02800, 05004], lr: 0.001000, loss: 1.0396
2022-02-24 18:24:22 - train: epoch 0071, iter [02900, 05004], lr: 0.001000, loss: 1.0119
2022-02-24 18:24:56 - train: epoch 0071, iter [03000, 05004], lr: 0.001000, loss: 1.0138
2022-02-24 18:25:29 - train: epoch 0071, iter [03100, 05004], lr: 0.001000, loss: 0.8963
2022-02-24 18:26:02 - train: epoch 0071, iter [03200, 05004], lr: 0.001000, loss: 0.8696
2022-02-24 18:26:37 - train: epoch 0071, iter [03300, 05004], lr: 0.001000, loss: 0.8204
2022-02-24 18:27:10 - train: epoch 0071, iter [03400, 05004], lr: 0.001000, loss: 0.9059
2022-02-24 18:27:45 - train: epoch 0071, iter [03500, 05004], lr: 0.001000, loss: 1.0617
2022-02-24 18:28:19 - train: epoch 0071, iter [03600, 05004], lr: 0.001000, loss: 1.0842
2022-02-24 18:28:52 - train: epoch 0071, iter [03700, 05004], lr: 0.001000, loss: 0.9648
2022-02-24 18:29:28 - train: epoch 0071, iter [03800, 05004], lr: 0.001000, loss: 0.9690
2022-02-24 18:30:01 - train: epoch 0071, iter [03900, 05004], lr: 0.001000, loss: 1.0229
2022-02-24 18:30:36 - train: epoch 0071, iter [04000, 05004], lr: 0.001000, loss: 1.1109
2022-02-24 18:31:10 - train: epoch 0071, iter [04100, 05004], lr: 0.001000, loss: 0.9971
2022-02-24 18:31:44 - train: epoch 0071, iter [04200, 05004], lr: 0.001000, loss: 1.0857
2022-02-24 18:32:20 - train: epoch 0071, iter [04300, 05004], lr: 0.001000, loss: 1.0199
2022-02-24 18:32:54 - train: epoch 0071, iter [04400, 05004], lr: 0.001000, loss: 0.9679
2022-02-24 18:33:31 - train: epoch 0071, iter [04500, 05004], lr: 0.001000, loss: 0.8692
2022-02-24 18:34:11 - train: epoch 0071, iter [04600, 05004], lr: 0.001000, loss: 1.0958
2022-02-24 18:34:48 - train: epoch 0071, iter [04700, 05004], lr: 0.001000, loss: 0.8347
2022-02-24 18:35:33 - train: epoch 0071, iter [04800, 05004], lr: 0.001000, loss: 0.8178
2022-02-24 18:36:20 - train: epoch 0071, iter [04900, 05004], lr: 0.001000, loss: 0.7210
2022-02-24 18:37:09 - train: epoch 0071, iter [05000, 05004], lr: 0.001000, loss: 0.8627
2022-02-24 18:37:12 - train: epoch 071, train_loss: 0.9649
2022-02-24 18:38:34 - eval: epoch: 071, acc1: 76.792%, acc5: 93.360%, test_loss: 0.9037, per_image_load_time: 1.597ms, per_image_inference_time: 0.606ms
2022-02-24 18:38:35 - until epoch: 071, best_acc1: 76.792%
2022-02-24 18:38:35 - epoch 072 lr: 0.0010000000000000002
2022-02-24 18:39:15 - train: epoch 0072, iter [00100, 05004], lr: 0.001000, loss: 1.0212
2022-02-24 18:39:48 - train: epoch 0072, iter [00200, 05004], lr: 0.001000, loss: 0.8830
2022-02-24 18:40:21 - train: epoch 0072, iter [00300, 05004], lr: 0.001000, loss: 0.8465
2022-02-24 18:40:54 - train: epoch 0072, iter [00400, 05004], lr: 0.001000, loss: 0.9953
2022-02-24 18:41:27 - train: epoch 0072, iter [00500, 05004], lr: 0.001000, loss: 0.8912
2022-02-24 18:41:59 - train: epoch 0072, iter [00600, 05004], lr: 0.001000, loss: 0.9390
2022-02-24 18:42:33 - train: epoch 0072, iter [00700, 05004], lr: 0.001000, loss: 0.9852
2022-02-24 18:43:05 - train: epoch 0072, iter [00800, 05004], lr: 0.001000, loss: 1.0997
2022-02-24 18:43:39 - train: epoch 0072, iter [00900, 05004], lr: 0.001000, loss: 0.8669
2022-02-24 18:44:12 - train: epoch 0072, iter [01000, 05004], lr: 0.001000, loss: 0.8646
2022-02-24 18:44:45 - train: epoch 0072, iter [01100, 05004], lr: 0.001000, loss: 0.9558
2022-02-24 18:45:18 - train: epoch 0072, iter [01200, 05004], lr: 0.001000, loss: 0.8874
2022-02-24 18:45:51 - train: epoch 0072, iter [01300, 05004], lr: 0.001000, loss: 1.0202
2022-02-24 18:46:24 - train: epoch 0072, iter [01400, 05004], lr: 0.001000, loss: 1.0181
2022-02-24 18:46:57 - train: epoch 0072, iter [01500, 05004], lr: 0.001000, loss: 0.9227
2022-02-24 18:47:30 - train: epoch 0072, iter [01600, 05004], lr: 0.001000, loss: 1.0473
2022-02-24 18:48:04 - train: epoch 0072, iter [01700, 05004], lr: 0.001000, loss: 0.8836
2022-02-24 18:48:37 - train: epoch 0072, iter [01800, 05004], lr: 0.001000, loss: 0.7770
2022-02-24 18:49:11 - train: epoch 0072, iter [01900, 05004], lr: 0.001000, loss: 0.7872
2022-02-24 18:49:44 - train: epoch 0072, iter [02000, 05004], lr: 0.001000, loss: 1.0159
2022-02-24 18:50:18 - train: epoch 0072, iter [02100, 05004], lr: 0.001000, loss: 1.0043
2022-02-24 18:50:51 - train: epoch 0072, iter [02200, 05004], lr: 0.001000, loss: 1.0328
2022-02-24 18:51:24 - train: epoch 0072, iter [02300, 05004], lr: 0.001000, loss: 1.0852
2022-02-24 18:51:58 - train: epoch 0072, iter [02400, 05004], lr: 0.001000, loss: 0.8758
2022-02-24 18:52:31 - train: epoch 0072, iter [02500, 05004], lr: 0.001000, loss: 0.8765
2022-02-24 18:53:05 - train: epoch 0072, iter [02600, 05004], lr: 0.001000, loss: 0.8493
2022-02-24 18:53:39 - train: epoch 0072, iter [02700, 05004], lr: 0.001000, loss: 0.8725
2022-02-24 18:54:12 - train: epoch 0072, iter [02800, 05004], lr: 0.001000, loss: 1.0654
2022-02-24 18:54:46 - train: epoch 0072, iter [02900, 05004], lr: 0.001000, loss: 0.9386
2022-02-24 18:55:19 - train: epoch 0072, iter [03000, 05004], lr: 0.001000, loss: 0.9044
2022-02-24 18:55:53 - train: epoch 0072, iter [03100, 05004], lr: 0.001000, loss: 1.0518
2022-02-24 18:56:27 - train: epoch 0072, iter [03200, 05004], lr: 0.001000, loss: 0.9308
2022-02-24 18:57:00 - train: epoch 0072, iter [03300, 05004], lr: 0.001000, loss: 0.8868
2022-02-24 18:57:34 - train: epoch 0072, iter [03400, 05004], lr: 0.001000, loss: 1.0144
2022-02-24 18:58:08 - train: epoch 0072, iter [03500, 05004], lr: 0.001000, loss: 0.9355
2022-02-24 18:58:42 - train: epoch 0072, iter [03600, 05004], lr: 0.001000, loss: 0.8566
2022-02-24 18:59:16 - train: epoch 0072, iter [03700, 05004], lr: 0.001000, loss: 1.0823
2022-02-24 18:59:49 - train: epoch 0072, iter [03800, 05004], lr: 0.001000, loss: 0.9535
2022-02-24 19:00:24 - train: epoch 0072, iter [03900, 05004], lr: 0.001000, loss: 1.0655
2022-02-24 19:00:58 - train: epoch 0072, iter [04000, 05004], lr: 0.001000, loss: 0.9578
2022-02-24 19:01:33 - train: epoch 0072, iter [04100, 05004], lr: 0.001000, loss: 1.0518
2022-02-24 19:02:07 - train: epoch 0072, iter [04200, 05004], lr: 0.001000, loss: 0.9718
2022-02-24 19:02:41 - train: epoch 0072, iter [04300, 05004], lr: 0.001000, loss: 0.9923
2022-02-24 19:03:18 - train: epoch 0072, iter [04400, 05004], lr: 0.001000, loss: 0.8345
2022-02-24 19:03:51 - train: epoch 0072, iter [04500, 05004], lr: 0.001000, loss: 1.0100
2022-02-24 19:04:30 - train: epoch 0072, iter [04600, 05004], lr: 0.001000, loss: 0.9839
2022-02-24 19:05:07 - train: epoch 0072, iter [04700, 05004], lr: 0.001000, loss: 1.0055
2022-02-24 19:06:12 - train: epoch 0072, iter [04800, 05004], lr: 0.001000, loss: 1.1593
2022-02-24 19:07:29 - train: epoch 0072, iter [04900, 05004], lr: 0.001000, loss: 1.0301
2022-02-24 19:08:15 - train: epoch 0072, iter [05000, 05004], lr: 0.001000, loss: 0.9135
2022-02-24 19:08:20 - train: epoch 072, train_loss: 0.9612
2022-02-24 19:09:46 - eval: epoch: 072, acc1: 76.658%, acc5: 93.326%, test_loss: 0.9062, per_image_load_time: 0.814ms, per_image_inference_time: 0.573ms
2022-02-24 19:09:47 - until epoch: 072, best_acc1: 76.792%
2022-02-24 19:09:47 - epoch 073 lr: 0.0010000000000000002
2022-02-24 19:10:26 - train: epoch 0073, iter [00100, 05004], lr: 0.001000, loss: 1.1709
2022-02-24 19:10:59 - train: epoch 0073, iter [00200, 05004], lr: 0.001000, loss: 0.9821
2022-02-24 19:11:32 - train: epoch 0073, iter [00300, 05004], lr: 0.001000, loss: 1.0571
2022-02-24 19:12:05 - train: epoch 0073, iter [00400, 05004], lr: 0.001000, loss: 0.7131
2022-02-24 19:12:38 - train: epoch 0073, iter [00500, 05004], lr: 0.001000, loss: 0.8733
2022-02-24 19:13:11 - train: epoch 0073, iter [00600, 05004], lr: 0.001000, loss: 0.8569
2022-02-24 19:13:44 - train: epoch 0073, iter [00700, 05004], lr: 0.001000, loss: 0.9116
2022-02-24 19:14:17 - train: epoch 0073, iter [00800, 05004], lr: 0.001000, loss: 0.8275
2022-02-24 19:14:50 - train: epoch 0073, iter [00900, 05004], lr: 0.001000, loss: 0.7948
2022-02-24 19:15:23 - train: epoch 0073, iter [01000, 05004], lr: 0.001000, loss: 0.9525
2022-02-24 19:15:55 - train: epoch 0073, iter [01100, 05004], lr: 0.001000, loss: 0.9923
2022-02-24 19:16:28 - train: epoch 0073, iter [01200, 05004], lr: 0.001000, loss: 0.9566
2022-02-24 19:17:01 - train: epoch 0073, iter [01300, 05004], lr: 0.001000, loss: 0.9324
2022-02-24 19:17:34 - train: epoch 0073, iter [01400, 05004], lr: 0.001000, loss: 0.8558
2022-02-24 19:18:07 - train: epoch 0073, iter [01500, 05004], lr: 0.001000, loss: 0.8997
2022-02-24 19:18:40 - train: epoch 0073, iter [01600, 05004], lr: 0.001000, loss: 1.0088
2022-02-24 19:19:13 - train: epoch 0073, iter [01700, 05004], lr: 0.001000, loss: 1.2019
2022-02-24 19:19:46 - train: epoch 0073, iter [01800, 05004], lr: 0.001000, loss: 0.8138
2022-02-24 19:20:19 - train: epoch 0073, iter [01900, 05004], lr: 0.001000, loss: 1.0434
2022-02-24 19:20:51 - train: epoch 0073, iter [02000, 05004], lr: 0.001000, loss: 0.7570
2022-02-24 19:21:25 - train: epoch 0073, iter [02100, 05004], lr: 0.001000, loss: 0.9481
2022-02-24 19:21:59 - train: epoch 0073, iter [02200, 05004], lr: 0.001000, loss: 1.0994
2022-02-24 19:22:33 - train: epoch 0073, iter [02300, 05004], lr: 0.001000, loss: 1.0882
2022-02-24 19:23:06 - train: epoch 0073, iter [02400, 05004], lr: 0.001000, loss: 0.9558
2022-02-24 19:23:41 - train: epoch 0073, iter [02500, 05004], lr: 0.001000, loss: 1.0646
2022-02-24 19:24:14 - train: epoch 0073, iter [02600, 05004], lr: 0.001000, loss: 1.0119
2022-02-24 19:24:48 - train: epoch 0073, iter [02700, 05004], lr: 0.001000, loss: 1.0357
2022-02-24 19:25:21 - train: epoch 0073, iter [02800, 05004], lr: 0.001000, loss: 1.0022
2022-02-24 19:25:54 - train: epoch 0073, iter [02900, 05004], lr: 0.001000, loss: 1.0979
2022-02-24 19:26:27 - train: epoch 0073, iter [03000, 05004], lr: 0.001000, loss: 0.7939
2022-02-24 19:27:01 - train: epoch 0073, iter [03100, 05004], lr: 0.001000, loss: 0.9152
2022-02-24 19:27:35 - train: epoch 0073, iter [03200, 05004], lr: 0.001000, loss: 0.8357
2022-02-24 19:28:08 - train: epoch 0073, iter [03300, 05004], lr: 0.001000, loss: 0.8725
2022-02-24 19:28:42 - train: epoch 0073, iter [03400, 05004], lr: 0.001000, loss: 0.9684
2022-02-24 19:29:16 - train: epoch 0073, iter [03500, 05004], lr: 0.001000, loss: 0.9753
2022-02-24 19:29:49 - train: epoch 0073, iter [03600, 05004], lr: 0.001000, loss: 0.8397
2022-02-24 19:30:28 - train: epoch 0073, iter [03700, 05004], lr: 0.001000, loss: 0.9594
2022-02-24 19:31:05 - train: epoch 0073, iter [03800, 05004], lr: 0.001000, loss: 1.1843
2022-02-24 19:31:40 - train: epoch 0073, iter [03900, 05004], lr: 0.001000, loss: 0.9600
2022-02-24 19:32:26 - train: epoch 0073, iter [04000, 05004], lr: 0.001000, loss: 0.9971
2022-02-24 19:32:59 - train: epoch 0073, iter [04100, 05004], lr: 0.001000, loss: 0.9259
2022-02-24 19:33:35 - train: epoch 0073, iter [04200, 05004], lr: 0.001000, loss: 0.9970
2022-02-24 19:34:08 - train: epoch 0073, iter [04300, 05004], lr: 0.001000, loss: 0.9736
2022-02-24 19:34:44 - train: epoch 0073, iter [04400, 05004], lr: 0.001000, loss: 0.9718
2022-02-24 19:35:18 - train: epoch 0073, iter [04500, 05004], lr: 0.001000, loss: 0.9237
2022-02-24 19:35:56 - train: epoch 0073, iter [04600, 05004], lr: 0.001000, loss: 1.0919
2022-02-24 19:36:35 - train: epoch 0073, iter [04700, 05004], lr: 0.001000, loss: 0.8146
2022-02-24 19:37:13 - train: epoch 0073, iter [04800, 05004], lr: 0.001000, loss: 1.0725
2022-02-24 19:37:53 - train: epoch 0073, iter [04900, 05004], lr: 0.001000, loss: 0.7858
2022-02-24 19:38:37 - train: epoch 0073, iter [05000, 05004], lr: 0.001000, loss: 1.0220
2022-02-24 19:38:40 - train: epoch 073, train_loss: 0.9564
2022-02-24 19:39:58 - eval: epoch: 073, acc1: 76.762%, acc5: 93.414%, test_loss: 0.9035, per_image_load_time: 1.039ms, per_image_inference_time: 0.609ms
2022-02-24 19:39:59 - until epoch: 073, best_acc1: 76.792%
2022-02-24 19:39:59 - epoch 074 lr: 0.0010000000000000002
2022-02-24 19:40:39 - train: epoch 0074, iter [00100, 05004], lr: 0.001000, loss: 0.8821
2022-02-24 19:41:12 - train: epoch 0074, iter [00200, 05004], lr: 0.001000, loss: 0.9840
2022-02-24 19:41:44 - train: epoch 0074, iter [00300, 05004], lr: 0.001000, loss: 1.0671
2022-02-24 19:42:17 - train: epoch 0074, iter [00400, 05004], lr: 0.001000, loss: 1.1164
2022-02-24 19:42:50 - train: epoch 0074, iter [00500, 05004], lr: 0.001000, loss: 1.0606
2022-02-24 19:43:23 - train: epoch 0074, iter [00600, 05004], lr: 0.001000, loss: 0.9994
2022-02-24 19:43:56 - train: epoch 0074, iter [00700, 05004], lr: 0.001000, loss: 0.9568
2022-02-24 19:44:29 - train: epoch 0074, iter [00800, 05004], lr: 0.001000, loss: 1.1335
2022-02-24 19:45:02 - train: epoch 0074, iter [00900, 05004], lr: 0.001000, loss: 0.9969
2022-02-24 19:45:35 - train: epoch 0074, iter [01000, 05004], lr: 0.001000, loss: 1.0195
2022-02-24 19:46:08 - train: epoch 0074, iter [01100, 05004], lr: 0.001000, loss: 1.1034
2022-02-24 19:46:41 - train: epoch 0074, iter [01200, 05004], lr: 0.001000, loss: 0.8984
2022-02-24 19:47:14 - train: epoch 0074, iter [01300, 05004], lr: 0.001000, loss: 1.0828
2022-02-24 19:47:47 - train: epoch 0074, iter [01400, 05004], lr: 0.001000, loss: 0.8494
2022-02-24 19:48:20 - train: epoch 0074, iter [01500, 05004], lr: 0.001000, loss: 0.8757
2022-02-24 19:48:53 - train: epoch 0074, iter [01600, 05004], lr: 0.001000, loss: 0.7139
2022-02-24 19:49:27 - train: epoch 0074, iter [01700, 05004], lr: 0.001000, loss: 1.0077
2022-02-24 19:50:00 - train: epoch 0074, iter [01800, 05004], lr: 0.001000, loss: 1.2574
2022-02-24 19:50:33 - train: epoch 0074, iter [01900, 05004], lr: 0.001000, loss: 1.0512
2022-02-24 19:51:06 - train: epoch 0074, iter [02000, 05004], lr: 0.001000, loss: 0.6921
2022-02-24 19:51:40 - train: epoch 0074, iter [02100, 05004], lr: 0.001000, loss: 0.8934
2022-02-24 19:52:13 - train: epoch 0074, iter [02200, 05004], lr: 0.001000, loss: 1.2521
2022-02-24 19:52:47 - train: epoch 0074, iter [02300, 05004], lr: 0.001000, loss: 1.0728
2022-02-24 19:53:20 - train: epoch 0074, iter [02400, 05004], lr: 0.001000, loss: 0.9992
2022-02-24 19:53:54 - train: epoch 0074, iter [02500, 05004], lr: 0.001000, loss: 0.9180
2022-02-24 19:54:27 - train: epoch 0074, iter [02600, 05004], lr: 0.001000, loss: 0.7705
2022-02-24 19:55:01 - train: epoch 0074, iter [02700, 05004], lr: 0.001000, loss: 0.8794
2022-02-24 19:55:34 - train: epoch 0074, iter [02800, 05004], lr: 0.001000, loss: 1.1740
2022-02-24 19:56:07 - train: epoch 0074, iter [02900, 05004], lr: 0.001000, loss: 0.8790
2022-02-24 19:56:41 - train: epoch 0074, iter [03000, 05004], lr: 0.001000, loss: 0.9563
2022-02-24 19:57:14 - train: epoch 0074, iter [03100, 05004], lr: 0.001000, loss: 0.9048
2022-02-24 19:57:49 - train: epoch 0074, iter [03200, 05004], lr: 0.001000, loss: 0.8956
2022-02-24 19:58:22 - train: epoch 0074, iter [03300, 05004], lr: 0.001000, loss: 0.9792
2022-02-24 19:58:56 - train: epoch 0074, iter [03400, 05004], lr: 0.001000, loss: 0.9942
2022-02-24 19:59:30 - train: epoch 0074, iter [03500, 05004], lr: 0.001000, loss: 0.8551
2022-02-24 20:00:04 - train: epoch 0074, iter [03600, 05004], lr: 0.001000, loss: 0.9606
2022-02-24 20:00:38 - train: epoch 0074, iter [03700, 05004], lr: 0.001000, loss: 0.9623
2022-02-24 20:01:12 - train: epoch 0074, iter [03800, 05004], lr: 0.001000, loss: 0.9563
2022-02-24 20:01:46 - train: epoch 0074, iter [03900, 05004], lr: 0.001000, loss: 0.7684
2022-02-24 20:02:21 - train: epoch 0074, iter [04000, 05004], lr: 0.001000, loss: 0.8402
2022-02-24 20:02:55 - train: epoch 0074, iter [04100, 05004], lr: 0.001000, loss: 1.1354
2022-02-24 20:03:31 - train: epoch 0074, iter [04200, 05004], lr: 0.001000, loss: 0.9232
2022-02-24 20:04:05 - train: epoch 0074, iter [04300, 05004], lr: 0.001000, loss: 0.8886
2022-02-24 20:04:42 - train: epoch 0074, iter [04400, 05004], lr: 0.001000, loss: 0.8440
2022-02-24 20:05:18 - train: epoch 0074, iter [04500, 05004], lr: 0.001000, loss: 0.7968
2022-02-24 20:06:02 - train: epoch 0074, iter [04600, 05004], lr: 0.001000, loss: 1.0458
2022-02-24 20:07:19 - train: epoch 0074, iter [04700, 05004], lr: 0.001000, loss: 1.0479
2022-02-24 20:08:12 - train: epoch 0074, iter [04800, 05004], lr: 0.001000, loss: 1.0334
2022-02-24 20:08:58 - train: epoch 0074, iter [04900, 05004], lr: 0.001000, loss: 1.1435
2022-02-24 20:09:40 - train: epoch 0074, iter [05000, 05004], lr: 0.001000, loss: 0.9703
2022-02-24 20:09:42 - train: epoch 074, train_loss: 0.9506
2022-02-24 20:11:10 - eval: epoch: 074, acc1: 76.828%, acc5: 93.456%, test_loss: 0.9028, per_image_load_time: 2.810ms, per_image_inference_time: 0.555ms
2022-02-24 20:11:11 - until epoch: 074, best_acc1: 76.828%
2022-02-24 20:11:11 - epoch 075 lr: 0.0010000000000000002
2022-02-24 20:11:51 - train: epoch 0075, iter [00100, 05004], lr: 0.001000, loss: 0.9919
2022-02-24 20:12:24 - train: epoch 0075, iter [00200, 05004], lr: 0.001000, loss: 0.9018
2022-02-24 20:12:57 - train: epoch 0075, iter [00300, 05004], lr: 0.001000, loss: 0.8771
2022-02-24 20:13:30 - train: epoch 0075, iter [00400, 05004], lr: 0.001000, loss: 1.0118
2022-02-24 20:14:02 - train: epoch 0075, iter [00500, 05004], lr: 0.001000, loss: 0.7644
2022-02-24 20:14:35 - train: epoch 0075, iter [00600, 05004], lr: 0.001000, loss: 0.9190
2022-02-24 20:15:08 - train: epoch 0075, iter [00700, 05004], lr: 0.001000, loss: 1.0066
2022-02-24 20:15:40 - train: epoch 0075, iter [00800, 05004], lr: 0.001000, loss: 1.1295
2022-02-24 20:16:14 - train: epoch 0075, iter [00900, 05004], lr: 0.001000, loss: 1.1258
2022-02-24 20:16:46 - train: epoch 0075, iter [01000, 05004], lr: 0.001000, loss: 0.7557
2022-02-24 20:17:19 - train: epoch 0075, iter [01100, 05004], lr: 0.001000, loss: 1.0206
2022-02-24 20:17:52 - train: epoch 0075, iter [01200, 05004], lr: 0.001000, loss: 0.8746
2022-02-24 20:18:25 - train: epoch 0075, iter [01300, 05004], lr: 0.001000, loss: 0.8567
2022-02-24 20:18:58 - train: epoch 0075, iter [01400, 05004], lr: 0.001000, loss: 0.9423
2022-02-24 20:19:32 - train: epoch 0075, iter [01500, 05004], lr: 0.001000, loss: 1.1178
2022-02-24 20:20:07 - train: epoch 0075, iter [01600, 05004], lr: 0.001000, loss: 0.7176
2022-02-24 20:20:41 - train: epoch 0075, iter [01700, 05004], lr: 0.001000, loss: 0.8803
2022-02-24 20:21:14 - train: epoch 0075, iter [01800, 05004], lr: 0.001000, loss: 0.9306
2022-02-24 20:21:47 - train: epoch 0075, iter [01900, 05004], lr: 0.001000, loss: 0.8328
2022-02-24 20:22:21 - train: epoch 0075, iter [02000, 05004], lr: 0.001000, loss: 0.9995
2022-02-24 20:22:54 - train: epoch 0075, iter [02100, 05004], lr: 0.001000, loss: 0.9109
2022-02-24 20:23:27 - train: epoch 0075, iter [02200, 05004], lr: 0.001000, loss: 1.0156
2022-02-24 20:24:00 - train: epoch 0075, iter [02300, 05004], lr: 0.001000, loss: 1.0099
2022-02-24 20:24:33 - train: epoch 0075, iter [02400, 05004], lr: 0.001000, loss: 0.9495
2022-02-24 20:25:06 - train: epoch 0075, iter [02500, 05004], lr: 0.001000, loss: 0.9658
2022-02-24 20:25:39 - train: epoch 0075, iter [02600, 05004], lr: 0.001000, loss: 1.0334
2022-02-24 20:26:12 - train: epoch 0075, iter [02700, 05004], lr: 0.001000, loss: 0.7980
2022-02-24 20:26:45 - train: epoch 0075, iter [02800, 05004], lr: 0.001000, loss: 0.8802
2022-02-24 20:27:19 - train: epoch 0075, iter [02900, 05004], lr: 0.001000, loss: 1.0460
2022-02-24 20:27:52 - train: epoch 0075, iter [03000, 05004], lr: 0.001000, loss: 1.1408
2022-02-24 20:28:25 - train: epoch 0075, iter [03100, 05004], lr: 0.001000, loss: 0.9716
2022-02-24 20:28:59 - train: epoch 0075, iter [03200, 05004], lr: 0.001000, loss: 0.9052
2022-02-24 20:29:32 - train: epoch 0075, iter [03300, 05004], lr: 0.001000, loss: 0.9834
2022-02-24 20:30:06 - train: epoch 0075, iter [03400, 05004], lr: 0.001000, loss: 0.7797
2022-02-24 20:30:40 - train: epoch 0075, iter [03500, 05004], lr: 0.001000, loss: 0.8789
2022-02-24 20:31:15 - train: epoch 0075, iter [03600, 05004], lr: 0.001000, loss: 0.8996
2022-02-24 20:31:49 - train: epoch 0075, iter [03700, 05004], lr: 0.001000, loss: 0.9034
2022-02-24 20:32:24 - train: epoch 0075, iter [03800, 05004], lr: 0.001000, loss: 0.9390
2022-02-24 20:32:59 - train: epoch 0075, iter [03900, 05004], lr: 0.001000, loss: 1.1066
2022-02-24 20:33:33 - train: epoch 0075, iter [04000, 05004], lr: 0.001000, loss: 0.9107
2022-02-24 20:34:08 - train: epoch 0075, iter [04100, 05004], lr: 0.001000, loss: 0.7086
2022-02-24 20:34:43 - train: epoch 0075, iter [04200, 05004], lr: 0.001000, loss: 1.0246
2022-02-24 20:35:18 - train: epoch 0075, iter [04300, 05004], lr: 0.001000, loss: 1.1523
2022-02-24 20:35:55 - train: epoch 0075, iter [04400, 05004], lr: 0.001000, loss: 0.7691
2022-02-24 20:36:31 - train: epoch 0075, iter [04500, 05004], lr: 0.001000, loss: 0.9846
2022-02-24 20:37:11 - train: epoch 0075, iter [04600, 05004], lr: 0.001000, loss: 0.8032
2022-02-24 20:37:53 - train: epoch 0075, iter [04700, 05004], lr: 0.001000, loss: 1.1001
2022-02-24 20:38:34 - train: epoch 0075, iter [04800, 05004], lr: 0.001000, loss: 0.9650
2022-02-24 20:39:15 - train: epoch 0075, iter [04900, 05004], lr: 0.001000, loss: 0.8221
2022-02-24 20:40:04 - train: epoch 0075, iter [05000, 05004], lr: 0.001000, loss: 1.0610
2022-02-24 20:40:07 - train: epoch 075, train_loss: 0.9482
2022-02-24 20:41:42 - eval: epoch: 075, acc1: 76.830%, acc5: 93.358%, test_loss: 0.9003, per_image_load_time: 1.363ms, per_image_inference_time: 0.555ms
2022-02-24 20:41:43 - until epoch: 075, best_acc1: 76.830%
2022-02-24 20:41:43 - epoch 076 lr: 0.0010000000000000002
2022-02-24 20:42:23 - train: epoch 0076, iter [00100, 05004], lr: 0.001000, loss: 0.7714
2022-02-24 20:42:56 - train: epoch 0076, iter [00200, 05004], lr: 0.001000, loss: 0.9572
2022-02-24 20:43:29 - train: epoch 0076, iter [00300, 05004], lr: 0.001000, loss: 0.9824
2022-02-24 20:44:02 - train: epoch 0076, iter [00400, 05004], lr: 0.001000, loss: 0.9913
2022-02-24 20:44:35 - train: epoch 0076, iter [00500, 05004], lr: 0.001000, loss: 0.9320
2022-02-24 20:45:08 - train: epoch 0076, iter [00600, 05004], lr: 0.001000, loss: 0.9586
2022-02-24 20:45:41 - train: epoch 0076, iter [00700, 05004], lr: 0.001000, loss: 0.9648
2022-02-24 20:46:14 - train: epoch 0076, iter [00800, 05004], lr: 0.001000, loss: 0.8729
2022-02-24 20:46:47 - train: epoch 0076, iter [00900, 05004], lr: 0.001000, loss: 0.7625
2022-02-24 20:47:21 - train: epoch 0076, iter [01000, 05004], lr: 0.001000, loss: 0.7260
2022-02-24 20:47:53 - train: epoch 0076, iter [01100, 05004], lr: 0.001000, loss: 0.8524
2022-02-24 20:48:27 - train: epoch 0076, iter [01200, 05004], lr: 0.001000, loss: 0.9580
2022-02-24 20:49:00 - train: epoch 0076, iter [01300, 05004], lr: 0.001000, loss: 0.9623
2022-02-24 20:49:33 - train: epoch 0076, iter [01400, 05004], lr: 0.001000, loss: 0.9224
2022-02-24 20:50:07 - train: epoch 0076, iter [01500, 05004], lr: 0.001000, loss: 0.8057
2022-02-24 20:50:40 - train: epoch 0076, iter [01600, 05004], lr: 0.001000, loss: 0.8813
2022-02-24 20:51:13 - train: epoch 0076, iter [01700, 05004], lr: 0.001000, loss: 0.9238
2022-02-24 20:51:46 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 0.7685
2022-02-24 20:52:19 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 1.0917
2022-02-24 20:52:53 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 1.0023
2022-02-24 20:53:26 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 1.0753
2022-02-24 20:53:59 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 1.0855
2022-02-24 20:54:32 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 0.9443
2022-02-24 20:55:05 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 1.1266
2022-02-24 20:55:38 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 0.8984
2022-02-24 20:56:11 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 1.0769
2022-02-24 20:56:45 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 0.9736
2022-02-24 20:57:18 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 0.8849
2022-02-24 20:57:52 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 0.8830
2022-02-24 20:58:25 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 0.8276
2022-02-24 20:58:59 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 0.9345
2022-02-24 20:59:32 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 1.0241
2022-02-24 21:00:06 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 0.9507
2022-02-24 21:00:40 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 0.9757
2022-02-24 21:01:14 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 0.8585
2022-02-24 21:01:48 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 0.8910
2022-02-24 21:02:22 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 0.8663
2022-02-24 21:02:55 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 0.8398
2022-02-24 21:03:30 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 0.7664
2022-02-24 21:04:04 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 0.9302
2022-02-24 21:04:38 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 0.8503
2022-02-24 21:05:13 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 1.1294
2022-02-24 21:05:47 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 0.9249
2022-02-24 21:06:23 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 0.8930
2022-02-24 21:07:01 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 0.9773
2022-02-24 21:07:39 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 0.8401
2022-02-24 21:08:17 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 1.0092
2022-02-24 21:09:00 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 0.7340
2022-02-24 21:09:45 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 0.9372
2022-02-24 21:10:34 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 1.0136
2022-02-24 21:10:39 - train: epoch 076, train_loss: 0.9447
2022-02-24 21:12:41 - eval: epoch: 076, acc1: 76.912%, acc5: 93.434%, test_loss: 0.9001, per_image_load_time: 2.985ms, per_image_inference_time: 0.546ms
2022-02-24 21:12:42 - until epoch: 076, best_acc1: 76.912%
2022-02-24 21:12:42 - epoch 077 lr: 0.0010000000000000002
2022-02-24 21:13:22 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 1.0303
2022-02-24 21:13:56 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 0.9671
2022-02-24 21:14:28 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 0.7442
2022-02-24 21:15:01 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 1.0327
2022-02-24 21:15:34 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 0.7242
2022-02-24 21:16:07 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 0.7324
2022-02-24 21:16:40 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 0.9626
2022-02-24 21:17:13 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 1.0645
2022-02-24 21:17:47 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 1.0497
2022-02-24 21:18:20 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 0.8176
2022-02-24 21:18:53 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 0.9717
2022-02-24 21:19:26 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 0.9805
2022-02-24 21:19:59 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 0.8314
2022-02-24 21:20:33 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 1.0479
2022-02-24 21:21:06 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 0.8248
2022-02-24 21:21:39 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 0.9544
2022-02-24 21:22:13 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 1.1477
2022-02-24 21:22:46 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 0.7753
2022-02-24 21:23:19 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 0.9321
2022-02-24 21:23:52 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 0.8240
2022-02-24 21:24:25 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 0.9503
2022-02-24 21:24:59 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 1.0227
2022-02-24 21:25:32 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 1.0690
2022-02-24 21:26:06 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 0.9658
2022-02-24 21:26:40 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 1.0528
2022-02-24 21:27:15 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 0.7377
2022-02-24 21:27:49 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 1.0017
2022-02-24 21:28:25 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 0.9996
2022-02-24 21:28:58 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 1.2393
2022-02-24 21:29:32 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 0.8523
2022-02-24 21:30:06 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 0.9887
2022-02-24 21:30:43 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 1.0108
2022-02-24 21:31:18 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 0.8410
2022-02-24 21:31:56 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 1.1423
2022-02-24 21:32:30 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 0.8238
2022-02-24 21:33:04 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 0.9830
2022-02-24 21:33:38 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 1.0143
2022-02-24 21:34:12 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 0.9718
2022-02-24 21:34:47 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 1.0311
2022-02-24 21:35:29 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 0.9587
2022-02-24 21:36:10 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 1.1043
2022-02-24 21:36:54 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 1.0362
2022-02-24 21:37:28 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 0.8863
2022-02-24 21:38:04 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 0.8862
2022-02-24 21:38:41 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 1.0483
2022-02-24 21:39:18 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 0.9039
2022-02-24 21:40:11 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 0.7645
2022-02-24 21:40:55 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 0.9975
2022-02-24 21:41:39 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 1.1227
2022-02-24 21:42:23 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 1.1768
2022-02-24 21:42:26 - train: epoch 077, train_loss: 0.9389
2022-02-24 21:43:44 - eval: epoch: 077, acc1: 76.842%, acc5: 93.466%, test_loss: 0.9018, per_image_load_time: 2.395ms, per_image_inference_time: 0.587ms
2022-02-24 21:43:44 - until epoch: 077, best_acc1: 76.912%
2022-02-24 21:43:44 - epoch 078 lr: 0.0010000000000000002
2022-02-24 21:44:23 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 0.9434
2022-02-24 21:44:56 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 1.1088
2022-02-24 21:45:29 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 1.0281
2022-02-24 21:46:02 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 0.9416
2022-02-24 21:46:34 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 0.9032
2022-02-24 21:47:07 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 0.9642
2022-02-24 21:47:40 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 1.0179
2022-02-24 21:48:13 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 1.0769
2022-02-24 21:48:45 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 0.9810
2022-02-24 21:49:18 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 0.9638
2022-02-24 21:49:51 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 0.8125
2022-02-24 21:50:23 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 0.7257
2022-02-24 21:50:56 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 1.0509
2022-02-24 21:51:29 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 0.8365
2022-02-24 21:52:01 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 0.9214
2022-02-24 21:52:34 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 1.0731
2022-02-24 21:53:07 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 0.9081
2022-02-24 21:53:39 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 0.9110
2022-02-24 21:54:12 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 0.8169
2022-02-24 21:54:46 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 0.7872
2022-02-24 21:55:19 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 1.1033
2022-02-24 21:55:52 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 0.8794
2022-02-24 21:56:25 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 0.9912
2022-02-24 21:56:58 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 0.8878
2022-02-24 21:57:31 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 0.8153
2022-02-24 21:58:04 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 0.8500
2022-02-24 21:58:37 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 0.9115
2022-02-24 21:59:11 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 0.9406
2022-02-24 21:59:44 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 0.8605
2022-02-24 22:00:18 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 0.7913
2022-02-24 22:00:51 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 1.0739
2022-02-24 22:01:24 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 0.9352
2022-02-24 22:01:58 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 0.9995
2022-02-24 22:02:31 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 0.8465
2022-02-24 22:03:05 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 0.9061
2022-02-24 22:03:38 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 0.9969
2022-02-24 22:04:13 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 0.8464
2022-02-24 22:04:46 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 0.9873
2022-02-24 22:05:20 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 0.9675
2022-02-24 22:05:55 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 0.9178
2022-02-24 22:06:29 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 1.0591
2022-02-24 22:07:04 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 1.0577
2022-02-24 22:07:38 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 1.0145
2022-02-24 22:08:16 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 0.9078
2022-02-24 22:08:54 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 1.0381
2022-02-24 22:09:31 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 0.8085
2022-02-24 22:10:11 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 1.0392
2022-02-24 22:10:53 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 1.1488
2022-02-24 22:11:37 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 0.9742
2022-02-24 22:12:35 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 0.9605
2022-02-24 22:12:38 - train: epoch 078, train_loss: 0.9333
2022-02-24 22:14:08 - eval: epoch: 078, acc1: 76.842%, acc5: 93.374%, test_loss: 0.9036, per_image_load_time: 0.685ms, per_image_inference_time: 0.587ms
2022-02-24 22:14:08 - until epoch: 078, best_acc1: 76.912%
2022-02-24 22:14:08 - epoch 079 lr: 0.0010000000000000002
2022-02-24 22:14:48 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 0.9390
2022-02-24 22:15:21 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 0.8549
2022-02-24 22:15:54 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 1.0219
2022-02-24 22:16:27 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 0.9903
2022-02-24 22:17:00 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 0.9502
2022-02-24 22:17:33 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 0.9174
2022-02-24 22:18:07 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 0.8663
2022-02-24 22:18:40 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 1.0398
2022-02-24 22:19:13 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 0.8072
2022-02-24 22:19:46 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 0.8182
2022-02-24 22:20:19 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 1.0336
2022-02-24 22:20:52 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 1.1882
2022-02-24 22:21:26 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 0.8035
2022-02-24 22:21:59 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 0.8604
2022-02-24 22:22:32 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 0.8148
2022-02-24 22:23:06 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 0.8131
2022-02-24 22:23:39 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 0.7927
2022-02-24 22:24:12 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 0.7884
2022-02-24 22:24:45 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 1.0432
2022-02-24 22:25:18 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 1.1318
2022-02-24 22:25:52 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 0.8112
2022-02-24 22:26:27 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 0.9918
2022-02-24 22:27:01 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 0.8463
2022-02-24 22:27:36 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 1.0159
2022-02-24 22:28:09 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 0.9204
2022-02-24 22:28:42 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 0.8660
2022-02-24 22:29:16 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 0.8061
2022-02-24 22:29:49 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 0.7974
2022-02-24 22:30:22 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 0.8352
2022-02-24 22:30:56 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 1.0026
2022-02-24 22:31:30 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 1.0124
2022-02-24 22:32:04 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 1.1679
2022-02-24 22:32:38 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 0.8883
2022-02-24 22:33:12 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 0.7542
2022-02-24 22:33:46 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 1.1228
2022-02-24 22:34:24 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 0.8223
2022-02-24 22:34:59 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 0.8181
2022-02-24 22:35:33 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 0.9415
2022-02-24 22:36:08 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 0.8167
2022-02-24 22:36:42 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 0.8011
2022-02-24 22:37:17 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 1.0508
2022-02-24 22:37:51 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 0.8276
2022-02-24 22:38:27 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 0.6710
2022-02-24 22:39:02 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 1.0298
2022-02-24 22:39:37 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 1.0798
2022-02-24 22:40:16 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 1.0950
2022-02-24 22:40:51 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 0.9645
2022-02-24 22:41:33 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 1.0150
2022-02-24 22:42:18 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 1.0822
2022-02-24 22:43:04 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 0.8163
2022-02-24 22:43:08 - train: epoch 079, train_loss: 0.9311
2022-02-24 22:44:30 - eval: epoch: 079, acc1: 76.920%, acc5: 93.536%, test_loss: 0.9008, per_image_load_time: 1.209ms, per_image_inference_time: 0.613ms
2022-02-24 22:44:31 - until epoch: 079, best_acc1: 76.920%
2022-02-24 22:44:31 - epoch 080 lr: 0.0010000000000000002
2022-02-24 22:45:10 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 0.7024
2022-02-24 22:45:44 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 0.8147
2022-02-24 22:46:18 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 1.0503
2022-02-24 22:46:52 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 0.7979
2022-02-24 22:47:26 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 0.9814
2022-02-24 22:48:00 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 0.8468
2022-02-24 22:48:33 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 0.9397
2022-02-24 22:49:07 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 0.8009
2022-02-24 22:49:40 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 0.9515
2022-02-24 22:50:14 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 0.8946
2022-02-24 22:50:48 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 0.9245
2022-02-24 22:51:22 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 0.8961
2022-02-24 22:51:55 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 0.8517
2022-02-24 22:52:30 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 0.9640
2022-02-24 22:53:05 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 0.8433
2022-02-24 22:53:38 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 0.9382
2022-02-24 22:54:13 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 0.9645
2022-02-24 22:54:46 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 1.0341
2022-02-24 22:55:20 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 0.9166
2022-02-24 22:55:54 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 0.9852
2022-02-24 22:56:27 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 0.9277
2022-02-24 22:57:01 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 0.9979
2022-02-24 22:57:34 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 0.8867
2022-02-24 22:58:08 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 0.9027
2022-02-24 22:58:42 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 0.9284
2022-02-24 22:59:15 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 0.8548
2022-02-24 22:59:49 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 0.9460
2022-02-24 23:00:22 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 1.0859
2022-02-24 23:00:57 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 0.8407
2022-02-24 23:01:31 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 0.8996
2022-02-24 23:02:05 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 1.1447
2022-02-24 23:02:39 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 0.6532
2022-02-24 23:03:12 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 0.9054
2022-02-24 23:03:47 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 0.8942
2022-02-24 23:04:20 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 0.7400
2022-02-24 23:04:55 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 0.9797
2022-02-24 23:05:29 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 0.9546
2022-02-24 23:06:03 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 0.9785
2022-02-24 23:06:38 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 0.8604
2022-02-24 23:07:12 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 0.9986
2022-02-24 23:07:48 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 0.9801
2022-02-24 23:08:22 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 0.8781
2022-02-24 23:08:58 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 0.9948
2022-02-24 23:09:34 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 0.9259
2022-02-24 23:10:10 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 0.9022
2022-02-24 23:10:50 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 0.9961
2022-02-24 23:11:28 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 0.9603
2022-02-24 23:12:07 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 1.0208
2022-02-24 23:12:50 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 0.9972
2022-02-24 23:13:37 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 0.7104
2022-02-24 23:13:40 - train: epoch 080, train_loss: 0.9295
2022-02-24 23:15:06 - eval: epoch: 080, acc1: 76.916%, acc5: 93.416%, test_loss: 0.9016, per_image_load_time: 2.714ms, per_image_inference_time: 0.564ms
2022-02-24 23:15:07 - until epoch: 080, best_acc1: 76.920%
2022-02-24 23:15:07 - epoch 081 lr: 0.0010000000000000002
2022-02-24 23:15:47 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 0.8336
2022-02-24 23:16:20 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 1.0023
2022-02-24 23:16:54 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 0.8196
2022-02-24 23:17:27 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 1.0021
2022-02-24 23:18:01 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 1.0388
2022-02-24 23:18:34 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 0.9676
2022-02-24 23:19:07 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 0.8525
2022-02-24 23:19:41 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 1.0700
2022-02-24 23:20:14 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 0.7982
2022-02-24 23:20:48 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 0.9496
2022-02-24 23:21:21 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 0.9909
2022-02-24 23:21:55 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 0.9366
2022-02-24 23:22:28 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 0.9004
2022-02-24 23:23:01 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 0.6130
2022-02-24 23:23:34 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 0.9418
2022-02-24 23:24:07 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 0.8652
2022-02-24 23:24:40 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 1.0125
2022-02-24 23:25:13 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 0.7843
2022-02-24 23:25:46 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 0.8157
2022-02-24 23:26:19 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 0.9812
2022-02-24 23:26:52 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 0.9386
2022-02-24 23:27:25 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 0.9561
2022-02-24 23:27:58 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 0.8312
2022-02-24 23:28:31 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 0.8732
2022-02-24 23:29:05 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 1.0987
2022-02-24 23:29:38 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 0.9942
2022-02-24 23:30:11 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 0.9280
2022-02-24 23:30:45 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 0.8924
2022-02-24 23:31:20 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 0.8217
2022-02-24 23:31:54 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 0.9803
2022-02-24 23:32:28 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 0.8244
2022-02-24 23:33:04 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 0.8549
2022-02-24 23:33:38 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 1.0020
2022-02-24 23:34:11 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 1.0422
2022-02-24 23:34:45 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 0.9212
2022-02-24 23:35:23 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 0.8231
2022-02-24 23:35:57 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 1.0122
2022-02-24 23:36:38 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 0.7579
2022-02-24 23:37:15 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 0.9796
2022-02-24 23:37:52 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 0.7134
2022-02-24 23:38:38 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 1.0274
2022-02-24 23:39:13 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 0.9184
2022-02-24 23:39:48 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 0.9513
2022-02-24 23:40:25 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 1.0711
2022-02-24 23:41:17 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 0.9414
2022-02-24 23:42:17 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 0.9320
2022-02-24 23:42:59 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 1.0063
2022-02-24 23:43:43 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 0.9856
2022-02-24 23:44:23 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 0.8372
2022-02-24 23:45:03 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 0.7585
2022-02-24 23:45:06 - train: epoch 081, train_loss: 0.9261
2022-02-24 23:46:39 - eval: epoch: 081, acc1: 76.860%, acc5: 93.474%, test_loss: 0.9008, per_image_load_time: 2.889ms, per_image_inference_time: 0.535ms
2022-02-24 23:46:39 - until epoch: 081, best_acc1: 76.920%
2022-02-24 23:46:39 - epoch 082 lr: 0.0010000000000000002
2022-02-24 23:47:19 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 0.7367
2022-02-24 23:47:52 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 0.8549
2022-02-24 23:48:26 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 1.0165
2022-02-24 23:48:59 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 1.0216
2022-02-24 23:49:33 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 0.9604
2022-02-24 23:50:06 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 0.8441
2022-02-24 23:50:39 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 1.0800
2022-02-24 23:51:13 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 0.9328
2022-02-24 23:51:46 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 1.0064
2022-02-24 23:52:19 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 0.9573
2022-02-24 23:52:53 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 1.0471
2022-02-24 23:53:26 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 0.9701
2022-02-24 23:53:59 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 1.0243
2022-02-24 23:54:32 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 0.8293
2022-02-24 23:55:06 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 0.8052
2022-02-24 23:55:39 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 0.9311
2022-02-24 23:56:13 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 0.8896
2022-02-24 23:56:46 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 0.8421
2022-02-24 23:57:20 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 0.8779
2022-02-24 23:57:54 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 0.7930
2022-02-24 23:58:27 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 0.8366
2022-02-24 23:59:02 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 0.9843
2022-02-24 23:59:36 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 0.9696
2022-02-25 00:00:10 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 1.0490
2022-02-25 00:00:44 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 0.8417
2022-02-25 00:01:18 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 0.8712
2022-02-25 00:01:52 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 0.8590
2022-02-25 00:02:26 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 0.8008
2022-02-25 00:03:01 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 0.8368
2022-02-25 00:03:35 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 0.9026
2022-02-25 00:04:09 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 0.8655
2022-02-25 00:04:43 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 1.0735
2022-02-25 00:05:17 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 0.8114
2022-02-25 00:05:52 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 0.9093
2022-02-25 00:06:26 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 0.8186
2022-02-25 00:07:01 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 0.8425
2022-02-25 00:07:36 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 0.8813
2022-02-25 00:08:10 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 1.1032
2022-02-25 00:08:45 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 0.9816
2022-02-25 00:09:20 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 0.9876
2022-02-25 00:09:54 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 0.8879
2022-02-25 00:10:30 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 0.9609
2022-02-25 00:11:05 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 0.7718
2022-02-25 00:11:41 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 0.9046
2022-02-25 00:12:19 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 1.0069
2022-02-25 00:12:56 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 1.0828
2022-02-25 00:13:39 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 0.8412
2022-02-25 00:14:21 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 0.8405
2022-02-25 00:15:01 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 0.8339
2022-02-25 00:15:44 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 0.9158
2022-02-25 00:15:47 - train: epoch 082, train_loss: 0.9228
2022-02-25 00:17:20 - eval: epoch: 082, acc1: 76.808%, acc5: 93.530%, test_loss: 0.9031, per_image_load_time: 1.693ms, per_image_inference_time: 0.527ms
2022-02-25 00:17:21 - until epoch: 082, best_acc1: 76.920%
2022-02-25 00:17:21 - epoch 083 lr: 0.0010000000000000002
2022-02-25 00:18:01 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 0.8040
2022-02-25 00:18:34 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 0.8526
2022-02-25 00:19:08 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 0.9914
2022-02-25 00:19:41 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 1.1131
2022-02-25 00:20:15 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 0.8935
2022-02-25 00:20:48 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 0.8278
2022-02-25 00:21:22 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 0.8451
2022-02-25 00:21:55 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 0.8898
2022-02-25 00:22:29 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 0.9693
2022-02-25 00:23:02 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 1.0312
2022-02-25 00:23:35 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 0.8763
2022-02-25 00:24:08 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 0.9293
2022-02-25 00:24:42 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 0.8189
2022-02-25 00:25:15 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 1.0445
2022-02-25 00:25:49 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 0.8231
2022-02-25 00:26:23 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 0.9147
2022-02-25 00:26:56 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 1.0265
2022-02-25 00:27:30 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 1.0588
2022-02-25 00:28:03 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 0.7358
2022-02-25 00:28:37 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 0.6651
2022-02-25 00:29:11 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 0.8729
2022-02-25 00:29:44 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 0.9311
2022-02-25 00:30:18 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 0.9227
2022-02-25 00:30:52 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 0.9028
2022-02-25 00:31:25 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 0.9578
2022-02-25 00:31:59 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 0.7983
2022-02-25 00:32:33 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 0.8909
2022-02-25 00:33:07 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 0.8270
2022-02-25 00:33:40 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 0.9167
2022-02-25 00:34:14 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 1.0032
2022-02-25 00:34:48 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 0.8236
2022-02-25 00:35:22 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 0.8793
2022-02-25 00:35:56 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 1.1705
2022-02-25 00:36:31 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 1.0325
2022-02-25 00:37:04 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 0.8923
2022-02-25 00:37:39 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 0.9366
2022-02-25 00:38:13 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 0.9657
2022-02-25 00:38:47 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 0.8558
2022-02-25 00:39:22 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 0.8634
2022-02-25 00:39:56 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 1.0454
2022-02-25 00:40:31 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 0.9380
2022-02-25 00:41:05 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 1.0885
2022-02-25 00:41:41 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 0.9199
2022-02-25 00:42:17 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 0.7733
2022-02-25 00:42:54 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 0.9540
2022-02-25 00:43:35 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 1.1643
2022-02-25 00:44:17 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 1.0152
2022-02-25 00:44:57 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 1.0006
2022-02-25 00:45:38 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 1.0826
2022-02-25 00:46:25 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 1.0348
2022-02-25 00:46:28 - train: epoch 083, train_loss: 0.9197
2022-02-25 00:47:57 - eval: epoch: 083, acc1: 76.956%, acc5: 93.490%, test_loss: 0.9017, per_image_load_time: 1.071ms, per_image_inference_time: 0.551ms
2022-02-25 00:47:58 - until epoch: 083, best_acc1: 76.956%
2022-02-25 00:47:58 - epoch 084 lr: 0.0010000000000000002
2022-02-25 00:48:38 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 0.8910
2022-02-25 00:49:11 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 0.9587
2022-02-25 00:49:44 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 0.7318
2022-02-25 00:50:17 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 0.9684
2022-02-25 00:50:50 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 0.9678
2022-02-25 00:51:24 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 1.0910
2022-02-25 00:51:57 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 0.9281
2022-02-25 00:52:31 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 1.0420
2022-02-25 00:53:04 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 0.9433
2022-02-25 00:53:38 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 0.9833
2022-02-25 00:54:12 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 0.8572
2022-02-25 00:54:45 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 1.1294
2022-02-25 00:55:19 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 0.8752
2022-02-25 00:55:52 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 0.9254
2022-02-25 00:56:26 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 0.9634
2022-02-25 00:57:00 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 0.8458
2022-02-25 00:57:33 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 0.9778
2022-02-25 00:58:07 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 0.8955
2022-02-25 00:58:40 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 0.9299
2022-02-25 00:59:14 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 0.9942
2022-02-25 00:59:48 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 0.8215
2022-02-25 01:00:21 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 0.7433
2022-02-25 01:00:55 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 0.9050
2022-02-25 01:01:28 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 0.7854
2022-02-25 01:02:02 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 0.9533
2022-02-25 01:02:36 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 1.0573
2022-02-25 01:03:10 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 0.9103
2022-02-25 01:03:43 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 1.0282
2022-02-25 01:04:17 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 0.9154
2022-02-25 01:04:51 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 0.8918
2022-02-25 01:05:26 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 0.8155
2022-02-25 01:06:02 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 0.8154
2022-02-25 01:06:39 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 0.9556
2022-02-25 01:07:17 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 0.8078
2022-02-25 01:07:51 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 0.7208
2022-02-25 01:08:25 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 0.8673
2022-02-25 01:09:00 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 1.0156
2022-02-25 01:09:34 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 1.1506
2022-02-25 01:10:09 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 0.9675
2022-02-25 01:10:43 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 0.9605
2022-02-25 01:11:18 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 0.9413
2022-02-25 01:11:54 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 0.9833
2022-02-25 01:12:29 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 0.8785
2022-02-25 01:13:06 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 1.0568
2022-02-25 01:13:43 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 0.8893
2022-02-25 01:14:21 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 0.7760
2022-02-25 01:15:04 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 1.2074
2022-02-25 01:15:48 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 0.8094
2022-02-25 01:16:26 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 0.7109
2022-02-25 01:17:12 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 0.9701
2022-02-25 01:17:15 - train: epoch 084, train_loss: 0.9162
2022-02-25 01:18:38 - eval: epoch: 084, acc1: 76.694%, acc5: 93.430%, test_loss: 0.9051, per_image_load_time: 1.271ms, per_image_inference_time: 0.557ms
2022-02-25 01:18:39 - until epoch: 084, best_acc1: 76.956%
2022-02-25 01:18:39 - epoch 085 lr: 0.0010000000000000002
2022-02-25 01:19:19 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 0.7716
2022-02-25 01:19:52 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 0.7556
2022-02-25 01:20:26 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 1.0544
2022-02-25 01:20:59 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 0.7701
2022-02-25 01:21:33 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 1.0558
2022-02-25 01:22:06 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 0.7313
2022-02-25 01:22:39 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 0.7971
2022-02-25 01:23:13 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 0.8956
2022-02-25 01:23:46 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 0.8697
2022-02-25 01:24:20 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 0.9435
2022-02-25 01:24:53 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 0.9623
2022-02-25 01:25:26 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 0.8377
2022-02-25 01:26:00 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 0.9504
2022-02-25 01:26:33 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 0.9832
2022-02-25 01:27:07 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 0.7438
2022-02-25 01:27:41 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 0.9260
2022-02-25 01:28:14 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 1.1002
2022-02-25 01:28:48 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 0.7847
2022-02-25 01:29:21 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 0.8127
2022-02-25 01:29:55 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 0.8488
2022-02-25 01:30:28 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 0.6999
2022-02-25 01:31:02 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 0.9292
2022-02-25 01:31:36 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 0.7799
2022-02-25 01:32:10 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 0.9811
2022-02-25 01:32:44 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 1.1301
2022-02-25 01:33:18 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 0.9741
2022-02-25 01:33:52 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 0.8626
2022-02-25 01:34:26 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 0.9146
2022-02-25 01:35:00 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 1.0700
2022-02-25 01:35:34 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 1.0468
2022-02-25 01:36:08 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 0.8785
2022-02-25 01:36:42 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 0.8815
2022-02-25 01:37:17 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 0.8996
2022-02-25 01:37:51 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 0.9786
2022-02-25 01:38:25 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 0.9233
2022-02-25 01:39:00 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 0.9106
2022-02-25 01:39:34 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 0.8729
2022-02-25 01:40:09 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 0.8060
2022-02-25 01:40:44 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 0.8684
2022-02-25 01:41:18 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 1.1463
2022-02-25 01:41:54 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 0.9260
2022-02-25 01:42:28 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 1.0394
2022-02-25 01:43:04 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 0.8746
2022-02-25 01:43:40 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 0.8172
2022-02-25 01:44:17 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 1.0245
2022-02-25 01:44:57 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 0.9297
2022-02-25 01:45:39 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 1.1361
2022-02-25 01:46:16 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 0.8232
2022-02-25 01:47:02 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 0.8865
2022-02-25 01:47:51 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 0.8489
2022-02-25 01:47:54 - train: epoch 085, train_loss: 0.9166
2022-02-25 01:49:35 - eval: epoch: 085, acc1: 76.702%, acc5: 93.454%, test_loss: 0.9078, per_image_load_time: 0.499ms, per_image_inference_time: 0.534ms
2022-02-25 01:49:36 - until epoch: 085, best_acc1: 76.956%
2022-02-25 01:49:36 - epoch 086 lr: 0.0010000000000000002
2022-02-25 01:50:16 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 0.8404
2022-02-25 01:50:49 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 0.7659
2022-02-25 01:51:23 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 0.9691
2022-02-25 01:51:56 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 0.9770
2022-02-25 01:52:29 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 0.9197
2022-02-25 01:53:03 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 0.9012
2022-02-25 01:53:36 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 0.8231
2022-02-25 01:54:10 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 1.0469
2022-02-25 01:54:43 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 1.1125
2022-02-25 01:55:17 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 0.9393
2022-02-25 01:55:51 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 0.9522
2022-02-25 01:56:24 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 0.8450
2022-02-25 01:56:57 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 0.9121
2022-02-25 01:57:31 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 0.7708
2022-02-25 01:58:04 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 0.7968
2022-02-25 01:58:38 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 1.0122
2022-02-25 01:59:12 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 0.8872
2022-02-25 01:59:45 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 0.9193
2022-02-25 02:00:18 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 1.0440
2022-02-25 02:00:53 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 0.8692
2022-02-25 02:01:26 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 0.8296
2022-02-25 02:01:59 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 0.9616
2022-02-25 02:02:32 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 0.8244
2022-02-25 02:03:06 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 0.8026
2022-02-25 02:03:40 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 0.8607
2022-02-25 02:04:14 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 0.9683
2022-02-25 02:04:47 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 0.7745
2022-02-25 02:05:21 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 1.0762
2022-02-25 02:05:55 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 0.7861
2022-02-25 02:06:29 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 0.9692
2022-02-25 02:07:03 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 0.9269
2022-02-25 02:07:37 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 1.0321
2022-02-25 02:08:12 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 0.9837
2022-02-25 02:08:47 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 0.9946
2022-02-25 02:09:20 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 0.8597
2022-02-25 02:09:55 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 0.9304
2022-02-25 02:10:29 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 1.0476
2022-02-25 02:11:04 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 0.9611
2022-02-25 02:11:39 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 0.9227
2022-02-25 02:12:13 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 1.0213
2022-02-25 02:12:48 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 0.9300
2022-02-25 02:13:24 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 0.9098
2022-02-25 02:13:59 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 0.9230
2022-02-25 02:14:37 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 0.9236
2022-02-25 02:15:13 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 0.8148
2022-02-25 02:15:51 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 0.9286
2022-02-25 02:16:34 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 0.8879
2022-02-25 02:17:18 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 0.9679
2022-02-25 02:17:57 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 0.9685
2022-02-25 02:18:46 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 0.9124
2022-02-25 02:18:48 - train: epoch 086, train_loss: 0.9119
2022-02-25 02:20:17 - eval: epoch: 086, acc1: 76.928%, acc5: 93.446%, test_loss: 0.9056, per_image_load_time: 0.738ms, per_image_inference_time: 0.554ms
2022-02-25 02:20:18 - until epoch: 086, best_acc1: 76.956%
2022-02-25 02:20:18 - epoch 087 lr: 0.0010000000000000002
2022-02-25 02:20:57 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 0.9786
2022-02-25 02:21:30 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 0.7889
2022-02-25 02:22:04 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 0.9578
2022-02-25 02:22:37 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 1.0212
2022-02-25 02:23:10 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 0.6926
2022-02-25 02:23:44 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 0.8634
2022-02-25 02:24:17 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 0.7056
2022-02-25 02:24:50 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 0.9191
2022-02-25 02:25:23 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 0.9941
2022-02-25 02:25:57 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 0.7436
2022-02-25 02:26:31 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 1.0190
2022-02-25 02:27:04 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 0.9018
2022-02-25 02:27:37 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 0.9651
2022-02-25 02:28:11 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 0.8827
2022-02-25 02:28:44 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 0.8508
2022-02-25 02:29:17 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 0.7903
2022-02-25 02:29:50 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 1.0925
2022-02-25 02:30:23 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 0.9913
2022-02-25 02:30:57 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 0.9007
2022-02-25 02:31:30 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 0.8777
2022-02-25 02:32:03 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 0.9956
2022-02-25 02:32:36 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 0.8114
2022-02-25 02:33:10 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 0.9962
2022-02-25 02:33:43 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 0.8819
2022-02-25 02:34:17 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 0.9426
2022-02-25 02:34:50 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 0.9133
2022-02-25 02:35:24 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 0.7786
2022-02-25 02:35:57 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 0.7652
2022-02-25 02:36:31 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 0.8106
2022-02-25 02:37:05 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 0.9507
2022-02-25 02:37:38 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 0.8676
2022-02-25 02:38:12 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 0.8263
2022-02-25 02:38:46 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 1.0103
2022-02-25 02:39:19 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 0.9952
2022-02-25 02:39:54 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 0.7898
2022-02-25 02:40:27 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 0.7805
2022-02-25 02:41:02 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 0.8950
2022-02-25 02:41:36 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 0.8484
2022-02-25 02:42:10 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 0.8637
2022-02-25 02:42:45 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 0.9269
2022-02-25 02:43:19 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 0.9706
2022-02-25 02:43:54 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 0.9844
2022-02-25 02:44:29 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 0.9558
2022-02-25 02:45:03 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 0.9279
2022-02-25 02:45:42 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 1.0721
2022-02-25 02:46:18 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 0.8657
2022-02-25 02:46:57 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 0.9894
2022-02-25 02:47:41 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 0.8513
2022-02-25 02:48:28 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 0.8361
2022-02-25 02:49:08 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 0.8935
2022-02-25 02:49:10 - train: epoch 087, train_loss: 0.9082
2022-02-25 02:50:29 - eval: epoch: 087, acc1: 76.818%, acc5: 93.532%, test_loss: 0.9040, per_image_load_time: 2.360ms, per_image_inference_time: 0.592ms
2022-02-25 02:50:29 - until epoch: 087, best_acc1: 76.956%
2022-02-25 02:50:29 - epoch 088 lr: 0.0010000000000000002
2022-02-25 02:51:10 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 0.8993
2022-02-25 02:51:42 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 0.8211
2022-02-25 02:52:15 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 0.9962
2022-02-25 02:52:49 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 0.8548
2022-02-25 02:53:22 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 0.7580
2022-02-25 02:53:56 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 0.8582
2022-02-25 02:54:29 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 0.8205
2022-02-25 02:55:02 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 0.8911
2022-02-25 02:55:35 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 0.9769
2022-02-25 02:56:09 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 0.8445
2022-02-25 02:56:42 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 0.8967
2022-02-25 02:57:16 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 0.8935
2022-02-25 02:57:49 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 1.0128
2022-02-25 02:58:23 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 0.8630
2022-02-25 02:58:56 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 0.9340
2022-02-25 02:59:30 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 0.8207
2022-02-25 03:00:03 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 0.9130
2022-02-25 03:00:37 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 0.7942
2022-02-25 03:01:10 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 0.8978
2022-02-25 03:01:44 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 0.7751
2022-02-25 03:02:18 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 0.8796
2022-02-25 03:02:51 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 0.7989
2022-02-25 03:03:25 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 0.7294
2022-02-25 03:03:59 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 0.9071
2022-02-25 03:04:32 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 0.8941
2022-02-25 03:05:06 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 0.9869
2022-02-25 03:05:40 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 0.9170
2022-02-25 03:06:14 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 0.8648
2022-02-25 03:06:47 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 0.8624
2022-02-25 03:07:21 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 1.0553
2022-02-25 03:07:55 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 0.8149
2022-02-25 03:08:29 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 0.8419
2022-02-25 03:09:03 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 0.7986
2022-02-25 03:09:37 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 0.7641
2022-02-25 03:10:11 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 0.8726
2022-02-25 03:10:45 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 0.9306
2022-02-25 03:11:19 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 1.0473
2022-02-25 03:11:53 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 0.9056
2022-02-25 03:12:28 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 0.9861
2022-02-25 03:13:03 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 0.8085
2022-02-25 03:13:37 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 0.8347
2022-02-25 03:14:13 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 1.0199
2022-02-25 03:14:47 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 0.8289
2022-02-25 03:15:24 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 0.8334
2022-02-25 03:15:58 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 0.9548
2022-02-25 03:16:36 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 1.0182
2022-02-25 03:17:17 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 0.9075
2022-02-25 03:17:52 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 0.7229
2022-02-25 03:18:35 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 0.7704
2022-02-25 03:19:20 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 0.9014
2022-02-25 03:19:23 - train: epoch 088, train_loss: 0.9062
2022-02-25 03:20:50 - eval: epoch: 088, acc1: 76.874%, acc5: 93.414%, test_loss: 0.9050, per_image_load_time: 0.679ms, per_image_inference_time: 0.566ms
2022-02-25 03:20:51 - until epoch: 088, best_acc1: 76.956%
2022-02-25 03:20:51 - epoch 089 lr: 0.0010000000000000002
2022-02-25 03:21:31 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 1.0323
2022-02-25 03:22:05 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 0.6855
2022-02-25 03:22:38 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 0.9795
2022-02-25 03:23:11 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 0.7962
2022-02-25 03:23:45 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 0.9795
2022-02-25 03:24:18 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 0.8664
2022-02-25 03:24:52 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 1.0120
2022-02-25 03:25:26 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 1.0506
2022-02-25 03:25:59 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 0.9761
2022-02-25 03:26:33 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 0.9387
2022-02-25 03:27:06 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 0.9100
2022-02-25 03:27:40 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 0.8809
2022-02-25 03:28:14 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 0.9376
2022-02-25 03:28:47 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 0.9468
2022-02-25 03:29:21 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 0.9229
2022-02-25 03:29:55 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 0.9225
2022-02-25 03:30:29 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 0.9737
2022-02-25 03:31:02 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 0.8786
2022-02-25 03:31:36 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 0.7841
2022-02-25 03:32:09 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 0.9296
2022-02-25 03:32:44 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 1.0142
2022-02-25 03:33:17 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 0.9162
2022-02-25 03:33:51 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 0.8194
2022-02-25 03:34:25 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 0.9641
2022-02-25 03:34:59 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 0.8254
2022-02-25 03:35:33 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 0.9260
2022-02-25 03:36:07 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 0.8138
2022-02-25 03:36:41 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 0.9816
2022-02-25 03:37:15 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 0.9431
2022-02-25 03:37:49 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 0.9427
2022-02-25 03:38:23 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 1.0054
2022-02-25 03:38:57 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 1.0382
2022-02-25 03:39:31 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 1.0582
2022-02-25 03:40:06 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 0.9768
2022-02-25 03:40:39 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 0.7664
2022-02-25 03:41:14 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 0.8688
2022-02-25 03:41:48 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 1.0725
2022-02-25 03:42:23 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 0.7917
2022-02-25 03:42:59 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 0.9615
2022-02-25 03:43:33 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 0.7349
2022-02-25 03:44:07 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 1.0526
2022-02-25 03:44:43 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 0.8688
2022-02-25 03:45:18 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 0.9143
2022-02-25 03:45:56 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 0.9125
2022-02-25 03:46:32 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 0.7955
2022-02-25 03:47:10 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 0.9220
2022-02-25 03:47:53 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 0.9957
2022-02-25 03:48:39 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 0.9377
2022-02-25 03:49:24 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 0.9073
2022-02-25 03:50:04 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 0.7152
2022-02-25 03:50:07 - train: epoch 089, train_loss: 0.9060
2022-02-25 03:51:34 - eval: epoch: 089, acc1: 76.758%, acc5: 93.338%, test_loss: 0.9059, per_image_load_time: 0.805ms, per_image_inference_time: 0.572ms
2022-02-25 03:51:34 - until epoch: 089, best_acc1: 76.956%
2022-02-25 03:51:34 - epoch 090 lr: 0.0010000000000000002
2022-02-25 03:52:15 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 0.9761
2022-02-25 03:52:47 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 0.9273
2022-02-25 03:53:21 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 0.8587
2022-02-25 03:53:54 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 0.8565
2022-02-25 03:54:27 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 0.9581
2022-02-25 03:55:01 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 1.0146
2022-02-25 03:55:34 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 0.8517
2022-02-25 03:56:07 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 0.8137
2022-02-25 03:56:41 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 0.8314
2022-02-25 03:57:14 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 0.7396
2022-02-25 03:57:48 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 0.9942
2022-02-25 03:58:21 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 0.9050
2022-02-25 03:58:55 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 1.0387
2022-02-25 03:59:28 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 0.8226
2022-02-25 04:00:01 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 1.1231
2022-02-25 04:00:35 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 0.8774
2022-02-25 04:01:09 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 0.7885
2022-02-25 04:01:42 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 0.8316
2022-02-25 04:02:16 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 0.7908
2022-02-25 04:02:49 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 1.0030
2022-02-25 04:03:23 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 1.0316
2022-02-25 04:03:57 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 0.8987
2022-02-25 04:04:30 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 1.0376
2022-02-25 04:05:04 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 0.9729
2022-02-25 04:05:37 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 0.9854
2022-02-25 04:06:11 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 0.8743
2022-02-25 04:06:45 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 0.8586
2022-02-25 04:07:18 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 0.8583
2022-02-25 04:07:52 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 0.8327
2022-02-25 04:08:25 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 0.9669
2022-02-25 04:09:00 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 0.8691
2022-02-25 04:09:34 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 0.8342
2022-02-25 04:10:07 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 1.0271
2022-02-25 04:10:42 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 0.7347
2022-02-25 04:11:16 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 0.9402
2022-02-25 04:11:50 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 0.9085
2022-02-25 04:12:25 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 0.8834
2022-02-25 04:12:59 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 0.9315
2022-02-25 04:13:34 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 0.7323
2022-02-25 04:14:08 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 0.9273
2022-02-25 04:14:44 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 1.0776
2022-02-25 04:15:18 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 0.9258
2022-02-25 04:15:54 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 0.9486
2022-02-25 04:16:31 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 0.8821
2022-02-25 04:17:09 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 0.8876
2022-02-25 04:17:46 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 0.8760
2022-02-25 04:18:28 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 0.8627
2022-02-25 04:19:12 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 0.9121
2022-02-25 04:19:50 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 0.7973
2022-02-25 04:20:34 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 0.8926
2022-02-25 04:20:37 - train: epoch 090, train_loss: 0.9043
2022-02-25 04:22:19 - eval: epoch: 090, acc1: 76.776%, acc5: 93.420%, test_loss: 0.9071, per_image_load_time: 1.467ms, per_image_inference_time: 0.539ms
2022-02-25 04:22:20 - until epoch: 090, best_acc1: 76.956%
2022-02-25 04:22:20 - epoch 091 lr: 0.00010000000000000003
2022-02-25 04:23:00 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 0.8087
2022-02-25 04:23:34 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 0.8852
2022-02-25 04:24:07 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 0.7847
2022-02-25 04:24:41 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 0.8173
2022-02-25 04:25:14 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 0.8325
2022-02-25 04:25:48 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 0.8501
2022-02-25 04:26:21 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 0.8529
2022-02-25 04:26:55 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 0.7654
2022-02-25 04:27:28 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 0.9152
2022-02-25 04:28:02 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 0.7645
2022-02-25 04:28:36 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 0.7166
2022-02-25 04:29:09 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 0.9604
2022-02-25 04:29:42 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 0.7883
2022-02-25 04:30:16 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 0.8952
2022-02-25 04:30:50 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 0.8635
2022-02-25 04:31:23 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 0.8603
2022-02-25 04:31:57 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 0.8895
2022-02-25 04:32:30 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 0.8141
2022-02-25 04:33:04 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 0.7987
2022-02-25 04:33:38 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 0.8483
2022-02-25 04:34:12 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 0.6814
2022-02-25 04:34:46 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 0.9278
2022-02-25 04:35:19 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 0.9431
2022-02-25 04:35:53 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 0.8235
2022-02-25 04:36:27 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 0.8362
2022-02-25 04:37:01 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 0.8161
2022-02-25 04:37:35 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 0.6733
2022-02-25 04:38:09 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 0.8771
2022-02-25 04:38:43 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 0.9536
2022-02-25 04:39:17 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 0.9684
2022-02-25 04:39:50 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 0.7633
2022-02-25 04:40:25 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 0.9480
2022-02-25 04:40:59 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 0.7907
2022-02-25 04:41:33 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 0.7514
2022-02-25 04:42:07 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 0.8549
2022-02-25 04:42:41 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 0.8116
2022-02-25 04:43:16 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 0.9114
2022-02-25 04:43:50 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 0.8860
2022-02-25 04:44:25 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 0.8941
2022-02-25 04:45:01 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 0.9047
2022-02-25 04:45:35 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 0.8905
2022-02-25 04:46:10 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 0.9368
2022-02-25 04:46:45 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 0.9107
2022-02-25 04:47:22 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 0.7777
2022-02-25 04:48:00 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 0.8093
2022-02-25 04:48:36 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 0.8577
2022-02-25 04:49:16 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 0.8579
2022-02-25 04:49:59 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 0.8947
2022-02-25 04:50:44 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 0.8474
2022-02-25 04:51:29 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 0.9922
2022-02-25 04:51:32 - train: epoch 091, train_loss: 0.8660
2022-02-25 04:53:02 - eval: epoch: 091, acc1: 77.114%, acc5: 93.668%, test_loss: 0.8847, per_image_load_time: 0.655ms, per_image_inference_time: 0.553ms
2022-02-25 04:53:04 - until epoch: 091, best_acc1: 77.114%
2022-02-25 04:53:04 - epoch 092 lr: 0.00010000000000000003
2022-02-25 04:53:44 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 0.8536
2022-02-25 04:54:17 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 0.9032
2022-02-25 04:54:50 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 0.8111
2022-02-25 04:55:23 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 0.7259
2022-02-25 04:55:56 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 0.9895
2022-02-25 04:56:30 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 0.9169
2022-02-25 04:57:03 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 0.8695
2022-02-25 04:57:36 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 0.9135
2022-02-25 04:58:09 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 0.8483
2022-02-25 04:58:42 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 1.0044
2022-02-25 04:59:16 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 0.7500
2022-02-25 04:59:49 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 0.7721
2022-02-25 05:00:22 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 0.8586
2022-02-25 05:00:56 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 0.9037
2022-02-25 05:01:29 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 0.7709
2022-02-25 05:02:02 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 0.8457
2022-02-25 05:02:36 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 0.8860
2022-02-25 05:03:09 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 0.8016
2022-02-25 05:03:43 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 0.8129
2022-02-25 05:04:16 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 0.7553
2022-02-25 05:04:50 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 0.8245
2022-02-25 05:05:23 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 0.9028
2022-02-25 05:05:57 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 0.8555
2022-02-25 05:06:31 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 0.8270
2022-02-25 05:07:04 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 0.8108
2022-02-25 05:07:38 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 1.0017
2022-02-25 05:08:12 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 0.8087
2022-02-25 05:08:45 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 0.7058
2022-02-25 05:09:20 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 0.8500
2022-02-25 05:09:54 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 0.7753
2022-02-25 05:10:27 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 0.8202
2022-02-25 05:11:02 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 0.7541
2022-02-25 05:11:36 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 0.8623
2022-02-25 05:12:09 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 0.9785
2022-02-25 05:12:44 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 0.7480
2022-02-25 05:13:18 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 0.7505
2022-02-25 05:13:52 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 0.7476
2022-02-25 05:14:26 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 1.0162
2022-02-25 05:15:01 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 0.8480
2022-02-25 05:15:37 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 0.9176
2022-02-25 05:16:10 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 0.7211
2022-02-25 05:16:46 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 0.8119
2022-02-25 05:17:21 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 0.8567
2022-02-25 05:17:56 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 0.6851
2022-02-25 05:18:35 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 0.7815
2022-02-25 05:19:12 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 0.7302
2022-02-25 05:19:52 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 0.5882
2022-02-25 05:20:36 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 0.6921
2022-02-25 05:21:23 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 0.8695
2022-02-25 05:22:11 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 0.9291
2022-02-25 05:22:14 - train: epoch 092, train_loss: 0.8534
2022-02-25 05:23:40 - eval: epoch: 092, acc1: 77.214%, acc5: 93.758%, test_loss: 0.8838, per_image_load_time: 0.657ms, per_image_inference_time: 0.572ms
2022-02-25 05:23:41 - until epoch: 092, best_acc1: 77.214%
2022-02-25 05:23:41 - epoch 093 lr: 0.00010000000000000003
2022-02-25 05:24:22 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 0.7389
2022-02-25 05:24:55 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 0.7738
2022-02-25 05:25:28 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 0.7843
2022-02-25 05:26:01 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 0.8201
2022-02-25 05:26:35 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 0.8673
2022-02-25 05:27:08 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 0.7917
2022-02-25 05:27:41 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 0.8771
2022-02-25 05:28:15 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 0.7044
2022-02-25 05:28:48 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 0.7862
2022-02-25 05:29:21 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.7052
2022-02-25 05:29:54 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 0.7183
2022-02-25 05:30:28 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 0.6904
2022-02-25 05:31:01 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 0.8623
2022-02-25 05:31:35 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 0.8212
2022-02-25 05:32:08 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 0.9955
2022-02-25 05:32:41 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 0.9582
2022-02-25 05:33:15 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 0.7783
2022-02-25 05:33:48 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 0.8686
2022-02-25 05:34:22 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 0.8644
2022-02-25 05:34:55 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 0.7585
2022-02-25 05:35:29 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 0.8219
2022-02-25 05:36:03 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 1.0828
2022-02-25 05:36:36 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 0.9037
2022-02-25 05:37:10 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 0.7546
2022-02-25 05:37:44 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 0.9201
2022-02-25 05:38:18 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 0.9207
2022-02-25 05:38:52 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 0.7852
2022-02-25 05:39:26 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 0.8396
2022-02-25 05:39:59 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 0.8836
2022-02-25 05:40:34 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 0.8022
2022-02-25 05:41:08 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 0.9756
2022-02-25 05:41:42 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 0.7705
2022-02-25 05:42:16 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 0.9729
2022-02-25 05:42:49 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 1.0285
2022-02-25 05:43:24 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 0.6900
2022-02-25 05:43:58 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 0.9862
2022-02-25 05:44:32 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 0.7380
2022-02-25 05:45:07 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 0.6908
2022-02-25 05:45:41 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 0.9665
2022-02-25 05:46:17 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 1.0721
2022-02-25 05:46:51 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 0.8595
2022-02-25 05:47:26 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 0.9047
2022-02-25 05:48:03 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 1.0147
2022-02-25 05:48:37 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 0.7590
2022-02-25 05:49:16 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 0.8636
2022-02-25 05:49:55 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 0.7531
2022-02-25 05:50:33 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 1.0425
2022-02-25 05:51:17 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 0.8932
2022-02-25 05:52:04 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 0.9619
2022-02-25 05:52:51 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 0.7823
2022-02-25 05:52:54 - train: epoch 093, train_loss: 0.8497
2022-02-25 05:54:14 - eval: epoch: 093, acc1: 77.334%, acc5: 93.626%, test_loss: 0.8823, per_image_load_time: 0.767ms, per_image_inference_time: 0.621ms
2022-02-25 05:54:15 - until epoch: 093, best_acc1: 77.334%
2022-02-25 05:54:15 - epoch 094 lr: 0.00010000000000000003
2022-02-25 05:54:55 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 0.8510
2022-02-25 05:55:29 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 0.8285
2022-02-25 05:56:02 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 0.9226
2022-02-25 05:56:35 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 0.9883
2022-02-25 05:57:09 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 0.7900
2022-02-25 05:57:42 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 0.7165
2022-02-25 05:58:16 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 0.9267
2022-02-25 05:58:49 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 0.7977
2022-02-25 05:59:23 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 0.8211
2022-02-25 05:59:56 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 0.8687
2022-02-25 06:00:30 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 0.8579
2022-02-25 06:01:03 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 0.9173
2022-02-25 06:01:37 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 0.8474
2022-02-25 06:02:10 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 0.8381
2022-02-25 06:02:43 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 0.9157
2022-02-25 06:03:17 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 1.2213
2022-02-25 06:03:50 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 0.8036
2022-02-25 06:04:24 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 0.8372
2022-02-25 06:04:57 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 0.8709
2022-02-25 06:05:31 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 0.6905
2022-02-25 06:06:05 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 0.9264
2022-02-25 06:06:38 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 0.7524
2022-02-25 06:07:12 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 0.7241
2022-02-25 06:07:45 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 0.8443
2022-02-25 06:08:19 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 0.7698
2022-02-25 06:08:53 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 0.7155
2022-02-25 06:09:27 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 0.7715
