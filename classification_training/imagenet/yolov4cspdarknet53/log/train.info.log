2022-02-25 06:10:00 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 0.8110
2022-02-25 06:10:34 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 0.9024
2022-02-25 06:11:09 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 0.7553
2022-02-25 06:11:42 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 0.9962
2022-02-25 06:12:16 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 0.8636
2022-02-25 06:12:50 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 0.8640
2022-02-25 06:13:24 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 0.9331
2022-02-25 06:13:58 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 1.0149
2022-02-25 06:14:32 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 0.8566
2022-02-25 06:15:07 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 0.9671
2022-02-25 06:15:41 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 0.8218
2022-02-25 06:16:15 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 0.7522
2022-02-25 06:16:50 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 0.9339
2022-02-25 06:17:25 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 1.0170
2022-02-25 06:17:59 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 0.6492
2022-02-25 06:18:35 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 0.9761
2022-02-25 06:19:10 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 0.9584
2022-02-25 06:19:48 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 0.9471
2022-02-25 06:20:29 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 0.9039
2022-02-25 06:21:04 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 0.8578
2022-02-25 06:21:49 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 0.8163
2022-02-25 06:22:36 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 0.8474
2022-02-25 06:23:26 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 0.7366
2022-02-25 06:23:29 - train: epoch 094, train_loss: 0.8481
2022-02-25 06:24:50 - eval: epoch: 094, acc1: 77.310%, acc5: 93.696%, test_loss: 0.8828, per_image_load_time: 0.619ms, per_image_inference_time: 0.593ms
2022-02-25 06:24:51 - until epoch: 094, best_acc1: 77.334%
2022-02-25 06:24:51 - epoch 095 lr: 0.00010000000000000003
2022-02-25 06:25:31 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 0.7038
2022-02-25 06:26:04 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 0.9361
2022-02-25 06:26:37 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 0.7500
2022-02-25 06:27:11 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 0.8539
2022-02-25 06:27:44 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 1.0325
2022-02-25 06:28:17 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 0.8135
2022-02-25 06:28:50 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 0.8834
2022-02-25 06:29:24 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 0.9546
2022-02-25 06:29:57 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 1.1028
2022-02-25 06:30:30 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 0.9221
2022-02-25 06:31:03 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 0.7613
2022-02-25 06:31:37 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 0.7503
2022-02-25 06:32:10 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 0.7878
2022-02-25 06:32:44 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 0.8119
2022-02-25 06:33:17 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 0.7883
2022-02-25 06:33:51 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.5453
2022-02-25 06:34:25 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 0.7893
2022-02-25 06:34:58 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 0.9441
2022-02-25 06:35:31 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 0.7496
2022-02-25 06:36:05 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 0.8556
2022-02-25 06:36:38 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 0.8344
2022-02-25 06:37:12 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 0.6582
2022-02-25 06:37:46 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 0.8282
2022-02-25 06:38:20 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 0.8819
2022-02-25 06:38:54 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 0.8450
2022-02-25 06:39:27 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 0.8430
2022-02-25 06:40:01 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 0.8526
2022-02-25 06:40:35 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 0.7758
2022-02-25 06:41:09 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 0.8368
2022-02-25 06:41:43 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 0.8933
2022-02-25 06:42:16 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 0.9424
2022-02-25 06:42:51 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 0.8418
2022-02-25 06:43:25 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 0.9637
2022-02-25 06:43:59 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 0.8123
2022-02-25 06:44:34 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 0.8006
2022-02-25 06:45:08 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 0.7554
2022-02-25 06:45:43 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 0.7727
2022-02-25 06:46:17 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 0.6573
2022-02-25 06:46:52 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 0.9134
2022-02-25 06:47:27 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 0.6947
2022-02-25 06:48:01 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 0.8712
2022-02-25 06:48:35 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 0.6789
2022-02-25 06:49:12 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 0.8570
2022-02-25 06:49:45 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 0.9050
2022-02-25 06:50:23 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 0.7237
2022-02-25 06:51:01 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 0.8620
2022-02-25 06:51:38 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 0.8131
2022-02-25 06:52:22 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 0.9102
2022-02-25 06:53:09 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 0.8275
2022-02-25 06:53:57 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 0.6887
2022-02-25 06:54:00 - train: epoch 095, train_loss: 0.8467
2022-02-25 06:55:21 - eval: epoch: 095, acc1: 77.378%, acc5: 93.676%, test_loss: 0.8829, per_image_load_time: 0.603ms, per_image_inference_time: 0.602ms
2022-02-25 06:55:23 - until epoch: 095, best_acc1: 77.378%
2022-02-25 06:55:23 - epoch 096 lr: 0.00010000000000000003
2022-02-25 06:56:03 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 0.8968
2022-02-25 06:56:37 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 0.9118
2022-02-25 06:57:09 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 0.8585
2022-02-25 06:57:43 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 0.7208
2022-02-25 06:58:17 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 0.7694
2022-02-25 06:58:50 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 0.9738
2022-02-25 06:59:23 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 0.6782
2022-02-25 06:59:57 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 0.7947
2022-02-25 07:00:30 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 0.7459
2022-02-25 07:01:03 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 0.8151
2022-02-25 07:01:37 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 0.8676
2022-02-25 07:02:10 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 0.8215
2022-02-25 07:02:43 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 0.9256
2022-02-25 07:03:17 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 0.7850
2022-02-25 07:03:50 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 0.7492
2022-02-25 07:04:24 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 0.6220
2022-02-25 07:04:57 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 0.8834
2022-02-25 07:05:30 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 0.8845
2022-02-25 07:06:04 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 0.9222
2022-02-25 07:06:38 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 0.7801
2022-02-25 07:07:11 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 0.9310
2022-02-25 07:07:45 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.6577
2022-02-25 07:08:19 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 0.7414
2022-02-25 07:08:52 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 0.7531
2022-02-25 07:09:26 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 0.7825
2022-02-25 07:09:59 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 0.7600
2022-02-25 07:10:33 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 0.8350
2022-02-25 07:11:07 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 0.9248
2022-02-25 07:11:41 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 0.7814
2022-02-25 07:12:16 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 0.8965
2022-02-25 07:12:49 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 0.8425
2022-02-25 07:13:23 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 0.8695
2022-02-25 07:13:57 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 1.0002
2022-02-25 07:14:31 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 0.6389
2022-02-25 07:15:06 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 0.7361
2022-02-25 07:15:40 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 0.7058
2022-02-25 07:16:15 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 0.8673
2022-02-25 07:16:49 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 0.8502
2022-02-25 07:17:24 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 0.8370
2022-02-25 07:17:59 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 0.7018
2022-02-25 07:18:34 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 0.7508
2022-02-25 07:19:08 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 0.8731
2022-02-25 07:19:44 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.5846
2022-02-25 07:20:19 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 0.8715
2022-02-25 07:20:57 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 0.7680
2022-02-25 07:21:37 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 0.8100
2022-02-25 07:22:13 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 0.8192
2022-02-25 07:22:56 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 0.9462
2022-02-25 07:23:41 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 1.0029
2022-02-25 07:24:31 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 0.8016
2022-02-25 07:24:33 - train: epoch 096, train_loss: 0.8426
2022-02-25 07:25:54 - eval: epoch: 096, acc1: 77.352%, acc5: 93.756%, test_loss: 0.8821, per_image_load_time: 1.275ms, per_image_inference_time: 0.613ms
2022-02-25 07:25:54 - until epoch: 096, best_acc1: 77.378%
2022-02-25 07:25:54 - epoch 097 lr: 0.00010000000000000003
2022-02-25 07:26:34 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 0.9896
2022-02-25 07:27:08 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 0.6967
2022-02-25 07:27:41 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 0.8370
2022-02-25 07:28:14 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 1.0599
2022-02-25 07:28:47 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 0.8784
2022-02-25 07:29:21 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 0.8966
2022-02-25 07:29:54 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 0.8756
2022-02-25 07:30:28 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.7241
2022-02-25 07:31:01 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 0.7065
2022-02-25 07:31:35 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 0.7892
2022-02-25 07:32:08 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 0.7792
2022-02-25 07:32:42 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 0.8309
2022-02-25 07:33:16 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 0.7323
2022-02-25 07:33:49 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 0.7900
2022-02-25 07:34:23 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 0.8448
2022-02-25 07:34:57 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 0.7530
2022-02-25 07:35:30 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 0.8213
2022-02-25 07:36:04 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 0.8534
2022-02-25 07:36:38 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 0.8997
2022-02-25 07:37:11 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 0.7527
2022-02-25 07:37:45 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 0.8602
2022-02-25 07:38:19 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 0.9645
2022-02-25 07:38:53 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 0.7688
2022-02-25 07:39:27 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 0.8372
2022-02-25 07:40:00 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 0.8571
2022-02-25 07:40:34 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 0.9185
2022-02-25 07:41:08 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 0.6983
2022-02-25 07:41:42 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 0.7243
2022-02-25 07:42:17 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 1.0115
2022-02-25 07:42:51 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 0.8227
2022-02-25 07:43:24 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 0.8358
2022-02-25 07:43:59 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 0.8830
2022-02-25 07:44:33 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 0.8743
2022-02-25 07:45:07 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 0.9532
2022-02-25 07:45:42 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 0.9817
2022-02-25 07:46:16 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 0.8384
2022-02-25 07:46:51 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 0.6723
2022-02-25 07:47:25 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 0.7087
2022-02-25 07:47:59 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 0.8956
2022-02-25 07:48:34 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 0.8129
2022-02-25 07:49:08 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 0.8466
2022-02-25 07:49:45 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 0.8257
2022-02-25 07:50:19 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 0.7232
2022-02-25 07:50:56 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 0.7885
2022-02-25 07:51:34 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 0.8315
2022-02-25 07:52:12 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 0.9371
2022-02-25 07:52:51 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 0.9452
2022-02-25 07:53:36 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 0.8875
2022-02-25 07:54:22 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 1.0268
2022-02-25 07:55:09 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 0.8605
2022-02-25 07:55:12 - train: epoch 097, train_loss: 0.8423
2022-02-25 07:56:33 - eval: epoch: 097, acc1: 77.430%, acc5: 93.730%, test_loss: 0.8817, per_image_load_time: 1.419ms, per_image_inference_time: 0.590ms
2022-02-25 07:56:34 - until epoch: 097, best_acc1: 77.430%
2022-02-25 07:56:34 - epoch 098 lr: 0.00010000000000000003
2022-02-25 07:57:15 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 0.8691
2022-02-25 07:57:48 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 0.8873
2022-02-25 07:58:22 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 1.0663
2022-02-25 07:58:55 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 0.7045
2022-02-25 07:59:29 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 0.8343
2022-02-25 08:00:02 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 0.8695
2022-02-25 08:00:36 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 0.8087
2022-02-25 08:01:09 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 0.9232
2022-02-25 08:01:42 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 0.8564
2022-02-25 08:02:16 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 0.7552
2022-02-25 08:02:49 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 0.7009
2022-02-25 08:03:23 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 0.7668
2022-02-25 08:03:56 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 0.9242
2022-02-25 08:04:30 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 0.7911
2022-02-25 08:05:04 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 0.7598
2022-02-25 08:05:37 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 0.8460
2022-02-25 08:06:11 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 0.8228
2022-02-25 08:06:44 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 0.7925
2022-02-25 08:07:17 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 0.6633
2022-02-25 08:07:51 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 0.9624
2022-02-25 08:08:24 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 0.7689
2022-02-25 08:08:58 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 0.8358
2022-02-25 08:09:31 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 0.8346
2022-02-25 08:10:05 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 0.7690
2022-02-25 08:10:39 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 0.9688
2022-02-25 08:11:13 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 0.8077
2022-02-25 08:11:46 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 0.8412
2022-02-25 08:12:20 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 0.7341
2022-02-25 08:12:54 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 0.7376
2022-02-25 08:13:28 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 0.7783
2022-02-25 08:14:02 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 0.7859
2022-02-25 08:14:37 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 0.7344
2022-02-25 08:15:11 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 0.6944
2022-02-25 08:15:45 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 0.8880
2022-02-25 08:16:19 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 0.8713
2022-02-25 08:16:53 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 1.0652
2022-02-25 08:17:28 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 0.8784
2022-02-25 08:18:02 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 0.8642
2022-02-25 08:18:38 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 0.8503
2022-02-25 08:19:13 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 0.9498
2022-02-25 08:19:47 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 0.9494
2022-02-25 08:20:24 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 0.8212
2022-02-25 08:20:59 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 0.6761
2022-02-25 08:21:38 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 0.9604
2022-02-25 08:22:18 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 0.8906
2022-02-25 08:22:54 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 0.9264
2022-02-25 08:23:36 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 0.8130
2022-02-25 08:24:22 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 0.6178
2022-02-25 08:25:08 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 0.8944
2022-02-25 08:25:53 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 0.9541
2022-02-25 08:26:00 - train: epoch 098, train_loss: 0.8401
2022-02-25 08:27:27 - eval: epoch: 098, acc1: 77.316%, acc5: 93.696%, test_loss: 0.8816, per_image_load_time: 1.811ms, per_image_inference_time: 0.566ms
2022-02-25 08:27:27 - until epoch: 098, best_acc1: 77.430%
2022-02-25 08:27:27 - epoch 099 lr: 0.00010000000000000003
2022-02-25 08:28:08 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 0.7344
2022-02-25 08:28:41 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 0.8025
2022-02-25 08:29:14 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 0.8146
2022-02-25 08:29:48 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 0.8638
2022-02-25 08:30:21 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 0.9151
2022-02-25 08:30:55 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 0.7900
2022-02-25 08:31:28 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 0.8310
2022-02-25 08:32:01 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 0.8305
2022-02-25 08:32:35 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 0.7919
2022-02-25 08:33:09 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 0.8494
2022-02-25 08:33:42 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 0.8219
2022-02-25 08:34:16 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 0.7678
2022-02-25 08:34:49 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 0.8821
2022-02-25 08:35:23 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 0.8875
2022-02-25 08:35:57 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 0.7558
2022-02-25 08:36:31 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 1.1487
2022-02-25 08:37:04 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 0.7515
2022-02-25 08:37:38 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 0.8148
2022-02-25 08:38:12 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 0.8365
2022-02-25 08:38:45 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 0.7389
2022-02-25 08:39:19 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 0.7801
2022-02-25 08:39:52 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 0.8793
2022-02-25 08:40:27 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 0.9189
2022-02-25 08:41:00 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 0.9149
2022-02-25 08:41:34 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 0.7097
2022-02-25 08:42:08 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 0.7252
2022-02-25 08:42:41 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 0.8262
2022-02-25 08:43:15 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 1.0048
2022-02-25 08:43:49 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 0.8190
2022-02-25 08:44:23 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 0.9284
2022-02-25 08:44:57 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 0.7618
2022-02-25 08:45:31 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 0.9104
2022-02-25 08:46:05 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 0.7844
2022-02-25 08:46:39 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 0.8447
2022-02-25 08:47:13 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 0.8966
2022-02-25 08:47:48 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 0.7252
2022-02-25 08:48:22 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 0.6970
2022-02-25 08:48:56 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 0.9666
2022-02-25 08:49:31 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 0.9074
2022-02-25 08:50:05 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 0.9704
2022-02-25 08:50:41 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 0.6774
2022-02-25 08:51:15 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 0.8749
2022-02-25 08:51:51 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 0.8196
2022-02-25 08:52:27 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 0.9103
2022-02-25 08:53:02 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 0.8841
2022-02-25 08:53:42 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 1.0184
2022-02-25 08:54:24 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 0.7523
2022-02-25 08:55:06 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 1.0379
2022-02-25 08:55:46 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 0.8154
2022-02-25 08:56:34 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 0.8642
2022-02-25 08:56:37 - train: epoch 099, train_loss: 0.8403
2022-02-25 08:58:20 - eval: epoch: 099, acc1: 77.448%, acc5: 93.700%, test_loss: 0.8817, per_image_load_time: 1.730ms, per_image_inference_time: 0.548ms
2022-02-25 08:58:21 - until epoch: 099, best_acc1: 77.448%
2022-02-25 22:42:50 - epoch 100 lr: 0.00010000000000000003
2022-02-25 22:43:29 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 0.9736
2022-02-25 22:44:01 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 0.7954
2022-02-25 22:44:34 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 1.0253
2022-02-25 22:45:06 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 0.6670
2022-02-25 22:45:38 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 0.9188
2022-02-25 22:46:10 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 0.7851
2022-02-25 22:46:43 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 0.7028
2022-02-25 22:47:15 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 0.9757
2022-02-25 22:47:47 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 0.7109
2022-02-25 22:48:20 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 0.8177
2022-02-25 22:48:52 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 0.8397
2022-02-25 22:49:24 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 0.8048
2022-02-25 22:49:57 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 0.8380
2022-02-25 22:50:29 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 0.9329
2022-02-25 22:51:01 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 0.8479
2022-02-25 22:51:34 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 0.8208
2022-02-25 22:52:06 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 0.6956
2022-02-25 22:52:38 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 0.7451
2022-02-25 22:53:11 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 0.8320
2022-02-25 22:53:43 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 0.9986
2022-02-25 22:54:16 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 0.8492
2022-02-25 22:54:48 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 0.9540
2022-02-25 22:55:21 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 0.8528
2022-02-25 22:55:53 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 0.8318
2022-02-25 22:56:26 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 0.7659
2022-02-25 22:56:58 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 0.8212
2022-02-25 22:57:31 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 0.8285
2022-02-25 22:58:03 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 0.7686
2022-02-25 22:58:36 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 0.7262
2022-02-25 22:59:08 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 0.7927
2022-02-25 22:59:41 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 0.7612
2022-02-25 23:00:14 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 0.8375
2022-02-25 23:00:47 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 0.7995
2022-02-25 23:01:20 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 0.8166
2022-02-25 23:01:52 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 0.6596
2022-02-25 23:02:25 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 0.8260
2022-02-25 23:02:58 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 0.9272
2022-02-25 23:03:31 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 0.8506
2022-02-25 23:04:04 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 0.9700
2022-02-25 23:04:37 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 0.8746
2022-02-25 23:05:09 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 0.8850
2022-02-25 23:05:42 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 0.8495
2022-02-25 23:06:15 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 0.9060
2022-02-25 23:06:48 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 0.8304
2022-02-25 23:07:21 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 0.8194
2022-02-25 23:07:53 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 0.8394
2022-02-25 23:08:26 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 0.8703
2022-02-25 23:08:59 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 0.7882
2022-02-25 23:09:31 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 0.8718
2022-02-25 23:10:04 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 0.8707
2022-02-25 23:10:05 - train: epoch 100, train_loss: 0.8377
2022-02-25 23:11:23 - eval: epoch: 100, acc1: 77.410%, acc5: 93.724%, test_loss: 0.8809, per_image_load_time: 1.057ms, per_image_inference_time: 0.561ms
2022-02-25 23:11:23 - until epoch: 100, best_acc1: 77.448%
2022-02-25 23:11:23 - train done. model: yolov4cspdarknet53, train time: 51.269 hours, best_acc1: 77.448%
