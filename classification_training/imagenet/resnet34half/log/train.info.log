2022-07-09 23:32:40 - train: epoch 0053, iter [04400, 05004], lr: 0.010000, loss: 1.9342
2022-07-09 23:33:13 - train: epoch 0053, iter [04500, 05004], lr: 0.010000, loss: 2.0467
2022-07-09 23:33:47 - train: epoch 0053, iter [04600, 05004], lr: 0.010000, loss: 1.8251
2022-07-09 23:34:20 - train: epoch 0053, iter [04700, 05004], lr: 0.010000, loss: 1.7858
2022-07-09 23:34:53 - train: epoch 0053, iter [04800, 05004], lr: 0.010000, loss: 2.1775
2022-07-09 23:35:26 - train: epoch 0053, iter [04900, 05004], lr: 0.010000, loss: 1.8585
2022-07-09 23:35:58 - train: epoch 0053, iter [05000, 05004], lr: 0.010000, loss: 1.8344
2022-07-09 23:35:59 - train: epoch 053, train_loss: 1.8504
2022-07-09 23:37:12 - eval: epoch: 053, acc1: 61.094%, acc5: 84.052%, test_loss: 1.6111, per_image_load_time: 2.681ms, per_image_inference_time: 0.165ms
2022-07-09 23:37:12 - until epoch: 053, best_acc1: 62.214%
2022-07-09 23:37:12 - epoch 054 lr: 0.010000
2022-07-09 23:37:50 - train: epoch 0054, iter [00100, 05004], lr: 0.010000, loss: 1.9148
2022-07-09 23:38:24 - train: epoch 0054, iter [00200, 05004], lr: 0.010000, loss: 2.0642
2022-07-09 23:38:56 - train: epoch 0054, iter [00300, 05004], lr: 0.010000, loss: 1.8849
2022-07-09 23:39:28 - train: epoch 0054, iter [00400, 05004], lr: 0.010000, loss: 1.8461
2022-07-09 23:40:01 - train: epoch 0054, iter [00500, 05004], lr: 0.010000, loss: 1.5615
2022-07-09 23:40:34 - train: epoch 0054, iter [00600, 05004], lr: 0.010000, loss: 1.9073
2022-07-09 23:41:08 - train: epoch 0054, iter [00700, 05004], lr: 0.010000, loss: 1.9400
2022-07-09 23:41:40 - train: epoch 0054, iter [00800, 05004], lr: 0.010000, loss: 1.9605
2022-07-09 23:42:13 - train: epoch 0054, iter [00900, 05004], lr: 0.010000, loss: 1.6916
2022-07-09 23:42:45 - train: epoch 0054, iter [01000, 05004], lr: 0.010000, loss: 1.6648
2022-07-09 23:43:20 - train: epoch 0054, iter [01100, 05004], lr: 0.010000, loss: 1.4924
2022-07-09 23:43:53 - train: epoch 0054, iter [01200, 05004], lr: 0.010000, loss: 1.9209
2022-07-09 23:44:25 - train: epoch 0054, iter [01300, 05004], lr: 0.010000, loss: 1.8704
2022-07-09 23:44:57 - train: epoch 0054, iter [01400, 05004], lr: 0.010000, loss: 2.0285
2022-07-09 23:45:31 - train: epoch 0054, iter [01500, 05004], lr: 0.010000, loss: 1.8323
2022-07-09 23:46:04 - train: epoch 0054, iter [01600, 05004], lr: 0.010000, loss: 1.8526
2022-07-09 23:46:36 - train: epoch 0054, iter [01700, 05004], lr: 0.010000, loss: 1.6459
2022-07-09 23:47:11 - train: epoch 0054, iter [01800, 05004], lr: 0.010000, loss: 1.7847
2022-07-09 23:47:44 - train: epoch 0054, iter [01900, 05004], lr: 0.010000, loss: 1.8688
2022-07-09 23:48:17 - train: epoch 0054, iter [02000, 05004], lr: 0.010000, loss: 1.8378
2022-07-09 23:48:50 - train: epoch 0054, iter [02100, 05004], lr: 0.010000, loss: 1.7090
2022-07-09 23:49:24 - train: epoch 0054, iter [02200, 05004], lr: 0.010000, loss: 1.8137
2022-07-09 23:49:57 - train: epoch 0054, iter [02300, 05004], lr: 0.010000, loss: 1.8337
2022-07-09 23:50:31 - train: epoch 0054, iter [02400, 05004], lr: 0.010000, loss: 1.8117
2022-07-09 23:51:05 - train: epoch 0054, iter [02500, 05004], lr: 0.010000, loss: 1.8908
2022-07-09 23:51:36 - train: epoch 0054, iter [02600, 05004], lr: 0.010000, loss: 1.7139
2022-07-09 23:52:11 - train: epoch 0054, iter [02700, 05004], lr: 0.010000, loss: 1.6584
2022-07-09 23:52:43 - train: epoch 0054, iter [02800, 05004], lr: 0.010000, loss: 2.0160
2022-07-09 23:53:18 - train: epoch 0054, iter [02900, 05004], lr: 0.010000, loss: 1.6732
2022-07-09 23:53:50 - train: epoch 0054, iter [03000, 05004], lr: 0.010000, loss: 1.9840
2022-07-09 23:54:24 - train: epoch 0054, iter [03100, 05004], lr: 0.010000, loss: 1.9447
2022-07-09 23:54:56 - train: epoch 0054, iter [03200, 05004], lr: 0.010000, loss: 2.0137
2022-07-09 23:55:30 - train: epoch 0054, iter [03300, 05004], lr: 0.010000, loss: 1.9666
2022-07-09 23:56:03 - train: epoch 0054, iter [03400, 05004], lr: 0.010000, loss: 1.8248
2022-07-09 23:56:36 - train: epoch 0054, iter [03500, 05004], lr: 0.010000, loss: 1.8024
2022-07-09 23:57:09 - train: epoch 0054, iter [03600, 05004], lr: 0.010000, loss: 1.8114
2022-07-09 23:57:43 - train: epoch 0054, iter [03700, 05004], lr: 0.010000, loss: 1.7592
2022-07-09 23:58:15 - train: epoch 0054, iter [03800, 05004], lr: 0.010000, loss: 1.8570
2022-07-09 23:58:49 - train: epoch 0054, iter [03900, 05004], lr: 0.010000, loss: 1.8297
2022-07-09 23:59:22 - train: epoch 0054, iter [04000, 05004], lr: 0.010000, loss: 1.5863
2022-07-09 23:59:56 - train: epoch 0054, iter [04100, 05004], lr: 0.010000, loss: 1.7627
2022-07-10 00:00:29 - train: epoch 0054, iter [04200, 05004], lr: 0.010000, loss: 2.0662
2022-07-10 00:01:03 - train: epoch 0054, iter [04300, 05004], lr: 0.010000, loss: 1.9213
2022-07-10 00:01:36 - train: epoch 0054, iter [04400, 05004], lr: 0.010000, loss: 1.4344
2022-07-10 00:02:09 - train: epoch 0054, iter [04500, 05004], lr: 0.010000, loss: 1.6769
2022-07-10 00:02:43 - train: epoch 0054, iter [04600, 05004], lr: 0.010000, loss: 2.1388
2022-07-10 00:03:15 - train: epoch 0054, iter [04700, 05004], lr: 0.010000, loss: 2.1843
2022-07-10 00:03:49 - train: epoch 0054, iter [04800, 05004], lr: 0.010000, loss: 1.8737
2022-07-10 00:04:23 - train: epoch 0054, iter [04900, 05004], lr: 0.010000, loss: 1.7842
2022-07-10 00:04:55 - train: epoch 0054, iter [05000, 05004], lr: 0.010000, loss: 2.0505
2022-07-10 00:04:55 - train: epoch 054, train_loss: 1.8490
2022-07-10 00:06:08 - eval: epoch: 054, acc1: 61.278%, acc5: 84.016%, test_loss: 1.6118, per_image_load_time: 2.218ms, per_image_inference_time: 0.160ms
2022-07-10 00:06:08 - until epoch: 054, best_acc1: 62.214%
2022-07-10 00:06:08 - epoch 055 lr: 0.010000
2022-07-10 00:06:46 - train: epoch 0055, iter [00100, 05004], lr: 0.010000, loss: 1.7028
2022-07-10 00:07:19 - train: epoch 0055, iter [00200, 05004], lr: 0.010000, loss: 2.0421
2022-07-10 00:07:52 - train: epoch 0055, iter [00300, 05004], lr: 0.010000, loss: 1.7266
2022-07-10 00:08:25 - train: epoch 0055, iter [00400, 05004], lr: 0.010000, loss: 1.7511
2022-07-10 00:08:57 - train: epoch 0055, iter [00500, 05004], lr: 0.010000, loss: 1.6389
2022-07-10 00:09:29 - train: epoch 0055, iter [00600, 05004], lr: 0.010000, loss: 1.7865
2022-07-10 00:10:02 - train: epoch 0055, iter [00700, 05004], lr: 0.010000, loss: 1.6751
2022-07-10 00:10:35 - train: epoch 0055, iter [00800, 05004], lr: 0.010000, loss: 1.4863
2022-07-10 00:11:08 - train: epoch 0055, iter [00900, 05004], lr: 0.010000, loss: 1.9788
2022-07-10 00:11:41 - train: epoch 0055, iter [01000, 05004], lr: 0.010000, loss: 1.8031
2022-07-10 00:12:14 - train: epoch 0055, iter [01100, 05004], lr: 0.010000, loss: 1.8484
2022-07-10 00:12:48 - train: epoch 0055, iter [01200, 05004], lr: 0.010000, loss: 1.8282
2022-07-10 00:13:20 - train: epoch 0055, iter [01300, 05004], lr: 0.010000, loss: 1.8354
2022-07-10 00:13:54 - train: epoch 0055, iter [01400, 05004], lr: 0.010000, loss: 1.7879
2022-07-10 00:14:26 - train: epoch 0055, iter [01500, 05004], lr: 0.010000, loss: 1.7329
2022-07-10 00:15:00 - train: epoch 0055, iter [01600, 05004], lr: 0.010000, loss: 1.8211
2022-07-10 00:15:33 - train: epoch 0055, iter [01700, 05004], lr: 0.010000, loss: 1.9546
2022-07-10 00:16:05 - train: epoch 0055, iter [01800, 05004], lr: 0.010000, loss: 1.9734
2022-07-10 00:16:39 - train: epoch 0055, iter [01900, 05004], lr: 0.010000, loss: 1.8838
2022-07-10 00:17:12 - train: epoch 0055, iter [02000, 05004], lr: 0.010000, loss: 1.7028
2022-07-10 00:17:46 - train: epoch 0055, iter [02100, 05004], lr: 0.010000, loss: 1.6464
2022-07-10 00:18:19 - train: epoch 0055, iter [02200, 05004], lr: 0.010000, loss: 2.0124
2022-07-10 00:18:52 - train: epoch 0055, iter [02300, 05004], lr: 0.010000, loss: 1.6738
2022-07-10 00:19:25 - train: epoch 0055, iter [02400, 05004], lr: 0.010000, loss: 1.7577
2022-07-10 00:19:59 - train: epoch 0055, iter [02500, 05004], lr: 0.010000, loss: 1.7960
2022-07-10 00:20:32 - train: epoch 0055, iter [02600, 05004], lr: 0.010000, loss: 1.7216
2022-07-10 00:21:06 - train: epoch 0055, iter [02700, 05004], lr: 0.010000, loss: 1.8213
2022-07-10 00:21:39 - train: epoch 0055, iter [02800, 05004], lr: 0.010000, loss: 2.1231
2022-07-10 00:22:11 - train: epoch 0055, iter [02900, 05004], lr: 0.010000, loss: 1.9657
2022-07-10 00:22:45 - train: epoch 0055, iter [03000, 05004], lr: 0.010000, loss: 2.1225
2022-07-10 00:23:17 - train: epoch 0055, iter [03100, 05004], lr: 0.010000, loss: 2.0220
2022-07-10 00:23:50 - train: epoch 0055, iter [03200, 05004], lr: 0.010000, loss: 1.8067
2022-07-10 00:24:24 - train: epoch 0055, iter [03300, 05004], lr: 0.010000, loss: 1.7411
2022-07-10 00:24:56 - train: epoch 0055, iter [03400, 05004], lr: 0.010000, loss: 1.7079
2022-07-10 00:25:30 - train: epoch 0055, iter [03500, 05004], lr: 0.010000, loss: 1.7911
2022-07-10 00:26:04 - train: epoch 0055, iter [03600, 05004], lr: 0.010000, loss: 1.8611
2022-07-10 00:26:37 - train: epoch 0055, iter [03700, 05004], lr: 0.010000, loss: 1.6516
2022-07-10 00:27:10 - train: epoch 0055, iter [03800, 05004], lr: 0.010000, loss: 1.8910
2022-07-10 00:27:44 - train: epoch 0055, iter [03900, 05004], lr: 0.010000, loss: 2.2182
2022-07-10 00:28:17 - train: epoch 0055, iter [04000, 05004], lr: 0.010000, loss: 1.7978
2022-07-10 00:28:51 - train: epoch 0055, iter [04100, 05004], lr: 0.010000, loss: 1.8000
2022-07-10 00:29:24 - train: epoch 0055, iter [04200, 05004], lr: 0.010000, loss: 2.0454
2022-07-10 00:29:57 - train: epoch 0055, iter [04300, 05004], lr: 0.010000, loss: 2.0515
2022-07-10 00:30:30 - train: epoch 0055, iter [04400, 05004], lr: 0.010000, loss: 1.7886
2022-07-10 00:31:05 - train: epoch 0055, iter [04500, 05004], lr: 0.010000, loss: 1.8522
2022-07-10 00:31:37 - train: epoch 0055, iter [04600, 05004], lr: 0.010000, loss: 1.7679
2022-07-10 00:32:11 - train: epoch 0055, iter [04700, 05004], lr: 0.010000, loss: 1.8071
2022-07-10 00:32:44 - train: epoch 0055, iter [04800, 05004], lr: 0.010000, loss: 1.9169
2022-07-10 00:33:18 - train: epoch 0055, iter [04900, 05004], lr: 0.010000, loss: 1.7761
2022-07-10 00:33:48 - train: epoch 0055, iter [05000, 05004], lr: 0.010000, loss: 1.7603
2022-07-10 00:33:49 - train: epoch 055, train_loss: 1.8505
2022-07-10 00:35:02 - eval: epoch: 055, acc1: 61.438%, acc5: 84.226%, test_loss: 1.5959, per_image_load_time: 2.372ms, per_image_inference_time: 0.160ms
2022-07-10 00:35:02 - until epoch: 055, best_acc1: 62.214%
2022-07-10 00:35:02 - epoch 056 lr: 0.010000
2022-07-10 00:35:40 - train: epoch 0056, iter [00100, 05004], lr: 0.010000, loss: 1.8883
2022-07-10 00:36:12 - train: epoch 0056, iter [00200, 05004], lr: 0.010000, loss: 1.7513
2022-07-10 00:36:45 - train: epoch 0056, iter [00300, 05004], lr: 0.010000, loss: 1.7097
2022-07-10 00:37:18 - train: epoch 0056, iter [00400, 05004], lr: 0.010000, loss: 1.9836
2022-07-10 00:37:50 - train: epoch 0056, iter [00500, 05004], lr: 0.010000, loss: 2.0148
2022-07-10 00:38:23 - train: epoch 0056, iter [00600, 05004], lr: 0.010000, loss: 1.8882
2022-07-10 00:38:56 - train: epoch 0056, iter [00700, 05004], lr: 0.010000, loss: 1.8964
2022-07-10 00:39:28 - train: epoch 0056, iter [00800, 05004], lr: 0.010000, loss: 1.8412
2022-07-10 00:40:02 - train: epoch 0056, iter [00900, 05004], lr: 0.010000, loss: 1.9527
2022-07-10 00:40:34 - train: epoch 0056, iter [01000, 05004], lr: 0.010000, loss: 1.7489
2022-07-10 00:41:08 - train: epoch 0056, iter [01100, 05004], lr: 0.010000, loss: 1.5792
2022-07-10 00:41:40 - train: epoch 0056, iter [01200, 05004], lr: 0.010000, loss: 2.0646
2022-07-10 00:42:14 - train: epoch 0056, iter [01300, 05004], lr: 0.010000, loss: 1.9421
2022-07-10 00:42:46 - train: epoch 0056, iter [01400, 05004], lr: 0.010000, loss: 1.7100
2022-07-10 00:43:19 - train: epoch 0056, iter [01500, 05004], lr: 0.010000, loss: 2.3435
2022-07-10 00:43:53 - train: epoch 0056, iter [01600, 05004], lr: 0.010000, loss: 1.9362
2022-07-10 00:44:25 - train: epoch 0056, iter [01700, 05004], lr: 0.010000, loss: 1.7503
2022-07-10 00:44:58 - train: epoch 0056, iter [01800, 05004], lr: 0.010000, loss: 2.0225
2022-07-10 00:45:32 - train: epoch 0056, iter [01900, 05004], lr: 0.010000, loss: 1.9433
2022-07-10 00:46:05 - train: epoch 0056, iter [02000, 05004], lr: 0.010000, loss: 1.8778
2022-07-10 00:46:38 - train: epoch 0056, iter [02100, 05004], lr: 0.010000, loss: 1.8795
2022-07-10 00:47:12 - train: epoch 0056, iter [02200, 05004], lr: 0.010000, loss: 2.0553
2022-07-10 00:47:45 - train: epoch 0056, iter [02300, 05004], lr: 0.010000, loss: 1.9981
2022-07-10 00:48:17 - train: epoch 0056, iter [02400, 05004], lr: 0.010000, loss: 1.9985
2022-07-10 00:48:51 - train: epoch 0056, iter [02500, 05004], lr: 0.010000, loss: 2.1352
2022-07-10 00:49:24 - train: epoch 0056, iter [02600, 05004], lr: 0.010000, loss: 1.7238
2022-07-10 00:49:56 - train: epoch 0056, iter [02700, 05004], lr: 0.010000, loss: 1.9564
2022-07-10 00:50:29 - train: epoch 0056, iter [02800, 05004], lr: 0.010000, loss: 1.8802
2022-07-10 00:51:02 - train: epoch 0056, iter [02900, 05004], lr: 0.010000, loss: 1.8675
2022-07-10 00:51:35 - train: epoch 0056, iter [03000, 05004], lr: 0.010000, loss: 1.9814
2022-07-10 00:52:09 - train: epoch 0056, iter [03100, 05004], lr: 0.010000, loss: 1.7880
2022-07-10 00:52:41 - train: epoch 0056, iter [03200, 05004], lr: 0.010000, loss: 1.9414
2022-07-10 00:53:14 - train: epoch 0056, iter [03300, 05004], lr: 0.010000, loss: 1.9511
2022-07-10 00:53:47 - train: epoch 0056, iter [03400, 05004], lr: 0.010000, loss: 1.8985
2022-07-10 00:54:20 - train: epoch 0056, iter [03500, 05004], lr: 0.010000, loss: 1.8868
2022-07-10 00:54:53 - train: epoch 0056, iter [03600, 05004], lr: 0.010000, loss: 1.6731
2022-07-10 00:55:27 - train: epoch 0056, iter [03700, 05004], lr: 0.010000, loss: 1.8468
2022-07-10 00:55:59 - train: epoch 0056, iter [03800, 05004], lr: 0.010000, loss: 1.9943
2022-07-10 00:56:32 - train: epoch 0056, iter [03900, 05004], lr: 0.010000, loss: 2.0962
2022-07-10 00:57:06 - train: epoch 0056, iter [04000, 05004], lr: 0.010000, loss: 1.8469
2022-07-10 00:57:39 - train: epoch 0056, iter [04100, 05004], lr: 0.010000, loss: 1.8302
2022-07-10 00:58:12 - train: epoch 0056, iter [04200, 05004], lr: 0.010000, loss: 1.8676
2022-07-10 00:58:46 - train: epoch 0056, iter [04300, 05004], lr: 0.010000, loss: 1.7725
2022-07-10 00:59:19 - train: epoch 0056, iter [04400, 05004], lr: 0.010000, loss: 1.8690
2022-07-10 00:59:52 - train: epoch 0056, iter [04500, 05004], lr: 0.010000, loss: 1.7255
2022-07-10 01:00:24 - train: epoch 0056, iter [04600, 05004], lr: 0.010000, loss: 1.9304
2022-07-10 01:00:59 - train: epoch 0056, iter [04700, 05004], lr: 0.010000, loss: 1.8779
2022-07-10 01:01:31 - train: epoch 0056, iter [04800, 05004], lr: 0.010000, loss: 1.9478
2022-07-10 01:02:04 - train: epoch 0056, iter [04900, 05004], lr: 0.010000, loss: 1.9214
2022-07-10 01:02:36 - train: epoch 0056, iter [05000, 05004], lr: 0.010000, loss: 1.7172
2022-07-10 01:02:37 - train: epoch 056, train_loss: 1.8488
2022-07-10 01:03:50 - eval: epoch: 056, acc1: 60.526%, acc5: 83.498%, test_loss: 1.6540, per_image_load_time: 2.343ms, per_image_inference_time: 0.157ms
2022-07-10 01:03:50 - until epoch: 056, best_acc1: 62.214%
2022-07-10 01:03:50 - epoch 057 lr: 0.010000
2022-07-10 01:04:28 - train: epoch 0057, iter [00100, 05004], lr: 0.010000, loss: 1.9009
2022-07-10 01:05:02 - train: epoch 0057, iter [00200, 05004], lr: 0.010000, loss: 1.8902
2022-07-10 01:05:35 - train: epoch 0057, iter [00300, 05004], lr: 0.010000, loss: 1.7191
2022-07-10 01:06:07 - train: epoch 0057, iter [00400, 05004], lr: 0.010000, loss: 1.6956
2022-07-10 01:06:39 - train: epoch 0057, iter [00500, 05004], lr: 0.010000, loss: 1.7400
2022-07-10 01:07:14 - train: epoch 0057, iter [00600, 05004], lr: 0.010000, loss: 1.8541
2022-07-10 01:07:46 - train: epoch 0057, iter [00700, 05004], lr: 0.010000, loss: 1.7155
2022-07-10 01:08:20 - train: epoch 0057, iter [00800, 05004], lr: 0.010000, loss: 1.8682
2022-07-10 01:08:52 - train: epoch 0057, iter [00900, 05004], lr: 0.010000, loss: 1.9005
2022-07-10 01:09:26 - train: epoch 0057, iter [01000, 05004], lr: 0.010000, loss: 1.6458
2022-07-10 01:09:58 - train: epoch 0057, iter [01100, 05004], lr: 0.010000, loss: 1.8269
2022-07-10 01:10:31 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 1.7843
2022-07-10 01:11:04 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 1.8326
2022-07-10 01:11:37 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 1.8193
2022-07-10 01:12:10 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 1.9314
2022-07-10 01:12:44 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 1.8577
2022-07-10 01:13:16 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 1.8834
2022-07-10 01:13:50 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 2.0510
2022-07-10 01:14:22 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 1.8081
2022-07-10 01:14:57 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 1.8679
2022-07-10 01:15:29 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 1.8154
2022-07-10 01:16:02 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 1.7909
2022-07-10 01:16:36 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 1.8205
2022-07-10 01:17:08 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 1.6736
2022-07-10 01:17:41 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 1.9822
2022-07-10 01:18:14 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 1.7298
2022-07-10 01:18:48 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 1.5341
2022-07-10 01:19:20 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 1.7139
2022-07-10 01:19:54 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 1.7906
2022-07-10 01:20:26 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 2.0337
2022-07-10 01:21:00 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 1.9744
2022-07-10 01:21:33 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 2.0374
2022-07-10 01:22:06 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 1.7774
2022-07-10 01:22:39 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 2.0365
2022-07-10 01:23:14 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 2.0373
2022-07-10 01:23:45 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 1.8989
2022-07-10 01:24:19 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 1.5552
2022-07-10 01:24:51 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 1.6978
2022-07-10 01:25:26 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 2.1521
2022-07-10 01:25:58 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 1.7742
2022-07-10 01:26:31 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 1.9164
2022-07-10 01:27:05 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 1.7669
2022-07-10 01:27:38 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 1.6329
2022-07-10 01:28:12 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 2.0727
2022-07-10 01:28:44 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 1.8467
2022-07-10 01:29:17 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 1.6369
2022-07-10 01:29:51 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 1.9139
2022-07-10 01:30:25 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 1.8971
2022-07-10 01:30:57 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 2.0951
2022-07-10 01:31:29 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 2.0254
2022-07-10 01:31:29 - train: epoch 057, train_loss: 1.8481
2022-07-10 01:32:42 - eval: epoch: 057, acc1: 61.846%, acc5: 84.322%, test_loss: 1.5885, per_image_load_time: 2.605ms, per_image_inference_time: 0.154ms
2022-07-10 01:32:42 - until epoch: 057, best_acc1: 62.214%
2022-07-10 01:32:42 - epoch 058 lr: 0.010000
2022-07-10 01:33:20 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 1.9515
2022-07-10 01:33:53 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 1.8655
2022-07-10 01:34:26 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 1.7427
2022-07-10 01:34:59 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 1.8246
2022-07-10 01:35:31 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 1.8328
2022-07-10 01:36:03 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 1.8682
2022-07-10 01:36:37 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 1.7487
2022-07-10 01:37:09 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 1.7842
2022-07-10 01:37:43 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 1.5767
2022-07-10 01:38:17 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 1.7952
2022-07-10 01:38:50 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 1.7293
2022-07-10 01:39:22 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 1.8845
2022-07-10 01:39:55 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 2.1443
2022-07-10 01:40:28 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 1.9456
2022-07-10 01:41:02 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 1.9399
2022-07-10 01:41:35 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 2.0661
2022-07-10 01:42:08 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 1.8797
2022-07-10 01:42:40 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 2.0391
2022-07-10 01:43:14 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 2.0065
2022-07-10 01:43:47 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 1.9027
2022-07-10 01:44:22 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 1.8965
2022-07-10 01:44:54 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 1.8850
2022-07-10 01:45:26 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 1.8986
2022-07-10 01:46:01 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 1.9555
2022-07-10 01:46:33 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 1.9275
2022-07-10 01:47:06 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 1.7482
2022-07-10 01:47:39 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 1.9927
2022-07-10 01:48:12 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 1.7667
2022-07-10 01:48:46 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 1.6103
2022-07-10 01:49:19 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 1.8175
2022-07-10 01:49:52 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 1.6967
2022-07-10 01:50:26 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 1.6018
2022-07-10 01:50:58 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 1.9007
2022-07-10 01:51:32 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 1.8463
2022-07-10 01:52:05 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 1.7531
2022-07-10 01:52:38 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 1.7028
2022-07-10 01:53:11 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 1.9298
2022-07-10 01:53:45 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 1.7240
2022-07-10 01:54:18 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 1.7322
2022-07-10 01:54:52 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 1.8925
2022-07-10 01:55:25 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 1.9925
2022-07-10 01:55:57 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 1.7853
2022-07-10 01:56:31 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 1.7994
2022-07-10 01:57:03 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 1.6543
2022-07-10 01:57:37 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 1.6644
2022-07-10 01:58:10 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 1.8445
2022-07-10 01:58:43 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 2.0901
2022-07-10 01:59:17 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 1.9494
2022-07-10 01:59:50 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 1.7487
2022-07-10 02:00:21 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 1.7991
2022-07-10 02:00:22 - train: epoch 058, train_loss: 1.8448
2022-07-10 02:01:34 - eval: epoch: 058, acc1: 61.590%, acc5: 84.424%, test_loss: 1.5996, per_image_load_time: 2.578ms, per_image_inference_time: 0.162ms
2022-07-10 02:01:35 - until epoch: 058, best_acc1: 62.214%
2022-07-10 02:01:35 - epoch 059 lr: 0.010000
2022-07-10 02:02:13 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 1.9214
2022-07-10 02:02:46 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 1.7066
2022-07-10 02:03:18 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 1.9408
2022-07-10 02:03:51 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 1.8618
2022-07-10 02:04:25 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 1.6558
2022-07-10 02:04:56 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 1.9191
2022-07-10 02:05:30 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 1.6538
2022-07-10 02:06:02 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 1.8909
2022-07-10 02:06:35 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 1.8764
2022-07-10 02:07:08 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 2.0365
2022-07-10 02:07:41 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 2.1117
2022-07-10 02:08:14 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 1.6902
2022-07-10 02:08:47 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 2.1564
2022-07-10 02:09:21 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 2.0852
2022-07-10 02:09:54 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 1.8874
2022-07-10 02:10:27 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 1.6847
2022-07-10 02:11:00 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 1.8894
2022-07-10 02:11:33 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 1.6856
2022-07-10 02:12:07 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 1.7626
2022-07-10 02:12:39 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 1.6520
2022-07-10 02:13:12 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 2.0030
2022-07-10 02:13:44 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 1.8213
2022-07-10 02:14:18 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 1.7931
2022-07-10 02:14:51 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 2.1327
2022-07-10 02:15:25 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 1.9904
2022-07-10 02:15:58 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 1.6831
2022-07-10 02:16:31 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 1.8602
2022-07-10 02:17:05 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 1.9550
2022-07-10 02:17:37 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 1.8590
2022-07-10 02:18:11 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 1.9449
2022-07-10 02:18:44 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 1.7319
2022-07-10 02:19:18 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 1.9349
2022-07-10 02:19:51 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 1.9331
2022-07-10 02:20:24 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 2.2737
2022-07-10 02:20:57 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 1.6870
2022-07-10 02:21:30 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 2.0432
2022-07-10 02:22:03 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 1.7248
2022-07-10 02:22:36 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 1.8427
2022-07-10 02:23:11 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 1.7431
2022-07-10 02:23:43 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 1.9268
2022-07-10 02:24:17 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 1.7922
2022-07-10 02:24:49 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 1.8391
2022-07-10 02:25:23 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 1.8418
2022-07-10 02:25:56 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 2.0394
2022-07-10 02:26:30 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 1.9238
2022-07-10 02:27:03 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 1.8675
2022-07-10 02:27:36 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 1.8793
2022-07-10 02:28:09 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 1.7857
2022-07-10 02:28:43 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 1.7185
2022-07-10 02:29:14 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 2.0653
2022-07-10 02:29:15 - train: epoch 059, train_loss: 1.8441
2022-07-10 02:30:28 - eval: epoch: 059, acc1: 61.546%, acc5: 84.246%, test_loss: 1.5890, per_image_load_time: 2.419ms, per_image_inference_time: 0.170ms
2022-07-10 02:30:28 - until epoch: 059, best_acc1: 62.214%
2022-07-10 02:30:28 - epoch 060 lr: 0.010000
2022-07-10 02:31:06 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 1.7063
2022-07-10 02:31:39 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 1.6390
2022-07-10 02:32:11 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 1.8503
2022-07-10 02:32:43 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 1.9628
2022-07-10 02:33:17 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 2.0100
2022-07-10 02:33:49 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 2.0885
2022-07-10 02:34:22 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 2.0441
2022-07-10 02:34:55 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 2.0857
2022-07-10 02:35:28 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 1.7295
2022-07-10 02:36:01 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 1.6214
2022-07-10 02:36:34 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 1.8673
2022-07-10 02:37:08 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 1.6671
2022-07-10 02:37:41 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 1.6697
2022-07-10 02:38:13 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 1.8704
2022-07-10 02:38:47 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 1.9104
2022-07-10 02:39:19 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 1.7401
2022-07-10 02:39:52 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 1.9513
2022-07-10 02:40:26 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 1.9807
2022-07-10 02:40:58 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 2.1210
2022-07-10 02:41:33 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 1.7511
2022-07-10 02:42:05 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 1.9288
2022-07-10 02:42:38 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 2.0209
2022-07-10 02:43:11 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 1.7705
2022-07-10 02:43:44 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 1.9906
2022-07-10 02:44:17 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 1.7614
2022-07-10 02:44:51 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 2.0036
2022-07-10 02:45:25 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 1.6587
2022-07-10 02:45:57 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 2.0234
2022-07-10 02:46:31 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 2.0371
2022-07-10 02:47:04 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 1.8385
2022-07-10 02:47:38 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 2.0852
2022-07-10 02:48:10 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 1.8383
2022-07-10 02:48:43 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 1.4973
2022-07-10 02:49:18 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 1.8727
2022-07-10 02:49:50 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 2.0336
2022-07-10 02:50:23 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 2.0221
2022-07-10 02:50:56 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 2.0625
2022-07-10 02:51:29 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 1.8820
2022-07-10 02:52:03 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 1.9646
2022-07-10 02:52:36 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 1.9463
2022-07-10 02:53:09 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 1.8695
2022-07-10 02:53:43 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 1.9381
2022-07-10 02:54:15 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 1.7356
2022-07-10 02:54:49 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 2.0328
2022-07-10 02:55:22 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 2.0648
2022-07-10 02:55:55 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 1.8688
2022-07-10 02:56:29 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 1.8138
2022-07-10 02:57:02 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 1.8161
2022-07-10 02:57:35 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 1.9214
2022-07-10 02:58:06 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 1.9806
2022-07-10 02:58:07 - train: epoch 060, train_loss: 1.8431
2022-07-10 02:59:21 - eval: epoch: 060, acc1: 61.056%, acc5: 84.036%, test_loss: 1.6201, per_image_load_time: 2.161ms, per_image_inference_time: 0.166ms
2022-07-10 02:59:21 - until epoch: 060, best_acc1: 62.214%
2022-07-10 02:59:21 - epoch 061 lr: 0.001000
2022-07-10 02:59:59 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 1.3218
2022-07-10 03:00:31 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 1.6527
2022-07-10 03:01:03 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 1.6186
2022-07-10 03:01:37 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 2.0232
2022-07-10 03:02:09 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 1.6275
2022-07-10 03:02:42 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 1.6673
2022-07-10 03:03:15 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 1.7177
2022-07-10 03:03:48 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 1.7253
2022-07-10 03:04:20 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 1.5754
2022-07-10 03:04:53 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 1.5130
2022-07-10 03:05:27 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 1.4395
2022-07-10 03:06:00 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 1.5305
2022-07-10 03:06:33 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 1.4670
2022-07-10 03:07:07 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 1.6483
2022-07-10 03:07:40 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 1.5008
2022-07-10 03:08:13 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 1.4780
2022-07-10 03:08:45 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 1.8384
2022-07-10 03:09:19 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 1.8282
2022-07-10 03:09:51 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 1.8615
2022-07-10 03:10:25 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 1.5861
2022-07-10 03:10:57 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 1.9140
2022-07-10 03:11:31 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 1.5572
2022-07-10 03:12:04 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 1.6047
2022-07-10 03:12:37 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 1.4924
2022-07-10 03:13:12 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 1.6711
2022-07-10 03:13:44 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 1.6296
2022-07-10 03:14:17 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 1.8390
2022-07-10 03:14:50 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 1.5716
2022-07-10 03:15:23 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 1.7461
2022-07-10 03:15:57 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 1.6689
2022-07-10 03:16:30 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 1.6326
2022-07-10 03:17:04 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 1.5739
2022-07-10 03:17:36 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 1.6129
2022-07-10 03:18:10 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 1.5700
2022-07-10 03:18:43 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 1.7767
2022-07-10 03:19:17 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 1.7257
2022-07-10 03:19:49 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 1.5174
2022-07-10 03:20:23 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 1.6790
2022-07-10 03:20:55 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 1.7854
2022-07-10 03:21:29 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 1.8179
2022-07-10 03:22:03 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 1.9283
2022-07-10 03:22:35 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 1.7602
2022-07-10 03:23:09 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 1.7500
2022-07-10 03:23:42 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 1.6707
2022-07-10 03:24:16 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 1.5636
2022-07-10 03:24:49 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 1.5325
2022-07-10 03:25:22 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 1.8772
2022-07-10 03:25:56 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 1.5134
2022-07-10 03:26:29 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 1.6391
2022-07-10 03:27:01 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 1.8140
2022-07-10 03:27:02 - train: epoch 061, train_loss: 1.6702
2022-07-10 03:28:15 - eval: epoch: 061, acc1: 65.406%, acc5: 86.584%, test_loss: 1.4218, per_image_load_time: 1.834ms, per_image_inference_time: 0.188ms
2022-07-10 03:28:15 - until epoch: 061, best_acc1: 65.406%
2022-07-10 03:28:15 - epoch 062 lr: 0.001000
2022-07-10 03:28:52 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 1.7668
2022-07-10 03:29:25 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 1.6834
2022-07-10 03:29:57 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 1.6889
2022-07-10 03:30:30 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 1.7997
2022-07-10 03:31:02 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 1.6773
2022-07-10 03:31:35 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 1.4105
2022-07-10 03:32:08 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 1.7282
2022-07-10 03:32:41 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 1.7015
2022-07-10 03:33:14 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 1.6137
2022-07-10 03:33:47 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 1.7797
2022-07-10 03:34:19 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 1.6095
2022-07-10 03:34:52 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 1.6094
2022-07-10 03:35:26 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 1.7353
2022-07-10 03:35:59 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 1.5366
2022-07-10 03:36:32 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 1.7519
2022-07-10 03:37:04 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 1.8102
2022-07-10 03:37:38 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 1.6878
2022-07-10 03:38:11 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 1.4325
2022-07-10 03:38:44 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 1.5290
2022-07-10 03:39:17 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 1.7586
2022-07-10 03:39:50 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 1.9109
2022-07-10 03:40:23 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 1.4020
2022-07-10 03:40:56 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 1.5041
2022-07-10 03:41:29 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 1.7288
2022-07-10 03:42:02 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 1.7632
2022-07-10 03:42:35 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 1.6093
2022-07-10 03:43:09 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 1.6115
2022-07-10 03:43:41 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 1.8511
2022-07-10 03:44:15 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 1.7963
2022-07-10 03:44:48 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 1.7058
2022-07-10 03:45:21 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 1.6937
2022-07-10 03:45:55 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 1.5137
2022-07-10 03:46:28 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 1.6327
2022-07-10 03:47:00 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 1.5700
2022-07-10 03:47:34 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 1.5622
2022-07-10 03:48:06 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 1.6048
2022-07-10 03:48:40 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 1.6111
2022-07-10 03:49:12 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 1.6411
2022-07-10 03:49:46 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 1.7915
2022-07-10 03:50:19 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 1.6214
2022-07-10 03:50:52 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 1.7600
2022-07-10 03:51:26 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 1.3745
2022-07-10 03:51:59 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 1.4478
2022-07-10 03:52:31 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 1.5107
2022-07-10 03:53:05 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 1.6107
2022-07-10 03:53:38 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 1.5544
2022-07-10 03:54:12 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 1.5286
2022-07-10 03:54:44 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 1.5360
2022-07-10 03:55:18 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 1.7271
2022-07-10 03:55:49 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 1.7278
2022-07-10 03:55:50 - train: epoch 062, train_loss: 1.6256
2022-07-10 03:57:03 - eval: epoch: 062, acc1: 65.862%, acc5: 86.808%, test_loss: 1.4005, per_image_load_time: 2.213ms, per_image_inference_time: 0.178ms
2022-07-10 03:57:03 - until epoch: 062, best_acc1: 65.862%
2022-07-10 03:57:03 - epoch 063 lr: 0.001000
2022-07-10 03:57:40 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 1.6367
2022-07-10 03:58:13 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 1.4683
2022-07-10 03:58:47 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 1.6339
2022-07-10 03:59:19 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 1.6435
2022-07-10 03:59:52 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 1.5387
2022-07-10 04:00:25 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 1.6124
2022-07-10 04:00:58 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 1.7107
2022-07-10 04:01:30 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 1.7175
2022-07-10 04:02:04 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 1.6736
2022-07-10 04:02:36 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 1.7725
2022-07-10 04:03:10 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 1.4178
2022-07-10 04:03:43 - train: epoch 0063, iter [01200, 05004], lr: 0.001000, loss: 1.6266
2022-07-10 04:04:17 - train: epoch 0063, iter [01300, 05004], lr: 0.001000, loss: 1.3797
2022-07-10 04:04:49 - train: epoch 0063, iter [01400, 05004], lr: 0.001000, loss: 1.8515
2022-07-10 04:05:22 - train: epoch 0063, iter [01500, 05004], lr: 0.001000, loss: 1.6802
2022-07-10 04:05:55 - train: epoch 0063, iter [01600, 05004], lr: 0.001000, loss: 1.5793
2022-07-10 04:06:29 - train: epoch 0063, iter [01700, 05004], lr: 0.001000, loss: 1.5394
2022-07-10 04:07:01 - train: epoch 0063, iter [01800, 05004], lr: 0.001000, loss: 1.6264
2022-07-10 04:07:35 - train: epoch 0063, iter [01900, 05004], lr: 0.001000, loss: 1.7535
2022-07-10 04:08:07 - train: epoch 0063, iter [02000, 05004], lr: 0.001000, loss: 1.3579
2022-07-10 04:08:41 - train: epoch 0063, iter [02100, 05004], lr: 0.001000, loss: 1.6009
2022-07-10 04:09:14 - train: epoch 0063, iter [02200, 05004], lr: 0.001000, loss: 1.8348
2022-07-10 04:09:48 - train: epoch 0063, iter [02300, 05004], lr: 0.001000, loss: 1.7198
2022-07-10 04:10:21 - train: epoch 0063, iter [02400, 05004], lr: 0.001000, loss: 1.5763
2022-07-10 04:10:55 - train: epoch 0063, iter [02500, 05004], lr: 0.001000, loss: 1.6602
2022-07-10 04:11:28 - train: epoch 0063, iter [02600, 05004], lr: 0.001000, loss: 1.5268
2022-07-10 04:12:01 - train: epoch 0063, iter [02700, 05004], lr: 0.001000, loss: 1.8726
2022-07-10 04:12:33 - train: epoch 0063, iter [02800, 05004], lr: 0.001000, loss: 1.6561
2022-07-10 04:13:07 - train: epoch 0063, iter [02900, 05004], lr: 0.001000, loss: 1.7264
2022-07-10 04:13:40 - train: epoch 0063, iter [03000, 05004], lr: 0.001000, loss: 1.7417
2022-07-10 04:14:13 - train: epoch 0063, iter [03100, 05004], lr: 0.001000, loss: 1.9125
2022-07-10 04:14:45 - train: epoch 0063, iter [03200, 05004], lr: 0.001000, loss: 1.5815
2022-07-10 04:15:20 - train: epoch 0063, iter [03300, 05004], lr: 0.001000, loss: 1.5915
2022-07-10 04:15:52 - train: epoch 0063, iter [03400, 05004], lr: 0.001000, loss: 1.4701
2022-07-10 04:16:26 - train: epoch 0063, iter [03500, 05004], lr: 0.001000, loss: 1.7155
2022-07-10 04:16:58 - train: epoch 0063, iter [03600, 05004], lr: 0.001000, loss: 1.6063
2022-07-10 04:17:32 - train: epoch 0063, iter [03700, 05004], lr: 0.001000, loss: 1.5578
2022-07-10 04:18:05 - train: epoch 0063, iter [03800, 05004], lr: 0.001000, loss: 1.6876
2022-07-10 04:18:38 - train: epoch 0063, iter [03900, 05004], lr: 0.001000, loss: 1.5737
2022-07-10 04:19:11 - train: epoch 0063, iter [04000, 05004], lr: 0.001000, loss: 1.4208
2022-07-10 04:19:45 - train: epoch 0063, iter [04100, 05004], lr: 0.001000, loss: 1.6421
2022-07-10 04:20:17 - train: epoch 0063, iter [04200, 05004], lr: 0.001000, loss: 1.5249
2022-07-10 04:20:51 - train: epoch 0063, iter [04300, 05004], lr: 0.001000, loss: 1.7423
2022-07-10 04:21:24 - train: epoch 0063, iter [04400, 05004], lr: 0.001000, loss: 1.6419
2022-07-10 04:21:57 - train: epoch 0063, iter [04500, 05004], lr: 0.001000, loss: 1.5898
2022-07-10 04:22:30 - train: epoch 0063, iter [04600, 05004], lr: 0.001000, loss: 1.5119
2022-07-10 04:23:03 - train: epoch 0063, iter [04700, 05004], lr: 0.001000, loss: 1.6000
2022-07-10 04:23:36 - train: epoch 0063, iter [04800, 05004], lr: 0.001000, loss: 1.6356
2022-07-10 04:24:09 - train: epoch 0063, iter [04900, 05004], lr: 0.001000, loss: 1.6374
2022-07-10 04:24:41 - train: epoch 0063, iter [05000, 05004], lr: 0.001000, loss: 1.7079
2022-07-10 04:24:42 - train: epoch 063, train_loss: 1.6071
2022-07-10 04:25:55 - eval: epoch: 063, acc1: 66.066%, acc5: 86.950%, test_loss: 1.3925, per_image_load_time: 2.715ms, per_image_inference_time: 0.150ms
2022-07-10 04:25:55 - until epoch: 063, best_acc1: 66.066%
2022-07-10 04:25:55 - epoch 064 lr: 0.001000
2022-07-10 04:26:33 - train: epoch 0064, iter [00100, 05004], lr: 0.001000, loss: 1.3990
2022-07-10 04:27:06 - train: epoch 0064, iter [00200, 05004], lr: 0.001000, loss: 1.4931
2022-07-10 04:27:39 - train: epoch 0064, iter [00300, 05004], lr: 0.001000, loss: 1.5262
2022-07-10 04:28:12 - train: epoch 0064, iter [00400, 05004], lr: 0.001000, loss: 1.5409
2022-07-10 04:28:44 - train: epoch 0064, iter [00500, 05004], lr: 0.001000, loss: 1.4921
2022-07-10 04:29:18 - train: epoch 0064, iter [00600, 05004], lr: 0.001000, loss: 1.7094
2022-07-10 04:29:51 - train: epoch 0064, iter [00700, 05004], lr: 0.001000, loss: 1.8127
2022-07-10 04:30:23 - train: epoch 0064, iter [00800, 05004], lr: 0.001000, loss: 1.5648
2022-07-10 04:30:56 - train: epoch 0064, iter [00900, 05004], lr: 0.001000, loss: 1.5174
2022-07-10 04:31:30 - train: epoch 0064, iter [01000, 05004], lr: 0.001000, loss: 1.5284
2022-07-10 04:32:03 - train: epoch 0064, iter [01100, 05004], lr: 0.001000, loss: 1.5124
2022-07-10 04:32:37 - train: epoch 0064, iter [01200, 05004], lr: 0.001000, loss: 1.4785
2022-07-10 04:33:10 - train: epoch 0064, iter [01300, 05004], lr: 0.001000, loss: 1.6870
2022-07-10 04:33:43 - train: epoch 0064, iter [01400, 05004], lr: 0.001000, loss: 1.7263
2022-07-10 04:34:16 - train: epoch 0064, iter [01500, 05004], lr: 0.001000, loss: 1.7766
2022-07-10 04:34:50 - train: epoch 0064, iter [01600, 05004], lr: 0.001000, loss: 1.5586
2022-07-10 04:35:22 - train: epoch 0064, iter [01700, 05004], lr: 0.001000, loss: 1.4981
2022-07-10 04:35:57 - train: epoch 0064, iter [01800, 05004], lr: 0.001000, loss: 1.6231
2022-07-10 04:36:29 - train: epoch 0064, iter [01900, 05004], lr: 0.001000, loss: 1.5800
2022-07-10 04:37:02 - train: epoch 0064, iter [02000, 05004], lr: 0.001000, loss: 1.4754
2022-07-10 04:37:36 - train: epoch 0064, iter [02100, 05004], lr: 0.001000, loss: 1.6298
2022-07-10 04:38:08 - train: epoch 0064, iter [02200, 05004], lr: 0.001000, loss: 1.6728
2022-07-10 04:38:41 - train: epoch 0064, iter [02300, 05004], lr: 0.001000, loss: 1.6888
2022-07-10 04:39:14 - train: epoch 0064, iter [02400, 05004], lr: 0.001000, loss: 1.5034
2022-07-10 04:39:48 - train: epoch 0064, iter [02500, 05004], lr: 0.001000, loss: 1.5165
2022-07-10 04:40:21 - train: epoch 0064, iter [02600, 05004], lr: 0.001000, loss: 1.6864
2022-07-10 04:40:54 - train: epoch 0064, iter [02700, 05004], lr: 0.001000, loss: 1.5730
2022-07-10 04:41:28 - train: epoch 0064, iter [02800, 05004], lr: 0.001000, loss: 1.4943
2022-07-10 04:42:01 - train: epoch 0064, iter [02900, 05004], lr: 0.001000, loss: 1.6006
2022-07-10 04:42:35 - train: epoch 0064, iter [03000, 05004], lr: 0.001000, loss: 1.4226
2022-07-10 04:43:07 - train: epoch 0064, iter [03100, 05004], lr: 0.001000, loss: 1.6043
2022-07-10 04:43:42 - train: epoch 0064, iter [03200, 05004], lr: 0.001000, loss: 1.5862
2022-07-10 04:44:14 - train: epoch 0064, iter [03300, 05004], lr: 0.001000, loss: 1.5679
2022-07-10 04:44:48 - train: epoch 0064, iter [03400, 05004], lr: 0.001000, loss: 1.5950
2022-07-10 04:45:21 - train: epoch 0064, iter [03500, 05004], lr: 0.001000, loss: 1.5336
2022-07-10 04:45:54 - train: epoch 0064, iter [03600, 05004], lr: 0.001000, loss: 1.4901
2022-07-10 04:46:26 - train: epoch 0064, iter [03700, 05004], lr: 0.001000, loss: 1.3336
2022-07-10 04:47:00 - train: epoch 0064, iter [03800, 05004], lr: 0.001000, loss: 1.7059
2022-07-10 04:47:33 - train: epoch 0064, iter [03900, 05004], lr: 0.001000, loss: 1.6746
2022-07-10 04:48:08 - train: epoch 0064, iter [04000, 05004], lr: 0.001000, loss: 1.4715
2022-07-10 04:48:41 - train: epoch 0064, iter [04100, 05004], lr: 0.001000, loss: 1.6966
2022-07-10 04:49:14 - train: epoch 0064, iter [04200, 05004], lr: 0.001000, loss: 1.4306
2022-07-10 04:49:47 - train: epoch 0064, iter [04300, 05004], lr: 0.001000, loss: 1.6582
2022-07-10 04:50:20 - train: epoch 0064, iter [04400, 05004], lr: 0.001000, loss: 1.5755
2022-07-10 04:50:54 - train: epoch 0064, iter [04500, 05004], lr: 0.001000, loss: 1.5346
2022-07-10 04:51:27 - train: epoch 0064, iter [04600, 05004], lr: 0.001000, loss: 1.7283
2022-07-10 04:52:01 - train: epoch 0064, iter [04700, 05004], lr: 0.001000, loss: 1.8671
2022-07-10 04:52:34 - train: epoch 0064, iter [04800, 05004], lr: 0.001000, loss: 1.7471
2022-07-10 04:53:07 - train: epoch 0064, iter [04900, 05004], lr: 0.001000, loss: 1.6346
2022-07-10 04:53:38 - train: epoch 0064, iter [05000, 05004], lr: 0.001000, loss: 1.5815
2022-07-10 04:53:39 - train: epoch 064, train_loss: 1.5993
2022-07-10 04:54:52 - eval: epoch: 064, acc1: 66.276%, acc5: 87.134%, test_loss: 1.3845, per_image_load_time: 2.540ms, per_image_inference_time: 0.150ms
2022-07-10 04:54:52 - until epoch: 064, best_acc1: 66.276%
2022-07-10 04:54:52 - epoch 065 lr: 0.001000
2022-07-10 04:55:31 - train: epoch 0065, iter [00100, 05004], lr: 0.001000, loss: 1.7978
2022-07-10 04:56:03 - train: epoch 0065, iter [00200, 05004], lr: 0.001000, loss: 1.5995
2022-07-10 04:56:35 - train: epoch 0065, iter [00300, 05004], lr: 0.001000, loss: 1.5782
2022-07-10 04:57:08 - train: epoch 0065, iter [00400, 05004], lr: 0.001000, loss: 1.4613
2022-07-10 04:57:41 - train: epoch 0065, iter [00500, 05004], lr: 0.001000, loss: 1.7741
2022-07-10 04:58:15 - train: epoch 0065, iter [00600, 05004], lr: 0.001000, loss: 1.6064
2022-07-10 04:58:48 - train: epoch 0065, iter [00700, 05004], lr: 0.001000, loss: 1.6454
2022-07-10 04:59:20 - train: epoch 0065, iter [00800, 05004], lr: 0.001000, loss: 1.5060
2022-07-10 04:59:53 - train: epoch 0065, iter [00900, 05004], lr: 0.001000, loss: 1.6557
2022-07-10 05:00:26 - train: epoch 0065, iter [01000, 05004], lr: 0.001000, loss: 1.5893
2022-07-10 05:00:59 - train: epoch 0065, iter [01100, 05004], lr: 0.001000, loss: 1.4403
2022-07-10 05:01:32 - train: epoch 0065, iter [01200, 05004], lr: 0.001000, loss: 1.9289
2022-07-10 05:02:06 - train: epoch 0065, iter [01300, 05004], lr: 0.001000, loss: 1.5971
2022-07-10 05:02:39 - train: epoch 0065, iter [01400, 05004], lr: 0.001000, loss: 1.3736
2022-07-10 05:03:12 - train: epoch 0065, iter [01500, 05004], lr: 0.001000, loss: 1.5381
2022-07-10 05:03:45 - train: epoch 0065, iter [01600, 05004], lr: 0.001000, loss: 1.6888
2022-07-10 05:04:18 - train: epoch 0065, iter [01700, 05004], lr: 0.001000, loss: 1.5761
2022-07-10 05:04:52 - train: epoch 0065, iter [01800, 05004], lr: 0.001000, loss: 1.4525
2022-07-10 05:05:24 - train: epoch 0065, iter [01900, 05004], lr: 0.001000, loss: 1.5708
2022-07-10 05:05:57 - train: epoch 0065, iter [02000, 05004], lr: 0.001000, loss: 1.6257
2022-07-10 05:06:29 - train: epoch 0065, iter [02100, 05004], lr: 0.001000, loss: 1.6335
2022-07-10 05:07:03 - train: epoch 0065, iter [02200, 05004], lr: 0.001000, loss: 1.5555
2022-07-10 05:07:36 - train: epoch 0065, iter [02300, 05004], lr: 0.001000, loss: 1.6820
2022-07-10 05:08:09 - train: epoch 0065, iter [02400, 05004], lr: 0.001000, loss: 1.5511
2022-07-10 05:08:42 - train: epoch 0065, iter [02500, 05004], lr: 0.001000, loss: 1.4461
2022-07-10 05:09:16 - train: epoch 0065, iter [02600, 05004], lr: 0.001000, loss: 1.8011
2022-07-10 05:09:49 - train: epoch 0065, iter [02700, 05004], lr: 0.001000, loss: 1.7071
2022-07-10 05:10:22 - train: epoch 0065, iter [02800, 05004], lr: 0.001000, loss: 1.6672
2022-07-10 05:10:54 - train: epoch 0065, iter [02900, 05004], lr: 0.001000, loss: 1.4244
2022-07-10 05:11:28 - train: epoch 0065, iter [03000, 05004], lr: 0.001000, loss: 1.4484
2022-07-10 05:12:02 - train: epoch 0065, iter [03100, 05004], lr: 0.001000, loss: 1.5978
2022-07-10 05:12:34 - train: epoch 0065, iter [03200, 05004], lr: 0.001000, loss: 1.6052
2022-07-10 05:13:07 - train: epoch 0065, iter [03300, 05004], lr: 0.001000, loss: 1.4793
2022-07-10 05:13:40 - train: epoch 0065, iter [03400, 05004], lr: 0.001000, loss: 1.5117
2022-07-10 05:14:13 - train: epoch 0065, iter [03500, 05004], lr: 0.001000, loss: 1.7184
2022-07-10 05:14:46 - train: epoch 0065, iter [03600, 05004], lr: 0.001000, loss: 1.4999
2022-07-10 05:15:21 - train: epoch 0065, iter [03700, 05004], lr: 0.001000, loss: 1.4757
2022-07-10 05:15:53 - train: epoch 0065, iter [03800, 05004], lr: 0.001000, loss: 1.5940
2022-07-10 05:16:27 - train: epoch 0065, iter [03900, 05004], lr: 0.001000, loss: 1.7077
2022-07-10 05:17:00 - train: epoch 0065, iter [04000, 05004], lr: 0.001000, loss: 1.7349
2022-07-10 05:17:32 - train: epoch 0065, iter [04100, 05004], lr: 0.001000, loss: 1.6414
2022-07-10 05:18:06 - train: epoch 0065, iter [04200, 05004], lr: 0.001000, loss: 1.5595
2022-07-10 05:18:39 - train: epoch 0065, iter [04300, 05004], lr: 0.001000, loss: 1.4585
2022-07-10 05:19:13 - train: epoch 0065, iter [04400, 05004], lr: 0.001000, loss: 1.6428
2022-07-10 05:19:45 - train: epoch 0065, iter [04500, 05004], lr: 0.001000, loss: 1.5579
2022-07-10 05:20:18 - train: epoch 0065, iter [04600, 05004], lr: 0.001000, loss: 1.5369
2022-07-10 05:20:52 - train: epoch 0065, iter [04700, 05004], lr: 0.001000, loss: 1.4926
2022-07-10 05:21:25 - train: epoch 0065, iter [04800, 05004], lr: 0.001000, loss: 1.3950
2022-07-10 05:21:58 - train: epoch 0065, iter [04900, 05004], lr: 0.001000, loss: 1.5556
2022-07-10 05:22:30 - train: epoch 0065, iter [05000, 05004], lr: 0.001000, loss: 1.6114
2022-07-10 05:22:30 - train: epoch 065, train_loss: 1.5886
2022-07-10 05:23:43 - eval: epoch: 065, acc1: 66.470%, acc5: 87.022%, test_loss: 1.3827, per_image_load_time: 1.930ms, per_image_inference_time: 0.160ms
2022-07-10 05:23:43 - until epoch: 065, best_acc1: 66.470%
2022-07-10 05:23:43 - epoch 066 lr: 0.001000
2022-07-10 05:24:21 - train: epoch 0066, iter [00100, 05004], lr: 0.001000, loss: 1.4813
2022-07-10 05:24:55 - train: epoch 0066, iter [00200, 05004], lr: 0.001000, loss: 1.7553
2022-07-10 05:25:27 - train: epoch 0066, iter [00300, 05004], lr: 0.001000, loss: 1.4232
2022-07-10 05:26:00 - train: epoch 0066, iter [00400, 05004], lr: 0.001000, loss: 1.3710
2022-07-10 05:26:32 - train: epoch 0066, iter [00500, 05004], lr: 0.001000, loss: 1.6587
2022-07-10 05:27:05 - train: epoch 0066, iter [00600, 05004], lr: 0.001000, loss: 1.5151
2022-07-10 05:27:37 - train: epoch 0066, iter [00700, 05004], lr: 0.001000, loss: 1.7136
2022-07-10 05:28:10 - train: epoch 0066, iter [00800, 05004], lr: 0.001000, loss: 1.6183
2022-07-10 05:28:43 - train: epoch 0066, iter [00900, 05004], lr: 0.001000, loss: 1.4439
2022-07-10 05:29:17 - train: epoch 0066, iter [01000, 05004], lr: 0.001000, loss: 1.6158
2022-07-10 05:29:49 - train: epoch 0066, iter [01100, 05004], lr: 0.001000, loss: 1.5040
2022-07-10 05:30:22 - train: epoch 0066, iter [01200, 05004], lr: 0.001000, loss: 1.6830
2022-07-10 05:30:55 - train: epoch 0066, iter [01300, 05004], lr: 0.001000, loss: 1.5308
2022-07-10 05:31:28 - train: epoch 0066, iter [01400, 05004], lr: 0.001000, loss: 1.5317
2022-07-10 05:32:01 - train: epoch 0066, iter [01500, 05004], lr: 0.001000, loss: 1.6422
2022-07-10 05:32:34 - train: epoch 0066, iter [01600, 05004], lr: 0.001000, loss: 1.6303
2022-07-10 05:33:08 - train: epoch 0066, iter [01700, 05004], lr: 0.001000, loss: 1.5975
2022-07-10 05:33:41 - train: epoch 0066, iter [01800, 05004], lr: 0.001000, loss: 1.4097
2022-07-10 05:34:14 - train: epoch 0066, iter [01900, 05004], lr: 0.001000, loss: 1.7928
2022-07-10 05:34:46 - train: epoch 0066, iter [02000, 05004], lr: 0.001000, loss: 1.5132
2022-07-10 05:35:19 - train: epoch 0066, iter [02100, 05004], lr: 0.001000, loss: 1.4891
2022-07-10 05:35:52 - train: epoch 0066, iter [02200, 05004], lr: 0.001000, loss: 1.4416
2022-07-10 05:36:26 - train: epoch 0066, iter [02300, 05004], lr: 0.001000, loss: 1.7320
2022-07-10 05:36:59 - train: epoch 0066, iter [02400, 05004], lr: 0.001000, loss: 1.5967
2022-07-10 05:37:32 - train: epoch 0066, iter [02500, 05004], lr: 0.001000, loss: 1.6223
2022-07-10 05:38:05 - train: epoch 0066, iter [02600, 05004], lr: 0.001000, loss: 1.4208
2022-07-10 05:38:39 - train: epoch 0066, iter [02700, 05004], lr: 0.001000, loss: 1.6830
2022-07-10 05:39:11 - train: epoch 0066, iter [02800, 05004], lr: 0.001000, loss: 1.5319
2022-07-10 05:39:46 - train: epoch 0066, iter [02900, 05004], lr: 0.001000, loss: 1.5609
2022-07-10 05:40:17 - train: epoch 0066, iter [03000, 05004], lr: 0.001000, loss: 1.4964
2022-07-10 05:40:52 - train: epoch 0066, iter [03100, 05004], lr: 0.001000, loss: 1.8838
2022-07-10 05:41:24 - train: epoch 0066, iter [03200, 05004], lr: 0.001000, loss: 1.6826
2022-07-10 05:41:58 - train: epoch 0066, iter [03300, 05004], lr: 0.001000, loss: 1.6574
2022-07-10 05:42:30 - train: epoch 0066, iter [03400, 05004], lr: 0.001000, loss: 1.6524
2022-07-10 05:43:04 - train: epoch 0066, iter [03500, 05004], lr: 0.001000, loss: 1.7608
2022-07-10 05:43:38 - train: epoch 0066, iter [03600, 05004], lr: 0.001000, loss: 1.5732
2022-07-10 05:44:10 - train: epoch 0066, iter [03700, 05004], lr: 0.001000, loss: 1.5689
2022-07-10 05:44:44 - train: epoch 0066, iter [03800, 05004], lr: 0.001000, loss: 1.5620
2022-07-10 05:45:17 - train: epoch 0066, iter [03900, 05004], lr: 0.001000, loss: 1.5285
2022-07-10 05:45:51 - train: epoch 0066, iter [04000, 05004], lr: 0.001000, loss: 1.7006
2022-07-10 05:46:23 - train: epoch 0066, iter [04100, 05004], lr: 0.001000, loss: 1.5294
2022-07-10 05:46:56 - train: epoch 0066, iter [04200, 05004], lr: 0.001000, loss: 1.3370
2022-07-10 05:47:28 - train: epoch 0066, iter [04300, 05004], lr: 0.001000, loss: 1.5693
2022-07-10 05:48:02 - train: epoch 0066, iter [04400, 05004], lr: 0.001000, loss: 1.6059
2022-07-10 05:48:35 - train: epoch 0066, iter [04500, 05004], lr: 0.001000, loss: 1.7512
2022-07-10 05:49:09 - train: epoch 0066, iter [04600, 05004], lr: 0.001000, loss: 1.6326
2022-07-10 05:49:42 - train: epoch 0066, iter [04700, 05004], lr: 0.001000, loss: 1.5470
2022-07-10 05:50:15 - train: epoch 0066, iter [04800, 05004], lr: 0.001000, loss: 1.6416
2022-07-10 05:50:48 - train: epoch 0066, iter [04900, 05004], lr: 0.001000, loss: 1.3855
2022-07-10 05:51:20 - train: epoch 0066, iter [05000, 05004], lr: 0.001000, loss: 1.5672
2022-07-10 05:51:20 - train: epoch 066, train_loss: 1.5813
2022-07-10 05:52:34 - eval: epoch: 066, acc1: 66.328%, acc5: 87.218%, test_loss: 1.3771, per_image_load_time: 2.637ms, per_image_inference_time: 0.159ms
2022-07-10 05:52:34 - until epoch: 066, best_acc1: 66.470%
2022-07-10 05:52:34 - epoch 067 lr: 0.001000
2022-07-10 05:53:12 - train: epoch 0067, iter [00100, 05004], lr: 0.001000, loss: 1.4609
2022-07-10 05:53:46 - train: epoch 0067, iter [00200, 05004], lr: 0.001000, loss: 1.7384
2022-07-10 05:54:19 - train: epoch 0067, iter [00300, 05004], lr: 0.001000, loss: 1.5333
2022-07-10 05:54:50 - train: epoch 0067, iter [00400, 05004], lr: 0.001000, loss: 1.5129
2022-07-10 05:55:23 - train: epoch 0067, iter [00500, 05004], lr: 0.001000, loss: 1.3743
2022-07-10 05:55:56 - train: epoch 0067, iter [00600, 05004], lr: 0.001000, loss: 1.4681
2022-07-10 05:56:28 - train: epoch 0067, iter [00700, 05004], lr: 0.001000, loss: 1.6279
2022-07-10 05:57:02 - train: epoch 0067, iter [00800, 05004], lr: 0.001000, loss: 1.6055
2022-07-10 05:57:35 - train: epoch 0067, iter [00900, 05004], lr: 0.001000, loss: 1.8002
2022-07-10 05:58:08 - train: epoch 0067, iter [01000, 05004], lr: 0.001000, loss: 1.4906
2022-07-10 05:58:41 - train: epoch 0067, iter [01100, 05004], lr: 0.001000, loss: 1.5180
2022-07-10 05:59:14 - train: epoch 0067, iter [01200, 05004], lr: 0.001000, loss: 1.6079
2022-07-10 05:59:47 - train: epoch 0067, iter [01300, 05004], lr: 0.001000, loss: 1.6109
2022-07-10 06:00:20 - train: epoch 0067, iter [01400, 05004], lr: 0.001000, loss: 1.5127
2022-07-10 06:00:54 - train: epoch 0067, iter [01500, 05004], lr: 0.001000, loss: 1.5514
2022-07-10 06:01:26 - train: epoch 0067, iter [01600, 05004], lr: 0.001000, loss: 1.4870
2022-07-10 06:02:00 - train: epoch 0067, iter [01700, 05004], lr: 0.001000, loss: 1.4309
2022-07-10 06:02:31 - train: epoch 0067, iter [01800, 05004], lr: 0.001000, loss: 1.8612
2022-07-10 06:03:05 - train: epoch 0067, iter [01900, 05004], lr: 0.001000, loss: 1.6068
2022-07-10 06:03:37 - train: epoch 0067, iter [02000, 05004], lr: 0.001000, loss: 1.6520
2022-07-10 06:04:11 - train: epoch 0067, iter [02100, 05004], lr: 0.001000, loss: 1.4686
2022-07-10 06:04:45 - train: epoch 0067, iter [02200, 05004], lr: 0.001000, loss: 1.7035
2022-07-10 06:05:18 - train: epoch 0067, iter [02300, 05004], lr: 0.001000, loss: 1.6302
2022-07-10 06:05:51 - train: epoch 0067, iter [02400, 05004], lr: 0.001000, loss: 1.4355
2022-07-10 06:06:23 - train: epoch 0067, iter [02500, 05004], lr: 0.001000, loss: 1.5562
2022-07-10 06:06:56 - train: epoch 0067, iter [02600, 05004], lr: 0.001000, loss: 1.6074
2022-07-10 06:07:29 - train: epoch 0067, iter [02700, 05004], lr: 0.001000, loss: 1.2775
2022-07-10 06:08:03 - train: epoch 0067, iter [02800, 05004], lr: 0.001000, loss: 1.6808
2022-07-10 06:08:36 - train: epoch 0067, iter [02900, 05004], lr: 0.001000, loss: 1.4979
2022-07-10 06:09:10 - train: epoch 0067, iter [03000, 05004], lr: 0.001000, loss: 1.5786
2022-07-10 06:09:42 - train: epoch 0067, iter [03100, 05004], lr: 0.001000, loss: 1.4383
2022-07-10 06:10:16 - train: epoch 0067, iter [03200, 05004], lr: 0.001000, loss: 1.5264
2022-07-10 06:10:49 - train: epoch 0067, iter [03300, 05004], lr: 0.001000, loss: 1.4871
2022-07-10 06:11:21 - train: epoch 0067, iter [03400, 05004], lr: 0.001000, loss: 1.4931
2022-07-10 06:11:55 - train: epoch 0067, iter [03500, 05004], lr: 0.001000, loss: 1.5956
2022-07-10 06:12:29 - train: epoch 0067, iter [03600, 05004], lr: 0.001000, loss: 1.6516
2022-07-10 06:13:02 - train: epoch 0067, iter [03700, 05004], lr: 0.001000, loss: 1.6969
2022-07-10 06:13:35 - train: epoch 0067, iter [03800, 05004], lr: 0.001000, loss: 1.6040
2022-07-10 06:14:08 - train: epoch 0067, iter [03900, 05004], lr: 0.001000, loss: 1.7537
2022-07-10 06:14:42 - train: epoch 0067, iter [04000, 05004], lr: 0.001000, loss: 1.5059
2022-07-10 06:15:14 - train: epoch 0067, iter [04100, 05004], lr: 0.001000, loss: 1.6233
2022-07-10 06:15:48 - train: epoch 0067, iter [04200, 05004], lr: 0.001000, loss: 1.5068
2022-07-10 06:16:21 - train: epoch 0067, iter [04300, 05004], lr: 0.001000, loss: 1.3911
2022-07-10 06:16:54 - train: epoch 0067, iter [04400, 05004], lr: 0.001000, loss: 1.5602
2022-07-10 06:17:28 - train: epoch 0067, iter [04500, 05004], lr: 0.001000, loss: 1.4659
2022-07-10 06:18:01 - train: epoch 0067, iter [04600, 05004], lr: 0.001000, loss: 1.5799
2022-07-10 06:18:35 - train: epoch 0067, iter [04700, 05004], lr: 0.001000, loss: 1.6283
2022-07-10 06:19:07 - train: epoch 0067, iter [04800, 05004], lr: 0.001000, loss: 1.2329
2022-07-10 06:19:40 - train: epoch 0067, iter [04900, 05004], lr: 0.001000, loss: 1.4742
2022-07-10 06:20:12 - train: epoch 0067, iter [05000, 05004], lr: 0.001000, loss: 1.5598
2022-07-10 06:20:13 - train: epoch 067, train_loss: 1.5746
2022-07-10 06:21:27 - eval: epoch: 067, acc1: 66.474%, acc5: 87.296%, test_loss: 1.3783, per_image_load_time: 2.573ms, per_image_inference_time: 0.155ms
2022-07-10 06:21:27 - until epoch: 067, best_acc1: 66.474%
2022-07-10 06:21:27 - epoch 068 lr: 0.001000
2022-07-10 06:22:06 - train: epoch 0068, iter [00100, 05004], lr: 0.001000, loss: 1.6717
2022-07-10 06:22:39 - train: epoch 0068, iter [00200, 05004], lr: 0.001000, loss: 1.6761
2022-07-10 06:23:12 - train: epoch 0068, iter [00300, 05004], lr: 0.001000, loss: 1.6090
2022-07-10 06:23:44 - train: epoch 0068, iter [00400, 05004], lr: 0.001000, loss: 1.4682
2022-07-10 06:24:17 - train: epoch 0068, iter [00500, 05004], lr: 0.001000, loss: 1.4286
2022-07-10 06:24:50 - train: epoch 0068, iter [00600, 05004], lr: 0.001000, loss: 1.6389
2022-07-10 06:25:22 - train: epoch 0068, iter [00700, 05004], lr: 0.001000, loss: 1.6645
2022-07-10 06:25:56 - train: epoch 0068, iter [00800, 05004], lr: 0.001000, loss: 1.6248
2022-07-10 06:26:28 - train: epoch 0068, iter [00900, 05004], lr: 0.001000, loss: 1.3487
2022-07-10 06:27:02 - train: epoch 0068, iter [01000, 05004], lr: 0.001000, loss: 1.5991
2022-07-10 06:27:34 - train: epoch 0068, iter [01100, 05004], lr: 0.001000, loss: 1.7904
2022-07-10 06:28:07 - train: epoch 0068, iter [01200, 05004], lr: 0.001000, loss: 1.4300
2022-07-10 06:28:40 - train: epoch 0068, iter [01300, 05004], lr: 0.001000, loss: 1.6268
2022-07-10 06:29:13 - train: epoch 0068, iter [01400, 05004], lr: 0.001000, loss: 1.5932
2022-07-10 06:29:46 - train: epoch 0068, iter [01500, 05004], lr: 0.001000, loss: 1.6922
2022-07-10 06:30:19 - train: epoch 0068, iter [01600, 05004], lr: 0.001000, loss: 1.5572
2022-07-10 06:30:53 - train: epoch 0068, iter [01700, 05004], lr: 0.001000, loss: 1.5841
2022-07-10 06:31:25 - train: epoch 0068, iter [01800, 05004], lr: 0.001000, loss: 1.6254
2022-07-10 06:31:59 - train: epoch 0068, iter [01900, 05004], lr: 0.001000, loss: 1.4678
2022-07-10 06:32:30 - train: epoch 0068, iter [02000, 05004], lr: 0.001000, loss: 1.8634
2022-07-10 06:33:05 - train: epoch 0068, iter [02100, 05004], lr: 0.001000, loss: 1.5806
2022-07-10 06:33:38 - train: epoch 0068, iter [02200, 05004], lr: 0.001000, loss: 1.6484
2022-07-10 06:34:12 - train: epoch 0068, iter [02300, 05004], lr: 0.001000, loss: 1.5287
2022-07-10 06:34:44 - train: epoch 0068, iter [02400, 05004], lr: 0.001000, loss: 1.4599
2022-07-10 06:35:18 - train: epoch 0068, iter [02500, 05004], lr: 0.001000, loss: 1.5952
2022-07-10 06:35:51 - train: epoch 0068, iter [02600, 05004], lr: 0.001000, loss: 1.6116
2022-07-10 06:36:24 - train: epoch 0068, iter [02700, 05004], lr: 0.001000, loss: 1.5789
2022-07-10 06:36:57 - train: epoch 0068, iter [02800, 05004], lr: 0.001000, loss: 1.5788
2022-07-10 06:37:30 - train: epoch 0068, iter [02900, 05004], lr: 0.001000, loss: 1.7367
2022-07-10 06:38:03 - train: epoch 0068, iter [03000, 05004], lr: 0.001000, loss: 1.7304
2022-07-10 06:38:37 - train: epoch 0068, iter [03100, 05004], lr: 0.001000, loss: 1.3624
2022-07-10 06:39:10 - train: epoch 0068, iter [03200, 05004], lr: 0.001000, loss: 1.5909
2022-07-10 06:39:44 - train: epoch 0068, iter [03300, 05004], lr: 0.001000, loss: 1.5020
2022-07-10 06:40:16 - train: epoch 0068, iter [03400, 05004], lr: 0.001000, loss: 1.4002
2022-07-10 06:40:49 - train: epoch 0068, iter [03500, 05004], lr: 0.001000, loss: 1.8065
2022-07-10 06:41:22 - train: epoch 0068, iter [03600, 05004], lr: 0.001000, loss: 1.6191
2022-07-10 06:41:55 - train: epoch 0068, iter [03700, 05004], lr: 0.001000, loss: 1.5785
2022-07-10 06:42:29 - train: epoch 0068, iter [03800, 05004], lr: 0.001000, loss: 1.7631
2022-07-10 06:43:02 - train: epoch 0068, iter [03900, 05004], lr: 0.001000, loss: 1.4130
2022-07-10 06:43:35 - train: epoch 0068, iter [04000, 05004], lr: 0.001000, loss: 1.7264
2022-07-10 06:44:08 - train: epoch 0068, iter [04100, 05004], lr: 0.001000, loss: 1.4851
2022-07-10 06:44:41 - train: epoch 0068, iter [04200, 05004], lr: 0.001000, loss: 1.6945
2022-07-10 06:45:14 - train: epoch 0068, iter [04300, 05004], lr: 0.001000, loss: 1.4527
2022-07-10 06:45:48 - train: epoch 0068, iter [04400, 05004], lr: 0.001000, loss: 1.4931
2022-07-10 06:46:21 - train: epoch 0068, iter [04500, 05004], lr: 0.001000, loss: 1.5840
2022-07-10 06:46:55 - train: epoch 0068, iter [04600, 05004], lr: 0.001000, loss: 1.5104
2022-07-10 06:47:28 - train: epoch 0068, iter [04700, 05004], lr: 0.001000, loss: 1.7171
2022-07-10 06:48:02 - train: epoch 0068, iter [04800, 05004], lr: 0.001000, loss: 1.7929
2022-07-10 06:48:35 - train: epoch 0068, iter [04900, 05004], lr: 0.001000, loss: 1.6641
2022-07-10 06:49:07 - train: epoch 0068, iter [05000, 05004], lr: 0.001000, loss: 1.4552
2022-07-10 06:49:08 - train: epoch 068, train_loss: 1.5697
2022-07-10 06:50:20 - eval: epoch: 068, acc1: 66.526%, acc5: 87.406%, test_loss: 1.3683, per_image_load_time: 2.611ms, per_image_inference_time: 0.181ms
2022-07-10 06:50:20 - until epoch: 068, best_acc1: 66.526%
2022-07-10 06:50:20 - epoch 069 lr: 0.001000
2022-07-10 06:50:57 - train: epoch 0069, iter [00100, 05004], lr: 0.001000, loss: 1.7822
2022-07-10 06:51:31 - train: epoch 0069, iter [00200, 05004], lr: 0.001000, loss: 1.7631
2022-07-10 06:52:03 - train: epoch 0069, iter [00300, 05004], lr: 0.001000, loss: 1.5920
2022-07-10 06:52:36 - train: epoch 0069, iter [00400, 05004], lr: 0.001000, loss: 1.6961
2022-07-10 06:53:10 - train: epoch 0069, iter [00500, 05004], lr: 0.001000, loss: 1.7125
2022-07-10 06:53:42 - train: epoch 0069, iter [00600, 05004], lr: 0.001000, loss: 1.4193
2022-07-10 06:54:16 - train: epoch 0069, iter [00700, 05004], lr: 0.001000, loss: 1.6099
2022-07-10 06:54:48 - train: epoch 0069, iter [00800, 05004], lr: 0.001000, loss: 1.6820
2022-07-10 06:55:21 - train: epoch 0069, iter [00900, 05004], lr: 0.001000, loss: 1.3643
2022-07-10 06:55:54 - train: epoch 0069, iter [01000, 05004], lr: 0.001000, loss: 1.8390
2022-07-10 06:56:28 - train: epoch 0069, iter [01100, 05004], lr: 0.001000, loss: 1.4817
2022-07-10 06:57:00 - train: epoch 0069, iter [01200, 05004], lr: 0.001000, loss: 1.3372
2022-07-10 06:57:33 - train: epoch 0069, iter [01300, 05004], lr: 0.001000, loss: 1.7415
2022-07-10 06:58:07 - train: epoch 0069, iter [01400, 05004], lr: 0.001000, loss: 1.4580
2022-07-10 06:58:40 - train: epoch 0069, iter [01500, 05004], lr: 0.001000, loss: 1.4764
2022-07-10 06:59:14 - train: epoch 0069, iter [01600, 05004], lr: 0.001000, loss: 1.7550
2022-07-10 06:59:46 - train: epoch 0069, iter [01700, 05004], lr: 0.001000, loss: 1.4466
2022-07-10 07:00:19 - train: epoch 0069, iter [01800, 05004], lr: 0.001000, loss: 1.4473
2022-07-10 07:00:52 - train: epoch 0069, iter [01900, 05004], lr: 0.001000, loss: 1.4539
2022-07-10 07:01:26 - train: epoch 0069, iter [02000, 05004], lr: 0.001000, loss: 1.4960
2022-07-10 07:01:59 - train: epoch 0069, iter [02100, 05004], lr: 0.001000, loss: 1.5287
2022-07-10 07:02:31 - train: epoch 0069, iter [02200, 05004], lr: 0.001000, loss: 1.6325
2022-07-10 07:03:04 - train: epoch 0069, iter [02300, 05004], lr: 0.001000, loss: 1.3468
2022-07-10 07:03:37 - train: epoch 0069, iter [02400, 05004], lr: 0.001000, loss: 1.6073
2022-07-10 07:04:11 - train: epoch 0069, iter [02500, 05004], lr: 0.001000, loss: 1.5118
2022-07-10 07:04:44 - train: epoch 0069, iter [02600, 05004], lr: 0.001000, loss: 1.4750
2022-07-10 07:05:18 - train: epoch 0069, iter [02700, 05004], lr: 0.001000, loss: 1.5935
2022-07-10 07:05:51 - train: epoch 0069, iter [02800, 05004], lr: 0.001000, loss: 1.7022
2022-07-10 07:06:23 - train: epoch 0069, iter [02900, 05004], lr: 0.001000, loss: 1.5277
2022-07-10 07:06:57 - train: epoch 0069, iter [03000, 05004], lr: 0.001000, loss: 1.6046
2022-07-10 07:07:31 - train: epoch 0069, iter [03100, 05004], lr: 0.001000, loss: 1.6220
2022-07-10 07:08:04 - train: epoch 0069, iter [03200, 05004], lr: 0.001000, loss: 1.6090
2022-07-10 07:08:37 - train: epoch 0069, iter [03300, 05004], lr: 0.001000, loss: 1.5406
2022-07-10 07:09:10 - train: epoch 0069, iter [03400, 05004], lr: 0.001000, loss: 1.4007
2022-07-10 07:09:44 - train: epoch 0069, iter [03500, 05004], lr: 0.001000, loss: 1.4307
2022-07-10 07:10:16 - train: epoch 0069, iter [03600, 05004], lr: 0.001000, loss: 1.3855
2022-07-10 07:10:50 - train: epoch 0069, iter [03700, 05004], lr: 0.001000, loss: 1.5812
2022-07-10 07:11:23 - train: epoch 0069, iter [03800, 05004], lr: 0.001000, loss: 1.6866
2022-07-10 07:11:56 - train: epoch 0069, iter [03900, 05004], lr: 0.001000, loss: 1.8119
2022-07-10 07:12:30 - train: epoch 0069, iter [04000, 05004], lr: 0.001000, loss: 1.6708
2022-07-10 07:13:03 - train: epoch 0069, iter [04100, 05004], lr: 0.001000, loss: 1.4868
2022-07-10 07:13:36 - train: epoch 0069, iter [04200, 05004], lr: 0.001000, loss: 1.4773
2022-07-10 07:14:09 - train: epoch 0069, iter [04300, 05004], lr: 0.001000, loss: 1.5455
2022-07-10 07:14:43 - train: epoch 0069, iter [04400, 05004], lr: 0.001000, loss: 1.8102
2022-07-10 07:15:16 - train: epoch 0069, iter [04500, 05004], lr: 0.001000, loss: 1.6509
2022-07-10 07:15:49 - train: epoch 0069, iter [04600, 05004], lr: 0.001000, loss: 1.6209
2022-07-10 07:16:23 - train: epoch 0069, iter [04700, 05004], lr: 0.001000, loss: 1.7145
2022-07-10 07:16:56 - train: epoch 0069, iter [04800, 05004], lr: 0.001000, loss: 1.7824
2022-07-10 07:17:29 - train: epoch 0069, iter [04900, 05004], lr: 0.001000, loss: 1.4339
2022-07-10 07:18:00 - train: epoch 0069, iter [05000, 05004], lr: 0.001000, loss: 1.7148
2022-07-10 07:18:01 - train: epoch 069, train_loss: 1.5646
2022-07-10 07:19:15 - eval: epoch: 069, acc1: 66.590%, acc5: 87.326%, test_loss: 1.3708, per_image_load_time: 2.673ms, per_image_inference_time: 0.159ms
2022-07-10 07:19:15 - until epoch: 069, best_acc1: 66.590%
2022-07-10 07:19:15 - epoch 070 lr: 0.001000
2022-07-10 07:19:53 - train: epoch 0070, iter [00100, 05004], lr: 0.001000, loss: 1.6785
2022-07-10 07:20:25 - train: epoch 0070, iter [00200, 05004], lr: 0.001000, loss: 1.4675
2022-07-10 07:20:58 - train: epoch 0070, iter [00300, 05004], lr: 0.001000, loss: 1.7766
2022-07-10 07:21:30 - train: epoch 0070, iter [00400, 05004], lr: 0.001000, loss: 1.5551
2022-07-10 07:22:04 - train: epoch 0070, iter [00500, 05004], lr: 0.001000, loss: 1.5467
2022-07-10 07:22:36 - train: epoch 0070, iter [00600, 05004], lr: 0.001000, loss: 1.6138
2022-07-10 07:23:10 - train: epoch 0070, iter [00700, 05004], lr: 0.001000, loss: 1.5057
2022-07-10 07:23:42 - train: epoch 0070, iter [00800, 05004], lr: 0.001000, loss: 1.4689
2022-07-10 07:24:16 - train: epoch 0070, iter [00900, 05004], lr: 0.001000, loss: 1.5261
2022-07-10 07:24:49 - train: epoch 0070, iter [01000, 05004], lr: 0.001000, loss: 1.4960
2022-07-10 07:25:23 - train: epoch 0070, iter [01100, 05004], lr: 0.001000, loss: 1.8637
2022-07-10 07:25:56 - train: epoch 0070, iter [01200, 05004], lr: 0.001000, loss: 1.4014
2022-07-10 07:26:29 - train: epoch 0070, iter [01300, 05004], lr: 0.001000, loss: 1.4780
2022-07-10 07:27:01 - train: epoch 0070, iter [01400, 05004], lr: 0.001000, loss: 1.6570
2022-07-10 07:27:34 - train: epoch 0070, iter [01500, 05004], lr: 0.001000, loss: 1.7104
2022-07-10 07:28:07 - train: epoch 0070, iter [01600, 05004], lr: 0.001000, loss: 1.5598
2022-07-10 07:28:41 - train: epoch 0070, iter [01700, 05004], lr: 0.001000, loss: 1.7055
2022-07-10 07:29:14 - train: epoch 0070, iter [01800, 05004], lr: 0.001000, loss: 1.4788
2022-07-10 07:29:48 - train: epoch 0070, iter [01900, 05004], lr: 0.001000, loss: 1.4031
2022-07-10 07:30:20 - train: epoch 0070, iter [02000, 05004], lr: 0.001000, loss: 1.4628
2022-07-10 07:30:54 - train: epoch 0070, iter [02100, 05004], lr: 0.001000, loss: 1.4525
2022-07-10 07:31:27 - train: epoch 0070, iter [02200, 05004], lr: 0.001000, loss: 1.6702
2022-07-10 07:32:00 - train: epoch 0070, iter [02300, 05004], lr: 0.001000, loss: 1.5496
2022-07-10 07:32:33 - train: epoch 0070, iter [02400, 05004], lr: 0.001000, loss: 1.5956
2022-07-10 07:33:07 - train: epoch 0070, iter [02500, 05004], lr: 0.001000, loss: 1.3822
2022-07-10 07:33:39 - train: epoch 0070, iter [02600, 05004], lr: 0.001000, loss: 1.4863
2022-07-10 07:34:11 - train: epoch 0070, iter [02700, 05004], lr: 0.001000, loss: 1.5019
2022-07-10 07:34:45 - train: epoch 0070, iter [02800, 05004], lr: 0.001000, loss: 1.6982
2022-07-10 07:35:18 - train: epoch 0070, iter [02900, 05004], lr: 0.001000, loss: 1.5521
2022-07-10 07:35:52 - train: epoch 0070, iter [03000, 05004], lr: 0.001000, loss: 1.6180
2022-07-10 07:36:24 - train: epoch 0070, iter [03100, 05004], lr: 0.001000, loss: 1.6121
2022-07-10 07:36:58 - train: epoch 0070, iter [03200, 05004], lr: 0.001000, loss: 1.7237
2022-07-10 07:37:31 - train: epoch 0070, iter [03300, 05004], lr: 0.001000, loss: 1.4121
2022-07-10 07:38:04 - train: epoch 0070, iter [03400, 05004], lr: 0.001000, loss: 1.6931
2022-07-10 07:38:38 - train: epoch 0070, iter [03500, 05004], lr: 0.001000, loss: 1.5644
2022-07-10 07:39:10 - train: epoch 0070, iter [03600, 05004], lr: 0.001000, loss: 1.5494
2022-07-10 07:39:44 - train: epoch 0070, iter [03700, 05004], lr: 0.001000, loss: 1.6241
2022-07-10 07:40:16 - train: epoch 0070, iter [03800, 05004], lr: 0.001000, loss: 1.4549
2022-07-10 07:40:50 - train: epoch 0070, iter [03900, 05004], lr: 0.001000, loss: 1.3650
2022-07-10 07:41:23 - train: epoch 0070, iter [04000, 05004], lr: 0.001000, loss: 1.4689
2022-07-10 07:41:56 - train: epoch 0070, iter [04100, 05004], lr: 0.001000, loss: 1.4156
2022-07-10 07:42:29 - train: epoch 0070, iter [04200, 05004], lr: 0.001000, loss: 1.5636
2022-07-10 07:43:03 - train: epoch 0070, iter [04300, 05004], lr: 0.001000, loss: 1.6080
2022-07-10 07:43:37 - train: epoch 0070, iter [04400, 05004], lr: 0.001000, loss: 1.4506
2022-07-10 07:44:09 - train: epoch 0070, iter [04500, 05004], lr: 0.001000, loss: 1.6428
2022-07-10 07:44:43 - train: epoch 0070, iter [04600, 05004], lr: 0.001000, loss: 1.7039
2022-07-10 07:45:17 - train: epoch 0070, iter [04700, 05004], lr: 0.001000, loss: 1.5493
2022-07-10 07:45:49 - train: epoch 0070, iter [04800, 05004], lr: 0.001000, loss: 1.4130
2022-07-10 07:46:23 - train: epoch 0070, iter [04900, 05004], lr: 0.001000, loss: 1.5738
2022-07-10 07:46:55 - train: epoch 0070, iter [05000, 05004], lr: 0.001000, loss: 1.5489
2022-07-10 07:46:56 - train: epoch 070, train_loss: 1.5603
2022-07-10 07:48:09 - eval: epoch: 070, acc1: 66.624%, acc5: 87.360%, test_loss: 1.3652, per_image_load_time: 1.942ms, per_image_inference_time: 0.151ms
2022-07-10 07:48:09 - until epoch: 070, best_acc1: 66.624%
2022-07-10 07:48:09 - epoch 071 lr: 0.001000
2022-07-10 07:48:47 - train: epoch 0071, iter [00100, 05004], lr: 0.001000, loss: 1.5257
2022-07-10 07:49:20 - train: epoch 0071, iter [00200, 05004], lr: 0.001000, loss: 1.4666
2022-07-10 07:49:53 - train: epoch 0071, iter [00300, 05004], lr: 0.001000, loss: 1.6803
2022-07-10 07:50:25 - train: epoch 0071, iter [00400, 05004], lr: 0.001000, loss: 1.4736
2022-07-10 07:50:59 - train: epoch 0071, iter [00500, 05004], lr: 0.001000, loss: 1.5831
2022-07-10 07:51:31 - train: epoch 0071, iter [00600, 05004], lr: 0.001000, loss: 1.7337
2022-07-10 07:52:04 - train: epoch 0071, iter [00700, 05004], lr: 0.001000, loss: 1.4424
2022-07-10 07:52:36 - train: epoch 0071, iter [00800, 05004], lr: 0.001000, loss: 1.6343
2022-07-10 07:53:10 - train: epoch 0071, iter [00900, 05004], lr: 0.001000, loss: 1.5434
2022-07-10 07:53:42 - train: epoch 0071, iter [01000, 05004], lr: 0.001000, loss: 1.5978
2022-07-10 07:54:16 - train: epoch 0071, iter [01100, 05004], lr: 0.001000, loss: 1.7670
2022-07-10 07:54:49 - train: epoch 0071, iter [01200, 05004], lr: 0.001000, loss: 1.6875
2022-07-10 07:55:22 - train: epoch 0071, iter [01300, 05004], lr: 0.001000, loss: 1.5377
2022-07-10 07:55:55 - train: epoch 0071, iter [01400, 05004], lr: 0.001000, loss: 1.3935
2022-07-10 07:56:28 - train: epoch 0071, iter [01500, 05004], lr: 0.001000, loss: 1.5490
2022-07-10 07:57:02 - train: epoch 0071, iter [01600, 05004], lr: 0.001000, loss: 1.1904
2022-07-10 07:57:35 - train: epoch 0071, iter [01700, 05004], lr: 0.001000, loss: 1.5890
2022-07-10 07:58:08 - train: epoch 0071, iter [01800, 05004], lr: 0.001000, loss: 1.5367
2022-07-10 07:58:41 - train: epoch 0071, iter [01900, 05004], lr: 0.001000, loss: 1.5279
2022-07-10 07:59:15 - train: epoch 0071, iter [02000, 05004], lr: 0.001000, loss: 1.6841
2022-07-10 07:59:48 - train: epoch 0071, iter [02100, 05004], lr: 0.001000, loss: 1.4508
2022-07-10 08:00:21 - train: epoch 0071, iter [02200, 05004], lr: 0.001000, loss: 1.4027
2022-07-10 08:00:54 - train: epoch 0071, iter [02300, 05004], lr: 0.001000, loss: 1.4094
2022-07-10 08:01:27 - train: epoch 0071, iter [02400, 05004], lr: 0.001000, loss: 1.4796
2022-07-10 08:02:00 - train: epoch 0071, iter [02500, 05004], lr: 0.001000, loss: 1.5076
2022-07-10 08:02:34 - train: epoch 0071, iter [02600, 05004], lr: 0.001000, loss: 1.6054
2022-07-10 08:03:06 - train: epoch 0071, iter [02700, 05004], lr: 0.001000, loss: 1.5711
2022-07-10 08:03:40 - train: epoch 0071, iter [02800, 05004], lr: 0.001000, loss: 1.8169
2022-07-10 08:04:13 - train: epoch 0071, iter [02900, 05004], lr: 0.001000, loss: 1.4843
2022-07-10 08:04:46 - train: epoch 0071, iter [03000, 05004], lr: 0.001000, loss: 1.7702
2022-07-10 08:05:19 - train: epoch 0071, iter [03100, 05004], lr: 0.001000, loss: 1.5346
2022-07-10 08:05:53 - train: epoch 0071, iter [03200, 05004], lr: 0.001000, loss: 1.4319
2022-07-10 08:06:26 - train: epoch 0071, iter [03300, 05004], lr: 0.001000, loss: 1.4990
2022-07-10 08:06:59 - train: epoch 0071, iter [03400, 05004], lr: 0.001000, loss: 1.3308
2022-07-10 08:07:32 - train: epoch 0071, iter [03500, 05004], lr: 0.001000, loss: 1.5939
2022-07-10 08:08:06 - train: epoch 0071, iter [03600, 05004], lr: 0.001000, loss: 1.5796
2022-07-10 08:08:38 - train: epoch 0071, iter [03700, 05004], lr: 0.001000, loss: 1.6209
2022-07-10 08:09:12 - train: epoch 0071, iter [03800, 05004], lr: 0.001000, loss: 1.6176
2022-07-10 08:09:45 - train: epoch 0071, iter [03900, 05004], lr: 0.001000, loss: 1.7977
2022-07-10 08:10:19 - train: epoch 0071, iter [04000, 05004], lr: 0.001000, loss: 1.5267
2022-07-10 08:10:52 - train: epoch 0071, iter [04100, 05004], lr: 0.001000, loss: 1.4692
2022-07-10 08:11:26 - train: epoch 0071, iter [04200, 05004], lr: 0.001000, loss: 1.6965
2022-07-10 08:11:59 - train: epoch 0071, iter [04300, 05004], lr: 0.001000, loss: 1.3667
2022-07-10 08:12:33 - train: epoch 0071, iter [04400, 05004], lr: 0.001000, loss: 1.7030
2022-07-10 08:13:06 - train: epoch 0071, iter [04500, 05004], lr: 0.001000, loss: 1.5223
2022-07-10 08:13:39 - train: epoch 0071, iter [04600, 05004], lr: 0.001000, loss: 1.5865
2022-07-10 08:14:13 - train: epoch 0071, iter [04700, 05004], lr: 0.001000, loss: 1.5912
2022-07-10 08:14:46 - train: epoch 0071, iter [04800, 05004], lr: 0.001000, loss: 1.5616
2022-07-10 08:15:20 - train: epoch 0071, iter [04900, 05004], lr: 0.001000, loss: 1.5720
2022-07-10 08:15:51 - train: epoch 0071, iter [05000, 05004], lr: 0.001000, loss: 1.5689
2022-07-10 08:15:52 - train: epoch 071, train_loss: 1.5602
2022-07-10 08:17:05 - eval: epoch: 071, acc1: 66.786%, acc5: 87.462%, test_loss: 1.3614, per_image_load_time: 2.451ms, per_image_inference_time: 0.180ms
2022-07-10 08:17:05 - until epoch: 071, best_acc1: 66.786%
2022-07-10 08:17:05 - epoch 072 lr: 0.001000
2022-07-10 08:17:43 - train: epoch 0072, iter [00100, 05004], lr: 0.001000, loss: 1.7858
2022-07-10 08:18:16 - train: epoch 0072, iter [00200, 05004], lr: 0.001000, loss: 1.5458
2022-07-10 08:18:48 - train: epoch 0072, iter [00300, 05004], lr: 0.001000, loss: 1.5164
2022-07-10 08:19:22 - train: epoch 0072, iter [00400, 05004], lr: 0.001000, loss: 1.7899
2022-07-10 08:19:53 - train: epoch 0072, iter [00500, 05004], lr: 0.001000, loss: 1.3332
2022-07-10 08:20:27 - train: epoch 0072, iter [00600, 05004], lr: 0.001000, loss: 1.4438
2022-07-10 08:20:58 - train: epoch 0072, iter [00700, 05004], lr: 0.001000, loss: 1.4270
2022-07-10 08:21:32 - train: epoch 0072, iter [00800, 05004], lr: 0.001000, loss: 1.7489
2022-07-10 08:22:04 - train: epoch 0072, iter [00900, 05004], lr: 0.001000, loss: 1.3105
2022-07-10 08:22:37 - train: epoch 0072, iter [01000, 05004], lr: 0.001000, loss: 1.3668
2022-07-10 08:23:10 - train: epoch 0072, iter [01100, 05004], lr: 0.001000, loss: 1.6665
2022-07-10 08:23:42 - train: epoch 0072, iter [01200, 05004], lr: 0.001000, loss: 1.5080
2022-07-10 08:24:16 - train: epoch 0072, iter [01300, 05004], lr: 0.001000, loss: 1.5474
2022-07-10 08:24:49 - train: epoch 0072, iter [01400, 05004], lr: 0.001000, loss: 1.6316
2022-07-10 08:25:23 - train: epoch 0072, iter [01500, 05004], lr: 0.001000, loss: 1.6223
2022-07-10 08:25:56 - train: epoch 0072, iter [01600, 05004], lr: 0.001000, loss: 1.5844
2022-07-10 08:26:30 - train: epoch 0072, iter [01700, 05004], lr: 0.001000, loss: 1.2998
2022-07-10 08:27:02 - train: epoch 0072, iter [01800, 05004], lr: 0.001000, loss: 1.4046
2022-07-10 08:27:35 - train: epoch 0072, iter [01900, 05004], lr: 0.001000, loss: 1.4091
2022-07-10 08:28:08 - train: epoch 0072, iter [02000, 05004], lr: 0.001000, loss: 1.5407
2022-07-10 08:28:41 - train: epoch 0072, iter [02100, 05004], lr: 0.001000, loss: 1.8057
2022-07-10 08:29:14 - train: epoch 0072, iter [02200, 05004], lr: 0.001000, loss: 1.6299
2022-07-10 08:29:47 - train: epoch 0072, iter [02300, 05004], lr: 0.001000, loss: 1.5635
2022-07-10 08:30:20 - train: epoch 0072, iter [02400, 05004], lr: 0.001000, loss: 1.4851
2022-07-10 08:30:53 - train: epoch 0072, iter [02500, 05004], lr: 0.001000, loss: 1.4707
2022-07-10 08:31:26 - train: epoch 0072, iter [02600, 05004], lr: 0.001000, loss: 1.5709
2022-07-10 08:31:58 - train: epoch 0072, iter [02700, 05004], lr: 0.001000, loss: 1.6071
2022-07-10 08:32:33 - train: epoch 0072, iter [02800, 05004], lr: 0.001000, loss: 1.5104
2022-07-10 08:33:05 - train: epoch 0072, iter [02900, 05004], lr: 0.001000, loss: 1.3800
2022-07-10 08:33:39 - train: epoch 0072, iter [03000, 05004], lr: 0.001000, loss: 1.5385
2022-07-10 08:34:12 - train: epoch 0072, iter [03100, 05004], lr: 0.001000, loss: 1.5728
2022-07-10 08:34:45 - train: epoch 0072, iter [03200, 05004], lr: 0.001000, loss: 1.5693
2022-07-10 08:35:18 - train: epoch 0072, iter [03300, 05004], lr: 0.001000, loss: 1.4540
2022-07-10 08:35:51 - train: epoch 0072, iter [03400, 05004], lr: 0.001000, loss: 1.5148
2022-07-10 08:36:25 - train: epoch 0072, iter [03500, 05004], lr: 0.001000, loss: 1.4470
2022-07-10 08:36:58 - train: epoch 0072, iter [03600, 05004], lr: 0.001000, loss: 1.5482
2022-07-10 08:37:32 - train: epoch 0072, iter [03700, 05004], lr: 0.001000, loss: 1.7869
2022-07-10 08:38:04 - train: epoch 0072, iter [03800, 05004], lr: 0.001000, loss: 1.3882
2022-07-10 08:38:37 - train: epoch 0072, iter [03900, 05004], lr: 0.001000, loss: 1.4219
2022-07-10 08:39:11 - train: epoch 0072, iter [04000, 05004], lr: 0.001000, loss: 1.4957
2022-07-10 08:39:44 - train: epoch 0072, iter [04100, 05004], lr: 0.001000, loss: 1.6707
2022-07-10 08:40:17 - train: epoch 0072, iter [04200, 05004], lr: 0.001000, loss: 1.3512
2022-07-10 08:40:49 - train: epoch 0072, iter [04300, 05004], lr: 0.001000, loss: 1.5340
2022-07-10 08:41:23 - train: epoch 0072, iter [04400, 05004], lr: 0.001000, loss: 1.5649
2022-07-10 08:41:56 - train: epoch 0072, iter [04500, 05004], lr: 0.001000, loss: 1.5921
2022-07-10 08:42:30 - train: epoch 0072, iter [04600, 05004], lr: 0.001000, loss: 1.4195
2022-07-10 08:43:02 - train: epoch 0072, iter [04700, 05004], lr: 0.001000, loss: 1.5850
2022-07-10 08:43:36 - train: epoch 0072, iter [04800, 05004], lr: 0.001000, loss: 1.7510
2022-07-10 08:44:08 - train: epoch 0072, iter [04900, 05004], lr: 0.001000, loss: 1.6207
2022-07-10 08:44:40 - train: epoch 0072, iter [05000, 05004], lr: 0.001000, loss: 1.6957
2022-07-10 08:44:41 - train: epoch 072, train_loss: 1.5553
2022-07-10 08:45:53 - eval: epoch: 072, acc1: 66.806%, acc5: 87.428%, test_loss: 1.3591, per_image_load_time: 1.696ms, per_image_inference_time: 0.149ms
2022-07-10 08:45:53 - until epoch: 072, best_acc1: 66.806%
2022-07-10 08:45:53 - epoch 073 lr: 0.001000
2022-07-10 08:46:32 - train: epoch 0073, iter [00100, 05004], lr: 0.001000, loss: 1.8872
2022-07-10 08:47:04 - train: epoch 0073, iter [00200, 05004], lr: 0.001000, loss: 1.5525
2022-07-10 08:47:38 - train: epoch 0073, iter [00300, 05004], lr: 0.001000, loss: 1.6319
2022-07-10 08:48:10 - train: epoch 0073, iter [00400, 05004], lr: 0.001000, loss: 1.2952
2022-07-10 08:48:43 - train: epoch 0073, iter [00500, 05004], lr: 0.001000, loss: 1.5176
2022-07-10 08:49:15 - train: epoch 0073, iter [00600, 05004], lr: 0.001000, loss: 1.4105
2022-07-10 08:49:49 - train: epoch 0073, iter [00700, 05004], lr: 0.001000, loss: 1.6240
2022-07-10 08:50:20 - train: epoch 0073, iter [00800, 05004], lr: 0.001000, loss: 1.4122
2022-07-10 08:50:54 - train: epoch 0073, iter [00900, 05004], lr: 0.001000, loss: 1.6043
2022-07-10 08:51:26 - train: epoch 0073, iter [01000, 05004], lr: 0.001000, loss: 1.5801
2022-07-10 08:51:59 - train: epoch 0073, iter [01100, 05004], lr: 0.001000, loss: 1.7472
2022-07-10 08:52:32 - train: epoch 0073, iter [01200, 05004], lr: 0.001000, loss: 1.3874
2022-07-10 08:53:06 - train: epoch 0073, iter [01300, 05004], lr: 0.001000, loss: 1.6353
2022-07-10 08:53:38 - train: epoch 0073, iter [01400, 05004], lr: 0.001000, loss: 1.6618
2022-07-10 08:54:11 - train: epoch 0073, iter [01500, 05004], lr: 0.001000, loss: 1.4843
2022-07-10 08:54:43 - train: epoch 0073, iter [01600, 05004], lr: 0.001000, loss: 1.4966
2022-07-10 08:55:17 - train: epoch 0073, iter [01700, 05004], lr: 0.001000, loss: 1.6597
2022-07-10 08:55:50 - train: epoch 0073, iter [01800, 05004], lr: 0.001000, loss: 1.3983
2022-07-10 08:56:23 - train: epoch 0073, iter [01900, 05004], lr: 0.001000, loss: 1.4889
2022-07-10 08:56:56 - train: epoch 0073, iter [02000, 05004], lr: 0.001000, loss: 1.4936
2022-07-10 08:57:30 - train: epoch 0073, iter [02100, 05004], lr: 0.001000, loss: 1.4434
2022-07-10 08:58:03 - train: epoch 0073, iter [02200, 05004], lr: 0.001000, loss: 1.5898
2022-07-10 08:58:36 - train: epoch 0073, iter [02300, 05004], lr: 0.001000, loss: 1.3976
2022-07-10 08:59:10 - train: epoch 0073, iter [02400, 05004], lr: 0.001000, loss: 1.6642
2022-07-10 08:59:43 - train: epoch 0073, iter [02500, 05004], lr: 0.001000, loss: 1.5327
2022-07-10 09:00:16 - train: epoch 0073, iter [02600, 05004], lr: 0.001000, loss: 1.5634
2022-07-10 09:00:49 - train: epoch 0073, iter [02700, 05004], lr: 0.001000, loss: 1.4800
2022-07-10 09:01:23 - train: epoch 0073, iter [02800, 05004], lr: 0.001000, loss: 1.5483
2022-07-10 09:01:56 - train: epoch 0073, iter [02900, 05004], lr: 0.001000, loss: 1.7053
2022-07-10 09:02:29 - train: epoch 0073, iter [03000, 05004], lr: 0.001000, loss: 1.4176
2022-07-10 09:03:02 - train: epoch 0073, iter [03100, 05004], lr: 0.001000, loss: 1.4437
2022-07-10 09:03:36 - train: epoch 0073, iter [03200, 05004], lr: 0.001000, loss: 1.5428
2022-07-10 09:04:08 - train: epoch 0073, iter [03300, 05004], lr: 0.001000, loss: 1.6495
2022-07-10 09:04:42 - train: epoch 0073, iter [03400, 05004], lr: 0.001000, loss: 1.5862
2022-07-10 09:05:16 - train: epoch 0073, iter [03500, 05004], lr: 0.001000, loss: 1.6995
2022-07-10 09:05:49 - train: epoch 0073, iter [03600, 05004], lr: 0.001000, loss: 1.4637
2022-07-10 09:06:22 - train: epoch 0073, iter [03700, 05004], lr: 0.001000, loss: 1.5488
2022-07-10 09:06:55 - train: epoch 0073, iter [03800, 05004], lr: 0.001000, loss: 1.7984
2022-07-10 09:07:29 - train: epoch 0073, iter [03900, 05004], lr: 0.001000, loss: 1.6578
2022-07-10 09:08:02 - train: epoch 0073, iter [04000, 05004], lr: 0.001000, loss: 1.7502
2022-07-10 09:08:36 - train: epoch 0073, iter [04100, 05004], lr: 0.001000, loss: 1.4769
2022-07-10 09:09:09 - train: epoch 0073, iter [04200, 05004], lr: 0.001000, loss: 1.6851
2022-07-10 09:09:42 - train: epoch 0073, iter [04300, 05004], lr: 0.001000, loss: 1.5821
2022-07-10 09:10:15 - train: epoch 0073, iter [04400, 05004], lr: 0.001000, loss: 1.6483
2022-07-10 09:10:49 - train: epoch 0073, iter [04500, 05004], lr: 0.001000, loss: 1.5919
2022-07-10 09:11:22 - train: epoch 0073, iter [04600, 05004], lr: 0.001000, loss: 1.7286
2022-07-10 09:11:55 - train: epoch 0073, iter [04700, 05004], lr: 0.001000, loss: 1.5363
2022-07-10 09:12:28 - train: epoch 0073, iter [04800, 05004], lr: 0.001000, loss: 1.4302
2022-07-10 09:13:02 - train: epoch 0073, iter [04900, 05004], lr: 0.001000, loss: 1.4588
2022-07-10 09:13:34 - train: epoch 0073, iter [05000, 05004], lr: 0.001000, loss: 1.5792
2022-07-10 09:13:34 - train: epoch 073, train_loss: 1.5499
2022-07-10 09:14:48 - eval: epoch: 073, acc1: 66.824%, acc5: 87.434%, test_loss: 1.3609, per_image_load_time: 2.660ms, per_image_inference_time: 0.174ms
2022-07-10 09:14:48 - until epoch: 073, best_acc1: 66.824%
2022-07-10 09:14:48 - epoch 074 lr: 0.001000
2022-07-10 09:15:27 - train: epoch 0074, iter [00100, 05004], lr: 0.001000, loss: 1.5693
2022-07-10 09:15:59 - train: epoch 0074, iter [00200, 05004], lr: 0.001000, loss: 1.6462
2022-07-10 09:16:31 - train: epoch 0074, iter [00300, 05004], lr: 0.001000, loss: 1.5448
2022-07-10 09:17:04 - train: epoch 0074, iter [00400, 05004], lr: 0.001000, loss: 1.7532
2022-07-10 09:17:38 - train: epoch 0074, iter [00500, 05004], lr: 0.001000, loss: 1.4794
2022-07-10 09:18:10 - train: epoch 0074, iter [00600, 05004], lr: 0.001000, loss: 1.6540
2022-07-10 09:18:43 - train: epoch 0074, iter [00700, 05004], lr: 0.001000, loss: 1.5869
2022-07-10 09:19:15 - train: epoch 0074, iter [00800, 05004], lr: 0.001000, loss: 1.6342
2022-07-10 09:19:48 - train: epoch 0074, iter [00900, 05004], lr: 0.001000, loss: 1.4801
2022-07-10 09:20:22 - train: epoch 0074, iter [01000, 05004], lr: 0.001000, loss: 1.7792
2022-07-10 09:20:54 - train: epoch 0074, iter [01100, 05004], lr: 0.001000, loss: 1.6064
2022-07-10 09:21:27 - train: epoch 0074, iter [01200, 05004], lr: 0.001000, loss: 1.6444
2022-07-10 09:22:01 - train: epoch 0074, iter [01300, 05004], lr: 0.001000, loss: 1.5015
2022-07-10 09:22:34 - train: epoch 0074, iter [01400, 05004], lr: 0.001000, loss: 1.3852
2022-07-10 09:23:07 - train: epoch 0074, iter [01500, 05004], lr: 0.001000, loss: 1.6013
2022-07-10 09:23:39 - train: epoch 0074, iter [01600, 05004], lr: 0.001000, loss: 1.4863
2022-07-10 09:24:12 - train: epoch 0074, iter [01700, 05004], lr: 0.001000, loss: 1.6436
2022-07-10 09:24:45 - train: epoch 0074, iter [01800, 05004], lr: 0.001000, loss: 1.7284
2022-07-10 09:25:18 - train: epoch 0074, iter [01900, 05004], lr: 0.001000, loss: 1.6936
2022-07-10 09:25:51 - train: epoch 0074, iter [02000, 05004], lr: 0.001000, loss: 1.2255
2022-07-10 09:26:24 - train: epoch 0074, iter [02100, 05004], lr: 0.001000, loss: 1.3766
2022-07-10 09:26:58 - train: epoch 0074, iter [02200, 05004], lr: 0.001000, loss: 1.7161
2022-07-10 09:27:31 - train: epoch 0074, iter [02300, 05004], lr: 0.001000, loss: 1.6604
2022-07-10 09:28:04 - train: epoch 0074, iter [02400, 05004], lr: 0.001000, loss: 1.6446
2022-07-10 09:28:37 - train: epoch 0074, iter [02500, 05004], lr: 0.001000, loss: 1.4117
2022-07-10 09:29:10 - train: epoch 0074, iter [02600, 05004], lr: 0.001000, loss: 1.2482
2022-07-10 09:29:44 - train: epoch 0074, iter [02700, 05004], lr: 0.001000, loss: 1.4010
2022-07-10 09:30:16 - train: epoch 0074, iter [02800, 05004], lr: 0.001000, loss: 1.6194
2022-07-10 09:30:49 - train: epoch 0074, iter [02900, 05004], lr: 0.001000, loss: 1.6270
2022-07-10 09:31:22 - train: epoch 0074, iter [03000, 05004], lr: 0.001000, loss: 1.8053
2022-07-10 09:31:55 - train: epoch 0074, iter [03100, 05004], lr: 0.001000, loss: 1.6095
2022-07-10 09:32:29 - train: epoch 0074, iter [03200, 05004], lr: 0.001000, loss: 1.5127
2022-07-10 09:33:02 - train: epoch 0074, iter [03300, 05004], lr: 0.001000, loss: 1.6384
2022-07-10 09:33:35 - train: epoch 0074, iter [03400, 05004], lr: 0.001000, loss: 1.7212
2022-07-10 09:34:08 - train: epoch 0074, iter [03500, 05004], lr: 0.001000, loss: 1.4267
2022-07-10 09:34:41 - train: epoch 0074, iter [03600, 05004], lr: 0.001000, loss: 1.8768
2022-07-10 09:35:14 - train: epoch 0074, iter [03700, 05004], lr: 0.001000, loss: 1.5429
2022-07-10 09:35:48 - train: epoch 0074, iter [03800, 05004], lr: 0.001000, loss: 1.3235
2022-07-10 09:36:20 - train: epoch 0074, iter [03900, 05004], lr: 0.001000, loss: 1.4277
2022-07-10 09:36:54 - train: epoch 0074, iter [04000, 05004], lr: 0.001000, loss: 1.5424
2022-07-10 09:37:28 - train: epoch 0074, iter [04100, 05004], lr: 0.001000, loss: 1.5944
2022-07-10 09:38:00 - train: epoch 0074, iter [04200, 05004], lr: 0.001000, loss: 1.5896
2022-07-10 09:38:34 - train: epoch 0074, iter [04300, 05004], lr: 0.001000, loss: 1.5806
2022-07-10 09:39:07 - train: epoch 0074, iter [04400, 05004], lr: 0.001000, loss: 1.4607
2022-07-10 09:39:41 - train: epoch 0074, iter [04500, 05004], lr: 0.001000, loss: 1.6643
2022-07-10 09:40:13 - train: epoch 0074, iter [04600, 05004], lr: 0.001000, loss: 1.6604
2022-07-10 09:40:46 - train: epoch 0074, iter [04700, 05004], lr: 0.001000, loss: 1.5505
2022-07-10 09:41:19 - train: epoch 0074, iter [04800, 05004], lr: 0.001000, loss: 1.6464
2022-07-10 09:41:52 - train: epoch 0074, iter [04900, 05004], lr: 0.001000, loss: 1.8118
2022-07-10 09:42:24 - train: epoch 0074, iter [05000, 05004], lr: 0.001000, loss: 1.4879
2022-07-10 09:42:25 - train: epoch 074, train_loss: 1.5471
2022-07-10 09:43:38 - eval: epoch: 074, acc1: 67.008%, acc5: 87.418%, test_loss: 1.3580, per_image_load_time: 2.662ms, per_image_inference_time: 0.152ms
2022-07-10 09:43:39 - until epoch: 074, best_acc1: 67.008%
2022-07-10 09:43:39 - epoch 075 lr: 0.001000
2022-07-10 09:44:17 - train: epoch 0075, iter [00100, 05004], lr: 0.001000, loss: 1.8186
2022-07-10 09:44:50 - train: epoch 0075, iter [00200, 05004], lr: 0.001000, loss: 1.4647
2022-07-10 09:45:22 - train: epoch 0075, iter [00300, 05004], lr: 0.001000, loss: 1.6155
2022-07-10 09:45:55 - train: epoch 0075, iter [00400, 05004], lr: 0.001000, loss: 1.5281
2022-07-10 09:46:29 - train: epoch 0075, iter [00500, 05004], lr: 0.001000, loss: 1.7403
2022-07-10 09:47:01 - train: epoch 0075, iter [00600, 05004], lr: 0.001000, loss: 1.3448
2022-07-10 09:47:34 - train: epoch 0075, iter [00700, 05004], lr: 0.001000, loss: 1.6393
2022-07-10 09:48:08 - train: epoch 0075, iter [00800, 05004], lr: 0.001000, loss: 1.6087
2022-07-10 09:48:40 - train: epoch 0075, iter [00900, 05004], lr: 0.001000, loss: 1.5709
2022-07-10 09:49:12 - train: epoch 0075, iter [01000, 05004], lr: 0.001000, loss: 1.3789
2022-07-10 09:49:46 - train: epoch 0075, iter [01100, 05004], lr: 0.001000, loss: 1.6629
2022-07-10 09:50:19 - train: epoch 0075, iter [01200, 05004], lr: 0.001000, loss: 1.4610
2022-07-10 09:50:52 - train: epoch 0075, iter [01300, 05004], lr: 0.001000, loss: 1.6900
2022-07-10 09:51:24 - train: epoch 0075, iter [01400, 05004], lr: 0.001000, loss: 1.5724
2022-07-10 09:51:58 - train: epoch 0075, iter [01500, 05004], lr: 0.001000, loss: 1.5891
2022-07-10 09:52:30 - train: epoch 0075, iter [01600, 05004], lr: 0.001000, loss: 1.2110
2022-07-10 09:53:03 - train: epoch 0075, iter [01700, 05004], lr: 0.001000, loss: 1.7475
2022-07-10 09:53:37 - train: epoch 0075, iter [01800, 05004], lr: 0.001000, loss: 1.5780
2022-07-10 09:54:10 - train: epoch 0075, iter [01900, 05004], lr: 0.001000, loss: 1.5049
2022-07-10 09:54:43 - train: epoch 0075, iter [02000, 05004], lr: 0.001000, loss: 1.5305
2022-07-10 09:55:16 - train: epoch 0075, iter [02100, 05004], lr: 0.001000, loss: 1.4367
2022-07-10 09:55:49 - train: epoch 0075, iter [02200, 05004], lr: 0.001000, loss: 1.5256
2022-07-10 09:56:22 - train: epoch 0075, iter [02300, 05004], lr: 0.001000, loss: 1.4700
2022-07-10 09:56:55 - train: epoch 0075, iter [02400, 05004], lr: 0.001000, loss: 1.4742
2022-07-10 09:57:28 - train: epoch 0075, iter [02500, 05004], lr: 0.001000, loss: 1.6312
2022-07-10 09:58:00 - train: epoch 0075, iter [02600, 05004], lr: 0.001000, loss: 1.6502
2022-07-10 09:58:34 - train: epoch 0075, iter [02700, 05004], lr: 0.001000, loss: 1.3244
2022-07-10 09:59:07 - train: epoch 0075, iter [02800, 05004], lr: 0.001000, loss: 1.4291
2022-07-10 09:59:40 - train: epoch 0075, iter [02900, 05004], lr: 0.001000, loss: 1.6020
2022-07-10 10:00:13 - train: epoch 0075, iter [03000, 05004], lr: 0.001000, loss: 1.5445
2022-07-10 10:00:46 - train: epoch 0075, iter [03100, 05004], lr: 0.001000, loss: 1.5660
2022-07-10 10:01:19 - train: epoch 0075, iter [03200, 05004], lr: 0.001000, loss: 1.5648
2022-07-10 10:01:52 - train: epoch 0075, iter [03300, 05004], lr: 0.001000, loss: 1.5931
2022-07-10 10:02:26 - train: epoch 0075, iter [03400, 05004], lr: 0.001000, loss: 1.4175
2022-07-10 10:02:58 - train: epoch 0075, iter [03500, 05004], lr: 0.001000, loss: 1.4939
2022-07-10 10:03:32 - train: epoch 0075, iter [03600, 05004], lr: 0.001000, loss: 1.7234
2022-07-10 10:04:05 - train: epoch 0075, iter [03700, 05004], lr: 0.001000, loss: 1.5454
2022-07-10 10:04:38 - train: epoch 0075, iter [03800, 05004], lr: 0.001000, loss: 1.5675
2022-07-10 10:05:11 - train: epoch 0075, iter [03900, 05004], lr: 0.001000, loss: 1.6092
2022-07-10 10:05:44 - train: epoch 0075, iter [04000, 05004], lr: 0.001000, loss: 1.3351
2022-07-10 10:06:16 - train: epoch 0075, iter [04100, 05004], lr: 0.001000, loss: 1.4520
2022-07-10 10:06:50 - train: epoch 0075, iter [04200, 05004], lr: 0.001000, loss: 1.6364
2022-07-10 10:07:23 - train: epoch 0075, iter [04300, 05004], lr: 0.001000, loss: 1.6099
2022-07-10 10:07:56 - train: epoch 0075, iter [04400, 05004], lr: 0.001000, loss: 1.4302
2022-07-10 10:08:30 - train: epoch 0075, iter [04500, 05004], lr: 0.001000, loss: 1.5110
2022-07-10 10:09:02 - train: epoch 0075, iter [04600, 05004], lr: 0.001000, loss: 1.4673
2022-07-10 10:09:35 - train: epoch 0075, iter [04700, 05004], lr: 0.001000, loss: 1.7090
2022-07-10 10:10:09 - train: epoch 0075, iter [04800, 05004], lr: 0.001000, loss: 1.4034
2022-07-10 10:10:42 - train: epoch 0075, iter [04900, 05004], lr: 0.001000, loss: 1.4276
2022-07-10 10:11:13 - train: epoch 0075, iter [05000, 05004], lr: 0.001000, loss: 1.3693
2022-07-10 10:11:14 - train: epoch 075, train_loss: 1.5432
2022-07-10 10:12:28 - eval: epoch: 075, acc1: 67.022%, acc5: 87.536%, test_loss: 1.3516, per_image_load_time: 2.665ms, per_image_inference_time: 0.147ms
2022-07-10 10:12:28 - until epoch: 075, best_acc1: 67.022%
2022-07-10 10:12:28 - epoch 076 lr: 0.001000
2022-07-10 10:13:06 - train: epoch 0076, iter [00100, 05004], lr: 0.001000, loss: 1.5937
2022-07-10 10:13:39 - train: epoch 0076, iter [00200, 05004], lr: 0.001000, loss: 1.4382
2022-07-10 10:14:12 - train: epoch 0076, iter [00300, 05004], lr: 0.001000, loss: 1.6051
2022-07-10 10:14:45 - train: epoch 0076, iter [00400, 05004], lr: 0.001000, loss: 1.5047
2022-07-10 10:15:18 - train: epoch 0076, iter [00500, 05004], lr: 0.001000, loss: 1.5821
2022-07-10 10:15:52 - train: epoch 0076, iter [00600, 05004], lr: 0.001000, loss: 1.4126
2022-07-10 10:16:25 - train: epoch 0076, iter [00700, 05004], lr: 0.001000, loss: 1.4214
2022-07-10 10:16:58 - train: epoch 0076, iter [00800, 05004], lr: 0.001000, loss: 1.5039
2022-07-10 10:17:32 - train: epoch 0076, iter [00900, 05004], lr: 0.001000, loss: 1.3486
2022-07-10 10:18:05 - train: epoch 0076, iter [01000, 05004], lr: 0.001000, loss: 1.4146
2022-07-10 10:18:39 - train: epoch 0076, iter [01100, 05004], lr: 0.001000, loss: 1.4315
2022-07-10 10:19:11 - train: epoch 0076, iter [01200, 05004], lr: 0.001000, loss: 1.2603
2022-07-10 10:19:45 - train: epoch 0076, iter [01300, 05004], lr: 0.001000, loss: 1.5495
2022-07-10 10:20:18 - train: epoch 0076, iter [01400, 05004], lr: 0.001000, loss: 1.4781
2022-07-10 10:20:50 - train: epoch 0076, iter [01500, 05004], lr: 0.001000, loss: 1.6566
2022-07-10 10:21:24 - train: epoch 0076, iter [01600, 05004], lr: 0.001000, loss: 1.6340
2022-07-10 10:21:57 - train: epoch 0076, iter [01700, 05004], lr: 0.001000, loss: 1.5968
2022-07-10 10:22:29 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 1.4778
2022-07-10 10:23:03 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 1.4311
2022-07-10 10:23:36 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 1.4555
2022-07-10 10:24:09 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 1.7798
2022-07-10 10:24:42 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 1.5055
2022-07-10 10:25:15 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 1.4166
2022-07-10 10:25:48 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 1.7514
2022-07-10 10:26:20 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 1.4978
2022-07-10 10:26:54 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 1.7605
2022-07-10 10:27:27 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 1.3777
2022-07-10 10:28:00 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 1.5056
2022-07-10 10:28:32 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 1.6094
2022-07-10 10:29:07 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 1.2836
2022-07-10 10:29:39 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 1.6980
2022-07-10 10:30:13 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 1.5059
2022-07-10 10:30:46 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 1.4468
2022-07-10 10:31:19 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 1.5858
2022-07-10 10:31:53 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 1.4494
2022-07-10 10:32:26 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 1.3307
2022-07-10 10:32:59 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 1.5712
2022-07-10 10:33:33 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 1.4807
2022-07-10 10:34:05 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 1.4067
2022-07-10 10:34:38 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 1.3886
2022-07-10 10:35:11 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 1.5559
2022-07-10 10:35:44 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 1.5476
2022-07-10 10:36:17 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 1.4500
2022-07-10 10:36:51 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 1.5097
2022-07-10 10:37:24 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 1.4592
2022-07-10 10:37:57 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 1.4012
2022-07-10 10:38:30 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 1.5020
2022-07-10 10:39:03 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 1.4866
2022-07-10 10:39:37 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 1.5689
2022-07-10 10:40:08 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 1.6434
2022-07-10 10:40:08 - train: epoch 076, train_loss: 1.5426
2022-07-10 10:41:22 - eval: epoch: 076, acc1: 66.948%, acc5: 87.572%, test_loss: 1.3517, per_image_load_time: 2.661ms, per_image_inference_time: 0.154ms
2022-07-10 10:41:23 - until epoch: 076, best_acc1: 67.022%
2022-07-10 10:41:23 - epoch 077 lr: 0.001000
2022-07-10 10:42:01 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 1.6013
2022-07-10 10:42:33 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 1.4249
2022-07-10 10:43:07 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 1.4640
2022-07-10 10:43:39 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 1.4443
2022-07-10 10:44:12 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 1.1652
2022-07-10 10:44:44 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 1.4277
2022-07-10 10:45:17 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 1.5361
2022-07-10 10:45:50 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 1.5766
2022-07-10 10:46:23 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 1.6101
2022-07-10 10:46:56 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 1.4732
2022-07-10 10:47:30 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 1.7827
2022-07-10 10:48:02 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 1.6151
2022-07-10 10:48:37 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 1.3914
2022-07-10 10:49:09 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 1.5742
2022-07-10 10:49:43 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 1.4800
2022-07-10 10:50:14 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 1.5034
2022-07-10 10:50:48 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 1.8937
2022-07-10 10:51:21 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 1.4220
2022-07-10 10:51:53 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 1.3592
2022-07-10 10:52:27 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 1.5304
2022-07-10 10:53:00 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 1.5730
2022-07-10 10:53:33 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 1.3914
2022-07-10 10:54:07 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 1.7311
2022-07-10 10:54:40 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 1.4217
2022-07-10 10:55:13 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 1.6606
2022-07-10 10:55:46 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 1.3652
2022-07-10 10:56:19 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 1.6009
2022-07-10 10:56:52 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 1.4305
2022-07-10 10:57:25 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 1.6506
2022-07-10 10:57:58 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 1.5208
2022-07-10 10:58:32 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 1.3355
2022-07-10 10:59:06 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 1.6780
2022-07-10 10:59:39 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 1.3709
2022-07-10 11:00:11 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 1.7190
2022-07-10 11:00:45 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 1.4049
2022-07-10 11:01:19 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 1.3380
2022-07-10 11:01:51 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 1.4563
2022-07-10 11:02:24 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 1.5268
2022-07-10 11:02:58 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 1.5405
2022-07-10 11:03:31 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 1.5068
2022-07-10 11:04:04 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 1.6345
2022-07-10 11:04:37 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 1.4859
2022-07-10 11:05:09 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 1.5149
2022-07-10 11:05:43 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 1.3811
2022-07-10 11:06:16 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 1.6538
2022-07-10 11:06:49 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 1.5986
2022-07-10 11:07:22 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 1.5012
2022-07-10 11:07:56 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 1.5259
2022-07-10 11:08:28 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 1.7157
2022-07-10 11:09:00 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 1.5541
2022-07-10 11:09:01 - train: epoch 077, train_loss: 1.5438
2022-07-10 11:10:15 - eval: epoch: 077, acc1: 67.058%, acc5: 87.408%, test_loss: 1.3547, per_image_load_time: 2.686ms, per_image_inference_time: 0.167ms
2022-07-10 11:10:15 - until epoch: 077, best_acc1: 67.058%
2022-07-10 11:10:15 - epoch 078 lr: 0.001000
2022-07-10 11:10:53 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 1.4642
2022-07-10 11:11:26 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 1.5628
2022-07-10 11:11:58 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 1.5828
2022-07-10 11:12:33 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 1.6047
2022-07-10 11:13:04 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 1.2335
2022-07-10 11:13:38 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 1.4820
2022-07-10 11:14:10 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 1.5874
2022-07-10 11:14:44 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 1.6574
2022-07-10 11:15:15 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 1.5573
2022-07-10 11:15:49 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 1.5377
2022-07-10 11:16:21 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 1.4593
2022-07-10 11:16:55 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 1.5210
2022-07-10 11:17:27 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 1.4032
2022-07-10 11:18:00 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 1.3729
2022-07-10 11:18:34 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 1.5771
2022-07-10 11:19:06 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 1.5397
2022-07-10 11:19:40 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 1.5779
2022-07-10 11:20:13 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 1.6457
2022-07-10 11:20:46 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 1.3930
2022-07-10 11:21:19 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 1.5661
2022-07-10 11:21:53 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 1.5542
2022-07-10 11:22:27 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 1.5819
2022-07-10 11:22:59 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 1.4824
2022-07-10 11:23:32 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 1.5766
2022-07-10 11:24:05 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 1.4891
2022-07-10 11:24:39 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 1.6969
2022-07-10 11:25:13 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 1.5075
2022-07-10 11:25:44 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 1.6685
2022-07-10 11:26:18 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 1.5118
2022-07-10 11:26:51 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 1.6685
2022-07-10 11:27:24 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 1.6417
2022-07-10 11:27:57 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 1.5298
2022-07-10 11:28:30 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 1.6309
2022-07-10 11:29:04 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 1.5516
2022-07-10 11:29:36 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 1.6752
2022-07-10 11:30:10 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 1.6043
2022-07-10 11:30:43 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 1.5419
2022-07-10 11:31:16 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 1.5654
2022-07-10 11:31:48 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 1.5290
2022-07-10 11:32:21 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 1.5676
2022-07-10 11:32:55 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 1.4303
2022-07-10 11:33:28 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 1.7703
2022-07-10 11:34:01 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 1.6156
2022-07-10 11:34:35 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 1.4029
2022-07-10 11:35:07 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 1.5554
2022-07-10 11:35:41 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 1.3781
2022-07-10 11:36:14 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 1.6434
2022-07-10 11:36:47 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 1.8313
2022-07-10 11:37:20 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 1.6405
2022-07-10 11:37:51 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 1.6608
2022-07-10 11:37:52 - train: epoch 078, train_loss: 1.5389
2022-07-10 11:39:06 - eval: epoch: 078, acc1: 66.914%, acc5: 87.510%, test_loss: 1.3539, per_image_load_time: 2.671ms, per_image_inference_time: 0.162ms
2022-07-10 11:39:06 - until epoch: 078, best_acc1: 67.058%
2022-07-10 11:39:06 - epoch 079 lr: 0.001000
2022-07-10 11:39:44 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 1.4791
2022-07-10 11:40:17 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 1.5484
2022-07-10 11:40:50 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 1.6173
2022-07-10 11:41:22 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 1.6618
2022-07-10 11:41:56 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 1.4491
2022-07-10 11:42:28 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 1.5109
2022-07-10 11:43:03 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 1.3994
2022-07-10 11:43:34 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 1.7072
2022-07-10 11:44:08 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 1.7080
2022-07-10 11:44:41 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 1.5234
2022-07-10 11:45:13 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 1.7674
2022-07-10 11:45:47 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 1.5377
2022-07-10 11:46:20 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 1.3515
2022-07-10 11:46:53 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 1.6828
2022-07-10 11:47:26 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 1.6103
2022-07-10 11:47:59 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 1.3735
2022-07-10 11:48:33 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 1.5030
2022-07-10 11:49:05 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 1.3994
2022-07-10 11:49:39 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 1.3800
2022-07-10 11:50:11 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 1.7937
2022-07-10 11:50:44 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 1.4452
2022-07-10 11:51:18 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 1.4629
2022-07-10 11:51:52 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 1.4485
2022-07-10 11:52:24 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 1.5884
2022-07-10 11:52:57 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 1.4663
2022-07-10 11:53:30 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 1.5580
2022-07-10 11:54:04 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 1.2282
2022-07-10 11:54:36 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 1.5488
2022-07-10 11:55:10 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 1.6139
2022-07-10 11:55:43 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 1.6814
2022-07-10 11:56:16 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 1.3929
2022-07-10 11:56:49 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 1.7469
2022-07-10 11:57:22 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 1.5550
2022-07-10 11:57:56 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 1.5584
2022-07-10 11:58:28 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 1.5515
2022-07-10 11:59:02 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 1.3584
2022-07-10 11:59:35 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 1.4291
2022-07-10 12:00:08 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 1.7118
2022-07-10 12:00:41 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 1.3511
2022-07-10 12:01:14 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 1.4227
2022-07-10 12:01:48 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 1.6019
2022-07-10 12:02:20 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 1.4249
2022-07-10 12:02:55 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 1.3129
2022-07-10 12:03:27 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 1.5642
2022-07-10 12:04:01 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 1.6926
2022-07-10 12:04:34 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 1.6805
2022-07-10 12:05:08 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 1.3953
2022-07-10 12:05:40 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 1.4253
2022-07-10 12:06:14 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 1.5345
2022-07-10 12:06:46 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 1.3973
2022-07-10 12:06:46 - train: epoch 079, train_loss: 1.5353
2022-07-10 12:08:01 - eval: epoch: 079, acc1: 66.908%, acc5: 87.482%, test_loss: 1.3568, per_image_load_time: 2.677ms, per_image_inference_time: 0.159ms
2022-07-10 12:08:01 - until epoch: 079, best_acc1: 67.058%
2022-07-10 12:08:01 - epoch 080 lr: 0.001000
2022-07-10 12:08:39 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 1.4248
2022-07-10 12:09:13 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 1.5695
2022-07-10 12:09:45 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 1.4951
2022-07-10 12:10:18 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 1.3535
2022-07-10 12:10:52 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 1.3667
2022-07-10 12:11:24 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 1.3004
2022-07-10 12:11:57 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 1.5648
2022-07-10 12:12:30 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 1.2513
2022-07-10 12:13:03 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 1.5955
2022-07-10 12:13:36 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 1.4827
2022-07-10 12:14:09 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 1.6448
2022-07-10 12:14:43 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 1.6002
2022-07-10 12:15:16 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 1.3482
2022-07-10 12:15:49 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 1.4111
2022-07-10 12:16:21 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 1.4326
2022-07-10 12:16:55 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 1.3819
2022-07-10 12:17:29 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 1.6571
2022-07-10 12:18:01 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 1.5355
2022-07-10 12:18:34 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 1.7334
2022-07-10 12:19:08 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 1.4217
2022-07-10 12:19:40 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 1.5998
2022-07-10 12:20:14 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 1.5632
2022-07-10 12:20:47 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 1.5089
2022-07-10 12:21:20 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 1.7891
2022-07-10 12:21:53 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 1.4185
2022-07-10 12:22:27 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 1.6969
2022-07-10 12:23:00 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 1.3834
2022-07-10 12:23:34 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 1.5201
2022-07-10 12:24:07 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 1.5939
2022-07-10 12:24:41 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 1.7322
2022-07-10 12:25:13 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 1.6875
2022-07-10 12:25:47 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 1.3666
2022-07-10 12:26:20 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 1.5680
2022-07-10 12:26:53 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 1.6057
2022-07-10 12:27:26 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 1.4464
2022-07-10 12:28:00 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 1.6287
2022-07-10 12:28:32 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 1.4367
2022-07-10 12:29:05 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 1.7872
2022-07-10 12:29:39 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 1.3830
2022-07-10 12:30:12 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 1.6321
2022-07-10 12:30:46 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 1.8273
2022-07-10 12:31:18 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 1.3548
2022-07-10 12:31:52 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 1.8631
2022-07-10 12:32:24 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 1.6399
2022-07-10 12:32:58 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 1.5736
2022-07-10 12:33:31 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 1.4161
2022-07-10 12:34:04 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 1.5862
2022-07-10 12:34:38 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 1.7104
2022-07-10 12:35:11 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 1.8159
2022-07-10 12:35:42 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 1.4363
2022-07-10 12:35:43 - train: epoch 080, train_loss: 1.5343
2022-07-10 12:36:57 - eval: epoch: 080, acc1: 67.008%, acc5: 87.586%, test_loss: 1.3509, per_image_load_time: 2.696ms, per_image_inference_time: 0.157ms
2022-07-10 12:36:57 - until epoch: 080, best_acc1: 67.058%
2022-07-10 12:36:57 - epoch 081 lr: 0.001000
2022-07-10 12:37:35 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 1.4893
2022-07-10 12:38:07 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 1.3612
2022-07-10 12:38:41 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 1.6657
2022-07-10 12:39:14 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 1.7280
2022-07-10 12:39:47 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 1.8339
2022-07-10 12:40:20 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 1.4129
2022-07-10 12:40:53 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 1.5593
2022-07-10 12:41:26 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 1.7430
2022-07-10 12:41:59 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 1.7692
2022-07-10 12:42:33 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 1.6057
2022-07-10 12:43:05 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 1.5288
2022-07-10 12:43:38 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 1.4100
2022-07-10 12:44:12 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 1.4104
2022-07-10 12:44:44 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 1.2431
2022-07-10 12:45:17 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 1.5280
2022-07-10 12:45:49 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 1.5159
2022-07-10 12:46:24 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 1.4004
2022-07-10 12:46:57 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 1.4741
2022-07-10 12:47:31 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 1.3720
2022-07-10 12:48:04 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 1.5776
2022-07-10 12:48:37 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 1.6099
2022-07-10 12:49:09 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 1.3826
2022-07-10 12:49:43 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 1.3699
2022-07-10 12:50:16 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 1.5504
2022-07-10 12:50:49 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 1.6244
2022-07-10 12:51:21 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 1.6937
2022-07-10 12:51:55 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 1.6124
2022-07-10 12:52:28 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 1.4336
2022-07-10 12:53:02 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 1.3954
2022-07-10 12:53:34 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 1.6422
2022-07-10 12:54:07 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 1.3435
2022-07-10 12:54:40 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 1.5459
2022-07-10 12:55:14 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 1.5797
2022-07-10 12:55:47 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 1.7236
2022-07-10 12:56:21 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 1.5834
2022-07-10 12:56:54 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 1.3205
2022-07-10 12:57:28 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 1.4451
2022-07-10 12:58:01 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 1.4306
2022-07-10 12:58:34 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 1.6879
2022-07-10 12:59:07 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 1.3282
2022-07-10 12:59:40 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 1.3991
2022-07-10 13:00:14 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 1.6332
2022-07-10 13:00:48 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 1.4710
2022-07-10 13:01:21 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 1.5749
2022-07-10 13:01:53 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 1.4981
2022-07-10 13:02:26 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 1.5195
2022-07-10 13:02:59 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 1.6153
2022-07-10 13:03:33 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 1.5263
2022-07-10 13:04:05 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 1.6120
2022-07-10 13:04:37 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 1.3846
2022-07-10 13:04:38 - train: epoch 081, train_loss: 1.5327
2022-07-10 13:05:52 - eval: epoch: 081, acc1: 66.908%, acc5: 87.530%, test_loss: 1.3533, per_image_load_time: 2.696ms, per_image_inference_time: 0.143ms
2022-07-10 13:05:52 - until epoch: 081, best_acc1: 67.058%
2022-07-10 13:05:52 - epoch 082 lr: 0.001000
2022-07-10 13:06:30 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 1.2590
2022-07-10 13:07:04 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 1.4874
2022-07-10 13:07:36 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 1.5678
2022-07-10 13:08:09 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 1.5217
2022-07-10 13:08:41 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 1.7543
2022-07-10 13:09:15 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 1.5225
2022-07-10 13:09:48 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 1.7357
2022-07-10 13:10:20 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 1.5951
2022-07-10 13:10:54 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 1.5262
2022-07-10 13:11:27 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 1.3620
2022-07-10 13:11:59 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 1.4922
2022-07-10 13:12:32 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 1.6063
2022-07-10 13:13:06 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 1.6724
2022-07-10 13:13:39 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 1.3692
2022-07-10 13:14:11 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 1.5499
2022-07-10 13:14:44 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 1.4685
2022-07-10 13:15:18 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 1.3285
2022-07-10 13:15:51 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 1.3409
2022-07-10 13:16:25 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 1.6534
2022-07-10 13:16:58 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 1.4201
2022-07-10 13:17:31 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 1.6121
2022-07-10 13:18:04 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 1.6194
2022-07-10 13:18:38 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 1.3997
2022-07-10 13:19:10 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 1.7213
2022-07-10 13:19:44 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 1.4689
2022-07-10 13:20:17 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 1.4568
2022-07-10 13:20:50 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 1.4536
2022-07-10 13:21:24 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 1.3267
2022-07-10 13:21:58 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 1.2589
2022-07-10 13:22:31 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 1.5258
2022-07-10 13:23:05 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 1.7322
2022-07-10 13:23:37 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 1.5742
2022-07-10 13:24:11 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 1.5492
2022-07-10 13:24:44 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 1.5633
2022-07-10 13:25:18 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 1.5011
2022-07-10 13:25:50 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 1.6094
2022-07-10 13:26:24 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 1.3190
2022-07-10 13:26:57 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 1.6886
2022-07-10 13:27:30 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 1.6244
2022-07-10 13:28:03 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 1.7580
2022-07-10 13:28:36 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 1.7072
2022-07-10 13:29:10 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 1.7061
2022-07-10 13:29:43 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 1.2746
2022-07-10 13:30:16 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 1.4500
2022-07-10 13:30:49 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 1.4419
2022-07-10 13:31:22 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 1.6033
2022-07-10 13:31:55 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 1.4515
2022-07-10 13:32:28 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 1.5133
2022-07-10 13:33:02 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 1.6187
2022-07-10 13:33:34 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 1.5527
2022-07-10 13:33:35 - train: epoch 082, train_loss: 1.5296
2022-07-10 13:34:49 - eval: epoch: 082, acc1: 67.064%, acc5: 87.552%, test_loss: 1.3501, per_image_load_time: 2.718ms, per_image_inference_time: 0.132ms
2022-07-10 13:34:49 - until epoch: 082, best_acc1: 67.064%
2022-07-10 13:34:49 - epoch 083 lr: 0.001000
2022-07-10 13:35:26 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 1.2381
2022-07-10 13:35:59 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 1.4158
2022-07-10 13:36:31 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 1.6994
2022-07-10 13:37:04 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 1.5844
2022-07-10 13:37:38 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 1.6012
2022-07-10 13:38:10 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 1.4301
2022-07-10 13:38:43 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 1.5548
2022-07-10 13:39:17 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 1.4307
2022-07-10 13:39:49 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 1.5507
2022-07-10 13:40:22 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 1.8617
2022-07-10 13:40:55 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 1.7616
2022-07-10 13:41:28 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 1.6341
2022-07-10 13:42:01 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 1.5666
2022-07-10 13:42:34 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 1.6462
2022-07-10 13:43:07 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 1.4828
2022-07-10 13:43:41 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 1.6062
2022-07-10 13:44:14 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 1.4944
2022-07-10 13:44:46 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 1.7288
2022-07-10 13:45:19 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 1.5834
2022-07-10 13:45:53 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 1.3355
2022-07-10 13:46:26 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 1.3932
2022-07-10 13:46:59 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 1.4107
2022-07-10 13:47:31 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 1.5217
2022-07-10 13:48:06 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 1.4942
2022-07-10 13:48:38 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 1.4232
2022-07-10 13:49:11 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 1.4918
2022-07-10 13:49:45 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 1.4872
2022-07-10 13:50:18 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 1.4786
2022-07-10 13:50:51 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 1.6361
2022-07-10 13:51:25 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 1.5439
2022-07-10 13:51:58 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 1.4651
2022-07-10 13:52:31 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 1.3824
2022-07-10 13:53:05 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 1.5999
2022-07-10 13:53:38 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 1.4178
2022-07-10 13:54:10 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 1.4605
2022-07-10 13:54:43 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 1.5784
2022-07-10 13:55:17 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 1.3802
2022-07-10 13:55:50 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 1.7076
2022-07-10 13:56:23 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 1.6902
2022-07-10 13:56:56 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 1.7225
2022-07-10 13:57:30 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 1.4916
2022-07-10 13:58:02 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 1.7126
2022-07-10 13:58:36 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 1.4494
2022-07-10 13:59:08 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 1.4906
2022-07-10 13:59:43 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 1.3689
2022-07-10 14:00:15 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 1.5376
2022-07-10 14:00:50 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 1.7678
2022-07-10 14:01:22 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 1.6417
2022-07-10 14:01:56 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 1.5072
2022-07-10 14:02:26 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 1.5742
2022-07-10 14:02:27 - train: epoch 083, train_loss: 1.5287
2022-07-10 14:03:41 - eval: epoch: 083, acc1: 67.118%, acc5: 87.470%, test_loss: 1.3523, per_image_load_time: 2.683ms, per_image_inference_time: 0.155ms
2022-07-10 14:03:41 - until epoch: 083, best_acc1: 67.118%
2022-07-10 14:03:41 - epoch 084 lr: 0.001000
2022-07-10 14:04:20 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 1.4929
2022-07-10 14:04:53 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 1.6509
2022-07-10 14:05:26 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 1.3609
2022-07-10 14:05:59 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 1.6436
2022-07-10 14:06:31 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 1.6523
2022-07-10 14:07:05 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 1.6862
2022-07-10 14:07:37 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 1.6179
2022-07-10 14:08:10 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 1.6702
2022-07-10 14:08:44 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 1.5589
2022-07-10 14:09:17 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 1.5419
2022-07-10 14:09:50 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 1.5209
2022-07-10 14:10:23 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 1.6592
2022-07-10 14:10:56 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 1.6585
2022-07-10 14:11:29 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 1.3705
2022-07-10 14:12:03 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 1.6249
2022-07-10 14:12:35 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 1.4398
2022-07-10 14:13:09 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 1.8055
2022-07-10 14:13:42 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 1.6258
2022-07-10 14:14:16 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 1.5810
2022-07-10 14:14:49 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 1.4459
2022-07-10 14:15:21 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 1.3669
2022-07-10 14:15:55 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 1.4926
2022-07-10 14:16:29 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 1.4149
2022-07-10 14:17:01 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 1.5352
2022-07-10 14:17:35 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 1.8045
2022-07-10 14:18:08 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 1.4962
2022-07-10 14:18:41 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 1.3922
2022-07-10 14:19:14 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 1.5148
2022-07-10 14:19:47 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 1.5440
2022-07-10 14:20:21 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 1.6387
2022-07-10 14:20:54 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 1.4664
2022-07-10 14:21:28 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 1.5618
2022-07-10 14:22:00 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 1.6504
2022-07-10 14:22:34 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 1.5180
2022-07-10 14:23:07 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 1.2804
2022-07-10 14:23:40 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 1.5085
2022-07-10 14:24:13 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 1.8791
2022-07-10 14:24:48 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 1.5009
2022-07-10 14:25:20 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 1.6071
2022-07-10 14:25:53 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 1.4758
2022-07-10 14:26:26 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 1.5715
2022-07-10 14:26:59 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 1.4518
2022-07-10 14:27:33 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 1.6894
2022-07-10 14:28:06 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 1.9620
2022-07-10 14:28:39 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 1.4129
2022-07-10 14:29:13 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 1.4590
2022-07-10 14:29:45 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 1.4245
2022-07-10 14:30:19 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 1.3603
2022-07-10 14:30:52 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 1.4040
2022-07-10 14:31:24 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 1.4648
2022-07-10 14:31:25 - train: epoch 084, train_loss: 1.5271
2022-07-10 14:32:39 - eval: epoch: 084, acc1: 67.130%, acc5: 87.598%, test_loss: 1.3476, per_image_load_time: 2.684ms, per_image_inference_time: 0.167ms
2022-07-10 14:32:39 - until epoch: 084, best_acc1: 67.130%
2022-07-10 14:32:39 - epoch 085 lr: 0.001000
2022-07-10 14:33:17 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 1.4775
2022-07-10 14:33:49 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 1.4522
2022-07-10 14:34:22 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 1.6342
2022-07-10 14:34:57 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 1.4443
2022-07-10 14:35:28 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 1.6795
2022-07-10 14:36:01 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 1.2945
2022-07-10 14:36:34 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 1.4430
2022-07-10 14:37:08 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 1.3047
2022-07-10 14:37:39 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 1.5495
2022-07-10 14:38:12 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 1.4770
2022-07-10 14:38:45 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 1.6007
2022-07-10 14:39:18 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 1.5403
2022-07-10 14:39:53 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 1.5311
2022-07-10 14:40:25 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 1.3846
2022-07-10 14:40:58 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 1.4544
2022-07-10 14:41:32 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 1.5482
2022-07-10 14:42:04 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 1.9875
2022-07-10 14:42:37 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 1.3430
2022-07-10 14:43:10 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 1.3682
2022-07-10 14:43:43 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 1.3096
2022-07-10 14:44:16 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 1.2883
2022-07-10 14:44:49 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 1.5975
2022-07-10 14:45:22 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 1.4476
2022-07-10 14:45:55 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 1.7339
2022-07-10 14:46:28 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 1.8843
2022-07-10 14:47:01 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 1.5530
2022-07-10 14:47:35 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 1.4315
2022-07-10 14:48:08 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 1.6869
2022-07-10 14:48:41 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 1.6073
2022-07-10 14:49:15 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 1.6253
2022-07-10 14:49:48 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 1.5687
2022-07-10 14:50:21 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 1.7398
2022-07-10 14:50:54 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 1.5480
2022-07-10 14:51:26 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 1.6053
2022-07-10 14:52:00 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 1.6258
2022-07-10 14:52:33 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 1.6058
2022-07-10 14:53:06 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 1.2238
2022-07-10 14:53:39 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 1.4673
2022-07-10 14:54:13 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 1.4218
2022-07-10 14:54:46 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 1.6486
2022-07-10 14:55:19 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 1.6371
2022-07-10 14:55:52 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 1.6868
2022-07-10 14:56:25 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 1.5810
2022-07-10 14:56:59 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 1.5563
2022-07-10 14:57:31 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 1.5642
2022-07-10 14:58:04 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 1.5078
2022-07-10 14:58:37 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 1.8030
2022-07-10 14:59:11 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 1.3817
2022-07-10 14:59:44 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 1.5023
2022-07-10 15:00:16 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 1.4913
2022-07-10 15:00:17 - train: epoch 085, train_loss: 1.5255
2022-07-10 15:01:30 - eval: epoch: 085, acc1: 67.118%, acc5: 87.578%, test_loss: 1.3500, per_image_load_time: 2.671ms, per_image_inference_time: 0.167ms
2022-07-10 15:01:30 - until epoch: 085, best_acc1: 67.130%
2022-07-10 15:01:30 - epoch 086 lr: 0.001000
2022-07-10 15:02:08 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 1.6437
2022-07-10 15:02:42 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 1.4769
2022-07-10 15:03:15 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 1.7013
2022-07-10 15:03:47 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 1.6063
2022-07-10 15:04:21 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 1.5537
2022-07-10 15:04:53 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 1.5302
2022-07-10 15:05:27 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 1.3278
2022-07-10 15:05:59 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 1.7174
2022-07-10 15:06:33 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 1.4320
2022-07-10 15:07:05 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 1.5073
2022-07-10 15:07:39 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 1.6019
2022-07-10 15:08:12 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 1.5538
2022-07-10 15:08:45 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 1.7968
2022-07-10 15:09:18 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 1.5586
2022-07-10 15:09:52 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 1.3377
2022-07-10 15:10:25 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 1.4526
2022-07-10 15:10:57 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 1.5810
2022-07-10 15:11:31 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 1.6473
2022-07-10 15:12:04 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 1.5514
2022-07-10 15:12:37 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 1.4716
2022-07-10 15:13:10 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 1.3039
2022-07-10 15:13:43 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 1.5865
2022-07-10 15:14:15 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 1.4110
2022-07-10 15:14:49 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 1.3603
2022-07-10 15:15:22 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 1.4449
2022-07-10 15:15:56 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 1.6302
2022-07-10 15:16:29 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 1.5476
2022-07-10 15:17:03 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 1.6156
2022-07-10 15:17:36 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 1.2827
2022-07-10 15:18:09 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 1.2902
2022-07-10 15:18:43 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 1.7001
2022-07-10 15:19:17 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 1.6755
2022-07-10 15:19:50 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 1.4034
2022-07-10 15:20:23 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 1.7298
2022-07-10 15:20:56 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 1.5538
2022-07-10 15:21:30 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 1.4857
2022-07-10 15:22:05 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 1.6377
2022-07-10 15:22:37 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 1.4695
2022-07-10 15:23:10 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 1.3237
2022-07-10 15:23:43 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 1.6268
2022-07-10 15:24:17 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 1.4688
2022-07-10 15:24:50 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 1.7271
2022-07-10 15:25:24 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 1.6757
2022-07-10 15:25:57 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 1.3981
2022-07-10 15:26:30 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 1.4235
2022-07-10 15:27:03 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 1.7146
2022-07-10 15:27:37 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 1.4644
2022-07-10 15:28:10 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 1.4979
2022-07-10 15:28:44 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 1.5893
2022-07-10 15:29:15 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 1.4861
2022-07-10 15:29:15 - train: epoch 086, train_loss: 1.5224
2022-07-10 15:30:29 - eval: epoch: 086, acc1: 67.012%, acc5: 87.622%, test_loss: 1.3522, per_image_load_time: 2.663ms, per_image_inference_time: 0.166ms
2022-07-10 15:30:29 - until epoch: 086, best_acc1: 67.130%
2022-07-10 15:30:29 - epoch 087 lr: 0.001000
2022-07-10 15:31:07 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 1.5773
2022-07-10 15:31:40 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 1.4671
2022-07-10 15:32:13 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 1.5069
2022-07-10 15:32:46 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 1.7027
2022-07-10 15:33:19 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 1.2473
2022-07-10 15:33:53 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 1.5802
2022-07-10 15:34:25 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 1.4163
2022-07-10 15:34:58 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 1.4484
2022-07-10 15:35:31 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 1.5827
2022-07-10 15:36:05 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 1.4929
2022-07-10 15:36:38 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 1.6139
2022-07-10 15:37:12 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 1.5275
2022-07-10 15:37:45 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 1.5363
2022-07-10 15:38:19 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 1.4011
2022-07-10 15:38:51 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 1.3686
2022-07-10 15:39:25 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 1.4820
2022-07-10 15:39:58 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 1.9033
2022-07-10 15:40:31 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 1.5366
2022-07-10 15:41:04 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 1.7453
2022-07-10 15:41:37 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 1.5910
2022-07-10 15:42:10 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 1.6119
2022-07-10 15:42:43 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 1.4655
2022-07-10 15:43:17 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 1.7039
2022-07-10 15:43:50 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 1.4830
2022-07-10 15:44:23 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 1.6321
2022-07-10 15:44:57 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 1.5514
2022-07-10 15:45:31 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 1.5310
2022-07-10 15:46:03 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 1.6274
2022-07-10 15:46:36 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 1.3223
2022-07-10 15:47:10 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 1.6307
2022-07-10 15:47:43 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 1.4037
2022-07-10 15:48:17 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 1.4942
2022-07-10 15:48:49 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 1.4080
2022-07-10 15:49:24 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 1.3183
2022-07-10 15:49:57 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 1.3519
2022-07-10 15:50:30 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 1.3504
2022-07-10 15:51:04 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 1.6323
2022-07-10 15:51:37 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 1.5329
2022-07-10 15:52:10 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 1.5826
2022-07-10 15:52:44 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 1.5555
2022-07-10 15:53:16 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 1.6200
2022-07-10 15:53:50 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 1.7279
2022-07-10 15:54:22 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 1.4413
2022-07-10 15:54:56 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 1.4221
2022-07-10 15:55:29 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 1.4239
2022-07-10 15:56:02 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 1.6338
2022-07-10 15:56:35 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 1.5225
2022-07-10 15:57:09 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 1.4500
2022-07-10 15:57:42 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 1.3639
2022-07-10 15:58:14 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 1.7133
2022-07-10 15:58:15 - train: epoch 087, train_loss: 1.5199
2022-07-10 15:59:28 - eval: epoch: 087, acc1: 67.134%, acc5: 87.494%, test_loss: 1.3504, per_image_load_time: 2.628ms, per_image_inference_time: 0.160ms
2022-07-10 15:59:28 - until epoch: 087, best_acc1: 67.134%
2022-07-10 15:59:28 - epoch 088 lr: 0.001000
2022-07-10 16:00:07 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 1.4189
2022-07-10 16:00:39 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 1.5467
2022-07-10 16:01:12 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 1.6066
2022-07-10 16:01:46 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 1.4921
2022-07-10 16:02:18 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 1.6489
2022-07-10 16:02:51 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 1.5457
2022-07-10 16:03:25 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 1.4227
2022-07-10 16:03:57 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 1.5396
2022-07-10 16:04:30 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 1.6208
2022-07-10 16:05:03 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 1.4571
2022-07-10 16:05:36 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 1.2935
2022-07-10 16:06:09 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 1.5341
2022-07-10 16:06:43 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 1.4256
2022-07-10 16:07:16 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 1.3246
2022-07-10 16:07:50 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 1.6407
2022-07-10 16:08:22 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 1.3258
2022-07-10 16:08:56 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 1.3162
2022-07-10 16:09:29 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 1.4418
2022-07-10 16:10:02 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 1.5427
2022-07-10 16:10:35 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 1.4249
2022-07-10 16:11:08 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 1.5138
2022-07-10 16:11:41 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 1.5351
2022-07-10 16:12:15 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 1.4198
2022-07-10 16:12:47 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 1.7123
2022-07-10 16:13:20 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 1.5950
2022-07-10 16:13:54 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 1.6006
2022-07-10 16:14:28 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 1.7324
2022-07-10 16:15:00 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 1.6389
2022-07-10 16:15:34 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 1.5952
2022-07-10 16:16:07 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 1.7483
2022-07-10 16:16:40 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 1.5029
2022-07-10 16:17:13 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 1.4987
2022-07-10 16:17:47 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 1.3390
2022-07-10 16:18:20 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 1.2051
2022-07-10 16:18:54 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 1.4740
2022-07-10 16:19:26 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 1.5256
2022-07-10 16:20:00 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 1.6119
2022-07-10 16:20:32 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 1.5224
2022-07-10 16:21:07 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 1.6666
2022-07-10 16:21:40 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 1.3432
2022-07-10 16:22:14 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 1.5806
2022-07-10 16:22:46 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 1.6751
2022-07-10 16:23:20 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 1.4216
2022-07-10 16:23:53 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 1.3692
2022-07-10 16:24:26 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 1.4966
2022-07-10 16:24:59 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 1.7555
2022-07-10 16:25:33 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 1.7633
2022-07-10 16:26:06 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 1.5366
2022-07-10 16:26:40 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 1.3072
2022-07-10 16:27:11 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 1.4914
2022-07-10 16:27:12 - train: epoch 088, train_loss: 1.5192
2022-07-10 16:28:25 - eval: epoch: 088, acc1: 67.122%, acc5: 87.662%, test_loss: 1.3459, per_image_load_time: 2.649ms, per_image_inference_time: 0.156ms
2022-07-10 16:28:25 - until epoch: 088, best_acc1: 67.134%
2022-07-10 16:28:25 - epoch 089 lr: 0.001000
2022-07-10 16:29:04 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 1.6526
2022-07-10 16:29:36 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 1.3120
2022-07-10 16:30:09 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 1.5792
2022-07-10 16:30:42 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 1.4274
2022-07-10 16:31:15 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 1.5215
2022-07-10 16:31:47 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 1.4945
2022-07-10 16:32:20 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 1.7178
2022-07-10 16:32:53 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 1.8198
2022-07-10 16:33:27 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 1.4435
2022-07-10 16:33:59 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 1.7264
2022-07-10 16:34:32 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 1.5701
2022-07-10 16:35:05 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 1.6786
2022-07-10 16:35:38 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 1.5677
2022-07-10 16:36:12 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 1.4780
2022-07-10 16:36:46 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 1.4735
2022-07-10 16:37:18 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 1.3459
2022-07-10 16:37:51 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 1.5535
2022-07-10 16:38:24 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 1.6544
2022-07-10 16:38:57 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 1.3799
2022-07-10 16:39:31 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 1.3326
2022-07-10 16:40:03 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 1.3686
2022-07-10 16:40:37 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 1.5916
2022-07-10 16:41:10 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 1.4590
2022-07-10 16:41:43 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 1.7419
2022-07-10 16:42:16 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 1.4620
2022-07-10 16:42:49 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 1.4749
2022-07-10 16:43:22 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 1.4258
2022-07-10 16:43:55 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 1.6040
2022-07-10 16:44:29 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 1.4862
2022-07-10 16:45:02 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 1.4897
2022-07-10 16:45:36 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 1.4777
2022-07-10 16:46:08 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 1.6061
2022-07-10 16:46:42 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 1.6736
2022-07-10 16:47:14 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 1.6611
2022-07-10 16:47:48 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 1.3042
2022-07-10 16:48:21 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 1.4437
2022-07-10 16:48:55 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 1.4827
2022-07-10 16:49:28 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 1.3419
2022-07-10 16:50:01 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 1.7114
2022-07-10 16:50:33 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 1.4504
2022-07-10 16:51:07 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 1.7356
2022-07-10 16:51:41 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 1.6622
2022-07-10 16:52:14 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 1.5977
2022-07-10 16:52:48 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 1.5368
2022-07-10 16:53:19 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 1.5522
2022-07-10 16:53:53 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 1.4648
2022-07-10 16:54:26 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 1.4904
2022-07-10 16:54:59 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 1.4026
2022-07-10 16:55:32 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 1.4371
2022-07-10 16:56:03 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 1.2424
2022-07-10 16:56:04 - train: epoch 089, train_loss: 1.5188
2022-07-10 16:57:17 - eval: epoch: 089, acc1: 67.208%, acc5: 87.686%, test_loss: 1.3457, per_image_load_time: 2.647ms, per_image_inference_time: 0.154ms
2022-07-10 16:57:17 - until epoch: 089, best_acc1: 67.208%
2022-07-10 16:57:17 - epoch 090 lr: 0.001000
2022-07-10 16:57:56 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 1.4934
2022-07-10 16:58:28 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 1.4597
2022-07-10 16:59:01 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 1.6267
2022-07-10 16:59:34 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 1.4531
2022-07-10 17:00:06 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 1.5110
2022-07-10 17:00:39 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 1.7997
2022-07-10 17:01:11 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 1.4565
2022-07-10 17:01:44 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 1.5442
2022-07-10 17:02:18 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 1.4794
2022-07-10 17:02:50 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 1.4724
2022-07-10 17:03:23 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 1.5009
2022-07-10 17:03:57 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 1.3671
2022-07-10 17:04:30 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 1.5701
2022-07-10 17:05:02 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 1.4437
2022-07-10 17:05:36 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 1.4911
2022-07-10 17:06:09 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 1.4533
2022-07-10 17:06:42 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 1.3391
2022-07-10 17:07:15 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 1.6892
2022-07-10 17:07:48 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 1.3059
2022-07-10 17:08:22 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 1.4216
2022-07-10 17:08:54 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 1.7031
2022-07-10 17:09:28 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 1.6373
2022-07-10 17:10:00 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 1.6858
2022-07-10 17:10:34 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 1.7438
2022-07-10 17:11:07 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 1.4520
2022-07-10 17:11:41 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 1.4936
2022-07-10 17:12:13 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 1.4498
2022-07-10 17:12:47 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 1.6148
2022-07-10 17:13:19 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 1.3705
2022-07-10 17:13:52 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 1.6074
2022-07-10 17:14:26 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 1.2493
2022-07-10 17:14:58 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 1.4601
2022-07-10 17:15:32 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 1.6092
2022-07-10 17:16:04 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 1.4986
2022-07-10 17:16:38 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 1.4712
2022-07-10 17:17:12 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 1.3752
2022-07-10 17:17:43 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 1.6354
2022-07-10 17:18:17 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 1.5271
2022-07-10 17:18:50 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 1.3088
2022-07-10 17:19:23 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 1.3102
2022-07-10 17:19:57 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 1.6951
2022-07-10 17:20:30 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 1.6061
2022-07-10 17:21:04 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 1.3077
2022-07-10 17:21:37 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 1.4908
2022-07-10 17:22:10 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 1.5310
2022-07-10 17:22:42 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 1.6000
2022-07-10 17:23:16 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 1.4538
2022-07-10 17:23:48 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 1.6828
2022-07-10 17:24:22 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 1.3613
2022-07-10 17:24:54 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 1.3365
2022-07-10 17:24:54 - train: epoch 090, train_loss: 1.5173
2022-07-10 17:26:08 - eval: epoch: 090, acc1: 67.074%, acc5: 87.578%, test_loss: 1.3502, per_image_load_time: 2.630ms, per_image_inference_time: 0.146ms
2022-07-10 17:26:08 - until epoch: 090, best_acc1: 67.208%
2022-07-10 17:26:08 - epoch 091 lr: 0.000100
2022-07-10 17:26:45 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 1.3047
2022-07-10 17:27:18 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 1.2990
2022-07-10 17:27:52 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 1.4577
2022-07-10 17:28:24 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 1.4965
2022-07-10 17:28:57 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 1.4816
2022-07-10 17:29:30 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 1.5065
2022-07-10 17:30:03 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 1.5716
2022-07-10 17:30:36 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 1.2508
2022-07-10 17:31:10 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 1.4578
2022-07-10 17:31:42 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 1.5259
2022-07-10 17:32:15 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 1.3046
2022-07-10 17:32:48 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 1.4773
2022-07-10 17:33:21 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 1.3197
2022-07-10 17:33:54 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 1.6720
2022-07-10 17:34:27 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 1.3825
2022-07-10 17:35:00 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 1.7009
2022-07-10 17:35:33 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 1.4861
2022-07-10 17:36:07 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 1.6150
2022-07-10 17:36:40 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 1.4480
2022-07-10 17:37:13 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 1.4218
2022-07-10 17:37:46 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 1.3949
2022-07-10 17:38:19 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 1.6347
2022-07-10 17:38:52 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 1.5185
2022-07-10 17:39:25 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 1.4031
2022-07-10 17:39:59 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 1.5774
2022-07-10 17:40:31 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 1.4450
2022-07-10 17:41:05 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 1.3965
2022-07-10 17:41:38 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 1.5622
2022-07-10 17:42:12 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 1.5466
2022-07-10 17:42:44 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 1.5939
2022-07-10 17:43:17 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 1.6395
2022-07-10 17:43:50 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 1.5915
2022-07-10 17:44:23 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 1.4396
2022-07-10 17:44:57 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 1.3918
2022-07-10 17:45:30 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 1.5085
2022-07-10 17:46:02 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 1.4785
2022-07-10 17:46:36 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 1.6557
2022-07-10 17:47:09 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 1.4607
2022-07-10 17:47:42 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 1.3517
2022-07-10 17:48:15 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 1.3916
2022-07-10 17:48:49 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 1.5402
2022-07-10 17:49:21 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 1.6187
2022-07-10 17:49:55 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 1.3034
2022-07-10 17:50:27 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 1.1108
2022-07-10 17:51:00 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 1.4346
2022-07-10 17:51:33 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 1.4431
2022-07-10 17:52:07 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 1.4881
2022-07-10 17:52:39 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 1.4181
2022-07-10 17:53:13 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 1.3260
2022-07-10 17:53:44 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 1.8747
2022-07-10 17:53:45 - train: epoch 091, train_loss: 1.4921
2022-07-10 17:54:59 - eval: epoch: 091, acc1: 67.498%, acc5: 87.874%, test_loss: 1.3280, per_image_load_time: 2.659ms, per_image_inference_time: 0.160ms
2022-07-10 17:54:59 - until epoch: 091, best_acc1: 67.498%
2022-07-10 17:54:59 - epoch 092 lr: 0.000100
2022-07-10 17:55:37 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 1.4336
2022-07-10 17:56:11 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 1.5329
2022-07-10 17:56:43 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 1.5342
2022-07-10 17:57:17 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 1.5010
2022-07-10 17:57:49 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 1.4483
2022-07-10 17:58:22 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 1.4526
2022-07-10 17:58:54 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 1.3598
2022-07-10 17:59:28 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 1.5548
2022-07-10 18:00:00 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 1.4123
2022-07-10 18:00:33 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 1.3698
2022-07-10 18:01:07 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 1.4510
2022-07-10 18:01:39 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 1.3610
2022-07-10 18:02:13 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 1.3968
2022-07-10 18:02:46 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 1.3212
2022-07-10 18:03:19 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 1.5487
2022-07-10 18:03:51 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 1.5789
2022-07-10 18:04:25 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 1.5420
2022-07-10 18:04:57 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 1.4807
2022-07-10 18:05:31 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 1.5523
2022-07-10 18:06:04 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 1.2655
2022-07-10 18:06:36 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 1.4071
2022-07-10 18:07:10 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 1.4665
2022-07-10 18:07:42 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 1.4809
2022-07-10 18:08:15 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 1.2851
2022-07-10 18:08:48 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 1.2567
2022-07-10 18:09:21 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 1.6268
2022-07-10 18:09:54 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 1.4829
2022-07-10 18:10:27 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 1.4993
2022-07-10 18:11:00 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 1.5252
2022-07-10 18:11:33 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 1.4252
2022-07-10 18:12:06 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 1.5953
2022-07-10 18:12:40 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 1.3960
2022-07-10 18:13:12 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 1.4902
2022-07-10 18:13:46 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 1.5584
2022-07-10 18:14:18 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 1.6066
2022-07-10 18:14:52 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 1.4383
2022-07-10 18:15:24 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 1.4866
2022-07-10 18:15:58 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 1.5387
2022-07-10 18:16:31 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 1.5161
2022-07-10 18:17:04 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 1.5234
2022-07-10 18:17:36 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 1.3285
2022-07-10 18:18:11 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 1.5277
2022-07-10 18:18:43 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 1.5162
2022-07-10 18:19:17 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 1.4948
2022-07-10 18:19:49 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 1.4873
2022-07-10 18:20:22 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 1.5627
2022-07-10 18:20:55 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 1.3360
2022-07-10 18:21:28 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 1.5775
2022-07-10 18:22:01 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 1.3654
2022-07-10 18:22:33 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 1.4181
2022-07-10 18:22:34 - train: epoch 092, train_loss: 1.4855
2022-07-10 18:23:48 - eval: epoch: 092, acc1: 67.580%, acc5: 87.926%, test_loss: 1.3281, per_image_load_time: 2.715ms, per_image_inference_time: 0.160ms
2022-07-10 18:23:48 - until epoch: 092, best_acc1: 67.580%
2022-07-10 18:23:48 - epoch 093 lr: 0.000100
2022-07-10 18:24:27 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 1.5965
2022-07-10 18:24:59 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 1.3483
2022-07-10 18:25:31 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 1.5452
2022-07-10 18:26:05 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 1.6338
2022-07-10 18:26:38 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 1.7092
2022-07-10 18:27:10 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 1.2890
2022-07-10 18:27:43 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 1.5358
2022-07-10 18:28:16 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 1.3855
2022-07-10 18:28:49 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 1.5261
2022-07-10 18:29:23 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 1.3967
2022-07-10 18:29:54 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 1.5848
2022-07-10 18:30:28 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 1.5457
2022-07-10 18:31:01 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 1.4767
2022-07-10 18:31:34 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 1.4393
2022-07-10 18:32:06 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 1.6184
2022-07-10 18:32:41 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 1.4688
2022-07-10 18:33:13 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 1.4899
2022-07-10 18:33:46 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 1.6027
2022-07-10 18:34:20 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 1.2017
2022-07-10 18:34:52 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 1.3882
2022-07-10 18:35:26 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 1.3299
2022-07-10 18:35:59 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 1.6744
2022-07-10 18:36:32 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 1.3313
2022-07-10 18:37:05 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 1.3520
2022-07-10 18:37:38 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 1.5293
2022-07-10 18:38:10 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 1.7041
2022-07-10 18:38:44 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 1.3929
2022-07-10 18:39:17 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 1.4041
2022-07-10 18:39:50 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 1.2834
2022-07-10 18:40:23 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 1.4752
2022-07-10 18:40:56 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 1.5713
2022-07-10 18:41:29 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 1.4540
2022-07-10 18:42:02 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 1.4396
2022-07-10 18:42:35 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 1.5626
2022-07-10 18:43:09 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 1.4345
2022-07-10 18:43:42 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 1.5962
2022-07-10 18:44:14 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 1.3264
2022-07-10 18:44:48 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 1.4058
2022-07-10 18:45:20 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 1.4221
2022-07-10 18:45:53 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 1.7251
2022-07-10 18:46:26 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 1.5200
2022-07-10 18:47:00 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 1.6181
2022-07-10 18:47:33 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 1.6935
2022-07-10 18:48:07 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 1.4457
2022-07-10 18:48:39 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 1.4025
2022-07-10 18:49:12 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 1.3536
2022-07-10 18:49:45 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 1.8272
2022-07-10 18:50:19 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 1.4071
2022-07-10 18:50:51 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 1.5105
2022-07-10 18:51:22 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 1.4527
2022-07-10 18:51:23 - train: epoch 093, train_loss: 1.4843
2022-07-10 18:52:37 - eval: epoch: 093, acc1: 67.600%, acc5: 87.972%, test_loss: 1.3247, per_image_load_time: 2.701ms, per_image_inference_time: 0.149ms
2022-07-10 18:52:38 - until epoch: 093, best_acc1: 67.600%
2022-07-10 18:52:38 - epoch 094 lr: 0.000100
2022-07-10 18:53:15 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 1.5272
2022-07-10 18:53:48 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 1.5187
2022-07-10 18:54:21 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 1.5491
2022-07-10 18:54:54 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 1.8404
2022-07-10 18:55:27 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 1.3327
2022-07-10 18:55:59 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 1.3066
2022-07-10 18:56:32 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 1.5321
2022-07-10 18:57:05 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 1.6423
2022-07-10 18:57:38 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 1.4338
2022-07-10 18:58:10 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 1.5087
2022-07-10 18:58:44 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 1.5509
2022-07-10 18:59:16 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 1.4670
2022-07-10 18:59:50 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 1.5615
2022-07-10 19:00:22 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 1.3047
2022-07-10 19:00:56 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 1.4872
2022-07-10 19:01:28 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 1.6629
2022-07-10 19:02:02 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 1.4450
2022-07-10 19:02:35 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 1.2004
2022-07-10 19:03:08 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 1.4427
2022-07-10 19:03:41 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 1.3196
2022-07-10 19:04:13 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 1.2837
2022-07-10 19:04:47 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 1.4543
2022-07-10 19:05:20 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 1.3674
2022-07-10 19:05:54 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 1.6617
2022-07-10 19:06:27 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 1.4328
2022-07-10 19:07:00 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 1.4086
2022-07-10 19:07:34 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 1.5619
2022-07-10 19:08:06 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 1.5215
2022-07-10 19:08:40 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 1.3618
2022-07-10 19:09:13 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 1.5605
2022-07-10 19:09:46 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 1.5913
2022-07-10 19:10:18 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 1.5065
2022-07-10 19:10:52 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 1.4880
2022-07-10 19:11:26 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 1.5670
2022-07-10 19:11:59 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 1.6622
2022-07-10 19:12:33 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 1.2305
2022-07-10 19:13:05 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 1.7383
2022-07-10 19:13:39 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 1.3176
2022-07-10 19:14:12 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 1.4341
2022-07-10 19:14:45 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 1.5380
2022-07-10 19:15:18 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 1.5038
2022-07-10 19:15:52 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 1.4794
2022-07-10 19:16:25 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 1.5740
2022-07-10 19:16:57 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 1.7086
2022-07-10 19:17:32 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 1.5433
2022-07-10 19:18:05 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 1.4019
2022-07-10 19:18:37 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 1.4746
2022-07-10 19:19:11 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 1.4656
2022-07-10 19:19:45 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 1.5622
2022-07-10 19:20:15 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 1.3030
2022-07-10 19:20:16 - train: epoch 094, train_loss: 1.4804
2022-07-10 19:21:30 - eval: epoch: 094, acc1: 67.656%, acc5: 87.988%, test_loss: 1.3235, per_image_load_time: 2.686ms, per_image_inference_time: 0.139ms
2022-07-10 19:21:30 - until epoch: 094, best_acc1: 67.656%
2022-07-10 19:21:30 - epoch 095 lr: 0.000100
2022-07-10 19:22:08 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 1.5323
2022-07-10 19:22:41 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 1.5892
2022-07-10 19:23:14 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 1.4125
2022-07-10 19:23:46 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 1.4635
2022-07-10 19:24:20 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 1.5408
2022-07-10 19:24:51 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 1.3843
2022-07-10 19:25:25 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 1.5810
2022-07-10 19:25:58 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 1.4256
2022-07-10 19:26:31 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 1.6387
2022-07-10 19:27:04 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 1.4623
2022-07-10 19:27:37 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 1.4504
2022-07-10 19:28:11 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 1.5342
2022-07-10 19:28:43 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 1.4178
2022-07-10 19:29:17 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 1.6007
2022-07-10 19:29:48 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 1.5480
2022-07-10 19:30:22 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 1.1590
2022-07-10 19:30:55 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 1.3632
2022-07-10 19:31:29 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 1.5657
2022-07-10 19:32:02 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 1.5142
2022-07-10 19:32:34 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 1.4056
2022-07-10 19:33:08 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 1.5487
2022-07-10 19:33:41 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 1.3011
2022-07-10 19:34:14 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 1.4745
2022-07-10 19:34:47 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 1.4398
2022-07-10 19:35:20 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 1.4769
2022-07-10 19:35:53 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 1.3457
2022-07-10 19:36:27 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 1.3009
2022-07-10 19:37:00 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 1.2471
2022-07-10 19:37:34 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 1.5823
2022-07-10 19:38:06 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 1.7495
2022-07-10 19:38:40 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 1.4918
2022-07-10 19:39:13 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 1.5846
2022-07-10 19:39:46 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 1.5303
2022-07-10 19:40:19 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 1.3333
2022-07-10 19:40:51 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 1.4399
2022-07-10 19:41:25 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 1.3106
2022-07-10 19:41:58 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 1.4556
2022-07-10 19:42:31 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 1.3399
2022-07-10 19:43:05 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 1.5045
2022-07-10 19:43:38 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 1.3413
2022-07-10 19:44:11 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 1.4208
2022-07-10 19:44:44 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 1.3133
2022-07-10 19:45:18 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 1.7665
2022-07-10 19:45:51 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 1.6756
2022-07-10 19:46:24 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 1.5542
2022-07-10 19:46:56 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 1.4341
2022-07-10 19:47:29 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 1.5745
2022-07-10 19:48:03 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 1.3453
2022-07-10 19:48:36 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 1.2788
2022-07-10 19:49:07 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 1.4336
2022-07-10 19:49:08 - train: epoch 095, train_loss: 1.4812
2022-07-10 19:50:22 - eval: epoch: 095, acc1: 67.696%, acc5: 87.976%, test_loss: 1.3236, per_image_load_time: 2.662ms, per_image_inference_time: 0.162ms
2022-07-10 19:50:22 - until epoch: 095, best_acc1: 67.696%
2022-07-10 19:50:22 - epoch 096 lr: 0.000100
2022-07-10 19:51:00 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 1.4550
2022-07-10 19:51:32 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 1.5755
2022-07-10 19:52:05 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 1.3346
2022-07-10 19:52:38 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 1.3867
2022-07-10 19:53:10 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 1.5802
2022-07-10 19:53:43 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 1.4965
2022-07-10 19:54:15 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 1.5127
2022-07-10 19:54:49 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 1.3594
2022-07-10 19:55:22 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 1.4945
2022-07-10 19:55:54 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 1.4390
2022-07-10 19:56:26 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 1.6316
2022-07-10 19:57:01 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 1.4023
2022-07-10 19:57:32 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 1.3790
2022-07-10 19:58:06 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 1.5270
2022-07-10 19:58:38 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 1.4301
2022-07-10 19:59:12 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 1.2697
2022-07-10 19:59:44 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 1.4034
2022-07-10 20:00:17 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 1.3373
2022-07-10 20:00:50 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 1.6059
2022-07-10 20:01:23 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 1.4159
2022-07-10 20:01:57 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 1.4512
2022-07-10 20:02:29 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 1.2274
2022-07-10 20:03:03 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 1.4325
2022-07-10 20:03:35 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 1.3478
2022-07-10 20:04:09 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 1.4883
2022-07-10 20:04:42 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 1.3373
2022-07-10 20:05:14 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 1.5764
2022-07-10 20:05:48 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 1.4362
2022-07-10 20:06:21 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 1.5583
2022-07-10 20:06:55 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 1.6493
2022-07-10 20:07:28 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 1.4811
2022-07-10 20:08:01 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 1.5904
2022-07-10 20:08:33 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 1.5152
2022-07-10 20:09:07 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 1.4338
2022-07-10 20:09:40 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 1.3781
2022-07-10 20:10:14 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 1.3330
2022-07-10 20:10:46 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 1.4655
2022-07-10 20:11:21 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 1.2639
2022-07-10 20:11:54 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 1.3913
2022-07-10 20:12:28 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 1.5476
2022-07-10 20:13:00 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 1.3901
2022-07-10 20:13:34 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 1.4030
2022-07-10 20:14:07 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 1.3737
2022-07-10 20:14:39 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 1.4569
2022-07-10 20:15:13 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 1.4834
2022-07-10 20:15:47 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 1.4436
2022-07-10 20:16:19 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 1.5614
2022-07-10 20:16:52 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 1.4516
2022-07-10 20:17:26 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 1.6466
2022-07-10 20:17:57 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 1.5070
2022-07-10 20:17:58 - train: epoch 096, train_loss: 1.4802
2022-07-10 20:19:12 - eval: epoch: 096, acc1: 67.696%, acc5: 87.966%, test_loss: 1.3229, per_image_load_time: 2.707ms, per_image_inference_time: 0.162ms
2022-07-10 20:19:12 - until epoch: 096, best_acc1: 67.696%
2022-07-10 20:19:12 - epoch 097 lr: 0.000100
2022-07-10 20:19:50 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 1.6443
2022-07-10 20:20:23 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 1.4779
2022-07-10 20:20:55 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 1.6791
2022-07-10 20:21:29 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 1.6114
2022-07-10 20:22:03 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 1.6824
2022-07-10 20:22:35 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 1.3881
2022-07-10 20:23:09 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 1.6312
2022-07-10 20:23:39 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 1.3913
2022-07-10 20:24:14 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 1.3127
2022-07-10 20:24:45 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 1.5811
2022-07-10 20:25:18 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 1.3971
2022-07-10 20:25:51 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 1.4152
2022-07-10 20:26:24 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 1.3190
2022-07-10 20:26:58 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 1.5597
2022-07-10 20:27:30 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 1.4069
2022-07-10 20:28:03 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 1.4410
2022-07-10 20:28:37 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 1.3684
2022-07-10 20:29:10 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 1.4812
2022-07-10 20:29:43 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 1.3048
2022-07-10 20:30:17 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 1.2477
2022-07-10 20:30:49 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 1.3849
2022-07-10 20:31:22 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 1.4775
2022-07-10 20:31:55 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 1.2535
2022-07-10 20:32:28 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 1.5914
2022-07-10 20:33:01 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 1.4817
2022-07-10 20:33:34 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 1.4630
2022-07-10 20:34:08 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 1.2409
2022-07-10 20:34:41 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 1.5031
2022-07-10 20:35:14 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 1.4703
2022-07-10 20:35:47 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 1.5799
2022-07-10 20:36:20 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 1.4009
2022-07-10 20:36:54 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 1.3918
2022-07-10 20:37:27 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 1.6437
2022-07-10 20:38:01 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 1.6758
2022-07-10 20:38:33 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 1.4406
2022-07-10 20:39:07 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 1.4710
2022-07-10 20:39:39 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 1.1201
2022-07-10 20:40:14 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 1.2637
2022-07-10 20:40:45 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 1.4333
2022-07-10 20:41:18 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 1.4513
2022-07-10 20:41:52 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 1.3746
2022-07-10 20:42:25 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 1.3642
2022-07-10 20:42:59 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 1.3811
2022-07-10 20:43:32 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 1.3374
2022-07-10 20:44:05 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 1.6219
2022-07-10 20:44:38 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 1.4759
2022-07-10 20:45:12 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 1.3435
2022-07-10 20:45:44 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 1.4465
2022-07-10 20:46:18 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 1.5757
2022-07-10 20:46:49 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 1.2523
2022-07-10 20:46:50 - train: epoch 097, train_loss: 1.4775
2022-07-10 20:48:04 - eval: epoch: 097, acc1: 67.690%, acc5: 88.038%, test_loss: 1.3219, per_image_load_time: 2.680ms, per_image_inference_time: 0.187ms
2022-07-10 20:48:04 - until epoch: 097, best_acc1: 67.696%
2022-07-10 20:49:33 - epoch 098 lr: 0.000100
2022-07-10 20:50:12 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 1.5768
2022-07-10 20:50:45 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 1.7190
2022-07-10 20:51:18 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 1.4462
2022-07-10 20:51:50 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 1.5364
2022-07-10 20:52:23 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 1.5204
2022-07-10 20:52:56 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 1.5173
2022-07-10 20:53:29 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 1.6029
2022-07-10 20:54:01 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 1.3888
2022-07-10 20:54:34 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 1.4314
2022-07-10 20:55:07 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 1.5110
2022-07-10 20:55:41 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 1.3840
2022-07-10 20:56:14 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 1.3472
2022-07-10 20:56:47 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 1.6442
2022-07-10 20:57:20 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 1.5212
2022-07-10 20:57:52 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 1.4734
2022-07-10 20:58:26 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 1.3067
2022-07-10 20:58:59 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 1.5000
2022-07-10 20:59:31 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 1.6157
2022-07-10 21:00:05 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 1.3627
2022-07-10 21:00:38 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 1.5713
2022-07-10 21:01:11 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 1.5134
2022-07-10 21:01:44 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 1.4120
2022-07-10 21:02:17 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 1.4350
2022-07-10 21:02:50 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 1.5228
2022-07-10 21:03:23 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 1.6511
2022-07-10 21:03:57 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 1.3231
2022-07-10 21:04:30 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 1.4465
2022-07-10 21:05:03 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 1.5720
2022-07-10 21:05:35 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 1.3360
2022-07-10 21:06:09 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 1.5077
2022-07-10 21:06:43 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 1.4697
2022-07-10 21:07:15 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 1.2698
2022-07-10 21:07:48 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 1.3540
2022-07-10 21:08:22 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 1.4243
2022-07-10 21:08:54 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 1.4245
2022-07-10 21:09:27 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 1.7992
2022-07-10 21:10:00 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 1.4195
2022-07-10 21:10:33 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 1.2545
2022-07-10 21:11:06 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 1.5686
2022-07-10 21:11:40 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 1.7881
2022-07-10 21:12:12 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 1.5506
2022-07-10 21:12:46 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 1.5960
2022-07-10 21:13:18 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 1.3848
2022-07-10 21:13:53 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 1.6052
2022-07-10 21:14:24 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 1.5796
2022-07-10 21:14:59 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 1.7088
2022-07-10 21:15:31 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 1.5187
2022-07-10 21:16:04 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 1.4487
2022-07-10 21:16:37 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 1.3838
2022-07-10 21:17:09 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 1.5734
2022-07-10 21:17:09 - train: epoch 098, train_loss: 1.4757
2022-07-10 21:18:23 - eval: epoch: 098, acc1: 67.620%, acc5: 88.002%, test_loss: 1.3218, per_image_load_time: 2.696ms, per_image_inference_time: 0.171ms
2022-07-10 21:18:23 - until epoch: 098, best_acc1: 67.696%
2022-07-10 21:18:23 - epoch 099 lr: 0.000100
2022-07-10 21:19:01 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 1.5559
2022-07-10 21:19:34 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 1.5109
2022-07-10 21:20:06 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 1.2470
2022-07-10 21:20:40 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 1.5948
2022-07-10 21:21:13 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 1.4555
2022-07-10 21:21:46 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 1.3601
2022-07-10 21:22:19 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 1.4764
2022-07-10 21:22:53 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 1.3821
2022-07-10 21:23:25 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 1.5292
2022-07-10 21:23:59 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 1.5135
2022-07-10 21:24:32 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 1.5598
2022-07-10 21:25:06 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 1.2686
2022-07-10 21:25:38 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 1.5593
2022-07-10 21:26:11 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 1.5114
2022-07-10 21:26:44 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 1.4259
2022-07-10 21:27:17 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 1.4404
2022-07-10 21:27:50 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 1.3475
2022-07-10 21:28:23 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 1.6030
2022-07-10 21:28:56 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 1.5381
2022-07-10 21:29:30 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 1.4630
2022-07-10 21:30:03 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 1.5949
2022-07-10 21:30:35 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 1.4042
2022-07-10 21:31:09 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 1.4214
2022-07-10 21:31:43 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 1.5968
2022-07-10 21:32:16 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 1.3392
2022-07-10 21:32:49 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 1.3992
2022-07-10 21:33:22 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 1.4907
2022-07-10 21:33:55 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 1.4094
2022-07-10 21:34:29 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 1.3741
2022-07-10 21:35:01 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 1.6121
2022-07-10 21:35:35 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 1.3447
2022-07-10 21:36:08 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 1.4606
2022-07-10 21:36:42 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 1.4959
2022-07-10 21:37:15 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 1.3067
2022-07-10 21:37:47 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 1.5315
2022-07-10 21:38:22 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 1.4695
2022-07-10 21:38:54 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 1.2998
2022-07-10 21:39:27 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 1.4597
2022-07-10 21:40:01 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 1.4169
2022-07-10 21:40:34 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 1.3635
2022-07-10 21:41:07 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 1.4046
2022-07-10 21:41:41 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 1.6847
2022-07-10 21:42:14 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 1.5850
2022-07-10 21:42:48 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 1.4869
2022-07-10 21:43:20 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 1.5247
2022-07-10 21:43:54 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 1.5116
2022-07-10 21:44:27 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 1.3594
2022-07-10 21:45:01 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 1.6311
2022-07-10 21:45:34 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 1.4963
2022-07-10 21:46:06 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 1.6637
2022-07-10 21:46:06 - train: epoch 099, train_loss: 1.4760
2022-07-10 21:47:19 - eval: epoch: 099, acc1: 67.716%, acc5: 88.034%, test_loss: 1.3219, per_image_load_time: 2.671ms, per_image_inference_time: 0.169ms
2022-07-10 21:47:19 - until epoch: 099, best_acc1: 67.716%
2022-07-10 21:47:19 - epoch 100 lr: 0.000100
2022-07-10 21:47:57 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 1.5396
2022-07-10 21:48:30 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 1.3415
2022-07-10 21:49:02 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 1.4606
2022-07-10 21:49:35 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 1.2992
2022-07-10 21:50:07 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 1.5323
2022-07-10 21:50:40 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 1.6274
2022-07-10 21:51:13 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 1.2873
2022-07-10 21:51:45 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 1.4299
2022-07-10 21:52:19 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 1.4655
2022-07-10 21:52:51 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 1.4682
2022-07-10 21:53:24 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 1.4267
2022-07-10 21:53:57 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 1.5622
2022-07-10 21:54:29 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 1.3487
2022-07-10 21:55:02 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 1.7537
2022-07-10 21:55:35 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 1.6063
2022-07-10 21:56:08 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 1.3933
2022-07-10 21:56:41 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 1.3970
2022-07-10 21:57:14 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 1.3969
2022-07-10 21:57:47 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 1.6343
2022-07-10 21:58:21 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 1.6804
2022-07-10 21:58:53 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 1.3098
2022-07-10 21:59:26 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 1.6422
2022-07-10 22:00:00 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 1.6260
2022-07-10 22:00:33 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 1.6015
2022-07-10 22:01:06 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 1.4619
2022-07-10 22:01:40 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 1.5035
2022-07-10 22:02:12 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 1.3161
2022-07-10 22:02:45 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 1.5066
2022-07-10 22:03:19 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 1.4801
2022-07-10 22:03:51 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 1.2129
2022-07-10 22:04:24 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 1.2076
2022-07-10 22:04:58 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 1.6966
2022-07-10 22:05:32 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 1.4340
2022-07-10 22:06:04 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 1.5203
2022-07-10 22:06:37 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 1.2375
2022-07-10 22:07:11 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 1.5560
2022-07-10 22:07:44 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 1.3017
2022-07-10 22:08:17 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 1.4249
2022-07-10 22:08:50 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 1.4387
2022-07-10 22:09:23 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 1.4316
2022-07-10 22:09:57 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 1.6356
2022-07-10 22:10:31 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 1.4468
2022-07-10 22:11:02 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 1.3364
2022-07-10 22:11:37 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 1.5295
2022-07-10 22:12:09 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 1.2766
2022-07-10 22:12:43 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 1.4062
2022-07-10 22:13:15 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 1.5156
2022-07-10 22:13:48 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 1.3646
2022-07-10 22:14:23 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 1.5455
2022-07-10 22:14:53 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 1.5110
2022-07-10 22:14:54 - train: epoch 100, train_loss: 1.4742
2022-07-10 22:16:08 - eval: epoch: 100, acc1: 67.752%, acc5: 88.034%, test_loss: 1.3211, per_image_load_time: 2.610ms, per_image_inference_time: 0.172ms
2022-07-10 22:16:08 - until epoch: 100, best_acc1: 67.752%
2022-07-10 22:16:08 - train done. model: resnet34half, train time: 48.125 hours, best_acc1: 67.752%
