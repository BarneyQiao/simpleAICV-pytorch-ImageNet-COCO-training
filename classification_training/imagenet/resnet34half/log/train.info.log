2022-02-22 05:11:55 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 1.6545
2022-02-22 05:12:28 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 1.4858
2022-02-22 05:13:01 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 1.8043
2022-02-22 05:13:34 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 1.5219
2022-02-22 05:14:07 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 1.4632
2022-02-22 05:14:41 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 1.4850
2022-02-22 05:15:14 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 1.5107
2022-02-22 05:15:47 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 1.6824
2022-02-22 05:16:21 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 1.4642
2022-02-22 05:16:54 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 1.3877
2022-02-22 05:17:27 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 1.7590
2022-02-22 05:18:00 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 1.5632
2022-02-22 05:18:35 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 1.5795
2022-02-22 05:19:07 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 1.3801
2022-02-22 05:19:41 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 1.2954
2022-02-22 05:20:14 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 1.5364
2022-02-22 05:20:46 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 1.5457
2022-02-22 05:20:48 - train: epoch 098, train_loss: 1.5054
2022-02-22 05:22:04 - eval: epoch: 098, acc1: 67.612%, acc5: 87.918%, test_loss: 1.3173, per_image_load_time: 2.590ms, per_image_inference_time: 0.151ms
2022-02-22 05:22:04 - until epoch: 098, best_acc1: 67.612%
2022-02-22 05:22:04 - epoch 099 lr: 0.00010000000000000003
2022-02-22 05:22:43 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 1.3571
2022-02-22 05:23:15 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 1.4134
2022-02-22 05:23:49 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 1.4057
2022-02-22 05:24:22 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 1.5655
2022-02-22 05:24:56 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 1.6283
2022-02-22 05:25:29 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 1.4601
2022-02-22 05:26:02 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 1.5311
2022-02-22 05:26:35 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 1.4518
2022-02-22 05:27:08 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 1.3998
2022-02-22 05:27:41 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 1.6002
2022-02-22 05:28:15 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 1.5418
2022-02-22 05:28:49 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 1.3633
2022-02-22 05:29:21 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 1.7338
2022-02-22 05:29:54 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 1.4939
2022-02-22 05:30:27 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 1.4056
2022-02-22 05:31:00 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 1.6614
2022-02-22 05:31:33 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 1.4331
2022-02-22 05:32:06 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 1.5427
2022-02-22 05:32:39 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 1.5387
2022-02-22 05:33:13 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 1.3382
2022-02-22 05:33:45 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 1.4918
2022-02-22 05:34:18 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 1.5420
2022-02-22 05:34:51 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 1.5057
2022-02-22 05:35:24 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 1.8207
2022-02-22 05:35:58 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 1.4122
2022-02-22 05:36:30 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 1.4584
2022-02-22 05:37:04 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 1.4701
2022-02-22 05:37:37 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 1.5575
2022-02-22 05:38:10 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 1.5040
2022-02-22 05:38:43 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 1.7113
2022-02-22 05:39:16 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 1.4124
2022-02-22 05:39:49 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 1.5795
2022-02-22 05:40:23 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 1.4070
2022-02-22 05:40:56 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 1.5678
2022-02-22 05:41:29 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 1.5055
2022-02-22 05:42:01 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 1.4726
2022-02-22 05:42:35 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 1.2641
2022-02-22 05:43:08 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 1.6299
2022-02-22 05:43:42 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 1.4672
2022-02-22 05:44:14 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 1.5675
2022-02-22 05:44:47 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 1.3706
2022-02-22 05:45:21 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 1.5692
2022-02-22 05:45:54 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 1.4163
2022-02-22 05:46:27 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 1.5947
2022-02-22 05:47:01 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 1.5782
2022-02-22 05:47:34 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 1.7100
2022-02-22 05:48:08 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 1.3772
2022-02-22 05:48:41 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 1.6915
2022-02-22 05:49:14 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 1.3609
2022-02-22 05:49:47 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 1.5112
2022-02-22 05:49:49 - train: epoch 099, train_loss: 1.5063
2022-02-22 05:51:05 - eval: epoch: 099, acc1: 67.722%, acc5: 87.930%, test_loss: 1.3165, per_image_load_time: 1.767ms, per_image_inference_time: 0.174ms
2022-02-22 05:51:05 - until epoch: 099, best_acc1: 67.722%
2022-02-22 05:51:05 - epoch 100 lr: 0.00010000000000000003
2022-02-22 05:51:43 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 1.4289
2022-02-22 05:52:16 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 1.5564
2022-02-22 05:52:50 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 1.3989
2022-02-22 05:53:23 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 1.2297
2022-02-22 05:53:56 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 1.4548
2022-02-22 05:54:28 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 1.6786
2022-02-22 05:55:02 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 1.3007
2022-02-22 05:55:36 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 1.5999
2022-02-22 05:56:08 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 1.3784
2022-02-22 05:56:42 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 1.5579
2022-02-22 05:57:14 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 1.4154
2022-02-22 05:57:47 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 1.6234
2022-02-22 05:58:20 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 1.5275
2022-02-22 05:58:54 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 1.6413
2022-02-22 05:59:27 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 1.4769
2022-02-22 06:00:00 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 1.4585
2022-02-22 06:00:34 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 1.4876
2022-02-22 06:01:06 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 1.5564
2022-02-22 06:01:40 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 1.5004
2022-02-22 06:02:13 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 1.5125
2022-02-22 06:02:46 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 1.4789
2022-02-22 06:03:20 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 1.6438
2022-02-22 06:03:52 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 1.4926
2022-02-22 06:04:25 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 1.4862
2022-02-22 06:04:58 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 1.4965
2022-02-22 06:05:32 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 1.5435
2022-02-22 06:06:04 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 1.4177
2022-02-22 06:06:39 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 1.5585
2022-02-22 06:07:11 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 1.6508
2022-02-22 06:07:45 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 1.3729
2022-02-22 06:08:17 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 1.4461
2022-02-22 06:08:51 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 1.6030
2022-02-22 06:09:25 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 1.7075
2022-02-22 06:09:58 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 1.6101
2022-02-22 06:10:32 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 1.2606
2022-02-22 06:11:05 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 1.5342
2022-02-22 06:11:39 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 1.4703
2022-02-22 06:12:13 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 1.5003
2022-02-22 06:12:47 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 1.5632
2022-02-22 06:13:21 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 1.4966
2022-02-22 06:13:55 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 1.5509
2022-02-22 06:14:28 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 1.5888
2022-02-22 06:15:02 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 1.4395
2022-02-22 06:15:36 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 1.6360
2022-02-22 06:16:10 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 1.4230
2022-02-22 06:16:44 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 1.2262
2022-02-22 06:17:16 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 1.6086
2022-02-22 06:17:50 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 1.2471
2022-02-22 06:18:23 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 1.4838
2022-02-22 06:18:55 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 1.6565
2022-02-22 06:18:57 - train: epoch 100, train_loss: 1.5035
2022-02-22 06:20:14 - eval: epoch: 100, acc1: 67.616%, acc5: 87.902%, test_loss: 1.3174, per_image_load_time: 2.637ms, per_image_inference_time: 0.196ms
2022-02-22 06:20:14 - until epoch: 100, best_acc1: 67.722%
2022-02-22 06:20:14 - train done. model: resnet34half, train time: 49.142 hours, best_acc1: 67.722%
