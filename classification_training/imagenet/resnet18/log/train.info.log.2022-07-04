2022-07-04 08:09:41 - network: resnet18
2022-07-04 08:09:41 - num_classes: 1000
2022-07-04 08:09:41 - input_image_size: 224
2022-07-04 08:09:41 - scale: 1.1428571428571428
2022-07-04 08:09:41 - trained_model_path: 
2022-07-04 08:09:41 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-07-04 08:09:41 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-07-04 08:09:41 - train_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7fe93d0755e0>
2022-07-04 08:09:41 - test_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7fe93d0758b0>
2022-07-04 08:09:41 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fe93d0758e0>
2022-07-04 08:09:41 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fe93d075940>
2022-07-04 08:09:41 - seed: 0
2022-07-04 08:09:41 - batch_size: 256
2022-07-04 08:09:41 - num_workers: 16
2022-07-04 08:09:41 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0001, 'no_weight_decay_layer_name_list': []})
2022-07-04 08:09:41 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [30, 60, 90]})
2022-07-04 08:09:41 - epochs: 100
2022-07-04 08:09:41 - print_interval: 100
2022-07-04 08:09:41 - sync_bn: False
2022-07-04 08:09:41 - apex: True
2022-07-04 08:09:41 - use_ema_model: False
2022-07-04 08:09:41 - ema_model_decay: 0.9999
2022-07-04 08:09:41 - gpus_type: NVIDIA RTX A5000
2022-07-04 08:09:41 - gpus_num: 2
2022-07-04 08:09:41 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7fe90c6feab0>
2022-07-04 08:09:42 - --------------------parameters--------------------
2022-07-04 08:09:42 - name: conv1.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: conv1.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: conv1.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer1.0.conv1.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer1.0.conv1.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer1.0.conv1.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer1.0.conv2.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer1.0.conv2.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer1.0.conv2.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer1.1.conv1.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer1.1.conv1.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer1.1.conv1.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer1.1.conv2.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer1.1.conv2.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer1.1.conv2.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer2.0.conv1.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer2.0.conv1.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer2.0.conv1.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer2.0.conv2.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer2.0.conv2.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer2.0.conv2.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer2.1.conv1.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer2.1.conv1.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer2.1.conv1.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer2.1.conv2.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer2.1.conv2.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer2.1.conv2.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer3.0.conv1.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer3.0.conv1.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer3.0.conv1.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer3.0.conv2.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer3.0.conv2.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer3.0.conv2.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer3.1.conv1.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer3.1.conv1.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer3.1.conv1.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer3.1.conv2.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer3.1.conv2.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer3.1.conv2.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer4.0.conv1.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer4.0.conv1.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer4.0.conv1.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer4.0.conv2.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer4.0.conv2.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer4.0.conv2.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer4.1.conv1.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer4.1.conv1.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer4.1.conv1.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: layer4.1.conv2.layer.0.weight, grad: True
2022-07-04 08:09:42 - name: layer4.1.conv2.layer.1.weight, grad: True
2022-07-04 08:09:42 - name: layer4.1.conv2.layer.1.bias, grad: True
2022-07-04 08:09:42 - name: fc.weight, grad: True
2022-07-04 08:09:42 - name: fc.bias, grad: True
2022-07-04 08:09:42 - --------------------buffers--------------------
2022-07-04 08:09:42 - name: conv1.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: conv1.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: conv1.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer1.0.conv1.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer1.0.conv2.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer1.1.conv1.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer1.1.conv2.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer2.0.conv1.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer2.0.conv2.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer2.1.conv1.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer2.1.conv2.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer3.0.conv1.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer3.0.conv2.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer3.1.conv1.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer3.1.conv2.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer4.0.conv1.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer4.0.conv2.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer4.1.conv1.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2022-07-04 08:09:42 - name: layer4.1.conv2.layer.1.running_var, grad: False
2022-07-04 08:09:42 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-04 08:09:42 - -----------no weight decay layers--------------
2022-07-04 08:09:42 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-04 08:09:42 - -------------weight decay layers---------------
2022-07-04 08:09:42 - name: conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - name: fc.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-04 08:09:42 - epoch 001 lr: 0.100000
2022-07-04 08:10:19 - train: epoch 0001, iter [00100, 05004], lr: 0.100000, loss: 6.8134
2022-07-04 08:10:53 - train: epoch 0001, iter [00200, 05004], lr: 0.100000, loss: 6.6549
2022-07-04 08:11:24 - train: epoch 0001, iter [00300, 05004], lr: 0.100000, loss: 6.4947
2022-07-04 08:11:57 - train: epoch 0001, iter [00400, 05004], lr: 0.100000, loss: 6.3380
2022-07-04 08:12:30 - train: epoch 0001, iter [00500, 05004], lr: 0.100000, loss: 6.1871
2022-07-04 08:13:05 - train: epoch 0001, iter [00600, 05004], lr: 0.100000, loss: 5.9002
2022-07-04 08:13:37 - train: epoch 0001, iter [00700, 05004], lr: 0.100000, loss: 5.9387
2022-07-04 08:14:09 - train: epoch 0001, iter [00800, 05004], lr: 0.100000, loss: 5.8697
2022-07-04 08:14:42 - train: epoch 0001, iter [00900, 05004], lr: 0.100000, loss: 5.8878
2022-07-04 08:15:16 - train: epoch 0001, iter [01000, 05004], lr: 0.100000, loss: 5.6530
2022-07-04 08:15:48 - train: epoch 0001, iter [01100, 05004], lr: 0.100000, loss: 5.6661
2022-07-04 08:16:22 - train: epoch 0001, iter [01200, 05004], lr: 0.100000, loss: 5.4977
2022-07-04 08:16:54 - train: epoch 0001, iter [01300, 05004], lr: 0.100000, loss: 5.4077
2022-07-04 08:17:28 - train: epoch 0001, iter [01400, 05004], lr: 0.100000, loss: 5.3302
2022-07-04 08:18:01 - train: epoch 0001, iter [01500, 05004], lr: 0.100000, loss: 5.2733
2022-07-04 08:18:33 - train: epoch 0001, iter [01600, 05004], lr: 0.100000, loss: 5.3455
2022-07-04 08:19:06 - train: epoch 0001, iter [01700, 05004], lr: 0.100000, loss: 5.1663
2022-07-04 08:19:40 - train: epoch 0001, iter [01800, 05004], lr: 0.100000, loss: 5.2352
2022-07-04 08:20:13 - train: epoch 0001, iter [01900, 05004], lr: 0.100000, loss: 5.0566
2022-07-04 08:20:46 - train: epoch 0001, iter [02000, 05004], lr: 0.100000, loss: 4.9745
2022-07-04 08:21:19 - train: epoch 0001, iter [02100, 05004], lr: 0.100000, loss: 4.9524
2022-07-04 08:21:52 - train: epoch 0001, iter [02200, 05004], lr: 0.100000, loss: 4.9044
2022-07-04 08:22:24 - train: epoch 0001, iter [02300, 05004], lr: 0.100000, loss: 4.6861
2022-07-04 08:22:58 - train: epoch 0001, iter [02400, 05004], lr: 0.100000, loss: 4.7453
2022-07-04 08:23:30 - train: epoch 0001, iter [02500, 05004], lr: 0.100000, loss: 4.7914
2022-07-04 08:24:04 - train: epoch 0001, iter [02600, 05004], lr: 0.100000, loss: 4.9414
2022-07-04 08:24:36 - train: epoch 0001, iter [02700, 05004], lr: 0.100000, loss: 4.8815
2022-07-04 08:25:09 - train: epoch 0001, iter [02800, 05004], lr: 0.100000, loss: 4.5341
2022-07-04 08:25:43 - train: epoch 0001, iter [02900, 05004], lr: 0.100000, loss: 4.4201
2022-07-04 08:26:16 - train: epoch 0001, iter [03000, 05004], lr: 0.100000, loss: 4.6382
2022-07-04 08:26:49 - train: epoch 0001, iter [03100, 05004], lr: 0.100000, loss: 4.7294
2022-07-04 08:27:22 - train: epoch 0001, iter [03200, 05004], lr: 0.100000, loss: 4.5601
2022-07-04 08:27:54 - train: epoch 0001, iter [03300, 05004], lr: 0.100000, loss: 4.2672
2022-07-04 08:28:27 - train: epoch 0001, iter [03400, 05004], lr: 0.100000, loss: 4.3138
2022-07-04 08:29:01 - train: epoch 0001, iter [03500, 05004], lr: 0.100000, loss: 4.4246
2022-07-04 08:29:33 - train: epoch 0001, iter [03600, 05004], lr: 0.100000, loss: 4.3035
2022-07-04 08:30:07 - train: epoch 0001, iter [03700, 05004], lr: 0.100000, loss: 4.5043
2022-07-04 08:30:40 - train: epoch 0001, iter [03800, 05004], lr: 0.100000, loss: 4.2432
2022-07-04 08:31:12 - train: epoch 0001, iter [03900, 05004], lr: 0.100000, loss: 4.3658
2022-07-04 08:31:45 - train: epoch 0001, iter [04000, 05004], lr: 0.100000, loss: 4.2827
2022-07-04 08:32:18 - train: epoch 0001, iter [04100, 05004], lr: 0.100000, loss: 4.2730
2022-07-04 08:32:51 - train: epoch 0001, iter [04200, 05004], lr: 0.100000, loss: 4.1731
2022-07-04 08:33:23 - train: epoch 0001, iter [04300, 05004], lr: 0.100000, loss: 4.1176
2022-07-04 08:33:57 - train: epoch 0001, iter [04400, 05004], lr: 0.100000, loss: 3.8989
2022-07-04 08:34:29 - train: epoch 0001, iter [04500, 05004], lr: 0.100000, loss: 4.0664
2022-07-04 08:35:02 - train: epoch 0001, iter [04600, 05004], lr: 0.100000, loss: 4.2695
2022-07-04 08:35:35 - train: epoch 0001, iter [04700, 05004], lr: 0.100000, loss: 4.0307
2022-07-04 08:36:09 - train: epoch 0001, iter [04800, 05004], lr: 0.100000, loss: 4.2698
2022-07-04 08:36:41 - train: epoch 0001, iter [04900, 05004], lr: 0.100000, loss: 3.9331
2022-07-04 08:37:13 - train: epoch 0001, iter [05000, 05004], lr: 0.100000, loss: 3.8990
2022-07-04 08:37:14 - train: epoch 001, train_loss: 4.9316
2022-07-04 08:38:27 - eval: epoch: 001, acc1: 22.638%, acc5: 46.272%, test_loss: 3.8077, per_image_load_time: 2.665ms, per_image_inference_time: 0.167ms
2022-07-04 08:38:28 - until epoch: 001, best_acc1: 22.638%
2022-07-04 08:38:28 - epoch 002 lr: 0.100000
2022-07-04 08:39:06 - train: epoch 0002, iter [00100, 05004], lr: 0.100000, loss: 4.0228
2022-07-04 08:39:38 - train: epoch 0002, iter [00200, 05004], lr: 0.100000, loss: 3.7969
2022-07-04 08:40:11 - train: epoch 0002, iter [00300, 05004], lr: 0.100000, loss: 4.0154
2022-07-04 08:40:44 - train: epoch 0002, iter [00400, 05004], lr: 0.100000, loss: 3.9193
2022-07-04 08:41:17 - train: epoch 0002, iter [00500, 05004], lr: 0.100000, loss: 3.6403
2022-07-04 08:41:49 - train: epoch 0002, iter [00600, 05004], lr: 0.100000, loss: 3.5995
2022-07-04 08:42:22 - train: epoch 0002, iter [00700, 05004], lr: 0.100000, loss: 3.8853
2022-07-04 08:42:56 - train: epoch 0002, iter [00800, 05004], lr: 0.100000, loss: 3.5364
2022-07-04 08:43:28 - train: epoch 0002, iter [00900, 05004], lr: 0.100000, loss: 3.3422
2022-07-04 08:44:02 - train: epoch 0002, iter [01000, 05004], lr: 0.100000, loss: 3.8968
2022-07-04 08:44:34 - train: epoch 0002, iter [01100, 05004], lr: 0.100000, loss: 3.8233
2022-07-04 08:45:08 - train: epoch 0002, iter [01200, 05004], lr: 0.100000, loss: 3.7388
2022-07-04 08:45:39 - train: epoch 0002, iter [01300, 05004], lr: 0.100000, loss: 3.6744
2022-07-04 08:46:13 - train: epoch 0002, iter [01400, 05004], lr: 0.100000, loss: 3.7874
2022-07-04 08:46:47 - train: epoch 0002, iter [01500, 05004], lr: 0.100000, loss: 3.7097
2022-07-04 08:47:19 - train: epoch 0002, iter [01600, 05004], lr: 0.100000, loss: 3.6461
2022-07-04 08:47:52 - train: epoch 0002, iter [01700, 05004], lr: 0.100000, loss: 3.6560
2022-07-04 08:48:25 - train: epoch 0002, iter [01800, 05004], lr: 0.100000, loss: 3.7144
2022-07-04 08:48:59 - train: epoch 0002, iter [01900, 05004], lr: 0.100000, loss: 3.5953
2022-07-04 08:49:32 - train: epoch 0002, iter [02000, 05004], lr: 0.100000, loss: 3.2949
2022-07-04 08:50:04 - train: epoch 0002, iter [02100, 05004], lr: 0.100000, loss: 3.5331
2022-07-04 08:50:36 - train: epoch 0002, iter [02200, 05004], lr: 0.100000, loss: 3.2621
2022-07-04 08:51:11 - train: epoch 0002, iter [02300, 05004], lr: 0.100000, loss: 3.4882
2022-07-04 08:51:42 - train: epoch 0002, iter [02400, 05004], lr: 0.100000, loss: 3.3833
2022-07-04 08:52:17 - train: epoch 0002, iter [02500, 05004], lr: 0.100000, loss: 3.3695
2022-07-04 08:52:49 - train: epoch 0002, iter [02600, 05004], lr: 0.100000, loss: 3.3533
2022-07-04 08:53:22 - train: epoch 0002, iter [02700, 05004], lr: 0.100000, loss: 3.5784
2022-07-04 08:53:54 - train: epoch 0002, iter [02800, 05004], lr: 0.100000, loss: 3.4724
2022-07-04 08:54:29 - train: epoch 0002, iter [02900, 05004], lr: 0.100000, loss: 3.3938
2022-07-04 08:55:01 - train: epoch 0002, iter [03000, 05004], lr: 0.100000, loss: 3.2849
2022-07-04 08:55:35 - train: epoch 0002, iter [03100, 05004], lr: 0.100000, loss: 3.3258
2022-07-04 08:56:07 - train: epoch 0002, iter [03200, 05004], lr: 0.100000, loss: 3.4656
2022-07-04 08:56:40 - train: epoch 0002, iter [03300, 05004], lr: 0.100000, loss: 3.3157
2022-07-04 08:57:13 - train: epoch 0002, iter [03400, 05004], lr: 0.100000, loss: 3.6075
2022-07-04 08:57:46 - train: epoch 0002, iter [03500, 05004], lr: 0.100000, loss: 3.3864
2022-07-04 08:58:20 - train: epoch 0002, iter [03600, 05004], lr: 0.100000, loss: 3.3464
2022-07-04 08:58:53 - train: epoch 0002, iter [03700, 05004], lr: 0.100000, loss: 3.4019
2022-07-04 08:59:26 - train: epoch 0002, iter [03800, 05004], lr: 0.100000, loss: 3.1937
2022-07-04 09:00:00 - train: epoch 0002, iter [03900, 05004], lr: 0.100000, loss: 3.4126
2022-07-04 09:00:33 - train: epoch 0002, iter [04000, 05004], lr: 0.100000, loss: 3.3017
2022-07-04 09:01:06 - train: epoch 0002, iter [04100, 05004], lr: 0.100000, loss: 3.4528
2022-07-04 09:01:39 - train: epoch 0002, iter [04200, 05004], lr: 0.100000, loss: 3.2157
2022-07-04 09:02:12 - train: epoch 0002, iter [04300, 05004], lr: 0.100000, loss: 3.2848
2022-07-04 09:02:46 - train: epoch 0002, iter [04400, 05004], lr: 0.100000, loss: 3.1144
2022-07-04 09:03:18 - train: epoch 0002, iter [04500, 05004], lr: 0.100000, loss: 3.2123
2022-07-04 09:03:52 - train: epoch 0002, iter [04600, 05004], lr: 0.100000, loss: 3.2431
2022-07-04 09:04:24 - train: epoch 0002, iter [04700, 05004], lr: 0.100000, loss: 3.3154
2022-07-04 09:04:58 - train: epoch 0002, iter [04800, 05004], lr: 0.100000, loss: 3.1787
2022-07-04 09:05:31 - train: epoch 0002, iter [04900, 05004], lr: 0.100000, loss: 3.1019
2022-07-04 09:06:03 - train: epoch 0002, iter [05000, 05004], lr: 0.100000, loss: 3.0806
2022-07-04 09:06:03 - train: epoch 002, train_loss: 3.5168
2022-07-04 09:07:17 - eval: epoch: 002, acc1: 33.782%, acc5: 60.256%, test_loss: 3.0730, per_image_load_time: 2.688ms, per_image_inference_time: 0.159ms
2022-07-04 09:07:17 - until epoch: 002, best_acc1: 33.782%
2022-07-04 09:07:17 - epoch 003 lr: 0.100000
2022-07-04 09:07:54 - train: epoch 0003, iter [00100, 05004], lr: 0.100000, loss: 3.2609
2022-07-04 09:08:29 - train: epoch 0003, iter [00200, 05004], lr: 0.100000, loss: 3.2370
2022-07-04 09:09:01 - train: epoch 0003, iter [00300, 05004], lr: 0.100000, loss: 3.1401
2022-07-04 09:09:34 - train: epoch 0003, iter [00400, 05004], lr: 0.100000, loss: 3.2297
2022-07-04 09:10:05 - train: epoch 0003, iter [00500, 05004], lr: 0.100000, loss: 3.4232
2022-07-04 09:10:40 - train: epoch 0003, iter [00600, 05004], lr: 0.100000, loss: 3.0887
2022-07-04 09:11:12 - train: epoch 0003, iter [00700, 05004], lr: 0.100000, loss: 3.3535
2022-07-04 09:11:45 - train: epoch 0003, iter [00800, 05004], lr: 0.100000, loss: 3.2058
2022-07-04 09:12:18 - train: epoch 0003, iter [00900, 05004], lr: 0.100000, loss: 3.0620
2022-07-04 09:12:50 - train: epoch 0003, iter [01000, 05004], lr: 0.100000, loss: 3.0713
2022-07-04 09:13:24 - train: epoch 0003, iter [01100, 05004], lr: 0.100000, loss: 2.9921
2022-07-04 09:13:57 - train: epoch 0003, iter [01200, 05004], lr: 0.100000, loss: 3.0301
2022-07-04 09:14:30 - train: epoch 0003, iter [01300, 05004], lr: 0.100000, loss: 3.1402
2022-07-04 09:15:03 - train: epoch 0003, iter [01400, 05004], lr: 0.100000, loss: 3.0612
2022-07-04 09:15:36 - train: epoch 0003, iter [01500, 05004], lr: 0.100000, loss: 3.3255
2022-07-04 09:16:08 - train: epoch 0003, iter [01600, 05004], lr: 0.100000, loss: 3.0295
2022-07-04 09:16:42 - train: epoch 0003, iter [01700, 05004], lr: 0.100000, loss: 3.0774
2022-07-04 09:17:15 - train: epoch 0003, iter [01800, 05004], lr: 0.100000, loss: 2.9956
2022-07-04 09:17:49 - train: epoch 0003, iter [01900, 05004], lr: 0.100000, loss: 3.1618
2022-07-04 09:18:21 - train: epoch 0003, iter [02000, 05004], lr: 0.100000, loss: 3.4688
2022-07-04 09:18:55 - train: epoch 0003, iter [02100, 05004], lr: 0.100000, loss: 3.2746
2022-07-04 09:19:28 - train: epoch 0003, iter [02200, 05004], lr: 0.100000, loss: 3.5762
2022-07-04 09:20:00 - train: epoch 0003, iter [02300, 05004], lr: 0.100000, loss: 3.0639
2022-07-04 09:20:34 - train: epoch 0003, iter [02400, 05004], lr: 0.100000, loss: 3.0060
2022-07-04 09:21:08 - train: epoch 0003, iter [02500, 05004], lr: 0.100000, loss: 3.1044
2022-07-04 09:21:40 - train: epoch 0003, iter [02600, 05004], lr: 0.100000, loss: 3.1177
2022-07-04 09:22:14 - train: epoch 0003, iter [02700, 05004], lr: 0.100000, loss: 3.3270
2022-07-04 09:22:47 - train: epoch 0003, iter [02800, 05004], lr: 0.100000, loss: 2.9563
2022-07-04 09:23:20 - train: epoch 0003, iter [02900, 05004], lr: 0.100000, loss: 3.0162
2022-07-04 09:23:53 - train: epoch 0003, iter [03000, 05004], lr: 0.100000, loss: 3.2293
2022-07-04 09:24:26 - train: epoch 0003, iter [03100, 05004], lr: 0.100000, loss: 3.1560
2022-07-04 09:25:00 - train: epoch 0003, iter [03200, 05004], lr: 0.100000, loss: 3.0970
2022-07-04 09:25:33 - train: epoch 0003, iter [03300, 05004], lr: 0.100000, loss: 3.1210
2022-07-04 09:26:07 - train: epoch 0003, iter [03400, 05004], lr: 0.100000, loss: 3.2279
2022-07-04 09:26:40 - train: epoch 0003, iter [03500, 05004], lr: 0.100000, loss: 2.8560
2022-07-04 09:27:13 - train: epoch 0003, iter [03600, 05004], lr: 0.100000, loss: 2.8428
2022-07-04 09:27:47 - train: epoch 0003, iter [03700, 05004], lr: 0.100000, loss: 2.9683
2022-07-04 09:28:20 - train: epoch 0003, iter [03800, 05004], lr: 0.100000, loss: 3.0263
2022-07-04 09:28:53 - train: epoch 0003, iter [03900, 05004], lr: 0.100000, loss: 3.1975
2022-07-04 09:29:26 - train: epoch 0003, iter [04000, 05004], lr: 0.100000, loss: 3.0081
2022-07-04 09:29:59 - train: epoch 0003, iter [04100, 05004], lr: 0.100000, loss: 3.0824
2022-07-04 09:30:32 - train: epoch 0003, iter [04200, 05004], lr: 0.100000, loss: 2.9499
2022-07-04 09:31:05 - train: epoch 0003, iter [04300, 05004], lr: 0.100000, loss: 2.6409
2022-07-04 09:31:39 - train: epoch 0003, iter [04400, 05004], lr: 0.100000, loss: 2.8496
2022-07-04 09:32:12 - train: epoch 0003, iter [04500, 05004], lr: 0.100000, loss: 3.0079
2022-07-04 09:32:46 - train: epoch 0003, iter [04600, 05004], lr: 0.100000, loss: 2.9397
2022-07-04 09:33:19 - train: epoch 0003, iter [04700, 05004], lr: 0.100000, loss: 2.8617
2022-07-04 09:33:53 - train: epoch 0003, iter [04800, 05004], lr: 0.100000, loss: 3.1891
2022-07-04 09:34:25 - train: epoch 0003, iter [04900, 05004], lr: 0.100000, loss: 3.1540
2022-07-04 09:34:57 - train: epoch 0003, iter [05000, 05004], lr: 0.100000, loss: 2.9493
2022-07-04 09:34:57 - train: epoch 003, train_loss: 3.0672
2022-07-04 09:36:10 - eval: epoch: 003, acc1: 37.332%, acc5: 63.786%, test_loss: 2.8801, per_image_load_time: 2.663ms, per_image_inference_time: 0.162ms
2022-07-04 09:36:10 - until epoch: 003, best_acc1: 37.332%
2022-07-04 09:36:10 - epoch 004 lr: 0.100000
2022-07-04 09:36:48 - train: epoch 0004, iter [00100, 05004], lr: 0.100000, loss: 2.9679
2022-07-04 09:37:21 - train: epoch 0004, iter [00200, 05004], lr: 0.100000, loss: 2.9112
2022-07-04 09:37:54 - train: epoch 0004, iter [00300, 05004], lr: 0.100000, loss: 2.9172
2022-07-04 09:38:28 - train: epoch 0004, iter [00400, 05004], lr: 0.100000, loss: 2.8488
2022-07-04 09:39:00 - train: epoch 0004, iter [00500, 05004], lr: 0.100000, loss: 2.7082
2022-07-04 09:39:32 - train: epoch 0004, iter [00600, 05004], lr: 0.100000, loss: 2.9952
2022-07-04 09:40:06 - train: epoch 0004, iter [00700, 05004], lr: 0.100000, loss: 2.9732
2022-07-04 09:40:38 - train: epoch 0004, iter [00800, 05004], lr: 0.100000, loss: 2.6656
2022-07-04 09:41:12 - train: epoch 0004, iter [00900, 05004], lr: 0.100000, loss: 2.5853
2022-07-04 09:41:44 - train: epoch 0004, iter [01000, 05004], lr: 0.100000, loss: 2.9112
2022-07-04 09:42:18 - train: epoch 0004, iter [01100, 05004], lr: 0.100000, loss: 3.0080
2022-07-04 09:42:51 - train: epoch 0004, iter [01200, 05004], lr: 0.100000, loss: 2.7434
2022-07-04 09:43:23 - train: epoch 0004, iter [01300, 05004], lr: 0.100000, loss: 2.6929
2022-07-04 09:43:56 - train: epoch 0004, iter [01400, 05004], lr: 0.100000, loss: 2.9830
2022-07-04 09:44:29 - train: epoch 0004, iter [01500, 05004], lr: 0.100000, loss: 3.0348
2022-07-04 09:45:02 - train: epoch 0004, iter [01600, 05004], lr: 0.100000, loss: 2.7831
2022-07-04 09:45:35 - train: epoch 0004, iter [01700, 05004], lr: 0.100000, loss: 2.9762
2022-07-04 09:46:08 - train: epoch 0004, iter [01800, 05004], lr: 0.100000, loss: 3.1028
2022-07-04 09:46:41 - train: epoch 0004, iter [01900, 05004], lr: 0.100000, loss: 3.0160
2022-07-04 09:47:14 - train: epoch 0004, iter [02000, 05004], lr: 0.100000, loss: 2.8040
2022-07-04 09:47:48 - train: epoch 0004, iter [02100, 05004], lr: 0.100000, loss: 2.9479
2022-07-04 09:48:20 - train: epoch 0004, iter [02200, 05004], lr: 0.100000, loss: 2.9001
2022-07-04 09:48:53 - train: epoch 0004, iter [02300, 05004], lr: 0.100000, loss: 2.6837
2022-07-04 09:49:26 - train: epoch 0004, iter [02400, 05004], lr: 0.100000, loss: 2.7948
2022-07-04 09:50:00 - train: epoch 0004, iter [02500, 05004], lr: 0.100000, loss: 2.7195
2022-07-04 09:50:33 - train: epoch 0004, iter [02600, 05004], lr: 0.100000, loss: 2.8724
2022-07-04 09:51:06 - train: epoch 0004, iter [02700, 05004], lr: 0.100000, loss: 2.7164
2022-07-04 09:51:38 - train: epoch 0004, iter [02800, 05004], lr: 0.100000, loss: 2.8000
2022-07-04 09:52:13 - train: epoch 0004, iter [02900, 05004], lr: 0.100000, loss: 2.7830
2022-07-04 09:52:44 - train: epoch 0004, iter [03000, 05004], lr: 0.100000, loss: 2.8214
2022-07-04 09:53:18 - train: epoch 0004, iter [03100, 05004], lr: 0.100000, loss: 2.8921
2022-07-04 09:53:51 - train: epoch 0004, iter [03200, 05004], lr: 0.100000, loss: 2.7790
2022-07-04 09:54:23 - train: epoch 0004, iter [03300, 05004], lr: 0.100000, loss: 2.8784
2022-07-04 09:54:56 - train: epoch 0004, iter [03400, 05004], lr: 0.100000, loss: 2.8908
2022-07-04 09:55:29 - train: epoch 0004, iter [03500, 05004], lr: 0.100000, loss: 2.7324
2022-07-04 09:56:02 - train: epoch 0004, iter [03600, 05004], lr: 0.100000, loss: 2.6802
2022-07-04 09:56:35 - train: epoch 0004, iter [03700, 05004], lr: 0.100000, loss: 2.8272
2022-07-04 09:57:10 - train: epoch 0004, iter [03800, 05004], lr: 0.100000, loss: 2.7242
2022-07-04 09:57:42 - train: epoch 0004, iter [03900, 05004], lr: 0.100000, loss: 2.8312
2022-07-04 09:58:15 - train: epoch 0004, iter [04000, 05004], lr: 0.100000, loss: 2.4431
2022-07-04 09:58:48 - train: epoch 0004, iter [04100, 05004], lr: 0.100000, loss: 2.8654
2022-07-04 09:59:23 - train: epoch 0004, iter [04200, 05004], lr: 0.100000, loss: 2.7332
2022-07-04 09:59:55 - train: epoch 0004, iter [04300, 05004], lr: 0.100000, loss: 2.6367
2022-07-04 10:00:29 - train: epoch 0004, iter [04400, 05004], lr: 0.100000, loss: 2.5996
2022-07-04 10:01:01 - train: epoch 0004, iter [04500, 05004], lr: 0.100000, loss: 2.3274
2022-07-04 10:01:34 - train: epoch 0004, iter [04600, 05004], lr: 0.100000, loss: 2.7404
2022-07-04 10:02:08 - train: epoch 0004, iter [04700, 05004], lr: 0.100000, loss: 2.6817
2022-07-04 10:02:41 - train: epoch 0004, iter [04800, 05004], lr: 0.100000, loss: 2.6899
2022-07-04 10:03:15 - train: epoch 0004, iter [04900, 05004], lr: 0.100000, loss: 2.8796
2022-07-04 10:03:46 - train: epoch 0004, iter [05000, 05004], lr: 0.100000, loss: 2.7992
2022-07-04 10:03:47 - train: epoch 004, train_loss: 2.8607
2022-07-04 10:05:00 - eval: epoch: 004, acc1: 43.176%, acc5: 69.528%, test_loss: 2.5402, per_image_load_time: 2.647ms, per_image_inference_time: 0.173ms
2022-07-04 10:05:00 - until epoch: 004, best_acc1: 43.176%
2022-07-04 10:05:00 - epoch 005 lr: 0.100000
2022-07-04 10:05:38 - train: epoch 0005, iter [00100, 05004], lr: 0.100000, loss: 2.8740
2022-07-04 10:06:11 - train: epoch 0005, iter [00200, 05004], lr: 0.100000, loss: 2.7728
2022-07-04 10:06:44 - train: epoch 0005, iter [00300, 05004], lr: 0.100000, loss: 2.9325
2022-07-04 10:07:16 - train: epoch 0005, iter [00400, 05004], lr: 0.100000, loss: 2.7596
2022-07-04 10:07:50 - train: epoch 0005, iter [00500, 05004], lr: 0.100000, loss: 2.5292
2022-07-04 10:08:22 - train: epoch 0005, iter [00600, 05004], lr: 0.100000, loss: 2.8248
2022-07-04 10:08:56 - train: epoch 0005, iter [00700, 05004], lr: 0.100000, loss: 2.6602
2022-07-04 10:09:28 - train: epoch 0005, iter [00800, 05004], lr: 0.100000, loss: 2.9266
2022-07-04 10:10:01 - train: epoch 0005, iter [00900, 05004], lr: 0.100000, loss: 2.6020
2022-07-04 10:10:35 - train: epoch 0005, iter [01000, 05004], lr: 0.100000, loss: 2.8187
2022-07-04 10:11:08 - train: epoch 0005, iter [01100, 05004], lr: 0.100000, loss: 2.8180
2022-07-04 10:11:41 - train: epoch 0005, iter [01200, 05004], lr: 0.100000, loss: 2.8765
2022-07-04 10:12:14 - train: epoch 0005, iter [01300, 05004], lr: 0.100000, loss: 2.6984
2022-07-04 10:12:48 - train: epoch 0005, iter [01400, 05004], lr: 0.100000, loss: 2.8276
2022-07-04 10:13:20 - train: epoch 0005, iter [01500, 05004], lr: 0.100000, loss: 2.5269
2022-07-04 10:13:54 - train: epoch 0005, iter [01600, 05004], lr: 0.100000, loss: 2.5793
2022-07-04 10:14:26 - train: epoch 0005, iter [01700, 05004], lr: 0.100000, loss: 2.7044
2022-07-04 10:15:00 - train: epoch 0005, iter [01800, 05004], lr: 0.100000, loss: 2.7769
2022-07-04 10:15:32 - train: epoch 0005, iter [01900, 05004], lr: 0.100000, loss: 2.6011
2022-07-04 10:16:06 - train: epoch 0005, iter [02000, 05004], lr: 0.100000, loss: 2.7837
2022-07-04 10:16:39 - train: epoch 0005, iter [02100, 05004], lr: 0.100000, loss: 2.6022
2022-07-04 10:17:13 - train: epoch 0005, iter [02200, 05004], lr: 0.100000, loss: 2.5313
2022-07-04 10:17:45 - train: epoch 0005, iter [02300, 05004], lr: 0.100000, loss: 2.5726
2022-07-04 10:18:19 - train: epoch 0005, iter [02400, 05004], lr: 0.100000, loss: 2.6474
2022-07-04 10:18:51 - train: epoch 0005, iter [02500, 05004], lr: 0.100000, loss: 2.8775
2022-07-04 10:19:26 - train: epoch 0005, iter [02600, 05004], lr: 0.100000, loss: 2.9568
2022-07-04 10:19:58 - train: epoch 0005, iter [02700, 05004], lr: 0.100000, loss: 2.8036
2022-07-04 10:20:32 - train: epoch 0005, iter [02800, 05004], lr: 0.100000, loss: 2.7037
2022-07-04 10:21:04 - train: epoch 0005, iter [02900, 05004], lr: 0.100000, loss: 2.6552
2022-07-04 10:21:38 - train: epoch 0005, iter [03000, 05004], lr: 0.100000, loss: 2.7139
2022-07-04 10:22:11 - train: epoch 0005, iter [03100, 05004], lr: 0.100000, loss: 2.7697
2022-07-04 10:22:45 - train: epoch 0005, iter [03200, 05004], lr: 0.100000, loss: 2.7970
2022-07-04 10:23:17 - train: epoch 0005, iter [03300, 05004], lr: 0.100000, loss: 2.5103
2022-07-04 10:23:51 - train: epoch 0005, iter [03400, 05004], lr: 0.100000, loss: 2.6696
2022-07-04 10:24:24 - train: epoch 0005, iter [03500, 05004], lr: 0.100000, loss: 2.6663
2022-07-04 10:24:57 - train: epoch 0005, iter [03600, 05004], lr: 0.100000, loss: 2.7951
2022-07-04 10:25:30 - train: epoch 0005, iter [03700, 05004], lr: 0.100000, loss: 2.6079
2022-07-04 10:26:05 - train: epoch 0005, iter [03800, 05004], lr: 0.100000, loss: 2.4675
2022-07-04 10:26:37 - train: epoch 0005, iter [03900, 05004], lr: 0.100000, loss: 3.0144
2022-07-04 10:27:11 - train: epoch 0005, iter [04000, 05004], lr: 0.100000, loss: 2.7263
2022-07-04 10:27:43 - train: epoch 0005, iter [04100, 05004], lr: 0.100000, loss: 2.7391
2022-07-04 10:28:15 - train: epoch 0005, iter [04200, 05004], lr: 0.100000, loss: 2.8467
2022-07-04 10:28:49 - train: epoch 0005, iter [04300, 05004], lr: 0.100000, loss: 2.5970
2022-07-04 10:29:23 - train: epoch 0005, iter [04400, 05004], lr: 0.100000, loss: 2.8213
2022-07-04 10:29:55 - train: epoch 0005, iter [04500, 05004], lr: 0.100000, loss: 2.7867
2022-07-04 10:30:29 - train: epoch 0005, iter [04600, 05004], lr: 0.100000, loss: 2.6141
2022-07-04 10:31:01 - train: epoch 0005, iter [04700, 05004], lr: 0.100000, loss: 2.4528
2022-07-04 10:31:35 - train: epoch 0005, iter [04800, 05004], lr: 0.100000, loss: 2.4971
2022-07-04 10:32:08 - train: epoch 0005, iter [04900, 05004], lr: 0.100000, loss: 2.7899
2022-07-04 10:32:40 - train: epoch 0005, iter [05000, 05004], lr: 0.100000, loss: 2.5454
2022-07-04 10:32:41 - train: epoch 005, train_loss: 2.7421
2022-07-04 10:33:55 - eval: epoch: 005, acc1: 43.034%, acc5: 69.956%, test_loss: 2.5308, per_image_load_time: 2.714ms, per_image_inference_time: 0.163ms
2022-07-04 10:33:55 - until epoch: 005, best_acc1: 43.176%
2022-07-04 10:33:55 - epoch 006 lr: 0.100000
2022-07-04 10:34:32 - train: epoch 0006, iter [00100, 05004], lr: 0.100000, loss: 2.7500
2022-07-04 10:35:06 - train: epoch 0006, iter [00200, 05004], lr: 0.100000, loss: 2.6743
2022-07-04 10:35:39 - train: epoch 0006, iter [00300, 05004], lr: 0.100000, loss: 2.5039
2022-07-04 10:36:11 - train: epoch 0006, iter [00400, 05004], lr: 0.100000, loss: 2.6845
2022-07-04 10:36:45 - train: epoch 0006, iter [00500, 05004], lr: 0.100000, loss: 2.7188
2022-07-04 10:37:19 - train: epoch 0006, iter [00600, 05004], lr: 0.100000, loss: 2.7097
2022-07-04 10:37:52 - train: epoch 0006, iter [00700, 05004], lr: 0.100000, loss: 2.7124
2022-07-04 10:38:24 - train: epoch 0006, iter [00800, 05004], lr: 0.100000, loss: 2.7971
2022-07-04 10:38:58 - train: epoch 0006, iter [00900, 05004], lr: 0.100000, loss: 2.6021
2022-07-04 10:39:31 - train: epoch 0006, iter [01000, 05004], lr: 0.100000, loss: 2.5723
2022-07-04 10:40:05 - train: epoch 0006, iter [01100, 05004], lr: 0.100000, loss: 2.6527
2022-07-04 10:40:37 - train: epoch 0006, iter [01200, 05004], lr: 0.100000, loss: 2.8355
2022-07-04 10:41:11 - train: epoch 0006, iter [01300, 05004], lr: 0.100000, loss: 2.8191
2022-07-04 10:41:43 - train: epoch 0006, iter [01400, 05004], lr: 0.100000, loss: 2.7266
2022-07-04 10:42:17 - train: epoch 0006, iter [01500, 05004], lr: 0.100000, loss: 2.8538
2022-07-04 10:42:49 - train: epoch 0006, iter [01600, 05004], lr: 0.100000, loss: 2.4883
2022-07-04 10:43:23 - train: epoch 0006, iter [01700, 05004], lr: 0.100000, loss: 2.7635
2022-07-04 10:43:55 - train: epoch 0006, iter [01800, 05004], lr: 0.100000, loss: 2.8197
2022-07-04 10:44:29 - train: epoch 0006, iter [01900, 05004], lr: 0.100000, loss: 2.5158
2022-07-04 10:45:02 - train: epoch 0006, iter [02000, 05004], lr: 0.100000, loss: 2.7875
2022-07-04 10:45:36 - train: epoch 0006, iter [02100, 05004], lr: 0.100000, loss: 2.8678
2022-07-04 10:46:08 - train: epoch 0006, iter [02200, 05004], lr: 0.100000, loss: 2.5436
2022-07-04 10:46:42 - train: epoch 0006, iter [02300, 05004], lr: 0.100000, loss: 2.5504
2022-07-04 10:47:13 - train: epoch 0006, iter [02400, 05004], lr: 0.100000, loss: 2.6607
2022-07-04 10:47:48 - train: epoch 0006, iter [02500, 05004], lr: 0.100000, loss: 2.8705
2022-07-04 10:48:20 - train: epoch 0006, iter [02600, 05004], lr: 0.100000, loss: 2.5789
2022-07-04 10:48:54 - train: epoch 0006, iter [02700, 05004], lr: 0.100000, loss: 2.7936
2022-07-04 10:49:26 - train: epoch 0006, iter [02800, 05004], lr: 0.100000, loss: 2.4681
2022-07-04 10:50:00 - train: epoch 0006, iter [02900, 05004], lr: 0.100000, loss: 2.8280
2022-07-04 10:50:32 - train: epoch 0006, iter [03000, 05004], lr: 0.100000, loss: 2.6221
2022-07-04 10:51:05 - train: epoch 0006, iter [03100, 05004], lr: 0.100000, loss: 2.4538
2022-07-04 10:51:39 - train: epoch 0006, iter [03200, 05004], lr: 0.100000, loss: 2.6316
2022-07-04 10:52:11 - train: epoch 0006, iter [03300, 05004], lr: 0.100000, loss: 2.5728
2022-07-04 10:52:46 - train: epoch 0006, iter [03400, 05004], lr: 0.100000, loss: 2.8686
2022-07-04 10:53:19 - train: epoch 0006, iter [03500, 05004], lr: 0.100000, loss: 2.7807
2022-07-04 10:53:53 - train: epoch 0006, iter [03600, 05004], lr: 0.100000, loss: 2.5925
2022-07-04 10:54:26 - train: epoch 0006, iter [03700, 05004], lr: 0.100000, loss: 2.6761
2022-07-04 10:54:59 - train: epoch 0006, iter [03800, 05004], lr: 0.100000, loss: 2.5844
2022-07-04 10:55:31 - train: epoch 0006, iter [03900, 05004], lr: 0.100000, loss: 2.6180
2022-07-04 10:56:05 - train: epoch 0006, iter [04000, 05004], lr: 0.100000, loss: 2.8664
2022-07-04 10:56:40 - train: epoch 0006, iter [04100, 05004], lr: 0.100000, loss: 2.5666
2022-07-04 10:57:12 - train: epoch 0006, iter [04200, 05004], lr: 0.100000, loss: 2.4280
2022-07-04 10:57:46 - train: epoch 0006, iter [04300, 05004], lr: 0.100000, loss: 2.6295
2022-07-04 10:58:19 - train: epoch 0006, iter [04400, 05004], lr: 0.100000, loss: 2.7136
2022-07-04 10:58:53 - train: epoch 0006, iter [04500, 05004], lr: 0.100000, loss: 2.6591
2022-07-04 10:59:26 - train: epoch 0006, iter [04600, 05004], lr: 0.100000, loss: 2.7323
2022-07-04 11:00:01 - train: epoch 0006, iter [04700, 05004], lr: 0.100000, loss: 2.6724
2022-07-04 11:00:32 - train: epoch 0006, iter [04800, 05004], lr: 0.100000, loss: 2.6006
2022-07-04 11:01:07 - train: epoch 0006, iter [04900, 05004], lr: 0.100000, loss: 2.6989
2022-07-04 11:01:38 - train: epoch 0006, iter [05000, 05004], lr: 0.100000, loss: 2.4993
2022-07-04 11:01:38 - train: epoch 006, train_loss: 2.6687
2022-07-04 11:02:52 - eval: epoch: 006, acc1: 45.964%, acc5: 72.356%, test_loss: 2.3829, per_image_load_time: 2.677ms, per_image_inference_time: 0.169ms
2022-07-04 11:02:52 - until epoch: 006, best_acc1: 45.964%
2022-07-04 11:02:52 - epoch 007 lr: 0.100000
2022-07-04 11:03:30 - train: epoch 0007, iter [00100, 05004], lr: 0.100000, loss: 2.4726
2022-07-04 11:04:03 - train: epoch 0007, iter [00200, 05004], lr: 0.100000, loss: 2.8392
2022-07-04 11:04:36 - train: epoch 0007, iter [00300, 05004], lr: 0.100000, loss: 2.7977
2022-07-04 11:05:09 - train: epoch 0007, iter [00400, 05004], lr: 0.100000, loss: 2.7678
2022-07-04 11:05:43 - train: epoch 0007, iter [00500, 05004], lr: 0.100000, loss: 2.5602
2022-07-04 11:06:15 - train: epoch 0007, iter [00600, 05004], lr: 0.100000, loss: 2.7824
2022-07-04 11:06:49 - train: epoch 0007, iter [00700, 05004], lr: 0.100000, loss: 2.5411
2022-07-04 11:07:21 - train: epoch 0007, iter [00800, 05004], lr: 0.100000, loss: 2.6171
2022-07-04 11:07:53 - train: epoch 0007, iter [00900, 05004], lr: 0.100000, loss: 2.6251
2022-07-04 11:08:26 - train: epoch 0007, iter [01000, 05004], lr: 0.100000, loss: 2.6593
2022-07-04 11:08:59 - train: epoch 0007, iter [01100, 05004], lr: 0.100000, loss: 2.4906
2022-07-04 11:09:32 - train: epoch 0007, iter [01200, 05004], lr: 0.100000, loss: 2.6714
2022-07-04 11:10:06 - train: epoch 0007, iter [01300, 05004], lr: 0.100000, loss: 2.5304
2022-07-04 11:10:39 - train: epoch 0007, iter [01400, 05004], lr: 0.100000, loss: 2.6051
2022-07-04 11:11:11 - train: epoch 0007, iter [01500, 05004], lr: 0.100000, loss: 2.6958
2022-07-04 11:11:44 - train: epoch 0007, iter [01600, 05004], lr: 0.100000, loss: 2.5393
2022-07-04 11:12:18 - train: epoch 0007, iter [01700, 05004], lr: 0.100000, loss: 2.7060
2022-07-04 11:12:50 - train: epoch 0007, iter [01800, 05004], lr: 0.100000, loss: 2.5299
2022-07-04 11:13:24 - train: epoch 0007, iter [01900, 05004], lr: 0.100000, loss: 2.6818
2022-07-04 11:13:57 - train: epoch 0007, iter [02000, 05004], lr: 0.100000, loss: 2.4547
2022-07-04 11:14:30 - train: epoch 0007, iter [02100, 05004], lr: 0.100000, loss: 2.6997
2022-07-04 11:15:02 - train: epoch 0007, iter [02200, 05004], lr: 0.100000, loss: 2.4263
2022-07-04 11:15:35 - train: epoch 0007, iter [02300, 05004], lr: 0.100000, loss: 2.6819
2022-07-04 11:16:10 - train: epoch 0007, iter [02400, 05004], lr: 0.100000, loss: 2.6362
2022-07-04 11:16:43 - train: epoch 0007, iter [02500, 05004], lr: 0.100000, loss: 2.6037
2022-07-04 11:17:16 - train: epoch 0007, iter [02600, 05004], lr: 0.100000, loss: 2.5089
2022-07-04 11:17:50 - train: epoch 0007, iter [02700, 05004], lr: 0.100000, loss: 2.4859
2022-07-04 11:18:22 - train: epoch 0007, iter [02800, 05004], lr: 0.100000, loss: 2.5784
2022-07-04 11:18:56 - train: epoch 0007, iter [02900, 05004], lr: 0.100000, loss: 2.6255
2022-07-04 11:19:28 - train: epoch 0007, iter [03000, 05004], lr: 0.100000, loss: 2.6609
2022-07-04 11:20:02 - train: epoch 0007, iter [03100, 05004], lr: 0.100000, loss: 2.5107
2022-07-04 11:20:35 - train: epoch 0007, iter [03200, 05004], lr: 0.100000, loss: 2.6039
2022-07-04 11:21:09 - train: epoch 0007, iter [03300, 05004], lr: 0.100000, loss: 2.8914
2022-07-04 11:21:40 - train: epoch 0007, iter [03400, 05004], lr: 0.100000, loss: 2.4697
2022-07-04 11:22:14 - train: epoch 0007, iter [03500, 05004], lr: 0.100000, loss: 2.6171
2022-07-04 11:22:47 - train: epoch 0007, iter [03600, 05004], lr: 0.100000, loss: 2.3937
2022-07-04 11:23:20 - train: epoch 0007, iter [03700, 05004], lr: 0.100000, loss: 2.5940
2022-07-04 11:23:54 - train: epoch 0007, iter [03800, 05004], lr: 0.100000, loss: 2.7505
2022-07-04 11:24:27 - train: epoch 0007, iter [03900, 05004], lr: 0.100000, loss: 2.5341
2022-07-04 11:25:01 - train: epoch 0007, iter [04000, 05004], lr: 0.100000, loss: 2.7255
2022-07-04 11:25:34 - train: epoch 0007, iter [04100, 05004], lr: 0.100000, loss: 2.5187
2022-07-04 11:26:06 - train: epoch 0007, iter [04200, 05004], lr: 0.100000, loss: 2.4568
2022-07-04 11:26:39 - train: epoch 0007, iter [04300, 05004], lr: 0.100000, loss: 2.7179
2022-07-04 11:27:13 - train: epoch 0007, iter [04400, 05004], lr: 0.100000, loss: 2.4426
2022-07-04 11:27:45 - train: epoch 0007, iter [04500, 05004], lr: 0.100000, loss: 2.7837
2022-07-04 11:28:19 - train: epoch 0007, iter [04600, 05004], lr: 0.100000, loss: 2.7889
2022-07-04 11:28:52 - train: epoch 0007, iter [04700, 05004], lr: 0.100000, loss: 2.7192
2022-07-04 11:29:26 - train: epoch 0007, iter [04800, 05004], lr: 0.100000, loss: 2.9998
2022-07-04 11:29:59 - train: epoch 0007, iter [04900, 05004], lr: 0.100000, loss: 2.6533
2022-07-04 11:30:31 - train: epoch 0007, iter [05000, 05004], lr: 0.100000, loss: 2.6043
2022-07-04 11:30:31 - train: epoch 007, train_loss: 2.6164
2022-07-04 11:31:45 - eval: epoch: 007, acc1: 44.468%, acc5: 70.450%, test_loss: 2.4853, per_image_load_time: 2.130ms, per_image_inference_time: 0.178ms
2022-07-04 11:31:45 - until epoch: 007, best_acc1: 45.964%
2022-07-04 11:31:45 - epoch 008 lr: 0.100000
2022-07-04 11:32:23 - train: epoch 0008, iter [00100, 05004], lr: 0.100000, loss: 2.5328
2022-07-04 11:32:56 - train: epoch 0008, iter [00200, 05004], lr: 0.100000, loss: 2.8178
2022-07-04 11:33:28 - train: epoch 0008, iter [00300, 05004], lr: 0.100000, loss: 2.3486
2022-07-04 11:34:02 - train: epoch 0008, iter [00400, 05004], lr: 0.100000, loss: 2.4519
2022-07-04 11:34:33 - train: epoch 0008, iter [00500, 05004], lr: 0.100000, loss: 2.4824
2022-07-04 11:35:06 - train: epoch 0008, iter [00600, 05004], lr: 0.100000, loss: 2.5024
2022-07-04 11:35:40 - train: epoch 0008, iter [00700, 05004], lr: 0.100000, loss: 2.9057
2022-07-04 11:36:12 - train: epoch 0008, iter [00800, 05004], lr: 0.100000, loss: 2.2955
2022-07-04 11:36:45 - train: epoch 0008, iter [00900, 05004], lr: 0.100000, loss: 2.5612
2022-07-04 11:37:18 - train: epoch 0008, iter [01000, 05004], lr: 0.100000, loss: 2.6407
2022-07-04 11:37:51 - train: epoch 0008, iter [01100, 05004], lr: 0.100000, loss: 2.3182
2022-07-04 11:38:24 - train: epoch 0008, iter [01200, 05004], lr: 0.100000, loss: 2.4336
2022-07-04 11:38:57 - train: epoch 0008, iter [01300, 05004], lr: 0.100000, loss: 2.5352
2022-07-04 11:39:30 - train: epoch 0008, iter [01400, 05004], lr: 0.100000, loss: 2.4820
2022-07-04 11:40:02 - train: epoch 0008, iter [01500, 05004], lr: 0.100000, loss: 2.6434
2022-07-04 11:40:36 - train: epoch 0008, iter [01600, 05004], lr: 0.100000, loss: 2.6269
2022-07-04 11:41:09 - train: epoch 0008, iter [01700, 05004], lr: 0.100000, loss: 2.4582
2022-07-04 11:41:43 - train: epoch 0008, iter [01800, 05004], lr: 0.100000, loss: 2.7359
2022-07-04 11:42:15 - train: epoch 0008, iter [01900, 05004], lr: 0.100000, loss: 2.4409
2022-07-04 11:42:49 - train: epoch 0008, iter [02000, 05004], lr: 0.100000, loss: 2.5943
2022-07-04 11:43:22 - train: epoch 0008, iter [02100, 05004], lr: 0.100000, loss: 2.5576
2022-07-04 11:43:56 - train: epoch 0008, iter [02200, 05004], lr: 0.100000, loss: 2.5003
2022-07-04 11:44:28 - train: epoch 0008, iter [02300, 05004], lr: 0.100000, loss: 2.7405
2022-07-04 11:45:01 - train: epoch 0008, iter [02400, 05004], lr: 0.100000, loss: 2.5045
2022-07-04 11:45:33 - train: epoch 0008, iter [02500, 05004], lr: 0.100000, loss: 2.5915
2022-07-04 11:46:08 - train: epoch 0008, iter [02600, 05004], lr: 0.100000, loss: 2.8584
2022-07-04 11:46:40 - train: epoch 0008, iter [02700, 05004], lr: 0.100000, loss: 2.6498
2022-07-04 11:47:14 - train: epoch 0008, iter [02800, 05004], lr: 0.100000, loss: 2.5747
2022-07-04 11:47:46 - train: epoch 0008, iter [02900, 05004], lr: 0.100000, loss: 2.4998
2022-07-04 11:48:20 - train: epoch 0008, iter [03000, 05004], lr: 0.100000, loss: 2.5942
2022-07-04 11:48:52 - train: epoch 0008, iter [03100, 05004], lr: 0.100000, loss: 2.6038
2022-07-04 11:49:26 - train: epoch 0008, iter [03200, 05004], lr: 0.100000, loss: 2.7900
2022-07-04 11:49:59 - train: epoch 0008, iter [03300, 05004], lr: 0.100000, loss: 2.7099
2022-07-04 11:50:31 - train: epoch 0008, iter [03400, 05004], lr: 0.100000, loss: 2.7930
2022-07-04 11:51:04 - train: epoch 0008, iter [03500, 05004], lr: 0.100000, loss: 2.5469
2022-07-04 11:51:37 - train: epoch 0008, iter [03600, 05004], lr: 0.100000, loss: 2.6696
2022-07-04 11:52:11 - train: epoch 0008, iter [03700, 05004], lr: 0.100000, loss: 2.4935
2022-07-04 11:52:44 - train: epoch 0008, iter [03800, 05004], lr: 0.100000, loss: 2.4936
2022-07-04 11:53:16 - train: epoch 0008, iter [03900, 05004], lr: 0.100000, loss: 2.7703
2022-07-04 11:53:51 - train: epoch 0008, iter [04000, 05004], lr: 0.100000, loss: 2.7930
2022-07-04 11:54:23 - train: epoch 0008, iter [04100, 05004], lr: 0.100000, loss: 2.4490
2022-07-04 11:54:56 - train: epoch 0008, iter [04200, 05004], lr: 0.100000, loss: 2.5412
2022-07-04 11:55:31 - train: epoch 0008, iter [04300, 05004], lr: 0.100000, loss: 2.2967
2022-07-04 11:56:03 - train: epoch 0008, iter [04400, 05004], lr: 0.100000, loss: 2.4248
2022-07-04 11:56:36 - train: epoch 0008, iter [04500, 05004], lr: 0.100000, loss: 2.7537
2022-07-04 11:57:10 - train: epoch 0008, iter [04600, 05004], lr: 0.100000, loss: 2.6977
2022-07-04 11:57:43 - train: epoch 0008, iter [04700, 05004], lr: 0.100000, loss: 2.4893
2022-07-04 11:58:17 - train: epoch 0008, iter [04800, 05004], lr: 0.100000, loss: 2.5758
2022-07-04 11:58:49 - train: epoch 0008, iter [04900, 05004], lr: 0.100000, loss: 2.5880
2022-07-04 11:59:21 - train: epoch 0008, iter [05000, 05004], lr: 0.100000, loss: 2.5191
2022-07-04 11:59:22 - train: epoch 008, train_loss: 2.5743
2022-07-04 12:00:35 - eval: epoch: 008, acc1: 47.786%, acc5: 73.768%, test_loss: 2.2954, per_image_load_time: 2.261ms, per_image_inference_time: 0.178ms
2022-07-04 12:00:35 - until epoch: 008, best_acc1: 47.786%
2022-07-04 12:00:35 - epoch 009 lr: 0.100000
2022-07-04 12:01:13 - train: epoch 0009, iter [00100, 05004], lr: 0.100000, loss: 2.2897
2022-07-04 12:01:46 - train: epoch 0009, iter [00200, 05004], lr: 0.100000, loss: 2.3727
2022-07-04 12:02:19 - train: epoch 0009, iter [00300, 05004], lr: 0.100000, loss: 2.2323
2022-07-04 12:02:53 - train: epoch 0009, iter [00400, 05004], lr: 0.100000, loss: 2.8194
2022-07-04 12:03:24 - train: epoch 0009, iter [00500, 05004], lr: 0.100000, loss: 2.5335
2022-07-04 12:03:57 - train: epoch 0009, iter [00600, 05004], lr: 0.100000, loss: 2.5159
2022-07-04 12:04:31 - train: epoch 0009, iter [00700, 05004], lr: 0.100000, loss: 2.5006
2022-07-04 12:05:03 - train: epoch 0009, iter [00800, 05004], lr: 0.100000, loss: 2.3702
2022-07-04 12:05:38 - train: epoch 0009, iter [00900, 05004], lr: 0.100000, loss: 2.3302
2022-07-04 12:06:10 - train: epoch 0009, iter [01000, 05004], lr: 0.100000, loss: 2.3235
2022-07-04 12:06:43 - train: epoch 0009, iter [01100, 05004], lr: 0.100000, loss: 2.8753
2022-07-04 12:07:15 - train: epoch 0009, iter [01200, 05004], lr: 0.100000, loss: 2.6290
2022-07-04 12:07:49 - train: epoch 0009, iter [01300, 05004], lr: 0.100000, loss: 2.6439
2022-07-04 12:08:22 - train: epoch 0009, iter [01400, 05004], lr: 0.100000, loss: 2.2898
2022-07-04 12:08:56 - train: epoch 0009, iter [01500, 05004], lr: 0.100000, loss: 2.4443
2022-07-04 12:09:29 - train: epoch 0009, iter [01600, 05004], lr: 0.100000, loss: 2.5984
2022-07-04 12:10:02 - train: epoch 0009, iter [01700, 05004], lr: 0.100000, loss: 2.7789
2022-07-04 12:10:35 - train: epoch 0009, iter [01800, 05004], lr: 0.100000, loss: 2.4303
2022-07-04 12:11:10 - train: epoch 0009, iter [01900, 05004], lr: 0.100000, loss: 2.3478
2022-07-04 12:11:42 - train: epoch 0009, iter [02000, 05004], lr: 0.100000, loss: 2.2484
2022-07-04 12:12:16 - train: epoch 0009, iter [02100, 05004], lr: 0.100000, loss: 2.6448
2022-07-04 12:12:48 - train: epoch 0009, iter [02200, 05004], lr: 0.100000, loss: 2.6413
2022-07-04 12:13:21 - train: epoch 0009, iter [02300, 05004], lr: 0.100000, loss: 2.3305
2022-07-04 12:13:55 - train: epoch 0009, iter [02400, 05004], lr: 0.100000, loss: 2.5559
2022-07-04 12:14:28 - train: epoch 0009, iter [02500, 05004], lr: 0.100000, loss: 2.3935
2022-07-04 12:15:01 - train: epoch 0009, iter [02600, 05004], lr: 0.100000, loss: 2.5230
2022-07-04 12:15:34 - train: epoch 0009, iter [02700, 05004], lr: 0.100000, loss: 2.4335
2022-07-04 12:16:07 - train: epoch 0009, iter [02800, 05004], lr: 0.100000, loss: 2.6749
2022-07-04 12:16:40 - train: epoch 0009, iter [02900, 05004], lr: 0.100000, loss: 2.3165
2022-07-04 12:17:13 - train: epoch 0009, iter [03000, 05004], lr: 0.100000, loss: 2.4049
2022-07-04 12:17:46 - train: epoch 0009, iter [03100, 05004], lr: 0.100000, loss: 2.6351
2022-07-04 12:18:20 - train: epoch 0009, iter [03200, 05004], lr: 0.100000, loss: 2.5021
2022-07-04 12:18:53 - train: epoch 0009, iter [03300, 05004], lr: 0.100000, loss: 2.5708
2022-07-04 12:19:26 - train: epoch 0009, iter [03400, 05004], lr: 0.100000, loss: 2.7002
2022-07-04 12:20:00 - train: epoch 0009, iter [03500, 05004], lr: 0.100000, loss: 2.6374
2022-07-04 12:20:33 - train: epoch 0009, iter [03600, 05004], lr: 0.100000, loss: 2.4224
2022-07-04 12:21:05 - train: epoch 0009, iter [03700, 05004], lr: 0.100000, loss: 2.6502
2022-07-04 12:21:38 - train: epoch 0009, iter [03800, 05004], lr: 0.100000, loss: 2.7050
2022-07-04 12:22:12 - train: epoch 0009, iter [03900, 05004], lr: 0.100000, loss: 2.2797
2022-07-04 12:22:45 - train: epoch 0009, iter [04000, 05004], lr: 0.100000, loss: 2.7171
2022-07-04 12:23:19 - train: epoch 0009, iter [04100, 05004], lr: 0.100000, loss: 2.5502
2022-07-04 12:23:51 - train: epoch 0009, iter [04200, 05004], lr: 0.100000, loss: 2.3744
2022-07-04 12:24:24 - train: epoch 0009, iter [04300, 05004], lr: 0.100000, loss: 2.7016
2022-07-04 12:24:57 - train: epoch 0009, iter [04400, 05004], lr: 0.100000, loss: 2.4820
2022-07-04 12:25:30 - train: epoch 0009, iter [04500, 05004], lr: 0.100000, loss: 2.4935
2022-07-04 12:26:03 - train: epoch 0009, iter [04600, 05004], lr: 0.100000, loss: 2.5088
2022-07-04 12:26:36 - train: epoch 0009, iter [04700, 05004], lr: 0.100000, loss: 2.7113
2022-07-04 12:27:08 - train: epoch 0009, iter [04800, 05004], lr: 0.100000, loss: 2.7307
2022-07-04 12:27:42 - train: epoch 0009, iter [04900, 05004], lr: 0.100000, loss: 2.5916
2022-07-04 12:28:13 - train: epoch 0009, iter [05000, 05004], lr: 0.100000, loss: 2.4811
2022-07-04 12:28:14 - train: epoch 009, train_loss: 2.5458
2022-07-04 12:29:27 - eval: epoch: 009, acc1: 46.956%, acc5: 73.156%, test_loss: 2.3345, per_image_load_time: 2.672ms, per_image_inference_time: 0.174ms
2022-07-04 12:29:27 - until epoch: 009, best_acc1: 47.786%
2022-07-04 12:29:27 - epoch 010 lr: 0.100000
2022-07-04 12:30:06 - train: epoch 0010, iter [00100, 05004], lr: 0.100000, loss: 2.5730
2022-07-04 12:30:39 - train: epoch 0010, iter [00200, 05004], lr: 0.100000, loss: 2.6149
2022-07-04 12:31:11 - train: epoch 0010, iter [00300, 05004], lr: 0.100000, loss: 2.5488
2022-07-04 12:31:44 - train: epoch 0010, iter [00400, 05004], lr: 0.100000, loss: 2.6494
2022-07-04 12:32:17 - train: epoch 0010, iter [00500, 05004], lr: 0.100000, loss: 2.5327
2022-07-04 12:32:50 - train: epoch 0010, iter [00600, 05004], lr: 0.100000, loss: 2.6165
2022-07-04 12:33:22 - train: epoch 0010, iter [00700, 05004], lr: 0.100000, loss: 2.4878
2022-07-04 12:33:55 - train: epoch 0010, iter [00800, 05004], lr: 0.100000, loss: 2.4184
2022-07-04 12:34:28 - train: epoch 0010, iter [00900, 05004], lr: 0.100000, loss: 2.4048
2022-07-04 12:35:02 - train: epoch 0010, iter [01000, 05004], lr: 0.100000, loss: 2.3190
2022-07-04 12:35:34 - train: epoch 0010, iter [01100, 05004], lr: 0.100000, loss: 2.4608
2022-07-04 12:36:08 - train: epoch 0010, iter [01200, 05004], lr: 0.100000, loss: 2.4093
2022-07-04 12:36:41 - train: epoch 0010, iter [01300, 05004], lr: 0.100000, loss: 2.2839
2022-07-04 12:37:14 - train: epoch 0010, iter [01400, 05004], lr: 0.100000, loss: 2.5337
2022-07-04 12:37:47 - train: epoch 0010, iter [01500, 05004], lr: 0.100000, loss: 2.2671
2022-07-04 12:38:20 - train: epoch 0010, iter [01600, 05004], lr: 0.100000, loss: 2.6405
2022-07-04 12:38:54 - train: epoch 0010, iter [01700, 05004], lr: 0.100000, loss: 2.6423
2022-07-04 12:39:26 - train: epoch 0010, iter [01800, 05004], lr: 0.100000, loss: 2.4962
2022-07-04 12:39:59 - train: epoch 0010, iter [01900, 05004], lr: 0.100000, loss: 2.4925
2022-07-04 12:40:32 - train: epoch 0010, iter [02000, 05004], lr: 0.100000, loss: 2.6147
2022-07-04 12:41:06 - train: epoch 0010, iter [02100, 05004], lr: 0.100000, loss: 2.4027
2022-07-04 12:41:38 - train: epoch 0010, iter [02200, 05004], lr: 0.100000, loss: 2.7498
2022-07-04 12:42:11 - train: epoch 0010, iter [02300, 05004], lr: 0.100000, loss: 2.6866
2022-07-04 12:42:45 - train: epoch 0010, iter [02400, 05004], lr: 0.100000, loss: 2.6699
2022-07-04 12:43:18 - train: epoch 0010, iter [02500, 05004], lr: 0.100000, loss: 2.5912
2022-07-04 12:43:51 - train: epoch 0010, iter [02600, 05004], lr: 0.100000, loss: 2.6164
2022-07-04 12:44:24 - train: epoch 0010, iter [02700, 05004], lr: 0.100000, loss: 2.3646
2022-07-04 12:44:57 - train: epoch 0010, iter [02800, 05004], lr: 0.100000, loss: 2.4611
2022-07-04 12:45:30 - train: epoch 0010, iter [02900, 05004], lr: 0.100000, loss: 2.5121
2022-07-04 12:46:04 - train: epoch 0010, iter [03000, 05004], lr: 0.100000, loss: 2.5001
2022-07-04 12:46:36 - train: epoch 0010, iter [03100, 05004], lr: 0.100000, loss: 2.7553
2022-07-04 12:47:10 - train: epoch 0010, iter [03200, 05004], lr: 0.100000, loss: 2.5853
2022-07-04 12:47:42 - train: epoch 0010, iter [03300, 05004], lr: 0.100000, loss: 2.7165
2022-07-04 12:48:15 - train: epoch 0010, iter [03400, 05004], lr: 0.100000, loss: 2.7195
2022-07-04 12:48:49 - train: epoch 0010, iter [03500, 05004], lr: 0.100000, loss: 2.6569
2022-07-04 12:49:23 - train: epoch 0010, iter [03600, 05004], lr: 0.100000, loss: 2.7960
2022-07-04 12:49:55 - train: epoch 0010, iter [03700, 05004], lr: 0.100000, loss: 2.3780
2022-07-04 12:50:28 - train: epoch 0010, iter [03800, 05004], lr: 0.100000, loss: 2.5615
2022-07-04 12:51:02 - train: epoch 0010, iter [03900, 05004], lr: 0.100000, loss: 2.1667
2022-07-04 12:51:34 - train: epoch 0010, iter [04000, 05004], lr: 0.100000, loss: 2.4499
2022-07-04 12:52:08 - train: epoch 0010, iter [04100, 05004], lr: 0.100000, loss: 2.3063
2022-07-04 12:52:41 - train: epoch 0010, iter [04200, 05004], lr: 0.100000, loss: 2.5720
2022-07-04 12:53:14 - train: epoch 0010, iter [04300, 05004], lr: 0.100000, loss: 2.4257
2022-07-04 12:53:46 - train: epoch 0010, iter [04400, 05004], lr: 0.100000, loss: 2.4035
2022-07-04 12:54:21 - train: epoch 0010, iter [04500, 05004], lr: 0.100000, loss: 2.3581
2022-07-04 12:54:53 - train: epoch 0010, iter [04600, 05004], lr: 0.100000, loss: 2.5735
2022-07-04 12:55:27 - train: epoch 0010, iter [04700, 05004], lr: 0.100000, loss: 2.5399
2022-07-04 12:56:00 - train: epoch 0010, iter [04800, 05004], lr: 0.100000, loss: 2.4572
2022-07-04 12:56:34 - train: epoch 0010, iter [04900, 05004], lr: 0.100000, loss: 2.3382
2022-07-04 12:57:05 - train: epoch 0010, iter [05000, 05004], lr: 0.100000, loss: 2.2683
2022-07-04 12:57:05 - train: epoch 010, train_loss: 2.5193
2022-07-04 12:58:18 - eval: epoch: 010, acc1: 48.594%, acc5: 74.588%, test_loss: 2.2446, per_image_load_time: 2.376ms, per_image_inference_time: 0.163ms
2022-07-04 12:58:19 - until epoch: 010, best_acc1: 48.594%
2022-07-04 12:58:19 - epoch 011 lr: 0.100000
2022-07-04 12:58:57 - train: epoch 0011, iter [00100, 05004], lr: 0.100000, loss: 2.3301
2022-07-04 12:59:29 - train: epoch 0011, iter [00200, 05004], lr: 0.100000, loss: 2.5824
2022-07-04 13:00:03 - train: epoch 0011, iter [00300, 05004], lr: 0.100000, loss: 2.3989
2022-07-04 13:00:35 - train: epoch 0011, iter [00400, 05004], lr: 0.100000, loss: 2.6459
2022-07-04 13:01:08 - train: epoch 0011, iter [00500, 05004], lr: 0.100000, loss: 2.5366
2022-07-04 13:01:41 - train: epoch 0011, iter [00600, 05004], lr: 0.100000, loss: 2.5473
2022-07-04 13:02:15 - train: epoch 0011, iter [00700, 05004], lr: 0.100000, loss: 2.5568
2022-07-04 13:02:47 - train: epoch 0011, iter [00800, 05004], lr: 0.100000, loss: 2.4843
2022-07-04 13:03:21 - train: epoch 0011, iter [00900, 05004], lr: 0.100000, loss: 2.5409
2022-07-04 13:03:54 - train: epoch 0011, iter [01000, 05004], lr: 0.100000, loss: 2.5016
2022-07-04 13:04:27 - train: epoch 0011, iter [01100, 05004], lr: 0.100000, loss: 2.4542
2022-07-04 13:05:01 - train: epoch 0011, iter [01200, 05004], lr: 0.100000, loss: 2.7443
2022-07-04 13:05:33 - train: epoch 0011, iter [01300, 05004], lr: 0.100000, loss: 2.6969
2022-07-04 13:06:06 - train: epoch 0011, iter [01400, 05004], lr: 0.100000, loss: 2.6445
2022-07-04 13:06:40 - train: epoch 0011, iter [01500, 05004], lr: 0.100000, loss: 2.3554
2022-07-04 13:07:11 - train: epoch 0011, iter [01600, 05004], lr: 0.100000, loss: 2.5706
2022-07-04 13:07:46 - train: epoch 0011, iter [01700, 05004], lr: 0.100000, loss: 2.5503
2022-07-04 13:08:18 - train: epoch 0011, iter [01800, 05004], lr: 0.100000, loss: 2.3772
2022-07-04 13:08:52 - train: epoch 0011, iter [01900, 05004], lr: 0.100000, loss: 2.3858
2022-07-04 13:09:25 - train: epoch 0011, iter [02000, 05004], lr: 0.100000, loss: 2.6140
2022-07-04 13:09:58 - train: epoch 0011, iter [02100, 05004], lr: 0.100000, loss: 2.5690
2022-07-04 13:10:31 - train: epoch 0011, iter [02200, 05004], lr: 0.100000, loss: 2.3960
2022-07-04 13:11:04 - train: epoch 0011, iter [02300, 05004], lr: 0.100000, loss: 2.6726
2022-07-04 13:11:38 - train: epoch 0011, iter [02400, 05004], lr: 0.100000, loss: 2.2952
2022-07-04 13:12:11 - train: epoch 0011, iter [02500, 05004], lr: 0.100000, loss: 2.7732
2022-07-04 13:12:44 - train: epoch 0011, iter [02600, 05004], lr: 0.100000, loss: 2.4496
2022-07-04 13:13:17 - train: epoch 0011, iter [02700, 05004], lr: 0.100000, loss: 2.4647
2022-07-04 13:13:51 - train: epoch 0011, iter [02800, 05004], lr: 0.100000, loss: 2.1462
2022-07-04 13:14:23 - train: epoch 0011, iter [02900, 05004], lr: 0.100000, loss: 2.5261
2022-07-04 13:14:57 - train: epoch 0011, iter [03000, 05004], lr: 0.100000, loss: 2.7997
2022-07-04 13:15:30 - train: epoch 0011, iter [03100, 05004], lr: 0.100000, loss: 2.5106
2022-07-04 13:16:04 - train: epoch 0011, iter [03200, 05004], lr: 0.100000, loss: 2.3020
2022-07-04 13:16:37 - train: epoch 0011, iter [03300, 05004], lr: 0.100000, loss: 2.5403
2022-07-04 13:17:11 - train: epoch 0011, iter [03400, 05004], lr: 0.100000, loss: 2.4597
2022-07-04 13:17:43 - train: epoch 0011, iter [03500, 05004], lr: 0.100000, loss: 2.4729
2022-07-04 13:18:16 - train: epoch 0011, iter [03600, 05004], lr: 0.100000, loss: 2.5270
2022-07-04 13:18:51 - train: epoch 0011, iter [03700, 05004], lr: 0.100000, loss: 2.5875
2022-07-04 13:19:23 - train: epoch 0011, iter [03800, 05004], lr: 0.100000, loss: 2.1819
2022-07-04 13:19:56 - train: epoch 0011, iter [03900, 05004], lr: 0.100000, loss: 2.4900
2022-07-04 13:20:29 - train: epoch 0011, iter [04000, 05004], lr: 0.100000, loss: 2.4884
2022-07-04 13:21:02 - train: epoch 0011, iter [04100, 05004], lr: 0.100000, loss: 2.2294
2022-07-04 13:21:35 - train: epoch 0011, iter [04200, 05004], lr: 0.100000, loss: 2.3510
2022-07-04 13:22:08 - train: epoch 0011, iter [04300, 05004], lr: 0.100000, loss: 2.5476
2022-07-04 13:22:41 - train: epoch 0011, iter [04400, 05004], lr: 0.100000, loss: 2.4902
2022-07-04 13:23:14 - train: epoch 0011, iter [04500, 05004], lr: 0.100000, loss: 2.2529
2022-07-04 13:23:47 - train: epoch 0011, iter [04600, 05004], lr: 0.100000, loss: 2.3879
2022-07-04 13:24:22 - train: epoch 0011, iter [04700, 05004], lr: 0.100000, loss: 2.2059
2022-07-04 13:24:55 - train: epoch 0011, iter [04800, 05004], lr: 0.100000, loss: 2.3045
2022-07-04 13:25:28 - train: epoch 0011, iter [04900, 05004], lr: 0.100000, loss: 2.2413
2022-07-04 13:26:00 - train: epoch 0011, iter [05000, 05004], lr: 0.100000, loss: 2.4508
2022-07-04 13:26:00 - train: epoch 011, train_loss: 2.4974
2022-07-04 13:27:14 - eval: epoch: 011, acc1: 45.898%, acc5: 72.374%, test_loss: 2.3811, per_image_load_time: 1.951ms, per_image_inference_time: 0.180ms
2022-07-04 13:27:14 - until epoch: 011, best_acc1: 48.594%
2022-07-04 13:27:14 - epoch 012 lr: 0.100000
2022-07-04 13:27:52 - train: epoch 0012, iter [00100, 05004], lr: 0.100000, loss: 2.3468
2022-07-04 13:28:25 - train: epoch 0012, iter [00200, 05004], lr: 0.100000, loss: 2.3749
2022-07-04 13:28:58 - train: epoch 0012, iter [00300, 05004], lr: 0.100000, loss: 2.5839
2022-07-04 13:29:31 - train: epoch 0012, iter [00400, 05004], lr: 0.100000, loss: 2.5371
2022-07-04 13:30:04 - train: epoch 0012, iter [00500, 05004], lr: 0.100000, loss: 2.7220
2022-07-04 13:30:37 - train: epoch 0012, iter [00600, 05004], lr: 0.100000, loss: 2.3021
2022-07-04 13:31:11 - train: epoch 0012, iter [00700, 05004], lr: 0.100000, loss: 2.4078
2022-07-04 13:31:43 - train: epoch 0012, iter [00800, 05004], lr: 0.100000, loss: 2.4798
2022-07-04 13:32:16 - train: epoch 0012, iter [00900, 05004], lr: 0.100000, loss: 2.6417
2022-07-04 13:32:49 - train: epoch 0012, iter [01000, 05004], lr: 0.100000, loss: 2.3082
2022-07-04 13:33:22 - train: epoch 0012, iter [01100, 05004], lr: 0.100000, loss: 2.8185
2022-07-04 13:33:56 - train: epoch 0012, iter [01200, 05004], lr: 0.100000, loss: 2.3183
2022-07-04 13:34:28 - train: epoch 0012, iter [01300, 05004], lr: 0.100000, loss: 2.3950
2022-07-04 13:35:01 - train: epoch 0012, iter [01400, 05004], lr: 0.100000, loss: 2.5635
2022-07-04 13:35:35 - train: epoch 0012, iter [01500, 05004], lr: 0.100000, loss: 2.3205
2022-07-04 13:36:08 - train: epoch 0012, iter [01600, 05004], lr: 0.100000, loss: 2.3077
2022-07-04 13:36:41 - train: epoch 0012, iter [01700, 05004], lr: 0.100000, loss: 2.3862
2022-07-04 13:37:14 - train: epoch 0012, iter [01800, 05004], lr: 0.100000, loss: 2.4231
2022-07-04 13:37:47 - train: epoch 0012, iter [01900, 05004], lr: 0.100000, loss: 2.4710
2022-07-04 13:38:20 - train: epoch 0012, iter [02000, 05004], lr: 0.100000, loss: 2.7079
2022-07-04 13:38:53 - train: epoch 0012, iter [02100, 05004], lr: 0.100000, loss: 2.4220
2022-07-04 13:39:25 - train: epoch 0012, iter [02200, 05004], lr: 0.100000, loss: 2.6726
2022-07-04 13:40:00 - train: epoch 0012, iter [02300, 05004], lr: 0.100000, loss: 2.4595
2022-07-04 13:40:32 - train: epoch 0012, iter [02400, 05004], lr: 0.100000, loss: 2.4361
2022-07-04 13:41:06 - train: epoch 0012, iter [02500, 05004], lr: 0.100000, loss: 2.2745
2022-07-04 13:41:39 - train: epoch 0012, iter [02600, 05004], lr: 0.100000, loss: 2.3329
2022-07-04 13:42:13 - train: epoch 0012, iter [02700, 05004], lr: 0.100000, loss: 2.4015
2022-07-04 13:42:45 - train: epoch 0012, iter [02800, 05004], lr: 0.100000, loss: 2.4584
2022-07-04 13:43:20 - train: epoch 0012, iter [02900, 05004], lr: 0.100000, loss: 2.3112
2022-07-04 13:43:52 - train: epoch 0012, iter [03000, 05004], lr: 0.100000, loss: 2.3565
2022-07-04 13:44:25 - train: epoch 0012, iter [03100, 05004], lr: 0.100000, loss: 2.6820
2022-07-04 13:44:59 - train: epoch 0012, iter [03200, 05004], lr: 0.100000, loss: 2.1750
2022-07-04 13:45:32 - train: epoch 0012, iter [03300, 05004], lr: 0.100000, loss: 2.3573
2022-07-04 13:46:05 - train: epoch 0012, iter [03400, 05004], lr: 0.100000, loss: 2.4003
2022-07-04 13:46:39 - train: epoch 0012, iter [03500, 05004], lr: 0.100000, loss: 2.5846
2022-07-04 13:47:11 - train: epoch 0012, iter [03600, 05004], lr: 0.100000, loss: 2.5132
2022-07-04 13:47:44 - train: epoch 0012, iter [03700, 05004], lr: 0.100000, loss: 2.4403
2022-07-04 13:48:18 - train: epoch 0012, iter [03800, 05004], lr: 0.100000, loss: 2.4490
2022-07-04 13:48:52 - train: epoch 0012, iter [03900, 05004], lr: 0.100000, loss: 2.3986
2022-07-04 13:49:25 - train: epoch 0012, iter [04000, 05004], lr: 0.100000, loss: 2.4310
2022-07-04 13:49:59 - train: epoch 0012, iter [04100, 05004], lr: 0.100000, loss: 2.3362
2022-07-04 13:50:32 - train: epoch 0012, iter [04200, 05004], lr: 0.100000, loss: 2.2165
2022-07-04 13:51:06 - train: epoch 0012, iter [04300, 05004], lr: 0.100000, loss: 2.5014
2022-07-04 13:51:38 - train: epoch 0012, iter [04400, 05004], lr: 0.100000, loss: 2.3737
2022-07-04 13:52:12 - train: epoch 0012, iter [04500, 05004], lr: 0.100000, loss: 2.4222
2022-07-04 13:52:45 - train: epoch 0012, iter [04600, 05004], lr: 0.100000, loss: 2.7312
2022-07-04 13:53:18 - train: epoch 0012, iter [04700, 05004], lr: 0.100000, loss: 2.4402
2022-07-04 13:53:52 - train: epoch 0012, iter [04800, 05004], lr: 0.100000, loss: 2.6560
2022-07-04 13:54:25 - train: epoch 0012, iter [04900, 05004], lr: 0.100000, loss: 2.5152
2022-07-04 13:54:57 - train: epoch 0012, iter [05000, 05004], lr: 0.100000, loss: 2.1864
2022-07-04 13:54:58 - train: epoch 012, train_loss: 2.4812
2022-07-04 13:56:11 - eval: epoch: 012, acc1: 49.776%, acc5: 75.734%, test_loss: 2.1790, per_image_load_time: 2.678ms, per_image_inference_time: 0.195ms
2022-07-04 13:56:11 - until epoch: 012, best_acc1: 49.776%
2022-07-04 13:56:11 - epoch 013 lr: 0.100000
2022-07-04 13:56:50 - train: epoch 0013, iter [00100, 05004], lr: 0.100000, loss: 2.2762
2022-07-04 13:57:22 - train: epoch 0013, iter [00200, 05004], lr: 0.100000, loss: 2.3824
2022-07-04 13:57:56 - train: epoch 0013, iter [00300, 05004], lr: 0.100000, loss: 2.3791
2022-07-04 13:58:28 - train: epoch 0013, iter [00400, 05004], lr: 0.100000, loss: 2.4248
2022-07-04 13:59:01 - train: epoch 0013, iter [00500, 05004], lr: 0.100000, loss: 2.4089
2022-07-04 13:59:33 - train: epoch 0013, iter [00600, 05004], lr: 0.100000, loss: 2.5514
2022-07-04 14:00:07 - train: epoch 0013, iter [00700, 05004], lr: 0.100000, loss: 2.3756
2022-07-04 14:00:39 - train: epoch 0013, iter [00800, 05004], lr: 0.100000, loss: 2.5417
2022-07-04 14:01:12 - train: epoch 0013, iter [00900, 05004], lr: 0.100000, loss: 2.3795
2022-07-04 14:01:45 - train: epoch 0013, iter [01000, 05004], lr: 0.100000, loss: 2.4532
2022-07-04 14:02:18 - train: epoch 0013, iter [01100, 05004], lr: 0.100000, loss: 2.5006
2022-07-04 14:02:51 - train: epoch 0013, iter [01200, 05004], lr: 0.100000, loss: 2.5633
2022-07-04 14:03:24 - train: epoch 0013, iter [01300, 05004], lr: 0.100000, loss: 2.5776
2022-07-04 14:03:58 - train: epoch 0013, iter [01400, 05004], lr: 0.100000, loss: 2.4695
2022-07-04 14:04:31 - train: epoch 0013, iter [01500, 05004], lr: 0.100000, loss: 2.6217
2022-07-04 14:05:04 - train: epoch 0013, iter [01600, 05004], lr: 0.100000, loss: 2.1282
2022-07-04 14:05:37 - train: epoch 0013, iter [01700, 05004], lr: 0.100000, loss: 2.4524
2022-07-04 14:06:10 - train: epoch 0013, iter [01800, 05004], lr: 0.100000, loss: 2.3942
2022-07-04 14:06:42 - train: epoch 0013, iter [01900, 05004], lr: 0.100000, loss: 2.4973
2022-07-04 14:07:16 - train: epoch 0013, iter [02000, 05004], lr: 0.100000, loss: 2.7671
2022-07-04 14:07:49 - train: epoch 0013, iter [02100, 05004], lr: 0.100000, loss: 2.8163
2022-07-04 14:08:23 - train: epoch 0013, iter [02200, 05004], lr: 0.100000, loss: 2.3245
2022-07-04 14:08:55 - train: epoch 0013, iter [02300, 05004], lr: 0.100000, loss: 2.5306
2022-07-04 14:09:28 - train: epoch 0013, iter [02400, 05004], lr: 0.100000, loss: 2.4469
2022-07-04 14:10:02 - train: epoch 0013, iter [02500, 05004], lr: 0.100000, loss: 2.3759
2022-07-04 14:10:35 - train: epoch 0013, iter [02600, 05004], lr: 0.100000, loss: 2.3564
2022-07-04 14:11:09 - train: epoch 0013, iter [02700, 05004], lr: 0.100000, loss: 2.2980
2022-07-04 14:11:40 - train: epoch 0013, iter [02800, 05004], lr: 0.100000, loss: 2.4996
2022-07-04 14:12:14 - train: epoch 0013, iter [02900, 05004], lr: 0.100000, loss: 2.4838
2022-07-04 14:12:47 - train: epoch 0013, iter [03000, 05004], lr: 0.100000, loss: 2.3552
2022-07-04 14:13:21 - train: epoch 0013, iter [03100, 05004], lr: 0.100000, loss: 2.2850
2022-07-04 14:13:53 - train: epoch 0013, iter [03200, 05004], lr: 0.100000, loss: 2.6099
2022-07-04 14:14:27 - train: epoch 0013, iter [03300, 05004], lr: 0.100000, loss: 2.2359
2022-07-04 14:15:01 - train: epoch 0013, iter [03400, 05004], lr: 0.100000, loss: 2.3623
2022-07-04 14:15:33 - train: epoch 0013, iter [03500, 05004], lr: 0.100000, loss: 2.2415
2022-07-04 14:16:07 - train: epoch 0013, iter [03600, 05004], lr: 0.100000, loss: 2.7104
2022-07-04 14:16:40 - train: epoch 0013, iter [03700, 05004], lr: 0.100000, loss: 2.1280
2022-07-04 14:17:14 - train: epoch 0013, iter [03800, 05004], lr: 0.100000, loss: 2.6249
2022-07-04 14:17:47 - train: epoch 0013, iter [03900, 05004], lr: 0.100000, loss: 2.5988
2022-07-04 14:18:20 - train: epoch 0013, iter [04000, 05004], lr: 0.100000, loss: 2.5679
2022-07-04 14:18:54 - train: epoch 0013, iter [04100, 05004], lr: 0.100000, loss: 2.4168
2022-07-04 14:19:27 - train: epoch 0013, iter [04200, 05004], lr: 0.100000, loss: 2.5203
2022-07-04 14:20:00 - train: epoch 0013, iter [04300, 05004], lr: 0.100000, loss: 2.3763
2022-07-04 14:20:32 - train: epoch 0013, iter [04400, 05004], lr: 0.100000, loss: 2.3123
2022-07-04 14:21:07 - train: epoch 0013, iter [04500, 05004], lr: 0.100000, loss: 2.4215
2022-07-04 14:21:41 - train: epoch 0013, iter [04600, 05004], lr: 0.100000, loss: 2.4473
2022-07-04 14:22:14 - train: epoch 0013, iter [04700, 05004], lr: 0.100000, loss: 2.5667
2022-07-04 14:22:47 - train: epoch 0013, iter [04800, 05004], lr: 0.100000, loss: 2.6796
2022-07-04 14:23:20 - train: epoch 0013, iter [04900, 05004], lr: 0.100000, loss: 2.6342
2022-07-04 14:23:52 - train: epoch 0013, iter [05000, 05004], lr: 0.100000, loss: 2.5297
2022-07-04 14:23:53 - train: epoch 013, train_loss: 2.4668
2022-07-04 14:25:06 - eval: epoch: 013, acc1: 48.674%, acc5: 74.720%, test_loss: 2.2363, per_image_load_time: 2.632ms, per_image_inference_time: 0.191ms
2022-07-04 14:25:06 - until epoch: 013, best_acc1: 49.776%
2022-07-04 14:25:06 - epoch 014 lr: 0.100000
2022-07-04 14:25:44 - train: epoch 0014, iter [00100, 05004], lr: 0.100000, loss: 2.5006
2022-07-04 14:26:17 - train: epoch 0014, iter [00200, 05004], lr: 0.100000, loss: 2.5173
2022-07-04 14:26:50 - train: epoch 0014, iter [00300, 05004], lr: 0.100000, loss: 2.1939
2022-07-04 14:27:23 - train: epoch 0014, iter [00400, 05004], lr: 0.100000, loss: 2.3683
2022-07-04 14:27:56 - train: epoch 0014, iter [00500, 05004], lr: 0.100000, loss: 2.3741
2022-07-04 14:28:29 - train: epoch 0014, iter [00600, 05004], lr: 0.100000, loss: 2.4496
2022-07-04 14:29:02 - train: epoch 0014, iter [00700, 05004], lr: 0.100000, loss: 2.4368
2022-07-04 14:29:34 - train: epoch 0014, iter [00800, 05004], lr: 0.100000, loss: 2.5130
2022-07-04 14:30:07 - train: epoch 0014, iter [00900, 05004], lr: 0.100000, loss: 2.4765
2022-07-04 14:30:40 - train: epoch 0014, iter [01000, 05004], lr: 0.100000, loss: 2.5410
2022-07-04 14:31:14 - train: epoch 0014, iter [01100, 05004], lr: 0.100000, loss: 2.3755
2022-07-04 14:31:46 - train: epoch 0014, iter [01200, 05004], lr: 0.100000, loss: 2.4598
2022-07-04 14:32:20 - train: epoch 0014, iter [01300, 05004], lr: 0.100000, loss: 2.4682
2022-07-04 14:32:52 - train: epoch 0014, iter [01400, 05004], lr: 0.100000, loss: 2.5084
2022-07-04 14:33:25 - train: epoch 0014, iter [01500, 05004], lr: 0.100000, loss: 2.6061
2022-07-04 14:33:59 - train: epoch 0014, iter [01600, 05004], lr: 0.100000, loss: 2.4218
2022-07-04 14:34:32 - train: epoch 0014, iter [01700, 05004], lr: 0.100000, loss: 2.5391
2022-07-04 14:35:04 - train: epoch 0014, iter [01800, 05004], lr: 0.100000, loss: 2.6963
2022-07-04 14:35:39 - train: epoch 0014, iter [01900, 05004], lr: 0.100000, loss: 2.2973
2022-07-04 14:36:11 - train: epoch 0014, iter [02000, 05004], lr: 0.100000, loss: 2.4015
2022-07-04 14:36:44 - train: epoch 0014, iter [02100, 05004], lr: 0.100000, loss: 2.6499
2022-07-04 14:37:16 - train: epoch 0014, iter [02200, 05004], lr: 0.100000, loss: 2.4363
2022-07-04 14:37:50 - train: epoch 0014, iter [02300, 05004], lr: 0.100000, loss: 2.3497
2022-07-04 14:38:22 - train: epoch 0014, iter [02400, 05004], lr: 0.100000, loss: 2.7252
2022-07-04 14:38:57 - train: epoch 0014, iter [02500, 05004], lr: 0.100000, loss: 2.4069
2022-07-04 14:39:30 - train: epoch 0014, iter [02600, 05004], lr: 0.100000, loss: 2.3942
2022-07-04 14:40:03 - train: epoch 0014, iter [02700, 05004], lr: 0.100000, loss: 2.4185
2022-07-04 14:40:36 - train: epoch 0014, iter [02800, 05004], lr: 0.100000, loss: 2.6915
2022-07-04 14:41:09 - train: epoch 0014, iter [02900, 05004], lr: 0.100000, loss: 2.3499
2022-07-04 14:41:42 - train: epoch 0014, iter [03000, 05004], lr: 0.100000, loss: 2.6378
2022-07-04 14:42:15 - train: epoch 0014, iter [03100, 05004], lr: 0.100000, loss: 2.2517
2022-07-04 14:42:48 - train: epoch 0014, iter [03200, 05004], lr: 0.100000, loss: 2.3336
2022-07-04 14:43:22 - train: epoch 0014, iter [03300, 05004], lr: 0.100000, loss: 2.3620
2022-07-04 14:43:56 - train: epoch 0014, iter [03400, 05004], lr: 0.100000, loss: 2.4089
2022-07-04 14:44:28 - train: epoch 0014, iter [03500, 05004], lr: 0.100000, loss: 2.3939
2022-07-04 14:45:01 - train: epoch 0014, iter [03600, 05004], lr: 0.100000, loss: 2.3411
2022-07-04 14:45:34 - train: epoch 0014, iter [03700, 05004], lr: 0.100000, loss: 2.3199
2022-07-04 14:46:07 - train: epoch 0014, iter [03800, 05004], lr: 0.100000, loss: 2.6528
2022-07-04 14:46:40 - train: epoch 0014, iter [03900, 05004], lr: 0.100000, loss: 2.3077
2022-07-04 14:47:14 - train: epoch 0014, iter [04000, 05004], lr: 0.100000, loss: 2.5774
2022-07-04 14:47:47 - train: epoch 0014, iter [04100, 05004], lr: 0.100000, loss: 2.3311
2022-07-04 14:48:20 - train: epoch 0014, iter [04200, 05004], lr: 0.100000, loss: 2.3062
2022-07-04 14:48:53 - train: epoch 0014, iter [04300, 05004], lr: 0.100000, loss: 2.3460
2022-07-04 14:49:27 - train: epoch 0014, iter [04400, 05004], lr: 0.100000, loss: 2.3021
2022-07-04 14:50:00 - train: epoch 0014, iter [04500, 05004], lr: 0.100000, loss: 2.3847
2022-07-04 14:50:32 - train: epoch 0014, iter [04600, 05004], lr: 0.100000, loss: 2.4012
2022-07-04 14:51:07 - train: epoch 0014, iter [04700, 05004], lr: 0.100000, loss: 2.3024
2022-07-04 14:51:39 - train: epoch 0014, iter [04800, 05004], lr: 0.100000, loss: 2.4182
2022-07-04 14:52:13 - train: epoch 0014, iter [04900, 05004], lr: 0.100000, loss: 2.3444
2022-07-04 14:52:44 - train: epoch 0014, iter [05000, 05004], lr: 0.100000, loss: 2.4253
2022-07-04 14:52:45 - train: epoch 014, train_loss: 2.4530
2022-07-04 14:53:58 - eval: epoch: 014, acc1: 48.296%, acc5: 74.484%, test_loss: 2.2782, per_image_load_time: 2.650ms, per_image_inference_time: 0.188ms
2022-07-04 14:53:58 - until epoch: 014, best_acc1: 49.776%
2022-07-04 14:53:58 - epoch 015 lr: 0.100000
2022-07-04 14:54:37 - train: epoch 0015, iter [00100, 05004], lr: 0.100000, loss: 2.1553
2022-07-04 14:55:10 - train: epoch 0015, iter [00200, 05004], lr: 0.100000, loss: 2.5388
2022-07-04 14:55:42 - train: epoch 0015, iter [00300, 05004], lr: 0.100000, loss: 2.5355
2022-07-04 14:56:14 - train: epoch 0015, iter [00400, 05004], lr: 0.100000, loss: 2.4232
2022-07-04 14:56:48 - train: epoch 0015, iter [00500, 05004], lr: 0.100000, loss: 2.4198
2022-07-04 14:57:21 - train: epoch 0015, iter [00600, 05004], lr: 0.100000, loss: 2.5842
2022-07-04 14:57:54 - train: epoch 0015, iter [00700, 05004], lr: 0.100000, loss: 2.3833
2022-07-04 14:58:26 - train: epoch 0015, iter [00800, 05004], lr: 0.100000, loss: 2.2431
2022-07-04 14:59:00 - train: epoch 0015, iter [00900, 05004], lr: 0.100000, loss: 2.2597
2022-07-04 14:59:33 - train: epoch 0015, iter [01000, 05004], lr: 0.100000, loss: 2.4572
2022-07-04 15:00:05 - train: epoch 0015, iter [01100, 05004], lr: 0.100000, loss: 2.2771
2022-07-04 15:00:38 - train: epoch 0015, iter [01200, 05004], lr: 0.100000, loss: 2.4927
2022-07-04 15:01:11 - train: epoch 0015, iter [01300, 05004], lr: 0.100000, loss: 2.7370
2022-07-04 15:01:44 - train: epoch 0015, iter [01400, 05004], lr: 0.100000, loss: 2.3876
2022-07-04 15:02:18 - train: epoch 0015, iter [01500, 05004], lr: 0.100000, loss: 2.1503
2022-07-04 15:02:50 - train: epoch 0015, iter [01600, 05004], lr: 0.100000, loss: 2.4886
2022-07-04 15:03:22 - train: epoch 0015, iter [01700, 05004], lr: 0.100000, loss: 2.5954
2022-07-04 15:03:56 - train: epoch 0015, iter [01800, 05004], lr: 0.100000, loss: 2.3845
2022-07-04 15:04:28 - train: epoch 0015, iter [01900, 05004], lr: 0.100000, loss: 2.3776
2022-07-04 15:05:01 - train: epoch 0015, iter [02000, 05004], lr: 0.100000, loss: 2.4714
2022-07-04 15:05:35 - train: epoch 0015, iter [02100, 05004], lr: 0.100000, loss: 2.3138
2022-07-04 15:06:08 - train: epoch 0015, iter [02200, 05004], lr: 0.100000, loss: 2.6146
2022-07-04 15:06:41 - train: epoch 0015, iter [02300, 05004], lr: 0.100000, loss: 2.2638
2022-07-04 15:07:14 - train: epoch 0015, iter [02400, 05004], lr: 0.100000, loss: 2.4702
2022-07-04 15:07:47 - train: epoch 0015, iter [02500, 05004], lr: 0.100000, loss: 2.4769
2022-07-04 15:08:20 - train: epoch 0015, iter [02600, 05004], lr: 0.100000, loss: 2.2589
2022-07-04 15:08:53 - train: epoch 0015, iter [02700, 05004], lr: 0.100000, loss: 2.5110
2022-07-04 15:09:27 - train: epoch 0015, iter [02800, 05004], lr: 0.100000, loss: 2.6222
2022-07-04 15:10:00 - train: epoch 0015, iter [02900, 05004], lr: 0.100000, loss: 2.3629
2022-07-04 15:10:33 - train: epoch 0015, iter [03000, 05004], lr: 0.100000, loss: 2.3435
2022-07-04 15:11:06 - train: epoch 0015, iter [03100, 05004], lr: 0.100000, loss: 2.2756
2022-07-04 15:11:39 - train: epoch 0015, iter [03200, 05004], lr: 0.100000, loss: 2.3814
2022-07-04 15:12:12 - train: epoch 0015, iter [03300, 05004], lr: 0.100000, loss: 2.1798
2022-07-04 15:12:47 - train: epoch 0015, iter [03400, 05004], lr: 0.100000, loss: 2.4347
2022-07-04 15:13:18 - train: epoch 0015, iter [03500, 05004], lr: 0.100000, loss: 2.6036
2022-07-04 15:13:52 - train: epoch 0015, iter [03600, 05004], lr: 0.100000, loss: 2.4654
2022-07-04 15:14:25 - train: epoch 0015, iter [03700, 05004], lr: 0.100000, loss: 2.3487
2022-07-04 15:14:59 - train: epoch 0015, iter [03800, 05004], lr: 0.100000, loss: 2.3872
2022-07-04 15:15:31 - train: epoch 0015, iter [03900, 05004], lr: 0.100000, loss: 2.5919
2022-07-04 15:16:05 - train: epoch 0015, iter [04000, 05004], lr: 0.100000, loss: 2.4586
2022-07-04 15:16:38 - train: epoch 0015, iter [04100, 05004], lr: 0.100000, loss: 2.6434
2022-07-04 15:17:11 - train: epoch 0015, iter [04200, 05004], lr: 0.100000, loss: 2.1531
2022-07-04 15:17:44 - train: epoch 0015, iter [04300, 05004], lr: 0.100000, loss: 2.6032
2022-07-04 15:18:17 - train: epoch 0015, iter [04400, 05004], lr: 0.100000, loss: 2.4165
2022-07-04 15:18:50 - train: epoch 0015, iter [04500, 05004], lr: 0.100000, loss: 2.5328
2022-07-04 15:19:25 - train: epoch 0015, iter [04600, 05004], lr: 0.100000, loss: 2.3383
2022-07-04 15:19:57 - train: epoch 0015, iter [04700, 05004], lr: 0.100000, loss: 2.5965
2022-07-04 15:20:31 - train: epoch 0015, iter [04800, 05004], lr: 0.100000, loss: 2.5154
2022-07-04 15:21:03 - train: epoch 0015, iter [04900, 05004], lr: 0.100000, loss: 2.4538
2022-07-04 15:21:35 - train: epoch 0015, iter [05000, 05004], lr: 0.100000, loss: 2.5885
2022-07-04 15:21:36 - train: epoch 015, train_loss: 2.4421
2022-07-04 15:22:49 - eval: epoch: 015, acc1: 49.014%, acc5: 74.814%, test_loss: 2.2325, per_image_load_time: 2.698ms, per_image_inference_time: 0.174ms
2022-07-04 15:22:49 - until epoch: 015, best_acc1: 49.776%
2022-07-04 15:22:49 - epoch 016 lr: 0.100000
2022-07-04 15:23:27 - train: epoch 0016, iter [00100, 05004], lr: 0.100000, loss: 2.4120
2022-07-04 15:24:00 - train: epoch 0016, iter [00200, 05004], lr: 0.100000, loss: 2.2468
2022-07-04 15:24:33 - train: epoch 0016, iter [00300, 05004], lr: 0.100000, loss: 2.4608
2022-07-04 15:25:06 - train: epoch 0016, iter [00400, 05004], lr: 0.100000, loss: 2.6768
2022-07-04 15:25:39 - train: epoch 0016, iter [00500, 05004], lr: 0.100000, loss: 2.2053
2022-07-04 15:26:10 - train: epoch 0016, iter [00600, 05004], lr: 0.100000, loss: 2.5563
2022-07-04 15:26:44 - train: epoch 0016, iter [00700, 05004], lr: 0.100000, loss: 2.2534
2022-07-04 15:27:17 - train: epoch 0016, iter [00800, 05004], lr: 0.100000, loss: 2.4970
2022-07-04 15:27:49 - train: epoch 0016, iter [00900, 05004], lr: 0.100000, loss: 2.5339
2022-07-04 15:28:23 - train: epoch 0016, iter [01000, 05004], lr: 0.100000, loss: 2.2689
2022-07-04 15:28:55 - train: epoch 0016, iter [01100, 05004], lr: 0.100000, loss: 2.3108
2022-07-04 15:29:29 - train: epoch 0016, iter [01200, 05004], lr: 0.100000, loss: 2.1987
2022-07-04 15:30:01 - train: epoch 0016, iter [01300, 05004], lr: 0.100000, loss: 2.6257
2022-07-04 15:30:35 - train: epoch 0016, iter [01400, 05004], lr: 0.100000, loss: 2.3153
2022-07-04 15:31:07 - train: epoch 0016, iter [01500, 05004], lr: 0.100000, loss: 2.5443
2022-07-04 15:31:41 - train: epoch 0016, iter [01600, 05004], lr: 0.100000, loss: 2.5364
2022-07-04 15:32:13 - train: epoch 0016, iter [01700, 05004], lr: 0.100000, loss: 2.2845
2022-07-04 15:32:47 - train: epoch 0016, iter [01800, 05004], lr: 0.100000, loss: 2.4343
2022-07-04 15:33:19 - train: epoch 0016, iter [01900, 05004], lr: 0.100000, loss: 2.4860
2022-07-04 15:33:53 - train: epoch 0016, iter [02000, 05004], lr: 0.100000, loss: 2.0653
2022-07-04 15:34:25 - train: epoch 0016, iter [02100, 05004], lr: 0.100000, loss: 2.6423
2022-07-04 15:34:59 - train: epoch 0016, iter [02200, 05004], lr: 0.100000, loss: 2.4283
2022-07-04 15:35:31 - train: epoch 0016, iter [02300, 05004], lr: 0.100000, loss: 2.7012
2022-07-04 15:36:06 - train: epoch 0016, iter [02400, 05004], lr: 0.100000, loss: 2.6164
2022-07-04 15:36:38 - train: epoch 0016, iter [02500, 05004], lr: 0.100000, loss: 2.3409
2022-07-04 15:37:11 - train: epoch 0016, iter [02600, 05004], lr: 0.100000, loss: 2.4995
2022-07-04 15:37:44 - train: epoch 0016, iter [02700, 05004], lr: 0.100000, loss: 2.3507
2022-07-04 15:38:17 - train: epoch 0016, iter [02800, 05004], lr: 0.100000, loss: 2.2773
2022-07-04 15:38:50 - train: epoch 0016, iter [02900, 05004], lr: 0.100000, loss: 2.5077
2022-07-04 15:39:23 - train: epoch 0016, iter [03000, 05004], lr: 0.100000, loss: 2.7012
2022-07-04 15:39:55 - train: epoch 0016, iter [03100, 05004], lr: 0.100000, loss: 2.5796
2022-07-04 15:40:29 - train: epoch 0016, iter [03200, 05004], lr: 0.100000, loss: 2.6079
2022-07-04 15:41:02 - train: epoch 0016, iter [03300, 05004], lr: 0.100000, loss: 2.3682
2022-07-04 15:41:36 - train: epoch 0016, iter [03400, 05004], lr: 0.100000, loss: 2.3741
2022-07-04 15:42:08 - train: epoch 0016, iter [03500, 05004], lr: 0.100000, loss: 2.3874
2022-07-04 15:42:42 - train: epoch 0016, iter [03600, 05004], lr: 0.100000, loss: 2.2701
2022-07-04 15:43:15 - train: epoch 0016, iter [03700, 05004], lr: 0.100000, loss: 2.5073
2022-07-04 15:43:48 - train: epoch 0016, iter [03800, 05004], lr: 0.100000, loss: 2.8094
2022-07-04 15:44:21 - train: epoch 0016, iter [03900, 05004], lr: 0.100000, loss: 2.4694
2022-07-04 15:44:55 - train: epoch 0016, iter [04000, 05004], lr: 0.100000, loss: 2.4529
2022-07-04 15:45:27 - train: epoch 0016, iter [04100, 05004], lr: 0.100000, loss: 2.3866
2022-07-04 15:46:01 - train: epoch 0016, iter [04200, 05004], lr: 0.100000, loss: 2.4245
2022-07-04 15:46:35 - train: epoch 0016, iter [04300, 05004], lr: 0.100000, loss: 2.3301
2022-07-04 15:47:08 - train: epoch 0016, iter [04400, 05004], lr: 0.100000, loss: 2.3586
2022-07-04 15:47:40 - train: epoch 0016, iter [04500, 05004], lr: 0.100000, loss: 2.6164
2022-07-04 15:48:14 - train: epoch 0016, iter [04600, 05004], lr: 0.100000, loss: 2.2963
2022-07-04 15:48:47 - train: epoch 0016, iter [04700, 05004], lr: 0.100000, loss: 2.6547
2022-07-04 15:49:19 - train: epoch 0016, iter [04800, 05004], lr: 0.100000, loss: 2.3831
2022-07-04 15:49:53 - train: epoch 0016, iter [04900, 05004], lr: 0.100000, loss: 2.4323
2022-07-04 15:50:24 - train: epoch 0016, iter [05000, 05004], lr: 0.100000, loss: 2.5314
2022-07-04 15:50:25 - train: epoch 016, train_loss: 2.4326
2022-07-04 15:51:39 - eval: epoch: 016, acc1: 48.924%, acc5: 75.216%, test_loss: 2.2043, per_image_load_time: 2.702ms, per_image_inference_time: 0.165ms
2022-07-04 15:51:39 - until epoch: 016, best_acc1: 49.776%
2022-07-04 15:51:39 - epoch 017 lr: 0.100000
2022-07-04 15:52:16 - train: epoch 0017, iter [00100, 05004], lr: 0.100000, loss: 2.3579
2022-07-04 15:52:50 - train: epoch 0017, iter [00200, 05004], lr: 0.100000, loss: 2.4900
2022-07-04 15:53:23 - train: epoch 0017, iter [00300, 05004], lr: 0.100000, loss: 2.6693
2022-07-04 15:53:55 - train: epoch 0017, iter [00400, 05004], lr: 0.100000, loss: 2.1811
2022-07-04 15:54:29 - train: epoch 0017, iter [00500, 05004], lr: 0.100000, loss: 2.5311
2022-07-04 15:55:02 - train: epoch 0017, iter [00600, 05004], lr: 0.100000, loss: 2.7486
2022-07-04 15:55:34 - train: epoch 0017, iter [00700, 05004], lr: 0.100000, loss: 2.3968
2022-07-04 15:56:07 - train: epoch 0017, iter [00800, 05004], lr: 0.100000, loss: 2.3343
2022-07-04 15:56:39 - train: epoch 0017, iter [00900, 05004], lr: 0.100000, loss: 2.3821
2022-07-04 15:57:12 - train: epoch 0017, iter [01000, 05004], lr: 0.100000, loss: 2.3576
2022-07-04 15:57:45 - train: epoch 0017, iter [01100, 05004], lr: 0.100000, loss: 2.7050
2022-07-04 15:58:19 - train: epoch 0017, iter [01200, 05004], lr: 0.100000, loss: 2.5334
2022-07-04 15:58:51 - train: epoch 0017, iter [01300, 05004], lr: 0.100000, loss: 2.4153
2022-07-04 15:59:24 - train: epoch 0017, iter [01400, 05004], lr: 0.100000, loss: 2.4640
2022-07-04 15:59:58 - train: epoch 0017, iter [01500, 05004], lr: 0.100000, loss: 2.0724
2022-07-04 16:00:30 - train: epoch 0017, iter [01600, 05004], lr: 0.100000, loss: 2.2568
2022-07-04 16:01:04 - train: epoch 0017, iter [01700, 05004], lr: 0.100000, loss: 2.4842
2022-07-04 16:01:37 - train: epoch 0017, iter [01800, 05004], lr: 0.100000, loss: 2.5414
2022-07-04 16:02:11 - train: epoch 0017, iter [01900, 05004], lr: 0.100000, loss: 2.1928
2022-07-04 16:02:43 - train: epoch 0017, iter [02000, 05004], lr: 0.100000, loss: 2.5240
2022-07-04 16:03:17 - train: epoch 0017, iter [02100, 05004], lr: 0.100000, loss: 2.4019
2022-07-04 16:03:49 - train: epoch 0017, iter [02200, 05004], lr: 0.100000, loss: 2.3350
2022-07-04 16:04:22 - train: epoch 0017, iter [02300, 05004], lr: 0.100000, loss: 2.3641
2022-07-04 16:04:55 - train: epoch 0017, iter [02400, 05004], lr: 0.100000, loss: 2.2843
2022-07-04 16:05:28 - train: epoch 0017, iter [02500, 05004], lr: 0.100000, loss: 2.5476
2022-07-04 16:06:01 - train: epoch 0017, iter [02600, 05004], lr: 0.100000, loss: 2.3322
2022-07-04 16:06:34 - train: epoch 0017, iter [02700, 05004], lr: 0.100000, loss: 2.3745
2022-07-04 16:07:07 - train: epoch 0017, iter [02800, 05004], lr: 0.100000, loss: 2.6102
2022-07-04 16:07:40 - train: epoch 0017, iter [02900, 05004], lr: 0.100000, loss: 2.6159
2022-07-04 16:08:14 - train: epoch 0017, iter [03000, 05004], lr: 0.100000, loss: 2.1458
2022-07-04 16:08:47 - train: epoch 0017, iter [03100, 05004], lr: 0.100000, loss: 2.5545
2022-07-04 16:09:20 - train: epoch 0017, iter [03200, 05004], lr: 0.100000, loss: 2.3115
2022-07-04 16:09:52 - train: epoch 0017, iter [03300, 05004], lr: 0.100000, loss: 2.4898
2022-07-04 16:10:26 - train: epoch 0017, iter [03400, 05004], lr: 0.100000, loss: 2.2585
2022-07-04 16:11:00 - train: epoch 0017, iter [03500, 05004], lr: 0.100000, loss: 2.4425
2022-07-04 16:11:32 - train: epoch 0017, iter [03600, 05004], lr: 0.100000, loss: 2.6556
2022-07-04 16:12:05 - train: epoch 0017, iter [03700, 05004], lr: 0.100000, loss: 2.4095
2022-07-04 16:12:39 - train: epoch 0017, iter [03800, 05004], lr: 0.100000, loss: 2.6782
2022-07-04 16:13:12 - train: epoch 0017, iter [03900, 05004], lr: 0.100000, loss: 2.3705
2022-07-04 16:13:45 - train: epoch 0017, iter [04000, 05004], lr: 0.100000, loss: 2.2240
2022-07-04 16:14:18 - train: epoch 0017, iter [04100, 05004], lr: 0.100000, loss: 2.4085
2022-07-04 16:14:51 - train: epoch 0017, iter [04200, 05004], lr: 0.100000, loss: 2.4628
2022-07-04 16:15:23 - train: epoch 0017, iter [04300, 05004], lr: 0.100000, loss: 2.3052
2022-07-04 16:15:57 - train: epoch 0017, iter [04400, 05004], lr: 0.100000, loss: 2.3417
2022-07-04 16:16:30 - train: epoch 0017, iter [04500, 05004], lr: 0.100000, loss: 2.4764
2022-07-04 16:17:04 - train: epoch 0017, iter [04600, 05004], lr: 0.100000, loss: 2.3881
2022-07-04 16:17:36 - train: epoch 0017, iter [04700, 05004], lr: 0.100000, loss: 2.5161
2022-07-04 16:18:10 - train: epoch 0017, iter [04800, 05004], lr: 0.100000, loss: 2.5951
2022-07-04 16:18:42 - train: epoch 0017, iter [04900, 05004], lr: 0.100000, loss: 2.2634
2022-07-04 16:19:14 - train: epoch 0017, iter [05000, 05004], lr: 0.100000, loss: 2.1780
2022-07-04 16:19:15 - train: epoch 017, train_loss: 2.4224
2022-07-04 16:20:29 - eval: epoch: 017, acc1: 50.166%, acc5: 76.148%, test_loss: 2.1599, per_image_load_time: 2.520ms, per_image_inference_time: 0.171ms
2022-07-04 16:20:29 - until epoch: 017, best_acc1: 50.166%
2022-07-04 16:20:29 - epoch 018 lr: 0.100000
2022-07-04 16:21:06 - train: epoch 0018, iter [00100, 05004], lr: 0.100000, loss: 2.4281
2022-07-04 16:21:39 - train: epoch 0018, iter [00200, 05004], lr: 0.100000, loss: 2.4649
2022-07-04 16:22:12 - train: epoch 0018, iter [00300, 05004], lr: 0.100000, loss: 2.6127
2022-07-04 16:22:46 - train: epoch 0018, iter [00400, 05004], lr: 0.100000, loss: 2.5837
2022-07-04 16:23:19 - train: epoch 0018, iter [00500, 05004], lr: 0.100000, loss: 2.3487
2022-07-04 16:23:51 - train: epoch 0018, iter [00600, 05004], lr: 0.100000, loss: 2.3906
2022-07-04 16:24:24 - train: epoch 0018, iter [00700, 05004], lr: 0.100000, loss: 2.1668
2022-07-04 16:24:56 - train: epoch 0018, iter [00800, 05004], lr: 0.100000, loss: 2.3682
2022-07-04 16:25:30 - train: epoch 0018, iter [00900, 05004], lr: 0.100000, loss: 2.4387
2022-07-04 16:26:02 - train: epoch 0018, iter [01000, 05004], lr: 0.100000, loss: 2.2725
2022-07-04 16:26:35 - train: epoch 0018, iter [01100, 05004], lr: 0.100000, loss: 2.7165
2022-07-04 16:27:07 - train: epoch 0018, iter [01200, 05004], lr: 0.100000, loss: 2.4092
2022-07-04 16:27:41 - train: epoch 0018, iter [01300, 05004], lr: 0.100000, loss: 2.7302
2022-07-04 16:28:13 - train: epoch 0018, iter [01400, 05004], lr: 0.100000, loss: 2.3344
2022-07-04 16:28:48 - train: epoch 0018, iter [01500, 05004], lr: 0.100000, loss: 2.5883
2022-07-04 16:29:20 - train: epoch 0018, iter [01600, 05004], lr: 0.100000, loss: 2.4266
2022-07-04 16:29:54 - train: epoch 0018, iter [01700, 05004], lr: 0.100000, loss: 2.2599
2022-07-04 16:30:26 - train: epoch 0018, iter [01800, 05004], lr: 0.100000, loss: 2.2004
2022-07-04 16:31:01 - train: epoch 0018, iter [01900, 05004], lr: 0.100000, loss: 2.4600
2022-07-04 16:31:33 - train: epoch 0018, iter [02000, 05004], lr: 0.100000, loss: 2.7039
2022-07-04 16:32:07 - train: epoch 0018, iter [02100, 05004], lr: 0.100000, loss: 2.6960
2022-07-04 16:32:39 - train: epoch 0018, iter [02200, 05004], lr: 0.100000, loss: 2.3822
2022-07-04 16:33:13 - train: epoch 0018, iter [02300, 05004], lr: 0.100000, loss: 2.5245
2022-07-04 16:33:46 - train: epoch 0018, iter [02400, 05004], lr: 0.100000, loss: 2.1812
2022-07-04 16:34:20 - train: epoch 0018, iter [02500, 05004], lr: 0.100000, loss: 2.1058
2022-07-04 16:34:53 - train: epoch 0018, iter [02600, 05004], lr: 0.100000, loss: 2.2351
2022-07-04 16:35:25 - train: epoch 0018, iter [02700, 05004], lr: 0.100000, loss: 2.6433
2022-07-04 16:35:59 - train: epoch 0018, iter [02800, 05004], lr: 0.100000, loss: 2.1428
2022-07-04 16:36:32 - train: epoch 0018, iter [02900, 05004], lr: 0.100000, loss: 2.4055
2022-07-04 16:37:05 - train: epoch 0018, iter [03000, 05004], lr: 0.100000, loss: 2.2780
2022-07-04 16:37:38 - train: epoch 0018, iter [03100, 05004], lr: 0.100000, loss: 2.7773
2022-07-04 16:38:11 - train: epoch 0018, iter [03200, 05004], lr: 0.100000, loss: 2.2785
2022-07-04 16:38:44 - train: epoch 0018, iter [03300, 05004], lr: 0.100000, loss: 2.2508
2022-07-04 16:39:18 - train: epoch 0018, iter [03400, 05004], lr: 0.100000, loss: 2.2933
2022-07-04 16:39:51 - train: epoch 0018, iter [03500, 05004], lr: 0.100000, loss: 2.6579
2022-07-04 16:40:23 - train: epoch 0018, iter [03600, 05004], lr: 0.100000, loss: 2.4556
2022-07-04 16:40:58 - train: epoch 0018, iter [03700, 05004], lr: 0.100000, loss: 2.7436
2022-07-04 16:41:30 - train: epoch 0018, iter [03800, 05004], lr: 0.100000, loss: 2.5054
2022-07-04 16:42:03 - train: epoch 0018, iter [03900, 05004], lr: 0.100000, loss: 2.4802
2022-07-04 16:42:36 - train: epoch 0018, iter [04000, 05004], lr: 0.100000, loss: 2.2358
2022-07-04 16:43:09 - train: epoch 0018, iter [04100, 05004], lr: 0.100000, loss: 2.3987
2022-07-04 16:43:43 - train: epoch 0018, iter [04200, 05004], lr: 0.100000, loss: 2.3999
2022-07-04 16:44:16 - train: epoch 0018, iter [04300, 05004], lr: 0.100000, loss: 2.1519
2022-07-04 16:44:48 - train: epoch 0018, iter [04400, 05004], lr: 0.100000, loss: 2.5747
2022-07-04 16:45:22 - train: epoch 0018, iter [04500, 05004], lr: 0.100000, loss: 2.4407
2022-07-04 16:45:54 - train: epoch 0018, iter [04600, 05004], lr: 0.100000, loss: 2.2776
2022-07-04 16:46:28 - train: epoch 0018, iter [04700, 05004], lr: 0.100000, loss: 2.6114
2022-07-04 16:47:01 - train: epoch 0018, iter [04800, 05004], lr: 0.100000, loss: 2.6020
2022-07-04 16:47:34 - train: epoch 0018, iter [04900, 05004], lr: 0.100000, loss: 2.3645
2022-07-04 16:48:05 - train: epoch 0018, iter [05000, 05004], lr: 0.100000, loss: 2.5352
2022-07-04 16:48:06 - train: epoch 018, train_loss: 2.4131
2022-07-04 16:49:20 - eval: epoch: 018, acc1: 50.690%, acc5: 76.370%, test_loss: 2.1395, per_image_load_time: 2.684ms, per_image_inference_time: 0.187ms
2022-07-04 16:49:20 - until epoch: 018, best_acc1: 50.690%
2022-07-04 16:49:20 - epoch 019 lr: 0.100000
2022-07-04 16:49:59 - train: epoch 0019, iter [00100, 05004], lr: 0.100000, loss: 2.1358
2022-07-04 16:50:30 - train: epoch 0019, iter [00200, 05004], lr: 0.100000, loss: 2.4992
2022-07-04 16:51:03 - train: epoch 0019, iter [00300, 05004], lr: 0.100000, loss: 2.6908
2022-07-04 16:51:36 - train: epoch 0019, iter [00400, 05004], lr: 0.100000, loss: 2.2643
2022-07-04 16:52:09 - train: epoch 0019, iter [00500, 05004], lr: 0.100000, loss: 2.2655
2022-07-04 16:52:43 - train: epoch 0019, iter [00600, 05004], lr: 0.100000, loss: 2.2783
2022-07-04 16:53:15 - train: epoch 0019, iter [00700, 05004], lr: 0.100000, loss: 2.1093
2022-07-04 16:53:48 - train: epoch 0019, iter [00800, 05004], lr: 0.100000, loss: 2.5562
2022-07-04 16:54:22 - train: epoch 0019, iter [00900, 05004], lr: 0.100000, loss: 2.4061
2022-07-04 16:54:53 - train: epoch 0019, iter [01000, 05004], lr: 0.100000, loss: 2.6087
2022-07-04 16:55:27 - train: epoch 0019, iter [01100, 05004], lr: 0.100000, loss: 2.3492
2022-07-04 16:56:00 - train: epoch 0019, iter [01200, 05004], lr: 0.100000, loss: 2.4590
2022-07-04 16:56:33 - train: epoch 0019, iter [01300, 05004], lr: 0.100000, loss: 2.5942
2022-07-04 16:57:05 - train: epoch 0019, iter [01400, 05004], lr: 0.100000, loss: 2.3214
2022-07-04 16:57:40 - train: epoch 0019, iter [01500, 05004], lr: 0.100000, loss: 2.7337
2022-07-04 16:58:13 - train: epoch 0019, iter [01600, 05004], lr: 0.100000, loss: 2.2894
2022-07-04 16:58:45 - train: epoch 0019, iter [01700, 05004], lr: 0.100000, loss: 2.4215
2022-07-04 16:59:19 - train: epoch 0019, iter [01800, 05004], lr: 0.100000, loss: 2.3119
2022-07-04 16:59:52 - train: epoch 0019, iter [01900, 05004], lr: 0.100000, loss: 2.6314
2022-07-04 17:00:25 - train: epoch 0019, iter [02000, 05004], lr: 0.100000, loss: 2.3486
2022-07-04 17:00:58 - train: epoch 0019, iter [02100, 05004], lr: 0.100000, loss: 2.3097
2022-07-04 17:01:32 - train: epoch 0019, iter [02200, 05004], lr: 0.100000, loss: 2.4032
2022-07-04 17:02:05 - train: epoch 0019, iter [02300, 05004], lr: 0.100000, loss: 2.4119
2022-07-04 17:02:38 - train: epoch 0019, iter [02400, 05004], lr: 0.100000, loss: 2.5131
2022-07-04 17:03:11 - train: epoch 0019, iter [02500, 05004], lr: 0.100000, loss: 2.2604
2022-07-04 17:03:44 - train: epoch 0019, iter [02600, 05004], lr: 0.100000, loss: 2.4185
2022-07-04 17:04:17 - train: epoch 0019, iter [02700, 05004], lr: 0.100000, loss: 2.5873
2022-07-04 17:04:50 - train: epoch 0019, iter [02800, 05004], lr: 0.100000, loss: 2.5414
2022-07-04 17:05:23 - train: epoch 0019, iter [02900, 05004], lr: 0.100000, loss: 2.4043
2022-07-04 17:05:56 - train: epoch 0019, iter [03000, 05004], lr: 0.100000, loss: 2.7316
2022-07-04 17:06:30 - train: epoch 0019, iter [03100, 05004], lr: 0.100000, loss: 2.5964
2022-07-04 17:07:03 - train: epoch 0019, iter [03200, 05004], lr: 0.100000, loss: 2.1958
2022-07-04 17:07:36 - train: epoch 0019, iter [03300, 05004], lr: 0.100000, loss: 2.3504
2022-07-04 17:08:09 - train: epoch 0019, iter [03400, 05004], lr: 0.100000, loss: 2.4182
2022-07-04 17:08:42 - train: epoch 0019, iter [03500, 05004], lr: 0.100000, loss: 2.4327
2022-07-04 17:09:16 - train: epoch 0019, iter [03600, 05004], lr: 0.100000, loss: 2.2845
2022-07-04 17:09:49 - train: epoch 0019, iter [03700, 05004], lr: 0.100000, loss: 2.5279
2022-07-04 17:10:23 - train: epoch 0019, iter [03800, 05004], lr: 0.100000, loss: 2.4601
2022-07-04 17:10:56 - train: epoch 0019, iter [03900, 05004], lr: 0.100000, loss: 2.3520
2022-07-04 17:11:28 - train: epoch 0019, iter [04000, 05004], lr: 0.100000, loss: 2.2438
2022-07-04 17:12:02 - train: epoch 0019, iter [04100, 05004], lr: 0.100000, loss: 2.4180
2022-07-04 17:12:35 - train: epoch 0019, iter [04200, 05004], lr: 0.100000, loss: 2.4205
2022-07-04 17:13:08 - train: epoch 0019, iter [04300, 05004], lr: 0.100000, loss: 2.1061
2022-07-04 17:13:42 - train: epoch 0019, iter [04400, 05004], lr: 0.100000, loss: 2.5346
2022-07-04 17:14:14 - train: epoch 0019, iter [04500, 05004], lr: 0.100000, loss: 2.6551
2022-07-04 17:14:47 - train: epoch 0019, iter [04600, 05004], lr: 0.100000, loss: 2.4279
2022-07-04 17:15:20 - train: epoch 0019, iter [04700, 05004], lr: 0.100000, loss: 2.3918
2022-07-04 17:15:54 - train: epoch 0019, iter [04800, 05004], lr: 0.100000, loss: 2.4314
2022-07-04 17:16:26 - train: epoch 0019, iter [04900, 05004], lr: 0.100000, loss: 2.3037
2022-07-04 17:16:59 - train: epoch 0019, iter [05000, 05004], lr: 0.100000, loss: 2.3852
2022-07-04 17:16:59 - train: epoch 019, train_loss: 2.4098
2022-07-04 17:18:12 - eval: epoch: 019, acc1: 50.540%, acc5: 76.028%, test_loss: 2.1479, per_image_load_time: 2.449ms, per_image_inference_time: 0.169ms
2022-07-04 17:18:13 - until epoch: 019, best_acc1: 50.690%
2022-07-04 17:18:13 - epoch 020 lr: 0.100000
2022-07-04 17:18:50 - train: epoch 0020, iter [00100, 05004], lr: 0.100000, loss: 2.5670
2022-07-04 17:19:23 - train: epoch 0020, iter [00200, 05004], lr: 0.100000, loss: 2.1370
2022-07-04 17:19:57 - train: epoch 0020, iter [00300, 05004], lr: 0.100000, loss: 2.3657
2022-07-04 17:20:29 - train: epoch 0020, iter [00400, 05004], lr: 0.100000, loss: 2.2003
2022-07-04 17:21:03 - train: epoch 0020, iter [00500, 05004], lr: 0.100000, loss: 2.3797
2022-07-04 17:21:36 - train: epoch 0020, iter [00600, 05004], lr: 0.100000, loss: 2.5765
2022-07-04 17:22:08 - train: epoch 0020, iter [00700, 05004], lr: 0.100000, loss: 2.1425
2022-07-04 17:22:42 - train: epoch 0020, iter [00800, 05004], lr: 0.100000, loss: 2.3920
2022-07-04 17:23:15 - train: epoch 0020, iter [00900, 05004], lr: 0.100000, loss: 2.6760
2022-07-04 17:23:49 - train: epoch 0020, iter [01000, 05004], lr: 0.100000, loss: 2.4488
2022-07-04 17:24:21 - train: epoch 0020, iter [01100, 05004], lr: 0.100000, loss: 2.1897
2022-07-04 17:24:54 - train: epoch 0020, iter [01200, 05004], lr: 0.100000, loss: 2.2098
2022-07-04 17:25:28 - train: epoch 0020, iter [01300, 05004], lr: 0.100000, loss: 2.2080
2022-07-04 17:26:01 - train: epoch 0020, iter [01400, 05004], lr: 0.100000, loss: 2.5603
2022-07-04 17:26:34 - train: epoch 0020, iter [01500, 05004], lr: 0.100000, loss: 2.4766
2022-07-04 17:27:07 - train: epoch 0020, iter [01600, 05004], lr: 0.100000, loss: 2.2941
2022-07-04 17:27:40 - train: epoch 0020, iter [01700, 05004], lr: 0.100000, loss: 2.0738
2022-07-04 17:28:13 - train: epoch 0020, iter [01800, 05004], lr: 0.100000, loss: 2.2850
2022-07-04 17:28:46 - train: epoch 0020, iter [01900, 05004], lr: 0.100000, loss: 2.1626
2022-07-04 17:29:19 - train: epoch 0020, iter [02000, 05004], lr: 0.100000, loss: 2.3755
2022-07-04 17:29:52 - train: epoch 0020, iter [02100, 05004], lr: 0.100000, loss: 2.5744
2022-07-04 17:30:26 - train: epoch 0020, iter [02200, 05004], lr: 0.100000, loss: 2.2798
2022-07-04 17:30:59 - train: epoch 0020, iter [02300, 05004], lr: 0.100000, loss: 2.2904
2022-07-04 17:31:32 - train: epoch 0020, iter [02400, 05004], lr: 0.100000, loss: 2.6026
2022-07-04 17:32:05 - train: epoch 0020, iter [02500, 05004], lr: 0.100000, loss: 2.3984
2022-07-04 17:32:39 - train: epoch 0020, iter [02600, 05004], lr: 0.100000, loss: 2.2170
2022-07-04 17:33:12 - train: epoch 0020, iter [02700, 05004], lr: 0.100000, loss: 2.4058
2022-07-04 17:33:45 - train: epoch 0020, iter [02800, 05004], lr: 0.100000, loss: 2.4469
2022-07-04 17:34:18 - train: epoch 0020, iter [02900, 05004], lr: 0.100000, loss: 2.3622
2022-07-04 17:34:51 - train: epoch 0020, iter [03000, 05004], lr: 0.100000, loss: 2.2929
2022-07-04 17:35:24 - train: epoch 0020, iter [03100, 05004], lr: 0.100000, loss: 2.3811
2022-07-04 17:35:58 - train: epoch 0020, iter [03200, 05004], lr: 0.100000, loss: 2.5440
2022-07-04 17:36:32 - train: epoch 0020, iter [03300, 05004], lr: 0.100000, loss: 2.2179
2022-07-04 17:37:04 - train: epoch 0020, iter [03400, 05004], lr: 0.100000, loss: 2.3957
2022-07-04 17:37:37 - train: epoch 0020, iter [03500, 05004], lr: 0.100000, loss: 2.3062
2022-07-04 17:38:11 - train: epoch 0020, iter [03600, 05004], lr: 0.100000, loss: 2.3601
2022-07-04 17:38:43 - train: epoch 0020, iter [03700, 05004], lr: 0.100000, loss: 2.3244
2022-07-04 17:39:18 - train: epoch 0020, iter [03800, 05004], lr: 0.100000, loss: 2.4017
2022-07-04 17:39:50 - train: epoch 0020, iter [03900, 05004], lr: 0.100000, loss: 2.5385
2022-07-04 17:40:23 - train: epoch 0020, iter [04000, 05004], lr: 0.100000, loss: 2.1671
2022-07-04 17:40:56 - train: epoch 0020, iter [04100, 05004], lr: 0.100000, loss: 2.2608
2022-07-04 17:41:30 - train: epoch 0020, iter [04200, 05004], lr: 0.100000, loss: 2.3449
2022-07-04 17:42:02 - train: epoch 0020, iter [04300, 05004], lr: 0.100000, loss: 2.4920
2022-07-04 17:42:36 - train: epoch 0020, iter [04400, 05004], lr: 0.100000, loss: 2.3520
2022-07-04 17:43:08 - train: epoch 0020, iter [04500, 05004], lr: 0.100000, loss: 2.5614
2022-07-04 17:43:42 - train: epoch 0020, iter [04600, 05004], lr: 0.100000, loss: 2.4483
2022-07-04 17:44:15 - train: epoch 0020, iter [04700, 05004], lr: 0.100000, loss: 2.2505
2022-07-04 17:44:49 - train: epoch 0020, iter [04800, 05004], lr: 0.100000, loss: 2.4166
2022-07-04 17:45:21 - train: epoch 0020, iter [04900, 05004], lr: 0.100000, loss: 2.4270
2022-07-04 17:45:53 - train: epoch 0020, iter [05000, 05004], lr: 0.100000, loss: 2.2143
2022-07-04 17:45:54 - train: epoch 020, train_loss: 2.3973
2022-07-04 17:47:07 - eval: epoch: 020, acc1: 50.526%, acc5: 76.684%, test_loss: 2.1372, per_image_load_time: 2.660ms, per_image_inference_time: 0.180ms
2022-07-04 17:47:07 - until epoch: 020, best_acc1: 50.690%
2022-07-04 17:47:07 - epoch 021 lr: 0.100000
2022-07-04 17:47:45 - train: epoch 0021, iter [00100, 05004], lr: 0.100000, loss: 2.2775
2022-07-04 17:48:17 - train: epoch 0021, iter [00200, 05004], lr: 0.100000, loss: 2.3363
2022-07-04 17:48:51 - train: epoch 0021, iter [00300, 05004], lr: 0.100000, loss: 2.0113
2022-07-04 17:49:23 - train: epoch 0021, iter [00400, 05004], lr: 0.100000, loss: 2.5020
2022-07-04 17:49:58 - train: epoch 0021, iter [00500, 05004], lr: 0.100000, loss: 2.2881
2022-07-04 17:50:31 - train: epoch 0021, iter [00600, 05004], lr: 0.100000, loss: 2.1838
2022-07-04 17:51:04 - train: epoch 0021, iter [00700, 05004], lr: 0.100000, loss: 2.2337
2022-07-04 17:51:37 - train: epoch 0021, iter [00800, 05004], lr: 0.100000, loss: 2.5364
2022-07-04 17:52:11 - train: epoch 0021, iter [00900, 05004], lr: 0.100000, loss: 2.4344
2022-07-04 17:52:43 - train: epoch 0021, iter [01000, 05004], lr: 0.100000, loss: 2.3044
2022-07-04 17:53:16 - train: epoch 0021, iter [01100, 05004], lr: 0.100000, loss: 2.4090
2022-07-04 17:53:48 - train: epoch 0021, iter [01200, 05004], lr: 0.100000, loss: 2.3322
2022-07-04 17:54:22 - train: epoch 0021, iter [01300, 05004], lr: 0.100000, loss: 2.3762
2022-07-04 17:54:55 - train: epoch 0021, iter [01400, 05004], lr: 0.100000, loss: 2.3297
2022-07-04 17:55:28 - train: epoch 0021, iter [01500, 05004], lr: 0.100000, loss: 2.1565
2022-07-04 17:56:01 - train: epoch 0021, iter [01600, 05004], lr: 0.100000, loss: 2.3411
2022-07-04 17:56:35 - train: epoch 0021, iter [01700, 05004], lr: 0.100000, loss: 2.4052
2022-07-04 17:57:07 - train: epoch 0021, iter [01800, 05004], lr: 0.100000, loss: 2.2364
2022-07-04 17:57:41 - train: epoch 0021, iter [01900, 05004], lr: 0.100000, loss: 2.3895
2022-07-04 17:58:13 - train: epoch 0021, iter [02000, 05004], lr: 0.100000, loss: 2.5945
2022-07-04 17:58:46 - train: epoch 0021, iter [02100, 05004], lr: 0.100000, loss: 2.1989
2022-07-04 17:59:19 - train: epoch 0021, iter [02200, 05004], lr: 0.100000, loss: 2.3716
2022-07-04 17:59:53 - train: epoch 0021, iter [02300, 05004], lr: 0.100000, loss: 2.2548
2022-07-04 18:00:25 - train: epoch 0021, iter [02400, 05004], lr: 0.100000, loss: 2.3106
2022-07-04 18:00:58 - train: epoch 0021, iter [02500, 05004], lr: 0.100000, loss: 2.4975
2022-07-04 18:01:32 - train: epoch 0021, iter [02600, 05004], lr: 0.100000, loss: 2.6141
2022-07-04 18:02:05 - train: epoch 0021, iter [02700, 05004], lr: 0.100000, loss: 2.3055
2022-07-04 18:02:40 - train: epoch 0021, iter [02800, 05004], lr: 0.100000, loss: 2.3397
2022-07-04 18:03:11 - train: epoch 0021, iter [02900, 05004], lr: 0.100000, loss: 2.2497
2022-07-04 18:03:45 - train: epoch 0021, iter [03000, 05004], lr: 0.100000, loss: 2.6042
2022-07-04 18:04:18 - train: epoch 0021, iter [03100, 05004], lr: 0.100000, loss: 2.5036
2022-07-04 18:04:51 - train: epoch 0021, iter [03200, 05004], lr: 0.100000, loss: 2.4821
2022-07-04 18:05:24 - train: epoch 0021, iter [03300, 05004], lr: 0.100000, loss: 2.6597
2022-07-04 18:05:56 - train: epoch 0021, iter [03400, 05004], lr: 0.100000, loss: 2.5349
2022-07-04 18:06:29 - train: epoch 0021, iter [03500, 05004], lr: 0.100000, loss: 2.2886
2022-07-04 18:07:03 - train: epoch 0021, iter [03600, 05004], lr: 0.100000, loss: 2.3972
2022-07-04 18:07:36 - train: epoch 0021, iter [03700, 05004], lr: 0.100000, loss: 2.3473
2022-07-04 18:08:11 - train: epoch 0021, iter [03800, 05004], lr: 0.100000, loss: 2.3874
2022-07-04 18:08:42 - train: epoch 0021, iter [03900, 05004], lr: 0.100000, loss: 2.2486
2022-07-04 18:09:16 - train: epoch 0021, iter [04000, 05004], lr: 0.100000, loss: 2.5982
2022-07-04 18:09:49 - train: epoch 0021, iter [04100, 05004], lr: 0.100000, loss: 2.2943
2022-07-04 18:10:23 - train: epoch 0021, iter [04200, 05004], lr: 0.100000, loss: 2.4110
2022-07-04 18:10:55 - train: epoch 0021, iter [04300, 05004], lr: 0.100000, loss: 2.4986
2022-07-04 18:11:29 - train: epoch 0021, iter [04400, 05004], lr: 0.100000, loss: 2.4641
2022-07-04 18:12:01 - train: epoch 0021, iter [04500, 05004], lr: 0.100000, loss: 2.6090
2022-07-04 18:12:35 - train: epoch 0021, iter [04600, 05004], lr: 0.100000, loss: 2.3377
2022-07-04 18:13:08 - train: epoch 0021, iter [04700, 05004], lr: 0.100000, loss: 2.4744
2022-07-04 18:13:41 - train: epoch 0021, iter [04800, 05004], lr: 0.100000, loss: 2.5699
2022-07-04 18:14:14 - train: epoch 0021, iter [04900, 05004], lr: 0.100000, loss: 2.1918
2022-07-04 18:14:45 - train: epoch 0021, iter [05000, 05004], lr: 0.100000, loss: 2.4303
2022-07-04 18:14:46 - train: epoch 021, train_loss: 2.3924
2022-07-04 18:15:59 - eval: epoch: 021, acc1: 50.700%, acc5: 76.438%, test_loss: 2.1318, per_image_load_time: 2.339ms, per_image_inference_time: 0.180ms
2022-07-04 18:15:59 - until epoch: 021, best_acc1: 50.700%
2022-07-04 18:15:59 - epoch 022 lr: 0.100000
2022-07-04 18:16:37 - train: epoch 0022, iter [00100, 05004], lr: 0.100000, loss: 2.0999
2022-07-04 18:17:09 - train: epoch 0022, iter [00200, 05004], lr: 0.100000, loss: 2.2521
2022-07-04 18:17:43 - train: epoch 0022, iter [00300, 05004], lr: 0.100000, loss: 2.0551
2022-07-04 18:18:16 - train: epoch 0022, iter [00400, 05004], lr: 0.100000, loss: 2.1372
2022-07-04 18:18:49 - train: epoch 0022, iter [00500, 05004], lr: 0.100000, loss: 2.3356
2022-07-04 18:19:23 - train: epoch 0022, iter [00600, 05004], lr: 0.100000, loss: 2.4097
2022-07-04 18:19:55 - train: epoch 0022, iter [00700, 05004], lr: 0.100000, loss: 2.4803
2022-07-04 18:20:28 - train: epoch 0022, iter [00800, 05004], lr: 0.100000, loss: 2.5209
2022-07-04 18:21:00 - train: epoch 0022, iter [00900, 05004], lr: 0.100000, loss: 2.4949
2022-07-04 18:21:34 - train: epoch 0022, iter [01000, 05004], lr: 0.100000, loss: 2.4188
2022-07-04 18:22:06 - train: epoch 0022, iter [01100, 05004], lr: 0.100000, loss: 2.4222
2022-07-04 18:22:40 - train: epoch 0022, iter [01200, 05004], lr: 0.100000, loss: 2.0604
2022-07-04 18:23:13 - train: epoch 0022, iter [01300, 05004], lr: 0.100000, loss: 2.3113
2022-07-04 18:23:47 - train: epoch 0022, iter [01400, 05004], lr: 0.100000, loss: 2.3326
2022-07-04 18:24:19 - train: epoch 0022, iter [01500, 05004], lr: 0.100000, loss: 2.2944
2022-07-04 18:24:53 - train: epoch 0022, iter [01600, 05004], lr: 0.100000, loss: 2.2781
2022-07-04 18:25:26 - train: epoch 0022, iter [01700, 05004], lr: 0.100000, loss: 2.1354
2022-07-04 18:25:59 - train: epoch 0022, iter [01800, 05004], lr: 0.100000, loss: 2.6306
2022-07-04 18:26:31 - train: epoch 0022, iter [01900, 05004], lr: 0.100000, loss: 2.3101
2022-07-04 18:27:05 - train: epoch 0022, iter [02000, 05004], lr: 0.100000, loss: 2.3332
2022-07-04 18:27:37 - train: epoch 0022, iter [02100, 05004], lr: 0.100000, loss: 2.4187
2022-07-04 18:28:11 - train: epoch 0022, iter [02200, 05004], lr: 0.100000, loss: 2.2346
2022-07-04 18:28:44 - train: epoch 0022, iter [02300, 05004], lr: 0.100000, loss: 2.4659
2022-07-04 18:29:18 - train: epoch 0022, iter [02400, 05004], lr: 0.100000, loss: 2.3043
2022-07-04 18:29:50 - train: epoch 0022, iter [02500, 05004], lr: 0.100000, loss: 2.3833
2022-07-04 18:30:23 - train: epoch 0022, iter [02600, 05004], lr: 0.100000, loss: 2.0955
2022-07-04 18:30:57 - train: epoch 0022, iter [02700, 05004], lr: 0.100000, loss: 2.2394
2022-07-04 18:31:30 - train: epoch 0022, iter [02800, 05004], lr: 0.100000, loss: 2.6827
2022-07-04 18:32:02 - train: epoch 0022, iter [02900, 05004], lr: 0.100000, loss: 2.2055
2022-07-04 18:32:35 - train: epoch 0022, iter [03000, 05004], lr: 0.100000, loss: 2.4209
2022-07-04 18:33:09 - train: epoch 0022, iter [03100, 05004], lr: 0.100000, loss: 2.5125
2022-07-04 18:33:41 - train: epoch 0022, iter [03200, 05004], lr: 0.100000, loss: 2.5436
2022-07-04 18:34:14 - train: epoch 0022, iter [03300, 05004], lr: 0.100000, loss: 2.3772
2022-07-04 18:34:47 - train: epoch 0022, iter [03400, 05004], lr: 0.100000, loss: 2.2982
2022-07-04 18:35:20 - train: epoch 0022, iter [03500, 05004], lr: 0.100000, loss: 2.4812
2022-07-04 18:35:54 - train: epoch 0022, iter [03600, 05004], lr: 0.100000, loss: 2.4430
2022-07-04 18:36:26 - train: epoch 0022, iter [03700, 05004], lr: 0.100000, loss: 2.5027
2022-07-04 18:37:00 - train: epoch 0022, iter [03800, 05004], lr: 0.100000, loss: 2.5385
2022-07-04 18:37:32 - train: epoch 0022, iter [03900, 05004], lr: 0.100000, loss: 2.3959
2022-07-04 18:38:07 - train: epoch 0022, iter [04000, 05004], lr: 0.100000, loss: 2.4084
2022-07-04 18:38:38 - train: epoch 0022, iter [04100, 05004], lr: 0.100000, loss: 2.2598
2022-07-04 18:39:13 - train: epoch 0022, iter [04200, 05004], lr: 0.100000, loss: 2.3900
2022-07-04 18:39:45 - train: epoch 0022, iter [04300, 05004], lr: 0.100000, loss: 2.6619
2022-07-04 18:40:19 - train: epoch 0022, iter [04400, 05004], lr: 0.100000, loss: 2.5257
2022-07-04 18:40:51 - train: epoch 0022, iter [04500, 05004], lr: 0.100000, loss: 2.4114
2022-07-04 18:41:25 - train: epoch 0022, iter [04600, 05004], lr: 0.100000, loss: 2.6029
2022-07-04 18:41:58 - train: epoch 0022, iter [04700, 05004], lr: 0.100000, loss: 2.5289
2022-07-04 18:42:31 - train: epoch 0022, iter [04800, 05004], lr: 0.100000, loss: 2.2403
2022-07-04 18:43:04 - train: epoch 0022, iter [04900, 05004], lr: 0.100000, loss: 2.2049
2022-07-04 18:43:36 - train: epoch 0022, iter [05000, 05004], lr: 0.100000, loss: 2.2996
2022-07-04 18:43:36 - train: epoch 022, train_loss: 2.3894
2022-07-04 18:44:49 - eval: epoch: 022, acc1: 50.990%, acc5: 76.420%, test_loss: 2.1330, per_image_load_time: 2.640ms, per_image_inference_time: 0.165ms
2022-07-04 18:44:49 - until epoch: 022, best_acc1: 50.990%
2022-07-04 18:44:49 - epoch 023 lr: 0.100000
2022-07-04 18:45:27 - train: epoch 0023, iter [00100, 05004], lr: 0.100000, loss: 2.1607
2022-07-04 18:46:00 - train: epoch 0023, iter [00200, 05004], lr: 0.100000, loss: 1.9954
2022-07-04 18:46:34 - train: epoch 0023, iter [00300, 05004], lr: 0.100000, loss: 2.3042
2022-07-04 18:47:07 - train: epoch 0023, iter [00400, 05004], lr: 0.100000, loss: 2.4037
2022-07-04 18:47:38 - train: epoch 0023, iter [00500, 05004], lr: 0.100000, loss: 2.4305
2022-07-04 18:48:12 - train: epoch 0023, iter [00600, 05004], lr: 0.100000, loss: 2.3743
2022-07-04 18:48:45 - train: epoch 0023, iter [00700, 05004], lr: 0.100000, loss: 2.1542
2022-07-04 18:49:18 - train: epoch 0023, iter [00800, 05004], lr: 0.100000, loss: 2.3274
2022-07-04 18:49:51 - train: epoch 0023, iter [00900, 05004], lr: 0.100000, loss: 2.3318
2022-07-04 18:50:24 - train: epoch 0023, iter [01000, 05004], lr: 0.100000, loss: 2.2245
2022-07-04 18:50:57 - train: epoch 0023, iter [01100, 05004], lr: 0.100000, loss: 2.4315
2022-07-04 18:51:30 - train: epoch 0023, iter [01200, 05004], lr: 0.100000, loss: 2.2509
2022-07-04 18:52:04 - train: epoch 0023, iter [01300, 05004], lr: 0.100000, loss: 2.3700
2022-07-04 18:52:37 - train: epoch 0023, iter [01400, 05004], lr: 0.100000, loss: 2.4673
2022-07-04 18:53:10 - train: epoch 0023, iter [01500, 05004], lr: 0.100000, loss: 2.2033
2022-07-04 18:53:43 - train: epoch 0023, iter [01600, 05004], lr: 0.100000, loss: 2.4049
2022-07-04 18:54:16 - train: epoch 0023, iter [01700, 05004], lr: 0.100000, loss: 2.6098
2022-07-04 18:54:51 - train: epoch 0023, iter [01800, 05004], lr: 0.100000, loss: 2.2395
2022-07-04 18:55:22 - train: epoch 0023, iter [01900, 05004], lr: 0.100000, loss: 2.3769
2022-07-04 18:55:56 - train: epoch 0023, iter [02000, 05004], lr: 0.100000, loss: 1.9896
2022-07-04 18:56:28 - train: epoch 0023, iter [02100, 05004], lr: 0.100000, loss: 2.4680
2022-07-04 18:57:02 - train: epoch 0023, iter [02200, 05004], lr: 0.100000, loss: 2.0689
2022-07-04 18:57:35 - train: epoch 0023, iter [02300, 05004], lr: 0.100000, loss: 2.3218
2022-07-04 18:58:08 - train: epoch 0023, iter [02400, 05004], lr: 0.100000, loss: 2.3300
2022-07-04 18:58:42 - train: epoch 0023, iter [02500, 05004], lr: 0.100000, loss: 2.4496
2022-07-04 18:59:15 - train: epoch 0023, iter [02600, 05004], lr: 0.100000, loss: 2.4911
2022-07-04 18:59:48 - train: epoch 0023, iter [02700, 05004], lr: 0.100000, loss: 2.2499
2022-07-04 19:00:21 - train: epoch 0023, iter [02800, 05004], lr: 0.100000, loss: 2.3886
2022-07-04 19:00:54 - train: epoch 0023, iter [02900, 05004], lr: 0.100000, loss: 2.4298
2022-07-04 19:01:28 - train: epoch 0023, iter [03000, 05004], lr: 0.100000, loss: 2.6240
2022-07-04 19:02:01 - train: epoch 0023, iter [03100, 05004], lr: 0.100000, loss: 2.5237
2022-07-04 19:02:34 - train: epoch 0023, iter [03200, 05004], lr: 0.100000, loss: 2.5458
2022-07-04 19:03:07 - train: epoch 0023, iter [03300, 05004], lr: 0.100000, loss: 2.4928
2022-07-04 19:03:41 - train: epoch 0023, iter [03400, 05004], lr: 0.100000, loss: 2.5835
2022-07-04 19:04:14 - train: epoch 0023, iter [03500, 05004], lr: 0.100000, loss: 2.2868
2022-07-04 19:04:47 - train: epoch 0023, iter [03600, 05004], lr: 0.100000, loss: 2.1466
2022-07-04 19:05:20 - train: epoch 0023, iter [03700, 05004], lr: 0.100000, loss: 2.3813
2022-07-04 19:05:54 - train: epoch 0023, iter [03800, 05004], lr: 0.100000, loss: 2.4755
2022-07-04 19:06:26 - train: epoch 0023, iter [03900, 05004], lr: 0.100000, loss: 2.3108
2022-07-04 19:07:00 - train: epoch 0023, iter [04000, 05004], lr: 0.100000, loss: 2.4118
2022-07-04 19:07:33 - train: epoch 0023, iter [04100, 05004], lr: 0.100000, loss: 2.2436
2022-07-04 19:08:06 - train: epoch 0023, iter [04200, 05004], lr: 0.100000, loss: 2.3789
2022-07-04 19:08:39 - train: epoch 0023, iter [04300, 05004], lr: 0.100000, loss: 2.1572
2022-07-04 19:09:13 - train: epoch 0023, iter [04400, 05004], lr: 0.100000, loss: 2.2280
2022-07-04 19:09:46 - train: epoch 0023, iter [04500, 05004], lr: 0.100000, loss: 2.1587
2022-07-04 19:10:19 - train: epoch 0023, iter [04600, 05004], lr: 0.100000, loss: 2.3501
2022-07-04 19:10:52 - train: epoch 0023, iter [04700, 05004], lr: 0.100000, loss: 2.2291
2022-07-04 19:11:25 - train: epoch 0023, iter [04800, 05004], lr: 0.100000, loss: 2.3548
2022-07-04 19:11:58 - train: epoch 0023, iter [04900, 05004], lr: 0.100000, loss: 2.2766
2022-07-04 19:12:30 - train: epoch 0023, iter [05000, 05004], lr: 0.100000, loss: 2.4865
2022-07-04 19:12:30 - train: epoch 023, train_loss: 2.3840
2022-07-04 19:13:43 - eval: epoch: 023, acc1: 49.980%, acc5: 75.888%, test_loss: 2.1765, per_image_load_time: 2.596ms, per_image_inference_time: 0.177ms
2022-07-04 19:13:43 - until epoch: 023, best_acc1: 50.990%
2022-07-04 19:13:43 - epoch 024 lr: 0.100000
2022-07-04 19:14:20 - train: epoch 0024, iter [00100, 05004], lr: 0.100000, loss: 2.3262
2022-07-04 19:14:55 - train: epoch 0024, iter [00200, 05004], lr: 0.100000, loss: 2.3719
2022-07-04 19:15:27 - train: epoch 0024, iter [00300, 05004], lr: 0.100000, loss: 2.2550
2022-07-04 19:16:00 - train: epoch 0024, iter [00400, 05004], lr: 0.100000, loss: 2.4987
2022-07-04 19:16:32 - train: epoch 0024, iter [00500, 05004], lr: 0.100000, loss: 2.3176
2022-07-04 19:17:05 - train: epoch 0024, iter [00600, 05004], lr: 0.100000, loss: 2.0628
2022-07-04 19:17:39 - train: epoch 0024, iter [00700, 05004], lr: 0.100000, loss: 2.2502
2022-07-04 19:18:12 - train: epoch 0024, iter [00800, 05004], lr: 0.100000, loss: 2.2539
2022-07-04 19:18:44 - train: epoch 0024, iter [00900, 05004], lr: 0.100000, loss: 2.3487
2022-07-04 19:19:18 - train: epoch 0024, iter [01000, 05004], lr: 0.100000, loss: 2.3308
2022-07-04 19:19:51 - train: epoch 0024, iter [01100, 05004], lr: 0.100000, loss: 2.0897
2022-07-04 19:20:24 - train: epoch 0024, iter [01200, 05004], lr: 0.100000, loss: 2.2488
2022-07-04 19:20:56 - train: epoch 0024, iter [01300, 05004], lr: 0.100000, loss: 2.7946
2022-07-04 19:21:30 - train: epoch 0024, iter [01400, 05004], lr: 0.100000, loss: 2.2982
2022-07-04 19:22:03 - train: epoch 0024, iter [01500, 05004], lr: 0.100000, loss: 2.5058
2022-07-04 19:22:36 - train: epoch 0024, iter [01600, 05004], lr: 0.100000, loss: 2.3641
2022-07-04 19:23:09 - train: epoch 0024, iter [01700, 05004], lr: 0.100000, loss: 2.4056
2022-07-04 19:23:43 - train: epoch 0024, iter [01800, 05004], lr: 0.100000, loss: 2.5495
2022-07-04 19:24:15 - train: epoch 0024, iter [01900, 05004], lr: 0.100000, loss: 2.1744
2022-07-04 19:24:48 - train: epoch 0024, iter [02000, 05004], lr: 0.100000, loss: 2.4960
2022-07-04 19:25:22 - train: epoch 0024, iter [02100, 05004], lr: 0.100000, loss: 2.3673
2022-07-04 19:25:54 - train: epoch 0024, iter [02200, 05004], lr: 0.100000, loss: 2.2638
2022-07-04 19:26:28 - train: epoch 0024, iter [02300, 05004], lr: 0.100000, loss: 2.3861
2022-07-04 19:27:00 - train: epoch 0024, iter [02400, 05004], lr: 0.100000, loss: 2.2731
2022-07-04 19:27:35 - train: epoch 0024, iter [02500, 05004], lr: 0.100000, loss: 2.3294
2022-07-04 19:28:07 - train: epoch 0024, iter [02600, 05004], lr: 0.100000, loss: 2.3044
2022-07-04 19:28:41 - train: epoch 0024, iter [02700, 05004], lr: 0.100000, loss: 2.4924
2022-07-04 19:29:13 - train: epoch 0024, iter [02800, 05004], lr: 0.100000, loss: 2.4937
2022-07-04 19:29:48 - train: epoch 0024, iter [02900, 05004], lr: 0.100000, loss: 2.5453
2022-07-04 19:30:19 - train: epoch 0024, iter [03000, 05004], lr: 0.100000, loss: 2.1738
2022-07-04 19:30:53 - train: epoch 0024, iter [03100, 05004], lr: 0.100000, loss: 2.2252
2022-07-04 19:31:26 - train: epoch 0024, iter [03200, 05004], lr: 0.100000, loss: 2.5449
2022-07-04 19:32:00 - train: epoch 0024, iter [03300, 05004], lr: 0.100000, loss: 1.9874
2022-07-04 19:32:33 - train: epoch 0024, iter [03400, 05004], lr: 0.100000, loss: 2.4405
2022-07-04 19:33:05 - train: epoch 0024, iter [03500, 05004], lr: 0.100000, loss: 2.2665
2022-07-04 19:33:39 - train: epoch 0024, iter [03600, 05004], lr: 0.100000, loss: 2.4538
2022-07-04 19:34:13 - train: epoch 0024, iter [03700, 05004], lr: 0.100000, loss: 2.2696
2022-07-04 19:34:45 - train: epoch 0024, iter [03800, 05004], lr: 0.100000, loss: 2.7015
2022-07-04 19:35:19 - train: epoch 0024, iter [03900, 05004], lr: 0.100000, loss: 2.3103
2022-07-04 19:35:51 - train: epoch 0024, iter [04000, 05004], lr: 0.100000, loss: 2.3857
2022-07-04 19:36:25 - train: epoch 0024, iter [04100, 05004], lr: 0.100000, loss: 2.3837
2022-07-04 19:36:59 - train: epoch 0024, iter [04200, 05004], lr: 0.100000, loss: 2.2475
2022-07-04 19:37:31 - train: epoch 0024, iter [04300, 05004], lr: 0.100000, loss: 2.3738
2022-07-04 19:38:04 - train: epoch 0024, iter [04400, 05004], lr: 0.100000, loss: 2.4909
2022-07-04 19:38:37 - train: epoch 0024, iter [04500, 05004], lr: 0.100000, loss: 2.1693
2022-07-04 19:39:10 - train: epoch 0024, iter [04600, 05004], lr: 0.100000, loss: 2.3711
2022-07-04 19:39:44 - train: epoch 0024, iter [04700, 05004], lr: 0.100000, loss: 2.2630
2022-07-04 19:40:17 - train: epoch 0024, iter [04800, 05004], lr: 0.100000, loss: 2.2619
2022-07-04 19:40:52 - train: epoch 0024, iter [04900, 05004], lr: 0.100000, loss: 2.4349
2022-07-04 19:41:22 - train: epoch 0024, iter [05000, 05004], lr: 0.100000, loss: 2.5268
2022-07-04 19:41:22 - train: epoch 024, train_loss: 2.3788
2022-07-04 19:42:36 - eval: epoch: 024, acc1: 50.432%, acc5: 76.376%, test_loss: 2.1367, per_image_load_time: 2.680ms, per_image_inference_time: 0.175ms
2022-07-04 19:42:36 - until epoch: 024, best_acc1: 50.990%
2022-07-04 19:42:36 - epoch 025 lr: 0.100000
2022-07-04 19:43:13 - train: epoch 0025, iter [00100, 05004], lr: 0.100000, loss: 2.1069
2022-07-04 19:43:47 - train: epoch 0025, iter [00200, 05004], lr: 0.100000, loss: 2.1686
2022-07-04 19:44:20 - train: epoch 0025, iter [00300, 05004], lr: 0.100000, loss: 2.1838
2022-07-04 19:44:52 - train: epoch 0025, iter [00400, 05004], lr: 0.100000, loss: 2.3699
2022-07-04 19:45:25 - train: epoch 0025, iter [00500, 05004], lr: 0.100000, loss: 2.2642
2022-07-04 19:45:58 - train: epoch 0025, iter [00600, 05004], lr: 0.100000, loss: 2.3091
2022-07-04 19:46:30 - train: epoch 0025, iter [00700, 05004], lr: 0.100000, loss: 2.4626
2022-07-04 19:47:03 - train: epoch 0025, iter [00800, 05004], lr: 0.100000, loss: 2.2782
2022-07-04 19:47:36 - train: epoch 0025, iter [00900, 05004], lr: 0.100000, loss: 2.2127
2022-07-04 19:48:10 - train: epoch 0025, iter [01000, 05004], lr: 0.100000, loss: 2.2667
2022-07-04 19:48:42 - train: epoch 0025, iter [01100, 05004], lr: 0.100000, loss: 2.4095
2022-07-04 19:49:16 - train: epoch 0025, iter [01200, 05004], lr: 0.100000, loss: 2.3475
2022-07-04 19:49:48 - train: epoch 0025, iter [01300, 05004], lr: 0.100000, loss: 2.4193
2022-07-04 19:50:22 - train: epoch 0025, iter [01400, 05004], lr: 0.100000, loss: 2.3786
2022-07-04 19:50:55 - train: epoch 0025, iter [01500, 05004], lr: 0.100000, loss: 2.3685
2022-07-04 19:51:28 - train: epoch 0025, iter [01600, 05004], lr: 0.100000, loss: 2.0653
2022-07-04 19:52:00 - train: epoch 0025, iter [01700, 05004], lr: 0.100000, loss: 2.3541
2022-07-04 19:52:34 - train: epoch 0025, iter [01800, 05004], lr: 0.100000, loss: 2.2461
2022-07-04 19:53:07 - train: epoch 0025, iter [01900, 05004], lr: 0.100000, loss: 2.2019
2022-07-04 19:53:41 - train: epoch 0025, iter [02000, 05004], lr: 0.100000, loss: 2.3561
2022-07-04 19:54:14 - train: epoch 0025, iter [02100, 05004], lr: 0.100000, loss: 2.2328
2022-07-04 19:54:47 - train: epoch 0025, iter [02200, 05004], lr: 0.100000, loss: 2.2494
2022-07-04 19:55:20 - train: epoch 0025, iter [02300, 05004], lr: 0.100000, loss: 2.4524
2022-07-04 19:55:53 - train: epoch 0025, iter [02400, 05004], lr: 0.100000, loss: 2.1643
2022-07-04 19:56:27 - train: epoch 0025, iter [02500, 05004], lr: 0.100000, loss: 2.4927
2022-07-04 19:57:00 - train: epoch 0025, iter [02600, 05004], lr: 0.100000, loss: 2.4455
2022-07-04 19:57:33 - train: epoch 0025, iter [02700, 05004], lr: 0.100000, loss: 2.5047
2022-07-04 19:58:07 - train: epoch 0025, iter [02800, 05004], lr: 0.100000, loss: 2.2781
2022-07-04 19:58:40 - train: epoch 0025, iter [02900, 05004], lr: 0.100000, loss: 2.5921
2022-07-04 19:59:14 - train: epoch 0025, iter [03000, 05004], lr: 0.100000, loss: 2.6482
2022-07-04 19:59:46 - train: epoch 0025, iter [03100, 05004], lr: 0.100000, loss: 2.4051
2022-07-04 20:00:21 - train: epoch 0025, iter [03200, 05004], lr: 0.100000, loss: 2.5653
2022-07-04 20:00:54 - train: epoch 0025, iter [03300, 05004], lr: 0.100000, loss: 2.4205
2022-07-04 20:01:27 - train: epoch 0025, iter [03400, 05004], lr: 0.100000, loss: 2.6248
2022-07-04 20:02:00 - train: epoch 0025, iter [03500, 05004], lr: 0.100000, loss: 2.1449
2022-07-04 20:02:34 - train: epoch 0025, iter [03600, 05004], lr: 0.100000, loss: 2.5336
2022-07-04 20:03:06 - train: epoch 0025, iter [03700, 05004], lr: 0.100000, loss: 2.3312
2022-07-04 20:03:39 - train: epoch 0025, iter [03800, 05004], lr: 0.100000, loss: 2.4290
2022-07-04 20:04:13 - train: epoch 0025, iter [03900, 05004], lr: 0.100000, loss: 2.5920
2022-07-04 20:04:46 - train: epoch 0025, iter [04000, 05004], lr: 0.100000, loss: 2.5438
2022-07-04 20:05:20 - train: epoch 0025, iter [04100, 05004], lr: 0.100000, loss: 2.6859
2022-07-04 20:05:54 - train: epoch 0025, iter [04200, 05004], lr: 0.100000, loss: 2.3734
2022-07-04 20:06:26 - train: epoch 0025, iter [04300, 05004], lr: 0.100000, loss: 2.2928
2022-07-04 20:07:00 - train: epoch 0025, iter [04400, 05004], lr: 0.100000, loss: 2.2796
2022-07-04 20:07:32 - train: epoch 0025, iter [04500, 05004], lr: 0.100000, loss: 2.3001
2022-07-04 20:08:06 - train: epoch 0025, iter [04600, 05004], lr: 0.100000, loss: 2.3286
2022-07-04 20:08:39 - train: epoch 0025, iter [04700, 05004], lr: 0.100000, loss: 2.3524
2022-07-04 20:09:13 - train: epoch 0025, iter [04800, 05004], lr: 0.100000, loss: 2.0943
2022-07-04 20:09:45 - train: epoch 0025, iter [04900, 05004], lr: 0.100000, loss: 2.3764
2022-07-04 20:10:18 - train: epoch 0025, iter [05000, 05004], lr: 0.100000, loss: 2.5525
2022-07-04 20:10:18 - train: epoch 025, train_loss: 2.3734
2022-07-04 20:11:33 - eval: epoch: 025, acc1: 50.880%, acc5: 76.738%, test_loss: 2.1243, per_image_load_time: 1.958ms, per_image_inference_time: 0.171ms
2022-07-04 20:11:33 - until epoch: 025, best_acc1: 50.990%
2022-07-04 20:11:33 - epoch 026 lr: 0.100000
2022-07-04 20:12:11 - train: epoch 0026, iter [00100, 05004], lr: 0.100000, loss: 2.1531
2022-07-04 20:12:44 - train: epoch 0026, iter [00200, 05004], lr: 0.100000, loss: 2.1836
2022-07-04 20:13:17 - train: epoch 0026, iter [00300, 05004], lr: 0.100000, loss: 2.3928
2022-07-04 20:13:49 - train: epoch 0026, iter [00400, 05004], lr: 0.100000, loss: 2.3529
2022-07-04 20:14:21 - train: epoch 0026, iter [00500, 05004], lr: 0.100000, loss: 2.4392
2022-07-04 20:14:55 - train: epoch 0026, iter [00600, 05004], lr: 0.100000, loss: 2.4787
2022-07-04 20:15:27 - train: epoch 0026, iter [00700, 05004], lr: 0.100000, loss: 2.2313
2022-07-04 20:16:00 - train: epoch 0026, iter [00800, 05004], lr: 0.100000, loss: 2.0927
2022-07-04 20:16:33 - train: epoch 0026, iter [00900, 05004], lr: 0.100000, loss: 2.5560
2022-07-04 20:17:07 - train: epoch 0026, iter [01000, 05004], lr: 0.100000, loss: 2.3515
2022-07-04 20:17:40 - train: epoch 0026, iter [01100, 05004], lr: 0.100000, loss: 2.2451
2022-07-04 20:18:13 - train: epoch 0026, iter [01200, 05004], lr: 0.100000, loss: 2.3890
2022-07-04 20:18:46 - train: epoch 0026, iter [01300, 05004], lr: 0.100000, loss: 2.3125
2022-07-04 20:19:19 - train: epoch 0026, iter [01400, 05004], lr: 0.100000, loss: 2.4997
2022-07-04 20:19:52 - train: epoch 0026, iter [01500, 05004], lr: 0.100000, loss: 2.3501
2022-07-04 20:20:25 - train: epoch 0026, iter [01600, 05004], lr: 0.100000, loss: 2.6210
2022-07-04 20:20:59 - train: epoch 0026, iter [01700, 05004], lr: 0.100000, loss: 2.1845
2022-07-04 20:21:30 - train: epoch 0026, iter [01800, 05004], lr: 0.100000, loss: 2.4075
2022-07-04 20:22:04 - train: epoch 0026, iter [01900, 05004], lr: 0.100000, loss: 2.6401
2022-07-04 20:22:37 - train: epoch 0026, iter [02000, 05004], lr: 0.100000, loss: 2.5854
2022-07-04 20:23:09 - train: epoch 0026, iter [02100, 05004], lr: 0.100000, loss: 2.3869
2022-07-04 20:23:43 - train: epoch 0026, iter [02200, 05004], lr: 0.100000, loss: 2.3270
2022-07-04 20:24:16 - train: epoch 0026, iter [02300, 05004], lr: 0.100000, loss: 2.3833
2022-07-04 20:24:50 - train: epoch 0026, iter [02400, 05004], lr: 0.100000, loss: 2.5540
2022-07-04 20:25:22 - train: epoch 0026, iter [02500, 05004], lr: 0.100000, loss: 2.5239
2022-07-04 20:25:56 - train: epoch 0026, iter [02600, 05004], lr: 0.100000, loss: 2.3285
2022-07-04 20:26:29 - train: epoch 0026, iter [02700, 05004], lr: 0.100000, loss: 2.2863
2022-07-04 20:27:01 - train: epoch 0026, iter [02800, 05004], lr: 0.100000, loss: 2.2431
2022-07-04 20:27:34 - train: epoch 0026, iter [02900, 05004], lr: 0.100000, loss: 2.5239
2022-07-04 20:28:08 - train: epoch 0026, iter [03000, 05004], lr: 0.100000, loss: 2.3707
2022-07-04 20:28:42 - train: epoch 0026, iter [03100, 05004], lr: 0.100000, loss: 2.3770
2022-07-04 20:29:17 - train: epoch 0026, iter [03200, 05004], lr: 0.100000, loss: 2.2870
2022-07-04 20:29:49 - train: epoch 0026, iter [03300, 05004], lr: 0.100000, loss: 2.0691
2022-07-04 20:30:21 - train: epoch 0026, iter [03400, 05004], lr: 0.100000, loss: 2.5478
2022-07-04 20:30:54 - train: epoch 0026, iter [03500, 05004], lr: 0.100000, loss: 2.4547
2022-07-04 20:31:28 - train: epoch 0026, iter [03600, 05004], lr: 0.100000, loss: 2.3022
2022-07-04 20:32:02 - train: epoch 0026, iter [03700, 05004], lr: 0.100000, loss: 2.4348
2022-07-04 20:32:34 - train: epoch 0026, iter [03800, 05004], lr: 0.100000, loss: 2.5348
2022-07-04 20:33:08 - train: epoch 0026, iter [03900, 05004], lr: 0.100000, loss: 2.4907
2022-07-04 20:33:40 - train: epoch 0026, iter [04000, 05004], lr: 0.100000, loss: 2.6013
2022-07-04 20:34:14 - train: epoch 0026, iter [04100, 05004], lr: 0.100000, loss: 2.4363
2022-07-04 20:34:48 - train: epoch 0026, iter [04200, 05004], lr: 0.100000, loss: 2.5089
2022-07-04 20:35:20 - train: epoch 0026, iter [04300, 05004], lr: 0.100000, loss: 2.4387
2022-07-04 20:35:54 - train: epoch 0026, iter [04400, 05004], lr: 0.100000, loss: 2.5618
2022-07-04 20:36:27 - train: epoch 0026, iter [04500, 05004], lr: 0.100000, loss: 2.5791
2022-07-04 20:37:00 - train: epoch 0026, iter [04600, 05004], lr: 0.100000, loss: 2.2486
2022-07-04 20:37:33 - train: epoch 0026, iter [04700, 05004], lr: 0.100000, loss: 2.2666
2022-07-04 20:38:07 - train: epoch 0026, iter [04800, 05004], lr: 0.100000, loss: 2.2621
2022-07-04 20:38:40 - train: epoch 0026, iter [04900, 05004], lr: 0.100000, loss: 2.4306
2022-07-04 20:39:12 - train: epoch 0026, iter [05000, 05004], lr: 0.100000, loss: 2.5692
2022-07-04 20:39:13 - train: epoch 026, train_loss: 2.3683
2022-07-04 20:40:26 - eval: epoch: 026, acc1: 50.064%, acc5: 76.114%, test_loss: 2.1639, per_image_load_time: 2.704ms, per_image_inference_time: 0.171ms
2022-07-04 20:40:26 - until epoch: 026, best_acc1: 50.990%
2022-07-04 20:40:26 - epoch 027 lr: 0.100000
2022-07-04 20:41:04 - train: epoch 0027, iter [00100, 05004], lr: 0.100000, loss: 2.5245
2022-07-04 20:41:37 - train: epoch 0027, iter [00200, 05004], lr: 0.100000, loss: 2.2056
2022-07-04 20:42:09 - train: epoch 0027, iter [00300, 05004], lr: 0.100000, loss: 2.3955
2022-07-04 20:42:43 - train: epoch 0027, iter [00400, 05004], lr: 0.100000, loss: 2.5054
2022-07-04 20:43:16 - train: epoch 0027, iter [00500, 05004], lr: 0.100000, loss: 2.4540
2022-07-04 20:43:48 - train: epoch 0027, iter [00600, 05004], lr: 0.100000, loss: 2.5500
2022-07-04 20:44:21 - train: epoch 0027, iter [00700, 05004], lr: 0.100000, loss: 2.5722
2022-07-04 20:44:54 - train: epoch 0027, iter [00800, 05004], lr: 0.100000, loss: 2.3907
2022-07-04 20:45:28 - train: epoch 0027, iter [00900, 05004], lr: 0.100000, loss: 2.2413
2022-07-04 20:46:01 - train: epoch 0027, iter [01000, 05004], lr: 0.100000, loss: 2.5151
2022-07-04 20:46:34 - train: epoch 0027, iter [01100, 05004], lr: 0.100000, loss: 2.1930
2022-07-04 20:47:07 - train: epoch 0027, iter [01200, 05004], lr: 0.100000, loss: 2.6178
2022-07-04 20:47:41 - train: epoch 0027, iter [01300, 05004], lr: 0.100000, loss: 2.4544
2022-07-04 20:48:13 - train: epoch 0027, iter [01400, 05004], lr: 0.100000, loss: 2.5350
2022-07-04 20:48:47 - train: epoch 0027, iter [01500, 05004], lr: 0.100000, loss: 2.3684
2022-07-04 20:49:19 - train: epoch 0027, iter [01600, 05004], lr: 0.100000, loss: 2.3864
2022-07-04 20:49:52 - train: epoch 0027, iter [01700, 05004], lr: 0.100000, loss: 2.4007
2022-07-04 20:50:26 - train: epoch 0027, iter [01800, 05004], lr: 0.100000, loss: 2.3263
2022-07-04 20:50:58 - train: epoch 0027, iter [01900, 05004], lr: 0.100000, loss: 2.5867
2022-07-04 20:51:32 - train: epoch 0027, iter [02000, 05004], lr: 0.100000, loss: 2.2730
2022-07-04 20:52:04 - train: epoch 0027, iter [02100, 05004], lr: 0.100000, loss: 2.5671
2022-07-04 20:52:37 - train: epoch 0027, iter [02200, 05004], lr: 0.100000, loss: 2.5836
2022-07-04 20:53:10 - train: epoch 0027, iter [02300, 05004], lr: 0.100000, loss: 2.6615
2022-07-04 20:53:44 - train: epoch 0027, iter [02400, 05004], lr: 0.100000, loss: 2.2922
2022-07-04 20:54:17 - train: epoch 0027, iter [02500, 05004], lr: 0.100000, loss: 2.3387
2022-07-04 20:54:50 - train: epoch 0027, iter [02600, 05004], lr: 0.100000, loss: 2.6679
2022-07-04 20:55:23 - train: epoch 0027, iter [02700, 05004], lr: 0.100000, loss: 2.3900
2022-07-04 20:55:57 - train: epoch 0027, iter [02800, 05004], lr: 0.100000, loss: 2.6352
2022-07-04 20:56:29 - train: epoch 0027, iter [02900, 05004], lr: 0.100000, loss: 2.4391
2022-07-04 20:57:03 - train: epoch 0027, iter [03000, 05004], lr: 0.100000, loss: 2.1954
2022-07-04 20:57:36 - train: epoch 0027, iter [03100, 05004], lr: 0.100000, loss: 2.2959
2022-07-04 20:58:10 - train: epoch 0027, iter [03200, 05004], lr: 0.100000, loss: 2.2253
2022-07-04 20:58:43 - train: epoch 0027, iter [03300, 05004], lr: 0.100000, loss: 2.3777
2022-07-04 20:59:16 - train: epoch 0027, iter [03400, 05004], lr: 0.100000, loss: 2.2934
2022-07-04 20:59:49 - train: epoch 0027, iter [03500, 05004], lr: 0.100000, loss: 2.6514
2022-07-04 21:00:23 - train: epoch 0027, iter [03600, 05004], lr: 0.100000, loss: 2.2192
2022-07-04 21:00:56 - train: epoch 0027, iter [03700, 05004], lr: 0.100000, loss: 2.3701
2022-07-04 21:01:30 - train: epoch 0027, iter [03800, 05004], lr: 0.100000, loss: 2.0855
2022-07-04 21:02:02 - train: epoch 0027, iter [03900, 05004], lr: 0.100000, loss: 2.1666
2022-07-04 21:02:36 - train: epoch 0027, iter [04000, 05004], lr: 0.100000, loss: 2.4310
2022-07-04 21:03:09 - train: epoch 0027, iter [04100, 05004], lr: 0.100000, loss: 2.4922
2022-07-04 21:03:43 - train: epoch 0027, iter [04200, 05004], lr: 0.100000, loss: 2.4952
2022-07-04 21:04:16 - train: epoch 0027, iter [04300, 05004], lr: 0.100000, loss: 2.2086
2022-07-04 21:04:49 - train: epoch 0027, iter [04400, 05004], lr: 0.100000, loss: 2.3368
2022-07-04 21:05:21 - train: epoch 0027, iter [04500, 05004], lr: 0.100000, loss: 2.1449
2022-07-04 21:05:55 - train: epoch 0027, iter [04600, 05004], lr: 0.100000, loss: 2.3292
2022-07-04 21:06:28 - train: epoch 0027, iter [04700, 05004], lr: 0.100000, loss: 2.4623
2022-07-04 21:07:01 - train: epoch 0027, iter [04800, 05004], lr: 0.100000, loss: 2.4723
2022-07-04 21:07:35 - train: epoch 0027, iter [04900, 05004], lr: 0.100000, loss: 2.4639
2022-07-04 21:08:06 - train: epoch 0027, iter [05000, 05004], lr: 0.100000, loss: 2.0630
2022-07-04 21:08:07 - train: epoch 027, train_loss: 2.3646
2022-07-04 21:09:20 - eval: epoch: 027, acc1: 50.894%, acc5: 76.574%, test_loss: 2.1304, per_image_load_time: 2.648ms, per_image_inference_time: 0.189ms
2022-07-04 21:09:20 - until epoch: 027, best_acc1: 50.990%
2022-07-04 21:09:20 - epoch 028 lr: 0.100000
2022-07-04 21:09:59 - train: epoch 0028, iter [00100, 05004], lr: 0.100000, loss: 2.1373
2022-07-04 21:10:31 - train: epoch 0028, iter [00200, 05004], lr: 0.100000, loss: 2.2162
2022-07-04 21:11:04 - train: epoch 0028, iter [00300, 05004], lr: 0.100000, loss: 2.3527
2022-07-04 21:11:37 - train: epoch 0028, iter [00400, 05004], lr: 0.100000, loss: 2.2714
2022-07-04 21:12:10 - train: epoch 0028, iter [00500, 05004], lr: 0.100000, loss: 2.4161
2022-07-04 21:12:42 - train: epoch 0028, iter [00600, 05004], lr: 0.100000, loss: 2.3410
2022-07-04 21:13:16 - train: epoch 0028, iter [00700, 05004], lr: 0.100000, loss: 2.6101
2022-07-04 21:13:49 - train: epoch 0028, iter [00800, 05004], lr: 0.100000, loss: 2.0016
2022-07-04 21:14:21 - train: epoch 0028, iter [00900, 05004], lr: 0.100000, loss: 2.1265
2022-07-04 21:14:54 - train: epoch 0028, iter [01000, 05004], lr: 0.100000, loss: 2.3983
2022-07-04 21:15:27 - train: epoch 0028, iter [01100, 05004], lr: 0.100000, loss: 2.2966
2022-07-04 21:16:01 - train: epoch 0028, iter [01200, 05004], lr: 0.100000, loss: 2.2046
2022-07-04 21:16:33 - train: epoch 0028, iter [01300, 05004], lr: 0.100000, loss: 2.3046
2022-07-04 21:17:07 - train: epoch 0028, iter [01400, 05004], lr: 0.100000, loss: 2.6684
2022-07-04 21:17:39 - train: epoch 0028, iter [01500, 05004], lr: 0.100000, loss: 2.3058
2022-07-04 21:18:12 - train: epoch 0028, iter [01600, 05004], lr: 0.100000, loss: 2.3970
2022-07-04 21:18:46 - train: epoch 0028, iter [01700, 05004], lr: 0.100000, loss: 2.3696
2022-07-04 21:19:20 - train: epoch 0028, iter [01800, 05004], lr: 0.100000, loss: 2.2137
2022-07-04 21:19:51 - train: epoch 0028, iter [01900, 05004], lr: 0.100000, loss: 2.3826
2022-07-04 21:20:25 - train: epoch 0028, iter [02000, 05004], lr: 0.100000, loss: 2.4666
2022-07-04 21:20:59 - train: epoch 0028, iter [02100, 05004], lr: 0.100000, loss: 2.3573
2022-07-04 21:21:32 - train: epoch 0028, iter [02200, 05004], lr: 0.100000, loss: 2.3972
2022-07-04 21:22:05 - train: epoch 0028, iter [02300, 05004], lr: 0.100000, loss: 2.6286
2022-07-04 21:22:38 - train: epoch 0028, iter [02400, 05004], lr: 0.100000, loss: 2.6437
2022-07-04 21:23:11 - train: epoch 0028, iter [02500, 05004], lr: 0.100000, loss: 2.3108
2022-07-04 21:23:44 - train: epoch 0028, iter [02600, 05004], lr: 0.100000, loss: 2.1893
2022-07-04 21:24:18 - train: epoch 0028, iter [02700, 05004], lr: 0.100000, loss: 2.2538
2022-07-04 21:24:50 - train: epoch 0028, iter [02800, 05004], lr: 0.100000, loss: 2.4109
2022-07-04 21:25:25 - train: epoch 0028, iter [02900, 05004], lr: 0.100000, loss: 2.3653
2022-07-04 21:25:57 - train: epoch 0028, iter [03000, 05004], lr: 0.100000, loss: 2.5203
2022-07-04 21:26:31 - train: epoch 0028, iter [03100, 05004], lr: 0.100000, loss: 2.5222
2022-07-04 21:27:03 - train: epoch 0028, iter [03200, 05004], lr: 0.100000, loss: 2.2741
2022-07-04 21:27:37 - train: epoch 0028, iter [03300, 05004], lr: 0.100000, loss: 2.4010
2022-07-04 21:28:12 - train: epoch 0028, iter [03400, 05004], lr: 0.100000, loss: 2.3402
2022-07-04 21:28:44 - train: epoch 0028, iter [03500, 05004], lr: 0.100000, loss: 2.3559
2022-07-04 21:29:18 - train: epoch 0028, iter [03600, 05004], lr: 0.100000, loss: 2.2732
2022-07-04 21:29:51 - train: epoch 0028, iter [03700, 05004], lr: 0.100000, loss: 2.3384
2022-07-04 21:30:25 - train: epoch 0028, iter [03800, 05004], lr: 0.100000, loss: 2.0009
2022-07-04 21:30:58 - train: epoch 0028, iter [03900, 05004], lr: 0.100000, loss: 2.3063
2022-07-04 21:31:32 - train: epoch 0028, iter [04000, 05004], lr: 0.100000, loss: 2.5539
2022-07-04 21:32:04 - train: epoch 0028, iter [04100, 05004], lr: 0.100000, loss: 2.4568
2022-07-04 21:32:38 - train: epoch 0028, iter [04200, 05004], lr: 0.100000, loss: 2.5498
2022-07-04 21:33:10 - train: epoch 0028, iter [04300, 05004], lr: 0.100000, loss: 2.3007
2022-07-04 21:33:43 - train: epoch 0028, iter [04400, 05004], lr: 0.100000, loss: 2.3787
2022-07-04 21:34:17 - train: epoch 0028, iter [04500, 05004], lr: 0.100000, loss: 2.3616
2022-07-04 21:34:50 - train: epoch 0028, iter [04600, 05004], lr: 0.100000, loss: 2.4139
2022-07-04 21:35:23 - train: epoch 0028, iter [04700, 05004], lr: 0.100000, loss: 2.3418
2022-07-04 21:35:57 - train: epoch 0028, iter [04800, 05004], lr: 0.100000, loss: 2.2274
2022-07-04 21:36:30 - train: epoch 0028, iter [04900, 05004], lr: 0.100000, loss: 2.3258
2022-07-04 21:37:02 - train: epoch 0028, iter [05000, 05004], lr: 0.100000, loss: 2.2721
2022-07-04 21:37:03 - train: epoch 028, train_loss: 2.3596
2022-07-04 21:38:16 - eval: epoch: 028, acc1: 50.308%, acc5: 75.854%, test_loss: 2.1734, per_image_load_time: 2.601ms, per_image_inference_time: 0.154ms
2022-07-04 21:38:16 - until epoch: 028, best_acc1: 50.990%
2022-07-04 21:38:16 - epoch 029 lr: 0.100000
2022-07-04 21:38:53 - train: epoch 0029, iter [00100, 05004], lr: 0.100000, loss: 2.4978
2022-07-04 21:39:27 - train: epoch 0029, iter [00200, 05004], lr: 0.100000, loss: 2.3294
2022-07-04 21:40:01 - train: epoch 0029, iter [00300, 05004], lr: 0.100000, loss: 2.4817
2022-07-04 21:40:33 - train: epoch 0029, iter [00400, 05004], lr: 0.100000, loss: 2.2330
2022-07-04 21:41:06 - train: epoch 0029, iter [00500, 05004], lr: 0.100000, loss: 2.4778
2022-07-04 21:41:38 - train: epoch 0029, iter [00600, 05004], lr: 0.100000, loss: 2.6607
2022-07-04 21:42:12 - train: epoch 0029, iter [00700, 05004], lr: 0.100000, loss: 1.8677
2022-07-04 21:42:45 - train: epoch 0029, iter [00800, 05004], lr: 0.100000, loss: 2.5096
2022-07-04 21:43:18 - train: epoch 0029, iter [00900, 05004], lr: 0.100000, loss: 2.3313
2022-07-04 21:43:50 - train: epoch 0029, iter [01000, 05004], lr: 0.100000, loss: 2.2528
2022-07-04 21:44:24 - train: epoch 0029, iter [01100, 05004], lr: 0.100000, loss: 2.2742
2022-07-04 21:44:56 - train: epoch 0029, iter [01200, 05004], lr: 0.100000, loss: 2.4988
2022-07-04 21:45:30 - train: epoch 0029, iter [01300, 05004], lr: 0.100000, loss: 2.2746
2022-07-04 21:46:04 - train: epoch 0029, iter [01400, 05004], lr: 0.100000, loss: 2.5255
2022-07-04 21:46:37 - train: epoch 0029, iter [01500, 05004], lr: 0.100000, loss: 2.4011
2022-07-04 21:47:09 - train: epoch 0029, iter [01600, 05004], lr: 0.100000, loss: 2.2796
2022-07-04 21:47:43 - train: epoch 0029, iter [01700, 05004], lr: 0.100000, loss: 2.3824
2022-07-04 21:48:16 - train: epoch 0029, iter [01800, 05004], lr: 0.100000, loss: 2.4418
2022-07-04 21:48:49 - train: epoch 0029, iter [01900, 05004], lr: 0.100000, loss: 2.0698
2022-07-04 21:49:22 - train: epoch 0029, iter [02000, 05004], lr: 0.100000, loss: 2.5392
2022-07-04 21:49:54 - train: epoch 0029, iter [02100, 05004], lr: 0.100000, loss: 2.3607
2022-07-04 21:50:27 - train: epoch 0029, iter [02200, 05004], lr: 0.100000, loss: 2.4552
2022-07-04 21:51:00 - train: epoch 0029, iter [02300, 05004], lr: 0.100000, loss: 2.4075
2022-07-04 21:51:34 - train: epoch 0029, iter [02400, 05004], lr: 0.100000, loss: 2.2520
2022-07-04 21:52:07 - train: epoch 0029, iter [02500, 05004], lr: 0.100000, loss: 2.2774
2022-07-04 21:52:40 - train: epoch 0029, iter [02600, 05004], lr: 0.100000, loss: 2.3031
2022-07-04 21:53:12 - train: epoch 0029, iter [02700, 05004], lr: 0.100000, loss: 2.2707
2022-07-04 21:53:46 - train: epoch 0029, iter [02800, 05004], lr: 0.100000, loss: 2.2194
2022-07-04 21:54:19 - train: epoch 0029, iter [02900, 05004], lr: 0.100000, loss: 2.2651
2022-07-04 21:54:52 - train: epoch 0029, iter [03000, 05004], lr: 0.100000, loss: 2.3258
2022-07-04 21:55:25 - train: epoch 0029, iter [03100, 05004], lr: 0.100000, loss: 2.4999
2022-07-04 21:55:58 - train: epoch 0029, iter [03200, 05004], lr: 0.100000, loss: 2.3299
2022-07-04 21:56:31 - train: epoch 0029, iter [03300, 05004], lr: 0.100000, loss: 2.3473
2022-07-04 21:57:04 - train: epoch 0029, iter [03400, 05004], lr: 0.100000, loss: 2.1831
2022-07-04 21:57:37 - train: epoch 0029, iter [03500, 05004], lr: 0.100000, loss: 2.4519
2022-07-04 21:58:10 - train: epoch 0029, iter [03600, 05004], lr: 0.100000, loss: 2.1689
2022-07-04 21:58:43 - train: epoch 0029, iter [03700, 05004], lr: 0.100000, loss: 2.3105
2022-07-04 21:59:17 - train: epoch 0029, iter [03800, 05004], lr: 0.100000, loss: 2.2687
2022-07-04 21:59:50 - train: epoch 0029, iter [03900, 05004], lr: 0.100000, loss: 2.1451
2022-07-04 22:00:23 - train: epoch 0029, iter [04000, 05004], lr: 0.100000, loss: 2.3742
2022-07-04 22:00:57 - train: epoch 0029, iter [04100, 05004], lr: 0.100000, loss: 2.3308
2022-07-04 22:01:29 - train: epoch 0029, iter [04200, 05004], lr: 0.100000, loss: 2.2177
2022-07-04 22:02:03 - train: epoch 0029, iter [04300, 05004], lr: 0.100000, loss: 2.5222
2022-07-04 22:02:35 - train: epoch 0029, iter [04400, 05004], lr: 0.100000, loss: 2.3020
2022-07-04 22:03:09 - train: epoch 0029, iter [04500, 05004], lr: 0.100000, loss: 2.4721
2022-07-04 22:03:42 - train: epoch 0029, iter [04600, 05004], lr: 0.100000, loss: 2.5578
2022-07-04 22:04:15 - train: epoch 0029, iter [04700, 05004], lr: 0.100000, loss: 2.1851
2022-07-04 22:04:49 - train: epoch 0029, iter [04800, 05004], lr: 0.100000, loss: 2.3963
2022-07-04 22:05:21 - train: epoch 0029, iter [04900, 05004], lr: 0.100000, loss: 2.8322
2022-07-04 22:05:54 - train: epoch 0029, iter [05000, 05004], lr: 0.100000, loss: 2.1720
2022-07-04 22:05:55 - train: epoch 029, train_loss: 2.3582
2022-07-04 22:07:08 - eval: epoch: 029, acc1: 49.238%, acc5: 75.172%, test_loss: 2.2130, per_image_load_time: 2.251ms, per_image_inference_time: 0.180ms
2022-07-04 22:07:08 - until epoch: 029, best_acc1: 50.990%
2022-07-04 22:07:08 - epoch 030 lr: 0.100000
2022-07-04 22:07:45 - train: epoch 0030, iter [00100, 05004], lr: 0.100000, loss: 2.5356
2022-07-04 22:08:18 - train: epoch 0030, iter [00200, 05004], lr: 0.100000, loss: 2.4261
2022-07-04 22:08:51 - train: epoch 0030, iter [00300, 05004], lr: 0.100000, loss: 2.1970
2022-07-04 22:09:25 - train: epoch 0030, iter [00400, 05004], lr: 0.100000, loss: 2.1011
2022-07-04 22:09:57 - train: epoch 0030, iter [00500, 05004], lr: 0.100000, loss: 2.7212
2022-07-04 22:10:31 - train: epoch 0030, iter [00600, 05004], lr: 0.100000, loss: 2.1696
2022-07-04 22:11:04 - train: epoch 0030, iter [00700, 05004], lr: 0.100000, loss: 2.2586
2022-07-04 22:11:37 - train: epoch 0030, iter [00800, 05004], lr: 0.100000, loss: 2.4674
2022-07-04 22:12:09 - train: epoch 0030, iter [00900, 05004], lr: 0.100000, loss: 2.4854
2022-07-04 22:12:43 - train: epoch 0030, iter [01000, 05004], lr: 0.100000, loss: 2.0455
2022-07-04 22:13:16 - train: epoch 0030, iter [01100, 05004], lr: 0.100000, loss: 2.1240
2022-07-04 22:13:50 - train: epoch 0030, iter [01200, 05004], lr: 0.100000, loss: 2.3605
2022-07-04 22:14:22 - train: epoch 0030, iter [01300, 05004], lr: 0.100000, loss: 2.0263
2022-07-04 22:14:54 - train: epoch 0030, iter [01400, 05004], lr: 0.100000, loss: 2.2359
2022-07-04 22:15:28 - train: epoch 0030, iter [01500, 05004], lr: 0.100000, loss: 2.3378
2022-07-04 22:16:01 - train: epoch 0030, iter [01600, 05004], lr: 0.100000, loss: 2.4980
2022-07-04 22:16:34 - train: epoch 0030, iter [01700, 05004], lr: 0.100000, loss: 2.5668
2022-07-04 22:17:06 - train: epoch 0030, iter [01800, 05004], lr: 0.100000, loss: 2.3023
2022-07-04 22:17:40 - train: epoch 0030, iter [01900, 05004], lr: 0.100000, loss: 2.5119
2022-07-04 22:18:12 - train: epoch 0030, iter [02000, 05004], lr: 0.100000, loss: 2.3686
2022-07-04 22:18:46 - train: epoch 0030, iter [02100, 05004], lr: 0.100000, loss: 2.4585
2022-07-04 22:19:18 - train: epoch 0030, iter [02200, 05004], lr: 0.100000, loss: 2.2028
2022-07-04 22:19:52 - train: epoch 0030, iter [02300, 05004], lr: 0.100000, loss: 2.4543
2022-07-04 22:20:24 - train: epoch 0030, iter [02400, 05004], lr: 0.100000, loss: 2.4915
2022-07-04 22:20:57 - train: epoch 0030, iter [02500, 05004], lr: 0.100000, loss: 2.3967
2022-07-04 22:21:30 - train: epoch 0030, iter [02600, 05004], lr: 0.100000, loss: 2.3445
2022-07-04 22:22:03 - train: epoch 0030, iter [02700, 05004], lr: 0.100000, loss: 2.2395
2022-07-04 22:22:36 - train: epoch 0030, iter [02800, 05004], lr: 0.100000, loss: 2.2934
2022-07-04 22:23:10 - train: epoch 0030, iter [02900, 05004], lr: 0.100000, loss: 2.4348
2022-07-04 22:23:43 - train: epoch 0030, iter [03000, 05004], lr: 0.100000, loss: 2.4530
2022-07-04 22:24:16 - train: epoch 0030, iter [03100, 05004], lr: 0.100000, loss: 2.3882
2022-07-04 22:24:49 - train: epoch 0030, iter [03200, 05004], lr: 0.100000, loss: 2.2456
2022-07-04 22:25:23 - train: epoch 0030, iter [03300, 05004], lr: 0.100000, loss: 2.6693
2022-07-04 22:25:56 - train: epoch 0030, iter [03400, 05004], lr: 0.100000, loss: 2.3667
2022-07-04 22:26:29 - train: epoch 0030, iter [03500, 05004], lr: 0.100000, loss: 2.4579
2022-07-04 22:27:02 - train: epoch 0030, iter [03600, 05004], lr: 0.100000, loss: 2.0926
2022-07-04 22:27:35 - train: epoch 0030, iter [03700, 05004], lr: 0.100000, loss: 2.2523
2022-07-04 22:28:09 - train: epoch 0030, iter [03800, 05004], lr: 0.100000, loss: 2.5190
2022-07-04 22:28:42 - train: epoch 0030, iter [03900, 05004], lr: 0.100000, loss: 2.3475
2022-07-04 22:29:14 - train: epoch 0030, iter [04000, 05004], lr: 0.100000, loss: 2.2125
2022-07-04 22:29:48 - train: epoch 0030, iter [04100, 05004], lr: 0.100000, loss: 2.1943
2022-07-04 22:30:21 - train: epoch 0030, iter [04200, 05004], lr: 0.100000, loss: 2.6350
2022-07-04 22:30:54 - train: epoch 0030, iter [04300, 05004], lr: 0.100000, loss: 2.2463
2022-07-04 22:31:28 - train: epoch 0030, iter [04400, 05004], lr: 0.100000, loss: 2.4565
2022-07-04 22:32:01 - train: epoch 0030, iter [04500, 05004], lr: 0.100000, loss: 2.5527
2022-07-04 22:32:33 - train: epoch 0030, iter [04600, 05004], lr: 0.100000, loss: 2.1453
2022-07-04 22:33:07 - train: epoch 0030, iter [04700, 05004], lr: 0.100000, loss: 2.3363
2022-07-04 22:33:40 - train: epoch 0030, iter [04800, 05004], lr: 0.100000, loss: 2.4276
2022-07-04 22:34:14 - train: epoch 0030, iter [04900, 05004], lr: 0.100000, loss: 2.5620
2022-07-04 22:34:45 - train: epoch 0030, iter [05000, 05004], lr: 0.100000, loss: 2.4029
2022-07-04 22:34:46 - train: epoch 030, train_loss: 2.3573
2022-07-04 22:35:58 - eval: epoch: 030, acc1: 51.702%, acc5: 77.436%, test_loss: 2.0836, per_image_load_time: 2.290ms, per_image_inference_time: 0.177ms
2022-07-04 22:35:59 - until epoch: 030, best_acc1: 51.702%
2022-07-05 07:22:14 - epoch 031 lr: 0.010000
2022-07-05 07:22:52 - train: epoch 0031, iter [00100, 05004], lr: 0.010000, loss: 2.2406
2022-07-05 07:23:25 - train: epoch 0031, iter [00200, 05004], lr: 0.010000, loss: 1.9666
2022-07-05 07:23:57 - train: epoch 0031, iter [00300, 05004], lr: 0.010000, loss: 1.8586
2022-07-05 07:24:29 - train: epoch 0031, iter [00400, 05004], lr: 0.010000, loss: 1.8629
2022-07-05 07:25:02 - train: epoch 0031, iter [00500, 05004], lr: 0.010000, loss: 2.1493
2022-07-05 07:25:35 - train: epoch 0031, iter [00600, 05004], lr: 0.010000, loss: 1.9155
2022-07-05 07:26:08 - train: epoch 0031, iter [00700, 05004], lr: 0.010000, loss: 1.9936
2022-07-05 07:26:40 - train: epoch 0031, iter [00800, 05004], lr: 0.010000, loss: 1.8966
2022-07-05 07:27:13 - train: epoch 0031, iter [00900, 05004], lr: 0.010000, loss: 1.8505
2022-07-05 07:27:45 - train: epoch 0031, iter [01000, 05004], lr: 0.010000, loss: 2.1774
2022-07-05 07:28:19 - train: epoch 0031, iter [01100, 05004], lr: 0.010000, loss: 1.9660
2022-07-05 07:28:51 - train: epoch 0031, iter [01200, 05004], lr: 0.010000, loss: 2.1070
2022-07-05 07:29:25 - train: epoch 0031, iter [01300, 05004], lr: 0.010000, loss: 1.4887
2022-07-05 07:29:58 - train: epoch 0031, iter [01400, 05004], lr: 0.010000, loss: 1.7043
2022-07-05 07:30:30 - train: epoch 0031, iter [01500, 05004], lr: 0.010000, loss: 2.0278
2022-07-05 07:31:04 - train: epoch 0031, iter [01600, 05004], lr: 0.010000, loss: 1.7157
2022-07-05 07:31:36 - train: epoch 0031, iter [01700, 05004], lr: 0.010000, loss: 1.7892
2022-07-05 07:32:11 - train: epoch 0031, iter [01800, 05004], lr: 0.010000, loss: 1.7122
2022-07-05 07:32:43 - train: epoch 0031, iter [01900, 05004], lr: 0.010000, loss: 1.6183
2022-07-05 07:33:17 - train: epoch 0031, iter [02000, 05004], lr: 0.010000, loss: 1.7537
2022-07-05 07:33:50 - train: epoch 0031, iter [02100, 05004], lr: 0.010000, loss: 1.8482
2022-07-05 07:34:23 - train: epoch 0031, iter [02200, 05004], lr: 0.010000, loss: 1.4767
2022-07-05 07:34:56 - train: epoch 0031, iter [02300, 05004], lr: 0.010000, loss: 1.6727
2022-07-05 07:35:28 - train: epoch 0031, iter [02400, 05004], lr: 0.010000, loss: 1.9740
2022-07-05 07:36:01 - train: epoch 0031, iter [02500, 05004], lr: 0.010000, loss: 1.8181
2022-07-05 07:36:34 - train: epoch 0031, iter [02600, 05004], lr: 0.010000, loss: 1.8142
2022-07-05 07:37:07 - train: epoch 0031, iter [02700, 05004], lr: 0.010000, loss: 1.9297
2022-07-05 07:37:41 - train: epoch 0031, iter [02800, 05004], lr: 0.010000, loss: 2.1225
2022-07-05 07:38:14 - train: epoch 0031, iter [02900, 05004], lr: 0.010000, loss: 1.7793
2022-07-05 07:38:46 - train: epoch 0031, iter [03000, 05004], lr: 0.010000, loss: 2.0913
2022-07-05 07:39:19 - train: epoch 0031, iter [03100, 05004], lr: 0.010000, loss: 1.7536
2022-07-05 07:39:52 - train: epoch 0031, iter [03200, 05004], lr: 0.010000, loss: 1.9862
2022-07-05 07:40:25 - train: epoch 0031, iter [03300, 05004], lr: 0.010000, loss: 1.7446
2022-07-05 07:40:59 - train: epoch 0031, iter [03400, 05004], lr: 0.010000, loss: 2.0385
2022-07-05 07:41:31 - train: epoch 0031, iter [03500, 05004], lr: 0.010000, loss: 1.9861
2022-07-05 07:42:04 - train: epoch 0031, iter [03600, 05004], lr: 0.010000, loss: 1.8348
2022-07-05 07:42:38 - train: epoch 0031, iter [03700, 05004], lr: 0.010000, loss: 1.7340
2022-07-05 07:43:11 - train: epoch 0031, iter [03800, 05004], lr: 0.010000, loss: 1.8695
2022-07-05 07:43:45 - train: epoch 0031, iter [03900, 05004], lr: 0.010000, loss: 2.0027
2022-07-05 07:44:19 - train: epoch 0031, iter [04000, 05004], lr: 0.010000, loss: 1.7185
2022-07-05 07:44:51 - train: epoch 0031, iter [04100, 05004], lr: 0.010000, loss: 1.8025
2022-07-05 07:45:24 - train: epoch 0031, iter [04200, 05004], lr: 0.010000, loss: 1.8666
2022-07-05 07:45:58 - train: epoch 0031, iter [04300, 05004], lr: 0.010000, loss: 1.7354
2022-07-05 07:46:31 - train: epoch 0031, iter [04400, 05004], lr: 0.010000, loss: 1.8700
2022-07-05 07:47:04 - train: epoch 0031, iter [04500, 05004], lr: 0.010000, loss: 1.9075
2022-07-05 07:47:38 - train: epoch 0031, iter [04600, 05004], lr: 0.010000, loss: 1.9704
2022-07-05 07:48:11 - train: epoch 0031, iter [04700, 05004], lr: 0.010000, loss: 1.6450
2022-07-05 07:48:44 - train: epoch 0031, iter [04800, 05004], lr: 0.010000, loss: 1.8745
2022-07-05 07:49:17 - train: epoch 0031, iter [04900, 05004], lr: 0.010000, loss: 1.9380
2022-07-05 07:49:48 - train: epoch 0031, iter [05000, 05004], lr: 0.010000, loss: 1.7202
2022-07-05 07:49:50 - train: epoch 031, train_loss: 1.8812
2022-07-05 07:51:03 - eval: epoch: 031, acc1: 63.282%, acc5: 85.372%, test_loss: 1.5225, per_image_load_time: 2.685ms, per_image_inference_time: 0.162ms
2022-07-05 07:51:03 - until epoch: 031, best_acc1: 63.282%
2022-07-05 07:51:03 - epoch 032 lr: 0.010000
2022-07-05 07:51:42 - train: epoch 0032, iter [00100, 05004], lr: 0.010000, loss: 1.6343
2022-07-05 07:52:15 - train: epoch 0032, iter [00200, 05004], lr: 0.010000, loss: 1.8659
2022-07-05 07:52:47 - train: epoch 0032, iter [00300, 05004], lr: 0.010000, loss: 1.5272
2022-07-05 07:53:19 - train: epoch 0032, iter [00400, 05004], lr: 0.010000, loss: 1.7426
2022-07-05 07:53:53 - train: epoch 0032, iter [00500, 05004], lr: 0.010000, loss: 1.6632
2022-07-05 07:54:24 - train: epoch 0032, iter [00600, 05004], lr: 0.010000, loss: 1.8376
2022-07-05 07:54:57 - train: epoch 0032, iter [00700, 05004], lr: 0.010000, loss: 1.6677
2022-07-05 07:55:30 - train: epoch 0032, iter [00800, 05004], lr: 0.010000, loss: 1.6083
2022-07-05 07:56:03 - train: epoch 0032, iter [00900, 05004], lr: 0.010000, loss: 1.9991
2022-07-05 07:56:37 - train: epoch 0032, iter [01000, 05004], lr: 0.010000, loss: 2.0380
2022-07-05 07:57:10 - train: epoch 0032, iter [01100, 05004], lr: 0.010000, loss: 1.6880
2022-07-05 07:57:42 - train: epoch 0032, iter [01200, 05004], lr: 0.010000, loss: 1.9466
2022-07-05 07:58:16 - train: epoch 0032, iter [01300, 05004], lr: 0.010000, loss: 1.8484
2022-07-05 07:58:49 - train: epoch 0032, iter [01400, 05004], lr: 0.010000, loss: 1.9613
2022-07-05 07:59:22 - train: epoch 0032, iter [01500, 05004], lr: 0.010000, loss: 1.7503
2022-07-05 07:59:55 - train: epoch 0032, iter [01600, 05004], lr: 0.010000, loss: 1.9368
2022-07-05 08:00:29 - train: epoch 0032, iter [01700, 05004], lr: 0.010000, loss: 1.7204
2022-07-05 08:01:02 - train: epoch 0032, iter [01800, 05004], lr: 0.010000, loss: 2.1104
2022-07-05 08:01:34 - train: epoch 0032, iter [01900, 05004], lr: 0.010000, loss: 1.5776
2022-07-05 08:02:08 - train: epoch 0032, iter [02000, 05004], lr: 0.010000, loss: 1.8501
2022-07-05 08:02:40 - train: epoch 0032, iter [02100, 05004], lr: 0.010000, loss: 1.7615
2022-07-05 08:03:13 - train: epoch 0032, iter [02200, 05004], lr: 0.010000, loss: 1.7503
2022-07-05 08:03:47 - train: epoch 0032, iter [02300, 05004], lr: 0.010000, loss: 1.8398
2022-07-05 08:04:20 - train: epoch 0032, iter [02400, 05004], lr: 0.010000, loss: 1.7949
2022-07-05 08:04:53 - train: epoch 0032, iter [02500, 05004], lr: 0.010000, loss: 1.8484
2022-07-05 08:05:26 - train: epoch 0032, iter [02600, 05004], lr: 0.010000, loss: 1.6523
2022-07-05 08:05:58 - train: epoch 0032, iter [02700, 05004], lr: 0.010000, loss: 1.7707
2022-07-05 08:06:32 - train: epoch 0032, iter [02800, 05004], lr: 0.010000, loss: 1.5805
2022-07-05 08:07:06 - train: epoch 0032, iter [02900, 05004], lr: 0.010000, loss: 1.6979
2022-07-05 08:07:39 - train: epoch 0032, iter [03000, 05004], lr: 0.010000, loss: 1.6248
2022-07-05 08:08:11 - train: epoch 0032, iter [03100, 05004], lr: 0.010000, loss: 1.9208
2022-07-05 08:08:45 - train: epoch 0032, iter [03200, 05004], lr: 0.010000, loss: 1.8789
2022-07-05 08:09:18 - train: epoch 0032, iter [03300, 05004], lr: 0.010000, loss: 1.5629
2022-07-05 08:09:50 - train: epoch 0032, iter [03400, 05004], lr: 0.010000, loss: 1.6838
2022-07-05 08:10:24 - train: epoch 0032, iter [03500, 05004], lr: 0.010000, loss: 1.6465
2022-07-05 08:10:57 - train: epoch 0032, iter [03600, 05004], lr: 0.010000, loss: 1.7424
2022-07-05 08:11:31 - train: epoch 0032, iter [03700, 05004], lr: 0.010000, loss: 1.6919
2022-07-05 08:12:04 - train: epoch 0032, iter [03800, 05004], lr: 0.010000, loss: 1.5881
2022-07-05 08:12:38 - train: epoch 0032, iter [03900, 05004], lr: 0.010000, loss: 1.5640
2022-07-05 08:13:10 - train: epoch 0032, iter [04000, 05004], lr: 0.010000, loss: 1.8374
2022-07-05 08:13:44 - train: epoch 0032, iter [04100, 05004], lr: 0.010000, loss: 1.6315
2022-07-05 08:14:16 - train: epoch 0032, iter [04200, 05004], lr: 0.010000, loss: 1.6045
2022-07-05 08:14:49 - train: epoch 0032, iter [04300, 05004], lr: 0.010000, loss: 1.7993
2022-07-05 08:15:22 - train: epoch 0032, iter [04400, 05004], lr: 0.010000, loss: 1.6556
2022-07-05 08:15:55 - train: epoch 0032, iter [04500, 05004], lr: 0.010000, loss: 1.9542
2022-07-05 08:16:28 - train: epoch 0032, iter [04600, 05004], lr: 0.010000, loss: 1.7452
2022-07-05 08:17:01 - train: epoch 0032, iter [04700, 05004], lr: 0.010000, loss: 1.6736
2022-07-05 08:17:35 - train: epoch 0032, iter [04800, 05004], lr: 0.010000, loss: 1.9706
2022-07-05 08:18:07 - train: epoch 0032, iter [04900, 05004], lr: 0.010000, loss: 1.8387
2022-07-05 08:18:39 - train: epoch 0032, iter [05000, 05004], lr: 0.010000, loss: 1.7641
2022-07-05 08:18:40 - train: epoch 032, train_loss: 1.7606
2022-07-05 08:19:53 - eval: epoch: 032, acc1: 64.224%, acc5: 85.844%, test_loss: 1.4736, per_image_load_time: 2.674ms, per_image_inference_time: 0.180ms
2022-07-05 08:19:54 - until epoch: 032, best_acc1: 64.224%
2022-07-05 08:19:54 - epoch 033 lr: 0.010000
2022-07-05 08:20:32 - train: epoch 0033, iter [00100, 05004], lr: 0.010000, loss: 1.7677
2022-07-05 08:21:05 - train: epoch 0033, iter [00200, 05004], lr: 0.010000, loss: 1.7112
2022-07-05 08:21:38 - train: epoch 0033, iter [00300, 05004], lr: 0.010000, loss: 1.7221
2022-07-05 08:22:10 - train: epoch 0033, iter [00400, 05004], lr: 0.010000, loss: 1.5319
2022-07-05 08:22:44 - train: epoch 0033, iter [00500, 05004], lr: 0.010000, loss: 1.8788
2022-07-05 08:23:16 - train: epoch 0033, iter [00600, 05004], lr: 0.010000, loss: 1.6948
2022-07-05 08:23:50 - train: epoch 0033, iter [00700, 05004], lr: 0.010000, loss: 1.9209
2022-07-05 08:24:22 - train: epoch 0033, iter [00800, 05004], lr: 0.010000, loss: 1.6960
2022-07-05 08:24:56 - train: epoch 0033, iter [00900, 05004], lr: 0.010000, loss: 1.5934
2022-07-05 08:25:28 - train: epoch 0033, iter [01000, 05004], lr: 0.010000, loss: 1.8607
2022-07-05 08:26:02 - train: epoch 0033, iter [01100, 05004], lr: 0.010000, loss: 1.6199
2022-07-05 08:26:35 - train: epoch 0033, iter [01200, 05004], lr: 0.010000, loss: 1.7682
2022-07-05 08:27:08 - train: epoch 0033, iter [01300, 05004], lr: 0.010000, loss: 1.6218
2022-07-05 08:27:42 - train: epoch 0033, iter [01400, 05004], lr: 0.010000, loss: 1.7999
2022-07-05 08:28:15 - train: epoch 0033, iter [01500, 05004], lr: 0.010000, loss: 1.8623
2022-07-05 08:28:48 - train: epoch 0033, iter [01600, 05004], lr: 0.010000, loss: 1.9674
2022-07-05 08:29:21 - train: epoch 0033, iter [01700, 05004], lr: 0.010000, loss: 1.7414
2022-07-05 08:29:54 - train: epoch 0033, iter [01800, 05004], lr: 0.010000, loss: 1.7562
2022-07-05 08:30:26 - train: epoch 0033, iter [01900, 05004], lr: 0.010000, loss: 1.7208
2022-07-05 08:31:00 - train: epoch 0033, iter [02000, 05004], lr: 0.010000, loss: 1.7663
2022-07-05 08:31:33 - train: epoch 0033, iter [02100, 05004], lr: 0.010000, loss: 1.7584
2022-07-05 08:32:07 - train: epoch 0033, iter [02200, 05004], lr: 0.010000, loss: 1.6110
2022-07-05 08:32:39 - train: epoch 0033, iter [02300, 05004], lr: 0.010000, loss: 1.5448
2022-07-05 08:33:14 - train: epoch 0033, iter [02400, 05004], lr: 0.010000, loss: 1.7621
2022-07-05 08:33:45 - train: epoch 0033, iter [02500, 05004], lr: 0.010000, loss: 1.7544
2022-07-05 08:34:18 - train: epoch 0033, iter [02600, 05004], lr: 0.010000, loss: 1.5240
2022-07-05 08:34:53 - train: epoch 0033, iter [02700, 05004], lr: 0.010000, loss: 1.5079
2022-07-05 08:35:25 - train: epoch 0033, iter [02800, 05004], lr: 0.010000, loss: 1.7453
2022-07-05 08:35:59 - train: epoch 0033, iter [02900, 05004], lr: 0.010000, loss: 1.6422
2022-07-05 08:36:31 - train: epoch 0033, iter [03000, 05004], lr: 0.010000, loss: 1.7777
2022-07-05 08:37:06 - train: epoch 0033, iter [03100, 05004], lr: 0.010000, loss: 1.8658
2022-07-05 08:37:39 - train: epoch 0033, iter [03200, 05004], lr: 0.010000, loss: 1.7991
2022-07-05 08:38:13 - train: epoch 0033, iter [03300, 05004], lr: 0.010000, loss: 1.6661
2022-07-05 08:38:46 - train: epoch 0033, iter [03400, 05004], lr: 0.010000, loss: 1.4418
2022-07-05 08:39:18 - train: epoch 0033, iter [03500, 05004], lr: 0.010000, loss: 1.8533
2022-07-05 08:39:52 - train: epoch 0033, iter [03600, 05004], lr: 0.010000, loss: 2.0359
2022-07-05 08:40:25 - train: epoch 0033, iter [03700, 05004], lr: 0.010000, loss: 1.5462
2022-07-05 08:40:59 - train: epoch 0033, iter [03800, 05004], lr: 0.010000, loss: 1.6569
2022-07-05 08:41:32 - train: epoch 0033, iter [03900, 05004], lr: 0.010000, loss: 1.9251
2022-07-05 08:42:05 - train: epoch 0033, iter [04000, 05004], lr: 0.010000, loss: 1.8123
2022-07-05 08:42:39 - train: epoch 0033, iter [04100, 05004], lr: 0.010000, loss: 1.7481
2022-07-05 08:43:12 - train: epoch 0033, iter [04200, 05004], lr: 0.010000, loss: 1.5251
2022-07-05 08:43:45 - train: epoch 0033, iter [04300, 05004], lr: 0.010000, loss: 1.8757
2022-07-05 08:44:18 - train: epoch 0033, iter [04400, 05004], lr: 0.010000, loss: 1.8242
2022-07-05 08:44:51 - train: epoch 0033, iter [04500, 05004], lr: 0.010000, loss: 1.9293
2022-07-05 08:45:26 - train: epoch 0033, iter [04600, 05004], lr: 0.010000, loss: 1.7061
2022-07-05 08:45:59 - train: epoch 0033, iter [04700, 05004], lr: 0.010000, loss: 1.4696
2022-07-05 08:46:32 - train: epoch 0033, iter [04800, 05004], lr: 0.010000, loss: 1.9288
2022-07-05 08:47:05 - train: epoch 0033, iter [04900, 05004], lr: 0.010000, loss: 1.4818
2022-07-05 08:47:37 - train: epoch 0033, iter [05000, 05004], lr: 0.010000, loss: 1.7370
2022-07-05 08:47:38 - train: epoch 033, train_loss: 1.7075
2022-07-05 08:48:51 - eval: epoch: 033, acc1: 64.852%, acc5: 86.354%, test_loss: 1.4463, per_image_load_time: 2.279ms, per_image_inference_time: 0.179ms
2022-07-05 08:48:52 - until epoch: 033, best_acc1: 64.852%
2022-07-05 08:48:52 - epoch 034 lr: 0.010000
2022-07-05 08:49:30 - train: epoch 0034, iter [00100, 05004], lr: 0.010000, loss: 1.5522
2022-07-05 08:50:02 - train: epoch 0034, iter [00200, 05004], lr: 0.010000, loss: 1.7244
2022-07-05 08:50:35 - train: epoch 0034, iter [00300, 05004], lr: 0.010000, loss: 1.6407
2022-07-05 08:51:07 - train: epoch 0034, iter [00400, 05004], lr: 0.010000, loss: 1.5149
2022-07-05 08:51:41 - train: epoch 0034, iter [00500, 05004], lr: 0.010000, loss: 1.6817
2022-07-05 08:52:13 - train: epoch 0034, iter [00600, 05004], lr: 0.010000, loss: 1.8296
2022-07-05 08:52:46 - train: epoch 0034, iter [00700, 05004], lr: 0.010000, loss: 1.4996
2022-07-05 08:53:17 - train: epoch 0034, iter [00800, 05004], lr: 0.010000, loss: 1.8123
2022-07-05 08:53:50 - train: epoch 0034, iter [00900, 05004], lr: 0.010000, loss: 1.6238
2022-07-05 08:54:23 - train: epoch 0034, iter [01000, 05004], lr: 0.010000, loss: 1.7011
2022-07-05 08:54:55 - train: epoch 0034, iter [01100, 05004], lr: 0.010000, loss: 1.5519
2022-07-05 08:55:29 - train: epoch 0034, iter [01200, 05004], lr: 0.010000, loss: 1.7422
2022-07-05 08:56:01 - train: epoch 0034, iter [01300, 05004], lr: 0.010000, loss: 1.5201
2022-07-05 08:56:35 - train: epoch 0034, iter [01400, 05004], lr: 0.010000, loss: 1.6446
2022-07-05 08:57:07 - train: epoch 0034, iter [01500, 05004], lr: 0.010000, loss: 1.6595
2022-07-05 08:57:41 - train: epoch 0034, iter [01600, 05004], lr: 0.010000, loss: 1.6697
2022-07-05 08:58:13 - train: epoch 0034, iter [01700, 05004], lr: 0.010000, loss: 1.5967
2022-07-05 08:58:47 - train: epoch 0034, iter [01800, 05004], lr: 0.010000, loss: 1.7240
2022-07-05 08:59:19 - train: epoch 0034, iter [01900, 05004], lr: 0.010000, loss: 1.7511
2022-07-05 08:59:53 - train: epoch 0034, iter [02000, 05004], lr: 0.010000, loss: 1.6499
2022-07-05 09:00:26 - train: epoch 0034, iter [02100, 05004], lr: 0.010000, loss: 1.8603
2022-07-05 09:01:00 - train: epoch 0034, iter [02200, 05004], lr: 0.010000, loss: 1.4960
2022-07-05 09:01:32 - train: epoch 0034, iter [02300, 05004], lr: 0.010000, loss: 1.8278
2022-07-05 09:02:06 - train: epoch 0034, iter [02400, 05004], lr: 0.010000, loss: 1.4288
2022-07-05 09:02:38 - train: epoch 0034, iter [02500, 05004], lr: 0.010000, loss: 1.7431
2022-07-05 09:03:12 - train: epoch 0034, iter [02600, 05004], lr: 0.010000, loss: 1.8174
2022-07-05 09:03:44 - train: epoch 0034, iter [02700, 05004], lr: 0.010000, loss: 1.7094
2022-07-05 09:04:18 - train: epoch 0034, iter [02800, 05004], lr: 0.010000, loss: 1.6064
2022-07-05 09:04:51 - train: epoch 0034, iter [02900, 05004], lr: 0.010000, loss: 1.5248
2022-07-05 09:05:25 - train: epoch 0034, iter [03000, 05004], lr: 0.010000, loss: 1.4943
2022-07-05 09:05:57 - train: epoch 0034, iter [03100, 05004], lr: 0.010000, loss: 1.7868
2022-07-05 09:06:31 - train: epoch 0034, iter [03200, 05004], lr: 0.010000, loss: 1.6672
2022-07-05 09:07:04 - train: epoch 0034, iter [03300, 05004], lr: 0.010000, loss: 1.6038
2022-07-05 09:07:37 - train: epoch 0034, iter [03400, 05004], lr: 0.010000, loss: 1.8426
2022-07-05 09:08:11 - train: epoch 0034, iter [03500, 05004], lr: 0.010000, loss: 1.4889
2022-07-05 09:08:44 - train: epoch 0034, iter [03600, 05004], lr: 0.010000, loss: 1.4042
2022-07-05 09:09:17 - train: epoch 0034, iter [03700, 05004], lr: 0.010000, loss: 1.5778
2022-07-05 09:09:51 - train: epoch 0034, iter [03800, 05004], lr: 0.010000, loss: 1.6081
2022-07-05 09:10:23 - train: epoch 0034, iter [03900, 05004], lr: 0.010000, loss: 1.7467
2022-07-05 09:10:58 - train: epoch 0034, iter [04000, 05004], lr: 0.010000, loss: 1.6616
2022-07-05 09:11:31 - train: epoch 0034, iter [04100, 05004], lr: 0.010000, loss: 1.8468
2022-07-05 09:12:04 - train: epoch 0034, iter [04200, 05004], lr: 0.010000, loss: 1.6781
2022-07-05 09:12:37 - train: epoch 0034, iter [04300, 05004], lr: 0.010000, loss: 1.6462
2022-07-05 09:13:11 - train: epoch 0034, iter [04400, 05004], lr: 0.010000, loss: 1.6538
2022-07-05 09:13:44 - train: epoch 0034, iter [04500, 05004], lr: 0.010000, loss: 1.7162
2022-07-05 09:14:17 - train: epoch 0034, iter [04600, 05004], lr: 0.010000, loss: 1.8430
2022-07-05 09:14:50 - train: epoch 0034, iter [04700, 05004], lr: 0.010000, loss: 1.6590
2022-07-05 09:15:23 - train: epoch 0034, iter [04800, 05004], lr: 0.010000, loss: 1.7334
2022-07-05 09:15:56 - train: epoch 0034, iter [04900, 05004], lr: 0.010000, loss: 1.8173
2022-07-05 09:16:28 - train: epoch 0034, iter [05000, 05004], lr: 0.010000, loss: 1.5634
2022-07-05 09:16:29 - train: epoch 034, train_loss: 1.6788
2022-07-05 09:17:41 - eval: epoch: 034, acc1: 64.808%, acc5: 86.406%, test_loss: 1.4408, per_image_load_time: 2.549ms, per_image_inference_time: 0.190ms
2022-07-05 09:17:41 - until epoch: 034, best_acc1: 64.852%
2022-07-05 09:17:41 - epoch 035 lr: 0.010000
2022-07-05 09:18:19 - train: epoch 0035, iter [00100, 05004], lr: 0.010000, loss: 1.2962
2022-07-05 09:18:52 - train: epoch 0035, iter [00200, 05004], lr: 0.010000, loss: 1.6384
2022-07-05 09:19:25 - train: epoch 0035, iter [00300, 05004], lr: 0.010000, loss: 1.7554
2022-07-05 09:19:57 - train: epoch 0035, iter [00400, 05004], lr: 0.010000, loss: 1.6274
2022-07-05 09:20:30 - train: epoch 0035, iter [00500, 05004], lr: 0.010000, loss: 1.4700
2022-07-05 09:21:03 - train: epoch 0035, iter [00600, 05004], lr: 0.010000, loss: 1.8598
2022-07-05 09:21:36 - train: epoch 0035, iter [00700, 05004], lr: 0.010000, loss: 1.6958
2022-07-05 09:22:09 - train: epoch 0035, iter [00800, 05004], lr: 0.010000, loss: 1.6726
2022-07-05 09:22:42 - train: epoch 0035, iter [00900, 05004], lr: 0.010000, loss: 1.7047
2022-07-05 09:23:15 - train: epoch 0035, iter [01000, 05004], lr: 0.010000, loss: 1.5304
2022-07-05 09:23:48 - train: epoch 0035, iter [01100, 05004], lr: 0.010000, loss: 1.6533
2022-07-05 09:24:21 - train: epoch 0035, iter [01200, 05004], lr: 0.010000, loss: 1.5431
2022-07-05 09:24:54 - train: epoch 0035, iter [01300, 05004], lr: 0.010000, loss: 1.7265
2022-07-05 09:25:28 - train: epoch 0035, iter [01400, 05004], lr: 0.010000, loss: 1.6483
2022-07-05 09:26:01 - train: epoch 0035, iter [01500, 05004], lr: 0.010000, loss: 1.6634
2022-07-05 09:26:35 - train: epoch 0035, iter [01600, 05004], lr: 0.010000, loss: 1.6602
2022-07-05 09:27:06 - train: epoch 0035, iter [01700, 05004], lr: 0.010000, loss: 1.4668
2022-07-05 09:27:40 - train: epoch 0035, iter [01800, 05004], lr: 0.010000, loss: 1.7852
2022-07-05 09:28:14 - train: epoch 0035, iter [01900, 05004], lr: 0.010000, loss: 1.6732
2022-07-05 09:28:47 - train: epoch 0035, iter [02000, 05004], lr: 0.010000, loss: 1.7579
2022-07-05 09:29:21 - train: epoch 0035, iter [02100, 05004], lr: 0.010000, loss: 1.7871
2022-07-05 09:29:54 - train: epoch 0035, iter [02200, 05004], lr: 0.010000, loss: 1.6822
2022-07-05 09:30:28 - train: epoch 0035, iter [02300, 05004], lr: 0.010000, loss: 1.5589
2022-07-05 09:31:00 - train: epoch 0035, iter [02400, 05004], lr: 0.010000, loss: 1.7217
2022-07-05 09:31:34 - train: epoch 0035, iter [02500, 05004], lr: 0.010000, loss: 1.7761
2022-07-05 09:32:07 - train: epoch 0035, iter [02600, 05004], lr: 0.010000, loss: 1.7623
2022-07-05 09:32:40 - train: epoch 0035, iter [02700, 05004], lr: 0.010000, loss: 1.7170
2022-07-05 09:33:13 - train: epoch 0035, iter [02800, 05004], lr: 0.010000, loss: 1.5393
2022-07-05 09:33:48 - train: epoch 0035, iter [02900, 05004], lr: 0.010000, loss: 1.7928
2022-07-05 09:34:19 - train: epoch 0035, iter [03000, 05004], lr: 0.010000, loss: 1.4668
2022-07-05 09:34:53 - train: epoch 0035, iter [03100, 05004], lr: 0.010000, loss: 1.7094
2022-07-05 09:35:26 - train: epoch 0035, iter [03200, 05004], lr: 0.010000, loss: 1.5879
2022-07-05 09:36:00 - train: epoch 0035, iter [03300, 05004], lr: 0.010000, loss: 1.6679
2022-07-05 09:36:33 - train: epoch 0035, iter [03400, 05004], lr: 0.010000, loss: 1.6493
2022-07-05 09:37:07 - train: epoch 0035, iter [03500, 05004], lr: 0.010000, loss: 1.4972
2022-07-05 09:37:39 - train: epoch 0035, iter [03600, 05004], lr: 0.010000, loss: 1.6630
2022-07-05 09:38:13 - train: epoch 0035, iter [03700, 05004], lr: 0.010000, loss: 1.7187
2022-07-05 09:38:45 - train: epoch 0035, iter [03800, 05004], lr: 0.010000, loss: 1.5517
2022-07-05 09:39:19 - train: epoch 0035, iter [03900, 05004], lr: 0.010000, loss: 1.6224
2022-07-05 09:39:51 - train: epoch 0035, iter [04000, 05004], lr: 0.010000, loss: 1.4621
2022-07-05 09:40:26 - train: epoch 0035, iter [04100, 05004], lr: 0.010000, loss: 1.8446
2022-07-05 09:40:58 - train: epoch 0035, iter [04200, 05004], lr: 0.010000, loss: 1.4834
2022-07-05 09:41:32 - train: epoch 0035, iter [04300, 05004], lr: 0.010000, loss: 1.7938
2022-07-05 09:42:04 - train: epoch 0035, iter [04400, 05004], lr: 0.010000, loss: 1.8214
2022-07-05 09:42:38 - train: epoch 0035, iter [04500, 05004], lr: 0.010000, loss: 1.6745
2022-07-05 09:43:11 - train: epoch 0035, iter [04600, 05004], lr: 0.010000, loss: 1.6853
2022-07-05 09:43:44 - train: epoch 0035, iter [04700, 05004], lr: 0.010000, loss: 1.9305
2022-07-05 09:44:18 - train: epoch 0035, iter [04800, 05004], lr: 0.010000, loss: 1.7077
2022-07-05 09:44:50 - train: epoch 0035, iter [04900, 05004], lr: 0.010000, loss: 1.5265
2022-07-05 09:45:22 - train: epoch 0035, iter [05000, 05004], lr: 0.010000, loss: 1.5620
2022-07-05 09:45:23 - train: epoch 035, train_loss: 1.6575
2022-07-05 09:46:35 - eval: epoch: 035, acc1: 65.378%, acc5: 86.660%, test_loss: 1.4237, per_image_load_time: 2.102ms, per_image_inference_time: 0.183ms
2022-07-05 09:46:35 - until epoch: 035, best_acc1: 65.378%
2022-07-05 09:46:35 - epoch 036 lr: 0.010000
2022-07-05 09:47:14 - train: epoch 0036, iter [00100, 05004], lr: 0.010000, loss: 1.7853
2022-07-05 09:47:46 - train: epoch 0036, iter [00200, 05004], lr: 0.010000, loss: 1.3662
2022-07-05 09:48:18 - train: epoch 0036, iter [00300, 05004], lr: 0.010000, loss: 1.3255
2022-07-05 09:48:52 - train: epoch 0036, iter [00400, 05004], lr: 0.010000, loss: 1.5655
2022-07-05 09:49:24 - train: epoch 0036, iter [00500, 05004], lr: 0.010000, loss: 1.6596
2022-07-05 09:49:57 - train: epoch 0036, iter [00600, 05004], lr: 0.010000, loss: 1.5057
2022-07-05 09:50:29 - train: epoch 0036, iter [00700, 05004], lr: 0.010000, loss: 1.5493
2022-07-05 09:51:02 - train: epoch 0036, iter [00800, 05004], lr: 0.010000, loss: 1.4242
2022-07-05 09:51:34 - train: epoch 0036, iter [00900, 05004], lr: 0.010000, loss: 1.6029
2022-07-05 09:52:07 - train: epoch 0036, iter [01000, 05004], lr: 0.010000, loss: 1.6120
2022-07-05 09:52:40 - train: epoch 0036, iter [01100, 05004], lr: 0.010000, loss: 1.6686
2022-07-05 09:53:13 - train: epoch 0036, iter [01200, 05004], lr: 0.010000, loss: 1.7461
2022-07-05 09:53:45 - train: epoch 0036, iter [01300, 05004], lr: 0.010000, loss: 1.7415
2022-07-05 09:54:19 - train: epoch 0036, iter [01400, 05004], lr: 0.010000, loss: 1.6659
2022-07-05 09:54:52 - train: epoch 0036, iter [01500, 05004], lr: 0.010000, loss: 1.5870
2022-07-05 09:55:25 - train: epoch 0036, iter [01600, 05004], lr: 0.010000, loss: 1.6996
2022-07-05 09:55:58 - train: epoch 0036, iter [01700, 05004], lr: 0.010000, loss: 1.7352
2022-07-05 09:56:32 - train: epoch 0036, iter [01800, 05004], lr: 0.010000, loss: 1.5950
2022-07-05 09:57:04 - train: epoch 0036, iter [01900, 05004], lr: 0.010000, loss: 1.6401
2022-07-05 09:57:37 - train: epoch 0036, iter [02000, 05004], lr: 0.010000, loss: 1.5900
2022-07-05 09:58:11 - train: epoch 0036, iter [02100, 05004], lr: 0.010000, loss: 1.5451
2022-07-05 09:58:43 - train: epoch 0036, iter [02200, 05004], lr: 0.010000, loss: 1.7668
2022-07-05 09:59:16 - train: epoch 0036, iter [02300, 05004], lr: 0.010000, loss: 1.7404
2022-07-05 09:59:49 - train: epoch 0036, iter [02400, 05004], lr: 0.010000, loss: 1.8089
2022-07-05 10:00:23 - train: epoch 0036, iter [02500, 05004], lr: 0.010000, loss: 1.5188
2022-07-05 10:00:57 - train: epoch 0036, iter [02600, 05004], lr: 0.010000, loss: 1.4812
2022-07-05 10:01:29 - train: epoch 0036, iter [02700, 05004], lr: 0.010000, loss: 1.5350
2022-07-05 10:02:03 - train: epoch 0036, iter [02800, 05004], lr: 0.010000, loss: 1.4399
2022-07-05 10:02:35 - train: epoch 0036, iter [02900, 05004], lr: 0.010000, loss: 1.5649
2022-07-05 10:03:10 - train: epoch 0036, iter [03000, 05004], lr: 0.010000, loss: 1.5128
2022-07-05 10:03:42 - train: epoch 0036, iter [03100, 05004], lr: 0.010000, loss: 1.7393
2022-07-05 10:04:16 - train: epoch 0036, iter [03200, 05004], lr: 0.010000, loss: 1.7227
2022-07-05 10:04:48 - train: epoch 0036, iter [03300, 05004], lr: 0.010000, loss: 1.5895
2022-07-05 10:05:22 - train: epoch 0036, iter [03400, 05004], lr: 0.010000, loss: 1.5652
2022-07-05 10:05:55 - train: epoch 0036, iter [03500, 05004], lr: 0.010000, loss: 1.7404
2022-07-05 10:06:29 - train: epoch 0036, iter [03600, 05004], lr: 0.010000, loss: 1.7579
2022-07-05 10:07:01 - train: epoch 0036, iter [03700, 05004], lr: 0.010000, loss: 1.8051
2022-07-05 10:07:35 - train: epoch 0036, iter [03800, 05004], lr: 0.010000, loss: 1.8938
2022-07-05 10:08:08 - train: epoch 0036, iter [03900, 05004], lr: 0.010000, loss: 1.4646
2022-07-05 10:08:41 - train: epoch 0036, iter [04000, 05004], lr: 0.010000, loss: 1.7666
2022-07-05 10:09:15 - train: epoch 0036, iter [04100, 05004], lr: 0.010000, loss: 1.5411
2022-07-05 10:09:49 - train: epoch 0036, iter [04200, 05004], lr: 0.010000, loss: 1.7603
2022-07-05 10:10:21 - train: epoch 0036, iter [04300, 05004], lr: 0.010000, loss: 1.6313
2022-07-05 10:10:55 - train: epoch 0036, iter [04400, 05004], lr: 0.010000, loss: 1.8583
2022-07-05 10:11:28 - train: epoch 0036, iter [04500, 05004], lr: 0.010000, loss: 1.5896
2022-07-05 10:12:00 - train: epoch 0036, iter [04600, 05004], lr: 0.010000, loss: 1.4607
2022-07-05 10:12:34 - train: epoch 0036, iter [04700, 05004], lr: 0.010000, loss: 1.6141
2022-07-05 10:13:08 - train: epoch 0036, iter [04800, 05004], lr: 0.010000, loss: 1.5080
2022-07-05 10:13:41 - train: epoch 0036, iter [04900, 05004], lr: 0.010000, loss: 1.5906
2022-07-05 10:14:12 - train: epoch 0036, iter [05000, 05004], lr: 0.010000, loss: 1.5210
2022-07-05 10:14:13 - train: epoch 036, train_loss: 1.6405
2022-07-05 10:15:25 - eval: epoch: 036, acc1: 65.586%, acc5: 86.788%, test_loss: 1.4102, per_image_load_time: 2.582ms, per_image_inference_time: 0.199ms
2022-07-05 10:15:25 - until epoch: 036, best_acc1: 65.586%
2022-07-05 10:15:25 - epoch 037 lr: 0.010000
2022-07-05 10:16:04 - train: epoch 0037, iter [00100, 05004], lr: 0.010000, loss: 1.4717
2022-07-05 10:16:36 - train: epoch 0037, iter [00200, 05004], lr: 0.010000, loss: 1.5147
2022-07-05 10:17:08 - train: epoch 0037, iter [00300, 05004], lr: 0.010000, loss: 1.5297
2022-07-05 10:17:42 - train: epoch 0037, iter [00400, 05004], lr: 0.010000, loss: 1.4758
2022-07-05 10:18:14 - train: epoch 0037, iter [00500, 05004], lr: 0.010000, loss: 1.7411
2022-07-05 10:18:47 - train: epoch 0037, iter [00600, 05004], lr: 0.010000, loss: 1.7385
2022-07-05 10:19:20 - train: epoch 0037, iter [00700, 05004], lr: 0.010000, loss: 1.7733
2022-07-05 10:19:52 - train: epoch 0037, iter [00800, 05004], lr: 0.010000, loss: 1.5368
2022-07-05 10:20:25 - train: epoch 0037, iter [00900, 05004], lr: 0.010000, loss: 1.9525
2022-07-05 10:20:58 - train: epoch 0037, iter [01000, 05004], lr: 0.010000, loss: 1.6381
2022-07-05 10:21:32 - train: epoch 0037, iter [01100, 05004], lr: 0.010000, loss: 1.8073
2022-07-05 10:22:04 - train: epoch 0037, iter [01200, 05004], lr: 0.010000, loss: 1.7439
2022-07-05 10:22:36 - train: epoch 0037, iter [01300, 05004], lr: 0.010000, loss: 1.7679
2022-07-05 10:23:11 - train: epoch 0037, iter [01400, 05004], lr: 0.010000, loss: 1.9801
2022-07-05 10:23:43 - train: epoch 0037, iter [01500, 05004], lr: 0.010000, loss: 1.5842
2022-07-05 10:24:17 - train: epoch 0037, iter [01600, 05004], lr: 0.010000, loss: 1.3298
2022-07-05 10:24:49 - train: epoch 0037, iter [01700, 05004], lr: 0.010000, loss: 1.7935
2022-07-05 10:25:23 - train: epoch 0037, iter [01800, 05004], lr: 0.010000, loss: 1.5593
2022-07-05 10:25:56 - train: epoch 0037, iter [01900, 05004], lr: 0.010000, loss: 1.6198
2022-07-05 10:26:28 - train: epoch 0037, iter [02000, 05004], lr: 0.010000, loss: 1.7484
2022-07-05 10:27:02 - train: epoch 0037, iter [02100, 05004], lr: 0.010000, loss: 1.7063
2022-07-05 10:27:35 - train: epoch 0037, iter [02200, 05004], lr: 0.010000, loss: 1.4733
2022-07-05 10:28:08 - train: epoch 0037, iter [02300, 05004], lr: 0.010000, loss: 1.5267
2022-07-05 10:28:41 - train: epoch 0037, iter [02400, 05004], lr: 0.010000, loss: 1.6411
2022-07-05 10:29:13 - train: epoch 0037, iter [02500, 05004], lr: 0.010000, loss: 1.6214
2022-07-05 10:29:47 - train: epoch 0037, iter [02600, 05004], lr: 0.010000, loss: 1.9279
2022-07-05 10:30:20 - train: epoch 0037, iter [02700, 05004], lr: 0.010000, loss: 1.8255
2022-07-05 10:30:53 - train: epoch 0037, iter [02800, 05004], lr: 0.010000, loss: 1.7547
2022-07-05 10:31:27 - train: epoch 0037, iter [02900, 05004], lr: 0.010000, loss: 1.6867
2022-07-05 10:31:59 - train: epoch 0037, iter [03000, 05004], lr: 0.010000, loss: 1.9270
2022-07-05 10:32:32 - train: epoch 0037, iter [03100, 05004], lr: 0.010000, loss: 1.6393
2022-07-05 10:33:05 - train: epoch 0037, iter [03200, 05004], lr: 0.010000, loss: 1.7377
2022-07-05 10:33:38 - train: epoch 0037, iter [03300, 05004], lr: 0.010000, loss: 1.5130
2022-07-05 10:34:12 - train: epoch 0037, iter [03400, 05004], lr: 0.010000, loss: 1.3655
2022-07-05 10:34:45 - train: epoch 0037, iter [03500, 05004], lr: 0.010000, loss: 1.7444
2022-07-05 10:35:19 - train: epoch 0037, iter [03600, 05004], lr: 0.010000, loss: 1.6830
2022-07-05 10:35:51 - train: epoch 0037, iter [03700, 05004], lr: 0.010000, loss: 1.5685
2022-07-05 10:36:24 - train: epoch 0037, iter [03800, 05004], lr: 0.010000, loss: 1.8061
2022-07-05 10:36:57 - train: epoch 0037, iter [03900, 05004], lr: 0.010000, loss: 1.6278
2022-07-05 10:37:31 - train: epoch 0037, iter [04000, 05004], lr: 0.010000, loss: 1.4985
2022-07-05 10:38:04 - train: epoch 0037, iter [04100, 05004], lr: 0.010000, loss: 1.5421
2022-07-05 10:38:37 - train: epoch 0037, iter [04200, 05004], lr: 0.010000, loss: 1.6198
2022-07-05 10:39:10 - train: epoch 0037, iter [04300, 05004], lr: 0.010000, loss: 1.5987
2022-07-05 10:39:44 - train: epoch 0037, iter [04400, 05004], lr: 0.010000, loss: 1.6780
2022-07-05 10:40:16 - train: epoch 0037, iter [04500, 05004], lr: 0.010000, loss: 1.4657
2022-07-05 10:40:50 - train: epoch 0037, iter [04600, 05004], lr: 0.010000, loss: 1.5760
2022-07-05 10:41:24 - train: epoch 0037, iter [04700, 05004], lr: 0.010000, loss: 1.6702
2022-07-05 10:41:56 - train: epoch 0037, iter [04800, 05004], lr: 0.010000, loss: 1.6671
2022-07-05 10:42:30 - train: epoch 0037, iter [04900, 05004], lr: 0.010000, loss: 1.6265
2022-07-05 10:43:02 - train: epoch 0037, iter [05000, 05004], lr: 0.010000, loss: 1.5646
2022-07-05 10:43:03 - train: epoch 037, train_loss: 1.6309
2022-07-05 10:44:15 - eval: epoch: 037, acc1: 65.498%, acc5: 86.874%, test_loss: 1.4110, per_image_load_time: 2.099ms, per_image_inference_time: 0.193ms
2022-07-05 10:44:15 - until epoch: 037, best_acc1: 65.586%
2022-07-05 10:44:15 - epoch 038 lr: 0.010000
2022-07-05 10:44:53 - train: epoch 0038, iter [00100, 05004], lr: 0.010000, loss: 1.5501
2022-07-05 10:45:25 - train: epoch 0038, iter [00200, 05004], lr: 0.010000, loss: 1.3879
2022-07-05 10:45:57 - train: epoch 0038, iter [00300, 05004], lr: 0.010000, loss: 1.2839
2022-07-05 10:46:30 - train: epoch 0038, iter [00400, 05004], lr: 0.010000, loss: 1.5900
2022-07-05 10:47:04 - train: epoch 0038, iter [00500, 05004], lr: 0.010000, loss: 1.5441
2022-07-05 10:47:37 - train: epoch 0038, iter [00600, 05004], lr: 0.010000, loss: 1.6910
2022-07-05 10:48:10 - train: epoch 0038, iter [00700, 05004], lr: 0.010000, loss: 1.6245
2022-07-05 10:48:43 - train: epoch 0038, iter [00800, 05004], lr: 0.010000, loss: 1.6000
2022-07-05 10:49:16 - train: epoch 0038, iter [00900, 05004], lr: 0.010000, loss: 1.6243
2022-07-05 10:49:49 - train: epoch 0038, iter [01000, 05004], lr: 0.010000, loss: 1.7275
2022-07-05 10:50:22 - train: epoch 0038, iter [01100, 05004], lr: 0.010000, loss: 1.6083
2022-07-05 10:50:55 - train: epoch 0038, iter [01200, 05004], lr: 0.010000, loss: 1.6753
2022-07-05 10:51:28 - train: epoch 0038, iter [01300, 05004], lr: 0.010000, loss: 1.6534
2022-07-05 10:52:00 - train: epoch 0038, iter [01400, 05004], lr: 0.010000, loss: 1.6981
2022-07-05 10:52:34 - train: epoch 0038, iter [01500, 05004], lr: 0.010000, loss: 1.6572
2022-07-05 10:53:07 - train: epoch 0038, iter [01600, 05004], lr: 0.010000, loss: 1.6552
2022-07-05 10:53:40 - train: epoch 0038, iter [01700, 05004], lr: 0.010000, loss: 1.7081
2022-07-05 10:54:13 - train: epoch 0038, iter [01800, 05004], lr: 0.010000, loss: 1.7542
2022-07-05 10:54:46 - train: epoch 0038, iter [01900, 05004], lr: 0.010000, loss: 1.6121
2022-07-05 10:55:20 - train: epoch 0038, iter [02000, 05004], lr: 0.010000, loss: 1.6523
2022-07-05 10:55:52 - train: epoch 0038, iter [02100, 05004], lr: 0.010000, loss: 1.4584
2022-07-05 10:56:26 - train: epoch 0038, iter [02200, 05004], lr: 0.010000, loss: 1.4651
2022-07-05 10:56:59 - train: epoch 0038, iter [02300, 05004], lr: 0.010000, loss: 1.7683
2022-07-05 10:57:33 - train: epoch 0038, iter [02400, 05004], lr: 0.010000, loss: 1.8117
2022-07-05 10:58:06 - train: epoch 0038, iter [02500, 05004], lr: 0.010000, loss: 1.4263
2022-07-05 10:58:39 - train: epoch 0038, iter [02600, 05004], lr: 0.010000, loss: 1.6637
2022-07-05 10:59:14 - train: epoch 0038, iter [02700, 05004], lr: 0.010000, loss: 1.6366
2022-07-05 10:59:46 - train: epoch 0038, iter [02800, 05004], lr: 0.010000, loss: 2.0038
2022-07-05 11:00:21 - train: epoch 0038, iter [02900, 05004], lr: 0.010000, loss: 1.6502
2022-07-05 11:00:53 - train: epoch 0038, iter [03000, 05004], lr: 0.010000, loss: 1.7386
2022-07-05 11:01:26 - train: epoch 0038, iter [03100, 05004], lr: 0.010000, loss: 1.6106
2022-07-05 11:01:59 - train: epoch 0038, iter [03200, 05004], lr: 0.010000, loss: 1.3865
2022-07-05 11:02:33 - train: epoch 0038, iter [03300, 05004], lr: 0.010000, loss: 1.6283
2022-07-05 11:03:06 - train: epoch 0038, iter [03400, 05004], lr: 0.010000, loss: 1.6416
2022-07-05 11:03:40 - train: epoch 0038, iter [03500, 05004], lr: 0.010000, loss: 1.5010
2022-07-05 11:04:12 - train: epoch 0038, iter [03600, 05004], lr: 0.010000, loss: 1.6299
2022-07-05 11:04:46 - train: epoch 0038, iter [03700, 05004], lr: 0.010000, loss: 1.4903
2022-07-05 11:05:18 - train: epoch 0038, iter [03800, 05004], lr: 0.010000, loss: 1.8987
2022-07-05 11:05:52 - train: epoch 0038, iter [03900, 05004], lr: 0.010000, loss: 1.5131
2022-07-05 11:06:25 - train: epoch 0038, iter [04000, 05004], lr: 0.010000, loss: 1.5889
2022-07-05 11:06:58 - train: epoch 0038, iter [04100, 05004], lr: 0.010000, loss: 1.6667
2022-07-05 11:07:31 - train: epoch 0038, iter [04200, 05004], lr: 0.010000, loss: 1.5765
2022-07-05 11:08:06 - train: epoch 0038, iter [04300, 05004], lr: 0.010000, loss: 1.6848
2022-07-05 11:08:38 - train: epoch 0038, iter [04400, 05004], lr: 0.010000, loss: 1.7783
2022-07-05 11:09:12 - train: epoch 0038, iter [04500, 05004], lr: 0.010000, loss: 1.6472
2022-07-05 11:09:45 - train: epoch 0038, iter [04600, 05004], lr: 0.010000, loss: 1.7249
2022-07-05 11:10:19 - train: epoch 0038, iter [04700, 05004], lr: 0.010000, loss: 1.5379
2022-07-05 11:10:51 - train: epoch 0038, iter [04800, 05004], lr: 0.010000, loss: 1.5748
2022-07-05 11:11:25 - train: epoch 0038, iter [04900, 05004], lr: 0.010000, loss: 1.6461
2022-07-05 11:11:56 - train: epoch 0038, iter [05000, 05004], lr: 0.010000, loss: 1.4297
2022-07-05 11:11:57 - train: epoch 038, train_loss: 1.6243
2022-07-05 11:13:10 - eval: epoch: 038, acc1: 65.700%, acc5: 86.796%, test_loss: 1.4089, per_image_load_time: 2.312ms, per_image_inference_time: 0.155ms
2022-07-05 11:13:10 - until epoch: 038, best_acc1: 65.700%
2022-07-05 11:13:10 - epoch 039 lr: 0.010000
2022-07-05 11:13:48 - train: epoch 0039, iter [00100, 05004], lr: 0.010000, loss: 1.6524
2022-07-05 11:14:21 - train: epoch 0039, iter [00200, 05004], lr: 0.010000, loss: 1.7435
2022-07-05 11:14:53 - train: epoch 0039, iter [00300, 05004], lr: 0.010000, loss: 1.4736
2022-07-05 11:15:26 - train: epoch 0039, iter [00400, 05004], lr: 0.010000, loss: 1.7530
2022-07-05 11:15:59 - train: epoch 0039, iter [00500, 05004], lr: 0.010000, loss: 1.6350
2022-07-05 11:16:33 - train: epoch 0039, iter [00600, 05004], lr: 0.010000, loss: 1.5269
2022-07-05 11:17:05 - train: epoch 0039, iter [00700, 05004], lr: 0.010000, loss: 1.7875
2022-07-05 11:17:38 - train: epoch 0039, iter [00800, 05004], lr: 0.010000, loss: 1.5317
2022-07-05 11:18:11 - train: epoch 0039, iter [00900, 05004], lr: 0.010000, loss: 1.6821
2022-07-05 11:18:45 - train: epoch 0039, iter [01000, 05004], lr: 0.010000, loss: 1.4898
2022-07-05 11:19:18 - train: epoch 0039, iter [01100, 05004], lr: 0.010000, loss: 1.8020
2022-07-05 11:19:51 - train: epoch 0039, iter [01200, 05004], lr: 0.010000, loss: 1.6665
2022-07-05 11:20:25 - train: epoch 0039, iter [01300, 05004], lr: 0.010000, loss: 1.5991
2022-07-05 11:20:57 - train: epoch 0039, iter [01400, 05004], lr: 0.010000, loss: 1.9043
2022-07-05 11:21:30 - train: epoch 0039, iter [01500, 05004], lr: 0.010000, loss: 1.3755
2022-07-05 11:22:04 - train: epoch 0039, iter [01600, 05004], lr: 0.010000, loss: 1.6032
2022-07-05 11:22:37 - train: epoch 0039, iter [01700, 05004], lr: 0.010000, loss: 1.6429
2022-07-05 11:23:10 - train: epoch 0039, iter [01800, 05004], lr: 0.010000, loss: 1.5458
2022-07-05 11:23:43 - train: epoch 0039, iter [01900, 05004], lr: 0.010000, loss: 1.4563
2022-07-05 11:24:15 - train: epoch 0039, iter [02000, 05004], lr: 0.010000, loss: 1.6513
2022-07-05 11:24:49 - train: epoch 0039, iter [02100, 05004], lr: 0.010000, loss: 1.7028
2022-07-05 11:25:21 - train: epoch 0039, iter [02200, 05004], lr: 0.010000, loss: 1.7197
2022-07-05 11:25:54 - train: epoch 0039, iter [02300, 05004], lr: 0.010000, loss: 1.7671
2022-07-05 11:26:28 - train: epoch 0039, iter [02400, 05004], lr: 0.010000, loss: 1.6972
2022-07-05 11:27:01 - train: epoch 0039, iter [02500, 05004], lr: 0.010000, loss: 1.6504
2022-07-05 11:27:34 - train: epoch 0039, iter [02600, 05004], lr: 0.010000, loss: 1.5494
2022-07-05 11:28:07 - train: epoch 0039, iter [02700, 05004], lr: 0.010000, loss: 1.6698
2022-07-05 11:28:40 - train: epoch 0039, iter [02800, 05004], lr: 0.010000, loss: 1.6160
2022-07-05 11:29:13 - train: epoch 0039, iter [02900, 05004], lr: 0.010000, loss: 1.4474
2022-07-05 11:29:47 - train: epoch 0039, iter [03000, 05004], lr: 0.010000, loss: 1.5274
2022-07-05 11:30:20 - train: epoch 0039, iter [03100, 05004], lr: 0.010000, loss: 1.4847
2022-07-05 11:30:53 - train: epoch 0039, iter [03200, 05004], lr: 0.010000, loss: 1.5886
2022-07-05 11:31:27 - train: epoch 0039, iter [03300, 05004], lr: 0.010000, loss: 1.5105
2022-07-05 11:32:00 - train: epoch 0039, iter [03400, 05004], lr: 0.010000, loss: 1.5672
2022-07-05 11:32:33 - train: epoch 0039, iter [03500, 05004], lr: 0.010000, loss: 1.7121
2022-07-05 11:33:07 - train: epoch 0039, iter [03600, 05004], lr: 0.010000, loss: 1.6874
2022-07-05 11:33:39 - train: epoch 0039, iter [03700, 05004], lr: 0.010000, loss: 1.5490
2022-07-05 11:34:12 - train: epoch 0039, iter [03800, 05004], lr: 0.010000, loss: 1.6094
2022-07-05 11:34:45 - train: epoch 0039, iter [03900, 05004], lr: 0.010000, loss: 1.7191
2022-07-05 11:35:19 - train: epoch 0039, iter [04000, 05004], lr: 0.010000, loss: 1.6192
2022-07-05 11:35:53 - train: epoch 0039, iter [04100, 05004], lr: 0.010000, loss: 1.7515
2022-07-05 11:36:26 - train: epoch 0039, iter [04200, 05004], lr: 0.010000, loss: 1.7271
2022-07-05 11:36:59 - train: epoch 0039, iter [04300, 05004], lr: 0.010000, loss: 1.6293
2022-07-05 11:37:32 - train: epoch 0039, iter [04400, 05004], lr: 0.010000, loss: 1.4515
2022-07-05 11:38:06 - train: epoch 0039, iter [04500, 05004], lr: 0.010000, loss: 1.6832
2022-07-05 11:38:39 - train: epoch 0039, iter [04600, 05004], lr: 0.010000, loss: 1.8241
2022-07-05 11:39:12 - train: epoch 0039, iter [04700, 05004], lr: 0.010000, loss: 1.4274
2022-07-05 11:39:45 - train: epoch 0039, iter [04800, 05004], lr: 0.010000, loss: 1.5807
2022-07-05 11:40:18 - train: epoch 0039, iter [04900, 05004], lr: 0.010000, loss: 1.5418
2022-07-05 11:40:50 - train: epoch 0039, iter [05000, 05004], lr: 0.010000, loss: 1.5726
2022-07-05 11:40:51 - train: epoch 039, train_loss: 1.6168
2022-07-05 11:42:04 - eval: epoch: 039, acc1: 65.324%, acc5: 86.668%, test_loss: 1.4205, per_image_load_time: 1.959ms, per_image_inference_time: 0.175ms
2022-07-05 11:42:04 - until epoch: 039, best_acc1: 65.700%
2022-07-05 11:42:04 - epoch 040 lr: 0.010000
2022-07-05 11:42:42 - train: epoch 0040, iter [00100, 05004], lr: 0.010000, loss: 1.6724
2022-07-05 11:43:14 - train: epoch 0040, iter [00200, 05004], lr: 0.010000, loss: 1.6913
2022-07-05 11:43:48 - train: epoch 0040, iter [00300, 05004], lr: 0.010000, loss: 1.6602
2022-07-05 11:44:19 - train: epoch 0040, iter [00400, 05004], lr: 0.010000, loss: 1.4058
2022-07-05 11:44:54 - train: epoch 0040, iter [00500, 05004], lr: 0.010000, loss: 1.4280
2022-07-05 11:45:26 - train: epoch 0040, iter [00600, 05004], lr: 0.010000, loss: 1.5226
2022-07-05 11:45:59 - train: epoch 0040, iter [00700, 05004], lr: 0.010000, loss: 1.5908
2022-07-05 11:46:31 - train: epoch 0040, iter [00800, 05004], lr: 0.010000, loss: 1.7120
2022-07-05 11:47:05 - train: epoch 0040, iter [00900, 05004], lr: 0.010000, loss: 1.5114
2022-07-05 11:47:37 - train: epoch 0040, iter [01000, 05004], lr: 0.010000, loss: 1.5518
2022-07-05 11:48:11 - train: epoch 0040, iter [01100, 05004], lr: 0.010000, loss: 1.5036
2022-07-05 11:48:44 - train: epoch 0040, iter [01200, 05004], lr: 0.010000, loss: 1.6298
2022-07-05 11:49:18 - train: epoch 0040, iter [01300, 05004], lr: 0.010000, loss: 1.4271
2022-07-05 11:49:51 - train: epoch 0040, iter [01400, 05004], lr: 0.010000, loss: 1.5685
2022-07-05 11:50:24 - train: epoch 0040, iter [01500, 05004], lr: 0.010000, loss: 1.6823
2022-07-05 11:50:56 - train: epoch 0040, iter [01600, 05004], lr: 0.010000, loss: 1.7635
2022-07-05 11:51:29 - train: epoch 0040, iter [01700, 05004], lr: 0.010000, loss: 1.6830
2022-07-05 11:52:02 - train: epoch 0040, iter [01800, 05004], lr: 0.010000, loss: 1.5024
2022-07-05 11:52:36 - train: epoch 0040, iter [01900, 05004], lr: 0.010000, loss: 1.4581
2022-07-05 11:53:09 - train: epoch 0040, iter [02000, 05004], lr: 0.010000, loss: 1.5810
2022-07-05 11:53:42 - train: epoch 0040, iter [02100, 05004], lr: 0.010000, loss: 1.4712
2022-07-05 11:54:15 - train: epoch 0040, iter [02200, 05004], lr: 0.010000, loss: 1.5302
2022-07-05 11:54:47 - train: epoch 0040, iter [02300, 05004], lr: 0.010000, loss: 1.5424
2022-07-05 11:55:21 - train: epoch 0040, iter [02400, 05004], lr: 0.010000, loss: 1.5446
2022-07-05 11:55:54 - train: epoch 0040, iter [02500, 05004], lr: 0.010000, loss: 1.7014
2022-07-05 11:56:28 - train: epoch 0040, iter [02600, 05004], lr: 0.010000, loss: 1.6118
2022-07-05 11:57:02 - train: epoch 0040, iter [02700, 05004], lr: 0.010000, loss: 1.7372
2022-07-05 11:57:34 - train: epoch 0040, iter [02800, 05004], lr: 0.010000, loss: 1.6325
2022-07-05 11:58:07 - train: epoch 0040, iter [02900, 05004], lr: 0.010000, loss: 1.6225
2022-07-05 11:58:41 - train: epoch 0040, iter [03000, 05004], lr: 0.010000, loss: 1.5462
2022-07-05 11:59:14 - train: epoch 0040, iter [03100, 05004], lr: 0.010000, loss: 1.7060
2022-07-05 11:59:48 - train: epoch 0040, iter [03200, 05004], lr: 0.010000, loss: 1.7100
2022-07-05 12:00:21 - train: epoch 0040, iter [03300, 05004], lr: 0.010000, loss: 1.8346
2022-07-05 12:00:55 - train: epoch 0040, iter [03400, 05004], lr: 0.010000, loss: 1.7730
2022-07-05 12:01:27 - train: epoch 0040, iter [03500, 05004], lr: 0.010000, loss: 1.7272
2022-07-05 12:02:00 - train: epoch 0040, iter [03600, 05004], lr: 0.010000, loss: 1.5955
2022-07-05 12:02:34 - train: epoch 0040, iter [03700, 05004], lr: 0.010000, loss: 1.5116
2022-07-05 12:03:07 - train: epoch 0040, iter [03800, 05004], lr: 0.010000, loss: 1.6034
2022-07-05 12:03:39 - train: epoch 0040, iter [03900, 05004], lr: 0.010000, loss: 1.9049
2022-07-05 12:04:14 - train: epoch 0040, iter [04000, 05004], lr: 0.010000, loss: 1.6878
2022-07-05 12:04:46 - train: epoch 0040, iter [04100, 05004], lr: 0.010000, loss: 1.5974
2022-07-05 12:05:21 - train: epoch 0040, iter [04200, 05004], lr: 0.010000, loss: 1.5686
2022-07-05 12:05:54 - train: epoch 0040, iter [04300, 05004], lr: 0.010000, loss: 1.7096
2022-07-05 12:06:27 - train: epoch 0040, iter [04400, 05004], lr: 0.010000, loss: 1.5368
2022-07-05 12:07:00 - train: epoch 0040, iter [04500, 05004], lr: 0.010000, loss: 1.4211
2022-07-05 12:07:33 - train: epoch 0040, iter [04600, 05004], lr: 0.010000, loss: 1.6443
2022-07-05 12:08:07 - train: epoch 0040, iter [04700, 05004], lr: 0.010000, loss: 1.8555
2022-07-05 12:08:40 - train: epoch 0040, iter [04800, 05004], lr: 0.010000, loss: 1.4850
2022-07-05 12:09:13 - train: epoch 0040, iter [04900, 05004], lr: 0.010000, loss: 1.5195
2022-07-05 12:09:44 - train: epoch 0040, iter [05000, 05004], lr: 0.010000, loss: 1.4963
2022-07-05 12:09:45 - train: epoch 040, train_loss: 1.6154
2022-07-05 12:10:58 - eval: epoch: 040, acc1: 65.788%, acc5: 86.976%, test_loss: 1.4018, per_image_load_time: 2.663ms, per_image_inference_time: 0.171ms
2022-07-05 12:10:58 - until epoch: 040, best_acc1: 65.788%
2022-07-05 12:10:58 - epoch 041 lr: 0.010000
2022-07-05 12:11:36 - train: epoch 0041, iter [00100, 05004], lr: 0.010000, loss: 1.8536
2022-07-05 12:12:09 - train: epoch 0041, iter [00200, 05004], lr: 0.010000, loss: 1.8996
2022-07-05 12:12:42 - train: epoch 0041, iter [00300, 05004], lr: 0.010000, loss: 1.5671
2022-07-05 12:13:14 - train: epoch 0041, iter [00400, 05004], lr: 0.010000, loss: 1.6436
2022-07-05 12:13:46 - train: epoch 0041, iter [00500, 05004], lr: 0.010000, loss: 1.4438
2022-07-05 12:14:19 - train: epoch 0041, iter [00600, 05004], lr: 0.010000, loss: 1.7606
2022-07-05 12:14:52 - train: epoch 0041, iter [00700, 05004], lr: 0.010000, loss: 1.5722
2022-07-05 12:15:25 - train: epoch 0041, iter [00800, 05004], lr: 0.010000, loss: 1.5092
2022-07-05 12:15:58 - train: epoch 0041, iter [00900, 05004], lr: 0.010000, loss: 1.4522
2022-07-05 12:16:32 - train: epoch 0041, iter [01000, 05004], lr: 0.010000, loss: 1.6849
2022-07-05 12:17:04 - train: epoch 0041, iter [01100, 05004], lr: 0.010000, loss: 1.6088
2022-07-05 12:17:37 - train: epoch 0041, iter [01200, 05004], lr: 0.010000, loss: 1.6077
2022-07-05 12:18:10 - train: epoch 0041, iter [01300, 05004], lr: 0.010000, loss: 1.4909
2022-07-05 12:18:44 - train: epoch 0041, iter [01400, 05004], lr: 0.010000, loss: 1.9391
2022-07-05 12:19:16 - train: epoch 0041, iter [01500, 05004], lr: 0.010000, loss: 1.7335
2022-07-05 12:19:49 - train: epoch 0041, iter [01600, 05004], lr: 0.010000, loss: 1.6969
2022-07-05 12:20:23 - train: epoch 0041, iter [01700, 05004], lr: 0.010000, loss: 1.4257
2022-07-05 12:20:55 - train: epoch 0041, iter [01800, 05004], lr: 0.010000, loss: 1.5127
2022-07-05 12:21:29 - train: epoch 0041, iter [01900, 05004], lr: 0.010000, loss: 1.7646
2022-07-05 12:22:02 - train: epoch 0041, iter [02000, 05004], lr: 0.010000, loss: 1.4777
2022-07-05 12:22:36 - train: epoch 0041, iter [02100, 05004], lr: 0.010000, loss: 1.3791
2022-07-05 12:23:08 - train: epoch 0041, iter [02200, 05004], lr: 0.010000, loss: 1.4147
2022-07-05 12:23:42 - train: epoch 0041, iter [02300, 05004], lr: 0.010000, loss: 1.5295
2022-07-05 12:24:15 - train: epoch 0041, iter [02400, 05004], lr: 0.010000, loss: 1.8755
2022-07-05 12:24:48 - train: epoch 0041, iter [02500, 05004], lr: 0.010000, loss: 1.4408
2022-07-05 12:25:21 - train: epoch 0041, iter [02600, 05004], lr: 0.010000, loss: 1.7331
2022-07-05 12:25:54 - train: epoch 0041, iter [02700, 05004], lr: 0.010000, loss: 1.8931
2022-07-05 12:26:28 - train: epoch 0041, iter [02800, 05004], lr: 0.010000, loss: 1.6710
2022-07-05 12:27:00 - train: epoch 0041, iter [02900, 05004], lr: 0.010000, loss: 1.5515
2022-07-05 12:27:34 - train: epoch 0041, iter [03000, 05004], lr: 0.010000, loss: 1.7389
2022-07-05 12:28:07 - train: epoch 0041, iter [03100, 05004], lr: 0.010000, loss: 1.6315
2022-07-05 12:28:40 - train: epoch 0041, iter [03200, 05004], lr: 0.010000, loss: 1.5452
2022-07-05 12:29:13 - train: epoch 0041, iter [03300, 05004], lr: 0.010000, loss: 1.8054
2022-07-05 12:29:46 - train: epoch 0041, iter [03400, 05004], lr: 0.010000, loss: 1.5121
2022-07-05 12:30:19 - train: epoch 0041, iter [03500, 05004], lr: 0.010000, loss: 1.5472
2022-07-05 12:30:53 - train: epoch 0041, iter [03600, 05004], lr: 0.010000, loss: 1.8665
2022-07-05 12:31:25 - train: epoch 0041, iter [03700, 05004], lr: 0.010000, loss: 1.6747
2022-07-05 12:31:58 - train: epoch 0041, iter [03800, 05004], lr: 0.010000, loss: 1.5818
2022-07-05 12:32:32 - train: epoch 0041, iter [03900, 05004], lr: 0.010000, loss: 1.4581
2022-07-05 12:33:04 - train: epoch 0041, iter [04000, 05004], lr: 0.010000, loss: 1.4143
2022-07-05 12:33:38 - train: epoch 0041, iter [04100, 05004], lr: 0.010000, loss: 1.7553
2022-07-05 12:34:10 - train: epoch 0041, iter [04200, 05004], lr: 0.010000, loss: 1.4760
2022-07-05 12:34:44 - train: epoch 0041, iter [04300, 05004], lr: 0.010000, loss: 1.5324
2022-07-05 12:35:17 - train: epoch 0041, iter [04400, 05004], lr: 0.010000, loss: 1.4107
2022-07-05 12:35:51 - train: epoch 0041, iter [04500, 05004], lr: 0.010000, loss: 1.6542
2022-07-05 12:36:23 - train: epoch 0041, iter [04600, 05004], lr: 0.010000, loss: 1.7312
2022-07-05 12:36:57 - train: epoch 0041, iter [04700, 05004], lr: 0.010000, loss: 1.6262
2022-07-05 12:37:29 - train: epoch 0041, iter [04800, 05004], lr: 0.010000, loss: 1.6339
2022-07-05 12:38:03 - train: epoch 0041, iter [04900, 05004], lr: 0.010000, loss: 1.6682
2022-07-05 12:38:35 - train: epoch 0041, iter [05000, 05004], lr: 0.010000, loss: 1.6251
2022-07-05 12:38:35 - train: epoch 041, train_loss: 1.6131
2022-07-05 12:39:48 - eval: epoch: 041, acc1: 65.324%, acc5: 86.784%, test_loss: 1.4237, per_image_load_time: 1.629ms, per_image_inference_time: 0.178ms
2022-07-05 12:39:48 - until epoch: 041, best_acc1: 65.788%
2022-07-05 12:39:48 - epoch 042 lr: 0.010000
2022-07-05 12:40:26 - train: epoch 0042, iter [00100, 05004], lr: 0.010000, loss: 1.1965
2022-07-05 12:40:58 - train: epoch 0042, iter [00200, 05004], lr: 0.010000, loss: 1.6024
2022-07-05 12:41:31 - train: epoch 0042, iter [00300, 05004], lr: 0.010000, loss: 1.5209
2022-07-05 12:42:04 - train: epoch 0042, iter [00400, 05004], lr: 0.010000, loss: 1.5268
2022-07-05 12:42:36 - train: epoch 0042, iter [00500, 05004], lr: 0.010000, loss: 1.4639
2022-07-05 12:43:10 - train: epoch 0042, iter [00600, 05004], lr: 0.010000, loss: 1.4363
2022-07-05 12:43:41 - train: epoch 0042, iter [00700, 05004], lr: 0.010000, loss: 1.8115
2022-07-05 12:44:14 - train: epoch 0042, iter [00800, 05004], lr: 0.010000, loss: 1.6863
2022-07-05 12:44:47 - train: epoch 0042, iter [00900, 05004], lr: 0.010000, loss: 1.8335
2022-07-05 12:45:20 - train: epoch 0042, iter [01000, 05004], lr: 0.010000, loss: 1.8275
2022-07-05 12:45:54 - train: epoch 0042, iter [01100, 05004], lr: 0.010000, loss: 1.5785
2022-07-05 12:46:27 - train: epoch 0042, iter [01200, 05004], lr: 0.010000, loss: 1.5945
2022-07-05 12:47:00 - train: epoch 0042, iter [01300, 05004], lr: 0.010000, loss: 1.8929
2022-07-05 12:47:32 - train: epoch 0042, iter [01400, 05004], lr: 0.010000, loss: 1.8027
2022-07-05 12:48:06 - train: epoch 0042, iter [01500, 05004], lr: 0.010000, loss: 1.4620
2022-07-05 12:48:38 - train: epoch 0042, iter [01600, 05004], lr: 0.010000, loss: 1.7475
2022-07-05 12:49:12 - train: epoch 0042, iter [01700, 05004], lr: 0.010000, loss: 1.6968
2022-07-05 12:49:45 - train: epoch 0042, iter [01800, 05004], lr: 0.010000, loss: 1.5142
2022-07-05 12:50:18 - train: epoch 0042, iter [01900, 05004], lr: 0.010000, loss: 1.6387
2022-07-05 12:50:50 - train: epoch 0042, iter [02000, 05004], lr: 0.010000, loss: 1.5933
2022-07-05 12:51:24 - train: epoch 0042, iter [02100, 05004], lr: 0.010000, loss: 1.2635
2022-07-05 12:51:56 - train: epoch 0042, iter [02200, 05004], lr: 0.010000, loss: 1.7492
2022-07-05 12:52:30 - train: epoch 0042, iter [02300, 05004], lr: 0.010000, loss: 1.6538
2022-07-05 12:53:03 - train: epoch 0042, iter [02400, 05004], lr: 0.010000, loss: 1.6285
2022-07-05 12:53:36 - train: epoch 0042, iter [02500, 05004], lr: 0.010000, loss: 1.6100
2022-07-05 12:54:09 - train: epoch 0042, iter [02600, 05004], lr: 0.010000, loss: 1.6463
2022-07-05 12:54:42 - train: epoch 0042, iter [02700, 05004], lr: 0.010000, loss: 1.5462
2022-07-05 12:55:15 - train: epoch 0042, iter [02800, 05004], lr: 0.010000, loss: 1.5511
2022-07-05 12:55:48 - train: epoch 0042, iter [02900, 05004], lr: 0.010000, loss: 1.4744
2022-07-05 12:56:21 - train: epoch 0042, iter [03000, 05004], lr: 0.010000, loss: 1.5491
2022-07-05 12:56:54 - train: epoch 0042, iter [03100, 05004], lr: 0.010000, loss: 1.6987
2022-07-05 12:57:28 - train: epoch 0042, iter [03200, 05004], lr: 0.010000, loss: 1.6992
2022-07-05 12:58:00 - train: epoch 0042, iter [03300, 05004], lr: 0.010000, loss: 1.9125
2022-07-05 12:58:33 - train: epoch 0042, iter [03400, 05004], lr: 0.010000, loss: 1.3781
2022-07-05 12:59:06 - train: epoch 0042, iter [03500, 05004], lr: 0.010000, loss: 1.7052
2022-07-05 12:59:39 - train: epoch 0042, iter [03600, 05004], lr: 0.010000, loss: 1.8506
2022-07-05 13:00:12 - train: epoch 0042, iter [03700, 05004], lr: 0.010000, loss: 1.5105
2022-07-05 13:00:46 - train: epoch 0042, iter [03800, 05004], lr: 0.010000, loss: 1.4316
2022-07-05 13:01:19 - train: epoch 0042, iter [03900, 05004], lr: 0.010000, loss: 1.6428
2022-07-05 13:01:53 - train: epoch 0042, iter [04000, 05004], lr: 0.010000, loss: 1.5189
2022-07-05 13:02:25 - train: epoch 0042, iter [04100, 05004], lr: 0.010000, loss: 1.7699
2022-07-05 13:03:00 - train: epoch 0042, iter [04200, 05004], lr: 0.010000, loss: 1.6065
2022-07-05 13:03:32 - train: epoch 0042, iter [04300, 05004], lr: 0.010000, loss: 1.5049
2022-07-05 13:04:05 - train: epoch 0042, iter [04400, 05004], lr: 0.010000, loss: 1.5173
2022-07-05 13:04:37 - train: epoch 0042, iter [04500, 05004], lr: 0.010000, loss: 1.6372
2022-07-05 13:05:12 - train: epoch 0042, iter [04600, 05004], lr: 0.010000, loss: 1.8014
2022-07-05 13:05:44 - train: epoch 0042, iter [04700, 05004], lr: 0.010000, loss: 1.5506
2022-07-05 13:06:17 - train: epoch 0042, iter [04800, 05004], lr: 0.010000, loss: 1.6570
2022-07-05 13:06:51 - train: epoch 0042, iter [04900, 05004], lr: 0.010000, loss: 1.5632
2022-07-05 13:07:22 - train: epoch 0042, iter [05000, 05004], lr: 0.010000, loss: 1.6685
2022-07-05 13:07:23 - train: epoch 042, train_loss: 1.6100
2022-07-05 13:08:36 - eval: epoch: 042, acc1: 65.474%, acc5: 86.904%, test_loss: 1.4174, per_image_load_time: 2.622ms, per_image_inference_time: 0.188ms
2022-07-05 13:08:36 - until epoch: 042, best_acc1: 65.788%
2022-07-05 13:08:36 - epoch 043 lr: 0.010000
2022-07-05 13:09:14 - train: epoch 0043, iter [00100, 05004], lr: 0.010000, loss: 1.7653
2022-07-05 13:09:47 - train: epoch 0043, iter [00200, 05004], lr: 0.010000, loss: 1.5666
2022-07-05 13:10:20 - train: epoch 0043, iter [00300, 05004], lr: 0.010000, loss: 1.2807
2022-07-05 13:10:52 - train: epoch 0043, iter [00400, 05004], lr: 0.010000, loss: 1.4300
2022-07-05 13:11:26 - train: epoch 0043, iter [00500, 05004], lr: 0.010000, loss: 1.4148
2022-07-05 13:11:57 - train: epoch 0043, iter [00600, 05004], lr: 0.010000, loss: 1.5855
2022-07-05 13:12:31 - train: epoch 0043, iter [00700, 05004], lr: 0.010000, loss: 1.6516
2022-07-05 13:13:03 - train: epoch 0043, iter [00800, 05004], lr: 0.010000, loss: 1.5053
2022-07-05 13:13:36 - train: epoch 0043, iter [00900, 05004], lr: 0.010000, loss: 1.6880
2022-07-05 13:14:08 - train: epoch 0043, iter [01000, 05004], lr: 0.010000, loss: 1.8198
2022-07-05 13:14:42 - train: epoch 0043, iter [01100, 05004], lr: 0.010000, loss: 1.6026
2022-07-05 13:15:15 - train: epoch 0043, iter [01200, 05004], lr: 0.010000, loss: 1.6120
2022-07-05 13:15:49 - train: epoch 0043, iter [01300, 05004], lr: 0.010000, loss: 1.9009
2022-07-05 13:16:22 - train: epoch 0043, iter [01400, 05004], lr: 0.010000, loss: 1.7404
2022-07-05 13:16:56 - train: epoch 0043, iter [01500, 05004], lr: 0.010000, loss: 1.3739
2022-07-05 13:17:28 - train: epoch 0043, iter [01600, 05004], lr: 0.010000, loss: 1.5316
2022-07-05 13:18:01 - train: epoch 0043, iter [01700, 05004], lr: 0.010000, loss: 1.6548
2022-07-05 13:18:34 - train: epoch 0043, iter [01800, 05004], lr: 0.010000, loss: 1.8634
2022-07-05 13:19:08 - train: epoch 0043, iter [01900, 05004], lr: 0.010000, loss: 1.6564
2022-07-05 13:19:40 - train: epoch 0043, iter [02000, 05004], lr: 0.010000, loss: 1.3104
2022-07-05 13:20:13 - train: epoch 0043, iter [02100, 05004], lr: 0.010000, loss: 1.5054
2022-07-05 13:20:47 - train: epoch 0043, iter [02200, 05004], lr: 0.010000, loss: 1.8020
2022-07-05 13:21:18 - train: epoch 0043, iter [02300, 05004], lr: 0.010000, loss: 1.6404
2022-07-05 13:21:52 - train: epoch 0043, iter [02400, 05004], lr: 0.010000, loss: 1.2512
2022-07-05 13:22:26 - train: epoch 0043, iter [02500, 05004], lr: 0.010000, loss: 1.6364
2022-07-05 13:22:59 - train: epoch 0043, iter [02600, 05004], lr: 0.010000, loss: 1.4159
2022-07-05 13:23:30 - train: epoch 0043, iter [02700, 05004], lr: 0.010000, loss: 1.7284
2022-07-05 13:24:04 - train: epoch 0043, iter [02800, 05004], lr: 0.010000, loss: 1.4407
2022-07-05 13:24:37 - train: epoch 0043, iter [02900, 05004], lr: 0.010000, loss: 1.5709
2022-07-05 13:25:10 - train: epoch 0043, iter [03000, 05004], lr: 0.010000, loss: 1.8028
2022-07-05 13:25:42 - train: epoch 0043, iter [03100, 05004], lr: 0.010000, loss: 1.7068
2022-07-05 13:26:16 - train: epoch 0043, iter [03200, 05004], lr: 0.010000, loss: 1.5559
2022-07-05 13:26:49 - train: epoch 0043, iter [03300, 05004], lr: 0.010000, loss: 1.7918
2022-07-05 13:27:23 - train: epoch 0043, iter [03400, 05004], lr: 0.010000, loss: 1.5011
2022-07-05 13:27:55 - train: epoch 0043, iter [03500, 05004], lr: 0.010000, loss: 1.6269
2022-07-05 13:28:29 - train: epoch 0043, iter [03600, 05004], lr: 0.010000, loss: 1.8459
2022-07-05 13:29:01 - train: epoch 0043, iter [03700, 05004], lr: 0.010000, loss: 1.4444
2022-07-05 13:29:35 - train: epoch 0043, iter [03800, 05004], lr: 0.010000, loss: 1.7012
2022-07-05 13:30:08 - train: epoch 0043, iter [03900, 05004], lr: 0.010000, loss: 1.5396
2022-07-05 13:30:41 - train: epoch 0043, iter [04000, 05004], lr: 0.010000, loss: 1.7320
2022-07-05 13:31:14 - train: epoch 0043, iter [04100, 05004], lr: 0.010000, loss: 1.7675
2022-07-05 13:31:47 - train: epoch 0043, iter [04200, 05004], lr: 0.010000, loss: 1.4407
2022-07-05 13:32:21 - train: epoch 0043, iter [04300, 05004], lr: 0.010000, loss: 1.7560
2022-07-05 13:32:54 - train: epoch 0043, iter [04400, 05004], lr: 0.010000, loss: 1.5276
2022-07-05 13:33:27 - train: epoch 0043, iter [04500, 05004], lr: 0.010000, loss: 1.6350
2022-07-05 13:34:00 - train: epoch 0043, iter [04600, 05004], lr: 0.010000, loss: 1.4249
2022-07-05 13:34:33 - train: epoch 0043, iter [04700, 05004], lr: 0.010000, loss: 1.6168
2022-07-05 13:35:05 - train: epoch 0043, iter [04800, 05004], lr: 0.010000, loss: 1.5871
2022-07-05 13:35:39 - train: epoch 0043, iter [04900, 05004], lr: 0.010000, loss: 1.5820
2022-07-05 13:36:11 - train: epoch 0043, iter [05000, 05004], lr: 0.010000, loss: 1.6515
2022-07-05 13:36:11 - train: epoch 043, train_loss: 1.6087
2022-07-05 13:37:24 - eval: epoch: 043, acc1: 65.186%, acc5: 86.590%, test_loss: 1.4309, per_image_load_time: 2.600ms, per_image_inference_time: 0.189ms
2022-07-05 13:37:24 - until epoch: 043, best_acc1: 65.788%
2022-07-05 13:37:24 - epoch 044 lr: 0.010000
2022-07-05 13:38:03 - train: epoch 0044, iter [00100, 05004], lr: 0.010000, loss: 1.6151
2022-07-05 13:38:35 - train: epoch 0044, iter [00200, 05004], lr: 0.010000, loss: 1.6350
2022-07-05 13:39:08 - train: epoch 0044, iter [00300, 05004], lr: 0.010000, loss: 1.6004
2022-07-05 13:39:41 - train: epoch 0044, iter [00400, 05004], lr: 0.010000, loss: 1.3349
2022-07-05 13:40:14 - train: epoch 0044, iter [00500, 05004], lr: 0.010000, loss: 1.7446
2022-07-05 13:40:46 - train: epoch 0044, iter [00600, 05004], lr: 0.010000, loss: 1.4280
2022-07-05 13:41:20 - train: epoch 0044, iter [00700, 05004], lr: 0.010000, loss: 1.7499
2022-07-05 13:41:53 - train: epoch 0044, iter [00800, 05004], lr: 0.010000, loss: 1.6267
2022-07-05 13:42:24 - train: epoch 0044, iter [00900, 05004], lr: 0.010000, loss: 1.4053
2022-07-05 13:42:58 - train: epoch 0044, iter [01000, 05004], lr: 0.010000, loss: 1.5803
2022-07-05 13:43:31 - train: epoch 0044, iter [01100, 05004], lr: 0.010000, loss: 1.3748
2022-07-05 13:44:04 - train: epoch 0044, iter [01200, 05004], lr: 0.010000, loss: 1.6002
2022-07-05 13:44:37 - train: epoch 0044, iter [01300, 05004], lr: 0.010000, loss: 1.6747
2022-07-05 13:45:11 - train: epoch 0044, iter [01400, 05004], lr: 0.010000, loss: 1.5234
2022-07-05 13:45:43 - train: epoch 0044, iter [01500, 05004], lr: 0.010000, loss: 1.5659
2022-07-05 13:46:17 - train: epoch 0044, iter [01600, 05004], lr: 0.010000, loss: 1.4799
2022-07-05 13:46:50 - train: epoch 0044, iter [01700, 05004], lr: 0.010000, loss: 1.5652
2022-07-05 13:47:23 - train: epoch 0044, iter [01800, 05004], lr: 0.010000, loss: 1.6286
2022-07-05 13:47:55 - train: epoch 0044, iter [01900, 05004], lr: 0.010000, loss: 1.7329
2022-07-05 13:48:29 - train: epoch 0044, iter [02000, 05004], lr: 0.010000, loss: 1.5129
2022-07-05 13:49:04 - train: epoch 0044, iter [02100, 05004], lr: 0.010000, loss: 1.7714
2022-07-05 13:49:36 - train: epoch 0044, iter [02200, 05004], lr: 0.010000, loss: 1.6997
2022-07-05 13:50:09 - train: epoch 0044, iter [02300, 05004], lr: 0.010000, loss: 1.7977
2022-07-05 13:50:43 - train: epoch 0044, iter [02400, 05004], lr: 0.010000, loss: 1.7009
2022-07-05 13:51:16 - train: epoch 0044, iter [02500, 05004], lr: 0.010000, loss: 1.6697
2022-07-05 13:51:49 - train: epoch 0044, iter [02600, 05004], lr: 0.010000, loss: 1.6692
2022-07-05 13:52:22 - train: epoch 0044, iter [02700, 05004], lr: 0.010000, loss: 1.6355
2022-07-05 13:52:56 - train: epoch 0044, iter [02800, 05004], lr: 0.010000, loss: 1.5531
2022-07-05 13:53:29 - train: epoch 0044, iter [02900, 05004], lr: 0.010000, loss: 1.2620
2022-07-05 13:54:02 - train: epoch 0044, iter [03000, 05004], lr: 0.010000, loss: 1.5628
2022-07-05 13:54:34 - train: epoch 0044, iter [03100, 05004], lr: 0.010000, loss: 1.5339
2022-07-05 13:55:07 - train: epoch 0044, iter [03200, 05004], lr: 0.010000, loss: 1.5563
2022-07-05 13:55:40 - train: epoch 0044, iter [03300, 05004], lr: 0.010000, loss: 1.5334
2022-07-05 13:56:13 - train: epoch 0044, iter [03400, 05004], lr: 0.010000, loss: 1.7844
2022-07-05 13:56:47 - train: epoch 0044, iter [03500, 05004], lr: 0.010000, loss: 1.7010
2022-07-05 13:57:20 - train: epoch 0044, iter [03600, 05004], lr: 0.010000, loss: 1.4770
2022-07-05 13:57:53 - train: epoch 0044, iter [03700, 05004], lr: 0.010000, loss: 1.5679
2022-07-05 13:58:25 - train: epoch 0044, iter [03800, 05004], lr: 0.010000, loss: 1.4036
2022-07-05 13:58:59 - train: epoch 0044, iter [03900, 05004], lr: 0.010000, loss: 1.6961
2022-07-05 13:59:32 - train: epoch 0044, iter [04000, 05004], lr: 0.010000, loss: 1.8260
2022-07-05 14:00:05 - train: epoch 0044, iter [04100, 05004], lr: 0.010000, loss: 1.4934
2022-07-05 14:00:39 - train: epoch 0044, iter [04200, 05004], lr: 0.010000, loss: 1.6116
2022-07-05 14:01:12 - train: epoch 0044, iter [04300, 05004], lr: 0.010000, loss: 1.5876
2022-07-05 14:01:46 - train: epoch 0044, iter [04400, 05004], lr: 0.010000, loss: 1.5557
2022-07-05 14:02:18 - train: epoch 0044, iter [04500, 05004], lr: 0.010000, loss: 1.7008
2022-07-05 14:02:51 - train: epoch 0044, iter [04600, 05004], lr: 0.010000, loss: 1.5578
2022-07-05 14:03:25 - train: epoch 0044, iter [04700, 05004], lr: 0.010000, loss: 1.6047
2022-07-05 14:03:58 - train: epoch 0044, iter [04800, 05004], lr: 0.010000, loss: 1.6909
2022-07-05 14:04:30 - train: epoch 0044, iter [04900, 05004], lr: 0.010000, loss: 1.4973
2022-07-05 14:05:02 - train: epoch 0044, iter [05000, 05004], lr: 0.010000, loss: 1.6858
2022-07-05 14:05:03 - train: epoch 044, train_loss: 1.6065
2022-07-05 14:06:16 - eval: epoch: 044, acc1: 64.982%, acc5: 86.662%, test_loss: 1.4412, per_image_load_time: 1.107ms, per_image_inference_time: 0.153ms
2022-07-05 14:06:17 - until epoch: 044, best_acc1: 65.788%
2022-07-05 14:06:17 - epoch 045 lr: 0.010000
2022-07-05 14:06:55 - train: epoch 0045, iter [00100, 05004], lr: 0.010000, loss: 1.4637
2022-07-05 14:07:28 - train: epoch 0045, iter [00200, 05004], lr: 0.010000, loss: 1.7803
2022-07-05 14:08:00 - train: epoch 0045, iter [00300, 05004], lr: 0.010000, loss: 1.4503
2022-07-05 14:08:33 - train: epoch 0045, iter [00400, 05004], lr: 0.010000, loss: 1.5731
2022-07-05 14:09:06 - train: epoch 0045, iter [00500, 05004], lr: 0.010000, loss: 2.0399
2022-07-05 14:09:38 - train: epoch 0045, iter [00600, 05004], lr: 0.010000, loss: 1.7384
2022-07-05 14:10:12 - train: epoch 0045, iter [00700, 05004], lr: 0.010000, loss: 1.4448
2022-07-05 14:10:45 - train: epoch 0045, iter [00800, 05004], lr: 0.010000, loss: 1.5636
2022-07-05 14:11:17 - train: epoch 0045, iter [00900, 05004], lr: 0.010000, loss: 1.3966
2022-07-05 14:11:51 - train: epoch 0045, iter [01000, 05004], lr: 0.010000, loss: 1.5860
2022-07-05 14:12:24 - train: epoch 0045, iter [01100, 05004], lr: 0.010000, loss: 1.6857
2022-07-05 14:12:57 - train: epoch 0045, iter [01200, 05004], lr: 0.010000, loss: 1.5871
2022-07-05 14:13:29 - train: epoch 0045, iter [01300, 05004], lr: 0.010000, loss: 1.6730
2022-07-05 14:14:02 - train: epoch 0045, iter [01400, 05004], lr: 0.010000, loss: 1.7540
2022-07-05 14:14:36 - train: epoch 0045, iter [01500, 05004], lr: 0.010000, loss: 1.5596
2022-07-05 14:15:09 - train: epoch 0045, iter [01600, 05004], lr: 0.010000, loss: 1.5157
2022-07-05 14:15:42 - train: epoch 0045, iter [01700, 05004], lr: 0.010000, loss: 1.4775
2022-07-05 14:16:15 - train: epoch 0045, iter [01800, 05004], lr: 0.010000, loss: 1.5958
2022-07-05 14:16:49 - train: epoch 0045, iter [01900, 05004], lr: 0.010000, loss: 1.5066
2022-07-05 14:17:22 - train: epoch 0045, iter [02000, 05004], lr: 0.010000, loss: 1.6602
2022-07-05 14:17:56 - train: epoch 0045, iter [02100, 05004], lr: 0.010000, loss: 1.5663
2022-07-05 14:18:28 - train: epoch 0045, iter [02200, 05004], lr: 0.010000, loss: 1.8546
2022-07-05 14:19:01 - train: epoch 0045, iter [02300, 05004], lr: 0.010000, loss: 1.4754
2022-07-05 14:19:34 - train: epoch 0045, iter [02400, 05004], lr: 0.010000, loss: 1.6984
2022-07-05 14:20:07 - train: epoch 0045, iter [02500, 05004], lr: 0.010000, loss: 1.5423
2022-07-05 14:20:41 - train: epoch 0045, iter [02600, 05004], lr: 0.010000, loss: 1.4899
2022-07-05 14:21:15 - train: epoch 0045, iter [02700, 05004], lr: 0.010000, loss: 1.5180
2022-07-05 14:21:48 - train: epoch 0045, iter [02800, 05004], lr: 0.010000, loss: 1.5715
2022-07-05 14:22:20 - train: epoch 0045, iter [02900, 05004], lr: 0.010000, loss: 1.9895
2022-07-05 14:22:54 - train: epoch 0045, iter [03000, 05004], lr: 0.010000, loss: 1.6101
2022-07-05 14:23:27 - train: epoch 0045, iter [03100, 05004], lr: 0.010000, loss: 1.5166
2022-07-05 14:24:00 - train: epoch 0045, iter [03200, 05004], lr: 0.010000, loss: 1.7797
2022-07-05 14:24:34 - train: epoch 0045, iter [03300, 05004], lr: 0.010000, loss: 1.7765
2022-07-05 14:25:07 - train: epoch 0045, iter [03400, 05004], lr: 0.010000, loss: 1.5027
2022-07-05 14:25:40 - train: epoch 0045, iter [03500, 05004], lr: 0.010000, loss: 1.6520
2022-07-05 14:26:13 - train: epoch 0045, iter [03600, 05004], lr: 0.010000, loss: 1.5918
2022-07-05 14:26:46 - train: epoch 0045, iter [03700, 05004], lr: 0.010000, loss: 1.7068
2022-07-05 14:27:19 - train: epoch 0045, iter [03800, 05004], lr: 0.010000, loss: 1.5272
2022-07-05 14:27:52 - train: epoch 0045, iter [03900, 05004], lr: 0.010000, loss: 1.5848
2022-07-05 14:28:25 - train: epoch 0045, iter [04000, 05004], lr: 0.010000, loss: 1.6606
2022-07-05 14:28:59 - train: epoch 0045, iter [04100, 05004], lr: 0.010000, loss: 1.5572
2022-07-05 14:29:32 - train: epoch 0045, iter [04200, 05004], lr: 0.010000, loss: 1.7592
2022-07-05 14:30:05 - train: epoch 0045, iter [04300, 05004], lr: 0.010000, loss: 1.7552
2022-07-05 14:30:38 - train: epoch 0045, iter [04400, 05004], lr: 0.010000, loss: 1.7604
2022-07-05 14:31:11 - train: epoch 0045, iter [04500, 05004], lr: 0.010000, loss: 1.5678
2022-07-05 14:31:44 - train: epoch 0045, iter [04600, 05004], lr: 0.010000, loss: 1.5958
2022-07-05 14:32:16 - train: epoch 0045, iter [04700, 05004], lr: 0.010000, loss: 1.6798
2022-07-05 14:32:50 - train: epoch 0045, iter [04800, 05004], lr: 0.010000, loss: 1.4363
2022-07-05 14:33:24 - train: epoch 0045, iter [04900, 05004], lr: 0.010000, loss: 1.8541
2022-07-05 14:33:55 - train: epoch 0045, iter [05000, 05004], lr: 0.010000, loss: 1.7187
2022-07-05 14:33:56 - train: epoch 045, train_loss: 1.6078
2022-07-05 14:35:10 - eval: epoch: 045, acc1: 65.284%, acc5: 86.778%, test_loss: 1.4251, per_image_load_time: 1.654ms, per_image_inference_time: 0.178ms
2022-07-05 14:35:10 - until epoch: 045, best_acc1: 65.788%
2022-07-05 14:35:10 - epoch 046 lr: 0.010000
2022-07-05 14:35:48 - train: epoch 0046, iter [00100, 05004], lr: 0.010000, loss: 1.5742
2022-07-05 14:36:20 - train: epoch 0046, iter [00200, 05004], lr: 0.010000, loss: 1.5105
2022-07-05 14:36:54 - train: epoch 0046, iter [00300, 05004], lr: 0.010000, loss: 1.4912
2022-07-05 14:37:26 - train: epoch 0046, iter [00400, 05004], lr: 0.010000, loss: 1.5637
2022-07-05 14:37:59 - train: epoch 0046, iter [00500, 05004], lr: 0.010000, loss: 1.6071
2022-07-05 14:38:32 - train: epoch 0046, iter [00600, 05004], lr: 0.010000, loss: 1.8114
2022-07-05 14:39:05 - train: epoch 0046, iter [00700, 05004], lr: 0.010000, loss: 1.5922
2022-07-05 14:39:38 - train: epoch 0046, iter [00800, 05004], lr: 0.010000, loss: 1.7530
2022-07-05 14:40:12 - train: epoch 0046, iter [00900, 05004], lr: 0.010000, loss: 1.4420
2022-07-05 14:40:44 - train: epoch 0046, iter [01000, 05004], lr: 0.010000, loss: 1.5839
2022-07-05 14:41:18 - train: epoch 0046, iter [01100, 05004], lr: 0.010000, loss: 1.4369
2022-07-05 14:41:51 - train: epoch 0046, iter [01200, 05004], lr: 0.010000, loss: 1.5051
2022-07-05 14:42:24 - train: epoch 0046, iter [01300, 05004], lr: 0.010000, loss: 1.5629
2022-07-05 14:42:57 - train: epoch 0046, iter [01400, 05004], lr: 0.010000, loss: 1.5840
2022-07-05 14:43:30 - train: epoch 0046, iter [01500, 05004], lr: 0.010000, loss: 1.5346
2022-07-05 14:44:03 - train: epoch 0046, iter [01600, 05004], lr: 0.010000, loss: 1.6737
2022-07-05 14:44:36 - train: epoch 0046, iter [01700, 05004], lr: 0.010000, loss: 1.7424
2022-07-05 14:45:10 - train: epoch 0046, iter [01800, 05004], lr: 0.010000, loss: 1.6168
2022-07-05 14:45:43 - train: epoch 0046, iter [01900, 05004], lr: 0.010000, loss: 1.4937
2022-07-05 14:46:17 - train: epoch 0046, iter [02000, 05004], lr: 0.010000, loss: 1.4751
2022-07-05 14:46:50 - train: epoch 0046, iter [02100, 05004], lr: 0.010000, loss: 1.6854
2022-07-05 14:47:24 - train: epoch 0046, iter [02200, 05004], lr: 0.010000, loss: 1.4078
2022-07-05 14:47:56 - train: epoch 0046, iter [02300, 05004], lr: 0.010000, loss: 1.8981
2022-07-05 14:48:29 - train: epoch 0046, iter [02400, 05004], lr: 0.010000, loss: 1.5937
2022-07-05 14:49:03 - train: epoch 0046, iter [02500, 05004], lr: 0.010000, loss: 1.4677
2022-07-05 14:49:36 - train: epoch 0046, iter [02600, 05004], lr: 0.010000, loss: 1.8026
2022-07-05 14:50:09 - train: epoch 0046, iter [02700, 05004], lr: 0.010000, loss: 1.6765
2022-07-05 14:50:43 - train: epoch 0046, iter [02800, 05004], lr: 0.010000, loss: 1.4343
2022-07-05 14:51:15 - train: epoch 0046, iter [02900, 05004], lr: 0.010000, loss: 1.7029
2022-07-05 14:51:49 - train: epoch 0046, iter [03000, 05004], lr: 0.010000, loss: 1.4489
2022-07-05 14:52:22 - train: epoch 0046, iter [03100, 05004], lr: 0.010000, loss: 1.4814
2022-07-05 14:52:55 - train: epoch 0046, iter [03200, 05004], lr: 0.010000, loss: 1.8849
2022-07-05 14:53:28 - train: epoch 0046, iter [03300, 05004], lr: 0.010000, loss: 1.5695
2022-07-05 14:54:01 - train: epoch 0046, iter [03400, 05004], lr: 0.010000, loss: 1.5677
2022-07-05 14:54:35 - train: epoch 0046, iter [03500, 05004], lr: 0.010000, loss: 1.7691
2022-07-05 14:55:09 - train: epoch 0046, iter [03600, 05004], lr: 0.010000, loss: 1.5486
2022-07-05 14:55:42 - train: epoch 0046, iter [03700, 05004], lr: 0.010000, loss: 1.4388
2022-07-05 14:56:15 - train: epoch 0046, iter [03800, 05004], lr: 0.010000, loss: 1.5716
2022-07-05 14:56:48 - train: epoch 0046, iter [03900, 05004], lr: 0.010000, loss: 1.8224
2022-07-05 14:57:22 - train: epoch 0046, iter [04000, 05004], lr: 0.010000, loss: 1.5372
2022-07-05 14:57:55 - train: epoch 0046, iter [04100, 05004], lr: 0.010000, loss: 1.5944
2022-07-05 14:58:28 - train: epoch 0046, iter [04200, 05004], lr: 0.010000, loss: 1.3962
2022-07-05 14:59:02 - train: epoch 0046, iter [04300, 05004], lr: 0.010000, loss: 1.6270
2022-07-05 14:59:34 - train: epoch 0046, iter [04400, 05004], lr: 0.010000, loss: 1.7940
2022-07-05 15:00:08 - train: epoch 0046, iter [04500, 05004], lr: 0.010000, loss: 1.5481
2022-07-05 15:00:40 - train: epoch 0046, iter [04600, 05004], lr: 0.010000, loss: 1.5595
2022-07-05 15:01:14 - train: epoch 0046, iter [04700, 05004], lr: 0.010000, loss: 1.5707
2022-07-05 15:01:47 - train: epoch 0046, iter [04800, 05004], lr: 0.010000, loss: 1.3945
2022-07-05 15:02:20 - train: epoch 0046, iter [04900, 05004], lr: 0.010000, loss: 1.6548
2022-07-05 15:02:52 - train: epoch 0046, iter [05000, 05004], lr: 0.010000, loss: 1.5482
2022-07-05 15:02:53 - train: epoch 046, train_loss: 1.6099
2022-07-05 15:04:06 - eval: epoch: 046, acc1: 65.492%, acc5: 86.798%, test_loss: 1.4155, per_image_load_time: 2.669ms, per_image_inference_time: 0.176ms
2022-07-05 15:04:06 - until epoch: 046, best_acc1: 65.788%
2022-07-05 15:04:06 - epoch 047 lr: 0.010000
2022-07-05 15:04:45 - train: epoch 0047, iter [00100, 05004], lr: 0.010000, loss: 1.4857
2022-07-05 15:05:17 - train: epoch 0047, iter [00200, 05004], lr: 0.010000, loss: 1.6569
2022-07-05 15:05:51 - train: epoch 0047, iter [00300, 05004], lr: 0.010000, loss: 1.3525
2022-07-05 15:06:22 - train: epoch 0047, iter [00400, 05004], lr: 0.010000, loss: 1.4234
2022-07-05 15:06:55 - train: epoch 0047, iter [00500, 05004], lr: 0.010000, loss: 1.5073
2022-07-05 15:07:29 - train: epoch 0047, iter [00600, 05004], lr: 0.010000, loss: 1.4723
2022-07-05 15:08:01 - train: epoch 0047, iter [00700, 05004], lr: 0.010000, loss: 1.7694
2022-07-05 15:08:34 - train: epoch 0047, iter [00800, 05004], lr: 0.010000, loss: 1.6009
2022-07-05 15:09:07 - train: epoch 0047, iter [00900, 05004], lr: 0.010000, loss: 1.6942
2022-07-05 15:09:40 - train: epoch 0047, iter [01000, 05004], lr: 0.010000, loss: 1.7196
2022-07-05 15:10:13 - train: epoch 0047, iter [01100, 05004], lr: 0.010000, loss: 1.7040
2022-07-05 15:10:46 - train: epoch 0047, iter [01200, 05004], lr: 0.010000, loss: 1.6202
2022-07-05 15:11:20 - train: epoch 0047, iter [01300, 05004], lr: 0.010000, loss: 1.6056
2022-07-05 15:11:53 - train: epoch 0047, iter [01400, 05004], lr: 0.010000, loss: 1.6829
2022-07-05 15:12:27 - train: epoch 0047, iter [01500, 05004], lr: 0.010000, loss: 1.6271
2022-07-05 15:12:58 - train: epoch 0047, iter [01600, 05004], lr: 0.010000, loss: 1.6459
2022-07-05 15:13:32 - train: epoch 0047, iter [01700, 05004], lr: 0.010000, loss: 1.4330
2022-07-05 15:14:05 - train: epoch 0047, iter [01800, 05004], lr: 0.010000, loss: 1.7639
2022-07-05 15:14:39 - train: epoch 0047, iter [01900, 05004], lr: 0.010000, loss: 1.4992
2022-07-05 15:15:12 - train: epoch 0047, iter [02000, 05004], lr: 0.010000, loss: 1.7138
2022-07-05 15:15:45 - train: epoch 0047, iter [02100, 05004], lr: 0.010000, loss: 1.7007
2022-07-05 15:16:19 - train: epoch 0047, iter [02200, 05004], lr: 0.010000, loss: 1.8547
2022-07-05 15:16:52 - train: epoch 0047, iter [02300, 05004], lr: 0.010000, loss: 1.5698
2022-07-05 15:17:25 - train: epoch 0047, iter [02400, 05004], lr: 0.010000, loss: 1.5447
2022-07-05 15:17:58 - train: epoch 0047, iter [02500, 05004], lr: 0.010000, loss: 1.6082
2022-07-05 15:18:31 - train: epoch 0047, iter [02600, 05004], lr: 0.010000, loss: 1.8106
2022-07-05 15:19:04 - train: epoch 0047, iter [02700, 05004], lr: 0.010000, loss: 1.3778
2022-07-05 15:19:37 - train: epoch 0047, iter [02800, 05004], lr: 0.010000, loss: 1.8992
2022-07-05 15:20:10 - train: epoch 0047, iter [02900, 05004], lr: 0.010000, loss: 1.5711
2022-07-05 15:20:44 - train: epoch 0047, iter [03000, 05004], lr: 0.010000, loss: 1.7865
2022-07-05 15:21:19 - train: epoch 0047, iter [03100, 05004], lr: 0.010000, loss: 1.6060
2022-07-05 15:21:50 - train: epoch 0047, iter [03200, 05004], lr: 0.010000, loss: 1.6709
2022-07-05 15:22:23 - train: epoch 0047, iter [03300, 05004], lr: 0.010000, loss: 1.6887
2022-07-05 15:22:58 - train: epoch 0047, iter [03400, 05004], lr: 0.010000, loss: 1.3980
2022-07-05 15:23:30 - train: epoch 0047, iter [03500, 05004], lr: 0.010000, loss: 1.8982
2022-07-05 15:24:04 - train: epoch 0047, iter [03600, 05004], lr: 0.010000, loss: 1.5482
2022-07-05 15:24:37 - train: epoch 0047, iter [03700, 05004], lr: 0.010000, loss: 1.4348
2022-07-05 15:25:10 - train: epoch 0047, iter [03800, 05004], lr: 0.010000, loss: 1.9542
2022-07-05 15:25:44 - train: epoch 0047, iter [03900, 05004], lr: 0.010000, loss: 1.6024
2022-07-05 15:26:16 - train: epoch 0047, iter [04000, 05004], lr: 0.010000, loss: 1.7992
2022-07-05 15:26:51 - train: epoch 0047, iter [04100, 05004], lr: 0.010000, loss: 1.7032
2022-07-05 15:27:23 - train: epoch 0047, iter [04200, 05004], lr: 0.010000, loss: 1.5905
2022-07-05 15:27:57 - train: epoch 0047, iter [04300, 05004], lr: 0.010000, loss: 1.5224
2022-07-05 15:28:30 - train: epoch 0047, iter [04400, 05004], lr: 0.010000, loss: 1.6975
2022-07-05 15:29:04 - train: epoch 0047, iter [04500, 05004], lr: 0.010000, loss: 1.6489
2022-07-05 15:29:37 - train: epoch 0047, iter [04600, 05004], lr: 0.010000, loss: 1.6108
2022-07-05 15:30:09 - train: epoch 0047, iter [04700, 05004], lr: 0.010000, loss: 1.7033
2022-07-05 15:30:43 - train: epoch 0047, iter [04800, 05004], lr: 0.010000, loss: 1.4960
2022-07-05 15:31:15 - train: epoch 0047, iter [04900, 05004], lr: 0.010000, loss: 1.4733
2022-07-05 15:31:48 - train: epoch 0047, iter [05000, 05004], lr: 0.010000, loss: 1.5390
2022-07-05 15:31:49 - train: epoch 047, train_loss: 1.6077
2022-07-05 15:33:03 - eval: epoch: 047, acc1: 65.348%, acc5: 86.670%, test_loss: 1.4246, per_image_load_time: 2.712ms, per_image_inference_time: 0.166ms
2022-07-05 15:33:03 - until epoch: 047, best_acc1: 65.788%
2022-07-05 15:33:03 - epoch 048 lr: 0.010000
2022-07-05 15:33:41 - train: epoch 0048, iter [00100, 05004], lr: 0.010000, loss: 1.6699
2022-07-05 15:34:14 - train: epoch 0048, iter [00200, 05004], lr: 0.010000, loss: 1.7704
2022-07-05 15:34:46 - train: epoch 0048, iter [00300, 05004], lr: 0.010000, loss: 1.4698
2022-07-05 15:35:20 - train: epoch 0048, iter [00400, 05004], lr: 0.010000, loss: 1.6600
2022-07-05 15:35:52 - train: epoch 0048, iter [00500, 05004], lr: 0.010000, loss: 1.4208
2022-07-05 15:36:25 - train: epoch 0048, iter [00600, 05004], lr: 0.010000, loss: 1.7192
2022-07-05 15:36:57 - train: epoch 0048, iter [00700, 05004], lr: 0.010000, loss: 1.5554
2022-07-05 15:37:31 - train: epoch 0048, iter [00800, 05004], lr: 0.010000, loss: 1.5132
2022-07-05 15:38:03 - train: epoch 0048, iter [00900, 05004], lr: 0.010000, loss: 1.8996
2022-07-05 15:38:36 - train: epoch 0048, iter [01000, 05004], lr: 0.010000, loss: 1.7979
2022-07-05 15:39:10 - train: epoch 0048, iter [01100, 05004], lr: 0.010000, loss: 1.9810
2022-07-05 15:39:41 - train: epoch 0048, iter [01200, 05004], lr: 0.010000, loss: 1.6872
2022-07-05 15:40:15 - train: epoch 0048, iter [01300, 05004], lr: 0.010000, loss: 1.5011
2022-07-05 15:40:48 - train: epoch 0048, iter [01400, 05004], lr: 0.010000, loss: 1.4675
2022-07-05 15:41:21 - train: epoch 0048, iter [01500, 05004], lr: 0.010000, loss: 1.6139
2022-07-05 15:41:54 - train: epoch 0048, iter [01600, 05004], lr: 0.010000, loss: 1.5300
2022-07-05 15:42:27 - train: epoch 0048, iter [01700, 05004], lr: 0.010000, loss: 1.6389
2022-07-05 15:43:00 - train: epoch 0048, iter [01800, 05004], lr: 0.010000, loss: 1.5630
2022-07-05 15:43:33 - train: epoch 0048, iter [01900, 05004], lr: 0.010000, loss: 1.6739
2022-07-05 15:44:07 - train: epoch 0048, iter [02000, 05004], lr: 0.010000, loss: 1.8379
2022-07-05 15:44:39 - train: epoch 0048, iter [02100, 05004], lr: 0.010000, loss: 1.6588
2022-07-05 15:45:12 - train: epoch 0048, iter [02200, 05004], lr: 0.010000, loss: 1.9286
2022-07-05 15:45:45 - train: epoch 0048, iter [02300, 05004], lr: 0.010000, loss: 1.4830
2022-07-05 15:46:18 - train: epoch 0048, iter [02400, 05004], lr: 0.010000, loss: 1.8135
2022-07-05 15:46:51 - train: epoch 0048, iter [02500, 05004], lr: 0.010000, loss: 1.7294
2022-07-05 15:47:23 - train: epoch 0048, iter [02600, 05004], lr: 0.010000, loss: 1.5828
2022-07-05 15:47:56 - train: epoch 0048, iter [02700, 05004], lr: 0.010000, loss: 1.7294
2022-07-05 15:48:30 - train: epoch 0048, iter [02800, 05004], lr: 0.010000, loss: 1.6697
2022-07-05 15:49:03 - train: epoch 0048, iter [02900, 05004], lr: 0.010000, loss: 1.7808
2022-07-05 15:49:36 - train: epoch 0048, iter [03000, 05004], lr: 0.010000, loss: 1.4936
2022-07-05 15:50:09 - train: epoch 0048, iter [03100, 05004], lr: 0.010000, loss: 1.7769
2022-07-05 15:50:41 - train: epoch 0048, iter [03200, 05004], lr: 0.010000, loss: 1.5393
2022-07-05 15:51:15 - train: epoch 0048, iter [03300, 05004], lr: 0.010000, loss: 1.6160
2022-07-05 15:51:47 - train: epoch 0048, iter [03400, 05004], lr: 0.010000, loss: 1.7176
2022-07-05 15:52:21 - train: epoch 0048, iter [03500, 05004], lr: 0.010000, loss: 1.7009
2022-07-05 15:52:55 - train: epoch 0048, iter [03600, 05004], lr: 0.010000, loss: 1.6960
2022-07-05 15:53:27 - train: epoch 0048, iter [03700, 05004], lr: 0.010000, loss: 1.7222
2022-07-05 15:53:59 - train: epoch 0048, iter [03800, 05004], lr: 0.010000, loss: 1.5221
2022-07-05 15:54:32 - train: epoch 0048, iter [03900, 05004], lr: 0.010000, loss: 1.8359
2022-07-05 15:55:05 - train: epoch 0048, iter [04000, 05004], lr: 0.010000, loss: 1.6083
2022-07-05 15:55:39 - train: epoch 0048, iter [04100, 05004], lr: 0.010000, loss: 1.6855
2022-07-05 15:56:11 - train: epoch 0048, iter [04200, 05004], lr: 0.010000, loss: 1.7062
2022-07-05 15:56:44 - train: epoch 0048, iter [04300, 05004], lr: 0.010000, loss: 1.5468
2022-07-05 15:57:17 - train: epoch 0048, iter [04400, 05004], lr: 0.010000, loss: 1.5616
2022-07-05 15:57:51 - train: epoch 0048, iter [04500, 05004], lr: 0.010000, loss: 1.7440
2022-07-05 15:58:24 - train: epoch 0048, iter [04600, 05004], lr: 0.010000, loss: 1.5327
2022-07-05 15:58:58 - train: epoch 0048, iter [04700, 05004], lr: 0.010000, loss: 1.7020
2022-07-05 15:59:31 - train: epoch 0048, iter [04800, 05004], lr: 0.010000, loss: 1.8743
2022-07-05 16:00:03 - train: epoch 0048, iter [04900, 05004], lr: 0.010000, loss: 1.7768
2022-07-05 16:00:35 - train: epoch 0048, iter [05000, 05004], lr: 0.010000, loss: 1.6168
2022-07-05 16:00:36 - train: epoch 048, train_loss: 1.6075
2022-07-05 16:01:49 - eval: epoch: 048, acc1: 65.122%, acc5: 86.526%, test_loss: 1.4324, per_image_load_time: 2.579ms, per_image_inference_time: 0.173ms
2022-07-05 16:01:49 - until epoch: 048, best_acc1: 65.788%
2022-07-05 16:01:49 - epoch 049 lr: 0.010000
2022-07-05 16:02:28 - train: epoch 0049, iter [00100, 05004], lr: 0.010000, loss: 1.5596
2022-07-05 16:03:00 - train: epoch 0049, iter [00200, 05004], lr: 0.010000, loss: 1.4938
2022-07-05 16:03:33 - train: epoch 0049, iter [00300, 05004], lr: 0.010000, loss: 1.7236
2022-07-05 16:04:05 - train: epoch 0049, iter [00400, 05004], lr: 0.010000, loss: 1.5015
2022-07-05 16:04:38 - train: epoch 0049, iter [00500, 05004], lr: 0.010000, loss: 1.6045
2022-07-05 16:05:11 - train: epoch 0049, iter [00600, 05004], lr: 0.010000, loss: 1.3155
2022-07-05 16:05:43 - train: epoch 0049, iter [00700, 05004], lr: 0.010000, loss: 1.7191
2022-07-05 16:06:16 - train: epoch 0049, iter [00800, 05004], lr: 0.010000, loss: 1.8009
2022-07-05 16:06:50 - train: epoch 0049, iter [00900, 05004], lr: 0.010000, loss: 1.4321
2022-07-05 16:07:23 - train: epoch 0049, iter [01000, 05004], lr: 0.010000, loss: 1.7397
2022-07-05 16:07:56 - train: epoch 0049, iter [01100, 05004], lr: 0.010000, loss: 1.6096
2022-07-05 16:08:28 - train: epoch 0049, iter [01200, 05004], lr: 0.010000, loss: 1.5778
2022-07-05 16:09:01 - train: epoch 0049, iter [01300, 05004], lr: 0.010000, loss: 1.8553
2022-07-05 16:09:33 - train: epoch 0049, iter [01400, 05004], lr: 0.010000, loss: 1.8394
2022-07-05 16:10:07 - train: epoch 0049, iter [01500, 05004], lr: 0.010000, loss: 1.4011
2022-07-05 16:10:40 - train: epoch 0049, iter [01600, 05004], lr: 0.010000, loss: 1.5360
2022-07-05 16:11:12 - train: epoch 0049, iter [01700, 05004], lr: 0.010000, loss: 1.5504
2022-07-05 16:11:47 - train: epoch 0049, iter [01800, 05004], lr: 0.010000, loss: 1.6930
2022-07-05 16:12:19 - train: epoch 0049, iter [01900, 05004], lr: 0.010000, loss: 1.4826
2022-07-05 16:12:53 - train: epoch 0049, iter [02000, 05004], lr: 0.010000, loss: 1.4358
2022-07-05 16:13:26 - train: epoch 0049, iter [02100, 05004], lr: 0.010000, loss: 1.4848
2022-07-05 16:14:00 - train: epoch 0049, iter [02200, 05004], lr: 0.010000, loss: 1.6451
2022-07-05 16:14:33 - train: epoch 0049, iter [02300, 05004], lr: 0.010000, loss: 1.6103
2022-07-05 16:15:07 - train: epoch 0049, iter [02400, 05004], lr: 0.010000, loss: 1.5908
2022-07-05 16:15:39 - train: epoch 0049, iter [02500, 05004], lr: 0.010000, loss: 1.7574
2022-07-05 16:16:12 - train: epoch 0049, iter [02600, 05004], lr: 0.010000, loss: 1.6969
2022-07-05 16:16:46 - train: epoch 0049, iter [02700, 05004], lr: 0.010000, loss: 1.5921
2022-07-05 16:17:19 - train: epoch 0049, iter [02800, 05004], lr: 0.010000, loss: 1.7638
2022-07-05 16:17:52 - train: epoch 0049, iter [02900, 05004], lr: 0.010000, loss: 1.6799
2022-07-05 16:18:25 - train: epoch 0049, iter [03000, 05004], lr: 0.010000, loss: 1.5623
2022-07-05 16:18:59 - train: epoch 0049, iter [03100, 05004], lr: 0.010000, loss: 1.6932
2022-07-05 16:19:33 - train: epoch 0049, iter [03200, 05004], lr: 0.010000, loss: 1.6871
2022-07-05 16:20:05 - train: epoch 0049, iter [03300, 05004], lr: 0.010000, loss: 1.5464
2022-07-05 16:20:39 - train: epoch 0049, iter [03400, 05004], lr: 0.010000, loss: 1.4639
2022-07-05 16:21:12 - train: epoch 0049, iter [03500, 05004], lr: 0.010000, loss: 1.6395
2022-07-05 16:21:45 - train: epoch 0049, iter [03600, 05004], lr: 0.010000, loss: 1.6865
2022-07-05 16:22:18 - train: epoch 0049, iter [03700, 05004], lr: 0.010000, loss: 1.5146
2022-07-05 16:22:52 - train: epoch 0049, iter [03800, 05004], lr: 0.010000, loss: 1.8169
2022-07-05 16:23:26 - train: epoch 0049, iter [03900, 05004], lr: 0.010000, loss: 1.7786
2022-07-05 16:23:59 - train: epoch 0049, iter [04000, 05004], lr: 0.010000, loss: 1.5788
2022-07-05 16:24:31 - train: epoch 0049, iter [04100, 05004], lr: 0.010000, loss: 1.5802
2022-07-05 16:25:04 - train: epoch 0049, iter [04200, 05004], lr: 0.010000, loss: 1.7354
2022-07-05 16:25:38 - train: epoch 0049, iter [04300, 05004], lr: 0.010000, loss: 1.8220
2022-07-05 16:26:11 - train: epoch 0049, iter [04400, 05004], lr: 0.010000, loss: 1.6584
2022-07-05 16:26:44 - train: epoch 0049, iter [04500, 05004], lr: 0.010000, loss: 1.5244
2022-07-05 16:27:17 - train: epoch 0049, iter [04600, 05004], lr: 0.010000, loss: 1.6000
2022-07-05 16:27:51 - train: epoch 0049, iter [04700, 05004], lr: 0.010000, loss: 1.6959
2022-07-05 16:28:25 - train: epoch 0049, iter [04800, 05004], lr: 0.010000, loss: 1.5033
2022-07-05 16:28:57 - train: epoch 0049, iter [04900, 05004], lr: 0.010000, loss: 1.6366
2022-07-05 16:29:29 - train: epoch 0049, iter [05000, 05004], lr: 0.010000, loss: 1.6189
2022-07-05 16:29:29 - train: epoch 049, train_loss: 1.6060
2022-07-05 16:30:42 - eval: epoch: 049, acc1: 65.312%, acc5: 86.446%, test_loss: 1.4287, per_image_load_time: 2.621ms, per_image_inference_time: 0.181ms
2022-07-05 16:30:42 - until epoch: 049, best_acc1: 65.788%
2022-07-05 16:30:42 - epoch 050 lr: 0.010000
2022-07-05 16:31:20 - train: epoch 0050, iter [00100, 05004], lr: 0.010000, loss: 1.6087
2022-07-05 16:31:52 - train: epoch 0050, iter [00200, 05004], lr: 0.010000, loss: 1.7157
2022-07-05 16:32:25 - train: epoch 0050, iter [00300, 05004], lr: 0.010000, loss: 1.6022
2022-07-05 16:32:57 - train: epoch 0050, iter [00400, 05004], lr: 0.010000, loss: 1.5658
2022-07-05 16:33:32 - train: epoch 0050, iter [00500, 05004], lr: 0.010000, loss: 1.4935
2022-07-05 16:34:03 - train: epoch 0050, iter [00600, 05004], lr: 0.010000, loss: 1.8228
2022-07-05 16:34:37 - train: epoch 0050, iter [00700, 05004], lr: 0.010000, loss: 1.4893
2022-07-05 16:35:10 - train: epoch 0050, iter [00800, 05004], lr: 0.010000, loss: 1.3262
2022-07-05 16:35:43 - train: epoch 0050, iter [00900, 05004], lr: 0.010000, loss: 1.5586
2022-07-05 16:36:15 - train: epoch 0050, iter [01000, 05004], lr: 0.010000, loss: 1.4974
2022-07-05 16:36:49 - train: epoch 0050, iter [01100, 05004], lr: 0.010000, loss: 1.6719
2022-07-05 16:37:21 - train: epoch 0050, iter [01200, 05004], lr: 0.010000, loss: 1.4478
2022-07-05 16:37:54 - train: epoch 0050, iter [01300, 05004], lr: 0.010000, loss: 1.4732
2022-07-05 16:38:27 - train: epoch 0050, iter [01400, 05004], lr: 0.010000, loss: 1.6612
2022-07-05 16:39:01 - train: epoch 0050, iter [01500, 05004], lr: 0.010000, loss: 1.6182
2022-07-05 16:39:34 - train: epoch 0050, iter [01600, 05004], lr: 0.010000, loss: 1.7000
2022-07-05 16:40:07 - train: epoch 0050, iter [01700, 05004], lr: 0.010000, loss: 1.7325
2022-07-05 16:40:39 - train: epoch 0050, iter [01800, 05004], lr: 0.010000, loss: 1.6857
2022-07-05 16:41:13 - train: epoch 0050, iter [01900, 05004], lr: 0.010000, loss: 1.6970
2022-07-05 16:41:46 - train: epoch 0050, iter [02000, 05004], lr: 0.010000, loss: 1.6255
2022-07-05 16:42:19 - train: epoch 0050, iter [02100, 05004], lr: 0.010000, loss: 1.5308
2022-07-05 16:42:52 - train: epoch 0050, iter [02200, 05004], lr: 0.010000, loss: 1.6093
2022-07-05 16:43:25 - train: epoch 0050, iter [02300, 05004], lr: 0.010000, loss: 1.4287
2022-07-05 16:43:58 - train: epoch 0050, iter [02400, 05004], lr: 0.010000, loss: 1.6391
2022-07-05 16:44:31 - train: epoch 0050, iter [02500, 05004], lr: 0.010000, loss: 1.6669
2022-07-05 16:45:04 - train: epoch 0050, iter [02600, 05004], lr: 0.010000, loss: 1.4390
2022-07-05 16:45:37 - train: epoch 0050, iter [02700, 05004], lr: 0.010000, loss: 1.6438
2022-07-05 16:46:10 - train: epoch 0050, iter [02800, 05004], lr: 0.010000, loss: 1.5464
2022-07-05 16:46:42 - train: epoch 0050, iter [02900, 05004], lr: 0.010000, loss: 1.7683
2022-07-05 16:47:16 - train: epoch 0050, iter [03000, 05004], lr: 0.010000, loss: 1.6095
2022-07-05 16:47:50 - train: epoch 0050, iter [03100, 05004], lr: 0.010000, loss: 1.7355
2022-07-05 16:48:22 - train: epoch 0050, iter [03200, 05004], lr: 0.010000, loss: 1.6200
2022-07-05 16:48:56 - train: epoch 0050, iter [03300, 05004], lr: 0.010000, loss: 1.4879
2022-07-05 16:49:28 - train: epoch 0050, iter [03400, 05004], lr: 0.010000, loss: 1.5750
2022-07-05 16:50:02 - train: epoch 0050, iter [03500, 05004], lr: 0.010000, loss: 1.6694
2022-07-05 16:50:35 - train: epoch 0050, iter [03600, 05004], lr: 0.010000, loss: 1.4748
2022-07-05 16:51:09 - train: epoch 0050, iter [03700, 05004], lr: 0.010000, loss: 2.0018
2022-07-05 16:51:41 - train: epoch 0050, iter [03800, 05004], lr: 0.010000, loss: 1.4694
2022-07-05 16:52:15 - train: epoch 0050, iter [03900, 05004], lr: 0.010000, loss: 1.5843
2022-07-05 16:52:47 - train: epoch 0050, iter [04000, 05004], lr: 0.010000, loss: 1.6173
2022-07-05 16:53:21 - train: epoch 0050, iter [04100, 05004], lr: 0.010000, loss: 1.6257
2022-07-05 16:53:53 - train: epoch 0050, iter [04200, 05004], lr: 0.010000, loss: 1.6683
2022-07-05 16:54:27 - train: epoch 0050, iter [04300, 05004], lr: 0.010000, loss: 1.7781
2022-07-05 16:55:00 - train: epoch 0050, iter [04400, 05004], lr: 0.010000, loss: 1.7782
2022-07-05 16:55:34 - train: epoch 0050, iter [04500, 05004], lr: 0.010000, loss: 1.4211
2022-07-05 16:56:07 - train: epoch 0050, iter [04600, 05004], lr: 0.010000, loss: 1.6562
2022-07-05 16:56:40 - train: epoch 0050, iter [04700, 05004], lr: 0.010000, loss: 1.7276
2022-07-05 16:57:12 - train: epoch 0050, iter [04800, 05004], lr: 0.010000, loss: 1.6089
2022-07-05 16:57:45 - train: epoch 0050, iter [04900, 05004], lr: 0.010000, loss: 1.5801
2022-07-05 16:58:18 - train: epoch 0050, iter [05000, 05004], lr: 0.010000, loss: 1.4860
2022-07-05 16:58:18 - train: epoch 050, train_loss: 1.6056
2022-07-05 16:59:31 - eval: epoch: 050, acc1: 65.248%, acc5: 86.656%, test_loss: 1.4321, per_image_load_time: 2.469ms, per_image_inference_time: 0.163ms
2022-07-05 16:59:31 - until epoch: 050, best_acc1: 65.788%
2022-07-05 16:59:31 - epoch 051 lr: 0.010000
2022-07-05 17:00:09 - train: epoch 0051, iter [00100, 05004], lr: 0.010000, loss: 1.6284
2022-07-05 17:00:42 - train: epoch 0051, iter [00200, 05004], lr: 0.010000, loss: 1.7575
2022-07-05 17:01:15 - train: epoch 0051, iter [00300, 05004], lr: 0.010000, loss: 1.6458
2022-07-05 17:01:48 - train: epoch 0051, iter [00400, 05004], lr: 0.010000, loss: 1.4133
2022-07-05 17:02:22 - train: epoch 0051, iter [00500, 05004], lr: 0.010000, loss: 1.6708
2022-07-05 17:02:54 - train: epoch 0051, iter [00600, 05004], lr: 0.010000, loss: 1.3947
2022-07-05 17:03:27 - train: epoch 0051, iter [00700, 05004], lr: 0.010000, loss: 1.4805
2022-07-05 17:04:00 - train: epoch 0051, iter [00800, 05004], lr: 0.010000, loss: 1.8006
2022-07-05 17:04:34 - train: epoch 0051, iter [00900, 05004], lr: 0.010000, loss: 1.5173
2022-07-05 17:05:06 - train: epoch 0051, iter [01000, 05004], lr: 0.010000, loss: 1.9188
2022-07-05 17:05:38 - train: epoch 0051, iter [01100, 05004], lr: 0.010000, loss: 1.7156
2022-07-05 17:06:12 - train: epoch 0051, iter [01200, 05004], lr: 0.010000, loss: 1.6090
2022-07-05 17:06:45 - train: epoch 0051, iter [01300, 05004], lr: 0.010000, loss: 1.4140
2022-07-05 17:07:18 - train: epoch 0051, iter [01400, 05004], lr: 0.010000, loss: 1.5896
2022-07-05 17:07:52 - train: epoch 0051, iter [01500, 05004], lr: 0.010000, loss: 1.6025
2022-07-05 17:08:24 - train: epoch 0051, iter [01600, 05004], lr: 0.010000, loss: 1.3365
2022-07-05 17:08:58 - train: epoch 0051, iter [01700, 05004], lr: 0.010000, loss: 1.5037
2022-07-05 17:09:31 - train: epoch 0051, iter [01800, 05004], lr: 0.010000, loss: 1.5520
2022-07-05 17:10:02 - train: epoch 0051, iter [01900, 05004], lr: 0.010000, loss: 1.5554
2022-07-05 17:10:36 - train: epoch 0051, iter [02000, 05004], lr: 0.010000, loss: 1.6684
2022-07-05 17:11:09 - train: epoch 0051, iter [02100, 05004], lr: 0.010000, loss: 1.6279
2022-07-05 17:11:42 - train: epoch 0051, iter [02200, 05004], lr: 0.010000, loss: 1.5325
2022-07-05 17:12:16 - train: epoch 0051, iter [02300, 05004], lr: 0.010000, loss: 1.6645
2022-07-05 17:12:48 - train: epoch 0051, iter [02400, 05004], lr: 0.010000, loss: 1.8067
2022-07-05 17:13:22 - train: epoch 0051, iter [02500, 05004], lr: 0.010000, loss: 1.5484
2022-07-05 17:13:55 - train: epoch 0051, iter [02600, 05004], lr: 0.010000, loss: 1.6005
2022-07-05 17:14:29 - train: epoch 0051, iter [02700, 05004], lr: 0.010000, loss: 1.4586
2022-07-05 17:15:02 - train: epoch 0051, iter [02800, 05004], lr: 0.010000, loss: 1.5352
2022-07-05 17:15:36 - train: epoch 0051, iter [02900, 05004], lr: 0.010000, loss: 1.5945
2022-07-05 17:16:08 - train: epoch 0051, iter [03000, 05004], lr: 0.010000, loss: 1.6966
2022-07-05 17:16:41 - train: epoch 0051, iter [03100, 05004], lr: 0.010000, loss: 1.4729
2022-07-05 17:17:13 - train: epoch 0051, iter [03200, 05004], lr: 0.010000, loss: 1.6254
2022-07-05 17:17:47 - train: epoch 0051, iter [03300, 05004], lr: 0.010000, loss: 1.5665
2022-07-05 17:18:20 - train: epoch 0051, iter [03400, 05004], lr: 0.010000, loss: 1.7060
2022-07-05 17:18:53 - train: epoch 0051, iter [03500, 05004], lr: 0.010000, loss: 1.6294
2022-07-05 17:19:26 - train: epoch 0051, iter [03600, 05004], lr: 0.010000, loss: 1.5274
2022-07-05 17:20:00 - train: epoch 0051, iter [03700, 05004], lr: 0.010000, loss: 1.6759
2022-07-05 17:20:33 - train: epoch 0051, iter [03800, 05004], lr: 0.010000, loss: 1.5961
2022-07-05 17:21:06 - train: epoch 0051, iter [03900, 05004], lr: 0.010000, loss: 1.7577
2022-07-05 17:21:39 - train: epoch 0051, iter [04000, 05004], lr: 0.010000, loss: 1.6885
2022-07-05 17:22:14 - train: epoch 0051, iter [04100, 05004], lr: 0.010000, loss: 1.6535
2022-07-05 17:22:46 - train: epoch 0051, iter [04200, 05004], lr: 0.010000, loss: 1.7450
2022-07-05 17:23:19 - train: epoch 0051, iter [04300, 05004], lr: 0.010000, loss: 1.5823
2022-07-05 17:23:51 - train: epoch 0051, iter [04400, 05004], lr: 0.010000, loss: 1.7091
2022-07-05 17:24:25 - train: epoch 0051, iter [04500, 05004], lr: 0.010000, loss: 1.3728
2022-07-05 17:24:58 - train: epoch 0051, iter [04600, 05004], lr: 0.010000, loss: 1.7694
2022-07-05 17:25:32 - train: epoch 0051, iter [04700, 05004], lr: 0.010000, loss: 1.6436
2022-07-05 17:26:04 - train: epoch 0051, iter [04800, 05004], lr: 0.010000, loss: 1.6690
2022-07-05 17:26:38 - train: epoch 0051, iter [04900, 05004], lr: 0.010000, loss: 1.7564
2022-07-05 17:27:09 - train: epoch 0051, iter [05000, 05004], lr: 0.010000, loss: 1.6611
2022-07-05 17:27:10 - train: epoch 051, train_loss: 1.6029
2022-07-05 17:28:23 - eval: epoch: 051, acc1: 65.424%, acc5: 86.764%, test_loss: 1.4189, per_image_load_time: 2.337ms, per_image_inference_time: 0.174ms
2022-07-05 17:28:23 - until epoch: 051, best_acc1: 65.788%
2022-07-05 17:28:23 - epoch 052 lr: 0.010000
2022-07-05 17:29:01 - train: epoch 0052, iter [00100, 05004], lr: 0.010000, loss: 1.6694
2022-07-05 17:29:34 - train: epoch 0052, iter [00200, 05004], lr: 0.010000, loss: 1.4773
2022-07-05 17:30:06 - train: epoch 0052, iter [00300, 05004], lr: 0.010000, loss: 1.5012
2022-07-05 17:30:38 - train: epoch 0052, iter [00400, 05004], lr: 0.010000, loss: 1.6669
2022-07-05 17:31:12 - train: epoch 0052, iter [00500, 05004], lr: 0.010000, loss: 1.6970
2022-07-05 17:31:45 - train: epoch 0052, iter [00600, 05004], lr: 0.010000, loss: 1.5911
2022-07-05 17:32:18 - train: epoch 0052, iter [00700, 05004], lr: 0.010000, loss: 1.7610
2022-07-05 17:32:50 - train: epoch 0052, iter [00800, 05004], lr: 0.010000, loss: 1.5399
2022-07-05 17:33:24 - train: epoch 0052, iter [00900, 05004], lr: 0.010000, loss: 1.7707
2022-07-05 17:33:57 - train: epoch 0052, iter [01000, 05004], lr: 0.010000, loss: 1.7452
2022-07-05 17:34:30 - train: epoch 0052, iter [01100, 05004], lr: 0.010000, loss: 1.7124
2022-07-05 17:35:05 - train: epoch 0052, iter [01200, 05004], lr: 0.010000, loss: 1.5122
2022-07-05 17:35:36 - train: epoch 0052, iter [01300, 05004], lr: 0.010000, loss: 1.4590
2022-07-05 17:36:09 - train: epoch 0052, iter [01400, 05004], lr: 0.010000, loss: 1.8071
2022-07-05 17:36:42 - train: epoch 0052, iter [01500, 05004], lr: 0.010000, loss: 1.5825
2022-07-05 17:37:15 - train: epoch 0052, iter [01600, 05004], lr: 0.010000, loss: 1.4625
2022-07-05 17:37:48 - train: epoch 0052, iter [01700, 05004], lr: 0.010000, loss: 1.4364
2022-07-05 17:38:21 - train: epoch 0052, iter [01800, 05004], lr: 0.010000, loss: 1.6232
2022-07-05 17:38:54 - train: epoch 0052, iter [01900, 05004], lr: 0.010000, loss: 1.3586
2022-07-05 17:39:27 - train: epoch 0052, iter [02000, 05004], lr: 0.010000, loss: 1.8612
2022-07-05 17:40:01 - train: epoch 0052, iter [02100, 05004], lr: 0.010000, loss: 1.5330
2022-07-05 17:40:33 - train: epoch 0052, iter [02200, 05004], lr: 0.010000, loss: 1.7724
2022-07-05 17:41:07 - train: epoch 0052, iter [02300, 05004], lr: 0.010000, loss: 1.5314
2022-07-05 17:41:40 - train: epoch 0052, iter [02400, 05004], lr: 0.010000, loss: 1.3111
2022-07-05 17:42:13 - train: epoch 0052, iter [02500, 05004], lr: 0.010000, loss: 1.4563
2022-07-05 17:42:47 - train: epoch 0052, iter [02600, 05004], lr: 0.010000, loss: 1.3017
2022-07-05 17:43:19 - train: epoch 0052, iter [02700, 05004], lr: 0.010000, loss: 1.5527
2022-07-05 17:43:52 - train: epoch 0052, iter [02800, 05004], lr: 0.010000, loss: 1.9664
2022-07-05 17:44:27 - train: epoch 0052, iter [02900, 05004], lr: 0.010000, loss: 1.4596
2022-07-05 17:44:58 - train: epoch 0052, iter [03000, 05004], lr: 0.010000, loss: 1.4237
2022-07-05 17:45:32 - train: epoch 0052, iter [03100, 05004], lr: 0.010000, loss: 1.7078
2022-07-05 17:46:06 - train: epoch 0052, iter [03200, 05004], lr: 0.010000, loss: 1.6440
2022-07-05 17:46:40 - train: epoch 0052, iter [03300, 05004], lr: 0.010000, loss: 1.6004
2022-07-05 17:47:12 - train: epoch 0052, iter [03400, 05004], lr: 0.010000, loss: 1.6474
2022-07-05 17:47:45 - train: epoch 0052, iter [03500, 05004], lr: 0.010000, loss: 1.7065
2022-07-05 17:48:18 - train: epoch 0052, iter [03600, 05004], lr: 0.010000, loss: 1.6775
2022-07-05 17:48:52 - train: epoch 0052, iter [03700, 05004], lr: 0.010000, loss: 1.6724
2022-07-05 17:49:25 - train: epoch 0052, iter [03800, 05004], lr: 0.010000, loss: 1.5972
2022-07-05 17:49:58 - train: epoch 0052, iter [03900, 05004], lr: 0.010000, loss: 1.3639
2022-07-05 17:50:31 - train: epoch 0052, iter [04000, 05004], lr: 0.010000, loss: 1.8129
2022-07-05 17:51:05 - train: epoch 0052, iter [04100, 05004], lr: 0.010000, loss: 1.2840
2022-07-05 17:51:39 - train: epoch 0052, iter [04200, 05004], lr: 0.010000, loss: 1.7483
2022-07-05 17:52:11 - train: epoch 0052, iter [04300, 05004], lr: 0.010000, loss: 1.4811
2022-07-05 17:52:46 - train: epoch 0052, iter [04400, 05004], lr: 0.010000, loss: 1.6066
2022-07-05 17:53:18 - train: epoch 0052, iter [04500, 05004], lr: 0.010000, loss: 1.6219
2022-07-05 17:53:51 - train: epoch 0052, iter [04600, 05004], lr: 0.010000, loss: 1.6494
2022-07-05 17:54:24 - train: epoch 0052, iter [04700, 05004], lr: 0.010000, loss: 1.7330
2022-07-05 17:54:57 - train: epoch 0052, iter [04800, 05004], lr: 0.010000, loss: 1.4200
2022-07-05 17:55:30 - train: epoch 0052, iter [04900, 05004], lr: 0.010000, loss: 1.4947
2022-07-05 17:56:02 - train: epoch 0052, iter [05000, 05004], lr: 0.010000, loss: 1.6375
2022-07-05 17:56:02 - train: epoch 052, train_loss: 1.6016
2022-07-05 17:57:16 - eval: epoch: 052, acc1: 64.898%, acc5: 86.376%, test_loss: 1.4546, per_image_load_time: 2.674ms, per_image_inference_time: 0.175ms
2022-07-05 17:57:16 - until epoch: 052, best_acc1: 65.788%
2022-07-05 17:57:16 - epoch 053 lr: 0.010000
2022-07-05 17:57:53 - train: epoch 0053, iter [00100, 05004], lr: 0.010000, loss: 1.7776
2022-07-05 17:58:27 - train: epoch 0053, iter [00200, 05004], lr: 0.010000, loss: 1.6275
2022-07-05 17:58:58 - train: epoch 0053, iter [00300, 05004], lr: 0.010000, loss: 1.6086
2022-07-05 17:59:32 - train: epoch 0053, iter [00400, 05004], lr: 0.010000, loss: 1.6476
2022-07-05 18:00:04 - train: epoch 0053, iter [00500, 05004], lr: 0.010000, loss: 1.6303
2022-07-05 18:00:37 - train: epoch 0053, iter [00600, 05004], lr: 0.010000, loss: 1.4660
2022-07-05 18:01:09 - train: epoch 0053, iter [00700, 05004], lr: 0.010000, loss: 1.5577
2022-07-05 18:01:42 - train: epoch 0053, iter [00800, 05004], lr: 0.010000, loss: 1.5860
2022-07-05 18:02:15 - train: epoch 0053, iter [00900, 05004], lr: 0.010000, loss: 1.6194
2022-07-05 18:02:49 - train: epoch 0053, iter [01000, 05004], lr: 0.010000, loss: 1.3926
2022-07-05 18:03:21 - train: epoch 0053, iter [01100, 05004], lr: 0.010000, loss: 1.6956
2022-07-05 18:03:55 - train: epoch 0053, iter [01200, 05004], lr: 0.010000, loss: 1.4457
2022-07-05 18:04:26 - train: epoch 0053, iter [01300, 05004], lr: 0.010000, loss: 1.5206
2022-07-05 18:05:00 - train: epoch 0053, iter [01400, 05004], lr: 0.010000, loss: 1.7648
2022-07-05 18:05:32 - train: epoch 0053, iter [01500, 05004], lr: 0.010000, loss: 1.5806
2022-07-05 18:06:05 - train: epoch 0053, iter [01600, 05004], lr: 0.010000, loss: 1.7813
2022-07-05 18:06:38 - train: epoch 0053, iter [01700, 05004], lr: 0.010000, loss: 1.5915
2022-07-05 18:07:11 - train: epoch 0053, iter [01800, 05004], lr: 0.010000, loss: 1.6518
2022-07-05 18:07:46 - train: epoch 0053, iter [01900, 05004], lr: 0.010000, loss: 1.6456
2022-07-05 18:08:18 - train: epoch 0053, iter [02000, 05004], lr: 0.010000, loss: 1.6189
2022-07-05 18:08:51 - train: epoch 0053, iter [02100, 05004], lr: 0.010000, loss: 1.7248
2022-07-05 18:09:24 - train: epoch 0053, iter [02200, 05004], lr: 0.010000, loss: 1.4908
2022-07-05 18:09:57 - train: epoch 0053, iter [02300, 05004], lr: 0.010000, loss: 1.5547
2022-07-05 18:10:31 - train: epoch 0053, iter [02400, 05004], lr: 0.010000, loss: 1.4231
2022-07-05 18:11:04 - train: epoch 0053, iter [02500, 05004], lr: 0.010000, loss: 1.6872
2022-07-05 18:11:38 - train: epoch 0053, iter [02600, 05004], lr: 0.010000, loss: 1.6990
2022-07-05 18:12:10 - train: epoch 0053, iter [02700, 05004], lr: 0.010000, loss: 1.6522
2022-07-05 18:12:43 - train: epoch 0053, iter [02800, 05004], lr: 0.010000, loss: 1.6302
2022-07-05 18:13:16 - train: epoch 0053, iter [02900, 05004], lr: 0.010000, loss: 1.5258
2022-07-05 18:13:50 - train: epoch 0053, iter [03000, 05004], lr: 0.010000, loss: 1.5935
2022-07-05 18:14:23 - train: epoch 0053, iter [03100, 05004], lr: 0.010000, loss: 1.9036
2022-07-05 18:14:57 - train: epoch 0053, iter [03200, 05004], lr: 0.010000, loss: 1.5851
2022-07-05 18:15:29 - train: epoch 0053, iter [03300, 05004], lr: 0.010000, loss: 1.5896
2022-07-05 18:16:03 - train: epoch 0053, iter [03400, 05004], lr: 0.010000, loss: 1.5070
2022-07-05 18:16:36 - train: epoch 0053, iter [03500, 05004], lr: 0.010000, loss: 1.6641
2022-07-05 18:17:09 - train: epoch 0053, iter [03600, 05004], lr: 0.010000, loss: 1.7459
2022-07-05 18:17:43 - train: epoch 0053, iter [03700, 05004], lr: 0.010000, loss: 1.7062
2022-07-05 18:18:16 - train: epoch 0053, iter [03800, 05004], lr: 0.010000, loss: 1.4681
2022-07-05 18:18:49 - train: epoch 0053, iter [03900, 05004], lr: 0.010000, loss: 1.9996
2022-07-05 18:19:22 - train: epoch 0053, iter [04000, 05004], lr: 0.010000, loss: 1.6126
2022-07-05 18:19:55 - train: epoch 0053, iter [04100, 05004], lr: 0.010000, loss: 1.6815
2022-07-05 18:20:29 - train: epoch 0053, iter [04200, 05004], lr: 0.010000, loss: 1.7596
2022-07-05 18:21:01 - train: epoch 0053, iter [04300, 05004], lr: 0.010000, loss: 1.7066
2022-07-05 18:21:35 - train: epoch 0053, iter [04400, 05004], lr: 0.010000, loss: 1.6452
2022-07-05 18:22:08 - train: epoch 0053, iter [04500, 05004], lr: 0.010000, loss: 1.6508
2022-07-05 18:22:42 - train: epoch 0053, iter [04600, 05004], lr: 0.010000, loss: 1.4135
2022-07-05 18:23:14 - train: epoch 0053, iter [04700, 05004], lr: 0.010000, loss: 1.7982
2022-07-05 18:23:47 - train: epoch 0053, iter [04800, 05004], lr: 0.010000, loss: 1.6291
2022-07-05 18:24:21 - train: epoch 0053, iter [04900, 05004], lr: 0.010000, loss: 1.6446
2022-07-05 18:24:52 - train: epoch 0053, iter [05000, 05004], lr: 0.010000, loss: 1.3738
2022-07-05 18:24:53 - train: epoch 053, train_loss: 1.5983
2022-07-05 18:26:06 - eval: epoch: 053, acc1: 65.260%, acc5: 86.778%, test_loss: 1.4217, per_image_load_time: 2.463ms, per_image_inference_time: 0.185ms
2022-07-05 18:26:06 - until epoch: 053, best_acc1: 65.788%
2022-07-05 18:26:06 - epoch 054 lr: 0.010000
2022-07-05 18:26:45 - train: epoch 0054, iter [00100, 05004], lr: 0.010000, loss: 1.4986
2022-07-05 18:27:18 - train: epoch 0054, iter [00200, 05004], lr: 0.010000, loss: 1.7228
2022-07-05 18:27:51 - train: epoch 0054, iter [00300, 05004], lr: 0.010000, loss: 1.4469
2022-07-05 18:28:24 - train: epoch 0054, iter [00400, 05004], lr: 0.010000, loss: 1.6317
2022-07-05 18:28:57 - train: epoch 0054, iter [00500, 05004], lr: 0.010000, loss: 1.5080
2022-07-05 18:29:29 - train: epoch 0054, iter [00600, 05004], lr: 0.010000, loss: 1.5633
2022-07-05 18:30:02 - train: epoch 0054, iter [00700, 05004], lr: 0.010000, loss: 1.6933
2022-07-05 18:30:35 - train: epoch 0054, iter [00800, 05004], lr: 0.010000, loss: 1.8103
2022-07-05 18:31:09 - train: epoch 0054, iter [00900, 05004], lr: 0.010000, loss: 1.3143
2022-07-05 18:31:40 - train: epoch 0054, iter [01000, 05004], lr: 0.010000, loss: 1.2403
2022-07-05 18:32:14 - train: epoch 0054, iter [01100, 05004], lr: 0.010000, loss: 1.3286
2022-07-05 18:32:47 - train: epoch 0054, iter [01200, 05004], lr: 0.010000, loss: 1.5789
2022-07-05 18:33:21 - train: epoch 0054, iter [01300, 05004], lr: 0.010000, loss: 1.5494
2022-07-05 18:33:53 - train: epoch 0054, iter [01400, 05004], lr: 0.010000, loss: 1.6337
2022-07-05 18:34:27 - train: epoch 0054, iter [01500, 05004], lr: 0.010000, loss: 1.4650
2022-07-05 18:35:00 - train: epoch 0054, iter [01600, 05004], lr: 0.010000, loss: 1.4325
2022-07-05 18:35:32 - train: epoch 0054, iter [01700, 05004], lr: 0.010000, loss: 1.4248
2022-07-05 18:36:05 - train: epoch 0054, iter [01800, 05004], lr: 0.010000, loss: 1.5288
2022-07-05 18:36:39 - train: epoch 0054, iter [01900, 05004], lr: 0.010000, loss: 1.7705
2022-07-05 18:37:11 - train: epoch 0054, iter [02000, 05004], lr: 0.010000, loss: 1.8929
2022-07-05 18:37:44 - train: epoch 0054, iter [02100, 05004], lr: 0.010000, loss: 1.6497
2022-07-05 18:38:18 - train: epoch 0054, iter [02200, 05004], lr: 0.010000, loss: 1.3416
2022-07-05 18:38:51 - train: epoch 0054, iter [02300, 05004], lr: 0.010000, loss: 1.3168
2022-07-05 18:39:24 - train: epoch 0054, iter [02400, 05004], lr: 0.010000, loss: 1.7083
2022-07-05 18:39:57 - train: epoch 0054, iter [02500, 05004], lr: 0.010000, loss: 1.5430
2022-07-05 18:40:30 - train: epoch 0054, iter [02600, 05004], lr: 0.010000, loss: 1.3741
2022-07-05 18:41:03 - train: epoch 0054, iter [02700, 05004], lr: 0.010000, loss: 1.5414
2022-07-05 18:41:37 - train: epoch 0054, iter [02800, 05004], lr: 0.010000, loss: 1.7169
2022-07-05 18:42:10 - train: epoch 0054, iter [02900, 05004], lr: 0.010000, loss: 1.5049
2022-07-05 18:42:43 - train: epoch 0054, iter [03000, 05004], lr: 0.010000, loss: 1.8175
2022-07-05 18:43:16 - train: epoch 0054, iter [03100, 05004], lr: 0.010000, loss: 1.7964
2022-07-05 18:43:49 - train: epoch 0054, iter [03200, 05004], lr: 0.010000, loss: 1.6935
2022-07-05 18:44:22 - train: epoch 0054, iter [03300, 05004], lr: 0.010000, loss: 1.5609
2022-07-05 18:44:56 - train: epoch 0054, iter [03400, 05004], lr: 0.010000, loss: 1.6808
2022-07-05 18:45:28 - train: epoch 0054, iter [03500, 05004], lr: 0.010000, loss: 1.6662
2022-07-05 18:46:01 - train: epoch 0054, iter [03600, 05004], lr: 0.010000, loss: 1.6410
2022-07-05 18:46:34 - train: epoch 0054, iter [03700, 05004], lr: 0.010000, loss: 1.5467
2022-07-05 18:47:07 - train: epoch 0054, iter [03800, 05004], lr: 0.010000, loss: 1.4936
2022-07-05 18:47:41 - train: epoch 0054, iter [03900, 05004], lr: 0.010000, loss: 1.5716
2022-07-05 18:48:14 - train: epoch 0054, iter [04000, 05004], lr: 0.010000, loss: 1.3999
2022-07-05 18:48:47 - train: epoch 0054, iter [04100, 05004], lr: 0.010000, loss: 1.6924
2022-07-05 18:49:20 - train: epoch 0054, iter [04200, 05004], lr: 0.010000, loss: 1.5291
2022-07-05 18:49:53 - train: epoch 0054, iter [04300, 05004], lr: 0.010000, loss: 1.7693
2022-07-05 18:50:27 - train: epoch 0054, iter [04400, 05004], lr: 0.010000, loss: 1.5346
2022-07-05 18:50:59 - train: epoch 0054, iter [04500, 05004], lr: 0.010000, loss: 1.6041
2022-07-05 18:51:32 - train: epoch 0054, iter [04600, 05004], lr: 0.010000, loss: 1.6581
2022-07-05 18:52:06 - train: epoch 0054, iter [04700, 05004], lr: 0.010000, loss: 1.7239
2022-07-05 18:52:39 - train: epoch 0054, iter [04800, 05004], lr: 0.010000, loss: 1.6351
2022-07-05 18:53:12 - train: epoch 0054, iter [04900, 05004], lr: 0.010000, loss: 1.3380
2022-07-05 18:53:44 - train: epoch 0054, iter [05000, 05004], lr: 0.010000, loss: 1.7875
2022-07-05 18:53:45 - train: epoch 054, train_loss: 1.5972
2022-07-05 18:54:58 - eval: epoch: 054, acc1: 65.120%, acc5: 86.682%, test_loss: 1.4357, per_image_load_time: 2.535ms, per_image_inference_time: 0.178ms
2022-07-05 18:54:58 - until epoch: 054, best_acc1: 65.788%
2022-07-05 18:54:58 - epoch 055 lr: 0.010000
2022-07-05 18:55:36 - train: epoch 0055, iter [00100, 05004], lr: 0.010000, loss: 1.4714
2022-07-05 18:56:08 - train: epoch 0055, iter [00200, 05004], lr: 0.010000, loss: 1.6684
2022-07-05 18:56:41 - train: epoch 0055, iter [00300, 05004], lr: 0.010000, loss: 1.4884
2022-07-05 18:57:13 - train: epoch 0055, iter [00400, 05004], lr: 0.010000, loss: 1.4409
2022-07-05 18:57:46 - train: epoch 0055, iter [00500, 05004], lr: 0.010000, loss: 1.3931
2022-07-05 18:58:18 - train: epoch 0055, iter [00600, 05004], lr: 0.010000, loss: 1.5630
2022-07-05 18:58:52 - train: epoch 0055, iter [00700, 05004], lr: 0.010000, loss: 1.6156
2022-07-05 18:59:24 - train: epoch 0055, iter [00800, 05004], lr: 0.010000, loss: 1.4379
2022-07-05 18:59:58 - train: epoch 0055, iter [00900, 05004], lr: 0.010000, loss: 1.5800
2022-07-05 19:00:31 - train: epoch 0055, iter [01000, 05004], lr: 0.010000, loss: 1.6338
2022-07-05 19:01:05 - train: epoch 0055, iter [01100, 05004], lr: 0.010000, loss: 1.6414
2022-07-05 19:01:37 - train: epoch 0055, iter [01200, 05004], lr: 0.010000, loss: 1.6112
2022-07-05 19:02:11 - train: epoch 0055, iter [01300, 05004], lr: 0.010000, loss: 1.5918
2022-07-05 19:02:43 - train: epoch 0055, iter [01400, 05004], lr: 0.010000, loss: 1.5962
2022-07-05 19:03:16 - train: epoch 0055, iter [01500, 05004], lr: 0.010000, loss: 1.4338
2022-07-05 19:03:49 - train: epoch 0055, iter [01600, 05004], lr: 0.010000, loss: 1.7889
2022-07-05 19:04:23 - train: epoch 0055, iter [01700, 05004], lr: 0.010000, loss: 1.6887
2022-07-05 19:04:55 - train: epoch 0055, iter [01800, 05004], lr: 0.010000, loss: 1.5952
2022-07-05 19:05:29 - train: epoch 0055, iter [01900, 05004], lr: 0.010000, loss: 1.7106
2022-07-05 19:06:02 - train: epoch 0055, iter [02000, 05004], lr: 0.010000, loss: 1.6811
2022-07-05 19:06:35 - train: epoch 0055, iter [02100, 05004], lr: 0.010000, loss: 1.3709
2022-07-05 19:07:08 - train: epoch 0055, iter [02200, 05004], lr: 0.010000, loss: 1.5284
2022-07-05 19:07:42 - train: epoch 0055, iter [02300, 05004], lr: 0.010000, loss: 1.5849
2022-07-05 19:08:15 - train: epoch 0055, iter [02400, 05004], lr: 0.010000, loss: 1.3899
2022-07-05 19:08:49 - train: epoch 0055, iter [02500, 05004], lr: 0.010000, loss: 1.5327
2022-07-05 19:09:21 - train: epoch 0055, iter [02600, 05004], lr: 0.010000, loss: 1.4107
2022-07-05 19:09:55 - train: epoch 0055, iter [02700, 05004], lr: 0.010000, loss: 1.4320
2022-07-05 19:10:27 - train: epoch 0055, iter [02800, 05004], lr: 0.010000, loss: 1.7503
2022-07-05 19:11:01 - train: epoch 0055, iter [02900, 05004], lr: 0.010000, loss: 1.6288
2022-07-05 19:11:33 - train: epoch 0055, iter [03000, 05004], lr: 0.010000, loss: 1.6809
2022-07-05 19:12:07 - train: epoch 0055, iter [03100, 05004], lr: 0.010000, loss: 1.4662
2022-07-05 19:12:40 - train: epoch 0055, iter [03200, 05004], lr: 0.010000, loss: 1.5638
2022-07-05 19:13:14 - train: epoch 0055, iter [03300, 05004], lr: 0.010000, loss: 1.4848
2022-07-05 19:13:46 - train: epoch 0055, iter [03400, 05004], lr: 0.010000, loss: 1.4506
2022-07-05 19:14:21 - train: epoch 0055, iter [03500, 05004], lr: 0.010000, loss: 1.4711
2022-07-05 19:14:53 - train: epoch 0055, iter [03600, 05004], lr: 0.010000, loss: 1.5727
2022-07-05 19:15:27 - train: epoch 0055, iter [03700, 05004], lr: 0.010000, loss: 1.5506
2022-07-05 19:16:00 - train: epoch 0055, iter [03800, 05004], lr: 0.010000, loss: 1.5632
2022-07-05 19:16:34 - train: epoch 0055, iter [03900, 05004], lr: 0.010000, loss: 1.8512
2022-07-05 19:17:06 - train: epoch 0055, iter [04000, 05004], lr: 0.010000, loss: 1.6227
2022-07-05 19:17:40 - train: epoch 0055, iter [04100, 05004], lr: 0.010000, loss: 1.5618
2022-07-05 19:18:12 - train: epoch 0055, iter [04200, 05004], lr: 0.010000, loss: 1.5659
2022-07-05 19:18:46 - train: epoch 0055, iter [04300, 05004], lr: 0.010000, loss: 1.7864
2022-07-05 19:19:19 - train: epoch 0055, iter [04400, 05004], lr: 0.010000, loss: 1.6659
2022-07-05 19:19:52 - train: epoch 0055, iter [04500, 05004], lr: 0.010000, loss: 1.6964
2022-07-05 19:20:24 - train: epoch 0055, iter [04600, 05004], lr: 0.010000, loss: 1.6152
2022-07-05 19:20:59 - train: epoch 0055, iter [04700, 05004], lr: 0.010000, loss: 1.4864
2022-07-05 19:21:32 - train: epoch 0055, iter [04800, 05004], lr: 0.010000, loss: 1.6554
2022-07-05 19:22:06 - train: epoch 0055, iter [04900, 05004], lr: 0.010000, loss: 1.5352
2022-07-05 19:22:37 - train: epoch 0055, iter [05000, 05004], lr: 0.010000, loss: 1.7719
2022-07-05 19:22:38 - train: epoch 055, train_loss: 1.5950
2022-07-05 19:23:50 - eval: epoch: 055, acc1: 64.944%, acc5: 86.396%, test_loss: 1.4428, per_image_load_time: 2.606ms, per_image_inference_time: 0.192ms
2022-07-05 19:23:51 - until epoch: 055, best_acc1: 65.788%
2022-07-05 19:23:51 - epoch 056 lr: 0.010000
2022-07-05 19:24:29 - train: epoch 0056, iter [00100, 05004], lr: 0.010000, loss: 1.5859
2022-07-05 19:25:01 - train: epoch 0056, iter [00200, 05004], lr: 0.010000, loss: 1.6459
2022-07-05 19:25:35 - train: epoch 0056, iter [00300, 05004], lr: 0.010000, loss: 1.4273
2022-07-05 19:26:07 - train: epoch 0056, iter [00400, 05004], lr: 0.010000, loss: 1.6705
2022-07-05 19:26:39 - train: epoch 0056, iter [00500, 05004], lr: 0.010000, loss: 1.6000
2022-07-05 19:27:12 - train: epoch 0056, iter [00600, 05004], lr: 0.010000, loss: 1.5986
2022-07-05 19:27:46 - train: epoch 0056, iter [00700, 05004], lr: 0.010000, loss: 1.5979
2022-07-05 19:28:18 - train: epoch 0056, iter [00800, 05004], lr: 0.010000, loss: 1.7265
2022-07-05 19:28:52 - train: epoch 0056, iter [00900, 05004], lr: 0.010000, loss: 1.5545
2022-07-05 19:29:24 - train: epoch 0056, iter [01000, 05004], lr: 0.010000, loss: 1.5739
2022-07-05 19:29:59 - train: epoch 0056, iter [01100, 05004], lr: 0.010000, loss: 1.5148
2022-07-05 19:30:31 - train: epoch 0056, iter [01200, 05004], lr: 0.010000, loss: 1.6773
2022-07-05 19:31:04 - train: epoch 0056, iter [01300, 05004], lr: 0.010000, loss: 1.9014
2022-07-05 19:31:36 - train: epoch 0056, iter [01400, 05004], lr: 0.010000, loss: 1.5590
2022-07-05 19:32:11 - train: epoch 0056, iter [01500, 05004], lr: 0.010000, loss: 1.8511
2022-07-05 19:32:44 - train: epoch 0056, iter [01600, 05004], lr: 0.010000, loss: 1.3572
2022-07-05 19:33:16 - train: epoch 0056, iter [01700, 05004], lr: 0.010000, loss: 1.4630
2022-07-05 19:33:50 - train: epoch 0056, iter [01800, 05004], lr: 0.010000, loss: 1.7882
2022-07-05 19:34:23 - train: epoch 0056, iter [01900, 05004], lr: 0.010000, loss: 1.7318
2022-07-05 19:34:57 - train: epoch 0056, iter [02000, 05004], lr: 0.010000, loss: 1.4504
2022-07-05 19:35:31 - train: epoch 0056, iter [02100, 05004], lr: 0.010000, loss: 1.5220
2022-07-05 19:36:04 - train: epoch 0056, iter [02200, 05004], lr: 0.010000, loss: 1.5601
2022-07-05 19:36:35 - train: epoch 0056, iter [02300, 05004], lr: 0.010000, loss: 1.4993
2022-07-05 19:37:09 - train: epoch 0056, iter [02400, 05004], lr: 0.010000, loss: 1.5791
2022-07-05 19:37:42 - train: epoch 0056, iter [02500, 05004], lr: 0.010000, loss: 1.7898
2022-07-05 19:38:15 - train: epoch 0056, iter [02600, 05004], lr: 0.010000, loss: 1.5604
2022-07-05 19:38:48 - train: epoch 0056, iter [02700, 05004], lr: 0.010000, loss: 1.5314
2022-07-05 19:39:22 - train: epoch 0056, iter [02800, 05004], lr: 0.010000, loss: 1.4424
2022-07-05 19:39:55 - train: epoch 0056, iter [02900, 05004], lr: 0.010000, loss: 1.6119
2022-07-05 19:40:28 - train: epoch 0056, iter [03000, 05004], lr: 0.010000, loss: 1.6646
2022-07-05 19:41:01 - train: epoch 0056, iter [03100, 05004], lr: 0.010000, loss: 1.6366
2022-07-05 19:41:34 - train: epoch 0056, iter [03200, 05004], lr: 0.010000, loss: 1.6041
2022-07-05 19:42:07 - train: epoch 0056, iter [03300, 05004], lr: 0.010000, loss: 1.7178
2022-07-05 19:42:41 - train: epoch 0056, iter [03400, 05004], lr: 0.010000, loss: 1.4661
2022-07-05 19:43:14 - train: epoch 0056, iter [03500, 05004], lr: 0.010000, loss: 1.6402
2022-07-05 19:43:49 - train: epoch 0056, iter [03600, 05004], lr: 0.010000, loss: 1.4479
2022-07-05 19:44:20 - train: epoch 0056, iter [03700, 05004], lr: 0.010000, loss: 1.7285
2022-07-05 19:44:54 - train: epoch 0056, iter [03800, 05004], lr: 0.010000, loss: 1.7561
2022-07-05 19:45:27 - train: epoch 0056, iter [03900, 05004], lr: 0.010000, loss: 1.7849
2022-07-05 19:46:01 - train: epoch 0056, iter [04000, 05004], lr: 0.010000, loss: 1.5014
2022-07-05 19:46:34 - train: epoch 0056, iter [04100, 05004], lr: 0.010000, loss: 1.6905
2022-07-05 19:47:07 - train: epoch 0056, iter [04200, 05004], lr: 0.010000, loss: 1.6732
2022-07-05 19:47:41 - train: epoch 0056, iter [04300, 05004], lr: 0.010000, loss: 1.4984
2022-07-05 19:48:14 - train: epoch 0056, iter [04400, 05004], lr: 0.010000, loss: 1.6061
2022-07-05 19:48:46 - train: epoch 0056, iter [04500, 05004], lr: 0.010000, loss: 1.5925
2022-07-05 19:49:20 - train: epoch 0056, iter [04600, 05004], lr: 0.010000, loss: 1.6709
2022-07-05 19:49:53 - train: epoch 0056, iter [04700, 05004], lr: 0.010000, loss: 1.6249
2022-07-05 19:50:27 - train: epoch 0056, iter [04800, 05004], lr: 0.010000, loss: 1.7123
2022-07-05 19:50:59 - train: epoch 0056, iter [04900, 05004], lr: 0.010000, loss: 1.5928
2022-07-05 19:51:32 - train: epoch 0056, iter [05000, 05004], lr: 0.010000, loss: 1.6979
2022-07-05 19:51:32 - train: epoch 056, train_loss: 1.5950
2022-07-05 19:52:45 - eval: epoch: 056, acc1: 63.970%, acc5: 85.780%, test_loss: 1.4879, per_image_load_time: 2.655ms, per_image_inference_time: 0.156ms
2022-07-05 19:52:46 - until epoch: 056, best_acc1: 65.788%
2022-07-05 19:52:46 - epoch 057 lr: 0.010000
2022-07-05 19:53:24 - train: epoch 0057, iter [00100, 05004], lr: 0.010000, loss: 1.7407
2022-07-05 19:53:56 - train: epoch 0057, iter [00200, 05004], lr: 0.010000, loss: 1.5567
2022-07-05 19:54:29 - train: epoch 0057, iter [00300, 05004], lr: 0.010000, loss: 1.5086
2022-07-05 19:55:02 - train: epoch 0057, iter [00400, 05004], lr: 0.010000, loss: 1.4271
2022-07-05 19:55:35 - train: epoch 0057, iter [00500, 05004], lr: 0.010000, loss: 1.4178
2022-07-05 19:56:08 - train: epoch 0057, iter [00600, 05004], lr: 0.010000, loss: 1.7871
2022-07-05 19:56:41 - train: epoch 0057, iter [00700, 05004], lr: 0.010000, loss: 1.4889
2022-07-05 19:57:14 - train: epoch 0057, iter [00800, 05004], lr: 0.010000, loss: 1.5678
2022-07-05 19:57:47 - train: epoch 0057, iter [00900, 05004], lr: 0.010000, loss: 1.6097
2022-07-05 19:58:20 - train: epoch 0057, iter [01000, 05004], lr: 0.010000, loss: 1.4637
2022-07-05 19:58:53 - train: epoch 0057, iter [01100, 05004], lr: 0.010000, loss: 1.4961
2022-07-05 19:59:27 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 1.5065
2022-07-05 20:00:00 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 1.5591
2022-07-05 20:00:34 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 1.5299
2022-07-05 20:01:06 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 1.6970
2022-07-05 20:01:39 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 1.6195
2022-07-05 20:02:11 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 1.7362
2022-07-05 20:02:45 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 1.5761
2022-07-05 20:03:17 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 1.5451
2022-07-05 20:03:51 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 1.6732
2022-07-05 20:04:23 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 1.4991
2022-07-05 20:04:56 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 1.5643
2022-07-05 20:05:30 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 1.5267
2022-07-05 20:06:03 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 1.7548
2022-07-05 20:06:36 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 1.8612
2022-07-05 20:07:10 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 1.5087
2022-07-05 20:07:42 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 1.5993
2022-07-05 20:08:15 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 1.4752
2022-07-05 20:08:49 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 1.6092
2022-07-05 20:09:21 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 1.7829
2022-07-05 20:09:55 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 1.7503
2022-07-05 20:10:28 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 1.6093
2022-07-05 20:11:00 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 1.6281
2022-07-05 20:11:34 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 1.5808
2022-07-05 20:12:07 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 1.7334
2022-07-05 20:12:41 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 1.4924
2022-07-05 20:13:13 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 1.5088
2022-07-05 20:13:46 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 1.4036
2022-07-05 20:14:19 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 1.6489
2022-07-05 20:14:53 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 1.5107
2022-07-05 20:15:26 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 1.8230
2022-07-05 20:15:59 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 1.9227
2022-07-05 20:16:32 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 1.4773
2022-07-05 20:17:05 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 1.6256
2022-07-05 20:17:39 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 1.6411
2022-07-05 20:18:11 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 1.5963
2022-07-05 20:18:45 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 1.6571
2022-07-05 20:19:18 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 1.9407
2022-07-05 20:19:51 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 1.8954
2022-07-05 20:20:22 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 1.7068
2022-07-05 20:20:23 - train: epoch 057, train_loss: 1.5952
2022-07-05 20:21:36 - eval: epoch: 057, acc1: 65.412%, acc5: 86.732%, test_loss: 1.4289, per_image_load_time: 2.137ms, per_image_inference_time: 0.163ms
2022-07-05 20:21:36 - until epoch: 057, best_acc1: 65.788%
2022-07-05 20:21:36 - epoch 058 lr: 0.010000
2022-07-05 20:22:14 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 1.5747
2022-07-05 20:22:47 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 1.7072
2022-07-05 20:23:20 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 1.4859
2022-07-05 20:23:51 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 1.5687
2022-07-05 20:24:24 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 1.5351
2022-07-05 20:24:58 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 1.8908
2022-07-05 20:25:30 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 1.5752
2022-07-05 20:26:03 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 1.4741
2022-07-05 20:26:36 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 1.3868
2022-07-05 20:27:09 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 1.6354
2022-07-05 20:27:42 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 1.5651
2022-07-05 20:28:15 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 1.4103
2022-07-05 20:28:48 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 1.8506
2022-07-05 20:29:22 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 1.6533
2022-07-05 20:29:54 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 1.6322
2022-07-05 20:30:28 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 1.5955
2022-07-05 20:31:01 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 1.7070
2022-07-05 20:31:35 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 1.6359
2022-07-05 20:32:07 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 1.6086
2022-07-05 20:32:41 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 1.8186
2022-07-05 20:33:13 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 1.5646
2022-07-05 20:33:47 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 1.4505
2022-07-05 20:34:20 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 1.6286
2022-07-05 20:34:53 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 1.5864
2022-07-05 20:35:26 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 1.5911
2022-07-05 20:35:59 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 1.5793
2022-07-05 20:36:33 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 1.8182
2022-07-05 20:37:05 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 1.5847
2022-07-05 20:37:38 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 1.3931
2022-07-05 20:38:11 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 1.6913
2022-07-05 20:38:44 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 1.7402
2022-07-05 20:39:17 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 1.4948
2022-07-05 20:39:50 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 1.5824
2022-07-05 20:40:24 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 1.6425
2022-07-05 20:40:57 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 1.6584
2022-07-05 20:41:30 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 1.5101
2022-07-05 20:42:03 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 1.6833
2022-07-05 20:42:37 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 1.5456
2022-07-05 20:43:10 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 1.4681
2022-07-05 20:43:43 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 1.5858
2022-07-05 20:44:17 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 1.5516
2022-07-05 20:44:49 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 1.5534
2022-07-05 20:45:23 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 1.8564
2022-07-05 20:45:56 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 1.3948
2022-07-05 20:46:29 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 1.4400
2022-07-05 20:47:04 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 1.7719
2022-07-05 20:47:36 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 1.5194
2022-07-05 20:48:10 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 1.8825
2022-07-05 20:48:42 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 1.4302
2022-07-05 20:49:14 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 1.3235
2022-07-05 20:49:15 - train: epoch 058, train_loss: 1.5917
2022-07-05 20:50:29 - eval: epoch: 058, acc1: 65.680%, acc5: 86.730%, test_loss: 1.4192, per_image_load_time: 2.675ms, per_image_inference_time: 0.174ms
2022-07-05 20:50:29 - until epoch: 058, best_acc1: 65.788%
2022-07-05 20:50:29 - epoch 059 lr: 0.010000
2022-07-05 20:51:07 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 1.7522
2022-07-05 20:51:41 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 1.5072
2022-07-05 20:52:12 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 1.5653
2022-07-05 20:52:46 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 1.5270
2022-07-05 20:53:19 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 1.4998
2022-07-05 20:53:51 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 1.5879
2022-07-05 20:54:24 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 1.3519
2022-07-05 20:54:56 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 1.9076
2022-07-05 20:55:31 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 1.5096
2022-07-05 20:56:04 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 1.7294
2022-07-05 20:56:37 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 1.8635
2022-07-05 20:57:09 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 1.3461
2022-07-05 20:57:43 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 1.8646
2022-07-05 20:58:16 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 1.8678
2022-07-05 20:58:48 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 1.5035
2022-07-05 20:59:21 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 1.6241
2022-07-05 20:59:54 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 1.5009
2022-07-05 21:00:28 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 1.4162
2022-07-05 21:01:00 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 1.6704
2022-07-05 21:01:34 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 1.4044
2022-07-05 21:02:07 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 1.5143
2022-07-05 21:02:40 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 1.4950
2022-07-05 21:03:12 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 1.5327
2022-07-05 21:03:47 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 1.6751
2022-07-05 21:04:19 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 1.4777
2022-07-05 21:04:53 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 1.6591
2022-07-05 21:05:26 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 1.7646
2022-07-05 21:05:59 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 1.6890
2022-07-05 21:06:31 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 1.4230
2022-07-05 21:07:06 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 1.8812
2022-07-05 21:07:38 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 1.5309
2022-07-05 21:08:12 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 1.7183
2022-07-05 21:08:45 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 1.5750
2022-07-05 21:09:19 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 1.8450
2022-07-05 21:09:51 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 1.5757
2022-07-05 21:10:24 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 1.7109
2022-07-05 21:10:58 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 1.7281
2022-07-05 21:11:30 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 1.6357
2022-07-05 21:12:05 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 1.4282
2022-07-05 21:12:37 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 1.7407
2022-07-05 21:13:11 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 1.4058
2022-07-05 21:13:44 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 1.6669
2022-07-05 21:14:18 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 1.7543
2022-07-05 21:14:51 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 1.5971
2022-07-05 21:15:24 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 1.8171
2022-07-05 21:15:56 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 1.6709
2022-07-05 21:16:30 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 1.4289
2022-07-05 21:17:03 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 1.5405
2022-07-05 21:17:37 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 1.6093
2022-07-05 21:18:08 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 1.8304
2022-07-05 21:18:09 - train: epoch 059, train_loss: 1.5899
2022-07-05 21:19:23 - eval: epoch: 059, acc1: 65.016%, acc5: 86.578%, test_loss: 1.4333, per_image_load_time: 2.609ms, per_image_inference_time: 0.169ms
2022-07-05 21:19:23 - until epoch: 059, best_acc1: 65.788%
2022-07-05 21:19:23 - epoch 060 lr: 0.010000
2022-07-05 21:20:01 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 1.6135
2022-07-05 21:20:33 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 1.4603
2022-07-05 21:21:06 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 1.6479
2022-07-05 21:21:38 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 1.5846
2022-07-05 21:22:11 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 1.8687
2022-07-05 21:22:42 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 1.7626
2022-07-05 21:23:16 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 1.8143
2022-07-05 21:23:48 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 1.7411
2022-07-05 21:24:21 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 1.5306
2022-07-05 21:24:55 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 1.4184
2022-07-05 21:25:28 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 1.5635
2022-07-05 21:26:01 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 1.4557
2022-07-05 21:26:34 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 1.4409
2022-07-05 21:27:07 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 1.6112
2022-07-05 21:27:40 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 1.6134
2022-07-05 21:28:13 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 1.5991
2022-07-05 21:28:46 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 1.6422
2022-07-05 21:29:19 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 1.8279
2022-07-05 21:29:52 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 1.7297
2022-07-05 21:30:25 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 1.5754
2022-07-05 21:30:59 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 1.6660
2022-07-05 21:31:32 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 1.7015
2022-07-05 21:32:05 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 1.6114
2022-07-05 21:32:38 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 1.5941
2022-07-05 21:33:11 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 1.5305
2022-07-05 21:33:44 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 1.7237
2022-07-05 21:34:17 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 1.3102
2022-07-05 21:34:49 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 1.8150
2022-07-05 21:35:23 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 1.7326
2022-07-05 21:35:56 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 1.5846
2022-07-05 21:36:29 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 1.7678
2022-07-05 21:37:02 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 1.3517
2022-07-05 21:37:35 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 1.3735
2022-07-05 21:38:09 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 1.6590
2022-07-05 21:38:41 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 1.6785
2022-07-05 21:39:15 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 1.7149
2022-07-05 21:39:47 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 1.4830
2022-07-05 21:40:20 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 1.4686
2022-07-05 21:40:54 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 1.7541
2022-07-05 21:41:28 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 1.6323
2022-07-05 21:42:01 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 1.6727
2022-07-05 21:42:35 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 1.6729
2022-07-05 21:43:08 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 1.4172
2022-07-05 21:43:40 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 1.8626
2022-07-05 21:44:13 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 1.5731
2022-07-05 21:44:47 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 1.3178
2022-07-05 21:45:20 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 1.6506
2022-07-05 21:45:54 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 1.6688
2022-07-05 21:46:26 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 1.5850
2022-07-05 21:46:57 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 1.6460
2022-07-05 21:46:58 - train: epoch 060, train_loss: 1.5875
2022-07-05 21:48:11 - eval: epoch: 060, acc1: 65.188%, acc5: 86.660%, test_loss: 1.4371, per_image_load_time: 2.692ms, per_image_inference_time: 0.174ms
2022-07-05 21:48:12 - until epoch: 060, best_acc1: 65.788%
2022-07-05 21:48:12 - epoch 061 lr: 0.001000
2022-07-05 21:48:49 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 1.1722
2022-07-05 21:49:23 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 1.5178
2022-07-05 21:49:55 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 1.4428
2022-07-05 21:50:28 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 1.5912
2022-07-05 21:51:01 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 1.3990
2022-07-05 21:51:33 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 1.4597
2022-07-05 21:52:06 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 1.2134
2022-07-05 21:52:39 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 1.2248
2022-07-05 21:53:11 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 1.3083
2022-07-05 21:53:46 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 1.4178
2022-07-05 21:54:19 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 1.2127
2022-07-05 21:54:52 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 1.3922
2022-07-05 21:55:25 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 1.5573
2022-07-05 21:55:59 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 1.2759
2022-07-05 21:56:31 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 1.4433
2022-07-05 21:57:04 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 1.5014
2022-07-05 21:57:37 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 1.3340
2022-07-05 21:58:11 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 1.4994
2022-07-05 21:58:43 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 1.5958
2022-07-05 21:59:17 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 1.4958
2022-07-05 21:59:50 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 1.4696
2022-07-05 22:00:24 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 1.1930
2022-07-05 22:00:56 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 1.4975
2022-07-05 22:01:30 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 1.3355
2022-07-05 22:02:03 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 1.3621
2022-07-05 22:02:37 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 1.4556
2022-07-05 22:03:10 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 1.4987
2022-07-05 22:03:44 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 1.5626
2022-07-05 22:04:15 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 1.4161
2022-07-05 22:04:50 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 1.3533
2022-07-05 22:05:22 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 1.3698
2022-07-05 22:05:56 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 1.2103
2022-07-05 22:06:28 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 1.4136
2022-07-05 22:07:02 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 1.1971
2022-07-05 22:07:35 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 1.4048
2022-07-05 22:08:09 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 1.3774
2022-07-05 22:08:41 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 1.3573
2022-07-05 22:09:15 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 1.4278
2022-07-05 22:09:48 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 1.4344
2022-07-05 22:10:21 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 1.4213
2022-07-05 22:10:55 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 1.6792
2022-07-05 22:11:28 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 1.4520
2022-07-05 22:12:01 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 1.2532
2022-07-05 22:12:34 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 1.3547
2022-07-05 22:13:08 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 1.2852
2022-07-05 22:13:43 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 1.4065
2022-07-05 22:14:14 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 1.6289
2022-07-05 22:14:48 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 1.3505
2022-07-05 22:15:22 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 1.2005
2022-07-05 22:15:52 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 1.4398
2022-07-05 22:15:53 - train: epoch 061, train_loss: 1.4198
2022-07-05 22:17:06 - eval: epoch: 061, acc1: 68.884%, acc5: 88.568%, test_loss: 1.2771, per_image_load_time: 1.813ms, per_image_inference_time: 0.181ms
2022-07-05 22:17:06 - until epoch: 061, best_acc1: 68.884%
2022-07-05 22:17:06 - epoch 062 lr: 0.001000
2022-07-05 22:17:44 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 1.4551
2022-07-05 22:18:17 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 1.5147
2022-07-05 22:18:50 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 1.4516
2022-07-05 22:19:24 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 1.0675
2022-07-05 22:19:56 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 1.3298
2022-07-05 22:20:29 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 1.4735
2022-07-05 22:21:02 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 1.2942
2022-07-05 22:21:35 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 1.3927
2022-07-05 22:22:08 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 1.4900
2022-07-05 22:22:41 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 1.4348
2022-07-05 22:23:14 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 1.4126
2022-07-05 22:23:48 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 1.6787
2022-07-05 22:24:21 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 1.3041
2022-07-05 22:24:54 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 1.3210
2022-07-05 22:25:28 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 1.4266
2022-07-05 22:26:01 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 1.5722
2022-07-05 22:26:34 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 1.5583
2022-07-05 22:27:07 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 1.2620
2022-07-05 22:27:39 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 1.4612
2022-07-05 22:28:13 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 1.3040
2022-07-05 22:28:46 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 1.3944
2022-07-05 22:29:19 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 1.1424
2022-07-05 22:29:53 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 1.3646
2022-07-05 22:30:26 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 1.3620
2022-07-05 22:31:00 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 1.3959
2022-07-05 22:31:32 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 1.2124
2022-07-05 22:32:06 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 1.2378
2022-07-05 22:32:38 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 1.4726
2022-07-05 22:33:12 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 1.3507
2022-07-05 22:33:44 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 1.4697
2022-07-05 22:34:18 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 1.6799
2022-07-05 22:34:50 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 1.3229
2022-07-05 22:35:24 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 1.3469
2022-07-05 22:35:56 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 1.4664
2022-07-05 22:36:30 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 1.3799
2022-07-05 22:37:03 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 1.3454
2022-07-05 22:37:37 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 1.5271
2022-07-05 22:38:09 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 1.4973
2022-07-05 22:38:43 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 1.3632
2022-07-05 22:39:16 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 1.2673
2022-07-05 22:39:50 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 1.3532
2022-07-05 22:40:22 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 1.2204
2022-07-05 22:40:56 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 1.3325
2022-07-05 22:41:29 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 1.3867
2022-07-05 22:42:02 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 1.3864
2022-07-05 22:42:35 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 1.2281
2022-07-05 22:43:08 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 1.3052
2022-07-05 22:43:42 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 1.2277
2022-07-05 22:44:15 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 1.3623
2022-07-05 22:44:46 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 1.5601
2022-07-05 22:44:47 - train: epoch 062, train_loss: 1.3739
2022-07-05 22:46:01 - eval: epoch: 062, acc1: 69.294%, acc5: 88.938%, test_loss: 1.2563, per_image_load_time: 1.345ms, per_image_inference_time: 0.190ms
2022-07-05 22:46:01 - until epoch: 062, best_acc1: 69.294%
2022-07-05 22:46:01 - epoch 063 lr: 0.001000
2022-07-05 22:46:40 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 1.3708
2022-07-05 22:47:12 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 1.3271
2022-07-05 22:47:45 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 1.3424
2022-07-05 22:48:17 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 1.4519
2022-07-05 22:48:50 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 1.2920
2022-07-05 22:49:23 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 1.4132
2022-07-05 22:49:56 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 1.4246
2022-07-05 22:50:29 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 1.2834
2022-07-05 22:51:02 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 1.4767
2022-07-05 22:51:36 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 1.4971
2022-07-05 22:52:08 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 1.3515
2022-07-05 22:52:41 - train: epoch 0063, iter [01200, 05004], lr: 0.001000, loss: 1.4048
2022-07-05 22:53:14 - train: epoch 0063, iter [01300, 05004], lr: 0.001000, loss: 1.1978
2022-07-05 22:53:46 - train: epoch 0063, iter [01400, 05004], lr: 0.001000, loss: 1.6617
2022-07-05 22:54:20 - train: epoch 0063, iter [01500, 05004], lr: 0.001000, loss: 1.3778
2022-07-05 22:54:52 - train: epoch 0063, iter [01600, 05004], lr: 0.001000, loss: 1.3055
2022-07-05 22:55:25 - train: epoch 0063, iter [01700, 05004], lr: 0.001000, loss: 1.3317
2022-07-05 22:55:58 - train: epoch 0063, iter [01800, 05004], lr: 0.001000, loss: 1.3702
2022-07-05 22:56:31 - train: epoch 0063, iter [01900, 05004], lr: 0.001000, loss: 1.4833
2022-07-05 22:57:05 - train: epoch 0063, iter [02000, 05004], lr: 0.001000, loss: 1.1886
2022-07-05 22:57:37 - train: epoch 0063, iter [02100, 05004], lr: 0.001000, loss: 1.2918
2022-07-05 22:58:10 - train: epoch 0063, iter [02200, 05004], lr: 0.001000, loss: 1.4775
2022-07-05 22:58:43 - train: epoch 0063, iter [02300, 05004], lr: 0.001000, loss: 1.4791
2022-07-05 22:59:17 - train: epoch 0063, iter [02400, 05004], lr: 0.001000, loss: 1.3756
2022-07-05 22:59:49 - train: epoch 0063, iter [02500, 05004], lr: 0.001000, loss: 1.2234
2022-07-05 23:00:22 - train: epoch 0063, iter [02600, 05004], lr: 0.001000, loss: 1.3614
2022-07-05 23:00:56 - train: epoch 0063, iter [02700, 05004], lr: 0.001000, loss: 1.3378
2022-07-05 23:01:29 - train: epoch 0063, iter [02800, 05004], lr: 0.001000, loss: 1.3441
2022-07-05 23:02:01 - train: epoch 0063, iter [02900, 05004], lr: 0.001000, loss: 1.4360
2022-07-05 23:02:35 - train: epoch 0063, iter [03000, 05004], lr: 0.001000, loss: 1.4009
