2022-07-05 23:03:09 - train: epoch 0063, iter [03100, 05004], lr: 0.001000, loss: 1.6485
2022-07-05 23:03:41 - train: epoch 0063, iter [03200, 05004], lr: 0.001000, loss: 1.4719
2022-07-05 23:04:15 - train: epoch 0063, iter [03300, 05004], lr: 0.001000, loss: 1.3397
2022-07-05 23:04:48 - train: epoch 0063, iter [03400, 05004], lr: 0.001000, loss: 1.2923
2022-07-05 23:05:21 - train: epoch 0063, iter [03500, 05004], lr: 0.001000, loss: 1.5801
2022-07-05 23:05:54 - train: epoch 0063, iter [03600, 05004], lr: 0.001000, loss: 1.2252
2022-07-05 23:06:27 - train: epoch 0063, iter [03700, 05004], lr: 0.001000, loss: 1.5662
2022-07-05 23:07:00 - train: epoch 0063, iter [03800, 05004], lr: 0.001000, loss: 1.4082
2022-07-05 23:07:33 - train: epoch 0063, iter [03900, 05004], lr: 0.001000, loss: 1.2666
2022-07-05 23:08:07 - train: epoch 0063, iter [04000, 05004], lr: 0.001000, loss: 1.2590
2022-07-05 23:08:39 - train: epoch 0063, iter [04100, 05004], lr: 0.001000, loss: 1.3764
2022-07-05 23:09:12 - train: epoch 0063, iter [04200, 05004], lr: 0.001000, loss: 1.2766
2022-07-05 23:09:46 - train: epoch 0063, iter [04300, 05004], lr: 0.001000, loss: 1.4249
2022-07-05 23:10:18 - train: epoch 0063, iter [04400, 05004], lr: 0.001000, loss: 1.4687
2022-07-05 23:10:52 - train: epoch 0063, iter [04500, 05004], lr: 0.001000, loss: 1.5923
2022-07-05 23:11:24 - train: epoch 0063, iter [04600, 05004], lr: 0.001000, loss: 1.4044
2022-07-05 23:11:58 - train: epoch 0063, iter [04700, 05004], lr: 0.001000, loss: 1.3931
2022-07-05 23:12:31 - train: epoch 0063, iter [04800, 05004], lr: 0.001000, loss: 1.2306
2022-07-05 23:13:05 - train: epoch 0063, iter [04900, 05004], lr: 0.001000, loss: 1.4028
2022-07-05 23:13:36 - train: epoch 0063, iter [05000, 05004], lr: 0.001000, loss: 1.4170
2022-07-05 23:13:36 - train: epoch 063, train_loss: 1.3551
2022-07-05 23:14:49 - eval: epoch: 063, acc1: 69.434%, acc5: 88.956%, test_loss: 1.2493, per_image_load_time: 2.244ms, per_image_inference_time: 0.178ms
2022-07-05 23:14:49 - until epoch: 063, best_acc1: 69.434%
2022-07-05 23:14:49 - epoch 064 lr: 0.001000
2022-07-05 23:15:27 - train: epoch 0064, iter [00100, 05004], lr: 0.001000, loss: 1.3898
2022-07-05 23:16:00 - train: epoch 0064, iter [00200, 05004], lr: 0.001000, loss: 1.3000
2022-07-05 23:16:33 - train: epoch 0064, iter [00300, 05004], lr: 0.001000, loss: 1.3445
2022-07-05 23:17:05 - train: epoch 0064, iter [00400, 05004], lr: 0.001000, loss: 1.2669
2022-07-05 23:17:39 - train: epoch 0064, iter [00500, 05004], lr: 0.001000, loss: 1.2847
2022-07-05 23:18:11 - train: epoch 0064, iter [00600, 05004], lr: 0.001000, loss: 1.3432
2022-07-05 23:18:44 - train: epoch 0064, iter [00700, 05004], lr: 0.001000, loss: 1.5073
2022-07-05 23:19:18 - train: epoch 0064, iter [00800, 05004], lr: 0.001000, loss: 1.1043
2022-07-05 23:19:51 - train: epoch 0064, iter [00900, 05004], lr: 0.001000, loss: 1.1006
2022-07-05 23:20:24 - train: epoch 0064, iter [01000, 05004], lr: 0.001000, loss: 1.2869
2022-07-05 23:20:57 - train: epoch 0064, iter [01100, 05004], lr: 0.001000, loss: 1.4439
2022-07-05 23:21:30 - train: epoch 0064, iter [01200, 05004], lr: 0.001000, loss: 1.1488
2022-07-05 23:22:05 - train: epoch 0064, iter [01300, 05004], lr: 0.001000, loss: 1.3030
2022-07-05 23:22:37 - train: epoch 0064, iter [01400, 05004], lr: 0.001000, loss: 1.5756
2022-07-05 23:23:10 - train: epoch 0064, iter [01500, 05004], lr: 0.001000, loss: 1.3919
2022-07-05 23:23:43 - train: epoch 0064, iter [01600, 05004], lr: 0.001000, loss: 1.2450
2022-07-05 23:24:16 - train: epoch 0064, iter [01700, 05004], lr: 0.001000, loss: 1.1821
2022-07-05 23:24:49 - train: epoch 0064, iter [01800, 05004], lr: 0.001000, loss: 1.3389
2022-07-05 23:25:24 - train: epoch 0064, iter [01900, 05004], lr: 0.001000, loss: 1.3274
2022-07-05 23:25:56 - train: epoch 0064, iter [02000, 05004], lr: 0.001000, loss: 1.3584
2022-07-05 23:26:30 - train: epoch 0064, iter [02100, 05004], lr: 0.001000, loss: 1.4839
2022-07-05 23:27:03 - train: epoch 0064, iter [02200, 05004], lr: 0.001000, loss: 1.2266
2022-07-05 23:27:37 - train: epoch 0064, iter [02300, 05004], lr: 0.001000, loss: 1.3908
2022-07-05 23:28:09 - train: epoch 0064, iter [02400, 05004], lr: 0.001000, loss: 1.2321
2022-07-05 23:28:42 - train: epoch 0064, iter [02500, 05004], lr: 0.001000, loss: 1.1847
2022-07-05 23:29:16 - train: epoch 0064, iter [02600, 05004], lr: 0.001000, loss: 1.4664
2022-07-05 23:29:48 - train: epoch 0064, iter [02700, 05004], lr: 0.001000, loss: 1.3354
2022-07-05 23:30:22 - train: epoch 0064, iter [02800, 05004], lr: 0.001000, loss: 1.1846
2022-07-05 23:30:55 - train: epoch 0064, iter [02900, 05004], lr: 0.001000, loss: 1.3936
2022-07-05 23:31:29 - train: epoch 0064, iter [03000, 05004], lr: 0.001000, loss: 1.2697
2022-07-05 23:32:02 - train: epoch 0064, iter [03100, 05004], lr: 0.001000, loss: 1.3761
2022-07-05 23:32:36 - train: epoch 0064, iter [03200, 05004], lr: 0.001000, loss: 1.4525
2022-07-05 23:33:07 - train: epoch 0064, iter [03300, 05004], lr: 0.001000, loss: 1.3195
2022-07-05 23:33:42 - train: epoch 0064, iter [03400, 05004], lr: 0.001000, loss: 1.4207
2022-07-05 23:34:14 - train: epoch 0064, iter [03500, 05004], lr: 0.001000, loss: 1.2242
2022-07-05 23:34:48 - train: epoch 0064, iter [03600, 05004], lr: 0.001000, loss: 1.2648
2022-07-05 23:35:21 - train: epoch 0064, iter [03700, 05004], lr: 0.001000, loss: 0.9835
2022-07-05 23:35:55 - train: epoch 0064, iter [03800, 05004], lr: 0.001000, loss: 1.2999
2022-07-05 23:36:27 - train: epoch 0064, iter [03900, 05004], lr: 0.001000, loss: 1.2291
2022-07-05 23:37:01 - train: epoch 0064, iter [04000, 05004], lr: 0.001000, loss: 1.3611
2022-07-05 23:37:34 - train: epoch 0064, iter [04100, 05004], lr: 0.001000, loss: 1.4729
2022-07-05 23:38:07 - train: epoch 0064, iter [04200, 05004], lr: 0.001000, loss: 1.2060
2022-07-05 23:38:41 - train: epoch 0064, iter [04300, 05004], lr: 0.001000, loss: 1.4665
2022-07-05 23:39:15 - train: epoch 0064, iter [04400, 05004], lr: 0.001000, loss: 1.1927
2022-07-05 23:39:47 - train: epoch 0064, iter [04500, 05004], lr: 0.001000, loss: 1.4181
2022-07-05 23:40:21 - train: epoch 0064, iter [04600, 05004], lr: 0.001000, loss: 1.3961
2022-07-05 23:40:54 - train: epoch 0064, iter [04700, 05004], lr: 0.001000, loss: 1.6865
2022-07-05 23:41:27 - train: epoch 0064, iter [04800, 05004], lr: 0.001000, loss: 1.5189
2022-07-05 23:42:00 - train: epoch 0064, iter [04900, 05004], lr: 0.001000, loss: 1.2899
2022-07-05 23:42:32 - train: epoch 0064, iter [05000, 05004], lr: 0.001000, loss: 1.0474
2022-07-05 23:42:33 - train: epoch 064, train_loss: 1.3405
2022-07-05 23:43:45 - eval: epoch: 064, acc1: 69.532%, acc5: 89.034%, test_loss: 1.2430, per_image_load_time: 2.338ms, per_image_inference_time: 0.176ms
2022-07-05 23:43:46 - until epoch: 064, best_acc1: 69.532%
2022-07-05 23:43:46 - epoch 065 lr: 0.001000
2022-07-05 23:44:24 - train: epoch 0065, iter [00100, 05004], lr: 0.001000, loss: 1.4367
2022-07-05 23:44:57 - train: epoch 0065, iter [00200, 05004], lr: 0.001000, loss: 1.3947
2022-07-05 23:45:29 - train: epoch 0065, iter [00300, 05004], lr: 0.001000, loss: 1.3788
2022-07-05 23:46:02 - train: epoch 0065, iter [00400, 05004], lr: 0.001000, loss: 1.2418
2022-07-05 23:46:35 - train: epoch 0065, iter [00500, 05004], lr: 0.001000, loss: 1.3981
2022-07-05 23:47:08 - train: epoch 0065, iter [00600, 05004], lr: 0.001000, loss: 1.2484
2022-07-05 23:47:40 - train: epoch 0065, iter [00700, 05004], lr: 0.001000, loss: 1.1900
2022-07-05 23:48:14 - train: epoch 0065, iter [00800, 05004], lr: 0.001000, loss: 1.2876
2022-07-05 23:48:46 - train: epoch 0065, iter [00900, 05004], lr: 0.001000, loss: 1.2468
2022-07-05 23:49:20 - train: epoch 0065, iter [01000, 05004], lr: 0.001000, loss: 1.5240
2022-07-05 23:49:52 - train: epoch 0065, iter [01100, 05004], lr: 0.001000, loss: 1.4830
2022-07-05 23:50:26 - train: epoch 0065, iter [01200, 05004], lr: 0.001000, loss: 1.6102
2022-07-05 23:50:58 - train: epoch 0065, iter [01300, 05004], lr: 0.001000, loss: 1.3207
2022-07-05 23:51:32 - train: epoch 0065, iter [01400, 05004], lr: 0.001000, loss: 1.2593
2022-07-05 23:52:04 - train: epoch 0065, iter [01500, 05004], lr: 0.001000, loss: 1.2137
2022-07-05 23:52:38 - train: epoch 0065, iter [01600, 05004], lr: 0.001000, loss: 1.3726
2022-07-05 23:53:10 - train: epoch 0065, iter [01700, 05004], lr: 0.001000, loss: 1.2988
2022-07-05 23:53:44 - train: epoch 0065, iter [01800, 05004], lr: 0.001000, loss: 1.1795
2022-07-05 23:54:17 - train: epoch 0065, iter [01900, 05004], lr: 0.001000, loss: 1.3161
2022-07-05 23:54:50 - train: epoch 0065, iter [02000, 05004], lr: 0.001000, loss: 1.3619
2022-07-05 23:55:23 - train: epoch 0065, iter [02100, 05004], lr: 0.001000, loss: 1.3040
2022-07-05 23:55:56 - train: epoch 0065, iter [02200, 05004], lr: 0.001000, loss: 1.4564
2022-07-05 23:56:29 - train: epoch 0065, iter [02300, 05004], lr: 0.001000, loss: 1.2306
2022-07-05 23:57:03 - train: epoch 0065, iter [02400, 05004], lr: 0.001000, loss: 1.2366
2022-07-05 23:57:36 - train: epoch 0065, iter [02500, 05004], lr: 0.001000, loss: 1.2647
2022-07-05 23:58:09 - train: epoch 0065, iter [02600, 05004], lr: 0.001000, loss: 1.4523
2022-07-05 23:58:43 - train: epoch 0065, iter [02700, 05004], lr: 0.001000, loss: 1.3876
2022-07-05 23:59:15 - train: epoch 0065, iter [02800, 05004], lr: 0.001000, loss: 1.3147
2022-07-05 23:59:49 - train: epoch 0065, iter [02900, 05004], lr: 0.001000, loss: 1.3847
2022-07-06 00:00:22 - train: epoch 0065, iter [03000, 05004], lr: 0.001000, loss: 1.3066
2022-07-06 00:00:55 - train: epoch 0065, iter [03100, 05004], lr: 0.001000, loss: 1.4694
2022-07-06 00:01:29 - train: epoch 0065, iter [03200, 05004], lr: 0.001000, loss: 1.3343
2022-07-06 00:02:02 - train: epoch 0065, iter [03300, 05004], lr: 0.001000, loss: 1.3984
2022-07-06 00:02:36 - train: epoch 0065, iter [03400, 05004], lr: 0.001000, loss: 1.3187
2022-07-06 00:03:09 - train: epoch 0065, iter [03500, 05004], lr: 0.001000, loss: 1.5932
2022-07-06 00:03:42 - train: epoch 0065, iter [03600, 05004], lr: 0.001000, loss: 1.3963
2022-07-06 00:04:14 - train: epoch 0065, iter [03700, 05004], lr: 0.001000, loss: 1.1942
2022-07-06 00:04:47 - train: epoch 0065, iter [03800, 05004], lr: 0.001000, loss: 1.1761
2022-07-06 00:05:21 - train: epoch 0065, iter [03900, 05004], lr: 0.001000, loss: 1.4019
2022-07-06 00:05:54 - train: epoch 0065, iter [04000, 05004], lr: 0.001000, loss: 1.2916
2022-07-06 00:06:28 - train: epoch 0065, iter [04100, 05004], lr: 0.001000, loss: 1.3053
2022-07-06 00:07:01 - train: epoch 0065, iter [04200, 05004], lr: 0.001000, loss: 1.2859
2022-07-06 00:07:34 - train: epoch 0065, iter [04300, 05004], lr: 0.001000, loss: 1.3824
2022-07-06 00:08:08 - train: epoch 0065, iter [04400, 05004], lr: 0.001000, loss: 1.3029
2022-07-06 00:08:41 - train: epoch 0065, iter [04500, 05004], lr: 0.001000, loss: 1.1396
2022-07-06 00:09:14 - train: epoch 0065, iter [04600, 05004], lr: 0.001000, loss: 1.3208
2022-07-06 00:09:48 - train: epoch 0065, iter [04700, 05004], lr: 0.001000, loss: 1.2369
2022-07-06 00:10:20 - train: epoch 0065, iter [04800, 05004], lr: 0.001000, loss: 1.1165
2022-07-06 00:10:54 - train: epoch 0065, iter [04900, 05004], lr: 0.001000, loss: 1.3754
2022-07-06 00:11:25 - train: epoch 0065, iter [05000, 05004], lr: 0.001000, loss: 1.3294
2022-07-06 00:11:26 - train: epoch 065, train_loss: 1.3293
2022-07-06 00:12:40 - eval: epoch: 065, acc1: 69.574%, acc5: 88.976%, test_loss: 1.2406, per_image_load_time: 2.666ms, per_image_inference_time: 0.171ms
2022-07-06 00:12:41 - until epoch: 065, best_acc1: 69.574%
2022-07-06 00:12:41 - epoch 066 lr: 0.001000
2022-07-06 00:13:18 - train: epoch 0066, iter [00100, 05004], lr: 0.001000, loss: 1.1847
2022-07-06 00:13:50 - train: epoch 0066, iter [00200, 05004], lr: 0.001000, loss: 1.5596
2022-07-06 00:14:24 - train: epoch 0066, iter [00300, 05004], lr: 0.001000, loss: 1.3000
2022-07-06 00:14:58 - train: epoch 0066, iter [00400, 05004], lr: 0.001000, loss: 1.1962
2022-07-06 00:15:30 - train: epoch 0066, iter [00500, 05004], lr: 0.001000, loss: 1.4516
2022-07-06 00:16:05 - train: epoch 0066, iter [00600, 05004], lr: 0.001000, loss: 1.2117
2022-07-06 00:16:37 - train: epoch 0066, iter [00700, 05004], lr: 0.001000, loss: 1.2493
2022-07-06 00:17:10 - train: epoch 0066, iter [00800, 05004], lr: 0.001000, loss: 1.4822
2022-07-06 00:17:42 - train: epoch 0066, iter [00900, 05004], lr: 0.001000, loss: 1.1281
2022-07-06 00:18:17 - train: epoch 0066, iter [01000, 05004], lr: 0.001000, loss: 1.3809
2022-07-06 00:18:50 - train: epoch 0066, iter [01100, 05004], lr: 0.001000, loss: 1.4864
2022-07-06 00:19:23 - train: epoch 0066, iter [01200, 05004], lr: 0.001000, loss: 1.4363
2022-07-06 00:19:56 - train: epoch 0066, iter [01300, 05004], lr: 0.001000, loss: 1.3068
2022-07-06 00:20:29 - train: epoch 0066, iter [01400, 05004], lr: 0.001000, loss: 1.4076
2022-07-06 00:21:03 - train: epoch 0066, iter [01500, 05004], lr: 0.001000, loss: 1.4510
2022-07-06 00:21:36 - train: epoch 0066, iter [01600, 05004], lr: 0.001000, loss: 1.3346
2022-07-06 00:22:09 - train: epoch 0066, iter [01700, 05004], lr: 0.001000, loss: 1.2254
2022-07-06 00:22:41 - train: epoch 0066, iter [01800, 05004], lr: 0.001000, loss: 1.1449
2022-07-06 00:23:15 - train: epoch 0066, iter [01900, 05004], lr: 0.001000, loss: 1.5203
2022-07-06 00:23:48 - train: epoch 0066, iter [02000, 05004], lr: 0.001000, loss: 1.1342
2022-07-06 00:24:20 - train: epoch 0066, iter [02100, 05004], lr: 0.001000, loss: 1.4572
2022-07-06 00:24:54 - train: epoch 0066, iter [02200, 05004], lr: 0.001000, loss: 1.2287
2022-07-06 00:25:27 - train: epoch 0066, iter [02300, 05004], lr: 0.001000, loss: 1.4420
2022-07-06 00:26:00 - train: epoch 0066, iter [02400, 05004], lr: 0.001000, loss: 1.3613
2022-07-06 00:26:34 - train: epoch 0066, iter [02500, 05004], lr: 0.001000, loss: 1.3794
2022-07-06 00:27:08 - train: epoch 0066, iter [02600, 05004], lr: 0.001000, loss: 1.3209
2022-07-06 00:27:40 - train: epoch 0066, iter [02700, 05004], lr: 0.001000, loss: 1.2633
2022-07-06 00:28:13 - train: epoch 0066, iter [02800, 05004], lr: 0.001000, loss: 1.2191
2022-07-06 00:28:47 - train: epoch 0066, iter [02900, 05004], lr: 0.001000, loss: 1.2650
2022-07-06 00:29:19 - train: epoch 0066, iter [03000, 05004], lr: 0.001000, loss: 1.4951
2022-07-06 00:29:52 - train: epoch 0066, iter [03100, 05004], lr: 0.001000, loss: 1.5991
2022-07-06 00:30:25 - train: epoch 0066, iter [03200, 05004], lr: 0.001000, loss: 1.3047
2022-07-06 00:30:59 - train: epoch 0066, iter [03300, 05004], lr: 0.001000, loss: 1.3856
2022-07-06 00:31:32 - train: epoch 0066, iter [03400, 05004], lr: 0.001000, loss: 1.4331
2022-07-06 00:32:05 - train: epoch 0066, iter [03500, 05004], lr: 0.001000, loss: 1.2326
2022-07-06 00:32:38 - train: epoch 0066, iter [03600, 05004], lr: 0.001000, loss: 1.3445
2022-07-06 00:33:12 - train: epoch 0066, iter [03700, 05004], lr: 0.001000, loss: 1.2285
2022-07-06 00:33:45 - train: epoch 0066, iter [03800, 05004], lr: 0.001000, loss: 1.4147
2022-07-06 00:34:17 - train: epoch 0066, iter [03900, 05004], lr: 0.001000, loss: 1.3108
2022-07-06 00:34:51 - train: epoch 0066, iter [04000, 05004], lr: 0.001000, loss: 1.4205
2022-07-06 00:35:24 - train: epoch 0066, iter [04100, 05004], lr: 0.001000, loss: 1.2221
2022-07-06 00:35:57 - train: epoch 0066, iter [04200, 05004], lr: 0.001000, loss: 1.1720
2022-07-06 00:36:30 - train: epoch 0066, iter [04300, 05004], lr: 0.001000, loss: 1.0547
2022-07-06 00:37:04 - train: epoch 0066, iter [04400, 05004], lr: 0.001000, loss: 1.3639
2022-07-06 00:37:36 - train: epoch 0066, iter [04500, 05004], lr: 0.001000, loss: 1.3040
2022-07-06 00:38:10 - train: epoch 0066, iter [04600, 05004], lr: 0.001000, loss: 1.3955
2022-07-06 00:38:43 - train: epoch 0066, iter [04700, 05004], lr: 0.001000, loss: 1.2520
2022-07-06 00:39:15 - train: epoch 0066, iter [04800, 05004], lr: 0.001000, loss: 1.3906
2022-07-06 00:39:49 - train: epoch 0066, iter [04900, 05004], lr: 0.001000, loss: 1.2909
2022-07-06 00:40:20 - train: epoch 0066, iter [05000, 05004], lr: 0.001000, loss: 1.2824
2022-07-06 00:40:21 - train: epoch 066, train_loss: 1.3225
2022-07-06 00:41:34 - eval: epoch: 066, acc1: 69.712%, acc5: 89.094%, test_loss: 1.2356, per_image_load_time: 2.549ms, per_image_inference_time: 0.176ms
2022-07-06 00:41:34 - until epoch: 066, best_acc1: 69.712%
2022-07-06 00:41:34 - epoch 067 lr: 0.001000
2022-07-06 00:42:13 - train: epoch 0067, iter [00100, 05004], lr: 0.001000, loss: 1.3764
2022-07-06 00:42:46 - train: epoch 0067, iter [00200, 05004], lr: 0.001000, loss: 1.4283
2022-07-06 00:43:19 - train: epoch 0067, iter [00300, 05004], lr: 0.001000, loss: 1.3750
2022-07-06 00:43:52 - train: epoch 0067, iter [00400, 05004], lr: 0.001000, loss: 1.1947
2022-07-06 00:44:24 - train: epoch 0067, iter [00500, 05004], lr: 0.001000, loss: 1.1279
2022-07-06 00:44:57 - train: epoch 0067, iter [00600, 05004], lr: 0.001000, loss: 1.2661
2022-07-06 00:45:31 - train: epoch 0067, iter [00700, 05004], lr: 0.001000, loss: 1.3642
2022-07-06 00:46:04 - train: epoch 0067, iter [00800, 05004], lr: 0.001000, loss: 1.3200
2022-07-06 00:46:36 - train: epoch 0067, iter [00900, 05004], lr: 0.001000, loss: 1.3719
2022-07-06 00:47:09 - train: epoch 0067, iter [01000, 05004], lr: 0.001000, loss: 1.1593
2022-07-06 00:47:42 - train: epoch 0067, iter [01100, 05004], lr: 0.001000, loss: 1.4409
2022-07-06 00:48:15 - train: epoch 0067, iter [01200, 05004], lr: 0.001000, loss: 1.1923
2022-07-06 00:48:48 - train: epoch 0067, iter [01300, 05004], lr: 0.001000, loss: 1.3136
2022-07-06 00:49:21 - train: epoch 0067, iter [01400, 05004], lr: 0.001000, loss: 1.2803
2022-07-06 00:49:55 - train: epoch 0067, iter [01500, 05004], lr: 0.001000, loss: 1.2146
2022-07-06 00:50:26 - train: epoch 0067, iter [01600, 05004], lr: 0.001000, loss: 1.1021
2022-07-06 00:51:00 - train: epoch 0067, iter [01700, 05004], lr: 0.001000, loss: 1.2785
2022-07-06 00:51:34 - train: epoch 0067, iter [01800, 05004], lr: 0.001000, loss: 1.6066
2022-07-06 00:52:07 - train: epoch 0067, iter [01900, 05004], lr: 0.001000, loss: 1.2279
2022-07-06 00:52:40 - train: epoch 0067, iter [02000, 05004], lr: 0.001000, loss: 1.3657
2022-07-06 00:53:12 - train: epoch 0067, iter [02100, 05004], lr: 0.001000, loss: 1.2448
2022-07-06 00:53:46 - train: epoch 0067, iter [02200, 05004], lr: 0.001000, loss: 1.4599
2022-07-06 00:54:19 - train: epoch 0067, iter [02300, 05004], lr: 0.001000, loss: 1.5006
2022-07-06 00:54:53 - train: epoch 0067, iter [02400, 05004], lr: 0.001000, loss: 1.3553
2022-07-06 00:55:26 - train: epoch 0067, iter [02500, 05004], lr: 0.001000, loss: 1.4545
2022-07-06 00:55:59 - train: epoch 0067, iter [02600, 05004], lr: 0.001000, loss: 1.2336
2022-07-06 00:56:32 - train: epoch 0067, iter [02700, 05004], lr: 0.001000, loss: 1.2710
2022-07-06 00:57:06 - train: epoch 0067, iter [02800, 05004], lr: 0.001000, loss: 1.5500
2022-07-06 00:57:38 - train: epoch 0067, iter [02900, 05004], lr: 0.001000, loss: 1.3431
2022-07-06 00:58:12 - train: epoch 0067, iter [03000, 05004], lr: 0.001000, loss: 1.3479
2022-07-06 00:58:45 - train: epoch 0067, iter [03100, 05004], lr: 0.001000, loss: 1.2870
2022-07-06 00:59:18 - train: epoch 0067, iter [03200, 05004], lr: 0.001000, loss: 1.4078
2022-07-06 00:59:52 - train: epoch 0067, iter [03300, 05004], lr: 0.001000, loss: 1.2309
2022-07-06 01:00:24 - train: epoch 0067, iter [03400, 05004], lr: 0.001000, loss: 1.3013
2022-07-06 01:00:58 - train: epoch 0067, iter [03500, 05004], lr: 0.001000, loss: 1.1797
2022-07-06 01:01:30 - train: epoch 0067, iter [03600, 05004], lr: 0.001000, loss: 1.3503
2022-07-06 01:02:04 - train: epoch 0067, iter [03700, 05004], lr: 0.001000, loss: 1.4326
2022-07-06 01:02:37 - train: epoch 0067, iter [03800, 05004], lr: 0.001000, loss: 1.3754
2022-07-06 01:03:11 - train: epoch 0067, iter [03900, 05004], lr: 0.001000, loss: 1.5467
2022-07-06 01:03:44 - train: epoch 0067, iter [04000, 05004], lr: 0.001000, loss: 1.2818
2022-07-06 01:04:17 - train: epoch 0067, iter [04100, 05004], lr: 0.001000, loss: 1.5024
2022-07-06 01:04:49 - train: epoch 0067, iter [04200, 05004], lr: 0.001000, loss: 1.3811
2022-07-06 01:05:23 - train: epoch 0067, iter [04300, 05004], lr: 0.001000, loss: 1.2420
2022-07-06 01:05:57 - train: epoch 0067, iter [04400, 05004], lr: 0.001000, loss: 1.1215
2022-07-06 01:06:30 - train: epoch 0067, iter [04500, 05004], lr: 0.001000, loss: 1.3329
2022-07-06 01:07:03 - train: epoch 0067, iter [04600, 05004], lr: 0.001000, loss: 1.1123
2022-07-06 01:07:37 - train: epoch 0067, iter [04700, 05004], lr: 0.001000, loss: 1.5070
2022-07-06 01:08:09 - train: epoch 0067, iter [04800, 05004], lr: 0.001000, loss: 1.0945
2022-07-06 01:08:43 - train: epoch 0067, iter [04900, 05004], lr: 0.001000, loss: 1.3100
2022-07-06 01:09:14 - train: epoch 0067, iter [05000, 05004], lr: 0.001000, loss: 1.4258
2022-07-06 01:09:15 - train: epoch 067, train_loss: 1.3186
2022-07-06 01:10:29 - eval: epoch: 067, acc1: 69.666%, acc5: 89.132%, test_loss: 1.2369, per_image_load_time: 2.105ms, per_image_inference_time: 0.188ms
2022-07-06 01:10:29 - until epoch: 067, best_acc1: 69.712%
2022-07-06 01:10:29 - epoch 068 lr: 0.001000
2022-07-06 01:11:06 - train: epoch 0068, iter [00100, 05004], lr: 0.001000, loss: 1.3858
2022-07-06 01:11:39 - train: epoch 0068, iter [00200, 05004], lr: 0.001000, loss: 1.2486
2022-07-06 01:12:12 - train: epoch 0068, iter [00300, 05004], lr: 0.001000, loss: 1.2745
2022-07-06 01:12:45 - train: epoch 0068, iter [00400, 05004], lr: 0.001000, loss: 1.2570
2022-07-06 01:13:17 - train: epoch 0068, iter [00500, 05004], lr: 0.001000, loss: 1.1889
2022-07-06 01:13:50 - train: epoch 0068, iter [00600, 05004], lr: 0.001000, loss: 1.3716
2022-07-06 01:14:22 - train: epoch 0068, iter [00700, 05004], lr: 0.001000, loss: 1.3032
2022-07-06 01:14:56 - train: epoch 0068, iter [00800, 05004], lr: 0.001000, loss: 1.3682
2022-07-06 01:15:29 - train: epoch 0068, iter [00900, 05004], lr: 0.001000, loss: 1.2369
2022-07-06 01:16:02 - train: epoch 0068, iter [01000, 05004], lr: 0.001000, loss: 1.4439
2022-07-06 01:16:33 - train: epoch 0068, iter [01100, 05004], lr: 0.001000, loss: 1.4442
2022-07-06 01:17:07 - train: epoch 0068, iter [01200, 05004], lr: 0.001000, loss: 1.2113
2022-07-06 01:17:40 - train: epoch 0068, iter [01300, 05004], lr: 0.001000, loss: 1.2815
2022-07-06 01:18:14 - train: epoch 0068, iter [01400, 05004], lr: 0.001000, loss: 1.2129
2022-07-06 01:18:47 - train: epoch 0068, iter [01500, 05004], lr: 0.001000, loss: 1.2871
2022-07-06 01:19:19 - train: epoch 0068, iter [01600, 05004], lr: 0.001000, loss: 1.4285
2022-07-06 01:19:52 - train: epoch 0068, iter [01700, 05004], lr: 0.001000, loss: 1.3918
2022-07-06 01:20:27 - train: epoch 0068, iter [01800, 05004], lr: 0.001000, loss: 1.5241
2022-07-06 01:20:59 - train: epoch 0068, iter [01900, 05004], lr: 0.001000, loss: 1.2513
2022-07-06 01:21:33 - train: epoch 0068, iter [02000, 05004], lr: 0.001000, loss: 1.5111
2022-07-06 01:22:05 - train: epoch 0068, iter [02100, 05004], lr: 0.001000, loss: 1.3714
2022-07-06 01:22:39 - train: epoch 0068, iter [02200, 05004], lr: 0.001000, loss: 1.3233
2022-07-06 01:23:13 - train: epoch 0068, iter [02300, 05004], lr: 0.001000, loss: 1.1930
2022-07-06 01:23:45 - train: epoch 0068, iter [02400, 05004], lr: 0.001000, loss: 1.5563
2022-07-06 01:24:19 - train: epoch 0068, iter [02500, 05004], lr: 0.001000, loss: 1.4214
2022-07-06 01:24:52 - train: epoch 0068, iter [02600, 05004], lr: 0.001000, loss: 1.2636
2022-07-06 01:25:25 - train: epoch 0068, iter [02700, 05004], lr: 0.001000, loss: 1.2657
2022-07-06 01:25:59 - train: epoch 0068, iter [02800, 05004], lr: 0.001000, loss: 1.3457
2022-07-06 01:26:32 - train: epoch 0068, iter [02900, 05004], lr: 0.001000, loss: 1.5548
2022-07-06 01:27:04 - train: epoch 0068, iter [03000, 05004], lr: 0.001000, loss: 1.2641
2022-07-06 01:27:37 - train: epoch 0068, iter [03100, 05004], lr: 0.001000, loss: 1.1511
2022-07-06 01:28:11 - train: epoch 0068, iter [03200, 05004], lr: 0.001000, loss: 1.4391
2022-07-06 01:28:44 - train: epoch 0068, iter [03300, 05004], lr: 0.001000, loss: 1.3778
2022-07-06 01:29:18 - train: epoch 0068, iter [03400, 05004], lr: 0.001000, loss: 1.1641
2022-07-06 01:29:51 - train: epoch 0068, iter [03500, 05004], lr: 0.001000, loss: 1.2667
2022-07-06 01:30:24 - train: epoch 0068, iter [03600, 05004], lr: 0.001000, loss: 1.2854
2022-07-06 01:30:57 - train: epoch 0068, iter [03700, 05004], lr: 0.001000, loss: 1.3841
2022-07-06 01:31:31 - train: epoch 0068, iter [03800, 05004], lr: 0.001000, loss: 1.3649
2022-07-06 01:32:04 - train: epoch 0068, iter [03900, 05004], lr: 0.001000, loss: 1.3266
2022-07-06 01:32:38 - train: epoch 0068, iter [04000, 05004], lr: 0.001000, loss: 1.2009
2022-07-06 01:33:11 - train: epoch 0068, iter [04100, 05004], lr: 0.001000, loss: 1.3129
2022-07-06 01:33:45 - train: epoch 0068, iter [04200, 05004], lr: 0.001000, loss: 1.2320
2022-07-06 01:34:18 - train: epoch 0068, iter [04300, 05004], lr: 0.001000, loss: 1.1556
2022-07-06 01:34:51 - train: epoch 0068, iter [04400, 05004], lr: 0.001000, loss: 1.1786
2022-07-06 01:35:24 - train: epoch 0068, iter [04500, 05004], lr: 0.001000, loss: 1.2679
2022-07-06 01:35:57 - train: epoch 0068, iter [04600, 05004], lr: 0.001000, loss: 1.3902
2022-07-06 01:36:29 - train: epoch 0068, iter [04700, 05004], lr: 0.001000, loss: 1.4709
2022-07-06 01:37:03 - train: epoch 0068, iter [04800, 05004], lr: 0.001000, loss: 1.3467
2022-07-06 01:37:37 - train: epoch 0068, iter [04900, 05004], lr: 0.001000, loss: 1.1274
2022-07-06 01:38:08 - train: epoch 0068, iter [05000, 05004], lr: 0.001000, loss: 1.3061
2022-07-06 01:38:09 - train: epoch 068, train_loss: 1.3118
2022-07-06 01:39:22 - eval: epoch: 068, acc1: 69.746%, acc5: 89.110%, test_loss: 1.2307, per_image_load_time: 2.143ms, per_image_inference_time: 0.167ms
2022-07-06 01:39:22 - until epoch: 068, best_acc1: 69.746%
2022-07-06 01:39:22 - epoch 069 lr: 0.001000
2022-07-06 01:40:00 - train: epoch 0069, iter [00100, 05004], lr: 0.001000, loss: 1.4302
2022-07-06 01:40:33 - train: epoch 0069, iter [00200, 05004], lr: 0.001000, loss: 1.2429
2022-07-06 01:41:06 - train: epoch 0069, iter [00300, 05004], lr: 0.001000, loss: 1.5518
2022-07-06 01:41:38 - train: epoch 0069, iter [00400, 05004], lr: 0.001000, loss: 1.1849
2022-07-06 01:42:11 - train: epoch 0069, iter [00500, 05004], lr: 0.001000, loss: 1.5227
2022-07-06 01:42:44 - train: epoch 0069, iter [00600, 05004], lr: 0.001000, loss: 1.1813
2022-07-06 01:43:17 - train: epoch 0069, iter [00700, 05004], lr: 0.001000, loss: 1.2203
2022-07-06 01:43:50 - train: epoch 0069, iter [00800, 05004], lr: 0.001000, loss: 1.3725
2022-07-06 01:44:23 - train: epoch 0069, iter [00900, 05004], lr: 0.001000, loss: 1.0401
2022-07-06 01:44:57 - train: epoch 0069, iter [01000, 05004], lr: 0.001000, loss: 1.3777
2022-07-06 01:45:29 - train: epoch 0069, iter [01100, 05004], lr: 0.001000, loss: 1.4096
2022-07-06 01:46:03 - train: epoch 0069, iter [01200, 05004], lr: 0.001000, loss: 1.2772
2022-07-06 01:46:35 - train: epoch 0069, iter [01300, 05004], lr: 0.001000, loss: 1.5711
2022-07-06 01:47:09 - train: epoch 0069, iter [01400, 05004], lr: 0.001000, loss: 1.2692
2022-07-06 01:47:41 - train: epoch 0069, iter [01500, 05004], lr: 0.001000, loss: 1.4097
2022-07-06 01:48:15 - train: epoch 0069, iter [01600, 05004], lr: 0.001000, loss: 1.4741
2022-07-06 01:48:48 - train: epoch 0069, iter [01700, 05004], lr: 0.001000, loss: 1.2665
2022-07-06 01:49:21 - train: epoch 0069, iter [01800, 05004], lr: 0.001000, loss: 1.2961
2022-07-06 01:49:53 - train: epoch 0069, iter [01900, 05004], lr: 0.001000, loss: 1.2795
2022-07-06 01:50:27 - train: epoch 0069, iter [02000, 05004], lr: 0.001000, loss: 1.1685
2022-07-06 01:50:59 - train: epoch 0069, iter [02100, 05004], lr: 0.001000, loss: 1.2905
2022-07-06 01:51:33 - train: epoch 0069, iter [02200, 05004], lr: 0.001000, loss: 1.4566
2022-07-06 01:52:05 - train: epoch 0069, iter [02300, 05004], lr: 0.001000, loss: 1.1155
2022-07-06 01:52:39 - train: epoch 0069, iter [02400, 05004], lr: 0.001000, loss: 1.3257
2022-07-06 01:53:12 - train: epoch 0069, iter [02500, 05004], lr: 0.001000, loss: 1.1851
2022-07-06 01:53:45 - train: epoch 0069, iter [02600, 05004], lr: 0.001000, loss: 1.3708
2022-07-06 01:54:18 - train: epoch 0069, iter [02700, 05004], lr: 0.001000, loss: 1.2508
2022-07-06 01:54:51 - train: epoch 0069, iter [02800, 05004], lr: 0.001000, loss: 1.2792
2022-07-06 01:55:24 - train: epoch 0069, iter [02900, 05004], lr: 0.001000, loss: 1.2251
2022-07-06 01:55:58 - train: epoch 0069, iter [03000, 05004], lr: 0.001000, loss: 1.2046
2022-07-06 01:56:31 - train: epoch 0069, iter [03100, 05004], lr: 0.001000, loss: 1.4040
2022-07-06 01:57:04 - train: epoch 0069, iter [03200, 05004], lr: 0.001000, loss: 1.3497
2022-07-06 01:57:36 - train: epoch 0069, iter [03300, 05004], lr: 0.001000, loss: 1.2702
2022-07-06 01:58:10 - train: epoch 0069, iter [03400, 05004], lr: 0.001000, loss: 1.1764
2022-07-06 01:58:43 - train: epoch 0069, iter [03500, 05004], lr: 0.001000, loss: 1.1876
2022-07-06 01:59:16 - train: epoch 0069, iter [03600, 05004], lr: 0.001000, loss: 1.1246
2022-07-06 01:59:49 - train: epoch 0069, iter [03700, 05004], lr: 0.001000, loss: 1.4518
2022-07-06 02:00:23 - train: epoch 0069, iter [03800, 05004], lr: 0.001000, loss: 1.4442
2022-07-06 02:00:55 - train: epoch 0069, iter [03900, 05004], lr: 0.001000, loss: 1.3557
2022-07-06 02:01:29 - train: epoch 0069, iter [04000, 05004], lr: 0.001000, loss: 1.4681
2022-07-06 02:02:02 - train: epoch 0069, iter [04100, 05004], lr: 0.001000, loss: 1.4017
2022-07-06 02:02:35 - train: epoch 0069, iter [04200, 05004], lr: 0.001000, loss: 1.2765
2022-07-06 02:03:09 - train: epoch 0069, iter [04300, 05004], lr: 0.001000, loss: 1.3477
2022-07-06 02:03:43 - train: epoch 0069, iter [04400, 05004], lr: 0.001000, loss: 1.4177
2022-07-06 02:04:15 - train: epoch 0069, iter [04500, 05004], lr: 0.001000, loss: 1.3717
2022-07-06 02:04:48 - train: epoch 0069, iter [04600, 05004], lr: 0.001000, loss: 1.3907
2022-07-06 02:05:22 - train: epoch 0069, iter [04700, 05004], lr: 0.001000, loss: 1.2127
2022-07-06 02:05:56 - train: epoch 0069, iter [04800, 05004], lr: 0.001000, loss: 1.3744
2022-07-06 02:06:28 - train: epoch 0069, iter [04900, 05004], lr: 0.001000, loss: 1.1669
2022-07-06 02:06:59 - train: epoch 0069, iter [05000, 05004], lr: 0.001000, loss: 1.1910
2022-07-06 02:07:00 - train: epoch 069, train_loss: 1.3047
2022-07-06 02:08:13 - eval: epoch: 069, acc1: 69.718%, acc5: 89.116%, test_loss: 1.2308, per_image_load_time: 2.650ms, per_image_inference_time: 0.174ms
2022-07-06 02:08:14 - until epoch: 069, best_acc1: 69.746%
2022-07-06 02:08:14 - epoch 070 lr: 0.001000
2022-07-06 02:08:51 - train: epoch 0070, iter [00100, 05004], lr: 0.001000, loss: 1.3412
2022-07-06 02:09:24 - train: epoch 0070, iter [00200, 05004], lr: 0.001000, loss: 1.4108
2022-07-06 02:09:57 - train: epoch 0070, iter [00300, 05004], lr: 0.001000, loss: 1.3712
2022-07-06 02:10:29 - train: epoch 0070, iter [00400, 05004], lr: 0.001000, loss: 1.2882
2022-07-06 02:11:02 - train: epoch 0070, iter [00500, 05004], lr: 0.001000, loss: 1.2294
2022-07-06 02:11:35 - train: epoch 0070, iter [00600, 05004], lr: 0.001000, loss: 1.4131
2022-07-06 02:12:08 - train: epoch 0070, iter [00700, 05004], lr: 0.001000, loss: 1.2060
2022-07-06 02:12:40 - train: epoch 0070, iter [00800, 05004], lr: 0.001000, loss: 1.2685
2022-07-06 02:13:14 - train: epoch 0070, iter [00900, 05004], lr: 0.001000, loss: 1.2839
2022-07-06 02:13:46 - train: epoch 0070, iter [01000, 05004], lr: 0.001000, loss: 1.2265
2022-07-06 02:14:20 - train: epoch 0070, iter [01100, 05004], lr: 0.001000, loss: 1.5899
2022-07-06 02:14:52 - train: epoch 0070, iter [01200, 05004], lr: 0.001000, loss: 1.1759
2022-07-06 02:15:25 - train: epoch 0070, iter [01300, 05004], lr: 0.001000, loss: 1.2137
2022-07-06 02:15:58 - train: epoch 0070, iter [01400, 05004], lr: 0.001000, loss: 1.2530
2022-07-06 02:16:30 - train: epoch 0070, iter [01500, 05004], lr: 0.001000, loss: 1.4163
2022-07-06 02:17:05 - train: epoch 0070, iter [01600, 05004], lr: 0.001000, loss: 1.3749
2022-07-06 02:17:37 - train: epoch 0070, iter [01700, 05004], lr: 0.001000, loss: 1.4643
2022-07-06 02:18:10 - train: epoch 0070, iter [01800, 05004], lr: 0.001000, loss: 1.1598
2022-07-06 02:18:44 - train: epoch 0070, iter [01900, 05004], lr: 0.001000, loss: 1.2778
2022-07-06 02:19:17 - train: epoch 0070, iter [02000, 05004], lr: 0.001000, loss: 1.3647
2022-07-06 02:19:50 - train: epoch 0070, iter [02100, 05004], lr: 0.001000, loss: 1.4242
2022-07-06 02:20:23 - train: epoch 0070, iter [02200, 05004], lr: 0.001000, loss: 1.3384
2022-07-06 02:20:56 - train: epoch 0070, iter [02300, 05004], lr: 0.001000, loss: 1.4357
2022-07-06 02:21:30 - train: epoch 0070, iter [02400, 05004], lr: 0.001000, loss: 1.2380
2022-07-06 02:22:03 - train: epoch 0070, iter [02500, 05004], lr: 0.001000, loss: 1.2484
2022-07-06 02:22:37 - train: epoch 0070, iter [02600, 05004], lr: 0.001000, loss: 1.2428
2022-07-06 02:23:09 - train: epoch 0070, iter [02700, 05004], lr: 0.001000, loss: 1.3884
2022-07-06 02:23:43 - train: epoch 0070, iter [02800, 05004], lr: 0.001000, loss: 1.5061
2022-07-06 02:24:16 - train: epoch 0070, iter [02900, 05004], lr: 0.001000, loss: 1.3095
2022-07-06 02:24:49 - train: epoch 0070, iter [03000, 05004], lr: 0.001000, loss: 1.2639
2022-07-06 02:25:22 - train: epoch 0070, iter [03100, 05004], lr: 0.001000, loss: 1.2596
2022-07-06 02:25:55 - train: epoch 0070, iter [03200, 05004], lr: 0.001000, loss: 1.3860
2022-07-06 02:26:28 - train: epoch 0070, iter [03300, 05004], lr: 0.001000, loss: 1.1710
2022-07-06 02:27:02 - train: epoch 0070, iter [03400, 05004], lr: 0.001000, loss: 1.3839
2022-07-06 02:27:34 - train: epoch 0070, iter [03500, 05004], lr: 0.001000, loss: 1.3678
2022-07-06 02:28:08 - train: epoch 0070, iter [03600, 05004], lr: 0.001000, loss: 1.3278
2022-07-06 02:28:41 - train: epoch 0070, iter [03700, 05004], lr: 0.001000, loss: 1.3858
2022-07-06 02:29:15 - train: epoch 0070, iter [03800, 05004], lr: 0.001000, loss: 1.2309
2022-07-06 02:29:47 - train: epoch 0070, iter [03900, 05004], lr: 0.001000, loss: 1.1324
2022-07-06 02:30:21 - train: epoch 0070, iter [04000, 05004], lr: 0.001000, loss: 1.3431
2022-07-06 02:30:53 - train: epoch 0070, iter [04100, 05004], lr: 0.001000, loss: 1.2195
2022-07-06 02:31:26 - train: epoch 0070, iter [04200, 05004], lr: 0.001000, loss: 1.1333
2022-07-06 02:32:00 - train: epoch 0070, iter [04300, 05004], lr: 0.001000, loss: 1.3289
2022-07-06 02:32:34 - train: epoch 0070, iter [04400, 05004], lr: 0.001000, loss: 1.3884
2022-07-06 02:33:06 - train: epoch 0070, iter [04500, 05004], lr: 0.001000, loss: 1.4068
2022-07-06 02:33:40 - train: epoch 0070, iter [04600, 05004], lr: 0.001000, loss: 1.4372
2022-07-06 02:34:13 - train: epoch 0070, iter [04700, 05004], lr: 0.001000, loss: 1.3528
2022-07-06 02:34:46 - train: epoch 0070, iter [04800, 05004], lr: 0.001000, loss: 1.4421
2022-07-06 02:35:19 - train: epoch 0070, iter [04900, 05004], lr: 0.001000, loss: 1.4716
2022-07-06 02:35:51 - train: epoch 0070, iter [05000, 05004], lr: 0.001000, loss: 1.5472
2022-07-06 02:35:52 - train: epoch 070, train_loss: 1.2997
2022-07-06 02:37:05 - eval: epoch: 070, acc1: 69.922%, acc5: 89.130%, test_loss: 1.2282, per_image_load_time: 2.622ms, per_image_inference_time: 0.190ms
2022-07-06 02:37:05 - until epoch: 070, best_acc1: 69.922%
2022-07-06 02:37:05 - epoch 071 lr: 0.001000
2022-07-06 02:37:43 - train: epoch 0071, iter [00100, 05004], lr: 0.001000, loss: 1.1810
2022-07-06 02:38:17 - train: epoch 0071, iter [00200, 05004], lr: 0.001000, loss: 1.1190
2022-07-06 02:38:48 - train: epoch 0071, iter [00300, 05004], lr: 0.001000, loss: 1.4722
2022-07-06 02:39:21 - train: epoch 0071, iter [00400, 05004], lr: 0.001000, loss: 1.1837
2022-07-06 02:39:54 - train: epoch 0071, iter [00500, 05004], lr: 0.001000, loss: 1.4631
2022-07-06 02:40:26 - train: epoch 0071, iter [00600, 05004], lr: 0.001000, loss: 1.2117
2022-07-06 02:41:00 - train: epoch 0071, iter [00700, 05004], lr: 0.001000, loss: 1.3407
2022-07-06 02:41:32 - train: epoch 0071, iter [00800, 05004], lr: 0.001000, loss: 1.2712
2022-07-06 02:42:06 - train: epoch 0071, iter [00900, 05004], lr: 0.001000, loss: 1.3523
2022-07-06 02:42:38 - train: epoch 0071, iter [01000, 05004], lr: 0.001000, loss: 1.2337
2022-07-06 02:43:11 - train: epoch 0071, iter [01100, 05004], lr: 0.001000, loss: 1.4709
2022-07-06 02:43:45 - train: epoch 0071, iter [01200, 05004], lr: 0.001000, loss: 1.1657
2022-07-06 02:44:18 - train: epoch 0071, iter [01300, 05004], lr: 0.001000, loss: 1.2960
2022-07-06 02:44:51 - train: epoch 0071, iter [01400, 05004], lr: 0.001000, loss: 1.1981
2022-07-06 02:45:23 - train: epoch 0071, iter [01500, 05004], lr: 0.001000, loss: 1.1761
2022-07-06 02:45:58 - train: epoch 0071, iter [01600, 05004], lr: 0.001000, loss: 1.2387
2022-07-06 02:46:29 - train: epoch 0071, iter [01700, 05004], lr: 0.001000, loss: 1.1570
2022-07-06 02:47:03 - train: epoch 0071, iter [01800, 05004], lr: 0.001000, loss: 1.3428
2022-07-06 02:47:36 - train: epoch 0071, iter [01900, 05004], lr: 0.001000, loss: 1.2528
2022-07-06 02:48:10 - train: epoch 0071, iter [02000, 05004], lr: 0.001000, loss: 1.3553
2022-07-06 02:48:43 - train: epoch 0071, iter [02100, 05004], lr: 0.001000, loss: 1.2003
2022-07-06 02:49:15 - train: epoch 0071, iter [02200, 05004], lr: 0.001000, loss: 1.2740
2022-07-06 02:49:50 - train: epoch 0071, iter [02300, 05004], lr: 0.001000, loss: 1.1631
2022-07-06 02:50:22 - train: epoch 0071, iter [02400, 05004], lr: 0.001000, loss: 1.1854
2022-07-06 02:50:56 - train: epoch 0071, iter [02500, 05004], lr: 0.001000, loss: 1.3482
2022-07-06 02:51:28 - train: epoch 0071, iter [02600, 05004], lr: 0.001000, loss: 1.2320
2022-07-06 02:52:01 - train: epoch 0071, iter [02700, 05004], lr: 0.001000, loss: 1.3613
2022-07-06 02:52:34 - train: epoch 0071, iter [02800, 05004], lr: 0.001000, loss: 1.3919
2022-07-06 02:53:08 - train: epoch 0071, iter [02900, 05004], lr: 0.001000, loss: 1.2484
2022-07-06 02:53:41 - train: epoch 0071, iter [03000, 05004], lr: 0.001000, loss: 1.2899
2022-07-06 02:54:14 - train: epoch 0071, iter [03100, 05004], lr: 0.001000, loss: 1.3036
2022-07-06 02:54:47 - train: epoch 0071, iter [03200, 05004], lr: 0.001000, loss: 1.2220
2022-07-06 02:55:21 - train: epoch 0071, iter [03300, 05004], lr: 0.001000, loss: 1.1146
2022-07-06 02:55:55 - train: epoch 0071, iter [03400, 05004], lr: 0.001000, loss: 1.3254
2022-07-06 02:56:27 - train: epoch 0071, iter [03500, 05004], lr: 0.001000, loss: 1.2974
2022-07-06 02:56:59 - train: epoch 0071, iter [03600, 05004], lr: 0.001000, loss: 1.4243
2022-07-06 02:57:32 - train: epoch 0071, iter [03700, 05004], lr: 0.001000, loss: 1.3706
2022-07-06 02:58:06 - train: epoch 0071, iter [03800, 05004], lr: 0.001000, loss: 1.2923
2022-07-06 02:58:39 - train: epoch 0071, iter [03900, 05004], lr: 0.001000, loss: 1.4199
2022-07-06 02:59:13 - train: epoch 0071, iter [04000, 05004], lr: 0.001000, loss: 1.4210
2022-07-06 02:59:45 - train: epoch 0071, iter [04100, 05004], lr: 0.001000, loss: 1.2776
2022-07-06 03:00:19 - train: epoch 0071, iter [04200, 05004], lr: 0.001000, loss: 1.5899
2022-07-06 03:00:51 - train: epoch 0071, iter [04300, 05004], lr: 0.001000, loss: 1.1810
2022-07-06 03:01:25 - train: epoch 0071, iter [04400, 05004], lr: 0.001000, loss: 1.3789
2022-07-06 03:01:58 - train: epoch 0071, iter [04500, 05004], lr: 0.001000, loss: 1.4458
2022-07-06 03:02:32 - train: epoch 0071, iter [04600, 05004], lr: 0.001000, loss: 1.4026
2022-07-06 03:03:06 - train: epoch 0071, iter [04700, 05004], lr: 0.001000, loss: 1.3169
2022-07-06 03:03:39 - train: epoch 0071, iter [04800, 05004], lr: 0.001000, loss: 1.2369
2022-07-06 03:04:13 - train: epoch 0071, iter [04900, 05004], lr: 0.001000, loss: 1.2204
2022-07-06 03:04:43 - train: epoch 0071, iter [05000, 05004], lr: 0.001000, loss: 1.0611
2022-07-06 03:04:44 - train: epoch 071, train_loss: 1.2959
2022-07-06 03:05:57 - eval: epoch: 071, acc1: 69.928%, acc5: 89.276%, test_loss: 1.2263, per_image_load_time: 2.597ms, per_image_inference_time: 0.175ms
2022-07-06 03:05:57 - until epoch: 071, best_acc1: 69.928%
2022-07-06 03:05:57 - epoch 072 lr: 0.001000
2022-07-06 03:06:35 - train: epoch 0072, iter [00100, 05004], lr: 0.001000, loss: 1.4086
2022-07-06 03:07:08 - train: epoch 0072, iter [00200, 05004], lr: 0.001000, loss: 1.2121
2022-07-06 03:07:41 - train: epoch 0072, iter [00300, 05004], lr: 0.001000, loss: 1.1555
2022-07-06 03:08:14 - train: epoch 0072, iter [00400, 05004], lr: 0.001000, loss: 1.2976
2022-07-06 03:08:46 - train: epoch 0072, iter [00500, 05004], lr: 0.001000, loss: 1.3441
2022-07-06 03:09:20 - train: epoch 0072, iter [00600, 05004], lr: 0.001000, loss: 1.1318
2022-07-06 03:09:52 - train: epoch 0072, iter [00700, 05004], lr: 0.001000, loss: 1.5329
2022-07-06 03:10:25 - train: epoch 0072, iter [00800, 05004], lr: 0.001000, loss: 1.3903
2022-07-06 03:10:58 - train: epoch 0072, iter [00900, 05004], lr: 0.001000, loss: 1.2906
2022-07-06 03:11:32 - train: epoch 0072, iter [01000, 05004], lr: 0.001000, loss: 1.2060
2022-07-06 03:12:04 - train: epoch 0072, iter [01100, 05004], lr: 0.001000, loss: 1.2920
2022-07-06 03:12:38 - train: epoch 0072, iter [01200, 05004], lr: 0.001000, loss: 1.2607
2022-07-06 03:13:11 - train: epoch 0072, iter [01300, 05004], lr: 0.001000, loss: 1.2466
2022-07-06 03:13:44 - train: epoch 0072, iter [01400, 05004], lr: 0.001000, loss: 1.2410
2022-07-06 03:14:17 - train: epoch 0072, iter [01500, 05004], lr: 0.001000, loss: 1.2877
2022-07-06 03:14:51 - train: epoch 0072, iter [01600, 05004], lr: 0.001000, loss: 1.2299
2022-07-06 03:15:24 - train: epoch 0072, iter [01700, 05004], lr: 0.001000, loss: 1.2915
2022-07-06 03:15:57 - train: epoch 0072, iter [01800, 05004], lr: 0.001000, loss: 1.2122
2022-07-06 03:16:31 - train: epoch 0072, iter [01900, 05004], lr: 0.001000, loss: 1.4006
2022-07-06 03:17:03 - train: epoch 0072, iter [02000, 05004], lr: 0.001000, loss: 1.1743
2022-07-06 03:17:36 - train: epoch 0072, iter [02100, 05004], lr: 0.001000, loss: 1.5326
2022-07-06 03:18:09 - train: epoch 0072, iter [02200, 05004], lr: 0.001000, loss: 1.4035
2022-07-06 03:18:44 - train: epoch 0072, iter [02300, 05004], lr: 0.001000, loss: 1.3032
2022-07-06 03:19:16 - train: epoch 0072, iter [02400, 05004], lr: 0.001000, loss: 1.3832
2022-07-06 03:19:50 - train: epoch 0072, iter [02500, 05004], lr: 0.001000, loss: 1.2695
2022-07-06 03:20:22 - train: epoch 0072, iter [02600, 05004], lr: 0.001000, loss: 1.1437
2022-07-06 03:20:56 - train: epoch 0072, iter [02700, 05004], lr: 0.001000, loss: 1.2743
2022-07-06 03:21:29 - train: epoch 0072, iter [02800, 05004], lr: 0.001000, loss: 1.2527
2022-07-06 03:22:02 - train: epoch 0072, iter [02900, 05004], lr: 0.001000, loss: 1.1663
2022-07-06 03:22:36 - train: epoch 0072, iter [03000, 05004], lr: 0.001000, loss: 1.2343
2022-07-06 03:23:09 - train: epoch 0072, iter [03100, 05004], lr: 0.001000, loss: 1.3776
2022-07-06 03:23:42 - train: epoch 0072, iter [03200, 05004], lr: 0.001000, loss: 1.4382
2022-07-06 03:24:16 - train: epoch 0072, iter [03300, 05004], lr: 0.001000, loss: 1.2524
2022-07-06 03:24:48 - train: epoch 0072, iter [03400, 05004], lr: 0.001000, loss: 1.4120
2022-07-06 03:25:22 - train: epoch 0072, iter [03500, 05004], lr: 0.001000, loss: 1.3619
2022-07-06 03:25:55 - train: epoch 0072, iter [03600, 05004], lr: 0.001000, loss: 1.3829
2022-07-06 03:26:28 - train: epoch 0072, iter [03700, 05004], lr: 0.001000, loss: 1.4697
2022-07-06 03:27:02 - train: epoch 0072, iter [03800, 05004], lr: 0.001000, loss: 1.3519
2022-07-06 03:27:36 - train: epoch 0072, iter [03900, 05004], lr: 0.001000, loss: 1.2082
2022-07-06 03:28:09 - train: epoch 0072, iter [04000, 05004], lr: 0.001000, loss: 1.3008
2022-07-06 03:28:43 - train: epoch 0072, iter [04100, 05004], lr: 0.001000, loss: 1.3595
2022-07-06 03:29:16 - train: epoch 0072, iter [04200, 05004], lr: 0.001000, loss: 1.0398
2022-07-06 03:29:49 - train: epoch 0072, iter [04300, 05004], lr: 0.001000, loss: 1.0603
2022-07-06 03:30:23 - train: epoch 0072, iter [04400, 05004], lr: 0.001000, loss: 1.3795
2022-07-06 03:30:55 - train: epoch 0072, iter [04500, 05004], lr: 0.001000, loss: 1.3516
2022-07-06 03:31:28 - train: epoch 0072, iter [04600, 05004], lr: 0.001000, loss: 1.2423
2022-07-06 03:32:01 - train: epoch 0072, iter [04700, 05004], lr: 0.001000, loss: 1.4883
2022-07-06 03:32:35 - train: epoch 0072, iter [04800, 05004], lr: 0.001000, loss: 1.4398
2022-07-06 03:33:08 - train: epoch 0072, iter [04900, 05004], lr: 0.001000, loss: 1.3722
2022-07-06 03:33:40 - train: epoch 0072, iter [05000, 05004], lr: 0.001000, loss: 1.2804
2022-07-06 03:33:40 - train: epoch 072, train_loss: 1.2919
2022-07-06 03:34:53 - eval: epoch: 072, acc1: 69.840%, acc5: 89.150%, test_loss: 1.2270, per_image_load_time: 2.644ms, per_image_inference_time: 0.186ms
2022-07-06 03:34:53 - until epoch: 072, best_acc1: 69.928%
2022-07-06 03:34:53 - epoch 073 lr: 0.001000
2022-07-06 03:35:32 - train: epoch 0073, iter [00100, 05004], lr: 0.001000, loss: 1.5521
2022-07-06 03:36:04 - train: epoch 0073, iter [00200, 05004], lr: 0.001000, loss: 1.4225
2022-07-06 03:36:37 - train: epoch 0073, iter [00300, 05004], lr: 0.001000, loss: 1.4767
2022-07-06 03:37:10 - train: epoch 0073, iter [00400, 05004], lr: 0.001000, loss: 1.0800
2022-07-06 03:37:43 - train: epoch 0073, iter [00500, 05004], lr: 0.001000, loss: 1.2472
2022-07-06 03:38:16 - train: epoch 0073, iter [00600, 05004], lr: 0.001000, loss: 1.1098
2022-07-06 03:38:49 - train: epoch 0073, iter [00700, 05004], lr: 0.001000, loss: 1.2725
2022-07-06 03:39:22 - train: epoch 0073, iter [00800, 05004], lr: 0.001000, loss: 1.0934
2022-07-06 03:39:55 - train: epoch 0073, iter [00900, 05004], lr: 0.001000, loss: 1.1994
2022-07-06 03:40:28 - train: epoch 0073, iter [01000, 05004], lr: 0.001000, loss: 1.3561
2022-07-06 03:41:01 - train: epoch 0073, iter [01100, 05004], lr: 0.001000, loss: 1.4282
2022-07-06 03:41:33 - train: epoch 0073, iter [01200, 05004], lr: 0.001000, loss: 1.2376
2022-07-06 03:42:08 - train: epoch 0073, iter [01300, 05004], lr: 0.001000, loss: 1.3726
2022-07-06 03:42:40 - train: epoch 0073, iter [01400, 05004], lr: 0.001000, loss: 1.1043
2022-07-06 03:43:14 - train: epoch 0073, iter [01500, 05004], lr: 0.001000, loss: 1.1347
2022-07-06 03:43:47 - train: epoch 0073, iter [01600, 05004], lr: 0.001000, loss: 1.4651
2022-07-06 03:44:19 - train: epoch 0073, iter [01700, 05004], lr: 0.001000, loss: 1.5152
2022-07-06 03:44:52 - train: epoch 0073, iter [01800, 05004], lr: 0.001000, loss: 1.1041
2022-07-06 03:45:26 - train: epoch 0073, iter [01900, 05004], lr: 0.001000, loss: 1.2497
2022-07-06 03:45:59 - train: epoch 0073, iter [02000, 05004], lr: 0.001000, loss: 1.3236
2022-07-06 03:46:33 - train: epoch 0073, iter [02100, 05004], lr: 0.001000, loss: 1.3096
2022-07-06 03:47:05 - train: epoch 0073, iter [02200, 05004], lr: 0.001000, loss: 1.2533
2022-07-06 03:47:38 - train: epoch 0073, iter [02300, 05004], lr: 0.001000, loss: 1.3980
2022-07-06 03:48:11 - train: epoch 0073, iter [02400, 05004], lr: 0.001000, loss: 1.2493
2022-07-06 03:48:45 - train: epoch 0073, iter [02500, 05004], lr: 0.001000, loss: 1.2919
2022-07-06 03:49:18 - train: epoch 0073, iter [02600, 05004], lr: 0.001000, loss: 1.3146
2022-07-06 03:49:51 - train: epoch 0073, iter [02700, 05004], lr: 0.001000, loss: 1.3530
2022-07-06 03:50:25 - train: epoch 0073, iter [02800, 05004], lr: 0.001000, loss: 1.2983
2022-07-06 03:50:58 - train: epoch 0073, iter [02900, 05004], lr: 0.001000, loss: 1.3820
2022-07-06 03:51:31 - train: epoch 0073, iter [03000, 05004], lr: 0.001000, loss: 1.1278
2022-07-06 03:52:04 - train: epoch 0073, iter [03100, 05004], lr: 0.001000, loss: 1.3059
2022-07-06 03:52:38 - train: epoch 0073, iter [03200, 05004], lr: 0.001000, loss: 1.2090
2022-07-06 03:53:11 - train: epoch 0073, iter [03300, 05004], lr: 0.001000, loss: 1.1925
2022-07-06 03:53:44 - train: epoch 0073, iter [03400, 05004], lr: 0.001000, loss: 1.1157
2022-07-06 03:54:17 - train: epoch 0073, iter [03500, 05004], lr: 0.001000, loss: 1.2991
2022-07-06 03:54:50 - train: epoch 0073, iter [03600, 05004], lr: 0.001000, loss: 1.2579
2022-07-06 03:55:23 - train: epoch 0073, iter [03700, 05004], lr: 0.001000, loss: 1.3240
2022-07-06 03:55:57 - train: epoch 0073, iter [03800, 05004], lr: 0.001000, loss: 1.3611
2022-07-06 03:56:29 - train: epoch 0073, iter [03900, 05004], lr: 0.001000, loss: 1.1931
2022-07-06 03:57:03 - train: epoch 0073, iter [04000, 05004], lr: 0.001000, loss: 1.4242
2022-07-06 03:57:35 - train: epoch 0073, iter [04100, 05004], lr: 0.001000, loss: 1.2946
2022-07-06 03:58:09 - train: epoch 0073, iter [04200, 05004], lr: 0.001000, loss: 1.4647
2022-07-06 03:58:42 - train: epoch 0073, iter [04300, 05004], lr: 0.001000, loss: 1.4330
2022-07-06 03:59:15 - train: epoch 0073, iter [04400, 05004], lr: 0.001000, loss: 1.2638
2022-07-06 03:59:49 - train: epoch 0073, iter [04500, 05004], lr: 0.001000, loss: 1.3437
2022-07-06 04:00:22 - train: epoch 0073, iter [04600, 05004], lr: 0.001000, loss: 1.3952
2022-07-06 04:00:55 - train: epoch 0073, iter [04700, 05004], lr: 0.001000, loss: 1.0485
2022-07-06 04:01:28 - train: epoch 0073, iter [04800, 05004], lr: 0.001000, loss: 1.2968
2022-07-06 04:02:02 - train: epoch 0073, iter [04900, 05004], lr: 0.001000, loss: 1.2349
2022-07-06 04:02:33 - train: epoch 0073, iter [05000, 05004], lr: 0.001000, loss: 1.2121
2022-07-06 04:02:34 - train: epoch 073, train_loss: 1.2882
2022-07-06 04:03:47 - eval: epoch: 073, acc1: 69.876%, acc5: 89.210%, test_loss: 1.2251, per_image_load_time: 2.606ms, per_image_inference_time: 0.157ms
2022-07-06 04:03:47 - until epoch: 073, best_acc1: 69.928%
2022-07-06 04:03:47 - epoch 074 lr: 0.001000
2022-07-06 04:04:25 - train: epoch 0074, iter [00100, 05004], lr: 0.001000, loss: 1.2628
2022-07-06 04:04:58 - train: epoch 0074, iter [00200, 05004], lr: 0.001000, loss: 1.4621
2022-07-06 04:05:31 - train: epoch 0074, iter [00300, 05004], lr: 0.001000, loss: 1.1790
2022-07-06 04:06:04 - train: epoch 0074, iter [00400, 05004], lr: 0.001000, loss: 1.4372
2022-07-06 04:06:37 - train: epoch 0074, iter [00500, 05004], lr: 0.001000, loss: 1.3837
2022-07-06 04:07:10 - train: epoch 0074, iter [00600, 05004], lr: 0.001000, loss: 1.1775
2022-07-06 04:07:43 - train: epoch 0074, iter [00700, 05004], lr: 0.001000, loss: 1.2550
2022-07-06 04:08:16 - train: epoch 0074, iter [00800, 05004], lr: 0.001000, loss: 1.3899
2022-07-06 04:08:50 - train: epoch 0074, iter [00900, 05004], lr: 0.001000, loss: 1.2375
2022-07-06 04:09:24 - train: epoch 0074, iter [01000, 05004], lr: 0.001000, loss: 1.4940
2022-07-06 04:09:55 - train: epoch 0074, iter [01100, 05004], lr: 0.001000, loss: 1.4091
2022-07-06 04:10:29 - train: epoch 0074, iter [01200, 05004], lr: 0.001000, loss: 1.3989
2022-07-06 04:11:01 - train: epoch 0074, iter [01300, 05004], lr: 0.001000, loss: 1.3307
2022-07-06 04:11:34 - train: epoch 0074, iter [01400, 05004], lr: 0.001000, loss: 1.1892
2022-07-06 04:12:07 - train: epoch 0074, iter [01500, 05004], lr: 0.001000, loss: 1.2083
2022-07-06 04:12:41 - train: epoch 0074, iter [01600, 05004], lr: 0.001000, loss: 1.2274
2022-07-06 04:13:13 - train: epoch 0074, iter [01700, 05004], lr: 0.001000, loss: 1.2258
2022-07-06 04:13:47 - train: epoch 0074, iter [01800, 05004], lr: 0.001000, loss: 1.3707
2022-07-06 04:14:21 - train: epoch 0074, iter [01900, 05004], lr: 0.001000, loss: 1.3821
2022-07-06 04:14:54 - train: epoch 0074, iter [02000, 05004], lr: 0.001000, loss: 0.9910
2022-07-06 04:15:27 - train: epoch 0074, iter [02100, 05004], lr: 0.001000, loss: 1.1886
2022-07-06 04:15:59 - train: epoch 0074, iter [02200, 05004], lr: 0.001000, loss: 1.4477
2022-07-06 04:16:33 - train: epoch 0074, iter [02300, 05004], lr: 0.001000, loss: 1.2326
2022-07-06 04:17:06 - train: epoch 0074, iter [02400, 05004], lr: 0.001000, loss: 1.3571
2022-07-06 04:17:40 - train: epoch 0074, iter [02500, 05004], lr: 0.001000, loss: 1.2095
2022-07-06 04:18:13 - train: epoch 0074, iter [02600, 05004], lr: 0.001000, loss: 1.1328
2022-07-06 04:18:47 - train: epoch 0074, iter [02700, 05004], lr: 0.001000, loss: 1.0636
2022-07-06 04:19:19 - train: epoch 0074, iter [02800, 05004], lr: 0.001000, loss: 1.6293
2022-07-06 04:19:51 - train: epoch 0074, iter [02900, 05004], lr: 0.001000, loss: 1.2254
2022-07-06 04:20:25 - train: epoch 0074, iter [03000, 05004], lr: 0.001000, loss: 1.3413
2022-07-06 04:20:57 - train: epoch 0074, iter [03100, 05004], lr: 0.001000, loss: 1.2443
2022-07-06 04:21:31 - train: epoch 0074, iter [03200, 05004], lr: 0.001000, loss: 1.0827
2022-07-06 04:22:04 - train: epoch 0074, iter [03300, 05004], lr: 0.001000, loss: 1.2338
2022-07-06 04:22:37 - train: epoch 0074, iter [03400, 05004], lr: 0.001000, loss: 1.2999
2022-07-06 04:23:10 - train: epoch 0074, iter [03500, 05004], lr: 0.001000, loss: 1.2252
2022-07-06 04:23:44 - train: epoch 0074, iter [03600, 05004], lr: 0.001000, loss: 1.4413
2022-07-06 04:24:17 - train: epoch 0074, iter [03700, 05004], lr: 0.001000, loss: 1.2151
2022-07-06 04:24:50 - train: epoch 0074, iter [03800, 05004], lr: 0.001000, loss: 1.2476
2022-07-06 04:25:22 - train: epoch 0074, iter [03900, 05004], lr: 0.001000, loss: 1.1539
2022-07-06 04:25:56 - train: epoch 0074, iter [04000, 05004], lr: 0.001000, loss: 1.3106
2022-07-06 04:26:28 - train: epoch 0074, iter [04100, 05004], lr: 0.001000, loss: 1.5414
2022-07-06 04:27:02 - train: epoch 0074, iter [04200, 05004], lr: 0.001000, loss: 1.4451
2022-07-06 04:27:35 - train: epoch 0074, iter [04300, 05004], lr: 0.001000, loss: 1.2874
2022-07-06 04:28:09 - train: epoch 0074, iter [04400, 05004], lr: 0.001000, loss: 1.2159
2022-07-06 04:28:41 - train: epoch 0074, iter [04500, 05004], lr: 0.001000, loss: 1.1714
2022-07-06 04:29:15 - train: epoch 0074, iter [04600, 05004], lr: 0.001000, loss: 1.4581
2022-07-06 04:29:48 - train: epoch 0074, iter [04700, 05004], lr: 0.001000, loss: 1.3843
2022-07-06 04:30:22 - train: epoch 0074, iter [04800, 05004], lr: 0.001000, loss: 1.4144
2022-07-06 04:30:54 - train: epoch 0074, iter [04900, 05004], lr: 0.001000, loss: 1.5460
2022-07-06 04:31:26 - train: epoch 0074, iter [05000, 05004], lr: 0.001000, loss: 1.3377
2022-07-06 04:31:27 - train: epoch 074, train_loss: 1.2867
2022-07-06 04:32:40 - eval: epoch: 074, acc1: 69.962%, acc5: 89.288%, test_loss: 1.2239, per_image_load_time: 2.172ms, per_image_inference_time: 0.196ms
2022-07-06 04:32:40 - until epoch: 074, best_acc1: 69.962%
2022-07-06 04:32:40 - epoch 075 lr: 0.001000
2022-07-06 04:33:19 - train: epoch 0075, iter [00100, 05004], lr: 0.001000, loss: 1.4940
2022-07-06 04:33:50 - train: epoch 0075, iter [00200, 05004], lr: 0.001000, loss: 1.3695
2022-07-06 04:34:23 - train: epoch 0075, iter [00300, 05004], lr: 0.001000, loss: 1.2730
2022-07-06 04:34:55 - train: epoch 0075, iter [00400, 05004], lr: 0.001000, loss: 1.1802
2022-07-06 04:35:29 - train: epoch 0075, iter [00500, 05004], lr: 0.001000, loss: 1.2610
2022-07-06 04:36:01 - train: epoch 0075, iter [00600, 05004], lr: 0.001000, loss: 1.1019
2022-07-06 04:36:34 - train: epoch 0075, iter [00700, 05004], lr: 0.001000, loss: 1.4432
2022-07-06 04:37:08 - train: epoch 0075, iter [00800, 05004], lr: 0.001000, loss: 1.0601
2022-07-06 04:37:41 - train: epoch 0075, iter [00900, 05004], lr: 0.001000, loss: 1.3076
2022-07-06 04:38:13 - train: epoch 0075, iter [01000, 05004], lr: 0.001000, loss: 1.1917
2022-07-06 04:38:47 - train: epoch 0075, iter [01100, 05004], lr: 0.001000, loss: 1.4890
2022-07-06 04:39:20 - train: epoch 0075, iter [01200, 05004], lr: 0.001000, loss: 1.1159
2022-07-06 04:39:53 - train: epoch 0075, iter [01300, 05004], lr: 0.001000, loss: 1.2583
2022-07-06 04:40:26 - train: epoch 0075, iter [01400, 05004], lr: 0.001000, loss: 1.1261
2022-07-06 04:40:59 - train: epoch 0075, iter [01500, 05004], lr: 0.001000, loss: 1.3802
2022-07-06 04:41:32 - train: epoch 0075, iter [01600, 05004], lr: 0.001000, loss: 1.0802
2022-07-06 04:42:06 - train: epoch 0075, iter [01700, 05004], lr: 0.001000, loss: 1.4351
2022-07-06 04:42:39 - train: epoch 0075, iter [01800, 05004], lr: 0.001000, loss: 1.1976
2022-07-06 04:43:12 - train: epoch 0075, iter [01900, 05004], lr: 0.001000, loss: 1.2170
2022-07-06 04:43:45 - train: epoch 0075, iter [02000, 05004], lr: 0.001000, loss: 1.3102
2022-07-06 04:44:19 - train: epoch 0075, iter [02100, 05004], lr: 0.001000, loss: 1.2178
2022-07-06 04:44:52 - train: epoch 0075, iter [02200, 05004], lr: 0.001000, loss: 1.3030
2022-07-06 04:45:24 - train: epoch 0075, iter [02300, 05004], lr: 0.001000, loss: 1.1359
2022-07-06 04:45:59 - train: epoch 0075, iter [02400, 05004], lr: 0.001000, loss: 1.2725
2022-07-06 04:46:31 - train: epoch 0075, iter [02500, 05004], lr: 0.001000, loss: 1.2950
2022-07-06 04:47:05 - train: epoch 0075, iter [02600, 05004], lr: 0.001000, loss: 1.3146
2022-07-06 04:47:38 - train: epoch 0075, iter [02700, 05004], lr: 0.001000, loss: 1.1360
2022-07-06 04:48:10 - train: epoch 0075, iter [02800, 05004], lr: 0.001000, loss: 1.2326
2022-07-06 04:48:44 - train: epoch 0075, iter [02900, 05004], lr: 0.001000, loss: 1.3511
2022-07-06 04:49:17 - train: epoch 0075, iter [03000, 05004], lr: 0.001000, loss: 1.5222
2022-07-06 04:49:51 - train: epoch 0075, iter [03100, 05004], lr: 0.001000, loss: 1.3180
2022-07-06 04:50:24 - train: epoch 0075, iter [03200, 05004], lr: 0.001000, loss: 1.3856
2022-07-06 04:50:57 - train: epoch 0075, iter [03300, 05004], lr: 0.001000, loss: 1.3022
2022-07-06 04:51:31 - train: epoch 0075, iter [03400, 05004], lr: 0.001000, loss: 1.2002
2022-07-06 04:52:04 - train: epoch 0075, iter [03500, 05004], lr: 0.001000, loss: 1.2780
2022-07-06 04:52:37 - train: epoch 0075, iter [03600, 05004], lr: 0.001000, loss: 1.2987
2022-07-06 04:53:10 - train: epoch 0075, iter [03700, 05004], lr: 0.001000, loss: 1.3443
2022-07-06 04:53:43 - train: epoch 0075, iter [03800, 05004], lr: 0.001000, loss: 1.3416
2022-07-06 04:54:17 - train: epoch 0075, iter [03900, 05004], lr: 0.001000, loss: 1.3288
2022-07-06 04:54:50 - train: epoch 0075, iter [04000, 05004], lr: 0.001000, loss: 1.2947
2022-07-06 04:55:23 - train: epoch 0075, iter [04100, 05004], lr: 0.001000, loss: 1.0392
2022-07-06 04:55:56 - train: epoch 0075, iter [04200, 05004], lr: 0.001000, loss: 1.2476
2022-07-06 04:56:29 - train: epoch 0075, iter [04300, 05004], lr: 0.001000, loss: 1.3850
2022-07-06 04:57:03 - train: epoch 0075, iter [04400, 05004], lr: 0.001000, loss: 1.1458
2022-07-06 04:57:36 - train: epoch 0075, iter [04500, 05004], lr: 0.001000, loss: 1.2910
2022-07-06 04:58:10 - train: epoch 0075, iter [04600, 05004], lr: 0.001000, loss: 1.2154
2022-07-06 04:58:43 - train: epoch 0075, iter [04700, 05004], lr: 0.001000, loss: 1.4704
2022-07-06 04:59:16 - train: epoch 0075, iter [04800, 05004], lr: 0.001000, loss: 1.0803
2022-07-06 04:59:49 - train: epoch 0075, iter [04900, 05004], lr: 0.001000, loss: 1.2739
2022-07-06 05:00:20 - train: epoch 0075, iter [05000, 05004], lr: 0.001000, loss: 1.4223
2022-07-06 05:00:21 - train: epoch 075, train_loss: 1.2796
2022-07-06 05:01:34 - eval: epoch: 075, acc1: 70.128%, acc5: 89.264%, test_loss: 1.2220, per_image_load_time: 1.644ms, per_image_inference_time: 0.187ms
2022-07-06 05:01:34 - until epoch: 075, best_acc1: 70.128%
2022-07-06 05:01:34 - epoch 076 lr: 0.001000
2022-07-06 05:02:13 - train: epoch 0076, iter [00100, 05004], lr: 0.001000, loss: 1.1997
2022-07-06 05:02:44 - train: epoch 0076, iter [00200, 05004], lr: 0.001000, loss: 1.1581
2022-07-06 05:03:18 - train: epoch 0076, iter [00300, 05004], lr: 0.001000, loss: 1.2380
2022-07-06 05:03:50 - train: epoch 0076, iter [00400, 05004], lr: 0.001000, loss: 1.3955
2022-07-06 05:04:22 - train: epoch 0076, iter [00500, 05004], lr: 0.001000, loss: 1.3621
2022-07-06 05:04:55 - train: epoch 0076, iter [00600, 05004], lr: 0.001000, loss: 1.2352
2022-07-06 05:05:28 - train: epoch 0076, iter [00700, 05004], lr: 0.001000, loss: 1.1586
2022-07-06 05:06:01 - train: epoch 0076, iter [00800, 05004], lr: 0.001000, loss: 1.2419
2022-07-06 05:06:34 - train: epoch 0076, iter [00900, 05004], lr: 0.001000, loss: 1.2065
2022-07-06 05:07:07 - train: epoch 0076, iter [01000, 05004], lr: 0.001000, loss: 1.4032
2022-07-06 05:07:39 - train: epoch 0076, iter [01100, 05004], lr: 0.001000, loss: 1.3266
2022-07-06 05:08:13 - train: epoch 0076, iter [01200, 05004], lr: 0.001000, loss: 1.2536
2022-07-06 05:08:46 - train: epoch 0076, iter [01300, 05004], lr: 0.001000, loss: 1.3667
2022-07-06 05:09:20 - train: epoch 0076, iter [01400, 05004], lr: 0.001000, loss: 1.2175
2022-07-06 05:09:53 - train: epoch 0076, iter [01500, 05004], lr: 0.001000, loss: 1.3118
2022-07-06 05:10:26 - train: epoch 0076, iter [01600, 05004], lr: 0.001000, loss: 1.2352
2022-07-06 05:10:59 - train: epoch 0076, iter [01700, 05004], lr: 0.001000, loss: 1.2412
2022-07-06 05:11:32 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 1.1335
2022-07-06 05:12:05 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 1.2122
2022-07-06 05:12:39 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 1.3006
2022-07-06 05:13:11 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 1.2793
2022-07-06 05:13:44 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 1.2517
2022-07-06 05:14:17 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 1.2863
2022-07-06 05:14:51 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 1.5435
2022-07-06 05:15:24 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 1.1818
2022-07-06 05:15:57 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 1.3243
2022-07-06 05:16:31 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 1.3257
2022-07-06 05:17:04 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 1.2740
2022-07-06 05:17:37 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 1.2689
2022-07-06 05:18:10 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 1.2772
2022-07-06 05:18:44 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 1.3881
2022-07-06 05:19:17 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 1.2755
2022-07-06 05:19:49 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 1.3307
2022-07-06 05:20:22 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 1.2474
2022-07-06 05:20:55 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 1.2939
2022-07-06 05:21:29 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 1.2935
2022-07-06 05:22:02 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 1.1991
2022-07-06 05:22:35 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 1.1965
2022-07-06 05:23:08 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 1.2722
2022-07-06 05:23:41 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 1.2482
2022-07-06 05:24:14 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 1.3336
2022-07-06 05:24:47 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 1.2466
2022-07-06 05:25:21 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 1.4055
2022-07-06 05:25:54 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 1.2620
2022-07-06 05:26:27 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 1.2230
2022-07-06 05:27:00 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 1.3157
2022-07-06 05:27:34 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 1.4837
2022-07-06 05:28:07 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 1.2486
2022-07-06 05:28:40 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 1.2272
2022-07-06 05:29:12 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 1.3293
2022-07-06 05:29:12 - train: epoch 076, train_loss: 1.2784
2022-07-06 05:30:25 - eval: epoch: 076, acc1: 69.926%, acc5: 89.384%, test_loss: 1.2204, per_image_load_time: 1.189ms, per_image_inference_time: 0.183ms
2022-07-06 05:30:25 - until epoch: 076, best_acc1: 70.128%
2022-07-06 05:30:25 - epoch 077 lr: 0.001000
2022-07-06 05:31:03 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 1.4079
2022-07-06 05:31:35 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 1.5239
2022-07-06 05:32:09 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 1.0952
2022-07-06 05:32:41 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 1.2643
2022-07-06 05:33:15 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 1.0298
2022-07-06 05:33:47 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 1.1069
2022-07-06 05:34:21 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 1.1563
2022-07-06 05:34:52 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 1.2224
2022-07-06 05:35:25 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 1.3486
2022-07-06 05:35:58 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 1.2014
2022-07-06 05:36:32 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 1.2992
2022-07-06 05:37:04 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 1.3238
2022-07-06 05:37:38 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 1.1450
2022-07-06 05:38:10 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 1.2016
2022-07-06 05:38:44 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 1.0964
2022-07-06 05:39:16 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 1.2484
2022-07-06 05:39:49 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 1.3991
2022-07-06 05:40:22 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 1.2794
2022-07-06 05:40:55 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 1.0402
2022-07-06 05:41:28 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 1.2338
2022-07-06 05:42:02 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 1.4767
2022-07-06 05:42:34 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 1.1410
2022-07-06 05:43:08 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 1.2559
2022-07-06 05:43:40 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 1.1401
2022-07-06 05:44:13 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 1.3210
2022-07-06 05:44:47 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 1.1181
2022-07-06 05:45:20 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 1.4883
2022-07-06 05:45:53 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 1.3350
2022-07-06 05:46:28 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 1.3164
2022-07-06 05:47:00 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 1.2464
2022-07-06 05:47:33 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 1.0721
2022-07-06 05:48:06 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 1.4049
2022-07-06 05:48:40 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 1.2097
2022-07-06 05:49:13 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 1.3113
2022-07-06 05:49:46 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 1.2903
2022-07-06 05:50:20 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 1.0974
2022-07-06 05:50:52 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 1.3321
2022-07-06 05:51:26 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 1.2685
2022-07-06 05:51:59 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 1.2261
2022-07-06 05:52:32 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 1.2799
2022-07-06 05:53:04 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 1.2450
2022-07-06 05:53:38 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 1.2950
2022-07-06 05:54:10 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 1.2513
2022-07-06 05:54:44 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 1.4666
2022-07-06 05:55:17 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 1.4407
2022-07-06 05:55:51 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 1.1735
2022-07-06 05:56:23 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 1.2528
2022-07-06 05:56:57 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 1.3168
2022-07-06 05:57:30 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 1.5405
2022-07-06 05:58:00 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 1.1909
2022-07-06 05:58:01 - train: epoch 077, train_loss: 1.2739
2022-07-06 05:59:14 - eval: epoch: 077, acc1: 70.074%, acc5: 89.402%, test_loss: 1.2167, per_image_load_time: 2.271ms, per_image_inference_time: 0.186ms
2022-07-06 05:59:14 - until epoch: 077, best_acc1: 70.128%
2022-07-06 05:59:14 - epoch 078 lr: 0.001000
2022-07-06 05:59:53 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 1.2508
2022-07-06 06:00:25 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 1.4077
2022-07-06 06:00:59 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 1.2645
2022-07-06 06:01:31 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 1.2536
2022-07-06 06:02:04 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 1.2944
2022-07-06 06:02:37 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 1.2575
2022-07-06 06:03:10 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 1.4920
2022-07-06 06:03:43 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 1.4571
2022-07-06 06:04:16 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 1.2712
2022-07-06 06:04:49 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 1.1078
2022-07-06 06:05:22 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 1.1023
2022-07-06 06:05:55 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 1.4018
2022-07-06 06:06:29 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 1.1622
2022-07-06 06:07:02 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 1.0886
2022-07-06 06:07:35 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 1.1991
2022-07-06 06:08:07 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 1.1494
2022-07-06 06:08:40 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 1.3419
2022-07-06 06:09:14 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 1.2287
2022-07-06 06:09:48 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 1.2220
2022-07-06 06:10:20 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 1.1881
2022-07-06 06:10:54 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 1.3957
2022-07-06 06:11:26 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 1.4404
2022-07-06 06:12:01 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 1.3646
2022-07-06 06:12:34 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 1.2508
2022-07-06 06:13:06 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 1.2072
2022-07-06 06:13:39 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 1.3468
2022-07-06 06:14:14 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 1.5524
2022-07-06 06:14:46 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 1.2554
2022-07-06 06:15:20 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 1.2016
2022-07-06 06:15:52 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 1.2458
2022-07-06 06:16:26 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 1.3246
2022-07-06 06:16:59 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 1.1284
2022-07-06 06:17:33 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 1.2763
2022-07-06 06:18:05 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 1.1682
2022-07-06 06:18:39 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 1.4013
2022-07-06 06:19:13 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 1.2825
2022-07-06 06:19:45 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 1.4013
2022-07-06 06:20:18 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 1.2151
2022-07-06 06:20:50 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 1.2175
2022-07-06 06:21:24 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 1.3011
2022-07-06 06:21:58 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 1.2188
2022-07-06 06:22:31 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 1.2200
2022-07-06 06:23:03 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 1.5247
2022-07-06 06:23:37 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 1.2250
2022-07-06 06:24:10 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 1.3114
2022-07-06 06:24:44 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 1.2430
2022-07-06 06:25:17 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 1.2057
2022-07-06 06:25:50 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 1.6760
2022-07-06 06:26:23 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 1.3356
2022-07-06 06:26:54 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 1.4358
2022-07-06 06:26:55 - train: epoch 078, train_loss: 1.2718
2022-07-06 06:28:08 - eval: epoch: 078, acc1: 69.982%, acc5: 89.244%, test_loss: 1.2228, per_image_load_time: 2.518ms, per_image_inference_time: 0.185ms
2022-07-06 06:28:09 - until epoch: 078, best_acc1: 70.128%
2022-07-06 06:28:09 - epoch 079 lr: 0.001000
2022-07-06 06:28:47 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 1.1221
2022-07-06 06:29:19 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 1.2872
2022-07-06 06:29:53 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 1.2661
2022-07-06 06:30:25 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 1.3505
2022-07-06 06:30:59 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 1.2694
2022-07-06 06:31:31 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 1.2173
2022-07-06 06:32:04 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 1.2958
2022-07-06 06:32:37 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 1.4712
2022-07-06 06:33:10 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 1.1573
2022-07-06 06:33:43 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 1.3251
2022-07-06 06:34:16 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 1.4406
2022-07-06 06:34:49 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 1.5642
2022-07-06 06:35:23 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 1.0594
2022-07-06 06:35:56 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 1.3017
2022-07-06 06:36:29 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 1.2896
2022-07-06 06:37:02 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 1.2108
2022-07-06 06:37:36 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 1.4353
2022-07-06 06:38:08 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 1.1889
2022-07-06 06:38:42 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 1.1019
2022-07-06 06:39:15 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 1.3738
2022-07-06 06:39:48 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 1.2391
2022-07-06 06:40:21 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 1.2966
2022-07-06 06:40:54 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 1.1585
2022-07-06 06:41:27 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 1.3548
2022-07-06 06:42:00 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 1.1440
2022-07-06 06:42:33 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 1.4069
2022-07-06 06:43:06 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 1.0734
2022-07-06 06:43:39 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 1.2856
2022-07-06 06:44:12 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 1.3601
2022-07-06 06:44:46 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 1.2654
2022-07-06 06:45:19 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 1.2494
2022-07-06 06:45:53 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 1.2719
2022-07-06 06:46:25 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 1.3315
2022-07-06 06:46:59 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 1.1897
2022-07-06 06:47:31 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 1.3058
2022-07-06 06:48:05 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 1.0318
2022-07-06 06:48:37 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 1.2424
2022-07-06 06:49:11 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 1.1924
2022-07-06 06:49:44 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 1.2052
2022-07-06 06:50:17 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 1.2329
2022-07-06 06:50:50 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 1.3907
2022-07-06 06:51:23 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 1.1799
2022-07-06 06:51:56 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 1.2207
2022-07-06 06:52:29 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 1.4646
2022-07-06 06:53:02 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 1.2688
2022-07-06 06:53:35 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 1.2628
2022-07-06 06:54:09 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 1.1885
2022-07-06 06:54:41 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 1.4179
2022-07-06 06:55:14 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 1.2502
2022-07-06 06:55:46 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 1.2945
2022-07-06 06:55:47 - train: epoch 079, train_loss: 1.2684
2022-07-06 06:57:00 - eval: epoch: 079, acc1: 70.030%, acc5: 89.334%, test_loss: 1.2227, per_image_load_time: 2.665ms, per_image_inference_time: 0.176ms
2022-07-06 06:57:00 - until epoch: 079, best_acc1: 70.128%
2022-07-06 06:57:00 - epoch 080 lr: 0.001000
2022-07-06 06:57:38 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 1.0638
2022-07-06 06:58:11 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 1.3469
2022-07-06 06:58:43 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 1.2094
2022-07-06 06:59:16 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 1.3703
2022-07-06 06:59:49 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 1.2070
2022-07-06 07:00:21 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 1.1111
2022-07-06 07:00:55 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 1.2560
2022-07-06 07:01:27 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 1.1208
2022-07-06 07:02:00 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 1.1785
2022-07-06 07:02:34 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 1.2746
2022-07-06 07:03:07 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 1.1784
2022-07-06 07:03:39 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 1.2203
2022-07-06 07:04:13 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 1.1299
2022-07-06 07:04:44 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 1.1830
2022-07-06 07:05:19 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 1.2712
2022-07-06 07:05:51 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 1.3396
2022-07-06 07:06:25 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 1.4321
2022-07-06 07:06:57 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 1.3376
2022-07-06 07:07:32 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 1.4718
2022-07-06 07:08:04 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 1.1972
2022-07-06 07:08:38 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 1.5346
2022-07-06 07:09:10 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 1.3495
2022-07-06 07:09:44 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 1.3482
2022-07-06 07:10:16 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 1.3085
2022-07-06 07:10:50 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 1.2377
2022-07-06 07:11:23 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 1.3138
2022-07-06 07:11:57 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 1.1875
2022-07-06 07:12:29 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 1.1945
2022-07-06 07:13:03 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 1.2712
2022-07-06 07:13:35 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 1.2876
2022-07-06 07:14:10 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 1.2990
2022-07-06 07:14:43 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 1.0402
2022-07-06 07:15:16 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 1.3453
2022-07-06 07:15:49 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 1.1856
2022-07-06 07:16:22 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 1.2950
2022-07-06 07:16:54 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 1.1566
2022-07-06 07:17:28 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 1.1700
2022-07-06 07:18:00 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 1.3492
2022-07-06 07:18:34 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 1.1566
2022-07-06 07:19:07 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 1.2890
2022-07-06 07:19:41 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 1.4864
2022-07-06 07:20:13 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 1.3240
2022-07-06 07:20:47 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 1.3660
2022-07-06 07:21:20 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 1.2549
2022-07-06 07:21:54 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 1.0778
2022-07-06 07:22:26 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 1.3126
2022-07-06 07:23:00 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 1.2194
2022-07-06 07:23:33 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 1.2720
2022-07-06 07:24:05 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 1.4324
2022-07-06 07:24:38 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 1.2322
2022-07-06 07:24:39 - train: epoch 080, train_loss: 1.2657
2022-07-06 07:25:52 - eval: epoch: 080, acc1: 69.946%, acc5: 89.422%, test_loss: 1.2187, per_image_load_time: 2.644ms, per_image_inference_time: 0.166ms
2022-07-06 07:25:52 - until epoch: 080, best_acc1: 70.128%
2022-07-06 07:25:52 - epoch 081 lr: 0.001000
2022-07-06 07:26:31 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 1.4078
2022-07-06 07:27:03 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 1.1946
2022-07-06 07:27:36 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 1.4633
2022-07-06 07:28:10 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 1.2658
2022-07-06 07:28:42 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 1.3703
2022-07-06 07:29:16 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 1.1869
2022-07-06 07:29:48 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 1.1218
2022-07-06 07:30:21 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 1.3263
2022-07-06 07:30:55 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 1.2083
2022-07-06 07:31:29 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 1.3671
2022-07-06 07:32:01 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 1.2282
2022-07-06 07:32:35 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 1.3372
2022-07-06 07:33:08 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 1.1307
2022-07-06 07:33:41 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 1.1088
2022-07-06 07:34:14 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 1.4633
2022-07-06 07:34:47 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 1.0599
2022-07-06 07:35:20 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 1.2588
2022-07-06 07:35:55 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 1.2940
2022-07-06 07:36:28 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 1.1512
2022-07-06 07:37:02 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 1.1723
2022-07-06 07:37:34 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 1.3756
2022-07-06 07:38:08 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 1.2039
2022-07-06 07:38:40 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 1.0897
2022-07-06 07:39:14 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 1.3809
2022-07-06 07:39:47 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 1.4523
2022-07-06 07:40:21 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 1.3413
2022-07-06 07:40:54 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 1.3171
2022-07-06 07:41:26 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 1.0459
2022-07-06 07:42:00 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 1.2270
2022-07-06 07:42:33 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 1.2283
2022-07-06 07:43:06 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 1.1228
2022-07-06 07:43:39 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 1.2897
2022-07-06 07:44:12 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 1.2718
2022-07-06 07:44:45 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 1.3734
2022-07-06 07:45:18 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 1.1448
2022-07-06 07:45:51 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 0.9611
2022-07-06 07:46:25 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 1.3023
2022-07-06 07:46:57 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 1.1369
2022-07-06 07:47:31 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 1.3433
2022-07-06 07:48:05 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 1.1421
2022-07-06 07:48:37 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 1.1772
2022-07-06 07:49:11 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 1.2879
2022-07-06 07:49:45 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 1.4723
2022-07-06 07:50:18 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 1.3388
2022-07-06 07:50:51 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 1.2586
2022-07-06 07:51:23 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 1.2123
2022-07-06 07:51:57 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 1.4159
2022-07-06 07:52:30 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 1.3643
2022-07-06 07:53:04 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 1.3328
2022-07-06 07:53:35 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 1.0664
2022-07-06 07:53:35 - train: epoch 081, train_loss: 1.2638
2022-07-06 07:54:48 - eval: epoch: 081, acc1: 70.008%, acc5: 89.272%, test_loss: 1.2223, per_image_load_time: 2.620ms, per_image_inference_time: 0.177ms
2022-07-06 07:54:48 - until epoch: 081, best_acc1: 70.128%
2022-07-06 07:54:48 - epoch 082 lr: 0.001000
2022-07-06 07:55:26 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 1.1826
2022-07-06 07:55:59 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 1.2285
2022-07-06 07:56:30 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 1.2947
2022-07-06 07:57:04 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 1.1931
2022-07-06 07:57:37 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 1.4602
2022-07-06 07:58:10 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 1.1377
2022-07-06 07:58:43 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 1.3240
2022-07-06 07:59:17 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 1.1681
2022-07-06 07:59:50 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 1.3154
2022-07-06 08:00:22 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 1.1748
2022-07-06 08:00:56 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 1.4648
2022-07-06 08:01:29 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 1.3208
2022-07-06 08:02:02 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 1.2764
2022-07-06 08:02:35 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 1.2164
2022-07-06 08:03:09 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 1.2394
2022-07-06 08:03:42 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 1.2062
2022-07-06 08:04:15 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 1.4350
2022-07-06 08:04:48 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 1.1807
2022-07-06 08:05:22 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 1.2908
2022-07-06 08:05:55 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 1.1334
2022-07-06 08:06:28 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 1.4638
2022-07-06 08:07:01 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 1.1772
2022-07-06 08:07:35 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 1.2813
2022-07-06 08:08:08 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 1.3392
2022-07-06 08:08:41 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 1.1575
2022-07-06 08:09:15 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 1.1017
2022-07-06 08:09:49 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 1.0793
2022-07-06 08:10:21 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 1.1709
2022-07-06 08:10:54 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 1.0382
2022-07-06 08:11:27 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 1.2067
2022-07-06 08:12:01 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 1.2405
2022-07-06 08:12:34 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 1.3198
2022-07-06 08:13:07 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 1.3388
2022-07-06 08:13:41 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 1.3601
2022-07-06 08:14:15 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 1.1960
2022-07-06 08:14:47 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 1.3829
2022-07-06 08:15:21 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 1.1592
2022-07-06 08:15:53 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 1.4681
2022-07-06 08:16:27 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 1.2166
2022-07-06 08:16:59 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 1.1550
2022-07-06 08:17:31 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 1.4038
2022-07-06 08:18:04 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 1.3086
2022-07-06 08:18:39 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 1.0981
2022-07-06 08:19:11 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 1.1807
2022-07-06 08:19:45 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 1.2027
2022-07-06 08:20:18 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 1.2225
2022-07-06 08:20:51 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 1.0089
2022-07-06 08:21:23 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 1.1064
2022-07-06 08:21:58 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 1.3018
2022-07-06 08:22:29 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 1.1565
2022-07-06 08:22:29 - train: epoch 082, train_loss: 1.2606
2022-07-06 08:23:43 - eval: epoch: 082, acc1: 70.000%, acc5: 89.354%, test_loss: 1.2192, per_image_load_time: 2.441ms, per_image_inference_time: 0.160ms
2022-07-06 08:23:43 - until epoch: 082, best_acc1: 70.128%
2022-07-06 08:23:43 - epoch 083 lr: 0.001000
2022-07-06 08:24:20 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 1.1287
2022-07-06 08:24:54 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 1.3709
2022-07-06 08:25:27 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 1.3823
2022-07-06 08:25:59 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 1.2435
2022-07-06 08:26:33 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 1.3260
2022-07-06 08:27:05 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 1.2056
2022-07-06 08:27:38 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 1.2936
2022-07-06 08:28:10 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 1.2774
2022-07-06 08:28:43 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 1.3206
2022-07-06 08:29:15 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 1.3670
2022-07-06 08:29:48 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 1.2197
2022-07-06 08:30:22 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 1.2953
2022-07-06 08:30:55 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 1.3679
2022-07-06 08:31:27 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 1.3820
2022-07-06 08:32:01 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 1.2185
2022-07-06 08:32:34 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 1.4193
2022-07-06 08:33:08 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 1.3408
2022-07-06 08:33:40 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 1.4460
2022-07-06 08:34:14 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 1.3924
2022-07-06 08:34:47 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 1.1123
2022-07-06 08:35:20 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 1.0897
2022-07-06 08:35:53 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 1.3050
2022-07-06 08:36:25 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 1.2665
2022-07-06 08:36:59 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 1.2517
2022-07-06 08:37:32 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 1.1484
2022-07-06 08:38:05 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 1.2194
2022-07-06 08:38:39 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 1.2429
2022-07-06 08:39:11 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 1.2938
2022-07-06 08:39:45 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 1.2897
2022-07-06 08:40:17 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 1.3484
2022-07-06 08:40:50 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 1.2071
2022-07-06 08:41:24 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 1.1149
2022-07-06 08:41:57 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 1.3702
2022-07-06 08:42:30 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 1.1713
2022-07-06 08:43:03 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 1.1740
2022-07-06 08:43:36 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 1.2724
2022-07-06 08:44:10 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 1.2706
2022-07-06 08:44:42 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 1.2562
2022-07-06 08:45:16 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 1.3077
2022-07-06 08:45:49 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 1.4976
2022-07-06 08:46:22 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 1.2261
2022-07-06 08:46:55 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 1.5679
2022-07-06 08:47:28 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 1.2227
2022-07-06 08:48:01 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 1.1884
2022-07-06 08:48:34 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 1.2192
2022-07-06 08:49:08 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 1.2823
2022-07-06 08:49:41 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 1.5134
2022-07-06 08:50:15 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 1.2308
2022-07-06 08:50:47 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 1.1926
2022-07-06 08:51:19 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 1.4502
2022-07-06 08:51:19 - train: epoch 083, train_loss: 1.2587
2022-07-06 08:52:33 - eval: epoch: 083, acc1: 70.088%, acc5: 89.406%, test_loss: 1.2198, per_image_load_time: 2.703ms, per_image_inference_time: 0.173ms
2022-07-06 08:52:33 - until epoch: 083, best_acc1: 70.128%
2022-07-06 08:52:33 - epoch 084 lr: 0.001000
2022-07-06 08:53:12 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 1.1941
2022-07-06 08:53:45 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 1.3805
2022-07-06 08:54:17 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 1.1830
2022-07-06 08:54:50 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 1.2390
2022-07-06 08:55:23 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 1.4597
2022-07-06 08:55:56 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 1.5048
2022-07-06 08:56:29 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 1.2841
2022-07-06 08:57:02 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 1.5563
2022-07-06 08:57:35 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 1.2307
2022-07-06 08:58:08 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 1.1788
2022-07-06 08:58:41 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 1.2407
2022-07-06 08:59:14 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 1.5562
2022-07-06 08:59:48 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 1.2265
2022-07-06 09:00:22 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 1.2273
2022-07-06 09:00:55 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 1.2768
2022-07-06 09:01:28 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 1.1109
2022-07-06 09:02:00 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 1.5635
2022-07-06 09:02:34 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 1.4155
2022-07-06 09:03:07 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 1.3896
2022-07-06 09:03:40 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 1.0373
2022-07-06 09:04:13 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 1.1154
2022-07-06 09:04:47 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 1.1445
2022-07-06 09:05:20 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 1.2316
2022-07-06 09:05:53 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 1.2853
2022-07-06 09:06:27 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 1.4523
2022-07-06 09:07:00 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 1.1060
2022-07-06 09:07:32 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 1.2725
2022-07-06 09:08:06 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 1.1070
2022-07-06 09:08:39 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 1.2157
2022-07-06 09:09:13 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 1.4174
2022-07-06 09:09:46 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 1.3424
2022-07-06 09:10:19 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 1.2516
2022-07-06 09:10:52 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 1.2618
2022-07-06 09:11:25 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 1.1600
2022-07-06 09:11:58 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 1.0775
2022-07-06 09:12:32 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 1.3219
2022-07-06 09:13:04 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 1.3026
2022-07-06 09:13:38 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 1.1648
2022-07-06 09:14:11 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 1.2718
2022-07-06 09:14:45 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 1.2722
2022-07-06 09:15:19 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 1.1111
2022-07-06 09:15:51 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 1.1955
2022-07-06 09:16:25 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 1.1974
2022-07-06 09:16:57 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 1.3796
2022-07-06 09:17:31 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 1.0284
2022-07-06 09:18:05 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 1.1634
2022-07-06 09:18:37 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 1.2803
2022-07-06 09:19:10 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 1.1595
2022-07-06 09:19:43 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 1.2373
2022-07-06 09:20:15 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 1.4123
2022-07-06 09:20:16 - train: epoch 084, train_loss: 1.2577
2022-07-06 09:21:29 - eval: epoch: 084, acc1: 70.202%, acc5: 89.302%, test_loss: 1.2201, per_image_load_time: 2.392ms, per_image_inference_time: 0.166ms
2022-07-06 09:21:29 - until epoch: 084, best_acc1: 70.202%
2022-07-06 09:21:29 - epoch 085 lr: 0.001000
2022-07-06 09:22:07 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 1.2952
2022-07-06 09:22:40 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 1.2414
2022-07-06 09:23:12 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 1.2492
2022-07-06 09:23:46 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 1.3044
2022-07-06 09:24:19 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 1.3480
2022-07-06 09:24:52 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 1.1016
2022-07-06 09:25:24 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 1.3439
2022-07-06 09:25:58 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 1.1357
2022-07-06 09:26:30 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 1.1298
2022-07-06 09:27:03 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 1.1832
2022-07-06 09:27:36 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 1.2886
2022-07-06 09:28:09 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 1.0792
2022-07-06 09:28:42 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 1.3095
2022-07-06 09:29:16 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 1.3822
2022-07-06 09:29:49 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 1.2090
2022-07-06 09:30:22 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 1.1840
2022-07-06 09:30:55 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 1.4650
2022-07-06 09:31:28 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 1.1630
2022-07-06 09:32:01 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 1.2366
2022-07-06 09:32:33 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 1.1607
2022-07-06 09:33:07 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 1.0430
2022-07-06 09:33:41 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 1.1882
2022-07-06 09:34:13 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 1.1328
2022-07-06 09:34:47 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 1.4313
2022-07-06 09:35:19 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 1.5493
2022-07-06 09:35:53 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 1.4514
2022-07-06 09:36:25 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 1.1022
2022-07-06 09:36:59 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 1.5872
2022-07-06 09:37:32 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 1.2613
2022-07-06 09:38:06 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 1.4210
2022-07-06 09:38:39 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 1.1635
2022-07-06 09:39:13 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 1.2346
2022-07-06 09:39:45 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 1.2734
2022-07-06 09:40:18 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 1.2326
2022-07-06 09:40:52 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 1.2690
2022-07-06 09:41:25 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 1.2098
2022-07-06 09:41:58 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 1.0667
2022-07-06 09:42:31 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 1.2513
2022-07-06 09:43:05 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 1.3277
2022-07-06 09:43:38 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 1.3331
2022-07-06 09:44:12 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 1.2982
2022-07-06 09:44:44 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 1.2634
2022-07-06 09:45:18 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 1.0782
2022-07-06 09:45:51 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 1.2463
2022-07-06 09:46:25 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 1.2045
2022-07-06 09:46:57 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 1.2224
2022-07-06 09:47:31 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 1.5174
2022-07-06 09:48:04 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 1.1850
2022-07-06 09:48:38 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 1.3248
2022-07-06 09:49:09 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 1.0548
2022-07-06 09:49:10 - train: epoch 085, train_loss: 1.2555
2022-07-06 09:50:22 - eval: epoch: 085, acc1: 70.314%, acc5: 89.374%, test_loss: 1.2169, per_image_load_time: 1.946ms, per_image_inference_time: 0.205ms
2022-07-06 09:50:23 - until epoch: 085, best_acc1: 70.314%
2022-07-06 09:50:23 - epoch 086 lr: 0.001000
2022-07-06 09:51:01 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 1.1631
2022-07-06 09:51:33 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 1.1903
2022-07-06 09:52:06 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 1.5145
2022-07-06 09:52:38 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 1.2961
2022-07-06 09:53:12 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 1.2135
2022-07-06 09:53:44 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 1.2689
2022-07-06 09:54:17 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 1.2220
2022-07-06 09:54:49 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 1.3989
2022-07-06 09:55:22 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 1.2216
2022-07-06 09:55:55 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 1.3076
2022-07-06 09:56:28 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 1.1418
2022-07-06 09:57:00 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 1.2543
2022-07-06 09:57:33 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 1.2506
2022-07-06 09:58:06 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 1.4099
2022-07-06 09:58:39 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 1.1635
2022-07-06 09:59:12 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 1.0555
2022-07-06 09:59:45 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 1.3085
2022-07-06 10:00:18 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 1.1869
2022-07-06 10:00:51 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 1.2826
2022-07-06 10:01:24 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 1.3669
2022-07-06 10:01:57 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 1.2066
2022-07-06 10:02:29 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 1.2309
2022-07-06 10:03:03 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 1.3241
2022-07-06 10:03:36 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 1.0384
2022-07-06 10:04:09 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 1.2407
2022-07-06 10:04:41 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 1.4441
2022-07-06 10:05:15 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 1.2591
2022-07-06 10:05:49 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 1.3793
2022-07-06 10:06:22 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 0.9069
2022-07-06 10:06:54 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 1.1860
2022-07-06 10:07:28 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 1.2421
2022-07-06 10:08:00 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 1.4302
2022-07-06 10:08:35 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 1.2481
2022-07-06 10:09:07 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 1.3829
2022-07-06 10:09:41 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 1.3514
2022-07-06 10:10:13 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 1.1881
2022-07-06 10:10:47 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 1.2931
2022-07-06 10:11:19 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 1.4261
2022-07-06 10:11:52 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 1.1837
2022-07-06 10:12:26 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 1.3876
2022-07-06 10:12:58 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 1.0667
2022-07-06 10:13:32 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 1.1491
2022-07-06 10:14:05 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 1.4516
2022-07-06 10:14:38 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 1.4021
2022-07-06 10:15:11 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 1.2719
2022-07-06 10:15:44 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 1.2831
2022-07-06 10:16:17 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 1.3056
2022-07-06 10:16:51 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 1.3723
2022-07-06 10:17:24 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 1.2696
2022-07-06 10:17:55 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 1.2017
2022-07-06 10:17:56 - train: epoch 086, train_loss: 1.2521
2022-07-06 10:19:09 - eval: epoch: 086, acc1: 70.160%, acc5: 89.338%, test_loss: 1.2213, per_image_load_time: 2.235ms, per_image_inference_time: 0.172ms
2022-07-06 10:19:09 - until epoch: 086, best_acc1: 70.314%
2022-07-06 10:19:09 - epoch 087 lr: 0.001000
2022-07-06 10:19:47 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 1.3009
2022-07-06 10:20:19 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 1.0904
2022-07-06 10:20:52 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 1.2443
2022-07-06 10:21:25 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 1.3808
2022-07-06 10:21:58 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 1.1803
2022-07-06 10:22:30 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 1.4242
2022-07-06 10:23:03 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 1.1932
2022-07-06 10:23:36 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 1.2451
2022-07-06 10:24:09 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 1.2294
2022-07-06 10:24:43 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 1.1352
2022-07-06 10:25:15 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 1.2178
2022-07-06 10:25:47 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 1.1749
2022-07-06 10:26:21 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 1.5022
2022-07-06 10:26:55 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 1.1281
2022-07-06 10:27:27 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 1.0360
2022-07-06 10:28:00 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 1.1539
2022-07-06 10:28:33 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 1.5653
2022-07-06 10:29:07 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 1.3643
2022-07-06 10:29:39 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 1.3815
2022-07-06 10:30:12 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 1.1927
2022-07-06 10:30:46 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 1.1801
2022-07-06 10:31:19 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 1.4211
2022-07-06 10:31:53 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 1.2189
2022-07-06 10:32:25 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 1.3680
2022-07-06 10:32:59 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 1.1961
2022-07-06 10:33:32 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 1.5235
2022-07-06 10:34:05 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 1.2256
2022-07-06 10:34:39 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 1.1152
2022-07-06 10:35:11 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 1.2428
2022-07-06 10:35:45 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 1.4169
2022-07-06 10:36:18 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 1.1959
2022-07-06 10:36:51 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 1.2166
2022-07-06 10:37:24 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 1.1102
2022-07-06 10:37:57 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 1.1433
2022-07-06 10:38:31 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 1.0243
2022-07-06 10:39:04 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 1.1264
2022-07-06 10:39:38 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 1.1368
2022-07-06 10:40:10 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 1.2516
2022-07-06 10:40:43 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 1.3116
2022-07-06 10:41:16 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 1.2075
2022-07-06 10:41:49 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 1.2417
2022-07-06 10:42:22 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 1.3438
2022-07-06 10:42:57 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 1.1422
2022-07-06 10:43:30 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 1.2990
2022-07-06 10:44:03 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 1.1744
2022-07-06 10:44:36 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 1.4801
2022-07-06 10:45:10 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 1.2295
2022-07-06 10:45:43 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 1.2171
2022-07-06 10:46:17 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 1.1329
2022-07-06 10:46:47 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 1.4639
2022-07-06 10:46:48 - train: epoch 087, train_loss: 1.2531
2022-07-06 10:48:01 - eval: epoch: 087, acc1: 70.146%, acc5: 89.388%, test_loss: 1.2195, per_image_load_time: 0.996ms, per_image_inference_time: 0.163ms
2022-07-06 10:48:01 - until epoch: 087, best_acc1: 70.314%
2022-07-06 10:48:01 - epoch 088 lr: 0.001000
2022-07-06 10:48:39 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 1.0414
2022-07-06 10:49:12 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 1.2492
2022-07-06 10:49:44 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 1.3453
2022-07-06 10:50:17 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 1.2209
2022-07-06 10:50:49 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 1.3740
2022-07-06 10:51:22 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 1.3050
2022-07-06 10:51:56 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 1.2176
2022-07-06 10:52:28 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 1.4384
2022-07-06 10:53:01 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 1.2788
2022-07-06 10:53:35 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 1.3123
2022-07-06 10:54:07 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 1.1272
2022-07-06 10:54:41 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 1.2161
2022-07-06 10:55:14 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 1.3690
2022-07-06 10:55:47 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 1.0048
2022-07-06 10:56:20 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 1.1449
2022-07-06 10:56:54 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 1.0607
2022-07-06 10:57:27 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 1.4419
2022-07-06 10:58:00 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 1.2485
2022-07-06 10:58:33 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 1.1521
2022-07-06 10:59:06 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 1.1456
2022-07-06 10:59:39 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 1.2508
2022-07-06 11:00:12 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 1.2338
2022-07-06 11:00:46 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 1.1444
2022-07-06 11:01:19 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 1.4709
2022-07-06 11:01:52 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 1.4210
2022-07-06 11:02:25 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 1.4561
2022-07-06 11:02:59 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 1.5476
2022-07-06 11:03:33 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 1.2557
2022-07-06 11:04:05 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 1.1782
2022-07-06 11:04:39 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 1.4548
2022-07-06 11:05:12 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 1.2465
2022-07-06 11:05:46 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 1.1207
2022-07-06 11:06:18 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 1.0731
2022-07-06 11:06:51 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 1.1783
2022-07-06 11:07:24 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 1.2452
2022-07-06 11:07:58 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 1.3843
2022-07-06 11:08:32 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 1.3191
2022-07-06 11:09:06 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 1.3313
2022-07-06 11:09:38 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 1.4405
2022-07-06 11:10:13 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 1.1153
2022-07-06 11:10:45 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 1.3931
2022-07-06 11:11:18 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 1.2726
2022-07-06 11:11:52 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 1.2697
2022-07-06 11:12:25 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 1.1624
2022-07-06 11:12:58 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 1.3597
2022-07-06 11:13:32 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 1.4022
2022-07-06 11:14:04 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 1.2793
2022-07-06 11:14:38 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 1.2291
2022-07-06 11:15:11 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 1.1723
2022-07-06 11:15:42 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 1.2337
2022-07-06 11:15:43 - train: epoch 088, train_loss: 1.2505
2022-07-06 11:16:58 - eval: epoch: 088, acc1: 70.200%, acc5: 89.420%, test_loss: 1.2162, per_image_load_time: 2.733ms, per_image_inference_time: 0.153ms
2022-07-06 11:16:58 - until epoch: 088, best_acc1: 70.314%
2022-07-06 11:16:58 - epoch 089 lr: 0.001000
2022-07-06 11:17:36 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 1.3154
2022-07-06 11:18:08 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 1.0075
2022-07-06 11:18:41 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 1.4329
2022-07-06 11:19:14 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 1.1013
2022-07-06 11:19:46 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 1.1179
2022-07-06 11:20:19 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 1.1274
2022-07-06 11:20:51 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 1.2588
2022-07-06 11:21:25 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 1.3932
2022-07-06 11:21:58 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 1.0710
2022-07-06 11:22:31 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 1.2898
2022-07-06 11:23:04 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 1.0635
2022-07-06 11:23:37 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 1.4283
2022-07-06 11:24:09 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 1.1949
2022-07-06 11:24:43 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 1.3219
2022-07-06 11:25:16 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 1.3414
2022-07-06 11:25:49 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 1.0690
2022-07-06 11:26:23 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 1.2400
2022-07-06 11:26:56 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 1.3403
2022-07-06 11:27:28 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 1.2336
2022-07-06 11:28:03 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 1.1847
2022-07-06 11:28:34 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 1.3768
2022-07-06 11:29:09 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 1.3484
2022-07-06 11:29:41 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 1.2380
2022-07-06 11:30:14 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 1.3726
2022-07-06 11:30:47 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 1.4126
2022-07-06 11:31:20 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 1.2136
2022-07-06 11:31:54 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 1.1403
2022-07-06 11:32:26 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 1.2672
2022-07-06 11:33:00 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 1.2347
2022-07-06 11:33:32 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 1.2619
2022-07-06 11:34:05 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 1.3096
2022-07-06 11:34:38 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 1.4657
2022-07-06 11:35:12 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 1.3921
2022-07-06 11:35:44 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 1.2926
2022-07-06 11:36:18 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 1.0734
2022-07-06 11:36:50 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 1.1323
2022-07-06 11:37:22 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 1.2400
2022-07-06 11:37:56 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 1.0868
2022-07-06 11:38:29 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 1.4484
2022-07-06 11:39:03 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 1.3071
2022-07-06 11:39:35 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 1.3578
2022-07-06 11:40:07 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 1.2554
2022-07-06 11:40:41 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 1.2596
2022-07-06 11:41:14 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 1.3647
2022-07-06 11:41:46 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 1.0550
2022-07-06 11:42:19 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 1.2489
2022-07-06 11:42:54 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 1.2553
2022-07-06 11:43:26 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 1.2437
2022-07-06 11:43:59 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 1.2657
2022-07-06 11:44:31 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 0.9768
2022-07-06 11:44:32 - train: epoch 089, train_loss: 1.2479
2022-07-06 11:45:45 - eval: epoch: 089, acc1: 70.136%, acc5: 89.370%, test_loss: 1.2187, per_image_load_time: 2.461ms, per_image_inference_time: 0.161ms
2022-07-06 11:45:45 - until epoch: 089, best_acc1: 70.314%
2022-07-06 11:45:45 - epoch 090 lr: 0.001000
2022-07-06 11:46:24 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 1.2781
2022-07-06 11:46:54 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 1.1579
2022-07-06 11:47:28 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 1.0723
2022-07-06 11:48:01 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 1.2306
2022-07-06 11:48:32 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 1.3782
2022-07-06 11:49:06 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 1.3895
2022-07-06 11:49:39 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 1.2184
2022-07-06 11:50:12 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 1.3129
2022-07-06 11:50:44 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 1.2671
2022-07-06 11:51:18 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 1.3294
2022-07-06 11:51:50 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 1.1375
2022-07-06 11:52:24 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 1.0688
2022-07-06 11:52:55 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 1.2665
2022-07-06 11:53:28 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 1.2668
2022-07-06 11:54:02 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 1.4479
2022-07-06 11:54:34 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 1.2146
2022-07-06 11:55:07 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 1.2253
2022-07-06 11:55:41 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 1.2663
2022-07-06 11:56:14 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 1.2383
2022-07-06 11:56:47 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 1.2363
2022-07-06 11:57:20 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 1.3797
2022-07-06 11:57:53 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 1.2846
2022-07-06 11:58:27 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 1.3439
2022-07-06 11:59:00 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 1.2430
2022-07-06 11:59:33 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 1.2320
2022-07-06 12:00:07 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 1.1963
2022-07-06 12:00:39 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 1.3725
2022-07-06 12:01:12 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 1.1893
2022-07-06 12:01:46 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 1.3219
2022-07-06 12:02:18 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 1.3402
2022-07-06 12:02:52 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 1.1219
2022-07-06 12:03:25 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 1.2797
2022-07-06 12:03:57 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 1.4895
2022-07-06 12:04:31 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 1.1988
2022-07-06 12:05:04 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 1.1431
2022-07-06 12:05:38 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 1.1270
2022-07-06 12:06:10 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 1.4138
2022-07-06 12:06:44 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 1.2655
2022-07-06 12:07:17 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 1.3211
2022-07-06 12:07:50 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 1.2056
2022-07-06 12:08:24 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 1.4948
2022-07-06 12:08:56 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 1.2336
2022-07-06 12:09:30 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 1.2780
2022-07-06 12:10:02 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 1.3476
2022-07-06 12:10:35 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 1.3196
2022-07-06 12:11:08 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 1.1431
2022-07-06 12:11:42 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 1.0373
2022-07-06 12:12:16 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 1.4725
2022-07-06 12:12:47 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 1.1506
2022-07-06 12:13:20 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 1.1879
2022-07-06 12:13:21 - train: epoch 090, train_loss: 1.2449
2022-07-06 12:14:34 - eval: epoch: 090, acc1: 70.026%, acc5: 89.396%, test_loss: 1.2178, per_image_load_time: 2.576ms, per_image_inference_time: 0.176ms
2022-07-06 12:14:34 - until epoch: 090, best_acc1: 70.314%
2022-07-06 12:14:34 - epoch 091 lr: 0.000100
2022-07-06 12:15:11 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 1.0698
2022-07-06 12:15:45 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 1.1938
2022-07-06 12:16:18 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 1.3227
2022-07-06 12:16:50 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 1.2480
2022-07-06 12:17:23 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 1.2696
2022-07-06 12:17:56 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 1.3503
2022-07-06 12:18:30 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 1.2489
2022-07-06 12:19:02 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 1.1584
2022-07-06 12:19:36 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 1.2617
2022-07-06 12:20:08 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 1.1146
2022-07-06 12:20:41 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 0.9457
2022-07-06 12:21:15 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 1.1277
2022-07-06 12:21:48 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 1.3144
2022-07-06 12:22:21 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 1.2597
2022-07-06 12:22:54 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 1.1366
2022-07-06 12:23:27 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 1.1246
2022-07-06 12:24:00 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 1.2344
2022-07-06 12:24:34 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 1.1703
2022-07-06 12:25:07 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 1.2259
2022-07-06 12:25:40 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 1.0781
2022-07-06 12:26:13 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 1.2526
2022-07-06 12:26:46 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 1.3313
2022-07-06 12:27:19 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 1.2923
2022-07-06 12:27:52 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 1.0936
2022-07-06 12:28:26 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 1.3656
2022-07-06 12:28:59 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 1.1586
2022-07-06 12:29:32 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 1.1586
2022-07-06 12:30:05 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 1.2240
2022-07-06 12:30:38 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 1.3864
2022-07-06 12:31:12 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 1.4976
2022-07-06 12:31:44 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 1.3629
2022-07-06 12:32:17 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 1.3811
2022-07-06 12:32:50 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 1.1766
2022-07-06 12:33:24 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 1.2571
2022-07-06 12:33:56 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 1.2087
2022-07-06 12:34:29 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 1.2044
2022-07-06 12:35:04 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 1.3473
2022-07-06 12:35:36 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 1.2168
2022-07-06 12:36:09 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 1.2197
2022-07-06 12:36:42 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 1.1757
2022-07-06 12:37:16 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 1.1384
2022-07-06 12:37:48 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 1.3546
2022-07-06 12:38:22 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 1.3617
2022-07-06 12:38:55 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 1.0377
2022-07-06 12:39:28 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 1.2444
2022-07-06 12:40:01 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 1.1327
2022-07-06 12:40:35 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 1.1886
2022-07-06 12:41:09 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 1.2298
2022-07-06 12:41:42 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 1.0852
2022-07-06 12:42:13 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 1.3537
2022-07-06 12:42:14 - train: epoch 091, train_loss: 1.2230
2022-07-06 12:43:28 - eval: epoch: 091, acc1: 70.540%, acc5: 89.582%, test_loss: 1.2023, per_image_load_time: 2.644ms, per_image_inference_time: 0.185ms
2022-07-06 12:43:28 - until epoch: 091, best_acc1: 70.540%
2022-07-06 12:43:28 - epoch 092 lr: 0.000100
2022-07-06 12:44:06 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 1.1849
2022-07-06 12:44:39 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 1.2526
2022-07-06 12:45:11 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 1.3237
2022-07-06 12:45:44 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 1.1160
2022-07-06 12:46:15 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 1.3740
2022-07-06 12:46:48 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 1.1359
2022-07-06 12:47:20 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 1.3217
2022-07-06 12:47:55 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 1.3693
2022-07-06 12:48:28 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 1.1461
2022-07-06 12:49:01 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 1.1418
2022-07-06 12:49:35 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 1.0522
2022-07-06 12:50:07 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 1.1995
2022-07-06 12:50:40 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 1.0611
2022-07-06 12:51:13 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 1.1578
2022-07-06 12:51:45 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 1.3831
2022-07-06 12:52:20 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 1.1834
2022-07-06 12:52:52 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 1.2877
2022-07-06 12:53:26 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 1.1403
2022-07-06 12:53:58 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 1.2087
2022-07-06 12:54:32 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 1.0886
2022-07-06 12:55:03 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 1.1771
2022-07-06 12:55:38 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 1.1967
2022-07-06 12:56:10 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 1.2213
2022-07-06 12:56:43 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 1.0580
2022-07-06 12:57:16 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 1.1080
2022-07-06 12:57:49 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 1.3567
2022-07-06 12:58:23 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 1.4276
2022-07-06 12:58:56 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 1.1754
2022-07-06 12:59:29 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 1.3870
2022-07-06 13:00:02 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 1.1433
2022-07-06 13:00:35 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 1.3199
2022-07-06 13:01:09 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 1.0765
2022-07-06 13:01:42 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 1.3555
2022-07-06 13:02:15 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 1.3221
2022-07-06 13:02:47 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 1.1505
2022-07-06 13:03:21 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 1.2078
2022-07-06 13:03:54 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 1.1591
2022-07-06 13:04:27 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 1.3156
2022-07-06 13:05:01 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 1.3035
2022-07-06 13:05:34 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 1.2641
2022-07-06 13:06:07 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 1.0586
2022-07-06 13:06:40 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 1.1208
2022-07-06 13:07:14 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 1.0956
2022-07-06 13:07:46 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 1.2073
2022-07-06 13:08:20 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 1.1355
2022-07-06 13:08:53 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 1.2302
2022-07-06 13:09:26 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 0.9852
2022-07-06 13:09:59 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 1.1354
2022-07-06 13:10:33 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 1.2531
2022-07-06 13:11:04 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 1.1420
2022-07-06 13:11:06 - train: epoch 092, train_loss: 1.2132
2022-07-06 13:12:19 - eval: epoch: 092, acc1: 70.606%, acc5: 89.656%, test_loss: 1.2010, per_image_load_time: 2.677ms, per_image_inference_time: 0.178ms
2022-07-06 13:12:19 - until epoch: 092, best_acc1: 70.606%
2022-07-06 13:12:19 - epoch 093 lr: 0.000100
2022-07-06 13:12:58 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 1.2665
2022-07-06 13:13:30 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 1.2247
2022-07-06 13:14:03 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 1.5213
2022-07-06 13:14:36 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 1.2778
2022-07-06 13:15:07 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 1.5018
2022-07-06 13:15:41 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 1.1523
2022-07-06 13:16:13 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 1.1022
2022-07-06 13:16:47 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 1.1126
2022-07-06 13:17:19 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 1.2343
2022-07-06 13:17:52 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.9496
2022-07-06 13:18:25 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 1.1326
2022-07-06 13:18:58 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 1.1561
2022-07-06 13:19:31 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 1.1359
2022-07-06 13:20:05 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 1.2846
2022-07-06 13:20:37 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 1.4741
2022-07-06 13:21:09 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 1.2047
2022-07-06 13:21:43 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 1.1839
2022-07-06 13:22:16 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 1.3899
2022-07-06 13:22:49 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 1.0917
2022-07-06 13:23:22 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 1.0483
2022-07-06 13:23:55 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 1.1759
2022-07-06 13:24:28 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 1.4105
2022-07-06 13:25:02 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 1.1215
2022-07-06 13:25:34 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 1.2215
2022-07-06 13:26:08 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 1.1462
2022-07-06 13:26:41 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 1.2894
2022-07-06 13:27:14 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 1.0299
2022-07-06 13:27:49 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 1.2014
2022-07-06 13:28:20 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 1.1480
2022-07-06 13:28:55 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 1.1986
2022-07-06 13:29:28 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 1.1100
2022-07-06 13:30:01 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 1.2010
2022-07-06 13:30:33 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 1.1729
2022-07-06 13:31:07 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 1.3070
2022-07-06 13:31:39 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 1.1909
2022-07-06 13:32:14 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 1.3180
2022-07-06 13:32:45 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 1.1209
2022-07-06 13:33:19 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 1.2994
2022-07-06 13:33:52 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 1.3459
2022-07-06 13:34:24 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 1.5618
2022-07-06 13:34:58 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 1.3049
2022-07-06 13:35:31 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 1.3732
2022-07-06 13:36:04 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 1.3381
2022-07-06 13:36:37 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 1.0935
2022-07-06 13:37:10 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 1.3496
2022-07-06 13:37:43 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 1.1875
2022-07-06 13:38:17 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 1.3874
2022-07-06 13:38:50 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 1.3642
2022-07-06 13:39:23 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 1.1815
2022-07-06 13:39:54 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 1.0756
2022-07-06 13:39:55 - train: epoch 093, train_loss: 1.2104
2022-07-06 13:41:09 - eval: epoch: 093, acc1: 70.632%, acc5: 89.658%, test_loss: 1.1993, per_image_load_time: 2.687ms, per_image_inference_time: 0.170ms
2022-07-06 13:41:09 - until epoch: 093, best_acc1: 70.632%
2022-07-06 13:41:09 - epoch 094 lr: 0.000100
2022-07-06 13:41:46 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 1.2345
2022-07-06 13:42:20 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 1.3116
2022-07-06 13:42:52 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 1.3508
2022-07-06 13:43:25 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 1.4033
2022-07-06 13:43:57 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 1.1593
2022-07-06 13:44:30 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 1.1422
2022-07-06 13:45:03 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 1.3966
2022-07-06 13:45:36 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 1.1831
2022-07-06 13:46:09 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 1.1737
2022-07-06 13:46:42 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 1.2845
2022-07-06 13:47:14 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 1.3215
2022-07-06 13:47:47 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 1.1646
2022-07-06 13:48:20 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 1.1705
2022-07-06 13:48:52 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 1.1735
2022-07-06 13:49:25 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 1.2200
2022-07-06 13:49:59 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 1.2932
2022-07-06 13:50:31 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 1.0278
2022-07-06 13:51:05 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 1.1824
2022-07-06 13:51:37 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 1.1346
2022-07-06 13:52:11 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 1.1147
2022-07-06 13:52:43 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 1.1207
2022-07-06 13:53:16 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 1.3054
2022-07-06 13:53:49 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 1.1429
2022-07-06 13:54:23 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 1.1326
2022-07-06 13:54:55 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 1.2095
2022-07-06 13:55:29 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 1.1642
2022-07-06 13:56:01 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 1.2528
2022-07-06 13:56:35 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 1.1674
2022-07-06 13:57:07 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 1.0214
2022-07-06 13:57:41 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 1.2086
2022-07-06 13:58:13 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 1.4611
2022-07-06 13:58:46 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 1.1737
2022-07-06 13:59:20 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 1.1707
2022-07-06 13:59:53 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 1.2203
2022-07-06 14:00:25 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 1.1680
2022-07-06 14:00:59 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 1.1436
2022-07-06 14:01:32 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 1.1651
2022-07-06 14:02:05 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 1.1793
2022-07-06 14:02:37 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 1.1119
2022-07-06 14:03:11 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 1.2027
2022-07-06 14:03:43 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 1.4420
2022-07-06 14:04:17 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 1.2688
2022-07-06 14:04:49 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 1.2061
2022-07-06 14:05:23 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 1.3024
2022-07-06 14:05:56 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 1.3142
2022-07-06 14:06:29 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 1.4806
2022-07-06 14:07:02 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 1.4822
2022-07-06 14:07:36 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 0.9315
2022-07-06 14:08:08 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 1.2393
2022-07-06 14:08:39 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 1.1698
2022-07-06 14:08:40 - train: epoch 094, train_loss: 1.2107
2022-07-06 14:09:53 - eval: epoch: 094, acc1: 70.634%, acc5: 89.636%, test_loss: 1.1990, per_image_load_time: 2.004ms, per_image_inference_time: 0.195ms
2022-07-06 14:09:53 - until epoch: 094, best_acc1: 70.634%
2022-07-06 14:09:53 - epoch 095 lr: 0.000100
2022-07-06 14:10:31 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 1.2998
2022-07-06 14:11:03 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 1.2496
2022-07-06 14:11:36 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 1.2514
2022-07-06 14:12:10 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 1.2106
2022-07-06 14:12:42 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 1.0396
2022-07-06 14:13:16 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 1.1761
2022-07-06 14:13:48 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 1.3228
2022-07-06 14:14:23 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 1.2082
2022-07-06 14:14:56 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 1.3807
2022-07-06 14:15:28 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 1.1877
2022-07-06 14:16:01 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 1.0535
2022-07-06 14:16:33 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 1.1552
2022-07-06 14:17:07 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 1.1713
2022-07-06 14:17:40 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 1.2705
2022-07-06 14:18:12 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 1.4132
2022-07-06 14:18:44 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.9539
2022-07-06 14:19:18 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 1.2557
2022-07-06 14:19:52 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 1.2498
2022-07-06 14:20:24 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 1.3143
2022-07-06 14:20:57 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 1.2131
2022-07-06 14:21:30 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 1.1141
2022-07-06 14:22:04 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 1.0904
2022-07-06 14:22:37 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 1.2147
2022-07-06 14:23:11 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 1.3064
2022-07-06 14:23:43 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 0.9635
2022-07-06 14:24:16 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 1.2169
2022-07-06 14:24:49 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 1.2486
2022-07-06 14:25:22 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 1.1226
2022-07-06 14:25:56 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 1.3665
2022-07-06 14:26:29 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 1.3370
2022-07-06 14:27:03 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 1.2371
2022-07-06 14:27:35 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 1.2856
2022-07-06 14:28:09 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 1.3045
2022-07-06 14:28:41 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 1.1546
2022-07-06 14:29:16 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 1.0660
2022-07-06 14:29:48 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 1.0728
2022-07-06 14:30:21 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 1.0448
2022-07-06 14:30:54 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 1.1291
2022-07-06 14:31:28 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 1.3123
2022-07-06 14:32:01 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 1.0758
2022-07-06 14:32:34 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 1.0795
2022-07-06 14:33:07 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 1.1562
2022-07-06 14:33:40 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 1.3778
2022-07-06 14:34:14 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 1.3516
2022-07-06 14:34:47 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 1.1972
2022-07-06 14:35:21 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 1.1652
2022-07-06 14:35:53 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 1.1320
2022-07-06 14:36:27 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 1.0398
2022-07-06 14:36:59 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 1.0936
2022-07-06 14:37:31 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 1.0880
2022-07-06 14:37:32 - train: epoch 095, train_loss: 1.2058
2022-07-06 14:38:45 - eval: epoch: 095, acc1: 70.628%, acc5: 89.662%, test_loss: 1.1980, per_image_load_time: 2.499ms, per_image_inference_time: 0.172ms
2022-07-06 14:38:46 - until epoch: 095, best_acc1: 70.634%
2022-07-06 14:38:46 - epoch 096 lr: 0.000100
2022-07-06 14:39:23 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 1.3590
2022-07-06 14:39:56 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 1.2637
2022-07-06 14:40:29 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 1.1604
2022-07-06 14:41:00 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 1.0940
2022-07-06 14:41:34 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 1.2300
2022-07-06 14:42:06 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 1.1905
2022-07-06 14:42:40 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 1.1061
2022-07-06 14:43:13 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 1.1483
2022-07-06 14:43:45 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 1.2784
2022-07-06 14:44:19 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 1.1981
2022-07-06 14:44:51 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 1.2677
2022-07-06 14:45:25 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 1.1566
2022-07-06 14:45:59 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 1.4088
2022-07-06 14:46:32 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 1.1210
2022-07-06 14:47:05 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 1.1347
2022-07-06 14:47:38 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 1.1629
2022-07-06 14:48:11 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 0.9437
2022-07-06 14:48:44 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 1.2636
2022-07-06 14:49:17 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 1.2934
2022-07-06 14:49:51 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 1.1583
2022-07-06 14:50:24 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 1.1146
2022-07-06 14:50:57 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.8881
2022-07-06 14:51:30 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 1.1763
2022-07-06 14:52:03 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 1.1132
2022-07-06 14:52:36 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 1.0358
2022-07-06 14:53:09 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 1.1002
2022-07-06 14:53:42 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 1.2204
2022-07-06 14:54:16 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 1.3005
2022-07-06 14:54:49 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 1.1296
2022-07-06 14:55:22 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 1.3955
2022-07-06 14:55:56 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 1.2464
2022-07-06 14:56:29 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 1.2313
2022-07-06 14:57:03 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 1.3515
2022-07-06 14:57:35 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 1.1410
2022-07-06 14:58:09 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 0.9766
2022-07-06 14:58:42 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 1.0464
2022-07-06 14:59:16 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 1.1262
2022-07-06 14:59:49 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 1.1731
2022-07-06 15:00:22 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 0.9962
2022-07-06 15:00:55 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 1.2635
2022-07-06 15:01:29 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 1.1098
2022-07-06 15:02:02 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 1.1291
2022-07-06 15:02:35 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.9890
2022-07-06 15:03:08 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 1.0510
2022-07-06 15:03:42 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 1.2719
2022-07-06 15:04:15 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 0.9969
2022-07-06 15:04:48 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 1.2203
2022-07-06 15:05:22 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 1.4059
2022-07-06 15:05:55 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 1.2718
2022-07-06 15:06:26 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 1.2064
2022-07-06 15:06:27 - train: epoch 096, train_loss: 1.2076
2022-07-06 15:07:40 - eval: epoch: 096, acc1: 70.622%, acc5: 89.668%, test_loss: 1.1980, per_image_load_time: 2.602ms, per_image_inference_time: 0.195ms
2022-07-06 15:07:40 - until epoch: 096, best_acc1: 70.634%
2022-07-06 15:07:40 - epoch 097 lr: 0.000100
2022-07-06 15:08:18 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 1.1811
2022-07-06 15:08:51 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 1.2406
2022-07-06 15:09:24 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 1.1572
2022-07-06 15:09:56 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 1.2816
2022-07-06 15:10:29 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 1.2803
2022-07-06 15:11:02 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 1.1398
2022-07-06 15:11:35 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 1.1822
2022-07-06 15:12:07 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 1.0467
2022-07-06 15:12:42 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 1.2603
2022-07-06 15:13:13 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 1.0625
2022-07-06 15:13:47 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 1.1548
2022-07-06 15:14:20 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 1.2178
2022-07-06 15:14:54 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 1.1938
2022-07-06 15:15:26 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 1.2043
2022-07-06 15:16:00 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 1.2350
2022-07-06 15:16:32 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 1.1720
2022-07-06 15:17:07 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 0.9529
2022-07-06 15:17:39 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 1.2756
2022-07-06 15:18:12 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 0.9927
2022-07-06 15:18:45 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 1.2602
2022-07-06 15:19:18 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 1.1104
2022-07-06 15:19:50 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 1.0227
2022-07-06 15:20:25 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 1.0870
2022-07-06 15:20:57 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 1.1388
2022-07-06 15:21:31 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 1.1449
2022-07-06 15:22:03 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 1.2438
2022-07-06 15:22:36 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 1.1554
2022-07-06 15:23:09 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 1.0731
2022-07-06 15:23:43 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 1.3426
2022-07-06 15:24:15 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 1.3420
2022-07-06 15:24:48 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 1.1568
2022-07-06 15:25:22 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 1.2121
2022-07-06 15:25:56 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 1.3015
2022-07-06 15:26:27 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 1.2871
2022-07-06 15:27:02 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 1.2213
2022-07-06 15:27:34 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 1.2199
2022-07-06 15:28:07 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 1.2140
2022-07-06 15:28:39 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 1.0608
2022-07-06 15:29:13 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 1.0693
2022-07-06 15:29:45 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 1.2552
2022-07-06 15:30:19 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 1.2706
2022-07-06 15:30:51 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 1.3379
2022-07-06 15:31:25 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 1.0468
2022-07-06 15:31:58 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 1.2277
2022-07-06 15:32:32 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 1.3968
2022-07-06 15:33:05 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 1.1824
2022-07-06 15:33:39 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 1.0094
2022-07-06 15:34:11 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 1.1265
2022-07-06 15:34:46 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 1.2584
2022-07-06 15:35:16 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 1.1503
2022-07-06 15:35:17 - train: epoch 097, train_loss: 1.2047
2022-07-06 15:36:30 - eval: epoch: 097, acc1: 70.712%, acc5: 89.666%, test_loss: 1.1970, per_image_load_time: 2.477ms, per_image_inference_time: 0.208ms
2022-07-06 15:36:30 - until epoch: 097, best_acc1: 70.712%
2022-07-06 15:36:30 - epoch 098 lr: 0.000100
2022-07-06 15:37:08 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 1.2257
2022-07-06 15:37:41 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 1.1652
2022-07-06 15:38:13 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 1.2599
2022-07-06 15:38:47 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 1.2183
2022-07-06 15:39:19 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 1.2692
2022-07-06 15:39:51 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 1.2426
2022-07-06 15:40:25 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 1.1778
2022-07-06 15:40:57 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 1.2635
2022-07-06 15:41:30 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 1.1830
2022-07-06 15:42:03 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 1.1834
2022-07-06 15:42:36 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 1.1998
2022-07-06 15:43:09 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 1.2338
2022-07-06 15:43:42 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 1.1474
2022-07-06 15:44:16 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 1.2504
2022-07-06 15:44:48 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 1.2356
2022-07-06 15:45:21 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 1.2193
2022-07-06 15:45:54 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 1.2633
2022-07-06 15:46:27 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 1.2523
2022-07-06 15:47:00 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 1.1266
2022-07-06 15:47:33 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 1.3185
2022-07-06 15:48:06 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 1.3642
2022-07-06 15:48:39 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 1.1418
2022-07-06 15:49:13 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 1.1612
2022-07-06 15:49:45 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 1.2934
2022-07-06 15:50:18 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 1.1549
2022-07-06 15:50:52 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 1.2792
2022-07-06 15:51:24 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 1.1816
2022-07-06 15:51:57 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 1.2462
2022-07-06 15:52:31 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 1.0556
2022-07-06 15:53:04 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 1.1838
2022-07-06 15:53:38 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 1.2281
2022-07-06 15:54:10 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 1.0533
2022-07-06 15:54:43 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 1.1392
2022-07-06 15:55:16 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 1.3429
2022-07-06 15:55:49 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 1.1961
2022-07-06 15:56:23 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 1.3838
2022-07-06 15:56:55 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 1.3097
2022-07-06 15:57:29 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 1.2135
2022-07-06 15:58:01 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 1.2162
2022-07-06 15:58:36 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 1.3188
2022-07-06 15:59:07 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 1.2237
2022-07-06 15:59:41 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 1.2934
2022-07-06 16:00:15 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 0.9684
2022-07-06 16:00:48 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 1.4612
2022-07-06 16:01:21 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 1.2854
2022-07-06 16:01:55 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 1.1807
2022-07-06 16:02:27 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 1.2440
2022-07-06 16:03:01 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 1.1228
2022-07-06 16:03:34 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 1.2374
2022-07-06 16:04:05 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 1.1766
2022-07-06 16:04:06 - train: epoch 098, train_loss: 1.2060
2022-07-06 16:05:19 - eval: epoch: 098, acc1: 70.628%, acc5: 89.662%, test_loss: 1.1967, per_image_load_time: 2.156ms, per_image_inference_time: 0.172ms
2022-07-06 16:05:19 - until epoch: 098, best_acc1: 70.712%
2022-07-06 16:05:19 - epoch 099 lr: 0.000100
2022-07-06 16:05:57 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 1.1558
2022-07-06 16:06:30 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 1.0624
2022-07-06 16:07:03 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 1.2826
2022-07-06 16:07:35 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 1.4606
2022-07-06 16:08:09 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 1.1726
2022-07-06 16:08:41 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 1.1872
2022-07-06 16:09:15 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 1.3239
2022-07-06 16:09:48 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 1.1148
2022-07-06 16:10:21 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 1.1960
2022-07-06 16:10:54 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 1.0398
2022-07-06 16:11:27 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 1.3462
2022-07-06 16:12:00 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 1.1269
2022-07-06 16:12:33 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 1.1735
2022-07-06 16:13:07 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 1.0354
2022-07-06 16:13:39 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 1.1470
2022-07-06 16:14:12 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 1.1442
2022-07-06 16:14:46 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 1.0276
2022-07-06 16:15:19 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 1.1351
2022-07-06 16:15:52 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 1.1744
2022-07-06 16:16:25 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 1.2346
2022-07-06 16:16:59 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 1.2404
2022-07-06 16:17:31 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 1.0075
2022-07-06 16:18:04 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 1.2615
2022-07-06 16:18:38 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 1.4473
2022-07-06 16:19:11 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 1.0663
2022-07-06 16:19:44 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 1.1699
2022-07-06 16:20:17 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 1.2181
2022-07-06 16:20:51 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 1.3512
2022-07-06 16:21:25 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 0.8602
2022-07-06 16:21:57 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 1.3124
2022-07-06 16:22:31 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 1.1376
2022-07-06 16:23:04 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 1.1463
2022-07-06 16:23:37 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 1.2094
2022-07-06 16:24:11 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 1.1724
2022-07-06 16:24:44 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 1.1652
2022-07-06 16:25:16 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 1.2053
2022-07-06 16:25:51 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 1.1821
2022-07-06 16:26:23 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 1.3212
2022-07-06 16:26:58 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 1.2206
2022-07-06 16:27:29 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 1.3185
2022-07-06 16:28:04 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 1.0751
2022-07-06 16:28:36 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 1.2662
2022-07-06 16:29:11 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 1.4200
2022-07-06 16:29:44 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 1.1202
2022-07-06 16:30:17 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 1.3090
2022-07-06 16:30:50 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 1.2178
2022-07-06 16:31:24 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 1.0698
2022-07-06 16:31:58 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 1.0813
2022-07-06 16:32:31 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 1.1818
2022-07-06 16:33:02 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 1.4138
2022-07-06 16:33:03 - train: epoch 099, train_loss: 1.2050
2022-07-06 16:34:17 - eval: epoch: 099, acc1: 70.696%, acc5: 89.682%, test_loss: 1.1967, per_image_load_time: 2.396ms, per_image_inference_time: 0.166ms
2022-07-06 16:34:17 - until epoch: 099, best_acc1: 70.712%
2022-07-06 16:34:17 - epoch 100 lr: 0.000100
2022-07-06 16:34:56 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 1.2523
2022-07-06 16:35:29 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 1.1754
2022-07-06 16:36:01 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 1.2388
2022-07-06 16:36:33 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 1.2630
2022-07-06 16:37:05 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 1.1480
2022-07-06 16:37:39 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 1.2480
2022-07-06 16:38:12 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 1.1179
2022-07-06 16:38:46 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 1.2239
2022-07-06 16:39:19 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 1.1251
2022-07-06 16:39:51 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 1.1082
2022-07-06 16:40:25 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 1.1669
2022-07-06 16:40:58 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 1.2632
2022-07-06 16:41:30 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 1.0612
2022-07-06 16:42:03 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 1.3339
2022-07-06 16:42:37 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 1.3652
2022-07-06 16:43:11 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 1.0935
2022-07-06 16:43:43 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 1.2484
2022-07-06 16:44:16 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 1.3514
2022-07-06 16:44:49 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 1.2651
2022-07-06 16:45:22 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 1.0789
2022-07-06 16:45:55 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 1.1476
2022-07-06 16:46:30 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 1.3326
2022-07-06 16:47:02 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 1.2927
2022-07-06 16:47:35 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 1.3920
2022-07-06 16:48:09 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 1.1443
2022-07-06 16:48:42 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 1.0419
2022-07-06 16:49:15 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 1.0276
2022-07-06 16:49:48 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 1.1693
2022-07-06 16:50:22 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 1.2485
2022-07-06 16:50:54 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 1.0584
2022-07-06 16:51:28 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 1.1428
2022-07-06 16:52:01 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 1.3903
2022-07-06 16:52:34 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 1.2417
2022-07-06 16:53:07 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 1.1334
2022-07-06 16:53:40 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 1.1005
2022-07-06 16:54:14 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 1.1000
2022-07-06 16:54:47 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 1.2247
2022-07-06 16:55:21 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 1.0984
2022-07-06 16:55:54 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 1.2101
2022-07-06 16:56:27 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 1.1446
2022-07-06 16:57:00 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 1.2156
2022-07-06 16:57:33 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 1.2973
2022-07-06 16:58:07 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 1.1091
2022-07-06 16:58:39 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 1.2185
2022-07-06 16:59:13 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 0.8538
2022-07-06 16:59:46 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 1.2642
2022-07-06 17:00:19 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 1.3774
2022-07-06 17:00:53 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 1.1661
2022-07-06 17:01:26 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 1.1467
2022-07-06 17:01:57 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 1.2471
2022-07-06 17:01:58 - train: epoch 100, train_loss: 1.2003
2022-07-06 17:03:11 - eval: epoch: 100, acc1: 70.634%, acc5: 89.668%, test_loss: 1.1963, per_image_load_time: 2.178ms, per_image_inference_time: 0.189ms
2022-07-06 17:03:11 - until epoch: 100, best_acc1: 70.712%
2022-07-06 17:03:11 - train done. model: resnet18, train time: 48.117 hours, best_acc1: 70.712%
