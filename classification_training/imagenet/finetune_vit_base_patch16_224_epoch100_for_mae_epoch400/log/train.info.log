2022-10-06 12:40:25 - network: vit_base_patch16
2022-10-06 12:40:25 - num_classes: 1000
2022-10-06 12:40:25 - input_image_size: 224
2022-10-06 12:40:25 - scale: 1.1428571428571428
2022-10-06 12:40:25 - trained_model_path: /root/code/SimpleAICV-ImageNet-CIFAR-COCO-VOC-training/pretrained_models/vit_base_patch16_224_mae_pretrain_model-loss0.388_encoder.pth
2022-10-06 12:40:25 - train_criterion: OneHotLabelCELoss()
2022-10-06 12:40:25 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-10-06 12:40:25 - train_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7f90501d1580>
2022-10-06 12:40:25 - test_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7f90501d10d0>
2022-10-06 12:40:25 - train_collater: <simpleAICV.classification.mixupcutmixclassificationcollator.MixupCutmixClassificationCollater object at 0x7f90501cafd0>
2022-10-06 12:40:25 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f90501caf10>
2022-10-06 12:40:25 - seed: 0
2022-10-06 12:40:25 - batch_size: 256
2022-10-06 12:40:25 - num_workers: 20
2022-10-06 12:40:25 - accumulation_steps: 4
2022-10-06 12:40:25 - optimizer: ('AdamW', {'lr': 0.002, 'global_weight_decay': False, 'weight_decay': 0.05, 'lr_layer_decay': 0.65, 'lr_layer_decay_block': ModuleList(
  (0): TransformerEncoderLayer(
    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (attention): MultiHeadAttention(
      (qkv_linear): Linear(in_features=768, out_features=2304, bias=True)
      (out_linear): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (feed_forward): FeedForward(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (gelu): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): Identity()
  )
  (1): TransformerEncoderLayer(
    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (attention): MultiHeadAttention(
      (qkv_linear): Linear(in_features=768, out_features=2304, bias=True)
      (out_linear): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (feed_forward): FeedForward(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (gelu): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): DropPathBlock()
  )
  (2): TransformerEncoderLayer(
    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (attention): MultiHeadAttention(
      (qkv_linear): Linear(in_features=768, out_features=2304, bias=True)
      (out_linear): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (feed_forward): FeedForward(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (gelu): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): DropPathBlock()
  )
  (3): TransformerEncoderLayer(
    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (attention): MultiHeadAttention(
      (qkv_linear): Linear(in_features=768, out_features=2304, bias=True)
      (out_linear): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (feed_forward): FeedForward(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (gelu): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): DropPathBlock()
  )
  (4): TransformerEncoderLayer(
    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (attention): MultiHeadAttention(
      (qkv_linear): Linear(in_features=768, out_features=2304, bias=True)
      (out_linear): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (feed_forward): FeedForward(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (gelu): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): DropPathBlock()
  )
  (5): TransformerEncoderLayer(
    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (attention): MultiHeadAttention(
      (qkv_linear): Linear(in_features=768, out_features=2304, bias=True)
      (out_linear): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (feed_forward): FeedForward(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (gelu): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): DropPathBlock()
  )
  (6): TransformerEncoderLayer(
    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (attention): MultiHeadAttention(
      (qkv_linear): Linear(in_features=768, out_features=2304, bias=True)
      (out_linear): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (feed_forward): FeedForward(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (gelu): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): DropPathBlock()
  )
  (7): TransformerEncoderLayer(
    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (attention): MultiHeadAttention(
      (qkv_linear): Linear(in_features=768, out_features=2304, bias=True)
      (out_linear): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (feed_forward): FeedForward(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (gelu): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): DropPathBlock()
  )
  (8): TransformerEncoderLayer(
    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (attention): MultiHeadAttention(
      (qkv_linear): Linear(in_features=768, out_features=2304, bias=True)
      (out_linear): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (feed_forward): FeedForward(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (gelu): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): DropPathBlock()
  )
  (9): TransformerEncoderLayer(
    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (attention): MultiHeadAttention(
      (qkv_linear): Linear(in_features=768, out_features=2304, bias=True)
      (out_linear): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (feed_forward): FeedForward(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (gelu): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): DropPathBlock()
  )
  (10): TransformerEncoderLayer(
    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (attention): MultiHeadAttention(
      (qkv_linear): Linear(in_features=768, out_features=2304, bias=True)
      (out_linear): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (feed_forward): FeedForward(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (gelu): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): DropPathBlock()
  )
  (11): TransformerEncoderLayer(
    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (attention): MultiHeadAttention(
      (qkv_linear): Linear(in_features=768, out_features=2304, bias=True)
      (out_linear): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (softmax): Softmax(dim=-1)
    )
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (feed_forward): FeedForward(
      (fc1): Linear(in_features=768, out_features=3072, bias=True)
      (gelu): GELU()
      (fc2): Linear(in_features=3072, out_features=768, bias=True)
      (drop): Dropout(p=0.0, inplace=False)
    )
    (drop_path): DropPathBlock()
  )
), 'block_name': 'blocks', 'no_weight_decay_layer_name_list': ['position_encoding', 'cls_token']})
2022-10-06 12:40:25 - scheduler: ('CosineLR', {'warm_up_epochs': 5, 'min_lr': 1e-06})
2022-10-06 12:40:25 - epochs: 100
2022-10-06 12:40:25 - print_interval: 10
2022-10-06 12:40:25 - sync_bn: False
2022-10-06 12:40:25 - apex: True
2022-10-06 12:40:25 - use_ema_model: False
2022-10-06 12:40:25 - ema_model_decay: 0.9999
2022-10-06 12:40:25 - gpus_type: NVIDIA RTX A5000
2022-10-06 12:40:25 - gpus_num: 2
2022-10-06 12:40:25 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f90252442b0>
2022-10-06 12:40:25 - --------------------parameters--------------------
2022-10-06 12:40:25 - name: cls_token, grad: True
2022-10-06 12:40:25 - name: position_encoding, grad: True
2022-10-06 12:40:25 - name: patch_embedding.conv.weight, grad: True
2022-10-06 12:40:25 - name: patch_embedding.conv.bias, grad: True
2022-10-06 12:40:25 - name: blocks.0.norm1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.0.norm1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.0.attention.qkv_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.0.attention.qkv_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.0.attention.out_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.0.attention.out_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.0.norm2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.0.norm2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.0.feed_forward.fc1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.0.feed_forward.fc1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.0.feed_forward.fc2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.0.feed_forward.fc2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.1.norm1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.1.norm1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.1.attention.qkv_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.1.attention.qkv_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.1.attention.out_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.1.attention.out_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.1.norm2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.1.norm2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.1.feed_forward.fc1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.1.feed_forward.fc1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.1.feed_forward.fc2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.1.feed_forward.fc2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.2.norm1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.2.norm1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.2.attention.qkv_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.2.attention.qkv_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.2.attention.out_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.2.attention.out_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.2.norm2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.2.norm2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.2.feed_forward.fc1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.2.feed_forward.fc1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.2.feed_forward.fc2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.2.feed_forward.fc2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.3.norm1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.3.norm1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.3.attention.qkv_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.3.attention.qkv_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.3.attention.out_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.3.attention.out_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.3.norm2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.3.norm2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.3.feed_forward.fc1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.3.feed_forward.fc1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.3.feed_forward.fc2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.3.feed_forward.fc2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.4.norm1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.4.norm1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.4.attention.qkv_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.4.attention.qkv_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.4.attention.out_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.4.attention.out_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.4.norm2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.4.norm2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.4.feed_forward.fc1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.4.feed_forward.fc1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.4.feed_forward.fc2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.4.feed_forward.fc2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.5.norm1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.5.norm1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.5.attention.qkv_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.5.attention.qkv_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.5.attention.out_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.5.attention.out_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.5.norm2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.5.norm2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.5.feed_forward.fc1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.5.feed_forward.fc1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.5.feed_forward.fc2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.5.feed_forward.fc2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.6.norm1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.6.norm1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.6.attention.qkv_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.6.attention.qkv_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.6.attention.out_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.6.attention.out_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.6.norm2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.6.norm2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.6.feed_forward.fc1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.6.feed_forward.fc1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.6.feed_forward.fc2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.6.feed_forward.fc2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.7.norm1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.7.norm1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.7.attention.qkv_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.7.attention.qkv_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.7.attention.out_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.7.attention.out_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.7.norm2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.7.norm2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.7.feed_forward.fc1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.7.feed_forward.fc1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.7.feed_forward.fc2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.7.feed_forward.fc2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.8.norm1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.8.norm1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.8.attention.qkv_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.8.attention.qkv_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.8.attention.out_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.8.attention.out_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.8.norm2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.8.norm2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.8.feed_forward.fc1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.8.feed_forward.fc1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.8.feed_forward.fc2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.8.feed_forward.fc2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.9.norm1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.9.norm1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.9.attention.qkv_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.9.attention.qkv_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.9.attention.out_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.9.attention.out_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.9.norm2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.9.norm2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.9.feed_forward.fc1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.9.feed_forward.fc1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.9.feed_forward.fc2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.9.feed_forward.fc2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.10.norm1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.10.norm1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.10.attention.qkv_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.10.attention.qkv_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.10.attention.out_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.10.attention.out_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.10.norm2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.10.norm2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.10.feed_forward.fc1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.10.feed_forward.fc1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.10.feed_forward.fc2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.10.feed_forward.fc2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.11.norm1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.11.norm1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.11.attention.qkv_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.11.attention.qkv_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.11.attention.out_linear.weight, grad: True
2022-10-06 12:40:25 - name: blocks.11.attention.out_linear.bias, grad: True
2022-10-06 12:40:25 - name: blocks.11.norm2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.11.norm2.bias, grad: True
2022-10-06 12:40:25 - name: blocks.11.feed_forward.fc1.weight, grad: True
2022-10-06 12:40:25 - name: blocks.11.feed_forward.fc1.bias, grad: True
2022-10-06 12:40:25 - name: blocks.11.feed_forward.fc2.weight, grad: True
2022-10-06 12:40:25 - name: blocks.11.feed_forward.fc2.bias, grad: True
2022-10-06 12:40:25 - name: norm.weight, grad: True
2022-10-06 12:40:25 - name: norm.bias, grad: True
2022-10-06 12:40:25 - name: fc.weight, grad: True
2022-10-06 12:40:25 - name: fc.bias, grad: True
2022-10-06 12:40:25 - --------------------buffers--------------------
2022-10-06 12:40:25 - -----------no weight decay layers--------------
2022-10-06 12:40:25 - name: cls_token, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: position_encoding, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.7.norm1.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.7.norm1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.7.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.7.attention.out_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.7.norm2.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.7.norm2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.7.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.7.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.8.norm1.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.8.norm1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.8.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.8.attention.out_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.8.norm2.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.8.norm2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.8.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.8.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.9.norm1.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.9.norm1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.9.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.9.attention.out_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.9.norm2.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.9.norm2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.9.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.9.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.10.norm1.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.10.norm1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.10.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.10.attention.out_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.10.norm2.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.10.norm2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.10.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.10.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.11.norm1.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.11.norm1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.11.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.11.attention.out_linear.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.11.norm2.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.11.norm2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.11.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: blocks.11.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: norm.weight, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: norm.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - name: fc.bias, weight_decay: 0.0, lr_scale: 1.0
2022-10-06 12:40:25 - -------------weight decay layers---------------
2022-10-06 12:40:25 - name: fc.weight, weight_decay: 0.05, lr_scale: 1.0
2022-10-06 12:40:25 - name: fc.weight, weight_decay: 0.05, lr_scale: 1.0
2022-10-06 12:40:25 - name: patch_embedding.conv.weight, weight_decay: 0.05, lr_scale: 0.003697205891018715
2022-10-06 12:40:25 - name: patch_embedding.conv.weight, weight_decay: 0.05, lr_scale: 0.003697205891018715
2022-10-06 12:40:25 - name: blocks.0.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: 0.005688009063105715
2022-10-06 12:40:25 - name: blocks.0.attention.out_linear.weight, weight_decay: 0.05, lr_scale: 0.005688009063105715
2022-10-06 12:40:25 - name: blocks.0.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: 0.005688009063105715
2022-10-06 12:40:25 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.005688009063105715
2022-10-06 12:40:25 - name: blocks.0.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.005688009063105715
2022-10-06 12:40:25 - name: blocks.1.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: 0.008750783174008792
2022-10-06 12:40:25 - name: blocks.1.attention.out_linear.weight, weight_decay: 0.05, lr_scale: 0.008750783174008792
2022-10-06 12:40:25 - name: blocks.1.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: 0.008750783174008792
2022-10-06 12:40:25 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.008750783174008792
2022-10-06 12:40:25 - name: blocks.1.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.008750783174008792
2022-10-06 12:40:25 - name: blocks.2.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: 0.013462743344628911
2022-10-06 12:40:25 - name: blocks.2.attention.out_linear.weight, weight_decay: 0.05, lr_scale: 0.013462743344628911
2022-10-06 12:40:25 - name: blocks.2.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: 0.013462743344628911
2022-10-06 12:40:25 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.013462743344628911
2022-10-06 12:40:25 - name: blocks.2.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.013462743344628911
2022-10-06 12:40:25 - name: blocks.3.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: 0.02071191283789063
2022-10-06 12:40:25 - name: blocks.3.attention.out_linear.weight, weight_decay: 0.05, lr_scale: 0.02071191283789063
2022-10-06 12:40:25 - name: blocks.3.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: 0.02071191283789063
2022-10-06 12:40:25 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.02071191283789063
2022-10-06 12:40:25 - name: blocks.3.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.02071191283789063
2022-10-06 12:40:25 - name: blocks.4.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: 0.03186448128906251
2022-10-06 12:40:25 - name: blocks.4.attention.out_linear.weight, weight_decay: 0.05, lr_scale: 0.03186448128906251
2022-10-06 12:40:25 - name: blocks.4.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: 0.03186448128906251
2022-10-06 12:40:25 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.03186448128906251
2022-10-06 12:40:25 - name: blocks.4.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.03186448128906251
2022-10-06 12:40:25 - name: blocks.5.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: 0.049022278906250015
2022-10-06 12:40:25 - name: blocks.5.attention.out_linear.weight, weight_decay: 0.05, lr_scale: 0.049022278906250015
2022-10-06 12:40:25 - name: blocks.5.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: 0.049022278906250015
2022-10-06 12:40:25 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.049022278906250015
2022-10-06 12:40:25 - name: blocks.5.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.049022278906250015
2022-10-06 12:40:25 - name: blocks.6.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: 0.07541889062500001
2022-10-06 12:40:25 - name: blocks.6.attention.out_linear.weight, weight_decay: 0.05, lr_scale: 0.07541889062500001
2022-10-06 12:40:25 - name: blocks.6.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: 0.07541889062500001
2022-10-06 12:40:25 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.07541889062500001
2022-10-06 12:40:25 - name: blocks.6.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.07541889062500001
2022-10-06 12:40:25 - name: blocks.7.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: 0.11602906250000002
2022-10-06 12:40:25 - name: blocks.7.attention.out_linear.weight, weight_decay: 0.05, lr_scale: 0.11602906250000002
2022-10-06 12:40:25 - name: blocks.7.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: 0.11602906250000002
2022-10-06 12:40:25 - name: blocks.7.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.11602906250000002
2022-10-06 12:40:25 - name: blocks.7.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.11602906250000002
2022-10-06 12:40:25 - name: blocks.8.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: 0.17850625000000003
2022-10-06 12:40:25 - name: blocks.8.attention.out_linear.weight, weight_decay: 0.05, lr_scale: 0.17850625000000003
2022-10-06 12:40:25 - name: blocks.8.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: 0.17850625000000003
2022-10-06 12:40:25 - name: blocks.8.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.17850625000000003
2022-10-06 12:40:25 - name: blocks.8.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.17850625000000003
2022-10-06 12:40:25 - name: blocks.9.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: 0.274625
2022-10-06 12:40:25 - name: blocks.9.attention.out_linear.weight, weight_decay: 0.05, lr_scale: 0.274625
2022-10-06 12:40:25 - name: blocks.9.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: 0.274625
2022-10-06 12:40:25 - name: blocks.9.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.274625
2022-10-06 12:40:25 - name: blocks.9.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.274625
2022-10-06 12:40:25 - name: blocks.10.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: 0.42250000000000004
2022-10-06 12:40:25 - name: blocks.10.attention.out_linear.weight, weight_decay: 0.05, lr_scale: 0.42250000000000004
2022-10-06 12:40:25 - name: blocks.10.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: 0.42250000000000004
2022-10-06 12:40:25 - name: blocks.10.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.42250000000000004
2022-10-06 12:40:25 - name: blocks.10.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.42250000000000004
2022-10-06 12:40:25 - name: blocks.11.attention.qkv_linear.weight, weight_decay: 0.05, lr_scale: 0.65
2022-10-06 12:40:25 - name: blocks.11.attention.out_linear.weight, weight_decay: 0.05, lr_scale: 0.65
2022-10-06 12:40:25 - name: blocks.11.feed_forward.fc1.weight, weight_decay: 0.05, lr_scale: 0.65
2022-10-06 12:40:25 - name: blocks.11.feed_forward.fc2.weight, weight_decay: 0.05, lr_scale: 0.65
2022-10-06 12:40:25 - epoch 001 lr: 0.002000
2022-10-06 12:40:58 - train: epoch 0001, iter [00010, 01251], lr: 0.000003, loss: 6.9119
2022-10-06 12:41:20 - train: epoch 0001, iter [00020, 01251], lr: 0.000006, loss: 6.9088
2022-10-06 12:41:42 - train: epoch 0001, iter [00030, 01251], lr: 0.000010, loss: 6.9061
2022-10-06 12:42:04 - train: epoch 0001, iter [00040, 01251], lr: 0.000013, loss: 6.9101
2022-10-06 12:42:25 - train: epoch 0001, iter [00050, 01251], lr: 0.000016, loss: 6.9080
2022-10-06 12:42:47 - train: epoch 0001, iter [00060, 01251], lr: 0.000019, loss: 6.9060
2022-10-06 12:43:09 - train: epoch 0001, iter [00070, 01251], lr: 0.000022, loss: 6.9083
2022-10-06 12:43:31 - train: epoch 0001, iter [00080, 01251], lr: 0.000026, loss: 6.9061
2022-10-06 12:43:53 - train: epoch 0001, iter [00090, 01251], lr: 0.000029, loss: 6.9032
2022-10-06 12:44:14 - train: epoch 0001, iter [00100, 01251], lr: 0.000032, loss: 6.9074
2022-10-06 12:44:36 - train: epoch 0001, iter [00110, 01251], lr: 0.000035, loss: 6.9074
2022-10-06 12:44:58 - train: epoch 0001, iter [00120, 01251], lr: 0.000038, loss: 6.9041
2022-10-06 12:45:20 - train: epoch 0001, iter [00130, 01251], lr: 0.000042, loss: 6.9008
2022-10-06 12:45:42 - train: epoch 0001, iter [00140, 01251], lr: 0.000045, loss: 6.9053
2022-10-06 12:46:04 - train: epoch 0001, iter [00150, 01251], lr: 0.000048, loss: 6.8887
2022-10-06 12:46:25 - train: epoch 0001, iter [00160, 01251], lr: 0.000051, loss: 6.8925
2022-10-06 12:46:47 - train: epoch 0001, iter [00170, 01251], lr: 0.000054, loss: 6.8796
2022-10-06 12:47:09 - train: epoch 0001, iter [00180, 01251], lr: 0.000058, loss: 6.8778
2022-10-06 12:47:31 - train: epoch 0001, iter [00190, 01251], lr: 0.000061, loss: 6.8562
2022-10-06 12:47:53 - train: epoch 0001, iter [00200, 01251], lr: 0.000064, loss: 6.8526
2022-10-06 12:48:15 - train: epoch 0001, iter [00210, 01251], lr: 0.000067, loss: 6.8582
2022-10-06 12:48:36 - train: epoch 0001, iter [00220, 01251], lr: 0.000070, loss: 6.8272
2022-10-06 12:48:58 - train: epoch 0001, iter [00230, 01251], lr: 0.000074, loss: 6.8406
2022-10-06 12:49:20 - train: epoch 0001, iter [00240, 01251], lr: 0.000077, loss: 6.7941
2022-10-06 12:49:42 - train: epoch 0001, iter [00250, 01251], lr: 0.000080, loss: 6.8351
2022-10-06 12:50:03 - train: epoch 0001, iter [00260, 01251], lr: 0.000083, loss: 6.7643
2022-10-06 12:50:25 - train: epoch 0001, iter [00270, 01251], lr: 0.000086, loss: 6.7530
2022-10-06 12:50:47 - train: epoch 0001, iter [00280, 01251], lr: 0.000090, loss: 6.7189
2022-10-06 12:51:09 - train: epoch 0001, iter [00290, 01251], lr: 0.000093, loss: 6.6940
2022-10-06 12:51:30 - train: epoch 0001, iter [00300, 01251], lr: 0.000096, loss: 6.6904
2022-10-06 12:51:52 - train: epoch 0001, iter [00310, 01251], lr: 0.000099, loss: 6.7331
2022-10-06 12:52:14 - train: epoch 0001, iter [00320, 01251], lr: 0.000102, loss: 6.6657
2022-10-06 12:52:35 - train: epoch 0001, iter [00330, 01251], lr: 0.000106, loss: 6.6358
2022-10-06 12:52:57 - train: epoch 0001, iter [00340, 01251], lr: 0.000109, loss: 6.6860
2022-10-06 12:53:19 - train: epoch 0001, iter [00350, 01251], lr: 0.000112, loss: 6.6061
2022-10-06 12:53:40 - train: epoch 0001, iter [00360, 01251], lr: 0.000115, loss: 6.5635
2022-10-06 12:54:02 - train: epoch 0001, iter [00370, 01251], lr: 0.000118, loss: 6.7066
2022-10-06 12:54:24 - train: epoch 0001, iter [00380, 01251], lr: 0.000122, loss: 6.5317
2022-10-06 12:54:46 - train: epoch 0001, iter [00390, 01251], lr: 0.000125, loss: 6.5968
2022-10-06 12:55:07 - train: epoch 0001, iter [00400, 01251], lr: 0.000128, loss: 6.5951
2022-10-06 12:55:29 - train: epoch 0001, iter [00410, 01251], lr: 0.000131, loss: 6.3935
2022-10-06 12:55:50 - train: epoch 0001, iter [00420, 01251], lr: 0.000134, loss: 6.5126
2022-10-06 12:56:12 - train: epoch 0001, iter [00430, 01251], lr: 0.000137, loss: 6.5042
2022-10-06 12:56:34 - train: epoch 0001, iter [00440, 01251], lr: 0.000141, loss: 6.4367
2022-10-06 12:56:55 - train: epoch 0001, iter [00450, 01251], lr: 0.000144, loss: 6.4053
2022-10-06 12:57:17 - train: epoch 0001, iter [00460, 01251], lr: 0.000147, loss: 6.3078
2022-10-06 12:57:38 - train: epoch 0001, iter [00470, 01251], lr: 0.000150, loss: 6.3977
2022-10-06 12:58:00 - train: epoch 0001, iter [00480, 01251], lr: 0.000153, loss: 6.2380
2022-10-06 12:58:21 - train: epoch 0001, iter [00490, 01251], lr: 0.000157, loss: 6.4113
2022-10-06 12:58:43 - train: epoch 0001, iter [00500, 01251], lr: 0.000160, loss: 6.3254
2022-10-06 12:59:04 - train: epoch 0001, iter [00510, 01251], lr: 0.000163, loss: 6.1501
2022-10-06 12:59:26 - train: epoch 0001, iter [00520, 01251], lr: 0.000166, loss: 6.4349
2022-10-06 12:59:47 - train: epoch 0001, iter [00530, 01251], lr: 0.000169, loss: 6.3788
2022-10-06 13:00:09 - train: epoch 0001, iter [00540, 01251], lr: 0.000173, loss: 6.5002
2022-10-06 13:00:31 - train: epoch 0001, iter [00550, 01251], lr: 0.000176, loss: 6.2813
2022-10-06 13:00:52 - train: epoch 0001, iter [00560, 01251], lr: 0.000179, loss: 6.2708
2022-10-06 13:01:13 - train: epoch 0001, iter [00570, 01251], lr: 0.000182, loss: 5.9505
2022-10-06 13:01:35 - train: epoch 0001, iter [00580, 01251], lr: 0.000185, loss: 6.1195
2022-10-06 13:01:56 - train: epoch 0001, iter [00590, 01251], lr: 0.000189, loss: 5.9627
2022-10-06 13:02:18 - train: epoch 0001, iter [00600, 01251], lr: 0.000192, loss: 6.0668
2022-10-06 13:02:39 - train: epoch 0001, iter [00610, 01251], lr: 0.000195, loss: 6.1703
2022-10-06 13:03:00 - train: epoch 0001, iter [00620, 01251], lr: 0.000198, loss: 5.9929
2022-10-06 13:03:22 - train: epoch 0001, iter [00630, 01251], lr: 0.000201, loss: 5.8981
2022-10-06 13:03:43 - train: epoch 0001, iter [00640, 01251], lr: 0.000205, loss: 5.8167
2022-10-06 13:04:04 - train: epoch 0001, iter [00650, 01251], lr: 0.000208, loss: 6.2329
2022-10-06 13:04:26 - train: epoch 0001, iter [00660, 01251], lr: 0.000211, loss: 5.9242
2022-10-06 13:04:47 - train: epoch 0001, iter [00670, 01251], lr: 0.000214, loss: 6.0163
2022-10-06 13:05:09 - train: epoch 0001, iter [00680, 01251], lr: 0.000217, loss: 5.6848
2022-10-06 13:05:30 - train: epoch 0001, iter [00690, 01251], lr: 0.000221, loss: 5.6798
2022-10-06 13:05:51 - train: epoch 0001, iter [00700, 01251], lr: 0.000224, loss: 5.7641
2022-10-06 13:06:13 - train: epoch 0001, iter [00710, 01251], lr: 0.000227, loss: 6.1710
2022-10-06 13:06:34 - train: epoch 0001, iter [00720, 01251], lr: 0.000230, loss: 6.1361
2022-10-06 13:06:56 - train: epoch 0001, iter [00730, 01251], lr: 0.000233, loss: 5.9607
2022-10-06 13:07:17 - train: epoch 0001, iter [00740, 01251], lr: 0.000237, loss: 5.5901
2022-10-06 13:07:39 - train: epoch 0001, iter [00750, 01251], lr: 0.000240, loss: 5.9004
2022-10-06 13:08:00 - train: epoch 0001, iter [00760, 01251], lr: 0.000243, loss: 5.8982
2022-10-06 13:08:22 - train: epoch 0001, iter [00770, 01251], lr: 0.000246, loss: 5.6631
2022-10-06 13:08:43 - train: epoch 0001, iter [00780, 01251], lr: 0.000249, loss: 5.9056
2022-10-06 13:09:05 - train: epoch 0001, iter [00790, 01251], lr: 0.000253, loss: 5.8126
2022-10-06 13:09:26 - train: epoch 0001, iter [00800, 01251], lr: 0.000256, loss: 5.4613
2022-10-06 13:09:48 - train: epoch 0001, iter [00810, 01251], lr: 0.000259, loss: 5.8712
2022-10-06 13:10:09 - train: epoch 0001, iter [00820, 01251], lr: 0.000262, loss: 5.5739
2022-10-06 13:10:31 - train: epoch 0001, iter [00830, 01251], lr: 0.000265, loss: 5.5891
2022-10-06 13:10:52 - train: epoch 0001, iter [00840, 01251], lr: 0.000269, loss: 5.8727
2022-10-06 13:11:14 - train: epoch 0001, iter [00850, 01251], lr: 0.000272, loss: 5.4891
2022-10-06 13:11:36 - train: epoch 0001, iter [00860, 01251], lr: 0.000275, loss: 5.5021
2022-10-06 13:11:57 - train: epoch 0001, iter [00870, 01251], lr: 0.000278, loss: 5.6655
2022-10-06 13:12:19 - train: epoch 0001, iter [00880, 01251], lr: 0.000281, loss: 5.7583
2022-10-06 13:12:41 - train: epoch 0001, iter [00890, 01251], lr: 0.000285, loss: 5.1483
2022-10-06 13:13:03 - train: epoch 0001, iter [00900, 01251], lr: 0.000288, loss: 5.5405
2022-10-06 13:13:24 - train: epoch 0001, iter [00910, 01251], lr: 0.000291, loss: 4.5754
2022-10-06 13:13:46 - train: epoch 0001, iter [00920, 01251], lr: 0.000294, loss: 5.8154
2022-10-06 13:14:07 - train: epoch 0001, iter [00930, 01251], lr: 0.000297, loss: 4.9988
2022-10-06 13:14:29 - train: epoch 0001, iter [00940, 01251], lr: 0.000301, loss: 5.2761
2022-10-06 13:14:50 - train: epoch 0001, iter [00950, 01251], lr: 0.000304, loss: 5.4411
2022-10-06 13:15:12 - train: epoch 0001, iter [00960, 01251], lr: 0.000307, loss: 5.4941
2022-10-06 13:15:33 - train: epoch 0001, iter [00970, 01251], lr: 0.000310, loss: 5.6077
2022-10-06 13:15:55 - train: epoch 0001, iter [00980, 01251], lr: 0.000313, loss: 5.6299
2022-10-06 13:16:16 - train: epoch 0001, iter [00990, 01251], lr: 0.000317, loss: 5.1116
2022-10-06 13:16:38 - train: epoch 0001, iter [01000, 01251], lr: 0.000320, loss: 5.7097
2022-10-06 13:16:59 - train: epoch 0001, iter [01010, 01251], lr: 0.000323, loss: 5.4503
2022-10-06 13:17:21 - train: epoch 0001, iter [01020, 01251], lr: 0.000326, loss: 5.4361
2022-10-06 13:17:42 - train: epoch 0001, iter [01030, 01251], lr: 0.000329, loss: 5.1797
2022-10-06 13:18:04 - train: epoch 0001, iter [01040, 01251], lr: 0.000333, loss: 5.3730
2022-10-06 13:18:25 - train: epoch 0001, iter [01050, 01251], lr: 0.000336, loss: 4.7726
2022-10-06 13:18:46 - train: epoch 0001, iter [01060, 01251], lr: 0.000339, loss: 5.1231
2022-10-06 13:19:08 - train: epoch 0001, iter [01070, 01251], lr: 0.000342, loss: 5.7811
2022-10-06 13:19:30 - train: epoch 0001, iter [01080, 01251], lr: 0.000345, loss: 5.6535
2022-10-06 13:19:51 - train: epoch 0001, iter [01090, 01251], lr: 0.000349, loss: 5.1114
2022-10-06 13:20:13 - train: epoch 0001, iter [01100, 01251], lr: 0.000352, loss: 5.5285
2022-10-06 13:20:34 - train: epoch 0001, iter [01110, 01251], lr: 0.000355, loss: 4.8178
2022-10-06 13:20:56 - train: epoch 0001, iter [01120, 01251], lr: 0.000358, loss: 5.5423
2022-10-06 13:21:17 - train: epoch 0001, iter [01130, 01251], lr: 0.000361, loss: 5.6848
2022-10-06 13:21:39 - train: epoch 0001, iter [01140, 01251], lr: 0.000365, loss: 5.1942
2022-10-06 13:22:00 - train: epoch 0001, iter [01150, 01251], lr: 0.000368, loss: 5.3293
2022-10-06 13:22:21 - train: epoch 0001, iter [01160, 01251], lr: 0.000371, loss: 5.2962
2022-10-06 13:22:43 - train: epoch 0001, iter [01170, 01251], lr: 0.000374, loss: 5.1220
2022-10-06 13:23:04 - train: epoch 0001, iter [01180, 01251], lr: 0.000377, loss: 5.1474
2022-10-06 13:23:25 - train: epoch 0001, iter [01190, 01251], lr: 0.000380, loss: 4.6467
2022-10-06 13:23:47 - train: epoch 0001, iter [01200, 01251], lr: 0.000384, loss: 5.2470
2022-10-06 13:24:08 - train: epoch 0001, iter [01210, 01251], lr: 0.000387, loss: 5.3983
2022-10-06 13:24:30 - train: epoch 0001, iter [01220, 01251], lr: 0.000390, loss: 5.4705
2022-10-06 13:24:51 - train: epoch 0001, iter [01230, 01251], lr: 0.000393, loss: 5.3986
2022-10-06 13:25:12 - train: epoch 0001, iter [01240, 01251], lr: 0.000396, loss: 4.3904
2022-10-06 13:25:33 - train: epoch 0001, iter [01250, 01251], lr: 0.000400, loss: 5.5371
2022-10-06 13:25:37 - train: epoch 001, train_loss: 6.0260
2022-10-06 13:26:54 - eval: epoch: 001, acc1: 49.288%, acc5: 78.070%, test_loss: 2.3477, per_image_load_time: 1.175ms, per_image_inference_time: 1.428ms
2022-10-06 13:26:55 - until epoch: 001, best_acc1: 49.288%
2022-10-06 13:26:55 - epoch 002 lr: 0.000400
2022-10-06 13:27:23 - train: epoch 0002, iter [00010, 01251], lr: 0.000403, loss: 4.7809
2022-10-06 13:27:45 - train: epoch 0002, iter [00020, 01251], lr: 0.000406, loss: 4.8624
2022-10-06 13:28:06 - train: epoch 0002, iter [00030, 01251], lr: 0.000410, loss: 4.8870
2022-10-06 13:28:28 - train: epoch 0002, iter [00040, 01251], lr: 0.000413, loss: 4.1138
2022-10-06 13:28:50 - train: epoch 0002, iter [00050, 01251], lr: 0.000416, loss: 5.6692
2022-10-06 13:29:11 - train: epoch 0002, iter [00060, 01251], lr: 0.000419, loss: 5.3648
2022-10-06 13:29:33 - train: epoch 0002, iter [00070, 01251], lr: 0.000422, loss: 5.0167
2022-10-06 13:29:54 - train: epoch 0002, iter [00080, 01251], lr: 0.000426, loss: 5.0931
2022-10-06 13:30:15 - train: epoch 0002, iter [00090, 01251], lr: 0.000429, loss: 5.6005
2022-10-06 13:30:37 - train: epoch 0002, iter [00100, 01251], lr: 0.000432, loss: 4.9563
2022-10-06 13:30:58 - train: epoch 0002, iter [00110, 01251], lr: 0.000435, loss: 5.0124
2022-10-06 13:31:20 - train: epoch 0002, iter [00120, 01251], lr: 0.000438, loss: 4.8789
2022-10-06 13:31:41 - train: epoch 0002, iter [00130, 01251], lr: 0.000442, loss: 4.7387
2022-10-06 13:32:02 - train: epoch 0002, iter [00140, 01251], lr: 0.000445, loss: 5.1216
2022-10-06 13:32:24 - train: epoch 0002, iter [00150, 01251], lr: 0.000448, loss: 5.1375
2022-10-06 13:32:45 - train: epoch 0002, iter [00160, 01251], lr: 0.000451, loss: 5.2543
2022-10-06 13:33:07 - train: epoch 0002, iter [00170, 01251], lr: 0.000454, loss: 3.9005
2022-10-06 13:33:28 - train: epoch 0002, iter [00180, 01251], lr: 0.000458, loss: 5.1991
2022-10-06 13:33:50 - train: epoch 0002, iter [00190, 01251], lr: 0.000461, loss: 4.9797
2022-10-06 13:34:11 - train: epoch 0002, iter [00200, 01251], lr: 0.000464, loss: 3.9988
2022-10-06 13:34:32 - train: epoch 0002, iter [00210, 01251], lr: 0.000467, loss: 5.1557
2022-10-06 13:34:54 - train: epoch 0002, iter [00220, 01251], lr: 0.000470, loss: 4.4624
2022-10-06 13:35:15 - train: epoch 0002, iter [00230, 01251], lr: 0.000474, loss: 3.8981
2022-10-06 13:35:37 - train: epoch 0002, iter [00240, 01251], lr: 0.000477, loss: 5.1272
2022-10-06 13:35:58 - train: epoch 0002, iter [00250, 01251], lr: 0.000480, loss: 4.4896
2022-10-06 13:36:19 - train: epoch 0002, iter [00260, 01251], lr: 0.000483, loss: 4.7035
2022-10-06 13:36:41 - train: epoch 0002, iter [00270, 01251], lr: 0.000486, loss: 4.0465
2022-10-06 13:37:02 - train: epoch 0002, iter [00280, 01251], lr: 0.000490, loss: 3.9755
2022-10-06 13:37:24 - train: epoch 0002, iter [00290, 01251], lr: 0.000493, loss: 5.0804
2022-10-06 13:37:45 - train: epoch 0002, iter [00300, 01251], lr: 0.000496, loss: 4.5208
2022-10-06 13:38:07 - train: epoch 0002, iter [00310, 01251], lr: 0.000499, loss: 4.9581
2022-10-06 13:38:28 - train: epoch 0002, iter [00320, 01251], lr: 0.000502, loss: 5.4986
2022-10-06 13:38:49 - train: epoch 0002, iter [00330, 01251], lr: 0.000506, loss: 4.7733
2022-10-06 13:39:11 - train: epoch 0002, iter [00340, 01251], lr: 0.000509, loss: 5.2771
2022-10-06 13:39:32 - train: epoch 0002, iter [00350, 01251], lr: 0.000512, loss: 5.4012
2022-10-06 13:39:53 - train: epoch 0002, iter [00360, 01251], lr: 0.000515, loss: 3.7824
2022-10-06 13:40:15 - train: epoch 0002, iter [00370, 01251], lr: 0.000518, loss: 4.7555
2022-10-06 13:40:36 - train: epoch 0002, iter [00380, 01251], lr: 0.000522, loss: 4.8752
2022-10-06 13:40:57 - train: epoch 0002, iter [00390, 01251], lr: 0.000525, loss: 3.8695
2022-10-06 13:41:19 - train: epoch 0002, iter [00400, 01251], lr: 0.000528, loss: 4.5805
2022-10-06 13:41:40 - train: epoch 0002, iter [00410, 01251], lr: 0.000531, loss: 4.7067
2022-10-06 13:42:02 - train: epoch 0002, iter [00420, 01251], lr: 0.000534, loss: 5.1169
2022-10-06 13:42:23 - train: epoch 0002, iter [00430, 01251], lr: 0.000537, loss: 4.4240
2022-10-06 13:42:44 - train: epoch 0002, iter [00440, 01251], lr: 0.000541, loss: 5.0458
2022-10-06 13:43:05 - train: epoch 0002, iter [00450, 01251], lr: 0.000544, loss: 4.8494
2022-10-06 13:43:27 - train: epoch 0002, iter [00460, 01251], lr: 0.000547, loss: 5.3827
2022-10-06 13:43:48 - train: epoch 0002, iter [00470, 01251], lr: 0.000550, loss: 4.8815
2022-10-06 13:44:09 - train: epoch 0002, iter [00480, 01251], lr: 0.000553, loss: 3.7642
2022-10-06 13:44:31 - train: epoch 0002, iter [00490, 01251], lr: 0.000557, loss: 4.8510
2022-10-06 13:44:52 - train: epoch 0002, iter [00500, 01251], lr: 0.000560, loss: 5.3811
2022-10-06 13:45:13 - train: epoch 0002, iter [00510, 01251], lr: 0.000563, loss: 5.1561
2022-10-06 13:45:35 - train: epoch 0002, iter [00520, 01251], lr: 0.000566, loss: 3.8725
2022-10-06 13:45:56 - train: epoch 0002, iter [00530, 01251], lr: 0.000569, loss: 4.6239
2022-10-06 13:46:17 - train: epoch 0002, iter [00540, 01251], lr: 0.000573, loss: 4.4349
2022-10-06 13:46:39 - train: epoch 0002, iter [00550, 01251], lr: 0.000576, loss: 5.0939
2022-10-06 13:47:00 - train: epoch 0002, iter [00560, 01251], lr: 0.000579, loss: 4.5335
2022-10-06 13:47:21 - train: epoch 0002, iter [00570, 01251], lr: 0.000582, loss: 4.1804
2022-10-06 13:47:43 - train: epoch 0002, iter [00580, 01251], lr: 0.000585, loss: 5.1339
2022-10-06 13:48:04 - train: epoch 0002, iter [00590, 01251], lr: 0.000589, loss: 4.0539
2022-10-06 13:48:25 - train: epoch 0002, iter [00600, 01251], lr: 0.000592, loss: 4.5274
2022-10-06 13:48:47 - train: epoch 0002, iter [00610, 01251], lr: 0.000595, loss: 4.5835
2022-10-06 13:49:08 - train: epoch 0002, iter [00620, 01251], lr: 0.000598, loss: 5.0096
2022-10-06 13:49:30 - train: epoch 0002, iter [00630, 01251], lr: 0.000601, loss: 4.6756
2022-10-06 13:49:51 - train: epoch 0002, iter [00640, 01251], lr: 0.000605, loss: 5.2834
2022-10-06 13:50:12 - train: epoch 0002, iter [00650, 01251], lr: 0.000608, loss: 4.5351
2022-10-06 13:50:34 - train: epoch 0002, iter [00660, 01251], lr: 0.000611, loss: 4.1430
2022-10-06 13:50:55 - train: epoch 0002, iter [00670, 01251], lr: 0.000614, loss: 4.3515
2022-10-06 13:51:16 - train: epoch 0002, iter [00680, 01251], lr: 0.000617, loss: 4.3631
2022-10-06 13:51:38 - train: epoch 0002, iter [00690, 01251], lr: 0.000621, loss: 4.9865
2022-10-06 13:51:59 - train: epoch 0002, iter [00700, 01251], lr: 0.000624, loss: 4.5193
2022-10-06 13:52:20 - train: epoch 0002, iter [00710, 01251], lr: 0.000627, loss: 4.2362
2022-10-06 13:52:42 - train: epoch 0002, iter [00720, 01251], lr: 0.000630, loss: 4.2400
2022-10-06 13:53:03 - train: epoch 0002, iter [00730, 01251], lr: 0.000633, loss: 3.9766
2022-10-06 13:53:24 - train: epoch 0002, iter [00740, 01251], lr: 0.000637, loss: 4.0762
2022-10-06 13:53:46 - train: epoch 0002, iter [00750, 01251], lr: 0.000640, loss: 5.4158
2022-10-06 13:54:07 - train: epoch 0002, iter [00760, 01251], lr: 0.000643, loss: 4.6778
2022-10-06 13:54:28 - train: epoch 0002, iter [00770, 01251], lr: 0.000646, loss: 4.8827
2022-10-06 13:54:50 - train: epoch 0002, iter [00780, 01251], lr: 0.000649, loss: 4.5640
2022-10-06 13:55:11 - train: epoch 0002, iter [00790, 01251], lr: 0.000653, loss: 4.3340
2022-10-06 13:55:32 - train: epoch 0002, iter [00800, 01251], lr: 0.000656, loss: 4.8123
2022-10-06 13:55:54 - train: epoch 0002, iter [00810, 01251], lr: 0.000659, loss: 4.3528
2022-10-06 13:56:15 - train: epoch 0002, iter [00820, 01251], lr: 0.000662, loss: 4.2810
2022-10-06 13:56:36 - train: epoch 0002, iter [00830, 01251], lr: 0.000665, loss: 4.6266
2022-10-06 13:56:57 - train: epoch 0002, iter [00840, 01251], lr: 0.000669, loss: 5.0375
2022-10-06 13:57:19 - train: epoch 0002, iter [00850, 01251], lr: 0.000672, loss: 3.9386
2022-10-06 13:57:40 - train: epoch 0002, iter [00860, 01251], lr: 0.000675, loss: 4.8831
2022-10-06 13:58:01 - train: epoch 0002, iter [00870, 01251], lr: 0.000678, loss: 4.4893
2022-10-06 13:58:23 - train: epoch 0002, iter [00880, 01251], lr: 0.000681, loss: 4.5070
2022-10-06 13:58:44 - train: epoch 0002, iter [00890, 01251], lr: 0.000685, loss: 4.3142
2022-10-06 13:59:05 - train: epoch 0002, iter [00900, 01251], lr: 0.000688, loss: 4.4879
2022-10-06 13:59:27 - train: epoch 0002, iter [00910, 01251], lr: 0.000691, loss: 5.2272
2022-10-06 13:59:48 - train: epoch 0002, iter [00920, 01251], lr: 0.000694, loss: 5.1046
2022-10-06 14:00:09 - train: epoch 0002, iter [00930, 01251], lr: 0.000697, loss: 5.0998
2022-10-06 14:00:30 - train: epoch 0002, iter [00940, 01251], lr: 0.000701, loss: 4.7629
2022-10-06 14:00:52 - train: epoch 0002, iter [00950, 01251], lr: 0.000704, loss: 4.3080
2022-10-06 14:01:13 - train: epoch 0002, iter [00960, 01251], lr: 0.000707, loss: 3.7262
2022-10-06 14:01:35 - train: epoch 0002, iter [00970, 01251], lr: 0.000710, loss: 4.7347
2022-10-06 14:01:56 - train: epoch 0002, iter [00980, 01251], lr: 0.000713, loss: 4.5461
2022-10-06 14:02:17 - train: epoch 0002, iter [00990, 01251], lr: 0.000717, loss: 3.7376
2022-10-06 14:02:39 - train: epoch 0002, iter [01000, 01251], lr: 0.000720, loss: 4.5991
2022-10-06 14:03:00 - train: epoch 0002, iter [01010, 01251], lr: 0.000723, loss: 4.3785
2022-10-06 14:03:21 - train: epoch 0002, iter [01020, 01251], lr: 0.000726, loss: 5.1700
2022-10-06 14:03:43 - train: epoch 0002, iter [01030, 01251], lr: 0.000729, loss: 4.6472
2022-10-06 14:04:04 - train: epoch 0002, iter [01040, 01251], lr: 0.000733, loss: 3.8730
2022-10-06 14:04:25 - train: epoch 0002, iter [01050, 01251], lr: 0.000736, loss: 4.8074
2022-10-06 14:04:46 - train: epoch 0002, iter [01060, 01251], lr: 0.000739, loss: 4.7812
2022-10-06 14:05:08 - train: epoch 0002, iter [01070, 01251], lr: 0.000742, loss: 4.2517
2022-10-06 14:05:29 - train: epoch 0002, iter [01080, 01251], lr: 0.000745, loss: 4.9103
2022-10-06 14:05:51 - train: epoch 0002, iter [01090, 01251], lr: 0.000749, loss: 4.3946
2022-10-06 14:06:12 - train: epoch 0002, iter [01100, 01251], lr: 0.000752, loss: 4.0990
2022-10-06 14:06:33 - train: epoch 0002, iter [01110, 01251], lr: 0.000755, loss: 4.1331
2022-10-06 14:06:55 - train: epoch 0002, iter [01120, 01251], lr: 0.000758, loss: 4.6457
2022-10-06 14:07:16 - train: epoch 0002, iter [01130, 01251], lr: 0.000761, loss: 4.9072
2022-10-06 14:07:37 - train: epoch 0002, iter [01140, 01251], lr: 0.000765, loss: 4.1856
2022-10-06 14:07:58 - train: epoch 0002, iter [01150, 01251], lr: 0.000768, loss: 4.9849
2022-10-06 14:08:20 - train: epoch 0002, iter [01160, 01251], lr: 0.000771, loss: 5.0783
2022-10-06 14:08:41 - train: epoch 0002, iter [01170, 01251], lr: 0.000774, loss: 4.6397
2022-10-06 14:09:02 - train: epoch 0002, iter [01180, 01251], lr: 0.000777, loss: 4.0033
2022-10-06 14:09:24 - train: epoch 0002, iter [01190, 01251], lr: 0.000780, loss: 4.1688
2022-10-06 14:09:45 - train: epoch 0002, iter [01200, 01251], lr: 0.000784, loss: 4.5372
2022-10-06 14:10:06 - train: epoch 0002, iter [01210, 01251], lr: 0.000787, loss: 5.2683
2022-10-06 14:10:28 - train: epoch 0002, iter [01220, 01251], lr: 0.000790, loss: 5.0929
2022-10-06 14:10:49 - train: epoch 0002, iter [01230, 01251], lr: 0.000793, loss: 5.2249
2022-10-06 14:11:10 - train: epoch 0002, iter [01240, 01251], lr: 0.000796, loss: 4.5213
2022-10-06 14:11:32 - train: epoch 0002, iter [01250, 01251], lr: 0.000800, loss: 4.3917
2022-10-06 14:11:35 - train: epoch 002, train_loss: 4.7096
2022-10-06 14:12:53 - eval: epoch: 002, acc1: 62.564%, acc5: 86.558%, test_loss: 1.6636, per_image_load_time: 0.508ms, per_image_inference_time: 1.428ms
2022-10-06 14:12:54 - until epoch: 002, best_acc1: 62.564%
2022-10-06 14:12:54 - epoch 003 lr: 0.000800
2022-10-06 14:13:21 - train: epoch 0003, iter [00010, 01251], lr: 0.000803, loss: 4.8279
2022-10-06 14:13:43 - train: epoch 0003, iter [00020, 01251], lr: 0.000806, loss: 4.3897
2022-10-06 14:14:04 - train: epoch 0003, iter [00030, 01251], lr: 0.000810, loss: 4.4933
2022-10-06 14:14:25 - train: epoch 0003, iter [00040, 01251], lr: 0.000813, loss: 4.3625
2022-10-06 14:14:47 - train: epoch 0003, iter [00050, 01251], lr: 0.000816, loss: 3.4592
2022-10-06 14:15:08 - train: epoch 0003, iter [00060, 01251], lr: 0.000819, loss: 4.3921
2022-10-06 14:15:30 - train: epoch 0003, iter [00070, 01251], lr: 0.000822, loss: 3.3192
2022-10-06 14:15:51 - train: epoch 0003, iter [00080, 01251], lr: 0.000826, loss: 4.1560
2022-10-06 14:16:12 - train: epoch 0003, iter [00090, 01251], lr: 0.000829, loss: 4.4232
2022-10-06 14:16:34 - train: epoch 0003, iter [00100, 01251], lr: 0.000832, loss: 4.6170
2022-10-06 14:16:55 - train: epoch 0003, iter [00110, 01251], lr: 0.000835, loss: 4.6478
2022-10-06 14:17:17 - train: epoch 0003, iter [00120, 01251], lr: 0.000838, loss: 4.4573
2022-10-06 14:17:38 - train: epoch 0003, iter [00130, 01251], lr: 0.000842, loss: 4.4655
2022-10-06 14:17:59 - train: epoch 0003, iter [00140, 01251], lr: 0.000845, loss: 4.3261
2022-10-06 14:18:21 - train: epoch 0003, iter [00150, 01251], lr: 0.000848, loss: 4.2077
2022-10-06 14:18:42 - train: epoch 0003, iter [00160, 01251], lr: 0.000851, loss: 4.2151
2022-10-06 14:19:03 - train: epoch 0003, iter [00170, 01251], lr: 0.000854, loss: 4.3978
2022-10-06 14:19:25 - train: epoch 0003, iter [00180, 01251], lr: 0.000858, loss: 5.0253
2022-10-06 14:19:46 - train: epoch 0003, iter [00190, 01251], lr: 0.000861, loss: 4.7767
2022-10-06 14:20:07 - train: epoch 0003, iter [00200, 01251], lr: 0.000864, loss: 4.7227
2022-10-06 14:20:29 - train: epoch 0003, iter [00210, 01251], lr: 0.000867, loss: 4.9393
2022-10-06 14:20:50 - train: epoch 0003, iter [00220, 01251], lr: 0.000870, loss: 4.9018
2022-10-06 14:21:11 - train: epoch 0003, iter [00230, 01251], lr: 0.000874, loss: 4.3994
2022-10-06 14:21:33 - train: epoch 0003, iter [00240, 01251], lr: 0.000877, loss: 4.1123
2022-10-06 14:21:54 - train: epoch 0003, iter [00250, 01251], lr: 0.000880, loss: 4.9244
2022-10-06 14:22:15 - train: epoch 0003, iter [00260, 01251], lr: 0.000883, loss: 4.9296
2022-10-06 14:22:36 - train: epoch 0003, iter [00270, 01251], lr: 0.000886, loss: 4.8410
2022-10-06 14:22:58 - train: epoch 0003, iter [00280, 01251], lr: 0.000890, loss: 4.6583
2022-10-06 14:23:19 - train: epoch 0003, iter [00290, 01251], lr: 0.000893, loss: 4.8218
2022-10-06 14:23:40 - train: epoch 0003, iter [00300, 01251], lr: 0.000896, loss: 4.2035
2022-10-06 14:24:02 - train: epoch 0003, iter [00310, 01251], lr: 0.000899, loss: 4.7484
2022-10-06 14:24:23 - train: epoch 0003, iter [00320, 01251], lr: 0.000902, loss: 4.5892
2022-10-06 14:24:45 - train: epoch 0003, iter [00330, 01251], lr: 0.000906, loss: 4.9601
2022-10-06 14:25:06 - train: epoch 0003, iter [00340, 01251], lr: 0.000909, loss: 4.6019
2022-10-06 14:25:27 - train: epoch 0003, iter [00350, 01251], lr: 0.000912, loss: 4.9469
2022-10-06 14:25:49 - train: epoch 0003, iter [00360, 01251], lr: 0.000915, loss: 5.1053
2022-10-06 14:26:10 - train: epoch 0003, iter [00370, 01251], lr: 0.000918, loss: 4.8037
2022-10-06 14:26:31 - train: epoch 0003, iter [00380, 01251], lr: 0.000922, loss: 4.0608
2022-10-06 14:26:52 - train: epoch 0003, iter [00390, 01251], lr: 0.000925, loss: 4.7329
2022-10-06 14:27:14 - train: epoch 0003, iter [00400, 01251], lr: 0.000928, loss: 4.8110
2022-10-06 14:27:35 - train: epoch 0003, iter [00410, 01251], lr: 0.000931, loss: 3.4851
2022-10-06 14:27:56 - train: epoch 0003, iter [00420, 01251], lr: 0.000934, loss: 4.0530
2022-10-06 14:28:18 - train: epoch 0003, iter [00430, 01251], lr: 0.000937, loss: 3.6848
2022-10-06 14:28:39 - train: epoch 0003, iter [00440, 01251], lr: 0.000941, loss: 4.2661
2022-10-06 14:29:00 - train: epoch 0003, iter [00450, 01251], lr: 0.000944, loss: 4.3458
2022-10-06 14:29:22 - train: epoch 0003, iter [00460, 01251], lr: 0.000947, loss: 4.1595
2022-10-06 14:29:43 - train: epoch 0003, iter [00470, 01251], lr: 0.000950, loss: 4.1514
2022-10-06 14:30:04 - train: epoch 0003, iter [00480, 01251], lr: 0.000953, loss: 4.8888
2022-10-06 14:30:26 - train: epoch 0003, iter [00490, 01251], lr: 0.000957, loss: 3.8568
2022-10-06 14:30:47 - train: epoch 0003, iter [00500, 01251], lr: 0.000960, loss: 4.5005
2022-10-06 14:31:08 - train: epoch 0003, iter [00510, 01251], lr: 0.000963, loss: 4.4427
2022-10-06 14:31:29 - train: epoch 0003, iter [00520, 01251], lr: 0.000966, loss: 3.8687
2022-10-06 14:31:51 - train: epoch 0003, iter [00530, 01251], lr: 0.000969, loss: 4.2354
2022-10-06 14:32:12 - train: epoch 0003, iter [00540, 01251], lr: 0.000973, loss: 4.6193
2022-10-06 14:32:34 - train: epoch 0003, iter [00550, 01251], lr: 0.000976, loss: 4.1587
2022-10-06 14:32:55 - train: epoch 0003, iter [00560, 01251], lr: 0.000979, loss: 4.2294
2022-10-06 14:33:16 - train: epoch 0003, iter [00570, 01251], lr: 0.000982, loss: 4.9115
2022-10-06 14:33:38 - train: epoch 0003, iter [00580, 01251], lr: 0.000985, loss: 4.0344
2022-10-06 14:33:59 - train: epoch 0003, iter [00590, 01251], lr: 0.000989, loss: 3.4949
2022-10-06 14:34:20 - train: epoch 0003, iter [00600, 01251], lr: 0.000992, loss: 4.8134
2022-10-06 14:34:42 - train: epoch 0003, iter [00610, 01251], lr: 0.000995, loss: 4.8683
2022-10-06 14:35:03 - train: epoch 0003, iter [00620, 01251], lr: 0.000998, loss: 4.5563
2022-10-06 14:35:24 - train: epoch 0003, iter [00630, 01251], lr: 0.001001, loss: 3.5733
2022-10-06 14:35:46 - train: epoch 0003, iter [00640, 01251], lr: 0.001005, loss: 4.0105
2022-10-06 14:36:07 - train: epoch 0003, iter [00650, 01251], lr: 0.001008, loss: 4.3400
2022-10-06 14:36:28 - train: epoch 0003, iter [00660, 01251], lr: 0.001011, loss: 4.4895
2022-10-06 14:36:49 - train: epoch 0003, iter [00670, 01251], lr: 0.001014, loss: 4.5617
2022-10-06 14:37:11 - train: epoch 0003, iter [00680, 01251], lr: 0.001017, loss: 4.6674
2022-10-06 14:37:32 - train: epoch 0003, iter [00690, 01251], lr: 0.001021, loss: 4.1216
2022-10-06 14:37:53 - train: epoch 0003, iter [00700, 01251], lr: 0.001024, loss: 3.1009
2022-10-06 14:38:14 - train: epoch 0003, iter [00710, 01251], lr: 0.001027, loss: 3.7939
2022-10-06 14:38:36 - train: epoch 0003, iter [00720, 01251], lr: 0.001030, loss: 3.9856
2022-10-06 14:38:57 - train: epoch 0003, iter [00730, 01251], lr: 0.001033, loss: 4.0784
2022-10-06 14:39:18 - train: epoch 0003, iter [00740, 01251], lr: 0.001037, loss: 4.4685
2022-10-06 14:39:40 - train: epoch 0003, iter [00750, 01251], lr: 0.001040, loss: 3.9531
2022-10-06 14:40:01 - train: epoch 0003, iter [00760, 01251], lr: 0.001043, loss: 4.3601
2022-10-06 14:40:22 - train: epoch 0003, iter [00770, 01251], lr: 0.001046, loss: 3.9464
2022-10-06 14:40:44 - train: epoch 0003, iter [00780, 01251], lr: 0.001049, loss: 4.8213
2022-10-06 14:41:05 - train: epoch 0003, iter [00790, 01251], lr: 0.001053, loss: 4.8071
2022-10-06 14:41:26 - train: epoch 0003, iter [00800, 01251], lr: 0.001056, loss: 4.4537
2022-10-06 14:41:47 - train: epoch 0003, iter [00810, 01251], lr: 0.001059, loss: 4.3121
2022-10-06 14:42:09 - train: epoch 0003, iter [00820, 01251], lr: 0.001062, loss: 4.4490
2022-10-06 14:42:30 - train: epoch 0003, iter [00830, 01251], lr: 0.001065, loss: 3.9743
2022-10-06 14:42:51 - train: epoch 0003, iter [00840, 01251], lr: 0.001069, loss: 3.8523
2022-10-06 14:43:13 - train: epoch 0003, iter [00850, 01251], lr: 0.001072, loss: 4.6623
2022-10-06 14:43:34 - train: epoch 0003, iter [00860, 01251], lr: 0.001075, loss: 4.1472
2022-10-06 14:43:55 - train: epoch 0003, iter [00870, 01251], lr: 0.001078, loss: 3.8334
2022-10-06 14:44:17 - train: epoch 0003, iter [00880, 01251], lr: 0.001081, loss: 3.7562
2022-10-06 14:44:38 - train: epoch 0003, iter [00890, 01251], lr: 0.001085, loss: 3.9070
2022-10-06 14:44:59 - train: epoch 0003, iter [00900, 01251], lr: 0.001088, loss: 4.6437
2022-10-06 14:45:21 - train: epoch 0003, iter [00910, 01251], lr: 0.001091, loss: 3.8569
2022-10-06 14:45:42 - train: epoch 0003, iter [00920, 01251], lr: 0.001094, loss: 4.9359
2022-10-06 14:46:03 - train: epoch 0003, iter [00930, 01251], lr: 0.001097, loss: 4.7221
2022-10-06 14:46:25 - train: epoch 0003, iter [00940, 01251], lr: 0.001101, loss: 4.5506
2022-10-06 14:46:46 - train: epoch 0003, iter [00950, 01251], lr: 0.001104, loss: 4.2545
2022-10-06 14:47:07 - train: epoch 0003, iter [00960, 01251], lr: 0.001107, loss: 4.2288
2022-10-06 14:47:29 - train: epoch 0003, iter [00970, 01251], lr: 0.001110, loss: 4.5860
2022-10-06 14:47:50 - train: epoch 0003, iter [00980, 01251], lr: 0.001113, loss: 4.7926
2022-10-06 14:48:11 - train: epoch 0003, iter [00990, 01251], lr: 0.001117, loss: 4.3909
2022-10-06 14:48:33 - train: epoch 0003, iter [01000, 01251], lr: 0.001120, loss: 4.5007
2022-10-06 14:48:54 - train: epoch 0003, iter [01010, 01251], lr: 0.001123, loss: 4.5614
2022-10-06 14:49:16 - train: epoch 0003, iter [01020, 01251], lr: 0.001126, loss: 4.4963
2022-10-06 14:49:37 - train: epoch 0003, iter [01030, 01251], lr: 0.001129, loss: 4.4373
2022-10-06 14:49:59 - train: epoch 0003, iter [01040, 01251], lr: 0.001133, loss: 4.1220
2022-10-06 14:50:20 - train: epoch 0003, iter [01050, 01251], lr: 0.001136, loss: 4.2816
2022-10-06 14:50:41 - train: epoch 0003, iter [01060, 01251], lr: 0.001139, loss: 5.0158
2022-10-06 14:51:03 - train: epoch 0003, iter [01070, 01251], lr: 0.001142, loss: 4.2029
2022-10-06 14:51:24 - train: epoch 0003, iter [01080, 01251], lr: 0.001145, loss: 3.8461
2022-10-06 14:51:45 - train: epoch 0003, iter [01090, 01251], lr: 0.001149, loss: 4.7635
2022-10-06 14:52:07 - train: epoch 0003, iter [01100, 01251], lr: 0.001152, loss: 3.3528
2022-10-06 14:52:28 - train: epoch 0003, iter [01110, 01251], lr: 0.001155, loss: 3.9524
2022-10-06 14:52:49 - train: epoch 0003, iter [01120, 01251], lr: 0.001158, loss: 4.1424
2022-10-06 14:53:11 - train: epoch 0003, iter [01130, 01251], lr: 0.001161, loss: 4.3556
2022-10-06 14:53:32 - train: epoch 0003, iter [01140, 01251], lr: 0.001165, loss: 3.5161
2022-10-06 14:53:53 - train: epoch 0003, iter [01150, 01251], lr: 0.001168, loss: 4.9101
2022-10-06 14:54:15 - train: epoch 0003, iter [01160, 01251], lr: 0.001171, loss: 4.8229
2022-10-06 14:54:36 - train: epoch 0003, iter [01170, 01251], lr: 0.001174, loss: 4.3060
2022-10-06 14:54:58 - train: epoch 0003, iter [01180, 01251], lr: 0.001177, loss: 4.4234
2022-10-06 14:55:19 - train: epoch 0003, iter [01190, 01251], lr: 0.001180, loss: 3.9449
2022-10-06 14:55:40 - train: epoch 0003, iter [01200, 01251], lr: 0.001184, loss: 3.4117
2022-10-06 14:56:02 - train: epoch 0003, iter [01210, 01251], lr: 0.001187, loss: 4.4289
2022-10-06 14:56:23 - train: epoch 0003, iter [01220, 01251], lr: 0.001190, loss: 3.8299
2022-10-06 14:56:45 - train: epoch 0003, iter [01230, 01251], lr: 0.001193, loss: 4.0856
2022-10-06 14:57:06 - train: epoch 0003, iter [01240, 01251], lr: 0.001196, loss: 4.3934
2022-10-06 14:57:27 - train: epoch 0003, iter [01250, 01251], lr: 0.001200, loss: 4.1543
2022-10-06 14:57:31 - train: epoch 003, train_loss: 4.3770
2022-10-06 14:58:48 - eval: epoch: 003, acc1: 66.392%, acc5: 88.756%, test_loss: 1.4931, per_image_load_time: 1.368ms, per_image_inference_time: 1.437ms
2022-10-06 14:58:50 - until epoch: 003, best_acc1: 66.392%
2022-10-06 14:58:50 - epoch 004 lr: 0.001200
2022-10-06 14:59:17 - train: epoch 0004, iter [00010, 01251], lr: 0.001203, loss: 3.8121
2022-10-06 14:59:38 - train: epoch 0004, iter [00020, 01251], lr: 0.001206, loss: 4.4803
2022-10-06 14:59:59 - train: epoch 0004, iter [00030, 01251], lr: 0.001210, loss: 4.4860
2022-10-06 15:00:21 - train: epoch 0004, iter [00040, 01251], lr: 0.001213, loss: 4.0419
2022-10-06 15:00:42 - train: epoch 0004, iter [00050, 01251], lr: 0.001216, loss: 4.5373
2022-10-06 15:01:04 - train: epoch 0004, iter [00060, 01251], lr: 0.001219, loss: 3.6352
2022-10-06 15:01:25 - train: epoch 0004, iter [00070, 01251], lr: 0.001222, loss: 3.4934
2022-10-06 15:01:46 - train: epoch 0004, iter [00080, 01251], lr: 0.001226, loss: 3.5923
2022-10-06 15:02:07 - train: epoch 0004, iter [00090, 01251], lr: 0.001229, loss: 4.4370
2022-10-06 15:02:29 - train: epoch 0004, iter [00100, 01251], lr: 0.001232, loss: 4.1698
2022-10-06 15:02:50 - train: epoch 0004, iter [00110, 01251], lr: 0.001235, loss: 4.3533
2022-10-06 15:03:12 - train: epoch 0004, iter [00120, 01251], lr: 0.001238, loss: 4.3003
2022-10-06 15:03:33 - train: epoch 0004, iter [00130, 01251], lr: 0.001242, loss: 4.3512
2022-10-06 15:03:54 - train: epoch 0004, iter [00140, 01251], lr: 0.001245, loss: 4.6151
2022-10-06 15:04:16 - train: epoch 0004, iter [00150, 01251], lr: 0.001248, loss: 3.9694
2022-10-06 15:04:37 - train: epoch 0004, iter [00160, 01251], lr: 0.001251, loss: 4.4533
2022-10-06 15:04:59 - train: epoch 0004, iter [00170, 01251], lr: 0.001254, loss: 4.6066
2022-10-06 15:05:20 - train: epoch 0004, iter [00180, 01251], lr: 0.001258, loss: 4.2349
2022-10-06 15:05:42 - train: epoch 0004, iter [00190, 01251], lr: 0.001261, loss: 4.5548
2022-10-06 15:06:03 - train: epoch 0004, iter [00200, 01251], lr: 0.001264, loss: 4.7649
2022-10-06 15:06:24 - train: epoch 0004, iter [00210, 01251], lr: 0.001267, loss: 4.2632
2022-10-06 15:06:46 - train: epoch 0004, iter [00220, 01251], lr: 0.001270, loss: 4.5002
2022-10-06 15:07:07 - train: epoch 0004, iter [00230, 01251], lr: 0.001274, loss: 3.9475
2022-10-06 15:07:28 - train: epoch 0004, iter [00240, 01251], lr: 0.001277, loss: 4.6322
2022-10-06 15:07:50 - train: epoch 0004, iter [00250, 01251], lr: 0.001280, loss: 3.7142
2022-10-06 15:08:11 - train: epoch 0004, iter [00260, 01251], lr: 0.001283, loss: 4.7526
2022-10-06 15:08:33 - train: epoch 0004, iter [00270, 01251], lr: 0.001286, loss: 4.8946
2022-10-06 15:08:54 - train: epoch 0004, iter [00280, 01251], lr: 0.001290, loss: 4.2390
2022-10-06 15:09:15 - train: epoch 0004, iter [00290, 01251], lr: 0.001293, loss: 5.0563
2022-10-06 15:09:37 - train: epoch 0004, iter [00300, 01251], lr: 0.001296, loss: 4.3196
2022-10-06 15:09:58 - train: epoch 0004, iter [00310, 01251], lr: 0.001299, loss: 4.5357
2022-10-06 15:10:19 - train: epoch 0004, iter [00320, 01251], lr: 0.001302, loss: 4.7430
2022-10-06 15:10:41 - train: epoch 0004, iter [00330, 01251], lr: 0.001306, loss: 3.8829
2022-10-06 15:11:02 - train: epoch 0004, iter [00340, 01251], lr: 0.001309, loss: 4.2201
2022-10-06 15:11:24 - train: epoch 0004, iter [00350, 01251], lr: 0.001312, loss: 4.6565
2022-10-06 15:11:45 - train: epoch 0004, iter [00360, 01251], lr: 0.001315, loss: 3.7086
2022-10-06 15:12:06 - train: epoch 0004, iter [00370, 01251], lr: 0.001318, loss: 4.4191
2022-10-06 15:12:28 - train: epoch 0004, iter [00380, 01251], lr: 0.001322, loss: 4.4057
2022-10-06 15:12:49 - train: epoch 0004, iter [00390, 01251], lr: 0.001325, loss: 4.0477
2022-10-06 15:13:10 - train: epoch 0004, iter [00400, 01251], lr: 0.001328, loss: 4.4385
2022-10-06 15:13:32 - train: epoch 0004, iter [00410, 01251], lr: 0.001331, loss: 4.3566
2022-10-06 15:13:53 - train: epoch 0004, iter [00420, 01251], lr: 0.001334, loss: 4.1077
2022-10-06 15:14:14 - train: epoch 0004, iter [00430, 01251], lr: 0.001337, loss: 3.9292
2022-10-06 15:14:36 - train: epoch 0004, iter [00440, 01251], lr: 0.001341, loss: 4.2452
2022-10-06 15:14:57 - train: epoch 0004, iter [00450, 01251], lr: 0.001344, loss: 4.6821
2022-10-06 15:15:18 - train: epoch 0004, iter [00460, 01251], lr: 0.001347, loss: 4.6679
2022-10-06 15:15:40 - train: epoch 0004, iter [00470, 01251], lr: 0.001350, loss: 3.1235
2022-10-06 15:16:01 - train: epoch 0004, iter [00480, 01251], lr: 0.001353, loss: 4.5715
2022-10-06 15:16:22 - train: epoch 0004, iter [00490, 01251], lr: 0.001357, loss: 4.9673
2022-10-06 15:16:44 - train: epoch 0004, iter [00500, 01251], lr: 0.001360, loss: 4.2851
2022-10-06 15:17:05 - train: epoch 0004, iter [00510, 01251], lr: 0.001363, loss: 4.5095
2022-10-06 15:17:26 - train: epoch 0004, iter [00520, 01251], lr: 0.001366, loss: 3.9990
2022-10-06 15:17:48 - train: epoch 0004, iter [00530, 01251], lr: 0.001369, loss: 3.0388
2022-10-06 15:18:09 - train: epoch 0004, iter [00540, 01251], lr: 0.001373, loss: 3.6686
2022-10-06 15:18:30 - train: epoch 0004, iter [00550, 01251], lr: 0.001376, loss: 4.7205
2022-10-06 15:18:52 - train: epoch 0004, iter [00560, 01251], lr: 0.001379, loss: 3.8168
2022-10-06 15:19:13 - train: epoch 0004, iter [00570, 01251], lr: 0.001382, loss: 4.4977
2022-10-06 15:19:35 - train: epoch 0004, iter [00580, 01251], lr: 0.001385, loss: 4.0753
2022-10-06 15:19:56 - train: epoch 0004, iter [00590, 01251], lr: 0.001389, loss: 4.4154
2022-10-06 15:20:17 - train: epoch 0004, iter [00600, 01251], lr: 0.001392, loss: 4.5204
2022-10-06 15:20:39 - train: epoch 0004, iter [00610, 01251], lr: 0.001395, loss: 4.3071
2022-10-06 15:21:00 - train: epoch 0004, iter [00620, 01251], lr: 0.001398, loss: 3.5551
2022-10-06 15:21:22 - train: epoch 0004, iter [00630, 01251], lr: 0.001401, loss: 4.3560
2022-10-06 15:21:43 - train: epoch 0004, iter [00640, 01251], lr: 0.001405, loss: 4.2392
2022-10-06 15:22:04 - train: epoch 0004, iter [00650, 01251], lr: 0.001408, loss: 3.8857
2022-10-06 15:22:26 - train: epoch 0004, iter [00660, 01251], lr: 0.001411, loss: 4.8104
2022-10-06 15:22:47 - train: epoch 0004, iter [00670, 01251], lr: 0.001414, loss: 3.9460
2022-10-06 15:23:09 - train: epoch 0004, iter [00680, 01251], lr: 0.001417, loss: 4.1382
2022-10-06 15:23:30 - train: epoch 0004, iter [00690, 01251], lr: 0.001421, loss: 4.5657
2022-10-06 15:23:51 - train: epoch 0004, iter [00700, 01251], lr: 0.001424, loss: 3.7327
2022-10-06 15:24:13 - train: epoch 0004, iter [00710, 01251], lr: 0.001427, loss: 4.2332
2022-10-06 15:24:34 - train: epoch 0004, iter [00720, 01251], lr: 0.001430, loss: 4.0047
2022-10-06 15:24:56 - train: epoch 0004, iter [00730, 01251], lr: 0.001433, loss: 4.3084
2022-10-06 15:25:17 - train: epoch 0004, iter [00740, 01251], lr: 0.001437, loss: 4.6242
2022-10-06 15:25:38 - train: epoch 0004, iter [00750, 01251], lr: 0.001440, loss: 3.7443
2022-10-06 15:26:00 - train: epoch 0004, iter [00760, 01251], lr: 0.001443, loss: 4.2850
2022-10-06 15:26:21 - train: epoch 0004, iter [00770, 01251], lr: 0.001446, loss: 3.7298
2022-10-06 15:26:43 - train: epoch 0004, iter [00780, 01251], lr: 0.001449, loss: 4.4701
2022-10-06 15:27:04 - train: epoch 0004, iter [00790, 01251], lr: 0.001453, loss: 4.5177
2022-10-06 15:27:25 - train: epoch 0004, iter [00800, 01251], lr: 0.001456, loss: 4.2565
2022-10-06 15:27:47 - train: epoch 0004, iter [00810, 01251], lr: 0.001459, loss: 3.7555
2022-10-06 15:28:08 - train: epoch 0004, iter [00820, 01251], lr: 0.001462, loss: 4.1017
2022-10-06 15:28:30 - train: epoch 0004, iter [00830, 01251], lr: 0.001465, loss: 3.8708
2022-10-06 15:28:51 - train: epoch 0004, iter [00840, 01251], lr: 0.001469, loss: 3.8057
2022-10-06 15:29:12 - train: epoch 0004, iter [00850, 01251], lr: 0.001472, loss: 4.2549
2022-10-06 15:29:34 - train: epoch 0004, iter [00860, 01251], lr: 0.001475, loss: 3.3280
2022-10-06 15:29:55 - train: epoch 0004, iter [00870, 01251], lr: 0.001478, loss: 4.2655
2022-10-06 15:30:17 - train: epoch 0004, iter [00880, 01251], lr: 0.001481, loss: 3.3729
2022-10-06 15:30:38 - train: epoch 0004, iter [00890, 01251], lr: 0.001485, loss: 4.1971
2022-10-06 15:30:59 - train: epoch 0004, iter [00900, 01251], lr: 0.001488, loss: 3.9799
2022-10-06 15:31:21 - train: epoch 0004, iter [00910, 01251], lr: 0.001491, loss: 4.6396
2022-10-06 15:31:42 - train: epoch 0004, iter [00920, 01251], lr: 0.001494, loss: 3.1431
2022-10-06 15:32:03 - train: epoch 0004, iter [00930, 01251], lr: 0.001497, loss: 3.5365
2022-10-06 15:32:25 - train: epoch 0004, iter [00940, 01251], lr: 0.001501, loss: 3.5911
2022-10-06 15:32:46 - train: epoch 0004, iter [00950, 01251], lr: 0.001504, loss: 2.9412
2022-10-06 15:33:07 - train: epoch 0004, iter [00960, 01251], lr: 0.001507, loss: 3.5585
2022-10-06 15:33:29 - train: epoch 0004, iter [00970, 01251], lr: 0.001510, loss: 4.5706
2022-10-06 15:33:50 - train: epoch 0004, iter [00980, 01251], lr: 0.001513, loss: 4.6312
2022-10-06 15:34:11 - train: epoch 0004, iter [00990, 01251], lr: 0.001517, loss: 3.9367
2022-10-06 15:34:33 - train: epoch 0004, iter [01000, 01251], lr: 0.001520, loss: 4.0428
2022-10-06 15:34:54 - train: epoch 0004, iter [01010, 01251], lr: 0.001523, loss: 4.1524
2022-10-06 15:35:16 - train: epoch 0004, iter [01020, 01251], lr: 0.001526, loss: 4.1070
2022-10-06 15:35:37 - train: epoch 0004, iter [01030, 01251], lr: 0.001529, loss: 4.1756
2022-10-06 15:35:58 - train: epoch 0004, iter [01040, 01251], lr: 0.001533, loss: 4.6156
2022-10-06 15:36:20 - train: epoch 0004, iter [01050, 01251], lr: 0.001536, loss: 4.4333
2022-10-06 15:36:41 - train: epoch 0004, iter [01060, 01251], lr: 0.001539, loss: 4.9091
2022-10-06 15:37:03 - train: epoch 0004, iter [01070, 01251], lr: 0.001542, loss: 4.1804
2022-10-06 15:37:24 - train: epoch 0004, iter [01080, 01251], lr: 0.001545, loss: 4.2003
2022-10-06 15:37:45 - train: epoch 0004, iter [01090, 01251], lr: 0.001549, loss: 4.8008
2022-10-06 15:38:07 - train: epoch 0004, iter [01100, 01251], lr: 0.001552, loss: 4.5219
2022-10-06 15:38:28 - train: epoch 0004, iter [01110, 01251], lr: 0.001555, loss: 4.7423
2022-10-06 15:38:49 - train: epoch 0004, iter [01120, 01251], lr: 0.001558, loss: 3.5457
2022-10-06 15:39:11 - train: epoch 0004, iter [01130, 01251], lr: 0.001561, loss: 4.6242
2022-10-06 15:39:32 - train: epoch 0004, iter [01140, 01251], lr: 0.001565, loss: 4.3648
2022-10-06 15:39:53 - train: epoch 0004, iter [01150, 01251], lr: 0.001568, loss: 3.5685
2022-10-06 15:40:15 - train: epoch 0004, iter [01160, 01251], lr: 0.001571, loss: 4.1084
2022-10-06 15:40:36 - train: epoch 0004, iter [01170, 01251], lr: 0.001574, loss: 4.3693
2022-10-06 15:40:58 - train: epoch 0004, iter [01180, 01251], lr: 0.001577, loss: 4.4609
2022-10-06 15:41:19 - train: epoch 0004, iter [01190, 01251], lr: 0.001580, loss: 3.7450
2022-10-06 15:41:40 - train: epoch 0004, iter [01200, 01251], lr: 0.001584, loss: 4.5284
2022-10-06 15:42:02 - train: epoch 0004, iter [01210, 01251], lr: 0.001587, loss: 4.2281
2022-10-06 15:42:23 - train: epoch 0004, iter [01220, 01251], lr: 0.001590, loss: 4.0899
2022-10-06 15:42:45 - train: epoch 0004, iter [01230, 01251], lr: 0.001593, loss: 4.3585
2022-10-06 15:43:06 - train: epoch 0004, iter [01240, 01251], lr: 0.001596, loss: 4.5472
2022-10-06 15:43:27 - train: epoch 0004, iter [01250, 01251], lr: 0.001600, loss: 4.7080
2022-10-06 15:43:31 - train: epoch 004, train_loss: 4.2255
2022-10-06 15:44:48 - eval: epoch: 004, acc1: 68.200%, acc5: 89.788%, test_loss: 1.3906, per_image_load_time: 0.558ms, per_image_inference_time: 1.430ms
2022-10-06 15:44:50 - until epoch: 004, best_acc1: 68.200%
2022-10-06 15:44:50 - epoch 005 lr: 0.001600
2022-10-06 15:45:17 - train: epoch 0005, iter [00010, 01251], lr: 0.001603, loss: 4.5200
2022-10-06 15:45:38 - train: epoch 0005, iter [00020, 01251], lr: 0.001606, loss: 4.0920
2022-10-06 15:46:00 - train: epoch 0005, iter [00030, 01251], lr: 0.001610, loss: 3.7155
2022-10-06 15:46:21 - train: epoch 0005, iter [00040, 01251], lr: 0.001613, loss: 4.6531
2022-10-06 15:46:43 - train: epoch 0005, iter [00050, 01251], lr: 0.001616, loss: 4.6846
2022-10-06 15:47:04 - train: epoch 0005, iter [00060, 01251], lr: 0.001619, loss: 4.4144
2022-10-06 15:47:25 - train: epoch 0005, iter [00070, 01251], lr: 0.001622, loss: 4.6985
2022-10-06 15:47:47 - train: epoch 0005, iter [00080, 01251], lr: 0.001626, loss: 4.3814
2022-10-06 15:48:08 - train: epoch 0005, iter [00090, 01251], lr: 0.001629, loss: 3.2956
2022-10-06 15:48:29 - train: epoch 0005, iter [00100, 01251], lr: 0.001632, loss: 4.0902
2022-10-06 15:48:50 - train: epoch 0005, iter [00110, 01251], lr: 0.001635, loss: 3.9083
2022-10-06 15:49:12 - train: epoch 0005, iter [00120, 01251], lr: 0.001638, loss: 4.3438
2022-10-06 15:49:33 - train: epoch 0005, iter [00130, 01251], lr: 0.001642, loss: 4.7431
2022-10-06 15:49:55 - train: epoch 0005, iter [00140, 01251], lr: 0.001645, loss: 4.3088
2022-10-06 15:50:16 - train: epoch 0005, iter [00150, 01251], lr: 0.001648, loss: 4.4555
2022-10-06 15:50:37 - train: epoch 0005, iter [00160, 01251], lr: 0.001651, loss: 4.4810
2022-10-06 15:50:59 - train: epoch 0005, iter [00170, 01251], lr: 0.001654, loss: 3.3643
2022-10-06 15:51:20 - train: epoch 0005, iter [00180, 01251], lr: 0.001658, loss: 4.4780
2022-10-06 15:51:41 - train: epoch 0005, iter [00190, 01251], lr: 0.001661, loss: 4.5138
2022-10-06 15:52:03 - train: epoch 0005, iter [00200, 01251], lr: 0.001664, loss: 5.0718
2022-10-06 15:52:24 - train: epoch 0005, iter [00210, 01251], lr: 0.001667, loss: 3.7318
2022-10-06 15:52:45 - train: epoch 0005, iter [00220, 01251], lr: 0.001670, loss: 3.3215
2022-10-06 15:53:07 - train: epoch 0005, iter [00230, 01251], lr: 0.001674, loss: 4.0561
2022-10-06 15:53:28 - train: epoch 0005, iter [00240, 01251], lr: 0.001677, loss: 2.9297
2022-10-06 15:53:49 - train: epoch 0005, iter [00250, 01251], lr: 0.001680, loss: 4.4209
2022-10-06 15:54:11 - train: epoch 0005, iter [00260, 01251], lr: 0.001683, loss: 3.9751
2022-10-06 15:54:32 - train: epoch 0005, iter [00270, 01251], lr: 0.001686, loss: 3.6735
2022-10-06 15:54:53 - train: epoch 0005, iter [00280, 01251], lr: 0.001690, loss: 3.8604
2022-10-06 15:55:15 - train: epoch 0005, iter [00290, 01251], lr: 0.001693, loss: 3.8568
2022-10-06 15:55:36 - train: epoch 0005, iter [00300, 01251], lr: 0.001696, loss: 3.9811
2022-10-06 15:55:57 - train: epoch 0005, iter [00310, 01251], lr: 0.001699, loss: 4.5786
2022-10-06 15:56:19 - train: epoch 0005, iter [00320, 01251], lr: 0.001702, loss: 3.1999
2022-10-06 15:56:40 - train: epoch 0005, iter [00330, 01251], lr: 0.001706, loss: 4.7206
2022-10-06 15:57:02 - train: epoch 0005, iter [00340, 01251], lr: 0.001709, loss: 3.8593
2022-10-06 15:57:23 - train: epoch 0005, iter [00350, 01251], lr: 0.001712, loss: 4.2632
2022-10-06 15:57:44 - train: epoch 0005, iter [00360, 01251], lr: 0.001715, loss: 4.5576
2022-10-06 15:58:06 - train: epoch 0005, iter [00370, 01251], lr: 0.001718, loss: 4.4388
2022-10-06 15:58:27 - train: epoch 0005, iter [00380, 01251], lr: 0.001722, loss: 3.9709
2022-10-06 15:58:48 - train: epoch 0005, iter [00390, 01251], lr: 0.001725, loss: 3.9984
2022-10-06 15:59:10 - train: epoch 0005, iter [00400, 01251], lr: 0.001728, loss: 3.8109
2022-10-06 15:59:31 - train: epoch 0005, iter [00410, 01251], lr: 0.001731, loss: 4.0132
2022-10-06 15:59:53 - train: epoch 0005, iter [00420, 01251], lr: 0.001734, loss: 4.5632
2022-10-06 16:00:14 - train: epoch 0005, iter [00430, 01251], lr: 0.001737, loss: 3.1491
2022-10-06 16:00:35 - train: epoch 0005, iter [00440, 01251], lr: 0.001741, loss: 4.2568
2022-10-06 16:00:56 - train: epoch 0005, iter [00450, 01251], lr: 0.001744, loss: 3.5639
2022-10-06 16:01:18 - train: epoch 0005, iter [00460, 01251], lr: 0.001747, loss: 3.6001
2022-10-06 16:01:39 - train: epoch 0005, iter [00470, 01251], lr: 0.001750, loss: 3.9678
2022-10-06 16:02:00 - train: epoch 0005, iter [00480, 01251], lr: 0.001753, loss: 4.1735
2022-10-06 16:02:22 - train: epoch 0005, iter [00490, 01251], lr: 0.001757, loss: 4.5595
2022-10-06 16:02:43 - train: epoch 0005, iter [00500, 01251], lr: 0.001760, loss: 4.1594
2022-10-06 16:03:04 - train: epoch 0005, iter [00510, 01251], lr: 0.001763, loss: 4.1844
2022-10-06 16:03:26 - train: epoch 0005, iter [00520, 01251], lr: 0.001766, loss: 4.0558
2022-10-06 16:03:47 - train: epoch 0005, iter [00530, 01251], lr: 0.001769, loss: 4.2278
2022-10-06 16:04:08 - train: epoch 0005, iter [00540, 01251], lr: 0.001773, loss: 4.8367
2022-10-06 16:04:30 - train: epoch 0005, iter [00550, 01251], lr: 0.001776, loss: 4.0085
2022-10-06 16:04:51 - train: epoch 0005, iter [00560, 01251], lr: 0.001779, loss: 4.4586
2022-10-06 16:05:12 - train: epoch 0005, iter [00570, 01251], lr: 0.001782, loss: 4.3435
2022-10-06 16:05:34 - train: epoch 0005, iter [00580, 01251], lr: 0.001785, loss: 3.5847
2022-10-06 16:05:55 - train: epoch 0005, iter [00590, 01251], lr: 0.001789, loss: 3.9786
2022-10-06 16:06:17 - train: epoch 0005, iter [00600, 01251], lr: 0.001792, loss: 4.4176
2022-10-06 16:06:38 - train: epoch 0005, iter [00610, 01251], lr: 0.001795, loss: 4.3783
2022-10-06 16:06:59 - train: epoch 0005, iter [00620, 01251], lr: 0.001798, loss: 4.2974
2022-10-06 16:07:21 - train: epoch 0005, iter [00630, 01251], lr: 0.001801, loss: 3.9774
2022-10-06 16:07:42 - train: epoch 0005, iter [00640, 01251], lr: 0.001805, loss: 4.0628
2022-10-06 16:08:03 - train: epoch 0005, iter [00650, 01251], lr: 0.001808, loss: 5.0073
2022-10-06 16:08:25 - train: epoch 0005, iter [00660, 01251], lr: 0.001811, loss: 4.2449
2022-10-06 16:08:46 - train: epoch 0005, iter [00670, 01251], lr: 0.001814, loss: 4.5193
2022-10-06 16:09:08 - train: epoch 0005, iter [00680, 01251], lr: 0.001817, loss: 4.4561
2022-10-06 16:09:29 - train: epoch 0005, iter [00690, 01251], lr: 0.001821, loss: 3.8489
2022-10-06 16:09:50 - train: epoch 0005, iter [00700, 01251], lr: 0.001824, loss: 4.2663
2022-10-06 16:10:12 - train: epoch 0005, iter [00710, 01251], lr: 0.001827, loss: 4.1341
2022-10-06 16:10:33 - train: epoch 0005, iter [00720, 01251], lr: 0.001830, loss: 4.6861
2022-10-06 16:10:55 - train: epoch 0005, iter [00730, 01251], lr: 0.001833, loss: 4.4367
2022-10-06 16:11:16 - train: epoch 0005, iter [00740, 01251], lr: 0.001837, loss: 4.8431
2022-10-06 16:11:37 - train: epoch 0005, iter [00750, 01251], lr: 0.001840, loss: 3.7550
2022-10-06 16:11:58 - train: epoch 0005, iter [00760, 01251], lr: 0.001843, loss: 3.4363
2022-10-06 16:12:20 - train: epoch 0005, iter [00770, 01251], lr: 0.001846, loss: 4.3997
2022-10-06 16:12:41 - train: epoch 0005, iter [00780, 01251], lr: 0.001849, loss: 4.7791
2022-10-06 16:13:03 - train: epoch 0005, iter [00790, 01251], lr: 0.001853, loss: 4.2531
2022-10-06 16:13:24 - train: epoch 0005, iter [00800, 01251], lr: 0.001856, loss: 3.5224
2022-10-06 16:13:45 - train: epoch 0005, iter [00810, 01251], lr: 0.001859, loss: 4.6327
2022-10-06 16:14:06 - train: epoch 0005, iter [00820, 01251], lr: 0.001862, loss: 4.4746
2022-10-06 16:14:28 - train: epoch 0005, iter [00830, 01251], lr: 0.001865, loss: 3.7768
2022-10-06 16:14:49 - train: epoch 0005, iter [00840, 01251], lr: 0.001869, loss: 4.3492
2022-10-06 16:15:11 - train: epoch 0005, iter [00850, 01251], lr: 0.001872, loss: 4.4451
2022-10-06 16:15:32 - train: epoch 0005, iter [00860, 01251], lr: 0.001875, loss: 3.1887
2022-10-06 16:15:53 - train: epoch 0005, iter [00870, 01251], lr: 0.001878, loss: 4.5588
2022-10-06 16:16:15 - train: epoch 0005, iter [00880, 01251], lr: 0.001881, loss: 3.3907
2022-10-06 16:16:36 - train: epoch 0005, iter [00890, 01251], lr: 0.001885, loss: 4.2158
2022-10-06 16:16:58 - train: epoch 0005, iter [00900, 01251], lr: 0.001888, loss: 4.2763
2022-10-06 16:17:19 - train: epoch 0005, iter [00910, 01251], lr: 0.001891, loss: 3.8981
2022-10-06 16:17:40 - train: epoch 0005, iter [00920, 01251], lr: 0.001894, loss: 4.1735
2022-10-06 16:18:02 - train: epoch 0005, iter [00930, 01251], lr: 0.001897, loss: 4.0826
2022-10-06 16:18:23 - train: epoch 0005, iter [00940, 01251], lr: 0.001901, loss: 3.5755
2022-10-06 16:18:44 - train: epoch 0005, iter [00950, 01251], lr: 0.001904, loss: 4.3676
2022-10-06 16:19:06 - train: epoch 0005, iter [00960, 01251], lr: 0.001907, loss: 3.9794
2022-10-06 16:19:27 - train: epoch 0005, iter [00970, 01251], lr: 0.001910, loss: 4.1618
2022-10-06 16:19:49 - train: epoch 0005, iter [00980, 01251], lr: 0.001913, loss: 3.8426
2022-10-06 16:20:10 - train: epoch 0005, iter [00990, 01251], lr: 0.001917, loss: 4.3700
2022-10-06 16:20:31 - train: epoch 0005, iter [01000, 01251], lr: 0.001920, loss: 4.3308
2022-10-06 16:20:53 - train: epoch 0005, iter [01010, 01251], lr: 0.001923, loss: 4.0626
2022-10-06 16:21:14 - train: epoch 0005, iter [01020, 01251], lr: 0.001926, loss: 3.9820
2022-10-06 16:21:35 - train: epoch 0005, iter [01030, 01251], lr: 0.001929, loss: 4.6988
2022-10-06 16:21:57 - train: epoch 0005, iter [01040, 01251], lr: 0.001933, loss: 4.4007
2022-10-06 16:22:18 - train: epoch 0005, iter [01050, 01251], lr: 0.001936, loss: 4.5858
2022-10-06 16:22:39 - train: epoch 0005, iter [01060, 01251], lr: 0.001939, loss: 3.9275
2022-10-06 16:23:01 - train: epoch 0005, iter [01070, 01251], lr: 0.001942, loss: 3.6317
2022-10-06 16:23:22 - train: epoch 0005, iter [01080, 01251], lr: 0.001945, loss: 3.8608
2022-10-06 16:23:44 - train: epoch 0005, iter [01090, 01251], lr: 0.001949, loss: 3.9443
2022-10-06 16:24:05 - train: epoch 0005, iter [01100, 01251], lr: 0.001952, loss: 3.7730
2022-10-06 16:24:26 - train: epoch 0005, iter [01110, 01251], lr: 0.001955, loss: 4.3084
2022-10-06 16:24:48 - train: epoch 0005, iter [01120, 01251], lr: 0.001958, loss: 3.6855
2022-10-06 16:25:09 - train: epoch 0005, iter [01130, 01251], lr: 0.001961, loss: 4.0698
2022-10-06 16:25:31 - train: epoch 0005, iter [01140, 01251], lr: 0.001965, loss: 4.5579
2022-10-06 16:25:52 - train: epoch 0005, iter [01150, 01251], lr: 0.001968, loss: 4.0979
2022-10-06 16:26:13 - train: epoch 0005, iter [01160, 01251], lr: 0.001971, loss: 3.8489
2022-10-06 16:26:35 - train: epoch 0005, iter [01170, 01251], lr: 0.001974, loss: 3.5863
2022-10-06 16:26:56 - train: epoch 0005, iter [01180, 01251], lr: 0.001977, loss: 3.0605
2022-10-06 16:27:17 - train: epoch 0005, iter [01190, 01251], lr: 0.001980, loss: 4.4891
2022-10-06 16:27:39 - train: epoch 0005, iter [01200, 01251], lr: 0.001984, loss: 4.0359
2022-10-06 16:28:00 - train: epoch 0005, iter [01210, 01251], lr: 0.001987, loss: 4.3847
2022-10-06 16:28:21 - train: epoch 0005, iter [01220, 01251], lr: 0.001990, loss: 3.5247
2022-10-06 16:28:43 - train: epoch 0005, iter [01230, 01251], lr: 0.001993, loss: 3.9135
2022-10-06 16:29:04 - train: epoch 0005, iter [01240, 01251], lr: 0.001996, loss: 4.3134
2022-10-06 16:29:25 - train: epoch 0005, iter [01250, 01251], lr: 0.002000, loss: 4.0625
2022-10-06 16:29:29 - train: epoch 005, train_loss: 4.1266
2022-10-06 16:30:46 - eval: epoch: 005, acc1: 68.806%, acc5: 90.212%, test_loss: 1.3923, per_image_load_time: 0.613ms, per_image_inference_time: 1.438ms
2022-10-06 16:30:48 - until epoch: 005, best_acc1: 68.806%
2022-10-06 16:30:48 - epoch 006 lr: 0.002000
2022-10-06 16:31:15 - train: epoch 0006, iter [00010, 01251], lr: 0.002000, loss: 2.9380
2022-10-06 16:31:36 - train: epoch 0006, iter [00020, 01251], lr: 0.002000, loss: 3.6363
2022-10-06 16:31:58 - train: epoch 0006, iter [00030, 01251], lr: 0.002000, loss: 4.0722
2022-10-06 16:32:19 - train: epoch 0006, iter [00040, 01251], lr: 0.002000, loss: 3.7766
2022-10-06 16:32:40 - train: epoch 0006, iter [00050, 01251], lr: 0.002000, loss: 4.8619
2022-10-06 16:33:02 - train: epoch 0006, iter [00060, 01251], lr: 0.002000, loss: 4.1899
2022-10-06 16:33:23 - train: epoch 0006, iter [00070, 01251], lr: 0.002000, loss: 4.4109
2022-10-06 16:33:44 - train: epoch 0006, iter [00080, 01251], lr: 0.002000, loss: 4.5460
2022-10-06 16:34:06 - train: epoch 0006, iter [00090, 01251], lr: 0.002000, loss: 3.7711
2022-10-06 16:34:27 - train: epoch 0006, iter [00100, 01251], lr: 0.002000, loss: 4.5644
2022-10-06 16:34:48 - train: epoch 0006, iter [00110, 01251], lr: 0.002000, loss: 4.1347
2022-10-06 16:35:10 - train: epoch 0006, iter [00120, 01251], lr: 0.002000, loss: 3.6636
2022-10-06 16:35:31 - train: epoch 0006, iter [00130, 01251], lr: 0.002000, loss: 4.3288
2022-10-06 16:35:53 - train: epoch 0006, iter [00140, 01251], lr: 0.002000, loss: 3.8756
2022-10-06 16:36:14 - train: epoch 0006, iter [00150, 01251], lr: 0.002000, loss: 3.8067
2022-10-06 16:36:35 - train: epoch 0006, iter [00160, 01251], lr: 0.002000, loss: 3.7208
2022-10-06 16:36:57 - train: epoch 0006, iter [00170, 01251], lr: 0.002000, loss: 3.7989
2022-10-06 16:37:18 - train: epoch 0006, iter [00180, 01251], lr: 0.002000, loss: 3.9113
2022-10-06 16:37:40 - train: epoch 0006, iter [00190, 01251], lr: 0.002000, loss: 3.9671
2022-10-06 16:38:01 - train: epoch 0006, iter [00200, 01251], lr: 0.002000, loss: 4.2016
2022-10-06 16:38:22 - train: epoch 0006, iter [00210, 01251], lr: 0.002000, loss: 4.6123
2022-10-06 16:38:44 - train: epoch 0006, iter [00220, 01251], lr: 0.002000, loss: 4.1709
2022-10-06 16:39:05 - train: epoch 0006, iter [00230, 01251], lr: 0.002000, loss: 4.2755
2022-10-06 16:39:27 - train: epoch 0006, iter [00240, 01251], lr: 0.002000, loss: 4.5499
2022-10-06 16:39:48 - train: epoch 0006, iter [00250, 01251], lr: 0.002000, loss: 3.5583
2022-10-06 16:40:09 - train: epoch 0006, iter [00260, 01251], lr: 0.002000, loss: 4.4744
2022-10-06 16:40:31 - train: epoch 0006, iter [00270, 01251], lr: 0.002000, loss: 4.1183
2022-10-06 16:40:52 - train: epoch 0006, iter [00280, 01251], lr: 0.002000, loss: 4.5808
2022-10-06 16:41:13 - train: epoch 0006, iter [00290, 01251], lr: 0.002000, loss: 4.8068
2022-10-06 16:41:35 - train: epoch 0006, iter [00300, 01251], lr: 0.002000, loss: 4.4093
2022-10-06 16:41:56 - train: epoch 0006, iter [00310, 01251], lr: 0.002000, loss: 4.7270
2022-10-06 16:42:18 - train: epoch 0006, iter [00320, 01251], lr: 0.002000, loss: 3.5306
2022-10-06 16:42:39 - train: epoch 0006, iter [00330, 01251], lr: 0.002000, loss: 4.3495
2022-10-06 16:43:00 - train: epoch 0006, iter [00340, 01251], lr: 0.002000, loss: 3.6308
2022-10-06 16:43:22 - train: epoch 0006, iter [00350, 01251], lr: 0.002000, loss: 4.0591
2022-10-06 16:43:43 - train: epoch 0006, iter [00360, 01251], lr: 0.002000, loss: 4.2628
2022-10-06 16:44:05 - train: epoch 0006, iter [00370, 01251], lr: 0.002000, loss: 3.5729
2022-10-06 16:44:26 - train: epoch 0006, iter [00380, 01251], lr: 0.002000, loss: 3.7571
2022-10-06 16:44:47 - train: epoch 0006, iter [00390, 01251], lr: 0.002000, loss: 4.5400
2022-10-06 16:45:09 - train: epoch 0006, iter [00400, 01251], lr: 0.002000, loss: 4.0371
2022-10-06 16:45:30 - train: epoch 0006, iter [00410, 01251], lr: 0.002000, loss: 4.4833
2022-10-06 16:45:52 - train: epoch 0006, iter [00420, 01251], lr: 0.002000, loss: 3.3259
2022-10-06 16:46:13 - train: epoch 0006, iter [00430, 01251], lr: 0.002000, loss: 3.8214
2022-10-06 16:46:34 - train: epoch 0006, iter [00440, 01251], lr: 0.002000, loss: 4.0987
2022-10-06 16:46:56 - train: epoch 0006, iter [00450, 01251], lr: 0.002000, loss: 4.3303
2022-10-06 16:47:17 - train: epoch 0006, iter [00460, 01251], lr: 0.002000, loss: 3.6217
2022-10-06 16:47:38 - train: epoch 0006, iter [00470, 01251], lr: 0.002000, loss: 3.2634
2022-10-06 16:48:00 - train: epoch 0006, iter [00480, 01251], lr: 0.002000, loss: 4.7123
2022-10-06 16:48:21 - train: epoch 0006, iter [00490, 01251], lr: 0.002000, loss: 3.5743
2022-10-06 16:48:43 - train: epoch 0006, iter [00500, 01251], lr: 0.002000, loss: 4.6260
2022-10-06 16:49:04 - train: epoch 0006, iter [00510, 01251], lr: 0.002000, loss: 4.3289
2022-10-06 16:49:25 - train: epoch 0006, iter [00520, 01251], lr: 0.002000, loss: 4.3586
2022-10-06 16:49:47 - train: epoch 0006, iter [00530, 01251], lr: 0.002000, loss: 4.2522
2022-10-06 16:50:08 - train: epoch 0006, iter [00540, 01251], lr: 0.002000, loss: 4.3779
2022-10-06 16:50:30 - train: epoch 0006, iter [00550, 01251], lr: 0.002000, loss: 4.3901
2022-10-06 16:50:51 - train: epoch 0006, iter [00560, 01251], lr: 0.002000, loss: 3.3687
2022-10-06 16:51:12 - train: epoch 0006, iter [00570, 01251], lr: 0.002000, loss: 4.2946
2022-10-06 16:51:34 - train: epoch 0006, iter [00580, 01251], lr: 0.002000, loss: 4.0279
2022-10-06 16:51:55 - train: epoch 0006, iter [00590, 01251], lr: 0.002000, loss: 3.6835
2022-10-06 16:52:17 - train: epoch 0006, iter [00600, 01251], lr: 0.002000, loss: 3.9916
2022-10-06 16:52:38 - train: epoch 0006, iter [00610, 01251], lr: 0.002000, loss: 3.6171
2022-10-06 16:52:59 - train: epoch 0006, iter [00620, 01251], lr: 0.002000, loss: 4.7099
2022-10-06 16:53:21 - train: epoch 0006, iter [00630, 01251], lr: 0.002000, loss: 4.3978
2022-10-06 16:53:42 - train: epoch 0006, iter [00640, 01251], lr: 0.002000, loss: 3.6853
2022-10-06 16:54:04 - train: epoch 0006, iter [00650, 01251], lr: 0.002000, loss: 3.8475
2022-10-06 16:54:25 - train: epoch 0006, iter [00660, 01251], lr: 0.002000, loss: 4.0754
2022-10-06 16:54:47 - train: epoch 0006, iter [00670, 01251], lr: 0.002000, loss: 3.8359
2022-10-06 16:55:08 - train: epoch 0006, iter [00680, 01251], lr: 0.002000, loss: 3.6866
2022-10-06 16:55:29 - train: epoch 0006, iter [00690, 01251], lr: 0.002000, loss: 3.8530
2022-10-06 16:55:51 - train: epoch 0006, iter [00700, 01251], lr: 0.002000, loss: 4.2570
2022-10-06 16:56:12 - train: epoch 0006, iter [00710, 01251], lr: 0.002000, loss: 4.0832
2022-10-06 16:56:33 - train: epoch 0006, iter [00720, 01251], lr: 0.002000, loss: 4.4103
2022-10-06 16:56:55 - train: epoch 0006, iter [00730, 01251], lr: 0.002000, loss: 4.0675
2022-10-06 16:57:16 - train: epoch 0006, iter [00740, 01251], lr: 0.002000, loss: 3.3197
2022-10-06 16:57:38 - train: epoch 0006, iter [00750, 01251], lr: 0.002000, loss: 3.9983
2022-10-06 16:57:59 - train: epoch 0006, iter [00760, 01251], lr: 0.002000, loss: 3.5086
2022-10-06 16:58:20 - train: epoch 0006, iter [00770, 01251], lr: 0.002000, loss: 3.3955
2022-10-06 16:58:42 - train: epoch 0006, iter [00780, 01251], lr: 0.002000, loss: 4.4135
2022-10-06 16:59:03 - train: epoch 0006, iter [00790, 01251], lr: 0.002000, loss: 3.8018
2022-10-06 16:59:25 - train: epoch 0006, iter [00800, 01251], lr: 0.002000, loss: 4.0320
2022-10-06 16:59:46 - train: epoch 0006, iter [00810, 01251], lr: 0.002000, loss: 4.4224
2022-10-06 17:00:07 - train: epoch 0006, iter [00820, 01251], lr: 0.002000, loss: 3.2040
2022-10-06 17:00:29 - train: epoch 0006, iter [00830, 01251], lr: 0.002000, loss: 4.4758
2022-10-06 17:00:50 - train: epoch 0006, iter [00840, 01251], lr: 0.002000, loss: 4.4939
2022-10-06 17:01:11 - train: epoch 0006, iter [00850, 01251], lr: 0.002000, loss: 4.0533
2022-10-06 17:01:33 - train: epoch 0006, iter [00860, 01251], lr: 0.002000, loss: 3.9971
2022-10-06 17:01:54 - train: epoch 0006, iter [00870, 01251], lr: 0.002000, loss: 4.3131
2022-10-06 17:02:15 - train: epoch 0006, iter [00880, 01251], lr: 0.002000, loss: 4.5164
2022-10-06 17:02:37 - train: epoch 0006, iter [00890, 01251], lr: 0.002000, loss: 4.1049
2022-10-06 17:02:58 - train: epoch 0006, iter [00900, 01251], lr: 0.002000, loss: 4.6772
2022-10-06 17:03:20 - train: epoch 0006, iter [00910, 01251], lr: 0.002000, loss: 3.9072
2022-10-06 17:03:41 - train: epoch 0006, iter [00920, 01251], lr: 0.002000, loss: 3.9315
2022-10-06 17:04:02 - train: epoch 0006, iter [00930, 01251], lr: 0.002000, loss: 4.1125
2022-10-06 17:04:24 - train: epoch 0006, iter [00940, 01251], lr: 0.002000, loss: 4.4658
2022-10-06 17:04:45 - train: epoch 0006, iter [00950, 01251], lr: 0.002000, loss: 3.7465
2022-10-06 17:05:06 - train: epoch 0006, iter [00960, 01251], lr: 0.002000, loss: 4.5713
2022-10-06 17:05:28 - train: epoch 0006, iter [00970, 01251], lr: 0.002000, loss: 3.8621
2022-10-06 17:05:49 - train: epoch 0006, iter [00980, 01251], lr: 0.002000, loss: 4.0453
2022-10-06 17:06:10 - train: epoch 0006, iter [00990, 01251], lr: 0.002000, loss: 3.6317
2022-10-06 17:06:32 - train: epoch 0006, iter [01000, 01251], lr: 0.002000, loss: 3.7213
2022-10-06 17:06:53 - train: epoch 0006, iter [01010, 01251], lr: 0.002000, loss: 2.9782
2022-10-06 17:07:14 - train: epoch 0006, iter [01020, 01251], lr: 0.002000, loss: 3.8946
2022-10-06 17:07:36 - train: epoch 0006, iter [01030, 01251], lr: 0.002000, loss: 3.2205
2022-10-06 17:07:57 - train: epoch 0006, iter [01040, 01251], lr: 0.002000, loss: 4.4365
2022-10-06 17:08:19 - train: epoch 0006, iter [01050, 01251], lr: 0.002000, loss: 4.2604
2022-10-06 17:08:40 - train: epoch 0006, iter [01060, 01251], lr: 0.002000, loss: 4.2625
2022-10-06 17:09:01 - train: epoch 0006, iter [01070, 01251], lr: 0.002000, loss: 3.7726
2022-10-06 17:09:23 - train: epoch 0006, iter [01080, 01251], lr: 0.002000, loss: 4.0841
2022-10-06 17:09:44 - train: epoch 0006, iter [01090, 01251], lr: 0.002000, loss: 4.2629
2022-10-06 17:10:05 - train: epoch 0006, iter [01100, 01251], lr: 0.002000, loss: 3.8207
2022-10-06 17:10:27 - train: epoch 0006, iter [01110, 01251], lr: 0.002000, loss: 4.2991
2022-10-06 17:10:48 - train: epoch 0006, iter [01120, 01251], lr: 0.002000, loss: 3.9757
2022-10-06 17:11:09 - train: epoch 0006, iter [01130, 01251], lr: 0.002000, loss: 3.7505
2022-10-06 17:11:31 - train: epoch 0006, iter [01140, 01251], lr: 0.002000, loss: 3.6686
2022-10-06 17:11:52 - train: epoch 0006, iter [01150, 01251], lr: 0.002000, loss: 4.6135
2022-10-06 17:12:13 - train: epoch 0006, iter [01160, 01251], lr: 0.002000, loss: 4.2523
2022-10-06 17:12:34 - train: epoch 0006, iter [01170, 01251], lr: 0.002000, loss: 4.2782
2022-10-06 17:12:56 - train: epoch 0006, iter [01180, 01251], lr: 0.002000, loss: 3.9093
2022-10-06 17:13:17 - train: epoch 0006, iter [01190, 01251], lr: 0.002000, loss: 4.1258
2022-10-06 17:13:38 - train: epoch 0006, iter [01200, 01251], lr: 0.001999, loss: 4.1867
2022-10-06 17:14:00 - train: epoch 0006, iter [01210, 01251], lr: 0.001999, loss: 3.6576
2022-10-06 17:14:21 - train: epoch 0006, iter [01220, 01251], lr: 0.001999, loss: 4.1448
2022-10-06 17:14:42 - train: epoch 0006, iter [01230, 01251], lr: 0.001999, loss: 3.4729
2022-10-06 17:15:04 - train: epoch 0006, iter [01240, 01251], lr: 0.001999, loss: 3.8217
2022-10-06 17:15:25 - train: epoch 0006, iter [01250, 01251], lr: 0.001999, loss: 3.7932
2022-10-06 17:15:29 - train: epoch 006, train_loss: 4.0436
2022-10-06 17:16:46 - eval: epoch: 006, acc1: 70.692%, acc5: 90.884%, test_loss: 1.2925, per_image_load_time: 1.159ms, per_image_inference_time: 1.439ms
2022-10-06 17:16:47 - until epoch: 006, best_acc1: 70.692%
2022-10-06 17:16:47 - epoch 007 lr: 0.001999
2022-10-06 17:17:15 - train: epoch 0007, iter [00010, 01251], lr: 0.001999, loss: 3.7858
2022-10-06 17:17:36 - train: epoch 0007, iter [00020, 01251], lr: 0.001999, loss: 3.9127
2022-10-06 17:17:57 - train: epoch 0007, iter [00030, 01251], lr: 0.001999, loss: 4.1246
2022-10-06 17:18:19 - train: epoch 0007, iter [00040, 01251], lr: 0.001999, loss: 3.3916
2022-10-06 17:18:40 - train: epoch 0007, iter [00050, 01251], lr: 0.001999, loss: 4.3884
2022-10-06 17:19:02 - train: epoch 0007, iter [00060, 01251], lr: 0.001999, loss: 3.9338
2022-10-06 17:19:23 - train: epoch 0007, iter [00070, 01251], lr: 0.001999, loss: 3.7147
2022-10-06 17:19:44 - train: epoch 0007, iter [00080, 01251], lr: 0.001999, loss: 3.7552
2022-10-06 17:20:06 - train: epoch 0007, iter [00090, 01251], lr: 0.001999, loss: 4.7770
2022-10-06 17:20:27 - train: epoch 0007, iter [00100, 01251], lr: 0.001999, loss: 3.8574
2022-10-06 17:20:48 - train: epoch 0007, iter [00110, 01251], lr: 0.001999, loss: 4.0442
2022-10-06 17:21:10 - train: epoch 0007, iter [00120, 01251], lr: 0.001999, loss: 3.8374
2022-10-06 17:21:31 - train: epoch 0007, iter [00130, 01251], lr: 0.001999, loss: 4.0982
2022-10-06 17:21:53 - train: epoch 0007, iter [00140, 01251], lr: 0.001999, loss: 3.9001
2022-10-06 17:22:14 - train: epoch 0007, iter [00150, 01251], lr: 0.001999, loss: 3.8247
2022-10-06 17:22:35 - train: epoch 0007, iter [00160, 01251], lr: 0.001999, loss: 4.2665
2022-10-06 17:22:57 - train: epoch 0007, iter [00170, 01251], lr: 0.001999, loss: 3.7271
2022-10-06 17:23:18 - train: epoch 0007, iter [00180, 01251], lr: 0.001999, loss: 3.9434
2022-10-06 17:23:40 - train: epoch 0007, iter [00190, 01251], lr: 0.001999, loss: 3.4649
2022-10-06 17:24:01 - train: epoch 0007, iter [00200, 01251], lr: 0.001999, loss: 3.9589
2022-10-06 17:24:22 - train: epoch 0007, iter [00210, 01251], lr: 0.001999, loss: 3.2385
2022-10-06 17:24:44 - train: epoch 0007, iter [00220, 01251], lr: 0.001999, loss: 4.7836
2022-10-06 17:25:05 - train: epoch 0007, iter [00230, 01251], lr: 0.001999, loss: 4.5196
2022-10-06 17:25:27 - train: epoch 0007, iter [00240, 01251], lr: 0.001999, loss: 4.2612
2022-10-06 17:25:48 - train: epoch 0007, iter [00250, 01251], lr: 0.001999, loss: 4.2717
2022-10-06 17:26:09 - train: epoch 0007, iter [00260, 01251], lr: 0.001999, loss: 3.9897
2022-10-06 17:26:31 - train: epoch 0007, iter [00270, 01251], lr: 0.001999, loss: 3.4022
2022-10-06 17:26:52 - train: epoch 0007, iter [00280, 01251], lr: 0.001999, loss: 3.7947
2022-10-06 17:27:14 - train: epoch 0007, iter [00290, 01251], lr: 0.001999, loss: 3.6888
2022-10-06 17:27:35 - train: epoch 0007, iter [00300, 01251], lr: 0.001999, loss: 3.8008
2022-10-06 17:27:57 - train: epoch 0007, iter [00310, 01251], lr: 0.001999, loss: 4.4166
2022-10-06 17:28:18 - train: epoch 0007, iter [00320, 01251], lr: 0.001999, loss: 2.8796
2022-10-06 17:28:39 - train: epoch 0007, iter [00330, 01251], lr: 0.001999, loss: 3.7285
2022-10-06 17:29:01 - train: epoch 0007, iter [00340, 01251], lr: 0.001999, loss: 4.7149
2022-10-06 17:29:22 - train: epoch 0007, iter [00350, 01251], lr: 0.001999, loss: 4.1659
2022-10-06 17:29:44 - train: epoch 0007, iter [00360, 01251], lr: 0.001999, loss: 4.3333
2022-10-06 17:30:05 - train: epoch 0007, iter [00370, 01251], lr: 0.001999, loss: 3.4619
2022-10-06 17:30:26 - train: epoch 0007, iter [00380, 01251], lr: 0.001999, loss: 4.2024
2022-10-06 17:30:48 - train: epoch 0007, iter [00390, 01251], lr: 0.001999, loss: 3.8119
2022-10-06 17:31:09 - train: epoch 0007, iter [00400, 01251], lr: 0.001999, loss: 3.1393
2022-10-06 17:31:30 - train: epoch 0007, iter [00410, 01251], lr: 0.001999, loss: 4.2754
2022-10-06 17:31:52 - train: epoch 0007, iter [00420, 01251], lr: 0.001999, loss: 3.4181
2022-10-06 17:32:13 - train: epoch 0007, iter [00430, 01251], lr: 0.001999, loss: 4.1511
2022-10-06 17:32:34 - train: epoch 0007, iter [00440, 01251], lr: 0.001999, loss: 3.7611
2022-10-06 17:32:56 - train: epoch 0007, iter [00450, 01251], lr: 0.001999, loss: 4.4238
2022-10-06 17:33:17 - train: epoch 0007, iter [00460, 01251], lr: 0.001999, loss: 3.6279
2022-10-06 17:33:39 - train: epoch 0007, iter [00470, 01251], lr: 0.001999, loss: 4.2044
2022-10-06 17:34:00 - train: epoch 0007, iter [00480, 01251], lr: 0.001999, loss: 4.3118
2022-10-06 17:34:21 - train: epoch 0007, iter [00490, 01251], lr: 0.001999, loss: 4.3335
2022-10-06 17:34:43 - train: epoch 0007, iter [00500, 01251], lr: 0.001999, loss: 4.1722
2022-10-06 17:35:04 - train: epoch 0007, iter [00510, 01251], lr: 0.001999, loss: 3.9980
2022-10-06 17:35:26 - train: epoch 0007, iter [00520, 01251], lr: 0.001999, loss: 4.6287
2022-10-06 17:35:47 - train: epoch 0007, iter [00530, 01251], lr: 0.001999, loss: 3.6822
2022-10-06 17:36:09 - train: epoch 0007, iter [00540, 01251], lr: 0.001999, loss: 4.1105
2022-10-06 17:36:30 - train: epoch 0007, iter [00550, 01251], lr: 0.001999, loss: 3.7315
2022-10-06 17:36:51 - train: epoch 0007, iter [00560, 01251], lr: 0.001999, loss: 4.2427
2022-10-06 17:37:13 - train: epoch 0007, iter [00570, 01251], lr: 0.001999, loss: 4.6583
2022-10-06 17:37:34 - train: epoch 0007, iter [00580, 01251], lr: 0.001999, loss: 3.8839
2022-10-06 17:37:56 - train: epoch 0007, iter [00590, 01251], lr: 0.001999, loss: 4.5063
2022-10-06 17:38:17 - train: epoch 0007, iter [00600, 01251], lr: 0.001999, loss: 4.1039
2022-10-06 17:38:38 - train: epoch 0007, iter [00610, 01251], lr: 0.001999, loss: 3.8682
2022-10-06 17:39:00 - train: epoch 0007, iter [00620, 01251], lr: 0.001999, loss: 3.6281
2022-10-06 17:39:21 - train: epoch 0007, iter [00630, 01251], lr: 0.001999, loss: 4.2967
2022-10-06 17:39:43 - train: epoch 0007, iter [00640, 01251], lr: 0.001999, loss: 4.1631
2022-10-06 17:40:04 - train: epoch 0007, iter [00650, 01251], lr: 0.001999, loss: 3.9639
2022-10-06 17:40:25 - train: epoch 0007, iter [00660, 01251], lr: 0.001999, loss: 3.4159
2022-10-06 17:40:47 - train: epoch 0007, iter [00670, 01251], lr: 0.001999, loss: 3.8646
2022-10-06 17:41:08 - train: epoch 0007, iter [00680, 01251], lr: 0.001999, loss: 3.3853
2022-10-06 17:41:30 - train: epoch 0007, iter [00690, 01251], lr: 0.001999, loss: 4.5651
2022-10-06 17:41:51 - train: epoch 0007, iter [00700, 01251], lr: 0.001999, loss: 3.9983
2022-10-06 17:42:12 - train: epoch 0007, iter [00710, 01251], lr: 0.001999, loss: 3.8590
2022-10-06 17:42:34 - train: epoch 0007, iter [00720, 01251], lr: 0.001999, loss: 3.5638
2022-10-06 17:42:55 - train: epoch 0007, iter [00730, 01251], lr: 0.001999, loss: 4.2901
2022-10-06 17:43:16 - train: epoch 0007, iter [00740, 01251], lr: 0.001999, loss: 4.3993
2022-10-06 17:43:38 - train: epoch 0007, iter [00750, 01251], lr: 0.001999, loss: 3.6264
2022-10-06 17:43:59 - train: epoch 0007, iter [00760, 01251], lr: 0.001999, loss: 3.7182
2022-10-06 17:44:21 - train: epoch 0007, iter [00770, 01251], lr: 0.001999, loss: 4.4247
2022-10-06 17:44:42 - train: epoch 0007, iter [00780, 01251], lr: 0.001999, loss: 3.3263
2022-10-06 17:45:03 - train: epoch 0007, iter [00790, 01251], lr: 0.001999, loss: 4.4436
2022-10-06 17:45:25 - train: epoch 0007, iter [00800, 01251], lr: 0.001999, loss: 3.5640
2022-10-06 17:45:46 - train: epoch 0007, iter [00810, 01251], lr: 0.001999, loss: 4.3086
2022-10-06 17:46:08 - train: epoch 0007, iter [00820, 01251], lr: 0.001999, loss: 4.3282
2022-10-06 17:46:29 - train: epoch 0007, iter [00830, 01251], lr: 0.001998, loss: 3.7948
2022-10-06 17:46:50 - train: epoch 0007, iter [00840, 01251], lr: 0.001998, loss: 4.1906
2022-10-06 17:47:12 - train: epoch 0007, iter [00850, 01251], lr: 0.001998, loss: 4.1476
2022-10-06 17:47:33 - train: epoch 0007, iter [00860, 01251], lr: 0.001998, loss: 4.0907
2022-10-06 17:47:55 - train: epoch 0007, iter [00870, 01251], lr: 0.001998, loss: 4.1729
2022-10-06 17:48:16 - train: epoch 0007, iter [00880, 01251], lr: 0.001998, loss: 4.4562
2022-10-06 17:48:38 - train: epoch 0007, iter [00890, 01251], lr: 0.001998, loss: 3.4805
2022-10-06 17:48:59 - train: epoch 0007, iter [00900, 01251], lr: 0.001998, loss: 4.3375
2022-10-06 17:49:20 - train: epoch 0007, iter [00910, 01251], lr: 0.001998, loss: 3.1222
2022-10-06 17:49:42 - train: epoch 0007, iter [00920, 01251], lr: 0.001998, loss: 3.6135
2022-10-06 17:50:03 - train: epoch 0007, iter [00930, 01251], lr: 0.001998, loss: 3.9121
2022-10-06 17:50:24 - train: epoch 0007, iter [00940, 01251], lr: 0.001998, loss: 3.9194
2022-10-06 17:50:46 - train: epoch 0007, iter [00950, 01251], lr: 0.001998, loss: 3.8475
2022-10-06 17:51:07 - train: epoch 0007, iter [00960, 01251], lr: 0.001998, loss: 4.3224
2022-10-06 17:51:29 - train: epoch 0007, iter [00970, 01251], lr: 0.001998, loss: 3.5623
2022-10-06 17:51:50 - train: epoch 0007, iter [00980, 01251], lr: 0.001998, loss: 3.0145
2022-10-06 17:52:11 - train: epoch 0007, iter [00990, 01251], lr: 0.001998, loss: 3.7412
2022-10-06 17:52:33 - train: epoch 0007, iter [01000, 01251], lr: 0.001998, loss: 3.9744
2022-10-06 17:52:54 - train: epoch 0007, iter [01010, 01251], lr: 0.001998, loss: 3.4149
2022-10-06 17:53:16 - train: epoch 0007, iter [01020, 01251], lr: 0.001998, loss: 4.2821
2022-10-06 17:53:37 - train: epoch 0007, iter [01030, 01251], lr: 0.001998, loss: 3.9028
2022-10-06 17:53:58 - train: epoch 0007, iter [01040, 01251], lr: 0.001998, loss: 4.3284
2022-10-06 17:54:20 - train: epoch 0007, iter [01050, 01251], lr: 0.001998, loss: 3.6452
2022-10-06 17:54:41 - train: epoch 0007, iter [01060, 01251], lr: 0.001998, loss: 3.6702
2022-10-06 17:55:02 - train: epoch 0007, iter [01070, 01251], lr: 0.001998, loss: 4.3135
2022-10-06 17:55:24 - train: epoch 0007, iter [01080, 01251], lr: 0.001998, loss: 3.9420
2022-10-06 17:55:45 - train: epoch 0007, iter [01090, 01251], lr: 0.001998, loss: 4.1619
2022-10-06 17:56:07 - train: epoch 0007, iter [01100, 01251], lr: 0.001998, loss: 3.8273
2022-10-06 17:56:28 - train: epoch 0007, iter [01110, 01251], lr: 0.001998, loss: 4.2521
2022-10-06 17:56:49 - train: epoch 0007, iter [01120, 01251], lr: 0.001998, loss: 4.4833
2022-10-06 17:57:11 - train: epoch 0007, iter [01130, 01251], lr: 0.001998, loss: 4.3424
2022-10-06 17:57:32 - train: epoch 0007, iter [01140, 01251], lr: 0.001998, loss: 4.4106
2022-10-06 17:57:54 - train: epoch 0007, iter [01150, 01251], lr: 0.001998, loss: 2.8688
2022-10-06 17:58:15 - train: epoch 0007, iter [01160, 01251], lr: 0.001998, loss: 3.9986
2022-10-06 17:58:36 - train: epoch 0007, iter [01170, 01251], lr: 0.001998, loss: 4.3134
2022-10-06 17:58:58 - train: epoch 0007, iter [01180, 01251], lr: 0.001998, loss: 4.3296
2022-10-06 17:59:19 - train: epoch 0007, iter [01190, 01251], lr: 0.001998, loss: 3.3292
2022-10-06 17:59:40 - train: epoch 0007, iter [01200, 01251], lr: 0.001998, loss: 4.2789
2022-10-06 18:00:02 - train: epoch 0007, iter [01210, 01251], lr: 0.001998, loss: 4.2516
2022-10-06 18:00:23 - train: epoch 0007, iter [01220, 01251], lr: 0.001998, loss: 3.7945
2022-10-06 18:00:45 - train: epoch 0007, iter [01230, 01251], lr: 0.001998, loss: 3.8942
2022-10-06 18:01:06 - train: epoch 0007, iter [01240, 01251], lr: 0.001998, loss: 3.3818
2022-10-06 18:01:27 - train: epoch 0007, iter [01250, 01251], lr: 0.001998, loss: 3.7077
2022-10-06 18:01:31 - train: epoch 007, train_loss: 3.9594
2022-10-06 18:02:48 - eval: epoch: 007, acc1: 71.808%, acc5: 91.550%, test_loss: 1.2719, per_image_load_time: 0.634ms, per_image_inference_time: 1.439ms
2022-10-06 18:02:50 - until epoch: 007, best_acc1: 71.808%
2022-10-06 18:02:50 - epoch 008 lr: 0.001998
2022-10-06 18:03:16 - train: epoch 0008, iter [00010, 01251], lr: 0.001998, loss: 4.0654
2022-10-06 18:03:38 - train: epoch 0008, iter [00020, 01251], lr: 0.001998, loss: 4.0948
2022-10-06 18:03:59 - train: epoch 0008, iter [00030, 01251], lr: 0.001998, loss: 4.0450
2022-10-06 18:04:20 - train: epoch 0008, iter [00040, 01251], lr: 0.001998, loss: 3.3759
2022-10-06 18:04:42 - train: epoch 0008, iter [00050, 01251], lr: 0.001998, loss: 4.1270
2022-10-06 18:05:03 - train: epoch 0008, iter [00060, 01251], lr: 0.001998, loss: 4.5732
2022-10-06 18:05:25 - train: epoch 0008, iter [00070, 01251], lr: 0.001998, loss: 4.0243
2022-10-06 18:05:46 - train: epoch 0008, iter [00080, 01251], lr: 0.001998, loss: 2.7570
2022-10-06 18:06:07 - train: epoch 0008, iter [00090, 01251], lr: 0.001998, loss: 3.9067
2022-10-06 18:06:29 - train: epoch 0008, iter [00100, 01251], lr: 0.001998, loss: 3.1854
2022-10-06 18:06:50 - train: epoch 0008, iter [00110, 01251], lr: 0.001998, loss: 4.0606
2022-10-06 18:07:12 - train: epoch 0008, iter [00120, 01251], lr: 0.001998, loss: 3.1287
2022-10-06 18:07:33 - train: epoch 0008, iter [00130, 01251], lr: 0.001998, loss: 3.6978
2022-10-06 18:07:54 - train: epoch 0008, iter [00140, 01251], lr: 0.001998, loss: 4.4310
2022-10-06 18:08:16 - train: epoch 0008, iter [00150, 01251], lr: 0.001998, loss: 3.5814
2022-10-06 18:08:37 - train: epoch 0008, iter [00160, 01251], lr: 0.001998, loss: 4.3296
2022-10-06 18:08:59 - train: epoch 0008, iter [00170, 01251], lr: 0.001998, loss: 3.8054
2022-10-06 18:09:20 - train: epoch 0008, iter [00180, 01251], lr: 0.001997, loss: 3.5887
2022-10-06 18:09:41 - train: epoch 0008, iter [00190, 01251], lr: 0.001997, loss: 3.6008
2022-10-06 18:10:03 - train: epoch 0008, iter [00200, 01251], lr: 0.001997, loss: 4.2652
2022-10-06 18:10:24 - train: epoch 0008, iter [00210, 01251], lr: 0.001997, loss: 4.6321
2022-10-06 18:10:45 - train: epoch 0008, iter [00220, 01251], lr: 0.001997, loss: 3.9206
2022-10-06 18:11:07 - train: epoch 0008, iter [00230, 01251], lr: 0.001997, loss: 4.1897
2022-10-06 18:11:28 - train: epoch 0008, iter [00240, 01251], lr: 0.001997, loss: 3.0772
2022-10-06 18:11:50 - train: epoch 0008, iter [00250, 01251], lr: 0.001997, loss: 4.2767
2022-10-06 18:12:11 - train: epoch 0008, iter [00260, 01251], lr: 0.001997, loss: 3.3817
2022-10-06 18:12:33 - train: epoch 0008, iter [00270, 01251], lr: 0.001997, loss: 4.4851
2022-10-06 18:12:54 - train: epoch 0008, iter [00280, 01251], lr: 0.001997, loss: 3.6828
2022-10-06 18:13:15 - train: epoch 0008, iter [00290, 01251], lr: 0.001997, loss: 4.7669
2022-10-06 18:13:37 - train: epoch 0008, iter [00300, 01251], lr: 0.001997, loss: 3.9901
2022-10-06 18:13:58 - train: epoch 0008, iter [00310, 01251], lr: 0.001997, loss: 3.7579
2022-10-06 18:14:20 - train: epoch 0008, iter [00320, 01251], lr: 0.001997, loss: 4.2130
2022-10-06 18:14:41 - train: epoch 0008, iter [00330, 01251], lr: 0.001997, loss: 3.3782
2022-10-06 18:15:02 - train: epoch 0008, iter [00340, 01251], lr: 0.001997, loss: 4.2301
2022-10-06 18:15:24 - train: epoch 0008, iter [00350, 01251], lr: 0.001997, loss: 4.3283
2022-10-06 18:15:45 - train: epoch 0008, iter [00360, 01251], lr: 0.001997, loss: 4.2177
2022-10-06 18:16:06 - train: epoch 0008, iter [00370, 01251], lr: 0.001997, loss: 4.0640
2022-10-06 18:16:28 - train: epoch 0008, iter [00380, 01251], lr: 0.001997, loss: 3.2833
2022-10-06 18:16:49 - train: epoch 0008, iter [00390, 01251], lr: 0.001997, loss: 3.7894
2022-10-06 18:17:11 - train: epoch 0008, iter [00400, 01251], lr: 0.001997, loss: 3.8919
2022-10-06 18:17:32 - train: epoch 0008, iter [00410, 01251], lr: 0.001997, loss: 4.0267
2022-10-06 18:17:53 - train: epoch 0008, iter [00420, 01251], lr: 0.001997, loss: 4.1015
2022-10-06 18:18:15 - train: epoch 0008, iter [00430, 01251], lr: 0.001997, loss: 4.1028
2022-10-06 18:18:36 - train: epoch 0008, iter [00440, 01251], lr: 0.001997, loss: 4.8144
2022-10-06 18:18:58 - train: epoch 0008, iter [00450, 01251], lr: 0.001997, loss: 4.2060
2022-10-06 18:19:19 - train: epoch 0008, iter [00460, 01251], lr: 0.001997, loss: 3.4912
2022-10-06 18:19:41 - train: epoch 0008, iter [00470, 01251], lr: 0.001997, loss: 2.7787
2022-10-06 18:20:02 - train: epoch 0008, iter [00480, 01251], lr: 0.001997, loss: 4.4970
2022-10-06 18:20:23 - train: epoch 0008, iter [00490, 01251], lr: 0.001997, loss: 4.1103
2022-10-06 18:20:45 - train: epoch 0008, iter [00500, 01251], lr: 0.001997, loss: 3.4472
2022-10-06 18:21:06 - train: epoch 0008, iter [00510, 01251], lr: 0.001997, loss: 4.3852
2022-10-06 18:21:28 - train: epoch 0008, iter [00520, 01251], lr: 0.001997, loss: 3.1016
2022-10-06 18:21:49 - train: epoch 0008, iter [00530, 01251], lr: 0.001997, loss: 3.3128
2022-10-06 18:22:10 - train: epoch 0008, iter [00540, 01251], lr: 0.001997, loss: 4.2476
2022-10-06 18:22:32 - train: epoch 0008, iter [00550, 01251], lr: 0.001997, loss: 4.1579
2022-10-06 18:22:53 - train: epoch 0008, iter [00560, 01251], lr: 0.001997, loss: 4.1172
2022-10-06 18:23:14 - train: epoch 0008, iter [00570, 01251], lr: 0.001997, loss: 3.9430
2022-10-06 18:23:36 - train: epoch 0008, iter [00580, 01251], lr: 0.001997, loss: 3.7906
2022-10-06 18:23:57 - train: epoch 0008, iter [00590, 01251], lr: 0.001997, loss: 2.8305
2022-10-06 18:24:19 - train: epoch 0008, iter [00600, 01251], lr: 0.001997, loss: 3.2157
2022-10-06 18:24:40 - train: epoch 0008, iter [00610, 01251], lr: 0.001997, loss: 4.3835
2022-10-06 18:25:01 - train: epoch 0008, iter [00620, 01251], lr: 0.001997, loss: 2.7881
2022-10-06 18:25:23 - train: epoch 0008, iter [00630, 01251], lr: 0.001997, loss: 4.3735
2022-10-06 18:25:44 - train: epoch 0008, iter [00640, 01251], lr: 0.001997, loss: 3.6816
2022-10-06 18:26:05 - train: epoch 0008, iter [00650, 01251], lr: 0.001997, loss: 3.1712
2022-10-06 18:26:27 - train: epoch 0008, iter [00660, 01251], lr: 0.001997, loss: 4.1346
2022-10-06 18:26:48 - train: epoch 0008, iter [00670, 01251], lr: 0.001996, loss: 3.6590
2022-10-06 18:27:09 - train: epoch 0008, iter [00680, 01251], lr: 0.001996, loss: 4.2265
2022-10-06 18:27:31 - train: epoch 0008, iter [00690, 01251], lr: 0.001996, loss: 4.4902
2022-10-06 18:27:52 - train: epoch 0008, iter [00700, 01251], lr: 0.001996, loss: 3.5307
2022-10-06 18:28:14 - train: epoch 0008, iter [00710, 01251], lr: 0.001996, loss: 4.1191
2022-10-06 18:28:35 - train: epoch 0008, iter [00720, 01251], lr: 0.001996, loss: 3.4910
2022-10-06 18:28:56 - train: epoch 0008, iter [00730, 01251], lr: 0.001996, loss: 4.4575
2022-10-06 18:29:18 - train: epoch 0008, iter [00740, 01251], lr: 0.001996, loss: 4.2498
2022-10-06 18:29:39 - train: epoch 0008, iter [00750, 01251], lr: 0.001996, loss: 3.7323
2022-10-06 18:30:00 - train: epoch 0008, iter [00760, 01251], lr: 0.001996, loss: 3.6669
2022-10-06 18:30:22 - train: epoch 0008, iter [00770, 01251], lr: 0.001996, loss: 4.1848
2022-10-06 18:30:43 - train: epoch 0008, iter [00780, 01251], lr: 0.001996, loss: 4.3964
2022-10-06 18:31:05 - train: epoch 0008, iter [00790, 01251], lr: 0.001996, loss: 3.5775
2022-10-06 18:31:26 - train: epoch 0008, iter [00800, 01251], lr: 0.001996, loss: 3.0628
2022-10-06 18:31:47 - train: epoch 0008, iter [00810, 01251], lr: 0.001996, loss: 3.7643
2022-10-06 18:32:08 - train: epoch 0008, iter [00820, 01251], lr: 0.001996, loss: 4.4502
2022-10-06 18:32:30 - train: epoch 0008, iter [00830, 01251], lr: 0.001996, loss: 3.7188
2022-10-06 18:32:51 - train: epoch 0008, iter [00840, 01251], lr: 0.001996, loss: 4.0843
2022-10-06 18:33:12 - train: epoch 0008, iter [00850, 01251], lr: 0.001996, loss: 3.7395
2022-10-06 18:33:34 - train: epoch 0008, iter [00860, 01251], lr: 0.001996, loss: 3.6946
2022-10-06 18:33:55 - train: epoch 0008, iter [00870, 01251], lr: 0.001996, loss: 3.5515
2022-10-06 18:34:17 - train: epoch 0008, iter [00880, 01251], lr: 0.001996, loss: 3.3193
2022-10-06 18:34:38 - train: epoch 0008, iter [00890, 01251], lr: 0.001996, loss: 3.7708
2022-10-06 18:34:59 - train: epoch 0008, iter [00900, 01251], lr: 0.001996, loss: 3.6446
2022-10-06 18:35:21 - train: epoch 0008, iter [00910, 01251], lr: 0.001996, loss: 3.2834
2022-10-06 18:35:42 - train: epoch 0008, iter [00920, 01251], lr: 0.001996, loss: 4.5590
2022-10-06 18:36:04 - train: epoch 0008, iter [00930, 01251], lr: 0.001996, loss: 2.8111
2022-10-06 18:36:25 - train: epoch 0008, iter [00940, 01251], lr: 0.001996, loss: 3.8080
2022-10-06 18:36:46 - train: epoch 0008, iter [00950, 01251], lr: 0.001996, loss: 4.2976
2022-10-06 18:37:08 - train: epoch 0008, iter [00960, 01251], lr: 0.001996, loss: 4.3666
2022-10-06 18:37:29 - train: epoch 0008, iter [00970, 01251], lr: 0.001996, loss: 4.1067
2022-10-06 18:37:50 - train: epoch 0008, iter [00980, 01251], lr: 0.001996, loss: 3.6350
2022-10-06 18:38:12 - train: epoch 0008, iter [00990, 01251], lr: 0.001996, loss: 3.9446
2022-10-06 18:38:33 - train: epoch 0008, iter [01000, 01251], lr: 0.001996, loss: 3.7722
2022-10-06 18:38:54 - train: epoch 0008, iter [01010, 01251], lr: 0.001996, loss: 4.0293
2022-10-06 18:39:16 - train: epoch 0008, iter [01020, 01251], lr: 0.001996, loss: 3.8620
2022-10-06 18:39:37 - train: epoch 0008, iter [01030, 01251], lr: 0.001996, loss: 4.1949
2022-10-06 18:39:59 - train: epoch 0008, iter [01040, 01251], lr: 0.001996, loss: 3.6119
2022-10-06 18:40:20 - train: epoch 0008, iter [01050, 01251], lr: 0.001996, loss: 3.1761
2022-10-06 18:40:41 - train: epoch 0008, iter [01060, 01251], lr: 0.001996, loss: 4.5083
2022-10-06 18:41:03 - train: epoch 0008, iter [01070, 01251], lr: 0.001996, loss: 4.4005
2022-10-06 18:41:24 - train: epoch 0008, iter [01080, 01251], lr: 0.001996, loss: 3.3456
2022-10-06 18:41:46 - train: epoch 0008, iter [01090, 01251], lr: 0.001995, loss: 3.5560
2022-10-06 18:42:07 - train: epoch 0008, iter [01100, 01251], lr: 0.001995, loss: 3.7594
2022-10-06 18:42:28 - train: epoch 0008, iter [01110, 01251], lr: 0.001995, loss: 2.8570
2022-10-06 18:42:50 - train: epoch 0008, iter [01120, 01251], lr: 0.001995, loss: 4.0437
2022-10-06 18:43:11 - train: epoch 0008, iter [01130, 01251], lr: 0.001995, loss: 4.0741
2022-10-06 18:43:32 - train: epoch 0008, iter [01140, 01251], lr: 0.001995, loss: 4.1752
2022-10-06 18:43:54 - train: epoch 0008, iter [01150, 01251], lr: 0.001995, loss: 3.9410
2022-10-06 18:44:15 - train: epoch 0008, iter [01160, 01251], lr: 0.001995, loss: 2.7172
2022-10-06 18:44:37 - train: epoch 0008, iter [01170, 01251], lr: 0.001995, loss: 3.5479
2022-10-06 18:44:58 - train: epoch 0008, iter [01180, 01251], lr: 0.001995, loss: 4.0136
2022-10-06 18:45:19 - train: epoch 0008, iter [01190, 01251], lr: 0.001995, loss: 3.5362
2022-10-06 18:45:41 - train: epoch 0008, iter [01200, 01251], lr: 0.001995, loss: 3.1489
2022-10-06 18:46:02 - train: epoch 0008, iter [01210, 01251], lr: 0.001995, loss: 3.2463
2022-10-06 18:46:23 - train: epoch 0008, iter [01220, 01251], lr: 0.001995, loss: 3.6657
2022-10-06 18:46:45 - train: epoch 0008, iter [01230, 01251], lr: 0.001995, loss: 3.3294
2022-10-06 18:47:06 - train: epoch 0008, iter [01240, 01251], lr: 0.001995, loss: 3.8951
2022-10-06 18:47:27 - train: epoch 0008, iter [01250, 01251], lr: 0.001995, loss: 3.3563
2022-10-06 18:47:31 - train: epoch 008, train_loss: 3.8797
2022-10-06 18:48:48 - eval: epoch: 008, acc1: 72.616%, acc5: 91.984%, test_loss: 1.1978, per_image_load_time: 1.061ms, per_image_inference_time: 1.433ms
2022-10-06 18:48:50 - until epoch: 008, best_acc1: 72.616%
2022-10-06 18:48:50 - epoch 009 lr: 0.001995
2022-10-06 18:49:17 - train: epoch 0009, iter [00010, 01251], lr: 0.001995, loss: 3.4346
2022-10-06 18:49:38 - train: epoch 0009, iter [00020, 01251], lr: 0.001995, loss: 4.5403
2022-10-06 18:49:59 - train: epoch 0009, iter [00030, 01251], lr: 0.001995, loss: 4.1823
2022-10-06 18:50:21 - train: epoch 0009, iter [00040, 01251], lr: 0.001995, loss: 4.3610
2022-10-06 18:50:42 - train: epoch 0009, iter [00050, 01251], lr: 0.001995, loss: 4.2068
2022-10-06 18:51:03 - train: epoch 0009, iter [00060, 01251], lr: 0.001995, loss: 4.2724
2022-10-06 18:51:25 - train: epoch 0009, iter [00070, 01251], lr: 0.001995, loss: 4.0568
2022-10-06 18:51:46 - train: epoch 0009, iter [00080, 01251], lr: 0.001995, loss: 3.4201
2022-10-06 18:52:08 - train: epoch 0009, iter [00090, 01251], lr: 0.001995, loss: 4.1507
2022-10-06 18:52:29 - train: epoch 0009, iter [00100, 01251], lr: 0.001995, loss: 3.8485
2022-10-06 18:52:50 - train: epoch 0009, iter [00110, 01251], lr: 0.001995, loss: 4.2883
2022-10-06 18:53:12 - train: epoch 0009, iter [00120, 01251], lr: 0.001995, loss: 3.8726
2022-10-06 18:53:33 - train: epoch 0009, iter [00130, 01251], lr: 0.001995, loss: 3.9715
2022-10-06 18:53:55 - train: epoch 0009, iter [00140, 01251], lr: 0.001995, loss: 4.0114
2022-10-06 18:54:16 - train: epoch 0009, iter [00150, 01251], lr: 0.001995, loss: 3.9390
2022-10-06 18:54:37 - train: epoch 0009, iter [00160, 01251], lr: 0.001995, loss: 3.4799
2022-10-06 18:54:59 - train: epoch 0009, iter [00170, 01251], lr: 0.001995, loss: 3.3927
2022-10-06 18:55:20 - train: epoch 0009, iter [00180, 01251], lr: 0.001995, loss: 4.2387
2022-10-06 18:55:41 - train: epoch 0009, iter [00190, 01251], lr: 0.001995, loss: 3.6386
2022-10-06 18:56:03 - train: epoch 0009, iter [00200, 01251], lr: 0.001995, loss: 3.7698
2022-10-06 18:56:24 - train: epoch 0009, iter [00210, 01251], lr: 0.001995, loss: 4.4212
2022-10-06 18:56:46 - train: epoch 0009, iter [00220, 01251], lr: 0.001994, loss: 3.7311
2022-10-06 18:57:07 - train: epoch 0009, iter [00230, 01251], lr: 0.001994, loss: 4.4781
2022-10-06 18:57:28 - train: epoch 0009, iter [00240, 01251], lr: 0.001994, loss: 3.7113
2022-10-06 18:57:50 - train: epoch 0009, iter [00250, 01251], lr: 0.001994, loss: 3.2477
2022-10-06 18:58:11 - train: epoch 0009, iter [00260, 01251], lr: 0.001994, loss: 3.3298
2022-10-06 18:58:33 - train: epoch 0009, iter [00270, 01251], lr: 0.001994, loss: 3.1521
2022-10-06 18:58:54 - train: epoch 0009, iter [00280, 01251], lr: 0.001994, loss: 4.0052
2022-10-06 18:59:15 - train: epoch 0009, iter [00290, 01251], lr: 0.001994, loss: 4.0625
2022-10-06 18:59:37 - train: epoch 0009, iter [00300, 01251], lr: 0.001994, loss: 3.8095
2022-10-06 18:59:58 - train: epoch 0009, iter [00310, 01251], lr: 0.001994, loss: 4.2337
2022-10-06 19:00:20 - train: epoch 0009, iter [00320, 01251], lr: 0.001994, loss: 4.0511
2022-10-06 19:00:41 - train: epoch 0009, iter [00330, 01251], lr: 0.001994, loss: 3.5779
2022-10-06 19:01:02 - train: epoch 0009, iter [00340, 01251], lr: 0.001994, loss: 4.4309
2022-10-06 19:01:24 - train: epoch 0009, iter [00350, 01251], lr: 0.001994, loss: 4.3223
2022-10-06 19:01:45 - train: epoch 0009, iter [00360, 01251], lr: 0.001994, loss: 3.8303
2022-10-06 19:02:06 - train: epoch 0009, iter [00370, 01251], lr: 0.001994, loss: 3.7869
2022-10-06 19:02:28 - train: epoch 0009, iter [00380, 01251], lr: 0.001994, loss: 3.6196
2022-10-06 19:02:49 - train: epoch 0009, iter [00390, 01251], lr: 0.001994, loss: 3.1778
2022-10-06 19:03:11 - train: epoch 0009, iter [00400, 01251], lr: 0.001994, loss: 3.9276
2022-10-06 19:03:32 - train: epoch 0009, iter [00410, 01251], lr: 0.001994, loss: 4.2528
2022-10-06 19:03:53 - train: epoch 0009, iter [00420, 01251], lr: 0.001994, loss: 4.0032
2022-10-06 19:04:15 - train: epoch 0009, iter [00430, 01251], lr: 0.001994, loss: 3.4529
2022-10-06 19:04:36 - train: epoch 0009, iter [00440, 01251], lr: 0.001994, loss: 3.0595
2022-10-06 19:04:58 - train: epoch 0009, iter [00450, 01251], lr: 0.001994, loss: 4.1369
2022-10-06 19:05:19 - train: epoch 0009, iter [00460, 01251], lr: 0.001994, loss: 3.0447
2022-10-06 19:05:40 - train: epoch 0009, iter [00470, 01251], lr: 0.001994, loss: 3.8032
2022-10-06 19:06:02 - train: epoch 0009, iter [00480, 01251], lr: 0.001994, loss: 3.9744
2022-10-06 19:06:23 - train: epoch 0009, iter [00490, 01251], lr: 0.001994, loss: 4.2723
2022-10-06 19:06:44 - train: epoch 0009, iter [00500, 01251], lr: 0.001994, loss: 3.4996
2022-10-06 19:07:06 - train: epoch 0009, iter [00510, 01251], lr: 0.001994, loss: 4.2383
2022-10-06 19:07:27 - train: epoch 0009, iter [00520, 01251], lr: 0.001994, loss: 3.6409
2022-10-06 19:07:48 - train: epoch 0009, iter [00530, 01251], lr: 0.001994, loss: 3.3960
2022-10-06 19:08:10 - train: epoch 0009, iter [00540, 01251], lr: 0.001994, loss: 4.3798
2022-10-06 19:08:31 - train: epoch 0009, iter [00550, 01251], lr: 0.001994, loss: 2.9346
2022-10-06 19:08:53 - train: epoch 0009, iter [00560, 01251], lr: 0.001994, loss: 3.8504
2022-10-06 19:09:14 - train: epoch 0009, iter [00570, 01251], lr: 0.001993, loss: 3.7387
2022-10-06 19:09:35 - train: epoch 0009, iter [00580, 01251], lr: 0.001993, loss: 4.2593
2022-10-06 19:09:57 - train: epoch 0009, iter [00590, 01251], lr: 0.001993, loss: 4.1028
2022-10-06 19:10:18 - train: epoch 0009, iter [00600, 01251], lr: 0.001993, loss: 3.2426
2022-10-06 19:10:39 - train: epoch 0009, iter [00610, 01251], lr: 0.001993, loss: 4.3013
2022-10-06 19:11:01 - train: epoch 0009, iter [00620, 01251], lr: 0.001993, loss: 3.9414
2022-10-06 19:11:22 - train: epoch 0009, iter [00630, 01251], lr: 0.001993, loss: 3.0662
2022-10-06 19:11:44 - train: epoch 0009, iter [00640, 01251], lr: 0.001993, loss: 3.5941
2022-10-06 19:12:05 - train: epoch 0009, iter [00650, 01251], lr: 0.001993, loss: 4.1528
2022-10-06 19:12:27 - train: epoch 0009, iter [00660, 01251], lr: 0.001993, loss: 3.6292
2022-10-06 19:12:48 - train: epoch 0009, iter [00670, 01251], lr: 0.001993, loss: 3.9483
2022-10-06 19:13:09 - train: epoch 0009, iter [00680, 01251], lr: 0.001993, loss: 3.7588
2022-10-06 19:13:30 - train: epoch 0009, iter [00690, 01251], lr: 0.001993, loss: 4.2158
2022-10-06 19:13:52 - train: epoch 0009, iter [00700, 01251], lr: 0.001993, loss: 4.1137
2022-10-06 19:14:13 - train: epoch 0009, iter [00710, 01251], lr: 0.001993, loss: 3.4647
2022-10-06 19:14:35 - train: epoch 0009, iter [00720, 01251], lr: 0.001993, loss: 4.1006
2022-10-06 19:14:56 - train: epoch 0009, iter [00730, 01251], lr: 0.001993, loss: 3.3292
2022-10-06 19:15:17 - train: epoch 0009, iter [00740, 01251], lr: 0.001993, loss: 3.0649
2022-10-06 19:15:39 - train: epoch 0009, iter [00750, 01251], lr: 0.001993, loss: 2.9554
2022-10-06 19:16:00 - train: epoch 0009, iter [00760, 01251], lr: 0.001993, loss: 4.4294
2022-10-06 19:16:21 - train: epoch 0009, iter [00770, 01251], lr: 0.001993, loss: 3.8438
2022-10-06 19:16:43 - train: epoch 0009, iter [00780, 01251], lr: 0.001993, loss: 3.8676
2022-10-06 19:17:04 - train: epoch 0009, iter [00790, 01251], lr: 0.001993, loss: 4.0783
2022-10-06 19:17:25 - train: epoch 0009, iter [00800, 01251], lr: 0.001993, loss: 3.5197
2022-10-06 19:17:47 - train: epoch 0009, iter [00810, 01251], lr: 0.001993, loss: 3.8176
2022-10-06 19:18:08 - train: epoch 0009, iter [00820, 01251], lr: 0.001993, loss: 4.0552
2022-10-06 19:18:30 - train: epoch 0009, iter [00830, 01251], lr: 0.001993, loss: 3.7332
2022-10-06 19:18:51 - train: epoch 0009, iter [00840, 01251], lr: 0.001993, loss: 4.1511
2022-10-06 19:19:12 - train: epoch 0009, iter [00850, 01251], lr: 0.001993, loss: 3.6484
2022-10-06 19:19:34 - train: epoch 0009, iter [00860, 01251], lr: 0.001993, loss: 4.3331
2022-10-06 19:19:55 - train: epoch 0009, iter [00870, 01251], lr: 0.001993, loss: 3.4632
2022-10-06 19:20:16 - train: epoch 0009, iter [00880, 01251], lr: 0.001993, loss: 3.3569
2022-10-06 19:20:38 - train: epoch 0009, iter [00890, 01251], lr: 0.001992, loss: 3.4268
2022-10-06 19:20:59 - train: epoch 0009, iter [00900, 01251], lr: 0.001992, loss: 3.4059
2022-10-06 19:21:20 - train: epoch 0009, iter [00910, 01251], lr: 0.001992, loss: 4.0060
2022-10-06 19:21:42 - train: epoch 0009, iter [00920, 01251], lr: 0.001992, loss: 3.4269
2022-10-06 19:22:03 - train: epoch 0009, iter [00930, 01251], lr: 0.001992, loss: 3.7053
2022-10-06 19:22:24 - train: epoch 0009, iter [00940, 01251], lr: 0.001992, loss: 4.5962
2022-10-06 19:22:46 - train: epoch 0009, iter [00950, 01251], lr: 0.001992, loss: 3.5114
2022-10-06 19:23:07 - train: epoch 0009, iter [00960, 01251], lr: 0.001992, loss: 3.7464
2022-10-06 19:23:28 - train: epoch 0009, iter [00970, 01251], lr: 0.001992, loss: 3.3770
2022-10-06 19:23:50 - train: epoch 0009, iter [00980, 01251], lr: 0.001992, loss: 3.4514
2022-10-06 19:24:11 - train: epoch 0009, iter [00990, 01251], lr: 0.001992, loss: 3.3856
2022-10-06 19:24:33 - train: epoch 0009, iter [01000, 01251], lr: 0.001992, loss: 4.3352
2022-10-06 19:24:54 - train: epoch 0009, iter [01010, 01251], lr: 0.001992, loss: 2.7681
2022-10-06 19:25:15 - train: epoch 0009, iter [01020, 01251], lr: 0.001992, loss: 4.0789
2022-10-06 19:25:37 - train: epoch 0009, iter [01030, 01251], lr: 0.001992, loss: 3.1540
2022-10-06 19:25:58 - train: epoch 0009, iter [01040, 01251], lr: 0.001992, loss: 3.9786
2022-10-06 19:26:19 - train: epoch 0009, iter [01050, 01251], lr: 0.001992, loss: 3.8841
2022-10-06 19:26:41 - train: epoch 0009, iter [01060, 01251], lr: 0.001992, loss: 3.8445
2022-10-06 19:27:02 - train: epoch 0009, iter [01070, 01251], lr: 0.001992, loss: 4.3240
2022-10-06 19:27:23 - train: epoch 0009, iter [01080, 01251], lr: 0.001992, loss: 4.0217
2022-10-06 19:27:45 - train: epoch 0009, iter [01090, 01251], lr: 0.001992, loss: 3.7033
2022-10-06 19:28:06 - train: epoch 0009, iter [01100, 01251], lr: 0.001992, loss: 3.2213
2022-10-06 19:28:28 - train: epoch 0009, iter [01110, 01251], lr: 0.001992, loss: 3.6112
2022-10-06 19:28:49 - train: epoch 0009, iter [01120, 01251], lr: 0.001992, loss: 3.4506
2022-10-06 19:29:10 - train: epoch 0009, iter [01130, 01251], lr: 0.001992, loss: 3.1436
2022-10-06 19:29:32 - train: epoch 0009, iter [01140, 01251], lr: 0.001992, loss: 4.0096
2022-10-06 19:29:53 - train: epoch 0009, iter [01150, 01251], lr: 0.001992, loss: 4.0651
2022-10-06 19:30:14 - train: epoch 0009, iter [01160, 01251], lr: 0.001992, loss: 3.2300
2022-10-06 19:30:36 - train: epoch 0009, iter [01170, 01251], lr: 0.001992, loss: 4.1645
2022-10-06 19:30:57 - train: epoch 0009, iter [01180, 01251], lr: 0.001992, loss: 3.6598
2022-10-06 19:31:18 - train: epoch 0009, iter [01190, 01251], lr: 0.001991, loss: 4.1079
2022-10-06 19:31:40 - train: epoch 0009, iter [01200, 01251], lr: 0.001991, loss: 3.4518
2022-10-06 19:32:01 - train: epoch 0009, iter [01210, 01251], lr: 0.001991, loss: 3.4915
2022-10-06 19:32:22 - train: epoch 0009, iter [01220, 01251], lr: 0.001991, loss: 4.4194
2022-10-06 19:32:44 - train: epoch 0009, iter [01230, 01251], lr: 0.001991, loss: 3.4633
2022-10-06 19:33:05 - train: epoch 0009, iter [01240, 01251], lr: 0.001991, loss: 3.5601
2022-10-06 19:33:26 - train: epoch 0009, iter [01250, 01251], lr: 0.001991, loss: 4.0289
2022-10-06 19:33:30 - train: epoch 009, train_loss: 3.8343
2022-10-06 19:34:47 - eval: epoch: 009, acc1: 72.904%, acc5: 92.208%, test_loss: 1.2107, per_image_load_time: 1.320ms, per_image_inference_time: 1.437ms
2022-10-06 19:34:48 - until epoch: 009, best_acc1: 72.904%
2022-10-06 19:34:48 - epoch 010 lr: 0.001991
2022-10-06 19:35:16 - train: epoch 0010, iter [00010, 01251], lr: 0.001991, loss: 3.8732
2022-10-06 19:35:37 - train: epoch 0010, iter [00020, 01251], lr: 0.001991, loss: 4.0149
2022-10-06 19:35:59 - train: epoch 0010, iter [00030, 01251], lr: 0.001991, loss: 3.9739
2022-10-06 19:36:20 - train: epoch 0010, iter [00040, 01251], lr: 0.001991, loss: 3.3270
2022-10-06 19:36:41 - train: epoch 0010, iter [00050, 01251], lr: 0.001991, loss: 4.2048
2022-10-06 19:37:03 - train: epoch 0010, iter [00060, 01251], lr: 0.001991, loss: 4.1995
2022-10-06 19:37:24 - train: epoch 0010, iter [00070, 01251], lr: 0.001991, loss: 3.6738
2022-10-06 19:37:45 - train: epoch 0010, iter [00080, 01251], lr: 0.001991, loss: 3.5432
2022-10-06 19:38:07 - train: epoch 0010, iter [00090, 01251], lr: 0.001991, loss: 4.0891
2022-10-06 19:38:28 - train: epoch 0010, iter [00100, 01251], lr: 0.001991, loss: 3.6965
2022-10-06 19:38:49 - train: epoch 0010, iter [00110, 01251], lr: 0.001991, loss: 3.3474
2022-10-06 19:39:11 - train: epoch 0010, iter [00120, 01251], lr: 0.001991, loss: 3.3887
2022-10-06 19:39:32 - train: epoch 0010, iter [00130, 01251], lr: 0.001991, loss: 3.9555
2022-10-06 19:39:54 - train: epoch 0010, iter [00140, 01251], lr: 0.001991, loss: 3.2612
2022-10-06 19:40:15 - train: epoch 0010, iter [00150, 01251], lr: 0.001991, loss: 3.9218
2022-10-06 19:40:36 - train: epoch 0010, iter [00160, 01251], lr: 0.001991, loss: 3.9427
2022-10-06 19:40:58 - train: epoch 0010, iter [00170, 01251], lr: 0.001991, loss: 3.5317
2022-10-06 19:41:19 - train: epoch 0010, iter [00180, 01251], lr: 0.001991, loss: 4.2425
2022-10-06 19:41:40 - train: epoch 0010, iter [00190, 01251], lr: 0.001991, loss: 4.1614
2022-10-06 19:42:02 - train: epoch 0010, iter [00200, 01251], lr: 0.001991, loss: 4.4323
2022-10-06 19:42:23 - train: epoch 0010, iter [00210, 01251], lr: 0.001991, loss: 4.1377
2022-10-06 19:42:44 - train: epoch 0010, iter [00220, 01251], lr: 0.001990, loss: 3.7276
2022-10-06 19:43:06 - train: epoch 0010, iter [00230, 01251], lr: 0.001990, loss: 3.7104
2022-10-06 19:43:27 - train: epoch 0010, iter [00240, 01251], lr: 0.001990, loss: 2.9038
2022-10-06 19:43:49 - train: epoch 0010, iter [00250, 01251], lr: 0.001990, loss: 3.2199
2022-10-06 19:44:10 - train: epoch 0010, iter [00260, 01251], lr: 0.001990, loss: 4.2733
2022-10-06 19:44:31 - train: epoch 0010, iter [00270, 01251], lr: 0.001990, loss: 3.9005
2022-10-06 19:44:53 - train: epoch 0010, iter [00280, 01251], lr: 0.001990, loss: 3.5650
2022-10-06 19:45:14 - train: epoch 0010, iter [00290, 01251], lr: 0.001990, loss: 2.6541
2022-10-06 19:45:35 - train: epoch 0010, iter [00300, 01251], lr: 0.001990, loss: 3.9908
2022-10-06 19:45:57 - train: epoch 0010, iter [00310, 01251], lr: 0.001990, loss: 3.3565
2022-10-06 19:46:18 - train: epoch 0010, iter [00320, 01251], lr: 0.001990, loss: 4.1257
2022-10-06 19:46:39 - train: epoch 0010, iter [00330, 01251], lr: 0.001990, loss: 3.8413
2022-10-06 19:47:01 - train: epoch 0010, iter [00340, 01251], lr: 0.001990, loss: 3.9479
2022-10-06 19:47:22 - train: epoch 0010, iter [00350, 01251], lr: 0.001990, loss: 3.8778
2022-10-06 19:47:43 - train: epoch 0010, iter [00360, 01251], lr: 0.001990, loss: 4.0233
2022-10-06 19:48:05 - train: epoch 0010, iter [00370, 01251], lr: 0.001990, loss: 4.3139
2022-10-06 19:48:26 - train: epoch 0010, iter [00380, 01251], lr: 0.001990, loss: 3.9976
2022-10-06 19:48:48 - train: epoch 0010, iter [00390, 01251], lr: 0.001990, loss: 3.7436
2022-10-06 19:49:09 - train: epoch 0010, iter [00400, 01251], lr: 0.001990, loss: 3.9420
2022-10-06 19:49:30 - train: epoch 0010, iter [00410, 01251], lr: 0.001990, loss: 3.8901
2022-10-06 19:49:52 - train: epoch 0010, iter [00420, 01251], lr: 0.001990, loss: 3.2928
2022-10-06 19:50:13 - train: epoch 0010, iter [00430, 01251], lr: 0.001990, loss: 3.6184
2022-10-06 19:50:34 - train: epoch 0010, iter [00440, 01251], lr: 0.001990, loss: 3.9048
2022-10-06 19:50:55 - train: epoch 0010, iter [00450, 01251], lr: 0.001990, loss: 3.6111
2022-10-06 19:51:17 - train: epoch 0010, iter [00460, 01251], lr: 0.001990, loss: 4.0326
2022-10-06 19:51:38 - train: epoch 0010, iter [00470, 01251], lr: 0.001990, loss: 4.2928
2022-10-06 19:51:59 - train: epoch 0010, iter [00480, 01251], lr: 0.001990, loss: 3.6525
2022-10-06 19:52:21 - train: epoch 0010, iter [00490, 01251], lr: 0.001989, loss: 4.1050
2022-10-06 19:52:42 - train: epoch 0010, iter [00500, 01251], lr: 0.001989, loss: 4.3023
2022-10-06 19:53:03 - train: epoch 0010, iter [00510, 01251], lr: 0.001989, loss: 3.1774
2022-10-06 19:53:25 - train: epoch 0010, iter [00520, 01251], lr: 0.001989, loss: 3.2301
2022-10-06 19:53:46 - train: epoch 0010, iter [00530, 01251], lr: 0.001989, loss: 3.6406
2022-10-06 19:54:08 - train: epoch 0010, iter [00540, 01251], lr: 0.001989, loss: 4.6150
2022-10-06 19:54:29 - train: epoch 0010, iter [00550, 01251], lr: 0.001989, loss: 3.6893
2022-10-06 19:54:50 - train: epoch 0010, iter [00560, 01251], lr: 0.001989, loss: 3.6459
2022-10-06 19:55:12 - train: epoch 0010, iter [00570, 01251], lr: 0.001989, loss: 3.2195
2022-10-06 19:55:33 - train: epoch 0010, iter [00580, 01251], lr: 0.001989, loss: 4.1202
2022-10-06 19:55:54 - train: epoch 0010, iter [00590, 01251], lr: 0.001989, loss: 4.3238
2022-10-06 19:56:16 - train: epoch 0010, iter [00600, 01251], lr: 0.001989, loss: 4.5594
2022-10-06 19:56:37 - train: epoch 0010, iter [00610, 01251], lr: 0.001989, loss: 3.7371
2022-10-06 19:56:58 - train: epoch 0010, iter [00620, 01251], lr: 0.001989, loss: 4.1755
2022-10-06 19:57:20 - train: epoch 0010, iter [00630, 01251], lr: 0.001989, loss: 3.9967
2022-10-06 19:57:41 - train: epoch 0010, iter [00640, 01251], lr: 0.001989, loss: 3.1902
2022-10-06 19:58:02 - train: epoch 0010, iter [00650, 01251], lr: 0.001989, loss: 3.1786
2022-10-06 19:58:24 - train: epoch 0010, iter [00660, 01251], lr: 0.001989, loss: 4.0929
2022-10-06 19:58:45 - train: epoch 0010, iter [00670, 01251], lr: 0.001989, loss: 3.9751
2022-10-06 19:59:06 - train: epoch 0010, iter [00680, 01251], lr: 0.001989, loss: 4.1554
2022-10-06 19:59:28 - train: epoch 0010, iter [00690, 01251], lr: 0.001989, loss: 3.7232
2022-10-06 19:59:49 - train: epoch 0010, iter [00700, 01251], lr: 0.001989, loss: 2.7442
2022-10-06 20:00:11 - train: epoch 0010, iter [00710, 01251], lr: 0.001989, loss: 4.2165
2022-10-06 20:00:32 - train: epoch 0010, iter [00720, 01251], lr: 0.001989, loss: 3.6743
2022-10-06 20:00:53 - train: epoch 0010, iter [00730, 01251], lr: 0.001989, loss: 3.7862
2022-10-06 20:01:15 - train: epoch 0010, iter [00740, 01251], lr: 0.001989, loss: 3.1679
2022-10-06 20:01:36 - train: epoch 0010, iter [00750, 01251], lr: 0.001988, loss: 3.8212
2022-10-06 20:01:57 - train: epoch 0010, iter [00760, 01251], lr: 0.001988, loss: 4.2871
2022-10-06 20:02:19 - train: epoch 0010, iter [00770, 01251], lr: 0.001988, loss: 3.7356
2022-10-06 20:02:40 - train: epoch 0010, iter [00780, 01251], lr: 0.001988, loss: 3.2092
2022-10-06 20:03:02 - train: epoch 0010, iter [00790, 01251], lr: 0.001988, loss: 3.5133
2022-10-06 20:03:23 - train: epoch 0010, iter [00800, 01251], lr: 0.001988, loss: 4.1065
2022-10-06 20:03:44 - train: epoch 0010, iter [00810, 01251], lr: 0.001988, loss: 3.7353
2022-10-06 20:04:06 - train: epoch 0010, iter [00820, 01251], lr: 0.001988, loss: 3.8074
2022-10-06 20:04:27 - train: epoch 0010, iter [00830, 01251], lr: 0.001988, loss: 3.4930
2022-10-06 20:04:48 - train: epoch 0010, iter [00840, 01251], lr: 0.001988, loss: 3.6959
2022-10-06 20:05:10 - train: epoch 0010, iter [00850, 01251], lr: 0.001988, loss: 3.5741
2022-10-06 20:05:31 - train: epoch 0010, iter [00860, 01251], lr: 0.001988, loss: 3.9677
2022-10-06 20:05:52 - train: epoch 0010, iter [00870, 01251], lr: 0.001988, loss: 3.8367
2022-10-06 20:06:14 - train: epoch 0010, iter [00880, 01251], lr: 0.001988, loss: 3.0508
2022-10-06 20:06:35 - train: epoch 0010, iter [00890, 01251], lr: 0.001988, loss: 3.8283
2022-10-06 20:06:56 - train: epoch 0010, iter [00900, 01251], lr: 0.001988, loss: 3.8691
2022-10-06 20:07:18 - train: epoch 0010, iter [00910, 01251], lr: 0.001988, loss: 4.0025
2022-10-06 20:07:39 - train: epoch 0010, iter [00920, 01251], lr: 0.001988, loss: 3.8818
2022-10-06 20:08:01 - train: epoch 0010, iter [00930, 01251], lr: 0.001988, loss: 3.9105
2022-10-06 20:08:22 - train: epoch 0010, iter [00940, 01251], lr: 0.001988, loss: 4.0490
2022-10-06 20:08:43 - train: epoch 0010, iter [00950, 01251], lr: 0.001988, loss: 4.2165
2022-10-06 20:09:04 - train: epoch 0010, iter [00960, 01251], lr: 0.001988, loss: 4.1229
2022-10-06 20:09:26 - train: epoch 0010, iter [00970, 01251], lr: 0.001988, loss: 3.6235
2022-10-06 20:09:47 - train: epoch 0010, iter [00980, 01251], lr: 0.001988, loss: 3.3884
2022-10-06 20:10:09 - train: epoch 0010, iter [00990, 01251], lr: 0.001987, loss: 3.7850
2022-10-06 20:10:30 - train: epoch 0010, iter [01000, 01251], lr: 0.001987, loss: 3.6265
2022-10-06 20:10:51 - train: epoch 0010, iter [01010, 01251], lr: 0.001987, loss: 4.0549
2022-10-06 20:11:13 - train: epoch 0010, iter [01020, 01251], lr: 0.001987, loss: 3.2316
2022-10-06 20:11:34 - train: epoch 0010, iter [01030, 01251], lr: 0.001987, loss: 3.1469
2022-10-06 20:11:55 - train: epoch 0010, iter [01040, 01251], lr: 0.001987, loss: 4.1420
2022-10-06 20:12:17 - train: epoch 0010, iter [01050, 01251], lr: 0.001987, loss: 3.8159
2022-10-06 20:12:38 - train: epoch 0010, iter [01060, 01251], lr: 0.001987, loss: 2.8635
2022-10-06 20:12:59 - train: epoch 0010, iter [01070, 01251], lr: 0.001987, loss: 4.0622
2022-10-06 20:13:21 - train: epoch 0010, iter [01080, 01251], lr: 0.001987, loss: 3.8414
2022-10-06 20:13:42 - train: epoch 0010, iter [01090, 01251], lr: 0.001987, loss: 4.2225
2022-10-06 20:14:04 - train: epoch 0010, iter [01100, 01251], lr: 0.001987, loss: 3.5384
2022-10-06 20:14:25 - train: epoch 0010, iter [01110, 01251], lr: 0.001987, loss: 3.6194
2022-10-06 20:14:46 - train: epoch 0010, iter [01120, 01251], lr: 0.001987, loss: 3.9922
2022-10-06 20:15:08 - train: epoch 0010, iter [01130, 01251], lr: 0.001987, loss: 3.4480
2022-10-06 20:15:29 - train: epoch 0010, iter [01140, 01251], lr: 0.001987, loss: 3.7199
2022-10-06 20:15:50 - train: epoch 0010, iter [01150, 01251], lr: 0.001987, loss: 4.1739
2022-10-06 20:16:12 - train: epoch 0010, iter [01160, 01251], lr: 0.001987, loss: 3.5150
2022-10-06 20:16:33 - train: epoch 0010, iter [01170, 01251], lr: 0.001987, loss: 3.8458
2022-10-06 20:16:54 - train: epoch 0010, iter [01180, 01251], lr: 0.001987, loss: 3.8469
2022-10-06 20:17:16 - train: epoch 0010, iter [01190, 01251], lr: 0.001987, loss: 3.2788
2022-10-06 20:17:37 - train: epoch 0010, iter [01200, 01251], lr: 0.001987, loss: 3.8390
2022-10-06 20:17:58 - train: epoch 0010, iter [01210, 01251], lr: 0.001987, loss: 4.2427
2022-10-06 20:18:20 - train: epoch 0010, iter [01220, 01251], lr: 0.001987, loss: 3.5933
2022-10-06 20:18:41 - train: epoch 0010, iter [01230, 01251], lr: 0.001986, loss: 4.4279
2022-10-06 20:19:02 - train: epoch 0010, iter [01240, 01251], lr: 0.001986, loss: 3.7055
2022-10-06 20:19:24 - train: epoch 0010, iter [01250, 01251], lr: 0.001986, loss: 4.4641
2022-10-06 20:19:28 - train: epoch 010, train_loss: 3.7786
2022-10-06 20:20:45 - eval: epoch: 010, acc1: 73.520%, acc5: 92.562%, test_loss: 1.1691, per_image_load_time: 0.636ms, per_image_inference_time: 1.422ms
2022-10-06 20:20:46 - until epoch: 010, best_acc1: 73.520%
2022-10-06 20:20:46 - epoch 011 lr: 0.001986
2022-10-06 20:21:14 - train: epoch 0011, iter [00010, 01251], lr: 0.001986, loss: 4.5771
2022-10-06 20:21:35 - train: epoch 0011, iter [00020, 01251], lr: 0.001986, loss: 3.5522
2022-10-06 20:21:56 - train: epoch 0011, iter [00030, 01251], lr: 0.001986, loss: 3.9817
2022-10-06 20:22:18 - train: epoch 0011, iter [00040, 01251], lr: 0.001986, loss: 4.4079
2022-10-06 20:22:39 - train: epoch 0011, iter [00050, 01251], lr: 0.001986, loss: 4.2069
2022-10-06 20:23:00 - train: epoch 0011, iter [00060, 01251], lr: 0.001986, loss: 4.2522
2022-10-06 20:23:22 - train: epoch 0011, iter [00070, 01251], lr: 0.001986, loss: 3.1583
2022-10-06 20:23:43 - train: epoch 0011, iter [00080, 01251], lr: 0.001986, loss: 3.4873
2022-10-06 20:24:04 - train: epoch 0011, iter [00090, 01251], lr: 0.001986, loss: 3.9961
2022-10-06 20:24:26 - train: epoch 0011, iter [00100, 01251], lr: 0.001986, loss: 3.5436
2022-10-06 20:24:47 - train: epoch 0011, iter [00110, 01251], lr: 0.001986, loss: 4.1704
2022-10-06 20:25:08 - train: epoch 0011, iter [00120, 01251], lr: 0.001986, loss: 3.0186
2022-10-06 20:25:30 - train: epoch 0011, iter [00130, 01251], lr: 0.001986, loss: 2.8864
2022-10-06 20:25:51 - train: epoch 0011, iter [00140, 01251], lr: 0.001986, loss: 3.8159
2022-10-06 20:26:12 - train: epoch 0011, iter [00150, 01251], lr: 0.001986, loss: 4.3279
2022-10-06 20:26:34 - train: epoch 0011, iter [00160, 01251], lr: 0.001986, loss: 4.3010
2022-10-06 20:26:55 - train: epoch 0011, iter [00170, 01251], lr: 0.001986, loss: 3.7391
2022-10-06 20:27:16 - train: epoch 0011, iter [00180, 01251], lr: 0.001986, loss: 3.4352
2022-10-06 20:27:38 - train: epoch 0011, iter [00190, 01251], lr: 0.001986, loss: 3.4907
2022-10-06 20:27:59 - train: epoch 0011, iter [00200, 01251], lr: 0.001985, loss: 3.4326
2022-10-06 20:28:20 - train: epoch 0011, iter [00210, 01251], lr: 0.001985, loss: 3.1183
2022-10-06 20:28:42 - train: epoch 0011, iter [00220, 01251], lr: 0.001985, loss: 2.4701
2022-10-06 20:29:03 - train: epoch 0011, iter [00230, 01251], lr: 0.001985, loss: 3.4480
2022-10-06 20:29:24 - train: epoch 0011, iter [00240, 01251], lr: 0.001985, loss: 3.6650
2022-10-06 20:29:46 - train: epoch 0011, iter [00250, 01251], lr: 0.001985, loss: 4.0910
2022-10-06 20:30:07 - train: epoch 0011, iter [00260, 01251], lr: 0.001985, loss: 3.6049
2022-10-06 20:30:28 - train: epoch 0011, iter [00270, 01251], lr: 0.001985, loss: 2.7576
2022-10-06 20:30:50 - train: epoch 0011, iter [00280, 01251], lr: 0.001985, loss: 4.4352
2022-10-06 20:31:11 - train: epoch 0011, iter [00290, 01251], lr: 0.001985, loss: 3.5180
2022-10-06 20:31:32 - train: epoch 0011, iter [00300, 01251], lr: 0.001985, loss: 3.4405
2022-10-06 20:31:54 - train: epoch 0011, iter [00310, 01251], lr: 0.001985, loss: 4.2442
2022-10-06 20:32:15 - train: epoch 0011, iter [00320, 01251], lr: 0.001985, loss: 3.8157
2022-10-06 20:32:36 - train: epoch 0011, iter [00330, 01251], lr: 0.001985, loss: 4.0609
2022-10-06 20:32:58 - train: epoch 0011, iter [00340, 01251], lr: 0.001985, loss: 2.4706
2022-10-06 20:33:19 - train: epoch 0011, iter [00350, 01251], lr: 0.001985, loss: 3.8884
2022-10-06 20:33:40 - train: epoch 0011, iter [00360, 01251], lr: 0.001985, loss: 3.8538
2022-10-06 20:34:02 - train: epoch 0011, iter [00370, 01251], lr: 0.001985, loss: 3.9306
2022-10-06 20:34:23 - train: epoch 0011, iter [00380, 01251], lr: 0.001985, loss: 2.9273
2022-10-06 20:34:44 - train: epoch 0011, iter [00390, 01251], lr: 0.001985, loss: 4.3133
2022-10-06 20:35:06 - train: epoch 0011, iter [00400, 01251], lr: 0.001985, loss: 3.2882
2022-10-06 20:35:27 - train: epoch 0011, iter [00410, 01251], lr: 0.001985, loss: 3.2668
2022-10-06 20:35:48 - train: epoch 0011, iter [00420, 01251], lr: 0.001984, loss: 3.3733
2022-10-06 20:36:10 - train: epoch 0011, iter [00430, 01251], lr: 0.001984, loss: 4.3393
2022-10-06 20:36:31 - train: epoch 0011, iter [00440, 01251], lr: 0.001984, loss: 3.7981
2022-10-06 20:36:52 - train: epoch 0011, iter [00450, 01251], lr: 0.001984, loss: 4.0125
2022-10-06 20:37:14 - train: epoch 0011, iter [00460, 01251], lr: 0.001984, loss: 3.3109
2022-10-06 20:37:35 - train: epoch 0011, iter [00470, 01251], lr: 0.001984, loss: 3.0762
2022-10-06 20:37:56 - train: epoch 0011, iter [00480, 01251], lr: 0.001984, loss: 3.4382
2022-10-06 20:38:18 - train: epoch 0011, iter [00490, 01251], lr: 0.001984, loss: 2.9184
2022-10-06 20:38:39 - train: epoch 0011, iter [00500, 01251], lr: 0.001984, loss: 3.5385
2022-10-06 20:39:00 - train: epoch 0011, iter [00510, 01251], lr: 0.001984, loss: 4.0423
2022-10-06 20:39:22 - train: epoch 0011, iter [00520, 01251], lr: 0.001984, loss: 3.1046
2022-10-06 20:39:43 - train: epoch 0011, iter [00530, 01251], lr: 0.001984, loss: 3.8822
2022-10-06 20:40:04 - train: epoch 0011, iter [00540, 01251], lr: 0.001984, loss: 3.9541
2022-10-06 20:40:26 - train: epoch 0011, iter [00550, 01251], lr: 0.001984, loss: 3.5019
2022-10-06 20:40:47 - train: epoch 0011, iter [00560, 01251], lr: 0.001984, loss: 3.2782
2022-10-06 20:41:08 - train: epoch 0011, iter [00570, 01251], lr: 0.001984, loss: 3.8047
2022-10-06 20:41:30 - train: epoch 0011, iter [00580, 01251], lr: 0.001984, loss: 4.0701
2022-10-06 20:41:51 - train: epoch 0011, iter [00590, 01251], lr: 0.001984, loss: 2.7062
2022-10-06 20:42:12 - train: epoch 0011, iter [00600, 01251], lr: 0.001984, loss: 3.5775
2022-10-06 20:42:34 - train: epoch 0011, iter [00610, 01251], lr: 0.001984, loss: 3.8714
2022-10-06 20:42:55 - train: epoch 0011, iter [00620, 01251], lr: 0.001984, loss: 3.6785
2022-10-06 20:43:16 - train: epoch 0011, iter [00630, 01251], lr: 0.001983, loss: 3.6348
2022-10-06 20:43:37 - train: epoch 0011, iter [00640, 01251], lr: 0.001983, loss: 3.6875
2022-10-06 20:43:59 - train: epoch 0011, iter [00650, 01251], lr: 0.001983, loss: 3.6164
2022-10-06 20:44:20 - train: epoch 0011, iter [00660, 01251], lr: 0.001983, loss: 4.2676
2022-10-06 20:44:41 - train: epoch 0011, iter [00670, 01251], lr: 0.001983, loss: 3.6721
2022-10-06 20:45:03 - train: epoch 0011, iter [00680, 01251], lr: 0.001983, loss: 3.6440
2022-10-06 20:45:24 - train: epoch 0011, iter [00690, 01251], lr: 0.001983, loss: 3.5207
2022-10-06 20:45:45 - train: epoch 0011, iter [00700, 01251], lr: 0.001983, loss: 3.6177
2022-10-06 20:46:07 - train: epoch 0011, iter [00710, 01251], lr: 0.001983, loss: 3.4620
2022-10-06 20:46:28 - train: epoch 0011, iter [00720, 01251], lr: 0.001983, loss: 3.4076
2022-10-06 20:46:49 - train: epoch 0011, iter [00730, 01251], lr: 0.001983, loss: 4.1729
2022-10-06 20:47:11 - train: epoch 0011, iter [00740, 01251], lr: 0.001983, loss: 3.6636
2022-10-06 20:47:32 - train: epoch 0011, iter [00750, 01251], lr: 0.001983, loss: 3.7179
2022-10-06 20:47:54 - train: epoch 0011, iter [00760, 01251], lr: 0.001983, loss: 3.2906
2022-10-06 20:48:15 - train: epoch 0011, iter [00770, 01251], lr: 0.001983, loss: 3.1967
2022-10-06 20:48:36 - train: epoch 0011, iter [00780, 01251], lr: 0.001983, loss: 3.6546
2022-10-06 20:48:58 - train: epoch 0011, iter [00790, 01251], lr: 0.001983, loss: 4.4102
2022-10-06 20:49:19 - train: epoch 0011, iter [00800, 01251], lr: 0.001983, loss: 4.0499
2022-10-06 20:49:40 - train: epoch 0011, iter [00810, 01251], lr: 0.001983, loss: 3.7132
2022-10-06 20:50:01 - train: epoch 0011, iter [00820, 01251], lr: 0.001983, loss: 2.7859
2022-10-06 20:50:23 - train: epoch 0011, iter [00830, 01251], lr: 0.001983, loss: 3.8916
2022-10-06 20:50:44 - train: epoch 0011, iter [00840, 01251], lr: 0.001982, loss: 3.3367
2022-10-06 20:51:05 - train: epoch 0011, iter [00850, 01251], lr: 0.001982, loss: 3.7629
2022-10-06 20:51:27 - train: epoch 0011, iter [00860, 01251], lr: 0.001982, loss: 3.6858
2022-10-06 20:51:48 - train: epoch 0011, iter [00870, 01251], lr: 0.001982, loss: 3.6617
2022-10-06 20:52:09 - train: epoch 0011, iter [00880, 01251], lr: 0.001982, loss: 3.3955
2022-10-06 20:52:30 - train: epoch 0011, iter [00890, 01251], lr: 0.001982, loss: 4.0707
2022-10-06 20:52:52 - train: epoch 0011, iter [00900, 01251], lr: 0.001982, loss: 3.5680
2022-10-06 20:53:13 - train: epoch 0011, iter [00910, 01251], lr: 0.001982, loss: 3.8388
2022-10-06 20:53:34 - train: epoch 0011, iter [00920, 01251], lr: 0.001982, loss: 3.8612
2022-10-06 20:53:56 - train: epoch 0011, iter [00930, 01251], lr: 0.001982, loss: 3.9342
2022-10-06 20:54:17 - train: epoch 0011, iter [00940, 01251], lr: 0.001982, loss: 3.1845
2022-10-06 20:54:38 - train: epoch 0011, iter [00950, 01251], lr: 0.001982, loss: 3.1844
2022-10-06 20:55:00 - train: epoch 0011, iter [00960, 01251], lr: 0.001982, loss: 3.7203
2022-10-06 20:55:21 - train: epoch 0011, iter [00970, 01251], lr: 0.001982, loss: 4.0362
2022-10-06 20:55:42 - train: epoch 0011, iter [00980, 01251], lr: 0.001982, loss: 4.2315
2022-10-06 20:56:04 - train: epoch 0011, iter [00990, 01251], lr: 0.001982, loss: 3.9869
2022-10-06 20:56:25 - train: epoch 0011, iter [01000, 01251], lr: 0.001982, loss: 3.8221
2022-10-06 20:56:46 - train: epoch 0011, iter [01010, 01251], lr: 0.001982, loss: 3.0177
2022-10-06 20:57:08 - train: epoch 0011, iter [01020, 01251], lr: 0.001982, loss: 3.8950
2022-10-06 20:57:29 - train: epoch 0011, iter [01030, 01251], lr: 0.001982, loss: 3.4727
2022-10-06 20:57:50 - train: epoch 0011, iter [01040, 01251], lr: 0.001981, loss: 4.2098
2022-10-06 20:58:12 - train: epoch 0011, iter [01050, 01251], lr: 0.001981, loss: 3.8555
2022-10-06 20:58:33 - train: epoch 0011, iter [01060, 01251], lr: 0.001981, loss: 3.5801
2022-10-06 20:58:54 - train: epoch 0011, iter [01070, 01251], lr: 0.001981, loss: 3.8258
2022-10-06 20:59:16 - train: epoch 0011, iter [01080, 01251], lr: 0.001981, loss: 4.3971
2022-10-06 20:59:37 - train: epoch 0011, iter [01090, 01251], lr: 0.001981, loss: 3.6572
2022-10-06 20:59:58 - train: epoch 0011, iter [01100, 01251], lr: 0.001981, loss: 4.0778
2022-10-06 21:00:20 - train: epoch 0011, iter [01110, 01251], lr: 0.001981, loss: 4.2514
2022-10-06 21:00:41 - train: epoch 0011, iter [01120, 01251], lr: 0.001981, loss: 3.6961
2022-10-06 21:01:02 - train: epoch 0011, iter [01130, 01251], lr: 0.001981, loss: 3.4549
2022-10-06 21:01:24 - train: epoch 0011, iter [01140, 01251], lr: 0.001981, loss: 3.5997
2022-10-06 21:01:45 - train: epoch 0011, iter [01150, 01251], lr: 0.001981, loss: 3.7178
2022-10-06 21:02:06 - train: epoch 0011, iter [01160, 01251], lr: 0.001981, loss: 3.9182
2022-10-06 21:02:28 - train: epoch 0011, iter [01170, 01251], lr: 0.001981, loss: 3.1175
2022-10-06 21:02:49 - train: epoch 0011, iter [01180, 01251], lr: 0.001981, loss: 3.5754
2022-10-06 21:03:11 - train: epoch 0011, iter [01190, 01251], lr: 0.001981, loss: 4.0128
2022-10-06 21:03:32 - train: epoch 0011, iter [01200, 01251], lr: 0.001981, loss: 4.1290
2022-10-06 21:03:53 - train: epoch 0011, iter [01210, 01251], lr: 0.001981, loss: 3.3512
2022-10-06 21:04:15 - train: epoch 0011, iter [01220, 01251], lr: 0.001981, loss: 3.7866
2022-10-06 21:04:36 - train: epoch 0011, iter [01230, 01251], lr: 0.001980, loss: 3.8704
2022-10-06 21:04:57 - train: epoch 0011, iter [01240, 01251], lr: 0.001980, loss: 3.2777
2022-10-06 21:05:19 - train: epoch 0011, iter [01250, 01251], lr: 0.001980, loss: 4.2394
2022-10-06 21:05:22 - train: epoch 011, train_loss: 3.7414
2022-10-06 21:06:38 - eval: epoch: 011, acc1: 74.576%, acc5: 92.764%, test_loss: 1.1176, per_image_load_time: 0.423ms, per_image_inference_time: 1.430ms
2022-10-06 21:06:40 - until epoch: 011, best_acc1: 74.576%
2022-10-06 21:06:40 - epoch 012 lr: 0.001980
2022-10-06 21:07:07 - train: epoch 0012, iter [00010, 01251], lr: 0.001980, loss: 3.2522
2022-10-06 21:07:28 - train: epoch 0012, iter [00020, 01251], lr: 0.001980, loss: 3.7313
2022-10-06 21:07:50 - train: epoch 0012, iter [00030, 01251], lr: 0.001980, loss: 3.9273
2022-10-06 21:08:11 - train: epoch 0012, iter [00040, 01251], lr: 0.001980, loss: 3.4106
2022-10-06 21:08:32 - train: epoch 0012, iter [00050, 01251], lr: 0.001980, loss: 3.3538
2022-10-06 21:08:54 - train: epoch 0012, iter [00060, 01251], lr: 0.001980, loss: 3.8685
2022-10-06 21:09:15 - train: epoch 0012, iter [00070, 01251], lr: 0.001980, loss: 3.9259
2022-10-06 21:09:36 - train: epoch 0012, iter [00080, 01251], lr: 0.001980, loss: 4.3115
2022-10-06 21:09:58 - train: epoch 0012, iter [00090, 01251], lr: 0.001980, loss: 3.6595
2022-10-06 21:10:19 - train: epoch 0012, iter [00100, 01251], lr: 0.001980, loss: 3.7658
2022-10-06 21:10:40 - train: epoch 0012, iter [00110, 01251], lr: 0.001980, loss: 3.8106
2022-10-06 21:11:02 - train: epoch 0012, iter [00120, 01251], lr: 0.001980, loss: 3.4344
2022-10-06 21:11:23 - train: epoch 0012, iter [00130, 01251], lr: 0.001980, loss: 4.4303
2022-10-06 21:11:45 - train: epoch 0012, iter [00140, 01251], lr: 0.001980, loss: 3.3877
2022-10-06 21:12:06 - train: epoch 0012, iter [00150, 01251], lr: 0.001980, loss: 3.6188
2022-10-06 21:12:27 - train: epoch 0012, iter [00160, 01251], lr: 0.001980, loss: 3.9884
2022-10-06 21:12:49 - train: epoch 0012, iter [00170, 01251], lr: 0.001979, loss: 3.3783
2022-10-06 21:13:10 - train: epoch 0012, iter [00180, 01251], lr: 0.001979, loss: 3.5030
2022-10-06 21:13:32 - train: epoch 0012, iter [00190, 01251], lr: 0.001979, loss: 3.7920
2022-10-06 21:13:53 - train: epoch 0012, iter [00200, 01251], lr: 0.001979, loss: 3.8331
2022-10-06 21:14:15 - train: epoch 0012, iter [00210, 01251], lr: 0.001979, loss: 3.6619
2022-10-06 21:14:36 - train: epoch 0012, iter [00220, 01251], lr: 0.001979, loss: 3.7971
2022-10-06 21:14:57 - train: epoch 0012, iter [00230, 01251], lr: 0.001979, loss: 3.7599
2022-10-06 21:15:19 - train: epoch 0012, iter [00240, 01251], lr: 0.001979, loss: 4.0191
2022-10-06 21:15:40 - train: epoch 0012, iter [00250, 01251], lr: 0.001979, loss: 3.8114
2022-10-06 21:16:02 - train: epoch 0012, iter [00260, 01251], lr: 0.001979, loss: 3.2702
2022-10-06 21:16:23 - train: epoch 0012, iter [00270, 01251], lr: 0.001979, loss: 4.0317
2022-10-06 21:16:45 - train: epoch 0012, iter [00280, 01251], lr: 0.001979, loss: 3.9549
2022-10-06 21:17:07 - train: epoch 0012, iter [00290, 01251], lr: 0.001979, loss: 4.0497
2022-10-06 21:17:28 - train: epoch 0012, iter [00300, 01251], lr: 0.001979, loss: 3.5523
2022-10-06 21:17:49 - train: epoch 0012, iter [00310, 01251], lr: 0.001979, loss: 3.2608
2022-10-06 21:18:11 - train: epoch 0012, iter [00320, 01251], lr: 0.001979, loss: 3.6848
2022-10-06 21:18:32 - train: epoch 0012, iter [00330, 01251], lr: 0.001979, loss: 4.1451
2022-10-06 21:18:54 - train: epoch 0012, iter [00340, 01251], lr: 0.001979, loss: 3.2623
2022-10-06 21:19:15 - train: epoch 0012, iter [00350, 01251], lr: 0.001979, loss: 2.9650
2022-10-06 21:19:36 - train: epoch 0012, iter [00360, 01251], lr: 0.001978, loss: 2.8215
2022-10-06 21:19:58 - train: epoch 0012, iter [00370, 01251], lr: 0.001978, loss: 4.0441
2022-10-06 21:20:19 - train: epoch 0012, iter [00380, 01251], lr: 0.001978, loss: 3.4416
2022-10-06 21:20:40 - train: epoch 0012, iter [00390, 01251], lr: 0.001978, loss: 3.8969
2022-10-06 21:21:02 - train: epoch 0012, iter [00400, 01251], lr: 0.001978, loss: 3.3908
2022-10-06 21:21:23 - train: epoch 0012, iter [00410, 01251], lr: 0.001978, loss: 3.6201
2022-10-06 21:21:44 - train: epoch 0012, iter [00420, 01251], lr: 0.001978, loss: 3.5569
2022-10-06 21:22:06 - train: epoch 0012, iter [00430, 01251], lr: 0.001978, loss: 3.4736
2022-10-06 21:22:27 - train: epoch 0012, iter [00440, 01251], lr: 0.001978, loss: 4.1096
2022-10-06 21:22:48 - train: epoch 0012, iter [00450, 01251], lr: 0.001978, loss: 3.8632
2022-10-06 21:23:10 - train: epoch 0012, iter [00460, 01251], lr: 0.001978, loss: 3.2793
2022-10-06 21:23:31 - train: epoch 0012, iter [00470, 01251], lr: 0.001978, loss: 4.0005
2022-10-06 21:23:52 - train: epoch 0012, iter [00480, 01251], lr: 0.001978, loss: 3.9372
2022-10-06 21:24:14 - train: epoch 0012, iter [00490, 01251], lr: 0.001978, loss: 2.8992
2022-10-06 21:24:35 - train: epoch 0012, iter [00500, 01251], lr: 0.001978, loss: 3.9605
2022-10-06 21:24:56 - train: epoch 0012, iter [00510, 01251], lr: 0.001978, loss: 3.2752
2022-10-06 21:25:17 - train: epoch 0012, iter [00520, 01251], lr: 0.001978, loss: 3.7890
2022-10-06 21:25:39 - train: epoch 0012, iter [00530, 01251], lr: 0.001978, loss: 3.0429
2022-10-06 21:26:00 - train: epoch 0012, iter [00540, 01251], lr: 0.001977, loss: 3.8932
2022-10-06 21:26:22 - train: epoch 0012, iter [00550, 01251], lr: 0.001977, loss: 3.8900
2022-10-06 21:26:43 - train: epoch 0012, iter [00560, 01251], lr: 0.001977, loss: 3.7110
2022-10-06 21:27:05 - train: epoch 0012, iter [00570, 01251], lr: 0.001977, loss: 3.7798
2022-10-06 21:27:26 - train: epoch 0012, iter [00580, 01251], lr: 0.001977, loss: 3.2527
2022-10-06 21:27:47 - train: epoch 0012, iter [00590, 01251], lr: 0.001977, loss: 3.6149
2022-10-06 21:28:09 - train: epoch 0012, iter [00600, 01251], lr: 0.001977, loss: 3.8606
2022-10-06 21:28:30 - train: epoch 0012, iter [00610, 01251], lr: 0.001977, loss: 3.9041
2022-10-06 21:28:52 - train: epoch 0012, iter [00620, 01251], lr: 0.001977, loss: 3.5160
2022-10-06 21:29:13 - train: epoch 0012, iter [00630, 01251], lr: 0.001977, loss: 3.8908
2022-10-06 21:29:35 - train: epoch 0012, iter [00640, 01251], lr: 0.001977, loss: 3.6233
2022-10-06 21:29:56 - train: epoch 0012, iter [00650, 01251], lr: 0.001977, loss: 2.9531
2022-10-06 21:30:18 - train: epoch 0012, iter [00660, 01251], lr: 0.001977, loss: 3.9212
2022-10-06 21:30:39 - train: epoch 0012, iter [00670, 01251], lr: 0.001977, loss: 3.6167
2022-10-06 21:31:00 - train: epoch 0012, iter [00680, 01251], lr: 0.001977, loss: 3.8770
2022-10-06 21:31:21 - train: epoch 0012, iter [00690, 01251], lr: 0.001977, loss: 3.5039
2022-10-06 21:31:43 - train: epoch 0012, iter [00700, 01251], lr: 0.001977, loss: 3.2399
2022-10-06 21:32:04 - train: epoch 0012, iter [00710, 01251], lr: 0.001977, loss: 4.1587
2022-10-06 21:32:26 - train: epoch 0012, iter [00720, 01251], lr: 0.001976, loss: 3.5757
2022-10-06 21:32:47 - train: epoch 0012, iter [00730, 01251], lr: 0.001976, loss: 3.6116
2022-10-06 21:33:08 - train: epoch 0012, iter [00740, 01251], lr: 0.001976, loss: 3.3430
2022-10-06 21:33:29 - train: epoch 0012, iter [00750, 01251], lr: 0.001976, loss: 3.7243
2022-10-06 21:33:51 - train: epoch 0012, iter [00760, 01251], lr: 0.001976, loss: 3.0756
2022-10-06 21:34:12 - train: epoch 0012, iter [00770, 01251], lr: 0.001976, loss: 4.1060
2022-10-06 21:34:33 - train: epoch 0012, iter [00780, 01251], lr: 0.001976, loss: 4.2897
2022-10-06 21:34:55 - train: epoch 0012, iter [00790, 01251], lr: 0.001976, loss: 3.3893
2022-10-06 21:35:16 - train: epoch 0012, iter [00800, 01251], lr: 0.001976, loss: 4.0407
2022-10-06 21:35:37 - train: epoch 0012, iter [00810, 01251], lr: 0.001976, loss: 3.5967
2022-10-06 21:35:59 - train: epoch 0012, iter [00820, 01251], lr: 0.001976, loss: 3.7162
2022-10-06 21:36:20 - train: epoch 0012, iter [00830, 01251], lr: 0.001976, loss: 4.6549
2022-10-06 21:36:41 - train: epoch 0012, iter [00840, 01251], lr: 0.001976, loss: 3.9551
2022-10-06 21:37:02 - train: epoch 0012, iter [00850, 01251], lr: 0.001976, loss: 3.6732
2022-10-06 21:37:24 - train: epoch 0012, iter [00860, 01251], lr: 0.001976, loss: 3.8139
2022-10-06 21:37:45 - train: epoch 0012, iter [00870, 01251], lr: 0.001976, loss: 3.7667
2022-10-06 21:38:06 - train: epoch 0012, iter [00880, 01251], lr: 0.001976, loss: 3.7147
2022-10-06 21:38:28 - train: epoch 0012, iter [00890, 01251], lr: 0.001975, loss: 3.5981
2022-10-06 21:38:49 - train: epoch 0012, iter [00900, 01251], lr: 0.001975, loss: 3.7486
2022-10-06 21:39:10 - train: epoch 0012, iter [00910, 01251], lr: 0.001975, loss: 4.0369
2022-10-06 21:39:32 - train: epoch 0012, iter [00920, 01251], lr: 0.001975, loss: 4.0795
2022-10-06 21:39:53 - train: epoch 0012, iter [00930, 01251], lr: 0.001975, loss: 3.8131
2022-10-06 21:40:14 - train: epoch 0012, iter [00940, 01251], lr: 0.001975, loss: 3.3326
2022-10-06 21:40:35 - train: epoch 0012, iter [00950, 01251], lr: 0.001975, loss: 3.9962
2022-10-06 21:40:57 - train: epoch 0012, iter [00960, 01251], lr: 0.001975, loss: 4.0835
2022-10-06 21:41:18 - train: epoch 0012, iter [00970, 01251], lr: 0.001975, loss: 3.5321
2022-10-06 21:41:39 - train: epoch 0012, iter [00980, 01251], lr: 0.001975, loss: 3.6674
2022-10-06 21:42:00 - train: epoch 0012, iter [00990, 01251], lr: 0.001975, loss: 3.5283
2022-10-06 21:42:22 - train: epoch 0012, iter [01000, 01251], lr: 0.001975, loss: 4.3064
2022-10-06 21:42:43 - train: epoch 0012, iter [01010, 01251], lr: 0.001975, loss: 3.3417
2022-10-06 21:43:04 - train: epoch 0012, iter [01020, 01251], lr: 0.001975, loss: 3.9524
2022-10-06 21:43:25 - train: epoch 0012, iter [01030, 01251], lr: 0.001975, loss: 3.5064
2022-10-06 21:43:47 - train: epoch 0012, iter [01040, 01251], lr: 0.001975, loss: 3.4075
2022-10-06 21:44:08 - train: epoch 0012, iter [01050, 01251], lr: 0.001975, loss: 3.8783
2022-10-06 21:44:29 - train: epoch 0012, iter [01060, 01251], lr: 0.001974, loss: 4.1040
2022-10-06 21:44:51 - train: epoch 0012, iter [01070, 01251], lr: 0.001974, loss: 3.2651
2022-10-06 21:45:12 - train: epoch 0012, iter [01080, 01251], lr: 0.001974, loss: 2.6536
2022-10-06 21:45:33 - train: epoch 0012, iter [01090, 01251], lr: 0.001974, loss: 4.1976
2022-10-06 21:45:54 - train: epoch 0012, iter [01100, 01251], lr: 0.001974, loss: 3.5614
2022-10-06 21:46:16 - train: epoch 0012, iter [01110, 01251], lr: 0.001974, loss: 3.6597
2022-10-06 21:46:37 - train: epoch 0012, iter [01120, 01251], lr: 0.001974, loss: 3.4880
2022-10-06 21:46:58 - train: epoch 0012, iter [01130, 01251], lr: 0.001974, loss: 3.3932
2022-10-06 21:47:20 - train: epoch 0012, iter [01140, 01251], lr: 0.001974, loss: 4.2092
2022-10-06 21:47:41 - train: epoch 0012, iter [01150, 01251], lr: 0.001974, loss: 3.7423
2022-10-06 21:48:02 - train: epoch 0012, iter [01160, 01251], lr: 0.001974, loss: 3.7427
2022-10-06 21:48:23 - train: epoch 0012, iter [01170, 01251], lr: 0.001974, loss: 4.0674
2022-10-06 21:48:45 - train: epoch 0012, iter [01180, 01251], lr: 0.001974, loss: 3.4156
2022-10-06 21:49:06 - train: epoch 0012, iter [01190, 01251], lr: 0.001974, loss: 3.2340
2022-10-06 21:49:28 - train: epoch 0012, iter [01200, 01251], lr: 0.001974, loss: 3.7556
2022-10-06 21:49:49 - train: epoch 0012, iter [01210, 01251], lr: 0.001974, loss: 3.9513
2022-10-06 21:50:10 - train: epoch 0012, iter [01220, 01251], lr: 0.001974, loss: 4.0744
2022-10-06 21:50:31 - train: epoch 0012, iter [01230, 01251], lr: 0.001973, loss: 2.6680
2022-10-06 21:50:53 - train: epoch 0012, iter [01240, 01251], lr: 0.001973, loss: 4.1632
2022-10-06 21:51:14 - train: epoch 0012, iter [01250, 01251], lr: 0.001973, loss: 3.1949
2022-10-06 21:51:17 - train: epoch 012, train_loss: 3.7008
2022-10-06 21:52:35 - eval: epoch: 012, acc1: 74.788%, acc5: 93.064%, test_loss: 1.1113, per_image_load_time: 1.534ms, per_image_inference_time: 1.418ms
2022-10-06 21:52:36 - until epoch: 012, best_acc1: 74.788%
2022-10-06 21:52:36 - epoch 013 lr: 0.001973
2022-10-06 21:53:03 - train: epoch 0013, iter [00010, 01251], lr: 0.001973, loss: 3.2724
2022-10-06 21:53:25 - train: epoch 0013, iter [00020, 01251], lr: 0.001973, loss: 3.1534
2022-10-06 21:53:46 - train: epoch 0013, iter [00030, 01251], lr: 0.001973, loss: 3.6982
2022-10-06 21:54:07 - train: epoch 0013, iter [00040, 01251], lr: 0.001973, loss: 4.3129
2022-10-06 21:54:29 - train: epoch 0013, iter [00050, 01251], lr: 0.001973, loss: 3.9049
2022-10-06 21:54:50 - train: epoch 0013, iter [00060, 01251], lr: 0.001973, loss: 3.5564
2022-10-06 21:55:11 - train: epoch 0013, iter [00070, 01251], lr: 0.001973, loss: 3.3463
2022-10-06 21:55:32 - train: epoch 0013, iter [00080, 01251], lr: 0.001973, loss: 3.9478
2022-10-06 21:55:54 - train: epoch 0013, iter [00090, 01251], lr: 0.001973, loss: 3.5186
2022-10-06 21:56:15 - train: epoch 0013, iter [00100, 01251], lr: 0.001973, loss: 3.3292
2022-10-06 21:56:36 - train: epoch 0013, iter [00110, 01251], lr: 0.001973, loss: 3.7904
2022-10-06 21:56:57 - train: epoch 0013, iter [00120, 01251], lr: 0.001973, loss: 4.4176
2022-10-06 21:57:19 - train: epoch 0013, iter [00130, 01251], lr: 0.001973, loss: 3.8423
2022-10-06 21:57:40 - train: epoch 0013, iter [00140, 01251], lr: 0.001972, loss: 3.7867
2022-10-06 21:58:01 - train: epoch 0013, iter [00150, 01251], lr: 0.001972, loss: 3.8105
2022-10-06 21:58:22 - train: epoch 0013, iter [00160, 01251], lr: 0.001972, loss: 4.0722
2022-10-06 21:58:44 - train: epoch 0013, iter [00170, 01251], lr: 0.001972, loss: 3.9097
2022-10-06 21:59:05 - train: epoch 0013, iter [00180, 01251], lr: 0.001972, loss: 3.3904
2022-10-06 21:59:26 - train: epoch 0013, iter [00190, 01251], lr: 0.001972, loss: 3.3763
2022-10-06 21:59:47 - train: epoch 0013, iter [00200, 01251], lr: 0.001972, loss: 4.0379
2022-10-06 22:00:08 - train: epoch 0013, iter [00210, 01251], lr: 0.001972, loss: 4.1197
2022-10-06 22:00:30 - train: epoch 0013, iter [00220, 01251], lr: 0.001972, loss: 3.0754
2022-10-06 22:00:51 - train: epoch 0013, iter [00230, 01251], lr: 0.001972, loss: 4.0250
2022-10-06 22:01:12 - train: epoch 0013, iter [00240, 01251], lr: 0.001972, loss: 3.9010
2022-10-06 22:01:33 - train: epoch 0013, iter [00250, 01251], lr: 0.001972, loss: 3.4305
2022-10-06 22:01:55 - train: epoch 0013, iter [00260, 01251], lr: 0.001972, loss: 2.7587
2022-10-06 22:02:16 - train: epoch 0013, iter [00270, 01251], lr: 0.001972, loss: 3.9875
2022-10-06 22:02:37 - train: epoch 0013, iter [00280, 01251], lr: 0.001972, loss: 4.2457
2022-10-06 22:02:59 - train: epoch 0013, iter [00290, 01251], lr: 0.001972, loss: 3.9185
2022-10-06 22:03:20 - train: epoch 0013, iter [00300, 01251], lr: 0.001971, loss: 3.6732
2022-10-06 22:03:41 - train: epoch 0013, iter [00310, 01251], lr: 0.001971, loss: 4.4667
2022-10-06 22:04:03 - train: epoch 0013, iter [00320, 01251], lr: 0.001971, loss: 3.4338
2022-10-06 22:04:24 - train: epoch 0013, iter [00330, 01251], lr: 0.001971, loss: 4.1695
2022-10-06 22:04:46 - train: epoch 0013, iter [00340, 01251], lr: 0.001971, loss: 4.1721
2022-10-06 22:05:07 - train: epoch 0013, iter [00350, 01251], lr: 0.001971, loss: 3.9343
2022-10-06 22:05:28 - train: epoch 0013, iter [00360, 01251], lr: 0.001971, loss: 3.5796
2022-10-06 22:05:49 - train: epoch 0013, iter [00370, 01251], lr: 0.001971, loss: 2.9543
2022-10-06 22:06:11 - train: epoch 0013, iter [00380, 01251], lr: 0.001971, loss: 4.0801
2022-10-06 22:06:32 - train: epoch 0013, iter [00390, 01251], lr: 0.001971, loss: 3.8983
2022-10-06 22:06:53 - train: epoch 0013, iter [00400, 01251], lr: 0.001971, loss: 3.6849
2022-10-06 22:07:15 - train: epoch 0013, iter [00410, 01251], lr: 0.001971, loss: 3.7101
2022-10-06 22:07:36 - train: epoch 0013, iter [00420, 01251], lr: 0.001971, loss: 3.8796
2022-10-06 22:07:57 - train: epoch 0013, iter [00430, 01251], lr: 0.001971, loss: 3.6224
2022-10-06 22:08:19 - train: epoch 0013, iter [00440, 01251], lr: 0.001971, loss: 3.6584
2022-10-06 22:08:40 - train: epoch 0013, iter [00450, 01251], lr: 0.001971, loss: 3.0067
2022-10-06 22:09:01 - train: epoch 0013, iter [00460, 01251], lr: 0.001970, loss: 3.9163
2022-10-06 22:09:23 - train: epoch 0013, iter [00470, 01251], lr: 0.001970, loss: 3.2607
2022-10-06 22:09:44 - train: epoch 0013, iter [00480, 01251], lr: 0.001970, loss: 3.7178
2022-10-06 22:10:05 - train: epoch 0013, iter [00490, 01251], lr: 0.001970, loss: 4.1548
2022-10-06 22:10:27 - train: epoch 0013, iter [00500, 01251], lr: 0.001970, loss: 3.9289
2022-10-06 22:10:48 - train: epoch 0013, iter [00510, 01251], lr: 0.001970, loss: 4.0663
2022-10-06 22:11:10 - train: epoch 0013, iter [00520, 01251], lr: 0.001970, loss: 3.6552
2022-10-06 22:11:31 - train: epoch 0013, iter [00530, 01251], lr: 0.001970, loss: 3.0938
2022-10-06 22:11:52 - train: epoch 0013, iter [00540, 01251], lr: 0.001970, loss: 4.0425
2022-10-06 22:12:14 - train: epoch 0013, iter [00550, 01251], lr: 0.001970, loss: 3.5208
2022-10-06 22:12:35 - train: epoch 0013, iter [00560, 01251], lr: 0.001970, loss: 3.5146
2022-10-06 22:12:56 - train: epoch 0013, iter [00570, 01251], lr: 0.001970, loss: 3.4466
2022-10-06 22:13:18 - train: epoch 0013, iter [00580, 01251], lr: 0.001970, loss: 2.9927
2022-10-06 22:13:39 - train: epoch 0013, iter [00590, 01251], lr: 0.001970, loss: 3.8964
2022-10-06 22:14:01 - train: epoch 0013, iter [00600, 01251], lr: 0.001970, loss: 3.4507
2022-10-06 22:14:22 - train: epoch 0013, iter [00610, 01251], lr: 0.001970, loss: 3.9042
2022-10-06 22:14:44 - train: epoch 0013, iter [00620, 01251], lr: 0.001969, loss: 3.8660
2022-10-06 22:15:05 - train: epoch 0013, iter [00630, 01251], lr: 0.001969, loss: 4.5071
2022-10-06 22:15:26 - train: epoch 0013, iter [00640, 01251], lr: 0.001969, loss: 3.8624
2022-10-06 22:15:48 - train: epoch 0013, iter [00650, 01251], lr: 0.001969, loss: 3.6951
2022-10-06 22:16:09 - train: epoch 0013, iter [00660, 01251], lr: 0.001969, loss: 3.9016
2022-10-06 22:16:31 - train: epoch 0013, iter [00670, 01251], lr: 0.001969, loss: 3.5720
2022-10-06 22:16:52 - train: epoch 0013, iter [00680, 01251], lr: 0.001969, loss: 4.1789
2022-10-06 22:17:14 - train: epoch 0013, iter [00690, 01251], lr: 0.001969, loss: 3.5113
2022-10-06 22:17:35 - train: epoch 0013, iter [00700, 01251], lr: 0.001969, loss: 3.3715
2022-10-06 22:17:56 - train: epoch 0013, iter [00710, 01251], lr: 0.001969, loss: 4.2393
2022-10-06 22:18:18 - train: epoch 0013, iter [00720, 01251], lr: 0.001969, loss: 3.5493
2022-10-06 22:18:39 - train: epoch 0013, iter [00730, 01251], lr: 0.001969, loss: 4.4674
2022-10-06 22:19:01 - train: epoch 0013, iter [00740, 01251], lr: 0.001969, loss: 3.7243
2022-10-06 22:19:23 - train: epoch 0013, iter [00750, 01251], lr: 0.001969, loss: 4.0411
2022-10-06 22:19:44 - train: epoch 0013, iter [00760, 01251], lr: 0.001969, loss: 3.2110
2022-10-06 22:20:06 - train: epoch 0013, iter [00770, 01251], lr: 0.001968, loss: 4.0999
2022-10-06 22:20:27 - train: epoch 0013, iter [00780, 01251], lr: 0.001968, loss: 3.6670
2022-10-06 22:20:49 - train: epoch 0013, iter [00790, 01251], lr: 0.001968, loss: 3.0426
2022-10-06 22:21:10 - train: epoch 0013, iter [00800, 01251], lr: 0.001968, loss: 3.6482
2022-10-06 22:21:32 - train: epoch 0013, iter [00810, 01251], lr: 0.001968, loss: 4.1817
2022-10-06 22:21:53 - train: epoch 0013, iter [00820, 01251], lr: 0.001968, loss: 3.5647
2022-10-06 22:22:15 - train: epoch 0013, iter [00830, 01251], lr: 0.001968, loss: 3.1986
2022-10-06 22:22:36 - train: epoch 0013, iter [00840, 01251], lr: 0.001968, loss: 3.1587
2022-10-06 22:22:58 - train: epoch 0013, iter [00850, 01251], lr: 0.001968, loss: 3.1700
2022-10-06 22:23:19 - train: epoch 0013, iter [00860, 01251], lr: 0.001968, loss: 3.7520
2022-10-06 22:23:41 - train: epoch 0013, iter [00870, 01251], lr: 0.001968, loss: 3.6454
2022-10-06 22:24:02 - train: epoch 0013, iter [00880, 01251], lr: 0.001968, loss: 4.3627
2022-10-06 22:24:24 - train: epoch 0013, iter [00890, 01251], lr: 0.001968, loss: 4.2070
2022-10-06 22:24:45 - train: epoch 0013, iter [00900, 01251], lr: 0.001968, loss: 3.1136
2022-10-06 22:25:07 - train: epoch 0013, iter [00910, 01251], lr: 0.001968, loss: 4.0379
2022-10-06 22:25:28 - train: epoch 0013, iter [00920, 01251], lr: 0.001967, loss: 3.8643
2022-10-06 22:25:49 - train: epoch 0013, iter [00930, 01251], lr: 0.001967, loss: 3.6312
2022-10-06 22:26:11 - train: epoch 0013, iter [00940, 01251], lr: 0.001967, loss: 4.0665
2022-10-06 22:26:33 - train: epoch 0013, iter [00950, 01251], lr: 0.001967, loss: 3.8350
2022-10-06 22:26:54 - train: epoch 0013, iter [00960, 01251], lr: 0.001967, loss: 3.1629
2022-10-06 22:27:16 - train: epoch 0013, iter [00970, 01251], lr: 0.001967, loss: 4.2650
2022-10-06 22:27:37 - train: epoch 0013, iter [00980, 01251], lr: 0.001967, loss: 3.0426
2022-10-06 22:27:59 - train: epoch 0013, iter [00990, 01251], lr: 0.001967, loss: 4.2422
2022-10-06 22:28:20 - train: epoch 0013, iter [01000, 01251], lr: 0.001967, loss: 3.1892
2022-10-06 22:28:42 - train: epoch 0013, iter [01010, 01251], lr: 0.001967, loss: 3.6630
2022-10-06 22:29:03 - train: epoch 0013, iter [01020, 01251], lr: 0.001967, loss: 4.0530
2022-10-06 22:29:25 - train: epoch 0013, iter [01030, 01251], lr: 0.001967, loss: 3.1309
2022-10-06 22:29:46 - train: epoch 0013, iter [01040, 01251], lr: 0.001967, loss: 4.0093
2022-10-06 22:30:08 - train: epoch 0013, iter [01050, 01251], lr: 0.001967, loss: 3.8711
2022-10-06 22:30:29 - train: epoch 0013, iter [01060, 01251], lr: 0.001967, loss: 3.9987
2022-10-06 22:30:51 - train: epoch 0013, iter [01070, 01251], lr: 0.001966, loss: 3.3436
2022-10-06 22:31:12 - train: epoch 0013, iter [01080, 01251], lr: 0.001966, loss: 3.5162
2022-10-06 22:31:34 - train: epoch 0013, iter [01090, 01251], lr: 0.001966, loss: 3.2059
2022-10-06 22:31:55 - train: epoch 0013, iter [01100, 01251], lr: 0.001966, loss: 3.8282
2022-10-06 22:32:16 - train: epoch 0013, iter [01110, 01251], lr: 0.001966, loss: 4.5590
2022-10-06 22:32:38 - train: epoch 0013, iter [01120, 01251], lr: 0.001966, loss: 3.6731
2022-10-06 22:33:00 - train: epoch 0013, iter [01130, 01251], lr: 0.001966, loss: 4.1217
2022-10-06 22:33:22 - train: epoch 0013, iter [01140, 01251], lr: 0.001966, loss: 3.2898
2022-10-06 22:33:43 - train: epoch 0013, iter [01150, 01251], lr: 0.001966, loss: 4.1012
2022-10-06 22:34:05 - train: epoch 0013, iter [01160, 01251], lr: 0.001966, loss: 3.9818
2022-10-06 22:34:26 - train: epoch 0013, iter [01170, 01251], lr: 0.001966, loss: 3.6569
2022-10-06 22:34:48 - train: epoch 0013, iter [01180, 01251], lr: 0.001966, loss: 4.0848
2022-10-06 22:35:09 - train: epoch 0013, iter [01190, 01251], lr: 0.001966, loss: 3.5111
2022-10-06 22:35:31 - train: epoch 0013, iter [01200, 01251], lr: 0.001966, loss: 4.2422
2022-10-06 22:35:52 - train: epoch 0013, iter [01210, 01251], lr: 0.001966, loss: 4.1332
2022-10-06 22:36:14 - train: epoch 0013, iter [01220, 01251], lr: 0.001965, loss: 3.9668
2022-10-06 22:36:35 - train: epoch 0013, iter [01230, 01251], lr: 0.001965, loss: 3.2291
2022-10-06 22:36:57 - train: epoch 0013, iter [01240, 01251], lr: 0.001965, loss: 2.8674
2022-10-06 22:37:18 - train: epoch 0013, iter [01250, 01251], lr: 0.001965, loss: 3.5290
2022-10-06 22:37:22 - train: epoch 013, train_loss: 3.6696
2022-10-06 22:38:39 - eval: epoch: 013, acc1: 74.936%, acc5: 93.202%, test_loss: 1.0863, per_image_load_time: 1.490ms, per_image_inference_time: 1.426ms
2022-10-06 22:38:41 - until epoch: 013, best_acc1: 74.936%
2022-10-06 22:38:41 - epoch 014 lr: 0.001965
2022-10-06 22:39:08 - train: epoch 0014, iter [00010, 01251], lr: 0.001965, loss: 3.5141
2022-10-06 22:39:29 - train: epoch 0014, iter [00020, 01251], lr: 0.001965, loss: 2.4435
2022-10-06 22:39:51 - train: epoch 0014, iter [00030, 01251], lr: 0.001965, loss: 4.0595
2022-10-06 22:40:12 - train: epoch 0014, iter [00040, 01251], lr: 0.001965, loss: 3.2733
2022-10-06 22:40:34 - train: epoch 0014, iter [00050, 01251], lr: 0.001965, loss: 3.8938
2022-10-06 22:40:55 - train: epoch 0014, iter [00060, 01251], lr: 0.001965, loss: 3.7138
2022-10-06 22:41:16 - train: epoch 0014, iter [00070, 01251], lr: 0.001965, loss: 3.2321
2022-10-06 22:41:37 - train: epoch 0014, iter [00080, 01251], lr: 0.001965, loss: 3.9301
2022-10-06 22:41:59 - train: epoch 0014, iter [00090, 01251], lr: 0.001965, loss: 3.2082
2022-10-06 22:42:20 - train: epoch 0014, iter [00100, 01251], lr: 0.001965, loss: 3.3214
2022-10-06 22:42:41 - train: epoch 0014, iter [00110, 01251], lr: 0.001964, loss: 3.2703
2022-10-06 22:43:03 - train: epoch 0014, iter [00120, 01251], lr: 0.001964, loss: 3.3346
2022-10-06 22:43:24 - train: epoch 0014, iter [00130, 01251], lr: 0.001964, loss: 3.6584
2022-10-06 22:43:45 - train: epoch 0014, iter [00140, 01251], lr: 0.001964, loss: 3.4371
2022-10-06 22:44:07 - train: epoch 0014, iter [00150, 01251], lr: 0.001964, loss: 3.7962
2022-10-06 22:44:28 - train: epoch 0014, iter [00160, 01251], lr: 0.001964, loss: 3.7795
2022-10-06 22:44:50 - train: epoch 0014, iter [00170, 01251], lr: 0.001964, loss: 4.1386
2022-10-06 22:45:11 - train: epoch 0014, iter [00180, 01251], lr: 0.001964, loss: 3.8151
2022-10-06 22:45:33 - train: epoch 0014, iter [00190, 01251], lr: 0.001964, loss: 4.1300
2022-10-06 22:45:54 - train: epoch 0014, iter [00200, 01251], lr: 0.001964, loss: 3.6084
2022-10-06 22:46:16 - train: epoch 0014, iter [00210, 01251], lr: 0.001964, loss: 3.6144
2022-10-06 22:46:37 - train: epoch 0014, iter [00220, 01251], lr: 0.001964, loss: 2.6263
2022-10-06 22:46:58 - train: epoch 0014, iter [00230, 01251], lr: 0.001964, loss: 3.4403
2022-10-06 22:47:19 - train: epoch 0014, iter [00240, 01251], lr: 0.001964, loss: 4.1620
2022-10-06 22:47:41 - train: epoch 0014, iter [00250, 01251], lr: 0.001963, loss: 3.7523
2022-10-06 22:48:02 - train: epoch 0014, iter [00260, 01251], lr: 0.001963, loss: 3.8298
2022-10-06 22:48:23 - train: epoch 0014, iter [00270, 01251], lr: 0.001963, loss: 4.1847
2022-10-06 22:48:44 - train: epoch 0014, iter [00280, 01251], lr: 0.001963, loss: 3.9913
2022-10-06 22:49:06 - train: epoch 0014, iter [00290, 01251], lr: 0.001963, loss: 3.5340
2022-10-06 22:49:27 - train: epoch 0014, iter [00300, 01251], lr: 0.001963, loss: 4.1296
2022-10-06 22:49:48 - train: epoch 0014, iter [00310, 01251], lr: 0.001963, loss: 3.7785
2022-10-06 22:50:10 - train: epoch 0014, iter [00320, 01251], lr: 0.001963, loss: 3.3054
2022-10-06 22:50:31 - train: epoch 0014, iter [00330, 01251], lr: 0.001963, loss: 3.7002
2022-10-06 22:50:52 - train: epoch 0014, iter [00340, 01251], lr: 0.001963, loss: 3.6565
2022-10-06 22:51:14 - train: epoch 0014, iter [00350, 01251], lr: 0.001963, loss: 3.6432
2022-10-06 22:51:35 - train: epoch 0014, iter [00360, 01251], lr: 0.001963, loss: 3.5089
2022-10-06 22:51:57 - train: epoch 0014, iter [00370, 01251], lr: 0.001963, loss: 3.2862
2022-10-06 22:52:18 - train: epoch 0014, iter [00380, 01251], lr: 0.001963, loss: 3.4425
2022-10-06 22:52:39 - train: epoch 0014, iter [00390, 01251], lr: 0.001962, loss: 3.8952
2022-10-06 22:53:01 - train: epoch 0014, iter [00400, 01251], lr: 0.001962, loss: 3.5291
2022-10-06 22:53:22 - train: epoch 0014, iter [00410, 01251], lr: 0.001962, loss: 3.1512
2022-10-06 22:53:43 - train: epoch 0014, iter [00420, 01251], lr: 0.001962, loss: 3.7781
2022-10-06 22:54:05 - train: epoch 0014, iter [00430, 01251], lr: 0.001962, loss: 3.7583
2022-10-06 22:54:26 - train: epoch 0014, iter [00440, 01251], lr: 0.001962, loss: 3.5797
2022-10-06 22:54:47 - train: epoch 0014, iter [00450, 01251], lr: 0.001962, loss: 3.4328
2022-10-06 22:55:08 - train: epoch 0014, iter [00460, 01251], lr: 0.001962, loss: 3.6255
2022-10-06 22:55:30 - train: epoch 0014, iter [00470, 01251], lr: 0.001962, loss: 3.5577
2022-10-06 22:55:51 - train: epoch 0014, iter [00480, 01251], lr: 0.001962, loss: 3.3788
2022-10-06 22:56:13 - train: epoch 0014, iter [00490, 01251], lr: 0.001962, loss: 4.3677
2022-10-06 22:56:34 - train: epoch 0014, iter [00500, 01251], lr: 0.001962, loss: 3.5863
2022-10-06 22:56:56 - train: epoch 0014, iter [00510, 01251], lr: 0.001962, loss: 3.6216
2022-10-06 22:57:17 - train: epoch 0014, iter [00520, 01251], lr: 0.001962, loss: 3.5392
2022-10-06 22:57:38 - train: epoch 0014, iter [00530, 01251], lr: 0.001961, loss: 4.1579
2022-10-06 22:58:00 - train: epoch 0014, iter [00540, 01251], lr: 0.001961, loss: 3.8855
2022-10-06 22:58:22 - train: epoch 0014, iter [00550, 01251], lr: 0.001961, loss: 3.3566
2022-10-06 22:58:43 - train: epoch 0014, iter [00560, 01251], lr: 0.001961, loss: 3.5519
2022-10-06 22:59:05 - train: epoch 0014, iter [00570, 01251], lr: 0.001961, loss: 3.9678
2022-10-06 22:59:26 - train: epoch 0014, iter [00580, 01251], lr: 0.001961, loss: 3.7852
2022-10-06 22:59:48 - train: epoch 0014, iter [00590, 01251], lr: 0.001961, loss: 3.7649
2022-10-06 23:00:09 - train: epoch 0014, iter [00600, 01251], lr: 0.001961, loss: 3.9302
2022-10-06 23:00:31 - train: epoch 0014, iter [00610, 01251], lr: 0.001961, loss: 3.5727
2022-10-06 23:00:52 - train: epoch 0014, iter [00620, 01251], lr: 0.001961, loss: 3.4418
2022-10-06 23:01:14 - train: epoch 0014, iter [00630, 01251], lr: 0.001961, loss: 3.1913
2022-10-06 23:01:35 - train: epoch 0014, iter [00640, 01251], lr: 0.001961, loss: 3.8662
2022-10-06 23:01:57 - train: epoch 0014, iter [00650, 01251], lr: 0.001961, loss: 3.7633
2022-10-06 23:02:18 - train: epoch 0014, iter [00660, 01251], lr: 0.001961, loss: 3.3509
2022-10-06 23:02:40 - train: epoch 0014, iter [00670, 01251], lr: 0.001960, loss: 4.1193
2022-10-06 23:03:01 - train: epoch 0014, iter [00680, 01251], lr: 0.001960, loss: 3.9510
2022-10-06 23:03:22 - train: epoch 0014, iter [00690, 01251], lr: 0.001960, loss: 3.4278
2022-10-06 23:03:44 - train: epoch 0014, iter [00700, 01251], lr: 0.001960, loss: 3.9995
2022-10-06 23:04:05 - train: epoch 0014, iter [00710, 01251], lr: 0.001960, loss: 3.9853
2022-10-06 23:04:27 - train: epoch 0014, iter [00720, 01251], lr: 0.001960, loss: 4.1110
2022-10-06 23:04:48 - train: epoch 0014, iter [00730, 01251], lr: 0.001960, loss: 3.2414
2022-10-06 23:05:10 - train: epoch 0014, iter [00740, 01251], lr: 0.001960, loss: 3.8871
2022-10-06 23:05:32 - train: epoch 0014, iter [00750, 01251], lr: 0.001960, loss: 3.1306
2022-10-06 23:05:53 - train: epoch 0014, iter [00760, 01251], lr: 0.001960, loss: 3.6704
2022-10-06 23:06:15 - train: epoch 0014, iter [00770, 01251], lr: 0.001960, loss: 3.6592
2022-10-06 23:06:36 - train: epoch 0014, iter [00780, 01251], lr: 0.001960, loss: 3.9739
2022-10-06 23:06:58 - train: epoch 0014, iter [00790, 01251], lr: 0.001960, loss: 3.4580
2022-10-06 23:07:19 - train: epoch 0014, iter [00800, 01251], lr: 0.001959, loss: 4.1945
2022-10-06 23:07:41 - train: epoch 0014, iter [00810, 01251], lr: 0.001959, loss: 3.5383
2022-10-06 23:08:02 - train: epoch 0014, iter [00820, 01251], lr: 0.001959, loss: 3.7452
2022-10-06 23:08:24 - train: epoch 0014, iter [00830, 01251], lr: 0.001959, loss: 3.1406
2022-10-06 23:08:45 - train: epoch 0014, iter [00840, 01251], lr: 0.001959, loss: 3.7071
2022-10-06 23:09:07 - train: epoch 0014, iter [00850, 01251], lr: 0.001959, loss: 3.9915
2022-10-06 23:09:28 - train: epoch 0014, iter [00860, 01251], lr: 0.001959, loss: 4.1719
2022-10-06 23:09:49 - train: epoch 0014, iter [00870, 01251], lr: 0.001959, loss: 3.9814
2022-10-06 23:10:11 - train: epoch 0014, iter [00880, 01251], lr: 0.001959, loss: 3.6613
2022-10-06 23:10:32 - train: epoch 0014, iter [00890, 01251], lr: 0.001959, loss: 4.3333
2022-10-06 23:10:54 - train: epoch 0014, iter [00900, 01251], lr: 0.001959, loss: 4.0534
2022-10-06 23:11:15 - train: epoch 0014, iter [00910, 01251], lr: 0.001959, loss: 2.8749
2022-10-06 23:11:36 - train: epoch 0014, iter [00920, 01251], lr: 0.001959, loss: 3.5215
2022-10-06 23:11:58 - train: epoch 0014, iter [00930, 01251], lr: 0.001959, loss: 3.3082
2022-10-06 23:12:19 - train: epoch 0014, iter [00940, 01251], lr: 0.001958, loss: 4.0281
2022-10-06 23:12:41 - train: epoch 0014, iter [00950, 01251], lr: 0.001958, loss: 3.0261
2022-10-06 23:13:02 - train: epoch 0014, iter [00960, 01251], lr: 0.001958, loss: 3.3635
2022-10-06 23:13:24 - train: epoch 0014, iter [00970, 01251], lr: 0.001958, loss: 3.7289
2022-10-06 23:13:45 - train: epoch 0014, iter [00980, 01251], lr: 0.001958, loss: 3.9873
2022-10-06 23:14:07 - train: epoch 0014, iter [00990, 01251], lr: 0.001958, loss: 3.4841
2022-10-06 23:14:28 - train: epoch 0014, iter [01000, 01251], lr: 0.001958, loss: 4.1868
2022-10-06 23:14:50 - train: epoch 0014, iter [01010, 01251], lr: 0.001958, loss: 3.5957
2022-10-06 23:15:11 - train: epoch 0014, iter [01020, 01251], lr: 0.001958, loss: 3.7007
2022-10-06 23:15:33 - train: epoch 0014, iter [01030, 01251], lr: 0.001958, loss: 3.6629
2022-10-06 23:15:54 - train: epoch 0014, iter [01040, 01251], lr: 0.001958, loss: 3.8944
2022-10-06 23:16:15 - train: epoch 0014, iter [01050, 01251], lr: 0.001958, loss: 3.5323
2022-10-06 23:16:37 - train: epoch 0014, iter [01060, 01251], lr: 0.001958, loss: 3.5009
2022-10-06 23:16:58 - train: epoch 0014, iter [01070, 01251], lr: 0.001957, loss: 3.3553
2022-10-06 23:17:20 - train: epoch 0014, iter [01080, 01251], lr: 0.001957, loss: 4.0601
2022-10-06 23:17:41 - train: epoch 0014, iter [01090, 01251], lr: 0.001957, loss: 2.6680
2022-10-06 23:18:03 - train: epoch 0014, iter [01100, 01251], lr: 0.001957, loss: 3.6282
2022-10-06 23:18:24 - train: epoch 0014, iter [01110, 01251], lr: 0.001957, loss: 3.9351
2022-10-06 23:18:45 - train: epoch 0014, iter [01120, 01251], lr: 0.001957, loss: 3.4797
2022-10-06 23:19:07 - train: epoch 0014, iter [01130, 01251], lr: 0.001957, loss: 3.5425
2022-10-06 23:19:29 - train: epoch 0014, iter [01140, 01251], lr: 0.001957, loss: 3.9563
2022-10-06 23:19:50 - train: epoch 0014, iter [01150, 01251], lr: 0.001957, loss: 3.8507
2022-10-06 23:20:12 - train: epoch 0014, iter [01160, 01251], lr: 0.001957, loss: 4.2467
2022-10-06 23:20:33 - train: epoch 0014, iter [01170, 01251], lr: 0.001957, loss: 3.5839
2022-10-06 23:20:55 - train: epoch 0014, iter [01180, 01251], lr: 0.001957, loss: 3.7914
2022-10-06 23:21:16 - train: epoch 0014, iter [01190, 01251], lr: 0.001957, loss: 3.4050
2022-10-06 23:21:37 - train: epoch 0014, iter [01200, 01251], lr: 0.001956, loss: 3.3966
2022-10-06 23:21:59 - train: epoch 0014, iter [01210, 01251], lr: 0.001956, loss: 3.4342
2022-10-06 23:22:20 - train: epoch 0014, iter [01220, 01251], lr: 0.001956, loss: 4.2524
2022-10-06 23:22:42 - train: epoch 0014, iter [01230, 01251], lr: 0.001956, loss: 3.3876
2022-10-06 23:23:03 - train: epoch 0014, iter [01240, 01251], lr: 0.001956, loss: 4.0395
2022-10-06 23:23:24 - train: epoch 0014, iter [01250, 01251], lr: 0.001956, loss: 2.5393
2022-10-06 23:23:28 - train: epoch 014, train_loss: 3.6439
2022-10-06 23:24:44 - eval: epoch: 014, acc1: 75.296%, acc5: 93.290%, test_loss: 1.0859, per_image_load_time: 0.669ms, per_image_inference_time: 1.416ms
2022-10-06 23:24:46 - until epoch: 014, best_acc1: 75.296%
2022-10-06 23:24:46 - epoch 015 lr: 0.001956
2022-10-06 23:25:13 - train: epoch 0015, iter [00010, 01251], lr: 0.001956, loss: 3.9843
2022-10-06 23:25:35 - train: epoch 0015, iter [00020, 01251], lr: 0.001956, loss: 3.6328
2022-10-06 23:25:56 - train: epoch 0015, iter [00030, 01251], lr: 0.001956, loss: 4.1602
2022-10-06 23:26:17 - train: epoch 0015, iter [00040, 01251], lr: 0.001956, loss: 3.2329
2022-10-06 23:26:39 - train: epoch 0015, iter [00050, 01251], lr: 0.001956, loss: 3.7704
2022-10-06 23:27:00 - train: epoch 0015, iter [00060, 01251], lr: 0.001956, loss: 4.1120
2022-10-06 23:27:21 - train: epoch 0015, iter [00070, 01251], lr: 0.001956, loss: 3.5681
2022-10-06 23:27:43 - train: epoch 0015, iter [00080, 01251], lr: 0.001955, loss: 3.7172
2022-10-06 23:28:04 - train: epoch 0015, iter [00090, 01251], lr: 0.001955, loss: 3.1061
2022-10-06 23:28:26 - train: epoch 0015, iter [00100, 01251], lr: 0.001955, loss: 3.4781
2022-10-06 23:28:47 - train: epoch 0015, iter [00110, 01251], lr: 0.001955, loss: 4.1063
2022-10-06 23:29:09 - train: epoch 0015, iter [00120, 01251], lr: 0.001955, loss: 3.9268
2022-10-06 23:29:30 - train: epoch 0015, iter [00130, 01251], lr: 0.001955, loss: 3.8914
2022-10-06 23:29:52 - train: epoch 0015, iter [00140, 01251], lr: 0.001955, loss: 3.7368
2022-10-06 23:30:13 - train: epoch 0015, iter [00150, 01251], lr: 0.001955, loss: 3.9920
2022-10-06 23:30:34 - train: epoch 0015, iter [00160, 01251], lr: 0.001955, loss: 4.1197
2022-10-06 23:30:56 - train: epoch 0015, iter [00170, 01251], lr: 0.001955, loss: 4.1450
2022-10-06 23:31:17 - train: epoch 0015, iter [00180, 01251], lr: 0.001955, loss: 3.3220
2022-10-06 23:31:39 - train: epoch 0015, iter [00190, 01251], lr: 0.001955, loss: 3.5310
2022-10-06 23:32:00 - train: epoch 0015, iter [00200, 01251], lr: 0.001954, loss: 3.2532
2022-10-06 23:32:21 - train: epoch 0015, iter [00210, 01251], lr: 0.001954, loss: 3.4884
2022-10-06 23:32:42 - train: epoch 0015, iter [00220, 01251], lr: 0.001954, loss: 3.7336
2022-10-06 23:33:04 - train: epoch 0015, iter [00230, 01251], lr: 0.001954, loss: 3.9223
2022-10-06 23:33:25 - train: epoch 0015, iter [00240, 01251], lr: 0.001954, loss: 2.7978
2022-10-06 23:33:47 - train: epoch 0015, iter [00250, 01251], lr: 0.001954, loss: 2.7675
2022-10-06 23:34:08 - train: epoch 0015, iter [00260, 01251], lr: 0.001954, loss: 3.5649
2022-10-06 23:34:30 - train: epoch 0015, iter [00270, 01251], lr: 0.001954, loss: 3.8783
2022-10-06 23:34:51 - train: epoch 0015, iter [00280, 01251], lr: 0.001954, loss: 4.1294
2022-10-06 23:35:12 - train: epoch 0015, iter [00290, 01251], lr: 0.001954, loss: 3.4073
2022-10-06 23:35:34 - train: epoch 0015, iter [00300, 01251], lr: 0.001954, loss: 4.1715
2022-10-06 23:35:55 - train: epoch 0015, iter [00310, 01251], lr: 0.001954, loss: 2.9930
2022-10-06 23:36:17 - train: epoch 0015, iter [00320, 01251], lr: 0.001954, loss: 3.6596
2022-10-06 23:36:38 - train: epoch 0015, iter [00330, 01251], lr: 0.001953, loss: 3.0058
2022-10-06 23:37:00 - train: epoch 0015, iter [00340, 01251], lr: 0.001953, loss: 2.4396
2022-10-06 23:37:21 - train: epoch 0015, iter [00350, 01251], lr: 0.001953, loss: 2.7503
2022-10-06 23:37:42 - train: epoch 0015, iter [00360, 01251], lr: 0.001953, loss: 3.9825
2022-10-06 23:38:04 - train: epoch 0015, iter [00370, 01251], lr: 0.001953, loss: 2.9819
2022-10-06 23:38:25 - train: epoch 0015, iter [00380, 01251], lr: 0.001953, loss: 3.6383
2022-10-06 23:38:47 - train: epoch 0015, iter [00390, 01251], lr: 0.001953, loss: 3.4495
2022-10-06 23:39:08 - train: epoch 0015, iter [00400, 01251], lr: 0.001953, loss: 3.6652
2022-10-06 23:39:30 - train: epoch 0015, iter [00410, 01251], lr: 0.001953, loss: 4.2440
2022-10-06 23:39:51 - train: epoch 0015, iter [00420, 01251], lr: 0.001953, loss: 3.5550
2022-10-06 23:40:13 - train: epoch 0015, iter [00430, 01251], lr: 0.001953, loss: 3.9019
2022-10-06 23:40:34 - train: epoch 0015, iter [00440, 01251], lr: 0.001953, loss: 3.9360
2022-10-06 23:40:56 - train: epoch 0015, iter [00450, 01251], lr: 0.001953, loss: 3.4232
2022-10-06 23:41:17 - train: epoch 0015, iter [00460, 01251], lr: 0.001952, loss: 3.8154
2022-10-06 23:41:39 - train: epoch 0015, iter [00470, 01251], lr: 0.001952, loss: 3.7897
2022-10-06 23:42:00 - train: epoch 0015, iter [00480, 01251], lr: 0.001952, loss: 3.0431
2022-10-06 23:42:21 - train: epoch 0015, iter [00490, 01251], lr: 0.001952, loss: 3.2164
2022-10-06 23:42:43 - train: epoch 0015, iter [00500, 01251], lr: 0.001952, loss: 4.2632
2022-10-06 23:43:04 - train: epoch 0015, iter [00510, 01251], lr: 0.001952, loss: 3.9031
2022-10-06 23:43:26 - train: epoch 0015, iter [00520, 01251], lr: 0.001952, loss: 3.6336
2022-10-06 23:43:47 - train: epoch 0015, iter [00530, 01251], lr: 0.001952, loss: 3.8562
2022-10-06 23:44:09 - train: epoch 0015, iter [00540, 01251], lr: 0.001952, loss: 4.0777
2022-10-06 23:44:30 - train: epoch 0015, iter [00550, 01251], lr: 0.001952, loss: 3.5009
2022-10-06 23:44:52 - train: epoch 0015, iter [00560, 01251], lr: 0.001952, loss: 3.1527
2022-10-06 23:45:13 - train: epoch 0015, iter [00570, 01251], lr: 0.001952, loss: 3.8016
2022-10-06 23:45:35 - train: epoch 0015, iter [00580, 01251], lr: 0.001951, loss: 3.6751
2022-10-06 23:45:56 - train: epoch 0015, iter [00590, 01251], lr: 0.001951, loss: 3.1010
2022-10-06 23:46:17 - train: epoch 0015, iter [00600, 01251], lr: 0.001951, loss: 4.0784
2022-10-06 23:46:39 - train: epoch 0015, iter [00610, 01251], lr: 0.001951, loss: 3.7947
2022-10-06 23:47:00 - train: epoch 0015, iter [00620, 01251], lr: 0.001951, loss: 3.6987
2022-10-06 23:47:21 - train: epoch 0015, iter [00630, 01251], lr: 0.001951, loss: 3.7608
2022-10-06 23:47:43 - train: epoch 0015, iter [00640, 01251], lr: 0.001951, loss: 4.1673
2022-10-06 23:48:04 - train: epoch 0015, iter [00650, 01251], lr: 0.001951, loss: 3.3914
2022-10-06 23:48:25 - train: epoch 0015, iter [00660, 01251], lr: 0.001951, loss: 3.5661
2022-10-06 23:48:47 - train: epoch 0015, iter [00670, 01251], lr: 0.001951, loss: 3.5486
2022-10-06 23:49:08 - train: epoch 0015, iter [00680, 01251], lr: 0.001951, loss: 3.2026
2022-10-06 23:49:29 - train: epoch 0015, iter [00690, 01251], lr: 0.001951, loss: 3.6058
2022-10-06 23:49:51 - train: epoch 0015, iter [00700, 01251], lr: 0.001950, loss: 3.6419
2022-10-06 23:50:12 - train: epoch 0015, iter [00710, 01251], lr: 0.001950, loss: 4.0592
2022-10-06 23:50:33 - train: epoch 0015, iter [00720, 01251], lr: 0.001950, loss: 3.3266
2022-10-06 23:50:55 - train: epoch 0015, iter [00730, 01251], lr: 0.001950, loss: 3.7272
2022-10-06 23:51:16 - train: epoch 0015, iter [00740, 01251], lr: 0.001950, loss: 3.9526
2022-10-06 23:51:37 - train: epoch 0015, iter [00750, 01251], lr: 0.001950, loss: 3.1158
2022-10-06 23:51:59 - train: epoch 0015, iter [00760, 01251], lr: 0.001950, loss: 3.8216
2022-10-06 23:52:20 - train: epoch 0015, iter [00770, 01251], lr: 0.001950, loss: 2.8845
2022-10-06 23:52:41 - train: epoch 0015, iter [00780, 01251], lr: 0.001950, loss: 2.6983
2022-10-06 23:53:03 - train: epoch 0015, iter [00790, 01251], lr: 0.001950, loss: 3.3864
2022-10-06 23:53:24 - train: epoch 0015, iter [00800, 01251], lr: 0.001950, loss: 3.7601
2022-10-06 23:53:45 - train: epoch 0015, iter [00810, 01251], lr: 0.001950, loss: 3.5543
2022-10-06 23:54:07 - train: epoch 0015, iter [00820, 01251], lr: 0.001949, loss: 4.3652
2022-10-06 23:54:28 - train: epoch 0015, iter [00830, 01251], lr: 0.001949, loss: 3.8864
2022-10-06 23:54:49 - train: epoch 0015, iter [00840, 01251], lr: 0.001949, loss: 3.0385
2022-10-06 23:55:11 - train: epoch 0015, iter [00850, 01251], lr: 0.001949, loss: 3.2497
2022-10-06 23:55:32 - train: epoch 0015, iter [00860, 01251], lr: 0.001949, loss: 4.0699
2022-10-06 23:55:53 - train: epoch 0015, iter [00870, 01251], lr: 0.001949, loss: 3.1835
2022-10-06 23:56:15 - train: epoch 0015, iter [00880, 01251], lr: 0.001949, loss: 3.4917
2022-10-06 23:56:36 - train: epoch 0015, iter [00890, 01251], lr: 0.001949, loss: 3.2555
2022-10-06 23:56:57 - train: epoch 0015, iter [00900, 01251], lr: 0.001949, loss: 4.0077
2022-10-06 23:57:19 - train: epoch 0015, iter [00910, 01251], lr: 0.001949, loss: 3.7469
2022-10-06 23:57:40 - train: epoch 0015, iter [00920, 01251], lr: 0.001949, loss: 3.6278
2022-10-06 23:58:01 - train: epoch 0015, iter [00930, 01251], lr: 0.001949, loss: 3.4979
2022-10-06 23:58:23 - train: epoch 0015, iter [00940, 01251], lr: 0.001948, loss: 3.0100
2022-10-06 23:58:44 - train: epoch 0015, iter [00950, 01251], lr: 0.001948, loss: 3.9585
2022-10-06 23:59:05 - train: epoch 0015, iter [00960, 01251], lr: 0.001948, loss: 3.0804
2022-10-06 23:59:27 - train: epoch 0015, iter [00970, 01251], lr: 0.001948, loss: 3.9459
2022-10-06 23:59:48 - train: epoch 0015, iter [00980, 01251], lr: 0.001948, loss: 3.9676
2022-10-07 00:00:10 - train: epoch 0015, iter [00990, 01251], lr: 0.001948, loss: 3.6646
2022-10-07 00:00:31 - train: epoch 0015, iter [01000, 01251], lr: 0.001948, loss: 3.7080
2022-10-07 00:00:52 - train: epoch 0015, iter [01010, 01251], lr: 0.001948, loss: 4.2010
2022-10-07 00:01:14 - train: epoch 0015, iter [01020, 01251], lr: 0.001948, loss: 3.7963
2022-10-07 00:01:35 - train: epoch 0015, iter [01030, 01251], lr: 0.001948, loss: 2.9181
2022-10-07 00:01:56 - train: epoch 0015, iter [01040, 01251], lr: 0.001948, loss: 3.8441
2022-10-07 00:02:18 - train: epoch 0015, iter [01050, 01251], lr: 0.001948, loss: 3.6090
2022-10-07 00:02:39 - train: epoch 0015, iter [01060, 01251], lr: 0.001947, loss: 4.0176
2022-10-07 00:03:00 - train: epoch 0015, iter [01070, 01251], lr: 0.001947, loss: 3.3899
2022-10-07 00:03:22 - train: epoch 0015, iter [01080, 01251], lr: 0.001947, loss: 3.9798
2022-10-07 00:03:43 - train: epoch 0015, iter [01090, 01251], lr: 0.001947, loss: 3.9261
2022-10-07 00:04:04 - train: epoch 0015, iter [01100, 01251], lr: 0.001947, loss: 3.4209
2022-10-07 00:04:25 - train: epoch 0015, iter [01110, 01251], lr: 0.001947, loss: 3.2766
2022-10-07 00:04:47 - train: epoch 0015, iter [01120, 01251], lr: 0.001947, loss: 4.2612
2022-10-07 00:05:08 - train: epoch 0015, iter [01130, 01251], lr: 0.001947, loss: 3.3026
2022-10-07 00:05:30 - train: epoch 0015, iter [01140, 01251], lr: 0.001947, loss: 3.6475
2022-10-07 00:05:51 - train: epoch 0015, iter [01150, 01251], lr: 0.001947, loss: 3.7924
2022-10-07 00:06:12 - train: epoch 0015, iter [01160, 01251], lr: 0.001947, loss: 3.1615
2022-10-07 00:06:34 - train: epoch 0015, iter [01170, 01251], lr: 0.001947, loss: 3.2867
2022-10-07 00:06:55 - train: epoch 0015, iter [01180, 01251], lr: 0.001946, loss: 4.1309
2022-10-07 00:07:17 - train: epoch 0015, iter [01190, 01251], lr: 0.001946, loss: 3.8321
2022-10-07 00:07:38 - train: epoch 0015, iter [01200, 01251], lr: 0.001946, loss: 4.1388
2022-10-07 00:07:59 - train: epoch 0015, iter [01210, 01251], lr: 0.001946, loss: 3.1246
2022-10-07 00:08:20 - train: epoch 0015, iter [01220, 01251], lr: 0.001946, loss: 3.9138
2022-10-07 00:08:41 - train: epoch 0015, iter [01230, 01251], lr: 0.001946, loss: 2.7891
2022-10-07 00:09:03 - train: epoch 0015, iter [01240, 01251], lr: 0.001946, loss: 3.4847
2022-10-07 00:09:24 - train: epoch 0015, iter [01250, 01251], lr: 0.001946, loss: 4.0394
2022-10-07 00:09:27 - train: epoch 015, train_loss: 3.6086
2022-10-07 00:10:42 - eval: epoch: 015, acc1: 75.988%, acc5: 93.566%, test_loss: 1.0570, per_image_load_time: 0.222ms, per_image_inference_time: 1.411ms
2022-10-07 00:10:44 - until epoch: 015, best_acc1: 75.988%
2022-10-07 00:10:44 - epoch 016 lr: 0.001946
2022-10-07 00:11:11 - train: epoch 0016, iter [00010, 01251], lr: 0.001946, loss: 3.8139
2022-10-07 00:11:33 - train: epoch 0016, iter [00020, 01251], lr: 0.001946, loss: 3.5661
2022-10-07 00:11:54 - train: epoch 0016, iter [00030, 01251], lr: 0.001946, loss: 3.2223
2022-10-07 00:12:16 - train: epoch 0016, iter [00040, 01251], lr: 0.001946, loss: 3.6365
2022-10-07 00:12:37 - train: epoch 0016, iter [00050, 01251], lr: 0.001945, loss: 3.7761
2022-10-07 00:12:59 - train: epoch 0016, iter [00060, 01251], lr: 0.001945, loss: 3.7260
2022-10-07 00:13:20 - train: epoch 0016, iter [00070, 01251], lr: 0.001945, loss: 3.8131
2022-10-07 00:13:42 - train: epoch 0016, iter [00080, 01251], lr: 0.001945, loss: 3.5756
2022-10-07 00:14:03 - train: epoch 0016, iter [00090, 01251], lr: 0.001945, loss: 3.2902
2022-10-07 00:14:25 - train: epoch 0016, iter [00100, 01251], lr: 0.001945, loss: 3.9028
2022-10-07 00:14:46 - train: epoch 0016, iter [00110, 01251], lr: 0.001945, loss: 3.0618
2022-10-07 00:15:08 - train: epoch 0016, iter [00120, 01251], lr: 0.001945, loss: 3.8957
2022-10-07 00:15:29 - train: epoch 0016, iter [00130, 01251], lr: 0.001945, loss: 3.6410
2022-10-07 00:15:50 - train: epoch 0016, iter [00140, 01251], lr: 0.001945, loss: 3.9943
2022-10-07 00:16:12 - train: epoch 0016, iter [00150, 01251], lr: 0.001945, loss: 3.1493
2022-10-07 00:16:33 - train: epoch 0016, iter [00160, 01251], lr: 0.001944, loss: 3.9703
2022-10-07 00:16:55 - train: epoch 0016, iter [00170, 01251], lr: 0.001944, loss: 3.9585
2022-10-07 00:17:16 - train: epoch 0016, iter [00180, 01251], lr: 0.001944, loss: 3.8942
2022-10-07 00:17:38 - train: epoch 0016, iter [00190, 01251], lr: 0.001944, loss: 4.1826
2022-10-07 00:17:59 - train: epoch 0016, iter [00200, 01251], lr: 0.001944, loss: 3.0382
2022-10-07 00:18:21 - train: epoch 0016, iter [00210, 01251], lr: 0.001944, loss: 3.7937
2022-10-07 00:18:42 - train: epoch 0016, iter [00220, 01251], lr: 0.001944, loss: 3.9629
2022-10-07 00:19:04 - train: epoch 0016, iter [00230, 01251], lr: 0.001944, loss: 4.0093
2022-10-07 00:19:25 - train: epoch 0016, iter [00240, 01251], lr: 0.001944, loss: 3.5659
2022-10-07 00:19:47 - train: epoch 0016, iter [00250, 01251], lr: 0.001944, loss: 3.9719
2022-10-07 00:20:08 - train: epoch 0016, iter [00260, 01251], lr: 0.001944, loss: 3.3042
2022-10-07 00:20:30 - train: epoch 0016, iter [00270, 01251], lr: 0.001944, loss: 3.0138
2022-10-07 00:20:51 - train: epoch 0016, iter [00280, 01251], lr: 0.001943, loss: 3.5166
2022-10-07 00:21:13 - train: epoch 0016, iter [00290, 01251], lr: 0.001943, loss: 4.2006
2022-10-07 00:21:34 - train: epoch 0016, iter [00300, 01251], lr: 0.001943, loss: 3.8633
2022-10-07 00:21:56 - train: epoch 0016, iter [00310, 01251], lr: 0.001943, loss: 3.4328
2022-10-07 00:22:17 - train: epoch 0016, iter [00320, 01251], lr: 0.001943, loss: 3.8988
2022-10-07 00:22:39 - train: epoch 0016, iter [00330, 01251], lr: 0.001943, loss: 4.3487
2022-10-07 00:23:00 - train: epoch 0016, iter [00340, 01251], lr: 0.001943, loss: 3.4151
2022-10-07 00:23:22 - train: epoch 0016, iter [00350, 01251], lr: 0.001943, loss: 3.4444
2022-10-07 00:23:43 - train: epoch 0016, iter [00360, 01251], lr: 0.001943, loss: 3.7150
2022-10-07 00:24:05 - train: epoch 0016, iter [00370, 01251], lr: 0.001943, loss: 3.5943
2022-10-07 00:24:26 - train: epoch 0016, iter [00380, 01251], lr: 0.001943, loss: 3.3748
2022-10-07 00:24:47 - train: epoch 0016, iter [00390, 01251], lr: 0.001942, loss: 3.2642
2022-10-07 00:25:09 - train: epoch 0016, iter [00400, 01251], lr: 0.001942, loss: 3.0678
2022-10-07 00:25:30 - train: epoch 0016, iter [00410, 01251], lr: 0.001942, loss: 4.1367
2022-10-07 00:25:52 - train: epoch 0016, iter [00420, 01251], lr: 0.001942, loss: 3.6662
2022-10-07 00:26:13 - train: epoch 0016, iter [00430, 01251], lr: 0.001942, loss: 3.3301
2022-10-07 00:26:35 - train: epoch 0016, iter [00440, 01251], lr: 0.001942, loss: 3.7695
2022-10-07 00:26:56 - train: epoch 0016, iter [00450, 01251], lr: 0.001942, loss: 3.9356
2022-10-07 00:27:18 - train: epoch 0016, iter [00460, 01251], lr: 0.001942, loss: 4.1121
2022-10-07 00:27:39 - train: epoch 0016, iter [00470, 01251], lr: 0.001942, loss: 4.1076
2022-10-07 00:28:01 - train: epoch 0016, iter [00480, 01251], lr: 0.001942, loss: 3.6989
2022-10-07 00:28:22 - train: epoch 0016, iter [00490, 01251], lr: 0.001942, loss: 3.9096
2022-10-07 00:28:44 - train: epoch 0016, iter [00500, 01251], lr: 0.001941, loss: 3.9479
2022-10-07 00:29:05 - train: epoch 0016, iter [00510, 01251], lr: 0.001941, loss: 3.5736
2022-10-07 00:29:27 - train: epoch 0016, iter [00520, 01251], lr: 0.001941, loss: 3.6951
2022-10-07 00:29:48 - train: epoch 0016, iter [00530, 01251], lr: 0.001941, loss: 3.5365
2022-10-07 00:30:09 - train: epoch 0016, iter [00540, 01251], lr: 0.001941, loss: 2.9715
2022-10-07 00:30:31 - train: epoch 0016, iter [00550, 01251], lr: 0.001941, loss: 3.7844
2022-10-07 00:30:52 - train: epoch 0016, iter [00560, 01251], lr: 0.001941, loss: 4.2747
2022-10-07 00:31:14 - train: epoch 0016, iter [00570, 01251], lr: 0.001941, loss: 3.3062
2022-10-07 00:31:35 - train: epoch 0016, iter [00580, 01251], lr: 0.001941, loss: 4.0018
2022-10-07 00:31:57 - train: epoch 0016, iter [00590, 01251], lr: 0.001941, loss: 3.9120
2022-10-07 00:32:18 - train: epoch 0016, iter [00600, 01251], lr: 0.001941, loss: 2.8910
2022-10-07 00:32:40 - train: epoch 0016, iter [00610, 01251], lr: 0.001940, loss: 3.6444
2022-10-07 00:33:01 - train: epoch 0016, iter [00620, 01251], lr: 0.001940, loss: 4.0963
2022-10-07 00:33:23 - train: epoch 0016, iter [00630, 01251], lr: 0.001940, loss: 3.1931
2022-10-07 00:33:44 - train: epoch 0016, iter [00640, 01251], lr: 0.001940, loss: 3.7852
2022-10-07 00:34:05 - train: epoch 0016, iter [00650, 01251], lr: 0.001940, loss: 3.8670
2022-10-07 00:34:27 - train: epoch 0016, iter [00660, 01251], lr: 0.001940, loss: 3.8619
2022-10-07 00:34:48 - train: epoch 0016, iter [00670, 01251], lr: 0.001940, loss: 3.8873
2022-10-07 00:35:10 - train: epoch 0016, iter [00680, 01251], lr: 0.001940, loss: 3.2499
2022-10-07 00:35:31 - train: epoch 0016, iter [00690, 01251], lr: 0.001940, loss: 3.9324
2022-10-07 00:35:53 - train: epoch 0016, iter [00700, 01251], lr: 0.001940, loss: 3.3194
2022-10-07 00:36:14 - train: epoch 0016, iter [00710, 01251], lr: 0.001940, loss: 3.4873
2022-10-07 00:36:35 - train: epoch 0016, iter [00720, 01251], lr: 0.001939, loss: 2.9014
2022-10-07 00:36:57 - train: epoch 0016, iter [00730, 01251], lr: 0.001939, loss: 3.6465
2022-10-07 00:37:18 - train: epoch 0016, iter [00740, 01251], lr: 0.001939, loss: 3.1459
2022-10-07 00:37:39 - train: epoch 0016, iter [00750, 01251], lr: 0.001939, loss: 3.9634
2022-10-07 00:38:01 - train: epoch 0016, iter [00760, 01251], lr: 0.001939, loss: 3.0255
2022-10-07 00:38:22 - train: epoch 0016, iter [00770, 01251], lr: 0.001939, loss: 3.3837
2022-10-07 00:38:44 - train: epoch 0016, iter [00780, 01251], lr: 0.001939, loss: 4.1992
2022-10-07 00:39:05 - train: epoch 0016, iter [00790, 01251], lr: 0.001939, loss: 3.5175
2022-10-07 00:39:27 - train: epoch 0016, iter [00800, 01251], lr: 0.001939, loss: 4.2292
2022-10-07 00:39:48 - train: epoch 0016, iter [00810, 01251], lr: 0.001939, loss: 3.1268
2022-10-07 00:40:09 - train: epoch 0016, iter [00820, 01251], lr: 0.001939, loss: 3.9713
2022-10-07 00:40:31 - train: epoch 0016, iter [00830, 01251], lr: 0.001938, loss: 4.0693
2022-10-07 00:40:52 - train: epoch 0016, iter [00840, 01251], lr: 0.001938, loss: 3.3726
2022-10-07 00:41:13 - train: epoch 0016, iter [00850, 01251], lr: 0.001938, loss: 3.0346
2022-10-07 00:41:35 - train: epoch 0016, iter [00860, 01251], lr: 0.001938, loss: 3.9086
2022-10-07 00:41:56 - train: epoch 0016, iter [00870, 01251], lr: 0.001938, loss: 3.2497
2022-10-07 00:42:17 - train: epoch 0016, iter [00880, 01251], lr: 0.001938, loss: 3.4959
2022-10-07 00:42:39 - train: epoch 0016, iter [00890, 01251], lr: 0.001938, loss: 3.9202
2022-10-07 00:43:00 - train: epoch 0016, iter [00900, 01251], lr: 0.001938, loss: 3.9223
2022-10-07 00:43:22 - train: epoch 0016, iter [00910, 01251], lr: 0.001938, loss: 3.2392
2022-10-07 00:43:43 - train: epoch 0016, iter [00920, 01251], lr: 0.001938, loss: 3.7322
2022-10-07 00:44:04 - train: epoch 0016, iter [00930, 01251], lr: 0.001938, loss: 3.9587
2022-10-07 00:44:26 - train: epoch 0016, iter [00940, 01251], lr: 0.001937, loss: 3.6637
2022-10-07 00:44:47 - train: epoch 0016, iter [00950, 01251], lr: 0.001937, loss: 3.8115
2022-10-07 00:45:09 - train: epoch 0016, iter [00960, 01251], lr: 0.001937, loss: 3.7639
2022-10-07 00:45:30 - train: epoch 0016, iter [00970, 01251], lr: 0.001937, loss: 4.1690
2022-10-07 00:45:51 - train: epoch 0016, iter [00980, 01251], lr: 0.001937, loss: 4.2514
2022-10-07 00:46:13 - train: epoch 0016, iter [00990, 01251], lr: 0.001937, loss: 3.1387
2022-10-07 00:46:34 - train: epoch 0016, iter [01000, 01251], lr: 0.001937, loss: 3.0215
2022-10-07 00:46:55 - train: epoch 0016, iter [01010, 01251], lr: 0.001937, loss: 2.8525
2022-10-07 00:47:17 - train: epoch 0016, iter [01020, 01251], lr: 0.001937, loss: 3.7929
2022-10-07 00:47:38 - train: epoch 0016, iter [01030, 01251], lr: 0.001937, loss: 3.1503
2022-10-07 00:48:00 - train: epoch 0016, iter [01040, 01251], lr: 0.001937, loss: 3.5921
2022-10-07 00:48:21 - train: epoch 0016, iter [01050, 01251], lr: 0.001936, loss: 3.6309
2022-10-07 00:48:42 - train: epoch 0016, iter [01060, 01251], lr: 0.001936, loss: 3.5014
2022-10-07 00:49:04 - train: epoch 0016, iter [01070, 01251], lr: 0.001936, loss: 3.0212
2022-10-07 00:49:25 - train: epoch 0016, iter [01080, 01251], lr: 0.001936, loss: 3.2607
2022-10-07 00:49:47 - train: epoch 0016, iter [01090, 01251], lr: 0.001936, loss: 3.9995
2022-10-07 00:50:08 - train: epoch 0016, iter [01100, 01251], lr: 0.001936, loss: 3.7940
2022-10-07 00:50:29 - train: epoch 0016, iter [01110, 01251], lr: 0.001936, loss: 3.9224
2022-10-07 00:50:51 - train: epoch 0016, iter [01120, 01251], lr: 0.001936, loss: 3.2836
2022-10-07 00:51:12 - train: epoch 0016, iter [01130, 01251], lr: 0.001936, loss: 3.5460
2022-10-07 00:51:34 - train: epoch 0016, iter [01140, 01251], lr: 0.001936, loss: 3.4420
2022-10-07 00:51:55 - train: epoch 0016, iter [01150, 01251], lr: 0.001936, loss: 3.1666
2022-10-07 00:52:17 - train: epoch 0016, iter [01160, 01251], lr: 0.001935, loss: 3.6469
2022-10-07 00:52:38 - train: epoch 0016, iter [01170, 01251], lr: 0.001935, loss: 3.7262
2022-10-07 00:53:00 - train: epoch 0016, iter [01180, 01251], lr: 0.001935, loss: 3.4037
2022-10-07 00:53:21 - train: epoch 0016, iter [01190, 01251], lr: 0.001935, loss: 3.0448
2022-10-07 00:53:43 - train: epoch 0016, iter [01200, 01251], lr: 0.001935, loss: 3.7452
2022-10-07 00:54:04 - train: epoch 0016, iter [01210, 01251], lr: 0.001935, loss: 2.9492
2022-10-07 00:54:26 - train: epoch 0016, iter [01220, 01251], lr: 0.001935, loss: 4.0945
2022-10-07 00:54:47 - train: epoch 0016, iter [01230, 01251], lr: 0.001935, loss: 3.5564
2022-10-07 00:55:08 - train: epoch 0016, iter [01240, 01251], lr: 0.001935, loss: 3.6391
2022-10-07 00:55:30 - train: epoch 0016, iter [01250, 01251], lr: 0.001935, loss: 2.5733
2022-10-07 00:55:33 - train: epoch 016, train_loss: 3.5880
2022-10-07 00:56:51 - eval: epoch: 016, acc1: 76.040%, acc5: 93.504%, test_loss: 1.0272, per_image_load_time: 0.661ms, per_image_inference_time: 1.406ms
2022-10-07 00:56:53 - until epoch: 016, best_acc1: 76.040%
2022-10-07 00:56:53 - epoch 017 lr: 0.001935
2022-10-07 00:57:21 - train: epoch 0017, iter [00010, 01251], lr: 0.001935, loss: 3.3841
2022-10-07 00:57:43 - train: epoch 0017, iter [00020, 01251], lr: 0.001934, loss: 3.4150
2022-10-07 00:58:04 - train: epoch 0017, iter [00030, 01251], lr: 0.001934, loss: 3.8055
2022-10-07 00:58:26 - train: epoch 0017, iter [00040, 01251], lr: 0.001934, loss: 3.3074
2022-10-07 00:58:47 - train: epoch 0017, iter [00050, 01251], lr: 0.001934, loss: 3.6771
2022-10-07 00:59:09 - train: epoch 0017, iter [00060, 01251], lr: 0.001934, loss: 3.9644
2022-10-07 00:59:30 - train: epoch 0017, iter [00070, 01251], lr: 0.001934, loss: 3.1389
2022-10-07 00:59:52 - train: epoch 0017, iter [00080, 01251], lr: 0.001934, loss: 3.5037
2022-10-07 01:00:13 - train: epoch 0017, iter [00090, 01251], lr: 0.001934, loss: 3.9618
2022-10-07 01:00:34 - train: epoch 0017, iter [00100, 01251], lr: 0.001934, loss: 3.5051
2022-10-07 01:00:56 - train: epoch 0017, iter [00110, 01251], lr: 0.001934, loss: 3.4119
2022-10-07 01:01:17 - train: epoch 0017, iter [00120, 01251], lr: 0.001933, loss: 3.5505
2022-10-07 01:01:39 - train: epoch 0017, iter [00130, 01251], lr: 0.001933, loss: 3.2681
2022-10-07 01:02:00 - train: epoch 0017, iter [00140, 01251], lr: 0.001933, loss: 3.3162
2022-10-07 01:02:21 - train: epoch 0017, iter [00150, 01251], lr: 0.001933, loss: 4.3514
2022-10-07 01:02:43 - train: epoch 0017, iter [00160, 01251], lr: 0.001933, loss: 3.7709
2022-10-07 01:03:04 - train: epoch 0017, iter [00170, 01251], lr: 0.001933, loss: 3.9893
2022-10-07 01:03:26 - train: epoch 0017, iter [00180, 01251], lr: 0.001933, loss: 3.1336
2022-10-07 01:03:47 - train: epoch 0017, iter [00190, 01251], lr: 0.001933, loss: 3.4534
2022-10-07 01:04:09 - train: epoch 0017, iter [00200, 01251], lr: 0.001933, loss: 4.0228
2022-10-07 01:04:30 - train: epoch 0017, iter [00210, 01251], lr: 0.001933, loss: 3.7303
2022-10-07 01:04:51 - train: epoch 0017, iter [00220, 01251], lr: 0.001933, loss: 3.7247
2022-10-07 01:05:13 - train: epoch 0017, iter [00230, 01251], lr: 0.001932, loss: 3.8808
2022-10-07 01:05:34 - train: epoch 0017, iter [00240, 01251], lr: 0.001932, loss: 3.6860
2022-10-07 01:05:55 - train: epoch 0017, iter [00250, 01251], lr: 0.001932, loss: 3.3714
2022-10-07 01:06:17 - train: epoch 0017, iter [00260, 01251], lr: 0.001932, loss: 3.5837
2022-10-07 01:06:38 - train: epoch 0017, iter [00270, 01251], lr: 0.001932, loss: 3.0295
2022-10-07 01:06:59 - train: epoch 0017, iter [00280, 01251], lr: 0.001932, loss: 3.4150
2022-10-07 01:07:21 - train: epoch 0017, iter [00290, 01251], lr: 0.001932, loss: 3.9206
2022-10-07 01:07:42 - train: epoch 0017, iter [00300, 01251], lr: 0.001932, loss: 3.6550
2022-10-07 01:08:03 - train: epoch 0017, iter [00310, 01251], lr: 0.001932, loss: 3.1524
2022-10-07 01:08:25 - train: epoch 0017, iter [00320, 01251], lr: 0.001932, loss: 3.6829
2022-10-07 01:08:46 - train: epoch 0017, iter [00330, 01251], lr: 0.001931, loss: 2.4566
2022-10-07 01:09:08 - train: epoch 0017, iter [00340, 01251], lr: 0.001931, loss: 3.3574
2022-10-07 01:09:29 - train: epoch 0017, iter [00350, 01251], lr: 0.001931, loss: 3.9314
2022-10-07 01:09:51 - train: epoch 0017, iter [00360, 01251], lr: 0.001931, loss: 3.4753
2022-10-07 01:10:12 - train: epoch 0017, iter [00370, 01251], lr: 0.001931, loss: 4.2096
2022-10-07 01:10:33 - train: epoch 0017, iter [00380, 01251], lr: 0.001931, loss: 2.9087
2022-10-07 01:10:55 - train: epoch 0017, iter [00390, 01251], lr: 0.001931, loss: 3.5070
2022-10-07 01:11:16 - train: epoch 0017, iter [00400, 01251], lr: 0.001931, loss: 3.3638
2022-10-07 01:11:37 - train: epoch 0017, iter [00410, 01251], lr: 0.001931, loss: 3.6635
2022-10-07 01:11:59 - train: epoch 0017, iter [00420, 01251], lr: 0.001931, loss: 3.6917
2022-10-07 01:12:20 - train: epoch 0017, iter [00430, 01251], lr: 0.001930, loss: 3.0738
2022-10-07 01:12:42 - train: epoch 0017, iter [00440, 01251], lr: 0.001930, loss: 3.6613
2022-10-07 01:13:03 - train: epoch 0017, iter [00450, 01251], lr: 0.001930, loss: 3.1191
2022-10-07 01:13:24 - train: epoch 0017, iter [00460, 01251], lr: 0.001930, loss: 3.3915
2022-10-07 01:13:46 - train: epoch 0017, iter [00470, 01251], lr: 0.001930, loss: 3.2414
2022-10-07 01:14:07 - train: epoch 0017, iter [00480, 01251], lr: 0.001930, loss: 3.5406
2022-10-07 01:14:29 - train: epoch 0017, iter [00490, 01251], lr: 0.001930, loss: 3.9057
2022-10-07 01:14:50 - train: epoch 0017, iter [00500, 01251], lr: 0.001930, loss: 3.3266
2022-10-07 01:15:12 - train: epoch 0017, iter [00510, 01251], lr: 0.001930, loss: 3.0960
2022-10-07 01:15:33 - train: epoch 0017, iter [00520, 01251], lr: 0.001930, loss: 3.0614
2022-10-07 01:15:54 - train: epoch 0017, iter [00530, 01251], lr: 0.001930, loss: 3.6656
2022-10-07 01:16:16 - train: epoch 0017, iter [00540, 01251], lr: 0.001929, loss: 3.9775
2022-10-07 01:16:37 - train: epoch 0017, iter [00550, 01251], lr: 0.001929, loss: 3.7891
2022-10-07 01:16:58 - train: epoch 0017, iter [00560, 01251], lr: 0.001929, loss: 3.9746
2022-10-07 01:17:20 - train: epoch 0017, iter [00570, 01251], lr: 0.001929, loss: 3.7243
2022-10-07 01:17:41 - train: epoch 0017, iter [00580, 01251], lr: 0.001929, loss: 3.2207
2022-10-07 01:18:02 - train: epoch 0017, iter [00590, 01251], lr: 0.001929, loss: 3.9284
2022-10-07 01:18:24 - train: epoch 0017, iter [00600, 01251], lr: 0.001929, loss: 2.9988
2022-10-07 01:18:45 - train: epoch 0017, iter [00610, 01251], lr: 0.001929, loss: 3.8604
2022-10-07 01:19:07 - train: epoch 0017, iter [00620, 01251], lr: 0.001929, loss: 3.5413
2022-10-07 01:19:28 - train: epoch 0017, iter [00630, 01251], lr: 0.001929, loss: 4.0083
2022-10-07 01:19:49 - train: epoch 0017, iter [00640, 01251], lr: 0.001928, loss: 3.3543
2022-10-07 01:20:11 - train: epoch 0017, iter [00650, 01251], lr: 0.001928, loss: 3.5084
2022-10-07 01:20:32 - train: epoch 0017, iter [00660, 01251], lr: 0.001928, loss: 3.5806
2022-10-07 01:20:54 - train: epoch 0017, iter [00670, 01251], lr: 0.001928, loss: 3.7191
2022-10-07 01:21:15 - train: epoch 0017, iter [00680, 01251], lr: 0.001928, loss: 3.9497
2022-10-07 01:21:36 - train: epoch 0017, iter [00690, 01251], lr: 0.001928, loss: 3.6386
2022-10-07 01:21:58 - train: epoch 0017, iter [00700, 01251], lr: 0.001928, loss: 3.7107
2022-10-07 01:22:19 - train: epoch 0017, iter [00710, 01251], lr: 0.001928, loss: 3.2033
2022-10-07 01:22:40 - train: epoch 0017, iter [00720, 01251], lr: 0.001928, loss: 3.8252
2022-10-07 01:23:02 - train: epoch 0017, iter [00730, 01251], lr: 0.001928, loss: 4.0536
2022-10-07 01:23:23 - train: epoch 0017, iter [00740, 01251], lr: 0.001927, loss: 4.1697
2022-10-07 01:23:45 - train: epoch 0017, iter [00750, 01251], lr: 0.001927, loss: 3.8819
2022-10-07 01:24:06 - train: epoch 0017, iter [00760, 01251], lr: 0.001927, loss: 4.0178
2022-10-07 01:24:27 - train: epoch 0017, iter [00770, 01251], lr: 0.001927, loss: 3.5070
2022-10-07 01:24:49 - train: epoch 0017, iter [00780, 01251], lr: 0.001927, loss: 3.8178
2022-10-07 01:25:10 - train: epoch 0017, iter [00790, 01251], lr: 0.001927, loss: 4.0853
2022-10-07 01:25:31 - train: epoch 0017, iter [00800, 01251], lr: 0.001927, loss: 3.3547
2022-10-07 01:25:53 - train: epoch 0017, iter [00810, 01251], lr: 0.001927, loss: 3.2646
2022-10-07 01:26:14 - train: epoch 0017, iter [00820, 01251], lr: 0.001927, loss: 4.1028
2022-10-07 01:26:35 - train: epoch 0017, iter [00830, 01251], lr: 0.001927, loss: 3.7606
2022-10-07 01:26:57 - train: epoch 0017, iter [00840, 01251], lr: 0.001926, loss: 3.3333
2022-10-07 01:27:18 - train: epoch 0017, iter [00850, 01251], lr: 0.001926, loss: 3.2559
2022-10-07 01:27:40 - train: epoch 0017, iter [00860, 01251], lr: 0.001926, loss: 3.5135
2022-10-07 01:28:01 - train: epoch 0017, iter [00870, 01251], lr: 0.001926, loss: 3.5172
2022-10-07 01:28:22 - train: epoch 0017, iter [00880, 01251], lr: 0.001926, loss: 3.0903
2022-10-07 01:28:44 - train: epoch 0017, iter [00890, 01251], lr: 0.001926, loss: 4.0831
2022-10-07 01:29:05 - train: epoch 0017, iter [00900, 01251], lr: 0.001926, loss: 3.8445
2022-10-07 01:29:27 - train: epoch 0017, iter [00910, 01251], lr: 0.001926, loss: 2.8421
2022-10-07 01:29:48 - train: epoch 0017, iter [00920, 01251], lr: 0.001926, loss: 3.6218
2022-10-07 01:30:09 - train: epoch 0017, iter [00930, 01251], lr: 0.001926, loss: 2.9108
2022-10-07 01:30:30 - train: epoch 0017, iter [00940, 01251], lr: 0.001925, loss: 3.6366
2022-10-07 01:30:52 - train: epoch 0017, iter [00950, 01251], lr: 0.001925, loss: 3.8885
2022-10-07 01:31:13 - train: epoch 0017, iter [00960, 01251], lr: 0.001925, loss: 3.4106
2022-10-07 01:31:35 - train: epoch 0017, iter [00970, 01251], lr: 0.001925, loss: 3.5056
2022-10-07 01:31:56 - train: epoch 0017, iter [00980, 01251], lr: 0.001925, loss: 3.5998
2022-10-07 01:32:18 - train: epoch 0017, iter [00990, 01251], lr: 0.001925, loss: 3.5720
2022-10-07 01:32:39 - train: epoch 0017, iter [01000, 01251], lr: 0.001925, loss: 3.1322
2022-10-07 01:33:00 - train: epoch 0017, iter [01010, 01251], lr: 0.001925, loss: 3.3645
2022-10-07 01:33:21 - train: epoch 0017, iter [01020, 01251], lr: 0.001925, loss: 3.8423
2022-10-07 01:33:43 - train: epoch 0017, iter [01030, 01251], lr: 0.001925, loss: 3.3817
2022-10-07 01:34:04 - train: epoch 0017, iter [01040, 01251], lr: 0.001924, loss: 3.6793
2022-10-07 01:34:25 - train: epoch 0017, iter [01050, 01251], lr: 0.001924, loss: 3.8436
2022-10-07 01:34:47 - train: epoch 0017, iter [01060, 01251], lr: 0.001924, loss: 3.9907
2022-10-07 01:35:08 - train: epoch 0017, iter [01070, 01251], lr: 0.001924, loss: 3.2993
2022-10-07 01:35:29 - train: epoch 0017, iter [01080, 01251], lr: 0.001924, loss: 3.1316
2022-10-07 01:35:51 - train: epoch 0017, iter [01090, 01251], lr: 0.001924, loss: 3.3262
2022-10-07 01:36:12 - train: epoch 0017, iter [01100, 01251], lr: 0.001924, loss: 3.5932
2022-10-07 01:36:34 - train: epoch 0017, iter [01110, 01251], lr: 0.001924, loss: 3.2985
2022-10-07 01:36:55 - train: epoch 0017, iter [01120, 01251], lr: 0.001924, loss: 3.6150
2022-10-07 01:37:16 - train: epoch 0017, iter [01130, 01251], lr: 0.001924, loss: 3.0888
2022-10-07 01:37:38 - train: epoch 0017, iter [01140, 01251], lr: 0.001923, loss: 3.5872
2022-10-07 01:37:59 - train: epoch 0017, iter [01150, 01251], lr: 0.001923, loss: 3.8231
2022-10-07 01:38:20 - train: epoch 0017, iter [01160, 01251], lr: 0.001923, loss: 3.5333
2022-10-07 01:38:41 - train: epoch 0017, iter [01170, 01251], lr: 0.001923, loss: 3.1738
2022-10-07 01:39:03 - train: epoch 0017, iter [01180, 01251], lr: 0.001923, loss: 3.7790
2022-10-07 01:39:24 - train: epoch 0017, iter [01190, 01251], lr: 0.001923, loss: 3.9876
2022-10-07 01:39:45 - train: epoch 0017, iter [01200, 01251], lr: 0.001923, loss: 3.3181
2022-10-07 01:40:07 - train: epoch 0017, iter [01210, 01251], lr: 0.001923, loss: 4.0832
2022-10-07 01:40:28 - train: epoch 0017, iter [01220, 01251], lr: 0.001923, loss: 3.5641
2022-10-07 01:40:49 - train: epoch 0017, iter [01230, 01251], lr: 0.001923, loss: 3.9243
2022-10-07 01:41:10 - train: epoch 0017, iter [01240, 01251], lr: 0.001922, loss: 3.9938
2022-10-07 01:41:32 - train: epoch 0017, iter [01250, 01251], lr: 0.001922, loss: 3.3263
2022-10-07 01:41:35 - train: epoch 017, train_loss: 3.5660
2022-10-07 01:42:52 - eval: epoch: 017, acc1: 76.148%, acc5: 93.730%, test_loss: 1.0337, per_image_load_time: 0.219ms, per_image_inference_time: 1.432ms
2022-10-07 01:42:53 - until epoch: 017, best_acc1: 76.148%
2022-10-07 01:42:53 - epoch 018 lr: 0.001922
2022-10-07 01:43:22 - train: epoch 0018, iter [00010, 01251], lr: 0.001922, loss: 3.2901
2022-10-07 01:43:43 - train: epoch 0018, iter [00020, 01251], lr: 0.001922, loss: 3.8164
2022-10-07 01:44:05 - train: epoch 0018, iter [00030, 01251], lr: 0.001922, loss: 3.8414
2022-10-07 01:44:26 - train: epoch 0018, iter [00040, 01251], lr: 0.001922, loss: 3.4161
2022-10-07 01:44:48 - train: epoch 0018, iter [00050, 01251], lr: 0.001922, loss: 3.5343
2022-10-07 01:45:09 - train: epoch 0018, iter [00060, 01251], lr: 0.001922, loss: 3.5395
2022-10-07 01:45:30 - train: epoch 0018, iter [00070, 01251], lr: 0.001922, loss: 3.4247
2022-10-07 01:45:51 - train: epoch 0018, iter [00080, 01251], lr: 0.001922, loss: 3.8784
2022-10-07 01:46:13 - train: epoch 0018, iter [00090, 01251], lr: 0.001921, loss: 3.7207
2022-10-07 01:46:34 - train: epoch 0018, iter [00100, 01251], lr: 0.001921, loss: 3.5537
2022-10-07 01:46:55 - train: epoch 0018, iter [00110, 01251], lr: 0.001921, loss: 3.7558
2022-10-07 01:47:16 - train: epoch 0018, iter [00120, 01251], lr: 0.001921, loss: 3.5999
2022-10-07 01:47:37 - train: epoch 0018, iter [00130, 01251], lr: 0.001921, loss: 3.0191
2022-10-07 01:47:58 - train: epoch 0018, iter [00140, 01251], lr: 0.001921, loss: 3.2495
2022-10-07 01:48:20 - train: epoch 0018, iter [00150, 01251], lr: 0.001921, loss: 3.8832
2022-10-07 01:48:41 - train: epoch 0018, iter [00160, 01251], lr: 0.001921, loss: 3.4196
2022-10-07 01:49:02 - train: epoch 0018, iter [00170, 01251], lr: 0.001921, loss: 3.3736
2022-10-07 01:49:24 - train: epoch 0018, iter [00180, 01251], lr: 0.001920, loss: 4.1513
2022-10-07 01:49:45 - train: epoch 0018, iter [00190, 01251], lr: 0.001920, loss: 2.7472
2022-10-07 01:50:06 - train: epoch 0018, iter [00200, 01251], lr: 0.001920, loss: 3.8576
2022-10-07 01:50:27 - train: epoch 0018, iter [00210, 01251], lr: 0.001920, loss: 4.0479
2022-10-07 01:50:49 - train: epoch 0018, iter [00220, 01251], lr: 0.001920, loss: 3.7928
2022-10-07 01:51:10 - train: epoch 0018, iter [00230, 01251], lr: 0.001920, loss: 3.8085
2022-10-07 01:51:31 - train: epoch 0018, iter [00240, 01251], lr: 0.001920, loss: 3.6409
2022-10-07 01:51:52 - train: epoch 0018, iter [00250, 01251], lr: 0.001920, loss: 3.8897
2022-10-07 01:52:14 - train: epoch 0018, iter [00260, 01251], lr: 0.001920, loss: 3.1030
2022-10-07 01:52:35 - train: epoch 0018, iter [00270, 01251], lr: 0.001920, loss: 3.8236
2022-10-07 01:52:56 - train: epoch 0018, iter [00280, 01251], lr: 0.001919, loss: 2.8579
2022-10-07 01:53:17 - train: epoch 0018, iter [00290, 01251], lr: 0.001919, loss: 3.6774
2022-10-07 01:53:39 - train: epoch 0018, iter [00300, 01251], lr: 0.001919, loss: 3.3255
2022-10-07 01:54:00 - train: epoch 0018, iter [00310, 01251], lr: 0.001919, loss: 3.7019
2022-10-07 01:54:21 - train: epoch 0018, iter [00320, 01251], lr: 0.001919, loss: 3.3020
2022-10-07 01:54:42 - train: epoch 0018, iter [00330, 01251], lr: 0.001919, loss: 3.1947
2022-10-07 01:55:03 - train: epoch 0018, iter [00340, 01251], lr: 0.001919, loss: 4.0983
2022-10-07 01:55:24 - train: epoch 0018, iter [00350, 01251], lr: 0.001919, loss: 3.3723
2022-10-07 01:55:46 - train: epoch 0018, iter [00360, 01251], lr: 0.001919, loss: 4.0006
2022-10-07 01:56:07 - train: epoch 0018, iter [00370, 01251], lr: 0.001919, loss: 3.1231
2022-10-07 01:56:28 - train: epoch 0018, iter [00380, 01251], lr: 0.001918, loss: 3.2649
2022-10-07 01:56:50 - train: epoch 0018, iter [00390, 01251], lr: 0.001918, loss: 3.0795
2022-10-07 01:57:11 - train: epoch 0018, iter [00400, 01251], lr: 0.001918, loss: 3.8938
2022-10-07 01:57:32 - train: epoch 0018, iter [00410, 01251], lr: 0.001918, loss: 3.5676
2022-10-07 01:57:53 - train: epoch 0018, iter [00420, 01251], lr: 0.001918, loss: 3.6397
2022-10-07 01:58:15 - train: epoch 0018, iter [00430, 01251], lr: 0.001918, loss: 3.6160
2022-10-07 01:58:36 - train: epoch 0018, iter [00440, 01251], lr: 0.001918, loss: 2.6985
2022-10-07 01:58:57 - train: epoch 0018, iter [00450, 01251], lr: 0.001918, loss: 3.0063
2022-10-07 01:59:18 - train: epoch 0018, iter [00460, 01251], lr: 0.001918, loss: 3.5687
2022-10-07 01:59:40 - train: epoch 0018, iter [00470, 01251], lr: 0.001917, loss: 3.8147
2022-10-07 02:00:01 - train: epoch 0018, iter [00480, 01251], lr: 0.001917, loss: 3.9167
2022-10-07 02:00:22 - train: epoch 0018, iter [00490, 01251], lr: 0.001917, loss: 3.5038
2022-10-07 02:00:43 - train: epoch 0018, iter [00500, 01251], lr: 0.001917, loss: 3.6054
2022-10-07 02:01:04 - train: epoch 0018, iter [00510, 01251], lr: 0.001917, loss: 3.3027
2022-10-07 02:01:26 - train: epoch 0018, iter [00520, 01251], lr: 0.001917, loss: 2.8571
2022-10-07 02:01:47 - train: epoch 0018, iter [00530, 01251], lr: 0.001917, loss: 2.9720
2022-10-07 02:02:08 - train: epoch 0018, iter [00540, 01251], lr: 0.001917, loss: 3.5687
2022-10-07 02:02:29 - train: epoch 0018, iter [00550, 01251], lr: 0.001917, loss: 3.2743
2022-10-07 02:02:50 - train: epoch 0018, iter [00560, 01251], lr: 0.001917, loss: 3.9180
2022-10-07 02:03:12 - train: epoch 0018, iter [00570, 01251], lr: 0.001916, loss: 4.0474
2022-10-07 02:03:33 - train: epoch 0018, iter [00580, 01251], lr: 0.001916, loss: 3.3518
2022-10-07 02:03:54 - train: epoch 0018, iter [00590, 01251], lr: 0.001916, loss: 3.4725
2022-10-07 02:04:16 - train: epoch 0018, iter [00600, 01251], lr: 0.001916, loss: 3.0493
2022-10-07 02:04:37 - train: epoch 0018, iter [00610, 01251], lr: 0.001916, loss: 3.6846
2022-10-07 02:04:58 - train: epoch 0018, iter [00620, 01251], lr: 0.001916, loss: 3.7853
2022-10-07 02:05:19 - train: epoch 0018, iter [00630, 01251], lr: 0.001916, loss: 3.3129
2022-10-07 02:05:41 - train: epoch 0018, iter [00640, 01251], lr: 0.001916, loss: 3.6296
2022-10-07 02:06:02 - train: epoch 0018, iter [00650, 01251], lr: 0.001916, loss: 3.2917
2022-10-07 02:06:23 - train: epoch 0018, iter [00660, 01251], lr: 0.001915, loss: 3.7951
2022-10-07 02:06:44 - train: epoch 0018, iter [00670, 01251], lr: 0.001915, loss: 3.2215
2022-10-07 02:07:05 - train: epoch 0018, iter [00680, 01251], lr: 0.001915, loss: 3.5731
2022-10-07 02:07:27 - train: epoch 0018, iter [00690, 01251], lr: 0.001915, loss: 3.1330
2022-10-07 02:07:48 - train: epoch 0018, iter [00700, 01251], lr: 0.001915, loss: 3.1460
2022-10-07 02:08:09 - train: epoch 0018, iter [00710, 01251], lr: 0.001915, loss: 3.8771
2022-10-07 02:08:31 - train: epoch 0018, iter [00720, 01251], lr: 0.001915, loss: 3.4314
2022-10-07 02:08:52 - train: epoch 0018, iter [00730, 01251], lr: 0.001915, loss: 2.8991
2022-10-07 02:09:13 - train: epoch 0018, iter [00740, 01251], lr: 0.001915, loss: 3.9467
2022-10-07 02:09:34 - train: epoch 0018, iter [00750, 01251], lr: 0.001914, loss: 3.7693
2022-10-07 02:09:56 - train: epoch 0018, iter [00760, 01251], lr: 0.001914, loss: 3.4801
2022-10-07 02:10:17 - train: epoch 0018, iter [00770, 01251], lr: 0.001914, loss: 3.7887
2022-10-07 02:10:38 - train: epoch 0018, iter [00780, 01251], lr: 0.001914, loss: 4.0291
2022-10-07 02:10:59 - train: epoch 0018, iter [00790, 01251], lr: 0.001914, loss: 3.1353
2022-10-07 02:11:21 - train: epoch 0018, iter [00800, 01251], lr: 0.001914, loss: 3.7198
2022-10-07 02:11:42 - train: epoch 0018, iter [00810, 01251], lr: 0.001914, loss: 3.2139
2022-10-07 02:12:03 - train: epoch 0018, iter [00820, 01251], lr: 0.001914, loss: 3.4038
2022-10-07 02:12:25 - train: epoch 0018, iter [00830, 01251], lr: 0.001914, loss: 3.8613
2022-10-07 02:12:46 - train: epoch 0018, iter [00840, 01251], lr: 0.001914, loss: 3.2741
2022-10-07 02:13:07 - train: epoch 0018, iter [00850, 01251], lr: 0.001913, loss: 3.1125
2022-10-07 02:13:29 - train: epoch 0018, iter [00860, 01251], lr: 0.001913, loss: 3.1043
2022-10-07 02:13:50 - train: epoch 0018, iter [00870, 01251], lr: 0.001913, loss: 3.3021
2022-10-07 02:14:11 - train: epoch 0018, iter [00880, 01251], lr: 0.001913, loss: 3.4881
2022-10-07 02:14:33 - train: epoch 0018, iter [00890, 01251], lr: 0.001913, loss: 3.8309
2022-10-07 02:14:54 - train: epoch 0018, iter [00900, 01251], lr: 0.001913, loss: 3.8535
2022-10-07 02:15:15 - train: epoch 0018, iter [00910, 01251], lr: 0.001913, loss: 3.8310
2022-10-07 02:15:36 - train: epoch 0018, iter [00920, 01251], lr: 0.001913, loss: 3.2048
2022-10-07 02:15:57 - train: epoch 0018, iter [00930, 01251], lr: 0.001913, loss: 3.2447
2022-10-07 02:16:19 - train: epoch 0018, iter [00940, 01251], lr: 0.001912, loss: 3.4277
2022-10-07 02:16:40 - train: epoch 0018, iter [00950, 01251], lr: 0.001912, loss: 3.7058
2022-10-07 02:17:01 - train: epoch 0018, iter [00960, 01251], lr: 0.001912, loss: 3.4825
2022-10-07 02:17:22 - train: epoch 0018, iter [00970, 01251], lr: 0.001912, loss: 3.5988
2022-10-07 02:17:43 - train: epoch 0018, iter [00980, 01251], lr: 0.001912, loss: 2.7865
2022-10-07 02:18:05 - train: epoch 0018, iter [00990, 01251], lr: 0.001912, loss: 3.2445
2022-10-07 02:18:26 - train: epoch 0018, iter [01000, 01251], lr: 0.001912, loss: 3.0183
2022-10-07 02:18:47 - train: epoch 0018, iter [01010, 01251], lr: 0.001912, loss: 3.4916
2022-10-07 02:19:08 - train: epoch 0018, iter [01020, 01251], lr: 0.001912, loss: 2.7395
2022-10-07 02:19:30 - train: epoch 0018, iter [01030, 01251], lr: 0.001911, loss: 4.0803
2022-10-07 02:19:51 - train: epoch 0018, iter [01040, 01251], lr: 0.001911, loss: 3.9899
2022-10-07 02:20:12 - train: epoch 0018, iter [01050, 01251], lr: 0.001911, loss: 3.7753
2022-10-07 02:20:33 - train: epoch 0018, iter [01060, 01251], lr: 0.001911, loss: 3.3345
2022-10-07 02:20:54 - train: epoch 0018, iter [01070, 01251], lr: 0.001911, loss: 3.8906
2022-10-07 02:21:16 - train: epoch 0018, iter [01080, 01251], lr: 0.001911, loss: 3.9656
2022-10-07 02:21:37 - train: epoch 0018, iter [01090, 01251], lr: 0.001911, loss: 2.9536
2022-10-07 02:21:58 - train: epoch 0018, iter [01100, 01251], lr: 0.001911, loss: 3.7021
2022-10-07 02:22:19 - train: epoch 0018, iter [01110, 01251], lr: 0.001911, loss: 3.2208
2022-10-07 02:22:40 - train: epoch 0018, iter [01120, 01251], lr: 0.001910, loss: 4.0495
2022-10-07 02:23:02 - train: epoch 0018, iter [01130, 01251], lr: 0.001910, loss: 3.0954
2022-10-07 02:23:23 - train: epoch 0018, iter [01140, 01251], lr: 0.001910, loss: 3.0582
2022-10-07 02:23:44 - train: epoch 0018, iter [01150, 01251], lr: 0.001910, loss: 3.1717
2022-10-07 02:24:05 - train: epoch 0018, iter [01160, 01251], lr: 0.001910, loss: 3.9573
2022-10-07 02:24:26 - train: epoch 0018, iter [01170, 01251], lr: 0.001910, loss: 3.7118
2022-10-07 02:24:48 - train: epoch 0018, iter [01180, 01251], lr: 0.001910, loss: 3.5174
2022-10-07 02:25:09 - train: epoch 0018, iter [01190, 01251], lr: 0.001910, loss: 3.8080
2022-10-07 02:25:30 - train: epoch 0018, iter [01200, 01251], lr: 0.001910, loss: 2.9785
2022-10-07 02:25:52 - train: epoch 0018, iter [01210, 01251], lr: 0.001910, loss: 3.4908
2022-10-07 02:26:13 - train: epoch 0018, iter [01220, 01251], lr: 0.001909, loss: 4.1312
2022-10-07 02:26:34 - train: epoch 0018, iter [01230, 01251], lr: 0.001909, loss: 3.5392
2022-10-07 02:26:55 - train: epoch 0018, iter [01240, 01251], lr: 0.001909, loss: 2.9331
2022-10-07 02:27:16 - train: epoch 0018, iter [01250, 01251], lr: 0.001909, loss: 3.1797
2022-10-07 02:27:20 - train: epoch 018, train_loss: 3.5375
2022-10-07 02:28:38 - eval: epoch: 018, acc1: 76.574%, acc5: 93.900%, test_loss: 1.0202, per_image_load_time: 0.280ms, per_image_inference_time: 1.418ms
2022-10-07 02:28:39 - until epoch: 018, best_acc1: 76.574%
2022-10-07 02:28:39 - epoch 019 lr: 0.001909
2022-10-07 02:29:08 - train: epoch 0019, iter [00010, 01251], lr: 0.001909, loss: 3.1166
2022-10-07 02:29:29 - train: epoch 0019, iter [00020, 01251], lr: 0.001909, loss: 3.5357
2022-10-07 02:29:50 - train: epoch 0019, iter [00030, 01251], lr: 0.001909, loss: 3.9448
2022-10-07 02:30:11 - train: epoch 0019, iter [00040, 01251], lr: 0.001909, loss: 4.1156
2022-10-07 02:30:32 - train: epoch 0019, iter [00050, 01251], lr: 0.001909, loss: 3.9717
2022-10-07 02:30:53 - train: epoch 0019, iter [00060, 01251], lr: 0.001908, loss: 3.5580
2022-10-07 02:31:15 - train: epoch 0019, iter [00070, 01251], lr: 0.001908, loss: 3.0908
2022-10-07 02:31:36 - train: epoch 0019, iter [00080, 01251], lr: 0.001908, loss: 3.1326
2022-10-07 02:31:57 - train: epoch 0019, iter [00090, 01251], lr: 0.001908, loss: 3.3249
2022-10-07 02:32:18 - train: epoch 0019, iter [00100, 01251], lr: 0.001908, loss: 3.1002
2022-10-07 02:32:40 - train: epoch 0019, iter [00110, 01251], lr: 0.001908, loss: 3.6775
2022-10-07 02:33:01 - train: epoch 0019, iter [00120, 01251], lr: 0.001908, loss: 3.6101
2022-10-07 02:33:22 - train: epoch 0019, iter [00130, 01251], lr: 0.001908, loss: 3.3596
2022-10-07 02:33:43 - train: epoch 0019, iter [00140, 01251], lr: 0.001908, loss: 3.3728
2022-10-07 02:34:04 - train: epoch 0019, iter [00150, 01251], lr: 0.001907, loss: 3.2731
2022-10-07 02:34:26 - train: epoch 0019, iter [00160, 01251], lr: 0.001907, loss: 3.9734
2022-10-07 02:34:47 - train: epoch 0019, iter [00170, 01251], lr: 0.001907, loss: 3.6506
2022-10-07 02:35:08 - train: epoch 0019, iter [00180, 01251], lr: 0.001907, loss: 3.1736
2022-10-07 02:35:30 - train: epoch 0019, iter [00190, 01251], lr: 0.001907, loss: 2.6091
2022-10-07 02:35:51 - train: epoch 0019, iter [00200, 01251], lr: 0.001907, loss: 3.7825
2022-10-07 02:36:12 - train: epoch 0019, iter [00210, 01251], lr: 0.001907, loss: 2.6307
2022-10-07 02:36:33 - train: epoch 0019, iter [00220, 01251], lr: 0.001907, loss: 3.3562
2022-10-07 02:36:54 - train: epoch 0019, iter [00230, 01251], lr: 0.001907, loss: 3.2534
2022-10-07 02:37:16 - train: epoch 0019, iter [00240, 01251], lr: 0.001906, loss: 3.0844
2022-10-07 02:37:37 - train: epoch 0019, iter [00250, 01251], lr: 0.001906, loss: 3.2964
2022-10-07 02:37:58 - train: epoch 0019, iter [00260, 01251], lr: 0.001906, loss: 4.2890
2022-10-07 02:38:19 - train: epoch 0019, iter [00270, 01251], lr: 0.001906, loss: 3.9214
2022-10-07 02:38:40 - train: epoch 0019, iter [00280, 01251], lr: 0.001906, loss: 3.6447
2022-10-07 02:39:02 - train: epoch 0019, iter [00290, 01251], lr: 0.001906, loss: 3.7143
2022-10-07 02:39:23 - train: epoch 0019, iter [00300, 01251], lr: 0.001906, loss: 2.9944
2022-10-07 02:39:44 - train: epoch 0019, iter [00310, 01251], lr: 0.001906, loss: 3.6857
2022-10-07 02:40:06 - train: epoch 0019, iter [00320, 01251], lr: 0.001905, loss: 4.0017
2022-10-07 02:40:27 - train: epoch 0019, iter [00330, 01251], lr: 0.001905, loss: 3.6758
2022-10-07 02:40:48 - train: epoch 0019, iter [00340, 01251], lr: 0.001905, loss: 3.9169
2022-10-07 02:41:09 - train: epoch 0019, iter [00350, 01251], lr: 0.001905, loss: 3.1952
2022-10-07 02:41:31 - train: epoch 0019, iter [00360, 01251], lr: 0.001905, loss: 4.0364
2022-10-07 02:41:52 - train: epoch 0019, iter [00370, 01251], lr: 0.001905, loss: 3.4217
2022-10-07 02:42:13 - train: epoch 0019, iter [00380, 01251], lr: 0.001905, loss: 3.7510
2022-10-07 02:42:35 - train: epoch 0019, iter [00390, 01251], lr: 0.001905, loss: 4.1817
2022-10-07 02:42:56 - train: epoch 0019, iter [00400, 01251], lr: 0.001905, loss: 2.4779
2022-10-07 02:43:17 - train: epoch 0019, iter [00410, 01251], lr: 0.001904, loss: 3.3154
2022-10-07 02:43:38 - train: epoch 0019, iter [00420, 01251], lr: 0.001904, loss: 3.1157
2022-10-07 02:44:00 - train: epoch 0019, iter [00430, 01251], lr: 0.001904, loss: 3.7171
2022-10-07 02:44:21 - train: epoch 0019, iter [00440, 01251], lr: 0.001904, loss: 3.7303
2022-10-07 02:44:42 - train: epoch 0019, iter [00450, 01251], lr: 0.001904, loss: 3.4393
2022-10-07 02:45:03 - train: epoch 0019, iter [00460, 01251], lr: 0.001904, loss: 3.7412
2022-10-07 02:45:24 - train: epoch 0019, iter [00470, 01251], lr: 0.001904, loss: 3.4901
2022-10-07 02:45:46 - train: epoch 0019, iter [00480, 01251], lr: 0.001904, loss: 3.0164
2022-10-07 02:46:07 - train: epoch 0019, iter [00490, 01251], lr: 0.001904, loss: 3.7556
2022-10-07 02:46:28 - train: epoch 0019, iter [00500, 01251], lr: 0.001903, loss: 3.7868
2022-10-07 02:46:49 - train: epoch 0019, iter [00510, 01251], lr: 0.001903, loss: 4.1010
2022-10-07 02:47:11 - train: epoch 0019, iter [00520, 01251], lr: 0.001903, loss: 3.2879
2022-10-07 02:47:32 - train: epoch 0019, iter [00530, 01251], lr: 0.001903, loss: 3.6771
2022-10-07 02:47:53 - train: epoch 0019, iter [00540, 01251], lr: 0.001903, loss: 3.2066
2022-10-07 02:48:14 - train: epoch 0019, iter [00550, 01251], lr: 0.001903, loss: 3.8105
2022-10-07 02:48:36 - train: epoch 0019, iter [00560, 01251], lr: 0.001903, loss: 3.6380
2022-10-07 02:48:57 - train: epoch 0019, iter [00570, 01251], lr: 0.001903, loss: 3.5740
2022-10-07 02:49:18 - train: epoch 0019, iter [00580, 01251], lr: 0.001903, loss: 4.2125
2022-10-07 02:49:40 - train: epoch 0019, iter [00590, 01251], lr: 0.001902, loss: 3.2476
2022-10-07 02:50:01 - train: epoch 0019, iter [00600, 01251], lr: 0.001902, loss: 3.3863
2022-10-07 02:50:23 - train: epoch 0019, iter [00610, 01251], lr: 0.001902, loss: 3.6868
2022-10-07 02:50:44 - train: epoch 0019, iter [00620, 01251], lr: 0.001902, loss: 3.1957
2022-10-07 02:51:05 - train: epoch 0019, iter [00630, 01251], lr: 0.001902, loss: 2.9468
2022-10-07 02:51:27 - train: epoch 0019, iter [00640, 01251], lr: 0.001902, loss: 3.3810
2022-10-07 02:51:48 - train: epoch 0019, iter [00650, 01251], lr: 0.001902, loss: 2.7259
2022-10-07 02:52:10 - train: epoch 0019, iter [00660, 01251], lr: 0.001902, loss: 3.8076
2022-10-07 02:52:31 - train: epoch 0019, iter [00670, 01251], lr: 0.001902, loss: 3.2755
2022-10-07 02:52:52 - train: epoch 0019, iter [00680, 01251], lr: 0.001901, loss: 3.9138
2022-10-07 02:53:14 - train: epoch 0019, iter [00690, 01251], lr: 0.001901, loss: 3.7484
2022-10-07 02:53:35 - train: epoch 0019, iter [00700, 01251], lr: 0.001901, loss: 3.3907
2022-10-07 02:53:56 - train: epoch 0019, iter [00710, 01251], lr: 0.001901, loss: 3.4979
2022-10-07 02:54:18 - train: epoch 0019, iter [00720, 01251], lr: 0.001901, loss: 3.1945
2022-10-07 02:54:39 - train: epoch 0019, iter [00730, 01251], lr: 0.001901, loss: 3.8174
2022-10-07 02:55:00 - train: epoch 0019, iter [00740, 01251], lr: 0.001901, loss: 3.4595
2022-10-07 02:55:22 - train: epoch 0019, iter [00750, 01251], lr: 0.001901, loss: 3.9083
2022-10-07 02:55:43 - train: epoch 0019, iter [00760, 01251], lr: 0.001901, loss: 3.0463
2022-10-07 02:56:04 - train: epoch 0019, iter [00770, 01251], lr: 0.001900, loss: 2.9558
2022-10-07 02:56:26 - train: epoch 0019, iter [00780, 01251], lr: 0.001900, loss: 3.2910
2022-10-07 02:56:47 - train: epoch 0019, iter [00790, 01251], lr: 0.001900, loss: 3.6186
2022-10-07 02:57:08 - train: epoch 0019, iter [00800, 01251], lr: 0.001900, loss: 3.6201
2022-10-07 02:57:29 - train: epoch 0019, iter [00810, 01251], lr: 0.001900, loss: 3.3546
2022-10-07 02:57:51 - train: epoch 0019, iter [00820, 01251], lr: 0.001900, loss: 3.5951
2022-10-07 02:58:12 - train: epoch 0019, iter [00830, 01251], lr: 0.001900, loss: 3.6996
2022-10-07 02:58:33 - train: epoch 0019, iter [00840, 01251], lr: 0.001900, loss: 3.8714
2022-10-07 02:58:55 - train: epoch 0019, iter [00850, 01251], lr: 0.001899, loss: 2.9958
2022-10-07 02:59:16 - train: epoch 0019, iter [00860, 01251], lr: 0.001899, loss: 3.7904
2022-10-07 02:59:37 - train: epoch 0019, iter [00870, 01251], lr: 0.001899, loss: 3.2896
2022-10-07 02:59:58 - train: epoch 0019, iter [00880, 01251], lr: 0.001899, loss: 3.9247
2022-10-07 03:00:20 - train: epoch 0019, iter [00890, 01251], lr: 0.001899, loss: 3.2743
2022-10-07 03:00:41 - train: epoch 0019, iter [00900, 01251], lr: 0.001899, loss: 4.0380
2022-10-07 03:01:02 - train: epoch 0019, iter [00910, 01251], lr: 0.001899, loss: 3.5939
2022-10-07 03:01:24 - train: epoch 0019, iter [00920, 01251], lr: 0.001899, loss: 3.7980
2022-10-07 03:01:45 - train: epoch 0019, iter [00930, 01251], lr: 0.001899, loss: 3.1669
2022-10-07 03:02:06 - train: epoch 0019, iter [00940, 01251], lr: 0.001898, loss: 3.9823
2022-10-07 03:02:27 - train: epoch 0019, iter [00950, 01251], lr: 0.001898, loss: 3.2280
2022-10-07 03:02:48 - train: epoch 0019, iter [00960, 01251], lr: 0.001898, loss: 3.5396
2022-10-07 03:03:10 - train: epoch 0019, iter [00970, 01251], lr: 0.001898, loss: 3.5031
2022-10-07 03:03:31 - train: epoch 0019, iter [00980, 01251], lr: 0.001898, loss: 3.1451
2022-10-07 03:03:52 - train: epoch 0019, iter [00990, 01251], lr: 0.001898, loss: 2.6658
2022-10-07 03:04:13 - train: epoch 0019, iter [01000, 01251], lr: 0.001898, loss: 3.4627
2022-10-07 03:04:35 - train: epoch 0019, iter [01010, 01251], lr: 0.001898, loss: 3.9362
2022-10-07 03:04:56 - train: epoch 0019, iter [01020, 01251], lr: 0.001897, loss: 4.0782
2022-10-07 03:05:17 - train: epoch 0019, iter [01030, 01251], lr: 0.001897, loss: 3.0600
2022-10-07 03:05:39 - train: epoch 0019, iter [01040, 01251], lr: 0.001897, loss: 3.5872
2022-10-07 03:06:00 - train: epoch 0019, iter [01050, 01251], lr: 0.001897, loss: 3.0423
2022-10-07 03:06:21 - train: epoch 0019, iter [01060, 01251], lr: 0.001897, loss: 3.5271
2022-10-07 03:06:42 - train: epoch 0019, iter [01070, 01251], lr: 0.001897, loss: 3.5680
2022-10-07 03:07:04 - train: epoch 0019, iter [01080, 01251], lr: 0.001897, loss: 3.7667
2022-10-07 03:07:25 - train: epoch 0019, iter [01090, 01251], lr: 0.001897, loss: 3.0248
2022-10-07 03:07:47 - train: epoch 0019, iter [01100, 01251], lr: 0.001897, loss: 4.0639
2022-10-07 03:08:08 - train: epoch 0019, iter [01110, 01251], lr: 0.001896, loss: 3.7448
2022-10-07 03:08:29 - train: epoch 0019, iter [01120, 01251], lr: 0.001896, loss: 3.2535
2022-10-07 03:08:50 - train: epoch 0019, iter [01130, 01251], lr: 0.001896, loss: 3.6477
2022-10-07 03:09:12 - train: epoch 0019, iter [01140, 01251], lr: 0.001896, loss: 3.6495
2022-10-07 03:09:33 - train: epoch 0019, iter [01150, 01251], lr: 0.001896, loss: 2.9808
2022-10-07 03:09:55 - train: epoch 0019, iter [01160, 01251], lr: 0.001896, loss: 4.1050
2022-10-07 03:10:16 - train: epoch 0019, iter [01170, 01251], lr: 0.001896, loss: 3.3359
2022-10-07 03:10:37 - train: epoch 0019, iter [01180, 01251], lr: 0.001896, loss: 3.5363
2022-10-07 03:10:59 - train: epoch 0019, iter [01190, 01251], lr: 0.001896, loss: 3.8210
2022-10-07 03:11:20 - train: epoch 0019, iter [01200, 01251], lr: 0.001895, loss: 3.2218
2022-10-07 03:11:41 - train: epoch 0019, iter [01210, 01251], lr: 0.001895, loss: 3.4345
2022-10-07 03:12:03 - train: epoch 0019, iter [01220, 01251], lr: 0.001895, loss: 3.8279
2022-10-07 03:12:24 - train: epoch 0019, iter [01230, 01251], lr: 0.001895, loss: 3.2793
2022-10-07 03:12:45 - train: epoch 0019, iter [01240, 01251], lr: 0.001895, loss: 3.4251
2022-10-07 03:13:07 - train: epoch 0019, iter [01250, 01251], lr: 0.001895, loss: 2.9026
2022-10-07 03:13:11 - train: epoch 019, train_loss: 3.5056
2022-10-07 03:14:29 - eval: epoch: 019, acc1: 76.438%, acc5: 93.960%, test_loss: 1.0238, per_image_load_time: 0.508ms, per_image_inference_time: 1.420ms
2022-10-07 03:14:30 - until epoch: 019, best_acc1: 76.574%
2022-10-07 03:14:30 - epoch 020 lr: 0.001895
2022-10-07 03:14:58 - train: epoch 0020, iter [00010, 01251], lr: 0.001895, loss: 3.1058
2022-10-07 03:15:20 - train: epoch 0020, iter [00020, 01251], lr: 0.001895, loss: 4.0082
2022-10-07 03:15:41 - train: epoch 0020, iter [00030, 01251], lr: 0.001894, loss: 2.9981
2022-10-07 03:16:02 - train: epoch 0020, iter [00040, 01251], lr: 0.001894, loss: 3.4509
2022-10-07 03:16:23 - train: epoch 0020, iter [00050, 01251], lr: 0.001894, loss: 2.9133
2022-10-07 03:16:44 - train: epoch 0020, iter [00060, 01251], lr: 0.001894, loss: 3.7453
2022-10-07 03:17:05 - train: epoch 0020, iter [00070, 01251], lr: 0.001894, loss: 3.6454
2022-10-07 03:17:26 - train: epoch 0020, iter [00080, 01251], lr: 0.001894, loss: 3.0400
2022-10-07 03:17:47 - train: epoch 0020, iter [00090, 01251], lr: 0.001894, loss: 2.4943
2022-10-07 03:18:08 - train: epoch 0020, iter [00100, 01251], lr: 0.001894, loss: 3.6015
2022-10-07 03:18:30 - train: epoch 0020, iter [00110, 01251], lr: 0.001893, loss: 3.0723
2022-10-07 03:18:51 - train: epoch 0020, iter [00120, 01251], lr: 0.001893, loss: 3.8275
2022-10-07 03:19:12 - train: epoch 0020, iter [00130, 01251], lr: 0.001893, loss: 3.7825
2022-10-07 03:19:33 - train: epoch 0020, iter [00140, 01251], lr: 0.001893, loss: 3.4451
2022-10-07 03:19:54 - train: epoch 0020, iter [00150, 01251], lr: 0.001893, loss: 3.4518
2022-10-07 03:20:15 - train: epoch 0020, iter [00160, 01251], lr: 0.001893, loss: 3.7043
2022-10-07 03:20:37 - train: epoch 0020, iter [00170, 01251], lr: 0.001893, loss: 3.0146
2022-10-07 03:20:58 - train: epoch 0020, iter [00180, 01251], lr: 0.001893, loss: 3.8025
2022-10-07 03:21:19 - train: epoch 0020, iter [00190, 01251], lr: 0.001893, loss: 4.0507
2022-10-07 03:21:40 - train: epoch 0020, iter [00200, 01251], lr: 0.001892, loss: 4.2403
2022-10-07 03:22:01 - train: epoch 0020, iter [00210, 01251], lr: 0.001892, loss: 3.3958
2022-10-07 03:22:23 - train: epoch 0020, iter [00220, 01251], lr: 0.001892, loss: 3.3823
2022-10-07 03:22:44 - train: epoch 0020, iter [00230, 01251], lr: 0.001892, loss: 3.8124
2022-10-07 03:23:05 - train: epoch 0020, iter [00240, 01251], lr: 0.001892, loss: 3.0448
2022-10-07 03:23:26 - train: epoch 0020, iter [00250, 01251], lr: 0.001892, loss: 3.5194
2022-10-07 03:23:47 - train: epoch 0020, iter [00260, 01251], lr: 0.001892, loss: 3.9507
2022-10-07 03:24:09 - train: epoch 0020, iter [00270, 01251], lr: 0.001892, loss: 2.8218
2022-10-07 03:24:30 - train: epoch 0020, iter [00280, 01251], lr: 0.001891, loss: 3.0689
2022-10-07 03:24:51 - train: epoch 0020, iter [00290, 01251], lr: 0.001891, loss: 3.9886
2022-10-07 03:25:13 - train: epoch 0020, iter [00300, 01251], lr: 0.001891, loss: 3.6676
2022-10-07 03:25:34 - train: epoch 0020, iter [00310, 01251], lr: 0.001891, loss: 3.4361
2022-10-07 03:25:55 - train: epoch 0020, iter [00320, 01251], lr: 0.001891, loss: 3.1637
2022-10-07 03:26:17 - train: epoch 0020, iter [00330, 01251], lr: 0.001891, loss: 3.2250
2022-10-07 03:26:38 - train: epoch 0020, iter [00340, 01251], lr: 0.001891, loss: 3.6616
2022-10-07 03:26:59 - train: epoch 0020, iter [00350, 01251], lr: 0.001891, loss: 4.0372
2022-10-07 03:27:20 - train: epoch 0020, iter [00360, 01251], lr: 0.001890, loss: 3.1473
2022-10-07 03:27:42 - train: epoch 0020, iter [00370, 01251], lr: 0.001890, loss: 3.4171
2022-10-07 03:28:03 - train: epoch 0020, iter [00380, 01251], lr: 0.001890, loss: 3.6923
2022-10-07 03:28:25 - train: epoch 0020, iter [00390, 01251], lr: 0.001890, loss: 3.6621
2022-10-07 03:28:46 - train: epoch 0020, iter [00400, 01251], lr: 0.001890, loss: 3.3437
2022-10-07 03:29:07 - train: epoch 0020, iter [00410, 01251], lr: 0.001890, loss: 3.5188
2022-10-07 03:29:28 - train: epoch 0020, iter [00420, 01251], lr: 0.001890, loss: 3.0771
2022-10-07 03:29:50 - train: epoch 0020, iter [00430, 01251], lr: 0.001890, loss: 3.7721
2022-10-07 03:30:11 - train: epoch 0020, iter [00440, 01251], lr: 0.001890, loss: 3.7786
2022-10-07 03:30:32 - train: epoch 0020, iter [00450, 01251], lr: 0.001889, loss: 3.8233
2022-10-07 03:30:54 - train: epoch 0020, iter [00460, 01251], lr: 0.001889, loss: 3.8399
2022-10-07 03:31:15 - train: epoch 0020, iter [00470, 01251], lr: 0.001889, loss: 3.6671
2022-10-07 03:31:36 - train: epoch 0020, iter [00480, 01251], lr: 0.001889, loss: 3.2503
2022-10-07 03:31:57 - train: epoch 0020, iter [00490, 01251], lr: 0.001889, loss: 3.4410
2022-10-07 03:32:19 - train: epoch 0020, iter [00500, 01251], lr: 0.001889, loss: 4.0587
2022-10-07 03:32:40 - train: epoch 0020, iter [00510, 01251], lr: 0.001889, loss: 3.7428
2022-10-07 03:33:01 - train: epoch 0020, iter [00520, 01251], lr: 0.001889, loss: 3.2278
2022-10-07 03:33:22 - train: epoch 0020, iter [00530, 01251], lr: 0.001888, loss: 3.6940
2022-10-07 03:33:44 - train: epoch 0020, iter [00540, 01251], lr: 0.001888, loss: 3.1572
2022-10-07 03:34:05 - train: epoch 0020, iter [00550, 01251], lr: 0.001888, loss: 3.7647
2022-10-07 03:34:26 - train: epoch 0020, iter [00560, 01251], lr: 0.001888, loss: 3.6413
2022-10-07 03:34:48 - train: epoch 0020, iter [00570, 01251], lr: 0.001888, loss: 3.6081
2022-10-07 03:35:09 - train: epoch 0020, iter [00580, 01251], lr: 0.001888, loss: 3.5335
2022-10-07 03:35:30 - train: epoch 0020, iter [00590, 01251], lr: 0.001888, loss: 3.4238
2022-10-07 03:35:51 - train: epoch 0020, iter [00600, 01251], lr: 0.001888, loss: 3.7500
2022-10-07 03:36:13 - train: epoch 0020, iter [00610, 01251], lr: 0.001887, loss: 3.8610
2022-10-07 03:36:34 - train: epoch 0020, iter [00620, 01251], lr: 0.001887, loss: 3.6398
2022-10-07 03:36:55 - train: epoch 0020, iter [00630, 01251], lr: 0.001887, loss: 4.0602
2022-10-07 03:37:17 - train: epoch 0020, iter [00640, 01251], lr: 0.001887, loss: 4.0368
2022-10-07 03:37:38 - train: epoch 0020, iter [00650, 01251], lr: 0.001887, loss: 2.9869
2022-10-07 03:37:59 - train: epoch 0020, iter [00660, 01251], lr: 0.001887, loss: 3.5031
2022-10-07 03:38:21 - train: epoch 0020, iter [00670, 01251], lr: 0.001887, loss: 3.5602
2022-10-07 03:38:42 - train: epoch 0020, iter [00680, 01251], lr: 0.001887, loss: 3.8946
2022-10-07 03:39:03 - train: epoch 0020, iter [00690, 01251], lr: 0.001886, loss: 3.4565
2022-10-07 03:39:25 - train: epoch 0020, iter [00700, 01251], lr: 0.001886, loss: 3.3646
2022-10-07 03:39:46 - train: epoch 0020, iter [00710, 01251], lr: 0.001886, loss: 2.8531
2022-10-07 03:40:07 - train: epoch 0020, iter [00720, 01251], lr: 0.001886, loss: 3.9782
2022-10-07 03:40:29 - train: epoch 0020, iter [00730, 01251], lr: 0.001886, loss: 3.8815
2022-10-07 03:40:50 - train: epoch 0020, iter [00740, 01251], lr: 0.001886, loss: 3.9526
2022-10-07 03:41:11 - train: epoch 0020, iter [00750, 01251], lr: 0.001886, loss: 2.9542
2022-10-07 03:41:32 - train: epoch 0020, iter [00760, 01251], lr: 0.001886, loss: 3.5361
2022-10-07 03:41:54 - train: epoch 0020, iter [00770, 01251], lr: 0.001886, loss: 3.3683
2022-10-07 03:42:15 - train: epoch 0020, iter [00780, 01251], lr: 0.001885, loss: 3.6032
2022-10-07 03:42:36 - train: epoch 0020, iter [00790, 01251], lr: 0.001885, loss: 3.7604
2022-10-07 03:42:58 - train: epoch 0020, iter [00800, 01251], lr: 0.001885, loss: 3.6414
2022-10-07 03:43:19 - train: epoch 0020, iter [00810, 01251], lr: 0.001885, loss: 3.1155
2022-10-07 03:43:40 - train: epoch 0020, iter [00820, 01251], lr: 0.001885, loss: 2.9001
2022-10-07 03:44:01 - train: epoch 0020, iter [00830, 01251], lr: 0.001885, loss: 3.3208
2022-10-07 03:44:23 - train: epoch 0020, iter [00840, 01251], lr: 0.001885, loss: 3.8239
2022-10-07 03:44:44 - train: epoch 0020, iter [00850, 01251], lr: 0.001885, loss: 3.1704
2022-10-07 03:45:05 - train: epoch 0020, iter [00860, 01251], lr: 0.001884, loss: 3.3032
2022-10-07 03:45:27 - train: epoch 0020, iter [00870, 01251], lr: 0.001884, loss: 3.9135
2022-10-07 03:45:48 - train: epoch 0020, iter [00880, 01251], lr: 0.001884, loss: 2.8091
2022-10-07 03:46:09 - train: epoch 0020, iter [00890, 01251], lr: 0.001884, loss: 3.6917
2022-10-07 03:46:31 - train: epoch 0020, iter [00900, 01251], lr: 0.001884, loss: 2.7069
2022-10-07 03:46:52 - train: epoch 0020, iter [00910, 01251], lr: 0.001884, loss: 3.6661
2022-10-07 03:47:13 - train: epoch 0020, iter [00920, 01251], lr: 0.001884, loss: 3.2670
2022-10-07 03:47:34 - train: epoch 0020, iter [00930, 01251], lr: 0.001884, loss: 4.2339
2022-10-07 03:47:56 - train: epoch 0020, iter [00940, 01251], lr: 0.001883, loss: 3.4136
2022-10-07 03:48:17 - train: epoch 0020, iter [00950, 01251], lr: 0.001883, loss: 3.5080
2022-10-07 03:48:39 - train: epoch 0020, iter [00960, 01251], lr: 0.001883, loss: 3.9468
2022-10-07 03:49:00 - train: epoch 0020, iter [00970, 01251], lr: 0.001883, loss: 3.5714
2022-10-07 03:49:21 - train: epoch 0020, iter [00980, 01251], lr: 0.001883, loss: 3.1119
2022-10-07 03:49:43 - train: epoch 0020, iter [00990, 01251], lr: 0.001883, loss: 3.4242
2022-10-07 03:50:04 - train: epoch 0020, iter [01000, 01251], lr: 0.001883, loss: 3.8927
2022-10-07 03:50:26 - train: epoch 0020, iter [01010, 01251], lr: 0.001883, loss: 3.4129
2022-10-07 03:50:47 - train: epoch 0020, iter [01020, 01251], lr: 0.001882, loss: 3.8749
2022-10-07 03:51:08 - train: epoch 0020, iter [01030, 01251], lr: 0.001882, loss: 3.9736
2022-10-07 03:51:29 - train: epoch 0020, iter [01040, 01251], lr: 0.001882, loss: 3.2052
2022-10-07 03:51:51 - train: epoch 0020, iter [01050, 01251], lr: 0.001882, loss: 3.9632
2022-10-07 03:52:12 - train: epoch 0020, iter [01060, 01251], lr: 0.001882, loss: 3.1564
2022-10-07 03:52:33 - train: epoch 0020, iter [01070, 01251], lr: 0.001882, loss: 3.8370
2022-10-07 03:52:55 - train: epoch 0020, iter [01080, 01251], lr: 0.001882, loss: 3.7867
2022-10-07 03:53:16 - train: epoch 0020, iter [01090, 01251], lr: 0.001882, loss: 2.6315
2022-10-07 03:53:37 - train: epoch 0020, iter [01100, 01251], lr: 0.001881, loss: 3.7890
2022-10-07 03:53:59 - train: epoch 0020, iter [01110, 01251], lr: 0.001881, loss: 3.2936
2022-10-07 03:54:20 - train: epoch 0020, iter [01120, 01251], lr: 0.001881, loss: 3.5082
2022-10-07 03:54:41 - train: epoch 0020, iter [01130, 01251], lr: 0.001881, loss: 3.7293
2022-10-07 03:55:02 - train: epoch 0020, iter [01140, 01251], lr: 0.001881, loss: 2.7159
2022-10-07 03:55:24 - train: epoch 0020, iter [01150, 01251], lr: 0.001881, loss: 3.7136
2022-10-07 03:55:45 - train: epoch 0020, iter [01160, 01251], lr: 0.001881, loss: 3.8269
2022-10-07 03:56:06 - train: epoch 0020, iter [01170, 01251], lr: 0.001881, loss: 3.8243
2022-10-07 03:56:27 - train: epoch 0020, iter [01180, 01251], lr: 0.001880, loss: 3.8022
2022-10-07 03:56:49 - train: epoch 0020, iter [01190, 01251], lr: 0.001880, loss: 3.4974
2022-10-07 03:57:10 - train: epoch 0020, iter [01200, 01251], lr: 0.001880, loss: 3.5013
2022-10-07 03:57:31 - train: epoch 0020, iter [01210, 01251], lr: 0.001880, loss: 2.9179
2022-10-07 03:57:52 - train: epoch 0020, iter [01220, 01251], lr: 0.001880, loss: 3.9018
2022-10-07 03:58:14 - train: epoch 0020, iter [01230, 01251], lr: 0.001880, loss: 3.1936
2022-10-07 03:58:35 - train: epoch 0020, iter [01240, 01251], lr: 0.001880, loss: 4.0968
2022-10-07 03:58:56 - train: epoch 0020, iter [01250, 01251], lr: 0.001880, loss: 3.5856
2022-10-07 03:59:00 - train: epoch 020, train_loss: 3.4973
2022-10-07 04:00:17 - eval: epoch: 020, acc1: 76.784%, acc5: 94.038%, test_loss: 0.9817, per_image_load_time: 0.480ms, per_image_inference_time: 1.432ms
2022-10-07 04:00:19 - until epoch: 020, best_acc1: 76.784%
2022-10-07 04:00:19 - epoch 021 lr: 0.001880
2022-10-07 04:00:47 - train: epoch 0021, iter [00010, 01251], lr: 0.001879, loss: 3.7852
2022-10-07 04:01:08 - train: epoch 0021, iter [00020, 01251], lr: 0.001879, loss: 3.3262
2022-10-07 04:01:29 - train: epoch 0021, iter [00030, 01251], lr: 0.001879, loss: 3.9630
2022-10-07 04:01:50 - train: epoch 0021, iter [00040, 01251], lr: 0.001879, loss: 2.9747
2022-10-07 04:02:11 - train: epoch 0021, iter [00050, 01251], lr: 0.001879, loss: 3.3018
2022-10-07 04:02:33 - train: epoch 0021, iter [00060, 01251], lr: 0.001879, loss: 3.2764
2022-10-07 04:02:54 - train: epoch 0021, iter [00070, 01251], lr: 0.001879, loss: 3.5717
2022-10-07 04:03:15 - train: epoch 0021, iter [00080, 01251], lr: 0.001879, loss: 2.9488
2022-10-07 04:03:36 - train: epoch 0021, iter [00090, 01251], lr: 0.001878, loss: 3.0380
2022-10-07 04:03:57 - train: epoch 0021, iter [00100, 01251], lr: 0.001878, loss: 3.2290
2022-10-07 04:04:19 - train: epoch 0021, iter [00110, 01251], lr: 0.001878, loss: 3.0995
2022-10-07 04:04:40 - train: epoch 0021, iter [00120, 01251], lr: 0.001878, loss: 3.2684
2022-10-07 04:05:01 - train: epoch 0021, iter [00130, 01251], lr: 0.001878, loss: 3.2200
2022-10-07 04:05:22 - train: epoch 0021, iter [00140, 01251], lr: 0.001878, loss: 3.8108
2022-10-07 04:05:43 - train: epoch 0021, iter [00150, 01251], lr: 0.001878, loss: 3.9707
2022-10-07 04:06:04 - train: epoch 0021, iter [00160, 01251], lr: 0.001878, loss: 2.8610
2022-10-07 04:06:26 - train: epoch 0021, iter [00170, 01251], lr: 0.001877, loss: 2.9989
2022-10-07 04:06:47 - train: epoch 0021, iter [00180, 01251], lr: 0.001877, loss: 3.8692
2022-10-07 04:07:08 - train: epoch 0021, iter [00190, 01251], lr: 0.001877, loss: 3.8391
2022-10-07 04:07:29 - train: epoch 0021, iter [00200, 01251], lr: 0.001877, loss: 4.3028
2022-10-07 04:07:50 - train: epoch 0021, iter [00210, 01251], lr: 0.001877, loss: 3.1401
2022-10-07 04:08:11 - train: epoch 0021, iter [00220, 01251], lr: 0.001877, loss: 3.7459
2022-10-07 04:08:33 - train: epoch 0021, iter [00230, 01251], lr: 0.001877, loss: 2.6615
2022-10-07 04:08:54 - train: epoch 0021, iter [00240, 01251], lr: 0.001876, loss: 3.0851
2022-10-07 04:09:15 - train: epoch 0021, iter [00250, 01251], lr: 0.001876, loss: 3.2021
2022-10-07 04:09:36 - train: epoch 0021, iter [00260, 01251], lr: 0.001876, loss: 3.5324
2022-10-07 04:09:58 - train: epoch 0021, iter [00270, 01251], lr: 0.001876, loss: 3.5106
2022-10-07 04:10:19 - train: epoch 0021, iter [00280, 01251], lr: 0.001876, loss: 3.6785
2022-10-07 04:10:41 - train: epoch 0021, iter [00290, 01251], lr: 0.001876, loss: 3.7374
2022-10-07 04:11:02 - train: epoch 0021, iter [00300, 01251], lr: 0.001876, loss: 2.5754
2022-10-07 04:11:23 - train: epoch 0021, iter [00310, 01251], lr: 0.001876, loss: 4.2381
2022-10-07 04:11:45 - train: epoch 0021, iter [00320, 01251], lr: 0.001875, loss: 3.0835
2022-10-07 04:12:06 - train: epoch 0021, iter [00330, 01251], lr: 0.001875, loss: 2.9222
2022-10-07 04:12:27 - train: epoch 0021, iter [00340, 01251], lr: 0.001875, loss: 3.2257
2022-10-07 04:12:49 - train: epoch 0021, iter [00350, 01251], lr: 0.001875, loss: 3.5395
2022-10-07 04:13:10 - train: epoch 0021, iter [00360, 01251], lr: 0.001875, loss: 3.4670
2022-10-07 04:13:31 - train: epoch 0021, iter [00370, 01251], lr: 0.001875, loss: 3.4694
2022-10-07 04:13:53 - train: epoch 0021, iter [00380, 01251], lr: 0.001875, loss: 3.5599
2022-10-07 04:14:14 - train: epoch 0021, iter [00390, 01251], lr: 0.001875, loss: 3.7923
2022-10-07 04:14:35 - train: epoch 0021, iter [00400, 01251], lr: 0.001874, loss: 3.4629
2022-10-07 04:14:57 - train: epoch 0021, iter [00410, 01251], lr: 0.001874, loss: 3.9261
2022-10-07 04:15:18 - train: epoch 0021, iter [00420, 01251], lr: 0.001874, loss: 3.2551
2022-10-07 04:15:39 - train: epoch 0021, iter [00430, 01251], lr: 0.001874, loss: 3.1791
2022-10-07 04:16:00 - train: epoch 0021, iter [00440, 01251], lr: 0.001874, loss: 3.6357
2022-10-07 04:16:22 - train: epoch 0021, iter [00450, 01251], lr: 0.001874, loss: 4.0502
2022-10-07 04:16:43 - train: epoch 0021, iter [00460, 01251], lr: 0.001874, loss: 3.2804
2022-10-07 04:17:04 - train: epoch 0021, iter [00470, 01251], lr: 0.001874, loss: 3.3481
2022-10-07 04:17:25 - train: epoch 0021, iter [00480, 01251], lr: 0.001873, loss: 3.1587
2022-10-07 04:17:47 - train: epoch 0021, iter [00490, 01251], lr: 0.001873, loss: 3.8042
2022-10-07 04:18:08 - train: epoch 0021, iter [00500, 01251], lr: 0.001873, loss: 3.7438
2022-10-07 04:18:30 - train: epoch 0021, iter [00510, 01251], lr: 0.001873, loss: 3.0241
2022-10-07 04:18:51 - train: epoch 0021, iter [00520, 01251], lr: 0.001873, loss: 3.2279
2022-10-07 04:19:12 - train: epoch 0021, iter [00530, 01251], lr: 0.001873, loss: 3.7214
2022-10-07 04:19:33 - train: epoch 0021, iter [00540, 01251], lr: 0.001873, loss: 3.5842
2022-10-07 04:19:55 - train: epoch 0021, iter [00550, 01251], lr: 0.001873, loss: 2.9020
2022-10-07 04:20:16 - train: epoch 0021, iter [00560, 01251], lr: 0.001872, loss: 3.5308
2022-10-07 04:20:37 - train: epoch 0021, iter [00570, 01251], lr: 0.001872, loss: 3.2787
2022-10-07 04:20:59 - train: epoch 0021, iter [00580, 01251], lr: 0.001872, loss: 3.6423
2022-10-07 04:21:20 - train: epoch 0021, iter [00590, 01251], lr: 0.001872, loss: 3.4581
2022-10-07 04:21:41 - train: epoch 0021, iter [00600, 01251], lr: 0.001872, loss: 3.1075
2022-10-07 04:22:03 - train: epoch 0021, iter [00610, 01251], lr: 0.001872, loss: 3.0879
2022-10-07 04:22:24 - train: epoch 0021, iter [00620, 01251], lr: 0.001872, loss: 3.7620
2022-10-07 04:22:45 - train: epoch 0021, iter [00630, 01251], lr: 0.001871, loss: 3.4901
2022-10-07 04:23:06 - train: epoch 0021, iter [00640, 01251], lr: 0.001871, loss: 4.0561
2022-10-07 04:23:28 - train: epoch 0021, iter [00650, 01251], lr: 0.001871, loss: 3.3282
2022-10-07 04:23:49 - train: epoch 0021, iter [00660, 01251], lr: 0.001871, loss: 3.3996
2022-10-07 04:24:10 - train: epoch 0021, iter [00670, 01251], lr: 0.001871, loss: 3.3481
2022-10-07 04:24:32 - train: epoch 0021, iter [00680, 01251], lr: 0.001871, loss: 3.7341
2022-10-07 04:24:53 - train: epoch 0021, iter [00690, 01251], lr: 0.001871, loss: 3.6761
2022-10-07 04:25:14 - train: epoch 0021, iter [00700, 01251], lr: 0.001871, loss: 2.4013
2022-10-07 04:25:35 - train: epoch 0021, iter [00710, 01251], lr: 0.001870, loss: 4.1316
2022-10-07 04:25:57 - train: epoch 0021, iter [00720, 01251], lr: 0.001870, loss: 2.9765
2022-10-07 04:26:18 - train: epoch 0021, iter [00730, 01251], lr: 0.001870, loss: 3.2862
2022-10-07 04:26:39 - train: epoch 0021, iter [00740, 01251], lr: 0.001870, loss: 3.3092
2022-10-07 04:27:00 - train: epoch 0021, iter [00750, 01251], lr: 0.001870, loss: 2.4693
2022-10-07 04:27:22 - train: epoch 0021, iter [00760, 01251], lr: 0.001870, loss: 3.5873
2022-10-07 04:27:43 - train: epoch 0021, iter [00770, 01251], lr: 0.001870, loss: 3.7031
2022-10-07 04:28:04 - train: epoch 0021, iter [00780, 01251], lr: 0.001870, loss: 3.3603
2022-10-07 04:28:25 - train: epoch 0021, iter [00790, 01251], lr: 0.001869, loss: 3.0547
2022-10-07 04:28:47 - train: epoch 0021, iter [00800, 01251], lr: 0.001869, loss: 2.3530
2022-10-07 04:29:08 - train: epoch 0021, iter [00810, 01251], lr: 0.001869, loss: 3.2998
2022-10-07 04:29:29 - train: epoch 0021, iter [00820, 01251], lr: 0.001869, loss: 3.3356
2022-10-07 04:29:51 - train: epoch 0021, iter [00830, 01251], lr: 0.001869, loss: 2.5386
2022-10-07 04:30:12 - train: epoch 0021, iter [00840, 01251], lr: 0.001869, loss: 3.1432
2022-10-07 04:30:33 - train: epoch 0021, iter [00850, 01251], lr: 0.001869, loss: 3.1908
2022-10-07 04:30:55 - train: epoch 0021, iter [00860, 01251], lr: 0.001868, loss: 3.2530
2022-10-07 04:31:16 - train: epoch 0021, iter [00870, 01251], lr: 0.001868, loss: 3.3533
2022-10-07 04:31:37 - train: epoch 0021, iter [00880, 01251], lr: 0.001868, loss: 3.6308
2022-10-07 04:31:58 - train: epoch 0021, iter [00890, 01251], lr: 0.001868, loss: 3.7454
2022-10-07 04:32:20 - train: epoch 0021, iter [00900, 01251], lr: 0.001868, loss: 3.4745
2022-10-07 04:32:41 - train: epoch 0021, iter [00910, 01251], lr: 0.001868, loss: 3.4066
2022-10-07 04:33:02 - train: epoch 0021, iter [00920, 01251], lr: 0.001868, loss: 3.8110
2022-10-07 04:33:24 - train: epoch 0021, iter [00930, 01251], lr: 0.001868, loss: 3.8035
2022-10-07 04:33:45 - train: epoch 0021, iter [00940, 01251], lr: 0.001867, loss: 3.7280
2022-10-07 04:34:06 - train: epoch 0021, iter [00950, 01251], lr: 0.001867, loss: 3.5933
2022-10-07 04:34:27 - train: epoch 0021, iter [00960, 01251], lr: 0.001867, loss: 2.9865
2022-10-07 04:34:49 - train: epoch 0021, iter [00970, 01251], lr: 0.001867, loss: 3.7720
2022-10-07 04:35:10 - train: epoch 0021, iter [00980, 01251], lr: 0.001867, loss: 3.7534
2022-10-07 04:35:31 - train: epoch 0021, iter [00990, 01251], lr: 0.001867, loss: 4.3558
2022-10-07 04:35:53 - train: epoch 0021, iter [01000, 01251], lr: 0.001867, loss: 3.4842
2022-10-07 04:36:14 - train: epoch 0021, iter [01010, 01251], lr: 0.001867, loss: 3.7823
2022-10-07 04:36:35 - train: epoch 0021, iter [01020, 01251], lr: 0.001866, loss: 3.0540
2022-10-07 04:36:56 - train: epoch 0021, iter [01030, 01251], lr: 0.001866, loss: 3.8063
2022-10-07 04:37:17 - train: epoch 0021, iter [01040, 01251], lr: 0.001866, loss: 2.4268
2022-10-07 04:37:38 - train: epoch 0021, iter [01050, 01251], lr: 0.001866, loss: 3.9205
2022-10-07 04:37:59 - train: epoch 0021, iter [01060, 01251], lr: 0.001866, loss: 3.7588
2022-10-07 04:38:20 - train: epoch 0021, iter [01070, 01251], lr: 0.001866, loss: 2.9788
2022-10-07 04:38:41 - train: epoch 0021, iter [01080, 01251], lr: 0.001866, loss: 3.2817
2022-10-07 04:39:03 - train: epoch 0021, iter [01090, 01251], lr: 0.001865, loss: 3.1528
2022-10-07 04:39:24 - train: epoch 0021, iter [01100, 01251], lr: 0.001865, loss: 3.3136
2022-10-07 04:39:45 - train: epoch 0021, iter [01110, 01251], lr: 0.001865, loss: 3.7753
2022-10-07 04:40:06 - train: epoch 0021, iter [01120, 01251], lr: 0.001865, loss: 3.3012
2022-10-07 04:40:27 - train: epoch 0021, iter [01130, 01251], lr: 0.001865, loss: 3.7081
2022-10-07 04:40:48 - train: epoch 0021, iter [01140, 01251], lr: 0.001865, loss: 3.5197
2022-10-07 04:41:09 - train: epoch 0021, iter [01150, 01251], lr: 0.001865, loss: 3.1714
2022-10-07 04:41:30 - train: epoch 0021, iter [01160, 01251], lr: 0.001865, loss: 3.7072
2022-10-07 04:41:51 - train: epoch 0021, iter [01170, 01251], lr: 0.001864, loss: 3.5068
2022-10-07 04:42:12 - train: epoch 0021, iter [01180, 01251], lr: 0.001864, loss: 3.6671
2022-10-07 04:42:33 - train: epoch 0021, iter [01190, 01251], lr: 0.001864, loss: 3.6723
2022-10-07 04:42:54 - train: epoch 0021, iter [01200, 01251], lr: 0.001864, loss: 3.9408
2022-10-07 04:43:16 - train: epoch 0021, iter [01210, 01251], lr: 0.001864, loss: 3.9942
2022-10-07 04:43:37 - train: epoch 0021, iter [01220, 01251], lr: 0.001864, loss: 3.9160
2022-10-07 04:43:58 - train: epoch 0021, iter [01230, 01251], lr: 0.001864, loss: 2.7306
2022-10-07 04:44:19 - train: epoch 0021, iter [01240, 01251], lr: 0.001863, loss: 3.6140
2022-10-07 04:44:40 - train: epoch 0021, iter [01250, 01251], lr: 0.001863, loss: 3.4249
2022-10-07 04:44:43 - train: epoch 021, train_loss: 3.4862
2022-10-07 04:46:00 - eval: epoch: 021, acc1: 76.794%, acc5: 94.098%, test_loss: 1.0211, per_image_load_time: 0.183ms, per_image_inference_time: 1.426ms
2022-10-07 04:46:01 - until epoch: 021, best_acc1: 76.794%
2022-10-07 04:46:01 - epoch 022 lr: 0.001863
2022-10-07 04:46:29 - train: epoch 0022, iter [00010, 01251], lr: 0.001863, loss: 3.2825
2022-10-07 04:46:50 - train: epoch 0022, iter [00020, 01251], lr: 0.001863, loss: 3.0883
2022-10-07 04:47:11 - train: epoch 0022, iter [00030, 01251], lr: 0.001863, loss: 2.6779
2022-10-07 04:47:32 - train: epoch 0022, iter [00040, 01251], lr: 0.001863, loss: 3.3244
2022-10-07 04:47:53 - train: epoch 0022, iter [00050, 01251], lr: 0.001863, loss: 3.1787
2022-10-07 04:48:14 - train: epoch 0022, iter [00060, 01251], lr: 0.001863, loss: 3.3012
2022-10-07 04:48:35 - train: epoch 0022, iter [00070, 01251], lr: 0.001862, loss: 3.4754
2022-10-07 04:48:56 - train: epoch 0022, iter [00080, 01251], lr: 0.001862, loss: 3.3020
2022-10-07 04:49:17 - train: epoch 0022, iter [00090, 01251], lr: 0.001862, loss: 3.6495
2022-10-07 04:49:38 - train: epoch 0022, iter [00100, 01251], lr: 0.001862, loss: 3.2090
2022-10-07 04:49:59 - train: epoch 0022, iter [00110, 01251], lr: 0.001862, loss: 3.0774
2022-10-07 04:50:20 - train: epoch 0022, iter [00120, 01251], lr: 0.001862, loss: 3.8238
2022-10-07 04:50:41 - train: epoch 0022, iter [00130, 01251], lr: 0.001862, loss: 3.6865
2022-10-07 04:51:02 - train: epoch 0022, iter [00140, 01251], lr: 0.001861, loss: 3.2024
2022-10-07 04:51:23 - train: epoch 0022, iter [00150, 01251], lr: 0.001861, loss: 3.4460
2022-10-07 04:51:44 - train: epoch 0022, iter [00160, 01251], lr: 0.001861, loss: 3.6160
2022-10-07 04:52:05 - train: epoch 0022, iter [00170, 01251], lr: 0.001861, loss: 3.7068
2022-10-07 04:52:26 - train: epoch 0022, iter [00180, 01251], lr: 0.001861, loss: 3.2499
2022-10-07 04:52:47 - train: epoch 0022, iter [00190, 01251], lr: 0.001861, loss: 2.9146
2022-10-07 04:53:08 - train: epoch 0022, iter [00200, 01251], lr: 0.001861, loss: 3.6821
2022-10-07 04:53:29 - train: epoch 0022, iter [00210, 01251], lr: 0.001861, loss: 3.1467
2022-10-07 04:53:50 - train: epoch 0022, iter [00220, 01251], lr: 0.001860, loss: 2.4476
2022-10-07 04:54:11 - train: epoch 0022, iter [00230, 01251], lr: 0.001860, loss: 3.3746
2022-10-07 04:54:32 - train: epoch 0022, iter [00240, 01251], lr: 0.001860, loss: 3.4363
2022-10-07 04:54:53 - train: epoch 0022, iter [00250, 01251], lr: 0.001860, loss: 3.6257
2022-10-07 04:55:14 - train: epoch 0022, iter [00260, 01251], lr: 0.001860, loss: 3.1690
2022-10-07 04:55:35 - train: epoch 0022, iter [00270, 01251], lr: 0.001860, loss: 3.3947
2022-10-07 04:55:56 - train: epoch 0022, iter [00280, 01251], lr: 0.001860, loss: 3.4226
2022-10-07 04:56:18 - train: epoch 0022, iter [00290, 01251], lr: 0.001859, loss: 3.5214
2022-10-07 04:56:39 - train: epoch 0022, iter [00300, 01251], lr: 0.001859, loss: 2.9009
2022-10-07 04:57:00 - train: epoch 0022, iter [00310, 01251], lr: 0.001859, loss: 2.9172
2022-10-07 04:57:21 - train: epoch 0022, iter [00320, 01251], lr: 0.001859, loss: 4.1092
2022-10-07 04:57:42 - train: epoch 0022, iter [00330, 01251], lr: 0.001859, loss: 3.3249
2022-10-07 04:58:03 - train: epoch 0022, iter [00340, 01251], lr: 0.001859, loss: 3.3659
2022-10-07 04:58:24 - train: epoch 0022, iter [00350, 01251], lr: 0.001859, loss: 3.3385
2022-10-07 04:58:45 - train: epoch 0022, iter [00360, 01251], lr: 0.001858, loss: 3.4711
2022-10-07 04:59:06 - train: epoch 0022, iter [00370, 01251], lr: 0.001858, loss: 3.5438
2022-10-07 04:59:27 - train: epoch 0022, iter [00380, 01251], lr: 0.001858, loss: 3.4375
2022-10-07 04:59:49 - train: epoch 0022, iter [00390, 01251], lr: 0.001858, loss: 3.6400
2022-10-07 05:00:10 - train: epoch 0022, iter [00400, 01251], lr: 0.001858, loss: 3.8204
2022-10-07 05:00:31 - train: epoch 0022, iter [00410, 01251], lr: 0.001858, loss: 3.6402
2022-10-07 05:00:52 - train: epoch 0022, iter [00420, 01251], lr: 0.001858, loss: 3.7260
2022-10-07 05:01:13 - train: epoch 0022, iter [00430, 01251], lr: 0.001858, loss: 3.6673
2022-10-07 05:01:34 - train: epoch 0022, iter [00440, 01251], lr: 0.001857, loss: 2.9400
2022-10-07 05:01:56 - train: epoch 0022, iter [00450, 01251], lr: 0.001857, loss: 3.8062
2022-10-07 05:02:17 - train: epoch 0022, iter [00460, 01251], lr: 0.001857, loss: 3.9171
2022-10-07 05:02:38 - train: epoch 0022, iter [00470, 01251], lr: 0.001857, loss: 3.7269
2022-10-07 05:02:59 - train: epoch 0022, iter [00480, 01251], lr: 0.001857, loss: 3.0713
2022-10-07 05:03:20 - train: epoch 0022, iter [00490, 01251], lr: 0.001857, loss: 3.1629
2022-10-07 05:03:41 - train: epoch 0022, iter [00500, 01251], lr: 0.001857, loss: 3.2360
2022-10-07 05:04:02 - train: epoch 0022, iter [00510, 01251], lr: 0.001856, loss: 2.4271
2022-10-07 05:04:24 - train: epoch 0022, iter [00520, 01251], lr: 0.001856, loss: 3.6884
2022-10-07 05:04:45 - train: epoch 0022, iter [00530, 01251], lr: 0.001856, loss: 2.9263
2022-10-07 05:05:06 - train: epoch 0022, iter [00540, 01251], lr: 0.001856, loss: 3.1952
2022-10-07 05:05:27 - train: epoch 0022, iter [00550, 01251], lr: 0.001856, loss: 3.7887
2022-10-07 05:05:48 - train: epoch 0022, iter [00560, 01251], lr: 0.001856, loss: 3.3105
2022-10-07 05:06:09 - train: epoch 0022, iter [00570, 01251], lr: 0.001856, loss: 3.8526
2022-10-07 05:06:30 - train: epoch 0022, iter [00580, 01251], lr: 0.001855, loss: 3.6896
2022-10-07 05:06:51 - train: epoch 0022, iter [00590, 01251], lr: 0.001855, loss: 2.4283
2022-10-07 05:07:13 - train: epoch 0022, iter [00600, 01251], lr: 0.001855, loss: 2.7831
2022-10-07 05:07:34 - train: epoch 0022, iter [00610, 01251], lr: 0.001855, loss: 3.5156
2022-10-07 05:07:55 - train: epoch 0022, iter [00620, 01251], lr: 0.001855, loss: 3.7720
2022-10-07 05:08:16 - train: epoch 0022, iter [00630, 01251], lr: 0.001855, loss: 2.9795
2022-10-07 05:08:37 - train: epoch 0022, iter [00640, 01251], lr: 0.001855, loss: 3.8053
2022-10-07 05:08:58 - train: epoch 0022, iter [00650, 01251], lr: 0.001855, loss: 3.7945
2022-10-07 05:09:19 - train: epoch 0022, iter [00660, 01251], lr: 0.001854, loss: 3.3384
2022-10-07 05:09:40 - train: epoch 0022, iter [00670, 01251], lr: 0.001854, loss: 3.4544
2022-10-07 05:10:01 - train: epoch 0022, iter [00680, 01251], lr: 0.001854, loss: 3.8089
2022-10-07 05:10:22 - train: epoch 0022, iter [00690, 01251], lr: 0.001854, loss: 3.2141
2022-10-07 05:10:43 - train: epoch 0022, iter [00700, 01251], lr: 0.001854, loss: 3.1888
2022-10-07 05:11:05 - train: epoch 0022, iter [00710, 01251], lr: 0.001854, loss: 3.5724
2022-10-07 05:11:26 - train: epoch 0022, iter [00720, 01251], lr: 0.001854, loss: 3.4120
2022-10-07 05:11:47 - train: epoch 0022, iter [00730, 01251], lr: 0.001853, loss: 3.1552
2022-10-07 05:12:08 - train: epoch 0022, iter [00740, 01251], lr: 0.001853, loss: 2.7341
2022-10-07 05:12:29 - train: epoch 0022, iter [00750, 01251], lr: 0.001853, loss: 3.2827
2022-10-07 05:12:50 - train: epoch 0022, iter [00760, 01251], lr: 0.001853, loss: 2.9125
2022-10-07 05:13:11 - train: epoch 0022, iter [00770, 01251], lr: 0.001853, loss: 3.4056
2022-10-07 05:13:32 - train: epoch 0022, iter [00780, 01251], lr: 0.001853, loss: 4.2533
2022-10-07 05:13:53 - train: epoch 0022, iter [00790, 01251], lr: 0.001853, loss: 3.7866
2022-10-07 05:14:14 - train: epoch 0022, iter [00800, 01251], lr: 0.001852, loss: 3.9069
2022-10-07 05:14:35 - train: epoch 0022, iter [00810, 01251], lr: 0.001852, loss: 3.3322
2022-10-07 05:14:57 - train: epoch 0022, iter [00820, 01251], lr: 0.001852, loss: 3.7752
2022-10-07 05:15:18 - train: epoch 0022, iter [00830, 01251], lr: 0.001852, loss: 3.3363
2022-10-07 05:15:39 - train: epoch 0022, iter [00840, 01251], lr: 0.001852, loss: 3.2949
2022-10-07 05:16:00 - train: epoch 0022, iter [00850, 01251], lr: 0.001852, loss: 3.0508
2022-10-07 05:16:21 - train: epoch 0022, iter [00860, 01251], lr: 0.001852, loss: 2.7933
2022-10-07 05:16:42 - train: epoch 0022, iter [00870, 01251], lr: 0.001851, loss: 3.6526
2022-10-07 05:17:03 - train: epoch 0022, iter [00880, 01251], lr: 0.001851, loss: 3.4995
2022-10-07 05:17:24 - train: epoch 0022, iter [00890, 01251], lr: 0.001851, loss: 3.6153
2022-10-07 05:17:45 - train: epoch 0022, iter [00900, 01251], lr: 0.001851, loss: 3.1921
2022-10-07 05:18:06 - train: epoch 0022, iter [00910, 01251], lr: 0.001851, loss: 3.9520
2022-10-07 05:18:27 - train: epoch 0022, iter [00920, 01251], lr: 0.001851, loss: 3.7522
2022-10-07 05:18:48 - train: epoch 0022, iter [00930, 01251], lr: 0.001851, loss: 3.2892
2022-10-07 05:19:09 - train: epoch 0022, iter [00940, 01251], lr: 0.001851, loss: 3.7901
2022-10-07 05:19:31 - train: epoch 0022, iter [00950, 01251], lr: 0.001850, loss: 3.8237
2022-10-07 05:19:52 - train: epoch 0022, iter [00960, 01251], lr: 0.001850, loss: 3.6245
2022-10-07 05:20:13 - train: epoch 0022, iter [00970, 01251], lr: 0.001850, loss: 2.7151
2022-10-07 05:20:34 - train: epoch 0022, iter [00980, 01251], lr: 0.001850, loss: 3.4684
2022-10-07 05:20:55 - train: epoch 0022, iter [00990, 01251], lr: 0.001850, loss: 3.6434
2022-10-07 05:21:16 - train: epoch 0022, iter [01000, 01251], lr: 0.001850, loss: 2.9829
2022-10-07 05:21:37 - train: epoch 0022, iter [01010, 01251], lr: 0.001850, loss: 3.0270
2022-10-07 05:21:58 - train: epoch 0022, iter [01020, 01251], lr: 0.001849, loss: 3.3571
2022-10-07 05:22:19 - train: epoch 0022, iter [01030, 01251], lr: 0.001849, loss: 3.8769
2022-10-07 05:22:40 - train: epoch 0022, iter [01040, 01251], lr: 0.001849, loss: 3.5328
2022-10-07 05:23:01 - train: epoch 0022, iter [01050, 01251], lr: 0.001849, loss: 3.2337
2022-10-07 05:23:23 - train: epoch 0022, iter [01060, 01251], lr: 0.001849, loss: 3.1699
2022-10-07 05:23:44 - train: epoch 0022, iter [01070, 01251], lr: 0.001849, loss: 3.2503
2022-10-07 05:24:05 - train: epoch 0022, iter [01080, 01251], lr: 0.001849, loss: 3.2101
2022-10-07 05:24:26 - train: epoch 0022, iter [01090, 01251], lr: 0.001848, loss: 3.5639
2022-10-07 05:24:48 - train: epoch 0022, iter [01100, 01251], lr: 0.001848, loss: 3.3521
2022-10-07 05:25:09 - train: epoch 0022, iter [01110, 01251], lr: 0.001848, loss: 3.2181
2022-10-07 05:25:30 - train: epoch 0022, iter [01120, 01251], lr: 0.001848, loss: 3.2675
2022-10-07 05:25:51 - train: epoch 0022, iter [01130, 01251], lr: 0.001848, loss: 3.8418
2022-10-07 05:26:12 - train: epoch 0022, iter [01140, 01251], lr: 0.001848, loss: 3.0153
2022-10-07 05:26:33 - train: epoch 0022, iter [01150, 01251], lr: 0.001848, loss: 3.5567
2022-10-07 05:26:55 - train: epoch 0022, iter [01160, 01251], lr: 0.001847, loss: 3.6637
2022-10-07 05:27:16 - train: epoch 0022, iter [01170, 01251], lr: 0.001847, loss: 2.8572
2022-10-07 05:27:37 - train: epoch 0022, iter [01180, 01251], lr: 0.001847, loss: 3.7163
2022-10-07 05:27:58 - train: epoch 0022, iter [01190, 01251], lr: 0.001847, loss: 3.3634
2022-10-07 05:28:20 - train: epoch 0022, iter [01200, 01251], lr: 0.001847, loss: 3.6246
2022-10-07 05:28:41 - train: epoch 0022, iter [01210, 01251], lr: 0.001847, loss: 3.8843
2022-10-07 05:29:02 - train: epoch 0022, iter [01220, 01251], lr: 0.001847, loss: 3.8022
2022-10-07 05:29:23 - train: epoch 0022, iter [01230, 01251], lr: 0.001846, loss: 2.8456
2022-10-07 05:29:44 - train: epoch 0022, iter [01240, 01251], lr: 0.001846, loss: 3.3080
2022-10-07 05:30:05 - train: epoch 0022, iter [01250, 01251], lr: 0.001846, loss: 3.1283
2022-10-07 05:30:09 - train: epoch 022, train_loss: 3.4587
2022-10-07 05:31:28 - eval: epoch: 022, acc1: 77.134%, acc5: 94.146%, test_loss: 1.0040, per_image_load_time: 0.586ms, per_image_inference_time: 1.421ms
2022-10-07 05:31:30 - until epoch: 022, best_acc1: 77.134%
2022-10-07 05:31:30 - epoch 023 lr: 0.001846
2022-10-07 05:31:58 - train: epoch 0023, iter [00010, 01251], lr: 0.001846, loss: 3.8550
2022-10-07 05:32:19 - train: epoch 0023, iter [00020, 01251], lr: 0.001846, loss: 3.1224
2022-10-07 05:32:41 - train: epoch 0023, iter [00030, 01251], lr: 0.001846, loss: 3.6746
2022-10-07 05:33:02 - train: epoch 0023, iter [00040, 01251], lr: 0.001846, loss: 2.3255
2022-10-07 05:33:24 - train: epoch 0023, iter [00050, 01251], lr: 0.001845, loss: 3.3478
2022-10-07 05:33:45 - train: epoch 0023, iter [00060, 01251], lr: 0.001845, loss: 3.2857
2022-10-07 05:34:07 - train: epoch 0023, iter [00070, 01251], lr: 0.001845, loss: 3.6239
2022-10-07 05:34:28 - train: epoch 0023, iter [00080, 01251], lr: 0.001845, loss: 2.6676
2022-10-07 05:34:49 - train: epoch 0023, iter [00090, 01251], lr: 0.001845, loss: 3.1323
2022-10-07 05:35:10 - train: epoch 0023, iter [00100, 01251], lr: 0.001845, loss: 3.5712
2022-10-07 05:35:32 - train: epoch 0023, iter [00110, 01251], lr: 0.001845, loss: 3.4404
2022-10-07 05:35:53 - train: epoch 0023, iter [00120, 01251], lr: 0.001844, loss: 3.6388
2022-10-07 05:36:15 - train: epoch 0023, iter [00130, 01251], lr: 0.001844, loss: 3.6422
2022-10-07 05:36:36 - train: epoch 0023, iter [00140, 01251], lr: 0.001844, loss: 3.2202
2022-10-07 05:36:57 - train: epoch 0023, iter [00150, 01251], lr: 0.001844, loss: 3.8736
2022-10-07 05:37:18 - train: epoch 0023, iter [00160, 01251], lr: 0.001844, loss: 2.7659
2022-10-07 05:37:39 - train: epoch 0023, iter [00170, 01251], lr: 0.001844, loss: 3.7404
2022-10-07 05:38:01 - train: epoch 0023, iter [00180, 01251], lr: 0.001844, loss: 3.1863
2022-10-07 05:38:22 - train: epoch 0023, iter [00190, 01251], lr: 0.001843, loss: 3.1074
2022-10-07 05:38:43 - train: epoch 0023, iter [00200, 01251], lr: 0.001843, loss: 3.4632
2022-10-07 05:39:05 - train: epoch 0023, iter [00210, 01251], lr: 0.001843, loss: 3.5684
2022-10-07 05:39:26 - train: epoch 0023, iter [00220, 01251], lr: 0.001843, loss: 2.9264
2022-10-07 05:39:47 - train: epoch 0023, iter [00230, 01251], lr: 0.001843, loss: 3.3666
2022-10-07 05:40:08 - train: epoch 0023, iter [00240, 01251], lr: 0.001843, loss: 3.4759
2022-10-07 05:40:30 - train: epoch 0023, iter [00250, 01251], lr: 0.001843, loss: 3.2998
2022-10-07 05:40:51 - train: epoch 0023, iter [00260, 01251], lr: 0.001842, loss: 3.7061
2022-10-07 05:41:12 - train: epoch 0023, iter [00270, 01251], lr: 0.001842, loss: 3.7704
2022-10-07 05:41:33 - train: epoch 0023, iter [00280, 01251], lr: 0.001842, loss: 3.3445
2022-10-07 05:41:55 - train: epoch 0023, iter [00290, 01251], lr: 0.001842, loss: 3.5273
2022-10-07 05:42:16 - train: epoch 0023, iter [00300, 01251], lr: 0.001842, loss: 3.0978
2022-10-07 05:42:37 - train: epoch 0023, iter [00310, 01251], lr: 0.001842, loss: 3.0692
2022-10-07 05:42:58 - train: epoch 0023, iter [00320, 01251], lr: 0.001842, loss: 3.5921
2022-10-07 05:43:20 - train: epoch 0023, iter [00330, 01251], lr: 0.001841, loss: 3.6790
2022-10-07 05:43:41 - train: epoch 0023, iter [00340, 01251], lr: 0.001841, loss: 3.9064
2022-10-07 05:44:02 - train: epoch 0023, iter [00350, 01251], lr: 0.001841, loss: 3.7959
2022-10-07 05:44:23 - train: epoch 0023, iter [00360, 01251], lr: 0.001841, loss: 3.6837
2022-10-07 05:44:44 - train: epoch 0023, iter [00370, 01251], lr: 0.001841, loss: 2.9037
2022-10-07 05:45:05 - train: epoch 0023, iter [00380, 01251], lr: 0.001841, loss: 3.9162
2022-10-07 05:45:27 - train: epoch 0023, iter [00390, 01251], lr: 0.001841, loss: 2.6473
2022-10-07 05:45:48 - train: epoch 0023, iter [00400, 01251], lr: 0.001840, loss: 3.0969
2022-10-07 05:46:09 - train: epoch 0023, iter [00410, 01251], lr: 0.001840, loss: 3.8372
2022-10-07 05:46:30 - train: epoch 0023, iter [00420, 01251], lr: 0.001840, loss: 3.8744
2022-10-07 05:46:52 - train: epoch 0023, iter [00430, 01251], lr: 0.001840, loss: 3.1409
2022-10-07 05:47:13 - train: epoch 0023, iter [00440, 01251], lr: 0.001840, loss: 3.4401
2022-10-07 05:47:34 - train: epoch 0023, iter [00450, 01251], lr: 0.001840, loss: 4.0245
2022-10-07 05:47:55 - train: epoch 0023, iter [00460, 01251], lr: 0.001840, loss: 3.4586
2022-10-07 05:48:17 - train: epoch 0023, iter [00470, 01251], lr: 0.001839, loss: 3.0611
2022-10-07 05:48:38 - train: epoch 0023, iter [00480, 01251], lr: 0.001839, loss: 3.5383
2022-10-07 05:48:59 - train: epoch 0023, iter [00490, 01251], lr: 0.001839, loss: 3.4930
2022-10-07 05:49:20 - train: epoch 0023, iter [00500, 01251], lr: 0.001839, loss: 2.7761
2022-10-07 05:49:41 - train: epoch 0023, iter [00510, 01251], lr: 0.001839, loss: 3.6260
2022-10-07 05:50:03 - train: epoch 0023, iter [00520, 01251], lr: 0.001839, loss: 3.7721
2022-10-07 05:50:24 - train: epoch 0023, iter [00530, 01251], lr: 0.001839, loss: 3.3119
2022-10-07 05:50:45 - train: epoch 0023, iter [00540, 01251], lr: 0.001838, loss: 3.4595
2022-10-07 05:51:06 - train: epoch 0023, iter [00550, 01251], lr: 0.001838, loss: 3.4961
2022-10-07 05:51:28 - train: epoch 0023, iter [00560, 01251], lr: 0.001838, loss: 3.4990
2022-10-07 05:51:49 - train: epoch 0023, iter [00570, 01251], lr: 0.001838, loss: 3.7380
2022-10-07 05:52:10 - train: epoch 0023, iter [00580, 01251], lr: 0.001838, loss: 3.2100
2022-10-07 05:52:31 - train: epoch 0023, iter [00590, 01251], lr: 0.001838, loss: 3.2015
2022-10-07 05:52:53 - train: epoch 0023, iter [00600, 01251], lr: 0.001838, loss: 3.4191
2022-10-07 05:53:14 - train: epoch 0023, iter [00610, 01251], lr: 0.001837, loss: 3.2845
2022-10-07 05:53:35 - train: epoch 0023, iter [00620, 01251], lr: 0.001837, loss: 3.0959
2022-10-07 05:53:56 - train: epoch 0023, iter [00630, 01251], lr: 0.001837, loss: 3.5380
2022-10-07 05:54:18 - train: epoch 0023, iter [00640, 01251], lr: 0.001837, loss: 3.1090
2022-10-07 05:54:39 - train: epoch 0023, iter [00650, 01251], lr: 0.001837, loss: 3.2548
2022-10-07 05:55:00 - train: epoch 0023, iter [00660, 01251], lr: 0.001837, loss: 3.8572
2022-10-07 05:55:21 - train: epoch 0023, iter [00670, 01251], lr: 0.001837, loss: 3.3963
2022-10-07 05:55:43 - train: epoch 0023, iter [00680, 01251], lr: 0.001836, loss: 3.4999
2022-10-07 05:56:04 - train: epoch 0023, iter [00690, 01251], lr: 0.001836, loss: 3.3665
2022-10-07 05:56:25 - train: epoch 0023, iter [00700, 01251], lr: 0.001836, loss: 3.6286
2022-10-07 05:56:46 - train: epoch 0023, iter [00710, 01251], lr: 0.001836, loss: 3.4766
2022-10-07 05:57:08 - train: epoch 0023, iter [00720, 01251], lr: 0.001836, loss: 3.7603
2022-10-07 05:57:29 - train: epoch 0023, iter [00730, 01251], lr: 0.001836, loss: 3.6452
2022-10-07 05:57:50 - train: epoch 0023, iter [00740, 01251], lr: 0.001836, loss: 3.1222
2022-10-07 05:58:11 - train: epoch 0023, iter [00750, 01251], lr: 0.001835, loss: 3.9235
2022-10-07 05:58:33 - train: epoch 0023, iter [00760, 01251], lr: 0.001835, loss: 3.9290
2022-10-07 05:58:54 - train: epoch 0023, iter [00770, 01251], lr: 0.001835, loss: 3.4782
2022-10-07 05:59:15 - train: epoch 0023, iter [00780, 01251], lr: 0.001835, loss: 3.3755
2022-10-07 05:59:36 - train: epoch 0023, iter [00790, 01251], lr: 0.001835, loss: 3.0469
2022-10-07 05:59:57 - train: epoch 0023, iter [00800, 01251], lr: 0.001835, loss: 3.7197
2022-10-07 06:00:19 - train: epoch 0023, iter [00810, 01251], lr: 0.001835, loss: 3.7836
2022-10-07 06:00:40 - train: epoch 0023, iter [00820, 01251], lr: 0.001834, loss: 3.5883
2022-10-07 06:01:01 - train: epoch 0023, iter [00830, 01251], lr: 0.001834, loss: 3.6478
2022-10-07 06:01:22 - train: epoch 0023, iter [00840, 01251], lr: 0.001834, loss: 3.4687
2022-10-07 06:01:44 - train: epoch 0023, iter [00850, 01251], lr: 0.001834, loss: 3.8340
2022-10-07 06:02:05 - train: epoch 0023, iter [00860, 01251], lr: 0.001834, loss: 3.8100
2022-10-07 06:02:26 - train: epoch 0023, iter [00870, 01251], lr: 0.001834, loss: 2.4217
2022-10-07 06:02:47 - train: epoch 0023, iter [00880, 01251], lr: 0.001834, loss: 3.1618
2022-10-07 06:03:09 - train: epoch 0023, iter [00890, 01251], lr: 0.001833, loss: 3.7727
2022-10-07 06:03:30 - train: epoch 0023, iter [00900, 01251], lr: 0.001833, loss: 3.0398
2022-10-07 06:03:51 - train: epoch 0023, iter [00910, 01251], lr: 0.001833, loss: 3.4946
2022-10-07 06:04:12 - train: epoch 0023, iter [00920, 01251], lr: 0.001833, loss: 3.5201
2022-10-07 06:04:34 - train: epoch 0023, iter [00930, 01251], lr: 0.001833, loss: 3.7357
2022-10-07 06:04:55 - train: epoch 0023, iter [00940, 01251], lr: 0.001833, loss: 2.9821
2022-10-07 06:05:16 - train: epoch 0023, iter [00950, 01251], lr: 0.001833, loss: 3.8032
2022-10-07 06:05:37 - train: epoch 0023, iter [00960, 01251], lr: 0.001832, loss: 3.4074
2022-10-07 06:05:58 - train: epoch 0023, iter [00970, 01251], lr: 0.001832, loss: 3.9172
2022-10-07 06:06:20 - train: epoch 0023, iter [00980, 01251], lr: 0.001832, loss: 3.2856
2022-10-07 06:06:41 - train: epoch 0023, iter [00990, 01251], lr: 0.001832, loss: 3.3121
2022-10-07 06:07:02 - train: epoch 0023, iter [01000, 01251], lr: 0.001832, loss: 3.0289
2022-10-07 06:07:23 - train: epoch 0023, iter [01010, 01251], lr: 0.001832, loss: 3.9053
2022-10-07 06:07:45 - train: epoch 0023, iter [01020, 01251], lr: 0.001832, loss: 3.4031
2022-10-07 06:08:06 - train: epoch 0023, iter [01030, 01251], lr: 0.001831, loss: 3.4270
2022-10-07 06:08:27 - train: epoch 0023, iter [01040, 01251], lr: 0.001831, loss: 2.4350
2022-10-07 06:08:48 - train: epoch 0023, iter [01050, 01251], lr: 0.001831, loss: 3.8697
2022-10-07 06:09:09 - train: epoch 0023, iter [01060, 01251], lr: 0.001831, loss: 3.3214
2022-10-07 06:09:31 - train: epoch 0023, iter [01070, 01251], lr: 0.001831, loss: 3.7011
2022-10-07 06:09:52 - train: epoch 0023, iter [01080, 01251], lr: 0.001831, loss: 2.9795
2022-10-07 06:10:13 - train: epoch 0023, iter [01090, 01251], lr: 0.001830, loss: 3.4724
2022-10-07 06:10:35 - train: epoch 0023, iter [01100, 01251], lr: 0.001830, loss: 3.3090
2022-10-07 06:10:56 - train: epoch 0023, iter [01110, 01251], lr: 0.001830, loss: 3.5797
2022-10-07 06:11:17 - train: epoch 0023, iter [01120, 01251], lr: 0.001830, loss: 3.6548
2022-10-07 06:11:38 - train: epoch 0023, iter [01130, 01251], lr: 0.001830, loss: 3.4797
2022-10-07 06:12:00 - train: epoch 0023, iter [01140, 01251], lr: 0.001830, loss: 3.7564
2022-10-07 06:12:21 - train: epoch 0023, iter [01150, 01251], lr: 0.001830, loss: 3.8136
2022-10-07 06:12:42 - train: epoch 0023, iter [01160, 01251], lr: 0.001829, loss: 3.7236
2022-10-07 06:13:03 - train: epoch 0023, iter [01170, 01251], lr: 0.001829, loss: 3.0167
2022-10-07 06:13:24 - train: epoch 0023, iter [01180, 01251], lr: 0.001829, loss: 3.0551
2022-10-07 06:13:46 - train: epoch 0023, iter [01190, 01251], lr: 0.001829, loss: 3.9464
2022-10-07 06:14:07 - train: epoch 0023, iter [01200, 01251], lr: 0.001829, loss: 3.8011
2022-10-07 06:14:28 - train: epoch 0023, iter [01210, 01251], lr: 0.001829, loss: 3.8477
2022-10-07 06:14:49 - train: epoch 0023, iter [01220, 01251], lr: 0.001829, loss: 3.1211
2022-10-07 06:15:10 - train: epoch 0023, iter [01230, 01251], lr: 0.001828, loss: 3.7889
2022-10-07 06:15:32 - train: epoch 0023, iter [01240, 01251], lr: 0.001828, loss: 3.2556
2022-10-07 06:15:53 - train: epoch 0023, iter [01250, 01251], lr: 0.001828, loss: 3.3594
2022-10-07 06:15:56 - train: epoch 023, train_loss: 3.4390
2022-10-07 06:17:14 - eval: epoch: 023, acc1: 77.176%, acc5: 94.194%, test_loss: 0.9659, per_image_load_time: 1.301ms, per_image_inference_time: 1.444ms
2022-10-07 06:17:16 - until epoch: 023, best_acc1: 77.176%
2022-10-07 06:17:16 - epoch 024 lr: 0.001828
2022-10-07 06:17:43 - train: epoch 0024, iter [00010, 01251], lr: 0.001828, loss: 3.9030
2022-10-07 06:18:05 - train: epoch 0024, iter [00020, 01251], lr: 0.001828, loss: 2.7716
2022-10-07 06:18:26 - train: epoch 0024, iter [00030, 01251], lr: 0.001828, loss: 3.5349
2022-10-07 06:18:47 - train: epoch 0024, iter [00040, 01251], lr: 0.001828, loss: 3.3824
2022-10-07 06:19:08 - train: epoch 0024, iter [00050, 01251], lr: 0.001827, loss: 3.6802
2022-10-07 06:19:30 - train: epoch 0024, iter [00060, 01251], lr: 0.001827, loss: 3.5891
2022-10-07 06:19:51 - train: epoch 0024, iter [00070, 01251], lr: 0.001827, loss: 3.9274
2022-10-07 06:20:12 - train: epoch 0024, iter [00080, 01251], lr: 0.001827, loss: 3.3076
2022-10-07 06:20:34 - train: epoch 0024, iter [00090, 01251], lr: 0.001827, loss: 3.7594
2022-10-07 06:20:55 - train: epoch 0024, iter [00100, 01251], lr: 0.001827, loss: 3.0849
2022-10-07 06:21:16 - train: epoch 0024, iter [00110, 01251], lr: 0.001826, loss: 3.3319
2022-10-07 06:21:37 - train: epoch 0024, iter [00120, 01251], lr: 0.001826, loss: 3.1876
2022-10-07 06:21:59 - train: epoch 0024, iter [00130, 01251], lr: 0.001826, loss: 3.1426
2022-10-07 06:22:20 - train: epoch 0024, iter [00140, 01251], lr: 0.001826, loss: 3.1837
2022-10-07 06:22:41 - train: epoch 0024, iter [00150, 01251], lr: 0.001826, loss: 3.8830
2022-10-07 06:23:02 - train: epoch 0024, iter [00160, 01251], lr: 0.001826, loss: 3.2816
2022-10-07 06:23:23 - train: epoch 0024, iter [00170, 01251], lr: 0.001826, loss: 3.8309
2022-10-07 06:23:45 - train: epoch 0024, iter [00180, 01251], lr: 0.001825, loss: 3.6045
2022-10-07 06:24:06 - train: epoch 0024, iter [00190, 01251], lr: 0.001825, loss: 3.0858
2022-10-07 06:24:27 - train: epoch 0024, iter [00200, 01251], lr: 0.001825, loss: 2.9972
2022-10-07 06:24:48 - train: epoch 0024, iter [00210, 01251], lr: 0.001825, loss: 3.4417
2022-10-07 06:25:09 - train: epoch 0024, iter [00220, 01251], lr: 0.001825, loss: 3.1803
2022-10-07 06:25:31 - train: epoch 0024, iter [00230, 01251], lr: 0.001825, loss: 3.6459
2022-10-07 06:25:52 - train: epoch 0024, iter [00240, 01251], lr: 0.001825, loss: 2.8308
2022-10-07 06:26:13 - train: epoch 0024, iter [00250, 01251], lr: 0.001824, loss: 3.1312
2022-10-07 06:26:34 - train: epoch 0024, iter [00260, 01251], lr: 0.001824, loss: 4.0099
2022-10-07 06:26:56 - train: epoch 0024, iter [00270, 01251], lr: 0.001824, loss: 3.2169
2022-10-07 06:27:17 - train: epoch 0024, iter [00280, 01251], lr: 0.001824, loss: 3.3929
2022-10-07 06:27:38 - train: epoch 0024, iter [00290, 01251], lr: 0.001824, loss: 3.4692
2022-10-07 06:27:59 - train: epoch 0024, iter [00300, 01251], lr: 0.001824, loss: 3.0797
2022-10-07 06:28:21 - train: epoch 0024, iter [00310, 01251], lr: 0.001823, loss: 3.4134
2022-10-07 06:28:42 - train: epoch 0024, iter [00320, 01251], lr: 0.001823, loss: 3.6970
2022-10-07 06:29:03 - train: epoch 0024, iter [00330, 01251], lr: 0.001823, loss: 3.1513
2022-10-07 06:29:24 - train: epoch 0024, iter [00340, 01251], lr: 0.001823, loss: 3.1729
2022-10-07 06:29:45 - train: epoch 0024, iter [00350, 01251], lr: 0.001823, loss: 2.8979
2022-10-07 06:30:07 - train: epoch 0024, iter [00360, 01251], lr: 0.001823, loss: 3.8068
2022-10-07 06:30:28 - train: epoch 0024, iter [00370, 01251], lr: 0.001823, loss: 3.6253
2022-10-07 06:30:49 - train: epoch 0024, iter [00380, 01251], lr: 0.001822, loss: 3.2080
2022-10-07 06:31:11 - train: epoch 0024, iter [00390, 01251], lr: 0.001822, loss: 3.5886
2022-10-07 06:31:32 - train: epoch 0024, iter [00400, 01251], lr: 0.001822, loss: 3.6698
2022-10-07 06:31:53 - train: epoch 0024, iter [00410, 01251], lr: 0.001822, loss: 3.0443
2022-10-07 06:32:14 - train: epoch 0024, iter [00420, 01251], lr: 0.001822, loss: 3.6288
2022-10-07 06:32:36 - train: epoch 0024, iter [00430, 01251], lr: 0.001822, loss: 3.7713
2022-10-07 06:32:57 - train: epoch 0024, iter [00440, 01251], lr: 0.001822, loss: 3.7067
2022-10-07 06:33:18 - train: epoch 0024, iter [00450, 01251], lr: 0.001821, loss: 3.4287
2022-10-07 06:33:40 - train: epoch 0024, iter [00460, 01251], lr: 0.001821, loss: 3.0986
2022-10-07 06:34:01 - train: epoch 0024, iter [00470, 01251], lr: 0.001821, loss: 3.3328
2022-10-07 06:34:22 - train: epoch 0024, iter [00480, 01251], lr: 0.001821, loss: 3.4305
2022-10-07 06:34:43 - train: epoch 0024, iter [00490, 01251], lr: 0.001821, loss: 3.8392
2022-10-07 06:35:05 - train: epoch 0024, iter [00500, 01251], lr: 0.001821, loss: 3.3728
2022-10-07 06:35:26 - train: epoch 0024, iter [00510, 01251], lr: 0.001820, loss: 3.1143
2022-10-07 06:35:47 - train: epoch 0024, iter [00520, 01251], lr: 0.001820, loss: 2.7903
2022-10-07 06:36:08 - train: epoch 0024, iter [00530, 01251], lr: 0.001820, loss: 2.9816
2022-10-07 06:36:30 - train: epoch 0024, iter [00540, 01251], lr: 0.001820, loss: 3.0541
2022-10-07 06:36:51 - train: epoch 0024, iter [00550, 01251], lr: 0.001820, loss: 3.9666
2022-10-07 06:37:12 - train: epoch 0024, iter [00560, 01251], lr: 0.001820, loss: 3.8679
2022-10-07 06:37:33 - train: epoch 0024, iter [00570, 01251], lr: 0.001820, loss: 3.2681
2022-10-07 06:37:55 - train: epoch 0024, iter [00580, 01251], lr: 0.001819, loss: 3.6597
2022-10-07 06:38:16 - train: epoch 0024, iter [00590, 01251], lr: 0.001819, loss: 3.9211
2022-10-07 06:38:37 - train: epoch 0024, iter [00600, 01251], lr: 0.001819, loss: 3.6094
2022-10-07 06:38:58 - train: epoch 0024, iter [00610, 01251], lr: 0.001819, loss: 3.5904
2022-10-07 06:39:19 - train: epoch 0024, iter [00620, 01251], lr: 0.001819, loss: 3.5265
2022-10-07 06:39:41 - train: epoch 0024, iter [00630, 01251], lr: 0.001819, loss: 3.2117
2022-10-07 06:40:02 - train: epoch 0024, iter [00640, 01251], lr: 0.001818, loss: 3.0672
2022-10-07 06:40:23 - train: epoch 0024, iter [00650, 01251], lr: 0.001818, loss: 2.9448
2022-10-07 06:40:44 - train: epoch 0024, iter [00660, 01251], lr: 0.001818, loss: 3.5080
2022-10-07 06:41:05 - train: epoch 0024, iter [00670, 01251], lr: 0.001818, loss: 3.1264
2022-10-07 06:41:27 - train: epoch 0024, iter [00680, 01251], lr: 0.001818, loss: 3.5157
2022-10-07 06:41:48 - train: epoch 0024, iter [00690, 01251], lr: 0.001818, loss: 3.7470
2022-10-07 06:42:09 - train: epoch 0024, iter [00700, 01251], lr: 0.001818, loss: 3.0616
2022-10-07 06:42:30 - train: epoch 0024, iter [00710, 01251], lr: 0.001817, loss: 3.9819
2022-10-07 06:42:52 - train: epoch 0024, iter [00720, 01251], lr: 0.001817, loss: 3.7047
2022-10-07 06:43:13 - train: epoch 0024, iter [00730, 01251], lr: 0.001817, loss: 3.3676
2022-10-07 06:43:34 - train: epoch 0024, iter [00740, 01251], lr: 0.001817, loss: 3.3567
2022-10-07 06:43:55 - train: epoch 0024, iter [00750, 01251], lr: 0.001817, loss: 3.7084
2022-10-07 06:44:16 - train: epoch 0024, iter [00760, 01251], lr: 0.001817, loss: 3.3727
2022-10-07 06:44:38 - train: epoch 0024, iter [00770, 01251], lr: 0.001817, loss: 2.9752
2022-10-07 06:44:59 - train: epoch 0024, iter [00780, 01251], lr: 0.001816, loss: 4.0571
2022-10-07 06:45:20 - train: epoch 0024, iter [00790, 01251], lr: 0.001816, loss: 3.2120
2022-10-07 06:45:41 - train: epoch 0024, iter [00800, 01251], lr: 0.001816, loss: 3.7699
2022-10-07 06:46:02 - train: epoch 0024, iter [00810, 01251], lr: 0.001816, loss: 3.3964
2022-10-07 06:46:24 - train: epoch 0024, iter [00820, 01251], lr: 0.001816, loss: 4.1052
2022-10-07 06:46:45 - train: epoch 0024, iter [00830, 01251], lr: 0.001816, loss: 3.2304
2022-10-07 06:47:06 - train: epoch 0024, iter [00840, 01251], lr: 0.001815, loss: 4.2211
2022-10-07 06:47:27 - train: epoch 0024, iter [00850, 01251], lr: 0.001815, loss: 3.3396
2022-10-07 06:47:49 - train: epoch 0024, iter [00860, 01251], lr: 0.001815, loss: 3.1603
2022-10-07 06:48:10 - train: epoch 0024, iter [00870, 01251], lr: 0.001815, loss: 3.1810
2022-10-07 06:48:31 - train: epoch 0024, iter [00880, 01251], lr: 0.001815, loss: 3.6281
2022-10-07 06:48:52 - train: epoch 0024, iter [00890, 01251], lr: 0.001815, loss: 2.8825
2022-10-07 06:49:14 - train: epoch 0024, iter [00900, 01251], lr: 0.001815, loss: 3.3327
2022-10-07 06:49:35 - train: epoch 0024, iter [00910, 01251], lr: 0.001814, loss: 3.7072
2022-10-07 06:49:56 - train: epoch 0024, iter [00920, 01251], lr: 0.001814, loss: 3.9633
2022-10-07 06:50:17 - train: epoch 0024, iter [00930, 01251], lr: 0.001814, loss: 3.3186
2022-10-07 06:50:38 - train: epoch 0024, iter [00940, 01251], lr: 0.001814, loss: 2.9254
2022-10-07 06:51:00 - train: epoch 0024, iter [00950, 01251], lr: 0.001814, loss: 3.4630
2022-10-07 06:51:21 - train: epoch 0024, iter [00960, 01251], lr: 0.001814, loss: 3.4519
2022-10-07 06:51:42 - train: epoch 0024, iter [00970, 01251], lr: 0.001813, loss: 3.6725
2022-10-07 06:52:03 - train: epoch 0024, iter [00980, 01251], lr: 0.001813, loss: 3.5218
2022-10-07 06:52:24 - train: epoch 0024, iter [00990, 01251], lr: 0.001813, loss: 3.0000
2022-10-07 06:52:46 - train: epoch 0024, iter [01000, 01251], lr: 0.001813, loss: 3.3296
2022-10-07 06:53:07 - train: epoch 0024, iter [01010, 01251], lr: 0.001813, loss: 3.6586
2022-10-07 06:53:28 - train: epoch 0024, iter [01020, 01251], lr: 0.001813, loss: 3.3543
2022-10-07 06:53:49 - train: epoch 0024, iter [01030, 01251], lr: 0.001813, loss: 3.6851
2022-10-07 06:54:11 - train: epoch 0024, iter [01040, 01251], lr: 0.001812, loss: 2.9150
2022-10-07 06:54:32 - train: epoch 0024, iter [01050, 01251], lr: 0.001812, loss: 2.7381
2022-10-07 06:54:53 - train: epoch 0024, iter [01060, 01251], lr: 0.001812, loss: 3.7698
2022-10-07 06:55:14 - train: epoch 0024, iter [01070, 01251], lr: 0.001812, loss: 3.5551
2022-10-07 06:55:36 - train: epoch 0024, iter [01080, 01251], lr: 0.001812, loss: 3.3758
2022-10-07 06:55:57 - train: epoch 0024, iter [01090, 01251], lr: 0.001812, loss: 3.6495
2022-10-07 06:56:18 - train: epoch 0024, iter [01100, 01251], lr: 0.001811, loss: 3.1310
2022-10-07 06:56:39 - train: epoch 0024, iter [01110, 01251], lr: 0.001811, loss: 3.7976
2022-10-07 06:57:00 - train: epoch 0024, iter [01120, 01251], lr: 0.001811, loss: 2.8756
2022-10-07 06:57:22 - train: epoch 0024, iter [01130, 01251], lr: 0.001811, loss: 2.5881
2022-10-07 06:57:43 - train: epoch 0024, iter [01140, 01251], lr: 0.001811, loss: 3.6405
2022-10-07 06:58:04 - train: epoch 0024, iter [01150, 01251], lr: 0.001811, loss: 3.5766
2022-10-07 06:58:25 - train: epoch 0024, iter [01160, 01251], lr: 0.001811, loss: 3.5396
2022-10-07 06:58:47 - train: epoch 0024, iter [01170, 01251], lr: 0.001810, loss: 3.6673
2022-10-07 06:59:08 - train: epoch 0024, iter [01180, 01251], lr: 0.001810, loss: 3.0434
2022-10-07 06:59:29 - train: epoch 0024, iter [01190, 01251], lr: 0.001810, loss: 3.0920
2022-10-07 06:59:50 - train: epoch 0024, iter [01200, 01251], lr: 0.001810, loss: 3.4185
2022-10-07 07:00:12 - train: epoch 0024, iter [01210, 01251], lr: 0.001810, loss: 2.9586
2022-10-07 07:00:33 - train: epoch 0024, iter [01220, 01251], lr: 0.001810, loss: 3.8954
2022-10-07 07:00:54 - train: epoch 0024, iter [01230, 01251], lr: 0.001809, loss: 3.9450
2022-10-07 07:01:15 - train: epoch 0024, iter [01240, 01251], lr: 0.001809, loss: 3.9460
2022-10-07 07:01:36 - train: epoch 0024, iter [01250, 01251], lr: 0.001809, loss: 3.4841
2022-10-07 07:01:40 - train: epoch 024, train_loss: 3.4299
2022-10-07 07:02:58 - eval: epoch: 024, acc1: 77.568%, acc5: 94.316%, test_loss: 0.9560, per_image_load_time: 1.428ms, per_image_inference_time: 1.452ms
2022-10-07 07:03:00 - until epoch: 024, best_acc1: 77.568%
2022-10-07 07:03:00 - epoch 025 lr: 0.001809
2022-10-07 07:03:27 - train: epoch 0025, iter [00010, 01251], lr: 0.001809, loss: 2.6753
2022-10-07 07:03:48 - train: epoch 0025, iter [00020, 01251], lr: 0.001809, loss: 3.0537
2022-10-07 07:04:09 - train: epoch 0025, iter [00030, 01251], lr: 0.001809, loss: 3.5522
2022-10-07 07:04:31 - train: epoch 0025, iter [00040, 01251], lr: 0.001808, loss: 3.3873
2022-10-07 07:04:52 - train: epoch 0025, iter [00050, 01251], lr: 0.001808, loss: 3.1549
2022-10-07 07:05:13 - train: epoch 0025, iter [00060, 01251], lr: 0.001808, loss: 3.4777
2022-10-07 07:05:34 - train: epoch 0025, iter [00070, 01251], lr: 0.001808, loss: 3.3989
2022-10-07 07:05:56 - train: epoch 0025, iter [00080, 01251], lr: 0.001808, loss: 3.0644
2022-10-07 07:06:17 - train: epoch 0025, iter [00090, 01251], lr: 0.001808, loss: 3.5444
2022-10-07 07:06:38 - train: epoch 0025, iter [00100, 01251], lr: 0.001808, loss: 3.8467
2022-10-07 07:06:59 - train: epoch 0025, iter [00110, 01251], lr: 0.001807, loss: 3.3667
2022-10-07 07:07:21 - train: epoch 0025, iter [00120, 01251], lr: 0.001807, loss: 2.8034
2022-10-07 07:07:42 - train: epoch 0025, iter [00130, 01251], lr: 0.001807, loss: 3.0405
2022-10-07 07:08:03 - train: epoch 0025, iter [00140, 01251], lr: 0.001807, loss: 2.9108
2022-10-07 07:08:24 - train: epoch 0025, iter [00150, 01251], lr: 0.001807, loss: 3.9752
2022-10-07 07:08:46 - train: epoch 0025, iter [00160, 01251], lr: 0.001807, loss: 3.6617
2022-10-07 07:09:07 - train: epoch 0025, iter [00170, 01251], lr: 0.001806, loss: 3.4591
2022-10-07 07:09:28 - train: epoch 0025, iter [00180, 01251], lr: 0.001806, loss: 3.3556
2022-10-07 07:09:49 - train: epoch 0025, iter [00190, 01251], lr: 0.001806, loss: 3.8653
2022-10-07 07:10:11 - train: epoch 0025, iter [00200, 01251], lr: 0.001806, loss: 2.6459
2022-10-07 07:10:32 - train: epoch 0025, iter [00210, 01251], lr: 0.001806, loss: 2.4875
2022-10-07 07:10:53 - train: epoch 0025, iter [00220, 01251], lr: 0.001806, loss: 3.7384
2022-10-07 07:11:14 - train: epoch 0025, iter [00230, 01251], lr: 0.001806, loss: 3.1461
2022-10-07 07:11:35 - train: epoch 0025, iter [00240, 01251], lr: 0.001805, loss: 3.4619
2022-10-07 07:11:56 - train: epoch 0025, iter [00250, 01251], lr: 0.001805, loss: 3.2986
2022-10-07 07:12:18 - train: epoch 0025, iter [00260, 01251], lr: 0.001805, loss: 3.6732
2022-10-07 07:12:39 - train: epoch 0025, iter [00270, 01251], lr: 0.001805, loss: 3.7825
2022-10-07 07:13:00 - train: epoch 0025, iter [00280, 01251], lr: 0.001805, loss: 4.0086
2022-10-07 07:13:21 - train: epoch 0025, iter [00290, 01251], lr: 0.001805, loss: 2.7088
2022-10-07 07:13:43 - train: epoch 0025, iter [00300, 01251], lr: 0.001804, loss: 3.0823
2022-10-07 07:14:04 - train: epoch 0025, iter [00310, 01251], lr: 0.001804, loss: 3.6135
2022-10-07 07:14:25 - train: epoch 0025, iter [00320, 01251], lr: 0.001804, loss: 3.9458
2022-10-07 07:14:46 - train: epoch 0025, iter [00330, 01251], lr: 0.001804, loss: 3.4899
2022-10-07 07:15:08 - train: epoch 0025, iter [00340, 01251], lr: 0.001804, loss: 3.7835
2022-10-07 07:15:29 - train: epoch 0025, iter [00350, 01251], lr: 0.001804, loss: 3.7239
2022-10-07 07:15:50 - train: epoch 0025, iter [00360, 01251], lr: 0.001803, loss: 3.6046
2022-10-07 07:16:11 - train: epoch 0025, iter [00370, 01251], lr: 0.001803, loss: 3.2424
2022-10-07 07:16:32 - train: epoch 0025, iter [00380, 01251], lr: 0.001803, loss: 3.5115
2022-10-07 07:16:54 - train: epoch 0025, iter [00390, 01251], lr: 0.001803, loss: 2.8035
2022-10-07 07:17:15 - train: epoch 0025, iter [00400, 01251], lr: 0.001803, loss: 3.3373
2022-10-07 07:17:36 - train: epoch 0025, iter [00410, 01251], lr: 0.001803, loss: 3.4785
2022-10-07 07:17:57 - train: epoch 0025, iter [00420, 01251], lr: 0.001803, loss: 3.4067
2022-10-07 07:18:19 - train: epoch 0025, iter [00430, 01251], lr: 0.001802, loss: 3.3914
2022-10-07 07:18:40 - train: epoch 0025, iter [00440, 01251], lr: 0.001802, loss: 3.5664
2022-10-07 07:19:01 - train: epoch 0025, iter [00450, 01251], lr: 0.001802, loss: 3.4669
2022-10-07 07:19:22 - train: epoch 0025, iter [00460, 01251], lr: 0.001802, loss: 3.6842
2022-10-07 07:19:43 - train: epoch 0025, iter [00470, 01251], lr: 0.001802, loss: 2.7643
2022-10-07 07:20:05 - train: epoch 0025, iter [00480, 01251], lr: 0.001802, loss: 3.4040
2022-10-07 07:20:26 - train: epoch 0025, iter [00490, 01251], lr: 0.001801, loss: 3.1768
2022-10-07 07:20:47 - train: epoch 0025, iter [00500, 01251], lr: 0.001801, loss: 3.2082
2022-10-07 07:21:08 - train: epoch 0025, iter [00510, 01251], lr: 0.001801, loss: 2.9278
2022-10-07 07:21:30 - train: epoch 0025, iter [00520, 01251], lr: 0.001801, loss: 3.8441
2022-10-07 07:21:51 - train: epoch 0025, iter [00530, 01251], lr: 0.001801, loss: 2.9985
2022-10-07 07:22:12 - train: epoch 0025, iter [00540, 01251], lr: 0.001801, loss: 3.7403
2022-10-07 07:22:33 - train: epoch 0025, iter [00550, 01251], lr: 0.001800, loss: 2.9840
2022-10-07 07:22:54 - train: epoch 0025, iter [00560, 01251], lr: 0.001800, loss: 2.4638
2022-10-07 07:23:16 - train: epoch 0025, iter [00570, 01251], lr: 0.001800, loss: 3.0207
2022-10-07 07:23:37 - train: epoch 0025, iter [00580, 01251], lr: 0.001800, loss: 3.3709
2022-10-07 07:23:58 - train: epoch 0025, iter [00590, 01251], lr: 0.001800, loss: 3.8187
2022-10-07 07:24:19 - train: epoch 0025, iter [00600, 01251], lr: 0.001800, loss: 2.8431
2022-10-07 07:24:41 - train: epoch 0025, iter [00610, 01251], lr: 0.001800, loss: 3.0471
2022-10-07 07:25:02 - train: epoch 0025, iter [00620, 01251], lr: 0.001799, loss: 3.4797
2022-10-07 07:25:23 - train: epoch 0025, iter [00630, 01251], lr: 0.001799, loss: 3.6917
2022-10-07 07:25:44 - train: epoch 0025, iter [00640, 01251], lr: 0.001799, loss: 3.8060
2022-10-07 07:26:05 - train: epoch 0025, iter [00650, 01251], lr: 0.001799, loss: 3.8074
2022-10-07 07:26:27 - train: epoch 0025, iter [00660, 01251], lr: 0.001799, loss: 3.3636
2022-10-07 07:26:48 - train: epoch 0025, iter [00670, 01251], lr: 0.001799, loss: 4.2300
2022-10-07 07:27:09 - train: epoch 0025, iter [00680, 01251], lr: 0.001798, loss: 3.7390
2022-10-07 07:27:30 - train: epoch 0025, iter [00690, 01251], lr: 0.001798, loss: 3.7773
2022-10-07 07:27:52 - train: epoch 0025, iter [00700, 01251], lr: 0.001798, loss: 3.6210
2022-10-07 07:28:13 - train: epoch 0025, iter [00710, 01251], lr: 0.001798, loss: 3.5611
2022-10-07 07:28:34 - train: epoch 0025, iter [00720, 01251], lr: 0.001798, loss: 2.8819
2022-10-07 07:28:55 - train: epoch 0025, iter [00730, 01251], lr: 0.001798, loss: 3.2340
2022-10-07 07:29:17 - train: epoch 0025, iter [00740, 01251], lr: 0.001797, loss: 3.1766
2022-10-07 07:29:38 - train: epoch 0025, iter [00750, 01251], lr: 0.001797, loss: 3.2518
2022-10-07 07:29:59 - train: epoch 0025, iter [00760, 01251], lr: 0.001797, loss: 3.1946
2022-10-07 07:30:20 - train: epoch 0025, iter [00770, 01251], lr: 0.001797, loss: 3.4630
2022-10-07 07:30:42 - train: epoch 0025, iter [00780, 01251], lr: 0.001797, loss: 3.1215
2022-10-07 07:31:03 - train: epoch 0025, iter [00790, 01251], lr: 0.001797, loss: 3.6240
2022-10-07 07:31:24 - train: epoch 0025, iter [00800, 01251], lr: 0.001797, loss: 3.6924
2022-10-07 07:31:45 - train: epoch 0025, iter [00810, 01251], lr: 0.001796, loss: 3.1495
2022-10-07 07:32:07 - train: epoch 0025, iter [00820, 01251], lr: 0.001796, loss: 3.5129
2022-10-07 07:32:28 - train: epoch 0025, iter [00830, 01251], lr: 0.001796, loss: 3.0819
2022-10-07 07:32:49 - train: epoch 0025, iter [00840, 01251], lr: 0.001796, loss: 3.2089
2022-10-07 07:33:10 - train: epoch 0025, iter [00850, 01251], lr: 0.001796, loss: 3.6611
2022-10-07 07:33:32 - train: epoch 0025, iter [00860, 01251], lr: 0.001796, loss: 3.3293
2022-10-07 07:33:53 - train: epoch 0025, iter [00870, 01251], lr: 0.001795, loss: 3.3329
2022-10-07 07:34:14 - train: epoch 0025, iter [00880, 01251], lr: 0.001795, loss: 3.0277
2022-10-07 07:34:35 - train: epoch 0025, iter [00890, 01251], lr: 0.001795, loss: 2.7482
2022-10-07 07:34:57 - train: epoch 0025, iter [00900, 01251], lr: 0.001795, loss: 2.8591
2022-10-07 07:35:18 - train: epoch 0025, iter [00910, 01251], lr: 0.001795, loss: 3.1944
2022-10-07 07:35:39 - train: epoch 0025, iter [00920, 01251], lr: 0.001795, loss: 3.7601
2022-10-07 07:36:01 - train: epoch 0025, iter [00930, 01251], lr: 0.001794, loss: 3.5733
2022-10-07 07:36:22 - train: epoch 0025, iter [00940, 01251], lr: 0.001794, loss: 3.2139
2022-10-07 07:36:43 - train: epoch 0025, iter [00950, 01251], lr: 0.001794, loss: 3.7458
2022-10-07 07:37:04 - train: epoch 0025, iter [00960, 01251], lr: 0.001794, loss: 3.6472
2022-10-07 07:37:26 - train: epoch 0025, iter [00970, 01251], lr: 0.001794, loss: 3.8344
2022-10-07 07:37:47 - train: epoch 0025, iter [00980, 01251], lr: 0.001794, loss: 3.7976
2022-10-07 07:38:08 - train: epoch 0025, iter [00990, 01251], lr: 0.001793, loss: 3.6722
2022-10-07 07:38:30 - train: epoch 0025, iter [01000, 01251], lr: 0.001793, loss: 3.5583
2022-10-07 07:38:51 - train: epoch 0025, iter [01010, 01251], lr: 0.001793, loss: 3.6127
2022-10-07 07:39:12 - train: epoch 0025, iter [01020, 01251], lr: 0.001793, loss: 3.7594
2022-10-07 07:39:33 - train: epoch 0025, iter [01030, 01251], lr: 0.001793, loss: 3.6482
2022-10-07 07:39:55 - train: epoch 0025, iter [01040, 01251], lr: 0.001793, loss: 3.6444
2022-10-07 07:40:16 - train: epoch 0025, iter [01050, 01251], lr: 0.001792, loss: 3.9906
2022-10-07 07:40:37 - train: epoch 0025, iter [01060, 01251], lr: 0.001792, loss: 3.7842
2022-10-07 07:40:58 - train: epoch 0025, iter [01070, 01251], lr: 0.001792, loss: 3.1867
2022-10-07 07:41:20 - train: epoch 0025, iter [01080, 01251], lr: 0.001792, loss: 3.6802
2022-10-07 07:41:41 - train: epoch 0025, iter [01090, 01251], lr: 0.001792, loss: 3.2194
2022-10-07 07:42:02 - train: epoch 0025, iter [01100, 01251], lr: 0.001792, loss: 3.2731
2022-10-07 07:42:23 - train: epoch 0025, iter [01110, 01251], lr: 0.001792, loss: 3.0624
2022-10-07 07:42:45 - train: epoch 0025, iter [01120, 01251], lr: 0.001791, loss: 2.9627
2022-10-07 07:43:06 - train: epoch 0025, iter [01130, 01251], lr: 0.001791, loss: 3.4594
2022-10-07 07:43:27 - train: epoch 0025, iter [01140, 01251], lr: 0.001791, loss: 2.8827
2022-10-07 07:43:48 - train: epoch 0025, iter [01150, 01251], lr: 0.001791, loss: 3.2584
2022-10-07 07:44:10 - train: epoch 0025, iter [01160, 01251], lr: 0.001791, loss: 3.1355
2022-10-07 07:44:31 - train: epoch 0025, iter [01170, 01251], lr: 0.001791, loss: 3.2647
2022-10-07 07:44:52 - train: epoch 0025, iter [01180, 01251], lr: 0.001790, loss: 3.4372
2022-10-07 07:45:14 - train: epoch 0025, iter [01190, 01251], lr: 0.001790, loss: 3.3491
2022-10-07 07:45:35 - train: epoch 0025, iter [01200, 01251], lr: 0.001790, loss: 3.7392
2022-10-07 07:45:56 - train: epoch 0025, iter [01210, 01251], lr: 0.001790, loss: 3.1494
2022-10-07 07:46:17 - train: epoch 0025, iter [01220, 01251], lr: 0.001790, loss: 3.6682
2022-10-07 07:46:38 - train: epoch 0025, iter [01230, 01251], lr: 0.001790, loss: 3.7422
2022-10-07 07:47:00 - train: epoch 0025, iter [01240, 01251], lr: 0.001789, loss: 3.4295
2022-10-07 07:47:21 - train: epoch 0025, iter [01250, 01251], lr: 0.001789, loss: 3.4855
2022-10-07 07:47:24 - train: epoch 025, train_loss: 3.4151
2022-10-07 07:48:43 - eval: epoch: 025, acc1: 77.714%, acc5: 94.322%, test_loss: 0.9567, per_image_load_time: 1.453ms, per_image_inference_time: 1.444ms
2022-10-07 07:48:44 - until epoch: 025, best_acc1: 77.714%
2022-10-07 07:48:44 - epoch 026 lr: 0.001789
2022-10-07 07:49:12 - train: epoch 0026, iter [00010, 01251], lr: 0.001789, loss: 3.1638
2022-10-07 07:49:33 - train: epoch 0026, iter [00020, 01251], lr: 0.001789, loss: 3.4432
2022-10-07 07:49:55 - train: epoch 0026, iter [00030, 01251], lr: 0.001789, loss: 3.6125
2022-10-07 07:50:16 - train: epoch 0026, iter [00040, 01251], lr: 0.001789, loss: 3.6300
2022-10-07 07:50:37 - train: epoch 0026, iter [00050, 01251], lr: 0.001788, loss: 3.9401
2022-10-07 07:50:58 - train: epoch 0026, iter [00060, 01251], lr: 0.001788, loss: 3.6900
2022-10-07 07:51:19 - train: epoch 0026, iter [00070, 01251], lr: 0.001788, loss: 3.4905
2022-10-07 07:51:41 - train: epoch 0026, iter [00080, 01251], lr: 0.001788, loss: 3.6426
2022-10-07 07:52:02 - train: epoch 0026, iter [00090, 01251], lr: 0.001788, loss: 4.0796
2022-10-07 07:52:23 - train: epoch 0026, iter [00100, 01251], lr: 0.001788, loss: 2.9995
2022-10-07 07:52:44 - train: epoch 0026, iter [00110, 01251], lr: 0.001787, loss: 3.4412
2022-10-07 07:53:06 - train: epoch 0026, iter [00120, 01251], lr: 0.001787, loss: 3.1284
2022-10-07 07:53:27 - train: epoch 0026, iter [00130, 01251], lr: 0.001787, loss: 3.9146
2022-10-07 07:53:48 - train: epoch 0026, iter [00140, 01251], lr: 0.001787, loss: 3.6037
2022-10-07 07:54:09 - train: epoch 0026, iter [00150, 01251], lr: 0.001787, loss: 3.7404
2022-10-07 07:54:30 - train: epoch 0026, iter [00160, 01251], lr: 0.001787, loss: 3.8166
2022-10-07 07:54:51 - train: epoch 0026, iter [00170, 01251], lr: 0.001786, loss: 2.4278
2022-10-07 07:55:12 - train: epoch 0026, iter [00180, 01251], lr: 0.001786, loss: 3.3228
2022-10-07 07:55:34 - train: epoch 0026, iter [00190, 01251], lr: 0.001786, loss: 3.8659
2022-10-07 07:55:55 - train: epoch 0026, iter [00200, 01251], lr: 0.001786, loss: 3.7263
2022-10-07 07:56:16 - train: epoch 0026, iter [00210, 01251], lr: 0.001786, loss: 3.5723
2022-10-07 07:56:37 - train: epoch 0026, iter [00220, 01251], lr: 0.001786, loss: 3.4217
2022-10-07 07:56:58 - train: epoch 0026, iter [00230, 01251], lr: 0.001785, loss: 2.4500
2022-10-07 07:57:19 - train: epoch 0026, iter [00240, 01251], lr: 0.001785, loss: 3.5826
2022-10-07 07:57:40 - train: epoch 0026, iter [00250, 01251], lr: 0.001785, loss: 3.5299
2022-10-07 07:58:02 - train: epoch 0026, iter [00260, 01251], lr: 0.001785, loss: 3.7386
2022-10-07 07:58:23 - train: epoch 0026, iter [00270, 01251], lr: 0.001785, loss: 2.8782
2022-10-07 07:58:44 - train: epoch 0026, iter [00280, 01251], lr: 0.001785, loss: 3.4698
2022-10-07 07:59:05 - train: epoch 0026, iter [00290, 01251], lr: 0.001785, loss: 3.1798
2022-10-07 07:59:26 - train: epoch 0026, iter [00300, 01251], lr: 0.001784, loss: 2.8914
2022-10-07 07:59:48 - train: epoch 0026, iter [00310, 01251], lr: 0.001784, loss: 3.5758
2022-10-07 08:00:09 - train: epoch 0026, iter [00320, 01251], lr: 0.001784, loss: 3.9505
2022-10-07 08:00:30 - train: epoch 0026, iter [00330, 01251], lr: 0.001784, loss: 2.8013
2022-10-07 08:00:51 - train: epoch 0026, iter [00340, 01251], lr: 0.001784, loss: 3.5248
2022-10-07 08:01:12 - train: epoch 0026, iter [00350, 01251], lr: 0.001784, loss: 3.6574
2022-10-07 08:01:33 - train: epoch 0026, iter [00360, 01251], lr: 0.001783, loss: 3.7090
2022-10-07 08:01:54 - train: epoch 0026, iter [00370, 01251], lr: 0.001783, loss: 3.1084
2022-10-07 08:02:16 - train: epoch 0026, iter [00380, 01251], lr: 0.001783, loss: 3.7952
2022-10-07 08:02:37 - train: epoch 0026, iter [00390, 01251], lr: 0.001783, loss: 3.8840
2022-10-07 08:02:58 - train: epoch 0026, iter [00400, 01251], lr: 0.001783, loss: 3.1327
2022-10-07 08:03:19 - train: epoch 0026, iter [00410, 01251], lr: 0.001783, loss: 3.8340
2022-10-07 08:03:40 - train: epoch 0026, iter [00420, 01251], lr: 0.001782, loss: 3.0007
2022-10-07 08:04:01 - train: epoch 0026, iter [00430, 01251], lr: 0.001782, loss: 2.8068
2022-10-07 08:04:22 - train: epoch 0026, iter [00440, 01251], lr: 0.001782, loss: 3.7959
2022-10-07 08:04:43 - train: epoch 0026, iter [00450, 01251], lr: 0.001782, loss: 3.3195
2022-10-07 08:05:04 - train: epoch 0026, iter [00460, 01251], lr: 0.001782, loss: 3.4409
2022-10-07 08:05:26 - train: epoch 0026, iter [00470, 01251], lr: 0.001782, loss: 3.4589
2022-10-07 08:05:47 - train: epoch 0026, iter [00480, 01251], lr: 0.001781, loss: 3.7752
2022-10-07 08:06:08 - train: epoch 0026, iter [00490, 01251], lr: 0.001781, loss: 3.4075
2022-10-07 08:06:29 - train: epoch 0026, iter [00500, 01251], lr: 0.001781, loss: 3.3636
2022-10-07 08:06:50 - train: epoch 0026, iter [00510, 01251], lr: 0.001781, loss: 3.4695
2022-10-07 08:07:11 - train: epoch 0026, iter [00520, 01251], lr: 0.001781, loss: 3.0316
2022-10-07 08:07:32 - train: epoch 0026, iter [00530, 01251], lr: 0.001781, loss: 3.0614
2022-10-07 08:07:54 - train: epoch 0026, iter [00540, 01251], lr: 0.001780, loss: 3.8449
2022-10-07 08:08:15 - train: epoch 0026, iter [00550, 01251], lr: 0.001780, loss: 3.7030
2022-10-07 08:08:36 - train: epoch 0026, iter [00560, 01251], lr: 0.001780, loss: 3.7218
2022-10-07 08:08:57 - train: epoch 0026, iter [00570, 01251], lr: 0.001780, loss: 3.6037
2022-10-07 08:09:18 - train: epoch 0026, iter [00580, 01251], lr: 0.001780, loss: 3.9396
2022-10-07 08:09:39 - train: epoch 0026, iter [00590, 01251], lr: 0.001780, loss: 3.7633
2022-10-07 08:10:00 - train: epoch 0026, iter [00600, 01251], lr: 0.001779, loss: 3.2156
2022-10-07 08:10:22 - train: epoch 0026, iter [00610, 01251], lr: 0.001779, loss: 3.8916
2022-10-07 08:10:43 - train: epoch 0026, iter [00620, 01251], lr: 0.001779, loss: 3.0098
2022-10-07 08:11:04 - train: epoch 0026, iter [00630, 01251], lr: 0.001779, loss: 3.0674
2022-10-07 08:11:25 - train: epoch 0026, iter [00640, 01251], lr: 0.001779, loss: 3.6905
2022-10-07 08:11:46 - train: epoch 0026, iter [00650, 01251], lr: 0.001779, loss: 2.7533
2022-10-07 08:12:07 - train: epoch 0026, iter [00660, 01251], lr: 0.001778, loss: 3.1606
2022-10-07 08:12:28 - train: epoch 0026, iter [00670, 01251], lr: 0.001778, loss: 3.8335
2022-10-07 08:12:50 - train: epoch 0026, iter [00680, 01251], lr: 0.001778, loss: 3.7643
2022-10-07 08:13:11 - train: epoch 0026, iter [00690, 01251], lr: 0.001778, loss: 4.1656
2022-10-07 08:13:32 - train: epoch 0026, iter [00700, 01251], lr: 0.001778, loss: 3.3356
2022-10-07 08:13:53 - train: epoch 0026, iter [00710, 01251], lr: 0.001778, loss: 3.5730
2022-10-07 08:14:14 - train: epoch 0026, iter [00720, 01251], lr: 0.001777, loss: 2.9889
2022-10-07 08:14:35 - train: epoch 0026, iter [00730, 01251], lr: 0.001777, loss: 2.8464
2022-10-07 08:14:57 - train: epoch 0026, iter [00740, 01251], lr: 0.001777, loss: 4.0285
2022-10-07 08:15:18 - train: epoch 0026, iter [00750, 01251], lr: 0.001777, loss: 3.2334
2022-10-07 08:15:39 - train: epoch 0026, iter [00760, 01251], lr: 0.001777, loss: 3.0689
2022-10-07 08:16:00 - train: epoch 0026, iter [00770, 01251], lr: 0.001777, loss: 3.0903
2022-10-07 08:16:21 - train: epoch 0026, iter [00780, 01251], lr: 0.001776, loss: 3.2779
2022-10-07 08:16:42 - train: epoch 0026, iter [00790, 01251], lr: 0.001776, loss: 3.4605
2022-10-07 08:17:03 - train: epoch 0026, iter [00800, 01251], lr: 0.001776, loss: 3.8504
2022-10-07 08:17:24 - train: epoch 0026, iter [00810, 01251], lr: 0.001776, loss: 3.1631
2022-10-07 08:17:46 - train: epoch 0026, iter [00820, 01251], lr: 0.001776, loss: 3.6608
2022-10-07 08:18:07 - train: epoch 0026, iter [00830, 01251], lr: 0.001776, loss: 3.6125
2022-10-07 08:18:28 - train: epoch 0026, iter [00840, 01251], lr: 0.001775, loss: 3.5895
2022-10-07 08:18:49 - train: epoch 0026, iter [00850, 01251], lr: 0.001775, loss: 3.8386
2022-10-07 08:19:10 - train: epoch 0026, iter [00860, 01251], lr: 0.001775, loss: 3.2659
2022-10-07 08:19:32 - train: epoch 0026, iter [00870, 01251], lr: 0.001775, loss: 3.0754
2022-10-07 08:19:53 - train: epoch 0026, iter [00880, 01251], lr: 0.001775, loss: 3.3012
2022-10-07 08:20:14 - train: epoch 0026, iter [00890, 01251], lr: 0.001775, loss: 3.6761
2022-10-07 08:20:35 - train: epoch 0026, iter [00900, 01251], lr: 0.001774, loss: 3.7758
2022-10-07 08:20:56 - train: epoch 0026, iter [00910, 01251], lr: 0.001774, loss: 3.4695
2022-10-07 08:21:17 - train: epoch 0026, iter [00920, 01251], lr: 0.001774, loss: 3.2449
2022-10-07 08:21:39 - train: epoch 0026, iter [00930, 01251], lr: 0.001774, loss: 3.9054
2022-10-07 08:22:00 - train: epoch 0026, iter [00940, 01251], lr: 0.001774, loss: 3.0515
2022-10-07 08:22:21 - train: epoch 0026, iter [00950, 01251], lr: 0.001774, loss: 3.1752
2022-10-07 08:22:42 - train: epoch 0026, iter [00960, 01251], lr: 0.001773, loss: 3.5673
2022-10-07 08:23:03 - train: epoch 0026, iter [00970, 01251], lr: 0.001773, loss: 3.7028
2022-10-07 08:23:24 - train: epoch 0026, iter [00980, 01251], lr: 0.001773, loss: 2.8767
2022-10-07 08:23:45 - train: epoch 0026, iter [00990, 01251], lr: 0.001773, loss: 2.8029
2022-10-07 08:24:07 - train: epoch 0026, iter [01000, 01251], lr: 0.001773, loss: 3.8290
2022-10-07 08:24:28 - train: epoch 0026, iter [01010, 01251], lr: 0.001773, loss: 3.2814
2022-10-07 08:24:49 - train: epoch 0026, iter [01020, 01251], lr: 0.001772, loss: 3.2969
2022-10-07 08:25:10 - train: epoch 0026, iter [01030, 01251], lr: 0.001772, loss: 3.3691
2022-10-07 08:25:31 - train: epoch 0026, iter [01040, 01251], lr: 0.001772, loss: 3.6310
2022-10-07 08:25:53 - train: epoch 0026, iter [01050, 01251], lr: 0.001772, loss: 3.5409
2022-10-07 08:26:14 - train: epoch 0026, iter [01060, 01251], lr: 0.001772, loss: 3.6025
2022-10-07 08:26:35 - train: epoch 0026, iter [01070, 01251], lr: 0.001772, loss: 3.1860
2022-10-07 08:26:56 - train: epoch 0026, iter [01080, 01251], lr: 0.001771, loss: 3.7234
2022-10-07 08:27:17 - train: epoch 0026, iter [01090, 01251], lr: 0.001771, loss: 3.1696
2022-10-07 08:27:39 - train: epoch 0026, iter [01100, 01251], lr: 0.001771, loss: 3.1400
2022-10-07 08:28:00 - train: epoch 0026, iter [01110, 01251], lr: 0.001771, loss: 3.5660
2022-10-07 08:28:21 - train: epoch 0026, iter [01120, 01251], lr: 0.001771, loss: 2.8975
2022-10-07 08:28:42 - train: epoch 0026, iter [01130, 01251], lr: 0.001771, loss: 4.0417
2022-10-07 08:29:03 - train: epoch 0026, iter [01140, 01251], lr: 0.001770, loss: 2.9594
2022-10-07 08:29:24 - train: epoch 0026, iter [01150, 01251], lr: 0.001770, loss: 3.8924
2022-10-07 08:29:46 - train: epoch 0026, iter [01160, 01251], lr: 0.001770, loss: 3.8182
2022-10-07 08:30:07 - train: epoch 0026, iter [01170, 01251], lr: 0.001770, loss: 3.1796
2022-10-07 08:30:28 - train: epoch 0026, iter [01180, 01251], lr: 0.001770, loss: 3.7373
2022-10-07 08:30:49 - train: epoch 0026, iter [01190, 01251], lr: 0.001770, loss: 2.9948
2022-10-07 08:31:10 - train: epoch 0026, iter [01200, 01251], lr: 0.001769, loss: 3.5165
2022-10-07 08:31:31 - train: epoch 0026, iter [01210, 01251], lr: 0.001769, loss: 3.6881
2022-10-07 08:31:52 - train: epoch 0026, iter [01220, 01251], lr: 0.001769, loss: 3.2522
2022-10-07 08:32:14 - train: epoch 0026, iter [01230, 01251], lr: 0.001769, loss: 3.3265
2022-10-07 08:32:35 - train: epoch 0026, iter [01240, 01251], lr: 0.001769, loss: 3.5765
2022-10-07 08:32:56 - train: epoch 0026, iter [01250, 01251], lr: 0.001769, loss: 3.6449
2022-10-07 08:33:00 - train: epoch 026, train_loss: 3.3995
2022-10-07 08:34:18 - eval: epoch: 026, acc1: 77.846%, acc5: 94.532%, test_loss: 0.9546, per_image_load_time: 1.457ms, per_image_inference_time: 1.422ms
2022-10-07 08:34:19 - until epoch: 026, best_acc1: 77.846%
2022-10-07 08:34:19 - epoch 027 lr: 0.001769
2022-10-07 08:34:47 - train: epoch 0027, iter [00010, 01251], lr: 0.001768, loss: 3.3867
2022-10-07 08:35:08 - train: epoch 0027, iter [00020, 01251], lr: 0.001768, loss: 3.4349
2022-10-07 08:35:29 - train: epoch 0027, iter [00030, 01251], lr: 0.001768, loss: 3.9199
2022-10-07 08:35:50 - train: epoch 0027, iter [00040, 01251], lr: 0.001768, loss: 3.4109
2022-10-07 08:36:11 - train: epoch 0027, iter [00050, 01251], lr: 0.001768, loss: 3.5494
2022-10-07 08:36:32 - train: epoch 0027, iter [00060, 01251], lr: 0.001768, loss: 3.4569
2022-10-07 08:36:54 - train: epoch 0027, iter [00070, 01251], lr: 0.001767, loss: 3.8740
2022-10-07 08:37:15 - train: epoch 0027, iter [00080, 01251], lr: 0.001767, loss: 2.9112
2022-10-07 08:37:36 - train: epoch 0027, iter [00090, 01251], lr: 0.001767, loss: 3.7057
2022-10-07 08:37:57 - train: epoch 0027, iter [00100, 01251], lr: 0.001767, loss: 3.8314
2022-10-07 08:38:18 - train: epoch 0027, iter [00110, 01251], lr: 0.001767, loss: 3.8993
2022-10-07 08:38:39 - train: epoch 0027, iter [00120, 01251], lr: 0.001766, loss: 2.3341
2022-10-07 08:39:00 - train: epoch 0027, iter [00130, 01251], lr: 0.001766, loss: 3.4995
2022-10-07 08:39:21 - train: epoch 0027, iter [00140, 01251], lr: 0.001766, loss: 3.8052
2022-10-07 08:39:43 - train: epoch 0027, iter [00150, 01251], lr: 0.001766, loss: 3.7557
2022-10-07 08:40:04 - train: epoch 0027, iter [00160, 01251], lr: 0.001766, loss: 3.5233
2022-10-07 08:40:25 - train: epoch 0027, iter [00170, 01251], lr: 0.001766, loss: 3.4166
2022-10-07 08:40:46 - train: epoch 0027, iter [00180, 01251], lr: 0.001765, loss: 3.2108
2022-10-07 08:41:07 - train: epoch 0027, iter [00190, 01251], lr: 0.001765, loss: 3.5167
2022-10-07 08:41:28 - train: epoch 0027, iter [00200, 01251], lr: 0.001765, loss: 3.0592
2022-10-07 08:41:50 - train: epoch 0027, iter [00210, 01251], lr: 0.001765, loss: 3.6961
2022-10-07 08:42:11 - train: epoch 0027, iter [00220, 01251], lr: 0.001765, loss: 3.4872
2022-10-07 08:42:32 - train: epoch 0027, iter [00230, 01251], lr: 0.001765, loss: 3.8950
2022-10-07 08:42:53 - train: epoch 0027, iter [00240, 01251], lr: 0.001764, loss: 3.6779
2022-10-07 08:43:14 - train: epoch 0027, iter [00250, 01251], lr: 0.001764, loss: 2.9860
2022-10-07 08:43:35 - train: epoch 0027, iter [00260, 01251], lr: 0.001764, loss: 3.5029
2022-10-07 08:43:57 - train: epoch 0027, iter [00270, 01251], lr: 0.001764, loss: 3.1083
2022-10-07 08:44:18 - train: epoch 0027, iter [00280, 01251], lr: 0.001764, loss: 3.5331
2022-10-07 08:44:39 - train: epoch 0027, iter [00290, 01251], lr: 0.001764, loss: 3.2548
2022-10-07 08:45:00 - train: epoch 0027, iter [00300, 01251], lr: 0.001763, loss: 3.8006
2022-10-07 08:45:21 - train: epoch 0027, iter [00310, 01251], lr: 0.001763, loss: 3.7405
2022-10-07 08:45:42 - train: epoch 0027, iter [00320, 01251], lr: 0.001763, loss: 3.3541
2022-10-07 08:46:04 - train: epoch 0027, iter [00330, 01251], lr: 0.001763, loss: 3.4153
2022-10-07 08:46:25 - train: epoch 0027, iter [00340, 01251], lr: 0.001763, loss: 3.1335
2022-10-07 08:46:46 - train: epoch 0027, iter [00350, 01251], lr: 0.001763, loss: 2.9497
2022-10-07 08:47:07 - train: epoch 0027, iter [00360, 01251], lr: 0.001762, loss: 3.3623
2022-10-07 08:47:28 - train: epoch 0027, iter [00370, 01251], lr: 0.001762, loss: 3.9422
2022-10-07 08:47:49 - train: epoch 0027, iter [00380, 01251], lr: 0.001762, loss: 3.2643
2022-10-07 08:48:10 - train: epoch 0027, iter [00390, 01251], lr: 0.001762, loss: 3.9561
2022-10-07 08:48:31 - train: epoch 0027, iter [00400, 01251], lr: 0.001762, loss: 3.6600
2022-10-07 08:48:53 - train: epoch 0027, iter [00410, 01251], lr: 0.001762, loss: 3.2788
2022-10-07 08:49:14 - train: epoch 0027, iter [00420, 01251], lr: 0.001761, loss: 3.1703
2022-10-07 08:49:35 - train: epoch 0027, iter [00430, 01251], lr: 0.001761, loss: 3.4072
2022-10-07 08:49:56 - train: epoch 0027, iter [00440, 01251], lr: 0.001761, loss: 3.2761
2022-10-07 08:50:17 - train: epoch 0027, iter [00450, 01251], lr: 0.001761, loss: 3.6250
2022-10-07 08:50:38 - train: epoch 0027, iter [00460, 01251], lr: 0.001761, loss: 3.9638
2022-10-07 08:50:59 - train: epoch 0027, iter [00470, 01251], lr: 0.001761, loss: 3.1102
2022-10-07 08:51:20 - train: epoch 0027, iter [00480, 01251], lr: 0.001760, loss: 3.6274
2022-10-07 08:51:42 - train: epoch 0027, iter [00490, 01251], lr: 0.001760, loss: 3.4563
2022-10-07 08:52:03 - train: epoch 0027, iter [00500, 01251], lr: 0.001760, loss: 3.5241
2022-10-07 08:52:24 - train: epoch 0027, iter [00510, 01251], lr: 0.001760, loss: 3.0489
2022-10-07 08:52:45 - train: epoch 0027, iter [00520, 01251], lr: 0.001760, loss: 3.1304
2022-10-07 08:53:06 - train: epoch 0027, iter [00530, 01251], lr: 0.001759, loss: 3.5369
2022-10-07 08:53:27 - train: epoch 0027, iter [00540, 01251], lr: 0.001759, loss: 3.2460
2022-10-07 08:53:48 - train: epoch 0027, iter [00550, 01251], lr: 0.001759, loss: 3.7078
2022-10-07 08:54:10 - train: epoch 0027, iter [00560, 01251], lr: 0.001759, loss: 3.2278
2022-10-07 08:54:31 - train: epoch 0027, iter [00570, 01251], lr: 0.001759, loss: 3.7841
2022-10-07 08:54:52 - train: epoch 0027, iter [00580, 01251], lr: 0.001759, loss: 3.3372
2022-10-07 08:55:13 - train: epoch 0027, iter [00590, 01251], lr: 0.001758, loss: 3.8369
2022-10-07 08:55:34 - train: epoch 0027, iter [00600, 01251], lr: 0.001758, loss: 3.5250
2022-10-07 08:55:55 - train: epoch 0027, iter [00610, 01251], lr: 0.001758, loss: 3.7572
2022-10-07 08:56:16 - train: epoch 0027, iter [00620, 01251], lr: 0.001758, loss: 2.7662
2022-10-07 08:56:38 - train: epoch 0027, iter [00630, 01251], lr: 0.001758, loss: 3.6945
2022-10-07 08:56:59 - train: epoch 0027, iter [00640, 01251], lr: 0.001758, loss: 3.1493
2022-10-07 08:57:20 - train: epoch 0027, iter [00650, 01251], lr: 0.001757, loss: 3.5825
2022-10-07 08:57:41 - train: epoch 0027, iter [00660, 01251], lr: 0.001757, loss: 3.7285
2022-10-07 08:58:02 - train: epoch 0027, iter [00670, 01251], lr: 0.001757, loss: 3.8022
2022-10-07 08:58:23 - train: epoch 0027, iter [00680, 01251], lr: 0.001757, loss: 3.3289
2022-10-07 08:58:45 - train: epoch 0027, iter [00690, 01251], lr: 0.001757, loss: 3.8709
2022-10-07 08:59:06 - train: epoch 0027, iter [00700, 01251], lr: 0.001757, loss: 3.5524
2022-10-07 08:59:27 - train: epoch 0027, iter [00710, 01251], lr: 0.001756, loss: 3.3999
2022-10-07 08:59:48 - train: epoch 0027, iter [00720, 01251], lr: 0.001756, loss: 3.5367
2022-10-07 09:00:09 - train: epoch 0027, iter [00730, 01251], lr: 0.001756, loss: 3.9448
2022-10-07 09:00:31 - train: epoch 0027, iter [00740, 01251], lr: 0.001756, loss: 3.1642
2022-10-07 09:00:52 - train: epoch 0027, iter [00750, 01251], lr: 0.001756, loss: 3.8695
2022-10-07 09:01:13 - train: epoch 0027, iter [00760, 01251], lr: 0.001756, loss: 3.2987
2022-10-07 09:01:34 - train: epoch 0027, iter [00770, 01251], lr: 0.001755, loss: 3.7744
2022-10-07 09:01:55 - train: epoch 0027, iter [00780, 01251], lr: 0.001755, loss: 3.5946
2022-10-07 09:02:16 - train: epoch 0027, iter [00790, 01251], lr: 0.001755, loss: 3.5986
2022-10-07 09:02:37 - train: epoch 0027, iter [00800, 01251], lr: 0.001755, loss: 3.6189
2022-10-07 09:02:59 - train: epoch 0027, iter [00810, 01251], lr: 0.001755, loss: 3.8876
2022-10-07 09:03:20 - train: epoch 0027, iter [00820, 01251], lr: 0.001754, loss: 3.7709
2022-10-07 09:03:41 - train: epoch 0027, iter [00830, 01251], lr: 0.001754, loss: 3.4359
2022-10-07 09:04:02 - train: epoch 0027, iter [00840, 01251], lr: 0.001754, loss: 3.7374
2022-10-07 09:04:23 - train: epoch 0027, iter [00850, 01251], lr: 0.001754, loss: 3.4360
2022-10-07 09:04:45 - train: epoch 0027, iter [00860, 01251], lr: 0.001754, loss: 3.0300
2022-10-07 09:05:06 - train: epoch 0027, iter [00870, 01251], lr: 0.001754, loss: 3.3832
2022-10-07 09:05:27 - train: epoch 0027, iter [00880, 01251], lr: 0.001753, loss: 3.3575
2022-10-07 09:05:48 - train: epoch 0027, iter [00890, 01251], lr: 0.001753, loss: 3.5233
2022-10-07 09:06:09 - train: epoch 0027, iter [00900, 01251], lr: 0.001753, loss: 3.5426
2022-10-07 09:06:30 - train: epoch 0027, iter [00910, 01251], lr: 0.001753, loss: 2.9673
2022-10-07 09:06:52 - train: epoch 0027, iter [00920, 01251], lr: 0.001753, loss: 2.9922
2022-10-07 09:07:13 - train: epoch 0027, iter [00930, 01251], lr: 0.001753, loss: 3.2735
2022-10-07 09:07:34 - train: epoch 0027, iter [00940, 01251], lr: 0.001752, loss: 3.9385
2022-10-07 09:07:55 - train: epoch 0027, iter [00950, 01251], lr: 0.001752, loss: 3.0942
2022-10-07 09:08:16 - train: epoch 0027, iter [00960, 01251], lr: 0.001752, loss: 2.8373
2022-10-07 09:08:37 - train: epoch 0027, iter [00970, 01251], lr: 0.001752, loss: 3.5881
2022-10-07 09:08:59 - train: epoch 0027, iter [00980, 01251], lr: 0.001752, loss: 3.6592
2022-10-07 09:09:20 - train: epoch 0027, iter [00990, 01251], lr: 0.001752, loss: 3.5689
2022-10-07 09:09:41 - train: epoch 0027, iter [01000, 01251], lr: 0.001751, loss: 3.7750
2022-10-07 09:10:02 - train: epoch 0027, iter [01010, 01251], lr: 0.001751, loss: 3.4555
2022-10-07 09:10:23 - train: epoch 0027, iter [01020, 01251], lr: 0.001751, loss: 3.4540
2022-10-07 09:10:44 - train: epoch 0027, iter [01030, 01251], lr: 0.001751, loss: 3.3205
2022-10-07 09:11:06 - train: epoch 0027, iter [01040, 01251], lr: 0.001751, loss: 3.5769
2022-10-07 09:11:27 - train: epoch 0027, iter [01050, 01251], lr: 0.001750, loss: 3.2407
2022-10-07 09:11:48 - train: epoch 0027, iter [01060, 01251], lr: 0.001750, loss: 2.9329
2022-10-07 09:12:09 - train: epoch 0027, iter [01070, 01251], lr: 0.001750, loss: 3.5890
2022-10-07 09:12:30 - train: epoch 0027, iter [01080, 01251], lr: 0.001750, loss: 3.6848
2022-10-07 09:12:52 - train: epoch 0027, iter [01090, 01251], lr: 0.001750, loss: 3.6360
2022-10-07 09:13:13 - train: epoch 0027, iter [01100, 01251], lr: 0.001750, loss: 3.5550
2022-10-07 09:13:34 - train: epoch 0027, iter [01110, 01251], lr: 0.001749, loss: 3.8259
2022-10-07 09:13:55 - train: epoch 0027, iter [01120, 01251], lr: 0.001749, loss: 3.4361
2022-10-07 09:14:16 - train: epoch 0027, iter [01130, 01251], lr: 0.001749, loss: 3.2119
2022-10-07 09:14:38 - train: epoch 0027, iter [01140, 01251], lr: 0.001749, loss: 3.8121
2022-10-07 09:14:59 - train: epoch 0027, iter [01150, 01251], lr: 0.001749, loss: 3.6751
2022-10-07 09:15:20 - train: epoch 0027, iter [01160, 01251], lr: 0.001749, loss: 3.5406
2022-10-07 09:15:41 - train: epoch 0027, iter [01170, 01251], lr: 0.001748, loss: 3.2457
2022-10-07 09:16:02 - train: epoch 0027, iter [01180, 01251], lr: 0.001748, loss: 2.6631
2022-10-07 09:16:24 - train: epoch 0027, iter [01190, 01251], lr: 0.001748, loss: 3.5042
2022-10-07 09:16:45 - train: epoch 0027, iter [01200, 01251], lr: 0.001748, loss: 3.0913
2022-10-07 09:17:06 - train: epoch 0027, iter [01210, 01251], lr: 0.001748, loss: 3.1032
2022-10-07 09:17:27 - train: epoch 0027, iter [01220, 01251], lr: 0.001747, loss: 3.5378
2022-10-07 09:17:48 - train: epoch 0027, iter [01230, 01251], lr: 0.001747, loss: 3.6100
2022-10-07 09:18:09 - train: epoch 0027, iter [01240, 01251], lr: 0.001747, loss: 3.4102
2022-10-07 09:18:30 - train: epoch 0027, iter [01250, 01251], lr: 0.001747, loss: 2.5272
2022-10-07 09:18:34 - train: epoch 027, train_loss: 3.3896
2022-10-07 09:19:52 - eval: epoch: 027, acc1: 78.040%, acc5: 94.466%, test_loss: 0.9372, per_image_load_time: 1.494ms, per_image_inference_time: 1.430ms
2022-10-07 09:19:53 - until epoch: 027, best_acc1: 78.040%
2022-10-07 09:19:53 - epoch 028 lr: 0.001747
2022-10-07 09:20:21 - train: epoch 0028, iter [00010, 01251], lr: 0.001747, loss: 3.7628
2022-10-07 09:20:42 - train: epoch 0028, iter [00020, 01251], lr: 0.001747, loss: 3.3160
2022-10-07 09:21:03 - train: epoch 0028, iter [00030, 01251], lr: 0.001746, loss: 3.3496
2022-10-07 09:21:24 - train: epoch 0028, iter [00040, 01251], lr: 0.001746, loss: 3.2148
2022-10-07 09:21:45 - train: epoch 0028, iter [00050, 01251], lr: 0.001746, loss: 3.2592
2022-10-07 09:22:06 - train: epoch 0028, iter [00060, 01251], lr: 0.001746, loss: 2.8488
2022-10-07 09:22:28 - train: epoch 0028, iter [00070, 01251], lr: 0.001746, loss: 3.7227
2022-10-07 09:22:49 - train: epoch 0028, iter [00080, 01251], lr: 0.001746, loss: 3.2287
2022-10-07 09:23:10 - train: epoch 0028, iter [00090, 01251], lr: 0.001745, loss: 2.6185
2022-10-07 09:23:31 - train: epoch 0028, iter [00100, 01251], lr: 0.001745, loss: 3.6623
2022-10-07 09:23:52 - train: epoch 0028, iter [00110, 01251], lr: 0.001745, loss: 2.9253
2022-10-07 09:24:14 - train: epoch 0028, iter [00120, 01251], lr: 0.001745, loss: 3.2516
2022-10-07 09:24:35 - train: epoch 0028, iter [00130, 01251], lr: 0.001745, loss: 3.4134
2022-10-07 09:24:56 - train: epoch 0028, iter [00140, 01251], lr: 0.001744, loss: 3.6720
2022-10-07 09:25:17 - train: epoch 0028, iter [00150, 01251], lr: 0.001744, loss: 3.7173
2022-10-07 09:25:38 - train: epoch 0028, iter [00160, 01251], lr: 0.001744, loss: 3.2671
2022-10-07 09:25:59 - train: epoch 0028, iter [00170, 01251], lr: 0.001744, loss: 3.8031
2022-10-07 09:26:21 - train: epoch 0028, iter [00180, 01251], lr: 0.001744, loss: 3.5866
2022-10-07 09:26:42 - train: epoch 0028, iter [00190, 01251], lr: 0.001744, loss: 3.8237
2022-10-07 09:27:03 - train: epoch 0028, iter [00200, 01251], lr: 0.001743, loss: 3.6609
2022-10-07 09:27:24 - train: epoch 0028, iter [00210, 01251], lr: 0.001743, loss: 3.2425
2022-10-07 09:27:45 - train: epoch 0028, iter [00220, 01251], lr: 0.001743, loss: 2.6391
2022-10-07 09:28:07 - train: epoch 0028, iter [00230, 01251], lr: 0.001743, loss: 3.4913
2022-10-07 09:28:28 - train: epoch 0028, iter [00240, 01251], lr: 0.001743, loss: 3.6328
2022-10-07 09:28:49 - train: epoch 0028, iter [00250, 01251], lr: 0.001743, loss: 3.1743
2022-10-07 09:29:10 - train: epoch 0028, iter [00260, 01251], lr: 0.001742, loss: 3.1207
2022-10-07 09:29:31 - train: epoch 0028, iter [00270, 01251], lr: 0.001742, loss: 3.7217
2022-10-07 09:29:52 - train: epoch 0028, iter [00280, 01251], lr: 0.001742, loss: 3.8976
2022-10-07 09:30:14 - train: epoch 0028, iter [00290, 01251], lr: 0.001742, loss: 3.4882
2022-10-07 09:30:35 - train: epoch 0028, iter [00300, 01251], lr: 0.001742, loss: 3.2130
2022-10-07 09:30:56 - train: epoch 0028, iter [00310, 01251], lr: 0.001741, loss: 3.5775
2022-10-07 09:31:17 - train: epoch 0028, iter [00320, 01251], lr: 0.001741, loss: 3.8880
2022-10-07 09:31:38 - train: epoch 0028, iter [00330, 01251], lr: 0.001741, loss: 3.5543
2022-10-07 09:31:59 - train: epoch 0028, iter [00340, 01251], lr: 0.001741, loss: 2.8831
2022-10-07 09:32:21 - train: epoch 0028, iter [00350, 01251], lr: 0.001741, loss: 3.2579
2022-10-07 09:32:42 - train: epoch 0028, iter [00360, 01251], lr: 0.001741, loss: 2.7955
2022-10-07 09:33:03 - train: epoch 0028, iter [00370, 01251], lr: 0.001740, loss: 3.3189
2022-10-07 09:33:24 - train: epoch 0028, iter [00380, 01251], lr: 0.001740, loss: 3.5069
2022-10-07 09:33:45 - train: epoch 0028, iter [00390, 01251], lr: 0.001740, loss: 3.9083
2022-10-07 09:34:06 - train: epoch 0028, iter [00400, 01251], lr: 0.001740, loss: 2.9149
2022-10-07 09:34:28 - train: epoch 0028, iter [00410, 01251], lr: 0.001740, loss: 3.1560
2022-10-07 09:34:49 - train: epoch 0028, iter [00420, 01251], lr: 0.001740, loss: 3.3567
2022-10-07 09:35:10 - train: epoch 0028, iter [00430, 01251], lr: 0.001739, loss: 3.7299
2022-10-07 09:35:31 - train: epoch 0028, iter [00440, 01251], lr: 0.001739, loss: 3.1097
2022-10-07 09:35:53 - train: epoch 0028, iter [00450, 01251], lr: 0.001739, loss: 3.4711
2022-10-07 09:36:14 - train: epoch 0028, iter [00460, 01251], lr: 0.001739, loss: 3.4094
2022-10-07 09:36:35 - train: epoch 0028, iter [00470, 01251], lr: 0.001739, loss: 3.5455
2022-10-07 09:36:56 - train: epoch 0028, iter [00480, 01251], lr: 0.001738, loss: 3.4783
2022-10-07 09:37:18 - train: epoch 0028, iter [00490, 01251], lr: 0.001738, loss: 3.7368
2022-10-07 09:37:39 - train: epoch 0028, iter [00500, 01251], lr: 0.001738, loss: 3.2154
2022-10-07 09:38:00 - train: epoch 0028, iter [00510, 01251], lr: 0.001738, loss: 3.3424
2022-10-07 09:38:21 - train: epoch 0028, iter [00520, 01251], lr: 0.001738, loss: 3.1374
2022-10-07 09:38:43 - train: epoch 0028, iter [00530, 01251], lr: 0.001738, loss: 3.3564
2022-10-07 09:39:04 - train: epoch 0028, iter [00540, 01251], lr: 0.001737, loss: 3.5947
2022-10-07 09:39:25 - train: epoch 0028, iter [00550, 01251], lr: 0.001737, loss: 3.4224
2022-10-07 09:39:46 - train: epoch 0028, iter [00560, 01251], lr: 0.001737, loss: 3.0721
2022-10-07 09:40:08 - train: epoch 0028, iter [00570, 01251], lr: 0.001737, loss: 3.7032
2022-10-07 09:40:29 - train: epoch 0028, iter [00580, 01251], lr: 0.001737, loss: 3.1299
2022-10-07 09:40:50 - train: epoch 0028, iter [00590, 01251], lr: 0.001736, loss: 3.2397
2022-10-07 09:41:11 - train: epoch 0028, iter [00600, 01251], lr: 0.001736, loss: 3.6114
2022-10-07 09:41:33 - train: epoch 0028, iter [00610, 01251], lr: 0.001736, loss: 3.6549
2022-10-07 09:41:54 - train: epoch 0028, iter [00620, 01251], lr: 0.001736, loss: 3.5512
2022-10-07 09:42:15 - train: epoch 0028, iter [00630, 01251], lr: 0.001736, loss: 3.2845
2022-10-07 09:42:37 - train: epoch 0028, iter [00640, 01251], lr: 0.001736, loss: 3.3351
2022-10-07 09:42:58 - train: epoch 0028, iter [00650, 01251], lr: 0.001735, loss: 3.7551
2022-10-07 09:43:19 - train: epoch 0028, iter [00660, 01251], lr: 0.001735, loss: 3.2055
2022-10-07 09:43:40 - train: epoch 0028, iter [00670, 01251], lr: 0.001735, loss: 3.6958
2022-10-07 09:44:02 - train: epoch 0028, iter [00680, 01251], lr: 0.001735, loss: 3.4629
2022-10-07 09:44:23 - train: epoch 0028, iter [00690, 01251], lr: 0.001735, loss: 3.2226
2022-10-07 09:44:44 - train: epoch 0028, iter [00700, 01251], lr: 0.001735, loss: 2.8780
2022-10-07 09:45:06 - train: epoch 0028, iter [00710, 01251], lr: 0.001734, loss: 3.3704
2022-10-07 09:45:27 - train: epoch 0028, iter [00720, 01251], lr: 0.001734, loss: 3.2077
2022-10-07 09:45:48 - train: epoch 0028, iter [00730, 01251], lr: 0.001734, loss: 3.1507
2022-10-07 09:46:09 - train: epoch 0028, iter [00740, 01251], lr: 0.001734, loss: 3.9023
2022-10-07 09:46:31 - train: epoch 0028, iter [00750, 01251], lr: 0.001734, loss: 3.3237
2022-10-07 09:46:52 - train: epoch 0028, iter [00760, 01251], lr: 0.001733, loss: 3.2263
2022-10-07 09:47:13 - train: epoch 0028, iter [00770, 01251], lr: 0.001733, loss: 3.2427
2022-10-07 09:47:34 - train: epoch 0028, iter [00780, 01251], lr: 0.001733, loss: 3.3229
2022-10-07 09:47:56 - train: epoch 0028, iter [00790, 01251], lr: 0.001733, loss: 3.4397
2022-10-07 09:48:17 - train: epoch 0028, iter [00800, 01251], lr: 0.001733, loss: 3.3409
2022-10-07 09:48:38 - train: epoch 0028, iter [00810, 01251], lr: 0.001733, loss: 3.3876
2022-10-07 09:48:59 - train: epoch 0028, iter [00820, 01251], lr: 0.001732, loss: 3.2863
2022-10-07 09:49:21 - train: epoch 0028, iter [00830, 01251], lr: 0.001732, loss: 3.7495
2022-10-07 09:49:42 - train: epoch 0028, iter [00840, 01251], lr: 0.001732, loss: 3.6591
2022-10-07 09:50:03 - train: epoch 0028, iter [00850, 01251], lr: 0.001732, loss: 3.0010
2022-10-07 09:50:24 - train: epoch 0028, iter [00860, 01251], lr: 0.001732, loss: 3.6771
2022-10-07 09:50:46 - train: epoch 0028, iter [00870, 01251], lr: 0.001731, loss: 3.5337
2022-10-07 09:51:07 - train: epoch 0028, iter [00880, 01251], lr: 0.001731, loss: 3.2175
2022-10-07 09:51:28 - train: epoch 0028, iter [00890, 01251], lr: 0.001731, loss: 3.4787
2022-10-07 09:51:50 - train: epoch 0028, iter [00900, 01251], lr: 0.001731, loss: 2.9301
2022-10-07 09:52:11 - train: epoch 0028, iter [00910, 01251], lr: 0.001731, loss: 3.0697
2022-10-07 09:52:32 - train: epoch 0028, iter [00920, 01251], lr: 0.001731, loss: 3.2922
2022-10-07 09:52:53 - train: epoch 0028, iter [00930, 01251], lr: 0.001730, loss: 3.8161
2022-10-07 09:53:15 - train: epoch 0028, iter [00940, 01251], lr: 0.001730, loss: 3.0667
2022-10-07 09:53:36 - train: epoch 0028, iter [00950, 01251], lr: 0.001730, loss: 2.9219
2022-10-07 09:53:57 - train: epoch 0028, iter [00960, 01251], lr: 0.001730, loss: 3.5987
2022-10-07 09:54:19 - train: epoch 0028, iter [00970, 01251], lr: 0.001730, loss: 3.8952
2022-10-07 09:54:40 - train: epoch 0028, iter [00980, 01251], lr: 0.001729, loss: 3.9828
2022-10-07 09:55:01 - train: epoch 0028, iter [00990, 01251], lr: 0.001729, loss: 3.6536
2022-10-07 09:55:22 - train: epoch 0028, iter [01000, 01251], lr: 0.001729, loss: 2.5654
2022-10-07 09:55:44 - train: epoch 0028, iter [01010, 01251], lr: 0.001729, loss: 3.9461
2022-10-07 09:56:05 - train: epoch 0028, iter [01020, 01251], lr: 0.001729, loss: 3.4699
2022-10-07 09:56:26 - train: epoch 0028, iter [01030, 01251], lr: 0.001729, loss: 3.6624
2022-10-07 09:56:47 - train: epoch 0028, iter [01040, 01251], lr: 0.001728, loss: 3.4348
2022-10-07 09:57:09 - train: epoch 0028, iter [01050, 01251], lr: 0.001728, loss: 3.6860
2022-10-07 09:57:30 - train: epoch 0028, iter [01060, 01251], lr: 0.001728, loss: 3.4797
2022-10-07 09:57:51 - train: epoch 0028, iter [01070, 01251], lr: 0.001728, loss: 3.6569
2022-10-07 09:58:12 - train: epoch 0028, iter [01080, 01251], lr: 0.001728, loss: 3.4296
2022-10-07 09:58:34 - train: epoch 0028, iter [01090, 01251], lr: 0.001727, loss: 3.5025
2022-10-07 09:58:55 - train: epoch 0028, iter [01100, 01251], lr: 0.001727, loss: 2.7606
2022-10-07 09:59:16 - train: epoch 0028, iter [01110, 01251], lr: 0.001727, loss: 3.7180
2022-10-07 09:59:37 - train: epoch 0028, iter [01120, 01251], lr: 0.001727, loss: 3.8431
2022-10-07 09:59:59 - train: epoch 0028, iter [01130, 01251], lr: 0.001727, loss: 3.1641
2022-10-07 10:00:20 - train: epoch 0028, iter [01140, 01251], lr: 0.001727, loss: 3.5053
2022-10-07 10:00:41 - train: epoch 0028, iter [01150, 01251], lr: 0.001726, loss: 3.5301
2022-10-07 10:01:02 - train: epoch 0028, iter [01160, 01251], lr: 0.001726, loss: 3.8531
2022-10-07 10:01:24 - train: epoch 0028, iter [01170, 01251], lr: 0.001726, loss: 3.4754
2022-10-07 10:01:45 - train: epoch 0028, iter [01180, 01251], lr: 0.001726, loss: 3.1084
2022-10-07 10:02:06 - train: epoch 0028, iter [01190, 01251], lr: 0.001726, loss: 3.2564
2022-10-07 10:02:27 - train: epoch 0028, iter [01200, 01251], lr: 0.001725, loss: 3.1009
2022-10-07 10:02:49 - train: epoch 0028, iter [01210, 01251], lr: 0.001725, loss: 3.6168
2022-10-07 10:03:10 - train: epoch 0028, iter [01220, 01251], lr: 0.001725, loss: 2.9276
2022-10-07 10:03:31 - train: epoch 0028, iter [01230, 01251], lr: 0.001725, loss: 2.8025
2022-10-07 10:03:52 - train: epoch 0028, iter [01240, 01251], lr: 0.001725, loss: 2.8945
2022-10-07 10:04:13 - train: epoch 0028, iter [01250, 01251], lr: 0.001725, loss: 3.2144
2022-10-07 10:04:17 - train: epoch 028, train_loss: 3.3759
2022-10-07 10:05:33 - eval: epoch: 028, acc1: 78.544%, acc5: 94.602%, test_loss: 0.9290, per_image_load_time: 1.352ms, per_image_inference_time: 1.428ms
2022-10-07 10:05:35 - until epoch: 028, best_acc1: 78.544%
2022-10-07 10:05:35 - epoch 029 lr: 0.001725
2022-10-07 10:06:02 - train: epoch 0029, iter [00010, 01251], lr: 0.001724, loss: 3.2986
2022-10-07 10:06:23 - train: epoch 0029, iter [00020, 01251], lr: 0.001724, loss: 3.2757
2022-10-07 10:06:44 - train: epoch 0029, iter [00030, 01251], lr: 0.001724, loss: 2.3415
2022-10-07 10:07:05 - train: epoch 0029, iter [00040, 01251], lr: 0.001724, loss: 2.6820
2022-10-07 10:07:27 - train: epoch 0029, iter [00050, 01251], lr: 0.001724, loss: 3.4153
2022-10-07 10:07:48 - train: epoch 0029, iter [00060, 01251], lr: 0.001723, loss: 2.9780
2022-10-07 10:08:09 - train: epoch 0029, iter [00070, 01251], lr: 0.001723, loss: 3.0436
2022-10-07 10:08:31 - train: epoch 0029, iter [00080, 01251], lr: 0.001723, loss: 3.3066
2022-10-07 10:08:52 - train: epoch 0029, iter [00090, 01251], lr: 0.001723, loss: 3.7443
2022-10-07 10:09:13 - train: epoch 0029, iter [00100, 01251], lr: 0.001723, loss: 3.8300
2022-10-07 10:09:35 - train: epoch 0029, iter [00110, 01251], lr: 0.001723, loss: 2.9144
2022-10-07 10:09:56 - train: epoch 0029, iter [00120, 01251], lr: 0.001722, loss: 3.7400
2022-10-07 10:10:17 - train: epoch 0029, iter [00130, 01251], lr: 0.001722, loss: 3.0449
2022-10-07 10:10:39 - train: epoch 0029, iter [00140, 01251], lr: 0.001722, loss: 3.5880
2022-10-07 10:11:00 - train: epoch 0029, iter [00150, 01251], lr: 0.001722, loss: 3.3238
2022-10-07 10:11:21 - train: epoch 0029, iter [00160, 01251], lr: 0.001722, loss: 3.6230
2022-10-07 10:11:42 - train: epoch 0029, iter [00170, 01251], lr: 0.001721, loss: 2.8926
2022-10-07 10:12:03 - train: epoch 0029, iter [00180, 01251], lr: 0.001721, loss: 3.6729
2022-10-07 10:12:25 - train: epoch 0029, iter [00190, 01251], lr: 0.001721, loss: 2.9853
2022-10-07 10:12:46 - train: epoch 0029, iter [00200, 01251], lr: 0.001721, loss: 2.9280
2022-10-07 10:13:07 - train: epoch 0029, iter [00210, 01251], lr: 0.001721, loss: 3.6534
2022-10-07 10:13:29 - train: epoch 0029, iter [00220, 01251], lr: 0.001721, loss: 2.9258
2022-10-07 10:13:50 - train: epoch 0029, iter [00230, 01251], lr: 0.001720, loss: 3.6358
2022-10-07 10:14:11 - train: epoch 0029, iter [00240, 01251], lr: 0.001720, loss: 3.3701
2022-10-07 10:14:33 - train: epoch 0029, iter [00250, 01251], lr: 0.001720, loss: 3.9617
2022-10-07 10:14:54 - train: epoch 0029, iter [00260, 01251], lr: 0.001720, loss: 3.3979
2022-10-07 10:15:15 - train: epoch 0029, iter [00270, 01251], lr: 0.001720, loss: 3.1355
2022-10-07 10:15:36 - train: epoch 0029, iter [00280, 01251], lr: 0.001719, loss: 3.0897
2022-10-07 10:15:58 - train: epoch 0029, iter [00290, 01251], lr: 0.001719, loss: 3.1227
2022-10-07 10:16:19 - train: epoch 0029, iter [00300, 01251], lr: 0.001719, loss: 3.2062
2022-10-07 10:16:40 - train: epoch 0029, iter [00310, 01251], lr: 0.001719, loss: 3.7707
2022-10-07 10:17:01 - train: epoch 0029, iter [00320, 01251], lr: 0.001719, loss: 3.7697
2022-10-07 10:17:23 - train: epoch 0029, iter [00330, 01251], lr: 0.001719, loss: 3.9620
2022-10-07 10:17:44 - train: epoch 0029, iter [00340, 01251], lr: 0.001718, loss: 3.5661
2022-10-07 10:18:05 - train: epoch 0029, iter [00350, 01251], lr: 0.001718, loss: 3.1381
2022-10-07 10:18:26 - train: epoch 0029, iter [00360, 01251], lr: 0.001718, loss: 3.3963
2022-10-07 10:18:48 - train: epoch 0029, iter [00370, 01251], lr: 0.001718, loss: 3.8179
2022-10-07 10:19:09 - train: epoch 0029, iter [00380, 01251], lr: 0.001718, loss: 3.2950
2022-10-07 10:19:30 - train: epoch 0029, iter [00390, 01251], lr: 0.001717, loss: 3.1893
2022-10-07 10:19:52 - train: epoch 0029, iter [00400, 01251], lr: 0.001717, loss: 3.7950
2022-10-07 10:20:13 - train: epoch 0029, iter [00410, 01251], lr: 0.001717, loss: 3.2128
2022-10-07 10:20:34 - train: epoch 0029, iter [00420, 01251], lr: 0.001717, loss: 2.8526
2022-10-07 10:20:55 - train: epoch 0029, iter [00430, 01251], lr: 0.001717, loss: 2.8778
2022-10-07 10:21:17 - train: epoch 0029, iter [00440, 01251], lr: 0.001717, loss: 3.3713
2022-10-07 10:21:38 - train: epoch 0029, iter [00450, 01251], lr: 0.001716, loss: 2.8719
2022-10-07 10:21:59 - train: epoch 0029, iter [00460, 01251], lr: 0.001716, loss: 2.8059
2022-10-07 10:22:20 - train: epoch 0029, iter [00470, 01251], lr: 0.001716, loss: 3.8280
2022-10-07 10:22:42 - train: epoch 0029, iter [00480, 01251], lr: 0.001716, loss: 3.2515
2022-10-07 10:23:03 - train: epoch 0029, iter [00490, 01251], lr: 0.001716, loss: 3.3064
2022-10-07 10:23:24 - train: epoch 0029, iter [00500, 01251], lr: 0.001715, loss: 3.7315
2022-10-07 10:23:45 - train: epoch 0029, iter [00510, 01251], lr: 0.001715, loss: 4.0600
2022-10-07 10:24:07 - train: epoch 0029, iter [00520, 01251], lr: 0.001715, loss: 3.8583
2022-10-07 10:24:28 - train: epoch 0029, iter [00530, 01251], lr: 0.001715, loss: 3.5244
2022-10-07 10:24:49 - train: epoch 0029, iter [00540, 01251], lr: 0.001715, loss: 3.5289
2022-10-07 10:25:10 - train: epoch 0029, iter [00550, 01251], lr: 0.001714, loss: 3.5890
2022-10-07 10:25:31 - train: epoch 0029, iter [00560, 01251], lr: 0.001714, loss: 3.1777
2022-10-07 10:25:53 - train: epoch 0029, iter [00570, 01251], lr: 0.001714, loss: 3.3106
2022-10-07 10:26:14 - train: epoch 0029, iter [00580, 01251], lr: 0.001714, loss: 3.4217
2022-10-07 10:26:35 - train: epoch 0029, iter [00590, 01251], lr: 0.001714, loss: 3.2551
2022-10-07 10:26:57 - train: epoch 0029, iter [00600, 01251], lr: 0.001714, loss: 2.4422
2022-10-07 10:27:18 - train: epoch 0029, iter [00610, 01251], lr: 0.001713, loss: 3.7443
2022-10-07 10:27:39 - train: epoch 0029, iter [00620, 01251], lr: 0.001713, loss: 3.5326
2022-10-07 10:28:00 - train: epoch 0029, iter [00630, 01251], lr: 0.001713, loss: 3.6650
2022-10-07 10:28:22 - train: epoch 0029, iter [00640, 01251], lr: 0.001713, loss: 3.5956
2022-10-07 10:28:43 - train: epoch 0029, iter [00650, 01251], lr: 0.001713, loss: 3.6915
2022-10-07 10:29:04 - train: epoch 0029, iter [00660, 01251], lr: 0.001712, loss: 3.0485
2022-10-07 10:29:25 - train: epoch 0029, iter [00670, 01251], lr: 0.001712, loss: 2.8741
2022-10-07 10:29:47 - train: epoch 0029, iter [00680, 01251], lr: 0.001712, loss: 3.9827
2022-10-07 10:30:08 - train: epoch 0029, iter [00690, 01251], lr: 0.001712, loss: 3.6525
2022-10-07 10:30:29 - train: epoch 0029, iter [00700, 01251], lr: 0.001712, loss: 3.0036
2022-10-07 10:30:51 - train: epoch 0029, iter [00710, 01251], lr: 0.001712, loss: 2.8864
2022-10-07 10:31:12 - train: epoch 0029, iter [00720, 01251], lr: 0.001711, loss: 3.4350
2022-10-07 10:31:33 - train: epoch 0029, iter [00730, 01251], lr: 0.001711, loss: 3.5884
2022-10-07 10:31:54 - train: epoch 0029, iter [00740, 01251], lr: 0.001711, loss: 3.4080
2022-10-07 10:32:16 - train: epoch 0029, iter [00750, 01251], lr: 0.001711, loss: 3.3794
2022-10-07 10:32:37 - train: epoch 0029, iter [00760, 01251], lr: 0.001711, loss: 3.4653
2022-10-07 10:32:58 - train: epoch 0029, iter [00770, 01251], lr: 0.001710, loss: 3.8936
2022-10-07 10:33:19 - train: epoch 0029, iter [00780, 01251], lr: 0.001710, loss: 3.1275
2022-10-07 10:33:41 - train: epoch 0029, iter [00790, 01251], lr: 0.001710, loss: 3.6358
2022-10-07 10:34:02 - train: epoch 0029, iter [00800, 01251], lr: 0.001710, loss: 3.7481
2022-10-07 10:34:23 - train: epoch 0029, iter [00810, 01251], lr: 0.001710, loss: 3.6666
2022-10-07 10:34:44 - train: epoch 0029, iter [00820, 01251], lr: 0.001709, loss: 3.8627
2022-10-07 10:35:06 - train: epoch 0029, iter [00830, 01251], lr: 0.001709, loss: 3.4326
2022-10-07 10:35:27 - train: epoch 0029, iter [00840, 01251], lr: 0.001709, loss: 3.1008
2022-10-07 10:35:48 - train: epoch 0029, iter [00850, 01251], lr: 0.001709, loss: 3.5414
2022-10-07 10:36:09 - train: epoch 0029, iter [00860, 01251], lr: 0.001709, loss: 2.7774
2022-10-07 10:36:31 - train: epoch 0029, iter [00870, 01251], lr: 0.001709, loss: 3.6109
2022-10-07 10:36:52 - train: epoch 0029, iter [00880, 01251], lr: 0.001708, loss: 3.8282
2022-10-07 10:37:13 - train: epoch 0029, iter [00890, 01251], lr: 0.001708, loss: 3.1367
2022-10-07 10:37:35 - train: epoch 0029, iter [00900, 01251], lr: 0.001708, loss: 3.4503
2022-10-07 10:37:56 - train: epoch 0029, iter [00910, 01251], lr: 0.001708, loss: 3.3534
2022-10-07 10:38:17 - train: epoch 0029, iter [00920, 01251], lr: 0.001708, loss: 3.4803
2022-10-07 10:38:38 - train: epoch 0029, iter [00930, 01251], lr: 0.001707, loss: 3.3286
2022-10-07 10:38:59 - train: epoch 0029, iter [00940, 01251], lr: 0.001707, loss: 3.3432
2022-10-07 10:39:21 - train: epoch 0029, iter [00950, 01251], lr: 0.001707, loss: 2.9364
2022-10-07 10:39:42 - train: epoch 0029, iter [00960, 01251], lr: 0.001707, loss: 3.7738
2022-10-07 10:40:03 - train: epoch 0029, iter [00970, 01251], lr: 0.001707, loss: 3.4848
2022-10-07 10:40:24 - train: epoch 0029, iter [00980, 01251], lr: 0.001706, loss: 3.4881
2022-10-07 10:40:45 - train: epoch 0029, iter [00990, 01251], lr: 0.001706, loss: 3.6636
2022-10-07 10:41:07 - train: epoch 0029, iter [01000, 01251], lr: 0.001706, loss: 3.8587
2022-10-07 10:41:28 - train: epoch 0029, iter [01010, 01251], lr: 0.001706, loss: 3.5724
2022-10-07 10:41:49 - train: epoch 0029, iter [01020, 01251], lr: 0.001706, loss: 3.6596
2022-10-07 10:42:10 - train: epoch 0029, iter [01030, 01251], lr: 0.001706, loss: 2.7260
2022-10-07 10:42:32 - train: epoch 0029, iter [01040, 01251], lr: 0.001705, loss: 3.0202
2022-10-07 10:42:53 - train: epoch 0029, iter [01050, 01251], lr: 0.001705, loss: 3.2495
2022-10-07 10:43:14 - train: epoch 0029, iter [01060, 01251], lr: 0.001705, loss: 3.5290
2022-10-07 10:43:35 - train: epoch 0029, iter [01070, 01251], lr: 0.001705, loss: 3.3134
2022-10-07 10:43:57 - train: epoch 0029, iter [01080, 01251], lr: 0.001705, loss: 3.6541
2022-10-07 10:44:18 - train: epoch 0029, iter [01090, 01251], lr: 0.001704, loss: 3.8944
2022-10-07 10:44:39 - train: epoch 0029, iter [01100, 01251], lr: 0.001704, loss: 2.6858
2022-10-07 10:45:00 - train: epoch 0029, iter [01110, 01251], lr: 0.001704, loss: 3.0216
2022-10-07 10:45:22 - train: epoch 0029, iter [01120, 01251], lr: 0.001704, loss: 3.4996
2022-10-07 10:45:43 - train: epoch 0029, iter [01130, 01251], lr: 0.001704, loss: 2.9251
2022-10-07 10:46:04 - train: epoch 0029, iter [01140, 01251], lr: 0.001703, loss: 3.9464
2022-10-07 10:46:25 - train: epoch 0029, iter [01150, 01251], lr: 0.001703, loss: 3.6233
2022-10-07 10:46:47 - train: epoch 0029, iter [01160, 01251], lr: 0.001703, loss: 3.1468
2022-10-07 10:47:08 - train: epoch 0029, iter [01170, 01251], lr: 0.001703, loss: 3.8666
2022-10-07 10:47:29 - train: epoch 0029, iter [01180, 01251], lr: 0.001703, loss: 3.9568
2022-10-07 10:47:51 - train: epoch 0029, iter [01190, 01251], lr: 0.001703, loss: 2.8476
2022-10-07 10:48:12 - train: epoch 0029, iter [01200, 01251], lr: 0.001702, loss: 3.3705
2022-10-07 10:48:33 - train: epoch 0029, iter [01210, 01251], lr: 0.001702, loss: 3.8490
2022-10-07 10:48:54 - train: epoch 0029, iter [01220, 01251], lr: 0.001702, loss: 3.6500
2022-10-07 10:49:16 - train: epoch 0029, iter [01230, 01251], lr: 0.001702, loss: 3.8243
2022-10-07 10:49:37 - train: epoch 0029, iter [01240, 01251], lr: 0.001702, loss: 3.6408
2022-10-07 10:49:58 - train: epoch 0029, iter [01250, 01251], lr: 0.001701, loss: 3.7083
2022-10-07 10:50:01 - train: epoch 029, train_loss: 3.3591
2022-10-07 10:51:18 - eval: epoch: 029, acc1: 78.296%, acc5: 94.484%, test_loss: 0.9452, per_image_load_time: 0.343ms, per_image_inference_time: 1.415ms
2022-10-07 10:51:19 - until epoch: 029, best_acc1: 78.544%
2022-10-07 10:51:19 - epoch 030 lr: 0.001701
2022-10-07 10:51:46 - train: epoch 0030, iter [00010, 01251], lr: 0.001701, loss: 3.8061
2022-10-07 10:52:08 - train: epoch 0030, iter [00020, 01251], lr: 0.001701, loss: 3.7727
2022-10-07 10:52:29 - train: epoch 0030, iter [00030, 01251], lr: 0.001701, loss: 3.6521
2022-10-07 10:52:51 - train: epoch 0030, iter [00040, 01251], lr: 0.001701, loss: 3.5986
2022-10-07 10:53:12 - train: epoch 0030, iter [00050, 01251], lr: 0.001700, loss: 3.4047
2022-10-07 10:53:33 - train: epoch 0030, iter [00060, 01251], lr: 0.001700, loss: 3.5557
2022-10-07 10:53:55 - train: epoch 0030, iter [00070, 01251], lr: 0.001700, loss: 3.6580
2022-10-07 10:54:16 - train: epoch 0030, iter [00080, 01251], lr: 0.001700, loss: 2.9835
2022-10-07 10:54:38 - train: epoch 0030, iter [00090, 01251], lr: 0.001700, loss: 3.9231
2022-10-07 10:54:59 - train: epoch 0030, iter [00100, 01251], lr: 0.001700, loss: 3.2070
2022-10-07 10:55:20 - train: epoch 0030, iter [00110, 01251], lr: 0.001699, loss: 3.4270
2022-10-07 10:55:42 - train: epoch 0030, iter [00120, 01251], lr: 0.001699, loss: 3.6039
2022-10-07 10:56:03 - train: epoch 0030, iter [00130, 01251], lr: 0.001699, loss: 3.5948
2022-10-07 10:56:25 - train: epoch 0030, iter [00140, 01251], lr: 0.001699, loss: 3.0815
2022-10-07 10:56:46 - train: epoch 0030, iter [00150, 01251], lr: 0.001699, loss: 2.4081
2022-10-07 10:57:07 - train: epoch 0030, iter [00160, 01251], lr: 0.001698, loss: 3.4354
2022-10-07 10:57:29 - train: epoch 0030, iter [00170, 01251], lr: 0.001698, loss: 3.3796
2022-10-07 10:57:50 - train: epoch 0030, iter [00180, 01251], lr: 0.001698, loss: 3.3922
2022-10-07 10:58:11 - train: epoch 0030, iter [00190, 01251], lr: 0.001698, loss: 3.4347
2022-10-07 10:58:33 - train: epoch 0030, iter [00200, 01251], lr: 0.001698, loss: 3.4791
2022-10-07 10:58:54 - train: epoch 0030, iter [00210, 01251], lr: 0.001697, loss: 2.9929
2022-10-07 10:59:16 - train: epoch 0030, iter [00220, 01251], lr: 0.001697, loss: 3.4160
2022-10-07 10:59:37 - train: epoch 0030, iter [00230, 01251], lr: 0.001697, loss: 3.9752
2022-10-07 10:59:58 - train: epoch 0030, iter [00240, 01251], lr: 0.001697, loss: 3.2283
2022-10-07 11:00:20 - train: epoch 0030, iter [00250, 01251], lr: 0.001697, loss: 3.2047
2022-10-07 11:00:41 - train: epoch 0030, iter [00260, 01251], lr: 0.001696, loss: 3.7499
2022-10-07 11:01:03 - train: epoch 0030, iter [00270, 01251], lr: 0.001696, loss: 3.2678
2022-10-07 11:01:24 - train: epoch 0030, iter [00280, 01251], lr: 0.001696, loss: 4.0785
2022-10-07 11:01:45 - train: epoch 0030, iter [00290, 01251], lr: 0.001696, loss: 2.5756
2022-10-07 11:02:07 - train: epoch 0030, iter [00300, 01251], lr: 0.001696, loss: 2.7047
2022-10-07 11:02:28 - train: epoch 0030, iter [00310, 01251], lr: 0.001696, loss: 3.5386
2022-10-07 11:02:49 - train: epoch 0030, iter [00320, 01251], lr: 0.001695, loss: 3.6139
2022-10-07 11:03:10 - train: epoch 0030, iter [00330, 01251], lr: 0.001695, loss: 2.8182
2022-10-07 11:03:31 - train: epoch 0030, iter [00340, 01251], lr: 0.001695, loss: 2.6533
2022-10-07 11:03:52 - train: epoch 0030, iter [00350, 01251], lr: 0.001695, loss: 3.7933
2022-10-07 11:04:13 - train: epoch 0030, iter [00360, 01251], lr: 0.001695, loss: 3.2568
2022-10-07 11:04:35 - train: epoch 0030, iter [00370, 01251], lr: 0.001694, loss: 3.1647
2022-10-07 11:04:56 - train: epoch 0030, iter [00380, 01251], lr: 0.001694, loss: 3.2113
2022-10-07 11:05:17 - train: epoch 0030, iter [00390, 01251], lr: 0.001694, loss: 3.3438
2022-10-07 11:05:38 - train: epoch 0030, iter [00400, 01251], lr: 0.001694, loss: 3.2723
2022-10-07 11:05:59 - train: epoch 0030, iter [00410, 01251], lr: 0.001694, loss: 3.1454
2022-10-07 11:06:20 - train: epoch 0030, iter [00420, 01251], lr: 0.001693, loss: 3.7064
2022-10-07 11:06:41 - train: epoch 0030, iter [00430, 01251], lr: 0.001693, loss: 3.6005
2022-10-07 11:07:02 - train: epoch 0030, iter [00440, 01251], lr: 0.001693, loss: 3.0825
2022-10-07 11:07:23 - train: epoch 0030, iter [00450, 01251], lr: 0.001693, loss: 3.4122
2022-10-07 11:07:44 - train: epoch 0030, iter [00460, 01251], lr: 0.001693, loss: 3.4364
2022-10-07 11:08:05 - train: epoch 0030, iter [00470, 01251], lr: 0.001692, loss: 2.8881
2022-10-07 11:08:26 - train: epoch 0030, iter [00480, 01251], lr: 0.001692, loss: 3.3559
2022-10-07 11:08:47 - train: epoch 0030, iter [00490, 01251], lr: 0.001692, loss: 3.4823
2022-10-07 11:09:08 - train: epoch 0030, iter [00500, 01251], lr: 0.001692, loss: 3.6314
2022-10-07 11:09:29 - train: epoch 0030, iter [00510, 01251], lr: 0.001692, loss: 3.8479
2022-10-07 11:09:50 - train: epoch 0030, iter [00520, 01251], lr: 0.001692, loss: 3.2048
2022-10-07 11:10:11 - train: epoch 0030, iter [00530, 01251], lr: 0.001691, loss: 3.2449
2022-10-07 11:10:32 - train: epoch 0030, iter [00540, 01251], lr: 0.001691, loss: 3.6511
2022-10-07 11:10:53 - train: epoch 0030, iter [00550, 01251], lr: 0.001691, loss: 3.5228
2022-10-07 11:11:14 - train: epoch 0030, iter [00560, 01251], lr: 0.001691, loss: 3.1676
2022-10-07 11:11:35 - train: epoch 0030, iter [00570, 01251], lr: 0.001691, loss: 3.0937
2022-10-07 11:11:56 - train: epoch 0030, iter [00580, 01251], lr: 0.001690, loss: 3.4719
2022-10-07 11:12:17 - train: epoch 0030, iter [00590, 01251], lr: 0.001690, loss: 3.2670
2022-10-07 11:12:38 - train: epoch 0030, iter [00600, 01251], lr: 0.001690, loss: 3.2298
2022-10-07 11:12:59 - train: epoch 0030, iter [00610, 01251], lr: 0.001690, loss: 3.6738
2022-10-07 11:13:21 - train: epoch 0030, iter [00620, 01251], lr: 0.001690, loss: 2.9650
2022-10-07 11:13:42 - train: epoch 0030, iter [00630, 01251], lr: 0.001689, loss: 3.4460
2022-10-07 11:14:03 - train: epoch 0030, iter [00640, 01251], lr: 0.001689, loss: 3.1285
2022-10-07 11:14:24 - train: epoch 0030, iter [00650, 01251], lr: 0.001689, loss: 2.6775
2022-10-07 11:14:45 - train: epoch 0030, iter [00660, 01251], lr: 0.001689, loss: 3.5687
2022-10-07 11:15:06 - train: epoch 0030, iter [00670, 01251], lr: 0.001689, loss: 3.8590
2022-10-07 11:15:26 - train: epoch 0030, iter [00680, 01251], lr: 0.001688, loss: 3.5363
2022-10-07 11:15:47 - train: epoch 0030, iter [00690, 01251], lr: 0.001688, loss: 3.6411
2022-10-07 11:16:08 - train: epoch 0030, iter [00700, 01251], lr: 0.001688, loss: 3.3389
2022-10-07 11:16:29 - train: epoch 0030, iter [00710, 01251], lr: 0.001688, loss: 3.3520
2022-10-07 11:16:50 - train: epoch 0030, iter [00720, 01251], lr: 0.001688, loss: 3.2970
2022-10-07 11:17:11 - train: epoch 0030, iter [00730, 01251], lr: 0.001688, loss: 3.6055
2022-10-07 11:17:32 - train: epoch 0030, iter [00740, 01251], lr: 0.001687, loss: 3.5206
2022-10-07 11:17:53 - train: epoch 0030, iter [00750, 01251], lr: 0.001687, loss: 3.5649
2022-10-07 11:18:15 - train: epoch 0030, iter [00760, 01251], lr: 0.001687, loss: 3.5868
2022-10-07 11:18:35 - train: epoch 0030, iter [00770, 01251], lr: 0.001687, loss: 2.4259
2022-10-07 11:18:56 - train: epoch 0030, iter [00780, 01251], lr: 0.001687, loss: 3.5717
2022-10-07 11:19:17 - train: epoch 0030, iter [00790, 01251], lr: 0.001686, loss: 2.9565
2022-10-07 11:19:38 - train: epoch 0030, iter [00800, 01251], lr: 0.001686, loss: 3.5293
2022-10-07 11:20:00 - train: epoch 0030, iter [00810, 01251], lr: 0.001686, loss: 3.4526
2022-10-07 11:20:20 - train: epoch 0030, iter [00820, 01251], lr: 0.001686, loss: 3.4841
2022-10-07 11:20:41 - train: epoch 0030, iter [00830, 01251], lr: 0.001686, loss: 3.8627
2022-10-07 11:21:02 - train: epoch 0030, iter [00840, 01251], lr: 0.001685, loss: 3.5249
2022-10-07 11:21:23 - train: epoch 0030, iter [00850, 01251], lr: 0.001685, loss: 2.8914
2022-10-07 11:21:45 - train: epoch 0030, iter [00860, 01251], lr: 0.001685, loss: 3.4752
2022-10-07 11:22:06 - train: epoch 0030, iter [00870, 01251], lr: 0.001685, loss: 3.7486
2022-10-07 11:22:27 - train: epoch 0030, iter [00880, 01251], lr: 0.001685, loss: 3.4489
2022-10-07 11:22:48 - train: epoch 0030, iter [00890, 01251], lr: 0.001684, loss: 2.9956
2022-10-07 11:23:09 - train: epoch 0030, iter [00900, 01251], lr: 0.001684, loss: 2.8090
2022-10-07 11:23:30 - train: epoch 0030, iter [00910, 01251], lr: 0.001684, loss: 3.0107
2022-10-07 11:23:51 - train: epoch 0030, iter [00920, 01251], lr: 0.001684, loss: 3.6808
2022-10-07 11:24:12 - train: epoch 0030, iter [00930, 01251], lr: 0.001684, loss: 2.8006
2022-10-07 11:24:33 - train: epoch 0030, iter [00940, 01251], lr: 0.001683, loss: 3.5031
2022-10-07 11:24:54 - train: epoch 0030, iter [00950, 01251], lr: 0.001683, loss: 3.2567
2022-10-07 11:25:15 - train: epoch 0030, iter [00960, 01251], lr: 0.001683, loss: 3.4211
2022-10-07 11:25:36 - train: epoch 0030, iter [00970, 01251], lr: 0.001683, loss: 3.6489
2022-10-07 11:25:57 - train: epoch 0030, iter [00980, 01251], lr: 0.001683, loss: 3.3781
2022-10-07 11:26:18 - train: epoch 0030, iter [00990, 01251], lr: 0.001683, loss: 3.3408
2022-10-07 11:26:39 - train: epoch 0030, iter [01000, 01251], lr: 0.001682, loss: 3.5479
2022-10-07 11:27:00 - train: epoch 0030, iter [01010, 01251], lr: 0.001682, loss: 3.7703
2022-10-07 11:27:21 - train: epoch 0030, iter [01020, 01251], lr: 0.001682, loss: 3.4250
2022-10-07 11:27:42 - train: epoch 0030, iter [01030, 01251], lr: 0.001682, loss: 3.3260
2022-10-07 11:28:03 - train: epoch 0030, iter [01040, 01251], lr: 0.001682, loss: 3.6638
2022-10-07 11:28:24 - train: epoch 0030, iter [01050, 01251], lr: 0.001681, loss: 3.9657
2022-10-07 11:28:45 - train: epoch 0030, iter [01060, 01251], lr: 0.001681, loss: 3.9021
2022-10-07 11:29:06 - train: epoch 0030, iter [01070, 01251], lr: 0.001681, loss: 3.9306
2022-10-07 11:29:27 - train: epoch 0030, iter [01080, 01251], lr: 0.001681, loss: 3.7231
2022-10-07 11:29:48 - train: epoch 0030, iter [01090, 01251], lr: 0.001681, loss: 3.7960
2022-10-07 11:30:09 - train: epoch 0030, iter [01100, 01251], lr: 0.001680, loss: 3.6819
2022-10-07 11:30:30 - train: epoch 0030, iter [01110, 01251], lr: 0.001680, loss: 2.4366
2022-10-07 11:30:51 - train: epoch 0030, iter [01120, 01251], lr: 0.001680, loss: 2.8120
2022-10-07 11:31:12 - train: epoch 0030, iter [01130, 01251], lr: 0.001680, loss: 3.8622
2022-10-07 11:31:33 - train: epoch 0030, iter [01140, 01251], lr: 0.001680, loss: 3.0727
2022-10-07 11:31:54 - train: epoch 0030, iter [01150, 01251], lr: 0.001679, loss: 3.1942
2022-10-07 11:32:15 - train: epoch 0030, iter [01160, 01251], lr: 0.001679, loss: 3.5040
2022-10-07 11:32:36 - train: epoch 0030, iter [01170, 01251], lr: 0.001679, loss: 3.0121
2022-10-07 11:32:57 - train: epoch 0030, iter [01180, 01251], lr: 0.001679, loss: 3.5645
2022-10-07 11:33:18 - train: epoch 0030, iter [01190, 01251], lr: 0.001679, loss: 4.0202
2022-10-07 11:33:39 - train: epoch 0030, iter [01200, 01251], lr: 0.001678, loss: 2.9569
2022-10-07 11:34:00 - train: epoch 0030, iter [01210, 01251], lr: 0.001678, loss: 3.8326
2022-10-07 11:34:21 - train: epoch 0030, iter [01220, 01251], lr: 0.001678, loss: 3.4754
2022-10-07 11:34:42 - train: epoch 0030, iter [01230, 01251], lr: 0.001678, loss: 3.0882
2022-10-07 11:35:03 - train: epoch 0030, iter [01240, 01251], lr: 0.001678, loss: 3.7029
2022-10-07 11:35:24 - train: epoch 0030, iter [01250, 01251], lr: 0.001677, loss: 2.9798
2022-10-07 11:35:27 - train: epoch 030, train_loss: 3.3474
2022-10-07 11:36:44 - eval: epoch: 030, acc1: 78.418%, acc5: 94.686%, test_loss: 0.9589, per_image_load_time: 1.208ms, per_image_inference_time: 1.427ms
2022-10-07 11:36:45 - until epoch: 030, best_acc1: 78.544%
2022-10-07 11:36:45 - epoch 031 lr: 0.001677
2022-10-07 11:37:12 - train: epoch 0031, iter [00010, 01251], lr: 0.001677, loss: 3.6268
2022-10-07 11:37:33 - train: epoch 0031, iter [00020, 01251], lr: 0.001677, loss: 2.9879
2022-10-07 11:37:55 - train: epoch 0031, iter [00030, 01251], lr: 0.001677, loss: 3.4820
2022-10-07 11:38:16 - train: epoch 0031, iter [00040, 01251], lr: 0.001677, loss: 3.1232
2022-10-07 11:38:37 - train: epoch 0031, iter [00050, 01251], lr: 0.001676, loss: 3.4858
2022-10-07 11:38:58 - train: epoch 0031, iter [00060, 01251], lr: 0.001676, loss: 3.2732
2022-10-07 11:39:19 - train: epoch 0031, iter [00070, 01251], lr: 0.001676, loss: 2.8827
2022-10-07 11:39:41 - train: epoch 0031, iter [00080, 01251], lr: 0.001676, loss: 3.2028
2022-10-07 11:40:02 - train: epoch 0031, iter [00090, 01251], lr: 0.001676, loss: 3.4808
2022-10-07 11:40:23 - train: epoch 0031, iter [00100, 01251], lr: 0.001675, loss: 2.9980
2022-10-07 11:40:44 - train: epoch 0031, iter [00110, 01251], lr: 0.001675, loss: 3.5096
2022-10-07 11:41:06 - train: epoch 0031, iter [00120, 01251], lr: 0.001675, loss: 3.1252
2022-10-07 11:41:27 - train: epoch 0031, iter [00130, 01251], lr: 0.001675, loss: 3.4546
2022-10-07 11:41:48 - train: epoch 0031, iter [00140, 01251], lr: 0.001675, loss: 3.5048
2022-10-07 11:42:09 - train: epoch 0031, iter [00150, 01251], lr: 0.001675, loss: 3.3265
2022-10-07 11:42:30 - train: epoch 0031, iter [00160, 01251], lr: 0.001674, loss: 3.5325
2022-10-07 11:42:52 - train: epoch 0031, iter [00170, 01251], lr: 0.001674, loss: 3.5314
2022-10-07 11:43:13 - train: epoch 0031, iter [00180, 01251], lr: 0.001674, loss: 3.1351
2022-10-07 11:43:34 - train: epoch 0031, iter [00190, 01251], lr: 0.001674, loss: 3.5229
2022-10-07 11:43:56 - train: epoch 0031, iter [00200, 01251], lr: 0.001674, loss: 3.2058
2022-10-07 11:44:17 - train: epoch 0031, iter [00210, 01251], lr: 0.001673, loss: 3.6498
2022-10-07 11:44:38 - train: epoch 0031, iter [00220, 01251], lr: 0.001673, loss: 3.1614
2022-10-07 11:44:59 - train: epoch 0031, iter [00230, 01251], lr: 0.001673, loss: 3.0695
2022-10-07 11:45:21 - train: epoch 0031, iter [00240, 01251], lr: 0.001673, loss: 3.4533
2022-10-07 11:45:42 - train: epoch 0031, iter [00250, 01251], lr: 0.001673, loss: 3.2995
2022-10-07 11:46:03 - train: epoch 0031, iter [00260, 01251], lr: 0.001672, loss: 3.3375
2022-10-07 11:46:24 - train: epoch 0031, iter [00270, 01251], lr: 0.001672, loss: 3.7470
2022-10-07 11:46:45 - train: epoch 0031, iter [00280, 01251], lr: 0.001672, loss: 3.3332
2022-10-07 11:47:07 - train: epoch 0031, iter [00290, 01251], lr: 0.001672, loss: 3.6899
2022-10-07 11:47:28 - train: epoch 0031, iter [00300, 01251], lr: 0.001672, loss: 3.6935
2022-10-07 11:47:49 - train: epoch 0031, iter [00310, 01251], lr: 0.001671, loss: 4.0087
2022-10-07 11:48:10 - train: epoch 0031, iter [00320, 01251], lr: 0.001671, loss: 3.5226
2022-10-07 11:48:32 - train: epoch 0031, iter [00330, 01251], lr: 0.001671, loss: 3.6664
2022-10-07 11:48:53 - train: epoch 0031, iter [00340, 01251], lr: 0.001671, loss: 3.8475
2022-10-07 11:49:14 - train: epoch 0031, iter [00350, 01251], lr: 0.001671, loss: 3.0415
2022-10-07 11:49:35 - train: epoch 0031, iter [00360, 01251], lr: 0.001670, loss: 3.9356
2022-10-07 11:49:56 - train: epoch 0031, iter [00370, 01251], lr: 0.001670, loss: 2.8536
2022-10-07 11:50:17 - train: epoch 0031, iter [00380, 01251], lr: 0.001670, loss: 2.7604
2022-10-07 11:50:38 - train: epoch 0031, iter [00390, 01251], lr: 0.001670, loss: 3.0286
2022-10-07 11:50:59 - train: epoch 0031, iter [00400, 01251], lr: 0.001670, loss: 3.3850
2022-10-07 11:51:20 - train: epoch 0031, iter [00410, 01251], lr: 0.001669, loss: 2.2200
2022-10-07 11:51:41 - train: epoch 0031, iter [00420, 01251], lr: 0.001669, loss: 3.1275
2022-10-07 11:52:02 - train: epoch 0031, iter [00430, 01251], lr: 0.001669, loss: 2.6221
2022-10-07 11:52:24 - train: epoch 0031, iter [00440, 01251], lr: 0.001669, loss: 3.2694
2022-10-07 11:52:45 - train: epoch 0031, iter [00450, 01251], lr: 0.001669, loss: 3.2411
2022-10-07 11:53:06 - train: epoch 0031, iter [00460, 01251], lr: 0.001668, loss: 3.4139
2022-10-07 11:53:27 - train: epoch 0031, iter [00470, 01251], lr: 0.001668, loss: 3.1211
2022-10-07 11:53:48 - train: epoch 0031, iter [00480, 01251], lr: 0.001668, loss: 3.7562
2022-10-07 11:54:09 - train: epoch 0031, iter [00490, 01251], lr: 0.001668, loss: 3.8103
2022-10-07 11:54:30 - train: epoch 0031, iter [00500, 01251], lr: 0.001668, loss: 3.4659
2022-10-07 11:54:51 - train: epoch 0031, iter [00510, 01251], lr: 0.001667, loss: 3.6744
2022-10-07 11:55:12 - train: epoch 0031, iter [00520, 01251], lr: 0.001667, loss: 2.9448
2022-10-07 11:55:33 - train: epoch 0031, iter [00530, 01251], lr: 0.001667, loss: 2.8646
2022-10-07 11:55:55 - train: epoch 0031, iter [00540, 01251], lr: 0.001667, loss: 2.7456
2022-10-07 11:56:16 - train: epoch 0031, iter [00550, 01251], lr: 0.001667, loss: 2.9413
2022-10-07 11:56:37 - train: epoch 0031, iter [00560, 01251], lr: 0.001666, loss: 3.4785
2022-10-07 11:56:58 - train: epoch 0031, iter [00570, 01251], lr: 0.001666, loss: 3.3854
2022-10-07 11:57:19 - train: epoch 0031, iter [00580, 01251], lr: 0.001666, loss: 3.4222
2022-10-07 11:57:40 - train: epoch 0031, iter [00590, 01251], lr: 0.001666, loss: 3.5579
2022-10-07 11:58:01 - train: epoch 0031, iter [00600, 01251], lr: 0.001666, loss: 3.6012
2022-10-07 11:58:22 - train: epoch 0031, iter [00610, 01251], lr: 0.001665, loss: 2.5105
2022-10-07 11:58:43 - train: epoch 0031, iter [00620, 01251], lr: 0.001665, loss: 3.9733
2022-10-07 11:59:04 - train: epoch 0031, iter [00630, 01251], lr: 0.001665, loss: 3.5413
2022-10-07 11:59:25 - train: epoch 0031, iter [00640, 01251], lr: 0.001665, loss: 3.4956
2022-10-07 11:59:46 - train: epoch 0031, iter [00650, 01251], lr: 0.001665, loss: 3.2332
2022-10-07 12:00:07 - train: epoch 0031, iter [00660, 01251], lr: 0.001665, loss: 3.0965
2022-10-07 12:00:28 - train: epoch 0031, iter [00670, 01251], lr: 0.001664, loss: 3.6659
2022-10-07 12:00:49 - train: epoch 0031, iter [00680, 01251], lr: 0.001664, loss: 3.5547
2022-10-07 12:01:10 - train: epoch 0031, iter [00690, 01251], lr: 0.001664, loss: 2.9861
2022-10-07 12:01:31 - train: epoch 0031, iter [00700, 01251], lr: 0.001664, loss: 3.3763
2022-10-07 12:01:53 - train: epoch 0031, iter [00710, 01251], lr: 0.001664, loss: 2.7640
2022-10-07 12:02:14 - train: epoch 0031, iter [00720, 01251], lr: 0.001663, loss: 3.2113
2022-10-07 12:02:35 - train: epoch 0031, iter [00730, 01251], lr: 0.001663, loss: 3.2558
2022-10-07 12:02:56 - train: epoch 0031, iter [00740, 01251], lr: 0.001663, loss: 2.4394
2022-10-07 12:03:17 - train: epoch 0031, iter [00750, 01251], lr: 0.001663, loss: 3.4928
2022-10-07 12:03:38 - train: epoch 0031, iter [00760, 01251], lr: 0.001663, loss: 3.0064
2022-10-07 12:03:59 - train: epoch 0031, iter [00770, 01251], lr: 0.001662, loss: 3.5024
2022-10-07 12:04:20 - train: epoch 0031, iter [00780, 01251], lr: 0.001662, loss: 3.3557
2022-10-07 12:04:41 - train: epoch 0031, iter [00790, 01251], lr: 0.001662, loss: 2.9746
2022-10-07 12:05:02 - train: epoch 0031, iter [00800, 01251], lr: 0.001662, loss: 3.2759
2022-10-07 12:05:23 - train: epoch 0031, iter [00810, 01251], lr: 0.001662, loss: 3.2091
2022-10-07 12:05:44 - train: epoch 0031, iter [00820, 01251], lr: 0.001661, loss: 2.8390
2022-10-07 12:06:05 - train: epoch 0031, iter [00830, 01251], lr: 0.001661, loss: 2.8681
2022-10-07 12:06:26 - train: epoch 0031, iter [00840, 01251], lr: 0.001661, loss: 3.3289
2022-10-07 12:06:47 - train: epoch 0031, iter [00850, 01251], lr: 0.001661, loss: 3.0807
2022-10-07 12:07:08 - train: epoch 0031, iter [00860, 01251], lr: 0.001661, loss: 3.5360
2022-10-07 12:07:29 - train: epoch 0031, iter [00870, 01251], lr: 0.001660, loss: 3.5855
2022-10-07 12:07:51 - train: epoch 0031, iter [00880, 01251], lr: 0.001660, loss: 3.6502
2022-10-07 12:08:12 - train: epoch 0031, iter [00890, 01251], lr: 0.001660, loss: 3.7900
2022-10-07 12:08:33 - train: epoch 0031, iter [00900, 01251], lr: 0.001660, loss: 3.1767
2022-10-07 12:08:54 - train: epoch 0031, iter [00910, 01251], lr: 0.001660, loss: 2.6869
2022-10-07 12:09:15 - train: epoch 0031, iter [00920, 01251], lr: 0.001659, loss: 3.3907
2022-10-07 12:09:36 - train: epoch 0031, iter [00930, 01251], lr: 0.001659, loss: 3.5269
2022-10-07 12:09:57 - train: epoch 0031, iter [00940, 01251], lr: 0.001659, loss: 3.3318
2022-10-07 12:10:18 - train: epoch 0031, iter [00950, 01251], lr: 0.001659, loss: 3.4646
2022-10-07 12:10:39 - train: epoch 0031, iter [00960, 01251], lr: 0.001659, loss: 3.2952
2022-10-07 12:11:00 - train: epoch 0031, iter [00970, 01251], lr: 0.001658, loss: 2.3212
2022-10-07 12:11:21 - train: epoch 0031, iter [00980, 01251], lr: 0.001658, loss: 3.3292
2022-10-07 12:11:43 - train: epoch 0031, iter [00990, 01251], lr: 0.001658, loss: 3.1675
2022-10-07 12:12:04 - train: epoch 0031, iter [01000, 01251], lr: 0.001658, loss: 3.0718
2022-10-07 12:12:25 - train: epoch 0031, iter [01010, 01251], lr: 0.001658, loss: 3.9212
2022-10-07 12:12:46 - train: epoch 0031, iter [01020, 01251], lr: 0.001657, loss: 3.3630
2022-10-07 12:13:07 - train: epoch 0031, iter [01030, 01251], lr: 0.001657, loss: 3.2866
2022-10-07 12:13:28 - train: epoch 0031, iter [01040, 01251], lr: 0.001657, loss: 3.4483
2022-10-07 12:13:49 - train: epoch 0031, iter [01050, 01251], lr: 0.001657, loss: 3.4289
2022-10-07 12:14:10 - train: epoch 0031, iter [01060, 01251], lr: 0.001657, loss: 3.4429
2022-10-07 12:14:31 - train: epoch 0031, iter [01070, 01251], lr: 0.001656, loss: 3.1271
2022-10-07 12:14:52 - train: epoch 0031, iter [01080, 01251], lr: 0.001656, loss: 3.3013
2022-10-07 12:15:13 - train: epoch 0031, iter [01090, 01251], lr: 0.001656, loss: 3.3772
2022-10-07 12:15:34 - train: epoch 0031, iter [01100, 01251], lr: 0.001656, loss: 3.5717
2022-10-07 12:15:55 - train: epoch 0031, iter [01110, 01251], lr: 0.001656, loss: 3.9659
2022-10-07 12:16:16 - train: epoch 0031, iter [01120, 01251], lr: 0.001655, loss: 3.3213
2022-10-07 12:16:37 - train: epoch 0031, iter [01130, 01251], lr: 0.001655, loss: 3.3993
2022-10-07 12:16:58 - train: epoch 0031, iter [01140, 01251], lr: 0.001655, loss: 3.6152
2022-10-07 12:17:19 - train: epoch 0031, iter [01150, 01251], lr: 0.001655, loss: 2.8718
2022-10-07 12:17:40 - train: epoch 0031, iter [01160, 01251], lr: 0.001655, loss: 2.8448
2022-10-07 12:18:01 - train: epoch 0031, iter [01170, 01251], lr: 0.001654, loss: 2.9652
2022-10-07 12:18:22 - train: epoch 0031, iter [01180, 01251], lr: 0.001654, loss: 2.8646
2022-10-07 12:18:43 - train: epoch 0031, iter [01190, 01251], lr: 0.001654, loss: 3.2664
2022-10-07 12:19:04 - train: epoch 0031, iter [01200, 01251], lr: 0.001654, loss: 3.6278
2022-10-07 12:19:25 - train: epoch 0031, iter [01210, 01251], lr: 0.001654, loss: 3.3607
2022-10-07 12:19:46 - train: epoch 0031, iter [01220, 01251], lr: 0.001653, loss: 3.8691
2022-10-07 12:20:07 - train: epoch 0031, iter [01230, 01251], lr: 0.001653, loss: 2.8949
2022-10-07 12:20:28 - train: epoch 0031, iter [01240, 01251], lr: 0.001653, loss: 3.5786
2022-10-07 12:20:49 - train: epoch 0031, iter [01250, 01251], lr: 0.001653, loss: 3.7667
2022-10-07 12:20:53 - train: epoch 031, train_loss: 3.3286
2022-10-07 12:22:09 - eval: epoch: 031, acc1: 78.506%, acc5: 94.720%, test_loss: 0.9468, per_image_load_time: 0.961ms, per_image_inference_time: 1.435ms
2022-10-07 12:22:11 - until epoch: 031, best_acc1: 78.544%
2022-10-07 12:22:11 - epoch 032 lr: 0.001653
2022-10-07 12:22:38 - train: epoch 0032, iter [00010, 01251], lr: 0.001653, loss: 3.3742
2022-10-07 12:22:59 - train: epoch 0032, iter [00020, 01251], lr: 0.001652, loss: 2.9539
2022-10-07 12:23:20 - train: epoch 0032, iter [00030, 01251], lr: 0.001652, loss: 3.1638
2022-10-07 12:23:41 - train: epoch 0032, iter [00040, 01251], lr: 0.001652, loss: 2.6106
2022-10-07 12:24:02 - train: epoch 0032, iter [00050, 01251], lr: 0.001652, loss: 3.5195
2022-10-07 12:24:23 - train: epoch 0032, iter [00060, 01251], lr: 0.001652, loss: 2.9689
2022-10-07 12:24:44 - train: epoch 0032, iter [00070, 01251], lr: 0.001651, loss: 3.5862
2022-10-07 12:25:05 - train: epoch 0032, iter [00080, 01251], lr: 0.001651, loss: 2.7656
2022-10-07 12:25:26 - train: epoch 0032, iter [00090, 01251], lr: 0.001651, loss: 3.7657
2022-10-07 12:25:47 - train: epoch 0032, iter [00100, 01251], lr: 0.001651, loss: 3.1548
2022-10-07 12:26:08 - train: epoch 0032, iter [00110, 01251], lr: 0.001651, loss: 2.9828
2022-10-07 12:26:29 - train: epoch 0032, iter [00120, 01251], lr: 0.001650, loss: 3.3175
2022-10-07 12:26:50 - train: epoch 0032, iter [00130, 01251], lr: 0.001650, loss: 3.7118
2022-10-07 12:27:11 - train: epoch 0032, iter [00140, 01251], lr: 0.001650, loss: 3.0112
2022-10-07 12:27:32 - train: epoch 0032, iter [00150, 01251], lr: 0.001650, loss: 3.6288
2022-10-07 12:27:53 - train: epoch 0032, iter [00160, 01251], lr: 0.001650, loss: 3.5512
2022-10-07 12:28:15 - train: epoch 0032, iter [00170, 01251], lr: 0.001649, loss: 3.4876
2022-10-07 12:28:36 - train: epoch 0032, iter [00180, 01251], lr: 0.001649, loss: 3.3539
2022-10-07 12:28:57 - train: epoch 0032, iter [00190, 01251], lr: 0.001649, loss: 2.7656
2022-10-07 12:29:18 - train: epoch 0032, iter [00200, 01251], lr: 0.001649, loss: 2.9055
2022-10-07 12:29:39 - train: epoch 0032, iter [00210, 01251], lr: 0.001649, loss: 2.7618
2022-10-07 12:30:00 - train: epoch 0032, iter [00220, 01251], lr: 0.001648, loss: 3.2821
2022-10-07 12:30:21 - train: epoch 0032, iter [00230, 01251], lr: 0.001648, loss: 3.0414
2022-10-07 12:30:42 - train: epoch 0032, iter [00240, 01251], lr: 0.001648, loss: 2.9539
2022-10-07 12:31:04 - train: epoch 0032, iter [00250, 01251], lr: 0.001648, loss: 3.6049
2022-10-07 12:31:25 - train: epoch 0032, iter [00260, 01251], lr: 0.001648, loss: 2.8126
2022-10-07 12:31:46 - train: epoch 0032, iter [00270, 01251], lr: 0.001647, loss: 3.2451
2022-10-07 12:32:07 - train: epoch 0032, iter [00280, 01251], lr: 0.001647, loss: 2.6429
2022-10-07 12:32:28 - train: epoch 0032, iter [00290, 01251], lr: 0.001647, loss: 2.3505
2022-10-07 12:32:49 - train: epoch 0032, iter [00300, 01251], lr: 0.001647, loss: 3.5778
2022-10-07 12:33:10 - train: epoch 0032, iter [00310, 01251], lr: 0.001647, loss: 3.1555
2022-10-07 12:33:31 - train: epoch 0032, iter [00320, 01251], lr: 0.001646, loss: 3.8382
2022-10-07 12:33:52 - train: epoch 0032, iter [00330, 01251], lr: 0.001646, loss: 3.6714
2022-10-07 12:34:13 - train: epoch 0032, iter [00340, 01251], lr: 0.001646, loss: 3.1831
2022-10-07 12:34:34 - train: epoch 0032, iter [00350, 01251], lr: 0.001646, loss: 3.7118
2022-10-07 12:34:55 - train: epoch 0032, iter [00360, 01251], lr: 0.001646, loss: 3.0330
2022-10-07 12:35:16 - train: epoch 0032, iter [00370, 01251], lr: 0.001645, loss: 2.9491
2022-10-07 12:35:37 - train: epoch 0032, iter [00380, 01251], lr: 0.001645, loss: 3.5760
2022-10-07 12:35:58 - train: epoch 0032, iter [00390, 01251], lr: 0.001645, loss: 3.4094
2022-10-07 12:36:19 - train: epoch 0032, iter [00400, 01251], lr: 0.001645, loss: 3.4420
2022-10-07 12:36:40 - train: epoch 0032, iter [00410, 01251], lr: 0.001645, loss: 3.2695
2022-10-07 12:37:01 - train: epoch 0032, iter [00420, 01251], lr: 0.001644, loss: 3.1330
2022-10-07 12:37:23 - train: epoch 0032, iter [00430, 01251], lr: 0.001644, loss: 3.6682
2022-10-07 12:37:44 - train: epoch 0032, iter [00440, 01251], lr: 0.001644, loss: 3.2421
2022-10-07 12:38:05 - train: epoch 0032, iter [00450, 01251], lr: 0.001644, loss: 2.7005
2022-10-07 12:38:26 - train: epoch 0032, iter [00460, 01251], lr: 0.001644, loss: 4.1647
2022-10-07 12:38:47 - train: epoch 0032, iter [00470, 01251], lr: 0.001643, loss: 3.1735
2022-10-07 12:39:08 - train: epoch 0032, iter [00480, 01251], lr: 0.001643, loss: 3.3869
2022-10-07 12:39:29 - train: epoch 0032, iter [00490, 01251], lr: 0.001643, loss: 3.6744
2022-10-07 12:39:50 - train: epoch 0032, iter [00500, 01251], lr: 0.001643, loss: 3.3820
2022-10-07 12:40:11 - train: epoch 0032, iter [00510, 01251], lr: 0.001642, loss: 3.5779
2022-10-07 12:40:32 - train: epoch 0032, iter [00520, 01251], lr: 0.001642, loss: 3.5168
2022-10-07 12:40:53 - train: epoch 0032, iter [00530, 01251], lr: 0.001642, loss: 3.7989
2022-10-07 12:41:14 - train: epoch 0032, iter [00540, 01251], lr: 0.001642, loss: 3.9034
2022-10-07 12:41:35 - train: epoch 0032, iter [00550, 01251], lr: 0.001642, loss: 3.0683
2022-10-07 12:41:56 - train: epoch 0032, iter [00560, 01251], lr: 0.001641, loss: 2.8363
2022-10-07 12:42:17 - train: epoch 0032, iter [00570, 01251], lr: 0.001641, loss: 3.7466
2022-10-07 12:42:38 - train: epoch 0032, iter [00580, 01251], lr: 0.001641, loss: 3.0293
2022-10-07 12:42:59 - train: epoch 0032, iter [00590, 01251], lr: 0.001641, loss: 2.9877
2022-10-07 12:43:20 - train: epoch 0032, iter [00600, 01251], lr: 0.001641, loss: 3.1647
2022-10-07 12:43:41 - train: epoch 0032, iter [00610, 01251], lr: 0.001640, loss: 3.6879
2022-10-07 12:44:02 - train: epoch 0032, iter [00620, 01251], lr: 0.001640, loss: 3.0188
2022-10-07 12:44:23 - train: epoch 0032, iter [00630, 01251], lr: 0.001640, loss: 3.6555
2022-10-07 12:44:45 - train: epoch 0032, iter [00640, 01251], lr: 0.001640, loss: 3.4812
2022-10-07 12:45:06 - train: epoch 0032, iter [00650, 01251], lr: 0.001640, loss: 3.4425
2022-10-07 12:45:27 - train: epoch 0032, iter [00660, 01251], lr: 0.001639, loss: 3.4054
2022-10-07 12:45:48 - train: epoch 0032, iter [00670, 01251], lr: 0.001639, loss: 3.2567
2022-10-07 12:46:09 - train: epoch 0032, iter [00680, 01251], lr: 0.001639, loss: 3.5357
2022-10-07 12:46:30 - train: epoch 0032, iter [00690, 01251], lr: 0.001639, loss: 3.9254
2022-10-07 12:46:51 - train: epoch 0032, iter [00700, 01251], lr: 0.001639, loss: 3.6730
2022-10-07 12:47:12 - train: epoch 0032, iter [00710, 01251], lr: 0.001638, loss: 3.5113
2022-10-07 12:47:33 - train: epoch 0032, iter [00720, 01251], lr: 0.001638, loss: 3.2707
2022-10-07 12:47:54 - train: epoch 0032, iter [00730, 01251], lr: 0.001638, loss: 3.4339
2022-10-07 12:48:15 - train: epoch 0032, iter [00740, 01251], lr: 0.001638, loss: 2.9628
2022-10-07 12:48:36 - train: epoch 0032, iter [00750, 01251], lr: 0.001638, loss: 2.9007
2022-10-07 12:48:57 - train: epoch 0032, iter [00760, 01251], lr: 0.001637, loss: 4.1034
2022-10-07 12:49:18 - train: epoch 0032, iter [00770, 01251], lr: 0.001637, loss: 3.7989
2022-10-07 12:49:39 - train: epoch 0032, iter [00780, 01251], lr: 0.001637, loss: 3.6189
2022-10-07 12:50:00 - train: epoch 0032, iter [00790, 01251], lr: 0.001637, loss: 2.8390
2022-10-07 12:50:21 - train: epoch 0032, iter [00800, 01251], lr: 0.001637, loss: 3.4765
2022-10-07 12:50:42 - train: epoch 0032, iter [00810, 01251], lr: 0.001636, loss: 3.6033
2022-10-07 12:51:03 - train: epoch 0032, iter [00820, 01251], lr: 0.001636, loss: 3.2232
2022-10-07 12:51:24 - train: epoch 0032, iter [00830, 01251], lr: 0.001636, loss: 3.7537
2022-10-07 12:51:45 - train: epoch 0032, iter [00840, 01251], lr: 0.001636, loss: 3.1693
2022-10-07 12:52:06 - train: epoch 0032, iter [00850, 01251], lr: 0.001636, loss: 3.5579
2022-10-07 12:52:27 - train: epoch 0032, iter [00860, 01251], lr: 0.001635, loss: 3.5055
2022-10-07 12:52:48 - train: epoch 0032, iter [00870, 01251], lr: 0.001635, loss: 3.4002
2022-10-07 12:53:10 - train: epoch 0032, iter [00880, 01251], lr: 0.001635, loss: 3.2982
2022-10-07 12:53:31 - train: epoch 0032, iter [00890, 01251], lr: 0.001635, loss: 3.8577
2022-10-07 12:53:52 - train: epoch 0032, iter [00900, 01251], lr: 0.001635, loss: 3.7098
2022-10-07 12:54:13 - train: epoch 0032, iter [00910, 01251], lr: 0.001634, loss: 3.6299
2022-10-07 12:54:34 - train: epoch 0032, iter [00920, 01251], lr: 0.001634, loss: 3.4245
2022-10-07 12:54:55 - train: epoch 0032, iter [00930, 01251], lr: 0.001634, loss: 3.8005
2022-10-07 12:55:16 - train: epoch 0032, iter [00940, 01251], lr: 0.001634, loss: 2.7896
2022-10-07 12:55:37 - train: epoch 0032, iter [00950, 01251], lr: 0.001634, loss: 3.5935
2022-10-07 12:55:58 - train: epoch 0032, iter [00960, 01251], lr: 0.001633, loss: 3.1947
2022-10-07 12:56:19 - train: epoch 0032, iter [00970, 01251], lr: 0.001633, loss: 2.7593
2022-10-07 12:56:40 - train: epoch 0032, iter [00980, 01251], lr: 0.001633, loss: 3.7309
2022-10-07 12:57:01 - train: epoch 0032, iter [00990, 01251], lr: 0.001633, loss: 3.4162
2022-10-07 12:57:22 - train: epoch 0032, iter [01000, 01251], lr: 0.001633, loss: 3.4518
2022-10-07 12:57:43 - train: epoch 0032, iter [01010, 01251], lr: 0.001632, loss: 3.1888
2022-10-07 12:58:04 - train: epoch 0032, iter [01020, 01251], lr: 0.001632, loss: 3.6033
2022-10-07 12:58:25 - train: epoch 0032, iter [01030, 01251], lr: 0.001632, loss: 3.6673
2022-10-07 12:58:46 - train: epoch 0032, iter [01040, 01251], lr: 0.001632, loss: 3.7495
2022-10-07 12:59:07 - train: epoch 0032, iter [01050, 01251], lr: 0.001631, loss: 3.5175
2022-10-07 12:59:28 - train: epoch 0032, iter [01060, 01251], lr: 0.001631, loss: 3.6729
2022-10-07 12:59:49 - train: epoch 0032, iter [01070, 01251], lr: 0.001631, loss: 3.4828
2022-10-07 13:00:10 - train: epoch 0032, iter [01080, 01251], lr: 0.001631, loss: 3.5611
2022-10-07 13:00:31 - train: epoch 0032, iter [01090, 01251], lr: 0.001631, loss: 3.3232
2022-10-07 13:00:52 - train: epoch 0032, iter [01100, 01251], lr: 0.001630, loss: 3.4414
2022-10-07 13:01:13 - train: epoch 0032, iter [01110, 01251], lr: 0.001630, loss: 3.6269
2022-10-07 13:01:34 - train: epoch 0032, iter [01120, 01251], lr: 0.001630, loss: 3.0298
2022-10-07 13:01:55 - train: epoch 0032, iter [01130, 01251], lr: 0.001630, loss: 3.4127
2022-10-07 13:02:16 - train: epoch 0032, iter [01140, 01251], lr: 0.001630, loss: 2.8676
2022-10-07 13:02:37 - train: epoch 0032, iter [01150, 01251], lr: 0.001629, loss: 3.5645
2022-10-07 13:02:58 - train: epoch 0032, iter [01160, 01251], lr: 0.001629, loss: 3.3558
2022-10-07 13:03:19 - train: epoch 0032, iter [01170, 01251], lr: 0.001629, loss: 3.0111
2022-10-07 13:03:41 - train: epoch 0032, iter [01180, 01251], lr: 0.001629, loss: 3.8794
2022-10-07 13:04:02 - train: epoch 0032, iter [01190, 01251], lr: 0.001629, loss: 2.6352
2022-10-07 13:04:23 - train: epoch 0032, iter [01200, 01251], lr: 0.001628, loss: 2.9366
2022-10-07 13:04:44 - train: epoch 0032, iter [01210, 01251], lr: 0.001628, loss: 3.1997
2022-10-07 13:05:05 - train: epoch 0032, iter [01220, 01251], lr: 0.001628, loss: 3.3315
2022-10-07 13:05:26 - train: epoch 0032, iter [01230, 01251], lr: 0.001628, loss: 3.3711
2022-10-07 13:05:47 - train: epoch 0032, iter [01240, 01251], lr: 0.001628, loss: 3.4446
2022-10-07 13:06:08 - train: epoch 0032, iter [01250, 01251], lr: 0.001627, loss: 3.7808
2022-10-07 13:06:11 - train: epoch 032, train_loss: 3.3250
2022-10-07 13:07:28 - eval: epoch: 032, acc1: 78.588%, acc5: 94.844%, test_loss: 0.9398, per_image_load_time: 0.728ms, per_image_inference_time: 1.431ms
2022-10-07 13:07:29 - until epoch: 032, best_acc1: 78.588%
2022-10-07 13:07:29 - epoch 033 lr: 0.001627
2022-10-07 13:07:56 - train: epoch 0033, iter [00010, 01251], lr: 0.001627, loss: 3.1073
2022-10-07 13:08:17 - train: epoch 0033, iter [00020, 01251], lr: 0.001627, loss: 3.6651
2022-10-07 13:08:38 - train: epoch 0033, iter [00030, 01251], lr: 0.001627, loss: 2.9642
2022-10-07 13:08:59 - train: epoch 0033, iter [00040, 01251], lr: 0.001627, loss: 2.9408
2022-10-07 13:09:20 - train: epoch 0033, iter [00050, 01251], lr: 0.001626, loss: 3.0499
2022-10-07 13:09:41 - train: epoch 0033, iter [00060, 01251], lr: 0.001626, loss: 3.3939
2022-10-07 13:10:02 - train: epoch 0033, iter [00070, 01251], lr: 0.001626, loss: 3.4083
2022-10-07 13:10:23 - train: epoch 0033, iter [00080, 01251], lr: 0.001626, loss: 3.6693
2022-10-07 13:10:45 - train: epoch 0033, iter [00090, 01251], lr: 0.001626, loss: 3.0517
2022-10-07 13:11:06 - train: epoch 0033, iter [00100, 01251], lr: 0.001625, loss: 3.7499
2022-10-07 13:11:27 - train: epoch 0033, iter [00110, 01251], lr: 0.001625, loss: 3.0716
2022-10-07 13:11:48 - train: epoch 0033, iter [00120, 01251], lr: 0.001625, loss: 3.4217
2022-10-07 13:12:09 - train: epoch 0033, iter [00130, 01251], lr: 0.001625, loss: 3.7077
2022-10-07 13:12:30 - train: epoch 0033, iter [00140, 01251], lr: 0.001624, loss: 3.5625
2022-10-07 13:12:51 - train: epoch 0033, iter [00150, 01251], lr: 0.001624, loss: 3.3383
2022-10-07 13:13:12 - train: epoch 0033, iter [00160, 01251], lr: 0.001624, loss: 3.0883
2022-10-07 13:13:34 - train: epoch 0033, iter [00170, 01251], lr: 0.001624, loss: 2.6681
2022-10-07 13:13:55 - train: epoch 0033, iter [00180, 01251], lr: 0.001624, loss: 2.9643
2022-10-07 13:14:16 - train: epoch 0033, iter [00190, 01251], lr: 0.001623, loss: 3.1980
2022-10-07 13:14:37 - train: epoch 0033, iter [00200, 01251], lr: 0.001623, loss: 3.1896
2022-10-07 13:14:58 - train: epoch 0033, iter [00210, 01251], lr: 0.001623, loss: 2.5760
2022-10-07 13:15:19 - train: epoch 0033, iter [00220, 01251], lr: 0.001623, loss: 3.1781
2022-10-07 13:15:40 - train: epoch 0033, iter [00230, 01251], lr: 0.001623, loss: 3.1190
2022-10-07 13:16:01 - train: epoch 0033, iter [00240, 01251], lr: 0.001622, loss: 3.1262
2022-10-07 13:16:22 - train: epoch 0033, iter [00250, 01251], lr: 0.001622, loss: 3.6181
2022-10-07 13:16:43 - train: epoch 0033, iter [00260, 01251], lr: 0.001622, loss: 2.8581
2022-10-07 13:17:04 - train: epoch 0033, iter [00270, 01251], lr: 0.001622, loss: 3.3479
2022-10-07 13:17:25 - train: epoch 0033, iter [00280, 01251], lr: 0.001622, loss: 3.7405
2022-10-07 13:17:47 - train: epoch 0033, iter [00290, 01251], lr: 0.001621, loss: 3.1065
2022-10-07 13:18:08 - train: epoch 0033, iter [00300, 01251], lr: 0.001621, loss: 3.3590
2022-10-07 13:18:29 - train: epoch 0033, iter [00310, 01251], lr: 0.001621, loss: 3.4391
2022-10-07 13:18:50 - train: epoch 0033, iter [00320, 01251], lr: 0.001621, loss: 3.7989
2022-10-07 13:19:11 - train: epoch 0033, iter [00330, 01251], lr: 0.001621, loss: 3.2718
2022-10-07 13:19:32 - train: epoch 0033, iter [00340, 01251], lr: 0.001620, loss: 3.0279
2022-10-07 13:19:53 - train: epoch 0033, iter [00350, 01251], lr: 0.001620, loss: 3.1935
2022-10-07 13:20:14 - train: epoch 0033, iter [00360, 01251], lr: 0.001620, loss: 2.5985
2022-10-07 13:20:35 - train: epoch 0033, iter [00370, 01251], lr: 0.001620, loss: 3.3610
2022-10-07 13:20:56 - train: epoch 0033, iter [00380, 01251], lr: 0.001620, loss: 3.4869
2022-10-07 13:21:18 - train: epoch 0033, iter [00390, 01251], lr: 0.001619, loss: 2.8573
2022-10-07 13:21:39 - train: epoch 0033, iter [00400, 01251], lr: 0.001619, loss: 3.1284
2022-10-07 13:22:00 - train: epoch 0033, iter [00410, 01251], lr: 0.001619, loss: 3.3460
2022-10-07 13:22:21 - train: epoch 0033, iter [00420, 01251], lr: 0.001619, loss: 3.0528
2022-10-07 13:22:42 - train: epoch 0033, iter [00430, 01251], lr: 0.001618, loss: 3.6625
2022-10-07 13:23:03 - train: epoch 0033, iter [00440, 01251], lr: 0.001618, loss: 3.5747
2022-10-07 13:23:24 - train: epoch 0033, iter [00450, 01251], lr: 0.001618, loss: 3.6326
2022-10-07 13:23:45 - train: epoch 0033, iter [00460, 01251], lr: 0.001618, loss: 3.4478
2022-10-07 13:24:06 - train: epoch 0033, iter [00470, 01251], lr: 0.001618, loss: 3.7541
2022-10-07 13:24:28 - train: epoch 0033, iter [00480, 01251], lr: 0.001617, loss: 3.0500
2022-10-07 13:24:49 - train: epoch 0033, iter [00490, 01251], lr: 0.001617, loss: 3.7428
2022-10-07 13:25:10 - train: epoch 0033, iter [00500, 01251], lr: 0.001617, loss: 3.4100
2022-10-07 13:25:31 - train: epoch 0033, iter [00510, 01251], lr: 0.001617, loss: 3.4444
2022-10-07 13:25:52 - train: epoch 0033, iter [00520, 01251], lr: 0.001617, loss: 3.0850
2022-10-07 13:26:13 - train: epoch 0033, iter [00530, 01251], lr: 0.001616, loss: 3.4327
2022-10-07 13:26:34 - train: epoch 0033, iter [00540, 01251], lr: 0.001616, loss: 3.1773
2022-10-07 13:26:55 - train: epoch 0033, iter [00550, 01251], lr: 0.001616, loss: 3.6817
2022-10-07 13:27:16 - train: epoch 0033, iter [00560, 01251], lr: 0.001616, loss: 3.5243
2022-10-07 13:27:38 - train: epoch 0033, iter [00570, 01251], lr: 0.001616, loss: 3.5588
2022-10-07 13:27:59 - train: epoch 0033, iter [00580, 01251], lr: 0.001615, loss: 3.0991
2022-10-07 13:28:20 - train: epoch 0033, iter [00590, 01251], lr: 0.001615, loss: 3.2691
2022-10-07 13:28:41 - train: epoch 0033, iter [00600, 01251], lr: 0.001615, loss: 2.6785
2022-10-07 13:29:02 - train: epoch 0033, iter [00610, 01251], lr: 0.001615, loss: 3.1075
2022-10-07 13:29:23 - train: epoch 0033, iter [00620, 01251], lr: 0.001615, loss: 3.6159
2022-10-07 13:29:44 - train: epoch 0033, iter [00630, 01251], lr: 0.001614, loss: 3.7620
2022-10-07 13:30:05 - train: epoch 0033, iter [00640, 01251], lr: 0.001614, loss: 2.6859
2022-10-07 13:30:26 - train: epoch 0033, iter [00650, 01251], lr: 0.001614, loss: 3.9876
2022-10-07 13:30:47 - train: epoch 0033, iter [00660, 01251], lr: 0.001614, loss: 2.8761
2022-10-07 13:31:08 - train: epoch 0033, iter [00670, 01251], lr: 0.001613, loss: 3.0441
2022-10-07 13:31:29 - train: epoch 0033, iter [00680, 01251], lr: 0.001613, loss: 3.4622
2022-10-07 13:31:50 - train: epoch 0033, iter [00690, 01251], lr: 0.001613, loss: 3.3531
2022-10-07 13:32:11 - train: epoch 0033, iter [00700, 01251], lr: 0.001613, loss: 3.1287
2022-10-07 13:32:32 - train: epoch 0033, iter [00710, 01251], lr: 0.001613, loss: 3.5991
2022-10-07 13:32:53 - train: epoch 0033, iter [00720, 01251], lr: 0.001612, loss: 3.0143
2022-10-07 13:33:14 - train: epoch 0033, iter [00730, 01251], lr: 0.001612, loss: 3.6943
2022-10-07 13:33:35 - train: epoch 0033, iter [00740, 01251], lr: 0.001612, loss: 3.8267
2022-10-07 13:33:57 - train: epoch 0033, iter [00750, 01251], lr: 0.001612, loss: 3.9695
2022-10-07 13:34:18 - train: epoch 0033, iter [00760, 01251], lr: 0.001612, loss: 3.2127
2022-10-07 13:34:39 - train: epoch 0033, iter [00770, 01251], lr: 0.001611, loss: 3.0286
2022-10-07 13:35:00 - train: epoch 0033, iter [00780, 01251], lr: 0.001611, loss: 3.5956
2022-10-07 13:35:21 - train: epoch 0033, iter [00790, 01251], lr: 0.001611, loss: 3.3514
2022-10-07 13:35:42 - train: epoch 0033, iter [00800, 01251], lr: 0.001611, loss: 2.4555
2022-10-07 13:36:03 - train: epoch 0033, iter [00810, 01251], lr: 0.001611, loss: 3.5523
2022-10-07 13:36:24 - train: epoch 0033, iter [00820, 01251], lr: 0.001610, loss: 3.4947
2022-10-07 13:36:45 - train: epoch 0033, iter [00830, 01251], lr: 0.001610, loss: 3.7864
2022-10-07 13:37:06 - train: epoch 0033, iter [00840, 01251], lr: 0.001610, loss: 2.4240
2022-10-07 13:37:27 - train: epoch 0033, iter [00850, 01251], lr: 0.001610, loss: 3.1852
2022-10-07 13:37:48 - train: epoch 0033, iter [00860, 01251], lr: 0.001610, loss: 3.5759
2022-10-07 13:38:09 - train: epoch 0033, iter [00870, 01251], lr: 0.001609, loss: 3.6140
2022-10-07 13:38:30 - train: epoch 0033, iter [00880, 01251], lr: 0.001609, loss: 3.3774
2022-10-07 13:38:51 - train: epoch 0033, iter [00890, 01251], lr: 0.001609, loss: 3.6420
2022-10-07 13:39:13 - train: epoch 0033, iter [00900, 01251], lr: 0.001609, loss: 3.3954
2022-10-07 13:39:34 - train: epoch 0033, iter [00910, 01251], lr: 0.001608, loss: 3.2566
2022-10-07 13:39:55 - train: epoch 0033, iter [00920, 01251], lr: 0.001608, loss: 3.8586
2022-10-07 13:40:16 - train: epoch 0033, iter [00930, 01251], lr: 0.001608, loss: 2.9625
2022-10-07 13:40:37 - train: epoch 0033, iter [00940, 01251], lr: 0.001608, loss: 3.6014
2022-10-07 13:40:58 - train: epoch 0033, iter [00950, 01251], lr: 0.001608, loss: 3.2280
2022-10-07 13:41:19 - train: epoch 0033, iter [00960, 01251], lr: 0.001607, loss: 3.3584
2022-10-07 13:41:40 - train: epoch 0033, iter [00970, 01251], lr: 0.001607, loss: 3.9447
2022-10-07 13:42:01 - train: epoch 0033, iter [00980, 01251], lr: 0.001607, loss: 2.5594
2022-10-07 13:42:22 - train: epoch 0033, iter [00990, 01251], lr: 0.001607, loss: 2.8970
2022-10-07 13:42:43 - train: epoch 0033, iter [01000, 01251], lr: 0.001607, loss: 3.6470
2022-10-07 13:43:04 - train: epoch 0033, iter [01010, 01251], lr: 0.001606, loss: 3.6361
2022-10-07 13:43:25 - train: epoch 0033, iter [01020, 01251], lr: 0.001606, loss: 3.3460
2022-10-07 13:43:46 - train: epoch 0033, iter [01030, 01251], lr: 0.001606, loss: 3.6794
2022-10-07 13:44:07 - train: epoch 0033, iter [01040, 01251], lr: 0.001606, loss: 3.4767
2022-10-07 13:44:28 - train: epoch 0033, iter [01050, 01251], lr: 0.001606, loss: 3.1731
2022-10-07 13:44:49 - train: epoch 0033, iter [01060, 01251], lr: 0.001605, loss: 3.7883
2022-10-07 13:45:10 - train: epoch 0033, iter [01070, 01251], lr: 0.001605, loss: 3.3572
2022-10-07 13:45:31 - train: epoch 0033, iter [01080, 01251], lr: 0.001605, loss: 3.1860
2022-10-07 13:45:53 - train: epoch 0033, iter [01090, 01251], lr: 0.001605, loss: 3.3822
2022-10-07 13:46:14 - train: epoch 0033, iter [01100, 01251], lr: 0.001604, loss: 3.7190
2022-10-07 13:46:35 - train: epoch 0033, iter [01110, 01251], lr: 0.001604, loss: 3.7020
2022-10-07 13:46:56 - train: epoch 0033, iter [01120, 01251], lr: 0.001604, loss: 3.1479
2022-10-07 13:47:17 - train: epoch 0033, iter [01130, 01251], lr: 0.001604, loss: 3.4504
2022-10-07 13:47:38 - train: epoch 0033, iter [01140, 01251], lr: 0.001604, loss: 3.6120
2022-10-07 13:47:59 - train: epoch 0033, iter [01150, 01251], lr: 0.001603, loss: 3.9296
2022-10-07 13:48:20 - train: epoch 0033, iter [01160, 01251], lr: 0.001603, loss: 3.0879
2022-10-07 13:48:41 - train: epoch 0033, iter [01170, 01251], lr: 0.001603, loss: 3.5217
2022-10-07 13:49:02 - train: epoch 0033, iter [01180, 01251], lr: 0.001603, loss: 3.5583
2022-10-07 13:49:23 - train: epoch 0033, iter [01190, 01251], lr: 0.001603, loss: 3.2631
2022-10-07 13:49:44 - train: epoch 0033, iter [01200, 01251], lr: 0.001602, loss: 3.1505
2022-10-07 13:50:05 - train: epoch 0033, iter [01210, 01251], lr: 0.001602, loss: 3.6212
2022-10-07 13:50:26 - train: epoch 0033, iter [01220, 01251], lr: 0.001602, loss: 3.4110
2022-10-07 13:50:47 - train: epoch 0033, iter [01230, 01251], lr: 0.001602, loss: 3.9068
2022-10-07 13:51:08 - train: epoch 0033, iter [01240, 01251], lr: 0.001602, loss: 3.1489
2022-10-07 13:51:29 - train: epoch 0033, iter [01250, 01251], lr: 0.001601, loss: 3.1373
2022-10-07 13:51:33 - train: epoch 033, train_loss: 3.3044
2022-10-07 13:52:49 - eval: epoch: 033, acc1: 78.784%, acc5: 94.922%, test_loss: 0.9522, per_image_load_time: 0.992ms, per_image_inference_time: 1.433ms
2022-10-07 13:52:51 - until epoch: 033, best_acc1: 78.784%
2022-10-07 13:52:51 - epoch 034 lr: 0.001601
2022-10-07 13:53:18 - train: epoch 0034, iter [00010, 01251], lr: 0.001601, loss: 3.5760
2022-10-07 13:53:39 - train: epoch 0034, iter [00020, 01251], lr: 0.001601, loss: 3.6229
2022-10-07 13:54:00 - train: epoch 0034, iter [00030, 01251], lr: 0.001601, loss: 3.3649
2022-10-07 13:54:21 - train: epoch 0034, iter [00040, 01251], lr: 0.001600, loss: 3.5462
2022-10-07 13:54:42 - train: epoch 0034, iter [00050, 01251], lr: 0.001600, loss: 3.2879
2022-10-07 13:55:03 - train: epoch 0034, iter [00060, 01251], lr: 0.001600, loss: 3.4524
2022-10-07 13:55:24 - train: epoch 0034, iter [00070, 01251], lr: 0.001600, loss: 3.0373
2022-10-07 13:55:46 - train: epoch 0034, iter [00080, 01251], lr: 0.001600, loss: 3.3750
2022-10-07 13:56:07 - train: epoch 0034, iter [00090, 01251], lr: 0.001599, loss: 3.1489
2022-10-07 13:56:28 - train: epoch 0034, iter [00100, 01251], lr: 0.001599, loss: 2.9209
2022-10-07 13:56:49 - train: epoch 0034, iter [00110, 01251], lr: 0.001599, loss: 3.3029
2022-10-07 13:57:10 - train: epoch 0034, iter [00120, 01251], lr: 0.001599, loss: 3.2867
2022-10-07 13:57:31 - train: epoch 0034, iter [00130, 01251], lr: 0.001599, loss: 3.8448
2022-10-07 13:57:52 - train: epoch 0034, iter [00140, 01251], lr: 0.001598, loss: 3.3064
2022-10-07 13:58:14 - train: epoch 0034, iter [00150, 01251], lr: 0.001598, loss: 3.0802
2022-10-07 13:58:35 - train: epoch 0034, iter [00160, 01251], lr: 0.001598, loss: 3.2934
2022-10-07 13:58:56 - train: epoch 0034, iter [00170, 01251], lr: 0.001598, loss: 3.5771
2022-10-07 13:59:17 - train: epoch 0034, iter [00180, 01251], lr: 0.001597, loss: 3.3411
2022-10-07 13:59:38 - train: epoch 0034, iter [00190, 01251], lr: 0.001597, loss: 3.4398
2022-10-07 13:59:59 - train: epoch 0034, iter [00200, 01251], lr: 0.001597, loss: 3.5538
2022-10-07 14:00:20 - train: epoch 0034, iter [00210, 01251], lr: 0.001597, loss: 3.1391
2022-10-07 14:00:41 - train: epoch 0034, iter [00220, 01251], lr: 0.001597, loss: 3.4467
2022-10-07 14:01:02 - train: epoch 0034, iter [00230, 01251], lr: 0.001596, loss: 3.2286
2022-10-07 14:01:24 - train: epoch 0034, iter [00240, 01251], lr: 0.001596, loss: 3.0993
2022-10-07 14:01:45 - train: epoch 0034, iter [00250, 01251], lr: 0.001596, loss: 3.7953
2022-10-07 14:02:06 - train: epoch 0034, iter [00260, 01251], lr: 0.001596, loss: 3.7751
2022-10-07 14:02:27 - train: epoch 0034, iter [00270, 01251], lr: 0.001596, loss: 3.9457
2022-10-07 14:02:48 - train: epoch 0034, iter [00280, 01251], lr: 0.001595, loss: 3.6763
2022-10-07 14:03:09 - train: epoch 0034, iter [00290, 01251], lr: 0.001595, loss: 3.5934
2022-10-07 14:03:30 - train: epoch 0034, iter [00300, 01251], lr: 0.001595, loss: 2.7493
2022-10-07 14:03:51 - train: epoch 0034, iter [00310, 01251], lr: 0.001595, loss: 3.2042
2022-10-07 14:04:12 - train: epoch 0034, iter [00320, 01251], lr: 0.001595, loss: 3.6230
2022-10-07 14:04:33 - train: epoch 0034, iter [00330, 01251], lr: 0.001594, loss: 3.2915
2022-10-07 14:04:55 - train: epoch 0034, iter [00340, 01251], lr: 0.001594, loss: 2.9017
2022-10-07 14:05:16 - train: epoch 0034, iter [00350, 01251], lr: 0.001594, loss: 3.2479
2022-10-07 14:05:37 - train: epoch 0034, iter [00360, 01251], lr: 0.001594, loss: 3.0659
2022-10-07 14:05:58 - train: epoch 0034, iter [00370, 01251], lr: 0.001593, loss: 3.8656
2022-10-07 14:06:19 - train: epoch 0034, iter [00380, 01251], lr: 0.001593, loss: 2.9605
2022-10-07 14:06:40 - train: epoch 0034, iter [00390, 01251], lr: 0.001593, loss: 2.8206
2022-10-07 14:07:02 - train: epoch 0034, iter [00400, 01251], lr: 0.001593, loss: 3.6133
2022-10-07 14:07:23 - train: epoch 0034, iter [00410, 01251], lr: 0.001593, loss: 3.7590
2022-10-07 14:07:44 - train: epoch 0034, iter [00420, 01251], lr: 0.001592, loss: 3.3825
2022-10-07 14:08:05 - train: epoch 0034, iter [00430, 01251], lr: 0.001592, loss: 3.3035
2022-10-07 14:08:26 - train: epoch 0034, iter [00440, 01251], lr: 0.001592, loss: 3.1945
2022-10-07 14:08:47 - train: epoch 0034, iter [00450, 01251], lr: 0.001592, loss: 2.9264
2022-10-07 14:09:08 - train: epoch 0034, iter [00460, 01251], lr: 0.001592, loss: 3.5694
2022-10-07 14:09:30 - train: epoch 0034, iter [00470, 01251], lr: 0.001591, loss: 3.6481
2022-10-07 14:09:51 - train: epoch 0034, iter [00480, 01251], lr: 0.001591, loss: 3.0516
2022-10-07 14:10:12 - train: epoch 0034, iter [00490, 01251], lr: 0.001591, loss: 3.3196
2022-10-07 14:10:33 - train: epoch 0034, iter [00500, 01251], lr: 0.001591, loss: 2.8894
2022-10-07 14:10:55 - train: epoch 0034, iter [00510, 01251], lr: 0.001590, loss: 3.1645
2022-10-07 14:11:16 - train: epoch 0034, iter [00520, 01251], lr: 0.001590, loss: 2.6484
2022-10-07 14:11:37 - train: epoch 0034, iter [00530, 01251], lr: 0.001590, loss: 2.7708
2022-10-07 14:11:58 - train: epoch 0034, iter [00540, 01251], lr: 0.001590, loss: 3.0555
2022-10-07 14:12:19 - train: epoch 0034, iter [00550, 01251], lr: 0.001590, loss: 3.0561
2022-10-07 14:12:40 - train: epoch 0034, iter [00560, 01251], lr: 0.001589, loss: 3.2469
2022-10-07 14:13:02 - train: epoch 0034, iter [00570, 01251], lr: 0.001589, loss: 3.5086
2022-10-07 14:13:23 - train: epoch 0034, iter [00580, 01251], lr: 0.001589, loss: 3.5403
2022-10-07 14:13:44 - train: epoch 0034, iter [00590, 01251], lr: 0.001589, loss: 3.1123
2022-10-07 14:14:05 - train: epoch 0034, iter [00600, 01251], lr: 0.001589, loss: 3.6280
2022-10-07 14:14:26 - train: epoch 0034, iter [00610, 01251], lr: 0.001588, loss: 3.2651
2022-10-07 14:14:48 - train: epoch 0034, iter [00620, 01251], lr: 0.001588, loss: 3.6266
2022-10-07 14:15:09 - train: epoch 0034, iter [00630, 01251], lr: 0.001588, loss: 3.5942
2022-10-07 14:15:30 - train: epoch 0034, iter [00640, 01251], lr: 0.001588, loss: 2.9238
2022-10-07 14:15:51 - train: epoch 0034, iter [00650, 01251], lr: 0.001587, loss: 2.9761
2022-10-07 14:16:12 - train: epoch 0034, iter [00660, 01251], lr: 0.001587, loss: 3.3340
2022-10-07 14:16:33 - train: epoch 0034, iter [00670, 01251], lr: 0.001587, loss: 2.8038
2022-10-07 14:16:55 - train: epoch 0034, iter [00680, 01251], lr: 0.001587, loss: 3.5629
2022-10-07 14:17:16 - train: epoch 0034, iter [00690, 01251], lr: 0.001587, loss: 3.5590
2022-10-07 14:17:37 - train: epoch 0034, iter [00700, 01251], lr: 0.001586, loss: 3.4694
2022-10-07 14:17:58 - train: epoch 0034, iter [00710, 01251], lr: 0.001586, loss: 3.1546
2022-10-07 14:18:19 - train: epoch 0034, iter [00720, 01251], lr: 0.001586, loss: 3.1805
2022-10-07 14:18:40 - train: epoch 0034, iter [00730, 01251], lr: 0.001586, loss: 2.8335
2022-10-07 14:19:02 - train: epoch 0034, iter [00740, 01251], lr: 0.001586, loss: 3.6669
2022-10-07 14:19:23 - train: epoch 0034, iter [00750, 01251], lr: 0.001585, loss: 3.3007
2022-10-07 14:19:44 - train: epoch 0034, iter [00760, 01251], lr: 0.001585, loss: 3.3988
2022-10-07 14:20:05 - train: epoch 0034, iter [00770, 01251], lr: 0.001585, loss: 3.2420
2022-10-07 14:20:27 - train: epoch 0034, iter [00780, 01251], lr: 0.001585, loss: 3.4235
2022-10-07 14:20:48 - train: epoch 0034, iter [00790, 01251], lr: 0.001584, loss: 3.0338
2022-10-07 14:21:09 - train: epoch 0034, iter [00800, 01251], lr: 0.001584, loss: 3.2728
2022-10-07 14:21:30 - train: epoch 0034, iter [00810, 01251], lr: 0.001584, loss: 3.6812
2022-10-07 14:21:52 - train: epoch 0034, iter [00820, 01251], lr: 0.001584, loss: 3.6726
2022-10-07 14:22:13 - train: epoch 0034, iter [00830, 01251], lr: 0.001584, loss: 3.0882
2022-10-07 14:22:34 - train: epoch 0034, iter [00840, 01251], lr: 0.001583, loss: 3.8991
2022-10-07 14:22:55 - train: epoch 0034, iter [00850, 01251], lr: 0.001583, loss: 3.8172
2022-10-07 14:23:17 - train: epoch 0034, iter [00860, 01251], lr: 0.001583, loss: 3.4975
2022-10-07 14:23:38 - train: epoch 0034, iter [00870, 01251], lr: 0.001583, loss: 2.8256
2022-10-07 14:23:59 - train: epoch 0034, iter [00880, 01251], lr: 0.001583, loss: 3.6327
2022-10-07 14:24:20 - train: epoch 0034, iter [00890, 01251], lr: 0.001582, loss: 3.5776
2022-10-07 14:24:41 - train: epoch 0034, iter [00900, 01251], lr: 0.001582, loss: 3.3967
2022-10-07 14:25:02 - train: epoch 0034, iter [00910, 01251], lr: 0.001582, loss: 3.7778
2022-10-07 14:25:24 - train: epoch 0034, iter [00920, 01251], lr: 0.001582, loss: 3.6531
2022-10-07 14:25:45 - train: epoch 0034, iter [00930, 01251], lr: 0.001581, loss: 3.4559
2022-10-07 14:26:06 - train: epoch 0034, iter [00940, 01251], lr: 0.001581, loss: 3.7118
2022-10-07 14:26:27 - train: epoch 0034, iter [00950, 01251], lr: 0.001581, loss: 3.1711
2022-10-07 14:26:48 - train: epoch 0034, iter [00960, 01251], lr: 0.001581, loss: 3.9694
2022-10-07 14:27:09 - train: epoch 0034, iter [00970, 01251], lr: 0.001581, loss: 3.3910
2022-10-07 14:27:31 - train: epoch 0034, iter [00980, 01251], lr: 0.001580, loss: 3.3706
2022-10-07 14:27:52 - train: epoch 0034, iter [00990, 01251], lr: 0.001580, loss: 3.6755
2022-10-07 14:28:13 - train: epoch 0034, iter [01000, 01251], lr: 0.001580, loss: 2.9996
2022-10-07 14:28:34 - train: epoch 0034, iter [01010, 01251], lr: 0.001580, loss: 3.5503
2022-10-07 14:28:55 - train: epoch 0034, iter [01020, 01251], lr: 0.001580, loss: 3.0898
2022-10-07 14:29:16 - train: epoch 0034, iter [01030, 01251], lr: 0.001579, loss: 3.2210
2022-10-07 14:29:37 - train: epoch 0034, iter [01040, 01251], lr: 0.001579, loss: 3.1011
2022-10-07 14:29:59 - train: epoch 0034, iter [01050, 01251], lr: 0.001579, loss: 3.2973
2022-10-07 14:30:20 - train: epoch 0034, iter [01060, 01251], lr: 0.001579, loss: 3.3103
2022-10-07 14:30:41 - train: epoch 0034, iter [01070, 01251], lr: 0.001578, loss: 3.0123
2022-10-07 14:31:02 - train: epoch 0034, iter [01080, 01251], lr: 0.001578, loss: 3.0015
2022-10-07 14:31:23 - train: epoch 0034, iter [01090, 01251], lr: 0.001578, loss: 3.7126
2022-10-07 14:31:44 - train: epoch 0034, iter [01100, 01251], lr: 0.001578, loss: 3.0145
2022-10-07 14:32:05 - train: epoch 0034, iter [01110, 01251], lr: 0.001578, loss: 2.7920
2022-10-07 14:32:26 - train: epoch 0034, iter [01120, 01251], lr: 0.001577, loss: 2.7971
2022-10-07 14:32:48 - train: epoch 0034, iter [01130, 01251], lr: 0.001577, loss: 2.9060
2022-10-07 14:33:09 - train: epoch 0034, iter [01140, 01251], lr: 0.001577, loss: 3.5123
2022-10-07 14:33:30 - train: epoch 0034, iter [01150, 01251], lr: 0.001577, loss: 3.1580
2022-10-07 14:33:51 - train: epoch 0034, iter [01160, 01251], lr: 0.001577, loss: 3.5556
2022-10-07 14:34:12 - train: epoch 0034, iter [01170, 01251], lr: 0.001576, loss: 3.3673
2022-10-07 14:34:34 - train: epoch 0034, iter [01180, 01251], lr: 0.001576, loss: 3.3097
2022-10-07 14:34:55 - train: epoch 0034, iter [01190, 01251], lr: 0.001576, loss: 3.2522
2022-10-07 14:35:16 - train: epoch 0034, iter [01200, 01251], lr: 0.001576, loss: 3.5045
2022-10-07 14:35:37 - train: epoch 0034, iter [01210, 01251], lr: 0.001575, loss: 2.6917
2022-10-07 14:35:58 - train: epoch 0034, iter [01220, 01251], lr: 0.001575, loss: 3.6198
2022-10-07 14:36:19 - train: epoch 0034, iter [01230, 01251], lr: 0.001575, loss: 2.8875
2022-10-07 14:36:40 - train: epoch 0034, iter [01240, 01251], lr: 0.001575, loss: 2.9793
2022-10-07 14:37:01 - train: epoch 0034, iter [01250, 01251], lr: 0.001575, loss: 3.5730
2022-10-07 14:37:04 - train: epoch 034, train_loss: 3.2965
2022-10-07 14:38:21 - eval: epoch: 034, acc1: 79.038%, acc5: 94.882%, test_loss: 0.9343, per_image_load_time: 0.422ms, per_image_inference_time: 1.425ms
2022-10-07 14:38:22 - until epoch: 034, best_acc1: 79.038%
2022-10-07 14:38:22 - epoch 035 lr: 0.001575
2022-10-07 14:38:50 - train: epoch 0035, iter [00010, 01251], lr: 0.001574, loss: 3.1146
2022-10-07 14:39:11 - train: epoch 0035, iter [00020, 01251], lr: 0.001574, loss: 3.1168
2022-10-07 14:39:32 - train: epoch 0035, iter [00030, 01251], lr: 0.001574, loss: 2.4221
2022-10-07 14:39:53 - train: epoch 0035, iter [00040, 01251], lr: 0.001574, loss: 3.5729
2022-10-07 14:40:14 - train: epoch 0035, iter [00050, 01251], lr: 0.001573, loss: 2.9182
2022-10-07 14:40:35 - train: epoch 0035, iter [00060, 01251], lr: 0.001573, loss: 3.1941
2022-10-07 14:40:56 - train: epoch 0035, iter [00070, 01251], lr: 0.001573, loss: 3.5042
2022-10-07 14:41:18 - train: epoch 0035, iter [00080, 01251], lr: 0.001573, loss: 3.0469
2022-10-07 14:41:39 - train: epoch 0035, iter [00090, 01251], lr: 0.001573, loss: 3.2302
2022-10-07 14:42:00 - train: epoch 0035, iter [00100, 01251], lr: 0.001572, loss: 2.8321
2022-10-07 14:42:21 - train: epoch 0035, iter [00110, 01251], lr: 0.001572, loss: 3.8914
2022-10-07 14:42:42 - train: epoch 0035, iter [00120, 01251], lr: 0.001572, loss: 3.7720
2022-10-07 14:43:04 - train: epoch 0035, iter [00130, 01251], lr: 0.001572, loss: 3.1365
2022-10-07 14:43:25 - train: epoch 0035, iter [00140, 01251], lr: 0.001572, loss: 3.4390
2022-10-07 14:43:46 - train: epoch 0035, iter [00150, 01251], lr: 0.001571, loss: 3.0982
2022-10-07 14:44:08 - train: epoch 0035, iter [00160, 01251], lr: 0.001571, loss: 3.0953
2022-10-07 14:44:29 - train: epoch 0035, iter [00170, 01251], lr: 0.001571, loss: 3.4694
2022-10-07 14:44:50 - train: epoch 0035, iter [00180, 01251], lr: 0.001571, loss: 3.7834
2022-10-07 14:45:11 - train: epoch 0035, iter [00190, 01251], lr: 0.001570, loss: 3.7484
2022-10-07 14:45:32 - train: epoch 0035, iter [00200, 01251], lr: 0.001570, loss: 3.1904
2022-10-07 14:45:54 - train: epoch 0035, iter [00210, 01251], lr: 0.001570, loss: 3.4945
2022-10-07 14:46:15 - train: epoch 0035, iter [00220, 01251], lr: 0.001570, loss: 2.8572
2022-10-07 14:46:36 - train: epoch 0035, iter [00230, 01251], lr: 0.001570, loss: 3.8652
2022-10-07 14:46:57 - train: epoch 0035, iter [00240, 01251], lr: 0.001569, loss: 3.8278
2022-10-07 14:47:18 - train: epoch 0035, iter [00250, 01251], lr: 0.001569, loss: 2.5916
2022-10-07 14:47:40 - train: epoch 0035, iter [00260, 01251], lr: 0.001569, loss: 3.4478
2022-10-07 14:48:01 - train: epoch 0035, iter [00270, 01251], lr: 0.001569, loss: 3.3957
2022-10-07 14:48:22 - train: epoch 0035, iter [00280, 01251], lr: 0.001568, loss: 2.9390
2022-10-07 14:48:43 - train: epoch 0035, iter [00290, 01251], lr: 0.001568, loss: 2.7582
2022-10-07 14:49:04 - train: epoch 0035, iter [00300, 01251], lr: 0.001568, loss: 2.9294
2022-10-07 14:49:26 - train: epoch 0035, iter [00310, 01251], lr: 0.001568, loss: 3.6141
2022-10-07 14:49:47 - train: epoch 0035, iter [00320, 01251], lr: 0.001568, loss: 3.5531
2022-10-07 14:50:08 - train: epoch 0035, iter [00330, 01251], lr: 0.001567, loss: 3.2698
2022-10-07 14:50:29 - train: epoch 0035, iter [00340, 01251], lr: 0.001567, loss: 3.1289
2022-10-07 14:50:50 - train: epoch 0035, iter [00350, 01251], lr: 0.001567, loss: 3.3292
2022-10-07 14:51:11 - train: epoch 0035, iter [00360, 01251], lr: 0.001567, loss: 3.3584
2022-10-07 14:51:33 - train: epoch 0035, iter [00370, 01251], lr: 0.001567, loss: 3.2200
2022-10-07 14:51:54 - train: epoch 0035, iter [00380, 01251], lr: 0.001566, loss: 3.3405
2022-10-07 14:52:15 - train: epoch 0035, iter [00390, 01251], lr: 0.001566, loss: 3.7928
2022-10-07 14:52:36 - train: epoch 0035, iter [00400, 01251], lr: 0.001566, loss: 3.6124
2022-10-07 14:52:57 - train: epoch 0035, iter [00410, 01251], lr: 0.001566, loss: 3.5949
2022-10-07 14:53:18 - train: epoch 0035, iter [00420, 01251], lr: 0.001565, loss: 3.1363
2022-10-07 14:53:40 - train: epoch 0035, iter [00430, 01251], lr: 0.001565, loss: 3.3594
2022-10-07 14:54:01 - train: epoch 0035, iter [00440, 01251], lr: 0.001565, loss: 3.2210
2022-10-07 14:54:22 - train: epoch 0035, iter [00450, 01251], lr: 0.001565, loss: 3.6027
2022-10-07 14:54:43 - train: epoch 0035, iter [00460, 01251], lr: 0.001565, loss: 3.6998
2022-10-07 14:55:04 - train: epoch 0035, iter [00470, 01251], lr: 0.001564, loss: 3.3604
2022-10-07 14:55:25 - train: epoch 0035, iter [00480, 01251], lr: 0.001564, loss: 3.6915
2022-10-07 14:55:47 - train: epoch 0035, iter [00490, 01251], lr: 0.001564, loss: 3.0763
2022-10-07 14:56:08 - train: epoch 0035, iter [00500, 01251], lr: 0.001564, loss: 3.0939
2022-10-07 14:56:29 - train: epoch 0035, iter [00510, 01251], lr: 0.001563, loss: 3.0160
2022-10-07 14:56:50 - train: epoch 0035, iter [00520, 01251], lr: 0.001563, loss: 2.9913
2022-10-07 14:57:11 - train: epoch 0035, iter [00530, 01251], lr: 0.001563, loss: 3.4882
2022-10-07 14:57:32 - train: epoch 0035, iter [00540, 01251], lr: 0.001563, loss: 2.7079
2022-10-07 14:57:54 - train: epoch 0035, iter [00550, 01251], lr: 0.001563, loss: 3.3321
2022-10-07 14:58:15 - train: epoch 0035, iter [00560, 01251], lr: 0.001562, loss: 3.5001
2022-10-07 14:58:36 - train: epoch 0035, iter [00570, 01251], lr: 0.001562, loss: 3.0605
2022-10-07 14:58:57 - train: epoch 0035, iter [00580, 01251], lr: 0.001562, loss: 3.9043
2022-10-07 14:59:19 - train: epoch 0035, iter [00590, 01251], lr: 0.001562, loss: 3.2704
2022-10-07 14:59:40 - train: epoch 0035, iter [00600, 01251], lr: 0.001561, loss: 3.3365
2022-10-07 15:00:01 - train: epoch 0035, iter [00610, 01251], lr: 0.001561, loss: 3.0594
2022-10-07 15:00:22 - train: epoch 0035, iter [00620, 01251], lr: 0.001561, loss: 3.3218
2022-10-07 15:00:43 - train: epoch 0035, iter [00630, 01251], lr: 0.001561, loss: 3.2907
2022-10-07 15:01:05 - train: epoch 0035, iter [00640, 01251], lr: 0.001561, loss: 3.4920
2022-10-07 15:01:26 - train: epoch 0035, iter [00650, 01251], lr: 0.001560, loss: 3.7382
2022-10-07 15:01:47 - train: epoch 0035, iter [00660, 01251], lr: 0.001560, loss: 3.7198
2022-10-07 15:02:08 - train: epoch 0035, iter [00670, 01251], lr: 0.001560, loss: 3.7024
2022-10-07 15:02:30 - train: epoch 0035, iter [00680, 01251], lr: 0.001560, loss: 3.3607
2022-10-07 15:02:51 - train: epoch 0035, iter [00690, 01251], lr: 0.001560, loss: 3.2406
2022-10-07 15:03:12 - train: epoch 0035, iter [00700, 01251], lr: 0.001559, loss: 3.6913
2022-10-07 15:03:33 - train: epoch 0035, iter [00710, 01251], lr: 0.001559, loss: 3.5523
2022-10-07 15:03:54 - train: epoch 0035, iter [00720, 01251], lr: 0.001559, loss: 2.5689
2022-10-07 15:04:16 - train: epoch 0035, iter [00730, 01251], lr: 0.001559, loss: 3.0940
2022-10-07 15:04:37 - train: epoch 0035, iter [00740, 01251], lr: 0.001558, loss: 3.5634
2022-10-07 15:04:58 - train: epoch 0035, iter [00750, 01251], lr: 0.001558, loss: 2.7362
2022-10-07 15:05:19 - train: epoch 0035, iter [00760, 01251], lr: 0.001558, loss: 2.5834
2022-10-07 15:05:40 - train: epoch 0035, iter [00770, 01251], lr: 0.001558, loss: 2.4860
2022-10-07 15:06:01 - train: epoch 0035, iter [00780, 01251], lr: 0.001558, loss: 3.6542
2022-10-07 15:06:23 - train: epoch 0035, iter [00790, 01251], lr: 0.001557, loss: 3.9460
2022-10-07 15:06:44 - train: epoch 0035, iter [00800, 01251], lr: 0.001557, loss: 2.7274
2022-10-07 15:07:05 - train: epoch 0035, iter [00810, 01251], lr: 0.001557, loss: 3.9110
2022-10-07 15:07:26 - train: epoch 0035, iter [00820, 01251], lr: 0.001557, loss: 2.9920
2022-10-07 15:07:47 - train: epoch 0035, iter [00830, 01251], lr: 0.001556, loss: 2.6597
2022-10-07 15:08:09 - train: epoch 0035, iter [00840, 01251], lr: 0.001556, loss: 2.9190
2022-10-07 15:08:30 - train: epoch 0035, iter [00850, 01251], lr: 0.001556, loss: 3.6971
2022-10-07 15:08:51 - train: epoch 0035, iter [00860, 01251], lr: 0.001556, loss: 3.0648
2022-10-07 15:09:12 - train: epoch 0035, iter [00870, 01251], lr: 0.001556, loss: 3.2999
2022-10-07 15:09:33 - train: epoch 0035, iter [00880, 01251], lr: 0.001555, loss: 3.3322
2022-10-07 15:09:54 - train: epoch 0035, iter [00890, 01251], lr: 0.001555, loss: 3.3728
2022-10-07 15:10:15 - train: epoch 0035, iter [00900, 01251], lr: 0.001555, loss: 3.6043
2022-10-07 15:10:37 - train: epoch 0035, iter [00910, 01251], lr: 0.001555, loss: 3.8021
2022-10-07 15:10:58 - train: epoch 0035, iter [00920, 01251], lr: 0.001554, loss: 3.6567
2022-10-07 15:11:19 - train: epoch 0035, iter [00930, 01251], lr: 0.001554, loss: 3.4757
2022-10-07 15:11:40 - train: epoch 0035, iter [00940, 01251], lr: 0.001554, loss: 3.1182
2022-10-07 15:12:01 - train: epoch 0035, iter [00950, 01251], lr: 0.001554, loss: 3.1828
2022-10-07 15:12:22 - train: epoch 0035, iter [00960, 01251], lr: 0.001554, loss: 3.6711
2022-10-07 15:12:43 - train: epoch 0035, iter [00970, 01251], lr: 0.001553, loss: 3.7761
2022-10-07 15:13:04 - train: epoch 0035, iter [00980, 01251], lr: 0.001553, loss: 3.2327
2022-10-07 15:13:26 - train: epoch 0035, iter [00990, 01251], lr: 0.001553, loss: 3.6594
2022-10-07 15:13:47 - train: epoch 0035, iter [01000, 01251], lr: 0.001553, loss: 3.3622
2022-10-07 15:14:08 - train: epoch 0035, iter [01010, 01251], lr: 0.001552, loss: 3.1645
2022-10-07 15:14:29 - train: epoch 0035, iter [01020, 01251], lr: 0.001552, loss: 3.5597
2022-10-07 15:14:50 - train: epoch 0035, iter [01030, 01251], lr: 0.001552, loss: 3.1541
2022-10-07 15:15:11 - train: epoch 0035, iter [01040, 01251], lr: 0.001552, loss: 3.6937
2022-10-07 15:15:32 - train: epoch 0035, iter [01050, 01251], lr: 0.001552, loss: 3.0621
2022-10-07 15:15:53 - train: epoch 0035, iter [01060, 01251], lr: 0.001551, loss: 3.5211
2022-10-07 15:16:15 - train: epoch 0035, iter [01070, 01251], lr: 0.001551, loss: 2.4732
2022-10-07 15:16:36 - train: epoch 0035, iter [01080, 01251], lr: 0.001551, loss: 3.7035
2022-10-07 15:16:57 - train: epoch 0035, iter [01090, 01251], lr: 0.001551, loss: 3.5968
2022-10-07 15:17:18 - train: epoch 0035, iter [01100, 01251], lr: 0.001551, loss: 3.4394
2022-10-07 15:17:39 - train: epoch 0035, iter [01110, 01251], lr: 0.001550, loss: 3.7457
2022-10-07 15:18:00 - train: epoch 0035, iter [01120, 01251], lr: 0.001550, loss: 3.5702
2022-10-07 15:18:21 - train: epoch 0035, iter [01130, 01251], lr: 0.001550, loss: 3.4544
2022-10-07 15:18:42 - train: epoch 0035, iter [01140, 01251], lr: 0.001550, loss: 3.0672
2022-10-07 15:19:03 - train: epoch 0035, iter [01150, 01251], lr: 0.001549, loss: 3.2785
2022-10-07 15:19:25 - train: epoch 0035, iter [01160, 01251], lr: 0.001549, loss: 3.1755
2022-10-07 15:19:46 - train: epoch 0035, iter [01170, 01251], lr: 0.001549, loss: 3.6449
2022-10-07 15:20:07 - train: epoch 0035, iter [01180, 01251], lr: 0.001549, loss: 3.0818
2022-10-07 15:20:28 - train: epoch 0035, iter [01190, 01251], lr: 0.001549, loss: 3.1120
2022-10-07 15:20:49 - train: epoch 0035, iter [01200, 01251], lr: 0.001548, loss: 3.4228
2022-10-07 15:21:10 - train: epoch 0035, iter [01210, 01251], lr: 0.001548, loss: 3.0004
2022-10-07 15:21:31 - train: epoch 0035, iter [01220, 01251], lr: 0.001548, loss: 2.7964
2022-10-07 15:21:52 - train: epoch 0035, iter [01230, 01251], lr: 0.001548, loss: 3.3503
2022-10-07 15:22:13 - train: epoch 0035, iter [01240, 01251], lr: 0.001547, loss: 3.8108
2022-10-07 15:22:34 - train: epoch 0035, iter [01250, 01251], lr: 0.001547, loss: 3.6066
2022-10-07 15:22:38 - train: epoch 035, train_loss: 3.2790
2022-10-07 15:23:54 - eval: epoch: 035, acc1: 79.152%, acc5: 94.886%, test_loss: 0.9324, per_image_load_time: 0.441ms, per_image_inference_time: 1.448ms
2022-10-07 15:23:56 - until epoch: 035, best_acc1: 79.152%
2022-10-07 15:23:56 - epoch 036 lr: 0.001547
2022-10-07 15:24:23 - train: epoch 0036, iter [00010, 01251], lr: 0.001547, loss: 2.9919
2022-10-07 15:24:44 - train: epoch 0036, iter [00020, 01251], lr: 0.001547, loss: 3.4295
2022-10-07 15:25:05 - train: epoch 0036, iter [00030, 01251], lr: 0.001547, loss: 3.0521
2022-10-07 15:25:26 - train: epoch 0036, iter [00040, 01251], lr: 0.001546, loss: 3.3077
2022-10-07 15:25:47 - train: epoch 0036, iter [00050, 01251], lr: 0.001546, loss: 3.0733
2022-10-07 15:26:08 - train: epoch 0036, iter [00060, 01251], lr: 0.001546, loss: 3.2790
2022-10-07 15:26:30 - train: epoch 0036, iter [00070, 01251], lr: 0.001546, loss: 3.5959
2022-10-07 15:26:51 - train: epoch 0036, iter [00080, 01251], lr: 0.001545, loss: 3.7784
2022-10-07 15:27:12 - train: epoch 0036, iter [00090, 01251], lr: 0.001545, loss: 2.8511
2022-10-07 15:27:33 - train: epoch 0036, iter [00100, 01251], lr: 0.001545, loss: 3.7792
2022-10-07 15:27:54 - train: epoch 0036, iter [00110, 01251], lr: 0.001545, loss: 3.7762
2022-10-07 15:28:15 - train: epoch 0036, iter [00120, 01251], lr: 0.001545, loss: 2.9839
2022-10-07 15:28:37 - train: epoch 0036, iter [00130, 01251], lr: 0.001544, loss: 3.5513
2022-10-07 15:28:58 - train: epoch 0036, iter [00140, 01251], lr: 0.001544, loss: 3.8220
2022-10-07 15:29:19 - train: epoch 0036, iter [00150, 01251], lr: 0.001544, loss: 2.8442
2022-10-07 15:29:40 - train: epoch 0036, iter [00160, 01251], lr: 0.001544, loss: 3.2338
2022-10-07 15:30:01 - train: epoch 0036, iter [00170, 01251], lr: 0.001543, loss: 3.0420
2022-10-07 15:30:22 - train: epoch 0036, iter [00180, 01251], lr: 0.001543, loss: 2.5778
2022-10-07 15:30:44 - train: epoch 0036, iter [00190, 01251], lr: 0.001543, loss: 3.7236
2022-10-07 15:31:05 - train: epoch 0036, iter [00200, 01251], lr: 0.001543, loss: 2.8762
2022-10-07 15:31:26 - train: epoch 0036, iter [00210, 01251], lr: 0.001543, loss: 3.7842
2022-10-07 15:31:47 - train: epoch 0036, iter [00220, 01251], lr: 0.001542, loss: 3.3970
2022-10-07 15:32:08 - train: epoch 0036, iter [00230, 01251], lr: 0.001542, loss: 3.1008
2022-10-07 15:32:29 - train: epoch 0036, iter [00240, 01251], lr: 0.001542, loss: 3.6754
2022-10-07 15:32:51 - train: epoch 0036, iter [00250, 01251], lr: 0.001542, loss: 3.2998
2022-10-07 15:33:12 - train: epoch 0036, iter [00260, 01251], lr: 0.001541, loss: 2.8658
2022-10-07 15:33:33 - train: epoch 0036, iter [00270, 01251], lr: 0.001541, loss: 3.6004
2022-10-07 15:33:54 - train: epoch 0036, iter [00280, 01251], lr: 0.001541, loss: 3.4947
2022-10-07 15:34:15 - train: epoch 0036, iter [00290, 01251], lr: 0.001541, loss: 3.1916
2022-10-07 15:34:37 - train: epoch 0036, iter [00300, 01251], lr: 0.001541, loss: 3.4785
2022-10-07 15:34:58 - train: epoch 0036, iter [00310, 01251], lr: 0.001540, loss: 3.0190
2022-10-07 15:35:19 - train: epoch 0036, iter [00320, 01251], lr: 0.001540, loss: 3.7542
2022-10-07 15:35:40 - train: epoch 0036, iter [00330, 01251], lr: 0.001540, loss: 3.4671
2022-10-07 15:36:01 - train: epoch 0036, iter [00340, 01251], lr: 0.001540, loss: 3.3259
2022-10-07 15:36:23 - train: epoch 0036, iter [00350, 01251], lr: 0.001539, loss: 2.9835
2022-10-07 15:36:44 - train: epoch 0036, iter [00360, 01251], lr: 0.001539, loss: 2.6307
2022-10-07 15:37:05 - train: epoch 0036, iter [00370, 01251], lr: 0.001539, loss: 3.3982
2022-10-07 15:37:26 - train: epoch 0036, iter [00380, 01251], lr: 0.001539, loss: 3.4940
2022-10-07 15:37:47 - train: epoch 0036, iter [00390, 01251], lr: 0.001539, loss: 3.1804
2022-10-07 15:38:09 - train: epoch 0036, iter [00400, 01251], lr: 0.001538, loss: 3.6194
2022-10-07 15:38:30 - train: epoch 0036, iter [00410, 01251], lr: 0.001538, loss: 3.1783
2022-10-07 15:38:51 - train: epoch 0036, iter [00420, 01251], lr: 0.001538, loss: 3.0531
2022-10-07 15:39:12 - train: epoch 0036, iter [00430, 01251], lr: 0.001538, loss: 3.4640
2022-10-07 15:39:34 - train: epoch 0036, iter [00440, 01251], lr: 0.001537, loss: 3.0142
2022-10-07 15:39:55 - train: epoch 0036, iter [00450, 01251], lr: 0.001537, loss: 2.7188
2022-10-07 15:40:16 - train: epoch 0036, iter [00460, 01251], lr: 0.001537, loss: 3.3042
2022-10-07 15:40:37 - train: epoch 0036, iter [00470, 01251], lr: 0.001537, loss: 3.5213
2022-10-07 15:40:58 - train: epoch 0036, iter [00480, 01251], lr: 0.001537, loss: 3.2327
2022-10-07 15:41:20 - train: epoch 0036, iter [00490, 01251], lr: 0.001536, loss: 2.5256
2022-10-07 15:41:41 - train: epoch 0036, iter [00500, 01251], lr: 0.001536, loss: 3.5603
2022-10-07 15:42:02 - train: epoch 0036, iter [00510, 01251], lr: 0.001536, loss: 2.9578
2022-10-07 15:42:23 - train: epoch 0036, iter [00520, 01251], lr: 0.001536, loss: 3.7836
2022-10-07 15:42:44 - train: epoch 0036, iter [00530, 01251], lr: 0.001535, loss: 3.2776
2022-10-07 15:43:06 - train: epoch 0036, iter [00540, 01251], lr: 0.001535, loss: 3.4825
2022-10-07 15:43:27 - train: epoch 0036, iter [00550, 01251], lr: 0.001535, loss: 3.6506
2022-10-07 15:43:48 - train: epoch 0036, iter [00560, 01251], lr: 0.001535, loss: 3.7793
2022-10-07 15:44:09 - train: epoch 0036, iter [00570, 01251], lr: 0.001535, loss: 3.1962
2022-10-07 15:44:30 - train: epoch 0036, iter [00580, 01251], lr: 0.001534, loss: 3.8160
2022-10-07 15:44:52 - train: epoch 0036, iter [00590, 01251], lr: 0.001534, loss: 3.0293
2022-10-07 15:45:13 - train: epoch 0036, iter [00600, 01251], lr: 0.001534, loss: 3.0927
2022-10-07 15:45:34 - train: epoch 0036, iter [00610, 01251], lr: 0.001534, loss: 3.5993
2022-10-07 15:45:55 - train: epoch 0036, iter [00620, 01251], lr: 0.001533, loss: 3.0507
2022-10-07 15:46:17 - train: epoch 0036, iter [00630, 01251], lr: 0.001533, loss: 3.4496
2022-10-07 15:46:38 - train: epoch 0036, iter [00640, 01251], lr: 0.001533, loss: 3.0567
2022-10-07 15:46:59 - train: epoch 0036, iter [00650, 01251], lr: 0.001533, loss: 3.4785
2022-10-07 15:47:20 - train: epoch 0036, iter [00660, 01251], lr: 0.001532, loss: 3.5879
2022-10-07 15:47:41 - train: epoch 0036, iter [00670, 01251], lr: 0.001532, loss: 2.8607
2022-10-07 15:48:03 - train: epoch 0036, iter [00680, 01251], lr: 0.001532, loss: 3.0135
2022-10-07 15:48:24 - train: epoch 0036, iter [00690, 01251], lr: 0.001532, loss: 3.8285
2022-10-07 15:48:45 - train: epoch 0036, iter [00700, 01251], lr: 0.001532, loss: 2.8048
2022-10-07 15:49:06 - train: epoch 0036, iter [00710, 01251], lr: 0.001531, loss: 2.9339
2022-10-07 15:49:27 - train: epoch 0036, iter [00720, 01251], lr: 0.001531, loss: 3.1982
2022-10-07 15:49:49 - train: epoch 0036, iter [00730, 01251], lr: 0.001531, loss: 3.4600
2022-10-07 15:50:10 - train: epoch 0036, iter [00740, 01251], lr: 0.001531, loss: 3.4031
2022-10-07 15:50:31 - train: epoch 0036, iter [00750, 01251], lr: 0.001530, loss: 3.1146
2022-10-07 15:50:52 - train: epoch 0036, iter [00760, 01251], lr: 0.001530, loss: 2.6340
2022-10-07 15:51:13 - train: epoch 0036, iter [00770, 01251], lr: 0.001530, loss: 2.9091
2022-10-07 15:51:34 - train: epoch 0036, iter [00780, 01251], lr: 0.001530, loss: 2.9032
2022-10-07 15:51:56 - train: epoch 0036, iter [00790, 01251], lr: 0.001530, loss: 3.8749
2022-10-07 15:52:17 - train: epoch 0036, iter [00800, 01251], lr: 0.001529, loss: 3.8053
2022-10-07 15:52:38 - train: epoch 0036, iter [00810, 01251], lr: 0.001529, loss: 3.5436
2022-10-07 15:52:59 - train: epoch 0036, iter [00820, 01251], lr: 0.001529, loss: 2.8565
2022-10-07 15:53:20 - train: epoch 0036, iter [00830, 01251], lr: 0.001529, loss: 3.5304
2022-10-07 15:53:41 - train: epoch 0036, iter [00840, 01251], lr: 0.001528, loss: 3.7819
2022-10-07 15:54:03 - train: epoch 0036, iter [00850, 01251], lr: 0.001528, loss: 3.2652
2022-10-07 15:54:24 - train: epoch 0036, iter [00860, 01251], lr: 0.001528, loss: 3.3856
2022-10-07 15:54:45 - train: epoch 0036, iter [00870, 01251], lr: 0.001528, loss: 2.7293
2022-10-07 15:55:06 - train: epoch 0036, iter [00880, 01251], lr: 0.001528, loss: 3.1046
2022-10-07 15:55:27 - train: epoch 0036, iter [00890, 01251], lr: 0.001527, loss: 3.4451
2022-10-07 15:55:49 - train: epoch 0036, iter [00900, 01251], lr: 0.001527, loss: 3.3708
2022-10-07 15:56:10 - train: epoch 0036, iter [00910, 01251], lr: 0.001527, loss: 3.1747
2022-10-07 15:56:31 - train: epoch 0036, iter [00920, 01251], lr: 0.001527, loss: 3.7889
2022-10-07 15:56:52 - train: epoch 0036, iter [00930, 01251], lr: 0.001526, loss: 3.6980
2022-10-07 15:57:14 - train: epoch 0036, iter [00940, 01251], lr: 0.001526, loss: 2.8446
2022-10-07 15:57:35 - train: epoch 0036, iter [00950, 01251], lr: 0.001526, loss: 3.0514
2022-10-07 15:57:56 - train: epoch 0036, iter [00960, 01251], lr: 0.001526, loss: 3.0604
2022-10-07 15:58:17 - train: epoch 0036, iter [00970, 01251], lr: 0.001526, loss: 3.6808
2022-10-07 15:58:39 - train: epoch 0036, iter [00980, 01251], lr: 0.001525, loss: 3.5993
2022-10-07 15:59:00 - train: epoch 0036, iter [00990, 01251], lr: 0.001525, loss: 3.5738
2022-10-07 15:59:21 - train: epoch 0036, iter [01000, 01251], lr: 0.001525, loss: 3.5179
2022-10-07 15:59:43 - train: epoch 0036, iter [01010, 01251], lr: 0.001525, loss: 3.6380
2022-10-07 16:00:04 - train: epoch 0036, iter [01020, 01251], lr: 0.001524, loss: 3.2534
2022-10-07 16:00:25 - train: epoch 0036, iter [01030, 01251], lr: 0.001524, loss: 3.7069
2022-10-07 16:00:46 - train: epoch 0036, iter [01040, 01251], lr: 0.001524, loss: 3.4263
2022-10-07 16:01:07 - train: epoch 0036, iter [01050, 01251], lr: 0.001524, loss: 2.9623
2022-10-07 16:01:29 - train: epoch 0036, iter [01060, 01251], lr: 0.001524, loss: 3.4948
2022-10-07 16:01:50 - train: epoch 0036, iter [01070, 01251], lr: 0.001523, loss: 3.4877
2022-10-07 16:02:11 - train: epoch 0036, iter [01080, 01251], lr: 0.001523, loss: 2.6758
2022-10-07 16:02:32 - train: epoch 0036, iter [01090, 01251], lr: 0.001523, loss: 3.6469
2022-10-07 16:02:54 - train: epoch 0036, iter [01100, 01251], lr: 0.001523, loss: 3.6926
2022-10-07 16:03:15 - train: epoch 0036, iter [01110, 01251], lr: 0.001522, loss: 3.6254
2022-10-07 16:03:36 - train: epoch 0036, iter [01120, 01251], lr: 0.001522, loss: 2.9129
2022-10-07 16:03:57 - train: epoch 0036, iter [01130, 01251], lr: 0.001522, loss: 3.6751
2022-10-07 16:04:18 - train: epoch 0036, iter [01140, 01251], lr: 0.001522, loss: 3.4224
2022-10-07 16:04:40 - train: epoch 0036, iter [01150, 01251], lr: 0.001521, loss: 3.6974
2022-10-07 16:05:01 - train: epoch 0036, iter [01160, 01251], lr: 0.001521, loss: 3.3050
2022-10-07 16:05:22 - train: epoch 0036, iter [01170, 01251], lr: 0.001521, loss: 3.6222
2022-10-07 16:05:43 - train: epoch 0036, iter [01180, 01251], lr: 0.001521, loss: 3.4282
2022-10-07 16:06:04 - train: epoch 0036, iter [01190, 01251], lr: 0.001521, loss: 3.5393
2022-10-07 16:06:26 - train: epoch 0036, iter [01200, 01251], lr: 0.001520, loss: 2.9966
2022-10-07 16:06:47 - train: epoch 0036, iter [01210, 01251], lr: 0.001520, loss: 2.8263
2022-10-07 16:07:08 - train: epoch 0036, iter [01220, 01251], lr: 0.001520, loss: 3.6514
2022-10-07 16:07:29 - train: epoch 0036, iter [01230, 01251], lr: 0.001520, loss: 3.8402
2022-10-07 16:07:51 - train: epoch 0036, iter [01240, 01251], lr: 0.001519, loss: 3.5562
2022-10-07 16:08:12 - train: epoch 0036, iter [01250, 01251], lr: 0.001519, loss: 3.4181
2022-10-07 16:08:15 - train: epoch 036, train_loss: 3.2708
2022-10-07 16:09:33 - eval: epoch: 036, acc1: 79.230%, acc5: 94.936%, test_loss: 0.9050, per_image_load_time: 0.408ms, per_image_inference_time: 1.424ms
2022-10-07 16:09:35 - until epoch: 036, best_acc1: 79.230%
2022-10-07 16:09:35 - epoch 037 lr: 0.001519
2022-10-07 16:10:01 - train: epoch 0037, iter [00010, 01251], lr: 0.001519, loss: 3.3925
2022-10-07 16:10:22 - train: epoch 0037, iter [00020, 01251], lr: 0.001519, loss: 3.7712
2022-10-07 16:10:44 - train: epoch 0037, iter [00030, 01251], lr: 0.001519, loss: 3.1234
2022-10-07 16:11:05 - train: epoch 0037, iter [00040, 01251], lr: 0.001518, loss: 3.3396
2022-10-07 16:11:26 - train: epoch 0037, iter [00050, 01251], lr: 0.001518, loss: 3.2721
2022-10-07 16:11:47 - train: epoch 0037, iter [00060, 01251], lr: 0.001518, loss: 3.7030
2022-10-07 16:12:09 - train: epoch 0037, iter [00070, 01251], lr: 0.001518, loss: 2.9121
2022-10-07 16:12:30 - train: epoch 0037, iter [00080, 01251], lr: 0.001517, loss: 3.5543
2022-10-07 16:12:51 - train: epoch 0037, iter [00090, 01251], lr: 0.001517, loss: 3.0905
2022-10-07 16:13:13 - train: epoch 0037, iter [00100, 01251], lr: 0.001517, loss: 3.2299
2022-10-07 16:13:34 - train: epoch 0037, iter [00110, 01251], lr: 0.001517, loss: 3.4334
2022-10-07 16:13:55 - train: epoch 0037, iter [00120, 01251], lr: 0.001516, loss: 2.5927
2022-10-07 16:14:16 - train: epoch 0037, iter [00130, 01251], lr: 0.001516, loss: 3.6603
2022-10-07 16:14:37 - train: epoch 0037, iter [00140, 01251], lr: 0.001516, loss: 2.5339
2022-10-07 16:14:59 - train: epoch 0037, iter [00150, 01251], lr: 0.001516, loss: 2.5391
2022-10-07 16:15:20 - train: epoch 0037, iter [00160, 01251], lr: 0.001516, loss: 3.5823
2022-10-07 16:15:41 - train: epoch 0037, iter [00170, 01251], lr: 0.001515, loss: 3.3484
2022-10-07 16:16:03 - train: epoch 0037, iter [00180, 01251], lr: 0.001515, loss: 2.8380
2022-10-07 16:16:24 - train: epoch 0037, iter [00190, 01251], lr: 0.001515, loss: 3.4886
2022-10-07 16:16:45 - train: epoch 0037, iter [00200, 01251], lr: 0.001515, loss: 3.7621
2022-10-07 16:17:06 - train: epoch 0037, iter [00210, 01251], lr: 0.001514, loss: 3.2403
2022-10-07 16:17:28 - train: epoch 0037, iter [00220, 01251], lr: 0.001514, loss: 3.0560
2022-10-07 16:17:49 - train: epoch 0037, iter [00230, 01251], lr: 0.001514, loss: 3.0113
2022-10-07 16:18:10 - train: epoch 0037, iter [00240, 01251], lr: 0.001514, loss: 3.6155
2022-10-07 16:18:31 - train: epoch 0037, iter [00250, 01251], lr: 0.001514, loss: 2.3823
2022-10-07 16:18:53 - train: epoch 0037, iter [00260, 01251], lr: 0.001513, loss: 2.7782
2022-10-07 16:19:14 - train: epoch 0037, iter [00270, 01251], lr: 0.001513, loss: 3.6699
2022-10-07 16:19:35 - train: epoch 0037, iter [00280, 01251], lr: 0.001513, loss: 3.0481
2022-10-07 16:19:57 - train: epoch 0037, iter [00290, 01251], lr: 0.001513, loss: 3.2129
2022-10-07 16:20:18 - train: epoch 0037, iter [00300, 01251], lr: 0.001512, loss: 3.2648
2022-10-07 16:20:39 - train: epoch 0037, iter [00310, 01251], lr: 0.001512, loss: 3.1367
2022-10-07 16:21:00 - train: epoch 0037, iter [00320, 01251], lr: 0.001512, loss: 3.3967
2022-10-07 16:21:22 - train: epoch 0037, iter [00330, 01251], lr: 0.001512, loss: 3.5508
2022-10-07 16:21:43 - train: epoch 0037, iter [00340, 01251], lr: 0.001512, loss: 3.4705
2022-10-07 16:22:04 - train: epoch 0037, iter [00350, 01251], lr: 0.001511, loss: 3.7806
2022-10-07 16:22:25 - train: epoch 0037, iter [00360, 01251], lr: 0.001511, loss: 3.4386
2022-10-07 16:22:47 - train: epoch 0037, iter [00370, 01251], lr: 0.001511, loss: 3.6616
2022-10-07 16:23:08 - train: epoch 0037, iter [00380, 01251], lr: 0.001511, loss: 3.3680
2022-10-07 16:23:29 - train: epoch 0037, iter [00390, 01251], lr: 0.001510, loss: 2.7629
2022-10-07 16:23:51 - train: epoch 0037, iter [00400, 01251], lr: 0.001510, loss: 3.2477
2022-10-07 16:24:12 - train: epoch 0037, iter [00410, 01251], lr: 0.001510, loss: 3.2304
2022-10-07 16:24:33 - train: epoch 0037, iter [00420, 01251], lr: 0.001510, loss: 3.2125
2022-10-07 16:24:54 - train: epoch 0037, iter [00430, 01251], lr: 0.001509, loss: 3.5464
2022-10-07 16:25:16 - train: epoch 0037, iter [00440, 01251], lr: 0.001509, loss: 2.8641
2022-10-07 16:25:37 - train: epoch 0037, iter [00450, 01251], lr: 0.001509, loss: 3.5287
2022-10-07 16:25:58 - train: epoch 0037, iter [00460, 01251], lr: 0.001509, loss: 3.3678
2022-10-07 16:26:19 - train: epoch 0037, iter [00470, 01251], lr: 0.001509, loss: 3.4588
2022-10-07 16:26:41 - train: epoch 0037, iter [00480, 01251], lr: 0.001508, loss: 3.5640
2022-10-07 16:27:02 - train: epoch 0037, iter [00490, 01251], lr: 0.001508, loss: 3.0293
2022-10-07 16:27:23 - train: epoch 0037, iter [00500, 01251], lr: 0.001508, loss: 3.2731
2022-10-07 16:27:44 - train: epoch 0037, iter [00510, 01251], lr: 0.001508, loss: 2.8382
2022-10-07 16:28:06 - train: epoch 0037, iter [00520, 01251], lr: 0.001507, loss: 3.7654
2022-10-07 16:28:27 - train: epoch 0037, iter [00530, 01251], lr: 0.001507, loss: 3.1262
2022-10-07 16:28:48 - train: epoch 0037, iter [00540, 01251], lr: 0.001507, loss: 3.7239
2022-10-07 16:29:09 - train: epoch 0037, iter [00550, 01251], lr: 0.001507, loss: 3.0067
2022-10-07 16:29:30 - train: epoch 0037, iter [00560, 01251], lr: 0.001507, loss: 3.0615
2022-10-07 16:29:52 - train: epoch 0037, iter [00570, 01251], lr: 0.001506, loss: 3.6107
2022-10-07 16:30:13 - train: epoch 0037, iter [00580, 01251], lr: 0.001506, loss: 3.4942
2022-10-07 16:30:34 - train: epoch 0037, iter [00590, 01251], lr: 0.001506, loss: 2.7328
2022-10-07 16:30:55 - train: epoch 0037, iter [00600, 01251], lr: 0.001506, loss: 3.7929
2022-10-07 16:31:17 - train: epoch 0037, iter [00610, 01251], lr: 0.001505, loss: 2.7359
2022-10-07 16:31:38 - train: epoch 0037, iter [00620, 01251], lr: 0.001505, loss: 3.6791
2022-10-07 16:31:59 - train: epoch 0037, iter [00630, 01251], lr: 0.001505, loss: 3.6775
2022-10-07 16:32:20 - train: epoch 0037, iter [00640, 01251], lr: 0.001505, loss: 3.7902
2022-10-07 16:32:42 - train: epoch 0037, iter [00650, 01251], lr: 0.001504, loss: 3.1890
2022-10-07 16:33:03 - train: epoch 0037, iter [00660, 01251], lr: 0.001504, loss: 3.0556
2022-10-07 16:33:24 - train: epoch 0037, iter [00670, 01251], lr: 0.001504, loss: 3.4842
2022-10-07 16:33:45 - train: epoch 0037, iter [00680, 01251], lr: 0.001504, loss: 3.7755
2022-10-07 16:34:06 - train: epoch 0037, iter [00690, 01251], lr: 0.001504, loss: 2.5047
2022-10-07 16:34:27 - train: epoch 0037, iter [00700, 01251], lr: 0.001503, loss: 3.0532
2022-10-07 16:34:49 - train: epoch 0037, iter [00710, 01251], lr: 0.001503, loss: 3.1958
2022-10-07 16:35:10 - train: epoch 0037, iter [00720, 01251], lr: 0.001503, loss: 3.5616
2022-10-07 16:35:31 - train: epoch 0037, iter [00730, 01251], lr: 0.001503, loss: 3.2684
2022-10-07 16:35:52 - train: epoch 0037, iter [00740, 01251], lr: 0.001502, loss: 2.5822
2022-10-07 16:36:13 - train: epoch 0037, iter [00750, 01251], lr: 0.001502, loss: 3.6234
2022-10-07 16:36:34 - train: epoch 0037, iter [00760, 01251], lr: 0.001502, loss: 3.5840
2022-10-07 16:36:56 - train: epoch 0037, iter [00770, 01251], lr: 0.001502, loss: 3.6670
2022-10-07 16:37:17 - train: epoch 0037, iter [00780, 01251], lr: 0.001501, loss: 3.3456
2022-10-07 16:37:38 - train: epoch 0037, iter [00790, 01251], lr: 0.001501, loss: 3.5022
2022-10-07 16:37:59 - train: epoch 0037, iter [00800, 01251], lr: 0.001501, loss: 3.7300
2022-10-07 16:38:20 - train: epoch 0037, iter [00810, 01251], lr: 0.001501, loss: 3.0682
2022-10-07 16:38:41 - train: epoch 0037, iter [00820, 01251], lr: 0.001501, loss: 3.3178
2022-10-07 16:39:02 - train: epoch 0037, iter [00830, 01251], lr: 0.001500, loss: 3.5279
2022-10-07 16:39:23 - train: epoch 0037, iter [00840, 01251], lr: 0.001500, loss: 3.4115
2022-10-07 16:39:45 - train: epoch 0037, iter [00850, 01251], lr: 0.001500, loss: 3.5204
2022-10-07 16:40:06 - train: epoch 0037, iter [00860, 01251], lr: 0.001500, loss: 3.7791
2022-10-07 16:40:27 - train: epoch 0037, iter [00870, 01251], lr: 0.001499, loss: 3.4858
2022-10-07 16:40:48 - train: epoch 0037, iter [00880, 01251], lr: 0.001499, loss: 2.7532
2022-10-07 16:41:09 - train: epoch 0037, iter [00890, 01251], lr: 0.001499, loss: 2.8696
2022-10-07 16:41:30 - train: epoch 0037, iter [00900, 01251], lr: 0.001499, loss: 3.2189
2022-10-07 16:41:51 - train: epoch 0037, iter [00910, 01251], lr: 0.001499, loss: 3.5910
2022-10-07 16:42:12 - train: epoch 0037, iter [00920, 01251], lr: 0.001498, loss: 3.1429
2022-10-07 16:42:33 - train: epoch 0037, iter [00930, 01251], lr: 0.001498, loss: 2.7746
2022-10-07 16:42:54 - train: epoch 0037, iter [00940, 01251], lr: 0.001498, loss: 3.8750
2022-10-07 16:43:15 - train: epoch 0037, iter [00950, 01251], lr: 0.001498, loss: 3.3493
2022-10-07 16:43:36 - train: epoch 0037, iter [00960, 01251], lr: 0.001497, loss: 3.1022
2022-10-07 16:43:58 - train: epoch 0037, iter [00970, 01251], lr: 0.001497, loss: 3.8439
2022-10-07 16:44:19 - train: epoch 0037, iter [00980, 01251], lr: 0.001497, loss: 3.5246
2022-10-07 16:44:40 - train: epoch 0037, iter [00990, 01251], lr: 0.001497, loss: 2.7835
2022-10-07 16:45:01 - train: epoch 0037, iter [01000, 01251], lr: 0.001496, loss: 2.9810
2022-10-07 16:45:22 - train: epoch 0037, iter [01010, 01251], lr: 0.001496, loss: 3.5398
2022-10-07 16:45:43 - train: epoch 0037, iter [01020, 01251], lr: 0.001496, loss: 2.8713
2022-10-07 16:46:04 - train: epoch 0037, iter [01030, 01251], lr: 0.001496, loss: 3.8114
2022-10-07 16:46:25 - train: epoch 0037, iter [01040, 01251], lr: 0.001496, loss: 3.1685
2022-10-07 16:46:46 - train: epoch 0037, iter [01050, 01251], lr: 0.001495, loss: 3.5996
2022-10-07 16:47:08 - train: epoch 0037, iter [01060, 01251], lr: 0.001495, loss: 3.2542
2022-10-07 16:47:29 - train: epoch 0037, iter [01070, 01251], lr: 0.001495, loss: 3.0101
2022-10-07 16:47:50 - train: epoch 0037, iter [01080, 01251], lr: 0.001495, loss: 3.7491
2022-10-07 16:48:11 - train: epoch 0037, iter [01090, 01251], lr: 0.001494, loss: 3.3048
2022-10-07 16:48:32 - train: epoch 0037, iter [01100, 01251], lr: 0.001494, loss: 3.5438
2022-10-07 16:48:53 - train: epoch 0037, iter [01110, 01251], lr: 0.001494, loss: 3.3805
2022-10-07 16:49:14 - train: epoch 0037, iter [01120, 01251], lr: 0.001494, loss: 2.7811
2022-10-07 16:49:35 - train: epoch 0037, iter [01130, 01251], lr: 0.001493, loss: 4.0045
2022-10-07 16:49:56 - train: epoch 0037, iter [01140, 01251], lr: 0.001493, loss: 3.4445
2022-10-07 16:50:17 - train: epoch 0037, iter [01150, 01251], lr: 0.001493, loss: 3.5228
2022-10-07 16:50:38 - train: epoch 0037, iter [01160, 01251], lr: 0.001493, loss: 3.3705
2022-10-07 16:50:59 - train: epoch 0037, iter [01170, 01251], lr: 0.001493, loss: 2.9709
2022-10-07 16:51:20 - train: epoch 0037, iter [01180, 01251], lr: 0.001492, loss: 3.0824
2022-10-07 16:51:41 - train: epoch 0037, iter [01190, 01251], lr: 0.001492, loss: 2.8270
2022-10-07 16:52:02 - train: epoch 0037, iter [01200, 01251], lr: 0.001492, loss: 2.9434
2022-10-07 16:52:23 - train: epoch 0037, iter [01210, 01251], lr: 0.001492, loss: 3.1019
2022-10-07 16:52:44 - train: epoch 0037, iter [01220, 01251], lr: 0.001491, loss: 3.6799
2022-10-07 16:53:06 - train: epoch 0037, iter [01230, 01251], lr: 0.001491, loss: 3.3548
2022-10-07 16:53:27 - train: epoch 0037, iter [01240, 01251], lr: 0.001491, loss: 3.3682
2022-10-07 16:53:48 - train: epoch 0037, iter [01250, 01251], lr: 0.001491, loss: 3.1493
2022-10-07 16:53:51 - train: epoch 037, train_loss: 3.2596
2022-10-07 16:55:08 - eval: epoch: 037, acc1: 79.432%, acc5: 95.134%, test_loss: 0.8756, per_image_load_time: 1.444ms, per_image_inference_time: 1.431ms
2022-10-07 16:55:10 - until epoch: 037, best_acc1: 79.432%
2022-10-07 16:55:10 - epoch 038 lr: 0.001491
2022-10-07 16:55:37 - train: epoch 0038, iter [00010, 01251], lr: 0.001490, loss: 3.6811
2022-10-07 16:55:58 - train: epoch 0038, iter [00020, 01251], lr: 0.001490, loss: 3.5202
2022-10-07 16:56:19 - train: epoch 0038, iter [00030, 01251], lr: 0.001490, loss: 3.2228
2022-10-07 16:56:40 - train: epoch 0038, iter [00040, 01251], lr: 0.001490, loss: 3.5269
2022-10-07 16:57:01 - train: epoch 0038, iter [00050, 01251], lr: 0.001490, loss: 3.1927
2022-10-07 16:57:23 - train: epoch 0038, iter [00060, 01251], lr: 0.001489, loss: 3.7920
2022-10-07 16:57:44 - train: epoch 0038, iter [00070, 01251], lr: 0.001489, loss: 3.3628
2022-10-07 16:58:05 - train: epoch 0038, iter [00080, 01251], lr: 0.001489, loss: 3.6134
2022-10-07 16:58:27 - train: epoch 0038, iter [00090, 01251], lr: 0.001489, loss: 3.4654
2022-10-07 16:58:48 - train: epoch 0038, iter [00100, 01251], lr: 0.001488, loss: 3.2721
2022-10-07 16:59:09 - train: epoch 0038, iter [00110, 01251], lr: 0.001488, loss: 3.2956
2022-10-07 16:59:31 - train: epoch 0038, iter [00120, 01251], lr: 0.001488, loss: 3.2832
2022-10-07 16:59:52 - train: epoch 0038, iter [00130, 01251], lr: 0.001488, loss: 2.4508
2022-10-07 17:00:13 - train: epoch 0038, iter [00140, 01251], lr: 0.001487, loss: 3.4466
2022-10-07 17:00:35 - train: epoch 0038, iter [00150, 01251], lr: 0.001487, loss: 2.8106
2022-10-07 17:00:56 - train: epoch 0038, iter [00160, 01251], lr: 0.001487, loss: 3.5805
2022-10-07 17:01:17 - train: epoch 0038, iter [00170, 01251], lr: 0.001487, loss: 3.4878
2022-10-07 17:01:39 - train: epoch 0038, iter [00180, 01251], lr: 0.001487, loss: 2.9597
2022-10-07 17:02:00 - train: epoch 0038, iter [00190, 01251], lr: 0.001486, loss: 3.3761
2022-10-07 17:02:21 - train: epoch 0038, iter [00200, 01251], lr: 0.001486, loss: 3.3911
2022-10-07 17:02:42 - train: epoch 0038, iter [00210, 01251], lr: 0.001486, loss: 3.3687
2022-10-07 17:03:03 - train: epoch 0038, iter [00220, 01251], lr: 0.001486, loss: 3.6513
2022-10-07 17:03:25 - train: epoch 0038, iter [00230, 01251], lr: 0.001485, loss: 3.8035
2022-10-07 17:03:46 - train: epoch 0038, iter [00240, 01251], lr: 0.001485, loss: 3.1916
2022-10-07 17:04:07 - train: epoch 0038, iter [00250, 01251], lr: 0.001485, loss: 2.8612
2022-10-07 17:04:28 - train: epoch 0038, iter [00260, 01251], lr: 0.001485, loss: 2.9601
2022-10-07 17:04:49 - train: epoch 0038, iter [00270, 01251], lr: 0.001484, loss: 3.3882
2022-10-07 17:05:11 - train: epoch 0038, iter [00280, 01251], lr: 0.001484, loss: 3.2161
2022-10-07 17:05:32 - train: epoch 0038, iter [00290, 01251], lr: 0.001484, loss: 3.1915
2022-10-07 17:05:53 - train: epoch 0038, iter [00300, 01251], lr: 0.001484, loss: 3.3397
2022-10-07 17:06:14 - train: epoch 0038, iter [00310, 01251], lr: 0.001484, loss: 3.4821
2022-10-07 17:06:35 - train: epoch 0038, iter [00320, 01251], lr: 0.001483, loss: 3.2516
2022-10-07 17:06:57 - train: epoch 0038, iter [00330, 01251], lr: 0.001483, loss: 3.1989
2022-10-07 17:07:18 - train: epoch 0038, iter [00340, 01251], lr: 0.001483, loss: 3.6103
2022-10-07 17:07:39 - train: epoch 0038, iter [00350, 01251], lr: 0.001483, loss: 2.6479
2022-10-07 17:08:00 - train: epoch 0038, iter [00360, 01251], lr: 0.001482, loss: 3.3148
2022-10-07 17:08:22 - train: epoch 0038, iter [00370, 01251], lr: 0.001482, loss: 3.1863
2022-10-07 17:08:43 - train: epoch 0038, iter [00380, 01251], lr: 0.001482, loss: 3.1098
2022-10-07 17:09:04 - train: epoch 0038, iter [00390, 01251], lr: 0.001482, loss: 3.2334
2022-10-07 17:09:26 - train: epoch 0038, iter [00400, 01251], lr: 0.001481, loss: 2.8121
2022-10-07 17:09:47 - train: epoch 0038, iter [00410, 01251], lr: 0.001481, loss: 2.9325
2022-10-07 17:10:08 - train: epoch 0038, iter [00420, 01251], lr: 0.001481, loss: 3.2319
2022-10-07 17:10:29 - train: epoch 0038, iter [00430, 01251], lr: 0.001481, loss: 2.6739
2022-10-07 17:10:51 - train: epoch 0038, iter [00440, 01251], lr: 0.001481, loss: 3.5937
2022-10-07 17:11:12 - train: epoch 0038, iter [00450, 01251], lr: 0.001480, loss: 3.5241
2022-10-07 17:11:33 - train: epoch 0038, iter [00460, 01251], lr: 0.001480, loss: 2.7338
2022-10-07 17:11:54 - train: epoch 0038, iter [00470, 01251], lr: 0.001480, loss: 2.5478
2022-10-07 17:12:15 - train: epoch 0038, iter [00480, 01251], lr: 0.001480, loss: 3.1760
2022-10-07 17:12:36 - train: epoch 0038, iter [00490, 01251], lr: 0.001479, loss: 3.1776
2022-10-07 17:12:58 - train: epoch 0038, iter [00500, 01251], lr: 0.001479, loss: 3.1020
2022-10-07 17:13:19 - train: epoch 0038, iter [00510, 01251], lr: 0.001479, loss: 3.3788
2022-10-07 17:13:40 - train: epoch 0038, iter [00520, 01251], lr: 0.001479, loss: 3.3439
2022-10-07 17:14:01 - train: epoch 0038, iter [00530, 01251], lr: 0.001478, loss: 3.6804
2022-10-07 17:14:22 - train: epoch 0038, iter [00540, 01251], lr: 0.001478, loss: 2.5128
2022-10-07 17:14:44 - train: epoch 0038, iter [00550, 01251], lr: 0.001478, loss: 3.7220
2022-10-07 17:15:05 - train: epoch 0038, iter [00560, 01251], lr: 0.001478, loss: 3.2344
2022-10-07 17:15:26 - train: epoch 0038, iter [00570, 01251], lr: 0.001477, loss: 3.5543
2022-10-07 17:15:47 - train: epoch 0038, iter [00580, 01251], lr: 0.001477, loss: 3.4987
2022-10-07 17:16:08 - train: epoch 0038, iter [00590, 01251], lr: 0.001477, loss: 3.0068
2022-10-07 17:16:30 - train: epoch 0038, iter [00600, 01251], lr: 0.001477, loss: 3.5811
2022-10-07 17:16:51 - train: epoch 0038, iter [00610, 01251], lr: 0.001477, loss: 3.2542
2022-10-07 17:17:12 - train: epoch 0038, iter [00620, 01251], lr: 0.001476, loss: 3.8367
2022-10-07 17:17:33 - train: epoch 0038, iter [00630, 01251], lr: 0.001476, loss: 3.4539
2022-10-07 17:17:54 - train: epoch 0038, iter [00640, 01251], lr: 0.001476, loss: 3.8201
2022-10-07 17:18:15 - train: epoch 0038, iter [00650, 01251], lr: 0.001476, loss: 3.3170
2022-10-07 17:18:37 - train: epoch 0038, iter [00660, 01251], lr: 0.001475, loss: 3.1816
2022-10-07 17:18:58 - train: epoch 0038, iter [00670, 01251], lr: 0.001475, loss: 3.1599
2022-10-07 17:19:19 - train: epoch 0038, iter [00680, 01251], lr: 0.001475, loss: 3.1620
2022-10-07 17:19:40 - train: epoch 0038, iter [00690, 01251], lr: 0.001475, loss: 3.5630
2022-10-07 17:20:01 - train: epoch 0038, iter [00700, 01251], lr: 0.001474, loss: 3.5769
2022-10-07 17:20:23 - train: epoch 0038, iter [00710, 01251], lr: 0.001474, loss: 3.5961
2022-10-07 17:20:44 - train: epoch 0038, iter [00720, 01251], lr: 0.001474, loss: 2.2883
2022-10-07 17:21:05 - train: epoch 0038, iter [00730, 01251], lr: 0.001474, loss: 3.6979
2022-10-07 17:21:26 - train: epoch 0038, iter [00740, 01251], lr: 0.001474, loss: 3.6225
2022-10-07 17:21:48 - train: epoch 0038, iter [00750, 01251], lr: 0.001473, loss: 3.3722
2022-10-07 17:22:09 - train: epoch 0038, iter [00760, 01251], lr: 0.001473, loss: 3.0585
2022-10-07 17:22:30 - train: epoch 0038, iter [00770, 01251], lr: 0.001473, loss: 3.6321
2022-10-07 17:22:51 - train: epoch 0038, iter [00780, 01251], lr: 0.001473, loss: 3.4861
2022-10-07 17:23:12 - train: epoch 0038, iter [00790, 01251], lr: 0.001472, loss: 3.7004
2022-10-07 17:23:33 - train: epoch 0038, iter [00800, 01251], lr: 0.001472, loss: 3.3310
2022-10-07 17:23:55 - train: epoch 0038, iter [00810, 01251], lr: 0.001472, loss: 3.6374
2022-10-07 17:24:16 - train: epoch 0038, iter [00820, 01251], lr: 0.001472, loss: 3.3180
2022-10-07 17:24:37 - train: epoch 0038, iter [00830, 01251], lr: 0.001471, loss: 3.5997
2022-10-07 17:24:58 - train: epoch 0038, iter [00840, 01251], lr: 0.001471, loss: 3.4740
2022-10-07 17:25:19 - train: epoch 0038, iter [00850, 01251], lr: 0.001471, loss: 3.5284
2022-10-07 17:25:40 - train: epoch 0038, iter [00860, 01251], lr: 0.001471, loss: 2.0932
2022-10-07 17:26:02 - train: epoch 0038, iter [00870, 01251], lr: 0.001471, loss: 2.9685
2022-10-07 17:26:23 - train: epoch 0038, iter [00880, 01251], lr: 0.001470, loss: 2.7022
2022-10-07 17:26:44 - train: epoch 0038, iter [00890, 01251], lr: 0.001470, loss: 3.0802
2022-10-07 17:27:05 - train: epoch 0038, iter [00900, 01251], lr: 0.001470, loss: 3.4979
2022-10-07 17:27:26 - train: epoch 0038, iter [00910, 01251], lr: 0.001470, loss: 3.2527
2022-10-07 17:27:47 - train: epoch 0038, iter [00920, 01251], lr: 0.001469, loss: 3.6346
2022-10-07 17:28:08 - train: epoch 0038, iter [00930, 01251], lr: 0.001469, loss: 2.7669
2022-10-07 17:28:30 - train: epoch 0038, iter [00940, 01251], lr: 0.001469, loss: 3.3741
2022-10-07 17:28:51 - train: epoch 0038, iter [00950, 01251], lr: 0.001469, loss: 2.7893
2022-10-07 17:29:12 - train: epoch 0038, iter [00960, 01251], lr: 0.001468, loss: 2.9030
2022-10-07 17:29:33 - train: epoch 0038, iter [00970, 01251], lr: 0.001468, loss: 3.6194
2022-10-07 17:29:54 - train: epoch 0038, iter [00980, 01251], lr: 0.001468, loss: 3.4724
2022-10-07 17:30:15 - train: epoch 0038, iter [00990, 01251], lr: 0.001468, loss: 3.2821
2022-10-07 17:30:36 - train: epoch 0038, iter [01000, 01251], lr: 0.001467, loss: 3.2161
2022-10-07 17:30:58 - train: epoch 0038, iter [01010, 01251], lr: 0.001467, loss: 2.8924
2022-10-07 17:31:19 - train: epoch 0038, iter [01020, 01251], lr: 0.001467, loss: 3.2550
2022-10-07 17:31:40 - train: epoch 0038, iter [01030, 01251], lr: 0.001467, loss: 3.1421
2022-10-07 17:32:01 - train: epoch 0038, iter [01040, 01251], lr: 0.001467, loss: 3.8913
2022-10-07 17:32:23 - train: epoch 0038, iter [01050, 01251], lr: 0.001466, loss: 2.9123
2022-10-07 17:32:44 - train: epoch 0038, iter [01060, 01251], lr: 0.001466, loss: 3.5882
2022-10-07 17:33:05 - train: epoch 0038, iter [01070, 01251], lr: 0.001466, loss: 3.6582
2022-10-07 17:33:26 - train: epoch 0038, iter [01080, 01251], lr: 0.001466, loss: 3.5603
2022-10-07 17:33:47 - train: epoch 0038, iter [01090, 01251], lr: 0.001465, loss: 3.0396
2022-10-07 17:34:08 - train: epoch 0038, iter [01100, 01251], lr: 0.001465, loss: 3.3518
2022-10-07 17:34:30 - train: epoch 0038, iter [01110, 01251], lr: 0.001465, loss: 3.9288
2022-10-07 17:34:51 - train: epoch 0038, iter [01120, 01251], lr: 0.001465, loss: 3.1456
2022-10-07 17:35:12 - train: epoch 0038, iter [01130, 01251], lr: 0.001464, loss: 2.6866
2022-10-07 17:35:33 - train: epoch 0038, iter [01140, 01251], lr: 0.001464, loss: 3.4414
2022-10-07 17:35:54 - train: epoch 0038, iter [01150, 01251], lr: 0.001464, loss: 3.1568
2022-10-07 17:36:15 - train: epoch 0038, iter [01160, 01251], lr: 0.001464, loss: 3.0288
2022-10-07 17:36:36 - train: epoch 0038, iter [01170, 01251], lr: 0.001464, loss: 3.2797
2022-10-07 17:36:57 - train: epoch 0038, iter [01180, 01251], lr: 0.001463, loss: 3.1658
2022-10-07 17:37:18 - train: epoch 0038, iter [01190, 01251], lr: 0.001463, loss: 3.0188
2022-10-07 17:37:39 - train: epoch 0038, iter [01200, 01251], lr: 0.001463, loss: 2.8225
2022-10-07 17:38:01 - train: epoch 0038, iter [01210, 01251], lr: 0.001463, loss: 3.2380
2022-10-07 17:38:22 - train: epoch 0038, iter [01220, 01251], lr: 0.001462, loss: 2.9242
2022-10-07 17:38:43 - train: epoch 0038, iter [01230, 01251], lr: 0.001462, loss: 3.1633
2022-10-07 17:39:04 - train: epoch 0038, iter [01240, 01251], lr: 0.001462, loss: 3.6288
2022-10-07 17:39:25 - train: epoch 0038, iter [01250, 01251], lr: 0.001462, loss: 3.3756
2022-10-07 17:39:29 - train: epoch 038, train_loss: 3.2493
2022-10-07 17:40:45 - eval: epoch: 038, acc1: 79.558%, acc5: 95.010%, test_loss: 0.9129, per_image_load_time: 1.456ms, per_image_inference_time: 1.443ms
2022-10-07 17:40:47 - until epoch: 038, best_acc1: 79.558%
2022-10-07 17:40:47 - epoch 039 lr: 0.001462
2022-10-07 17:41:14 - train: epoch 0039, iter [00010, 01251], lr: 0.001461, loss: 3.2043
2022-10-07 17:41:35 - train: epoch 0039, iter [00020, 01251], lr: 0.001461, loss: 3.4278
2022-10-07 17:41:56 - train: epoch 0039, iter [00030, 01251], lr: 0.001461, loss: 3.1783
2022-10-07 17:42:17 - train: epoch 0039, iter [00040, 01251], lr: 0.001461, loss: 2.1398
2022-10-07 17:42:38 - train: epoch 0039, iter [00050, 01251], lr: 0.001460, loss: 3.6328
2022-10-07 17:42:59 - train: epoch 0039, iter [00060, 01251], lr: 0.001460, loss: 3.7760
2022-10-07 17:43:20 - train: epoch 0039, iter [00070, 01251], lr: 0.001460, loss: 3.5179
2022-10-07 17:43:41 - train: epoch 0039, iter [00080, 01251], lr: 0.001460, loss: 2.7191
2022-10-07 17:44:02 - train: epoch 0039, iter [00090, 01251], lr: 0.001459, loss: 3.0933
2022-10-07 17:44:24 - train: epoch 0039, iter [00100, 01251], lr: 0.001459, loss: 3.6624
2022-10-07 17:44:45 - train: epoch 0039, iter [00110, 01251], lr: 0.001459, loss: 2.9659
2022-10-07 17:45:06 - train: epoch 0039, iter [00120, 01251], lr: 0.001459, loss: 3.5643
2022-10-07 17:45:27 - train: epoch 0039, iter [00130, 01251], lr: 0.001459, loss: 3.6695
2022-10-07 17:45:48 - train: epoch 0039, iter [00140, 01251], lr: 0.001458, loss: 3.1959
2022-10-07 17:46:09 - train: epoch 0039, iter [00150, 01251], lr: 0.001458, loss: 3.6720
2022-10-07 17:46:30 - train: epoch 0039, iter [00160, 01251], lr: 0.001458, loss: 3.1211
2022-10-07 17:46:51 - train: epoch 0039, iter [00170, 01251], lr: 0.001458, loss: 3.4342
2022-10-07 17:47:12 - train: epoch 0039, iter [00180, 01251], lr: 0.001457, loss: 3.6348
2022-10-07 17:47:33 - train: epoch 0039, iter [00190, 01251], lr: 0.001457, loss: 3.5369
2022-10-07 17:47:54 - train: epoch 0039, iter [00200, 01251], lr: 0.001457, loss: 3.1215
2022-10-07 17:48:15 - train: epoch 0039, iter [00210, 01251], lr: 0.001457, loss: 3.5654
2022-10-07 17:48:36 - train: epoch 0039, iter [00220, 01251], lr: 0.001456, loss: 3.3814
2022-10-07 17:48:57 - train: epoch 0039, iter [00230, 01251], lr: 0.001456, loss: 2.7016
2022-10-07 17:49:19 - train: epoch 0039, iter [00240, 01251], lr: 0.001456, loss: 3.4461
2022-10-07 17:49:40 - train: epoch 0039, iter [00250, 01251], lr: 0.001456, loss: 2.6602
2022-10-07 17:50:01 - train: epoch 0039, iter [00260, 01251], lr: 0.001456, loss: 3.6070
2022-10-07 17:50:22 - train: epoch 0039, iter [00270, 01251], lr: 0.001455, loss: 3.0325
2022-10-07 17:50:43 - train: epoch 0039, iter [00280, 01251], lr: 0.001455, loss: 3.2873
2022-10-07 17:51:04 - train: epoch 0039, iter [00290, 01251], lr: 0.001455, loss: 3.4482
2022-10-07 17:51:25 - train: epoch 0039, iter [00300, 01251], lr: 0.001455, loss: 2.9078
2022-10-07 17:51:46 - train: epoch 0039, iter [00310, 01251], lr: 0.001454, loss: 3.2057
2022-10-07 17:52:07 - train: epoch 0039, iter [00320, 01251], lr: 0.001454, loss: 2.9668
2022-10-07 17:52:28 - train: epoch 0039, iter [00330, 01251], lr: 0.001454, loss: 3.3446
2022-10-07 17:52:50 - train: epoch 0039, iter [00340, 01251], lr: 0.001454, loss: 3.7771
2022-10-07 17:53:11 - train: epoch 0039, iter [00350, 01251], lr: 0.001453, loss: 3.2130
2022-10-07 17:53:32 - train: epoch 0039, iter [00360, 01251], lr: 0.001453, loss: 2.3071
2022-10-07 17:53:53 - train: epoch 0039, iter [00370, 01251], lr: 0.001453, loss: 2.9651
2022-10-07 17:54:14 - train: epoch 0039, iter [00380, 01251], lr: 0.001453, loss: 3.1475
2022-10-07 17:54:35 - train: epoch 0039, iter [00390, 01251], lr: 0.001452, loss: 3.1601
2022-10-07 17:54:56 - train: epoch 0039, iter [00400, 01251], lr: 0.001452, loss: 3.3397
2022-10-07 17:55:17 - train: epoch 0039, iter [00410, 01251], lr: 0.001452, loss: 3.3857
2022-10-07 17:55:38 - train: epoch 0039, iter [00420, 01251], lr: 0.001452, loss: 3.3000
2022-10-07 17:55:59 - train: epoch 0039, iter [00430, 01251], lr: 0.001452, loss: 3.2204
2022-10-07 17:56:20 - train: epoch 0039, iter [00440, 01251], lr: 0.001451, loss: 3.4504
2022-10-07 17:56:42 - train: epoch 0039, iter [00450, 01251], lr: 0.001451, loss: 3.8974
2022-10-07 17:57:03 - train: epoch 0039, iter [00460, 01251], lr: 0.001451, loss: 3.4052
2022-10-07 17:57:24 - train: epoch 0039, iter [00470, 01251], lr: 0.001451, loss: 3.5497
2022-10-07 17:57:45 - train: epoch 0039, iter [00480, 01251], lr: 0.001450, loss: 2.9500
2022-10-07 17:58:06 - train: epoch 0039, iter [00490, 01251], lr: 0.001450, loss: 3.6959
2022-10-07 17:58:27 - train: epoch 0039, iter [00500, 01251], lr: 0.001450, loss: 3.4027
2022-10-07 17:58:48 - train: epoch 0039, iter [00510, 01251], lr: 0.001450, loss: 3.5900
2022-10-07 17:59:09 - train: epoch 0039, iter [00520, 01251], lr: 0.001449, loss: 2.8215
2022-10-07 17:59:30 - train: epoch 0039, iter [00530, 01251], lr: 0.001449, loss: 3.7266
2022-10-07 17:59:51 - train: epoch 0039, iter [00540, 01251], lr: 0.001449, loss: 2.6817
2022-10-07 18:00:12 - train: epoch 0039, iter [00550, 01251], lr: 0.001449, loss: 2.9310
2022-10-07 18:00:33 - train: epoch 0039, iter [00560, 01251], lr: 0.001448, loss: 2.7593
2022-10-07 18:00:54 - train: epoch 0039, iter [00570, 01251], lr: 0.001448, loss: 3.5471
2022-10-07 18:01:15 - train: epoch 0039, iter [00580, 01251], lr: 0.001448, loss: 3.1871
2022-10-07 18:01:36 - train: epoch 0039, iter [00590, 01251], lr: 0.001448, loss: 2.7063
2022-10-07 18:01:57 - train: epoch 0039, iter [00600, 01251], lr: 0.001447, loss: 3.5458
2022-10-07 18:02:18 - train: epoch 0039, iter [00610, 01251], lr: 0.001447, loss: 2.9859
2022-10-07 18:02:40 - train: epoch 0039, iter [00620, 01251], lr: 0.001447, loss: 3.4324
2022-10-07 18:03:01 - train: epoch 0039, iter [00630, 01251], lr: 0.001447, loss: 3.1353
2022-10-07 18:03:22 - train: epoch 0039, iter [00640, 01251], lr: 0.001447, loss: 2.8269
2022-10-07 18:03:43 - train: epoch 0039, iter [00650, 01251], lr: 0.001446, loss: 3.1330
2022-10-07 18:04:04 - train: epoch 0039, iter [00660, 01251], lr: 0.001446, loss: 3.3305
2022-10-07 18:04:25 - train: epoch 0039, iter [00670, 01251], lr: 0.001446, loss: 3.0013
2022-10-07 18:04:46 - train: epoch 0039, iter [00680, 01251], lr: 0.001446, loss: 3.0155
2022-10-07 18:05:07 - train: epoch 0039, iter [00690, 01251], lr: 0.001445, loss: 2.4724
2022-10-07 18:05:28 - train: epoch 0039, iter [00700, 01251], lr: 0.001445, loss: 2.5139
2022-10-07 18:05:49 - train: epoch 0039, iter [00710, 01251], lr: 0.001445, loss: 3.4545
2022-10-07 18:06:10 - train: epoch 0039, iter [00720, 01251], lr: 0.001445, loss: 3.5533
2022-10-07 18:06:31 - train: epoch 0039, iter [00730, 01251], lr: 0.001444, loss: 3.6174
2022-10-07 18:06:52 - train: epoch 0039, iter [00740, 01251], lr: 0.001444, loss: 3.1755
2022-10-07 18:07:13 - train: epoch 0039, iter [00750, 01251], lr: 0.001444, loss: 3.1222
2022-10-07 18:07:34 - train: epoch 0039, iter [00760, 01251], lr: 0.001444, loss: 3.4344
2022-10-07 18:07:56 - train: epoch 0039, iter [00770, 01251], lr: 0.001443, loss: 2.7282
2022-10-07 18:08:17 - train: epoch 0039, iter [00780, 01251], lr: 0.001443, loss: 2.8615
2022-10-07 18:08:38 - train: epoch 0039, iter [00790, 01251], lr: 0.001443, loss: 2.7281
2022-10-07 18:08:59 - train: epoch 0039, iter [00800, 01251], lr: 0.001443, loss: 3.1219
2022-10-07 18:09:20 - train: epoch 0039, iter [00810, 01251], lr: 0.001443, loss: 3.1687
2022-10-07 18:09:41 - train: epoch 0039, iter [00820, 01251], lr: 0.001442, loss: 3.4018
2022-10-07 18:10:02 - train: epoch 0039, iter [00830, 01251], lr: 0.001442, loss: 3.6070
2022-10-07 18:10:23 - train: epoch 0039, iter [00840, 01251], lr: 0.001442, loss: 3.5610
2022-10-07 18:10:44 - train: epoch 0039, iter [00850, 01251], lr: 0.001442, loss: 3.4723
2022-10-07 18:11:05 - train: epoch 0039, iter [00860, 01251], lr: 0.001441, loss: 3.4655
2022-10-07 18:11:26 - train: epoch 0039, iter [00870, 01251], lr: 0.001441, loss: 3.5649
2022-10-07 18:11:47 - train: epoch 0039, iter [00880, 01251], lr: 0.001441, loss: 3.4756
2022-10-07 18:12:08 - train: epoch 0039, iter [00890, 01251], lr: 0.001441, loss: 2.8173
2022-10-07 18:12:29 - train: epoch 0039, iter [00900, 01251], lr: 0.001440, loss: 3.2703
2022-10-07 18:12:51 - train: epoch 0039, iter [00910, 01251], lr: 0.001440, loss: 3.4732
2022-10-07 18:13:12 - train: epoch 0039, iter [00920, 01251], lr: 0.001440, loss: 2.8359
2022-10-07 18:13:33 - train: epoch 0039, iter [00930, 01251], lr: 0.001440, loss: 3.5140
2022-10-07 18:13:54 - train: epoch 0039, iter [00940, 01251], lr: 0.001439, loss: 3.7023
2022-10-07 18:14:15 - train: epoch 0039, iter [00950, 01251], lr: 0.001439, loss: 3.6271
2022-10-07 18:14:36 - train: epoch 0039, iter [00960, 01251], lr: 0.001439, loss: 2.9231
2022-10-07 18:14:57 - train: epoch 0039, iter [00970, 01251], lr: 0.001439, loss: 3.5656
2022-10-07 18:15:18 - train: epoch 0039, iter [00980, 01251], lr: 0.001438, loss: 3.1509
2022-10-07 18:15:39 - train: epoch 0039, iter [00990, 01251], lr: 0.001438, loss: 2.9815
2022-10-07 18:16:00 - train: epoch 0039, iter [01000, 01251], lr: 0.001438, loss: 3.6351
2022-10-07 18:16:21 - train: epoch 0039, iter [01010, 01251], lr: 0.001438, loss: 3.2402
2022-10-07 18:16:42 - train: epoch 0039, iter [01020, 01251], lr: 0.001438, loss: 3.2291
2022-10-07 18:17:03 - train: epoch 0039, iter [01030, 01251], lr: 0.001437, loss: 3.5877
2022-10-07 18:17:24 - train: epoch 0039, iter [01040, 01251], lr: 0.001437, loss: 2.3135
2022-10-07 18:17:45 - train: epoch 0039, iter [01050, 01251], lr: 0.001437, loss: 3.4226
2022-10-07 18:18:06 - train: epoch 0039, iter [01060, 01251], lr: 0.001437, loss: 2.7575
2022-10-07 18:18:28 - train: epoch 0039, iter [01070, 01251], lr: 0.001436, loss: 3.3272
2022-10-07 18:18:48 - train: epoch 0039, iter [01080, 01251], lr: 0.001436, loss: 3.3870
2022-10-07 18:19:10 - train: epoch 0039, iter [01090, 01251], lr: 0.001436, loss: 3.1264
2022-10-07 18:19:31 - train: epoch 0039, iter [01100, 01251], lr: 0.001436, loss: 3.3842
2022-10-07 18:19:52 - train: epoch 0039, iter [01110, 01251], lr: 0.001435, loss: 3.4478
2022-10-07 18:20:13 - train: epoch 0039, iter [01120, 01251], lr: 0.001435, loss: 2.7417
2022-10-07 18:20:34 - train: epoch 0039, iter [01130, 01251], lr: 0.001435, loss: 2.9539
2022-10-07 18:20:55 - train: epoch 0039, iter [01140, 01251], lr: 0.001435, loss: 3.5966
2022-10-07 18:21:16 - train: epoch 0039, iter [01150, 01251], lr: 0.001434, loss: 3.1758
2022-10-07 18:21:37 - train: epoch 0039, iter [01160, 01251], lr: 0.001434, loss: 3.3783
2022-10-07 18:21:58 - train: epoch 0039, iter [01170, 01251], lr: 0.001434, loss: 3.1936
2022-10-07 18:22:19 - train: epoch 0039, iter [01180, 01251], lr: 0.001434, loss: 3.9101
2022-10-07 18:22:41 - train: epoch 0039, iter [01190, 01251], lr: 0.001433, loss: 3.1986
2022-10-07 18:23:02 - train: epoch 0039, iter [01200, 01251], lr: 0.001433, loss: 3.6896
2022-10-07 18:23:23 - train: epoch 0039, iter [01210, 01251], lr: 0.001433, loss: 3.6894
2022-10-07 18:23:44 - train: epoch 0039, iter [01220, 01251], lr: 0.001433, loss: 3.2783
2022-10-07 18:24:05 - train: epoch 0039, iter [01230, 01251], lr: 0.001433, loss: 3.3946
2022-10-07 18:24:26 - train: epoch 0039, iter [01240, 01251], lr: 0.001432, loss: 2.9986
2022-10-07 18:24:47 - train: epoch 0039, iter [01250, 01251], lr: 0.001432, loss: 2.9898
2022-10-07 18:24:51 - train: epoch 039, train_loss: 3.2329
2022-10-07 18:26:06 - eval: epoch: 039, acc1: 79.236%, acc5: 95.126%, test_loss: 0.8783, per_image_load_time: 0.340ms, per_image_inference_time: 1.432ms
2022-10-07 18:26:07 - until epoch: 039, best_acc1: 79.558%
2022-10-07 18:26:07 - epoch 040 lr: 0.001432
2022-10-07 18:26:34 - train: epoch 0040, iter [00010, 01251], lr: 0.001432, loss: 3.3658
2022-10-07 18:26:55 - train: epoch 0040, iter [00020, 01251], lr: 0.001432, loss: 3.3672
2022-10-07 18:27:16 - train: epoch 0040, iter [00030, 01251], lr: 0.001431, loss: 2.8380
2022-10-07 18:27:38 - train: epoch 0040, iter [00040, 01251], lr: 0.001431, loss: 3.3446
2022-10-07 18:27:59 - train: epoch 0040, iter [00050, 01251], lr: 0.001431, loss: 3.1561
2022-10-07 18:28:20 - train: epoch 0040, iter [00060, 01251], lr: 0.001431, loss: 3.5273
2022-10-07 18:28:41 - train: epoch 0040, iter [00070, 01251], lr: 0.001430, loss: 3.5651
2022-10-07 18:29:02 - train: epoch 0040, iter [00080, 01251], lr: 0.001430, loss: 3.4820
2022-10-07 18:29:23 - train: epoch 0040, iter [00090, 01251], lr: 0.001430, loss: 3.4670
2022-10-07 18:29:45 - train: epoch 0040, iter [00100, 01251], lr: 0.001430, loss: 2.8326
2022-10-07 18:30:06 - train: epoch 0040, iter [00110, 01251], lr: 0.001429, loss: 3.6040
2022-10-07 18:30:27 - train: epoch 0040, iter [00120, 01251], lr: 0.001429, loss: 3.4434
2022-10-07 18:30:48 - train: epoch 0040, iter [00130, 01251], lr: 0.001429, loss: 2.8864
2022-10-07 18:31:09 - train: epoch 0040, iter [00140, 01251], lr: 0.001429, loss: 3.3164
2022-10-07 18:31:30 - train: epoch 0040, iter [00150, 01251], lr: 0.001428, loss: 3.8028
2022-10-07 18:31:52 - train: epoch 0040, iter [00160, 01251], lr: 0.001428, loss: 2.8304
2022-10-07 18:32:13 - train: epoch 0040, iter [00170, 01251], lr: 0.001428, loss: 2.8482
2022-10-07 18:32:34 - train: epoch 0040, iter [00180, 01251], lr: 0.001428, loss: 2.9922
2022-10-07 18:32:55 - train: epoch 0040, iter [00190, 01251], lr: 0.001428, loss: 2.6262
2022-10-07 18:33:17 - train: epoch 0040, iter [00200, 01251], lr: 0.001427, loss: 2.7685
2022-10-07 18:33:38 - train: epoch 0040, iter [00210, 01251], lr: 0.001427, loss: 2.3926
2022-10-07 18:33:59 - train: epoch 0040, iter [00220, 01251], lr: 0.001427, loss: 3.2224
2022-10-07 18:34:20 - train: epoch 0040, iter [00230, 01251], lr: 0.001427, loss: 3.5487
2022-10-07 18:34:41 - train: epoch 0040, iter [00240, 01251], lr: 0.001426, loss: 2.6943
2022-10-07 18:35:02 - train: epoch 0040, iter [00250, 01251], lr: 0.001426, loss: 2.6864
2022-10-07 18:35:23 - train: epoch 0040, iter [00260, 01251], lr: 0.001426, loss: 3.0141
2022-10-07 18:35:44 - train: epoch 0040, iter [00270, 01251], lr: 0.001426, loss: 3.0899
2022-10-07 18:36:06 - train: epoch 0040, iter [00280, 01251], lr: 0.001425, loss: 3.3693
2022-10-07 18:36:27 - train: epoch 0040, iter [00290, 01251], lr: 0.001425, loss: 3.0565
2022-10-07 18:36:48 - train: epoch 0040, iter [00300, 01251], lr: 0.001425, loss: 2.8423
2022-10-07 18:37:09 - train: epoch 0040, iter [00310, 01251], lr: 0.001425, loss: 3.5448
2022-10-07 18:37:30 - train: epoch 0040, iter [00320, 01251], lr: 0.001424, loss: 3.4976
2022-10-07 18:37:51 - train: epoch 0040, iter [00330, 01251], lr: 0.001424, loss: 3.2880
2022-10-07 18:38:12 - train: epoch 0040, iter [00340, 01251], lr: 0.001424, loss: 3.7333
2022-10-07 18:38:34 - train: epoch 0040, iter [00350, 01251], lr: 0.001424, loss: 3.5823
2022-10-07 18:38:55 - train: epoch 0040, iter [00360, 01251], lr: 0.001423, loss: 3.0911
2022-10-07 18:39:16 - train: epoch 0040, iter [00370, 01251], lr: 0.001423, loss: 3.1712
2022-10-07 18:39:37 - train: epoch 0040, iter [00380, 01251], lr: 0.001423, loss: 3.4530
2022-10-07 18:39:58 - train: epoch 0040, iter [00390, 01251], lr: 0.001423, loss: 3.6149
2022-10-07 18:40:19 - train: epoch 0040, iter [00400, 01251], lr: 0.001422, loss: 3.5518
2022-10-07 18:40:40 - train: epoch 0040, iter [00410, 01251], lr: 0.001422, loss: 3.1916
2022-10-07 18:41:02 - train: epoch 0040, iter [00420, 01251], lr: 0.001422, loss: 3.5740
2022-10-07 18:41:23 - train: epoch 0040, iter [00430, 01251], lr: 0.001422, loss: 2.2110
2022-10-07 18:41:44 - train: epoch 0040, iter [00440, 01251], lr: 0.001422, loss: 3.8054
2022-10-07 18:42:05 - train: epoch 0040, iter [00450, 01251], lr: 0.001421, loss: 3.3337
2022-10-07 18:42:26 - train: epoch 0040, iter [00460, 01251], lr: 0.001421, loss: 3.7144
2022-10-07 18:42:47 - train: epoch 0040, iter [00470, 01251], lr: 0.001421, loss: 3.2041
2022-10-07 18:43:08 - train: epoch 0040, iter [00480, 01251], lr: 0.001421, loss: 2.9368
2022-10-07 18:43:29 - train: epoch 0040, iter [00490, 01251], lr: 0.001420, loss: 3.6444
2022-10-07 18:43:50 - train: epoch 0040, iter [00500, 01251], lr: 0.001420, loss: 3.3075
2022-10-07 18:44:11 - train: epoch 0040, iter [00510, 01251], lr: 0.001420, loss: 2.9824
2022-10-07 18:44:32 - train: epoch 0040, iter [00520, 01251], lr: 0.001420, loss: 3.1815
2022-10-07 18:44:53 - train: epoch 0040, iter [00530, 01251], lr: 0.001419, loss: 3.7639
2022-10-07 18:45:14 - train: epoch 0040, iter [00540, 01251], lr: 0.001419, loss: 3.1995
2022-10-07 18:45:36 - train: epoch 0040, iter [00550, 01251], lr: 0.001419, loss: 3.4346
2022-10-07 18:45:57 - train: epoch 0040, iter [00560, 01251], lr: 0.001419, loss: 3.4006
2022-10-07 18:46:18 - train: epoch 0040, iter [00570, 01251], lr: 0.001418, loss: 3.3255
2022-10-07 18:46:39 - train: epoch 0040, iter [00580, 01251], lr: 0.001418, loss: 3.7512
2022-10-07 18:47:00 - train: epoch 0040, iter [00590, 01251], lr: 0.001418, loss: 3.2871
2022-10-07 18:47:21 - train: epoch 0040, iter [00600, 01251], lr: 0.001418, loss: 3.0535
2022-10-07 18:47:42 - train: epoch 0040, iter [00610, 01251], lr: 0.001417, loss: 2.9794
2022-10-07 18:48:03 - train: epoch 0040, iter [00620, 01251], lr: 0.001417, loss: 2.9853
2022-10-07 18:48:24 - train: epoch 0040, iter [00630, 01251], lr: 0.001417, loss: 3.2045
2022-10-07 18:48:45 - train: epoch 0040, iter [00640, 01251], lr: 0.001417, loss: 3.7277
2022-10-07 18:49:06 - train: epoch 0040, iter [00650, 01251], lr: 0.001416, loss: 3.3619
2022-10-07 18:49:27 - train: epoch 0040, iter [00660, 01251], lr: 0.001416, loss: 2.9060
2022-10-07 18:49:48 - train: epoch 0040, iter [00670, 01251], lr: 0.001416, loss: 2.9024
2022-10-07 18:50:09 - train: epoch 0040, iter [00680, 01251], lr: 0.001416, loss: 3.5784
2022-10-07 18:50:30 - train: epoch 0040, iter [00690, 01251], lr: 0.001416, loss: 2.8045
2022-10-07 18:50:51 - train: epoch 0040, iter [00700, 01251], lr: 0.001415, loss: 3.0355
2022-10-07 18:51:13 - train: epoch 0040, iter [00710, 01251], lr: 0.001415, loss: 3.1845
2022-10-07 18:51:34 - train: epoch 0040, iter [00720, 01251], lr: 0.001415, loss: 2.8529
2022-10-07 18:51:55 - train: epoch 0040, iter [00730, 01251], lr: 0.001415, loss: 3.6174
2022-10-07 18:52:16 - train: epoch 0040, iter [00740, 01251], lr: 0.001414, loss: 2.9538
2022-10-07 18:52:37 - train: epoch 0040, iter [00750, 01251], lr: 0.001414, loss: 3.4418
2022-10-07 18:52:58 - train: epoch 0040, iter [00760, 01251], lr: 0.001414, loss: 2.8201
2022-10-07 18:53:19 - train: epoch 0040, iter [00770, 01251], lr: 0.001414, loss: 2.7719
2022-10-07 18:53:40 - train: epoch 0040, iter [00780, 01251], lr: 0.001413, loss: 3.0531
2022-10-07 18:54:01 - train: epoch 0040, iter [00790, 01251], lr: 0.001413, loss: 2.9356
2022-10-07 18:54:22 - train: epoch 0040, iter [00800, 01251], lr: 0.001413, loss: 3.6009
2022-10-07 18:54:43 - train: epoch 0040, iter [00810, 01251], lr: 0.001413, loss: 2.7152
2022-10-07 18:55:04 - train: epoch 0040, iter [00820, 01251], lr: 0.001412, loss: 3.6380
2022-10-07 18:55:25 - train: epoch 0040, iter [00830, 01251], lr: 0.001412, loss: 3.4970
2022-10-07 18:55:47 - train: epoch 0040, iter [00840, 01251], lr: 0.001412, loss: 3.0776
2022-10-07 18:56:08 - train: epoch 0040, iter [00850, 01251], lr: 0.001412, loss: 3.0475
2022-10-07 18:56:29 - train: epoch 0040, iter [00860, 01251], lr: 0.001411, loss: 2.8474
2022-10-07 18:56:50 - train: epoch 0040, iter [00870, 01251], lr: 0.001411, loss: 2.8800
2022-10-07 18:57:11 - train: epoch 0040, iter [00880, 01251], lr: 0.001411, loss: 3.0996
2022-10-07 18:57:32 - train: epoch 0040, iter [00890, 01251], lr: 0.001411, loss: 3.3987
2022-10-07 18:57:53 - train: epoch 0040, iter [00900, 01251], lr: 0.001410, loss: 3.4850
2022-10-07 18:58:14 - train: epoch 0040, iter [00910, 01251], lr: 0.001410, loss: 3.6910
2022-10-07 18:58:35 - train: epoch 0040, iter [00920, 01251], lr: 0.001410, loss: 3.8240
2022-10-07 18:58:56 - train: epoch 0040, iter [00930, 01251], lr: 0.001410, loss: 3.5470
2022-10-07 18:59:17 - train: epoch 0040, iter [00940, 01251], lr: 0.001410, loss: 3.2668
2022-10-07 18:59:38 - train: epoch 0040, iter [00950, 01251], lr: 0.001409, loss: 2.7307
2022-10-07 18:59:59 - train: epoch 0040, iter [00960, 01251], lr: 0.001409, loss: 3.2994
2022-10-07 19:00:20 - train: epoch 0040, iter [00970, 01251], lr: 0.001409, loss: 3.0039
2022-10-07 19:00:42 - train: epoch 0040, iter [00980, 01251], lr: 0.001409, loss: 3.6529
2022-10-07 19:01:03 - train: epoch 0040, iter [00990, 01251], lr: 0.001408, loss: 3.4625
2022-10-07 19:01:24 - train: epoch 0040, iter [01000, 01251], lr: 0.001408, loss: 2.8755
2022-10-07 19:01:45 - train: epoch 0040, iter [01010, 01251], lr: 0.001408, loss: 3.3156
2022-10-07 19:02:06 - train: epoch 0040, iter [01020, 01251], lr: 0.001408, loss: 3.5133
2022-10-07 19:02:27 - train: epoch 0040, iter [01030, 01251], lr: 0.001407, loss: 2.6278
2022-10-07 19:02:48 - train: epoch 0040, iter [01040, 01251], lr: 0.001407, loss: 3.5990
2022-10-07 19:03:09 - train: epoch 0040, iter [01050, 01251], lr: 0.001407, loss: 3.6717
2022-10-07 19:03:30 - train: epoch 0040, iter [01060, 01251], lr: 0.001407, loss: 3.0956
2022-10-07 19:03:51 - train: epoch 0040, iter [01070, 01251], lr: 0.001406, loss: 3.4212
2022-10-07 19:04:12 - train: epoch 0040, iter [01080, 01251], lr: 0.001406, loss: 3.2169
2022-10-07 19:04:33 - train: epoch 0040, iter [01090, 01251], lr: 0.001406, loss: 3.5824
2022-10-07 19:04:54 - train: epoch 0040, iter [01100, 01251], lr: 0.001406, loss: 3.4469
2022-10-07 19:05:15 - train: epoch 0040, iter [01110, 01251], lr: 0.001405, loss: 3.5740
2022-10-07 19:05:36 - train: epoch 0040, iter [01120, 01251], lr: 0.001405, loss: 2.7974
2022-10-07 19:05:57 - train: epoch 0040, iter [01130, 01251], lr: 0.001405, loss: 2.9870
2022-10-07 19:06:18 - train: epoch 0040, iter [01140, 01251], lr: 0.001405, loss: 3.5710
2022-10-07 19:06:39 - train: epoch 0040, iter [01150, 01251], lr: 0.001404, loss: 3.4405
2022-10-07 19:07:00 - train: epoch 0040, iter [01160, 01251], lr: 0.001404, loss: 3.4693
2022-10-07 19:07:21 - train: epoch 0040, iter [01170, 01251], lr: 0.001404, loss: 3.2310
2022-10-07 19:07:42 - train: epoch 0040, iter [01180, 01251], lr: 0.001404, loss: 3.6661
2022-10-07 19:08:03 - train: epoch 0040, iter [01190, 01251], lr: 0.001403, loss: 3.1629
2022-10-07 19:08:24 - train: epoch 0040, iter [01200, 01251], lr: 0.001403, loss: 3.2519
2022-10-07 19:08:45 - train: epoch 0040, iter [01210, 01251], lr: 0.001403, loss: 3.1449
2022-10-07 19:09:06 - train: epoch 0040, iter [01220, 01251], lr: 0.001403, loss: 3.2012
2022-10-07 19:09:27 - train: epoch 0040, iter [01230, 01251], lr: 0.001403, loss: 3.4135
2022-10-07 19:09:49 - train: epoch 0040, iter [01240, 01251], lr: 0.001402, loss: 3.3677
2022-10-07 19:10:09 - train: epoch 0040, iter [01250, 01251], lr: 0.001402, loss: 3.3908
2022-10-07 19:10:13 - train: epoch 040, train_loss: 3.2259
2022-10-07 19:11:29 - eval: epoch: 040, acc1: 79.860%, acc5: 95.284%, test_loss: 0.8853, per_image_load_time: 0.575ms, per_image_inference_time: 1.442ms
2022-10-07 19:11:31 - until epoch: 040, best_acc1: 79.860%
2022-10-07 19:11:31 - epoch 041 lr: 0.001402
2022-10-07 19:11:57 - train: epoch 0041, iter [00010, 01251], lr: 0.001402, loss: 3.0016
2022-10-07 19:12:18 - train: epoch 0041, iter [00020, 01251], lr: 0.001402, loss: 3.1168
2022-10-07 19:12:39 - train: epoch 0041, iter [00030, 01251], lr: 0.001401, loss: 2.7466
2022-10-07 19:13:01 - train: epoch 0041, iter [00040, 01251], lr: 0.001401, loss: 2.8373
2022-10-07 19:13:22 - train: epoch 0041, iter [00050, 01251], lr: 0.001401, loss: 2.9193
2022-10-07 19:13:43 - train: epoch 0041, iter [00060, 01251], lr: 0.001401, loss: 3.0261
2022-10-07 19:14:04 - train: epoch 0041, iter [00070, 01251], lr: 0.001400, loss: 2.8277
2022-10-07 19:14:25 - train: epoch 0041, iter [00080, 01251], lr: 0.001400, loss: 2.9816
2022-10-07 19:14:46 - train: epoch 0041, iter [00090, 01251], lr: 0.001400, loss: 2.7974
2022-10-07 19:15:07 - train: epoch 0041, iter [00100, 01251], lr: 0.001400, loss: 2.6673
2022-10-07 19:15:28 - train: epoch 0041, iter [00110, 01251], lr: 0.001399, loss: 3.5533
2022-10-07 19:15:50 - train: epoch 0041, iter [00120, 01251], lr: 0.001399, loss: 3.2372
2022-10-07 19:16:11 - train: epoch 0041, iter [00130, 01251], lr: 0.001399, loss: 3.2296
2022-10-07 19:16:32 - train: epoch 0041, iter [00140, 01251], lr: 0.001399, loss: 3.2029
2022-10-07 19:16:53 - train: epoch 0041, iter [00150, 01251], lr: 0.001398, loss: 3.5447
2022-10-07 19:17:14 - train: epoch 0041, iter [00160, 01251], lr: 0.001398, loss: 2.7373
2022-10-07 19:17:35 - train: epoch 0041, iter [00170, 01251], lr: 0.001398, loss: 3.4386
2022-10-07 19:17:56 - train: epoch 0041, iter [00180, 01251], lr: 0.001398, loss: 2.8862
2022-10-07 19:18:18 - train: epoch 0041, iter [00190, 01251], lr: 0.001397, loss: 2.8907
2022-10-07 19:18:39 - train: epoch 0041, iter [00200, 01251], lr: 0.001397, loss: 3.5045
2022-10-07 19:19:00 - train: epoch 0041, iter [00210, 01251], lr: 0.001397, loss: 2.7999
2022-10-07 19:19:21 - train: epoch 0041, iter [00220, 01251], lr: 0.001397, loss: 2.7623
2022-10-07 19:19:43 - train: epoch 0041, iter [00230, 01251], lr: 0.001396, loss: 3.6842
2022-10-07 19:20:04 - train: epoch 0041, iter [00240, 01251], lr: 0.001396, loss: 3.0146
2022-10-07 19:20:25 - train: epoch 0041, iter [00250, 01251], lr: 0.001396, loss: 3.7074
2022-10-07 19:20:46 - train: epoch 0041, iter [00260, 01251], lr: 0.001396, loss: 3.2263
2022-10-07 19:21:07 - train: epoch 0041, iter [00270, 01251], lr: 0.001395, loss: 3.4237
2022-10-07 19:21:28 - train: epoch 0041, iter [00280, 01251], lr: 0.001395, loss: 3.6587
2022-10-07 19:21:49 - train: epoch 0041, iter [00290, 01251], lr: 0.001395, loss: 3.6185
2022-10-07 19:22:10 - train: epoch 0041, iter [00300, 01251], lr: 0.001395, loss: 3.1743
2022-10-07 19:22:31 - train: epoch 0041, iter [00310, 01251], lr: 0.001394, loss: 2.6571
2022-10-07 19:22:52 - train: epoch 0041, iter [00320, 01251], lr: 0.001394, loss: 2.7325
2022-10-07 19:23:13 - train: epoch 0041, iter [00330, 01251], lr: 0.001394, loss: 3.5074
2022-10-07 19:23:35 - train: epoch 0041, iter [00340, 01251], lr: 0.001394, loss: 3.4049
2022-10-07 19:23:56 - train: epoch 0041, iter [00350, 01251], lr: 0.001394, loss: 3.0711
2022-10-07 19:24:17 - train: epoch 0041, iter [00360, 01251], lr: 0.001393, loss: 3.5239
2022-10-07 19:24:38 - train: epoch 0041, iter [00370, 01251], lr: 0.001393, loss: 3.5053
2022-10-07 19:24:59 - train: epoch 0041, iter [00380, 01251], lr: 0.001393, loss: 3.2357
2022-10-07 19:25:20 - train: epoch 0041, iter [00390, 01251], lr: 0.001393, loss: 3.5773
2022-10-07 19:25:41 - train: epoch 0041, iter [00400, 01251], lr: 0.001392, loss: 2.7325
2022-10-07 19:26:03 - train: epoch 0041, iter [00410, 01251], lr: 0.001392, loss: 3.1949
2022-10-07 19:26:24 - train: epoch 0041, iter [00420, 01251], lr: 0.001392, loss: 3.1521
2022-10-07 19:26:45 - train: epoch 0041, iter [00430, 01251], lr: 0.001392, loss: 2.6048
2022-10-07 19:27:06 - train: epoch 0041, iter [00440, 01251], lr: 0.001391, loss: 3.5922
2022-10-07 19:27:27 - train: epoch 0041, iter [00450, 01251], lr: 0.001391, loss: 3.5126
2022-10-07 19:27:48 - train: epoch 0041, iter [00460, 01251], lr: 0.001391, loss: 3.0964
2022-10-07 19:28:09 - train: epoch 0041, iter [00470, 01251], lr: 0.001391, loss: 3.3364
2022-10-07 19:28:30 - train: epoch 0041, iter [00480, 01251], lr: 0.001390, loss: 3.5232
2022-10-07 19:28:51 - train: epoch 0041, iter [00490, 01251], lr: 0.001390, loss: 3.0042
2022-10-07 19:29:12 - train: epoch 0041, iter [00500, 01251], lr: 0.001390, loss: 3.3722
2022-10-07 19:29:33 - train: epoch 0041, iter [00510, 01251], lr: 0.001390, loss: 3.1539
2022-10-07 19:29:54 - train: epoch 0041, iter [00520, 01251], lr: 0.001389, loss: 3.4779
2022-10-07 19:30:15 - train: epoch 0041, iter [00530, 01251], lr: 0.001389, loss: 3.1564
2022-10-07 19:30:37 - train: epoch 0041, iter [00540, 01251], lr: 0.001389, loss: 3.2533
2022-10-07 19:30:58 - train: epoch 0041, iter [00550, 01251], lr: 0.001389, loss: 3.5461
2022-10-07 19:31:19 - train: epoch 0041, iter [00560, 01251], lr: 0.001388, loss: 3.4362
2022-10-07 19:31:40 - train: epoch 0041, iter [00570, 01251], lr: 0.001388, loss: 3.2541
2022-10-07 19:32:01 - train: epoch 0041, iter [00580, 01251], lr: 0.001388, loss: 3.3027
2022-10-07 19:32:22 - train: epoch 0041, iter [00590, 01251], lr: 0.001388, loss: 2.5387
2022-10-07 19:32:43 - train: epoch 0041, iter [00600, 01251], lr: 0.001387, loss: 3.8088
2022-10-07 19:33:04 - train: epoch 0041, iter [00610, 01251], lr: 0.001387, loss: 2.8543
2022-10-07 19:33:25 - train: epoch 0041, iter [00620, 01251], lr: 0.001387, loss: 3.2237
2022-10-07 19:33:46 - train: epoch 0041, iter [00630, 01251], lr: 0.001387, loss: 2.9532
2022-10-07 19:34:08 - train: epoch 0041, iter [00640, 01251], lr: 0.001386, loss: 3.5448
2022-10-07 19:34:29 - train: epoch 0041, iter [00650, 01251], lr: 0.001386, loss: 3.5102
2022-10-07 19:34:50 - train: epoch 0041, iter [00660, 01251], lr: 0.001386, loss: 3.1318
2022-10-07 19:35:11 - train: epoch 0041, iter [00670, 01251], lr: 0.001386, loss: 3.3698
2022-10-07 19:35:32 - train: epoch 0041, iter [00680, 01251], lr: 0.001385, loss: 3.8993
2022-10-07 19:35:53 - train: epoch 0041, iter [00690, 01251], lr: 0.001385, loss: 2.9460
2022-10-07 19:36:14 - train: epoch 0041, iter [00700, 01251], lr: 0.001385, loss: 3.3880
2022-10-07 19:36:35 - train: epoch 0041, iter [00710, 01251], lr: 0.001385, loss: 2.6079
2022-10-07 19:36:56 - train: epoch 0041, iter [00720, 01251], lr: 0.001385, loss: 3.1726
2022-10-07 19:37:17 - train: epoch 0041, iter [00730, 01251], lr: 0.001384, loss: 3.3676
2022-10-07 19:37:38 - train: epoch 0041, iter [00740, 01251], lr: 0.001384, loss: 2.6164
2022-10-07 19:37:59 - train: epoch 0041, iter [00750, 01251], lr: 0.001384, loss: 2.7476
2022-10-07 19:38:20 - train: epoch 0041, iter [00760, 01251], lr: 0.001384, loss: 3.2121
2022-10-07 19:38:41 - train: epoch 0041, iter [00770, 01251], lr: 0.001383, loss: 2.6055
2022-10-07 19:39:02 - train: epoch 0041, iter [00780, 01251], lr: 0.001383, loss: 3.4963
2022-10-07 19:39:23 - train: epoch 0041, iter [00790, 01251], lr: 0.001383, loss: 3.4717
2022-10-07 19:39:44 - train: epoch 0041, iter [00800, 01251], lr: 0.001383, loss: 3.7050
2022-10-07 19:40:05 - train: epoch 0041, iter [00810, 01251], lr: 0.001382, loss: 3.6534
2022-10-07 19:40:26 - train: epoch 0041, iter [00820, 01251], lr: 0.001382, loss: 2.3151
2022-10-07 19:40:47 - train: epoch 0041, iter [00830, 01251], lr: 0.001382, loss: 3.7016
2022-10-07 19:41:08 - train: epoch 0041, iter [00840, 01251], lr: 0.001382, loss: 3.6257
2022-10-07 19:41:29 - train: epoch 0041, iter [00850, 01251], lr: 0.001381, loss: 3.0256
2022-10-07 19:41:50 - train: epoch 0041, iter [00860, 01251], lr: 0.001381, loss: 3.5950
2022-10-07 19:42:11 - train: epoch 0041, iter [00870, 01251], lr: 0.001381, loss: 3.3357
2022-10-07 19:42:32 - train: epoch 0041, iter [00880, 01251], lr: 0.001381, loss: 3.6515
2022-10-07 19:42:53 - train: epoch 0041, iter [00890, 01251], lr: 0.001380, loss: 3.5147
2022-10-07 19:43:14 - train: epoch 0041, iter [00900, 01251], lr: 0.001380, loss: 3.6448
2022-10-07 19:43:35 - train: epoch 0041, iter [00910, 01251], lr: 0.001380, loss: 2.7866
2022-10-07 19:43:56 - train: epoch 0041, iter [00920, 01251], lr: 0.001380, loss: 2.9773
2022-10-07 19:44:17 - train: epoch 0041, iter [00930, 01251], lr: 0.001379, loss: 3.2213
2022-10-07 19:44:38 - train: epoch 0041, iter [00940, 01251], lr: 0.001379, loss: 3.3930
2022-10-07 19:44:59 - train: epoch 0041, iter [00950, 01251], lr: 0.001379, loss: 3.2011
2022-10-07 19:45:20 - train: epoch 0041, iter [00960, 01251], lr: 0.001379, loss: 3.5148
2022-10-07 19:45:41 - train: epoch 0041, iter [00970, 01251], lr: 0.001378, loss: 3.4729
2022-10-07 19:46:02 - train: epoch 0041, iter [00980, 01251], lr: 0.001378, loss: 2.9426
2022-10-07 19:46:23 - train: epoch 0041, iter [00990, 01251], lr: 0.001378, loss: 3.6863
2022-10-07 19:46:45 - train: epoch 0041, iter [01000, 01251], lr: 0.001378, loss: 3.0776
2022-10-07 19:47:06 - train: epoch 0041, iter [01010, 01251], lr: 0.001377, loss: 2.8842
2022-10-07 19:47:27 - train: epoch 0041, iter [01020, 01251], lr: 0.001377, loss: 3.4119
2022-10-07 19:47:48 - train: epoch 0041, iter [01030, 01251], lr: 0.001377, loss: 3.2377
2022-10-07 19:48:09 - train: epoch 0041, iter [01040, 01251], lr: 0.001377, loss: 3.4657
2022-10-07 19:48:30 - train: epoch 0041, iter [01050, 01251], lr: 0.001376, loss: 3.3817
2022-10-07 19:48:51 - train: epoch 0041, iter [01060, 01251], lr: 0.001376, loss: 3.5446
2022-10-07 19:49:12 - train: epoch 0041, iter [01070, 01251], lr: 0.001376, loss: 3.5550
2022-10-07 19:49:33 - train: epoch 0041, iter [01080, 01251], lr: 0.001376, loss: 3.1827
2022-10-07 19:49:54 - train: epoch 0041, iter [01090, 01251], lr: 0.001375, loss: 3.2051
2022-10-07 19:50:15 - train: epoch 0041, iter [01100, 01251], lr: 0.001375, loss: 3.5397
2022-10-07 19:50:36 - train: epoch 0041, iter [01110, 01251], lr: 0.001375, loss: 3.4545
2022-10-07 19:50:57 - train: epoch 0041, iter [01120, 01251], lr: 0.001375, loss: 3.5428
2022-10-07 19:51:18 - train: epoch 0041, iter [01130, 01251], lr: 0.001374, loss: 3.4888
2022-10-07 19:51:39 - train: epoch 0041, iter [01140, 01251], lr: 0.001374, loss: 3.0803
2022-10-07 19:52:00 - train: epoch 0041, iter [01150, 01251], lr: 0.001374, loss: 3.3026
2022-10-07 19:52:21 - train: epoch 0041, iter [01160, 01251], lr: 0.001374, loss: 3.6748
2022-10-07 19:52:42 - train: epoch 0041, iter [01170, 01251], lr: 0.001373, loss: 3.5993
2022-10-07 19:53:03 - train: epoch 0041, iter [01180, 01251], lr: 0.001373, loss: 3.4311
2022-10-07 19:53:24 - train: epoch 0041, iter [01190, 01251], lr: 0.001373, loss: 3.0030
2022-10-07 19:53:45 - train: epoch 0041, iter [01200, 01251], lr: 0.001373, loss: 3.1592
2022-10-07 19:54:07 - train: epoch 0041, iter [01210, 01251], lr: 0.001373, loss: 3.4611
2022-10-07 19:54:28 - train: epoch 0041, iter [01220, 01251], lr: 0.001372, loss: 3.2272
2022-10-07 19:54:49 - train: epoch 0041, iter [01230, 01251], lr: 0.001372, loss: 3.0089
2022-10-07 19:55:10 - train: epoch 0041, iter [01240, 01251], lr: 0.001372, loss: 3.5109
2022-10-07 19:55:31 - train: epoch 0041, iter [01250, 01251], lr: 0.001372, loss: 3.0705
2022-10-07 19:55:35 - train: epoch 041, train_loss: 3.2133
2022-10-07 19:56:51 - eval: epoch: 041, acc1: 79.620%, acc5: 95.126%, test_loss: 0.9014, per_image_load_time: 0.542ms, per_image_inference_time: 1.432ms
2022-10-07 19:56:52 - until epoch: 041, best_acc1: 79.860%
2022-10-07 19:56:52 - epoch 042 lr: 0.001372
2022-10-07 19:57:19 - train: epoch 0042, iter [00010, 01251], lr: 0.001371, loss: 3.5635
2022-10-07 19:57:40 - train: epoch 0042, iter [00020, 01251], lr: 0.001371, loss: 3.5448
2022-10-07 19:58:01 - train: epoch 0042, iter [00030, 01251], lr: 0.001371, loss: 2.8683
2022-10-07 19:58:22 - train: epoch 0042, iter [00040, 01251], lr: 0.001371, loss: 3.0057
2022-10-07 19:58:43 - train: epoch 0042, iter [00050, 01251], lr: 0.001370, loss: 3.1652
2022-10-07 19:59:05 - train: epoch 0042, iter [00060, 01251], lr: 0.001370, loss: 3.3716
2022-10-07 19:59:26 - train: epoch 0042, iter [00070, 01251], lr: 0.001370, loss: 3.0855
2022-10-07 19:59:47 - train: epoch 0042, iter [00080, 01251], lr: 0.001370, loss: 2.9942
2022-10-07 20:00:08 - train: epoch 0042, iter [00090, 01251], lr: 0.001369, loss: 3.4720
2022-10-07 20:00:29 - train: epoch 0042, iter [00100, 01251], lr: 0.001369, loss: 3.7751
2022-10-07 20:00:51 - train: epoch 0042, iter [00110, 01251], lr: 0.001369, loss: 3.3740
2022-10-07 20:01:12 - train: epoch 0042, iter [00120, 01251], lr: 0.001369, loss: 3.5070
2022-10-07 20:01:33 - train: epoch 0042, iter [00130, 01251], lr: 0.001368, loss: 2.7097
2022-10-07 20:01:54 - train: epoch 0042, iter [00140, 01251], lr: 0.001368, loss: 3.4481
2022-10-07 20:02:15 - train: epoch 0042, iter [00150, 01251], lr: 0.001368, loss: 2.8920
2022-10-07 20:02:36 - train: epoch 0042, iter [00160, 01251], lr: 0.001368, loss: 3.1192
2022-10-07 20:02:57 - train: epoch 0042, iter [00170, 01251], lr: 0.001367, loss: 2.8511
2022-10-07 20:03:18 - train: epoch 0042, iter [00180, 01251], lr: 0.001367, loss: 2.7610
2022-10-07 20:03:39 - train: epoch 0042, iter [00190, 01251], lr: 0.001367, loss: 3.1143
2022-10-07 20:04:00 - train: epoch 0042, iter [00200, 01251], lr: 0.001367, loss: 3.1710
2022-10-07 20:04:21 - train: epoch 0042, iter [00210, 01251], lr: 0.001366, loss: 3.0536
2022-10-07 20:04:42 - train: epoch 0042, iter [00220, 01251], lr: 0.001366, loss: 2.7555
2022-10-07 20:05:04 - train: epoch 0042, iter [00230, 01251], lr: 0.001366, loss: 3.1414
2022-10-07 20:05:25 - train: epoch 0042, iter [00240, 01251], lr: 0.001366, loss: 2.9271
2022-10-07 20:05:46 - train: epoch 0042, iter [00250, 01251], lr: 0.001365, loss: 3.3957
2022-10-07 20:06:07 - train: epoch 0042, iter [00260, 01251], lr: 0.001365, loss: 2.6812
2022-10-07 20:06:28 - train: epoch 0042, iter [00270, 01251], lr: 0.001365, loss: 3.6860
2022-10-07 20:06:49 - train: epoch 0042, iter [00280, 01251], lr: 0.001365, loss: 3.6335
2022-10-07 20:07:10 - train: epoch 0042, iter [00290, 01251], lr: 0.001364, loss: 3.2084
2022-10-07 20:07:31 - train: epoch 0042, iter [00300, 01251], lr: 0.001364, loss: 2.9280
2022-10-07 20:07:52 - train: epoch 0042, iter [00310, 01251], lr: 0.001364, loss: 3.1039
2022-10-07 20:08:14 - train: epoch 0042, iter [00320, 01251], lr: 0.001364, loss: 2.7147
2022-10-07 20:08:35 - train: epoch 0042, iter [00330, 01251], lr: 0.001363, loss: 2.8944
2022-10-07 20:08:56 - train: epoch 0042, iter [00340, 01251], lr: 0.001363, loss: 3.4476
2022-10-07 20:09:17 - train: epoch 0042, iter [00350, 01251], lr: 0.001363, loss: 2.5016
2022-10-07 20:09:38 - train: epoch 0042, iter [00360, 01251], lr: 0.001363, loss: 3.2480
2022-10-07 20:09:59 - train: epoch 0042, iter [00370, 01251], lr: 0.001362, loss: 3.1736
2022-10-07 20:10:20 - train: epoch 0042, iter [00380, 01251], lr: 0.001362, loss: 2.9466
2022-10-07 20:10:41 - train: epoch 0042, iter [00390, 01251], lr: 0.001362, loss: 3.1645
2022-10-07 20:11:02 - train: epoch 0042, iter [00400, 01251], lr: 0.001362, loss: 2.8136
2022-10-07 20:11:23 - train: epoch 0042, iter [00410, 01251], lr: 0.001361, loss: 3.3903
2022-10-07 20:11:45 - train: epoch 0042, iter [00420, 01251], lr: 0.001361, loss: 3.1801
2022-10-07 20:12:06 - train: epoch 0042, iter [00430, 01251], lr: 0.001361, loss: 3.3880
2022-10-07 20:12:27 - train: epoch 0042, iter [00440, 01251], lr: 0.001361, loss: 3.5627
2022-10-07 20:12:48 - train: epoch 0042, iter [00450, 01251], lr: 0.001360, loss: 3.1470
2022-10-07 20:13:09 - train: epoch 0042, iter [00460, 01251], lr: 0.001360, loss: 3.4840
2022-10-07 20:13:30 - train: epoch 0042, iter [00470, 01251], lr: 0.001360, loss: 3.6610
2022-10-07 20:13:51 - train: epoch 0042, iter [00480, 01251], lr: 0.001360, loss: 2.8028
2022-10-07 20:14:12 - train: epoch 0042, iter [00490, 01251], lr: 0.001359, loss: 3.2821
2022-10-07 20:14:33 - train: epoch 0042, iter [00500, 01251], lr: 0.001359, loss: 3.6111
2022-10-07 20:14:54 - train: epoch 0042, iter [00510, 01251], lr: 0.001359, loss: 2.8259
2022-10-07 20:15:15 - train: epoch 0042, iter [00520, 01251], lr: 0.001359, loss: 3.6762
2022-10-07 20:15:36 - train: epoch 0042, iter [00530, 01251], lr: 0.001358, loss: 3.6928
2022-10-07 20:15:57 - train: epoch 0042, iter [00540, 01251], lr: 0.001358, loss: 3.4727
2022-10-07 20:16:18 - train: epoch 0042, iter [00550, 01251], lr: 0.001358, loss: 3.3162
2022-10-07 20:16:39 - train: epoch 0042, iter [00560, 01251], lr: 0.001358, loss: 2.2754
2022-10-07 20:17:00 - train: epoch 0042, iter [00570, 01251], lr: 0.001357, loss: 3.5967
2022-10-07 20:17:21 - train: epoch 0042, iter [00580, 01251], lr: 0.001357, loss: 3.1253
2022-10-07 20:17:42 - train: epoch 0042, iter [00590, 01251], lr: 0.001357, loss: 3.4394
2022-10-07 20:18:03 - train: epoch 0042, iter [00600, 01251], lr: 0.001357, loss: 2.8908
2022-10-07 20:18:25 - train: epoch 0042, iter [00610, 01251], lr: 0.001356, loss: 3.3740
2022-10-07 20:18:46 - train: epoch 0042, iter [00620, 01251], lr: 0.001356, loss: 3.5718
2022-10-07 20:19:07 - train: epoch 0042, iter [00630, 01251], lr: 0.001356, loss: 3.2265
2022-10-07 20:19:28 - train: epoch 0042, iter [00640, 01251], lr: 0.001356, loss: 3.2642
2022-10-07 20:19:49 - train: epoch 0042, iter [00650, 01251], lr: 0.001356, loss: 3.3668
2022-10-07 20:20:10 - train: epoch 0042, iter [00660, 01251], lr: 0.001355, loss: 2.8516
2022-10-07 20:20:31 - train: epoch 0042, iter [00670, 01251], lr: 0.001355, loss: 2.8054
2022-10-07 20:20:52 - train: epoch 0042, iter [00680, 01251], lr: 0.001355, loss: 3.1528
2022-10-07 20:21:13 - train: epoch 0042, iter [00690, 01251], lr: 0.001355, loss: 3.5596
2022-10-07 20:21:34 - train: epoch 0042, iter [00700, 01251], lr: 0.001354, loss: 3.7250
2022-10-07 20:21:55 - train: epoch 0042, iter [00710, 01251], lr: 0.001354, loss: 3.1183
2022-10-07 20:22:16 - train: epoch 0042, iter [00720, 01251], lr: 0.001354, loss: 3.4839
2022-10-07 20:22:37 - train: epoch 0042, iter [00730, 01251], lr: 0.001354, loss: 3.8026
2022-10-07 20:22:59 - train: epoch 0042, iter [00740, 01251], lr: 0.001353, loss: 2.8266
2022-10-07 20:23:20 - train: epoch 0042, iter [00750, 01251], lr: 0.001353, loss: 3.0300
2022-10-07 20:23:41 - train: epoch 0042, iter [00760, 01251], lr: 0.001353, loss: 3.5414
2022-10-07 20:24:02 - train: epoch 0042, iter [00770, 01251], lr: 0.001353, loss: 3.2137
2022-10-07 20:24:23 - train: epoch 0042, iter [00780, 01251], lr: 0.001352, loss: 3.7904
2022-10-07 20:24:44 - train: epoch 0042, iter [00790, 01251], lr: 0.001352, loss: 3.4906
2022-10-07 20:25:06 - train: epoch 0042, iter [00800, 01251], lr: 0.001352, loss: 2.8563
2022-10-07 20:25:27 - train: epoch 0042, iter [00810, 01251], lr: 0.001352, loss: 3.5099
2022-10-07 20:25:48 - train: epoch 0042, iter [00820, 01251], lr: 0.001351, loss: 3.1558
2022-10-07 20:26:09 - train: epoch 0042, iter [00830, 01251], lr: 0.001351, loss: 3.5170
2022-10-07 20:26:30 - train: epoch 0042, iter [00840, 01251], lr: 0.001351, loss: 3.5150
2022-10-07 20:26:51 - train: epoch 0042, iter [00850, 01251], lr: 0.001351, loss: 3.3834
2022-10-07 20:27:12 - train: epoch 0042, iter [00860, 01251], lr: 0.001350, loss: 3.0691
2022-10-07 20:27:33 - train: epoch 0042, iter [00870, 01251], lr: 0.001350, loss: 3.3772
2022-10-07 20:27:55 - train: epoch 0042, iter [00880, 01251], lr: 0.001350, loss: 3.4749
2022-10-07 20:28:16 - train: epoch 0042, iter [00890, 01251], lr: 0.001350, loss: 2.8880
2022-10-07 20:28:37 - train: epoch 0042, iter [00900, 01251], lr: 0.001349, loss: 2.8437
2022-10-07 20:28:58 - train: epoch 0042, iter [00910, 01251], lr: 0.001349, loss: 3.4833
2022-10-07 20:29:19 - train: epoch 0042, iter [00920, 01251], lr: 0.001349, loss: 3.1480
2022-10-07 20:29:40 - train: epoch 0042, iter [00930, 01251], lr: 0.001349, loss: 2.9444
2022-10-07 20:30:01 - train: epoch 0042, iter [00940, 01251], lr: 0.001348, loss: 2.6904
2022-10-07 20:30:23 - train: epoch 0042, iter [00950, 01251], lr: 0.001348, loss: 3.0434
2022-10-07 20:30:44 - train: epoch 0042, iter [00960, 01251], lr: 0.001348, loss: 2.6013
2022-10-07 20:31:05 - train: epoch 0042, iter [00970, 01251], lr: 0.001348, loss: 3.1323
2022-10-07 20:31:26 - train: epoch 0042, iter [00980, 01251], lr: 0.001347, loss: 3.3877
2022-10-07 20:31:48 - train: epoch 0042, iter [00990, 01251], lr: 0.001347, loss: 3.2137
2022-10-07 20:32:09 - train: epoch 0042, iter [01000, 01251], lr: 0.001347, loss: 2.5448
2022-10-07 20:32:30 - train: epoch 0042, iter [01010, 01251], lr: 0.001347, loss: 3.0605
2022-10-07 20:32:51 - train: epoch 0042, iter [01020, 01251], lr: 0.001346, loss: 2.9679
2022-10-07 20:33:12 - train: epoch 0042, iter [01030, 01251], lr: 0.001346, loss: 3.3421
2022-10-07 20:33:34 - train: epoch 0042, iter [01040, 01251], lr: 0.001346, loss: 3.6275
2022-10-07 20:33:55 - train: epoch 0042, iter [01050, 01251], lr: 0.001346, loss: 3.6379
2022-10-07 20:34:16 - train: epoch 0042, iter [01060, 01251], lr: 0.001345, loss: 3.5719
2022-10-07 20:34:37 - train: epoch 0042, iter [01070, 01251], lr: 0.001345, loss: 3.1558
2022-10-07 20:34:59 - train: epoch 0042, iter [01080, 01251], lr: 0.001345, loss: 2.9728
2022-10-07 20:35:20 - train: epoch 0042, iter [01090, 01251], lr: 0.001345, loss: 3.5539
2022-10-07 20:35:41 - train: epoch 0042, iter [01100, 01251], lr: 0.001344, loss: 3.1382
2022-10-07 20:36:02 - train: epoch 0042, iter [01110, 01251], lr: 0.001344, loss: 3.1504
2022-10-07 20:36:23 - train: epoch 0042, iter [01120, 01251], lr: 0.001344, loss: 2.7626
2022-10-07 20:36:45 - train: epoch 0042, iter [01130, 01251], lr: 0.001344, loss: 2.9464
2022-10-07 20:37:06 - train: epoch 0042, iter [01140, 01251], lr: 0.001343, loss: 3.3843
2022-10-07 20:37:27 - train: epoch 0042, iter [01150, 01251], lr: 0.001343, loss: 3.7669
2022-10-07 20:37:48 - train: epoch 0042, iter [01160, 01251], lr: 0.001343, loss: 3.5039
2022-10-07 20:38:10 - train: epoch 0042, iter [01170, 01251], lr: 0.001343, loss: 3.5487
2022-10-07 20:38:31 - train: epoch 0042, iter [01180, 01251], lr: 0.001342, loss: 3.3910
2022-10-07 20:38:52 - train: epoch 0042, iter [01190, 01251], lr: 0.001342, loss: 2.7718
2022-10-07 20:39:13 - train: epoch 0042, iter [01200, 01251], lr: 0.001342, loss: 2.6726
2022-10-07 20:39:35 - train: epoch 0042, iter [01210, 01251], lr: 0.001342, loss: 3.4721
2022-10-07 20:39:56 - train: epoch 0042, iter [01220, 01251], lr: 0.001341, loss: 2.9593
2022-10-07 20:40:17 - train: epoch 0042, iter [01230, 01251], lr: 0.001341, loss: 2.3421
2022-10-07 20:40:38 - train: epoch 0042, iter [01240, 01251], lr: 0.001341, loss: 3.5649
2022-10-07 20:40:59 - train: epoch 0042, iter [01250, 01251], lr: 0.001341, loss: 3.5264
2022-10-07 20:41:03 - train: epoch 042, train_loss: 3.2053
2022-10-07 20:42:20 - eval: epoch: 042, acc1: 79.716%, acc5: 95.298%, test_loss: 0.8979, per_image_load_time: 0.329ms, per_image_inference_time: 1.420ms
2022-10-07 20:42:21 - until epoch: 042, best_acc1: 79.860%
2022-10-07 20:42:21 - epoch 043 lr: 0.001341
2022-10-07 20:42:49 - train: epoch 0043, iter [00010, 01251], lr: 0.001340, loss: 3.2714
2022-10-07 20:43:10 - train: epoch 0043, iter [00020, 01251], lr: 0.001340, loss: 2.5942
2022-10-07 20:43:31 - train: epoch 0043, iter [00030, 01251], lr: 0.001340, loss: 3.5067
2022-10-07 20:43:52 - train: epoch 0043, iter [00040, 01251], lr: 0.001340, loss: 3.5326
2022-10-07 20:44:13 - train: epoch 0043, iter [00050, 01251], lr: 0.001339, loss: 2.9592
2022-10-07 20:44:35 - train: epoch 0043, iter [00060, 01251], lr: 0.001339, loss: 3.3591
2022-10-07 20:44:56 - train: epoch 0043, iter [00070, 01251], lr: 0.001339, loss: 3.3114
2022-10-07 20:45:17 - train: epoch 0043, iter [00080, 01251], lr: 0.001339, loss: 3.3954
2022-10-07 20:45:38 - train: epoch 0043, iter [00090, 01251], lr: 0.001338, loss: 3.3050
2022-10-07 20:45:59 - train: epoch 0043, iter [00100, 01251], lr: 0.001338, loss: 2.7733
2022-10-07 20:46:21 - train: epoch 0043, iter [00110, 01251], lr: 0.001338, loss: 2.8925
2022-10-07 20:46:42 - train: epoch 0043, iter [00120, 01251], lr: 0.001338, loss: 2.9367
2022-10-07 20:47:03 - train: epoch 0043, iter [00130, 01251], lr: 0.001337, loss: 2.6191
2022-10-07 20:47:24 - train: epoch 0043, iter [00140, 01251], lr: 0.001337, loss: 2.9531
2022-10-07 20:47:45 - train: epoch 0043, iter [00150, 01251], lr: 0.001337, loss: 3.2117
2022-10-07 20:48:07 - train: epoch 0043, iter [00160, 01251], lr: 0.001337, loss: 2.9173
2022-10-07 20:48:28 - train: epoch 0043, iter [00170, 01251], lr: 0.001336, loss: 3.3735
2022-10-07 20:48:49 - train: epoch 0043, iter [00180, 01251], lr: 0.001336, loss: 2.9381
2022-10-07 20:49:10 - train: epoch 0043, iter [00190, 01251], lr: 0.001336, loss: 2.8154
2022-10-07 20:49:32 - train: epoch 0043, iter [00200, 01251], lr: 0.001336, loss: 3.4488
2022-10-07 20:49:53 - train: epoch 0043, iter [00210, 01251], lr: 0.001335, loss: 2.6427
2022-10-07 20:50:14 - train: epoch 0043, iter [00220, 01251], lr: 0.001335, loss: 3.5052
2022-10-07 20:50:35 - train: epoch 0043, iter [00230, 01251], lr: 0.001335, loss: 2.9796
2022-10-07 20:50:56 - train: epoch 0043, iter [00240, 01251], lr: 0.001335, loss: 3.0219
2022-10-07 20:51:18 - train: epoch 0043, iter [00250, 01251], lr: 0.001334, loss: 3.5545
2022-10-07 20:51:39 - train: epoch 0043, iter [00260, 01251], lr: 0.001334, loss: 2.4511
2022-10-07 20:52:00 - train: epoch 0043, iter [00270, 01251], lr: 0.001334, loss: 3.0402
2022-10-07 20:52:21 - train: epoch 0043, iter [00280, 01251], lr: 0.001334, loss: 2.6804
2022-10-07 20:52:42 - train: epoch 0043, iter [00290, 01251], lr: 0.001333, loss: 3.6628
2022-10-07 20:53:04 - train: epoch 0043, iter [00300, 01251], lr: 0.001333, loss: 2.8116
2022-10-07 20:53:25 - train: epoch 0043, iter [00310, 01251], lr: 0.001333, loss: 2.9131
2022-10-07 20:53:46 - train: epoch 0043, iter [00320, 01251], lr: 0.001333, loss: 3.2695
2022-10-07 20:54:08 - train: epoch 0043, iter [00330, 01251], lr: 0.001332, loss: 3.5075
2022-10-07 20:54:29 - train: epoch 0043, iter [00340, 01251], lr: 0.001332, loss: 3.1263
2022-10-07 20:54:50 - train: epoch 0043, iter [00350, 01251], lr: 0.001332, loss: 3.3197
2022-10-07 20:55:11 - train: epoch 0043, iter [00360, 01251], lr: 0.001332, loss: 2.9053
2022-10-07 20:55:33 - train: epoch 0043, iter [00370, 01251], lr: 0.001331, loss: 2.8920
2022-10-07 20:55:54 - train: epoch 0043, iter [00380, 01251], lr: 0.001331, loss: 3.1087
2022-10-07 20:56:15 - train: epoch 0043, iter [00390, 01251], lr: 0.001331, loss: 3.2637
2022-10-07 20:56:36 - train: epoch 0043, iter [00400, 01251], lr: 0.001331, loss: 3.2846
2022-10-07 20:56:58 - train: epoch 0043, iter [00410, 01251], lr: 0.001330, loss: 3.5133
2022-10-07 20:57:19 - train: epoch 0043, iter [00420, 01251], lr: 0.001330, loss: 3.0041
2022-10-07 20:57:40 - train: epoch 0043, iter [00430, 01251], lr: 0.001330, loss: 2.9449
2022-10-07 20:58:01 - train: epoch 0043, iter [00440, 01251], lr: 0.001330, loss: 2.5114
2022-10-07 20:58:22 - train: epoch 0043, iter [00450, 01251], lr: 0.001329, loss: 3.6237
2022-10-07 20:58:43 - train: epoch 0043, iter [00460, 01251], lr: 0.001329, loss: 2.8446
2022-10-07 20:59:04 - train: epoch 0043, iter [00470, 01251], lr: 0.001329, loss: 3.3960
2022-10-07 20:59:26 - train: epoch 0043, iter [00480, 01251], lr: 0.001329, loss: 3.5282
2022-10-07 20:59:47 - train: epoch 0043, iter [00490, 01251], lr: 0.001328, loss: 3.3670
2022-10-07 21:00:08 - train: epoch 0043, iter [00500, 01251], lr: 0.001328, loss: 2.6348
2022-10-07 21:00:29 - train: epoch 0043, iter [00510, 01251], lr: 0.001328, loss: 2.9299
2022-10-07 21:00:50 - train: epoch 0043, iter [00520, 01251], lr: 0.001328, loss: 3.7126
2022-10-07 21:01:12 - train: epoch 0043, iter [00530, 01251], lr: 0.001327, loss: 3.2431
2022-10-07 21:01:33 - train: epoch 0043, iter [00540, 01251], lr: 0.001327, loss: 3.3684
2022-10-07 21:01:54 - train: epoch 0043, iter [00550, 01251], lr: 0.001327, loss: 3.4553
2022-10-07 21:02:15 - train: epoch 0043, iter [00560, 01251], lr: 0.001327, loss: 3.3256
2022-10-07 21:02:36 - train: epoch 0043, iter [00570, 01251], lr: 0.001326, loss: 3.2660
2022-10-07 21:02:57 - train: epoch 0043, iter [00580, 01251], lr: 0.001326, loss: 2.9119
2022-10-07 21:03:19 - train: epoch 0043, iter [00590, 01251], lr: 0.001326, loss: 3.2276
2022-10-07 21:03:40 - train: epoch 0043, iter [00600, 01251], lr: 0.001326, loss: 3.0294
2022-10-07 21:04:01 - train: epoch 0043, iter [00610, 01251], lr: 0.001325, loss: 3.2743
2022-10-07 21:04:22 - train: epoch 0043, iter [00620, 01251], lr: 0.001325, loss: 3.8108
2022-10-07 21:04:43 - train: epoch 0043, iter [00630, 01251], lr: 0.001325, loss: 2.7207
2022-10-07 21:05:05 - train: epoch 0043, iter [00640, 01251], lr: 0.001325, loss: 2.5876
2022-10-07 21:05:26 - train: epoch 0043, iter [00650, 01251], lr: 0.001324, loss: 2.7682
2022-10-07 21:05:47 - train: epoch 0043, iter [00660, 01251], lr: 0.001324, loss: 3.0834
2022-10-07 21:06:08 - train: epoch 0043, iter [00670, 01251], lr: 0.001324, loss: 3.3493
2022-10-07 21:06:29 - train: epoch 0043, iter [00680, 01251], lr: 0.001324, loss: 3.1562
2022-10-07 21:06:51 - train: epoch 0043, iter [00690, 01251], lr: 0.001323, loss: 3.4501
2022-10-07 21:07:12 - train: epoch 0043, iter [00700, 01251], lr: 0.001323, loss: 2.5992
2022-10-07 21:07:33 - train: epoch 0043, iter [00710, 01251], lr: 0.001323, loss: 3.4321
2022-10-07 21:07:54 - train: epoch 0043, iter [00720, 01251], lr: 0.001323, loss: 3.3719
2022-10-07 21:08:15 - train: epoch 0043, iter [00730, 01251], lr: 0.001322, loss: 3.6277
2022-10-07 21:08:36 - train: epoch 0043, iter [00740, 01251], lr: 0.001322, loss: 3.2273
2022-10-07 21:08:57 - train: epoch 0043, iter [00750, 01251], lr: 0.001322, loss: 3.0856
2022-10-07 21:09:19 - train: epoch 0043, iter [00760, 01251], lr: 0.001322, loss: 2.9697
2022-10-07 21:09:40 - train: epoch 0043, iter [00770, 01251], lr: 0.001321, loss: 3.5475
2022-10-07 21:10:01 - train: epoch 0043, iter [00780, 01251], lr: 0.001321, loss: 3.3672
2022-10-07 21:10:22 - train: epoch 0043, iter [00790, 01251], lr: 0.001321, loss: 2.8307
2022-10-07 21:10:43 - train: epoch 0043, iter [00800, 01251], lr: 0.001321, loss: 3.6787
2022-10-07 21:11:04 - train: epoch 0043, iter [00810, 01251], lr: 0.001320, loss: 2.9435
2022-10-07 21:11:25 - train: epoch 0043, iter [00820, 01251], lr: 0.001320, loss: 2.8471
2022-10-07 21:11:46 - train: epoch 0043, iter [00830, 01251], lr: 0.001320, loss: 2.9025
2022-10-07 21:12:07 - train: epoch 0043, iter [00840, 01251], lr: 0.001320, loss: 3.4110
2022-10-07 21:12:29 - train: epoch 0043, iter [00850, 01251], lr: 0.001319, loss: 3.1288
2022-10-07 21:12:50 - train: epoch 0043, iter [00860, 01251], lr: 0.001319, loss: 3.5713
2022-10-07 21:13:11 - train: epoch 0043, iter [00870, 01251], lr: 0.001319, loss: 3.6391
2022-10-07 21:13:32 - train: epoch 0043, iter [00880, 01251], lr: 0.001319, loss: 2.9001
2022-10-07 21:13:53 - train: epoch 0043, iter [00890, 01251], lr: 0.001318, loss: 3.1899
2022-10-07 21:14:15 - train: epoch 0043, iter [00900, 01251], lr: 0.001318, loss: 3.6814
2022-10-07 21:14:36 - train: epoch 0043, iter [00910, 01251], lr: 0.001318, loss: 3.0398
2022-10-07 21:14:57 - train: epoch 0043, iter [00920, 01251], lr: 0.001318, loss: 3.6952
2022-10-07 21:15:18 - train: epoch 0043, iter [00930, 01251], lr: 0.001317, loss: 2.9768
2022-10-07 21:15:39 - train: epoch 0043, iter [00940, 01251], lr: 0.001317, loss: 3.0555
2022-10-07 21:16:00 - train: epoch 0043, iter [00950, 01251], lr: 0.001317, loss: 3.2339
2022-10-07 21:16:21 - train: epoch 0043, iter [00960, 01251], lr: 0.001317, loss: 3.2530
2022-10-07 21:16:42 - train: epoch 0043, iter [00970, 01251], lr: 0.001316, loss: 3.2079
2022-10-07 21:17:03 - train: epoch 0043, iter [00980, 01251], lr: 0.001316, loss: 3.3522
2022-10-07 21:17:25 - train: epoch 0043, iter [00990, 01251], lr: 0.001316, loss: 3.2806
2022-10-07 21:17:46 - train: epoch 0043, iter [01000, 01251], lr: 0.001316, loss: 3.1324
2022-10-07 21:18:07 - train: epoch 0043, iter [01010, 01251], lr: 0.001315, loss: 3.4467
2022-10-07 21:18:28 - train: epoch 0043, iter [01020, 01251], lr: 0.001315, loss: 3.0889
2022-10-07 21:18:49 - train: epoch 0043, iter [01030, 01251], lr: 0.001315, loss: 3.3126
2022-10-07 21:19:10 - train: epoch 0043, iter [01040, 01251], lr: 0.001315, loss: 3.3517
2022-10-07 21:19:32 - train: epoch 0043, iter [01050, 01251], lr: 0.001314, loss: 3.3127
2022-10-07 21:19:53 - train: epoch 0043, iter [01060, 01251], lr: 0.001314, loss: 3.6656
2022-10-07 21:20:14 - train: epoch 0043, iter [01070, 01251], lr: 0.001314, loss: 3.0189
2022-10-07 21:20:35 - train: epoch 0043, iter [01080, 01251], lr: 0.001314, loss: 2.8582
2022-10-07 21:20:56 - train: epoch 0043, iter [01090, 01251], lr: 0.001313, loss: 3.6230
2022-10-07 21:21:17 - train: epoch 0043, iter [01100, 01251], lr: 0.001313, loss: 3.5274
2022-10-07 21:21:38 - train: epoch 0043, iter [01110, 01251], lr: 0.001313, loss: 3.1497
2022-10-07 21:22:00 - train: epoch 0043, iter [01120, 01251], lr: 0.001313, loss: 3.6482
2022-10-07 21:22:21 - train: epoch 0043, iter [01130, 01251], lr: 0.001312, loss: 3.5519
2022-10-07 21:22:42 - train: epoch 0043, iter [01140, 01251], lr: 0.001312, loss: 2.7036
2022-10-07 21:23:03 - train: epoch 0043, iter [01150, 01251], lr: 0.001312, loss: 3.0957
2022-10-07 21:23:24 - train: epoch 0043, iter [01160, 01251], lr: 0.001312, loss: 3.3271
2022-10-07 21:23:45 - train: epoch 0043, iter [01170, 01251], lr: 0.001311, loss: 2.6144
2022-10-07 21:24:07 - train: epoch 0043, iter [01180, 01251], lr: 0.001311, loss: 2.3045
2022-10-07 21:24:28 - train: epoch 0043, iter [01190, 01251], lr: 0.001311, loss: 2.5705
2022-10-07 21:24:49 - train: epoch 0043, iter [01200, 01251], lr: 0.001311, loss: 3.1331
2022-10-07 21:25:10 - train: epoch 0043, iter [01210, 01251], lr: 0.001310, loss: 3.2737
2022-10-07 21:25:31 - train: epoch 0043, iter [01220, 01251], lr: 0.001310, loss: 3.4096
2022-10-07 21:25:52 - train: epoch 0043, iter [01230, 01251], lr: 0.001310, loss: 3.2112
2022-10-07 21:26:13 - train: epoch 0043, iter [01240, 01251], lr: 0.001310, loss: 3.4880
2022-10-07 21:26:35 - train: epoch 0043, iter [01250, 01251], lr: 0.001309, loss: 3.3096
2022-10-07 21:26:38 - train: epoch 043, train_loss: 3.1883
2022-10-07 21:27:54 - eval: epoch: 043, acc1: 79.830%, acc5: 95.324%, test_loss: 0.8630, per_image_load_time: 1.111ms, per_image_inference_time: 1.462ms
2022-10-07 21:27:55 - until epoch: 043, best_acc1: 79.860%
2022-10-07 21:27:55 - epoch 044 lr: 0.001309
2022-10-07 21:28:22 - train: epoch 0044, iter [00010, 01251], lr: 0.001309, loss: 3.4758
2022-10-07 21:28:43 - train: epoch 0044, iter [00020, 01251], lr: 0.001309, loss: 3.2045
2022-10-07 21:29:05 - train: epoch 0044, iter [00030, 01251], lr: 0.001309, loss: 2.9416
2022-10-07 21:29:26 - train: epoch 0044, iter [00040, 01251], lr: 0.001308, loss: 3.1369
2022-10-07 21:29:47 - train: epoch 0044, iter [00050, 01251], lr: 0.001308, loss: 2.6751
2022-10-07 21:30:08 - train: epoch 0044, iter [00060, 01251], lr: 0.001308, loss: 3.1058
2022-10-07 21:30:30 - train: epoch 0044, iter [00070, 01251], lr: 0.001308, loss: 3.1167
2022-10-07 21:30:51 - train: epoch 0044, iter [00080, 01251], lr: 0.001307, loss: 3.0847
2022-10-07 21:31:12 - train: epoch 0044, iter [00090, 01251], lr: 0.001307, loss: 2.0881
2022-10-07 21:31:33 - train: epoch 0044, iter [00100, 01251], lr: 0.001307, loss: 3.3334
2022-10-07 21:31:54 - train: epoch 0044, iter [00110, 01251], lr: 0.001307, loss: 3.2938
2022-10-07 21:32:16 - train: epoch 0044, iter [00120, 01251], lr: 0.001306, loss: 3.6386
2022-10-07 21:32:37 - train: epoch 0044, iter [00130, 01251], lr: 0.001306, loss: 2.9835
2022-10-07 21:32:58 - train: epoch 0044, iter [00140, 01251], lr: 0.001306, loss: 3.6642
2022-10-07 21:33:19 - train: epoch 0044, iter [00150, 01251], lr: 0.001306, loss: 3.4226
2022-10-07 21:33:41 - train: epoch 0044, iter [00160, 01251], lr: 0.001305, loss: 3.7742
2022-10-07 21:34:02 - train: epoch 0044, iter [00170, 01251], lr: 0.001305, loss: 3.3879
2022-10-07 21:34:23 - train: epoch 0044, iter [00180, 01251], lr: 0.001305, loss: 3.5573
2022-10-07 21:34:44 - train: epoch 0044, iter [00190, 01251], lr: 0.001305, loss: 3.3370
2022-10-07 21:35:05 - train: epoch 0044, iter [00200, 01251], lr: 0.001304, loss: 3.5080
2022-10-07 21:35:26 - train: epoch 0044, iter [00210, 01251], lr: 0.001304, loss: 3.6783
2022-10-07 21:35:48 - train: epoch 0044, iter [00220, 01251], lr: 0.001304, loss: 3.2609
2022-10-07 21:36:09 - train: epoch 0044, iter [00230, 01251], lr: 0.001304, loss: 3.1371
2022-10-07 21:36:30 - train: epoch 0044, iter [00240, 01251], lr: 0.001303, loss: 3.2435
2022-10-07 21:36:51 - train: epoch 0044, iter [00250, 01251], lr: 0.001303, loss: 3.1465
2022-10-07 21:37:12 - train: epoch 0044, iter [00260, 01251], lr: 0.001303, loss: 3.2708
2022-10-07 21:37:34 - train: epoch 0044, iter [00270, 01251], lr: 0.001303, loss: 3.7712
2022-10-07 21:37:55 - train: epoch 0044, iter [00280, 01251], lr: 0.001302, loss: 3.4772
2022-10-07 21:38:16 - train: epoch 0044, iter [00290, 01251], lr: 0.001302, loss: 3.3799
2022-10-07 21:38:37 - train: epoch 0044, iter [00300, 01251], lr: 0.001302, loss: 3.5165
2022-10-07 21:38:58 - train: epoch 0044, iter [00310, 01251], lr: 0.001302, loss: 3.4492
2022-10-07 21:39:19 - train: epoch 0044, iter [00320, 01251], lr: 0.001301, loss: 2.6189
2022-10-07 21:39:41 - train: epoch 0044, iter [00330, 01251], lr: 0.001301, loss: 2.7649
2022-10-07 21:40:02 - train: epoch 0044, iter [00340, 01251], lr: 0.001301, loss: 3.2953
2022-10-07 21:40:23 - train: epoch 0044, iter [00350, 01251], lr: 0.001301, loss: 3.3308
2022-10-07 21:40:44 - train: epoch 0044, iter [00360, 01251], lr: 0.001300, loss: 3.1733
2022-10-07 21:41:05 - train: epoch 0044, iter [00370, 01251], lr: 0.001300, loss: 3.5802
2022-10-07 21:41:26 - train: epoch 0044, iter [00380, 01251], lr: 0.001300, loss: 3.0160
2022-10-07 21:41:48 - train: epoch 0044, iter [00390, 01251], lr: 0.001300, loss: 3.1977
2022-10-07 21:42:09 - train: epoch 0044, iter [00400, 01251], lr: 0.001299, loss: 3.5017
2022-10-07 21:42:30 - train: epoch 0044, iter [00410, 01251], lr: 0.001299, loss: 3.4021
2022-10-07 21:42:51 - train: epoch 0044, iter [00420, 01251], lr: 0.001299, loss: 2.7083
2022-10-07 21:43:12 - train: epoch 0044, iter [00430, 01251], lr: 0.001299, loss: 2.9426
2022-10-07 21:43:34 - train: epoch 0044, iter [00440, 01251], lr: 0.001298, loss: 3.4175
2022-10-07 21:43:55 - train: epoch 0044, iter [00450, 01251], lr: 0.001298, loss: 3.5523
2022-10-07 21:44:16 - train: epoch 0044, iter [00460, 01251], lr: 0.001298, loss: 2.2361
2022-10-07 21:44:37 - train: epoch 0044, iter [00470, 01251], lr: 0.001298, loss: 3.1662
2022-10-07 21:44:58 - train: epoch 0044, iter [00480, 01251], lr: 0.001297, loss: 2.9573
2022-10-07 21:45:20 - train: epoch 0044, iter [00490, 01251], lr: 0.001297, loss: 3.2513
2022-10-07 21:45:41 - train: epoch 0044, iter [00500, 01251], lr: 0.001297, loss: 2.7212
2022-10-07 21:46:02 - train: epoch 0044, iter [00510, 01251], lr: 0.001297, loss: 3.2508
2022-10-07 21:46:23 - train: epoch 0044, iter [00520, 01251], lr: 0.001296, loss: 3.6453
2022-10-07 21:46:44 - train: epoch 0044, iter [00530, 01251], lr: 0.001296, loss: 3.1423
2022-10-07 21:47:06 - train: epoch 0044, iter [00540, 01251], lr: 0.001296, loss: 3.0566
2022-10-07 21:47:27 - train: epoch 0044, iter [00550, 01251], lr: 0.001296, loss: 3.3969
2022-10-07 21:47:48 - train: epoch 0044, iter [00560, 01251], lr: 0.001295, loss: 2.9922
2022-10-07 21:48:09 - train: epoch 0044, iter [00570, 01251], lr: 0.001295, loss: 3.5983
2022-10-07 21:48:31 - train: epoch 0044, iter [00580, 01251], lr: 0.001295, loss: 3.2436
2022-10-07 21:48:52 - train: epoch 0044, iter [00590, 01251], lr: 0.001294, loss: 3.4555
2022-10-07 21:49:13 - train: epoch 0044, iter [00600, 01251], lr: 0.001294, loss: 2.8349
2022-10-07 21:49:34 - train: epoch 0044, iter [00610, 01251], lr: 0.001294, loss: 3.2941
2022-10-07 21:49:56 - train: epoch 0044, iter [00620, 01251], lr: 0.001294, loss: 3.1623
2022-10-07 21:50:17 - train: epoch 0044, iter [00630, 01251], lr: 0.001293, loss: 2.8759
2022-10-07 21:50:38 - train: epoch 0044, iter [00640, 01251], lr: 0.001293, loss: 2.9645
2022-10-07 21:50:59 - train: epoch 0044, iter [00650, 01251], lr: 0.001293, loss: 3.0361
2022-10-07 21:51:20 - train: epoch 0044, iter [00660, 01251], lr: 0.001293, loss: 3.2664
2022-10-07 21:51:42 - train: epoch 0044, iter [00670, 01251], lr: 0.001292, loss: 2.6464
2022-10-07 21:52:03 - train: epoch 0044, iter [00680, 01251], lr: 0.001292, loss: 2.5524
2022-10-07 21:52:24 - train: epoch 0044, iter [00690, 01251], lr: 0.001292, loss: 3.3360
2022-10-07 21:52:45 - train: epoch 0044, iter [00700, 01251], lr: 0.001292, loss: 3.2760
2022-10-07 21:53:06 - train: epoch 0044, iter [00710, 01251], lr: 0.001291, loss: 3.5389
2022-10-07 21:53:28 - train: epoch 0044, iter [00720, 01251], lr: 0.001291, loss: 3.2898
2022-10-07 21:53:49 - train: epoch 0044, iter [00730, 01251], lr: 0.001291, loss: 3.2853
2022-10-07 21:54:10 - train: epoch 0044, iter [00740, 01251], lr: 0.001291, loss: 3.8413
2022-10-07 21:54:31 - train: epoch 0044, iter [00750, 01251], lr: 0.001290, loss: 3.3998
2022-10-07 21:54:52 - train: epoch 0044, iter [00760, 01251], lr: 0.001290, loss: 3.6304
2022-10-07 21:55:14 - train: epoch 0044, iter [00770, 01251], lr: 0.001290, loss: 3.2898
2022-10-07 21:55:35 - train: epoch 0044, iter [00780, 01251], lr: 0.001290, loss: 3.3779
2022-10-07 21:55:56 - train: epoch 0044, iter [00790, 01251], lr: 0.001289, loss: 3.3164
2022-10-07 21:56:17 - train: epoch 0044, iter [00800, 01251], lr: 0.001289, loss: 3.5734
2022-10-07 21:56:39 - train: epoch 0044, iter [00810, 01251], lr: 0.001289, loss: 3.1121
2022-10-07 21:57:00 - train: epoch 0044, iter [00820, 01251], lr: 0.001289, loss: 3.5573
2022-10-07 21:57:21 - train: epoch 0044, iter [00830, 01251], lr: 0.001288, loss: 3.3655
2022-10-07 21:57:42 - train: epoch 0044, iter [00840, 01251], lr: 0.001288, loss: 3.0208
2022-10-07 21:58:03 - train: epoch 0044, iter [00850, 01251], lr: 0.001288, loss: 2.7351
2022-10-07 21:58:25 - train: epoch 0044, iter [00860, 01251], lr: 0.001288, loss: 2.5817
2022-10-07 21:58:46 - train: epoch 0044, iter [00870, 01251], lr: 0.001287, loss: 3.3584
2022-10-07 21:59:07 - train: epoch 0044, iter [00880, 01251], lr: 0.001287, loss: 3.0256
2022-10-07 21:59:28 - train: epoch 0044, iter [00890, 01251], lr: 0.001287, loss: 3.0560
2022-10-07 21:59:49 - train: epoch 0044, iter [00900, 01251], lr: 0.001287, loss: 3.4488
2022-10-07 22:00:11 - train: epoch 0044, iter [00910, 01251], lr: 0.001286, loss: 3.5318
2022-10-07 22:00:32 - train: epoch 0044, iter [00920, 01251], lr: 0.001286, loss: 3.6636
2022-10-07 22:00:53 - train: epoch 0044, iter [00930, 01251], lr: 0.001286, loss: 3.3743
2022-10-07 22:01:14 - train: epoch 0044, iter [00940, 01251], lr: 0.001286, loss: 3.2792
2022-10-07 22:01:36 - train: epoch 0044, iter [00950, 01251], lr: 0.001285, loss: 3.2400
2022-10-07 22:01:57 - train: epoch 0044, iter [00960, 01251], lr: 0.001285, loss: 3.0203
2022-10-07 22:02:18 - train: epoch 0044, iter [00970, 01251], lr: 0.001285, loss: 3.0245
2022-10-07 22:02:39 - train: epoch 0044, iter [00980, 01251], lr: 0.001285, loss: 3.4637
2022-10-07 22:03:00 - train: epoch 0044, iter [00990, 01251], lr: 0.001284, loss: 3.2235
2022-10-07 22:03:22 - train: epoch 0044, iter [01000, 01251], lr: 0.001284, loss: 2.7776
2022-10-07 22:03:43 - train: epoch 0044, iter [01010, 01251], lr: 0.001284, loss: 3.6715
2022-10-07 22:04:04 - train: epoch 0044, iter [01020, 01251], lr: 0.001284, loss: 3.5660
2022-10-07 22:04:26 - train: epoch 0044, iter [01030, 01251], lr: 0.001283, loss: 3.5026
2022-10-07 22:04:47 - train: epoch 0044, iter [01040, 01251], lr: 0.001283, loss: 3.6012
2022-10-07 22:05:08 - train: epoch 0044, iter [01050, 01251], lr: 0.001283, loss: 3.5226
2022-10-07 22:05:29 - train: epoch 0044, iter [01060, 01251], lr: 0.001283, loss: 3.6067
2022-10-07 22:05:50 - train: epoch 0044, iter [01070, 01251], lr: 0.001282, loss: 3.4589
2022-10-07 22:06:12 - train: epoch 0044, iter [01080, 01251], lr: 0.001282, loss: 3.4233
2022-10-07 22:06:33 - train: epoch 0044, iter [01090, 01251], lr: 0.001282, loss: 3.4773
2022-10-07 22:06:54 - train: epoch 0044, iter [01100, 01251], lr: 0.001282, loss: 2.5585
2022-10-07 22:07:15 - train: epoch 0044, iter [01110, 01251], lr: 0.001281, loss: 3.4413
2022-10-07 22:07:37 - train: epoch 0044, iter [01120, 01251], lr: 0.001281, loss: 3.5896
2022-10-07 22:07:58 - train: epoch 0044, iter [01130, 01251], lr: 0.001281, loss: 3.2018
2022-10-07 22:08:19 - train: epoch 0044, iter [01140, 01251], lr: 0.001281, loss: 3.6834
2022-10-07 22:08:41 - train: epoch 0044, iter [01150, 01251], lr: 0.001280, loss: 2.7229
2022-10-07 22:09:02 - train: epoch 0044, iter [01160, 01251], lr: 0.001280, loss: 3.0009
2022-10-07 22:09:23 - train: epoch 0044, iter [01170, 01251], lr: 0.001280, loss: 2.6503
2022-10-07 22:09:44 - train: epoch 0044, iter [01180, 01251], lr: 0.001280, loss: 2.7393
2022-10-07 22:10:06 - train: epoch 0044, iter [01190, 01251], lr: 0.001279, loss: 3.7200
2022-10-07 22:10:27 - train: epoch 0044, iter [01200, 01251], lr: 0.001279, loss: 3.2887
2022-10-07 22:10:48 - train: epoch 0044, iter [01210, 01251], lr: 0.001279, loss: 2.9886
2022-10-07 22:11:09 - train: epoch 0044, iter [01220, 01251], lr: 0.001279, loss: 3.4076
2022-10-07 22:11:31 - train: epoch 0044, iter [01230, 01251], lr: 0.001278, loss: 3.3269
2022-10-07 22:11:52 - train: epoch 0044, iter [01240, 01251], lr: 0.001278, loss: 2.8420
2022-10-07 22:12:13 - train: epoch 0044, iter [01250, 01251], lr: 0.001278, loss: 3.3639
2022-10-07 22:12:16 - train: epoch 044, train_loss: 3.1807
2022-10-07 22:13:33 - eval: epoch: 044, acc1: 79.892%, acc5: 95.346%, test_loss: 0.8786, per_image_load_time: 0.556ms, per_image_inference_time: 1.440ms
2022-10-07 22:13:34 - until epoch: 044, best_acc1: 79.892%
2022-10-07 22:13:34 - epoch 045 lr: 0.001278
2022-10-07 22:14:01 - train: epoch 0045, iter [00010, 01251], lr: 0.001278, loss: 3.5485
2022-10-07 22:14:22 - train: epoch 0045, iter [00020, 01251], lr: 0.001277, loss: 3.3843
2022-10-07 22:14:43 - train: epoch 0045, iter [00030, 01251], lr: 0.001277, loss: 3.3096
2022-10-07 22:15:04 - train: epoch 0045, iter [00040, 01251], lr: 0.001277, loss: 3.6028
2022-10-07 22:15:25 - train: epoch 0045, iter [00050, 01251], lr: 0.001276, loss: 2.5201
2022-10-07 22:15:47 - train: epoch 0045, iter [00060, 01251], lr: 0.001276, loss: 3.5821
2022-10-07 22:16:08 - train: epoch 0045, iter [00070, 01251], lr: 0.001276, loss: 3.0400
2022-10-07 22:16:29 - train: epoch 0045, iter [00080, 01251], lr: 0.001276, loss: 3.4767
2022-10-07 22:16:50 - train: epoch 0045, iter [00090, 01251], lr: 0.001275, loss: 2.8732
2022-10-07 22:17:11 - train: epoch 0045, iter [00100, 01251], lr: 0.001275, loss: 2.9816
2022-10-07 22:17:32 - train: epoch 0045, iter [00110, 01251], lr: 0.001275, loss: 3.6809
2022-10-07 22:17:54 - train: epoch 0045, iter [00120, 01251], lr: 0.001275, loss: 3.4584
2022-10-07 22:18:15 - train: epoch 0045, iter [00130, 01251], lr: 0.001274, loss: 3.0677
2022-10-07 22:18:36 - train: epoch 0045, iter [00140, 01251], lr: 0.001274, loss: 3.2929
2022-10-07 22:18:58 - train: epoch 0045, iter [00150, 01251], lr: 0.001274, loss: 2.9943
2022-10-07 22:19:19 - train: epoch 0045, iter [00160, 01251], lr: 0.001274, loss: 2.4446
2022-10-07 22:19:40 - train: epoch 0045, iter [00170, 01251], lr: 0.001273, loss: 3.5201
2022-10-07 22:20:02 - train: epoch 0045, iter [00180, 01251], lr: 0.001273, loss: 3.7081
2022-10-07 22:20:23 - train: epoch 0045, iter [00190, 01251], lr: 0.001273, loss: 3.1112
2022-10-07 22:20:44 - train: epoch 0045, iter [00200, 01251], lr: 0.001273, loss: 3.7373
2022-10-07 22:21:05 - train: epoch 0045, iter [00210, 01251], lr: 0.001272, loss: 3.0888
2022-10-07 22:21:27 - train: epoch 0045, iter [00220, 01251], lr: 0.001272, loss: 2.7088
2022-10-07 22:21:48 - train: epoch 0045, iter [00230, 01251], lr: 0.001272, loss: 3.5216
2022-10-07 22:22:09 - train: epoch 0045, iter [00240, 01251], lr: 0.001272, loss: 2.1453
2022-10-07 22:22:30 - train: epoch 0045, iter [00250, 01251], lr: 0.001271, loss: 3.5142
2022-10-07 22:22:52 - train: epoch 0045, iter [00260, 01251], lr: 0.001271, loss: 2.8154
2022-10-07 22:23:13 - train: epoch 0045, iter [00270, 01251], lr: 0.001271, loss: 3.5620
2022-10-07 22:23:34 - train: epoch 0045, iter [00280, 01251], lr: 0.001271, loss: 2.9667
2022-10-07 22:23:55 - train: epoch 0045, iter [00290, 01251], lr: 0.001270, loss: 3.4899
2022-10-07 22:24:17 - train: epoch 0045, iter [00300, 01251], lr: 0.001270, loss: 3.0624
2022-10-07 22:24:38 - train: epoch 0045, iter [00310, 01251], lr: 0.001270, loss: 3.3114
2022-10-07 22:24:59 - train: epoch 0045, iter [00320, 01251], lr: 0.001270, loss: 2.3572
2022-10-07 22:25:20 - train: epoch 0045, iter [00330, 01251], lr: 0.001269, loss: 3.1653
2022-10-07 22:25:42 - train: epoch 0045, iter [00340, 01251], lr: 0.001269, loss: 3.5180
2022-10-07 22:26:03 - train: epoch 0045, iter [00350, 01251], lr: 0.001269, loss: 2.4933
2022-10-07 22:26:24 - train: epoch 0045, iter [00360, 01251], lr: 0.001269, loss: 3.0999
2022-10-07 22:26:45 - train: epoch 0045, iter [00370, 01251], lr: 0.001268, loss: 3.5358
2022-10-07 22:27:06 - train: epoch 0045, iter [00380, 01251], lr: 0.001268, loss: 2.8609
2022-10-07 22:27:28 - train: epoch 0045, iter [00390, 01251], lr: 0.001268, loss: 3.2855
2022-10-07 22:27:49 - train: epoch 0045, iter [00400, 01251], lr: 0.001268, loss: 3.2056
2022-10-07 22:28:10 - train: epoch 0045, iter [00410, 01251], lr: 0.001267, loss: 3.0937
2022-10-07 22:28:31 - train: epoch 0045, iter [00420, 01251], lr: 0.001267, loss: 3.2605
2022-10-07 22:28:53 - train: epoch 0045, iter [00430, 01251], lr: 0.001267, loss: 3.6644
2022-10-07 22:29:14 - train: epoch 0045, iter [00440, 01251], lr: 0.001267, loss: 3.1534
2022-10-07 22:29:35 - train: epoch 0045, iter [00450, 01251], lr: 0.001266, loss: 3.6338
2022-10-07 22:29:56 - train: epoch 0045, iter [00460, 01251], lr: 0.001266, loss: 3.0748
2022-10-07 22:30:17 - train: epoch 0045, iter [00470, 01251], lr: 0.001266, loss: 3.3723
2022-10-07 22:30:39 - train: epoch 0045, iter [00480, 01251], lr: 0.001266, loss: 3.0090
2022-10-07 22:31:00 - train: epoch 0045, iter [00490, 01251], lr: 0.001265, loss: 3.3959
2022-10-07 22:31:21 - train: epoch 0045, iter [00500, 01251], lr: 0.001265, loss: 2.7306
2022-10-07 22:31:42 - train: epoch 0045, iter [00510, 01251], lr: 0.001265, loss: 3.2548
2022-10-07 22:32:04 - train: epoch 0045, iter [00520, 01251], lr: 0.001265, loss: 3.4872
2022-10-07 22:32:25 - train: epoch 0045, iter [00530, 01251], lr: 0.001264, loss: 3.1199
2022-10-07 22:32:46 - train: epoch 0045, iter [00540, 01251], lr: 0.001264, loss: 3.4114
2022-10-07 22:33:08 - train: epoch 0045, iter [00550, 01251], lr: 0.001264, loss: 2.7956
2022-10-07 22:33:29 - train: epoch 0045, iter [00560, 01251], lr: 0.001264, loss: 3.2067
2022-10-07 22:33:50 - train: epoch 0045, iter [00570, 01251], lr: 0.001263, loss: 3.7598
2022-10-07 22:34:12 - train: epoch 0045, iter [00580, 01251], lr: 0.001263, loss: 3.2752
2022-10-07 22:34:33 - train: epoch 0045, iter [00590, 01251], lr: 0.001263, loss: 3.0686
2022-10-07 22:34:54 - train: epoch 0045, iter [00600, 01251], lr: 0.001262, loss: 3.0326
2022-10-07 22:35:15 - train: epoch 0045, iter [00610, 01251], lr: 0.001262, loss: 3.5551
2022-10-07 22:35:37 - train: epoch 0045, iter [00620, 01251], lr: 0.001262, loss: 3.2132
2022-10-07 22:35:58 - train: epoch 0045, iter [00630, 01251], lr: 0.001262, loss: 3.1237
2022-10-07 22:36:19 - train: epoch 0045, iter [00640, 01251], lr: 0.001261, loss: 3.1451
2022-10-07 22:36:40 - train: epoch 0045, iter [00650, 01251], lr: 0.001261, loss: 2.5885
2022-10-07 22:37:02 - train: epoch 0045, iter [00660, 01251], lr: 0.001261, loss: 3.5853
2022-10-07 22:37:23 - train: epoch 0045, iter [00670, 01251], lr: 0.001261, loss: 3.4515
2022-10-07 22:37:44 - train: epoch 0045, iter [00680, 01251], lr: 0.001260, loss: 3.0488
2022-10-07 22:38:06 - train: epoch 0045, iter [00690, 01251], lr: 0.001260, loss: 2.9678
2022-10-07 22:38:27 - train: epoch 0045, iter [00700, 01251], lr: 0.001260, loss: 2.8260
2022-10-07 22:38:48 - train: epoch 0045, iter [00710, 01251], lr: 0.001260, loss: 3.3497
2022-10-07 22:39:10 - train: epoch 0045, iter [00720, 01251], lr: 0.001259, loss: 2.9567
2022-10-07 22:39:31 - train: epoch 0045, iter [00730, 01251], lr: 0.001259, loss: 3.4806
2022-10-07 22:39:53 - train: epoch 0045, iter [00740, 01251], lr: 0.001259, loss: 2.9760
2022-10-07 22:40:14 - train: epoch 0045, iter [00750, 01251], lr: 0.001259, loss: 3.0769
2022-10-07 22:40:35 - train: epoch 0045, iter [00760, 01251], lr: 0.001258, loss: 2.8315
2022-10-07 22:40:56 - train: epoch 0045, iter [00770, 01251], lr: 0.001258, loss: 2.8118
2022-10-07 22:41:18 - train: epoch 0045, iter [00780, 01251], lr: 0.001258, loss: 2.9203
2022-10-07 22:41:39 - train: epoch 0045, iter [00790, 01251], lr: 0.001258, loss: 3.5752
2022-10-07 22:42:00 - train: epoch 0045, iter [00800, 01251], lr: 0.001257, loss: 3.5701
2022-10-07 22:42:22 - train: epoch 0045, iter [00810, 01251], lr: 0.001257, loss: 3.0592
2022-10-07 22:42:43 - train: epoch 0045, iter [00820, 01251], lr: 0.001257, loss: 3.3499
2022-10-07 22:43:04 - train: epoch 0045, iter [00830, 01251], lr: 0.001257, loss: 3.7873
2022-10-07 22:43:25 - train: epoch 0045, iter [00840, 01251], lr: 0.001256, loss: 2.5876
2022-10-07 22:43:47 - train: epoch 0045, iter [00850, 01251], lr: 0.001256, loss: 3.4394
2022-10-07 22:44:08 - train: epoch 0045, iter [00860, 01251], lr: 0.001256, loss: 3.5472
2022-10-07 22:44:29 - train: epoch 0045, iter [00870, 01251], lr: 0.001256, loss: 3.2386
2022-10-07 22:44:50 - train: epoch 0045, iter [00880, 01251], lr: 0.001255, loss: 3.0223
2022-10-07 22:45:12 - train: epoch 0045, iter [00890, 01251], lr: 0.001255, loss: 2.9703
2022-10-07 22:45:33 - train: epoch 0045, iter [00900, 01251], lr: 0.001255, loss: 3.1370
2022-10-07 22:45:54 - train: epoch 0045, iter [00910, 01251], lr: 0.001255, loss: 3.2205
2022-10-07 22:46:16 - train: epoch 0045, iter [00920, 01251], lr: 0.001254, loss: 2.8436
2022-10-07 22:46:37 - train: epoch 0045, iter [00930, 01251], lr: 0.001254, loss: 3.2341
2022-10-07 22:46:58 - train: epoch 0045, iter [00940, 01251], lr: 0.001254, loss: 3.0143
2022-10-07 22:47:19 - train: epoch 0045, iter [00950, 01251], lr: 0.001254, loss: 3.0609
2022-10-07 22:47:40 - train: epoch 0045, iter [00960, 01251], lr: 0.001253, loss: 2.7080
2022-10-07 22:48:01 - train: epoch 0045, iter [00970, 01251], lr: 0.001253, loss: 2.8249
2022-10-07 22:48:22 - train: epoch 0045, iter [00980, 01251], lr: 0.001253, loss: 3.4537
2022-10-07 22:48:43 - train: epoch 0045, iter [00990, 01251], lr: 0.001253, loss: 3.6860
2022-10-07 22:49:04 - train: epoch 0045, iter [01000, 01251], lr: 0.001252, loss: 3.0687
2022-10-07 22:49:26 - train: epoch 0045, iter [01010, 01251], lr: 0.001252, loss: 2.9478
2022-10-07 22:49:47 - train: epoch 0045, iter [01020, 01251], lr: 0.001252, loss: 3.4670
2022-10-07 22:50:08 - train: epoch 0045, iter [01030, 01251], lr: 0.001252, loss: 3.5236
2022-10-07 22:50:29 - train: epoch 0045, iter [01040, 01251], lr: 0.001251, loss: 3.4444
2022-10-07 22:50:50 - train: epoch 0045, iter [01050, 01251], lr: 0.001251, loss: 3.4011
2022-10-07 22:51:11 - train: epoch 0045, iter [01060, 01251], lr: 0.001251, loss: 3.4451
2022-10-07 22:51:32 - train: epoch 0045, iter [01070, 01251], lr: 0.001250, loss: 2.7221
2022-10-07 22:51:53 - train: epoch 0045, iter [01080, 01251], lr: 0.001250, loss: 3.5217
2022-10-07 22:52:14 - train: epoch 0045, iter [01090, 01251], lr: 0.001250, loss: 3.2710
2022-10-07 22:52:35 - train: epoch 0045, iter [01100, 01251], lr: 0.001250, loss: 3.6267
2022-10-07 22:52:56 - train: epoch 0045, iter [01110, 01251], lr: 0.001249, loss: 3.6062
2022-10-07 22:53:17 - train: epoch 0045, iter [01120, 01251], lr: 0.001249, loss: 3.3726
2022-10-07 22:53:38 - train: epoch 0045, iter [01130, 01251], lr: 0.001249, loss: 3.1103
2022-10-07 22:53:59 - train: epoch 0045, iter [01140, 01251], lr: 0.001249, loss: 3.1851
2022-10-07 22:54:20 - train: epoch 0045, iter [01150, 01251], lr: 0.001248, loss: 2.8033
2022-10-07 22:54:42 - train: epoch 0045, iter [01160, 01251], lr: 0.001248, loss: 2.8964
2022-10-07 22:55:03 - train: epoch 0045, iter [01170, 01251], lr: 0.001248, loss: 3.5270
2022-10-07 22:55:24 - train: epoch 0045, iter [01180, 01251], lr: 0.001248, loss: 3.0165
2022-10-07 22:55:45 - train: epoch 0045, iter [01190, 01251], lr: 0.001247, loss: 3.2060
2022-10-07 22:56:06 - train: epoch 0045, iter [01200, 01251], lr: 0.001247, loss: 3.3405
2022-10-07 22:56:27 - train: epoch 0045, iter [01210, 01251], lr: 0.001247, loss: 3.2611
2022-10-07 22:56:48 - train: epoch 0045, iter [01220, 01251], lr: 0.001247, loss: 3.6663
2022-10-07 22:57:09 - train: epoch 0045, iter [01230, 01251], lr: 0.001246, loss: 2.9587
2022-10-07 22:57:30 - train: epoch 0045, iter [01240, 01251], lr: 0.001246, loss: 2.8999
2022-10-07 22:57:51 - train: epoch 0045, iter [01250, 01251], lr: 0.001246, loss: 3.1310
2022-10-07 22:57:54 - train: epoch 045, train_loss: 3.1671
2022-10-07 22:59:11 - eval: epoch: 045, acc1: 80.120%, acc5: 95.380%, test_loss: 0.8659, per_image_load_time: 1.340ms, per_image_inference_time: 1.407ms
2022-10-07 22:59:13 - until epoch: 045, best_acc1: 80.120%
2022-10-07 22:59:13 - epoch 046 lr: 0.001246
2022-10-07 22:59:40 - train: epoch 0046, iter [00010, 01251], lr: 0.001246, loss: 3.1698
2022-10-07 23:00:01 - train: epoch 0046, iter [00020, 01251], lr: 0.001245, loss: 3.0331
2022-10-07 23:00:22 - train: epoch 0046, iter [00030, 01251], lr: 0.001245, loss: 3.1390
2022-10-07 23:00:43 - train: epoch 0046, iter [00040, 01251], lr: 0.001245, loss: 2.8949
2022-10-07 23:01:05 - train: epoch 0046, iter [00050, 01251], lr: 0.001245, loss: 3.2039
2022-10-07 23:01:26 - train: epoch 0046, iter [00060, 01251], lr: 0.001244, loss: 3.2918
2022-10-07 23:01:47 - train: epoch 0046, iter [00070, 01251], lr: 0.001244, loss: 3.3040
2022-10-07 23:02:09 - train: epoch 0046, iter [00080, 01251], lr: 0.001244, loss: 3.3149
2022-10-07 23:02:30 - train: epoch 0046, iter [00090, 01251], lr: 0.001244, loss: 3.5298
2022-10-07 23:02:51 - train: epoch 0046, iter [00100, 01251], lr: 0.001243, loss: 3.3714
2022-10-07 23:03:13 - train: epoch 0046, iter [00110, 01251], lr: 0.001243, loss: 3.0831
2022-10-07 23:03:34 - train: epoch 0046, iter [00120, 01251], lr: 0.001243, loss: 3.2146
2022-10-07 23:03:55 - train: epoch 0046, iter [00130, 01251], lr: 0.001243, loss: 3.0103
2022-10-07 23:04:16 - train: epoch 0046, iter [00140, 01251], lr: 0.001242, loss: 3.3712
2022-10-07 23:04:38 - train: epoch 0046, iter [00150, 01251], lr: 0.001242, loss: 3.2859
2022-10-07 23:04:59 - train: epoch 0046, iter [00160, 01251], lr: 0.001242, loss: 2.9060
2022-10-07 23:05:20 - train: epoch 0046, iter [00170, 01251], lr: 0.001242, loss: 3.0566
2022-10-07 23:05:41 - train: epoch 0046, iter [00180, 01251], lr: 0.001241, loss: 3.6344
2022-10-07 23:06:03 - train: epoch 0046, iter [00190, 01251], lr: 0.001241, loss: 3.5534
2022-10-07 23:06:24 - train: epoch 0046, iter [00200, 01251], lr: 0.001241, loss: 3.2112
2022-10-07 23:06:45 - train: epoch 0046, iter [00210, 01251], lr: 0.001240, loss: 3.6043
2022-10-07 23:07:06 - train: epoch 0046, iter [00220, 01251], lr: 0.001240, loss: 3.3512
2022-10-07 23:07:27 - train: epoch 0046, iter [00230, 01251], lr: 0.001240, loss: 2.6822
2022-10-07 23:07:48 - train: epoch 0046, iter [00240, 01251], lr: 0.001240, loss: 3.5419
2022-10-07 23:08:09 - train: epoch 0046, iter [00250, 01251], lr: 0.001239, loss: 3.1588
2022-10-07 23:08:31 - train: epoch 0046, iter [00260, 01251], lr: 0.001239, loss: 2.9216
2022-10-07 23:08:52 - train: epoch 0046, iter [00270, 01251], lr: 0.001239, loss: 3.0772
2022-10-07 23:09:13 - train: epoch 0046, iter [00280, 01251], lr: 0.001239, loss: 2.9386
2022-10-07 23:09:34 - train: epoch 0046, iter [00290, 01251], lr: 0.001238, loss: 2.9626
2022-10-07 23:09:55 - train: epoch 0046, iter [00300, 01251], lr: 0.001238, loss: 3.2508
2022-10-07 23:10:16 - train: epoch 0046, iter [00310, 01251], lr: 0.001238, loss: 3.1921
2022-10-07 23:10:37 - train: epoch 0046, iter [00320, 01251], lr: 0.001238, loss: 3.2102
2022-10-07 23:10:58 - train: epoch 0046, iter [00330, 01251], lr: 0.001237, loss: 2.1777
2022-10-07 23:11:19 - train: epoch 0046, iter [00340, 01251], lr: 0.001237, loss: 3.2877
2022-10-07 23:11:40 - train: epoch 0046, iter [00350, 01251], lr: 0.001237, loss: 2.9253
2022-10-07 23:12:02 - train: epoch 0046, iter [00360, 01251], lr: 0.001237, loss: 2.8703
2022-10-07 23:12:23 - train: epoch 0046, iter [00370, 01251], lr: 0.001236, loss: 2.5961
2022-10-07 23:12:44 - train: epoch 0046, iter [00380, 01251], lr: 0.001236, loss: 2.8151
2022-10-07 23:13:05 - train: epoch 0046, iter [00390, 01251], lr: 0.001236, loss: 3.4468
2022-10-07 23:13:26 - train: epoch 0046, iter [00400, 01251], lr: 0.001236, loss: 2.8674
2022-10-07 23:13:47 - train: epoch 0046, iter [00410, 01251], lr: 0.001235, loss: 2.6317
2022-10-07 23:14:08 - train: epoch 0046, iter [00420, 01251], lr: 0.001235, loss: 3.3824
2022-10-07 23:14:29 - train: epoch 0046, iter [00430, 01251], lr: 0.001235, loss: 3.1362
2022-10-07 23:14:50 - train: epoch 0046, iter [00440, 01251], lr: 0.001235, loss: 3.3699
2022-10-07 23:15:11 - train: epoch 0046, iter [00450, 01251], lr: 0.001234, loss: 3.0537
2022-10-07 23:15:32 - train: epoch 0046, iter [00460, 01251], lr: 0.001234, loss: 2.9851
2022-10-07 23:15:54 - train: epoch 0046, iter [00470, 01251], lr: 0.001234, loss: 3.0842
2022-10-07 23:16:15 - train: epoch 0046, iter [00480, 01251], lr: 0.001234, loss: 3.5074
2022-10-07 23:16:36 - train: epoch 0046, iter [00490, 01251], lr: 0.001233, loss: 2.9470
2022-10-07 23:16:57 - train: epoch 0046, iter [00500, 01251], lr: 0.001233, loss: 2.8683
2022-10-07 23:17:18 - train: epoch 0046, iter [00510, 01251], lr: 0.001233, loss: 3.1610
2022-10-07 23:17:40 - train: epoch 0046, iter [00520, 01251], lr: 0.001233, loss: 2.7845
2022-10-07 23:18:01 - train: epoch 0046, iter [00530, 01251], lr: 0.001232, loss: 2.6481
2022-10-07 23:18:22 - train: epoch 0046, iter [00540, 01251], lr: 0.001232, loss: 2.8659
2022-10-07 23:18:43 - train: epoch 0046, iter [00550, 01251], lr: 0.001232, loss: 3.3483
2022-10-07 23:19:04 - train: epoch 0046, iter [00560, 01251], lr: 0.001231, loss: 3.2502
2022-10-07 23:19:25 - train: epoch 0046, iter [00570, 01251], lr: 0.001231, loss: 3.4737
2022-10-07 23:19:46 - train: epoch 0046, iter [00580, 01251], lr: 0.001231, loss: 3.3256
2022-10-07 23:20:07 - train: epoch 0046, iter [00590, 01251], lr: 0.001231, loss: 2.9615
2022-10-07 23:20:28 - train: epoch 0046, iter [00600, 01251], lr: 0.001230, loss: 3.5751
2022-10-07 23:20:49 - train: epoch 0046, iter [00610, 01251], lr: 0.001230, loss: 3.0514
2022-10-07 23:21:10 - train: epoch 0046, iter [00620, 01251], lr: 0.001230, loss: 3.5245
2022-10-07 23:21:31 - train: epoch 0046, iter [00630, 01251], lr: 0.001230, loss: 2.6998
2022-10-07 23:21:52 - train: epoch 0046, iter [00640, 01251], lr: 0.001229, loss: 3.2144
2022-10-07 23:22:14 - train: epoch 0046, iter [00650, 01251], lr: 0.001229, loss: 3.5069
2022-10-07 23:22:35 - train: epoch 0046, iter [00660, 01251], lr: 0.001229, loss: 3.2675
2022-10-07 23:22:56 - train: epoch 0046, iter [00670, 01251], lr: 0.001229, loss: 2.8020
2022-10-07 23:23:17 - train: epoch 0046, iter [00680, 01251], lr: 0.001228, loss: 3.1554
2022-10-07 23:23:38 - train: epoch 0046, iter [00690, 01251], lr: 0.001228, loss: 2.8303
2022-10-07 23:23:59 - train: epoch 0046, iter [00700, 01251], lr: 0.001228, loss: 3.5681
2022-10-07 23:24:20 - train: epoch 0046, iter [00710, 01251], lr: 0.001228, loss: 3.2238
2022-10-07 23:24:41 - train: epoch 0046, iter [00720, 01251], lr: 0.001227, loss: 3.6554
2022-10-07 23:25:02 - train: epoch 0046, iter [00730, 01251], lr: 0.001227, loss: 3.3434
2022-10-07 23:25:23 - train: epoch 0046, iter [00740, 01251], lr: 0.001227, loss: 2.9304
2022-10-07 23:25:44 - train: epoch 0046, iter [00750, 01251], lr: 0.001227, loss: 3.0433
2022-10-07 23:26:05 - train: epoch 0046, iter [00760, 01251], lr: 0.001226, loss: 3.4444
2022-10-07 23:26:27 - train: epoch 0046, iter [00770, 01251], lr: 0.001226, loss: 3.5455
2022-10-07 23:26:48 - train: epoch 0046, iter [00780, 01251], lr: 0.001226, loss: 3.5233
2022-10-07 23:27:09 - train: epoch 0046, iter [00790, 01251], lr: 0.001226, loss: 2.8159
2022-10-07 23:27:30 - train: epoch 0046, iter [00800, 01251], lr: 0.001225, loss: 3.2422
2022-10-07 23:27:51 - train: epoch 0046, iter [00810, 01251], lr: 0.001225, loss: 3.5460
2022-10-07 23:28:12 - train: epoch 0046, iter [00820, 01251], lr: 0.001225, loss: 3.1175
2022-10-07 23:28:33 - train: epoch 0046, iter [00830, 01251], lr: 0.001225, loss: 3.1611
2022-10-07 23:28:54 - train: epoch 0046, iter [00840, 01251], lr: 0.001224, loss: 3.1463
2022-10-07 23:29:15 - train: epoch 0046, iter [00850, 01251], lr: 0.001224, loss: 2.4143
2022-10-07 23:29:36 - train: epoch 0046, iter [00860, 01251], lr: 0.001224, loss: 3.6699
2022-10-07 23:29:57 - train: epoch 0046, iter [00870, 01251], lr: 0.001224, loss: 3.5332
2022-10-07 23:30:19 - train: epoch 0046, iter [00880, 01251], lr: 0.001223, loss: 3.4345
2022-10-07 23:30:40 - train: epoch 0046, iter [00890, 01251], lr: 0.001223, loss: 2.7193
2022-10-07 23:31:01 - train: epoch 0046, iter [00900, 01251], lr: 0.001223, loss: 2.9661
2022-10-07 23:31:22 - train: epoch 0046, iter [00910, 01251], lr: 0.001222, loss: 3.5947
2022-10-07 23:31:43 - train: epoch 0046, iter [00920, 01251], lr: 0.001222, loss: 2.9815
2022-10-07 23:32:04 - train: epoch 0046, iter [00930, 01251], lr: 0.001222, loss: 3.3571
2022-10-07 23:32:25 - train: epoch 0046, iter [00940, 01251], lr: 0.001222, loss: 3.0879
2022-10-07 23:32:46 - train: epoch 0046, iter [00950, 01251], lr: 0.001221, loss: 3.6841
2022-10-07 23:33:07 - train: epoch 0046, iter [00960, 01251], lr: 0.001221, loss: 3.4707
2022-10-07 23:33:28 - train: epoch 0046, iter [00970, 01251], lr: 0.001221, loss: 3.3775
2022-10-07 23:33:49 - train: epoch 0046, iter [00980, 01251], lr: 0.001221, loss: 3.3197
2022-10-07 23:34:10 - train: epoch 0046, iter [00990, 01251], lr: 0.001220, loss: 3.5672
2022-10-07 23:34:31 - train: epoch 0046, iter [01000, 01251], lr: 0.001220, loss: 3.1332
2022-10-07 23:34:52 - train: epoch 0046, iter [01010, 01251], lr: 0.001220, loss: 3.5941
2022-10-07 23:35:13 - train: epoch 0046, iter [01020, 01251], lr: 0.001220, loss: 2.8869
2022-10-07 23:35:35 - train: epoch 0046, iter [01030, 01251], lr: 0.001219, loss: 3.5175
2022-10-07 23:35:56 - train: epoch 0046, iter [01040, 01251], lr: 0.001219, loss: 3.5011
2022-10-07 23:36:17 - train: epoch 0046, iter [01050, 01251], lr: 0.001219, loss: 3.4089
2022-10-07 23:36:38 - train: epoch 0046, iter [01060, 01251], lr: 0.001219, loss: 2.8782
2022-10-07 23:36:59 - train: epoch 0046, iter [01070, 01251], lr: 0.001218, loss: 3.1694
2022-10-07 23:37:20 - train: epoch 0046, iter [01080, 01251], lr: 0.001218, loss: 2.4456
2022-10-07 23:37:41 - train: epoch 0046, iter [01090, 01251], lr: 0.001218, loss: 3.4975
2022-10-07 23:38:02 - train: epoch 0046, iter [01100, 01251], lr: 0.001218, loss: 3.4423
2022-10-07 23:38:23 - train: epoch 0046, iter [01110, 01251], lr: 0.001217, loss: 3.0053
2022-10-07 23:38:44 - train: epoch 0046, iter [01120, 01251], lr: 0.001217, loss: 3.4576
2022-10-07 23:39:05 - train: epoch 0046, iter [01130, 01251], lr: 0.001217, loss: 2.9255
2022-10-07 23:39:26 - train: epoch 0046, iter [01140, 01251], lr: 0.001217, loss: 2.6898
2022-10-07 23:39:47 - train: epoch 0046, iter [01150, 01251], lr: 0.001216, loss: 3.4461
2022-10-07 23:40:08 - train: epoch 0046, iter [01160, 01251], lr: 0.001216, loss: 2.8894
2022-10-07 23:40:30 - train: epoch 0046, iter [01170, 01251], lr: 0.001216, loss: 3.6294
2022-10-07 23:40:51 - train: epoch 0046, iter [01180, 01251], lr: 0.001216, loss: 3.2440
2022-10-07 23:41:12 - train: epoch 0046, iter [01190, 01251], lr: 0.001215, loss: 3.3662
2022-10-07 23:41:33 - train: epoch 0046, iter [01200, 01251], lr: 0.001215, loss: 2.2914
2022-10-07 23:41:54 - train: epoch 0046, iter [01210, 01251], lr: 0.001215, loss: 3.4244
2022-10-07 23:42:15 - train: epoch 0046, iter [01220, 01251], lr: 0.001214, loss: 3.4297
2022-10-07 23:42:36 - train: epoch 0046, iter [01230, 01251], lr: 0.001214, loss: 3.1643
2022-10-07 23:42:57 - train: epoch 0046, iter [01240, 01251], lr: 0.001214, loss: 3.3619
2022-10-07 23:43:18 - train: epoch 0046, iter [01250, 01251], lr: 0.001214, loss: 3.2351
2022-10-07 23:43:22 - train: epoch 046, train_loss: 3.1581
2022-10-07 23:44:38 - eval: epoch: 046, acc1: 80.124%, acc5: 95.348%, test_loss: 0.8731, per_image_load_time: 1.487ms, per_image_inference_time: 1.427ms
2022-10-07 23:44:40 - until epoch: 046, best_acc1: 80.124%
2022-10-07 23:44:40 - epoch 047 lr: 0.001214
2022-10-07 23:45:07 - train: epoch 0047, iter [00010, 01251], lr: 0.001213, loss: 3.0965
2022-10-07 23:45:28 - train: epoch 0047, iter [00020, 01251], lr: 0.001213, loss: 3.3960
2022-10-07 23:45:49 - train: epoch 0047, iter [00030, 01251], lr: 0.001213, loss: 3.3165
2022-10-07 23:46:10 - train: epoch 0047, iter [00040, 01251], lr: 0.001213, loss: 2.8826
2022-10-07 23:46:31 - train: epoch 0047, iter [00050, 01251], lr: 0.001212, loss: 2.8970
2022-10-07 23:46:52 - train: epoch 0047, iter [00060, 01251], lr: 0.001212, loss: 3.4587
2022-10-07 23:47:13 - train: epoch 0047, iter [00070, 01251], lr: 0.001212, loss: 3.1858
2022-10-07 23:47:34 - train: epoch 0047, iter [00080, 01251], lr: 0.001212, loss: 3.2315
2022-10-07 23:47:55 - train: epoch 0047, iter [00090, 01251], lr: 0.001211, loss: 3.5191
2022-10-07 23:48:16 - train: epoch 0047, iter [00100, 01251], lr: 0.001211, loss: 3.3645
2022-10-07 23:48:37 - train: epoch 0047, iter [00110, 01251], lr: 0.001211, loss: 3.2894
2022-10-07 23:48:58 - train: epoch 0047, iter [00120, 01251], lr: 0.001211, loss: 2.7234
2022-10-07 23:49:19 - train: epoch 0047, iter [00130, 01251], lr: 0.001210, loss: 3.0440
2022-10-07 23:49:40 - train: epoch 0047, iter [00140, 01251], lr: 0.001210, loss: 3.2507
2022-10-07 23:50:02 - train: epoch 0047, iter [00150, 01251], lr: 0.001210, loss: 3.5496
2022-10-07 23:50:23 - train: epoch 0047, iter [00160, 01251], lr: 0.001210, loss: 3.6036
2022-10-07 23:50:44 - train: epoch 0047, iter [00170, 01251], lr: 0.001209, loss: 2.7566
2022-10-07 23:51:05 - train: epoch 0047, iter [00180, 01251], lr: 0.001209, loss: 3.6180
2022-10-07 23:51:26 - train: epoch 0047, iter [00190, 01251], lr: 0.001209, loss: 2.8096
2022-10-07 23:51:47 - train: epoch 0047, iter [00200, 01251], lr: 0.001209, loss: 3.3599
2022-10-07 23:52:08 - train: epoch 0047, iter [00210, 01251], lr: 0.001208, loss: 3.4536
2022-10-07 23:52:29 - train: epoch 0047, iter [00220, 01251], lr: 0.001208, loss: 3.4723
2022-10-07 23:52:50 - train: epoch 0047, iter [00230, 01251], lr: 0.001208, loss: 3.1006
2022-10-07 23:53:11 - train: epoch 0047, iter [00240, 01251], lr: 0.001207, loss: 2.3840
2022-10-07 23:53:32 - train: epoch 0047, iter [00250, 01251], lr: 0.001207, loss: 3.4123
2022-10-07 23:53:53 - train: epoch 0047, iter [00260, 01251], lr: 0.001207, loss: 3.3322
2022-10-07 23:54:14 - train: epoch 0047, iter [00270, 01251], lr: 0.001207, loss: 2.8267
2022-10-07 23:54:35 - train: epoch 0047, iter [00280, 01251], lr: 0.001206, loss: 2.7222
2022-10-07 23:54:56 - train: epoch 0047, iter [00290, 01251], lr: 0.001206, loss: 3.5374
2022-10-07 23:55:17 - train: epoch 0047, iter [00300, 01251], lr: 0.001206, loss: 3.7173
2022-10-07 23:55:39 - train: epoch 0047, iter [00310, 01251], lr: 0.001206, loss: 3.5451
2022-10-07 23:56:00 - train: epoch 0047, iter [00320, 01251], lr: 0.001205, loss: 3.4684
2022-10-07 23:56:21 - train: epoch 0047, iter [00330, 01251], lr: 0.001205, loss: 3.7908
2022-10-07 23:56:42 - train: epoch 0047, iter [00340, 01251], lr: 0.001205, loss: 3.4937
2022-10-07 23:57:03 - train: epoch 0047, iter [00350, 01251], lr: 0.001205, loss: 3.1914
2022-10-07 23:57:24 - train: epoch 0047, iter [00360, 01251], lr: 0.001204, loss: 2.3985
2022-10-07 23:57:45 - train: epoch 0047, iter [00370, 01251], lr: 0.001204, loss: 3.4879
2022-10-07 23:58:06 - train: epoch 0047, iter [00380, 01251], lr: 0.001204, loss: 2.8467
2022-10-07 23:58:27 - train: epoch 0047, iter [00390, 01251], lr: 0.001204, loss: 3.1572
2022-10-07 23:58:48 - train: epoch 0047, iter [00400, 01251], lr: 0.001203, loss: 2.8711
2022-10-07 23:59:09 - train: epoch 0047, iter [00410, 01251], lr: 0.001203, loss: 3.0689
2022-10-07 23:59:30 - train: epoch 0047, iter [00420, 01251], lr: 0.001203, loss: 3.5407
2022-10-07 23:59:51 - train: epoch 0047, iter [00430, 01251], lr: 0.001203, loss: 3.3522
2022-10-08 00:00:12 - train: epoch 0047, iter [00440, 01251], lr: 0.001202, loss: 3.0683
2022-10-08 00:00:33 - train: epoch 0047, iter [00450, 01251], lr: 0.001202, loss: 3.4725
2022-10-08 00:00:54 - train: epoch 0047, iter [00460, 01251], lr: 0.001202, loss: 3.2589
2022-10-08 00:01:16 - train: epoch 0047, iter [00470, 01251], lr: 0.001202, loss: 3.4849
2022-10-08 00:01:37 - train: epoch 0047, iter [00480, 01251], lr: 0.001201, loss: 3.4794
2022-10-08 00:01:58 - train: epoch 0047, iter [00490, 01251], lr: 0.001201, loss: 3.1618
2022-10-08 00:02:19 - train: epoch 0047, iter [00500, 01251], lr: 0.001201, loss: 3.4232
2022-10-08 00:02:40 - train: epoch 0047, iter [00510, 01251], lr: 0.001201, loss: 3.2135
2022-10-08 00:03:01 - train: epoch 0047, iter [00520, 01251], lr: 0.001200, loss: 2.8800
2022-10-08 00:03:22 - train: epoch 0047, iter [00530, 01251], lr: 0.001200, loss: 3.3839
2022-10-08 00:03:43 - train: epoch 0047, iter [00540, 01251], lr: 0.001200, loss: 2.9992
2022-10-08 00:04:04 - train: epoch 0047, iter [00550, 01251], lr: 0.001199, loss: 2.5829
2022-10-08 00:04:25 - train: epoch 0047, iter [00560, 01251], lr: 0.001199, loss: 3.4244
2022-10-08 00:04:46 - train: epoch 0047, iter [00570, 01251], lr: 0.001199, loss: 3.4338
2022-10-08 00:05:07 - train: epoch 0047, iter [00580, 01251], lr: 0.001199, loss: 3.6683
2022-10-08 00:05:28 - train: epoch 0047, iter [00590, 01251], lr: 0.001198, loss: 3.1642
2022-10-08 00:05:49 - train: epoch 0047, iter [00600, 01251], lr: 0.001198, loss: 3.6101
2022-10-08 00:06:10 - train: epoch 0047, iter [00610, 01251], lr: 0.001198, loss: 2.9114
2022-10-08 00:06:31 - train: epoch 0047, iter [00620, 01251], lr: 0.001198, loss: 3.2188
2022-10-08 00:06:53 - train: epoch 0047, iter [00630, 01251], lr: 0.001197, loss: 3.0278
2022-10-08 00:07:14 - train: epoch 0047, iter [00640, 01251], lr: 0.001197, loss: 3.0469
2022-10-08 00:07:35 - train: epoch 0047, iter [00650, 01251], lr: 0.001197, loss: 3.2046
2022-10-08 00:07:56 - train: epoch 0047, iter [00660, 01251], lr: 0.001197, loss: 2.6929
2022-10-08 00:08:17 - train: epoch 0047, iter [00670, 01251], lr: 0.001196, loss: 2.5523
2022-10-08 00:08:38 - train: epoch 0047, iter [00680, 01251], lr: 0.001196, loss: 2.7788
2022-10-08 00:08:59 - train: epoch 0047, iter [00690, 01251], lr: 0.001196, loss: 3.2807
2022-10-08 00:09:20 - train: epoch 0047, iter [00700, 01251], lr: 0.001196, loss: 3.2501
2022-10-08 00:09:41 - train: epoch 0047, iter [00710, 01251], lr: 0.001195, loss: 3.0171
2022-10-08 00:10:02 - train: epoch 0047, iter [00720, 01251], lr: 0.001195, loss: 3.4272
2022-10-08 00:10:23 - train: epoch 0047, iter [00730, 01251], lr: 0.001195, loss: 3.2161
2022-10-08 00:10:45 - train: epoch 0047, iter [00740, 01251], lr: 0.001195, loss: 3.3343
2022-10-08 00:11:06 - train: epoch 0047, iter [00750, 01251], lr: 0.001194, loss: 3.0590
2022-10-08 00:11:27 - train: epoch 0047, iter [00760, 01251], lr: 0.001194, loss: 3.2314
2022-10-08 00:11:48 - train: epoch 0047, iter [00770, 01251], lr: 0.001194, loss: 3.2279
2022-10-08 00:12:09 - train: epoch 0047, iter [00780, 01251], lr: 0.001194, loss: 3.3937
2022-10-08 00:12:30 - train: epoch 0047, iter [00790, 01251], lr: 0.001193, loss: 3.2845
2022-10-08 00:12:51 - train: epoch 0047, iter [00800, 01251], lr: 0.001193, loss: 2.6696
2022-10-08 00:13:12 - train: epoch 0047, iter [00810, 01251], lr: 0.001193, loss: 3.0513
2022-10-08 00:13:33 - train: epoch 0047, iter [00820, 01251], lr: 0.001192, loss: 2.3052
2022-10-08 00:13:54 - train: epoch 0047, iter [00830, 01251], lr: 0.001192, loss: 2.9744
2022-10-08 00:14:15 - train: epoch 0047, iter [00840, 01251], lr: 0.001192, loss: 3.3381
2022-10-08 00:14:36 - train: epoch 0047, iter [00850, 01251], lr: 0.001192, loss: 3.4205
2022-10-08 00:14:57 - train: epoch 0047, iter [00860, 01251], lr: 0.001191, loss: 2.9751
2022-10-08 00:15:19 - train: epoch 0047, iter [00870, 01251], lr: 0.001191, loss: 3.4846
2022-10-08 00:15:40 - train: epoch 0047, iter [00880, 01251], lr: 0.001191, loss: 2.6293
2022-10-08 00:16:01 - train: epoch 0047, iter [00890, 01251], lr: 0.001191, loss: 3.5058
2022-10-08 00:16:22 - train: epoch 0047, iter [00900, 01251], lr: 0.001190, loss: 2.8523
2022-10-08 00:16:43 - train: epoch 0047, iter [00910, 01251], lr: 0.001190, loss: 3.0749
2022-10-08 00:17:04 - train: epoch 0047, iter [00920, 01251], lr: 0.001190, loss: 2.6362
2022-10-08 00:17:25 - train: epoch 0047, iter [00930, 01251], lr: 0.001190, loss: 2.8735
2022-10-08 00:17:46 - train: epoch 0047, iter [00940, 01251], lr: 0.001189, loss: 2.7324
2022-10-08 00:18:07 - train: epoch 0047, iter [00950, 01251], lr: 0.001189, loss: 3.3003
2022-10-08 00:18:28 - train: epoch 0047, iter [00960, 01251], lr: 0.001189, loss: 2.4349
2022-10-08 00:18:49 - train: epoch 0047, iter [00970, 01251], lr: 0.001189, loss: 2.7756
2022-10-08 00:19:10 - train: epoch 0047, iter [00980, 01251], lr: 0.001188, loss: 2.9895
2022-10-08 00:19:31 - train: epoch 0047, iter [00990, 01251], lr: 0.001188, loss: 3.1971
2022-10-08 00:19:52 - train: epoch 0047, iter [01000, 01251], lr: 0.001188, loss: 3.3715
2022-10-08 00:20:14 - train: epoch 0047, iter [01010, 01251], lr: 0.001188, loss: 3.7521
2022-10-08 00:20:35 - train: epoch 0047, iter [01020, 01251], lr: 0.001187, loss: 2.5284
2022-10-08 00:20:56 - train: epoch 0047, iter [01030, 01251], lr: 0.001187, loss: 2.7559
2022-10-08 00:21:17 - train: epoch 0047, iter [01040, 01251], lr: 0.001187, loss: 3.4343
2022-10-08 00:21:38 - train: epoch 0047, iter [01050, 01251], lr: 0.001187, loss: 3.4138
2022-10-08 00:21:59 - train: epoch 0047, iter [01060, 01251], lr: 0.001186, loss: 3.6702
2022-10-08 00:22:20 - train: epoch 0047, iter [01070, 01251], lr: 0.001186, loss: 3.2125
2022-10-08 00:22:41 - train: epoch 0047, iter [01080, 01251], lr: 0.001186, loss: 2.7789
2022-10-08 00:23:02 - train: epoch 0047, iter [01090, 01251], lr: 0.001185, loss: 3.1597
2022-10-08 00:23:23 - train: epoch 0047, iter [01100, 01251], lr: 0.001185, loss: 3.6634
2022-10-08 00:23:44 - train: epoch 0047, iter [01110, 01251], lr: 0.001185, loss: 3.2514
2022-10-08 00:24:05 - train: epoch 0047, iter [01120, 01251], lr: 0.001185, loss: 3.2476
2022-10-08 00:24:26 - train: epoch 0047, iter [01130, 01251], lr: 0.001184, loss: 3.0265
2022-10-08 00:24:48 - train: epoch 0047, iter [01140, 01251], lr: 0.001184, loss: 2.4542
2022-10-08 00:25:09 - train: epoch 0047, iter [01150, 01251], lr: 0.001184, loss: 2.9741
2022-10-08 00:25:30 - train: epoch 0047, iter [01160, 01251], lr: 0.001184, loss: 3.5960
2022-10-08 00:25:51 - train: epoch 0047, iter [01170, 01251], lr: 0.001183, loss: 2.8978
2022-10-08 00:26:12 - train: epoch 0047, iter [01180, 01251], lr: 0.001183, loss: 3.2322
2022-10-08 00:26:33 - train: epoch 0047, iter [01190, 01251], lr: 0.001183, loss: 3.0020
2022-10-08 00:26:54 - train: epoch 0047, iter [01200, 01251], lr: 0.001183, loss: 2.9148
2022-10-08 00:27:15 - train: epoch 0047, iter [01210, 01251], lr: 0.001182, loss: 3.2845
2022-10-08 00:27:36 - train: epoch 0047, iter [01220, 01251], lr: 0.001182, loss: 2.3360
2022-10-08 00:27:58 - train: epoch 0047, iter [01230, 01251], lr: 0.001182, loss: 3.1202
2022-10-08 00:28:19 - train: epoch 0047, iter [01240, 01251], lr: 0.001182, loss: 3.1286
2022-10-08 00:28:40 - train: epoch 0047, iter [01250, 01251], lr: 0.001181, loss: 2.5512
2022-10-08 00:28:43 - train: epoch 047, train_loss: 3.1390
2022-10-08 00:29:59 - eval: epoch: 047, acc1: 80.390%, acc5: 95.494%, test_loss: 0.8467, per_image_load_time: 1.418ms, per_image_inference_time: 1.428ms
2022-10-08 00:30:01 - until epoch: 047, best_acc1: 80.390%
2022-10-08 00:30:01 - epoch 048 lr: 0.001181
2022-10-08 00:30:28 - train: epoch 0048, iter [00010, 01251], lr: 0.001181, loss: 3.1448
2022-10-08 00:30:49 - train: epoch 0048, iter [00020, 01251], lr: 0.001181, loss: 2.9888
2022-10-08 00:31:10 - train: epoch 0048, iter [00030, 01251], lr: 0.001181, loss: 3.2828
2022-10-08 00:31:31 - train: epoch 0048, iter [00040, 01251], lr: 0.001180, loss: 3.5630
2022-10-08 00:31:52 - train: epoch 0048, iter [00050, 01251], lr: 0.001180, loss: 3.1734
2022-10-08 00:32:13 - train: epoch 0048, iter [00060, 01251], lr: 0.001180, loss: 3.3783
2022-10-08 00:32:34 - train: epoch 0048, iter [00070, 01251], lr: 0.001179, loss: 2.8645
2022-10-08 00:32:55 - train: epoch 0048, iter [00080, 01251], lr: 0.001179, loss: 3.0917
2022-10-08 00:33:16 - train: epoch 0048, iter [00090, 01251], lr: 0.001179, loss: 3.0233
2022-10-08 00:33:37 - train: epoch 0048, iter [00100, 01251], lr: 0.001179, loss: 3.0877
2022-10-08 00:33:58 - train: epoch 0048, iter [00110, 01251], lr: 0.001178, loss: 3.4057
2022-10-08 00:34:20 - train: epoch 0048, iter [00120, 01251], lr: 0.001178, loss: 3.2878
2022-10-08 00:34:41 - train: epoch 0048, iter [00130, 01251], lr: 0.001178, loss: 3.2667
2022-10-08 00:35:02 - train: epoch 0048, iter [00140, 01251], lr: 0.001178, loss: 3.0695
2022-10-08 00:35:23 - train: epoch 0048, iter [00150, 01251], lr: 0.001177, loss: 3.5533
2022-10-08 00:35:44 - train: epoch 0048, iter [00160, 01251], lr: 0.001177, loss: 3.2937
2022-10-08 00:36:05 - train: epoch 0048, iter [00170, 01251], lr: 0.001177, loss: 3.2870
2022-10-08 00:36:26 - train: epoch 0048, iter [00180, 01251], lr: 0.001177, loss: 3.0495
2022-10-08 00:36:47 - train: epoch 0048, iter [00190, 01251], lr: 0.001176, loss: 3.0806
2022-10-08 00:37:08 - train: epoch 0048, iter [00200, 01251], lr: 0.001176, loss: 3.3244
2022-10-08 00:37:30 - train: epoch 0048, iter [00210, 01251], lr: 0.001176, loss: 2.9782
2022-10-08 00:37:51 - train: epoch 0048, iter [00220, 01251], lr: 0.001176, loss: 3.1330
2022-10-08 00:38:12 - train: epoch 0048, iter [00230, 01251], lr: 0.001175, loss: 3.1309
2022-10-08 00:38:33 - train: epoch 0048, iter [00240, 01251], lr: 0.001175, loss: 3.2870
2022-10-08 00:38:54 - train: epoch 0048, iter [00250, 01251], lr: 0.001175, loss: 3.2419
2022-10-08 00:39:15 - train: epoch 0048, iter [00260, 01251], lr: 0.001175, loss: 2.9894
2022-10-08 00:39:36 - train: epoch 0048, iter [00270, 01251], lr: 0.001174, loss: 3.4425
2022-10-08 00:39:57 - train: epoch 0048, iter [00280, 01251], lr: 0.001174, loss: 3.5594
2022-10-08 00:40:19 - train: epoch 0048, iter [00290, 01251], lr: 0.001174, loss: 3.2458
2022-10-08 00:40:40 - train: epoch 0048, iter [00300, 01251], lr: 0.001173, loss: 2.6297
2022-10-08 00:41:01 - train: epoch 0048, iter [00310, 01251], lr: 0.001173, loss: 3.0749
2022-10-08 00:41:22 - train: epoch 0048, iter [00320, 01251], lr: 0.001173, loss: 3.1583
2022-10-08 00:41:43 - train: epoch 0048, iter [00330, 01251], lr: 0.001173, loss: 3.5235
2022-10-08 00:42:04 - train: epoch 0048, iter [00340, 01251], lr: 0.001172, loss: 3.2290
2022-10-08 00:42:25 - train: epoch 0048, iter [00350, 01251], lr: 0.001172, loss: 2.8159
2022-10-08 00:42:46 - train: epoch 0048, iter [00360, 01251], lr: 0.001172, loss: 3.1486
2022-10-08 00:43:07 - train: epoch 0048, iter [00370, 01251], lr: 0.001172, loss: 3.3231
2022-10-08 00:43:28 - train: epoch 0048, iter [00380, 01251], lr: 0.001171, loss: 3.4196
2022-10-08 00:43:50 - train: epoch 0048, iter [00390, 01251], lr: 0.001171, loss: 3.3946
2022-10-08 00:44:11 - train: epoch 0048, iter [00400, 01251], lr: 0.001171, loss: 3.2324
2022-10-08 00:44:32 - train: epoch 0048, iter [00410, 01251], lr: 0.001171, loss: 3.6901
2022-10-08 00:44:53 - train: epoch 0048, iter [00420, 01251], lr: 0.001170, loss: 3.3072
2022-10-08 00:45:14 - train: epoch 0048, iter [00430, 01251], lr: 0.001170, loss: 2.8382
2022-10-08 00:45:35 - train: epoch 0048, iter [00440, 01251], lr: 0.001170, loss: 3.3067
2022-10-08 00:45:56 - train: epoch 0048, iter [00450, 01251], lr: 0.001170, loss: 3.1118
2022-10-08 00:46:17 - train: epoch 0048, iter [00460, 01251], lr: 0.001169, loss: 2.7484
2022-10-08 00:46:38 - train: epoch 0048, iter [00470, 01251], lr: 0.001169, loss: 2.7071
2022-10-08 00:47:00 - train: epoch 0048, iter [00480, 01251], lr: 0.001169, loss: 3.0899
2022-10-08 00:47:21 - train: epoch 0048, iter [00490, 01251], lr: 0.001169, loss: 3.5082
2022-10-08 00:47:42 - train: epoch 0048, iter [00500, 01251], lr: 0.001168, loss: 3.3652
2022-10-08 00:48:03 - train: epoch 0048, iter [00510, 01251], lr: 0.001168, loss: 3.2363
2022-10-08 00:48:24 - train: epoch 0048, iter [00520, 01251], lr: 0.001168, loss: 3.4382
2022-10-08 00:48:45 - train: epoch 0048, iter [00530, 01251], lr: 0.001168, loss: 2.8539
2022-10-08 00:49:06 - train: epoch 0048, iter [00540, 01251], lr: 0.001167, loss: 2.2630
2022-10-08 00:49:27 - train: epoch 0048, iter [00550, 01251], lr: 0.001167, loss: 2.6943
2022-10-08 00:49:48 - train: epoch 0048, iter [00560, 01251], lr: 0.001167, loss: 3.3624
2022-10-08 00:50:09 - train: epoch 0048, iter [00570, 01251], lr: 0.001166, loss: 3.4691
2022-10-08 00:50:31 - train: epoch 0048, iter [00580, 01251], lr: 0.001166, loss: 3.0130
2022-10-08 00:50:52 - train: epoch 0048, iter [00590, 01251], lr: 0.001166, loss: 3.3853
2022-10-08 00:51:13 - train: epoch 0048, iter [00600, 01251], lr: 0.001166, loss: 2.9190
2022-10-08 00:51:34 - train: epoch 0048, iter [00610, 01251], lr: 0.001165, loss: 3.5074
2022-10-08 00:51:55 - train: epoch 0048, iter [00620, 01251], lr: 0.001165, loss: 2.8412
2022-10-08 00:52:16 - train: epoch 0048, iter [00630, 01251], lr: 0.001165, loss: 2.1804
2022-10-08 00:52:37 - train: epoch 0048, iter [00640, 01251], lr: 0.001165, loss: 3.0202
2022-10-08 00:52:58 - train: epoch 0048, iter [00650, 01251], lr: 0.001164, loss: 3.5723
2022-10-08 00:53:19 - train: epoch 0048, iter [00660, 01251], lr: 0.001164, loss: 3.2355
2022-10-08 00:53:40 - train: epoch 0048, iter [00670, 01251], lr: 0.001164, loss: 2.9661
2022-10-08 00:54:01 - train: epoch 0048, iter [00680, 01251], lr: 0.001164, loss: 3.5090
2022-10-08 00:54:23 - train: epoch 0048, iter [00690, 01251], lr: 0.001163, loss: 3.4364
2022-10-08 00:54:44 - train: epoch 0048, iter [00700, 01251], lr: 0.001163, loss: 2.1951
2022-10-08 00:55:05 - train: epoch 0048, iter [00710, 01251], lr: 0.001163, loss: 3.4897
2022-10-08 00:55:26 - train: epoch 0048, iter [00720, 01251], lr: 0.001163, loss: 3.0512
2022-10-08 00:55:47 - train: epoch 0048, iter [00730, 01251], lr: 0.001162, loss: 3.5885
2022-10-08 00:56:08 - train: epoch 0048, iter [00740, 01251], lr: 0.001162, loss: 3.7324
2022-10-08 00:56:29 - train: epoch 0048, iter [00750, 01251], lr: 0.001162, loss: 3.1884
2022-10-08 00:56:50 - train: epoch 0048, iter [00760, 01251], lr: 0.001162, loss: 2.8319
2022-10-08 00:57:11 - train: epoch 0048, iter [00770, 01251], lr: 0.001161, loss: 3.6365
2022-10-08 00:57:32 - train: epoch 0048, iter [00780, 01251], lr: 0.001161, loss: 3.6223
2022-10-08 00:57:53 - train: epoch 0048, iter [00790, 01251], lr: 0.001161, loss: 2.7400
2022-10-08 00:58:14 - train: epoch 0048, iter [00800, 01251], lr: 0.001160, loss: 2.2472
2022-10-08 00:58:35 - train: epoch 0048, iter [00810, 01251], lr: 0.001160, loss: 3.0542
2022-10-08 00:58:56 - train: epoch 0048, iter [00820, 01251], lr: 0.001160, loss: 3.1581
2022-10-08 00:59:17 - train: epoch 0048, iter [00830, 01251], lr: 0.001160, loss: 3.0829
2022-10-08 00:59:38 - train: epoch 0048, iter [00840, 01251], lr: 0.001159, loss: 3.1535
2022-10-08 00:59:59 - train: epoch 0048, iter [00850, 01251], lr: 0.001159, loss: 2.2161
2022-10-08 01:00:20 - train: epoch 0048, iter [00860, 01251], lr: 0.001159, loss: 2.7749
2022-10-08 01:00:41 - train: epoch 0048, iter [00870, 01251], lr: 0.001159, loss: 2.7299
2022-10-08 01:01:02 - train: epoch 0048, iter [00880, 01251], lr: 0.001158, loss: 3.0287
2022-10-08 01:01:23 - train: epoch 0048, iter [00890, 01251], lr: 0.001158, loss: 2.6379
2022-10-08 01:01:44 - train: epoch 0048, iter [00900, 01251], lr: 0.001158, loss: 2.8493
2022-10-08 01:02:05 - train: epoch 0048, iter [00910, 01251], lr: 0.001158, loss: 3.4608
2022-10-08 01:02:26 - train: epoch 0048, iter [00920, 01251], lr: 0.001157, loss: 2.6918
2022-10-08 01:02:47 - train: epoch 0048, iter [00930, 01251], lr: 0.001157, loss: 2.9536
2022-10-08 01:03:08 - train: epoch 0048, iter [00940, 01251], lr: 0.001157, loss: 3.1768
2022-10-08 01:03:29 - train: epoch 0048, iter [00950, 01251], lr: 0.001157, loss: 2.9185
2022-10-08 01:03:50 - train: epoch 0048, iter [00960, 01251], lr: 0.001156, loss: 3.1247
2022-10-08 01:04:11 - train: epoch 0048, iter [00970, 01251], lr: 0.001156, loss: 3.2486
2022-10-08 01:04:32 - train: epoch 0048, iter [00980, 01251], lr: 0.001156, loss: 3.0902
2022-10-08 01:04:53 - train: epoch 0048, iter [00990, 01251], lr: 0.001156, loss: 3.3875
2022-10-08 01:05:14 - train: epoch 0048, iter [01000, 01251], lr: 0.001155, loss: 2.7613
2022-10-08 01:05:35 - train: epoch 0048, iter [01010, 01251], lr: 0.001155, loss: 3.1285
2022-10-08 01:05:56 - train: epoch 0048, iter [01020, 01251], lr: 0.001155, loss: 3.5649
2022-10-08 01:06:17 - train: epoch 0048, iter [01030, 01251], lr: 0.001154, loss: 3.4962
2022-10-08 01:06:38 - train: epoch 0048, iter [01040, 01251], lr: 0.001154, loss: 3.6742
2022-10-08 01:06:59 - train: epoch 0048, iter [01050, 01251], lr: 0.001154, loss: 3.4211
2022-10-08 01:07:20 - train: epoch 0048, iter [01060, 01251], lr: 0.001154, loss: 3.4667
2022-10-08 01:07:41 - train: epoch 0048, iter [01070, 01251], lr: 0.001153, loss: 3.0000
2022-10-08 01:08:02 - train: epoch 0048, iter [01080, 01251], lr: 0.001153, loss: 3.1362
2022-10-08 01:08:23 - train: epoch 0048, iter [01090, 01251], lr: 0.001153, loss: 3.5470
2022-10-08 01:08:44 - train: epoch 0048, iter [01100, 01251], lr: 0.001153, loss: 3.1717
2022-10-08 01:09:05 - train: epoch 0048, iter [01110, 01251], lr: 0.001152, loss: 2.5451
2022-10-08 01:09:26 - train: epoch 0048, iter [01120, 01251], lr: 0.001152, loss: 3.3978
2022-10-08 01:09:47 - train: epoch 0048, iter [01130, 01251], lr: 0.001152, loss: 3.3577
2022-10-08 01:10:08 - train: epoch 0048, iter [01140, 01251], lr: 0.001152, loss: 2.9370
2022-10-08 01:10:29 - train: epoch 0048, iter [01150, 01251], lr: 0.001151, loss: 3.7112
2022-10-08 01:10:50 - train: epoch 0048, iter [01160, 01251], lr: 0.001151, loss: 3.3748
2022-10-08 01:11:11 - train: epoch 0048, iter [01170, 01251], lr: 0.001151, loss: 2.4125
2022-10-08 01:11:33 - train: epoch 0048, iter [01180, 01251], lr: 0.001151, loss: 3.3092
2022-10-08 01:11:54 - train: epoch 0048, iter [01190, 01251], lr: 0.001150, loss: 3.1491
2022-10-08 01:12:15 - train: epoch 0048, iter [01200, 01251], lr: 0.001150, loss: 3.5131
2022-10-08 01:12:36 - train: epoch 0048, iter [01210, 01251], lr: 0.001150, loss: 3.0924
2022-10-08 01:12:57 - train: epoch 0048, iter [01220, 01251], lr: 0.001149, loss: 3.5952
2022-10-08 01:13:18 - train: epoch 0048, iter [01230, 01251], lr: 0.001149, loss: 3.7208
2022-10-08 01:13:39 - train: epoch 0048, iter [01240, 01251], lr: 0.001149, loss: 3.1059
2022-10-08 01:14:00 - train: epoch 0048, iter [01250, 01251], lr: 0.001149, loss: 2.7751
2022-10-08 01:14:03 - train: epoch 048, train_loss: 3.1461
2022-10-08 01:15:19 - eval: epoch: 048, acc1: 80.394%, acc5: 95.486%, test_loss: 0.8624, per_image_load_time: 0.491ms, per_image_inference_time: 1.424ms
2022-10-08 01:15:21 - until epoch: 048, best_acc1: 80.394%
2022-10-08 01:15:21 - epoch 049 lr: 0.001149
2022-10-08 01:15:47 - train: epoch 0049, iter [00010, 01251], lr: 0.001148, loss: 2.8582
2022-10-08 01:16:08 - train: epoch 0049, iter [00020, 01251], lr: 0.001148, loss: 2.9776
2022-10-08 01:16:29 - train: epoch 0049, iter [00030, 01251], lr: 0.001148, loss: 3.2180
2022-10-08 01:16:51 - train: epoch 0049, iter [00040, 01251], lr: 0.001148, loss: 3.4660
2022-10-08 01:17:12 - train: epoch 0049, iter [00050, 01251], lr: 0.001147, loss: 3.4885
2022-10-08 01:17:33 - train: epoch 0049, iter [00060, 01251], lr: 0.001147, loss: 2.3120
2022-10-08 01:17:54 - train: epoch 0049, iter [00070, 01251], lr: 0.001147, loss: 3.1289
2022-10-08 01:18:15 - train: epoch 0049, iter [00080, 01251], lr: 0.001147, loss: 2.9551
2022-10-08 01:18:36 - train: epoch 0049, iter [00090, 01251], lr: 0.001146, loss: 3.0128
2022-10-08 01:18:57 - train: epoch 0049, iter [00100, 01251], lr: 0.001146, loss: 3.3283
2022-10-08 01:19:19 - train: epoch 0049, iter [00110, 01251], lr: 0.001146, loss: 3.5845
2022-10-08 01:19:40 - train: epoch 0049, iter [00120, 01251], lr: 0.001146, loss: 3.1056
2022-10-08 01:20:01 - train: epoch 0049, iter [00130, 01251], lr: 0.001145, loss: 3.1185
2022-10-08 01:20:22 - train: epoch 0049, iter [00140, 01251], lr: 0.001145, loss: 3.0650
2022-10-08 01:20:43 - train: epoch 0049, iter [00150, 01251], lr: 0.001145, loss: 2.7092
2022-10-08 01:21:04 - train: epoch 0049, iter [00160, 01251], lr: 0.001145, loss: 3.1779
2022-10-08 01:21:25 - train: epoch 0049, iter [00170, 01251], lr: 0.001144, loss: 2.1724
2022-10-08 01:21:47 - train: epoch 0049, iter [00180, 01251], lr: 0.001144, loss: 2.7083
2022-10-08 01:22:08 - train: epoch 0049, iter [00190, 01251], lr: 0.001144, loss: 3.4836
2022-10-08 01:22:29 - train: epoch 0049, iter [00200, 01251], lr: 0.001143, loss: 3.7668
2022-10-08 01:22:50 - train: epoch 0049, iter [00210, 01251], lr: 0.001143, loss: 2.8373
2022-10-08 01:23:11 - train: epoch 0049, iter [00220, 01251], lr: 0.001143, loss: 3.1975
2022-10-08 01:23:32 - train: epoch 0049, iter [00230, 01251], lr: 0.001143, loss: 3.3316
2022-10-08 01:23:53 - train: epoch 0049, iter [00240, 01251], lr: 0.001142, loss: 3.3367
2022-10-08 01:24:15 - train: epoch 0049, iter [00250, 01251], lr: 0.001142, loss: 3.4829
2022-10-08 01:24:36 - train: epoch 0049, iter [00260, 01251], lr: 0.001142, loss: 3.3208
2022-10-08 01:24:57 - train: epoch 0049, iter [00270, 01251], lr: 0.001142, loss: 2.8892
2022-10-08 01:25:18 - train: epoch 0049, iter [00280, 01251], lr: 0.001141, loss: 3.4999
2022-10-08 01:25:39 - train: epoch 0049, iter [00290, 01251], lr: 0.001141, loss: 3.3798
2022-10-08 01:26:00 - train: epoch 0049, iter [00300, 01251], lr: 0.001141, loss: 3.4014
2022-10-08 01:26:21 - train: epoch 0049, iter [00310, 01251], lr: 0.001141, loss: 3.2064
2022-10-08 01:26:42 - train: epoch 0049, iter [00320, 01251], lr: 0.001140, loss: 3.1729
2022-10-08 01:27:03 - train: epoch 0049, iter [00330, 01251], lr: 0.001140, loss: 3.1661
2022-10-08 01:27:25 - train: epoch 0049, iter [00340, 01251], lr: 0.001140, loss: 3.5887
2022-10-08 01:27:46 - train: epoch 0049, iter [00350, 01251], lr: 0.001140, loss: 3.5499
2022-10-08 01:28:07 - train: epoch 0049, iter [00360, 01251], lr: 0.001139, loss: 3.4479
2022-10-08 01:28:28 - train: epoch 0049, iter [00370, 01251], lr: 0.001139, loss: 2.9979
2022-10-08 01:28:49 - train: epoch 0049, iter [00380, 01251], lr: 0.001139, loss: 2.9622
2022-10-08 01:29:11 - train: epoch 0049, iter [00390, 01251], lr: 0.001138, loss: 3.1329
2022-10-08 01:29:32 - train: epoch 0049, iter [00400, 01251], lr: 0.001138, loss: 3.3745
2022-10-08 01:29:53 - train: epoch 0049, iter [00410, 01251], lr: 0.001138, loss: 3.6156
2022-10-08 01:30:14 - train: epoch 0049, iter [00420, 01251], lr: 0.001138, loss: 3.0556
2022-10-08 01:30:35 - train: epoch 0049, iter [00430, 01251], lr: 0.001137, loss: 2.8534
2022-10-08 01:30:56 - train: epoch 0049, iter [00440, 01251], lr: 0.001137, loss: 3.2179
2022-10-08 01:31:17 - train: epoch 0049, iter [00450, 01251], lr: 0.001137, loss: 2.4674
2022-10-08 01:31:38 - train: epoch 0049, iter [00460, 01251], lr: 0.001137, loss: 3.4916
2022-10-08 01:31:59 - train: epoch 0049, iter [00470, 01251], lr: 0.001136, loss: 2.7924
2022-10-08 01:32:21 - train: epoch 0049, iter [00480, 01251], lr: 0.001136, loss: 3.4844
2022-10-08 01:32:42 - train: epoch 0049, iter [00490, 01251], lr: 0.001136, loss: 2.1902
2022-10-08 01:33:03 - train: epoch 0049, iter [00500, 01251], lr: 0.001136, loss: 2.6871
2022-10-08 01:33:24 - train: epoch 0049, iter [00510, 01251], lr: 0.001135, loss: 3.3569
2022-10-08 01:33:45 - train: epoch 0049, iter [00520, 01251], lr: 0.001135, loss: 3.4600
2022-10-08 01:34:06 - train: epoch 0049, iter [00530, 01251], lr: 0.001135, loss: 3.5449
2022-10-08 01:34:27 - train: epoch 0049, iter [00540, 01251], lr: 0.001135, loss: 2.4036
2022-10-08 01:34:49 - train: epoch 0049, iter [00550, 01251], lr: 0.001134, loss: 3.1201
2022-10-08 01:35:10 - train: epoch 0049, iter [00560, 01251], lr: 0.001134, loss: 3.4743
2022-10-08 01:35:31 - train: epoch 0049, iter [00570, 01251], lr: 0.001134, loss: 3.0747
2022-10-08 01:35:52 - train: epoch 0049, iter [00580, 01251], lr: 0.001134, loss: 3.4852
2022-10-08 01:36:13 - train: epoch 0049, iter [00590, 01251], lr: 0.001133, loss: 3.0355
2022-10-08 01:36:34 - train: epoch 0049, iter [00600, 01251], lr: 0.001133, loss: 2.7636
2022-10-08 01:36:55 - train: epoch 0049, iter [00610, 01251], lr: 0.001133, loss: 3.3321
2022-10-08 01:37:16 - train: epoch 0049, iter [00620, 01251], lr: 0.001132, loss: 3.2558
2022-10-08 01:37:37 - train: epoch 0049, iter [00630, 01251], lr: 0.001132, loss: 3.1522
2022-10-08 01:37:58 - train: epoch 0049, iter [00640, 01251], lr: 0.001132, loss: 3.4536
2022-10-08 01:38:20 - train: epoch 0049, iter [00650, 01251], lr: 0.001132, loss: 3.4525
2022-10-08 01:38:41 - train: epoch 0049, iter [00660, 01251], lr: 0.001131, loss: 3.3527
2022-10-08 01:39:02 - train: epoch 0049, iter [00670, 01251], lr: 0.001131, loss: 3.0755
2022-10-08 01:39:23 - train: epoch 0049, iter [00680, 01251], lr: 0.001131, loss: 3.3503
2022-10-08 01:39:44 - train: epoch 0049, iter [00690, 01251], lr: 0.001131, loss: 3.1238
2022-10-08 01:40:05 - train: epoch 0049, iter [00700, 01251], lr: 0.001130, loss: 2.2920
2022-10-08 01:40:27 - train: epoch 0049, iter [00710, 01251], lr: 0.001130, loss: 3.1314
2022-10-08 01:40:48 - train: epoch 0049, iter [00720, 01251], lr: 0.001130, loss: 3.5352
2022-10-08 01:41:09 - train: epoch 0049, iter [00730, 01251], lr: 0.001130, loss: 2.9786
2022-10-08 01:41:30 - train: epoch 0049, iter [00740, 01251], lr: 0.001129, loss: 3.5460
2022-10-08 01:41:51 - train: epoch 0049, iter [00750, 01251], lr: 0.001129, loss: 3.3966
2022-10-08 01:42:12 - train: epoch 0049, iter [00760, 01251], lr: 0.001129, loss: 2.8372
2022-10-08 01:42:33 - train: epoch 0049, iter [00770, 01251], lr: 0.001129, loss: 2.7073
2022-10-08 01:42:55 - train: epoch 0049, iter [00780, 01251], lr: 0.001128, loss: 2.5807
2022-10-08 01:43:16 - train: epoch 0049, iter [00790, 01251], lr: 0.001128, loss: 3.3576
2022-10-08 01:43:37 - train: epoch 0049, iter [00800, 01251], lr: 0.001128, loss: 3.0621
2022-10-08 01:43:58 - train: epoch 0049, iter [00810, 01251], lr: 0.001127, loss: 3.1402
2022-10-08 01:44:19 - train: epoch 0049, iter [00820, 01251], lr: 0.001127, loss: 3.5060
2022-10-08 01:44:40 - train: epoch 0049, iter [00830, 01251], lr: 0.001127, loss: 3.5300
2022-10-08 01:45:02 - train: epoch 0049, iter [00840, 01251], lr: 0.001127, loss: 3.4928
2022-10-08 01:45:23 - train: epoch 0049, iter [00850, 01251], lr: 0.001126, loss: 2.2430
2022-10-08 01:45:44 - train: epoch 0049, iter [00860, 01251], lr: 0.001126, loss: 3.3523
2022-10-08 01:46:05 - train: epoch 0049, iter [00870, 01251], lr: 0.001126, loss: 3.4364
2022-10-08 01:46:26 - train: epoch 0049, iter [00880, 01251], lr: 0.001126, loss: 3.2019
2022-10-08 01:46:47 - train: epoch 0049, iter [00890, 01251], lr: 0.001125, loss: 3.3284
2022-10-08 01:47:08 - train: epoch 0049, iter [00900, 01251], lr: 0.001125, loss: 3.3336
2022-10-08 01:47:29 - train: epoch 0049, iter [00910, 01251], lr: 0.001125, loss: 2.5506
2022-10-08 01:47:51 - train: epoch 0049, iter [00920, 01251], lr: 0.001125, loss: 2.6251
2022-10-08 01:48:12 - train: epoch 0049, iter [00930, 01251], lr: 0.001124, loss: 2.8314
2022-10-08 01:48:33 - train: epoch 0049, iter [00940, 01251], lr: 0.001124, loss: 3.6932
2022-10-08 01:48:54 - train: epoch 0049, iter [00950, 01251], lr: 0.001124, loss: 2.7434
2022-10-08 01:49:15 - train: epoch 0049, iter [00960, 01251], lr: 0.001124, loss: 3.3666
2022-10-08 01:49:36 - train: epoch 0049, iter [00970, 01251], lr: 0.001123, loss: 2.8049
2022-10-08 01:49:57 - train: epoch 0049, iter [00980, 01251], lr: 0.001123, loss: 3.7215
2022-10-08 01:50:19 - train: epoch 0049, iter [00990, 01251], lr: 0.001123, loss: 3.4561
2022-10-08 01:50:40 - train: epoch 0049, iter [01000, 01251], lr: 0.001123, loss: 2.9930
2022-10-08 01:51:01 - train: epoch 0049, iter [01010, 01251], lr: 0.001122, loss: 2.8867
2022-10-08 01:51:22 - train: epoch 0049, iter [01020, 01251], lr: 0.001122, loss: 3.4290
2022-10-08 01:51:43 - train: epoch 0049, iter [01030, 01251], lr: 0.001122, loss: 2.2846
2022-10-08 01:52:04 - train: epoch 0049, iter [01040, 01251], lr: 0.001121, loss: 3.1804
2022-10-08 01:52:25 - train: epoch 0049, iter [01050, 01251], lr: 0.001121, loss: 3.2108
2022-10-08 01:52:47 - train: epoch 0049, iter [01060, 01251], lr: 0.001121, loss: 2.9602
2022-10-08 01:53:08 - train: epoch 0049, iter [01070, 01251], lr: 0.001121, loss: 2.9757
2022-10-08 01:53:29 - train: epoch 0049, iter [01080, 01251], lr: 0.001120, loss: 3.3230
2022-10-08 01:53:50 - train: epoch 0049, iter [01090, 01251], lr: 0.001120, loss: 3.3848
2022-10-08 01:54:11 - train: epoch 0049, iter [01100, 01251], lr: 0.001120, loss: 3.1230
2022-10-08 01:54:32 - train: epoch 0049, iter [01110, 01251], lr: 0.001120, loss: 3.0807
2022-10-08 01:54:53 - train: epoch 0049, iter [01120, 01251], lr: 0.001119, loss: 3.0405
2022-10-08 01:55:14 - train: epoch 0049, iter [01130, 01251], lr: 0.001119, loss: 3.4681
2022-10-08 01:55:35 - train: epoch 0049, iter [01140, 01251], lr: 0.001119, loss: 3.2806
2022-10-08 01:55:56 - train: epoch 0049, iter [01150, 01251], lr: 0.001119, loss: 2.5694
2022-10-08 01:56:18 - train: epoch 0049, iter [01160, 01251], lr: 0.001118, loss: 3.5271
2022-10-08 01:56:39 - train: epoch 0049, iter [01170, 01251], lr: 0.001118, loss: 3.5139
2022-10-08 01:57:00 - train: epoch 0049, iter [01180, 01251], lr: 0.001118, loss: 2.9886
2022-10-08 01:57:21 - train: epoch 0049, iter [01190, 01251], lr: 0.001118, loss: 2.9628
2022-10-08 01:57:42 - train: epoch 0049, iter [01200, 01251], lr: 0.001117, loss: 2.2840
2022-10-08 01:58:03 - train: epoch 0049, iter [01210, 01251], lr: 0.001117, loss: 2.7604
2022-10-08 01:58:24 - train: epoch 0049, iter [01220, 01251], lr: 0.001117, loss: 3.3485
2022-10-08 01:58:45 - train: epoch 0049, iter [01230, 01251], lr: 0.001116, loss: 2.5919
2022-10-08 01:59:06 - train: epoch 0049, iter [01240, 01251], lr: 0.001116, loss: 3.3157
2022-10-08 01:59:27 - train: epoch 0049, iter [01250, 01251], lr: 0.001116, loss: 3.4098
2022-10-08 01:59:31 - train: epoch 049, train_loss: 3.1257
2022-10-08 02:00:47 - eval: epoch: 049, acc1: 80.482%, acc5: 95.532%, test_loss: 0.8733, per_image_load_time: 1.446ms, per_image_inference_time: 1.423ms
2022-10-08 02:00:49 - until epoch: 049, best_acc1: 80.482%
2022-10-08 02:00:49 - epoch 050 lr: 0.001116
2022-10-08 02:01:15 - train: epoch 0050, iter [00010, 01251], lr: 0.001116, loss: 2.9309
2022-10-08 02:01:37 - train: epoch 0050, iter [00020, 01251], lr: 0.001115, loss: 3.4570
2022-10-08 02:01:58 - train: epoch 0050, iter [00030, 01251], lr: 0.001115, loss: 3.3834
2022-10-08 02:02:19 - train: epoch 0050, iter [00040, 01251], lr: 0.001115, loss: 3.1014
2022-10-08 02:02:41 - train: epoch 0050, iter [00050, 01251], lr: 0.001115, loss: 3.1251
2022-10-08 02:03:02 - train: epoch 0050, iter [00060, 01251], lr: 0.001114, loss: 3.0988
2022-10-08 02:03:23 - train: epoch 0050, iter [00070, 01251], lr: 0.001114, loss: 2.8261
2022-10-08 02:03:44 - train: epoch 0050, iter [00080, 01251], lr: 0.001114, loss: 3.3455
2022-10-08 02:04:06 - train: epoch 0050, iter [00090, 01251], lr: 0.001114, loss: 3.0679
2022-10-08 02:04:27 - train: epoch 0050, iter [00100, 01251], lr: 0.001113, loss: 3.4548
2022-10-08 02:04:48 - train: epoch 0050, iter [00110, 01251], lr: 0.001113, loss: 2.8762
2022-10-08 02:05:10 - train: epoch 0050, iter [00120, 01251], lr: 0.001113, loss: 3.2140
2022-10-08 02:05:31 - train: epoch 0050, iter [00130, 01251], lr: 0.001113, loss: 2.6866
2022-10-08 02:05:52 - train: epoch 0050, iter [00140, 01251], lr: 0.001112, loss: 3.5310
2022-10-08 02:06:13 - train: epoch 0050, iter [00150, 01251], lr: 0.001112, loss: 2.8840
2022-10-08 02:06:35 - train: epoch 0050, iter [00160, 01251], lr: 0.001112, loss: 3.1055
2022-10-08 02:06:56 - train: epoch 0050, iter [00170, 01251], lr: 0.001111, loss: 3.3241
2022-10-08 02:07:17 - train: epoch 0050, iter [00180, 01251], lr: 0.001111, loss: 3.3565
2022-10-08 02:07:38 - train: epoch 0050, iter [00190, 01251], lr: 0.001111, loss: 2.8447
2022-10-08 02:07:59 - train: epoch 0050, iter [00200, 01251], lr: 0.001111, loss: 2.7968
2022-10-08 02:08:20 - train: epoch 0050, iter [00210, 01251], lr: 0.001110, loss: 2.8522
2022-10-08 02:08:42 - train: epoch 0050, iter [00220, 01251], lr: 0.001110, loss: 3.5021
2022-10-08 02:09:03 - train: epoch 0050, iter [00230, 01251], lr: 0.001110, loss: 3.4123
2022-10-08 02:09:24 - train: epoch 0050, iter [00240, 01251], lr: 0.001110, loss: 3.2994
2022-10-08 02:09:45 - train: epoch 0050, iter [00250, 01251], lr: 0.001109, loss: 3.1400
2022-10-08 02:10:06 - train: epoch 0050, iter [00260, 01251], lr: 0.001109, loss: 3.0696
2022-10-08 02:10:27 - train: epoch 0050, iter [00270, 01251], lr: 0.001109, loss: 3.1741
2022-10-08 02:10:48 - train: epoch 0050, iter [00280, 01251], lr: 0.001109, loss: 3.5946
2022-10-08 02:11:09 - train: epoch 0050, iter [00290, 01251], lr: 0.001108, loss: 2.5441
2022-10-08 02:11:31 - train: epoch 0050, iter [00300, 01251], lr: 0.001108, loss: 3.3204
2022-10-08 02:11:52 - train: epoch 0050, iter [00310, 01251], lr: 0.001108, loss: 3.0905
2022-10-08 02:12:13 - train: epoch 0050, iter [00320, 01251], lr: 0.001108, loss: 3.1323
2022-10-08 02:12:34 - train: epoch 0050, iter [00330, 01251], lr: 0.001107, loss: 2.9747
2022-10-08 02:12:55 - train: epoch 0050, iter [00340, 01251], lr: 0.001107, loss: 2.9375
2022-10-08 02:13:16 - train: epoch 0050, iter [00350, 01251], lr: 0.001107, loss: 3.6156
2022-10-08 02:13:37 - train: epoch 0050, iter [00360, 01251], lr: 0.001106, loss: 2.7012
2022-10-08 02:13:58 - train: epoch 0050, iter [00370, 01251], lr: 0.001106, loss: 3.2222
2022-10-08 02:14:19 - train: epoch 0050, iter [00380, 01251], lr: 0.001106, loss: 2.7368
2022-10-08 02:14:41 - train: epoch 0050, iter [00390, 01251], lr: 0.001106, loss: 3.1822
2022-10-08 02:15:02 - train: epoch 0050, iter [00400, 01251], lr: 0.001105, loss: 2.9076
2022-10-08 02:15:23 - train: epoch 0050, iter [00410, 01251], lr: 0.001105, loss: 3.7283
2022-10-08 02:15:44 - train: epoch 0050, iter [00420, 01251], lr: 0.001105, loss: 3.0934
2022-10-08 02:16:05 - train: epoch 0050, iter [00430, 01251], lr: 0.001105, loss: 2.5282
2022-10-08 02:16:26 - train: epoch 0050, iter [00440, 01251], lr: 0.001104, loss: 3.4496
2022-10-08 02:16:47 - train: epoch 0050, iter [00450, 01251], lr: 0.001104, loss: 3.8507
2022-10-08 02:17:08 - train: epoch 0050, iter [00460, 01251], lr: 0.001104, loss: 3.4128
2022-10-08 02:17:29 - train: epoch 0050, iter [00470, 01251], lr: 0.001104, loss: 3.1906
2022-10-08 02:17:50 - train: epoch 0050, iter [00480, 01251], lr: 0.001103, loss: 3.4594
2022-10-08 02:18:12 - train: epoch 0050, iter [00490, 01251], lr: 0.001103, loss: 3.4749
2022-10-08 02:18:33 - train: epoch 0050, iter [00500, 01251], lr: 0.001103, loss: 3.0378
2022-10-08 02:18:54 - train: epoch 0050, iter [00510, 01251], lr: 0.001103, loss: 3.0641
2022-10-08 02:19:15 - train: epoch 0050, iter [00520, 01251], lr: 0.001102, loss: 2.6780
2022-10-08 02:19:36 - train: epoch 0050, iter [00530, 01251], lr: 0.001102, loss: 2.6978
2022-10-08 02:19:57 - train: epoch 0050, iter [00540, 01251], lr: 0.001102, loss: 2.7896
2022-10-08 02:20:18 - train: epoch 0050, iter [00550, 01251], lr: 0.001101, loss: 3.2707
2022-10-08 02:20:39 - train: epoch 0050, iter [00560, 01251], lr: 0.001101, loss: 3.0340
2022-10-08 02:21:00 - train: epoch 0050, iter [00570, 01251], lr: 0.001101, loss: 2.8004
2022-10-08 02:21:21 - train: epoch 0050, iter [00580, 01251], lr: 0.001101, loss: 3.1848
2022-10-08 02:21:42 - train: epoch 0050, iter [00590, 01251], lr: 0.001100, loss: 3.4632
2022-10-08 02:22:03 - train: epoch 0050, iter [00600, 01251], lr: 0.001100, loss: 3.8217
2022-10-08 02:22:24 - train: epoch 0050, iter [00610, 01251], lr: 0.001100, loss: 2.6911
2022-10-08 02:22:46 - train: epoch 0050, iter [00620, 01251], lr: 0.001100, loss: 3.4602
2022-10-08 02:23:07 - train: epoch 0050, iter [00630, 01251], lr: 0.001099, loss: 2.7759
2022-10-08 02:23:28 - train: epoch 0050, iter [00640, 01251], lr: 0.001099, loss: 3.1161
2022-10-08 02:23:49 - train: epoch 0050, iter [00650, 01251], lr: 0.001099, loss: 3.2332
2022-10-08 02:24:10 - train: epoch 0050, iter [00660, 01251], lr: 0.001099, loss: 2.8956
2022-10-08 02:24:31 - train: epoch 0050, iter [00670, 01251], lr: 0.001098, loss: 2.8483
2022-10-08 02:24:52 - train: epoch 0050, iter [00680, 01251], lr: 0.001098, loss: 2.8348
2022-10-08 02:25:13 - train: epoch 0050, iter [00690, 01251], lr: 0.001098, loss: 3.2105
2022-10-08 02:25:34 - train: epoch 0050, iter [00700, 01251], lr: 0.001098, loss: 3.4379
2022-10-08 02:25:55 - train: epoch 0050, iter [00710, 01251], lr: 0.001097, loss: 3.1060
2022-10-08 02:26:16 - train: epoch 0050, iter [00720, 01251], lr: 0.001097, loss: 3.5238
2022-10-08 02:26:37 - train: epoch 0050, iter [00730, 01251], lr: 0.001097, loss: 2.6497
2022-10-08 02:26:58 - train: epoch 0050, iter [00740, 01251], lr: 0.001096, loss: 3.2306
2022-10-08 02:27:19 - train: epoch 0050, iter [00750, 01251], lr: 0.001096, loss: 3.3338
2022-10-08 02:27:40 - train: epoch 0050, iter [00760, 01251], lr: 0.001096, loss: 3.4464
2022-10-08 02:28:01 - train: epoch 0050, iter [00770, 01251], lr: 0.001096, loss: 2.8571
2022-10-08 02:28:23 - train: epoch 0050, iter [00780, 01251], lr: 0.001095, loss: 3.7271
2022-10-08 02:28:44 - train: epoch 0050, iter [00790, 01251], lr: 0.001095, loss: 3.5424
2022-10-08 02:29:05 - train: epoch 0050, iter [00800, 01251], lr: 0.001095, loss: 3.3983
2022-10-08 02:29:26 - train: epoch 0050, iter [00810, 01251], lr: 0.001095, loss: 2.8795
2022-10-08 02:29:47 - train: epoch 0050, iter [00820, 01251], lr: 0.001094, loss: 2.7186
2022-10-08 02:30:08 - train: epoch 0050, iter [00830, 01251], lr: 0.001094, loss: 3.2806
2022-10-08 02:30:29 - train: epoch 0050, iter [00840, 01251], lr: 0.001094, loss: 3.4266
2022-10-08 02:30:50 - train: epoch 0050, iter [00850, 01251], lr: 0.001094, loss: 3.1331
2022-10-08 02:31:11 - train: epoch 0050, iter [00860, 01251], lr: 0.001093, loss: 3.2476
2022-10-08 02:31:32 - train: epoch 0050, iter [00870, 01251], lr: 0.001093, loss: 3.2306
2022-10-08 02:31:53 - train: epoch 0050, iter [00880, 01251], lr: 0.001093, loss: 3.7074
2022-10-08 02:32:14 - train: epoch 0050, iter [00890, 01251], lr: 0.001093, loss: 3.4234
2022-10-08 02:32:35 - train: epoch 0050, iter [00900, 01251], lr: 0.001092, loss: 3.1874
2022-10-08 02:32:56 - train: epoch 0050, iter [00910, 01251], lr: 0.001092, loss: 3.0284
2022-10-08 02:33:17 - train: epoch 0050, iter [00920, 01251], lr: 0.001092, loss: 2.7771
2022-10-08 02:33:38 - train: epoch 0050, iter [00930, 01251], lr: 0.001091, loss: 3.0640
2022-10-08 02:33:59 - train: epoch 0050, iter [00940, 01251], lr: 0.001091, loss: 3.2538
2022-10-08 02:34:20 - train: epoch 0050, iter [00950, 01251], lr: 0.001091, loss: 3.2863
2022-10-08 02:34:41 - train: epoch 0050, iter [00960, 01251], lr: 0.001091, loss: 3.2970
2022-10-08 02:35:02 - train: epoch 0050, iter [00970, 01251], lr: 0.001090, loss: 2.4968
2022-10-08 02:35:23 - train: epoch 0050, iter [00980, 01251], lr: 0.001090, loss: 2.9690
2022-10-08 02:35:44 - train: epoch 0050, iter [00990, 01251], lr: 0.001090, loss: 3.3721
2022-10-08 02:36:05 - train: epoch 0050, iter [01000, 01251], lr: 0.001090, loss: 3.4319
2022-10-08 02:36:26 - train: epoch 0050, iter [01010, 01251], lr: 0.001089, loss: 3.1619
2022-10-08 02:36:47 - train: epoch 0050, iter [01020, 01251], lr: 0.001089, loss: 2.7704
2022-10-08 02:37:09 - train: epoch 0050, iter [01030, 01251], lr: 0.001089, loss: 2.4978
2022-10-08 02:37:30 - train: epoch 0050, iter [01040, 01251], lr: 0.001089, loss: 2.9805
2022-10-08 02:37:51 - train: epoch 0050, iter [01050, 01251], lr: 0.001088, loss: 3.3882
2022-10-08 02:38:12 - train: epoch 0050, iter [01060, 01251], lr: 0.001088, loss: 3.0176
2022-10-08 02:38:33 - train: epoch 0050, iter [01070, 01251], lr: 0.001088, loss: 3.4026
2022-10-08 02:38:54 - train: epoch 0050, iter [01080, 01251], lr: 0.001088, loss: 3.2473
2022-10-08 02:39:15 - train: epoch 0050, iter [01090, 01251], lr: 0.001087, loss: 3.6009
2022-10-08 02:39:36 - train: epoch 0050, iter [01100, 01251], lr: 0.001087, loss: 3.3534
2022-10-08 02:39:57 - train: epoch 0050, iter [01110, 01251], lr: 0.001087, loss: 2.8534
2022-10-08 02:40:18 - train: epoch 0050, iter [01120, 01251], lr: 0.001086, loss: 3.1885
2022-10-08 02:40:39 - train: epoch 0050, iter [01130, 01251], lr: 0.001086, loss: 2.9187
2022-10-08 02:41:00 - train: epoch 0050, iter [01140, 01251], lr: 0.001086, loss: 3.2306
2022-10-08 02:41:21 - train: epoch 0050, iter [01150, 01251], lr: 0.001086, loss: 3.2750
2022-10-08 02:41:42 - train: epoch 0050, iter [01160, 01251], lr: 0.001085, loss: 2.0709
2022-10-08 02:42:03 - train: epoch 0050, iter [01170, 01251], lr: 0.001085, loss: 3.2087
2022-10-08 02:42:24 - train: epoch 0050, iter [01180, 01251], lr: 0.001085, loss: 2.8740
2022-10-08 02:42:45 - train: epoch 0050, iter [01190, 01251], lr: 0.001085, loss: 3.3807
2022-10-08 02:43:06 - train: epoch 0050, iter [01200, 01251], lr: 0.001084, loss: 2.9830
2022-10-08 02:43:27 - train: epoch 0050, iter [01210, 01251], lr: 0.001084, loss: 3.5812
2022-10-08 02:43:49 - train: epoch 0050, iter [01220, 01251], lr: 0.001084, loss: 3.3720
2022-10-08 02:44:10 - train: epoch 0050, iter [01230, 01251], lr: 0.001084, loss: 2.6563
2022-10-08 02:44:31 - train: epoch 0050, iter [01240, 01251], lr: 0.001083, loss: 3.4316
2022-10-08 02:44:51 - train: epoch 0050, iter [01250, 01251], lr: 0.001083, loss: 3.4435
2022-10-08 02:44:55 - train: epoch 050, train_loss: 3.1162
2022-10-08 02:46:13 - eval: epoch: 050, acc1: 80.562%, acc5: 95.570%, test_loss: 0.8377, per_image_load_time: 1.503ms, per_image_inference_time: 1.433ms
2022-10-08 02:46:14 - until epoch: 050, best_acc1: 80.562%
2022-10-08 02:46:14 - epoch 051 lr: 0.001083
2022-10-08 02:46:41 - train: epoch 0051, iter [00010, 01251], lr: 0.001083, loss: 2.9211
2022-10-08 02:47:02 - train: epoch 0051, iter [00020, 01251], lr: 0.001083, loss: 2.9649
2022-10-08 02:47:23 - train: epoch 0051, iter [00030, 01251], lr: 0.001082, loss: 3.4436
2022-10-08 02:47:44 - train: epoch 0051, iter [00040, 01251], lr: 0.001082, loss: 2.9984
2022-10-08 02:48:05 - train: epoch 0051, iter [00050, 01251], lr: 0.001082, loss: 3.4792
2022-10-08 02:48:27 - train: epoch 0051, iter [00060, 01251], lr: 0.001081, loss: 3.2267
2022-10-08 02:48:48 - train: epoch 0051, iter [00070, 01251], lr: 0.001081, loss: 3.3856
2022-10-08 02:49:09 - train: epoch 0051, iter [00080, 01251], lr: 0.001081, loss: 3.2748
2022-10-08 02:49:30 - train: epoch 0051, iter [00090, 01251], lr: 0.001081, loss: 3.0950
2022-10-08 02:49:51 - train: epoch 0051, iter [00100, 01251], lr: 0.001080, loss: 2.8107
2022-10-08 02:50:13 - train: epoch 0051, iter [00110, 01251], lr: 0.001080, loss: 3.4274
2022-10-08 02:50:34 - train: epoch 0051, iter [00120, 01251], lr: 0.001080, loss: 2.4732
2022-10-08 02:50:55 - train: epoch 0051, iter [00130, 01251], lr: 0.001080, loss: 2.6871
2022-10-08 02:51:16 - train: epoch 0051, iter [00140, 01251], lr: 0.001079, loss: 3.2913
2022-10-08 02:51:37 - train: epoch 0051, iter [00150, 01251], lr: 0.001079, loss: 3.1916
2022-10-08 02:51:58 - train: epoch 0051, iter [00160, 01251], lr: 0.001079, loss: 3.1399
2022-10-08 02:52:19 - train: epoch 0051, iter [00170, 01251], lr: 0.001079, loss: 2.8577
2022-10-08 02:52:41 - train: epoch 0051, iter [00180, 01251], lr: 0.001078, loss: 2.9536
2022-10-08 02:53:02 - train: epoch 0051, iter [00190, 01251], lr: 0.001078, loss: 2.8343
2022-10-08 02:53:23 - train: epoch 0051, iter [00200, 01251], lr: 0.001078, loss: 3.3669
2022-10-08 02:53:44 - train: epoch 0051, iter [00210, 01251], lr: 0.001078, loss: 3.2321
2022-10-08 02:54:05 - train: epoch 0051, iter [00220, 01251], lr: 0.001077, loss: 2.9555
2022-10-08 02:54:26 - train: epoch 0051, iter [00230, 01251], lr: 0.001077, loss: 3.2621
2022-10-08 02:54:47 - train: epoch 0051, iter [00240, 01251], lr: 0.001077, loss: 3.5898
2022-10-08 02:55:09 - train: epoch 0051, iter [00250, 01251], lr: 0.001076, loss: 3.1059
2022-10-08 02:55:30 - train: epoch 0051, iter [00260, 01251], lr: 0.001076, loss: 2.7286
2022-10-08 02:55:51 - train: epoch 0051, iter [00270, 01251], lr: 0.001076, loss: 3.2235
2022-10-08 02:56:12 - train: epoch 0051, iter [00280, 01251], lr: 0.001076, loss: 3.1935
2022-10-08 02:56:33 - train: epoch 0051, iter [00290, 01251], lr: 0.001075, loss: 2.7955
2022-10-08 02:56:54 - train: epoch 0051, iter [00300, 01251], lr: 0.001075, loss: 2.7165
2022-10-08 02:57:15 - train: epoch 0051, iter [00310, 01251], lr: 0.001075, loss: 2.6748
2022-10-08 02:57:36 - train: epoch 0051, iter [00320, 01251], lr: 0.001075, loss: 2.8117
2022-10-08 02:57:57 - train: epoch 0051, iter [00330, 01251], lr: 0.001074, loss: 2.6386
2022-10-08 02:58:18 - train: epoch 0051, iter [00340, 01251], lr: 0.001074, loss: 2.9132
2022-10-08 02:58:40 - train: epoch 0051, iter [00350, 01251], lr: 0.001074, loss: 2.9267
2022-10-08 02:59:01 - train: epoch 0051, iter [00360, 01251], lr: 0.001074, loss: 3.2539
2022-10-08 02:59:22 - train: epoch 0051, iter [00370, 01251], lr: 0.001073, loss: 3.2793
2022-10-08 02:59:43 - train: epoch 0051, iter [00380, 01251], lr: 0.001073, loss: 3.3735
2022-10-08 03:00:04 - train: epoch 0051, iter [00390, 01251], lr: 0.001073, loss: 3.2884
2022-10-08 03:00:25 - train: epoch 0051, iter [00400, 01251], lr: 0.001073, loss: 3.1046
2022-10-08 03:00:46 - train: epoch 0051, iter [00410, 01251], lr: 0.001072, loss: 3.3198
2022-10-08 03:01:07 - train: epoch 0051, iter [00420, 01251], lr: 0.001072, loss: 3.3581
2022-10-08 03:01:28 - train: epoch 0051, iter [00430, 01251], lr: 0.001072, loss: 3.4190
2022-10-08 03:01:49 - train: epoch 0051, iter [00440, 01251], lr: 0.001071, loss: 3.1259
2022-10-08 03:02:10 - train: epoch 0051, iter [00450, 01251], lr: 0.001071, loss: 3.3973
2022-10-08 03:02:31 - train: epoch 0051, iter [00460, 01251], lr: 0.001071, loss: 3.5269
2022-10-08 03:02:52 - train: epoch 0051, iter [00470, 01251], lr: 0.001071, loss: 3.3567
2022-10-08 03:03:13 - train: epoch 0051, iter [00480, 01251], lr: 0.001070, loss: 3.2396
2022-10-08 03:03:35 - train: epoch 0051, iter [00490, 01251], lr: 0.001070, loss: 3.2314
2022-10-08 03:03:56 - train: epoch 0051, iter [00500, 01251], lr: 0.001070, loss: 2.9408
2022-10-08 03:04:17 - train: epoch 0051, iter [00510, 01251], lr: 0.001070, loss: 3.1853
2022-10-08 03:04:38 - train: epoch 0051, iter [00520, 01251], lr: 0.001069, loss: 3.5418
2022-10-08 03:04:59 - train: epoch 0051, iter [00530, 01251], lr: 0.001069, loss: 3.2437
2022-10-08 03:05:20 - train: epoch 0051, iter [00540, 01251], lr: 0.001069, loss: 3.5429
2022-10-08 03:05:41 - train: epoch 0051, iter [00550, 01251], lr: 0.001069, loss: 3.5849
2022-10-08 03:06:02 - train: epoch 0051, iter [00560, 01251], lr: 0.001068, loss: 3.5612
2022-10-08 03:06:23 - train: epoch 0051, iter [00570, 01251], lr: 0.001068, loss: 2.7942
2022-10-08 03:06:44 - train: epoch 0051, iter [00580, 01251], lr: 0.001068, loss: 3.4539
2022-10-08 03:07:05 - train: epoch 0051, iter [00590, 01251], lr: 0.001067, loss: 3.0248
2022-10-08 03:07:26 - train: epoch 0051, iter [00600, 01251], lr: 0.001067, loss: 3.1187
2022-10-08 03:07:48 - train: epoch 0051, iter [00610, 01251], lr: 0.001067, loss: 3.2825
2022-10-08 03:08:09 - train: epoch 0051, iter [00620, 01251], lr: 0.001067, loss: 3.1853
2022-10-08 03:08:30 - train: epoch 0051, iter [00630, 01251], lr: 0.001066, loss: 2.8134
2022-10-08 03:08:51 - train: epoch 0051, iter [00640, 01251], lr: 0.001066, loss: 2.8468
2022-10-08 03:09:12 - train: epoch 0051, iter [00650, 01251], lr: 0.001066, loss: 3.0460
2022-10-08 03:09:33 - train: epoch 0051, iter [00660, 01251], lr: 0.001066, loss: 2.7245
2022-10-08 03:09:54 - train: epoch 0051, iter [00670, 01251], lr: 0.001065, loss: 3.0751
2022-10-08 03:10:15 - train: epoch 0051, iter [00680, 01251], lr: 0.001065, loss: 2.9851
2022-10-08 03:10:36 - train: epoch 0051, iter [00690, 01251], lr: 0.001065, loss: 2.8477
2022-10-08 03:10:57 - train: epoch 0051, iter [00700, 01251], lr: 0.001065, loss: 3.0282
2022-10-08 03:11:19 - train: epoch 0051, iter [00710, 01251], lr: 0.001064, loss: 2.7234
2022-10-08 03:11:40 - train: epoch 0051, iter [00720, 01251], lr: 0.001064, loss: 3.3148
2022-10-08 03:12:01 - train: epoch 0051, iter [00730, 01251], lr: 0.001064, loss: 3.1510
2022-10-08 03:12:22 - train: epoch 0051, iter [00740, 01251], lr: 0.001064, loss: 3.3405
2022-10-08 03:12:43 - train: epoch 0051, iter [00750, 01251], lr: 0.001063, loss: 3.0094
2022-10-08 03:13:04 - train: epoch 0051, iter [00760, 01251], lr: 0.001063, loss: 3.0894
2022-10-08 03:13:25 - train: epoch 0051, iter [00770, 01251], lr: 0.001063, loss: 2.2594
2022-10-08 03:13:46 - train: epoch 0051, iter [00780, 01251], lr: 0.001062, loss: 3.4527
2022-10-08 03:14:07 - train: epoch 0051, iter [00790, 01251], lr: 0.001062, loss: 3.6204
2022-10-08 03:14:28 - train: epoch 0051, iter [00800, 01251], lr: 0.001062, loss: 3.2620
2022-10-08 03:14:49 - train: epoch 0051, iter [00810, 01251], lr: 0.001062, loss: 3.3049
2022-10-08 03:15:10 - train: epoch 0051, iter [00820, 01251], lr: 0.001061, loss: 3.4137
2022-10-08 03:15:31 - train: epoch 0051, iter [00830, 01251], lr: 0.001061, loss: 3.2584
2022-10-08 03:15:53 - train: epoch 0051, iter [00840, 01251], lr: 0.001061, loss: 3.1081
2022-10-08 03:16:14 - train: epoch 0051, iter [00850, 01251], lr: 0.001061, loss: 3.1821
2022-10-08 03:16:35 - train: epoch 0051, iter [00860, 01251], lr: 0.001060, loss: 2.7190
2022-10-08 03:16:56 - train: epoch 0051, iter [00870, 01251], lr: 0.001060, loss: 3.1526
2022-10-08 03:17:17 - train: epoch 0051, iter [00880, 01251], lr: 0.001060, loss: 3.1812
2022-10-08 03:17:38 - train: epoch 0051, iter [00890, 01251], lr: 0.001060, loss: 3.4275
2022-10-08 03:17:59 - train: epoch 0051, iter [00900, 01251], lr: 0.001059, loss: 3.2204
2022-10-08 03:18:20 - train: epoch 0051, iter [00910, 01251], lr: 0.001059, loss: 3.3542
2022-10-08 03:18:41 - train: epoch 0051, iter [00920, 01251], lr: 0.001059, loss: 3.1342
2022-10-08 03:19:02 - train: epoch 0051, iter [00930, 01251], lr: 0.001059, loss: 3.5226
2022-10-08 03:19:23 - train: epoch 0051, iter [00940, 01251], lr: 0.001058, loss: 3.0257
2022-10-08 03:19:44 - train: epoch 0051, iter [00950, 01251], lr: 0.001058, loss: 3.4671
2022-10-08 03:20:05 - train: epoch 0051, iter [00960, 01251], lr: 0.001058, loss: 2.6559
2022-10-08 03:20:27 - train: epoch 0051, iter [00970, 01251], lr: 0.001057, loss: 3.0591
2022-10-08 03:20:48 - train: epoch 0051, iter [00980, 01251], lr: 0.001057, loss: 3.4215
2022-10-08 03:21:09 - train: epoch 0051, iter [00990, 01251], lr: 0.001057, loss: 3.2611
2022-10-08 03:21:30 - train: epoch 0051, iter [01000, 01251], lr: 0.001057, loss: 3.4245
2022-10-08 03:21:51 - train: epoch 0051, iter [01010, 01251], lr: 0.001056, loss: 3.2539
2022-10-08 03:22:12 - train: epoch 0051, iter [01020, 01251], lr: 0.001056, loss: 3.6864
2022-10-08 03:22:33 - train: epoch 0051, iter [01030, 01251], lr: 0.001056, loss: 3.4766
2022-10-08 03:22:54 - train: epoch 0051, iter [01040, 01251], lr: 0.001056, loss: 2.7548
2022-10-08 03:23:15 - train: epoch 0051, iter [01050, 01251], lr: 0.001055, loss: 3.3192
2022-10-08 03:23:36 - train: epoch 0051, iter [01060, 01251], lr: 0.001055, loss: 3.3777
2022-10-08 03:23:57 - train: epoch 0051, iter [01070, 01251], lr: 0.001055, loss: 3.4084
2022-10-08 03:24:18 - train: epoch 0051, iter [01080, 01251], lr: 0.001055, loss: 2.6993
2022-10-08 03:24:39 - train: epoch 0051, iter [01090, 01251], lr: 0.001054, loss: 3.3478
2022-10-08 03:25:00 - train: epoch 0051, iter [01100, 01251], lr: 0.001054, loss: 2.9675
2022-10-08 03:25:21 - train: epoch 0051, iter [01110, 01251], lr: 0.001054, loss: 3.4215
2022-10-08 03:25:42 - train: epoch 0051, iter [01120, 01251], lr: 0.001054, loss: 3.2314
2022-10-08 03:26:03 - train: epoch 0051, iter [01130, 01251], lr: 0.001053, loss: 3.5381
2022-10-08 03:26:24 - train: epoch 0051, iter [01140, 01251], lr: 0.001053, loss: 3.6724
2022-10-08 03:26:46 - train: epoch 0051, iter [01150, 01251], lr: 0.001053, loss: 3.5173
2022-10-08 03:27:07 - train: epoch 0051, iter [01160, 01251], lr: 0.001052, loss: 3.4023
2022-10-08 03:27:28 - train: epoch 0051, iter [01170, 01251], lr: 0.001052, loss: 3.3171
2022-10-08 03:27:49 - train: epoch 0051, iter [01180, 01251], lr: 0.001052, loss: 3.1083
2022-10-08 03:28:10 - train: epoch 0051, iter [01190, 01251], lr: 0.001052, loss: 3.1429
2022-10-08 03:28:31 - train: epoch 0051, iter [01200, 01251], lr: 0.001051, loss: 3.5514
2022-10-08 03:28:52 - train: epoch 0051, iter [01210, 01251], lr: 0.001051, loss: 2.7963
2022-10-08 03:29:13 - train: epoch 0051, iter [01220, 01251], lr: 0.001051, loss: 2.9280
2022-10-08 03:29:34 - train: epoch 0051, iter [01230, 01251], lr: 0.001051, loss: 3.8895
2022-10-08 03:29:55 - train: epoch 0051, iter [01240, 01251], lr: 0.001050, loss: 3.3504
2022-10-08 03:30:16 - train: epoch 0051, iter [01250, 01251], lr: 0.001050, loss: 3.4566
2022-10-08 03:30:19 - train: epoch 051, train_loss: 3.1031
2022-10-08 03:31:35 - eval: epoch: 051, acc1: 80.986%, acc5: 95.616%, test_loss: 0.8297, per_image_load_time: 0.316ms, per_image_inference_time: 1.428ms
2022-10-08 03:31:36 - until epoch: 051, best_acc1: 80.986%
2022-10-08 03:31:36 - epoch 052 lr: 0.001050
2022-10-08 03:32:03 - train: epoch 0052, iter [00010, 01251], lr: 0.001050, loss: 3.2973
2022-10-08 03:32:25 - train: epoch 0052, iter [00020, 01251], lr: 0.001050, loss: 3.4144
2022-10-08 03:32:46 - train: epoch 0052, iter [00030, 01251], lr: 0.001049, loss: 2.8351
2022-10-08 03:33:07 - train: epoch 0052, iter [00040, 01251], lr: 0.001049, loss: 2.5717
2022-10-08 03:33:28 - train: epoch 0052, iter [00050, 01251], lr: 0.001049, loss: 3.4649
2022-10-08 03:33:49 - train: epoch 0052, iter [00060, 01251], lr: 0.001048, loss: 2.9358
2022-10-08 03:34:10 - train: epoch 0052, iter [00070, 01251], lr: 0.001048, loss: 3.2590
2022-10-08 03:34:31 - train: epoch 0052, iter [00080, 01251], lr: 0.001048, loss: 3.0227
2022-10-08 03:34:53 - train: epoch 0052, iter [00090, 01251], lr: 0.001048, loss: 2.8152
2022-10-08 03:35:14 - train: epoch 0052, iter [00100, 01251], lr: 0.001047, loss: 3.3411
2022-10-08 03:35:35 - train: epoch 0052, iter [00110, 01251], lr: 0.001047, loss: 3.1267
2022-10-08 03:35:56 - train: epoch 0052, iter [00120, 01251], lr: 0.001047, loss: 3.3856
2022-10-08 03:36:17 - train: epoch 0052, iter [00130, 01251], lr: 0.001047, loss: 2.8848
2022-10-08 03:36:38 - train: epoch 0052, iter [00140, 01251], lr: 0.001046, loss: 3.2925
2022-10-08 03:36:59 - train: epoch 0052, iter [00150, 01251], lr: 0.001046, loss: 3.1814
2022-10-08 03:37:20 - train: epoch 0052, iter [00160, 01251], lr: 0.001046, loss: 2.9237
2022-10-08 03:37:42 - train: epoch 0052, iter [00170, 01251], lr: 0.001046, loss: 2.6978
2022-10-08 03:38:03 - train: epoch 0052, iter [00180, 01251], lr: 0.001045, loss: 3.1131
2022-10-08 03:38:24 - train: epoch 0052, iter [00190, 01251], lr: 0.001045, loss: 2.7311
2022-10-08 03:38:45 - train: epoch 0052, iter [00200, 01251], lr: 0.001045, loss: 3.3401
2022-10-08 03:39:06 - train: epoch 0052, iter [00210, 01251], lr: 0.001045, loss: 3.1140
2022-10-08 03:39:27 - train: epoch 0052, iter [00220, 01251], lr: 0.001044, loss: 3.3229
2022-10-08 03:39:49 - train: epoch 0052, iter [00230, 01251], lr: 0.001044, loss: 3.4965
2022-10-08 03:40:10 - train: epoch 0052, iter [00240, 01251], lr: 0.001044, loss: 3.0378
2022-10-08 03:40:31 - train: epoch 0052, iter [00250, 01251], lr: 0.001043, loss: 2.6147
2022-10-08 03:40:52 - train: epoch 0052, iter [00260, 01251], lr: 0.001043, loss: 2.7373
2022-10-08 03:41:13 - train: epoch 0052, iter [00270, 01251], lr: 0.001043, loss: 2.8955
2022-10-08 03:41:34 - train: epoch 0052, iter [00280, 01251], lr: 0.001043, loss: 3.2794
2022-10-08 03:41:56 - train: epoch 0052, iter [00290, 01251], lr: 0.001042, loss: 3.0405
2022-10-08 03:42:17 - train: epoch 0052, iter [00300, 01251], lr: 0.001042, loss: 2.8152
2022-10-08 03:42:38 - train: epoch 0052, iter [00310, 01251], lr: 0.001042, loss: 2.9428
2022-10-08 03:42:59 - train: epoch 0052, iter [00320, 01251], lr: 0.001042, loss: 3.0176
2022-10-08 03:43:20 - train: epoch 0052, iter [00330, 01251], lr: 0.001041, loss: 3.3623
2022-10-08 03:43:42 - train: epoch 0052, iter [00340, 01251], lr: 0.001041, loss: 3.6906
2022-10-08 03:44:03 - train: epoch 0052, iter [00350, 01251], lr: 0.001041, loss: 2.6989
2022-10-08 03:44:24 - train: epoch 0052, iter [00360, 01251], lr: 0.001041, loss: 3.3395
2022-10-08 03:44:45 - train: epoch 0052, iter [00370, 01251], lr: 0.001040, loss: 3.5377
2022-10-08 03:45:06 - train: epoch 0052, iter [00380, 01251], lr: 0.001040, loss: 2.5293
2022-10-08 03:45:27 - train: epoch 0052, iter [00390, 01251], lr: 0.001040, loss: 2.7598
2022-10-08 03:45:48 - train: epoch 0052, iter [00400, 01251], lr: 0.001040, loss: 2.9727
2022-10-08 03:46:09 - train: epoch 0052, iter [00410, 01251], lr: 0.001039, loss: 3.6567
2022-10-08 03:46:30 - train: epoch 0052, iter [00420, 01251], lr: 0.001039, loss: 3.2153
2022-10-08 03:46:52 - train: epoch 0052, iter [00430, 01251], lr: 0.001039, loss: 2.3708
2022-10-08 03:47:13 - train: epoch 0052, iter [00440, 01251], lr: 0.001038, loss: 3.1039
2022-10-08 03:47:34 - train: epoch 0052, iter [00450, 01251], lr: 0.001038, loss: 3.0900
2022-10-08 03:47:55 - train: epoch 0052, iter [00460, 01251], lr: 0.001038, loss: 3.1651
2022-10-08 03:48:16 - train: epoch 0052, iter [00470, 01251], lr: 0.001038, loss: 3.4875
2022-10-08 03:48:37 - train: epoch 0052, iter [00480, 01251], lr: 0.001037, loss: 3.1225
2022-10-08 03:48:58 - train: epoch 0052, iter [00490, 01251], lr: 0.001037, loss: 3.6694
2022-10-08 03:49:20 - train: epoch 0052, iter [00500, 01251], lr: 0.001037, loss: 3.2094
2022-10-08 03:49:41 - train: epoch 0052, iter [00510, 01251], lr: 0.001037, loss: 2.8442
2022-10-08 03:50:02 - train: epoch 0052, iter [00520, 01251], lr: 0.001036, loss: 3.5701
2022-10-08 03:50:23 - train: epoch 0052, iter [00530, 01251], lr: 0.001036, loss: 3.0392
2022-10-08 03:50:44 - train: epoch 0052, iter [00540, 01251], lr: 0.001036, loss: 3.4715
2022-10-08 03:51:05 - train: epoch 0052, iter [00550, 01251], lr: 0.001036, loss: 2.4671
2022-10-08 03:51:26 - train: epoch 0052, iter [00560, 01251], lr: 0.001035, loss: 3.2242
2022-10-08 03:51:47 - train: epoch 0052, iter [00570, 01251], lr: 0.001035, loss: 3.0615
2022-10-08 03:52:09 - train: epoch 0052, iter [00580, 01251], lr: 0.001035, loss: 3.5244
2022-10-08 03:52:30 - train: epoch 0052, iter [00590, 01251], lr: 0.001034, loss: 3.1084
2022-10-08 03:52:51 - train: epoch 0052, iter [00600, 01251], lr: 0.001034, loss: 3.1437
2022-10-08 03:53:12 - train: epoch 0052, iter [00610, 01251], lr: 0.001034, loss: 2.7671
2022-10-08 03:53:33 - train: epoch 0052, iter [00620, 01251], lr: 0.001034, loss: 2.6716
2022-10-08 03:53:54 - train: epoch 0052, iter [00630, 01251], lr: 0.001033, loss: 3.2866
2022-10-08 03:54:15 - train: epoch 0052, iter [00640, 01251], lr: 0.001033, loss: 2.8469
2022-10-08 03:54:36 - train: epoch 0052, iter [00650, 01251], lr: 0.001033, loss: 3.0642
2022-10-08 03:54:57 - train: epoch 0052, iter [00660, 01251], lr: 0.001033, loss: 2.5949
2022-10-08 03:55:19 - train: epoch 0052, iter [00670, 01251], lr: 0.001032, loss: 2.9256
2022-10-08 03:55:40 - train: epoch 0052, iter [00680, 01251], lr: 0.001032, loss: 3.3906
2022-10-08 03:56:01 - train: epoch 0052, iter [00690, 01251], lr: 0.001032, loss: 3.5594
2022-10-08 03:56:22 - train: epoch 0052, iter [00700, 01251], lr: 0.001032, loss: 3.0206
2022-10-08 03:56:43 - train: epoch 0052, iter [00710, 01251], lr: 0.001031, loss: 2.6639
2022-10-08 03:57:04 - train: epoch 0052, iter [00720, 01251], lr: 0.001031, loss: 3.3774
2022-10-08 03:57:25 - train: epoch 0052, iter [00730, 01251], lr: 0.001031, loss: 2.7243
2022-10-08 03:57:46 - train: epoch 0052, iter [00740, 01251], lr: 0.001031, loss: 3.2511
2022-10-08 03:58:07 - train: epoch 0052, iter [00750, 01251], lr: 0.001030, loss: 3.3792
2022-10-08 03:58:28 - train: epoch 0052, iter [00760, 01251], lr: 0.001030, loss: 3.2269
2022-10-08 03:58:49 - train: epoch 0052, iter [00770, 01251], lr: 0.001030, loss: 3.0810
2022-10-08 03:59:10 - train: epoch 0052, iter [00780, 01251], lr: 0.001029, loss: 3.5952
2022-10-08 03:59:31 - train: epoch 0052, iter [00790, 01251], lr: 0.001029, loss: 2.7544
2022-10-08 03:59:52 - train: epoch 0052, iter [00800, 01251], lr: 0.001029, loss: 3.0870
2022-10-08 04:00:14 - train: epoch 0052, iter [00810, 01251], lr: 0.001029, loss: 2.7351
2022-10-08 04:00:35 - train: epoch 0052, iter [00820, 01251], lr: 0.001028, loss: 3.1507
2022-10-08 04:00:56 - train: epoch 0052, iter [00830, 01251], lr: 0.001028, loss: 3.1096
2022-10-08 04:01:17 - train: epoch 0052, iter [00840, 01251], lr: 0.001028, loss: 3.2046
2022-10-08 04:01:38 - train: epoch 0052, iter [00850, 01251], lr: 0.001028, loss: 2.8432
2022-10-08 04:01:59 - train: epoch 0052, iter [00860, 01251], lr: 0.001027, loss: 3.3936
2022-10-08 04:02:20 - train: epoch 0052, iter [00870, 01251], lr: 0.001027, loss: 2.7846
2022-10-08 04:02:41 - train: epoch 0052, iter [00880, 01251], lr: 0.001027, loss: 3.3730
2022-10-08 04:03:02 - train: epoch 0052, iter [00890, 01251], lr: 0.001027, loss: 3.2149
2022-10-08 04:03:23 - train: epoch 0052, iter [00900, 01251], lr: 0.001026, loss: 2.9850
2022-10-08 04:03:44 - train: epoch 0052, iter [00910, 01251], lr: 0.001026, loss: 3.1802
2022-10-08 04:04:06 - train: epoch 0052, iter [00920, 01251], lr: 0.001026, loss: 3.2465
2022-10-08 04:04:27 - train: epoch 0052, iter [00930, 01251], lr: 0.001026, loss: 3.2409
2022-10-08 04:04:48 - train: epoch 0052, iter [00940, 01251], lr: 0.001025, loss: 2.8533
2022-10-08 04:05:09 - train: epoch 0052, iter [00950, 01251], lr: 0.001025, loss: 3.1543
2022-10-08 04:05:30 - train: epoch 0052, iter [00960, 01251], lr: 0.001025, loss: 3.6359
2022-10-08 04:05:51 - train: epoch 0052, iter [00970, 01251], lr: 0.001024, loss: 2.4329
2022-10-08 04:06:12 - train: epoch 0052, iter [00980, 01251], lr: 0.001024, loss: 3.1613
2022-10-08 04:06:33 - train: epoch 0052, iter [00990, 01251], lr: 0.001024, loss: 3.2566
2022-10-08 04:06:54 - train: epoch 0052, iter [01000, 01251], lr: 0.001024, loss: 2.9624
2022-10-08 04:07:15 - train: epoch 0052, iter [01010, 01251], lr: 0.001023, loss: 3.5004
2022-10-08 04:07:36 - train: epoch 0052, iter [01020, 01251], lr: 0.001023, loss: 3.1958
2022-10-08 04:07:57 - train: epoch 0052, iter [01030, 01251], lr: 0.001023, loss: 3.6606
2022-10-08 04:08:18 - train: epoch 0052, iter [01040, 01251], lr: 0.001023, loss: 3.3687
2022-10-08 04:08:40 - train: epoch 0052, iter [01050, 01251], lr: 0.001022, loss: 3.5568
2022-10-08 04:09:01 - train: epoch 0052, iter [01060, 01251], lr: 0.001022, loss: 2.9864
2022-10-08 04:09:22 - train: epoch 0052, iter [01070, 01251], lr: 0.001022, loss: 3.3061
2022-10-08 04:09:43 - train: epoch 0052, iter [01080, 01251], lr: 0.001022, loss: 3.4293
2022-10-08 04:10:04 - train: epoch 0052, iter [01090, 01251], lr: 0.001021, loss: 3.4189
2022-10-08 04:10:25 - train: epoch 0052, iter [01100, 01251], lr: 0.001021, loss: 2.9530
2022-10-08 04:10:46 - train: epoch 0052, iter [01110, 01251], lr: 0.001021, loss: 2.4632
2022-10-08 04:11:07 - train: epoch 0052, iter [01120, 01251], lr: 0.001020, loss: 2.8799
2022-10-08 04:11:28 - train: epoch 0052, iter [01130, 01251], lr: 0.001020, loss: 3.4854
2022-10-08 04:11:49 - train: epoch 0052, iter [01140, 01251], lr: 0.001020, loss: 3.3665
2022-10-08 04:12:10 - train: epoch 0052, iter [01150, 01251], lr: 0.001020, loss: 2.7147
2022-10-08 04:12:31 - train: epoch 0052, iter [01160, 01251], lr: 0.001019, loss: 2.8472
2022-10-08 04:12:52 - train: epoch 0052, iter [01170, 01251], lr: 0.001019, loss: 3.4403
2022-10-08 04:13:13 - train: epoch 0052, iter [01180, 01251], lr: 0.001019, loss: 3.5232
2022-10-08 04:13:34 - train: epoch 0052, iter [01190, 01251], lr: 0.001019, loss: 3.1710
2022-10-08 04:13:55 - train: epoch 0052, iter [01200, 01251], lr: 0.001018, loss: 2.5565
2022-10-08 04:14:16 - train: epoch 0052, iter [01210, 01251], lr: 0.001018, loss: 3.2539
2022-10-08 04:14:37 - train: epoch 0052, iter [01220, 01251], lr: 0.001018, loss: 3.3626
2022-10-08 04:14:59 - train: epoch 0052, iter [01230, 01251], lr: 0.001018, loss: 3.2647
2022-10-08 04:15:20 - train: epoch 0052, iter [01240, 01251], lr: 0.001017, loss: 2.9569
2022-10-08 04:15:41 - train: epoch 0052, iter [01250, 01251], lr: 0.001017, loss: 3.3368
2022-10-08 04:15:44 - train: epoch 052, train_loss: 3.0931
2022-10-08 04:17:00 - eval: epoch: 052, acc1: 80.716%, acc5: 95.636%, test_loss: 0.8319, per_image_load_time: 1.165ms, per_image_inference_time: 1.417ms
2022-10-08 04:17:01 - until epoch: 052, best_acc1: 80.986%
2022-10-08 04:17:01 - epoch 053 lr: 0.001017
2022-10-08 04:17:29 - train: epoch 0053, iter [00010, 01251], lr: 0.001017, loss: 3.0586
2022-10-08 04:17:50 - train: epoch 0053, iter [00020, 01251], lr: 0.001016, loss: 2.8971
2022-10-08 04:18:11 - train: epoch 0053, iter [00030, 01251], lr: 0.001016, loss: 3.4138
2022-10-08 04:18:32 - train: epoch 0053, iter [00040, 01251], lr: 0.001016, loss: 2.9487
2022-10-08 04:18:53 - train: epoch 0053, iter [00050, 01251], lr: 0.001016, loss: 3.3607
2022-10-08 04:19:15 - train: epoch 0053, iter [00060, 01251], lr: 0.001015, loss: 3.1034
2022-10-08 04:19:36 - train: epoch 0053, iter [00070, 01251], lr: 0.001015, loss: 2.7876
2022-10-08 04:19:57 - train: epoch 0053, iter [00080, 01251], lr: 0.001015, loss: 2.8673
2022-10-08 04:20:18 - train: epoch 0053, iter [00090, 01251], lr: 0.001015, loss: 2.5012
2022-10-08 04:20:39 - train: epoch 0053, iter [00100, 01251], lr: 0.001014, loss: 2.5088
2022-10-08 04:21:01 - train: epoch 0053, iter [00110, 01251], lr: 0.001014, loss: 2.9978
2022-10-08 04:21:22 - train: epoch 0053, iter [00120, 01251], lr: 0.001014, loss: 3.5640
2022-10-08 04:21:43 - train: epoch 0053, iter [00130, 01251], lr: 0.001014, loss: 3.2068
2022-10-08 04:22:04 - train: epoch 0053, iter [00140, 01251], lr: 0.001013, loss: 3.5077
2022-10-08 04:22:25 - train: epoch 0053, iter [00150, 01251], lr: 0.001013, loss: 2.9893
2022-10-08 04:22:46 - train: epoch 0053, iter [00160, 01251], lr: 0.001013, loss: 3.2858
2022-10-08 04:23:08 - train: epoch 0053, iter [00170, 01251], lr: 0.001013, loss: 2.9333
2022-10-08 04:23:29 - train: epoch 0053, iter [00180, 01251], lr: 0.001012, loss: 2.3345
2022-10-08 04:23:50 - train: epoch 0053, iter [00190, 01251], lr: 0.001012, loss: 3.3008
2022-10-08 04:24:11 - train: epoch 0053, iter [00200, 01251], lr: 0.001012, loss: 2.7765
2022-10-08 04:24:32 - train: epoch 0053, iter [00210, 01251], lr: 0.001011, loss: 2.7508
2022-10-08 04:24:54 - train: epoch 0053, iter [00220, 01251], lr: 0.001011, loss: 3.0504
2022-10-08 04:25:15 - train: epoch 0053, iter [00230, 01251], lr: 0.001011, loss: 2.7543
2022-10-08 04:25:36 - train: epoch 0053, iter [00240, 01251], lr: 0.001011, loss: 2.6350
2022-10-08 04:25:57 - train: epoch 0053, iter [00250, 01251], lr: 0.001010, loss: 3.3353
2022-10-08 04:26:18 - train: epoch 0053, iter [00260, 01251], lr: 0.001010, loss: 3.2177
2022-10-08 04:26:39 - train: epoch 0053, iter [00270, 01251], lr: 0.001010, loss: 3.1039
2022-10-08 04:27:00 - train: epoch 0053, iter [00280, 01251], lr: 0.001010, loss: 2.7331
2022-10-08 04:27:21 - train: epoch 0053, iter [00290, 01251], lr: 0.001009, loss: 3.6613
2022-10-08 04:27:43 - train: epoch 0053, iter [00300, 01251], lr: 0.001009, loss: 3.2758
2022-10-08 04:28:04 - train: epoch 0053, iter [00310, 01251], lr: 0.001009, loss: 3.0794
2022-10-08 04:28:25 - train: epoch 0053, iter [00320, 01251], lr: 0.001009, loss: 3.3266
2022-10-08 04:28:46 - train: epoch 0053, iter [00330, 01251], lr: 0.001008, loss: 2.9776
2022-10-08 04:29:07 - train: epoch 0053, iter [00340, 01251], lr: 0.001008, loss: 3.5787
2022-10-08 04:29:28 - train: epoch 0053, iter [00350, 01251], lr: 0.001008, loss: 3.6390
2022-10-08 04:29:49 - train: epoch 0053, iter [00360, 01251], lr: 0.001008, loss: 3.6437
2022-10-08 04:30:10 - train: epoch 0053, iter [00370, 01251], lr: 0.001007, loss: 2.8537
2022-10-08 04:30:32 - train: epoch 0053, iter [00380, 01251], lr: 0.001007, loss: 2.6151
2022-10-08 04:30:53 - train: epoch 0053, iter [00390, 01251], lr: 0.001007, loss: 3.3525
2022-10-08 04:31:14 - train: epoch 0053, iter [00400, 01251], lr: 0.001006, loss: 2.9555
2022-10-08 04:31:35 - train: epoch 0053, iter [00410, 01251], lr: 0.001006, loss: 2.8220
2022-10-08 04:31:56 - train: epoch 0053, iter [00420, 01251], lr: 0.001006, loss: 3.2811
2022-10-08 04:32:17 - train: epoch 0053, iter [00430, 01251], lr: 0.001006, loss: 2.3457
2022-10-08 04:32:38 - train: epoch 0053, iter [00440, 01251], lr: 0.001005, loss: 2.7678
2022-10-08 04:32:59 - train: epoch 0053, iter [00450, 01251], lr: 0.001005, loss: 3.4327
2022-10-08 04:33:20 - train: epoch 0053, iter [00460, 01251], lr: 0.001005, loss: 2.9335
2022-10-08 04:33:41 - train: epoch 0053, iter [00470, 01251], lr: 0.001005, loss: 3.4615
2022-10-08 04:34:02 - train: epoch 0053, iter [00480, 01251], lr: 0.001004, loss: 3.2052
2022-10-08 04:34:23 - train: epoch 0053, iter [00490, 01251], lr: 0.001004, loss: 2.2946
2022-10-08 04:34:45 - train: epoch 0053, iter [00500, 01251], lr: 0.001004, loss: 3.0382
2022-10-08 04:35:06 - train: epoch 0053, iter [00510, 01251], lr: 0.001004, loss: 3.5807
2022-10-08 04:35:27 - train: epoch 0053, iter [00520, 01251], lr: 0.001003, loss: 2.6422
2022-10-08 04:35:48 - train: epoch 0053, iter [00530, 01251], lr: 0.001003, loss: 2.9874
2022-10-08 04:36:09 - train: epoch 0053, iter [00540, 01251], lr: 0.001003, loss: 3.3412
2022-10-08 04:36:30 - train: epoch 0053, iter [00550, 01251], lr: 0.001002, loss: 3.4682
2022-10-08 04:36:51 - train: epoch 0053, iter [00560, 01251], lr: 0.001002, loss: 3.2983
2022-10-08 04:37:12 - train: epoch 0053, iter [00570, 01251], lr: 0.001002, loss: 3.0621
2022-10-08 04:37:33 - train: epoch 0053, iter [00580, 01251], lr: 0.001002, loss: 2.6864
2022-10-08 04:37:54 - train: epoch 0053, iter [00590, 01251], lr: 0.001001, loss: 2.5231
2022-10-08 04:38:15 - train: epoch 0053, iter [00600, 01251], lr: 0.001001, loss: 2.9866
2022-10-08 04:38:36 - train: epoch 0053, iter [00610, 01251], lr: 0.001001, loss: 3.3548
2022-10-08 04:38:57 - train: epoch 0053, iter [00620, 01251], lr: 0.001001, loss: 3.1282
2022-10-08 04:39:18 - train: epoch 0053, iter [00630, 01251], lr: 0.001000, loss: 3.2715
2022-10-08 04:39:39 - train: epoch 0053, iter [00640, 01251], lr: 0.001000, loss: 3.4280
2022-10-08 04:40:01 - train: epoch 0053, iter [00650, 01251], lr: 0.001000, loss: 2.5187
2022-10-08 04:40:22 - train: epoch 0053, iter [00660, 01251], lr: 0.001000, loss: 3.4865
2022-10-08 04:40:43 - train: epoch 0053, iter [00670, 01251], lr: 0.000999, loss: 2.9652
2022-10-08 04:41:04 - train: epoch 0053, iter [00680, 01251], lr: 0.000999, loss: 2.9376
2022-10-08 04:41:25 - train: epoch 0053, iter [00690, 01251], lr: 0.000999, loss: 3.5526
2022-10-08 04:41:46 - train: epoch 0053, iter [00700, 01251], lr: 0.000999, loss: 3.1563
2022-10-08 04:42:07 - train: epoch 0053, iter [00710, 01251], lr: 0.000998, loss: 2.7153
2022-10-08 04:42:28 - train: epoch 0053, iter [00720, 01251], lr: 0.000998, loss: 3.0011
2022-10-08 04:42:49 - train: epoch 0053, iter [00730, 01251], lr: 0.000998, loss: 3.3379
2022-10-08 04:43:10 - train: epoch 0053, iter [00740, 01251], lr: 0.000997, loss: 3.3169
2022-10-08 04:43:31 - train: epoch 0053, iter [00750, 01251], lr: 0.000997, loss: 3.0725
2022-10-08 04:43:52 - train: epoch 0053, iter [00760, 01251], lr: 0.000997, loss: 3.6140
2022-10-08 04:44:13 - train: epoch 0053, iter [00770, 01251], lr: 0.000997, loss: 3.0573
2022-10-08 04:44:34 - train: epoch 0053, iter [00780, 01251], lr: 0.000996, loss: 3.3988
2022-10-08 04:44:55 - train: epoch 0053, iter [00790, 01251], lr: 0.000996, loss: 2.6691
2022-10-08 04:45:17 - train: epoch 0053, iter [00800, 01251], lr: 0.000996, loss: 3.4212
2022-10-08 04:45:38 - train: epoch 0053, iter [00810, 01251], lr: 0.000996, loss: 3.3622
2022-10-08 04:45:58 - train: epoch 0053, iter [00820, 01251], lr: 0.000995, loss: 2.8468
2022-10-08 04:46:20 - train: epoch 0053, iter [00830, 01251], lr: 0.000995, loss: 3.3755
2022-10-08 04:46:41 - train: epoch 0053, iter [00840, 01251], lr: 0.000995, loss: 3.5253
2022-10-08 04:47:02 - train: epoch 0053, iter [00850, 01251], lr: 0.000995, loss: 3.0282
2022-10-08 04:47:23 - train: epoch 0053, iter [00860, 01251], lr: 0.000994, loss: 3.0085
2022-10-08 04:47:44 - train: epoch 0053, iter [00870, 01251], lr: 0.000994, loss: 2.4498
2022-10-08 04:48:05 - train: epoch 0053, iter [00880, 01251], lr: 0.000994, loss: 3.4456
2022-10-08 04:48:26 - train: epoch 0053, iter [00890, 01251], lr: 0.000994, loss: 2.4012
2022-10-08 04:48:47 - train: epoch 0053, iter [00900, 01251], lr: 0.000993, loss: 3.3808
2022-10-08 04:49:08 - train: epoch 0053, iter [00910, 01251], lr: 0.000993, loss: 3.3586
2022-10-08 04:49:29 - train: epoch 0053, iter [00920, 01251], lr: 0.000993, loss: 2.9276
2022-10-08 04:49:50 - train: epoch 0053, iter [00930, 01251], lr: 0.000992, loss: 2.8218
2022-10-08 04:50:11 - train: epoch 0053, iter [00940, 01251], lr: 0.000992, loss: 3.5091
2022-10-08 04:50:32 - train: epoch 0053, iter [00950, 01251], lr: 0.000992, loss: 3.1179
2022-10-08 04:50:53 - train: epoch 0053, iter [00960, 01251], lr: 0.000992, loss: 2.7821
2022-10-08 04:51:14 - train: epoch 0053, iter [00970, 01251], lr: 0.000991, loss: 2.8398
2022-10-08 04:51:35 - train: epoch 0053, iter [00980, 01251], lr: 0.000991, loss: 3.0633
2022-10-08 04:51:56 - train: epoch 0053, iter [00990, 01251], lr: 0.000991, loss: 2.4112
2022-10-08 04:52:17 - train: epoch 0053, iter [01000, 01251], lr: 0.000991, loss: 3.2784
2022-10-08 04:52:38 - train: epoch 0053, iter [01010, 01251], lr: 0.000990, loss: 3.5569
2022-10-08 04:52:59 - train: epoch 0053, iter [01020, 01251], lr: 0.000990, loss: 3.1162
2022-10-08 04:53:20 - train: epoch 0053, iter [01030, 01251], lr: 0.000990, loss: 2.7832
2022-10-08 04:53:41 - train: epoch 0053, iter [01040, 01251], lr: 0.000990, loss: 3.5598
2022-10-08 04:54:02 - train: epoch 0053, iter [01050, 01251], lr: 0.000989, loss: 2.3999
2022-10-08 04:54:23 - train: epoch 0053, iter [01060, 01251], lr: 0.000989, loss: 3.4440
2022-10-08 04:54:44 - train: epoch 0053, iter [01070, 01251], lr: 0.000989, loss: 3.3341
2022-10-08 04:55:06 - train: epoch 0053, iter [01080, 01251], lr: 0.000988, loss: 2.8156
2022-10-08 04:55:26 - train: epoch 0053, iter [01090, 01251], lr: 0.000988, loss: 2.9230
2022-10-08 04:55:48 - train: epoch 0053, iter [01100, 01251], lr: 0.000988, loss: 2.7977
2022-10-08 04:56:09 - train: epoch 0053, iter [01110, 01251], lr: 0.000988, loss: 3.1182
2022-10-08 04:56:30 - train: epoch 0053, iter [01120, 01251], lr: 0.000987, loss: 2.8055
2022-10-08 04:56:51 - train: epoch 0053, iter [01130, 01251], lr: 0.000987, loss: 2.8078
2022-10-08 04:57:12 - train: epoch 0053, iter [01140, 01251], lr: 0.000987, loss: 3.4491
2022-10-08 04:57:33 - train: epoch 0053, iter [01150, 01251], lr: 0.000987, loss: 2.6889
2022-10-08 04:57:54 - train: epoch 0053, iter [01160, 01251], lr: 0.000986, loss: 2.9853
2022-10-08 04:58:15 - train: epoch 0053, iter [01170, 01251], lr: 0.000986, loss: 3.3335
2022-10-08 04:58:36 - train: epoch 0053, iter [01180, 01251], lr: 0.000986, loss: 3.2398
2022-10-08 04:58:57 - train: epoch 0053, iter [01190, 01251], lr: 0.000986, loss: 3.0718
2022-10-08 04:59:18 - train: epoch 0053, iter [01200, 01251], lr: 0.000985, loss: 3.5981
2022-10-08 04:59:39 - train: epoch 0053, iter [01210, 01251], lr: 0.000985, loss: 2.9548
2022-10-08 05:00:00 - train: epoch 0053, iter [01220, 01251], lr: 0.000985, loss: 3.1063
2022-10-08 05:00:21 - train: epoch 0053, iter [01230, 01251], lr: 0.000985, loss: 3.2546
2022-10-08 05:00:42 - train: epoch 0053, iter [01240, 01251], lr: 0.000984, loss: 3.6274
2022-10-08 05:01:03 - train: epoch 0053, iter [01250, 01251], lr: 0.000984, loss: 3.3172
2022-10-08 05:01:07 - train: epoch 053, train_loss: 3.0857
2022-10-08 05:02:23 - eval: epoch: 053, acc1: 80.754%, acc5: 95.758%, test_loss: 0.8296, per_image_load_time: 0.391ms, per_image_inference_time: 1.438ms
2022-10-08 05:02:24 - until epoch: 053, best_acc1: 80.986%
2022-10-08 05:02:24 - epoch 054 lr: 0.000984
2022-10-08 05:02:51 - train: epoch 0054, iter [00010, 01251], lr: 0.000984, loss: 2.8102
2022-10-08 05:03:12 - train: epoch 0054, iter [00020, 01251], lr: 0.000983, loss: 2.6408
2022-10-08 05:03:33 - train: epoch 0054, iter [00030, 01251], lr: 0.000983, loss: 2.9555
2022-10-08 05:03:54 - train: epoch 0054, iter [00040, 01251], lr: 0.000983, loss: 3.2224
2022-10-08 05:04:15 - train: epoch 0054, iter [00050, 01251], lr: 0.000983, loss: 3.2185
2022-10-08 05:04:36 - train: epoch 0054, iter [00060, 01251], lr: 0.000982, loss: 3.1743
2022-10-08 05:04:58 - train: epoch 0054, iter [00070, 01251], lr: 0.000982, loss: 3.1722
2022-10-08 05:05:19 - train: epoch 0054, iter [00080, 01251], lr: 0.000982, loss: 3.5553
2022-10-08 05:05:40 - train: epoch 0054, iter [00090, 01251], lr: 0.000982, loss: 3.1212
2022-10-08 05:06:01 - train: epoch 0054, iter [00100, 01251], lr: 0.000981, loss: 3.5051
2022-10-08 05:06:22 - train: epoch 0054, iter [00110, 01251], lr: 0.000981, loss: 3.0098
2022-10-08 05:06:43 - train: epoch 0054, iter [00120, 01251], lr: 0.000981, loss: 2.9326
2022-10-08 05:07:05 - train: epoch 0054, iter [00130, 01251], lr: 0.000981, loss: 2.5864
2022-10-08 05:07:26 - train: epoch 0054, iter [00140, 01251], lr: 0.000980, loss: 3.3629
2022-10-08 05:07:47 - train: epoch 0054, iter [00150, 01251], lr: 0.000980, loss: 2.8243
2022-10-08 05:08:08 - train: epoch 0054, iter [00160, 01251], lr: 0.000980, loss: 3.2965
2022-10-08 05:08:29 - train: epoch 0054, iter [00170, 01251], lr: 0.000979, loss: 2.8613
2022-10-08 05:08:50 - train: epoch 0054, iter [00180, 01251], lr: 0.000979, loss: 2.8863
2022-10-08 05:09:11 - train: epoch 0054, iter [00190, 01251], lr: 0.000979, loss: 3.0546
2022-10-08 05:09:32 - train: epoch 0054, iter [00200, 01251], lr: 0.000979, loss: 2.8539
2022-10-08 05:09:54 - train: epoch 0054, iter [00210, 01251], lr: 0.000978, loss: 3.0849
2022-10-08 05:10:15 - train: epoch 0054, iter [00220, 01251], lr: 0.000978, loss: 2.6247
2022-10-08 05:10:36 - train: epoch 0054, iter [00230, 01251], lr: 0.000978, loss: 2.6855
2022-10-08 05:10:57 - train: epoch 0054, iter [00240, 01251], lr: 0.000978, loss: 3.1320
2022-10-08 05:11:18 - train: epoch 0054, iter [00250, 01251], lr: 0.000977, loss: 3.0074
2022-10-08 05:11:39 - train: epoch 0054, iter [00260, 01251], lr: 0.000977, loss: 2.7129
2022-10-08 05:12:00 - train: epoch 0054, iter [00270, 01251], lr: 0.000977, loss: 3.3962
2022-10-08 05:12:21 - train: epoch 0054, iter [00280, 01251], lr: 0.000977, loss: 3.3934
2022-10-08 05:12:42 - train: epoch 0054, iter [00290, 01251], lr: 0.000976, loss: 3.3021
2022-10-08 05:13:03 - train: epoch 0054, iter [00300, 01251], lr: 0.000976, loss: 3.3524
2022-10-08 05:13:24 - train: epoch 0054, iter [00310, 01251], lr: 0.000976, loss: 3.0325
2022-10-08 05:13:46 - train: epoch 0054, iter [00320, 01251], lr: 0.000976, loss: 3.0518
2022-10-08 05:14:07 - train: epoch 0054, iter [00330, 01251], lr: 0.000975, loss: 3.3382
2022-10-08 05:14:28 - train: epoch 0054, iter [00340, 01251], lr: 0.000975, loss: 3.1327
2022-10-08 05:14:49 - train: epoch 0054, iter [00350, 01251], lr: 0.000975, loss: 3.3803
2022-10-08 05:15:10 - train: epoch 0054, iter [00360, 01251], lr: 0.000974, loss: 3.1189
2022-10-08 05:15:31 - train: epoch 0054, iter [00370, 01251], lr: 0.000974, loss: 2.7107
2022-10-08 05:15:52 - train: epoch 0054, iter [00380, 01251], lr: 0.000974, loss: 3.0201
2022-10-08 05:16:13 - train: epoch 0054, iter [00390, 01251], lr: 0.000974, loss: 2.7245
2022-10-08 05:16:35 - train: epoch 0054, iter [00400, 01251], lr: 0.000973, loss: 2.5318
2022-10-08 05:16:56 - train: epoch 0054, iter [00410, 01251], lr: 0.000973, loss: 2.8805
2022-10-08 05:17:17 - train: epoch 0054, iter [00420, 01251], lr: 0.000973, loss: 2.7085
2022-10-08 05:17:38 - train: epoch 0054, iter [00430, 01251], lr: 0.000973, loss: 3.6201
2022-10-08 05:17:59 - train: epoch 0054, iter [00440, 01251], lr: 0.000972, loss: 3.4541
2022-10-08 05:18:20 - train: epoch 0054, iter [00450, 01251], lr: 0.000972, loss: 3.4257
2022-10-08 05:18:41 - train: epoch 0054, iter [00460, 01251], lr: 0.000972, loss: 3.2096
2022-10-08 05:19:02 - train: epoch 0054, iter [00470, 01251], lr: 0.000972, loss: 3.1642
2022-10-08 05:19:23 - train: epoch 0054, iter [00480, 01251], lr: 0.000971, loss: 3.1427
2022-10-08 05:19:44 - train: epoch 0054, iter [00490, 01251], lr: 0.000971, loss: 2.8209
2022-10-08 05:20:05 - train: epoch 0054, iter [00500, 01251], lr: 0.000971, loss: 3.4741
2022-10-08 05:20:26 - train: epoch 0054, iter [00510, 01251], lr: 0.000971, loss: 2.7909
2022-10-08 05:20:47 - train: epoch 0054, iter [00520, 01251], lr: 0.000970, loss: 2.7612
2022-10-08 05:21:08 - train: epoch 0054, iter [00530, 01251], lr: 0.000970, loss: 3.0536
2022-10-08 05:21:29 - train: epoch 0054, iter [00540, 01251], lr: 0.000970, loss: 3.0001
2022-10-08 05:21:51 - train: epoch 0054, iter [00550, 01251], lr: 0.000969, loss: 3.5310
2022-10-08 05:22:12 - train: epoch 0054, iter [00560, 01251], lr: 0.000969, loss: 3.0463
2022-10-08 05:22:33 - train: epoch 0054, iter [00570, 01251], lr: 0.000969, loss: 2.3417
2022-10-08 05:22:54 - train: epoch 0054, iter [00580, 01251], lr: 0.000969, loss: 3.3222
2022-10-08 05:23:15 - train: epoch 0054, iter [00590, 01251], lr: 0.000968, loss: 3.2318
2022-10-08 05:23:36 - train: epoch 0054, iter [00600, 01251], lr: 0.000968, loss: 2.3797
2022-10-08 05:23:57 - train: epoch 0054, iter [00610, 01251], lr: 0.000968, loss: 2.3701
2022-10-08 05:24:18 - train: epoch 0054, iter [00620, 01251], lr: 0.000968, loss: 3.2200
2022-10-08 05:24:39 - train: epoch 0054, iter [00630, 01251], lr: 0.000967, loss: 3.5622
2022-10-08 05:25:00 - train: epoch 0054, iter [00640, 01251], lr: 0.000967, loss: 2.8680
2022-10-08 05:25:21 - train: epoch 0054, iter [00650, 01251], lr: 0.000967, loss: 1.9975
2022-10-08 05:25:42 - train: epoch 0054, iter [00660, 01251], lr: 0.000967, loss: 3.4956
2022-10-08 05:26:03 - train: epoch 0054, iter [00670, 01251], lr: 0.000966, loss: 3.2599
2022-10-08 05:26:25 - train: epoch 0054, iter [00680, 01251], lr: 0.000966, loss: 3.3712
2022-10-08 05:26:46 - train: epoch 0054, iter [00690, 01251], lr: 0.000966, loss: 3.7421
2022-10-08 05:27:07 - train: epoch 0054, iter [00700, 01251], lr: 0.000965, loss: 3.3837
2022-10-08 05:27:28 - train: epoch 0054, iter [00710, 01251], lr: 0.000965, loss: 3.4355
2022-10-08 05:27:49 - train: epoch 0054, iter [00720, 01251], lr: 0.000965, loss: 3.3914
2022-10-08 05:28:10 - train: epoch 0054, iter [00730, 01251], lr: 0.000965, loss: 3.1964
2022-10-08 05:28:31 - train: epoch 0054, iter [00740, 01251], lr: 0.000964, loss: 3.1301
2022-10-08 05:28:52 - train: epoch 0054, iter [00750, 01251], lr: 0.000964, loss: 3.2949
2022-10-08 05:29:13 - train: epoch 0054, iter [00760, 01251], lr: 0.000964, loss: 3.0187
2022-10-08 05:29:34 - train: epoch 0054, iter [00770, 01251], lr: 0.000964, loss: 2.7881
2022-10-08 05:29:55 - train: epoch 0054, iter [00780, 01251], lr: 0.000963, loss: 3.2866
2022-10-08 05:30:16 - train: epoch 0054, iter [00790, 01251], lr: 0.000963, loss: 3.3486
2022-10-08 05:30:37 - train: epoch 0054, iter [00800, 01251], lr: 0.000963, loss: 3.5448
2022-10-08 05:30:58 - train: epoch 0054, iter [00810, 01251], lr: 0.000963, loss: 3.1160
2022-10-08 05:31:19 - train: epoch 0054, iter [00820, 01251], lr: 0.000962, loss: 2.9755
2022-10-08 05:31:40 - train: epoch 0054, iter [00830, 01251], lr: 0.000962, loss: 3.1381
2022-10-08 05:32:01 - train: epoch 0054, iter [00840, 01251], lr: 0.000962, loss: 2.7778
2022-10-08 05:32:22 - train: epoch 0054, iter [00850, 01251], lr: 0.000962, loss: 2.9515
2022-10-08 05:32:43 - train: epoch 0054, iter [00860, 01251], lr: 0.000961, loss: 3.2109
2022-10-08 05:33:05 - train: epoch 0054, iter [00870, 01251], lr: 0.000961, loss: 2.5812
2022-10-08 05:33:26 - train: epoch 0054, iter [00880, 01251], lr: 0.000961, loss: 3.5251
2022-10-08 05:33:47 - train: epoch 0054, iter [00890, 01251], lr: 0.000960, loss: 3.4634
2022-10-08 05:34:08 - train: epoch 0054, iter [00900, 01251], lr: 0.000960, loss: 3.4832
2022-10-08 05:34:29 - train: epoch 0054, iter [00910, 01251], lr: 0.000960, loss: 2.4664
2022-10-08 05:34:50 - train: epoch 0054, iter [00920, 01251], lr: 0.000960, loss: 3.2834
2022-10-08 05:35:11 - train: epoch 0054, iter [00930, 01251], lr: 0.000959, loss: 3.2931
2022-10-08 05:35:32 - train: epoch 0054, iter [00940, 01251], lr: 0.000959, loss: 3.4055
2022-10-08 05:35:53 - train: epoch 0054, iter [00950, 01251], lr: 0.000959, loss: 3.1069
2022-10-08 05:36:14 - train: epoch 0054, iter [00960, 01251], lr: 0.000959, loss: 3.1158
2022-10-08 05:36:35 - train: epoch 0054, iter [00970, 01251], lr: 0.000958, loss: 2.5893
2022-10-08 05:36:56 - train: epoch 0054, iter [00980, 01251], lr: 0.000958, loss: 2.8950
2022-10-08 05:37:17 - train: epoch 0054, iter [00990, 01251], lr: 0.000958, loss: 3.5256
2022-10-08 05:37:38 - train: epoch 0054, iter [01000, 01251], lr: 0.000958, loss: 2.7842
2022-10-08 05:37:59 - train: epoch 0054, iter [01010, 01251], lr: 0.000957, loss: 2.8101
2022-10-08 05:38:20 - train: epoch 0054, iter [01020, 01251], lr: 0.000957, loss: 3.2233
2022-10-08 05:38:41 - train: epoch 0054, iter [01030, 01251], lr: 0.000957, loss: 3.4220
2022-10-08 05:39:02 - train: epoch 0054, iter [01040, 01251], lr: 0.000957, loss: 2.8478
2022-10-08 05:39:24 - train: epoch 0054, iter [01050, 01251], lr: 0.000956, loss: 3.0660
2022-10-08 05:39:45 - train: epoch 0054, iter [01060, 01251], lr: 0.000956, loss: 3.6150
2022-10-08 05:40:06 - train: epoch 0054, iter [01070, 01251], lr: 0.000956, loss: 2.7337
2022-10-08 05:40:27 - train: epoch 0054, iter [01080, 01251], lr: 0.000955, loss: 2.7031
2022-10-08 05:40:48 - train: epoch 0054, iter [01090, 01251], lr: 0.000955, loss: 3.4191
2022-10-08 05:41:09 - train: epoch 0054, iter [01100, 01251], lr: 0.000955, loss: 2.6167
2022-10-08 05:41:30 - train: epoch 0054, iter [01110, 01251], lr: 0.000955, loss: 2.8313
2022-10-08 05:41:51 - train: epoch 0054, iter [01120, 01251], lr: 0.000954, loss: 3.3489
2022-10-08 05:42:12 - train: epoch 0054, iter [01130, 01251], lr: 0.000954, loss: 2.5047
2022-10-08 05:42:33 - train: epoch 0054, iter [01140, 01251], lr: 0.000954, loss: 3.4136
2022-10-08 05:42:54 - train: epoch 0054, iter [01150, 01251], lr: 0.000954, loss: 3.4668
2022-10-08 05:43:15 - train: epoch 0054, iter [01160, 01251], lr: 0.000953, loss: 3.3874
2022-10-08 05:43:36 - train: epoch 0054, iter [01170, 01251], lr: 0.000953, loss: 2.5672
2022-10-08 05:43:57 - train: epoch 0054, iter [01180, 01251], lr: 0.000953, loss: 3.1775
2022-10-08 05:44:18 - train: epoch 0054, iter [01190, 01251], lr: 0.000953, loss: 3.5004
2022-10-08 05:44:39 - train: epoch 0054, iter [01200, 01251], lr: 0.000952, loss: 3.4342
2022-10-08 05:45:00 - train: epoch 0054, iter [01210, 01251], lr: 0.000952, loss: 2.3723
2022-10-08 05:45:21 - train: epoch 0054, iter [01220, 01251], lr: 0.000952, loss: 3.2049
2022-10-08 05:45:42 - train: epoch 0054, iter [01230, 01251], lr: 0.000951, loss: 3.2407
2022-10-08 05:46:04 - train: epoch 0054, iter [01240, 01251], lr: 0.000951, loss: 3.3619
2022-10-08 05:46:24 - train: epoch 0054, iter [01250, 01251], lr: 0.000951, loss: 3.5799
2022-10-08 05:46:28 - train: epoch 054, train_loss: 3.0717
2022-10-08 05:47:44 - eval: epoch: 054, acc1: 80.902%, acc5: 95.680%, test_loss: 0.8315, per_image_load_time: 1.055ms, per_image_inference_time: 1.411ms
2022-10-08 05:47:45 - until epoch: 054, best_acc1: 80.986%
2022-10-08 05:47:45 - epoch 055 lr: 0.000951
2022-10-08 05:48:12 - train: epoch 0055, iter [00010, 01251], lr: 0.000951, loss: 2.2405
2022-10-08 05:48:33 - train: epoch 0055, iter [00020, 01251], lr: 0.000950, loss: 3.3263
2022-10-08 05:48:54 - train: epoch 0055, iter [00030, 01251], lr: 0.000950, loss: 2.1254
2022-10-08 05:49:15 - train: epoch 0055, iter [00040, 01251], lr: 0.000950, loss: 3.0923
2022-10-08 05:49:37 - train: epoch 0055, iter [00050, 01251], lr: 0.000950, loss: 3.4717
2022-10-08 05:49:58 - train: epoch 0055, iter [00060, 01251], lr: 0.000949, loss: 3.2555
2022-10-08 05:50:19 - train: epoch 0055, iter [00070, 01251], lr: 0.000949, loss: 2.6987
2022-10-08 05:50:40 - train: epoch 0055, iter [00080, 01251], lr: 0.000949, loss: 3.3389
2022-10-08 05:51:01 - train: epoch 0055, iter [00090, 01251], lr: 0.000949, loss: 2.8267
2022-10-08 05:51:23 - train: epoch 0055, iter [00100, 01251], lr: 0.000948, loss: 2.9653
2022-10-08 05:51:44 - train: epoch 0055, iter [00110, 01251], lr: 0.000948, loss: 2.7322
2022-10-08 05:52:05 - train: epoch 0055, iter [00120, 01251], lr: 0.000948, loss: 3.3717
2022-10-08 05:52:26 - train: epoch 0055, iter [00130, 01251], lr: 0.000948, loss: 2.7321
2022-10-08 05:52:47 - train: epoch 0055, iter [00140, 01251], lr: 0.000947, loss: 3.5490
2022-10-08 05:53:09 - train: epoch 0055, iter [00150, 01251], lr: 0.000947, loss: 2.7873
2022-10-08 05:53:30 - train: epoch 0055, iter [00160, 01251], lr: 0.000947, loss: 2.7126
2022-10-08 05:53:51 - train: epoch 0055, iter [00170, 01251], lr: 0.000946, loss: 2.9767
2022-10-08 05:54:12 - train: epoch 0055, iter [00180, 01251], lr: 0.000946, loss: 3.1294
2022-10-08 05:54:33 - train: epoch 0055, iter [00190, 01251], lr: 0.000946, loss: 2.5825
2022-10-08 05:54:54 - train: epoch 0055, iter [00200, 01251], lr: 0.000946, loss: 2.9465
2022-10-08 05:55:15 - train: epoch 0055, iter [00210, 01251], lr: 0.000945, loss: 3.5688
2022-10-08 05:55:36 - train: epoch 0055, iter [00220, 01251], lr: 0.000945, loss: 3.0322
2022-10-08 05:55:57 - train: epoch 0055, iter [00230, 01251], lr: 0.000945, loss: 3.3613
2022-10-08 05:56:19 - train: epoch 0055, iter [00240, 01251], lr: 0.000945, loss: 3.0649
2022-10-08 05:56:40 - train: epoch 0055, iter [00250, 01251], lr: 0.000944, loss: 3.5825
2022-10-08 05:57:01 - train: epoch 0055, iter [00260, 01251], lr: 0.000944, loss: 3.3535
2022-10-08 05:57:22 - train: epoch 0055, iter [00270, 01251], lr: 0.000944, loss: 2.7962
2022-10-08 05:57:43 - train: epoch 0055, iter [00280, 01251], lr: 0.000944, loss: 2.5130
2022-10-08 05:58:04 - train: epoch 0055, iter [00290, 01251], lr: 0.000943, loss: 3.3043
2022-10-08 05:58:25 - train: epoch 0055, iter [00300, 01251], lr: 0.000943, loss: 3.1294
2022-10-08 05:58:46 - train: epoch 0055, iter [00310, 01251], lr: 0.000943, loss: 3.2485
2022-10-08 05:59:07 - train: epoch 0055, iter [00320, 01251], lr: 0.000942, loss: 2.8378
2022-10-08 05:59:28 - train: epoch 0055, iter [00330, 01251], lr: 0.000942, loss: 2.7680
2022-10-08 05:59:49 - train: epoch 0055, iter [00340, 01251], lr: 0.000942, loss: 3.3007
2022-10-08 06:00:10 - train: epoch 0055, iter [00350, 01251], lr: 0.000942, loss: 2.7904
2022-10-08 06:00:31 - train: epoch 0055, iter [00360, 01251], lr: 0.000941, loss: 3.0790
2022-10-08 06:00:53 - train: epoch 0055, iter [00370, 01251], lr: 0.000941, loss: 2.9002
2022-10-08 06:01:14 - train: epoch 0055, iter [00380, 01251], lr: 0.000941, loss: 2.5299
2022-10-08 06:01:35 - train: epoch 0055, iter [00390, 01251], lr: 0.000941, loss: 3.4433
2022-10-08 06:01:56 - train: epoch 0055, iter [00400, 01251], lr: 0.000940, loss: 3.2265
2022-10-08 06:02:17 - train: epoch 0055, iter [00410, 01251], lr: 0.000940, loss: 3.1935
2022-10-08 06:02:38 - train: epoch 0055, iter [00420, 01251], lr: 0.000940, loss: 2.9244
2022-10-08 06:02:59 - train: epoch 0055, iter [00430, 01251], lr: 0.000940, loss: 2.8097
2022-10-08 06:03:20 - train: epoch 0055, iter [00440, 01251], lr: 0.000939, loss: 3.6905
2022-10-08 06:03:42 - train: epoch 0055, iter [00450, 01251], lr: 0.000939, loss: 2.8601
2022-10-08 06:04:03 - train: epoch 0055, iter [00460, 01251], lr: 0.000939, loss: 3.3450
2022-10-08 06:04:24 - train: epoch 0055, iter [00470, 01251], lr: 0.000939, loss: 2.7636
2022-10-08 06:04:45 - train: epoch 0055, iter [00480, 01251], lr: 0.000938, loss: 2.8689
2022-10-08 06:05:06 - train: epoch 0055, iter [00490, 01251], lr: 0.000938, loss: 3.2951
2022-10-08 06:05:27 - train: epoch 0055, iter [00500, 01251], lr: 0.000938, loss: 3.2592
2022-10-08 06:05:48 - train: epoch 0055, iter [00510, 01251], lr: 0.000937, loss: 2.9674
2022-10-08 06:06:09 - train: epoch 0055, iter [00520, 01251], lr: 0.000937, loss: 2.7269
2022-10-08 06:06:30 - train: epoch 0055, iter [00530, 01251], lr: 0.000937, loss: 3.4095
2022-10-08 06:06:52 - train: epoch 0055, iter [00540, 01251], lr: 0.000937, loss: 3.3222
2022-10-08 06:07:13 - train: epoch 0055, iter [00550, 01251], lr: 0.000936, loss: 3.0683
2022-10-08 06:07:34 - train: epoch 0055, iter [00560, 01251], lr: 0.000936, loss: 2.8772
2022-10-08 06:07:55 - train: epoch 0055, iter [00570, 01251], lr: 0.000936, loss: 3.4714
2022-10-08 06:08:16 - train: epoch 0055, iter [00580, 01251], lr: 0.000936, loss: 3.3508
2022-10-08 06:08:37 - train: epoch 0055, iter [00590, 01251], lr: 0.000935, loss: 2.6127
2022-10-08 06:08:58 - train: epoch 0055, iter [00600, 01251], lr: 0.000935, loss: 3.2197
2022-10-08 06:09:19 - train: epoch 0055, iter [00610, 01251], lr: 0.000935, loss: 3.6348
2022-10-08 06:09:40 - train: epoch 0055, iter [00620, 01251], lr: 0.000935, loss: 2.9914
2022-10-08 06:10:01 - train: epoch 0055, iter [00630, 01251], lr: 0.000934, loss: 3.2590
2022-10-08 06:10:22 - train: epoch 0055, iter [00640, 01251], lr: 0.000934, loss: 3.3219
2022-10-08 06:10:43 - train: epoch 0055, iter [00650, 01251], lr: 0.000934, loss: 3.3124
2022-10-08 06:11:04 - train: epoch 0055, iter [00660, 01251], lr: 0.000934, loss: 2.3275
2022-10-08 06:11:25 - train: epoch 0055, iter [00670, 01251], lr: 0.000933, loss: 2.8788
2022-10-08 06:11:46 - train: epoch 0055, iter [00680, 01251], lr: 0.000933, loss: 2.9975
2022-10-08 06:12:07 - train: epoch 0055, iter [00690, 01251], lr: 0.000933, loss: 3.0321
2022-10-08 06:12:28 - train: epoch 0055, iter [00700, 01251], lr: 0.000932, loss: 2.1070
2022-10-08 06:12:49 - train: epoch 0055, iter [00710, 01251], lr: 0.000932, loss: 2.5805
2022-10-08 06:13:10 - train: epoch 0055, iter [00720, 01251], lr: 0.000932, loss: 3.0446
2022-10-08 06:13:31 - train: epoch 0055, iter [00730, 01251], lr: 0.000932, loss: 3.4235
2022-10-08 06:13:52 - train: epoch 0055, iter [00740, 01251], lr: 0.000931, loss: 2.7988
2022-10-08 06:14:13 - train: epoch 0055, iter [00750, 01251], lr: 0.000931, loss: 3.0624
2022-10-08 06:14:34 - train: epoch 0055, iter [00760, 01251], lr: 0.000931, loss: 2.7963
2022-10-08 06:14:55 - train: epoch 0055, iter [00770, 01251], lr: 0.000931, loss: 3.2412
2022-10-08 06:15:16 - train: epoch 0055, iter [00780, 01251], lr: 0.000930, loss: 2.9538
2022-10-08 06:15:37 - train: epoch 0055, iter [00790, 01251], lr: 0.000930, loss: 2.9511
2022-10-08 06:15:58 - train: epoch 0055, iter [00800, 01251], lr: 0.000930, loss: 1.9429
2022-10-08 06:16:19 - train: epoch 0055, iter [00810, 01251], lr: 0.000930, loss: 2.8049
2022-10-08 06:16:40 - train: epoch 0055, iter [00820, 01251], lr: 0.000929, loss: 2.5312
2022-10-08 06:17:01 - train: epoch 0055, iter [00830, 01251], lr: 0.000929, loss: 3.2619
2022-10-08 06:17:22 - train: epoch 0055, iter [00840, 01251], lr: 0.000929, loss: 3.0313
2022-10-08 06:17:43 - train: epoch 0055, iter [00850, 01251], lr: 0.000929, loss: 2.4872
2022-10-08 06:18:04 - train: epoch 0055, iter [00860, 01251], lr: 0.000928, loss: 2.8108
2022-10-08 06:18:25 - train: epoch 0055, iter [00870, 01251], lr: 0.000928, loss: 2.9676
2022-10-08 06:18:46 - train: epoch 0055, iter [00880, 01251], lr: 0.000928, loss: 2.8829
2022-10-08 06:19:07 - train: epoch 0055, iter [00890, 01251], lr: 0.000927, loss: 3.4241
2022-10-08 06:19:28 - train: epoch 0055, iter [00900, 01251], lr: 0.000927, loss: 3.4101
2022-10-08 06:19:49 - train: epoch 0055, iter [00910, 01251], lr: 0.000927, loss: 2.0855
2022-10-08 06:20:10 - train: epoch 0055, iter [00920, 01251], lr: 0.000927, loss: 2.6393
2022-10-08 06:20:31 - train: epoch 0055, iter [00930, 01251], lr: 0.000926, loss: 3.1637
2022-10-08 06:20:52 - train: epoch 0055, iter [00940, 01251], lr: 0.000926, loss: 2.7124
2022-10-08 06:21:13 - train: epoch 0055, iter [00950, 01251], lr: 0.000926, loss: 3.6159
2022-10-08 06:21:34 - train: epoch 0055, iter [00960, 01251], lr: 0.000926, loss: 3.3699
2022-10-08 06:21:55 - train: epoch 0055, iter [00970, 01251], lr: 0.000925, loss: 2.9910
2022-10-08 06:22:16 - train: epoch 0055, iter [00980, 01251], lr: 0.000925, loss: 3.1725
2022-10-08 06:22:37 - train: epoch 0055, iter [00990, 01251], lr: 0.000925, loss: 3.0459
2022-10-08 06:22:58 - train: epoch 0055, iter [01000, 01251], lr: 0.000925, loss: 2.9153
2022-10-08 06:23:19 - train: epoch 0055, iter [01010, 01251], lr: 0.000924, loss: 2.6686
2022-10-08 06:23:40 - train: epoch 0055, iter [01020, 01251], lr: 0.000924, loss: 3.0515
2022-10-08 06:24:01 - train: epoch 0055, iter [01030, 01251], lr: 0.000924, loss: 3.0429
2022-10-08 06:24:22 - train: epoch 0055, iter [01040, 01251], lr: 0.000924, loss: 3.1982
2022-10-08 06:24:43 - train: epoch 0055, iter [01050, 01251], lr: 0.000923, loss: 3.6148
2022-10-08 06:25:04 - train: epoch 0055, iter [01060, 01251], lr: 0.000923, loss: 2.5169
2022-10-08 06:25:25 - train: epoch 0055, iter [01070, 01251], lr: 0.000923, loss: 3.4514
2022-10-08 06:25:46 - train: epoch 0055, iter [01080, 01251], lr: 0.000922, loss: 3.4789
2022-10-08 06:26:07 - train: epoch 0055, iter [01090, 01251], lr: 0.000922, loss: 2.8472
2022-10-08 06:26:28 - train: epoch 0055, iter [01100, 01251], lr: 0.000922, loss: 2.8091
2022-10-08 06:26:49 - train: epoch 0055, iter [01110, 01251], lr: 0.000922, loss: 3.0165
2022-10-08 06:27:10 - train: epoch 0055, iter [01120, 01251], lr: 0.000921, loss: 3.4032
2022-10-08 06:27:31 - train: epoch 0055, iter [01130, 01251], lr: 0.000921, loss: 2.7424
2022-10-08 06:27:52 - train: epoch 0055, iter [01140, 01251], lr: 0.000921, loss: 3.2750
2022-10-08 06:28:13 - train: epoch 0055, iter [01150, 01251], lr: 0.000921, loss: 3.0141
2022-10-08 06:28:34 - train: epoch 0055, iter [01160, 01251], lr: 0.000920, loss: 3.0916
2022-10-08 06:28:55 - train: epoch 0055, iter [01170, 01251], lr: 0.000920, loss: 3.1284
2022-10-08 06:29:16 - train: epoch 0055, iter [01180, 01251], lr: 0.000920, loss: 3.1598
2022-10-08 06:29:37 - train: epoch 0055, iter [01190, 01251], lr: 0.000920, loss: 3.4205
2022-10-08 06:29:59 - train: epoch 0055, iter [01200, 01251], lr: 0.000919, loss: 2.8282
2022-10-08 06:30:20 - train: epoch 0055, iter [01210, 01251], lr: 0.000919, loss: 3.0232
2022-10-08 06:30:41 - train: epoch 0055, iter [01220, 01251], lr: 0.000919, loss: 3.0303
2022-10-08 06:31:02 - train: epoch 0055, iter [01230, 01251], lr: 0.000919, loss: 3.4229
2022-10-08 06:31:23 - train: epoch 0055, iter [01240, 01251], lr: 0.000918, loss: 3.1092
2022-10-08 06:31:44 - train: epoch 0055, iter [01250, 01251], lr: 0.000918, loss: 2.7670
2022-10-08 06:31:47 - train: epoch 055, train_loss: 3.0616
2022-10-08 06:33:04 - eval: epoch: 055, acc1: 80.928%, acc5: 95.836%, test_loss: 0.8303, per_image_load_time: 0.473ms, per_image_inference_time: 1.436ms
2022-10-08 06:33:05 - until epoch: 055, best_acc1: 80.986%
2022-10-08 06:33:05 - epoch 056 lr: 0.000918
2022-10-08 06:33:32 - train: epoch 0056, iter [00010, 01251], lr: 0.000918, loss: 3.2700
2022-10-08 06:33:53 - train: epoch 0056, iter [00020, 01251], lr: 0.000917, loss: 3.5893
2022-10-08 06:34:14 - train: epoch 0056, iter [00030, 01251], lr: 0.000917, loss: 3.3233
2022-10-08 06:34:35 - train: epoch 0056, iter [00040, 01251], lr: 0.000917, loss: 3.3741
2022-10-08 06:34:56 - train: epoch 0056, iter [00050, 01251], lr: 0.000917, loss: 2.9382
2022-10-08 06:35:18 - train: epoch 0056, iter [00060, 01251], lr: 0.000916, loss: 2.9346
2022-10-08 06:35:39 - train: epoch 0056, iter [00070, 01251], lr: 0.000916, loss: 2.7050
2022-10-08 06:36:00 - train: epoch 0056, iter [00080, 01251], lr: 0.000916, loss: 3.2647
2022-10-08 06:36:21 - train: epoch 0056, iter [00090, 01251], lr: 0.000916, loss: 3.5363
2022-10-08 06:36:42 - train: epoch 0056, iter [00100, 01251], lr: 0.000915, loss: 3.1878
2022-10-08 06:37:03 - train: epoch 0056, iter [00110, 01251], lr: 0.000915, loss: 2.8837
2022-10-08 06:37:24 - train: epoch 0056, iter [00120, 01251], lr: 0.000915, loss: 3.1882
2022-10-08 06:37:45 - train: epoch 0056, iter [00130, 01251], lr: 0.000915, loss: 3.2295
2022-10-08 06:38:06 - train: epoch 0056, iter [00140, 01251], lr: 0.000914, loss: 2.9981
2022-10-08 06:38:27 - train: epoch 0056, iter [00150, 01251], lr: 0.000914, loss: 2.8984
2022-10-08 06:38:49 - train: epoch 0056, iter [00160, 01251], lr: 0.000914, loss: 3.4910
2022-10-08 06:39:10 - train: epoch 0056, iter [00170, 01251], lr: 0.000913, loss: 3.1255
2022-10-08 06:39:31 - train: epoch 0056, iter [00180, 01251], lr: 0.000913, loss: 2.9982
2022-10-08 06:39:52 - train: epoch 0056, iter [00190, 01251], lr: 0.000913, loss: 3.1572
2022-10-08 06:40:13 - train: epoch 0056, iter [00200, 01251], lr: 0.000913, loss: 3.2575
2022-10-08 06:40:34 - train: epoch 0056, iter [00210, 01251], lr: 0.000912, loss: 2.6603
2022-10-08 06:40:55 - train: epoch 0056, iter [00220, 01251], lr: 0.000912, loss: 2.3905
2022-10-08 06:41:16 - train: epoch 0056, iter [00230, 01251], lr: 0.000912, loss: 3.3877
2022-10-08 06:41:37 - train: epoch 0056, iter [00240, 01251], lr: 0.000912, loss: 2.4837
2022-10-08 06:41:59 - train: epoch 0056, iter [00250, 01251], lr: 0.000911, loss: 2.8939
2022-10-08 06:42:20 - train: epoch 0056, iter [00260, 01251], lr: 0.000911, loss: 2.7558
2022-10-08 06:42:41 - train: epoch 0056, iter [00270, 01251], lr: 0.000911, loss: 3.3715
2022-10-08 06:43:02 - train: epoch 0056, iter [00280, 01251], lr: 0.000911, loss: 2.7369
2022-10-08 06:43:23 - train: epoch 0056, iter [00290, 01251], lr: 0.000910, loss: 3.1260
2022-10-08 06:43:44 - train: epoch 0056, iter [00300, 01251], lr: 0.000910, loss: 3.3431
2022-10-08 06:44:05 - train: epoch 0056, iter [00310, 01251], lr: 0.000910, loss: 3.2085
2022-10-08 06:44:26 - train: epoch 0056, iter [00320, 01251], lr: 0.000910, loss: 2.6398
2022-10-08 06:44:47 - train: epoch 0056, iter [00330, 01251], lr: 0.000909, loss: 3.1950
2022-10-08 06:45:08 - train: epoch 0056, iter [00340, 01251], lr: 0.000909, loss: 3.4199
2022-10-08 06:45:29 - train: epoch 0056, iter [00350, 01251], lr: 0.000909, loss: 2.7076
2022-10-08 06:45:51 - train: epoch 0056, iter [00360, 01251], lr: 0.000908, loss: 3.3786
2022-10-08 06:46:12 - train: epoch 0056, iter [00370, 01251], lr: 0.000908, loss: 3.3139
2022-10-08 06:46:33 - train: epoch 0056, iter [00380, 01251], lr: 0.000908, loss: 3.1619
2022-10-08 06:46:54 - train: epoch 0056, iter [00390, 01251], lr: 0.000908, loss: 2.1398
2022-10-08 06:47:15 - train: epoch 0056, iter [00400, 01251], lr: 0.000907, loss: 2.9947
2022-10-08 06:47:36 - train: epoch 0056, iter [00410, 01251], lr: 0.000907, loss: 2.6444
2022-10-08 06:47:57 - train: epoch 0056, iter [00420, 01251], lr: 0.000907, loss: 3.4072
2022-10-08 06:48:18 - train: epoch 0056, iter [00430, 01251], lr: 0.000907, loss: 3.0389
2022-10-08 06:48:39 - train: epoch 0056, iter [00440, 01251], lr: 0.000906, loss: 2.9441
2022-10-08 06:49:00 - train: epoch 0056, iter [00450, 01251], lr: 0.000906, loss: 2.8789
2022-10-08 06:49:21 - train: epoch 0056, iter [00460, 01251], lr: 0.000906, loss: 3.1223
2022-10-08 06:49:42 - train: epoch 0056, iter [00470, 01251], lr: 0.000906, loss: 3.4075
2022-10-08 06:50:03 - train: epoch 0056, iter [00480, 01251], lr: 0.000905, loss: 3.4866
2022-10-08 06:50:24 - train: epoch 0056, iter [00490, 01251], lr: 0.000905, loss: 2.9586
2022-10-08 06:50:45 - train: epoch 0056, iter [00500, 01251], lr: 0.000905, loss: 3.3764
2022-10-08 06:51:07 - train: epoch 0056, iter [00510, 01251], lr: 0.000905, loss: 3.1357
2022-10-08 06:51:28 - train: epoch 0056, iter [00520, 01251], lr: 0.000904, loss: 3.2278
2022-10-08 06:51:49 - train: epoch 0056, iter [00530, 01251], lr: 0.000904, loss: 2.3499
2022-10-08 06:52:10 - train: epoch 0056, iter [00540, 01251], lr: 0.000904, loss: 2.4981
2022-10-08 06:52:31 - train: epoch 0056, iter [00550, 01251], lr: 0.000903, loss: 3.0913
2022-10-08 06:52:52 - train: epoch 0056, iter [00560, 01251], lr: 0.000903, loss: 3.4429
2022-10-08 06:53:13 - train: epoch 0056, iter [00570, 01251], lr: 0.000903, loss: 2.8273
2022-10-08 06:53:34 - train: epoch 0056, iter [00580, 01251], lr: 0.000903, loss: 3.2571
2022-10-08 06:53:55 - train: epoch 0056, iter [00590, 01251], lr: 0.000902, loss: 2.3480
2022-10-08 06:54:16 - train: epoch 0056, iter [00600, 01251], lr: 0.000902, loss: 3.4603
2022-10-08 06:54:37 - train: epoch 0056, iter [00610, 01251], lr: 0.000902, loss: 2.8527
2022-10-08 06:54:58 - train: epoch 0056, iter [00620, 01251], lr: 0.000902, loss: 2.6462
2022-10-08 06:55:19 - train: epoch 0056, iter [00630, 01251], lr: 0.000901, loss: 3.6837
2022-10-08 06:55:40 - train: epoch 0056, iter [00640, 01251], lr: 0.000901, loss: 3.1876
2022-10-08 06:56:01 - train: epoch 0056, iter [00650, 01251], lr: 0.000901, loss: 2.6610
2022-10-08 06:56:22 - train: epoch 0056, iter [00660, 01251], lr: 0.000901, loss: 3.3259
2022-10-08 06:56:44 - train: epoch 0056, iter [00670, 01251], lr: 0.000900, loss: 3.3778
2022-10-08 06:57:05 - train: epoch 0056, iter [00680, 01251], lr: 0.000900, loss: 3.0659
2022-10-08 06:57:26 - train: epoch 0056, iter [00690, 01251], lr: 0.000900, loss: 2.7051
2022-10-08 06:57:47 - train: epoch 0056, iter [00700, 01251], lr: 0.000900, loss: 2.7088
2022-10-08 06:58:08 - train: epoch 0056, iter [00710, 01251], lr: 0.000899, loss: 2.9492
2022-10-08 06:58:29 - train: epoch 0056, iter [00720, 01251], lr: 0.000899, loss: 2.7941
2022-10-08 06:58:50 - train: epoch 0056, iter [00730, 01251], lr: 0.000899, loss: 3.3576
2022-10-08 06:59:11 - train: epoch 0056, iter [00740, 01251], lr: 0.000898, loss: 2.7478
2022-10-08 06:59:32 - train: epoch 0056, iter [00750, 01251], lr: 0.000898, loss: 3.1733
2022-10-08 06:59:53 - train: epoch 0056, iter [00760, 01251], lr: 0.000898, loss: 3.1832
2022-10-08 07:00:14 - train: epoch 0056, iter [00770, 01251], lr: 0.000898, loss: 3.2328
2022-10-08 07:00:35 - train: epoch 0056, iter [00780, 01251], lr: 0.000897, loss: 3.2432
2022-10-08 07:00:56 - train: epoch 0056, iter [00790, 01251], lr: 0.000897, loss: 3.2630
2022-10-08 07:01:17 - train: epoch 0056, iter [00800, 01251], lr: 0.000897, loss: 2.8986
2022-10-08 07:01:38 - train: epoch 0056, iter [00810, 01251], lr: 0.000897, loss: 3.2285
2022-10-08 07:01:59 - train: epoch 0056, iter [00820, 01251], lr: 0.000896, loss: 2.8422
2022-10-08 07:02:20 - train: epoch 0056, iter [00830, 01251], lr: 0.000896, loss: 3.3421
2022-10-08 07:02:41 - train: epoch 0056, iter [00840, 01251], lr: 0.000896, loss: 3.3597
2022-10-08 07:03:02 - train: epoch 0056, iter [00850, 01251], lr: 0.000896, loss: 2.7504
2022-10-08 07:03:23 - train: epoch 0056, iter [00860, 01251], lr: 0.000895, loss: 2.9269
2022-10-08 07:03:45 - train: epoch 0056, iter [00870, 01251], lr: 0.000895, loss: 3.2840
2022-10-08 07:04:06 - train: epoch 0056, iter [00880, 01251], lr: 0.000895, loss: 3.0425
2022-10-08 07:04:27 - train: epoch 0056, iter [00890, 01251], lr: 0.000895, loss: 2.8827
2022-10-08 07:04:48 - train: epoch 0056, iter [00900, 01251], lr: 0.000894, loss: 2.8340
2022-10-08 07:05:09 - train: epoch 0056, iter [00910, 01251], lr: 0.000894, loss: 2.9032
2022-10-08 07:05:30 - train: epoch 0056, iter [00920, 01251], lr: 0.000894, loss: 3.3328
2022-10-08 07:05:51 - train: epoch 0056, iter [00930, 01251], lr: 0.000894, loss: 3.2082
2022-10-08 07:06:12 - train: epoch 0056, iter [00940, 01251], lr: 0.000893, loss: 2.4222
2022-10-08 07:06:33 - train: epoch 0056, iter [00950, 01251], lr: 0.000893, loss: 3.2928
2022-10-08 07:06:54 - train: epoch 0056, iter [00960, 01251], lr: 0.000893, loss: 2.7943
2022-10-08 07:07:15 - train: epoch 0056, iter [00970, 01251], lr: 0.000892, loss: 3.5144
2022-10-08 07:07:36 - train: epoch 0056, iter [00980, 01251], lr: 0.000892, loss: 2.9167
2022-10-08 07:07:57 - train: epoch 0056, iter [00990, 01251], lr: 0.000892, loss: 3.4966
2022-10-08 07:08:18 - train: epoch 0056, iter [01000, 01251], lr: 0.000892, loss: 2.3011
2022-10-08 07:08:39 - train: epoch 0056, iter [01010, 01251], lr: 0.000891, loss: 3.4064
2022-10-08 07:09:00 - train: epoch 0056, iter [01020, 01251], lr: 0.000891, loss: 3.3521
2022-10-08 07:09:21 - train: epoch 0056, iter [01030, 01251], lr: 0.000891, loss: 2.0110
2022-10-08 07:09:42 - train: epoch 0056, iter [01040, 01251], lr: 0.000891, loss: 3.0248
2022-10-08 07:10:03 - train: epoch 0056, iter [01050, 01251], lr: 0.000890, loss: 3.4258
2022-10-08 07:10:24 - train: epoch 0056, iter [01060, 01251], lr: 0.000890, loss: 3.4797
2022-10-08 07:10:45 - train: epoch 0056, iter [01070, 01251], lr: 0.000890, loss: 2.0597
2022-10-08 07:11:06 - train: epoch 0056, iter [01080, 01251], lr: 0.000890, loss: 3.3606
2022-10-08 07:11:28 - train: epoch 0056, iter [01090, 01251], lr: 0.000889, loss: 3.1301
2022-10-08 07:11:49 - train: epoch 0056, iter [01100, 01251], lr: 0.000889, loss: 2.9728
2022-10-08 07:12:10 - train: epoch 0056, iter [01110, 01251], lr: 0.000889, loss: 2.6448
2022-10-08 07:12:31 - train: epoch 0056, iter [01120, 01251], lr: 0.000889, loss: 3.1160
2022-10-08 07:12:52 - train: epoch 0056, iter [01130, 01251], lr: 0.000888, loss: 3.0999
2022-10-08 07:13:13 - train: epoch 0056, iter [01140, 01251], lr: 0.000888, loss: 3.0285
2022-10-08 07:13:34 - train: epoch 0056, iter [01150, 01251], lr: 0.000888, loss: 3.3271
2022-10-08 07:13:55 - train: epoch 0056, iter [01160, 01251], lr: 0.000887, loss: 3.1427
2022-10-08 07:14:16 - train: epoch 0056, iter [01170, 01251], lr: 0.000887, loss: 3.0294
2022-10-08 07:14:37 - train: epoch 0056, iter [01180, 01251], lr: 0.000887, loss: 3.0040
2022-10-08 07:14:58 - train: epoch 0056, iter [01190, 01251], lr: 0.000887, loss: 2.6761
2022-10-08 07:15:19 - train: epoch 0056, iter [01200, 01251], lr: 0.000886, loss: 3.3657
2022-10-08 07:15:40 - train: epoch 0056, iter [01210, 01251], lr: 0.000886, loss: 3.0992
2022-10-08 07:16:01 - train: epoch 0056, iter [01220, 01251], lr: 0.000886, loss: 3.4894
2022-10-08 07:16:22 - train: epoch 0056, iter [01230, 01251], lr: 0.000886, loss: 3.1259
2022-10-08 07:16:43 - train: epoch 0056, iter [01240, 01251], lr: 0.000885, loss: 2.8020
2022-10-08 07:17:04 - train: epoch 0056, iter [01250, 01251], lr: 0.000885, loss: 2.9767
2022-10-08 07:17:08 - train: epoch 056, train_loss: 3.0466
2022-10-08 07:18:24 - eval: epoch: 056, acc1: 81.098%, acc5: 95.888%, test_loss: 0.8169, per_image_load_time: 0.589ms, per_image_inference_time: 1.429ms
2022-10-08 07:18:25 - until epoch: 056, best_acc1: 81.098%
2022-10-08 07:18:25 - epoch 057 lr: 0.000885
2022-10-08 07:18:52 - train: epoch 0057, iter [00010, 01251], lr: 0.000885, loss: 3.3052
2022-10-08 07:19:13 - train: epoch 0057, iter [00020, 01251], lr: 0.000885, loss: 2.7473
2022-10-08 07:19:34 - train: epoch 0057, iter [00030, 01251], lr: 0.000884, loss: 2.9279
2022-10-08 07:19:55 - train: epoch 0057, iter [00040, 01251], lr: 0.000884, loss: 3.1750
2022-10-08 07:20:17 - train: epoch 0057, iter [00050, 01251], lr: 0.000884, loss: 3.2041
2022-10-08 07:20:38 - train: epoch 0057, iter [00060, 01251], lr: 0.000883, loss: 3.0760
2022-10-08 07:20:59 - train: epoch 0057, iter [00070, 01251], lr: 0.000883, loss: 3.1426
2022-10-08 07:21:20 - train: epoch 0057, iter [00080, 01251], lr: 0.000883, loss: 3.2647
2022-10-08 07:21:41 - train: epoch 0057, iter [00090, 01251], lr: 0.000883, loss: 3.1670
2022-10-08 07:22:03 - train: epoch 0057, iter [00100, 01251], lr: 0.000882, loss: 2.5873
2022-10-08 07:22:24 - train: epoch 0057, iter [00110, 01251], lr: 0.000882, loss: 2.7239
2022-10-08 07:22:45 - train: epoch 0057, iter [00120, 01251], lr: 0.000882, loss: 3.3342
2022-10-08 07:23:06 - train: epoch 0057, iter [00130, 01251], lr: 0.000882, loss: 3.5020
2022-10-08 07:23:28 - train: epoch 0057, iter [00140, 01251], lr: 0.000881, loss: 2.8212
2022-10-08 07:23:49 - train: epoch 0057, iter [00150, 01251], lr: 0.000881, loss: 2.8573
2022-10-08 07:24:10 - train: epoch 0057, iter [00160, 01251], lr: 0.000881, loss: 3.1065
2022-10-08 07:24:31 - train: epoch 0057, iter [00170, 01251], lr: 0.000881, loss: 2.3072
2022-10-08 07:24:52 - train: epoch 0057, iter [00180, 01251], lr: 0.000880, loss: 2.9656
2022-10-08 07:25:14 - train: epoch 0057, iter [00190, 01251], lr: 0.000880, loss: 3.0714
2022-10-08 07:25:35 - train: epoch 0057, iter [00200, 01251], lr: 0.000880, loss: 2.8551
2022-10-08 07:25:56 - train: epoch 0057, iter [00210, 01251], lr: 0.000880, loss: 3.6151
2022-10-08 07:26:17 - train: epoch 0057, iter [00220, 01251], lr: 0.000879, loss: 3.1705
2022-10-08 07:26:38 - train: epoch 0057, iter [00230, 01251], lr: 0.000879, loss: 2.7679
2022-10-08 07:26:59 - train: epoch 0057, iter [00240, 01251], lr: 0.000879, loss: 2.5533
2022-10-08 07:27:21 - train: epoch 0057, iter [00250, 01251], lr: 0.000879, loss: 2.7206
2022-10-08 07:27:42 - train: epoch 0057, iter [00260, 01251], lr: 0.000878, loss: 3.3334
2022-10-08 07:28:03 - train: epoch 0057, iter [00270, 01251], lr: 0.000878, loss: 2.7104
2022-10-08 07:28:24 - train: epoch 0057, iter [00280, 01251], lr: 0.000878, loss: 2.9399
2022-10-08 07:28:45 - train: epoch 0057, iter [00290, 01251], lr: 0.000877, loss: 3.3572
2022-10-08 07:29:06 - train: epoch 0057, iter [00300, 01251], lr: 0.000877, loss: 3.2084
2022-10-08 07:29:28 - train: epoch 0057, iter [00310, 01251], lr: 0.000877, loss: 3.4215
2022-10-08 07:29:49 - train: epoch 0057, iter [00320, 01251], lr: 0.000877, loss: 3.3878
2022-10-08 07:30:10 - train: epoch 0057, iter [00330, 01251], lr: 0.000876, loss: 2.1374
2022-10-08 07:30:31 - train: epoch 0057, iter [00340, 01251], lr: 0.000876, loss: 3.0589
2022-10-08 07:30:52 - train: epoch 0057, iter [00350, 01251], lr: 0.000876, loss: 2.5830
2022-10-08 07:31:13 - train: epoch 0057, iter [00360, 01251], lr: 0.000876, loss: 2.3730
2022-10-08 07:31:34 - train: epoch 0057, iter [00370, 01251], lr: 0.000875, loss: 3.5204
2022-10-08 07:31:55 - train: epoch 0057, iter [00380, 01251], lr: 0.000875, loss: 2.5996
2022-10-08 07:32:17 - train: epoch 0057, iter [00390, 01251], lr: 0.000875, loss: 2.7967
2022-10-08 07:32:38 - train: epoch 0057, iter [00400, 01251], lr: 0.000875, loss: 3.1360
2022-10-08 07:32:59 - train: epoch 0057, iter [00410, 01251], lr: 0.000874, loss: 2.9411
2022-10-08 07:33:20 - train: epoch 0057, iter [00420, 01251], lr: 0.000874, loss: 3.5522
2022-10-08 07:33:41 - train: epoch 0057, iter [00430, 01251], lr: 0.000874, loss: 2.6530
2022-10-08 07:34:02 - train: epoch 0057, iter [00440, 01251], lr: 0.000874, loss: 3.2392
2022-10-08 07:34:23 - train: epoch 0057, iter [00450, 01251], lr: 0.000873, loss: 3.3150
2022-10-08 07:34:45 - train: epoch 0057, iter [00460, 01251], lr: 0.000873, loss: 3.3538
2022-10-08 07:35:06 - train: epoch 0057, iter [00470, 01251], lr: 0.000873, loss: 2.4796
2022-10-08 07:35:27 - train: epoch 0057, iter [00480, 01251], lr: 0.000872, loss: 3.1582
2022-10-08 07:35:48 - train: epoch 0057, iter [00490, 01251], lr: 0.000872, loss: 3.1000
2022-10-08 07:36:09 - train: epoch 0057, iter [00500, 01251], lr: 0.000872, loss: 2.2075
2022-10-08 07:36:30 - train: epoch 0057, iter [00510, 01251], lr: 0.000872, loss: 3.1685
2022-10-08 07:36:52 - train: epoch 0057, iter [00520, 01251], lr: 0.000871, loss: 3.3201
2022-10-08 07:37:13 - train: epoch 0057, iter [00530, 01251], lr: 0.000871, loss: 3.3983
2022-10-08 07:37:34 - train: epoch 0057, iter [00540, 01251], lr: 0.000871, loss: 3.3387
2022-10-08 07:37:55 - train: epoch 0057, iter [00550, 01251], lr: 0.000871, loss: 2.2200
2022-10-08 07:38:16 - train: epoch 0057, iter [00560, 01251], lr: 0.000870, loss: 2.5985
2022-10-08 07:38:37 - train: epoch 0057, iter [00570, 01251], lr: 0.000870, loss: 3.6270
2022-10-08 07:38:58 - train: epoch 0057, iter [00580, 01251], lr: 0.000870, loss: 3.1767
2022-10-08 07:39:20 - train: epoch 0057, iter [00590, 01251], lr: 0.000870, loss: 3.1940
2022-10-08 07:39:41 - train: epoch 0057, iter [00600, 01251], lr: 0.000869, loss: 2.7366
2022-10-08 07:40:02 - train: epoch 0057, iter [00610, 01251], lr: 0.000869, loss: 3.6446
2022-10-08 07:40:23 - train: epoch 0057, iter [00620, 01251], lr: 0.000869, loss: 3.3810
2022-10-08 07:40:44 - train: epoch 0057, iter [00630, 01251], lr: 0.000869, loss: 2.0868
2022-10-08 07:41:05 - train: epoch 0057, iter [00640, 01251], lr: 0.000868, loss: 3.2161
2022-10-08 07:41:26 - train: epoch 0057, iter [00650, 01251], lr: 0.000868, loss: 3.0476
2022-10-08 07:41:47 - train: epoch 0057, iter [00660, 01251], lr: 0.000868, loss: 3.0010
2022-10-08 07:42:09 - train: epoch 0057, iter [00670, 01251], lr: 0.000868, loss: 3.2245
2022-10-08 07:42:30 - train: epoch 0057, iter [00680, 01251], lr: 0.000867, loss: 3.4013
2022-10-08 07:42:51 - train: epoch 0057, iter [00690, 01251], lr: 0.000867, loss: 2.8349
2022-10-08 07:43:12 - train: epoch 0057, iter [00700, 01251], lr: 0.000867, loss: 2.6936
2022-10-08 07:43:33 - train: epoch 0057, iter [00710, 01251], lr: 0.000866, loss: 2.8372
2022-10-08 07:43:54 - train: epoch 0057, iter [00720, 01251], lr: 0.000866, loss: 2.9477
2022-10-08 07:44:15 - train: epoch 0057, iter [00730, 01251], lr: 0.000866, loss: 2.6704
2022-10-08 07:44:36 - train: epoch 0057, iter [00740, 01251], lr: 0.000866, loss: 3.5282
2022-10-08 07:44:57 - train: epoch 0057, iter [00750, 01251], lr: 0.000865, loss: 2.7640
2022-10-08 07:45:19 - train: epoch 0057, iter [00760, 01251], lr: 0.000865, loss: 2.8930
2022-10-08 07:45:40 - train: epoch 0057, iter [00770, 01251], lr: 0.000865, loss: 2.8844
2022-10-08 07:46:01 - train: epoch 0057, iter [00780, 01251], lr: 0.000865, loss: 3.3847
2022-10-08 07:46:22 - train: epoch 0057, iter [00790, 01251], lr: 0.000864, loss: 2.5674
2022-10-08 07:46:43 - train: epoch 0057, iter [00800, 01251], lr: 0.000864, loss: 3.5618
2022-10-08 07:47:04 - train: epoch 0057, iter [00810, 01251], lr: 0.000864, loss: 3.3145
2022-10-08 07:47:25 - train: epoch 0057, iter [00820, 01251], lr: 0.000864, loss: 2.9159
2022-10-08 07:47:46 - train: epoch 0057, iter [00830, 01251], lr: 0.000863, loss: 2.9175
2022-10-08 07:48:07 - train: epoch 0057, iter [00840, 01251], lr: 0.000863, loss: 3.3123
2022-10-08 07:48:28 - train: epoch 0057, iter [00850, 01251], lr: 0.000863, loss: 2.9794
2022-10-08 07:48:50 - train: epoch 0057, iter [00860, 01251], lr: 0.000863, loss: 2.8065
2022-10-08 07:49:11 - train: epoch 0057, iter [00870, 01251], lr: 0.000862, loss: 2.9192
2022-10-08 07:49:32 - train: epoch 0057, iter [00880, 01251], lr: 0.000862, loss: 2.7773
2022-10-08 07:49:53 - train: epoch 0057, iter [00890, 01251], lr: 0.000862, loss: 3.2120
2022-10-08 07:50:14 - train: epoch 0057, iter [00900, 01251], lr: 0.000861, loss: 3.4996
2022-10-08 07:50:35 - train: epoch 0057, iter [00910, 01251], lr: 0.000861, loss: 2.5175
2022-10-08 07:50:56 - train: epoch 0057, iter [00920, 01251], lr: 0.000861, loss: 2.7488
2022-10-08 07:51:17 - train: epoch 0057, iter [00930, 01251], lr: 0.000861, loss: 3.4477
2022-10-08 07:51:39 - train: epoch 0057, iter [00940, 01251], lr: 0.000860, loss: 3.1103
2022-10-08 07:52:00 - train: epoch 0057, iter [00950, 01251], lr: 0.000860, loss: 2.6695
2022-10-08 07:52:21 - train: epoch 0057, iter [00960, 01251], lr: 0.000860, loss: 3.3006
2022-10-08 07:52:42 - train: epoch 0057, iter [00970, 01251], lr: 0.000860, loss: 2.7758
2022-10-08 07:53:03 - train: epoch 0057, iter [00980, 01251], lr: 0.000859, loss: 3.1464
2022-10-08 07:53:24 - train: epoch 0057, iter [00990, 01251], lr: 0.000859, loss: 3.2059
2022-10-08 07:53:45 - train: epoch 0057, iter [01000, 01251], lr: 0.000859, loss: 3.1120
2022-10-08 07:54:06 - train: epoch 0057, iter [01010, 01251], lr: 0.000859, loss: 3.3948
2022-10-08 07:54:27 - train: epoch 0057, iter [01020, 01251], lr: 0.000858, loss: 3.3376
2022-10-08 07:54:49 - train: epoch 0057, iter [01030, 01251], lr: 0.000858, loss: 3.5011
2022-10-08 07:55:10 - train: epoch 0057, iter [01040, 01251], lr: 0.000858, loss: 2.9249
2022-10-08 07:55:31 - train: epoch 0057, iter [01050, 01251], lr: 0.000858, loss: 2.7530
2022-10-08 07:55:52 - train: epoch 0057, iter [01060, 01251], lr: 0.000857, loss: 2.8710
2022-10-08 07:56:13 - train: epoch 0057, iter [01070, 01251], lr: 0.000857, loss: 2.8131
2022-10-08 07:56:34 - train: epoch 0057, iter [01080, 01251], lr: 0.000857, loss: 3.3944
2022-10-08 07:56:55 - train: epoch 0057, iter [01090, 01251], lr: 0.000857, loss: 3.5490
2022-10-08 07:57:16 - train: epoch 0057, iter [01100, 01251], lr: 0.000856, loss: 3.2020
2022-10-08 07:57:37 - train: epoch 0057, iter [01110, 01251], lr: 0.000856, loss: 3.4199
2022-10-08 07:57:58 - train: epoch 0057, iter [01120, 01251], lr: 0.000856, loss: 3.4466
2022-10-08 07:58:19 - train: epoch 0057, iter [01130, 01251], lr: 0.000855, loss: 2.7812
2022-10-08 07:58:40 - train: epoch 0057, iter [01140, 01251], lr: 0.000855, loss: 3.3951
2022-10-08 07:59:02 - train: epoch 0057, iter [01150, 01251], lr: 0.000855, loss: 2.4795
2022-10-08 07:59:23 - train: epoch 0057, iter [01160, 01251], lr: 0.000855, loss: 3.2661
2022-10-08 07:59:44 - train: epoch 0057, iter [01170, 01251], lr: 0.000854, loss: 2.7266
2022-10-08 08:00:05 - train: epoch 0057, iter [01180, 01251], lr: 0.000854, loss: 2.9361
2022-10-08 08:00:26 - train: epoch 0057, iter [01190, 01251], lr: 0.000854, loss: 3.3694
2022-10-08 08:00:47 - train: epoch 0057, iter [01200, 01251], lr: 0.000854, loss: 2.9675
2022-10-08 08:01:08 - train: epoch 0057, iter [01210, 01251], lr: 0.000853, loss: 2.2881
2022-10-08 08:01:29 - train: epoch 0057, iter [01220, 01251], lr: 0.000853, loss: 3.5336
2022-10-08 08:01:50 - train: epoch 0057, iter [01230, 01251], lr: 0.000853, loss: 3.3885
2022-10-08 08:02:11 - train: epoch 0057, iter [01240, 01251], lr: 0.000853, loss: 3.1598
2022-10-08 08:02:32 - train: epoch 0057, iter [01250, 01251], lr: 0.000852, loss: 3.3238
2022-10-08 08:02:35 - train: epoch 057, train_loss: 3.0407
2022-10-08 08:03:52 - eval: epoch: 057, acc1: 81.108%, acc5: 95.920%, test_loss: 0.8140, per_image_load_time: 1.197ms, per_image_inference_time: 1.449ms
2022-10-08 08:03:54 - until epoch: 057, best_acc1: 81.108%
2022-10-08 08:03:54 - epoch 058 lr: 0.000852
2022-10-08 08:04:21 - train: epoch 0058, iter [00010, 01251], lr: 0.000852, loss: 3.1069
2022-10-08 08:04:42 - train: epoch 0058, iter [00020, 01251], lr: 0.000852, loss: 3.5212
2022-10-08 08:05:03 - train: epoch 0058, iter [00030, 01251], lr: 0.000852, loss: 3.3549
2022-10-08 08:05:24 - train: epoch 0058, iter [00040, 01251], lr: 0.000851, loss: 3.1134
2022-10-08 08:05:45 - train: epoch 0058, iter [00050, 01251], lr: 0.000851, loss: 2.7360
2022-10-08 08:06:07 - train: epoch 0058, iter [00060, 01251], lr: 0.000851, loss: 3.0775
2022-10-08 08:06:28 - train: epoch 0058, iter [00070, 01251], lr: 0.000850, loss: 3.1654
2022-10-08 08:06:49 - train: epoch 0058, iter [00080, 01251], lr: 0.000850, loss: 2.8241
2022-10-08 08:07:10 - train: epoch 0058, iter [00090, 01251], lr: 0.000850, loss: 2.6277
2022-10-08 08:07:31 - train: epoch 0058, iter [00100, 01251], lr: 0.000850, loss: 2.9576
2022-10-08 08:07:52 - train: epoch 0058, iter [00110, 01251], lr: 0.000849, loss: 3.1967
2022-10-08 08:08:14 - train: epoch 0058, iter [00120, 01251], lr: 0.000849, loss: 2.1481
2022-10-08 08:08:35 - train: epoch 0058, iter [00130, 01251], lr: 0.000849, loss: 3.1415
2022-10-08 08:08:56 - train: epoch 0058, iter [00140, 01251], lr: 0.000849, loss: 2.4641
2022-10-08 08:09:17 - train: epoch 0058, iter [00150, 01251], lr: 0.000848, loss: 3.3742
2022-10-08 08:09:38 - train: epoch 0058, iter [00160, 01251], lr: 0.000848, loss: 2.5219
2022-10-08 08:10:00 - train: epoch 0058, iter [00170, 01251], lr: 0.000848, loss: 3.4372
2022-10-08 08:10:21 - train: epoch 0058, iter [00180, 01251], lr: 0.000848, loss: 3.4116
2022-10-08 08:10:42 - train: epoch 0058, iter [00190, 01251], lr: 0.000847, loss: 2.2134
2022-10-08 08:11:03 - train: epoch 0058, iter [00200, 01251], lr: 0.000847, loss: 2.4944
2022-10-08 08:11:25 - train: epoch 0058, iter [00210, 01251], lr: 0.000847, loss: 2.7947
2022-10-08 08:11:46 - train: epoch 0058, iter [00220, 01251], lr: 0.000847, loss: 3.4673
2022-10-08 08:12:07 - train: epoch 0058, iter [00230, 01251], lr: 0.000846, loss: 2.4208
2022-10-08 08:12:28 - train: epoch 0058, iter [00240, 01251], lr: 0.000846, loss: 2.8367
2022-10-08 08:12:49 - train: epoch 0058, iter [00250, 01251], lr: 0.000846, loss: 3.3791
2022-10-08 08:13:11 - train: epoch 0058, iter [00260, 01251], lr: 0.000846, loss: 2.4025
2022-10-08 08:13:32 - train: epoch 0058, iter [00270, 01251], lr: 0.000845, loss: 2.6163
2022-10-08 08:13:53 - train: epoch 0058, iter [00280, 01251], lr: 0.000845, loss: 3.1196
2022-10-08 08:14:14 - train: epoch 0058, iter [00290, 01251], lr: 0.000845, loss: 2.8176
2022-10-08 08:14:35 - train: epoch 0058, iter [00300, 01251], lr: 0.000844, loss: 3.0807
2022-10-08 08:14:57 - train: epoch 0058, iter [00310, 01251], lr: 0.000844, loss: 3.0227
2022-10-08 08:15:18 - train: epoch 0058, iter [00320, 01251], lr: 0.000844, loss: 3.3348
2022-10-08 08:15:39 - train: epoch 0058, iter [00330, 01251], lr: 0.000844, loss: 3.3266
2022-10-08 08:16:00 - train: epoch 0058, iter [00340, 01251], lr: 0.000843, loss: 3.1643
2022-10-08 08:16:22 - train: epoch 0058, iter [00350, 01251], lr: 0.000843, loss: 2.8300
2022-10-08 08:16:43 - train: epoch 0058, iter [00360, 01251], lr: 0.000843, loss: 2.8148
2022-10-08 08:17:04 - train: epoch 0058, iter [00370, 01251], lr: 0.000843, loss: 3.4654
2022-10-08 08:17:25 - train: epoch 0058, iter [00380, 01251], lr: 0.000842, loss: 3.2495
2022-10-08 08:17:46 - train: epoch 0058, iter [00390, 01251], lr: 0.000842, loss: 3.0441
2022-10-08 08:18:07 - train: epoch 0058, iter [00400, 01251], lr: 0.000842, loss: 2.7983
2022-10-08 08:18:29 - train: epoch 0058, iter [00410, 01251], lr: 0.000842, loss: 2.5906
2022-10-08 08:18:50 - train: epoch 0058, iter [00420, 01251], lr: 0.000841, loss: 2.6888
2022-10-08 08:19:11 - train: epoch 0058, iter [00430, 01251], lr: 0.000841, loss: 3.4025
2022-10-08 08:19:32 - train: epoch 0058, iter [00440, 01251], lr: 0.000841, loss: 3.4915
2022-10-08 08:19:53 - train: epoch 0058, iter [00450, 01251], lr: 0.000841, loss: 2.8648
2022-10-08 08:20:14 - train: epoch 0058, iter [00460, 01251], lr: 0.000840, loss: 2.8765
2022-10-08 08:20:36 - train: epoch 0058, iter [00470, 01251], lr: 0.000840, loss: 3.2394
2022-10-08 08:20:57 - train: epoch 0058, iter [00480, 01251], lr: 0.000840, loss: 2.7729
2022-10-08 08:21:18 - train: epoch 0058, iter [00490, 01251], lr: 0.000840, loss: 2.5771
2022-10-08 08:21:39 - train: epoch 0058, iter [00500, 01251], lr: 0.000839, loss: 2.7657
2022-10-08 08:22:00 - train: epoch 0058, iter [00510, 01251], lr: 0.000839, loss: 3.2749
2022-10-08 08:22:21 - train: epoch 0058, iter [00520, 01251], lr: 0.000839, loss: 2.8513
2022-10-08 08:22:42 - train: epoch 0058, iter [00530, 01251], lr: 0.000838, loss: 3.0555
2022-10-08 08:23:04 - train: epoch 0058, iter [00540, 01251], lr: 0.000838, loss: 2.8746
2022-10-08 08:23:25 - train: epoch 0058, iter [00550, 01251], lr: 0.000838, loss: 3.2544
2022-10-08 08:23:46 - train: epoch 0058, iter [00560, 01251], lr: 0.000838, loss: 3.4950
2022-10-08 08:24:07 - train: epoch 0058, iter [00570, 01251], lr: 0.000837, loss: 3.0092
2022-10-08 08:24:28 - train: epoch 0058, iter [00580, 01251], lr: 0.000837, loss: 3.3203
2022-10-08 08:24:49 - train: epoch 0058, iter [00590, 01251], lr: 0.000837, loss: 3.4542
2022-10-08 08:25:11 - train: epoch 0058, iter [00600, 01251], lr: 0.000837, loss: 2.6766
2022-10-08 08:25:32 - train: epoch 0058, iter [00610, 01251], lr: 0.000836, loss: 3.1020
2022-10-08 08:25:53 - train: epoch 0058, iter [00620, 01251], lr: 0.000836, loss: 2.9447
2022-10-08 08:26:14 - train: epoch 0058, iter [00630, 01251], lr: 0.000836, loss: 2.4416
2022-10-08 08:26:35 - train: epoch 0058, iter [00640, 01251], lr: 0.000836, loss: 3.1034
2022-10-08 08:26:56 - train: epoch 0058, iter [00650, 01251], lr: 0.000835, loss: 3.3730
2022-10-08 08:27:18 - train: epoch 0058, iter [00660, 01251], lr: 0.000835, loss: 2.0957
2022-10-08 08:27:39 - train: epoch 0058, iter [00670, 01251], lr: 0.000835, loss: 3.4350
2022-10-08 08:28:00 - train: epoch 0058, iter [00680, 01251], lr: 0.000835, loss: 3.1301
2022-10-08 08:28:21 - train: epoch 0058, iter [00690, 01251], lr: 0.000834, loss: 3.6211
2022-10-08 08:28:43 - train: epoch 0058, iter [00700, 01251], lr: 0.000834, loss: 3.2495
2022-10-08 08:29:04 - train: epoch 0058, iter [00710, 01251], lr: 0.000834, loss: 2.6393
2022-10-08 08:29:25 - train: epoch 0058, iter [00720, 01251], lr: 0.000834, loss: 2.2280
2022-10-08 08:29:46 - train: epoch 0058, iter [00730, 01251], lr: 0.000833, loss: 3.2386
2022-10-08 08:30:07 - train: epoch 0058, iter [00740, 01251], lr: 0.000833, loss: 3.0753
2022-10-08 08:30:28 - train: epoch 0058, iter [00750, 01251], lr: 0.000833, loss: 3.4827
2022-10-08 08:30:50 - train: epoch 0058, iter [00760, 01251], lr: 0.000832, loss: 3.3755
2022-10-08 08:31:11 - train: epoch 0058, iter [00770, 01251], lr: 0.000832, loss: 3.0344
2022-10-08 08:31:32 - train: epoch 0058, iter [00780, 01251], lr: 0.000832, loss: 2.4910
2022-10-08 08:31:53 - train: epoch 0058, iter [00790, 01251], lr: 0.000832, loss: 2.5660
2022-10-08 08:32:14 - train: epoch 0058, iter [00800, 01251], lr: 0.000831, loss: 3.0279
2022-10-08 08:32:35 - train: epoch 0058, iter [00810, 01251], lr: 0.000831, loss: 3.2068
2022-10-08 08:32:57 - train: epoch 0058, iter [00820, 01251], lr: 0.000831, loss: 2.8526
2022-10-08 08:33:18 - train: epoch 0058, iter [00830, 01251], lr: 0.000831, loss: 3.3720
2022-10-08 08:33:39 - train: epoch 0058, iter [00840, 01251], lr: 0.000830, loss: 3.6210
2022-10-08 08:34:00 - train: epoch 0058, iter [00850, 01251], lr: 0.000830, loss: 2.7229
2022-10-08 08:34:21 - train: epoch 0058, iter [00860, 01251], lr: 0.000830, loss: 2.9434
2022-10-08 08:34:42 - train: epoch 0058, iter [00870, 01251], lr: 0.000830, loss: 2.9189
2022-10-08 08:35:03 - train: epoch 0058, iter [00880, 01251], lr: 0.000829, loss: 3.3447
2022-10-08 08:35:25 - train: epoch 0058, iter [00890, 01251], lr: 0.000829, loss: 1.9871
2022-10-08 08:35:46 - train: epoch 0058, iter [00900, 01251], lr: 0.000829, loss: 3.2005
2022-10-08 08:36:07 - train: epoch 0058, iter [00910, 01251], lr: 0.000829, loss: 3.4319
2022-10-08 08:36:28 - train: epoch 0058, iter [00920, 01251], lr: 0.000828, loss: 3.2491
2022-10-08 08:36:49 - train: epoch 0058, iter [00930, 01251], lr: 0.000828, loss: 2.8132
2022-10-08 08:37:10 - train: epoch 0058, iter [00940, 01251], lr: 0.000828, loss: 3.1496
2022-10-08 08:37:32 - train: epoch 0058, iter [00950, 01251], lr: 0.000828, loss: 3.1395
2022-10-08 08:37:53 - train: epoch 0058, iter [00960, 01251], lr: 0.000827, loss: 3.3422
2022-10-08 08:38:14 - train: epoch 0058, iter [00970, 01251], lr: 0.000827, loss: 2.7088
2022-10-08 08:38:35 - train: epoch 0058, iter [00980, 01251], lr: 0.000827, loss: 3.2471
2022-10-08 08:38:56 - train: epoch 0058, iter [00990, 01251], lr: 0.000826, loss: 2.8943
2022-10-08 08:39:18 - train: epoch 0058, iter [01000, 01251], lr: 0.000826, loss: 3.4269
2022-10-08 08:39:39 - train: epoch 0058, iter [01010, 01251], lr: 0.000826, loss: 3.3726
2022-10-08 08:40:00 - train: epoch 0058, iter [01020, 01251], lr: 0.000826, loss: 2.6272
2022-10-08 08:40:21 - train: epoch 0058, iter [01030, 01251], lr: 0.000825, loss: 2.8714
2022-10-08 08:40:42 - train: epoch 0058, iter [01040, 01251], lr: 0.000825, loss: 2.8376
2022-10-08 08:41:03 - train: epoch 0058, iter [01050, 01251], lr: 0.000825, loss: 2.5386
2022-10-08 08:41:24 - train: epoch 0058, iter [01060, 01251], lr: 0.000825, loss: 3.2499
2022-10-08 08:41:46 - train: epoch 0058, iter [01070, 01251], lr: 0.000824, loss: 2.7120
2022-10-08 08:42:07 - train: epoch 0058, iter [01080, 01251], lr: 0.000824, loss: 2.7799
2022-10-08 08:42:28 - train: epoch 0058, iter [01090, 01251], lr: 0.000824, loss: 2.1727
2022-10-08 08:42:49 - train: epoch 0058, iter [01100, 01251], lr: 0.000824, loss: 2.6302
2022-10-08 08:43:10 - train: epoch 0058, iter [01110, 01251], lr: 0.000823, loss: 3.5244
2022-10-08 08:43:31 - train: epoch 0058, iter [01120, 01251], lr: 0.000823, loss: 3.4551
2022-10-08 08:43:52 - train: epoch 0058, iter [01130, 01251], lr: 0.000823, loss: 3.0150
2022-10-08 08:44:14 - train: epoch 0058, iter [01140, 01251], lr: 0.000823, loss: 2.5140
2022-10-08 08:44:35 - train: epoch 0058, iter [01150, 01251], lr: 0.000822, loss: 3.1033
2022-10-08 08:44:56 - train: epoch 0058, iter [01160, 01251], lr: 0.000822, loss: 2.6960
2022-10-08 08:45:17 - train: epoch 0058, iter [01170, 01251], lr: 0.000822, loss: 3.2350
2022-10-08 08:45:38 - train: epoch 0058, iter [01180, 01251], lr: 0.000822, loss: 2.4991
2022-10-08 08:45:59 - train: epoch 0058, iter [01190, 01251], lr: 0.000821, loss: 3.3036
2022-10-08 08:46:20 - train: epoch 0058, iter [01200, 01251], lr: 0.000821, loss: 2.9386
2022-10-08 08:46:41 - train: epoch 0058, iter [01210, 01251], lr: 0.000821, loss: 2.7971
2022-10-08 08:47:02 - train: epoch 0058, iter [01220, 01251], lr: 0.000821, loss: 2.7258
2022-10-08 08:47:23 - train: epoch 0058, iter [01230, 01251], lr: 0.000820, loss: 2.8422
2022-10-08 08:47:44 - train: epoch 0058, iter [01240, 01251], lr: 0.000820, loss: 2.8805
2022-10-08 08:48:05 - train: epoch 0058, iter [01250, 01251], lr: 0.000820, loss: 2.6669
2022-10-08 08:48:09 - train: epoch 058, train_loss: 3.0234
2022-10-08 08:49:24 - eval: epoch: 058, acc1: 81.248%, acc5: 95.930%, test_loss: 0.8195, per_image_load_time: 0.786ms, per_image_inference_time: 1.440ms
2022-10-08 08:49:26 - until epoch: 058, best_acc1: 81.248%
2022-10-08 08:49:26 - epoch 059 lr: 0.000820
2022-10-08 08:49:52 - train: epoch 0059, iter [00010, 01251], lr: 0.000819, loss: 3.3638
2022-10-08 08:50:13 - train: epoch 0059, iter [00020, 01251], lr: 0.000819, loss: 2.6984
2022-10-08 08:50:35 - train: epoch 0059, iter [00030, 01251], lr: 0.000819, loss: 3.0377
2022-10-08 08:50:56 - train: epoch 0059, iter [00040, 01251], lr: 0.000819, loss: 2.2577
2022-10-08 08:51:17 - train: epoch 0059, iter [00050, 01251], lr: 0.000818, loss: 3.1794
2022-10-08 08:51:38 - train: epoch 0059, iter [00060, 01251], lr: 0.000818, loss: 2.7326
2022-10-08 08:51:59 - train: epoch 0059, iter [00070, 01251], lr: 0.000818, loss: 3.6872
2022-10-08 08:52:21 - train: epoch 0059, iter [00080, 01251], lr: 0.000818, loss: 2.8391
2022-10-08 08:52:42 - train: epoch 0059, iter [00090, 01251], lr: 0.000817, loss: 2.7011
2022-10-08 08:53:03 - train: epoch 0059, iter [00100, 01251], lr: 0.000817, loss: 2.6663
2022-10-08 08:53:24 - train: epoch 0059, iter [00110, 01251], lr: 0.000817, loss: 2.4154
2022-10-08 08:53:46 - train: epoch 0059, iter [00120, 01251], lr: 0.000817, loss: 2.5583
2022-10-08 08:54:07 - train: epoch 0059, iter [00130, 01251], lr: 0.000816, loss: 3.2208
2022-10-08 08:54:28 - train: epoch 0059, iter [00140, 01251], lr: 0.000816, loss: 3.4482
2022-10-08 08:54:49 - train: epoch 0059, iter [00150, 01251], lr: 0.000816, loss: 2.9779
2022-10-08 08:55:10 - train: epoch 0059, iter [00160, 01251], lr: 0.000816, loss: 3.1691
2022-10-08 08:55:32 - train: epoch 0059, iter [00170, 01251], lr: 0.000815, loss: 3.0433
2022-10-08 08:55:53 - train: epoch 0059, iter [00180, 01251], lr: 0.000815, loss: 3.0383
2022-10-08 08:56:14 - train: epoch 0059, iter [00190, 01251], lr: 0.000815, loss: 3.3548
2022-10-08 08:56:35 - train: epoch 0059, iter [00200, 01251], lr: 0.000815, loss: 2.2675
2022-10-08 08:56:56 - train: epoch 0059, iter [00210, 01251], lr: 0.000814, loss: 3.2934
2022-10-08 08:57:17 - train: epoch 0059, iter [00220, 01251], lr: 0.000814, loss: 2.6249
2022-10-08 08:57:39 - train: epoch 0059, iter [00230, 01251], lr: 0.000814, loss: 3.1798
2022-10-08 08:58:00 - train: epoch 0059, iter [00240, 01251], lr: 0.000813, loss: 3.1851
2022-10-08 08:58:21 - train: epoch 0059, iter [00250, 01251], lr: 0.000813, loss: 2.9799
2022-10-08 08:58:42 - train: epoch 0059, iter [00260, 01251], lr: 0.000813, loss: 3.4302
2022-10-08 08:59:03 - train: epoch 0059, iter [00270, 01251], lr: 0.000813, loss: 3.3802
2022-10-08 08:59:24 - train: epoch 0059, iter [00280, 01251], lr: 0.000812, loss: 2.9761
2022-10-08 08:59:45 - train: epoch 0059, iter [00290, 01251], lr: 0.000812, loss: 3.0206
2022-10-08 09:00:06 - train: epoch 0059, iter [00300, 01251], lr: 0.000812, loss: 3.0315
2022-10-08 09:00:28 - train: epoch 0059, iter [00310, 01251], lr: 0.000812, loss: 3.1992
2022-10-08 09:00:49 - train: epoch 0059, iter [00320, 01251], lr: 0.000811, loss: 3.3548
2022-10-08 09:01:10 - train: epoch 0059, iter [00330, 01251], lr: 0.000811, loss: 2.5776
2022-10-08 09:01:31 - train: epoch 0059, iter [00340, 01251], lr: 0.000811, loss: 3.1873
2022-10-08 09:01:52 - train: epoch 0059, iter [00350, 01251], lr: 0.000811, loss: 3.5315
2022-10-08 09:02:13 - train: epoch 0059, iter [00360, 01251], lr: 0.000810, loss: 3.3950
2022-10-08 09:02:34 - train: epoch 0059, iter [00370, 01251], lr: 0.000810, loss: 3.5029
2022-10-08 09:02:55 - train: epoch 0059, iter [00380, 01251], lr: 0.000810, loss: 1.9922
2022-10-08 09:03:17 - train: epoch 0059, iter [00390, 01251], lr: 0.000810, loss: 3.3474
2022-10-08 09:03:38 - train: epoch 0059, iter [00400, 01251], lr: 0.000809, loss: 3.3599
2022-10-08 09:03:59 - train: epoch 0059, iter [00410, 01251], lr: 0.000809, loss: 2.6700
2022-10-08 09:04:20 - train: epoch 0059, iter [00420, 01251], lr: 0.000809, loss: 2.7817
2022-10-08 09:04:41 - train: epoch 0059, iter [00430, 01251], lr: 0.000809, loss: 3.1503
2022-10-08 09:05:03 - train: epoch 0059, iter [00440, 01251], lr: 0.000808, loss: 3.3645
2022-10-08 09:05:24 - train: epoch 0059, iter [00450, 01251], lr: 0.000808, loss: 3.2793
2022-10-08 09:05:45 - train: epoch 0059, iter [00460, 01251], lr: 0.000808, loss: 2.7341
2022-10-08 09:06:06 - train: epoch 0059, iter [00470, 01251], lr: 0.000808, loss: 3.3787
2022-10-08 09:06:27 - train: epoch 0059, iter [00480, 01251], lr: 0.000807, loss: 3.0251
2022-10-08 09:06:48 - train: epoch 0059, iter [00490, 01251], lr: 0.000807, loss: 2.4558
2022-10-08 09:07:09 - train: epoch 0059, iter [00500, 01251], lr: 0.000807, loss: 2.5097
2022-10-08 09:07:30 - train: epoch 0059, iter [00510, 01251], lr: 0.000806, loss: 3.1446
2022-10-08 09:07:51 - train: epoch 0059, iter [00520, 01251], lr: 0.000806, loss: 3.4604
2022-10-08 09:08:12 - train: epoch 0059, iter [00530, 01251], lr: 0.000806, loss: 2.3710
2022-10-08 09:08:33 - train: epoch 0059, iter [00540, 01251], lr: 0.000806, loss: 3.5706
2022-10-08 09:08:54 - train: epoch 0059, iter [00550, 01251], lr: 0.000805, loss: 3.2512
2022-10-08 09:09:16 - train: epoch 0059, iter [00560, 01251], lr: 0.000805, loss: 3.1454
2022-10-08 09:09:37 - train: epoch 0059, iter [00570, 01251], lr: 0.000805, loss: 3.1782
2022-10-08 09:09:58 - train: epoch 0059, iter [00580, 01251], lr: 0.000805, loss: 2.9312
2022-10-08 09:10:19 - train: epoch 0059, iter [00590, 01251], lr: 0.000804, loss: 3.4341
2022-10-08 09:10:40 - train: epoch 0059, iter [00600, 01251], lr: 0.000804, loss: 2.9947
2022-10-08 09:11:01 - train: epoch 0059, iter [00610, 01251], lr: 0.000804, loss: 3.0216
2022-10-08 09:11:22 - train: epoch 0059, iter [00620, 01251], lr: 0.000804, loss: 3.3123
2022-10-08 09:11:43 - train: epoch 0059, iter [00630, 01251], lr: 0.000803, loss: 3.0311
2022-10-08 09:12:04 - train: epoch 0059, iter [00640, 01251], lr: 0.000803, loss: 3.2286
2022-10-08 09:12:25 - train: epoch 0059, iter [00650, 01251], lr: 0.000803, loss: 2.8683
2022-10-08 09:12:46 - train: epoch 0059, iter [00660, 01251], lr: 0.000803, loss: 3.5403
2022-10-08 09:13:08 - train: epoch 0059, iter [00670, 01251], lr: 0.000802, loss: 3.0275
2022-10-08 09:13:29 - train: epoch 0059, iter [00680, 01251], lr: 0.000802, loss: 3.3906
2022-10-08 09:13:50 - train: epoch 0059, iter [00690, 01251], lr: 0.000802, loss: 3.2154
2022-10-08 09:14:11 - train: epoch 0059, iter [00700, 01251], lr: 0.000802, loss: 3.0342
2022-10-08 09:14:32 - train: epoch 0059, iter [00710, 01251], lr: 0.000801, loss: 3.6269
2022-10-08 09:14:53 - train: epoch 0059, iter [00720, 01251], lr: 0.000801, loss: 3.5280
2022-10-08 09:15:14 - train: epoch 0059, iter [00730, 01251], lr: 0.000801, loss: 3.2273
2022-10-08 09:15:35 - train: epoch 0059, iter [00740, 01251], lr: 0.000801, loss: 3.1754
2022-10-08 09:15:56 - train: epoch 0059, iter [00750, 01251], lr: 0.000800, loss: 3.4152
2022-10-08 09:16:17 - train: epoch 0059, iter [00760, 01251], lr: 0.000800, loss: 3.3046
2022-10-08 09:16:38 - train: epoch 0059, iter [00770, 01251], lr: 0.000800, loss: 3.2965
2022-10-08 09:17:00 - train: epoch 0059, iter [00780, 01251], lr: 0.000799, loss: 2.5813
2022-10-08 09:17:21 - train: epoch 0059, iter [00790, 01251], lr: 0.000799, loss: 2.7373
2022-10-08 09:17:42 - train: epoch 0059, iter [00800, 01251], lr: 0.000799, loss: 2.7816
2022-10-08 09:18:03 - train: epoch 0059, iter [00810, 01251], lr: 0.000799, loss: 3.1852
2022-10-08 09:18:24 - train: epoch 0059, iter [00820, 01251], lr: 0.000798, loss: 2.3693
2022-10-08 09:18:45 - train: epoch 0059, iter [00830, 01251], lr: 0.000798, loss: 2.4140
2022-10-08 09:19:06 - train: epoch 0059, iter [00840, 01251], lr: 0.000798, loss: 3.0612
2022-10-08 09:19:27 - train: epoch 0059, iter [00850, 01251], lr: 0.000798, loss: 3.6009
2022-10-08 09:19:48 - train: epoch 0059, iter [00860, 01251], lr: 0.000797, loss: 2.6885
2022-10-08 09:20:09 - train: epoch 0059, iter [00870, 01251], lr: 0.000797, loss: 2.9593
2022-10-08 09:20:30 - train: epoch 0059, iter [00880, 01251], lr: 0.000797, loss: 3.4100
2022-10-08 09:20:51 - train: epoch 0059, iter [00890, 01251], lr: 0.000797, loss: 2.0577
2022-10-08 09:21:12 - train: epoch 0059, iter [00900, 01251], lr: 0.000796, loss: 2.5329
2022-10-08 09:21:33 - train: epoch 0059, iter [00910, 01251], lr: 0.000796, loss: 3.4476
2022-10-08 09:21:55 - train: epoch 0059, iter [00920, 01251], lr: 0.000796, loss: 3.1316
2022-10-08 09:22:16 - train: epoch 0059, iter [00930, 01251], lr: 0.000796, loss: 2.8530
2022-10-08 09:22:37 - train: epoch 0059, iter [00940, 01251], lr: 0.000795, loss: 2.2256
2022-10-08 09:22:58 - train: epoch 0059, iter [00950, 01251], lr: 0.000795, loss: 2.2061
2022-10-08 09:23:19 - train: epoch 0059, iter [00960, 01251], lr: 0.000795, loss: 2.7603
2022-10-08 09:23:40 - train: epoch 0059, iter [00970, 01251], lr: 0.000795, loss: 3.1803
2022-10-08 09:24:01 - train: epoch 0059, iter [00980, 01251], lr: 0.000794, loss: 3.2780
2022-10-08 09:24:22 - train: epoch 0059, iter [00990, 01251], lr: 0.000794, loss: 3.1099
2022-10-08 09:24:43 - train: epoch 0059, iter [01000, 01251], lr: 0.000794, loss: 2.5070
2022-10-08 09:25:04 - train: epoch 0059, iter [01010, 01251], lr: 0.000794, loss: 3.1568
2022-10-08 09:25:25 - train: epoch 0059, iter [01020, 01251], lr: 0.000793, loss: 3.0850
2022-10-08 09:25:46 - train: epoch 0059, iter [01030, 01251], lr: 0.000793, loss: 2.9755
2022-10-08 09:26:07 - train: epoch 0059, iter [01040, 01251], lr: 0.000793, loss: 2.1674
2022-10-08 09:26:28 - train: epoch 0059, iter [01050, 01251], lr: 0.000792, loss: 3.4517
2022-10-08 09:26:49 - train: epoch 0059, iter [01060, 01251], lr: 0.000792, loss: 2.6958
2022-10-08 09:27:10 - train: epoch 0059, iter [01070, 01251], lr: 0.000792, loss: 3.1976
2022-10-08 09:27:32 - train: epoch 0059, iter [01080, 01251], lr: 0.000792, loss: 3.2107
2022-10-08 09:27:53 - train: epoch 0059, iter [01090, 01251], lr: 0.000791, loss: 3.0962
2022-10-08 09:28:14 - train: epoch 0059, iter [01100, 01251], lr: 0.000791, loss: 3.1812
2022-10-08 09:28:35 - train: epoch 0059, iter [01110, 01251], lr: 0.000791, loss: 2.7709
2022-10-08 09:28:56 - train: epoch 0059, iter [01120, 01251], lr: 0.000791, loss: 3.1741
2022-10-08 09:29:17 - train: epoch 0059, iter [01130, 01251], lr: 0.000790, loss: 3.3732
2022-10-08 09:29:38 - train: epoch 0059, iter [01140, 01251], lr: 0.000790, loss: 3.6858
2022-10-08 09:29:59 - train: epoch 0059, iter [01150, 01251], lr: 0.000790, loss: 2.6268
2022-10-08 09:30:20 - train: epoch 0059, iter [01160, 01251], lr: 0.000790, loss: 2.9323
2022-10-08 09:30:41 - train: epoch 0059, iter [01170, 01251], lr: 0.000789, loss: 2.5405
2022-10-08 09:31:02 - train: epoch 0059, iter [01180, 01251], lr: 0.000789, loss: 3.3015
2022-10-08 09:31:23 - train: epoch 0059, iter [01190, 01251], lr: 0.000789, loss: 2.7940
2022-10-08 09:31:44 - train: epoch 0059, iter [01200, 01251], lr: 0.000789, loss: 3.0332
2022-10-08 09:32:05 - train: epoch 0059, iter [01210, 01251], lr: 0.000788, loss: 3.3343
2022-10-08 09:32:26 - train: epoch 0059, iter [01220, 01251], lr: 0.000788, loss: 2.8640
2022-10-08 09:32:47 - train: epoch 0059, iter [01230, 01251], lr: 0.000788, loss: 2.8147
2022-10-08 09:33:08 - train: epoch 0059, iter [01240, 01251], lr: 0.000788, loss: 2.8479
2022-10-08 09:33:29 - train: epoch 0059, iter [01250, 01251], lr: 0.000787, loss: 3.3670
2022-10-08 09:33:33 - train: epoch 059, train_loss: 3.0200
2022-10-08 09:34:48 - eval: epoch: 059, acc1: 81.408%, acc5: 95.966%, test_loss: 0.8222, per_image_load_time: 0.798ms, per_image_inference_time: 1.444ms
2022-10-08 09:34:50 - until epoch: 059, best_acc1: 81.408%
2022-10-08 09:34:50 - epoch 060 lr: 0.000787
2022-10-08 09:35:17 - train: epoch 0060, iter [00010, 01251], lr: 0.000787, loss: 3.2341
2022-10-08 09:35:38 - train: epoch 0060, iter [00020, 01251], lr: 0.000787, loss: 2.9236
2022-10-08 09:35:59 - train: epoch 0060, iter [00030, 01251], lr: 0.000787, loss: 3.0274
2022-10-08 09:36:20 - train: epoch 0060, iter [00040, 01251], lr: 0.000786, loss: 3.1865
2022-10-08 09:36:42 - train: epoch 0060, iter [00050, 01251], lr: 0.000786, loss: 2.5984
2022-10-08 09:37:03 - train: epoch 0060, iter [00060, 01251], lr: 0.000786, loss: 3.0909
2022-10-08 09:37:24 - train: epoch 0060, iter [00070, 01251], lr: 0.000786, loss: 2.7163
2022-10-08 09:37:45 - train: epoch 0060, iter [00080, 01251], lr: 0.000785, loss: 1.9565
2022-10-08 09:38:07 - train: epoch 0060, iter [00090, 01251], lr: 0.000785, loss: 2.9293
2022-10-08 09:38:28 - train: epoch 0060, iter [00100, 01251], lr: 0.000785, loss: 3.2592
2022-10-08 09:38:49 - train: epoch 0060, iter [00110, 01251], lr: 0.000784, loss: 3.2908
2022-10-08 09:39:10 - train: epoch 0060, iter [00120, 01251], lr: 0.000784, loss: 3.1670
2022-10-08 09:39:32 - train: epoch 0060, iter [00130, 01251], lr: 0.000784, loss: 3.0526
2022-10-08 09:39:53 - train: epoch 0060, iter [00140, 01251], lr: 0.000784, loss: 3.5139
2022-10-08 09:40:14 - train: epoch 0060, iter [00150, 01251], lr: 0.000783, loss: 2.9655
2022-10-08 09:40:35 - train: epoch 0060, iter [00160, 01251], lr: 0.000783, loss: 3.1985
2022-10-08 09:40:56 - train: epoch 0060, iter [00170, 01251], lr: 0.000783, loss: 3.0136
2022-10-08 09:41:18 - train: epoch 0060, iter [00180, 01251], lr: 0.000783, loss: 2.8128
2022-10-08 09:41:39 - train: epoch 0060, iter [00190, 01251], lr: 0.000782, loss: 3.2954
2022-10-08 09:42:00 - train: epoch 0060, iter [00200, 01251], lr: 0.000782, loss: 3.2703
2022-10-08 09:42:21 - train: epoch 0060, iter [00210, 01251], lr: 0.000782, loss: 3.1060
2022-10-08 09:42:42 - train: epoch 0060, iter [00220, 01251], lr: 0.000782, loss: 2.7757
2022-10-08 09:43:03 - train: epoch 0060, iter [00230, 01251], lr: 0.000781, loss: 2.7026
2022-10-08 09:43:24 - train: epoch 0060, iter [00240, 01251], lr: 0.000781, loss: 3.1768
2022-10-08 09:43:46 - train: epoch 0060, iter [00250, 01251], lr: 0.000781, loss: 3.3105
2022-10-08 09:44:07 - train: epoch 0060, iter [00260, 01251], lr: 0.000781, loss: 3.1269
2022-10-08 09:44:28 - train: epoch 0060, iter [00270, 01251], lr: 0.000780, loss: 3.3462
2022-10-08 09:44:49 - train: epoch 0060, iter [00280, 01251], lr: 0.000780, loss: 3.0298
2022-10-08 09:45:10 - train: epoch 0060, iter [00290, 01251], lr: 0.000780, loss: 2.9576
2022-10-08 09:45:31 - train: epoch 0060, iter [00300, 01251], lr: 0.000780, loss: 2.7573
2022-10-08 09:45:52 - train: epoch 0060, iter [00310, 01251], lr: 0.000779, loss: 3.3473
2022-10-08 09:46:13 - train: epoch 0060, iter [00320, 01251], lr: 0.000779, loss: 3.3650
2022-10-08 09:46:34 - train: epoch 0060, iter [00330, 01251], lr: 0.000779, loss: 3.0891
2022-10-08 09:46:56 - train: epoch 0060, iter [00340, 01251], lr: 0.000779, loss: 3.3268
2022-10-08 09:47:17 - train: epoch 0060, iter [00350, 01251], lr: 0.000778, loss: 2.8220
2022-10-08 09:47:38 - train: epoch 0060, iter [00360, 01251], lr: 0.000778, loss: 3.4271
2022-10-08 09:47:59 - train: epoch 0060, iter [00370, 01251], lr: 0.000778, loss: 3.1757
2022-10-08 09:48:20 - train: epoch 0060, iter [00380, 01251], lr: 0.000778, loss: 3.5757
2022-10-08 09:48:41 - train: epoch 0060, iter [00390, 01251], lr: 0.000777, loss: 2.9393
2022-10-08 09:49:02 - train: epoch 0060, iter [00400, 01251], lr: 0.000777, loss: 3.0257
2022-10-08 09:49:23 - train: epoch 0060, iter [00410, 01251], lr: 0.000777, loss: 3.4522
2022-10-08 09:49:44 - train: epoch 0060, iter [00420, 01251], lr: 0.000776, loss: 2.9181
2022-10-08 09:50:06 - train: epoch 0060, iter [00430, 01251], lr: 0.000776, loss: 2.8930
2022-10-08 09:50:27 - train: epoch 0060, iter [00440, 01251], lr: 0.000776, loss: 2.9472
2022-10-08 09:50:48 - train: epoch 0060, iter [00450, 01251], lr: 0.000776, loss: 3.6448
2022-10-08 09:51:09 - train: epoch 0060, iter [00460, 01251], lr: 0.000775, loss: 3.4713
2022-10-08 09:51:30 - train: epoch 0060, iter [00470, 01251], lr: 0.000775, loss: 3.1438
2022-10-08 09:51:51 - train: epoch 0060, iter [00480, 01251], lr: 0.000775, loss: 2.8787
2022-10-08 09:52:13 - train: epoch 0060, iter [00490, 01251], lr: 0.000775, loss: 3.4902
2022-10-08 09:52:34 - train: epoch 0060, iter [00500, 01251], lr: 0.000774, loss: 2.1470
2022-10-08 09:52:55 - train: epoch 0060, iter [00510, 01251], lr: 0.000774, loss: 2.6084
2022-10-08 09:53:16 - train: epoch 0060, iter [00520, 01251], lr: 0.000774, loss: 3.3559
2022-10-08 09:53:37 - train: epoch 0060, iter [00530, 01251], lr: 0.000774, loss: 2.3986
2022-10-08 09:53:58 - train: epoch 0060, iter [00540, 01251], lr: 0.000773, loss: 3.0040
2022-10-08 09:54:19 - train: epoch 0060, iter [00550, 01251], lr: 0.000773, loss: 3.4581
2022-10-08 09:54:40 - train: epoch 0060, iter [00560, 01251], lr: 0.000773, loss: 3.4492
2022-10-08 09:55:01 - train: epoch 0060, iter [00570, 01251], lr: 0.000773, loss: 2.6281
2022-10-08 09:55:23 - train: epoch 0060, iter [00580, 01251], lr: 0.000772, loss: 3.0642
2022-10-08 09:55:44 - train: epoch 0060, iter [00590, 01251], lr: 0.000772, loss: 2.5870
2022-10-08 09:56:05 - train: epoch 0060, iter [00600, 01251], lr: 0.000772, loss: 2.8864
2022-10-08 09:56:26 - train: epoch 0060, iter [00610, 01251], lr: 0.000772, loss: 2.9670
2022-10-08 09:56:47 - train: epoch 0060, iter [00620, 01251], lr: 0.000771, loss: 2.8721
2022-10-08 09:57:08 - train: epoch 0060, iter [00630, 01251], lr: 0.000771, loss: 2.7754
2022-10-08 09:57:29 - train: epoch 0060, iter [00640, 01251], lr: 0.000771, loss: 3.1513
2022-10-08 09:57:50 - train: epoch 0060, iter [00650, 01251], lr: 0.000771, loss: 3.3908
2022-10-08 09:58:11 - train: epoch 0060, iter [00660, 01251], lr: 0.000770, loss: 2.9397
2022-10-08 09:58:32 - train: epoch 0060, iter [00670, 01251], lr: 0.000770, loss: 2.5087
2022-10-08 09:58:53 - train: epoch 0060, iter [00680, 01251], lr: 0.000770, loss: 2.8040
2022-10-08 09:59:14 - train: epoch 0060, iter [00690, 01251], lr: 0.000770, loss: 3.0028
2022-10-08 09:59:35 - train: epoch 0060, iter [00700, 01251], lr: 0.000769, loss: 3.0582
2022-10-08 09:59:57 - train: epoch 0060, iter [00710, 01251], lr: 0.000769, loss: 2.7119
2022-10-08 10:00:18 - train: epoch 0060, iter [00720, 01251], lr: 0.000769, loss: 3.0285
2022-10-08 10:00:39 - train: epoch 0060, iter [00730, 01251], lr: 0.000769, loss: 3.2267
2022-10-08 10:01:00 - train: epoch 0060, iter [00740, 01251], lr: 0.000768, loss: 3.4448
2022-10-08 10:01:21 - train: epoch 0060, iter [00750, 01251], lr: 0.000768, loss: 2.8330
2022-10-08 10:01:42 - train: epoch 0060, iter [00760, 01251], lr: 0.000768, loss: 3.1833
2022-10-08 10:02:03 - train: epoch 0060, iter [00770, 01251], lr: 0.000767, loss: 3.0889
2022-10-08 10:02:24 - train: epoch 0060, iter [00780, 01251], lr: 0.000767, loss: 2.3508
2022-10-08 10:02:45 - train: epoch 0060, iter [00790, 01251], lr: 0.000767, loss: 3.0070
2022-10-08 10:03:06 - train: epoch 0060, iter [00800, 01251], lr: 0.000767, loss: 2.6118
2022-10-08 10:03:28 - train: epoch 0060, iter [00810, 01251], lr: 0.000766, loss: 2.4777
2022-10-08 10:03:49 - train: epoch 0060, iter [00820, 01251], lr: 0.000766, loss: 2.1286
2022-10-08 10:04:10 - train: epoch 0060, iter [00830, 01251], lr: 0.000766, loss: 2.6536
2022-10-08 10:04:31 - train: epoch 0060, iter [00840, 01251], lr: 0.000766, loss: 3.3550
2022-10-08 10:04:52 - train: epoch 0060, iter [00850, 01251], lr: 0.000765, loss: 3.3002
2022-10-08 10:05:14 - train: epoch 0060, iter [00860, 01251], lr: 0.000765, loss: 2.8192
2022-10-08 10:05:35 - train: epoch 0060, iter [00870, 01251], lr: 0.000765, loss: 3.2419
2022-10-08 10:05:56 - train: epoch 0060, iter [00880, 01251], lr: 0.000765, loss: 2.9859
2022-10-08 10:06:17 - train: epoch 0060, iter [00890, 01251], lr: 0.000764, loss: 3.2706
2022-10-08 10:06:38 - train: epoch 0060, iter [00900, 01251], lr: 0.000764, loss: 2.5116
2022-10-08 10:06:59 - train: epoch 0060, iter [00910, 01251], lr: 0.000764, loss: 3.0667
2022-10-08 10:07:20 - train: epoch 0060, iter [00920, 01251], lr: 0.000764, loss: 2.8884
2022-10-08 10:07:41 - train: epoch 0060, iter [00930, 01251], lr: 0.000763, loss: 2.7001
2022-10-08 10:08:02 - train: epoch 0060, iter [00940, 01251], lr: 0.000763, loss: 3.0079
2022-10-08 10:08:23 - train: epoch 0060, iter [00950, 01251], lr: 0.000763, loss: 2.6370
2022-10-08 10:08:44 - train: epoch 0060, iter [00960, 01251], lr: 0.000763, loss: 2.7379
2022-10-08 10:09:05 - train: epoch 0060, iter [00970, 01251], lr: 0.000762, loss: 3.2019
2022-10-08 10:09:26 - train: epoch 0060, iter [00980, 01251], lr: 0.000762, loss: 2.8685
2022-10-08 10:09:48 - train: epoch 0060, iter [00990, 01251], lr: 0.000762, loss: 3.7022
2022-10-08 10:10:08 - train: epoch 0060, iter [01000, 01251], lr: 0.000762, loss: 2.9565
2022-10-08 10:10:29 - train: epoch 0060, iter [01010, 01251], lr: 0.000761, loss: 3.1477
2022-10-08 10:10:50 - train: epoch 0060, iter [01020, 01251], lr: 0.000761, loss: 2.7133
2022-10-08 10:11:11 - train: epoch 0060, iter [01030, 01251], lr: 0.000761, loss: 2.4640
2022-10-08 10:11:33 - train: epoch 0060, iter [01040, 01251], lr: 0.000761, loss: 2.5625
2022-10-08 10:11:54 - train: epoch 0060, iter [01050, 01251], lr: 0.000760, loss: 2.8761
2022-10-08 10:12:15 - train: epoch 0060, iter [01060, 01251], lr: 0.000760, loss: 2.5568
2022-10-08 10:12:36 - train: epoch 0060, iter [01070, 01251], lr: 0.000760, loss: 2.8594
2022-10-08 10:12:57 - train: epoch 0060, iter [01080, 01251], lr: 0.000760, loss: 2.8469
2022-10-08 10:13:18 - train: epoch 0060, iter [01090, 01251], lr: 0.000759, loss: 3.1383
2022-10-08 10:13:39 - train: epoch 0060, iter [01100, 01251], lr: 0.000759, loss: 3.2245
2022-10-08 10:14:00 - train: epoch 0060, iter [01110, 01251], lr: 0.000759, loss: 3.1656
2022-10-08 10:14:21 - train: epoch 0060, iter [01120, 01251], lr: 0.000758, loss: 2.4124
2022-10-08 10:14:42 - train: epoch 0060, iter [01130, 01251], lr: 0.000758, loss: 2.5370
2022-10-08 10:15:04 - train: epoch 0060, iter [01140, 01251], lr: 0.000758, loss: 3.5051
2022-10-08 10:15:25 - train: epoch 0060, iter [01150, 01251], lr: 0.000758, loss: 3.2670
2022-10-08 10:15:46 - train: epoch 0060, iter [01160, 01251], lr: 0.000757, loss: 2.6451
2022-10-08 10:16:07 - train: epoch 0060, iter [01170, 01251], lr: 0.000757, loss: 3.3292
2022-10-08 10:16:28 - train: epoch 0060, iter [01180, 01251], lr: 0.000757, loss: 3.4300
2022-10-08 10:16:49 - train: epoch 0060, iter [01190, 01251], lr: 0.000757, loss: 3.3586
2022-10-08 10:17:10 - train: epoch 0060, iter [01200, 01251], lr: 0.000756, loss: 3.1604
2022-10-08 10:17:31 - train: epoch 0060, iter [01210, 01251], lr: 0.000756, loss: 3.2115
2022-10-08 10:17:52 - train: epoch 0060, iter [01220, 01251], lr: 0.000756, loss: 3.1221
2022-10-08 10:18:13 - train: epoch 0060, iter [01230, 01251], lr: 0.000756, loss: 2.9387
2022-10-08 10:18:34 - train: epoch 0060, iter [01240, 01251], lr: 0.000755, loss: 3.0380
2022-10-08 10:18:55 - train: epoch 0060, iter [01250, 01251], lr: 0.000755, loss: 2.7678
2022-10-08 10:18:59 - train: epoch 060, train_loss: 3.0092
2022-10-08 10:20:14 - eval: epoch: 060, acc1: 81.454%, acc5: 96.028%, test_loss: 0.8141, per_image_load_time: 1.017ms, per_image_inference_time: 1.430ms
2022-10-08 10:20:16 - until epoch: 060, best_acc1: 81.454%
2022-10-08 10:20:16 - epoch 061 lr: 0.000755
2022-10-08 10:20:42 - train: epoch 0061, iter [00010, 01251], lr: 0.000755, loss: 3.1089
2022-10-08 10:21:03 - train: epoch 0061, iter [00020, 01251], lr: 0.000755, loss: 2.7708
2022-10-08 10:21:25 - train: epoch 0061, iter [00030, 01251], lr: 0.000754, loss: 2.3299
2022-10-08 10:21:46 - train: epoch 0061, iter [00040, 01251], lr: 0.000754, loss: 2.8084
2022-10-08 10:22:07 - train: epoch 0061, iter [00050, 01251], lr: 0.000754, loss: 2.5835
2022-10-08 10:22:28 - train: epoch 0061, iter [00060, 01251], lr: 0.000754, loss: 2.1520
2022-10-08 10:22:50 - train: epoch 0061, iter [00070, 01251], lr: 0.000753, loss: 3.1681
2022-10-08 10:23:11 - train: epoch 0061, iter [00080, 01251], lr: 0.000753, loss: 3.0415
2022-10-08 10:23:32 - train: epoch 0061, iter [00090, 01251], lr: 0.000753, loss: 2.5466
2022-10-08 10:23:53 - train: epoch 0061, iter [00100, 01251], lr: 0.000753, loss: 2.8845
2022-10-08 10:24:14 - train: epoch 0061, iter [00110, 01251], lr: 0.000752, loss: 3.3066
2022-10-08 10:24:35 - train: epoch 0061, iter [00120, 01251], lr: 0.000752, loss: 3.0987
2022-10-08 10:24:56 - train: epoch 0061, iter [00130, 01251], lr: 0.000752, loss: 2.7247
2022-10-08 10:25:18 - train: epoch 0061, iter [00140, 01251], lr: 0.000752, loss: 3.2649
2022-10-08 10:25:39 - train: epoch 0061, iter [00150, 01251], lr: 0.000751, loss: 3.2957
2022-10-08 10:26:00 - train: epoch 0061, iter [00160, 01251], lr: 0.000751, loss: 2.8445
2022-10-08 10:26:21 - train: epoch 0061, iter [00170, 01251], lr: 0.000751, loss: 2.8341
2022-10-08 10:26:42 - train: epoch 0061, iter [00180, 01251], lr: 0.000751, loss: 2.6121
2022-10-08 10:27:03 - train: epoch 0061, iter [00190, 01251], lr: 0.000750, loss: 3.3051
2022-10-08 10:27:25 - train: epoch 0061, iter [00200, 01251], lr: 0.000750, loss: 3.0221
2022-10-08 10:27:46 - train: epoch 0061, iter [00210, 01251], lr: 0.000750, loss: 2.7426
2022-10-08 10:28:07 - train: epoch 0061, iter [00220, 01251], lr: 0.000750, loss: 2.7735
2022-10-08 10:28:28 - train: epoch 0061, iter [00230, 01251], lr: 0.000749, loss: 3.2170
2022-10-08 10:28:49 - train: epoch 0061, iter [00240, 01251], lr: 0.000749, loss: 3.3542
2022-10-08 10:29:10 - train: epoch 0061, iter [00250, 01251], lr: 0.000749, loss: 3.1304
2022-10-08 10:29:31 - train: epoch 0061, iter [00260, 01251], lr: 0.000748, loss: 3.2515
2022-10-08 10:29:52 - train: epoch 0061, iter [00270, 01251], lr: 0.000748, loss: 2.6924
2022-10-08 10:30:13 - train: epoch 0061, iter [00280, 01251], lr: 0.000748, loss: 2.7256
2022-10-08 10:30:35 - train: epoch 0061, iter [00290, 01251], lr: 0.000748, loss: 2.5421
2022-10-08 10:30:56 - train: epoch 0061, iter [00300, 01251], lr: 0.000747, loss: 3.1836
2022-10-08 10:31:17 - train: epoch 0061, iter [00310, 01251], lr: 0.000747, loss: 2.7743
2022-10-08 10:31:38 - train: epoch 0061, iter [00320, 01251], lr: 0.000747, loss: 3.2167
2022-10-08 10:31:59 - train: epoch 0061, iter [00330, 01251], lr: 0.000747, loss: 2.6831
2022-10-08 10:32:20 - train: epoch 0061, iter [00340, 01251], lr: 0.000746, loss: 2.5660
2022-10-08 10:32:41 - train: epoch 0061, iter [00350, 01251], lr: 0.000746, loss: 2.9245
2022-10-08 10:33:02 - train: epoch 0061, iter [00360, 01251], lr: 0.000746, loss: 3.3569
2022-10-08 10:33:23 - train: epoch 0061, iter [00370, 01251], lr: 0.000746, loss: 3.5612
2022-10-08 10:33:44 - train: epoch 0061, iter [00380, 01251], lr: 0.000745, loss: 2.5974
2022-10-08 10:34:05 - train: epoch 0061, iter [00390, 01251], lr: 0.000745, loss: 3.0916
2022-10-08 10:34:26 - train: epoch 0061, iter [00400, 01251], lr: 0.000745, loss: 3.1533
2022-10-08 10:34:47 - train: epoch 0061, iter [00410, 01251], lr: 0.000745, loss: 3.2636
2022-10-08 10:35:08 - train: epoch 0061, iter [00420, 01251], lr: 0.000744, loss: 3.3876
2022-10-08 10:35:30 - train: epoch 0061, iter [00430, 01251], lr: 0.000744, loss: 3.0809
2022-10-08 10:35:51 - train: epoch 0061, iter [00440, 01251], lr: 0.000744, loss: 3.3946
2022-10-08 10:36:12 - train: epoch 0061, iter [00450, 01251], lr: 0.000744, loss: 2.8517
2022-10-08 10:36:33 - train: epoch 0061, iter [00460, 01251], lr: 0.000743, loss: 2.6085
2022-10-08 10:36:54 - train: epoch 0061, iter [00470, 01251], lr: 0.000743, loss: 3.3206
2022-10-08 10:37:15 - train: epoch 0061, iter [00480, 01251], lr: 0.000743, loss: 2.9643
2022-10-08 10:37:36 - train: epoch 0061, iter [00490, 01251], lr: 0.000743, loss: 2.9656
2022-10-08 10:37:57 - train: epoch 0061, iter [00500, 01251], lr: 0.000742, loss: 2.8059
2022-10-08 10:38:18 - train: epoch 0061, iter [00510, 01251], lr: 0.000742, loss: 3.2663
2022-10-08 10:38:40 - train: epoch 0061, iter [00520, 01251], lr: 0.000742, loss: 2.7752
2022-10-08 10:39:01 - train: epoch 0061, iter [00530, 01251], lr: 0.000742, loss: 2.7205
2022-10-08 10:39:22 - train: epoch 0061, iter [00540, 01251], lr: 0.000741, loss: 3.1785
2022-10-08 10:39:43 - train: epoch 0061, iter [00550, 01251], lr: 0.000741, loss: 3.3177
2022-10-08 10:40:04 - train: epoch 0061, iter [00560, 01251], lr: 0.000741, loss: 3.2362
2022-10-08 10:40:25 - train: epoch 0061, iter [00570, 01251], lr: 0.000741, loss: 2.4397
2022-10-08 10:40:46 - train: epoch 0061, iter [00580, 01251], lr: 0.000740, loss: 3.3848
2022-10-08 10:41:07 - train: epoch 0061, iter [00590, 01251], lr: 0.000740, loss: 2.7150
2022-10-08 10:41:29 - train: epoch 0061, iter [00600, 01251], lr: 0.000740, loss: 2.6354
2022-10-08 10:41:50 - train: epoch 0061, iter [00610, 01251], lr: 0.000740, loss: 2.8244
2022-10-08 10:42:11 - train: epoch 0061, iter [00620, 01251], lr: 0.000739, loss: 3.3464
2022-10-08 10:42:32 - train: epoch 0061, iter [00630, 01251], lr: 0.000739, loss: 3.3163
2022-10-08 10:42:53 - train: epoch 0061, iter [00640, 01251], lr: 0.000739, loss: 3.3356
2022-10-08 10:43:14 - train: epoch 0061, iter [00650, 01251], lr: 0.000739, loss: 2.9355
2022-10-08 10:43:35 - train: epoch 0061, iter [00660, 01251], lr: 0.000738, loss: 2.2220
2022-10-08 10:43:56 - train: epoch 0061, iter [00670, 01251], lr: 0.000738, loss: 3.3914
2022-10-08 10:44:17 - train: epoch 0061, iter [00680, 01251], lr: 0.000738, loss: 3.2859
2022-10-08 10:44:38 - train: epoch 0061, iter [00690, 01251], lr: 0.000738, loss: 2.6216
2022-10-08 10:44:59 - train: epoch 0061, iter [00700, 01251], lr: 0.000737, loss: 2.5392
2022-10-08 10:45:20 - train: epoch 0061, iter [00710, 01251], lr: 0.000737, loss: 2.7802
2022-10-08 10:45:41 - train: epoch 0061, iter [00720, 01251], lr: 0.000737, loss: 2.9531
2022-10-08 10:46:02 - train: epoch 0061, iter [00730, 01251], lr: 0.000736, loss: 2.3818
2022-10-08 10:46:23 - train: epoch 0061, iter [00740, 01251], lr: 0.000736, loss: 3.1559
2022-10-08 10:46:44 - train: epoch 0061, iter [00750, 01251], lr: 0.000736, loss: 2.5525
2022-10-08 10:47:05 - train: epoch 0061, iter [00760, 01251], lr: 0.000736, loss: 3.0929
2022-10-08 10:47:27 - train: epoch 0061, iter [00770, 01251], lr: 0.000735, loss: 2.8192
2022-10-08 10:47:48 - train: epoch 0061, iter [00780, 01251], lr: 0.000735, loss: 2.5902
2022-10-08 10:48:09 - train: epoch 0061, iter [00790, 01251], lr: 0.000735, loss: 2.4917
2022-10-08 10:48:30 - train: epoch 0061, iter [00800, 01251], lr: 0.000735, loss: 2.5178
2022-10-08 10:48:51 - train: epoch 0061, iter [00810, 01251], lr: 0.000734, loss: 3.4676
2022-10-08 10:49:12 - train: epoch 0061, iter [00820, 01251], lr: 0.000734, loss: 2.6373
2022-10-08 10:49:33 - train: epoch 0061, iter [00830, 01251], lr: 0.000734, loss: 3.1868
2022-10-08 10:49:54 - train: epoch 0061, iter [00840, 01251], lr: 0.000734, loss: 2.8614
2022-10-08 10:50:15 - train: epoch 0061, iter [00850, 01251], lr: 0.000733, loss: 2.4420
2022-10-08 10:50:36 - train: epoch 0061, iter [00860, 01251], lr: 0.000733, loss: 2.4829
2022-10-08 10:50:57 - train: epoch 0061, iter [00870, 01251], lr: 0.000733, loss: 3.4612
2022-10-08 10:51:18 - train: epoch 0061, iter [00880, 01251], lr: 0.000733, loss: 3.1799
2022-10-08 10:51:39 - train: epoch 0061, iter [00890, 01251], lr: 0.000732, loss: 3.0343
2022-10-08 10:52:00 - train: epoch 0061, iter [00900, 01251], lr: 0.000732, loss: 3.7047
2022-10-08 10:52:21 - train: epoch 0061, iter [00910, 01251], lr: 0.000732, loss: 2.0492
2022-10-08 10:52:43 - train: epoch 0061, iter [00920, 01251], lr: 0.000732, loss: 3.0703
2022-10-08 10:53:04 - train: epoch 0061, iter [00930, 01251], lr: 0.000731, loss: 2.6777
2022-10-08 10:53:25 - train: epoch 0061, iter [00940, 01251], lr: 0.000731, loss: 2.4705
2022-10-08 10:53:46 - train: epoch 0061, iter [00950, 01251], lr: 0.000731, loss: 3.0726
2022-10-08 10:54:07 - train: epoch 0061, iter [00960, 01251], lr: 0.000731, loss: 3.2251
2022-10-08 10:54:28 - train: epoch 0061, iter [00970, 01251], lr: 0.000730, loss: 3.3287
2022-10-08 10:54:49 - train: epoch 0061, iter [00980, 01251], lr: 0.000730, loss: 2.5026
2022-10-08 10:55:10 - train: epoch 0061, iter [00990, 01251], lr: 0.000730, loss: 3.4498
2022-10-08 10:55:31 - train: epoch 0061, iter [01000, 01251], lr: 0.000730, loss: 3.2461
2022-10-08 10:55:52 - train: epoch 0061, iter [01010, 01251], lr: 0.000729, loss: 2.4954
2022-10-08 10:56:13 - train: epoch 0061, iter [01020, 01251], lr: 0.000729, loss: 2.9570
2022-10-08 10:56:34 - train: epoch 0061, iter [01030, 01251], lr: 0.000729, loss: 2.5800
2022-10-08 10:56:55 - train: epoch 0061, iter [01040, 01251], lr: 0.000729, loss: 3.2431
2022-10-08 10:57:16 - train: epoch 0061, iter [01050, 01251], lr: 0.000728, loss: 3.1447
2022-10-08 10:57:37 - train: epoch 0061, iter [01060, 01251], lr: 0.000728, loss: 2.5116
2022-10-08 10:57:58 - train: epoch 0061, iter [01070, 01251], lr: 0.000728, loss: 3.1601
2022-10-08 10:58:19 - train: epoch 0061, iter [01080, 01251], lr: 0.000728, loss: 2.6786
2022-10-08 10:58:40 - train: epoch 0061, iter [01090, 01251], lr: 0.000727, loss: 2.7088
2022-10-08 10:59:02 - train: epoch 0061, iter [01100, 01251], lr: 0.000727, loss: 2.4555
2022-10-08 10:59:23 - train: epoch 0061, iter [01110, 01251], lr: 0.000727, loss: 3.0561
2022-10-08 10:59:44 - train: epoch 0061, iter [01120, 01251], lr: 0.000727, loss: 2.7764
2022-10-08 11:00:05 - train: epoch 0061, iter [01130, 01251], lr: 0.000726, loss: 2.3649
2022-10-08 11:00:26 - train: epoch 0061, iter [01140, 01251], lr: 0.000726, loss: 2.7764
2022-10-08 11:00:47 - train: epoch 0061, iter [01150, 01251], lr: 0.000726, loss: 2.6100
2022-10-08 11:01:08 - train: epoch 0061, iter [01160, 01251], lr: 0.000726, loss: 3.3234
2022-10-08 11:01:29 - train: epoch 0061, iter [01170, 01251], lr: 0.000725, loss: 3.0673
2022-10-08 11:01:50 - train: epoch 0061, iter [01180, 01251], lr: 0.000725, loss: 3.3905
2022-10-08 11:02:11 - train: epoch 0061, iter [01190, 01251], lr: 0.000725, loss: 3.1426
2022-10-08 11:02:32 - train: epoch 0061, iter [01200, 01251], lr: 0.000725, loss: 2.8026
2022-10-08 11:02:53 - train: epoch 0061, iter [01210, 01251], lr: 0.000724, loss: 2.7701
2022-10-08 11:03:14 - train: epoch 0061, iter [01220, 01251], lr: 0.000724, loss: 3.4463
2022-10-08 11:03:35 - train: epoch 0061, iter [01230, 01251], lr: 0.000724, loss: 3.0687
2022-10-08 11:03:57 - train: epoch 0061, iter [01240, 01251], lr: 0.000724, loss: 3.0721
2022-10-08 11:04:17 - train: epoch 0061, iter [01250, 01251], lr: 0.000723, loss: 3.1050
2022-10-08 11:04:21 - train: epoch 061, train_loss: 3.0062
2022-10-08 11:05:37 - eval: epoch: 061, acc1: 81.472%, acc5: 95.974%, test_loss: 0.8066, per_image_load_time: 1.392ms, per_image_inference_time: 1.419ms
2022-10-08 11:05:38 - until epoch: 061, best_acc1: 81.472%
2022-10-08 11:05:38 - epoch 062 lr: 0.000723
2022-10-08 11:06:05 - train: epoch 0062, iter [00010, 01251], lr: 0.000723, loss: 2.8667
2022-10-08 11:06:26 - train: epoch 0062, iter [00020, 01251], lr: 0.000723, loss: 2.8270
2022-10-08 11:06:47 - train: epoch 0062, iter [00030, 01251], lr: 0.000722, loss: 2.4894
2022-10-08 11:07:08 - train: epoch 0062, iter [00040, 01251], lr: 0.000722, loss: 2.9744
2022-10-08 11:07:29 - train: epoch 0062, iter [00050, 01251], lr: 0.000722, loss: 3.3559
2022-10-08 11:07:50 - train: epoch 0062, iter [00060, 01251], lr: 0.000722, loss: 3.0166
2022-10-08 11:08:11 - train: epoch 0062, iter [00070, 01251], lr: 0.000721, loss: 2.4040
2022-10-08 11:08:32 - train: epoch 0062, iter [00080, 01251], lr: 0.000721, loss: 2.0189
2022-10-08 11:08:53 - train: epoch 0062, iter [00090, 01251], lr: 0.000721, loss: 2.9532
2022-10-08 11:09:14 - train: epoch 0062, iter [00100, 01251], lr: 0.000721, loss: 2.8972
2022-10-08 11:09:35 - train: epoch 0062, iter [00110, 01251], lr: 0.000720, loss: 3.3100
2022-10-08 11:09:57 - train: epoch 0062, iter [00120, 01251], lr: 0.000720, loss: 2.9881
2022-10-08 11:10:18 - train: epoch 0062, iter [00130, 01251], lr: 0.000720, loss: 2.7471
2022-10-08 11:10:39 - train: epoch 0062, iter [00140, 01251], lr: 0.000720, loss: 3.0570
2022-10-08 11:11:00 - train: epoch 0062, iter [00150, 01251], lr: 0.000719, loss: 2.9276
2022-10-08 11:11:21 - train: epoch 0062, iter [00160, 01251], lr: 0.000719, loss: 2.8105
2022-10-08 11:11:42 - train: epoch 0062, iter [00170, 01251], lr: 0.000719, loss: 2.8174
2022-10-08 11:12:03 - train: epoch 0062, iter [00180, 01251], lr: 0.000719, loss: 2.9381
2022-10-08 11:12:24 - train: epoch 0062, iter [00190, 01251], lr: 0.000718, loss: 2.7428
2022-10-08 11:12:45 - train: epoch 0062, iter [00200, 01251], lr: 0.000718, loss: 2.9515
2022-10-08 11:13:06 - train: epoch 0062, iter [00210, 01251], lr: 0.000718, loss: 3.0780
2022-10-08 11:13:27 - train: epoch 0062, iter [00220, 01251], lr: 0.000718, loss: 3.3244
2022-10-08 11:13:48 - train: epoch 0062, iter [00230, 01251], lr: 0.000717, loss: 2.3040
2022-10-08 11:14:09 - train: epoch 0062, iter [00240, 01251], lr: 0.000717, loss: 3.4739
2022-10-08 11:14:30 - train: epoch 0062, iter [00250, 01251], lr: 0.000717, loss: 3.0799
2022-10-08 11:14:51 - train: epoch 0062, iter [00260, 01251], lr: 0.000717, loss: 2.4071
2022-10-08 11:15:13 - train: epoch 0062, iter [00270, 01251], lr: 0.000716, loss: 3.1000
2022-10-08 11:15:34 - train: epoch 0062, iter [00280, 01251], lr: 0.000716, loss: 3.4063
2022-10-08 11:15:55 - train: epoch 0062, iter [00290, 01251], lr: 0.000716, loss: 2.9119
2022-10-08 11:16:16 - train: epoch 0062, iter [00300, 01251], lr: 0.000716, loss: 3.2623
2022-10-08 11:16:37 - train: epoch 0062, iter [00310, 01251], lr: 0.000715, loss: 3.5511
2022-10-08 11:16:58 - train: epoch 0062, iter [00320, 01251], lr: 0.000715, loss: 2.7414
2022-10-08 11:17:19 - train: epoch 0062, iter [00330, 01251], lr: 0.000715, loss: 3.0836
2022-10-08 11:17:40 - train: epoch 0062, iter [00340, 01251], lr: 0.000715, loss: 2.9222
2022-10-08 11:18:01 - train: epoch 0062, iter [00350, 01251], lr: 0.000714, loss: 2.9621
2022-10-08 11:18:22 - train: epoch 0062, iter [00360, 01251], lr: 0.000714, loss: 3.1697
2022-10-08 11:18:43 - train: epoch 0062, iter [00370, 01251], lr: 0.000714, loss: 2.7622
2022-10-08 11:19:04 - train: epoch 0062, iter [00380, 01251], lr: 0.000714, loss: 3.4343
2022-10-08 11:19:25 - train: epoch 0062, iter [00390, 01251], lr: 0.000713, loss: 2.6564
2022-10-08 11:19:46 - train: epoch 0062, iter [00400, 01251], lr: 0.000713, loss: 2.6622
2022-10-08 11:20:07 - train: epoch 0062, iter [00410, 01251], lr: 0.000713, loss: 2.8359
2022-10-08 11:20:28 - train: epoch 0062, iter [00420, 01251], lr: 0.000713, loss: 2.5755
2022-10-08 11:20:49 - train: epoch 0062, iter [00430, 01251], lr: 0.000712, loss: 2.4092
2022-10-08 11:21:10 - train: epoch 0062, iter [00440, 01251], lr: 0.000712, loss: 2.8373
2022-10-08 11:21:31 - train: epoch 0062, iter [00450, 01251], lr: 0.000712, loss: 2.7222
2022-10-08 11:21:52 - train: epoch 0062, iter [00460, 01251], lr: 0.000712, loss: 2.3945
2022-10-08 11:22:13 - train: epoch 0062, iter [00470, 01251], lr: 0.000711, loss: 2.8678
2022-10-08 11:22:34 - train: epoch 0062, iter [00480, 01251], lr: 0.000711, loss: 2.6966
2022-10-08 11:22:56 - train: epoch 0062, iter [00490, 01251], lr: 0.000711, loss: 3.2253
2022-10-08 11:23:17 - train: epoch 0062, iter [00500, 01251], lr: 0.000711, loss: 3.3278
2022-10-08 11:23:38 - train: epoch 0062, iter [00510, 01251], lr: 0.000710, loss: 2.6963
2022-10-08 11:23:59 - train: epoch 0062, iter [00520, 01251], lr: 0.000710, loss: 3.3112
2022-10-08 11:24:20 - train: epoch 0062, iter [00530, 01251], lr: 0.000710, loss: 3.2820
2022-10-08 11:24:41 - train: epoch 0062, iter [00540, 01251], lr: 0.000710, loss: 3.4802
2022-10-08 11:25:02 - train: epoch 0062, iter [00550, 01251], lr: 0.000709, loss: 2.9130
2022-10-08 11:25:23 - train: epoch 0062, iter [00560, 01251], lr: 0.000709, loss: 2.6802
2022-10-08 11:25:44 - train: epoch 0062, iter [00570, 01251], lr: 0.000709, loss: 2.7349
2022-10-08 11:26:05 - train: epoch 0062, iter [00580, 01251], lr: 0.000709, loss: 2.8359
2022-10-08 11:26:26 - train: epoch 0062, iter [00590, 01251], lr: 0.000708, loss: 3.1102
2022-10-08 11:26:47 - train: epoch 0062, iter [00600, 01251], lr: 0.000708, loss: 3.4270
2022-10-08 11:27:08 - train: epoch 0062, iter [00610, 01251], lr: 0.000708, loss: 3.2190
2022-10-08 11:27:29 - train: epoch 0062, iter [00620, 01251], lr: 0.000708, loss: 3.3805
2022-10-08 11:27:50 - train: epoch 0062, iter [00630, 01251], lr: 0.000707, loss: 3.1173
2022-10-08 11:28:11 - train: epoch 0062, iter [00640, 01251], lr: 0.000707, loss: 2.4562
2022-10-08 11:28:33 - train: epoch 0062, iter [00650, 01251], lr: 0.000707, loss: 2.9578
2022-10-08 11:28:54 - train: epoch 0062, iter [00660, 01251], lr: 0.000707, loss: 3.0350
2022-10-08 11:29:15 - train: epoch 0062, iter [00670, 01251], lr: 0.000706, loss: 3.1460
2022-10-08 11:29:36 - train: epoch 0062, iter [00680, 01251], lr: 0.000706, loss: 2.8640
2022-10-08 11:29:57 - train: epoch 0062, iter [00690, 01251], lr: 0.000706, loss: 3.0606
2022-10-08 11:30:18 - train: epoch 0062, iter [00700, 01251], lr: 0.000706, loss: 3.3045
2022-10-08 11:30:39 - train: epoch 0062, iter [00710, 01251], lr: 0.000705, loss: 3.1260
2022-10-08 11:31:00 - train: epoch 0062, iter [00720, 01251], lr: 0.000705, loss: 3.2594
2022-10-08 11:31:21 - train: epoch 0062, iter [00730, 01251], lr: 0.000705, loss: 2.7003
2022-10-08 11:31:42 - train: epoch 0062, iter [00740, 01251], lr: 0.000705, loss: 3.1207
2022-10-08 11:32:03 - train: epoch 0062, iter [00750, 01251], lr: 0.000704, loss: 2.7961
2022-10-08 11:32:24 - train: epoch 0062, iter [00760, 01251], lr: 0.000704, loss: 3.1121
2022-10-08 11:32:45 - train: epoch 0062, iter [00770, 01251], lr: 0.000704, loss: 3.0457
2022-10-08 11:33:06 - train: epoch 0062, iter [00780, 01251], lr: 0.000703, loss: 2.5651
2022-10-08 11:33:27 - train: epoch 0062, iter [00790, 01251], lr: 0.000703, loss: 2.8839
2022-10-08 11:33:48 - train: epoch 0062, iter [00800, 01251], lr: 0.000703, loss: 3.3098
2022-10-08 11:34:09 - train: epoch 0062, iter [00810, 01251], lr: 0.000703, loss: 2.8512
2022-10-08 11:34:30 - train: epoch 0062, iter [00820, 01251], lr: 0.000702, loss: 3.0264
2022-10-08 11:34:51 - train: epoch 0062, iter [00830, 01251], lr: 0.000702, loss: 2.8741
2022-10-08 11:35:12 - train: epoch 0062, iter [00840, 01251], lr: 0.000702, loss: 3.0434
2022-10-08 11:35:33 - train: epoch 0062, iter [00850, 01251], lr: 0.000702, loss: 3.2376
2022-10-08 11:35:54 - train: epoch 0062, iter [00860, 01251], lr: 0.000701, loss: 3.0467
2022-10-08 11:36:16 - train: epoch 0062, iter [00870, 01251], lr: 0.000701, loss: 3.1496
2022-10-08 11:36:37 - train: epoch 0062, iter [00880, 01251], lr: 0.000701, loss: 3.1710
2022-10-08 11:36:58 - train: epoch 0062, iter [00890, 01251], lr: 0.000701, loss: 2.8484
2022-10-08 11:37:19 - train: epoch 0062, iter [00900, 01251], lr: 0.000700, loss: 3.1338
2022-10-08 11:37:40 - train: epoch 0062, iter [00910, 01251], lr: 0.000700, loss: 3.4204
2022-10-08 11:38:01 - train: epoch 0062, iter [00920, 01251], lr: 0.000700, loss: 2.3614
2022-10-08 11:38:22 - train: epoch 0062, iter [00930, 01251], lr: 0.000700, loss: 2.6385
2022-10-08 11:38:43 - train: epoch 0062, iter [00940, 01251], lr: 0.000699, loss: 2.5121
2022-10-08 11:39:04 - train: epoch 0062, iter [00950, 01251], lr: 0.000699, loss: 2.9221
2022-10-08 11:39:25 - train: epoch 0062, iter [00960, 01251], lr: 0.000699, loss: 3.0433
2022-10-08 11:39:46 - train: epoch 0062, iter [00970, 01251], lr: 0.000699, loss: 2.4597
2022-10-08 11:40:07 - train: epoch 0062, iter [00980, 01251], lr: 0.000698, loss: 3.3496
2022-10-08 11:40:28 - train: epoch 0062, iter [00990, 01251], lr: 0.000698, loss: 2.8331
2022-10-08 11:40:49 - train: epoch 0062, iter [01000, 01251], lr: 0.000698, loss: 2.1389
2022-10-08 11:41:10 - train: epoch 0062, iter [01010, 01251], lr: 0.000698, loss: 3.1769
2022-10-08 11:41:31 - train: epoch 0062, iter [01020, 01251], lr: 0.000697, loss: 3.3477
2022-10-08 11:41:52 - train: epoch 0062, iter [01030, 01251], lr: 0.000697, loss: 2.7070
2022-10-08 11:42:13 - train: epoch 0062, iter [01040, 01251], lr: 0.000697, loss: 2.8532
2022-10-08 11:42:34 - train: epoch 0062, iter [01050, 01251], lr: 0.000697, loss: 2.9127
2022-10-08 11:42:55 - train: epoch 0062, iter [01060, 01251], lr: 0.000696, loss: 2.6582
2022-10-08 11:43:16 - train: epoch 0062, iter [01070, 01251], lr: 0.000696, loss: 2.7178
2022-10-08 11:43:38 - train: epoch 0062, iter [01080, 01251], lr: 0.000696, loss: 2.8060
2022-10-08 11:43:59 - train: epoch 0062, iter [01090, 01251], lr: 0.000696, loss: 2.6668
2022-10-08 11:44:20 - train: epoch 0062, iter [01100, 01251], lr: 0.000695, loss: 2.9534
2022-10-08 11:44:41 - train: epoch 0062, iter [01110, 01251], lr: 0.000695, loss: 2.6220
2022-10-08 11:45:02 - train: epoch 0062, iter [01120, 01251], lr: 0.000695, loss: 2.9192
2022-10-08 11:45:23 - train: epoch 0062, iter [01130, 01251], lr: 0.000695, loss: 3.2128
2022-10-08 11:45:44 - train: epoch 0062, iter [01140, 01251], lr: 0.000694, loss: 2.7043
2022-10-08 11:46:05 - train: epoch 0062, iter [01150, 01251], lr: 0.000694, loss: 3.2826
2022-10-08 11:46:26 - train: epoch 0062, iter [01160, 01251], lr: 0.000694, loss: 3.2969
2022-10-08 11:46:47 - train: epoch 0062, iter [01170, 01251], lr: 0.000694, loss: 3.0902
2022-10-08 11:47:08 - train: epoch 0062, iter [01180, 01251], lr: 0.000693, loss: 3.6712
2022-10-08 11:47:29 - train: epoch 0062, iter [01190, 01251], lr: 0.000693, loss: 2.6896
2022-10-08 11:47:50 - train: epoch 0062, iter [01200, 01251], lr: 0.000693, loss: 2.9124
2022-10-08 11:48:11 - train: epoch 0062, iter [01210, 01251], lr: 0.000693, loss: 3.1232
2022-10-08 11:48:32 - train: epoch 0062, iter [01220, 01251], lr: 0.000692, loss: 3.6495
2022-10-08 11:48:53 - train: epoch 0062, iter [01230, 01251], lr: 0.000692, loss: 3.1102
2022-10-08 11:49:14 - train: epoch 0062, iter [01240, 01251], lr: 0.000692, loss: 2.9411
2022-10-08 11:49:35 - train: epoch 0062, iter [01250, 01251], lr: 0.000692, loss: 3.2241
2022-10-08 11:49:38 - train: epoch 062, train_loss: 2.9789
2022-10-08 11:50:54 - eval: epoch: 062, acc1: 81.500%, acc5: 96.074%, test_loss: 0.8044, per_image_load_time: 1.345ms, per_image_inference_time: 1.431ms
2022-10-08 11:50:56 - until epoch: 062, best_acc1: 81.500%
2022-10-08 11:50:56 - epoch 063 lr: 0.000692
2022-10-08 11:51:23 - train: epoch 0063, iter [00010, 01251], lr: 0.000691, loss: 3.4656
2022-10-08 11:51:44 - train: epoch 0063, iter [00020, 01251], lr: 0.000691, loss: 2.4005
2022-10-08 11:52:05 - train: epoch 0063, iter [00030, 01251], lr: 0.000691, loss: 2.1528
2022-10-08 11:52:26 - train: epoch 0063, iter [00040, 01251], lr: 0.000691, loss: 2.9144
2022-10-08 11:52:48 - train: epoch 0063, iter [00050, 01251], lr: 0.000690, loss: 2.6306
2022-10-08 11:53:09 - train: epoch 0063, iter [00060, 01251], lr: 0.000690, loss: 2.7074
2022-10-08 11:53:30 - train: epoch 0063, iter [00070, 01251], lr: 0.000690, loss: 3.1388
2022-10-08 11:53:51 - train: epoch 0063, iter [00080, 01251], lr: 0.000690, loss: 3.1390
2022-10-08 11:54:12 - train: epoch 0063, iter [00090, 01251], lr: 0.000689, loss: 3.0986
2022-10-08 11:54:33 - train: epoch 0063, iter [00100, 01251], lr: 0.000689, loss: 3.0657
2022-10-08 11:54:55 - train: epoch 0063, iter [00110, 01251], lr: 0.000689, loss: 2.4298
2022-10-08 11:55:16 - train: epoch 0063, iter [00120, 01251], lr: 0.000689, loss: 3.0180
2022-10-08 11:55:37 - train: epoch 0063, iter [00130, 01251], lr: 0.000688, loss: 2.4181
2022-10-08 11:55:58 - train: epoch 0063, iter [00140, 01251], lr: 0.000688, loss: 3.0924
2022-10-08 11:56:20 - train: epoch 0063, iter [00150, 01251], lr: 0.000688, loss: 2.3503
2022-10-08 11:56:41 - train: epoch 0063, iter [00160, 01251], lr: 0.000688, loss: 2.8013
2022-10-08 11:57:02 - train: epoch 0063, iter [00170, 01251], lr: 0.000687, loss: 3.0606
2022-10-08 11:57:23 - train: epoch 0063, iter [00180, 01251], lr: 0.000687, loss: 3.2078
2022-10-08 11:57:44 - train: epoch 0063, iter [00190, 01251], lr: 0.000687, loss: 3.1172
2022-10-08 11:58:05 - train: epoch 0063, iter [00200, 01251], lr: 0.000687, loss: 2.7523
2022-10-08 11:58:26 - train: epoch 0063, iter [00210, 01251], lr: 0.000686, loss: 2.4393
2022-10-08 11:58:47 - train: epoch 0063, iter [00220, 01251], lr: 0.000686, loss: 3.3389
2022-10-08 11:59:09 - train: epoch 0063, iter [00230, 01251], lr: 0.000686, loss: 3.3816
2022-10-08 11:59:30 - train: epoch 0063, iter [00240, 01251], lr: 0.000686, loss: 3.3378
2022-10-08 11:59:51 - train: epoch 0063, iter [00250, 01251], lr: 0.000685, loss: 3.2037
2022-10-08 12:00:12 - train: epoch 0063, iter [00260, 01251], lr: 0.000685, loss: 3.3159
2022-10-08 12:00:33 - train: epoch 0063, iter [00270, 01251], lr: 0.000685, loss: 3.6019
2022-10-08 12:00:54 - train: epoch 0063, iter [00280, 01251], lr: 0.000685, loss: 2.7574
2022-10-08 12:01:15 - train: epoch 0063, iter [00290, 01251], lr: 0.000684, loss: 2.4693
2022-10-08 12:01:36 - train: epoch 0063, iter [00300, 01251], lr: 0.000684, loss: 3.0521
2022-10-08 12:01:58 - train: epoch 0063, iter [00310, 01251], lr: 0.000684, loss: 2.8427
2022-10-08 12:02:19 - train: epoch 0063, iter [00320, 01251], lr: 0.000684, loss: 3.1074
2022-10-08 12:02:40 - train: epoch 0063, iter [00330, 01251], lr: 0.000683, loss: 2.5043
2022-10-08 12:03:01 - train: epoch 0063, iter [00340, 01251], lr: 0.000683, loss: 2.6640
2022-10-08 12:03:23 - train: epoch 0063, iter [00350, 01251], lr: 0.000683, loss: 2.8025
2022-10-08 12:03:44 - train: epoch 0063, iter [00360, 01251], lr: 0.000683, loss: 3.5222
2022-10-08 12:04:05 - train: epoch 0063, iter [00370, 01251], lr: 0.000682, loss: 3.5576
2022-10-08 12:04:26 - train: epoch 0063, iter [00380, 01251], lr: 0.000682, loss: 2.7097
2022-10-08 12:04:47 - train: epoch 0063, iter [00390, 01251], lr: 0.000682, loss: 2.1064
2022-10-08 12:05:08 - train: epoch 0063, iter [00400, 01251], lr: 0.000682, loss: 3.1334
2022-10-08 12:05:29 - train: epoch 0063, iter [00410, 01251], lr: 0.000681, loss: 3.0039
2022-10-08 12:05:50 - train: epoch 0063, iter [00420, 01251], lr: 0.000681, loss: 3.2048
2022-10-08 12:06:12 - train: epoch 0063, iter [00430, 01251], lr: 0.000681, loss: 2.7701
2022-10-08 12:06:33 - train: epoch 0063, iter [00440, 01251], lr: 0.000681, loss: 3.0676
2022-10-08 12:06:54 - train: epoch 0063, iter [00450, 01251], lr: 0.000680, loss: 3.2453
2022-10-08 12:07:15 - train: epoch 0063, iter [00460, 01251], lr: 0.000680, loss: 3.3551
2022-10-08 12:07:36 - train: epoch 0063, iter [00470, 01251], lr: 0.000680, loss: 3.3011
2022-10-08 12:07:57 - train: epoch 0063, iter [00480, 01251], lr: 0.000680, loss: 2.6522
2022-10-08 12:08:18 - train: epoch 0063, iter [00490, 01251], lr: 0.000679, loss: 3.2069
2022-10-08 12:08:39 - train: epoch 0063, iter [00500, 01251], lr: 0.000679, loss: 2.9072
2022-10-08 12:09:00 - train: epoch 0063, iter [00510, 01251], lr: 0.000679, loss: 3.2222
2022-10-08 12:09:22 - train: epoch 0063, iter [00520, 01251], lr: 0.000679, loss: 3.0991
2022-10-08 12:09:43 - train: epoch 0063, iter [00530, 01251], lr: 0.000678, loss: 2.7596
2022-10-08 12:10:04 - train: epoch 0063, iter [00540, 01251], lr: 0.000678, loss: 3.3395
2022-10-08 12:10:25 - train: epoch 0063, iter [00550, 01251], lr: 0.000678, loss: 3.5181
2022-10-08 12:10:46 - train: epoch 0063, iter [00560, 01251], lr: 0.000678, loss: 3.2346
2022-10-08 12:11:07 - train: epoch 0063, iter [00570, 01251], lr: 0.000677, loss: 2.7659
2022-10-08 12:11:28 - train: epoch 0063, iter [00580, 01251], lr: 0.000677, loss: 3.4703
2022-10-08 12:11:49 - train: epoch 0063, iter [00590, 01251], lr: 0.000677, loss: 2.5409
2022-10-08 12:12:10 - train: epoch 0063, iter [00600, 01251], lr: 0.000677, loss: 2.5727
2022-10-08 12:12:31 - train: epoch 0063, iter [00610, 01251], lr: 0.000676, loss: 2.8440
2022-10-08 12:12:52 - train: epoch 0063, iter [00620, 01251], lr: 0.000676, loss: 3.0368
2022-10-08 12:13:13 - train: epoch 0063, iter [00630, 01251], lr: 0.000676, loss: 2.5534
2022-10-08 12:13:34 - train: epoch 0063, iter [00640, 01251], lr: 0.000676, loss: 3.0805
2022-10-08 12:13:56 - train: epoch 0063, iter [00650, 01251], lr: 0.000675, loss: 3.1443
2022-10-08 12:14:17 - train: epoch 0063, iter [00660, 01251], lr: 0.000675, loss: 3.4344
2022-10-08 12:14:38 - train: epoch 0063, iter [00670, 01251], lr: 0.000675, loss: 3.0637
2022-10-08 12:14:59 - train: epoch 0063, iter [00680, 01251], lr: 0.000675, loss: 2.8295
2022-10-08 12:15:20 - train: epoch 0063, iter [00690, 01251], lr: 0.000674, loss: 2.8996
2022-10-08 12:15:41 - train: epoch 0063, iter [00700, 01251], lr: 0.000674, loss: 2.9123
2022-10-08 12:16:02 - train: epoch 0063, iter [00710, 01251], lr: 0.000674, loss: 3.5075
2022-10-08 12:16:24 - train: epoch 0063, iter [00720, 01251], lr: 0.000674, loss: 3.1573
2022-10-08 12:16:45 - train: epoch 0063, iter [00730, 01251], lr: 0.000673, loss: 2.4942
2022-10-08 12:17:06 - train: epoch 0063, iter [00740, 01251], lr: 0.000673, loss: 3.1808
2022-10-08 12:17:27 - train: epoch 0063, iter [00750, 01251], lr: 0.000673, loss: 2.6688
2022-10-08 12:17:48 - train: epoch 0063, iter [00760, 01251], lr: 0.000673, loss: 2.9952
2022-10-08 12:18:09 - train: epoch 0063, iter [00770, 01251], lr: 0.000672, loss: 2.3998
2022-10-08 12:18:30 - train: epoch 0063, iter [00780, 01251], lr: 0.000672, loss: 2.7513
2022-10-08 12:18:51 - train: epoch 0063, iter [00790, 01251], lr: 0.000672, loss: 1.9149
2022-10-08 12:19:12 - train: epoch 0063, iter [00800, 01251], lr: 0.000672, loss: 3.4082
2022-10-08 12:19:33 - train: epoch 0063, iter [00810, 01251], lr: 0.000671, loss: 3.1974
2022-10-08 12:19:54 - train: epoch 0063, iter [00820, 01251], lr: 0.000671, loss: 2.9119
2022-10-08 12:20:15 - train: epoch 0063, iter [00830, 01251], lr: 0.000671, loss: 3.3255
2022-10-08 12:20:37 - train: epoch 0063, iter [00840, 01251], lr: 0.000671, loss: 2.0874
2022-10-08 12:20:58 - train: epoch 0063, iter [00850, 01251], lr: 0.000670, loss: 2.9413
2022-10-08 12:21:19 - train: epoch 0063, iter [00860, 01251], lr: 0.000670, loss: 2.6732
2022-10-08 12:21:40 - train: epoch 0063, iter [00870, 01251], lr: 0.000670, loss: 3.2332
2022-10-08 12:22:01 - train: epoch 0063, iter [00880, 01251], lr: 0.000670, loss: 2.8301
2022-10-08 12:22:22 - train: epoch 0063, iter [00890, 01251], lr: 0.000669, loss: 3.1946
2022-10-08 12:22:43 - train: epoch 0063, iter [00900, 01251], lr: 0.000669, loss: 3.4170
2022-10-08 12:23:05 - train: epoch 0063, iter [00910, 01251], lr: 0.000669, loss: 2.8819
2022-10-08 12:23:26 - train: epoch 0063, iter [00920, 01251], lr: 0.000669, loss: 3.1057
2022-10-08 12:23:47 - train: epoch 0063, iter [00930, 01251], lr: 0.000668, loss: 3.3637
2022-10-08 12:24:08 - train: epoch 0063, iter [00940, 01251], lr: 0.000668, loss: 2.2892
2022-10-08 12:24:29 - train: epoch 0063, iter [00950, 01251], lr: 0.000668, loss: 2.7287
2022-10-08 12:24:50 - train: epoch 0063, iter [00960, 01251], lr: 0.000668, loss: 3.3051
2022-10-08 12:25:11 - train: epoch 0063, iter [00970, 01251], lr: 0.000667, loss: 2.6465
2022-10-08 12:25:32 - train: epoch 0063, iter [00980, 01251], lr: 0.000667, loss: 2.0789
2022-10-08 12:25:53 - train: epoch 0063, iter [00990, 01251], lr: 0.000667, loss: 2.4755
2022-10-08 12:26:14 - train: epoch 0063, iter [01000, 01251], lr: 0.000667, loss: 2.8429
2022-10-08 12:26:36 - train: epoch 0063, iter [01010, 01251], lr: 0.000666, loss: 2.8608
2022-10-08 12:26:57 - train: epoch 0063, iter [01020, 01251], lr: 0.000666, loss: 3.0285
2022-10-08 12:27:18 - train: epoch 0063, iter [01030, 01251], lr: 0.000666, loss: 2.6560
2022-10-08 12:27:39 - train: epoch 0063, iter [01040, 01251], lr: 0.000666, loss: 2.9241
2022-10-08 12:28:00 - train: epoch 0063, iter [01050, 01251], lr: 0.000665, loss: 3.4946
2022-10-08 12:28:21 - train: epoch 0063, iter [01060, 01251], lr: 0.000665, loss: 3.4270
2022-10-08 12:28:42 - train: epoch 0063, iter [01070, 01251], lr: 0.000665, loss: 2.6813
2022-10-08 12:29:03 - train: epoch 0063, iter [01080, 01251], lr: 0.000665, loss: 3.2394
2022-10-08 12:29:24 - train: epoch 0063, iter [01090, 01251], lr: 0.000664, loss: 3.1087
2022-10-08 12:29:45 - train: epoch 0063, iter [01100, 01251], lr: 0.000664, loss: 3.2310
2022-10-08 12:30:06 - train: epoch 0063, iter [01110, 01251], lr: 0.000664, loss: 2.2826
2022-10-08 12:30:28 - train: epoch 0063, iter [01120, 01251], lr: 0.000664, loss: 2.1179
2022-10-08 12:30:49 - train: epoch 0063, iter [01130, 01251], lr: 0.000663, loss: 2.9541
2022-10-08 12:31:10 - train: epoch 0063, iter [01140, 01251], lr: 0.000663, loss: 2.6687
2022-10-08 12:31:31 - train: epoch 0063, iter [01150, 01251], lr: 0.000663, loss: 3.1130
2022-10-08 12:31:52 - train: epoch 0063, iter [01160, 01251], lr: 0.000663, loss: 3.1904
2022-10-08 12:32:13 - train: epoch 0063, iter [01170, 01251], lr: 0.000662, loss: 2.6176
2022-10-08 12:32:34 - train: epoch 0063, iter [01180, 01251], lr: 0.000662, loss: 2.9492
2022-10-08 12:32:55 - train: epoch 0063, iter [01190, 01251], lr: 0.000662, loss: 2.6853
2022-10-08 12:33:16 - train: epoch 0063, iter [01200, 01251], lr: 0.000662, loss: 2.6407
2022-10-08 12:33:37 - train: epoch 0063, iter [01210, 01251], lr: 0.000661, loss: 2.5804
2022-10-08 12:33:58 - train: epoch 0063, iter [01220, 01251], lr: 0.000661, loss: 3.3879
2022-10-08 12:34:19 - train: epoch 0063, iter [01230, 01251], lr: 0.000661, loss: 2.7734
2022-10-08 12:34:41 - train: epoch 0063, iter [01240, 01251], lr: 0.000661, loss: 3.1670
2022-10-08 12:35:01 - train: epoch 0063, iter [01250, 01251], lr: 0.000660, loss: 2.6640
2022-10-08 12:35:05 - train: epoch 063, train_loss: 2.9744
2022-10-08 12:36:21 - eval: epoch: 063, acc1: 81.866%, acc5: 96.064%, test_loss: 0.7881, per_image_load_time: 1.337ms, per_image_inference_time: 1.409ms
2022-10-08 12:36:23 - until epoch: 063, best_acc1: 81.866%
2022-10-08 12:36:23 - epoch 064 lr: 0.000660
2022-10-08 12:36:50 - train: epoch 0064, iter [00010, 01251], lr: 0.000660, loss: 2.7199
2022-10-08 12:37:11 - train: epoch 0064, iter [00020, 01251], lr: 0.000660, loss: 3.2862
2022-10-08 12:37:32 - train: epoch 0064, iter [00030, 01251], lr: 0.000660, loss: 2.9440
2022-10-08 12:37:53 - train: epoch 0064, iter [00040, 01251], lr: 0.000659, loss: 3.2527
2022-10-08 12:38:14 - train: epoch 0064, iter [00050, 01251], lr: 0.000659, loss: 3.3935
2022-10-08 12:38:35 - train: epoch 0064, iter [00060, 01251], lr: 0.000659, loss: 3.3269
2022-10-08 12:38:57 - train: epoch 0064, iter [00070, 01251], lr: 0.000659, loss: 2.8684
2022-10-08 12:39:18 - train: epoch 0064, iter [00080, 01251], lr: 0.000658, loss: 3.4210
2022-10-08 12:39:39 - train: epoch 0064, iter [00090, 01251], lr: 0.000658, loss: 2.7712
2022-10-08 12:40:00 - train: epoch 0064, iter [00100, 01251], lr: 0.000658, loss: 3.2223
2022-10-08 12:40:21 - train: epoch 0064, iter [00110, 01251], lr: 0.000658, loss: 3.4225
2022-10-08 12:40:42 - train: epoch 0064, iter [00120, 01251], lr: 0.000657, loss: 2.8768
2022-10-08 12:41:03 - train: epoch 0064, iter [00130, 01251], lr: 0.000657, loss: 2.0127
2022-10-08 12:41:25 - train: epoch 0064, iter [00140, 01251], lr: 0.000657, loss: 2.9341
2022-10-08 12:41:46 - train: epoch 0064, iter [00150, 01251], lr: 0.000657, loss: 2.6147
2022-10-08 12:42:07 - train: epoch 0064, iter [00160, 01251], lr: 0.000656, loss: 2.9065
2022-10-08 12:42:28 - train: epoch 0064, iter [00170, 01251], lr: 0.000656, loss: 3.2697
2022-10-08 12:42:49 - train: epoch 0064, iter [00180, 01251], lr: 0.000656, loss: 3.1765
2022-10-08 12:43:10 - train: epoch 0064, iter [00190, 01251], lr: 0.000656, loss: 2.6911
2022-10-08 12:43:31 - train: epoch 0064, iter [00200, 01251], lr: 0.000655, loss: 2.9123
2022-10-08 12:43:52 - train: epoch 0064, iter [00210, 01251], lr: 0.000655, loss: 3.1178
2022-10-08 12:44:13 - train: epoch 0064, iter [00220, 01251], lr: 0.000655, loss: 2.9266
2022-10-08 12:44:34 - train: epoch 0064, iter [00230, 01251], lr: 0.000655, loss: 3.4528
2022-10-08 12:44:55 - train: epoch 0064, iter [00240, 01251], lr: 0.000654, loss: 3.4378
2022-10-08 12:45:17 - train: epoch 0064, iter [00250, 01251], lr: 0.000654, loss: 2.3943
2022-10-08 12:45:38 - train: epoch 0064, iter [00260, 01251], lr: 0.000654, loss: 3.1906
2022-10-08 12:45:59 - train: epoch 0064, iter [00270, 01251], lr: 0.000654, loss: 3.3841
2022-10-08 12:46:20 - train: epoch 0064, iter [00280, 01251], lr: 0.000653, loss: 3.4243
2022-10-08 12:46:41 - train: epoch 0064, iter [00290, 01251], lr: 0.000653, loss: 2.7472
2022-10-08 12:47:02 - train: epoch 0064, iter [00300, 01251], lr: 0.000653, loss: 2.8568
2022-10-08 12:47:23 - train: epoch 0064, iter [00310, 01251], lr: 0.000653, loss: 3.4677
2022-10-08 12:47:44 - train: epoch 0064, iter [00320, 01251], lr: 0.000652, loss: 2.7954
2022-10-08 12:48:05 - train: epoch 0064, iter [00330, 01251], lr: 0.000652, loss: 2.9863
2022-10-08 12:48:26 - train: epoch 0064, iter [00340, 01251], lr: 0.000652, loss: 3.2324
2022-10-08 12:48:47 - train: epoch 0064, iter [00350, 01251], lr: 0.000652, loss: 3.1694
2022-10-08 12:49:09 - train: epoch 0064, iter [00360, 01251], lr: 0.000651, loss: 3.0507
2022-10-08 12:49:30 - train: epoch 0064, iter [00370, 01251], lr: 0.000651, loss: 2.3937
2022-10-08 12:49:51 - train: epoch 0064, iter [00380, 01251], lr: 0.000651, loss: 3.3303
2022-10-08 12:50:12 - train: epoch 0064, iter [00390, 01251], lr: 0.000651, loss: 3.2023
2022-10-08 12:50:33 - train: epoch 0064, iter [00400, 01251], lr: 0.000650, loss: 2.8663
2022-10-08 12:50:54 - train: epoch 0064, iter [00410, 01251], lr: 0.000650, loss: 2.8705
2022-10-08 12:51:16 - train: epoch 0064, iter [00420, 01251], lr: 0.000650, loss: 3.1260
2022-10-08 12:51:37 - train: epoch 0064, iter [00430, 01251], lr: 0.000650, loss: 2.9821
2022-10-08 12:51:58 - train: epoch 0064, iter [00440, 01251], lr: 0.000649, loss: 3.2743
2022-10-08 12:52:19 - train: epoch 0064, iter [00450, 01251], lr: 0.000649, loss: 3.4351
2022-10-08 12:52:40 - train: epoch 0064, iter [00460, 01251], lr: 0.000649, loss: 3.2120
2022-10-08 12:53:01 - train: epoch 0064, iter [00470, 01251], lr: 0.000649, loss: 3.0393
2022-10-08 12:53:22 - train: epoch 0064, iter [00480, 01251], lr: 0.000648, loss: 3.3014
2022-10-08 12:53:43 - train: epoch 0064, iter [00490, 01251], lr: 0.000648, loss: 3.0543
2022-10-08 12:54:05 - train: epoch 0064, iter [00500, 01251], lr: 0.000648, loss: 2.8504
2022-10-08 12:54:26 - train: epoch 0064, iter [00510, 01251], lr: 0.000648, loss: 3.4276
2022-10-08 12:54:47 - train: epoch 0064, iter [00520, 01251], lr: 0.000647, loss: 3.2996
2022-10-08 12:55:08 - train: epoch 0064, iter [00530, 01251], lr: 0.000647, loss: 2.7503
2022-10-08 12:55:29 - train: epoch 0064, iter [00540, 01251], lr: 0.000647, loss: 2.0267
2022-10-08 12:55:50 - train: epoch 0064, iter [00550, 01251], lr: 0.000647, loss: 3.1446
2022-10-08 12:56:11 - train: epoch 0064, iter [00560, 01251], lr: 0.000647, loss: 3.4793
2022-10-08 12:56:32 - train: epoch 0064, iter [00570, 01251], lr: 0.000646, loss: 3.1264
2022-10-08 12:56:53 - train: epoch 0064, iter [00580, 01251], lr: 0.000646, loss: 3.2321
2022-10-08 12:57:14 - train: epoch 0064, iter [00590, 01251], lr: 0.000646, loss: 3.4291
2022-10-08 12:57:36 - train: epoch 0064, iter [00600, 01251], lr: 0.000646, loss: 2.9135
2022-10-08 12:57:57 - train: epoch 0064, iter [00610, 01251], lr: 0.000645, loss: 3.3513
2022-10-08 12:58:18 - train: epoch 0064, iter [00620, 01251], lr: 0.000645, loss: 3.1530
2022-10-08 12:58:39 - train: epoch 0064, iter [00630, 01251], lr: 0.000645, loss: 3.1219
2022-10-08 12:59:00 - train: epoch 0064, iter [00640, 01251], lr: 0.000645, loss: 2.4920
2022-10-08 12:59:21 - train: epoch 0064, iter [00650, 01251], lr: 0.000644, loss: 2.5890
2022-10-08 12:59:42 - train: epoch 0064, iter [00660, 01251], lr: 0.000644, loss: 3.1965
2022-10-08 13:00:03 - train: epoch 0064, iter [00670, 01251], lr: 0.000644, loss: 3.5014
2022-10-08 13:00:24 - train: epoch 0064, iter [00680, 01251], lr: 0.000644, loss: 2.0736
2022-10-08 13:00:45 - train: epoch 0064, iter [00690, 01251], lr: 0.000643, loss: 3.3135
2022-10-08 13:01:06 - train: epoch 0064, iter [00700, 01251], lr: 0.000643, loss: 3.2347
2022-10-08 13:01:27 - train: epoch 0064, iter [00710, 01251], lr: 0.000643, loss: 3.1302
2022-10-08 13:01:48 - train: epoch 0064, iter [00720, 01251], lr: 0.000643, loss: 3.2436
2022-10-08 13:02:09 - train: epoch 0064, iter [00730, 01251], lr: 0.000642, loss: 3.3560
2022-10-08 13:02:31 - train: epoch 0064, iter [00740, 01251], lr: 0.000642, loss: 3.5349
2022-10-08 13:02:52 - train: epoch 0064, iter [00750, 01251], lr: 0.000642, loss: 3.3369
2022-10-08 13:03:13 - train: epoch 0064, iter [00760, 01251], lr: 0.000642, loss: 1.9749
2022-10-08 13:03:34 - train: epoch 0064, iter [00770, 01251], lr: 0.000641, loss: 3.0869
2022-10-08 13:03:55 - train: epoch 0064, iter [00780, 01251], lr: 0.000641, loss: 2.7231
2022-10-08 13:04:16 - train: epoch 0064, iter [00790, 01251], lr: 0.000641, loss: 3.1420
2022-10-08 13:04:37 - train: epoch 0064, iter [00800, 01251], lr: 0.000641, loss: 3.3645
2022-10-08 13:04:58 - train: epoch 0064, iter [00810, 01251], lr: 0.000640, loss: 2.4829
2022-10-08 13:05:19 - train: epoch 0064, iter [00820, 01251], lr: 0.000640, loss: 3.2832
2022-10-08 13:05:40 - train: epoch 0064, iter [00830, 01251], lr: 0.000640, loss: 2.8548
2022-10-08 13:06:01 - train: epoch 0064, iter [00840, 01251], lr: 0.000640, loss: 3.2776
2022-10-08 13:06:23 - train: epoch 0064, iter [00850, 01251], lr: 0.000639, loss: 3.1262
2022-10-08 13:06:44 - train: epoch 0064, iter [00860, 01251], lr: 0.000639, loss: 2.7907
2022-10-08 13:07:05 - train: epoch 0064, iter [00870, 01251], lr: 0.000639, loss: 3.2640
2022-10-08 13:07:26 - train: epoch 0064, iter [00880, 01251], lr: 0.000639, loss: 2.7066
2022-10-08 13:07:47 - train: epoch 0064, iter [00890, 01251], lr: 0.000638, loss: 3.0412
2022-10-08 13:08:08 - train: epoch 0064, iter [00900, 01251], lr: 0.000638, loss: 2.0005
2022-10-08 13:08:29 - train: epoch 0064, iter [00910, 01251], lr: 0.000638, loss: 2.9171
2022-10-08 13:08:50 - train: epoch 0064, iter [00920, 01251], lr: 0.000638, loss: 3.0142
2022-10-08 13:09:11 - train: epoch 0064, iter [00930, 01251], lr: 0.000637, loss: 3.3005
2022-10-08 13:09:32 - train: epoch 0064, iter [00940, 01251], lr: 0.000637, loss: 2.6425
2022-10-08 13:09:53 - train: epoch 0064, iter [00950, 01251], lr: 0.000637, loss: 3.3381
2022-10-08 13:10:14 - train: epoch 0064, iter [00960, 01251], lr: 0.000637, loss: 2.8101
2022-10-08 13:10:35 - train: epoch 0064, iter [00970, 01251], lr: 0.000636, loss: 2.7732
2022-10-08 13:10:56 - train: epoch 0064, iter [00980, 01251], lr: 0.000636, loss: 2.1437
2022-10-08 13:11:17 - train: epoch 0064, iter [00990, 01251], lr: 0.000636, loss: 3.0393
2022-10-08 13:11:38 - train: epoch 0064, iter [01000, 01251], lr: 0.000636, loss: 3.1325
2022-10-08 13:11:59 - train: epoch 0064, iter [01010, 01251], lr: 0.000635, loss: 2.9816
2022-10-08 13:12:20 - train: epoch 0064, iter [01020, 01251], lr: 0.000635, loss: 2.9160
2022-10-08 13:12:41 - train: epoch 0064, iter [01030, 01251], lr: 0.000635, loss: 3.3888
2022-10-08 13:13:03 - train: epoch 0064, iter [01040, 01251], lr: 0.000635, loss: 3.2589
2022-10-08 13:13:24 - train: epoch 0064, iter [01050, 01251], lr: 0.000634, loss: 2.2496
2022-10-08 13:13:45 - train: epoch 0064, iter [01060, 01251], lr: 0.000634, loss: 3.0593
2022-10-08 13:14:06 - train: epoch 0064, iter [01070, 01251], lr: 0.000634, loss: 2.8590
2022-10-08 13:14:27 - train: epoch 0064, iter [01080, 01251], lr: 0.000634, loss: 2.9606
2022-10-08 13:14:48 - train: epoch 0064, iter [01090, 01251], lr: 0.000633, loss: 2.7473
2022-10-08 13:15:09 - train: epoch 0064, iter [01100, 01251], lr: 0.000633, loss: 2.5520
2022-10-08 13:15:30 - train: epoch 0064, iter [01110, 01251], lr: 0.000633, loss: 2.3497
2022-10-08 13:15:51 - train: epoch 0064, iter [01120, 01251], lr: 0.000633, loss: 2.7327
2022-10-08 13:16:12 - train: epoch 0064, iter [01130, 01251], lr: 0.000632, loss: 2.4961
2022-10-08 13:16:33 - train: epoch 0064, iter [01140, 01251], lr: 0.000632, loss: 3.0852
2022-10-08 13:16:54 - train: epoch 0064, iter [01150, 01251], lr: 0.000632, loss: 3.3057
2022-10-08 13:17:15 - train: epoch 0064, iter [01160, 01251], lr: 0.000632, loss: 2.4099
2022-10-08 13:17:36 - train: epoch 0064, iter [01170, 01251], lr: 0.000631, loss: 2.5135
2022-10-08 13:17:58 - train: epoch 0064, iter [01180, 01251], lr: 0.000631, loss: 2.4819
2022-10-08 13:18:19 - train: epoch 0064, iter [01190, 01251], lr: 0.000631, loss: 3.2160
2022-10-08 13:18:40 - train: epoch 0064, iter [01200, 01251], lr: 0.000631, loss: 3.4857
2022-10-08 13:19:01 - train: epoch 0064, iter [01210, 01251], lr: 0.000630, loss: 2.5373
2022-10-08 13:19:22 - train: epoch 0064, iter [01220, 01251], lr: 0.000630, loss: 2.6290
2022-10-08 13:19:43 - train: epoch 0064, iter [01230, 01251], lr: 0.000630, loss: 3.1076
2022-10-08 13:20:04 - train: epoch 0064, iter [01240, 01251], lr: 0.000630, loss: 2.7271
2022-10-08 13:20:25 - train: epoch 0064, iter [01250, 01251], lr: 0.000630, loss: 2.8210
2022-10-08 13:20:28 - train: epoch 064, train_loss: 2.9713
2022-10-08 13:21:45 - eval: epoch: 064, acc1: 81.934%, acc5: 96.076%, test_loss: 0.7923, per_image_load_time: 1.392ms, per_image_inference_time: 1.445ms
2022-10-08 13:21:46 - until epoch: 064, best_acc1: 81.934%
2022-10-08 13:21:46 - epoch 065 lr: 0.000629
2022-10-08 13:22:13 - train: epoch 0065, iter [00010, 01251], lr: 0.000629, loss: 2.9677
2022-10-08 13:22:35 - train: epoch 0065, iter [00020, 01251], lr: 0.000629, loss: 2.4471
2022-10-08 13:22:56 - train: epoch 0065, iter [00030, 01251], lr: 0.000629, loss: 3.0665
2022-10-08 13:23:17 - train: epoch 0065, iter [00040, 01251], lr: 0.000629, loss: 2.8546
2022-10-08 13:23:38 - train: epoch 0065, iter [00050, 01251], lr: 0.000628, loss: 3.1826
2022-10-08 13:23:59 - train: epoch 0065, iter [00060, 01251], lr: 0.000628, loss: 2.6516
2022-10-08 13:24:20 - train: epoch 0065, iter [00070, 01251], lr: 0.000628, loss: 3.1471
2022-10-08 13:24:42 - train: epoch 0065, iter [00080, 01251], lr: 0.000628, loss: 3.3188
2022-10-08 13:25:03 - train: epoch 0065, iter [00090, 01251], lr: 0.000627, loss: 2.8171
2022-10-08 13:25:24 - train: epoch 0065, iter [00100, 01251], lr: 0.000627, loss: 2.4309
2022-10-08 13:25:45 - train: epoch 0065, iter [00110, 01251], lr: 0.000627, loss: 2.7941
2022-10-08 13:26:06 - train: epoch 0065, iter [00120, 01251], lr: 0.000627, loss: 3.1924
2022-10-08 13:26:28 - train: epoch 0065, iter [00130, 01251], lr: 0.000626, loss: 2.5359
2022-10-08 13:26:49 - train: epoch 0065, iter [00140, 01251], lr: 0.000626, loss: 3.2032
2022-10-08 13:27:10 - train: epoch 0065, iter [00150, 01251], lr: 0.000626, loss: 3.3671
2022-10-08 13:27:31 - train: epoch 0065, iter [00160, 01251], lr: 0.000626, loss: 2.6101
2022-10-08 13:27:52 - train: epoch 0065, iter [00170, 01251], lr: 0.000625, loss: 2.7446
2022-10-08 13:28:13 - train: epoch 0065, iter [00180, 01251], lr: 0.000625, loss: 3.3185
2022-10-08 13:28:34 - train: epoch 0065, iter [00190, 01251], lr: 0.000625, loss: 2.8530
2022-10-08 13:28:56 - train: epoch 0065, iter [00200, 01251], lr: 0.000625, loss: 3.0800
2022-10-08 13:29:17 - train: epoch 0065, iter [00210, 01251], lr: 0.000624, loss: 2.9571
2022-10-08 13:29:38 - train: epoch 0065, iter [00220, 01251], lr: 0.000624, loss: 2.5631
2022-10-08 13:29:59 - train: epoch 0065, iter [00230, 01251], lr: 0.000624, loss: 2.7482
2022-10-08 13:30:20 - train: epoch 0065, iter [00240, 01251], lr: 0.000624, loss: 3.1968
2022-10-08 13:30:41 - train: epoch 0065, iter [00250, 01251], lr: 0.000623, loss: 2.9460
2022-10-08 13:31:02 - train: epoch 0065, iter [00260, 01251], lr: 0.000623, loss: 2.6525
2022-10-08 13:31:23 - train: epoch 0065, iter [00270, 01251], lr: 0.000623, loss: 3.2002
2022-10-08 13:31:44 - train: epoch 0065, iter [00280, 01251], lr: 0.000623, loss: 2.9067
2022-10-08 13:32:05 - train: epoch 0065, iter [00290, 01251], lr: 0.000622, loss: 3.0215
2022-10-08 13:32:27 - train: epoch 0065, iter [00300, 01251], lr: 0.000622, loss: 2.8103
2022-10-08 13:32:48 - train: epoch 0065, iter [00310, 01251], lr: 0.000622, loss: 2.1651
2022-10-08 13:33:09 - train: epoch 0065, iter [00320, 01251], lr: 0.000622, loss: 3.2853
2022-10-08 13:33:30 - train: epoch 0065, iter [00330, 01251], lr: 0.000621, loss: 2.4246
2022-10-08 13:33:51 - train: epoch 0065, iter [00340, 01251], lr: 0.000621, loss: 3.0500
2022-10-08 13:34:12 - train: epoch 0065, iter [00350, 01251], lr: 0.000621, loss: 2.3715
2022-10-08 13:34:33 - train: epoch 0065, iter [00360, 01251], lr: 0.000621, loss: 3.4682
2022-10-08 13:34:54 - train: epoch 0065, iter [00370, 01251], lr: 0.000620, loss: 3.2760
2022-10-08 13:35:15 - train: epoch 0065, iter [00380, 01251], lr: 0.000620, loss: 3.1646
2022-10-08 13:35:36 - train: epoch 0065, iter [00390, 01251], lr: 0.000620, loss: 2.6047
2022-10-08 13:35:57 - train: epoch 0065, iter [00400, 01251], lr: 0.000620, loss: 3.4480
2022-10-08 13:36:18 - train: epoch 0065, iter [00410, 01251], lr: 0.000619, loss: 3.0659
2022-10-08 13:36:39 - train: epoch 0065, iter [00420, 01251], lr: 0.000619, loss: 2.9122
2022-10-08 13:37:01 - train: epoch 0065, iter [00430, 01251], lr: 0.000619, loss: 3.1982
2022-10-08 13:37:22 - train: epoch 0065, iter [00440, 01251], lr: 0.000619, loss: 2.3394
2022-10-08 13:37:43 - train: epoch 0065, iter [00450, 01251], lr: 0.000618, loss: 3.2663
2022-10-08 13:38:04 - train: epoch 0065, iter [00460, 01251], lr: 0.000618, loss: 2.7580
2022-10-08 13:38:25 - train: epoch 0065, iter [00470, 01251], lr: 0.000618, loss: 2.7615
2022-10-08 13:38:46 - train: epoch 0065, iter [00480, 01251], lr: 0.000618, loss: 2.8721
2022-10-08 13:39:07 - train: epoch 0065, iter [00490, 01251], lr: 0.000617, loss: 3.2714
2022-10-08 13:39:28 - train: epoch 0065, iter [00500, 01251], lr: 0.000617, loss: 3.1588
2022-10-08 13:39:49 - train: epoch 0065, iter [00510, 01251], lr: 0.000617, loss: 3.5702
2022-10-08 13:40:10 - train: epoch 0065, iter [00520, 01251], lr: 0.000617, loss: 3.4160
2022-10-08 13:40:31 - train: epoch 0065, iter [00530, 01251], lr: 0.000617, loss: 2.1427
2022-10-08 13:40:52 - train: epoch 0065, iter [00540, 01251], lr: 0.000616, loss: 2.8040
2022-10-08 13:41:14 - train: epoch 0065, iter [00550, 01251], lr: 0.000616, loss: 2.7548
2022-10-08 13:41:35 - train: epoch 0065, iter [00560, 01251], lr: 0.000616, loss: 3.1926
2022-10-08 13:41:56 - train: epoch 0065, iter [00570, 01251], lr: 0.000616, loss: 2.5062
2022-10-08 13:42:17 - train: epoch 0065, iter [00580, 01251], lr: 0.000615, loss: 2.6961
2022-10-08 13:42:38 - train: epoch 0065, iter [00590, 01251], lr: 0.000615, loss: 2.9865
2022-10-08 13:42:59 - train: epoch 0065, iter [00600, 01251], lr: 0.000615, loss: 3.2876
2022-10-08 13:43:20 - train: epoch 0065, iter [00610, 01251], lr: 0.000615, loss: 3.5401
2022-10-08 13:43:41 - train: epoch 0065, iter [00620, 01251], lr: 0.000614, loss: 3.2843
2022-10-08 13:44:02 - train: epoch 0065, iter [00630, 01251], lr: 0.000614, loss: 2.5471
2022-10-08 13:44:23 - train: epoch 0065, iter [00640, 01251], lr: 0.000614, loss: 3.1490
2022-10-08 13:44:44 - train: epoch 0065, iter [00650, 01251], lr: 0.000614, loss: 3.1228
2022-10-08 13:45:05 - train: epoch 0065, iter [00660, 01251], lr: 0.000613, loss: 3.2617
2022-10-08 13:45:26 - train: epoch 0065, iter [00670, 01251], lr: 0.000613, loss: 3.0192
2022-10-08 13:45:48 - train: epoch 0065, iter [00680, 01251], lr: 0.000613, loss: 3.0202
2022-10-08 13:46:09 - train: epoch 0065, iter [00690, 01251], lr: 0.000613, loss: 2.6104
2022-10-08 13:46:30 - train: epoch 0065, iter [00700, 01251], lr: 0.000612, loss: 2.7212
2022-10-08 13:46:51 - train: epoch 0065, iter [00710, 01251], lr: 0.000612, loss: 2.7098
2022-10-08 13:47:12 - train: epoch 0065, iter [00720, 01251], lr: 0.000612, loss: 3.0981
2022-10-08 13:47:33 - train: epoch 0065, iter [00730, 01251], lr: 0.000612, loss: 2.3453
2022-10-08 13:47:54 - train: epoch 0065, iter [00740, 01251], lr: 0.000611, loss: 3.4733
2022-10-08 13:48:15 - train: epoch 0065, iter [00750, 01251], lr: 0.000611, loss: 3.2272
2022-10-08 13:48:36 - train: epoch 0065, iter [00760, 01251], lr: 0.000611, loss: 3.1819
2022-10-08 13:48:58 - train: epoch 0065, iter [00770, 01251], lr: 0.000611, loss: 2.4166
2022-10-08 13:49:19 - train: epoch 0065, iter [00780, 01251], lr: 0.000610, loss: 3.1694
2022-10-08 13:49:40 - train: epoch 0065, iter [00790, 01251], lr: 0.000610, loss: 3.0127
2022-10-08 13:50:01 - train: epoch 0065, iter [00800, 01251], lr: 0.000610, loss: 2.8875
2022-10-08 13:50:22 - train: epoch 0065, iter [00810, 01251], lr: 0.000610, loss: 3.2480
2022-10-08 13:50:43 - train: epoch 0065, iter [00820, 01251], lr: 0.000609, loss: 3.3911
2022-10-08 13:51:04 - train: epoch 0065, iter [00830, 01251], lr: 0.000609, loss: 2.4673
2022-10-08 13:51:25 - train: epoch 0065, iter [00840, 01251], lr: 0.000609, loss: 2.7800
2022-10-08 13:51:46 - train: epoch 0065, iter [00850, 01251], lr: 0.000609, loss: 3.0578
2022-10-08 13:52:08 - train: epoch 0065, iter [00860, 01251], lr: 0.000608, loss: 3.2510
2022-10-08 13:52:29 - train: epoch 0065, iter [00870, 01251], lr: 0.000608, loss: 2.6381
2022-10-08 13:52:50 - train: epoch 0065, iter [00880, 01251], lr: 0.000608, loss: 2.9668
2022-10-08 13:53:11 - train: epoch 0065, iter [00890, 01251], lr: 0.000608, loss: 2.5146
2022-10-08 13:53:32 - train: epoch 0065, iter [00900, 01251], lr: 0.000608, loss: 3.1620
2022-10-08 13:53:53 - train: epoch 0065, iter [00910, 01251], lr: 0.000607, loss: 3.2010
2022-10-08 13:54:14 - train: epoch 0065, iter [00920, 01251], lr: 0.000607, loss: 2.6443
2022-10-08 13:54:35 - train: epoch 0065, iter [00930, 01251], lr: 0.000607, loss: 3.4085
2022-10-08 13:54:57 - train: epoch 0065, iter [00940, 01251], lr: 0.000607, loss: 2.7165
2022-10-08 13:55:18 - train: epoch 0065, iter [00950, 01251], lr: 0.000606, loss: 2.5236
2022-10-08 13:55:39 - train: epoch 0065, iter [00960, 01251], lr: 0.000606, loss: 3.1127
2022-10-08 13:56:00 - train: epoch 0065, iter [00970, 01251], lr: 0.000606, loss: 2.9952
2022-10-08 13:56:21 - train: epoch 0065, iter [00980, 01251], lr: 0.000606, loss: 2.4890
2022-10-08 13:56:42 - train: epoch 0065, iter [00990, 01251], lr: 0.000605, loss: 3.0107
2022-10-08 13:57:03 - train: epoch 0065, iter [01000, 01251], lr: 0.000605, loss: 1.9798
2022-10-08 13:57:25 - train: epoch 0065, iter [01010, 01251], lr: 0.000605, loss: 2.5375
2022-10-08 13:57:46 - train: epoch 0065, iter [01020, 01251], lr: 0.000605, loss: 2.8772
2022-10-08 13:58:07 - train: epoch 0065, iter [01030, 01251], lr: 0.000604, loss: 3.0792
2022-10-08 13:58:28 - train: epoch 0065, iter [01040, 01251], lr: 0.000604, loss: 2.1108
2022-10-08 13:58:49 - train: epoch 0065, iter [01050, 01251], lr: 0.000604, loss: 3.2529
2022-10-08 13:59:10 - train: epoch 0065, iter [01060, 01251], lr: 0.000604, loss: 3.1422
2022-10-08 13:59:31 - train: epoch 0065, iter [01070, 01251], lr: 0.000603, loss: 2.7129
2022-10-08 13:59:52 - train: epoch 0065, iter [01080, 01251], lr: 0.000603, loss: 2.4775
2022-10-08 14:00:14 - train: epoch 0065, iter [01090, 01251], lr: 0.000603, loss: 2.4740
2022-10-08 14:00:35 - train: epoch 0065, iter [01100, 01251], lr: 0.000603, loss: 3.0800
2022-10-08 14:00:56 - train: epoch 0065, iter [01110, 01251], lr: 0.000602, loss: 3.0530
2022-10-08 14:01:17 - train: epoch 0065, iter [01120, 01251], lr: 0.000602, loss: 3.4066
2022-10-08 14:01:38 - train: epoch 0065, iter [01130, 01251], lr: 0.000602, loss: 3.0545
2022-10-08 14:01:59 - train: epoch 0065, iter [01140, 01251], lr: 0.000602, loss: 2.4805
2022-10-08 14:02:20 - train: epoch 0065, iter [01150, 01251], lr: 0.000601, loss: 2.8085
2022-10-08 14:02:41 - train: epoch 0065, iter [01160, 01251], lr: 0.000601, loss: 3.2013
2022-10-08 14:03:02 - train: epoch 0065, iter [01170, 01251], lr: 0.000601, loss: 2.6718
2022-10-08 14:03:23 - train: epoch 0065, iter [01180, 01251], lr: 0.000601, loss: 2.7591
2022-10-08 14:03:44 - train: epoch 0065, iter [01190, 01251], lr: 0.000600, loss: 2.9741
2022-10-08 14:04:05 - train: epoch 0065, iter [01200, 01251], lr: 0.000600, loss: 2.4021
2022-10-08 14:04:27 - train: epoch 0065, iter [01210, 01251], lr: 0.000600, loss: 3.1238
2022-10-08 14:04:48 - train: epoch 0065, iter [01220, 01251], lr: 0.000600, loss: 2.7818
2022-10-08 14:05:09 - train: epoch 0065, iter [01230, 01251], lr: 0.000600, loss: 3.0185
2022-10-08 14:05:30 - train: epoch 0065, iter [01240, 01251], lr: 0.000599, loss: 2.8092
2022-10-08 14:05:51 - train: epoch 0065, iter [01250, 01251], lr: 0.000599, loss: 3.1607
2022-10-08 14:05:55 - train: epoch 065, train_loss: 2.9533
2022-10-08 14:07:10 - eval: epoch: 065, acc1: 81.814%, acc5: 96.112%, test_loss: 0.7962, per_image_load_time: 0.617ms, per_image_inference_time: 1.452ms
2022-10-08 14:07:11 - until epoch: 065, best_acc1: 81.934%
2022-10-08 14:07:11 - epoch 066 lr: 0.000599
2022-10-08 14:07:38 - train: epoch 0066, iter [00010, 01251], lr: 0.000599, loss: 3.0387
2022-10-08 14:07:59 - train: epoch 0066, iter [00020, 01251], lr: 0.000599, loss: 2.9879
2022-10-08 14:08:20 - train: epoch 0066, iter [00030, 01251], lr: 0.000598, loss: 2.6940
2022-10-08 14:08:42 - train: epoch 0066, iter [00040, 01251], lr: 0.000598, loss: 3.0843
2022-10-08 14:09:03 - train: epoch 0066, iter [00050, 01251], lr: 0.000598, loss: 2.5855
2022-10-08 14:09:24 - train: epoch 0066, iter [00060, 01251], lr: 0.000598, loss: 2.7376
2022-10-08 14:09:45 - train: epoch 0066, iter [00070, 01251], lr: 0.000597, loss: 3.2428
2022-10-08 14:10:06 - train: epoch 0066, iter [00080, 01251], lr: 0.000597, loss: 3.0367
2022-10-08 14:10:27 - train: epoch 0066, iter [00090, 01251], lr: 0.000597, loss: 2.7442
2022-10-08 14:10:48 - train: epoch 0066, iter [00100, 01251], lr: 0.000597, loss: 2.4818
2022-10-08 14:11:10 - train: epoch 0066, iter [00110, 01251], lr: 0.000596, loss: 2.9603
2022-10-08 14:11:31 - train: epoch 0066, iter [00120, 01251], lr: 0.000596, loss: 2.7117
2022-10-08 14:11:52 - train: epoch 0066, iter [00130, 01251], lr: 0.000596, loss: 3.0030
2022-10-08 14:12:13 - train: epoch 0066, iter [00140, 01251], lr: 0.000596, loss: 3.2604
2022-10-08 14:12:34 - train: epoch 0066, iter [00150, 01251], lr: 0.000595, loss: 3.2846
2022-10-08 14:12:56 - train: epoch 0066, iter [00160, 01251], lr: 0.000595, loss: 2.9062
2022-10-08 14:13:17 - train: epoch 0066, iter [00170, 01251], lr: 0.000595, loss: 3.2556
2022-10-08 14:13:38 - train: epoch 0066, iter [00180, 01251], lr: 0.000595, loss: 2.7630
2022-10-08 14:13:59 - train: epoch 0066, iter [00190, 01251], lr: 0.000594, loss: 3.2321
2022-10-08 14:14:20 - train: epoch 0066, iter [00200, 01251], lr: 0.000594, loss: 2.9159
2022-10-08 14:14:41 - train: epoch 0066, iter [00210, 01251], lr: 0.000594, loss: 2.5325
2022-10-08 14:15:02 - train: epoch 0066, iter [00220, 01251], lr: 0.000594, loss: 3.3231
2022-10-08 14:15:23 - train: epoch 0066, iter [00230, 01251], lr: 0.000593, loss: 2.9438
2022-10-08 14:15:44 - train: epoch 0066, iter [00240, 01251], lr: 0.000593, loss: 2.6927
2022-10-08 14:16:06 - train: epoch 0066, iter [00250, 01251], lr: 0.000593, loss: 2.8625
2022-10-08 14:16:27 - train: epoch 0066, iter [00260, 01251], lr: 0.000593, loss: 2.8338
2022-10-08 14:16:48 - train: epoch 0066, iter [00270, 01251], lr: 0.000592, loss: 3.2070
2022-10-08 14:17:09 - train: epoch 0066, iter [00280, 01251], lr: 0.000592, loss: 2.7706
2022-10-08 14:17:30 - train: epoch 0066, iter [00290, 01251], lr: 0.000592, loss: 3.0413
2022-10-08 14:17:51 - train: epoch 0066, iter [00300, 01251], lr: 0.000592, loss: 3.5597
2022-10-08 14:18:12 - train: epoch 0066, iter [00310, 01251], lr: 0.000592, loss: 2.5578
2022-10-08 14:18:33 - train: epoch 0066, iter [00320, 01251], lr: 0.000591, loss: 3.4025
2022-10-08 14:18:54 - train: epoch 0066, iter [00330, 01251], lr: 0.000591, loss: 3.1672
2022-10-08 14:19:15 - train: epoch 0066, iter [00340, 01251], lr: 0.000591, loss: 2.8129
2022-10-08 14:19:36 - train: epoch 0066, iter [00350, 01251], lr: 0.000591, loss: 2.8337
2022-10-08 14:19:58 - train: epoch 0066, iter [00360, 01251], lr: 0.000590, loss: 3.4582
2022-10-08 14:20:19 - train: epoch 0066, iter [00370, 01251], lr: 0.000590, loss: 3.0970
2022-10-08 14:20:40 - train: epoch 0066, iter [00380, 01251], lr: 0.000590, loss: 2.7122
2022-10-08 14:21:01 - train: epoch 0066, iter [00390, 01251], lr: 0.000590, loss: 2.7975
2022-10-08 14:21:22 - train: epoch 0066, iter [00400, 01251], lr: 0.000589, loss: 3.1776
2022-10-08 14:21:43 - train: epoch 0066, iter [00410, 01251], lr: 0.000589, loss: 2.9150
2022-10-08 14:22:04 - train: epoch 0066, iter [00420, 01251], lr: 0.000589, loss: 3.1277
2022-10-08 14:22:25 - train: epoch 0066, iter [00430, 01251], lr: 0.000589, loss: 1.9991
2022-10-08 14:22:46 - train: epoch 0066, iter [00440, 01251], lr: 0.000588, loss: 2.7035
2022-10-08 14:23:07 - train: epoch 0066, iter [00450, 01251], lr: 0.000588, loss: 3.4060
2022-10-08 14:23:28 - train: epoch 0066, iter [00460, 01251], lr: 0.000588, loss: 2.6614
2022-10-08 14:23:49 - train: epoch 0066, iter [00470, 01251], lr: 0.000588, loss: 3.4130
2022-10-08 14:24:10 - train: epoch 0066, iter [00480, 01251], lr: 0.000587, loss: 2.7290
2022-10-08 14:24:31 - train: epoch 0066, iter [00490, 01251], lr: 0.000587, loss: 3.3788
2022-10-08 14:24:52 - train: epoch 0066, iter [00500, 01251], lr: 0.000587, loss: 3.3472
2022-10-08 14:25:13 - train: epoch 0066, iter [00510, 01251], lr: 0.000587, loss: 3.2840
2022-10-08 14:25:34 - train: epoch 0066, iter [00520, 01251], lr: 0.000586, loss: 3.1185
2022-10-08 14:25:56 - train: epoch 0066, iter [00530, 01251], lr: 0.000586, loss: 2.8377
2022-10-08 14:26:17 - train: epoch 0066, iter [00540, 01251], lr: 0.000586, loss: 3.2953
2022-10-08 14:26:38 - train: epoch 0066, iter [00550, 01251], lr: 0.000586, loss: 2.6328
2022-10-08 14:26:59 - train: epoch 0066, iter [00560, 01251], lr: 0.000586, loss: 2.9121
2022-10-08 14:27:20 - train: epoch 0066, iter [00570, 01251], lr: 0.000585, loss: 3.1521
2022-10-08 14:27:41 - train: epoch 0066, iter [00580, 01251], lr: 0.000585, loss: 2.6403
2022-10-08 14:28:02 - train: epoch 0066, iter [00590, 01251], lr: 0.000585, loss: 2.2541
2022-10-08 14:28:24 - train: epoch 0066, iter [00600, 01251], lr: 0.000585, loss: 3.2532
2022-10-08 14:28:45 - train: epoch 0066, iter [00610, 01251], lr: 0.000584, loss: 3.2956
2022-10-08 14:29:06 - train: epoch 0066, iter [00620, 01251], lr: 0.000584, loss: 3.1701
2022-10-08 14:29:27 - train: epoch 0066, iter [00630, 01251], lr: 0.000584, loss: 2.8152
2022-10-08 14:29:48 - train: epoch 0066, iter [00640, 01251], lr: 0.000584, loss: 2.9077
2022-10-08 14:30:09 - train: epoch 0066, iter [00650, 01251], lr: 0.000583, loss: 3.4040
2022-10-08 14:30:30 - train: epoch 0066, iter [00660, 01251], lr: 0.000583, loss: 2.8626
2022-10-08 14:30:51 - train: epoch 0066, iter [00670, 01251], lr: 0.000583, loss: 3.4132
2022-10-08 14:31:12 - train: epoch 0066, iter [00680, 01251], lr: 0.000583, loss: 2.8768
2022-10-08 14:31:33 - train: epoch 0066, iter [00690, 01251], lr: 0.000582, loss: 3.2416
2022-10-08 14:31:54 - train: epoch 0066, iter [00700, 01251], lr: 0.000582, loss: 3.3640
2022-10-08 14:32:15 - train: epoch 0066, iter [00710, 01251], lr: 0.000582, loss: 3.1224
2022-10-08 14:32:36 - train: epoch 0066, iter [00720, 01251], lr: 0.000582, loss: 3.4808
2022-10-08 14:32:57 - train: epoch 0066, iter [00730, 01251], lr: 0.000581, loss: 2.5881
2022-10-08 14:33:18 - train: epoch 0066, iter [00740, 01251], lr: 0.000581, loss: 2.6674
2022-10-08 14:33:39 - train: epoch 0066, iter [00750, 01251], lr: 0.000581, loss: 3.3321
2022-10-08 14:34:00 - train: epoch 0066, iter [00760, 01251], lr: 0.000581, loss: 3.0721
2022-10-08 14:34:21 - train: epoch 0066, iter [00770, 01251], lr: 0.000580, loss: 2.8055
2022-10-08 14:34:43 - train: epoch 0066, iter [00780, 01251], lr: 0.000580, loss: 2.7933
2022-10-08 14:35:04 - train: epoch 0066, iter [00790, 01251], lr: 0.000580, loss: 2.8555
2022-10-08 14:35:25 - train: epoch 0066, iter [00800, 01251], lr: 0.000580, loss: 3.3058
2022-10-08 14:35:46 - train: epoch 0066, iter [00810, 01251], lr: 0.000580, loss: 2.9865
2022-10-08 14:36:07 - train: epoch 0066, iter [00820, 01251], lr: 0.000579, loss: 2.7311
2022-10-08 14:36:28 - train: epoch 0066, iter [00830, 01251], lr: 0.000579, loss: 3.0387
2022-10-08 14:36:49 - train: epoch 0066, iter [00840, 01251], lr: 0.000579, loss: 2.6205
2022-10-08 14:37:10 - train: epoch 0066, iter [00850, 01251], lr: 0.000579, loss: 2.6316
2022-10-08 14:37:31 - train: epoch 0066, iter [00860, 01251], lr: 0.000578, loss: 3.2897
2022-10-08 14:37:52 - train: epoch 0066, iter [00870, 01251], lr: 0.000578, loss: 2.7014
2022-10-08 14:38:13 - train: epoch 0066, iter [00880, 01251], lr: 0.000578, loss: 3.1256
2022-10-08 14:38:34 - train: epoch 0066, iter [00890, 01251], lr: 0.000578, loss: 3.2597
2022-10-08 14:38:55 - train: epoch 0066, iter [00900, 01251], lr: 0.000577, loss: 3.4685
2022-10-08 14:39:16 - train: epoch 0066, iter [00910, 01251], lr: 0.000577, loss: 3.1219
2022-10-08 14:39:37 - train: epoch 0066, iter [00920, 01251], lr: 0.000577, loss: 2.6733
2022-10-08 14:39:58 - train: epoch 0066, iter [00930, 01251], lr: 0.000577, loss: 3.1642
2022-10-08 14:40:19 - train: epoch 0066, iter [00940, 01251], lr: 0.000576, loss: 2.5103
2022-10-08 14:40:40 - train: epoch 0066, iter [00950, 01251], lr: 0.000576, loss: 3.3861
2022-10-08 14:41:01 - train: epoch 0066, iter [00960, 01251], lr: 0.000576, loss: 3.2777
2022-10-08 14:41:22 - train: epoch 0066, iter [00970, 01251], lr: 0.000576, loss: 3.3013
2022-10-08 14:41:43 - train: epoch 0066, iter [00980, 01251], lr: 0.000575, loss: 2.7883
2022-10-08 14:42:04 - train: epoch 0066, iter [00990, 01251], lr: 0.000575, loss: 3.3882
2022-10-08 14:42:26 - train: epoch 0066, iter [01000, 01251], lr: 0.000575, loss: 2.9771
2022-10-08 14:42:47 - train: epoch 0066, iter [01010, 01251], lr: 0.000575, loss: 3.2266
2022-10-08 14:43:08 - train: epoch 0066, iter [01020, 01251], lr: 0.000574, loss: 2.9900
2022-10-08 14:43:29 - train: epoch 0066, iter [01030, 01251], lr: 0.000574, loss: 3.0483
2022-10-08 14:43:50 - train: epoch 0066, iter [01040, 01251], lr: 0.000574, loss: 2.7558
2022-10-08 14:44:11 - train: epoch 0066, iter [01050, 01251], lr: 0.000574, loss: 2.7524
2022-10-08 14:44:32 - train: epoch 0066, iter [01060, 01251], lr: 0.000574, loss: 3.0965
2022-10-08 14:44:53 - train: epoch 0066, iter [01070, 01251], lr: 0.000573, loss: 2.8282
2022-10-08 14:45:14 - train: epoch 0066, iter [01080, 01251], lr: 0.000573, loss: 3.2225
2022-10-08 14:45:35 - train: epoch 0066, iter [01090, 01251], lr: 0.000573, loss: 3.1715
2022-10-08 14:45:56 - train: epoch 0066, iter [01100, 01251], lr: 0.000573, loss: 3.2731
2022-10-08 14:46:17 - train: epoch 0066, iter [01110, 01251], lr: 0.000572, loss: 3.2763
2022-10-08 14:46:38 - train: epoch 0066, iter [01120, 01251], lr: 0.000572, loss: 3.0386
2022-10-08 14:46:59 - train: epoch 0066, iter [01130, 01251], lr: 0.000572, loss: 3.1698
2022-10-08 14:47:20 - train: epoch 0066, iter [01140, 01251], lr: 0.000572, loss: 3.2682
2022-10-08 14:47:41 - train: epoch 0066, iter [01150, 01251], lr: 0.000571, loss: 2.5847
2022-10-08 14:48:02 - train: epoch 0066, iter [01160, 01251], lr: 0.000571, loss: 2.9007
2022-10-08 14:48:23 - train: epoch 0066, iter [01170, 01251], lr: 0.000571, loss: 2.9816
2022-10-08 14:48:44 - train: epoch 0066, iter [01180, 01251], lr: 0.000571, loss: 2.9079
2022-10-08 14:49:05 - train: epoch 0066, iter [01190, 01251], lr: 0.000570, loss: 2.8160
2022-10-08 14:49:26 - train: epoch 0066, iter [01200, 01251], lr: 0.000570, loss: 2.2589
2022-10-08 14:49:47 - train: epoch 0066, iter [01210, 01251], lr: 0.000570, loss: 2.9058
2022-10-08 14:50:09 - train: epoch 0066, iter [01220, 01251], lr: 0.000570, loss: 3.1761
2022-10-08 14:50:30 - train: epoch 0066, iter [01230, 01251], lr: 0.000569, loss: 2.5737
2022-10-08 14:50:51 - train: epoch 0066, iter [01240, 01251], lr: 0.000569, loss: 3.2774
2022-10-08 14:51:12 - train: epoch 0066, iter [01250, 01251], lr: 0.000569, loss: 3.1250
2022-10-08 14:51:15 - train: epoch 066, train_loss: 2.9487
2022-10-08 14:52:32 - eval: epoch: 066, acc1: 81.852%, acc5: 96.114%, test_loss: 0.7978, per_image_load_time: 1.185ms, per_image_inference_time: 1.424ms
2022-10-08 14:52:33 - until epoch: 066, best_acc1: 81.934%
2022-10-08 14:52:33 - epoch 067 lr: 0.000569
2022-10-08 14:53:00 - train: epoch 0067, iter [00010, 01251], lr: 0.000569, loss: 3.1337
2022-10-08 14:53:21 - train: epoch 0067, iter [00020, 01251], lr: 0.000568, loss: 2.3837
2022-10-08 14:53:42 - train: epoch 0067, iter [00030, 01251], lr: 0.000568, loss: 3.2118
2022-10-08 14:54:03 - train: epoch 0067, iter [00040, 01251], lr: 0.000568, loss: 3.3857
2022-10-08 14:54:24 - train: epoch 0067, iter [00050, 01251], lr: 0.000568, loss: 3.2032
2022-10-08 14:54:46 - train: epoch 0067, iter [00060, 01251], lr: 0.000568, loss: 3.3169
2022-10-08 14:55:07 - train: epoch 0067, iter [00070, 01251], lr: 0.000567, loss: 2.7549
2022-10-08 14:55:28 - train: epoch 0067, iter [00080, 01251], lr: 0.000567, loss: 2.9211
2022-10-08 14:55:49 - train: epoch 0067, iter [00090, 01251], lr: 0.000567, loss: 3.2977
2022-10-08 14:56:11 - train: epoch 0067, iter [00100, 01251], lr: 0.000567, loss: 2.8115
2022-10-08 14:56:32 - train: epoch 0067, iter [00110, 01251], lr: 0.000566, loss: 2.8547
2022-10-08 14:56:53 - train: epoch 0067, iter [00120, 01251], lr: 0.000566, loss: 3.3982
2022-10-08 14:57:14 - train: epoch 0067, iter [00130, 01251], lr: 0.000566, loss: 2.8903
2022-10-08 14:57:36 - train: epoch 0067, iter [00140, 01251], lr: 0.000566, loss: 3.3686
2022-10-08 14:57:57 - train: epoch 0067, iter [00150, 01251], lr: 0.000565, loss: 3.2811
2022-10-08 14:58:18 - train: epoch 0067, iter [00160, 01251], lr: 0.000565, loss: 3.0701
2022-10-08 14:58:39 - train: epoch 0067, iter [00170, 01251], lr: 0.000565, loss: 3.0062
2022-10-08 14:59:01 - train: epoch 0067, iter [00180, 01251], lr: 0.000565, loss: 3.1556
2022-10-08 14:59:22 - train: epoch 0067, iter [00190, 01251], lr: 0.000564, loss: 2.7199
2022-10-08 14:59:43 - train: epoch 0067, iter [00200, 01251], lr: 0.000564, loss: 3.1417
2022-10-08 15:00:04 - train: epoch 0067, iter [00210, 01251], lr: 0.000564, loss: 3.1483
2022-10-08 15:00:25 - train: epoch 0067, iter [00220, 01251], lr: 0.000564, loss: 3.3774
2022-10-08 15:00:46 - train: epoch 0067, iter [00230, 01251], lr: 0.000563, loss: 2.5654
2022-10-08 15:01:07 - train: epoch 0067, iter [00240, 01251], lr: 0.000563, loss: 3.3237
2022-10-08 15:01:28 - train: epoch 0067, iter [00250, 01251], lr: 0.000563, loss: 2.9189
2022-10-08 15:01:50 - train: epoch 0067, iter [00260, 01251], lr: 0.000563, loss: 3.2978
2022-10-08 15:02:11 - train: epoch 0067, iter [00270, 01251], lr: 0.000563, loss: 2.5617
2022-10-08 15:02:32 - train: epoch 0067, iter [00280, 01251], lr: 0.000562, loss: 2.9911
2022-10-08 15:02:53 - train: epoch 0067, iter [00290, 01251], lr: 0.000562, loss: 2.7737
2022-10-08 15:03:14 - train: epoch 0067, iter [00300, 01251], lr: 0.000562, loss: 3.1540
2022-10-08 15:03:35 - train: epoch 0067, iter [00310, 01251], lr: 0.000562, loss: 2.9609
2022-10-08 15:03:56 - train: epoch 0067, iter [00320, 01251], lr: 0.000561, loss: 2.8415
2022-10-08 15:04:17 - train: epoch 0067, iter [00330, 01251], lr: 0.000561, loss: 3.3528
2022-10-08 15:04:38 - train: epoch 0067, iter [00340, 01251], lr: 0.000561, loss: 3.2465
2022-10-08 15:04:59 - train: epoch 0067, iter [00350, 01251], lr: 0.000561, loss: 2.9348
2022-10-08 15:05:20 - train: epoch 0067, iter [00360, 01251], lr: 0.000560, loss: 3.0839
2022-10-08 15:05:41 - train: epoch 0067, iter [00370, 01251], lr: 0.000560, loss: 2.6742
2022-10-08 15:06:02 - train: epoch 0067, iter [00380, 01251], lr: 0.000560, loss: 2.3722
2022-10-08 15:06:23 - train: epoch 0067, iter [00390, 01251], lr: 0.000560, loss: 3.1225
2022-10-08 15:06:44 - train: epoch 0067, iter [00400, 01251], lr: 0.000559, loss: 2.6217
2022-10-08 15:07:06 - train: epoch 0067, iter [00410, 01251], lr: 0.000559, loss: 3.6305
2022-10-08 15:07:27 - train: epoch 0067, iter [00420, 01251], lr: 0.000559, loss: 3.1321
2022-10-08 15:07:48 - train: epoch 0067, iter [00430, 01251], lr: 0.000559, loss: 2.5104
2022-10-08 15:08:09 - train: epoch 0067, iter [00440, 01251], lr: 0.000559, loss: 2.2248
2022-10-08 15:08:30 - train: epoch 0067, iter [00450, 01251], lr: 0.000558, loss: 2.5966
2022-10-08 15:08:51 - train: epoch 0067, iter [00460, 01251], lr: 0.000558, loss: 3.1482
2022-10-08 15:09:12 - train: epoch 0067, iter [00470, 01251], lr: 0.000558, loss: 3.1713
2022-10-08 15:09:33 - train: epoch 0067, iter [00480, 01251], lr: 0.000558, loss: 3.1317
2022-10-08 15:09:54 - train: epoch 0067, iter [00490, 01251], lr: 0.000557, loss: 3.1037
2022-10-08 15:10:15 - train: epoch 0067, iter [00500, 01251], lr: 0.000557, loss: 2.8874
2022-10-08 15:10:36 - train: epoch 0067, iter [00510, 01251], lr: 0.000557, loss: 3.1200
2022-10-08 15:10:57 - train: epoch 0067, iter [00520, 01251], lr: 0.000557, loss: 2.8985
2022-10-08 15:11:18 - train: epoch 0067, iter [00530, 01251], lr: 0.000556, loss: 3.1878
2022-10-08 15:11:39 - train: epoch 0067, iter [00540, 01251], lr: 0.000556, loss: 2.7045
2022-10-08 15:12:00 - train: epoch 0067, iter [00550, 01251], lr: 0.000556, loss: 3.0675
2022-10-08 15:12:21 - train: epoch 0067, iter [00560, 01251], lr: 0.000556, loss: 3.2560
2022-10-08 15:12:42 - train: epoch 0067, iter [00570, 01251], lr: 0.000555, loss: 3.4341
2022-10-08 15:13:03 - train: epoch 0067, iter [00580, 01251], lr: 0.000555, loss: 3.1737
2022-10-08 15:13:25 - train: epoch 0067, iter [00590, 01251], lr: 0.000555, loss: 2.8010
2022-10-08 15:13:46 - train: epoch 0067, iter [00600, 01251], lr: 0.000555, loss: 2.8548
2022-10-08 15:14:07 - train: epoch 0067, iter [00610, 01251], lr: 0.000554, loss: 3.4313
2022-10-08 15:14:28 - train: epoch 0067, iter [00620, 01251], lr: 0.000554, loss: 3.2315
2022-10-08 15:14:49 - train: epoch 0067, iter [00630, 01251], lr: 0.000554, loss: 3.0854
2022-10-08 15:15:10 - train: epoch 0067, iter [00640, 01251], lr: 0.000554, loss: 2.5680
2022-10-08 15:15:31 - train: epoch 0067, iter [00650, 01251], lr: 0.000554, loss: 2.9235
2022-10-08 15:15:52 - train: epoch 0067, iter [00660, 01251], lr: 0.000553, loss: 2.6611
2022-10-08 15:16:13 - train: epoch 0067, iter [00670, 01251], lr: 0.000553, loss: 2.8688
2022-10-08 15:16:34 - train: epoch 0067, iter [00680, 01251], lr: 0.000553, loss: 2.3058
2022-10-08 15:16:55 - train: epoch 0067, iter [00690, 01251], lr: 0.000553, loss: 2.3917
2022-10-08 15:17:16 - train: epoch 0067, iter [00700, 01251], lr: 0.000552, loss: 3.3419
2022-10-08 15:17:37 - train: epoch 0067, iter [00710, 01251], lr: 0.000552, loss: 3.1662
2022-10-08 15:17:59 - train: epoch 0067, iter [00720, 01251], lr: 0.000552, loss: 3.3456
2022-10-08 15:18:20 - train: epoch 0067, iter [00730, 01251], lr: 0.000552, loss: 3.1493
2022-10-08 15:18:41 - train: epoch 0067, iter [00740, 01251], lr: 0.000551, loss: 2.6747
2022-10-08 15:19:02 - train: epoch 0067, iter [00750, 01251], lr: 0.000551, loss: 3.0907
2022-10-08 15:19:23 - train: epoch 0067, iter [00760, 01251], lr: 0.000551, loss: 2.6409
2022-10-08 15:19:44 - train: epoch 0067, iter [00770, 01251], lr: 0.000551, loss: 3.1545
2022-10-08 15:20:05 - train: epoch 0067, iter [00780, 01251], lr: 0.000550, loss: 3.3170
2022-10-08 15:20:26 - train: epoch 0067, iter [00790, 01251], lr: 0.000550, loss: 3.4557
2022-10-08 15:20:47 - train: epoch 0067, iter [00800, 01251], lr: 0.000550, loss: 2.6598
2022-10-08 15:21:08 - train: epoch 0067, iter [00810, 01251], lr: 0.000550, loss: 2.8574
2022-10-08 15:21:29 - train: epoch 0067, iter [00820, 01251], lr: 0.000550, loss: 3.0045
2022-10-08 15:21:50 - train: epoch 0067, iter [00830, 01251], lr: 0.000549, loss: 2.6634
2022-10-08 15:22:11 - train: epoch 0067, iter [00840, 01251], lr: 0.000549, loss: 3.1929
2022-10-08 15:22:32 - train: epoch 0067, iter [00850, 01251], lr: 0.000549, loss: 3.2329
2022-10-08 15:22:53 - train: epoch 0067, iter [00860, 01251], lr: 0.000549, loss: 2.5453
2022-10-08 15:23:14 - train: epoch 0067, iter [00870, 01251], lr: 0.000548, loss: 2.5579
2022-10-08 15:23:35 - train: epoch 0067, iter [00880, 01251], lr: 0.000548, loss: 3.0169
2022-10-08 15:23:56 - train: epoch 0067, iter [00890, 01251], lr: 0.000548, loss: 2.5008
2022-10-08 15:24:17 - train: epoch 0067, iter [00900, 01251], lr: 0.000548, loss: 2.8654
2022-10-08 15:24:38 - train: epoch 0067, iter [00910, 01251], lr: 0.000547, loss: 2.4409
2022-10-08 15:24:59 - train: epoch 0067, iter [00920, 01251], lr: 0.000547, loss: 3.2354
2022-10-08 15:25:20 - train: epoch 0067, iter [00930, 01251], lr: 0.000547, loss: 3.0344
2022-10-08 15:25:41 - train: epoch 0067, iter [00940, 01251], lr: 0.000547, loss: 2.8590
2022-10-08 15:26:03 - train: epoch 0067, iter [00950, 01251], lr: 0.000546, loss: 2.5872
2022-10-08 15:26:24 - train: epoch 0067, iter [00960, 01251], lr: 0.000546, loss: 2.7781
2022-10-08 15:26:45 - train: epoch 0067, iter [00970, 01251], lr: 0.000546, loss: 3.0911
2022-10-08 15:27:06 - train: epoch 0067, iter [00980, 01251], lr: 0.000546, loss: 3.0454
2022-10-08 15:27:27 - train: epoch 0067, iter [00990, 01251], lr: 0.000546, loss: 2.9821
2022-10-08 15:27:48 - train: epoch 0067, iter [01000, 01251], lr: 0.000545, loss: 2.9677
2022-10-08 15:28:09 - train: epoch 0067, iter [01010, 01251], lr: 0.000545, loss: 2.9243
2022-10-08 15:28:30 - train: epoch 0067, iter [01020, 01251], lr: 0.000545, loss: 3.1546
2022-10-08 15:28:51 - train: epoch 0067, iter [01030, 01251], lr: 0.000545, loss: 3.4310
2022-10-08 15:29:12 - train: epoch 0067, iter [01040, 01251], lr: 0.000544, loss: 2.8510
2022-10-08 15:29:33 - train: epoch 0067, iter [01050, 01251], lr: 0.000544, loss: 3.1727
2022-10-08 15:29:54 - train: epoch 0067, iter [01060, 01251], lr: 0.000544, loss: 3.2019
2022-10-08 15:30:15 - train: epoch 0067, iter [01070, 01251], lr: 0.000544, loss: 2.5617
2022-10-08 15:30:36 - train: epoch 0067, iter [01080, 01251], lr: 0.000543, loss: 3.2837
2022-10-08 15:30:57 - train: epoch 0067, iter [01090, 01251], lr: 0.000543, loss: 2.9422
2022-10-08 15:31:18 - train: epoch 0067, iter [01100, 01251], lr: 0.000543, loss: 2.4910
2022-10-08 15:31:39 - train: epoch 0067, iter [01110, 01251], lr: 0.000543, loss: 3.1926
2022-10-08 15:32:00 - train: epoch 0067, iter [01120, 01251], lr: 0.000542, loss: 3.0268
2022-10-08 15:32:21 - train: epoch 0067, iter [01130, 01251], lr: 0.000542, loss: 3.2165
2022-10-08 15:32:42 - train: epoch 0067, iter [01140, 01251], lr: 0.000542, loss: 2.7611
2022-10-08 15:33:04 - train: epoch 0067, iter [01150, 01251], lr: 0.000542, loss: 2.6887
2022-10-08 15:33:25 - train: epoch 0067, iter [01160, 01251], lr: 0.000542, loss: 3.2729
2022-10-08 15:33:46 - train: epoch 0067, iter [01170, 01251], lr: 0.000541, loss: 2.9400
2022-10-08 15:34:07 - train: epoch 0067, iter [01180, 01251], lr: 0.000541, loss: 3.1663
2022-10-08 15:34:28 - train: epoch 0067, iter [01190, 01251], lr: 0.000541, loss: 3.2761
2022-10-08 15:34:49 - train: epoch 0067, iter [01200, 01251], lr: 0.000541, loss: 2.7923
2022-10-08 15:35:10 - train: epoch 0067, iter [01210, 01251], lr: 0.000540, loss: 3.3941
2022-10-08 15:35:31 - train: epoch 0067, iter [01220, 01251], lr: 0.000540, loss: 3.2995
2022-10-08 15:35:52 - train: epoch 0067, iter [01230, 01251], lr: 0.000540, loss: 3.1742
2022-10-08 15:36:13 - train: epoch 0067, iter [01240, 01251], lr: 0.000540, loss: 2.8835
2022-10-08 15:36:33 - train: epoch 0067, iter [01250, 01251], lr: 0.000539, loss: 3.1928
2022-10-08 15:36:37 - train: epoch 067, train_loss: 2.9428
2022-10-08 15:37:55 - eval: epoch: 067, acc1: 81.922%, acc5: 96.160%, test_loss: 0.7913, per_image_load_time: 1.284ms, per_image_inference_time: 1.433ms
2022-10-08 15:37:56 - until epoch: 067, best_acc1: 81.934%
2022-10-08 15:37:56 - epoch 068 lr: 0.000539
2022-10-08 15:38:24 - train: epoch 0068, iter [00010, 01251], lr: 0.000539, loss: 3.1578
2022-10-08 15:38:45 - train: epoch 0068, iter [00020, 01251], lr: 0.000539, loss: 3.0292
2022-10-08 15:39:06 - train: epoch 0068, iter [00030, 01251], lr: 0.000539, loss: 3.1766
2022-10-08 15:39:27 - train: epoch 0068, iter [00040, 01251], lr: 0.000538, loss: 3.5212
2022-10-08 15:39:48 - train: epoch 0068, iter [00050, 01251], lr: 0.000538, loss: 3.4384
2022-10-08 15:40:09 - train: epoch 0068, iter [00060, 01251], lr: 0.000538, loss: 3.1100
2022-10-08 15:40:30 - train: epoch 0068, iter [00070, 01251], lr: 0.000538, loss: 3.4507
2022-10-08 15:40:52 - train: epoch 0068, iter [00080, 01251], lr: 0.000538, loss: 2.8218
2022-10-08 15:41:13 - train: epoch 0068, iter [00090, 01251], lr: 0.000537, loss: 3.2214
2022-10-08 15:41:34 - train: epoch 0068, iter [00100, 01251], lr: 0.000537, loss: 2.8786
2022-10-08 15:41:55 - train: epoch 0068, iter [00110, 01251], lr: 0.000537, loss: 2.7044
2022-10-08 15:42:16 - train: epoch 0068, iter [00120, 01251], lr: 0.000537, loss: 3.1330
2022-10-08 15:42:38 - train: epoch 0068, iter [00130, 01251], lr: 0.000536, loss: 3.0312
2022-10-08 15:42:59 - train: epoch 0068, iter [00140, 01251], lr: 0.000536, loss: 3.2629
2022-10-08 15:43:20 - train: epoch 0068, iter [00150, 01251], lr: 0.000536, loss: 3.1544
2022-10-08 15:43:41 - train: epoch 0068, iter [00160, 01251], lr: 0.000536, loss: 3.1600
2022-10-08 15:44:02 - train: epoch 0068, iter [00170, 01251], lr: 0.000535, loss: 2.0352
2022-10-08 15:44:24 - train: epoch 0068, iter [00180, 01251], lr: 0.000535, loss: 2.9783
2022-10-08 15:44:45 - train: epoch 0068, iter [00190, 01251], lr: 0.000535, loss: 3.4100
2022-10-08 15:45:06 - train: epoch 0068, iter [00200, 01251], lr: 0.000535, loss: 3.2273
2022-10-08 15:45:27 - train: epoch 0068, iter [00210, 01251], lr: 0.000534, loss: 2.9595
2022-10-08 15:45:48 - train: epoch 0068, iter [00220, 01251], lr: 0.000534, loss: 3.1566
2022-10-08 15:46:09 - train: epoch 0068, iter [00230, 01251], lr: 0.000534, loss: 3.0786
2022-10-08 15:46:31 - train: epoch 0068, iter [00240, 01251], lr: 0.000534, loss: 2.7845
2022-10-08 15:46:52 - train: epoch 0068, iter [00250, 01251], lr: 0.000534, loss: 2.5250
2022-10-08 15:47:13 - train: epoch 0068, iter [00260, 01251], lr: 0.000533, loss: 2.9194
2022-10-08 15:47:34 - train: epoch 0068, iter [00270, 01251], lr: 0.000533, loss: 2.7217
2022-10-08 15:47:55 - train: epoch 0068, iter [00280, 01251], lr: 0.000533, loss: 2.7921
2022-10-08 15:48:16 - train: epoch 0068, iter [00290, 01251], lr: 0.000533, loss: 3.3488
2022-10-08 15:48:38 - train: epoch 0068, iter [00300, 01251], lr: 0.000532, loss: 2.9027
2022-10-08 15:48:59 - train: epoch 0068, iter [00310, 01251], lr: 0.000532, loss: 2.9601
2022-10-08 15:49:20 - train: epoch 0068, iter [00320, 01251], lr: 0.000532, loss: 2.8140
2022-10-08 15:49:41 - train: epoch 0068, iter [00330, 01251], lr: 0.000532, loss: 3.4736
2022-10-08 15:50:02 - train: epoch 0068, iter [00340, 01251], lr: 0.000531, loss: 2.7937
2022-10-08 15:50:24 - train: epoch 0068, iter [00350, 01251], lr: 0.000531, loss: 2.9387
2022-10-08 15:50:45 - train: epoch 0068, iter [00360, 01251], lr: 0.000531, loss: 3.1606
2022-10-08 15:51:06 - train: epoch 0068, iter [00370, 01251], lr: 0.000531, loss: 3.3090
2022-10-08 15:51:27 - train: epoch 0068, iter [00380, 01251], lr: 0.000531, loss: 3.2394
2022-10-08 15:51:48 - train: epoch 0068, iter [00390, 01251], lr: 0.000530, loss: 3.1857
2022-10-08 15:52:09 - train: epoch 0068, iter [00400, 01251], lr: 0.000530, loss: 2.6498
2022-10-08 15:52:30 - train: epoch 0068, iter [00410, 01251], lr: 0.000530, loss: 2.3819
2022-10-08 15:52:52 - train: epoch 0068, iter [00420, 01251], lr: 0.000530, loss: 2.9623
2022-10-08 15:53:13 - train: epoch 0068, iter [00430, 01251], lr: 0.000529, loss: 2.7415
2022-10-08 15:53:34 - train: epoch 0068, iter [00440, 01251], lr: 0.000529, loss: 3.0675
2022-10-08 15:53:55 - train: epoch 0068, iter [00450, 01251], lr: 0.000529, loss: 2.8318
2022-10-08 15:54:16 - train: epoch 0068, iter [00460, 01251], lr: 0.000529, loss: 2.5457
2022-10-08 15:54:37 - train: epoch 0068, iter [00470, 01251], lr: 0.000528, loss: 2.8164
2022-10-08 15:54:59 - train: epoch 0068, iter [00480, 01251], lr: 0.000528, loss: 2.8032
2022-10-08 15:55:20 - train: epoch 0068, iter [00490, 01251], lr: 0.000528, loss: 2.4544
2022-10-08 15:55:41 - train: epoch 0068, iter [00500, 01251], lr: 0.000528, loss: 2.8972
2022-10-08 15:56:02 - train: epoch 0068, iter [00510, 01251], lr: 0.000527, loss: 2.9705
2022-10-08 15:56:23 - train: epoch 0068, iter [00520, 01251], lr: 0.000527, loss: 2.3585
2022-10-08 15:56:44 - train: epoch 0068, iter [00530, 01251], lr: 0.000527, loss: 3.0783
2022-10-08 15:57:05 - train: epoch 0068, iter [00540, 01251], lr: 0.000527, loss: 3.4630
2022-10-08 15:57:27 - train: epoch 0068, iter [00550, 01251], lr: 0.000527, loss: 2.8082
2022-10-08 15:57:48 - train: epoch 0068, iter [00560, 01251], lr: 0.000526, loss: 3.1255
2022-10-08 15:58:09 - train: epoch 0068, iter [00570, 01251], lr: 0.000526, loss: 3.5318
2022-10-08 15:58:30 - train: epoch 0068, iter [00580, 01251], lr: 0.000526, loss: 2.5567
2022-10-08 15:58:51 - train: epoch 0068, iter [00590, 01251], lr: 0.000526, loss: 2.6342
2022-10-08 15:59:13 - train: epoch 0068, iter [00600, 01251], lr: 0.000525, loss: 3.3533
2022-10-08 15:59:34 - train: epoch 0068, iter [00610, 01251], lr: 0.000525, loss: 3.2191
2022-10-08 15:59:55 - train: epoch 0068, iter [00620, 01251], lr: 0.000525, loss: 3.3147
2022-10-08 16:00:16 - train: epoch 0068, iter [00630, 01251], lr: 0.000525, loss: 2.9422
2022-10-08 16:00:37 - train: epoch 0068, iter [00640, 01251], lr: 0.000524, loss: 3.0307
2022-10-08 16:00:58 - train: epoch 0068, iter [00650, 01251], lr: 0.000524, loss: 3.1195
2022-10-08 16:01:20 - train: epoch 0068, iter [00660, 01251], lr: 0.000524, loss: 2.9143
2022-10-08 16:01:41 - train: epoch 0068, iter [00670, 01251], lr: 0.000524, loss: 3.0189
2022-10-08 16:02:02 - train: epoch 0068, iter [00680, 01251], lr: 0.000524, loss: 3.0104
2022-10-08 16:02:23 - train: epoch 0068, iter [00690, 01251], lr: 0.000523, loss: 2.6891
2022-10-08 16:02:44 - train: epoch 0068, iter [00700, 01251], lr: 0.000523, loss: 2.6799
2022-10-08 16:03:06 - train: epoch 0068, iter [00710, 01251], lr: 0.000523, loss: 2.5474
2022-10-08 16:03:27 - train: epoch 0068, iter [00720, 01251], lr: 0.000523, loss: 3.4837
2022-10-08 16:03:48 - train: epoch 0068, iter [00730, 01251], lr: 0.000522, loss: 3.1301
2022-10-08 16:04:09 - train: epoch 0068, iter [00740, 01251], lr: 0.000522, loss: 3.3359
2022-10-08 16:04:30 - train: epoch 0068, iter [00750, 01251], lr: 0.000522, loss: 3.1981
2022-10-08 16:04:52 - train: epoch 0068, iter [00760, 01251], lr: 0.000522, loss: 2.6464
2022-10-08 16:05:13 - train: epoch 0068, iter [00770, 01251], lr: 0.000521, loss: 3.3330
2022-10-08 16:05:34 - train: epoch 0068, iter [00780, 01251], lr: 0.000521, loss: 3.0589
2022-10-08 16:05:55 - train: epoch 0068, iter [00790, 01251], lr: 0.000521, loss: 2.9272
2022-10-08 16:06:17 - train: epoch 0068, iter [00800, 01251], lr: 0.000521, loss: 2.0632
2022-10-08 16:06:38 - train: epoch 0068, iter [00810, 01251], lr: 0.000521, loss: 2.6362
2022-10-08 16:06:59 - train: epoch 0068, iter [00820, 01251], lr: 0.000520, loss: 2.6225
2022-10-08 16:07:20 - train: epoch 0068, iter [00830, 01251], lr: 0.000520, loss: 3.2308
2022-10-08 16:07:41 - train: epoch 0068, iter [00840, 01251], lr: 0.000520, loss: 2.9412
2022-10-08 16:08:03 - train: epoch 0068, iter [00850, 01251], lr: 0.000520, loss: 3.4435
2022-10-08 16:08:24 - train: epoch 0068, iter [00860, 01251], lr: 0.000519, loss: 3.1394
2022-10-08 16:08:45 - train: epoch 0068, iter [00870, 01251], lr: 0.000519, loss: 2.8547
2022-10-08 16:09:06 - train: epoch 0068, iter [00880, 01251], lr: 0.000519, loss: 2.7815
2022-10-08 16:09:28 - train: epoch 0068, iter [00890, 01251], lr: 0.000519, loss: 3.2284
2022-10-08 16:09:49 - train: epoch 0068, iter [00900, 01251], lr: 0.000518, loss: 3.2105
2022-10-08 16:10:10 - train: epoch 0068, iter [00910, 01251], lr: 0.000518, loss: 2.4360
2022-10-08 16:10:31 - train: epoch 0068, iter [00920, 01251], lr: 0.000518, loss: 3.2115
2022-10-08 16:10:52 - train: epoch 0068, iter [00930, 01251], lr: 0.000518, loss: 3.5219
2022-10-08 16:11:13 - train: epoch 0068, iter [00940, 01251], lr: 0.000517, loss: 2.1227
2022-10-08 16:11:35 - train: epoch 0068, iter [00950, 01251], lr: 0.000517, loss: 3.1730
2022-10-08 16:11:56 - train: epoch 0068, iter [00960, 01251], lr: 0.000517, loss: 3.2254
2022-10-08 16:12:17 - train: epoch 0068, iter [00970, 01251], lr: 0.000517, loss: 3.2328
2022-10-08 16:12:38 - train: epoch 0068, iter [00980, 01251], lr: 0.000517, loss: 2.6910
2022-10-08 16:12:59 - train: epoch 0068, iter [00990, 01251], lr: 0.000516, loss: 2.5758
2022-10-08 16:13:20 - train: epoch 0068, iter [01000, 01251], lr: 0.000516, loss: 3.1179
2022-10-08 16:13:42 - train: epoch 0068, iter [01010, 01251], lr: 0.000516, loss: 3.0879
2022-10-08 16:14:03 - train: epoch 0068, iter [01020, 01251], lr: 0.000516, loss: 2.4485
2022-10-08 16:14:24 - train: epoch 0068, iter [01030, 01251], lr: 0.000515, loss: 3.2383
2022-10-08 16:14:45 - train: epoch 0068, iter [01040, 01251], lr: 0.000515, loss: 3.2044
2022-10-08 16:15:07 - train: epoch 0068, iter [01050, 01251], lr: 0.000515, loss: 3.0298
2022-10-08 16:15:28 - train: epoch 0068, iter [01060, 01251], lr: 0.000515, loss: 2.4178
2022-10-08 16:15:49 - train: epoch 0068, iter [01070, 01251], lr: 0.000514, loss: 2.5710
2022-10-08 16:16:10 - train: epoch 0068, iter [01080, 01251], lr: 0.000514, loss: 3.1181
2022-10-08 16:16:31 - train: epoch 0068, iter [01090, 01251], lr: 0.000514, loss: 2.5943
2022-10-08 16:16:53 - train: epoch 0068, iter [01100, 01251], lr: 0.000514, loss: 3.2011
2022-10-08 16:17:14 - train: epoch 0068, iter [01110, 01251], lr: 0.000514, loss: 3.0847
2022-10-08 16:17:35 - train: epoch 0068, iter [01120, 01251], lr: 0.000513, loss: 3.3774
2022-10-08 16:17:56 - train: epoch 0068, iter [01130, 01251], lr: 0.000513, loss: 3.2086
2022-10-08 16:18:17 - train: epoch 0068, iter [01140, 01251], lr: 0.000513, loss: 3.2751
2022-10-08 16:18:39 - train: epoch 0068, iter [01150, 01251], lr: 0.000513, loss: 3.1611
2022-10-08 16:19:00 - train: epoch 0068, iter [01160, 01251], lr: 0.000512, loss: 2.7144
2022-10-08 16:19:21 - train: epoch 0068, iter [01170, 01251], lr: 0.000512, loss: 2.6861
2022-10-08 16:19:42 - train: epoch 0068, iter [01180, 01251], lr: 0.000512, loss: 2.7575
2022-10-08 16:20:03 - train: epoch 0068, iter [01190, 01251], lr: 0.000512, loss: 3.3440
2022-10-08 16:20:24 - train: epoch 0068, iter [01200, 01251], lr: 0.000511, loss: 2.6377
2022-10-08 16:20:45 - train: epoch 0068, iter [01210, 01251], lr: 0.000511, loss: 2.7030
2022-10-08 16:21:06 - train: epoch 0068, iter [01220, 01251], lr: 0.000511, loss: 2.8384
2022-10-08 16:21:28 - train: epoch 0068, iter [01230, 01251], lr: 0.000511, loss: 3.0186
2022-10-08 16:21:49 - train: epoch 0068, iter [01240, 01251], lr: 0.000511, loss: 1.9844
2022-10-08 16:22:10 - train: epoch 0068, iter [01250, 01251], lr: 0.000510, loss: 2.8277
2022-10-08 16:22:13 - train: epoch 068, train_loss: 2.9209
2022-10-08 16:23:30 - eval: epoch: 068, acc1: 82.062%, acc5: 96.166%, test_loss: 0.7841, per_image_load_time: 1.163ms, per_image_inference_time: 1.444ms
2022-10-08 16:23:32 - until epoch: 068, best_acc1: 82.062%
2022-10-08 16:23:32 - epoch 069 lr: 0.000510
2022-10-08 16:23:59 - train: epoch 0069, iter [00010, 01251], lr: 0.000510, loss: 2.6469
2022-10-08 16:24:20 - train: epoch 0069, iter [00020, 01251], lr: 0.000510, loss: 2.6246
2022-10-08 16:24:41 - train: epoch 0069, iter [00030, 01251], lr: 0.000510, loss: 3.3437
2022-10-08 16:25:02 - train: epoch 0069, iter [00040, 01251], lr: 0.000509, loss: 2.7291
2022-10-08 16:25:23 - train: epoch 0069, iter [00050, 01251], lr: 0.000509, loss: 3.6020
2022-10-08 16:25:45 - train: epoch 0069, iter [00060, 01251], lr: 0.000509, loss: 1.7307
2022-10-08 16:26:06 - train: epoch 0069, iter [00070, 01251], lr: 0.000509, loss: 3.3620
2022-10-08 16:26:27 - train: epoch 0069, iter [00080, 01251], lr: 0.000508, loss: 2.9349
2022-10-08 16:26:48 - train: epoch 0069, iter [00090, 01251], lr: 0.000508, loss: 2.2648
2022-10-08 16:27:09 - train: epoch 0069, iter [00100, 01251], lr: 0.000508, loss: 3.2281
2022-10-08 16:27:30 - train: epoch 0069, iter [00110, 01251], lr: 0.000508, loss: 2.4683
2022-10-08 16:27:51 - train: epoch 0069, iter [00120, 01251], lr: 0.000508, loss: 3.0106
2022-10-08 16:28:12 - train: epoch 0069, iter [00130, 01251], lr: 0.000507, loss: 3.2866
2022-10-08 16:28:33 - train: epoch 0069, iter [00140, 01251], lr: 0.000507, loss: 3.3517
2022-10-08 16:28:55 - train: epoch 0069, iter [00150, 01251], lr: 0.000507, loss: 3.1200
2022-10-08 16:29:16 - train: epoch 0069, iter [00160, 01251], lr: 0.000507, loss: 2.8929
2022-10-08 16:29:37 - train: epoch 0069, iter [00170, 01251], lr: 0.000506, loss: 3.0336
2022-10-08 16:29:58 - train: epoch 0069, iter [00180, 01251], lr: 0.000506, loss: 2.5816
2022-10-08 16:30:19 - train: epoch 0069, iter [00190, 01251], lr: 0.000506, loss: 2.0314
2022-10-08 16:30:40 - train: epoch 0069, iter [00200, 01251], lr: 0.000506, loss: 2.5643
2022-10-08 16:31:01 - train: epoch 0069, iter [00210, 01251], lr: 0.000505, loss: 3.0097
2022-10-08 16:31:23 - train: epoch 0069, iter [00220, 01251], lr: 0.000505, loss: 2.4502
2022-10-08 16:31:44 - train: epoch 0069, iter [00230, 01251], lr: 0.000505, loss: 2.6781
2022-10-08 16:32:05 - train: epoch 0069, iter [00240, 01251], lr: 0.000505, loss: 2.4758
2022-10-08 16:32:26 - train: epoch 0069, iter [00250, 01251], lr: 0.000505, loss: 3.0262
2022-10-08 16:32:47 - train: epoch 0069, iter [00260, 01251], lr: 0.000504, loss: 2.9332
2022-10-08 16:33:08 - train: epoch 0069, iter [00270, 01251], lr: 0.000504, loss: 2.8027
2022-10-08 16:33:29 - train: epoch 0069, iter [00280, 01251], lr: 0.000504, loss: 3.2313
2022-10-08 16:33:50 - train: epoch 0069, iter [00290, 01251], lr: 0.000504, loss: 3.2666
2022-10-08 16:34:12 - train: epoch 0069, iter [00300, 01251], lr: 0.000503, loss: 2.5770
2022-10-08 16:34:33 - train: epoch 0069, iter [00310, 01251], lr: 0.000503, loss: 3.2586
2022-10-08 16:34:54 - train: epoch 0069, iter [00320, 01251], lr: 0.000503, loss: 2.6913
2022-10-08 16:35:15 - train: epoch 0069, iter [00330, 01251], lr: 0.000503, loss: 2.3104
2022-10-08 16:35:36 - train: epoch 0069, iter [00340, 01251], lr: 0.000503, loss: 2.4233
2022-10-08 16:35:57 - train: epoch 0069, iter [00350, 01251], lr: 0.000502, loss: 3.0089
2022-10-08 16:36:19 - train: epoch 0069, iter [00360, 01251], lr: 0.000502, loss: 3.1704
2022-10-08 16:36:40 - train: epoch 0069, iter [00370, 01251], lr: 0.000502, loss: 2.7617
2022-10-08 16:37:01 - train: epoch 0069, iter [00380, 01251], lr: 0.000502, loss: 2.6726
2022-10-08 16:37:22 - train: epoch 0069, iter [00390, 01251], lr: 0.000501, loss: 2.9402
2022-10-08 16:37:44 - train: epoch 0069, iter [00400, 01251], lr: 0.000501, loss: 2.8322
2022-10-08 16:38:05 - train: epoch 0069, iter [00410, 01251], lr: 0.000501, loss: 3.1883
2022-10-08 16:38:26 - train: epoch 0069, iter [00420, 01251], lr: 0.000501, loss: 3.2176
2022-10-08 16:38:47 - train: epoch 0069, iter [00430, 01251], lr: 0.000500, loss: 3.4172
2022-10-08 16:39:08 - train: epoch 0069, iter [00440, 01251], lr: 0.000500, loss: 3.3546
2022-10-08 16:39:30 - train: epoch 0069, iter [00450, 01251], lr: 0.000500, loss: 2.6185
2022-10-08 16:39:51 - train: epoch 0069, iter [00460, 01251], lr: 0.000500, loss: 2.8410
2022-10-08 16:40:12 - train: epoch 0069, iter [00470, 01251], lr: 0.000500, loss: 3.1369
2022-10-08 16:40:33 - train: epoch 0069, iter [00480, 01251], lr: 0.000499, loss: 2.3244
2022-10-08 16:40:54 - train: epoch 0069, iter [00490, 01251], lr: 0.000499, loss: 2.2892
2022-10-08 16:41:16 - train: epoch 0069, iter [00500, 01251], lr: 0.000499, loss: 2.9559
2022-10-08 16:41:37 - train: epoch 0069, iter [00510, 01251], lr: 0.000499, loss: 3.3254
2022-10-08 16:41:58 - train: epoch 0069, iter [00520, 01251], lr: 0.000498, loss: 3.0298
2022-10-08 16:42:19 - train: epoch 0069, iter [00530, 01251], lr: 0.000498, loss: 2.9001
2022-10-08 16:42:41 - train: epoch 0069, iter [00540, 01251], lr: 0.000498, loss: 3.2469
2022-10-08 16:43:02 - train: epoch 0069, iter [00550, 01251], lr: 0.000498, loss: 2.5914
2022-10-08 16:43:23 - train: epoch 0069, iter [00560, 01251], lr: 0.000497, loss: 2.7162
2022-10-08 16:43:44 - train: epoch 0069, iter [00570, 01251], lr: 0.000497, loss: 3.1163
2022-10-08 16:44:05 - train: epoch 0069, iter [00580, 01251], lr: 0.000497, loss: 2.2698
2022-10-08 16:44:27 - train: epoch 0069, iter [00590, 01251], lr: 0.000497, loss: 2.7624
2022-10-08 16:44:48 - train: epoch 0069, iter [00600, 01251], lr: 0.000497, loss: 3.1850
2022-10-08 16:45:09 - train: epoch 0069, iter [00610, 01251], lr: 0.000496, loss: 2.4155
2022-10-08 16:45:30 - train: epoch 0069, iter [00620, 01251], lr: 0.000496, loss: 3.1912
2022-10-08 16:45:51 - train: epoch 0069, iter [00630, 01251], lr: 0.000496, loss: 2.3832
2022-10-08 16:46:13 - train: epoch 0069, iter [00640, 01251], lr: 0.000496, loss: 2.7812
2022-10-08 16:46:34 - train: epoch 0069, iter [00650, 01251], lr: 0.000495, loss: 3.1302
2022-10-08 16:46:55 - train: epoch 0069, iter [00660, 01251], lr: 0.000495, loss: 2.5241
2022-10-08 16:47:16 - train: epoch 0069, iter [00670, 01251], lr: 0.000495, loss: 3.2875
2022-10-08 16:47:37 - train: epoch 0069, iter [00680, 01251], lr: 0.000495, loss: 2.9587
2022-10-08 16:47:58 - train: epoch 0069, iter [00690, 01251], lr: 0.000495, loss: 3.1383
2022-10-08 16:48:20 - train: epoch 0069, iter [00700, 01251], lr: 0.000494, loss: 2.6924
2022-10-08 16:48:41 - train: epoch 0069, iter [00710, 01251], lr: 0.000494, loss: 2.7881
2022-10-08 16:49:02 - train: epoch 0069, iter [00720, 01251], lr: 0.000494, loss: 2.0711
2022-10-08 16:49:23 - train: epoch 0069, iter [00730, 01251], lr: 0.000494, loss: 2.6639
2022-10-08 16:49:44 - train: epoch 0069, iter [00740, 01251], lr: 0.000493, loss: 2.1304
2022-10-08 16:50:05 - train: epoch 0069, iter [00750, 01251], lr: 0.000493, loss: 3.2836
2022-10-08 16:50:27 - train: epoch 0069, iter [00760, 01251], lr: 0.000493, loss: 3.3241
2022-10-08 16:50:48 - train: epoch 0069, iter [00770, 01251], lr: 0.000493, loss: 2.8088
2022-10-08 16:51:09 - train: epoch 0069, iter [00780, 01251], lr: 0.000492, loss: 3.4842
2022-10-08 16:51:30 - train: epoch 0069, iter [00790, 01251], lr: 0.000492, loss: 3.2394
2022-10-08 16:51:51 - train: epoch 0069, iter [00800, 01251], lr: 0.000492, loss: 3.3109
2022-10-08 16:52:12 - train: epoch 0069, iter [00810, 01251], lr: 0.000492, loss: 3.2842
2022-10-08 16:52:33 - train: epoch 0069, iter [00820, 01251], lr: 0.000492, loss: 2.6084
2022-10-08 16:52:55 - train: epoch 0069, iter [00830, 01251], lr: 0.000491, loss: 3.0418
2022-10-08 16:53:16 - train: epoch 0069, iter [00840, 01251], lr: 0.000491, loss: 2.8317
2022-10-08 16:53:37 - train: epoch 0069, iter [00850, 01251], lr: 0.000491, loss: 2.4501
2022-10-08 16:53:58 - train: epoch 0069, iter [00860, 01251], lr: 0.000491, loss: 3.0845
2022-10-08 16:54:19 - train: epoch 0069, iter [00870, 01251], lr: 0.000490, loss: 3.0062
2022-10-08 16:54:40 - train: epoch 0069, iter [00880, 01251], lr: 0.000490, loss: 2.6476
2022-10-08 16:55:01 - train: epoch 0069, iter [00890, 01251], lr: 0.000490, loss: 3.0488
2022-10-08 16:55:22 - train: epoch 0069, iter [00900, 01251], lr: 0.000490, loss: 2.7326
2022-10-08 16:55:43 - train: epoch 0069, iter [00910, 01251], lr: 0.000490, loss: 3.1887
2022-10-08 16:56:04 - train: epoch 0069, iter [00920, 01251], lr: 0.000489, loss: 3.2616
2022-10-08 16:56:26 - train: epoch 0069, iter [00930, 01251], lr: 0.000489, loss: 3.2049
2022-10-08 16:56:47 - train: epoch 0069, iter [00940, 01251], lr: 0.000489, loss: 3.3326
2022-10-08 16:57:08 - train: epoch 0069, iter [00950, 01251], lr: 0.000489, loss: 2.9075
2022-10-08 16:57:29 - train: epoch 0069, iter [00960, 01251], lr: 0.000488, loss: 2.8853
2022-10-08 16:57:50 - train: epoch 0069, iter [00970, 01251], lr: 0.000488, loss: 2.3801
2022-10-08 16:58:11 - train: epoch 0069, iter [00980, 01251], lr: 0.000488, loss: 3.0793
2022-10-08 16:58:32 - train: epoch 0069, iter [00990, 01251], lr: 0.000488, loss: 2.8740
2022-10-08 16:58:53 - train: epoch 0069, iter [01000, 01251], lr: 0.000487, loss: 3.1299
2022-10-08 16:59:15 - train: epoch 0069, iter [01010, 01251], lr: 0.000487, loss: 2.8778
2022-10-08 16:59:36 - train: epoch 0069, iter [01020, 01251], lr: 0.000487, loss: 2.7958
2022-10-08 16:59:57 - train: epoch 0069, iter [01030, 01251], lr: 0.000487, loss: 2.5454
2022-10-08 17:00:18 - train: epoch 0069, iter [01040, 01251], lr: 0.000487, loss: 3.0426
2022-10-08 17:00:39 - train: epoch 0069, iter [01050, 01251], lr: 0.000486, loss: 2.4605
2022-10-08 17:01:00 - train: epoch 0069, iter [01060, 01251], lr: 0.000486, loss: 3.1242
2022-10-08 17:01:21 - train: epoch 0069, iter [01070, 01251], lr: 0.000486, loss: 3.1303
2022-10-08 17:01:42 - train: epoch 0069, iter [01080, 01251], lr: 0.000486, loss: 3.2986
2022-10-08 17:02:04 - train: epoch 0069, iter [01090, 01251], lr: 0.000485, loss: 2.6285
2022-10-08 17:02:25 - train: epoch 0069, iter [01100, 01251], lr: 0.000485, loss: 3.2243
2022-10-08 17:02:46 - train: epoch 0069, iter [01110, 01251], lr: 0.000485, loss: 3.0529
2022-10-08 17:03:07 - train: epoch 0069, iter [01120, 01251], lr: 0.000485, loss: 3.3201
2022-10-08 17:03:28 - train: epoch 0069, iter [01130, 01251], lr: 0.000485, loss: 2.8623
2022-10-08 17:03:50 - train: epoch 0069, iter [01140, 01251], lr: 0.000484, loss: 2.5967
2022-10-08 17:04:11 - train: epoch 0069, iter [01150, 01251], lr: 0.000484, loss: 3.2783
2022-10-08 17:04:32 - train: epoch 0069, iter [01160, 01251], lr: 0.000484, loss: 2.4227
2022-10-08 17:04:53 - train: epoch 0069, iter [01170, 01251], lr: 0.000484, loss: 3.0879
2022-10-08 17:05:14 - train: epoch 0069, iter [01180, 01251], lr: 0.000483, loss: 2.5588
2022-10-08 17:05:35 - train: epoch 0069, iter [01190, 01251], lr: 0.000483, loss: 2.6694
2022-10-08 17:05:56 - train: epoch 0069, iter [01200, 01251], lr: 0.000483, loss: 3.0703
2022-10-08 17:06:18 - train: epoch 0069, iter [01210, 01251], lr: 0.000483, loss: 2.4487
2022-10-08 17:06:39 - train: epoch 0069, iter [01220, 01251], lr: 0.000482, loss: 2.6253
2022-10-08 17:07:00 - train: epoch 0069, iter [01230, 01251], lr: 0.000482, loss: 3.0601
2022-10-08 17:07:21 - train: epoch 0069, iter [01240, 01251], lr: 0.000482, loss: 3.1722
2022-10-08 17:07:42 - train: epoch 0069, iter [01250, 01251], lr: 0.000482, loss: 2.6467
2022-10-08 17:07:46 - train: epoch 069, train_loss: 2.9176
2022-10-08 17:09:03 - eval: epoch: 069, acc1: 82.022%, acc5: 96.162%, test_loss: 0.8087, per_image_load_time: 0.394ms, per_image_inference_time: 1.426ms
2022-10-08 17:09:04 - until epoch: 069, best_acc1: 82.062%
2022-10-08 17:09:04 - epoch 070 lr: 0.000482
2022-10-08 17:09:31 - train: epoch 0070, iter [00010, 01251], lr: 0.000482, loss: 2.8292
2022-10-08 17:09:52 - train: epoch 0070, iter [00020, 01251], lr: 0.000481, loss: 2.9438
2022-10-08 17:10:14 - train: epoch 0070, iter [00030, 01251], lr: 0.000481, loss: 2.7545
2022-10-08 17:10:35 - train: epoch 0070, iter [00040, 01251], lr: 0.000481, loss: 3.1886
2022-10-08 17:10:56 - train: epoch 0070, iter [00050, 01251], lr: 0.000481, loss: 3.2609
2022-10-08 17:11:18 - train: epoch 0070, iter [00060, 01251], lr: 0.000480, loss: 3.1149
2022-10-08 17:11:39 - train: epoch 0070, iter [00070, 01251], lr: 0.000480, loss: 2.2929
2022-10-08 17:12:00 - train: epoch 0070, iter [00080, 01251], lr: 0.000480, loss: 3.2223
2022-10-08 17:12:21 - train: epoch 0070, iter [00090, 01251], lr: 0.000480, loss: 2.7028
2022-10-08 17:12:42 - train: epoch 0070, iter [00100, 01251], lr: 0.000480, loss: 2.8164
2022-10-08 17:13:03 - train: epoch 0070, iter [00110, 01251], lr: 0.000479, loss: 2.6853
2022-10-08 17:13:25 - train: epoch 0070, iter [00120, 01251], lr: 0.000479, loss: 3.0313
2022-10-08 17:13:46 - train: epoch 0070, iter [00130, 01251], lr: 0.000479, loss: 2.2587
2022-10-08 17:14:07 - train: epoch 0070, iter [00140, 01251], lr: 0.000479, loss: 2.4808
2022-10-08 17:14:28 - train: epoch 0070, iter [00150, 01251], lr: 0.000478, loss: 2.9283
2022-10-08 17:14:50 - train: epoch 0070, iter [00160, 01251], lr: 0.000478, loss: 3.2118
2022-10-08 17:15:11 - train: epoch 0070, iter [00170, 01251], lr: 0.000478, loss: 3.1985
2022-10-08 17:15:32 - train: epoch 0070, iter [00180, 01251], lr: 0.000478, loss: 2.1771
2022-10-08 17:15:53 - train: epoch 0070, iter [00190, 01251], lr: 0.000478, loss: 2.3935
2022-10-08 17:16:15 - train: epoch 0070, iter [00200, 01251], lr: 0.000477, loss: 3.1298
2022-10-08 17:16:36 - train: epoch 0070, iter [00210, 01251], lr: 0.000477, loss: 2.7156
2022-10-08 17:16:57 - train: epoch 0070, iter [00220, 01251], lr: 0.000477, loss: 2.7642
2022-10-08 17:17:18 - train: epoch 0070, iter [00230, 01251], lr: 0.000477, loss: 3.1637
2022-10-08 17:17:40 - train: epoch 0070, iter [00240, 01251], lr: 0.000476, loss: 2.8391
2022-10-08 17:18:01 - train: epoch 0070, iter [00250, 01251], lr: 0.000476, loss: 3.3395
2022-10-08 17:18:22 - train: epoch 0070, iter [00260, 01251], lr: 0.000476, loss: 3.1985
2022-10-08 17:18:43 - train: epoch 0070, iter [00270, 01251], lr: 0.000476, loss: 2.5598
2022-10-08 17:19:04 - train: epoch 0070, iter [00280, 01251], lr: 0.000475, loss: 2.7026
2022-10-08 17:19:26 - train: epoch 0070, iter [00290, 01251], lr: 0.000475, loss: 2.5364
2022-10-08 17:19:47 - train: epoch 0070, iter [00300, 01251], lr: 0.000475, loss: 2.3312
2022-10-08 17:20:08 - train: epoch 0070, iter [00310, 01251], lr: 0.000475, loss: 2.9262
2022-10-08 17:20:29 - train: epoch 0070, iter [00320, 01251], lr: 0.000475, loss: 3.2514
2022-10-08 17:20:50 - train: epoch 0070, iter [00330, 01251], lr: 0.000474, loss: 2.5841
2022-10-08 17:21:12 - train: epoch 0070, iter [00340, 01251], lr: 0.000474, loss: 3.0369
2022-10-08 17:21:33 - train: epoch 0070, iter [00350, 01251], lr: 0.000474, loss: 3.3026
2022-10-08 17:21:54 - train: epoch 0070, iter [00360, 01251], lr: 0.000474, loss: 2.7246
2022-10-08 17:22:15 - train: epoch 0070, iter [00370, 01251], lr: 0.000473, loss: 2.6387
2022-10-08 17:22:36 - train: epoch 0070, iter [00380, 01251], lr: 0.000473, loss: 3.1292
2022-10-08 17:22:58 - train: epoch 0070, iter [00390, 01251], lr: 0.000473, loss: 2.9171
2022-10-08 17:23:19 - train: epoch 0070, iter [00400, 01251], lr: 0.000473, loss: 3.0448
2022-10-08 17:23:40 - train: epoch 0070, iter [00410, 01251], lr: 0.000473, loss: 3.0346
2022-10-08 17:24:01 - train: epoch 0070, iter [00420, 01251], lr: 0.000472, loss: 2.9238
2022-10-08 17:24:22 - train: epoch 0070, iter [00430, 01251], lr: 0.000472, loss: 2.3315
2022-10-08 17:24:44 - train: epoch 0070, iter [00440, 01251], lr: 0.000472, loss: 3.3195
2022-10-08 17:25:05 - train: epoch 0070, iter [00450, 01251], lr: 0.000472, loss: 3.2220
2022-10-08 17:25:26 - train: epoch 0070, iter [00460, 01251], lr: 0.000471, loss: 2.7591
2022-10-08 17:25:47 - train: epoch 0070, iter [00470, 01251], lr: 0.000471, loss: 3.0013
2022-10-08 17:26:08 - train: epoch 0070, iter [00480, 01251], lr: 0.000471, loss: 2.7258
2022-10-08 17:26:29 - train: epoch 0070, iter [00490, 01251], lr: 0.000471, loss: 2.8124
2022-10-08 17:26:51 - train: epoch 0070, iter [00500, 01251], lr: 0.000471, loss: 2.9163
2022-10-08 17:27:12 - train: epoch 0070, iter [00510, 01251], lr: 0.000470, loss: 3.1306
2022-10-08 17:27:33 - train: epoch 0070, iter [00520, 01251], lr: 0.000470, loss: 3.1391
2022-10-08 17:27:54 - train: epoch 0070, iter [00530, 01251], lr: 0.000470, loss: 3.0859
2022-10-08 17:28:15 - train: epoch 0070, iter [00540, 01251], lr: 0.000470, loss: 2.9976
2022-10-08 17:28:37 - train: epoch 0070, iter [00550, 01251], lr: 0.000469, loss: 2.3749
2022-10-08 17:28:58 - train: epoch 0070, iter [00560, 01251], lr: 0.000469, loss: 3.1764
2022-10-08 17:29:19 - train: epoch 0070, iter [00570, 01251], lr: 0.000469, loss: 2.9239
2022-10-08 17:29:40 - train: epoch 0070, iter [00580, 01251], lr: 0.000469, loss: 2.6675
2022-10-08 17:30:01 - train: epoch 0070, iter [00590, 01251], lr: 0.000469, loss: 2.8977
2022-10-08 17:30:23 - train: epoch 0070, iter [00600, 01251], lr: 0.000468, loss: 3.1462
2022-10-08 17:30:44 - train: epoch 0070, iter [00610, 01251], lr: 0.000468, loss: 3.0000
2022-10-08 17:31:05 - train: epoch 0070, iter [00620, 01251], lr: 0.000468, loss: 3.1579
2022-10-08 17:31:26 - train: epoch 0070, iter [00630, 01251], lr: 0.000468, loss: 3.2748
2022-10-08 17:31:47 - train: epoch 0070, iter [00640, 01251], lr: 0.000467, loss: 2.6070
2022-10-08 17:32:08 - train: epoch 0070, iter [00650, 01251], lr: 0.000467, loss: 2.7723
2022-10-08 17:32:30 - train: epoch 0070, iter [00660, 01251], lr: 0.000467, loss: 3.1710
2022-10-08 17:32:51 - train: epoch 0070, iter [00670, 01251], lr: 0.000467, loss: 2.5653
2022-10-08 17:33:12 - train: epoch 0070, iter [00680, 01251], lr: 0.000467, loss: 3.0420
2022-10-08 17:33:33 - train: epoch 0070, iter [00690, 01251], lr: 0.000466, loss: 3.2659
2022-10-08 17:33:55 - train: epoch 0070, iter [00700, 01251], lr: 0.000466, loss: 2.6125
2022-10-08 17:34:16 - train: epoch 0070, iter [00710, 01251], lr: 0.000466, loss: 3.0027
2022-10-08 17:34:37 - train: epoch 0070, iter [00720, 01251], lr: 0.000466, loss: 2.3716
2022-10-08 17:34:58 - train: epoch 0070, iter [00730, 01251], lr: 0.000465, loss: 2.5527
2022-10-08 17:35:19 - train: epoch 0070, iter [00740, 01251], lr: 0.000465, loss: 2.8749
2022-10-08 17:35:41 - train: epoch 0070, iter [00750, 01251], lr: 0.000465, loss: 2.8341
2022-10-08 17:36:02 - train: epoch 0070, iter [00760, 01251], lr: 0.000465, loss: 2.7474
2022-10-08 17:36:23 - train: epoch 0070, iter [00770, 01251], lr: 0.000465, loss: 3.0093
2022-10-08 17:36:44 - train: epoch 0070, iter [00780, 01251], lr: 0.000464, loss: 2.8712
2022-10-08 17:37:05 - train: epoch 0070, iter [00790, 01251], lr: 0.000464, loss: 2.6300
2022-10-08 17:37:27 - train: epoch 0070, iter [00800, 01251], lr: 0.000464, loss: 2.6823
2022-10-08 17:37:48 - train: epoch 0070, iter [00810, 01251], lr: 0.000464, loss: 3.3462
2022-10-08 17:38:09 - train: epoch 0070, iter [00820, 01251], lr: 0.000463, loss: 2.5359
2022-10-08 17:38:30 - train: epoch 0070, iter [00830, 01251], lr: 0.000463, loss: 2.1870
2022-10-08 17:38:51 - train: epoch 0070, iter [00840, 01251], lr: 0.000463, loss: 3.1124
2022-10-08 17:39:13 - train: epoch 0070, iter [00850, 01251], lr: 0.000463, loss: 3.0774
2022-10-08 17:39:34 - train: epoch 0070, iter [00860, 01251], lr: 0.000463, loss: 2.7685
2022-10-08 17:39:55 - train: epoch 0070, iter [00870, 01251], lr: 0.000462, loss: 2.7613
2022-10-08 17:40:16 - train: epoch 0070, iter [00880, 01251], lr: 0.000462, loss: 2.5972
2022-10-08 17:40:38 - train: epoch 0070, iter [00890, 01251], lr: 0.000462, loss: 2.9190
2022-10-08 17:40:59 - train: epoch 0070, iter [00900, 01251], lr: 0.000462, loss: 2.8308
2022-10-08 17:41:20 - train: epoch 0070, iter [00910, 01251], lr: 0.000461, loss: 3.0687
2022-10-08 17:41:41 - train: epoch 0070, iter [00920, 01251], lr: 0.000461, loss: 3.1448
2022-10-08 17:42:03 - train: epoch 0070, iter [00930, 01251], lr: 0.000461, loss: 3.0084
2022-10-08 17:42:24 - train: epoch 0070, iter [00940, 01251], lr: 0.000461, loss: 2.9807
2022-10-08 17:42:45 - train: epoch 0070, iter [00950, 01251], lr: 0.000461, loss: 3.2520
2022-10-08 17:43:06 - train: epoch 0070, iter [00960, 01251], lr: 0.000460, loss: 3.2139
2022-10-08 17:43:28 - train: epoch 0070, iter [00970, 01251], lr: 0.000460, loss: 3.1402
2022-10-08 17:43:49 - train: epoch 0070, iter [00980, 01251], lr: 0.000460, loss: 3.5293
2022-10-08 17:44:10 - train: epoch 0070, iter [00990, 01251], lr: 0.000460, loss: 2.8902
2022-10-08 17:44:31 - train: epoch 0070, iter [01000, 01251], lr: 0.000459, loss: 3.1313
2022-10-08 17:44:53 - train: epoch 0070, iter [01010, 01251], lr: 0.000459, loss: 3.1294
2022-10-08 17:45:14 - train: epoch 0070, iter [01020, 01251], lr: 0.000459, loss: 2.4310
2022-10-08 17:45:35 - train: epoch 0070, iter [01030, 01251], lr: 0.000459, loss: 2.6351
2022-10-08 17:45:56 - train: epoch 0070, iter [01040, 01251], lr: 0.000459, loss: 2.8797
2022-10-08 17:46:17 - train: epoch 0070, iter [01050, 01251], lr: 0.000458, loss: 2.5614
2022-10-08 17:46:38 - train: epoch 0070, iter [01060, 01251], lr: 0.000458, loss: 2.6603
2022-10-08 17:47:00 - train: epoch 0070, iter [01070, 01251], lr: 0.000458, loss: 2.5722
2022-10-08 17:47:21 - train: epoch 0070, iter [01080, 01251], lr: 0.000458, loss: 2.4780
2022-10-08 17:47:42 - train: epoch 0070, iter [01090, 01251], lr: 0.000457, loss: 2.6737
2022-10-08 17:48:03 - train: epoch 0070, iter [01100, 01251], lr: 0.000457, loss: 3.1571
2022-10-08 17:48:24 - train: epoch 0070, iter [01110, 01251], lr: 0.000457, loss: 3.0969
2022-10-08 17:48:45 - train: epoch 0070, iter [01120, 01251], lr: 0.000457, loss: 3.2105
2022-10-08 17:49:06 - train: epoch 0070, iter [01130, 01251], lr: 0.000457, loss: 2.8869
2022-10-08 17:49:27 - train: epoch 0070, iter [01140, 01251], lr: 0.000456, loss: 2.6799
2022-10-08 17:49:48 - train: epoch 0070, iter [01150, 01251], lr: 0.000456, loss: 3.0415
2022-10-08 17:50:09 - train: epoch 0070, iter [01160, 01251], lr: 0.000456, loss: 3.2201
2022-10-08 17:50:30 - train: epoch 0070, iter [01170, 01251], lr: 0.000456, loss: 2.7670
2022-10-08 17:50:51 - train: epoch 0070, iter [01180, 01251], lr: 0.000455, loss: 2.8662
2022-10-08 17:51:12 - train: epoch 0070, iter [01190, 01251], lr: 0.000455, loss: 2.7668
2022-10-08 17:51:33 - train: epoch 0070, iter [01200, 01251], lr: 0.000455, loss: 2.8542
2022-10-08 17:51:54 - train: epoch 0070, iter [01210, 01251], lr: 0.000455, loss: 2.6170
2022-10-08 17:52:15 - train: epoch 0070, iter [01220, 01251], lr: 0.000455, loss: 3.2253
2022-10-08 17:52:36 - train: epoch 0070, iter [01230, 01251], lr: 0.000454, loss: 2.7960
2022-10-08 17:52:57 - train: epoch 0070, iter [01240, 01251], lr: 0.000454, loss: 3.1959
2022-10-08 17:53:18 - train: epoch 0070, iter [01250, 01251], lr: 0.000454, loss: 3.3753
2022-10-08 17:53:21 - train: epoch 070, train_loss: 2.9120
2022-10-08 17:54:38 - eval: epoch: 070, acc1: 82.244%, acc5: 96.214%, test_loss: 0.7705, per_image_load_time: 0.557ms, per_image_inference_time: 1.410ms
2022-10-08 17:54:39 - until epoch: 070, best_acc1: 82.244%
2022-10-08 17:54:39 - epoch 071 lr: 0.000454
2022-10-08 17:55:06 - train: epoch 0071, iter [00010, 01251], lr: 0.000454, loss: 3.2061
2022-10-08 17:55:27 - train: epoch 0071, iter [00020, 01251], lr: 0.000453, loss: 2.6240
2022-10-08 17:55:49 - train: epoch 0071, iter [00030, 01251], lr: 0.000453, loss: 3.0190
2022-10-08 17:56:10 - train: epoch 0071, iter [00040, 01251], lr: 0.000453, loss: 3.2793
2022-10-08 17:56:31 - train: epoch 0071, iter [00050, 01251], lr: 0.000453, loss: 3.0091
2022-10-08 17:56:52 - train: epoch 0071, iter [00060, 01251], lr: 0.000452, loss: 2.9284
2022-10-08 17:57:13 - train: epoch 0071, iter [00070, 01251], lr: 0.000452, loss: 2.7849
2022-10-08 17:57:35 - train: epoch 0071, iter [00080, 01251], lr: 0.000452, loss: 3.2927
2022-10-08 17:57:56 - train: epoch 0071, iter [00090, 01251], lr: 0.000452, loss: 2.9088
2022-10-08 17:58:17 - train: epoch 0071, iter [00100, 01251], lr: 0.000452, loss: 2.5855
2022-10-08 17:58:38 - train: epoch 0071, iter [00110, 01251], lr: 0.000451, loss: 2.4467
2022-10-08 17:58:59 - train: epoch 0071, iter [00120, 01251], lr: 0.000451, loss: 3.0691
2022-10-08 17:59:21 - train: epoch 0071, iter [00130, 01251], lr: 0.000451, loss: 2.4802
2022-10-08 17:59:42 - train: epoch 0071, iter [00140, 01251], lr: 0.000451, loss: 2.3193
2022-10-08 18:00:03 - train: epoch 0071, iter [00150, 01251], lr: 0.000451, loss: 3.2903
2022-10-08 18:00:24 - train: epoch 0071, iter [00160, 01251], lr: 0.000450, loss: 2.7356
2022-10-08 18:00:46 - train: epoch 0071, iter [00170, 01251], lr: 0.000450, loss: 3.0129
2022-10-08 18:01:07 - train: epoch 0071, iter [00180, 01251], lr: 0.000450, loss: 3.4709
2022-10-08 18:01:28 - train: epoch 0071, iter [00190, 01251], lr: 0.000450, loss: 2.4882
2022-10-08 18:01:49 - train: epoch 0071, iter [00200, 01251], lr: 0.000449, loss: 2.3723
2022-10-08 18:02:10 - train: epoch 0071, iter [00210, 01251], lr: 0.000449, loss: 3.3202
2022-10-08 18:02:31 - train: epoch 0071, iter [00220, 01251], lr: 0.000449, loss: 3.1556
2022-10-08 18:02:52 - train: epoch 0071, iter [00230, 01251], lr: 0.000449, loss: 3.2256
2022-10-08 18:03:13 - train: epoch 0071, iter [00240, 01251], lr: 0.000449, loss: 3.1307
2022-10-08 18:03:35 - train: epoch 0071, iter [00250, 01251], lr: 0.000448, loss: 2.9703
2022-10-08 18:03:56 - train: epoch 0071, iter [00260, 01251], lr: 0.000448, loss: 2.3380
2022-10-08 18:04:17 - train: epoch 0071, iter [00270, 01251], lr: 0.000448, loss: 3.0361
2022-10-08 18:04:38 - train: epoch 0071, iter [00280, 01251], lr: 0.000448, loss: 2.7058
2022-10-08 18:04:59 - train: epoch 0071, iter [00290, 01251], lr: 0.000447, loss: 2.9483
2022-10-08 18:05:20 - train: epoch 0071, iter [00300, 01251], lr: 0.000447, loss: 2.3672
2022-10-08 18:05:41 - train: epoch 0071, iter [00310, 01251], lr: 0.000447, loss: 2.4502
2022-10-08 18:06:02 - train: epoch 0071, iter [00320, 01251], lr: 0.000447, loss: 2.5332
2022-10-08 18:06:23 - train: epoch 0071, iter [00330, 01251], lr: 0.000447, loss: 2.7117
2022-10-08 18:06:44 - train: epoch 0071, iter [00340, 01251], lr: 0.000446, loss: 2.3181
2022-10-08 18:07:05 - train: epoch 0071, iter [00350, 01251], lr: 0.000446, loss: 3.0105
2022-10-08 18:07:26 - train: epoch 0071, iter [00360, 01251], lr: 0.000446, loss: 2.4343
2022-10-08 18:07:47 - train: epoch 0071, iter [00370, 01251], lr: 0.000446, loss: 2.9419
2022-10-08 18:08:08 - train: epoch 0071, iter [00380, 01251], lr: 0.000445, loss: 2.6640
2022-10-08 18:08:30 - train: epoch 0071, iter [00390, 01251], lr: 0.000445, loss: 2.6576
2022-10-08 18:08:51 - train: epoch 0071, iter [00400, 01251], lr: 0.000445, loss: 2.5356
2022-10-08 18:09:12 - train: epoch 0071, iter [00410, 01251], lr: 0.000445, loss: 2.9392
2022-10-08 18:09:33 - train: epoch 0071, iter [00420, 01251], lr: 0.000445, loss: 3.2960
2022-10-08 18:09:54 - train: epoch 0071, iter [00430, 01251], lr: 0.000444, loss: 1.8486
2022-10-08 18:10:15 - train: epoch 0071, iter [00440, 01251], lr: 0.000444, loss: 2.8551
2022-10-08 18:10:36 - train: epoch 0071, iter [00450, 01251], lr: 0.000444, loss: 3.2900
2022-10-08 18:10:57 - train: epoch 0071, iter [00460, 01251], lr: 0.000444, loss: 3.1369
2022-10-08 18:11:18 - train: epoch 0071, iter [00470, 01251], lr: 0.000443, loss: 3.1583
2022-10-08 18:11:39 - train: epoch 0071, iter [00480, 01251], lr: 0.000443, loss: 2.8885
2022-10-08 18:12:00 - train: epoch 0071, iter [00490, 01251], lr: 0.000443, loss: 3.2838
2022-10-08 18:12:21 - train: epoch 0071, iter [00500, 01251], lr: 0.000443, loss: 2.9511
2022-10-08 18:12:42 - train: epoch 0071, iter [00510, 01251], lr: 0.000443, loss: 3.2411
2022-10-08 18:13:03 - train: epoch 0071, iter [00520, 01251], lr: 0.000442, loss: 2.9433
2022-10-08 18:13:24 - train: epoch 0071, iter [00530, 01251], lr: 0.000442, loss: 2.7103
2022-10-08 18:13:45 - train: epoch 0071, iter [00540, 01251], lr: 0.000442, loss: 2.9313
2022-10-08 18:14:06 - train: epoch 0071, iter [00550, 01251], lr: 0.000442, loss: 2.5380
2022-10-08 18:14:27 - train: epoch 0071, iter [00560, 01251], lr: 0.000441, loss: 3.1525
2022-10-08 18:14:48 - train: epoch 0071, iter [00570, 01251], lr: 0.000441, loss: 3.0119
2022-10-08 18:15:10 - train: epoch 0071, iter [00580, 01251], lr: 0.000441, loss: 3.0767
2022-10-08 18:15:31 - train: epoch 0071, iter [00590, 01251], lr: 0.000441, loss: 3.0129
2022-10-08 18:15:52 - train: epoch 0071, iter [00600, 01251], lr: 0.000441, loss: 2.6540
2022-10-08 18:16:13 - train: epoch 0071, iter [00610, 01251], lr: 0.000440, loss: 2.6899
2022-10-08 18:16:34 - train: epoch 0071, iter [00620, 01251], lr: 0.000440, loss: 2.4384
2022-10-08 18:16:55 - train: epoch 0071, iter [00630, 01251], lr: 0.000440, loss: 2.7268
2022-10-08 18:17:16 - train: epoch 0071, iter [00640, 01251], lr: 0.000440, loss: 3.1297
2022-10-08 18:17:37 - train: epoch 0071, iter [00650, 01251], lr: 0.000440, loss: 2.7292
2022-10-08 18:17:58 - train: epoch 0071, iter [00660, 01251], lr: 0.000439, loss: 3.0285
2022-10-08 18:18:19 - train: epoch 0071, iter [00670, 01251], lr: 0.000439, loss: 3.2408
2022-10-08 18:18:40 - train: epoch 0071, iter [00680, 01251], lr: 0.000439, loss: 2.9384
2022-10-08 18:19:01 - train: epoch 0071, iter [00690, 01251], lr: 0.000439, loss: 3.3060
2022-10-08 18:19:22 - train: epoch 0071, iter [00700, 01251], lr: 0.000438, loss: 3.2607
2022-10-08 18:19:43 - train: epoch 0071, iter [00710, 01251], lr: 0.000438, loss: 3.0741
2022-10-08 18:20:04 - train: epoch 0071, iter [00720, 01251], lr: 0.000438, loss: 3.0777
2022-10-08 18:20:25 - train: epoch 0071, iter [00730, 01251], lr: 0.000438, loss: 2.9881
2022-10-08 18:20:46 - train: epoch 0071, iter [00740, 01251], lr: 0.000438, loss: 3.2126
2022-10-08 18:21:07 - train: epoch 0071, iter [00750, 01251], lr: 0.000437, loss: 2.6382
2022-10-08 18:21:28 - train: epoch 0071, iter [00760, 01251], lr: 0.000437, loss: 3.3032
2022-10-08 18:21:49 - train: epoch 0071, iter [00770, 01251], lr: 0.000437, loss: 3.4257
2022-10-08 18:22:10 - train: epoch 0071, iter [00780, 01251], lr: 0.000437, loss: 2.6278
2022-10-08 18:22:31 - train: epoch 0071, iter [00790, 01251], lr: 0.000436, loss: 3.2420
2022-10-08 18:22:52 - train: epoch 0071, iter [00800, 01251], lr: 0.000436, loss: 2.8423
2022-10-08 18:23:13 - train: epoch 0071, iter [00810, 01251], lr: 0.000436, loss: 3.4227
2022-10-08 18:23:34 - train: epoch 0071, iter [00820, 01251], lr: 0.000436, loss: 2.9251
2022-10-08 18:23:55 - train: epoch 0071, iter [00830, 01251], lr: 0.000436, loss: 2.4072
2022-10-08 18:24:16 - train: epoch 0071, iter [00840, 01251], lr: 0.000435, loss: 3.3504
2022-10-08 18:24:37 - train: epoch 0071, iter [00850, 01251], lr: 0.000435, loss: 2.9827
2022-10-08 18:24:58 - train: epoch 0071, iter [00860, 01251], lr: 0.000435, loss: 2.4191
2022-10-08 18:25:19 - train: epoch 0071, iter [00870, 01251], lr: 0.000435, loss: 3.3303
2022-10-08 18:25:40 - train: epoch 0071, iter [00880, 01251], lr: 0.000435, loss: 3.1577
2022-10-08 18:26:01 - train: epoch 0071, iter [00890, 01251], lr: 0.000434, loss: 2.3951
2022-10-08 18:26:22 - train: epoch 0071, iter [00900, 01251], lr: 0.000434, loss: 2.9214
2022-10-08 18:26:43 - train: epoch 0071, iter [00910, 01251], lr: 0.000434, loss: 3.3481
2022-10-08 18:27:04 - train: epoch 0071, iter [00920, 01251], lr: 0.000434, loss: 2.6442
2022-10-08 18:27:25 - train: epoch 0071, iter [00930, 01251], lr: 0.000433, loss: 2.9030
2022-10-08 18:27:46 - train: epoch 0071, iter [00940, 01251], lr: 0.000433, loss: 3.1622
2022-10-08 18:28:08 - train: epoch 0071, iter [00950, 01251], lr: 0.000433, loss: 2.9043
2022-10-08 18:28:29 - train: epoch 0071, iter [00960, 01251], lr: 0.000433, loss: 3.3506
2022-10-08 18:28:50 - train: epoch 0071, iter [00970, 01251], lr: 0.000433, loss: 2.9985
2022-10-08 18:29:11 - train: epoch 0071, iter [00980, 01251], lr: 0.000432, loss: 2.9289
2022-10-08 18:29:32 - train: epoch 0071, iter [00990, 01251], lr: 0.000432, loss: 2.9477
2022-10-08 18:29:53 - train: epoch 0071, iter [01000, 01251], lr: 0.000432, loss: 3.3057
2022-10-08 18:30:14 - train: epoch 0071, iter [01010, 01251], lr: 0.000432, loss: 2.7811
2022-10-08 18:30:35 - train: epoch 0071, iter [01020, 01251], lr: 0.000431, loss: 2.8511
2022-10-08 18:30:56 - train: epoch 0071, iter [01030, 01251], lr: 0.000431, loss: 2.6438
2022-10-08 18:31:17 - train: epoch 0071, iter [01040, 01251], lr: 0.000431, loss: 3.1463
2022-10-08 18:31:38 - train: epoch 0071, iter [01050, 01251], lr: 0.000431, loss: 3.1713
2022-10-08 18:31:59 - train: epoch 0071, iter [01060, 01251], lr: 0.000431, loss: 3.2693
2022-10-08 18:32:20 - train: epoch 0071, iter [01070, 01251], lr: 0.000430, loss: 2.7021
2022-10-08 18:32:41 - train: epoch 0071, iter [01080, 01251], lr: 0.000430, loss: 2.2637
2022-10-08 18:33:02 - train: epoch 0071, iter [01090, 01251], lr: 0.000430, loss: 2.6837
2022-10-08 18:33:23 - train: epoch 0071, iter [01100, 01251], lr: 0.000430, loss: 2.5664
2022-10-08 18:33:44 - train: epoch 0071, iter [01110, 01251], lr: 0.000430, loss: 3.0382
2022-10-08 18:34:05 - train: epoch 0071, iter [01120, 01251], lr: 0.000429, loss: 2.6610
2022-10-08 18:34:26 - train: epoch 0071, iter [01130, 01251], lr: 0.000429, loss: 3.2364
2022-10-08 18:34:47 - train: epoch 0071, iter [01140, 01251], lr: 0.000429, loss: 2.7126
2022-10-08 18:35:08 - train: epoch 0071, iter [01150, 01251], lr: 0.000429, loss: 3.3894
2022-10-08 18:35:29 - train: epoch 0071, iter [01160, 01251], lr: 0.000428, loss: 2.5674
2022-10-08 18:35:50 - train: epoch 0071, iter [01170, 01251], lr: 0.000428, loss: 3.2525
2022-10-08 18:36:11 - train: epoch 0071, iter [01180, 01251], lr: 0.000428, loss: 2.5857
2022-10-08 18:36:32 - train: epoch 0071, iter [01190, 01251], lr: 0.000428, loss: 2.7203
2022-10-08 18:36:53 - train: epoch 0071, iter [01200, 01251], lr: 0.000428, loss: 3.1093
2022-10-08 18:37:14 - train: epoch 0071, iter [01210, 01251], lr: 0.000427, loss: 3.2290
2022-10-08 18:37:35 - train: epoch 0071, iter [01220, 01251], lr: 0.000427, loss: 2.4754
2022-10-08 18:37:56 - train: epoch 0071, iter [01230, 01251], lr: 0.000427, loss: 2.3917
2022-10-08 18:38:17 - train: epoch 0071, iter [01240, 01251], lr: 0.000427, loss: 2.7552
2022-10-08 18:38:38 - train: epoch 0071, iter [01250, 01251], lr: 0.000426, loss: 3.2439
2022-10-08 18:38:42 - train: epoch 071, train_loss: 2.9012
2022-10-08 18:39:58 - eval: epoch: 071, acc1: 82.280%, acc5: 96.250%, test_loss: 0.7793, per_image_load_time: 1.326ms, per_image_inference_time: 1.439ms
2022-10-08 18:39:59 - until epoch: 071, best_acc1: 82.280%
2022-10-08 18:39:59 - epoch 072 lr: 0.000426
2022-10-08 18:40:26 - train: epoch 0072, iter [00010, 01251], lr: 0.000426, loss: 2.6937
2022-10-08 18:40:48 - train: epoch 0072, iter [00020, 01251], lr: 0.000426, loss: 3.0565
2022-10-08 18:41:09 - train: epoch 0072, iter [00030, 01251], lr: 0.000426, loss: 3.1746
2022-10-08 18:41:30 - train: epoch 0072, iter [00040, 01251], lr: 0.000426, loss: 3.2451
2022-10-08 18:41:51 - train: epoch 0072, iter [00050, 01251], lr: 0.000425, loss: 2.8431
2022-10-08 18:42:12 - train: epoch 0072, iter [00060, 01251], lr: 0.000425, loss: 3.2719
2022-10-08 18:42:34 - train: epoch 0072, iter [00070, 01251], lr: 0.000425, loss: 3.2308
2022-10-08 18:42:55 - train: epoch 0072, iter [00080, 01251], lr: 0.000425, loss: 2.9852
2022-10-08 18:43:16 - train: epoch 0072, iter [00090, 01251], lr: 0.000425, loss: 2.9252
2022-10-08 18:43:37 - train: epoch 0072, iter [00100, 01251], lr: 0.000424, loss: 3.0078
2022-10-08 18:43:58 - train: epoch 0072, iter [00110, 01251], lr: 0.000424, loss: 2.4240
2022-10-08 18:44:19 - train: epoch 0072, iter [00120, 01251], lr: 0.000424, loss: 3.1731
2022-10-08 18:44:41 - train: epoch 0072, iter [00130, 01251], lr: 0.000424, loss: 2.8310
2022-10-08 18:45:02 - train: epoch 0072, iter [00140, 01251], lr: 0.000423, loss: 2.7150
2022-10-08 18:45:23 - train: epoch 0072, iter [00150, 01251], lr: 0.000423, loss: 2.4872
2022-10-08 18:45:44 - train: epoch 0072, iter [00160, 01251], lr: 0.000423, loss: 2.9302
2022-10-08 18:46:05 - train: epoch 0072, iter [00170, 01251], lr: 0.000423, loss: 3.2937
2022-10-08 18:46:26 - train: epoch 0072, iter [00180, 01251], lr: 0.000423, loss: 3.1425
2022-10-08 18:46:47 - train: epoch 0072, iter [00190, 01251], lr: 0.000422, loss: 2.5819
2022-10-08 18:47:08 - train: epoch 0072, iter [00200, 01251], lr: 0.000422, loss: 2.7520
2022-10-08 18:47:29 - train: epoch 0072, iter [00210, 01251], lr: 0.000422, loss: 2.8910
2022-10-08 18:47:50 - train: epoch 0072, iter [00220, 01251], lr: 0.000422, loss: 2.5605
2022-10-08 18:48:11 - train: epoch 0072, iter [00230, 01251], lr: 0.000421, loss: 2.7197
2022-10-08 18:48:33 - train: epoch 0072, iter [00240, 01251], lr: 0.000421, loss: 2.8829
2022-10-08 18:48:54 - train: epoch 0072, iter [00250, 01251], lr: 0.000421, loss: 3.1200
2022-10-08 18:49:15 - train: epoch 0072, iter [00260, 01251], lr: 0.000421, loss: 3.0738
2022-10-08 18:49:36 - train: epoch 0072, iter [00270, 01251], lr: 0.000421, loss: 2.4806
2022-10-08 18:49:57 - train: epoch 0072, iter [00280, 01251], lr: 0.000420, loss: 3.4935
2022-10-08 18:50:18 - train: epoch 0072, iter [00290, 01251], lr: 0.000420, loss: 2.7083
2022-10-08 18:50:39 - train: epoch 0072, iter [00300, 01251], lr: 0.000420, loss: 3.2655
2022-10-08 18:51:00 - train: epoch 0072, iter [00310, 01251], lr: 0.000420, loss: 2.6110
2022-10-08 18:51:21 - train: epoch 0072, iter [00320, 01251], lr: 0.000420, loss: 3.1227
2022-10-08 18:51:42 - train: epoch 0072, iter [00330, 01251], lr: 0.000419, loss: 3.2692
2022-10-08 18:52:03 - train: epoch 0072, iter [00340, 01251], lr: 0.000419, loss: 2.5698
2022-10-08 18:52:24 - train: epoch 0072, iter [00350, 01251], lr: 0.000419, loss: 3.0439
2022-10-08 18:52:46 - train: epoch 0072, iter [00360, 01251], lr: 0.000419, loss: 2.1424
2022-10-08 18:53:07 - train: epoch 0072, iter [00370, 01251], lr: 0.000418, loss: 3.1206
2022-10-08 18:53:28 - train: epoch 0072, iter [00380, 01251], lr: 0.000418, loss: 3.1993
2022-10-08 18:53:49 - train: epoch 0072, iter [00390, 01251], lr: 0.000418, loss: 2.8243
2022-10-08 18:54:10 - train: epoch 0072, iter [00400, 01251], lr: 0.000418, loss: 3.1490
2022-10-08 18:54:31 - train: epoch 0072, iter [00410, 01251], lr: 0.000418, loss: 2.6158
2022-10-08 18:54:52 - train: epoch 0072, iter [00420, 01251], lr: 0.000417, loss: 2.8885
2022-10-08 18:55:13 - train: epoch 0072, iter [00430, 01251], lr: 0.000417, loss: 2.7988
2022-10-08 18:55:34 - train: epoch 0072, iter [00440, 01251], lr: 0.000417, loss: 2.6942
2022-10-08 18:55:55 - train: epoch 0072, iter [00450, 01251], lr: 0.000417, loss: 3.2190
2022-10-08 18:56:16 - train: epoch 0072, iter [00460, 01251], lr: 0.000417, loss: 2.7394
2022-10-08 18:56:37 - train: epoch 0072, iter [00470, 01251], lr: 0.000416, loss: 2.1471
2022-10-08 18:56:58 - train: epoch 0072, iter [00480, 01251], lr: 0.000416, loss: 2.7721
2022-10-08 18:57:19 - train: epoch 0072, iter [00490, 01251], lr: 0.000416, loss: 3.2360
2022-10-08 18:57:40 - train: epoch 0072, iter [00500, 01251], lr: 0.000416, loss: 3.2394
2022-10-08 18:58:01 - train: epoch 0072, iter [00510, 01251], lr: 0.000415, loss: 3.1057
2022-10-08 18:58:22 - train: epoch 0072, iter [00520, 01251], lr: 0.000415, loss: 2.2316
2022-10-08 18:58:43 - train: epoch 0072, iter [00530, 01251], lr: 0.000415, loss: 2.7100
2022-10-08 18:59:04 - train: epoch 0072, iter [00540, 01251], lr: 0.000415, loss: 3.3065
2022-10-08 18:59:25 - train: epoch 0072, iter [00550, 01251], lr: 0.000415, loss: 3.2946
2022-10-08 18:59:46 - train: epoch 0072, iter [00560, 01251], lr: 0.000414, loss: 3.1415
2022-10-08 19:00:07 - train: epoch 0072, iter [00570, 01251], lr: 0.000414, loss: 3.3764
2022-10-08 19:00:28 - train: epoch 0072, iter [00580, 01251], lr: 0.000414, loss: 2.5401
2022-10-08 19:00:49 - train: epoch 0072, iter [00590, 01251], lr: 0.000414, loss: 2.4171
2022-10-08 19:01:10 - train: epoch 0072, iter [00600, 01251], lr: 0.000414, loss: 3.0916
2022-10-08 19:01:31 - train: epoch 0072, iter [00610, 01251], lr: 0.000413, loss: 2.7266
2022-10-08 19:01:52 - train: epoch 0072, iter [00620, 01251], lr: 0.000413, loss: 2.5768
2022-10-08 19:02:13 - train: epoch 0072, iter [00630, 01251], lr: 0.000413, loss: 2.9308
2022-10-08 19:02:34 - train: epoch 0072, iter [00640, 01251], lr: 0.000413, loss: 2.8247
2022-10-08 19:02:55 - train: epoch 0072, iter [00650, 01251], lr: 0.000412, loss: 2.8374
2022-10-08 19:03:16 - train: epoch 0072, iter [00660, 01251], lr: 0.000412, loss: 3.2303
2022-10-08 19:03:38 - train: epoch 0072, iter [00670, 01251], lr: 0.000412, loss: 2.6153
2022-10-08 19:03:59 - train: epoch 0072, iter [00680, 01251], lr: 0.000412, loss: 2.8046
2022-10-08 19:04:20 - train: epoch 0072, iter [00690, 01251], lr: 0.000412, loss: 2.9336
2022-10-08 19:04:41 - train: epoch 0072, iter [00700, 01251], lr: 0.000411, loss: 2.6721
2022-10-08 19:05:02 - train: epoch 0072, iter [00710, 01251], lr: 0.000411, loss: 2.4729
2022-10-08 19:05:23 - train: epoch 0072, iter [00720, 01251], lr: 0.000411, loss: 2.3549
2022-10-08 19:05:44 - train: epoch 0072, iter [00730, 01251], lr: 0.000411, loss: 3.2107
2022-10-08 19:06:05 - train: epoch 0072, iter [00740, 01251], lr: 0.000411, loss: 3.2358
2022-10-08 19:06:26 - train: epoch 0072, iter [00750, 01251], lr: 0.000410, loss: 2.8387
2022-10-08 19:06:46 - train: epoch 0072, iter [00760, 01251], lr: 0.000410, loss: 3.0118
2022-10-08 19:07:07 - train: epoch 0072, iter [00770, 01251], lr: 0.000410, loss: 3.1378
2022-10-08 19:07:28 - train: epoch 0072, iter [00780, 01251], lr: 0.000410, loss: 3.0341
2022-10-08 19:07:49 - train: epoch 0072, iter [00790, 01251], lr: 0.000409, loss: 2.7977
2022-10-08 19:08:10 - train: epoch 0072, iter [00800, 01251], lr: 0.000409, loss: 2.9777
2022-10-08 19:08:32 - train: epoch 0072, iter [00810, 01251], lr: 0.000409, loss: 3.2881
2022-10-08 19:08:53 - train: epoch 0072, iter [00820, 01251], lr: 0.000409, loss: 3.0730
2022-10-08 19:09:13 - train: epoch 0072, iter [00830, 01251], lr: 0.000409, loss: 3.0265
2022-10-08 19:09:35 - train: epoch 0072, iter [00840, 01251], lr: 0.000408, loss: 2.7868
2022-10-08 19:09:56 - train: epoch 0072, iter [00850, 01251], lr: 0.000408, loss: 3.1265
2022-10-08 19:10:17 - train: epoch 0072, iter [00860, 01251], lr: 0.000408, loss: 2.8504
2022-10-08 19:10:38 - train: epoch 0072, iter [00870, 01251], lr: 0.000408, loss: 2.8323
2022-10-08 19:10:59 - train: epoch 0072, iter [00880, 01251], lr: 0.000408, loss: 2.5846
2022-10-08 19:11:19 - train: epoch 0072, iter [00890, 01251], lr: 0.000407, loss: 3.1726
2022-10-08 19:11:40 - train: epoch 0072, iter [00900, 01251], lr: 0.000407, loss: 2.7883
2022-10-08 19:12:01 - train: epoch 0072, iter [00910, 01251], lr: 0.000407, loss: 2.7576
2022-10-08 19:12:22 - train: epoch 0072, iter [00920, 01251], lr: 0.000407, loss: 2.0320
2022-10-08 19:12:43 - train: epoch 0072, iter [00930, 01251], lr: 0.000407, loss: 3.1744
2022-10-08 19:13:04 - train: epoch 0072, iter [00940, 01251], lr: 0.000406, loss: 2.4170
2022-10-08 19:13:25 - train: epoch 0072, iter [00950, 01251], lr: 0.000406, loss: 2.4501
2022-10-08 19:13:46 - train: epoch 0072, iter [00960, 01251], lr: 0.000406, loss: 2.4363
2022-10-08 19:14:07 - train: epoch 0072, iter [00970, 01251], lr: 0.000406, loss: 3.0138
2022-10-08 19:14:28 - train: epoch 0072, iter [00980, 01251], lr: 0.000405, loss: 3.0661
2022-10-08 19:14:49 - train: epoch 0072, iter [00990, 01251], lr: 0.000405, loss: 2.6755
2022-10-08 19:15:10 - train: epoch 0072, iter [01000, 01251], lr: 0.000405, loss: 2.9878
2022-10-08 19:15:31 - train: epoch 0072, iter [01010, 01251], lr: 0.000405, loss: 3.3303
2022-10-08 19:15:52 - train: epoch 0072, iter [01020, 01251], lr: 0.000405, loss: 2.8773
2022-10-08 19:16:13 - train: epoch 0072, iter [01030, 01251], lr: 0.000404, loss: 2.4693
2022-10-08 19:16:34 - train: epoch 0072, iter [01040, 01251], lr: 0.000404, loss: 2.8663
2022-10-08 19:16:55 - train: epoch 0072, iter [01050, 01251], lr: 0.000404, loss: 2.0658
2022-10-08 19:17:16 - train: epoch 0072, iter [01060, 01251], lr: 0.000404, loss: 3.1886
2022-10-08 19:17:37 - train: epoch 0072, iter [01070, 01251], lr: 0.000404, loss: 3.1023
2022-10-08 19:17:58 - train: epoch 0072, iter [01080, 01251], lr: 0.000403, loss: 3.1045
2022-10-08 19:18:19 - train: epoch 0072, iter [01090, 01251], lr: 0.000403, loss: 3.0517
2022-10-08 19:18:40 - train: epoch 0072, iter [01100, 01251], lr: 0.000403, loss: 2.8805
2022-10-08 19:19:01 - train: epoch 0072, iter [01110, 01251], lr: 0.000403, loss: 2.2179
2022-10-08 19:19:22 - train: epoch 0072, iter [01120, 01251], lr: 0.000402, loss: 2.9298
2022-10-08 19:19:43 - train: epoch 0072, iter [01130, 01251], lr: 0.000402, loss: 2.7863
2022-10-08 19:20:04 - train: epoch 0072, iter [01140, 01251], lr: 0.000402, loss: 2.6710
2022-10-08 19:20:25 - train: epoch 0072, iter [01150, 01251], lr: 0.000402, loss: 3.0986
2022-10-08 19:20:46 - train: epoch 0072, iter [01160, 01251], lr: 0.000402, loss: 2.6024
2022-10-08 19:21:07 - train: epoch 0072, iter [01170, 01251], lr: 0.000401, loss: 2.6276
2022-10-08 19:21:28 - train: epoch 0072, iter [01180, 01251], lr: 0.000401, loss: 2.9603
2022-10-08 19:21:49 - train: epoch 0072, iter [01190, 01251], lr: 0.000401, loss: 2.3650
2022-10-08 19:22:10 - train: epoch 0072, iter [01200, 01251], lr: 0.000401, loss: 2.7464
2022-10-08 19:22:31 - train: epoch 0072, iter [01210, 01251], lr: 0.000401, loss: 3.0563
2022-10-08 19:22:52 - train: epoch 0072, iter [01220, 01251], lr: 0.000400, loss: 3.2770
2022-10-08 19:23:13 - train: epoch 0072, iter [01230, 01251], lr: 0.000400, loss: 3.0754
2022-10-08 19:23:34 - train: epoch 0072, iter [01240, 01251], lr: 0.000400, loss: 3.4288
2022-10-08 19:23:55 - train: epoch 0072, iter [01250, 01251], lr: 0.000400, loss: 2.5777
2022-10-08 19:23:58 - train: epoch 072, train_loss: 2.8898
2022-10-08 19:25:14 - eval: epoch: 072, acc1: 82.244%, acc5: 96.316%, test_loss: 0.7879, per_image_load_time: 0.790ms, per_image_inference_time: 1.433ms
2022-10-08 19:25:15 - until epoch: 072, best_acc1: 82.280%
2022-10-08 19:25:15 - epoch 073 lr: 0.000400
2022-10-08 19:25:43 - train: epoch 0073, iter [00010, 01251], lr: 0.000400, loss: 3.1187
2022-10-08 19:26:04 - train: epoch 0073, iter [00020, 01251], lr: 0.000399, loss: 3.4007
2022-10-08 19:26:25 - train: epoch 0073, iter [00030, 01251], lr: 0.000399, loss: 3.2711
2022-10-08 19:26:46 - train: epoch 0073, iter [00040, 01251], lr: 0.000399, loss: 2.8250
2022-10-08 19:27:07 - train: epoch 0073, iter [00050, 01251], lr: 0.000399, loss: 3.1867
2022-10-08 19:27:28 - train: epoch 0073, iter [00060, 01251], lr: 0.000398, loss: 3.1027
2022-10-08 19:27:49 - train: epoch 0073, iter [00070, 01251], lr: 0.000398, loss: 2.5426
2022-10-08 19:28:11 - train: epoch 0073, iter [00080, 01251], lr: 0.000398, loss: 2.8035
2022-10-08 19:28:32 - train: epoch 0073, iter [00090, 01251], lr: 0.000398, loss: 2.6521
2022-10-08 19:28:53 - train: epoch 0073, iter [00100, 01251], lr: 0.000398, loss: 2.8304
2022-10-08 19:29:14 - train: epoch 0073, iter [00110, 01251], lr: 0.000397, loss: 3.0496
2022-10-08 19:29:35 - train: epoch 0073, iter [00120, 01251], lr: 0.000397, loss: 2.5932
2022-10-08 19:29:56 - train: epoch 0073, iter [00130, 01251], lr: 0.000397, loss: 3.1641
2022-10-08 19:30:17 - train: epoch 0073, iter [00140, 01251], lr: 0.000397, loss: 2.4866
2022-10-08 19:30:38 - train: epoch 0073, iter [00150, 01251], lr: 0.000397, loss: 3.2636
2022-10-08 19:31:00 - train: epoch 0073, iter [00160, 01251], lr: 0.000396, loss: 2.7356
2022-10-08 19:31:21 - train: epoch 0073, iter [00170, 01251], lr: 0.000396, loss: 2.6339
2022-10-08 19:31:42 - train: epoch 0073, iter [00180, 01251], lr: 0.000396, loss: 3.4330
2022-10-08 19:32:03 - train: epoch 0073, iter [00190, 01251], lr: 0.000396, loss: 3.0089
2022-10-08 19:32:24 - train: epoch 0073, iter [00200, 01251], lr: 0.000396, loss: 3.0416
2022-10-08 19:32:45 - train: epoch 0073, iter [00210, 01251], lr: 0.000395, loss: 3.2072
2022-10-08 19:33:06 - train: epoch 0073, iter [00220, 01251], lr: 0.000395, loss: 2.6356
2022-10-08 19:33:27 - train: epoch 0073, iter [00230, 01251], lr: 0.000395, loss: 3.2405
2022-10-08 19:33:48 - train: epoch 0073, iter [00240, 01251], lr: 0.000395, loss: 3.4322
2022-10-08 19:34:10 - train: epoch 0073, iter [00250, 01251], lr: 0.000394, loss: 2.3422
2022-10-08 19:34:31 - train: epoch 0073, iter [00260, 01251], lr: 0.000394, loss: 2.5877
2022-10-08 19:34:52 - train: epoch 0073, iter [00270, 01251], lr: 0.000394, loss: 2.2534
2022-10-08 19:35:13 - train: epoch 0073, iter [00280, 01251], lr: 0.000394, loss: 3.0867
2022-10-08 19:35:34 - train: epoch 0073, iter [00290, 01251], lr: 0.000394, loss: 2.4569
2022-10-08 19:35:55 - train: epoch 0073, iter [00300, 01251], lr: 0.000393, loss: 2.8265
2022-10-08 19:36:16 - train: epoch 0073, iter [00310, 01251], lr: 0.000393, loss: 2.7298
2022-10-08 19:36:37 - train: epoch 0073, iter [00320, 01251], lr: 0.000393, loss: 2.7355
2022-10-08 19:36:58 - train: epoch 0073, iter [00330, 01251], lr: 0.000393, loss: 2.3046
2022-10-08 19:37:19 - train: epoch 0073, iter [00340, 01251], lr: 0.000393, loss: 2.9451
2022-10-08 19:37:41 - train: epoch 0073, iter [00350, 01251], lr: 0.000392, loss: 3.2168
2022-10-08 19:38:02 - train: epoch 0073, iter [00360, 01251], lr: 0.000392, loss: 2.6874
2022-10-08 19:38:23 - train: epoch 0073, iter [00370, 01251], lr: 0.000392, loss: 3.0970
2022-10-08 19:38:44 - train: epoch 0073, iter [00380, 01251], lr: 0.000392, loss: 2.3686
2022-10-08 19:39:05 - train: epoch 0073, iter [00390, 01251], lr: 0.000392, loss: 3.3940
2022-10-08 19:39:26 - train: epoch 0073, iter [00400, 01251], lr: 0.000391, loss: 3.3722
2022-10-08 19:39:47 - train: epoch 0073, iter [00410, 01251], lr: 0.000391, loss: 2.9070
2022-10-08 19:40:08 - train: epoch 0073, iter [00420, 01251], lr: 0.000391, loss: 2.8607
2022-10-08 19:40:29 - train: epoch 0073, iter [00430, 01251], lr: 0.000391, loss: 3.0914
2022-10-08 19:40:50 - train: epoch 0073, iter [00440, 01251], lr: 0.000390, loss: 2.5618
2022-10-08 19:41:11 - train: epoch 0073, iter [00450, 01251], lr: 0.000390, loss: 2.7538
2022-10-08 19:41:32 - train: epoch 0073, iter [00460, 01251], lr: 0.000390, loss: 2.9623
2022-10-08 19:41:53 - train: epoch 0073, iter [00470, 01251], lr: 0.000390, loss: 2.6656
2022-10-08 19:42:14 - train: epoch 0073, iter [00480, 01251], lr: 0.000390, loss: 2.8111
2022-10-08 19:42:35 - train: epoch 0073, iter [00490, 01251], lr: 0.000389, loss: 3.2887
2022-10-08 19:42:56 - train: epoch 0073, iter [00500, 01251], lr: 0.000389, loss: 2.5064
2022-10-08 19:43:17 - train: epoch 0073, iter [00510, 01251], lr: 0.000389, loss: 2.5968
2022-10-08 19:43:38 - train: epoch 0073, iter [00520, 01251], lr: 0.000389, loss: 3.1727
2022-10-08 19:43:59 - train: epoch 0073, iter [00530, 01251], lr: 0.000389, loss: 3.0495
2022-10-08 19:44:20 - train: epoch 0073, iter [00540, 01251], lr: 0.000388, loss: 2.6892
2022-10-08 19:44:41 - train: epoch 0073, iter [00550, 01251], lr: 0.000388, loss: 3.1003
2022-10-08 19:45:02 - train: epoch 0073, iter [00560, 01251], lr: 0.000388, loss: 2.4432
2022-10-08 19:45:23 - train: epoch 0073, iter [00570, 01251], lr: 0.000388, loss: 3.2623
2022-10-08 19:45:44 - train: epoch 0073, iter [00580, 01251], lr: 0.000388, loss: 2.4052
2022-10-08 19:46:05 - train: epoch 0073, iter [00590, 01251], lr: 0.000387, loss: 2.8290
2022-10-08 19:46:26 - train: epoch 0073, iter [00600, 01251], lr: 0.000387, loss: 2.5014
2022-10-08 19:46:47 - train: epoch 0073, iter [00610, 01251], lr: 0.000387, loss: 2.9402
2022-10-08 19:47:08 - train: epoch 0073, iter [00620, 01251], lr: 0.000387, loss: 3.0399
2022-10-08 19:47:29 - train: epoch 0073, iter [00630, 01251], lr: 0.000387, loss: 3.3792
2022-10-08 19:47:50 - train: epoch 0073, iter [00640, 01251], lr: 0.000386, loss: 2.7554
2022-10-08 19:48:11 - train: epoch 0073, iter [00650, 01251], lr: 0.000386, loss: 2.6211
2022-10-08 19:48:33 - train: epoch 0073, iter [00660, 01251], lr: 0.000386, loss: 3.1685
2022-10-08 19:48:54 - train: epoch 0073, iter [00670, 01251], lr: 0.000386, loss: 3.3840
2022-10-08 19:49:15 - train: epoch 0073, iter [00680, 01251], lr: 0.000385, loss: 2.9201
2022-10-08 19:49:36 - train: epoch 0073, iter [00690, 01251], lr: 0.000385, loss: 3.4259
2022-10-08 19:49:57 - train: epoch 0073, iter [00700, 01251], lr: 0.000385, loss: 2.7295
2022-10-08 19:50:19 - train: epoch 0073, iter [00710, 01251], lr: 0.000385, loss: 3.0520
2022-10-08 19:50:40 - train: epoch 0073, iter [00720, 01251], lr: 0.000385, loss: 2.5505
2022-10-08 19:51:01 - train: epoch 0073, iter [00730, 01251], lr: 0.000384, loss: 3.2697
2022-10-08 19:51:22 - train: epoch 0073, iter [00740, 01251], lr: 0.000384, loss: 1.9561
2022-10-08 19:51:43 - train: epoch 0073, iter [00750, 01251], lr: 0.000384, loss: 2.9548
2022-10-08 19:52:04 - train: epoch 0073, iter [00760, 01251], lr: 0.000384, loss: 2.4945
2022-10-08 19:52:25 - train: epoch 0073, iter [00770, 01251], lr: 0.000384, loss: 3.1403
2022-10-08 19:52:46 - train: epoch 0073, iter [00780, 01251], lr: 0.000383, loss: 2.4036
2022-10-08 19:53:07 - train: epoch 0073, iter [00790, 01251], lr: 0.000383, loss: 3.2291
2022-10-08 19:53:28 - train: epoch 0073, iter [00800, 01251], lr: 0.000383, loss: 3.2143
2022-10-08 19:53:49 - train: epoch 0073, iter [00810, 01251], lr: 0.000383, loss: 3.3795
2022-10-08 19:54:10 - train: epoch 0073, iter [00820, 01251], lr: 0.000383, loss: 2.6987
2022-10-08 19:54:31 - train: epoch 0073, iter [00830, 01251], lr: 0.000382, loss: 2.4566
2022-10-08 19:54:53 - train: epoch 0073, iter [00840, 01251], lr: 0.000382, loss: 3.1603
2022-10-08 19:55:14 - train: epoch 0073, iter [00850, 01251], lr: 0.000382, loss: 2.6736
2022-10-08 19:55:35 - train: epoch 0073, iter [00860, 01251], lr: 0.000382, loss: 3.2072
2022-10-08 19:55:56 - train: epoch 0073, iter [00870, 01251], lr: 0.000382, loss: 3.0175
2022-10-08 19:56:17 - train: epoch 0073, iter [00880, 01251], lr: 0.000381, loss: 2.7772
2022-10-08 19:56:38 - train: epoch 0073, iter [00890, 01251], lr: 0.000381, loss: 2.9843
2022-10-08 19:56:59 - train: epoch 0073, iter [00900, 01251], lr: 0.000381, loss: 2.9904
2022-10-08 19:57:20 - train: epoch 0073, iter [00910, 01251], lr: 0.000381, loss: 3.2814
2022-10-08 19:57:41 - train: epoch 0073, iter [00920, 01251], lr: 0.000380, loss: 2.9701
2022-10-08 19:58:02 - train: epoch 0073, iter [00930, 01251], lr: 0.000380, loss: 2.5849
2022-10-08 19:58:23 - train: epoch 0073, iter [00940, 01251], lr: 0.000380, loss: 2.8748
2022-10-08 19:58:44 - train: epoch 0073, iter [00950, 01251], lr: 0.000380, loss: 2.9012
2022-10-08 19:59:06 - train: epoch 0073, iter [00960, 01251], lr: 0.000380, loss: 3.0038
2022-10-08 19:59:27 - train: epoch 0073, iter [00970, 01251], lr: 0.000379, loss: 2.5811
2022-10-08 19:59:48 - train: epoch 0073, iter [00980, 01251], lr: 0.000379, loss: 2.9017
2022-10-08 20:00:09 - train: epoch 0073, iter [00990, 01251], lr: 0.000379, loss: 3.2229
2022-10-08 20:00:30 - train: epoch 0073, iter [01000, 01251], lr: 0.000379, loss: 2.8204
2022-10-08 20:00:51 - train: epoch 0073, iter [01010, 01251], lr: 0.000379, loss: 2.7070
2022-10-08 20:01:12 - train: epoch 0073, iter [01020, 01251], lr: 0.000378, loss: 3.6349
2022-10-08 20:01:33 - train: epoch 0073, iter [01030, 01251], lr: 0.000378, loss: 3.1465
2022-10-08 20:01:54 - train: epoch 0073, iter [01040, 01251], lr: 0.000378, loss: 2.8160
2022-10-08 20:02:15 - train: epoch 0073, iter [01050, 01251], lr: 0.000378, loss: 2.0954
2022-10-08 20:02:36 - train: epoch 0073, iter [01060, 01251], lr: 0.000378, loss: 2.9734
2022-10-08 20:02:57 - train: epoch 0073, iter [01070, 01251], lr: 0.000377, loss: 2.7866
2022-10-08 20:03:18 - train: epoch 0073, iter [01080, 01251], lr: 0.000377, loss: 2.4994
2022-10-08 20:03:39 - train: epoch 0073, iter [01090, 01251], lr: 0.000377, loss: 3.4386
2022-10-08 20:04:00 - train: epoch 0073, iter [01100, 01251], lr: 0.000377, loss: 2.7537
2022-10-08 20:04:21 - train: epoch 0073, iter [01110, 01251], lr: 0.000377, loss: 3.0913
2022-10-08 20:04:42 - train: epoch 0073, iter [01120, 01251], lr: 0.000376, loss: 3.0896
2022-10-08 20:05:03 - train: epoch 0073, iter [01130, 01251], lr: 0.000376, loss: 3.4868
2022-10-08 20:05:24 - train: epoch 0073, iter [01140, 01251], lr: 0.000376, loss: 2.4622
2022-10-08 20:05:45 - train: epoch 0073, iter [01150, 01251], lr: 0.000376, loss: 3.3132
2022-10-08 20:06:06 - train: epoch 0073, iter [01160, 01251], lr: 0.000376, loss: 2.9851
2022-10-08 20:06:27 - train: epoch 0073, iter [01170, 01251], lr: 0.000375, loss: 2.9264
2022-10-08 20:06:48 - train: epoch 0073, iter [01180, 01251], lr: 0.000375, loss: 2.4585
2022-10-08 20:07:09 - train: epoch 0073, iter [01190, 01251], lr: 0.000375, loss: 2.8541
2022-10-08 20:07:30 - train: epoch 0073, iter [01200, 01251], lr: 0.000375, loss: 3.2346
2022-10-08 20:07:51 - train: epoch 0073, iter [01210, 01251], lr: 0.000374, loss: 3.2898
2022-10-08 20:08:12 - train: epoch 0073, iter [01220, 01251], lr: 0.000374, loss: 3.1664
2022-10-08 20:08:33 - train: epoch 0073, iter [01230, 01251], lr: 0.000374, loss: 3.1931
2022-10-08 20:08:55 - train: epoch 0073, iter [01240, 01251], lr: 0.000374, loss: 3.2171
2022-10-08 20:09:15 - train: epoch 0073, iter [01250, 01251], lr: 0.000374, loss: 3.2002
2022-10-08 20:09:19 - train: epoch 073, train_loss: 2.8840
2022-10-08 20:10:35 - eval: epoch: 073, acc1: 82.360%, acc5: 96.366%, test_loss: 0.7659, per_image_load_time: 1.106ms, per_image_inference_time: 1.445ms
2022-10-08 20:10:37 - until epoch: 073, best_acc1: 82.360%
2022-10-08 20:10:37 - epoch 074 lr: 0.000374
2022-10-08 20:11:04 - train: epoch 0074, iter [00010, 01251], lr: 0.000373, loss: 2.8586
2022-10-08 20:11:25 - train: epoch 0074, iter [00020, 01251], lr: 0.000373, loss: 3.0629
2022-10-08 20:11:46 - train: epoch 0074, iter [00030, 01251], lr: 0.000373, loss: 2.9530
2022-10-08 20:12:07 - train: epoch 0074, iter [00040, 01251], lr: 0.000373, loss: 2.6562
2022-10-08 20:12:28 - train: epoch 0074, iter [00050, 01251], lr: 0.000373, loss: 3.1692
2022-10-08 20:12:49 - train: epoch 0074, iter [00060, 01251], lr: 0.000372, loss: 3.3455
2022-10-08 20:13:10 - train: epoch 0074, iter [00070, 01251], lr: 0.000372, loss: 2.9860
2022-10-08 20:13:32 - train: epoch 0074, iter [00080, 01251], lr: 0.000372, loss: 3.0044
2022-10-08 20:13:53 - train: epoch 0074, iter [00090, 01251], lr: 0.000372, loss: 2.9048
2022-10-08 20:14:14 - train: epoch 0074, iter [00100, 01251], lr: 0.000372, loss: 2.6433
2022-10-08 20:14:35 - train: epoch 0074, iter [00110, 01251], lr: 0.000371, loss: 3.5185
2022-10-08 20:14:56 - train: epoch 0074, iter [00120, 01251], lr: 0.000371, loss: 2.9388
2022-10-08 20:15:17 - train: epoch 0074, iter [00130, 01251], lr: 0.000371, loss: 3.3329
2022-10-08 20:15:38 - train: epoch 0074, iter [00140, 01251], lr: 0.000371, loss: 2.8999
2022-10-08 20:15:59 - train: epoch 0074, iter [00150, 01251], lr: 0.000371, loss: 3.0515
2022-10-08 20:16:20 - train: epoch 0074, iter [00160, 01251], lr: 0.000370, loss: 2.8331
2022-10-08 20:16:41 - train: epoch 0074, iter [00170, 01251], lr: 0.000370, loss: 2.5257
2022-10-08 20:17:02 - train: epoch 0074, iter [00180, 01251], lr: 0.000370, loss: 2.6031
2022-10-08 20:17:23 - train: epoch 0074, iter [00190, 01251], lr: 0.000370, loss: 2.5892
2022-10-08 20:17:44 - train: epoch 0074, iter [00200, 01251], lr: 0.000370, loss: 2.6410
2022-10-08 20:18:05 - train: epoch 0074, iter [00210, 01251], lr: 0.000369, loss: 2.9224
2022-10-08 20:18:26 - train: epoch 0074, iter [00220, 01251], lr: 0.000369, loss: 2.8596
2022-10-08 20:18:47 - train: epoch 0074, iter [00230, 01251], lr: 0.000369, loss: 2.5666
2022-10-08 20:19:08 - train: epoch 0074, iter [00240, 01251], lr: 0.000369, loss: 2.3723
2022-10-08 20:19:29 - train: epoch 0074, iter [00250, 01251], lr: 0.000369, loss: 3.3454
2022-10-08 20:19:51 - train: epoch 0074, iter [00260, 01251], lr: 0.000368, loss: 2.7153
2022-10-08 20:20:12 - train: epoch 0074, iter [00270, 01251], lr: 0.000368, loss: 2.4829
2022-10-08 20:20:33 - train: epoch 0074, iter [00280, 01251], lr: 0.000368, loss: 2.4833
2022-10-08 20:20:54 - train: epoch 0074, iter [00290, 01251], lr: 0.000368, loss: 2.6430
2022-10-08 20:21:15 - train: epoch 0074, iter [00300, 01251], lr: 0.000367, loss: 2.2027
2022-10-08 20:21:36 - train: epoch 0074, iter [00310, 01251], lr: 0.000367, loss: 2.3765
2022-10-08 20:21:57 - train: epoch 0074, iter [00320, 01251], lr: 0.000367, loss: 2.9969
2022-10-08 20:22:18 - train: epoch 0074, iter [00330, 01251], lr: 0.000367, loss: 3.3717
2022-10-08 20:22:39 - train: epoch 0074, iter [00340, 01251], lr: 0.000367, loss: 2.8807
2022-10-08 20:23:00 - train: epoch 0074, iter [00350, 01251], lr: 0.000366, loss: 2.7506
2022-10-08 20:23:21 - train: epoch 0074, iter [00360, 01251], lr: 0.000366, loss: 2.8499
2022-10-08 20:23:42 - train: epoch 0074, iter [00370, 01251], lr: 0.000366, loss: 2.7893
2022-10-08 20:24:03 - train: epoch 0074, iter [00380, 01251], lr: 0.000366, loss: 3.3972
2022-10-08 20:24:24 - train: epoch 0074, iter [00390, 01251], lr: 0.000366, loss: 3.4810
2022-10-08 20:24:45 - train: epoch 0074, iter [00400, 01251], lr: 0.000365, loss: 2.9329
2022-10-08 20:25:06 - train: epoch 0074, iter [00410, 01251], lr: 0.000365, loss: 3.3561
2022-10-08 20:25:27 - train: epoch 0074, iter [00420, 01251], lr: 0.000365, loss: 2.9151
2022-10-08 20:25:49 - train: epoch 0074, iter [00430, 01251], lr: 0.000365, loss: 2.6771
2022-10-08 20:26:10 - train: epoch 0074, iter [00440, 01251], lr: 0.000365, loss: 3.0361
2022-10-08 20:26:31 - train: epoch 0074, iter [00450, 01251], lr: 0.000364, loss: 3.4016
2022-10-08 20:26:52 - train: epoch 0074, iter [00460, 01251], lr: 0.000364, loss: 2.7385
2022-10-08 20:27:13 - train: epoch 0074, iter [00470, 01251], lr: 0.000364, loss: 3.2553
2022-10-08 20:27:34 - train: epoch 0074, iter [00480, 01251], lr: 0.000364, loss: 2.9641
2022-10-08 20:27:55 - train: epoch 0074, iter [00490, 01251], lr: 0.000364, loss: 3.1214
2022-10-08 20:28:16 - train: epoch 0074, iter [00500, 01251], lr: 0.000363, loss: 3.0011
2022-10-08 20:28:37 - train: epoch 0074, iter [00510, 01251], lr: 0.000363, loss: 2.7720
2022-10-08 20:28:58 - train: epoch 0074, iter [00520, 01251], lr: 0.000363, loss: 2.9049
2022-10-08 20:29:19 - train: epoch 0074, iter [00530, 01251], lr: 0.000363, loss: 3.4227
2022-10-08 20:29:40 - train: epoch 0074, iter [00540, 01251], lr: 0.000363, loss: 3.3044
2022-10-08 20:30:01 - train: epoch 0074, iter [00550, 01251], lr: 0.000362, loss: 3.1659
2022-10-08 20:30:22 - train: epoch 0074, iter [00560, 01251], lr: 0.000362, loss: 3.2271
2022-10-08 20:30:43 - train: epoch 0074, iter [00570, 01251], lr: 0.000362, loss: 3.1605
2022-10-08 20:31:04 - train: epoch 0074, iter [00580, 01251], lr: 0.000362, loss: 3.3434
2022-10-08 20:31:25 - train: epoch 0074, iter [00590, 01251], lr: 0.000362, loss: 2.3697
2022-10-08 20:31:46 - train: epoch 0074, iter [00600, 01251], lr: 0.000361, loss: 2.5457
2022-10-08 20:32:07 - train: epoch 0074, iter [00610, 01251], lr: 0.000361, loss: 2.4536
2022-10-08 20:32:28 - train: epoch 0074, iter [00620, 01251], lr: 0.000361, loss: 3.0195
2022-10-08 20:32:49 - train: epoch 0074, iter [00630, 01251], lr: 0.000361, loss: 3.1986
2022-10-08 20:33:10 - train: epoch 0074, iter [00640, 01251], lr: 0.000361, loss: 3.0550
2022-10-08 20:33:31 - train: epoch 0074, iter [00650, 01251], lr: 0.000360, loss: 3.1886
2022-10-08 20:33:52 - train: epoch 0074, iter [00660, 01251], lr: 0.000360, loss: 2.5783
2022-10-08 20:34:13 - train: epoch 0074, iter [00670, 01251], lr: 0.000360, loss: 2.6916
2022-10-08 20:34:34 - train: epoch 0074, iter [00680, 01251], lr: 0.000360, loss: 2.3766
2022-10-08 20:34:55 - train: epoch 0074, iter [00690, 01251], lr: 0.000360, loss: 2.5373
2022-10-08 20:35:16 - train: epoch 0074, iter [00700, 01251], lr: 0.000359, loss: 2.2957
2022-10-08 20:35:37 - train: epoch 0074, iter [00710, 01251], lr: 0.000359, loss: 2.7393
2022-10-08 20:35:58 - train: epoch 0074, iter [00720, 01251], lr: 0.000359, loss: 3.0871
2022-10-08 20:36:19 - train: epoch 0074, iter [00730, 01251], lr: 0.000359, loss: 2.8167
2022-10-08 20:36:40 - train: epoch 0074, iter [00740, 01251], lr: 0.000359, loss: 3.3124
2022-10-08 20:37:01 - train: epoch 0074, iter [00750, 01251], lr: 0.000358, loss: 2.7207
2022-10-08 20:37:22 - train: epoch 0074, iter [00760, 01251], lr: 0.000358, loss: 2.6674
2022-10-08 20:37:43 - train: epoch 0074, iter [00770, 01251], lr: 0.000358, loss: 3.0953
2022-10-08 20:38:04 - train: epoch 0074, iter [00780, 01251], lr: 0.000358, loss: 3.1215
2022-10-08 20:38:25 - train: epoch 0074, iter [00790, 01251], lr: 0.000358, loss: 2.8101
2022-10-08 20:38:46 - train: epoch 0074, iter [00800, 01251], lr: 0.000357, loss: 3.0702
2022-10-08 20:39:06 - train: epoch 0074, iter [00810, 01251], lr: 0.000357, loss: 3.0000
2022-10-08 20:39:27 - train: epoch 0074, iter [00820, 01251], lr: 0.000357, loss: 2.3725
2022-10-08 20:39:48 - train: epoch 0074, iter [00830, 01251], lr: 0.000357, loss: 2.6840
2022-10-08 20:40:09 - train: epoch 0074, iter [00840, 01251], lr: 0.000357, loss: 2.6576
2022-10-08 20:40:30 - train: epoch 0074, iter [00850, 01251], lr: 0.000356, loss: 3.4293
2022-10-08 20:40:51 - train: epoch 0074, iter [00860, 01251], lr: 0.000356, loss: 3.2126
2022-10-08 20:41:12 - train: epoch 0074, iter [00870, 01251], lr: 0.000356, loss: 3.1154
2022-10-08 20:41:33 - train: epoch 0074, iter [00880, 01251], lr: 0.000356, loss: 3.1507
2022-10-08 20:41:54 - train: epoch 0074, iter [00890, 01251], lr: 0.000355, loss: 2.7775
2022-10-08 20:42:15 - train: epoch 0074, iter [00900, 01251], lr: 0.000355, loss: 3.1073
2022-10-08 20:42:36 - train: epoch 0074, iter [00910, 01251], lr: 0.000355, loss: 2.5725
2022-10-08 20:42:57 - train: epoch 0074, iter [00920, 01251], lr: 0.000355, loss: 2.9971
2022-10-08 20:43:18 - train: epoch 0074, iter [00930, 01251], lr: 0.000355, loss: 2.7238
2022-10-08 20:43:39 - train: epoch 0074, iter [00940, 01251], lr: 0.000354, loss: 3.1346
2022-10-08 20:44:00 - train: epoch 0074, iter [00950, 01251], lr: 0.000354, loss: 2.9600
2022-10-08 20:44:21 - train: epoch 0074, iter [00960, 01251], lr: 0.000354, loss: 3.1688
2022-10-08 20:44:42 - train: epoch 0074, iter [00970, 01251], lr: 0.000354, loss: 2.7347
2022-10-08 20:45:03 - train: epoch 0074, iter [00980, 01251], lr: 0.000354, loss: 2.9981
2022-10-08 20:45:24 - train: epoch 0074, iter [00990, 01251], lr: 0.000353, loss: 3.0563
2022-10-08 20:45:45 - train: epoch 0074, iter [01000, 01251], lr: 0.000353, loss: 2.7532
2022-10-08 20:46:06 - train: epoch 0074, iter [01010, 01251], lr: 0.000353, loss: 3.3735
2022-10-08 20:46:27 - train: epoch 0074, iter [01020, 01251], lr: 0.000353, loss: 2.5444
2022-10-08 20:46:48 - train: epoch 0074, iter [01030, 01251], lr: 0.000353, loss: 3.0927
2022-10-08 20:47:09 - train: epoch 0074, iter [01040, 01251], lr: 0.000352, loss: 2.9176
2022-10-08 20:47:30 - train: epoch 0074, iter [01050, 01251], lr: 0.000352, loss: 2.9430
2022-10-08 20:47:51 - train: epoch 0074, iter [01060, 01251], lr: 0.000352, loss: 2.2785
2022-10-08 20:48:12 - train: epoch 0074, iter [01070, 01251], lr: 0.000352, loss: 2.7400
2022-10-08 20:48:34 - train: epoch 0074, iter [01080, 01251], lr: 0.000352, loss: 2.6722
2022-10-08 20:48:55 - train: epoch 0074, iter [01090, 01251], lr: 0.000351, loss: 2.8281
2022-10-08 20:49:16 - train: epoch 0074, iter [01100, 01251], lr: 0.000351, loss: 3.0794
2022-10-08 20:49:37 - train: epoch 0074, iter [01110, 01251], lr: 0.000351, loss: 2.8712
2022-10-08 20:49:58 - train: epoch 0074, iter [01120, 01251], lr: 0.000351, loss: 3.2583
2022-10-08 20:50:19 - train: epoch 0074, iter [01130, 01251], lr: 0.000351, loss: 2.5924
2022-10-08 20:50:40 - train: epoch 0074, iter [01140, 01251], lr: 0.000350, loss: 3.0922
2022-10-08 20:51:01 - train: epoch 0074, iter [01150, 01251], lr: 0.000350, loss: 2.6235
2022-10-08 20:51:22 - train: epoch 0074, iter [01160, 01251], lr: 0.000350, loss: 2.5369
2022-10-08 20:51:43 - train: epoch 0074, iter [01170, 01251], lr: 0.000350, loss: 2.6633
2022-10-08 20:52:04 - train: epoch 0074, iter [01180, 01251], lr: 0.000350, loss: 3.2084
2022-10-08 20:52:25 - train: epoch 0074, iter [01190, 01251], lr: 0.000349, loss: 3.0385
2022-10-08 20:52:46 - train: epoch 0074, iter [01200, 01251], lr: 0.000349, loss: 2.7796
2022-10-08 20:53:07 - train: epoch 0074, iter [01210, 01251], lr: 0.000349, loss: 2.1532
2022-10-08 20:53:28 - train: epoch 0074, iter [01220, 01251], lr: 0.000349, loss: 2.9518
2022-10-08 20:53:49 - train: epoch 0074, iter [01230, 01251], lr: 0.000349, loss: 2.6605
2022-10-08 20:54:10 - train: epoch 0074, iter [01240, 01251], lr: 0.000348, loss: 2.7910
2022-10-08 20:54:31 - train: epoch 0074, iter [01250, 01251], lr: 0.000348, loss: 2.5475
2022-10-08 20:54:34 - train: epoch 074, train_loss: 2.8760
2022-10-08 20:55:51 - eval: epoch: 074, acc1: 82.332%, acc5: 96.328%, test_loss: 0.7702, per_image_load_time: 0.479ms, per_image_inference_time: 1.454ms
2022-10-08 20:55:52 - until epoch: 074, best_acc1: 82.360%
2022-10-08 20:55:52 - epoch 075 lr: 0.000348
2022-10-08 20:56:19 - train: epoch 0075, iter [00010, 01251], lr: 0.000348, loss: 2.4154
2022-10-08 20:56:40 - train: epoch 0075, iter [00020, 01251], lr: 0.000348, loss: 2.8533
2022-10-08 20:57:01 - train: epoch 0075, iter [00030, 01251], lr: 0.000348, loss: 3.2578
2022-10-08 20:57:22 - train: epoch 0075, iter [00040, 01251], lr: 0.000347, loss: 2.5910
2022-10-08 20:57:43 - train: epoch 0075, iter [00050, 01251], lr: 0.000347, loss: 3.1860
2022-10-08 20:58:04 - train: epoch 0075, iter [00060, 01251], lr: 0.000347, loss: 3.0378
2022-10-08 20:58:25 - train: epoch 0075, iter [00070, 01251], lr: 0.000347, loss: 3.1614
2022-10-08 20:58:46 - train: epoch 0075, iter [00080, 01251], lr: 0.000347, loss: 2.4137
2022-10-08 20:59:08 - train: epoch 0075, iter [00090, 01251], lr: 0.000346, loss: 2.8223
2022-10-08 20:59:29 - train: epoch 0075, iter [00100, 01251], lr: 0.000346, loss: 3.0850
2022-10-08 20:59:50 - train: epoch 0075, iter [00110, 01251], lr: 0.000346, loss: 2.2255
2022-10-08 21:00:11 - train: epoch 0075, iter [00120, 01251], lr: 0.000346, loss: 2.6574
2022-10-08 21:00:32 - train: epoch 0075, iter [00130, 01251], lr: 0.000346, loss: 2.8084
2022-10-08 21:00:53 - train: epoch 0075, iter [00140, 01251], lr: 0.000345, loss: 3.0328
2022-10-08 21:01:14 - train: epoch 0075, iter [00150, 01251], lr: 0.000345, loss: 3.1476
2022-10-08 21:01:35 - train: epoch 0075, iter [00160, 01251], lr: 0.000345, loss: 3.2276
2022-10-08 21:01:57 - train: epoch 0075, iter [00170, 01251], lr: 0.000345, loss: 2.4989
2022-10-08 21:02:18 - train: epoch 0075, iter [00180, 01251], lr: 0.000345, loss: 3.0164
2022-10-08 21:02:39 - train: epoch 0075, iter [00190, 01251], lr: 0.000344, loss: 2.5565
2022-10-08 21:03:00 - train: epoch 0075, iter [00200, 01251], lr: 0.000344, loss: 2.6613
2022-10-08 21:03:21 - train: epoch 0075, iter [00210, 01251], lr: 0.000344, loss: 3.0418
2022-10-08 21:03:42 - train: epoch 0075, iter [00220, 01251], lr: 0.000344, loss: 3.2478
2022-10-08 21:04:03 - train: epoch 0075, iter [00230, 01251], lr: 0.000344, loss: 3.0204
2022-10-08 21:04:24 - train: epoch 0075, iter [00240, 01251], lr: 0.000343, loss: 2.5072
2022-10-08 21:04:45 - train: epoch 0075, iter [00250, 01251], lr: 0.000343, loss: 2.9947
2022-10-08 21:05:06 - train: epoch 0075, iter [00260, 01251], lr: 0.000343, loss: 2.9469
2022-10-08 21:05:27 - train: epoch 0075, iter [00270, 01251], lr: 0.000343, loss: 2.8197
2022-10-08 21:05:48 - train: epoch 0075, iter [00280, 01251], lr: 0.000343, loss: 2.8627
2022-10-08 21:06:09 - train: epoch 0075, iter [00290, 01251], lr: 0.000342, loss: 2.5713
2022-10-08 21:06:30 - train: epoch 0075, iter [00300, 01251], lr: 0.000342, loss: 2.5970
2022-10-08 21:06:51 - train: epoch 0075, iter [00310, 01251], lr: 0.000342, loss: 2.8909
2022-10-08 21:07:12 - train: epoch 0075, iter [00320, 01251], lr: 0.000342, loss: 2.6924
2022-10-08 21:07:33 - train: epoch 0075, iter [00330, 01251], lr: 0.000342, loss: 3.0335
2022-10-08 21:07:54 - train: epoch 0075, iter [00340, 01251], lr: 0.000341, loss: 3.0377
2022-10-08 21:08:15 - train: epoch 0075, iter [00350, 01251], lr: 0.000341, loss: 3.2495
2022-10-08 21:08:36 - train: epoch 0075, iter [00360, 01251], lr: 0.000341, loss: 2.9853
2022-10-08 21:08:57 - train: epoch 0075, iter [00370, 01251], lr: 0.000341, loss: 3.2288
2022-10-08 21:09:18 - train: epoch 0075, iter [00380, 01251], lr: 0.000341, loss: 2.8748
2022-10-08 21:09:39 - train: epoch 0075, iter [00390, 01251], lr: 0.000340, loss: 2.2535
2022-10-08 21:10:00 - train: epoch 0075, iter [00400, 01251], lr: 0.000340, loss: 2.3605
2022-10-08 21:10:22 - train: epoch 0075, iter [00410, 01251], lr: 0.000340, loss: 2.6453
2022-10-08 21:10:43 - train: epoch 0075, iter [00420, 01251], lr: 0.000340, loss: 2.8628
2022-10-08 21:11:04 - train: epoch 0075, iter [00430, 01251], lr: 0.000340, loss: 3.0852
2022-10-08 21:11:25 - train: epoch 0075, iter [00440, 01251], lr: 0.000339, loss: 2.2642
2022-10-08 21:11:46 - train: epoch 0075, iter [00450, 01251], lr: 0.000339, loss: 3.2433
2022-10-08 21:12:07 - train: epoch 0075, iter [00460, 01251], lr: 0.000339, loss: 3.3875
2022-10-08 21:12:28 - train: epoch 0075, iter [00470, 01251], lr: 0.000339, loss: 2.6203
2022-10-08 21:12:49 - train: epoch 0075, iter [00480, 01251], lr: 0.000339, loss: 3.0653
2022-10-08 21:13:11 - train: epoch 0075, iter [00490, 01251], lr: 0.000338, loss: 2.8115
2022-10-08 21:13:32 - train: epoch 0075, iter [00500, 01251], lr: 0.000338, loss: 3.2529
2022-10-08 21:13:53 - train: epoch 0075, iter [00510, 01251], lr: 0.000338, loss: 2.3431
2022-10-08 21:14:14 - train: epoch 0075, iter [00520, 01251], lr: 0.000338, loss: 2.6717
2022-10-08 21:14:35 - train: epoch 0075, iter [00530, 01251], lr: 0.000338, loss: 2.4641
2022-10-08 21:14:56 - train: epoch 0075, iter [00540, 01251], lr: 0.000337, loss: 2.4104
2022-10-08 21:15:17 - train: epoch 0075, iter [00550, 01251], lr: 0.000337, loss: 2.9982
2022-10-08 21:15:38 - train: epoch 0075, iter [00560, 01251], lr: 0.000337, loss: 2.5604
2022-10-08 21:15:59 - train: epoch 0075, iter [00570, 01251], lr: 0.000337, loss: 2.8973
2022-10-08 21:16:20 - train: epoch 0075, iter [00580, 01251], lr: 0.000337, loss: 2.7823
2022-10-08 21:16:41 - train: epoch 0075, iter [00590, 01251], lr: 0.000337, loss: 2.7959
2022-10-08 21:17:02 - train: epoch 0075, iter [00600, 01251], lr: 0.000336, loss: 2.6846
2022-10-08 21:17:23 - train: epoch 0075, iter [00610, 01251], lr: 0.000336, loss: 2.2733
2022-10-08 21:17:45 - train: epoch 0075, iter [00620, 01251], lr: 0.000336, loss: 2.6259
2022-10-08 21:18:06 - train: epoch 0075, iter [00630, 01251], lr: 0.000336, loss: 2.7486
2022-10-08 21:18:27 - train: epoch 0075, iter [00640, 01251], lr: 0.000336, loss: 2.7350
2022-10-08 21:18:48 - train: epoch 0075, iter [00650, 01251], lr: 0.000335, loss: 3.1833
2022-10-08 21:19:09 - train: epoch 0075, iter [00660, 01251], lr: 0.000335, loss: 3.5607
2022-10-08 21:19:30 - train: epoch 0075, iter [00670, 01251], lr: 0.000335, loss: 2.7590
2022-10-08 21:19:51 - train: epoch 0075, iter [00680, 01251], lr: 0.000335, loss: 3.2421
2022-10-08 21:20:12 - train: epoch 0075, iter [00690, 01251], lr: 0.000335, loss: 2.3827
2022-10-08 21:20:33 - train: epoch 0075, iter [00700, 01251], lr: 0.000334, loss: 2.3758
2022-10-08 21:20:54 - train: epoch 0075, iter [00710, 01251], lr: 0.000334, loss: 2.4442
2022-10-08 21:21:15 - train: epoch 0075, iter [00720, 01251], lr: 0.000334, loss: 3.2914
2022-10-08 21:21:36 - train: epoch 0075, iter [00730, 01251], lr: 0.000334, loss: 2.4472
2022-10-08 21:21:57 - train: epoch 0075, iter [00740, 01251], lr: 0.000334, loss: 2.6476
2022-10-08 21:22:18 - train: epoch 0075, iter [00750, 01251], lr: 0.000333, loss: 2.2661
2022-10-08 21:22:40 - train: epoch 0075, iter [00760, 01251], lr: 0.000333, loss: 2.9320
2022-10-08 21:23:01 - train: epoch 0075, iter [00770, 01251], lr: 0.000333, loss: 2.8866
2022-10-08 21:23:22 - train: epoch 0075, iter [00780, 01251], lr: 0.000333, loss: 2.4572
2022-10-08 21:23:43 - train: epoch 0075, iter [00790, 01251], lr: 0.000333, loss: 2.8857
2022-10-08 21:24:04 - train: epoch 0075, iter [00800, 01251], lr: 0.000332, loss: 2.9783
2022-10-08 21:24:25 - train: epoch 0075, iter [00810, 01251], lr: 0.000332, loss: 2.6507
2022-10-08 21:24:46 - train: epoch 0075, iter [00820, 01251], lr: 0.000332, loss: 2.8742
2022-10-08 21:25:07 - train: epoch 0075, iter [00830, 01251], lr: 0.000332, loss: 2.5174
2022-10-08 21:25:28 - train: epoch 0075, iter [00840, 01251], lr: 0.000332, loss: 3.3095
2022-10-08 21:25:49 - train: epoch 0075, iter [00850, 01251], lr: 0.000331, loss: 2.5922
2022-10-08 21:26:10 - train: epoch 0075, iter [00860, 01251], lr: 0.000331, loss: 2.5946
2022-10-08 21:26:31 - train: epoch 0075, iter [00870, 01251], lr: 0.000331, loss: 3.1708
2022-10-08 21:26:52 - train: epoch 0075, iter [00880, 01251], lr: 0.000331, loss: 2.6490
2022-10-08 21:27:13 - train: epoch 0075, iter [00890, 01251], lr: 0.000331, loss: 3.1912
2022-10-08 21:27:35 - train: epoch 0075, iter [00900, 01251], lr: 0.000330, loss: 3.0093
2022-10-08 21:27:56 - train: epoch 0075, iter [00910, 01251], lr: 0.000330, loss: 3.2575
2022-10-08 21:28:17 - train: epoch 0075, iter [00920, 01251], lr: 0.000330, loss: 2.7579
2022-10-08 21:28:38 - train: epoch 0075, iter [00930, 01251], lr: 0.000330, loss: 3.2098
2022-10-08 21:28:59 - train: epoch 0075, iter [00940, 01251], lr: 0.000330, loss: 2.1880
2022-10-08 21:29:20 - train: epoch 0075, iter [00950, 01251], lr: 0.000329, loss: 2.5241
2022-10-08 21:29:41 - train: epoch 0075, iter [00960, 01251], lr: 0.000329, loss: 3.0634
2022-10-08 21:30:02 - train: epoch 0075, iter [00970, 01251], lr: 0.000329, loss: 3.4114
2022-10-08 21:30:23 - train: epoch 0075, iter [00980, 01251], lr: 0.000329, loss: 2.5425
2022-10-08 21:30:44 - train: epoch 0075, iter [00990, 01251], lr: 0.000329, loss: 2.6913
2022-10-08 21:31:05 - train: epoch 0075, iter [01000, 01251], lr: 0.000328, loss: 2.9506
2022-10-08 21:31:26 - train: epoch 0075, iter [01010, 01251], lr: 0.000328, loss: 3.1943
2022-10-08 21:31:47 - train: epoch 0075, iter [01020, 01251], lr: 0.000328, loss: 3.0668
2022-10-08 21:32:08 - train: epoch 0075, iter [01030, 01251], lr: 0.000328, loss: 2.9155
2022-10-08 21:32:29 - train: epoch 0075, iter [01040, 01251], lr: 0.000328, loss: 2.9946
2022-10-08 21:32:50 - train: epoch 0075, iter [01050, 01251], lr: 0.000327, loss: 2.5287
2022-10-08 21:33:11 - train: epoch 0075, iter [01060, 01251], lr: 0.000327, loss: 2.2489
2022-10-08 21:33:32 - train: epoch 0075, iter [01070, 01251], lr: 0.000327, loss: 2.7580
2022-10-08 21:33:53 - train: epoch 0075, iter [01080, 01251], lr: 0.000327, loss: 3.3678
2022-10-08 21:34:14 - train: epoch 0075, iter [01090, 01251], lr: 0.000327, loss: 3.3449
2022-10-08 21:34:35 - train: epoch 0075, iter [01100, 01251], lr: 0.000326, loss: 3.0493
2022-10-08 21:34:56 - train: epoch 0075, iter [01110, 01251], lr: 0.000326, loss: 2.7306
2022-10-08 21:35:17 - train: epoch 0075, iter [01120, 01251], lr: 0.000326, loss: 2.8914
2022-10-08 21:35:38 - train: epoch 0075, iter [01130, 01251], lr: 0.000326, loss: 2.7003
2022-10-08 21:35:59 - train: epoch 0075, iter [01140, 01251], lr: 0.000326, loss: 2.6538
2022-10-08 21:36:20 - train: epoch 0075, iter [01150, 01251], lr: 0.000326, loss: 2.8600
2022-10-08 21:36:41 - train: epoch 0075, iter [01160, 01251], lr: 0.000325, loss: 2.8937
2022-10-08 21:37:02 - train: epoch 0075, iter [01170, 01251], lr: 0.000325, loss: 3.1322
2022-10-08 21:37:23 - train: epoch 0075, iter [01180, 01251], lr: 0.000325, loss: 2.8763
2022-10-08 21:37:44 - train: epoch 0075, iter [01190, 01251], lr: 0.000325, loss: 3.0300
2022-10-08 21:38:06 - train: epoch 0075, iter [01200, 01251], lr: 0.000325, loss: 3.0739
2022-10-08 21:38:27 - train: epoch 0075, iter [01210, 01251], lr: 0.000324, loss: 3.3852
2022-10-08 21:38:48 - train: epoch 0075, iter [01220, 01251], lr: 0.000324, loss: 3.0831
2022-10-08 21:39:09 - train: epoch 0075, iter [01230, 01251], lr: 0.000324, loss: 2.6341
2022-10-08 21:39:30 - train: epoch 0075, iter [01240, 01251], lr: 0.000324, loss: 3.0586
2022-10-08 21:39:51 - train: epoch 0075, iter [01250, 01251], lr: 0.000324, loss: 2.4474
2022-10-08 21:39:54 - train: epoch 075, train_loss: 2.8725
2022-10-08 21:41:10 - eval: epoch: 075, acc1: 82.440%, acc5: 96.364%, test_loss: 0.7707, per_image_load_time: 0.577ms, per_image_inference_time: 1.451ms
2022-10-08 21:41:12 - until epoch: 075, best_acc1: 82.440%
2022-10-08 21:41:12 - epoch 076 lr: 0.000324
2022-10-08 21:41:39 - train: epoch 0076, iter [00010, 01251], lr: 0.000323, loss: 2.8615
2022-10-08 21:42:00 - train: epoch 0076, iter [00020, 01251], lr: 0.000323, loss: 2.8445
2022-10-08 21:42:21 - train: epoch 0076, iter [00030, 01251], lr: 0.000323, loss: 3.0754
2022-10-08 21:42:42 - train: epoch 0076, iter [00040, 01251], lr: 0.000323, loss: 2.6549
2022-10-08 21:43:03 - train: epoch 0076, iter [00050, 01251], lr: 0.000323, loss: 2.5064
2022-10-08 21:43:24 - train: epoch 0076, iter [00060, 01251], lr: 0.000322, loss: 2.2715
2022-10-08 21:43:46 - train: epoch 0076, iter [00070, 01251], lr: 0.000322, loss: 3.0706
2022-10-08 21:44:07 - train: epoch 0076, iter [00080, 01251], lr: 0.000322, loss: 2.9217
2022-10-08 21:44:28 - train: epoch 0076, iter [00090, 01251], lr: 0.000322, loss: 3.0393
2022-10-08 21:44:49 - train: epoch 0076, iter [00100, 01251], lr: 0.000322, loss: 3.3635
2022-10-08 21:45:10 - train: epoch 0076, iter [00110, 01251], lr: 0.000321, loss: 2.9736
2022-10-08 21:45:32 - train: epoch 0076, iter [00120, 01251], lr: 0.000321, loss: 2.8602
2022-10-08 21:45:53 - train: epoch 0076, iter [00130, 01251], lr: 0.000321, loss: 2.9126
2022-10-08 21:46:14 - train: epoch 0076, iter [00140, 01251], lr: 0.000321, loss: 2.0199
2022-10-08 21:46:35 - train: epoch 0076, iter [00150, 01251], lr: 0.000321, loss: 3.3553
2022-10-08 21:46:57 - train: epoch 0076, iter [00160, 01251], lr: 0.000320, loss: 2.0667
2022-10-08 21:47:18 - train: epoch 0076, iter [00170, 01251], lr: 0.000320, loss: 2.7666
2022-10-08 21:47:39 - train: epoch 0076, iter [00180, 01251], lr: 0.000320, loss: 2.9936
2022-10-08 21:48:00 - train: epoch 0076, iter [00190, 01251], lr: 0.000320, loss: 2.8352
2022-10-08 21:48:21 - train: epoch 0076, iter [00200, 01251], lr: 0.000320, loss: 3.2767
2022-10-08 21:48:42 - train: epoch 0076, iter [00210, 01251], lr: 0.000319, loss: 3.2414
2022-10-08 21:49:04 - train: epoch 0076, iter [00220, 01251], lr: 0.000319, loss: 2.1671
2022-10-08 21:49:25 - train: epoch 0076, iter [00230, 01251], lr: 0.000319, loss: 2.8851
2022-10-08 21:49:46 - train: epoch 0076, iter [00240, 01251], lr: 0.000319, loss: 2.5523
2022-10-08 21:50:07 - train: epoch 0076, iter [00250, 01251], lr: 0.000319, loss: 3.2021
2022-10-08 21:50:28 - train: epoch 0076, iter [00260, 01251], lr: 0.000319, loss: 2.8665
2022-10-08 21:50:49 - train: epoch 0076, iter [00270, 01251], lr: 0.000318, loss: 3.0519
2022-10-08 21:51:10 - train: epoch 0076, iter [00280, 01251], lr: 0.000318, loss: 2.9961
2022-10-08 21:51:31 - train: epoch 0076, iter [00290, 01251], lr: 0.000318, loss: 3.3293
2022-10-08 21:51:52 - train: epoch 0076, iter [00300, 01251], lr: 0.000318, loss: 2.9618
2022-10-08 21:52:13 - train: epoch 0076, iter [00310, 01251], lr: 0.000318, loss: 2.9618
2022-10-08 21:52:34 - train: epoch 0076, iter [00320, 01251], lr: 0.000317, loss: 3.3274
2022-10-08 21:52:56 - train: epoch 0076, iter [00330, 01251], lr: 0.000317, loss: 2.9694
2022-10-08 21:53:17 - train: epoch 0076, iter [00340, 01251], lr: 0.000317, loss: 2.7922
2022-10-08 21:53:38 - train: epoch 0076, iter [00350, 01251], lr: 0.000317, loss: 3.1971
2022-10-08 21:53:59 - train: epoch 0076, iter [00360, 01251], lr: 0.000317, loss: 2.3894
2022-10-08 21:54:20 - train: epoch 0076, iter [00370, 01251], lr: 0.000316, loss: 3.3943
2022-10-08 21:54:41 - train: epoch 0076, iter [00380, 01251], lr: 0.000316, loss: 3.1149
2022-10-08 21:55:02 - train: epoch 0076, iter [00390, 01251], lr: 0.000316, loss: 2.6795
2022-10-08 21:55:23 - train: epoch 0076, iter [00400, 01251], lr: 0.000316, loss: 3.0347
2022-10-08 21:55:44 - train: epoch 0076, iter [00410, 01251], lr: 0.000316, loss: 3.1367
2022-10-08 21:56:05 - train: epoch 0076, iter [00420, 01251], lr: 0.000315, loss: 2.6683
2022-10-08 21:56:26 - train: epoch 0076, iter [00430, 01251], lr: 0.000315, loss: 2.5328
2022-10-08 21:56:47 - train: epoch 0076, iter [00440, 01251], lr: 0.000315, loss: 2.3913
2022-10-08 21:57:09 - train: epoch 0076, iter [00450, 01251], lr: 0.000315, loss: 2.6637
2022-10-08 21:57:30 - train: epoch 0076, iter [00460, 01251], lr: 0.000315, loss: 2.5434
2022-10-08 21:57:51 - train: epoch 0076, iter [00470, 01251], lr: 0.000314, loss: 3.0587
2022-10-08 21:58:12 - train: epoch 0076, iter [00480, 01251], lr: 0.000314, loss: 2.8890
2022-10-08 21:58:33 - train: epoch 0076, iter [00490, 01251], lr: 0.000314, loss: 2.7552
2022-10-08 21:58:54 - train: epoch 0076, iter [00500, 01251], lr: 0.000314, loss: 3.1994
2022-10-08 21:59:15 - train: epoch 0076, iter [00510, 01251], lr: 0.000314, loss: 2.9036
2022-10-08 21:59:36 - train: epoch 0076, iter [00520, 01251], lr: 0.000314, loss: 3.0659
2022-10-08 21:59:58 - train: epoch 0076, iter [00530, 01251], lr: 0.000313, loss: 2.4371
2022-10-08 22:00:19 - train: epoch 0076, iter [00540, 01251], lr: 0.000313, loss: 2.6128
2022-10-08 22:00:40 - train: epoch 0076, iter [00550, 01251], lr: 0.000313, loss: 2.6517
2022-10-08 22:01:01 - train: epoch 0076, iter [00560, 01251], lr: 0.000313, loss: 2.8575
2022-10-08 22:01:22 - train: epoch 0076, iter [00570, 01251], lr: 0.000313, loss: 2.8113
2022-10-08 22:01:43 - train: epoch 0076, iter [00580, 01251], lr: 0.000312, loss: 2.9006
2022-10-08 22:02:04 - train: epoch 0076, iter [00590, 01251], lr: 0.000312, loss: 2.8118
2022-10-08 22:02:25 - train: epoch 0076, iter [00600, 01251], lr: 0.000312, loss: 2.8830
2022-10-08 22:02:47 - train: epoch 0076, iter [00610, 01251], lr: 0.000312, loss: 3.1003
2022-10-08 22:03:08 - train: epoch 0076, iter [00620, 01251], lr: 0.000312, loss: 3.1697
2022-10-08 22:03:29 - train: epoch 0076, iter [00630, 01251], lr: 0.000311, loss: 2.9254
2022-10-08 22:03:50 - train: epoch 0076, iter [00640, 01251], lr: 0.000311, loss: 2.4990
2022-10-08 22:04:11 - train: epoch 0076, iter [00650, 01251], lr: 0.000311, loss: 3.2399
2022-10-08 22:04:32 - train: epoch 0076, iter [00660, 01251], lr: 0.000311, loss: 2.3958
2022-10-08 22:04:53 - train: epoch 0076, iter [00670, 01251], lr: 0.000311, loss: 2.7564
2022-10-08 22:05:14 - train: epoch 0076, iter [00680, 01251], lr: 0.000310, loss: 3.2914
2022-10-08 22:05:35 - train: epoch 0076, iter [00690, 01251], lr: 0.000310, loss: 2.7181
2022-10-08 22:05:56 - train: epoch 0076, iter [00700, 01251], lr: 0.000310, loss: 2.1202
2022-10-08 22:06:17 - train: epoch 0076, iter [00710, 01251], lr: 0.000310, loss: 2.6222
2022-10-08 22:06:38 - train: epoch 0076, iter [00720, 01251], lr: 0.000310, loss: 3.0792
2022-10-08 22:06:59 - train: epoch 0076, iter [00730, 01251], lr: 0.000309, loss: 2.7174
2022-10-08 22:07:20 - train: epoch 0076, iter [00740, 01251], lr: 0.000309, loss: 3.1439
2022-10-08 22:07:41 - train: epoch 0076, iter [00750, 01251], lr: 0.000309, loss: 3.1250
2022-10-08 22:08:02 - train: epoch 0076, iter [00760, 01251], lr: 0.000309, loss: 3.1088
2022-10-08 22:08:23 - train: epoch 0076, iter [00770, 01251], lr: 0.000309, loss: 3.2641
2022-10-08 22:08:44 - train: epoch 0076, iter [00780, 01251], lr: 0.000309, loss: 3.1793
2022-10-08 22:09:05 - train: epoch 0076, iter [00790, 01251], lr: 0.000308, loss: 3.2347
2022-10-08 22:09:26 - train: epoch 0076, iter [00800, 01251], lr: 0.000308, loss: 3.0781
2022-10-08 22:09:47 - train: epoch 0076, iter [00810, 01251], lr: 0.000308, loss: 2.8046
2022-10-08 22:10:08 - train: epoch 0076, iter [00820, 01251], lr: 0.000308, loss: 2.9879
2022-10-08 22:10:29 - train: epoch 0076, iter [00830, 01251], lr: 0.000308, loss: 3.0341
2022-10-08 22:10:51 - train: epoch 0076, iter [00840, 01251], lr: 0.000307, loss: 2.7764
2022-10-08 22:11:12 - train: epoch 0076, iter [00850, 01251], lr: 0.000307, loss: 3.0665
2022-10-08 22:11:33 - train: epoch 0076, iter [00860, 01251], lr: 0.000307, loss: 3.0468
2022-10-08 22:11:54 - train: epoch 0076, iter [00870, 01251], lr: 0.000307, loss: 2.2211
2022-10-08 22:12:15 - train: epoch 0076, iter [00880, 01251], lr: 0.000307, loss: 2.8551
2022-10-08 22:12:36 - train: epoch 0076, iter [00890, 01251], lr: 0.000306, loss: 3.1347
2022-10-08 22:12:57 - train: epoch 0076, iter [00900, 01251], lr: 0.000306, loss: 3.0110
2022-10-08 22:13:18 - train: epoch 0076, iter [00910, 01251], lr: 0.000306, loss: 2.7450
2022-10-08 22:13:39 - train: epoch 0076, iter [00920, 01251], lr: 0.000306, loss: 2.8052
2022-10-08 22:14:00 - train: epoch 0076, iter [00930, 01251], lr: 0.000306, loss: 3.1087
2022-10-08 22:14:21 - train: epoch 0076, iter [00940, 01251], lr: 0.000305, loss: 3.1551
2022-10-08 22:14:42 - train: epoch 0076, iter [00950, 01251], lr: 0.000305, loss: 3.0988
2022-10-08 22:15:03 - train: epoch 0076, iter [00960, 01251], lr: 0.000305, loss: 3.0761
2022-10-08 22:15:24 - train: epoch 0076, iter [00970, 01251], lr: 0.000305, loss: 3.1413
2022-10-08 22:15:45 - train: epoch 0076, iter [00980, 01251], lr: 0.000305, loss: 3.1744
2022-10-08 22:16:06 - train: epoch 0076, iter [00990, 01251], lr: 0.000305, loss: 2.6979
2022-10-08 22:16:27 - train: epoch 0076, iter [01000, 01251], lr: 0.000304, loss: 3.2321
2022-10-08 22:16:49 - train: epoch 0076, iter [01010, 01251], lr: 0.000304, loss: 2.6854
2022-10-08 22:17:09 - train: epoch 0076, iter [01020, 01251], lr: 0.000304, loss: 3.0147
2022-10-08 22:17:30 - train: epoch 0076, iter [01030, 01251], lr: 0.000304, loss: 3.1622
2022-10-08 22:17:51 - train: epoch 0076, iter [01040, 01251], lr: 0.000304, loss: 3.1675
2022-10-08 22:18:13 - train: epoch 0076, iter [01050, 01251], lr: 0.000303, loss: 2.6475
2022-10-08 22:18:34 - train: epoch 0076, iter [01060, 01251], lr: 0.000303, loss: 3.1416
2022-10-08 22:18:55 - train: epoch 0076, iter [01070, 01251], lr: 0.000303, loss: 3.2241
2022-10-08 22:19:16 - train: epoch 0076, iter [01080, 01251], lr: 0.000303, loss: 2.8137
2022-10-08 22:19:37 - train: epoch 0076, iter [01090, 01251], lr: 0.000303, loss: 2.8100
2022-10-08 22:19:58 - train: epoch 0076, iter [01100, 01251], lr: 0.000302, loss: 2.6975
2022-10-08 22:20:19 - train: epoch 0076, iter [01110, 01251], lr: 0.000302, loss: 3.0125
2022-10-08 22:20:40 - train: epoch 0076, iter [01120, 01251], lr: 0.000302, loss: 2.5711
2022-10-08 22:21:01 - train: epoch 0076, iter [01130, 01251], lr: 0.000302, loss: 2.6886
2022-10-08 22:21:22 - train: epoch 0076, iter [01140, 01251], lr: 0.000302, loss: 2.9231
2022-10-08 22:21:43 - train: epoch 0076, iter [01150, 01251], lr: 0.000302, loss: 2.8454
2022-10-08 22:22:04 - train: epoch 0076, iter [01160, 01251], lr: 0.000301, loss: 3.0160
2022-10-08 22:22:25 - train: epoch 0076, iter [01170, 01251], lr: 0.000301, loss: 2.7535
2022-10-08 22:22:46 - train: epoch 0076, iter [01180, 01251], lr: 0.000301, loss: 2.9758
2022-10-08 22:23:07 - train: epoch 0076, iter [01190, 01251], lr: 0.000301, loss: 3.0179
2022-10-08 22:23:29 - train: epoch 0076, iter [01200, 01251], lr: 0.000301, loss: 2.8574
2022-10-08 22:23:50 - train: epoch 0076, iter [01210, 01251], lr: 0.000300, loss: 3.0785
2022-10-08 22:24:11 - train: epoch 0076, iter [01220, 01251], lr: 0.000300, loss: 2.7859
2022-10-08 22:24:32 - train: epoch 0076, iter [01230, 01251], lr: 0.000300, loss: 3.0309
2022-10-08 22:24:53 - train: epoch 0076, iter [01240, 01251], lr: 0.000300, loss: 2.3558
2022-10-08 22:25:14 - train: epoch 0076, iter [01250, 01251], lr: 0.000300, loss: 2.2022
2022-10-08 22:25:18 - train: epoch 076, train_loss: 2.8575
2022-10-08 22:26:34 - eval: epoch: 076, acc1: 82.514%, acc5: 96.382%, test_loss: 0.7727, per_image_load_time: 1.148ms, per_image_inference_time: 1.447ms
2022-10-08 22:26:36 - until epoch: 076, best_acc1: 82.514%
2022-10-08 22:26:36 - epoch 077 lr: 0.000300
2022-10-08 22:27:03 - train: epoch 0077, iter [00010, 01251], lr: 0.000299, loss: 2.2583
2022-10-08 22:27:24 - train: epoch 0077, iter [00020, 01251], lr: 0.000299, loss: 2.5697
2022-10-08 22:27:45 - train: epoch 0077, iter [00030, 01251], lr: 0.000299, loss: 3.0688
2022-10-08 22:28:06 - train: epoch 0077, iter [00040, 01251], lr: 0.000299, loss: 2.8870
2022-10-08 22:28:27 - train: epoch 0077, iter [00050, 01251], lr: 0.000299, loss: 2.6905
2022-10-08 22:28:48 - train: epoch 0077, iter [00060, 01251], lr: 0.000298, loss: 1.8127
2022-10-08 22:29:09 - train: epoch 0077, iter [00070, 01251], lr: 0.000298, loss: 2.6938
2022-10-08 22:29:30 - train: epoch 0077, iter [00080, 01251], lr: 0.000298, loss: 2.9443
2022-10-08 22:29:52 - train: epoch 0077, iter [00090, 01251], lr: 0.000298, loss: 2.9584
2022-10-08 22:30:13 - train: epoch 0077, iter [00100, 01251], lr: 0.000298, loss: 2.8421
2022-10-08 22:30:34 - train: epoch 0077, iter [00110, 01251], lr: 0.000298, loss: 2.6840
2022-10-08 22:30:55 - train: epoch 0077, iter [00120, 01251], lr: 0.000297, loss: 3.1298
2022-10-08 22:31:16 - train: epoch 0077, iter [00130, 01251], lr: 0.000297, loss: 2.5599
2022-10-08 22:31:38 - train: epoch 0077, iter [00140, 01251], lr: 0.000297, loss: 2.7777
2022-10-08 22:31:59 - train: epoch 0077, iter [00150, 01251], lr: 0.000297, loss: 2.8614
2022-10-08 22:32:20 - train: epoch 0077, iter [00160, 01251], lr: 0.000297, loss: 2.8220
2022-10-08 22:32:41 - train: epoch 0077, iter [00170, 01251], lr: 0.000296, loss: 3.0106
2022-10-08 22:33:02 - train: epoch 0077, iter [00180, 01251], lr: 0.000296, loss: 2.8152
2022-10-08 22:33:24 - train: epoch 0077, iter [00190, 01251], lr: 0.000296, loss: 3.1943
2022-10-08 22:33:45 - train: epoch 0077, iter [00200, 01251], lr: 0.000296, loss: 2.7498
2022-10-08 22:34:06 - train: epoch 0077, iter [00210, 01251], lr: 0.000296, loss: 2.4571
2022-10-08 22:34:27 - train: epoch 0077, iter [00220, 01251], lr: 0.000295, loss: 3.0906
2022-10-08 22:34:48 - train: epoch 0077, iter [00230, 01251], lr: 0.000295, loss: 3.0972
2022-10-08 22:35:09 - train: epoch 0077, iter [00240, 01251], lr: 0.000295, loss: 2.5251
2022-10-08 22:35:30 - train: epoch 0077, iter [00250, 01251], lr: 0.000295, loss: 2.5860
2022-10-08 22:35:51 - train: epoch 0077, iter [00260, 01251], lr: 0.000295, loss: 3.1908
2022-10-08 22:36:12 - train: epoch 0077, iter [00270, 01251], lr: 0.000295, loss: 2.8324
2022-10-08 22:36:33 - train: epoch 0077, iter [00280, 01251], lr: 0.000294, loss: 3.1590
2022-10-08 22:36:54 - train: epoch 0077, iter [00290, 01251], lr: 0.000294, loss: 3.2803
2022-10-08 22:37:15 - train: epoch 0077, iter [00300, 01251], lr: 0.000294, loss: 2.1873
2022-10-08 22:37:37 - train: epoch 0077, iter [00310, 01251], lr: 0.000294, loss: 3.0001
2022-10-08 22:37:58 - train: epoch 0077, iter [00320, 01251], lr: 0.000294, loss: 3.0912
2022-10-08 22:38:19 - train: epoch 0077, iter [00330, 01251], lr: 0.000293, loss: 3.1155
2022-10-08 22:38:40 - train: epoch 0077, iter [00340, 01251], lr: 0.000293, loss: 2.7132
2022-10-08 22:39:01 - train: epoch 0077, iter [00350, 01251], lr: 0.000293, loss: 2.8396
2022-10-08 22:39:22 - train: epoch 0077, iter [00360, 01251], lr: 0.000293, loss: 2.6168
2022-10-08 22:39:43 - train: epoch 0077, iter [00370, 01251], lr: 0.000293, loss: 2.4397
2022-10-08 22:40:04 - train: epoch 0077, iter [00380, 01251], lr: 0.000292, loss: 3.2072
2022-10-08 22:40:25 - train: epoch 0077, iter [00390, 01251], lr: 0.000292, loss: 2.7238
2022-10-08 22:40:46 - train: epoch 0077, iter [00400, 01251], lr: 0.000292, loss: 2.7921
2022-10-08 22:41:07 - train: epoch 0077, iter [00410, 01251], lr: 0.000292, loss: 3.0834
2022-10-08 22:41:28 - train: epoch 0077, iter [00420, 01251], lr: 0.000292, loss: 3.0257
2022-10-08 22:41:49 - train: epoch 0077, iter [00430, 01251], lr: 0.000292, loss: 3.1222
2022-10-08 22:42:10 - train: epoch 0077, iter [00440, 01251], lr: 0.000291, loss: 2.3594
2022-10-08 22:42:31 - train: epoch 0077, iter [00450, 01251], lr: 0.000291, loss: 2.1938
2022-10-08 22:42:52 - train: epoch 0077, iter [00460, 01251], lr: 0.000291, loss: 3.0403
2022-10-08 22:43:13 - train: epoch 0077, iter [00470, 01251], lr: 0.000291, loss: 2.5481
2022-10-08 22:43:35 - train: epoch 0077, iter [00480, 01251], lr: 0.000291, loss: 2.8301
2022-10-08 22:43:56 - train: epoch 0077, iter [00490, 01251], lr: 0.000290, loss: 2.9396
2022-10-08 22:44:17 - train: epoch 0077, iter [00500, 01251], lr: 0.000290, loss: 2.6453
2022-10-08 22:44:38 - train: epoch 0077, iter [00510, 01251], lr: 0.000290, loss: 3.3452
2022-10-08 22:44:59 - train: epoch 0077, iter [00520, 01251], lr: 0.000290, loss: 3.3294
2022-10-08 22:45:20 - train: epoch 0077, iter [00530, 01251], lr: 0.000290, loss: 2.6994
2022-10-08 22:45:41 - train: epoch 0077, iter [00540, 01251], lr: 0.000290, loss: 2.7325
2022-10-08 22:46:02 - train: epoch 0077, iter [00550, 01251], lr: 0.000289, loss: 2.8684
2022-10-08 22:46:23 - train: epoch 0077, iter [00560, 01251], lr: 0.000289, loss: 3.0004
2022-10-08 22:46:44 - train: epoch 0077, iter [00570, 01251], lr: 0.000289, loss: 3.0112
2022-10-08 22:47:05 - train: epoch 0077, iter [00580, 01251], lr: 0.000289, loss: 2.5526
2022-10-08 22:47:26 - train: epoch 0077, iter [00590, 01251], lr: 0.000289, loss: 3.1223
2022-10-08 22:47:47 - train: epoch 0077, iter [00600, 01251], lr: 0.000288, loss: 3.1101
2022-10-08 22:48:08 - train: epoch 0077, iter [00610, 01251], lr: 0.000288, loss: 3.2644
2022-10-08 22:48:29 - train: epoch 0077, iter [00620, 01251], lr: 0.000288, loss: 2.7528
2022-10-08 22:48:50 - train: epoch 0077, iter [00630, 01251], lr: 0.000288, loss: 2.9715
2022-10-08 22:49:11 - train: epoch 0077, iter [00640, 01251], lr: 0.000288, loss: 3.3389
2022-10-08 22:49:32 - train: epoch 0077, iter [00650, 01251], lr: 0.000287, loss: 3.2419
2022-10-08 22:49:53 - train: epoch 0077, iter [00660, 01251], lr: 0.000287, loss: 2.9676
2022-10-08 22:50:14 - train: epoch 0077, iter [00670, 01251], lr: 0.000287, loss: 2.4100
2022-10-08 22:50:35 - train: epoch 0077, iter [00680, 01251], lr: 0.000287, loss: 2.8745
2022-10-08 22:50:56 - train: epoch 0077, iter [00690, 01251], lr: 0.000287, loss: 3.0445
2022-10-08 22:51:17 - train: epoch 0077, iter [00700, 01251], lr: 0.000287, loss: 2.7087
2022-10-08 22:51:38 - train: epoch 0077, iter [00710, 01251], lr: 0.000286, loss: 3.1202
2022-10-08 22:51:59 - train: epoch 0077, iter [00720, 01251], lr: 0.000286, loss: 3.3938
2022-10-08 22:52:20 - train: epoch 0077, iter [00730, 01251], lr: 0.000286, loss: 2.6480
2022-10-08 22:52:42 - train: epoch 0077, iter [00740, 01251], lr: 0.000286, loss: 2.9387
2022-10-08 22:53:03 - train: epoch 0077, iter [00750, 01251], lr: 0.000286, loss: 2.8012
2022-10-08 22:53:24 - train: epoch 0077, iter [00760, 01251], lr: 0.000285, loss: 2.8545
2022-10-08 22:53:45 - train: epoch 0077, iter [00770, 01251], lr: 0.000285, loss: 2.6501
2022-10-08 22:54:06 - train: epoch 0077, iter [00780, 01251], lr: 0.000285, loss: 2.1381
2022-10-08 22:54:27 - train: epoch 0077, iter [00790, 01251], lr: 0.000285, loss: 3.1104
2022-10-08 22:54:48 - train: epoch 0077, iter [00800, 01251], lr: 0.000285, loss: 2.9574
2022-10-08 22:55:09 - train: epoch 0077, iter [00810, 01251], lr: 0.000285, loss: 2.9502
2022-10-08 22:55:30 - train: epoch 0077, iter [00820, 01251], lr: 0.000284, loss: 3.3100
2022-10-08 22:55:51 - train: epoch 0077, iter [00830, 01251], lr: 0.000284, loss: 3.1490
2022-10-08 22:56:12 - train: epoch 0077, iter [00840, 01251], lr: 0.000284, loss: 2.2689
2022-10-08 22:56:33 - train: epoch 0077, iter [00850, 01251], lr: 0.000284, loss: 2.8191
2022-10-08 22:56:54 - train: epoch 0077, iter [00860, 01251], lr: 0.000284, loss: 2.8870
2022-10-08 22:57:15 - train: epoch 0077, iter [00870, 01251], lr: 0.000283, loss: 3.0255
2022-10-08 22:57:36 - train: epoch 0077, iter [00880, 01251], lr: 0.000283, loss: 3.0362
2022-10-08 22:57:57 - train: epoch 0077, iter [00890, 01251], lr: 0.000283, loss: 3.1824
2022-10-08 22:58:18 - train: epoch 0077, iter [00900, 01251], lr: 0.000283, loss: 2.8158
2022-10-08 22:58:40 - train: epoch 0077, iter [00910, 01251], lr: 0.000283, loss: 2.6121
2022-10-08 22:59:01 - train: epoch 0077, iter [00920, 01251], lr: 0.000282, loss: 2.9881
2022-10-08 22:59:21 - train: epoch 0077, iter [00930, 01251], lr: 0.000282, loss: 2.8226
2022-10-08 22:59:43 - train: epoch 0077, iter [00940, 01251], lr: 0.000282, loss: 3.1915
2022-10-08 23:00:04 - train: epoch 0077, iter [00950, 01251], lr: 0.000282, loss: 2.7019
2022-10-08 23:00:25 - train: epoch 0077, iter [00960, 01251], lr: 0.000282, loss: 2.2261
2022-10-08 23:00:46 - train: epoch 0077, iter [00970, 01251], lr: 0.000282, loss: 2.5417
2022-10-08 23:01:07 - train: epoch 0077, iter [00980, 01251], lr: 0.000281, loss: 2.9066
2022-10-08 23:01:28 - train: epoch 0077, iter [00990, 01251], lr: 0.000281, loss: 2.5251
2022-10-08 23:01:49 - train: epoch 0077, iter [01000, 01251], lr: 0.000281, loss: 2.8894
2022-10-08 23:02:10 - train: epoch 0077, iter [01010, 01251], lr: 0.000281, loss: 2.5184
2022-10-08 23:02:31 - train: epoch 0077, iter [01020, 01251], lr: 0.000281, loss: 2.9999
2022-10-08 23:02:52 - train: epoch 0077, iter [01030, 01251], lr: 0.000280, loss: 2.8665
2022-10-08 23:03:13 - train: epoch 0077, iter [01040, 01251], lr: 0.000280, loss: 2.6370
2022-10-08 23:03:34 - train: epoch 0077, iter [01050, 01251], lr: 0.000280, loss: 2.9676
2022-10-08 23:03:55 - train: epoch 0077, iter [01060, 01251], lr: 0.000280, loss: 2.2812
2022-10-08 23:04:16 - train: epoch 0077, iter [01070, 01251], lr: 0.000280, loss: 2.8503
2022-10-08 23:04:37 - train: epoch 0077, iter [01080, 01251], lr: 0.000280, loss: 3.0533
2022-10-08 23:04:58 - train: epoch 0077, iter [01090, 01251], lr: 0.000279, loss: 2.9059
2022-10-08 23:05:19 - train: epoch 0077, iter [01100, 01251], lr: 0.000279, loss: 3.0445
2022-10-08 23:05:40 - train: epoch 0077, iter [01110, 01251], lr: 0.000279, loss: 2.8797
2022-10-08 23:06:01 - train: epoch 0077, iter [01120, 01251], lr: 0.000279, loss: 2.7101
2022-10-08 23:06:22 - train: epoch 0077, iter [01130, 01251], lr: 0.000279, loss: 3.0589
2022-10-08 23:06:43 - train: epoch 0077, iter [01140, 01251], lr: 0.000278, loss: 2.4106
2022-10-08 23:07:04 - train: epoch 0077, iter [01150, 01251], lr: 0.000278, loss: 2.8172
2022-10-08 23:07:25 - train: epoch 0077, iter [01160, 01251], lr: 0.000278, loss: 2.9379
2022-10-08 23:07:46 - train: epoch 0077, iter [01170, 01251], lr: 0.000278, loss: 3.2347
2022-10-08 23:08:08 - train: epoch 0077, iter [01180, 01251], lr: 0.000278, loss: 2.9094
2022-10-08 23:08:29 - train: epoch 0077, iter [01190, 01251], lr: 0.000278, loss: 2.6450
2022-10-08 23:08:50 - train: epoch 0077, iter [01200, 01251], lr: 0.000277, loss: 2.5342
2022-10-08 23:09:11 - train: epoch 0077, iter [01210, 01251], lr: 0.000277, loss: 3.1877
2022-10-08 23:09:32 - train: epoch 0077, iter [01220, 01251], lr: 0.000277, loss: 2.8874
2022-10-08 23:09:53 - train: epoch 0077, iter [01230, 01251], lr: 0.000277, loss: 3.2723
2022-10-08 23:10:14 - train: epoch 0077, iter [01240, 01251], lr: 0.000277, loss: 2.9285
2022-10-08 23:10:35 - train: epoch 0077, iter [01250, 01251], lr: 0.000276, loss: 2.3840
2022-10-08 23:10:39 - train: epoch 077, train_loss: 2.8497
2022-10-08 23:11:55 - eval: epoch: 077, acc1: 82.522%, acc5: 96.380%, test_loss: 0.7726, per_image_load_time: 1.147ms, per_image_inference_time: 1.437ms
2022-10-08 23:11:56 - until epoch: 077, best_acc1: 82.522%
2022-10-08 23:11:56 - epoch 078 lr: 0.000276
2022-10-08 23:12:23 - train: epoch 0078, iter [00010, 01251], lr: 0.000276, loss: 2.7430
2022-10-08 23:12:44 - train: epoch 0078, iter [00020, 01251], lr: 0.000276, loss: 2.9791
2022-10-08 23:13:05 - train: epoch 0078, iter [00030, 01251], lr: 0.000276, loss: 2.2642
2022-10-08 23:13:26 - train: epoch 0078, iter [00040, 01251], lr: 0.000276, loss: 2.2726
2022-10-08 23:13:47 - train: epoch 0078, iter [00050, 01251], lr: 0.000276, loss: 3.1699
2022-10-08 23:14:08 - train: epoch 0078, iter [00060, 01251], lr: 0.000275, loss: 2.9766
2022-10-08 23:14:29 - train: epoch 0078, iter [00070, 01251], lr: 0.000275, loss: 2.5147
2022-10-08 23:14:50 - train: epoch 0078, iter [00080, 01251], lr: 0.000275, loss: 2.5000
2022-10-08 23:15:11 - train: epoch 0078, iter [00090, 01251], lr: 0.000275, loss: 3.1154
2022-10-08 23:15:32 - train: epoch 0078, iter [00100, 01251], lr: 0.000275, loss: 2.5419
2022-10-08 23:15:53 - train: epoch 0078, iter [00110, 01251], lr: 0.000274, loss: 3.2178
2022-10-08 23:16:14 - train: epoch 0078, iter [00120, 01251], lr: 0.000274, loss: 2.8247
2022-10-08 23:16:35 - train: epoch 0078, iter [00130, 01251], lr: 0.000274, loss: 2.5733
2022-10-08 23:16:56 - train: epoch 0078, iter [00140, 01251], lr: 0.000274, loss: 2.4950
2022-10-08 23:17:17 - train: epoch 0078, iter [00150, 01251], lr: 0.000274, loss: 3.3587
2022-10-08 23:17:39 - train: epoch 0078, iter [00160, 01251], lr: 0.000274, loss: 3.2151
2022-10-08 23:18:00 - train: epoch 0078, iter [00170, 01251], lr: 0.000273, loss: 2.7169
2022-10-08 23:18:21 - train: epoch 0078, iter [00180, 01251], lr: 0.000273, loss: 2.4379
2022-10-08 23:18:42 - train: epoch 0078, iter [00190, 01251], lr: 0.000273, loss: 2.9131
2022-10-08 23:19:03 - train: epoch 0078, iter [00200, 01251], lr: 0.000273, loss: 2.4073
2022-10-08 23:19:24 - train: epoch 0078, iter [00210, 01251], lr: 0.000273, loss: 3.2145
2022-10-08 23:19:45 - train: epoch 0078, iter [00220, 01251], lr: 0.000272, loss: 2.7440
2022-10-08 23:20:06 - train: epoch 0078, iter [00230, 01251], lr: 0.000272, loss: 3.1487
2022-10-08 23:20:27 - train: epoch 0078, iter [00240, 01251], lr: 0.000272, loss: 2.2920
2022-10-08 23:20:48 - train: epoch 0078, iter [00250, 01251], lr: 0.000272, loss: 3.0564
2022-10-08 23:21:09 - train: epoch 0078, iter [00260, 01251], lr: 0.000272, loss: 2.8421
2022-10-08 23:21:30 - train: epoch 0078, iter [00270, 01251], lr: 0.000272, loss: 2.6824
2022-10-08 23:21:51 - train: epoch 0078, iter [00280, 01251], lr: 0.000271, loss: 2.4470
2022-10-08 23:22:12 - train: epoch 0078, iter [00290, 01251], lr: 0.000271, loss: 3.1231
2022-10-08 23:22:33 - train: epoch 0078, iter [00300, 01251], lr: 0.000271, loss: 2.6585
2022-10-08 23:22:54 - train: epoch 0078, iter [00310, 01251], lr: 0.000271, loss: 3.2269
2022-10-08 23:23:15 - train: epoch 0078, iter [00320, 01251], lr: 0.000271, loss: 2.3443
2022-10-08 23:23:36 - train: epoch 0078, iter [00330, 01251], lr: 0.000270, loss: 2.4730
2022-10-08 23:23:57 - train: epoch 0078, iter [00340, 01251], lr: 0.000270, loss: 3.1337
2022-10-08 23:24:19 - train: epoch 0078, iter [00350, 01251], lr: 0.000270, loss: 2.8256
2022-10-08 23:24:40 - train: epoch 0078, iter [00360, 01251], lr: 0.000270, loss: 2.5326
2022-10-08 23:25:01 - train: epoch 0078, iter [00370, 01251], lr: 0.000270, loss: 3.0817
2022-10-08 23:25:22 - train: epoch 0078, iter [00380, 01251], lr: 0.000270, loss: 3.0971
2022-10-08 23:25:43 - train: epoch 0078, iter [00390, 01251], lr: 0.000269, loss: 2.9142
2022-10-08 23:26:04 - train: epoch 0078, iter [00400, 01251], lr: 0.000269, loss: 2.2961
2022-10-08 23:26:25 - train: epoch 0078, iter [00410, 01251], lr: 0.000269, loss: 3.2335
2022-10-08 23:26:46 - train: epoch 0078, iter [00420, 01251], lr: 0.000269, loss: 2.5874
2022-10-08 23:27:07 - train: epoch 0078, iter [00430, 01251], lr: 0.000269, loss: 2.5326
2022-10-08 23:27:28 - train: epoch 0078, iter [00440, 01251], lr: 0.000268, loss: 3.2056
2022-10-08 23:27:49 - train: epoch 0078, iter [00450, 01251], lr: 0.000268, loss: 3.1158
2022-10-08 23:28:10 - train: epoch 0078, iter [00460, 01251], lr: 0.000268, loss: 2.4654
2022-10-08 23:28:31 - train: epoch 0078, iter [00470, 01251], lr: 0.000268, loss: 3.3750
2022-10-08 23:28:52 - train: epoch 0078, iter [00480, 01251], lr: 0.000268, loss: 3.0276
2022-10-08 23:29:13 - train: epoch 0078, iter [00490, 01251], lr: 0.000268, loss: 3.1147
2022-10-08 23:29:34 - train: epoch 0078, iter [00500, 01251], lr: 0.000267, loss: 2.8592
2022-10-08 23:29:55 - train: epoch 0078, iter [00510, 01251], lr: 0.000267, loss: 2.1687
2022-10-08 23:30:16 - train: epoch 0078, iter [00520, 01251], lr: 0.000267, loss: 2.5260
2022-10-08 23:30:37 - train: epoch 0078, iter [00530, 01251], lr: 0.000267, loss: 2.7733
2022-10-08 23:30:58 - train: epoch 0078, iter [00540, 01251], lr: 0.000267, loss: 2.8508
2022-10-08 23:31:19 - train: epoch 0078, iter [00550, 01251], lr: 0.000266, loss: 3.1060
2022-10-08 23:31:40 - train: epoch 0078, iter [00560, 01251], lr: 0.000266, loss: 3.2263
2022-10-08 23:32:01 - train: epoch 0078, iter [00570, 01251], lr: 0.000266, loss: 2.5900
2022-10-08 23:32:22 - train: epoch 0078, iter [00580, 01251], lr: 0.000266, loss: 3.1055
2022-10-08 23:32:43 - train: epoch 0078, iter [00590, 01251], lr: 0.000266, loss: 2.7052
2022-10-08 23:33:04 - train: epoch 0078, iter [00600, 01251], lr: 0.000266, loss: 2.9668
2022-10-08 23:33:25 - train: epoch 0078, iter [00610, 01251], lr: 0.000265, loss: 2.7411
2022-10-08 23:33:46 - train: epoch 0078, iter [00620, 01251], lr: 0.000265, loss: 2.7099
2022-10-08 23:34:07 - train: epoch 0078, iter [00630, 01251], lr: 0.000265, loss: 2.8514
2022-10-08 23:34:28 - train: epoch 0078, iter [00640, 01251], lr: 0.000265, loss: 2.5183
2022-10-08 23:34:49 - train: epoch 0078, iter [00650, 01251], lr: 0.000265, loss: 3.1255
2022-10-08 23:35:10 - train: epoch 0078, iter [00660, 01251], lr: 0.000265, loss: 2.5231
2022-10-08 23:35:31 - train: epoch 0078, iter [00670, 01251], lr: 0.000264, loss: 2.5012
2022-10-08 23:35:52 - train: epoch 0078, iter [00680, 01251], lr: 0.000264, loss: 2.7287
2022-10-08 23:36:13 - train: epoch 0078, iter [00690, 01251], lr: 0.000264, loss: 2.5152
2022-10-08 23:36:34 - train: epoch 0078, iter [00700, 01251], lr: 0.000264, loss: 2.9619
2022-10-08 23:36:55 - train: epoch 0078, iter [00710, 01251], lr: 0.000264, loss: 3.1009
2022-10-08 23:37:16 - train: epoch 0078, iter [00720, 01251], lr: 0.000263, loss: 2.9314
2022-10-08 23:37:37 - train: epoch 0078, iter [00730, 01251], lr: 0.000263, loss: 2.6624
2022-10-08 23:37:58 - train: epoch 0078, iter [00740, 01251], lr: 0.000263, loss: 2.3947
2022-10-08 23:38:19 - train: epoch 0078, iter [00750, 01251], lr: 0.000263, loss: 2.8315
2022-10-08 23:38:40 - train: epoch 0078, iter [00760, 01251], lr: 0.000263, loss: 3.3197
2022-10-08 23:39:01 - train: epoch 0078, iter [00770, 01251], lr: 0.000263, loss: 2.9820
2022-10-08 23:39:22 - train: epoch 0078, iter [00780, 01251], lr: 0.000262, loss: 2.6926
2022-10-08 23:39:43 - train: epoch 0078, iter [00790, 01251], lr: 0.000262, loss: 2.7115
2022-10-08 23:40:04 - train: epoch 0078, iter [00800, 01251], lr: 0.000262, loss: 3.0181
2022-10-08 23:40:25 - train: epoch 0078, iter [00810, 01251], lr: 0.000262, loss: 2.8790
2022-10-08 23:40:46 - train: epoch 0078, iter [00820, 01251], lr: 0.000262, loss: 2.6225
2022-10-08 23:41:07 - train: epoch 0078, iter [00830, 01251], lr: 0.000261, loss: 2.8986
2022-10-08 23:41:28 - train: epoch 0078, iter [00840, 01251], lr: 0.000261, loss: 2.8381
2022-10-08 23:41:49 - train: epoch 0078, iter [00850, 01251], lr: 0.000261, loss: 2.7992
2022-10-08 23:42:10 - train: epoch 0078, iter [00860, 01251], lr: 0.000261, loss: 2.6029
2022-10-08 23:42:31 - train: epoch 0078, iter [00870, 01251], lr: 0.000261, loss: 2.4044
2022-10-08 23:42:52 - train: epoch 0078, iter [00880, 01251], lr: 0.000261, loss: 3.1709
2022-10-08 23:43:13 - train: epoch 0078, iter [00890, 01251], lr: 0.000260, loss: 3.3695
2022-10-08 23:43:34 - train: epoch 0078, iter [00900, 01251], lr: 0.000260, loss: 2.9208
2022-10-08 23:43:55 - train: epoch 0078, iter [00910, 01251], lr: 0.000260, loss: 2.0397
2022-10-08 23:44:16 - train: epoch 0078, iter [00920, 01251], lr: 0.000260, loss: 2.8907
2022-10-08 23:44:37 - train: epoch 0078, iter [00930, 01251], lr: 0.000260, loss: 2.8178
2022-10-08 23:44:58 - train: epoch 0078, iter [00940, 01251], lr: 0.000260, loss: 3.0695
2022-10-08 23:45:19 - train: epoch 0078, iter [00950, 01251], lr: 0.000259, loss: 3.2077
2022-10-08 23:45:40 - train: epoch 0078, iter [00960, 01251], lr: 0.000259, loss: 2.4249
2022-10-08 23:46:01 - train: epoch 0078, iter [00970, 01251], lr: 0.000259, loss: 3.0224
2022-10-08 23:46:22 - train: epoch 0078, iter [00980, 01251], lr: 0.000259, loss: 2.9345
2022-10-08 23:46:43 - train: epoch 0078, iter [00990, 01251], lr: 0.000259, loss: 2.7597
2022-10-08 23:47:04 - train: epoch 0078, iter [01000, 01251], lr: 0.000258, loss: 3.1293
2022-10-08 23:47:25 - train: epoch 0078, iter [01010, 01251], lr: 0.000258, loss: 2.7850
2022-10-08 23:47:46 - train: epoch 0078, iter [01020, 01251], lr: 0.000258, loss: 2.5192
2022-10-08 23:48:07 - train: epoch 0078, iter [01030, 01251], lr: 0.000258, loss: 2.4322
2022-10-08 23:48:28 - train: epoch 0078, iter [01040, 01251], lr: 0.000258, loss: 2.3848
2022-10-08 23:48:49 - train: epoch 0078, iter [01050, 01251], lr: 0.000258, loss: 2.8807
2022-10-08 23:49:10 - train: epoch 0078, iter [01060, 01251], lr: 0.000257, loss: 3.0142
2022-10-08 23:49:31 - train: epoch 0078, iter [01070, 01251], lr: 0.000257, loss: 3.0606
2022-10-08 23:49:52 - train: epoch 0078, iter [01080, 01251], lr: 0.000257, loss: 2.5287
2022-10-08 23:50:13 - train: epoch 0078, iter [01090, 01251], lr: 0.000257, loss: 2.5043
2022-10-08 23:50:34 - train: epoch 0078, iter [01100, 01251], lr: 0.000257, loss: 2.9797
2022-10-08 23:50:55 - train: epoch 0078, iter [01110, 01251], lr: 0.000257, loss: 2.4184
2022-10-08 23:51:16 - train: epoch 0078, iter [01120, 01251], lr: 0.000256, loss: 3.1484
2022-10-08 23:51:37 - train: epoch 0078, iter [01130, 01251], lr: 0.000256, loss: 2.6048
2022-10-08 23:51:58 - train: epoch 0078, iter [01140, 01251], lr: 0.000256, loss: 3.2685
2022-10-08 23:52:19 - train: epoch 0078, iter [01150, 01251], lr: 0.000256, loss: 3.0796
2022-10-08 23:52:39 - train: epoch 0078, iter [01160, 01251], lr: 0.000256, loss: 2.9735
2022-10-08 23:53:00 - train: epoch 0078, iter [01170, 01251], lr: 0.000255, loss: 2.6854
2022-10-08 23:53:21 - train: epoch 0078, iter [01180, 01251], lr: 0.000255, loss: 3.0038
2022-10-08 23:53:42 - train: epoch 0078, iter [01190, 01251], lr: 0.000255, loss: 3.2733
2022-10-08 23:54:03 - train: epoch 0078, iter [01200, 01251], lr: 0.000255, loss: 2.4388
2022-10-08 23:54:24 - train: epoch 0078, iter [01210, 01251], lr: 0.000255, loss: 2.8112
2022-10-08 23:54:45 - train: epoch 0078, iter [01220, 01251], lr: 0.000255, loss: 2.4374
2022-10-08 23:55:06 - train: epoch 0078, iter [01230, 01251], lr: 0.000254, loss: 3.0683
2022-10-08 23:55:27 - train: epoch 0078, iter [01240, 01251], lr: 0.000254, loss: 2.8125
2022-10-08 23:55:48 - train: epoch 0078, iter [01250, 01251], lr: 0.000254, loss: 3.0979
2022-10-08 23:55:52 - train: epoch 078, train_loss: 2.8488
2022-10-08 23:57:08 - eval: epoch: 078, acc1: 82.582%, acc5: 96.428%, test_loss: 0.7712, per_image_load_time: 0.372ms, per_image_inference_time: 1.444ms
2022-10-08 23:57:10 - until epoch: 078, best_acc1: 82.582%
2022-10-08 23:57:10 - epoch 079 lr: 0.000254
2022-10-08 23:57:36 - train: epoch 0079, iter [00010, 01251], lr: 0.000254, loss: 2.8965
2022-10-08 23:57:57 - train: epoch 0079, iter [00020, 01251], lr: 0.000254, loss: 3.2740
2022-10-08 23:58:18 - train: epoch 0079, iter [00030, 01251], lr: 0.000254, loss: 2.4930
2022-10-08 23:58:39 - train: epoch 0079, iter [00040, 01251], lr: 0.000253, loss: 3.0411
2022-10-08 23:59:01 - train: epoch 0079, iter [00050, 01251], lr: 0.000253, loss: 2.5049
2022-10-08 23:59:22 - train: epoch 0079, iter [00060, 01251], lr: 0.000253, loss: 2.9800
2022-10-08 23:59:43 - train: epoch 0079, iter [00070, 01251], lr: 0.000253, loss: 2.7277
2022-10-09 00:00:04 - train: epoch 0079, iter [00080, 01251], lr: 0.000253, loss: 2.8569
2022-10-09 00:00:25 - train: epoch 0079, iter [00090, 01251], lr: 0.000252, loss: 3.0815
2022-10-09 00:00:46 - train: epoch 0079, iter [00100, 01251], lr: 0.000252, loss: 2.5454
2022-10-09 00:01:07 - train: epoch 0079, iter [00110, 01251], lr: 0.000252, loss: 2.6720
2022-10-09 00:01:28 - train: epoch 0079, iter [00120, 01251], lr: 0.000252, loss: 3.1356
2022-10-09 00:01:49 - train: epoch 0079, iter [00130, 01251], lr: 0.000252, loss: 2.0836
2022-10-09 00:02:10 - train: epoch 0079, iter [00140, 01251], lr: 0.000252, loss: 2.7647
2022-10-09 00:02:31 - train: epoch 0079, iter [00150, 01251], lr: 0.000251, loss: 2.8106
2022-10-09 00:02:52 - train: epoch 0079, iter [00160, 01251], lr: 0.000251, loss: 2.3735
2022-10-09 00:03:13 - train: epoch 0079, iter [00170, 01251], lr: 0.000251, loss: 2.7248
2022-10-09 00:03:34 - train: epoch 0079, iter [00180, 01251], lr: 0.000251, loss: 2.6207
2022-10-09 00:03:55 - train: epoch 0079, iter [00190, 01251], lr: 0.000251, loss: 2.8771
2022-10-09 00:04:16 - train: epoch 0079, iter [00200, 01251], lr: 0.000251, loss: 2.6662
2022-10-09 00:04:37 - train: epoch 0079, iter [00210, 01251], lr: 0.000250, loss: 2.5094
2022-10-09 00:04:58 - train: epoch 0079, iter [00220, 01251], lr: 0.000250, loss: 2.6028
2022-10-09 00:05:19 - train: epoch 0079, iter [00230, 01251], lr: 0.000250, loss: 2.6492
2022-10-09 00:05:40 - train: epoch 0079, iter [00240, 01251], lr: 0.000250, loss: 2.8392
2022-10-09 00:06:01 - train: epoch 0079, iter [00250, 01251], lr: 0.000250, loss: 2.7191
2022-10-09 00:06:22 - train: epoch 0079, iter [00260, 01251], lr: 0.000250, loss: 2.9152
2022-10-09 00:06:43 - train: epoch 0079, iter [00270, 01251], lr: 0.000249, loss: 2.7934
2022-10-09 00:07:04 - train: epoch 0079, iter [00280, 01251], lr: 0.000249, loss: 2.7858
2022-10-09 00:07:25 - train: epoch 0079, iter [00290, 01251], lr: 0.000249, loss: 2.5683
2022-10-09 00:07:46 - train: epoch 0079, iter [00300, 01251], lr: 0.000249, loss: 2.6580
2022-10-09 00:08:07 - train: epoch 0079, iter [00310, 01251], lr: 0.000249, loss: 2.4301
2022-10-09 00:08:28 - train: epoch 0079, iter [00320, 01251], lr: 0.000248, loss: 3.2611
2022-10-09 00:08:49 - train: epoch 0079, iter [00330, 01251], lr: 0.000248, loss: 2.7341
2022-10-09 00:09:10 - train: epoch 0079, iter [00340, 01251], lr: 0.000248, loss: 2.9759
2022-10-09 00:09:31 - train: epoch 0079, iter [00350, 01251], lr: 0.000248, loss: 3.2379
2022-10-09 00:09:52 - train: epoch 0079, iter [00360, 01251], lr: 0.000248, loss: 3.2056
2022-10-09 00:10:13 - train: epoch 0079, iter [00370, 01251], lr: 0.000248, loss: 2.9202
2022-10-09 00:10:34 - train: epoch 0079, iter [00380, 01251], lr: 0.000247, loss: 3.1068
2022-10-09 00:10:55 - train: epoch 0079, iter [00390, 01251], lr: 0.000247, loss: 2.5885
2022-10-09 00:11:16 - train: epoch 0079, iter [00400, 01251], lr: 0.000247, loss: 2.4676
2022-10-09 00:11:37 - train: epoch 0079, iter [00410, 01251], lr: 0.000247, loss: 2.8762
2022-10-09 00:11:58 - train: epoch 0079, iter [00420, 01251], lr: 0.000247, loss: 2.6157
2022-10-09 00:12:19 - train: epoch 0079, iter [00430, 01251], lr: 0.000247, loss: 2.2609
2022-10-09 00:12:40 - train: epoch 0079, iter [00440, 01251], lr: 0.000246, loss: 2.7511
2022-10-09 00:13:01 - train: epoch 0079, iter [00450, 01251], lr: 0.000246, loss: 2.1197
2022-10-09 00:13:22 - train: epoch 0079, iter [00460, 01251], lr: 0.000246, loss: 2.6291
2022-10-09 00:13:42 - train: epoch 0079, iter [00470, 01251], lr: 0.000246, loss: 3.0012
2022-10-09 00:14:03 - train: epoch 0079, iter [00480, 01251], lr: 0.000246, loss: 3.1996
2022-10-09 00:14:24 - train: epoch 0079, iter [00490, 01251], lr: 0.000246, loss: 2.9042
2022-10-09 00:14:45 - train: epoch 0079, iter [00500, 01251], lr: 0.000245, loss: 2.7915
2022-10-09 00:15:06 - train: epoch 0079, iter [00510, 01251], lr: 0.000245, loss: 2.6929
2022-10-09 00:15:27 - train: epoch 0079, iter [00520, 01251], lr: 0.000245, loss: 2.4533
2022-10-09 00:15:48 - train: epoch 0079, iter [00530, 01251], lr: 0.000245, loss: 3.1750
2022-10-09 00:16:09 - train: epoch 0079, iter [00540, 01251], lr: 0.000245, loss: 2.6356
2022-10-09 00:16:30 - train: epoch 0079, iter [00550, 01251], lr: 0.000244, loss: 2.4383
2022-10-09 00:16:51 - train: epoch 0079, iter [00560, 01251], lr: 0.000244, loss: 2.9561
2022-10-09 00:17:12 - train: epoch 0079, iter [00570, 01251], lr: 0.000244, loss: 2.6008
2022-10-09 00:17:33 - train: epoch 0079, iter [00580, 01251], lr: 0.000244, loss: 2.9313
2022-10-09 00:17:54 - train: epoch 0079, iter [00590, 01251], lr: 0.000244, loss: 3.2102
2022-10-09 00:18:15 - train: epoch 0079, iter [00600, 01251], lr: 0.000244, loss: 2.8344
2022-10-09 00:18:36 - train: epoch 0079, iter [00610, 01251], lr: 0.000243, loss: 2.6469
2022-10-09 00:18:57 - train: epoch 0079, iter [00620, 01251], lr: 0.000243, loss: 2.8196
2022-10-09 00:19:18 - train: epoch 0079, iter [00630, 01251], lr: 0.000243, loss: 2.4898
2022-10-09 00:19:39 - train: epoch 0079, iter [00640, 01251], lr: 0.000243, loss: 3.1773
2022-10-09 00:20:00 - train: epoch 0079, iter [00650, 01251], lr: 0.000243, loss: 2.6258
2022-10-09 00:20:21 - train: epoch 0079, iter [00660, 01251], lr: 0.000243, loss: 3.0846
2022-10-09 00:20:42 - train: epoch 0079, iter [00670, 01251], lr: 0.000242, loss: 2.6061
2022-10-09 00:21:03 - train: epoch 0079, iter [00680, 01251], lr: 0.000242, loss: 3.1200
2022-10-09 00:21:24 - train: epoch 0079, iter [00690, 01251], lr: 0.000242, loss: 2.8658
2022-10-09 00:21:45 - train: epoch 0079, iter [00700, 01251], lr: 0.000242, loss: 2.7915
2022-10-09 00:22:06 - train: epoch 0079, iter [00710, 01251], lr: 0.000242, loss: 2.8403
2022-10-09 00:22:27 - train: epoch 0079, iter [00720, 01251], lr: 0.000242, loss: 3.2857
2022-10-09 00:22:48 - train: epoch 0079, iter [00730, 01251], lr: 0.000241, loss: 2.7991
2022-10-09 00:23:09 - train: epoch 0079, iter [00740, 01251], lr: 0.000241, loss: 2.5320
2022-10-09 00:23:30 - train: epoch 0079, iter [00750, 01251], lr: 0.000241, loss: 2.7371
2022-10-09 00:23:51 - train: epoch 0079, iter [00760, 01251], lr: 0.000241, loss: 2.7835
2022-10-09 00:24:12 - train: epoch 0079, iter [00770, 01251], lr: 0.000241, loss: 3.1305
2022-10-09 00:24:33 - train: epoch 0079, iter [00780, 01251], lr: 0.000241, loss: 3.1550
2022-10-09 00:24:54 - train: epoch 0079, iter [00790, 01251], lr: 0.000240, loss: 3.0574
2022-10-09 00:25:15 - train: epoch 0079, iter [00800, 01251], lr: 0.000240, loss: 2.5567
2022-10-09 00:25:36 - train: epoch 0079, iter [00810, 01251], lr: 0.000240, loss: 2.6727
2022-10-09 00:25:57 - train: epoch 0079, iter [00820, 01251], lr: 0.000240, loss: 2.7450
2022-10-09 00:26:18 - train: epoch 0079, iter [00830, 01251], lr: 0.000240, loss: 2.6196
2022-10-09 00:26:39 - train: epoch 0079, iter [00840, 01251], lr: 0.000239, loss: 2.6656
2022-10-09 00:27:00 - train: epoch 0079, iter [00850, 01251], lr: 0.000239, loss: 2.0261
2022-10-09 00:27:21 - train: epoch 0079, iter [00860, 01251], lr: 0.000239, loss: 3.1931
2022-10-09 00:27:42 - train: epoch 0079, iter [00870, 01251], lr: 0.000239, loss: 2.8253
2022-10-09 00:28:03 - train: epoch 0079, iter [00880, 01251], lr: 0.000239, loss: 2.2388
2022-10-09 00:28:24 - train: epoch 0079, iter [00890, 01251], lr: 0.000239, loss: 3.2436
2022-10-09 00:28:45 - train: epoch 0079, iter [00900, 01251], lr: 0.000238, loss: 3.0567
2022-10-09 00:29:06 - train: epoch 0079, iter [00910, 01251], lr: 0.000238, loss: 2.4613
2022-10-09 00:29:27 - train: epoch 0079, iter [00920, 01251], lr: 0.000238, loss: 2.9019
2022-10-09 00:29:48 - train: epoch 0079, iter [00930, 01251], lr: 0.000238, loss: 3.1335
2022-10-09 00:30:09 - train: epoch 0079, iter [00940, 01251], lr: 0.000238, loss: 2.6594
2022-10-09 00:30:30 - train: epoch 0079, iter [00950, 01251], lr: 0.000238, loss: 3.0721
2022-10-09 00:30:51 - train: epoch 0079, iter [00960, 01251], lr: 0.000237, loss: 1.9104
2022-10-09 00:31:12 - train: epoch 0079, iter [00970, 01251], lr: 0.000237, loss: 2.9070
2022-10-09 00:31:33 - train: epoch 0079, iter [00980, 01251], lr: 0.000237, loss: 2.7810
2022-10-09 00:31:54 - train: epoch 0079, iter [00990, 01251], lr: 0.000237, loss: 2.5487
2022-10-09 00:32:15 - train: epoch 0079, iter [01000, 01251], lr: 0.000237, loss: 2.6106
2022-10-09 00:32:36 - train: epoch 0079, iter [01010, 01251], lr: 0.000237, loss: 2.6479
2022-10-09 00:32:57 - train: epoch 0079, iter [01020, 01251], lr: 0.000236, loss: 3.1584
2022-10-09 00:33:18 - train: epoch 0079, iter [01030, 01251], lr: 0.000236, loss: 2.5499
2022-10-09 00:33:39 - train: epoch 0079, iter [01040, 01251], lr: 0.000236, loss: 2.8970
2022-10-09 00:34:00 - train: epoch 0079, iter [01050, 01251], lr: 0.000236, loss: 2.9512
2022-10-09 00:34:21 - train: epoch 0079, iter [01060, 01251], lr: 0.000236, loss: 2.3834
2022-10-09 00:34:42 - train: epoch 0079, iter [01070, 01251], lr: 0.000236, loss: 2.9209
2022-10-09 00:35:03 - train: epoch 0079, iter [01080, 01251], lr: 0.000235, loss: 2.6130
2022-10-09 00:35:24 - train: epoch 0079, iter [01090, 01251], lr: 0.000235, loss: 2.9770
2022-10-09 00:35:45 - train: epoch 0079, iter [01100, 01251], lr: 0.000235, loss: 3.2848
2022-10-09 00:36:06 - train: epoch 0079, iter [01110, 01251], lr: 0.000235, loss: 2.8992
2022-10-09 00:36:26 - train: epoch 0079, iter [01120, 01251], lr: 0.000235, loss: 2.8292
2022-10-09 00:36:48 - train: epoch 0079, iter [01130, 01251], lr: 0.000235, loss: 3.0303
2022-10-09 00:37:09 - train: epoch 0079, iter [01140, 01251], lr: 0.000234, loss: 3.4171
2022-10-09 00:37:30 - train: epoch 0079, iter [01150, 01251], lr: 0.000234, loss: 3.0057
2022-10-09 00:37:50 - train: epoch 0079, iter [01160, 01251], lr: 0.000234, loss: 2.4299
2022-10-09 00:38:11 - train: epoch 0079, iter [01170, 01251], lr: 0.000234, loss: 2.6749
2022-10-09 00:38:32 - train: epoch 0079, iter [01180, 01251], lr: 0.000234, loss: 2.5105
2022-10-09 00:38:53 - train: epoch 0079, iter [01190, 01251], lr: 0.000234, loss: 2.0677
2022-10-09 00:39:14 - train: epoch 0079, iter [01200, 01251], lr: 0.000233, loss: 2.5974
2022-10-09 00:39:35 - train: epoch 0079, iter [01210, 01251], lr: 0.000233, loss: 2.8364
2022-10-09 00:39:56 - train: epoch 0079, iter [01220, 01251], lr: 0.000233, loss: 3.0580
2022-10-09 00:40:17 - train: epoch 0079, iter [01230, 01251], lr: 0.000233, loss: 2.8817
2022-10-09 00:40:38 - train: epoch 0079, iter [01240, 01251], lr: 0.000233, loss: 2.8982
2022-10-09 00:40:59 - train: epoch 0079, iter [01250, 01251], lr: 0.000232, loss: 2.8387
2022-10-09 00:41:02 - train: epoch 079, train_loss: 2.8250
2022-10-09 00:42:16 - eval: epoch: 079, acc1: 82.630%, acc5: 96.426%, test_loss: 0.7657, per_image_load_time: 0.625ms, per_image_inference_time: 1.443ms
2022-10-09 00:42:18 - until epoch: 079, best_acc1: 82.630%
2022-10-09 00:42:18 - epoch 080 lr: 0.000232
2022-10-09 00:42:45 - train: epoch 0080, iter [00010, 01251], lr: 0.000232, loss: 2.8344
2022-10-09 00:43:06 - train: epoch 0080, iter [00020, 01251], lr: 0.000232, loss: 2.4965
2022-10-09 00:43:27 - train: epoch 0080, iter [00030, 01251], lr: 0.000232, loss: 3.0544
2022-10-09 00:43:48 - train: epoch 0080, iter [00040, 01251], lr: 0.000232, loss: 2.6090
2022-10-09 00:44:09 - train: epoch 0080, iter [00050, 01251], lr: 0.000232, loss: 2.8560
2022-10-09 00:44:30 - train: epoch 0080, iter [00060, 01251], lr: 0.000231, loss: 2.4253
2022-10-09 00:44:51 - train: epoch 0080, iter [00070, 01251], lr: 0.000231, loss: 2.3460
2022-10-09 00:45:12 - train: epoch 0080, iter [00080, 01251], lr: 0.000231, loss: 3.1894
2022-10-09 00:45:33 - train: epoch 0080, iter [00090, 01251], lr: 0.000231, loss: 3.1081
2022-10-09 00:45:54 - train: epoch 0080, iter [00100, 01251], lr: 0.000231, loss: 2.9153
2022-10-09 00:46:15 - train: epoch 0080, iter [00110, 01251], lr: 0.000231, loss: 3.2055
2022-10-09 00:46:36 - train: epoch 0080, iter [00120, 01251], lr: 0.000230, loss: 3.0811
2022-10-09 00:46:57 - train: epoch 0080, iter [00130, 01251], lr: 0.000230, loss: 2.3795
2022-10-09 00:47:18 - train: epoch 0080, iter [00140, 01251], lr: 0.000230, loss: 2.7992
2022-10-09 00:47:39 - train: epoch 0080, iter [00150, 01251], lr: 0.000230, loss: 2.5192
2022-10-09 00:48:01 - train: epoch 0080, iter [00160, 01251], lr: 0.000230, loss: 2.9020
2022-10-09 00:48:22 - train: epoch 0080, iter [00170, 01251], lr: 0.000230, loss: 2.8463
2022-10-09 00:48:43 - train: epoch 0080, iter [00180, 01251], lr: 0.000229, loss: 2.5745
2022-10-09 00:49:04 - train: epoch 0080, iter [00190, 01251], lr: 0.000229, loss: 2.6677
2022-10-09 00:49:25 - train: epoch 0080, iter [00200, 01251], lr: 0.000229, loss: 2.9851
2022-10-09 00:49:46 - train: epoch 0080, iter [00210, 01251], lr: 0.000229, loss: 2.7363
2022-10-09 00:50:07 - train: epoch 0080, iter [00220, 01251], lr: 0.000229, loss: 2.0159
2022-10-09 00:50:28 - train: epoch 0080, iter [00230, 01251], lr: 0.000229, loss: 3.0952
2022-10-09 00:50:49 - train: epoch 0080, iter [00240, 01251], lr: 0.000228, loss: 2.3607
2022-10-09 00:51:10 - train: epoch 0080, iter [00250, 01251], lr: 0.000228, loss: 3.0735
2022-10-09 00:51:31 - train: epoch 0080, iter [00260, 01251], lr: 0.000228, loss: 2.9245
2022-10-09 00:51:52 - train: epoch 0080, iter [00270, 01251], lr: 0.000228, loss: 2.9249
2022-10-09 00:52:13 - train: epoch 0080, iter [00280, 01251], lr: 0.000228, loss: 2.9599
2022-10-09 00:52:34 - train: epoch 0080, iter [00290, 01251], lr: 0.000228, loss: 3.0304
2022-10-09 00:52:55 - train: epoch 0080, iter [00300, 01251], lr: 0.000227, loss: 2.9669
2022-10-09 00:53:16 - train: epoch 0080, iter [00310, 01251], lr: 0.000227, loss: 2.9189
2022-10-09 00:53:37 - train: epoch 0080, iter [00320, 01251], lr: 0.000227, loss: 3.2362
2022-10-09 00:53:58 - train: epoch 0080, iter [00330, 01251], lr: 0.000227, loss: 2.8971
2022-10-09 00:54:20 - train: epoch 0080, iter [00340, 01251], lr: 0.000227, loss: 2.9666
2022-10-09 00:54:41 - train: epoch 0080, iter [00350, 01251], lr: 0.000227, loss: 2.0434
2022-10-09 00:55:02 - train: epoch 0080, iter [00360, 01251], lr: 0.000226, loss: 2.3308
2022-10-09 00:55:23 - train: epoch 0080, iter [00370, 01251], lr: 0.000226, loss: 3.1873
2022-10-09 00:55:44 - train: epoch 0080, iter [00380, 01251], lr: 0.000226, loss: 3.2624
2022-10-09 00:56:05 - train: epoch 0080, iter [00390, 01251], lr: 0.000226, loss: 3.0481
2022-10-09 00:56:26 - train: epoch 0080, iter [00400, 01251], lr: 0.000226, loss: 2.7780
2022-10-09 00:56:47 - train: epoch 0080, iter [00410, 01251], lr: 0.000226, loss: 2.7167
2022-10-09 00:57:08 - train: epoch 0080, iter [00420, 01251], lr: 0.000225, loss: 2.4448
2022-10-09 00:57:29 - train: epoch 0080, iter [00430, 01251], lr: 0.000225, loss: 2.0236
2022-10-09 00:57:50 - train: epoch 0080, iter [00440, 01251], lr: 0.000225, loss: 2.9450
2022-10-09 00:58:11 - train: epoch 0080, iter [00450, 01251], lr: 0.000225, loss: 2.5907
2022-10-09 00:58:33 - train: epoch 0080, iter [00460, 01251], lr: 0.000225, loss: 3.1934
2022-10-09 00:58:54 - train: epoch 0080, iter [00470, 01251], lr: 0.000225, loss: 2.4797
2022-10-09 00:59:15 - train: epoch 0080, iter [00480, 01251], lr: 0.000224, loss: 2.8830
2022-10-09 00:59:36 - train: epoch 0080, iter [00490, 01251], lr: 0.000224, loss: 2.5085
2022-10-09 00:59:57 - train: epoch 0080, iter [00500, 01251], lr: 0.000224, loss: 2.9026
2022-10-09 01:00:18 - train: epoch 0080, iter [00510, 01251], lr: 0.000224, loss: 1.8595
2022-10-09 01:00:39 - train: epoch 0080, iter [00520, 01251], lr: 0.000224, loss: 2.8627
2022-10-09 01:01:00 - train: epoch 0080, iter [00530, 01251], lr: 0.000224, loss: 2.3907
2022-10-09 01:01:21 - train: epoch 0080, iter [00540, 01251], lr: 0.000223, loss: 2.6779
2022-10-09 01:01:42 - train: epoch 0080, iter [00550, 01251], lr: 0.000223, loss: 2.9305
2022-10-09 01:02:03 - train: epoch 0080, iter [00560, 01251], lr: 0.000223, loss: 2.5072
2022-10-09 01:02:24 - train: epoch 0080, iter [00570, 01251], lr: 0.000223, loss: 2.8638
2022-10-09 01:02:45 - train: epoch 0080, iter [00580, 01251], lr: 0.000223, loss: 2.5456
2022-10-09 01:03:06 - train: epoch 0080, iter [00590, 01251], lr: 0.000223, loss: 2.8176
2022-10-09 01:03:27 - train: epoch 0080, iter [00600, 01251], lr: 0.000222, loss: 3.1296
2022-10-09 01:03:48 - train: epoch 0080, iter [00610, 01251], lr: 0.000222, loss: 2.8857
2022-10-09 01:04:09 - train: epoch 0080, iter [00620, 01251], lr: 0.000222, loss: 2.2657
2022-10-09 01:04:30 - train: epoch 0080, iter [00630, 01251], lr: 0.000222, loss: 2.8566
2022-10-09 01:04:51 - train: epoch 0080, iter [00640, 01251], lr: 0.000222, loss: 2.6654
2022-10-09 01:05:12 - train: epoch 0080, iter [00650, 01251], lr: 0.000222, loss: 2.9026
2022-10-09 01:05:33 - train: epoch 0080, iter [00660, 01251], lr: 0.000221, loss: 2.7140
2022-10-09 01:05:54 - train: epoch 0080, iter [00670, 01251], lr: 0.000221, loss: 3.2072
2022-10-09 01:06:15 - train: epoch 0080, iter [00680, 01251], lr: 0.000221, loss: 3.1289
2022-10-09 01:06:36 - train: epoch 0080, iter [00690, 01251], lr: 0.000221, loss: 2.8531
2022-10-09 01:06:58 - train: epoch 0080, iter [00700, 01251], lr: 0.000221, loss: 2.5440
2022-10-09 01:07:19 - train: epoch 0080, iter [00710, 01251], lr: 0.000221, loss: 3.2544
2022-10-09 01:07:40 - train: epoch 0080, iter [00720, 01251], lr: 0.000220, loss: 2.5973
2022-10-09 01:08:01 - train: epoch 0080, iter [00730, 01251], lr: 0.000220, loss: 2.6952
2022-10-09 01:08:22 - train: epoch 0080, iter [00740, 01251], lr: 0.000220, loss: 2.8644
2022-10-09 01:08:43 - train: epoch 0080, iter [00750, 01251], lr: 0.000220, loss: 3.2551
2022-10-09 01:09:04 - train: epoch 0080, iter [00760, 01251], lr: 0.000220, loss: 2.7326
2022-10-09 01:09:25 - train: epoch 0080, iter [00770, 01251], lr: 0.000220, loss: 2.4487
2022-10-09 01:09:46 - train: epoch 0080, iter [00780, 01251], lr: 0.000219, loss: 2.7513
2022-10-09 01:10:07 - train: epoch 0080, iter [00790, 01251], lr: 0.000219, loss: 2.8116
2022-10-09 01:10:28 - train: epoch 0080, iter [00800, 01251], lr: 0.000219, loss: 2.7752
2022-10-09 01:10:49 - train: epoch 0080, iter [00810, 01251], lr: 0.000219, loss: 2.9928
2022-10-09 01:11:10 - train: epoch 0080, iter [00820, 01251], lr: 0.000219, loss: 2.8011
2022-10-09 01:11:31 - train: epoch 0080, iter [00830, 01251], lr: 0.000219, loss: 3.1229
2022-10-09 01:11:52 - train: epoch 0080, iter [00840, 01251], lr: 0.000218, loss: 2.5461
2022-10-09 01:12:14 - train: epoch 0080, iter [00850, 01251], lr: 0.000218, loss: 2.8020
2022-10-09 01:12:35 - train: epoch 0080, iter [00860, 01251], lr: 0.000218, loss: 3.0925
2022-10-09 01:12:56 - train: epoch 0080, iter [00870, 01251], lr: 0.000218, loss: 3.2686
2022-10-09 01:13:17 - train: epoch 0080, iter [00880, 01251], lr: 0.000218, loss: 3.2264
2022-10-09 01:13:38 - train: epoch 0080, iter [00890, 01251], lr: 0.000218, loss: 2.7521
2022-10-09 01:13:59 - train: epoch 0080, iter [00900, 01251], lr: 0.000217, loss: 3.1308
2022-10-09 01:14:20 - train: epoch 0080, iter [00910, 01251], lr: 0.000217, loss: 2.8105
2022-10-09 01:14:41 - train: epoch 0080, iter [00920, 01251], lr: 0.000217, loss: 2.6677
2022-10-09 01:15:02 - train: epoch 0080, iter [00930, 01251], lr: 0.000217, loss: 2.1942
2022-10-09 01:15:23 - train: epoch 0080, iter [00940, 01251], lr: 0.000217, loss: 2.7890
2022-10-09 01:15:44 - train: epoch 0080, iter [00950, 01251], lr: 0.000217, loss: 2.2569
2022-10-09 01:16:05 - train: epoch 0080, iter [00960, 01251], lr: 0.000216, loss: 3.0698
2022-10-09 01:16:26 - train: epoch 0080, iter [00970, 01251], lr: 0.000216, loss: 2.4359
2022-10-09 01:16:47 - train: epoch 0080, iter [00980, 01251], lr: 0.000216, loss: 2.8602
2022-10-09 01:17:08 - train: epoch 0080, iter [00990, 01251], lr: 0.000216, loss: 3.1822
2022-10-09 01:17:29 - train: epoch 0080, iter [01000, 01251], lr: 0.000216, loss: 3.1994
2022-10-09 01:17:50 - train: epoch 0080, iter [01010, 01251], lr: 0.000216, loss: 2.8717
2022-10-09 01:18:11 - train: epoch 0080, iter [01020, 01251], lr: 0.000216, loss: 3.2074
2022-10-09 01:18:32 - train: epoch 0080, iter [01030, 01251], lr: 0.000215, loss: 3.2318
2022-10-09 01:18:53 - train: epoch 0080, iter [01040, 01251], lr: 0.000215, loss: 2.6571
2022-10-09 01:19:14 - train: epoch 0080, iter [01050, 01251], lr: 0.000215, loss: 3.1167
2022-10-09 01:19:35 - train: epoch 0080, iter [01060, 01251], lr: 0.000215, loss: 2.8255
2022-10-09 01:19:57 - train: epoch 0080, iter [01070, 01251], lr: 0.000215, loss: 2.2844
2022-10-09 01:20:18 - train: epoch 0080, iter [01080, 01251], lr: 0.000215, loss: 3.0849
2022-10-09 01:20:39 - train: epoch 0080, iter [01090, 01251], lr: 0.000214, loss: 3.1221
2022-10-09 01:21:00 - train: epoch 0080, iter [01100, 01251], lr: 0.000214, loss: 3.0362
2022-10-09 01:21:21 - train: epoch 0080, iter [01110, 01251], lr: 0.000214, loss: 3.1779
2022-10-09 01:21:42 - train: epoch 0080, iter [01120, 01251], lr: 0.000214, loss: 3.1590
2022-10-09 01:22:03 - train: epoch 0080, iter [01130, 01251], lr: 0.000214, loss: 2.7369
2022-10-09 01:22:24 - train: epoch 0080, iter [01140, 01251], lr: 0.000214, loss: 2.4413
2022-10-09 01:22:45 - train: epoch 0080, iter [01150, 01251], lr: 0.000213, loss: 2.8311
2022-10-09 01:23:06 - train: epoch 0080, iter [01160, 01251], lr: 0.000213, loss: 2.8564
2022-10-09 01:23:27 - train: epoch 0080, iter [01170, 01251], lr: 0.000213, loss: 2.6123
2022-10-09 01:23:48 - train: epoch 0080, iter [01180, 01251], lr: 0.000213, loss: 2.5198
2022-10-09 01:24:09 - train: epoch 0080, iter [01190, 01251], lr: 0.000213, loss: 2.7460
2022-10-09 01:24:30 - train: epoch 0080, iter [01200, 01251], lr: 0.000213, loss: 3.0608
2022-10-09 01:24:51 - train: epoch 0080, iter [01210, 01251], lr: 0.000212, loss: 1.8339
2022-10-09 01:25:12 - train: epoch 0080, iter [01220, 01251], lr: 0.000212, loss: 2.4724
2022-10-09 01:25:33 - train: epoch 0080, iter [01230, 01251], lr: 0.000212, loss: 2.7843
2022-10-09 01:25:54 - train: epoch 0080, iter [01240, 01251], lr: 0.000212, loss: 2.4820
2022-10-09 01:26:15 - train: epoch 0080, iter [01250, 01251], lr: 0.000212, loss: 2.8855
2022-10-09 01:26:19 - train: epoch 080, train_loss: 2.8169
2022-10-09 01:27:35 - eval: epoch: 080, acc1: 82.732%, acc5: 96.438%, test_loss: 0.7571, per_image_load_time: 0.434ms, per_image_inference_time: 1.430ms
2022-10-09 01:27:36 - until epoch: 080, best_acc1: 82.732%
2022-10-09 01:27:36 - epoch 081 lr: 0.000212
2022-10-09 01:28:03 - train: epoch 0081, iter [00010, 01251], lr: 0.000212, loss: 2.6423
2022-10-09 01:28:24 - train: epoch 0081, iter [00020, 01251], lr: 0.000211, loss: 2.7447
2022-10-09 01:28:45 - train: epoch 0081, iter [00030, 01251], lr: 0.000211, loss: 3.0348
2022-10-09 01:29:06 - train: epoch 0081, iter [00040, 01251], lr: 0.000211, loss: 2.8129
2022-10-09 01:29:28 - train: epoch 0081, iter [00050, 01251], lr: 0.000211, loss: 3.1232
2022-10-09 01:29:49 - train: epoch 0081, iter [00060, 01251], lr: 0.000211, loss: 3.1256
2022-10-09 01:30:10 - train: epoch 0081, iter [00070, 01251], lr: 0.000211, loss: 2.5795
2022-10-09 01:30:31 - train: epoch 0081, iter [00080, 01251], lr: 0.000210, loss: 2.9710
2022-10-09 01:30:52 - train: epoch 0081, iter [00090, 01251], lr: 0.000210, loss: 2.9871
2022-10-09 01:31:13 - train: epoch 0081, iter [00100, 01251], lr: 0.000210, loss: 2.8386
2022-10-09 01:31:35 - train: epoch 0081, iter [00110, 01251], lr: 0.000210, loss: 2.5329
2022-10-09 01:31:56 - train: epoch 0081, iter [00120, 01251], lr: 0.000210, loss: 2.8154
2022-10-09 01:32:17 - train: epoch 0081, iter [00130, 01251], lr: 0.000210, loss: 3.0167
2022-10-09 01:32:38 - train: epoch 0081, iter [00140, 01251], lr: 0.000209, loss: 3.0488
2022-10-09 01:32:59 - train: epoch 0081, iter [00150, 01251], lr: 0.000209, loss: 2.7032
2022-10-09 01:33:20 - train: epoch 0081, iter [00160, 01251], lr: 0.000209, loss: 2.4907
2022-10-09 01:33:42 - train: epoch 0081, iter [00170, 01251], lr: 0.000209, loss: 2.9571
2022-10-09 01:34:03 - train: epoch 0081, iter [00180, 01251], lr: 0.000209, loss: 2.7704
2022-10-09 01:34:24 - train: epoch 0081, iter [00190, 01251], lr: 0.000209, loss: 2.6823
2022-10-09 01:34:45 - train: epoch 0081, iter [00200, 01251], lr: 0.000209, loss: 3.1606
2022-10-09 01:35:06 - train: epoch 0081, iter [00210, 01251], lr: 0.000208, loss: 3.0905
2022-10-09 01:35:27 - train: epoch 0081, iter [00220, 01251], lr: 0.000208, loss: 2.9822
2022-10-09 01:35:48 - train: epoch 0081, iter [00230, 01251], lr: 0.000208, loss: 3.1457
2022-10-09 01:36:09 - train: epoch 0081, iter [00240, 01251], lr: 0.000208, loss: 2.6042
2022-10-09 01:36:31 - train: epoch 0081, iter [00250, 01251], lr: 0.000208, loss: 2.9196
2022-10-09 01:36:52 - train: epoch 0081, iter [00260, 01251], lr: 0.000208, loss: 3.1602
2022-10-09 01:37:13 - train: epoch 0081, iter [00270, 01251], lr: 0.000207, loss: 2.9885
2022-10-09 01:37:34 - train: epoch 0081, iter [00280, 01251], lr: 0.000207, loss: 2.4145
2022-10-09 01:37:55 - train: epoch 0081, iter [00290, 01251], lr: 0.000207, loss: 3.1112
2022-10-09 01:38:16 - train: epoch 0081, iter [00300, 01251], lr: 0.000207, loss: 2.6440
2022-10-09 01:38:37 - train: epoch 0081, iter [00310, 01251], lr: 0.000207, loss: 3.1233
2022-10-09 01:38:58 - train: epoch 0081, iter [00320, 01251], lr: 0.000207, loss: 3.1804
2022-10-09 01:39:19 - train: epoch 0081, iter [00330, 01251], lr: 0.000206, loss: 3.1467
2022-10-09 01:39:41 - train: epoch 0081, iter [00340, 01251], lr: 0.000206, loss: 3.0200
2022-10-09 01:40:02 - train: epoch 0081, iter [00350, 01251], lr: 0.000206, loss: 2.9899
2022-10-09 01:40:23 - train: epoch 0081, iter [00360, 01251], lr: 0.000206, loss: 3.1071
2022-10-09 01:40:44 - train: epoch 0081, iter [00370, 01251], lr: 0.000206, loss: 2.7285
2022-10-09 01:41:05 - train: epoch 0081, iter [00380, 01251], lr: 0.000206, loss: 2.7494
2022-10-09 01:41:26 - train: epoch 0081, iter [00390, 01251], lr: 0.000205, loss: 2.5303
2022-10-09 01:41:47 - train: epoch 0081, iter [00400, 01251], lr: 0.000205, loss: 3.0359
2022-10-09 01:42:08 - train: epoch 0081, iter [00410, 01251], lr: 0.000205, loss: 2.4418
2022-10-09 01:42:29 - train: epoch 0081, iter [00420, 01251], lr: 0.000205, loss: 2.4781
2022-10-09 01:42:50 - train: epoch 0081, iter [00430, 01251], lr: 0.000205, loss: 3.1872
2022-10-09 01:43:11 - train: epoch 0081, iter [00440, 01251], lr: 0.000205, loss: 2.3895
2022-10-09 01:43:33 - train: epoch 0081, iter [00450, 01251], lr: 0.000205, loss: 2.9884
2022-10-09 01:43:54 - train: epoch 0081, iter [00460, 01251], lr: 0.000204, loss: 2.8085
2022-10-09 01:44:15 - train: epoch 0081, iter [00470, 01251], lr: 0.000204, loss: 3.1908
2022-10-09 01:44:36 - train: epoch 0081, iter [00480, 01251], lr: 0.000204, loss: 3.2057
2022-10-09 01:44:57 - train: epoch 0081, iter [00490, 01251], lr: 0.000204, loss: 2.9175
2022-10-09 01:45:18 - train: epoch 0081, iter [00500, 01251], lr: 0.000204, loss: 3.0802
2022-10-09 01:45:39 - train: epoch 0081, iter [00510, 01251], lr: 0.000204, loss: 3.3289
2022-10-09 01:46:00 - train: epoch 0081, iter [00520, 01251], lr: 0.000203, loss: 3.0944
2022-10-09 01:46:21 - train: epoch 0081, iter [00530, 01251], lr: 0.000203, loss: 2.5856
2022-10-09 01:46:42 - train: epoch 0081, iter [00540, 01251], lr: 0.000203, loss: 1.9242
2022-10-09 01:47:03 - train: epoch 0081, iter [00550, 01251], lr: 0.000203, loss: 3.0632
2022-10-09 01:47:25 - train: epoch 0081, iter [00560, 01251], lr: 0.000203, loss: 3.2663
2022-10-09 01:47:46 - train: epoch 0081, iter [00570, 01251], lr: 0.000203, loss: 2.6998
2022-10-09 01:48:07 - train: epoch 0081, iter [00580, 01251], lr: 0.000202, loss: 3.1913
2022-10-09 01:48:28 - train: epoch 0081, iter [00590, 01251], lr: 0.000202, loss: 2.3237
2022-10-09 01:48:49 - train: epoch 0081, iter [00600, 01251], lr: 0.000202, loss: 2.9888
2022-10-09 01:49:10 - train: epoch 0081, iter [00610, 01251], lr: 0.000202, loss: 2.7045
2022-10-09 01:49:31 - train: epoch 0081, iter [00620, 01251], lr: 0.000202, loss: 3.1016
2022-10-09 01:49:52 - train: epoch 0081, iter [00630, 01251], lr: 0.000202, loss: 3.1103
2022-10-09 01:50:13 - train: epoch 0081, iter [00640, 01251], lr: 0.000201, loss: 2.4923
2022-10-09 01:50:34 - train: epoch 0081, iter [00650, 01251], lr: 0.000201, loss: 2.5534
2022-10-09 01:50:55 - train: epoch 0081, iter [00660, 01251], lr: 0.000201, loss: 2.9959
2022-10-09 01:51:16 - train: epoch 0081, iter [00670, 01251], lr: 0.000201, loss: 2.6501
2022-10-09 01:51:37 - train: epoch 0081, iter [00680, 01251], lr: 0.000201, loss: 2.6387
2022-10-09 01:51:58 - train: epoch 0081, iter [00690, 01251], lr: 0.000201, loss: 3.0637
2022-10-09 01:52:19 - train: epoch 0081, iter [00700, 01251], lr: 0.000201, loss: 2.6796
2022-10-09 01:52:41 - train: epoch 0081, iter [00710, 01251], lr: 0.000200, loss: 2.9889
2022-10-09 01:53:02 - train: epoch 0081, iter [00720, 01251], lr: 0.000200, loss: 3.1531
2022-10-09 01:53:23 - train: epoch 0081, iter [00730, 01251], lr: 0.000200, loss: 2.4060
2022-10-09 01:53:44 - train: epoch 0081, iter [00740, 01251], lr: 0.000200, loss: 2.7123
2022-10-09 01:54:05 - train: epoch 0081, iter [00750, 01251], lr: 0.000200, loss: 2.4412
2022-10-09 01:54:26 - train: epoch 0081, iter [00760, 01251], lr: 0.000200, loss: 3.1354
2022-10-09 01:54:47 - train: epoch 0081, iter [00770, 01251], lr: 0.000199, loss: 3.2397
2022-10-09 01:55:08 - train: epoch 0081, iter [00780, 01251], lr: 0.000199, loss: 2.4145
2022-10-09 01:55:29 - train: epoch 0081, iter [00790, 01251], lr: 0.000199, loss: 2.3976
2022-10-09 01:55:50 - train: epoch 0081, iter [00800, 01251], lr: 0.000199, loss: 2.5170
2022-10-09 01:56:12 - train: epoch 0081, iter [00810, 01251], lr: 0.000199, loss: 3.0801
2022-10-09 01:56:33 - train: epoch 0081, iter [00820, 01251], lr: 0.000199, loss: 2.9301
2022-10-09 01:56:54 - train: epoch 0081, iter [00830, 01251], lr: 0.000198, loss: 2.5615
2022-10-09 01:57:15 - train: epoch 0081, iter [00840, 01251], lr: 0.000198, loss: 2.9343
2022-10-09 01:57:36 - train: epoch 0081, iter [00850, 01251], lr: 0.000198, loss: 2.4631
2022-10-09 01:57:57 - train: epoch 0081, iter [00860, 01251], lr: 0.000198, loss: 2.3858
2022-10-09 01:58:18 - train: epoch 0081, iter [00870, 01251], lr: 0.000198, loss: 2.8694
2022-10-09 01:58:39 - train: epoch 0081, iter [00880, 01251], lr: 0.000198, loss: 2.1886
2022-10-09 01:59:00 - train: epoch 0081, iter [00890, 01251], lr: 0.000198, loss: 2.2026
2022-10-09 01:59:22 - train: epoch 0081, iter [00900, 01251], lr: 0.000197, loss: 2.1572
2022-10-09 01:59:43 - train: epoch 0081, iter [00910, 01251], lr: 0.000197, loss: 3.0157
2022-10-09 02:00:04 - train: epoch 0081, iter [00920, 01251], lr: 0.000197, loss: 2.5909
2022-10-09 02:00:25 - train: epoch 0081, iter [00930, 01251], lr: 0.000197, loss: 2.1899
2022-10-09 02:00:46 - train: epoch 0081, iter [00940, 01251], lr: 0.000197, loss: 2.6257
2022-10-09 02:01:07 - train: epoch 0081, iter [00950, 01251], lr: 0.000197, loss: 2.5608
2022-10-09 02:01:28 - train: epoch 0081, iter [00960, 01251], lr: 0.000196, loss: 2.9649
2022-10-09 02:01:49 - train: epoch 0081, iter [00970, 01251], lr: 0.000196, loss: 3.0730
2022-10-09 02:02:10 - train: epoch 0081, iter [00980, 01251], lr: 0.000196, loss: 2.3969
2022-10-09 02:02:31 - train: epoch 0081, iter [00990, 01251], lr: 0.000196, loss: 2.6504
2022-10-09 02:02:52 - train: epoch 0081, iter [01000, 01251], lr: 0.000196, loss: 2.9273
2022-10-09 02:03:13 - train: epoch 0081, iter [01010, 01251], lr: 0.000196, loss: 2.5580
2022-10-09 02:03:34 - train: epoch 0081, iter [01020, 01251], lr: 0.000195, loss: 2.9850
2022-10-09 02:03:55 - train: epoch 0081, iter [01030, 01251], lr: 0.000195, loss: 3.2609
2022-10-09 02:04:16 - train: epoch 0081, iter [01040, 01251], lr: 0.000195, loss: 3.0159
2022-10-09 02:04:37 - train: epoch 0081, iter [01050, 01251], lr: 0.000195, loss: 2.2494
2022-10-09 02:04:58 - train: epoch 0081, iter [01060, 01251], lr: 0.000195, loss: 2.3847
2022-10-09 02:05:19 - train: epoch 0081, iter [01070, 01251], lr: 0.000195, loss: 3.2676
2022-10-09 02:05:40 - train: epoch 0081, iter [01080, 01251], lr: 0.000195, loss: 2.2788
2022-10-09 02:06:01 - train: epoch 0081, iter [01090, 01251], lr: 0.000194, loss: 2.9401
2022-10-09 02:06:22 - train: epoch 0081, iter [01100, 01251], lr: 0.000194, loss: 3.3569
2022-10-09 02:06:44 - train: epoch 0081, iter [01110, 01251], lr: 0.000194, loss: 3.1733
2022-10-09 02:07:05 - train: epoch 0081, iter [01120, 01251], lr: 0.000194, loss: 3.1746
2022-10-09 02:07:26 - train: epoch 0081, iter [01130, 01251], lr: 0.000194, loss: 2.7486
2022-10-09 02:07:47 - train: epoch 0081, iter [01140, 01251], lr: 0.000194, loss: 2.4935
2022-10-09 02:08:08 - train: epoch 0081, iter [01150, 01251], lr: 0.000193, loss: 2.9119
2022-10-09 02:08:29 - train: epoch 0081, iter [01160, 01251], lr: 0.000193, loss: 2.5248
2022-10-09 02:08:50 - train: epoch 0081, iter [01170, 01251], lr: 0.000193, loss: 2.7135
2022-10-09 02:09:11 - train: epoch 0081, iter [01180, 01251], lr: 0.000193, loss: 3.0736
2022-10-09 02:09:32 - train: epoch 0081, iter [01190, 01251], lr: 0.000193, loss: 2.9369
2022-10-09 02:09:53 - train: epoch 0081, iter [01200, 01251], lr: 0.000193, loss: 2.9249
2022-10-09 02:10:14 - train: epoch 0081, iter [01210, 01251], lr: 0.000193, loss: 3.0441
2022-10-09 02:10:35 - train: epoch 0081, iter [01220, 01251], lr: 0.000192, loss: 2.8695
2022-10-09 02:10:56 - train: epoch 0081, iter [01230, 01251], lr: 0.000192, loss: 2.5951
2022-10-09 02:11:17 - train: epoch 0081, iter [01240, 01251], lr: 0.000192, loss: 2.6503
2022-10-09 02:11:38 - train: epoch 0081, iter [01250, 01251], lr: 0.000192, loss: 2.6181
2022-10-09 02:11:42 - train: epoch 081, train_loss: 2.8180
2022-10-09 02:12:58 - eval: epoch: 081, acc1: 82.864%, acc5: 96.436%, test_loss: 0.7605, per_image_load_time: 0.865ms, per_image_inference_time: 1.430ms
2022-10-09 02:13:00 - until epoch: 081, best_acc1: 82.864%
2022-10-09 02:13:00 - epoch 082 lr: 0.000192
2022-10-09 02:13:26 - train: epoch 0082, iter [00010, 01251], lr: 0.000192, loss: 2.1952
2022-10-09 02:13:47 - train: epoch 0082, iter [00020, 01251], lr: 0.000192, loss: 3.2410
2022-10-09 02:14:09 - train: epoch 0082, iter [00030, 01251], lr: 0.000191, loss: 2.9271
2022-10-09 02:14:30 - train: epoch 0082, iter [00040, 01251], lr: 0.000191, loss: 2.7178
2022-10-09 02:14:51 - train: epoch 0082, iter [00050, 01251], lr: 0.000191, loss: 3.2072
2022-10-09 02:15:12 - train: epoch 0082, iter [00060, 01251], lr: 0.000191, loss: 3.0490
2022-10-09 02:15:33 - train: epoch 0082, iter [00070, 01251], lr: 0.000191, loss: 2.9409
2022-10-09 02:15:54 - train: epoch 0082, iter [00080, 01251], lr: 0.000191, loss: 2.9784
2022-10-09 02:16:16 - train: epoch 0082, iter [00090, 01251], lr: 0.000190, loss: 3.0032
2022-10-09 02:16:37 - train: epoch 0082, iter [00100, 01251], lr: 0.000190, loss: 2.7747
2022-10-09 02:16:58 - train: epoch 0082, iter [00110, 01251], lr: 0.000190, loss: 2.9975
2022-10-09 02:17:19 - train: epoch 0082, iter [00120, 01251], lr: 0.000190, loss: 2.5786
2022-10-09 02:17:40 - train: epoch 0082, iter [00130, 01251], lr: 0.000190, loss: 2.5590
2022-10-09 02:18:01 - train: epoch 0082, iter [00140, 01251], lr: 0.000190, loss: 3.0053
2022-10-09 02:18:22 - train: epoch 0082, iter [00150, 01251], lr: 0.000190, loss: 2.3606
2022-10-09 02:18:43 - train: epoch 0082, iter [00160, 01251], lr: 0.000189, loss: 3.1210
2022-10-09 02:19:04 - train: epoch 0082, iter [00170, 01251], lr: 0.000189, loss: 2.6441
2022-10-09 02:19:25 - train: epoch 0082, iter [00180, 01251], lr: 0.000189, loss: 2.7595
2022-10-09 02:19:46 - train: epoch 0082, iter [00190, 01251], lr: 0.000189, loss: 2.8558
2022-10-09 02:20:07 - train: epoch 0082, iter [00200, 01251], lr: 0.000189, loss: 3.2230
2022-10-09 02:20:29 - train: epoch 0082, iter [00210, 01251], lr: 0.000189, loss: 2.6511
2022-10-09 02:20:50 - train: epoch 0082, iter [00220, 01251], lr: 0.000188, loss: 2.6784
2022-10-09 02:21:11 - train: epoch 0082, iter [00230, 01251], lr: 0.000188, loss: 3.0363
2022-10-09 02:21:32 - train: epoch 0082, iter [00240, 01251], lr: 0.000188, loss: 2.6816
2022-10-09 02:21:53 - train: epoch 0082, iter [00250, 01251], lr: 0.000188, loss: 2.6226
2022-10-09 02:22:14 - train: epoch 0082, iter [00260, 01251], lr: 0.000188, loss: 2.9073
2022-10-09 02:22:35 - train: epoch 0082, iter [00270, 01251], lr: 0.000188, loss: 2.9650
2022-10-09 02:22:57 - train: epoch 0082, iter [00280, 01251], lr: 0.000188, loss: 2.9849
2022-10-09 02:23:18 - train: epoch 0082, iter [00290, 01251], lr: 0.000187, loss: 2.1599
2022-10-09 02:23:39 - train: epoch 0082, iter [00300, 01251], lr: 0.000187, loss: 2.9332
2022-10-09 02:24:00 - train: epoch 0082, iter [00310, 01251], lr: 0.000187, loss: 2.7403
2022-10-09 02:24:21 - train: epoch 0082, iter [00320, 01251], lr: 0.000187, loss: 2.8161
2022-10-09 02:24:42 - train: epoch 0082, iter [00330, 01251], lr: 0.000187, loss: 2.7916
2022-10-09 02:25:03 - train: epoch 0082, iter [00340, 01251], lr: 0.000187, loss: 2.8761
2022-10-09 02:25:25 - train: epoch 0082, iter [00350, 01251], lr: 0.000186, loss: 2.8047
2022-10-09 02:25:46 - train: epoch 0082, iter [00360, 01251], lr: 0.000186, loss: 3.0568
2022-10-09 02:26:07 - train: epoch 0082, iter [00370, 01251], lr: 0.000186, loss: 2.7078
2022-10-09 02:26:28 - train: epoch 0082, iter [00380, 01251], lr: 0.000186, loss: 3.3325
2022-10-09 02:26:49 - train: epoch 0082, iter [00390, 01251], lr: 0.000186, loss: 2.5515
2022-10-09 02:27:10 - train: epoch 0082, iter [00400, 01251], lr: 0.000186, loss: 3.1318
2022-10-09 02:27:31 - train: epoch 0082, iter [00410, 01251], lr: 0.000186, loss: 2.9157
2022-10-09 02:27:52 - train: epoch 0082, iter [00420, 01251], lr: 0.000185, loss: 3.2641
2022-10-09 02:28:13 - train: epoch 0082, iter [00430, 01251], lr: 0.000185, loss: 2.2427
2022-10-09 02:28:34 - train: epoch 0082, iter [00440, 01251], lr: 0.000185, loss: 2.1854
2022-10-09 02:28:55 - train: epoch 0082, iter [00450, 01251], lr: 0.000185, loss: 3.0178
2022-10-09 02:29:16 - train: epoch 0082, iter [00460, 01251], lr: 0.000185, loss: 2.8728
2022-10-09 02:29:38 - train: epoch 0082, iter [00470, 01251], lr: 0.000185, loss: 3.0587
2022-10-09 02:29:59 - train: epoch 0082, iter [00480, 01251], lr: 0.000184, loss: 2.3794
2022-10-09 02:30:20 - train: epoch 0082, iter [00490, 01251], lr: 0.000184, loss: 2.4810
2022-10-09 02:30:41 - train: epoch 0082, iter [00500, 01251], lr: 0.000184, loss: 2.6371
2022-10-09 02:31:02 - train: epoch 0082, iter [00510, 01251], lr: 0.000184, loss: 3.1323
2022-10-09 02:31:24 - train: epoch 0082, iter [00520, 01251], lr: 0.000184, loss: 2.7609
2022-10-09 02:31:45 - train: epoch 0082, iter [00530, 01251], lr: 0.000184, loss: 2.7121
2022-10-09 02:32:06 - train: epoch 0082, iter [00540, 01251], lr: 0.000184, loss: 3.0639
2022-10-09 02:32:27 - train: epoch 0082, iter [00550, 01251], lr: 0.000183, loss: 2.5533
2022-10-09 02:32:48 - train: epoch 0082, iter [00560, 01251], lr: 0.000183, loss: 3.0610
2022-10-09 02:33:09 - train: epoch 0082, iter [00570, 01251], lr: 0.000183, loss: 3.1298
2022-10-09 02:33:30 - train: epoch 0082, iter [00580, 01251], lr: 0.000183, loss: 3.0852
2022-10-09 02:33:51 - train: epoch 0082, iter [00590, 01251], lr: 0.000183, loss: 2.6524
2022-10-09 02:34:12 - train: epoch 0082, iter [00600, 01251], lr: 0.000183, loss: 2.6365
2022-10-09 02:34:33 - train: epoch 0082, iter [00610, 01251], lr: 0.000183, loss: 2.9237
2022-10-09 02:34:55 - train: epoch 0082, iter [00620, 01251], lr: 0.000182, loss: 2.9482
2022-10-09 02:35:16 - train: epoch 0082, iter [00630, 01251], lr: 0.000182, loss: 2.2769
2022-10-09 02:35:37 - train: epoch 0082, iter [00640, 01251], lr: 0.000182, loss: 2.6568
2022-10-09 02:35:58 - train: epoch 0082, iter [00650, 01251], lr: 0.000182, loss: 3.0018
2022-10-09 02:36:19 - train: epoch 0082, iter [00660, 01251], lr: 0.000182, loss: 2.2115
2022-10-09 02:36:40 - train: epoch 0082, iter [00670, 01251], lr: 0.000182, loss: 2.1002
2022-10-09 02:37:01 - train: epoch 0082, iter [00680, 01251], lr: 0.000181, loss: 3.1713
2022-10-09 02:37:22 - train: epoch 0082, iter [00690, 01251], lr: 0.000181, loss: 3.0700
2022-10-09 02:37:43 - train: epoch 0082, iter [00700, 01251], lr: 0.000181, loss: 2.8201
2022-10-09 02:38:04 - train: epoch 0082, iter [00710, 01251], lr: 0.000181, loss: 2.9710
2022-10-09 02:38:25 - train: epoch 0082, iter [00720, 01251], lr: 0.000181, loss: 2.2443
2022-10-09 02:38:46 - train: epoch 0082, iter [00730, 01251], lr: 0.000181, loss: 2.9512
2022-10-09 02:39:07 - train: epoch 0082, iter [00740, 01251], lr: 0.000181, loss: 3.1514
2022-10-09 02:39:28 - train: epoch 0082, iter [00750, 01251], lr: 0.000180, loss: 2.8894
2022-10-09 02:39:49 - train: epoch 0082, iter [00760, 01251], lr: 0.000180, loss: 1.9318
2022-10-09 02:40:10 - train: epoch 0082, iter [00770, 01251], lr: 0.000180, loss: 2.7287
2022-10-09 02:40:31 - train: epoch 0082, iter [00780, 01251], lr: 0.000180, loss: 3.2836
2022-10-09 02:40:52 - train: epoch 0082, iter [00790, 01251], lr: 0.000180, loss: 2.8978
2022-10-09 02:41:13 - train: epoch 0082, iter [00800, 01251], lr: 0.000180, loss: 3.2065
2022-10-09 02:41:34 - train: epoch 0082, iter [00810, 01251], lr: 0.000179, loss: 2.9558
2022-10-09 02:41:55 - train: epoch 0082, iter [00820, 01251], lr: 0.000179, loss: 2.8132
2022-10-09 02:42:16 - train: epoch 0082, iter [00830, 01251], lr: 0.000179, loss: 2.5849
2022-10-09 02:42:37 - train: epoch 0082, iter [00840, 01251], lr: 0.000179, loss: 2.9448
2022-10-09 02:42:58 - train: epoch 0082, iter [00850, 01251], lr: 0.000179, loss: 2.9986
2022-10-09 02:43:19 - train: epoch 0082, iter [00860, 01251], lr: 0.000179, loss: 2.2561
2022-10-09 02:43:40 - train: epoch 0082, iter [00870, 01251], lr: 0.000179, loss: 3.1818
2022-10-09 02:44:01 - train: epoch 0082, iter [00880, 01251], lr: 0.000178, loss: 2.8185
2022-10-09 02:44:22 - train: epoch 0082, iter [00890, 01251], lr: 0.000178, loss: 3.3426
2022-10-09 02:44:43 - train: epoch 0082, iter [00900, 01251], lr: 0.000178, loss: 2.7898
2022-10-09 02:45:04 - train: epoch 0082, iter [00910, 01251], lr: 0.000178, loss: 3.1856
2022-10-09 02:45:25 - train: epoch 0082, iter [00920, 01251], lr: 0.000178, loss: 2.9809
2022-10-09 02:45:47 - train: epoch 0082, iter [00930, 01251], lr: 0.000178, loss: 2.3490
2022-10-09 02:46:08 - train: epoch 0082, iter [00940, 01251], lr: 0.000178, loss: 2.7666
2022-10-09 02:46:29 - train: epoch 0082, iter [00950, 01251], lr: 0.000177, loss: 3.2458
2022-10-09 02:46:50 - train: epoch 0082, iter [00960, 01251], lr: 0.000177, loss: 2.8980
2022-10-09 02:47:11 - train: epoch 0082, iter [00970, 01251], lr: 0.000177, loss: 2.6256
2022-10-09 02:47:32 - train: epoch 0082, iter [00980, 01251], lr: 0.000177, loss: 2.7993
2022-10-09 02:47:53 - train: epoch 0082, iter [00990, 01251], lr: 0.000177, loss: 3.0478
2022-10-09 02:48:14 - train: epoch 0082, iter [01000, 01251], lr: 0.000177, loss: 2.6079
2022-10-09 02:48:35 - train: epoch 0082, iter [01010, 01251], lr: 0.000176, loss: 3.0145
2022-10-09 02:48:56 - train: epoch 0082, iter [01020, 01251], lr: 0.000176, loss: 1.9349
2022-10-09 02:49:17 - train: epoch 0082, iter [01030, 01251], lr: 0.000176, loss: 2.8964
2022-10-09 02:49:38 - train: epoch 0082, iter [01040, 01251], lr: 0.000176, loss: 3.1799
2022-10-09 02:49:59 - train: epoch 0082, iter [01050, 01251], lr: 0.000176, loss: 2.2877
2022-10-09 02:50:20 - train: epoch 0082, iter [01060, 01251], lr: 0.000176, loss: 3.0264
2022-10-09 02:50:41 - train: epoch 0082, iter [01070, 01251], lr: 0.000176, loss: 2.5765
2022-10-09 02:51:02 - train: epoch 0082, iter [01080, 01251], lr: 0.000175, loss: 3.1443
2022-10-09 02:51:23 - train: epoch 0082, iter [01090, 01251], lr: 0.000175, loss: 2.8372
2022-10-09 02:51:44 - train: epoch 0082, iter [01100, 01251], lr: 0.000175, loss: 2.5181
2022-10-09 02:52:05 - train: epoch 0082, iter [01110, 01251], lr: 0.000175, loss: 3.0295
2022-10-09 02:52:26 - train: epoch 0082, iter [01120, 01251], lr: 0.000175, loss: 2.7371
2022-10-09 02:52:47 - train: epoch 0082, iter [01130, 01251], lr: 0.000175, loss: 2.8013
2022-10-09 02:53:08 - train: epoch 0082, iter [01140, 01251], lr: 0.000175, loss: 2.8445
2022-10-09 02:53:29 - train: epoch 0082, iter [01150, 01251], lr: 0.000174, loss: 2.8014
2022-10-09 02:53:50 - train: epoch 0082, iter [01160, 01251], lr: 0.000174, loss: 2.8956
2022-10-09 02:54:11 - train: epoch 0082, iter [01170, 01251], lr: 0.000174, loss: 2.3182
2022-10-09 02:54:32 - train: epoch 0082, iter [01180, 01251], lr: 0.000174, loss: 2.6938
2022-10-09 02:54:53 - train: epoch 0082, iter [01190, 01251], lr: 0.000174, loss: 2.5047
2022-10-09 02:55:14 - train: epoch 0082, iter [01200, 01251], lr: 0.000174, loss: 2.8036
2022-10-09 02:55:35 - train: epoch 0082, iter [01210, 01251], lr: 0.000174, loss: 2.8731
2022-10-09 02:55:56 - train: epoch 0082, iter [01220, 01251], lr: 0.000173, loss: 2.8189
2022-10-09 02:56:17 - train: epoch 0082, iter [01230, 01251], lr: 0.000173, loss: 3.2654
2022-10-09 02:56:38 - train: epoch 0082, iter [01240, 01251], lr: 0.000173, loss: 3.2917
2022-10-09 02:56:59 - train: epoch 0082, iter [01250, 01251], lr: 0.000173, loss: 3.1744
2022-10-09 02:57:03 - train: epoch 082, train_loss: 2.8125
2022-10-09 02:58:22 - eval: epoch: 082, acc1: 82.786%, acc5: 96.422%, test_loss: 0.7706, per_image_load_time: 1.546ms, per_image_inference_time: 1.447ms
2022-10-09 02:58:23 - until epoch: 082, best_acc1: 82.864%
2022-10-09 02:58:23 - epoch 083 lr: 0.000173
2022-10-09 02:58:50 - train: epoch 0083, iter [00010, 01251], lr: 0.000173, loss: 3.0444
2022-10-09 02:59:11 - train: epoch 0083, iter [00020, 01251], lr: 0.000173, loss: 2.8624
2022-10-09 02:59:32 - train: epoch 0083, iter [00030, 01251], lr: 0.000172, loss: 3.0309
2022-10-09 02:59:53 - train: epoch 0083, iter [00040, 01251], lr: 0.000172, loss: 2.8176
2022-10-09 03:00:14 - train: epoch 0083, iter [00050, 01251], lr: 0.000172, loss: 2.9483
2022-10-09 03:00:35 - train: epoch 0083, iter [00060, 01251], lr: 0.000172, loss: 2.9533
2022-10-09 03:00:56 - train: epoch 0083, iter [00070, 01251], lr: 0.000172, loss: 2.0962
2022-10-09 03:01:17 - train: epoch 0083, iter [00080, 01251], lr: 0.000172, loss: 3.0816
2022-10-09 03:01:39 - train: epoch 0083, iter [00090, 01251], lr: 0.000172, loss: 3.2885
2022-10-09 03:02:00 - train: epoch 0083, iter [00100, 01251], lr: 0.000171, loss: 3.2359
2022-10-09 03:02:21 - train: epoch 0083, iter [00110, 01251], lr: 0.000171, loss: 2.5428
2022-10-09 03:02:42 - train: epoch 0083, iter [00120, 01251], lr: 0.000171, loss: 3.0043
2022-10-09 03:03:03 - train: epoch 0083, iter [00130, 01251], lr: 0.000171, loss: 3.0959
2022-10-09 03:03:24 - train: epoch 0083, iter [00140, 01251], lr: 0.000171, loss: 2.8680
2022-10-09 03:03:46 - train: epoch 0083, iter [00150, 01251], lr: 0.000171, loss: 2.5223
2022-10-09 03:04:07 - train: epoch 0083, iter [00160, 01251], lr: 0.000171, loss: 3.1453
2022-10-09 03:04:28 - train: epoch 0083, iter [00170, 01251], lr: 0.000170, loss: 2.5938
2022-10-09 03:04:49 - train: epoch 0083, iter [00180, 01251], lr: 0.000170, loss: 3.0593
2022-10-09 03:05:10 - train: epoch 0083, iter [00190, 01251], lr: 0.000170, loss: 2.8860
2022-10-09 03:05:31 - train: epoch 0083, iter [00200, 01251], lr: 0.000170, loss: 2.5320
2022-10-09 03:05:52 - train: epoch 0083, iter [00210, 01251], lr: 0.000170, loss: 2.7678
2022-10-09 03:06:13 - train: epoch 0083, iter [00220, 01251], lr: 0.000170, loss: 2.5487
2022-10-09 03:06:34 - train: epoch 0083, iter [00230, 01251], lr: 0.000170, loss: 3.1356
2022-10-09 03:06:55 - train: epoch 0083, iter [00240, 01251], lr: 0.000169, loss: 2.5857
2022-10-09 03:07:16 - train: epoch 0083, iter [00250, 01251], lr: 0.000169, loss: 2.9415
2022-10-09 03:07:37 - train: epoch 0083, iter [00260, 01251], lr: 0.000169, loss: 2.3528
2022-10-09 03:07:59 - train: epoch 0083, iter [00270, 01251], lr: 0.000169, loss: 2.7669
2022-10-09 03:08:20 - train: epoch 0083, iter [00280, 01251], lr: 0.000169, loss: 2.3527
2022-10-09 03:08:41 - train: epoch 0083, iter [00290, 01251], lr: 0.000169, loss: 2.3689
2022-10-09 03:09:02 - train: epoch 0083, iter [00300, 01251], lr: 0.000168, loss: 3.1428
2022-10-09 03:09:23 - train: epoch 0083, iter [00310, 01251], lr: 0.000168, loss: 3.0632
2022-10-09 03:09:44 - train: epoch 0083, iter [00320, 01251], lr: 0.000168, loss: 2.6753
2022-10-09 03:10:05 - train: epoch 0083, iter [00330, 01251], lr: 0.000168, loss: 2.5698
2022-10-09 03:10:27 - train: epoch 0083, iter [00340, 01251], lr: 0.000168, loss: 2.4732
2022-10-09 03:10:48 - train: epoch 0083, iter [00350, 01251], lr: 0.000168, loss: 2.7094
2022-10-09 03:11:09 - train: epoch 0083, iter [00360, 01251], lr: 0.000168, loss: 2.8266
2022-10-09 03:11:30 - train: epoch 0083, iter [00370, 01251], lr: 0.000167, loss: 3.2902
2022-10-09 03:11:51 - train: epoch 0083, iter [00380, 01251], lr: 0.000167, loss: 2.9223
2022-10-09 03:12:12 - train: epoch 0083, iter [00390, 01251], lr: 0.000167, loss: 3.1942
2022-10-09 03:12:33 - train: epoch 0083, iter [00400, 01251], lr: 0.000167, loss: 3.3064
2022-10-09 03:12:54 - train: epoch 0083, iter [00410, 01251], lr: 0.000167, loss: 3.2117
2022-10-09 03:13:16 - train: epoch 0083, iter [00420, 01251], lr: 0.000167, loss: 2.9508
2022-10-09 03:13:37 - train: epoch 0083, iter [00430, 01251], lr: 0.000167, loss: 2.5648
2022-10-09 03:13:58 - train: epoch 0083, iter [00440, 01251], lr: 0.000166, loss: 2.8151
2022-10-09 03:14:19 - train: epoch 0083, iter [00450, 01251], lr: 0.000166, loss: 2.1299
2022-10-09 03:14:40 - train: epoch 0083, iter [00460, 01251], lr: 0.000166, loss: 2.9579
2022-10-09 03:15:01 - train: epoch 0083, iter [00470, 01251], lr: 0.000166, loss: 3.1688
2022-10-09 03:15:22 - train: epoch 0083, iter [00480, 01251], lr: 0.000166, loss: 3.3667
2022-10-09 03:15:43 - train: epoch 0083, iter [00490, 01251], lr: 0.000166, loss: 2.6612
2022-10-09 03:16:04 - train: epoch 0083, iter [00500, 01251], lr: 0.000166, loss: 2.4123
2022-10-09 03:16:25 - train: epoch 0083, iter [00510, 01251], lr: 0.000165, loss: 3.4072
2022-10-09 03:16:46 - train: epoch 0083, iter [00520, 01251], lr: 0.000165, loss: 3.0076
2022-10-09 03:17:07 - train: epoch 0083, iter [00530, 01251], lr: 0.000165, loss: 2.6009
2022-10-09 03:17:28 - train: epoch 0083, iter [00540, 01251], lr: 0.000165, loss: 2.3841
2022-10-09 03:17:49 - train: epoch 0083, iter [00550, 01251], lr: 0.000165, loss: 2.6883
2022-10-09 03:18:10 - train: epoch 0083, iter [00560, 01251], lr: 0.000165, loss: 2.7853
2022-10-09 03:18:32 - train: epoch 0083, iter [00570, 01251], lr: 0.000165, loss: 3.2610
2022-10-09 03:18:53 - train: epoch 0083, iter [00580, 01251], lr: 0.000164, loss: 2.3217
2022-10-09 03:19:14 - train: epoch 0083, iter [00590, 01251], lr: 0.000164, loss: 3.0733
2022-10-09 03:19:35 - train: epoch 0083, iter [00600, 01251], lr: 0.000164, loss: 2.0972
2022-10-09 03:19:56 - train: epoch 0083, iter [00610, 01251], lr: 0.000164, loss: 2.6565
2022-10-09 03:20:17 - train: epoch 0083, iter [00620, 01251], lr: 0.000164, loss: 2.4558
2022-10-09 03:20:38 - train: epoch 0083, iter [00630, 01251], lr: 0.000164, loss: 3.0435
2022-10-09 03:20:59 - train: epoch 0083, iter [00640, 01251], lr: 0.000164, loss: 2.9136
2022-10-09 03:21:20 - train: epoch 0083, iter [00650, 01251], lr: 0.000163, loss: 2.8106
2022-10-09 03:21:41 - train: epoch 0083, iter [00660, 01251], lr: 0.000163, loss: 2.9027
2022-10-09 03:22:02 - train: epoch 0083, iter [00670, 01251], lr: 0.000163, loss: 3.2190
2022-10-09 03:22:23 - train: epoch 0083, iter [00680, 01251], lr: 0.000163, loss: 2.5462
2022-10-09 03:22:44 - train: epoch 0083, iter [00690, 01251], lr: 0.000163, loss: 3.1675
2022-10-09 03:23:05 - train: epoch 0083, iter [00700, 01251], lr: 0.000163, loss: 3.3049
2022-10-09 03:23:26 - train: epoch 0083, iter [00710, 01251], lr: 0.000163, loss: 2.8412
2022-10-09 03:23:48 - train: epoch 0083, iter [00720, 01251], lr: 0.000162, loss: 2.0304
2022-10-09 03:24:09 - train: epoch 0083, iter [00730, 01251], lr: 0.000162, loss: 2.8601
2022-10-09 03:24:30 - train: epoch 0083, iter [00740, 01251], lr: 0.000162, loss: 2.6868
2022-10-09 03:24:51 - train: epoch 0083, iter [00750, 01251], lr: 0.000162, loss: 2.5938
2022-10-09 03:25:12 - train: epoch 0083, iter [00760, 01251], lr: 0.000162, loss: 2.6262
2022-10-09 03:25:33 - train: epoch 0083, iter [00770, 01251], lr: 0.000162, loss: 3.0086
2022-10-09 03:25:54 - train: epoch 0083, iter [00780, 01251], lr: 0.000162, loss: 2.4490
2022-10-09 03:26:15 - train: epoch 0083, iter [00790, 01251], lr: 0.000161, loss: 3.1747
2022-10-09 03:26:36 - train: epoch 0083, iter [00800, 01251], lr: 0.000161, loss: 2.8432
2022-10-09 03:26:57 - train: epoch 0083, iter [00810, 01251], lr: 0.000161, loss: 2.9654
2022-10-09 03:27:18 - train: epoch 0083, iter [00820, 01251], lr: 0.000161, loss: 3.2116
2022-10-09 03:27:39 - train: epoch 0083, iter [00830, 01251], lr: 0.000161, loss: 2.7557
2022-10-09 03:28:00 - train: epoch 0083, iter [00840, 01251], lr: 0.000161, loss: 2.8685
2022-10-09 03:28:22 - train: epoch 0083, iter [00850, 01251], lr: 0.000161, loss: 2.4717
2022-10-09 03:28:43 - train: epoch 0083, iter [00860, 01251], lr: 0.000160, loss: 3.0212
2022-10-09 03:29:04 - train: epoch 0083, iter [00870, 01251], lr: 0.000160, loss: 2.3686
2022-10-09 03:29:25 - train: epoch 0083, iter [00880, 01251], lr: 0.000160, loss: 2.4921
2022-10-09 03:29:46 - train: epoch 0083, iter [00890, 01251], lr: 0.000160, loss: 3.0516
2022-10-09 03:30:07 - train: epoch 0083, iter [00900, 01251], lr: 0.000160, loss: 2.5322
2022-10-09 03:30:28 - train: epoch 0083, iter [00910, 01251], lr: 0.000160, loss: 2.3996
2022-10-09 03:30:49 - train: epoch 0083, iter [00920, 01251], lr: 0.000160, loss: 2.2537
2022-10-09 03:31:10 - train: epoch 0083, iter [00930, 01251], lr: 0.000159, loss: 2.9771
2022-10-09 03:31:31 - train: epoch 0083, iter [00940, 01251], lr: 0.000159, loss: 2.7938
2022-10-09 03:31:52 - train: epoch 0083, iter [00950, 01251], lr: 0.000159, loss: 2.8474
2022-10-09 03:32:13 - train: epoch 0083, iter [00960, 01251], lr: 0.000159, loss: 3.1468
2022-10-09 03:32:34 - train: epoch 0083, iter [00970, 01251], lr: 0.000159, loss: 3.0130
2022-10-09 03:32:55 - train: epoch 0083, iter [00980, 01251], lr: 0.000159, loss: 3.0134
2022-10-09 03:33:16 - train: epoch 0083, iter [00990, 01251], lr: 0.000159, loss: 2.5631
2022-10-09 03:33:38 - train: epoch 0083, iter [01000, 01251], lr: 0.000158, loss: 3.3670
2022-10-09 03:33:59 - train: epoch 0083, iter [01010, 01251], lr: 0.000158, loss: 2.8645
2022-10-09 03:34:20 - train: epoch 0083, iter [01020, 01251], lr: 0.000158, loss: 2.8988
2022-10-09 03:34:41 - train: epoch 0083, iter [01030, 01251], lr: 0.000158, loss: 1.9439
2022-10-09 03:35:02 - train: epoch 0083, iter [01040, 01251], lr: 0.000158, loss: 2.8591
2022-10-09 03:35:23 - train: epoch 0083, iter [01050, 01251], lr: 0.000158, loss: 2.6502
2022-10-09 03:35:44 - train: epoch 0083, iter [01060, 01251], lr: 0.000158, loss: 2.4998
2022-10-09 03:36:05 - train: epoch 0083, iter [01070, 01251], lr: 0.000157, loss: 1.9774
2022-10-09 03:36:26 - train: epoch 0083, iter [01080, 01251], lr: 0.000157, loss: 2.7399
2022-10-09 03:36:47 - train: epoch 0083, iter [01090, 01251], lr: 0.000157, loss: 2.7429
2022-10-09 03:37:09 - train: epoch 0083, iter [01100, 01251], lr: 0.000157, loss: 2.3914
2022-10-09 03:37:30 - train: epoch 0083, iter [01110, 01251], lr: 0.000157, loss: 3.1496
2022-10-09 03:37:51 - train: epoch 0083, iter [01120, 01251], lr: 0.000157, loss: 2.9510
2022-10-09 03:38:12 - train: epoch 0083, iter [01130, 01251], lr: 0.000157, loss: 2.6713
2022-10-09 03:38:33 - train: epoch 0083, iter [01140, 01251], lr: 0.000156, loss: 3.0238
2022-10-09 03:38:54 - train: epoch 0083, iter [01150, 01251], lr: 0.000156, loss: 2.9540
2022-10-09 03:39:15 - train: epoch 0083, iter [01160, 01251], lr: 0.000156, loss: 2.5802
2022-10-09 03:39:36 - train: epoch 0083, iter [01170, 01251], lr: 0.000156, loss: 3.1553
2022-10-09 03:39:57 - train: epoch 0083, iter [01180, 01251], lr: 0.000156, loss: 2.6636
2022-10-09 03:40:18 - train: epoch 0083, iter [01190, 01251], lr: 0.000156, loss: 3.0861
2022-10-09 03:40:39 - train: epoch 0083, iter [01200, 01251], lr: 0.000156, loss: 2.6728
2022-10-09 03:41:00 - train: epoch 0083, iter [01210, 01251], lr: 0.000155, loss: 3.1216
2022-10-09 03:41:21 - train: epoch 0083, iter [01220, 01251], lr: 0.000155, loss: 2.2286
2022-10-09 03:41:43 - train: epoch 0083, iter [01230, 01251], lr: 0.000155, loss: 2.4701
2022-10-09 03:42:04 - train: epoch 0083, iter [01240, 01251], lr: 0.000155, loss: 2.4659
2022-10-09 03:42:25 - train: epoch 0083, iter [01250, 01251], lr: 0.000155, loss: 2.4929
2022-10-09 03:42:28 - train: epoch 083, train_loss: 2.8064
2022-10-09 03:43:43 - eval: epoch: 083, acc1: 82.808%, acc5: 96.428%, test_loss: 0.7685, per_image_load_time: 0.707ms, per_image_inference_time: 1.427ms
2022-10-09 03:43:44 - until epoch: 083, best_acc1: 82.864%
2022-10-09 03:43:44 - epoch 084 lr: 0.000155
2022-10-09 03:44:12 - train: epoch 0084, iter [00010, 01251], lr: 0.000155, loss: 2.5730
2022-10-09 03:44:33 - train: epoch 0084, iter [00020, 01251], lr: 0.000155, loss: 2.3319
2022-10-09 03:44:54 - train: epoch 0084, iter [00030, 01251], lr: 0.000154, loss: 2.7820
2022-10-09 03:45:16 - train: epoch 0084, iter [00040, 01251], lr: 0.000154, loss: 3.1407
2022-10-09 03:45:37 - train: epoch 0084, iter [00050, 01251], lr: 0.000154, loss: 3.0343
2022-10-09 03:45:59 - train: epoch 0084, iter [00060, 01251], lr: 0.000154, loss: 2.8157
2022-10-09 03:46:20 - train: epoch 0084, iter [00070, 01251], lr: 0.000154, loss: 2.8891
2022-10-09 03:46:41 - train: epoch 0084, iter [00080, 01251], lr: 0.000154, loss: 2.6013
2022-10-09 03:47:02 - train: epoch 0084, iter [00090, 01251], lr: 0.000154, loss: 2.9103
2022-10-09 03:47:24 - train: epoch 0084, iter [00100, 01251], lr: 0.000153, loss: 2.5630
2022-10-09 03:47:45 - train: epoch 0084, iter [00110, 01251], lr: 0.000153, loss: 2.3928
2022-10-09 03:48:06 - train: epoch 0084, iter [00120, 01251], lr: 0.000153, loss: 2.9903
2022-10-09 03:48:27 - train: epoch 0084, iter [00130, 01251], lr: 0.000153, loss: 2.6052
2022-10-09 03:48:48 - train: epoch 0084, iter [00140, 01251], lr: 0.000153, loss: 2.0901
2022-10-09 03:49:09 - train: epoch 0084, iter [00150, 01251], lr: 0.000153, loss: 2.5193
2022-10-09 03:49:31 - train: epoch 0084, iter [00160, 01251], lr: 0.000153, loss: 2.9933
2022-10-09 03:49:52 - train: epoch 0084, iter [00170, 01251], lr: 0.000152, loss: 3.1373
2022-10-09 03:50:13 - train: epoch 0084, iter [00180, 01251], lr: 0.000152, loss: 2.7860
2022-10-09 03:50:34 - train: epoch 0084, iter [00190, 01251], lr: 0.000152, loss: 2.7091
2022-10-09 03:50:56 - train: epoch 0084, iter [00200, 01251], lr: 0.000152, loss: 3.2061
2022-10-09 03:51:17 - train: epoch 0084, iter [00210, 01251], lr: 0.000152, loss: 3.3736
2022-10-09 03:51:38 - train: epoch 0084, iter [00220, 01251], lr: 0.000152, loss: 3.0276
2022-10-09 03:51:59 - train: epoch 0084, iter [00230, 01251], lr: 0.000152, loss: 2.8025
2022-10-09 03:52:20 - train: epoch 0084, iter [00240, 01251], lr: 0.000151, loss: 3.1909
2022-10-09 03:52:41 - train: epoch 0084, iter [00250, 01251], lr: 0.000151, loss: 2.9681
2022-10-09 03:53:03 - train: epoch 0084, iter [00260, 01251], lr: 0.000151, loss: 3.1190
2022-10-09 03:53:24 - train: epoch 0084, iter [00270, 01251], lr: 0.000151, loss: 2.8208
2022-10-09 03:53:45 - train: epoch 0084, iter [00280, 01251], lr: 0.000151, loss: 2.9276
2022-10-09 03:54:06 - train: epoch 0084, iter [00290, 01251], lr: 0.000151, loss: 2.8951
2022-10-09 03:54:27 - train: epoch 0084, iter [00300, 01251], lr: 0.000151, loss: 2.6622
2022-10-09 03:54:49 - train: epoch 0084, iter [00310, 01251], lr: 0.000150, loss: 2.6200
2022-10-09 03:55:10 - train: epoch 0084, iter [00320, 01251], lr: 0.000150, loss: 3.0243
2022-10-09 03:55:31 - train: epoch 0084, iter [00330, 01251], lr: 0.000150, loss: 2.7658
2022-10-09 03:55:52 - train: epoch 0084, iter [00340, 01251], lr: 0.000150, loss: 2.4591
2022-10-09 03:56:13 - train: epoch 0084, iter [00350, 01251], lr: 0.000150, loss: 2.9733
2022-10-09 03:56:34 - train: epoch 0084, iter [00360, 01251], lr: 0.000150, loss: 3.0752
2022-10-09 03:56:56 - train: epoch 0084, iter [00370, 01251], lr: 0.000150, loss: 2.9913
2022-10-09 03:57:17 - train: epoch 0084, iter [00380, 01251], lr: 0.000150, loss: 2.5832
2022-10-09 03:57:38 - train: epoch 0084, iter [00390, 01251], lr: 0.000149, loss: 3.0574
2022-10-09 03:57:59 - train: epoch 0084, iter [00400, 01251], lr: 0.000149, loss: 3.0982
2022-10-09 03:58:20 - train: epoch 0084, iter [00410, 01251], lr: 0.000149, loss: 2.7653
2022-10-09 03:58:42 - train: epoch 0084, iter [00420, 01251], lr: 0.000149, loss: 3.0455
2022-10-09 03:59:03 - train: epoch 0084, iter [00430, 01251], lr: 0.000149, loss: 2.8844
2022-10-09 03:59:24 - train: epoch 0084, iter [00440, 01251], lr: 0.000149, loss: 2.9116
2022-10-09 03:59:45 - train: epoch 0084, iter [00450, 01251], lr: 0.000149, loss: 2.7925
2022-10-09 04:00:07 - train: epoch 0084, iter [00460, 01251], lr: 0.000148, loss: 2.7825
2022-10-09 04:00:28 - train: epoch 0084, iter [00470, 01251], lr: 0.000148, loss: 2.6483
2022-10-09 04:00:49 - train: epoch 0084, iter [00480, 01251], lr: 0.000148, loss: 2.7549
2022-10-09 04:01:10 - train: epoch 0084, iter [00490, 01251], lr: 0.000148, loss: 2.8290
2022-10-09 04:01:31 - train: epoch 0084, iter [00500, 01251], lr: 0.000148, loss: 2.6271
2022-10-09 04:01:52 - train: epoch 0084, iter [00510, 01251], lr: 0.000148, loss: 2.4200
2022-10-09 04:02:14 - train: epoch 0084, iter [00520, 01251], lr: 0.000148, loss: 3.0889
2022-10-09 04:02:35 - train: epoch 0084, iter [00530, 01251], lr: 0.000147, loss: 3.4693
2022-10-09 04:02:56 - train: epoch 0084, iter [00540, 01251], lr: 0.000147, loss: 2.1755
2022-10-09 04:03:17 - train: epoch 0084, iter [00550, 01251], lr: 0.000147, loss: 2.8921
2022-10-09 04:03:38 - train: epoch 0084, iter [00560, 01251], lr: 0.000147, loss: 2.3499
2022-10-09 04:03:59 - train: epoch 0084, iter [00570, 01251], lr: 0.000147, loss: 2.4433
2022-10-09 04:04:21 - train: epoch 0084, iter [00580, 01251], lr: 0.000147, loss: 2.6406
2022-10-09 04:04:42 - train: epoch 0084, iter [00590, 01251], lr: 0.000147, loss: 3.3259
2022-10-09 04:05:03 - train: epoch 0084, iter [00600, 01251], lr: 0.000146, loss: 2.9053
2022-10-09 04:05:24 - train: epoch 0084, iter [00610, 01251], lr: 0.000146, loss: 2.9537
2022-10-09 04:05:45 - train: epoch 0084, iter [00620, 01251], lr: 0.000146, loss: 3.0246
2022-10-09 04:06:06 - train: epoch 0084, iter [00630, 01251], lr: 0.000146, loss: 2.9249
2022-10-09 04:06:27 - train: epoch 0084, iter [00640, 01251], lr: 0.000146, loss: 2.8987
2022-10-09 04:06:49 - train: epoch 0084, iter [00650, 01251], lr: 0.000146, loss: 2.5827
2022-10-09 04:07:10 - train: epoch 0084, iter [00660, 01251], lr: 0.000146, loss: 2.0561
2022-10-09 04:07:31 - train: epoch 0084, iter [00670, 01251], lr: 0.000146, loss: 3.1206
2022-10-09 04:07:52 - train: epoch 0084, iter [00680, 01251], lr: 0.000145, loss: 3.0299
2022-10-09 04:08:13 - train: epoch 0084, iter [00690, 01251], lr: 0.000145, loss: 2.2603
2022-10-09 04:08:34 - train: epoch 0084, iter [00700, 01251], lr: 0.000145, loss: 3.0600
2022-10-09 04:08:55 - train: epoch 0084, iter [00710, 01251], lr: 0.000145, loss: 2.9942
2022-10-09 04:09:17 - train: epoch 0084, iter [00720, 01251], lr: 0.000145, loss: 2.7912
2022-10-09 04:09:38 - train: epoch 0084, iter [00730, 01251], lr: 0.000145, loss: 2.7374
2022-10-09 04:09:59 - train: epoch 0084, iter [00740, 01251], lr: 0.000145, loss: 2.0096
2022-10-09 04:10:20 - train: epoch 0084, iter [00750, 01251], lr: 0.000144, loss: 2.1769
2022-10-09 04:10:41 - train: epoch 0084, iter [00760, 01251], lr: 0.000144, loss: 2.4255
2022-10-09 04:11:02 - train: epoch 0084, iter [00770, 01251], lr: 0.000144, loss: 3.2157
2022-10-09 04:11:23 - train: epoch 0084, iter [00780, 01251], lr: 0.000144, loss: 3.0693
2022-10-09 04:11:45 - train: epoch 0084, iter [00790, 01251], lr: 0.000144, loss: 2.4971
2022-10-09 04:12:06 - train: epoch 0084, iter [00800, 01251], lr: 0.000144, loss: 2.3256
2022-10-09 04:12:27 - train: epoch 0084, iter [00810, 01251], lr: 0.000144, loss: 2.7390
2022-10-09 04:12:48 - train: epoch 0084, iter [00820, 01251], lr: 0.000143, loss: 2.9804
2022-10-09 04:13:09 - train: epoch 0084, iter [00830, 01251], lr: 0.000143, loss: 3.1768
2022-10-09 04:13:30 - train: epoch 0084, iter [00840, 01251], lr: 0.000143, loss: 2.8763
2022-10-09 04:13:51 - train: epoch 0084, iter [00850, 01251], lr: 0.000143, loss: 3.1532
2022-10-09 04:14:12 - train: epoch 0084, iter [00860, 01251], lr: 0.000143, loss: 3.1176
2022-10-09 04:14:33 - train: epoch 0084, iter [00870, 01251], lr: 0.000143, loss: 2.7408
2022-10-09 04:14:54 - train: epoch 0084, iter [00880, 01251], lr: 0.000143, loss: 2.8035
2022-10-09 04:15:16 - train: epoch 0084, iter [00890, 01251], lr: 0.000143, loss: 3.0679
2022-10-09 04:15:37 - train: epoch 0084, iter [00900, 01251], lr: 0.000142, loss: 3.2780
2022-10-09 04:15:58 - train: epoch 0084, iter [00910, 01251], lr: 0.000142, loss: 3.0551
2022-10-09 04:16:19 - train: epoch 0084, iter [00920, 01251], lr: 0.000142, loss: 2.8560
2022-10-09 04:16:41 - train: epoch 0084, iter [00930, 01251], lr: 0.000142, loss: 3.0119
2022-10-09 04:17:02 - train: epoch 0084, iter [00940, 01251], lr: 0.000142, loss: 2.7772
2022-10-09 04:17:23 - train: epoch 0084, iter [00950, 01251], lr: 0.000142, loss: 2.6653
2022-10-09 04:17:44 - train: epoch 0084, iter [00960, 01251], lr: 0.000142, loss: 2.6541
2022-10-09 04:18:06 - train: epoch 0084, iter [00970, 01251], lr: 0.000141, loss: 3.2161
2022-10-09 04:18:27 - train: epoch 0084, iter [00980, 01251], lr: 0.000141, loss: 2.5296
2022-10-09 04:18:48 - train: epoch 0084, iter [00990, 01251], lr: 0.000141, loss: 3.0242
2022-10-09 04:19:09 - train: epoch 0084, iter [01000, 01251], lr: 0.000141, loss: 2.5482
2022-10-09 04:19:31 - train: epoch 0084, iter [01010, 01251], lr: 0.000141, loss: 2.7820
2022-10-09 04:19:52 - train: epoch 0084, iter [01020, 01251], lr: 0.000141, loss: 2.5701
2022-10-09 04:20:13 - train: epoch 0084, iter [01030, 01251], lr: 0.000141, loss: 2.7919
2022-10-09 04:20:34 - train: epoch 0084, iter [01040, 01251], lr: 0.000141, loss: 2.6593
2022-10-09 04:20:55 - train: epoch 0084, iter [01050, 01251], lr: 0.000140, loss: 3.0021
2022-10-09 04:21:17 - train: epoch 0084, iter [01060, 01251], lr: 0.000140, loss: 2.6818
2022-10-09 04:21:38 - train: epoch 0084, iter [01070, 01251], lr: 0.000140, loss: 2.6191
2022-10-09 04:21:59 - train: epoch 0084, iter [01080, 01251], lr: 0.000140, loss: 2.5651
2022-10-09 04:22:21 - train: epoch 0084, iter [01090, 01251], lr: 0.000140, loss: 2.4019
2022-10-09 04:22:42 - train: epoch 0084, iter [01100, 01251], lr: 0.000140, loss: 3.0134
2022-10-09 04:23:03 - train: epoch 0084, iter [01110, 01251], lr: 0.000140, loss: 2.2027
2022-10-09 04:23:25 - train: epoch 0084, iter [01120, 01251], lr: 0.000139, loss: 3.0204
2022-10-09 04:23:46 - train: epoch 0084, iter [01130, 01251], lr: 0.000139, loss: 2.7920
2022-10-09 04:24:08 - train: epoch 0084, iter [01140, 01251], lr: 0.000139, loss: 2.8360
2022-10-09 04:24:29 - train: epoch 0084, iter [01150, 01251], lr: 0.000139, loss: 1.9066
2022-10-09 04:24:50 - train: epoch 0084, iter [01160, 01251], lr: 0.000139, loss: 2.6703
2022-10-09 04:25:12 - train: epoch 0084, iter [01170, 01251], lr: 0.000139, loss: 3.1962
2022-10-09 04:25:33 - train: epoch 0084, iter [01180, 01251], lr: 0.000139, loss: 3.2104
2022-10-09 04:25:55 - train: epoch 0084, iter [01190, 01251], lr: 0.000138, loss: 3.1058
2022-10-09 04:26:16 - train: epoch 0084, iter [01200, 01251], lr: 0.000138, loss: 3.1234
2022-10-09 04:26:37 - train: epoch 0084, iter [01210, 01251], lr: 0.000138, loss: 2.7477
2022-10-09 04:26:59 - train: epoch 0084, iter [01220, 01251], lr: 0.000138, loss: 2.5916
2022-10-09 04:27:20 - train: epoch 0084, iter [01230, 01251], lr: 0.000138, loss: 3.0718
2022-10-09 04:27:41 - train: epoch 0084, iter [01240, 01251], lr: 0.000138, loss: 2.5764
2022-10-09 04:28:03 - train: epoch 0084, iter [01250, 01251], lr: 0.000138, loss: 2.9026
2022-10-09 04:28:06 - train: epoch 084, train_loss: 2.8051
2022-10-09 04:29:22 - eval: epoch: 084, acc1: 82.890%, acc5: 96.456%, test_loss: 0.7558, per_image_load_time: 0.175ms, per_image_inference_time: 1.429ms
2022-10-09 04:29:24 - until epoch: 084, best_acc1: 82.890%
2022-10-09 04:29:24 - epoch 085 lr: 0.000138
2022-10-09 04:29:52 - train: epoch 0085, iter [00010, 01251], lr: 0.000138, loss: 3.0933
2022-10-09 04:30:13 - train: epoch 0085, iter [00020, 01251], lr: 0.000137, loss: 3.2160
2022-10-09 04:30:34 - train: epoch 0085, iter [00030, 01251], lr: 0.000137, loss: 2.5723
2022-10-09 04:30:56 - train: epoch 0085, iter [00040, 01251], lr: 0.000137, loss: 2.1487
2022-10-09 04:31:17 - train: epoch 0085, iter [00050, 01251], lr: 0.000137, loss: 2.8466
2022-10-09 04:31:39 - train: epoch 0085, iter [00060, 01251], lr: 0.000137, loss: 2.9659
2022-10-09 04:32:00 - train: epoch 0085, iter [00070, 01251], lr: 0.000137, loss: 2.8853
2022-10-09 04:32:21 - train: epoch 0085, iter [00080, 01251], lr: 0.000137, loss: 2.6515
2022-10-09 04:32:42 - train: epoch 0085, iter [00090, 01251], lr: 0.000136, loss: 2.9723
2022-10-09 04:33:04 - train: epoch 0085, iter [00100, 01251], lr: 0.000136, loss: 3.1255
2022-10-09 04:33:25 - train: epoch 0085, iter [00110, 01251], lr: 0.000136, loss: 2.7083
2022-10-09 04:33:46 - train: epoch 0085, iter [00120, 01251], lr: 0.000136, loss: 2.8922
2022-10-09 04:34:08 - train: epoch 0085, iter [00130, 01251], lr: 0.000136, loss: 2.6063
2022-10-09 04:34:29 - train: epoch 0085, iter [00140, 01251], lr: 0.000136, loss: 2.7930
2022-10-09 04:34:50 - train: epoch 0085, iter [00150, 01251], lr: 0.000136, loss: 3.0436
2022-10-09 04:35:12 - train: epoch 0085, iter [00160, 01251], lr: 0.000136, loss: 2.4580
2022-10-09 04:35:33 - train: epoch 0085, iter [00170, 01251], lr: 0.000135, loss: 3.0256
2022-10-09 04:35:54 - train: epoch 0085, iter [00180, 01251], lr: 0.000135, loss: 2.5311
2022-10-09 04:36:16 - train: epoch 0085, iter [00190, 01251], lr: 0.000135, loss: 2.9121
2022-10-09 04:36:37 - train: epoch 0085, iter [00200, 01251], lr: 0.000135, loss: 2.9347
2022-10-09 04:36:58 - train: epoch 0085, iter [00210, 01251], lr: 0.000135, loss: 2.6794
2022-10-09 04:37:19 - train: epoch 0085, iter [00220, 01251], lr: 0.000135, loss: 2.8639
2022-10-09 04:37:41 - train: epoch 0085, iter [00230, 01251], lr: 0.000135, loss: 2.9631
2022-10-09 04:38:02 - train: epoch 0085, iter [00240, 01251], lr: 0.000134, loss: 3.0381
2022-10-09 04:38:23 - train: epoch 0085, iter [00250, 01251], lr: 0.000134, loss: 2.7427
2022-10-09 04:38:45 - train: epoch 0085, iter [00260, 01251], lr: 0.000134, loss: 2.8476
2022-10-09 04:39:06 - train: epoch 0085, iter [00270, 01251], lr: 0.000134, loss: 2.8864
2022-10-09 04:39:27 - train: epoch 0085, iter [00280, 01251], lr: 0.000134, loss: 3.0461
2022-10-09 04:39:49 - train: epoch 0085, iter [00290, 01251], lr: 0.000134, loss: 2.4560
2022-10-09 04:40:10 - train: epoch 0085, iter [00300, 01251], lr: 0.000134, loss: 2.9818
2022-10-09 04:40:31 - train: epoch 0085, iter [00310, 01251], lr: 0.000134, loss: 3.1650
2022-10-09 04:40:53 - train: epoch 0085, iter [00320, 01251], lr: 0.000133, loss: 3.0495
2022-10-09 04:41:14 - train: epoch 0085, iter [00330, 01251], lr: 0.000133, loss: 2.4662
2022-10-09 04:41:35 - train: epoch 0085, iter [00340, 01251], lr: 0.000133, loss: 3.0391
2022-10-09 04:41:57 - train: epoch 0085, iter [00350, 01251], lr: 0.000133, loss: 3.1560
2022-10-09 04:42:18 - train: epoch 0085, iter [00360, 01251], lr: 0.000133, loss: 2.4971
2022-10-09 04:42:39 - train: epoch 0085, iter [00370, 01251], lr: 0.000133, loss: 2.8716
2022-10-09 04:43:01 - train: epoch 0085, iter [00380, 01251], lr: 0.000133, loss: 3.0266
2022-10-09 04:43:22 - train: epoch 0085, iter [00390, 01251], lr: 0.000133, loss: 2.6313
2022-10-09 04:43:43 - train: epoch 0085, iter [00400, 01251], lr: 0.000132, loss: 2.4269
2022-10-09 04:44:04 - train: epoch 0085, iter [00410, 01251], lr: 0.000132, loss: 2.8877
2022-10-09 04:44:26 - train: epoch 0085, iter [00420, 01251], lr: 0.000132, loss: 3.3449
2022-10-09 04:44:47 - train: epoch 0085, iter [00430, 01251], lr: 0.000132, loss: 3.0230
2022-10-09 04:45:08 - train: epoch 0085, iter [00440, 01251], lr: 0.000132, loss: 2.9200
2022-10-09 04:45:30 - train: epoch 0085, iter [00450, 01251], lr: 0.000132, loss: 2.3613
2022-10-09 04:45:51 - train: epoch 0085, iter [00460, 01251], lr: 0.000132, loss: 2.6233
2022-10-09 04:46:12 - train: epoch 0085, iter [00470, 01251], lr: 0.000131, loss: 2.9504
2022-10-09 04:46:33 - train: epoch 0085, iter [00480, 01251], lr: 0.000131, loss: 3.1250
2022-10-09 04:46:55 - train: epoch 0085, iter [00490, 01251], lr: 0.000131, loss: 2.6147
2022-10-09 04:47:16 - train: epoch 0085, iter [00500, 01251], lr: 0.000131, loss: 2.9212
2022-10-09 04:47:37 - train: epoch 0085, iter [00510, 01251], lr: 0.000131, loss: 2.6536
2022-10-09 04:47:59 - train: epoch 0085, iter [00520, 01251], lr: 0.000131, loss: 3.1775
2022-10-09 04:48:20 - train: epoch 0085, iter [00530, 01251], lr: 0.000131, loss: 2.3698
2022-10-09 04:48:41 - train: epoch 0085, iter [00540, 01251], lr: 0.000131, loss: 2.6928
2022-10-09 04:49:02 - train: epoch 0085, iter [00550, 01251], lr: 0.000130, loss: 2.5929
2022-10-09 04:49:24 - train: epoch 0085, iter [00560, 01251], lr: 0.000130, loss: 2.8729
2022-10-09 04:49:45 - train: epoch 0085, iter [00570, 01251], lr: 0.000130, loss: 3.2265
2022-10-09 04:50:06 - train: epoch 0085, iter [00580, 01251], lr: 0.000130, loss: 3.1080
2022-10-09 04:50:27 - train: epoch 0085, iter [00590, 01251], lr: 0.000130, loss: 2.3249
2022-10-09 04:50:49 - train: epoch 0085, iter [00600, 01251], lr: 0.000130, loss: 2.5409
2022-10-09 04:51:10 - train: epoch 0085, iter [00610, 01251], lr: 0.000130, loss: 2.9053
2022-10-09 04:51:31 - train: epoch 0085, iter [00620, 01251], lr: 0.000130, loss: 2.8727
2022-10-09 04:51:53 - train: epoch 0085, iter [00630, 01251], lr: 0.000129, loss: 2.8258
2022-10-09 04:52:14 - train: epoch 0085, iter [00640, 01251], lr: 0.000129, loss: 2.9968
2022-10-09 04:52:35 - train: epoch 0085, iter [00650, 01251], lr: 0.000129, loss: 2.9737
2022-10-09 04:52:57 - train: epoch 0085, iter [00660, 01251], lr: 0.000129, loss: 2.8432
2022-10-09 04:53:18 - train: epoch 0085, iter [00670, 01251], lr: 0.000129, loss: 2.8414
2022-10-09 04:53:39 - train: epoch 0085, iter [00680, 01251], lr: 0.000129, loss: 2.9613
2022-10-09 04:54:00 - train: epoch 0085, iter [00690, 01251], lr: 0.000129, loss: 2.5741
2022-10-09 04:54:22 - train: epoch 0085, iter [00700, 01251], lr: 0.000128, loss: 3.1076
2022-10-09 04:54:43 - train: epoch 0085, iter [00710, 01251], lr: 0.000128, loss: 3.0042
2022-10-09 04:55:04 - train: epoch 0085, iter [00720, 01251], lr: 0.000128, loss: 2.4581
2022-10-09 04:55:25 - train: epoch 0085, iter [00730, 01251], lr: 0.000128, loss: 2.4320
2022-10-09 04:55:46 - train: epoch 0085, iter [00740, 01251], lr: 0.000128, loss: 3.0352
2022-10-09 04:56:08 - train: epoch 0085, iter [00750, 01251], lr: 0.000128, loss: 3.2905
2022-10-09 04:56:29 - train: epoch 0085, iter [00760, 01251], lr: 0.000128, loss: 2.9647
2022-10-09 04:56:50 - train: epoch 0085, iter [00770, 01251], lr: 0.000128, loss: 2.6063
2022-10-09 04:57:12 - train: epoch 0085, iter [00780, 01251], lr: 0.000127, loss: 2.7186
2022-10-09 04:57:33 - train: epoch 0085, iter [00790, 01251], lr: 0.000127, loss: 2.9920
2022-10-09 04:57:54 - train: epoch 0085, iter [00800, 01251], lr: 0.000127, loss: 3.1821
2022-10-09 04:58:16 - train: epoch 0085, iter [00810, 01251], lr: 0.000127, loss: 1.8934
2022-10-09 04:58:37 - train: epoch 0085, iter [00820, 01251], lr: 0.000127, loss: 2.2523
2022-10-09 04:58:58 - train: epoch 0085, iter [00830, 01251], lr: 0.000127, loss: 3.2975
2022-10-09 04:59:20 - train: epoch 0085, iter [00840, 01251], lr: 0.000127, loss: 2.3710
2022-10-09 04:59:41 - train: epoch 0085, iter [00850, 01251], lr: 0.000127, loss: 2.8771
2022-10-09 05:00:02 - train: epoch 0085, iter [00860, 01251], lr: 0.000126, loss: 2.9514
2022-10-09 05:00:23 - train: epoch 0085, iter [00870, 01251], lr: 0.000126, loss: 2.4981
2022-10-09 05:00:45 - train: epoch 0085, iter [00880, 01251], lr: 0.000126, loss: 2.2232
2022-10-09 05:01:06 - train: epoch 0085, iter [00890, 01251], lr: 0.000126, loss: 3.0706
2022-10-09 05:01:27 - train: epoch 0085, iter [00900, 01251], lr: 0.000126, loss: 2.8905
2022-10-09 05:01:49 - train: epoch 0085, iter [00910, 01251], lr: 0.000126, loss: 1.9563
2022-10-09 05:02:10 - train: epoch 0085, iter [00920, 01251], lr: 0.000126, loss: 3.0948
2022-10-09 05:02:31 - train: epoch 0085, iter [00930, 01251], lr: 0.000126, loss: 2.8916
2022-10-09 05:02:52 - train: epoch 0085, iter [00940, 01251], lr: 0.000125, loss: 2.6922
2022-10-09 05:03:14 - train: epoch 0085, iter [00950, 01251], lr: 0.000125, loss: 2.4269
2022-10-09 05:03:35 - train: epoch 0085, iter [00960, 01251], lr: 0.000125, loss: 2.6665
2022-10-09 05:03:56 - train: epoch 0085, iter [00970, 01251], lr: 0.000125, loss: 2.7185
2022-10-09 05:04:18 - train: epoch 0085, iter [00980, 01251], lr: 0.000125, loss: 2.7667
2022-10-09 05:04:39 - train: epoch 0085, iter [00990, 01251], lr: 0.000125, loss: 3.0819
2022-10-09 05:05:00 - train: epoch 0085, iter [01000, 01251], lr: 0.000125, loss: 3.0596
2022-10-09 05:05:21 - train: epoch 0085, iter [01010, 01251], lr: 0.000125, loss: 3.2644
2022-10-09 05:05:43 - train: epoch 0085, iter [01020, 01251], lr: 0.000124, loss: 2.4767
2022-10-09 05:06:04 - train: epoch 0085, iter [01030, 01251], lr: 0.000124, loss: 2.7056
2022-10-09 05:06:26 - train: epoch 0085, iter [01040, 01251], lr: 0.000124, loss: 2.7348
2022-10-09 05:06:47 - train: epoch 0085, iter [01050, 01251], lr: 0.000124, loss: 2.9512
2022-10-09 05:07:08 - train: epoch 0085, iter [01060, 01251], lr: 0.000124, loss: 2.5272
2022-10-09 05:07:29 - train: epoch 0085, iter [01070, 01251], lr: 0.000124, loss: 3.0161
2022-10-09 05:07:51 - train: epoch 0085, iter [01080, 01251], lr: 0.000124, loss: 2.8365
2022-10-09 05:08:12 - train: epoch 0085, iter [01090, 01251], lr: 0.000123, loss: 2.5254
2022-10-09 05:08:33 - train: epoch 0085, iter [01100, 01251], lr: 0.000123, loss: 2.8672
2022-10-09 05:08:54 - train: epoch 0085, iter [01110, 01251], lr: 0.000123, loss: 2.9877
2022-10-09 05:09:16 - train: epoch 0085, iter [01120, 01251], lr: 0.000123, loss: 3.1438
2022-10-09 05:09:37 - train: epoch 0085, iter [01130, 01251], lr: 0.000123, loss: 2.7811
2022-10-09 05:09:58 - train: epoch 0085, iter [01140, 01251], lr: 0.000123, loss: 3.2012
2022-10-09 05:10:20 - train: epoch 0085, iter [01150, 01251], lr: 0.000123, loss: 3.2714
2022-10-09 05:10:41 - train: epoch 0085, iter [01160, 01251], lr: 0.000123, loss: 3.0363
2022-10-09 05:11:02 - train: epoch 0085, iter [01170, 01251], lr: 0.000122, loss: 3.0164
2022-10-09 05:11:23 - train: epoch 0085, iter [01180, 01251], lr: 0.000122, loss: 2.2250
2022-10-09 05:11:45 - train: epoch 0085, iter [01190, 01251], lr: 0.000122, loss: 2.2252
2022-10-09 05:12:06 - train: epoch 0085, iter [01200, 01251], lr: 0.000122, loss: 2.5076
2022-10-09 05:12:27 - train: epoch 0085, iter [01210, 01251], lr: 0.000122, loss: 2.6720
2022-10-09 05:12:49 - train: epoch 0085, iter [01220, 01251], lr: 0.000122, loss: 3.0283
2022-10-09 05:13:10 - train: epoch 0085, iter [01230, 01251], lr: 0.000122, loss: 2.8546
2022-10-09 05:13:31 - train: epoch 0085, iter [01240, 01251], lr: 0.000122, loss: 2.9385
2022-10-09 05:13:52 - train: epoch 0085, iter [01250, 01251], lr: 0.000121, loss: 2.1655
2022-10-09 05:13:55 - train: epoch 085, train_loss: 2.7907
2022-10-09 05:15:11 - eval: epoch: 085, acc1: 82.882%, acc5: 96.484%, test_loss: 0.7495, per_image_load_time: 0.194ms, per_image_inference_time: 1.447ms
2022-10-09 05:15:12 - until epoch: 085, best_acc1: 82.890%
2022-10-09 05:15:12 - epoch 086 lr: 0.000121
2022-10-09 05:15:40 - train: epoch 0086, iter [00010, 01251], lr: 0.000121, loss: 3.1570
2022-10-09 05:16:01 - train: epoch 0086, iter [00020, 01251], lr: 0.000121, loss: 2.9329
2022-10-09 05:16:22 - train: epoch 0086, iter [00030, 01251], lr: 0.000121, loss: 2.9101
2022-10-09 05:16:43 - train: epoch 0086, iter [00040, 01251], lr: 0.000121, loss: 2.2533
2022-10-09 05:17:05 - train: epoch 0086, iter [00050, 01251], lr: 0.000121, loss: 2.8916
2022-10-09 05:17:26 - train: epoch 0086, iter [00060, 01251], lr: 0.000121, loss: 3.3410
2022-10-09 05:17:47 - train: epoch 0086, iter [00070, 01251], lr: 0.000121, loss: 2.7472
2022-10-09 05:18:08 - train: epoch 0086, iter [00080, 01251], lr: 0.000120, loss: 2.5676
2022-10-09 05:18:29 - train: epoch 0086, iter [00090, 01251], lr: 0.000120, loss: 2.6500
2022-10-09 05:18:50 - train: epoch 0086, iter [00100, 01251], lr: 0.000120, loss: 3.2079
2022-10-09 05:19:12 - train: epoch 0086, iter [00110, 01251], lr: 0.000120, loss: 2.8847
2022-10-09 05:19:33 - train: epoch 0086, iter [00120, 01251], lr: 0.000120, loss: 2.9429
2022-10-09 05:19:54 - train: epoch 0086, iter [00130, 01251], lr: 0.000120, loss: 2.9277
2022-10-09 05:20:15 - train: epoch 0086, iter [00140, 01251], lr: 0.000120, loss: 2.7639
2022-10-09 05:20:37 - train: epoch 0086, iter [00150, 01251], lr: 0.000120, loss: 3.0491
2022-10-09 05:20:58 - train: epoch 0086, iter [00160, 01251], lr: 0.000119, loss: 2.5289
2022-10-09 05:21:19 - train: epoch 0086, iter [00170, 01251], lr: 0.000119, loss: 3.0849
2022-10-09 05:21:40 - train: epoch 0086, iter [00180, 01251], lr: 0.000119, loss: 3.0472
2022-10-09 05:22:02 - train: epoch 0086, iter [00190, 01251], lr: 0.000119, loss: 3.1265
2022-10-09 05:22:23 - train: epoch 0086, iter [00200, 01251], lr: 0.000119, loss: 2.3847
2022-10-09 05:22:44 - train: epoch 0086, iter [00210, 01251], lr: 0.000119, loss: 2.5894
2022-10-09 05:23:06 - train: epoch 0086, iter [00220, 01251], lr: 0.000119, loss: 3.0271
2022-10-09 05:23:27 - train: epoch 0086, iter [00230, 01251], lr: 0.000119, loss: 2.6424
2022-10-09 05:23:48 - train: epoch 0086, iter [00240, 01251], lr: 0.000118, loss: 3.0356
2022-10-09 05:24:10 - train: epoch 0086, iter [00250, 01251], lr: 0.000118, loss: 2.9787
2022-10-09 05:24:31 - train: epoch 0086, iter [00260, 01251], lr: 0.000118, loss: 2.8989
2022-10-09 05:24:52 - train: epoch 0086, iter [00270, 01251], lr: 0.000118, loss: 2.3484
2022-10-09 05:25:13 - train: epoch 0086, iter [00280, 01251], lr: 0.000118, loss: 2.8100
2022-10-09 05:25:35 - train: epoch 0086, iter [00290, 01251], lr: 0.000118, loss: 3.1331
2022-10-09 05:25:56 - train: epoch 0086, iter [00300, 01251], lr: 0.000118, loss: 2.7484
2022-10-09 05:26:17 - train: epoch 0086, iter [00310, 01251], lr: 0.000118, loss: 2.7405
2022-10-09 05:26:38 - train: epoch 0086, iter [00320, 01251], lr: 0.000117, loss: 2.7097
2022-10-09 05:27:00 - train: epoch 0086, iter [00330, 01251], lr: 0.000117, loss: 2.3963
2022-10-09 05:27:21 - train: epoch 0086, iter [00340, 01251], lr: 0.000117, loss: 2.6072
2022-10-09 05:27:42 - train: epoch 0086, iter [00350, 01251], lr: 0.000117, loss: 2.5221
2022-10-09 05:28:03 - train: epoch 0086, iter [00360, 01251], lr: 0.000117, loss: 2.7872
2022-10-09 05:28:25 - train: epoch 0086, iter [00370, 01251], lr: 0.000117, loss: 2.8871
2022-10-09 05:28:46 - train: epoch 0086, iter [00380, 01251], lr: 0.000117, loss: 2.6966
2022-10-09 05:29:07 - train: epoch 0086, iter [00390, 01251], lr: 0.000117, loss: 3.1444
2022-10-09 05:29:28 - train: epoch 0086, iter [00400, 01251], lr: 0.000116, loss: 2.7119
2022-10-09 05:29:49 - train: epoch 0086, iter [00410, 01251], lr: 0.000116, loss: 2.9468
2022-10-09 05:30:11 - train: epoch 0086, iter [00420, 01251], lr: 0.000116, loss: 2.1424
2022-10-09 05:30:32 - train: epoch 0086, iter [00430, 01251], lr: 0.000116, loss: 2.3881
2022-10-09 05:30:53 - train: epoch 0086, iter [00440, 01251], lr: 0.000116, loss: 2.5534
2022-10-09 05:31:14 - train: epoch 0086, iter [00450, 01251], lr: 0.000116, loss: 2.8425
2022-10-09 05:31:35 - train: epoch 0086, iter [00460, 01251], lr: 0.000116, loss: 2.8301
2022-10-09 05:31:57 - train: epoch 0086, iter [00470, 01251], lr: 0.000116, loss: 2.2539
2022-10-09 05:32:18 - train: epoch 0086, iter [00480, 01251], lr: 0.000116, loss: 2.7828
2022-10-09 05:32:39 - train: epoch 0086, iter [00490, 01251], lr: 0.000115, loss: 3.0476
2022-10-09 05:33:01 - train: epoch 0086, iter [00500, 01251], lr: 0.000115, loss: 2.4626
2022-10-09 05:33:22 - train: epoch 0086, iter [00510, 01251], lr: 0.000115, loss: 3.1092
2022-10-09 05:33:43 - train: epoch 0086, iter [00520, 01251], lr: 0.000115, loss: 3.1832
2022-10-09 05:34:04 - train: epoch 0086, iter [00530, 01251], lr: 0.000115, loss: 1.9787
2022-10-09 05:34:26 - train: epoch 0086, iter [00540, 01251], lr: 0.000115, loss: 2.6446
2022-10-09 05:34:47 - train: epoch 0086, iter [00550, 01251], lr: 0.000115, loss: 2.7266
2022-10-09 05:35:08 - train: epoch 0086, iter [00560, 01251], lr: 0.000115, loss: 2.8114
2022-10-09 05:35:29 - train: epoch 0086, iter [00570, 01251], lr: 0.000114, loss: 2.9508
2022-10-09 05:35:51 - train: epoch 0086, iter [00580, 01251], lr: 0.000114, loss: 2.3637
2022-10-09 05:36:12 - train: epoch 0086, iter [00590, 01251], lr: 0.000114, loss: 3.2301
2022-10-09 05:36:33 - train: epoch 0086, iter [00600, 01251], lr: 0.000114, loss: 2.4567
2022-10-09 05:36:54 - train: epoch 0086, iter [00610, 01251], lr: 0.000114, loss: 3.1911
2022-10-09 05:37:16 - train: epoch 0086, iter [00620, 01251], lr: 0.000114, loss: 3.3514
2022-10-09 05:37:37 - train: epoch 0086, iter [00630, 01251], lr: 0.000114, loss: 2.9900
2022-10-09 05:37:58 - train: epoch 0086, iter [00640, 01251], lr: 0.000114, loss: 2.4571
2022-10-09 05:38:20 - train: epoch 0086, iter [00650, 01251], lr: 0.000113, loss: 2.7943
2022-10-09 05:38:41 - train: epoch 0086, iter [00660, 01251], lr: 0.000113, loss: 3.0237
2022-10-09 05:39:02 - train: epoch 0086, iter [00670, 01251], lr: 0.000113, loss: 2.9134
2022-10-09 05:39:23 - train: epoch 0086, iter [00680, 01251], lr: 0.000113, loss: 2.7723
2022-10-09 05:39:45 - train: epoch 0086, iter [00690, 01251], lr: 0.000113, loss: 2.6395
2022-10-09 05:40:06 - train: epoch 0086, iter [00700, 01251], lr: 0.000113, loss: 2.8044
2022-10-09 05:40:27 - train: epoch 0086, iter [00710, 01251], lr: 0.000113, loss: 2.8057
2022-10-09 05:40:49 - train: epoch 0086, iter [00720, 01251], lr: 0.000113, loss: 2.4462
2022-10-09 05:41:10 - train: epoch 0086, iter [00730, 01251], lr: 0.000112, loss: 2.6397
2022-10-09 05:41:31 - train: epoch 0086, iter [00740, 01251], lr: 0.000112, loss: 2.2344
2022-10-09 05:41:52 - train: epoch 0086, iter [00750, 01251], lr: 0.000112, loss: 2.4604
2022-10-09 05:42:14 - train: epoch 0086, iter [00760, 01251], lr: 0.000112, loss: 3.1080
2022-10-09 05:42:35 - train: epoch 0086, iter [00770, 01251], lr: 0.000112, loss: 2.7398
2022-10-09 05:42:56 - train: epoch 0086, iter [00780, 01251], lr: 0.000112, loss: 3.1765
2022-10-09 05:43:17 - train: epoch 0086, iter [00790, 01251], lr: 0.000112, loss: 2.0902
2022-10-09 05:43:38 - train: epoch 0086, iter [00800, 01251], lr: 0.000112, loss: 3.0485
2022-10-09 05:44:00 - train: epoch 0086, iter [00810, 01251], lr: 0.000111, loss: 2.0812
2022-10-09 05:44:21 - train: epoch 0086, iter [00820, 01251], lr: 0.000111, loss: 2.7958
2022-10-09 05:44:42 - train: epoch 0086, iter [00830, 01251], lr: 0.000111, loss: 2.8372
2022-10-09 05:45:04 - train: epoch 0086, iter [00840, 01251], lr: 0.000111, loss: 2.9643
2022-10-09 05:45:25 - train: epoch 0086, iter [00850, 01251], lr: 0.000111, loss: 3.1471
2022-10-09 05:45:46 - train: epoch 0086, iter [00860, 01251], lr: 0.000111, loss: 2.8159
2022-10-09 05:46:07 - train: epoch 0086, iter [00870, 01251], lr: 0.000111, loss: 2.4560
2022-10-09 05:46:29 - train: epoch 0086, iter [00880, 01251], lr: 0.000111, loss: 2.8902
2022-10-09 05:46:50 - train: epoch 0086, iter [00890, 01251], lr: 0.000111, loss: 3.0479
2022-10-09 05:47:11 - train: epoch 0086, iter [00900, 01251], lr: 0.000110, loss: 2.6934
2022-10-09 05:47:32 - train: epoch 0086, iter [00910, 01251], lr: 0.000110, loss: 2.9252
2022-10-09 05:47:54 - train: epoch 0086, iter [00920, 01251], lr: 0.000110, loss: 2.5936
2022-10-09 05:48:15 - train: epoch 0086, iter [00930, 01251], lr: 0.000110, loss: 2.8862
2022-10-09 05:48:36 - train: epoch 0086, iter [00940, 01251], lr: 0.000110, loss: 2.7882
2022-10-09 05:48:57 - train: epoch 0086, iter [00950, 01251], lr: 0.000110, loss: 2.7370
2022-10-09 05:49:19 - train: epoch 0086, iter [00960, 01251], lr: 0.000110, loss: 2.7057
2022-10-09 05:49:40 - train: epoch 0086, iter [00970, 01251], lr: 0.000110, loss: 2.7738
2022-10-09 05:50:01 - train: epoch 0086, iter [00980, 01251], lr: 0.000109, loss: 3.0583
2022-10-09 05:50:22 - train: epoch 0086, iter [00990, 01251], lr: 0.000109, loss: 3.0992
2022-10-09 05:50:43 - train: epoch 0086, iter [01000, 01251], lr: 0.000109, loss: 2.4282
2022-10-09 05:51:05 - train: epoch 0086, iter [01010, 01251], lr: 0.000109, loss: 2.8775
2022-10-09 05:51:26 - train: epoch 0086, iter [01020, 01251], lr: 0.000109, loss: 2.4769
2022-10-09 05:51:47 - train: epoch 0086, iter [01030, 01251], lr: 0.000109, loss: 2.6531
2022-10-09 05:52:08 - train: epoch 0086, iter [01040, 01251], lr: 0.000109, loss: 2.8905
2022-10-09 05:52:30 - train: epoch 0086, iter [01050, 01251], lr: 0.000109, loss: 2.9798
2022-10-09 05:52:51 - train: epoch 0086, iter [01060, 01251], lr: 0.000108, loss: 2.6109
2022-10-09 05:53:12 - train: epoch 0086, iter [01070, 01251], lr: 0.000108, loss: 3.0031
2022-10-09 05:53:33 - train: epoch 0086, iter [01080, 01251], lr: 0.000108, loss: 2.5108
2022-10-09 05:53:55 - train: epoch 0086, iter [01090, 01251], lr: 0.000108, loss: 2.5735
2022-10-09 05:54:16 - train: epoch 0086, iter [01100, 01251], lr: 0.000108, loss: 2.8060
2022-10-09 05:54:37 - train: epoch 0086, iter [01110, 01251], lr: 0.000108, loss: 2.9203
2022-10-09 05:54:58 - train: epoch 0086, iter [01120, 01251], lr: 0.000108, loss: 3.1509
2022-10-09 05:55:19 - train: epoch 0086, iter [01130, 01251], lr: 0.000108, loss: 2.6100
2022-10-09 05:55:40 - train: epoch 0086, iter [01140, 01251], lr: 0.000108, loss: 2.5978
2022-10-09 05:56:02 - train: epoch 0086, iter [01150, 01251], lr: 0.000107, loss: 3.0943
2022-10-09 05:56:23 - train: epoch 0086, iter [01160, 01251], lr: 0.000107, loss: 3.1332
2022-10-09 05:56:44 - train: epoch 0086, iter [01170, 01251], lr: 0.000107, loss: 2.6271
2022-10-09 05:57:05 - train: epoch 0086, iter [01180, 01251], lr: 0.000107, loss: 2.7087
2022-10-09 05:57:26 - train: epoch 0086, iter [01190, 01251], lr: 0.000107, loss: 3.0061
2022-10-09 05:57:47 - train: epoch 0086, iter [01200, 01251], lr: 0.000107, loss: 2.5252
2022-10-09 05:58:08 - train: epoch 0086, iter [01210, 01251], lr: 0.000107, loss: 3.0486
2022-10-09 05:58:29 - train: epoch 0086, iter [01220, 01251], lr: 0.000107, loss: 3.0581
2022-10-09 05:58:51 - train: epoch 0086, iter [01230, 01251], lr: 0.000106, loss: 2.8674
2022-10-09 05:59:12 - train: epoch 0086, iter [01240, 01251], lr: 0.000106, loss: 2.2061
2022-10-09 05:59:33 - train: epoch 0086, iter [01250, 01251], lr: 0.000106, loss: 2.9235
2022-10-09 05:59:36 - train: epoch 086, train_loss: 2.7813
2022-10-09 06:00:54 - eval: epoch: 086, acc1: 82.912%, acc5: 96.448%, test_loss: 0.7597, per_image_load_time: 0.732ms, per_image_inference_time: 1.442ms
2022-10-09 06:00:56 - until epoch: 086, best_acc1: 82.912%
2022-10-09 06:00:56 - epoch 087 lr: 0.000106
2022-10-09 06:01:24 - train: epoch 0087, iter [00010, 01251], lr: 0.000106, loss: 2.8922
2022-10-09 06:01:45 - train: epoch 0087, iter [00020, 01251], lr: 0.000106, loss: 3.1232
2022-10-09 06:02:06 - train: epoch 0087, iter [00030, 01251], lr: 0.000106, loss: 2.6780
2022-10-09 06:02:27 - train: epoch 0087, iter [00040, 01251], lr: 0.000106, loss: 2.9527
2022-10-09 06:02:49 - train: epoch 0087, iter [00050, 01251], lr: 0.000106, loss: 3.1332
2022-10-09 06:03:11 - train: epoch 0087, iter [00060, 01251], lr: 0.000106, loss: 3.1173
2022-10-09 06:03:32 - train: epoch 0087, iter [00070, 01251], lr: 0.000105, loss: 2.9466
2022-10-09 06:03:54 - train: epoch 0087, iter [00080, 01251], lr: 0.000105, loss: 2.0809
2022-10-09 06:04:15 - train: epoch 0087, iter [00090, 01251], lr: 0.000105, loss: 3.1540
2022-10-09 06:04:36 - train: epoch 0087, iter [00100, 01251], lr: 0.000105, loss: 3.0472
2022-10-09 06:04:57 - train: epoch 0087, iter [00110, 01251], lr: 0.000105, loss: 2.9024
2022-10-09 06:05:18 - train: epoch 0087, iter [00120, 01251], lr: 0.000105, loss: 2.5541
2022-10-09 06:05:39 - train: epoch 0087, iter [00130, 01251], lr: 0.000105, loss: 3.1417
2022-10-09 06:06:00 - train: epoch 0087, iter [00140, 01251], lr: 0.000105, loss: 2.7243
2022-10-09 06:06:22 - train: epoch 0087, iter [00150, 01251], lr: 0.000104, loss: 3.2021
2022-10-09 06:06:43 - train: epoch 0087, iter [00160, 01251], lr: 0.000104, loss: 2.9240
2022-10-09 06:07:04 - train: epoch 0087, iter [00170, 01251], lr: 0.000104, loss: 2.7768
2022-10-09 06:07:25 - train: epoch 0087, iter [00180, 01251], lr: 0.000104, loss: 2.8850
2022-10-09 06:07:46 - train: epoch 0087, iter [00190, 01251], lr: 0.000104, loss: 2.6967
2022-10-09 06:08:08 - train: epoch 0087, iter [00200, 01251], lr: 0.000104, loss: 2.8487
2022-10-09 06:08:29 - train: epoch 0087, iter [00210, 01251], lr: 0.000104, loss: 3.2671
2022-10-09 06:08:50 - train: epoch 0087, iter [00220, 01251], lr: 0.000104, loss: 2.8354
2022-10-09 06:09:11 - train: epoch 0087, iter [00230, 01251], lr: 0.000104, loss: 2.9833
2022-10-09 06:09:33 - train: epoch 0087, iter [00240, 01251], lr: 0.000103, loss: 2.9572
2022-10-09 06:09:54 - train: epoch 0087, iter [00250, 01251], lr: 0.000103, loss: 2.7092
2022-10-09 06:10:15 - train: epoch 0087, iter [00260, 01251], lr: 0.000103, loss: 2.8019
2022-10-09 06:10:37 - train: epoch 0087, iter [00270, 01251], lr: 0.000103, loss: 3.1636
2022-10-09 06:10:58 - train: epoch 0087, iter [00280, 01251], lr: 0.000103, loss: 2.9548
2022-10-09 06:11:19 - train: epoch 0087, iter [00290, 01251], lr: 0.000103, loss: 2.8180
2022-10-09 06:11:40 - train: epoch 0087, iter [00300, 01251], lr: 0.000103, loss: 3.0080
2022-10-09 06:12:01 - train: epoch 0087, iter [00310, 01251], lr: 0.000103, loss: 2.4531
2022-10-09 06:12:23 - train: epoch 0087, iter [00320, 01251], lr: 0.000102, loss: 2.3536
2022-10-09 06:12:44 - train: epoch 0087, iter [00330, 01251], lr: 0.000102, loss: 2.2336
2022-10-09 06:13:06 - train: epoch 0087, iter [00340, 01251], lr: 0.000102, loss: 2.1039
2022-10-09 06:13:27 - train: epoch 0087, iter [00350, 01251], lr: 0.000102, loss: 2.1930
2022-10-09 06:13:48 - train: epoch 0087, iter [00360, 01251], lr: 0.000102, loss: 2.8849
2022-10-09 06:14:10 - train: epoch 0087, iter [00370, 01251], lr: 0.000102, loss: 2.7503
2022-10-09 06:14:31 - train: epoch 0087, iter [00380, 01251], lr: 0.000102, loss: 2.6413
2022-10-09 06:14:52 - train: epoch 0087, iter [00390, 01251], lr: 0.000102, loss: 3.1072
2022-10-09 06:15:13 - train: epoch 0087, iter [00400, 01251], lr: 0.000102, loss: 3.0223
2022-10-09 06:15:35 - train: epoch 0087, iter [00410, 01251], lr: 0.000101, loss: 2.1205
2022-10-09 06:15:56 - train: epoch 0087, iter [00420, 01251], lr: 0.000101, loss: 2.9980
2022-10-09 06:16:17 - train: epoch 0087, iter [00430, 01251], lr: 0.000101, loss: 2.8937
2022-10-09 06:16:39 - train: epoch 0087, iter [00440, 01251], lr: 0.000101, loss: 2.9968
2022-10-09 06:17:00 - train: epoch 0087, iter [00450, 01251], lr: 0.000101, loss: 2.2845
2022-10-09 06:17:21 - train: epoch 0087, iter [00460, 01251], lr: 0.000101, loss: 3.2023
2022-10-09 06:17:42 - train: epoch 0087, iter [00470, 01251], lr: 0.000101, loss: 3.2214
2022-10-09 06:18:04 - train: epoch 0087, iter [00480, 01251], lr: 0.000101, loss: 2.6619
2022-10-09 06:18:25 - train: epoch 0087, iter [00490, 01251], lr: 0.000101, loss: 2.5007
2022-10-09 06:18:47 - train: epoch 0087, iter [00500, 01251], lr: 0.000100, loss: 2.6393
2022-10-09 06:19:08 - train: epoch 0087, iter [00510, 01251], lr: 0.000100, loss: 2.8697
2022-10-09 06:19:29 - train: epoch 0087, iter [00520, 01251], lr: 0.000100, loss: 3.1543
2022-10-09 06:19:50 - train: epoch 0087, iter [00530, 01251], lr: 0.000100, loss: 2.8984
2022-10-09 06:20:12 - train: epoch 0087, iter [00540, 01251], lr: 0.000100, loss: 3.1003
2022-10-09 06:20:33 - train: epoch 0087, iter [00550, 01251], lr: 0.000100, loss: 3.1583
2022-10-09 06:20:54 - train: epoch 0087, iter [00560, 01251], lr: 0.000100, loss: 2.7703
2022-10-09 06:21:15 - train: epoch 0087, iter [00570, 01251], lr: 0.000100, loss: 3.0739
2022-10-09 06:21:37 - train: epoch 0087, iter [00580, 01251], lr: 0.000099, loss: 2.2602
2022-10-09 06:21:58 - train: epoch 0087, iter [00590, 01251], lr: 0.000099, loss: 3.3366
2022-10-09 06:22:20 - train: epoch 0087, iter [00600, 01251], lr: 0.000099, loss: 2.8726
2022-10-09 06:22:41 - train: epoch 0087, iter [00610, 01251], lr: 0.000099, loss: 3.0402
2022-10-09 06:23:02 - train: epoch 0087, iter [00620, 01251], lr: 0.000099, loss: 3.2052
2022-10-09 06:23:24 - train: epoch 0087, iter [00630, 01251], lr: 0.000099, loss: 3.0549
2022-10-09 06:23:45 - train: epoch 0087, iter [00640, 01251], lr: 0.000099, loss: 2.7315
2022-10-09 06:24:06 - train: epoch 0087, iter [00650, 01251], lr: 0.000099, loss: 3.0039
2022-10-09 06:24:27 - train: epoch 0087, iter [00660, 01251], lr: 0.000099, loss: 2.9711
2022-10-09 06:24:49 - train: epoch 0087, iter [00670, 01251], lr: 0.000098, loss: 2.2903
2022-10-09 06:25:10 - train: epoch 0087, iter [00680, 01251], lr: 0.000098, loss: 2.9578
2022-10-09 06:25:31 - train: epoch 0087, iter [00690, 01251], lr: 0.000098, loss: 3.1249
2022-10-09 06:25:53 - train: epoch 0087, iter [00700, 01251], lr: 0.000098, loss: 2.1658
2022-10-09 06:26:14 - train: epoch 0087, iter [00710, 01251], lr: 0.000098, loss: 2.5276
2022-10-09 06:26:35 - train: epoch 0087, iter [00720, 01251], lr: 0.000098, loss: 2.7186
2022-10-09 06:26:57 - train: epoch 0087, iter [00730, 01251], lr: 0.000098, loss: 2.6232
2022-10-09 06:27:18 - train: epoch 0087, iter [00740, 01251], lr: 0.000098, loss: 2.7466
2022-10-09 06:27:39 - train: epoch 0087, iter [00750, 01251], lr: 0.000098, loss: 3.0500
2022-10-09 06:28:00 - train: epoch 0087, iter [00760, 01251], lr: 0.000097, loss: 2.4158
2022-10-09 06:28:22 - train: epoch 0087, iter [00770, 01251], lr: 0.000097, loss: 2.8507
2022-10-09 06:28:43 - train: epoch 0087, iter [00780, 01251], lr: 0.000097, loss: 2.6201
2022-10-09 06:29:04 - train: epoch 0087, iter [00790, 01251], lr: 0.000097, loss: 2.7069
2022-10-09 06:29:26 - train: epoch 0087, iter [00800, 01251], lr: 0.000097, loss: 2.8059
2022-10-09 06:29:47 - train: epoch 0087, iter [00810, 01251], lr: 0.000097, loss: 2.6538
2022-10-09 06:30:08 - train: epoch 0087, iter [00820, 01251], lr: 0.000097, loss: 2.8712
2022-10-09 06:30:29 - train: epoch 0087, iter [00830, 01251], lr: 0.000097, loss: 3.2651
2022-10-09 06:30:51 - train: epoch 0087, iter [00840, 01251], lr: 0.000097, loss: 2.9722
2022-10-09 06:31:12 - train: epoch 0087, iter [00850, 01251], lr: 0.000096, loss: 2.4502
2022-10-09 06:31:33 - train: epoch 0087, iter [00860, 01251], lr: 0.000096, loss: 2.8028
2022-10-09 06:31:55 - train: epoch 0087, iter [00870, 01251], lr: 0.000096, loss: 3.1829
2022-10-09 06:32:16 - train: epoch 0087, iter [00880, 01251], lr: 0.000096, loss: 2.6867
2022-10-09 06:32:38 - train: epoch 0087, iter [00890, 01251], lr: 0.000096, loss: 2.5334
2022-10-09 06:32:59 - train: epoch 0087, iter [00900, 01251], lr: 0.000096, loss: 2.1721
2022-10-09 06:33:20 - train: epoch 0087, iter [00910, 01251], lr: 0.000096, loss: 2.8690
2022-10-09 06:33:42 - train: epoch 0087, iter [00920, 01251], lr: 0.000096, loss: 3.1621
2022-10-09 06:34:03 - train: epoch 0087, iter [00930, 01251], lr: 0.000096, loss: 3.1038
2022-10-09 06:34:24 - train: epoch 0087, iter [00940, 01251], lr: 0.000095, loss: 3.2651
2022-10-09 06:34:46 - train: epoch 0087, iter [00950, 01251], lr: 0.000095, loss: 2.8186
2022-10-09 06:35:07 - train: epoch 0087, iter [00960, 01251], lr: 0.000095, loss: 2.3832
2022-10-09 06:35:28 - train: epoch 0087, iter [00970, 01251], lr: 0.000095, loss: 2.5224
2022-10-09 06:35:50 - train: epoch 0087, iter [00980, 01251], lr: 0.000095, loss: 2.8947
2022-10-09 06:36:11 - train: epoch 0087, iter [00990, 01251], lr: 0.000095, loss: 3.2137
2022-10-09 06:36:32 - train: epoch 0087, iter [01000, 01251], lr: 0.000095, loss: 3.0767
2022-10-09 06:36:54 - train: epoch 0087, iter [01010, 01251], lr: 0.000095, loss: 2.8631
2022-10-09 06:37:15 - train: epoch 0087, iter [01020, 01251], lr: 0.000095, loss: 3.2581
2022-10-09 06:37:36 - train: epoch 0087, iter [01030, 01251], lr: 0.000094, loss: 3.2221
2022-10-09 06:37:57 - train: epoch 0087, iter [01040, 01251], lr: 0.000094, loss: 2.8155
2022-10-09 06:38:19 - train: epoch 0087, iter [01050, 01251], lr: 0.000094, loss: 2.8395
2022-10-09 06:38:40 - train: epoch 0087, iter [01060, 01251], lr: 0.000094, loss: 3.0029
2022-10-09 06:39:01 - train: epoch 0087, iter [01070, 01251], lr: 0.000094, loss: 3.1437
2022-10-09 06:39:23 - train: epoch 0087, iter [01080, 01251], lr: 0.000094, loss: 2.7186
2022-10-09 06:39:44 - train: epoch 0087, iter [01090, 01251], lr: 0.000094, loss: 2.9070
2022-10-09 06:40:06 - train: epoch 0087, iter [01100, 01251], lr: 0.000094, loss: 3.2240
2022-10-09 06:40:27 - train: epoch 0087, iter [01110, 01251], lr: 0.000094, loss: 2.8195
2022-10-09 06:40:48 - train: epoch 0087, iter [01120, 01251], lr: 0.000093, loss: 2.9512
2022-10-09 06:41:09 - train: epoch 0087, iter [01130, 01251], lr: 0.000093, loss: 2.8291
2022-10-09 06:41:31 - train: epoch 0087, iter [01140, 01251], lr: 0.000093, loss: 3.0855
2022-10-09 06:41:52 - train: epoch 0087, iter [01150, 01251], lr: 0.000093, loss: 3.2786
2022-10-09 06:42:13 - train: epoch 0087, iter [01160, 01251], lr: 0.000093, loss: 3.0742
2022-10-09 06:42:35 - train: epoch 0087, iter [01170, 01251], lr: 0.000093, loss: 2.4788
2022-10-09 06:42:56 - train: epoch 0087, iter [01180, 01251], lr: 0.000093, loss: 3.0018
2022-10-09 06:43:17 - train: epoch 0087, iter [01190, 01251], lr: 0.000093, loss: 2.4764
2022-10-09 06:43:39 - train: epoch 0087, iter [01200, 01251], lr: 0.000093, loss: 2.5310
2022-10-09 06:44:00 - train: epoch 0087, iter [01210, 01251], lr: 0.000092, loss: 3.0316
2022-10-09 06:44:22 - train: epoch 0087, iter [01220, 01251], lr: 0.000092, loss: 2.9821
2022-10-09 06:44:43 - train: epoch 0087, iter [01230, 01251], lr: 0.000092, loss: 2.6743
2022-10-09 06:45:04 - train: epoch 0087, iter [01240, 01251], lr: 0.000092, loss: 2.8205
2022-10-09 06:45:25 - train: epoch 0087, iter [01250, 01251], lr: 0.000092, loss: 2.9578
2022-10-09 06:45:29 - train: epoch 087, train_loss: 2.7892
2022-10-09 06:46:44 - eval: epoch: 087, acc1: 82.934%, acc5: 96.530%, test_loss: 0.7522, per_image_load_time: 0.224ms, per_image_inference_time: 1.432ms
2022-10-09 06:46:46 - until epoch: 087, best_acc1: 82.934%
2022-10-09 06:46:46 - epoch 088 lr: 0.000092
2022-10-09 06:47:14 - train: epoch 0088, iter [00010, 01251], lr: 0.000092, loss: 3.1916
2022-10-09 06:47:35 - train: epoch 0088, iter [00020, 01251], lr: 0.000092, loss: 2.8310
2022-10-09 06:47:57 - train: epoch 0088, iter [00030, 01251], lr: 0.000092, loss: 2.9094
2022-10-09 06:48:18 - train: epoch 0088, iter [00040, 01251], lr: 0.000092, loss: 2.8591
2022-10-09 06:48:39 - train: epoch 0088, iter [00050, 01251], lr: 0.000091, loss: 2.5101
2022-10-09 06:49:01 - train: epoch 0088, iter [00060, 01251], lr: 0.000091, loss: 2.7197
2022-10-09 06:49:22 - train: epoch 0088, iter [00070, 01251], lr: 0.000091, loss: 2.7231
2022-10-09 06:49:44 - train: epoch 0088, iter [00080, 01251], lr: 0.000091, loss: 2.9486
2022-10-09 06:50:05 - train: epoch 0088, iter [00090, 01251], lr: 0.000091, loss: 2.6248
2022-10-09 06:50:27 - train: epoch 0088, iter [00100, 01251], lr: 0.000091, loss: 2.7891
2022-10-09 06:50:48 - train: epoch 0088, iter [00110, 01251], lr: 0.000091, loss: 2.9185
2022-10-09 06:51:10 - train: epoch 0088, iter [00120, 01251], lr: 0.000091, loss: 3.0381
2022-10-09 06:51:31 - train: epoch 0088, iter [00130, 01251], lr: 0.000091, loss: 2.8865
2022-10-09 06:51:53 - train: epoch 0088, iter [00140, 01251], lr: 0.000090, loss: 2.9376
2022-10-09 06:52:14 - train: epoch 0088, iter [00150, 01251], lr: 0.000090, loss: 2.4984
2022-10-09 06:52:36 - train: epoch 0088, iter [00160, 01251], lr: 0.000090, loss: 2.9165
2022-10-09 06:52:58 - train: epoch 0088, iter [00170, 01251], lr: 0.000090, loss: 2.2845
2022-10-09 06:53:19 - train: epoch 0088, iter [00180, 01251], lr: 0.000090, loss: 2.7560
2022-10-09 06:53:41 - train: epoch 0088, iter [00190, 01251], lr: 0.000090, loss: 2.6127
2022-10-09 06:54:02 - train: epoch 0088, iter [00200, 01251], lr: 0.000090, loss: 2.9270
2022-10-09 06:54:24 - train: epoch 0088, iter [00210, 01251], lr: 0.000090, loss: 2.5792
2022-10-09 06:54:45 - train: epoch 0088, iter [00220, 01251], lr: 0.000090, loss: 2.7943
2022-10-09 06:55:07 - train: epoch 0088, iter [00230, 01251], lr: 0.000089, loss: 2.9296
2022-10-09 06:55:28 - train: epoch 0088, iter [00240, 01251], lr: 0.000089, loss: 2.2826
2022-10-09 06:55:49 - train: epoch 0088, iter [00250, 01251], lr: 0.000089, loss: 3.2993
2022-10-09 06:56:11 - train: epoch 0088, iter [00260, 01251], lr: 0.000089, loss: 3.2078
2022-10-09 06:56:32 - train: epoch 0088, iter [00270, 01251], lr: 0.000089, loss: 2.7923
2022-10-09 06:56:54 - train: epoch 0088, iter [00280, 01251], lr: 0.000089, loss: 2.1990
2022-10-09 06:57:15 - train: epoch 0088, iter [00290, 01251], lr: 0.000089, loss: 3.0684
2022-10-09 06:57:37 - train: epoch 0088, iter [00300, 01251], lr: 0.000089, loss: 3.1256
2022-10-09 06:57:58 - train: epoch 0088, iter [00310, 01251], lr: 0.000089, loss: 3.0645
2022-10-09 06:58:20 - train: epoch 0088, iter [00320, 01251], lr: 0.000088, loss: 2.3690
2022-10-09 06:58:42 - train: epoch 0088, iter [00330, 01251], lr: 0.000088, loss: 2.8997
2022-10-09 06:59:03 - train: epoch 0088, iter [00340, 01251], lr: 0.000088, loss: 2.8851
2022-10-09 06:59:24 - train: epoch 0088, iter [00350, 01251], lr: 0.000088, loss: 2.8682
2022-10-09 06:59:46 - train: epoch 0088, iter [00360, 01251], lr: 0.000088, loss: 3.0601
2022-10-09 07:00:07 - train: epoch 0088, iter [00370, 01251], lr: 0.000088, loss: 2.7068
2022-10-09 07:00:29 - train: epoch 0088, iter [00380, 01251], lr: 0.000088, loss: 3.3232
2022-10-09 07:00:50 - train: epoch 0088, iter [00390, 01251], lr: 0.000088, loss: 3.1287
2022-10-09 07:01:12 - train: epoch 0088, iter [00400, 01251], lr: 0.000088, loss: 2.2369
2022-10-09 07:01:33 - train: epoch 0088, iter [00410, 01251], lr: 0.000087, loss: 2.4958
2022-10-09 07:01:55 - train: epoch 0088, iter [00420, 01251], lr: 0.000087, loss: 3.2408
2022-10-09 07:02:16 - train: epoch 0088, iter [00430, 01251], lr: 0.000087, loss: 2.5573
2022-10-09 07:02:38 - train: epoch 0088, iter [00440, 01251], lr: 0.000087, loss: 3.1874
2022-10-09 07:02:59 - train: epoch 0088, iter [00450, 01251], lr: 0.000087, loss: 2.8888
2022-10-09 07:03:21 - train: epoch 0088, iter [00460, 01251], lr: 0.000087, loss: 2.5842
2022-10-09 07:03:42 - train: epoch 0088, iter [00470, 01251], lr: 0.000087, loss: 2.7772
2022-10-09 07:04:04 - train: epoch 0088, iter [00480, 01251], lr: 0.000087, loss: 3.1383
2022-10-09 07:04:25 - train: epoch 0088, iter [00490, 01251], lr: 0.000087, loss: 2.9611
2022-10-09 07:04:47 - train: epoch 0088, iter [00500, 01251], lr: 0.000087, loss: 2.4356
2022-10-09 07:05:08 - train: epoch 0088, iter [00510, 01251], lr: 0.000086, loss: 2.4923
2022-10-09 07:05:30 - train: epoch 0088, iter [00520, 01251], lr: 0.000086, loss: 2.8843
2022-10-09 07:05:51 - train: epoch 0088, iter [00530, 01251], lr: 0.000086, loss: 2.8717
2022-10-09 07:06:13 - train: epoch 0088, iter [00540, 01251], lr: 0.000086, loss: 2.8771
2022-10-09 07:06:34 - train: epoch 0088, iter [00550, 01251], lr: 0.000086, loss: 3.1528
2022-10-09 07:06:56 - train: epoch 0088, iter [00560, 01251], lr: 0.000086, loss: 2.3566
2022-10-09 07:07:17 - train: epoch 0088, iter [00570, 01251], lr: 0.000086, loss: 2.8945
2022-10-09 07:07:39 - train: epoch 0088, iter [00580, 01251], lr: 0.000086, loss: 2.8661
2022-10-09 07:08:00 - train: epoch 0088, iter [00590, 01251], lr: 0.000086, loss: 3.1229
2022-10-09 07:08:21 - train: epoch 0088, iter [00600, 01251], lr: 0.000085, loss: 2.4740
2022-10-09 07:08:43 - train: epoch 0088, iter [00610, 01251], lr: 0.000085, loss: 2.4391
2022-10-09 07:09:05 - train: epoch 0088, iter [00620, 01251], lr: 0.000085, loss: 2.8674
2022-10-09 07:09:26 - train: epoch 0088, iter [00630, 01251], lr: 0.000085, loss: 2.9600
2022-10-09 07:09:48 - train: epoch 0088, iter [00640, 01251], lr: 0.000085, loss: 3.1026
2022-10-09 07:10:10 - train: epoch 0088, iter [00650, 01251], lr: 0.000085, loss: 2.6275
2022-10-09 07:10:31 - train: epoch 0088, iter [00660, 01251], lr: 0.000085, loss: 3.1405
2022-10-09 07:10:53 - train: epoch 0088, iter [00670, 01251], lr: 0.000085, loss: 3.1141
2022-10-09 07:11:14 - train: epoch 0088, iter [00680, 01251], lr: 0.000085, loss: 2.9386
2022-10-09 07:11:36 - train: epoch 0088, iter [00690, 01251], lr: 0.000085, loss: 3.1912
2022-10-09 07:11:57 - train: epoch 0088, iter [00700, 01251], lr: 0.000084, loss: 2.9887
2022-10-09 07:12:18 - train: epoch 0088, iter [00710, 01251], lr: 0.000084, loss: 2.9151
2022-10-09 07:12:40 - train: epoch 0088, iter [00720, 01251], lr: 0.000084, loss: 2.3909
2022-10-09 07:13:01 - train: epoch 0088, iter [00730, 01251], lr: 0.000084, loss: 2.4644
2022-10-09 07:13:23 - train: epoch 0088, iter [00740, 01251], lr: 0.000084, loss: 2.8996
2022-10-09 07:13:44 - train: epoch 0088, iter [00750, 01251], lr: 0.000084, loss: 2.4737
2022-10-09 07:14:06 - train: epoch 0088, iter [00760, 01251], lr: 0.000084, loss: 2.7941
2022-10-09 07:14:27 - train: epoch 0088, iter [00770, 01251], lr: 0.000084, loss: 3.2358
2022-10-09 07:14:49 - train: epoch 0088, iter [00780, 01251], lr: 0.000084, loss: 2.4852
2022-10-09 07:15:10 - train: epoch 0088, iter [00790, 01251], lr: 0.000083, loss: 2.5696
2022-10-09 07:15:32 - train: epoch 0088, iter [00800, 01251], lr: 0.000083, loss: 2.3919
2022-10-09 07:15:53 - train: epoch 0088, iter [00810, 01251], lr: 0.000083, loss: 2.6263
2022-10-09 07:16:15 - train: epoch 0088, iter [00820, 01251], lr: 0.000083, loss: 2.9630
2022-10-09 07:16:36 - train: epoch 0088, iter [00830, 01251], lr: 0.000083, loss: 2.7629
2022-10-09 07:16:58 - train: epoch 0088, iter [00840, 01251], lr: 0.000083, loss: 2.8730
2022-10-09 07:17:19 - train: epoch 0088, iter [00850, 01251], lr: 0.000083, loss: 1.7421
2022-10-09 07:17:40 - train: epoch 0088, iter [00860, 01251], lr: 0.000083, loss: 3.0768
2022-10-09 07:18:02 - train: epoch 0088, iter [00870, 01251], lr: 0.000083, loss: 3.1502
2022-10-09 07:18:24 - train: epoch 0088, iter [00880, 01251], lr: 0.000083, loss: 3.0972
2022-10-09 07:18:45 - train: epoch 0088, iter [00890, 01251], lr: 0.000082, loss: 2.9292
2022-10-09 07:19:07 - train: epoch 0088, iter [00900, 01251], lr: 0.000082, loss: 3.1512
2022-10-09 07:19:28 - train: epoch 0088, iter [00910, 01251], lr: 0.000082, loss: 3.1507
2022-10-09 07:19:50 - train: epoch 0088, iter [00920, 01251], lr: 0.000082, loss: 2.7976
2022-10-09 07:20:11 - train: epoch 0088, iter [00930, 01251], lr: 0.000082, loss: 2.8798
2022-10-09 07:20:33 - train: epoch 0088, iter [00940, 01251], lr: 0.000082, loss: 2.7583
2022-10-09 07:20:55 - train: epoch 0088, iter [00950, 01251], lr: 0.000082, loss: 2.7310
2022-10-09 07:21:16 - train: epoch 0088, iter [00960, 01251], lr: 0.000082, loss: 2.3818
2022-10-09 07:21:38 - train: epoch 0088, iter [00970, 01251], lr: 0.000082, loss: 2.8369
2022-10-09 07:21:59 - train: epoch 0088, iter [00980, 01251], lr: 0.000081, loss: 2.5543
2022-10-09 07:22:21 - train: epoch 0088, iter [00990, 01251], lr: 0.000081, loss: 2.8737
2022-10-09 07:22:42 - train: epoch 0088, iter [01000, 01251], lr: 0.000081, loss: 2.7925
2022-10-09 07:23:04 - train: epoch 0088, iter [01010, 01251], lr: 0.000081, loss: 2.3456
2022-10-09 07:23:25 - train: epoch 0088, iter [01020, 01251], lr: 0.000081, loss: 2.3566
2022-10-09 07:23:47 - train: epoch 0088, iter [01030, 01251], lr: 0.000081, loss: 3.1064
2022-10-09 07:24:08 - train: epoch 0088, iter [01040, 01251], lr: 0.000081, loss: 2.6262
2022-10-09 07:24:30 - train: epoch 0088, iter [01050, 01251], lr: 0.000081, loss: 2.8728
2022-10-09 07:24:51 - train: epoch 0088, iter [01060, 01251], lr: 0.000081, loss: 2.8455
2022-10-09 07:25:13 - train: epoch 0088, iter [01070, 01251], lr: 0.000081, loss: 2.6767
2022-10-09 07:25:34 - train: epoch 0088, iter [01080, 01251], lr: 0.000080, loss: 3.2236
2022-10-09 07:25:56 - train: epoch 0088, iter [01090, 01251], lr: 0.000080, loss: 3.0691
2022-10-09 07:26:17 - train: epoch 0088, iter [01100, 01251], lr: 0.000080, loss: 2.3205
2022-10-09 07:26:39 - train: epoch 0088, iter [01110, 01251], lr: 0.000080, loss: 2.5638
2022-10-09 07:27:00 - train: epoch 0088, iter [01120, 01251], lr: 0.000080, loss: 2.4804
2022-10-09 07:27:22 - train: epoch 0088, iter [01130, 01251], lr: 0.000080, loss: 2.4172
2022-10-09 07:27:43 - train: epoch 0088, iter [01140, 01251], lr: 0.000080, loss: 3.0827
2022-10-09 07:28:05 - train: epoch 0088, iter [01150, 01251], lr: 0.000080, loss: 2.8639
2022-10-09 07:28:26 - train: epoch 0088, iter [01160, 01251], lr: 0.000080, loss: 2.8491
2022-10-09 07:28:48 - train: epoch 0088, iter [01170, 01251], lr: 0.000080, loss: 2.6141
2022-10-09 07:29:09 - train: epoch 0088, iter [01180, 01251], lr: 0.000079, loss: 3.0712
2022-10-09 07:29:31 - train: epoch 0088, iter [01190, 01251], lr: 0.000079, loss: 3.3119
2022-10-09 07:29:52 - train: epoch 0088, iter [01200, 01251], lr: 0.000079, loss: 3.2434
2022-10-09 07:30:13 - train: epoch 0088, iter [01210, 01251], lr: 0.000079, loss: 2.7768
2022-10-09 07:30:35 - train: epoch 0088, iter [01220, 01251], lr: 0.000079, loss: 3.1624
2022-10-09 07:30:56 - train: epoch 0088, iter [01230, 01251], lr: 0.000079, loss: 2.8363
2022-10-09 07:31:18 - train: epoch 0088, iter [01240, 01251], lr: 0.000079, loss: 2.5200
2022-10-09 07:31:39 - train: epoch 0088, iter [01250, 01251], lr: 0.000079, loss: 3.2223
2022-10-09 07:31:42 - train: epoch 088, train_loss: 2.7809
2022-10-09 07:32:58 - eval: epoch: 088, acc1: 82.984%, acc5: 96.530%, test_loss: 0.7596, per_image_load_time: 0.217ms, per_image_inference_time: 1.438ms
2022-10-09 07:33:00 - until epoch: 088, best_acc1: 82.984%
2022-10-09 07:33:00 - epoch 089 lr: 0.000079
2022-10-09 07:33:28 - train: epoch 0089, iter [00010, 01251], lr: 0.000079, loss: 2.5605
2022-10-09 07:33:49 - train: epoch 0089, iter [00020, 01251], lr: 0.000078, loss: 3.1083
2022-10-09 07:34:10 - train: epoch 0089, iter [00030, 01251], lr: 0.000078, loss: 2.5775
2022-10-09 07:34:32 - train: epoch 0089, iter [00040, 01251], lr: 0.000078, loss: 2.7815
2022-10-09 07:34:53 - train: epoch 0089, iter [00050, 01251], lr: 0.000078, loss: 2.5149
2022-10-09 07:35:14 - train: epoch 0089, iter [00060, 01251], lr: 0.000078, loss: 3.0155
2022-10-09 07:35:36 - train: epoch 0089, iter [00070, 01251], lr: 0.000078, loss: 2.5857
2022-10-09 07:35:57 - train: epoch 0089, iter [00080, 01251], lr: 0.000078, loss: 2.9797
2022-10-09 07:36:19 - train: epoch 0089, iter [00090, 01251], lr: 0.000078, loss: 2.7056
2022-10-09 07:36:40 - train: epoch 0089, iter [00100, 01251], lr: 0.000078, loss: 3.0050
2022-10-09 07:37:02 - train: epoch 0089, iter [00110, 01251], lr: 0.000078, loss: 2.2113
2022-10-09 07:37:23 - train: epoch 0089, iter [00120, 01251], lr: 0.000077, loss: 2.3826
2022-10-09 07:37:45 - train: epoch 0089, iter [00130, 01251], lr: 0.000077, loss: 2.8568
2022-10-09 07:38:06 - train: epoch 0089, iter [00140, 01251], lr: 0.000077, loss: 2.6237
2022-10-09 07:38:28 - train: epoch 0089, iter [00150, 01251], lr: 0.000077, loss: 2.3568
2022-10-09 07:38:49 - train: epoch 0089, iter [00160, 01251], lr: 0.000077, loss: 2.8088
2022-10-09 07:39:11 - train: epoch 0089, iter [00170, 01251], lr: 0.000077, loss: 2.7022
2022-10-09 07:39:32 - train: epoch 0089, iter [00180, 01251], lr: 0.000077, loss: 2.8261
2022-10-09 07:39:54 - train: epoch 0089, iter [00190, 01251], lr: 0.000077, loss: 3.2742
2022-10-09 07:40:15 - train: epoch 0089, iter [00200, 01251], lr: 0.000077, loss: 2.5532
2022-10-09 07:40:36 - train: epoch 0089, iter [00210, 01251], lr: 0.000077, loss: 3.1375
2022-10-09 07:40:58 - train: epoch 0089, iter [00220, 01251], lr: 0.000076, loss: 3.1283
2022-10-09 07:41:19 - train: epoch 0089, iter [00230, 01251], lr: 0.000076, loss: 2.4114
2022-10-09 07:41:41 - train: epoch 0089, iter [00240, 01251], lr: 0.000076, loss: 3.2595
2022-10-09 07:42:03 - train: epoch 0089, iter [00250, 01251], lr: 0.000076, loss: 3.0104
2022-10-09 07:42:24 - train: epoch 0089, iter [00260, 01251], lr: 0.000076, loss: 2.8686
2022-10-09 07:42:46 - train: epoch 0089, iter [00270, 01251], lr: 0.000076, loss: 2.8875
2022-10-09 07:43:07 - train: epoch 0089, iter [00280, 01251], lr: 0.000076, loss: 2.6097
2022-10-09 07:43:29 - train: epoch 0089, iter [00290, 01251], lr: 0.000076, loss: 2.7335
2022-10-09 07:43:51 - train: epoch 0089, iter [00300, 01251], lr: 0.000076, loss: 2.9289
2022-10-09 07:44:12 - train: epoch 0089, iter [00310, 01251], lr: 0.000076, loss: 2.9261
2022-10-09 07:44:34 - train: epoch 0089, iter [00320, 01251], lr: 0.000075, loss: 2.8734
2022-10-09 07:44:55 - train: epoch 0089, iter [00330, 01251], lr: 0.000075, loss: 2.4273
2022-10-09 07:45:17 - train: epoch 0089, iter [00340, 01251], lr: 0.000075, loss: 3.2960
2022-10-09 07:45:38 - train: epoch 0089, iter [00350, 01251], lr: 0.000075, loss: 2.5969
2022-10-09 07:46:00 - train: epoch 0089, iter [00360, 01251], lr: 0.000075, loss: 2.7525
2022-10-09 07:46:21 - train: epoch 0089, iter [00370, 01251], lr: 0.000075, loss: 3.1399
2022-10-09 07:46:43 - train: epoch 0089, iter [00380, 01251], lr: 0.000075, loss: 2.5463
2022-10-09 07:47:04 - train: epoch 0089, iter [00390, 01251], lr: 0.000075, loss: 3.1445
2022-10-09 07:47:26 - train: epoch 0089, iter [00400, 01251], lr: 0.000075, loss: 2.5339
2022-10-09 07:47:47 - train: epoch 0089, iter [00410, 01251], lr: 0.000075, loss: 2.8086
2022-10-09 07:48:08 - train: epoch 0089, iter [00420, 01251], lr: 0.000074, loss: 2.3482
2022-10-09 07:48:30 - train: epoch 0089, iter [00430, 01251], lr: 0.000074, loss: 2.9439
2022-10-09 07:48:52 - train: epoch 0089, iter [00440, 01251], lr: 0.000074, loss: 3.0930
2022-10-09 07:49:13 - train: epoch 0089, iter [00450, 01251], lr: 0.000074, loss: 2.8122
2022-10-09 07:49:35 - train: epoch 0089, iter [00460, 01251], lr: 0.000074, loss: 2.9013
2022-10-09 07:49:56 - train: epoch 0089, iter [00470, 01251], lr: 0.000074, loss: 3.1894
2022-10-09 07:50:17 - train: epoch 0089, iter [00480, 01251], lr: 0.000074, loss: 3.1763
2022-10-09 07:50:39 - train: epoch 0089, iter [00490, 01251], lr: 0.000074, loss: 3.1836
2022-10-09 07:51:00 - train: epoch 0089, iter [00500, 01251], lr: 0.000074, loss: 2.1369
2022-10-09 07:51:22 - train: epoch 0089, iter [00510, 01251], lr: 0.000074, loss: 2.7396
2022-10-09 07:51:43 - train: epoch 0089, iter [00520, 01251], lr: 0.000073, loss: 2.1805
2022-10-09 07:52:05 - train: epoch 0089, iter [00530, 01251], lr: 0.000073, loss: 2.8784
2022-10-09 07:52:27 - train: epoch 0089, iter [00540, 01251], lr: 0.000073, loss: 2.6152
2022-10-09 07:52:48 - train: epoch 0089, iter [00550, 01251], lr: 0.000073, loss: 3.0865
2022-10-09 07:53:10 - train: epoch 0089, iter [00560, 01251], lr: 0.000073, loss: 2.7651
2022-10-09 07:53:31 - train: epoch 0089, iter [00570, 01251], lr: 0.000073, loss: 2.8181
2022-10-09 07:53:53 - train: epoch 0089, iter [00580, 01251], lr: 0.000073, loss: 2.5279
2022-10-09 07:54:14 - train: epoch 0089, iter [00590, 01251], lr: 0.000073, loss: 2.9032
2022-10-09 07:54:36 - train: epoch 0089, iter [00600, 01251], lr: 0.000073, loss: 2.4888
2022-10-09 07:54:57 - train: epoch 0089, iter [00610, 01251], lr: 0.000073, loss: 2.4912
2022-10-09 07:55:19 - train: epoch 0089, iter [00620, 01251], lr: 0.000072, loss: 2.8893
2022-10-09 07:55:40 - train: epoch 0089, iter [00630, 01251], lr: 0.000072, loss: 2.7635
2022-10-09 07:56:02 - train: epoch 0089, iter [00640, 01251], lr: 0.000072, loss: 3.0147
2022-10-09 07:56:24 - train: epoch 0089, iter [00650, 01251], lr: 0.000072, loss: 2.5976
2022-10-09 07:56:45 - train: epoch 0089, iter [00660, 01251], lr: 0.000072, loss: 2.5231
2022-10-09 07:57:06 - train: epoch 0089, iter [00670, 01251], lr: 0.000072, loss: 2.5430
2022-10-09 07:57:28 - train: epoch 0089, iter [00680, 01251], lr: 0.000072, loss: 3.0096
2022-10-09 07:57:49 - train: epoch 0089, iter [00690, 01251], lr: 0.000072, loss: 3.0672
2022-10-09 07:58:11 - train: epoch 0089, iter [00700, 01251], lr: 0.000072, loss: 2.4771
2022-10-09 07:58:32 - train: epoch 0089, iter [00710, 01251], lr: 0.000072, loss: 2.9032
2022-10-09 07:58:54 - train: epoch 0089, iter [00720, 01251], lr: 0.000071, loss: 2.6228
2022-10-09 07:59:15 - train: epoch 0089, iter [00730, 01251], lr: 0.000071, loss: 3.0853
2022-10-09 07:59:37 - train: epoch 0089, iter [00740, 01251], lr: 0.000071, loss: 2.6705
2022-10-09 07:59:59 - train: epoch 0089, iter [00750, 01251], lr: 0.000071, loss: 2.9558
2022-10-09 08:00:20 - train: epoch 0089, iter [00760, 01251], lr: 0.000071, loss: 2.4772
2022-10-09 08:00:42 - train: epoch 0089, iter [00770, 01251], lr: 0.000071, loss: 2.8652
2022-10-09 08:01:03 - train: epoch 0089, iter [00780, 01251], lr: 0.000071, loss: 3.1299
2022-10-09 08:01:25 - train: epoch 0089, iter [00790, 01251], lr: 0.000071, loss: 2.8384
2022-10-09 08:01:46 - train: epoch 0089, iter [00800, 01251], lr: 0.000071, loss: 3.1575
2022-10-09 08:02:07 - train: epoch 0089, iter [00810, 01251], lr: 0.000071, loss: 2.5894
2022-10-09 08:02:29 - train: epoch 0089, iter [00820, 01251], lr: 0.000071, loss: 2.8950
2022-10-09 08:02:50 - train: epoch 0089, iter [00830, 01251], lr: 0.000070, loss: 2.4003
2022-10-09 08:03:12 - train: epoch 0089, iter [00840, 01251], lr: 0.000070, loss: 2.9486
2022-10-09 08:03:33 - train: epoch 0089, iter [00850, 01251], lr: 0.000070, loss: 3.0290
2022-10-09 08:03:55 - train: epoch 0089, iter [00860, 01251], lr: 0.000070, loss: 3.1430
2022-10-09 08:04:16 - train: epoch 0089, iter [00870, 01251], lr: 0.000070, loss: 2.9591
2022-10-09 08:04:38 - train: epoch 0089, iter [00880, 01251], lr: 0.000070, loss: 2.6474
2022-10-09 08:04:59 - train: epoch 0089, iter [00890, 01251], lr: 0.000070, loss: 3.0258
2022-10-09 08:05:20 - train: epoch 0089, iter [00900, 01251], lr: 0.000070, loss: 2.6424
2022-10-09 08:05:42 - train: epoch 0089, iter [00910, 01251], lr: 0.000070, loss: 2.9630
2022-10-09 08:06:03 - train: epoch 0089, iter [00920, 01251], lr: 0.000070, loss: 3.1652
2022-10-09 08:06:25 - train: epoch 0089, iter [00930, 01251], lr: 0.000069, loss: 3.1247
2022-10-09 08:06:46 - train: epoch 0089, iter [00940, 01251], lr: 0.000069, loss: 2.7933
2022-10-09 08:07:08 - train: epoch 0089, iter [00950, 01251], lr: 0.000069, loss: 3.0693
2022-10-09 08:07:29 - train: epoch 0089, iter [00960, 01251], lr: 0.000069, loss: 2.9343
2022-10-09 08:07:51 - train: epoch 0089, iter [00970, 01251], lr: 0.000069, loss: 2.1086
2022-10-09 08:08:12 - train: epoch 0089, iter [00980, 01251], lr: 0.000069, loss: 2.7745
2022-10-09 08:08:34 - train: epoch 0089, iter [00990, 01251], lr: 0.000069, loss: 2.7893
2022-10-09 08:08:55 - train: epoch 0089, iter [01000, 01251], lr: 0.000069, loss: 2.3258
2022-10-09 08:09:17 - train: epoch 0089, iter [01010, 01251], lr: 0.000069, loss: 3.0201
2022-10-09 08:09:38 - train: epoch 0089, iter [01020, 01251], lr: 0.000069, loss: 2.5462
2022-10-09 08:10:00 - train: epoch 0089, iter [01030, 01251], lr: 0.000068, loss: 2.4953
2022-10-09 08:10:21 - train: epoch 0089, iter [01040, 01251], lr: 0.000068, loss: 2.5401
2022-10-09 08:10:43 - train: epoch 0089, iter [01050, 01251], lr: 0.000068, loss: 2.5042
2022-10-09 08:11:04 - train: epoch 0089, iter [01060, 01251], lr: 0.000068, loss: 3.0548
2022-10-09 08:11:26 - train: epoch 0089, iter [01070, 01251], lr: 0.000068, loss: 2.6962
2022-10-09 08:11:47 - train: epoch 0089, iter [01080, 01251], lr: 0.000068, loss: 3.1395
2022-10-09 08:12:09 - train: epoch 0089, iter [01090, 01251], lr: 0.000068, loss: 2.9533
2022-10-09 08:12:30 - train: epoch 0089, iter [01100, 01251], lr: 0.000068, loss: 2.9893
2022-10-09 08:12:52 - train: epoch 0089, iter [01110, 01251], lr: 0.000068, loss: 2.7256
2022-10-09 08:13:13 - train: epoch 0089, iter [01120, 01251], lr: 0.000068, loss: 2.9240
2022-10-09 08:13:34 - train: epoch 0089, iter [01130, 01251], lr: 0.000068, loss: 2.5902
2022-10-09 08:13:56 - train: epoch 0089, iter [01140, 01251], lr: 0.000067, loss: 2.2745
2022-10-09 08:14:17 - train: epoch 0089, iter [01150, 01251], lr: 0.000067, loss: 2.8176
2022-10-09 08:14:39 - train: epoch 0089, iter [01160, 01251], lr: 0.000067, loss: 3.1362
2022-10-09 08:15:00 - train: epoch 0089, iter [01170, 01251], lr: 0.000067, loss: 2.8596
2022-10-09 08:15:22 - train: epoch 0089, iter [01180, 01251], lr: 0.000067, loss: 2.0881
2022-10-09 08:15:43 - train: epoch 0089, iter [01190, 01251], lr: 0.000067, loss: 2.7118
2022-10-09 08:16:05 - train: epoch 0089, iter [01200, 01251], lr: 0.000067, loss: 2.1917
2022-10-09 08:16:26 - train: epoch 0089, iter [01210, 01251], lr: 0.000067, loss: 2.7431
2022-10-09 08:16:48 - train: epoch 0089, iter [01220, 01251], lr: 0.000067, loss: 2.7857
2022-10-09 08:17:09 - train: epoch 0089, iter [01230, 01251], lr: 0.000067, loss: 2.3747
2022-10-09 08:17:31 - train: epoch 0089, iter [01240, 01251], lr: 0.000067, loss: 2.9835
2022-10-09 08:17:52 - train: epoch 0089, iter [01250, 01251], lr: 0.000066, loss: 2.4924
2022-10-09 08:17:55 - train: epoch 089, train_loss: 2.7754
2022-10-09 08:19:12 - eval: epoch: 089, acc1: 83.018%, acc5: 96.474%, test_loss: 0.7597, per_image_load_time: 0.208ms, per_image_inference_time: 1.435ms
2022-10-09 08:19:13 - until epoch: 089, best_acc1: 83.018%
2022-10-09 08:19:13 - epoch 090 lr: 0.000066
2022-10-09 08:19:41 - train: epoch 0090, iter [00010, 01251], lr: 0.000066, loss: 2.5935
2022-10-09 08:20:02 - train: epoch 0090, iter [00020, 01251], lr: 0.000066, loss: 2.9490
2022-10-09 08:20:24 - train: epoch 0090, iter [00030, 01251], lr: 0.000066, loss: 3.0479
2022-10-09 08:20:45 - train: epoch 0090, iter [00040, 01251], lr: 0.000066, loss: 3.2217
2022-10-09 08:21:07 - train: epoch 0090, iter [00050, 01251], lr: 0.000066, loss: 3.0981
2022-10-09 08:21:28 - train: epoch 0090, iter [00060, 01251], lr: 0.000066, loss: 3.0696
2022-10-09 08:21:50 - train: epoch 0090, iter [00070, 01251], lr: 0.000066, loss: 2.9166
2022-10-09 08:22:11 - train: epoch 0090, iter [00080, 01251], lr: 0.000066, loss: 2.9739
2022-10-09 08:22:33 - train: epoch 0090, iter [00090, 01251], lr: 0.000066, loss: 2.8029
2022-10-09 08:22:54 - train: epoch 0090, iter [00100, 01251], lr: 0.000065, loss: 3.0290
2022-10-09 08:23:15 - train: epoch 0090, iter [00110, 01251], lr: 0.000065, loss: 3.0361
2022-10-09 08:23:37 - train: epoch 0090, iter [00120, 01251], lr: 0.000065, loss: 2.8863
2022-10-09 08:23:58 - train: epoch 0090, iter [00130, 01251], lr: 0.000065, loss: 2.8943
2022-10-09 08:24:19 - train: epoch 0090, iter [00140, 01251], lr: 0.000065, loss: 3.1188
2022-10-09 08:24:41 - train: epoch 0090, iter [00150, 01251], lr: 0.000065, loss: 2.6324
2022-10-09 08:25:02 - train: epoch 0090, iter [00160, 01251], lr: 0.000065, loss: 2.2635
2022-10-09 08:25:23 - train: epoch 0090, iter [00170, 01251], lr: 0.000065, loss: 2.8449
2022-10-09 08:25:45 - train: epoch 0090, iter [00180, 01251], lr: 0.000065, loss: 2.5299
2022-10-09 08:26:06 - train: epoch 0090, iter [00190, 01251], lr: 0.000065, loss: 2.6940
2022-10-09 08:26:28 - train: epoch 0090, iter [00200, 01251], lr: 0.000065, loss: 2.9351
2022-10-09 08:26:49 - train: epoch 0090, iter [00210, 01251], lr: 0.000064, loss: 2.6878
2022-10-09 08:27:11 - train: epoch 0090, iter [00220, 01251], lr: 0.000064, loss: 2.9536
2022-10-09 08:27:32 - train: epoch 0090, iter [00230, 01251], lr: 0.000064, loss: 2.8166
2022-10-09 08:27:54 - train: epoch 0090, iter [00240, 01251], lr: 0.000064, loss: 3.0845
2022-10-09 08:28:15 - train: epoch 0090, iter [00250, 01251], lr: 0.000064, loss: 3.1428
2022-10-09 08:28:37 - train: epoch 0090, iter [00260, 01251], lr: 0.000064, loss: 2.7108
2022-10-09 08:28:58 - train: epoch 0090, iter [00270, 01251], lr: 0.000064, loss: 2.9057
2022-10-09 08:29:19 - train: epoch 0090, iter [00280, 01251], lr: 0.000064, loss: 1.9053
2022-10-09 08:29:41 - train: epoch 0090, iter [00290, 01251], lr: 0.000064, loss: 2.6748
2022-10-09 08:30:02 - train: epoch 0090, iter [00300, 01251], lr: 0.000064, loss: 2.4627
2022-10-09 08:30:24 - train: epoch 0090, iter [00310, 01251], lr: 0.000064, loss: 2.5586
2022-10-09 08:30:45 - train: epoch 0090, iter [00320, 01251], lr: 0.000063, loss: 2.5914
2022-10-09 08:31:06 - train: epoch 0090, iter [00330, 01251], lr: 0.000063, loss: 3.0261
2022-10-09 08:31:28 - train: epoch 0090, iter [00340, 01251], lr: 0.000063, loss: 3.0349
2022-10-09 08:31:50 - train: epoch 0090, iter [00350, 01251], lr: 0.000063, loss: 2.7590
2022-10-09 08:32:11 - train: epoch 0090, iter [00360, 01251], lr: 0.000063, loss: 3.1259
2022-10-09 08:32:32 - train: epoch 0090, iter [00370, 01251], lr: 0.000063, loss: 2.9510
2022-10-09 08:32:54 - train: epoch 0090, iter [00380, 01251], lr: 0.000063, loss: 2.8182
2022-10-09 08:33:15 - train: epoch 0090, iter [00390, 01251], lr: 0.000063, loss: 2.4844
2022-10-09 08:33:37 - train: epoch 0090, iter [00400, 01251], lr: 0.000063, loss: 2.7867
2022-10-09 08:33:58 - train: epoch 0090, iter [00410, 01251], lr: 0.000063, loss: 3.1201
2022-10-09 08:34:19 - train: epoch 0090, iter [00420, 01251], lr: 0.000063, loss: 2.4591
2022-10-09 08:34:41 - train: epoch 0090, iter [00430, 01251], lr: 0.000062, loss: 2.7182
2022-10-09 08:35:02 - train: epoch 0090, iter [00440, 01251], lr: 0.000062, loss: 3.1452
2022-10-09 08:35:24 - train: epoch 0090, iter [00450, 01251], lr: 0.000062, loss: 2.9623
2022-10-09 08:35:45 - train: epoch 0090, iter [00460, 01251], lr: 0.000062, loss: 2.9039
2022-10-09 08:36:06 - train: epoch 0090, iter [00470, 01251], lr: 0.000062, loss: 2.7894
2022-10-09 08:36:28 - train: epoch 0090, iter [00480, 01251], lr: 0.000062, loss: 3.0766
2022-10-09 08:36:49 - train: epoch 0090, iter [00490, 01251], lr: 0.000062, loss: 2.9429
2022-10-09 08:37:11 - train: epoch 0090, iter [00500, 01251], lr: 0.000062, loss: 2.9824
2022-10-09 08:37:32 - train: epoch 0090, iter [00510, 01251], lr: 0.000062, loss: 1.9006
2022-10-09 08:37:54 - train: epoch 0090, iter [00520, 01251], lr: 0.000062, loss: 2.4957
2022-10-09 08:38:15 - train: epoch 0090, iter [00530, 01251], lr: 0.000062, loss: 2.1904
2022-10-09 08:38:37 - train: epoch 0090, iter [00540, 01251], lr: 0.000061, loss: 2.7149
2022-10-09 08:38:58 - train: epoch 0090, iter [00550, 01251], lr: 0.000061, loss: 3.1346
2022-10-09 08:39:19 - train: epoch 0090, iter [00560, 01251], lr: 0.000061, loss: 2.8676
2022-10-09 08:39:41 - train: epoch 0090, iter [00570, 01251], lr: 0.000061, loss: 2.9947
2022-10-09 08:40:02 - train: epoch 0090, iter [00580, 01251], lr: 0.000061, loss: 2.4317
2022-10-09 08:40:24 - train: epoch 0090, iter [00590, 01251], lr: 0.000061, loss: 2.8728
2022-10-09 08:40:45 - train: epoch 0090, iter [00600, 01251], lr: 0.000061, loss: 2.0219
2022-10-09 08:41:07 - train: epoch 0090, iter [00610, 01251], lr: 0.000061, loss: 1.8356
2022-10-09 08:41:28 - train: epoch 0090, iter [00620, 01251], lr: 0.000061, loss: 2.7750
2022-10-09 08:41:50 - train: epoch 0090, iter [00630, 01251], lr: 0.000061, loss: 3.0236
2022-10-09 08:42:11 - train: epoch 0090, iter [00640, 01251], lr: 0.000061, loss: 2.3604
2022-10-09 08:42:33 - train: epoch 0090, iter [00650, 01251], lr: 0.000060, loss: 2.9953
2022-10-09 08:42:54 - train: epoch 0090, iter [00660, 01251], lr: 0.000060, loss: 3.1722
2022-10-09 08:43:16 - train: epoch 0090, iter [00670, 01251], lr: 0.000060, loss: 2.4845
2022-10-09 08:43:37 - train: epoch 0090, iter [00680, 01251], lr: 0.000060, loss: 2.8177
2022-10-09 08:43:59 - train: epoch 0090, iter [00690, 01251], lr: 0.000060, loss: 2.6413
2022-10-09 08:44:20 - train: epoch 0090, iter [00700, 01251], lr: 0.000060, loss: 2.9168
2022-10-09 08:44:42 - train: epoch 0090, iter [00710, 01251], lr: 0.000060, loss: 2.7414
2022-10-09 08:45:03 - train: epoch 0090, iter [00720, 01251], lr: 0.000060, loss: 2.6312
2022-10-09 08:45:25 - train: epoch 0090, iter [00730, 01251], lr: 0.000060, loss: 2.2458
2022-10-09 08:45:46 - train: epoch 0090, iter [00740, 01251], lr: 0.000060, loss: 3.0964
2022-10-09 08:46:08 - train: epoch 0090, iter [00750, 01251], lr: 0.000060, loss: 2.7570
2022-10-09 08:46:29 - train: epoch 0090, iter [00760, 01251], lr: 0.000059, loss: 3.0680
2022-10-09 08:46:51 - train: epoch 0090, iter [00770, 01251], lr: 0.000059, loss: 2.6385
2022-10-09 08:47:12 - train: epoch 0090, iter [00780, 01251], lr: 0.000059, loss: 2.3315
2022-10-09 08:47:34 - train: epoch 0090, iter [00790, 01251], lr: 0.000059, loss: 2.6359
2022-10-09 08:47:55 - train: epoch 0090, iter [00800, 01251], lr: 0.000059, loss: 3.2195
2022-10-09 08:48:17 - train: epoch 0090, iter [00810, 01251], lr: 0.000059, loss: 3.1291
2022-10-09 08:48:38 - train: epoch 0090, iter [00820, 01251], lr: 0.000059, loss: 2.6541
2022-10-09 08:49:00 - train: epoch 0090, iter [00830, 01251], lr: 0.000059, loss: 3.0396
2022-10-09 08:49:21 - train: epoch 0090, iter [00840, 01251], lr: 0.000059, loss: 3.1135
2022-10-09 08:49:43 - train: epoch 0090, iter [00850, 01251], lr: 0.000059, loss: 2.9606
2022-10-09 08:50:04 - train: epoch 0090, iter [00860, 01251], lr: 0.000059, loss: 2.9537
2022-10-09 08:50:26 - train: epoch 0090, iter [00870, 01251], lr: 0.000058, loss: 2.9789
2022-10-09 08:50:47 - train: epoch 0090, iter [00880, 01251], lr: 0.000058, loss: 3.0345
2022-10-09 08:51:08 - train: epoch 0090, iter [00890, 01251], lr: 0.000058, loss: 2.5172
2022-10-09 08:51:30 - train: epoch 0090, iter [00900, 01251], lr: 0.000058, loss: 2.0920
2022-10-09 08:51:51 - train: epoch 0090, iter [00910, 01251], lr: 0.000058, loss: 2.9241
2022-10-09 08:52:13 - train: epoch 0090, iter [00920, 01251], lr: 0.000058, loss: 3.2476
2022-10-09 08:52:34 - train: epoch 0090, iter [00930, 01251], lr: 0.000058, loss: 2.2193
2022-10-09 08:52:56 - train: epoch 0090, iter [00940, 01251], lr: 0.000058, loss: 2.7779
2022-10-09 08:53:17 - train: epoch 0090, iter [00950, 01251], lr: 0.000058, loss: 2.7403
2022-10-09 08:53:39 - train: epoch 0090, iter [00960, 01251], lr: 0.000058, loss: 2.5340
2022-10-09 08:54:00 - train: epoch 0090, iter [00970, 01251], lr: 0.000058, loss: 2.8990
2022-10-09 08:54:22 - train: epoch 0090, iter [00980, 01251], lr: 0.000058, loss: 3.0422
2022-10-09 08:54:43 - train: epoch 0090, iter [00990, 01251], lr: 0.000057, loss: 2.8498
2022-10-09 08:55:04 - train: epoch 0090, iter [01000, 01251], lr: 0.000057, loss: 2.7999
2022-10-09 08:55:26 - train: epoch 0090, iter [01010, 01251], lr: 0.000057, loss: 2.3322
2022-10-09 08:55:47 - train: epoch 0090, iter [01020, 01251], lr: 0.000057, loss: 2.3480
2022-10-09 08:56:09 - train: epoch 0090, iter [01030, 01251], lr: 0.000057, loss: 2.7768
2022-10-09 08:56:30 - train: epoch 0090, iter [01040, 01251], lr: 0.000057, loss: 3.2081
2022-10-09 08:56:51 - train: epoch 0090, iter [01050, 01251], lr: 0.000057, loss: 2.2849
2022-10-09 08:57:13 - train: epoch 0090, iter [01060, 01251], lr: 0.000057, loss: 2.7839
2022-10-09 08:57:34 - train: epoch 0090, iter [01070, 01251], lr: 0.000057, loss: 2.5740
2022-10-09 08:57:56 - train: epoch 0090, iter [01080, 01251], lr: 0.000057, loss: 2.4460
2022-10-09 08:58:16 - train: epoch 0090, iter [01090, 01251], lr: 0.000057, loss: 2.6687
2022-10-09 08:58:38 - train: epoch 0090, iter [01100, 01251], lr: 0.000056, loss: 2.9111
2022-10-09 08:58:59 - train: epoch 0090, iter [01110, 01251], lr: 0.000056, loss: 2.6939
2022-10-09 08:59:20 - train: epoch 0090, iter [01120, 01251], lr: 0.000056, loss: 2.5871
2022-10-09 08:59:41 - train: epoch 0090, iter [01130, 01251], lr: 0.000056, loss: 2.9843
2022-10-09 09:00:02 - train: epoch 0090, iter [01140, 01251], lr: 0.000056, loss: 2.7077
2022-10-09 09:00:24 - train: epoch 0090, iter [01150, 01251], lr: 0.000056, loss: 2.5768
2022-10-09 09:00:45 - train: epoch 0090, iter [01160, 01251], lr: 0.000056, loss: 2.9603
2022-10-09 09:01:07 - train: epoch 0090, iter [01170, 01251], lr: 0.000056, loss: 3.0626
2022-10-09 09:01:29 - train: epoch 0090, iter [01180, 01251], lr: 0.000056, loss: 2.6001
2022-10-09 09:01:50 - train: epoch 0090, iter [01190, 01251], lr: 0.000056, loss: 3.0428
2022-10-09 09:02:12 - train: epoch 0090, iter [01200, 01251], lr: 0.000056, loss: 3.1217
2022-10-09 09:02:33 - train: epoch 0090, iter [01210, 01251], lr: 0.000056, loss: 3.0907
2022-10-09 09:02:54 - train: epoch 0090, iter [01220, 01251], lr: 0.000055, loss: 3.0153
2022-10-09 09:03:16 - train: epoch 0090, iter [01230, 01251], lr: 0.000055, loss: 2.7171
2022-10-09 09:03:37 - train: epoch 0090, iter [01240, 01251], lr: 0.000055, loss: 2.8627
2022-10-09 09:03:58 - train: epoch 0090, iter [01250, 01251], lr: 0.000055, loss: 2.1793
2022-10-09 09:04:02 - train: epoch 090, train_loss: 2.7722
2022-10-09 09:05:19 - eval: epoch: 090, acc1: 83.018%, acc5: 96.542%, test_loss: 0.7522, per_image_load_time: 0.251ms, per_image_inference_time: 1.445ms
2022-10-09 09:05:20 - until epoch: 090, best_acc1: 83.018%
2022-10-09 09:05:20 - epoch 091 lr: 0.000055
2022-10-09 09:05:48 - train: epoch 0091, iter [00010, 01251], lr: 0.000055, loss: 3.2034
2022-10-09 09:06:10 - train: epoch 0091, iter [00020, 01251], lr: 0.000055, loss: 3.1447
2022-10-09 09:06:31 - train: epoch 0091, iter [00030, 01251], lr: 0.000055, loss: 2.9324
2022-10-09 09:06:52 - train: epoch 0091, iter [00040, 01251], lr: 0.000055, loss: 2.5636
2022-10-09 09:07:14 - train: epoch 0091, iter [00050, 01251], lr: 0.000055, loss: 2.6533
2022-10-09 09:07:35 - train: epoch 0091, iter [00060, 01251], lr: 0.000055, loss: 3.0476
2022-10-09 09:07:56 - train: epoch 0091, iter [00070, 01251], lr: 0.000055, loss: 2.7090
2022-10-09 09:08:18 - train: epoch 0091, iter [00080, 01251], lr: 0.000054, loss: 2.3110
2022-10-09 09:08:39 - train: epoch 0091, iter [00090, 01251], lr: 0.000054, loss: 3.1285
2022-10-09 09:09:01 - train: epoch 0091, iter [00100, 01251], lr: 0.000054, loss: 3.0906
2022-10-09 09:09:22 - train: epoch 0091, iter [00110, 01251], lr: 0.000054, loss: 2.9243
2022-10-09 09:09:44 - train: epoch 0091, iter [00120, 01251], lr: 0.000054, loss: 2.6067
2022-10-09 09:10:05 - train: epoch 0091, iter [00130, 01251], lr: 0.000054, loss: 2.1810
2022-10-09 09:10:26 - train: epoch 0091, iter [00140, 01251], lr: 0.000054, loss: 3.1942
2022-10-09 09:10:47 - train: epoch 0091, iter [00150, 01251], lr: 0.000054, loss: 3.2338
2022-10-09 09:11:09 - train: epoch 0091, iter [00160, 01251], lr: 0.000054, loss: 2.4684
2022-10-09 09:11:30 - train: epoch 0091, iter [00170, 01251], lr: 0.000054, loss: 2.7036
2022-10-09 09:11:52 - train: epoch 0091, iter [00180, 01251], lr: 0.000054, loss: 3.0660
2022-10-09 09:12:13 - train: epoch 0091, iter [00190, 01251], lr: 0.000054, loss: 3.0855
2022-10-09 09:12:34 - train: epoch 0091, iter [00200, 01251], lr: 0.000053, loss: 2.9770
2022-10-09 09:12:56 - train: epoch 0091, iter [00210, 01251], lr: 0.000053, loss: 3.1908
2022-10-09 09:13:17 - train: epoch 0091, iter [00220, 01251], lr: 0.000053, loss: 2.9161
2022-10-09 09:13:39 - train: epoch 0091, iter [00230, 01251], lr: 0.000053, loss: 2.0776
2022-10-09 09:14:00 - train: epoch 0091, iter [00240, 01251], lr: 0.000053, loss: 2.5040
2022-10-09 09:14:21 - train: epoch 0091, iter [00250, 01251], lr: 0.000053, loss: 2.9800
2022-10-09 09:14:43 - train: epoch 0091, iter [00260, 01251], lr: 0.000053, loss: 3.0493
2022-10-09 09:15:04 - train: epoch 0091, iter [00270, 01251], lr: 0.000053, loss: 3.2951
2022-10-09 09:15:25 - train: epoch 0091, iter [00280, 01251], lr: 0.000053, loss: 2.3880
2022-10-09 09:15:47 - train: epoch 0091, iter [00290, 01251], lr: 0.000053, loss: 2.9189
2022-10-09 09:16:08 - train: epoch 0091, iter [00300, 01251], lr: 0.000053, loss: 2.7988
2022-10-09 09:16:29 - train: epoch 0091, iter [00310, 01251], lr: 0.000053, loss: 2.7033
2022-10-09 09:16:50 - train: epoch 0091, iter [00320, 01251], lr: 0.000052, loss: 2.3602
2022-10-09 09:17:11 - train: epoch 0091, iter [00330, 01251], lr: 0.000052, loss: 2.6693
2022-10-09 09:17:33 - train: epoch 0091, iter [00340, 01251], lr: 0.000052, loss: 2.9081
2022-10-09 09:17:54 - train: epoch 0091, iter [00350, 01251], lr: 0.000052, loss: 2.7986
2022-10-09 09:18:15 - train: epoch 0091, iter [00360, 01251], lr: 0.000052, loss: 2.5368
2022-10-09 09:18:36 - train: epoch 0091, iter [00370, 01251], lr: 0.000052, loss: 2.2359
2022-10-09 09:18:57 - train: epoch 0091, iter [00380, 01251], lr: 0.000052, loss: 2.1845
2022-10-09 09:19:19 - train: epoch 0091, iter [00390, 01251], lr: 0.000052, loss: 2.6154
2022-10-09 09:19:40 - train: epoch 0091, iter [00400, 01251], lr: 0.000052, loss: 2.9510
2022-10-09 09:20:01 - train: epoch 0091, iter [00410, 01251], lr: 0.000052, loss: 3.1950
2022-10-09 09:20:22 - train: epoch 0091, iter [00420, 01251], lr: 0.000052, loss: 3.0319
2022-10-09 09:20:43 - train: epoch 0091, iter [00430, 01251], lr: 0.000052, loss: 2.5725
2022-10-09 09:21:05 - train: epoch 0091, iter [00440, 01251], lr: 0.000051, loss: 2.4568
2022-10-09 09:21:26 - train: epoch 0091, iter [00450, 01251], lr: 0.000051, loss: 2.3459
2022-10-09 09:21:47 - train: epoch 0091, iter [00460, 01251], lr: 0.000051, loss: 2.9238
2022-10-09 09:22:08 - train: epoch 0091, iter [00470, 01251], lr: 0.000051, loss: 2.7178
2022-10-09 09:22:29 - train: epoch 0091, iter [00480, 01251], lr: 0.000051, loss: 2.6582
2022-10-09 09:22:51 - train: epoch 0091, iter [00490, 01251], lr: 0.000051, loss: 3.2322
2022-10-09 09:23:12 - train: epoch 0091, iter [00500, 01251], lr: 0.000051, loss: 3.0709
2022-10-09 09:23:33 - train: epoch 0091, iter [00510, 01251], lr: 0.000051, loss: 2.0091
2022-10-09 09:23:55 - train: epoch 0091, iter [00520, 01251], lr: 0.000051, loss: 3.3178
2022-10-09 09:24:16 - train: epoch 0091, iter [00530, 01251], lr: 0.000051, loss: 2.6794
2022-10-09 09:24:37 - train: epoch 0091, iter [00540, 01251], lr: 0.000051, loss: 2.6630
2022-10-09 09:24:59 - train: epoch 0091, iter [00550, 01251], lr: 0.000051, loss: 3.0906
2022-10-09 09:25:20 - train: epoch 0091, iter [00560, 01251], lr: 0.000050, loss: 2.4263
2022-10-09 09:25:42 - train: epoch 0091, iter [00570, 01251], lr: 0.000050, loss: 2.9829
2022-10-09 09:26:03 - train: epoch 0091, iter [00580, 01251], lr: 0.000050, loss: 2.6660
2022-10-09 09:26:24 - train: epoch 0091, iter [00590, 01251], lr: 0.000050, loss: 2.7531
2022-10-09 09:26:46 - train: epoch 0091, iter [00600, 01251], lr: 0.000050, loss: 2.7478
2022-10-09 09:27:07 - train: epoch 0091, iter [00610, 01251], lr: 0.000050, loss: 3.2819
2022-10-09 09:27:28 - train: epoch 0091, iter [00620, 01251], lr: 0.000050, loss: 3.2011
2022-10-09 09:27:50 - train: epoch 0091, iter [00630, 01251], lr: 0.000050, loss: 2.9093
2022-10-09 09:28:11 - train: epoch 0091, iter [00640, 01251], lr: 0.000050, loss: 2.7357
2022-10-09 09:28:32 - train: epoch 0091, iter [00650, 01251], lr: 0.000050, loss: 2.5103
2022-10-09 09:28:54 - train: epoch 0091, iter [00660, 01251], lr: 0.000050, loss: 3.0438
2022-10-09 09:29:15 - train: epoch 0091, iter [00670, 01251], lr: 0.000050, loss: 2.9298
2022-10-09 09:29:36 - train: epoch 0091, iter [00680, 01251], lr: 0.000049, loss: 3.1284
2022-10-09 09:29:58 - train: epoch 0091, iter [00690, 01251], lr: 0.000049, loss: 2.9675
2022-10-09 09:30:19 - train: epoch 0091, iter [00700, 01251], lr: 0.000049, loss: 2.5755
2022-10-09 09:30:40 - train: epoch 0091, iter [00710, 01251], lr: 0.000049, loss: 2.5959
2022-10-09 09:31:01 - train: epoch 0091, iter [00720, 01251], lr: 0.000049, loss: 2.9748
2022-10-09 09:31:23 - train: epoch 0091, iter [00730, 01251], lr: 0.000049, loss: 2.3850
2022-10-09 09:31:44 - train: epoch 0091, iter [00740, 01251], lr: 0.000049, loss: 2.6316
2022-10-09 09:32:06 - train: epoch 0091, iter [00750, 01251], lr: 0.000049, loss: 2.4858
2022-10-09 09:32:27 - train: epoch 0091, iter [00760, 01251], lr: 0.000049, loss: 2.1180
2022-10-09 09:32:48 - train: epoch 0091, iter [00770, 01251], lr: 0.000049, loss: 2.6903
2022-10-09 09:33:09 - train: epoch 0091, iter [00780, 01251], lr: 0.000049, loss: 2.6453
2022-10-09 09:33:30 - train: epoch 0091, iter [00790, 01251], lr: 0.000049, loss: 3.2031
2022-10-09 09:33:51 - train: epoch 0091, iter [00800, 01251], lr: 0.000049, loss: 2.9557
2022-10-09 09:34:13 - train: epoch 0091, iter [00810, 01251], lr: 0.000048, loss: 3.0447
2022-10-09 09:34:34 - train: epoch 0091, iter [00820, 01251], lr: 0.000048, loss: 3.1166
2022-10-09 09:34:55 - train: epoch 0091, iter [00830, 01251], lr: 0.000048, loss: 3.0961
2022-10-09 09:35:17 - train: epoch 0091, iter [00840, 01251], lr: 0.000048, loss: 2.2048
2022-10-09 09:35:38 - train: epoch 0091, iter [00850, 01251], lr: 0.000048, loss: 2.6959
2022-10-09 09:35:59 - train: epoch 0091, iter [00860, 01251], lr: 0.000048, loss: 3.0612
2022-10-09 09:36:21 - train: epoch 0091, iter [00870, 01251], lr: 0.000048, loss: 2.9183
2022-10-09 09:36:42 - train: epoch 0091, iter [00880, 01251], lr: 0.000048, loss: 3.1980
2022-10-09 09:37:03 - train: epoch 0091, iter [00890, 01251], lr: 0.000048, loss: 2.9442
2022-10-09 09:37:25 - train: epoch 0091, iter [00900, 01251], lr: 0.000048, loss: 2.8820
2022-10-09 09:37:46 - train: epoch 0091, iter [00910, 01251], lr: 0.000048, loss: 2.4242
2022-10-09 09:38:07 - train: epoch 0091, iter [00920, 01251], lr: 0.000048, loss: 2.6760
2022-10-09 09:38:29 - train: epoch 0091, iter [00930, 01251], lr: 0.000047, loss: 2.7294
2022-10-09 09:38:50 - train: epoch 0091, iter [00940, 01251], lr: 0.000047, loss: 2.7677
2022-10-09 09:39:11 - train: epoch 0091, iter [00950, 01251], lr: 0.000047, loss: 2.9213
2022-10-09 09:39:33 - train: epoch 0091, iter [00960, 01251], lr: 0.000047, loss: 2.8216
2022-10-09 09:39:54 - train: epoch 0091, iter [00970, 01251], lr: 0.000047, loss: 3.2139
2022-10-09 09:40:15 - train: epoch 0091, iter [00980, 01251], lr: 0.000047, loss: 2.4063
2022-10-09 09:40:36 - train: epoch 0091, iter [00990, 01251], lr: 0.000047, loss: 2.7980
2022-10-09 09:40:58 - train: epoch 0091, iter [01000, 01251], lr: 0.000047, loss: 2.9040
2022-10-09 09:41:19 - train: epoch 0091, iter [01010, 01251], lr: 0.000047, loss: 3.3380
2022-10-09 09:41:40 - train: epoch 0091, iter [01020, 01251], lr: 0.000047, loss: 2.6379
2022-10-09 09:42:02 - train: epoch 0091, iter [01030, 01251], lr: 0.000047, loss: 2.1502
2022-10-09 09:42:23 - train: epoch 0091, iter [01040, 01251], lr: 0.000047, loss: 2.8411
2022-10-09 09:42:44 - train: epoch 0091, iter [01050, 01251], lr: 0.000047, loss: 3.0504
2022-10-09 09:43:05 - train: epoch 0091, iter [01060, 01251], lr: 0.000046, loss: 3.1673
2022-10-09 09:43:27 - train: epoch 0091, iter [01070, 01251], lr: 0.000046, loss: 2.0080
2022-10-09 09:43:48 - train: epoch 0091, iter [01080, 01251], lr: 0.000046, loss: 3.0272
2022-10-09 09:44:09 - train: epoch 0091, iter [01090, 01251], lr: 0.000046, loss: 3.1034
2022-10-09 09:44:31 - train: epoch 0091, iter [01100, 01251], lr: 0.000046, loss: 3.1676
2022-10-09 09:44:52 - train: epoch 0091, iter [01110, 01251], lr: 0.000046, loss: 3.1040
2022-10-09 09:45:13 - train: epoch 0091, iter [01120, 01251], lr: 0.000046, loss: 2.6452
2022-10-09 09:45:35 - train: epoch 0091, iter [01130, 01251], lr: 0.000046, loss: 2.9967
2022-10-09 09:45:56 - train: epoch 0091, iter [01140, 01251], lr: 0.000046, loss: 3.0022
2022-10-09 09:46:17 - train: epoch 0091, iter [01150, 01251], lr: 0.000046, loss: 2.7332
2022-10-09 09:46:39 - train: epoch 0091, iter [01160, 01251], lr: 0.000046, loss: 2.6319
2022-10-09 09:47:00 - train: epoch 0091, iter [01170, 01251], lr: 0.000046, loss: 2.4685
2022-10-09 09:47:21 - train: epoch 0091, iter [01180, 01251], lr: 0.000045, loss: 2.6616
2022-10-09 09:47:43 - train: epoch 0091, iter [01190, 01251], lr: 0.000045, loss: 2.0439
2022-10-09 09:48:04 - train: epoch 0091, iter [01200, 01251], lr: 0.000045, loss: 3.2060
2022-10-09 09:48:25 - train: epoch 0091, iter [01210, 01251], lr: 0.000045, loss: 2.9617
2022-10-09 09:48:47 - train: epoch 0091, iter [01220, 01251], lr: 0.000045, loss: 2.9987
2022-10-09 09:49:08 - train: epoch 0091, iter [01230, 01251], lr: 0.000045, loss: 3.1796
2022-10-09 09:49:29 - train: epoch 0091, iter [01240, 01251], lr: 0.000045, loss: 2.8287
2022-10-09 09:49:50 - train: epoch 0091, iter [01250, 01251], lr: 0.000045, loss: 2.3396
2022-10-09 09:49:54 - train: epoch 091, train_loss: 2.7691
2022-10-09 09:51:10 - eval: epoch: 091, acc1: 83.044%, acc5: 96.518%, test_loss: 0.7523, per_image_load_time: 0.824ms, per_image_inference_time: 1.430ms
2022-10-09 09:51:11 - until epoch: 091, best_acc1: 83.044%
2022-10-09 09:51:11 - epoch 092 lr: 0.000045
2022-10-09 09:51:39 - train: epoch 0092, iter [00010, 01251], lr: 0.000045, loss: 2.9601
2022-10-09 09:52:00 - train: epoch 0092, iter [00020, 01251], lr: 0.000045, loss: 3.0878
2022-10-09 09:52:21 - train: epoch 0092, iter [00030, 01251], lr: 0.000045, loss: 2.6650
2022-10-09 09:52:42 - train: epoch 0092, iter [00040, 01251], lr: 0.000045, loss: 1.8471
2022-10-09 09:53:03 - train: epoch 0092, iter [00050, 01251], lr: 0.000045, loss: 3.1381
2022-10-09 09:53:24 - train: epoch 0092, iter [00060, 01251], lr: 0.000044, loss: 3.1367
2022-10-09 09:53:46 - train: epoch 0092, iter [00070, 01251], lr: 0.000044, loss: 2.4999
2022-10-09 09:54:07 - train: epoch 0092, iter [00080, 01251], lr: 0.000044, loss: 2.6399
2022-10-09 09:54:28 - train: epoch 0092, iter [00090, 01251], lr: 0.000044, loss: 3.0797
2022-10-09 09:54:49 - train: epoch 0092, iter [00100, 01251], lr: 0.000044, loss: 2.8416
2022-10-09 09:55:11 - train: epoch 0092, iter [00110, 01251], lr: 0.000044, loss: 2.9782
2022-10-09 09:55:32 - train: epoch 0092, iter [00120, 01251], lr: 0.000044, loss: 2.8389
2022-10-09 09:55:53 - train: epoch 0092, iter [00130, 01251], lr: 0.000044, loss: 3.0357
2022-10-09 09:56:15 - train: epoch 0092, iter [00140, 01251], lr: 0.000044, loss: 3.2033
2022-10-09 09:56:36 - train: epoch 0092, iter [00150, 01251], lr: 0.000044, loss: 2.5554
2022-10-09 09:56:57 - train: epoch 0092, iter [00160, 01251], lr: 0.000044, loss: 3.0619
2022-10-09 09:57:19 - train: epoch 0092, iter [00170, 01251], lr: 0.000044, loss: 3.1367
2022-10-09 09:57:40 - train: epoch 0092, iter [00180, 01251], lr: 0.000044, loss: 2.9441
2022-10-09 09:58:01 - train: epoch 0092, iter [00190, 01251], lr: 0.000043, loss: 2.5646
2022-10-09 09:58:22 - train: epoch 0092, iter [00200, 01251], lr: 0.000043, loss: 3.0836
2022-10-09 09:58:44 - train: epoch 0092, iter [00210, 01251], lr: 0.000043, loss: 2.6977
2022-10-09 09:59:05 - train: epoch 0092, iter [00220, 01251], lr: 0.000043, loss: 3.1993
2022-10-09 09:59:26 - train: epoch 0092, iter [00230, 01251], lr: 0.000043, loss: 2.9193
2022-10-09 09:59:48 - train: epoch 0092, iter [00240, 01251], lr: 0.000043, loss: 3.1459
2022-10-09 10:00:09 - train: epoch 0092, iter [00250, 01251], lr: 0.000043, loss: 3.0201
2022-10-09 10:00:30 - train: epoch 0092, iter [00260, 01251], lr: 0.000043, loss: 2.7979
2022-10-09 10:00:52 - train: epoch 0092, iter [00270, 01251], lr: 0.000043, loss: 3.0253
2022-10-09 10:01:13 - train: epoch 0092, iter [00280, 01251], lr: 0.000043, loss: 3.1810
2022-10-09 10:01:34 - train: epoch 0092, iter [00290, 01251], lr: 0.000043, loss: 2.8218
2022-10-09 10:01:56 - train: epoch 0092, iter [00300, 01251], lr: 0.000043, loss: 1.9643
2022-10-09 10:02:17 - train: epoch 0092, iter [00310, 01251], lr: 0.000043, loss: 2.9739
2022-10-09 10:02:39 - train: epoch 0092, iter [00320, 01251], lr: 0.000042, loss: 3.2133
2022-10-09 10:03:00 - train: epoch 0092, iter [00330, 01251], lr: 0.000042, loss: 2.6958
2022-10-09 10:03:21 - train: epoch 0092, iter [00340, 01251], lr: 0.000042, loss: 2.5449
2022-10-09 10:03:43 - train: epoch 0092, iter [00350, 01251], lr: 0.000042, loss: 2.9126
2022-10-09 10:04:04 - train: epoch 0092, iter [00360, 01251], lr: 0.000042, loss: 2.8073
2022-10-09 10:04:26 - train: epoch 0092, iter [00370, 01251], lr: 0.000042, loss: 3.1420
2022-10-09 10:04:47 - train: epoch 0092, iter [00380, 01251], lr: 0.000042, loss: 2.9746
2022-10-09 10:05:08 - train: epoch 0092, iter [00390, 01251], lr: 0.000042, loss: 2.1988
2022-10-09 10:05:30 - train: epoch 0092, iter [00400, 01251], lr: 0.000042, loss: 2.6182
2022-10-09 10:05:51 - train: epoch 0092, iter [00410, 01251], lr: 0.000042, loss: 2.2254
2022-10-09 10:06:12 - train: epoch 0092, iter [00420, 01251], lr: 0.000042, loss: 1.9125
2022-10-09 10:06:34 - train: epoch 0092, iter [00430, 01251], lr: 0.000042, loss: 2.6651
2022-10-09 10:06:55 - train: epoch 0092, iter [00440, 01251], lr: 0.000042, loss: 2.9458
2022-10-09 10:07:17 - train: epoch 0092, iter [00450, 01251], lr: 0.000042, loss: 1.9372
2022-10-09 10:07:38 - train: epoch 0092, iter [00460, 01251], lr: 0.000041, loss: 2.4265
2022-10-09 10:08:00 - train: epoch 0092, iter [00470, 01251], lr: 0.000041, loss: 2.9771
2022-10-09 10:08:21 - train: epoch 0092, iter [00480, 01251], lr: 0.000041, loss: 3.1747
2022-10-09 10:08:42 - train: epoch 0092, iter [00490, 01251], lr: 0.000041, loss: 2.6690
2022-10-09 10:09:04 - train: epoch 0092, iter [00500, 01251], lr: 0.000041, loss: 2.9510
2022-10-09 10:09:25 - train: epoch 0092, iter [00510, 01251], lr: 0.000041, loss: 3.1558
2022-10-09 10:09:47 - train: epoch 0092, iter [00520, 01251], lr: 0.000041, loss: 2.1020
2022-10-09 10:10:08 - train: epoch 0092, iter [00530, 01251], lr: 0.000041, loss: 2.9012
2022-10-09 10:10:29 - train: epoch 0092, iter [00540, 01251], lr: 0.000041, loss: 2.4760
2022-10-09 10:10:51 - train: epoch 0092, iter [00550, 01251], lr: 0.000041, loss: 2.6063
2022-10-09 10:11:12 - train: epoch 0092, iter [00560, 01251], lr: 0.000041, loss: 2.4712
2022-10-09 10:11:34 - train: epoch 0092, iter [00570, 01251], lr: 0.000041, loss: 2.9101
2022-10-09 10:11:55 - train: epoch 0092, iter [00580, 01251], lr: 0.000041, loss: 2.8774
2022-10-09 10:12:17 - train: epoch 0092, iter [00590, 01251], lr: 0.000040, loss: 2.6344
2022-10-09 10:12:38 - train: epoch 0092, iter [00600, 01251], lr: 0.000040, loss: 2.6290
2022-10-09 10:12:59 - train: epoch 0092, iter [00610, 01251], lr: 0.000040, loss: 2.0072
2022-10-09 10:13:20 - train: epoch 0092, iter [00620, 01251], lr: 0.000040, loss: 2.5308
2022-10-09 10:13:42 - train: epoch 0092, iter [00630, 01251], lr: 0.000040, loss: 2.7699
2022-10-09 10:14:03 - train: epoch 0092, iter [00640, 01251], lr: 0.000040, loss: 2.5287
2022-10-09 10:14:25 - train: epoch 0092, iter [00650, 01251], lr: 0.000040, loss: 2.9724
2022-10-09 10:14:46 - train: epoch 0092, iter [00660, 01251], lr: 0.000040, loss: 2.6408
2022-10-09 10:15:07 - train: epoch 0092, iter [00670, 01251], lr: 0.000040, loss: 3.1976
2022-10-09 10:15:29 - train: epoch 0092, iter [00680, 01251], lr: 0.000040, loss: 2.7229
2022-10-09 10:15:50 - train: epoch 0092, iter [00690, 01251], lr: 0.000040, loss: 2.4756
2022-10-09 10:16:11 - train: epoch 0092, iter [00700, 01251], lr: 0.000040, loss: 3.1221
2022-10-09 10:16:33 - train: epoch 0092, iter [00710, 01251], lr: 0.000040, loss: 2.6852
2022-10-09 10:16:54 - train: epoch 0092, iter [00720, 01251], lr: 0.000040, loss: 2.3801
2022-10-09 10:17:16 - train: epoch 0092, iter [00730, 01251], lr: 0.000039, loss: 2.7970
2022-10-09 10:17:37 - train: epoch 0092, iter [00740, 01251], lr: 0.000039, loss: 2.8615
2022-10-09 10:17:58 - train: epoch 0092, iter [00750, 01251], lr: 0.000039, loss: 2.6233
2022-10-09 10:18:20 - train: epoch 0092, iter [00760, 01251], lr: 0.000039, loss: 2.4932
2022-10-09 10:18:41 - train: epoch 0092, iter [00770, 01251], lr: 0.000039, loss: 2.9273
2022-10-09 10:19:02 - train: epoch 0092, iter [00780, 01251], lr: 0.000039, loss: 2.4579
2022-10-09 10:19:24 - train: epoch 0092, iter [00790, 01251], lr: 0.000039, loss: 3.0783
2022-10-09 10:19:45 - train: epoch 0092, iter [00800, 01251], lr: 0.000039, loss: 2.8833
2022-10-09 10:20:06 - train: epoch 0092, iter [00810, 01251], lr: 0.000039, loss: 3.1823
2022-10-09 10:20:28 - train: epoch 0092, iter [00820, 01251], lr: 0.000039, loss: 3.3173
2022-10-09 10:20:49 - train: epoch 0092, iter [00830, 01251], lr: 0.000039, loss: 2.3583
2022-10-09 10:21:10 - train: epoch 0092, iter [00840, 01251], lr: 0.000039, loss: 3.0814
2022-10-09 10:21:32 - train: epoch 0092, iter [00850, 01251], lr: 0.000039, loss: 3.1005
2022-10-09 10:21:53 - train: epoch 0092, iter [00860, 01251], lr: 0.000039, loss: 2.8475
2022-10-09 10:22:14 - train: epoch 0092, iter [00870, 01251], lr: 0.000038, loss: 3.1565
2022-10-09 10:22:35 - train: epoch 0092, iter [00880, 01251], lr: 0.000038, loss: 2.2175
2022-10-09 10:22:57 - train: epoch 0092, iter [00890, 01251], lr: 0.000038, loss: 2.5659
2022-10-09 10:23:18 - train: epoch 0092, iter [00900, 01251], lr: 0.000038, loss: 2.8350
2022-10-09 10:23:39 - train: epoch 0092, iter [00910, 01251], lr: 0.000038, loss: 2.5434
2022-10-09 10:24:00 - train: epoch 0092, iter [00920, 01251], lr: 0.000038, loss: 2.7308
2022-10-09 10:24:22 - train: epoch 0092, iter [00930, 01251], lr: 0.000038, loss: 2.7342
2022-10-09 10:24:43 - train: epoch 0092, iter [00940, 01251], lr: 0.000038, loss: 3.1327
2022-10-09 10:25:04 - train: epoch 0092, iter [00950, 01251], lr: 0.000038, loss: 3.0420
2022-10-09 10:25:25 - train: epoch 0092, iter [00960, 01251], lr: 0.000038, loss: 2.9188
2022-10-09 10:25:47 - train: epoch 0092, iter [00970, 01251], lr: 0.000038, loss: 2.6765
2022-10-09 10:26:08 - train: epoch 0092, iter [00980, 01251], lr: 0.000038, loss: 3.2489
2022-10-09 10:26:29 - train: epoch 0092, iter [00990, 01251], lr: 0.000038, loss: 2.5051
2022-10-09 10:26:51 - train: epoch 0092, iter [01000, 01251], lr: 0.000038, loss: 2.6005
2022-10-09 10:27:12 - train: epoch 0092, iter [01010, 01251], lr: 0.000037, loss: 2.9878
2022-10-09 10:27:34 - train: epoch 0092, iter [01020, 01251], lr: 0.000037, loss: 2.8356
2022-10-09 10:27:55 - train: epoch 0092, iter [01030, 01251], lr: 0.000037, loss: 2.4722
2022-10-09 10:28:16 - train: epoch 0092, iter [01040, 01251], lr: 0.000037, loss: 2.7536
2022-10-09 10:28:38 - train: epoch 0092, iter [01050, 01251], lr: 0.000037, loss: 2.8238
2022-10-09 10:28:59 - train: epoch 0092, iter [01060, 01251], lr: 0.000037, loss: 2.4942
2022-10-09 10:29:21 - train: epoch 0092, iter [01070, 01251], lr: 0.000037, loss: 2.5765
2022-10-09 10:29:42 - train: epoch 0092, iter [01080, 01251], lr: 0.000037, loss: 2.4103
2022-10-09 10:30:03 - train: epoch 0092, iter [01090, 01251], lr: 0.000037, loss: 2.4926
2022-10-09 10:30:25 - train: epoch 0092, iter [01100, 01251], lr: 0.000037, loss: 3.0870
2022-10-09 10:30:46 - train: epoch 0092, iter [01110, 01251], lr: 0.000037, loss: 2.3334
2022-10-09 10:31:08 - train: epoch 0092, iter [01120, 01251], lr: 0.000037, loss: 2.9349
2022-10-09 10:31:29 - train: epoch 0092, iter [01130, 01251], lr: 0.000037, loss: 3.1027
2022-10-09 10:31:50 - train: epoch 0092, iter [01140, 01251], lr: 0.000037, loss: 2.9391
2022-10-09 10:32:12 - train: epoch 0092, iter [01150, 01251], lr: 0.000036, loss: 2.0836
2022-10-09 10:32:33 - train: epoch 0092, iter [01160, 01251], lr: 0.000036, loss: 2.2103
2022-10-09 10:32:54 - train: epoch 0092, iter [01170, 01251], lr: 0.000036, loss: 2.8868
2022-10-09 10:33:16 - train: epoch 0092, iter [01180, 01251], lr: 0.000036, loss: 2.5723
2022-10-09 10:33:37 - train: epoch 0092, iter [01190, 01251], lr: 0.000036, loss: 2.8727
2022-10-09 10:33:59 - train: epoch 0092, iter [01200, 01251], lr: 0.000036, loss: 2.2579
2022-10-09 10:34:20 - train: epoch 0092, iter [01210, 01251], lr: 0.000036, loss: 2.1670
2022-10-09 10:34:41 - train: epoch 0092, iter [01220, 01251], lr: 0.000036, loss: 2.9611
2022-10-09 10:35:03 - train: epoch 0092, iter [01230, 01251], lr: 0.000036, loss: 3.0959
2022-10-09 10:35:24 - train: epoch 0092, iter [01240, 01251], lr: 0.000036, loss: 2.9800
2022-10-09 10:35:45 - train: epoch 0092, iter [01250, 01251], lr: 0.000036, loss: 2.8996
2022-10-09 10:35:48 - train: epoch 092, train_loss: 2.7656
2022-10-09 10:37:05 - eval: epoch: 092, acc1: 83.110%, acc5: 96.536%, test_loss: 0.7523, per_image_load_time: 0.293ms, per_image_inference_time: 1.406ms
2022-10-09 10:37:06 - until epoch: 092, best_acc1: 83.110%
2022-10-09 10:37:06 - epoch 093 lr: 0.000036
2022-10-09 10:37:35 - train: epoch 0093, iter [00010, 01251], lr: 0.000036, loss: 3.0372
2022-10-09 10:37:56 - train: epoch 0093, iter [00020, 01251], lr: 0.000036, loss: 2.4810
2022-10-09 10:38:17 - train: epoch 0093, iter [00030, 01251], lr: 0.000036, loss: 2.6151
2022-10-09 10:38:38 - train: epoch 0093, iter [00040, 01251], lr: 0.000035, loss: 2.9064
2022-10-09 10:39:00 - train: epoch 0093, iter [00050, 01251], lr: 0.000035, loss: 2.5503
2022-10-09 10:39:21 - train: epoch 0093, iter [00060, 01251], lr: 0.000035, loss: 3.1194
2022-10-09 10:39:43 - train: epoch 0093, iter [00070, 01251], lr: 0.000035, loss: 3.0376
2022-10-09 10:40:04 - train: epoch 0093, iter [00080, 01251], lr: 0.000035, loss: 2.2220
2022-10-09 10:40:25 - train: epoch 0093, iter [00090, 01251], lr: 0.000035, loss: 2.8885
2022-10-09 10:40:47 - train: epoch 0093, iter [00100, 01251], lr: 0.000035, loss: 3.1974
2022-10-09 10:41:08 - train: epoch 0093, iter [00110, 01251], lr: 0.000035, loss: 2.9330
2022-10-09 10:41:29 - train: epoch 0093, iter [00120, 01251], lr: 0.000035, loss: 2.9192
2022-10-09 10:41:50 - train: epoch 0093, iter [00130, 01251], lr: 0.000035, loss: 2.8380
2022-10-09 10:42:12 - train: epoch 0093, iter [00140, 01251], lr: 0.000035, loss: 2.9105
2022-10-09 10:42:33 - train: epoch 0093, iter [00150, 01251], lr: 0.000035, loss: 2.9188
2022-10-09 10:42:55 - train: epoch 0093, iter [00160, 01251], lr: 0.000035, loss: 3.1129
2022-10-09 10:43:16 - train: epoch 0093, iter [00170, 01251], lr: 0.000035, loss: 2.4755
2022-10-09 10:43:37 - train: epoch 0093, iter [00180, 01251], lr: 0.000035, loss: 2.5343
2022-10-09 10:43:59 - train: epoch 0093, iter [00190, 01251], lr: 0.000034, loss: 2.6633
2022-10-09 10:44:20 - train: epoch 0093, iter [00200, 01251], lr: 0.000034, loss: 2.4002
2022-10-09 10:44:41 - train: epoch 0093, iter [00210, 01251], lr: 0.000034, loss: 2.9062
2022-10-09 10:45:03 - train: epoch 0093, iter [00220, 01251], lr: 0.000034, loss: 2.7955
2022-10-09 10:45:24 - train: epoch 0093, iter [00230, 01251], lr: 0.000034, loss: 2.2932
2022-10-09 10:45:46 - train: epoch 0093, iter [00240, 01251], lr: 0.000034, loss: 3.0411
2022-10-09 10:46:07 - train: epoch 0093, iter [00250, 01251], lr: 0.000034, loss: 2.5168
2022-10-09 10:46:28 - train: epoch 0093, iter [00260, 01251], lr: 0.000034, loss: 3.1809
2022-10-09 10:46:49 - train: epoch 0093, iter [00270, 01251], lr: 0.000034, loss: 2.2404
2022-10-09 10:47:11 - train: epoch 0093, iter [00280, 01251], lr: 0.000034, loss: 2.6507
2022-10-09 10:47:32 - train: epoch 0093, iter [00290, 01251], lr: 0.000034, loss: 2.2169
2022-10-09 10:47:53 - train: epoch 0093, iter [00300, 01251], lr: 0.000034, loss: 2.4338
2022-10-09 10:48:15 - train: epoch 0093, iter [00310, 01251], lr: 0.000034, loss: 1.8541
2022-10-09 10:48:36 - train: epoch 0093, iter [00320, 01251], lr: 0.000034, loss: 2.7001
2022-10-09 10:48:57 - train: epoch 0093, iter [00330, 01251], lr: 0.000034, loss: 2.9636
2022-10-09 10:49:19 - train: epoch 0093, iter [00340, 01251], lr: 0.000033, loss: 2.6163
2022-10-09 10:49:40 - train: epoch 0093, iter [00350, 01251], lr: 0.000033, loss: 2.6567
2022-10-09 10:50:02 - train: epoch 0093, iter [00360, 01251], lr: 0.000033, loss: 3.3037
2022-10-09 10:50:23 - train: epoch 0093, iter [00370, 01251], lr: 0.000033, loss: 2.5649
2022-10-09 10:50:44 - train: epoch 0093, iter [00380, 01251], lr: 0.000033, loss: 3.1632
2022-10-09 10:51:06 - train: epoch 0093, iter [00390, 01251], lr: 0.000033, loss: 2.6305
2022-10-09 10:51:27 - train: epoch 0093, iter [00400, 01251], lr: 0.000033, loss: 2.8055
2022-10-09 10:51:49 - train: epoch 0093, iter [00410, 01251], lr: 0.000033, loss: 3.3017
2022-10-09 10:52:10 - train: epoch 0093, iter [00420, 01251], lr: 0.000033, loss: 2.7731
2022-10-09 10:52:31 - train: epoch 0093, iter [00430, 01251], lr: 0.000033, loss: 2.9224
2022-10-09 10:52:53 - train: epoch 0093, iter [00440, 01251], lr: 0.000033, loss: 3.0580
2022-10-09 10:53:14 - train: epoch 0093, iter [00450, 01251], lr: 0.000033, loss: 2.4797
2022-10-09 10:53:35 - train: epoch 0093, iter [00460, 01251], lr: 0.000033, loss: 2.9762
2022-10-09 10:53:57 - train: epoch 0093, iter [00470, 01251], lr: 0.000033, loss: 2.7794
2022-10-09 10:54:18 - train: epoch 0093, iter [00480, 01251], lr: 0.000033, loss: 3.2511
2022-10-09 10:54:39 - train: epoch 0093, iter [00490, 01251], lr: 0.000032, loss: 2.8365
2022-10-09 10:55:01 - train: epoch 0093, iter [00500, 01251], lr: 0.000032, loss: 2.6901
2022-10-09 10:55:22 - train: epoch 0093, iter [00510, 01251], lr: 0.000032, loss: 2.5112
2022-10-09 10:55:43 - train: epoch 0093, iter [00520, 01251], lr: 0.000032, loss: 2.4583
2022-10-09 10:56:04 - train: epoch 0093, iter [00530, 01251], lr: 0.000032, loss: 2.8950
2022-10-09 10:56:26 - train: epoch 0093, iter [00540, 01251], lr: 0.000032, loss: 2.2733
2022-10-09 10:56:47 - train: epoch 0093, iter [00550, 01251], lr: 0.000032, loss: 2.2784
2022-10-09 10:57:08 - train: epoch 0093, iter [00560, 01251], lr: 0.000032, loss: 2.9179
2022-10-09 10:57:30 - train: epoch 0093, iter [00570, 01251], lr: 0.000032, loss: 2.8739
2022-10-09 10:57:51 - train: epoch 0093, iter [00580, 01251], lr: 0.000032, loss: 2.8494
2022-10-09 10:58:13 - train: epoch 0093, iter [00590, 01251], lr: 0.000032, loss: 2.7542
2022-10-09 10:58:34 - train: epoch 0093, iter [00600, 01251], lr: 0.000032, loss: 2.4615
2022-10-09 10:58:55 - train: epoch 0093, iter [00610, 01251], lr: 0.000032, loss: 2.1244
2022-10-09 10:59:16 - train: epoch 0093, iter [00620, 01251], lr: 0.000032, loss: 2.3779
2022-10-09 10:59:38 - train: epoch 0093, iter [00630, 01251], lr: 0.000032, loss: 2.6037
2022-10-09 10:59:59 - train: epoch 0093, iter [00640, 01251], lr: 0.000031, loss: 2.7803
2022-10-09 11:00:21 - train: epoch 0093, iter [00650, 01251], lr: 0.000031, loss: 2.8807
2022-10-09 11:00:42 - train: epoch 0093, iter [00660, 01251], lr: 0.000031, loss: 2.6925
2022-10-09 11:01:03 - train: epoch 0093, iter [00670, 01251], lr: 0.000031, loss: 1.9808
2022-10-09 11:01:25 - train: epoch 0093, iter [00680, 01251], lr: 0.000031, loss: 2.7472
2022-10-09 11:01:46 - train: epoch 0093, iter [00690, 01251], lr: 0.000031, loss: 3.1047
2022-10-09 11:02:08 - train: epoch 0093, iter [00700, 01251], lr: 0.000031, loss: 2.8919
2022-10-09 11:02:29 - train: epoch 0093, iter [00710, 01251], lr: 0.000031, loss: 2.9345
2022-10-09 11:02:50 - train: epoch 0093, iter [00720, 01251], lr: 0.000031, loss: 2.9060
2022-10-09 11:03:12 - train: epoch 0093, iter [00730, 01251], lr: 0.000031, loss: 2.4196
2022-10-09 11:03:33 - train: epoch 0093, iter [00740, 01251], lr: 0.000031, loss: 3.2710
2022-10-09 11:03:54 - train: epoch 0093, iter [00750, 01251], lr: 0.000031, loss: 2.8984
2022-10-09 11:04:16 - train: epoch 0093, iter [00760, 01251], lr: 0.000031, loss: 2.4932
2022-10-09 11:04:37 - train: epoch 0093, iter [00770, 01251], lr: 0.000031, loss: 2.7439
2022-10-09 11:04:58 - train: epoch 0093, iter [00780, 01251], lr: 0.000031, loss: 2.6431
2022-10-09 11:05:20 - train: epoch 0093, iter [00790, 01251], lr: 0.000031, loss: 3.2596
2022-10-09 11:05:41 - train: epoch 0093, iter [00800, 01251], lr: 0.000030, loss: 2.7722
2022-10-09 11:06:02 - train: epoch 0093, iter [00810, 01251], lr: 0.000030, loss: 2.9311
2022-10-09 11:06:24 - train: epoch 0093, iter [00820, 01251], lr: 0.000030, loss: 3.2853
2022-10-09 11:06:45 - train: epoch 0093, iter [00830, 01251], lr: 0.000030, loss: 2.2047
2022-10-09 11:07:07 - train: epoch 0093, iter [00840, 01251], lr: 0.000030, loss: 3.2053
2022-10-09 11:07:28 - train: epoch 0093, iter [00850, 01251], lr: 0.000030, loss: 2.9348
2022-10-09 11:07:49 - train: epoch 0093, iter [00860, 01251], lr: 0.000030, loss: 2.8809
2022-10-09 11:08:11 - train: epoch 0093, iter [00870, 01251], lr: 0.000030, loss: 2.6104
2022-10-09 11:08:32 - train: epoch 0093, iter [00880, 01251], lr: 0.000030, loss: 2.7441
2022-10-09 11:08:53 - train: epoch 0093, iter [00890, 01251], lr: 0.000030, loss: 2.3876
2022-10-09 11:09:15 - train: epoch 0093, iter [00900, 01251], lr: 0.000030, loss: 2.5197
2022-10-09 11:09:36 - train: epoch 0093, iter [00910, 01251], lr: 0.000030, loss: 2.9468
2022-10-09 11:09:58 - train: epoch 0093, iter [00920, 01251], lr: 0.000030, loss: 2.1604
2022-10-09 11:10:19 - train: epoch 0093, iter [00930, 01251], lr: 0.000030, loss: 3.1372
2022-10-09 11:10:41 - train: epoch 0093, iter [00940, 01251], lr: 0.000030, loss: 3.0095
2022-10-09 11:11:02 - train: epoch 0093, iter [00950, 01251], lr: 0.000030, loss: 3.1142
2022-10-09 11:11:23 - train: epoch 0093, iter [00960, 01251], lr: 0.000029, loss: 2.4502
2022-10-09 11:11:45 - train: epoch 0093, iter [00970, 01251], lr: 0.000029, loss: 2.6237
2022-10-09 11:12:06 - train: epoch 0093, iter [00980, 01251], lr: 0.000029, loss: 3.3427
2022-10-09 11:12:28 - train: epoch 0093, iter [00990, 01251], lr: 0.000029, loss: 2.6024
2022-10-09 11:12:49 - train: epoch 0093, iter [01000, 01251], lr: 0.000029, loss: 3.0180
2022-10-09 11:13:11 - train: epoch 0093, iter [01010, 01251], lr: 0.000029, loss: 2.7694
2022-10-09 11:13:32 - train: epoch 0093, iter [01020, 01251], lr: 0.000029, loss: 3.0023
2022-10-09 11:13:53 - train: epoch 0093, iter [01030, 01251], lr: 0.000029, loss: 2.7276
2022-10-09 11:14:15 - train: epoch 0093, iter [01040, 01251], lr: 0.000029, loss: 2.4451
2022-10-09 11:14:36 - train: epoch 0093, iter [01050, 01251], lr: 0.000029, loss: 2.9512
2022-10-09 11:14:58 - train: epoch 0093, iter [01060, 01251], lr: 0.000029, loss: 2.9068
2022-10-09 11:15:19 - train: epoch 0093, iter [01070, 01251], lr: 0.000029, loss: 2.8630
2022-10-09 11:15:41 - train: epoch 0093, iter [01080, 01251], lr: 0.000029, loss: 3.1933
2022-10-09 11:16:02 - train: epoch 0093, iter [01090, 01251], lr: 0.000029, loss: 3.0836
2022-10-09 11:16:24 - train: epoch 0093, iter [01100, 01251], lr: 0.000029, loss: 2.7804
2022-10-09 11:16:45 - train: epoch 0093, iter [01110, 01251], lr: 0.000029, loss: 3.1906
2022-10-09 11:17:06 - train: epoch 0093, iter [01120, 01251], lr: 0.000028, loss: 3.1582
2022-10-09 11:17:28 - train: epoch 0093, iter [01130, 01251], lr: 0.000028, loss: 2.5899
2022-10-09 11:17:49 - train: epoch 0093, iter [01140, 01251], lr: 0.000028, loss: 3.2197
2022-10-09 11:18:10 - train: epoch 0093, iter [01150, 01251], lr: 0.000028, loss: 2.8714
2022-10-09 11:18:32 - train: epoch 0093, iter [01160, 01251], lr: 0.000028, loss: 3.1146
2022-10-09 11:18:53 - train: epoch 0093, iter [01170, 01251], lr: 0.000028, loss: 3.1116
2022-10-09 11:19:15 - train: epoch 0093, iter [01180, 01251], lr: 0.000028, loss: 2.2917
2022-10-09 11:19:36 - train: epoch 0093, iter [01190, 01251], lr: 0.000028, loss: 2.5678
2022-10-09 11:19:57 - train: epoch 0093, iter [01200, 01251], lr: 0.000028, loss: 2.6564
2022-10-09 11:20:19 - train: epoch 0093, iter [01210, 01251], lr: 0.000028, loss: 3.1089
2022-10-09 11:20:40 - train: epoch 0093, iter [01220, 01251], lr: 0.000028, loss: 2.8880
2022-10-09 11:21:02 - train: epoch 0093, iter [01230, 01251], lr: 0.000028, loss: 2.7696
2022-10-09 11:21:23 - train: epoch 0093, iter [01240, 01251], lr: 0.000028, loss: 2.7129
2022-10-09 11:21:44 - train: epoch 0093, iter [01250, 01251], lr: 0.000028, loss: 3.1855
2022-10-09 11:21:47 - train: epoch 093, train_loss: 2.7624
2022-10-09 11:23:04 - eval: epoch: 093, acc1: 83.088%, acc5: 96.554%, test_loss: 0.7501, per_image_load_time: 0.223ms, per_image_inference_time: 1.423ms
2022-10-09 11:23:05 - until epoch: 093, best_acc1: 83.110%
2022-10-09 11:23:05 - epoch 094 lr: 0.000028
2022-10-09 11:23:32 - train: epoch 0094, iter [00010, 01251], lr: 0.000028, loss: 2.4150
2022-10-09 11:23:54 - train: epoch 0094, iter [00020, 01251], lr: 0.000028, loss: 2.9904
2022-10-09 11:24:15 - train: epoch 0094, iter [00030, 01251], lr: 0.000027, loss: 2.8116
2022-10-09 11:24:36 - train: epoch 0094, iter [00040, 01251], lr: 0.000027, loss: 2.8602
2022-10-09 11:24:57 - train: epoch 0094, iter [00050, 01251], lr: 0.000027, loss: 2.3823
2022-10-09 11:25:19 - train: epoch 0094, iter [00060, 01251], lr: 0.000027, loss: 2.6612
2022-10-09 11:25:40 - train: epoch 0094, iter [00070, 01251], lr: 0.000027, loss: 3.0393
2022-10-09 11:26:01 - train: epoch 0094, iter [00080, 01251], lr: 0.000027, loss: 2.5018
2022-10-09 11:26:22 - train: epoch 0094, iter [00090, 01251], lr: 0.000027, loss: 2.8589
2022-10-09 11:26:44 - train: epoch 0094, iter [00100, 01251], lr: 0.000027, loss: 3.0042
2022-10-09 11:27:05 - train: epoch 0094, iter [00110, 01251], lr: 0.000027, loss: 2.2602
2022-10-09 11:27:26 - train: epoch 0094, iter [00120, 01251], lr: 0.000027, loss: 2.9703
2022-10-09 11:27:48 - train: epoch 0094, iter [00130, 01251], lr: 0.000027, loss: 3.0014
2022-10-09 11:28:09 - train: epoch 0094, iter [00140, 01251], lr: 0.000027, loss: 2.9983
2022-10-09 11:28:30 - train: epoch 0094, iter [00150, 01251], lr: 0.000027, loss: 2.8715
2022-10-09 11:28:51 - train: epoch 0094, iter [00160, 01251], lr: 0.000027, loss: 2.4689
2022-10-09 11:29:13 - train: epoch 0094, iter [00170, 01251], lr: 0.000027, loss: 3.0104
2022-10-09 11:29:34 - train: epoch 0094, iter [00180, 01251], lr: 0.000027, loss: 2.0475
2022-10-09 11:29:55 - train: epoch 0094, iter [00190, 01251], lr: 0.000027, loss: 2.3818
2022-10-09 11:30:17 - train: epoch 0094, iter [00200, 01251], lr: 0.000026, loss: 2.1478
2022-10-09 11:30:38 - train: epoch 0094, iter [00210, 01251], lr: 0.000026, loss: 3.0453
2022-10-09 11:30:59 - train: epoch 0094, iter [00220, 01251], lr: 0.000026, loss: 2.9000
2022-10-09 11:31:21 - train: epoch 0094, iter [00230, 01251], lr: 0.000026, loss: 2.9901
2022-10-09 11:31:42 - train: epoch 0094, iter [00240, 01251], lr: 0.000026, loss: 2.4483
2022-10-09 11:32:03 - train: epoch 0094, iter [00250, 01251], lr: 0.000026, loss: 3.0774
2022-10-09 11:32:25 - train: epoch 0094, iter [00260, 01251], lr: 0.000026, loss: 2.5701
2022-10-09 11:32:46 - train: epoch 0094, iter [00270, 01251], lr: 0.000026, loss: 2.7554
2022-10-09 11:33:07 - train: epoch 0094, iter [00280, 01251], lr: 0.000026, loss: 2.7047
2022-10-09 11:33:29 - train: epoch 0094, iter [00290, 01251], lr: 0.000026, loss: 2.3845
2022-10-09 11:33:50 - train: epoch 0094, iter [00300, 01251], lr: 0.000026, loss: 3.0407
2022-10-09 11:34:11 - train: epoch 0094, iter [00310, 01251], lr: 0.000026, loss: 3.1265
2022-10-09 11:34:33 - train: epoch 0094, iter [00320, 01251], lr: 0.000026, loss: 1.9791
2022-10-09 11:34:54 - train: epoch 0094, iter [00330, 01251], lr: 0.000026, loss: 2.8077
2022-10-09 11:35:16 - train: epoch 0094, iter [00340, 01251], lr: 0.000026, loss: 2.8912
2022-10-09 11:35:37 - train: epoch 0094, iter [00350, 01251], lr: 0.000026, loss: 2.3368
2022-10-09 11:35:58 - train: epoch 0094, iter [00360, 01251], lr: 0.000026, loss: 3.1618
2022-10-09 11:36:20 - train: epoch 0094, iter [00370, 01251], lr: 0.000025, loss: 2.9627
2022-10-09 11:36:41 - train: epoch 0094, iter [00380, 01251], lr: 0.000025, loss: 3.2132
2022-10-09 11:37:03 - train: epoch 0094, iter [00390, 01251], lr: 0.000025, loss: 2.4838
2022-10-09 11:37:24 - train: epoch 0094, iter [00400, 01251], lr: 0.000025, loss: 3.2546
2022-10-09 11:37:46 - train: epoch 0094, iter [00410, 01251], lr: 0.000025, loss: 2.0648
2022-10-09 11:38:07 - train: epoch 0094, iter [00420, 01251], lr: 0.000025, loss: 2.5507
2022-10-09 11:38:29 - train: epoch 0094, iter [00430, 01251], lr: 0.000025, loss: 3.1659
2022-10-09 11:38:50 - train: epoch 0094, iter [00440, 01251], lr: 0.000025, loss: 2.0955
2022-10-09 11:39:11 - train: epoch 0094, iter [00450, 01251], lr: 0.000025, loss: 3.1837
2022-10-09 11:39:33 - train: epoch 0094, iter [00460, 01251], lr: 0.000025, loss: 2.9936
2022-10-09 11:39:54 - train: epoch 0094, iter [00470, 01251], lr: 0.000025, loss: 2.6452
2022-10-09 11:40:15 - train: epoch 0094, iter [00480, 01251], lr: 0.000025, loss: 2.9264
2022-10-09 11:40:37 - train: epoch 0094, iter [00490, 01251], lr: 0.000025, loss: 2.3594
2022-10-09 11:40:58 - train: epoch 0094, iter [00500, 01251], lr: 0.000025, loss: 2.9359
2022-10-09 11:41:20 - train: epoch 0094, iter [00510, 01251], lr: 0.000025, loss: 2.9030
2022-10-09 11:41:41 - train: epoch 0094, iter [00520, 01251], lr: 0.000025, loss: 2.8795
2022-10-09 11:42:03 - train: epoch 0094, iter [00530, 01251], lr: 0.000025, loss: 2.9122
2022-10-09 11:42:24 - train: epoch 0094, iter [00540, 01251], lr: 0.000024, loss: 2.8607
2022-10-09 11:42:45 - train: epoch 0094, iter [00550, 01251], lr: 0.000024, loss: 3.0097
2022-10-09 11:43:07 - train: epoch 0094, iter [00560, 01251], lr: 0.000024, loss: 2.8540
2022-10-09 11:43:28 - train: epoch 0094, iter [00570, 01251], lr: 0.000024, loss: 3.1206
2022-10-09 11:43:50 - train: epoch 0094, iter [00580, 01251], lr: 0.000024, loss: 3.1194
2022-10-09 11:44:11 - train: epoch 0094, iter [00590, 01251], lr: 0.000024, loss: 2.9300
2022-10-09 11:44:33 - train: epoch 0094, iter [00600, 01251], lr: 0.000024, loss: 3.0944
2022-10-09 11:44:54 - train: epoch 0094, iter [00610, 01251], lr: 0.000024, loss: 2.8897
2022-10-09 11:45:15 - train: epoch 0094, iter [00620, 01251], lr: 0.000024, loss: 2.6290
2022-10-09 11:45:37 - train: epoch 0094, iter [00630, 01251], lr: 0.000024, loss: 2.8660
2022-10-09 11:45:58 - train: epoch 0094, iter [00640, 01251], lr: 0.000024, loss: 2.3528
2022-10-09 11:46:20 - train: epoch 0094, iter [00650, 01251], lr: 0.000024, loss: 2.7973
2022-10-09 11:46:41 - train: epoch 0094, iter [00660, 01251], lr: 0.000024, loss: 2.3960
2022-10-09 11:47:03 - train: epoch 0094, iter [00670, 01251], lr: 0.000024, loss: 3.0278
2022-10-09 11:47:24 - train: epoch 0094, iter [00680, 01251], lr: 0.000024, loss: 2.4669
2022-10-09 11:47:45 - train: epoch 0094, iter [00690, 01251], lr: 0.000024, loss: 3.1127
2022-10-09 11:48:07 - train: epoch 0094, iter [00700, 01251], lr: 0.000024, loss: 2.7900
2022-10-09 11:48:28 - train: epoch 0094, iter [00710, 01251], lr: 0.000024, loss: 2.8030
2022-10-09 11:48:50 - train: epoch 0094, iter [00720, 01251], lr: 0.000023, loss: 2.9047
2022-10-09 11:49:11 - train: epoch 0094, iter [00730, 01251], lr: 0.000023, loss: 2.9011
2022-10-09 11:49:32 - train: epoch 0094, iter [00740, 01251], lr: 0.000023, loss: 3.3083
2022-10-09 11:49:54 - train: epoch 0094, iter [00750, 01251], lr: 0.000023, loss: 2.3005
2022-10-09 11:50:15 - train: epoch 0094, iter [00760, 01251], lr: 0.000023, loss: 2.9067
2022-10-09 11:50:37 - train: epoch 0094, iter [00770, 01251], lr: 0.000023, loss: 3.1385
2022-10-09 11:50:58 - train: epoch 0094, iter [00780, 01251], lr: 0.000023, loss: 2.2152
2022-10-09 11:51:20 - train: epoch 0094, iter [00790, 01251], lr: 0.000023, loss: 2.4285
2022-10-09 11:51:41 - train: epoch 0094, iter [00800, 01251], lr: 0.000023, loss: 2.2551
2022-10-09 11:52:02 - train: epoch 0094, iter [00810, 01251], lr: 0.000023, loss: 2.7532
2022-10-09 11:52:24 - train: epoch 0094, iter [00820, 01251], lr: 0.000023, loss: 2.8074
2022-10-09 11:52:45 - train: epoch 0094, iter [00830, 01251], lr: 0.000023, loss: 2.6364
2022-10-09 11:53:07 - train: epoch 0094, iter [00840, 01251], lr: 0.000023, loss: 2.9506
2022-10-09 11:53:28 - train: epoch 0094, iter [00850, 01251], lr: 0.000023, loss: 2.9616
2022-10-09 11:53:50 - train: epoch 0094, iter [00860, 01251], lr: 0.000023, loss: 2.5992
2022-10-09 11:54:11 - train: epoch 0094, iter [00870, 01251], lr: 0.000023, loss: 3.1619
2022-10-09 11:54:32 - train: epoch 0094, iter [00880, 01251], lr: 0.000023, loss: 2.8243
2022-10-09 11:54:54 - train: epoch 0094, iter [00890, 01251], lr: 0.000023, loss: 2.4805
2022-10-09 11:55:15 - train: epoch 0094, iter [00900, 01251], lr: 0.000022, loss: 3.0295
2022-10-09 11:55:37 - train: epoch 0094, iter [00910, 01251], lr: 0.000022, loss: 3.3319
2022-10-09 11:55:58 - train: epoch 0094, iter [00920, 01251], lr: 0.000022, loss: 2.3714
2022-10-09 11:56:20 - train: epoch 0094, iter [00930, 01251], lr: 0.000022, loss: 2.9469
2022-10-09 11:56:41 - train: epoch 0094, iter [00940, 01251], lr: 0.000022, loss: 2.9780
2022-10-09 11:57:02 - train: epoch 0094, iter [00950, 01251], lr: 0.000022, loss: 3.1388
2022-10-09 11:57:24 - train: epoch 0094, iter [00960, 01251], lr: 0.000022, loss: 2.9903
2022-10-09 11:57:45 - train: epoch 0094, iter [00970, 01251], lr: 0.000022, loss: 2.7990
2022-10-09 11:58:06 - train: epoch 0094, iter [00980, 01251], lr: 0.000022, loss: 2.6698
2022-10-09 11:58:28 - train: epoch 0094, iter [00990, 01251], lr: 0.000022, loss: 2.7755
2022-10-09 11:58:49 - train: epoch 0094, iter [01000, 01251], lr: 0.000022, loss: 3.0976
2022-10-09 11:59:11 - train: epoch 0094, iter [01010, 01251], lr: 0.000022, loss: 2.3560
2022-10-09 11:59:32 - train: epoch 0094, iter [01020, 01251], lr: 0.000022, loss: 2.7950
2022-10-09 11:59:53 - train: epoch 0094, iter [01030, 01251], lr: 0.000022, loss: 2.7464
2022-10-09 12:00:15 - train: epoch 0094, iter [01040, 01251], lr: 0.000022, loss: 2.4135
2022-10-09 12:00:36 - train: epoch 0094, iter [01050, 01251], lr: 0.000022, loss: 3.0460
2022-10-09 12:00:57 - train: epoch 0094, iter [01060, 01251], lr: 0.000022, loss: 2.9463
2022-10-09 12:01:19 - train: epoch 0094, iter [01070, 01251], lr: 0.000022, loss: 2.0661
2022-10-09 12:01:40 - train: epoch 0094, iter [01080, 01251], lr: 0.000022, loss: 2.5332
2022-10-09 12:02:02 - train: epoch 0094, iter [01090, 01251], lr: 0.000021, loss: 3.2237
2022-10-09 12:02:23 - train: epoch 0094, iter [01100, 01251], lr: 0.000021, loss: 2.5569
2022-10-09 12:02:45 - train: epoch 0094, iter [01110, 01251], lr: 0.000021, loss: 3.0052
2022-10-09 12:03:06 - train: epoch 0094, iter [01120, 01251], lr: 0.000021, loss: 1.8853
2022-10-09 12:03:27 - train: epoch 0094, iter [01130, 01251], lr: 0.000021, loss: 2.5986
2022-10-09 12:03:49 - train: epoch 0094, iter [01140, 01251], lr: 0.000021, loss: 3.1753
2022-10-09 12:04:10 - train: epoch 0094, iter [01150, 01251], lr: 0.000021, loss: 2.6245
2022-10-09 12:04:31 - train: epoch 0094, iter [01160, 01251], lr: 0.000021, loss: 2.3724
2022-10-09 12:04:52 - train: epoch 0094, iter [01170, 01251], lr: 0.000021, loss: 2.7427
2022-10-09 12:05:14 - train: epoch 0094, iter [01180, 01251], lr: 0.000021, loss: 2.6773
2022-10-09 12:05:35 - train: epoch 0094, iter [01190, 01251], lr: 0.000021, loss: 2.5969
2022-10-09 12:05:56 - train: epoch 0094, iter [01200, 01251], lr: 0.000021, loss: 3.0964
2022-10-09 12:06:18 - train: epoch 0094, iter [01210, 01251], lr: 0.000021, loss: 2.8253
2022-10-09 12:06:39 - train: epoch 0094, iter [01220, 01251], lr: 0.000021, loss: 2.8069
2022-10-09 12:07:00 - train: epoch 0094, iter [01230, 01251], lr: 0.000021, loss: 2.9693
2022-10-09 12:07:22 - train: epoch 0094, iter [01240, 01251], lr: 0.000021, loss: 2.4262
2022-10-09 12:07:43 - train: epoch 0094, iter [01250, 01251], lr: 0.000021, loss: 2.2651
2022-10-09 12:07:47 - train: epoch 094, train_loss: 2.7534
2022-10-09 12:09:04 - eval: epoch: 094, acc1: 83.064%, acc5: 96.546%, test_loss: 0.7530, per_image_load_time: 0.215ms, per_image_inference_time: 1.429ms
2022-10-09 12:09:05 - until epoch: 094, best_acc1: 83.110%
2022-10-09 12:09:05 - epoch 095 lr: 0.000021
2022-10-09 12:09:33 - train: epoch 0095, iter [00010, 01251], lr: 0.000021, loss: 2.6446
2022-10-09 12:09:55 - train: epoch 0095, iter [00020, 01251], lr: 0.000021, loss: 2.5807
2022-10-09 12:10:16 - train: epoch 0095, iter [00030, 01251], lr: 0.000020, loss: 2.5542
2022-10-09 12:10:37 - train: epoch 0095, iter [00040, 01251], lr: 0.000020, loss: 2.5695
2022-10-09 12:10:58 - train: epoch 0095, iter [00050, 01251], lr: 0.000020, loss: 2.8383
2022-10-09 12:11:20 - train: epoch 0095, iter [00060, 01251], lr: 0.000020, loss: 2.7485
2022-10-09 12:11:41 - train: epoch 0095, iter [00070, 01251], lr: 0.000020, loss: 2.1365
2022-10-09 12:12:02 - train: epoch 0095, iter [00080, 01251], lr: 0.000020, loss: 2.8671
2022-10-09 12:12:23 - train: epoch 0095, iter [00090, 01251], lr: 0.000020, loss: 2.3593
2022-10-09 12:12:45 - train: epoch 0095, iter [00100, 01251], lr: 0.000020, loss: 3.0462
2022-10-09 12:13:06 - train: epoch 0095, iter [00110, 01251], lr: 0.000020, loss: 2.8102
2022-10-09 12:13:27 - train: epoch 0095, iter [00120, 01251], lr: 0.000020, loss: 3.0347
2022-10-09 12:13:49 - train: epoch 0095, iter [00130, 01251], lr: 0.000020, loss: 2.6325
2022-10-09 12:14:10 - train: epoch 0095, iter [00140, 01251], lr: 0.000020, loss: 2.3206
2022-10-09 12:14:31 - train: epoch 0095, iter [00150, 01251], lr: 0.000020, loss: 3.1670
2022-10-09 12:14:52 - train: epoch 0095, iter [00160, 01251], lr: 0.000020, loss: 3.1146
2022-10-09 12:15:14 - train: epoch 0095, iter [00170, 01251], lr: 0.000020, loss: 3.2384
2022-10-09 12:15:35 - train: epoch 0095, iter [00180, 01251], lr: 0.000020, loss: 2.4688
2022-10-09 12:15:56 - train: epoch 0095, iter [00190, 01251], lr: 0.000020, loss: 2.6791
2022-10-09 12:16:17 - train: epoch 0095, iter [00200, 01251], lr: 0.000020, loss: 2.5911
2022-10-09 12:16:39 - train: epoch 0095, iter [00210, 01251], lr: 0.000020, loss: 2.2499
2022-10-09 12:17:00 - train: epoch 0095, iter [00220, 01251], lr: 0.000019, loss: 2.4614
2022-10-09 12:17:21 - train: epoch 0095, iter [00230, 01251], lr: 0.000019, loss: 2.8524
2022-10-09 12:17:42 - train: epoch 0095, iter [00240, 01251], lr: 0.000019, loss: 2.6288
2022-10-09 12:18:04 - train: epoch 0095, iter [00250, 01251], lr: 0.000019, loss: 2.8303
2022-10-09 12:18:25 - train: epoch 0095, iter [00260, 01251], lr: 0.000019, loss: 2.7637
2022-10-09 12:18:46 - train: epoch 0095, iter [00270, 01251], lr: 0.000019, loss: 2.6407
2022-10-09 12:19:08 - train: epoch 0095, iter [00280, 01251], lr: 0.000019, loss: 2.8074
2022-10-09 12:19:29 - train: epoch 0095, iter [00290, 01251], lr: 0.000019, loss: 3.1043
2022-10-09 12:19:50 - train: epoch 0095, iter [00300, 01251], lr: 0.000019, loss: 3.1753
2022-10-09 12:20:11 - train: epoch 0095, iter [00310, 01251], lr: 0.000019, loss: 2.9827
2022-10-09 12:20:32 - train: epoch 0095, iter [00320, 01251], lr: 0.000019, loss: 2.8484
2022-10-09 12:20:54 - train: epoch 0095, iter [00330, 01251], lr: 0.000019, loss: 2.9688
2022-10-09 12:21:15 - train: epoch 0095, iter [00340, 01251], lr: 0.000019, loss: 3.0492
2022-10-09 12:21:36 - train: epoch 0095, iter [00350, 01251], lr: 0.000019, loss: 2.1350
2022-10-09 12:21:57 - train: epoch 0095, iter [00360, 01251], lr: 0.000019, loss: 2.9431
2022-10-09 12:22:19 - train: epoch 0095, iter [00370, 01251], lr: 0.000019, loss: 3.0644
2022-10-09 12:22:40 - train: epoch 0095, iter [00380, 01251], lr: 0.000019, loss: 2.6543
2022-10-09 12:23:01 - train: epoch 0095, iter [00390, 01251], lr: 0.000019, loss: 2.5144
2022-10-09 12:23:22 - train: epoch 0095, iter [00400, 01251], lr: 0.000019, loss: 2.7547
2022-10-09 12:23:44 - train: epoch 0095, iter [00410, 01251], lr: 0.000019, loss: 2.7129
2022-10-09 12:24:05 - train: epoch 0095, iter [00420, 01251], lr: 0.000018, loss: 3.0438
2022-10-09 12:24:26 - train: epoch 0095, iter [00430, 01251], lr: 0.000018, loss: 2.1258
2022-10-09 12:24:47 - train: epoch 0095, iter [00440, 01251], lr: 0.000018, loss: 2.9553
2022-10-09 12:25:08 - train: epoch 0095, iter [00450, 01251], lr: 0.000018, loss: 3.0894
2022-10-09 12:25:30 - train: epoch 0095, iter [00460, 01251], lr: 0.000018, loss: 3.4066
2022-10-09 12:25:51 - train: epoch 0095, iter [00470, 01251], lr: 0.000018, loss: 2.7715
2022-10-09 12:26:12 - train: epoch 0095, iter [00480, 01251], lr: 0.000018, loss: 2.8458
2022-10-09 12:26:33 - train: epoch 0095, iter [00490, 01251], lr: 0.000018, loss: 2.5470
2022-10-09 12:26:54 - train: epoch 0095, iter [00500, 01251], lr: 0.000018, loss: 3.0410
2022-10-09 12:27:16 - train: epoch 0095, iter [00510, 01251], lr: 0.000018, loss: 3.0771
2022-10-09 12:27:37 - train: epoch 0095, iter [00520, 01251], lr: 0.000018, loss: 2.3887
2022-10-09 12:27:58 - train: epoch 0095, iter [00530, 01251], lr: 0.000018, loss: 2.4958
2022-10-09 12:28:19 - train: epoch 0095, iter [00540, 01251], lr: 0.000018, loss: 2.9990
2022-10-09 12:28:41 - train: epoch 0095, iter [00550, 01251], lr: 0.000018, loss: 2.8466
2022-10-09 12:29:02 - train: epoch 0095, iter [00560, 01251], lr: 0.000018, loss: 3.0708
2022-10-09 12:29:23 - train: epoch 0095, iter [00570, 01251], lr: 0.000018, loss: 2.1830
2022-10-09 12:29:44 - train: epoch 0095, iter [00580, 01251], lr: 0.000018, loss: 3.0797
2022-10-09 12:30:05 - train: epoch 0095, iter [00590, 01251], lr: 0.000018, loss: 2.5184
2022-10-09 12:30:27 - train: epoch 0095, iter [00600, 01251], lr: 0.000018, loss: 2.5643
2022-10-09 12:30:48 - train: epoch 0095, iter [00610, 01251], lr: 0.000018, loss: 3.1464
2022-10-09 12:31:09 - train: epoch 0095, iter [00620, 01251], lr: 0.000018, loss: 2.3346
2022-10-09 12:31:30 - train: epoch 0095, iter [00630, 01251], lr: 0.000017, loss: 2.9248
2022-10-09 12:31:52 - train: epoch 0095, iter [00640, 01251], lr: 0.000017, loss: 2.8287
2022-10-09 12:32:13 - train: epoch 0095, iter [00650, 01251], lr: 0.000017, loss: 2.1484
2022-10-09 12:32:34 - train: epoch 0095, iter [00660, 01251], lr: 0.000017, loss: 2.8850
2022-10-09 12:32:55 - train: epoch 0095, iter [00670, 01251], lr: 0.000017, loss: 2.2980
2022-10-09 12:33:17 - train: epoch 0095, iter [00680, 01251], lr: 0.000017, loss: 2.2673
2022-10-09 12:33:38 - train: epoch 0095, iter [00690, 01251], lr: 0.000017, loss: 3.0699
2022-10-09 12:33:59 - train: epoch 0095, iter [00700, 01251], lr: 0.000017, loss: 2.8007
2022-10-09 12:34:20 - train: epoch 0095, iter [00710, 01251], lr: 0.000017, loss: 2.9397
2022-10-09 12:34:41 - train: epoch 0095, iter [00720, 01251], lr: 0.000017, loss: 3.0610
2022-10-09 12:35:03 - train: epoch 0095, iter [00730, 01251], lr: 0.000017, loss: 3.3342
2022-10-09 12:35:24 - train: epoch 0095, iter [00740, 01251], lr: 0.000017, loss: 3.1676
2022-10-09 12:35:45 - train: epoch 0095, iter [00750, 01251], lr: 0.000017, loss: 2.9281
2022-10-09 12:36:06 - train: epoch 0095, iter [00760, 01251], lr: 0.000017, loss: 2.6991
2022-10-09 12:36:28 - train: epoch 0095, iter [00770, 01251], lr: 0.000017, loss: 3.1644
2022-10-09 12:36:49 - train: epoch 0095, iter [00780, 01251], lr: 0.000017, loss: 3.0503
2022-10-09 12:37:10 - train: epoch 0095, iter [00790, 01251], lr: 0.000017, loss: 2.5018
2022-10-09 12:37:32 - train: epoch 0095, iter [00800, 01251], lr: 0.000017, loss: 2.7417
2022-10-09 12:37:53 - train: epoch 0095, iter [00810, 01251], lr: 0.000017, loss: 2.8948
2022-10-09 12:38:14 - train: epoch 0095, iter [00820, 01251], lr: 0.000017, loss: 2.5168
2022-10-09 12:38:35 - train: epoch 0095, iter [00830, 01251], lr: 0.000017, loss: 2.9966
2022-10-09 12:38:56 - train: epoch 0095, iter [00840, 01251], lr: 0.000016, loss: 3.0226
2022-10-09 12:39:18 - train: epoch 0095, iter [00850, 01251], lr: 0.000016, loss: 2.3794
2022-10-09 12:39:39 - train: epoch 0095, iter [00860, 01251], lr: 0.000016, loss: 2.1551
2022-10-09 12:40:00 - train: epoch 0095, iter [00870, 01251], lr: 0.000016, loss: 2.8167
2022-10-09 12:40:21 - train: epoch 0095, iter [00880, 01251], lr: 0.000016, loss: 2.8448
2022-10-09 12:40:43 - train: epoch 0095, iter [00890, 01251], lr: 0.000016, loss: 3.1984
2022-10-09 12:41:04 - train: epoch 0095, iter [00900, 01251], lr: 0.000016, loss: 2.6350
2022-10-09 12:41:25 - train: epoch 0095, iter [00910, 01251], lr: 0.000016, loss: 2.3977
2022-10-09 12:41:47 - train: epoch 0095, iter [00920, 01251], lr: 0.000016, loss: 2.5674
2022-10-09 12:42:08 - train: epoch 0095, iter [00930, 01251], lr: 0.000016, loss: 2.5375
2022-10-09 12:42:29 - train: epoch 0095, iter [00940, 01251], lr: 0.000016, loss: 2.5927
2022-10-09 12:42:50 - train: epoch 0095, iter [00950, 01251], lr: 0.000016, loss: 2.9227
2022-10-09 12:43:12 - train: epoch 0095, iter [00960, 01251], lr: 0.000016, loss: 2.5871
2022-10-09 12:43:33 - train: epoch 0095, iter [00970, 01251], lr: 0.000016, loss: 2.5354
2022-10-09 12:43:54 - train: epoch 0095, iter [00980, 01251], lr: 0.000016, loss: 3.2604
2022-10-09 12:44:15 - train: epoch 0095, iter [00990, 01251], lr: 0.000016, loss: 2.5468
2022-10-09 12:44:37 - train: epoch 0095, iter [01000, 01251], lr: 0.000016, loss: 2.6355
2022-10-09 12:44:58 - train: epoch 0095, iter [01010, 01251], lr: 0.000016, loss: 2.2097
2022-10-09 12:45:19 - train: epoch 0095, iter [01020, 01251], lr: 0.000016, loss: 2.7484
2022-10-09 12:45:40 - train: epoch 0095, iter [01030, 01251], lr: 0.000016, loss: 2.3859
2022-10-09 12:46:02 - train: epoch 0095, iter [01040, 01251], lr: 0.000016, loss: 3.1015
2022-10-09 12:46:23 - train: epoch 0095, iter [01050, 01251], lr: 0.000016, loss: 3.0182
2022-10-09 12:46:44 - train: epoch 0095, iter [01060, 01251], lr: 0.000015, loss: 2.3006
2022-10-09 12:47:06 - train: epoch 0095, iter [01070, 01251], lr: 0.000015, loss: 3.0575
2022-10-09 12:47:27 - train: epoch 0095, iter [01080, 01251], lr: 0.000015, loss: 3.0286
2022-10-09 12:47:48 - train: epoch 0095, iter [01090, 01251], lr: 0.000015, loss: 2.0000
2022-10-09 12:48:09 - train: epoch 0095, iter [01100, 01251], lr: 0.000015, loss: 2.9037
2022-10-09 12:48:30 - train: epoch 0095, iter [01110, 01251], lr: 0.000015, loss: 3.1080
2022-10-09 12:48:52 - train: epoch 0095, iter [01120, 01251], lr: 0.000015, loss: 2.3943
2022-10-09 12:49:13 - train: epoch 0095, iter [01130, 01251], lr: 0.000015, loss: 2.7092
2022-10-09 12:49:34 - train: epoch 0095, iter [01140, 01251], lr: 0.000015, loss: 2.8884
2022-10-09 12:49:56 - train: epoch 0095, iter [01150, 01251], lr: 0.000015, loss: 3.0624
2022-10-09 12:50:17 - train: epoch 0095, iter [01160, 01251], lr: 0.000015, loss: 3.1670
2022-10-09 12:50:38 - train: epoch 0095, iter [01170, 01251], lr: 0.000015, loss: 2.5280
2022-10-09 12:51:00 - train: epoch 0095, iter [01180, 01251], lr: 0.000015, loss: 3.3398
2022-10-09 12:51:21 - train: epoch 0095, iter [01190, 01251], lr: 0.000015, loss: 3.0073
2022-10-09 12:51:42 - train: epoch 0095, iter [01200, 01251], lr: 0.000015, loss: 2.8231
2022-10-09 12:52:03 - train: epoch 0095, iter [01210, 01251], lr: 0.000015, loss: 2.9961
2022-10-09 12:52:25 - train: epoch 0095, iter [01220, 01251], lr: 0.000015, loss: 3.1616
2022-10-09 12:52:46 - train: epoch 0095, iter [01230, 01251], lr: 0.000015, loss: 2.5453
2022-10-09 12:53:07 - train: epoch 0095, iter [01240, 01251], lr: 0.000015, loss: 3.0168
2022-10-09 12:53:28 - train: epoch 0095, iter [01250, 01251], lr: 0.000015, loss: 2.6307
2022-10-09 12:53:32 - train: epoch 095, train_loss: 2.7626
2022-10-09 12:54:49 - eval: epoch: 095, acc1: 83.094%, acc5: 96.524%, test_loss: 0.7519, per_image_load_time: 0.961ms, per_image_inference_time: 1.439ms
2022-10-09 12:54:51 - until epoch: 095, best_acc1: 83.110%
2022-10-09 12:54:51 - epoch 096 lr: 0.000015
2022-10-09 12:55:18 - train: epoch 0096, iter [00010, 01251], lr: 0.000015, loss: 2.5652
2022-10-09 12:55:39 - train: epoch 0096, iter [00020, 01251], lr: 0.000015, loss: 2.9076
2022-10-09 12:56:00 - train: epoch 0096, iter [00030, 01251], lr: 0.000015, loss: 2.3985
2022-10-09 12:56:21 - train: epoch 0096, iter [00040, 01251], lr: 0.000014, loss: 2.7673
2022-10-09 12:56:43 - train: epoch 0096, iter [00050, 01251], lr: 0.000014, loss: 2.5474
2022-10-09 12:57:04 - train: epoch 0096, iter [00060, 01251], lr: 0.000014, loss: 2.4328
2022-10-09 12:57:25 - train: epoch 0096, iter [00070, 01251], lr: 0.000014, loss: 3.1708
2022-10-09 12:57:46 - train: epoch 0096, iter [00080, 01251], lr: 0.000014, loss: 2.9243
2022-10-09 12:58:08 - train: epoch 0096, iter [00090, 01251], lr: 0.000014, loss: 2.6476
2022-10-09 12:58:29 - train: epoch 0096, iter [00100, 01251], lr: 0.000014, loss: 2.6656
2022-10-09 12:58:50 - train: epoch 0096, iter [00110, 01251], lr: 0.000014, loss: 2.3946
2022-10-09 12:59:11 - train: epoch 0096, iter [00120, 01251], lr: 0.000014, loss: 2.8746
2022-10-09 12:59:32 - train: epoch 0096, iter [00130, 01251], lr: 0.000014, loss: 2.7934
2022-10-09 12:59:54 - train: epoch 0096, iter [00140, 01251], lr: 0.000014, loss: 2.9422
2022-10-09 13:00:15 - train: epoch 0096, iter [00150, 01251], lr: 0.000014, loss: 3.1597
2022-10-09 13:00:36 - train: epoch 0096, iter [00160, 01251], lr: 0.000014, loss: 3.0628
2022-10-09 13:00:57 - train: epoch 0096, iter [00170, 01251], lr: 0.000014, loss: 3.0460
2022-10-09 13:01:18 - train: epoch 0096, iter [00180, 01251], lr: 0.000014, loss: 2.3380
2022-10-09 13:01:40 - train: epoch 0096, iter [00190, 01251], lr: 0.000014, loss: 2.1348
2022-10-09 13:02:01 - train: epoch 0096, iter [00200, 01251], lr: 0.000014, loss: 3.0782
2022-10-09 13:02:22 - train: epoch 0096, iter [00210, 01251], lr: 0.000014, loss: 2.5546
2022-10-09 13:02:43 - train: epoch 0096, iter [00220, 01251], lr: 0.000014, loss: 3.0417
2022-10-09 13:03:04 - train: epoch 0096, iter [00230, 01251], lr: 0.000014, loss: 2.7666
2022-10-09 13:03:25 - train: epoch 0096, iter [00240, 01251], lr: 0.000014, loss: 2.5229
2022-10-09 13:03:46 - train: epoch 0096, iter [00250, 01251], lr: 0.000014, loss: 2.9463
2022-10-09 13:04:07 - train: epoch 0096, iter [00260, 01251], lr: 0.000014, loss: 2.4878
2022-10-09 13:04:29 - train: epoch 0096, iter [00270, 01251], lr: 0.000013, loss: 3.0612
2022-10-09 13:04:50 - train: epoch 0096, iter [00280, 01251], lr: 0.000013, loss: 2.2843
2022-10-09 13:05:11 - train: epoch 0096, iter [00290, 01251], lr: 0.000013, loss: 2.7256
2022-10-09 13:05:32 - train: epoch 0096, iter [00300, 01251], lr: 0.000013, loss: 2.9789
2022-10-09 13:05:53 - train: epoch 0096, iter [00310, 01251], lr: 0.000013, loss: 3.0053
2022-10-09 13:06:14 - train: epoch 0096, iter [00320, 01251], lr: 0.000013, loss: 2.3951
2022-10-09 13:06:36 - train: epoch 0096, iter [00330, 01251], lr: 0.000013, loss: 2.5049
2022-10-09 13:06:57 - train: epoch 0096, iter [00340, 01251], lr: 0.000013, loss: 3.1353
2022-10-09 13:07:18 - train: epoch 0096, iter [00350, 01251], lr: 0.000013, loss: 3.1555
2022-10-09 13:07:39 - train: epoch 0096, iter [00360, 01251], lr: 0.000013, loss: 2.6920
2022-10-09 13:08:00 - train: epoch 0096, iter [00370, 01251], lr: 0.000013, loss: 3.2137
2022-10-09 13:08:21 - train: epoch 0096, iter [00380, 01251], lr: 0.000013, loss: 3.1692
2022-10-09 13:08:43 - train: epoch 0096, iter [00390, 01251], lr: 0.000013, loss: 2.5478
2022-10-09 13:09:04 - train: epoch 0096, iter [00400, 01251], lr: 0.000013, loss: 2.7892
2022-10-09 13:09:25 - train: epoch 0096, iter [00410, 01251], lr: 0.000013, loss: 2.7529
2022-10-09 13:09:46 - train: epoch 0096, iter [00420, 01251], lr: 0.000013, loss: 2.7410
2022-10-09 13:10:07 - train: epoch 0096, iter [00430, 01251], lr: 0.000013, loss: 3.3522
2022-10-09 13:10:28 - train: epoch 0096, iter [00440, 01251], lr: 0.000013, loss: 2.5309
2022-10-09 13:10:49 - train: epoch 0096, iter [00450, 01251], lr: 0.000013, loss: 2.9955
2022-10-09 13:11:10 - train: epoch 0096, iter [00460, 01251], lr: 0.000013, loss: 3.0948
2022-10-09 13:11:31 - train: epoch 0096, iter [00470, 01251], lr: 0.000013, loss: 2.5628
2022-10-09 13:11:53 - train: epoch 0096, iter [00480, 01251], lr: 0.000013, loss: 2.5617
2022-10-09 13:12:14 - train: epoch 0096, iter [00490, 01251], lr: 0.000013, loss: 3.1610
2022-10-09 13:12:35 - train: epoch 0096, iter [00500, 01251], lr: 0.000013, loss: 2.8599
2022-10-09 13:12:56 - train: epoch 0096, iter [00510, 01251], lr: 0.000013, loss: 2.9149
2022-10-09 13:13:17 - train: epoch 0096, iter [00520, 01251], lr: 0.000012, loss: 2.6201
2022-10-09 13:13:38 - train: epoch 0096, iter [00530, 01251], lr: 0.000012, loss: 3.1636
2022-10-09 13:14:00 - train: epoch 0096, iter [00540, 01251], lr: 0.000012, loss: 3.0033
2022-10-09 13:14:21 - train: epoch 0096, iter [00550, 01251], lr: 0.000012, loss: 2.6268
2022-10-09 13:14:42 - train: epoch 0096, iter [00560, 01251], lr: 0.000012, loss: 2.5217
2022-10-09 13:15:03 - train: epoch 0096, iter [00570, 01251], lr: 0.000012, loss: 2.9741
2022-10-09 13:15:24 - train: epoch 0096, iter [00580, 01251], lr: 0.000012, loss: 2.3839
2022-10-09 13:15:45 - train: epoch 0096, iter [00590, 01251], lr: 0.000012, loss: 2.3870
2022-10-09 13:16:06 - train: epoch 0096, iter [00600, 01251], lr: 0.000012, loss: 1.8695
2022-10-09 13:16:27 - train: epoch 0096, iter [00610, 01251], lr: 0.000012, loss: 2.5837
2022-10-09 13:16:48 - train: epoch 0096, iter [00620, 01251], lr: 0.000012, loss: 2.8109
2022-10-09 13:17:10 - train: epoch 0096, iter [00630, 01251], lr: 0.000012, loss: 2.6383
2022-10-09 13:17:31 - train: epoch 0096, iter [00640, 01251], lr: 0.000012, loss: 2.9870
2022-10-09 13:17:52 - train: epoch 0096, iter [00650, 01251], lr: 0.000012, loss: 3.0098
2022-10-09 13:18:13 - train: epoch 0096, iter [00660, 01251], lr: 0.000012, loss: 2.8331
2022-10-09 13:18:34 - train: epoch 0096, iter [00670, 01251], lr: 0.000012, loss: 3.0355
2022-10-09 13:18:55 - train: epoch 0096, iter [00680, 01251], lr: 0.000012, loss: 2.7497
2022-10-09 13:19:16 - train: epoch 0096, iter [00690, 01251], lr: 0.000012, loss: 2.2570
2022-10-09 13:19:38 - train: epoch 0096, iter [00700, 01251], lr: 0.000012, loss: 2.4153
2022-10-09 13:19:59 - train: epoch 0096, iter [00710, 01251], lr: 0.000012, loss: 2.7927
2022-10-09 13:20:20 - train: epoch 0096, iter [00720, 01251], lr: 0.000012, loss: 2.7574
2022-10-09 13:20:41 - train: epoch 0096, iter [00730, 01251], lr: 0.000012, loss: 2.9775
2022-10-09 13:21:02 - train: epoch 0096, iter [00740, 01251], lr: 0.000012, loss: 2.4511
2022-10-09 13:21:23 - train: epoch 0096, iter [00750, 01251], lr: 0.000012, loss: 3.1647
2022-10-09 13:21:44 - train: epoch 0096, iter [00760, 01251], lr: 0.000012, loss: 2.8076
2022-10-09 13:22:05 - train: epoch 0096, iter [00770, 01251], lr: 0.000011, loss: 2.7771
2022-10-09 13:22:26 - train: epoch 0096, iter [00780, 01251], lr: 0.000011, loss: 2.5637
2022-10-09 13:22:47 - train: epoch 0096, iter [00790, 01251], lr: 0.000011, loss: 2.6412
2022-10-09 13:23:08 - train: epoch 0096, iter [00800, 01251], lr: 0.000011, loss: 2.4370
2022-10-09 13:23:30 - train: epoch 0096, iter [00810, 01251], lr: 0.000011, loss: 2.3971
2022-10-09 13:23:51 - train: epoch 0096, iter [00820, 01251], lr: 0.000011, loss: 2.4045
2022-10-09 13:24:12 - train: epoch 0096, iter [00830, 01251], lr: 0.000011, loss: 2.5949
2022-10-09 13:24:33 - train: epoch 0096, iter [00840, 01251], lr: 0.000011, loss: 2.3700
2022-10-09 13:24:54 - train: epoch 0096, iter [00850, 01251], lr: 0.000011, loss: 2.3117
2022-10-09 13:25:15 - train: epoch 0096, iter [00860, 01251], lr: 0.000011, loss: 2.8294
2022-10-09 13:25:37 - train: epoch 0096, iter [00870, 01251], lr: 0.000011, loss: 2.5438
2022-10-09 13:25:58 - train: epoch 0096, iter [00880, 01251], lr: 0.000011, loss: 2.8120
2022-10-09 13:26:19 - train: epoch 0096, iter [00890, 01251], lr: 0.000011, loss: 2.7112
2022-10-09 13:26:40 - train: epoch 0096, iter [00900, 01251], lr: 0.000011, loss: 2.5824
2022-10-09 13:27:01 - train: epoch 0096, iter [00910, 01251], lr: 0.000011, loss: 2.9130
2022-10-09 13:27:22 - train: epoch 0096, iter [00920, 01251], lr: 0.000011, loss: 2.5536
2022-10-09 13:27:43 - train: epoch 0096, iter [00930, 01251], lr: 0.000011, loss: 2.8888
2022-10-09 13:28:04 - train: epoch 0096, iter [00940, 01251], lr: 0.000011, loss: 2.6207
2022-10-09 13:28:26 - train: epoch 0096, iter [00950, 01251], lr: 0.000011, loss: 2.6308
2022-10-09 13:28:47 - train: epoch 0096, iter [00960, 01251], lr: 0.000011, loss: 2.7673
2022-10-09 13:29:08 - train: epoch 0096, iter [00970, 01251], lr: 0.000011, loss: 2.6773
2022-10-09 13:29:29 - train: epoch 0096, iter [00980, 01251], lr: 0.000011, loss: 3.0260
2022-10-09 13:29:50 - train: epoch 0096, iter [00990, 01251], lr: 0.000011, loss: 2.9196
2022-10-09 13:30:11 - train: epoch 0096, iter [01000, 01251], lr: 0.000011, loss: 3.1227
2022-10-09 13:30:32 - train: epoch 0096, iter [01010, 01251], lr: 0.000011, loss: 2.9240
2022-10-09 13:30:53 - train: epoch 0096, iter [01020, 01251], lr: 0.000011, loss: 2.9895
2022-10-09 13:31:15 - train: epoch 0096, iter [01030, 01251], lr: 0.000011, loss: 2.9055
2022-10-09 13:31:36 - train: epoch 0096, iter [01040, 01251], lr: 0.000010, loss: 2.6463
2022-10-09 13:31:57 - train: epoch 0096, iter [01050, 01251], lr: 0.000010, loss: 3.1390
2022-10-09 13:32:18 - train: epoch 0096, iter [01060, 01251], lr: 0.000010, loss: 1.9824
2022-10-09 13:32:39 - train: epoch 0096, iter [01070, 01251], lr: 0.000010, loss: 2.1368
2022-10-09 13:33:00 - train: epoch 0096, iter [01080, 01251], lr: 0.000010, loss: 2.8530
2022-10-09 13:33:21 - train: epoch 0096, iter [01090, 01251], lr: 0.000010, loss: 2.7729
2022-10-09 13:33:42 - train: epoch 0096, iter [01100, 01251], lr: 0.000010, loss: 2.7604
2022-10-09 13:34:04 - train: epoch 0096, iter [01110, 01251], lr: 0.000010, loss: 2.8669
2022-10-09 13:34:25 - train: epoch 0096, iter [01120, 01251], lr: 0.000010, loss: 2.9924
2022-10-09 13:34:46 - train: epoch 0096, iter [01130, 01251], lr: 0.000010, loss: 2.7838
2022-10-09 13:35:07 - train: epoch 0096, iter [01140, 01251], lr: 0.000010, loss: 2.8710
2022-10-09 13:35:28 - train: epoch 0096, iter [01150, 01251], lr: 0.000010, loss: 2.3255
2022-10-09 13:35:49 - train: epoch 0096, iter [01160, 01251], lr: 0.000010, loss: 2.5230
2022-10-09 13:36:10 - train: epoch 0096, iter [01170, 01251], lr: 0.000010, loss: 2.6287
2022-10-09 13:36:31 - train: epoch 0096, iter [01180, 01251], lr: 0.000010, loss: 2.1018
2022-10-09 13:36:52 - train: epoch 0096, iter [01190, 01251], lr: 0.000010, loss: 2.8282
2022-10-09 13:37:13 - train: epoch 0096, iter [01200, 01251], lr: 0.000010, loss: 2.6044
2022-10-09 13:37:35 - train: epoch 0096, iter [01210, 01251], lr: 0.000010, loss: 2.5671
2022-10-09 13:37:56 - train: epoch 0096, iter [01220, 01251], lr: 0.000010, loss: 3.2008
2022-10-09 13:38:17 - train: epoch 0096, iter [01230, 01251], lr: 0.000010, loss: 3.2305
2022-10-09 13:38:38 - train: epoch 0096, iter [01240, 01251], lr: 0.000010, loss: 2.4295
2022-10-09 13:38:59 - train: epoch 0096, iter [01250, 01251], lr: 0.000010, loss: 3.0695
2022-10-09 13:39:03 - train: epoch 096, train_loss: 2.7605
2022-10-09 13:40:18 - eval: epoch: 096, acc1: 83.120%, acc5: 96.558%, test_loss: 0.7516, per_image_load_time: 0.369ms, per_image_inference_time: 1.434ms
2022-10-09 13:40:20 - until epoch: 096, best_acc1: 83.120%
2022-10-09 13:40:20 - epoch 097 lr: 0.000010
2022-10-09 13:40:48 - train: epoch 0097, iter [00010, 01251], lr: 0.000010, loss: 2.6855
2022-10-09 13:41:09 - train: epoch 0097, iter [00020, 01251], lr: 0.000010, loss: 2.9215
2022-10-09 13:41:30 - train: epoch 0097, iter [00030, 01251], lr: 0.000010, loss: 2.5366
2022-10-09 13:41:51 - train: epoch 0097, iter [00040, 01251], lr: 0.000010, loss: 3.0737
2022-10-09 13:42:13 - train: epoch 0097, iter [00050, 01251], lr: 0.000010, loss: 3.3140
2022-10-09 13:42:34 - train: epoch 0097, iter [00060, 01251], lr: 0.000010, loss: 3.1993
2022-10-09 13:42:55 - train: epoch 0097, iter [00070, 01251], lr: 0.000009, loss: 2.6951
2022-10-09 13:43:17 - train: epoch 0097, iter [00080, 01251], lr: 0.000009, loss: 2.4853
2022-10-09 13:43:38 - train: epoch 0097, iter [00090, 01251], lr: 0.000009, loss: 2.5956
2022-10-09 13:43:59 - train: epoch 0097, iter [00100, 01251], lr: 0.000009, loss: 2.5342
2022-10-09 13:44:21 - train: epoch 0097, iter [00110, 01251], lr: 0.000009, loss: 2.6537
2022-10-09 13:44:42 - train: epoch 0097, iter [00120, 01251], lr: 0.000009, loss: 2.5547
2022-10-09 13:45:03 - train: epoch 0097, iter [00130, 01251], lr: 0.000009, loss: 3.2176
2022-10-09 13:45:24 - train: epoch 0097, iter [00140, 01251], lr: 0.000009, loss: 2.9499
2022-10-09 13:45:45 - train: epoch 0097, iter [00150, 01251], lr: 0.000009, loss: 2.7227
2022-10-09 13:46:07 - train: epoch 0097, iter [00160, 01251], lr: 0.000009, loss: 2.4603
2022-10-09 13:46:28 - train: epoch 0097, iter [00170, 01251], lr: 0.000009, loss: 3.0129
2022-10-09 13:46:49 - train: epoch 0097, iter [00180, 01251], lr: 0.000009, loss: 3.0733
2022-10-09 13:47:10 - train: epoch 0097, iter [00190, 01251], lr: 0.000009, loss: 2.6327
2022-10-09 13:47:32 - train: epoch 0097, iter [00200, 01251], lr: 0.000009, loss: 2.7931
2022-10-09 13:47:53 - train: epoch 0097, iter [00210, 01251], lr: 0.000009, loss: 2.7719
2022-10-09 13:48:14 - train: epoch 0097, iter [00220, 01251], lr: 0.000009, loss: 2.8884
2022-10-09 13:48:36 - train: epoch 0097, iter [00230, 01251], lr: 0.000009, loss: 2.9319
2022-10-09 13:48:57 - train: epoch 0097, iter [00240, 01251], lr: 0.000009, loss: 2.8148
2022-10-09 13:49:18 - train: epoch 0097, iter [00250, 01251], lr: 0.000009, loss: 3.0691
2022-10-09 13:49:39 - train: epoch 0097, iter [00260, 01251], lr: 0.000009, loss: 3.1998
2022-10-09 13:50:00 - train: epoch 0097, iter [00270, 01251], lr: 0.000009, loss: 2.7147
2022-10-09 13:50:22 - train: epoch 0097, iter [00280, 01251], lr: 0.000009, loss: 2.7191
2022-10-09 13:50:43 - train: epoch 0097, iter [00290, 01251], lr: 0.000009, loss: 2.8340
2022-10-09 13:51:04 - train: epoch 0097, iter [00300, 01251], lr: 0.000009, loss: 2.4881
2022-10-09 13:51:25 - train: epoch 0097, iter [00310, 01251], lr: 0.000009, loss: 2.5892
2022-10-09 13:51:47 - train: epoch 0097, iter [00320, 01251], lr: 0.000009, loss: 2.8323
2022-10-09 13:52:08 - train: epoch 0097, iter [00330, 01251], lr: 0.000009, loss: 2.4462
2022-10-09 13:52:29 - train: epoch 0097, iter [00340, 01251], lr: 0.000009, loss: 2.3077
2022-10-09 13:52:50 - train: epoch 0097, iter [00350, 01251], lr: 0.000009, loss: 2.6287
2022-10-09 13:53:12 - train: epoch 0097, iter [00360, 01251], lr: 0.000009, loss: 3.0420
2022-10-09 13:53:33 - train: epoch 0097, iter [00370, 01251], lr: 0.000008, loss: 2.1151
2022-10-09 13:53:54 - train: epoch 0097, iter [00380, 01251], lr: 0.000008, loss: 2.0997
2022-10-09 13:54:15 - train: epoch 0097, iter [00390, 01251], lr: 0.000008, loss: 2.7837
2022-10-09 13:54:36 - train: epoch 0097, iter [00400, 01251], lr: 0.000008, loss: 2.6551
2022-10-09 13:54:58 - train: epoch 0097, iter [00410, 01251], lr: 0.000008, loss: 2.9241
2022-10-09 13:55:19 - train: epoch 0097, iter [00420, 01251], lr: 0.000008, loss: 2.9122
2022-10-09 13:55:40 - train: epoch 0097, iter [00430, 01251], lr: 0.000008, loss: 2.8604
2022-10-09 13:56:01 - train: epoch 0097, iter [00440, 01251], lr: 0.000008, loss: 2.5435
2022-10-09 13:56:22 - train: epoch 0097, iter [00450, 01251], lr: 0.000008, loss: 2.8178
2022-10-09 13:56:44 - train: epoch 0097, iter [00460, 01251], lr: 0.000008, loss: 3.2004
2022-10-09 13:57:05 - train: epoch 0097, iter [00470, 01251], lr: 0.000008, loss: 2.3031
2022-10-09 13:57:26 - train: epoch 0097, iter [00480, 01251], lr: 0.000008, loss: 2.7513
2022-10-09 13:57:48 - train: epoch 0097, iter [00490, 01251], lr: 0.000008, loss: 2.8559
2022-10-09 13:58:09 - train: epoch 0097, iter [00500, 01251], lr: 0.000008, loss: 2.5592
2022-10-09 13:58:30 - train: epoch 0097, iter [00510, 01251], lr: 0.000008, loss: 2.7360
2022-10-09 13:58:51 - train: epoch 0097, iter [00520, 01251], lr: 0.000008, loss: 2.9352
2022-10-09 13:59:12 - train: epoch 0097, iter [00530, 01251], lr: 0.000008, loss: 3.2033
2022-10-09 13:59:34 - train: epoch 0097, iter [00540, 01251], lr: 0.000008, loss: 3.2370
2022-10-09 13:59:55 - train: epoch 0097, iter [00550, 01251], lr: 0.000008, loss: 2.7793
2022-10-09 14:00:16 - train: epoch 0097, iter [00560, 01251], lr: 0.000008, loss: 2.0505
2022-10-09 14:00:38 - train: epoch 0097, iter [00570, 01251], lr: 0.000008, loss: 3.0523
2022-10-09 14:00:59 - train: epoch 0097, iter [00580, 01251], lr: 0.000008, loss: 2.8922
2022-10-09 14:01:21 - train: epoch 0097, iter [00590, 01251], lr: 0.000008, loss: 3.0853
2022-10-09 14:01:42 - train: epoch 0097, iter [00600, 01251], lr: 0.000008, loss: 3.0359
2022-10-09 14:02:03 - train: epoch 0097, iter [00610, 01251], lr: 0.000008, loss: 3.0410
2022-10-09 14:02:25 - train: epoch 0097, iter [00620, 01251], lr: 0.000008, loss: 3.1376
2022-10-09 14:02:46 - train: epoch 0097, iter [00630, 01251], lr: 0.000008, loss: 3.0298
2022-10-09 14:03:08 - train: epoch 0097, iter [00640, 01251], lr: 0.000008, loss: 2.8095
2022-10-09 14:03:29 - train: epoch 0097, iter [00650, 01251], lr: 0.000008, loss: 2.7887
2022-10-09 14:03:50 - train: epoch 0097, iter [00660, 01251], lr: 0.000008, loss: 2.7115
2022-10-09 14:04:11 - train: epoch 0097, iter [00670, 01251], lr: 0.000008, loss: 2.4133
2022-10-09 14:04:33 - train: epoch 0097, iter [00680, 01251], lr: 0.000008, loss: 2.6409
2022-10-09 14:04:54 - train: epoch 0097, iter [00690, 01251], lr: 0.000007, loss: 2.8678
2022-10-09 14:05:16 - train: epoch 0097, iter [00700, 01251], lr: 0.000007, loss: 2.9935
2022-10-09 14:05:37 - train: epoch 0097, iter [00710, 01251], lr: 0.000007, loss: 2.8214
2022-10-09 14:05:58 - train: epoch 0097, iter [00720, 01251], lr: 0.000007, loss: 2.7132
2022-10-09 14:06:20 - train: epoch 0097, iter [00730, 01251], lr: 0.000007, loss: 3.1099
2022-10-09 14:06:41 - train: epoch 0097, iter [00740, 01251], lr: 0.000007, loss: 3.0444
2022-10-09 14:07:03 - train: epoch 0097, iter [00750, 01251], lr: 0.000007, loss: 2.4094
2022-10-09 14:07:24 - train: epoch 0097, iter [00760, 01251], lr: 0.000007, loss: 2.4083
2022-10-09 14:07:45 - train: epoch 0097, iter [00770, 01251], lr: 0.000007, loss: 2.9304
2022-10-09 14:08:07 - train: epoch 0097, iter [00780, 01251], lr: 0.000007, loss: 3.2533
2022-10-09 14:08:28 - train: epoch 0097, iter [00790, 01251], lr: 0.000007, loss: 3.1315
2022-10-09 14:08:49 - train: epoch 0097, iter [00800, 01251], lr: 0.000007, loss: 2.8157
2022-10-09 14:09:11 - train: epoch 0097, iter [00810, 01251], lr: 0.000007, loss: 2.9236
2022-10-09 14:09:32 - train: epoch 0097, iter [00820, 01251], lr: 0.000007, loss: 3.0264
2022-10-09 14:09:53 - train: epoch 0097, iter [00830, 01251], lr: 0.000007, loss: 2.8683
2022-10-09 14:10:15 - train: epoch 0097, iter [00840, 01251], lr: 0.000007, loss: 2.0607
2022-10-09 14:10:36 - train: epoch 0097, iter [00850, 01251], lr: 0.000007, loss: 3.0864
2022-10-09 14:10:57 - train: epoch 0097, iter [00860, 01251], lr: 0.000007, loss: 3.0603
2022-10-09 14:11:19 - train: epoch 0097, iter [00870, 01251], lr: 0.000007, loss: 2.9915
2022-10-09 14:11:40 - train: epoch 0097, iter [00880, 01251], lr: 0.000007, loss: 3.1868
2022-10-09 14:12:02 - train: epoch 0097, iter [00890, 01251], lr: 0.000007, loss: 2.9147
2022-10-09 14:12:23 - train: epoch 0097, iter [00900, 01251], lr: 0.000007, loss: 2.7913
2022-10-09 14:12:44 - train: epoch 0097, iter [00910, 01251], lr: 0.000007, loss: 2.6209
2022-10-09 14:13:06 - train: epoch 0097, iter [00920, 01251], lr: 0.000007, loss: 2.9573
2022-10-09 14:13:27 - train: epoch 0097, iter [00930, 01251], lr: 0.000007, loss: 2.9168
2022-10-09 14:13:48 - train: epoch 0097, iter [00940, 01251], lr: 0.000007, loss: 2.2397
2022-10-09 14:14:09 - train: epoch 0097, iter [00950, 01251], lr: 0.000007, loss: 2.8146
2022-10-09 14:14:31 - train: epoch 0097, iter [00960, 01251], lr: 0.000007, loss: 1.8088
2022-10-09 14:14:52 - train: epoch 0097, iter [00970, 01251], lr: 0.000007, loss: 2.4295
2022-10-09 14:15:14 - train: epoch 0097, iter [00980, 01251], lr: 0.000007, loss: 2.5837
2022-10-09 14:15:35 - train: epoch 0097, iter [00990, 01251], lr: 0.000007, loss: 2.7550
2022-10-09 14:15:56 - train: epoch 0097, iter [01000, 01251], lr: 0.000007, loss: 3.0630
2022-10-09 14:16:17 - train: epoch 0097, iter [01010, 01251], lr: 0.000007, loss: 3.2769
2022-10-09 14:16:39 - train: epoch 0097, iter [01020, 01251], lr: 0.000007, loss: 2.9010
2022-10-09 14:17:00 - train: epoch 0097, iter [01030, 01251], lr: 0.000007, loss: 3.1002
2022-10-09 14:17:21 - train: epoch 0097, iter [01040, 01251], lr: 0.000006, loss: 2.8950
2022-10-09 14:17:43 - train: epoch 0097, iter [01050, 01251], lr: 0.000006, loss: 2.7989
2022-10-09 14:18:04 - train: epoch 0097, iter [01060, 01251], lr: 0.000006, loss: 3.0735
2022-10-09 14:18:26 - train: epoch 0097, iter [01070, 01251], lr: 0.000006, loss: 3.0804
2022-10-09 14:18:47 - train: epoch 0097, iter [01080, 01251], lr: 0.000006, loss: 2.5531
2022-10-09 14:19:08 - train: epoch 0097, iter [01090, 01251], lr: 0.000006, loss: 2.9319
2022-10-09 14:19:30 - train: epoch 0097, iter [01100, 01251], lr: 0.000006, loss: 2.9258
2022-10-09 14:19:51 - train: epoch 0097, iter [01110, 01251], lr: 0.000006, loss: 2.9533
2022-10-09 14:20:13 - train: epoch 0097, iter [01120, 01251], lr: 0.000006, loss: 2.5565
2022-10-09 14:20:34 - train: epoch 0097, iter [01130, 01251], lr: 0.000006, loss: 2.8423
2022-10-09 14:20:55 - train: epoch 0097, iter [01140, 01251], lr: 0.000006, loss: 3.1481
2022-10-09 14:21:17 - train: epoch 0097, iter [01150, 01251], lr: 0.000006, loss: 3.1799
2022-10-09 14:21:38 - train: epoch 0097, iter [01160, 01251], lr: 0.000006, loss: 2.7442
2022-10-09 14:21:59 - train: epoch 0097, iter [01170, 01251], lr: 0.000006, loss: 2.3070
2022-10-09 14:22:20 - train: epoch 0097, iter [01180, 01251], lr: 0.000006, loss: 2.5048
2022-10-09 14:22:42 - train: epoch 0097, iter [01190, 01251], lr: 0.000006, loss: 2.3887
2022-10-09 14:23:03 - train: epoch 0097, iter [01200, 01251], lr: 0.000006, loss: 2.5230
2022-10-09 14:23:24 - train: epoch 0097, iter [01210, 01251], lr: 0.000006, loss: 3.1333
2022-10-09 14:23:45 - train: epoch 0097, iter [01220, 01251], lr: 0.000006, loss: 2.6721
2022-10-09 14:24:07 - train: epoch 0097, iter [01230, 01251], lr: 0.000006, loss: 2.5446
2022-10-09 14:24:28 - train: epoch 0097, iter [01240, 01251], lr: 0.000006, loss: 3.2059
2022-10-09 14:24:49 - train: epoch 0097, iter [01250, 01251], lr: 0.000006, loss: 2.3287
2022-10-09 14:24:53 - train: epoch 097, train_loss: 2.7558
2022-10-09 14:26:09 - eval: epoch: 097, acc1: 83.130%, acc5: 96.546%, test_loss: 0.7523, per_image_load_time: 0.196ms, per_image_inference_time: 1.419ms
2022-10-09 14:26:10 - until epoch: 097, best_acc1: 83.130%
2022-10-09 14:26:10 - epoch 098 lr: 0.000006
2022-10-09 14:26:38 - train: epoch 0098, iter [00010, 01251], lr: 0.000006, loss: 2.6824
2022-10-09 14:26:59 - train: epoch 0098, iter [00020, 01251], lr: 0.000006, loss: 2.6588
2022-10-09 14:27:20 - train: epoch 0098, iter [00030, 01251], lr: 0.000006, loss: 2.6242
2022-10-09 14:27:42 - train: epoch 0098, iter [00040, 01251], lr: 0.000006, loss: 2.9578
2022-10-09 14:28:03 - train: epoch 0098, iter [00050, 01251], lr: 0.000006, loss: 2.6592
2022-10-09 14:28:24 - train: epoch 0098, iter [00060, 01251], lr: 0.000006, loss: 3.0816
2022-10-09 14:28:45 - train: epoch 0098, iter [00070, 01251], lr: 0.000006, loss: 3.0738
2022-10-09 14:29:07 - train: epoch 0098, iter [00080, 01251], lr: 0.000006, loss: 3.2293
2022-10-09 14:29:28 - train: epoch 0098, iter [00090, 01251], lr: 0.000006, loss: 2.8912
2022-10-09 14:29:49 - train: epoch 0098, iter [00100, 01251], lr: 0.000006, loss: 2.3887
2022-10-09 14:30:10 - train: epoch 0098, iter [00110, 01251], lr: 0.000006, loss: 2.4749
2022-10-09 14:30:31 - train: epoch 0098, iter [00120, 01251], lr: 0.000006, loss: 2.9199
2022-10-09 14:30:53 - train: epoch 0098, iter [00130, 01251], lr: 0.000006, loss: 2.9684
2022-10-09 14:31:14 - train: epoch 0098, iter [00140, 01251], lr: 0.000006, loss: 3.1454
2022-10-09 14:31:35 - train: epoch 0098, iter [00150, 01251], lr: 0.000006, loss: 2.1690
2022-10-09 14:31:56 - train: epoch 0098, iter [00160, 01251], lr: 0.000006, loss: 3.0403
2022-10-09 14:32:18 - train: epoch 0098, iter [00170, 01251], lr: 0.000005, loss: 2.8001
2022-10-09 14:32:39 - train: epoch 0098, iter [00180, 01251], lr: 0.000005, loss: 2.3899
2022-10-09 14:33:00 - train: epoch 0098, iter [00190, 01251], lr: 0.000005, loss: 2.5048
2022-10-09 14:33:22 - train: epoch 0098, iter [00200, 01251], lr: 0.000005, loss: 3.2166
2022-10-09 14:33:43 - train: epoch 0098, iter [00210, 01251], lr: 0.000005, loss: 2.7951
2022-10-09 14:34:04 - train: epoch 0098, iter [00220, 01251], lr: 0.000005, loss: 2.9045
2022-10-09 14:34:25 - train: epoch 0098, iter [00230, 01251], lr: 0.000005, loss: 2.8141
2022-10-09 14:34:47 - train: epoch 0098, iter [00240, 01251], lr: 0.000005, loss: 2.6312
2022-10-09 14:35:08 - train: epoch 0098, iter [00250, 01251], lr: 0.000005, loss: 2.5302
2022-10-09 14:35:29 - train: epoch 0098, iter [00260, 01251], lr: 0.000005, loss: 2.9334
2022-10-09 14:35:50 - train: epoch 0098, iter [00270, 01251], lr: 0.000005, loss: 3.1076
2022-10-09 14:36:12 - train: epoch 0098, iter [00280, 01251], lr: 0.000005, loss: 2.4908
2022-10-09 14:36:33 - train: epoch 0098, iter [00290, 01251], lr: 0.000005, loss: 2.4030
2022-10-09 14:36:54 - train: epoch 0098, iter [00300, 01251], lr: 0.000005, loss: 2.5302
2022-10-09 14:37:16 - train: epoch 0098, iter [00310, 01251], lr: 0.000005, loss: 2.8096
2022-10-09 14:37:37 - train: epoch 0098, iter [00320, 01251], lr: 0.000005, loss: 2.5923
2022-10-09 14:37:58 - train: epoch 0098, iter [00330, 01251], lr: 0.000005, loss: 2.9473
2022-10-09 14:38:19 - train: epoch 0098, iter [00340, 01251], lr: 0.000005, loss: 2.6797
2022-10-09 14:38:41 - train: epoch 0098, iter [00350, 01251], lr: 0.000005, loss: 3.0542
2022-10-09 14:39:02 - train: epoch 0098, iter [00360, 01251], lr: 0.000005, loss: 2.2510
2022-10-09 14:39:23 - train: epoch 0098, iter [00370, 01251], lr: 0.000005, loss: 3.1552
2022-10-09 14:39:44 - train: epoch 0098, iter [00380, 01251], lr: 0.000005, loss: 3.1131
2022-10-09 14:40:06 - train: epoch 0098, iter [00390, 01251], lr: 0.000005, loss: 2.4393
2022-10-09 14:40:27 - train: epoch 0098, iter [00400, 01251], lr: 0.000005, loss: 3.0369
2022-10-09 14:40:48 - train: epoch 0098, iter [00410, 01251], lr: 0.000005, loss: 2.5265
2022-10-09 14:41:10 - train: epoch 0098, iter [00420, 01251], lr: 0.000005, loss: 2.8247
2022-10-09 14:41:31 - train: epoch 0098, iter [00430, 01251], lr: 0.000005, loss: 2.9441
2022-10-09 14:41:52 - train: epoch 0098, iter [00440, 01251], lr: 0.000005, loss: 2.7281
2022-10-09 14:42:13 - train: epoch 0098, iter [00450, 01251], lr: 0.000005, loss: 2.8061
2022-10-09 14:42:35 - train: epoch 0098, iter [00460, 01251], lr: 0.000005, loss: 2.7619
2022-10-09 14:42:56 - train: epoch 0098, iter [00470, 01251], lr: 0.000005, loss: 3.1604
2022-10-09 14:43:17 - train: epoch 0098, iter [00480, 01251], lr: 0.000005, loss: 3.0425
2022-10-09 14:43:39 - train: epoch 0098, iter [00490, 01251], lr: 0.000005, loss: 2.7504
2022-10-09 14:44:00 - train: epoch 0098, iter [00500, 01251], lr: 0.000005, loss: 2.7551
2022-10-09 14:44:21 - train: epoch 0098, iter [00510, 01251], lr: 0.000005, loss: 2.8988
2022-10-09 14:44:43 - train: epoch 0098, iter [00520, 01251], lr: 0.000005, loss: 2.5214
2022-10-09 14:45:04 - train: epoch 0098, iter [00530, 01251], lr: 0.000005, loss: 2.4656
2022-10-09 14:45:25 - train: epoch 0098, iter [00540, 01251], lr: 0.000005, loss: 2.6602
2022-10-09 14:45:46 - train: epoch 0098, iter [00550, 01251], lr: 0.000005, loss: 2.4183
2022-10-09 14:46:08 - train: epoch 0098, iter [00560, 01251], lr: 0.000005, loss: 2.3550
2022-10-09 14:46:29 - train: epoch 0098, iter [00570, 01251], lr: 0.000005, loss: 2.7005
2022-10-09 14:46:50 - train: epoch 0098, iter [00580, 01251], lr: 0.000005, loss: 2.2837
2022-10-09 14:47:11 - train: epoch 0098, iter [00590, 01251], lr: 0.000004, loss: 3.2648
2022-10-09 14:47:33 - train: epoch 0098, iter [00600, 01251], lr: 0.000004, loss: 2.8036
2022-10-09 14:47:54 - train: epoch 0098, iter [00610, 01251], lr: 0.000004, loss: 2.4780
2022-10-09 14:48:15 - train: epoch 0098, iter [00620, 01251], lr: 0.000004, loss: 2.4444
2022-10-09 14:48:36 - train: epoch 0098, iter [00630, 01251], lr: 0.000004, loss: 2.9771
2022-10-09 14:48:58 - train: epoch 0098, iter [00640, 01251], lr: 0.000004, loss: 3.0092
2022-10-09 14:49:19 - train: epoch 0098, iter [00650, 01251], lr: 0.000004, loss: 2.6872
2022-10-09 14:49:41 - train: epoch 0098, iter [00660, 01251], lr: 0.000004, loss: 2.8180
2022-10-09 14:50:02 - train: epoch 0098, iter [00670, 01251], lr: 0.000004, loss: 3.2147
2022-10-09 14:50:23 - train: epoch 0098, iter [00680, 01251], lr: 0.000004, loss: 3.0857
2022-10-09 14:50:45 - train: epoch 0098, iter [00690, 01251], lr: 0.000004, loss: 2.9584
2022-10-09 14:51:06 - train: epoch 0098, iter [00700, 01251], lr: 0.000004, loss: 2.7595
2022-10-09 14:51:27 - train: epoch 0098, iter [00710, 01251], lr: 0.000004, loss: 2.8582
2022-10-09 14:51:49 - train: epoch 0098, iter [00720, 01251], lr: 0.000004, loss: 2.6110
2022-10-09 14:52:10 - train: epoch 0098, iter [00730, 01251], lr: 0.000004, loss: 2.8027
2022-10-09 14:52:31 - train: epoch 0098, iter [00740, 01251], lr: 0.000004, loss: 2.8021
2022-10-09 14:52:53 - train: epoch 0098, iter [00750, 01251], lr: 0.000004, loss: 3.1522
2022-10-09 14:53:14 - train: epoch 0098, iter [00760, 01251], lr: 0.000004, loss: 2.5214
2022-10-09 14:53:35 - train: epoch 0098, iter [00770, 01251], lr: 0.000004, loss: 2.3334
2022-10-09 14:53:57 - train: epoch 0098, iter [00780, 01251], lr: 0.000004, loss: 3.1455
2022-10-09 14:54:18 - train: epoch 0098, iter [00790, 01251], lr: 0.000004, loss: 2.9461
2022-10-09 14:54:40 - train: epoch 0098, iter [00800, 01251], lr: 0.000004, loss: 2.6061
2022-10-09 14:55:01 - train: epoch 0098, iter [00810, 01251], lr: 0.000004, loss: 2.6509
2022-10-09 14:55:22 - train: epoch 0098, iter [00820, 01251], lr: 0.000004, loss: 1.7458
2022-10-09 14:55:44 - train: epoch 0098, iter [00830, 01251], lr: 0.000004, loss: 2.2099
2022-10-09 14:56:05 - train: epoch 0098, iter [00840, 01251], lr: 0.000004, loss: 3.0126
2022-10-09 14:56:26 - train: epoch 0098, iter [00850, 01251], lr: 0.000004, loss: 2.7170
2022-10-09 14:56:48 - train: epoch 0098, iter [00860, 01251], lr: 0.000004, loss: 2.8195
2022-10-09 14:57:09 - train: epoch 0098, iter [00870, 01251], lr: 0.000004, loss: 2.6363
2022-10-09 14:57:30 - train: epoch 0098, iter [00880, 01251], lr: 0.000004, loss: 2.9058
2022-10-09 14:57:52 - train: epoch 0098, iter [00890, 01251], lr: 0.000004, loss: 2.9315
2022-10-09 14:58:13 - train: epoch 0098, iter [00900, 01251], lr: 0.000004, loss: 2.8759
2022-10-09 14:58:35 - train: epoch 0098, iter [00910, 01251], lr: 0.000004, loss: 2.7960
2022-10-09 14:58:56 - train: epoch 0098, iter [00920, 01251], lr: 0.000004, loss: 2.4050
2022-10-09 14:59:17 - train: epoch 0098, iter [00930, 01251], lr: 0.000004, loss: 2.3562
2022-10-09 14:59:39 - train: epoch 0098, iter [00940, 01251], lr: 0.000004, loss: 2.7679
2022-10-09 15:00:00 - train: epoch 0098, iter [00950, 01251], lr: 0.000004, loss: 2.5722
2022-10-09 15:00:21 - train: epoch 0098, iter [00960, 01251], lr: 0.000004, loss: 2.3268
2022-10-09 15:00:43 - train: epoch 0098, iter [00970, 01251], lr: 0.000004, loss: 2.7950
2022-10-09 15:01:04 - train: epoch 0098, iter [00980, 01251], lr: 0.000004, loss: 2.5218
2022-10-09 15:01:25 - train: epoch 0098, iter [00990, 01251], lr: 0.000004, loss: 2.4984
2022-10-09 15:01:47 - train: epoch 0098, iter [01000, 01251], lr: 0.000004, loss: 2.5904
2022-10-09 15:02:08 - train: epoch 0098, iter [01010, 01251], lr: 0.000004, loss: 2.5597
2022-10-09 15:02:29 - train: epoch 0098, iter [01020, 01251], lr: 0.000004, loss: 2.5498
2022-10-09 15:02:51 - train: epoch 0098, iter [01030, 01251], lr: 0.000004, loss: 2.5895
2022-10-09 15:03:12 - train: epoch 0098, iter [01040, 01251], lr: 0.000004, loss: 2.8274
2022-10-09 15:03:33 - train: epoch 0098, iter [01050, 01251], lr: 0.000004, loss: 2.9260
2022-10-09 15:03:55 - train: epoch 0098, iter [01060, 01251], lr: 0.000004, loss: 2.2568
2022-10-09 15:04:16 - train: epoch 0098, iter [01070, 01251], lr: 0.000004, loss: 2.3586
2022-10-09 15:04:38 - train: epoch 0098, iter [01080, 01251], lr: 0.000003, loss: 2.6417
2022-10-09 15:04:59 - train: epoch 0098, iter [01090, 01251], lr: 0.000003, loss: 2.6450
2022-10-09 15:05:20 - train: epoch 0098, iter [01100, 01251], lr: 0.000003, loss: 2.7015
2022-10-09 15:05:41 - train: epoch 0098, iter [01110, 01251], lr: 0.000003, loss: 2.5600
2022-10-09 15:06:03 - train: epoch 0098, iter [01120, 01251], lr: 0.000003, loss: 2.7939
2022-10-09 15:06:24 - train: epoch 0098, iter [01130, 01251], lr: 0.000003, loss: 2.8844
2022-10-09 15:06:46 - train: epoch 0098, iter [01140, 01251], lr: 0.000003, loss: 2.6476
2022-10-09 15:07:07 - train: epoch 0098, iter [01150, 01251], lr: 0.000003, loss: 2.9959
2022-10-09 15:07:28 - train: epoch 0098, iter [01160, 01251], lr: 0.000003, loss: 2.9236
2022-10-09 15:07:50 - train: epoch 0098, iter [01170, 01251], lr: 0.000003, loss: 2.6149
2022-10-09 15:08:11 - train: epoch 0098, iter [01180, 01251], lr: 0.000003, loss: 3.1647
2022-10-09 15:08:32 - train: epoch 0098, iter [01190, 01251], lr: 0.000003, loss: 2.7895
2022-10-09 15:08:53 - train: epoch 0098, iter [01200, 01251], lr: 0.000003, loss: 2.6510
2022-10-09 15:09:15 - train: epoch 0098, iter [01210, 01251], lr: 0.000003, loss: 2.9627
2022-10-09 15:09:36 - train: epoch 0098, iter [01220, 01251], lr: 0.000003, loss: 2.7887
2022-10-09 15:09:58 - train: epoch 0098, iter [01230, 01251], lr: 0.000003, loss: 2.6590
2022-10-09 15:10:19 - train: epoch 0098, iter [01240, 01251], lr: 0.000003, loss: 3.2084
2022-10-09 15:10:40 - train: epoch 0098, iter [01250, 01251], lr: 0.000003, loss: 3.2361
2022-10-09 15:10:43 - train: epoch 098, train_loss: 2.7576
2022-10-09 15:12:00 - eval: epoch: 098, acc1: 83.112%, acc5: 96.546%, test_loss: 0.7515, per_image_load_time: 0.192ms, per_image_inference_time: 1.425ms
2022-10-09 15:12:01 - until epoch: 098, best_acc1: 83.130%
2022-10-09 15:12:01 - epoch 099 lr: 0.000003
2022-10-09 15:12:29 - train: epoch 0099, iter [00010, 01251], lr: 0.000003, loss: 3.0057
2022-10-09 15:12:50 - train: epoch 0099, iter [00020, 01251], lr: 0.000003, loss: 2.6813
2022-10-09 15:13:11 - train: epoch 0099, iter [00030, 01251], lr: 0.000003, loss: 2.6721
2022-10-09 15:13:32 - train: epoch 0099, iter [00040, 01251], lr: 0.000003, loss: 3.0386
2022-10-09 15:13:54 - train: epoch 0099, iter [00050, 01251], lr: 0.000003, loss: 2.3677
2022-10-09 15:14:15 - train: epoch 0099, iter [00060, 01251], lr: 0.000003, loss: 2.2870
2022-10-09 15:14:36 - train: epoch 0099, iter [00070, 01251], lr: 0.000003, loss: 2.9555
2022-10-09 15:14:57 - train: epoch 0099, iter [00080, 01251], lr: 0.000003, loss: 3.1145
2022-10-09 15:15:19 - train: epoch 0099, iter [00090, 01251], lr: 0.000003, loss: 2.8478
2022-10-09 15:15:40 - train: epoch 0099, iter [00100, 01251], lr: 0.000003, loss: 2.7284
2022-10-09 15:16:01 - train: epoch 0099, iter [00110, 01251], lr: 0.000003, loss: 2.7668
2022-10-09 15:16:22 - train: epoch 0099, iter [00120, 01251], lr: 0.000003, loss: 2.2799
2022-10-09 15:16:43 - train: epoch 0099, iter [00130, 01251], lr: 0.000003, loss: 2.7303
2022-10-09 15:17:05 - train: epoch 0099, iter [00140, 01251], lr: 0.000003, loss: 2.5534
2022-10-09 15:17:26 - train: epoch 0099, iter [00150, 01251], lr: 0.000003, loss: 2.4890
2022-10-09 15:17:47 - train: epoch 0099, iter [00160, 01251], lr: 0.000003, loss: 2.5229
2022-10-09 15:18:09 - train: epoch 0099, iter [00170, 01251], lr: 0.000003, loss: 2.3702
2022-10-09 15:18:30 - train: epoch 0099, iter [00180, 01251], lr: 0.000003, loss: 2.7052
2022-10-09 15:18:51 - train: epoch 0099, iter [00190, 01251], lr: 0.000003, loss: 2.9950
2022-10-09 15:19:13 - train: epoch 0099, iter [00200, 01251], lr: 0.000003, loss: 3.0165
2022-10-09 15:19:34 - train: epoch 0099, iter [00210, 01251], lr: 0.000003, loss: 3.2875
2022-10-09 15:19:55 - train: epoch 0099, iter [00220, 01251], lr: 0.000003, loss: 2.7584
2022-10-09 15:20:17 - train: epoch 0099, iter [00230, 01251], lr: 0.000003, loss: 2.3463
2022-10-09 15:20:38 - train: epoch 0099, iter [00240, 01251], lr: 0.000003, loss: 2.6731
2022-10-09 15:20:59 - train: epoch 0099, iter [00250, 01251], lr: 0.000003, loss: 2.6088
2022-10-09 15:21:20 - train: epoch 0099, iter [00260, 01251], lr: 0.000003, loss: 2.1125
2022-10-09 15:21:41 - train: epoch 0099, iter [00270, 01251], lr: 0.000003, loss: 2.7599
2022-10-09 15:22:03 - train: epoch 0099, iter [00280, 01251], lr: 0.000003, loss: 2.3484
2022-10-09 15:22:24 - train: epoch 0099, iter [00290, 01251], lr: 0.000003, loss: 2.5938
2022-10-09 15:22:46 - train: epoch 0099, iter [00300, 01251], lr: 0.000003, loss: 2.5276
2022-10-09 15:23:07 - train: epoch 0099, iter [00310, 01251], lr: 0.000003, loss: 2.2846
2022-10-09 15:23:28 - train: epoch 0099, iter [00320, 01251], lr: 0.000003, loss: 2.8301
2022-10-09 15:23:49 - train: epoch 0099, iter [00330, 01251], lr: 0.000003, loss: 2.8355
2022-10-09 15:24:11 - train: epoch 0099, iter [00340, 01251], lr: 0.000003, loss: 2.8641
2022-10-09 15:24:32 - train: epoch 0099, iter [00350, 01251], lr: 0.000003, loss: 2.9902
2022-10-09 15:24:53 - train: epoch 0099, iter [00360, 01251], lr: 0.000003, loss: 2.8368
2022-10-09 15:25:14 - train: epoch 0099, iter [00370, 01251], lr: 0.000003, loss: 3.1829
2022-10-09 15:25:35 - train: epoch 0099, iter [00380, 01251], lr: 0.000003, loss: 2.6404
2022-10-09 15:25:57 - train: epoch 0099, iter [00390, 01251], lr: 0.000003, loss: 2.4788
2022-10-09 15:26:18 - train: epoch 0099, iter [00400, 01251], lr: 0.000003, loss: 2.4572
2022-10-09 15:26:39 - train: epoch 0099, iter [00410, 01251], lr: 0.000003, loss: 2.7536
2022-10-09 15:27:01 - train: epoch 0099, iter [00420, 01251], lr: 0.000003, loss: 3.1813
2022-10-09 15:27:22 - train: epoch 0099, iter [00430, 01251], lr: 0.000002, loss: 2.6161
2022-10-09 15:27:43 - train: epoch 0099, iter [00440, 01251], lr: 0.000002, loss: 2.4566
2022-10-09 15:28:05 - train: epoch 0099, iter [00450, 01251], lr: 0.000002, loss: 2.4404
2022-10-09 15:28:26 - train: epoch 0099, iter [00460, 01251], lr: 0.000002, loss: 2.9808
2022-10-09 15:28:47 - train: epoch 0099, iter [00470, 01251], lr: 0.000002, loss: 2.8608
2022-10-09 15:29:08 - train: epoch 0099, iter [00480, 01251], lr: 0.000002, loss: 2.8053
2022-10-09 15:29:30 - train: epoch 0099, iter [00490, 01251], lr: 0.000002, loss: 2.9784
2022-10-09 15:29:51 - train: epoch 0099, iter [00500, 01251], lr: 0.000002, loss: 2.5981
2022-10-09 15:30:12 - train: epoch 0099, iter [00510, 01251], lr: 0.000002, loss: 2.9762
2022-10-09 15:30:33 - train: epoch 0099, iter [00520, 01251], lr: 0.000002, loss: 2.9730
2022-10-09 15:30:55 - train: epoch 0099, iter [00530, 01251], lr: 0.000002, loss: 2.6501
2022-10-09 15:31:16 - train: epoch 0099, iter [00540, 01251], lr: 0.000002, loss: 2.4031
2022-10-09 15:31:37 - train: epoch 0099, iter [00550, 01251], lr: 0.000002, loss: 2.7773
2022-10-09 15:31:58 - train: epoch 0099, iter [00560, 01251], lr: 0.000002, loss: 2.7069
2022-10-09 15:32:20 - train: epoch 0099, iter [00570, 01251], lr: 0.000002, loss: 2.2225
2022-10-09 15:32:41 - train: epoch 0099, iter [00580, 01251], lr: 0.000002, loss: 3.0085
2022-10-09 15:33:02 - train: epoch 0099, iter [00590, 01251], lr: 0.000002, loss: 2.7969
2022-10-09 15:33:24 - train: epoch 0099, iter [00600, 01251], lr: 0.000002, loss: 2.9474
2022-10-09 15:33:45 - train: epoch 0099, iter [00610, 01251], lr: 0.000002, loss: 3.2055
2022-10-09 15:34:06 - train: epoch 0099, iter [00620, 01251], lr: 0.000002, loss: 2.9584
2022-10-09 15:34:27 - train: epoch 0099, iter [00630, 01251], lr: 0.000002, loss: 3.0556
2022-10-09 15:34:48 - train: epoch 0099, iter [00640, 01251], lr: 0.000002, loss: 3.1839
2022-10-09 15:35:10 - train: epoch 0099, iter [00650, 01251], lr: 0.000002, loss: 2.6156
2022-10-09 15:35:31 - train: epoch 0099, iter [00660, 01251], lr: 0.000002, loss: 2.1232
2022-10-09 15:35:52 - train: epoch 0099, iter [00670, 01251], lr: 0.000002, loss: 3.2014
2022-10-09 15:36:13 - train: epoch 0099, iter [00680, 01251], lr: 0.000002, loss: 2.2479
2022-10-09 15:36:34 - train: epoch 0099, iter [00690, 01251], lr: 0.000002, loss: 2.9967
2022-10-09 15:36:56 - train: epoch 0099, iter [00700, 01251], lr: 0.000002, loss: 3.1615
2022-10-09 15:37:17 - train: epoch 0099, iter [00710, 01251], lr: 0.000002, loss: 2.4669
2022-10-09 15:37:38 - train: epoch 0099, iter [00720, 01251], lr: 0.000002, loss: 3.2964
2022-10-09 15:37:59 - train: epoch 0099, iter [00730, 01251], lr: 0.000002, loss: 2.9642
2022-10-09 15:38:21 - train: epoch 0099, iter [00740, 01251], lr: 0.000002, loss: 2.8669
2022-10-09 15:38:42 - train: epoch 0099, iter [00750, 01251], lr: 0.000002, loss: 3.0350
2022-10-09 15:39:04 - train: epoch 0099, iter [00760, 01251], lr: 0.000002, loss: 2.9009
2022-10-09 15:39:25 - train: epoch 0099, iter [00770, 01251], lr: 0.000002, loss: 2.7703
2022-10-09 15:39:46 - train: epoch 0099, iter [00780, 01251], lr: 0.000002, loss: 2.5264
2022-10-09 15:40:08 - train: epoch 0099, iter [00790, 01251], lr: 0.000002, loss: 2.9864
2022-10-09 15:40:29 - train: epoch 0099, iter [00800, 01251], lr: 0.000002, loss: 3.0314
2022-10-09 15:40:50 - train: epoch 0099, iter [00810, 01251], lr: 0.000002, loss: 2.8225
2022-10-09 15:41:11 - train: epoch 0099, iter [00820, 01251], lr: 0.000002, loss: 2.7286
2022-10-09 15:41:33 - train: epoch 0099, iter [00830, 01251], lr: 0.000002, loss: 2.4006
2022-10-09 15:41:54 - train: epoch 0099, iter [00840, 01251], lr: 0.000002, loss: 2.5118
2022-10-09 15:42:15 - train: epoch 0099, iter [00850, 01251], lr: 0.000002, loss: 3.0206
2022-10-09 15:42:37 - train: epoch 0099, iter [00860, 01251], lr: 0.000002, loss: 2.5870
2022-10-09 15:42:58 - train: epoch 0099, iter [00870, 01251], lr: 0.000002, loss: 2.9957
2022-10-09 15:43:19 - train: epoch 0099, iter [00880, 01251], lr: 0.000002, loss: 2.9314
2022-10-09 15:43:40 - train: epoch 0099, iter [00890, 01251], lr: 0.000002, loss: 2.6803
2022-10-09 15:44:02 - train: epoch 0099, iter [00900, 01251], lr: 0.000002, loss: 2.7700
2022-10-09 15:44:23 - train: epoch 0099, iter [00910, 01251], lr: 0.000002, loss: 3.0597
2022-10-09 15:44:44 - train: epoch 0099, iter [00920, 01251], lr: 0.000002, loss: 2.5894
2022-10-09 15:45:05 - train: epoch 0099, iter [00930, 01251], lr: 0.000002, loss: 1.8902
2022-10-09 15:45:27 - train: epoch 0099, iter [00940, 01251], lr: 0.000002, loss: 2.5612
2022-10-09 15:45:48 - train: epoch 0099, iter [00950, 01251], lr: 0.000002, loss: 2.8488
2022-10-09 15:46:09 - train: epoch 0099, iter [00960, 01251], lr: 0.000002, loss: 2.7287
2022-10-09 15:46:31 - train: epoch 0099, iter [00970, 01251], lr: 0.000002, loss: 2.8855
2022-10-09 15:46:52 - train: epoch 0099, iter [00980, 01251], lr: 0.000002, loss: 2.5686
2022-10-09 15:47:13 - train: epoch 0099, iter [00990, 01251], lr: 0.000002, loss: 2.2751
2022-10-09 15:47:34 - train: epoch 0099, iter [01000, 01251], lr: 0.000002, loss: 2.8818
2022-10-09 15:47:56 - train: epoch 0099, iter [01010, 01251], lr: 0.000002, loss: 2.7448
2022-10-09 15:48:17 - train: epoch 0099, iter [01020, 01251], lr: 0.000002, loss: 3.0371
2022-10-09 15:48:38 - train: epoch 0099, iter [01030, 01251], lr: 0.000002, loss: 2.9033
2022-10-09 15:49:00 - train: epoch 0099, iter [01040, 01251], lr: 0.000002, loss: 3.0825
2022-10-09 15:49:21 - train: epoch 0099, iter [01050, 01251], lr: 0.000002, loss: 2.9162
2022-10-09 15:49:42 - train: epoch 0099, iter [01060, 01251], lr: 0.000002, loss: 3.1992
2022-10-09 15:50:03 - train: epoch 0099, iter [01070, 01251], lr: 0.000002, loss: 2.7591
2022-10-09 15:50:24 - train: epoch 0099, iter [01080, 01251], lr: 0.000002, loss: 2.9432
2022-10-09 15:50:46 - train: epoch 0099, iter [01090, 01251], lr: 0.000002, loss: 2.2414
2022-10-09 15:51:07 - train: epoch 0099, iter [01100, 01251], lr: 0.000002, loss: 2.5486
2022-10-09 15:51:28 - train: epoch 0099, iter [01110, 01251], lr: 0.000002, loss: 3.0299
2022-10-09 15:51:49 - train: epoch 0099, iter [01120, 01251], lr: 0.000002, loss: 2.9339
2022-10-09 15:52:10 - train: epoch 0099, iter [01130, 01251], lr: 0.000002, loss: 2.2882
2022-10-09 15:52:32 - train: epoch 0099, iter [01140, 01251], lr: 0.000002, loss: 2.6497
2022-10-09 15:52:53 - train: epoch 0099, iter [01150, 01251], lr: 0.000002, loss: 3.2996
2022-10-09 15:53:14 - train: epoch 0099, iter [01160, 01251], lr: 0.000002, loss: 3.2916
2022-10-09 15:53:35 - train: epoch 0099, iter [01170, 01251], lr: 0.000002, loss: 2.8515
2022-10-09 15:53:57 - train: epoch 0099, iter [01180, 01251], lr: 0.000002, loss: 2.7896
2022-10-09 15:54:18 - train: epoch 0099, iter [01190, 01251], lr: 0.000002, loss: 2.8750
2022-10-09 15:54:39 - train: epoch 0099, iter [01200, 01251], lr: 0.000002, loss: 2.8731
2022-10-09 15:55:01 - train: epoch 0099, iter [01210, 01251], lr: 0.000002, loss: 2.7274
2022-10-09 15:55:22 - train: epoch 0099, iter [01220, 01251], lr: 0.000002, loss: 2.7160
2022-10-09 15:55:43 - train: epoch 0099, iter [01230, 01251], lr: 0.000002, loss: 2.3327
2022-10-09 15:56:05 - train: epoch 0099, iter [01240, 01251], lr: 0.000002, loss: 2.9472
2022-10-09 15:56:26 - train: epoch 0099, iter [01250, 01251], lr: 0.000002, loss: 3.0566
2022-10-09 15:56:29 - train: epoch 099, train_loss: 2.7577
2022-10-09 15:57:44 - eval: epoch: 099, acc1: 83.096%, acc5: 96.552%, test_loss: 0.7528, per_image_load_time: 0.191ms, per_image_inference_time: 1.435ms
2022-10-09 15:57:45 - until epoch: 099, best_acc1: 83.130%
2022-10-09 15:57:45 - epoch 100 lr: 0.000002
2022-10-09 15:58:14 - train: epoch 0100, iter [00010, 01251], lr: 0.000002, loss: 2.9231
2022-10-09 15:58:35 - train: epoch 0100, iter [00020, 01251], lr: 0.000002, loss: 2.2260
2022-10-09 15:58:56 - train: epoch 0100, iter [00030, 01251], lr: 0.000002, loss: 2.7277
2022-10-09 15:59:17 - train: epoch 0100, iter [00040, 01251], lr: 0.000002, loss: 2.7885
2022-10-09 15:59:39 - train: epoch 0100, iter [00050, 01251], lr: 0.000002, loss: 2.2970
2022-10-09 16:00:00 - train: epoch 0100, iter [00060, 01251], lr: 0.000001, loss: 3.1323
2022-10-09 16:00:21 - train: epoch 0100, iter [00070, 01251], lr: 0.000001, loss: 2.3632
2022-10-09 16:00:42 - train: epoch 0100, iter [00080, 01251], lr: 0.000001, loss: 2.9720
2022-10-09 16:01:03 - train: epoch 0100, iter [00090, 01251], lr: 0.000001, loss: 2.5757
2022-10-09 16:01:25 - train: epoch 0100, iter [00100, 01251], lr: 0.000001, loss: 2.1521
2022-10-09 16:01:46 - train: epoch 0100, iter [00110, 01251], lr: 0.000001, loss: 3.0202
2022-10-09 16:02:07 - train: epoch 0100, iter [00120, 01251], lr: 0.000001, loss: 2.8950
2022-10-09 16:02:29 - train: epoch 0100, iter [00130, 01251], lr: 0.000001, loss: 3.0179
2022-10-09 16:02:50 - train: epoch 0100, iter [00140, 01251], lr: 0.000001, loss: 2.1682
2022-10-09 16:03:11 - train: epoch 0100, iter [00150, 01251], lr: 0.000001, loss: 2.3817
2022-10-09 16:03:32 - train: epoch 0100, iter [00160, 01251], lr: 0.000001, loss: 2.8916
2022-10-09 16:03:53 - train: epoch 0100, iter [00170, 01251], lr: 0.000001, loss: 2.9544
2022-10-09 16:04:15 - train: epoch 0100, iter [00180, 01251], lr: 0.000001, loss: 2.4581
2022-10-09 16:04:36 - train: epoch 0100, iter [00190, 01251], lr: 0.000001, loss: 2.8204
2022-10-09 16:04:57 - train: epoch 0100, iter [00200, 01251], lr: 0.000001, loss: 2.2445
2022-10-09 16:05:18 - train: epoch 0100, iter [00210, 01251], lr: 0.000001, loss: 2.5283
2022-10-09 16:05:40 - train: epoch 0100, iter [00220, 01251], lr: 0.000001, loss: 2.8559
2022-10-09 16:06:01 - train: epoch 0100, iter [00230, 01251], lr: 0.000001, loss: 2.2169
2022-10-09 16:06:22 - train: epoch 0100, iter [00240, 01251], lr: 0.000001, loss: 3.0058
2022-10-09 16:06:43 - train: epoch 0100, iter [00250, 01251], lr: 0.000001, loss: 3.1547
2022-10-09 16:07:05 - train: epoch 0100, iter [00260, 01251], lr: 0.000001, loss: 2.7576
2022-10-09 16:07:26 - train: epoch 0100, iter [00270, 01251], lr: 0.000001, loss: 3.0176
2022-10-09 16:07:47 - train: epoch 0100, iter [00280, 01251], lr: 0.000001, loss: 2.4349
2022-10-09 16:08:08 - train: epoch 0100, iter [00290, 01251], lr: 0.000001, loss: 2.1202
2022-10-09 16:08:30 - train: epoch 0100, iter [00300, 01251], lr: 0.000001, loss: 2.8434
2022-10-09 16:08:51 - train: epoch 0100, iter [00310, 01251], lr: 0.000001, loss: 2.2314
2022-10-09 16:09:12 - train: epoch 0100, iter [00320, 01251], lr: 0.000001, loss: 3.1841
2022-10-09 16:09:33 - train: epoch 0100, iter [00330, 01251], lr: 0.000001, loss: 2.6326
2022-10-09 16:09:55 - train: epoch 0100, iter [00340, 01251], lr: 0.000001, loss: 2.7103
2022-10-09 16:10:16 - train: epoch 0100, iter [00350, 01251], lr: 0.000001, loss: 2.9716
2022-10-09 16:10:37 - train: epoch 0100, iter [00360, 01251], lr: 0.000001, loss: 2.5036
2022-10-09 16:10:59 - train: epoch 0100, iter [00370, 01251], lr: 0.000001, loss: 2.9408
2022-10-09 16:11:20 - train: epoch 0100, iter [00380, 01251], lr: 0.000001, loss: 2.8517
2022-10-09 16:11:41 - train: epoch 0100, iter [00390, 01251], lr: 0.000001, loss: 2.9112
2022-10-09 16:12:02 - train: epoch 0100, iter [00400, 01251], lr: 0.000001, loss: 2.5694
2022-10-09 16:12:23 - train: epoch 0100, iter [00410, 01251], lr: 0.000001, loss: 2.4189
2022-10-09 16:12:45 - train: epoch 0100, iter [00420, 01251], lr: 0.000001, loss: 2.2096
2022-10-09 16:13:06 - train: epoch 0100, iter [00430, 01251], lr: 0.000001, loss: 3.3451
2022-10-09 16:13:27 - train: epoch 0100, iter [00440, 01251], lr: 0.000001, loss: 2.8031
2022-10-09 16:13:48 - train: epoch 0100, iter [00450, 01251], lr: 0.000001, loss: 2.9040
2022-10-09 16:14:10 - train: epoch 0100, iter [00460, 01251], lr: 0.000001, loss: 2.5887
2022-10-09 16:14:31 - train: epoch 0100, iter [00470, 01251], lr: 0.000001, loss: 2.7897
2022-10-09 16:14:52 - train: epoch 0100, iter [00480, 01251], lr: 0.000001, loss: 2.9187
2022-10-09 16:15:13 - train: epoch 0100, iter [00490, 01251], lr: 0.000001, loss: 2.4567
2022-10-09 16:15:34 - train: epoch 0100, iter [00500, 01251], lr: 0.000001, loss: 2.9947
2022-10-09 16:15:56 - train: epoch 0100, iter [00510, 01251], lr: 0.000001, loss: 3.1576
2022-10-09 16:16:17 - train: epoch 0100, iter [00520, 01251], lr: 0.000001, loss: 2.0715
2022-10-09 16:16:38 - train: epoch 0100, iter [00530, 01251], lr: 0.000001, loss: 2.9974
2022-10-09 16:16:59 - train: epoch 0100, iter [00540, 01251], lr: 0.000001, loss: 3.1440
2022-10-09 16:17:20 - train: epoch 0100, iter [00550, 01251], lr: 0.000001, loss: 2.4371
2022-10-09 16:17:42 - train: epoch 0100, iter [00560, 01251], lr: 0.000001, loss: 2.9576
2022-10-09 16:18:03 - train: epoch 0100, iter [00570, 01251], lr: 0.000001, loss: 2.7468
2022-10-09 16:18:24 - train: epoch 0100, iter [00580, 01251], lr: 0.000001, loss: 1.7678
2022-10-09 16:18:45 - train: epoch 0100, iter [00590, 01251], lr: 0.000001, loss: 2.7936
2022-10-09 16:19:06 - train: epoch 0100, iter [00600, 01251], lr: 0.000001, loss: 3.0165
2022-10-09 16:19:28 - train: epoch 0100, iter [00610, 01251], lr: 0.000001, loss: 3.2440
2022-10-09 16:19:49 - train: epoch 0100, iter [00620, 01251], lr: 0.000001, loss: 2.7869
2022-10-09 16:20:10 - train: epoch 0100, iter [00630, 01251], lr: 0.000001, loss: 2.9774
2022-10-09 16:20:31 - train: epoch 0100, iter [00640, 01251], lr: 0.000001, loss: 2.3418
2022-10-09 16:20:52 - train: epoch 0100, iter [00650, 01251], lr: 0.000001, loss: 2.6928
2022-10-09 16:21:14 - train: epoch 0100, iter [00660, 01251], lr: 0.000001, loss: 3.1126
2022-10-09 16:21:35 - train: epoch 0100, iter [00670, 01251], lr: 0.000001, loss: 3.2202
2022-10-09 16:21:56 - train: epoch 0100, iter [00680, 01251], lr: 0.000001, loss: 2.4671
2022-10-09 16:22:18 - train: epoch 0100, iter [00690, 01251], lr: 0.000001, loss: 2.5927
2022-10-09 16:22:39 - train: epoch 0100, iter [00700, 01251], lr: 0.000001, loss: 2.9512
2022-10-09 16:23:00 - train: epoch 0100, iter [00710, 01251], lr: 0.000001, loss: 2.4937
2022-10-09 16:23:21 - train: epoch 0100, iter [00720, 01251], lr: 0.000001, loss: 2.9457
2022-10-09 16:23:43 - train: epoch 0100, iter [00730, 01251], lr: 0.000001, loss: 2.9378
2022-10-09 16:24:04 - train: epoch 0100, iter [00740, 01251], lr: 0.000001, loss: 3.0668
2022-10-09 16:24:25 - train: epoch 0100, iter [00750, 01251], lr: 0.000001, loss: 2.8437
2022-10-09 16:24:46 - train: epoch 0100, iter [00760, 01251], lr: 0.000001, loss: 2.9806
2022-10-09 16:25:07 - train: epoch 0100, iter [00770, 01251], lr: 0.000001, loss: 2.7608
2022-10-09 16:25:29 - train: epoch 0100, iter [00780, 01251], lr: 0.000001, loss: 2.5903
2022-10-09 16:25:50 - train: epoch 0100, iter [00790, 01251], lr: 0.000001, loss: 2.4650
2022-10-09 16:26:11 - train: epoch 0100, iter [00800, 01251], lr: 0.000001, loss: 3.2657
2022-10-09 16:26:32 - train: epoch 0100, iter [00810, 01251], lr: 0.000001, loss: 2.5736
2022-10-09 16:26:54 - train: epoch 0100, iter [00820, 01251], lr: 0.000001, loss: 2.3746
2022-10-09 16:27:15 - train: epoch 0100, iter [00830, 01251], lr: 0.000001, loss: 2.1408
2022-10-09 16:27:36 - train: epoch 0100, iter [00840, 01251], lr: 0.000001, loss: 3.1085
2022-10-09 16:27:57 - train: epoch 0100, iter [00850, 01251], lr: 0.000001, loss: 2.5341
2022-10-09 16:28:19 - train: epoch 0100, iter [00860, 01251], lr: 0.000001, loss: 2.8231
2022-10-09 16:28:40 - train: epoch 0100, iter [00870, 01251], lr: 0.000001, loss: 2.8271
2022-10-09 16:29:01 - train: epoch 0100, iter [00880, 01251], lr: 0.000001, loss: 2.7494
2022-10-09 16:29:22 - train: epoch 0100, iter [00890, 01251], lr: 0.000001, loss: 2.8035
2022-10-09 16:29:43 - train: epoch 0100, iter [00900, 01251], lr: 0.000001, loss: 2.6113
2022-10-09 16:30:05 - train: epoch 0100, iter [00910, 01251], lr: 0.000001, loss: 2.3678
2022-10-09 16:30:26 - train: epoch 0100, iter [00920, 01251], lr: 0.000001, loss: 2.9654
2022-10-09 16:30:47 - train: epoch 0100, iter [00930, 01251], lr: 0.000001, loss: 2.6266
2022-10-09 16:31:09 - train: epoch 0100, iter [00940, 01251], lr: 0.000001, loss: 2.3008
2022-10-09 16:31:30 - train: epoch 0100, iter [00950, 01251], lr: 0.000001, loss: 2.3593
2022-10-09 16:31:51 - train: epoch 0100, iter [00960, 01251], lr: 0.000001, loss: 3.1562
2022-10-09 16:32:13 - train: epoch 0100, iter [00970, 01251], lr: 0.000001, loss: 2.9900
2022-10-09 16:32:34 - train: epoch 0100, iter [00980, 01251], lr: 0.000001, loss: 2.9399
2022-10-09 16:32:55 - train: epoch 0100, iter [00990, 01251], lr: 0.000001, loss: 2.8278
2022-10-09 16:33:16 - train: epoch 0100, iter [01000, 01251], lr: 0.000001, loss: 2.9106
2022-10-09 16:33:38 - train: epoch 0100, iter [01010, 01251], lr: 0.000001, loss: 2.6750
2022-10-09 16:33:59 - train: epoch 0100, iter [01020, 01251], lr: 0.000001, loss: 2.6596
2022-10-09 16:34:20 - train: epoch 0100, iter [01030, 01251], lr: 0.000001, loss: 2.3634
2022-10-09 16:34:41 - train: epoch 0100, iter [01040, 01251], lr: 0.000001, loss: 3.0458
2022-10-09 16:35:03 - train: epoch 0100, iter [01050, 01251], lr: 0.000001, loss: 2.1694
2022-10-09 16:35:24 - train: epoch 0100, iter [01060, 01251], lr: 0.000001, loss: 2.9876
2022-10-09 16:35:45 - train: epoch 0100, iter [01070, 01251], lr: 0.000001, loss: 3.1569
2022-10-09 16:36:06 - train: epoch 0100, iter [01080, 01251], lr: 0.000001, loss: 2.8665
2022-10-09 16:36:28 - train: epoch 0100, iter [01090, 01251], lr: 0.000001, loss: 2.8043
2022-10-09 16:36:49 - train: epoch 0100, iter [01100, 01251], lr: 0.000001, loss: 3.1382
2022-10-09 16:37:10 - train: epoch 0100, iter [01110, 01251], lr: 0.000001, loss: 2.8650
2022-10-09 16:37:31 - train: epoch 0100, iter [01120, 01251], lr: 0.000001, loss: 2.7752
2022-10-09 16:37:52 - train: epoch 0100, iter [01130, 01251], lr: 0.000001, loss: 2.9475
2022-10-09 16:38:14 - train: epoch 0100, iter [01140, 01251], lr: 0.000001, loss: 3.2203
2022-10-09 16:38:35 - train: epoch 0100, iter [01150, 01251], lr: 0.000001, loss: 2.4277
2022-10-09 16:38:56 - train: epoch 0100, iter [01160, 01251], lr: 0.000001, loss: 2.0966
2022-10-09 16:39:18 - train: epoch 0100, iter [01170, 01251], lr: 0.000001, loss: 2.9741
2022-10-09 16:39:39 - train: epoch 0100, iter [01180, 01251], lr: 0.000001, loss: 3.2409
2022-10-09 16:40:00 - train: epoch 0100, iter [01190, 01251], lr: 0.000001, loss: 3.1351
2022-10-09 16:40:21 - train: epoch 0100, iter [01200, 01251], lr: 0.000001, loss: 2.6959
2022-10-09 16:40:43 - train: epoch 0100, iter [01210, 01251], lr: 0.000001, loss: 3.0185
2022-10-09 16:41:04 - train: epoch 0100, iter [01220, 01251], lr: 0.000001, loss: 2.3783
2022-10-09 16:41:25 - train: epoch 0100, iter [01230, 01251], lr: 0.000001, loss: 2.5441
2022-10-09 16:41:46 - train: epoch 0100, iter [01240, 01251], lr: 0.000001, loss: 2.7756
2022-10-09 16:42:07 - train: epoch 0100, iter [01250, 01251], lr: 0.000001, loss: 3.0329
2022-10-09 16:42:10 - train: epoch 100, train_loss: 2.7525
2022-10-09 16:43:27 - eval: epoch: 100, acc1: 83.106%, acc5: 96.566%, test_loss: 0.7527, per_image_load_time: 0.355ms, per_image_inference_time: 1.437ms
2022-10-09 16:43:28 - until epoch: 100, best_acc1: 83.130%
2022-10-09 16:43:28 - train done. model: vit_base_patch16, train time: 76.011 hours, best_acc1: 83.130%
