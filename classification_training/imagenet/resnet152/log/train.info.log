2022-07-01 01:34:58 - train: epoch 0040, iter [04500, 05004], lr: 0.010000, loss: 0.8884
2022-07-01 01:35:40 - train: epoch 0040, iter [04600, 05004], lr: 0.010000, loss: 1.0476
2022-07-01 01:36:21 - train: epoch 0040, iter [04700, 05004], lr: 0.010000, loss: 1.0180
2022-07-01 01:37:03 - train: epoch 0040, iter [04800, 05004], lr: 0.010000, loss: 1.0838
2022-07-01 01:37:45 - train: epoch 0040, iter [04900, 05004], lr: 0.010000, loss: 1.1648
2022-07-01 01:38:27 - train: epoch 0040, iter [05000, 05004], lr: 0.010000, loss: 1.1978
2022-07-01 01:38:29 - train: epoch 040, train_loss: 1.0691
2022-07-01 01:39:43 - eval: epoch: 040, acc1: 74.496%, acc5: 92.224%, test_loss: 1.0078, per_image_load_time: 1.997ms, per_image_inference_time: 0.884ms
2022-07-01 01:39:44 - until epoch: 040, best_acc1: 74.676%
2022-07-01 01:39:44 - epoch 041 lr: 0.010000
2022-07-01 01:40:31 - train: epoch 0041, iter [00100, 05004], lr: 0.010000, loss: 1.1314
2022-07-01 01:41:12 - train: epoch 0041, iter [00200, 05004], lr: 0.010000, loss: 1.1170
2022-07-01 01:41:54 - train: epoch 0041, iter [00300, 05004], lr: 0.010000, loss: 1.0369
2022-07-01 01:42:35 - train: epoch 0041, iter [00400, 05004], lr: 0.010000, loss: 1.0396
2022-07-01 01:43:17 - train: epoch 0041, iter [00500, 05004], lr: 0.010000, loss: 0.9150
2022-07-01 01:43:58 - train: epoch 0041, iter [00600, 05004], lr: 0.010000, loss: 1.1073
2022-07-01 01:44:40 - train: epoch 0041, iter [00700, 05004], lr: 0.010000, loss: 0.9917
2022-07-01 01:45:22 - train: epoch 0041, iter [00800, 05004], lr: 0.010000, loss: 0.8136
2022-07-01 01:46:03 - train: epoch 0041, iter [00900, 05004], lr: 0.010000, loss: 0.9107
2022-07-01 01:46:45 - train: epoch 0041, iter [01000, 05004], lr: 0.010000, loss: 1.2542
2022-07-01 01:47:26 - train: epoch 0041, iter [01100, 05004], lr: 0.010000, loss: 0.8804
2022-07-01 01:48:08 - train: epoch 0041, iter [01200, 05004], lr: 0.010000, loss: 0.9008
2022-07-01 01:48:49 - train: epoch 0041, iter [01300, 05004], lr: 0.010000, loss: 1.0843
2022-07-01 01:49:31 - train: epoch 0041, iter [01400, 05004], lr: 0.010000, loss: 1.2081
2022-07-01 01:50:12 - train: epoch 0041, iter [01500, 05004], lr: 0.010000, loss: 1.3296
2022-07-01 01:50:54 - train: epoch 0041, iter [01600, 05004], lr: 0.010000, loss: 0.8969
2022-07-01 01:51:36 - train: epoch 0041, iter [01700, 05004], lr: 0.010000, loss: 1.0662
2022-07-01 01:52:17 - train: epoch 0041, iter [01800, 05004], lr: 0.010000, loss: 1.0914
2022-07-01 01:52:58 - train: epoch 0041, iter [01900, 05004], lr: 0.010000, loss: 1.2544
2022-07-01 01:53:40 - train: epoch 0041, iter [02000, 05004], lr: 0.010000, loss: 0.9783
2022-07-01 01:54:21 - train: epoch 0041, iter [02100, 05004], lr: 0.010000, loss: 0.9936
2022-07-01 01:55:03 - train: epoch 0041, iter [02200, 05004], lr: 0.010000, loss: 0.9571
2022-07-01 01:55:44 - train: epoch 0041, iter [02300, 05004], lr: 0.010000, loss: 0.8999
2022-07-01 01:56:26 - train: epoch 0041, iter [02400, 05004], lr: 0.010000, loss: 1.2318
2022-07-01 01:57:07 - train: epoch 0041, iter [02500, 05004], lr: 0.010000, loss: 0.9866
2022-07-01 01:57:49 - train: epoch 0041, iter [02600, 05004], lr: 0.010000, loss: 1.1840
2022-07-01 01:58:30 - train: epoch 0041, iter [02700, 05004], lr: 0.010000, loss: 1.1885
2022-07-01 01:59:12 - train: epoch 0041, iter [02800, 05004], lr: 0.010000, loss: 1.0717
2022-07-01 01:59:53 - train: epoch 0041, iter [02900, 05004], lr: 0.010000, loss: 1.1483
2022-07-01 02:00:35 - train: epoch 0041, iter [03000, 05004], lr: 0.010000, loss: 1.1690
2022-07-01 02:01:17 - train: epoch 0041, iter [03100, 05004], lr: 0.010000, loss: 1.2298
2022-07-01 02:01:58 - train: epoch 0041, iter [03200, 05004], lr: 0.010000, loss: 0.9245
2022-07-01 02:02:40 - train: epoch 0041, iter [03300, 05004], lr: 0.010000, loss: 0.9518
2022-07-01 02:03:21 - train: epoch 0041, iter [03400, 05004], lr: 0.010000, loss: 1.0207
2022-07-01 02:04:03 - train: epoch 0041, iter [03500, 05004], lr: 0.010000, loss: 1.2063
2022-07-01 02:04:45 - train: epoch 0041, iter [03600, 05004], lr: 0.010000, loss: 1.1193
2022-07-01 02:05:26 - train: epoch 0041, iter [03700, 05004], lr: 0.010000, loss: 1.1412
2022-07-01 02:06:08 - train: epoch 0041, iter [03800, 05004], lr: 0.010000, loss: 1.0012
2022-07-01 02:06:49 - train: epoch 0041, iter [03900, 05004], lr: 0.010000, loss: 1.0826
2022-07-01 02:07:31 - train: epoch 0041, iter [04000, 05004], lr: 0.010000, loss: 0.8663
2022-07-01 02:08:13 - train: epoch 0041, iter [04100, 05004], lr: 0.010000, loss: 1.1052
2022-07-01 02:08:54 - train: epoch 0041, iter [04200, 05004], lr: 0.010000, loss: 1.0226
2022-07-01 02:09:36 - train: epoch 0041, iter [04300, 05004], lr: 0.010000, loss: 1.1069
2022-07-01 02:10:18 - train: epoch 0041, iter [04400, 05004], lr: 0.010000, loss: 1.0070
2022-07-01 02:11:00 - train: epoch 0041, iter [04500, 05004], lr: 0.010000, loss: 1.0861
2022-07-01 02:11:41 - train: epoch 0041, iter [04600, 05004], lr: 0.010000, loss: 1.0957
2022-07-01 02:12:23 - train: epoch 0041, iter [04700, 05004], lr: 0.010000, loss: 1.3385
2022-07-01 02:13:05 - train: epoch 0041, iter [04800, 05004], lr: 0.010000, loss: 1.0485
2022-07-01 02:13:46 - train: epoch 0041, iter [04900, 05004], lr: 0.010000, loss: 1.0112
2022-07-01 02:14:28 - train: epoch 0041, iter [05000, 05004], lr: 0.010000, loss: 1.0880
2022-07-01 02:14:30 - train: epoch 041, train_loss: 1.0667
2022-07-01 02:15:44 - eval: epoch: 041, acc1: 74.076%, acc5: 92.108%, test_loss: 1.0211, per_image_load_time: 1.830ms, per_image_inference_time: 0.896ms
2022-07-01 02:15:45 - until epoch: 041, best_acc1: 74.676%
2022-07-01 02:15:45 - epoch 042 lr: 0.010000
2022-07-01 02:16:33 - train: epoch 0042, iter [00100, 05004], lr: 0.010000, loss: 0.7814
2022-07-01 02:17:14 - train: epoch 0042, iter [00200, 05004], lr: 0.010000, loss: 1.1488
2022-07-01 02:17:56 - train: epoch 0042, iter [00300, 05004], lr: 0.010000, loss: 1.0374
2022-07-01 02:18:38 - train: epoch 0042, iter [00400, 05004], lr: 0.010000, loss: 0.8994
2022-07-01 02:19:19 - train: epoch 0042, iter [00500, 05004], lr: 0.010000, loss: 1.0789
2022-07-01 02:20:01 - train: epoch 0042, iter [00600, 05004], lr: 0.010000, loss: 0.9044
2022-07-01 02:20:42 - train: epoch 0042, iter [00700, 05004], lr: 0.010000, loss: 0.9555
2022-07-01 02:21:24 - train: epoch 0042, iter [00800, 05004], lr: 0.010000, loss: 0.9928
2022-07-01 02:22:06 - train: epoch 0042, iter [00900, 05004], lr: 0.010000, loss: 1.2351
2022-07-01 02:22:47 - train: epoch 0042, iter [01000, 05004], lr: 0.010000, loss: 1.1634
2022-07-01 02:23:29 - train: epoch 0042, iter [01100, 05004], lr: 0.010000, loss: 0.8611
2022-07-01 02:24:10 - train: epoch 0042, iter [01200, 05004], lr: 0.010000, loss: 1.0534
2022-07-01 02:24:52 - train: epoch 0042, iter [01300, 05004], lr: 0.010000, loss: 1.1540
2022-07-01 02:25:33 - train: epoch 0042, iter [01400, 05004], lr: 0.010000, loss: 1.2320
2022-07-01 02:26:15 - train: epoch 0042, iter [01500, 05004], lr: 0.010000, loss: 1.0111
2022-07-01 02:26:56 - train: epoch 0042, iter [01600, 05004], lr: 0.010000, loss: 1.1901
2022-07-01 02:27:38 - train: epoch 0042, iter [01700, 05004], lr: 0.010000, loss: 1.0430
2022-07-01 02:28:19 - train: epoch 0042, iter [01800, 05004], lr: 0.010000, loss: 1.0499
2022-07-01 02:29:01 - train: epoch 0042, iter [01900, 05004], lr: 0.010000, loss: 1.1569
2022-07-01 02:29:42 - train: epoch 0042, iter [02000, 05004], lr: 0.010000, loss: 0.9812
2022-07-01 02:30:24 - train: epoch 0042, iter [02100, 05004], lr: 0.010000, loss: 0.8912
2022-07-01 02:31:05 - train: epoch 0042, iter [02200, 05004], lr: 0.010000, loss: 0.9574
2022-07-01 02:31:47 - train: epoch 0042, iter [02300, 05004], lr: 0.010000, loss: 1.0342
2022-07-01 02:32:28 - train: epoch 0042, iter [02400, 05004], lr: 0.010000, loss: 1.3403
2022-07-01 02:33:10 - train: epoch 0042, iter [02500, 05004], lr: 0.010000, loss: 1.1658
2022-07-01 02:33:51 - train: epoch 0042, iter [02600, 05004], lr: 0.010000, loss: 1.1910
2022-07-01 02:34:33 - train: epoch 0042, iter [02700, 05004], lr: 0.010000, loss: 0.9113
2022-07-01 02:35:15 - train: epoch 0042, iter [02800, 05004], lr: 0.010000, loss: 0.9620
2022-07-01 02:35:56 - train: epoch 0042, iter [02900, 05004], lr: 0.010000, loss: 0.9900
2022-07-01 02:36:38 - train: epoch 0042, iter [03000, 05004], lr: 0.010000, loss: 1.0698
2022-07-01 02:37:19 - train: epoch 0042, iter [03100, 05004], lr: 0.010000, loss: 1.0306
2022-07-01 02:38:01 - train: epoch 0042, iter [03200, 05004], lr: 0.010000, loss: 1.0889
2022-07-01 02:38:42 - train: epoch 0042, iter [03300, 05004], lr: 0.010000, loss: 1.1884
2022-07-01 02:39:24 - train: epoch 0042, iter [03400, 05004], lr: 0.010000, loss: 0.9571
2022-07-01 02:40:06 - train: epoch 0042, iter [03500, 05004], lr: 0.010000, loss: 1.0272
2022-07-01 02:40:48 - train: epoch 0042, iter [03600, 05004], lr: 0.010000, loss: 1.2111
2022-07-01 02:41:29 - train: epoch 0042, iter [03700, 05004], lr: 0.010000, loss: 1.0631
2022-07-01 02:42:11 - train: epoch 0042, iter [03800, 05004], lr: 0.010000, loss: 0.8763
2022-07-01 02:42:53 - train: epoch 0042, iter [03900, 05004], lr: 0.010000, loss: 0.9328
2022-07-01 02:43:34 - train: epoch 0042, iter [04000, 05004], lr: 0.010000, loss: 1.1097
2022-07-01 02:44:16 - train: epoch 0042, iter [04100, 05004], lr: 0.010000, loss: 1.1343
2022-07-01 02:44:57 - train: epoch 0042, iter [04200, 05004], lr: 0.010000, loss: 1.0923
2022-07-01 02:45:39 - train: epoch 0042, iter [04300, 05004], lr: 0.010000, loss: 0.9670
2022-07-01 02:46:21 - train: epoch 0042, iter [04400, 05004], lr: 0.010000, loss: 1.0124
2022-07-01 02:47:02 - train: epoch 0042, iter [04500, 05004], lr: 0.010000, loss: 1.0990
2022-07-01 02:47:44 - train: epoch 0042, iter [04600, 05004], lr: 0.010000, loss: 1.2775
2022-07-01 02:48:26 - train: epoch 0042, iter [04700, 05004], lr: 0.010000, loss: 1.0146
2022-07-01 02:49:07 - train: epoch 0042, iter [04800, 05004], lr: 0.010000, loss: 1.1214
2022-07-01 02:49:49 - train: epoch 0042, iter [04900, 05004], lr: 0.010000, loss: 1.0687
2022-07-01 02:50:31 - train: epoch 0042, iter [05000, 05004], lr: 0.010000, loss: 1.0197
2022-07-01 02:50:33 - train: epoch 042, train_loss: 1.0615
2022-07-01 02:51:47 - eval: epoch: 042, acc1: 74.142%, acc5: 92.134%, test_loss: 1.0230, per_image_load_time: 1.173ms, per_image_inference_time: 0.877ms
2022-07-01 02:51:48 - until epoch: 042, best_acc1: 74.676%
2022-07-01 02:51:48 - epoch 043 lr: 0.010000
2022-07-01 02:52:36 - train: epoch 0043, iter [00100, 05004], lr: 0.010000, loss: 1.0627
2022-07-01 02:53:17 - train: epoch 0043, iter [00200, 05004], lr: 0.010000, loss: 1.1170
2022-07-01 02:53:59 - train: epoch 0043, iter [00300, 05004], lr: 0.010000, loss: 0.8454
2022-07-01 02:54:40 - train: epoch 0043, iter [00400, 05004], lr: 0.010000, loss: 0.9732
2022-07-01 02:55:22 - train: epoch 0043, iter [00500, 05004], lr: 0.010000, loss: 1.1486
2022-07-01 02:56:04 - train: epoch 0043, iter [00600, 05004], lr: 0.010000, loss: 0.9807
2022-07-01 02:56:45 - train: epoch 0043, iter [00700, 05004], lr: 0.010000, loss: 1.1805
2022-07-01 02:57:27 - train: epoch 0043, iter [00800, 05004], lr: 0.010000, loss: 1.2011
2022-07-01 02:58:09 - train: epoch 0043, iter [00900, 05004], lr: 0.010000, loss: 0.9956
2022-07-01 02:58:50 - train: epoch 0043, iter [01000, 05004], lr: 0.010000, loss: 1.1072
2022-07-01 02:59:32 - train: epoch 0043, iter [01100, 05004], lr: 0.010000, loss: 1.2079
2022-07-01 03:00:13 - train: epoch 0043, iter [01200, 05004], lr: 0.010000, loss: 1.2028
2022-07-01 03:00:55 - train: epoch 0043, iter [01300, 05004], lr: 0.010000, loss: 1.0507
2022-07-01 03:01:37 - train: epoch 0043, iter [01400, 05004], lr: 0.010000, loss: 1.0800
2022-07-01 03:02:18 - train: epoch 0043, iter [01500, 05004], lr: 0.010000, loss: 0.9981
2022-07-01 03:03:00 - train: epoch 0043, iter [01600, 05004], lr: 0.010000, loss: 1.0958
2022-07-01 03:03:42 - train: epoch 0043, iter [01700, 05004], lr: 0.010000, loss: 1.1356
2022-07-01 03:04:23 - train: epoch 0043, iter [01800, 05004], lr: 0.010000, loss: 1.1160
2022-07-01 03:05:05 - train: epoch 0043, iter [01900, 05004], lr: 0.010000, loss: 1.1419
2022-07-01 03:05:46 - train: epoch 0043, iter [02000, 05004], lr: 0.010000, loss: 0.8658
2022-07-01 03:06:28 - train: epoch 0043, iter [02100, 05004], lr: 0.010000, loss: 1.0369
2022-07-01 03:07:10 - train: epoch 0043, iter [02200, 05004], lr: 0.010000, loss: 1.0703
2022-07-01 03:07:52 - train: epoch 0043, iter [02300, 05004], lr: 0.010000, loss: 1.2098
2022-07-01 03:08:34 - train: epoch 0043, iter [02400, 05004], lr: 0.010000, loss: 0.8924
2022-07-01 03:09:15 - train: epoch 0043, iter [02500, 05004], lr: 0.010000, loss: 1.2700
2022-07-01 03:09:57 - train: epoch 0043, iter [02600, 05004], lr: 0.010000, loss: 0.8091
2022-07-01 03:10:39 - train: epoch 0043, iter [02700, 05004], lr: 0.010000, loss: 1.0208
2022-07-01 03:11:20 - train: epoch 0043, iter [02800, 05004], lr: 0.010000, loss: 1.0188
2022-07-01 03:12:02 - train: epoch 0043, iter [02900, 05004], lr: 0.010000, loss: 1.1492
2022-07-01 03:12:44 - train: epoch 0043, iter [03000, 05004], lr: 0.010000, loss: 1.2462
2022-07-01 03:13:26 - train: epoch 0043, iter [03100, 05004], lr: 0.010000, loss: 1.2342
2022-07-01 03:14:08 - train: epoch 0043, iter [03200, 05004], lr: 0.010000, loss: 1.1667
2022-07-01 03:14:50 - train: epoch 0043, iter [03300, 05004], lr: 0.010000, loss: 1.1258
2022-07-01 03:15:32 - train: epoch 0043, iter [03400, 05004], lr: 0.010000, loss: 1.0998
2022-07-01 03:16:14 - train: epoch 0043, iter [03500, 05004], lr: 0.010000, loss: 1.1197
2022-07-01 03:16:56 - train: epoch 0043, iter [03600, 05004], lr: 0.010000, loss: 1.0142
2022-07-01 03:17:38 - train: epoch 0043, iter [03700, 05004], lr: 0.010000, loss: 1.0717
2022-07-01 03:18:20 - train: epoch 0043, iter [03800, 05004], lr: 0.010000, loss: 1.1493
2022-07-01 03:19:01 - train: epoch 0043, iter [03900, 05004], lr: 0.010000, loss: 1.2095
2022-07-01 03:19:43 - train: epoch 0043, iter [04000, 05004], lr: 0.010000, loss: 1.0953
2022-07-01 03:20:25 - train: epoch 0043, iter [04100, 05004], lr: 0.010000, loss: 1.2656
2022-07-01 03:21:07 - train: epoch 0043, iter [04200, 05004], lr: 0.010000, loss: 1.1313
2022-07-01 03:21:49 - train: epoch 0043, iter [04300, 05004], lr: 0.010000, loss: 1.0815
2022-07-01 03:22:31 - train: epoch 0043, iter [04400, 05004], lr: 0.010000, loss: 1.0570
2022-07-01 03:23:13 - train: epoch 0043, iter [04500, 05004], lr: 0.010000, loss: 1.0717
2022-07-01 03:23:55 - train: epoch 0043, iter [04600, 05004], lr: 0.010000, loss: 1.1430
2022-07-01 03:24:37 - train: epoch 0043, iter [04700, 05004], lr: 0.010000, loss: 0.9763
2022-07-01 03:25:19 - train: epoch 0043, iter [04800, 05004], lr: 0.010000, loss: 1.0040
2022-07-01 03:26:01 - train: epoch 0043, iter [04900, 05004], lr: 0.010000, loss: 0.9239
2022-07-01 03:26:43 - train: epoch 0043, iter [05000, 05004], lr: 0.010000, loss: 0.9916
2022-07-01 03:26:45 - train: epoch 043, train_loss: 1.0602
2022-07-01 03:27:58 - eval: epoch: 043, acc1: 73.914%, acc5: 92.200%, test_loss: 1.0253, per_image_load_time: 1.527ms, per_image_inference_time: 0.889ms
2022-07-01 03:27:59 - until epoch: 043, best_acc1: 74.676%
2022-07-01 03:27:59 - epoch 044 lr: 0.010000
2022-07-01 03:28:46 - train: epoch 0044, iter [00100, 05004], lr: 0.010000, loss: 1.1191
2022-07-01 03:29:28 - train: epoch 0044, iter [00200, 05004], lr: 0.010000, loss: 1.0169
2022-07-01 03:30:09 - train: epoch 0044, iter [00300, 05004], lr: 0.010000, loss: 1.0911
2022-07-01 03:30:50 - train: epoch 0044, iter [00400, 05004], lr: 0.010000, loss: 0.8966
2022-07-01 03:31:32 - train: epoch 0044, iter [00500, 05004], lr: 0.010000, loss: 0.9950
2022-07-01 03:32:13 - train: epoch 0044, iter [00600, 05004], lr: 0.010000, loss: 0.8876
2022-07-01 03:32:55 - train: epoch 0044, iter [00700, 05004], lr: 0.010000, loss: 0.7925
2022-07-01 03:33:36 - train: epoch 0044, iter [00800, 05004], lr: 0.010000, loss: 0.9422
2022-07-01 03:34:18 - train: epoch 0044, iter [00900, 05004], lr: 0.010000, loss: 1.0643
2022-07-01 03:34:59 - train: epoch 0044, iter [01000, 05004], lr: 0.010000, loss: 1.0698
2022-07-01 03:35:41 - train: epoch 0044, iter [01100, 05004], lr: 0.010000, loss: 1.0334
2022-07-01 03:36:23 - train: epoch 0044, iter [01200, 05004], lr: 0.010000, loss: 0.8853
2022-07-01 03:37:04 - train: epoch 0044, iter [01300, 05004], lr: 0.010000, loss: 1.0781
2022-07-01 03:37:46 - train: epoch 0044, iter [01400, 05004], lr: 0.010000, loss: 0.9270
2022-07-01 03:38:27 - train: epoch 0044, iter [01500, 05004], lr: 0.010000, loss: 0.9396
2022-07-01 03:39:09 - train: epoch 0044, iter [01600, 05004], lr: 0.010000, loss: 1.0015
2022-07-01 03:39:51 - train: epoch 0044, iter [01700, 05004], lr: 0.010000, loss: 1.0698
2022-07-01 03:40:32 - train: epoch 0044, iter [01800, 05004], lr: 0.010000, loss: 1.1074
2022-07-01 03:41:14 - train: epoch 0044, iter [01900, 05004], lr: 0.010000, loss: 1.1857
2022-07-01 03:41:55 - train: epoch 0044, iter [02000, 05004], lr: 0.010000, loss: 0.9685
2022-07-01 03:42:37 - train: epoch 0044, iter [02100, 05004], lr: 0.010000, loss: 1.1613
2022-07-01 03:43:18 - train: epoch 0044, iter [02200, 05004], lr: 0.010000, loss: 0.9971
2022-07-01 03:44:00 - train: epoch 0044, iter [02300, 05004], lr: 0.010000, loss: 1.2253
2022-07-01 03:44:41 - train: epoch 0044, iter [02400, 05004], lr: 0.010000, loss: 1.0171
2022-07-01 03:45:23 - train: epoch 0044, iter [02500, 05004], lr: 0.010000, loss: 1.1359
2022-07-01 03:46:04 - train: epoch 0044, iter [02600, 05004], lr: 0.010000, loss: 1.0081
2022-07-01 03:46:46 - train: epoch 0044, iter [02700, 05004], lr: 0.010000, loss: 1.1315
2022-07-01 03:47:28 - train: epoch 0044, iter [02800, 05004], lr: 0.010000, loss: 0.8440
2022-07-01 03:48:09 - train: epoch 0044, iter [02900, 05004], lr: 0.010000, loss: 0.9402
2022-07-01 03:48:51 - train: epoch 0044, iter [03000, 05004], lr: 0.010000, loss: 0.8901
2022-07-01 03:49:32 - train: epoch 0044, iter [03100, 05004], lr: 0.010000, loss: 1.1227
2022-07-01 03:50:13 - train: epoch 0044, iter [03200, 05004], lr: 0.010000, loss: 0.8136
2022-07-01 03:50:55 - train: epoch 0044, iter [03300, 05004], lr: 0.010000, loss: 0.9902
2022-07-01 03:51:37 - train: epoch 0044, iter [03400, 05004], lr: 0.010000, loss: 1.2948
2022-07-01 03:52:18 - train: epoch 0044, iter [03500, 05004], lr: 0.010000, loss: 1.0088
2022-07-01 03:53:00 - train: epoch 0044, iter [03600, 05004], lr: 0.010000, loss: 1.2986
2022-07-01 03:53:41 - train: epoch 0044, iter [03700, 05004], lr: 0.010000, loss: 1.1672
2022-07-01 03:54:23 - train: epoch 0044, iter [03800, 05004], lr: 0.010000, loss: 0.8931
2022-07-01 03:55:04 - train: epoch 0044, iter [03900, 05004], lr: 0.010000, loss: 1.1985
2022-07-01 03:55:46 - train: epoch 0044, iter [04000, 05004], lr: 0.010000, loss: 1.1042
2022-07-01 03:56:28 - train: epoch 0044, iter [04100, 05004], lr: 0.010000, loss: 0.9725
2022-07-01 03:57:09 - train: epoch 0044, iter [04200, 05004], lr: 0.010000, loss: 1.1796
2022-07-01 03:57:51 - train: epoch 0044, iter [04300, 05004], lr: 0.010000, loss: 1.3003
2022-07-01 03:58:33 - train: epoch 0044, iter [04400, 05004], lr: 0.010000, loss: 1.0123
2022-07-01 03:59:14 - train: epoch 0044, iter [04500, 05004], lr: 0.010000, loss: 1.1115
2022-07-01 03:59:56 - train: epoch 0044, iter [04600, 05004], lr: 0.010000, loss: 1.2060
2022-07-01 04:00:38 - train: epoch 0044, iter [04700, 05004], lr: 0.010000, loss: 1.1541
2022-07-01 04:01:19 - train: epoch 0044, iter [04800, 05004], lr: 0.010000, loss: 1.3039
2022-07-01 04:02:01 - train: epoch 0044, iter [04900, 05004], lr: 0.010000, loss: 0.8414
2022-07-01 04:02:43 - train: epoch 0044, iter [05000, 05004], lr: 0.010000, loss: 1.1504
2022-07-01 04:02:45 - train: epoch 044, train_loss: 1.0611
2022-07-01 04:03:59 - eval: epoch: 044, acc1: 74.058%, acc5: 91.900%, test_loss: 1.0345, per_image_load_time: 1.927ms, per_image_inference_time: 0.889ms
2022-07-01 04:04:00 - until epoch: 044, best_acc1: 74.676%
2022-07-01 04:04:00 - epoch 045 lr: 0.010000
2022-07-01 04:04:47 - train: epoch 0045, iter [00100, 05004], lr: 0.010000, loss: 0.9099
2022-07-01 04:05:28 - train: epoch 0045, iter [00200, 05004], lr: 0.010000, loss: 1.0577
2022-07-01 04:06:10 - train: epoch 0045, iter [00300, 05004], lr: 0.010000, loss: 1.1216
2022-07-01 04:06:51 - train: epoch 0045, iter [00400, 05004], lr: 0.010000, loss: 0.9279
2022-07-01 04:07:33 - train: epoch 0045, iter [00500, 05004], lr: 0.010000, loss: 1.1736
2022-07-01 04:08:15 - train: epoch 0045, iter [00600, 05004], lr: 0.010000, loss: 1.0344
2022-07-01 04:08:56 - train: epoch 0045, iter [00700, 05004], lr: 0.010000, loss: 0.8506
2022-07-01 04:09:38 - train: epoch 0045, iter [00800, 05004], lr: 0.010000, loss: 0.9394
2022-07-01 04:10:19 - train: epoch 0045, iter [00900, 05004], lr: 0.010000, loss: 1.0462
2022-07-01 04:11:01 - train: epoch 0045, iter [01000, 05004], lr: 0.010000, loss: 1.0185
2022-07-01 04:11:43 - train: epoch 0045, iter [01100, 05004], lr: 0.010000, loss: 1.1107
2022-07-01 04:12:24 - train: epoch 0045, iter [01200, 05004], lr: 0.010000, loss: 1.1097
2022-07-01 04:13:06 - train: epoch 0045, iter [01300, 05004], lr: 0.010000, loss: 1.1368
2022-07-01 04:13:47 - train: epoch 0045, iter [01400, 05004], lr: 0.010000, loss: 1.0367
2022-07-01 04:14:29 - train: epoch 0045, iter [01500, 05004], lr: 0.010000, loss: 1.1397
2022-07-01 04:15:11 - train: epoch 0045, iter [01600, 05004], lr: 0.010000, loss: 1.0064
2022-07-01 04:15:52 - train: epoch 0045, iter [01700, 05004], lr: 0.010000, loss: 0.9312
2022-07-01 04:16:34 - train: epoch 0045, iter [01800, 05004], lr: 0.010000, loss: 0.8754
2022-07-01 04:17:16 - train: epoch 0045, iter [01900, 05004], lr: 0.010000, loss: 1.0707
2022-07-01 04:17:57 - train: epoch 0045, iter [02000, 05004], lr: 0.010000, loss: 0.9718
2022-07-01 04:18:39 - train: epoch 0045, iter [02100, 05004], lr: 0.010000, loss: 1.2360
2022-07-01 04:19:21 - train: epoch 0045, iter [02200, 05004], lr: 0.010000, loss: 1.1271
2022-07-01 04:20:02 - train: epoch 0045, iter [02300, 05004], lr: 0.010000, loss: 0.9566
2022-07-01 04:20:44 - train: epoch 0045, iter [02400, 05004], lr: 0.010000, loss: 1.1995
2022-07-01 04:21:26 - train: epoch 0045, iter [02500, 05004], lr: 0.010000, loss: 1.2000
2022-07-01 04:22:08 - train: epoch 0045, iter [02600, 05004], lr: 0.010000, loss: 1.0016
2022-07-01 04:22:49 - train: epoch 0045, iter [02700, 05004], lr: 0.010000, loss: 0.9475
2022-07-01 04:23:31 - train: epoch 0045, iter [02800, 05004], lr: 0.010000, loss: 1.0828
2022-07-01 04:24:12 - train: epoch 0045, iter [02900, 05004], lr: 0.010000, loss: 1.1167
2022-07-01 04:24:54 - train: epoch 0045, iter [03000, 05004], lr: 0.010000, loss: 1.1862
2022-07-01 04:25:36 - train: epoch 0045, iter [03100, 05004], lr: 0.010000, loss: 1.0703
2022-07-01 04:26:17 - train: epoch 0045, iter [03200, 05004], lr: 0.010000, loss: 1.0893
2022-07-01 04:26:59 - train: epoch 0045, iter [03300, 05004], lr: 0.010000, loss: 1.1489
2022-07-01 04:27:41 - train: epoch 0045, iter [03400, 05004], lr: 0.010000, loss: 0.8599
2022-07-01 04:28:23 - train: epoch 0045, iter [03500, 05004], lr: 0.010000, loss: 1.2041
2022-07-01 04:29:04 - train: epoch 0045, iter [03600, 05004], lr: 0.010000, loss: 1.0972
2022-07-01 04:29:46 - train: epoch 0045, iter [03700, 05004], lr: 0.010000, loss: 1.0216
2022-07-01 04:30:28 - train: epoch 0045, iter [03800, 05004], lr: 0.010000, loss: 0.9101
2022-07-01 04:31:10 - train: epoch 0045, iter [03900, 05004], lr: 0.010000, loss: 1.1919
2022-07-01 04:31:51 - train: epoch 0045, iter [04000, 05004], lr: 0.010000, loss: 1.1710
2022-07-01 04:32:33 - train: epoch 0045, iter [04100, 05004], lr: 0.010000, loss: 0.9452
2022-07-01 04:33:15 - train: epoch 0045, iter [04200, 05004], lr: 0.010000, loss: 1.2213
2022-07-01 04:33:57 - train: epoch 0045, iter [04300, 05004], lr: 0.010000, loss: 1.2634
2022-07-01 04:34:38 - train: epoch 0045, iter [04400, 05004], lr: 0.010000, loss: 1.1560
2022-07-01 04:35:20 - train: epoch 0045, iter [04500, 05004], lr: 0.010000, loss: 0.9947
2022-07-01 04:36:02 - train: epoch 0045, iter [04600, 05004], lr: 0.010000, loss: 1.2024
2022-07-01 04:36:44 - train: epoch 0045, iter [04700, 05004], lr: 0.010000, loss: 1.1355
2022-07-01 04:37:25 - train: epoch 0045, iter [04800, 05004], lr: 0.010000, loss: 0.9914
2022-07-01 04:38:07 - train: epoch 0045, iter [04900, 05004], lr: 0.010000, loss: 1.0893
2022-07-01 04:38:49 - train: epoch 0045, iter [05000, 05004], lr: 0.010000, loss: 1.0339
2022-07-01 04:38:51 - train: epoch 045, train_loss: 1.0515
2022-07-01 04:40:05 - eval: epoch: 045, acc1: 73.818%, acc5: 92.144%, test_loss: 1.0321, per_image_load_time: 1.224ms, per_image_inference_time: 0.920ms
2022-07-01 04:40:05 - until epoch: 045, best_acc1: 74.676%
2022-07-01 04:40:05 - epoch 046 lr: 0.010000
2022-07-01 04:40:53 - train: epoch 0046, iter [00100, 05004], lr: 0.010000, loss: 0.8997
2022-07-01 04:41:34 - train: epoch 0046, iter [00200, 05004], lr: 0.010000, loss: 1.0183
2022-07-01 04:42:16 - train: epoch 0046, iter [00300, 05004], lr: 0.010000, loss: 1.0801
2022-07-01 04:42:57 - train: epoch 0046, iter [00400, 05004], lr: 0.010000, loss: 1.1301
2022-07-01 04:43:39 - train: epoch 0046, iter [00500, 05004], lr: 0.010000, loss: 0.8895
2022-07-01 04:44:21 - train: epoch 0046, iter [00600, 05004], lr: 0.010000, loss: 1.1700
2022-07-01 04:45:02 - train: epoch 0046, iter [00700, 05004], lr: 0.010000, loss: 1.0268
2022-07-01 04:45:44 - train: epoch 0046, iter [00800, 05004], lr: 0.010000, loss: 1.0757
2022-07-01 04:46:25 - train: epoch 0046, iter [00900, 05004], lr: 0.010000, loss: 1.1171
2022-07-01 04:47:07 - train: epoch 0046, iter [01000, 05004], lr: 0.010000, loss: 0.8815
2022-07-01 04:47:49 - train: epoch 0046, iter [01100, 05004], lr: 0.010000, loss: 0.9495
2022-07-01 04:48:30 - train: epoch 0046, iter [01200, 05004], lr: 0.010000, loss: 1.1312
2022-07-01 04:49:12 - train: epoch 0046, iter [01300, 05004], lr: 0.010000, loss: 1.0301
2022-07-01 04:49:54 - train: epoch 0046, iter [01400, 05004], lr: 0.010000, loss: 1.0996
2022-07-01 04:50:35 - train: epoch 0046, iter [01500, 05004], lr: 0.010000, loss: 1.0159
2022-07-01 04:51:17 - train: epoch 0046, iter [01600, 05004], lr: 0.010000, loss: 1.0705
2022-07-01 04:51:59 - train: epoch 0046, iter [01700, 05004], lr: 0.010000, loss: 0.9250
2022-07-01 04:52:41 - train: epoch 0046, iter [01800, 05004], lr: 0.010000, loss: 1.1291
2022-07-01 04:53:22 - train: epoch 0046, iter [01900, 05004], lr: 0.010000, loss: 0.8939
2022-07-01 04:54:04 - train: epoch 0046, iter [02000, 05004], lr: 0.010000, loss: 1.0207
2022-07-01 04:54:46 - train: epoch 0046, iter [02100, 05004], lr: 0.010000, loss: 1.2646
2022-07-01 04:55:28 - train: epoch 0046, iter [02200, 05004], lr: 0.010000, loss: 0.9437
2022-07-01 04:56:10 - train: epoch 0046, iter [02300, 05004], lr: 0.010000, loss: 1.2058
2022-07-01 04:56:51 - train: epoch 0046, iter [02400, 05004], lr: 0.010000, loss: 1.0116
2022-07-01 04:57:33 - train: epoch 0046, iter [02500, 05004], lr: 0.010000, loss: 1.0646
2022-07-01 04:58:15 - train: epoch 0046, iter [02600, 05004], lr: 0.010000, loss: 1.2095
2022-07-01 04:58:57 - train: epoch 0046, iter [02700, 05004], lr: 0.010000, loss: 0.9656
2022-07-01 04:59:39 - train: epoch 0046, iter [02800, 05004], lr: 0.010000, loss: 0.8686
2022-07-01 05:00:21 - train: epoch 0046, iter [02900, 05004], lr: 0.010000, loss: 1.0986
2022-07-01 05:01:02 - train: epoch 0046, iter [03000, 05004], lr: 0.010000, loss: 0.9090
2022-07-01 05:01:44 - train: epoch 0046, iter [03100, 05004], lr: 0.010000, loss: 0.9792
2022-07-01 05:02:26 - train: epoch 0046, iter [03200, 05004], lr: 0.010000, loss: 1.3361
2022-07-01 05:03:08 - train: epoch 0046, iter [03300, 05004], lr: 0.010000, loss: 1.0622
2022-07-01 05:03:50 - train: epoch 0046, iter [03400, 05004], lr: 0.010000, loss: 1.0644
2022-07-01 05:04:32 - train: epoch 0046, iter [03500, 05004], lr: 0.010000, loss: 0.9845
2022-07-01 05:05:13 - train: epoch 0046, iter [03600, 05004], lr: 0.010000, loss: 0.9249
2022-07-01 05:05:55 - train: epoch 0046, iter [03700, 05004], lr: 0.010000, loss: 0.9756
2022-07-01 05:06:37 - train: epoch 0046, iter [03800, 05004], lr: 0.010000, loss: 1.1515
2022-07-01 05:07:19 - train: epoch 0046, iter [03900, 05004], lr: 0.010000, loss: 1.2008
2022-07-01 05:08:01 - train: epoch 0046, iter [04000, 05004], lr: 0.010000, loss: 0.9528
2022-07-01 05:08:43 - train: epoch 0046, iter [04100, 05004], lr: 0.010000, loss: 1.1799
2022-07-01 05:09:24 - train: epoch 0046, iter [04200, 05004], lr: 0.010000, loss: 1.0030
2022-07-01 05:10:06 - train: epoch 0046, iter [04300, 05004], lr: 0.010000, loss: 1.1947
2022-07-01 05:10:48 - train: epoch 0046, iter [04400, 05004], lr: 0.010000, loss: 1.0264
2022-07-01 05:11:30 - train: epoch 0046, iter [04500, 05004], lr: 0.010000, loss: 0.9705
2022-07-01 05:12:12 - train: epoch 0046, iter [04600, 05004], lr: 0.010000, loss: 1.1612
2022-07-01 05:12:53 - train: epoch 0046, iter [04700, 05004], lr: 0.010000, loss: 1.0101
2022-07-01 05:13:35 - train: epoch 0046, iter [04800, 05004], lr: 0.010000, loss: 1.0190
2022-07-01 05:14:17 - train: epoch 0046, iter [04900, 05004], lr: 0.010000, loss: 1.1168
2022-07-01 05:14:58 - train: epoch 0046, iter [05000, 05004], lr: 0.010000, loss: 0.9199
2022-07-01 05:15:00 - train: epoch 046, train_loss: 1.0486
2022-07-01 05:16:13 - eval: epoch: 046, acc1: 73.876%, acc5: 91.962%, test_loss: 1.0275, per_image_load_time: 1.859ms, per_image_inference_time: 0.917ms
2022-07-01 05:16:14 - until epoch: 046, best_acc1: 74.676%
2022-07-01 05:16:14 - epoch 047 lr: 0.010000
2022-07-01 05:17:02 - train: epoch 0047, iter [00100, 05004], lr: 0.010000, loss: 0.9547
2022-07-01 05:17:43 - train: epoch 0047, iter [00200, 05004], lr: 0.010000, loss: 1.1489
2022-07-01 05:18:25 - train: epoch 0047, iter [00300, 05004], lr: 0.010000, loss: 0.8520
2022-07-01 05:19:06 - train: epoch 0047, iter [00400, 05004], lr: 0.010000, loss: 1.0045
2022-07-01 05:19:48 - train: epoch 0047, iter [00500, 05004], lr: 0.010000, loss: 1.1463
2022-07-01 05:20:29 - train: epoch 0047, iter [00600, 05004], lr: 0.010000, loss: 1.0172
2022-07-01 05:21:11 - train: epoch 0047, iter [00700, 05004], lr: 0.010000, loss: 1.1511
2022-07-01 05:21:53 - train: epoch 0047, iter [00800, 05004], lr: 0.010000, loss: 0.9451
2022-07-01 05:22:34 - train: epoch 0047, iter [00900, 05004], lr: 0.010000, loss: 1.1824
2022-07-01 05:23:16 - train: epoch 0047, iter [01000, 05004], lr: 0.010000, loss: 1.1110
2022-07-01 05:23:57 - train: epoch 0047, iter [01100, 05004], lr: 0.010000, loss: 1.1361
2022-07-01 05:24:38 - train: epoch 0047, iter [01200, 05004], lr: 0.010000, loss: 0.9031
2022-07-01 05:25:20 - train: epoch 0047, iter [01300, 05004], lr: 0.010000, loss: 1.0296
2022-07-01 05:26:01 - train: epoch 0047, iter [01400, 05004], lr: 0.010000, loss: 1.0676
2022-07-01 05:26:43 - train: epoch 0047, iter [01500, 05004], lr: 0.010000, loss: 0.8878
2022-07-01 05:27:25 - train: epoch 0047, iter [01600, 05004], lr: 0.010000, loss: 0.9120
2022-07-01 05:28:06 - train: epoch 0047, iter [01700, 05004], lr: 0.010000, loss: 0.8780
2022-07-01 05:28:48 - train: epoch 0047, iter [01800, 05004], lr: 0.010000, loss: 1.0816
2022-07-01 05:29:29 - train: epoch 0047, iter [01900, 05004], lr: 0.010000, loss: 0.9719
2022-07-01 05:30:11 - train: epoch 0047, iter [02000, 05004], lr: 0.010000, loss: 0.9626
2022-07-01 05:30:53 - train: epoch 0047, iter [02100, 05004], lr: 0.010000, loss: 1.2051
2022-07-01 05:31:34 - train: epoch 0047, iter [02200, 05004], lr: 0.010000, loss: 1.2033
2022-07-01 05:32:16 - train: epoch 0047, iter [02300, 05004], lr: 0.010000, loss: 1.1469
2022-07-01 05:32:57 - train: epoch 0047, iter [02400, 05004], lr: 0.010000, loss: 0.8968
2022-07-01 05:33:39 - train: epoch 0047, iter [02500, 05004], lr: 0.010000, loss: 1.0552
2022-07-01 05:34:20 - train: epoch 0047, iter [02600, 05004], lr: 0.010000, loss: 1.3242
2022-07-01 05:35:02 - train: epoch 0047, iter [02700, 05004], lr: 0.010000, loss: 1.1163
2022-07-01 05:35:44 - train: epoch 0047, iter [02800, 05004], lr: 0.010000, loss: 1.1872
2022-07-01 05:36:25 - train: epoch 0047, iter [02900, 05004], lr: 0.010000, loss: 0.9661
2022-07-01 05:37:07 - train: epoch 0047, iter [03000, 05004], lr: 0.010000, loss: 1.0654
2022-07-01 05:37:49 - train: epoch 0047, iter [03100, 05004], lr: 0.010000, loss: 0.9614
2022-07-01 05:38:30 - train: epoch 0047, iter [03200, 05004], lr: 0.010000, loss: 1.2987
2022-07-01 05:39:12 - train: epoch 0047, iter [03300, 05004], lr: 0.010000, loss: 0.8910
2022-07-01 05:39:54 - train: epoch 0047, iter [03400, 05004], lr: 0.010000, loss: 1.0498
2022-07-01 05:40:35 - train: epoch 0047, iter [03500, 05004], lr: 0.010000, loss: 1.2392
2022-07-01 05:41:17 - train: epoch 0047, iter [03600, 05004], lr: 0.010000, loss: 1.0725
2022-07-01 05:41:59 - train: epoch 0047, iter [03700, 05004], lr: 0.010000, loss: 1.1883
2022-07-01 05:42:41 - train: epoch 0047, iter [03800, 05004], lr: 0.010000, loss: 1.0941
2022-07-01 05:43:23 - train: epoch 0047, iter [03900, 05004], lr: 0.010000, loss: 1.0304
2022-07-01 05:44:06 - train: epoch 0047, iter [04000, 05004], lr: 0.010000, loss: 1.1138
2022-07-01 05:44:48 - train: epoch 0047, iter [04100, 05004], lr: 0.010000, loss: 1.0636
2022-07-01 05:45:29 - train: epoch 0047, iter [04200, 05004], lr: 0.010000, loss: 1.0345
2022-07-01 05:46:11 - train: epoch 0047, iter [04300, 05004], lr: 0.010000, loss: 1.0265
2022-07-01 05:46:53 - train: epoch 0047, iter [04400, 05004], lr: 0.010000, loss: 1.0007
2022-07-01 05:47:35 - train: epoch 0047, iter [04500, 05004], lr: 0.010000, loss: 1.2488
2022-07-01 05:48:17 - train: epoch 0047, iter [04600, 05004], lr: 0.010000, loss: 1.1220
2022-07-01 05:48:59 - train: epoch 0047, iter [04700, 05004], lr: 0.010000, loss: 1.1651
2022-07-01 05:49:41 - train: epoch 0047, iter [04800, 05004], lr: 0.010000, loss: 0.9496
2022-07-01 05:50:23 - train: epoch 0047, iter [04900, 05004], lr: 0.010000, loss: 1.0725
2022-07-01 05:51:05 - train: epoch 0047, iter [05000, 05004], lr: 0.010000, loss: 0.9848
2022-07-01 05:51:07 - train: epoch 047, train_loss: 1.0503
2022-07-01 05:52:21 - eval: epoch: 047, acc1: 74.082%, acc5: 92.340%, test_loss: 1.0218, per_image_load_time: 1.949ms, per_image_inference_time: 0.902ms
2022-07-01 05:52:22 - until epoch: 047, best_acc1: 74.676%
2022-07-01 05:52:22 - epoch 048 lr: 0.010000
2022-07-01 05:53:09 - train: epoch 0048, iter [00100, 05004], lr: 0.010000, loss: 1.2320
2022-07-01 05:53:51 - train: epoch 0048, iter [00200, 05004], lr: 0.010000, loss: 1.2829
2022-07-01 05:54:32 - train: epoch 0048, iter [00300, 05004], lr: 0.010000, loss: 1.0016
2022-07-01 05:55:14 - train: epoch 0048, iter [00400, 05004], lr: 0.010000, loss: 1.0469
2022-07-01 05:55:56 - train: epoch 0048, iter [00500, 05004], lr: 0.010000, loss: 0.9254
2022-07-01 05:56:37 - train: epoch 0048, iter [00600, 05004], lr: 0.010000, loss: 1.0594
2022-07-01 05:57:19 - train: epoch 0048, iter [00700, 05004], lr: 0.010000, loss: 1.0263
2022-07-01 05:58:01 - train: epoch 0048, iter [00800, 05004], lr: 0.010000, loss: 1.0666
2022-07-01 05:58:42 - train: epoch 0048, iter [00900, 05004], lr: 0.010000, loss: 1.1590
2022-07-01 05:59:24 - train: epoch 0048, iter [01000, 05004], lr: 0.010000, loss: 1.0835
2022-07-01 06:00:06 - train: epoch 0048, iter [01100, 05004], lr: 0.010000, loss: 1.0566
2022-07-01 06:00:47 - train: epoch 0048, iter [01200, 05004], lr: 0.010000, loss: 1.1645
2022-07-01 06:01:29 - train: epoch 0048, iter [01300, 05004], lr: 0.010000, loss: 0.9130
2022-07-01 06:02:10 - train: epoch 0048, iter [01400, 05004], lr: 0.010000, loss: 0.9539
2022-07-01 06:02:52 - train: epoch 0048, iter [01500, 05004], lr: 0.010000, loss: 1.0531
2022-07-01 06:03:33 - train: epoch 0048, iter [01600, 05004], lr: 0.010000, loss: 0.9721
2022-07-01 06:04:15 - train: epoch 0048, iter [01700, 05004], lr: 0.010000, loss: 1.0783
2022-07-01 06:04:57 - train: epoch 0048, iter [01800, 05004], lr: 0.010000, loss: 1.0848
2022-07-01 06:05:38 - train: epoch 0048, iter [01900, 05004], lr: 0.010000, loss: 1.0326
2022-07-01 06:06:20 - train: epoch 0048, iter [02000, 05004], lr: 0.010000, loss: 1.2260
2022-07-01 06:07:02 - train: epoch 0048, iter [02100, 05004], lr: 0.010000, loss: 1.1591
2022-07-01 06:07:43 - train: epoch 0048, iter [02200, 05004], lr: 0.010000, loss: 1.2508
2022-07-01 06:08:25 - train: epoch 0048, iter [02300, 05004], lr: 0.010000, loss: 1.0007
2022-07-01 06:09:07 - train: epoch 0048, iter [02400, 05004], lr: 0.010000, loss: 1.1755
2022-07-01 06:09:49 - train: epoch 0048, iter [02500, 05004], lr: 0.010000, loss: 1.0636
2022-07-01 06:10:31 - train: epoch 0048, iter [02600, 05004], lr: 0.010000, loss: 1.2799
2022-07-01 06:11:12 - train: epoch 0048, iter [02700, 05004], lr: 0.010000, loss: 1.2242
2022-07-01 06:11:54 - train: epoch 0048, iter [02800, 05004], lr: 0.010000, loss: 0.9728
2022-07-01 06:12:36 - train: epoch 0048, iter [02900, 05004], lr: 0.010000, loss: 1.1455
2022-07-01 06:13:18 - train: epoch 0048, iter [03000, 05004], lr: 0.010000, loss: 0.9974
2022-07-01 06:14:00 - train: epoch 0048, iter [03100, 05004], lr: 0.010000, loss: 0.9527
2022-07-01 06:14:41 - train: epoch 0048, iter [03200, 05004], lr: 0.010000, loss: 0.9651
2022-07-01 06:15:23 - train: epoch 0048, iter [03300, 05004], lr: 0.010000, loss: 1.1314
2022-07-01 06:16:05 - train: epoch 0048, iter [03400, 05004], lr: 0.010000, loss: 0.9391
2022-07-01 06:16:47 - train: epoch 0048, iter [03500, 05004], lr: 0.010000, loss: 1.2997
2022-07-01 06:17:29 - train: epoch 0048, iter [03600, 05004], lr: 0.010000, loss: 1.1193
2022-07-01 06:18:11 - train: epoch 0048, iter [03700, 05004], lr: 0.010000, loss: 1.0957
2022-07-01 06:18:52 - train: epoch 0048, iter [03800, 05004], lr: 0.010000, loss: 0.9375
2022-07-01 06:19:34 - train: epoch 0048, iter [03900, 05004], lr: 0.010000, loss: 1.2617
2022-07-01 06:20:16 - train: epoch 0048, iter [04000, 05004], lr: 0.010000, loss: 0.8639
2022-07-01 06:20:58 - train: epoch 0048, iter [04100, 05004], lr: 0.010000, loss: 1.2039
2022-07-01 06:21:40 - train: epoch 0048, iter [04200, 05004], lr: 0.010000, loss: 1.0539
2022-07-01 06:22:22 - train: epoch 0048, iter [04300, 05004], lr: 0.010000, loss: 1.0613
2022-07-01 06:23:04 - train: epoch 0048, iter [04400, 05004], lr: 0.010000, loss: 0.8966
2022-07-01 06:23:46 - train: epoch 0048, iter [04500, 05004], lr: 0.010000, loss: 1.1329
2022-07-01 06:24:28 - train: epoch 0048, iter [04600, 05004], lr: 0.010000, loss: 0.9024
2022-07-01 06:25:11 - train: epoch 0048, iter [04700, 05004], lr: 0.010000, loss: 1.0696
2022-07-01 06:25:52 - train: epoch 0048, iter [04800, 05004], lr: 0.010000, loss: 1.3645
2022-07-01 06:26:34 - train: epoch 0048, iter [04900, 05004], lr: 0.010000, loss: 1.1555
2022-07-01 06:27:16 - train: epoch 0048, iter [05000, 05004], lr: 0.010000, loss: 1.0803
2022-07-01 06:27:18 - train: epoch 048, train_loss: 1.0483
2022-07-01 06:28:32 - eval: epoch: 048, acc1: 73.956%, acc5: 92.082%, test_loss: 1.0366, per_image_load_time: 1.148ms, per_image_inference_time: 0.891ms
2022-07-01 06:28:32 - until epoch: 048, best_acc1: 74.676%
2022-07-01 06:28:32 - epoch 049 lr: 0.010000
2022-07-01 06:29:20 - train: epoch 0049, iter [00100, 05004], lr: 0.010000, loss: 1.0911
2022-07-01 06:30:02 - train: epoch 0049, iter [00200, 05004], lr: 0.010000, loss: 1.0120
2022-07-01 06:30:44 - train: epoch 0049, iter [00300, 05004], lr: 0.010000, loss: 1.0086
2022-07-01 06:31:26 - train: epoch 0049, iter [00400, 05004], lr: 0.010000, loss: 0.9733
2022-07-01 06:32:07 - train: epoch 0049, iter [00500, 05004], lr: 0.010000, loss: 1.0023
2022-07-01 06:32:49 - train: epoch 0049, iter [00600, 05004], lr: 0.010000, loss: 0.9576
2022-07-01 06:33:31 - train: epoch 0049, iter [00700, 05004], lr: 0.010000, loss: 1.1621
2022-07-01 06:34:13 - train: epoch 0049, iter [00800, 05004], lr: 0.010000, loss: 1.2160
2022-07-01 06:34:55 - train: epoch 0049, iter [00900, 05004], lr: 0.010000, loss: 0.9736
2022-07-01 06:35:37 - train: epoch 0049, iter [01000, 05004], lr: 0.010000, loss: 1.0795
2022-07-01 06:36:18 - train: epoch 0049, iter [01100, 05004], lr: 0.010000, loss: 0.9552
2022-07-01 06:37:00 - train: epoch 0049, iter [01200, 05004], lr: 0.010000, loss: 0.9046
2022-07-01 06:37:42 - train: epoch 0049, iter [01300, 05004], lr: 0.010000, loss: 1.1270
2022-07-01 06:38:24 - train: epoch 0049, iter [01400, 05004], lr: 0.010000, loss: 1.1616
2022-07-01 06:39:06 - train: epoch 0049, iter [01500, 05004], lr: 0.010000, loss: 0.9610
2022-07-01 06:39:48 - train: epoch 0049, iter [01600, 05004], lr: 0.010000, loss: 1.2020
2022-07-01 06:40:29 - train: epoch 0049, iter [01700, 05004], lr: 0.010000, loss: 1.1005
2022-07-01 06:41:11 - train: epoch 0049, iter [01800, 05004], lr: 0.010000, loss: 0.8987
2022-07-01 06:41:53 - train: epoch 0049, iter [01900, 05004], lr: 0.010000, loss: 1.0545
2022-07-01 06:42:34 - train: epoch 0049, iter [02000, 05004], lr: 0.010000, loss: 0.9193
2022-07-01 06:43:16 - train: epoch 0049, iter [02100, 05004], lr: 0.010000, loss: 0.9388
2022-07-01 06:43:58 - train: epoch 0049, iter [02200, 05004], lr: 0.010000, loss: 1.0469
2022-07-01 06:44:40 - train: epoch 0049, iter [02300, 05004], lr: 0.010000, loss: 1.0014
2022-07-01 06:45:22 - train: epoch 0049, iter [02400, 05004], lr: 0.010000, loss: 1.1031
2022-07-01 06:46:04 - train: epoch 0049, iter [02500, 05004], lr: 0.010000, loss: 1.0483
2022-07-01 06:46:45 - train: epoch 0049, iter [02600, 05004], lr: 0.010000, loss: 0.9779
2022-07-01 06:47:28 - train: epoch 0049, iter [02700, 05004], lr: 0.010000, loss: 1.0050
2022-07-01 06:48:10 - train: epoch 0049, iter [02800, 05004], lr: 0.010000, loss: 1.0189
2022-07-01 06:48:52 - train: epoch 0049, iter [02900, 05004], lr: 0.010000, loss: 1.1859
2022-07-01 06:49:34 - train: epoch 0049, iter [03000, 05004], lr: 0.010000, loss: 1.1716
2022-07-01 06:50:15 - train: epoch 0049, iter [03100, 05004], lr: 0.010000, loss: 1.0702
2022-07-01 06:50:57 - train: epoch 0049, iter [03200, 05004], lr: 0.010000, loss: 1.0508
2022-07-01 06:51:39 - train: epoch 0049, iter [03300, 05004], lr: 0.010000, loss: 1.1402
2022-07-01 06:52:21 - train: epoch 0049, iter [03400, 05004], lr: 0.010000, loss: 1.1707
2022-07-01 06:53:03 - train: epoch 0049, iter [03500, 05004], lr: 0.010000, loss: 1.0496
2022-07-01 06:53:45 - train: epoch 0049, iter [03600, 05004], lr: 0.010000, loss: 1.2660
2022-07-01 06:54:27 - train: epoch 0049, iter [03700, 05004], lr: 0.010000, loss: 1.0411
2022-07-01 06:55:09 - train: epoch 0049, iter [03800, 05004], lr: 0.010000, loss: 1.2814
2022-07-01 06:55:51 - train: epoch 0049, iter [03900, 05004], lr: 0.010000, loss: 1.2521
2022-07-01 06:56:33 - train: epoch 0049, iter [04000, 05004], lr: 0.010000, loss: 1.1051
2022-07-01 06:57:15 - train: epoch 0049, iter [04100, 05004], lr: 0.010000, loss: 0.9971
2022-07-01 06:57:57 - train: epoch 0049, iter [04200, 05004], lr: 0.010000, loss: 1.0232
2022-07-01 06:58:38 - train: epoch 0049, iter [04300, 05004], lr: 0.010000, loss: 1.2532
2022-07-01 06:59:20 - train: epoch 0049, iter [04400, 05004], lr: 0.010000, loss: 1.0710
2022-07-01 07:00:02 - train: epoch 0049, iter [04500, 05004], lr: 0.010000, loss: 0.9913
2022-07-01 07:00:44 - train: epoch 0049, iter [04600, 05004], lr: 0.010000, loss: 1.1327
2022-07-01 07:01:26 - train: epoch 0049, iter [04700, 05004], lr: 0.010000, loss: 1.1110
2022-07-01 07:02:08 - train: epoch 0049, iter [04800, 05004], lr: 0.010000, loss: 0.8808
2022-07-01 07:02:50 - train: epoch 0049, iter [04900, 05004], lr: 0.010000, loss: 0.9031
2022-07-01 07:03:32 - train: epoch 0049, iter [05000, 05004], lr: 0.010000, loss: 1.0586
2022-07-01 07:03:34 - train: epoch 049, train_loss: 1.0429
2022-07-01 07:04:48 - eval: epoch: 049, acc1: 73.956%, acc5: 91.942%, test_loss: 1.0353, per_image_load_time: 1.099ms, per_image_inference_time: 0.882ms
2022-07-01 07:04:49 - until epoch: 049, best_acc1: 74.676%
2022-07-01 07:04:49 - epoch 050 lr: 0.010000
2022-07-01 07:05:36 - train: epoch 0050, iter [00100, 05004], lr: 0.010000, loss: 1.1127
2022-07-01 07:06:18 - train: epoch 0050, iter [00200, 05004], lr: 0.010000, loss: 0.9627
2022-07-01 07:07:00 - train: epoch 0050, iter [00300, 05004], lr: 0.010000, loss: 1.0752
2022-07-01 07:07:41 - train: epoch 0050, iter [00400, 05004], lr: 0.010000, loss: 0.9407
2022-07-01 07:08:23 - train: epoch 0050, iter [00500, 05004], lr: 0.010000, loss: 1.0317
2022-07-01 07:09:04 - train: epoch 0050, iter [00600, 05004], lr: 0.010000, loss: 1.0489
2022-07-01 07:09:46 - train: epoch 0050, iter [00700, 05004], lr: 0.010000, loss: 0.8654
2022-07-01 07:10:27 - train: epoch 0050, iter [00800, 05004], lr: 0.010000, loss: 0.8643
2022-07-01 07:11:09 - train: epoch 0050, iter [00900, 05004], lr: 0.010000, loss: 0.9610
2022-07-01 07:11:50 - train: epoch 0050, iter [01000, 05004], lr: 0.010000, loss: 1.0937
2022-07-01 07:12:32 - train: epoch 0050, iter [01100, 05004], lr: 0.010000, loss: 1.1129
2022-07-01 07:13:13 - train: epoch 0050, iter [01200, 05004], lr: 0.010000, loss: 0.9971
2022-07-01 07:13:55 - train: epoch 0050, iter [01300, 05004], lr: 0.010000, loss: 0.9108
2022-07-01 07:14:36 - train: epoch 0050, iter [01400, 05004], lr: 0.010000, loss: 1.0095
2022-07-01 07:15:18 - train: epoch 0050, iter [01500, 05004], lr: 0.010000, loss: 1.0447
2022-07-01 07:15:59 - train: epoch 0050, iter [01600, 05004], lr: 0.010000, loss: 0.9541
2022-07-01 07:16:41 - train: epoch 0050, iter [01700, 05004], lr: 0.010000, loss: 1.0537
2022-07-01 07:17:22 - train: epoch 0050, iter [01800, 05004], lr: 0.010000, loss: 0.9019
2022-07-01 07:18:03 - train: epoch 0050, iter [01900, 05004], lr: 0.010000, loss: 1.0047
2022-07-01 07:18:45 - train: epoch 0050, iter [02000, 05004], lr: 0.010000, loss: 1.0472
2022-07-01 07:19:26 - train: epoch 0050, iter [02100, 05004], lr: 0.010000, loss: 0.8638
2022-07-01 07:20:08 - train: epoch 0050, iter [02200, 05004], lr: 0.010000, loss: 1.2197
2022-07-01 07:20:49 - train: epoch 0050, iter [02300, 05004], lr: 0.010000, loss: 0.9841
2022-07-01 07:21:31 - train: epoch 0050, iter [02400, 05004], lr: 0.010000, loss: 0.9881
2022-07-01 07:22:12 - train: epoch 0050, iter [02500, 05004], lr: 0.010000, loss: 1.0814
2022-07-01 07:22:54 - train: epoch 0050, iter [02600, 05004], lr: 0.010000, loss: 0.9663
2022-07-01 07:23:36 - train: epoch 0050, iter [02700, 05004], lr: 0.010000, loss: 1.1172
2022-07-01 07:24:17 - train: epoch 0050, iter [02800, 05004], lr: 0.010000, loss: 1.1496
2022-07-01 07:24:59 - train: epoch 0050, iter [02900, 05004], lr: 0.010000, loss: 1.1554
2022-07-01 07:25:40 - train: epoch 0050, iter [03000, 05004], lr: 0.010000, loss: 1.1381
2022-07-01 07:26:22 - train: epoch 0050, iter [03100, 05004], lr: 0.010000, loss: 0.9625
2022-07-01 07:27:03 - train: epoch 0050, iter [03200, 05004], lr: 0.010000, loss: 1.0484
2022-07-01 07:27:45 - train: epoch 0050, iter [03300, 05004], lr: 0.010000, loss: 0.9749
2022-07-01 07:28:26 - train: epoch 0050, iter [03400, 05004], lr: 0.010000, loss: 0.9711
2022-07-01 07:29:08 - train: epoch 0050, iter [03500, 05004], lr: 0.010000, loss: 1.0689
2022-07-01 07:29:49 - train: epoch 0050, iter [03600, 05004], lr: 0.010000, loss: 1.1246
2022-07-01 07:30:31 - train: epoch 0050, iter [03700, 05004], lr: 0.010000, loss: 1.0780
2022-07-01 07:31:12 - train: epoch 0050, iter [03800, 05004], lr: 0.010000, loss: 0.8846
2022-07-01 07:31:54 - train: epoch 0050, iter [03900, 05004], lr: 0.010000, loss: 0.8732
2022-07-01 07:32:35 - train: epoch 0050, iter [04000, 05004], lr: 0.010000, loss: 1.1849
2022-07-01 07:33:16 - train: epoch 0050, iter [04100, 05004], lr: 0.010000, loss: 0.9934
2022-07-01 07:33:58 - train: epoch 0050, iter [04200, 05004], lr: 0.010000, loss: 1.0255
2022-07-01 07:34:39 - train: epoch 0050, iter [04300, 05004], lr: 0.010000, loss: 0.9757
2022-07-01 07:35:21 - train: epoch 0050, iter [04400, 05004], lr: 0.010000, loss: 0.9781
2022-07-01 07:36:02 - train: epoch 0050, iter [04500, 05004], lr: 0.010000, loss: 1.0083
2022-07-01 07:36:44 - train: epoch 0050, iter [04600, 05004], lr: 0.010000, loss: 1.0132
2022-07-01 07:37:26 - train: epoch 0050, iter [04700, 05004], lr: 0.010000, loss: 1.0720
2022-07-01 07:38:07 - train: epoch 0050, iter [04800, 05004], lr: 0.010000, loss: 0.9642
2022-07-01 07:38:48 - train: epoch 0050, iter [04900, 05004], lr: 0.010000, loss: 1.0143
2022-07-01 07:39:30 - train: epoch 0050, iter [05000, 05004], lr: 0.010000, loss: 1.0446
2022-07-01 07:39:32 - train: epoch 050, train_loss: 1.0393
2022-07-01 07:40:46 - eval: epoch: 050, acc1: 74.016%, acc5: 92.160%, test_loss: 1.0237, per_image_load_time: 1.870ms, per_image_inference_time: 0.886ms
2022-07-01 07:40:47 - until epoch: 050, best_acc1: 74.676%
2022-07-01 07:40:47 - epoch 051 lr: 0.010000
2022-07-01 07:41:34 - train: epoch 0051, iter [00100, 05004], lr: 0.010000, loss: 1.0655
2022-07-01 07:42:16 - train: epoch 0051, iter [00200, 05004], lr: 0.010000, loss: 1.1699
2022-07-01 07:42:57 - train: epoch 0051, iter [00300, 05004], lr: 0.010000, loss: 1.1356
2022-07-01 07:43:39 - train: epoch 0051, iter [00400, 05004], lr: 0.010000, loss: 0.8943
2022-07-01 07:44:20 - train: epoch 0051, iter [00500, 05004], lr: 0.010000, loss: 1.0781
2022-07-01 07:45:02 - train: epoch 0051, iter [00600, 05004], lr: 0.010000, loss: 1.0641
2022-07-01 07:45:43 - train: epoch 0051, iter [00700, 05004], lr: 0.010000, loss: 0.9309
2022-07-01 07:46:25 - train: epoch 0051, iter [00800, 05004], lr: 0.010000, loss: 1.1470
2022-07-01 07:47:06 - train: epoch 0051, iter [00900, 05004], lr: 0.010000, loss: 0.8946
2022-07-01 07:47:48 - train: epoch 0051, iter [01000, 05004], lr: 0.010000, loss: 1.2158
2022-07-01 07:48:29 - train: epoch 0051, iter [01100, 05004], lr: 0.010000, loss: 1.1798
2022-07-01 07:49:11 - train: epoch 0051, iter [01200, 05004], lr: 0.010000, loss: 0.8867
2022-07-01 07:49:53 - train: epoch 0051, iter [01300, 05004], lr: 0.010000, loss: 0.8339
2022-07-01 07:50:34 - train: epoch 0051, iter [01400, 05004], lr: 0.010000, loss: 0.8957
2022-07-01 07:51:16 - train: epoch 0051, iter [01500, 05004], lr: 0.010000, loss: 1.0922
2022-07-01 07:51:57 - train: epoch 0051, iter [01600, 05004], lr: 0.010000, loss: 0.9926
2022-07-01 07:52:39 - train: epoch 0051, iter [01700, 05004], lr: 0.010000, loss: 1.0851
2022-07-01 07:53:20 - train: epoch 0051, iter [01800, 05004], lr: 0.010000, loss: 1.0767
2022-07-01 07:54:02 - train: epoch 0051, iter [01900, 05004], lr: 0.010000, loss: 0.8516
2022-07-01 07:54:43 - train: epoch 0051, iter [02000, 05004], lr: 0.010000, loss: 0.9984
2022-07-01 07:55:25 - train: epoch 0051, iter [02100, 05004], lr: 0.010000, loss: 1.0448
2022-07-01 07:56:06 - train: epoch 0051, iter [02200, 05004], lr: 0.010000, loss: 1.0394
2022-07-01 07:56:48 - train: epoch 0051, iter [02300, 05004], lr: 0.010000, loss: 0.9576
2022-07-01 07:57:29 - train: epoch 0051, iter [02400, 05004], lr: 0.010000, loss: 1.0796
2022-07-01 07:58:11 - train: epoch 0051, iter [02500, 05004], lr: 0.010000, loss: 0.9648
2022-07-01 07:58:52 - train: epoch 0051, iter [02600, 05004], lr: 0.010000, loss: 1.0527
2022-07-01 07:59:34 - train: epoch 0051, iter [02700, 05004], lr: 0.010000, loss: 1.0684
2022-07-01 08:00:15 - train: epoch 0051, iter [02800, 05004], lr: 0.010000, loss: 0.9418
2022-07-01 08:00:57 - train: epoch 0051, iter [02900, 05004], lr: 0.010000, loss: 1.0039
2022-07-01 08:01:38 - train: epoch 0051, iter [03000, 05004], lr: 0.010000, loss: 0.9308
2022-07-01 08:02:20 - train: epoch 0051, iter [03100, 05004], lr: 0.010000, loss: 0.9563
2022-07-01 08:03:02 - train: epoch 0051, iter [03200, 05004], lr: 0.010000, loss: 1.0070
2022-07-01 08:03:43 - train: epoch 0051, iter [03300, 05004], lr: 0.010000, loss: 1.1198
2022-07-01 08:04:25 - train: epoch 0051, iter [03400, 05004], lr: 0.010000, loss: 1.1364
2022-07-01 08:05:06 - train: epoch 0051, iter [03500, 05004], lr: 0.010000, loss: 1.0175
2022-07-01 08:05:48 - train: epoch 0051, iter [03600, 05004], lr: 0.010000, loss: 1.0144
2022-07-01 08:06:29 - train: epoch 0051, iter [03700, 05004], lr: 0.010000, loss: 1.0588
2022-07-01 08:07:11 - train: epoch 0051, iter [03800, 05004], lr: 0.010000, loss: 1.0505
2022-07-01 08:07:53 - train: epoch 0051, iter [03900, 05004], lr: 0.010000, loss: 1.1168
2022-07-01 08:08:34 - train: epoch 0051, iter [04000, 05004], lr: 0.010000, loss: 1.0730
2022-07-01 08:09:16 - train: epoch 0051, iter [04100, 05004], lr: 0.010000, loss: 1.1597
2022-07-01 08:09:57 - train: epoch 0051, iter [04200, 05004], lr: 0.010000, loss: 1.2735
2022-07-01 08:10:39 - train: epoch 0051, iter [04300, 05004], lr: 0.010000, loss: 0.9912
2022-07-01 08:11:21 - train: epoch 0051, iter [04400, 05004], lr: 0.010000, loss: 1.0817
2022-07-01 08:12:03 - train: epoch 0051, iter [04500, 05004], lr: 0.010000, loss: 0.9376
2022-07-01 08:12:44 - train: epoch 0051, iter [04600, 05004], lr: 0.010000, loss: 1.0892
2022-07-01 08:13:26 - train: epoch 0051, iter [04700, 05004], lr: 0.010000, loss: 1.0299
2022-07-01 08:14:08 - train: epoch 0051, iter [04800, 05004], lr: 0.010000, loss: 1.0305
2022-07-01 08:14:50 - train: epoch 0051, iter [04900, 05004], lr: 0.010000, loss: 1.1655
2022-07-01 08:15:31 - train: epoch 0051, iter [05000, 05004], lr: 0.010000, loss: 1.0538
2022-07-01 08:15:33 - train: epoch 051, train_loss: 1.0379
2022-07-01 08:16:48 - eval: epoch: 051, acc1: 74.262%, acc5: 92.142%, test_loss: 1.0227, per_image_load_time: 1.991ms, per_image_inference_time: 0.875ms
2022-07-01 08:16:48 - until epoch: 051, best_acc1: 74.676%
2022-07-01 08:16:48 - epoch 052 lr: 0.010000
2022-07-01 08:17:36 - train: epoch 0052, iter [00100, 05004], lr: 0.010000, loss: 0.9287
2022-07-01 08:18:17 - train: epoch 0052, iter [00200, 05004], lr: 0.010000, loss: 1.0834
2022-07-01 08:18:58 - train: epoch 0052, iter [00300, 05004], lr: 0.010000, loss: 1.1156
2022-07-01 08:19:40 - train: epoch 0052, iter [00400, 05004], lr: 0.010000, loss: 1.1029
2022-07-01 08:20:21 - train: epoch 0052, iter [00500, 05004], lr: 0.010000, loss: 1.1231
2022-07-01 08:21:03 - train: epoch 0052, iter [00600, 05004], lr: 0.010000, loss: 0.9537
2022-07-01 08:21:44 - train: epoch 0052, iter [00700, 05004], lr: 0.010000, loss: 1.0670
2022-07-01 08:22:26 - train: epoch 0052, iter [00800, 05004], lr: 0.010000, loss: 1.1183
2022-07-01 08:23:07 - train: epoch 0052, iter [00900, 05004], lr: 0.010000, loss: 1.0233
2022-07-01 08:23:49 - train: epoch 0052, iter [01000, 05004], lr: 0.010000, loss: 1.1139
2022-07-01 08:24:30 - train: epoch 0052, iter [01100, 05004], lr: 0.010000, loss: 1.0155
2022-07-01 08:25:12 - train: epoch 0052, iter [01200, 05004], lr: 0.010000, loss: 0.9660
2022-07-01 08:25:53 - train: epoch 0052, iter [01300, 05004], lr: 0.010000, loss: 0.9635
2022-07-01 08:26:35 - train: epoch 0052, iter [01400, 05004], lr: 0.010000, loss: 1.2956
2022-07-01 08:27:16 - train: epoch 0052, iter [01500, 05004], lr: 0.010000, loss: 0.9195
2022-07-01 08:27:58 - train: epoch 0052, iter [01600, 05004], lr: 0.010000, loss: 0.8750
2022-07-01 08:28:39 - train: epoch 0052, iter [01700, 05004], lr: 0.010000, loss: 0.8932
2022-07-01 08:29:21 - train: epoch 0052, iter [01800, 05004], lr: 0.010000, loss: 0.8549
2022-07-01 08:30:02 - train: epoch 0052, iter [01900, 05004], lr: 0.010000, loss: 1.1459
2022-07-01 08:30:44 - train: epoch 0052, iter [02000, 05004], lr: 0.010000, loss: 1.0459
2022-07-01 08:31:25 - train: epoch 0052, iter [02100, 05004], lr: 0.010000, loss: 0.9054
2022-07-01 08:32:07 - train: epoch 0052, iter [02200, 05004], lr: 0.010000, loss: 1.1458
2022-07-01 08:32:48 - train: epoch 0052, iter [02300, 05004], lr: 0.010000, loss: 0.9515
2022-07-01 08:33:30 - train: epoch 0052, iter [02400, 05004], lr: 0.010000, loss: 0.9276
2022-07-01 08:34:11 - train: epoch 0052, iter [02500, 05004], lr: 0.010000, loss: 1.0126
2022-07-01 08:34:53 - train: epoch 0052, iter [02600, 05004], lr: 0.010000, loss: 0.8328
2022-07-01 08:35:35 - train: epoch 0052, iter [02700, 05004], lr: 0.010000, loss: 0.9597
2022-07-01 08:36:16 - train: epoch 0052, iter [02800, 05004], lr: 0.010000, loss: 1.0082
2022-07-01 08:36:58 - train: epoch 0052, iter [02900, 05004], lr: 0.010000, loss: 0.9642
2022-07-01 08:37:39 - train: epoch 0052, iter [03000, 05004], lr: 0.010000, loss: 1.0435
2022-07-01 08:38:21 - train: epoch 0052, iter [03100, 05004], lr: 0.010000, loss: 1.0015
2022-07-01 08:39:03 - train: epoch 0052, iter [03200, 05004], lr: 0.010000, loss: 1.1867
2022-07-01 08:39:44 - train: epoch 0052, iter [03300, 05004], lr: 0.010000, loss: 1.1115
2022-07-01 08:40:26 - train: epoch 0052, iter [03400, 05004], lr: 0.010000, loss: 1.1158
2022-07-01 08:41:07 - train: epoch 0052, iter [03500, 05004], lr: 0.010000, loss: 1.1289
2022-07-01 08:41:49 - train: epoch 0052, iter [03600, 05004], lr: 0.010000, loss: 1.0998
2022-07-01 08:42:31 - train: epoch 0052, iter [03700, 05004], lr: 0.010000, loss: 1.2359
2022-07-01 08:43:12 - train: epoch 0052, iter [03800, 05004], lr: 0.010000, loss: 1.0342
2022-07-01 08:43:54 - train: epoch 0052, iter [03900, 05004], lr: 0.010000, loss: 0.9998
2022-07-01 08:44:36 - train: epoch 0052, iter [04000, 05004], lr: 0.010000, loss: 1.2382
2022-07-01 08:45:17 - train: epoch 0052, iter [04100, 05004], lr: 0.010000, loss: 0.9816
2022-07-01 08:45:59 - train: epoch 0052, iter [04200, 05004], lr: 0.010000, loss: 0.8559
2022-07-01 08:46:41 - train: epoch 0052, iter [04300, 05004], lr: 0.010000, loss: 1.0328
2022-07-01 08:47:22 - train: epoch 0052, iter [04400, 05004], lr: 0.010000, loss: 1.0701
2022-07-01 08:48:04 - train: epoch 0052, iter [04500, 05004], lr: 0.010000, loss: 0.9732
2022-07-01 08:48:45 - train: epoch 0052, iter [04600, 05004], lr: 0.010000, loss: 1.1560
2022-07-01 08:49:27 - train: epoch 0052, iter [04700, 05004], lr: 0.010000, loss: 1.0203
2022-07-01 08:50:09 - train: epoch 0052, iter [04800, 05004], lr: 0.010000, loss: 0.9097
2022-07-01 08:50:50 - train: epoch 0052, iter [04900, 05004], lr: 0.010000, loss: 0.9523
2022-07-01 08:51:32 - train: epoch 0052, iter [05000, 05004], lr: 0.010000, loss: 1.1169
2022-07-01 08:51:34 - train: epoch 052, train_loss: 1.0323
2022-07-01 08:52:48 - eval: epoch: 052, acc1: 73.956%, acc5: 92.124%, test_loss: 1.0436, per_image_load_time: 1.873ms, per_image_inference_time: 0.885ms
2022-07-01 08:52:49 - until epoch: 052, best_acc1: 74.676%
2022-07-01 08:52:49 - epoch 053 lr: 0.010000
2022-07-01 08:53:36 - train: epoch 0053, iter [00100, 05004], lr: 0.010000, loss: 0.9484
2022-07-01 08:54:17 - train: epoch 0053, iter [00200, 05004], lr: 0.010000, loss: 1.1411
2022-07-01 08:54:59 - train: epoch 0053, iter [00300, 05004], lr: 0.010000, loss: 1.0057
2022-07-01 08:55:40 - train: epoch 0053, iter [00400, 05004], lr: 0.010000, loss: 1.0633
2022-07-01 08:56:22 - train: epoch 0053, iter [00500, 05004], lr: 0.010000, loss: 1.2095
2022-07-01 08:57:03 - train: epoch 0053, iter [00600, 05004], lr: 0.010000, loss: 0.9261
2022-07-01 08:57:45 - train: epoch 0053, iter [00700, 05004], lr: 0.010000, loss: 0.7966
2022-07-01 08:58:27 - train: epoch 0053, iter [00800, 05004], lr: 0.010000, loss: 1.0626
2022-07-01 08:59:08 - train: epoch 0053, iter [00900, 05004], lr: 0.010000, loss: 1.0053
2022-07-01 08:59:50 - train: epoch 0053, iter [01000, 05004], lr: 0.010000, loss: 0.9088
2022-07-01 09:00:31 - train: epoch 0053, iter [01100, 05004], lr: 0.010000, loss: 1.0661
2022-07-01 09:01:13 - train: epoch 0053, iter [01200, 05004], lr: 0.010000, loss: 0.9252
2022-07-01 09:01:54 - train: epoch 0053, iter [01300, 05004], lr: 0.010000, loss: 1.0152
2022-07-01 09:02:35 - train: epoch 0053, iter [01400, 05004], lr: 0.010000, loss: 1.2577
2022-07-01 09:03:17 - train: epoch 0053, iter [01500, 05004], lr: 0.010000, loss: 0.9749
2022-07-01 09:03:58 - train: epoch 0053, iter [01600, 05004], lr: 0.010000, loss: 1.2511
2022-07-01 09:04:40 - train: epoch 0053, iter [01700, 05004], lr: 0.010000, loss: 1.2095
2022-07-01 09:05:21 - train: epoch 0053, iter [01800, 05004], lr: 0.010000, loss: 1.0746
2022-07-01 09:06:03 - train: epoch 0053, iter [01900, 05004], lr: 0.010000, loss: 0.8065
2022-07-01 09:06:45 - train: epoch 0053, iter [02000, 05004], lr: 0.010000, loss: 1.0077
2022-07-01 09:07:26 - train: epoch 0053, iter [02100, 05004], lr: 0.010000, loss: 1.0389
2022-07-01 09:08:08 - train: epoch 0053, iter [02200, 05004], lr: 0.010000, loss: 0.9716
2022-07-01 09:08:49 - train: epoch 0053, iter [02300, 05004], lr: 0.010000, loss: 1.0547
2022-07-01 09:09:31 - train: epoch 0053, iter [02400, 05004], lr: 0.010000, loss: 1.1242
2022-07-01 09:10:13 - train: epoch 0053, iter [02500, 05004], lr: 0.010000, loss: 1.2473
2022-07-01 09:10:54 - train: epoch 0053, iter [02600, 05004], lr: 0.010000, loss: 0.9931
2022-07-01 09:11:36 - train: epoch 0053, iter [02700, 05004], lr: 0.010000, loss: 1.1551
2022-07-01 09:12:18 - train: epoch 0053, iter [02800, 05004], lr: 0.010000, loss: 1.0596
2022-07-01 09:12:59 - train: epoch 0053, iter [02900, 05004], lr: 0.010000, loss: 0.8560
2022-07-01 09:13:41 - train: epoch 0053, iter [03000, 05004], lr: 0.010000, loss: 0.8438
2022-07-01 09:14:23 - train: epoch 0053, iter [03100, 05004], lr: 0.010000, loss: 1.1717
2022-07-01 09:15:04 - train: epoch 0053, iter [03200, 05004], lr: 0.010000, loss: 1.2350
2022-07-01 09:15:46 - train: epoch 0053, iter [03300, 05004], lr: 0.010000, loss: 1.0500
2022-07-01 09:16:27 - train: epoch 0053, iter [03400, 05004], lr: 0.010000, loss: 1.2267
2022-07-01 09:17:09 - train: epoch 0053, iter [03500, 05004], lr: 0.010000, loss: 1.1511
2022-07-01 09:17:50 - train: epoch 0053, iter [03600, 05004], lr: 0.010000, loss: 1.0548
2022-07-01 09:18:32 - train: epoch 0053, iter [03700, 05004], lr: 0.010000, loss: 1.1399
2022-07-01 09:19:14 - train: epoch 0053, iter [03800, 05004], lr: 0.010000, loss: 0.9922
2022-07-01 09:19:55 - train: epoch 0053, iter [03900, 05004], lr: 0.010000, loss: 1.1246
2022-07-01 09:20:37 - train: epoch 0053, iter [04000, 05004], lr: 0.010000, loss: 1.0731
2022-07-01 09:21:18 - train: epoch 0053, iter [04100, 05004], lr: 0.010000, loss: 1.0794
2022-07-01 09:22:00 - train: epoch 0053, iter [04200, 05004], lr: 0.010000, loss: 1.1165
2022-07-01 09:22:42 - train: epoch 0053, iter [04300, 05004], lr: 0.010000, loss: 1.2625
2022-07-01 09:23:23 - train: epoch 0053, iter [04400, 05004], lr: 0.010000, loss: 1.0301
2022-07-01 09:24:05 - train: epoch 0053, iter [04500, 05004], lr: 0.010000, loss: 1.0960
2022-07-01 09:24:47 - train: epoch 0053, iter [04600, 05004], lr: 0.010000, loss: 0.9766
2022-07-01 09:25:29 - train: epoch 0053, iter [04700, 05004], lr: 0.010000, loss: 1.2355
2022-07-01 09:26:10 - train: epoch 0053, iter [04800, 05004], lr: 0.010000, loss: 1.2514
2022-07-01 09:26:52 - train: epoch 0053, iter [04900, 05004], lr: 0.010000, loss: 0.9290
2022-07-01 09:27:34 - train: epoch 0053, iter [05000, 05004], lr: 0.010000, loss: 1.0194
2022-07-01 09:27:36 - train: epoch 053, train_loss: 1.0304
2022-07-01 09:28:50 - eval: epoch: 053, acc1: 74.090%, acc5: 92.126%, test_loss: 1.0369, per_image_load_time: 1.625ms, per_image_inference_time: 0.904ms
2022-07-01 09:28:51 - until epoch: 053, best_acc1: 74.676%
2022-07-01 09:28:51 - epoch 054 lr: 0.010000
2022-07-01 09:29:38 - train: epoch 0054, iter [00100, 05004], lr: 0.010000, loss: 0.7929
2022-07-01 09:30:20 - train: epoch 0054, iter [00200, 05004], lr: 0.010000, loss: 1.2545
2022-07-01 09:31:01 - train: epoch 0054, iter [00300, 05004], lr: 0.010000, loss: 0.9842
2022-07-01 09:31:43 - train: epoch 0054, iter [00400, 05004], lr: 0.010000, loss: 0.8982
2022-07-01 09:32:24 - train: epoch 0054, iter [00500, 05004], lr: 0.010000, loss: 1.0351
2022-07-01 09:33:06 - train: epoch 0054, iter [00600, 05004], lr: 0.010000, loss: 0.9292
2022-07-01 09:33:48 - train: epoch 0054, iter [00700, 05004], lr: 0.010000, loss: 0.9868
2022-07-01 09:34:29 - train: epoch 0054, iter [00800, 05004], lr: 0.010000, loss: 1.1536
2022-07-01 09:35:11 - train: epoch 0054, iter [00900, 05004], lr: 0.010000, loss: 0.8916
2022-07-01 09:35:53 - train: epoch 0054, iter [01000, 05004], lr: 0.010000, loss: 0.8603
2022-07-01 09:36:34 - train: epoch 0054, iter [01100, 05004], lr: 0.010000, loss: 0.9162
2022-07-01 09:37:16 - train: epoch 0054, iter [01200, 05004], lr: 0.010000, loss: 1.0873
2022-07-01 09:37:58 - train: epoch 0054, iter [01300, 05004], lr: 0.010000, loss: 0.9457
2022-07-01 09:38:39 - train: epoch 0054, iter [01400, 05004], lr: 0.010000, loss: 1.1104
2022-07-01 09:39:21 - train: epoch 0054, iter [01500, 05004], lr: 0.010000, loss: 1.0323
2022-07-01 09:40:02 - train: epoch 0054, iter [01600, 05004], lr: 0.010000, loss: 0.6891
2022-07-01 09:40:43 - train: epoch 0054, iter [01700, 05004], lr: 0.010000, loss: 1.0355
2022-07-01 09:41:25 - train: epoch 0054, iter [01800, 05004], lr: 0.010000, loss: 0.9927
2022-07-01 09:42:07 - train: epoch 0054, iter [01900, 05004], lr: 0.010000, loss: 1.2551
2022-07-01 09:42:48 - train: epoch 0054, iter [02000, 05004], lr: 0.010000, loss: 1.0245
2022-07-01 09:43:30 - train: epoch 0054, iter [02100, 05004], lr: 0.010000, loss: 0.8077
2022-07-01 09:44:11 - train: epoch 0054, iter [02200, 05004], lr: 0.010000, loss: 0.9109
2022-07-01 09:44:53 - train: epoch 0054, iter [02300, 05004], lr: 0.010000, loss: 1.1377
2022-07-01 09:45:34 - train: epoch 0054, iter [02400, 05004], lr: 0.010000, loss: 0.8801
2022-07-01 09:46:16 - train: epoch 0054, iter [02500, 05004], lr: 0.010000, loss: 1.0496
2022-07-01 09:46:58 - train: epoch 0054, iter [02600, 05004], lr: 0.010000, loss: 0.9230
2022-07-01 09:47:39 - train: epoch 0054, iter [02700, 05004], lr: 0.010000, loss: 1.0632
2022-07-01 09:48:21 - train: epoch 0054, iter [02800, 05004], lr: 0.010000, loss: 1.2585
2022-07-01 09:49:02 - train: epoch 0054, iter [02900, 05004], lr: 0.010000, loss: 0.9702
2022-07-01 09:49:44 - train: epoch 0054, iter [03000, 05004], lr: 0.010000, loss: 1.1273
2022-07-01 09:50:25 - train: epoch 0054, iter [03100, 05004], lr: 0.010000, loss: 0.9955
2022-07-01 09:51:07 - train: epoch 0054, iter [03200, 05004], lr: 0.010000, loss: 1.2034
2022-07-01 09:51:48 - train: epoch 0054, iter [03300, 05004], lr: 0.010000, loss: 1.0092
2022-07-01 09:52:29 - train: epoch 0054, iter [03400, 05004], lr: 0.010000, loss: 1.1156
2022-07-01 09:53:11 - train: epoch 0054, iter [03500, 05004], lr: 0.010000, loss: 1.1103
2022-07-01 09:53:52 - train: epoch 0054, iter [03600, 05004], lr: 0.010000, loss: 1.0061
2022-07-01 09:54:34 - train: epoch 0054, iter [03700, 05004], lr: 0.010000, loss: 1.0203
2022-07-01 09:55:16 - train: epoch 0054, iter [03800, 05004], lr: 0.010000, loss: 0.9401
2022-07-01 09:55:57 - train: epoch 0054, iter [03900, 05004], lr: 0.010000, loss: 1.0820
2022-07-01 09:56:39 - train: epoch 0054, iter [04000, 05004], lr: 0.010000, loss: 0.8914
2022-07-01 09:57:20 - train: epoch 0054, iter [04100, 05004], lr: 0.010000, loss: 1.0729
2022-07-01 09:58:02 - train: epoch 0054, iter [04200, 05004], lr: 0.010000, loss: 0.9955
2022-07-01 09:58:44 - train: epoch 0054, iter [04300, 05004], lr: 0.010000, loss: 1.1064
2022-07-01 09:59:25 - train: epoch 0054, iter [04400, 05004], lr: 0.010000, loss: 0.8811
2022-07-01 10:00:07 - train: epoch 0054, iter [04500, 05004], lr: 0.010000, loss: 0.8573
2022-07-01 10:00:49 - train: epoch 0054, iter [04600, 05004], lr: 0.010000, loss: 1.0235
2022-07-01 10:01:30 - train: epoch 0054, iter [04700, 05004], lr: 0.010000, loss: 1.1678
2022-07-01 10:02:11 - train: epoch 0054, iter [04800, 05004], lr: 0.010000, loss: 1.1892
2022-07-01 10:02:53 - train: epoch 0054, iter [04900, 05004], lr: 0.010000, loss: 0.9351
2022-07-01 10:03:34 - train: epoch 0054, iter [05000, 05004], lr: 0.010000, loss: 1.1276
2022-07-01 10:03:36 - train: epoch 054, train_loss: 1.0287
2022-07-01 10:04:51 - eval: epoch: 054, acc1: 73.230%, acc5: 91.828%, test_loss: 1.0616, per_image_load_time: 1.990ms, per_image_inference_time: 0.876ms
2022-07-01 10:04:51 - until epoch: 054, best_acc1: 74.676%
2022-07-01 10:04:51 - epoch 055 lr: 0.010000
2022-07-01 10:05:39 - train: epoch 0055, iter [00100, 05004], lr: 0.010000, loss: 0.9880
2022-07-01 10:06:21 - train: epoch 0055, iter [00200, 05004], lr: 0.010000, loss: 0.8478
2022-07-01 10:07:03 - train: epoch 0055, iter [00300, 05004], lr: 0.010000, loss: 0.8059
2022-07-01 10:07:44 - train: epoch 0055, iter [00400, 05004], lr: 0.010000, loss: 0.9195
2022-07-01 10:08:26 - train: epoch 0055, iter [00500, 05004], lr: 0.010000, loss: 0.7729
2022-07-01 10:09:07 - train: epoch 0055, iter [00600, 05004], lr: 0.010000, loss: 0.9197
2022-07-01 10:09:49 - train: epoch 0055, iter [00700, 05004], lr: 0.010000, loss: 1.0800
2022-07-01 10:10:30 - train: epoch 0055, iter [00800, 05004], lr: 0.010000, loss: 0.8344
2022-07-01 10:11:12 - train: epoch 0055, iter [00900, 05004], lr: 0.010000, loss: 0.9531
2022-07-01 10:11:54 - train: epoch 0055, iter [01000, 05004], lr: 0.010000, loss: 0.9889
2022-07-01 10:12:35 - train: epoch 0055, iter [01100, 05004], lr: 0.010000, loss: 0.9698
2022-07-01 10:13:17 - train: epoch 0055, iter [01200, 05004], lr: 0.010000, loss: 1.0990
2022-07-01 10:13:58 - train: epoch 0055, iter [01300, 05004], lr: 0.010000, loss: 1.0771
2022-07-01 10:14:40 - train: epoch 0055, iter [01400, 05004], lr: 0.010000, loss: 0.9722
2022-07-01 10:15:21 - train: epoch 0055, iter [01500, 05004], lr: 0.010000, loss: 1.0028
2022-07-01 10:16:03 - train: epoch 0055, iter [01600, 05004], lr: 0.010000, loss: 1.1649
2022-07-01 10:16:44 - train: epoch 0055, iter [01700, 05004], lr: 0.010000, loss: 1.0567
2022-07-01 10:17:26 - train: epoch 0055, iter [01800, 05004], lr: 0.010000, loss: 1.0804
2022-07-01 10:18:08 - train: epoch 0055, iter [01900, 05004], lr: 0.010000, loss: 1.0444
2022-07-01 10:18:49 - train: epoch 0055, iter [02000, 05004], lr: 0.010000, loss: 0.9695
2022-07-01 10:19:31 - train: epoch 0055, iter [02100, 05004], lr: 0.010000, loss: 0.8925
2022-07-01 10:20:12 - train: epoch 0055, iter [02200, 05004], lr: 0.010000, loss: 1.1152
2022-07-01 10:20:54 - train: epoch 0055, iter [02300, 05004], lr: 0.010000, loss: 0.9918
2022-07-01 10:21:36 - train: epoch 0055, iter [02400, 05004], lr: 0.010000, loss: 0.8952
2022-07-01 10:22:18 - train: epoch 0055, iter [02500, 05004], lr: 0.010000, loss: 1.0493
2022-07-01 10:22:59 - train: epoch 0055, iter [02600, 05004], lr: 0.010000, loss: 0.8776
2022-07-01 10:23:41 - train: epoch 0055, iter [02700, 05004], lr: 0.010000, loss: 0.8903
2022-07-01 10:24:22 - train: epoch 0055, iter [02800, 05004], lr: 0.010000, loss: 1.0432
2022-07-01 10:25:04 - train: epoch 0055, iter [02900, 05004], lr: 0.010000, loss: 1.1265
2022-07-01 10:25:45 - train: epoch 0055, iter [03000, 05004], lr: 0.010000, loss: 0.9226
2022-07-01 10:26:27 - train: epoch 0055, iter [03100, 05004], lr: 0.010000, loss: 1.1712
2022-07-01 10:27:09 - train: epoch 0055, iter [03200, 05004], lr: 0.010000, loss: 0.9323
2022-07-01 10:27:50 - train: epoch 0055, iter [03300, 05004], lr: 0.010000, loss: 0.7429
2022-07-01 10:28:32 - train: epoch 0055, iter [03400, 05004], lr: 0.010000, loss: 0.9692
2022-07-01 10:29:13 - train: epoch 0055, iter [03500, 05004], lr: 0.010000, loss: 0.8799
2022-07-01 10:29:55 - train: epoch 0055, iter [03600, 05004], lr: 0.010000, loss: 1.0299
2022-07-01 10:30:36 - train: epoch 0055, iter [03700, 05004], lr: 0.010000, loss: 1.0907
2022-07-01 10:31:18 - train: epoch 0055, iter [03800, 05004], lr: 0.010000, loss: 1.1651
2022-07-01 10:31:59 - train: epoch 0055, iter [03900, 05004], lr: 0.010000, loss: 1.2424
2022-07-01 10:32:41 - train: epoch 0055, iter [04000, 05004], lr: 0.010000, loss: 1.0311
2022-07-01 10:33:22 - train: epoch 0055, iter [04100, 05004], lr: 0.010000, loss: 0.9911
2022-07-01 10:34:04 - train: epoch 0055, iter [04200, 05004], lr: 0.010000, loss: 0.9692
2022-07-01 10:34:45 - train: epoch 0055, iter [04300, 05004], lr: 0.010000, loss: 1.0935
2022-07-01 10:35:27 - train: epoch 0055, iter [04400, 05004], lr: 0.010000, loss: 1.2572
2022-07-01 10:36:08 - train: epoch 0055, iter [04500, 05004], lr: 0.010000, loss: 1.0196
2022-07-01 10:36:50 - train: epoch 0055, iter [04600, 05004], lr: 0.010000, loss: 1.1229
2022-07-01 10:37:31 - train: epoch 0055, iter [04700, 05004], lr: 0.010000, loss: 0.8420
2022-07-01 10:38:13 - train: epoch 0055, iter [04800, 05004], lr: 0.010000, loss: 1.1259
2022-07-01 10:38:54 - train: epoch 0055, iter [04900, 05004], lr: 0.010000, loss: 0.9686
2022-07-01 10:39:36 - train: epoch 0055, iter [05000, 05004], lr: 0.010000, loss: 1.1386
2022-07-01 10:39:38 - train: epoch 055, train_loss: 1.0233
2022-07-01 10:40:52 - eval: epoch: 055, acc1: 73.828%, acc5: 92.186%, test_loss: 1.0346, per_image_load_time: 1.971ms, per_image_inference_time: 0.885ms
2022-07-01 10:40:53 - until epoch: 055, best_acc1: 74.676%
2022-07-01 10:40:53 - epoch 056 lr: 0.010000
2022-07-01 10:41:40 - train: epoch 0056, iter [00100, 05004], lr: 0.010000, loss: 1.1295
2022-07-01 10:42:22 - train: epoch 0056, iter [00200, 05004], lr: 0.010000, loss: 1.1258
2022-07-01 10:43:04 - train: epoch 0056, iter [00300, 05004], lr: 0.010000, loss: 0.9909
2022-07-01 10:43:45 - train: epoch 0056, iter [00400, 05004], lr: 0.010000, loss: 0.9874
2022-07-01 10:44:27 - train: epoch 0056, iter [00500, 05004], lr: 0.010000, loss: 0.9892
2022-07-01 10:45:09 - train: epoch 0056, iter [00600, 05004], lr: 0.010000, loss: 1.1008
2022-07-01 10:45:50 - train: epoch 0056, iter [00700, 05004], lr: 0.010000, loss: 1.0566
2022-07-01 10:46:32 - train: epoch 0056, iter [00800, 05004], lr: 0.010000, loss: 1.1563
2022-07-01 10:47:13 - train: epoch 0056, iter [00900, 05004], lr: 0.010000, loss: 1.1082
2022-07-01 10:47:54 - train: epoch 0056, iter [01000, 05004], lr: 0.010000, loss: 1.0714
2022-07-01 10:48:36 - train: epoch 0056, iter [01100, 05004], lr: 0.010000, loss: 0.9633
2022-07-01 10:49:17 - train: epoch 0056, iter [01200, 05004], lr: 0.010000, loss: 0.8880
2022-07-01 10:49:59 - train: epoch 0056, iter [01300, 05004], lr: 0.010000, loss: 1.0324
2022-07-01 10:50:41 - train: epoch 0056, iter [01400, 05004], lr: 0.010000, loss: 1.0444
2022-07-01 10:51:22 - train: epoch 0056, iter [01500, 05004], lr: 0.010000, loss: 1.2198
2022-07-01 10:52:04 - train: epoch 0056, iter [01600, 05004], lr: 0.010000, loss: 0.9239
2022-07-01 10:52:46 - train: epoch 0056, iter [01700, 05004], lr: 0.010000, loss: 1.0906
2022-07-01 10:53:27 - train: epoch 0056, iter [01800, 05004], lr: 0.010000, loss: 1.1583
2022-07-01 10:54:09 - train: epoch 0056, iter [01900, 05004], lr: 0.010000, loss: 0.9774
2022-07-01 10:54:51 - train: epoch 0056, iter [02000, 05004], lr: 0.010000, loss: 0.9879
2022-07-01 10:55:32 - train: epoch 0056, iter [02100, 05004], lr: 0.010000, loss: 1.0663
2022-07-01 10:56:14 - train: epoch 0056, iter [02200, 05004], lr: 0.010000, loss: 1.0381
2022-07-01 10:56:56 - train: epoch 0056, iter [02300, 05004], lr: 0.010000, loss: 1.1061
2022-07-01 10:57:37 - train: epoch 0056, iter [02400, 05004], lr: 0.010000, loss: 1.0512
2022-07-01 10:58:19 - train: epoch 0056, iter [02500, 05004], lr: 0.010000, loss: 1.1498
2022-07-01 10:59:01 - train: epoch 0056, iter [02600, 05004], lr: 0.010000, loss: 0.9566
2022-07-01 10:59:43 - train: epoch 0056, iter [02700, 05004], lr: 0.010000, loss: 1.0071
2022-07-01 11:00:24 - train: epoch 0056, iter [02800, 05004], lr: 0.010000, loss: 1.0054
2022-07-01 11:01:06 - train: epoch 0056, iter [02900, 05004], lr: 0.010000, loss: 1.1079
2022-07-01 11:01:48 - train: epoch 0056, iter [03000, 05004], lr: 0.010000, loss: 1.0683
2022-07-01 11:02:29 - train: epoch 0056, iter [03100, 05004], lr: 0.010000, loss: 1.0255
2022-07-01 11:03:11 - train: epoch 0056, iter [03200, 05004], lr: 0.010000, loss: 0.8582
2022-07-01 11:03:53 - train: epoch 0056, iter [03300, 05004], lr: 0.010000, loss: 1.1989
2022-07-01 11:04:35 - train: epoch 0056, iter [03400, 05004], lr: 0.010000, loss: 0.9560
2022-07-01 11:05:16 - train: epoch 0056, iter [03500, 05004], lr: 0.010000, loss: 0.9606
2022-07-01 11:05:58 - train: epoch 0056, iter [03600, 05004], lr: 0.010000, loss: 0.8790
2022-07-01 11:06:40 - train: epoch 0056, iter [03700, 05004], lr: 0.010000, loss: 0.9188
2022-07-01 11:07:21 - train: epoch 0056, iter [03800, 05004], lr: 0.010000, loss: 0.8130
2022-07-01 11:08:03 - train: epoch 0056, iter [03900, 05004], lr: 0.010000, loss: 1.1800
2022-07-01 11:08:45 - train: epoch 0056, iter [04000, 05004], lr: 0.010000, loss: 1.0611
2022-07-01 11:09:27 - train: epoch 0056, iter [04100, 05004], lr: 0.010000, loss: 1.2400
2022-07-01 11:10:09 - train: epoch 0056, iter [04200, 05004], lr: 0.010000, loss: 1.0701
2022-07-01 11:10:50 - train: epoch 0056, iter [04300, 05004], lr: 0.010000, loss: 0.9845
2022-07-01 11:11:32 - train: epoch 0056, iter [04400, 05004], lr: 0.010000, loss: 1.1061
2022-07-01 11:12:14 - train: epoch 0056, iter [04500, 05004], lr: 0.010000, loss: 1.0879
2022-07-01 11:12:56 - train: epoch 0056, iter [04600, 05004], lr: 0.010000, loss: 0.9708
2022-07-01 11:13:38 - train: epoch 0056, iter [04700, 05004], lr: 0.010000, loss: 1.1880
2022-07-01 11:14:19 - train: epoch 0056, iter [04800, 05004], lr: 0.010000, loss: 1.1655
2022-07-01 11:15:01 - train: epoch 0056, iter [04900, 05004], lr: 0.010000, loss: 0.9688
2022-07-01 11:15:43 - train: epoch 0056, iter [05000, 05004], lr: 0.010000, loss: 1.1512
2022-07-01 11:15:45 - train: epoch 056, train_loss: 1.0179
2022-07-01 11:16:59 - eval: epoch: 056, acc1: 73.278%, acc5: 91.626%, test_loss: 1.0720, per_image_load_time: 1.985ms, per_image_inference_time: 0.879ms
2022-07-01 11:17:00 - until epoch: 056, best_acc1: 74.676%
2022-07-01 11:17:00 - epoch 057 lr: 0.010000
2022-07-01 11:17:47 - train: epoch 0057, iter [00100, 05004], lr: 0.010000, loss: 1.0434
2022-07-01 11:18:29 - train: epoch 0057, iter [00200, 05004], lr: 0.010000, loss: 0.9377
2022-07-01 11:19:10 - train: epoch 0057, iter [00300, 05004], lr: 0.010000, loss: 0.7975
2022-07-01 11:19:52 - train: epoch 0057, iter [00400, 05004], lr: 0.010000, loss: 0.8859
2022-07-01 11:20:33 - train: epoch 0057, iter [00500, 05004], lr: 0.010000, loss: 0.7887
2022-07-01 11:21:15 - train: epoch 0057, iter [00600, 05004], lr: 0.010000, loss: 1.1258
2022-07-01 11:21:57 - train: epoch 0057, iter [00700, 05004], lr: 0.010000, loss: 0.7251
2022-07-01 11:22:38 - train: epoch 0057, iter [00800, 05004], lr: 0.010000, loss: 1.0432
2022-07-01 11:23:20 - train: epoch 0057, iter [00900, 05004], lr: 0.010000, loss: 1.0828
2022-07-01 11:24:02 - train: epoch 0057, iter [01000, 05004], lr: 0.010000, loss: 0.9900
2022-07-01 11:24:43 - train: epoch 0057, iter [01100, 05004], lr: 0.010000, loss: 0.9379
2022-07-01 11:25:25 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 0.8836
2022-07-01 11:26:07 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 0.9814
2022-07-01 11:26:48 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 0.9994
2022-07-01 11:27:30 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 1.1302
2022-07-01 11:28:11 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 1.1249
2022-07-01 11:28:53 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 1.2080
2022-07-01 11:29:35 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 1.0844
2022-07-01 11:30:17 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 0.9172
2022-07-01 11:30:58 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 1.0765
2022-07-01 11:31:40 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 1.0299
2022-07-01 11:32:22 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 0.9901
2022-07-01 11:33:03 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 1.0050
2022-07-01 11:33:45 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 0.9119
2022-07-01 11:34:27 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 1.0295
2022-07-01 11:35:08 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 0.8821
2022-07-01 11:35:50 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 0.8885
2022-07-01 11:36:32 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 0.8052
2022-07-01 11:37:13 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 1.0893
2022-07-01 11:37:55 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 1.0483
2022-07-01 11:38:37 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 1.2005
2022-07-01 11:39:19 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 1.1314
2022-07-01 11:40:00 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 1.0123
2022-07-01 11:40:42 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 1.0389
2022-07-01 11:41:24 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 0.9889
2022-07-01 11:42:06 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 1.0386
2022-07-01 11:42:48 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 0.9826
2022-07-01 11:43:30 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 0.9397
2022-07-01 11:44:11 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 1.1692
2022-07-01 11:44:53 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 1.0028
2022-07-01 11:45:35 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 1.0740
2022-07-01 11:46:17 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 1.0952
2022-07-01 11:46:59 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 1.0023
2022-07-01 11:47:41 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 1.0159
2022-07-01 11:48:22 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 1.1234
2022-07-01 11:49:04 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 0.9543
2022-07-01 11:49:46 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 0.9314
2022-07-01 11:50:27 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 1.1533
2022-07-01 11:51:09 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 1.2872
2022-07-01 11:51:51 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 1.1494
2022-07-01 11:51:53 - train: epoch 057, train_loss: 1.0161
2022-07-01 11:53:07 - eval: epoch: 057, acc1: 73.824%, acc5: 92.110%, test_loss: 1.0364, per_image_load_time: 1.121ms, per_image_inference_time: 0.894ms
2022-07-01 11:53:08 - until epoch: 057, best_acc1: 74.676%
2022-07-01 11:53:08 - epoch 058 lr: 0.010000
2022-07-01 11:53:55 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 0.9543
2022-07-01 11:54:36 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 0.8526
2022-07-01 11:55:18 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 1.0460
2022-07-01 11:56:00 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 1.0432
2022-07-01 11:56:42 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 0.8797
2022-07-01 11:57:23 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 1.1441
2022-07-01 11:58:05 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 1.0067
2022-07-01 11:58:46 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 0.8485
2022-07-01 11:59:28 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 0.9010
2022-07-01 12:00:09 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 1.0212
2022-07-01 12:00:51 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 0.8308
2022-07-01 12:01:33 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 0.9249
2022-07-01 12:02:15 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 0.9806
2022-07-01 12:02:56 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 0.9593
2022-07-01 12:03:38 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 1.0507
2022-07-01 12:04:20 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 0.9881
2022-07-01 12:05:01 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 1.2325
2022-07-01 12:05:43 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 1.0814
2022-07-01 12:06:25 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 1.1844
2022-07-01 12:07:06 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 1.0517
2022-07-01 12:07:48 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 0.8956
2022-07-01 12:08:29 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 0.7904
2022-07-01 12:09:11 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 1.0261
2022-07-01 12:09:53 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 0.9609
2022-07-01 12:10:34 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 1.0792
2022-07-01 12:11:16 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 0.9656
2022-07-01 12:11:57 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 1.1272
2022-07-01 12:12:39 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 0.8754
2022-07-01 12:13:21 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 0.9507
2022-07-01 12:14:03 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 1.0632
2022-07-01 12:14:44 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 0.8102
2022-07-01 12:15:26 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 0.9435
2022-07-01 12:16:08 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 1.0808
2022-07-01 12:16:49 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 0.9963
2022-07-01 12:17:31 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 0.9578
2022-07-01 12:18:12 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 0.8333
2022-07-01 12:18:54 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 1.0099
2022-07-01 12:19:36 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 1.0332
2022-07-01 12:20:17 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 1.0439
2022-07-01 12:20:59 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 1.1618
2022-07-01 12:21:41 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 1.0857
2022-07-01 12:22:23 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 0.8833
2022-07-01 12:23:04 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 1.2281
2022-07-01 12:23:46 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 0.8718
2022-07-01 12:24:28 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 1.1468
2022-07-01 12:25:10 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 0.9499
2022-07-01 12:25:52 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 1.0025
2022-07-01 12:26:34 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 1.0766
2022-07-01 12:27:16 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 1.0438
2022-07-01 12:27:58 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 1.0142
2022-07-01 12:28:00 - train: epoch 058, train_loss: 1.0105
2022-07-01 12:29:14 - eval: epoch: 058, acc1: 73.970%, acc5: 92.048%, test_loss: 1.0414, per_image_load_time: 1.356ms, per_image_inference_time: 0.888ms
2022-07-01 12:29:15 - until epoch: 058, best_acc1: 74.676%
2022-07-01 12:29:15 - epoch 059 lr: 0.010000
2022-07-01 12:30:02 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 1.0421
2022-07-01 12:30:44 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 0.9471
2022-07-01 12:31:25 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 1.0223
2022-07-01 12:32:07 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 1.0736
2022-07-01 12:32:48 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 1.2096
2022-07-01 12:33:30 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 0.9283
2022-07-01 12:34:11 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 0.9950
2022-07-01 12:34:53 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 1.1276
2022-07-01 12:35:35 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 0.9653
2022-07-01 12:36:16 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 0.8863
2022-07-01 12:36:58 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 1.1230
2022-07-01 12:37:40 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 0.8578
2022-07-01 12:38:21 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 1.0325
2022-07-01 12:39:03 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 1.0831
2022-07-01 12:39:44 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 1.2199
2022-07-01 12:40:26 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 0.9369
2022-07-01 12:41:07 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 1.0142
2022-07-01 12:41:49 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 1.0248
2022-07-01 12:42:30 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 1.0931
2022-07-01 12:43:12 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 0.9658
2022-07-01 12:43:53 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 1.1561
2022-07-01 12:44:35 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 1.1587
2022-07-01 12:45:16 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 0.9513
2022-07-01 12:45:58 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 1.1674
2022-07-01 12:46:39 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 0.9413
2022-07-01 12:47:21 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 1.0062
2022-07-01 12:48:03 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 0.9338
2022-07-01 12:48:44 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 1.1870
2022-07-01 12:49:26 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 0.9692
2022-07-01 12:50:07 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 1.2984
2022-07-01 12:50:49 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 1.0528
2022-07-01 12:51:30 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 0.9413
2022-07-01 12:52:12 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 1.0978
2022-07-01 12:52:53 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 1.3764
2022-07-01 12:53:35 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 0.9590
2022-07-01 12:54:16 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 0.9530
2022-07-01 12:54:58 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 0.9539
2022-07-01 12:55:40 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 1.0548
2022-07-01 12:56:21 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 1.0007
2022-07-01 12:57:03 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 1.3752
2022-07-01 12:57:44 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 1.0895
2022-07-01 12:58:26 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 1.1001
2022-07-01 12:59:08 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 1.1985
2022-07-01 12:59:49 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 1.2467
2022-07-01 13:00:31 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 1.0152
2022-07-01 13:01:13 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 0.9742
2022-07-01 13:01:54 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 0.9655
2022-07-01 13:02:36 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 0.9506
2022-07-01 13:03:17 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 1.2003
2022-07-01 13:03:59 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 1.1445
2022-07-01 13:04:01 - train: epoch 059, train_loss: 1.0130
2022-07-01 13:05:15 - eval: epoch: 059, acc1: 74.066%, acc5: 92.028%, test_loss: 1.0427, per_image_load_time: 1.906ms, per_image_inference_time: 0.890ms
2022-07-01 13:05:16 - until epoch: 059, best_acc1: 74.676%
2022-07-01 13:05:16 - epoch 060 lr: 0.010000
2022-07-01 13:06:03 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 0.9199
2022-07-01 13:06:45 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 1.0224
2022-07-01 13:07:26 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 0.9680
2022-07-01 13:08:08 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 0.9909
2022-07-01 13:08:49 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 1.1078
2022-07-01 13:09:31 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 1.0752
2022-07-01 13:10:12 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 0.9705
2022-07-01 13:10:54 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 1.1675
2022-07-01 13:11:35 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 0.8514
2022-07-01 13:12:17 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 0.7525
2022-07-01 13:12:59 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 0.8418
2022-07-01 13:13:40 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 0.9067
2022-07-01 13:14:22 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 0.9415
2022-07-01 13:15:04 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 1.0309
2022-07-01 13:15:45 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 1.0080
2022-07-01 13:16:27 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 0.9840
2022-07-01 13:17:08 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 0.9188
2022-07-01 13:17:50 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 1.0334
2022-07-01 13:18:31 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 1.0237
2022-07-01 13:19:13 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 0.9702
2022-07-01 13:19:54 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 1.0254
2022-07-01 13:20:36 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 1.1193
2022-07-01 13:21:17 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 0.8483
2022-07-01 13:21:59 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 0.9400
2022-07-01 13:22:40 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 1.0003
2022-07-01 13:23:22 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 1.0982
2022-07-01 13:24:03 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 1.0644
2022-07-01 13:24:45 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 0.9173
2022-07-01 13:25:27 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 1.0503
2022-07-01 13:26:08 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 1.1596
2022-07-01 13:26:50 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 1.0128
2022-07-01 13:27:31 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 0.9972
2022-07-01 13:28:13 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 0.8179
2022-07-01 13:28:54 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 0.9695
2022-07-01 13:29:36 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 1.0522
2022-07-01 13:30:17 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 0.9478
2022-07-01 13:30:59 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 1.0403
2022-07-01 13:31:40 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 1.0621
2022-07-01 13:32:22 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 1.3910
2022-07-01 13:33:03 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 1.0838
2022-07-01 13:33:45 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 1.1254
2022-07-01 13:34:26 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 1.1826
2022-07-01 13:35:08 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 1.0618
2022-07-01 13:35:50 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 1.1125
2022-07-01 13:36:31 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 0.9678
2022-07-01 13:37:13 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 0.9627
2022-07-01 13:37:55 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 1.0046
2022-07-01 13:38:36 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 0.9132
2022-07-01 13:39:18 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 0.9638
2022-07-01 13:40:00 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 1.1028
2022-07-01 13:40:02 - train: epoch 060, train_loss: 1.0063
2022-07-01 13:41:15 - eval: epoch: 060, acc1: 73.542%, acc5: 91.678%, test_loss: 1.0562, per_image_load_time: 1.240ms, per_image_inference_time: 0.888ms
2022-07-01 13:41:16 - until epoch: 060, best_acc1: 74.676%
2022-07-01 13:41:16 - epoch 061 lr: 0.001000
2022-07-01 13:42:03 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 0.8797
2022-07-01 13:42:45 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 1.0207
2022-07-01 13:43:26 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 0.7441
2022-07-01 13:44:08 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 1.1227
2022-07-01 13:44:50 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 0.8657
2022-07-01 13:45:32 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 0.9058
2022-07-01 13:46:13 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 0.6541
2022-07-01 13:46:55 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 0.9247
2022-07-01 13:47:36 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 0.7188
2022-07-01 13:48:18 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 0.6047
2022-07-01 13:48:59 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 0.7168
2022-07-01 13:49:41 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 0.8361
2022-07-01 13:50:23 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 0.8245
2022-07-01 13:51:04 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 0.6805
2022-07-01 13:51:45 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 0.8957
2022-07-01 13:52:27 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 0.7543
2022-07-01 13:53:09 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 0.8414
2022-07-01 13:53:50 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 0.8982
2022-07-01 13:54:32 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 0.8859
2022-07-01 13:55:13 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 0.7937
2022-07-01 13:55:55 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 1.0623
2022-07-01 13:56:36 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 0.7583
2022-07-01 13:57:18 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 0.8774
2022-07-01 13:57:59 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 0.6456
2022-07-01 13:58:41 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 0.7654
2022-07-01 13:59:23 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 0.8776
2022-07-01 14:00:04 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 1.0620
2022-07-01 14:00:46 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 0.8364
2022-07-01 14:01:27 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 0.8888
2022-07-01 14:02:09 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 0.7357
2022-07-01 14:02:50 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 0.9363
2022-07-01 14:03:32 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 0.8255
2022-07-01 14:04:13 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 0.7537
2022-07-01 14:04:55 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 0.6297
2022-07-01 14:05:36 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 0.8496
2022-07-01 14:06:18 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 0.8391
2022-07-01 14:07:00 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 0.9043
2022-07-01 14:07:41 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 0.8625
2022-07-01 14:08:23 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 0.8520
2022-07-01 14:09:04 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 0.9171
2022-07-01 14:09:46 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 0.9809
2022-07-01 14:10:28 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 0.7844
2022-07-01 14:11:09 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 0.8993
2022-07-01 14:11:51 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 0.8035
2022-07-01 14:12:32 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 0.7464
2022-07-01 14:13:14 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 0.8641
2022-07-01 14:13:55 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 0.7683
2022-07-01 14:14:37 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 0.8268
2022-07-01 14:15:18 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 0.9434
2022-07-01 14:16:00 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 0.7932
2022-07-01 14:16:02 - train: epoch 061, train_loss: 0.8301
2022-07-01 14:17:17 - eval: epoch: 061, acc1: 77.176%, acc5: 93.620%, test_loss: 0.9041, per_image_load_time: 1.999ms, per_image_inference_time: 0.885ms
2022-07-01 14:17:18 - until epoch: 061, best_acc1: 77.176%
2022-07-01 14:17:18 - epoch 062 lr: 0.001000
2022-07-01 14:18:05 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 0.8614
2022-07-01 14:18:47 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 0.7942
2022-07-01 14:19:28 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 0.7002
2022-07-01 14:20:10 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 0.6011
2022-07-01 14:20:51 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 0.6186
2022-07-01 14:21:33 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 0.7806
2022-07-01 14:22:15 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 0.9695
2022-07-01 14:22:56 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 0.7853
2022-07-01 14:23:38 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 0.6041
2022-07-01 14:24:19 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 0.9765
2022-07-01 14:25:01 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 0.6622
2022-07-01 14:25:42 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 0.9419
2022-07-01 14:26:24 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 0.8239
2022-07-01 14:27:05 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 0.7777
2022-07-01 14:27:47 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 0.7896
2022-07-01 14:28:28 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 0.8297
2022-07-01 14:29:10 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 0.8881
2022-07-01 14:29:52 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 0.7146
2022-07-01 14:30:33 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 0.7171
2022-07-01 14:31:15 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 0.7042
2022-07-01 14:31:56 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 0.9062
2022-07-01 14:32:38 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 0.7019
2022-07-01 14:33:20 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 0.8289
2022-07-01 14:34:01 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 0.7260
2022-07-01 14:34:43 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 0.7884
2022-07-01 14:35:25 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 0.7534
2022-07-01 14:36:06 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 0.7688
2022-07-01 14:36:48 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 0.8974
2022-07-01 14:37:29 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 0.8340
2022-07-01 14:38:11 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 0.8978
2022-07-01 14:38:53 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 0.8271
2022-07-01 14:39:34 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 0.6167
2022-07-01 14:40:16 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 0.9709
2022-07-01 14:40:58 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 0.8591
2022-07-01 14:41:39 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 0.8624
2022-07-01 14:42:21 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 0.7939
2022-07-01 14:43:03 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 0.7536
2022-07-01 14:43:45 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 0.7585
2022-07-01 14:44:27 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 0.7570
2022-07-01 14:45:08 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 0.5918
2022-07-01 14:45:50 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 0.7582
2022-07-01 14:46:32 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 0.6759
2022-07-01 14:47:13 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 0.7529
2022-07-01 14:47:55 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 0.6672
2022-07-01 14:48:37 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 0.6935
2022-07-01 14:49:19 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 0.5883
2022-07-01 14:50:00 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 0.7699
2022-07-01 14:50:42 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 0.7102
2022-07-01 14:51:24 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 0.6940
2022-07-01 14:52:05 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 0.7457
2022-07-01 14:52:08 - train: epoch 062, train_loss: 0.7771
2022-07-01 14:53:21 - eval: epoch: 062, acc1: 77.484%, acc5: 93.730%, test_loss: 0.8917, per_image_load_time: 0.983ms, per_image_inference_time: 0.888ms
2022-07-01 14:53:22 - until epoch: 062, best_acc1: 77.484%
2022-07-01 14:53:22 - epoch 063 lr: 0.001000
2022-07-01 14:54:10 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 0.7573
2022-07-01 14:54:51 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 0.7411
2022-07-01 14:55:33 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 0.8567
2022-07-01 14:56:15 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 0.8915
2022-07-01 14:56:56 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 0.7553
2022-07-01 14:57:38 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 0.8195
2022-07-01 14:58:20 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 0.6432
2022-07-01 14:59:02 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 0.8052
2022-07-01 14:59:43 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 0.7667
2022-07-01 15:00:25 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 0.8682
2022-07-01 15:01:07 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 0.6570
2022-07-01 15:01:48 - train: epoch 0063, iter [01200, 05004], lr: 0.001000, loss: 0.6149
2022-07-01 15:02:30 - train: epoch 0063, iter [01300, 05004], lr: 0.001000, loss: 0.8407
2022-07-01 15:03:12 - train: epoch 0063, iter [01400, 05004], lr: 0.001000, loss: 1.0167
2022-07-01 15:03:53 - train: epoch 0063, iter [01500, 05004], lr: 0.001000, loss: 0.7933
2022-07-01 15:04:35 - train: epoch 0063, iter [01600, 05004], lr: 0.001000, loss: 0.6951
2022-07-01 15:05:17 - train: epoch 0063, iter [01700, 05004], lr: 0.001000, loss: 0.7259
2022-07-01 15:05:59 - train: epoch 0063, iter [01800, 05004], lr: 0.001000, loss: 0.8409
2022-07-01 15:06:40 - train: epoch 0063, iter [01900, 05004], lr: 0.001000, loss: 0.8443
2022-07-01 15:07:22 - train: epoch 0063, iter [02000, 05004], lr: 0.001000, loss: 0.6679
2022-07-01 15:08:04 - train: epoch 0063, iter [02100, 05004], lr: 0.001000, loss: 0.6311
2022-07-01 15:08:45 - train: epoch 0063, iter [02200, 05004], lr: 0.001000, loss: 1.0066
2022-07-01 15:09:27 - train: epoch 0063, iter [02300, 05004], lr: 0.001000, loss: 0.8039
2022-07-01 15:10:09 - train: epoch 0063, iter [02400, 05004], lr: 0.001000, loss: 0.8685
2022-07-01 15:10:50 - train: epoch 0063, iter [02500, 05004], lr: 0.001000, loss: 0.7486
2022-07-01 15:11:32 - train: epoch 0063, iter [02600, 05004], lr: 0.001000, loss: 0.7025
2022-07-01 15:12:13 - train: epoch 0063, iter [02700, 05004], lr: 0.001000, loss: 0.9022
2022-07-01 15:12:55 - train: epoch 0063, iter [02800, 05004], lr: 0.001000, loss: 0.7168
2022-07-01 15:13:37 - train: epoch 0063, iter [02900, 05004], lr: 0.001000, loss: 0.7605
2022-07-01 15:14:18 - train: epoch 0063, iter [03000, 05004], lr: 0.001000, loss: 0.8658
2022-07-01 15:15:00 - train: epoch 0063, iter [03100, 05004], lr: 0.001000, loss: 0.9882
2022-07-01 15:15:41 - train: epoch 0063, iter [03200, 05004], lr: 0.001000, loss: 0.8488
2022-07-01 15:16:23 - train: epoch 0063, iter [03300, 05004], lr: 0.001000, loss: 0.7497
2022-07-01 15:17:05 - train: epoch 0063, iter [03400, 05004], lr: 0.001000, loss: 0.6528
2022-07-01 15:17:46 - train: epoch 0063, iter [03500, 05004], lr: 0.001000, loss: 0.8486
2022-07-01 15:18:28 - train: epoch 0063, iter [03600, 05004], lr: 0.001000, loss: 0.6858
2022-07-01 15:19:10 - train: epoch 0063, iter [03700, 05004], lr: 0.001000, loss: 0.8584
2022-07-01 15:19:51 - train: epoch 0063, iter [03800, 05004], lr: 0.001000, loss: 1.0041
2022-07-01 15:20:33 - train: epoch 0063, iter [03900, 05004], lr: 0.001000, loss: 0.5350
2022-07-01 15:21:15 - train: epoch 0063, iter [04000, 05004], lr: 0.001000, loss: 0.5860
2022-07-01 15:21:56 - train: epoch 0063, iter [04100, 05004], lr: 0.001000, loss: 0.8544
2022-07-01 15:22:38 - train: epoch 0063, iter [04200, 05004], lr: 0.001000, loss: 0.7626
2022-07-01 15:23:19 - train: epoch 0063, iter [04300, 05004], lr: 0.001000, loss: 0.7908
2022-07-01 15:24:01 - train: epoch 0063, iter [04400, 05004], lr: 0.001000, loss: 0.7900
2022-07-01 15:24:43 - train: epoch 0063, iter [04500, 05004], lr: 0.001000, loss: 0.6857
2022-07-01 15:25:24 - train: epoch 0063, iter [04600, 05004], lr: 0.001000, loss: 0.6601
2022-07-01 15:26:06 - train: epoch 0063, iter [04700, 05004], lr: 0.001000, loss: 0.6570
2022-07-01 15:26:48 - train: epoch 0063, iter [04800, 05004], lr: 0.001000, loss: 0.7365
2022-07-01 15:27:30 - train: epoch 0063, iter [04900, 05004], lr: 0.001000, loss: 0.7111
2022-07-01 15:28:12 - train: epoch 0063, iter [05000, 05004], lr: 0.001000, loss: 0.6866
2022-07-01 15:28:14 - train: epoch 063, train_loss: 0.7561
2022-07-01 15:29:27 - eval: epoch: 063, acc1: 77.712%, acc5: 93.758%, test_loss: 0.8880, per_image_load_time: 1.832ms, per_image_inference_time: 0.887ms
2022-07-01 15:29:29 - until epoch: 063, best_acc1: 77.712%
2022-07-01 15:29:29 - epoch 064 lr: 0.001000
2022-07-01 15:30:16 - train: epoch 0064, iter [00100, 05004], lr: 0.001000, loss: 0.7305
2022-07-01 15:30:58 - train: epoch 0064, iter [00200, 05004], lr: 0.001000, loss: 0.7845
2022-07-01 15:31:39 - train: epoch 0064, iter [00300, 05004], lr: 0.001000, loss: 0.5404
2022-07-01 15:32:21 - train: epoch 0064, iter [00400, 05004], lr: 0.001000, loss: 0.8583
2022-07-01 15:33:02 - train: epoch 0064, iter [00500, 05004], lr: 0.001000, loss: 0.7181
2022-07-01 15:33:44 - train: epoch 0064, iter [00600, 05004], lr: 0.001000, loss: 0.8078
2022-07-01 15:34:26 - train: epoch 0064, iter [00700, 05004], lr: 0.001000, loss: 0.8791
2022-07-01 15:35:07 - train: epoch 0064, iter [00800, 05004], lr: 0.001000, loss: 0.7045
2022-07-01 15:35:49 - train: epoch 0064, iter [00900, 05004], lr: 0.001000, loss: 0.6947
2022-07-01 15:36:30 - train: epoch 0064, iter [01000, 05004], lr: 0.001000, loss: 0.6785
2022-07-01 15:37:12 - train: epoch 0064, iter [01100, 05004], lr: 0.001000, loss: 0.6405
2022-07-01 15:37:53 - train: epoch 0064, iter [01200, 05004], lr: 0.001000, loss: 0.6512
2022-07-01 15:38:35 - train: epoch 0064, iter [01300, 05004], lr: 0.001000, loss: 0.7415
2022-07-01 15:39:16 - train: epoch 0064, iter [01400, 05004], lr: 0.001000, loss: 0.9789
2022-07-01 15:39:58 - train: epoch 0064, iter [01500, 05004], lr: 0.001000, loss: 0.7642
2022-07-01 15:40:39 - train: epoch 0064, iter [01600, 05004], lr: 0.001000, loss: 0.6698
2022-07-01 15:41:21 - train: epoch 0064, iter [01700, 05004], lr: 0.001000, loss: 0.6456
2022-07-01 15:42:03 - train: epoch 0064, iter [01800, 05004], lr: 0.001000, loss: 0.6378
2022-07-01 15:42:44 - train: epoch 0064, iter [01900, 05004], lr: 0.001000, loss: 0.6157
2022-07-01 15:43:26 - train: epoch 0064, iter [02000, 05004], lr: 0.001000, loss: 0.7125
2022-07-01 15:44:07 - train: epoch 0064, iter [02100, 05004], lr: 0.001000, loss: 0.8385
2022-07-01 15:44:49 - train: epoch 0064, iter [02200, 05004], lr: 0.001000, loss: 0.7537
2022-07-01 15:45:30 - train: epoch 0064, iter [02300, 05004], lr: 0.001000, loss: 0.8351
2022-07-01 15:46:12 - train: epoch 0064, iter [02400, 05004], lr: 0.001000, loss: 0.6766
2022-07-01 15:46:53 - train: epoch 0064, iter [02500, 05004], lr: 0.001000, loss: 0.5719
2022-07-01 15:47:35 - train: epoch 0064, iter [02600, 05004], lr: 0.001000, loss: 0.6445
2022-07-01 15:48:17 - train: epoch 0064, iter [02700, 05004], lr: 0.001000, loss: 0.7076
2022-07-01 15:48:58 - train: epoch 0064, iter [02800, 05004], lr: 0.001000, loss: 0.6960
2022-07-01 15:49:40 - train: epoch 0064, iter [02900, 05004], lr: 0.001000, loss: 0.9559
2022-07-01 15:50:22 - train: epoch 0064, iter [03000, 05004], lr: 0.001000, loss: 0.7906
2022-07-01 15:51:03 - train: epoch 0064, iter [03100, 05004], lr: 0.001000, loss: 0.7018
2022-07-01 15:51:45 - train: epoch 0064, iter [03200, 05004], lr: 0.001000, loss: 0.7141
2022-07-01 15:52:26 - train: epoch 0064, iter [03300, 05004], lr: 0.001000, loss: 0.7613
2022-07-01 15:53:08 - train: epoch 0064, iter [03400, 05004], lr: 0.001000, loss: 0.8187
2022-07-01 15:53:50 - train: epoch 0064, iter [03500, 05004], lr: 0.001000, loss: 0.6710
2022-07-01 15:54:31 - train: epoch 0064, iter [03600, 05004], lr: 0.001000, loss: 0.6632
2022-07-01 15:55:13 - train: epoch 0064, iter [03700, 05004], lr: 0.001000, loss: 0.5725
2022-07-01 15:55:55 - train: epoch 0064, iter [03800, 05004], lr: 0.001000, loss: 0.8274
2022-07-01 15:56:36 - train: epoch 0064, iter [03900, 05004], lr: 0.001000, loss: 0.6587
2022-07-01 15:57:18 - train: epoch 0064, iter [04000, 05004], lr: 0.001000, loss: 0.5940
2022-07-01 15:58:00 - train: epoch 0064, iter [04100, 05004], lr: 0.001000, loss: 0.7258
2022-07-01 15:58:42 - train: epoch 0064, iter [04200, 05004], lr: 0.001000, loss: 0.7058
2022-07-01 15:59:23 - train: epoch 0064, iter [04300, 05004], lr: 0.001000, loss: 0.8683
2022-07-01 16:00:05 - train: epoch 0064, iter [04400, 05004], lr: 0.001000, loss: 0.7390
2022-07-01 16:00:47 - train: epoch 0064, iter [04500, 05004], lr: 0.001000, loss: 0.6143
2022-07-01 16:01:29 - train: epoch 0064, iter [04600, 05004], lr: 0.001000, loss: 0.9313
2022-07-01 16:02:11 - train: epoch 0064, iter [04700, 05004], lr: 0.001000, loss: 1.0026
2022-07-01 16:02:52 - train: epoch 0064, iter [04800, 05004], lr: 0.001000, loss: 0.6611
2022-07-01 16:03:34 - train: epoch 0064, iter [04900, 05004], lr: 0.001000, loss: 0.9324
2022-07-01 16:04:16 - train: epoch 0064, iter [05000, 05004], lr: 0.001000, loss: 0.5954
2022-07-01 16:04:18 - train: epoch 064, train_loss: 0.7409
2022-07-01 16:05:33 - eval: epoch: 064, acc1: 77.684%, acc5: 93.796%, test_loss: 0.8860, per_image_load_time: 1.988ms, per_image_inference_time: 0.891ms
2022-07-01 16:05:34 - until epoch: 064, best_acc1: 77.712%
2022-07-01 16:05:34 - epoch 065 lr: 0.001000
2022-07-01 16:06:21 - train: epoch 0065, iter [00100, 05004], lr: 0.001000, loss: 0.8081
2022-07-01 16:07:02 - train: epoch 0065, iter [00200, 05004], lr: 0.001000, loss: 0.6939
2022-07-01 16:07:44 - train: epoch 0065, iter [00300, 05004], lr: 0.001000, loss: 0.7951
2022-07-01 16:08:25 - train: epoch 0065, iter [00400, 05004], lr: 0.001000, loss: 0.8288
2022-07-01 16:09:07 - train: epoch 0065, iter [00500, 05004], lr: 0.001000, loss: 0.6039
2022-07-01 16:09:49 - train: epoch 0065, iter [00600, 05004], lr: 0.001000, loss: 0.7743
2022-07-01 16:10:30 - train: epoch 0065, iter [00700, 05004], lr: 0.001000, loss: 0.5804
2022-07-01 16:11:12 - train: epoch 0065, iter [00800, 05004], lr: 0.001000, loss: 0.7477
2022-07-01 16:11:53 - train: epoch 0065, iter [00900, 05004], lr: 0.001000, loss: 0.6874
2022-07-01 16:12:35 - train: epoch 0065, iter [01000, 05004], lr: 0.001000, loss: 0.6890
2022-07-01 16:13:16 - train: epoch 0065, iter [01100, 05004], lr: 0.001000, loss: 0.7202
2022-07-01 16:13:58 - train: epoch 0065, iter [01200, 05004], lr: 0.001000, loss: 0.8895
2022-07-01 16:14:39 - train: epoch 0065, iter [01300, 05004], lr: 0.001000, loss: 0.7433
2022-07-01 16:15:21 - train: epoch 0065, iter [01400, 05004], lr: 0.001000, loss: 0.5797
2022-07-01 16:16:03 - train: epoch 0065, iter [01500, 05004], lr: 0.001000, loss: 0.7325
2022-07-01 16:16:44 - train: epoch 0065, iter [01600, 05004], lr: 0.001000, loss: 0.6929
2022-07-01 16:17:26 - train: epoch 0065, iter [01700, 05004], lr: 0.001000, loss: 0.6482
2022-07-01 16:18:08 - train: epoch 0065, iter [01800, 05004], lr: 0.001000, loss: 0.6665
2022-07-01 16:18:50 - train: epoch 0065, iter [01900, 05004], lr: 0.001000, loss: 0.6887
2022-07-01 16:19:31 - train: epoch 0065, iter [02000, 05004], lr: 0.001000, loss: 0.6960
2022-07-01 16:20:13 - train: epoch 0065, iter [02100, 05004], lr: 0.001000, loss: 0.7946
2022-07-01 16:20:55 - train: epoch 0065, iter [02200, 05004], lr: 0.001000, loss: 0.8367
2022-07-01 16:21:36 - train: epoch 0065, iter [02300, 05004], lr: 0.001000, loss: 0.7100
2022-07-01 16:22:18 - train: epoch 0065, iter [02400, 05004], lr: 0.001000, loss: 0.6608
2022-07-01 16:23:00 - train: epoch 0065, iter [02500, 05004], lr: 0.001000, loss: 0.7646
2022-07-01 16:23:41 - train: epoch 0065, iter [02600, 05004], lr: 0.001000, loss: 0.7650
2022-07-01 16:24:23 - train: epoch 0065, iter [02700, 05004], lr: 0.001000, loss: 0.7349
2022-07-01 16:25:05 - train: epoch 0065, iter [02800, 05004], lr: 0.001000, loss: 0.6511
2022-07-01 16:25:46 - train: epoch 0065, iter [02900, 05004], lr: 0.001000, loss: 0.8338
2022-07-01 16:26:28 - train: epoch 0065, iter [03000, 05004], lr: 0.001000, loss: 0.6535
2022-07-01 16:27:09 - train: epoch 0065, iter [03100, 05004], lr: 0.001000, loss: 0.7531
2022-07-01 16:27:51 - train: epoch 0065, iter [03200, 05004], lr: 0.001000, loss: 0.7632
2022-07-01 16:28:32 - train: epoch 0065, iter [03300, 05004], lr: 0.001000, loss: 0.6368
2022-07-01 16:29:14 - train: epoch 0065, iter [03400, 05004], lr: 0.001000, loss: 0.6188
2022-07-01 16:29:56 - train: epoch 0065, iter [03500, 05004], lr: 0.001000, loss: 0.8668
2022-07-01 16:30:37 - train: epoch 0065, iter [03600, 05004], lr: 0.001000, loss: 0.7205
2022-07-01 16:31:19 - train: epoch 0065, iter [03700, 05004], lr: 0.001000, loss: 0.6824
2022-07-01 16:32:00 - train: epoch 0065, iter [03800, 05004], lr: 0.001000, loss: 0.5977
2022-07-01 16:32:42 - train: epoch 0065, iter [03900, 05004], lr: 0.001000, loss: 0.7129
2022-07-01 16:33:24 - train: epoch 0065, iter [04000, 05004], lr: 0.001000, loss: 0.7144
2022-07-01 16:34:05 - train: epoch 0065, iter [04100, 05004], lr: 0.001000, loss: 0.6067
2022-07-01 16:34:47 - train: epoch 0065, iter [04200, 05004], lr: 0.001000, loss: 0.7562
2022-07-01 16:35:29 - train: epoch 0065, iter [04300, 05004], lr: 0.001000, loss: 0.6379
2022-07-01 16:36:10 - train: epoch 0065, iter [04400, 05004], lr: 0.001000, loss: 0.6560
2022-07-01 16:36:52 - train: epoch 0065, iter [04500, 05004], lr: 0.001000, loss: 0.6457
2022-07-01 16:37:33 - train: epoch 0065, iter [04600, 05004], lr: 0.001000, loss: 0.7026
2022-07-01 16:38:15 - train: epoch 0065, iter [04700, 05004], lr: 0.001000, loss: 0.7965
2022-07-01 16:38:57 - train: epoch 0065, iter [04800, 05004], lr: 0.001000, loss: 0.4933
2022-07-01 16:39:38 - train: epoch 0065, iter [04900, 05004], lr: 0.001000, loss: 0.6194
2022-07-01 16:40:20 - train: epoch 0065, iter [05000, 05004], lr: 0.001000, loss: 0.8123
2022-07-01 16:40:22 - train: epoch 065, train_loss: 0.7276
2022-07-01 16:41:36 - eval: epoch: 065, acc1: 77.780%, acc5: 93.810%, test_loss: 0.8852, per_image_load_time: 1.657ms, per_image_inference_time: 0.883ms
2022-07-01 16:41:37 - until epoch: 065, best_acc1: 77.780%
2022-07-01 16:41:37 - epoch 066 lr: 0.001000
2022-07-01 16:42:24 - train: epoch 0066, iter [00100, 05004], lr: 0.001000, loss: 0.5846
2022-07-01 16:43:06 - train: epoch 0066, iter [00200, 05004], lr: 0.001000, loss: 0.8333
2022-07-01 16:43:48 - train: epoch 0066, iter [00300, 05004], lr: 0.001000, loss: 0.5388
2022-07-01 16:44:29 - train: epoch 0066, iter [00400, 05004], lr: 0.001000, loss: 0.5495
2022-07-01 16:45:11 - train: epoch 0066, iter [00500, 05004], lr: 0.001000, loss: 0.7383
2022-07-01 16:45:52 - train: epoch 0066, iter [00600, 05004], lr: 0.001000, loss: 0.6963
2022-07-01 16:46:34 - train: epoch 0066, iter [00700, 05004], lr: 0.001000, loss: 0.6941
2022-07-01 16:47:16 - train: epoch 0066, iter [00800, 05004], lr: 0.001000, loss: 0.9124
2022-07-01 16:47:57 - train: epoch 0066, iter [00900, 05004], lr: 0.001000, loss: 0.7700
2022-07-01 16:48:39 - train: epoch 0066, iter [01000, 05004], lr: 0.001000, loss: 0.8085
2022-07-01 16:49:20 - train: epoch 0066, iter [01100, 05004], lr: 0.001000, loss: 0.7795
2022-07-01 16:50:02 - train: epoch 0066, iter [01200, 05004], lr: 0.001000, loss: 0.7516
2022-07-01 16:50:43 - train: epoch 0066, iter [01300, 05004], lr: 0.001000, loss: 0.8020
2022-07-01 16:51:25 - train: epoch 0066, iter [01400, 05004], lr: 0.001000, loss: 0.5525
2022-07-01 16:52:06 - train: epoch 0066, iter [01500, 05004], lr: 0.001000, loss: 0.7655
2022-07-01 16:52:48 - train: epoch 0066, iter [01600, 05004], lr: 0.001000, loss: 0.6898
2022-07-01 16:53:29 - train: epoch 0066, iter [01700, 05004], lr: 0.001000, loss: 0.6759
2022-07-01 16:54:11 - train: epoch 0066, iter [01800, 05004], lr: 0.001000, loss: 0.6793
2022-07-01 16:54:52 - train: epoch 0066, iter [01900, 05004], lr: 0.001000, loss: 0.9013
2022-07-01 16:55:34 - train: epoch 0066, iter [02000, 05004], lr: 0.001000, loss: 0.7954
2022-07-01 16:56:15 - train: epoch 0066, iter [02100, 05004], lr: 0.001000, loss: 0.6662
2022-07-01 16:56:57 - train: epoch 0066, iter [02200, 05004], lr: 0.001000, loss: 0.7124
2022-07-01 16:57:38 - train: epoch 0066, iter [02300, 05004], lr: 0.001000, loss: 0.8801
2022-07-01 16:58:20 - train: epoch 0066, iter [02400, 05004], lr: 0.001000, loss: 0.6081
2022-07-01 16:59:01 - train: epoch 0066, iter [02500, 05004], lr: 0.001000, loss: 0.6806
2022-07-01 16:59:43 - train: epoch 0066, iter [02600, 05004], lr: 0.001000, loss: 0.5780
2022-07-01 17:00:24 - train: epoch 0066, iter [02700, 05004], lr: 0.001000, loss: 0.9045
2022-07-01 17:01:06 - train: epoch 0066, iter [02800, 05004], lr: 0.001000, loss: 0.8884
2022-07-01 17:01:47 - train: epoch 0066, iter [02900, 05004], lr: 0.001000, loss: 0.6118
2022-07-01 17:02:29 - train: epoch 0066, iter [03000, 05004], lr: 0.001000, loss: 0.6826
2022-07-01 17:03:10 - train: epoch 0066, iter [03100, 05004], lr: 0.001000, loss: 0.7831
2022-07-01 17:03:52 - train: epoch 0066, iter [03200, 05004], lr: 0.001000, loss: 0.5323
2022-07-01 17:04:33 - train: epoch 0066, iter [03300, 05004], lr: 0.001000, loss: 0.6412
2022-07-01 17:05:15 - train: epoch 0066, iter [03400, 05004], lr: 0.001000, loss: 0.8963
2022-07-01 17:05:56 - train: epoch 0066, iter [03500, 05004], lr: 0.001000, loss: 0.6458
2022-07-01 17:06:38 - train: epoch 0066, iter [03600, 05004], lr: 0.001000, loss: 0.8114
2022-07-01 17:07:19 - train: epoch 0066, iter [03700, 05004], lr: 0.001000, loss: 0.7424
2022-07-01 17:08:01 - train: epoch 0066, iter [03800, 05004], lr: 0.001000, loss: 0.5781
2022-07-01 17:08:42 - train: epoch 0066, iter [03900, 05004], lr: 0.001000, loss: 0.6569
2022-07-01 17:09:24 - train: epoch 0066, iter [04000, 05004], lr: 0.001000, loss: 0.8399
2022-07-01 17:10:05 - train: epoch 0066, iter [04100, 05004], lr: 0.001000, loss: 0.6231
2022-07-01 17:10:46 - train: epoch 0066, iter [04200, 05004], lr: 0.001000, loss: 0.5713
2022-07-01 17:11:28 - train: epoch 0066, iter [04300, 05004], lr: 0.001000, loss: 0.6131
2022-07-01 17:12:10 - train: epoch 0066, iter [04400, 05004], lr: 0.001000, loss: 0.6837
2022-07-01 17:12:51 - train: epoch 0066, iter [04500, 05004], lr: 0.001000, loss: 0.7206
2022-07-01 17:13:33 - train: epoch 0066, iter [04600, 05004], lr: 0.001000, loss: 0.8780
2022-07-01 17:14:14 - train: epoch 0066, iter [04700, 05004], lr: 0.001000, loss: 0.6475
2022-07-01 17:14:56 - train: epoch 0066, iter [04800, 05004], lr: 0.001000, loss: 0.7204
2022-07-01 17:15:37 - train: epoch 0066, iter [04900, 05004], lr: 0.001000, loss: 0.7551
2022-07-01 17:16:18 - train: epoch 0066, iter [05000, 05004], lr: 0.001000, loss: 0.6710
2022-07-01 17:16:20 - train: epoch 066, train_loss: 0.7183
2022-07-01 17:17:35 - eval: epoch: 066, acc1: 77.796%, acc5: 93.858%, test_loss: 0.8810, per_image_load_time: 2.001ms, per_image_inference_time: 0.876ms
2022-07-01 17:17:36 - until epoch: 066, best_acc1: 77.796%
2022-07-01 17:17:36 - epoch 067 lr: 0.001000
2022-07-01 17:18:23 - train: epoch 0067, iter [00100, 05004], lr: 0.001000, loss: 0.6129
2022-07-01 17:19:05 - train: epoch 0067, iter [00200, 05004], lr: 0.001000, loss: 0.6344
2022-07-01 17:19:46 - train: epoch 0067, iter [00300, 05004], lr: 0.001000, loss: 0.9420
2022-07-01 17:20:28 - train: epoch 0067, iter [00400, 05004], lr: 0.001000, loss: 0.8215
2022-07-01 17:21:10 - train: epoch 0067, iter [00500, 05004], lr: 0.001000, loss: 0.7715
2022-07-01 17:21:51 - train: epoch 0067, iter [00600, 05004], lr: 0.001000, loss: 0.7433
2022-07-01 17:22:33 - train: epoch 0067, iter [00700, 05004], lr: 0.001000, loss: 0.7789
2022-07-01 17:23:15 - train: epoch 0067, iter [00800, 05004], lr: 0.001000, loss: 0.7740
2022-07-01 17:23:56 - train: epoch 0067, iter [00900, 05004], lr: 0.001000, loss: 0.6843
2022-07-01 17:24:38 - train: epoch 0067, iter [01000, 05004], lr: 0.001000, loss: 0.5559
2022-07-01 17:25:20 - train: epoch 0067, iter [01100, 05004], lr: 0.001000, loss: 0.7328
2022-07-01 17:26:01 - train: epoch 0067, iter [01200, 05004], lr: 0.001000, loss: 0.7549
2022-07-01 17:26:43 - train: epoch 0067, iter [01300, 05004], lr: 0.001000, loss: 0.8832
2022-07-01 17:27:24 - train: epoch 0067, iter [01400, 05004], lr: 0.001000, loss: 0.6956
2022-07-01 17:28:06 - train: epoch 0067, iter [01500, 05004], lr: 0.001000, loss: 0.7946
2022-07-01 17:28:48 - train: epoch 0067, iter [01600, 05004], lr: 0.001000, loss: 0.7212
2022-07-01 17:29:30 - train: epoch 0067, iter [01700, 05004], lr: 0.001000, loss: 0.6581
2022-07-01 17:30:11 - train: epoch 0067, iter [01800, 05004], lr: 0.001000, loss: 0.8178
2022-07-01 17:30:53 - train: epoch 0067, iter [01900, 05004], lr: 0.001000, loss: 0.5995
2022-07-01 17:31:35 - train: epoch 0067, iter [02000, 05004], lr: 0.001000, loss: 0.8033
2022-07-01 17:32:16 - train: epoch 0067, iter [02100, 05004], lr: 0.001000, loss: 0.6517
2022-07-01 17:32:58 - train: epoch 0067, iter [02200, 05004], lr: 0.001000, loss: 0.8226
2022-07-01 17:33:40 - train: epoch 0067, iter [02300, 05004], lr: 0.001000, loss: 0.6698
2022-07-01 17:34:22 - train: epoch 0067, iter [02400, 05004], lr: 0.001000, loss: 0.7266
2022-07-01 17:35:04 - train: epoch 0067, iter [02500, 05004], lr: 0.001000, loss: 0.6637
2022-07-01 17:35:46 - train: epoch 0067, iter [02600, 05004], lr: 0.001000, loss: 0.5971
2022-07-01 17:36:28 - train: epoch 0067, iter [02700, 05004], lr: 0.001000, loss: 0.6930
2022-07-01 17:37:09 - train: epoch 0067, iter [02800, 05004], lr: 0.001000, loss: 0.7588
2022-07-01 17:37:51 - train: epoch 0067, iter [02900, 05004], lr: 0.001000, loss: 0.6145
2022-07-01 17:38:33 - train: epoch 0067, iter [03000, 05004], lr: 0.001000, loss: 0.7039
2022-07-01 17:39:15 - train: epoch 0067, iter [03100, 05004], lr: 0.001000, loss: 0.6143
2022-07-01 17:39:57 - train: epoch 0067, iter [03200, 05004], lr: 0.001000, loss: 0.7282
2022-07-01 17:40:38 - train: epoch 0067, iter [03300, 05004], lr: 0.001000, loss: 0.6155
2022-07-01 17:41:20 - train: epoch 0067, iter [03400, 05004], lr: 0.001000, loss: 0.6731
2022-07-01 17:42:02 - train: epoch 0067, iter [03500, 05004], lr: 0.001000, loss: 0.5864
2022-07-01 17:42:44 - train: epoch 0067, iter [03600, 05004], lr: 0.001000, loss: 0.6985
2022-07-01 17:43:25 - train: epoch 0067, iter [03700, 05004], lr: 0.001000, loss: 0.8367
2022-07-01 17:44:07 - train: epoch 0067, iter [03800, 05004], lr: 0.001000, loss: 0.6189
2022-07-01 17:44:49 - train: epoch 0067, iter [03900, 05004], lr: 0.001000, loss: 0.7119
2022-07-01 17:45:31 - train: epoch 0067, iter [04000, 05004], lr: 0.001000, loss: 0.8246
2022-07-01 17:46:13 - train: epoch 0067, iter [04100, 05004], lr: 0.001000, loss: 0.7924
2022-07-01 17:46:55 - train: epoch 0067, iter [04200, 05004], lr: 0.001000, loss: 0.8639
2022-07-01 17:47:36 - train: epoch 0067, iter [04300, 05004], lr: 0.001000, loss: 0.6572
2022-07-01 17:48:18 - train: epoch 0067, iter [04400, 05004], lr: 0.001000, loss: 0.7291
2022-07-01 17:49:00 - train: epoch 0067, iter [04500, 05004], lr: 0.001000, loss: 0.6344
2022-07-01 17:49:42 - train: epoch 0067, iter [04600, 05004], lr: 0.001000, loss: 0.5343
2022-07-01 17:50:24 - train: epoch 0067, iter [04700, 05004], lr: 0.001000, loss: 0.6406
2022-07-01 17:51:06 - train: epoch 0067, iter [04800, 05004], lr: 0.001000, loss: 0.5743
2022-07-01 17:51:48 - train: epoch 0067, iter [04900, 05004], lr: 0.001000, loss: 0.6736
2022-07-01 17:52:30 - train: epoch 0067, iter [05000, 05004], lr: 0.001000, loss: 0.7597
2022-07-01 17:52:32 - train: epoch 067, train_loss: 0.7098
2022-07-01 17:53:46 - eval: epoch: 067, acc1: 77.896%, acc5: 93.920%, test_loss: 0.8838, per_image_load_time: 2.032ms, per_image_inference_time: 0.866ms
2022-07-01 17:53:47 - until epoch: 067, best_acc1: 77.896%
2022-07-01 17:53:47 - epoch 068 lr: 0.001000
2022-07-01 17:54:34 - train: epoch 0068, iter [00100, 05004], lr: 0.001000, loss: 0.7732
2022-07-01 17:55:15 - train: epoch 0068, iter [00200, 05004], lr: 0.001000, loss: 0.7646
2022-07-01 17:55:57 - train: epoch 0068, iter [00300, 05004], lr: 0.001000, loss: 0.7299
2022-07-01 17:56:38 - train: epoch 0068, iter [00400, 05004], lr: 0.001000, loss: 0.7362
2022-07-01 17:57:20 - train: epoch 0068, iter [00500, 05004], lr: 0.001000, loss: 0.7093
2022-07-01 17:58:01 - train: epoch 0068, iter [00600, 05004], lr: 0.001000, loss: 0.7253
2022-07-01 17:58:43 - train: epoch 0068, iter [00700, 05004], lr: 0.001000, loss: 1.0204
2022-07-01 17:59:24 - train: epoch 0068, iter [00800, 05004], lr: 0.001000, loss: 0.7065
2022-07-01 18:00:05 - train: epoch 0068, iter [00900, 05004], lr: 0.001000, loss: 0.6241
2022-07-01 18:00:47 - train: epoch 0068, iter [01000, 05004], lr: 0.001000, loss: 0.6790
2022-07-01 18:01:28 - train: epoch 0068, iter [01100, 05004], lr: 0.001000, loss: 0.8252
2022-07-01 18:02:09 - train: epoch 0068, iter [01200, 05004], lr: 0.001000, loss: 0.6259
2022-07-01 18:02:51 - train: epoch 0068, iter [01300, 05004], lr: 0.001000, loss: 0.5913
2022-07-01 18:03:32 - train: epoch 0068, iter [01400, 05004], lr: 0.001000, loss: 0.7163
2022-07-01 18:04:13 - train: epoch 0068, iter [01500, 05004], lr: 0.001000, loss: 0.8082
2022-07-01 18:04:55 - train: epoch 0068, iter [01600, 05004], lr: 0.001000, loss: 0.7599
2022-07-01 18:05:36 - train: epoch 0068, iter [01700, 05004], lr: 0.001000, loss: 0.8709
2022-07-01 18:06:17 - train: epoch 0068, iter [01800, 05004], lr: 0.001000, loss: 0.7499
2022-07-01 18:06:59 - train: epoch 0068, iter [01900, 05004], lr: 0.001000, loss: 0.6910
2022-07-01 18:07:40 - train: epoch 0068, iter [02000, 05004], lr: 0.001000, loss: 0.6953
2022-07-01 18:08:22 - train: epoch 0068, iter [02100, 05004], lr: 0.001000, loss: 0.6560
2022-07-01 18:09:03 - train: epoch 0068, iter [02200, 05004], lr: 0.001000, loss: 0.7847
2022-07-01 18:09:44 - train: epoch 0068, iter [02300, 05004], lr: 0.001000, loss: 0.6091
2022-07-01 18:10:26 - train: epoch 0068, iter [02400, 05004], lr: 0.001000, loss: 0.7751
2022-07-01 18:11:07 - train: epoch 0068, iter [02500, 05004], lr: 0.001000, loss: 0.6296
2022-07-01 18:11:49 - train: epoch 0068, iter [02600, 05004], lr: 0.001000, loss: 0.7019
2022-07-01 18:12:30 - train: epoch 0068, iter [02700, 05004], lr: 0.001000, loss: 0.7196
2022-07-01 18:13:11 - train: epoch 0068, iter [02800, 05004], lr: 0.001000, loss: 0.8488
2022-07-01 18:13:53 - train: epoch 0068, iter [02900, 05004], lr: 0.001000, loss: 0.7458
2022-07-01 18:14:34 - train: epoch 0068, iter [03000, 05004], lr: 0.001000, loss: 0.8335
2022-07-01 18:15:16 - train: epoch 0068, iter [03100, 05004], lr: 0.001000, loss: 0.6408
2022-07-01 18:15:57 - train: epoch 0068, iter [03200, 05004], lr: 0.001000, loss: 0.7592
2022-07-01 18:16:39 - train: epoch 0068, iter [03300, 05004], lr: 0.001000, loss: 0.6591
2022-07-01 18:17:20 - train: epoch 0068, iter [03400, 05004], lr: 0.001000, loss: 0.5955
2022-07-01 18:18:01 - train: epoch 0068, iter [03500, 05004], lr: 0.001000, loss: 0.7397
2022-07-01 18:18:43 - train: epoch 0068, iter [03600, 05004], lr: 0.001000, loss: 0.6554
2022-07-01 18:19:25 - train: epoch 0068, iter [03700, 05004], lr: 0.001000, loss: 0.8216
2022-07-01 18:20:06 - train: epoch 0068, iter [03800, 05004], lr: 0.001000, loss: 0.7205
2022-07-01 18:20:48 - train: epoch 0068, iter [03900, 05004], lr: 0.001000, loss: 0.7502
2022-07-01 18:21:29 - train: epoch 0068, iter [04000, 05004], lr: 0.001000, loss: 0.7003
2022-07-01 18:22:11 - train: epoch 0068, iter [04100, 05004], lr: 0.001000, loss: 0.5868
2022-07-01 18:22:52 - train: epoch 0068, iter [04200, 05004], lr: 0.001000, loss: 0.8515
2022-07-01 18:23:34 - train: epoch 0068, iter [04300, 05004], lr: 0.001000, loss: 0.8111
2022-07-01 18:24:15 - train: epoch 0068, iter [04400, 05004], lr: 0.001000, loss: 0.6615
2022-07-01 18:24:57 - train: epoch 0068, iter [04500, 05004], lr: 0.001000, loss: 0.7953
2022-07-01 18:25:38 - train: epoch 0068, iter [04600, 05004], lr: 0.001000, loss: 0.8694
2022-07-01 18:26:20 - train: epoch 0068, iter [04700, 05004], lr: 0.001000, loss: 0.9078
2022-07-01 18:27:01 - train: epoch 0068, iter [04800, 05004], lr: 0.001000, loss: 0.7837
2022-07-01 18:27:43 - train: epoch 0068, iter [04900, 05004], lr: 0.001000, loss: 0.8102
2022-07-01 18:28:25 - train: epoch 0068, iter [05000, 05004], lr: 0.001000, loss: 0.6085
2022-07-01 18:28:27 - train: epoch 068, train_loss: 0.7013
2022-07-01 18:29:41 - eval: epoch: 068, acc1: 77.856%, acc5: 93.810%, test_loss: 0.8874, per_image_load_time: 2.014ms, per_image_inference_time: 0.868ms
2022-07-01 18:29:42 - until epoch: 068, best_acc1: 77.896%
2022-07-01 18:29:42 - epoch 069 lr: 0.001000
2022-07-01 18:30:29 - train: epoch 0069, iter [00100, 05004], lr: 0.001000, loss: 0.8294
2022-07-01 18:31:10 - train: epoch 0069, iter [00200, 05004], lr: 0.001000, loss: 0.8239
2022-07-01 18:31:52 - train: epoch 0069, iter [00300, 05004], lr: 0.001000, loss: 0.7759
2022-07-01 18:32:34 - train: epoch 0069, iter [00400, 05004], lr: 0.001000, loss: 0.7293
2022-07-01 18:33:15 - train: epoch 0069, iter [00500, 05004], lr: 0.001000, loss: 0.5799
2022-07-01 18:33:57 - train: epoch 0069, iter [00600, 05004], lr: 0.001000, loss: 0.6650
2022-07-01 18:34:38 - train: epoch 0069, iter [00700, 05004], lr: 0.001000, loss: 0.6395
2022-07-01 18:35:20 - train: epoch 0069, iter [00800, 05004], lr: 0.001000, loss: 0.6895
2022-07-01 18:36:01 - train: epoch 0069, iter [00900, 05004], lr: 0.001000, loss: 0.6666
2022-07-01 18:36:43 - train: epoch 0069, iter [01000, 05004], lr: 0.001000, loss: 0.6540
2022-07-01 18:37:25 - train: epoch 0069, iter [01100, 05004], lr: 0.001000, loss: 0.6829
2022-07-01 18:38:06 - train: epoch 0069, iter [01200, 05004], lr: 0.001000, loss: 0.6658
2022-07-01 18:38:48 - train: epoch 0069, iter [01300, 05004], lr: 0.001000, loss: 0.8635
2022-07-01 18:39:29 - train: epoch 0069, iter [01400, 05004], lr: 0.001000, loss: 0.8469
2022-07-01 18:40:11 - train: epoch 0069, iter [01500, 05004], lr: 0.001000, loss: 0.7404
2022-07-01 18:40:52 - train: epoch 0069, iter [01600, 05004], lr: 0.001000, loss: 0.7062
2022-07-01 18:41:34 - train: epoch 0069, iter [01700, 05004], lr: 0.001000, loss: 0.7084
2022-07-01 18:42:16 - train: epoch 0069, iter [01800, 05004], lr: 0.001000, loss: 0.5553
2022-07-01 18:42:57 - train: epoch 0069, iter [01900, 05004], lr: 0.001000, loss: 0.6236
2022-07-01 18:43:39 - train: epoch 0069, iter [02000, 05004], lr: 0.001000, loss: 0.4705
2022-07-01 18:44:20 - train: epoch 0069, iter [02100, 05004], lr: 0.001000, loss: 0.7430
2022-07-01 18:45:02 - train: epoch 0069, iter [02200, 05004], lr: 0.001000, loss: 0.8090
2022-07-01 18:45:44 - train: epoch 0069, iter [02300, 05004], lr: 0.001000, loss: 0.7364
2022-07-01 18:46:25 - train: epoch 0069, iter [02400, 05004], lr: 0.001000, loss: 0.7399
2022-07-01 18:47:06 - train: epoch 0069, iter [02500, 05004], lr: 0.001000, loss: 0.7420
2022-07-01 18:47:48 - train: epoch 0069, iter [02600, 05004], lr: 0.001000, loss: 0.8298
2022-07-01 18:48:30 - train: epoch 0069, iter [02700, 05004], lr: 0.001000, loss: 0.8215
2022-07-01 18:49:11 - train: epoch 0069, iter [02800, 05004], lr: 0.001000, loss: 0.9145
2022-07-01 18:49:53 - train: epoch 0069, iter [02900, 05004], lr: 0.001000, loss: 0.5530
2022-07-01 18:50:34 - train: epoch 0069, iter [03000, 05004], lr: 0.001000, loss: 0.5930
2022-07-01 18:51:16 - train: epoch 0069, iter [03100, 05004], lr: 0.001000, loss: 0.5594
2022-07-01 18:51:58 - train: epoch 0069, iter [03200, 05004], lr: 0.001000, loss: 0.6264
2022-07-01 18:52:40 - train: epoch 0069, iter [03300, 05004], lr: 0.001000, loss: 0.5766
2022-07-01 18:53:21 - train: epoch 0069, iter [03400, 05004], lr: 0.001000, loss: 0.5646
2022-07-01 18:54:03 - train: epoch 0069, iter [03500, 05004], lr: 0.001000, loss: 0.6679
2022-07-01 18:54:45 - train: epoch 0069, iter [03600, 05004], lr: 0.001000, loss: 0.6533
2022-07-01 18:55:26 - train: epoch 0069, iter [03700, 05004], lr: 0.001000, loss: 0.7625
2022-07-01 18:56:08 - train: epoch 0069, iter [03800, 05004], lr: 0.001000, loss: 0.7462
2022-07-01 18:56:49 - train: epoch 0069, iter [03900, 05004], lr: 0.001000, loss: 0.7666
2022-07-01 18:57:31 - train: epoch 0069, iter [04000, 05004], lr: 0.001000, loss: 0.7846
2022-07-01 18:58:13 - train: epoch 0069, iter [04100, 05004], lr: 0.001000, loss: 0.8525
2022-07-01 18:58:54 - train: epoch 0069, iter [04200, 05004], lr: 0.001000, loss: 0.5698
2022-07-01 18:59:36 - train: epoch 0069, iter [04300, 05004], lr: 0.001000, loss: 0.7356
2022-07-01 19:00:17 - train: epoch 0069, iter [04400, 05004], lr: 0.001000, loss: 0.7073
2022-07-01 19:00:59 - train: epoch 0069, iter [04500, 05004], lr: 0.001000, loss: 0.6521
2022-07-01 19:01:40 - train: epoch 0069, iter [04600, 05004], lr: 0.001000, loss: 0.7711
2022-07-01 19:02:22 - train: epoch 0069, iter [04700, 05004], lr: 0.001000, loss: 0.7713
2022-07-01 19:03:04 - train: epoch 0069, iter [04800, 05004], lr: 0.001000, loss: 0.6535
2022-07-01 19:03:45 - train: epoch 0069, iter [04900, 05004], lr: 0.001000, loss: 0.6757
2022-07-01 19:04:27 - train: epoch 0069, iter [05000, 05004], lr: 0.001000, loss: 0.7031
2022-07-01 19:04:29 - train: epoch 069, train_loss: 0.6935
2022-07-01 19:05:43 - eval: epoch: 069, acc1: 77.884%, acc5: 93.822%, test_loss: 0.8883, per_image_load_time: 1.601ms, per_image_inference_time: 0.881ms
2022-07-01 19:05:44 - until epoch: 069, best_acc1: 77.896%
2022-07-01 19:05:44 - epoch 070 lr: 0.001000
2022-07-01 19:06:31 - train: epoch 0070, iter [00100, 05004], lr: 0.001000, loss: 0.7303
2022-07-01 19:07:12 - train: epoch 0070, iter [00200, 05004], lr: 0.001000, loss: 0.7432
2022-07-01 19:07:54 - train: epoch 0070, iter [00300, 05004], lr: 0.001000, loss: 0.7795
2022-07-01 19:08:35 - train: epoch 0070, iter [00400, 05004], lr: 0.001000, loss: 0.6649
2022-07-01 19:09:17 - train: epoch 0070, iter [00500, 05004], lr: 0.001000, loss: 0.7774
2022-07-01 19:09:58 - train: epoch 0070, iter [00600, 05004], lr: 0.001000, loss: 0.6261
2022-07-01 19:10:39 - train: epoch 0070, iter [00700, 05004], lr: 0.001000, loss: 0.6813
2022-07-01 19:11:21 - train: epoch 0070, iter [00800, 05004], lr: 0.001000, loss: 0.6127
2022-07-01 19:12:02 - train: epoch 0070, iter [00900, 05004], lr: 0.001000, loss: 0.7404
2022-07-01 19:12:43 - train: epoch 0070, iter [01000, 05004], lr: 0.001000, loss: 0.6192
2022-07-01 19:13:25 - train: epoch 0070, iter [01100, 05004], lr: 0.001000, loss: 0.8985
2022-07-01 19:14:06 - train: epoch 0070, iter [01200, 05004], lr: 0.001000, loss: 0.5257
2022-07-01 19:14:48 - train: epoch 0070, iter [01300, 05004], lr: 0.001000, loss: 0.7005
2022-07-01 19:15:29 - train: epoch 0070, iter [01400, 05004], lr: 0.001000, loss: 0.6553
2022-07-01 19:16:11 - train: epoch 0070, iter [01500, 05004], lr: 0.001000, loss: 0.6221
2022-07-01 19:16:52 - train: epoch 0070, iter [01600, 05004], lr: 0.001000, loss: 0.6799
2022-07-01 19:17:34 - train: epoch 0070, iter [01700, 05004], lr: 0.001000, loss: 0.7902
2022-07-01 19:18:15 - train: epoch 0070, iter [01800, 05004], lr: 0.001000, loss: 0.6595
2022-07-01 19:18:57 - train: epoch 0070, iter [01900, 05004], lr: 0.001000, loss: 0.7028
2022-07-01 19:19:38 - train: epoch 0070, iter [02000, 05004], lr: 0.001000, loss: 0.7174
2022-07-01 19:20:20 - train: epoch 0070, iter [02100, 05004], lr: 0.001000, loss: 0.7016
2022-07-01 19:21:01 - train: epoch 0070, iter [02200, 05004], lr: 0.001000, loss: 0.7148
2022-07-01 19:21:43 - train: epoch 0070, iter [02300, 05004], lr: 0.001000, loss: 0.6176
2022-07-01 19:22:24 - train: epoch 0070, iter [02400, 05004], lr: 0.001000, loss: 0.8691
2022-07-01 19:23:06 - train: epoch 0070, iter [02500, 05004], lr: 0.001000, loss: 0.7228
2022-07-01 19:23:47 - train: epoch 0070, iter [02600, 05004], lr: 0.001000, loss: 0.6831
2022-07-01 19:24:29 - train: epoch 0070, iter [02700, 05004], lr: 0.001000, loss: 0.6108
2022-07-01 19:25:10 - train: epoch 0070, iter [02800, 05004], lr: 0.001000, loss: 0.7728
2022-07-01 19:25:52 - train: epoch 0070, iter [02900, 05004], lr: 0.001000, loss: 0.8889
2022-07-01 19:26:33 - train: epoch 0070, iter [03000, 05004], lr: 0.001000, loss: 0.5802
2022-07-01 19:27:15 - train: epoch 0070, iter [03100, 05004], lr: 0.001000, loss: 0.6893
2022-07-01 19:27:56 - train: epoch 0070, iter [03200, 05004], lr: 0.001000, loss: 0.7869
2022-07-01 19:28:38 - train: epoch 0070, iter [03300, 05004], lr: 0.001000, loss: 0.6262
2022-07-01 19:29:19 - train: epoch 0070, iter [03400, 05004], lr: 0.001000, loss: 0.7733
2022-07-01 19:30:01 - train: epoch 0070, iter [03500, 05004], lr: 0.001000, loss: 0.6665
2022-07-01 19:30:42 - train: epoch 0070, iter [03600, 05004], lr: 0.001000, loss: 0.6809
2022-07-01 19:31:24 - train: epoch 0070, iter [03700, 05004], lr: 0.001000, loss: 0.6967
2022-07-01 19:32:06 - train: epoch 0070, iter [03800, 05004], lr: 0.001000, loss: 0.6959
2022-07-01 19:32:47 - train: epoch 0070, iter [03900, 05004], lr: 0.001000, loss: 0.6179
2022-07-01 19:33:29 - train: epoch 0070, iter [04000, 05004], lr: 0.001000, loss: 0.5987
2022-07-01 19:34:11 - train: epoch 0070, iter [04100, 05004], lr: 0.001000, loss: 0.6459
2022-07-01 19:34:52 - train: epoch 0070, iter [04200, 05004], lr: 0.001000, loss: 0.7369
2022-07-01 19:35:34 - train: epoch 0070, iter [04300, 05004], lr: 0.001000, loss: 0.6284
2022-07-01 19:36:15 - train: epoch 0070, iter [04400, 05004], lr: 0.001000, loss: 0.8306
2022-07-01 19:36:57 - train: epoch 0070, iter [04500, 05004], lr: 0.001000, loss: 0.7363
2022-07-01 19:37:38 - train: epoch 0070, iter [04600, 05004], lr: 0.001000, loss: 0.7398
2022-07-01 19:38:20 - train: epoch 0070, iter [04700, 05004], lr: 0.001000, loss: 0.7669
2022-07-01 19:39:02 - train: epoch 0070, iter [04800, 05004], lr: 0.001000, loss: 0.6362
2022-07-01 19:39:43 - train: epoch 0070, iter [04900, 05004], lr: 0.001000, loss: 0.7798
2022-07-01 19:40:25 - train: epoch 0070, iter [05000, 05004], lr: 0.001000, loss: 0.6756
2022-07-01 19:40:27 - train: epoch 070, train_loss: 0.6886
2022-07-01 19:41:42 - eval: epoch: 070, acc1: 77.864%, acc5: 93.868%, test_loss: 0.8855, per_image_load_time: 1.995ms, per_image_inference_time: 0.878ms
2022-07-01 19:41:42 - until epoch: 070, best_acc1: 77.896%
2022-07-01 19:41:42 - epoch 071 lr: 0.001000
2022-07-01 19:42:30 - train: epoch 0071, iter [00100, 05004], lr: 0.001000, loss: 0.5540
2022-07-01 19:43:11 - train: epoch 0071, iter [00200, 05004], lr: 0.001000, loss: 0.6719
2022-07-01 19:43:52 - train: epoch 0071, iter [00300, 05004], lr: 0.001000, loss: 0.6143
2022-07-01 19:44:34 - train: epoch 0071, iter [00400, 05004], lr: 0.001000, loss: 0.7123
2022-07-01 19:45:15 - train: epoch 0071, iter [00500, 05004], lr: 0.001000, loss: 0.6767
2022-07-01 19:45:56 - train: epoch 0071, iter [00600, 05004], lr: 0.001000, loss: 0.6917
2022-07-01 19:46:38 - train: epoch 0071, iter [00700, 05004], lr: 0.001000, loss: 0.8744
2022-07-01 19:47:19 - train: epoch 0071, iter [00800, 05004], lr: 0.001000, loss: 0.6518
2022-07-01 19:48:01 - train: epoch 0071, iter [00900, 05004], lr: 0.001000, loss: 0.6993
2022-07-01 19:48:42 - train: epoch 0071, iter [01000, 05004], lr: 0.001000, loss: 0.7677
2022-07-01 19:49:24 - train: epoch 0071, iter [01100, 05004], lr: 0.001000, loss: 0.7700
2022-07-01 19:50:05 - train: epoch 0071, iter [01200, 05004], lr: 0.001000, loss: 0.6855
2022-07-01 19:50:47 - train: epoch 0071, iter [01300, 05004], lr: 0.001000, loss: 0.6791
2022-07-01 19:51:28 - train: epoch 0071, iter [01400, 05004], lr: 0.001000, loss: 0.6600
2022-07-01 19:52:10 - train: epoch 0071, iter [01500, 05004], lr: 0.001000, loss: 0.5441
2022-07-01 19:52:52 - train: epoch 0071, iter [01600, 05004], lr: 0.001000, loss: 0.6922
2022-07-01 19:53:34 - train: epoch 0071, iter [01700, 05004], lr: 0.001000, loss: 0.6556
2022-07-01 19:54:15 - train: epoch 0071, iter [01800, 05004], lr: 0.001000, loss: 0.7144
2022-07-01 19:54:57 - train: epoch 0071, iter [01900, 05004], lr: 0.001000, loss: 0.5794
2022-07-01 19:55:39 - train: epoch 0071, iter [02000, 05004], lr: 0.001000, loss: 0.6925
2022-07-01 19:56:20 - train: epoch 0071, iter [02100, 05004], lr: 0.001000, loss: 0.5655
2022-07-01 19:57:02 - train: epoch 0071, iter [02200, 05004], lr: 0.001000, loss: 0.7081
2022-07-01 19:57:43 - train: epoch 0071, iter [02300, 05004], lr: 0.001000, loss: 0.5465
2022-07-01 19:58:25 - train: epoch 0071, iter [02400, 05004], lr: 0.001000, loss: 0.5919
2022-07-01 19:59:07 - train: epoch 0071, iter [02500, 05004], lr: 0.001000, loss: 0.6741
2022-07-01 19:59:48 - train: epoch 0071, iter [02600, 05004], lr: 0.001000, loss: 0.6717
2022-07-01 20:00:30 - train: epoch 0071, iter [02700, 05004], lr: 0.001000, loss: 0.6791
2022-07-01 20:01:12 - train: epoch 0071, iter [02800, 05004], lr: 0.001000, loss: 0.7740
2022-07-01 20:01:53 - train: epoch 0071, iter [02900, 05004], lr: 0.001000, loss: 0.6781
2022-07-01 20:02:35 - train: epoch 0071, iter [03000, 05004], lr: 0.001000, loss: 0.5897
2022-07-01 20:03:16 - train: epoch 0071, iter [03100, 05004], lr: 0.001000, loss: 0.7310
2022-07-01 20:03:58 - train: epoch 0071, iter [03200, 05004], lr: 0.001000, loss: 0.5662
2022-07-01 20:04:40 - train: epoch 0071, iter [03300, 05004], lr: 0.001000, loss: 0.5198
2022-07-01 20:05:21 - train: epoch 0071, iter [03400, 05004], lr: 0.001000, loss: 0.7102
2022-07-01 20:06:03 - train: epoch 0071, iter [03500, 05004], lr: 0.001000, loss: 0.8259
2022-07-01 20:06:45 - train: epoch 0071, iter [03600, 05004], lr: 0.001000, loss: 0.7903
2022-07-01 20:07:26 - train: epoch 0071, iter [03700, 05004], lr: 0.001000, loss: 0.6730
2022-07-01 20:08:08 - train: epoch 0071, iter [03800, 05004], lr: 0.001000, loss: 0.6595
2022-07-01 20:08:50 - train: epoch 0071, iter [03900, 05004], lr: 0.001000, loss: 0.8051
2022-07-01 20:09:31 - train: epoch 0071, iter [04000, 05004], lr: 0.001000, loss: 0.8306
2022-07-01 20:10:13 - train: epoch 0071, iter [04100, 05004], lr: 0.001000, loss: 0.5803
2022-07-01 20:10:54 - train: epoch 0071, iter [04200, 05004], lr: 0.001000, loss: 0.7682
2022-07-01 20:11:36 - train: epoch 0071, iter [04300, 05004], lr: 0.001000, loss: 0.7492
2022-07-01 20:12:17 - train: epoch 0071, iter [04400, 05004], lr: 0.001000, loss: 0.6738
2022-07-01 20:12:59 - train: epoch 0071, iter [04500, 05004], lr: 0.001000, loss: 0.6400
2022-07-01 20:13:40 - train: epoch 0071, iter [04600, 05004], lr: 0.001000, loss: 0.7684
2022-07-01 20:14:22 - train: epoch 0071, iter [04700, 05004], lr: 0.001000, loss: 0.6005
2022-07-01 20:15:03 - train: epoch 0071, iter [04800, 05004], lr: 0.001000, loss: 0.5204
2022-07-01 20:15:44 - train: epoch 0071, iter [04900, 05004], lr: 0.001000, loss: 0.4787
2022-07-01 20:16:26 - train: epoch 0071, iter [05000, 05004], lr: 0.001000, loss: 0.6015
2022-07-01 20:16:28 - train: epoch 071, train_loss: 0.6810
2022-07-01 20:17:42 - eval: epoch: 071, acc1: 77.880%, acc5: 93.872%, test_loss: 0.8861, per_image_load_time: 1.933ms, per_image_inference_time: 0.889ms
2022-07-01 20:17:42 - until epoch: 071, best_acc1: 77.896%
2022-07-01 20:17:42 - epoch 072 lr: 0.001000
2022-07-01 20:18:30 - train: epoch 0072, iter [00100, 05004], lr: 0.001000, loss: 0.7375
2022-07-01 20:19:11 - train: epoch 0072, iter [00200, 05004], lr: 0.001000, loss: 0.5753
2022-07-01 20:19:53 - train: epoch 0072, iter [00300, 05004], lr: 0.001000, loss: 0.5396
2022-07-01 20:20:34 - train: epoch 0072, iter [00400, 05004], lr: 0.001000, loss: 0.6384
2022-07-01 20:21:16 - train: epoch 0072, iter [00500, 05004], lr: 0.001000, loss: 0.6445
2022-07-01 20:21:57 - train: epoch 0072, iter [00600, 05004], lr: 0.001000, loss: 0.6732
2022-07-01 20:22:39 - train: epoch 0072, iter [00700, 05004], lr: 0.001000, loss: 0.6833
2022-07-01 20:23:20 - train: epoch 0072, iter [00800, 05004], lr: 0.001000, loss: 0.7646
2022-07-01 20:24:02 - train: epoch 0072, iter [00900, 05004], lr: 0.001000, loss: 0.5673
2022-07-01 20:24:44 - train: epoch 0072, iter [01000, 05004], lr: 0.001000, loss: 0.6833
2022-07-01 20:25:25 - train: epoch 0072, iter [01100, 05004], lr: 0.001000, loss: 0.5955
2022-07-01 20:26:07 - train: epoch 0072, iter [01200, 05004], lr: 0.001000, loss: 0.6130
2022-07-01 20:26:48 - train: epoch 0072, iter [01300, 05004], lr: 0.001000, loss: 0.6942
2022-07-01 20:27:30 - train: epoch 0072, iter [01400, 05004], lr: 0.001000, loss: 0.7680
2022-07-01 20:28:11 - train: epoch 0072, iter [01500, 05004], lr: 0.001000, loss: 0.6360
2022-07-01 20:28:52 - train: epoch 0072, iter [01600, 05004], lr: 0.001000, loss: 0.6902
2022-07-01 20:29:34 - train: epoch 0072, iter [01700, 05004], lr: 0.001000, loss: 0.6308
2022-07-01 20:30:15 - train: epoch 0072, iter [01800, 05004], lr: 0.001000, loss: 0.5101
2022-07-01 20:30:56 - train: epoch 0072, iter [01900, 05004], lr: 0.001000, loss: 0.5791
2022-07-01 20:31:38 - train: epoch 0072, iter [02000, 05004], lr: 0.001000, loss: 0.7915
2022-07-01 20:32:19 - train: epoch 0072, iter [02100, 05004], lr: 0.001000, loss: 0.6482
2022-07-01 20:33:00 - train: epoch 0072, iter [02200, 05004], lr: 0.001000, loss: 0.6930
2022-07-01 20:33:42 - train: epoch 0072, iter [02300, 05004], lr: 0.001000, loss: 0.7714
2022-07-01 20:34:23 - train: epoch 0072, iter [02400, 05004], lr: 0.001000, loss: 0.5715
2022-07-01 20:35:05 - train: epoch 0072, iter [02500, 05004], lr: 0.001000, loss: 0.5561
2022-07-01 20:35:46 - train: epoch 0072, iter [02600, 05004], lr: 0.001000, loss: 0.6003
2022-07-01 20:36:27 - train: epoch 0072, iter [02700, 05004], lr: 0.001000, loss: 0.7742
2022-07-01 20:37:09 - train: epoch 0072, iter [02800, 05004], lr: 0.001000, loss: 0.6810
2022-07-01 20:37:50 - train: epoch 0072, iter [02900, 05004], lr: 0.001000, loss: 0.6269
2022-07-01 20:38:32 - train: epoch 0072, iter [03000, 05004], lr: 0.001000, loss: 0.6132
2022-07-01 20:39:13 - train: epoch 0072, iter [03100, 05004], lr: 0.001000, loss: 0.7668
2022-07-01 20:39:54 - train: epoch 0072, iter [03200, 05004], lr: 0.001000, loss: 0.6333
2022-07-01 20:40:36 - train: epoch 0072, iter [03300, 05004], lr: 0.001000, loss: 0.6033
2022-07-01 20:41:17 - train: epoch 0072, iter [03400, 05004], lr: 0.001000, loss: 0.7052
2022-07-01 20:41:58 - train: epoch 0072, iter [03500, 05004], lr: 0.001000, loss: 0.7141
2022-07-01 20:42:40 - train: epoch 0072, iter [03600, 05004], lr: 0.001000, loss: 0.6051
2022-07-01 20:43:21 - train: epoch 0072, iter [03700, 05004], lr: 0.001000, loss: 0.6420
2022-07-01 20:44:03 - train: epoch 0072, iter [03800, 05004], lr: 0.001000, loss: 0.7111
2022-07-01 20:44:44 - train: epoch 0072, iter [03900, 05004], lr: 0.001000, loss: 0.7659
2022-07-01 20:45:26 - train: epoch 0072, iter [04000, 05004], lr: 0.001000, loss: 0.6360
2022-07-01 20:46:08 - train: epoch 0072, iter [04100, 05004], lr: 0.001000, loss: 0.8227
2022-07-01 20:46:49 - train: epoch 0072, iter [04200, 05004], lr: 0.001000, loss: 0.6290
2022-07-01 20:47:31 - train: epoch 0072, iter [04300, 05004], lr: 0.001000, loss: 0.6673
2022-07-01 20:48:13 - train: epoch 0072, iter [04400, 05004], lr: 0.001000, loss: 0.5754
2022-07-01 20:48:54 - train: epoch 0072, iter [04500, 05004], lr: 0.001000, loss: 0.7684
2022-07-01 20:49:36 - train: epoch 0072, iter [04600, 05004], lr: 0.001000, loss: 0.6893
2022-07-01 20:50:18 - train: epoch 0072, iter [04700, 05004], lr: 0.001000, loss: 0.7242
2022-07-01 20:50:59 - train: epoch 0072, iter [04800, 05004], lr: 0.001000, loss: 0.7627
2022-07-01 20:51:41 - train: epoch 0072, iter [04900, 05004], lr: 0.001000, loss: 0.7630
2022-07-01 20:52:23 - train: epoch 0072, iter [05000, 05004], lr: 0.001000, loss: 0.6698
2022-07-01 20:52:25 - train: epoch 072, train_loss: 0.6762
2022-07-01 20:53:39 - eval: epoch: 072, acc1: 77.802%, acc5: 93.764%, test_loss: 0.8893, per_image_load_time: 1.982ms, per_image_inference_time: 0.864ms
2022-07-01 20:53:39 - until epoch: 072, best_acc1: 77.896%
2022-07-01 21:14:15 - epoch 073 lr: 0.001000
2022-07-01 21:15:04 - train: epoch 0073, iter [00100, 05004], lr: 0.001000, loss: 0.7686
2022-07-01 21:15:46 - train: epoch 0073, iter [00200, 05004], lr: 0.001000, loss: 0.6668
2022-07-01 21:16:28 - train: epoch 0073, iter [00300, 05004], lr: 0.001000, loss: 0.7344
2022-07-01 21:17:11 - train: epoch 0073, iter [00400, 05004], lr: 0.001000, loss: 0.4952
2022-07-01 21:17:53 - train: epoch 0073, iter [00500, 05004], lr: 0.001000, loss: 0.6005
2022-07-01 21:18:35 - train: epoch 0073, iter [00600, 05004], lr: 0.001000, loss: 0.6695
2022-07-01 21:19:17 - train: epoch 0073, iter [00700, 05004], lr: 0.001000, loss: 0.6720
2022-07-01 21:19:59 - train: epoch 0073, iter [00800, 05004], lr: 0.001000, loss: 0.6696
2022-07-01 21:20:42 - train: epoch 0073, iter [00900, 05004], lr: 0.001000, loss: 0.5566
2022-07-01 21:21:24 - train: epoch 0073, iter [01000, 05004], lr: 0.001000, loss: 0.6511
2022-07-01 21:22:06 - train: epoch 0073, iter [01100, 05004], lr: 0.001000, loss: 0.7222
2022-07-01 21:22:48 - train: epoch 0073, iter [01200, 05004], lr: 0.001000, loss: 0.7564
2022-07-01 21:23:30 - train: epoch 0073, iter [01300, 05004], lr: 0.001000, loss: 0.5389
2022-07-01 21:24:12 - train: epoch 0073, iter [01400, 05004], lr: 0.001000, loss: 0.6219
2022-07-01 21:24:55 - train: epoch 0073, iter [01500, 05004], lr: 0.001000, loss: 0.7157
2022-07-01 21:25:37 - train: epoch 0073, iter [01600, 05004], lr: 0.001000, loss: 0.6991
2022-07-01 21:26:19 - train: epoch 0073, iter [01700, 05004], lr: 0.001000, loss: 0.7476
2022-07-01 21:27:01 - train: epoch 0073, iter [01800, 05004], lr: 0.001000, loss: 0.5334
2022-07-01 21:27:44 - train: epoch 0073, iter [01900, 05004], lr: 0.001000, loss: 0.5706
2022-07-01 21:28:26 - train: epoch 0073, iter [02000, 05004], lr: 0.001000, loss: 0.6544
2022-07-01 21:29:08 - train: epoch 0073, iter [02100, 05004], lr: 0.001000, loss: 0.7267
2022-07-01 21:29:50 - train: epoch 0073, iter [02200, 05004], lr: 0.001000, loss: 0.5770
2022-07-01 21:30:32 - train: epoch 0073, iter [02300, 05004], lr: 0.001000, loss: 0.5842
2022-07-01 21:31:14 - train: epoch 0073, iter [02400, 05004], lr: 0.001000, loss: 0.9020
2022-07-01 21:31:57 - train: epoch 0073, iter [02500, 05004], lr: 0.001000, loss: 0.7974
2022-07-01 21:32:39 - train: epoch 0073, iter [02600, 05004], lr: 0.001000, loss: 0.7144
2022-07-01 21:33:21 - train: epoch 0073, iter [02700, 05004], lr: 0.001000, loss: 0.7154
2022-07-01 21:34:03 - train: epoch 0073, iter [02800, 05004], lr: 0.001000, loss: 0.5531
2022-07-01 21:34:45 - train: epoch 0073, iter [02900, 05004], lr: 0.001000, loss: 0.6146
2022-07-01 21:35:28 - train: epoch 0073, iter [03000, 05004], lr: 0.001000, loss: 0.6461
2022-07-01 21:36:10 - train: epoch 0073, iter [03100, 05004], lr: 0.001000, loss: 0.6523
2022-07-01 21:36:52 - train: epoch 0073, iter [03200, 05004], lr: 0.001000, loss: 0.6349
2022-07-01 21:37:34 - train: epoch 0073, iter [03300, 05004], lr: 0.001000, loss: 0.5812
2022-07-01 21:38:16 - train: epoch 0073, iter [03400, 05004], lr: 0.001000, loss: 0.6802
2022-07-01 21:38:58 - train: epoch 0073, iter [03500, 05004], lr: 0.001000, loss: 0.5235
2022-07-01 21:39:40 - train: epoch 0073, iter [03600, 05004], lr: 0.001000, loss: 0.7007
2022-07-01 21:40:23 - train: epoch 0073, iter [03700, 05004], lr: 0.001000, loss: 0.5777
2022-07-01 21:41:05 - train: epoch 0073, iter [03800, 05004], lr: 0.001000, loss: 0.8873
2022-07-01 21:41:47 - train: epoch 0073, iter [03900, 05004], lr: 0.001000, loss: 0.6041
2022-07-01 21:42:29 - train: epoch 0073, iter [04000, 05004], lr: 0.001000, loss: 0.7900
2022-07-01 21:43:11 - train: epoch 0073, iter [04100, 05004], lr: 0.001000, loss: 0.6530
2022-07-01 21:43:53 - train: epoch 0073, iter [04200, 05004], lr: 0.001000, loss: 0.7817
2022-07-01 21:44:36 - train: epoch 0073, iter [04300, 05004], lr: 0.001000, loss: 0.7341
2022-07-01 21:45:18 - train: epoch 0073, iter [04400, 05004], lr: 0.001000, loss: 0.6465
2022-07-01 21:46:00 - train: epoch 0073, iter [04500, 05004], lr: 0.001000, loss: 0.6267
2022-07-01 21:46:42 - train: epoch 0073, iter [04600, 05004], lr: 0.001000, loss: 0.7873
2022-07-01 21:47:24 - train: epoch 0073, iter [04700, 05004], lr: 0.001000, loss: 0.5335
2022-07-01 21:48:06 - train: epoch 0073, iter [04800, 05004], lr: 0.001000, loss: 0.5581
2022-07-01 21:48:49 - train: epoch 0073, iter [04900, 05004], lr: 0.001000, loss: 0.9224
2022-07-01 21:49:31 - train: epoch 0073, iter [05000, 05004], lr: 0.001000, loss: 0.7142
2022-07-01 21:49:33 - train: epoch 073, train_loss: 0.6721
2022-07-01 21:50:47 - eval: epoch: 073, acc1: 77.782%, acc5: 93.810%, test_loss: 0.8891, per_image_load_time: 1.745ms, per_image_inference_time: 0.883ms
2022-07-01 21:50:48 - until epoch: 073, best_acc1: 77.896%
2022-07-01 21:50:48 - epoch 074 lr: 0.001000
2022-07-01 21:51:36 - train: epoch 0074, iter [00100, 05004], lr: 0.001000, loss: 0.7708
2022-07-01 21:52:18 - train: epoch 0074, iter [00200, 05004], lr: 0.001000, loss: 0.8385
2022-07-01 21:53:00 - train: epoch 0074, iter [00300, 05004], lr: 0.001000, loss: 0.6124
2022-07-01 21:53:42 - train: epoch 0074, iter [00400, 05004], lr: 0.001000, loss: 0.6724
2022-07-01 21:54:24 - train: epoch 0074, iter [00500, 05004], lr: 0.001000, loss: 0.6305
2022-07-01 21:55:06 - train: epoch 0074, iter [00600, 05004], lr: 0.001000, loss: 0.6596
2022-07-01 21:55:48 - train: epoch 0074, iter [00700, 05004], lr: 0.001000, loss: 0.5894
2022-07-01 21:56:31 - train: epoch 0074, iter [00800, 05004], lr: 0.001000, loss: 0.8226
2022-07-01 21:57:13 - train: epoch 0074, iter [00900, 05004], lr: 0.001000, loss: 0.6507
2022-07-01 21:57:55 - train: epoch 0074, iter [01000, 05004], lr: 0.001000, loss: 0.7380
2022-07-01 21:58:37 - train: epoch 0074, iter [01100, 05004], lr: 0.001000, loss: 0.5852
2022-07-01 21:59:19 - train: epoch 0074, iter [01200, 05004], lr: 0.001000, loss: 0.6632
2022-07-01 22:00:01 - train: epoch 0074, iter [01300, 05004], lr: 0.001000, loss: 0.6518
2022-07-01 22:00:43 - train: epoch 0074, iter [01400, 05004], lr: 0.001000, loss: 0.6180
2022-07-01 22:01:25 - train: epoch 0074, iter [01500, 05004], lr: 0.001000, loss: 0.5603
2022-07-01 22:02:07 - train: epoch 0074, iter [01600, 05004], lr: 0.001000, loss: 0.6862
2022-07-01 22:02:50 - train: epoch 0074, iter [01700, 05004], lr: 0.001000, loss: 0.7741
2022-07-01 22:03:32 - train: epoch 0074, iter [01800, 05004], lr: 0.001000, loss: 0.7584
2022-07-01 22:04:14 - train: epoch 0074, iter [01900, 05004], lr: 0.001000, loss: 0.6326
2022-07-01 22:04:56 - train: epoch 0074, iter [02000, 05004], lr: 0.001000, loss: 0.5998
2022-07-01 22:05:38 - train: epoch 0074, iter [02100, 05004], lr: 0.001000, loss: 0.5545
2022-07-01 22:06:20 - train: epoch 0074, iter [02200, 05004], lr: 0.001000, loss: 0.8236
2022-07-01 22:07:02 - train: epoch 0074, iter [02300, 05004], lr: 0.001000, loss: 0.7639
2022-07-01 22:07:44 - train: epoch 0074, iter [02400, 05004], lr: 0.001000, loss: 0.5236
2022-07-01 22:08:26 - train: epoch 0074, iter [02500, 05004], lr: 0.001000, loss: 0.6308
2022-07-01 22:09:08 - train: epoch 0074, iter [02600, 05004], lr: 0.001000, loss: 0.6134
2022-07-01 22:09:50 - train: epoch 0074, iter [02700, 05004], lr: 0.001000, loss: 0.6392
2022-07-01 22:10:32 - train: epoch 0074, iter [02800, 05004], lr: 0.001000, loss: 0.7665
2022-07-01 22:11:14 - train: epoch 0074, iter [02900, 05004], lr: 0.001000, loss: 0.7226
2022-07-01 22:11:57 - train: epoch 0074, iter [03000, 05004], lr: 0.001000, loss: 0.6730
2022-07-01 22:12:39 - train: epoch 0074, iter [03100, 05004], lr: 0.001000, loss: 0.6961
2022-07-01 22:13:21 - train: epoch 0074, iter [03200, 05004], lr: 0.001000, loss: 0.6133
2022-07-01 22:14:03 - train: epoch 0074, iter [03300, 05004], lr: 0.001000, loss: 0.6600
2022-07-01 22:14:45 - train: epoch 0074, iter [03400, 05004], lr: 0.001000, loss: 0.7130
2022-07-01 22:15:27 - train: epoch 0074, iter [03500, 05004], lr: 0.001000, loss: 0.5569
2022-07-01 22:16:09 - train: epoch 0074, iter [03600, 05004], lr: 0.001000, loss: 0.8374
2022-07-01 22:16:51 - train: epoch 0074, iter [03700, 05004], lr: 0.001000, loss: 0.6721
2022-07-01 22:17:33 - train: epoch 0074, iter [03800, 05004], lr: 0.001000, loss: 0.6959
2022-07-01 22:18:16 - train: epoch 0074, iter [03900, 05004], lr: 0.001000, loss: 0.6608
2022-07-01 22:18:57 - train: epoch 0074, iter [04000, 05004], lr: 0.001000, loss: 0.7239
2022-07-01 22:19:39 - train: epoch 0074, iter [04100, 05004], lr: 0.001000, loss: 0.5786
2022-07-01 22:20:22 - train: epoch 0074, iter [04200, 05004], lr: 0.001000, loss: 0.5830
2022-07-01 22:21:04 - train: epoch 0074, iter [04300, 05004], lr: 0.001000, loss: 0.6688
2022-07-01 22:21:46 - train: epoch 0074, iter [04400, 05004], lr: 0.001000, loss: 0.5250
2022-07-01 22:22:28 - train: epoch 0074, iter [04500, 05004], lr: 0.001000, loss: 0.7841
2022-07-01 22:23:10 - train: epoch 0074, iter [04600, 05004], lr: 0.001000, loss: 0.7225
2022-07-01 22:23:53 - train: epoch 0074, iter [04700, 05004], lr: 0.001000, loss: 0.5539
2022-07-01 22:24:35 - train: epoch 0074, iter [04800, 05004], lr: 0.001000, loss: 0.6420
2022-07-01 22:25:17 - train: epoch 0074, iter [04900, 05004], lr: 0.001000, loss: 0.7898
2022-07-01 22:25:59 - train: epoch 0074, iter [05000, 05004], lr: 0.001000, loss: 0.7108
2022-07-01 22:26:01 - train: epoch 074, train_loss: 0.6647
2022-07-01 22:27:15 - eval: epoch: 074, acc1: 77.898%, acc5: 93.848%, test_loss: 0.8879, per_image_load_time: 1.598ms, per_image_inference_time: 0.884ms
2022-07-01 22:27:16 - until epoch: 074, best_acc1: 77.898%
2022-07-01 22:27:16 - epoch 075 lr: 0.001000
2022-07-01 22:28:04 - train: epoch 0075, iter [00100, 05004], lr: 0.001000, loss: 0.6659
2022-07-01 22:28:46 - train: epoch 0075, iter [00200, 05004], lr: 0.001000, loss: 0.6352
2022-07-01 22:29:29 - train: epoch 0075, iter [00300, 05004], lr: 0.001000, loss: 0.7329
2022-07-01 22:30:11 - train: epoch 0075, iter [00400, 05004], lr: 0.001000, loss: 0.6583
2022-07-01 22:30:53 - train: epoch 0075, iter [00500, 05004], lr: 0.001000, loss: 0.6161
2022-07-01 22:31:35 - train: epoch 0075, iter [00600, 05004], lr: 0.001000, loss: 0.5374
2022-07-01 22:32:18 - train: epoch 0075, iter [00700, 05004], lr: 0.001000, loss: 0.6476
2022-07-01 22:33:00 - train: epoch 0075, iter [00800, 05004], lr: 0.001000, loss: 0.6322
2022-07-01 22:33:42 - train: epoch 0075, iter [00900, 05004], lr: 0.001000, loss: 0.6159
2022-07-01 22:34:24 - train: epoch 0075, iter [01000, 05004], lr: 0.001000, loss: 0.6333
2022-07-01 22:35:06 - train: epoch 0075, iter [01100, 05004], lr: 0.001000, loss: 0.6405
2022-07-01 22:35:49 - train: epoch 0075, iter [01200, 05004], lr: 0.001000, loss: 0.5321
2022-07-01 22:36:31 - train: epoch 0075, iter [01300, 05004], lr: 0.001000, loss: 0.7204
2022-07-01 22:37:13 - train: epoch 0075, iter [01400, 05004], lr: 0.001000, loss: 0.6552
2022-07-01 22:37:55 - train: epoch 0075, iter [01500, 05004], lr: 0.001000, loss: 0.7101
2022-07-01 22:38:38 - train: epoch 0075, iter [01600, 05004], lr: 0.001000, loss: 0.6240
2022-07-01 22:39:20 - train: epoch 0075, iter [01700, 05004], lr: 0.001000, loss: 0.5553
2022-07-01 22:40:02 - train: epoch 0075, iter [01800, 05004], lr: 0.001000, loss: 0.7412
2022-07-01 22:40:44 - train: epoch 0075, iter [01900, 05004], lr: 0.001000, loss: 0.6000
2022-07-01 22:41:27 - train: epoch 0075, iter [02000, 05004], lr: 0.001000, loss: 0.6776
2022-07-01 22:42:09 - train: epoch 0075, iter [02100, 05004], lr: 0.001000, loss: 0.6359
2022-07-01 22:42:51 - train: epoch 0075, iter [02200, 05004], lr: 0.001000, loss: 0.5648
2022-07-01 22:43:33 - train: epoch 0075, iter [02300, 05004], lr: 0.001000, loss: 0.7400
2022-07-01 22:44:15 - train: epoch 0075, iter [02400, 05004], lr: 0.001000, loss: 0.7076
2022-07-01 22:44:58 - train: epoch 0075, iter [02500, 05004], lr: 0.001000, loss: 0.6209
2022-07-01 22:45:40 - train: epoch 0075, iter [02600, 05004], lr: 0.001000, loss: 0.7439
2022-07-01 22:46:22 - train: epoch 0075, iter [02700, 05004], lr: 0.001000, loss: 0.6325
2022-07-01 22:47:04 - train: epoch 0075, iter [02800, 05004], lr: 0.001000, loss: 0.5376
2022-07-01 22:47:46 - train: epoch 0075, iter [02900, 05004], lr: 0.001000, loss: 0.6492
2022-07-01 22:48:28 - train: epoch 0075, iter [03000, 05004], lr: 0.001000, loss: 0.6493
2022-07-01 22:49:11 - train: epoch 0075, iter [03100, 05004], lr: 0.001000, loss: 0.6507
2022-07-01 22:49:53 - train: epoch 0075, iter [03200, 05004], lr: 0.001000, loss: 0.6757
2022-07-01 22:50:35 - train: epoch 0075, iter [03300, 05004], lr: 0.001000, loss: 0.7349
2022-07-01 22:51:17 - train: epoch 0075, iter [03400, 05004], lr: 0.001000, loss: 0.6357
2022-07-01 22:51:59 - train: epoch 0075, iter [03500, 05004], lr: 0.001000, loss: 0.6813
2022-07-01 22:52:42 - train: epoch 0075, iter [03600, 05004], lr: 0.001000, loss: 0.7433
2022-07-01 22:53:24 - train: epoch 0075, iter [03700, 05004], lr: 0.001000, loss: 0.6091
2022-07-01 22:54:06 - train: epoch 0075, iter [03800, 05004], lr: 0.001000, loss: 0.5348
2022-07-01 22:54:48 - train: epoch 0075, iter [03900, 05004], lr: 0.001000, loss: 0.6692
2022-07-01 22:55:30 - train: epoch 0075, iter [04000, 05004], lr: 0.001000, loss: 0.6354
2022-07-01 22:56:13 - train: epoch 0075, iter [04100, 05004], lr: 0.001000, loss: 0.6048
2022-07-01 22:56:55 - train: epoch 0075, iter [04200, 05004], lr: 0.001000, loss: 0.7216
2022-07-01 22:57:37 - train: epoch 0075, iter [04300, 05004], lr: 0.001000, loss: 0.7067
2022-07-01 22:58:19 - train: epoch 0075, iter [04400, 05004], lr: 0.001000, loss: 0.4956
2022-07-01 22:59:02 - train: epoch 0075, iter [04500, 05004], lr: 0.001000, loss: 0.7435
2022-07-01 22:59:44 - train: epoch 0075, iter [04600, 05004], lr: 0.001000, loss: 0.6154
2022-07-01 23:00:26 - train: epoch 0075, iter [04700, 05004], lr: 0.001000, loss: 0.6918
2022-07-01 23:01:09 - train: epoch 0075, iter [04800, 05004], lr: 0.001000, loss: 0.6893
2022-07-01 23:01:51 - train: epoch 0075, iter [04900, 05004], lr: 0.001000, loss: 0.7415
2022-07-01 23:02:33 - train: epoch 0075, iter [05000, 05004], lr: 0.001000, loss: 0.6090
2022-07-01 23:02:35 - train: epoch 075, train_loss: 0.6603
2022-07-01 23:03:49 - eval: epoch: 075, acc1: 77.948%, acc5: 93.782%, test_loss: 0.8887, per_image_load_time: 1.866ms, per_image_inference_time: 0.871ms
2022-07-01 23:03:50 - until epoch: 075, best_acc1: 77.948%
2022-07-01 23:03:50 - epoch 076 lr: 0.001000
2022-07-01 23:04:38 - train: epoch 0076, iter [00100, 05004], lr: 0.001000, loss: 0.6137
2022-07-01 23:05:20 - train: epoch 0076, iter [00200, 05004], lr: 0.001000, loss: 0.4842
2022-07-01 23:06:02 - train: epoch 0076, iter [00300, 05004], lr: 0.001000, loss: 0.6424
2022-07-01 23:06:44 - train: epoch 0076, iter [00400, 05004], lr: 0.001000, loss: 0.6608
2022-07-01 23:07:26 - train: epoch 0076, iter [00500, 05004], lr: 0.001000, loss: 0.6573
2022-07-01 23:08:08 - train: epoch 0076, iter [00600, 05004], lr: 0.001000, loss: 0.5839
2022-07-01 23:08:50 - train: epoch 0076, iter [00700, 05004], lr: 0.001000, loss: 0.6998
2022-07-01 23:09:32 - train: epoch 0076, iter [00800, 05004], lr: 0.001000, loss: 0.7515
2022-07-01 23:10:15 - train: epoch 0076, iter [00900, 05004], lr: 0.001000, loss: 0.6670
2022-07-01 23:10:57 - train: epoch 0076, iter [01000, 05004], lr: 0.001000, loss: 0.7204
2022-07-01 23:11:39 - train: epoch 0076, iter [01100, 05004], lr: 0.001000, loss: 0.5620
2022-07-01 23:12:21 - train: epoch 0076, iter [01200, 05004], lr: 0.001000, loss: 0.6967
2022-07-01 23:13:03 - train: epoch 0076, iter [01300, 05004], lr: 0.001000, loss: 0.7271
2022-07-01 23:13:45 - train: epoch 0076, iter [01400, 05004], lr: 0.001000, loss: 0.6589
2022-07-01 23:14:27 - train: epoch 0076, iter [01500, 05004], lr: 0.001000, loss: 0.5651
2022-07-01 23:15:09 - train: epoch 0076, iter [01600, 05004], lr: 0.001000, loss: 0.5756
2022-07-01 23:15:51 - train: epoch 0076, iter [01700, 05004], lr: 0.001000, loss: 0.6510
2022-07-01 23:16:33 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 0.4837
2022-07-01 23:17:15 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 0.7136
2022-07-01 23:17:58 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 0.5851
2022-07-01 23:18:40 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 0.8177
2022-07-01 23:19:22 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 0.6465
2022-07-01 23:20:04 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 0.5245
2022-07-01 23:20:46 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 0.8092
2022-07-01 23:21:28 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 0.6026
2022-07-01 23:22:10 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 0.7722
2022-07-01 23:22:52 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 0.6185
2022-07-01 23:23:35 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 0.4494
2022-07-01 23:24:17 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 0.5783
2022-07-01 23:24:59 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 0.6589
2022-07-01 23:25:41 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 0.7198
2022-07-01 23:26:23 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 0.7206
2022-07-01 23:27:05 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 0.5617
2022-07-01 23:27:47 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 0.8435
2022-07-01 23:28:29 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 0.6575
2022-07-01 23:29:11 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 0.5415
2022-07-01 23:29:53 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 0.5248
2022-07-01 23:30:35 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 0.6649
2022-07-01 23:31:17 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 0.5596
2022-07-01 23:31:59 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 0.6870
2022-07-01 23:32:42 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 0.6271
2022-07-01 23:33:24 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 0.6956
2022-07-01 23:34:06 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 0.7895
2022-07-01 23:34:48 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 0.8442
2022-07-01 23:35:30 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 0.7189
2022-07-01 23:36:13 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 0.7270
2022-07-01 23:36:55 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 0.8696
2022-07-01 23:37:37 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 0.6955
2022-07-01 23:38:19 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 0.6410
2022-07-01 23:39:01 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 0.8138
2022-07-01 23:39:03 - train: epoch 076, train_loss: 0.6546
2022-07-01 23:40:17 - eval: epoch: 076, acc1: 77.870%, acc5: 93.892%, test_loss: 0.8901, per_image_load_time: 1.948ms, per_image_inference_time: 0.925ms
2022-07-01 23:40:18 - until epoch: 076, best_acc1: 77.948%
2022-07-01 23:40:18 - epoch 077 lr: 0.001000
2022-07-01 23:41:07 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 0.6507
2022-07-01 23:41:49 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 0.9977
2022-07-01 23:42:32 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 0.6164
2022-07-01 23:43:14 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 0.7630
2022-07-01 23:43:56 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 0.7283
2022-07-01 23:44:39 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 0.4367
2022-07-01 23:45:21 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 0.5472
2022-07-01 23:46:03 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 0.7629
2022-07-01 23:46:45 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 0.6728
2022-07-01 23:47:27 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 0.7192
2022-07-01 23:48:09 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 0.6620
2022-07-01 23:48:51 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 0.7562
2022-07-01 23:49:34 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 0.4895
2022-07-01 23:50:16 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 0.6693
2022-07-01 23:50:58 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 0.6092
2022-07-01 23:51:40 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 0.6371
2022-07-01 23:52:22 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 0.7194
2022-07-01 23:53:04 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 0.7399
2022-07-01 23:53:47 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 0.5835
2022-07-01 23:54:29 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 0.5048
2022-07-01 23:55:11 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 0.6710
2022-07-01 23:55:53 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 0.6044
2022-07-01 23:56:35 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 0.7522
2022-07-01 23:57:17 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 0.6018
2022-07-01 23:57:59 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 0.6680
2022-07-01 23:58:42 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 0.7373
2022-07-01 23:59:24 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 0.6104
2022-07-02 00:00:06 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 0.6897
2022-07-02 00:00:48 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 0.6966
2022-07-02 00:01:31 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 0.5724
2022-07-02 00:02:13 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 0.5889
2022-07-02 00:02:55 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 0.8051
2022-07-02 00:03:37 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 0.6248
2022-07-02 00:04:19 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 0.6118
2022-07-02 00:05:01 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 0.6259
2022-07-02 00:05:43 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 0.5577
2022-07-02 00:06:26 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 0.6822
2022-07-02 00:07:08 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 0.5358
2022-07-02 00:07:50 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 0.4506
2022-07-02 00:08:32 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 0.6572
2022-07-02 00:09:15 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 0.6679
2022-07-02 00:09:57 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 0.7292
2022-07-02 00:10:39 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 0.6442
2022-07-02 00:11:21 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 0.6913
2022-07-02 00:12:03 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 0.7298
2022-07-02 00:12:46 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 0.5357
2022-07-02 00:13:28 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 0.6143
2022-07-02 00:14:10 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 0.6447
2022-07-02 00:14:52 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 0.7678
2022-07-02 00:15:35 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 0.5317
2022-07-02 00:15:37 - train: epoch 077, train_loss: 0.6518
2022-07-02 00:16:51 - eval: epoch: 077, acc1: 77.958%, acc5: 93.858%, test_loss: 0.8911, per_image_load_time: 1.965ms, per_image_inference_time: 0.888ms
2022-07-02 00:16:52 - until epoch: 077, best_acc1: 77.958%
2022-07-02 00:16:52 - epoch 078 lr: 0.001000
2022-07-02 00:17:40 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 0.5303
2022-07-02 00:18:22 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 0.8014
2022-07-02 00:19:04 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 0.5340
2022-07-02 00:19:46 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 0.7000
2022-07-02 00:20:28 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 0.5235
2022-07-02 00:21:10 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 0.5486
2022-07-02 00:21:52 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 0.7235
2022-07-02 00:22:35 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 0.6973
2022-07-02 00:23:17 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 0.8012
2022-07-02 00:23:59 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 0.6828
2022-07-02 00:24:41 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 0.6207
2022-07-02 00:25:23 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 0.5842
2022-07-02 00:26:05 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 0.7324
2022-07-02 00:26:47 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 0.6193
2022-07-02 00:27:29 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 0.4997
2022-07-02 00:28:11 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 0.7035
2022-07-02 00:28:54 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 0.6848
2022-07-02 00:29:36 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 0.6808
2022-07-02 00:30:18 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 0.6834
2022-07-02 00:31:00 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 0.5913
2022-07-02 00:31:42 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 0.8171
2022-07-02 00:32:24 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 0.6901
2022-07-02 00:33:06 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 0.6867
2022-07-02 00:33:48 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 0.6900
2022-07-02 00:34:31 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 0.7235
2022-07-02 00:35:13 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 0.6400
2022-07-02 00:35:55 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 0.7065
2022-07-02 00:36:37 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 0.6461
2022-07-02 00:37:19 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 0.6354
2022-07-02 00:38:02 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 0.5980
2022-07-02 00:38:44 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 0.6886
2022-07-02 00:39:26 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 0.6835
2022-07-02 00:40:08 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 0.6894
2022-07-02 00:40:50 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 0.4709
2022-07-02 00:41:33 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 0.6844
2022-07-02 00:42:15 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 0.7715
2022-07-02 00:42:57 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 0.6799
2022-07-02 00:43:39 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 0.7178
2022-07-02 00:44:21 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 0.5862
2022-07-02 00:45:03 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 0.5341
2022-07-02 00:45:45 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 0.7547
2022-07-02 00:46:27 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 0.8594
2022-07-02 00:47:10 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 0.6208
2022-07-02 00:47:52 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 0.6873
2022-07-02 00:48:34 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 0.6342
2022-07-02 00:49:16 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 0.5311
2022-07-02 00:49:58 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 0.6439
2022-07-02 00:50:40 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 0.7095
2022-07-02 00:51:23 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 0.6246
2022-07-02 00:52:05 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 0.7110
2022-07-02 00:52:07 - train: epoch 078, train_loss: 0.6464
2022-07-02 00:53:21 - eval: epoch: 078, acc1: 77.922%, acc5: 93.828%, test_loss: 0.8913, per_image_load_time: 1.676ms, per_image_inference_time: 0.899ms
2022-07-02 00:53:22 - until epoch: 078, best_acc1: 77.958%
2022-07-02 00:53:22 - epoch 079 lr: 0.001000
2022-07-02 00:54:10 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 0.6403
2022-07-02 00:54:53 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 0.6238
2022-07-02 00:55:36 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 0.7266
2022-07-02 00:56:18 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 0.6301
2022-07-02 00:57:01 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 0.6371
2022-07-02 00:57:43 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 0.6897
2022-07-02 00:58:25 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 0.5726
2022-07-02 00:59:08 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 0.7372
2022-07-02 00:59:50 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 0.6136
2022-07-02 01:00:33 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 0.7633
2022-07-02 01:01:15 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 0.7984
2022-07-02 01:01:58 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 0.7264
2022-07-02 01:02:40 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 0.6495
2022-07-02 01:03:23 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 0.7704
2022-07-02 01:04:05 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 0.7005
2022-07-02 01:04:48 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 0.5713
2022-07-02 01:05:30 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 0.6740
2022-07-02 01:06:13 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 0.6226
2022-07-02 01:06:55 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 0.5860
2022-07-02 01:07:38 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 0.7314
2022-07-02 01:08:20 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 0.4814
2022-07-02 01:09:02 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 0.5245
2022-07-02 01:09:45 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 0.5525
2022-07-02 01:10:27 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 0.6107
2022-07-02 01:11:09 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 0.6186
2022-07-02 01:11:52 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 0.5746
2022-07-02 01:12:34 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 0.5915
2022-07-02 01:13:17 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 0.6619
2022-07-02 01:13:59 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 0.6868
2022-07-02 01:14:42 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 0.5929
2022-07-02 01:15:24 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 0.6302
2022-07-02 01:16:07 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 0.7616
2022-07-02 01:16:49 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 0.6694
2022-07-02 01:17:32 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 0.6027
2022-07-02 01:18:14 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 0.6976
2022-07-02 01:18:57 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 0.6262
2022-07-02 01:19:40 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 0.6535
2022-07-02 01:20:22 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 0.7241
2022-07-02 01:21:04 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 0.5775
2022-07-02 01:21:47 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 0.6113
2022-07-02 01:22:29 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 0.5987
2022-07-02 01:23:12 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 0.5810
2022-07-02 01:23:55 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 0.4560
2022-07-02 01:24:37 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 0.8388
2022-07-02 01:25:20 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 0.6789
2022-07-02 01:26:02 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 0.6104
2022-07-02 01:26:45 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 0.6247
2022-07-02 01:27:27 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 0.8868
2022-07-02 01:28:10 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 0.5231
2022-07-02 01:28:52 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 0.6581
2022-07-02 01:28:54 - train: epoch 079, train_loss: 0.6433
2022-07-02 01:30:08 - eval: epoch: 079, acc1: 77.826%, acc5: 93.870%, test_loss: 0.8939, per_image_load_time: 1.234ms, per_image_inference_time: 0.887ms
2022-07-02 01:30:09 - until epoch: 079, best_acc1: 77.958%
2022-07-02 01:30:09 - epoch 080 lr: 0.001000
2022-07-02 01:30:57 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 0.6380
2022-07-02 01:31:39 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 0.6845
2022-07-02 01:32:21 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 0.6634
2022-07-02 01:33:03 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 0.7329
2022-07-02 01:33:44 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 0.5797
2022-07-02 01:34:26 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 0.6716
2022-07-02 01:35:08 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 0.6524
2022-07-02 01:35:50 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 0.4998
2022-07-02 01:36:32 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 0.6010
2022-07-02 01:37:13 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 0.5295
2022-07-02 01:37:55 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 0.5387
2022-07-02 01:38:37 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 0.7165
2022-07-02 01:39:19 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 0.5655
2022-07-02 01:40:01 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 0.6107
2022-07-02 01:40:42 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 0.6097
2022-07-02 01:41:24 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 0.6252
2022-07-02 01:42:06 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 0.6391
2022-07-02 01:42:47 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 0.7210
2022-07-02 01:43:29 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 0.5346
2022-07-02 01:44:11 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 0.6518
2022-07-02 01:44:53 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 0.6196
2022-07-02 01:45:35 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 0.5723
2022-07-02 01:46:17 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 0.5575
2022-07-02 01:46:58 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 0.7625
2022-07-02 01:47:40 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 0.6024
2022-07-02 01:48:22 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 0.7727
2022-07-02 01:49:04 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 0.4876
2022-07-02 01:49:46 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 0.6417
2022-07-02 01:50:28 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 0.6582
2022-07-02 01:51:09 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 0.5667
2022-07-02 01:51:51 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 0.5909
2022-07-02 01:52:33 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 0.4665
2022-07-02 01:53:15 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 0.6885
2022-07-02 01:53:57 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 0.6581
2022-07-02 01:54:39 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 0.6748
2022-07-02 01:55:20 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 0.6166
2022-07-02 01:56:02 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 0.6315
2022-07-02 01:56:44 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 0.4847
2022-07-02 01:57:26 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 0.5326
2022-07-02 01:58:08 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 0.7243
2022-07-02 01:58:50 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 0.7860
2022-07-02 01:59:32 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 0.7164
2022-07-02 02:00:13 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 0.7160
2022-07-02 02:00:55 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 0.6201
2022-07-02 02:01:37 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 0.5767
2022-07-02 02:02:19 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 0.5514
2022-07-02 02:03:01 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 0.5759
2022-07-02 02:03:43 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 0.7007
2022-07-02 02:04:25 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 0.6767
2022-07-02 02:05:07 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 0.6066
2022-07-02 02:05:09 - train: epoch 080, train_loss: 0.6385
2022-07-02 02:06:23 - eval: epoch: 080, acc1: 77.862%, acc5: 93.738%, test_loss: 0.8981, per_image_load_time: 1.085ms, per_image_inference_time: 0.887ms
2022-07-02 02:06:24 - until epoch: 080, best_acc1: 77.958%
2022-07-02 02:06:24 - epoch 081 lr: 0.001000
2022-07-02 02:07:12 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 0.5707
2022-07-02 02:07:54 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 0.4865
2022-07-02 02:08:36 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 0.6249
2022-07-02 02:09:18 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 0.5791
2022-07-02 02:10:00 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 0.7267
2022-07-02 02:10:42 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 0.5340
2022-07-02 02:11:24 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 0.7459
2022-07-02 02:12:06 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 0.5848
2022-07-02 02:12:48 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 0.7746
2022-07-02 02:13:30 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 0.6920
2022-07-02 02:14:12 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 0.5768
2022-07-02 02:14:54 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 0.6771
2022-07-02 02:15:36 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 0.5603
2022-07-02 02:16:18 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 0.5215
2022-07-02 02:17:01 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 0.6505
2022-07-02 02:17:43 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 0.6110
2022-07-02 02:18:25 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 0.6427
2022-07-02 02:19:07 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 0.6819
2022-07-02 02:19:49 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 0.6161
2022-07-02 02:20:31 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 0.7671
2022-07-02 02:21:14 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 0.6868
2022-07-02 02:21:56 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 0.6063
2022-07-02 02:22:38 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 0.6130
2022-07-02 02:23:20 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 0.6920
2022-07-02 02:24:03 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 0.4780
2022-07-02 02:24:45 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 0.7031
2022-07-02 02:25:27 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 0.7104
2022-07-02 02:26:09 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 0.6165
2022-07-02 02:26:51 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 0.5705
2022-07-02 02:27:33 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 0.5765
2022-07-02 02:28:15 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 0.6435
2022-07-02 02:28:58 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 0.4710
2022-07-02 02:29:40 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 0.5795
2022-07-02 02:30:22 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 0.8405
2022-07-02 02:31:04 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 0.8250
2022-07-02 02:31:46 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 0.6293
2022-07-02 02:32:28 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 0.6638
2022-07-02 02:33:10 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 0.5897
2022-07-02 02:33:53 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 0.5614
2022-07-02 02:34:35 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 0.6578
2022-07-02 02:35:17 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 0.6239
2022-07-02 02:35:59 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 0.7033
2022-07-02 02:36:41 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 0.6923
2022-07-02 02:37:23 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 0.5074
2022-07-02 02:38:06 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 0.5555
2022-07-02 02:38:48 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 0.7051
2022-07-02 02:39:30 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 0.7110
2022-07-02 02:40:12 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 0.5222
2022-07-02 02:40:54 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 0.6015
2022-07-02 02:41:36 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 0.5750
2022-07-02 02:41:38 - train: epoch 081, train_loss: 0.6336
2022-07-02 02:42:52 - eval: epoch: 081, acc1: 77.800%, acc5: 93.756%, test_loss: 0.8981, per_image_load_time: 1.553ms, per_image_inference_time: 0.892ms
2022-07-02 02:42:53 - until epoch: 081, best_acc1: 77.958%
2022-07-02 02:42:53 - epoch 082 lr: 0.001000
2022-07-02 02:43:42 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 0.5599
2022-07-02 02:44:24 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 0.5628
2022-07-02 02:45:06 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 0.6470
2022-07-02 02:45:48 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 0.6399
2022-07-02 02:46:30 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 0.6475
2022-07-02 02:47:12 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 0.5629
2022-07-02 02:47:54 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 0.5937
2022-07-02 02:48:36 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 0.6685
2022-07-02 02:49:18 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 0.6559
2022-07-02 02:50:00 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 0.6225
2022-07-02 02:50:42 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 0.7836
2022-07-02 02:51:24 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 0.8522
2022-07-02 02:52:06 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 0.7631
2022-07-02 02:52:48 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 0.6566
2022-07-02 02:53:30 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 0.6527
2022-07-02 02:54:12 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 0.6159
2022-07-02 02:54:54 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 0.6016
2022-07-02 02:55:36 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 0.7718
2022-07-02 02:56:18 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 0.4977
2022-07-02 02:57:00 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 0.5338
2022-07-02 02:57:42 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 0.6330
2022-07-02 02:58:24 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 0.6457
2022-07-02 02:59:06 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 0.6919
2022-07-02 02:59:48 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 0.7767
2022-07-02 03:00:30 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 0.4826
2022-07-02 03:01:12 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 0.6218
2022-07-02 03:01:54 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 0.5958
2022-07-02 03:02:37 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 0.5817
2022-07-02 03:03:18 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 0.5118
2022-07-02 03:04:01 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 0.5258
2022-07-02 03:04:43 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 0.5892
2022-07-02 03:05:24 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 0.8280
2022-07-02 03:06:06 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 0.6677
2022-07-02 03:06:48 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 0.6302
2022-07-02 03:07:30 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 0.6379
2022-07-02 03:08:12 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 0.6062
2022-07-02 03:08:54 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 0.5572
2022-07-02 03:09:36 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 0.6187
2022-07-02 03:10:18 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 0.5525
2022-07-02 03:11:00 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 0.5613
2022-07-02 03:11:42 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 0.6480
2022-07-02 03:12:25 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 0.7486
2022-07-02 03:13:07 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 0.5818
2022-07-02 03:13:48 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 0.7113
2022-07-02 03:14:31 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 0.5497
2022-07-02 03:15:13 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 0.7005
2022-07-02 03:15:55 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 0.5143
2022-07-02 03:16:37 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 0.6387
2022-07-02 03:17:19 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 0.6114
2022-07-02 03:18:01 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 0.6388
2022-07-02 03:18:03 - train: epoch 082, train_loss: 0.6319
2022-07-02 03:19:16 - eval: epoch: 082, acc1: 77.914%, acc5: 93.796%, test_loss: 0.8985, per_image_load_time: 1.910ms, per_image_inference_time: 0.896ms
2022-07-02 03:19:17 - until epoch: 082, best_acc1: 77.958%
2022-07-02 03:19:17 - epoch 083 lr: 0.001000
2022-07-02 03:20:06 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 0.5514
2022-07-02 03:20:48 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 0.6178
2022-07-02 03:21:30 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 0.6267
2022-07-02 03:22:12 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 0.7422
2022-07-02 03:22:54 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 0.5217
2022-07-02 03:23:35 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 0.5778
2022-07-02 03:24:17 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 0.6898
2022-07-02 03:24:59 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 0.6654
2022-07-02 03:25:41 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 0.6957
2022-07-02 03:26:23 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 0.7293
2022-07-02 03:27:05 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 0.7166
2022-07-02 03:27:47 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 0.6352
2022-07-02 03:28:29 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 0.7176
2022-07-02 03:29:11 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 0.6190
2022-07-02 03:29:53 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 0.5789
2022-07-02 03:30:34 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 0.5559
2022-07-02 03:31:16 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 0.5723
2022-07-02 03:31:58 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 0.6713
2022-07-02 03:32:40 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 0.5083
2022-07-02 03:33:22 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 0.4588
2022-07-02 03:34:04 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 0.8028
2022-07-02 03:34:46 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 0.7415
2022-07-02 03:35:28 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 0.6760
2022-07-02 03:36:10 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 0.5663
2022-07-02 03:36:52 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 0.7366
2022-07-02 03:37:34 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 0.6111
2022-07-02 03:38:16 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 0.6178
2022-07-02 03:38:58 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 0.5989
2022-07-02 03:39:40 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 0.8244
2022-07-02 03:40:22 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 0.6433
2022-07-02 03:41:03 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 0.5831
2022-07-02 03:41:45 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 0.5744
2022-07-02 03:42:27 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 0.8175
2022-07-02 03:43:09 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 0.7090
2022-07-02 03:43:51 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 0.7291
2022-07-02 03:44:33 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 0.6478
2022-07-02 03:45:15 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 0.5209
2022-07-02 03:45:57 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 0.5687
2022-07-02 03:46:39 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 0.7554
2022-07-02 03:47:21 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 0.6853
2022-07-02 03:48:03 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 0.5385
2022-07-02 03:48:45 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 0.9254
2022-07-02 03:49:27 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 0.6860
2022-07-02 03:50:09 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 0.6864
2022-07-02 03:50:51 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 0.5507
2022-07-02 03:51:33 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 0.7438
2022-07-02 03:52:15 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 0.6535
2022-07-02 03:52:57 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 0.5620
2022-07-02 03:53:39 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 0.6426
2022-07-02 03:54:21 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 0.4908
2022-07-02 03:54:23 - train: epoch 083, train_loss: 0.6301
2022-07-02 03:55:37 - eval: epoch: 083, acc1: 77.912%, acc5: 93.780%, test_loss: 0.9026, per_image_load_time: 1.585ms, per_image_inference_time: 0.874ms
2022-07-02 03:55:37 - until epoch: 083, best_acc1: 77.958%
2022-07-02 03:55:37 - epoch 084 lr: 0.001000
2022-07-02 03:56:25 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 0.5703
2022-07-02 03:57:07 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 0.5732
2022-07-02 03:57:49 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 0.5465
2022-07-02 03:58:30 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 0.6036
2022-07-02 03:59:12 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 0.6925
2022-07-02 03:59:54 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 0.8575
2022-07-02 04:00:36 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 0.5820
2022-07-02 04:01:18 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 0.7141
2022-07-02 04:02:00 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 0.7234
2022-07-02 04:02:41 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 0.5265
2022-07-02 04:03:23 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 0.6765
2022-07-02 04:04:05 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 0.6854
2022-07-02 04:04:47 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 0.7935
2022-07-02 04:05:29 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 0.6994
2022-07-02 04:06:11 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 0.6434
2022-07-02 04:06:53 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 0.4243
2022-07-02 04:07:35 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 0.7172
2022-07-02 04:08:16 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 0.5306
2022-07-02 04:08:58 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 0.6354
2022-07-02 04:09:40 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 0.6690
2022-07-02 04:10:22 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 0.5449
2022-07-02 04:11:04 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 0.6707
2022-07-02 04:11:45 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 0.5794
2022-07-02 04:12:27 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 0.5153
2022-07-02 04:13:09 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 0.6147
2022-07-02 04:13:51 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 0.4927
2022-07-02 04:14:33 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 0.7151
2022-07-02 04:15:15 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 0.5823
2022-07-02 04:15:57 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 0.7845
2022-07-02 04:16:39 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 0.7838
2022-07-02 04:17:21 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 0.5824
2022-07-02 04:18:03 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 0.5416
2022-07-02 04:18:45 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 0.4638
2022-07-02 04:19:26 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 0.6541
2022-07-02 04:20:08 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 0.5552
2022-07-02 04:20:50 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 0.5336
2022-07-02 04:21:32 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 0.8634
2022-07-02 04:22:14 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 0.6038
2022-07-02 04:22:56 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 0.6305
2022-07-02 04:23:38 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 0.5777
2022-07-02 04:24:20 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 0.6532
2022-07-02 04:25:02 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 0.5937
2022-07-02 04:25:44 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 0.6455
2022-07-02 04:26:25 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 0.7082
2022-07-02 04:27:07 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 0.5753
2022-07-02 04:27:49 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 0.6025
2022-07-02 04:28:31 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 0.5444
2022-07-02 04:29:13 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 0.6314
2022-07-02 04:29:55 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 0.6145
2022-07-02 04:30:37 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 0.8109
2022-07-02 04:30:39 - train: epoch 084, train_loss: 0.6241
2022-07-02 04:31:54 - eval: epoch: 084, acc1: 77.768%, acc5: 93.768%, test_loss: 0.9048, per_image_load_time: 1.728ms, per_image_inference_time: 0.908ms
2022-07-02 04:31:55 - until epoch: 084, best_acc1: 77.958%
2022-07-02 04:31:55 - epoch 085 lr: 0.001000
2022-07-02 04:32:42 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 0.5321
2022-07-02 04:33:24 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 0.5264
2022-07-02 04:34:06 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 0.7056
2022-07-02 04:34:48 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 0.6463
2022-07-02 04:35:30 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 0.6606
2022-07-02 04:36:12 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 0.5427
2022-07-02 04:36:54 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 0.5915
2022-07-02 04:37:35 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 0.5826
2022-07-02 04:38:17 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 0.7073
2022-07-02 04:38:59 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 0.5641
2022-07-02 04:39:41 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 0.5894
2022-07-02 04:40:23 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 0.6629
2022-07-02 04:41:05 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 0.8306
2022-07-02 04:41:46 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 0.6429
2022-07-02 04:42:28 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 0.6536
2022-07-02 04:43:10 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 0.5243
2022-07-02 04:43:52 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 0.7273
2022-07-02 04:44:34 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 0.5119
2022-07-02 04:45:15 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 0.5597
2022-07-02 04:45:57 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 0.5538
2022-07-02 04:46:39 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 0.5533
2022-07-02 04:47:21 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 0.6525
2022-07-02 04:48:03 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 0.6510
2022-07-02 04:48:44 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 0.7614
2022-07-02 04:49:26 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 0.6041
2022-07-02 04:50:08 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 0.6756
2022-07-02 04:50:50 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 0.6039
2022-07-02 04:51:32 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 0.7306
2022-07-02 04:52:14 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 0.6971
2022-07-02 04:52:55 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 0.6347
2022-07-02 04:53:37 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 0.7192
2022-07-02 04:54:19 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 0.5626
2022-07-02 04:55:01 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 0.6312
2022-07-02 04:55:43 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 0.6207
2022-07-02 04:56:25 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 0.6197
2022-07-02 04:57:07 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 0.7429
2022-07-02 04:57:49 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 0.5942
2022-07-02 04:58:31 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 0.4805
2022-07-02 04:59:13 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 0.6531
2022-07-02 04:59:55 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 0.8384
2022-07-02 05:00:37 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 0.6934
2022-07-02 05:01:19 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 0.6253
2022-07-02 05:02:01 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 0.6422
2022-07-02 05:02:43 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 0.6449
2022-07-02 05:03:25 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 0.7486
2022-07-02 05:04:07 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 0.5847
2022-07-02 05:04:49 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 0.8545
2022-07-02 05:05:31 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 0.4880
2022-07-02 05:06:12 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 0.5560
2022-07-02 05:06:54 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 0.4900
2022-07-02 05:06:57 - train: epoch 085, train_loss: 0.6183
2022-07-02 05:08:11 - eval: epoch: 085, acc1: 77.802%, acc5: 93.720%, test_loss: 0.9029, per_image_load_time: 1.367ms, per_image_inference_time: 0.892ms
2022-07-02 05:08:11 - until epoch: 085, best_acc1: 77.958%
2022-07-02 05:08:11 - epoch 086 lr: 0.001000
2022-07-02 05:08:59 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 0.5552
2022-07-02 05:09:41 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 0.5537
2022-07-02 05:10:23 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 0.5114
2022-07-02 05:11:05 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 0.7376
2022-07-02 05:11:47 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 0.5781
2022-07-02 05:12:29 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 0.5705
2022-07-02 05:13:11 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 0.5297
2022-07-02 05:13:52 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 0.5572
2022-07-02 05:14:34 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 0.5269
2022-07-02 05:15:16 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 0.5234
2022-07-02 05:15:58 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 0.7458
2022-07-02 05:16:40 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 0.5185
2022-07-02 05:17:22 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 0.6926
2022-07-02 05:18:04 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 0.6401
2022-07-02 05:18:45 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 0.5007
2022-07-02 05:19:27 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 0.4995
2022-07-02 05:20:09 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 0.6253
2022-07-02 05:20:51 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 0.6035
2022-07-02 05:21:33 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 0.4457
2022-07-02 05:22:14 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 0.7304
2022-07-02 05:22:56 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 0.5831
2022-07-02 05:23:38 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 0.6642
2022-07-02 05:24:20 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 0.6798
2022-07-02 05:25:02 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 0.4741
2022-07-02 05:25:44 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 0.8181
2022-07-02 05:26:26 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 0.6028
2022-07-02 05:27:08 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 0.5811
2022-07-02 05:27:49 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 0.7915
2022-07-02 05:28:31 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 0.4437
2022-07-02 05:29:13 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 0.6952
2022-07-02 05:29:55 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 0.6227
2022-07-02 05:30:37 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 0.5864
2022-07-02 05:31:19 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 0.5363
2022-07-02 05:32:01 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 0.5466
2022-07-02 05:32:43 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 0.6718
2022-07-02 05:33:25 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 0.5712
2022-07-02 05:34:07 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 0.7417
2022-07-02 05:34:49 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 0.6659
2022-07-02 05:35:31 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 0.5776
2022-07-02 05:36:13 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 0.5975
2022-07-02 05:36:55 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 0.5478
2022-07-02 05:37:37 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 0.7084
2022-07-02 05:38:19 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 0.6163
2022-07-02 05:39:00 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 0.5575
2022-07-02 05:39:42 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 0.5343
2022-07-02 05:40:24 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 0.5668
2022-07-02 05:41:06 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 0.5707
2022-07-02 05:41:48 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 0.7248
2022-07-02 05:42:29 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 0.5323
2022-07-02 05:43:11 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 0.6599
2022-07-02 05:43:13 - train: epoch 086, train_loss: 0.6159
2022-07-02 05:44:28 - eval: epoch: 086, acc1: 77.782%, acc5: 93.758%, test_loss: 0.9064, per_image_load_time: 1.185ms, per_image_inference_time: 0.875ms
2022-07-02 05:44:29 - until epoch: 086, best_acc1: 77.958%
2022-07-02 05:44:29 - epoch 087 lr: 0.001000
2022-07-02 05:45:18 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 0.4633
2022-07-02 05:46:00 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 0.5619
2022-07-02 05:46:42 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 0.5615
2022-07-02 05:47:24 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 0.7096
2022-07-02 05:48:06 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 0.5391
2022-07-02 05:48:47 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 0.6436
2022-07-02 05:49:29 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 0.5976
2022-07-02 05:50:11 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 0.5876
2022-07-02 05:50:53 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 0.4782
2022-07-02 05:51:35 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 0.4912
2022-07-02 05:52:17 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 0.5313
2022-07-02 05:52:59 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 0.6229
2022-07-02 05:53:41 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 0.8338
2022-07-02 05:54:23 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 0.4993
2022-07-02 05:55:05 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 0.5461
2022-07-02 05:55:46 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 0.6178
2022-07-02 05:56:28 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 0.7504
2022-07-02 05:57:10 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 0.7650
2022-07-02 05:57:52 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 0.6410
2022-07-02 05:58:34 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 0.6405
2022-07-02 05:59:16 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 0.7530
2022-07-02 05:59:58 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 0.5686
2022-07-02 06:00:40 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 0.5613
2022-07-02 06:01:21 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 0.6237
2022-07-02 06:02:03 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 0.6827
2022-07-02 06:02:45 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 0.5154
2022-07-02 06:03:27 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 0.6418
2022-07-02 06:04:09 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 0.5308
2022-07-02 06:04:51 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 0.5697
2022-07-02 06:05:33 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 0.6727
2022-07-02 06:06:15 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 0.6529
2022-07-02 06:06:57 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 0.6467
2022-07-02 06:07:39 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 0.6255
2022-07-02 06:08:21 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 0.5468
2022-07-02 06:09:03 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 0.5047
2022-07-02 06:09:44 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 0.5372
2022-07-02 06:10:26 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 0.7079
2022-07-02 06:11:08 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 0.4901
2022-07-02 06:11:50 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 0.6858
2022-07-02 06:12:32 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 0.6410
2022-07-02 06:13:14 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 0.7265
2022-07-02 06:13:56 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 0.5828
2022-07-02 06:14:37 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 0.6999
2022-07-02 06:15:19 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 0.5939
2022-07-02 06:16:02 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 0.6450
2022-07-02 06:16:44 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 0.6906
2022-07-02 06:17:26 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 0.6079
2022-07-02 06:18:08 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 0.7725
2022-07-02 06:18:50 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 0.7099
2022-07-02 06:19:31 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 0.5573
2022-07-02 06:19:34 - train: epoch 087, train_loss: 0.6121
2022-07-02 06:20:47 - eval: epoch: 087, acc1: 77.738%, acc5: 93.760%, test_loss: 0.9084, per_image_load_time: 0.905ms, per_image_inference_time: 0.889ms
2022-07-02 06:20:48 - until epoch: 087, best_acc1: 77.958%
2022-07-02 06:20:48 - epoch 088 lr: 0.001000
2022-07-02 06:21:37 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 0.6681
2022-07-02 06:22:19 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 0.5827
2022-07-02 06:23:00 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 0.5700
2022-07-02 06:23:42 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 0.6725
2022-07-02 06:24:24 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 0.7373
2022-07-02 06:25:06 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 0.7214
2022-07-02 06:25:48 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 0.5964
2022-07-02 06:26:30 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 0.9170
2022-07-02 06:27:12 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 0.6771
2022-07-02 06:27:53 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 0.6972
2022-07-02 06:28:35 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 0.4599
2022-07-02 06:29:17 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 0.7211
2022-07-02 06:29:59 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 0.6472
2022-07-02 06:30:41 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 0.6430
2022-07-02 06:31:22 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 0.6652
2022-07-02 06:32:04 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 0.7359
2022-07-02 06:32:46 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 0.5144
2022-07-02 06:33:28 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 0.5568
2022-07-02 06:34:10 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 0.6127
2022-07-02 06:34:52 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 0.4962
2022-07-02 06:35:33 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 0.7764
2022-07-02 06:36:15 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 0.7048
2022-07-02 06:36:57 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 0.5023
2022-07-02 06:37:39 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 0.6225
2022-07-02 06:38:21 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 0.6314
2022-07-02 06:39:03 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 0.5280
2022-07-02 06:39:45 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 0.6574
2022-07-02 06:40:27 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 0.6214
2022-07-02 06:41:09 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 0.5648
2022-07-02 06:41:51 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 0.6614
2022-07-02 06:42:33 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 0.5138
2022-07-02 06:43:15 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 0.7796
2022-07-02 06:43:56 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 0.5735
2022-07-02 06:44:38 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 0.4602
2022-07-02 06:45:20 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 0.5470
2022-07-02 06:46:02 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 0.6064
2022-07-02 06:46:44 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 0.6513
2022-07-02 06:47:26 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 0.6737
2022-07-02 06:48:08 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 0.5731
2022-07-02 06:48:50 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 0.4688
2022-07-02 06:49:32 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 0.7555
2022-07-02 06:50:14 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 0.6452
2022-07-02 06:50:56 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 0.6325
2022-07-02 06:51:38 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 0.5527
2022-07-02 06:52:20 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 0.5895
2022-07-02 06:53:01 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 0.7648
2022-07-02 06:53:43 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 0.6790
2022-07-02 06:54:25 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 0.7143
2022-07-02 06:55:08 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 0.4714
2022-07-02 06:55:50 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 0.6551
2022-07-02 06:55:52 - train: epoch 088, train_loss: 0.6112
2022-07-02 06:57:06 - eval: epoch: 088, acc1: 77.576%, acc5: 93.726%, test_loss: 0.9114, per_image_load_time: 0.668ms, per_image_inference_time: 0.875ms
2022-07-02 06:57:07 - until epoch: 088, best_acc1: 77.958%
2022-07-02 06:57:07 - epoch 089 lr: 0.001000
2022-07-02 06:57:55 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 0.7296
2022-07-02 06:58:37 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 0.4531
2022-07-02 06:59:19 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 0.7775
2022-07-02 07:00:00 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 0.6638
2022-07-02 07:00:42 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 0.5970
2022-07-02 07:01:24 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 0.5828
2022-07-02 07:02:06 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 0.6909
2022-07-02 07:02:48 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 0.5738
2022-07-02 07:03:30 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 0.5113
2022-07-02 07:04:11 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 0.7476
2022-07-02 07:04:53 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 0.5611
2022-07-02 07:05:35 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 0.7692
2022-07-02 07:06:17 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 0.5522
2022-07-02 07:06:59 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 0.5864
2022-07-02 07:07:41 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 0.5950
2022-07-02 07:08:23 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 0.5292
2022-07-02 07:09:05 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 0.8750
2022-07-02 07:09:47 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 0.7507
2022-07-02 07:10:29 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 0.4657
2022-07-02 07:11:11 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 0.6265
2022-07-02 07:11:53 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 0.5952
2022-07-02 07:12:35 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 0.7194
2022-07-02 07:13:17 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 0.6016
2022-07-02 07:13:58 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 0.6636
2022-07-02 07:14:40 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 0.5857
2022-07-02 07:15:22 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 0.5350
2022-07-02 07:16:04 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 0.5956
2022-07-02 07:16:46 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 0.7781
2022-07-02 07:17:28 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 0.6094
2022-07-02 07:18:10 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 0.6245
2022-07-02 07:18:52 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 0.5926
2022-07-02 07:19:34 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 0.6337
2022-07-02 07:20:16 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 0.6731
2022-07-02 07:20:58 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 0.5599
2022-07-02 07:21:40 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 0.6201
2022-07-02 07:22:21 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 0.7792
2022-07-02 07:23:03 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 0.6211
2022-07-02 07:23:45 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 0.6416
2022-07-02 07:24:27 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 0.6138
2022-07-02 07:25:09 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 0.5282
2022-07-02 07:25:51 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 0.5915
2022-07-02 07:26:33 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 0.5763
2022-07-02 07:27:15 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 0.6632
2022-07-02 07:27:57 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 0.5383
2022-07-02 07:28:39 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 0.5736
2022-07-02 07:29:21 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 0.7220
2022-07-02 07:30:03 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 0.5792
2022-07-02 07:30:45 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 0.5677
2022-07-02 07:31:27 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 0.5827
2022-07-02 07:32:09 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 0.4659
2022-07-02 07:32:11 - train: epoch 089, train_loss: 0.6065
2022-07-02 07:33:24 - eval: epoch: 089, acc1: 77.748%, acc5: 93.700%, test_loss: 0.9089, per_image_load_time: 1.331ms, per_image_inference_time: 0.899ms
2022-07-02 07:33:25 - until epoch: 089, best_acc1: 77.958%
2022-07-02 07:33:25 - epoch 090 lr: 0.001000
2022-07-02 07:34:13 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 0.5499
2022-07-02 07:34:55 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 0.6998
2022-07-02 07:35:37 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 0.5336
2022-07-02 07:36:19 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 0.6984
2022-07-02 07:37:00 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 0.6687
2022-07-02 07:37:42 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 0.8337
2022-07-02 07:38:24 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 0.6197
2022-07-02 07:39:06 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 0.7927
2022-07-02 07:39:48 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 0.5018
2022-07-02 07:40:30 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 0.6046
2022-07-02 07:41:12 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 0.5441
2022-07-02 07:41:54 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 0.5652
2022-07-02 07:42:35 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 0.6341
2022-07-02 07:43:17 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 0.5610
2022-07-02 07:43:59 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 0.7418
2022-07-02 07:44:41 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 0.5392
2022-07-02 07:45:23 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 0.5247
2022-07-02 07:46:05 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 0.5398
2022-07-02 07:46:47 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 0.5907
2022-07-02 07:47:29 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 0.7220
2022-07-02 07:48:11 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 0.7723
2022-07-02 07:48:53 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 0.6407
2022-07-02 07:49:34 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 0.6122
2022-07-02 07:50:16 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 0.5201
2022-07-02 07:50:58 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 0.6693
2022-07-02 07:51:40 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 0.5241
2022-07-02 07:52:22 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 0.5059
2022-07-02 07:53:04 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 0.6382
2022-07-02 07:53:46 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 0.6497
2022-07-02 07:54:28 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 0.6818
2022-07-02 07:55:10 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 0.5890
2022-07-02 07:55:52 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 0.4947
2022-07-02 07:56:34 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 0.6931
2022-07-02 07:57:16 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 0.6941
2022-07-02 07:57:58 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 0.5747
2022-07-02 07:58:40 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 0.4749
2022-07-02 07:59:22 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 0.6089
2022-07-02 08:00:04 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 0.6862
2022-07-02 08:00:47 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 0.6236
2022-07-02 08:01:29 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 0.4612
2022-07-02 08:02:11 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 0.6668
2022-07-02 08:02:53 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 0.5881
2022-07-02 08:03:35 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 0.5656
2022-07-02 08:04:17 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 0.6212
2022-07-02 08:04:59 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 0.6840
2022-07-02 08:05:41 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 0.5536
2022-07-02 08:06:23 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 0.7542
2022-07-02 08:07:05 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 0.5911
2022-07-02 08:07:47 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 0.5673
2022-07-02 08:08:29 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 0.5468
2022-07-02 08:08:31 - train: epoch 090, train_loss: 0.6042
2022-07-02 08:09:44 - eval: epoch: 090, acc1: 77.544%, acc5: 93.650%, test_loss: 0.9158, per_image_load_time: 0.696ms, per_image_inference_time: 0.882ms
2022-07-02 08:09:45 - until epoch: 090, best_acc1: 77.958%
2022-07-02 08:09:45 - epoch 091 lr: 0.000100
2022-07-02 08:10:34 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 0.4805
2022-07-02 08:11:16 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 0.6385
2022-07-02 08:11:58 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 0.6050
2022-07-02 08:12:39 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 0.5357
2022-07-02 08:13:21 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 0.5769
2022-07-02 08:14:03 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 0.5104
2022-07-02 08:14:45 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 0.7070
2022-07-02 08:15:27 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 0.5536
2022-07-02 08:16:09 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 0.7521
2022-07-02 08:16:51 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 0.5159
2022-07-02 08:17:32 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 0.4083
2022-07-02 08:18:14 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 0.7119
2022-07-02 08:18:56 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 0.6500
2022-07-02 08:19:38 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 0.5639
2022-07-02 08:20:20 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 0.5303
2022-07-02 08:21:02 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 0.5027
2022-07-02 08:21:44 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 0.5869
2022-07-02 08:22:26 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 0.5472
2022-07-02 08:23:08 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 0.5527
2022-07-02 08:23:50 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 0.4682
2022-07-02 08:24:32 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 0.5510
2022-07-02 08:25:14 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 0.6251
2022-07-02 08:25:56 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 0.5276
2022-07-02 08:26:38 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 0.4952
2022-07-02 08:27:20 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 0.5407
2022-07-02 08:28:02 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 0.6917
2022-07-02 08:28:45 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 0.5278
2022-07-02 08:29:27 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 0.7227
2022-07-02 08:30:09 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 0.6580
2022-07-02 08:30:51 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 0.7839
2022-07-02 08:31:33 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 0.5824
2022-07-02 08:32:15 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 0.6071
2022-07-02 08:32:57 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 0.4636
2022-07-02 08:33:39 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 0.6122
2022-07-02 08:34:21 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 0.7371
2022-07-02 08:35:03 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 0.6567
2022-07-02 08:35:45 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 0.5626
2022-07-02 08:36:27 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 0.5844
2022-07-02 08:37:09 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 0.6620
2022-07-02 08:37:51 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 0.6446
2022-07-02 08:38:33 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 0.6692
2022-07-02 08:39:16 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 0.5483
2022-07-02 08:39:57 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 0.6736
2022-07-02 08:40:40 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 0.5105
2022-07-02 08:41:22 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 0.6883
2022-07-02 08:42:04 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 0.4948
2022-07-02 08:42:46 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 0.4575
2022-07-02 08:43:28 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 0.5813
2022-07-02 08:44:10 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 0.6172
2022-07-02 08:44:52 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 0.5499
2022-07-02 08:44:54 - train: epoch 091, train_loss: 0.5828
2022-07-02 08:46:09 - eval: epoch: 091, acc1: 77.808%, acc5: 93.822%, test_loss: 0.9040, per_image_load_time: 0.696ms, per_image_inference_time: 0.878ms
2022-07-02 08:46:09 - until epoch: 091, best_acc1: 77.958%
2022-07-02 08:46:09 - epoch 092 lr: 0.000100
2022-07-02 08:46:58 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 0.5725
2022-07-02 08:47:39 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 0.7874
2022-07-02 08:48:21 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 0.7287
2022-07-02 08:49:03 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 0.7103
2022-07-02 08:49:45 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 0.5140
2022-07-02 08:50:27 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 0.5693
2022-07-02 08:51:09 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 0.6182
2022-07-02 08:51:51 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 0.4791
2022-07-02 08:52:33 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 0.5012
2022-07-02 08:53:15 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 0.5092
2022-07-02 08:53:56 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 0.5099
2022-07-02 08:54:39 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 0.5091
2022-07-02 08:55:21 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 0.4806
2022-07-02 08:56:03 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 0.5830
2022-07-02 08:56:45 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 0.4626
2022-07-02 08:57:27 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 0.5885
2022-07-02 08:58:09 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 0.6396
2022-07-02 08:58:51 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 0.5836
2022-07-02 08:59:33 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 0.5499
2022-07-02 09:00:16 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 0.5969
2022-07-02 09:00:58 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 0.6063
2022-07-02 09:01:40 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 0.5108
2022-07-02 09:02:22 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 0.6147
2022-07-02 09:03:04 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 0.4577
2022-07-02 09:03:46 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 0.5525
2022-07-02 09:04:28 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 0.4673
2022-07-02 09:05:10 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 0.6815
2022-07-02 09:05:52 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 0.6291
2022-07-02 09:06:35 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 0.5341
2022-07-02 09:07:17 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 0.5291
2022-07-02 09:07:59 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 0.5401
2022-07-02 09:08:41 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 0.5721
2022-07-02 09:09:23 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 0.5614
2022-07-02 09:10:05 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 0.6012
2022-07-02 09:10:47 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 0.2928
2022-07-02 09:11:29 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 0.4031
2022-07-02 09:12:11 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 0.4792
2022-07-02 09:12:53 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 0.6373
2022-07-02 09:13:35 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 0.6183
2022-07-02 09:14:18 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 0.6182
2022-07-02 09:15:00 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 0.4930
2022-07-02 09:15:42 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 0.6002
2022-07-02 09:16:24 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 0.4727
2022-07-02 09:17:06 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 0.7910
2022-07-02 09:17:48 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 0.4761
2022-07-02 09:18:30 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 0.6389
2022-07-02 09:19:13 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 0.4563
2022-07-02 09:19:55 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 0.5562
2022-07-02 09:20:37 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 0.7089
2022-07-02 09:21:19 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 0.4300
2022-07-02 09:21:21 - train: epoch 092, train_loss: 0.5733
2022-07-02 09:22:36 - eval: epoch: 092, acc1: 77.920%, acc5: 93.822%, test_loss: 0.9039, per_image_load_time: 0.593ms, per_image_inference_time: 0.849ms
2022-07-02 09:22:37 - until epoch: 092, best_acc1: 77.958%
2022-07-02 09:22:37 - epoch 093 lr: 0.000100
2022-07-02 09:23:25 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 0.5052
2022-07-02 09:24:07 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 0.6059
2022-07-02 09:24:49 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 0.5492
2022-07-02 09:25:31 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 0.6222
2022-07-02 09:26:13 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 0.6611
2022-07-02 09:26:54 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 0.6146
2022-07-02 09:27:36 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 0.6103
2022-07-02 09:28:18 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 0.6244
2022-07-02 09:29:00 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 0.7390
2022-07-02 09:29:42 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.3836
2022-07-02 09:30:24 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 0.5998
2022-07-02 09:31:06 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 0.5706
2022-07-02 09:31:47 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 0.4455
2022-07-02 09:32:29 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 0.7819
2022-07-02 09:33:11 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 0.6458
2022-07-02 09:33:53 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 0.5306
2022-07-02 09:34:35 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 0.6277
2022-07-02 09:35:17 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 0.5708
2022-07-02 09:35:59 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 0.4156
2022-07-02 09:36:40 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 0.4815
2022-07-02 09:37:22 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 0.5693
2022-07-02 09:38:04 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 0.6443
2022-07-02 09:38:46 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 0.5148
2022-07-02 09:39:28 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 0.6112
2022-07-02 09:40:10 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 0.5385
2022-07-02 09:40:52 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 0.7365
2022-07-02 09:41:33 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 0.4972
2022-07-02 09:42:15 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 0.6130
2022-07-02 09:42:57 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 0.4684
2022-07-02 09:43:39 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 0.4714
2022-07-02 09:44:21 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 0.5593
2022-07-02 09:45:03 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 0.4958
2022-07-02 09:45:45 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 0.5743
2022-07-02 09:46:27 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 0.5903
2022-07-02 09:47:09 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 0.5996
2022-07-02 09:47:51 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 0.7340
2022-07-02 09:48:33 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 0.6143
2022-07-02 09:49:15 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 0.5706
2022-07-02 09:49:57 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 0.3694
2022-07-02 09:50:39 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 0.6684
2022-07-02 09:51:20 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 0.5072
2022-07-02 09:52:02 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 0.6434
2022-07-02 09:52:44 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 0.5952
2022-07-02 09:53:26 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 0.3923
2022-07-02 09:54:09 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 0.6560
2022-07-02 09:54:51 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 0.5284
2022-07-02 09:55:33 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 0.5596
2022-07-02 09:56:15 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 0.6590
2022-07-02 09:56:57 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 0.6118
2022-07-02 09:57:39 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 0.5559
2022-07-02 09:57:41 - train: epoch 093, train_loss: 0.5706
2022-07-02 09:58:55 - eval: epoch: 093, acc1: 77.936%, acc5: 93.788%, test_loss: 0.9024, per_image_load_time: 0.646ms, per_image_inference_time: 0.891ms
2022-07-02 09:58:56 - until epoch: 093, best_acc1: 77.958%
2022-07-02 18:08:04 - epoch 094 lr: 0.000100
2022-07-02 18:08:52 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 0.5128
2022-07-02 18:09:34 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 0.6265
2022-07-02 18:10:16 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 0.6362
2022-07-02 18:10:58 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 0.4864
2022-07-02 18:11:40 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 0.6185
2022-07-02 18:12:22 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 0.4743
2022-07-02 18:13:04 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 0.5439
2022-07-02 18:13:46 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 0.5453
2022-07-02 18:14:27 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 0.4938
2022-07-02 18:15:09 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 0.6247
2022-07-02 18:15:51 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 0.5504
2022-07-02 18:16:33 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 0.3788
2022-07-02 18:17:15 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 0.5286
2022-07-02 18:17:57 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 0.6721
2022-07-02 18:18:39 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 0.6477
2022-07-02 18:19:21 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 0.7195
2022-07-02 18:20:03 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 0.5611
2022-07-02 18:20:45 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 0.6707
2022-07-02 18:21:27 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 0.5768
2022-07-02 18:22:09 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 0.4669
2022-07-02 18:22:51 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 0.4733
2022-07-02 18:23:33 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 0.4273
2022-07-02 18:24:15 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 0.4372
2022-07-02 18:24:57 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 0.5957
2022-07-02 18:25:39 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 0.5496
2022-07-02 18:26:21 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 0.5950
2022-07-02 18:27:03 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 0.4342
2022-07-02 18:27:45 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 0.7078
2022-07-02 18:28:28 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 0.4383
2022-07-02 18:29:10 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 0.5693
2022-07-02 18:29:52 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 0.6703
2022-07-02 18:30:34 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 0.4988
2022-07-02 18:31:16 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 0.6655
2022-07-02 18:31:58 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 0.6611
2022-07-02 18:32:40 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 0.7007
2022-07-02 18:33:23 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 0.5435
2022-07-02 18:34:05 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 0.6451
2022-07-02 18:34:47 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 0.5232
2022-07-02 18:35:29 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 0.6144
2022-07-02 18:36:11 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 0.6502
2022-07-02 18:36:53 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 0.6915
2022-07-02 18:37:36 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 0.6733
2022-07-02 18:38:18 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 0.6446
2022-07-02 18:39:00 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 0.5399
2022-07-02 18:39:42 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 0.5493
2022-07-02 18:40:24 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 0.6965
2022-07-02 18:41:06 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 0.6969
2022-07-02 18:41:49 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 0.6028
2022-07-02 18:42:31 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 0.5852
2022-07-02 18:43:13 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 0.6624
2022-07-02 18:43:15 - train: epoch 094, train_loss: 0.5687
2022-07-02 18:44:29 - eval: epoch: 094, acc1: 77.916%, acc5: 93.820%, test_loss: 0.9038, per_image_load_time: 0.838ms, per_image_inference_time: 0.905ms
2022-07-02 18:44:30 - until epoch: 094, best_acc1: 77.958%
2022-07-02 18:44:30 - epoch 095 lr: 0.000100
2022-07-02 18:45:18 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 0.6468
2022-07-02 18:46:00 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 0.6699
2022-07-02 18:46:42 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 0.6999
2022-07-02 18:47:24 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 0.5419
2022-07-02 18:48:06 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 0.6093
2022-07-02 18:48:48 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 0.5056
2022-07-02 18:49:30 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 0.5856
2022-07-02 18:50:12 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 0.6224
2022-07-02 18:50:54 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 0.6117
2022-07-02 18:51:36 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 0.6452
2022-07-02 18:52:18 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 0.4117
2022-07-02 18:53:00 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 0.5133
2022-07-02 18:53:42 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 0.4447
2022-07-02 18:54:24 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 0.5521
2022-07-02 18:55:06 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 0.3947
2022-07-02 18:55:48 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.4711
2022-07-02 18:56:30 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 0.5003
2022-07-02 18:57:12 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 0.5826
2022-07-02 18:57:54 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 0.6772
2022-07-02 18:58:36 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 0.5653
2022-07-02 18:59:18 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 0.5010
2022-07-02 19:00:00 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 0.4671
2022-07-02 19:00:42 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 0.4926
2022-07-02 19:01:23 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 0.4885
2022-07-02 19:02:05 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 0.5279
2022-07-02 19:02:47 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 0.6215
2022-07-02 19:03:29 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 0.6186
2022-07-02 19:04:11 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 0.3933
2022-07-02 19:04:53 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 0.5641
2022-07-02 19:05:35 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 0.5902
2022-07-02 19:06:17 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 0.6875
2022-07-02 19:06:59 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 0.5947
2022-07-02 19:07:41 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 0.6274
2022-07-02 19:08:23 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 0.4000
2022-07-02 19:09:05 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 0.5138
2022-07-02 19:09:47 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 0.4302
2022-07-02 19:10:29 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 0.4947
2022-07-02 19:11:11 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 0.7203
2022-07-02 19:11:53 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 0.4959
2022-07-02 19:12:35 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 0.4178
2022-07-02 19:13:17 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 0.5459
2022-07-02 19:13:59 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 0.4171
2022-07-02 19:14:41 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 0.7363
2022-07-02 19:15:23 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 0.4586
2022-07-02 19:16:05 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 0.5575
2022-07-02 19:16:47 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 0.6257
2022-07-02 19:17:29 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 0.4501
2022-07-02 19:18:11 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 0.6108
2022-07-02 19:18:53 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 0.4886
2022-07-02 19:19:35 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 0.5337
2022-07-02 19:19:37 - train: epoch 095, train_loss: 0.5672
2022-07-02 19:20:51 - eval: epoch: 095, acc1: 77.962%, acc5: 93.844%, test_loss: 0.9026, per_image_load_time: 0.708ms, per_image_inference_time: 0.877ms
2022-07-02 19:20:53 - until epoch: 095, best_acc1: 77.962%
2022-07-02 19:20:53 - epoch 096 lr: 0.000100
2022-07-02 19:21:40 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 0.7123
2022-07-02 19:22:22 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 0.4827
2022-07-02 19:23:04 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 0.5356
2022-07-02 19:23:46 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 0.3532
2022-07-02 19:24:28 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 0.6679
2022-07-02 19:25:10 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 0.5470
2022-07-02 19:25:52 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 0.5164
2022-07-02 19:26:34 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 0.4307
2022-07-02 19:27:16 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 0.5797
2022-07-02 19:27:58 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 0.4986
2022-07-02 19:28:40 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 0.7018
2022-07-02 19:29:22 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 0.6990
2022-07-02 19:30:04 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 0.5147
2022-07-02 19:30:46 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 0.6420
2022-07-02 19:31:27 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 0.7617
2022-07-02 19:32:09 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 0.5026
2022-07-02 19:32:52 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 0.4870
2022-07-02 19:33:34 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 0.5417
2022-07-02 19:34:16 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 0.6262
2022-07-02 19:34:58 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 0.7050
2022-07-02 19:35:40 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 0.5726
2022-07-02 19:36:22 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.4326
2022-07-02 19:37:04 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 0.4892
2022-07-02 19:37:46 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 0.5120
2022-07-02 19:38:28 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 0.4625
2022-07-02 19:39:10 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 0.5827
2022-07-02 19:39:52 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 0.6004
2022-07-02 19:40:34 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 0.4746
2022-07-02 19:41:16 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 0.7567
2022-07-02 19:41:58 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 0.5196
2022-07-02 19:42:40 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 0.5812
2022-07-02 19:43:22 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 0.6575
2022-07-02 19:44:04 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 0.8593
2022-07-02 19:44:45 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 0.4375
2022-07-02 19:45:28 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 0.4489
2022-07-02 19:46:10 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 0.3393
2022-07-02 19:46:52 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 0.6099
2022-07-02 19:47:34 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 0.6084
2022-07-02 19:48:16 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 0.5700
2022-07-02 19:48:58 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 0.6406
2022-07-02 19:49:40 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 0.6133
2022-07-02 19:50:22 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 0.5370
2022-07-02 19:51:04 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.3978
2022-07-02 19:51:46 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 0.4764
2022-07-02 19:52:28 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 0.6954
2022-07-02 19:53:10 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 0.5163
2022-07-02 19:53:52 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 0.6373
2022-07-02 19:54:34 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 0.6876
2022-07-02 19:55:16 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 0.5797
2022-07-02 19:55:58 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 0.5476
2022-07-02 19:56:00 - train: epoch 096, train_loss: 0.5661
2022-07-02 19:57:14 - eval: epoch: 096, acc1: 77.924%, acc5: 93.852%, test_loss: 0.9022, per_image_load_time: 1.642ms, per_image_inference_time: 0.884ms
2022-07-02 19:57:15 - until epoch: 096, best_acc1: 77.962%
2022-07-02 19:57:15 - epoch 097 lr: 0.000100
2022-07-02 19:58:04 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 0.5214
2022-07-02 19:58:45 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 0.6131
2022-07-02 19:59:27 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 0.6018
2022-07-02 20:00:09 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 0.4874
2022-07-02 20:00:51 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 0.5307
2022-07-02 20:01:33 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 0.5798
2022-07-02 20:02:15 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 0.6086
2022-07-02 20:02:57 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.4387
2022-07-02 20:03:39 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 0.5061
2022-07-02 20:04:21 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 0.5579
2022-07-02 20:05:03 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 0.4272
2022-07-02 20:05:45 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 0.5722
2022-07-02 20:06:27 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 0.6475
2022-07-02 20:07:09 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 0.5883
2022-07-02 20:07:52 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 0.4541
2022-07-02 20:08:34 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 0.5925
2022-07-02 20:09:16 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 0.5587
2022-07-02 20:09:58 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 0.7782
2022-07-02 20:10:40 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 0.4882
2022-07-02 20:11:22 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 0.5309
2022-07-02 20:12:04 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 0.5545
2022-07-02 20:12:46 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 0.4754
2022-07-02 20:13:28 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 0.4974
2022-07-02 20:14:10 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 0.5828
2022-07-02 20:14:52 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 0.4811
2022-07-02 20:15:34 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 0.5453
2022-07-02 20:16:16 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 0.5830
2022-07-02 20:16:58 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 0.5318
2022-07-02 20:17:40 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 0.7367
2022-07-02 20:18:23 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 0.5759
2022-07-02 20:19:05 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 0.5868
2022-07-02 20:19:47 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 0.6352
2022-07-02 20:20:29 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 0.6363
2022-07-02 20:21:11 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 0.5937
2022-07-02 20:21:53 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 0.3930
2022-07-02 20:22:35 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 0.5209
2022-07-02 20:23:17 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 0.3643
2022-07-02 20:23:59 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 0.6572
2022-07-02 20:24:41 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 0.5774
2022-07-02 20:25:23 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 0.5975
2022-07-02 20:26:06 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 0.5689
2022-07-02 20:26:48 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 0.6426
2022-07-02 20:27:30 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 0.5931
2022-07-02 20:28:12 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 0.5703
2022-07-02 20:28:54 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 0.5441
2022-07-02 20:29:37 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 0.5840
2022-07-02 20:30:19 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 0.4634
2022-07-02 20:31:01 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 0.5312
2022-07-02 20:31:43 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 0.6971
2022-07-02 20:32:25 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 0.5468
2022-07-02 20:32:27 - train: epoch 097, train_loss: 0.5637
2022-07-02 20:33:42 - eval: epoch: 097, acc1: 77.916%, acc5: 93.840%, test_loss: 0.9018, per_image_load_time: 0.809ms, per_image_inference_time: 0.881ms
2022-07-02 20:33:42 - until epoch: 097, best_acc1: 77.962%
2022-07-02 20:33:42 - epoch 098 lr: 0.000100
2022-07-02 20:34:31 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 0.4752
2022-07-02 20:35:12 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 0.5271
2022-07-02 20:35:54 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 0.4803
2022-07-02 20:36:36 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 0.5984
2022-07-02 20:37:18 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 0.6277
2022-07-02 20:38:01 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 0.5317
2022-07-02 20:38:42 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 0.5699
2022-07-02 20:39:25 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 0.6523
2022-07-02 20:40:07 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 0.6387
2022-07-02 20:40:49 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 0.4675
2022-07-02 20:41:31 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 0.5673
2022-07-02 20:42:13 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 0.6080
2022-07-02 20:42:55 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 0.5798
2022-07-02 20:43:37 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 0.5497
2022-07-02 20:44:19 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 0.4848
2022-07-02 20:45:01 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 0.4490
2022-07-02 20:45:43 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 0.6577
2022-07-02 20:46:25 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 0.5529
2022-07-02 20:47:07 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 0.4544
2022-07-02 20:47:49 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 0.5985
2022-07-02 20:48:31 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 0.6289
2022-07-02 20:49:13 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 0.4813
2022-07-02 20:49:55 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 0.5302
2022-07-02 20:50:37 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 0.5255
2022-07-02 20:51:19 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 0.5958
2022-07-02 20:52:01 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 0.5726
2022-07-02 20:52:43 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 0.4566
2022-07-02 20:53:25 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 0.5336
2022-07-02 20:54:07 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 0.4760
2022-07-02 20:54:49 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 0.6198
2022-07-02 20:55:31 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 0.5048
2022-07-02 20:56:13 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 0.5532
2022-07-02 20:56:55 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 0.5316
2022-07-02 20:57:37 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 0.4639
2022-07-02 20:58:19 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 0.5292
2022-07-02 20:59:01 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 0.7054
2022-07-02 20:59:43 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 0.6333
2022-07-02 21:00:25 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 0.5916
2022-07-02 21:01:07 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 0.5010
2022-07-02 21:01:49 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 0.6571
2022-07-02 21:02:31 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 0.5089
2022-07-02 21:03:13 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 0.5381
2022-07-02 21:03:55 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 0.4605
2022-07-02 21:04:37 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 0.6955
2022-07-02 21:05:19 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 0.5988
2022-07-02 21:06:01 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 0.5440
2022-07-02 21:06:43 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 0.4647
2022-07-02 21:07:25 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 0.3543
2022-07-02 21:08:07 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 0.5892
2022-07-02 21:08:49 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 0.5452
2022-07-02 21:08:51 - train: epoch 098, train_loss: 0.5643
2022-07-02 21:10:06 - eval: epoch: 098, acc1: 77.986%, acc5: 93.812%, test_loss: 0.9036, per_image_load_time: 0.806ms, per_image_inference_time: 0.885ms
2022-07-02 21:10:07 - until epoch: 098, best_acc1: 77.986%
2022-07-02 21:10:07 - epoch 099 lr: 0.000100
2022-07-02 21:10:55 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 0.4814
2022-07-02 21:11:37 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 0.6173
2022-07-02 21:12:19 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 0.5342
2022-07-02 21:13:01 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 0.5641
2022-07-02 21:13:43 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 0.5352
2022-07-02 21:14:25 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 0.5027
2022-07-02 21:15:07 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 0.8288
2022-07-02 21:15:49 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 0.5854
2022-07-02 21:16:31 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 0.8013
2022-07-02 21:17:13 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 0.6292
2022-07-02 21:17:55 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 0.5421
2022-07-02 21:18:37 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 0.4274
2022-07-02 21:19:19 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 0.6050
2022-07-02 21:20:01 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 0.3998
2022-07-02 21:20:43 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 0.5306
2022-07-02 21:21:25 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 0.7162
2022-07-02 21:22:07 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 0.5461
2022-07-02 21:22:49 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 0.4256
2022-07-02 21:23:31 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 0.6024
2022-07-02 21:24:13 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 0.4506
2022-07-02 21:24:55 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 0.4808
2022-07-02 21:25:37 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 0.4902
2022-07-02 21:26:19 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 0.4597
2022-07-02 21:27:01 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 0.7778
2022-07-02 21:27:43 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 0.6143
2022-07-02 21:28:25 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 0.6121
2022-07-02 21:29:07 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 0.5679
2022-07-02 21:29:49 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 0.5425
2022-07-02 21:30:31 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 0.4892
2022-07-02 21:31:13 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 0.4970
2022-07-02 21:31:55 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 0.5731
2022-07-02 21:32:37 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 0.6728
2022-07-02 21:33:19 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 0.5323
2022-07-02 21:34:01 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 0.5299
2022-07-02 21:34:43 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 0.6125
2022-07-02 21:35:25 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 0.5347
2022-07-02 21:36:07 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 0.4403
2022-07-02 21:36:49 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 0.6363
2022-07-02 21:37:31 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 0.4899
2022-07-02 21:38:13 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 0.6307
2022-07-02 21:38:55 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 0.4242
2022-07-02 21:39:37 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 0.6641
2022-07-02 21:40:19 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 0.6317
2022-07-02 21:41:01 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 0.5783
2022-07-02 21:41:44 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 0.6732
2022-07-02 21:42:26 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 0.5733
2022-07-02 21:43:08 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 0.6932
2022-07-02 21:43:50 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 0.5699
2022-07-02 21:44:32 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 0.5908
2022-07-02 21:45:15 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 0.5602
2022-07-02 21:45:17 - train: epoch 099, train_loss: 0.5620
2022-07-02 21:46:31 - eval: epoch: 099, acc1: 78.006%, acc5: 93.828%, test_loss: 0.9038, per_image_load_time: 0.911ms, per_image_inference_time: 0.883ms
2022-07-02 21:46:32 - until epoch: 099, best_acc1: 78.006%
2022-07-02 21:46:32 - epoch 100 lr: 0.000100
2022-07-02 21:47:20 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 0.6255
2022-07-02 21:48:02 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 0.6099
2022-07-02 21:48:44 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 0.5259
2022-07-02 21:49:26 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 0.4389
2022-07-02 21:50:08 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 0.6743
2022-07-02 21:50:50 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 0.5800
2022-07-02 21:51:32 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 0.5224
2022-07-02 21:52:13 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 0.4979
2022-07-02 21:52:56 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 0.5679
2022-07-02 21:53:38 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 0.5381
2022-07-02 21:54:19 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 0.4504
2022-07-02 21:55:02 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 0.6471
2022-07-02 21:55:44 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 0.6369
2022-07-02 21:56:26 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 0.6825
2022-07-02 21:57:08 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 0.6464
2022-07-02 21:57:50 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 0.5093
2022-07-02 21:58:32 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 0.5404
2022-07-02 21:59:14 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 0.5915
2022-07-02 21:59:56 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 0.7265
2022-07-02 22:00:38 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 0.6211
2022-07-02 22:01:21 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 0.4953
2022-07-02 22:02:03 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 0.5575
2022-07-02 22:02:45 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 0.4629
2022-07-02 22:03:27 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 0.5409
2022-07-02 22:04:09 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 0.5363
2022-07-02 22:04:51 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 0.6887
2022-07-02 22:05:33 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 0.5015
2022-07-02 22:06:15 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 0.4164
2022-07-02 22:06:57 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 0.5449
2022-07-02 22:07:39 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 0.3690
2022-07-02 22:08:21 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 0.4163
2022-07-02 22:09:03 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 0.6745
2022-07-02 22:09:45 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 0.5263
2022-07-02 22:10:27 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 0.6017
2022-07-02 22:11:09 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 0.5655
2022-07-02 22:11:51 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 0.4880
2022-07-02 22:12:33 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 0.4960
2022-07-02 22:13:15 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 0.4747
2022-07-02 22:13:57 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 0.5857
2022-07-02 22:14:39 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 0.5759
2022-07-02 22:15:22 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 0.6403
2022-07-02 22:16:04 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 0.6051
2022-07-02 22:16:46 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 0.5143
2022-07-02 22:17:28 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 0.6028
2022-07-02 22:18:11 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 0.5078
2022-07-02 22:18:53 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 0.5112
2022-07-02 22:19:35 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 0.5688
2022-07-02 22:20:17 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 0.5004
2022-07-02 22:21:00 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 0.4529
2022-07-02 22:21:42 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 0.4958
2022-07-02 22:21:44 - train: epoch 100, train_loss: 0.5592
2022-07-02 22:22:59 - eval: epoch: 100, acc1: 77.968%, acc5: 93.814%, test_loss: 0.9033, per_image_load_time: 1.387ms, per_image_inference_time: 0.878ms
2022-07-02 22:23:00 - until epoch: 100, best_acc1: 78.006%
2022-07-02 22:23:00 - train done. model: resnet152, train time: 60.283 hours, best_acc1: 78.006%
