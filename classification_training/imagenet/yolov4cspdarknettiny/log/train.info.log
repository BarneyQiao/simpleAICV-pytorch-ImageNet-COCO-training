2022-02-26 22:43:27 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 1.7380
2022-02-26 22:44:01 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 1.8549
2022-02-26 22:44:34 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 1.9993
2022-02-26 22:45:08 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 1.8121
2022-02-26 22:45:41 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 1.8033
2022-02-26 22:46:14 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 1.5605
2022-02-26 22:46:46 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 1.9306
2022-02-26 22:47:19 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 1.7744
2022-02-26 22:47:54 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 2.1751
2022-02-26 22:48:26 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 1.7072
2022-02-26 22:48:59 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 1.7820
2022-02-26 22:49:33 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 1.9565
2022-02-26 22:50:06 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 1.6601
2022-02-26 22:50:39 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 1.7634
2022-02-26 22:51:12 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 1.7654
2022-02-26 22:51:44 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 1.6797
2022-02-26 22:52:19 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 1.8227
2022-02-26 22:52:51 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 1.7420
2022-02-26 22:53:25 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 1.5812
2022-02-26 22:53:57 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 1.7158
2022-02-26 22:54:31 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 1.6770
2022-02-26 22:55:03 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 1.8101
2022-02-26 22:55:37 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 1.9357
2022-02-26 22:56:09 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 1.7314
2022-02-26 22:56:42 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 1.8232
2022-02-26 22:57:14 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 1.7926
2022-02-26 22:57:49 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 1.6844
2022-02-26 22:58:23 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 1.7513
2022-02-26 22:58:59 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 1.5228
2022-02-26 22:59:34 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 1.8622
2022-02-26 23:00:10 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 1.7351
2022-02-26 23:00:48 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 1.7845
2022-02-26 23:01:24 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 1.8830
2022-02-26 23:01:26 - train: epoch 076, train_loss: 1.8034
2022-02-26 23:02:46 - eval: epoch: 076, acc1: 63.622%, acc5: 85.162%, test_loss: 1.5333, per_image_load_time: 2.999ms, per_image_inference_time: 0.114ms
2022-02-26 23:02:46 - until epoch: 076, best_acc1: 63.718%
2022-02-26 23:02:46 - epoch 077 lr: 0.0010000000000000002
2022-02-26 23:03:24 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 1.9840
2022-02-26 23:03:58 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 1.8461
2022-02-26 23:04:32 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 1.7207
2022-02-26 23:05:05 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 1.7765
2022-02-26 23:05:38 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 1.6509
2022-02-26 23:06:11 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 1.5616
2022-02-26 23:06:45 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 1.7902
2022-02-26 23:07:16 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 1.8033
2022-02-26 23:07:51 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 1.9618
2022-02-26 23:08:23 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 1.9040
2022-02-26 23:08:58 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 1.9357
2022-02-26 23:09:30 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 1.9386
2022-02-26 23:10:06 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 1.5145
2022-02-26 23:10:38 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 1.7816
2022-02-26 23:11:13 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 1.6941
2022-02-26 23:11:46 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 1.8422
2022-02-26 23:12:18 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 2.1840
2022-02-26 23:12:53 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 1.7759
2022-02-26 23:13:26 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 1.7243
2022-02-26 23:14:00 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 1.7183
2022-02-26 23:14:33 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 1.9230
2022-02-26 23:15:07 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 1.7195
2022-02-26 23:15:39 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 1.7773
2022-02-26 23:16:13 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 1.8302
2022-02-26 23:16:47 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 1.8933
2022-02-26 23:17:21 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 1.5923
2022-02-26 23:17:55 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 1.8948
2022-02-26 23:18:29 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 1.9165
2022-02-26 23:19:01 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 2.0536
2022-02-26 23:19:36 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 1.7509
2022-02-26 23:20:09 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 1.7542
2022-02-26 23:20:43 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 1.9721
2022-02-26 23:21:16 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 1.8011
2022-02-26 23:21:51 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 2.0268
2022-02-26 23:22:24 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 1.6321
2022-02-26 23:22:57 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 1.6819
2022-02-26 23:23:31 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 1.6498
2022-02-26 23:24:04 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 1.6750
2022-02-26 23:24:39 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 1.7006
2022-02-26 23:25:13 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 2.1166
2022-02-26 23:25:47 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 1.8641
2022-02-26 23:26:20 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 1.7421
2022-02-26 23:26:55 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 1.8677
2022-02-26 23:27:30 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 1.7878
2022-02-26 23:28:04 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 1.9874
2022-02-26 23:28:40 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 1.6888
2022-02-26 23:29:16 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 1.6626
2022-02-26 23:29:54 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 1.9343
2022-02-26 23:30:32 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 2.0636
2022-02-26 23:31:12 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 1.8070
2022-02-26 23:31:14 - train: epoch 077, train_loss: 1.8027
2022-02-26 23:32:34 - eval: epoch: 077, acc1: 63.578%, acc5: 85.214%, test_loss: 1.5279, per_image_load_time: 2.126ms, per_image_inference_time: 0.126ms
2022-02-26 23:32:34 - until epoch: 077, best_acc1: 63.718%
2022-02-26 23:32:34 - epoch 078 lr: 0.0010000000000000002
2022-02-26 23:33:13 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 1.9342
2022-02-26 23:33:47 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 2.0406
2022-02-26 23:34:20 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 1.9933
2022-02-26 23:34:55 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 1.8168
2022-02-26 23:35:27 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 1.6140
2022-02-26 23:36:00 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 1.6767
2022-02-26 23:36:34 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 1.8888
2022-02-26 23:37:07 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 1.8698
2022-02-26 23:37:42 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 1.8096
2022-02-26 23:38:15 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 1.9430
2022-02-26 23:38:49 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 1.6041
2022-02-26 23:39:23 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 1.7398
2022-02-26 23:39:56 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 1.7407
2022-02-26 23:40:29 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 1.6273
2022-02-26 23:41:03 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 1.7169
2022-02-26 23:41:37 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 1.8837
2022-02-26 23:42:12 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 1.6992
2022-02-26 23:42:45 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 1.9530
2022-02-26 23:43:19 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 1.8557
2022-02-26 23:43:52 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 1.8298
2022-02-26 23:44:27 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 1.9507
2022-02-26 23:45:00 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 1.8734
2022-02-26 23:45:34 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 1.8247
2022-02-26 23:46:07 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 1.8413
2022-02-26 23:46:42 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 1.7353
2022-02-26 23:47:15 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 1.9417
2022-02-26 23:47:50 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 1.8229
2022-02-26 23:48:22 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 1.8739
2022-02-26 23:48:57 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 1.6648
2022-02-26 23:49:30 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 1.8226
2022-02-26 23:50:05 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 1.8509
2022-02-26 23:50:38 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 1.9101
2022-02-26 23:51:11 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 1.9431
2022-02-26 23:51:45 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 1.5901
2022-02-26 23:52:18 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 1.7796
2022-02-26 23:52:53 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 1.8908
2022-02-26 23:53:27 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 1.9203
2022-02-26 23:53:59 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 1.7126
2022-02-26 23:54:33 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 1.6927
2022-02-26 23:55:06 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 1.8270
2022-02-26 23:55:41 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 1.7972
2022-02-26 23:56:13 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 2.0986
2022-02-26 23:56:48 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 1.9738
2022-02-26 23:57:22 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 1.7817
2022-02-26 23:57:59 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 1.7429
2022-02-26 23:58:48 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 1.7459
2022-02-26 23:59:23 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 1.8098
2022-02-27 00:00:04 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 1.8933
2022-02-27 00:00:41 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 1.6835
2022-02-27 00:01:18 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 1.8662
2022-02-27 00:01:20 - train: epoch 078, train_loss: 1.8013
2022-02-27 00:02:47 - eval: epoch: 078, acc1: 63.802%, acc5: 85.204%, test_loss: 1.5292, per_image_load_time: 1.546ms, per_image_inference_time: 0.107ms
2022-02-27 00:02:48 - until epoch: 078, best_acc1: 63.802%
2022-02-27 00:02:48 - epoch 079 lr: 0.0010000000000000002
2022-02-27 00:03:26 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 1.7291
2022-02-27 00:04:00 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 1.7411
2022-02-27 00:04:33 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 1.9377
2022-02-27 00:05:07 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 1.7992
2022-02-27 00:05:40 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 1.6949
2022-02-27 00:06:14 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 1.8232
2022-02-27 00:06:49 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 1.7039
2022-02-27 00:07:22 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 1.8895
2022-02-27 00:07:55 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 1.7650
2022-02-27 00:08:29 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 1.8933
2022-02-27 00:09:02 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 2.1388
2022-02-27 00:09:37 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 1.7846
2022-02-27 00:10:10 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 1.6902
2022-02-27 00:10:44 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 1.7076
2022-02-27 00:11:17 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 1.8149
2022-02-27 00:11:50 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 1.7534
2022-02-27 00:12:24 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 1.7315
2022-02-27 00:12:58 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 1.9184
2022-02-27 00:13:32 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 1.7568
2022-02-27 00:14:05 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 1.9761
2022-02-27 00:14:39 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 1.6502
2022-02-27 00:15:12 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 1.8511
2022-02-27 00:15:45 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 1.6922
2022-02-27 00:16:19 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 1.8188
2022-02-27 00:16:52 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 1.6670
2022-02-27 00:17:24 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 1.7488
2022-02-27 00:17:59 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 1.5636
2022-02-27 00:18:31 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 1.6977
2022-02-27 00:19:05 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 1.9654
2022-02-27 00:19:39 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 1.8798
2022-02-27 00:20:14 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 1.8194
2022-02-27 00:20:46 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 1.9406
2022-02-27 00:21:20 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 1.7023
2022-02-27 00:21:53 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 1.7964
2022-02-27 00:22:27 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 1.9103
2022-02-27 00:23:01 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 1.7123
2022-02-27 00:23:35 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 1.8086
2022-02-27 00:24:09 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 2.0746
2022-02-27 00:24:43 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 1.7446
2022-02-27 00:25:16 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 1.5078
2022-02-27 00:25:49 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 1.7642
2022-02-27 00:26:22 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 1.5317
2022-02-27 00:26:56 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 1.4203
2022-02-27 00:27:30 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 1.9804
2022-02-27 00:28:06 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 2.0399
2022-02-27 00:28:40 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 1.8592
2022-02-27 00:29:18 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 1.6017
2022-02-27 00:29:53 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 1.8633
2022-02-27 00:30:32 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 1.8442
2022-02-27 00:31:11 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 1.5365
2022-02-27 00:31:13 - train: epoch 079, train_loss: 1.7993
2022-02-27 00:32:29 - eval: epoch: 079, acc1: 63.620%, acc5: 85.210%, test_loss: 1.5314, per_image_load_time: 2.364ms, per_image_inference_time: 0.149ms
2022-02-27 00:32:29 - until epoch: 079, best_acc1: 63.802%
2022-02-27 00:32:29 - epoch 080 lr: 0.0010000000000000002
2022-02-27 00:33:06 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 1.7460
2022-02-27 00:33:40 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 1.7487
2022-02-27 00:34:14 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 1.8231
2022-02-27 00:34:47 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 1.6994
2022-02-27 00:35:20 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 1.5750
2022-02-27 00:35:55 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 1.6477
2022-02-27 00:36:27 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 1.6224
2022-02-27 00:37:02 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 1.6491
2022-02-27 00:37:34 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 1.7156
2022-02-27 00:38:09 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 1.8565
2022-02-27 00:38:43 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 1.7569
2022-02-27 00:39:16 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 1.7647
2022-02-27 00:39:49 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 1.6562
2022-02-27 00:40:22 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 1.7349
2022-02-27 00:40:56 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 1.6952
2022-02-27 00:41:29 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 1.9488
2022-02-27 00:42:02 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 1.8573
2022-02-27 00:42:36 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 1.8088
2022-02-27 00:43:09 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 1.7558
2022-02-27 00:43:43 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 1.8474
2022-02-27 00:44:16 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 1.8617
2022-02-27 00:44:50 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 1.9098
2022-02-27 00:45:23 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 1.9185
2022-02-27 00:45:57 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 2.0292
2022-02-27 00:46:31 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 1.7109
2022-02-27 00:47:04 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 1.8158
2022-02-27 00:47:37 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 1.7085
2022-02-27 00:48:11 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 1.9437
2022-02-27 00:48:43 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 1.8850
2022-02-27 00:49:17 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 1.7226
2022-02-27 00:49:50 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 1.9412
2022-02-27 00:50:25 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 1.5487
2022-02-27 00:50:57 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 1.8215
2022-02-27 00:51:31 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 1.6886
2022-02-27 00:52:04 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 1.6447
2022-02-27 00:52:39 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 1.7781
2022-02-27 00:53:12 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 1.6624
2022-02-27 00:53:46 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 1.8425
2022-02-27 00:54:19 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 1.5905
2022-02-27 00:54:52 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 1.7916
2022-02-27 00:55:25 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 1.9714
2022-02-27 00:55:59 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 1.7040
2022-02-27 00:56:32 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 2.1128
2022-02-27 00:57:06 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 1.7619
2022-02-27 00:57:42 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 1.7886
2022-02-27 00:58:16 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 1.8856
2022-02-27 00:58:51 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 1.7619
2022-02-27 00:59:29 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 1.6589
2022-02-27 01:00:06 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 2.0217
2022-02-27 01:00:44 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 1.8564
2022-02-27 01:00:46 - train: epoch 080, train_loss: 1.7996
2022-02-27 01:02:11 - eval: epoch: 080, acc1: 63.710%, acc5: 85.124%, test_loss: 1.5303, per_image_load_time: 1.250ms, per_image_inference_time: 0.114ms
2022-02-27 01:02:11 - until epoch: 080, best_acc1: 63.802%
2022-02-27 01:02:11 - epoch 081 lr: 0.0010000000000000002
2022-02-27 01:02:50 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 1.7079
2022-02-27 01:03:23 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 1.7423
2022-02-27 01:03:57 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 1.9901
2022-02-27 01:04:30 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 1.7513
2022-02-27 01:05:03 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 2.0648
2022-02-27 01:05:38 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 1.7647
2022-02-27 01:06:11 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 1.8266
2022-02-27 01:06:46 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 1.9398
2022-02-27 01:07:18 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 2.1945
2022-02-27 01:07:53 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 1.8543
2022-02-27 01:08:25 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 1.6874
2022-02-27 01:08:59 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 1.9589
2022-02-27 01:09:32 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 1.7739
2022-02-27 01:10:07 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 1.6027
2022-02-27 01:10:40 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 2.0182
2022-02-27 01:11:14 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 1.5797
2022-02-27 01:11:47 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 1.7243
2022-02-27 01:12:22 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 1.7636
2022-02-27 01:12:55 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 1.7262
2022-02-27 01:13:29 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 1.7300
2022-02-27 01:14:01 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 1.7621
2022-02-27 01:14:36 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 1.6802
2022-02-27 01:15:08 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 1.6279
2022-02-27 01:15:42 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 1.7616
2022-02-27 01:16:15 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 2.0636
2022-02-27 01:16:49 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 1.8412
2022-02-27 01:17:21 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 1.9459
2022-02-27 01:17:55 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 1.8217
2022-02-27 01:18:28 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 1.7420
2022-02-27 01:19:01 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 1.8287
2022-02-27 01:19:34 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 1.7184
2022-02-27 01:20:07 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 1.7058
2022-02-27 01:20:41 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 1.7427
2022-02-27 01:21:16 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 1.8577
2022-02-27 01:21:49 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 1.8697
2022-02-27 01:22:23 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 1.6380
2022-02-27 01:22:57 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 1.9752
2022-02-27 01:23:30 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 1.7906
2022-02-27 01:24:04 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 2.0547
2022-02-27 01:24:38 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 1.7279
2022-02-27 01:25:12 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 1.7572
2022-02-27 01:25:46 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 1.8795
2022-02-27 01:26:19 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 1.6608
2022-02-27 01:26:53 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 1.9634
2022-02-27 01:27:27 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 1.8851
2022-02-27 01:28:01 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 1.6433
2022-02-27 01:28:38 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 1.9217
2022-02-27 01:29:14 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 1.8229
2022-02-27 01:29:50 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 1.8786
2022-02-27 01:30:27 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 1.6499
2022-02-27 01:30:29 - train: epoch 081, train_loss: 1.7996
2022-02-27 01:31:49 - eval: epoch: 081, acc1: 63.748%, acc5: 85.186%, test_loss: 1.5270, per_image_load_time: 2.921ms, per_image_inference_time: 0.137ms
2022-02-27 01:31:49 - until epoch: 081, best_acc1: 63.802%
2022-02-27 01:31:49 - epoch 082 lr: 0.0010000000000000002
2022-02-27 01:32:29 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 1.5910
2022-02-27 01:33:03 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 1.7231
2022-02-27 01:33:35 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 1.7070
2022-02-27 01:34:09 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 1.8642
2022-02-27 01:34:43 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 1.9216
2022-02-27 01:35:17 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 1.7130
2022-02-27 01:35:50 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 1.9847
2022-02-27 01:36:25 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 1.7889
2022-02-27 01:36:57 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 1.8073
2022-02-27 01:37:32 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 1.7137
2022-02-27 01:38:05 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 1.8361
2022-02-27 01:38:40 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 1.8487
2022-02-27 01:39:13 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 1.8835
2022-02-27 01:39:47 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 1.5737
2022-02-27 01:40:21 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 1.7333
2022-02-27 01:40:55 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 1.8619
2022-02-27 01:41:29 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 1.7745
2022-02-27 01:42:03 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 1.4907
2022-02-27 01:42:39 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 1.7244
2022-02-27 01:43:12 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 1.6894
2022-02-27 01:43:46 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 1.7556
2022-02-27 01:44:19 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 1.9470
2022-02-27 01:44:53 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 1.8256
2022-02-27 01:45:26 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 2.0741
2022-02-27 01:46:00 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 1.8254
2022-02-27 01:46:32 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 1.8029
2022-02-27 01:47:05 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 1.6869
2022-02-27 01:47:40 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 1.5704
2022-02-27 01:48:13 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 1.5196
2022-02-27 01:48:48 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 1.7390
2022-02-27 01:49:20 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 1.6907
2022-02-27 01:49:53 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 1.6846
2022-02-27 01:50:26 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 1.7442
2022-02-27 01:51:01 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 1.7675
2022-02-27 01:51:33 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 1.6864
2022-02-27 01:52:06 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 1.7510
2022-02-27 01:52:38 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 1.6093
2022-02-27 01:53:11 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 1.9501
2022-02-27 01:53:46 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 1.8263
2022-02-27 01:54:18 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 1.8578
2022-02-27 01:54:52 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 1.9164
2022-02-27 01:55:25 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 1.7713
2022-02-27 01:56:00 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 1.6792
2022-02-27 01:56:33 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 1.7900
2022-02-27 01:57:08 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 1.6820
2022-02-27 01:57:42 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 1.8417
2022-02-27 01:58:20 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 1.6578
2022-02-27 01:58:53 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 1.6990
2022-02-27 01:59:30 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 1.8263
2022-02-27 02:00:06 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 1.7426
2022-02-27 02:00:08 - train: epoch 082, train_loss: 1.7988
2022-02-27 02:01:25 - eval: epoch: 082, acc1: 63.734%, acc5: 85.204%, test_loss: 1.5262, per_image_load_time: 2.136ms, per_image_inference_time: 0.134ms
2022-02-27 02:01:25 - until epoch: 082, best_acc1: 63.802%
2022-02-27 02:01:25 - epoch 083 lr: 0.0010000000000000002
2022-02-27 02:02:04 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 1.5948
2022-02-27 02:02:37 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 1.7588
2022-02-27 02:03:11 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 1.7674
2022-02-27 02:03:44 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 1.8354
2022-02-27 02:04:19 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 1.8069
2022-02-27 02:04:50 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 1.7037
2022-02-27 02:05:25 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 1.7743
2022-02-27 02:05:58 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 1.8547
2022-02-27 02:06:32 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 1.6493
2022-02-27 02:07:04 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 2.0008
2022-02-27 02:07:39 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 1.9075
2022-02-27 02:08:11 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 1.8068
2022-02-27 02:08:44 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 1.6585
2022-02-27 02:09:19 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 1.9735
2022-02-27 02:09:51 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 1.7655
2022-02-27 02:10:26 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 1.7465
2022-02-27 02:10:59 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 1.7762
2022-02-27 02:11:32 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 1.9823
2022-02-27 02:12:06 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 1.7840
2022-02-27 02:12:39 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 1.4299
2022-02-27 02:13:14 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 1.7278
2022-02-27 02:13:46 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 1.6623
2022-02-27 02:14:19 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 1.7163
2022-02-27 02:14:52 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 1.6845
2022-02-27 02:15:26 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 1.6803
2022-02-27 02:15:58 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 1.7697
2022-02-27 02:16:32 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 1.6979
2022-02-27 02:17:05 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 1.6632
2022-02-27 02:17:39 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 1.9468
2022-02-27 02:18:11 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 1.8136
2022-02-27 02:18:45 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 1.6071
2022-02-27 02:19:17 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 1.7311
2022-02-27 02:19:50 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 1.7240
2022-02-27 02:20:23 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 1.5872
2022-02-27 02:20:57 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 1.8551
2022-02-27 02:21:30 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 1.6887
2022-02-27 02:22:03 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 1.6540
2022-02-27 02:22:36 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 1.8487
2022-02-27 02:23:11 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 1.9647
2022-02-27 02:23:43 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 1.9032
2022-02-27 02:24:17 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 1.8108
2022-02-27 02:24:50 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 2.0235
2022-02-27 02:25:23 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 1.8391
2022-02-27 02:25:56 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 1.8977
2022-02-27 02:26:30 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 1.7863
2022-02-27 02:27:02 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 1.7666
2022-02-27 02:27:36 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 1.9549
2022-02-27 02:28:10 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 2.0281
2022-02-27 02:28:43 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 1.8131
2022-02-27 02:29:16 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 1.7413
2022-02-27 02:29:18 - train: epoch 083, train_loss: 1.7966
2022-02-27 02:30:34 - eval: epoch: 083, acc1: 63.766%, acc5: 85.258%, test_loss: 1.5285, per_image_load_time: 2.766ms, per_image_inference_time: 0.130ms
2022-02-27 02:30:34 - until epoch: 083, best_acc1: 63.802%
2022-02-27 02:30:34 - epoch 084 lr: 0.0010000000000000002
2022-02-27 02:31:12 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 1.7126
2022-02-27 02:31:46 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 1.7257
2022-02-27 02:32:19 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 1.6544
2022-02-27 02:32:52 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 1.7288
2022-02-27 02:33:25 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 1.9612
2022-02-27 02:33:58 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 2.1395
2022-02-27 02:34:32 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 1.9115
2022-02-27 02:35:04 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 1.8341
2022-02-27 02:35:39 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 1.9265
2022-02-27 02:36:11 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 1.8144
2022-02-27 02:36:45 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 1.7614
2022-02-27 02:37:18 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 1.9982
2022-02-27 02:37:52 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 1.9984
2022-02-27 02:38:24 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 1.8141
2022-02-27 02:38:58 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 1.9149
2022-02-27 02:39:31 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 1.7014
2022-02-27 02:40:05 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 2.0461
2022-02-27 02:40:38 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 2.0156
2022-02-27 02:41:12 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 1.8182
2022-02-27 02:41:44 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 1.6737
2022-02-27 02:42:18 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 1.6992
2022-02-27 02:42:51 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 1.7564
2022-02-27 02:43:24 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 1.8973
2022-02-27 02:43:57 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 1.6632
2022-02-27 02:44:32 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 2.1263
2022-02-27 02:45:04 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 1.7048
2022-02-27 02:45:38 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 1.7497
2022-02-27 02:46:11 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 1.7712
2022-02-27 02:46:45 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 1.7908
2022-02-27 02:47:18 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 1.8229
2022-02-27 02:47:52 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 1.8361
2022-02-27 02:48:25 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 1.7566
2022-02-27 02:48:59 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 1.8959
2022-02-27 02:49:32 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 1.8790
2022-02-27 02:50:06 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 1.6529
2022-02-27 02:50:39 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 1.7442
2022-02-27 02:51:13 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 1.8756
2022-02-27 02:51:46 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 1.8889
2022-02-27 02:52:20 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 1.8763
2022-02-27 02:52:53 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 1.8109
2022-02-27 02:53:27 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 1.6834
2022-02-27 02:54:00 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 2.0358
2022-02-27 02:54:34 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 1.7000
2022-02-27 02:55:06 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 1.9320
2022-02-27 02:55:40 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 1.6909
2022-02-27 02:56:13 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 1.6887
2022-02-27 02:56:48 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 1.6657
2022-02-27 02:57:22 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 1.5915
2022-02-27 02:57:55 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 1.6238
2022-02-27 02:58:28 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 1.8021
2022-02-27 02:58:30 - train: epoch 084, train_loss: 1.7962
2022-02-27 02:59:46 - eval: epoch: 084, acc1: 63.814%, acc5: 85.200%, test_loss: 1.5289, per_image_load_time: 2.761ms, per_image_inference_time: 0.141ms
2022-02-27 02:59:46 - until epoch: 084, best_acc1: 63.814%
2022-02-27 02:59:46 - epoch 085 lr: 0.0010000000000000002
2022-02-27 03:00:25 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 1.6373
2022-02-27 03:00:58 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 1.8903
2022-02-27 03:01:32 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 1.9604
2022-02-27 03:02:04 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 1.7934
2022-02-27 03:02:37 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 1.7968
2022-02-27 03:03:10 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 1.6457
2022-02-27 03:03:43 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 1.8661
2022-02-27 03:04:17 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 1.7610
2022-02-27 03:04:49 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 1.5564
2022-02-27 03:05:24 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 1.7026
2022-02-27 03:05:55 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 1.7986
2022-02-27 03:06:28 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 1.6687
2022-02-27 03:07:03 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 1.9653
2022-02-27 03:07:36 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 1.8580
2022-02-27 03:08:09 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 1.7973
2022-02-27 03:08:43 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 1.7346
2022-02-27 03:09:17 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 1.9085
2022-02-27 03:09:49 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 1.5066
2022-02-27 03:10:23 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 1.6929
2022-02-27 03:10:55 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 1.7392
2022-02-27 03:11:28 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 1.8272
2022-02-27 03:12:01 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 1.9316
2022-02-27 03:12:35 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 1.5607
2022-02-27 03:13:07 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 1.8067
2022-02-27 03:13:42 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 2.0226
2022-02-27 03:14:14 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 1.8385
2022-02-27 03:14:48 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 1.8331
2022-02-27 03:15:20 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 1.9618
2022-02-27 03:15:54 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 1.9695
2022-02-27 03:16:27 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 2.0673
2022-02-27 03:17:00 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 1.9265
2022-02-27 03:17:34 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 1.8896
2022-02-27 03:18:07 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 1.7134
2022-02-27 03:18:40 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 1.8504
2022-02-27 03:19:14 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 1.8231
2022-02-27 03:19:46 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 1.9288
2022-02-27 03:20:19 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 1.4526
2022-02-27 03:20:53 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 1.8861
2022-02-27 03:21:27 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 1.8079
2022-02-27 03:21:59 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 2.1308
2022-02-27 03:22:34 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 1.8315
2022-02-27 03:23:06 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 1.9396
2022-02-27 03:23:40 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 1.8124
2022-02-27 03:24:13 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 1.8017
2022-02-27 03:24:47 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 1.9226
2022-02-27 03:25:19 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 2.0041
2022-02-27 03:25:54 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 2.0717
2022-02-27 03:26:26 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 1.6797
2022-02-27 03:27:01 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 1.8916
2022-02-27 03:27:33 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 1.7024
2022-02-27 03:27:35 - train: epoch 085, train_loss: 1.7943
2022-02-27 03:28:51 - eval: epoch: 085, acc1: 63.634%, acc5: 85.226%, test_loss: 1.5279, per_image_load_time: 2.666ms, per_image_inference_time: 0.138ms
2022-02-27 03:28:51 - until epoch: 085, best_acc1: 63.814%
2022-02-27 03:28:51 - epoch 086 lr: 0.0010000000000000002
2022-02-27 03:29:29 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 1.7886
2022-02-27 03:30:02 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 1.6211
2022-02-27 03:30:36 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 2.0886
2022-02-27 03:31:08 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 1.8420
2022-02-27 03:31:41 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 2.1176
2022-02-27 03:32:15 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 1.9142
2022-02-27 03:32:47 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 1.8846
2022-02-27 03:33:21 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 1.8167
2022-02-27 03:33:53 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 1.7820
2022-02-27 03:34:27 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 1.9268
2022-02-27 03:34:59 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 1.7669
2022-02-27 03:35:33 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 1.8558
2022-02-27 03:36:06 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 1.8865
2022-02-27 03:36:40 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 1.8345
2022-02-27 03:37:12 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 1.5786
2022-02-27 03:37:46 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 1.8939
2022-02-27 03:38:19 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 1.7168
2022-02-27 03:38:52 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 1.8384
2022-02-27 03:39:25 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 1.8364
2022-02-27 03:39:59 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 1.9192
2022-02-27 03:40:32 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 1.5378
2022-02-27 03:41:05 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 1.8212
2022-02-27 03:41:38 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 1.8231
2022-02-27 03:42:13 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 1.6813
2022-02-27 03:42:45 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 1.8154
2022-02-27 03:43:19 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 1.8072
2022-02-27 03:43:52 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 1.7703
2022-02-27 03:44:26 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 1.8981
2022-02-27 03:44:59 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 1.7534
2022-02-27 03:45:33 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 1.7542
2022-02-27 03:46:05 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 1.9175
2022-02-27 03:46:40 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 2.0045
2022-02-27 03:47:12 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 1.9582
2022-02-27 03:47:46 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 1.9271
2022-02-27 03:48:19 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 1.8436
2022-02-27 03:48:53 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 1.7409
2022-02-27 03:49:26 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 1.9512
2022-02-27 03:49:59 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 1.7380
2022-02-27 03:50:33 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 1.7768
2022-02-27 03:51:07 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 1.7648
2022-02-27 03:51:39 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 1.6484
2022-02-27 03:52:13 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 1.7814
2022-02-27 03:52:47 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 1.9204
2022-02-27 03:53:21 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 1.8052
2022-02-27 03:53:54 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 1.7058
2022-02-27 03:54:27 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 1.7027
2022-02-27 03:55:01 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 1.7142
2022-02-27 03:55:34 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 1.8368
2022-02-27 03:56:08 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 1.8514
2022-02-27 03:56:41 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 1.7289
2022-02-27 03:56:43 - train: epoch 086, train_loss: 1.7941
2022-02-27 03:57:59 - eval: epoch: 086, acc1: 63.658%, acc5: 85.142%, test_loss: 1.5315, per_image_load_time: 2.477ms, per_image_inference_time: 0.156ms
2022-02-27 03:57:59 - until epoch: 086, best_acc1: 63.814%
2022-02-27 03:57:59 - epoch 087 lr: 0.0010000000000000002
2022-02-27 03:58:37 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 1.9365
2022-02-27 03:59:09 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 1.7313
2022-02-27 03:59:44 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 1.8596
2022-02-27 04:00:16 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 1.8964
2022-02-27 04:00:51 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 1.7801
2022-02-27 04:01:22 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 2.0439
2022-02-27 04:01:56 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 1.6222
2022-02-27 04:02:29 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 1.7047
2022-02-27 04:03:03 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 1.8025
2022-02-27 04:03:35 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 1.7779
2022-02-27 04:04:09 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 1.9026
2022-02-27 04:04:41 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 1.7178
2022-02-27 04:05:15 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 2.0784
2022-02-27 04:05:47 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 1.4611
2022-02-27 04:06:21 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 1.6099
2022-02-27 04:06:54 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 1.6330
2022-02-27 04:07:28 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 1.9329
2022-02-27 04:08:01 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 1.8411
2022-02-27 04:08:34 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 1.9304
2022-02-27 04:09:07 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 1.6919
2022-02-27 04:09:41 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 1.8743
2022-02-27 04:10:14 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 1.8755
2022-02-27 04:10:48 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 1.8892
2022-02-27 04:11:20 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 1.7345
2022-02-27 04:11:54 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 1.8067
2022-02-27 04:12:27 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 1.8338
2022-02-27 04:13:01 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 1.7547
2022-02-27 04:13:34 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 1.6246
2022-02-27 04:14:08 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 1.6926
2022-02-27 04:14:40 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 1.9223
2022-02-27 04:15:14 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 1.7386
2022-02-27 04:15:47 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 1.8405
2022-02-27 04:16:21 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 1.7750
2022-02-27 04:16:53 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 1.6940
2022-02-27 04:17:27 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 1.5738
2022-02-27 04:17:59 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 1.5602
2022-02-27 04:18:33 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 1.6673
2022-02-27 04:19:06 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 1.8023
2022-02-27 04:19:40 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 1.8895
2022-02-27 04:20:12 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 1.7253
2022-02-27 04:20:47 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 1.9883
2022-02-27 04:21:19 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 1.8119
2022-02-27 04:21:54 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 1.6409
2022-02-27 04:22:26 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 1.8770
2022-02-27 04:23:01 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 1.6660
2022-02-27 04:23:33 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 1.7017
2022-02-27 04:24:07 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 1.8459
2022-02-27 04:24:40 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 1.8108
2022-02-27 04:25:15 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 1.6962
2022-02-27 04:25:46 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 1.8600
2022-02-27 04:25:49 - train: epoch 087, train_loss: 1.7921
2022-02-27 04:27:05 - eval: epoch: 087, acc1: 63.580%, acc5: 85.186%, test_loss: 1.5258, per_image_load_time: 2.772ms, per_image_inference_time: 0.135ms
2022-02-27 04:27:05 - until epoch: 087, best_acc1: 63.814%
2022-02-27 04:27:05 - epoch 088 lr: 0.0010000000000000002
2022-02-27 04:27:44 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 1.6175
2022-02-27 04:28:18 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 1.8581
2022-02-27 04:28:49 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 2.0273
2022-02-27 04:29:23 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 1.9995
2022-02-27 04:29:55 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 1.7083
2022-02-27 04:30:30 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 1.9003
2022-02-27 04:31:02 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 1.7058
2022-02-27 04:31:36 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 1.7394
2022-02-27 04:32:08 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 1.7394
2022-02-27 04:32:42 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 1.6891
2022-02-27 04:33:14 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 1.8616
2022-02-27 04:33:49 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 1.9016
2022-02-27 04:34:21 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 1.9500
2022-02-27 04:34:54 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 1.7490
2022-02-27 04:35:27 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 1.7973
2022-02-27 04:36:01 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 1.6830
2022-02-27 04:36:34 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 1.8105
2022-02-27 04:37:07 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 1.6719
2022-02-27 04:37:41 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 1.6958
2022-02-27 04:38:13 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 1.7581
2022-02-27 04:38:47 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 1.9953
2022-02-27 04:39:19 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 1.8834
2022-02-27 04:39:53 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 1.7651
2022-02-27 04:40:24 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 1.9458
2022-02-27 04:40:59 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 1.9229
2022-02-27 04:41:32 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 2.0123
2022-02-27 04:42:05 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 1.8189
2022-02-27 04:42:39 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 1.8039
2022-02-27 04:43:11 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 1.6703
2022-02-27 04:43:45 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 1.8775
2022-02-27 04:44:17 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 1.6575
2022-02-27 04:44:50 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 1.8844
2022-02-27 04:45:24 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 1.5874
2022-02-27 04:45:57 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 1.7571
2022-02-27 04:46:31 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 1.7272
2022-02-27 04:47:04 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 1.6546
2022-02-27 04:47:38 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 1.9271
2022-02-27 04:48:10 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 1.9468
2022-02-27 04:48:45 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 1.7570
2022-02-27 04:49:17 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 1.4482
2022-02-27 04:49:51 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 1.8647
2022-02-27 04:50:24 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 1.6974
2022-02-27 04:50:59 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 1.8268
2022-02-27 04:51:31 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 1.6114
2022-02-27 04:52:04 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 1.7866
2022-02-27 04:52:37 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 2.0344
2022-02-27 04:53:11 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 1.8987
2022-02-27 04:53:45 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 1.7754
2022-02-27 04:54:19 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 1.5867
2022-02-27 04:54:50 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 1.7977
2022-02-27 04:54:53 - train: epoch 088, train_loss: 1.7907
2022-02-27 04:56:09 - eval: epoch: 088, acc1: 63.856%, acc5: 85.274%, test_loss: 1.5201, per_image_load_time: 1.340ms, per_image_inference_time: 0.128ms
2022-02-27 04:56:09 - until epoch: 088, best_acc1: 63.856%
2022-02-27 04:56:09 - epoch 089 lr: 0.0010000000000000002
2022-02-27 04:56:47 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 2.0453
2022-02-27 04:57:21 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 1.6136
2022-02-27 04:57:54 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 1.8295
2022-02-27 04:58:27 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 1.7566
2022-02-27 04:58:59 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 1.7917
2022-02-27 04:59:33 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 1.6896
2022-02-27 05:00:07 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 2.1797
2022-02-27 05:00:39 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 2.1317
2022-02-27 05:01:12 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 1.7121
2022-02-27 05:01:46 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 2.0349
2022-02-27 05:02:19 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 1.6860
2022-02-27 05:02:52 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 1.9639
2022-02-27 05:03:25 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 1.8223
2022-02-27 05:03:59 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 2.0172
2022-02-27 05:04:31 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 1.9046
2022-02-27 05:05:05 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 1.7586
2022-02-27 05:05:39 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 1.9418
2022-02-27 05:06:12 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 1.7777
2022-02-27 05:06:45 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 1.7152
2022-02-27 05:07:20 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 1.7755
2022-02-27 05:07:52 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 1.7843
2022-02-27 05:08:26 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 1.6872
2022-02-27 05:08:59 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 1.8234
2022-02-27 05:09:33 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 1.8477
2022-02-27 05:10:05 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 1.9661
2022-02-27 05:10:39 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 1.6532
2022-02-27 05:11:12 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 1.7870
2022-02-27 05:11:45 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 1.9925
2022-02-27 05:12:18 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 1.7544
2022-02-27 05:12:51 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 1.7857
2022-02-27 05:13:23 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 1.9052
2022-02-27 05:13:57 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 2.0850
2022-02-27 05:14:31 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 1.9913
2022-02-27 05:15:03 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 1.7226
2022-02-27 05:15:37 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 1.6041
2022-02-27 05:16:10 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 1.7027
2022-02-27 05:16:44 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 2.0088
2022-02-27 05:17:17 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 1.8014
2022-02-27 05:17:51 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 1.9886
2022-02-27 05:18:24 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 1.8285
2022-02-27 05:18:57 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 1.8851
2022-02-27 05:19:30 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 1.6616
2022-02-27 05:20:04 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 1.7518
2022-02-27 05:20:38 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 1.8310
2022-02-27 05:21:11 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 1.5516
2022-02-27 05:21:44 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 1.7147
2022-02-27 05:22:19 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 1.7244
2022-02-27 05:22:52 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 1.5742
2022-02-27 05:23:25 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 1.7697
2022-02-27 05:23:58 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 1.4156
2022-02-27 05:24:00 - train: epoch 089, train_loss: 1.7917
2022-02-27 05:25:16 - eval: epoch: 089, acc1: 63.722%, acc5: 85.136%, test_loss: 1.5275, per_image_load_time: 1.385ms, per_image_inference_time: 0.138ms
2022-02-27 05:25:16 - until epoch: 089, best_acc1: 63.856%
2022-02-27 05:25:16 - epoch 090 lr: 0.0010000000000000002
2022-02-27 05:25:54 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 1.7678
2022-02-27 05:26:27 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 1.7630
2022-02-27 05:27:01 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 1.8366
2022-02-27 05:27:34 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 1.6033
2022-02-27 05:28:08 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 1.7392
2022-02-27 05:28:40 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 1.9557
2022-02-27 05:29:13 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 1.8402
2022-02-27 05:29:47 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 1.9081
2022-02-27 05:30:20 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 1.6386
2022-02-27 05:30:53 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 1.6066
2022-02-27 05:31:27 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 1.7420
2022-02-27 05:31:59 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 1.7511
2022-02-27 05:32:33 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 1.7382
2022-02-27 05:33:06 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 1.7454
2022-02-27 05:33:39 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 1.9745
2022-02-27 05:34:13 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 1.9069
2022-02-27 05:34:46 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 1.5825
2022-02-27 05:35:20 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 1.6373
2022-02-27 05:35:53 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 1.7513
2022-02-27 05:36:27 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 1.7729
2022-02-27 05:37:00 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 2.0080
2022-02-27 05:37:34 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 2.0117
2022-02-27 05:38:07 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 2.0510
2022-02-27 05:38:40 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 1.8119
2022-02-27 05:39:14 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 1.8529
2022-02-27 05:39:47 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 1.6056
2022-02-27 05:40:20 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 1.5463
2022-02-27 05:40:53 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 1.8462
2022-02-27 05:41:27 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 1.5824
2022-02-27 05:41:59 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 1.8550
2022-02-27 05:42:34 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 1.6123
2022-02-27 05:43:06 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 1.7871
2022-02-27 05:43:40 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 2.1349
2022-02-27 05:44:13 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 1.7000
2022-02-27 05:44:45 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 1.7778
2022-02-27 05:45:19 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 1.7220
2022-02-27 05:45:52 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 1.9539
2022-02-27 05:46:25 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 1.7928
2022-02-27 05:46:59 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 1.6537
2022-02-27 05:47:32 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 1.8509
2022-02-27 05:48:05 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 2.0405
2022-02-27 05:48:40 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 1.9600
2022-02-27 05:49:12 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 1.7193
2022-02-27 05:49:46 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 1.6669
2022-02-27 05:50:19 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 1.6971
2022-02-27 05:50:53 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 1.7483
2022-02-27 05:51:26 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 1.6574
2022-02-27 05:51:59 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 2.0834
2022-02-27 05:52:33 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 1.6753
2022-02-27 05:53:06 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 1.5943
2022-02-27 05:53:09 - train: epoch 090, train_loss: 1.7891
2022-02-27 05:54:25 - eval: epoch: 090, acc1: 63.712%, acc5: 85.328%, test_loss: 1.5232, per_image_load_time: 1.327ms, per_image_inference_time: 0.155ms
2022-02-27 05:54:25 - until epoch: 090, best_acc1: 63.856%
2022-02-27 05:54:25 - epoch 091 lr: 0.00010000000000000003
2022-02-27 05:55:04 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 1.5881
2022-02-27 05:55:38 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 1.7655
2022-02-27 05:56:10 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 1.7912
2022-02-27 05:56:42 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 1.7986
2022-02-27 05:57:16 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 1.7641
2022-02-27 05:57:48 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 2.0616
2022-02-27 05:58:22 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 1.9278
2022-02-27 05:58:55 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 1.5388
2022-02-27 05:59:29 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 1.8100
2022-02-27 06:00:01 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 1.5636
2022-02-27 06:00:35 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 1.4463
2022-02-27 06:01:08 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 1.8157
2022-02-27 06:01:42 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 1.8502
2022-02-27 06:02:15 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 1.7399
2022-02-27 06:02:49 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 1.7742
2022-02-27 06:03:22 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 1.6973
2022-02-27 06:03:55 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 1.7786
2022-02-27 06:04:28 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 1.7440
2022-02-27 06:05:02 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 1.8290
2022-02-27 06:05:35 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 1.7360
2022-02-27 06:06:09 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 1.6082
2022-02-27 06:06:43 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 1.7928
2022-02-27 06:07:15 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 1.7383
2022-02-27 06:07:49 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 1.7428
2022-02-27 06:08:22 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 1.7943
2022-02-27 06:08:55 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 1.7171
2022-02-27 06:09:28 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 1.7522
2022-02-27 06:10:03 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 1.8468
2022-02-27 06:10:34 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 1.7636
2022-02-27 06:11:08 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 1.8899
2022-02-27 06:11:42 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 1.7907
2022-02-27 06:12:14 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 1.9872
2022-02-27 06:12:48 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 1.6490
2022-02-27 06:13:21 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 1.8326
2022-02-27 06:13:55 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 1.8069
2022-02-27 06:14:28 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 1.8172
2022-02-27 06:15:03 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 1.8002
2022-02-27 06:15:36 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 1.8032
2022-02-27 06:16:10 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 1.5501
2022-02-27 06:16:43 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 1.5165
2022-02-27 06:17:16 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 1.8588
2022-02-27 06:17:48 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 1.7982
2022-02-27 06:18:22 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 1.7435
2022-02-27 06:18:56 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 1.5935
2022-02-27 06:19:29 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 1.7327
2022-02-27 06:20:03 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 1.7946
2022-02-27 06:20:36 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 1.8892
2022-02-27 06:21:10 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 1.7147
2022-02-27 06:21:44 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 1.7104
2022-02-27 06:22:16 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 2.0483
2022-02-27 06:22:18 - train: epoch 091, train_loss: 1.7632
2022-02-27 06:23:35 - eval: epoch: 091, acc1: 64.132%, acc5: 85.506%, test_loss: 1.5050, per_image_load_time: 1.924ms, per_image_inference_time: 0.141ms
2022-02-27 06:23:35 - until epoch: 091, best_acc1: 64.132%
2022-02-27 06:23:35 - epoch 092 lr: 0.00010000000000000003
2022-02-27 06:24:13 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 1.6375
2022-02-27 06:24:46 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 1.6815
2022-02-27 06:25:19 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 1.7951
2022-02-27 06:25:52 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 1.8797
2022-02-27 06:26:25 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 1.6277
2022-02-27 06:26:58 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 1.7000
2022-02-27 06:27:32 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 1.8034
2022-02-27 06:28:04 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 1.9626
2022-02-27 06:28:38 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 2.0492
2022-02-27 06:29:11 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 1.7312
2022-02-27 06:29:45 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 1.7388
2022-02-27 06:30:17 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 1.7185
2022-02-27 06:30:51 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 1.6014
2022-02-27 06:31:24 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 1.7077
2022-02-27 06:31:58 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 1.5724
2022-02-27 06:32:30 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 1.7546
2022-02-27 06:33:04 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 1.7782
2022-02-27 06:33:37 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 1.5941
2022-02-27 06:34:11 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 1.4750
2022-02-27 06:34:44 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 1.6068
2022-02-27 06:35:17 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 1.6723
2022-02-27 06:35:51 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 1.7870
2022-02-27 06:36:24 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 2.0155
2022-02-27 06:36:58 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 1.6999
2022-02-27 06:37:31 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 1.6496
2022-02-27 06:38:05 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 1.6820
2022-02-27 06:38:38 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 1.9691
2022-02-27 06:39:11 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 1.6099
2022-02-27 06:39:44 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 1.9173
2022-02-27 06:40:17 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 1.6953
2022-02-27 06:40:51 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 1.8177
2022-02-27 06:41:23 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 1.6254
2022-02-27 06:41:57 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 1.7294
2022-02-27 06:42:32 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 1.9138
2022-02-27 06:43:04 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 1.7799
2022-02-27 06:43:37 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 1.5440
2022-02-27 06:44:10 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 1.6460
2022-02-27 06:44:44 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 1.8310
2022-02-27 06:45:18 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 1.8468
2022-02-27 06:45:50 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 1.8904
2022-02-27 06:46:24 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 1.5535
2022-02-27 06:46:57 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 1.8296
2022-02-27 06:47:31 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 1.6463
2022-02-27 06:48:05 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 1.7552
2022-02-27 06:48:38 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 1.6398
2022-02-27 06:49:12 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 1.6645
2022-02-27 06:49:45 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 1.5842
2022-02-27 06:50:19 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 1.7194
2022-02-27 06:50:52 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 1.5499
2022-02-27 06:51:24 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 1.6981
2022-02-27 06:51:27 - train: epoch 092, train_loss: 1.7595
2022-02-27 06:52:43 - eval: epoch: 092, acc1: 64.250%, acc5: 85.518%, test_loss: 1.5039, per_image_load_time: 2.557ms, per_image_inference_time: 0.144ms
2022-02-27 06:52:43 - until epoch: 092, best_acc1: 64.250%
2022-02-27 06:52:43 - epoch 093 lr: 0.00010000000000000003
2022-02-27 06:53:22 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 1.6283
2022-02-27 06:53:54 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 1.6007
2022-02-27 06:54:28 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 1.7218
2022-02-27 06:55:00 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 1.9530
2022-02-27 06:55:33 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 1.7049
2022-02-27 06:56:05 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 1.7339
2022-02-27 06:56:38 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 1.8309
2022-02-27 06:57:11 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 1.6954
2022-02-27 06:57:44 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 1.7186
2022-02-27 06:58:18 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 1.7315
2022-02-27 06:58:51 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 1.7364
2022-02-27 06:59:25 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 1.8773
2022-02-27 06:59:57 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 1.7339
2022-02-27 07:00:31 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 1.5550
2022-02-27 07:01:03 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 1.9431
2022-02-27 07:01:37 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 1.7613
2022-02-27 07:02:10 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 1.8957
2022-02-27 07:02:44 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 1.9428
2022-02-27 07:03:17 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 1.5534
2022-02-27 07:03:49 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 1.6760
2022-02-27 07:04:23 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 1.7390
2022-02-27 07:04:56 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 1.9046
2022-02-27 07:05:30 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 1.7880
2022-02-27 07:06:03 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 1.6497
2022-02-27 07:06:36 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 1.7062
2022-02-27 07:07:10 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 1.9374
2022-02-27 07:07:43 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 1.8064
2022-02-27 07:08:17 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 1.4939
2022-02-27 07:08:49 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 1.4794
2022-02-27 07:09:23 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 1.5251
2022-02-27 07:09:56 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 2.0184
2022-02-27 07:10:30 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 1.7444
2022-02-27 07:11:03 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 1.7707
2022-02-27 07:11:37 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 1.9210
2022-02-27 07:12:10 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 1.7609
2022-02-27 07:12:43 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 1.7317
2022-02-27 07:13:16 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 1.6946
2022-02-27 07:13:49 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 1.6500
2022-02-27 07:14:23 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 1.8615
2022-02-27 07:14:56 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 1.9927
2022-02-27 07:15:29 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 1.8514
2022-02-27 07:16:03 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 1.7515
2022-02-27 07:16:35 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 1.7443
2022-02-27 07:17:10 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 1.7308
2022-02-27 07:17:42 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 1.7626
2022-02-27 07:18:16 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 1.5280
2022-02-27 07:18:51 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 2.1838
2022-02-27 07:19:24 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 1.7097
2022-02-27 07:19:58 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 1.6675
2022-02-27 07:20:30 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 1.6562
2022-02-27 07:20:32 - train: epoch 093, train_loss: 1.7540
2022-02-27 07:21:49 - eval: epoch: 093, acc1: 64.334%, acc5: 85.538%, test_loss: 1.5035, per_image_load_time: 2.767ms, per_image_inference_time: 0.147ms
2022-02-27 07:21:49 - until epoch: 093, best_acc1: 64.334%
2022-02-27 07:21:49 - epoch 094 lr: 0.00010000000000000003
2022-02-27 07:22:28 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 1.5559
2022-02-27 07:23:02 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 1.7787
2022-02-27 07:23:34 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 2.0142
2022-02-27 07:24:08 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 1.7795
2022-02-27 07:24:40 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 1.5741
2022-02-27 07:25:12 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 1.6215
2022-02-27 07:25:45 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 1.9271
2022-02-27 07:26:18 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 1.7608
2022-02-27 07:26:51 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 1.5810
2022-02-27 07:27:24 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 1.5168
2022-02-27 07:27:58 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 1.8639
2022-02-27 07:28:31 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 1.7365
2022-02-27 07:29:05 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 1.7139
2022-02-27 07:29:38 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 1.6668
2022-02-27 07:30:12 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 1.7809
2022-02-27 07:30:45 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 1.8834
2022-02-27 07:31:19 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 1.6472
2022-02-27 07:31:51 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 1.6593
2022-02-27 07:32:26 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 1.6749
2022-02-27 07:32:58 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 1.6593
2022-02-27 07:33:32 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 1.7448
2022-02-27 07:34:05 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 1.6854
2022-02-27 07:34:40 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 1.7897
2022-02-27 07:35:13 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 1.6016
2022-02-27 07:35:46 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 1.7497
2022-02-27 07:36:20 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 1.5783
2022-02-27 07:36:53 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 1.7155
2022-02-27 07:37:27 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 1.9940
2022-02-27 07:38:00 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 1.6343
2022-02-27 07:38:34 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 1.9046
2022-02-27 07:39:07 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 1.9146
2022-02-27 07:39:40 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 1.8767
2022-02-27 07:40:14 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 1.7904
2022-02-27 07:40:47 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 1.7221
2022-02-27 07:41:22 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 2.0721
2022-02-27 07:41:55 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 1.6186
2022-02-27 07:42:29 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 1.9414
2022-02-27 07:43:01 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 1.5266
2022-02-27 07:43:36 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 1.7978
2022-02-27 07:44:08 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 1.6850
2022-02-27 07:44:41 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 1.9335
2022-02-27 07:45:14 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 1.8784
2022-02-27 07:45:49 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 1.7452
2022-02-27 07:46:22 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 1.8656
2022-02-27 07:46:57 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 1.7633
2022-02-27 07:47:29 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 1.8599
2022-02-27 07:48:04 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 1.7938
2022-02-27 07:48:37 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 1.5788
2022-02-27 07:49:12 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 1.8289
2022-02-27 07:49:43 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 1.5974
2022-02-27 07:49:45 - train: epoch 094, train_loss: 1.7550
2022-02-27 07:51:02 - eval: epoch: 094, acc1: 64.296%, acc5: 85.554%, test_loss: 1.5014, per_image_load_time: 2.751ms, per_image_inference_time: 0.131ms
2022-02-27 07:51:02 - until epoch: 094, best_acc1: 64.334%
2022-02-27 07:51:02 - epoch 095 lr: 0.00010000000000000003
2022-02-27 07:51:40 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 2.0570
2022-02-27 07:52:13 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 1.8808
2022-02-27 07:52:46 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 1.8579
2022-02-27 07:53:19 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 1.7967
2022-02-27 07:53:53 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 1.6597
2022-02-27 07:54:26 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 1.5547
2022-02-27 07:54:58 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 1.9147
2022-02-27 07:55:33 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 1.7851
2022-02-27 07:56:05 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 1.9356
2022-02-27 07:56:39 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 1.8944
2022-02-27 07:57:11 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 1.8056
2022-02-27 07:57:46 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 1.5832
2022-02-27 07:58:18 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 1.5670
2022-02-27 07:58:52 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 1.5535
2022-02-27 07:59:24 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 1.7251
2022-02-27 07:59:57 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 1.4314
2022-02-27 08:00:31 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 1.8129
2022-02-27 08:01:04 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 1.9681
2022-02-27 08:01:37 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 1.8059
2022-02-27 08:02:11 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 1.6150
2022-02-27 08:02:44 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 1.8141
2022-02-27 08:03:18 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 1.5826
2022-02-27 08:03:50 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 1.7754
2022-02-27 08:04:24 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 1.7450
2022-02-27 08:04:57 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 1.5582
2022-02-27 08:05:31 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 1.7880
2022-02-27 08:06:04 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 1.8235
2022-02-27 08:06:38 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 1.7017
2022-02-27 08:07:11 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 1.8999
2022-02-27 08:07:45 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 2.0011
2022-02-27 08:08:18 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 1.8055
2022-02-27 08:08:52 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 1.8234
2022-02-27 08:09:25 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 1.7348
2022-02-27 08:09:58 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 1.4306
2022-02-27 08:10:31 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 1.7972
2022-02-27 08:11:04 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 1.6332
2022-02-27 08:11:38 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 1.7464
2022-02-27 08:12:11 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 1.6806
2022-02-27 08:12:45 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 1.9010
2022-02-27 08:13:18 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 1.6006
2022-02-27 08:13:52 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 1.6572
2022-02-27 08:14:24 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 1.8041
2022-02-27 08:14:58 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 1.8174
2022-02-27 08:15:31 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 2.0491
2022-02-27 08:16:06 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 1.6786
2022-02-27 08:16:38 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 1.6669
2022-02-27 08:17:13 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 1.7389
2022-02-27 08:17:46 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 1.5881
2022-02-27 08:18:20 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 1.6597
2022-02-27 08:18:53 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 1.6280
2022-02-27 08:18:56 - train: epoch 095, train_loss: 1.7540
2022-02-27 08:20:12 - eval: epoch: 095, acc1: 64.196%, acc5: 85.592%, test_loss: 1.5018, per_image_load_time: 2.789ms, per_image_inference_time: 0.132ms
2022-02-27 08:20:12 - until epoch: 095, best_acc1: 64.334%
2022-02-27 09:09:17 - epoch 096 lr: 0.00010000000000000003
2022-02-27 09:09:55 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 1.6773
2022-02-27 09:10:27 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 1.7171
2022-02-27 09:11:00 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 1.7147
2022-02-27 09:11:33 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 1.5857
2022-02-27 09:12:06 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 1.7646
2022-02-27 09:12:39 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 1.8073
2022-02-27 09:13:11 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 1.6746
2022-02-27 09:13:45 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 1.6299
2022-02-27 09:14:17 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 1.7474
2022-02-27 09:14:52 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 1.8613
2022-02-27 09:15:24 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 1.8192
2022-02-27 09:15:59 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 1.6734
2022-02-27 09:16:31 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 1.7790
2022-02-27 09:17:05 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 1.8585
2022-02-27 09:17:38 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 1.8315
2022-02-27 09:18:13 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 1.4000
2022-02-27 09:18:46 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 1.6815
2022-02-27 09:19:20 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 1.9685
2022-02-27 09:19:52 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 1.7385
2022-02-27 09:20:26 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 1.7347
2022-02-27 09:20:58 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 1.6871
2022-02-27 09:21:32 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 1.3329
2022-02-27 09:22:05 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 1.7242
2022-02-27 09:22:43 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 1.8022
2022-02-27 09:23:15 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 1.6480
2022-02-27 09:23:49 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 1.7575
2022-02-27 09:24:21 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 2.0005
2022-02-27 09:24:54 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 1.8499
2022-02-27 09:25:27 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 1.6618
2022-02-27 09:26:01 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 1.8037
2022-02-27 09:26:34 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 1.8396
2022-02-27 09:27:08 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 1.7691
2022-02-27 09:27:41 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 1.7977
2022-02-27 09:28:15 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 1.6381
2022-02-27 09:28:47 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 1.7402
2022-02-27 09:29:21 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 1.5868
2022-02-27 09:29:53 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 1.7491
2022-02-27 09:30:27 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 1.6119
2022-02-27 09:30:59 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 1.6653
2022-02-27 09:31:34 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 1.8211
2022-02-27 09:32:06 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 1.8872
2022-02-27 09:32:40 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 1.8563
2022-02-27 09:33:13 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 1.5897
2022-02-27 09:33:47 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 1.6793
2022-02-27 09:34:22 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 1.8982
2022-02-27 09:34:54 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 1.7182
2022-02-27 09:35:29 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 2.0041
2022-02-27 09:36:02 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 1.8199
2022-02-27 09:36:38 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 1.9322
2022-02-27 09:37:10 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 1.8936
2022-02-27 09:37:11 - train: epoch 096, train_loss: 1.7536
2022-02-27 09:38:26 - eval: epoch: 096, acc1: 64.278%, acc5: 85.554%, test_loss: 1.4999, per_image_load_time: 2.456ms, per_image_inference_time: 0.136ms
2022-02-27 09:38:26 - until epoch: 096, best_acc1: 64.334%
2022-02-27 09:38:26 - epoch 097 lr: 0.00010000000000000003
2022-02-27 09:39:04 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 1.8258
2022-02-27 09:39:39 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 1.7169
2022-02-27 09:40:11 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 1.7947
2022-02-27 09:40:45 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 1.8903
2022-02-27 09:41:17 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 1.7197
2022-02-27 09:41:52 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 1.7651
2022-02-27 09:42:23 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 1.6668
2022-02-27 09:42:57 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 1.5758
2022-02-27 09:43:31 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 1.7015
2022-02-27 09:44:04 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 1.8336
2022-02-27 09:44:38 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 1.6150
2022-02-27 09:45:11 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 1.9686
2022-02-27 09:45:46 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 1.5406
2022-02-27 09:46:18 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 1.7852
2022-02-27 09:46:52 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 1.6550
2022-02-27 09:47:26 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 1.5413
2022-02-27 09:48:00 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 1.6622
2022-02-27 09:48:34 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 1.9298
2022-02-27 09:49:07 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 1.7778
2022-02-27 09:49:40 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 1.6903
2022-02-27 09:50:14 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 1.6200
2022-02-27 09:50:47 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 1.5926
2022-02-27 09:51:21 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 1.7788
2022-02-27 09:51:54 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 1.7860
2022-02-27 09:52:28 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 1.7408
2022-02-27 09:53:01 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 1.9324
2022-02-27 09:53:34 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 1.6387
2022-02-27 09:54:09 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 1.7322
2022-02-27 09:54:42 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 1.6759
2022-02-27 09:55:15 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 1.8737
2022-02-27 09:55:49 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 1.6939
2022-02-27 09:56:23 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 1.8640
2022-02-27 09:56:57 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 1.8423
2022-02-27 09:57:30 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 1.7391
2022-02-27 09:58:04 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 1.7521
2022-02-27 09:58:36 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 1.8194
2022-02-27 09:59:10 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 1.3657
2022-02-27 09:59:43 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 1.6981
2022-02-27 10:00:18 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 1.7589
2022-02-27 10:00:50 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 1.8607
2022-02-27 10:01:24 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 1.8263
2022-02-27 10:01:58 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 1.6719
2022-02-27 10:02:33 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 1.8137
2022-02-27 10:03:05 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 1.8262
2022-02-27 10:03:40 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 1.8335
2022-02-27 10:04:13 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 2.0433
2022-02-27 10:04:49 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 1.7341
2022-02-27 10:05:22 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 1.6152
2022-02-27 10:05:57 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 1.7597
2022-02-27 10:06:30 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 1.5641
2022-02-27 10:06:31 - train: epoch 097, train_loss: 1.7540
2022-02-27 10:07:45 - eval: epoch: 097, acc1: 64.368%, acc5: 85.594%, test_loss: 1.4992, per_image_load_time: 2.671ms, per_image_inference_time: 0.157ms
2022-02-27 10:07:45 - until epoch: 097, best_acc1: 64.368%
2022-02-27 10:07:45 - epoch 098 lr: 0.00010000000000000003
2022-02-27 10:08:23 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 1.6990
2022-02-27 10:08:57 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 1.8760
2022-02-27 10:09:28 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 1.8475
2022-02-27 10:10:01 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 1.7748
2022-02-27 10:10:34 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 1.8905
2022-02-27 10:11:06 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 1.6746
2022-02-27 10:11:39 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 1.7092
2022-02-27 10:12:12 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 1.7814
2022-02-27 10:12:45 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 1.7510
2022-02-27 10:13:18 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 1.7254
2022-02-27 10:13:51 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 1.7868
2022-02-27 10:14:24 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 1.7783
2022-02-27 10:14:58 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 1.7045
2022-02-27 10:15:31 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 1.7757
2022-02-27 10:16:05 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 1.6715
2022-02-27 10:16:38 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 1.6670
2022-02-27 10:17:11 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 1.7694
2022-02-27 10:17:46 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 1.6162
2022-02-27 10:18:20 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 1.4934
2022-02-27 10:18:52 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 1.9293
2022-02-27 10:19:26 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 1.9305
2022-02-27 10:20:00 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 1.6698
2022-02-27 10:20:34 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 1.6213
2022-02-27 10:21:07 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 1.7426
2022-02-27 10:21:40 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 1.7752
2022-02-27 10:22:14 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 1.6831
2022-02-27 10:22:48 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 1.7991
2022-02-27 10:23:21 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 1.9669
2022-02-27 10:23:55 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 1.5502
2022-02-27 10:24:28 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 1.7259
2022-02-27 10:25:01 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 1.7296
2022-02-27 10:25:36 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 1.6930
2022-02-27 10:26:09 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 1.8030
2022-02-27 10:26:42 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 1.8265
2022-02-27 10:27:16 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 1.6388
2022-02-27 10:27:49 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 1.8221
2022-02-27 10:28:23 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 1.7295
2022-02-27 10:28:56 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 1.6830
2022-02-27 10:29:30 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 1.6867
2022-02-27 10:30:04 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 1.8388
2022-02-27 10:30:38 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 1.8477
2022-02-27 10:31:11 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 1.7762
2022-02-27 10:31:45 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 1.6333
2022-02-27 10:32:21 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 1.8217
2022-02-27 10:32:52 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 1.6242
2022-02-27 10:33:27 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 1.7789
2022-02-27 10:34:02 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 1.5676
2022-02-27 10:34:36 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 1.7663
2022-02-27 10:35:10 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 1.8775
2022-02-27 10:35:43 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 1.7078
2022-02-27 10:35:43 - train: epoch 098, train_loss: 1.7534
2022-02-27 10:36:57 - eval: epoch: 098, acc1: 64.220%, acc5: 85.530%, test_loss: 1.4995, per_image_load_time: 2.626ms, per_image_inference_time: 0.129ms
2022-02-27 10:36:58 - until epoch: 098, best_acc1: 64.368%
2022-02-27 10:36:58 - epoch 099 lr: 0.00010000000000000003
2022-02-27 10:37:37 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 1.7738
2022-02-27 10:38:11 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 1.6859
2022-02-27 10:38:44 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 1.5420
2022-02-27 10:39:19 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 1.7084
2022-02-27 10:39:51 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 1.6976
2022-02-27 10:40:25 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 1.7296
2022-02-27 10:40:59 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 1.8425
2022-02-27 10:41:32 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 1.7838
2022-02-27 10:42:05 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 1.8253
2022-02-27 10:42:40 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 1.7405
2022-02-27 10:43:14 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 1.6291
2022-02-27 10:43:49 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 1.5318
2022-02-27 10:44:21 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 1.7768
2022-02-27 10:44:56 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 1.7017
2022-02-27 10:45:29 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 1.6907
2022-02-27 10:46:03 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 1.6691
2022-02-27 10:46:35 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 1.6293
2022-02-27 10:47:10 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 1.7510
2022-02-27 10:47:42 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 1.8676
2022-02-27 10:48:18 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 1.5940
2022-02-27 10:48:50 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 1.6967
2022-02-27 10:49:24 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 1.7397
2022-02-27 10:49:58 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 1.7364
2022-02-27 10:50:33 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 1.9270
2022-02-27 10:51:06 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 1.6347
2022-02-27 10:51:42 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 1.6814
2022-02-27 10:52:15 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 1.8024
2022-02-27 10:52:50 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 1.6685
2022-02-27 10:53:23 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 1.6860
2022-02-27 10:53:57 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 1.8946
2022-02-27 10:54:31 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 1.6364
2022-02-27 10:55:05 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 1.9142
2022-02-27 10:55:39 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 1.8048
2022-02-27 10:56:11 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 1.9772
2022-02-27 10:56:44 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 1.9353
2022-02-27 10:57:18 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 1.5920
2022-02-27 10:57:50 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 1.6091
2022-02-27 10:58:24 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 1.7789
2022-02-27 10:58:57 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 1.8744
2022-02-27 10:59:31 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 1.7721
2022-02-27 11:00:05 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 1.7570
2022-02-27 11:00:38 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 1.8576
2022-02-27 11:01:12 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 1.7233
2022-02-27 11:01:45 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 1.9022
2022-02-27 11:02:20 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 2.0269
2022-02-27 11:02:53 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 1.8185
2022-02-27 11:03:29 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 1.6179
2022-02-27 11:04:03 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 1.8811
2022-02-27 11:04:38 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 1.7742
2022-02-27 11:05:11 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 1.8804
2022-02-27 11:05:12 - train: epoch 099, train_loss: 1.7526
2022-02-27 11:06:28 - eval: epoch: 099, acc1: 64.264%, acc5: 85.596%, test_loss: 1.5003, per_image_load_time: 2.737ms, per_image_inference_time: 0.130ms
2022-02-27 11:06:28 - until epoch: 099, best_acc1: 64.368%
2022-02-27 11:06:28 - epoch 100 lr: 0.00010000000000000003
2022-02-27 11:07:07 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 1.7510
2022-02-27 11:07:39 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 1.9861
2022-02-27 11:08:14 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 1.7512
2022-02-27 11:08:47 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 1.7167
2022-02-27 11:09:20 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 1.8216
2022-02-27 11:09:53 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 1.6835
2022-02-27 11:10:26 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 1.6794
2022-02-27 11:11:00 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 1.8856
2022-02-27 11:11:32 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 1.8460
2022-02-27 11:12:05 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 1.7607
2022-02-27 11:12:38 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 1.5922
2022-02-27 11:13:12 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 1.7409
2022-02-27 11:13:44 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 1.8907
2022-02-27 11:14:18 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 2.0473
2022-02-27 11:14:50 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 1.7490
2022-02-27 11:15:24 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 1.6715
2022-02-27 11:15:55 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 1.6133
2022-02-27 11:16:29 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 1.6381
2022-02-27 11:17:02 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 1.8009
2022-02-27 11:17:36 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 1.8035
2022-02-27 11:18:09 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 1.7085
2022-02-27 11:18:43 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 1.8930
2022-02-27 11:19:16 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 1.9189
2022-02-27 11:19:49 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 1.9057
2022-02-27 11:20:23 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 1.9168
2022-02-27 11:20:55 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 1.8759
2022-02-27 11:21:28 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 1.6617
2022-02-27 11:22:01 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 1.6520
2022-02-27 11:22:35 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 1.6663
2022-02-27 11:23:07 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 1.6236
2022-02-27 11:23:41 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 1.7100
2022-02-27 11:24:14 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 2.0123
2022-02-27 11:24:47 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 1.8283
2022-02-27 11:25:22 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 1.7816
2022-02-27 11:25:55 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 1.6553
2022-02-27 11:26:28 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 1.5415
2022-02-27 11:27:02 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 1.4761
2022-02-27 11:27:36 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 1.6518
2022-02-27 11:28:10 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 1.7551
2022-02-27 11:28:44 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 1.7275
2022-02-27 11:29:17 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 1.7166
2022-02-27 11:29:51 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 1.6999
2022-02-27 11:30:25 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 1.7937
2022-02-27 11:30:59 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 1.9353
2022-02-27 11:31:34 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 1.5950
2022-02-27 11:32:08 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 1.9389
2022-02-27 11:32:43 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 1.9080
2022-02-27 11:33:17 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 1.5464
2022-02-27 11:33:53 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 1.8508
2022-02-27 11:34:25 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 1.9516
2022-02-27 11:34:26 - train: epoch 100, train_loss: 1.7508
2022-02-27 11:35:44 - eval: epoch: 100, acc1: 64.306%, acc5: 85.558%, test_loss: 1.5005, per_image_load_time: 1.867ms, per_image_inference_time: 0.112ms
2022-02-27 11:35:45 - until epoch: 100, best_acc1: 64.368%
2022-02-27 11:35:45 - train done. model: yolov4cspdarknettiny, train time: 48.872 hours, best_acc1: 64.368%
