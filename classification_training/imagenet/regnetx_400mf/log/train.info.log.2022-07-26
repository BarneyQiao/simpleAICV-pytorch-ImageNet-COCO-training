2022-07-26 12:04:16 - train: epoch 0028, iter [03700, 05004], lr: 0.173034, loss: 2.4174
2022-07-26 12:06:16 - train: epoch 0028, iter [03800, 05004], lr: 0.172989, loss: 2.1552
2022-07-26 12:08:15 - train: epoch 0028, iter [03900, 05004], lr: 0.172944, loss: 2.3391
2022-07-26 12:10:12 - train: epoch 0028, iter [04000, 05004], lr: 0.172898, loss: 2.3525
2022-07-26 12:12:11 - train: epoch 0028, iter [04100, 05004], lr: 0.172853, loss: 2.2303
2022-07-26 12:14:12 - train: epoch 0028, iter [04200, 05004], lr: 0.172808, loss: 2.2955
2022-07-26 12:15:54 - train: epoch 0028, iter [04300, 05004], lr: 0.172762, loss: 2.3661
2022-07-26 12:18:18 - train: epoch 0028, iter [04400, 05004], lr: 0.172717, loss: 2.3778
2022-07-26 12:20:17 - train: epoch 0028, iter [04500, 05004], lr: 0.172672, loss: 2.4222
2022-07-26 12:22:25 - train: epoch 0028, iter [04600, 05004], lr: 0.172626, loss: 2.2428
2022-07-26 12:24:26 - train: epoch 0028, iter [04700, 05004], lr: 0.172581, loss: 2.3475
2022-07-26 12:26:24 - train: epoch 0028, iter [04800, 05004], lr: 0.172535, loss: 2.2746
2022-07-26 12:28:25 - train: epoch 0028, iter [04900, 05004], lr: 0.172490, loss: 2.3027
2022-07-26 12:30:19 - train: epoch 0028, iter [05000, 05004], lr: 0.172444, loss: 2.0714
2022-07-26 12:30:23 - train: epoch 028, train_loss: 2.2507
2022-07-26 12:34:35 - eval: epoch: 028, acc1: 52.750%, acc5: 77.836%, test_loss: 2.0360, per_image_load_time: 8.928ms, per_image_inference_time: 0.704ms
2022-07-26 12:34:35 - until epoch: 028, best_acc1: 54.440%
2022-07-26 12:34:35 - epoch 029 lr: 0.172442
2022-07-26 12:36:51 - train: epoch 0029, iter [00100, 05004], lr: 0.172397, loss: 2.0549
2022-07-26 12:38:51 - train: epoch 0029, iter [00200, 05004], lr: 0.172351, loss: 2.2568
2022-07-26 12:40:51 - train: epoch 0029, iter [00300, 05004], lr: 0.172306, loss: 2.3868
2022-07-26 12:42:45 - train: epoch 0029, iter [00400, 05004], lr: 0.172260, loss: 2.3209
2022-07-26 12:44:39 - train: epoch 0029, iter [00500, 05004], lr: 0.172214, loss: 2.1825
2022-07-26 12:46:37 - train: epoch 0029, iter [00600, 05004], lr: 0.172169, loss: 2.3944
2022-07-26 12:48:35 - train: epoch 0029, iter [00700, 05004], lr: 0.172123, loss: 2.2322
2022-07-26 12:50:29 - train: epoch 0029, iter [00800, 05004], lr: 0.172077, loss: 2.2501
2022-07-26 12:52:26 - train: epoch 0029, iter [00900, 05004], lr: 0.172031, loss: 2.2284
2022-07-26 12:54:24 - train: epoch 0029, iter [01000, 05004], lr: 0.171985, loss: 2.1435
2022-07-26 12:56:26 - train: epoch 0029, iter [01100, 05004], lr: 0.171939, loss: 2.1696
2022-07-26 12:58:23 - train: epoch 0029, iter [01200, 05004], lr: 0.171894, loss: 2.1366
2022-07-26 13:00:19 - train: epoch 0029, iter [01300, 05004], lr: 0.171848, loss: 2.2188
2022-07-26 13:02:15 - train: epoch 0029, iter [01400, 05004], lr: 0.171802, loss: 2.2588
2022-07-26 13:04:11 - train: epoch 0029, iter [01500, 05004], lr: 0.171756, loss: 2.4444
2022-07-26 13:06:10 - train: epoch 0029, iter [01600, 05004], lr: 0.171710, loss: 2.2525
2022-07-26 13:08:03 - train: epoch 0029, iter [01700, 05004], lr: 0.171664, loss: 2.2203
2022-07-26 13:10:00 - train: epoch 0029, iter [01800, 05004], lr: 0.171617, loss: 2.5913
2022-07-26 13:12:00 - train: epoch 0029, iter [01900, 05004], lr: 0.171571, loss: 2.0778
2022-07-26 13:13:58 - train: epoch 0029, iter [02000, 05004], lr: 0.171525, loss: 2.3540
2022-07-26 13:15:53 - train: epoch 0029, iter [02100, 05004], lr: 0.171479, loss: 2.2578
2022-07-26 13:17:51 - train: epoch 0029, iter [02200, 05004], lr: 0.171433, loss: 2.3534
2022-07-26 13:19:48 - train: epoch 0029, iter [02300, 05004], lr: 0.171386, loss: 2.1499
2022-07-26 13:21:44 - train: epoch 0029, iter [02400, 05004], lr: 0.171340, loss: 2.1376
2022-07-26 13:23:39 - train: epoch 0029, iter [02500, 05004], lr: 0.171294, loss: 2.3084
2022-07-26 13:25:40 - train: epoch 0029, iter [02600, 05004], lr: 0.171247, loss: 2.2862
2022-07-26 13:27:34 - train: epoch 0029, iter [02700, 05004], lr: 0.171201, loss: 2.0280
2022-07-26 13:29:26 - train: epoch 0029, iter [02800, 05004], lr: 0.171155, loss: 2.2511
2022-07-26 13:31:17 - train: epoch 0029, iter [02900, 05004], lr: 0.171108, loss: 2.2544
2022-07-26 13:33:18 - train: epoch 0029, iter [03000, 05004], lr: 0.171062, loss: 2.1712
2022-07-26 13:35:26 - train: epoch 0029, iter [03100, 05004], lr: 0.171015, loss: 2.3151
2022-07-26 13:37:26 - train: epoch 0029, iter [03200, 05004], lr: 0.170969, loss: 2.2048
2022-07-26 13:39:30 - train: epoch 0029, iter [03300, 05004], lr: 0.170922, loss: 2.1131
2022-07-26 13:41:30 - train: epoch 0029, iter [03400, 05004], lr: 0.170875, loss: 2.1270
2022-07-26 13:43:28 - train: epoch 0029, iter [03500, 05004], lr: 0.170829, loss: 2.4051
2022-07-26 13:45:29 - train: epoch 0029, iter [03600, 05004], lr: 0.170782, loss: 2.1649
2022-07-26 13:47:29 - train: epoch 0029, iter [03700, 05004], lr: 0.170735, loss: 2.1387
2022-07-26 13:49:29 - train: epoch 0029, iter [03800, 05004], lr: 0.170689, loss: 2.2426
2022-07-26 13:51:34 - train: epoch 0029, iter [03900, 05004], lr: 0.170642, loss: 2.1693
2022-07-26 13:53:31 - train: epoch 0029, iter [04000, 05004], lr: 0.170595, loss: 2.3813
2022-07-26 13:55:29 - train: epoch 0029, iter [04100, 05004], lr: 0.170548, loss: 2.3271
2022-07-26 13:57:28 - train: epoch 0029, iter [04200, 05004], lr: 0.170501, loss: 2.2315
2022-07-26 13:59:31 - train: epoch 0029, iter [04300, 05004], lr: 0.170455, loss: 2.2227
2022-07-26 14:02:08 - train: epoch 0029, iter [04400, 05004], lr: 0.170408, loss: 2.2551
2022-07-26 14:04:04 - train: epoch 0029, iter [04500, 05004], lr: 0.170361, loss: 2.3137
2022-07-26 14:06:09 - train: epoch 0029, iter [04600, 05004], lr: 0.170314, loss: 2.4799
2022-07-26 14:08:14 - train: epoch 0029, iter [04700, 05004], lr: 0.170267, loss: 2.0127
2022-07-26 14:10:20 - train: epoch 0029, iter [04800, 05004], lr: 0.170220, loss: 2.2058
2022-07-26 14:12:22 - train: epoch 0029, iter [04900, 05004], lr: 0.170173, loss: 2.5196
2022-07-26 14:14:22 - train: epoch 0029, iter [05000, 05004], lr: 0.170126, loss: 2.0410
2022-07-26 14:14:26 - train: epoch 029, train_loss: 2.2426
2022-07-26 14:18:35 - eval: epoch: 029, acc1: 52.698%, acc5: 77.920%, test_loss: 2.0334, per_image_load_time: 8.550ms, per_image_inference_time: 0.751ms
2022-07-26 14:18:35 - until epoch: 029, best_acc1: 54.440%
2022-07-26 14:18:35 - epoch 030 lr: 0.170123
2022-07-26 14:20:56 - train: epoch 0030, iter [00100, 05004], lr: 0.170077, loss: 2.2593
2022-07-26 14:22:59 - train: epoch 0030, iter [00200, 05004], lr: 0.170029, loss: 2.1781
2022-07-26 14:24:57 - train: epoch 0030, iter [00300, 05004], lr: 0.169982, loss: 2.1742
2022-07-26 14:26:58 - train: epoch 0030, iter [00400, 05004], lr: 0.169935, loss: 2.1485
2022-07-26 14:29:03 - train: epoch 0030, iter [00500, 05004], lr: 0.169888, loss: 2.3127
2022-07-26 14:31:10 - train: epoch 0030, iter [00600, 05004], lr: 0.169840, loss: 2.3347
2022-07-26 14:33:08 - train: epoch 0030, iter [00700, 05004], lr: 0.169793, loss: 2.2973
2022-07-26 14:35:10 - train: epoch 0030, iter [00800, 05004], lr: 0.169746, loss: 2.2380
2022-07-26 14:37:14 - train: epoch 0030, iter [00900, 05004], lr: 0.169698, loss: 2.3246
2022-07-26 14:39:18 - train: epoch 0030, iter [01000, 05004], lr: 0.169651, loss: 2.0944
2022-07-26 14:41:19 - train: epoch 0030, iter [01100, 05004], lr: 0.169604, loss: 2.1233
2022-07-26 14:43:26 - train: epoch 0030, iter [01200, 05004], lr: 0.169556, loss: 2.2921
2022-07-26 14:45:30 - train: epoch 0030, iter [01300, 05004], lr: 0.169509, loss: 2.0912
2022-07-26 14:47:33 - train: epoch 0030, iter [01400, 05004], lr: 0.169461, loss: 2.1244
2022-07-26 14:49:37 - train: epoch 0030, iter [01500, 05004], lr: 0.169414, loss: 2.2158
2022-07-26 14:51:45 - train: epoch 0030, iter [01600, 05004], lr: 0.169366, loss: 2.2389
2022-07-26 14:53:47 - train: epoch 0030, iter [01700, 05004], lr: 0.169318, loss: 2.2913
2022-07-26 14:55:45 - train: epoch 0030, iter [01800, 05004], lr: 0.169271, loss: 2.1553
2022-07-26 14:57:51 - train: epoch 0030, iter [01900, 05004], lr: 0.169223, loss: 2.4326
2022-07-26 14:59:53 - train: epoch 0030, iter [02000, 05004], lr: 0.169175, loss: 2.2809
2022-07-26 15:01:56 - train: epoch 0030, iter [02100, 05004], lr: 0.169128, loss: 2.3499
2022-07-26 15:04:00 - train: epoch 0030, iter [02200, 05004], lr: 0.169080, loss: 2.2449
2022-07-26 15:06:06 - train: epoch 0030, iter [02300, 05004], lr: 0.169032, loss: 2.1102
2022-07-26 15:08:01 - train: epoch 0030, iter [02400, 05004], lr: 0.168984, loss: 2.2422
2022-07-26 15:10:03 - train: epoch 0030, iter [02500, 05004], lr: 0.168936, loss: 2.3905
2022-07-26 15:12:03 - train: epoch 0030, iter [02600, 05004], lr: 0.168888, loss: 2.2240
2022-07-26 15:14:05 - train: epoch 0030, iter [02700, 05004], lr: 0.168840, loss: 2.0920
2022-07-26 15:16:02 - train: epoch 0030, iter [02800, 05004], lr: 0.168793, loss: 2.2556
2022-07-26 15:18:02 - train: epoch 0030, iter [02900, 05004], lr: 0.168745, loss: 2.0300
2022-07-26 15:20:03 - train: epoch 0030, iter [03000, 05004], lr: 0.168697, loss: 2.2480
2022-07-26 15:22:07 - train: epoch 0030, iter [03100, 05004], lr: 0.168649, loss: 2.2702
2022-07-26 15:24:07 - train: epoch 0030, iter [03200, 05004], lr: 0.168600, loss: 1.9855
2022-07-26 15:26:08 - train: epoch 0030, iter [03300, 05004], lr: 0.168552, loss: 2.3357
2022-07-26 15:28:07 - train: epoch 0030, iter [03400, 05004], lr: 0.168504, loss: 2.2193
2022-07-26 15:30:08 - train: epoch 0030, iter [03500, 05004], lr: 0.168456, loss: 2.4054
2022-07-26 15:32:08 - train: epoch 0030, iter [03600, 05004], lr: 0.168408, loss: 2.2577
2022-07-26 15:34:08 - train: epoch 0030, iter [03700, 05004], lr: 0.168360, loss: 2.2094
2022-07-26 15:36:11 - train: epoch 0030, iter [03800, 05004], lr: 0.168311, loss: 2.3008
2022-07-26 15:38:15 - train: epoch 0030, iter [03900, 05004], lr: 0.168263, loss: 2.1999
2022-07-26 15:40:19 - train: epoch 0030, iter [04000, 05004], lr: 0.168215, loss: 2.2068
2022-07-26 15:42:19 - train: epoch 0030, iter [04100, 05004], lr: 0.168166, loss: 2.2002
2022-07-26 15:44:11 - train: epoch 0030, iter [04200, 05004], lr: 0.168118, loss: 2.3786
2022-07-26 15:46:37 - train: epoch 0030, iter [04300, 05004], lr: 0.168070, loss: 2.1494
2022-07-26 15:48:42 - train: epoch 0030, iter [04400, 05004], lr: 0.168021, loss: 2.1527
2022-07-26 15:50:54 - train: epoch 0030, iter [04500, 05004], lr: 0.167973, loss: 2.4245
2022-07-26 15:53:01 - train: epoch 0030, iter [04600, 05004], lr: 0.167924, loss: 2.0197
2022-07-26 15:55:01 - train: epoch 0030, iter [04700, 05004], lr: 0.167876, loss: 2.0763
2022-07-26 15:57:09 - train: epoch 0030, iter [04800, 05004], lr: 0.167827, loss: 2.2819
2022-07-26 15:59:17 - train: epoch 0030, iter [04900, 05004], lr: 0.167779, loss: 2.4492
2022-07-26 16:01:17 - train: epoch 0030, iter [05000, 05004], lr: 0.167730, loss: 2.4234
2022-07-26 16:01:22 - train: epoch 030, train_loss: 2.2332
2022-07-26 16:05:32 - eval: epoch: 030, acc1: 53.740%, acc5: 79.422%, test_loss: 1.9523, per_image_load_time: 7.966ms, per_image_inference_time: 0.783ms
2022-07-26 16:05:32 - until epoch: 030, best_acc1: 54.440%
2022-07-26 16:05:32 - epoch 031 lr: 0.167728
2022-07-26 16:07:57 - train: epoch 0031, iter [00100, 05004], lr: 0.167680, loss: 2.3865
2022-07-26 16:09:58 - train: epoch 0031, iter [00200, 05004], lr: 0.167631, loss: 2.1153
2022-07-26 16:12:04 - train: epoch 0031, iter [00300, 05004], lr: 0.167582, loss: 2.0619
2022-07-26 16:14:03 - train: epoch 0031, iter [00400, 05004], lr: 0.167533, loss: 2.1087
2022-07-26 16:16:02 - train: epoch 0031, iter [00500, 05004], lr: 0.167485, loss: 2.2443
2022-07-26 16:18:02 - train: epoch 0031, iter [00600, 05004], lr: 0.167436, loss: 2.1571
2022-07-26 16:20:11 - train: epoch 0031, iter [00700, 05004], lr: 0.167387, loss: 2.1177
2022-07-26 16:22:11 - train: epoch 0031, iter [00800, 05004], lr: 0.167338, loss: 2.2772
2022-07-26 16:24:14 - train: epoch 0031, iter [00900, 05004], lr: 0.167289, loss: 2.1714
2022-07-26 16:26:21 - train: epoch 0031, iter [01000, 05004], lr: 0.167240, loss: 2.4811
2022-07-26 16:28:20 - train: epoch 0031, iter [01100, 05004], lr: 0.167192, loss: 2.1699
2022-07-26 16:30:26 - train: epoch 0031, iter [01200, 05004], lr: 0.167143, loss: 2.0287
2022-07-26 16:32:29 - train: epoch 0031, iter [01300, 05004], lr: 0.167094, loss: 1.8087
2022-07-26 16:34:35 - train: epoch 0031, iter [01400, 05004], lr: 0.167045, loss: 2.2029
2022-07-26 16:36:37 - train: epoch 0031, iter [01500, 05004], lr: 0.166996, loss: 2.5732
2022-07-26 16:38:43 - train: epoch 0031, iter [01600, 05004], lr: 0.166946, loss: 1.9924
2022-07-26 16:40:42 - train: epoch 0031, iter [01700, 05004], lr: 0.166897, loss: 2.2327
2022-07-26 16:42:41 - train: epoch 0031, iter [01800, 05004], lr: 0.166848, loss: 2.0837
2022-07-26 16:44:44 - train: epoch 0031, iter [01900, 05004], lr: 0.166799, loss: 2.1463
2022-07-26 16:46:44 - train: epoch 0031, iter [02000, 05004], lr: 0.166750, loss: 2.1782
2022-07-26 16:48:45 - train: epoch 0031, iter [02100, 05004], lr: 0.166701, loss: 2.1255
2022-07-26 16:50:46 - train: epoch 0031, iter [02200, 05004], lr: 0.166651, loss: 2.0205
2022-07-26 16:52:49 - train: epoch 0031, iter [02300, 05004], lr: 0.166602, loss: 1.8578
2022-07-26 16:54:52 - train: epoch 0031, iter [02400, 05004], lr: 0.166553, loss: 2.3445
2022-07-26 16:56:56 - train: epoch 0031, iter [02500, 05004], lr: 0.166503, loss: 2.2081
2022-07-26 16:58:57 - train: epoch 0031, iter [02600, 05004], lr: 0.166454, loss: 2.1095
2022-07-26 17:01:05 - train: epoch 0031, iter [02700, 05004], lr: 0.166405, loss: 2.3106
2022-07-26 17:03:03 - train: epoch 0031, iter [02800, 05004], lr: 0.166355, loss: 2.6191
2022-07-26 17:05:07 - train: epoch 0031, iter [02900, 05004], lr: 0.166306, loss: 2.2595
2022-07-26 17:07:05 - train: epoch 0031, iter [03000, 05004], lr: 0.166256, loss: 2.4362
2022-07-26 17:09:05 - train: epoch 0031, iter [03100, 05004], lr: 0.166207, loss: 2.2906
2022-07-26 17:11:04 - train: epoch 0031, iter [03200, 05004], lr: 0.166157, loss: 2.2402
2022-07-26 17:13:04 - train: epoch 0031, iter [03300, 05004], lr: 0.166108, loss: 2.1873
2022-07-26 17:15:07 - train: epoch 0031, iter [03400, 05004], lr: 0.166058, loss: 2.4125
2022-07-26 17:17:07 - train: epoch 0031, iter [03500, 05004], lr: 0.166008, loss: 2.3732
2022-07-26 17:19:09 - train: epoch 0031, iter [03600, 05004], lr: 0.165959, loss: 2.2108
2022-07-26 17:21:10 - train: epoch 0031, iter [03700, 05004], lr: 0.165909, loss: 2.1589
2022-07-26 17:23:10 - train: epoch 0031, iter [03800, 05004], lr: 0.165859, loss: 2.1673
2022-07-26 17:25:13 - train: epoch 0031, iter [03900, 05004], lr: 0.165810, loss: 2.3585
2022-07-26 17:27:16 - train: epoch 0031, iter [04000, 05004], lr: 0.165760, loss: 2.1703
2022-07-26 17:29:20 - train: epoch 0031, iter [04100, 05004], lr: 0.165710, loss: 2.3296
2022-07-26 17:31:14 - train: epoch 0031, iter [04200, 05004], lr: 0.165660, loss: 2.2643
2022-07-26 17:33:52 - train: epoch 0031, iter [04300, 05004], lr: 0.165610, loss: 2.1642
2022-07-26 17:35:52 - train: epoch 0031, iter [04400, 05004], lr: 0.165561, loss: 2.2885
2022-07-26 17:37:59 - train: epoch 0031, iter [04500, 05004], lr: 0.165511, loss: 2.2117
2022-07-26 17:40:01 - train: epoch 0031, iter [04600, 05004], lr: 0.165461, loss: 2.4204
2022-07-26 17:42:04 - train: epoch 0031, iter [04700, 05004], lr: 0.165411, loss: 2.1292
2022-07-26 17:44:09 - train: epoch 0031, iter [04800, 05004], lr: 0.165361, loss: 2.1396
2022-07-26 17:46:07 - train: epoch 0031, iter [04900, 05004], lr: 0.165311, loss: 2.0962
2022-07-26 17:48:04 - train: epoch 0031, iter [05000, 05004], lr: 0.165261, loss: 2.2509
2022-07-26 17:48:08 - train: epoch 031, train_loss: 2.2223
2022-07-26 17:52:19 - eval: epoch: 031, acc1: 53.996%, acc5: 79.212%, test_loss: 1.9596, per_image_load_time: 8.313ms, per_image_inference_time: 0.814ms
2022-07-26 17:52:19 - until epoch: 031, best_acc1: 54.440%
2022-07-26 17:52:19 - epoch 032 lr: 0.165258
2022-07-26 17:54:42 - train: epoch 0032, iter [00100, 05004], lr: 0.165208, loss: 2.0829
2022-07-26 17:56:42 - train: epoch 0032, iter [00200, 05004], lr: 0.165158, loss: 2.1609
2022-07-26 17:58:41 - train: epoch 0032, iter [00300, 05004], lr: 0.165108, loss: 2.0550
2022-07-26 18:00:43 - train: epoch 0032, iter [00400, 05004], lr: 0.165058, loss: 2.2141
2022-07-26 18:02:42 - train: epoch 0032, iter [00500, 05004], lr: 0.165008, loss: 2.1494
2022-07-26 18:04:47 - train: epoch 0032, iter [00600, 05004], lr: 0.164958, loss: 2.2278
2022-07-26 18:06:50 - train: epoch 0032, iter [00700, 05004], lr: 0.164907, loss: 2.0672
2022-07-26 18:08:49 - train: epoch 0032, iter [00800, 05004], lr: 0.164857, loss: 2.1120
2022-07-26 18:10:51 - train: epoch 0032, iter [00900, 05004], lr: 0.164807, loss: 2.4273
2022-07-26 18:12:54 - train: epoch 0032, iter [01000, 05004], lr: 0.164756, loss: 2.2692
2022-07-26 18:14:55 - train: epoch 0032, iter [01100, 05004], lr: 0.164706, loss: 2.1380
2022-07-26 18:16:58 - train: epoch 0032, iter [01200, 05004], lr: 0.164656, loss: 2.2931
2022-07-26 18:18:58 - train: epoch 0032, iter [01300, 05004], lr: 0.164605, loss: 2.0423
2022-07-26 18:20:59 - train: epoch 0032, iter [01400, 05004], lr: 0.164555, loss: 2.4201
2022-07-26 18:23:03 - train: epoch 0032, iter [01500, 05004], lr: 0.164504, loss: 2.2449
2022-07-26 18:25:03 - train: epoch 0032, iter [01600, 05004], lr: 0.164454, loss: 2.3372
2022-07-26 18:27:05 - train: epoch 0032, iter [01700, 05004], lr: 0.164403, loss: 2.2134
2022-07-26 18:29:14 - train: epoch 0032, iter [01800, 05004], lr: 0.164353, loss: 2.4423
2022-07-26 18:31:14 - train: epoch 0032, iter [01900, 05004], lr: 0.164302, loss: 2.1095
2022-07-26 18:33:14 - train: epoch 0032, iter [02000, 05004], lr: 0.164251, loss: 2.2435
2022-07-26 18:35:17 - train: epoch 0032, iter [02100, 05004], lr: 0.164201, loss: 1.7864
2022-07-26 18:37:18 - train: epoch 0032, iter [02200, 05004], lr: 0.164150, loss: 2.0487
2022-07-26 18:39:20 - train: epoch 0032, iter [02300, 05004], lr: 0.164099, loss: 2.2305
2022-07-26 18:41:26 - train: epoch 0032, iter [02400, 05004], lr: 0.164049, loss: 2.1688
2022-07-26 18:43:30 - train: epoch 0032, iter [02500, 05004], lr: 0.163998, loss: 2.2855
2022-07-26 18:45:31 - train: epoch 0032, iter [02600, 05004], lr: 0.163947, loss: 2.0549
2022-07-26 18:47:33 - train: epoch 0032, iter [02700, 05004], lr: 0.163896, loss: 2.1515
2022-07-26 18:49:37 - train: epoch 0032, iter [02800, 05004], lr: 0.163845, loss: 2.1299
2022-07-26 18:51:39 - train: epoch 0032, iter [02900, 05004], lr: 0.163795, loss: 2.2038
2022-07-26 18:53:41 - train: epoch 0032, iter [03000, 05004], lr: 0.163744, loss: 2.2732
2022-07-26 18:55:41 - train: epoch 0032, iter [03100, 05004], lr: 0.163693, loss: 2.3743
2022-07-26 18:57:45 - train: epoch 0032, iter [03200, 05004], lr: 0.163642, loss: 2.3237
2022-07-26 18:59:43 - train: epoch 0032, iter [03300, 05004], lr: 0.163591, loss: 1.9833
2022-07-26 19:01:46 - train: epoch 0032, iter [03400, 05004], lr: 0.163540, loss: 2.0379
2022-07-26 19:03:46 - train: epoch 0032, iter [03500, 05004], lr: 0.163489, loss: 2.1188
2022-07-26 19:05:47 - train: epoch 0032, iter [03600, 05004], lr: 0.163438, loss: 2.4060
2022-07-26 19:07:46 - train: epoch 0032, iter [03700, 05004], lr: 0.163387, loss: 2.2686
2022-07-26 19:09:48 - train: epoch 0032, iter [03800, 05004], lr: 0.163335, loss: 1.9549
2022-07-26 19:11:46 - train: epoch 0032, iter [03900, 05004], lr: 0.163284, loss: 2.2419
2022-07-26 19:13:50 - train: epoch 0032, iter [04000, 05004], lr: 0.163233, loss: 2.1860
2022-07-26 19:15:42 - train: epoch 0032, iter [04100, 05004], lr: 0.163182, loss: 2.1179
2022-07-26 19:18:04 - train: epoch 0032, iter [04200, 05004], lr: 0.163131, loss: 2.0073
2022-07-26 19:20:05 - train: epoch 0032, iter [04300, 05004], lr: 0.163079, loss: 2.4104
2022-07-26 19:22:13 - train: epoch 0032, iter [04400, 05004], lr: 0.163028, loss: 2.1851
2022-07-26 19:24:20 - train: epoch 0032, iter [04500, 05004], lr: 0.162977, loss: 2.3342
2022-07-26 19:26:23 - train: epoch 0032, iter [04600, 05004], lr: 0.162925, loss: 2.0409
2022-07-26 19:28:27 - train: epoch 0032, iter [04700, 05004], lr: 0.162874, loss: 2.2608
2022-07-26 19:30:26 - train: epoch 0032, iter [04800, 05004], lr: 0.162823, loss: 2.0719
2022-07-26 19:32:26 - train: epoch 0032, iter [04900, 05004], lr: 0.162771, loss: 2.2157
2022-07-26 19:34:23 - train: epoch 0032, iter [05000, 05004], lr: 0.162720, loss: 2.2207
2022-07-26 19:34:27 - train: epoch 032, train_loss: 2.2108
2022-07-26 19:38:30 - eval: epoch: 032, acc1: 54.350%, acc5: 79.434%, test_loss: 1.9292, per_image_load_time: 7.432ms, per_image_inference_time: 0.746ms
2022-07-26 19:38:31 - until epoch: 032, best_acc1: 54.440%
2022-07-26 19:38:31 - epoch 033 lr: 0.162717
2022-07-26 19:40:50 - train: epoch 0033, iter [00100, 05004], lr: 0.162666, loss: 1.9158
2022-07-26 19:42:53 - train: epoch 0033, iter [00200, 05004], lr: 0.162615, loss: 2.1862
2022-07-26 19:44:55 - train: epoch 0033, iter [00300, 05004], lr: 0.162563, loss: 2.0208
2022-07-26 19:46:56 - train: epoch 0033, iter [00400, 05004], lr: 0.162512, loss: 2.0669
2022-07-26 19:48:59 - train: epoch 0033, iter [00500, 05004], lr: 0.162460, loss: 2.3030
2022-07-26 19:50:59 - train: epoch 0033, iter [00600, 05004], lr: 0.162408, loss: 2.1142
2022-07-26 19:52:59 - train: epoch 0033, iter [00700, 05004], lr: 0.162357, loss: 2.4019
2022-07-26 19:55:04 - train: epoch 0033, iter [00800, 05004], lr: 0.162305, loss: 2.3974
2022-07-26 19:57:05 - train: epoch 0033, iter [00900, 05004], lr: 0.162253, loss: 2.1106
2022-07-26 19:59:07 - train: epoch 0033, iter [01000, 05004], lr: 0.162202, loss: 2.5253
2022-07-26 20:01:08 - train: epoch 0033, iter [01100, 05004], lr: 0.162150, loss: 1.8819
2022-07-26 20:03:12 - train: epoch 0033, iter [01200, 05004], lr: 0.162098, loss: 2.3773
2022-07-26 20:05:15 - train: epoch 0033, iter [01300, 05004], lr: 0.162046, loss: 2.0906
2022-07-26 20:07:14 - train: epoch 0033, iter [01400, 05004], lr: 0.161994, loss: 2.2388
2022-07-26 20:09:16 - train: epoch 0033, iter [01500, 05004], lr: 0.161942, loss: 2.4554
2022-07-26 20:11:17 - train: epoch 0033, iter [01600, 05004], lr: 0.161891, loss: 2.3509
2022-07-26 20:13:17 - train: epoch 0033, iter [01700, 05004], lr: 0.161839, loss: 2.0967
2022-07-26 20:15:19 - train: epoch 0033, iter [01800, 05004], lr: 0.161787, loss: 2.1703
2022-07-26 20:17:21 - train: epoch 0033, iter [01900, 05004], lr: 0.161735, loss: 2.3327
2022-07-26 20:19:21 - train: epoch 0033, iter [02000, 05004], lr: 0.161683, loss: 2.1436
2022-07-26 20:21:22 - train: epoch 0033, iter [02100, 05004], lr: 0.161631, loss: 2.2235
2022-07-26 20:23:23 - train: epoch 0033, iter [02200, 05004], lr: 0.161579, loss: 2.2683
2022-07-26 20:25:25 - train: epoch 0033, iter [02300, 05004], lr: 0.161527, loss: 2.3149
2022-07-26 20:27:22 - train: epoch 0033, iter [02400, 05004], lr: 0.161474, loss: 2.3231
2022-07-26 20:29:23 - train: epoch 0033, iter [02500, 05004], lr: 0.161422, loss: 2.2843
2022-07-26 20:31:25 - train: epoch 0033, iter [02600, 05004], lr: 0.161370, loss: 2.0224
2022-07-26 20:33:29 - train: epoch 0033, iter [02700, 05004], lr: 0.161318, loss: 2.2928
2022-07-26 20:35:32 - train: epoch 0033, iter [02800, 05004], lr: 0.161266, loss: 2.3837
2022-07-26 20:37:36 - train: epoch 0033, iter [02900, 05004], lr: 0.161213, loss: 2.2064
2022-07-26 20:39:38 - train: epoch 0033, iter [03000, 05004], lr: 0.161161, loss: 2.2527
2022-07-26 20:41:44 - train: epoch 0033, iter [03100, 05004], lr: 0.161109, loss: 2.2891
2022-07-26 20:43:45 - train: epoch 0033, iter [03200, 05004], lr: 0.161057, loss: 2.2358
2022-07-26 20:45:44 - train: epoch 0033, iter [03300, 05004], lr: 0.161004, loss: 2.2689
2022-07-26 20:47:44 - train: epoch 0033, iter [03400, 05004], lr: 0.160952, loss: 2.1196
2022-07-26 20:49:44 - train: epoch 0033, iter [03500, 05004], lr: 0.160899, loss: 2.1638
2022-07-26 20:51:48 - train: epoch 0033, iter [03600, 05004], lr: 0.160847, loss: 2.3264
2022-07-26 20:53:46 - train: epoch 0033, iter [03700, 05004], lr: 0.160795, loss: 2.2673
2022-07-26 20:55:49 - train: epoch 0033, iter [03800, 05004], lr: 0.160742, loss: 2.2400
2022-07-26 20:57:54 - train: epoch 0033, iter [03900, 05004], lr: 0.160690, loss: 2.4011
2022-07-26 20:59:54 - train: epoch 0033, iter [04000, 05004], lr: 0.160637, loss: 2.3180
2022-07-26 21:01:37 - train: epoch 0033, iter [04100, 05004], lr: 0.160584, loss: 2.3617
2022-07-26 21:04:00 - train: epoch 0033, iter [04200, 05004], lr: 0.160532, loss: 2.0639
2022-07-26 21:06:05 - train: epoch 0033, iter [04300, 05004], lr: 0.160479, loss: 2.3356
2022-07-26 21:08:12 - train: epoch 0033, iter [04400, 05004], lr: 0.160427, loss: 2.2210
2022-07-26 21:10:13 - train: epoch 0033, iter [04500, 05004], lr: 0.160374, loss: 2.3854
2022-07-26 21:12:15 - train: epoch 0033, iter [04600, 05004], lr: 0.160321, loss: 2.3165
2022-07-26 21:14:20 - train: epoch 0033, iter [04700, 05004], lr: 0.160269, loss: 2.3308
2022-07-26 21:16:20 - train: epoch 0033, iter [04800, 05004], lr: 0.160216, loss: 2.6958
2022-07-26 21:18:17 - train: epoch 0033, iter [04900, 05004], lr: 0.160163, loss: 2.0548
2022-07-26 21:20:12 - train: epoch 0033, iter [05000, 05004], lr: 0.160110, loss: 2.1998
2022-07-26 21:20:16 - train: epoch 033, train_loss: 2.1999
2022-07-26 21:24:17 - eval: epoch: 033, acc1: 51.468%, acc5: 76.826%, test_loss: 2.0981, per_image_load_time: 8.427ms, per_image_inference_time: 0.662ms
2022-07-26 21:24:18 - until epoch: 033, best_acc1: 54.440%
2022-07-26 21:24:18 - epoch 034 lr: 0.160108
2022-07-26 21:26:32 - train: epoch 0034, iter [00100, 05004], lr: 0.160055, loss: 2.1915
2022-07-26 21:28:33 - train: epoch 0034, iter [00200, 05004], lr: 0.160002, loss: 1.8929
2022-07-26 21:30:27 - train: epoch 0034, iter [00300, 05004], lr: 0.159950, loss: 2.0313
2022-07-26 21:32:22 - train: epoch 0034, iter [00400, 05004], lr: 0.159897, loss: 2.0201
2022-07-26 21:34:22 - train: epoch 0034, iter [00500, 05004], lr: 0.159844, loss: 2.2305
2022-07-26 21:36:16 - train: epoch 0034, iter [00600, 05004], lr: 0.159791, loss: 2.3476
2022-07-26 21:38:22 - train: epoch 0034, iter [00700, 05004], lr: 0.159738, loss: 2.1404
2022-07-26 21:40:18 - train: epoch 0034, iter [00800, 05004], lr: 0.159685, loss: 2.2258
2022-07-26 21:42:23 - train: epoch 0034, iter [00900, 05004], lr: 0.159632, loss: 2.1837
2022-07-26 21:44:27 - train: epoch 0034, iter [01000, 05004], lr: 0.159579, loss: 1.9712
2022-07-26 21:46:27 - train: epoch 0034, iter [01100, 05004], lr: 0.159526, loss: 2.1713
2022-07-26 21:48:29 - train: epoch 0034, iter [01200, 05004], lr: 0.159472, loss: 2.2172
2022-07-26 21:50:27 - train: epoch 0034, iter [01300, 05004], lr: 0.159419, loss: 2.0384
2022-07-26 21:52:32 - train: epoch 0034, iter [01400, 05004], lr: 0.159366, loss: 2.2141
2022-07-26 21:54:32 - train: epoch 0034, iter [01500, 05004], lr: 0.159313, loss: 2.2410
2022-07-26 21:56:32 - train: epoch 0034, iter [01600, 05004], lr: 0.159260, loss: 2.3213
2022-07-26 21:58:37 - train: epoch 0034, iter [01700, 05004], lr: 0.159206, loss: 2.0603
2022-07-26 22:00:38 - train: epoch 0034, iter [01800, 05004], lr: 0.159153, loss: 2.2922
2022-07-26 22:02:42 - train: epoch 0034, iter [01900, 05004], lr: 0.159100, loss: 2.3006
2022-07-26 22:04:42 - train: epoch 0034, iter [02000, 05004], lr: 0.159047, loss: 2.0614
2022-07-26 22:06:38 - train: epoch 0034, iter [02100, 05004], lr: 0.158993, loss: 2.0945
2022-07-26 22:08:44 - train: epoch 0034, iter [02200, 05004], lr: 0.158940, loss: 1.9168
2022-07-26 22:10:44 - train: epoch 0034, iter [02300, 05004], lr: 0.158886, loss: 2.1723
2022-07-26 22:12:41 - train: epoch 0034, iter [02400, 05004], lr: 0.158833, loss: 1.9700
2022-07-26 22:14:40 - train: epoch 0034, iter [02500, 05004], lr: 0.158780, loss: 2.2940
2022-07-26 22:16:41 - train: epoch 0034, iter [02600, 05004], lr: 0.158726, loss: 2.3235
2022-07-26 22:18:47 - train: epoch 0034, iter [02700, 05004], lr: 0.158673, loss: 2.2499
2022-07-26 22:20:46 - train: epoch 0034, iter [02800, 05004], lr: 0.158619, loss: 1.8359
2022-07-26 22:22:53 - train: epoch 0034, iter [02900, 05004], lr: 0.158566, loss: 2.1003
2022-07-26 22:25:00 - train: epoch 0034, iter [03000, 05004], lr: 0.158512, loss: 1.9905
2022-07-26 22:27:08 - train: epoch 0034, iter [03100, 05004], lr: 0.158458, loss: 2.1594
2022-07-26 22:29:18 - train: epoch 0034, iter [03200, 05004], lr: 0.158405, loss: 2.1837
2022-07-26 22:31:36 - train: epoch 0034, iter [03300, 05004], lr: 0.158351, loss: 2.0226
2022-07-26 22:33:45 - train: epoch 0034, iter [03400, 05004], lr: 0.158297, loss: 2.3975
2022-07-26 22:36:00 - train: epoch 0034, iter [03500, 05004], lr: 0.158244, loss: 2.0505
2022-07-26 22:38:10 - train: epoch 0034, iter [03600, 05004], lr: 0.158190, loss: 1.7409
2022-07-26 22:40:19 - train: epoch 0034, iter [03700, 05004], lr: 0.158136, loss: 2.1316
2022-07-26 22:42:23 - train: epoch 0034, iter [03800, 05004], lr: 0.158082, loss: 2.0879
2022-07-26 22:44:27 - train: epoch 0034, iter [03900, 05004], lr: 0.158029, loss: 2.4866
2022-07-26 22:46:16 - train: epoch 0034, iter [04000, 05004], lr: 0.157975, loss: 2.0173
2022-07-26 22:48:47 - train: epoch 0034, iter [04100, 05004], lr: 0.157921, loss: 2.2548
2022-07-26 22:50:51 - train: epoch 0034, iter [04200, 05004], lr: 0.157867, loss: 2.1931
2022-07-26 22:53:04 - train: epoch 0034, iter [04300, 05004], lr: 0.157813, loss: 2.2676
2022-07-26 22:55:13 - train: epoch 0034, iter [04400, 05004], lr: 0.157759, loss: 2.1224
2022-07-26 22:57:22 - train: epoch 0034, iter [04500, 05004], lr: 0.157705, loss: 2.2138
2022-07-26 22:59:31 - train: epoch 0034, iter [04600, 05004], lr: 0.157651, loss: 2.2269
2022-07-26 23:01:36 - train: epoch 0034, iter [04700, 05004], lr: 0.157597, loss: 2.0763
2022-07-26 23:03:41 - train: epoch 0034, iter [04800, 05004], lr: 0.157543, loss: 2.1780
2022-07-26 23:05:45 - train: epoch 0034, iter [04900, 05004], lr: 0.157489, loss: 2.1597
2022-07-26 23:07:49 - train: epoch 0034, iter [05000, 05004], lr: 0.157435, loss: 2.0360
2022-07-26 23:07:54 - train: epoch 034, train_loss: 2.1899
2022-07-26 23:12:17 - eval: epoch: 034, acc1: 55.262%, acc5: 80.194%, test_loss: 1.9036, per_image_load_time: 3.274ms, per_image_inference_time: 0.807ms
2022-07-26 23:12:17 - until epoch: 034, best_acc1: 55.262%
2022-07-26 23:12:17 - epoch 035 lr: 0.157432
2022-07-26 23:14:44 - train: epoch 0035, iter [00100, 05004], lr: 0.157379, loss: 1.8623
2022-07-26 23:16:50 - train: epoch 0035, iter [00200, 05004], lr: 0.157325, loss: 2.0206
2022-07-26 23:18:54 - train: epoch 0035, iter [00300, 05004], lr: 0.157270, loss: 2.2275
2022-07-26 23:20:56 - train: epoch 0035, iter [00400, 05004], lr: 0.157216, loss: 2.0819
2022-07-26 23:23:01 - train: epoch 0035, iter [00500, 05004], lr: 0.157162, loss: 1.9984
2022-07-26 23:25:01 - train: epoch 0035, iter [00600, 05004], lr: 0.157108, loss: 2.2061
2022-07-26 23:27:05 - train: epoch 0035, iter [00700, 05004], lr: 0.157054, loss: 2.2654
2022-07-26 23:29:05 - train: epoch 0035, iter [00800, 05004], lr: 0.156999, loss: 2.1832
2022-07-26 23:31:09 - train: epoch 0035, iter [00900, 05004], lr: 0.156945, loss: 2.2392
2022-07-26 23:33:12 - train: epoch 0035, iter [01000, 05004], lr: 0.156891, loss: 2.1171
2022-07-26 23:35:20 - train: epoch 0035, iter [01100, 05004], lr: 0.156836, loss: 2.2464
2022-07-26 23:37:28 - train: epoch 0035, iter [01200, 05004], lr: 0.156782, loss: 2.0891
2022-07-26 23:39:29 - train: epoch 0035, iter [01300, 05004], lr: 0.156727, loss: 2.3716
2022-07-26 23:41:36 - train: epoch 0035, iter [01400, 05004], lr: 0.156673, loss: 2.2210
2022-07-26 23:43:39 - train: epoch 0035, iter [01500, 05004], lr: 0.156619, loss: 2.2308
2022-07-26 23:45:44 - train: epoch 0035, iter [01600, 05004], lr: 0.156564, loss: 2.1846
2022-07-26 23:47:48 - train: epoch 0035, iter [01700, 05004], lr: 0.156510, loss: 1.9884
2022-07-26 23:49:48 - train: epoch 0035, iter [01800, 05004], lr: 0.156455, loss: 2.2110
2022-07-26 23:51:46 - train: epoch 0035, iter [01900, 05004], lr: 0.156400, loss: 2.0215
2022-07-26 23:53:49 - train: epoch 0035, iter [02000, 05004], lr: 0.156346, loss: 2.4313
2022-07-26 23:55:48 - train: epoch 0035, iter [02100, 05004], lr: 0.156291, loss: 2.1058
2022-07-26 23:57:55 - train: epoch 0035, iter [02200, 05004], lr: 0.156237, loss: 2.4753
2022-07-26 23:59:59 - train: epoch 0035, iter [02300, 05004], lr: 0.156182, loss: 2.1213
2022-07-27 00:02:00 - train: epoch 0035, iter [02400, 05004], lr: 0.156127, loss: 2.4007
2022-07-27 00:04:05 - train: epoch 0035, iter [02500, 05004], lr: 0.156073, loss: 2.1594
2022-07-27 00:06:08 - train: epoch 0035, iter [02600, 05004], lr: 0.156018, loss: 2.1962
2022-07-27 00:08:14 - train: epoch 0035, iter [02700, 05004], lr: 0.155963, loss: 2.1747
2022-07-27 00:10:17 - train: epoch 0035, iter [02800, 05004], lr: 0.155908, loss: 2.0936
2022-07-27 00:12:18 - train: epoch 0035, iter [02900, 05004], lr: 0.155854, loss: 2.2198
2022-07-27 00:14:29 - train: epoch 0035, iter [03000, 05004], lr: 0.155799, loss: 2.0597
2022-07-27 00:16:23 - train: epoch 0035, iter [03100, 05004], lr: 0.155744, loss: 2.3082
2022-07-27 00:18:28 - train: epoch 0035, iter [03200, 05004], lr: 0.155689, loss: 2.1838
2022-07-27 00:20:32 - train: epoch 0035, iter [03300, 05004], lr: 0.155634, loss: 2.1905
2022-07-27 00:22:33 - train: epoch 0035, iter [03400, 05004], lr: 0.155579, loss: 2.4629
2022-07-27 00:24:38 - train: epoch 0035, iter [03500, 05004], lr: 0.155524, loss: 1.9597
2022-07-27 00:26:37 - train: epoch 0035, iter [03600, 05004], lr: 0.155469, loss: 2.2864
2022-07-27 00:28:38 - train: epoch 0035, iter [03700, 05004], lr: 0.155414, loss: 2.0628
2022-07-27 00:30:43 - train: epoch 0035, iter [03800, 05004], lr: 0.155359, loss: 2.1250
2022-07-27 00:32:38 - train: epoch 0035, iter [03900, 05004], lr: 0.155304, loss: 2.0583
2022-07-27 00:34:58 - train: epoch 0035, iter [04000, 05004], lr: 0.155249, loss: 1.9431
2022-07-27 00:36:53 - train: epoch 0035, iter [04100, 05004], lr: 0.155194, loss: 2.4294
2022-07-27 00:39:00 - train: epoch 0035, iter [04200, 05004], lr: 0.155139, loss: 1.9512
2022-07-27 00:41:06 - train: epoch 0035, iter [04300, 05004], lr: 0.155084, loss: 2.3100
2022-07-27 00:43:12 - train: epoch 0035, iter [04400, 05004], lr: 0.155029, loss: 2.1908
2022-07-27 00:45:12 - train: epoch 0035, iter [04500, 05004], lr: 0.154973, loss: 2.2956
2022-07-27 00:47:11 - train: epoch 0035, iter [04600, 05004], lr: 0.154918, loss: 2.0563
2022-07-27 00:49:05 - train: epoch 0035, iter [04700, 05004], lr: 0.154863, loss: 2.3288
2022-07-27 00:51:03 - train: epoch 0035, iter [04800, 05004], lr: 0.154808, loss: 2.5232
2022-07-27 00:52:59 - train: epoch 0035, iter [04900, 05004], lr: 0.154752, loss: 2.2616
2022-07-27 00:54:57 - train: epoch 0035, iter [05000, 05004], lr: 0.154697, loss: 2.0711
2022-07-27 00:55:01 - train: epoch 035, train_loss: 2.1809
2022-07-27 00:59:11 - eval: epoch: 035, acc1: 55.868%, acc5: 80.550%, test_loss: 1.8700, per_image_load_time: 8.825ms, per_image_inference_time: 0.697ms
2022-07-27 00:59:12 - until epoch: 035, best_acc1: 55.868%
2022-07-27 00:59:12 - epoch 036 lr: 0.154694
2022-07-27 01:01:28 - train: epoch 0036, iter [00100, 05004], lr: 0.154639, loss: 2.1031
2022-07-27 01:03:24 - train: epoch 0036, iter [00200, 05004], lr: 0.154584, loss: 2.0849
2022-07-27 01:05:25 - train: epoch 0036, iter [00300, 05004], lr: 0.154529, loss: 1.9792
2022-07-27 01:07:21 - train: epoch 0036, iter [00400, 05004], lr: 0.154473, loss: 2.0709
2022-07-27 01:09:18 - train: epoch 0036, iter [00500, 05004], lr: 0.154418, loss: 2.1606
2022-07-27 01:11:17 - train: epoch 0036, iter [00600, 05004], lr: 0.154362, loss: 1.9481
2022-07-27 01:13:14 - train: epoch 0036, iter [00700, 05004], lr: 0.154307, loss: 2.0680
2022-07-27 01:15:11 - train: epoch 0036, iter [00800, 05004], lr: 0.154251, loss: 2.0585
2022-07-27 01:17:09 - train: epoch 0036, iter [00900, 05004], lr: 0.154196, loss: 2.2884
2022-07-27 01:19:04 - train: epoch 0036, iter [01000, 05004], lr: 0.154140, loss: 2.1227
2022-07-27 01:21:07 - train: epoch 0036, iter [01100, 05004], lr: 0.154085, loss: 2.1210
2022-07-27 01:23:10 - train: epoch 0036, iter [01200, 05004], lr: 0.154029, loss: 2.1695
2022-07-27 01:25:09 - train: epoch 0036, iter [01300, 05004], lr: 0.153974, loss: 1.8962
2022-07-27 01:27:03 - train: epoch 0036, iter [01400, 05004], lr: 0.153918, loss: 2.1573
2022-07-27 01:29:01 - train: epoch 0036, iter [01500, 05004], lr: 0.153862, loss: 2.1659
2022-07-27 01:31:01 - train: epoch 0036, iter [01600, 05004], lr: 0.153807, loss: 2.3253
2022-07-27 01:33:00 - train: epoch 0036, iter [01700, 05004], lr: 0.153751, loss: 2.0605
2022-07-27 01:34:57 - train: epoch 0036, iter [01800, 05004], lr: 0.153695, loss: 2.1341
2022-07-27 01:36:53 - train: epoch 0036, iter [01900, 05004], lr: 0.153639, loss: 2.2920
2022-07-27 01:38:51 - train: epoch 0036, iter [02000, 05004], lr: 0.153584, loss: 2.0850
2022-07-27 01:40:47 - train: epoch 0036, iter [02100, 05004], lr: 0.153528, loss: 2.0828
2022-07-27 01:42:47 - train: epoch 0036, iter [02200, 05004], lr: 0.153472, loss: 2.1459
2022-07-27 01:44:42 - train: epoch 0036, iter [02300, 05004], lr: 0.153416, loss: 2.2248
2022-07-27 01:46:39 - train: epoch 0036, iter [02400, 05004], lr: 0.153360, loss: 2.2832
2022-07-27 01:48:38 - train: epoch 0036, iter [02500, 05004], lr: 0.153304, loss: 2.1902
2022-07-27 01:50:40 - train: epoch 0036, iter [02600, 05004], lr: 0.153248, loss: 2.3257
2022-07-27 01:52:36 - train: epoch 0036, iter [02700, 05004], lr: 0.153192, loss: 1.8220
2022-07-27 01:54:39 - train: epoch 0036, iter [02800, 05004], lr: 0.153136, loss: 2.0721
2022-07-27 01:56:36 - train: epoch 0036, iter [02900, 05004], lr: 0.153080, loss: 1.8744
2022-07-27 01:58:33 - train: epoch 0036, iter [03000, 05004], lr: 0.153024, loss: 2.2923
2022-07-27 02:00:29 - train: epoch 0036, iter [03100, 05004], lr: 0.152968, loss: 2.2285
2022-07-27 02:02:28 - train: epoch 0036, iter [03200, 05004], lr: 0.152912, loss: 2.3325
2022-07-27 02:04:24 - train: epoch 0036, iter [03300, 05004], lr: 0.152856, loss: 2.0451
2022-07-27 02:06:23 - train: epoch 0036, iter [03400, 05004], lr: 0.152800, loss: 1.8814
2022-07-27 02:08:23 - train: epoch 0036, iter [03500, 05004], lr: 0.152744, loss: 2.2617
2022-07-27 02:10:18 - train: epoch 0036, iter [03600, 05004], lr: 0.152688, loss: 2.3666
2022-07-27 02:12:14 - train: epoch 0036, iter [03700, 05004], lr: 0.152632, loss: 2.0431
2022-07-27 02:14:09 - train: epoch 0036, iter [03800, 05004], lr: 0.152575, loss: 2.1778
2022-07-27 02:16:27 - train: epoch 0036, iter [03900, 05004], lr: 0.152519, loss: 2.1510
2022-07-27 02:18:34 - train: epoch 0036, iter [04000, 05004], lr: 0.152463, loss: 2.1480
2022-07-27 02:20:40 - train: epoch 0036, iter [04100, 05004], lr: 0.152407, loss: 2.0460
2022-07-27 02:22:38 - train: epoch 0036, iter [04200, 05004], lr: 0.152350, loss: 2.2542
2022-07-27 02:24:41 - train: epoch 0036, iter [04300, 05004], lr: 0.152294, loss: 2.1716
2022-07-27 02:26:37 - train: epoch 0036, iter [04400, 05004], lr: 0.152238, loss: 2.2366
2022-07-27 02:28:39 - train: epoch 0036, iter [04500, 05004], lr: 0.152181, loss: 2.2222
2022-07-27 02:30:39 - train: epoch 0036, iter [04600, 05004], lr: 0.152125, loss: 2.0130
2022-07-27 02:32:39 - train: epoch 0036, iter [04700, 05004], lr: 0.152069, loss: 2.1906
2022-07-27 02:34:40 - train: epoch 0036, iter [04800, 05004], lr: 0.152012, loss: 2.0722
2022-07-27 02:36:34 - train: epoch 0036, iter [04900, 05004], lr: 0.151956, loss: 2.0273
2022-07-27 02:38:29 - train: epoch 0036, iter [05000, 05004], lr: 0.151899, loss: 1.9693
2022-07-27 02:38:32 - train: epoch 036, train_loss: 2.1692
2022-07-27 02:42:42 - eval: epoch: 036, acc1: 55.244%, acc5: 80.296%, test_loss: 1.8822, per_image_load_time: 8.843ms, per_image_inference_time: 0.685ms
2022-07-27 02:42:42 - until epoch: 036, best_acc1: 55.868%
2022-07-27 02:42:42 - epoch 037 lr: 0.151896
2022-07-27 02:44:58 - train: epoch 0037, iter [00100, 05004], lr: 0.151840, loss: 1.8810
2022-07-27 02:46:51 - train: epoch 0037, iter [00200, 05004], lr: 0.151784, loss: 1.9781
2022-07-27 02:48:50 - train: epoch 0037, iter [00300, 05004], lr: 0.151727, loss: 2.1550
2022-07-27 02:50:49 - train: epoch 0037, iter [00400, 05004], lr: 0.151671, loss: 1.8425
2022-07-27 02:52:50 - train: epoch 0037, iter [00500, 05004], lr: 0.151614, loss: 2.2027
2022-07-27 02:54:50 - train: epoch 0037, iter [00600, 05004], lr: 0.151558, loss: 2.2711
2022-07-27 02:56:51 - train: epoch 0037, iter [00700, 05004], lr: 0.151501, loss: 2.1776
2022-07-27 02:58:51 - train: epoch 0037, iter [00800, 05004], lr: 0.151444, loss: 2.2237
2022-07-27 03:00:50 - train: epoch 0037, iter [00900, 05004], lr: 0.151388, loss: 2.2110
2022-07-27 03:02:49 - train: epoch 0037, iter [01000, 05004], lr: 0.151331, loss: 2.0661
2022-07-27 03:04:49 - train: epoch 0037, iter [01100, 05004], lr: 0.151274, loss: 2.1432
2022-07-27 03:06:49 - train: epoch 0037, iter [01200, 05004], lr: 0.151217, loss: 2.2891
2022-07-27 03:08:50 - train: epoch 0037, iter [01300, 05004], lr: 0.151161, loss: 2.2973
2022-07-27 03:10:45 - train: epoch 0037, iter [01400, 05004], lr: 0.151104, loss: 2.4502
2022-07-27 03:12:41 - train: epoch 0037, iter [01500, 05004], lr: 0.151047, loss: 2.1528
2022-07-27 03:14:37 - train: epoch 0037, iter [01600, 05004], lr: 0.150990, loss: 1.9173
2022-07-27 03:16:40 - train: epoch 0037, iter [01700, 05004], lr: 0.150933, loss: 2.3577
2022-07-27 03:18:36 - train: epoch 0037, iter [01800, 05004], lr: 0.150876, loss: 2.1226
2022-07-27 03:20:31 - train: epoch 0037, iter [01900, 05004], lr: 0.150820, loss: 2.1477
2022-07-27 03:22:29 - train: epoch 0037, iter [02000, 05004], lr: 0.150763, loss: 2.2277
2022-07-27 03:24:22 - train: epoch 0037, iter [02100, 05004], lr: 0.150706, loss: 2.0529
2022-07-27 03:26:26 - train: epoch 0037, iter [02200, 05004], lr: 0.150649, loss: 2.1027
2022-07-27 03:28:21 - train: epoch 0037, iter [02300, 05004], lr: 0.150592, loss: 2.0217
2022-07-27 03:30:20 - train: epoch 0037, iter [02400, 05004], lr: 0.150535, loss: 2.1633
2022-07-27 03:32:19 - train: epoch 0037, iter [02500, 05004], lr: 0.150478, loss: 2.1923
2022-07-27 03:34:20 - train: epoch 0037, iter [02600, 05004], lr: 0.150421, loss: 2.2670
2022-07-27 03:36:19 - train: epoch 0037, iter [02700, 05004], lr: 0.150364, loss: 2.2824
2022-07-27 03:38:17 - train: epoch 0037, iter [02800, 05004], lr: 0.150306, loss: 2.1336
2022-07-27 03:40:11 - train: epoch 0037, iter [02900, 05004], lr: 0.150249, loss: 2.0991
2022-07-27 03:42:12 - train: epoch 0037, iter [03000, 05004], lr: 0.150192, loss: 2.2740
2022-07-27 03:44:07 - train: epoch 0037, iter [03100, 05004], lr: 0.150135, loss: 2.0652
2022-07-27 03:46:03 - train: epoch 0037, iter [03200, 05004], lr: 0.150078, loss: 2.2598
2022-07-27 03:48:06 - train: epoch 0037, iter [03300, 05004], lr: 0.150021, loss: 2.1841
2022-07-27 03:50:05 - train: epoch 0037, iter [03400, 05004], lr: 0.149963, loss: 2.0939
2022-07-27 03:52:05 - train: epoch 0037, iter [03500, 05004], lr: 0.149906, loss: 2.0476
2022-07-27 03:54:01 - train: epoch 0037, iter [03600, 05004], lr: 0.149849, loss: 2.1282
2022-07-27 03:55:55 - train: epoch 0037, iter [03700, 05004], lr: 0.149792, loss: 2.1918
2022-07-27 03:58:05 - train: epoch 0037, iter [03800, 05004], lr: 0.149734, loss: 2.2775
2022-07-27 04:00:16 - train: epoch 0037, iter [03900, 05004], lr: 0.149677, loss: 2.0678
2022-07-27 04:02:17 - train: epoch 0037, iter [04000, 05004], lr: 0.149619, loss: 2.0823
2022-07-27 04:04:25 - train: epoch 0037, iter [04100, 05004], lr: 0.149562, loss: 2.0111
2022-07-27 04:06:27 - train: epoch 0037, iter [04200, 05004], lr: 0.149505, loss: 2.2646
2022-07-27 04:08:29 - train: epoch 0037, iter [04300, 05004], lr: 0.149447, loss: 2.1537
2022-07-27 04:10:23 - train: epoch 0037, iter [04400, 05004], lr: 0.149390, loss: 2.1194
2022-07-27 04:12:23 - train: epoch 0037, iter [04500, 05004], lr: 0.149332, loss: 2.0601
2022-07-27 04:14:24 - train: epoch 0037, iter [04600, 05004], lr: 0.149275, loss: 2.0682
2022-07-27 04:16:21 - train: epoch 0037, iter [04700, 05004], lr: 0.149217, loss: 2.3271
2022-07-27 04:18:19 - train: epoch 0037, iter [04800, 05004], lr: 0.149160, loss: 1.9905
2022-07-27 04:20:25 - train: epoch 0037, iter [04900, 05004], lr: 0.149102, loss: 2.2490
2022-07-27 04:22:22 - train: epoch 0037, iter [05000, 05004], lr: 0.149045, loss: 2.0305
2022-07-27 04:22:26 - train: epoch 037, train_loss: 2.1598
2022-07-27 04:26:33 - eval: epoch: 037, acc1: 55.204%, acc5: 80.222%, test_loss: 1.8831, per_image_load_time: 8.744ms, per_image_inference_time: 0.701ms
2022-07-27 04:26:34 - until epoch: 037, best_acc1: 55.868%
2022-07-27 04:26:34 - epoch 038 lr: 0.149042
2022-07-27 04:28:46 - train: epoch 0038, iter [00100, 05004], lr: 0.148985, loss: 1.9976
2022-07-27 04:30:42 - train: epoch 0038, iter [00200, 05004], lr: 0.148927, loss: 2.0800
2022-07-27 04:32:38 - train: epoch 0038, iter [00300, 05004], lr: 0.148869, loss: 1.9797
2022-07-27 04:34:43 - train: epoch 0038, iter [00400, 05004], lr: 0.148812, loss: 2.0393
2022-07-27 04:36:41 - train: epoch 0038, iter [00500, 05004], lr: 0.148754, loss: 2.0537
2022-07-27 04:38:39 - train: epoch 0038, iter [00600, 05004], lr: 0.148696, loss: 2.3160
2022-07-27 04:40:34 - train: epoch 0038, iter [00700, 05004], lr: 0.148639, loss: 1.8683
2022-07-27 04:42:33 - train: epoch 0038, iter [00800, 05004], lr: 0.148581, loss: 2.1358
2022-07-27 04:44:28 - train: epoch 0038, iter [00900, 05004], lr: 0.148523, loss: 2.2494
2022-07-27 04:46:23 - train: epoch 0038, iter [01000, 05004], lr: 0.148465, loss: 2.2063
2022-07-27 04:48:25 - train: epoch 0038, iter [01100, 05004], lr: 0.148408, loss: 2.3065
2022-07-27 04:50:22 - train: epoch 0038, iter [01200, 05004], lr: 0.148350, loss: 2.3300
2022-07-27 04:52:23 - train: epoch 0038, iter [01300, 05004], lr: 0.148292, loss: 2.1963
2022-07-27 04:54:19 - train: epoch 0038, iter [01400, 05004], lr: 0.148234, loss: 2.1607
2022-07-27 04:56:18 - train: epoch 0038, iter [01500, 05004], lr: 0.148176, loss: 1.9369
2022-07-27 04:58:15 - train: epoch 0038, iter [01600, 05004], lr: 0.148118, loss: 2.1860
2022-07-27 05:00:09 - train: epoch 0038, iter [01700, 05004], lr: 0.148060, loss: 2.3484
2022-07-27 05:02:07 - train: epoch 0038, iter [01800, 05004], lr: 0.148002, loss: 2.1098
2022-07-27 05:04:06 - train: epoch 0038, iter [01900, 05004], lr: 0.147944, loss: 1.9564
2022-07-27 05:06:06 - train: epoch 0038, iter [02000, 05004], lr: 0.147886, loss: 1.9781
2022-07-27 05:08:02 - train: epoch 0038, iter [02100, 05004], lr: 0.147828, loss: 2.2381
2022-07-27 05:09:57 - train: epoch 0038, iter [02200, 05004], lr: 0.147770, loss: 2.1512
2022-07-27 05:11:56 - train: epoch 0038, iter [02300, 05004], lr: 0.147712, loss: 2.1326
2022-07-27 05:13:54 - train: epoch 0038, iter [02400, 05004], lr: 0.147654, loss: 2.4246
2022-07-27 05:15:50 - train: epoch 0038, iter [02500, 05004], lr: 0.147596, loss: 1.9890
2022-07-27 05:17:48 - train: epoch 0038, iter [02600, 05004], lr: 0.147538, loss: 2.1162
2022-07-27 05:19:47 - train: epoch 0038, iter [02700, 05004], lr: 0.147480, loss: 2.2207
2022-07-27 05:21:45 - train: epoch 0038, iter [02800, 05004], lr: 0.147421, loss: 2.2882
2022-07-27 05:23:42 - train: epoch 0038, iter [02900, 05004], lr: 0.147363, loss: 2.1167
2022-07-27 05:25:39 - train: epoch 0038, iter [03000, 05004], lr: 0.147305, loss: 2.1535
2022-07-27 05:27:43 - train: epoch 0038, iter [03100, 05004], lr: 0.147247, loss: 2.1048
2022-07-27 05:29:37 - train: epoch 0038, iter [03200, 05004], lr: 0.147189, loss: 1.9267
2022-07-27 05:31:39 - train: epoch 0038, iter [03300, 05004], lr: 0.147130, loss: 2.0691
2022-07-27 05:33:35 - train: epoch 0038, iter [03400, 05004], lr: 0.147072, loss: 2.1284
2022-07-27 05:35:34 - train: epoch 0038, iter [03500, 05004], lr: 0.147014, loss: 2.1525
2022-07-27 05:37:31 - train: epoch 0038, iter [03600, 05004], lr: 0.146955, loss: 2.1262
2022-07-27 05:39:27 - train: epoch 0038, iter [03700, 05004], lr: 0.146897, loss: 1.9904
2022-07-27 05:41:51 - train: epoch 0038, iter [03800, 05004], lr: 0.146839, loss: 2.2917
2022-07-27 05:43:48 - train: epoch 0038, iter [03900, 05004], lr: 0.146780, loss: 2.1358
2022-07-27 05:45:52 - train: epoch 0038, iter [04000, 05004], lr: 0.146722, loss: 2.2569
2022-07-27 05:47:59 - train: epoch 0038, iter [04100, 05004], lr: 0.146663, loss: 1.9974
2022-07-27 05:50:01 - train: epoch 0038, iter [04200, 05004], lr: 0.146605, loss: 1.8519
2022-07-27 05:52:01 - train: epoch 0038, iter [04300, 05004], lr: 0.146546, loss: 2.1897
2022-07-27 05:54:03 - train: epoch 0038, iter [04400, 05004], lr: 0.146488, loss: 2.3181
2022-07-27 05:56:03 - train: epoch 0038, iter [04500, 05004], lr: 0.146429, loss: 2.2786
2022-07-27 05:58:03 - train: epoch 0038, iter [04600, 05004], lr: 0.146371, loss: 2.1742
2022-07-27 06:00:00 - train: epoch 0038, iter [04700, 05004], lr: 0.146312, loss: 2.0465
2022-07-27 06:01:56 - train: epoch 0038, iter [04800, 05004], lr: 0.146254, loss: 2.0544
2022-07-27 06:03:57 - train: epoch 0038, iter [04900, 05004], lr: 0.146195, loss: 1.9132
2022-07-27 06:05:55 - train: epoch 0038, iter [05000, 05004], lr: 0.146136, loss: 1.9555
2022-07-27 06:05:59 - train: epoch 038, train_loss: 2.1473
2022-07-27 06:10:09 - eval: epoch: 038, acc1: 54.666%, acc5: 79.816%, test_loss: 1.9141, per_image_load_time: 8.936ms, per_image_inference_time: 0.651ms
2022-07-27 06:10:09 - until epoch: 038, best_acc1: 55.868%
2022-07-27 06:10:09 - epoch 039 lr: 0.146134
2022-07-27 06:12:23 - train: epoch 0039, iter [00100, 05004], lr: 0.146075, loss: 1.9299
2022-07-27 06:14:23 - train: epoch 0039, iter [00200, 05004], lr: 0.146017, loss: 2.2132
2022-07-27 06:16:18 - train: epoch 0039, iter [00300, 05004], lr: 0.145958, loss: 2.0782
2022-07-27 06:18:16 - train: epoch 0039, iter [00400, 05004], lr: 0.145899, loss: 2.0374
2022-07-27 06:20:12 - train: epoch 0039, iter [00500, 05004], lr: 0.145841, loss: 2.2288
2022-07-27 06:22:10 - train: epoch 0039, iter [00600, 05004], lr: 0.145782, loss: 1.9862
2022-07-27 06:24:10 - train: epoch 0039, iter [00700, 05004], lr: 0.145723, loss: 2.3263
2022-07-27 06:26:07 - train: epoch 0039, iter [00800, 05004], lr: 0.145664, loss: 2.0170
2022-07-27 06:28:08 - train: epoch 0039, iter [00900, 05004], lr: 0.145606, loss: 2.2453
2022-07-27 06:30:06 - train: epoch 0039, iter [01000, 05004], lr: 0.145547, loss: 2.1609
2022-07-27 06:32:02 - train: epoch 0039, iter [01100, 05004], lr: 0.145488, loss: 2.2185
2022-07-27 06:34:02 - train: epoch 0039, iter [01200, 05004], lr: 0.145429, loss: 2.3100
2022-07-27 06:35:58 - train: epoch 0039, iter [01300, 05004], lr: 0.145370, loss: 2.1842
2022-07-27 06:37:53 - train: epoch 0039, iter [01400, 05004], lr: 0.145311, loss: 2.3371
2022-07-27 06:39:50 - train: epoch 0039, iter [01500, 05004], lr: 0.145252, loss: 2.0203
2022-07-27 06:41:44 - train: epoch 0039, iter [01600, 05004], lr: 0.145193, loss: 2.2961
2022-07-27 06:43:44 - train: epoch 0039, iter [01700, 05004], lr: 0.145134, loss: 1.9166
2022-07-27 06:45:45 - train: epoch 0039, iter [01800, 05004], lr: 0.145075, loss: 2.0180
2022-07-27 06:47:41 - train: epoch 0039, iter [01900, 05004], lr: 0.145016, loss: 1.7052
2022-07-27 06:49:37 - train: epoch 0039, iter [02000, 05004], lr: 0.144957, loss: 1.9987
2022-07-27 06:51:33 - train: epoch 0039, iter [02100, 05004], lr: 0.144898, loss: 2.3286
2022-07-27 06:53:28 - train: epoch 0039, iter [02200, 05004], lr: 0.144839, loss: 2.0925
2022-07-27 06:55:26 - train: epoch 0039, iter [02300, 05004], lr: 0.144780, loss: 2.4392
2022-07-27 06:57:26 - train: epoch 0039, iter [02400, 05004], lr: 0.144721, loss: 2.3611
2022-07-27 06:59:21 - train: epoch 0039, iter [02500, 05004], lr: 0.144662, loss: 2.0841
2022-07-27 07:01:23 - train: epoch 0039, iter [02600, 05004], lr: 0.144603, loss: 2.1588
2022-07-27 07:03:26 - train: epoch 0039, iter [02700, 05004], lr: 0.144544, loss: 2.2319
2022-07-27 07:05:25 - train: epoch 0039, iter [02800, 05004], lr: 0.144485, loss: 2.0792
2022-07-27 07:07:19 - train: epoch 0039, iter [02900, 05004], lr: 0.144425, loss: 1.9775
2022-07-27 07:09:19 - train: epoch 0039, iter [03000, 05004], lr: 0.144366, loss: 2.0106
2022-07-27 07:11:16 - train: epoch 0039, iter [03100, 05004], lr: 0.144307, loss: 2.0089
2022-07-27 07:13:16 - train: epoch 0039, iter [03200, 05004], lr: 0.144248, loss: 2.1870
2022-07-27 07:15:12 - train: epoch 0039, iter [03300, 05004], lr: 0.144188, loss: 2.2235
2022-07-27 07:17:07 - train: epoch 0039, iter [03400, 05004], lr: 0.144129, loss: 2.1837
2022-07-27 07:19:07 - train: epoch 0039, iter [03500, 05004], lr: 0.144070, loss: 2.3850
2022-07-27 07:20:57 - train: epoch 0039, iter [03600, 05004], lr: 0.144010, loss: 2.2882
2022-07-27 07:23:27 - train: epoch 0039, iter [03700, 05004], lr: 0.143951, loss: 2.1449
2022-07-27 07:25:33 - train: epoch 0039, iter [03800, 05004], lr: 0.143892, loss: 2.0223
2022-07-27 07:27:36 - train: epoch 0039, iter [03900, 05004], lr: 0.143832, loss: 2.0929
2022-07-27 07:29:45 - train: epoch 0039, iter [04000, 05004], lr: 0.143773, loss: 2.2396
2022-07-27 07:31:49 - train: epoch 0039, iter [04100, 05004], lr: 0.143714, loss: 2.2334
2022-07-27 07:33:52 - train: epoch 0039, iter [04200, 05004], lr: 0.143654, loss: 2.2809
2022-07-27 07:35:50 - train: epoch 0039, iter [04300, 05004], lr: 0.143595, loss: 1.9821
2022-07-27 07:37:47 - train: epoch 0039, iter [04400, 05004], lr: 0.143535, loss: 2.1830
2022-07-27 07:39:47 - train: epoch 0039, iter [04500, 05004], lr: 0.143476, loss: 2.0715
2022-07-27 07:41:44 - train: epoch 0039, iter [04600, 05004], lr: 0.143416, loss: 2.1155
2022-07-27 07:43:42 - train: epoch 0039, iter [04700, 05004], lr: 0.143357, loss: 2.2046
2022-07-27 07:45:39 - train: epoch 0039, iter [04800, 05004], lr: 0.143297, loss: 2.1755
2022-07-27 07:47:41 - train: epoch 0039, iter [04900, 05004], lr: 0.143237, loss: 2.1352
2022-07-27 07:49:42 - train: epoch 0039, iter [05000, 05004], lr: 0.143178, loss: 2.1817
2022-07-27 07:49:46 - train: epoch 039, train_loss: 2.1360
2022-07-27 07:54:04 - eval: epoch: 039, acc1: 55.394%, acc5: 80.428%, test_loss: 1.8803, per_image_load_time: 9.000ms, per_image_inference_time: 0.721ms
2022-07-27 07:54:04 - until epoch: 039, best_acc1: 55.868%
2022-07-27 07:54:04 - epoch 040 lr: 0.143175
2022-07-27 07:56:23 - train: epoch 0040, iter [00100, 05004], lr: 0.143116, loss: 2.3173
2022-07-27 07:58:25 - train: epoch 0040, iter [00200, 05004], lr: 0.143056, loss: 2.1631
2022-07-27 08:00:38 - train: epoch 0040, iter [00300, 05004], lr: 0.142997, loss: 2.1759
2022-07-27 08:02:46 - train: epoch 0040, iter [00400, 05004], lr: 0.142937, loss: 2.1089
2022-07-27 08:04:49 - train: epoch 0040, iter [00500, 05004], lr: 0.142877, loss: 1.8203
2022-07-27 08:06:55 - train: epoch 0040, iter [00600, 05004], lr: 0.142817, loss: 2.1451
2022-07-27 08:09:00 - train: epoch 0040, iter [00700, 05004], lr: 0.142758, loss: 1.9943
2022-07-27 08:11:00 - train: epoch 0040, iter [00800, 05004], lr: 0.142698, loss: 2.1001
2022-07-27 08:13:05 - train: epoch 0040, iter [00900, 05004], lr: 0.142638, loss: 1.9478
2022-07-27 08:15:07 - train: epoch 0040, iter [01000, 05004], lr: 0.142578, loss: 2.0352
2022-07-27 08:17:13 - train: epoch 0040, iter [01100, 05004], lr: 0.142519, loss: 1.8801
2022-07-27 08:19:12 - train: epoch 0040, iter [01200, 05004], lr: 0.142459, loss: 2.1148
2022-07-27 08:21:17 - train: epoch 0040, iter [01300, 05004], lr: 0.142399, loss: 2.1049
2022-07-27 08:23:22 - train: epoch 0040, iter [01400, 05004], lr: 0.142339, loss: 2.2273
2022-07-27 08:25:22 - train: epoch 0040, iter [01500, 05004], lr: 0.142279, loss: 2.1981
2022-07-27 08:27:25 - train: epoch 0040, iter [01600, 05004], lr: 0.142219, loss: 2.1983
2022-07-27 08:29:27 - train: epoch 0040, iter [01700, 05004], lr: 0.142159, loss: 2.1223
2022-07-27 08:31:25 - train: epoch 0040, iter [01800, 05004], lr: 0.142099, loss: 1.9490
2022-07-27 08:33:32 - train: epoch 0040, iter [01900, 05004], lr: 0.142039, loss: 1.9319
2022-07-27 08:35:33 - train: epoch 0040, iter [02000, 05004], lr: 0.141980, loss: 2.2746
2022-07-27 08:37:35 - train: epoch 0040, iter [02100, 05004], lr: 0.141920, loss: 2.0413
2022-07-27 08:39:47 - train: epoch 0040, iter [02200, 05004], lr: 0.141860, loss: 1.8451
2022-07-27 08:41:48 - train: epoch 0040, iter [02300, 05004], lr: 0.141799, loss: 2.1506
2022-07-27 08:43:54 - train: epoch 0040, iter [02400, 05004], lr: 0.141739, loss: 2.2227
2022-07-27 08:45:57 - train: epoch 0040, iter [02500, 05004], lr: 0.141679, loss: 2.2415
2022-07-27 08:47:55 - train: epoch 0040, iter [02600, 05004], lr: 0.141619, loss: 2.0104
2022-07-27 08:49:54 - train: epoch 0040, iter [02700, 05004], lr: 0.141559, loss: 2.2135
2022-07-27 08:51:54 - train: epoch 0040, iter [02800, 05004], lr: 0.141499, loss: 2.1120
2022-07-27 08:53:58 - train: epoch 0040, iter [02900, 05004], lr: 0.141439, loss: 2.4777
2022-07-27 08:56:00 - train: epoch 0040, iter [03000, 05004], lr: 0.141379, loss: 2.0551
2022-07-27 08:58:06 - train: epoch 0040, iter [03100, 05004], lr: 0.141319, loss: 2.1514
2022-07-27 09:00:05 - train: epoch 0040, iter [03200, 05004], lr: 0.141258, loss: 2.4161
2022-07-27 09:02:12 - train: epoch 0040, iter [03300, 05004], lr: 0.141198, loss: 2.3538
2022-07-27 09:04:11 - train: epoch 0040, iter [03400, 05004], lr: 0.141138, loss: 2.0312
2022-07-27 09:06:11 - train: epoch 0040, iter [03500, 05004], lr: 0.141078, loss: 2.1618
2022-07-27 09:08:46 - train: epoch 0040, iter [03600, 05004], lr: 0.141017, loss: 2.1312
2022-07-27 09:10:48 - train: epoch 0040, iter [03700, 05004], lr: 0.140957, loss: 2.0678
2022-07-27 09:12:54 - train: epoch 0040, iter [03800, 05004], lr: 0.140897, loss: 2.0258
2022-07-27 09:15:06 - train: epoch 0040, iter [03900, 05004], lr: 0.140837, loss: 2.1500
2022-07-27 09:17:17 - train: epoch 0040, iter [04000, 05004], lr: 0.140776, loss: 2.2141
2022-07-27 09:19:29 - train: epoch 0040, iter [04100, 05004], lr: 0.140716, loss: 2.0631
2022-07-27 09:21:34 - train: epoch 0040, iter [04200, 05004], lr: 0.140656, loss: 2.0911
2022-07-27 09:23:39 - train: epoch 0040, iter [04300, 05004], lr: 0.140595, loss: 2.2352
2022-07-27 09:25:42 - train: epoch 0040, iter [04400, 05004], lr: 0.140535, loss: 2.1532
2022-07-27 09:27:47 - train: epoch 0040, iter [04500, 05004], lr: 0.140474, loss: 1.8987
2022-07-27 09:29:53 - train: epoch 0040, iter [04600, 05004], lr: 0.140414, loss: 2.1951
2022-07-27 09:31:59 - train: epoch 0040, iter [04700, 05004], lr: 0.140353, loss: 2.1703
2022-07-27 09:33:58 - train: epoch 0040, iter [04800, 05004], lr: 0.140293, loss: 1.9918
2022-07-27 09:35:59 - train: epoch 0040, iter [04900, 05004], lr: 0.140232, loss: 2.0478
2022-07-27 09:38:01 - train: epoch 0040, iter [05000, 05004], lr: 0.140172, loss: 2.1660
2022-07-27 09:38:05 - train: epoch 040, train_loss: 2.1235
2022-07-27 09:42:28 - eval: epoch: 040, acc1: 55.850%, acc5: 80.676%, test_loss: 1.8549, per_image_load_time: 4.684ms, per_image_inference_time: 0.776ms
2022-07-27 09:42:29 - until epoch: 040, best_acc1: 55.868%
2022-07-27 09:42:29 - epoch 041 lr: 0.140169
2022-07-27 09:44:56 - train: epoch 0041, iter [00100, 05004], lr: 0.140109, loss: 2.3175
2022-07-27 09:46:59 - train: epoch 0041, iter [00200, 05004], lr: 0.140048, loss: 2.1718
2022-07-27 09:49:04 - train: epoch 0041, iter [00300, 05004], lr: 0.139988, loss: 2.0332
2022-07-27 09:51:07 - train: epoch 0041, iter [00400, 05004], lr: 0.139927, loss: 2.2432
2022-07-27 09:53:17 - train: epoch 0041, iter [00500, 05004], lr: 0.139867, loss: 1.8864
2022-07-27 09:55:20 - train: epoch 0041, iter [00600, 05004], lr: 0.139806, loss: 2.2112
2022-07-27 09:57:19 - train: epoch 0041, iter [00700, 05004], lr: 0.139745, loss: 1.8377
2022-07-27 09:59:24 - train: epoch 0041, iter [00800, 05004], lr: 0.139685, loss: 2.1949
2022-07-27 10:01:27 - train: epoch 0041, iter [00900, 05004], lr: 0.139624, loss: 2.0140
2022-07-27 10:03:28 - train: epoch 0041, iter [01000, 05004], lr: 0.139563, loss: 2.3665
2022-07-27 10:05:27 - train: epoch 0041, iter [01100, 05004], lr: 0.139503, loss: 2.0922
2022-07-27 10:07:28 - train: epoch 0041, iter [01200, 05004], lr: 0.139442, loss: 2.1055
2022-07-27 10:09:31 - train: epoch 0041, iter [01300, 05004], lr: 0.139381, loss: 1.9269
2022-07-27 10:11:36 - train: epoch 0041, iter [01400, 05004], lr: 0.139321, loss: 2.2333
2022-07-27 10:13:38 - train: epoch 0041, iter [01500, 05004], lr: 0.139260, loss: 2.4119
2022-07-27 10:15:40 - train: epoch 0041, iter [01600, 05004], lr: 0.139199, loss: 2.1601
2022-07-27 10:17:43 - train: epoch 0041, iter [01700, 05004], lr: 0.139138, loss: 2.1915
2022-07-27 10:19:49 - train: epoch 0041, iter [01800, 05004], lr: 0.139077, loss: 2.0431
2022-07-27 10:21:53 - train: epoch 0041, iter [01900, 05004], lr: 0.139017, loss: 2.3222
2022-07-27 10:23:53 - train: epoch 0041, iter [02000, 05004], lr: 0.138956, loss: 2.1463
2022-07-27 10:25:52 - train: epoch 0041, iter [02100, 05004], lr: 0.138895, loss: 1.9806
2022-07-27 10:27:51 - train: epoch 0041, iter [02200, 05004], lr: 0.138834, loss: 1.7769
2022-07-27 10:29:48 - train: epoch 0041, iter [02300, 05004], lr: 0.138773, loss: 2.0104
2022-07-27 10:31:53 - train: epoch 0041, iter [02400, 05004], lr: 0.138712, loss: 2.0294
2022-07-27 10:33:53 - train: epoch 0041, iter [02500, 05004], lr: 0.138651, loss: 2.0953
2022-07-27 10:35:58 - train: epoch 0041, iter [02600, 05004], lr: 0.138590, loss: 2.3912
2022-07-27 10:37:57 - train: epoch 0041, iter [02700, 05004], lr: 0.138529, loss: 2.3303
2022-07-27 10:40:00 - train: epoch 0041, iter [02800, 05004], lr: 0.138468, loss: 2.0582
2022-07-27 10:41:59 - train: epoch 0041, iter [02900, 05004], lr: 0.138407, loss: 2.1590
2022-07-27 10:44:03 - train: epoch 0041, iter [03000, 05004], lr: 0.138346, loss: 2.1671
2022-07-27 10:46:10 - train: epoch 0041, iter [03100, 05004], lr: 0.138285, loss: 2.2317
2022-07-27 10:48:13 - train: epoch 0041, iter [03200, 05004], lr: 0.138224, loss: 1.8956
2022-07-27 10:50:14 - train: epoch 0041, iter [03300, 05004], lr: 0.138163, loss: 2.0459
2022-07-27 10:52:24 - train: epoch 0041, iter [03400, 05004], lr: 0.138102, loss: 1.9816
2022-07-27 10:54:47 - train: epoch 0041, iter [03500, 05004], lr: 0.138041, loss: 2.2982
2022-07-27 10:56:59 - train: epoch 0041, iter [03600, 05004], lr: 0.137980, loss: 2.1349
2022-07-27 10:59:12 - train: epoch 0041, iter [03700, 05004], lr: 0.137919, loss: 2.0114
2022-07-27 11:01:12 - train: epoch 0041, iter [03800, 05004], lr: 0.137857, loss: 2.1282
2022-07-27 11:03:18 - train: epoch 0041, iter [03900, 05004], lr: 0.137796, loss: 2.1972
2022-07-27 11:05:13 - train: epoch 0041, iter [04000, 05004], lr: 0.137735, loss: 1.7754
2022-07-27 11:07:12 - train: epoch 0041, iter [04100, 05004], lr: 0.137674, loss: 2.1818
2022-07-27 11:09:10 - train: epoch 0041, iter [04200, 05004], lr: 0.137613, loss: 2.0060
2022-07-27 11:11:08 - train: epoch 0041, iter [04300, 05004], lr: 0.137551, loss: 2.0089
2022-07-27 11:13:05 - train: epoch 0041, iter [04400, 05004], lr: 0.137490, loss: 1.8089
2022-07-27 11:15:02 - train: epoch 0041, iter [04500, 05004], lr: 0.137429, loss: 2.1178
2022-07-27 11:17:03 - train: epoch 0041, iter [04600, 05004], lr: 0.137368, loss: 2.3354
2022-07-27 11:19:04 - train: epoch 0041, iter [04700, 05004], lr: 0.137306, loss: 2.0648
2022-07-27 11:21:01 - train: epoch 0041, iter [04800, 05004], lr: 0.137245, loss: 2.2090
2022-07-27 11:23:04 - train: epoch 0041, iter [04900, 05004], lr: 0.137184, loss: 2.3597
2022-07-27 11:24:56 - train: epoch 0041, iter [05000, 05004], lr: 0.137122, loss: 2.2946
2022-07-27 11:25:00 - train: epoch 041, train_loss: 2.1165
2022-07-27 11:29:18 - eval: epoch: 041, acc1: 56.578%, acc5: 81.110%, test_loss: 1.8346, per_image_load_time: 9.180ms, per_image_inference_time: 0.681ms
2022-07-27 11:29:18 - until epoch: 041, best_acc1: 56.578%
2022-07-27 11:29:18 - epoch 042 lr: 0.137119
2022-07-27 11:31:36 - train: epoch 0042, iter [00100, 05004], lr: 0.137058, loss: 1.9059
2022-07-27 11:33:33 - train: epoch 0042, iter [00200, 05004], lr: 0.136997, loss: 2.0975
2022-07-27 11:35:39 - train: epoch 0042, iter [00300, 05004], lr: 0.136936, loss: 2.1621
2022-07-27 11:37:37 - train: epoch 0042, iter [00400, 05004], lr: 0.136874, loss: 1.7694
2022-07-27 11:39:41 - train: epoch 0042, iter [00500, 05004], lr: 0.136813, loss: 2.0472
2022-07-27 11:41:38 - train: epoch 0042, iter [00600, 05004], lr: 0.136751, loss: 1.9716
2022-07-27 11:43:39 - train: epoch 0042, iter [00700, 05004], lr: 0.136690, loss: 2.0679
2022-07-27 11:45:38 - train: epoch 0042, iter [00800, 05004], lr: 0.136628, loss: 2.1025
2022-07-27 11:47:35 - train: epoch 0042, iter [00900, 05004], lr: 0.136567, loss: 2.0186
2022-07-27 11:49:34 - train: epoch 0042, iter [01000, 05004], lr: 0.136505, loss: 2.2234
2022-07-27 11:51:34 - train: epoch 0042, iter [01100, 05004], lr: 0.136444, loss: 1.9256
2022-07-27 11:53:31 - train: epoch 0042, iter [01200, 05004], lr: 0.136382, loss: 1.8529
2022-07-27 11:55:31 - train: epoch 0042, iter [01300, 05004], lr: 0.136321, loss: 2.2204
2022-07-27 11:57:29 - train: epoch 0042, iter [01400, 05004], lr: 0.136259, loss: 2.3438
2022-07-27 11:59:32 - train: epoch 0042, iter [01500, 05004], lr: 0.136197, loss: 2.0797
2022-07-27 12:01:33 - train: epoch 0042, iter [01600, 05004], lr: 0.136136, loss: 2.2890
2022-07-27 12:03:38 - train: epoch 0042, iter [01700, 05004], lr: 0.136074, loss: 2.1640
