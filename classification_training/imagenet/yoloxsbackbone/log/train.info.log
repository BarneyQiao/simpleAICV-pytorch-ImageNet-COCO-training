2022-03-13 22:40:30 - train: epoch 0051, iter [00100, 05004], lr: 0.010000, loss: 2.0768
2022-03-13 22:41:02 - train: epoch 0051, iter [00200, 05004], lr: 0.010000, loss: 2.2087
2022-03-13 22:41:34 - train: epoch 0051, iter [00300, 05004], lr: 0.010000, loss: 1.8178
2022-03-13 22:42:05 - train: epoch 0051, iter [00400, 05004], lr: 0.010000, loss: 1.5193
2022-03-13 22:42:37 - train: epoch 0051, iter [00500, 05004], lr: 0.010000, loss: 2.0134
2022-03-13 22:43:08 - train: epoch 0051, iter [00600, 05004], lr: 0.010000, loss: 1.6879
2022-03-13 22:43:40 - train: epoch 0051, iter [00700, 05004], lr: 0.010000, loss: 1.7215
2022-03-13 22:44:12 - train: epoch 0051, iter [00800, 05004], lr: 0.010000, loss: 2.1208
2022-03-13 22:44:43 - train: epoch 0051, iter [00900, 05004], lr: 0.010000, loss: 1.7271
2022-03-13 22:45:14 - train: epoch 0051, iter [01000, 05004], lr: 0.010000, loss: 2.0601
2022-03-13 22:45:46 - train: epoch 0051, iter [01100, 05004], lr: 0.010000, loss: 1.8889
2022-03-13 22:46:17 - train: epoch 0051, iter [01200, 05004], lr: 0.010000, loss: 1.7830
2022-03-13 22:46:50 - train: epoch 0051, iter [01300, 05004], lr: 0.010000, loss: 1.5351
2022-03-13 22:47:21 - train: epoch 0051, iter [01400, 05004], lr: 0.010000, loss: 1.7240
2022-03-13 22:47:53 - train: epoch 0051, iter [01500, 05004], lr: 0.010000, loss: 1.7078
2022-03-13 22:48:24 - train: epoch 0051, iter [01600, 05004], lr: 0.010000, loss: 1.5969
2022-03-13 22:48:56 - train: epoch 0051, iter [01700, 05004], lr: 0.010000, loss: 1.8361
2022-03-13 22:49:26 - train: epoch 0051, iter [01800, 05004], lr: 0.010000, loss: 1.6823
2022-03-13 22:49:58 - train: epoch 0051, iter [01900, 05004], lr: 0.010000, loss: 1.5965
2022-03-13 22:50:29 - train: epoch 0051, iter [02000, 05004], lr: 0.010000, loss: 1.7885
2022-03-13 22:51:01 - train: epoch 0051, iter [02100, 05004], lr: 0.010000, loss: 1.6463
2022-03-13 22:51:32 - train: epoch 0051, iter [02200, 05004], lr: 0.010000, loss: 1.8270
2022-03-13 22:52:04 - train: epoch 0051, iter [02300, 05004], lr: 0.010000, loss: 1.9551
2022-03-13 22:52:35 - train: epoch 0051, iter [02400, 05004], lr: 0.010000, loss: 1.9429
2022-03-13 22:53:06 - train: epoch 0051, iter [02500, 05004], lr: 0.010000, loss: 1.7956
2022-03-13 22:53:40 - train: epoch 0051, iter [02600, 05004], lr: 0.010000, loss: 1.6016
2022-03-13 22:54:13 - train: epoch 0051, iter [02700, 05004], lr: 0.010000, loss: 1.8680
2022-03-13 22:54:44 - train: epoch 0051, iter [02800, 05004], lr: 0.010000, loss: 1.7471
2022-03-13 22:55:16 - train: epoch 0051, iter [02900, 05004], lr: 0.010000, loss: 1.7410
2022-03-13 22:55:47 - train: epoch 0051, iter [03000, 05004], lr: 0.010000, loss: 1.7739
2022-03-13 22:56:19 - train: epoch 0051, iter [03100, 05004], lr: 0.010000, loss: 1.7532
2022-03-13 22:56:51 - train: epoch 0051, iter [03200, 05004], lr: 0.010000, loss: 1.8450
2022-03-13 22:57:23 - train: epoch 0051, iter [03300, 05004], lr: 0.010000, loss: 1.9310
2022-03-13 22:57:54 - train: epoch 0051, iter [03400, 05004], lr: 0.010000, loss: 1.8136
2022-03-13 22:58:26 - train: epoch 0051, iter [03500, 05004], lr: 0.010000, loss: 1.7590
2022-03-13 22:58:59 - train: epoch 0051, iter [03600, 05004], lr: 0.010000, loss: 1.8306
2022-03-13 22:59:30 - train: epoch 0051, iter [03700, 05004], lr: 0.010000, loss: 1.9490
2022-03-13 23:00:02 - train: epoch 0051, iter [03800, 05004], lr: 0.010000, loss: 1.8273
2022-03-13 23:00:34 - train: epoch 0051, iter [03900, 05004], lr: 0.010000, loss: 1.8930
2022-03-13 23:01:06 - train: epoch 0051, iter [04000, 05004], lr: 0.010000, loss: 1.8039
2022-03-13 23:01:37 - train: epoch 0051, iter [04100, 05004], lr: 0.010000, loss: 1.9279
2022-03-13 23:02:10 - train: epoch 0051, iter [04200, 05004], lr: 0.010000, loss: 2.0591
2022-03-13 23:02:41 - train: epoch 0051, iter [04300, 05004], lr: 0.010000, loss: 1.6973
2022-03-13 23:03:13 - train: epoch 0051, iter [04400, 05004], lr: 0.010000, loss: 1.8989
2022-03-13 23:03:44 - train: epoch 0051, iter [04500, 05004], lr: 0.010000, loss: 1.5569
2022-03-13 23:04:18 - train: epoch 0051, iter [04600, 05004], lr: 0.010000, loss: 1.9730
2022-03-13 23:04:49 - train: epoch 0051, iter [04700, 05004], lr: 0.010000, loss: 1.8732
2022-03-13 23:05:21 - train: epoch 0051, iter [04800, 05004], lr: 0.010000, loss: 1.7887
2022-03-13 23:05:52 - train: epoch 0051, iter [04900, 05004], lr: 0.010000, loss: 1.9253
2022-03-13 23:06:23 - train: epoch 0051, iter [05000, 05004], lr: 0.010000, loss: 1.8442
2022-03-13 23:06:24 - train: epoch 051, train_loss: 1.8124
2022-03-13 23:07:35 - eval: epoch: 051, acc1: 62.656%, acc5: 85.076%, test_loss: 1.5236, per_image_load_time: 1.636ms, per_image_inference_time: 0.167ms
2022-03-13 23:07:35 - until epoch: 051, best_acc1: 62.890%
2022-03-13 23:07:35 - epoch 052 lr: 0.010000000000000002
2022-03-13 23:08:11 - train: epoch 0052, iter [00100, 05004], lr: 0.010000, loss: 1.7016
2022-03-13 23:08:43 - train: epoch 0052, iter [00200, 05004], lr: 0.010000, loss: 1.8330
2022-03-13 23:09:16 - train: epoch 0052, iter [00300, 05004], lr: 0.010000, loss: 1.8834
2022-03-13 23:09:48 - train: epoch 0052, iter [00400, 05004], lr: 0.010000, loss: 1.8320
2022-03-13 23:10:19 - train: epoch 0052, iter [00500, 05004], lr: 0.010000, loss: 1.8709
2022-03-13 23:10:52 - train: epoch 0052, iter [00600, 05004], lr: 0.010000, loss: 1.6288
2022-03-13 23:11:23 - train: epoch 0052, iter [00700, 05004], lr: 0.010000, loss: 1.8662
2022-03-13 23:11:55 - train: epoch 0052, iter [00800, 05004], lr: 0.010000, loss: 1.7385
2022-03-13 23:12:27 - train: epoch 0052, iter [00900, 05004], lr: 0.010000, loss: 1.9272
2022-03-13 23:12:58 - train: epoch 0052, iter [01000, 05004], lr: 0.010000, loss: 1.9855
2022-03-13 23:13:30 - train: epoch 0052, iter [01100, 05004], lr: 0.010000, loss: 1.8155
2022-03-13 23:14:02 - train: epoch 0052, iter [01200, 05004], lr: 0.010000, loss: 1.6818
2022-03-13 23:14:34 - train: epoch 0052, iter [01300, 05004], lr: 0.010000, loss: 1.7335
2022-03-13 23:15:06 - train: epoch 0052, iter [01400, 05004], lr: 0.010000, loss: 2.1430
2022-03-13 23:15:38 - train: epoch 0052, iter [01500, 05004], lr: 0.010000, loss: 1.5544
2022-03-13 23:16:10 - train: epoch 0052, iter [01600, 05004], lr: 0.010000, loss: 1.5834
2022-03-13 23:16:42 - train: epoch 0052, iter [01700, 05004], lr: 0.010000, loss: 1.6260
2022-03-13 23:17:13 - train: epoch 0052, iter [01800, 05004], lr: 0.010000, loss: 1.6164
2022-03-13 23:17:45 - train: epoch 0052, iter [01900, 05004], lr: 0.010000, loss: 1.7542
2022-03-13 23:18:17 - train: epoch 0052, iter [02000, 05004], lr: 0.010000, loss: 1.9166
2022-03-13 23:18:48 - train: epoch 0052, iter [02100, 05004], lr: 0.010000, loss: 1.7066
2022-03-13 23:19:22 - train: epoch 0052, iter [02200, 05004], lr: 0.010000, loss: 1.8340
2022-03-13 23:19:53 - train: epoch 0052, iter [02300, 05004], lr: 0.010000, loss: 1.6546
2022-03-13 23:20:25 - train: epoch 0052, iter [02400, 05004], lr: 0.010000, loss: 1.6524
2022-03-13 23:20:56 - train: epoch 0052, iter [02500, 05004], lr: 0.010000, loss: 1.6193
2022-03-13 23:21:29 - train: epoch 0052, iter [02600, 05004], lr: 0.010000, loss: 1.6344
2022-03-13 23:22:00 - train: epoch 0052, iter [02700, 05004], lr: 0.010000, loss: 1.7254
2022-03-13 23:22:32 - train: epoch 0052, iter [02800, 05004], lr: 0.010000, loss: 1.8369
2022-03-13 23:23:04 - train: epoch 0052, iter [02900, 05004], lr: 0.010000, loss: 1.6048
2022-03-13 23:23:36 - train: epoch 0052, iter [03000, 05004], lr: 0.010000, loss: 1.7227
2022-03-13 23:24:08 - train: epoch 0052, iter [03100, 05004], lr: 0.010000, loss: 1.8289
2022-03-13 23:24:39 - train: epoch 0052, iter [03200, 05004], lr: 0.010000, loss: 1.8799
2022-03-13 23:25:12 - train: epoch 0052, iter [03300, 05004], lr: 0.010000, loss: 1.7327
2022-03-13 23:25:43 - train: epoch 0052, iter [03400, 05004], lr: 0.010000, loss: 1.7786
2022-03-13 23:26:15 - train: epoch 0052, iter [03500, 05004], lr: 0.010000, loss: 1.9482
2022-03-13 23:26:47 - train: epoch 0052, iter [03600, 05004], lr: 0.010000, loss: 1.8535
2022-03-13 23:27:19 - train: epoch 0052, iter [03700, 05004], lr: 0.010000, loss: 1.9908
2022-03-13 23:27:51 - train: epoch 0052, iter [03800, 05004], lr: 0.010000, loss: 1.6869
2022-03-13 23:28:23 - train: epoch 0052, iter [03900, 05004], lr: 0.010000, loss: 1.6430
2022-03-13 23:28:55 - train: epoch 0052, iter [04000, 05004], lr: 0.010000, loss: 1.9047
2022-03-13 23:29:27 - train: epoch 0052, iter [04100, 05004], lr: 0.010000, loss: 1.5350
2022-03-13 23:29:59 - train: epoch 0052, iter [04200, 05004], lr: 0.010000, loss: 1.6954
2022-03-13 23:30:32 - train: epoch 0052, iter [04300, 05004], lr: 0.010000, loss: 1.7189
2022-03-13 23:31:03 - train: epoch 0052, iter [04400, 05004], lr: 0.010000, loss: 1.9137
2022-03-13 23:31:35 - train: epoch 0052, iter [04500, 05004], lr: 0.010000, loss: 1.6882
2022-03-13 23:32:06 - train: epoch 0052, iter [04600, 05004], lr: 0.010000, loss: 1.8813
2022-03-13 23:32:39 - train: epoch 0052, iter [04700, 05004], lr: 0.010000, loss: 1.8509
2022-03-13 23:33:10 - train: epoch 0052, iter [04800, 05004], lr: 0.010000, loss: 1.5814
2022-03-13 23:33:42 - train: epoch 0052, iter [04900, 05004], lr: 0.010000, loss: 1.6967
2022-03-13 23:34:13 - train: epoch 0052, iter [05000, 05004], lr: 0.010000, loss: 1.7829
2022-03-13 23:34:13 - train: epoch 052, train_loss: 1.8106
2022-03-13 23:35:25 - eval: epoch: 052, acc1: 62.862%, acc5: 85.078%, test_loss: 1.5245, per_image_load_time: 1.283ms, per_image_inference_time: 0.155ms
2022-03-13 23:35:25 - until epoch: 052, best_acc1: 62.890%
2022-03-13 23:35:25 - epoch 053 lr: 0.010000000000000002
2022-03-13 23:36:02 - train: epoch 0053, iter [00100, 05004], lr: 0.010000, loss: 1.8817
2022-03-13 23:36:34 - train: epoch 0053, iter [00200, 05004], lr: 0.010000, loss: 1.9590
2022-03-13 23:37:05 - train: epoch 0053, iter [00300, 05004], lr: 0.010000, loss: 1.8762
2022-03-13 23:37:38 - train: epoch 0053, iter [00400, 05004], lr: 0.010000, loss: 1.8824
2022-03-13 23:38:09 - train: epoch 0053, iter [00500, 05004], lr: 0.010000, loss: 1.9209
2022-03-13 23:38:42 - train: epoch 0053, iter [00600, 05004], lr: 0.010000, loss: 1.8207
2022-03-13 23:39:13 - train: epoch 0053, iter [00700, 05004], lr: 0.010000, loss: 1.6983
2022-03-13 23:39:45 - train: epoch 0053, iter [00800, 05004], lr: 0.010000, loss: 1.8246
2022-03-13 23:40:17 - train: epoch 0053, iter [00900, 05004], lr: 0.010000, loss: 1.7734
2022-03-13 23:40:48 - train: epoch 0053, iter [01000, 05004], lr: 0.010000, loss: 1.6998
2022-03-13 23:41:20 - train: epoch 0053, iter [01100, 05004], lr: 0.010000, loss: 1.7473
2022-03-13 23:41:52 - train: epoch 0053, iter [01200, 05004], lr: 0.010000, loss: 1.7164
2022-03-13 23:42:24 - train: epoch 0053, iter [01300, 05004], lr: 0.010000, loss: 1.8592
2022-03-13 23:42:56 - train: epoch 0053, iter [01400, 05004], lr: 0.010000, loss: 2.1929
2022-03-13 23:43:28 - train: epoch 0053, iter [01500, 05004], lr: 0.010000, loss: 1.8318
2022-03-13 23:44:01 - train: epoch 0053, iter [01600, 05004], lr: 0.010000, loss: 2.0670
2022-03-13 23:44:33 - train: epoch 0053, iter [01700, 05004], lr: 0.010000, loss: 2.0354
2022-03-13 23:45:06 - train: epoch 0053, iter [01800, 05004], lr: 0.010000, loss: 1.8544
2022-03-13 23:45:38 - train: epoch 0053, iter [01900, 05004], lr: 0.010000, loss: 1.5960
2022-03-13 23:46:10 - train: epoch 0053, iter [02000, 05004], lr: 0.010000, loss: 1.9350
2022-03-13 23:46:43 - train: epoch 0053, iter [02100, 05004], lr: 0.010000, loss: 1.7629
2022-03-13 23:47:16 - train: epoch 0053, iter [02200, 05004], lr: 0.010000, loss: 1.7236
2022-03-13 23:47:49 - train: epoch 0053, iter [02300, 05004], lr: 0.010000, loss: 1.8105
2022-03-13 23:48:21 - train: epoch 0053, iter [02400, 05004], lr: 0.010000, loss: 1.7923
2022-03-13 23:48:54 - train: epoch 0053, iter [02500, 05004], lr: 0.010000, loss: 2.0232
2022-03-13 23:49:26 - train: epoch 0053, iter [02600, 05004], lr: 0.010000, loss: 1.9463
2022-03-13 23:49:58 - train: epoch 0053, iter [02700, 05004], lr: 0.010000, loss: 2.1348
2022-03-13 23:50:31 - train: epoch 0053, iter [02800, 05004], lr: 0.010000, loss: 1.9565
2022-03-13 23:51:05 - train: epoch 0053, iter [02900, 05004], lr: 0.010000, loss: 1.6280
2022-03-13 23:51:36 - train: epoch 0053, iter [03000, 05004], lr: 0.010000, loss: 1.6200
2022-03-13 23:52:09 - train: epoch 0053, iter [03100, 05004], lr: 0.010000, loss: 2.0343
2022-03-13 23:52:42 - train: epoch 0053, iter [03200, 05004], lr: 0.010000, loss: 2.0696
2022-03-13 23:53:15 - train: epoch 0053, iter [03300, 05004], lr: 0.010000, loss: 1.7334
2022-03-13 23:53:47 - train: epoch 0053, iter [03400, 05004], lr: 0.010000, loss: 1.9605
2022-03-13 23:54:20 - train: epoch 0053, iter [03500, 05004], lr: 0.010000, loss: 1.8151
2022-03-13 23:54:53 - train: epoch 0053, iter [03600, 05004], lr: 0.010000, loss: 1.8672
2022-03-13 23:55:25 - train: epoch 0053, iter [03700, 05004], lr: 0.010000, loss: 1.9230
2022-03-13 23:55:58 - train: epoch 0053, iter [03800, 05004], lr: 0.010000, loss: 1.7364
2022-03-13 23:56:31 - train: epoch 0053, iter [03900, 05004], lr: 0.010000, loss: 1.9174
2022-03-13 23:57:03 - train: epoch 0053, iter [04000, 05004], lr: 0.010000, loss: 1.7787
2022-03-13 23:57:35 - train: epoch 0053, iter [04100, 05004], lr: 0.010000, loss: 1.8578
2022-03-13 23:58:08 - train: epoch 0053, iter [04200, 05004], lr: 0.010000, loss: 1.8314
2022-03-13 23:58:41 - train: epoch 0053, iter [04300, 05004], lr: 0.010000, loss: 2.0442
2022-03-13 23:59:13 - train: epoch 0053, iter [04400, 05004], lr: 0.010000, loss: 1.7788
2022-03-13 23:59:45 - train: epoch 0053, iter [04500, 05004], lr: 0.010000, loss: 2.0131
2022-03-14 00:00:18 - train: epoch 0053, iter [04600, 05004], lr: 0.010000, loss: 1.7803
2022-03-14 00:00:50 - train: epoch 0053, iter [04700, 05004], lr: 0.010000, loss: 1.9181
2022-03-14 00:01:23 - train: epoch 0053, iter [04800, 05004], lr: 0.010000, loss: 2.0041
2022-03-14 00:01:55 - train: epoch 0053, iter [04900, 05004], lr: 0.010000, loss: 1.7078
2022-03-14 00:02:26 - train: epoch 0053, iter [05000, 05004], lr: 0.010000, loss: 1.8224
2022-03-14 00:02:27 - train: epoch 053, train_loss: 1.8063
2022-03-14 00:03:41 - eval: epoch: 053, acc1: 62.868%, acc5: 85.136%, test_loss: 1.5198, per_image_load_time: 1.269ms, per_image_inference_time: 0.169ms
2022-03-14 00:03:41 - until epoch: 053, best_acc1: 62.890%
2022-03-14 00:03:41 - epoch 054 lr: 0.010000000000000002
2022-03-14 00:04:20 - train: epoch 0054, iter [00100, 05004], lr: 0.010000, loss: 1.6536
2022-03-14 00:04:54 - train: epoch 0054, iter [00200, 05004], lr: 0.010000, loss: 2.0181
2022-03-14 00:05:27 - train: epoch 0054, iter [00300, 05004], lr: 0.010000, loss: 1.8380
2022-03-14 00:06:01 - train: epoch 0054, iter [00400, 05004], lr: 0.010000, loss: 1.6959
2022-03-14 00:06:34 - train: epoch 0054, iter [00500, 05004], lr: 0.010000, loss: 1.8662
2022-03-14 00:07:08 - train: epoch 0054, iter [00600, 05004], lr: 0.010000, loss: 1.5959
2022-03-14 00:07:41 - train: epoch 0054, iter [00700, 05004], lr: 0.010000, loss: 1.8764
2022-03-14 00:08:15 - train: epoch 0054, iter [00800, 05004], lr: 0.010000, loss: 1.9372
2022-03-14 00:08:49 - train: epoch 0054, iter [00900, 05004], lr: 0.010000, loss: 1.5552
2022-03-14 00:09:22 - train: epoch 0054, iter [01000, 05004], lr: 0.010000, loss: 1.6236
2022-03-14 00:09:56 - train: epoch 0054, iter [01100, 05004], lr: 0.010000, loss: 1.5697
2022-03-14 00:10:29 - train: epoch 0054, iter [01200, 05004], lr: 0.010000, loss: 1.9730
2022-03-14 00:11:02 - train: epoch 0054, iter [01300, 05004], lr: 0.010000, loss: 1.7379
2022-03-14 00:11:37 - train: epoch 0054, iter [01400, 05004], lr: 0.010000, loss: 1.8426
2022-03-14 00:12:11 - train: epoch 0054, iter [01500, 05004], lr: 0.010000, loss: 1.8607
2022-03-14 00:12:45 - train: epoch 0054, iter [01600, 05004], lr: 0.010000, loss: 1.5084
2022-03-14 00:13:18 - train: epoch 0054, iter [01700, 05004], lr: 0.010000, loss: 1.8000
2022-03-14 00:13:52 - train: epoch 0054, iter [01800, 05004], lr: 0.010000, loss: 1.8062
2022-03-14 00:14:26 - train: epoch 0054, iter [01900, 05004], lr: 0.010000, loss: 2.1057
2022-03-14 00:15:00 - train: epoch 0054, iter [02000, 05004], lr: 0.010000, loss: 1.8626
2022-03-14 00:15:33 - train: epoch 0054, iter [02100, 05004], lr: 0.010000, loss: 1.5165
2022-03-14 00:16:06 - train: epoch 0054, iter [02200, 05004], lr: 0.010000, loss: 1.7811
2022-03-14 00:16:40 - train: epoch 0054, iter [02300, 05004], lr: 0.010000, loss: 1.7953
2022-03-14 00:17:14 - train: epoch 0054, iter [02400, 05004], lr: 0.010000, loss: 1.5877
2022-03-14 00:17:48 - train: epoch 0054, iter [02500, 05004], lr: 0.010000, loss: 1.9437
2022-03-14 00:18:20 - train: epoch 0054, iter [02600, 05004], lr: 0.010000, loss: 1.7300
2022-03-14 00:18:55 - train: epoch 0054, iter [02700, 05004], lr: 0.010000, loss: 1.8563
2022-03-14 00:19:28 - train: epoch 0054, iter [02800, 05004], lr: 0.010000, loss: 2.1612
2022-03-14 00:20:01 - train: epoch 0054, iter [02900, 05004], lr: 0.010000, loss: 1.6229
2022-03-14 00:20:35 - train: epoch 0054, iter [03000, 05004], lr: 0.010000, loss: 1.9158
2022-03-14 00:21:08 - train: epoch 0054, iter [03100, 05004], lr: 0.010000, loss: 1.8078
2022-03-14 00:21:42 - train: epoch 0054, iter [03200, 05004], lr: 0.010000, loss: 1.9462
2022-03-14 00:22:16 - train: epoch 0054, iter [03300, 05004], lr: 0.010000, loss: 1.8109
2022-03-14 00:22:49 - train: epoch 0054, iter [03400, 05004], lr: 0.010000, loss: 1.7845
2022-03-14 00:23:23 - train: epoch 0054, iter [03500, 05004], lr: 0.010000, loss: 1.9383
2022-03-14 00:23:57 - train: epoch 0054, iter [03600, 05004], lr: 0.010000, loss: 1.7420
2022-03-14 00:24:31 - train: epoch 0054, iter [03700, 05004], lr: 0.010000, loss: 1.6970
2022-03-14 00:25:03 - train: epoch 0054, iter [03800, 05004], lr: 0.010000, loss: 1.8768
2022-03-14 00:25:37 - train: epoch 0054, iter [03900, 05004], lr: 0.010000, loss: 1.7403
2022-03-14 00:26:10 - train: epoch 0054, iter [04000, 05004], lr: 0.010000, loss: 1.6684
2022-03-14 00:26:44 - train: epoch 0054, iter [04100, 05004], lr: 0.010000, loss: 1.8710
2022-03-14 00:27:18 - train: epoch 0054, iter [04200, 05004], lr: 0.010000, loss: 1.9382
2022-03-14 00:27:51 - train: epoch 0054, iter [04300, 05004], lr: 0.010000, loss: 1.8934
2022-03-14 00:28:25 - train: epoch 0054, iter [04400, 05004], lr: 0.010000, loss: 1.5834
2022-03-14 00:28:58 - train: epoch 0054, iter [04500, 05004], lr: 0.010000, loss: 1.6843
2022-03-14 00:29:32 - train: epoch 0054, iter [04600, 05004], lr: 0.010000, loss: 1.7935
2022-03-14 00:30:05 - train: epoch 0054, iter [04700, 05004], lr: 0.010000, loss: 2.1612
2022-03-14 00:30:40 - train: epoch 0054, iter [04800, 05004], lr: 0.010000, loss: 1.8623
2022-03-14 00:31:13 - train: epoch 0054, iter [04900, 05004], lr: 0.010000, loss: 1.6015
2022-03-14 00:31:45 - train: epoch 0054, iter [05000, 05004], lr: 0.010000, loss: 1.9028
2022-03-14 00:31:46 - train: epoch 054, train_loss: 1.8078
2022-03-14 00:33:01 - eval: epoch: 054, acc1: 62.544%, acc5: 84.906%, test_loss: 1.5366, per_image_load_time: 0.995ms, per_image_inference_time: 0.195ms
2022-03-14 00:33:01 - until epoch: 054, best_acc1: 62.890%
2022-03-14 00:33:01 - epoch 055 lr: 0.010000000000000002
2022-03-14 00:33:40 - train: epoch 0055, iter [00100, 05004], lr: 0.010000, loss: 1.7825
2022-03-14 00:34:13 - train: epoch 0055, iter [00200, 05004], lr: 0.010000, loss: 1.7500
2022-03-14 00:34:46 - train: epoch 0055, iter [00300, 05004], lr: 0.010000, loss: 1.5854
2022-03-14 00:35:18 - train: epoch 0055, iter [00400, 05004], lr: 0.010000, loss: 1.7367
2022-03-14 00:35:52 - train: epoch 0055, iter [00500, 05004], lr: 0.010000, loss: 1.6181
2022-03-14 00:36:25 - train: epoch 0055, iter [00600, 05004], lr: 0.010000, loss: 1.7249
2022-03-14 00:36:59 - train: epoch 0055, iter [00700, 05004], lr: 0.010000, loss: 2.0049
2022-03-14 00:37:31 - train: epoch 0055, iter [00800, 05004], lr: 0.010000, loss: 1.6045
2022-03-14 00:38:06 - train: epoch 0055, iter [00900, 05004], lr: 0.010000, loss: 1.8416
2022-03-14 00:38:39 - train: epoch 0055, iter [01000, 05004], lr: 0.010000, loss: 1.7629
2022-03-14 00:39:13 - train: epoch 0055, iter [01100, 05004], lr: 0.010000, loss: 1.8409
2022-03-14 00:39:46 - train: epoch 0055, iter [01200, 05004], lr: 0.010000, loss: 1.7732
2022-03-14 00:40:19 - train: epoch 0055, iter [01300, 05004], lr: 0.010000, loss: 1.9401
2022-03-14 00:40:53 - train: epoch 0055, iter [01400, 05004], lr: 0.010000, loss: 1.8122
2022-03-14 00:41:26 - train: epoch 0055, iter [01500, 05004], lr: 0.010000, loss: 1.7810
2022-03-14 00:42:00 - train: epoch 0055, iter [01600, 05004], lr: 0.010000, loss: 1.9609
2022-03-14 00:42:33 - train: epoch 0055, iter [01700, 05004], lr: 0.010000, loss: 1.8624
2022-03-14 00:43:07 - train: epoch 0055, iter [01800, 05004], lr: 0.010000, loss: 2.0328
2022-03-14 00:43:40 - train: epoch 0055, iter [01900, 05004], lr: 0.010000, loss: 1.8746
2022-03-14 00:44:13 - train: epoch 0055, iter [02000, 05004], lr: 0.010000, loss: 1.8370
2022-03-14 00:44:46 - train: epoch 0055, iter [02100, 05004], lr: 0.010000, loss: 1.4608
2022-03-14 00:45:20 - train: epoch 0055, iter [02200, 05004], lr: 0.010000, loss: 1.8962
2022-03-14 00:45:54 - train: epoch 0055, iter [02300, 05004], lr: 0.010000, loss: 1.7668
2022-03-14 00:46:27 - train: epoch 0055, iter [02400, 05004], lr: 0.010000, loss: 1.7729
2022-03-14 00:47:02 - train: epoch 0055, iter [02500, 05004], lr: 0.010000, loss: 1.8320
2022-03-14 00:47:34 - train: epoch 0055, iter [02600, 05004], lr: 0.010000, loss: 1.8364
2022-03-14 00:48:08 - train: epoch 0055, iter [02700, 05004], lr: 0.010000, loss: 1.6507
2022-03-14 00:48:41 - train: epoch 0055, iter [02800, 05004], lr: 0.010000, loss: 1.7669
2022-03-14 00:49:15 - train: epoch 0055, iter [02900, 05004], lr: 0.010000, loss: 1.9687
2022-03-14 00:49:48 - train: epoch 0055, iter [03000, 05004], lr: 0.010000, loss: 1.6849
2022-03-14 00:50:21 - train: epoch 0055, iter [03100, 05004], lr: 0.010000, loss: 1.8150
2022-03-14 00:50:56 - train: epoch 0055, iter [03200, 05004], lr: 0.010000, loss: 1.6942
2022-03-14 00:51:30 - train: epoch 0055, iter [03300, 05004], lr: 0.010000, loss: 1.6092
2022-03-14 00:52:03 - train: epoch 0055, iter [03400, 05004], lr: 0.010000, loss: 1.7213
2022-03-14 00:52:37 - train: epoch 0055, iter [03500, 05004], lr: 0.010000, loss: 1.6110
2022-03-14 00:53:10 - train: epoch 0055, iter [03600, 05004], lr: 0.010000, loss: 1.8787
2022-03-14 00:53:44 - train: epoch 0055, iter [03700, 05004], lr: 0.010000, loss: 1.7502
2022-03-14 00:54:18 - train: epoch 0055, iter [03800, 05004], lr: 0.010000, loss: 1.8135
2022-03-14 00:54:52 - train: epoch 0055, iter [03900, 05004], lr: 0.010000, loss: 2.1925
2022-03-14 00:55:25 - train: epoch 0055, iter [04000, 05004], lr: 0.010000, loss: 1.8125
2022-03-14 00:56:00 - train: epoch 0055, iter [04100, 05004], lr: 0.010000, loss: 1.8642
2022-03-14 00:56:33 - train: epoch 0055, iter [04200, 05004], lr: 0.010000, loss: 1.7554
2022-03-14 00:57:07 - train: epoch 0055, iter [04300, 05004], lr: 0.010000, loss: 1.8860
2022-03-14 00:57:40 - train: epoch 0055, iter [04400, 05004], lr: 0.010000, loss: 1.9754
2022-03-14 00:58:15 - train: epoch 0055, iter [04500, 05004], lr: 0.010000, loss: 1.8049
2022-03-14 00:58:49 - train: epoch 0055, iter [04600, 05004], lr: 0.010000, loss: 1.9567
2022-03-14 00:59:22 - train: epoch 0055, iter [04700, 05004], lr: 0.010000, loss: 1.6820
2022-03-14 00:59:56 - train: epoch 0055, iter [04800, 05004], lr: 0.010000, loss: 1.8996
2022-03-14 01:00:30 - train: epoch 0055, iter [04900, 05004], lr: 0.010000, loss: 1.8191
2022-03-14 01:01:02 - train: epoch 0055, iter [05000, 05004], lr: 0.010000, loss: 1.8752
2022-03-14 01:01:03 - train: epoch 055, train_loss: 1.8021
2022-03-14 01:02:17 - eval: epoch: 055, acc1: 62.874%, acc5: 85.196%, test_loss: 1.5205, per_image_load_time: 1.782ms, per_image_inference_time: 0.201ms
2022-03-14 01:02:17 - until epoch: 055, best_acc1: 62.890%
2022-03-14 01:02:17 - epoch 056 lr: 0.010000000000000002
2022-03-14 01:02:56 - train: epoch 0056, iter [00100, 05004], lr: 0.010000, loss: 1.8961
2022-03-14 01:03:29 - train: epoch 0056, iter [00200, 05004], lr: 0.010000, loss: 1.9334
2022-03-14 01:04:03 - train: epoch 0056, iter [00300, 05004], lr: 0.010000, loss: 1.7319
2022-03-14 01:04:37 - train: epoch 0056, iter [00400, 05004], lr: 0.010000, loss: 1.7162
2022-03-14 01:05:10 - train: epoch 0056, iter [00500, 05004], lr: 0.010000, loss: 1.7373
2022-03-14 01:05:43 - train: epoch 0056, iter [00600, 05004], lr: 0.010000, loss: 1.8338
2022-03-14 01:06:17 - train: epoch 0056, iter [00700, 05004], lr: 0.010000, loss: 1.7816
2022-03-14 01:06:51 - train: epoch 0056, iter [00800, 05004], lr: 0.010000, loss: 1.9965
2022-03-14 01:07:24 - train: epoch 0056, iter [00900, 05004], lr: 0.010000, loss: 1.8349
2022-03-14 01:07:57 - train: epoch 0056, iter [01000, 05004], lr: 0.010000, loss: 1.7622
2022-03-14 01:08:31 - train: epoch 0056, iter [01100, 05004], lr: 0.010000, loss: 1.6251
2022-03-14 01:09:05 - train: epoch 0056, iter [01200, 05004], lr: 0.010000, loss: 1.8575
2022-03-14 01:09:38 - train: epoch 0056, iter [01300, 05004], lr: 0.010000, loss: 1.8893
2022-03-14 01:10:12 - train: epoch 0056, iter [01400, 05004], lr: 0.010000, loss: 1.7543
2022-03-14 01:10:45 - train: epoch 0056, iter [01500, 05004], lr: 0.010000, loss: 2.0915
2022-03-14 01:11:20 - train: epoch 0056, iter [01600, 05004], lr: 0.010000, loss: 1.5798
2022-03-14 01:11:52 - train: epoch 0056, iter [01700, 05004], lr: 0.010000, loss: 1.9194
2022-03-14 01:12:26 - train: epoch 0056, iter [01800, 05004], lr: 0.010000, loss: 2.0647
2022-03-14 01:12:59 - train: epoch 0056, iter [01900, 05004], lr: 0.010000, loss: 1.8856
2022-03-14 01:13:33 - train: epoch 0056, iter [02000, 05004], lr: 0.010000, loss: 1.7761
2022-03-14 01:14:07 - train: epoch 0056, iter [02100, 05004], lr: 0.010000, loss: 1.7878
2022-03-14 01:14:42 - train: epoch 0056, iter [02200, 05004], lr: 0.010000, loss: 1.9337
2022-03-14 01:15:14 - train: epoch 0056, iter [02300, 05004], lr: 0.010000, loss: 2.0119
2022-03-14 01:15:48 - train: epoch 0056, iter [02400, 05004], lr: 0.010000, loss: 1.8600
2022-03-14 01:16:22 - train: epoch 0056, iter [02500, 05004], lr: 0.010000, loss: 1.9838
2022-03-14 01:16:56 - train: epoch 0056, iter [02600, 05004], lr: 0.010000, loss: 1.7443
2022-03-14 01:17:29 - train: epoch 0056, iter [02700, 05004], lr: 0.010000, loss: 1.6995
2022-03-14 01:18:03 - train: epoch 0056, iter [02800, 05004], lr: 0.010000, loss: 1.7711
2022-03-14 01:18:37 - train: epoch 0056, iter [02900, 05004], lr: 0.010000, loss: 1.9244
2022-03-14 01:19:11 - train: epoch 0056, iter [03000, 05004], lr: 0.010000, loss: 1.9619
2022-03-14 01:19:45 - train: epoch 0056, iter [03100, 05004], lr: 0.010000, loss: 1.6856
2022-03-14 01:20:19 - train: epoch 0056, iter [03200, 05004], lr: 0.010000, loss: 1.6610
2022-03-14 01:20:53 - train: epoch 0056, iter [03300, 05004], lr: 0.010000, loss: 2.1933
2022-03-14 01:21:27 - train: epoch 0056, iter [03400, 05004], lr: 0.010000, loss: 1.7206
2022-03-14 01:22:01 - train: epoch 0056, iter [03500, 05004], lr: 0.010000, loss: 1.7616
2022-03-14 01:22:34 - train: epoch 0056, iter [03600, 05004], lr: 0.010000, loss: 1.5475
2022-03-14 01:23:07 - train: epoch 0056, iter [03700, 05004], lr: 0.010000, loss: 1.7470
2022-03-14 01:23:41 - train: epoch 0056, iter [03800, 05004], lr: 0.010000, loss: 1.6473
2022-03-14 01:24:15 - train: epoch 0056, iter [03900, 05004], lr: 0.010000, loss: 2.0158
2022-03-14 01:24:49 - train: epoch 0056, iter [04000, 05004], lr: 0.010000, loss: 1.9206
2022-03-14 01:25:22 - train: epoch 0056, iter [04100, 05004], lr: 0.010000, loss: 1.9801
2022-03-14 01:25:57 - train: epoch 0056, iter [04200, 05004], lr: 0.010000, loss: 1.7505
2022-03-14 01:26:31 - train: epoch 0056, iter [04300, 05004], lr: 0.010000, loss: 1.6412
2022-03-14 01:27:03 - train: epoch 0056, iter [04400, 05004], lr: 0.010000, loss: 1.8737
2022-03-14 01:27:38 - train: epoch 0056, iter [04500, 05004], lr: 0.010000, loss: 1.7343
2022-03-14 01:28:11 - train: epoch 0056, iter [04600, 05004], lr: 0.010000, loss: 1.9458
2022-03-14 01:28:45 - train: epoch 0056, iter [04700, 05004], lr: 0.010000, loss: 1.8967
2022-03-14 01:29:19 - train: epoch 0056, iter [04800, 05004], lr: 0.010000, loss: 1.9867
2022-03-14 01:29:53 - train: epoch 0056, iter [04900, 05004], lr: 0.010000, loss: 1.7986
2022-03-14 01:30:25 - train: epoch 0056, iter [05000, 05004], lr: 0.010000, loss: 1.8662
2022-03-14 01:30:26 - train: epoch 056, train_loss: 1.7984
2022-03-14 01:31:41 - eval: epoch: 056, acc1: 62.962%, acc5: 85.260%, test_loss: 1.5170, per_image_load_time: 2.577ms, per_image_inference_time: 0.193ms
2022-03-14 01:31:41 - until epoch: 056, best_acc1: 62.962%
2022-03-14 01:31:41 - epoch 057 lr: 0.010000000000000002
2022-03-14 01:32:21 - train: epoch 0057, iter [00100, 05004], lr: 0.010000, loss: 1.9096
2022-03-14 01:32:55 - train: epoch 0057, iter [00200, 05004], lr: 0.010000, loss: 1.6687
2022-03-14 01:33:28 - train: epoch 0057, iter [00300, 05004], lr: 0.010000, loss: 1.6640
2022-03-14 01:34:02 - train: epoch 0057, iter [00400, 05004], lr: 0.010000, loss: 1.8255
2022-03-14 01:34:36 - train: epoch 0057, iter [00500, 05004], lr: 0.010000, loss: 1.5619
2022-03-14 01:35:09 - train: epoch 0057, iter [00600, 05004], lr: 0.010000, loss: 2.0083
2022-03-14 01:35:42 - train: epoch 0057, iter [00700, 05004], lr: 0.010000, loss: 1.5429
2022-03-14 01:36:15 - train: epoch 0057, iter [00800, 05004], lr: 0.010000, loss: 1.7291
2022-03-14 01:36:49 - train: epoch 0057, iter [00900, 05004], lr: 0.010000, loss: 1.9360
2022-03-14 01:37:22 - train: epoch 0057, iter [01000, 05004], lr: 0.010000, loss: 1.6878
2022-03-14 01:37:56 - train: epoch 0057, iter [01100, 05004], lr: 0.010000, loss: 1.7046
2022-03-14 01:38:30 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 1.7642
2022-03-14 01:39:04 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 1.8525
2022-03-14 01:39:38 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 1.8592
2022-03-14 01:40:12 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 1.9508
2022-03-14 01:40:45 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 1.8987
2022-03-14 01:41:19 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 1.9656
2022-03-14 01:41:53 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 1.9477
2022-03-14 01:42:27 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 1.7314
2022-03-14 01:43:01 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 1.7877
2022-03-14 01:43:34 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 1.8823
2022-03-14 01:44:08 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 1.9406
2022-03-14 01:44:41 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 1.7473
2022-03-14 01:45:16 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 1.6512
2022-03-14 01:45:49 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 1.7788
2022-03-14 01:46:23 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 1.6079
2022-03-14 01:46:56 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 1.4839
2022-03-14 01:47:30 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 1.4477
2022-03-14 01:48:03 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 1.8959
2022-03-14 01:48:37 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 1.8971
2022-03-14 01:49:10 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 2.0933
2022-03-14 01:49:45 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 1.9104
2022-03-14 01:50:18 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 1.7989
2022-03-14 01:50:52 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 1.8207
2022-03-14 01:51:26 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 1.9113
2022-03-14 01:52:00 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 1.8396
2022-03-14 01:52:33 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 1.8246
2022-03-14 01:53:07 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 1.7690
2022-03-14 01:53:40 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 1.8501
2022-03-14 01:54:14 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 1.7608
2022-03-14 01:54:48 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 1.8184
2022-03-14 01:55:21 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 1.9543
2022-03-14 01:55:55 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 1.6439
2022-03-14 01:56:29 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 1.7782
2022-03-14 01:57:02 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 1.8629
2022-03-14 01:57:37 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 2.0222
2022-03-14 01:58:10 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 1.7568
2022-03-14 01:58:44 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 2.0420
2022-03-14 01:59:17 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 1.9350
2022-03-14 01:59:49 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 1.9096
2022-03-14 01:59:49 - train: epoch 057, train_loss: 1.7972
2022-03-14 02:01:04 - eval: epoch: 057, acc1: 63.126%, acc5: 85.294%, test_loss: 1.5162, per_image_load_time: 2.632ms, per_image_inference_time: 0.181ms
2022-03-14 02:01:04 - until epoch: 057, best_acc1: 63.126%
2022-03-14 02:01:04 - epoch 058 lr: 0.010000000000000002
2022-03-14 02:01:43 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 1.9021
2022-03-14 02:02:17 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 1.6441
2022-03-14 02:02:51 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 1.8655
2022-03-14 02:03:23 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 1.7188
2022-03-14 02:03:58 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 1.6128
2022-03-14 02:04:31 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 1.9037
2022-03-14 02:05:05 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 1.8052
2022-03-14 02:05:38 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 1.6812
2022-03-14 02:06:11 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 1.6522
2022-03-14 02:06:45 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 1.9023
2022-03-14 02:07:19 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 1.4670
2022-03-14 02:07:52 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 1.6776
2022-03-14 02:08:26 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 1.9351
2022-03-14 02:08:59 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 1.8899
2022-03-14 02:09:33 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 1.7550
2022-03-14 02:10:06 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 1.7542
2022-03-14 02:10:40 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 1.9353
2022-03-14 02:11:13 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 1.7866
2022-03-14 02:11:47 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 1.9469
2022-03-14 02:12:21 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 1.9413
2022-03-14 02:12:55 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 1.6465
2022-03-14 02:13:28 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 1.5641
2022-03-14 02:14:02 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 1.7267
2022-03-14 02:14:36 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 1.9262
2022-03-14 02:15:10 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 1.8653
2022-03-14 02:15:44 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 1.6353
2022-03-14 02:16:17 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 2.1233
2022-03-14 02:16:51 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 1.5452
2022-03-14 02:17:26 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 1.7438
2022-03-14 02:17:59 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 1.9543
2022-03-14 02:18:32 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 1.5917
2022-03-14 02:19:06 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 1.5881
2022-03-14 02:19:41 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 1.7946
2022-03-14 02:20:14 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 1.5539
2022-03-14 02:20:48 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 1.6691
2022-03-14 02:21:20 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 1.6960
2022-03-14 02:21:53 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 1.6780
2022-03-14 02:22:27 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 1.8617
2022-03-14 02:23:01 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 1.8775
2022-03-14 02:23:35 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 1.9901
2022-03-14 02:24:09 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 1.9079
2022-03-14 02:24:42 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 1.5174
2022-03-14 02:25:15 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 2.0635
2022-03-14 02:25:51 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 1.5831
2022-03-14 02:26:23 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 1.8409
2022-03-14 02:26:58 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 1.5823
2022-03-14 02:27:31 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 1.8377
2022-03-14 02:28:05 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 1.8953
2022-03-14 02:28:39 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 1.6520
2022-03-14 02:29:11 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 1.7330
2022-03-14 02:29:11 - train: epoch 058, train_loss: 1.7925
2022-03-14 02:30:26 - eval: epoch: 058, acc1: 62.896%, acc5: 85.146%, test_loss: 1.5212, per_image_load_time: 2.401ms, per_image_inference_time: 0.199ms
2022-03-14 02:30:26 - until epoch: 058, best_acc1: 63.126%
2022-03-14 02:30:26 - epoch 059 lr: 0.010000000000000002
2022-03-14 02:31:05 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 1.9212
2022-03-14 02:31:39 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 1.7232
2022-03-14 02:32:12 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 1.7349
2022-03-14 02:32:46 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 1.8583
2022-03-14 02:33:19 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 1.9271
2022-03-14 02:33:52 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 1.7736
2022-03-14 02:34:25 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 1.7040
2022-03-14 02:34:59 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 1.7839
2022-03-14 02:35:32 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 1.6510
2022-03-14 02:36:05 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 1.7366
2022-03-14 02:36:39 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 2.0887
2022-03-14 02:37:13 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 1.5717
2022-03-14 02:37:46 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 1.9791
2022-03-14 02:38:20 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 1.9734
2022-03-14 02:38:53 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 1.9126
2022-03-14 02:39:27 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 1.7074
2022-03-14 02:40:01 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 1.9451
2022-03-14 02:40:34 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 1.8110
2022-03-14 02:41:08 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 1.8186
2022-03-14 02:41:41 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 1.7123
2022-03-14 02:42:15 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 1.9390
2022-03-14 02:42:48 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 1.9089
2022-03-14 02:43:22 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 1.7110
2022-03-14 02:43:55 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 1.8425
2022-03-14 02:44:29 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 1.7381
2022-03-14 02:45:03 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 1.6957
2022-03-14 02:45:36 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 1.6519
2022-03-14 02:46:10 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 2.0152
2022-03-14 02:46:43 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 1.6945
2022-03-14 02:47:17 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 2.2609
2022-03-14 02:47:50 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 1.5286
2022-03-14 02:48:25 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 1.7568
2022-03-14 02:48:57 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 1.8320
2022-03-14 02:49:31 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 2.1473
2022-03-14 02:50:05 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 1.5897
2022-03-14 02:50:38 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 1.8267
2022-03-14 02:51:13 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 1.4900
2022-03-14 02:51:46 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 1.6816
2022-03-14 02:52:20 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 1.7163
2022-03-14 02:52:53 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 2.0718
2022-03-14 02:53:27 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 1.7963
2022-03-14 02:54:00 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 1.8560
2022-03-14 02:54:34 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 1.8645
2022-03-14 02:55:07 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 1.9356
2022-03-14 02:55:41 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 1.8708
2022-03-14 02:56:16 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 1.7991
2022-03-14 02:56:49 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 1.7540
2022-03-14 02:57:23 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 1.7411
2022-03-14 02:57:56 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 2.0122
2022-03-14 02:58:28 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 1.8320
2022-03-14 02:58:29 - train: epoch 059, train_loss: 1.7926
2022-03-14 02:59:44 - eval: epoch: 059, acc1: 62.730%, acc5: 84.956%, test_loss: 1.5283, per_image_load_time: 2.633ms, per_image_inference_time: 0.200ms
2022-03-14 02:59:44 - until epoch: 059, best_acc1: 63.126%
2022-03-14 02:59:44 - epoch 060 lr: 0.010000000000000002
2022-03-14 03:00:23 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 1.7310
2022-03-14 03:00:57 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 1.9697
2022-03-14 03:01:30 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 1.7751
2022-03-14 03:02:03 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 1.8866
2022-03-14 03:02:36 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 1.9820
2022-03-14 03:03:10 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 1.8998
2022-03-14 03:03:43 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 1.7986
2022-03-14 03:04:17 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 1.9240
2022-03-14 03:04:51 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 1.4937
2022-03-14 03:05:24 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 1.5017
2022-03-14 03:05:58 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 1.5245
2022-03-14 03:06:32 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 1.6843
2022-03-14 03:07:05 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 1.7317
2022-03-14 03:07:39 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 1.9236
2022-03-14 03:08:12 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 1.8955
2022-03-14 03:08:46 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 1.8191
2022-03-14 03:09:19 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 1.7581
2022-03-14 03:09:52 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 1.7488
2022-03-14 03:10:26 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 1.9292
2022-03-14 03:11:00 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 1.6206
2022-03-14 03:11:34 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 1.8502
2022-03-14 03:12:07 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 1.8734
2022-03-14 03:12:41 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 1.6636
2022-03-14 03:13:14 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 1.7260
2022-03-14 03:13:48 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 1.8313
2022-03-14 03:14:22 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 1.9089
2022-03-14 03:14:55 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 1.7360
2022-03-14 03:15:29 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 1.7507
2022-03-14 03:16:04 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 1.8624
2022-03-14 03:16:37 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 2.0872
2022-03-14 03:17:11 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 1.8594
2022-03-14 03:17:45 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 1.7482
2022-03-14 03:18:19 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 1.6444
2022-03-14 03:18:52 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 1.8568
2022-03-14 03:19:26 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 1.8907
2022-03-14 03:20:00 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 1.7978
2022-03-14 03:20:33 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 1.8077
2022-03-14 03:21:07 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 1.8098
2022-03-14 03:21:41 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 2.1085
2022-03-14 03:22:14 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 1.7321
2022-03-14 03:22:48 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 1.8992
2022-03-14 03:23:21 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 1.9538
2022-03-14 03:23:54 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 1.7447
2022-03-14 03:24:29 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 1.9690
2022-03-14 03:25:01 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 1.6912
2022-03-14 03:25:35 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 1.7161
2022-03-14 03:26:09 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 1.9678
2022-03-14 03:26:42 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 1.6453
2022-03-14 03:27:16 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 1.7591
2022-03-14 03:27:47 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 1.8102
2022-03-14 03:27:48 - train: epoch 060, train_loss: 1.7892
2022-03-14 03:29:03 - eval: epoch: 060, acc1: 63.116%, acc5: 85.338%, test_loss: 1.5123, per_image_load_time: 2.705ms, per_image_inference_time: 0.186ms
2022-03-14 03:29:03 - until epoch: 060, best_acc1: 63.126%
2022-03-14 03:29:03 - epoch 061 lr: 0.0010000000000000002
2022-03-14 03:29:42 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 1.5235
2022-03-14 03:30:15 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 1.7720
2022-03-14 03:30:50 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 1.4904
2022-03-14 03:31:23 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 1.8261
2022-03-14 03:31:57 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 1.6615
2022-03-14 03:32:30 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 1.7203
2022-03-14 03:33:04 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 1.4302
2022-03-14 03:33:38 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 1.7215
2022-03-14 03:34:11 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 1.6115
2022-03-14 03:34:45 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 1.4865
2022-03-14 03:35:19 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 1.4623
2022-03-14 03:35:52 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 1.5005
2022-03-14 03:36:26 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 1.5417
2022-03-14 03:37:00 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 1.4998
2022-03-14 03:37:33 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 1.7152
2022-03-14 03:38:07 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 1.3768
2022-03-14 03:38:40 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 1.6173
2022-03-14 03:39:14 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 1.5672
2022-03-14 03:39:47 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 1.8525
2022-03-14 03:40:21 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 1.5771
2022-03-14 03:40:53 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 1.9500
2022-03-14 03:41:27 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 1.5756
2022-03-14 03:42:00 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 1.4974
2022-03-14 03:42:34 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 1.3441
2022-03-14 03:43:07 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 1.5202
2022-03-14 03:43:41 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 1.6684
2022-03-14 03:44:14 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 1.7558
2022-03-14 03:44:48 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 1.6293
2022-03-14 03:45:22 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 1.6887
2022-03-14 03:45:55 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 1.5176
2022-03-14 03:46:29 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 1.7595
2022-03-14 03:47:02 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 1.6505
2022-03-14 03:47:36 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 1.5723
2022-03-14 03:48:08 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 1.3509
2022-03-14 03:48:42 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 1.5985
2022-03-14 03:49:16 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 1.6085
2022-03-14 03:49:50 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 1.7077
2022-03-14 03:50:22 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 1.6173
2022-03-14 03:50:56 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 1.4839
2022-03-14 03:51:29 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 1.5478
2022-03-14 03:52:02 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 1.8233
2022-03-14 03:52:36 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 1.4568
2022-03-14 03:53:10 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 1.5774
2022-03-14 03:53:43 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 1.6483
2022-03-14 03:54:17 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 1.4888
2022-03-14 03:54:51 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 1.6257
2022-03-14 03:55:24 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 1.6007
2022-03-14 03:55:57 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 1.5152
2022-03-14 03:56:31 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 1.6547
2022-03-14 03:57:03 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 1.6891
2022-03-14 03:57:04 - train: epoch 061, train_loss: 1.6043
2022-03-14 03:58:18 - eval: epoch: 061, acc1: 67.068%, acc5: 87.506%, test_loss: 1.3391, per_image_load_time: 2.660ms, per_image_inference_time: 0.177ms
2022-03-14 03:58:18 - until epoch: 061, best_acc1: 67.068%
2022-03-14 03:58:18 - epoch 062 lr: 0.0010000000000000002
2022-03-14 03:58:58 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 1.6174
2022-03-14 03:59:31 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 1.6616
2022-03-14 04:00:05 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 1.5112
2022-03-14 04:00:38 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 1.4412
2022-03-14 04:01:11 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 1.5486
2022-03-14 04:01:45 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 1.4836
2022-03-14 04:02:18 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 1.8553
2022-03-14 04:02:52 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 1.5860
2022-03-14 04:03:25 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 1.5300
2022-03-14 04:03:58 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 1.7359
2022-03-14 04:04:32 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 1.4903
2022-03-14 04:05:05 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 1.7755
2022-03-14 04:05:39 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 1.6524
2022-03-14 04:06:12 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 1.5724
2022-03-14 04:06:47 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 1.7253
2022-03-14 04:07:19 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 1.7533
2022-03-14 04:07:53 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 1.5877
2022-03-14 04:08:26 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 1.4409
2022-03-14 04:09:00 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 1.6123
2022-03-14 04:09:33 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 1.5416
2022-03-14 04:10:08 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 1.7194
2022-03-14 04:10:40 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 1.4667
2022-03-14 04:11:14 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 1.4770
2022-03-14 04:11:48 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 1.5415
2022-03-14 04:12:22 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 1.6202
2022-03-14 04:12:55 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 1.4247
2022-03-14 04:13:29 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 1.6333
2022-03-14 04:14:03 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 1.7079
2022-03-14 04:14:37 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 1.6168
2022-03-14 04:15:10 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 1.7626
2022-03-14 04:15:44 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 1.5673
2022-03-14 04:16:17 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 1.3743
2022-03-14 04:16:51 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 1.7411
2022-03-14 04:17:25 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 1.6039
2022-03-14 04:17:59 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 1.5729
2022-03-14 04:18:32 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 1.6134
2022-03-14 04:19:05 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 1.5329
2022-03-14 04:19:39 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 1.4742
2022-03-14 04:20:13 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 1.5537
2022-03-14 04:20:46 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 1.3766
2022-03-14 04:21:20 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 1.6498
2022-03-14 04:21:53 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 1.3516
2022-03-14 04:22:27 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 1.6116
2022-03-14 04:23:01 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 1.5001
2022-03-14 04:23:35 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 1.4187
2022-03-14 04:24:08 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 1.3045
2022-03-14 04:24:42 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 1.5137
2022-03-14 04:25:15 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 1.4264
2022-03-14 04:25:50 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 1.4204
2022-03-14 04:26:21 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 1.5183
2022-03-14 04:26:22 - train: epoch 062, train_loss: 1.5596
2022-03-14 04:27:37 - eval: epoch: 062, acc1: 67.398%, acc5: 87.818%, test_loss: 1.3226, per_image_load_time: 2.429ms, per_image_inference_time: 0.186ms
2022-03-14 04:27:37 - until epoch: 062, best_acc1: 67.398%
2022-03-14 04:27:37 - epoch 063 lr: 0.0010000000000000002
2022-03-14 04:28:16 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 1.4864
2022-03-14 04:28:50 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 1.3791
2022-03-14 04:29:23 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 1.7173
2022-03-14 04:29:57 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 1.5039
2022-03-14 04:30:30 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 1.3749
2022-03-14 04:31:03 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 1.6259
2022-03-14 04:31:37 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 1.5817
2022-03-14 04:32:09 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 1.5600
2022-03-14 04:32:43 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 1.6080
2022-03-14 04:33:17 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 1.6286
2022-03-14 04:33:51 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 1.4332
2022-03-14 04:34:24 - train: epoch 0063, iter [01200, 05004], lr: 0.001000, loss: 1.5449
2022-03-14 04:34:57 - train: epoch 0063, iter [01300, 05004], lr: 0.001000, loss: 1.5186
2022-03-14 04:35:30 - train: epoch 0063, iter [01400, 05004], lr: 0.001000, loss: 1.8851
2022-03-14 04:36:05 - train: epoch 0063, iter [01500, 05004], lr: 0.001000, loss: 1.6059
2022-03-14 04:36:39 - train: epoch 0063, iter [01600, 05004], lr: 0.001000, loss: 1.4761
2022-03-14 04:37:12 - train: epoch 0063, iter [01700, 05004], lr: 0.001000, loss: 1.3889
2022-03-14 04:37:45 - train: epoch 0063, iter [01800, 05004], lr: 0.001000, loss: 1.5743
2022-03-14 04:38:19 - train: epoch 0063, iter [01900, 05004], lr: 0.001000, loss: 1.7120
2022-03-14 04:38:53 - train: epoch 0063, iter [02000, 05004], lr: 0.001000, loss: 1.4209
2022-03-14 04:39:25 - train: epoch 0063, iter [02100, 05004], lr: 0.001000, loss: 1.5028
2022-03-14 04:40:00 - train: epoch 0063, iter [02200, 05004], lr: 0.001000, loss: 1.8826
2022-03-14 04:40:33 - train: epoch 0063, iter [02300, 05004], lr: 0.001000, loss: 1.7452
2022-03-14 04:41:06 - train: epoch 0063, iter [02400, 05004], lr: 0.001000, loss: 1.6549
2022-03-14 04:41:40 - train: epoch 0063, iter [02500, 05004], lr: 0.001000, loss: 1.5191
2022-03-14 04:42:13 - train: epoch 0063, iter [02600, 05004], lr: 0.001000, loss: 1.4409
2022-03-14 04:42:48 - train: epoch 0063, iter [02700, 05004], lr: 0.001000, loss: 1.7922
2022-03-14 04:43:21 - train: epoch 0063, iter [02800, 05004], lr: 0.001000, loss: 1.6309
2022-03-14 04:43:56 - train: epoch 0063, iter [02900, 05004], lr: 0.001000, loss: 1.6013
2022-03-14 04:44:29 - train: epoch 0063, iter [03000, 05004], lr: 0.001000, loss: 1.6440
2022-03-14 04:45:03 - train: epoch 0063, iter [03100, 05004], lr: 0.001000, loss: 1.8677
2022-03-14 04:45:36 - train: epoch 0063, iter [03200, 05004], lr: 0.001000, loss: 1.5553
2022-03-14 04:46:10 - train: epoch 0063, iter [03300, 05004], lr: 0.001000, loss: 1.4203
2022-03-14 04:46:44 - train: epoch 0063, iter [03400, 05004], lr: 0.001000, loss: 1.2365
2022-03-14 04:47:17 - train: epoch 0063, iter [03500, 05004], lr: 0.001000, loss: 1.6694
2022-03-14 04:47:51 - train: epoch 0063, iter [03600, 05004], lr: 0.001000, loss: 1.4059
2022-03-14 04:48:25 - train: epoch 0063, iter [03700, 05004], lr: 0.001000, loss: 1.7053
2022-03-14 04:48:59 - train: epoch 0063, iter [03800, 05004], lr: 0.001000, loss: 1.7424
2022-03-14 04:49:33 - train: epoch 0063, iter [03900, 05004], lr: 0.001000, loss: 1.3064
2022-03-14 04:50:06 - train: epoch 0063, iter [04000, 05004], lr: 0.001000, loss: 1.2323
2022-03-14 04:50:39 - train: epoch 0063, iter [04100, 05004], lr: 0.001000, loss: 1.6425
2022-03-14 04:51:13 - train: epoch 0063, iter [04200, 05004], lr: 0.001000, loss: 1.4731
2022-03-14 04:51:47 - train: epoch 0063, iter [04300, 05004], lr: 0.001000, loss: 1.6084
2022-03-14 04:52:20 - train: epoch 0063, iter [04400, 05004], lr: 0.001000, loss: 1.5399
2022-03-14 04:52:54 - train: epoch 0063, iter [04500, 05004], lr: 0.001000, loss: 1.4312
2022-03-14 04:53:27 - train: epoch 0063, iter [04600, 05004], lr: 0.001000, loss: 1.4399
2022-03-14 04:54:02 - train: epoch 0063, iter [04700, 05004], lr: 0.001000, loss: 1.3948
2022-03-14 04:54:35 - train: epoch 0063, iter [04800, 05004], lr: 0.001000, loss: 1.6017
2022-03-14 04:55:09 - train: epoch 0063, iter [04900, 05004], lr: 0.001000, loss: 1.4407
2022-03-14 04:55:41 - train: epoch 0063, iter [05000, 05004], lr: 0.001000, loss: 1.5307
2022-03-14 04:55:41 - train: epoch 063, train_loss: 1.5442
2022-03-14 04:56:57 - eval: epoch: 063, acc1: 67.456%, acc5: 87.816%, test_loss: 1.3163, per_image_load_time: 2.432ms, per_image_inference_time: 0.196ms
2022-03-14 04:56:57 - until epoch: 063, best_acc1: 67.456%
2022-03-14 04:56:57 - epoch 064 lr: 0.0010000000000000002
2022-03-14 04:57:35 - train: epoch 0064, iter [00100, 05004], lr: 0.001000, loss: 1.3933
2022-03-14 04:58:10 - train: epoch 0064, iter [00200, 05004], lr: 0.001000, loss: 1.5533
2022-03-14 04:58:43 - train: epoch 0064, iter [00300, 05004], lr: 0.001000, loss: 1.3911
2022-03-14 04:59:16 - train: epoch 0064, iter [00400, 05004], lr: 0.001000, loss: 1.5978
2022-03-14 04:59:49 - train: epoch 0064, iter [00500, 05004], lr: 0.001000, loss: 1.4054
2022-03-14 05:00:23 - train: epoch 0064, iter [00600, 05004], lr: 0.001000, loss: 1.7853
2022-03-14 05:00:56 - train: epoch 0064, iter [00700, 05004], lr: 0.001000, loss: 1.5831
2022-03-14 05:01:30 - train: epoch 0064, iter [00800, 05004], lr: 0.001000, loss: 1.4019
2022-03-14 05:02:03 - train: epoch 0064, iter [00900, 05004], lr: 0.001000, loss: 1.4358
2022-03-14 05:02:36 - train: epoch 0064, iter [01000, 05004], lr: 0.001000, loss: 1.5127
2022-03-14 05:03:10 - train: epoch 0064, iter [01100, 05004], lr: 0.001000, loss: 1.4888
2022-03-14 05:03:44 - train: epoch 0064, iter [01200, 05004], lr: 0.001000, loss: 1.3755
2022-03-14 05:04:17 - train: epoch 0064, iter [01300, 05004], lr: 0.001000, loss: 1.5359
2022-03-14 05:04:51 - train: epoch 0064, iter [01400, 05004], lr: 0.001000, loss: 1.8149
2022-03-14 05:05:25 - train: epoch 0064, iter [01500, 05004], lr: 0.001000, loss: 1.6166
2022-03-14 05:05:57 - train: epoch 0064, iter [01600, 05004], lr: 0.001000, loss: 1.4033
2022-03-14 05:06:32 - train: epoch 0064, iter [01700, 05004], lr: 0.001000, loss: 1.3686
2022-03-14 05:07:05 - train: epoch 0064, iter [01800, 05004], lr: 0.001000, loss: 1.4200
2022-03-14 05:07:39 - train: epoch 0064, iter [01900, 05004], lr: 0.001000, loss: 1.3656
2022-03-14 05:08:12 - train: epoch 0064, iter [02000, 05004], lr: 0.001000, loss: 1.4356
2022-03-14 05:08:46 - train: epoch 0064, iter [02100, 05004], lr: 0.001000, loss: 1.5454
2022-03-14 05:09:19 - train: epoch 0064, iter [02200, 05004], lr: 0.001000, loss: 1.6406
2022-03-14 05:09:53 - train: epoch 0064, iter [02300, 05004], lr: 0.001000, loss: 1.6703
2022-03-14 05:10:27 - train: epoch 0064, iter [02400, 05004], lr: 0.001000, loss: 1.5408
2022-03-14 05:11:00 - train: epoch 0064, iter [02500, 05004], lr: 0.001000, loss: 1.4962
2022-03-14 05:11:34 - train: epoch 0064, iter [02600, 05004], lr: 0.001000, loss: 1.4594
2022-03-14 05:12:07 - train: epoch 0064, iter [02700, 05004], lr: 0.001000, loss: 1.6200
2022-03-14 05:12:41 - train: epoch 0064, iter [02800, 05004], lr: 0.001000, loss: 1.3729
2022-03-14 05:13:14 - train: epoch 0064, iter [02900, 05004], lr: 0.001000, loss: 1.7724
2022-03-14 05:13:48 - train: epoch 0064, iter [03000, 05004], lr: 0.001000, loss: 1.5774
2022-03-14 05:14:22 - train: epoch 0064, iter [03100, 05004], lr: 0.001000, loss: 1.4735
2022-03-14 05:14:56 - train: epoch 0064, iter [03200, 05004], lr: 0.001000, loss: 1.5732
2022-03-14 05:15:29 - train: epoch 0064, iter [03300, 05004], lr: 0.001000, loss: 1.4187
2022-03-14 05:16:04 - train: epoch 0064, iter [03400, 05004], lr: 0.001000, loss: 1.6975
2022-03-14 05:16:37 - train: epoch 0064, iter [03500, 05004], lr: 0.001000, loss: 1.4998
2022-03-14 05:17:11 - train: epoch 0064, iter [03600, 05004], lr: 0.001000, loss: 1.4376
2022-03-14 05:17:45 - train: epoch 0064, iter [03700, 05004], lr: 0.001000, loss: 1.2406
2022-03-14 05:18:19 - train: epoch 0064, iter [03800, 05004], lr: 0.001000, loss: 1.6710
2022-03-14 05:18:52 - train: epoch 0064, iter [03900, 05004], lr: 0.001000, loss: 1.5072
2022-03-14 05:19:26 - train: epoch 0064, iter [04000, 05004], lr: 0.001000, loss: 1.4520
2022-03-14 05:19:59 - train: epoch 0064, iter [04100, 05004], lr: 0.001000, loss: 1.6169
2022-03-14 05:20:33 - train: epoch 0064, iter [04200, 05004], lr: 0.001000, loss: 1.4495
2022-03-14 05:21:06 - train: epoch 0064, iter [04300, 05004], lr: 0.001000, loss: 1.7221
2022-03-14 05:21:40 - train: epoch 0064, iter [04400, 05004], lr: 0.001000, loss: 1.5071
2022-03-14 05:22:13 - train: epoch 0064, iter [04500, 05004], lr: 0.001000, loss: 1.3953
2022-03-14 05:22:47 - train: epoch 0064, iter [04600, 05004], lr: 0.001000, loss: 1.7484
2022-03-14 05:23:20 - train: epoch 0064, iter [04700, 05004], lr: 0.001000, loss: 1.8995
2022-03-14 05:23:54 - train: epoch 0064, iter [04800, 05004], lr: 0.001000, loss: 1.5262
2022-03-14 05:24:28 - train: epoch 0064, iter [04900, 05004], lr: 0.001000, loss: 1.7001
2022-03-14 05:24:59 - train: epoch 0064, iter [05000, 05004], lr: 0.001000, loss: 1.4063
2022-03-14 05:25:00 - train: epoch 064, train_loss: 1.5350
2022-03-14 05:26:15 - eval: epoch: 064, acc1: 67.872%, acc5: 87.926%, test_loss: 1.3085, per_image_load_time: 2.597ms, per_image_inference_time: 0.174ms
2022-03-14 05:26:15 - until epoch: 064, best_acc1: 67.872%
2022-03-14 05:26:15 - epoch 065 lr: 0.0010000000000000002
2022-03-14 05:26:54 - train: epoch 0065, iter [00100, 05004], lr: 0.001000, loss: 1.6687
2022-03-14 05:27:28 - train: epoch 0065, iter [00200, 05004], lr: 0.001000, loss: 1.5356
2022-03-14 05:28:01 - train: epoch 0065, iter [00300, 05004], lr: 0.001000, loss: 1.5762
2022-03-14 05:28:35 - train: epoch 0065, iter [00400, 05004], lr: 0.001000, loss: 1.6517
2022-03-14 05:29:09 - train: epoch 0065, iter [00500, 05004], lr: 0.001000, loss: 1.4860
2022-03-14 05:29:42 - train: epoch 0065, iter [00600, 05004], lr: 0.001000, loss: 1.5202
2022-03-14 05:30:16 - train: epoch 0065, iter [00700, 05004], lr: 0.001000, loss: 1.4612
2022-03-14 05:30:49 - train: epoch 0065, iter [00800, 05004], lr: 0.001000, loss: 1.4039
2022-03-14 05:31:23 - train: epoch 0065, iter [00900, 05004], lr: 0.001000, loss: 1.3420
2022-03-14 05:31:56 - train: epoch 0065, iter [01000, 05004], lr: 0.001000, loss: 1.4806
2022-03-14 05:32:30 - train: epoch 0065, iter [01100, 05004], lr: 0.001000, loss: 1.5749
2022-03-14 05:33:04 - train: epoch 0065, iter [01200, 05004], lr: 0.001000, loss: 1.7700
2022-03-14 05:33:37 - train: epoch 0065, iter [01300, 05004], lr: 0.001000, loss: 1.4326
2022-03-14 05:34:11 - train: epoch 0065, iter [01400, 05004], lr: 0.001000, loss: 1.3737
2022-03-14 05:34:45 - train: epoch 0065, iter [01500, 05004], lr: 0.001000, loss: 1.5525
2022-03-14 05:35:18 - train: epoch 0065, iter [01600, 05004], lr: 0.001000, loss: 1.4927
2022-03-14 05:35:51 - train: epoch 0065, iter [01700, 05004], lr: 0.001000, loss: 1.4221
2022-03-14 05:36:25 - train: epoch 0065, iter [01800, 05004], lr: 0.001000, loss: 1.4117
2022-03-14 05:36:58 - train: epoch 0065, iter [01900, 05004], lr: 0.001000, loss: 1.2747
2022-03-14 05:37:33 - train: epoch 0065, iter [02000, 05004], lr: 0.001000, loss: 1.4070
2022-03-14 05:38:06 - train: epoch 0065, iter [02100, 05004], lr: 0.001000, loss: 1.4474
2022-03-14 05:38:40 - train: epoch 0065, iter [02200, 05004], lr: 0.001000, loss: 1.6250
2022-03-14 05:39:13 - train: epoch 0065, iter [02300, 05004], lr: 0.001000, loss: 1.4556
2022-03-14 05:39:46 - train: epoch 0065, iter [02400, 05004], lr: 0.001000, loss: 1.4016
2022-03-14 05:40:20 - train: epoch 0065, iter [02500, 05004], lr: 0.001000, loss: 1.4803
2022-03-14 05:40:54 - train: epoch 0065, iter [02600, 05004], lr: 0.001000, loss: 1.7804
2022-03-14 05:41:28 - train: epoch 0065, iter [02700, 05004], lr: 0.001000, loss: 1.5963
2022-03-14 05:42:01 - train: epoch 0065, iter [02800, 05004], lr: 0.001000, loss: 1.4125
2022-03-14 05:42:34 - train: epoch 0065, iter [02900, 05004], lr: 0.001000, loss: 1.5948
2022-03-14 05:43:08 - train: epoch 0065, iter [03000, 05004], lr: 0.001000, loss: 1.3864
2022-03-14 05:43:42 - train: epoch 0065, iter [03100, 05004], lr: 0.001000, loss: 1.5573
2022-03-14 05:44:16 - train: epoch 0065, iter [03200, 05004], lr: 0.001000, loss: 1.6567
2022-03-14 05:44:49 - train: epoch 0065, iter [03300, 05004], lr: 0.001000, loss: 1.4570
2022-03-14 05:45:23 - train: epoch 0065, iter [03400, 05004], lr: 0.001000, loss: 1.3508
2022-03-14 05:45:56 - train: epoch 0065, iter [03500, 05004], lr: 0.001000, loss: 1.7886
2022-03-14 05:46:30 - train: epoch 0065, iter [03600, 05004], lr: 0.001000, loss: 1.5562
2022-03-14 05:47:03 - train: epoch 0065, iter [03700, 05004], lr: 0.001000, loss: 1.3907
2022-03-14 05:47:37 - train: epoch 0065, iter [03800, 05004], lr: 0.001000, loss: 1.3938
2022-03-14 05:48:10 - train: epoch 0065, iter [03900, 05004], lr: 0.001000, loss: 1.6413
2022-03-14 05:48:43 - train: epoch 0065, iter [04000, 05004], lr: 0.001000, loss: 1.5724
2022-03-14 05:49:17 - train: epoch 0065, iter [04100, 05004], lr: 0.001000, loss: 1.4455
2022-03-14 05:49:52 - train: epoch 0065, iter [04200, 05004], lr: 0.001000, loss: 1.5849
2022-03-14 05:50:25 - train: epoch 0065, iter [04300, 05004], lr: 0.001000, loss: 1.4764
2022-03-14 05:50:59 - train: epoch 0065, iter [04400, 05004], lr: 0.001000, loss: 1.5435
2022-03-14 05:51:32 - train: epoch 0065, iter [04500, 05004], lr: 0.001000, loss: 1.4590
2022-03-14 05:52:06 - train: epoch 0065, iter [04600, 05004], lr: 0.001000, loss: 1.5967
2022-03-14 05:52:39 - train: epoch 0065, iter [04700, 05004], lr: 0.001000, loss: 1.6178
2022-03-14 05:53:14 - train: epoch 0065, iter [04800, 05004], lr: 0.001000, loss: 1.2788
2022-03-14 05:53:47 - train: epoch 0065, iter [04900, 05004], lr: 0.001000, loss: 1.4641
2022-03-14 05:54:19 - train: epoch 0065, iter [05000, 05004], lr: 0.001000, loss: 1.6142
2022-03-14 05:54:20 - train: epoch 065, train_loss: 1.5256
2022-03-14 05:55:34 - eval: epoch: 065, acc1: 67.872%, acc5: 87.968%, test_loss: 1.3046, per_image_load_time: 2.083ms, per_image_inference_time: 0.186ms
2022-03-14 05:55:34 - until epoch: 065, best_acc1: 67.872%
2022-03-14 05:55:34 - epoch 066 lr: 0.0010000000000000002
2022-03-14 05:56:13 - train: epoch 0066, iter [00100, 05004], lr: 0.001000, loss: 1.5135
2022-03-14 05:56:47 - train: epoch 0066, iter [00200, 05004], lr: 0.001000, loss: 1.7011
2022-03-14 05:57:20 - train: epoch 0066, iter [00300, 05004], lr: 0.001000, loss: 1.3683
2022-03-14 05:57:55 - train: epoch 0066, iter [00400, 05004], lr: 0.001000, loss: 1.2709
2022-03-14 05:58:28 - train: epoch 0066, iter [00500, 05004], lr: 0.001000, loss: 1.5175
2022-03-14 05:59:02 - train: epoch 0066, iter [00600, 05004], lr: 0.001000, loss: 1.5704
2022-03-14 05:59:35 - train: epoch 0066, iter [00700, 05004], lr: 0.001000, loss: 1.5229
2022-03-14 06:00:09 - train: epoch 0066, iter [00800, 05004], lr: 0.001000, loss: 1.8416
2022-03-14 06:00:42 - train: epoch 0066, iter [00900, 05004], lr: 0.001000, loss: 1.6405
2022-03-14 06:01:16 - train: epoch 0066, iter [01000, 05004], lr: 0.001000, loss: 1.5919
2022-03-14 06:01:49 - train: epoch 0066, iter [01100, 05004], lr: 0.001000, loss: 1.5478
2022-03-14 06:02:23 - train: epoch 0066, iter [01200, 05004], lr: 0.001000, loss: 1.6449
2022-03-14 06:02:56 - train: epoch 0066, iter [01300, 05004], lr: 0.001000, loss: 1.6929
2022-03-14 06:03:30 - train: epoch 0066, iter [01400, 05004], lr: 0.001000, loss: 1.3843
2022-03-14 06:04:04 - train: epoch 0066, iter [01500, 05004], lr: 0.001000, loss: 1.5592
2022-03-14 06:04:38 - train: epoch 0066, iter [01600, 05004], lr: 0.001000, loss: 1.6005
2022-03-14 06:05:11 - train: epoch 0066, iter [01700, 05004], lr: 0.001000, loss: 1.4453
2022-03-14 06:05:45 - train: epoch 0066, iter [01800, 05004], lr: 0.001000, loss: 1.2855
2022-03-14 06:06:18 - train: epoch 0066, iter [01900, 05004], lr: 0.001000, loss: 1.8259
2022-03-14 06:06:52 - train: epoch 0066, iter [02000, 05004], lr: 0.001000, loss: 1.5579
2022-03-14 06:07:24 - train: epoch 0066, iter [02100, 05004], lr: 0.001000, loss: 1.5686
2022-03-14 06:07:58 - train: epoch 0066, iter [02200, 05004], lr: 0.001000, loss: 1.4921
2022-03-14 06:08:32 - train: epoch 0066, iter [02300, 05004], lr: 0.001000, loss: 1.7457
2022-03-14 06:09:06 - train: epoch 0066, iter [02400, 05004], lr: 0.001000, loss: 1.4402
2022-03-14 06:09:39 - train: epoch 0066, iter [02500, 05004], lr: 0.001000, loss: 1.5094
2022-03-14 06:10:13 - train: epoch 0066, iter [02600, 05004], lr: 0.001000, loss: 1.3785
2022-03-14 06:10:46 - train: epoch 0066, iter [02700, 05004], lr: 0.001000, loss: 1.7067
2022-03-14 06:11:20 - train: epoch 0066, iter [02800, 05004], lr: 0.001000, loss: 1.5855
2022-03-14 06:11:54 - train: epoch 0066, iter [02900, 05004], lr: 0.001000, loss: 1.4601
2022-03-14 06:12:28 - train: epoch 0066, iter [03000, 05004], lr: 0.001000, loss: 1.4501
2022-03-14 06:13:01 - train: epoch 0066, iter [03100, 05004], lr: 0.001000, loss: 1.7081
2022-03-14 06:13:35 - train: epoch 0066, iter [03200, 05004], lr: 0.001000, loss: 1.3990
2022-03-14 06:14:10 - train: epoch 0066, iter [03300, 05004], lr: 0.001000, loss: 1.4536
2022-03-14 06:14:43 - train: epoch 0066, iter [03400, 05004], lr: 0.001000, loss: 1.7097
2022-03-14 06:15:17 - train: epoch 0066, iter [03500, 05004], lr: 0.001000, loss: 1.5610
2022-03-14 06:15:50 - train: epoch 0066, iter [03600, 05004], lr: 0.001000, loss: 1.6174
2022-03-14 06:16:25 - train: epoch 0066, iter [03700, 05004], lr: 0.001000, loss: 1.5511
2022-03-14 06:16:58 - train: epoch 0066, iter [03800, 05004], lr: 0.001000, loss: 1.3660
2022-03-14 06:17:32 - train: epoch 0066, iter [03900, 05004], lr: 0.001000, loss: 1.3988
2022-03-14 06:18:05 - train: epoch 0066, iter [04000, 05004], lr: 0.001000, loss: 1.6413
2022-03-14 06:18:38 - train: epoch 0066, iter [04100, 05004], lr: 0.001000, loss: 1.2920
2022-03-14 06:19:12 - train: epoch 0066, iter [04200, 05004], lr: 0.001000, loss: 1.3527
2022-03-14 06:19:46 - train: epoch 0066, iter [04300, 05004], lr: 0.001000, loss: 1.3125
2022-03-14 06:20:19 - train: epoch 0066, iter [04400, 05004], lr: 0.001000, loss: 1.4349
2022-03-14 06:20:52 - train: epoch 0066, iter [04500, 05004], lr: 0.001000, loss: 1.5414
2022-03-14 06:21:27 - train: epoch 0066, iter [04600, 05004], lr: 0.001000, loss: 1.6642
2022-03-14 06:22:01 - train: epoch 0066, iter [04700, 05004], lr: 0.001000, loss: 1.4248
2022-03-14 06:22:34 - train: epoch 0066, iter [04800, 05004], lr: 0.001000, loss: 1.5131
2022-03-14 06:23:08 - train: epoch 0066, iter [04900, 05004], lr: 0.001000, loss: 1.4494
2022-03-14 06:23:40 - train: epoch 0066, iter [05000, 05004], lr: 0.001000, loss: 1.4043
2022-03-14 06:23:41 - train: epoch 066, train_loss: 1.5199
2022-03-14 06:24:55 - eval: epoch: 066, acc1: 67.926%, acc5: 88.016%, test_loss: 1.3010, per_image_load_time: 2.363ms, per_image_inference_time: 0.175ms
2022-03-14 06:24:56 - until epoch: 066, best_acc1: 67.926%
2022-03-14 06:24:56 - epoch 067 lr: 0.0010000000000000002
2022-03-14 06:25:35 - train: epoch 0067, iter [00100, 05004], lr: 0.001000, loss: 1.4088
2022-03-14 06:26:09 - train: epoch 0067, iter [00200, 05004], lr: 0.001000, loss: 1.4882
2022-03-14 06:26:42 - train: epoch 0067, iter [00300, 05004], lr: 0.001000, loss: 1.7026
2022-03-14 06:27:16 - train: epoch 0067, iter [00400, 05004], lr: 0.001000, loss: 1.5941
2022-03-14 06:27:50 - train: epoch 0067, iter [00500, 05004], lr: 0.001000, loss: 1.4178
2022-03-14 06:28:23 - train: epoch 0067, iter [00600, 05004], lr: 0.001000, loss: 1.3531
2022-03-14 06:28:57 - train: epoch 0067, iter [00700, 05004], lr: 0.001000, loss: 1.5172
2022-03-14 06:29:30 - train: epoch 0067, iter [00800, 05004], lr: 0.001000, loss: 1.6124
2022-03-14 06:30:04 - train: epoch 0067, iter [00900, 05004], lr: 0.001000, loss: 1.7045
2022-03-14 06:30:37 - train: epoch 0067, iter [01000, 05004], lr: 0.001000, loss: 1.3999
2022-03-14 06:31:11 - train: epoch 0067, iter [01100, 05004], lr: 0.001000, loss: 1.5969
2022-03-14 06:31:44 - train: epoch 0067, iter [01200, 05004], lr: 0.001000, loss: 1.5073
2022-03-14 06:32:18 - train: epoch 0067, iter [01300, 05004], lr: 0.001000, loss: 1.6656
2022-03-14 06:32:51 - train: epoch 0067, iter [01400, 05004], lr: 0.001000, loss: 1.4545
2022-03-14 06:33:25 - train: epoch 0067, iter [01500, 05004], lr: 0.001000, loss: 1.5374
2022-03-14 06:33:58 - train: epoch 0067, iter [01600, 05004], lr: 0.001000, loss: 1.5764
2022-03-14 06:34:33 - train: epoch 0067, iter [01700, 05004], lr: 0.001000, loss: 1.4083
2022-03-14 06:35:06 - train: epoch 0067, iter [01800, 05004], lr: 0.001000, loss: 1.7505
2022-03-14 06:35:40 - train: epoch 0067, iter [01900, 05004], lr: 0.001000, loss: 1.4087
2022-03-14 06:36:13 - train: epoch 0067, iter [02000, 05004], lr: 0.001000, loss: 1.6620
2022-03-14 06:36:47 - train: epoch 0067, iter [02100, 05004], lr: 0.001000, loss: 1.4022
2022-03-14 06:37:20 - train: epoch 0067, iter [02200, 05004], lr: 0.001000, loss: 1.5881
2022-03-14 06:37:55 - train: epoch 0067, iter [02300, 05004], lr: 0.001000, loss: 1.4800
2022-03-14 06:38:28 - train: epoch 0067, iter [02400, 05004], lr: 0.001000, loss: 1.5373
2022-03-14 06:39:02 - train: epoch 0067, iter [02500, 05004], lr: 0.001000, loss: 1.3984
2022-03-14 06:39:35 - train: epoch 0067, iter [02600, 05004], lr: 0.001000, loss: 1.4491
2022-03-14 06:40:08 - train: epoch 0067, iter [02700, 05004], lr: 0.001000, loss: 1.3958
2022-03-14 06:40:43 - train: epoch 0067, iter [02800, 05004], lr: 0.001000, loss: 1.6186
2022-03-14 06:41:16 - train: epoch 0067, iter [02900, 05004], lr: 0.001000, loss: 1.4725
2022-03-14 06:41:50 - train: epoch 0067, iter [03000, 05004], lr: 0.001000, loss: 1.4977
2022-03-14 06:42:24 - train: epoch 0067, iter [03100, 05004], lr: 0.001000, loss: 1.3255
2022-03-14 06:42:57 - train: epoch 0067, iter [03200, 05004], lr: 0.001000, loss: 1.6960
2022-03-14 06:43:31 - train: epoch 0067, iter [03300, 05004], lr: 0.001000, loss: 1.3269
2022-03-14 06:44:04 - train: epoch 0067, iter [03400, 05004], lr: 0.001000, loss: 1.5777
2022-03-14 06:44:39 - train: epoch 0067, iter [03500, 05004], lr: 0.001000, loss: 1.4597
2022-03-14 06:45:12 - train: epoch 0067, iter [03600, 05004], lr: 0.001000, loss: 1.5070
2022-03-14 06:45:46 - train: epoch 0067, iter [03700, 05004], lr: 0.001000, loss: 1.7223
2022-03-14 06:46:19 - train: epoch 0067, iter [03800, 05004], lr: 0.001000, loss: 1.5571
2022-03-14 06:46:54 - train: epoch 0067, iter [03900, 05004], lr: 0.001000, loss: 1.6088
2022-03-14 06:47:26 - train: epoch 0067, iter [04000, 05004], lr: 0.001000, loss: 1.6243
2022-03-14 06:48:00 - train: epoch 0067, iter [04100, 05004], lr: 0.001000, loss: 1.7477
2022-03-14 06:48:33 - train: epoch 0067, iter [04200, 05004], lr: 0.001000, loss: 1.8003
2022-03-14 06:49:07 - train: epoch 0067, iter [04300, 05004], lr: 0.001000, loss: 1.3422
2022-03-14 06:49:40 - train: epoch 0067, iter [04400, 05004], lr: 0.001000, loss: 1.5804
2022-03-14 06:50:15 - train: epoch 0067, iter [04500, 05004], lr: 0.001000, loss: 1.3029
2022-03-14 06:50:48 - train: epoch 0067, iter [04600, 05004], lr: 0.001000, loss: 1.2052
2022-03-14 06:51:23 - train: epoch 0067, iter [04700, 05004], lr: 0.001000, loss: 1.4237
2022-03-14 06:51:55 - train: epoch 0067, iter [04800, 05004], lr: 0.001000, loss: 1.2583
2022-03-14 06:52:30 - train: epoch 0067, iter [04900, 05004], lr: 0.001000, loss: 1.5729
2022-03-14 06:53:01 - train: epoch 0067, iter [05000, 05004], lr: 0.001000, loss: 1.6219
2022-03-14 06:53:02 - train: epoch 067, train_loss: 1.5152
2022-03-14 06:54:17 - eval: epoch: 067, acc1: 67.842%, acc5: 88.032%, test_loss: 1.3023, per_image_load_time: 2.705ms, per_image_inference_time: 0.178ms
2022-03-14 06:54:17 - until epoch: 067, best_acc1: 67.926%
2022-03-14 06:54:17 - epoch 068 lr: 0.0010000000000000002
2022-03-14 06:54:55 - train: epoch 0068, iter [00100, 05004], lr: 0.001000, loss: 1.6131
2022-03-14 06:55:29 - train: epoch 0068, iter [00200, 05004], lr: 0.001000, loss: 1.4686
2022-03-14 06:56:03 - train: epoch 0068, iter [00300, 05004], lr: 0.001000, loss: 1.6239
2022-03-14 06:56:36 - train: epoch 0068, iter [00400, 05004], lr: 0.001000, loss: 1.4732
2022-03-14 06:57:10 - train: epoch 0068, iter [00500, 05004], lr: 0.001000, loss: 1.4251
2022-03-14 06:57:45 - train: epoch 0068, iter [00600, 05004], lr: 0.001000, loss: 1.5018
2022-03-14 06:58:18 - train: epoch 0068, iter [00700, 05004], lr: 0.001000, loss: 1.7761
2022-03-14 06:58:52 - train: epoch 0068, iter [00800, 05004], lr: 0.001000, loss: 1.5380
2022-03-14 06:59:25 - train: epoch 0068, iter [00900, 05004], lr: 0.001000, loss: 1.4483
2022-03-14 06:59:59 - train: epoch 0068, iter [01000, 05004], lr: 0.001000, loss: 1.4601
2022-03-14 07:00:32 - train: epoch 0068, iter [01100, 05004], lr: 0.001000, loss: 1.7067
2022-03-14 07:01:06 - train: epoch 0068, iter [01200, 05004], lr: 0.001000, loss: 1.3591
2022-03-14 07:01:39 - train: epoch 0068, iter [01300, 05004], lr: 0.001000, loss: 1.3436
2022-03-14 07:02:13 - train: epoch 0068, iter [01400, 05004], lr: 0.001000, loss: 1.5443
2022-03-14 07:02:46 - train: epoch 0068, iter [01500, 05004], lr: 0.001000, loss: 1.6667
2022-03-14 07:03:20 - train: epoch 0068, iter [01600, 05004], lr: 0.001000, loss: 1.5773
2022-03-14 07:03:53 - train: epoch 0068, iter [01700, 05004], lr: 0.001000, loss: 1.6950
2022-03-14 07:04:28 - train: epoch 0068, iter [01800, 05004], lr: 0.001000, loss: 1.5429
2022-03-14 07:05:01 - train: epoch 0068, iter [01900, 05004], lr: 0.001000, loss: 1.5980
2022-03-14 07:05:35 - train: epoch 0068, iter [02000, 05004], lr: 0.001000, loss: 1.6166
2022-03-14 07:06:07 - train: epoch 0068, iter [02100, 05004], lr: 0.001000, loss: 1.5207
2022-03-14 07:06:42 - train: epoch 0068, iter [02200, 05004], lr: 0.001000, loss: 1.5247
2022-03-14 07:07:15 - train: epoch 0068, iter [02300, 05004], lr: 0.001000, loss: 1.3811
2022-03-14 07:07:49 - train: epoch 0068, iter [02400, 05004], lr: 0.001000, loss: 1.5666
2022-03-14 07:08:22 - train: epoch 0068, iter [02500, 05004], lr: 0.001000, loss: 1.6391
2022-03-14 07:08:56 - train: epoch 0068, iter [02600, 05004], lr: 0.001000, loss: 1.5848
2022-03-14 07:09:30 - train: epoch 0068, iter [02700, 05004], lr: 0.001000, loss: 1.5477
2022-03-14 07:10:03 - train: epoch 0068, iter [02800, 05004], lr: 0.001000, loss: 1.7015
2022-03-14 07:10:37 - train: epoch 0068, iter [02900, 05004], lr: 0.001000, loss: 1.6457
2022-03-14 07:11:10 - train: epoch 0068, iter [03000, 05004], lr: 0.001000, loss: 1.7005
2022-03-14 07:11:44 - train: epoch 0068, iter [03100, 05004], lr: 0.001000, loss: 1.3490
2022-03-14 07:12:17 - train: epoch 0068, iter [03200, 05004], lr: 0.001000, loss: 1.5971
2022-03-14 07:12:52 - train: epoch 0068, iter [03300, 05004], lr: 0.001000, loss: 1.5397
2022-03-14 07:13:25 - train: epoch 0068, iter [03400, 05004], lr: 0.001000, loss: 1.3143
2022-03-14 07:13:59 - train: epoch 0068, iter [03500, 05004], lr: 0.001000, loss: 1.4748
2022-03-14 07:14:32 - train: epoch 0068, iter [03600, 05004], lr: 0.001000, loss: 1.3712
2022-03-14 07:15:06 - train: epoch 0068, iter [03700, 05004], lr: 0.001000, loss: 1.5555
2022-03-14 07:15:39 - train: epoch 0068, iter [03800, 05004], lr: 0.001000, loss: 1.6585
2022-03-14 07:16:13 - train: epoch 0068, iter [03900, 05004], lr: 0.001000, loss: 1.5756
2022-03-14 07:16:45 - train: epoch 0068, iter [04000, 05004], lr: 0.001000, loss: 1.5198
2022-03-14 07:17:20 - train: epoch 0068, iter [04100, 05004], lr: 0.001000, loss: 1.3140
2022-03-14 07:17:54 - train: epoch 0068, iter [04200, 05004], lr: 0.001000, loss: 1.5998
2022-03-14 07:18:27 - train: epoch 0068, iter [04300, 05004], lr: 0.001000, loss: 1.5727
2022-03-14 07:19:01 - train: epoch 0068, iter [04400, 05004], lr: 0.001000, loss: 1.5124
2022-03-14 07:19:34 - train: epoch 0068, iter [04500, 05004], lr: 0.001000, loss: 1.5300
2022-03-14 07:20:08 - train: epoch 0068, iter [04600, 05004], lr: 0.001000, loss: 1.5218
2022-03-14 07:20:41 - train: epoch 0068, iter [04700, 05004], lr: 0.001000, loss: 1.7837
2022-03-14 07:21:15 - train: epoch 0068, iter [04800, 05004], lr: 0.001000, loss: 1.6255
2022-03-14 07:21:49 - train: epoch 0068, iter [04900, 05004], lr: 0.001000, loss: 1.6086
2022-03-14 07:22:21 - train: epoch 0068, iter [05000, 05004], lr: 0.001000, loss: 1.5837
2022-03-14 07:22:22 - train: epoch 068, train_loss: 1.5106
2022-03-14 07:23:36 - eval: epoch: 068, acc1: 67.938%, acc5: 88.152%, test_loss: 1.2943, per_image_load_time: 2.580ms, per_image_inference_time: 0.192ms
2022-03-14 07:23:37 - until epoch: 068, best_acc1: 67.938%
2022-03-14 07:23:37 - epoch 069 lr: 0.0010000000000000002
2022-03-14 07:24:15 - train: epoch 0069, iter [00100, 05004], lr: 0.001000, loss: 1.6612
2022-03-14 07:24:49 - train: epoch 0069, iter [00200, 05004], lr: 0.001000, loss: 1.7012
2022-03-14 07:25:23 - train: epoch 0069, iter [00300, 05004], lr: 0.001000, loss: 1.4770
2022-03-14 07:25:56 - train: epoch 0069, iter [00400, 05004], lr: 0.001000, loss: 1.4208
2022-03-14 07:26:29 - train: epoch 0069, iter [00500, 05004], lr: 0.001000, loss: 1.3874
2022-03-14 07:27:03 - train: epoch 0069, iter [00600, 05004], lr: 0.001000, loss: 1.3631
2022-03-14 07:27:37 - train: epoch 0069, iter [00700, 05004], lr: 0.001000, loss: 1.4385
2022-03-14 07:28:10 - train: epoch 0069, iter [00800, 05004], lr: 0.001000, loss: 1.4892
2022-03-14 07:28:44 - train: epoch 0069, iter [00900, 05004], lr: 0.001000, loss: 1.4840
2022-03-14 07:29:17 - train: epoch 0069, iter [01000, 05004], lr: 0.001000, loss: 1.5357
2022-03-14 07:29:50 - train: epoch 0069, iter [01100, 05004], lr: 0.001000, loss: 1.4898
2022-03-14 07:30:24 - train: epoch 0069, iter [01200, 05004], lr: 0.001000, loss: 1.4388
2022-03-14 07:30:57 - train: epoch 0069, iter [01300, 05004], lr: 0.001000, loss: 1.8730
2022-03-14 07:31:31 - train: epoch 0069, iter [01400, 05004], lr: 0.001000, loss: 1.5613
2022-03-14 07:32:05 - train: epoch 0069, iter [01500, 05004], lr: 0.001000, loss: 1.4894
2022-03-14 07:32:38 - train: epoch 0069, iter [01600, 05004], lr: 0.001000, loss: 1.6614
2022-03-14 07:33:12 - train: epoch 0069, iter [01700, 05004], lr: 0.001000, loss: 1.4249
2022-03-14 07:33:45 - train: epoch 0069, iter [01800, 05004], lr: 0.001000, loss: 1.3563
2022-03-14 07:34:19 - train: epoch 0069, iter [01900, 05004], lr: 0.001000, loss: 1.4940
2022-03-14 07:34:53 - train: epoch 0069, iter [02000, 05004], lr: 0.001000, loss: 1.2479
2022-03-14 07:35:26 - train: epoch 0069, iter [02100, 05004], lr: 0.001000, loss: 1.5548
2022-03-14 07:36:00 - train: epoch 0069, iter [02200, 05004], lr: 0.001000, loss: 1.5324
2022-03-14 07:36:33 - train: epoch 0069, iter [02300, 05004], lr: 0.001000, loss: 1.5584
2022-03-14 07:37:08 - train: epoch 0069, iter [02400, 05004], lr: 0.001000, loss: 1.6273
2022-03-14 07:37:41 - train: epoch 0069, iter [02500, 05004], lr: 0.001000, loss: 1.5005
2022-03-14 07:38:15 - train: epoch 0069, iter [02600, 05004], lr: 0.001000, loss: 1.5123
2022-03-14 07:38:48 - train: epoch 0069, iter [02700, 05004], lr: 0.001000, loss: 1.7805
2022-03-14 07:39:22 - train: epoch 0069, iter [02800, 05004], lr: 0.001000, loss: 1.6644
2022-03-14 07:39:55 - train: epoch 0069, iter [02900, 05004], lr: 0.001000, loss: 1.3565
2022-03-14 07:40:29 - train: epoch 0069, iter [03000, 05004], lr: 0.001000, loss: 1.4629
2022-03-14 07:41:03 - train: epoch 0069, iter [03100, 05004], lr: 0.001000, loss: 1.3618
2022-03-14 07:41:36 - train: epoch 0069, iter [03200, 05004], lr: 0.001000, loss: 1.3884
2022-03-14 07:42:10 - train: epoch 0069, iter [03300, 05004], lr: 0.001000, loss: 1.4383
2022-03-14 07:42:44 - train: epoch 0069, iter [03400, 05004], lr: 0.001000, loss: 1.3752
2022-03-14 07:43:17 - train: epoch 0069, iter [03500, 05004], lr: 0.001000, loss: 1.3845
2022-03-14 07:43:51 - train: epoch 0069, iter [03600, 05004], lr: 0.001000, loss: 1.3339
2022-03-14 07:44:25 - train: epoch 0069, iter [03700, 05004], lr: 0.001000, loss: 1.5322
2022-03-14 07:44:58 - train: epoch 0069, iter [03800, 05004], lr: 0.001000, loss: 1.5982
2022-03-14 07:45:32 - train: epoch 0069, iter [03900, 05004], lr: 0.001000, loss: 1.4193
2022-03-14 07:46:06 - train: epoch 0069, iter [04000, 05004], lr: 0.001000, loss: 1.6050
2022-03-14 07:46:39 - train: epoch 0069, iter [04100, 05004], lr: 0.001000, loss: 1.5532
2022-03-14 07:47:13 - train: epoch 0069, iter [04200, 05004], lr: 0.001000, loss: 1.4342
2022-03-14 07:47:47 - train: epoch 0069, iter [04300, 05004], lr: 0.001000, loss: 1.6020
2022-03-14 07:48:21 - train: epoch 0069, iter [04400, 05004], lr: 0.001000, loss: 1.5255
2022-03-14 07:48:55 - train: epoch 0069, iter [04500, 05004], lr: 0.001000, loss: 1.5649
2022-03-14 07:49:28 - train: epoch 0069, iter [04600, 05004], lr: 0.001000, loss: 1.6541
2022-03-14 07:50:01 - train: epoch 0069, iter [04700, 05004], lr: 0.001000, loss: 1.4888
2022-03-14 07:50:36 - train: epoch 0069, iter [04800, 05004], lr: 0.001000, loss: 1.5356
2022-03-14 07:51:09 - train: epoch 0069, iter [04900, 05004], lr: 0.001000, loss: 1.4894
2022-03-14 07:51:41 - train: epoch 0069, iter [05000, 05004], lr: 0.001000, loss: 1.5530
2022-03-14 07:51:42 - train: epoch 069, train_loss: 1.5051
2022-03-14 07:52:56 - eval: epoch: 069, acc1: 68.066%, acc5: 88.108%, test_loss: 1.2923, per_image_load_time: 2.701ms, per_image_inference_time: 0.194ms
2022-03-14 07:52:56 - until epoch: 069, best_acc1: 68.066%
2022-03-14 07:52:56 - epoch 070 lr: 0.0010000000000000002
2022-03-14 07:53:35 - train: epoch 0070, iter [00100, 05004], lr: 0.001000, loss: 1.6416
2022-03-14 07:54:10 - train: epoch 0070, iter [00200, 05004], lr: 0.001000, loss: 1.6199
2022-03-14 07:54:42 - train: epoch 0070, iter [00300, 05004], lr: 0.001000, loss: 1.5934
2022-03-14 07:55:17 - train: epoch 0070, iter [00400, 05004], lr: 0.001000, loss: 1.4543
2022-03-14 07:55:50 - train: epoch 0070, iter [00500, 05004], lr: 0.001000, loss: 1.5163
2022-03-14 07:56:25 - train: epoch 0070, iter [00600, 05004], lr: 0.001000, loss: 1.4823
2022-03-14 07:56:58 - train: epoch 0070, iter [00700, 05004], lr: 0.001000, loss: 1.4086
2022-03-14 07:57:31 - train: epoch 0070, iter [00800, 05004], lr: 0.001000, loss: 1.4900
2022-03-14 07:58:05 - train: epoch 0070, iter [00900, 05004], lr: 0.001000, loss: 1.5215
2022-03-14 07:58:38 - train: epoch 0070, iter [01000, 05004], lr: 0.001000, loss: 1.4749
2022-03-14 07:59:12 - train: epoch 0070, iter [01100, 05004], lr: 0.001000, loss: 1.8698
2022-03-14 07:59:46 - train: epoch 0070, iter [01200, 05004], lr: 0.001000, loss: 1.3254
2022-03-14 08:00:19 - train: epoch 0070, iter [01300, 05004], lr: 0.001000, loss: 1.5215
2022-03-14 08:00:53 - train: epoch 0070, iter [01400, 05004], lr: 0.001000, loss: 1.4719
2022-03-14 08:01:26 - train: epoch 0070, iter [01500, 05004], lr: 0.001000, loss: 1.3914
2022-03-14 08:01:59 - train: epoch 0070, iter [01600, 05004], lr: 0.001000, loss: 1.5557
2022-03-14 08:02:34 - train: epoch 0070, iter [01700, 05004], lr: 0.001000, loss: 1.6426
2022-03-14 08:03:06 - train: epoch 0070, iter [01800, 05004], lr: 0.001000, loss: 1.3709
2022-03-14 08:03:40 - train: epoch 0070, iter [01900, 05004], lr: 0.001000, loss: 1.4021
2022-03-14 08:04:13 - train: epoch 0070, iter [02000, 05004], lr: 0.001000, loss: 1.4957
2022-03-14 08:04:47 - train: epoch 0070, iter [02100, 05004], lr: 0.001000, loss: 1.5995
2022-03-14 08:05:21 - train: epoch 0070, iter [02200, 05004], lr: 0.001000, loss: 1.5274
2022-03-14 08:05:54 - train: epoch 0070, iter [02300, 05004], lr: 0.001000, loss: 1.5155
2022-03-14 08:06:28 - train: epoch 0070, iter [02400, 05004], lr: 0.001000, loss: 1.6181
2022-03-14 08:07:02 - train: epoch 0070, iter [02500, 05004], lr: 0.001000, loss: 1.5120
2022-03-14 08:07:36 - train: epoch 0070, iter [02600, 05004], lr: 0.001000, loss: 1.5476
2022-03-14 08:08:09 - train: epoch 0070, iter [02700, 05004], lr: 0.001000, loss: 1.4952
2022-03-14 08:08:44 - train: epoch 0070, iter [02800, 05004], lr: 0.001000, loss: 1.6323
2022-03-14 08:09:18 - train: epoch 0070, iter [02900, 05004], lr: 0.001000, loss: 1.7133
2022-03-14 08:09:51 - train: epoch 0070, iter [03000, 05004], lr: 0.001000, loss: 1.4272
2022-03-14 08:10:24 - train: epoch 0070, iter [03100, 05004], lr: 0.001000, loss: 1.5729
2022-03-14 08:10:58 - train: epoch 0070, iter [03200, 05004], lr: 0.001000, loss: 1.6190
2022-03-14 08:11:32 - train: epoch 0070, iter [03300, 05004], lr: 0.001000, loss: 1.4754
2022-03-14 08:12:06 - train: epoch 0070, iter [03400, 05004], lr: 0.001000, loss: 1.5871
2022-03-14 08:12:40 - train: epoch 0070, iter [03500, 05004], lr: 0.001000, loss: 1.5663
2022-03-14 08:13:13 - train: epoch 0070, iter [03600, 05004], lr: 0.001000, loss: 1.5565
2022-03-14 08:13:47 - train: epoch 0070, iter [03700, 05004], lr: 0.001000, loss: 1.5749
2022-03-14 08:14:20 - train: epoch 0070, iter [03800, 05004], lr: 0.001000, loss: 1.4041
2022-03-14 08:14:54 - train: epoch 0070, iter [03900, 05004], lr: 0.001000, loss: 1.4078
2022-03-14 08:15:28 - train: epoch 0070, iter [04000, 05004], lr: 0.001000, loss: 1.4023
2022-03-14 08:16:01 - train: epoch 0070, iter [04100, 05004], lr: 0.001000, loss: 1.3640
2022-03-14 08:16:36 - train: epoch 0070, iter [04200, 05004], lr: 0.001000, loss: 1.5521
2022-03-14 08:17:10 - train: epoch 0070, iter [04300, 05004], lr: 0.001000, loss: 1.5671
2022-03-14 08:17:44 - train: epoch 0070, iter [04400, 05004], lr: 0.001000, loss: 1.5781
2022-03-14 08:18:18 - train: epoch 0070, iter [04500, 05004], lr: 0.001000, loss: 1.4837
2022-03-14 08:18:51 - train: epoch 0070, iter [04600, 05004], lr: 0.001000, loss: 1.5771
2022-03-14 08:19:26 - train: epoch 0070, iter [04700, 05004], lr: 0.001000, loss: 1.5091
2022-03-14 08:19:59 - train: epoch 0070, iter [04800, 05004], lr: 0.001000, loss: 1.5461
2022-03-14 08:20:33 - train: epoch 0070, iter [04900, 05004], lr: 0.001000, loss: 1.6050
2022-03-14 08:21:05 - train: epoch 0070, iter [05000, 05004], lr: 0.001000, loss: 1.5707
2022-03-14 08:21:06 - train: epoch 070, train_loss: 1.5023
2022-03-14 08:22:21 - eval: epoch: 070, acc1: 68.122%, acc5: 88.106%, test_loss: 1.2901, per_image_load_time: 2.724ms, per_image_inference_time: 0.204ms
2022-03-14 08:22:21 - until epoch: 070, best_acc1: 68.122%
2022-03-14 08:22:21 - epoch 071 lr: 0.0010000000000000002
2022-03-14 08:23:00 - train: epoch 0071, iter [00100, 05004], lr: 0.001000, loss: 1.3579
2022-03-14 08:23:34 - train: epoch 0071, iter [00200, 05004], lr: 0.001000, loss: 1.5101
2022-03-14 08:24:07 - train: epoch 0071, iter [00300, 05004], lr: 0.001000, loss: 1.4292
2022-03-14 08:24:40 - train: epoch 0071, iter [00400, 05004], lr: 0.001000, loss: 1.5262
2022-03-14 08:25:14 - train: epoch 0071, iter [00500, 05004], lr: 0.001000, loss: 1.5663
2022-03-14 08:25:46 - train: epoch 0071, iter [00600, 05004], lr: 0.001000, loss: 1.6602
2022-03-14 08:26:20 - train: epoch 0071, iter [00700, 05004], lr: 0.001000, loss: 1.6427
2022-03-14 08:26:54 - train: epoch 0071, iter [00800, 05004], lr: 0.001000, loss: 1.4447
2022-03-14 08:27:28 - train: epoch 0071, iter [00900, 05004], lr: 0.001000, loss: 1.5416
2022-03-14 08:28:01 - train: epoch 0071, iter [01000, 05004], lr: 0.001000, loss: 1.6137
2022-03-14 08:28:35 - train: epoch 0071, iter [01100, 05004], lr: 0.001000, loss: 1.6803
2022-03-14 08:29:09 - train: epoch 0071, iter [01200, 05004], lr: 0.001000, loss: 1.4595
2022-03-14 08:29:41 - train: epoch 0071, iter [01300, 05004], lr: 0.001000, loss: 1.5182
2022-03-14 08:30:15 - train: epoch 0071, iter [01400, 05004], lr: 0.001000, loss: 1.5391
2022-03-14 08:30:48 - train: epoch 0071, iter [01500, 05004], lr: 0.001000, loss: 1.3420
2022-03-14 08:31:23 - train: epoch 0071, iter [01600, 05004], lr: 0.001000, loss: 1.3433
2022-03-14 08:31:56 - train: epoch 0071, iter [01700, 05004], lr: 0.001000, loss: 1.4623
2022-03-14 08:32:30 - train: epoch 0071, iter [01800, 05004], lr: 0.001000, loss: 1.4619
2022-03-14 08:33:03 - train: epoch 0071, iter [01900, 05004], lr: 0.001000, loss: 1.4301
2022-03-14 08:33:37 - train: epoch 0071, iter [02000, 05004], lr: 0.001000, loss: 1.6111
2022-03-14 08:34:10 - train: epoch 0071, iter [02100, 05004], lr: 0.001000, loss: 1.3489
2022-03-14 08:34:44 - train: epoch 0071, iter [02200, 05004], lr: 0.001000, loss: 1.2687
2022-03-14 08:35:17 - train: epoch 0071, iter [02300, 05004], lr: 0.001000, loss: 1.4364
2022-03-14 08:35:52 - train: epoch 0071, iter [02400, 05004], lr: 0.001000, loss: 1.4721
2022-03-14 08:36:25 - train: epoch 0071, iter [02500, 05004], lr: 0.001000, loss: 1.6473
2022-03-14 08:36:59 - train: epoch 0071, iter [02600, 05004], lr: 0.001000, loss: 1.3838
2022-03-14 08:37:32 - train: epoch 0071, iter [02700, 05004], lr: 0.001000, loss: 1.4947
2022-03-14 08:38:05 - train: epoch 0071, iter [02800, 05004], lr: 0.001000, loss: 1.5992
2022-03-14 08:38:39 - train: epoch 0071, iter [02900, 05004], lr: 0.001000, loss: 1.4312
2022-03-14 08:39:13 - train: epoch 0071, iter [03000, 05004], lr: 0.001000, loss: 1.5765
2022-03-14 08:39:48 - train: epoch 0071, iter [03100, 05004], lr: 0.001000, loss: 1.4082
2022-03-14 08:40:24 - train: epoch 0071, iter [03200, 05004], lr: 0.001000, loss: 1.3038
2022-03-14 08:40:59 - train: epoch 0071, iter [03300, 05004], lr: 0.001000, loss: 1.3773
2022-03-14 08:41:34 - train: epoch 0071, iter [03400, 05004], lr: 0.001000, loss: 1.3694
2022-03-14 08:42:07 - train: epoch 0071, iter [03500, 05004], lr: 0.001000, loss: 1.5989
2022-03-14 08:42:40 - train: epoch 0071, iter [03600, 05004], lr: 0.001000, loss: 1.6255
2022-03-14 08:43:14 - train: epoch 0071, iter [03700, 05004], lr: 0.001000, loss: 1.4688
2022-03-14 08:43:48 - train: epoch 0071, iter [03800, 05004], lr: 0.001000, loss: 1.5027
2022-03-14 08:44:21 - train: epoch 0071, iter [03900, 05004], lr: 0.001000, loss: 1.4371
2022-03-14 08:44:55 - train: epoch 0071, iter [04000, 05004], lr: 0.001000, loss: 1.6866
2022-03-14 08:45:28 - train: epoch 0071, iter [04100, 05004], lr: 0.001000, loss: 1.4205
2022-03-14 08:46:02 - train: epoch 0071, iter [04200, 05004], lr: 0.001000, loss: 1.6451
2022-03-14 08:46:35 - train: epoch 0071, iter [04300, 05004], lr: 0.001000, loss: 1.4842
2022-03-14 08:47:09 - train: epoch 0071, iter [04400, 05004], lr: 0.001000, loss: 1.5909
2022-03-14 08:47:43 - train: epoch 0071, iter [04500, 05004], lr: 0.001000, loss: 1.4008
2022-03-14 08:48:16 - train: epoch 0071, iter [04600, 05004], lr: 0.001000, loss: 1.6254
2022-03-14 08:48:49 - train: epoch 0071, iter [04700, 05004], lr: 0.001000, loss: 1.4557
2022-03-14 08:49:24 - train: epoch 0071, iter [04800, 05004], lr: 0.001000, loss: 1.4633
2022-03-14 08:49:57 - train: epoch 0071, iter [04900, 05004], lr: 0.001000, loss: 1.2916
2022-03-14 08:50:29 - train: epoch 0071, iter [05000, 05004], lr: 0.001000, loss: 1.3287
2022-03-14 08:50:30 - train: epoch 071, train_loss: 1.4983
2022-03-14 08:51:45 - eval: epoch: 071, acc1: 68.064%, acc5: 88.300%, test_loss: 1.2886, per_image_load_time: 2.559ms, per_image_inference_time: 0.208ms
2022-03-14 08:51:45 - until epoch: 071, best_acc1: 68.122%
2022-03-14 08:51:45 - epoch 072 lr: 0.0010000000000000002
2022-03-14 08:52:24 - train: epoch 0072, iter [00100, 05004], lr: 0.001000, loss: 1.6136
2022-03-14 08:52:58 - train: epoch 0072, iter [00200, 05004], lr: 0.001000, loss: 1.2449
2022-03-14 08:53:32 - train: epoch 0072, iter [00300, 05004], lr: 0.001000, loss: 1.4712
2022-03-14 08:54:05 - train: epoch 0072, iter [00400, 05004], lr: 0.001000, loss: 1.5800
2022-03-14 08:54:38 - train: epoch 0072, iter [00500, 05004], lr: 0.001000, loss: 1.3969
2022-03-14 08:55:12 - train: epoch 0072, iter [00600, 05004], lr: 0.001000, loss: 1.3530
2022-03-14 08:55:45 - train: epoch 0072, iter [00700, 05004], lr: 0.001000, loss: 1.4852
2022-03-14 08:56:19 - train: epoch 0072, iter [00800, 05004], lr: 0.001000, loss: 1.6506
2022-03-14 08:56:52 - train: epoch 0072, iter [00900, 05004], lr: 0.001000, loss: 1.4171
2022-03-14 08:57:26 - train: epoch 0072, iter [01000, 05004], lr: 0.001000, loss: 1.4412
2022-03-14 08:58:00 - train: epoch 0072, iter [01100, 05004], lr: 0.001000, loss: 1.5798
2022-03-14 08:58:34 - train: epoch 0072, iter [01200, 05004], lr: 0.001000, loss: 1.3759
2022-03-14 08:59:08 - train: epoch 0072, iter [01300, 05004], lr: 0.001000, loss: 1.4362
2022-03-14 08:59:42 - train: epoch 0072, iter [01400, 05004], lr: 0.001000, loss: 1.5555
2022-03-14 09:00:16 - train: epoch 0072, iter [01500, 05004], lr: 0.001000, loss: 1.4186
2022-03-14 09:00:49 - train: epoch 0072, iter [01600, 05004], lr: 0.001000, loss: 1.6273
2022-03-14 09:01:24 - train: epoch 0072, iter [01700, 05004], lr: 0.001000, loss: 1.3970
2022-03-14 09:01:56 - train: epoch 0072, iter [01800, 05004], lr: 0.001000, loss: 1.3866
2022-03-14 09:02:30 - train: epoch 0072, iter [01900, 05004], lr: 0.001000, loss: 1.3857
2022-03-14 09:03:05 - train: epoch 0072, iter [02000, 05004], lr: 0.001000, loss: 1.5866
2022-03-14 09:03:38 - train: epoch 0072, iter [02100, 05004], lr: 0.001000, loss: 1.5870
2022-03-14 09:04:12 - train: epoch 0072, iter [02200, 05004], lr: 0.001000, loss: 1.6514
2022-03-14 09:04:45 - train: epoch 0072, iter [02300, 05004], lr: 0.001000, loss: 1.6927
2022-03-14 09:05:20 - train: epoch 0072, iter [02400, 05004], lr: 0.001000, loss: 1.5149
2022-03-14 09:05:54 - train: epoch 0072, iter [02500, 05004], lr: 0.001000, loss: 1.3489
2022-03-14 09:06:28 - train: epoch 0072, iter [02600, 05004], lr: 0.001000, loss: 1.3348
2022-03-14 09:07:01 - train: epoch 0072, iter [02700, 05004], lr: 0.001000, loss: 1.4701
2022-03-14 09:07:36 - train: epoch 0072, iter [02800, 05004], lr: 0.001000, loss: 1.6438
2022-03-14 09:08:09 - train: epoch 0072, iter [02900, 05004], lr: 0.001000, loss: 1.4511
2022-03-14 09:08:43 - train: epoch 0072, iter [03000, 05004], lr: 0.001000, loss: 1.3541
2022-03-14 09:09:17 - train: epoch 0072, iter [03100, 05004], lr: 0.001000, loss: 1.5405
2022-03-14 09:09:51 - train: epoch 0072, iter [03200, 05004], lr: 0.001000, loss: 1.4101
2022-03-14 09:10:24 - train: epoch 0072, iter [03300, 05004], lr: 0.001000, loss: 1.4002
2022-03-14 09:10:58 - train: epoch 0072, iter [03400, 05004], lr: 0.001000, loss: 1.6380
2022-03-14 09:11:32 - train: epoch 0072, iter [03500, 05004], lr: 0.001000, loss: 1.5205
2022-03-14 09:12:05 - train: epoch 0072, iter [03600, 05004], lr: 0.001000, loss: 1.4937
2022-03-14 09:12:39 - train: epoch 0072, iter [03700, 05004], lr: 0.001000, loss: 1.5570
2022-03-14 09:13:13 - train: epoch 0072, iter [03800, 05004], lr: 0.001000, loss: 1.5008
2022-03-14 09:13:47 - train: epoch 0072, iter [03900, 05004], lr: 0.001000, loss: 1.5890
2022-03-14 09:14:21 - train: epoch 0072, iter [04000, 05004], lr: 0.001000, loss: 1.4968
2022-03-14 09:14:55 - train: epoch 0072, iter [04100, 05004], lr: 0.001000, loss: 1.6453
2022-03-14 09:15:29 - train: epoch 0072, iter [04200, 05004], lr: 0.001000, loss: 1.5646
2022-03-14 09:16:03 - train: epoch 0072, iter [04300, 05004], lr: 0.001000, loss: 1.5010
2022-03-14 09:16:37 - train: epoch 0072, iter [04400, 05004], lr: 0.001000, loss: 1.3887
2022-03-14 09:17:11 - train: epoch 0072, iter [04500, 05004], lr: 0.001000, loss: 1.6106
2022-03-14 09:17:45 - train: epoch 0072, iter [04600, 05004], lr: 0.001000, loss: 1.3508
2022-03-14 09:18:18 - train: epoch 0072, iter [04700, 05004], lr: 0.001000, loss: 1.5146
2022-03-14 09:18:53 - train: epoch 0072, iter [04800, 05004], lr: 0.001000, loss: 1.6740
2022-03-14 09:19:27 - train: epoch 0072, iter [04900, 05004], lr: 0.001000, loss: 1.4545
2022-03-14 09:19:59 - train: epoch 0072, iter [05000, 05004], lr: 0.001000, loss: 1.4121
2022-03-14 09:20:00 - train: epoch 072, train_loss: 1.4963
2022-03-14 09:21:15 - eval: epoch: 072, acc1: 68.088%, acc5: 88.182%, test_loss: 1.2888, per_image_load_time: 2.481ms, per_image_inference_time: 0.182ms
2022-03-14 09:21:15 - until epoch: 072, best_acc1: 68.122%
2022-03-14 09:21:15 - epoch 073 lr: 0.0010000000000000002
2022-03-14 09:21:54 - train: epoch 0073, iter [00100, 05004], lr: 0.001000, loss: 1.7697
2022-03-14 09:22:28 - train: epoch 0073, iter [00200, 05004], lr: 0.001000, loss: 1.5180
2022-03-14 09:23:02 - train: epoch 0073, iter [00300, 05004], lr: 0.001000, loss: 1.5889
2022-03-14 09:23:36 - train: epoch 0073, iter [00400, 05004], lr: 0.001000, loss: 1.2389
2022-03-14 09:24:10 - train: epoch 0073, iter [00500, 05004], lr: 0.001000, loss: 1.4500
2022-03-14 09:24:43 - train: epoch 0073, iter [00600, 05004], lr: 0.001000, loss: 1.3468
2022-03-14 09:25:17 - train: epoch 0073, iter [00700, 05004], lr: 0.001000, loss: 1.5157
2022-03-14 09:25:50 - train: epoch 0073, iter [00800, 05004], lr: 0.001000, loss: 1.4162
2022-03-14 09:26:24 - train: epoch 0073, iter [00900, 05004], lr: 0.001000, loss: 1.2927
2022-03-14 09:26:58 - train: epoch 0073, iter [01000, 05004], lr: 0.001000, loss: 1.4050
2022-03-14 09:27:31 - train: epoch 0073, iter [01100, 05004], lr: 0.001000, loss: 1.5785
2022-03-14 09:28:06 - train: epoch 0073, iter [01200, 05004], lr: 0.001000, loss: 1.4543
2022-03-14 09:28:38 - train: epoch 0073, iter [01300, 05004], lr: 0.001000, loss: 1.4854
2022-03-14 09:29:13 - train: epoch 0073, iter [01400, 05004], lr: 0.001000, loss: 1.4168
2022-03-14 09:29:46 - train: epoch 0073, iter [01500, 05004], lr: 0.001000, loss: 1.4703
2022-03-14 09:30:20 - train: epoch 0073, iter [01600, 05004], lr: 0.001000, loss: 1.5271
2022-03-14 09:30:53 - train: epoch 0073, iter [01700, 05004], lr: 0.001000, loss: 1.8125
2022-03-14 09:31:27 - train: epoch 0073, iter [01800, 05004], lr: 0.001000, loss: 1.3046
2022-03-14 09:32:01 - train: epoch 0073, iter [01900, 05004], lr: 0.001000, loss: 1.5543
2022-03-14 09:32:36 - train: epoch 0073, iter [02000, 05004], lr: 0.001000, loss: 1.2324
2022-03-14 09:33:08 - train: epoch 0073, iter [02100, 05004], lr: 0.001000, loss: 1.4693
2022-03-14 09:33:43 - train: epoch 0073, iter [02200, 05004], lr: 0.001000, loss: 1.5296
2022-03-14 09:34:17 - train: epoch 0073, iter [02300, 05004], lr: 0.001000, loss: 1.5532
2022-03-14 09:34:51 - train: epoch 0073, iter [02400, 05004], lr: 0.001000, loss: 1.4432
2022-03-14 09:35:25 - train: epoch 0073, iter [02500, 05004], lr: 0.001000, loss: 1.6279
2022-03-14 09:35:59 - train: epoch 0073, iter [02600, 05004], lr: 0.001000, loss: 1.5357
2022-03-14 09:36:34 - train: epoch 0073, iter [02700, 05004], lr: 0.001000, loss: 1.5575
2022-03-14 09:37:07 - train: epoch 0073, iter [02800, 05004], lr: 0.001000, loss: 1.4971
2022-03-14 09:37:42 - train: epoch 0073, iter [02900, 05004], lr: 0.001000, loss: 1.6278
2022-03-14 09:38:15 - train: epoch 0073, iter [03000, 05004], lr: 0.001000, loss: 1.2812
2022-03-14 09:38:50 - train: epoch 0073, iter [03100, 05004], lr: 0.001000, loss: 1.4598
2022-03-14 09:39:23 - train: epoch 0073, iter [03200, 05004], lr: 0.001000, loss: 1.3318
2022-03-14 09:39:58 - train: epoch 0073, iter [03300, 05004], lr: 0.001000, loss: 1.5539
2022-03-14 09:40:32 - train: epoch 0073, iter [03400, 05004], lr: 0.001000, loss: 1.4753
2022-03-14 09:41:06 - train: epoch 0073, iter [03500, 05004], lr: 0.001000, loss: 1.6326
2022-03-14 09:41:39 - train: epoch 0073, iter [03600, 05004], lr: 0.001000, loss: 1.3774
2022-03-14 09:42:14 - train: epoch 0073, iter [03700, 05004], lr: 0.001000, loss: 1.5298
2022-03-14 09:42:47 - train: epoch 0073, iter [03800, 05004], lr: 0.001000, loss: 1.7557
2022-03-14 09:43:21 - train: epoch 0073, iter [03900, 05004], lr: 0.001000, loss: 1.4408
2022-03-14 09:43:55 - train: epoch 0073, iter [04000, 05004], lr: 0.001000, loss: 1.6025
2022-03-14 09:44:29 - train: epoch 0073, iter [04100, 05004], lr: 0.001000, loss: 1.4324
2022-03-14 09:45:03 - train: epoch 0073, iter [04200, 05004], lr: 0.001000, loss: 1.7291
2022-03-14 09:45:38 - train: epoch 0073, iter [04300, 05004], lr: 0.001000, loss: 1.4747
2022-03-14 09:46:11 - train: epoch 0073, iter [04400, 05004], lr: 0.001000, loss: 1.5422
2022-03-14 09:46:46 - train: epoch 0073, iter [04500, 05004], lr: 0.001000, loss: 1.3043
2022-03-14 09:47:18 - train: epoch 0073, iter [04600, 05004], lr: 0.001000, loss: 1.7369
2022-03-14 09:47:53 - train: epoch 0073, iter [04700, 05004], lr: 0.001000, loss: 1.3130
2022-03-14 09:48:26 - train: epoch 0073, iter [04800, 05004], lr: 0.001000, loss: 1.5642
2022-03-14 09:49:01 - train: epoch 0073, iter [04900, 05004], lr: 0.001000, loss: 1.3856
2022-03-14 09:49:32 - train: epoch 0073, iter [05000, 05004], lr: 0.001000, loss: 1.5799
2022-03-14 09:49:33 - train: epoch 073, train_loss: 1.4940
2022-03-14 09:50:49 - eval: epoch: 073, acc1: 68.220%, acc5: 88.314%, test_loss: 1.2855, per_image_load_time: 2.677ms, per_image_inference_time: 0.194ms
2022-03-14 09:50:49 - until epoch: 073, best_acc1: 68.220%
2022-03-14 09:50:49 - epoch 074 lr: 0.0010000000000000002
2022-03-14 09:51:27 - train: epoch 0074, iter [00100, 05004], lr: 0.001000, loss: 1.4115
2022-03-14 09:52:02 - train: epoch 0074, iter [00200, 05004], lr: 0.001000, loss: 1.5919
2022-03-14 09:52:35 - train: epoch 0074, iter [00300, 05004], lr: 0.001000, loss: 1.5732
2022-03-14 09:53:09 - train: epoch 0074, iter [00400, 05004], lr: 0.001000, loss: 1.7145
2022-03-14 09:53:41 - train: epoch 0074, iter [00500, 05004], lr: 0.001000, loss: 1.4611
2022-03-14 09:54:15 - train: epoch 0074, iter [00600, 05004], lr: 0.001000, loss: 1.5138
2022-03-14 09:54:49 - train: epoch 0074, iter [00700, 05004], lr: 0.001000, loss: 1.5189
2022-03-14 09:55:22 - train: epoch 0074, iter [00800, 05004], lr: 0.001000, loss: 1.6678
2022-03-14 09:55:56 - train: epoch 0074, iter [00900, 05004], lr: 0.001000, loss: 1.4027
2022-03-14 09:56:29 - train: epoch 0074, iter [01000, 05004], lr: 0.001000, loss: 1.5758
2022-03-14 09:57:02 - train: epoch 0074, iter [01100, 05004], lr: 0.001000, loss: 1.6401
2022-03-14 09:57:35 - train: epoch 0074, iter [01200, 05004], lr: 0.001000, loss: 1.3642
2022-03-14 09:58:09 - train: epoch 0074, iter [01300, 05004], lr: 0.001000, loss: 1.5332
2022-03-14 09:58:43 - train: epoch 0074, iter [01400, 05004], lr: 0.001000, loss: 1.3305
2022-03-14 09:59:15 - train: epoch 0074, iter [01500, 05004], lr: 0.001000, loss: 1.4438
2022-03-14 09:59:49 - train: epoch 0074, iter [01600, 05004], lr: 0.001000, loss: 1.3139
2022-03-14 10:00:23 - train: epoch 0074, iter [01700, 05004], lr: 0.001000, loss: 1.6318
2022-03-14 10:00:56 - train: epoch 0074, iter [01800, 05004], lr: 0.001000, loss: 1.8057
2022-03-14 10:01:30 - train: epoch 0074, iter [01900, 05004], lr: 0.001000, loss: 1.6366
2022-03-14 10:02:04 - train: epoch 0074, iter [02000, 05004], lr: 0.001000, loss: 1.2321
2022-03-14 10:02:37 - train: epoch 0074, iter [02100, 05004], lr: 0.001000, loss: 1.5432
2022-03-14 10:03:11 - train: epoch 0074, iter [02200, 05004], lr: 0.001000, loss: 1.8456
2022-03-14 10:03:45 - train: epoch 0074, iter [02300, 05004], lr: 0.001000, loss: 1.6272
2022-03-14 10:04:19 - train: epoch 0074, iter [02400, 05004], lr: 0.001000, loss: 1.4351
2022-03-14 10:04:53 - train: epoch 0074, iter [02500, 05004], lr: 0.001000, loss: 1.2737
2022-03-14 10:05:27 - train: epoch 0074, iter [02600, 05004], lr: 0.001000, loss: 1.2754
2022-03-14 10:06:02 - train: epoch 0074, iter [02700, 05004], lr: 0.001000, loss: 1.4833
2022-03-14 10:06:35 - train: epoch 0074, iter [02800, 05004], lr: 0.001000, loss: 1.7732
2022-03-14 10:07:08 - train: epoch 0074, iter [02900, 05004], lr: 0.001000, loss: 1.4234
2022-03-14 10:07:43 - train: epoch 0074, iter [03000, 05004], lr: 0.001000, loss: 1.5611
2022-03-14 10:08:16 - train: epoch 0074, iter [03100, 05004], lr: 0.001000, loss: 1.4464
2022-03-14 10:08:49 - train: epoch 0074, iter [03200, 05004], lr: 0.001000, loss: 1.4335
2022-03-14 10:09:24 - train: epoch 0074, iter [03300, 05004], lr: 0.001000, loss: 1.5643
2022-03-14 10:09:56 - train: epoch 0074, iter [03400, 05004], lr: 0.001000, loss: 1.4833
2022-03-14 10:10:31 - train: epoch 0074, iter [03500, 05004], lr: 0.001000, loss: 1.2824
2022-03-14 10:11:04 - train: epoch 0074, iter [03600, 05004], lr: 0.001000, loss: 1.5521
2022-03-14 10:11:39 - train: epoch 0074, iter [03700, 05004], lr: 0.001000, loss: 1.5826
2022-03-14 10:12:13 - train: epoch 0074, iter [03800, 05004], lr: 0.001000, loss: 1.4369
2022-03-14 10:12:47 - train: epoch 0074, iter [03900, 05004], lr: 0.001000, loss: 1.2876
2022-03-14 10:13:20 - train: epoch 0074, iter [04000, 05004], lr: 0.001000, loss: 1.3763
2022-03-14 10:13:54 - train: epoch 0074, iter [04100, 05004], lr: 0.001000, loss: 1.6534
2022-03-14 10:14:28 - train: epoch 0074, iter [04200, 05004], lr: 0.001000, loss: 1.5296
2022-03-14 10:15:01 - train: epoch 0074, iter [04300, 05004], lr: 0.001000, loss: 1.4681
2022-03-14 10:15:36 - train: epoch 0074, iter [04400, 05004], lr: 0.001000, loss: 1.3078
2022-03-14 10:16:09 - train: epoch 0074, iter [04500, 05004], lr: 0.001000, loss: 1.2346
2022-03-14 10:16:44 - train: epoch 0074, iter [04600, 05004], lr: 0.001000, loss: 1.6182
2022-03-14 10:17:17 - train: epoch 0074, iter [04700, 05004], lr: 0.001000, loss: 1.5364
2022-03-14 10:17:51 - train: epoch 0074, iter [04800, 05004], lr: 0.001000, loss: 1.4995
2022-03-14 10:18:25 - train: epoch 0074, iter [04900, 05004], lr: 0.001000, loss: 1.7400
2022-03-14 10:18:58 - train: epoch 0074, iter [05000, 05004], lr: 0.001000, loss: 1.3495
2022-03-14 10:18:58 - train: epoch 074, train_loss: 1.4894
2022-03-14 10:20:14 - eval: epoch: 074, acc1: 68.350%, acc5: 88.364%, test_loss: 1.2798, per_image_load_time: 1.384ms, per_image_inference_time: 0.197ms
2022-03-14 10:20:14 - until epoch: 074, best_acc1: 68.350%
2022-03-14 10:20:14 - epoch 075 lr: 0.0010000000000000002
2022-03-14 10:20:53 - train: epoch 0075, iter [00100, 05004], lr: 0.001000, loss: 1.6088
2022-03-14 10:21:28 - train: epoch 0075, iter [00200, 05004], lr: 0.001000, loss: 1.4977
2022-03-14 10:22:01 - train: epoch 0075, iter [00300, 05004], lr: 0.001000, loss: 1.4897
2022-03-14 10:22:34 - train: epoch 0075, iter [00400, 05004], lr: 0.001000, loss: 1.5543
2022-03-14 10:23:08 - train: epoch 0075, iter [00500, 05004], lr: 0.001000, loss: 1.3633
2022-03-14 10:23:42 - train: epoch 0075, iter [00600, 05004], lr: 0.001000, loss: 1.3784
2022-03-14 10:24:17 - train: epoch 0075, iter [00700, 05004], lr: 0.001000, loss: 1.6542
2022-03-14 10:24:50 - train: epoch 0075, iter [00800, 05004], lr: 0.001000, loss: 1.6399
2022-03-14 10:25:25 - train: epoch 0075, iter [00900, 05004], lr: 0.001000, loss: 1.5586
2022-03-14 10:25:57 - train: epoch 0075, iter [01000, 05004], lr: 0.001000, loss: 1.2526
2022-03-14 10:26:33 - train: epoch 0075, iter [01100, 05004], lr: 0.001000, loss: 1.6078
2022-03-14 10:27:05 - train: epoch 0075, iter [01200, 05004], lr: 0.001000, loss: 1.4960
2022-03-14 10:27:39 - train: epoch 0075, iter [01300, 05004], lr: 0.001000, loss: 1.3374
2022-03-14 10:28:12 - train: epoch 0075, iter [01400, 05004], lr: 0.001000, loss: 1.3949
2022-03-14 10:28:46 - train: epoch 0075, iter [01500, 05004], lr: 0.001000, loss: 1.6884
2022-03-14 10:29:20 - train: epoch 0075, iter [01600, 05004], lr: 0.001000, loss: 1.1499
2022-03-14 10:29:54 - train: epoch 0075, iter [01700, 05004], lr: 0.001000, loss: 1.3874
2022-03-14 10:30:28 - train: epoch 0075, iter [01800, 05004], lr: 0.001000, loss: 1.4701
2022-03-14 10:31:01 - train: epoch 0075, iter [01900, 05004], lr: 0.001000, loss: 1.4333
2022-03-14 10:31:35 - train: epoch 0075, iter [02000, 05004], lr: 0.001000, loss: 1.4898
2022-03-14 10:32:09 - train: epoch 0075, iter [02100, 05004], lr: 0.001000, loss: 1.3814
2022-03-14 10:32:43 - train: epoch 0075, iter [02200, 05004], lr: 0.001000, loss: 1.5428
2022-03-14 10:33:16 - train: epoch 0075, iter [02300, 05004], lr: 0.001000, loss: 1.4885
2022-03-14 10:33:50 - train: epoch 0075, iter [02400, 05004], lr: 0.001000, loss: 1.5036
2022-03-14 10:34:24 - train: epoch 0075, iter [02500, 05004], lr: 0.001000, loss: 1.4836
2022-03-14 10:34:57 - train: epoch 0075, iter [02600, 05004], lr: 0.001000, loss: 1.5500
2022-03-14 10:35:31 - train: epoch 0075, iter [02700, 05004], lr: 0.001000, loss: 1.1847
2022-03-14 10:36:04 - train: epoch 0075, iter [02800, 05004], lr: 0.001000, loss: 1.5002
2022-03-14 10:36:38 - train: epoch 0075, iter [02900, 05004], lr: 0.001000, loss: 1.5740
2022-03-14 10:37:11 - train: epoch 0075, iter [03000, 05004], lr: 0.001000, loss: 1.6579
2022-03-14 10:37:46 - train: epoch 0075, iter [03100, 05004], lr: 0.001000, loss: 1.5996
2022-03-14 10:38:19 - train: epoch 0075, iter [03200, 05004], lr: 0.001000, loss: 1.4681
2022-03-14 10:38:53 - train: epoch 0075, iter [03300, 05004], lr: 0.001000, loss: 1.5125
2022-03-14 10:39:26 - train: epoch 0075, iter [03400, 05004], lr: 0.001000, loss: 1.3034
2022-03-14 10:40:00 - train: epoch 0075, iter [03500, 05004], lr: 0.001000, loss: 1.3418
2022-03-14 10:40:34 - train: epoch 0075, iter [03600, 05004], lr: 0.001000, loss: 1.4770
2022-03-14 10:41:08 - train: epoch 0075, iter [03700, 05004], lr: 0.001000, loss: 1.5789
2022-03-14 10:41:42 - train: epoch 0075, iter [03800, 05004], lr: 0.001000, loss: 1.4096
2022-03-14 10:42:16 - train: epoch 0075, iter [03900, 05004], lr: 0.001000, loss: 1.7150
2022-03-14 10:42:49 - train: epoch 0075, iter [04000, 05004], lr: 0.001000, loss: 1.3333
2022-03-14 10:43:24 - train: epoch 0075, iter [04100, 05004], lr: 0.001000, loss: 1.2205
2022-03-14 10:43:58 - train: epoch 0075, iter [04200, 05004], lr: 0.001000, loss: 1.5687
2022-03-14 10:44:31 - train: epoch 0075, iter [04300, 05004], lr: 0.001000, loss: 1.6725
2022-03-14 10:45:05 - train: epoch 0075, iter [04400, 05004], lr: 0.001000, loss: 1.2830
2022-03-14 10:45:38 - train: epoch 0075, iter [04500, 05004], lr: 0.001000, loss: 1.5039
2022-03-14 10:46:13 - train: epoch 0075, iter [04600, 05004], lr: 0.001000, loss: 1.2927
2022-03-14 10:46:46 - train: epoch 0075, iter [04700, 05004], lr: 0.001000, loss: 1.7435
2022-03-14 10:47:20 - train: epoch 0075, iter [04800, 05004], lr: 0.001000, loss: 1.5126
2022-03-14 10:47:55 - train: epoch 0075, iter [04900, 05004], lr: 0.001000, loss: 1.2755
2022-03-14 10:48:27 - train: epoch 0075, iter [05000, 05004], lr: 0.001000, loss: 1.5550
2022-03-14 10:48:27 - train: epoch 075, train_loss: 1.4881
2022-03-14 10:49:43 - eval: epoch: 075, acc1: 68.184%, acc5: 88.334%, test_loss: 1.2824, per_image_load_time: 2.526ms, per_image_inference_time: 0.184ms
2022-03-14 10:49:43 - until epoch: 075, best_acc1: 68.350%
2022-03-14 10:49:43 - epoch 076 lr: 0.0010000000000000002
2022-03-14 10:50:22 - train: epoch 0076, iter [00100, 05004], lr: 0.001000, loss: 1.3047
2022-03-14 10:50:56 - train: epoch 0076, iter [00200, 05004], lr: 0.001000, loss: 1.4742
2022-03-14 10:51:30 - train: epoch 0076, iter [00300, 05004], lr: 0.001000, loss: 1.5488
2022-03-14 10:52:03 - train: epoch 0076, iter [00400, 05004], lr: 0.001000, loss: 1.4932
2022-03-14 10:52:37 - train: epoch 0076, iter [00500, 05004], lr: 0.001000, loss: 1.4730
2022-03-14 10:53:11 - train: epoch 0076, iter [00600, 05004], lr: 0.001000, loss: 1.4469
2022-03-14 10:53:44 - train: epoch 0076, iter [00700, 05004], lr: 0.001000, loss: 1.4638
2022-03-14 10:54:18 - train: epoch 0076, iter [00800, 05004], lr: 0.001000, loss: 1.3546
2022-03-14 10:54:52 - train: epoch 0076, iter [00900, 05004], lr: 0.001000, loss: 1.3391
2022-03-14 10:55:26 - train: epoch 0076, iter [01000, 05004], lr: 0.001000, loss: 1.3030
2022-03-14 10:56:00 - train: epoch 0076, iter [01100, 05004], lr: 0.001000, loss: 1.3819
2022-03-14 10:56:34 - train: epoch 0076, iter [01200, 05004], lr: 0.001000, loss: 1.4984
2022-03-14 10:57:07 - train: epoch 0076, iter [01300, 05004], lr: 0.001000, loss: 1.5952
2022-03-14 10:57:42 - train: epoch 0076, iter [01400, 05004], lr: 0.001000, loss: 1.4292
2022-03-14 10:58:15 - train: epoch 0076, iter [01500, 05004], lr: 0.001000, loss: 1.4181
2022-03-14 10:58:48 - train: epoch 0076, iter [01600, 05004], lr: 0.001000, loss: 1.4186
2022-03-14 10:59:23 - train: epoch 0076, iter [01700, 05004], lr: 0.001000, loss: 1.4383
2022-03-14 10:59:56 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 1.2400
2022-03-14 11:00:30 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 1.5341
2022-03-14 11:01:04 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 1.5079
2022-03-14 11:01:38 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 1.5389
2022-03-14 11:02:11 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 1.6044
2022-03-14 11:02:45 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 1.3539
2022-03-14 11:03:20 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 1.7341
2022-03-14 11:03:52 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 1.4479
2022-03-14 11:04:27 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 1.7089
2022-03-14 11:05:01 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 1.5347
2022-03-14 11:05:35 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 1.3807
2022-03-14 11:06:08 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 1.5690
2022-03-14 11:06:43 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 1.2761
2022-03-14 11:07:16 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 1.5854
2022-03-14 11:07:50 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 1.5719
2022-03-14 11:08:25 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 1.4420
2022-03-14 11:08:57 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 1.5375
2022-03-14 11:09:32 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 1.3819
2022-03-14 11:10:05 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 1.3763
2022-03-14 11:10:39 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 1.3297
2022-03-14 11:11:13 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 1.3544
2022-03-14 11:11:47 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 1.4149
2022-03-14 11:12:21 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 1.4774
2022-03-14 11:12:53 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 1.3141
2022-03-14 11:13:27 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 1.6751
2022-03-14 11:14:00 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 1.4870
2022-03-14 11:14:33 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 1.3926
2022-03-14 11:15:05 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 1.4491
2022-03-14 11:15:37 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 1.3587
2022-03-14 11:16:09 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 1.5815
2022-03-14 11:16:43 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 1.3007
2022-03-14 11:17:15 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 1.4943
2022-03-14 11:17:46 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 1.4601
2022-03-14 11:17:46 - train: epoch 076, train_loss: 1.4862
2022-03-14 11:18:58 - eval: epoch: 076, acc1: 68.340%, acc5: 88.336%, test_loss: 1.2810, per_image_load_time: 1.654ms, per_image_inference_time: 0.182ms
2022-03-14 11:18:58 - until epoch: 076, best_acc1: 68.350%
2022-03-14 11:18:58 - epoch 077 lr: 0.0010000000000000002
2022-03-14 11:19:35 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 1.6586
2022-03-14 11:20:07 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 1.6551
2022-03-14 11:20:40 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 1.3157
2022-03-14 11:21:13 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 1.6191
2022-03-14 11:21:44 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 1.3430
2022-03-14 11:22:16 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 1.2818
2022-03-14 11:22:49 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 1.5509
2022-03-14 11:23:21 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 1.6273
2022-03-14 11:23:54 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 1.7317
2022-03-14 11:24:26 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 1.3237
2022-03-14 11:24:59 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 1.5422
2022-03-14 11:25:31 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 1.6212
2022-03-14 11:26:04 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 1.1660
2022-03-14 11:26:35 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 1.6122
2022-03-14 11:27:08 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 1.3630
2022-03-14 11:27:41 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 1.4354
2022-03-14 11:28:14 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 1.7231
2022-03-14 11:28:46 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 1.3521
2022-03-14 11:29:19 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 1.3622
2022-03-14 11:29:51 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 1.4246
2022-03-14 11:30:24 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 1.5290
2022-03-14 11:30:56 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 1.5992
2022-03-14 11:31:28 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 1.6775
2022-03-14 11:32:01 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 1.4516
2022-03-14 11:32:33 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 1.6507
2022-03-14 11:33:06 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 1.1919
2022-03-14 11:33:38 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 1.5215
2022-03-14 11:34:11 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 1.6200
2022-03-14 11:34:43 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 1.8185
2022-03-14 11:35:16 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 1.3780
2022-03-14 11:35:47 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 1.4164
2022-03-14 11:36:21 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 1.6762
2022-03-14 11:36:52 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 1.2905
2022-03-14 11:37:25 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 1.7008
2022-03-14 11:37:58 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 1.3053
2022-03-14 11:38:31 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 1.4416
2022-03-14 11:39:03 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 1.5189
2022-03-14 11:39:36 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 1.4306
2022-03-14 11:40:08 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 1.5233
2022-03-14 11:40:41 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 1.5634
2022-03-14 11:41:12 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 1.5632
2022-03-14 11:41:45 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 1.6051
2022-03-14 11:42:17 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 1.4279
2022-03-14 11:42:50 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 1.4165
2022-03-14 11:43:23 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 1.6690
2022-03-14 11:43:54 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 1.3594
2022-03-14 11:44:27 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 1.2669
2022-03-14 11:44:59 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 1.5138
2022-03-14 11:45:31 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 1.5774
2022-03-14 11:46:02 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 1.6413
2022-03-14 11:46:03 - train: epoch 077, train_loss: 1.4829
2022-03-14 11:47:15 - eval: epoch: 077, acc1: 68.314%, acc5: 88.250%, test_loss: 1.2796, per_image_load_time: 2.111ms, per_image_inference_time: 0.162ms
2022-03-14 11:47:15 - until epoch: 077, best_acc1: 68.350%
2022-03-14 11:47:15 - epoch 078 lr: 0.0010000000000000002
2022-03-14 11:47:52 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 1.4477
2022-03-14 11:48:25 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 1.5812
2022-03-14 11:48:57 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 1.6009
2022-03-14 11:49:30 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 1.4798
2022-03-14 11:50:02 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 1.4424
2022-03-14 11:50:34 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 1.3727
2022-03-14 11:51:06 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 1.6416
2022-03-14 11:51:39 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 1.6762
2022-03-14 11:52:10 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 1.6034
2022-03-14 11:52:42 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 1.5132
2022-03-14 11:53:15 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 1.1886
2022-03-14 11:53:47 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 1.2670
2022-03-14 11:54:20 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 1.6356
2022-03-14 11:54:52 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 1.2768
2022-03-14 11:55:24 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 1.3758
2022-03-14 11:55:56 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 1.5407
2022-03-14 11:56:28 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 1.4691
2022-03-14 11:57:01 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 1.4112
2022-03-14 11:57:33 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 1.3532
2022-03-14 11:58:06 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 1.3958
2022-03-14 11:58:38 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 1.6734
2022-03-14 11:59:11 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 1.4791
2022-03-14 11:59:43 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 1.5624
2022-03-14 12:00:15 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 1.4825
2022-03-14 12:00:48 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 1.2468
2022-03-14 12:01:21 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 1.4397
2022-03-14 12:01:54 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 1.4993
2022-03-14 12:02:25 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 1.4839
2022-03-14 12:02:57 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 1.4547
2022-03-14 12:03:30 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 1.4283
2022-03-14 12:04:01 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 1.5920
2022-03-14 12:04:34 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 1.5261
2022-03-14 12:05:06 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 1.6124
2022-03-14 12:05:39 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 1.5138
2022-03-14 12:06:11 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 1.4454
2022-03-14 12:06:44 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 1.5121
2022-03-14 12:07:15 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 1.3554
2022-03-14 12:07:48 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 1.4234
2022-03-14 12:08:19 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 1.4637
2022-03-14 12:08:52 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 1.4274
2022-03-14 12:09:24 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 1.6227
2022-03-14 12:09:56 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 1.6875
2022-03-14 12:10:28 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 1.5012
2022-03-14 12:11:01 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 1.4325
2022-03-14 12:11:32 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 1.5720
2022-03-14 12:12:05 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 1.3103
2022-03-14 12:12:37 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 1.5837
2022-03-14 12:13:09 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 1.7794
2022-03-14 12:13:41 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 1.5542
2022-03-14 12:14:12 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 1.4921
2022-03-14 12:14:13 - train: epoch 078, train_loss: 1.4793
2022-03-14 12:15:24 - eval: epoch: 078, acc1: 68.186%, acc5: 88.390%, test_loss: 1.2801, per_image_load_time: 2.605ms, per_image_inference_time: 0.174ms
2022-03-14 12:15:25 - until epoch: 078, best_acc1: 68.350%
2022-03-14 12:15:25 - epoch 079 lr: 0.0010000000000000002
2022-03-14 12:16:02 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 1.4264
2022-03-14 12:16:34 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 1.4394
2022-03-14 12:17:05 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 1.6186
2022-03-14 12:17:38 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 1.6044
2022-03-14 12:18:10 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 1.4595
2022-03-14 12:18:43 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 1.3973
2022-03-14 12:19:14 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 1.3484
2022-03-14 12:19:47 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 1.5592
2022-03-14 12:20:19 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 1.4099
2022-03-14 12:20:51 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 1.3830
2022-03-14 12:21:24 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 1.6089
2022-03-14 12:21:56 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 1.6634
2022-03-14 12:22:29 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 1.3011
2022-03-14 12:23:00 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 1.3411
2022-03-14 12:23:33 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 1.4535
2022-03-14 12:24:05 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 1.2433
2022-03-14 12:24:38 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 1.3943
2022-03-14 12:25:10 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 1.4025
2022-03-14 12:25:43 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 1.4646
2022-03-14 12:26:15 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 1.6316
2022-03-14 12:26:47 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 1.3457
2022-03-14 12:27:20 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 1.5283
2022-03-14 12:27:52 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 1.4825
2022-03-14 12:28:25 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 1.5244
2022-03-14 12:28:57 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 1.4467
2022-03-14 12:29:29 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 1.3961
2022-03-14 12:30:01 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 1.2456
2022-03-14 12:30:33 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 1.3699
2022-03-14 12:31:05 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 1.3344
2022-03-14 12:31:37 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 1.4228
2022-03-14 12:32:09 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 1.4612
2022-03-14 12:32:42 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 1.7870
2022-03-14 12:33:14 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 1.4824
2022-03-14 12:33:46 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 1.2949
2022-03-14 12:34:17 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 1.5550
2022-03-14 12:34:50 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 1.3760
2022-03-14 12:35:22 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 1.2919
2022-03-14 12:35:54 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 1.5306
2022-03-14 12:36:27 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 1.3773
2022-03-14 12:36:59 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 1.3053
2022-03-14 12:37:31 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 1.6636
2022-03-14 12:38:02 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 1.3422
2022-03-14 12:38:35 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 1.2526
2022-03-14 12:39:07 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 1.6690
2022-03-14 12:39:39 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 1.7617
2022-03-14 12:40:11 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 1.6589
2022-03-14 12:40:43 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 1.5123
2022-03-14 12:41:15 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 1.5960
2022-03-14 12:41:48 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 1.6028
2022-03-14 12:42:18 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 1.3541
2022-03-14 12:42:19 - train: epoch 079, train_loss: 1.4775
2022-03-14 12:43:31 - eval: epoch: 079, acc1: 68.272%, acc5: 88.310%, test_loss: 1.2787, per_image_load_time: 2.591ms, per_image_inference_time: 0.169ms
2022-03-14 12:43:31 - until epoch: 079, best_acc1: 68.350%
2022-03-14 12:43:31 - epoch 080 lr: 0.0010000000000000002
2022-03-14 12:44:08 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 1.2967
2022-03-14 12:44:41 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 1.4338
2022-03-14 12:45:13 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 1.5859
2022-03-14 12:45:46 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 1.3950
2022-03-14 12:46:18 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 1.5324
2022-03-14 12:46:50 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 1.3532
2022-03-14 12:47:22 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 1.4482
2022-03-14 12:47:54 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 1.3729
2022-03-14 12:48:26 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 1.4748
2022-03-14 12:48:59 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 1.3264
2022-03-14 12:49:31 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 1.4907
2022-03-14 12:50:04 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 1.5020
2022-03-14 12:50:35 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 1.3992
2022-03-14 12:51:07 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 1.4101
2022-03-14 12:51:39 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 1.3366
2022-03-14 12:52:11 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 1.3627
2022-03-14 12:52:43 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 1.4190
2022-03-14 12:53:15 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 1.5670
2022-03-14 12:53:47 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 1.4697
2022-03-14 12:54:20 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 1.5769
2022-03-14 12:54:52 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 1.5974
2022-03-14 12:55:24 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 1.6096
2022-03-14 12:55:56 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 1.3282
2022-03-14 12:56:28 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 1.4885
2022-03-14 12:57:00 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 1.4658
2022-03-14 12:57:32 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 1.4751
2022-03-14 12:58:04 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 1.5691
2022-03-14 12:58:37 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 1.4920
2022-03-14 12:59:08 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 1.4125
2022-03-14 12:59:41 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 1.4893
2022-03-14 13:00:13 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 1.7149
2022-03-14 13:00:45 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 1.1572
2022-03-14 13:01:17 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 1.4452
2022-03-14 13:01:50 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 1.4295
2022-03-14 13:02:21 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 1.2518
2022-03-14 13:02:54 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 1.4988
2022-03-14 13:03:25 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 1.4327
2022-03-14 13:03:58 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 1.5692
2022-03-14 13:04:30 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 1.3262
2022-03-14 13:05:01 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 1.6841
2022-03-14 13:05:34 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 1.5054
2022-03-14 13:06:06 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 1.4625
2022-03-14 13:06:38 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 1.5730
2022-03-14 13:07:10 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 1.4628
2022-03-14 13:07:43 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 1.4003
2022-03-14 13:08:15 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 1.5813
2022-03-14 13:08:47 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 1.6266
2022-03-14 13:09:19 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 1.4646
2022-03-14 13:09:51 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 1.6652
2022-03-14 13:10:21 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 1.3510
2022-03-14 13:10:22 - train: epoch 080, train_loss: 1.4760
2022-03-14 13:11:33 - eval: epoch: 080, acc1: 68.340%, acc5: 88.456%, test_loss: 1.2759, per_image_load_time: 2.379ms, per_image_inference_time: 0.173ms
2022-03-14 13:11:33 - until epoch: 080, best_acc1: 68.350%
2022-03-14 13:11:33 - epoch 081 lr: 0.0010000000000000002
2022-03-14 13:12:10 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 1.3795
2022-03-14 13:12:42 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 1.4503
2022-03-14 13:13:16 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 1.4282
2022-03-14 13:13:48 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 1.5624
2022-03-14 13:14:20 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 1.6032
2022-03-14 13:14:52 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 1.5627
2022-03-14 13:15:24 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 1.4018
2022-03-14 13:15:56 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 1.6394
2022-03-14 13:16:28 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 1.3937
2022-03-14 13:17:00 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 1.4589
2022-03-14 13:17:32 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 1.3968
2022-03-14 13:18:04 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 1.5481
2022-03-14 13:18:36 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 1.3647
2022-03-14 13:19:08 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 1.1258
2022-03-14 13:19:40 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 1.6161
2022-03-14 13:20:12 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 1.3982
2022-03-14 13:20:44 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 1.5865
2022-03-14 13:21:17 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 1.3545
2022-03-14 13:21:49 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 1.4334
2022-03-14 13:22:22 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 1.5930
2022-03-14 13:22:54 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 1.4791
2022-03-14 13:23:26 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 1.5350
2022-03-14 13:23:58 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 1.3974
2022-03-14 13:24:30 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 1.4163
2022-03-14 13:25:03 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 1.6080
2022-03-14 13:25:35 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 1.6041
2022-03-14 13:26:08 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 1.4830
2022-03-14 13:26:40 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 1.3428
2022-03-14 13:27:11 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 1.3264
2022-03-14 13:27:44 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 1.4364
2022-03-14 13:28:16 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 1.3133
2022-03-14 13:28:48 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 1.4323
2022-03-14 13:29:20 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 1.4472
2022-03-14 13:29:52 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 1.5844
2022-03-14 13:30:24 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 1.5302
2022-03-14 13:30:56 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 1.2704
2022-03-14 13:31:29 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 1.5449
2022-03-14 13:32:02 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 1.2782
2022-03-14 13:32:33 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 1.5688
2022-03-14 13:33:06 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 1.3182
2022-03-14 13:33:37 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 1.4921
2022-03-14 13:34:10 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 1.4714
2022-03-14 13:34:42 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 1.4828
2022-03-14 13:35:14 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 1.5718
2022-03-14 13:35:47 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 1.5776
2022-03-14 13:36:18 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 1.4822
2022-03-14 13:36:51 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 1.5580
2022-03-14 13:37:23 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 1.5580
2022-03-14 13:37:55 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 1.4205
2022-03-14 13:38:25 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 1.2554
2022-03-14 13:38:26 - train: epoch 081, train_loss: 1.4751
2022-03-14 13:39:38 - eval: epoch: 081, acc1: 68.324%, acc5: 88.360%, test_loss: 1.2761, per_image_load_time: 2.115ms, per_image_inference_time: 0.181ms
2022-03-14 13:39:38 - until epoch: 081, best_acc1: 68.350%
2022-03-14 13:39:38 - epoch 082 lr: 0.0010000000000000002
2022-03-14 13:40:16 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 1.2298
2022-03-14 13:40:47 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 1.3970
2022-03-14 13:41:20 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 1.5419
2022-03-14 13:41:52 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 1.6260
2022-03-14 13:42:24 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 1.5642
2022-03-14 13:42:56 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 1.2992
2022-03-14 13:43:29 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 1.6334
2022-03-14 13:44:00 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 1.4309
2022-03-14 13:44:32 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 1.6701
2022-03-14 13:45:04 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 1.5405
2022-03-14 13:45:37 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 1.5358
2022-03-14 13:46:08 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 1.5145
2022-03-14 13:46:41 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 1.6491
2022-03-14 13:47:14 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 1.3154
2022-03-14 13:47:45 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 1.4710
2022-03-14 13:48:17 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 1.3501
2022-03-14 13:48:50 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 1.4813
2022-03-14 13:49:21 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 1.3710
2022-03-14 13:49:54 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 1.3696
2022-03-14 13:50:26 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 1.3945
2022-03-14 13:50:58 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 1.4470
2022-03-14 13:51:31 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 1.4720
2022-03-14 13:52:03 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 1.4808
2022-03-14 13:52:36 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 1.6353
2022-03-14 13:53:08 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 1.4546
2022-03-14 13:53:40 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 1.3725
2022-03-14 13:54:14 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 1.4159
2022-03-14 13:54:45 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 1.3279
2022-03-14 13:55:18 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 1.2758
2022-03-14 13:55:49 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 1.4437
2022-03-14 13:56:22 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 1.4617
2022-03-14 13:56:54 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 1.6293
2022-03-14 13:57:26 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 1.4130
2022-03-14 13:57:58 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 1.4409
2022-03-14 13:58:30 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 1.3703
2022-03-14 13:59:02 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 1.4632
2022-03-14 13:59:34 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 1.4114
2022-03-14 14:00:06 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 1.6762
2022-03-14 14:00:38 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 1.5793
2022-03-14 14:01:09 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 1.5074
2022-03-14 14:01:41 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 1.4590
2022-03-14 14:02:13 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 1.6541
2022-03-14 14:02:47 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 1.2729
2022-03-14 14:03:18 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 1.3709
2022-03-14 14:03:50 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 1.5064
2022-03-14 14:04:22 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 1.6125
2022-03-14 14:04:55 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 1.4079
2022-03-14 14:05:25 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 1.3645
2022-03-14 14:05:58 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 1.4417
2022-03-14 14:06:28 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 1.4256
2022-03-14 14:06:29 - train: epoch 082, train_loss: 1.4716
2022-03-14 14:07:40 - eval: epoch: 082, acc1: 68.226%, acc5: 88.354%, test_loss: 1.2768, per_image_load_time: 2.563ms, per_image_inference_time: 0.188ms
2022-03-14 14:07:40 - until epoch: 082, best_acc1: 68.350%
2022-03-14 14:07:40 - epoch 083 lr: 0.0010000000000000002
2022-03-14 14:08:17 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 1.3859
2022-03-14 14:08:49 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 1.3952
2022-03-14 14:09:21 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 1.5678
2022-03-14 14:09:52 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 1.6142
2022-03-14 14:10:24 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 1.5082
2022-03-14 14:10:57 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 1.3048
2022-03-14 14:11:28 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 1.3721
2022-03-14 14:12:01 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 1.3369
2022-03-14 14:12:32 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 1.5623
2022-03-14 14:13:05 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 1.6228
2022-03-14 14:13:36 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 1.4663
2022-03-14 14:14:09 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 1.4630
2022-03-14 14:14:40 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 1.2881
2022-03-14 14:15:12 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 1.5052
2022-03-14 14:15:44 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 1.3711
2022-03-14 14:16:16 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 1.4875
2022-03-14 14:16:48 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 1.5676
2022-03-14 14:17:21 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 1.7448
2022-03-14 14:17:52 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 1.3930
2022-03-14 14:18:24 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 1.1734
2022-03-14 14:18:56 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 1.3866
2022-03-14 14:19:27 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 1.4423
2022-03-14 14:20:00 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 1.5306
2022-03-14 14:20:33 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 1.3218
2022-03-14 14:21:04 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 1.4863
2022-03-14 14:21:37 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 1.4159
2022-03-14 14:22:08 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 1.4749
2022-03-14 14:22:41 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 1.4387
2022-03-14 14:23:12 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 1.4642
2022-03-14 14:23:44 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 1.5764
2022-03-14 14:24:15 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 1.3733
2022-03-14 14:24:49 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 1.3473
2022-03-14 14:25:20 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 1.7054
2022-03-14 14:25:52 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 1.5251
2022-03-14 14:26:24 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 1.5565
2022-03-14 14:26:56 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 1.4725
2022-03-14 14:27:28 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 1.4728
2022-03-14 14:28:00 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 1.3540
2022-03-14 14:28:34 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 1.6279
2022-03-14 14:29:04 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 1.7076
2022-03-14 14:29:37 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 1.4468
2022-03-14 14:30:09 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 1.7518
2022-03-14 14:30:41 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 1.5050
2022-03-14 14:31:13 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 1.3748
2022-03-14 14:31:46 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 1.4645
2022-03-14 14:32:17 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 1.6173
2022-03-14 14:32:50 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 1.6518
2022-03-14 14:33:22 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 1.5833
2022-03-14 14:33:55 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 1.6460
2022-03-14 14:34:25 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 1.5223
2022-03-14 14:34:26 - train: epoch 083, train_loss: 1.4707
2022-03-14 14:35:38 - eval: epoch: 083, acc1: 68.264%, acc5: 88.502%, test_loss: 1.2783, per_image_load_time: 2.516ms, per_image_inference_time: 0.192ms
2022-03-14 14:35:38 - until epoch: 083, best_acc1: 68.350%
2022-03-14 14:35:38 - epoch 084 lr: 0.0010000000000000002
2022-03-14 14:36:15 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 1.5326
2022-03-14 14:36:48 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 1.5833
2022-03-14 14:37:20 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 1.2454
2022-03-14 14:37:53 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 1.5337
2022-03-14 14:38:24 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 1.5830
2022-03-14 14:38:56 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 1.7028
2022-03-14 14:39:28 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 1.4829
2022-03-14 14:40:00 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 1.6477
2022-03-14 14:40:33 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 1.4146
2022-03-14 14:41:04 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 1.6956
2022-03-14 14:41:36 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 1.3656
2022-03-14 14:42:08 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 1.7682
2022-03-14 14:42:40 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 1.5129
2022-03-14 14:43:12 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 1.5445
2022-03-14 14:43:44 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 1.5550
2022-03-14 14:44:16 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 1.4325
2022-03-14 14:44:48 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 1.6134
2022-03-14 14:45:20 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 1.4760
2022-03-14 14:45:52 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 1.4522
2022-03-14 14:46:24 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 1.5583
2022-03-14 14:46:56 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 1.4045
2022-03-14 14:47:28 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 1.1812
2022-03-14 14:48:01 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 1.5219
2022-03-14 14:48:33 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 1.3088
2022-03-14 14:49:05 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 1.5719
2022-03-14 14:49:37 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 1.6056
2022-03-14 14:50:09 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 1.4554
2022-03-14 14:50:41 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 1.5857
2022-03-14 14:51:13 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 1.3967
2022-03-14 14:51:47 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 1.4727
2022-03-14 14:52:20 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 1.4103
2022-03-14 14:52:54 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 1.3014
2022-03-14 14:53:25 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 1.4929
2022-03-14 14:53:58 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 1.3367
2022-03-14 14:54:30 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 1.2658
2022-03-14 14:55:02 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 1.4549
2022-03-14 14:55:34 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 1.6009
2022-03-14 14:56:07 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 1.8008
2022-03-14 14:56:39 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 1.6219
2022-03-14 14:57:11 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 1.5395
2022-03-14 14:57:44 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 1.5287
2022-03-14 14:58:16 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 1.5634
2022-03-14 14:58:47 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 1.5071
2022-03-14 14:59:20 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 1.7494
2022-03-14 14:59:51 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 1.3789
2022-03-14 15:00:23 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 1.3936
2022-03-14 15:00:55 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 1.7705
2022-03-14 15:01:28 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 1.3036
2022-03-14 15:02:00 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 1.2541
2022-03-14 15:02:30 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 1.4842
2022-03-14 15:02:31 - train: epoch 084, train_loss: 1.4686
2022-03-14 15:03:43 - eval: epoch: 084, acc1: 68.244%, acc5: 88.458%, test_loss: 1.2748, per_image_load_time: 2.599ms, per_image_inference_time: 0.160ms
2022-03-14 15:03:43 - until epoch: 084, best_acc1: 68.350%
2022-03-14 15:03:43 - epoch 085 lr: 0.0010000000000000002
2022-03-14 15:04:20 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 1.4342
2022-03-14 15:04:52 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 1.3360
2022-03-14 15:05:25 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 1.5867
2022-03-14 15:05:57 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 1.4038
2022-03-14 15:06:29 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 1.6954
2022-03-14 15:07:02 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 1.2367
2022-03-14 15:07:34 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 1.3405
2022-03-14 15:08:06 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 1.4024
2022-03-14 15:08:38 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 1.3011
2022-03-14 15:09:11 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 1.5271
2022-03-14 15:09:42 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 1.4988
2022-03-14 15:10:15 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 1.3210
2022-03-14 15:10:48 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 1.4590
2022-03-14 15:11:20 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 1.4757
2022-03-14 15:11:52 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 1.3306
2022-03-14 15:12:25 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 1.5635
2022-03-14 15:12:56 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 1.6429
2022-03-14 15:13:28 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 1.2882
2022-03-14 15:14:01 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 1.3413
2022-03-14 15:14:33 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 1.3722
2022-03-14 15:15:05 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 1.1270
2022-03-14 15:15:38 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 1.6377
2022-03-14 15:16:09 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 1.2829
2022-03-14 15:16:42 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 1.6264
2022-03-14 15:17:15 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 1.6640
2022-03-14 15:17:47 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 1.5057
2022-03-14 15:18:20 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 1.4296
2022-03-14 15:18:51 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 1.5896
2022-03-14 15:19:24 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 1.5442
2022-03-14 15:19:56 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 1.6485
2022-03-14 15:20:29 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 1.4686
2022-03-14 15:21:01 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 1.4179
2022-03-14 15:21:33 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 1.4584
2022-03-14 15:22:06 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 1.5533
2022-03-14 15:22:38 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 1.4796
2022-03-14 15:23:11 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 1.5711
2022-03-14 15:23:42 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 1.2536
2022-03-14 15:24:15 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 1.4793
2022-03-14 15:24:47 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 1.4390
2022-03-14 15:25:19 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 1.6462
2022-03-14 15:25:51 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 1.5237
2022-03-14 15:26:23 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 1.5606
2022-03-14 15:26:56 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 1.3167
2022-03-14 15:27:28 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 1.4126
2022-03-14 15:28:00 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 1.6239
2022-03-14 15:28:32 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 1.5456
2022-03-14 15:29:05 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 1.6882
2022-03-14 15:29:38 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 1.2764
2022-03-14 15:30:09 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 1.3982
2022-03-14 15:30:40 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 1.4007
2022-03-14 15:30:40 - train: epoch 085, train_loss: 1.4697
2022-03-14 15:31:53 - eval: epoch: 085, acc1: 68.338%, acc5: 88.496%, test_loss: 1.2787, per_image_load_time: 2.635ms, per_image_inference_time: 0.180ms
2022-03-14 15:31:53 - until epoch: 085, best_acc1: 68.350%
2022-03-14 15:31:53 - epoch 086 lr: 0.0010000000000000002
2022-03-14 15:32:30 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 1.2892
2022-03-14 15:33:03 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 1.3860
2022-03-14 15:33:35 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 1.6090
2022-03-14 15:34:07 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 1.4722
2022-03-14 15:34:40 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 1.4061
2022-03-14 15:35:12 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 1.4564
2022-03-14 15:35:44 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 1.3277
2022-03-14 15:36:16 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 1.7132
2022-03-14 15:36:48 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 1.6026
2022-03-14 15:37:20 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 1.5951
2022-03-14 15:37:52 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 1.5134
2022-03-14 15:38:24 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 1.3229
2022-03-14 15:38:56 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 1.3883
2022-03-14 15:39:28 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 1.4097
2022-03-14 15:40:00 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 1.3493
2022-03-14 15:40:32 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 1.4548
2022-03-14 15:41:04 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 1.3555
2022-03-14 15:41:37 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 1.4651
2022-03-14 15:42:09 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 1.6773
2022-03-14 15:42:42 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 1.5179
2022-03-14 15:43:13 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 1.3970
2022-03-14 15:43:46 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 1.5280
2022-03-14 15:44:18 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 1.4564
2022-03-14 15:44:51 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 1.2452
2022-03-14 15:45:22 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 1.4036
2022-03-14 15:45:56 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 1.4544
2022-03-14 15:46:27 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 1.4293
2022-03-14 15:46:59 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 1.5405
2022-03-14 15:47:30 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 1.2645
2022-03-14 15:48:03 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 1.5077
2022-03-14 15:48:35 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 1.3790
2022-03-14 15:49:07 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 1.5622
2022-03-14 15:49:40 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 1.5365
2022-03-14 15:50:12 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 1.5854
2022-03-14 15:50:44 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 1.5089
2022-03-14 15:51:17 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 1.4932
2022-03-14 15:51:50 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 1.5152
2022-03-14 15:52:21 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 1.4545
2022-03-14 15:52:54 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 1.5266
2022-03-14 15:53:26 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 1.5140
2022-03-14 15:53:58 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 1.5045
2022-03-14 15:54:30 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 1.6035
2022-03-14 15:55:03 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 1.5465
2022-03-14 15:55:35 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 1.3538
2022-03-14 15:56:07 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 1.2963
2022-03-14 15:56:40 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 1.3658
2022-03-14 15:57:12 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 1.5063
2022-03-14 15:57:44 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 1.5608
2022-03-14 15:58:16 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 1.4506
2022-03-14 15:58:46 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 1.3609
2022-03-14 15:58:47 - train: epoch 086, train_loss: 1.4671
2022-03-14 15:59:59 - eval: epoch: 086, acc1: 68.360%, acc5: 88.364%, test_loss: 1.2775, per_image_load_time: 1.925ms, per_image_inference_time: 0.199ms
2022-03-14 16:00:00 - until epoch: 086, best_acc1: 68.360%
2022-03-14 16:00:00 - epoch 087 lr: 0.0010000000000000002
2022-03-14 16:00:37 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 1.5457
2022-03-14 16:01:10 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 1.2927
2022-03-14 16:01:42 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 1.5349
2022-03-14 16:02:13 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 1.6335
2022-03-14 16:02:45 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 1.1902
2022-03-14 16:03:18 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 1.5036
2022-03-14 16:03:50 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 1.2491
2022-03-14 16:04:22 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 1.4794
2022-03-14 16:04:54 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 1.5873
2022-03-14 16:05:27 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 1.3704
2022-03-14 16:05:58 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 1.4624
2022-03-14 16:06:31 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 1.5198
2022-03-14 16:07:03 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 1.6581
2022-03-14 16:07:36 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 1.4638
2022-03-14 16:08:08 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 1.3928
2022-03-14 16:08:40 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 1.2388
2022-03-14 16:09:13 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 1.7188
2022-03-14 16:09:45 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 1.4448
2022-03-14 16:10:17 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 1.5320
2022-03-14 16:10:49 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 1.4373
2022-03-14 16:11:22 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 1.5811
2022-03-14 16:11:54 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 1.5112
2022-03-14 16:12:25 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 1.5943
2022-03-14 16:12:57 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 1.4133
2022-03-14 16:13:29 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 1.4900
2022-03-14 16:14:02 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 1.4878
2022-03-14 16:14:34 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 1.3600
2022-03-14 16:15:06 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 1.2804
2022-03-14 16:15:38 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 1.3891
2022-03-14 16:16:11 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 1.5568
2022-03-14 16:16:42 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 1.4737
2022-03-14 16:17:16 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 1.4208
2022-03-14 16:17:48 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 1.4053
2022-03-14 16:18:20 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 1.5135
2022-03-14 16:18:52 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 1.3620
2022-03-14 16:19:24 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 1.3128
2022-03-14 16:19:56 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 1.4430
2022-03-14 16:20:29 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 1.5325
2022-03-14 16:21:01 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 1.4406
2022-03-14 16:21:34 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 1.5739
2022-03-14 16:22:05 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 1.5481
2022-03-14 16:22:38 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 1.4915
2022-03-14 16:23:10 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 1.4473
2022-03-14 16:23:42 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 1.5638
2022-03-14 16:24:13 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 1.6047
2022-03-14 16:24:46 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 1.5319
2022-03-14 16:25:18 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 1.4895
2022-03-14 16:25:50 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 1.4118
2022-03-14 16:26:22 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 1.4876
2022-03-14 16:26:53 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 1.5062
2022-03-14 16:26:53 - train: epoch 087, train_loss: 1.4644
2022-03-14 16:28:06 - eval: epoch: 087, acc1: 68.366%, acc5: 88.408%, test_loss: 1.2754, per_image_load_time: 1.916ms, per_image_inference_time: 0.164ms
2022-03-14 16:28:06 - until epoch: 087, best_acc1: 68.366%
2022-03-14 16:28:06 - epoch 088 lr: 0.0010000000000000002
2022-03-14 16:28:43 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 1.4500
2022-03-14 16:29:16 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 1.4428
2022-03-14 16:29:47 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 1.5277
2022-03-14 16:30:20 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 1.4981
2022-03-14 16:30:52 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 1.4371
2022-03-14 16:31:24 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 1.4464
2022-03-14 16:31:57 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 1.4494
2022-03-14 16:32:29 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 1.4120
2022-03-14 16:33:01 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 1.5174
2022-03-14 16:33:33 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 1.3980
2022-03-14 16:34:06 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 1.5146
2022-03-14 16:34:38 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 1.5089
2022-03-14 16:35:11 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 1.6258
2022-03-14 16:35:42 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 1.3043
2022-03-14 16:36:15 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 1.5347
2022-03-14 16:36:47 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 1.4195
2022-03-14 16:37:19 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 1.6543
2022-03-14 16:37:52 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 1.4056
2022-03-14 16:38:25 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 1.4596
2022-03-14 16:38:57 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 1.2459
2022-03-14 16:39:29 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 1.4838
2022-03-14 16:40:01 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 1.4078
2022-03-14 16:40:34 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 1.2534
2022-03-14 16:41:05 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 1.5336
2022-03-14 16:41:39 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 1.6826
2022-03-14 16:42:10 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 1.6226
2022-03-14 16:42:43 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 1.5231
2022-03-14 16:43:15 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 1.4470
2022-03-14 16:43:47 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 1.3716
2022-03-14 16:44:20 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 1.7352
2022-03-14 16:44:53 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 1.2537
2022-03-14 16:45:25 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 1.3696
2022-03-14 16:45:57 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 1.2833
2022-03-14 16:46:30 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 1.1808
2022-03-14 16:47:02 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 1.3330
2022-03-14 16:47:34 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 1.3988
2022-03-14 16:48:07 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 1.5215
2022-03-14 16:48:39 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 1.5086
2022-03-14 16:49:12 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 1.5512
2022-03-14 16:49:43 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 1.3195
2022-03-14 16:50:16 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 1.4895
2022-03-14 16:50:48 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 1.4907
2022-03-14 16:51:21 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 1.4090
2022-03-14 16:51:53 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 1.3591
2022-03-14 16:52:26 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 1.5212
2022-03-14 16:52:57 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 1.5638
2022-03-14 16:53:29 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 1.4721
2022-03-14 16:54:01 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 1.3128
2022-03-14 16:54:34 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 1.2451
2022-03-14 16:55:04 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 1.4830
2022-03-14 16:55:05 - train: epoch 088, train_loss: 1.4636
2022-03-14 16:56:16 - eval: epoch: 088, acc1: 68.388%, acc5: 88.618%, test_loss: 1.2687, per_image_load_time: 1.243ms, per_image_inference_time: 0.177ms
2022-03-14 16:56:17 - until epoch: 088, best_acc1: 68.388%
2022-03-14 16:56:17 - epoch 089 lr: 0.0010000000000000002
2022-03-14 16:56:53 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 1.7124
2022-03-14 16:57:26 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 1.2667
2022-03-14 16:57:58 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 1.4123
2022-03-14 16:58:31 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 1.3432
2022-03-14 16:59:03 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 1.4294
2022-03-14 16:59:35 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 1.3096
2022-03-14 17:00:07 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 1.4717
2022-03-14 17:00:38 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 1.7311
2022-03-14 17:01:10 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 1.5336
2022-03-14 17:01:43 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 1.6260
2022-03-14 17:02:15 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 1.4537
2022-03-14 17:02:47 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 1.5764
2022-03-14 17:03:19 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 1.4589
2022-03-14 17:03:51 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 1.5373
2022-03-14 17:04:24 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 1.4495
2022-03-14 17:04:56 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 1.4049
2022-03-14 17:05:28 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 1.4723
2022-03-14 17:05:59 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 1.5261
2022-03-14 17:06:32 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 1.3631
2022-03-14 17:07:04 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 1.4384
2022-03-14 17:07:36 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 1.5497
2022-03-14 17:08:09 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 1.5216
2022-03-14 17:08:41 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 1.3308
2022-03-14 17:09:13 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 1.5952
2022-03-14 17:09:46 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 1.3997
2022-03-14 17:10:17 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 1.4794
2022-03-14 17:10:50 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 1.3845
2022-03-14 17:11:21 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 1.4729
2022-03-14 17:11:55 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 1.4778
2022-03-14 17:12:26 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 1.5291
2022-03-14 17:12:59 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 1.5363
2022-03-14 17:13:30 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 1.6356
2022-03-14 17:14:03 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 1.6752
2022-03-14 17:14:34 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 1.4285
2022-03-14 17:15:07 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 1.2178
2022-03-14 17:15:39 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 1.4543
2022-03-14 17:16:11 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 1.6053
2022-03-14 17:16:43 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 1.4399
2022-03-14 17:17:15 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 1.5065
2022-03-14 17:17:49 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 1.3450
2022-03-14 17:18:21 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 1.8412
2022-03-14 17:18:52 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 1.3985
2022-03-14 17:19:25 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 1.4724
2022-03-14 17:19:57 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 1.4383
2022-03-14 17:20:28 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 1.2105
2022-03-14 17:21:01 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 1.4231
2022-03-14 17:21:33 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 1.4062
2022-03-14 17:22:06 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 1.4641
2022-03-14 17:22:38 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 1.4455
2022-03-14 17:23:09 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 1.1752
2022-03-14 17:23:10 - train: epoch 089, train_loss: 1.4637
2022-03-14 17:24:22 - eval: epoch: 089, acc1: 68.360%, acc5: 88.506%, test_loss: 1.2716, per_image_load_time: 2.553ms, per_image_inference_time: 0.170ms
2022-03-14 17:24:22 - until epoch: 089, best_acc1: 68.388%
2022-03-14 17:24:22 - epoch 090 lr: 0.0010000000000000002
2022-03-14 17:25:00 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 1.4497
2022-03-14 17:25:32 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 1.4953
2022-03-14 17:26:04 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 1.4108
2022-03-14 17:26:37 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 1.3795
2022-03-14 17:27:09 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 1.4837
2022-03-14 17:27:41 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 1.6397
2022-03-14 17:28:14 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 1.5045
2022-03-14 17:28:45 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 1.3928
2022-03-14 17:29:18 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 1.4697
2022-03-14 17:29:49 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 1.2558
2022-03-14 17:30:22 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 1.4668
2022-03-14 17:30:53 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 1.5159
2022-03-14 17:31:25 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 1.6045
2022-03-14 17:31:57 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 1.3083
2022-03-14 17:32:29 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 1.6832
2022-03-14 17:33:02 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 1.4171
2022-03-14 17:33:33 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 1.2508
2022-03-14 17:34:05 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 1.3582
2022-03-14 17:34:37 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 1.4131
2022-03-14 17:35:10 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 1.5164
2022-03-14 17:35:42 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 1.5522
2022-03-14 17:36:15 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 1.5988
2022-03-14 17:36:47 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 1.5653
2022-03-14 17:37:20 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 1.4670
2022-03-14 17:37:52 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 1.5189
2022-03-14 17:38:24 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 1.4604
2022-03-14 17:38:56 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 1.2721
2022-03-14 17:39:28 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 1.4430
2022-03-14 17:40:00 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 1.4133
2022-03-14 17:40:32 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 1.4065
2022-03-14 17:41:05 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 1.3093
2022-03-14 17:41:36 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 1.3772
2022-03-14 17:42:08 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 1.5597
2022-03-14 17:42:40 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 1.3478
2022-03-14 17:43:12 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 1.4661
2022-03-14 17:43:45 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 1.4108
2022-03-14 17:44:16 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 1.5788
2022-03-14 17:44:49 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 1.4813
2022-03-14 17:45:21 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 1.1374
2022-03-14 17:45:53 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 1.3721
2022-03-14 17:46:26 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 1.8012
2022-03-14 17:46:58 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 1.6805
2022-03-14 17:47:30 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 1.5242
2022-03-14 17:48:01 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 1.4759
2022-03-14 17:48:34 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 1.3376
2022-03-14 17:49:07 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 1.4230
2022-03-14 17:49:38 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 1.3690
2022-03-14 17:50:11 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 1.4985
2022-03-14 17:50:43 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 1.3564
2022-03-14 17:51:13 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 1.4093
2022-03-14 17:51:14 - train: epoch 090, train_loss: 1.4618
2022-03-14 17:52:26 - eval: epoch: 090, acc1: 68.326%, acc5: 88.554%, test_loss: 1.2666, per_image_load_time: 2.649ms, per_image_inference_time: 0.171ms
2022-03-14 17:52:27 - until epoch: 090, best_acc1: 68.388%
2022-03-14 17:52:27 - epoch 091 lr: 0.00010000000000000003
2022-03-14 17:53:03 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 1.3640
2022-03-14 17:53:37 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 1.3868
2022-03-14 17:54:08 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 1.4244
2022-03-14 17:54:40 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 1.4189
2022-03-14 17:55:13 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 1.3949
2022-03-14 17:55:45 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 1.5183
2022-03-14 17:56:17 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 1.4445
2022-03-14 17:56:49 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 1.1905
2022-03-14 17:57:21 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 1.4723
2022-03-14 17:57:53 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 1.3766
2022-03-14 17:58:26 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 1.2259
2022-03-14 17:58:59 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 1.4914
2022-03-14 17:59:31 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 1.3118
2022-03-14 18:00:04 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 1.5417
2022-03-14 18:00:36 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 1.4178
2022-03-14 18:01:08 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 1.4424
2022-03-14 18:01:41 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 1.5149
2022-03-14 18:02:13 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 1.4376
2022-03-14 18:02:45 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 1.3185
2022-03-14 18:03:17 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 1.4790
2022-03-14 18:03:50 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 1.2380
2022-03-14 18:04:22 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 1.5180
2022-03-14 18:04:54 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 1.5065
2022-03-14 18:05:26 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 1.3871
2022-03-14 18:05:59 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 1.3634
2022-03-14 18:06:30 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 1.4347
2022-03-14 18:07:02 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 1.2564
2022-03-14 18:07:35 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 1.4441
2022-03-14 18:08:08 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 1.4531
2022-03-14 18:08:41 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 1.4289
2022-03-14 18:09:12 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 1.3347
2022-03-14 18:09:45 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 1.5042
2022-03-14 18:10:16 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 1.3951
2022-03-14 18:10:50 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 1.3539
2022-03-14 18:11:22 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 1.4597
2022-03-14 18:11:55 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 1.3241
2022-03-14 18:12:27 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 1.4743
2022-03-14 18:12:59 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 1.4536
2022-03-14 18:13:32 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 1.2586
2022-03-14 18:14:05 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 1.3648
2022-03-14 18:14:37 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 1.4232
2022-03-14 18:15:09 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 1.5153
2022-03-14 18:15:41 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 1.4739
2022-03-14 18:16:14 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 1.3112
2022-03-14 18:16:46 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 1.3330
2022-03-14 18:17:18 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 1.4758
2022-03-14 18:17:50 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 1.5273
2022-03-14 18:18:22 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 1.4817
2022-03-14 18:18:54 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 1.4338
2022-03-14 18:19:25 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 1.6723
2022-03-14 18:19:26 - train: epoch 091, train_loss: 1.4317
2022-03-14 18:20:38 - eval: epoch: 091, acc1: 68.874%, acc5: 88.752%, test_loss: 1.2485, per_image_load_time: 1.899ms, per_image_inference_time: 0.184ms
2022-03-14 18:20:39 - until epoch: 091, best_acc1: 68.874%
2022-03-14 18:20:39 - epoch 092 lr: 0.00010000000000000003
2022-03-14 18:21:16 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 1.4182
2022-03-14 18:21:49 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 1.5196
2022-03-14 18:22:21 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 1.3221
2022-03-14 18:22:53 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 1.3026
2022-03-14 18:23:25 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 1.5600
2022-03-14 18:23:57 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 1.4775
2022-03-14 18:24:29 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 1.3847
2022-03-14 18:25:01 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 1.4891
2022-03-14 18:25:33 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 1.3057
2022-03-14 18:26:05 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 1.5540
2022-03-14 18:26:38 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 1.3074
2022-03-14 18:27:09 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 1.3516
2022-03-14 18:27:41 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 1.3300
2022-03-14 18:28:14 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 1.3794
2022-03-14 18:28:46 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 1.3471
2022-03-14 18:29:17 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 1.3202
2022-03-14 18:29:50 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 1.3993
2022-03-14 18:30:23 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 1.2906
2022-03-14 18:30:54 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 1.3493
2022-03-14 18:31:27 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 1.3252
2022-03-14 18:31:58 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 1.3286
2022-03-14 18:32:30 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 1.3483
2022-03-14 18:33:02 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 1.4017
2022-03-14 18:33:35 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 1.3167
2022-03-14 18:34:07 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 1.3519
2022-03-14 18:34:39 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 1.5733
2022-03-14 18:35:11 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 1.4187
2022-03-14 18:35:43 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 1.2611
2022-03-14 18:36:15 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 1.5810
2022-03-14 18:36:46 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 1.3133
2022-03-14 18:37:18 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 1.3869
2022-03-14 18:37:52 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 1.2128
2022-03-14 18:38:23 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 1.4597
2022-03-14 18:38:56 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 1.4887
2022-03-14 18:39:28 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 1.4126
2022-03-14 18:40:00 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 1.3220
2022-03-14 18:40:32 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 1.3481
2022-03-14 18:41:04 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 1.5808
2022-03-14 18:41:36 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 1.4958
2022-03-14 18:42:09 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 1.5996
2022-03-14 18:42:41 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 1.2735
2022-03-14 18:43:13 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 1.4117
2022-03-14 18:43:46 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 1.4458
2022-03-14 18:44:18 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 1.3158
2022-03-14 18:44:51 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 1.3926
2022-03-14 18:45:23 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 1.3189
2022-03-14 18:45:55 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 1.1148
2022-03-14 18:46:27 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 1.3603
2022-03-14 18:47:00 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 1.3905
2022-03-14 18:47:30 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 1.5229
2022-03-14 18:47:31 - train: epoch 092, train_loss: 1.4215
2022-03-14 18:48:43 - eval: epoch: 092, acc1: 68.862%, acc5: 88.780%, test_loss: 1.2470, per_image_load_time: 2.527ms, per_image_inference_time: 0.177ms
2022-03-14 18:48:43 - until epoch: 092, best_acc1: 68.874%
2022-03-14 18:48:43 - epoch 093 lr: 0.00010000000000000003
2022-03-14 18:49:20 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 1.2983
2022-03-14 18:49:53 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 1.2966
2022-03-14 18:50:26 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 1.3838
2022-03-14 18:50:58 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 1.3814
2022-03-14 18:51:31 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 1.6561
2022-03-14 18:52:03 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 1.3967
2022-03-14 18:52:35 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 1.4874
2022-03-14 18:53:08 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 1.4087
2022-03-14 18:53:40 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 1.3271
2022-03-14 18:54:13 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 1.2880
2022-03-14 18:54:45 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 1.3233
2022-03-14 18:55:18 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 1.4004
2022-03-14 18:55:50 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 1.3720
2022-03-14 18:56:23 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 1.2548
2022-03-14 18:56:56 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 1.5788
2022-03-14 18:57:28 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 1.3994
2022-03-14 18:58:01 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 1.3557
2022-03-14 18:58:33 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 1.4075
2022-03-14 18:59:06 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 1.3577
2022-03-14 18:59:38 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 1.2850
2022-03-14 19:00:11 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 1.3286
2022-03-14 19:00:43 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 1.5789
2022-03-14 19:01:16 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 1.4909
2022-03-14 19:01:49 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 1.3312
2022-03-14 19:02:22 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 1.3411
2022-03-14 19:02:55 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 1.6045
2022-03-14 19:03:26 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 1.4216
2022-03-14 19:03:59 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 1.4283
2022-03-14 19:04:31 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 1.4316
2022-03-14 19:05:03 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 1.2223
2022-03-14 19:05:35 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 1.5687
2022-03-14 19:06:08 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 1.3428
2022-03-14 19:06:40 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 1.4625
2022-03-14 19:07:12 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 1.6146
2022-03-14 19:07:45 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 1.1737
2022-03-14 19:08:17 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 1.6363
2022-03-14 19:08:50 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 1.3526
2022-03-14 19:09:22 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 1.3146
2022-03-14 19:09:54 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 1.4163
2022-03-14 19:10:27 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 1.6548
2022-03-14 19:10:59 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 1.5223
2022-03-14 19:11:32 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 1.5716
2022-03-14 19:12:04 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 1.6140
2022-03-14 19:12:37 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 1.3213
2022-03-14 19:13:08 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 1.4271
2022-03-14 19:13:41 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 1.2073
2022-03-14 19:14:13 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 1.7103
2022-03-14 19:14:44 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 1.3096
2022-03-14 19:15:17 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 1.5352
2022-03-14 19:15:46 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 1.4108
2022-03-14 19:15:47 - train: epoch 093, train_loss: 1.4205
2022-03-14 19:16:59 - eval: epoch: 093, acc1: 69.012%, acc5: 88.844%, test_loss: 1.2458, per_image_load_time: 1.511ms, per_image_inference_time: 0.175ms
2022-03-14 19:16:59 - until epoch: 093, best_acc1: 69.012%
2022-03-14 19:16:59 - epoch 094 lr: 0.00010000000000000003
2022-03-14 19:17:37 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 1.4033
2022-03-14 19:18:08 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 1.4346
2022-03-14 19:18:40 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 1.5897
2022-03-14 19:19:12 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 1.6531
2022-03-14 19:19:43 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 1.3014
2022-03-14 19:20:16 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 1.2162
2022-03-14 19:20:47 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 1.5603
2022-03-14 19:21:20 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 1.3619
2022-03-14 19:21:51 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 1.3954
2022-03-14 19:22:23 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 1.4827
2022-03-14 19:22:55 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 1.5302
2022-03-14 19:23:27 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 1.4135
2022-03-14 19:24:00 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 1.3478
2022-03-14 19:24:31 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 1.3611
2022-03-14 19:25:04 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 1.4523
2022-03-14 19:25:37 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 1.7743
2022-03-14 19:26:08 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 1.2518
2022-03-14 19:26:41 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 1.3410
2022-03-14 19:27:12 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 1.3346
2022-03-14 19:27:45 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 1.2289
2022-03-14 19:28:17 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 1.4387
2022-03-14 19:28:49 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 1.2523
2022-03-14 19:29:21 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 1.1989
2022-03-14 19:29:54 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 1.4443
2022-03-14 19:30:25 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 1.4268
2022-03-14 19:30:58 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 1.2607
2022-03-14 19:31:30 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 1.3413
2022-03-14 19:32:03 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 1.3863
2022-03-14 19:32:35 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 1.3864
2022-03-14 19:33:07 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 1.3715
2022-03-14 19:33:39 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 1.6216
2022-03-14 19:34:11 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 1.3898
2022-03-14 19:34:43 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 1.3683
2022-03-14 19:35:16 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 1.4509
2022-03-14 19:35:49 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 1.6112
2022-03-14 19:36:20 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 1.4859
2022-03-14 19:36:53 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 1.6265
2022-03-14 19:37:25 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 1.2952
2022-03-14 19:37:58 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 1.3318
2022-03-14 19:38:29 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 1.5454
2022-03-14 19:39:02 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 1.7471
2022-03-14 19:39:34 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 1.2399
2022-03-14 19:40:06 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 1.5787
2022-03-14 19:40:39 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 1.5676
2022-03-14 19:41:11 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 1.4963
2022-03-14 19:41:43 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 1.4783
2022-03-14 19:42:15 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 1.3781
2022-03-14 19:42:48 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 1.4275
2022-03-14 19:43:20 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 1.3677
2022-03-14 19:43:50 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 1.2784
2022-03-14 19:43:51 - train: epoch 094, train_loss: 1.4175
2022-03-14 19:45:04 - eval: epoch: 094, acc1: 68.990%, acc5: 88.808%, test_loss: 1.2457, per_image_load_time: 1.318ms, per_image_inference_time: 0.189ms
2022-03-14 19:45:04 - until epoch: 094, best_acc1: 69.012%
2022-03-14 19:45:04 - epoch 095 lr: 0.00010000000000000003
2022-03-14 19:45:42 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 1.3245
2022-03-14 19:46:14 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 1.5891
2022-03-14 19:46:46 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 1.3700
2022-03-14 19:47:18 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 1.5249
2022-03-14 19:47:50 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 1.5644
2022-03-14 19:48:21 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 1.4382
2022-03-14 19:48:54 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 1.5337
2022-03-14 19:49:26 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 1.5090
2022-03-14 19:49:57 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 1.6906
2022-03-14 19:50:30 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 1.5163
2022-03-14 19:51:02 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 1.2449
2022-03-14 19:51:33 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 1.2957
2022-03-14 19:52:06 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 1.3148
2022-03-14 19:52:39 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 1.4833
2022-03-14 19:53:11 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 1.5152
2022-03-14 19:53:43 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.9870
2022-03-14 19:54:16 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 1.2231
2022-03-14 19:54:47 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 1.4678
2022-03-14 19:55:20 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 1.3105
2022-03-14 19:55:52 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 1.4615
2022-03-14 19:56:25 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 1.4426
2022-03-14 19:56:56 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 1.1389
2022-03-14 19:57:29 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 1.3886
2022-03-14 19:58:00 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 1.4941
2022-03-14 19:58:33 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 1.2704
2022-03-14 19:59:05 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 1.4360
2022-03-14 19:59:37 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 1.4224
2022-03-14 20:00:09 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 1.3698
2022-03-14 20:00:42 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 1.3567
2022-03-14 20:01:14 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 1.6071
2022-03-14 20:01:46 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 1.5972
2022-03-14 20:02:17 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 1.3900
2022-03-14 20:02:50 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 1.4685
2022-03-14 20:03:22 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 1.2488
2022-03-14 20:03:55 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 1.3774
2022-03-14 20:04:26 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 1.3227
2022-03-14 20:05:00 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 1.3007
2022-03-14 20:05:31 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 1.1913
2022-03-14 20:06:04 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 1.5166
2022-03-14 20:06:35 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 1.2147
2022-03-14 20:07:07 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 1.3458
2022-03-14 20:07:39 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 1.2957
2022-03-14 20:08:12 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 1.4257
2022-03-14 20:08:44 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 1.5542
2022-03-14 20:09:17 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 1.3142
2022-03-14 20:09:48 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 1.4521
2022-03-14 20:10:21 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 1.3132
2022-03-14 20:10:53 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 1.4652
2022-03-14 20:11:25 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 1.3667
2022-03-14 20:11:55 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 1.2611
2022-03-14 20:11:56 - train: epoch 095, train_loss: 1.4182
2022-03-14 20:13:09 - eval: epoch: 095, acc1: 68.942%, acc5: 88.818%, test_loss: 1.2458, per_image_load_time: 1.100ms, per_image_inference_time: 0.182ms
2022-03-14 20:13:09 - until epoch: 095, best_acc1: 69.012%
2022-03-14 20:13:09 - epoch 096 lr: 0.00010000000000000003
2022-03-14 20:13:46 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 1.4005
2022-03-14 20:14:19 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 1.3343
2022-03-14 20:14:51 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 1.4341
2022-03-14 20:15:23 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 1.2663
2022-03-14 20:15:56 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 1.3899
2022-03-14 20:16:27 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 1.5955
2022-03-14 20:16:59 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 1.3148
2022-03-14 20:17:31 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 1.3734
2022-03-14 20:18:03 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 1.2996
2022-03-14 20:18:35 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 1.3993
2022-03-14 20:19:07 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 1.4137
2022-03-14 20:19:39 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 1.4994
2022-03-14 20:20:11 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 1.4786
2022-03-14 20:20:44 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 1.3114
2022-03-14 20:21:15 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 1.2670
2022-03-14 20:21:48 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 1.1516
2022-03-14 20:22:20 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 1.3550
2022-03-14 20:22:52 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 1.5343
2022-03-14 20:23:24 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 1.5803
2022-03-14 20:23:57 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 1.3675
2022-03-14 20:24:28 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 1.4050
2022-03-14 20:25:01 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 1.2491
2022-03-14 20:25:32 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 1.4068
2022-03-14 20:26:05 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 1.3066
2022-03-14 20:26:37 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 1.2991
2022-03-14 20:27:10 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 1.4035
2022-03-14 20:27:41 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 1.5431
2022-03-14 20:28:14 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 1.4922
2022-03-14 20:28:46 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 1.3595
2022-03-14 20:29:18 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 1.4179
2022-03-14 20:29:51 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 1.3671
2022-03-14 20:30:23 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 1.4399
2022-03-14 20:30:56 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 1.5019
2022-03-14 20:31:27 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 1.3292
2022-03-14 20:31:59 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 1.3257
2022-03-14 20:32:31 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 1.2150
2022-03-14 20:33:05 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 1.4407
2022-03-14 20:33:36 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 1.3560
2022-03-14 20:34:09 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 1.3638
2022-03-14 20:34:41 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 1.2648
2022-03-14 20:35:15 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 1.3563
2022-03-14 20:35:46 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 1.4314
2022-03-14 20:36:19 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 1.1060
2022-03-14 20:36:50 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 1.3971
2022-03-14 20:37:23 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 1.3245
2022-03-14 20:37:55 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 1.2586
2022-03-14 20:38:28 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 1.4283
2022-03-14 20:38:59 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 1.4552
2022-03-14 20:39:33 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 1.5836
2022-03-14 20:40:03 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 1.4339
2022-03-14 20:40:04 - train: epoch 096, train_loss: 1.4140
2022-03-14 20:41:17 - eval: epoch: 096, acc1: 68.902%, acc5: 88.920%, test_loss: 1.2427, per_image_load_time: 0.902ms, per_image_inference_time: 0.169ms
2022-03-14 20:41:17 - until epoch: 096, best_acc1: 69.012%
2022-03-14 20:41:17 - epoch 097 lr: 0.00010000000000000003
2022-03-14 20:41:54 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 1.4854
2022-03-14 20:42:28 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 1.2118
2022-03-14 20:43:00 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 1.5292
2022-03-14 20:43:33 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 1.6578
2022-03-14 20:44:05 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 1.4004
2022-03-14 20:44:38 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 1.4882
2022-03-14 20:45:10 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 1.3677
2022-03-14 20:45:43 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 1.3551
2022-03-14 20:46:17 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 1.3475
2022-03-14 20:46:49 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 1.4193
2022-03-14 20:47:21 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 1.2265
2022-03-14 20:47:54 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 1.3422
2022-03-14 20:48:26 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 1.3162
2022-03-14 20:48:59 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 1.4336
2022-03-14 20:49:31 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 1.3497
2022-03-14 20:50:05 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 1.3275
2022-03-14 20:50:37 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 1.2535
2022-03-14 20:51:10 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 1.5256
2022-03-14 20:51:42 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 1.4004
2022-03-14 20:52:15 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 1.3586
2022-03-14 20:52:47 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 1.3602
2022-03-14 20:53:19 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 1.5314
2022-03-14 20:53:51 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 1.3153
2022-03-14 20:54:24 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 1.4512
2022-03-14 20:54:56 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 1.4409
2022-03-14 20:55:29 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 1.5201
2022-03-14 20:56:01 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 1.2709
2022-03-14 20:56:33 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 1.2120
2022-03-14 20:57:06 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 1.5500
2022-03-14 20:57:38 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 1.3452
2022-03-14 20:58:11 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 1.3583
2022-03-14 20:58:43 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 1.4795
2022-03-14 20:59:16 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 1.5244
2022-03-14 20:59:48 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 1.5720
2022-03-14 21:00:21 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 1.4996
2022-03-14 21:00:53 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 1.4550
2022-03-14 21:01:25 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 1.1972
2022-03-14 21:01:58 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 1.1838
2022-03-14 21:02:29 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 1.3398
2022-03-14 21:03:02 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 1.4550
2022-03-14 21:03:35 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 1.3742
2022-03-14 21:04:07 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 1.3981
2022-03-14 21:04:40 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 1.2577
2022-03-14 21:05:12 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 1.2741
2022-03-14 21:05:45 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 1.4441
2022-03-14 21:06:17 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 1.5199
2022-03-14 21:06:50 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 1.4146
2022-03-14 21:07:23 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 1.3683
2022-03-14 21:07:56 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 1.7058
2022-03-14 21:08:27 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 1.4178
2022-03-14 21:08:28 - train: epoch 097, train_loss: 1.4156
2022-03-14 21:09:43 - eval: epoch: 097, acc1: 69.000%, acc5: 88.846%, test_loss: 1.2424, per_image_load_time: 0.859ms, per_image_inference_time: 0.169ms
2022-03-14 21:09:43 - until epoch: 097, best_acc1: 69.012%
2022-03-14 21:09:43 - epoch 098 lr: 0.00010000000000000003
2022-03-14 21:10:21 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 1.5391
2022-03-14 21:10:54 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 1.4866
2022-03-14 21:11:27 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 1.6278
2022-03-14 21:11:59 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 1.3163
2022-03-14 21:12:31 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 1.4324
2022-03-14 21:13:04 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 1.5241
2022-03-14 21:13:37 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 1.3992
2022-03-14 21:14:09 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 1.4626
2022-03-14 21:14:42 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 1.4734
2022-03-14 21:15:15 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 1.3368
2022-03-14 21:15:48 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 1.1125
2022-03-14 21:16:21 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 1.3587
2022-03-14 21:16:53 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 1.5746
2022-03-14 21:17:26 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 1.3581
2022-03-14 21:17:58 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 1.2933
2022-03-14 21:18:31 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 1.4196
2022-03-14 21:19:04 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 1.4826
2022-03-14 21:19:37 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 1.3710
2022-03-14 21:20:09 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 1.2790
2022-03-14 21:20:42 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 1.4438
2022-03-14 21:21:15 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 1.4175
2022-03-14 21:21:47 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 1.3917
2022-03-14 21:22:20 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 1.4008
2022-03-14 21:22:52 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 1.4478
2022-03-14 21:23:25 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 1.5467
2022-03-14 21:23:58 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 1.3722
2022-03-14 21:24:30 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 1.5040
2022-03-14 21:25:03 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 1.3759
2022-03-14 21:25:37 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 1.3823
2022-03-14 21:26:09 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 1.3301
2022-03-14 21:26:42 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 1.3525
2022-03-14 21:27:15 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 1.1878
2022-03-14 21:27:47 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 1.2163
2022-03-14 21:28:20 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 1.5059
2022-03-14 21:28:52 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 1.3473
2022-03-14 21:29:25 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 1.7446
2022-03-14 21:29:58 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 1.4434
2022-03-14 21:30:31 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 1.4212
2022-03-14 21:31:04 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 1.4226
2022-03-14 21:31:37 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 1.5026
2022-03-14 21:32:09 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 1.5973
2022-03-14 21:32:42 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 1.3346
2022-03-14 21:33:15 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 1.2637
2022-03-14 21:33:48 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 1.5533
2022-03-14 21:34:20 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 1.5422
2022-03-14 21:34:54 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 1.5356
2022-03-14 21:35:26 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 1.2834
2022-03-14 21:35:59 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 1.1650
2022-03-14 21:36:31 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 1.4466
2022-03-14 21:37:03 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 1.4508
2022-03-14 21:37:03 - train: epoch 098, train_loss: 1.4129
2022-03-14 21:38:18 - eval: epoch: 098, acc1: 69.052%, acc5: 88.868%, test_loss: 1.2422, per_image_load_time: 0.840ms, per_image_inference_time: 0.183ms
2022-03-14 21:38:18 - until epoch: 098, best_acc1: 69.052%
2022-03-14 21:38:18 - epoch 099 lr: 0.00010000000000000003
2022-03-14 21:38:57 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 1.1683
2022-03-14 21:39:29 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 1.2978
2022-03-14 21:40:02 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 1.3247
2022-03-14 21:40:34 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 1.4557
2022-03-14 21:41:06 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 1.4868
2022-03-14 21:41:39 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 1.3369
2022-03-14 21:42:12 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 1.4759
2022-03-14 21:42:44 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 1.4420
2022-03-14 21:43:17 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 1.3550
2022-03-14 21:43:49 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 1.5108
2022-03-14 21:44:22 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 1.4241
2022-03-14 21:44:55 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 1.3275
2022-03-14 21:45:28 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 1.5694
2022-03-14 21:46:01 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 1.4975
2022-03-14 21:46:33 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 1.3276
2022-03-14 21:47:05 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 1.5401
2022-03-14 21:47:39 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 1.3531
2022-03-14 21:48:11 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 1.5007
2022-03-14 21:48:45 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 1.4338
2022-03-14 21:49:18 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 1.2365
2022-03-14 21:49:50 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 1.3292
2022-03-14 21:50:23 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 1.4450
2022-03-14 21:50:56 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 1.4080
2022-03-14 21:51:29 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 1.5532
2022-03-14 21:52:01 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 1.3790
2022-03-14 21:52:34 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 1.3802
2022-03-14 21:53:07 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 1.4229
2022-03-14 21:53:40 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 1.4451
2022-03-14 21:54:13 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 1.3368
2022-03-14 21:54:46 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 1.5497
2022-03-14 21:55:19 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 1.3321
2022-03-14 21:55:52 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 1.5584
2022-03-14 21:56:24 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 1.3918
2022-03-14 21:56:57 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 1.4609
2022-03-14 21:57:30 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 1.5014
2022-03-14 21:58:02 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 1.3566
2022-03-14 21:58:35 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 1.2705
2022-03-14 21:59:08 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 1.5215
2022-03-14 21:59:41 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 1.4305
2022-03-14 22:00:13 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 1.5346
2022-03-14 22:00:46 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 1.2429
2022-03-14 22:01:19 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 1.5148
2022-03-14 22:01:52 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 1.3283
2022-03-14 22:02:26 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 1.4469
2022-03-14 22:02:58 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 1.4648
2022-03-14 22:03:32 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 1.6069
2022-03-14 22:04:04 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 1.3500
2022-03-14 22:04:37 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 1.6310
2022-03-14 22:05:09 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 1.3308
2022-03-14 22:05:41 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 1.4676
2022-03-14 22:05:41 - train: epoch 099, train_loss: 1.4136
2022-03-14 22:06:56 - eval: epoch: 099, acc1: 69.058%, acc5: 88.836%, test_loss: 1.2422, per_image_load_time: 0.895ms, per_image_inference_time: 0.170ms
2022-03-14 22:06:56 - until epoch: 099, best_acc1: 69.058%
2022-03-14 22:06:56 - epoch 100 lr: 0.00010000000000000003
2022-03-14 22:07:34 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 1.3851
2022-03-14 22:08:06 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 1.4851
2022-03-14 22:08:39 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 1.3396
2022-03-14 22:09:13 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 1.0939
2022-03-14 22:09:45 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 1.4874
2022-03-14 22:10:18 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 1.6223
2022-03-14 22:10:50 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 1.2665
2022-03-14 22:11:24 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 1.5490
2022-03-14 22:11:55 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 1.2942
2022-03-14 22:12:29 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 1.3900
2022-03-14 22:13:02 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 1.3905
2022-03-14 22:13:35 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 1.5994
2022-03-14 22:14:06 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 1.4713
2022-03-14 22:14:40 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 1.5502
2022-03-14 22:15:12 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 1.3543
2022-03-14 22:15:46 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 1.3222
2022-03-14 22:16:18 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 1.4152
2022-03-14 22:16:51 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 1.5065
2022-03-14 22:17:23 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 1.3910
2022-03-14 22:17:57 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 1.4895
2022-03-14 22:18:29 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 1.3255
2022-03-14 22:19:02 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 1.6167
2022-03-14 22:19:34 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 1.4108
2022-03-14 22:20:08 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 1.3305
2022-03-14 22:20:41 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 1.4145
2022-03-14 22:21:13 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 1.5079
2022-03-14 22:21:46 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 1.3419
2022-03-14 22:22:18 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 1.3876
2022-03-14 22:22:51 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 1.4818
2022-03-14 22:23:24 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 1.2581
2022-03-14 22:23:58 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 1.3534
2022-03-14 22:24:30 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 1.4933
2022-03-14 22:25:03 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 1.6312
2022-03-14 22:25:36 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 1.4914
2022-03-14 22:26:08 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 1.2284
2022-03-14 22:26:42 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 1.4298
2022-03-14 22:27:13 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 1.2784
2022-03-14 22:27:48 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 1.3481
2022-03-14 22:28:20 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 1.4678
2022-03-14 22:28:54 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 1.3221
2022-03-14 22:29:27 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 1.4295
2022-03-14 22:30:01 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 1.4490
2022-03-14 22:30:34 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 1.3121
2022-03-14 22:31:07 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 1.5601
2022-03-14 22:31:40 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 1.4011
2022-03-14 22:32:13 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 1.3049
2022-03-14 22:32:46 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 1.3965
2022-03-14 22:33:20 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 1.1655
2022-03-14 22:33:54 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 1.3840
2022-03-14 22:34:24 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 1.5433
2022-03-14 22:34:25 - train: epoch 100, train_loss: 1.4128
2022-03-14 22:35:39 - eval: epoch: 100, acc1: 69.022%, acc5: 88.882%, test_loss: 1.2424, per_image_load_time: 2.442ms, per_image_inference_time: 0.204ms
2022-03-14 22:35:39 - until epoch: 100, best_acc1: 69.058%
2022-03-14 22:35:39 - train done. model: yoloxsbackbone, train time: 47.924 hours, best_acc1: 69.058%
