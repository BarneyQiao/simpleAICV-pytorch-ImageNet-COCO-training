2022-07-07 21:17:10 - train: epoch 0050, iter [03900, 05004], lr: 0.010000, loss: 1.2923
2022-07-07 21:17:42 - train: epoch 0050, iter [04000, 05004], lr: 0.010000, loss: 1.5180
2022-07-07 21:18:16 - train: epoch 0050, iter [04100, 05004], lr: 0.010000, loss: 1.4418
2022-07-07 21:18:49 - train: epoch 0050, iter [04200, 05004], lr: 0.010000, loss: 1.5528
2022-07-07 21:19:23 - train: epoch 0050, iter [04300, 05004], lr: 0.010000, loss: 1.4459
2022-07-07 21:19:56 - train: epoch 0050, iter [04400, 05004], lr: 0.010000, loss: 1.4356
2022-07-07 21:20:30 - train: epoch 0050, iter [04500, 05004], lr: 0.010000, loss: 1.4586
2022-07-07 21:21:03 - train: epoch 0050, iter [04600, 05004], lr: 0.010000, loss: 1.4771
2022-07-07 21:21:36 - train: epoch 0050, iter [04700, 05004], lr: 0.010000, loss: 1.5101
2022-07-07 21:22:09 - train: epoch 0050, iter [04800, 05004], lr: 0.010000, loss: 1.2392
2022-07-07 21:22:42 - train: epoch 0050, iter [04900, 05004], lr: 0.010000, loss: 1.3202
2022-07-07 21:23:15 - train: epoch 0050, iter [05000, 05004], lr: 0.010000, loss: 1.4529
2022-07-07 21:23:15 - train: epoch 050, train_loss: 1.4922
2022-07-07 21:24:28 - eval: epoch: 050, acc1: 67.148%, acc5: 87.854%, test_loss: 1.3451, per_image_load_time: 2.500ms, per_image_inference_time: 0.300ms
2022-07-07 21:24:28 - until epoch: 050, best_acc1: 67.926%
2022-07-07 21:24:28 - epoch 051 lr: 0.010000
2022-07-07 21:25:07 - train: epoch 0051, iter [00100, 05004], lr: 0.010000, loss: 1.6338
2022-07-07 21:25:40 - train: epoch 0051, iter [00200, 05004], lr: 0.010000, loss: 1.7636
2022-07-07 21:26:12 - train: epoch 0051, iter [00300, 05004], lr: 0.010000, loss: 1.4841
2022-07-07 21:26:45 - train: epoch 0051, iter [00400, 05004], lr: 0.010000, loss: 1.2767
2022-07-07 21:27:18 - train: epoch 0051, iter [00500, 05004], lr: 0.010000, loss: 1.4931
2022-07-07 21:27:52 - train: epoch 0051, iter [00600, 05004], lr: 0.010000, loss: 1.4667
2022-07-07 21:28:25 - train: epoch 0051, iter [00700, 05004], lr: 0.010000, loss: 1.4355
2022-07-07 21:28:57 - train: epoch 0051, iter [00800, 05004], lr: 0.010000, loss: 1.7483
2022-07-07 21:29:30 - train: epoch 0051, iter [00900, 05004], lr: 0.010000, loss: 1.3638
2022-07-07 21:30:03 - train: epoch 0051, iter [01000, 05004], lr: 0.010000, loss: 1.8111
2022-07-07 21:30:37 - train: epoch 0051, iter [01100, 05004], lr: 0.010000, loss: 1.6410
2022-07-07 21:31:10 - train: epoch 0051, iter [01200, 05004], lr: 0.010000, loss: 1.2912
2022-07-07 21:31:43 - train: epoch 0051, iter [01300, 05004], lr: 0.010000, loss: 1.2271
2022-07-07 21:32:17 - train: epoch 0051, iter [01400, 05004], lr: 0.010000, loss: 1.4379
2022-07-07 21:32:50 - train: epoch 0051, iter [01500, 05004], lr: 0.010000, loss: 1.4336
2022-07-07 21:33:23 - train: epoch 0051, iter [01600, 05004], lr: 0.010000, loss: 1.3939
2022-07-07 21:33:56 - train: epoch 0051, iter [01700, 05004], lr: 0.010000, loss: 1.4602
2022-07-07 21:34:29 - train: epoch 0051, iter [01800, 05004], lr: 0.010000, loss: 1.4732
2022-07-07 21:35:03 - train: epoch 0051, iter [01900, 05004], lr: 0.010000, loss: 1.2684
2022-07-07 21:35:36 - train: epoch 0051, iter [02000, 05004], lr: 0.010000, loss: 1.5494
2022-07-07 21:36:09 - train: epoch 0051, iter [02100, 05004], lr: 0.010000, loss: 1.4863
2022-07-07 21:36:42 - train: epoch 0051, iter [02200, 05004], lr: 0.010000, loss: 1.4327
2022-07-07 21:37:16 - train: epoch 0051, iter [02300, 05004], lr: 0.010000, loss: 1.5298
2022-07-07 21:37:49 - train: epoch 0051, iter [02400, 05004], lr: 0.010000, loss: 1.5347
2022-07-07 21:38:22 - train: epoch 0051, iter [02500, 05004], lr: 0.010000, loss: 1.4120
2022-07-07 21:38:56 - train: epoch 0051, iter [02600, 05004], lr: 0.010000, loss: 1.3586
2022-07-07 21:39:28 - train: epoch 0051, iter [02700, 05004], lr: 0.010000, loss: 1.5523
2022-07-07 21:40:02 - train: epoch 0051, iter [02800, 05004], lr: 0.010000, loss: 1.4120
2022-07-07 21:40:35 - train: epoch 0051, iter [02900, 05004], lr: 0.010000, loss: 1.5007
2022-07-07 21:41:09 - train: epoch 0051, iter [03000, 05004], lr: 0.010000, loss: 1.3702
2022-07-07 21:41:42 - train: epoch 0051, iter [03100, 05004], lr: 0.010000, loss: 1.3536
2022-07-07 21:42:15 - train: epoch 0051, iter [03200, 05004], lr: 0.010000, loss: 1.4815
2022-07-07 21:42:48 - train: epoch 0051, iter [03300, 05004], lr: 0.010000, loss: 1.5206
2022-07-07 21:43:22 - train: epoch 0051, iter [03400, 05004], lr: 0.010000, loss: 1.4933
2022-07-07 21:43:55 - train: epoch 0051, iter [03500, 05004], lr: 0.010000, loss: 1.3543
2022-07-07 21:44:29 - train: epoch 0051, iter [03600, 05004], lr: 0.010000, loss: 1.5098
2022-07-07 21:45:02 - train: epoch 0051, iter [03700, 05004], lr: 0.010000, loss: 1.6348
2022-07-07 21:45:35 - train: epoch 0051, iter [03800, 05004], lr: 0.010000, loss: 1.5080
2022-07-07 21:46:08 - train: epoch 0051, iter [03900, 05004], lr: 0.010000, loss: 1.6107
2022-07-07 21:46:41 - train: epoch 0051, iter [04000, 05004], lr: 0.010000, loss: 1.5128
2022-07-07 21:47:15 - train: epoch 0051, iter [04100, 05004], lr: 0.010000, loss: 1.6085
2022-07-07 21:47:47 - train: epoch 0051, iter [04200, 05004], lr: 0.010000, loss: 1.8059
2022-07-07 21:48:21 - train: epoch 0051, iter [04300, 05004], lr: 0.010000, loss: 1.4225
2022-07-07 21:48:54 - train: epoch 0051, iter [04400, 05004], lr: 0.010000, loss: 1.5723
2022-07-07 21:49:27 - train: epoch 0051, iter [04500, 05004], lr: 0.010000, loss: 1.3473
2022-07-07 21:50:01 - train: epoch 0051, iter [04600, 05004], lr: 0.010000, loss: 1.6068
2022-07-07 21:50:34 - train: epoch 0051, iter [04700, 05004], lr: 0.010000, loss: 1.5553
2022-07-07 21:51:07 - train: epoch 0051, iter [04800, 05004], lr: 0.010000, loss: 1.4167
2022-07-07 21:51:40 - train: epoch 0051, iter [04900, 05004], lr: 0.010000, loss: 1.6684
2022-07-07 21:52:12 - train: epoch 0051, iter [05000, 05004], lr: 0.010000, loss: 1.4588
2022-07-07 21:52:13 - train: epoch 051, train_loss: 1.4918
2022-07-07 21:53:26 - eval: epoch: 051, acc1: 67.154%, acc5: 87.808%, test_loss: 1.3410, per_image_load_time: 1.645ms, per_image_inference_time: 0.272ms
2022-07-07 21:53:26 - until epoch: 051, best_acc1: 67.926%
2022-07-07 21:53:26 - epoch 052 lr: 0.010000
2022-07-07 21:54:05 - train: epoch 0052, iter [00100, 05004], lr: 0.010000, loss: 1.3465
2022-07-07 21:54:38 - train: epoch 0052, iter [00200, 05004], lr: 0.010000, loss: 1.4969
2022-07-07 21:55:10 - train: epoch 0052, iter [00300, 05004], lr: 0.010000, loss: 1.6334
2022-07-07 21:55:42 - train: epoch 0052, iter [00400, 05004], lr: 0.010000, loss: 1.5398
2022-07-07 21:56:16 - train: epoch 0052, iter [00500, 05004], lr: 0.010000, loss: 1.5939
2022-07-07 21:56:49 - train: epoch 0052, iter [00600, 05004], lr: 0.010000, loss: 1.3858
2022-07-07 21:57:20 - train: epoch 0052, iter [00700, 05004], lr: 0.010000, loss: 1.5874
2022-07-07 21:57:54 - train: epoch 0052, iter [00800, 05004], lr: 0.010000, loss: 1.5428
2022-07-07 21:58:27 - train: epoch 0052, iter [00900, 05004], lr: 0.010000, loss: 1.5385
2022-07-07 21:59:00 - train: epoch 0052, iter [01000, 05004], lr: 0.010000, loss: 1.6301
2022-07-07 21:59:33 - train: epoch 0052, iter [01100, 05004], lr: 0.010000, loss: 1.4519
2022-07-07 22:00:07 - train: epoch 0052, iter [01200, 05004], lr: 0.010000, loss: 1.3160
2022-07-07 22:00:39 - train: epoch 0052, iter [01300, 05004], lr: 0.010000, loss: 1.4029
2022-07-07 22:01:12 - train: epoch 0052, iter [01400, 05004], lr: 0.010000, loss: 1.7862
2022-07-07 22:01:45 - train: epoch 0052, iter [01500, 05004], lr: 0.010000, loss: 1.3692
2022-07-07 22:02:18 - train: epoch 0052, iter [01600, 05004], lr: 0.010000, loss: 1.2625
2022-07-07 22:02:51 - train: epoch 0052, iter [01700, 05004], lr: 0.010000, loss: 1.3058
2022-07-07 22:03:25 - train: epoch 0052, iter [01800, 05004], lr: 0.010000, loss: 1.3116
2022-07-07 22:03:57 - train: epoch 0052, iter [01900, 05004], lr: 0.010000, loss: 1.5148
2022-07-07 22:04:31 - train: epoch 0052, iter [02000, 05004], lr: 0.010000, loss: 1.6195
2022-07-07 22:05:03 - train: epoch 0052, iter [02100, 05004], lr: 0.010000, loss: 1.3865
2022-07-07 22:05:37 - train: epoch 0052, iter [02200, 05004], lr: 0.010000, loss: 1.5144
2022-07-07 22:06:10 - train: epoch 0052, iter [02300, 05004], lr: 0.010000, loss: 1.3162
2022-07-07 22:06:44 - train: epoch 0052, iter [02400, 05004], lr: 0.010000, loss: 1.4301
2022-07-07 22:07:16 - train: epoch 0052, iter [02500, 05004], lr: 0.010000, loss: 1.2961
2022-07-07 22:07:51 - train: epoch 0052, iter [02600, 05004], lr: 0.010000, loss: 1.3007
2022-07-07 22:08:23 - train: epoch 0052, iter [02700, 05004], lr: 0.010000, loss: 1.3553
2022-07-07 22:08:56 - train: epoch 0052, iter [02800, 05004], lr: 0.010000, loss: 1.4925
2022-07-07 22:09:29 - train: epoch 0052, iter [02900, 05004], lr: 0.010000, loss: 1.3533
2022-07-07 22:10:03 - train: epoch 0052, iter [03000, 05004], lr: 0.010000, loss: 1.4316
2022-07-07 22:10:35 - train: epoch 0052, iter [03100, 05004], lr: 0.010000, loss: 1.5562
2022-07-07 22:11:10 - train: epoch 0052, iter [03200, 05004], lr: 0.010000, loss: 1.6627
2022-07-07 22:11:42 - train: epoch 0052, iter [03300, 05004], lr: 0.010000, loss: 1.4998
2022-07-07 22:12:15 - train: epoch 0052, iter [03400, 05004], lr: 0.010000, loss: 1.6222
2022-07-07 22:12:49 - train: epoch 0052, iter [03500, 05004], lr: 0.010000, loss: 1.5490
2022-07-07 22:13:22 - train: epoch 0052, iter [03600, 05004], lr: 0.010000, loss: 1.5843
2022-07-07 22:13:55 - train: epoch 0052, iter [03700, 05004], lr: 0.010000, loss: 1.6899
2022-07-07 22:14:29 - train: epoch 0052, iter [03800, 05004], lr: 0.010000, loss: 1.3810
2022-07-07 22:15:01 - train: epoch 0052, iter [03900, 05004], lr: 0.010000, loss: 1.3721
2022-07-07 22:15:35 - train: epoch 0052, iter [04000, 05004], lr: 0.010000, loss: 1.6043
2022-07-07 22:16:08 - train: epoch 0052, iter [04100, 05004], lr: 0.010000, loss: 1.3060
2022-07-07 22:16:41 - train: epoch 0052, iter [04200, 05004], lr: 0.010000, loss: 1.4041
2022-07-07 22:17:15 - train: epoch 0052, iter [04300, 05004], lr: 0.010000, loss: 1.4943
2022-07-07 22:17:49 - train: epoch 0052, iter [04400, 05004], lr: 0.010000, loss: 1.5704
2022-07-07 22:18:21 - train: epoch 0052, iter [04500, 05004], lr: 0.010000, loss: 1.4805
2022-07-07 22:18:55 - train: epoch 0052, iter [04600, 05004], lr: 0.010000, loss: 1.6538
2022-07-07 22:19:28 - train: epoch 0052, iter [04700, 05004], lr: 0.010000, loss: 1.4916
2022-07-07 22:20:02 - train: epoch 0052, iter [04800, 05004], lr: 0.010000, loss: 1.3677
2022-07-07 22:20:34 - train: epoch 0052, iter [04900, 05004], lr: 0.010000, loss: 1.3162
2022-07-07 22:21:06 - train: epoch 0052, iter [05000, 05004], lr: 0.010000, loss: 1.4418
2022-07-07 22:21:07 - train: epoch 052, train_loss: 1.4899
2022-07-07 22:22:20 - eval: epoch: 052, acc1: 67.026%, acc5: 87.744%, test_loss: 1.3472, per_image_load_time: 2.394ms, per_image_inference_time: 0.285ms
2022-07-07 22:22:20 - until epoch: 052, best_acc1: 67.926%
2022-07-07 22:22:20 - epoch 053 lr: 0.010000
2022-07-07 22:22:58 - train: epoch 0053, iter [00100, 05004], lr: 0.010000, loss: 1.5326
2022-07-07 22:23:32 - train: epoch 0053, iter [00200, 05004], lr: 0.010000, loss: 1.7403
2022-07-07 22:24:04 - train: epoch 0053, iter [00300, 05004], lr: 0.010000, loss: 1.4310
2022-07-07 22:24:37 - train: epoch 0053, iter [00400, 05004], lr: 0.010000, loss: 1.5628
2022-07-07 22:25:10 - train: epoch 0053, iter [00500, 05004], lr: 0.010000, loss: 1.5871
2022-07-07 22:25:43 - train: epoch 0053, iter [00600, 05004], lr: 0.010000, loss: 1.4671
2022-07-07 22:26:16 - train: epoch 0053, iter [00700, 05004], lr: 0.010000, loss: 1.3847
2022-07-07 22:26:49 - train: epoch 0053, iter [00800, 05004], lr: 0.010000, loss: 1.5711
2022-07-07 22:27:22 - train: epoch 0053, iter [00900, 05004], lr: 0.010000, loss: 1.3968
2022-07-07 22:27:55 - train: epoch 0053, iter [01000, 05004], lr: 0.010000, loss: 1.5077
2022-07-07 22:28:28 - train: epoch 0053, iter [01100, 05004], lr: 0.010000, loss: 1.4775
2022-07-07 22:29:01 - train: epoch 0053, iter [01200, 05004], lr: 0.010000, loss: 1.5029
2022-07-07 22:29:34 - train: epoch 0053, iter [01300, 05004], lr: 0.010000, loss: 1.5682
2022-07-07 22:30:08 - train: epoch 0053, iter [01400, 05004], lr: 0.010000, loss: 1.8296
2022-07-07 22:30:40 - train: epoch 0053, iter [01500, 05004], lr: 0.010000, loss: 1.5055
2022-07-07 22:31:15 - train: epoch 0053, iter [01600, 05004], lr: 0.010000, loss: 1.6551
2022-07-07 22:31:48 - train: epoch 0053, iter [01700, 05004], lr: 0.010000, loss: 1.7277
2022-07-07 22:32:21 - train: epoch 0053, iter [01800, 05004], lr: 0.010000, loss: 1.6589
2022-07-07 22:32:54 - train: epoch 0053, iter [01900, 05004], lr: 0.010000, loss: 1.3099
2022-07-07 22:33:27 - train: epoch 0053, iter [02000, 05004], lr: 0.010000, loss: 1.4531
2022-07-07 22:34:00 - train: epoch 0053, iter [02100, 05004], lr: 0.010000, loss: 1.5366
2022-07-07 22:34:34 - train: epoch 0053, iter [02200, 05004], lr: 0.010000, loss: 1.3656
2022-07-07 22:35:07 - train: epoch 0053, iter [02300, 05004], lr: 0.010000, loss: 1.5404
2022-07-07 22:35:40 - train: epoch 0053, iter [02400, 05004], lr: 0.010000, loss: 1.4957
2022-07-07 22:36:14 - train: epoch 0053, iter [02500, 05004], lr: 0.010000, loss: 1.7600
2022-07-07 22:36:47 - train: epoch 0053, iter [02600, 05004], lr: 0.010000, loss: 1.6254
2022-07-07 22:37:20 - train: epoch 0053, iter [02700, 05004], lr: 0.010000, loss: 1.7152
2022-07-07 22:37:53 - train: epoch 0053, iter [02800, 05004], lr: 0.010000, loss: 1.6590
2022-07-07 22:38:27 - train: epoch 0053, iter [02900, 05004], lr: 0.010000, loss: 1.3689
2022-07-07 22:38:59 - train: epoch 0053, iter [03000, 05004], lr: 0.010000, loss: 1.2469
2022-07-07 22:39:33 - train: epoch 0053, iter [03100, 05004], lr: 0.010000, loss: 1.7104
2022-07-07 22:40:07 - train: epoch 0053, iter [03200, 05004], lr: 0.010000, loss: 1.7586
2022-07-07 22:40:40 - train: epoch 0053, iter [03300, 05004], lr: 0.010000, loss: 1.3955
2022-07-07 22:41:14 - train: epoch 0053, iter [03400, 05004], lr: 0.010000, loss: 1.6673
2022-07-07 22:41:47 - train: epoch 0053, iter [03500, 05004], lr: 0.010000, loss: 1.5285
2022-07-07 22:42:20 - train: epoch 0053, iter [03600, 05004], lr: 0.010000, loss: 1.6097
2022-07-07 22:42:53 - train: epoch 0053, iter [03700, 05004], lr: 0.010000, loss: 1.6431
2022-07-07 22:43:27 - train: epoch 0053, iter [03800, 05004], lr: 0.010000, loss: 1.4334
2022-07-07 22:44:00 - train: epoch 0053, iter [03900, 05004], lr: 0.010000, loss: 1.6127
2022-07-07 22:44:34 - train: epoch 0053, iter [04000, 05004], lr: 0.010000, loss: 1.5650
2022-07-07 22:45:07 - train: epoch 0053, iter [04100, 05004], lr: 0.010000, loss: 1.5632
2022-07-07 22:45:41 - train: epoch 0053, iter [04200, 05004], lr: 0.010000, loss: 1.5919
2022-07-07 22:46:14 - train: epoch 0053, iter [04300, 05004], lr: 0.010000, loss: 1.7627
2022-07-07 22:46:47 - train: epoch 0053, iter [04400, 05004], lr: 0.010000, loss: 1.4237
2022-07-07 22:47:20 - train: epoch 0053, iter [04500, 05004], lr: 0.010000, loss: 1.6188
2022-07-07 22:47:54 - train: epoch 0053, iter [04600, 05004], lr: 0.010000, loss: 1.4567
2022-07-07 22:48:27 - train: epoch 0053, iter [04700, 05004], lr: 0.010000, loss: 1.6779
2022-07-07 22:49:01 - train: epoch 0053, iter [04800, 05004], lr: 0.010000, loss: 1.6804
2022-07-07 22:49:34 - train: epoch 0053, iter [04900, 05004], lr: 0.010000, loss: 1.3348
2022-07-07 22:50:06 - train: epoch 0053, iter [05000, 05004], lr: 0.010000, loss: 1.4809
2022-07-07 22:50:06 - train: epoch 053, train_loss: 1.4887
2022-07-07 22:51:20 - eval: epoch: 053, acc1: 67.338%, acc5: 88.054%, test_loss: 1.3311, per_image_load_time: 2.079ms, per_image_inference_time: 0.287ms
2022-07-07 22:51:20 - until epoch: 053, best_acc1: 67.926%
2022-07-07 22:51:20 - epoch 054 lr: 0.010000
2022-07-07 22:51:58 - train: epoch 0054, iter [00100, 05004], lr: 0.010000, loss: 1.3091
2022-07-07 22:52:31 - train: epoch 0054, iter [00200, 05004], lr: 0.010000, loss: 1.8143
2022-07-07 22:53:03 - train: epoch 0054, iter [00300, 05004], lr: 0.010000, loss: 1.4909
2022-07-07 22:53:36 - train: epoch 0054, iter [00400, 05004], lr: 0.010000, loss: 1.3120
2022-07-07 22:54:09 - train: epoch 0054, iter [00500, 05004], lr: 0.010000, loss: 1.4763
2022-07-07 22:54:42 - train: epoch 0054, iter [00600, 05004], lr: 0.010000, loss: 1.3110
2022-07-07 22:55:16 - train: epoch 0054, iter [00700, 05004], lr: 0.010000, loss: 1.5018
2022-07-07 22:55:48 - train: epoch 0054, iter [00800, 05004], lr: 0.010000, loss: 1.5981
2022-07-07 22:56:22 - train: epoch 0054, iter [00900, 05004], lr: 0.010000, loss: 1.2209
2022-07-07 22:56:54 - train: epoch 0054, iter [01000, 05004], lr: 0.010000, loss: 1.3007
2022-07-07 22:57:29 - train: epoch 0054, iter [01100, 05004], lr: 0.010000, loss: 1.3488
2022-07-07 22:58:02 - train: epoch 0054, iter [01200, 05004], lr: 0.010000, loss: 1.6175
2022-07-07 22:58:35 - train: epoch 0054, iter [01300, 05004], lr: 0.010000, loss: 1.3562
2022-07-07 22:59:07 - train: epoch 0054, iter [01400, 05004], lr: 0.010000, loss: 1.5078
2022-07-07 22:59:41 - train: epoch 0054, iter [01500, 05004], lr: 0.010000, loss: 1.5097
2022-07-07 23:00:15 - train: epoch 0054, iter [01600, 05004], lr: 0.010000, loss: 1.2146
2022-07-07 23:00:47 - train: epoch 0054, iter [01700, 05004], lr: 0.010000, loss: 1.4971
2022-07-07 23:01:22 - train: epoch 0054, iter [01800, 05004], lr: 0.010000, loss: 1.4439
2022-07-07 23:01:54 - train: epoch 0054, iter [01900, 05004], lr: 0.010000, loss: 1.7776
2022-07-07 23:02:27 - train: epoch 0054, iter [02000, 05004], lr: 0.010000, loss: 1.5946
2022-07-07 23:03:00 - train: epoch 0054, iter [02100, 05004], lr: 0.010000, loss: 1.3196
2022-07-07 23:03:34 - train: epoch 0054, iter [02200, 05004], lr: 0.010000, loss: 1.4155
2022-07-07 23:04:07 - train: epoch 0054, iter [02300, 05004], lr: 0.010000, loss: 1.5615
2022-07-07 23:04:41 - train: epoch 0054, iter [02400, 05004], lr: 0.010000, loss: 1.3806
2022-07-07 23:05:14 - train: epoch 0054, iter [02500, 05004], lr: 0.010000, loss: 1.5761
2022-07-07 23:05:46 - train: epoch 0054, iter [02600, 05004], lr: 0.010000, loss: 1.4396
2022-07-07 23:06:21 - train: epoch 0054, iter [02700, 05004], lr: 0.010000, loss: 1.5635
2022-07-07 23:06:53 - train: epoch 0054, iter [02800, 05004], lr: 0.010000, loss: 1.8331
2022-07-07 23:07:28 - train: epoch 0054, iter [02900, 05004], lr: 0.010000, loss: 1.3781
2022-07-07 23:08:00 - train: epoch 0054, iter [03000, 05004], lr: 0.010000, loss: 1.5478
2022-07-07 23:08:33 - train: epoch 0054, iter [03100, 05004], lr: 0.010000, loss: 1.4743
2022-07-07 23:09:07 - train: epoch 0054, iter [03200, 05004], lr: 0.010000, loss: 1.6196
2022-07-07 23:09:40 - train: epoch 0054, iter [03300, 05004], lr: 0.010000, loss: 1.4316
2022-07-07 23:10:13 - train: epoch 0054, iter [03400, 05004], lr: 0.010000, loss: 1.5771
2022-07-07 23:10:47 - train: epoch 0054, iter [03500, 05004], lr: 0.010000, loss: 1.6351
2022-07-07 23:11:20 - train: epoch 0054, iter [03600, 05004], lr: 0.010000, loss: 1.4723
2022-07-07 23:11:53 - train: epoch 0054, iter [03700, 05004], lr: 0.010000, loss: 1.4188
2022-07-07 23:12:26 - train: epoch 0054, iter [03800, 05004], lr: 0.010000, loss: 1.5170
2022-07-07 23:13:00 - train: epoch 0054, iter [03900, 05004], lr: 0.010000, loss: 1.4858
2022-07-07 23:13:33 - train: epoch 0054, iter [04000, 05004], lr: 0.010000, loss: 1.3226
2022-07-07 23:14:07 - train: epoch 0054, iter [04100, 05004], lr: 0.010000, loss: 1.5947
2022-07-07 23:14:40 - train: epoch 0054, iter [04200, 05004], lr: 0.010000, loss: 1.5205
2022-07-07 23:15:13 - train: epoch 0054, iter [04300, 05004], lr: 0.010000, loss: 1.5109
2022-07-07 23:15:46 - train: epoch 0054, iter [04400, 05004], lr: 0.010000, loss: 1.3111
2022-07-07 23:16:20 - train: epoch 0054, iter [04500, 05004], lr: 0.010000, loss: 1.3473
2022-07-07 23:16:53 - train: epoch 0054, iter [04600, 05004], lr: 0.010000, loss: 1.4934
2022-07-07 23:17:26 - train: epoch 0054, iter [04700, 05004], lr: 0.010000, loss: 1.6899
2022-07-07 23:18:00 - train: epoch 0054, iter [04800, 05004], lr: 0.010000, loss: 1.6823
2022-07-07 23:18:32 - train: epoch 0054, iter [04900, 05004], lr: 0.010000, loss: 1.3871
2022-07-07 23:19:04 - train: epoch 0054, iter [05000, 05004], lr: 0.010000, loss: 1.5592
2022-07-07 23:19:05 - train: epoch 054, train_loss: 1.4886
2022-07-07 23:20:19 - eval: epoch: 054, acc1: 66.996%, acc5: 87.740%, test_loss: 1.3499, per_image_load_time: 2.584ms, per_image_inference_time: 0.264ms
2022-07-07 23:20:19 - until epoch: 054, best_acc1: 67.926%
2022-07-07 23:20:19 - epoch 055 lr: 0.010000
2022-07-07 23:20:58 - train: epoch 0055, iter [00100, 05004], lr: 0.010000, loss: 1.4464
2022-07-07 23:21:30 - train: epoch 0055, iter [00200, 05004], lr: 0.010000, loss: 1.3001
2022-07-07 23:22:03 - train: epoch 0055, iter [00300, 05004], lr: 0.010000, loss: 1.2330
2022-07-07 23:22:36 - train: epoch 0055, iter [00400, 05004], lr: 0.010000, loss: 1.4875
2022-07-07 23:23:09 - train: epoch 0055, iter [00500, 05004], lr: 0.010000, loss: 1.3518
2022-07-07 23:23:42 - train: epoch 0055, iter [00600, 05004], lr: 0.010000, loss: 1.4208
2022-07-07 23:24:15 - train: epoch 0055, iter [00700, 05004], lr: 0.010000, loss: 1.4842
2022-07-07 23:24:48 - train: epoch 0055, iter [00800, 05004], lr: 0.010000, loss: 1.3668
2022-07-07 23:25:22 - train: epoch 0055, iter [00900, 05004], lr: 0.010000, loss: 1.5302
2022-07-07 23:25:54 - train: epoch 0055, iter [01000, 05004], lr: 0.010000, loss: 1.4469
2022-07-07 23:26:27 - train: epoch 0055, iter [01100, 05004], lr: 0.010000, loss: 1.4311
2022-07-07 23:27:00 - train: epoch 0055, iter [01200, 05004], lr: 0.010000, loss: 1.4957
2022-07-07 23:27:34 - train: epoch 0055, iter [01300, 05004], lr: 0.010000, loss: 1.6033
2022-07-07 23:28:07 - train: epoch 0055, iter [01400, 05004], lr: 0.010000, loss: 1.4607
2022-07-07 23:28:40 - train: epoch 0055, iter [01500, 05004], lr: 0.010000, loss: 1.4848
2022-07-07 23:29:13 - train: epoch 0055, iter [01600, 05004], lr: 0.010000, loss: 1.5944
2022-07-07 23:29:47 - train: epoch 0055, iter [01700, 05004], lr: 0.010000, loss: 1.5555
2022-07-07 23:30:20 - train: epoch 0055, iter [01800, 05004], lr: 0.010000, loss: 1.5995
2022-07-07 23:30:53 - train: epoch 0055, iter [01900, 05004], lr: 0.010000, loss: 1.5364
2022-07-07 23:31:28 - train: epoch 0055, iter [02000, 05004], lr: 0.010000, loss: 1.4335
2022-07-07 23:32:01 - train: epoch 0055, iter [02100, 05004], lr: 0.010000, loss: 1.2345
2022-07-07 23:32:34 - train: epoch 0055, iter [02200, 05004], lr: 0.010000, loss: 1.5916
2022-07-07 23:33:07 - train: epoch 0055, iter [02300, 05004], lr: 0.010000, loss: 1.4255
2022-07-07 23:33:41 - train: epoch 0055, iter [02400, 05004], lr: 0.010000, loss: 1.2778
2022-07-07 23:34:14 - train: epoch 0055, iter [02500, 05004], lr: 0.010000, loss: 1.5221
2022-07-07 23:34:47 - train: epoch 0055, iter [02600, 05004], lr: 0.010000, loss: 1.3856
2022-07-07 23:35:20 - train: epoch 0055, iter [02700, 05004], lr: 0.010000, loss: 1.3409
2022-07-07 23:35:54 - train: epoch 0055, iter [02800, 05004], lr: 0.010000, loss: 1.5003
2022-07-07 23:36:26 - train: epoch 0055, iter [02900, 05004], lr: 0.010000, loss: 1.6246
2022-07-07 23:37:00 - train: epoch 0055, iter [03000, 05004], lr: 0.010000, loss: 1.4364
2022-07-07 23:37:33 - train: epoch 0055, iter [03100, 05004], lr: 0.010000, loss: 1.6078
2022-07-07 23:38:06 - train: epoch 0055, iter [03200, 05004], lr: 0.010000, loss: 1.3970
2022-07-07 23:38:39 - train: epoch 0055, iter [03300, 05004], lr: 0.010000, loss: 1.2519
2022-07-07 23:39:14 - train: epoch 0055, iter [03400, 05004], lr: 0.010000, loss: 1.4088
2022-07-07 23:39:46 - train: epoch 0055, iter [03500, 05004], lr: 0.010000, loss: 1.3105
2022-07-07 23:40:20 - train: epoch 0055, iter [03600, 05004], lr: 0.010000, loss: 1.5122
2022-07-07 23:40:53 - train: epoch 0055, iter [03700, 05004], lr: 0.010000, loss: 1.5114
2022-07-07 23:41:26 - train: epoch 0055, iter [03800, 05004], lr: 0.010000, loss: 1.5664
2022-07-07 23:41:59 - train: epoch 0055, iter [03900, 05004], lr: 0.010000, loss: 1.7821
2022-07-07 23:42:33 - train: epoch 0055, iter [04000, 05004], lr: 0.010000, loss: 1.4329
2022-07-07 23:43:06 - train: epoch 0055, iter [04100, 05004], lr: 0.010000, loss: 1.5237
2022-07-07 23:43:40 - train: epoch 0055, iter [04200, 05004], lr: 0.010000, loss: 1.4960
2022-07-07 23:44:14 - train: epoch 0055, iter [04300, 05004], lr: 0.010000, loss: 1.6126
2022-07-07 23:44:47 - train: epoch 0055, iter [04400, 05004], lr: 0.010000, loss: 1.7469
2022-07-07 23:45:20 - train: epoch 0055, iter [04500, 05004], lr: 0.010000, loss: 1.5651
2022-07-07 23:45:54 - train: epoch 0055, iter [04600, 05004], lr: 0.010000, loss: 1.5606
2022-07-07 23:46:27 - train: epoch 0055, iter [04700, 05004], lr: 0.010000, loss: 1.3645
2022-07-07 23:47:01 - train: epoch 0055, iter [04800, 05004], lr: 0.010000, loss: 1.5195
2022-07-07 23:47:34 - train: epoch 0055, iter [04900, 05004], lr: 0.010000, loss: 1.3469
2022-07-07 23:48:05 - train: epoch 0055, iter [05000, 05004], lr: 0.010000, loss: 1.6074
2022-07-07 23:48:06 - train: epoch 055, train_loss: 1.4846
2022-07-07 23:49:19 - eval: epoch: 055, acc1: 67.520%, acc5: 88.124%, test_loss: 1.3173, per_image_load_time: 1.952ms, per_image_inference_time: 0.274ms
2022-07-07 23:49:19 - until epoch: 055, best_acc1: 67.926%
2022-07-07 23:49:19 - epoch 056 lr: 0.010000
2022-07-07 23:49:58 - train: epoch 0056, iter [00100, 05004], lr: 0.010000, loss: 1.6052
2022-07-07 23:50:31 - train: epoch 0056, iter [00200, 05004], lr: 0.010000, loss: 1.6225
2022-07-07 23:51:04 - train: epoch 0056, iter [00300, 05004], lr: 0.010000, loss: 1.4518
2022-07-07 23:51:36 - train: epoch 0056, iter [00400, 05004], lr: 0.010000, loss: 1.4513
2022-07-07 23:52:11 - train: epoch 0056, iter [00500, 05004], lr: 0.010000, loss: 1.4188
2022-07-07 23:52:43 - train: epoch 0056, iter [00600, 05004], lr: 0.010000, loss: 1.4130
2022-07-07 23:53:16 - train: epoch 0056, iter [00700, 05004], lr: 0.010000, loss: 1.5418
2022-07-07 23:53:49 - train: epoch 0056, iter [00800, 05004], lr: 0.010000, loss: 1.6170
2022-07-07 23:54:22 - train: epoch 0056, iter [00900, 05004], lr: 0.010000, loss: 1.5705
2022-07-07 23:54:55 - train: epoch 0056, iter [01000, 05004], lr: 0.010000, loss: 1.4808
2022-07-07 23:55:29 - train: epoch 0056, iter [01100, 05004], lr: 0.010000, loss: 1.3421
2022-07-07 23:56:02 - train: epoch 0056, iter [01200, 05004], lr: 0.010000, loss: 1.4028
2022-07-07 23:56:35 - train: epoch 0056, iter [01300, 05004], lr: 0.010000, loss: 1.5398
2022-07-07 23:57:08 - train: epoch 0056, iter [01400, 05004], lr: 0.010000, loss: 1.4496
2022-07-07 23:57:41 - train: epoch 0056, iter [01500, 05004], lr: 0.010000, loss: 1.8275
2022-07-07 23:58:15 - train: epoch 0056, iter [01600, 05004], lr: 0.010000, loss: 1.3290
2022-07-07 23:58:48 - train: epoch 0056, iter [01700, 05004], lr: 0.010000, loss: 1.6124
2022-07-07 23:59:21 - train: epoch 0056, iter [01800, 05004], lr: 0.010000, loss: 1.6818
2022-07-07 23:59:55 - train: epoch 0056, iter [01900, 05004], lr: 0.010000, loss: 1.4876
2022-07-08 00:00:29 - train: epoch 0056, iter [02000, 05004], lr: 0.010000, loss: 1.5194
2022-07-08 00:01:02 - train: epoch 0056, iter [02100, 05004], lr: 0.010000, loss: 1.5540
2022-07-08 00:01:36 - train: epoch 0056, iter [02200, 05004], lr: 0.010000, loss: 1.5432
2022-07-08 00:02:09 - train: epoch 0056, iter [02300, 05004], lr: 0.010000, loss: 1.5786
2022-07-08 00:02:42 - train: epoch 0056, iter [02400, 05004], lr: 0.010000, loss: 1.4496
2022-07-08 00:03:16 - train: epoch 0056, iter [02500, 05004], lr: 0.010000, loss: 1.6855
2022-07-08 00:03:49 - train: epoch 0056, iter [02600, 05004], lr: 0.010000, loss: 1.4596
2022-07-08 00:04:23 - train: epoch 0056, iter [02700, 05004], lr: 0.010000, loss: 1.4822
2022-07-08 00:04:55 - train: epoch 0056, iter [02800, 05004], lr: 0.010000, loss: 1.3954
2022-07-08 00:05:29 - train: epoch 0056, iter [02900, 05004], lr: 0.010000, loss: 1.5976
2022-07-08 00:06:03 - train: epoch 0056, iter [03000, 05004], lr: 0.010000, loss: 1.6677
2022-07-08 00:06:36 - train: epoch 0056, iter [03100, 05004], lr: 0.010000, loss: 1.3650
2022-07-08 00:07:10 - train: epoch 0056, iter [03200, 05004], lr: 0.010000, loss: 1.3375
2022-07-08 00:07:43 - train: epoch 0056, iter [03300, 05004], lr: 0.010000, loss: 1.7227
2022-07-08 00:08:16 - train: epoch 0056, iter [03400, 05004], lr: 0.010000, loss: 1.5124
2022-07-08 00:08:50 - train: epoch 0056, iter [03500, 05004], lr: 0.010000, loss: 1.5438
2022-07-08 00:09:24 - train: epoch 0056, iter [03600, 05004], lr: 0.010000, loss: 1.2753
2022-07-08 00:09:56 - train: epoch 0056, iter [03700, 05004], lr: 0.010000, loss: 1.4281
2022-07-08 00:10:30 - train: epoch 0056, iter [03800, 05004], lr: 0.010000, loss: 1.3415
2022-07-08 00:11:02 - train: epoch 0056, iter [03900, 05004], lr: 0.010000, loss: 1.6483
2022-07-08 00:11:36 - train: epoch 0056, iter [04000, 05004], lr: 0.010000, loss: 1.5908
2022-07-08 00:12:09 - train: epoch 0056, iter [04100, 05004], lr: 0.010000, loss: 1.6611
2022-07-08 00:12:43 - train: epoch 0056, iter [04200, 05004], lr: 0.010000, loss: 1.4213
2022-07-08 00:13:17 - train: epoch 0056, iter [04300, 05004], lr: 0.010000, loss: 1.4402
2022-07-08 00:13:49 - train: epoch 0056, iter [04400, 05004], lr: 0.010000, loss: 1.6664
2022-07-08 00:14:24 - train: epoch 0056, iter [04500, 05004], lr: 0.010000, loss: 1.5477
2022-07-08 00:14:56 - train: epoch 0056, iter [04600, 05004], lr: 0.010000, loss: 1.5589
2022-07-08 00:15:30 - train: epoch 0056, iter [04700, 05004], lr: 0.010000, loss: 1.5154
2022-07-08 00:16:04 - train: epoch 0056, iter [04800, 05004], lr: 0.010000, loss: 1.7252
2022-07-08 00:16:37 - train: epoch 0056, iter [04900, 05004], lr: 0.010000, loss: 1.5150
2022-07-08 00:17:08 - train: epoch 0056, iter [05000, 05004], lr: 0.010000, loss: 1.6504
2022-07-08 00:17:09 - train: epoch 056, train_loss: 1.4818
2022-07-08 00:18:23 - eval: epoch: 056, acc1: 66.878%, acc5: 87.880%, test_loss: 1.3539, per_image_load_time: 1.771ms, per_image_inference_time: 0.272ms
2022-07-08 00:18:23 - until epoch: 056, best_acc1: 67.926%
2022-07-08 00:18:23 - epoch 057 lr: 0.010000
2022-07-08 00:19:03 - train: epoch 0057, iter [00100, 05004], lr: 0.010000, loss: 1.5863
2022-07-08 00:19:35 - train: epoch 0057, iter [00200, 05004], lr: 0.010000, loss: 1.2807
2022-07-08 00:20:08 - train: epoch 0057, iter [00300, 05004], lr: 0.010000, loss: 1.3930
2022-07-08 00:20:42 - train: epoch 0057, iter [00400, 05004], lr: 0.010000, loss: 1.4601
2022-07-08 00:21:15 - train: epoch 0057, iter [00500, 05004], lr: 0.010000, loss: 1.1678
2022-07-08 00:21:47 - train: epoch 0057, iter [00600, 05004], lr: 0.010000, loss: 1.6535
2022-07-08 00:22:20 - train: epoch 0057, iter [00700, 05004], lr: 0.010000, loss: 1.2375
2022-07-08 00:22:53 - train: epoch 0057, iter [00800, 05004], lr: 0.010000, loss: 1.5290
2022-07-08 00:23:27 - train: epoch 0057, iter [00900, 05004], lr: 0.010000, loss: 1.5896
2022-07-08 00:24:00 - train: epoch 0057, iter [01000, 05004], lr: 0.010000, loss: 1.4369
2022-07-08 00:24:34 - train: epoch 0057, iter [01100, 05004], lr: 0.010000, loss: 1.3313
2022-07-08 00:25:06 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 1.4238
2022-07-08 00:25:40 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 1.5264
2022-07-08 00:26:14 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 1.5145
2022-07-08 00:26:46 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 1.6217
2022-07-08 00:27:19 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 1.5535
2022-07-08 00:27:52 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 1.6996
2022-07-08 00:28:25 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 1.7381
2022-07-08 00:28:58 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 1.3743
2022-07-08 00:29:33 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 1.5179
2022-07-08 00:30:05 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 1.4754
2022-07-08 00:30:38 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 1.5229
2022-07-08 00:31:12 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 1.4488
2022-07-08 00:31:45 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 1.4488
2022-07-08 00:32:18 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 1.5886
2022-07-08 00:32:51 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 1.3376
2022-07-08 00:33:24 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 1.1969
2022-07-08 00:33:57 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 1.0927
2022-07-08 00:34:30 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 1.5827
2022-07-08 00:35:04 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 1.7039
2022-07-08 00:35:38 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 1.7417
2022-07-08 00:36:11 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 1.5636
2022-07-08 00:36:44 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 1.4019
2022-07-08 00:37:18 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 1.5151
2022-07-08 00:37:51 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 1.5243
2022-07-08 00:38:25 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 1.3551
2022-07-08 00:38:58 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 1.4929
2022-07-08 00:39:30 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 1.5047
2022-07-08 00:40:04 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 1.6182
2022-07-08 00:40:38 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 1.4256
2022-07-08 00:41:10 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 1.5337
2022-07-08 00:41:44 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 1.5661
2022-07-08 00:42:17 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 1.3875
2022-07-08 00:42:51 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 1.4610
2022-07-08 00:43:24 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 1.6621
2022-07-08 00:43:58 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 1.5862
2022-07-08 00:44:32 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 1.3617
2022-07-08 00:45:04 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 1.6363
2022-07-08 00:45:37 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 1.6922
2022-07-08 00:46:09 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 1.6322
2022-07-08 00:46:10 - train: epoch 057, train_loss: 1.4810
2022-07-08 00:47:23 - eval: epoch: 057, acc1: 67.226%, acc5: 88.038%, test_loss: 1.3349, per_image_load_time: 2.350ms, per_image_inference_time: 0.267ms
2022-07-08 00:47:23 - until epoch: 057, best_acc1: 67.926%
2022-07-08 00:47:23 - epoch 058 lr: 0.010000
2022-07-08 00:48:02 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 1.4582
2022-07-08 00:48:34 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 1.3461
2022-07-08 00:49:07 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 1.5694
2022-07-08 00:49:40 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 1.4751
2022-07-08 00:50:13 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 1.4226
2022-07-08 00:50:47 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 1.6798
2022-07-08 00:51:20 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 1.4259
2022-07-08 00:51:53 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 1.4265
2022-07-08 00:52:26 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 1.3215
2022-07-08 00:53:00 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 1.5735
2022-07-08 00:53:34 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 1.2374
2022-07-08 00:54:07 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 1.3616
2022-07-08 00:54:41 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 1.5636
2022-07-08 00:55:14 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 1.4860
2022-07-08 00:55:48 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 1.4659
2022-07-08 00:56:21 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 1.4396
2022-07-08 00:56:54 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 1.7202
2022-07-08 00:57:27 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 1.4665
2022-07-08 00:58:00 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 1.4969
2022-07-08 00:58:34 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 1.5512
2022-07-08 00:59:06 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 1.2301
2022-07-08 00:59:40 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 1.2651
2022-07-08 01:00:13 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 1.4680
2022-07-08 01:00:47 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 1.4959
2022-07-08 01:01:20 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 1.6608
2022-07-08 01:01:54 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 1.3227
2022-07-08 01:02:27 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 1.6621
2022-07-08 01:03:00 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 1.3159
2022-07-08 01:03:34 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 1.3801
2022-07-08 01:04:06 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 1.5963
2022-07-08 01:04:41 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 1.2817
2022-07-08 01:05:13 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 1.3548
2022-07-08 01:05:47 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 1.4162
2022-07-08 01:06:21 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 1.4290
2022-07-08 01:06:55 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 1.4317
2022-07-08 01:07:27 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 1.4028
2022-07-08 01:08:01 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 1.3973
2022-07-08 01:08:34 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 1.6033
2022-07-08 01:09:07 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 1.5178
2022-07-08 01:09:41 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 1.5456
2022-07-08 01:10:14 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 1.5895
2022-07-08 01:10:48 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 1.3416
2022-07-08 01:11:21 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 1.7085
2022-07-08 01:11:54 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 1.3726
2022-07-08 01:12:28 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 1.4970
2022-07-08 01:13:01 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 1.3563
2022-07-08 01:13:35 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 1.4865
2022-07-08 01:14:08 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 1.6161
2022-07-08 01:14:41 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 1.4386
2022-07-08 01:15:13 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 1.4610
2022-07-08 01:15:14 - train: epoch 058, train_loss: 1.4770
2022-07-08 01:16:26 - eval: epoch: 058, acc1: 67.428%, acc5: 88.006%, test_loss: 1.3331, per_image_load_time: 2.400ms, per_image_inference_time: 0.243ms
2022-07-08 01:16:26 - until epoch: 058, best_acc1: 67.926%
2022-07-08 01:16:26 - epoch 059 lr: 0.010000
2022-07-08 01:17:05 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 1.6440
2022-07-08 01:17:37 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 1.3935
2022-07-08 01:18:10 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 1.4697
2022-07-08 01:18:43 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 1.6048
2022-07-08 01:19:16 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 1.7179
2022-07-08 01:19:48 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 1.3971
2022-07-08 01:20:21 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 1.4835
2022-07-08 01:20:54 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 1.5213
2022-07-08 01:21:28 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 1.4442
2022-07-08 01:21:59 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 1.4450
2022-07-08 01:22:33 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 1.7354
2022-07-08 01:23:05 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 1.1921
2022-07-08 01:23:39 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 1.6378
2022-07-08 01:24:12 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 1.6731
2022-07-08 01:24:45 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 1.5904
2022-07-08 01:25:19 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 1.5288
2022-07-08 01:25:52 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 1.4778
2022-07-08 01:26:25 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 1.4282
2022-07-08 01:27:00 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 1.5258
2022-07-08 01:27:32 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 1.4455
2022-07-08 01:28:06 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 1.7355
2022-07-08 01:28:38 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 1.6646
2022-07-08 01:29:12 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 1.4424
2022-07-08 01:29:45 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 1.6384
2022-07-08 01:30:18 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 1.4423
2022-07-08 01:30:51 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 1.4216
2022-07-08 01:31:25 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 1.4077
2022-07-08 01:31:58 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 1.7143
2022-07-08 01:32:31 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 1.4206
2022-07-08 01:33:04 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 1.9013
2022-07-08 01:33:37 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 1.4041
2022-07-08 01:34:11 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 1.4377
2022-07-08 01:34:44 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 1.5840
2022-07-08 01:35:17 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 1.8555
2022-07-08 01:35:51 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 1.3622
2022-07-08 01:36:24 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 1.4825
2022-07-08 01:36:58 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 1.3741
2022-07-08 01:37:31 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 1.5305
2022-07-08 01:38:04 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 1.4668
2022-07-08 01:38:38 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 1.7232
2022-07-08 01:39:11 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 1.5060
2022-07-08 01:39:44 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 1.5333
2022-07-08 01:40:18 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 1.6086
2022-07-08 01:40:52 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 1.7430
2022-07-08 01:41:25 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 1.6570
2022-07-08 01:41:58 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 1.5153
2022-07-08 01:42:31 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 1.4497
2022-07-08 01:43:05 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 1.4181
2022-07-08 01:43:39 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 1.6612
2022-07-08 01:44:10 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 1.6566
2022-07-08 01:44:11 - train: epoch 059, train_loss: 1.4768
2022-07-08 01:45:24 - eval: epoch: 059, acc1: 67.266%, acc5: 87.988%, test_loss: 1.3334, per_image_load_time: 1.691ms, per_image_inference_time: 0.271ms
2022-07-08 01:45:24 - until epoch: 059, best_acc1: 67.926%
2022-07-08 01:45:24 - epoch 060 lr: 0.010000
2022-07-08 01:46:02 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 1.3953
2022-07-08 01:46:36 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 1.5696
2022-07-08 01:47:08 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 1.5294
2022-07-08 01:47:40 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 1.5661
2022-07-08 01:48:13 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 1.5812
2022-07-08 01:48:47 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 1.5372
2022-07-08 01:49:20 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 1.5188
2022-07-08 01:49:52 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 1.6730
2022-07-08 01:50:26 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 1.2169
2022-07-08 01:50:59 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 1.1847
2022-07-08 01:51:32 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 1.2388
2022-07-08 01:52:06 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 1.3975
2022-07-08 01:52:39 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 1.2738
2022-07-08 01:53:12 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 1.4949
2022-07-08 01:53:45 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 1.5082
2022-07-08 01:54:19 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 1.4830
2022-07-08 01:54:51 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 1.4371
2022-07-08 01:55:25 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 1.4984
2022-07-08 01:55:58 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 1.5198
2022-07-08 01:56:31 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 1.3026
2022-07-08 01:57:05 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 1.5878
2022-07-08 01:57:38 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 1.5556
2022-07-08 01:58:12 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 1.2801
2022-07-08 01:58:45 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 1.4006
2022-07-08 01:59:19 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 1.4727
2022-07-08 01:59:52 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 1.5057
2022-07-08 02:00:25 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 1.4276
2022-07-08 02:00:59 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 1.3500
2022-07-08 02:01:32 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 1.6016
2022-07-08 02:02:05 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 1.6754
2022-07-08 02:02:39 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 1.5854
2022-07-08 02:03:12 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 1.4483
2022-07-08 02:03:46 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 1.3069
2022-07-08 02:04:19 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 1.6227
2022-07-08 02:04:52 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 1.5760
2022-07-08 02:05:26 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 1.4005
2022-07-08 02:05:59 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 1.5527
2022-07-08 02:06:33 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 1.4540
2022-07-08 02:07:05 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 1.8068
2022-07-08 02:07:39 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 1.5160
2022-07-08 02:08:12 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 1.6396
2022-07-08 02:08:45 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 1.4703
2022-07-08 02:09:19 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 1.5061
2022-07-08 02:09:52 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 1.5593
2022-07-08 02:10:25 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 1.4248
2022-07-08 02:10:58 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 1.3818
2022-07-08 02:11:31 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 1.6065
2022-07-08 02:12:05 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 1.2885
2022-07-08 02:12:39 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 1.4450
2022-07-08 02:13:10 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 1.6292
2022-07-08 02:13:11 - train: epoch 060, train_loss: 1.4738
2022-07-08 02:14:25 - eval: epoch: 060, acc1: 67.350%, acc5: 88.018%, test_loss: 1.3280, per_image_load_time: 2.541ms, per_image_inference_time: 0.275ms
2022-07-08 02:14:25 - until epoch: 060, best_acc1: 67.926%
2022-07-08 02:14:25 - epoch 061 lr: 0.001000
2022-07-08 02:15:03 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 1.2659
2022-07-08 02:15:37 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 1.4006
2022-07-08 02:16:09 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 1.1956
2022-07-08 02:16:42 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 1.6425
2022-07-08 02:17:15 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 1.3937
2022-07-08 02:17:48 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 1.4582
2022-07-08 02:18:21 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 1.0541
2022-07-08 02:18:54 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 1.4478
2022-07-08 02:19:28 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 1.2745
2022-07-08 02:20:01 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 1.1323
2022-07-08 02:20:34 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 1.1880
2022-07-08 02:21:07 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 1.3083
2022-07-08 02:21:41 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 1.2562
2022-07-08 02:22:14 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 1.2467
2022-07-08 02:22:47 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 1.3583
2022-07-08 02:23:20 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 1.1968
2022-07-08 02:23:53 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 1.3696
2022-07-08 02:24:27 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 1.3529
2022-07-08 02:25:00 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 1.4283
2022-07-08 02:25:33 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 1.2196
2022-07-08 02:26:05 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 1.7184
2022-07-08 02:26:40 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 1.1819
2022-07-08 02:27:13 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 1.2657
2022-07-08 02:27:47 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 1.0784
2022-07-08 02:28:19 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 1.2411
2022-07-08 02:28:52 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 1.4787
2022-07-08 02:29:26 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 1.4783
2022-07-08 02:29:59 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 1.2775
2022-07-08 02:30:33 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 1.4141
2022-07-08 02:31:06 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 1.1587
2022-07-08 02:31:40 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 1.4889
2022-07-08 02:32:13 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 1.3425
2022-07-08 02:32:47 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 1.2472
2022-07-08 02:33:21 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 1.1413
2022-07-08 02:33:53 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 1.3854
2022-07-08 02:34:28 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 1.3270
2022-07-08 02:35:01 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 1.4054
2022-07-08 02:35:34 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 1.3463
2022-07-08 02:36:07 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 1.2318
2022-07-08 02:36:41 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 1.3172
2022-07-08 02:37:14 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 1.5370
2022-07-08 02:37:47 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 1.1452
2022-07-08 02:38:21 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 1.3671
2022-07-08 02:38:54 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 1.3489
2022-07-08 02:39:27 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 1.2137
2022-07-08 02:40:01 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 1.3298
2022-07-08 02:40:34 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 1.2069
2022-07-08 02:41:08 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 1.2874
2022-07-08 02:41:41 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 1.2973
2022-07-08 02:42:13 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 1.3914
2022-07-08 02:42:14 - train: epoch 061, train_loss: 1.3039
2022-07-08 02:43:27 - eval: epoch: 061, acc1: 70.832%, acc5: 89.918%, test_loss: 1.1699, per_image_load_time: 2.132ms, per_image_inference_time: 0.261ms
2022-07-08 02:43:27 - until epoch: 061, best_acc1: 70.832%
2022-07-08 02:43:27 - epoch 062 lr: 0.001000
2022-07-08 02:44:05 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 1.3168
2022-07-08 02:44:39 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 1.4024
2022-07-08 02:45:12 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 1.2653
2022-07-08 02:45:44 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 1.1068
2022-07-08 02:46:17 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 1.1669
2022-07-08 02:46:50 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 1.2190
2022-07-08 02:47:22 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 1.5084
2022-07-08 02:47:56 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 1.2479
2022-07-08 02:48:29 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 1.2069
2022-07-08 02:49:02 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 1.4586
2022-07-08 02:49:35 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 1.1102
2022-07-08 02:50:08 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 1.5095
2022-07-08 02:50:42 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 1.3643
2022-07-08 02:51:15 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 1.2429
2022-07-08 02:51:49 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 1.3035
2022-07-08 02:52:21 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 1.3440
2022-07-08 02:52:54 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 1.3599
2022-07-08 02:53:27 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 1.2426
2022-07-08 02:54:01 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 1.2144
2022-07-08 02:54:35 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 1.1531
2022-07-08 02:55:09 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 1.3644
2022-07-08 02:55:42 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 1.1591
2022-07-08 02:56:15 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 1.2555
2022-07-08 02:56:48 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 1.1664
2022-07-08 02:57:21 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 1.3091
2022-07-08 02:57:54 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 1.1195
2022-07-08 02:58:27 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 1.2978
2022-07-08 02:59:01 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 1.3865
2022-07-08 02:59:34 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 1.3078
2022-07-08 03:00:07 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 1.4026
2022-07-08 03:00:40 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 1.3373
2022-07-08 03:01:14 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 1.0509
2022-07-08 03:01:47 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 1.3516
2022-07-08 03:02:21 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 1.3133
2022-07-08 03:02:53 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 1.3383
2022-07-08 03:03:27 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 1.2733
2022-07-08 03:04:00 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 1.2214
2022-07-08 03:04:33 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 1.2271
2022-07-08 03:05:07 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 1.2303
2022-07-08 03:05:40 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 1.0910
2022-07-08 03:06:13 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 1.2857
2022-07-08 03:06:47 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 1.1184
2022-07-08 03:07:20 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 1.2605
2022-07-08 03:07:53 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 1.2591
2022-07-08 03:08:27 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 1.1543
2022-07-08 03:08:59 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 0.9850
2022-07-08 03:09:33 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 1.2875
2022-07-08 03:10:07 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 1.1842
2022-07-08 03:10:40 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 1.1921
2022-07-08 03:11:12 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 1.3211
2022-07-08 03:11:13 - train: epoch 062, train_loss: 1.2588
2022-07-08 03:12:27 - eval: epoch: 062, acc1: 71.416%, acc5: 90.250%, test_loss: 1.1545, per_image_load_time: 2.493ms, per_image_inference_time: 0.263ms
2022-07-08 03:12:27 - until epoch: 062, best_acc1: 71.416%
2022-07-08 03:12:27 - epoch 063 lr: 0.001000
2022-07-08 03:13:04 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 1.2744
2022-07-08 03:13:37 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 1.0909
2022-07-08 03:14:10 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 1.3531
2022-07-08 03:14:43 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 1.2787
2022-07-08 03:15:15 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 1.1146
2022-07-08 03:15:47 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 1.3347
2022-07-08 03:16:21 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 1.2135
2022-07-08 03:16:53 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 1.2345
2022-07-08 03:17:26 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 1.2237
2022-07-08 03:18:00 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 1.4125
2022-07-08 03:18:33 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 1.1548
2022-07-08 03:19:05 - train: epoch 0063, iter [01200, 05004], lr: 0.001000, loss: 1.1242
2022-07-08 03:19:39 - train: epoch 0063, iter [01300, 05004], lr: 0.001000, loss: 1.2457
2022-07-08 03:20:12 - train: epoch 0063, iter [01400, 05004], lr: 0.001000, loss: 1.4985
2022-07-08 03:20:45 - train: epoch 0063, iter [01500, 05004], lr: 0.001000, loss: 1.2232
2022-07-08 03:21:18 - train: epoch 0063, iter [01600, 05004], lr: 0.001000, loss: 1.1696
2022-07-08 03:21:51 - train: epoch 0063, iter [01700, 05004], lr: 0.001000, loss: 1.0878
2022-07-08 03:22:25 - train: epoch 0063, iter [01800, 05004], lr: 0.001000, loss: 1.4205
2022-07-08 03:22:57 - train: epoch 0063, iter [01900, 05004], lr: 0.001000, loss: 1.3446
2022-07-08 03:23:31 - train: epoch 0063, iter [02000, 05004], lr: 0.001000, loss: 1.1622
2022-07-08 03:24:04 - train: epoch 0063, iter [02100, 05004], lr: 0.001000, loss: 1.1401
2022-07-08 03:24:38 - train: epoch 0063, iter [02200, 05004], lr: 0.001000, loss: 1.6096
2022-07-08 03:25:11 - train: epoch 0063, iter [02300, 05004], lr: 0.001000, loss: 1.3356
2022-07-08 03:25:44 - train: epoch 0063, iter [02400, 05004], lr: 0.001000, loss: 1.3789
2022-07-08 03:26:18 - train: epoch 0063, iter [02500, 05004], lr: 0.001000, loss: 1.2804
2022-07-08 03:26:51 - train: epoch 0063, iter [02600, 05004], lr: 0.001000, loss: 1.2208
2022-07-08 03:27:23 - train: epoch 0063, iter [02700, 05004], lr: 0.001000, loss: 1.3846
2022-07-08 03:27:56 - train: epoch 0063, iter [02800, 05004], lr: 0.001000, loss: 1.2356
2022-07-08 03:28:30 - train: epoch 0063, iter [02900, 05004], lr: 0.001000, loss: 1.2413
2022-07-08 03:29:02 - train: epoch 0063, iter [03000, 05004], lr: 0.001000, loss: 1.3095
2022-07-08 03:29:36 - train: epoch 0063, iter [03100, 05004], lr: 0.001000, loss: 1.5596
2022-07-08 03:30:08 - train: epoch 0063, iter [03200, 05004], lr: 0.001000, loss: 1.3823
2022-07-08 03:30:42 - train: epoch 0063, iter [03300, 05004], lr: 0.001000, loss: 1.2322
2022-07-08 03:31:14 - train: epoch 0063, iter [03400, 05004], lr: 0.001000, loss: 1.0066
2022-07-08 03:31:48 - train: epoch 0063, iter [03500, 05004], lr: 0.001000, loss: 1.4030
2022-07-08 03:32:21 - train: epoch 0063, iter [03600, 05004], lr: 0.001000, loss: 1.1751
2022-07-08 03:32:54 - train: epoch 0063, iter [03700, 05004], lr: 0.001000, loss: 1.3842
2022-07-08 03:33:28 - train: epoch 0063, iter [03800, 05004], lr: 0.001000, loss: 1.5132
2022-07-08 03:34:01 - train: epoch 0063, iter [03900, 05004], lr: 0.001000, loss: 1.0317
2022-07-08 03:34:34 - train: epoch 0063, iter [04000, 05004], lr: 0.001000, loss: 1.0539
2022-07-08 03:35:07 - train: epoch 0063, iter [04100, 05004], lr: 0.001000, loss: 1.3395
2022-07-08 03:35:40 - train: epoch 0063, iter [04200, 05004], lr: 0.001000, loss: 1.1027
2022-07-08 03:36:14 - train: epoch 0063, iter [04300, 05004], lr: 0.001000, loss: 1.3872
2022-07-08 03:36:47 - train: epoch 0063, iter [04400, 05004], lr: 0.001000, loss: 1.2244
2022-07-08 03:37:20 - train: epoch 0063, iter [04500, 05004], lr: 0.001000, loss: 1.1486
2022-07-08 03:37:53 - train: epoch 0063, iter [04600, 05004], lr: 0.001000, loss: 1.1607
2022-07-08 03:38:26 - train: epoch 0063, iter [04700, 05004], lr: 0.001000, loss: 1.1199
2022-07-08 03:38:59 - train: epoch 0063, iter [04800, 05004], lr: 0.001000, loss: 1.2551
2022-07-08 03:39:33 - train: epoch 0063, iter [04900, 05004], lr: 0.001000, loss: 1.2067
2022-07-08 03:40:04 - train: epoch 0063, iter [05000, 05004], lr: 0.001000, loss: 1.2325
2022-07-08 03:40:05 - train: epoch 063, train_loss: 1.2434
2022-07-08 03:41:18 - eval: epoch: 063, acc1: 71.648%, acc5: 90.336%, test_loss: 1.1465, per_image_load_time: 2.041ms, per_image_inference_time: 0.262ms
2022-07-08 03:41:18 - until epoch: 063, best_acc1: 71.648%
2022-07-08 03:41:18 - epoch 064 lr: 0.001000
2022-07-08 03:41:56 - train: epoch 0064, iter [00100, 05004], lr: 0.001000, loss: 1.2425
2022-07-08 03:42:29 - train: epoch 0064, iter [00200, 05004], lr: 0.001000, loss: 1.2990
2022-07-08 03:43:01 - train: epoch 0064, iter [00300, 05004], lr: 0.001000, loss: 1.0122
2022-07-08 03:43:34 - train: epoch 0064, iter [00400, 05004], lr: 0.001000, loss: 1.3352
2022-07-08 03:44:06 - train: epoch 0064, iter [00500, 05004], lr: 0.001000, loss: 1.1414
2022-07-08 03:44:39 - train: epoch 0064, iter [00600, 05004], lr: 0.001000, loss: 1.3849
2022-07-08 03:45:12 - train: epoch 0064, iter [00700, 05004], lr: 0.001000, loss: 1.3113
2022-07-08 03:45:45 - train: epoch 0064, iter [00800, 05004], lr: 0.001000, loss: 1.0900
2022-07-08 03:46:18 - train: epoch 0064, iter [00900, 05004], lr: 0.001000, loss: 1.2611
2022-07-08 03:46:51 - train: epoch 0064, iter [01000, 05004], lr: 0.001000, loss: 1.2661
2022-07-08 03:47:25 - train: epoch 0064, iter [01100, 05004], lr: 0.001000, loss: 1.1417
2022-07-08 03:47:58 - train: epoch 0064, iter [01200, 05004], lr: 0.001000, loss: 1.0665
2022-07-08 03:48:32 - train: epoch 0064, iter [01300, 05004], lr: 0.001000, loss: 1.2268
2022-07-08 03:49:04 - train: epoch 0064, iter [01400, 05004], lr: 0.001000, loss: 1.4912
2022-07-08 03:49:38 - train: epoch 0064, iter [01500, 05004], lr: 0.001000, loss: 1.2374
2022-07-08 03:50:10 - train: epoch 0064, iter [01600, 05004], lr: 0.001000, loss: 1.1770
2022-07-08 03:50:43 - train: epoch 0064, iter [01700, 05004], lr: 0.001000, loss: 1.1312
2022-07-08 03:51:17 - train: epoch 0064, iter [01800, 05004], lr: 0.001000, loss: 1.0947
2022-07-08 03:51:49 - train: epoch 0064, iter [01900, 05004], lr: 0.001000, loss: 1.1699
2022-07-08 03:52:23 - train: epoch 0064, iter [02000, 05004], lr: 0.001000, loss: 1.1562
2022-07-08 03:52:56 - train: epoch 0064, iter [02100, 05004], lr: 0.001000, loss: 1.2908
2022-07-08 03:53:29 - train: epoch 0064, iter [02200, 05004], lr: 0.001000, loss: 1.2458
2022-07-08 03:54:03 - train: epoch 0064, iter [02300, 05004], lr: 0.001000, loss: 1.3590
2022-07-08 03:54:36 - train: epoch 0064, iter [02400, 05004], lr: 0.001000, loss: 1.1962
2022-07-08 03:55:09 - train: epoch 0064, iter [02500, 05004], lr: 0.001000, loss: 1.1074
2022-07-08 03:55:42 - train: epoch 0064, iter [02600, 05004], lr: 0.001000, loss: 1.1493
2022-07-08 03:56:16 - train: epoch 0064, iter [02700, 05004], lr: 0.001000, loss: 1.2796
2022-07-08 03:56:50 - train: epoch 0064, iter [02800, 05004], lr: 0.001000, loss: 1.0632
2022-07-08 03:57:22 - train: epoch 0064, iter [02900, 05004], lr: 0.001000, loss: 1.4148
2022-07-08 03:57:56 - train: epoch 0064, iter [03000, 05004], lr: 0.001000, loss: 1.2612
2022-07-08 03:58:29 - train: epoch 0064, iter [03100, 05004], lr: 0.001000, loss: 1.1859
2022-07-08 03:59:03 - train: epoch 0064, iter [03200, 05004], lr: 0.001000, loss: 1.2285
2022-07-08 03:59:36 - train: epoch 0064, iter [03300, 05004], lr: 0.001000, loss: 1.1571
2022-07-08 04:00:10 - train: epoch 0064, iter [03400, 05004], lr: 0.001000, loss: 1.3758
2022-07-08 04:00:43 - train: epoch 0064, iter [03500, 05004], lr: 0.001000, loss: 1.1897
2022-07-08 04:01:16 - train: epoch 0064, iter [03600, 05004], lr: 0.001000, loss: 1.1981
2022-07-08 04:01:49 - train: epoch 0064, iter [03700, 05004], lr: 0.001000, loss: 0.9111
2022-07-08 04:02:23 - train: epoch 0064, iter [03800, 05004], lr: 0.001000, loss: 1.3923
2022-07-08 04:02:55 - train: epoch 0064, iter [03900, 05004], lr: 0.001000, loss: 1.0874
2022-07-08 04:03:29 - train: epoch 0064, iter [04000, 05004], lr: 0.001000, loss: 1.0640
2022-07-08 04:04:02 - train: epoch 0064, iter [04100, 05004], lr: 0.001000, loss: 1.3174
2022-07-08 04:04:35 - train: epoch 0064, iter [04200, 05004], lr: 0.001000, loss: 1.1642
2022-07-08 04:05:08 - train: epoch 0064, iter [04300, 05004], lr: 0.001000, loss: 1.3795
2022-07-08 04:05:42 - train: epoch 0064, iter [04400, 05004], lr: 0.001000, loss: 1.1907
2022-07-08 04:06:15 - train: epoch 0064, iter [04500, 05004], lr: 0.001000, loss: 1.1012
2022-07-08 04:06:48 - train: epoch 0064, iter [04600, 05004], lr: 0.001000, loss: 1.4490
2022-07-08 04:07:22 - train: epoch 0064, iter [04700, 05004], lr: 0.001000, loss: 1.5629
2022-07-08 04:07:55 - train: epoch 0064, iter [04800, 05004], lr: 0.001000, loss: 1.1245
2022-07-08 04:08:29 - train: epoch 0064, iter [04900, 05004], lr: 0.001000, loss: 1.4018
2022-07-08 04:09:01 - train: epoch 0064, iter [05000, 05004], lr: 0.001000, loss: 1.1031
2022-07-08 04:09:01 - train: epoch 064, train_loss: 1.2326
2022-07-08 04:10:14 - eval: epoch: 064, acc1: 71.656%, acc5: 90.324%, test_loss: 1.1398, per_image_load_time: 1.217ms, per_image_inference_time: 0.258ms
2022-07-08 04:10:14 - until epoch: 064, best_acc1: 71.656%
2022-07-08 04:10:14 - epoch 065 lr: 0.001000
2022-07-08 04:10:53 - train: epoch 0065, iter [00100, 05004], lr: 0.001000, loss: 1.3618
2022-07-08 04:11:26 - train: epoch 0065, iter [00200, 05004], lr: 0.001000, loss: 1.2238
2022-07-08 04:11:58 - train: epoch 0065, iter [00300, 05004], lr: 0.001000, loss: 1.2694
2022-07-08 04:12:31 - train: epoch 0065, iter [00400, 05004], lr: 0.001000, loss: 1.3486
2022-07-08 04:13:04 - train: epoch 0065, iter [00500, 05004], lr: 0.001000, loss: 1.1745
2022-07-08 04:13:37 - train: epoch 0065, iter [00600, 05004], lr: 0.001000, loss: 1.2743
2022-07-08 04:14:10 - train: epoch 0065, iter [00700, 05004], lr: 0.001000, loss: 1.1588
2022-07-08 04:14:43 - train: epoch 0065, iter [00800, 05004], lr: 0.001000, loss: 1.2086
2022-07-08 04:15:17 - train: epoch 0065, iter [00900, 05004], lr: 0.001000, loss: 1.1696
2022-07-08 04:15:50 - train: epoch 0065, iter [01000, 05004], lr: 0.001000, loss: 1.1820
2022-07-08 04:16:23 - train: epoch 0065, iter [01100, 05004], lr: 0.001000, loss: 1.1727
2022-07-08 04:16:57 - train: epoch 0065, iter [01200, 05004], lr: 0.001000, loss: 1.4800
2022-07-08 04:17:30 - train: epoch 0065, iter [01300, 05004], lr: 0.001000, loss: 1.2291
2022-07-08 04:18:03 - train: epoch 0065, iter [01400, 05004], lr: 0.001000, loss: 1.0601
2022-07-08 04:18:36 - train: epoch 0065, iter [01500, 05004], lr: 0.001000, loss: 1.1905
2022-07-08 04:19:09 - train: epoch 0065, iter [01600, 05004], lr: 0.001000, loss: 1.2690
2022-07-08 04:19:42 - train: epoch 0065, iter [01700, 05004], lr: 0.001000, loss: 1.2553
2022-07-08 04:20:15 - train: epoch 0065, iter [01800, 05004], lr: 0.001000, loss: 1.1536
2022-07-08 04:20:49 - train: epoch 0065, iter [01900, 05004], lr: 0.001000, loss: 1.1060
2022-07-08 04:21:22 - train: epoch 0065, iter [02000, 05004], lr: 0.001000, loss: 1.1068
2022-07-08 04:21:56 - train: epoch 0065, iter [02100, 05004], lr: 0.001000, loss: 1.2102
2022-07-08 04:22:29 - train: epoch 0065, iter [02200, 05004], lr: 0.001000, loss: 1.3313
2022-07-08 04:23:03 - train: epoch 0065, iter [02300, 05004], lr: 0.001000, loss: 1.1193
2022-07-08 04:23:36 - train: epoch 0065, iter [02400, 05004], lr: 0.001000, loss: 1.1655
2022-07-08 04:24:09 - train: epoch 0065, iter [02500, 05004], lr: 0.001000, loss: 1.2430
2022-07-08 04:24:43 - train: epoch 0065, iter [02600, 05004], lr: 0.001000, loss: 1.2984
2022-07-08 04:25:17 - train: epoch 0065, iter [02700, 05004], lr: 0.001000, loss: 1.2174
2022-07-08 04:25:49 - train: epoch 0065, iter [02800, 05004], lr: 0.001000, loss: 1.0708
2022-07-08 04:26:23 - train: epoch 0065, iter [02900, 05004], lr: 0.001000, loss: 1.2508
2022-07-08 04:26:56 - train: epoch 0065, iter [03000, 05004], lr: 0.001000, loss: 1.1051
2022-07-08 04:27:30 - train: epoch 0065, iter [03100, 05004], lr: 0.001000, loss: 1.2325
2022-07-08 04:28:03 - train: epoch 0065, iter [03200, 05004], lr: 0.001000, loss: 1.3630
2022-07-08 04:28:37 - train: epoch 0065, iter [03300, 05004], lr: 0.001000, loss: 1.2174
2022-07-08 04:29:10 - train: epoch 0065, iter [03400, 05004], lr: 0.001000, loss: 1.1339
2022-07-08 04:29:43 - train: epoch 0065, iter [03500, 05004], lr: 0.001000, loss: 1.4893
2022-07-08 04:30:16 - train: epoch 0065, iter [03600, 05004], lr: 0.001000, loss: 1.3003
2022-07-08 04:30:49 - train: epoch 0065, iter [03700, 05004], lr: 0.001000, loss: 1.1738
2022-07-08 04:31:22 - train: epoch 0065, iter [03800, 05004], lr: 0.001000, loss: 1.0626
2022-07-08 04:31:55 - train: epoch 0065, iter [03900, 05004], lr: 0.001000, loss: 1.3255
2022-07-08 04:32:28 - train: epoch 0065, iter [04000, 05004], lr: 0.001000, loss: 1.2187
2022-07-08 04:33:01 - train: epoch 0065, iter [04100, 05004], lr: 0.001000, loss: 1.0774
2022-07-08 04:33:35 - train: epoch 0065, iter [04200, 05004], lr: 0.001000, loss: 1.2483
2022-07-08 04:34:08 - train: epoch 0065, iter [04300, 05004], lr: 0.001000, loss: 1.1513
2022-07-08 04:34:42 - train: epoch 0065, iter [04400, 05004], lr: 0.001000, loss: 1.1711
2022-07-08 04:35:15 - train: epoch 0065, iter [04500, 05004], lr: 0.001000, loss: 1.1752
2022-07-08 04:35:48 - train: epoch 0065, iter [04600, 05004], lr: 0.001000, loss: 1.2398
2022-07-08 04:36:21 - train: epoch 0065, iter [04700, 05004], lr: 0.001000, loss: 1.2969
2022-07-08 04:36:55 - train: epoch 0065, iter [04800, 05004], lr: 0.001000, loss: 0.9278
2022-07-08 04:37:29 - train: epoch 0065, iter [04900, 05004], lr: 0.001000, loss: 1.0562
2022-07-08 04:38:00 - train: epoch 0065, iter [05000, 05004], lr: 0.001000, loss: 1.3166
2022-07-08 04:38:01 - train: epoch 065, train_loss: 1.2225
2022-07-08 04:39:14 - eval: epoch: 065, acc1: 71.676%, acc5: 90.434%, test_loss: 1.1386, per_image_load_time: 2.362ms, per_image_inference_time: 0.238ms
2022-07-08 04:39:14 - until epoch: 065, best_acc1: 71.676%
2022-07-08 04:39:14 - epoch 066 lr: 0.001000
2022-07-08 04:39:52 - train: epoch 0066, iter [00100, 05004], lr: 0.001000, loss: 1.1737
2022-07-08 04:40:25 - train: epoch 0066, iter [00200, 05004], lr: 0.001000, loss: 1.3867
2022-07-08 04:40:59 - train: epoch 0066, iter [00300, 05004], lr: 0.001000, loss: 1.0631
2022-07-08 04:41:31 - train: epoch 0066, iter [00400, 05004], lr: 0.001000, loss: 1.0412
2022-07-08 04:42:05 - train: epoch 0066, iter [00500, 05004], lr: 0.001000, loss: 1.2664
2022-07-08 04:42:37 - train: epoch 0066, iter [00600, 05004], lr: 0.001000, loss: 1.1744
2022-07-08 04:43:11 - train: epoch 0066, iter [00700, 05004], lr: 0.001000, loss: 1.2380
2022-07-08 04:43:43 - train: epoch 0066, iter [00800, 05004], lr: 0.001000, loss: 1.4784
2022-07-08 04:44:16 - train: epoch 0066, iter [00900, 05004], lr: 0.001000, loss: 1.3173
2022-07-08 04:44:49 - train: epoch 0066, iter [01000, 05004], lr: 0.001000, loss: 1.3487
2022-07-08 04:45:22 - train: epoch 0066, iter [01100, 05004], lr: 0.001000, loss: 1.2941
2022-07-08 04:45:55 - train: epoch 0066, iter [01200, 05004], lr: 0.001000, loss: 1.3282
2022-07-08 04:46:29 - train: epoch 0066, iter [01300, 05004], lr: 0.001000, loss: 1.3126
2022-07-08 04:47:02 - train: epoch 0066, iter [01400, 05004], lr: 0.001000, loss: 1.0417
2022-07-08 04:47:35 - train: epoch 0066, iter [01500, 05004], lr: 0.001000, loss: 1.2578
2022-07-08 04:48:09 - train: epoch 0066, iter [01600, 05004], lr: 0.001000, loss: 1.1991
2022-07-08 04:48:43 - train: epoch 0066, iter [01700, 05004], lr: 0.001000, loss: 1.1370
2022-07-08 04:49:16 - train: epoch 0066, iter [01800, 05004], lr: 0.001000, loss: 1.0475
2022-07-08 04:49:50 - train: epoch 0066, iter [01900, 05004], lr: 0.001000, loss: 1.4556
2022-07-08 04:50:23 - train: epoch 0066, iter [02000, 05004], lr: 0.001000, loss: 1.2802
2022-07-08 04:50:55 - train: epoch 0066, iter [02100, 05004], lr: 0.001000, loss: 1.2405
2022-07-08 04:51:29 - train: epoch 0066, iter [02200, 05004], lr: 0.001000, loss: 1.1809
2022-07-08 04:52:02 - train: epoch 0066, iter [02300, 05004], lr: 0.001000, loss: 1.3952
2022-07-08 04:52:35 - train: epoch 0066, iter [02400, 05004], lr: 0.001000, loss: 1.1544
2022-07-08 04:53:08 - train: epoch 0066, iter [02500, 05004], lr: 0.001000, loss: 1.2133
2022-07-08 04:53:41 - train: epoch 0066, iter [02600, 05004], lr: 0.001000, loss: 1.0891
2022-07-08 04:54:15 - train: epoch 0066, iter [02700, 05004], lr: 0.001000, loss: 1.3728
2022-07-08 04:54:48 - train: epoch 0066, iter [02800, 05004], lr: 0.001000, loss: 1.3510
2022-07-08 04:55:22 - train: epoch 0066, iter [02900, 05004], lr: 0.001000, loss: 1.1557
2022-07-08 04:55:55 - train: epoch 0066, iter [03000, 05004], lr: 0.001000, loss: 1.1452
2022-07-08 04:56:29 - train: epoch 0066, iter [03100, 05004], lr: 0.001000, loss: 1.3474
2022-07-08 04:57:02 - train: epoch 0066, iter [03200, 05004], lr: 0.001000, loss: 1.0603
2022-07-08 04:57:35 - train: epoch 0066, iter [03300, 05004], lr: 0.001000, loss: 1.1570
2022-07-08 04:58:08 - train: epoch 0066, iter [03400, 05004], lr: 0.001000, loss: 1.4586
2022-07-08 04:58:42 - train: epoch 0066, iter [03500, 05004], lr: 0.001000, loss: 1.2570
2022-07-08 04:59:15 - train: epoch 0066, iter [03600, 05004], lr: 0.001000, loss: 1.3035
2022-07-08 04:59:48 - train: epoch 0066, iter [03700, 05004], lr: 0.001000, loss: 1.1731
2022-07-08 05:00:22 - train: epoch 0066, iter [03800, 05004], lr: 0.001000, loss: 1.0807
2022-07-08 05:00:55 - train: epoch 0066, iter [03900, 05004], lr: 0.001000, loss: 1.0449
2022-07-08 05:01:28 - train: epoch 0066, iter [04000, 05004], lr: 0.001000, loss: 1.3849
2022-07-08 05:02:01 - train: epoch 0066, iter [04100, 05004], lr: 0.001000, loss: 1.0576
2022-07-08 05:02:34 - train: epoch 0066, iter [04200, 05004], lr: 0.001000, loss: 1.0629
2022-07-08 05:03:08 - train: epoch 0066, iter [04300, 05004], lr: 0.001000, loss: 1.0657
2022-07-08 05:03:41 - train: epoch 0066, iter [04400, 05004], lr: 0.001000, loss: 1.2302
2022-07-08 05:04:14 - train: epoch 0066, iter [04500, 05004], lr: 0.001000, loss: 1.1592
2022-07-08 05:04:48 - train: epoch 0066, iter [04600, 05004], lr: 0.001000, loss: 1.3660
2022-07-08 05:05:21 - train: epoch 0066, iter [04700, 05004], lr: 0.001000, loss: 1.0807
2022-07-08 05:05:55 - train: epoch 0066, iter [04800, 05004], lr: 0.001000, loss: 1.1741
2022-07-08 05:06:29 - train: epoch 0066, iter [04900, 05004], lr: 0.001000, loss: 1.2617
2022-07-08 05:07:00 - train: epoch 0066, iter [05000, 05004], lr: 0.001000, loss: 1.1255
2022-07-08 05:07:01 - train: epoch 066, train_loss: 1.2149
2022-07-08 05:08:14 - eval: epoch: 066, acc1: 71.834%, acc5: 90.480%, test_loss: 1.1320, per_image_load_time: 2.569ms, per_image_inference_time: 0.270ms
2022-07-08 05:08:14 - until epoch: 066, best_acc1: 71.834%
2022-07-08 05:08:14 - epoch 067 lr: 0.001000
2022-07-08 05:08:52 - train: epoch 0067, iter [00100, 05004], lr: 0.001000, loss: 1.1959
2022-07-08 05:09:26 - train: epoch 0067, iter [00200, 05004], lr: 0.001000, loss: 1.1292
2022-07-08 05:09:59 - train: epoch 0067, iter [00300, 05004], lr: 0.001000, loss: 1.4721
2022-07-08 05:10:31 - train: epoch 0067, iter [00400, 05004], lr: 0.001000, loss: 1.2845
2022-07-08 05:11:05 - train: epoch 0067, iter [00500, 05004], lr: 0.001000, loss: 1.1322
2022-07-08 05:11:38 - train: epoch 0067, iter [00600, 05004], lr: 0.001000, loss: 1.1405
2022-07-08 05:12:12 - train: epoch 0067, iter [00700, 05004], lr: 0.001000, loss: 1.3269
2022-07-08 05:12:45 - train: epoch 0067, iter [00800, 05004], lr: 0.001000, loss: 1.2681
2022-07-08 05:13:19 - train: epoch 0067, iter [00900, 05004], lr: 0.001000, loss: 1.3049
2022-07-08 05:13:51 - train: epoch 0067, iter [01000, 05004], lr: 0.001000, loss: 1.0895
2022-07-08 05:14:25 - train: epoch 0067, iter [01100, 05004], lr: 0.001000, loss: 1.2218
2022-07-08 05:14:58 - train: epoch 0067, iter [01200, 05004], lr: 0.001000, loss: 1.1939
2022-07-08 05:15:32 - train: epoch 0067, iter [01300, 05004], lr: 0.001000, loss: 1.4063
2022-07-08 05:16:06 - train: epoch 0067, iter [01400, 05004], lr: 0.001000, loss: 1.2244
2022-07-08 05:16:39 - train: epoch 0067, iter [01500, 05004], lr: 0.001000, loss: 1.2105
2022-07-08 05:17:12 - train: epoch 0067, iter [01600, 05004], lr: 0.001000, loss: 1.2087
2022-07-08 05:17:46 - train: epoch 0067, iter [01700, 05004], lr: 0.001000, loss: 1.0629
2022-07-08 05:18:19 - train: epoch 0067, iter [01800, 05004], lr: 0.001000, loss: 1.3716
2022-07-08 05:18:52 - train: epoch 0067, iter [01900, 05004], lr: 0.001000, loss: 1.1515
2022-07-08 05:19:26 - train: epoch 0067, iter [02000, 05004], lr: 0.001000, loss: 1.3999
2022-07-08 05:19:59 - train: epoch 0067, iter [02100, 05004], lr: 0.001000, loss: 1.0575
2022-07-08 05:20:32 - train: epoch 0067, iter [02200, 05004], lr: 0.001000, loss: 1.2958
2022-07-08 05:21:06 - train: epoch 0067, iter [02300, 05004], lr: 0.001000, loss: 1.2248
2022-07-08 05:21:40 - train: epoch 0067, iter [02400, 05004], lr: 0.001000, loss: 1.1738
2022-07-08 05:22:13 - train: epoch 0067, iter [02500, 05004], lr: 0.001000, loss: 1.1385
2022-07-08 05:22:46 - train: epoch 0067, iter [02600, 05004], lr: 0.001000, loss: 1.0930
2022-07-08 05:23:19 - train: epoch 0067, iter [02700, 05004], lr: 0.001000, loss: 1.1001
2022-07-08 05:23:54 - train: epoch 0067, iter [02800, 05004], lr: 0.001000, loss: 1.3639
2022-07-08 05:24:26 - train: epoch 0067, iter [02900, 05004], lr: 0.001000, loss: 1.2654
2022-07-08 05:24:59 - train: epoch 0067, iter [03000, 05004], lr: 0.001000, loss: 1.1257
2022-07-08 05:25:33 - train: epoch 0067, iter [03100, 05004], lr: 0.001000, loss: 1.0375
2022-07-08 05:26:07 - train: epoch 0067, iter [03200, 05004], lr: 0.001000, loss: 1.2921
2022-07-08 05:26:40 - train: epoch 0067, iter [03300, 05004], lr: 0.001000, loss: 1.0386
2022-07-08 05:27:14 - train: epoch 0067, iter [03400, 05004], lr: 0.001000, loss: 1.1780
2022-07-08 05:27:47 - train: epoch 0067, iter [03500, 05004], lr: 0.001000, loss: 1.0330
2022-07-08 05:28:21 - train: epoch 0067, iter [03600, 05004], lr: 0.001000, loss: 1.1943
2022-07-08 05:28:54 - train: epoch 0067, iter [03700, 05004], lr: 0.001000, loss: 1.3871
2022-07-08 05:29:27 - train: epoch 0067, iter [03800, 05004], lr: 0.001000, loss: 1.1790
2022-07-08 05:30:01 - train: epoch 0067, iter [03900, 05004], lr: 0.001000, loss: 1.2480
2022-07-08 05:30:34 - train: epoch 0067, iter [04000, 05004], lr: 0.001000, loss: 1.3341
2022-07-08 05:31:07 - train: epoch 0067, iter [04100, 05004], lr: 0.001000, loss: 1.3764
2022-07-08 05:31:41 - train: epoch 0067, iter [04200, 05004], lr: 0.001000, loss: 1.4445
2022-07-08 05:32:15 - train: epoch 0067, iter [04300, 05004], lr: 0.001000, loss: 1.0838
2022-07-08 05:32:48 - train: epoch 0067, iter [04400, 05004], lr: 0.001000, loss: 1.2008
2022-07-08 05:33:22 - train: epoch 0067, iter [04500, 05004], lr: 0.001000, loss: 1.1400
2022-07-08 05:33:55 - train: epoch 0067, iter [04600, 05004], lr: 0.001000, loss: 0.9458
2022-07-08 05:34:30 - train: epoch 0067, iter [04700, 05004], lr: 0.001000, loss: 1.2037
2022-07-08 05:35:02 - train: epoch 0067, iter [04800, 05004], lr: 0.001000, loss: 0.9510
2022-07-08 05:35:36 - train: epoch 0067, iter [04900, 05004], lr: 0.001000, loss: 1.2060
2022-07-08 05:36:08 - train: epoch 0067, iter [05000, 05004], lr: 0.001000, loss: 1.2548
2022-07-08 05:36:09 - train: epoch 067, train_loss: 1.2096
2022-07-08 05:37:22 - eval: epoch: 067, acc1: 71.816%, acc5: 90.510%, test_loss: 1.1323, per_image_load_time: 2.085ms, per_image_inference_time: 0.262ms
2022-07-08 05:37:23 - until epoch: 067, best_acc1: 71.834%
2022-07-08 05:37:23 - epoch 068 lr: 0.001000
2022-07-08 05:38:01 - train: epoch 0068, iter [00100, 05004], lr: 0.001000, loss: 1.1462
2022-07-08 05:38:35 - train: epoch 0068, iter [00200, 05004], lr: 0.001000, loss: 1.1820
2022-07-08 05:39:07 - train: epoch 0068, iter [00300, 05004], lr: 0.001000, loss: 1.2718
2022-07-08 05:39:40 - train: epoch 0068, iter [00400, 05004], lr: 0.001000, loss: 1.1916
2022-07-08 05:40:13 - train: epoch 0068, iter [00500, 05004], lr: 0.001000, loss: 1.1598
2022-07-08 05:40:46 - train: epoch 0068, iter [00600, 05004], lr: 0.001000, loss: 1.2580
2022-07-08 05:41:19 - train: epoch 0068, iter [00700, 05004], lr: 0.001000, loss: 1.5184
2022-07-08 05:41:53 - train: epoch 0068, iter [00800, 05004], lr: 0.001000, loss: 1.1618
2022-07-08 05:42:26 - train: epoch 0068, iter [00900, 05004], lr: 0.001000, loss: 1.0697
2022-07-08 05:42:59 - train: epoch 0068, iter [01000, 05004], lr: 0.001000, loss: 1.1918
2022-07-08 05:43:33 - train: epoch 0068, iter [01100, 05004], lr: 0.001000, loss: 1.3897
2022-07-08 05:44:06 - train: epoch 0068, iter [01200, 05004], lr: 0.001000, loss: 1.1361
2022-07-08 05:44:39 - train: epoch 0068, iter [01300, 05004], lr: 0.001000, loss: 1.0597
2022-07-08 05:45:13 - train: epoch 0068, iter [01400, 05004], lr: 0.001000, loss: 1.2052
2022-07-08 05:45:45 - train: epoch 0068, iter [01500, 05004], lr: 0.001000, loss: 1.3226
2022-07-08 05:46:19 - train: epoch 0068, iter [01600, 05004], lr: 0.001000, loss: 1.2984
2022-07-08 05:46:52 - train: epoch 0068, iter [01700, 05004], lr: 0.001000, loss: 1.3621
2022-07-08 05:47:26 - train: epoch 0068, iter [01800, 05004], lr: 0.001000, loss: 1.3174
2022-07-08 05:47:58 - train: epoch 0068, iter [01900, 05004], lr: 0.001000, loss: 1.2842
2022-07-08 05:48:32 - train: epoch 0068, iter [02000, 05004], lr: 0.001000, loss: 1.1330
2022-07-08 05:49:06 - train: epoch 0068, iter [02100, 05004], lr: 0.001000, loss: 1.2040
2022-07-08 05:49:39 - train: epoch 0068, iter [02200, 05004], lr: 0.001000, loss: 1.2138
2022-07-08 05:50:13 - train: epoch 0068, iter [02300, 05004], lr: 0.001000, loss: 1.0682
2022-07-08 05:50:46 - train: epoch 0068, iter [02400, 05004], lr: 0.001000, loss: 1.3239
2022-07-08 05:51:20 - train: epoch 0068, iter [02500, 05004], lr: 0.001000, loss: 1.1584
2022-07-08 05:51:53 - train: epoch 0068, iter [02600, 05004], lr: 0.001000, loss: 1.2547
2022-07-08 05:52:26 - train: epoch 0068, iter [02700, 05004], lr: 0.001000, loss: 1.1593
2022-07-08 05:53:00 - train: epoch 0068, iter [02800, 05004], lr: 0.001000, loss: 1.3955
2022-07-08 05:53:34 - train: epoch 0068, iter [02900, 05004], lr: 0.001000, loss: 1.3513
2022-07-08 05:54:07 - train: epoch 0068, iter [03000, 05004], lr: 0.001000, loss: 1.3973
2022-07-08 05:54:41 - train: epoch 0068, iter [03100, 05004], lr: 0.001000, loss: 1.1058
2022-07-08 05:55:14 - train: epoch 0068, iter [03200, 05004], lr: 0.001000, loss: 1.3510
2022-07-08 05:55:47 - train: epoch 0068, iter [03300, 05004], lr: 0.001000, loss: 1.2113
2022-07-08 05:56:20 - train: epoch 0068, iter [03400, 05004], lr: 0.001000, loss: 1.1276
2022-07-08 05:56:54 - train: epoch 0068, iter [03500, 05004], lr: 0.001000, loss: 1.2024
2022-07-08 05:57:26 - train: epoch 0068, iter [03600, 05004], lr: 0.001000, loss: 1.0837
2022-07-08 05:58:00 - train: epoch 0068, iter [03700, 05004], lr: 0.001000, loss: 1.2477
2022-07-08 05:58:33 - train: epoch 0068, iter [03800, 05004], lr: 0.001000, loss: 1.3438
2022-07-08 05:59:07 - train: epoch 0068, iter [03900, 05004], lr: 0.001000, loss: 1.2778
2022-07-08 05:59:40 - train: epoch 0068, iter [04000, 05004], lr: 0.001000, loss: 1.2135
2022-07-08 06:00:13 - train: epoch 0068, iter [04100, 05004], lr: 0.001000, loss: 1.0570
2022-07-08 06:00:47 - train: epoch 0068, iter [04200, 05004], lr: 0.001000, loss: 1.4514
2022-07-08 06:01:21 - train: epoch 0068, iter [04300, 05004], lr: 0.001000, loss: 1.3605
2022-07-08 06:01:54 - train: epoch 0068, iter [04400, 05004], lr: 0.001000, loss: 1.0963
2022-07-08 06:02:27 - train: epoch 0068, iter [04500, 05004], lr: 0.001000, loss: 1.3104
2022-07-08 06:03:01 - train: epoch 0068, iter [04600, 05004], lr: 0.001000, loss: 1.3514
2022-07-08 06:03:34 - train: epoch 0068, iter [04700, 05004], lr: 0.001000, loss: 1.3935
2022-07-08 06:04:07 - train: epoch 0068, iter [04800, 05004], lr: 0.001000, loss: 1.3788
2022-07-08 06:04:42 - train: epoch 0068, iter [04900, 05004], lr: 0.001000, loss: 1.3431
2022-07-08 06:05:14 - train: epoch 0068, iter [05000, 05004], lr: 0.001000, loss: 1.0446
2022-07-08 06:05:14 - train: epoch 068, train_loss: 1.2038
2022-07-08 06:06:28 - eval: epoch: 068, acc1: 71.952%, acc5: 90.498%, test_loss: 1.1300, per_image_load_time: 2.575ms, per_image_inference_time: 0.260ms
2022-07-08 06:06:28 - until epoch: 068, best_acc1: 71.952%
2022-07-08 06:06:28 - epoch 069 lr: 0.001000
2022-07-08 06:07:06 - train: epoch 0069, iter [00100, 05004], lr: 0.001000, loss: 1.4066
2022-07-08 06:07:40 - train: epoch 0069, iter [00200, 05004], lr: 0.001000, loss: 1.4174
2022-07-08 06:08:13 - train: epoch 0069, iter [00300, 05004], lr: 0.001000, loss: 1.3345
2022-07-08 06:08:44 - train: epoch 0069, iter [00400, 05004], lr: 0.001000, loss: 1.1124
2022-07-08 06:09:17 - train: epoch 0069, iter [00500, 05004], lr: 0.001000, loss: 1.0810
2022-07-08 06:09:50 - train: epoch 0069, iter [00600, 05004], lr: 0.001000, loss: 1.0562
2022-07-08 06:10:23 - train: epoch 0069, iter [00700, 05004], lr: 0.001000, loss: 1.1486
2022-07-08 06:10:55 - train: epoch 0069, iter [00800, 05004], lr: 0.001000, loss: 1.2373
2022-07-08 06:11:29 - train: epoch 0069, iter [00900, 05004], lr: 0.001000, loss: 1.1205
2022-07-08 06:12:02 - train: epoch 0069, iter [01000, 05004], lr: 0.001000, loss: 1.2006
2022-07-08 06:12:35 - train: epoch 0069, iter [01100, 05004], lr: 0.001000, loss: 1.1564
2022-07-08 06:13:09 - train: epoch 0069, iter [01200, 05004], lr: 0.001000, loss: 1.1733
2022-07-08 06:13:41 - train: epoch 0069, iter [01300, 05004], lr: 0.001000, loss: 1.3896
2022-07-08 06:14:15 - train: epoch 0069, iter [01400, 05004], lr: 0.001000, loss: 1.2467
2022-07-08 06:14:48 - train: epoch 0069, iter [01500, 05004], lr: 0.001000, loss: 1.2323
2022-07-08 06:15:21 - train: epoch 0069, iter [01600, 05004], lr: 0.001000, loss: 1.3353
2022-07-08 06:15:55 - train: epoch 0069, iter [01700, 05004], lr: 0.001000, loss: 1.1369
2022-07-08 06:16:28 - train: epoch 0069, iter [01800, 05004], lr: 0.001000, loss: 1.0561
2022-07-08 06:17:01 - train: epoch 0069, iter [01900, 05004], lr: 0.001000, loss: 1.1523
2022-07-08 06:17:34 - train: epoch 0069, iter [02000, 05004], lr: 0.001000, loss: 1.0300
2022-07-08 06:18:06 - train: epoch 0069, iter [02100, 05004], lr: 0.001000, loss: 1.2293
2022-07-08 06:18:40 - train: epoch 0069, iter [02200, 05004], lr: 0.001000, loss: 1.2614
2022-07-08 06:19:13 - train: epoch 0069, iter [02300, 05004], lr: 0.001000, loss: 1.1599
2022-07-08 06:19:47 - train: epoch 0069, iter [02400, 05004], lr: 0.001000, loss: 1.2460
2022-07-08 06:20:20 - train: epoch 0069, iter [02500, 05004], lr: 0.001000, loss: 1.1954
2022-07-08 06:20:52 - train: epoch 0069, iter [02600, 05004], lr: 0.001000, loss: 1.3410
2022-07-08 06:21:25 - train: epoch 0069, iter [02700, 05004], lr: 0.001000, loss: 1.4662
2022-07-08 06:21:58 - train: epoch 0069, iter [02800, 05004], lr: 0.001000, loss: 1.4114
2022-07-08 06:22:31 - train: epoch 0069, iter [02900, 05004], lr: 0.001000, loss: 1.0456
2022-07-08 06:23:05 - train: epoch 0069, iter [03000, 05004], lr: 0.001000, loss: 1.1531
2022-07-08 06:23:38 - train: epoch 0069, iter [03100, 05004], lr: 0.001000, loss: 1.0634
2022-07-08 06:24:12 - train: epoch 0069, iter [03200, 05004], lr: 0.001000, loss: 1.0927
2022-07-08 06:24:44 - train: epoch 0069, iter [03300, 05004], lr: 0.001000, loss: 1.1696
2022-07-08 06:25:18 - train: epoch 0069, iter [03400, 05004], lr: 0.001000, loss: 1.0698
2022-07-08 06:25:51 - train: epoch 0069, iter [03500, 05004], lr: 0.001000, loss: 1.0406
2022-07-08 06:26:24 - train: epoch 0069, iter [03600, 05004], lr: 0.001000, loss: 1.1090
2022-07-08 06:26:57 - train: epoch 0069, iter [03700, 05004], lr: 0.001000, loss: 1.2511
2022-07-08 06:27:30 - train: epoch 0069, iter [03800, 05004], lr: 0.001000, loss: 1.2348
2022-07-08 06:28:03 - train: epoch 0069, iter [03900, 05004], lr: 0.001000, loss: 1.3077
2022-07-08 06:28:36 - train: epoch 0069, iter [04000, 05004], lr: 0.001000, loss: 1.2885
2022-07-08 06:29:10 - train: epoch 0069, iter [04100, 05004], lr: 0.001000, loss: 1.3029
2022-07-08 06:29:43 - train: epoch 0069, iter [04200, 05004], lr: 0.001000, loss: 0.9858
2022-07-08 06:30:15 - train: epoch 0069, iter [04300, 05004], lr: 0.001000, loss: 1.2360
2022-07-08 06:30:49 - train: epoch 0069, iter [04400, 05004], lr: 0.001000, loss: 1.2155
2022-07-08 06:31:22 - train: epoch 0069, iter [04500, 05004], lr: 0.001000, loss: 1.1885
2022-07-08 06:31:55 - train: epoch 0069, iter [04600, 05004], lr: 0.001000, loss: 1.3417
2022-07-08 06:32:28 - train: epoch 0069, iter [04700, 05004], lr: 0.001000, loss: 1.2648
2022-07-08 06:33:01 - train: epoch 0069, iter [04800, 05004], lr: 0.001000, loss: 1.1803
2022-07-08 06:33:34 - train: epoch 0069, iter [04900, 05004], lr: 0.001000, loss: 1.1404
2022-07-08 06:34:06 - train: epoch 0069, iter [05000, 05004], lr: 0.001000, loss: 1.2702
2022-07-08 06:34:07 - train: epoch 069, train_loss: 1.1977
2022-07-08 06:35:21 - eval: epoch: 069, acc1: 71.972%, acc5: 90.564%, test_loss: 1.1303, per_image_load_time: 2.596ms, per_image_inference_time: 0.258ms
2022-07-08 06:35:21 - until epoch: 069, best_acc1: 71.972%
2022-07-08 06:35:21 - epoch 070 lr: 0.001000
2022-07-08 06:36:00 - train: epoch 0070, iter [00100, 05004], lr: 0.001000, loss: 1.3200
2022-07-08 06:36:33 - train: epoch 0070, iter [00200, 05004], lr: 0.001000, loss: 1.2569
2022-07-08 06:37:05 - train: epoch 0070, iter [00300, 05004], lr: 0.001000, loss: 1.3829
2022-07-08 06:37:39 - train: epoch 0070, iter [00400, 05004], lr: 0.001000, loss: 1.1737
2022-07-08 06:38:12 - train: epoch 0070, iter [00500, 05004], lr: 0.001000, loss: 1.3211
2022-07-08 06:38:46 - train: epoch 0070, iter [00600, 05004], lr: 0.001000, loss: 1.0819
2022-07-08 06:39:18 - train: epoch 0070, iter [00700, 05004], lr: 0.001000, loss: 1.2141
2022-07-08 06:39:51 - train: epoch 0070, iter [00800, 05004], lr: 0.001000, loss: 1.1250
2022-07-08 06:40:25 - train: epoch 0070, iter [00900, 05004], lr: 0.001000, loss: 1.2161
2022-07-08 06:40:58 - train: epoch 0070, iter [01000, 05004], lr: 0.001000, loss: 1.1613
2022-07-08 06:41:31 - train: epoch 0070, iter [01100, 05004], lr: 0.001000, loss: 1.5655
2022-07-08 06:42:05 - train: epoch 0070, iter [01200, 05004], lr: 0.001000, loss: 0.9900
2022-07-08 06:42:37 - train: epoch 0070, iter [01300, 05004], lr: 0.001000, loss: 1.0924
2022-07-08 06:43:10 - train: epoch 0070, iter [01400, 05004], lr: 0.001000, loss: 1.1854
2022-07-08 06:43:43 - train: epoch 0070, iter [01500, 05004], lr: 0.001000, loss: 1.1555
2022-07-08 06:44:16 - train: epoch 0070, iter [01600, 05004], lr: 0.001000, loss: 1.3180
2022-07-08 06:44:50 - train: epoch 0070, iter [01700, 05004], lr: 0.001000, loss: 1.2431
2022-07-08 06:45:23 - train: epoch 0070, iter [01800, 05004], lr: 0.001000, loss: 1.1278
2022-07-08 06:45:57 - train: epoch 0070, iter [01900, 05004], lr: 0.001000, loss: 1.1720
2022-07-08 06:46:29 - train: epoch 0070, iter [02000, 05004], lr: 0.001000, loss: 1.1885
2022-07-08 06:47:03 - train: epoch 0070, iter [02100, 05004], lr: 0.001000, loss: 1.2520
2022-07-08 06:47:36 - train: epoch 0070, iter [02200, 05004], lr: 0.001000, loss: 1.2398
2022-07-08 06:48:09 - train: epoch 0070, iter [02300, 05004], lr: 0.001000, loss: 1.1380
2022-07-08 06:48:44 - train: epoch 0070, iter [02400, 05004], lr: 0.001000, loss: 1.3201
2022-07-08 06:49:16 - train: epoch 0070, iter [02500, 05004], lr: 0.001000, loss: 1.2541
2022-07-08 06:49:49 - train: epoch 0070, iter [02600, 05004], lr: 0.001000, loss: 1.1423
2022-07-08 06:50:22 - train: epoch 0070, iter [02700, 05004], lr: 0.001000, loss: 1.1201
2022-07-08 06:50:56 - train: epoch 0070, iter [02800, 05004], lr: 0.001000, loss: 1.2383
2022-07-08 06:51:29 - train: epoch 0070, iter [02900, 05004], lr: 0.001000, loss: 1.4380
2022-07-08 06:52:02 - train: epoch 0070, iter [03000, 05004], lr: 0.001000, loss: 1.1783
2022-07-08 06:52:36 - train: epoch 0070, iter [03100, 05004], lr: 0.001000, loss: 1.1887
2022-07-08 06:53:09 - train: epoch 0070, iter [03200, 05004], lr: 0.001000, loss: 1.3567
2022-07-08 06:53:42 - train: epoch 0070, iter [03300, 05004], lr: 0.001000, loss: 1.1400
2022-07-08 06:54:16 - train: epoch 0070, iter [03400, 05004], lr: 0.001000, loss: 1.2407
2022-07-08 06:54:49 - train: epoch 0070, iter [03500, 05004], lr: 0.001000, loss: 1.2306
2022-07-08 06:55:22 - train: epoch 0070, iter [03600, 05004], lr: 0.001000, loss: 1.2511
2022-07-08 06:55:57 - train: epoch 0070, iter [03700, 05004], lr: 0.001000, loss: 1.1839
2022-07-08 06:56:29 - train: epoch 0070, iter [03800, 05004], lr: 0.001000, loss: 1.2384
2022-07-08 06:57:03 - train: epoch 0070, iter [03900, 05004], lr: 0.001000, loss: 1.0343
2022-07-08 06:57:36 - train: epoch 0070, iter [04000, 05004], lr: 0.001000, loss: 0.9769
2022-07-08 06:58:09 - train: epoch 0070, iter [04100, 05004], lr: 0.001000, loss: 1.1132
2022-07-08 06:58:42 - train: epoch 0070, iter [04200, 05004], lr: 0.001000, loss: 1.2440
2022-07-08 06:59:16 - train: epoch 0070, iter [04300, 05004], lr: 0.001000, loss: 1.1866
2022-07-08 06:59:49 - train: epoch 0070, iter [04400, 05004], lr: 0.001000, loss: 1.3193
2022-07-08 07:00:22 - train: epoch 0070, iter [04500, 05004], lr: 0.001000, loss: 1.1397
2022-07-08 07:00:56 - train: epoch 0070, iter [04600, 05004], lr: 0.001000, loss: 1.2638
2022-07-08 07:01:30 - train: epoch 0070, iter [04700, 05004], lr: 0.001000, loss: 1.2430
2022-07-08 07:02:02 - train: epoch 0070, iter [04800, 05004], lr: 0.001000, loss: 1.2434
2022-07-08 07:02:36 - train: epoch 0070, iter [04900, 05004], lr: 0.001000, loss: 1.3031
2022-07-08 07:03:07 - train: epoch 0070, iter [05000, 05004], lr: 0.001000, loss: 1.2267
2022-07-08 07:03:08 - train: epoch 070, train_loss: 1.1944
2022-07-08 07:04:21 - eval: epoch: 070, acc1: 71.874%, acc5: 90.432%, test_loss: 1.1300, per_image_load_time: 2.491ms, per_image_inference_time: 0.282ms
2022-07-08 07:04:21 - until epoch: 070, best_acc1: 71.972%
2022-07-08 07:04:21 - epoch 071 lr: 0.001000
2022-07-08 07:05:00 - train: epoch 0071, iter [00100, 05004], lr: 0.001000, loss: 1.0721
2022-07-08 07:05:33 - train: epoch 0071, iter [00200, 05004], lr: 0.001000, loss: 1.1759
2022-07-08 07:06:05 - train: epoch 0071, iter [00300, 05004], lr: 0.001000, loss: 1.0947
2022-07-08 07:06:39 - train: epoch 0071, iter [00400, 05004], lr: 0.001000, loss: 1.3065
2022-07-08 07:07:11 - train: epoch 0071, iter [00500, 05004], lr: 0.001000, loss: 1.2657
2022-07-08 07:07:44 - train: epoch 0071, iter [00600, 05004], lr: 0.001000, loss: 1.3676
2022-07-08 07:08:17 - train: epoch 0071, iter [00700, 05004], lr: 0.001000, loss: 1.3496
2022-07-08 07:08:50 - train: epoch 0071, iter [00800, 05004], lr: 0.001000, loss: 1.2089
2022-07-08 07:09:23 - train: epoch 0071, iter [00900, 05004], lr: 0.001000, loss: 1.2904
2022-07-08 07:09:57 - train: epoch 0071, iter [01000, 05004], lr: 0.001000, loss: 1.2908
2022-07-08 07:10:29 - train: epoch 0071, iter [01100, 05004], lr: 0.001000, loss: 1.4066
2022-07-08 07:11:03 - train: epoch 0071, iter [01200, 05004], lr: 0.001000, loss: 1.2421
2022-07-08 07:11:36 - train: epoch 0071, iter [01300, 05004], lr: 0.001000, loss: 1.1660
2022-07-08 07:12:10 - train: epoch 0071, iter [01400, 05004], lr: 0.001000, loss: 1.1982
2022-07-08 07:12:43 - train: epoch 0071, iter [01500, 05004], lr: 0.001000, loss: 1.0444
2022-07-08 07:13:17 - train: epoch 0071, iter [01600, 05004], lr: 0.001000, loss: 1.1398
2022-07-08 07:13:49 - train: epoch 0071, iter [01700, 05004], lr: 0.001000, loss: 1.1891
2022-07-08 07:14:23 - train: epoch 0071, iter [01800, 05004], lr: 0.001000, loss: 1.2058
2022-07-08 07:14:55 - train: epoch 0071, iter [01900, 05004], lr: 0.001000, loss: 1.1659
2022-07-08 07:15:29 - train: epoch 0071, iter [02000, 05004], lr: 0.001000, loss: 1.2831
2022-07-08 07:16:03 - train: epoch 0071, iter [02100, 05004], lr: 0.001000, loss: 0.9893
2022-07-08 07:16:37 - train: epoch 0071, iter [02200, 05004], lr: 0.001000, loss: 1.1355
2022-07-08 07:17:09 - train: epoch 0071, iter [02300, 05004], lr: 0.001000, loss: 1.1238
2022-07-08 07:17:42 - train: epoch 0071, iter [02400, 05004], lr: 0.001000, loss: 1.1035
2022-07-08 07:18:16 - train: epoch 0071, iter [02500, 05004], lr: 0.001000, loss: 1.2355
2022-07-08 07:18:50 - train: epoch 0071, iter [02600, 05004], lr: 0.001000, loss: 1.0490
2022-07-08 07:19:23 - train: epoch 0071, iter [02700, 05004], lr: 0.001000, loss: 1.2044
2022-07-08 07:19:56 - train: epoch 0071, iter [02800, 05004], lr: 0.001000, loss: 1.3113
2022-07-08 07:20:29 - train: epoch 0071, iter [02900, 05004], lr: 0.001000, loss: 1.1740
2022-07-08 07:21:03 - train: epoch 0071, iter [03000, 05004], lr: 0.001000, loss: 1.1805
2022-07-08 07:21:36 - train: epoch 0071, iter [03100, 05004], lr: 0.001000, loss: 1.1738
2022-07-08 07:22:09 - train: epoch 0071, iter [03200, 05004], lr: 0.001000, loss: 1.0589
2022-07-08 07:22:41 - train: epoch 0071, iter [03300, 05004], lr: 0.001000, loss: 1.0217
2022-07-08 07:23:16 - train: epoch 0071, iter [03400, 05004], lr: 0.001000, loss: 1.0740
2022-07-08 07:23:48 - train: epoch 0071, iter [03500, 05004], lr: 0.001000, loss: 1.3441
2022-07-08 07:24:21 - train: epoch 0071, iter [03600, 05004], lr: 0.001000, loss: 1.3744
2022-07-08 07:24:54 - train: epoch 0071, iter [03700, 05004], lr: 0.001000, loss: 1.1007
2022-07-08 07:25:28 - train: epoch 0071, iter [03800, 05004], lr: 0.001000, loss: 1.1458
2022-07-08 07:26:01 - train: epoch 0071, iter [03900, 05004], lr: 0.001000, loss: 1.2152
2022-07-08 07:26:35 - train: epoch 0071, iter [04000, 05004], lr: 0.001000, loss: 1.3421
2022-07-08 07:27:08 - train: epoch 0071, iter [04100, 05004], lr: 0.001000, loss: 1.1500
2022-07-08 07:27:42 - train: epoch 0071, iter [04200, 05004], lr: 0.001000, loss: 1.4428
2022-07-08 07:28:15 - train: epoch 0071, iter [04300, 05004], lr: 0.001000, loss: 1.1864
2022-07-08 07:28:48 - train: epoch 0071, iter [04400, 05004], lr: 0.001000, loss: 1.2031
2022-07-08 07:29:21 - train: epoch 0071, iter [04500, 05004], lr: 0.001000, loss: 1.1986
2022-07-08 07:29:55 - train: epoch 0071, iter [04600, 05004], lr: 0.001000, loss: 1.2698
2022-07-08 07:30:28 - train: epoch 0071, iter [04700, 05004], lr: 0.001000, loss: 1.0044
2022-07-08 07:31:02 - train: epoch 0071, iter [04800, 05004], lr: 0.001000, loss: 1.0323
2022-07-08 07:31:34 - train: epoch 0071, iter [04900, 05004], lr: 0.001000, loss: 0.9102
2022-07-08 07:32:06 - train: epoch 0071, iter [05000, 05004], lr: 0.001000, loss: 1.0922
2022-07-08 07:32:07 - train: epoch 071, train_loss: 1.1907
2022-07-08 07:33:20 - eval: epoch: 071, acc1: 72.168%, acc5: 90.604%, test_loss: 1.1209, per_image_load_time: 2.027ms, per_image_inference_time: 0.269ms
2022-07-08 07:33:20 - until epoch: 071, best_acc1: 72.168%
2022-07-08 07:33:20 - epoch 072 lr: 0.001000
2022-07-08 07:33:57 - train: epoch 0072, iter [00100, 05004], lr: 0.001000, loss: 1.3437
2022-07-08 07:34:31 - train: epoch 0072, iter [00200, 05004], lr: 0.001000, loss: 1.0501
2022-07-08 07:35:03 - train: epoch 0072, iter [00300, 05004], lr: 0.001000, loss: 1.0675
2022-07-08 07:35:37 - train: epoch 0072, iter [00400, 05004], lr: 0.001000, loss: 1.1838
2022-07-08 07:36:09 - train: epoch 0072, iter [00500, 05004], lr: 0.001000, loss: 1.0633
2022-07-08 07:36:42 - train: epoch 0072, iter [00600, 05004], lr: 0.001000, loss: 1.2271
2022-07-08 07:37:16 - train: epoch 0072, iter [00700, 05004], lr: 0.001000, loss: 1.1740
2022-07-08 07:37:48 - train: epoch 0072, iter [00800, 05004], lr: 0.001000, loss: 1.3687
2022-07-08 07:38:22 - train: epoch 0072, iter [00900, 05004], lr: 0.001000, loss: 1.0460
2022-07-08 07:38:54 - train: epoch 0072, iter [01000, 05004], lr: 0.001000, loss: 1.0568
2022-07-08 07:39:27 - train: epoch 0072, iter [01100, 05004], lr: 0.001000, loss: 1.1743
2022-07-08 07:40:00 - train: epoch 0072, iter [01200, 05004], lr: 0.001000, loss: 1.0430
2022-07-08 07:40:33 - train: epoch 0072, iter [01300, 05004], lr: 0.001000, loss: 1.1917
2022-07-08 07:41:06 - train: epoch 0072, iter [01400, 05004], lr: 0.001000, loss: 1.2396
2022-07-08 07:41:40 - train: epoch 0072, iter [01500, 05004], lr: 0.001000, loss: 1.0959
2022-07-08 07:42:13 - train: epoch 0072, iter [01600, 05004], lr: 0.001000, loss: 1.3237
2022-07-08 07:42:47 - train: epoch 0072, iter [01700, 05004], lr: 0.001000, loss: 1.1415
2022-07-08 07:43:19 - train: epoch 0072, iter [01800, 05004], lr: 0.001000, loss: 1.0676
2022-07-08 07:43:53 - train: epoch 0072, iter [01900, 05004], lr: 0.001000, loss: 1.0282
2022-07-08 07:44:26 - train: epoch 0072, iter [02000, 05004], lr: 0.001000, loss: 1.2686
2022-07-08 07:44:58 - train: epoch 0072, iter [02100, 05004], lr: 0.001000, loss: 1.3209
2022-07-08 07:45:32 - train: epoch 0072, iter [02200, 05004], lr: 0.001000, loss: 1.2648
2022-07-08 07:46:05 - train: epoch 0072, iter [02300, 05004], lr: 0.001000, loss: 1.2983
2022-07-08 07:46:38 - train: epoch 0072, iter [02400, 05004], lr: 0.001000, loss: 1.0670
2022-07-08 07:47:12 - train: epoch 0072, iter [02500, 05004], lr: 0.001000, loss: 1.0293
2022-07-08 07:47:45 - train: epoch 0072, iter [02600, 05004], lr: 0.001000, loss: 1.0404
2022-07-08 07:48:18 - train: epoch 0072, iter [02700, 05004], lr: 0.001000, loss: 1.2155
2022-07-08 07:48:52 - train: epoch 0072, iter [02800, 05004], lr: 0.001000, loss: 1.3118
2022-07-08 07:49:24 - train: epoch 0072, iter [02900, 05004], lr: 0.001000, loss: 1.1568
2022-07-08 07:49:58 - train: epoch 0072, iter [03000, 05004], lr: 0.001000, loss: 1.1366
2022-07-08 07:50:31 - train: epoch 0072, iter [03100, 05004], lr: 0.001000, loss: 1.2025
2022-07-08 07:51:04 - train: epoch 0072, iter [03200, 05004], lr: 0.001000, loss: 1.1576
2022-07-08 07:51:38 - train: epoch 0072, iter [03300, 05004], lr: 0.001000, loss: 1.1322
2022-07-08 07:52:11 - train: epoch 0072, iter [03400, 05004], lr: 0.001000, loss: 1.2868
2022-07-08 07:52:45 - train: epoch 0072, iter [03500, 05004], lr: 0.001000, loss: 1.2352
2022-07-08 07:53:18 - train: epoch 0072, iter [03600, 05004], lr: 0.001000, loss: 1.1673
2022-07-08 07:53:50 - train: epoch 0072, iter [03700, 05004], lr: 0.001000, loss: 1.2836
2022-07-08 07:54:24 - train: epoch 0072, iter [03800, 05004], lr: 0.001000, loss: 1.2580
2022-07-08 07:54:57 - train: epoch 0072, iter [03900, 05004], lr: 0.001000, loss: 1.3275
2022-07-08 07:55:30 - train: epoch 0072, iter [04000, 05004], lr: 0.001000, loss: 1.1144
2022-07-08 07:56:03 - train: epoch 0072, iter [04100, 05004], lr: 0.001000, loss: 1.4009
2022-07-08 07:56:37 - train: epoch 0072, iter [04200, 05004], lr: 0.001000, loss: 1.2262
2022-07-08 07:57:11 - train: epoch 0072, iter [04300, 05004], lr: 0.001000, loss: 1.1281
2022-07-08 07:57:44 - train: epoch 0072, iter [04400, 05004], lr: 0.001000, loss: 1.0574
2022-07-08 07:58:17 - train: epoch 0072, iter [04500, 05004], lr: 0.001000, loss: 1.3893
2022-07-08 07:58:50 - train: epoch 0072, iter [04600, 05004], lr: 0.001000, loss: 1.1293
2022-07-08 07:59:23 - train: epoch 0072, iter [04700, 05004], lr: 0.001000, loss: 1.2650
2022-07-08 07:59:57 - train: epoch 0072, iter [04800, 05004], lr: 0.001000, loss: 1.3296
2022-07-08 08:00:29 - train: epoch 0072, iter [04900, 05004], lr: 0.001000, loss: 1.2731
2022-07-08 08:01:01 - train: epoch 0072, iter [05000, 05004], lr: 0.001000, loss: 1.1695
2022-07-08 08:01:02 - train: epoch 072, train_loss: 1.1887
2022-07-08 08:02:15 - eval: epoch: 072, acc1: 72.024%, acc5: 90.498%, test_loss: 1.1249, per_image_load_time: 2.499ms, per_image_inference_time: 0.262ms
2022-07-08 08:02:15 - until epoch: 072, best_acc1: 72.168%
2022-07-08 08:02:15 - epoch 073 lr: 0.001000
2022-07-08 08:02:54 - train: epoch 0073, iter [00100, 05004], lr: 0.001000, loss: 1.3686
2022-07-08 08:03:27 - train: epoch 0073, iter [00200, 05004], lr: 0.001000, loss: 1.2342
2022-07-08 08:03:59 - train: epoch 0073, iter [00300, 05004], lr: 0.001000, loss: 1.3655
2022-07-08 08:04:32 - train: epoch 0073, iter [00400, 05004], lr: 0.001000, loss: 0.9248
2022-07-08 08:05:05 - train: epoch 0073, iter [00500, 05004], lr: 0.001000, loss: 1.0031
2022-07-08 08:05:37 - train: epoch 0073, iter [00600, 05004], lr: 0.001000, loss: 1.1158
2022-07-08 08:06:11 - train: epoch 0073, iter [00700, 05004], lr: 0.001000, loss: 1.1473
2022-07-08 08:06:43 - train: epoch 0073, iter [00800, 05004], lr: 0.001000, loss: 1.0788
2022-07-08 08:07:16 - train: epoch 0073, iter [00900, 05004], lr: 0.001000, loss: 0.9583
2022-07-08 08:07:49 - train: epoch 0073, iter [01000, 05004], lr: 0.001000, loss: 0.9902
2022-07-08 08:08:22 - train: epoch 0073, iter [01100, 05004], lr: 0.001000, loss: 1.2042
2022-07-08 08:08:55 - train: epoch 0073, iter [01200, 05004], lr: 0.001000, loss: 1.1583
2022-07-08 08:09:29 - train: epoch 0073, iter [01300, 05004], lr: 0.001000, loss: 1.2188
2022-07-08 08:10:02 - train: epoch 0073, iter [01400, 05004], lr: 0.001000, loss: 1.1752
2022-07-08 08:10:35 - train: epoch 0073, iter [01500, 05004], lr: 0.001000, loss: 1.1579
2022-07-08 08:11:07 - train: epoch 0073, iter [01600, 05004], lr: 0.001000, loss: 1.2633
2022-07-08 08:11:41 - train: epoch 0073, iter [01700, 05004], lr: 0.001000, loss: 1.3785
2022-07-08 08:12:14 - train: epoch 0073, iter [01800, 05004], lr: 0.001000, loss: 1.0913
2022-07-08 08:12:47 - train: epoch 0073, iter [01900, 05004], lr: 0.001000, loss: 1.2447
2022-07-08 08:13:20 - train: epoch 0073, iter [02000, 05004], lr: 0.001000, loss: 0.9875
2022-07-08 08:13:53 - train: epoch 0073, iter [02100, 05004], lr: 0.001000, loss: 1.3115
2022-07-08 08:14:27 - train: epoch 0073, iter [02200, 05004], lr: 0.001000, loss: 1.3060
2022-07-08 08:14:59 - train: epoch 0073, iter [02300, 05004], lr: 0.001000, loss: 1.2771
2022-07-08 08:15:33 - train: epoch 0073, iter [02400, 05004], lr: 0.001000, loss: 1.1379
2022-07-08 08:16:06 - train: epoch 0073, iter [02500, 05004], lr: 0.001000, loss: 1.2910
2022-07-08 08:16:39 - train: epoch 0073, iter [02600, 05004], lr: 0.001000, loss: 1.2536
2022-07-08 08:17:13 - train: epoch 0073, iter [02700, 05004], lr: 0.001000, loss: 1.2285
2022-07-08 08:17:45 - train: epoch 0073, iter [02800, 05004], lr: 0.001000, loss: 1.1652
2022-07-08 08:18:19 - train: epoch 0073, iter [02900, 05004], lr: 0.001000, loss: 1.2498
2022-07-08 08:18:51 - train: epoch 0073, iter [03000, 05004], lr: 0.001000, loss: 0.9996
2022-07-08 08:19:25 - train: epoch 0073, iter [03100, 05004], lr: 0.001000, loss: 1.0817
2022-07-08 08:19:58 - train: epoch 0073, iter [03200, 05004], lr: 0.001000, loss: 1.1060
2022-07-08 08:20:31 - train: epoch 0073, iter [03300, 05004], lr: 0.001000, loss: 1.0761
2022-07-08 08:21:04 - train: epoch 0073, iter [03400, 05004], lr: 0.001000, loss: 1.1935
2022-07-08 08:21:38 - train: epoch 0073, iter [03500, 05004], lr: 0.001000, loss: 1.2334
2022-07-08 08:22:12 - train: epoch 0073, iter [03600, 05004], lr: 0.001000, loss: 1.0840
2022-07-08 08:22:45 - train: epoch 0073, iter [03700, 05004], lr: 0.001000, loss: 1.2282
2022-07-08 08:23:18 - train: epoch 0073, iter [03800, 05004], lr: 0.001000, loss: 1.4297
2022-07-08 08:23:51 - train: epoch 0073, iter [03900, 05004], lr: 0.001000, loss: 1.1323
2022-07-08 08:24:25 - train: epoch 0073, iter [04000, 05004], lr: 0.001000, loss: 1.2813
2022-07-08 08:24:57 - train: epoch 0073, iter [04100, 05004], lr: 0.001000, loss: 1.1782
2022-07-08 08:25:31 - train: epoch 0073, iter [04200, 05004], lr: 0.001000, loss: 1.3448
2022-07-08 08:26:04 - train: epoch 0073, iter [04300, 05004], lr: 0.001000, loss: 1.2056
2022-07-08 08:26:38 - train: epoch 0073, iter [04400, 05004], lr: 0.001000, loss: 1.2656
2022-07-08 08:27:12 - train: epoch 0073, iter [04500, 05004], lr: 0.001000, loss: 1.1164
2022-07-08 08:27:45 - train: epoch 0073, iter [04600, 05004], lr: 0.001000, loss: 1.3244
2022-07-08 08:28:19 - train: epoch 0073, iter [04700, 05004], lr: 0.001000, loss: 0.9930
2022-07-08 08:28:51 - train: epoch 0073, iter [04800, 05004], lr: 0.001000, loss: 1.3374
2022-07-08 08:29:24 - train: epoch 0073, iter [04900, 05004], lr: 0.001000, loss: 1.0628
2022-07-08 08:29:56 - train: epoch 0073, iter [05000, 05004], lr: 0.001000, loss: 1.2454
2022-07-08 08:29:57 - train: epoch 073, train_loss: 1.1851
2022-07-08 08:31:11 - eval: epoch: 073, acc1: 71.916%, acc5: 90.656%, test_loss: 1.1228, per_image_load_time: 0.929ms, per_image_inference_time: 0.273ms
2022-07-08 08:31:11 - until epoch: 073, best_acc1: 72.168%
2022-07-08 08:31:11 - epoch 074 lr: 0.001000
2022-07-08 08:31:49 - train: epoch 0074, iter [00100, 05004], lr: 0.001000, loss: 1.0314
2022-07-08 08:32:22 - train: epoch 0074, iter [00200, 05004], lr: 0.001000, loss: 1.2751
2022-07-08 08:32:55 - train: epoch 0074, iter [00300, 05004], lr: 0.001000, loss: 1.2322
2022-07-08 08:33:28 - train: epoch 0074, iter [00400, 05004], lr: 0.001000, loss: 1.3753
2022-07-08 08:34:02 - train: epoch 0074, iter [00500, 05004], lr: 0.001000, loss: 1.1631
2022-07-08 08:34:34 - train: epoch 0074, iter [00600, 05004], lr: 0.001000, loss: 1.1850
2022-07-08 08:35:08 - train: epoch 0074, iter [00700, 05004], lr: 0.001000, loss: 1.1776
2022-07-08 08:35:40 - train: epoch 0074, iter [00800, 05004], lr: 0.001000, loss: 1.3414
2022-07-08 08:36:14 - train: epoch 0074, iter [00900, 05004], lr: 0.001000, loss: 1.1889
2022-07-08 08:36:46 - train: epoch 0074, iter [01000, 05004], lr: 0.001000, loss: 1.3262
2022-07-08 08:37:20 - train: epoch 0074, iter [01100, 05004], lr: 0.001000, loss: 1.2990
2022-07-08 08:37:53 - train: epoch 0074, iter [01200, 05004], lr: 0.001000, loss: 1.0965
2022-07-08 08:38:26 - train: epoch 0074, iter [01300, 05004], lr: 0.001000, loss: 1.3089
2022-07-08 08:38:59 - train: epoch 0074, iter [01400, 05004], lr: 0.001000, loss: 1.0852
2022-07-08 08:39:33 - train: epoch 0074, iter [01500, 05004], lr: 0.001000, loss: 1.1396
2022-07-08 08:40:06 - train: epoch 0074, iter [01600, 05004], lr: 0.001000, loss: 1.0606
2022-07-08 08:40:39 - train: epoch 0074, iter [01700, 05004], lr: 0.001000, loss: 1.3560
2022-07-08 08:41:12 - train: epoch 0074, iter [01800, 05004], lr: 0.001000, loss: 1.5577
2022-07-08 08:41:45 - train: epoch 0074, iter [01900, 05004], lr: 0.001000, loss: 1.3496
2022-07-08 08:42:20 - train: epoch 0074, iter [02000, 05004], lr: 0.001000, loss: 0.9687
2022-07-08 08:42:53 - train: epoch 0074, iter [02100, 05004], lr: 0.001000, loss: 1.2014
2022-07-08 08:43:26 - train: epoch 0074, iter [02200, 05004], lr: 0.001000, loss: 1.4882
2022-07-08 08:43:59 - train: epoch 0074, iter [02300, 05004], lr: 0.001000, loss: 1.2981
2022-07-08 08:44:32 - train: epoch 0074, iter [02400, 05004], lr: 0.001000, loss: 1.1203
2022-07-08 08:45:05 - train: epoch 0074, iter [02500, 05004], lr: 0.001000, loss: 1.1096
2022-07-08 08:45:38 - train: epoch 0074, iter [02600, 05004], lr: 0.001000, loss: 1.0174
2022-07-08 08:46:12 - train: epoch 0074, iter [02700, 05004], lr: 0.001000, loss: 1.0949
2022-07-08 08:46:45 - train: epoch 0074, iter [02800, 05004], lr: 0.001000, loss: 1.4426
2022-07-08 08:47:18 - train: epoch 0074, iter [02900, 05004], lr: 0.001000, loss: 1.0558
2022-07-08 08:47:52 - train: epoch 0074, iter [03000, 05004], lr: 0.001000, loss: 1.1834
2022-07-08 08:48:25 - train: epoch 0074, iter [03100, 05004], lr: 0.001000, loss: 1.1461
2022-07-08 08:48:58 - train: epoch 0074, iter [03200, 05004], lr: 0.001000, loss: 1.0826
2022-07-08 08:49:32 - train: epoch 0074, iter [03300, 05004], lr: 0.001000, loss: 1.2549
2022-07-08 08:50:05 - train: epoch 0074, iter [03400, 05004], lr: 0.001000, loss: 1.2536
2022-07-08 08:50:38 - train: epoch 0074, iter [03500, 05004], lr: 0.001000, loss: 1.0068
2022-07-08 08:51:12 - train: epoch 0074, iter [03600, 05004], lr: 0.001000, loss: 1.2397
2022-07-08 08:51:45 - train: epoch 0074, iter [03700, 05004], lr: 0.001000, loss: 1.2794
2022-07-08 08:52:18 - train: epoch 0074, iter [03800, 05004], lr: 0.001000, loss: 1.1274
2022-07-08 08:52:52 - train: epoch 0074, iter [03900, 05004], lr: 0.001000, loss: 1.0174
2022-07-08 08:53:25 - train: epoch 0074, iter [04000, 05004], lr: 0.001000, loss: 1.0657
2022-07-08 08:53:58 - train: epoch 0074, iter [04100, 05004], lr: 0.001000, loss: 1.3826
2022-07-08 08:54:32 - train: epoch 0074, iter [04200, 05004], lr: 0.001000, loss: 1.1512
2022-07-08 08:55:06 - train: epoch 0074, iter [04300, 05004], lr: 0.001000, loss: 1.1524
2022-07-08 08:55:40 - train: epoch 0074, iter [04400, 05004], lr: 0.001000, loss: 1.0323
2022-07-08 08:56:13 - train: epoch 0074, iter [04500, 05004], lr: 0.001000, loss: 1.0513
2022-07-08 08:56:45 - train: epoch 0074, iter [04600, 05004], lr: 0.001000, loss: 1.3061
2022-07-08 08:57:19 - train: epoch 0074, iter [04700, 05004], lr: 0.001000, loss: 1.1642
2022-07-08 08:57:52 - train: epoch 0074, iter [04800, 05004], lr: 0.001000, loss: 1.1566
2022-07-08 08:58:27 - train: epoch 0074, iter [04900, 05004], lr: 0.001000, loss: 1.4550
2022-07-08 08:58:58 - train: epoch 0074, iter [05000, 05004], lr: 0.001000, loss: 1.1958
2022-07-08 08:58:59 - train: epoch 074, train_loss: 1.1805
2022-07-08 09:00:12 - eval: epoch: 074, acc1: 72.176%, acc5: 90.662%, test_loss: 1.1194, per_image_load_time: 2.375ms, per_image_inference_time: 0.260ms
2022-07-08 09:00:13 - until epoch: 074, best_acc1: 72.176%
2022-07-08 09:00:13 - epoch 075 lr: 0.001000
2022-07-08 09:00:51 - train: epoch 0075, iter [00100, 05004], lr: 0.001000, loss: 1.2504
2022-07-08 09:01:25 - train: epoch 0075, iter [00200, 05004], lr: 0.001000, loss: 1.1746
2022-07-08 09:01:57 - train: epoch 0075, iter [00300, 05004], lr: 0.001000, loss: 1.1074
2022-07-08 09:02:31 - train: epoch 0075, iter [00400, 05004], lr: 0.001000, loss: 1.1751
2022-07-08 09:03:04 - train: epoch 0075, iter [00500, 05004], lr: 0.001000, loss: 1.0232
2022-07-08 09:03:36 - train: epoch 0075, iter [00600, 05004], lr: 0.001000, loss: 1.0991
2022-07-08 09:04:09 - train: epoch 0075, iter [00700, 05004], lr: 0.001000, loss: 1.3494
2022-07-08 09:04:43 - train: epoch 0075, iter [00800, 05004], lr: 0.001000, loss: 1.2746
2022-07-08 09:05:16 - train: epoch 0075, iter [00900, 05004], lr: 0.001000, loss: 1.3556
2022-07-08 09:05:49 - train: epoch 0075, iter [01000, 05004], lr: 0.001000, loss: 0.9724
2022-07-08 09:06:23 - train: epoch 0075, iter [01100, 05004], lr: 0.001000, loss: 1.2938
2022-07-08 09:06:55 - train: epoch 0075, iter [01200, 05004], lr: 0.001000, loss: 1.1462
2022-07-08 09:07:29 - train: epoch 0075, iter [01300, 05004], lr: 0.001000, loss: 1.0874
2022-07-08 09:08:02 - train: epoch 0075, iter [01400, 05004], lr: 0.001000, loss: 1.1931
2022-07-08 09:08:36 - train: epoch 0075, iter [01500, 05004], lr: 0.001000, loss: 1.3008
2022-07-08 09:09:08 - train: epoch 0075, iter [01600, 05004], lr: 0.001000, loss: 0.9543
2022-07-08 09:09:42 - train: epoch 0075, iter [01700, 05004], lr: 0.001000, loss: 1.1134
2022-07-08 09:10:15 - train: epoch 0075, iter [01800, 05004], lr: 0.001000, loss: 1.1656
2022-07-08 09:10:48 - train: epoch 0075, iter [01900, 05004], lr: 0.001000, loss: 1.0399
2022-07-08 09:11:21 - train: epoch 0075, iter [02000, 05004], lr: 0.001000, loss: 1.2024
2022-07-08 09:11:55 - train: epoch 0075, iter [02100, 05004], lr: 0.001000, loss: 1.0824
2022-07-08 09:12:29 - train: epoch 0075, iter [02200, 05004], lr: 0.001000, loss: 1.2129
2022-07-08 09:13:01 - train: epoch 0075, iter [02300, 05004], lr: 0.001000, loss: 1.2185
2022-07-08 09:13:34 - train: epoch 0075, iter [02400, 05004], lr: 0.001000, loss: 1.1382
2022-07-08 09:14:08 - train: epoch 0075, iter [02500, 05004], lr: 0.001000, loss: 1.2841
2022-07-08 09:14:41 - train: epoch 0075, iter [02600, 05004], lr: 0.001000, loss: 1.1864
2022-07-08 09:15:15 - train: epoch 0075, iter [02700, 05004], lr: 0.001000, loss: 0.9947
2022-07-08 09:15:47 - train: epoch 0075, iter [02800, 05004], lr: 0.001000, loss: 1.1466
2022-07-08 09:16:21 - train: epoch 0075, iter [02900, 05004], lr: 0.001000, loss: 1.2778
2022-07-08 09:16:54 - train: epoch 0075, iter [03000, 05004], lr: 0.001000, loss: 1.3684
2022-07-08 09:17:27 - train: epoch 0075, iter [03100, 05004], lr: 0.001000, loss: 1.2853
2022-07-08 09:17:59 - train: epoch 0075, iter [03200, 05004], lr: 0.001000, loss: 1.1662
2022-07-08 09:18:34 - train: epoch 0075, iter [03300, 05004], lr: 0.001000, loss: 1.2095
2022-07-08 09:19:06 - train: epoch 0075, iter [03400, 05004], lr: 0.001000, loss: 1.0013
2022-07-08 09:19:40 - train: epoch 0075, iter [03500, 05004], lr: 0.001000, loss: 1.1544
2022-07-08 09:20:13 - train: epoch 0075, iter [03600, 05004], lr: 0.001000, loss: 1.2167
2022-07-08 09:20:46 - train: epoch 0075, iter [03700, 05004], lr: 0.001000, loss: 1.2067
2022-07-08 09:21:19 - train: epoch 0075, iter [03800, 05004], lr: 0.001000, loss: 1.0740
2022-07-08 09:21:53 - train: epoch 0075, iter [03900, 05004], lr: 0.001000, loss: 1.3312
2022-07-08 09:22:26 - train: epoch 0075, iter [04000, 05004], lr: 0.001000, loss: 1.0727
2022-07-08 09:22:59 - train: epoch 0075, iter [04100, 05004], lr: 0.001000, loss: 0.9328
2022-07-08 09:23:33 - train: epoch 0075, iter [04200, 05004], lr: 0.001000, loss: 1.2684
2022-07-08 09:24:06 - train: epoch 0075, iter [04300, 05004], lr: 0.001000, loss: 1.3626
2022-07-08 09:24:40 - train: epoch 0075, iter [04400, 05004], lr: 0.001000, loss: 1.0501
2022-07-08 09:25:13 - train: epoch 0075, iter [04500, 05004], lr: 0.001000, loss: 1.2243
2022-07-08 09:25:46 - train: epoch 0075, iter [04600, 05004], lr: 0.001000, loss: 1.0276
2022-07-08 09:26:20 - train: epoch 0075, iter [04700, 05004], lr: 0.001000, loss: 1.2636
2022-07-08 09:26:53 - train: epoch 0075, iter [04800, 05004], lr: 0.001000, loss: 1.2399
2022-07-08 09:27:26 - train: epoch 0075, iter [04900, 05004], lr: 0.001000, loss: 1.0643
2022-07-08 09:27:58 - train: epoch 0075, iter [05000, 05004], lr: 0.001000, loss: 1.2720
2022-07-08 09:27:59 - train: epoch 075, train_loss: 1.1795
2022-07-08 09:29:12 - eval: epoch: 075, acc1: 72.174%, acc5: 90.666%, test_loss: 1.1176, per_image_load_time: 2.048ms, per_image_inference_time: 0.273ms
2022-07-08 09:29:13 - until epoch: 075, best_acc1: 72.176%
2022-07-08 09:29:13 - epoch 076 lr: 0.001000
2022-07-08 09:29:51 - train: epoch 0076, iter [00100, 05004], lr: 0.001000, loss: 1.0186
2022-07-08 09:30:24 - train: epoch 0076, iter [00200, 05004], lr: 0.001000, loss: 1.2043
2022-07-08 09:30:57 - train: epoch 0076, iter [00300, 05004], lr: 0.001000, loss: 1.2415
2022-07-08 09:31:29 - train: epoch 0076, iter [00400, 05004], lr: 0.001000, loss: 1.1645
2022-07-08 09:32:02 - train: epoch 0076, iter [00500, 05004], lr: 0.001000, loss: 1.2352
2022-07-08 09:32:36 - train: epoch 0076, iter [00600, 05004], lr: 0.001000, loss: 1.1949
2022-07-08 09:33:08 - train: epoch 0076, iter [00700, 05004], lr: 0.001000, loss: 1.2100
2022-07-08 09:33:42 - train: epoch 0076, iter [00800, 05004], lr: 0.001000, loss: 1.1994
2022-07-08 09:34:14 - train: epoch 0076, iter [00900, 05004], lr: 0.001000, loss: 1.0352
2022-07-08 09:34:48 - train: epoch 0076, iter [01000, 05004], lr: 0.001000, loss: 1.0342
2022-07-08 09:35:20 - train: epoch 0076, iter [01100, 05004], lr: 0.001000, loss: 1.0670
2022-07-08 09:35:54 - train: epoch 0076, iter [01200, 05004], lr: 0.001000, loss: 1.0270
2022-07-08 09:36:27 - train: epoch 0076, iter [01300, 05004], lr: 0.001000, loss: 1.2248
2022-07-08 09:37:00 - train: epoch 0076, iter [01400, 05004], lr: 0.001000, loss: 1.0753
2022-07-08 09:37:33 - train: epoch 0076, iter [01500, 05004], lr: 0.001000, loss: 1.0951
2022-07-08 09:38:06 - train: epoch 0076, iter [01600, 05004], lr: 0.001000, loss: 1.0987
2022-07-08 09:38:39 - train: epoch 0076, iter [01700, 05004], lr: 0.001000, loss: 1.1740
2022-07-08 09:39:12 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 1.0348
2022-07-08 09:39:45 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 1.3240
2022-07-08 09:40:18 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 1.3214
2022-07-08 09:40:52 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 1.2887
2022-07-08 09:41:25 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 1.3024
2022-07-08 09:41:58 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 1.1254
2022-07-08 09:42:32 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 1.3619
2022-07-08 09:43:05 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 1.1210
2022-07-08 09:43:38 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 1.4430
2022-07-08 09:44:11 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 1.2367
2022-07-08 09:44:45 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 1.2135
2022-07-08 09:45:18 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 1.2535
2022-07-08 09:45:52 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 1.0470
2022-07-08 09:46:25 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 1.2627
2022-07-08 09:46:58 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 1.2219
2022-07-08 09:47:32 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 1.1213
2022-07-08 09:48:04 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 1.1771
2022-07-08 09:48:39 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 1.0768
2022-07-08 09:49:12 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 1.0523
2022-07-08 09:49:46 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 1.0134
2022-07-08 09:50:19 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 1.0938
2022-07-08 09:50:52 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 1.0990
2022-07-08 09:51:25 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 1.2146
2022-07-08 09:52:00 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 1.0737
2022-07-08 09:52:33 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 1.3532
2022-07-08 09:53:07 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 1.2217
2022-07-08 09:53:40 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 1.2284
2022-07-08 09:54:13 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 1.1800
2022-07-08 09:54:46 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 1.2206
2022-07-08 09:55:20 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 1.3058
2022-07-08 09:55:53 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 1.0608
2022-07-08 09:56:27 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 1.1683
2022-07-08 09:56:58 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 1.1637
2022-07-08 09:56:59 - train: epoch 076, train_loss: 1.1764
2022-07-08 09:58:12 - eval: epoch: 076, acc1: 72.132%, acc5: 90.620%, test_loss: 1.1221, per_image_load_time: 2.366ms, per_image_inference_time: 0.262ms
2022-07-08 09:58:12 - until epoch: 076, best_acc1: 72.176%
2022-07-08 09:58:12 - epoch 077 lr: 0.001000
2022-07-08 09:58:52 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 1.2573
2022-07-08 09:59:23 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 1.3057
2022-07-08 09:59:57 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 0.9664
2022-07-08 10:00:28 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 1.2993
2022-07-08 10:01:02 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 1.0572
2022-07-08 10:01:34 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 0.9588
2022-07-08 10:02:07 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 1.2524
2022-07-08 10:02:41 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 1.3622
2022-07-08 10:03:13 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 1.3408
2022-07-08 10:03:47 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 0.9594
2022-07-08 10:04:19 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 1.1448
2022-07-08 10:04:52 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 1.2723
2022-07-08 10:05:25 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 0.9780
2022-07-08 10:05:59 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 1.2907
2022-07-08 10:06:32 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 1.0118
2022-07-08 10:07:05 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 1.1517
2022-07-08 10:07:38 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 1.4317
2022-07-08 10:08:12 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 1.0582
2022-07-08 10:08:45 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 1.1650
2022-07-08 10:09:18 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 1.0590
2022-07-08 10:09:51 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 1.1991
2022-07-08 10:10:25 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 1.2263
2022-07-08 10:10:58 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 1.3035
2022-07-08 10:11:32 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 1.1305
2022-07-08 10:12:05 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 1.3643
2022-07-08 10:12:38 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 0.9597
2022-07-08 10:13:12 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 1.1977
2022-07-08 10:13:45 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 1.3194
2022-07-08 10:14:19 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 1.4660
2022-07-08 10:14:52 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 1.0770
2022-07-08 10:15:25 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 1.1536
2022-07-08 10:15:59 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 1.2891
2022-07-08 10:16:32 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 1.0277
2022-07-08 10:17:06 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 1.3406
2022-07-08 10:17:38 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 1.0232
2022-07-08 10:18:11 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 1.1223
2022-07-08 10:18:45 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 1.2089
2022-07-08 10:19:18 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 1.1603
2022-07-08 10:19:52 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 1.2375
2022-07-08 10:20:25 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 1.2057
2022-07-08 10:20:59 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 1.2821
2022-07-08 10:21:32 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 1.2293
2022-07-08 10:22:05 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 1.0885
2022-07-08 10:22:39 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 1.1612
2022-07-08 10:23:12 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 1.2064
2022-07-08 10:23:45 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 1.1353
2022-07-08 10:24:18 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 1.0454
2022-07-08 10:24:52 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 1.2514
2022-07-08 10:25:25 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 1.3554
2022-07-08 10:25:57 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 1.3769
2022-07-08 10:25:57 - train: epoch 077, train_loss: 1.1708
2022-07-08 10:27:11 - eval: epoch: 077, acc1: 72.130%, acc5: 90.614%, test_loss: 1.1205, per_image_load_time: 1.236ms, per_image_inference_time: 0.276ms
2022-07-08 10:27:11 - until epoch: 077, best_acc1: 72.176%
2022-07-08 10:27:11 - epoch 078 lr: 0.001000
2022-07-08 10:27:49 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 1.1734
2022-07-08 10:28:22 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 1.2539
2022-07-08 10:28:54 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 1.2988
2022-07-08 10:29:28 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 1.1432
2022-07-08 10:30:00 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 1.2146
2022-07-08 10:30:33 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 1.1853
2022-07-08 10:31:06 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 1.2381
2022-07-08 10:31:39 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 1.4026
2022-07-08 10:32:12 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 1.1989
2022-07-08 10:32:44 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 1.1737
2022-07-08 10:33:18 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 1.0277
2022-07-08 10:33:51 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 0.9248
2022-07-08 10:34:24 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 1.2435
2022-07-08 10:34:57 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 1.0506
2022-07-08 10:35:30 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 1.0881
2022-07-08 10:36:03 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 1.2882
2022-07-08 10:36:36 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 1.0941
2022-07-08 10:37:09 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 1.1121
2022-07-08 10:37:43 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 1.0332
2022-07-08 10:38:16 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 1.0072
2022-07-08 10:38:49 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 1.4107
2022-07-08 10:39:22 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 1.1349
2022-07-08 10:39:56 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 1.3001
2022-07-08 10:40:29 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 1.0966
2022-07-08 10:41:03 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 1.1982
2022-07-08 10:41:36 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 1.1180
2022-07-08 10:42:11 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 1.0813
2022-07-08 10:42:42 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 1.2136
2022-07-08 10:43:16 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 1.0919
2022-07-08 10:43:49 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 1.0939
2022-07-08 10:44:22 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 1.2600
2022-07-08 10:44:55 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 1.0916
2022-07-08 10:45:28 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 1.2582
2022-07-08 10:46:02 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 1.1967
2022-07-08 10:46:35 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 1.2587
2022-07-08 10:47:09 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 1.2337
2022-07-08 10:47:42 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 1.0666
2022-07-08 10:48:15 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 1.1856
2022-07-08 10:48:48 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 1.2340
2022-07-08 10:49:21 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 1.0867
2022-07-08 10:49:54 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 1.3361
2022-07-08 10:50:28 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 1.2902
2022-07-08 10:51:00 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 1.2149
2022-07-08 10:51:34 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 1.1278
2022-07-08 10:52:07 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 1.2293
2022-07-08 10:52:41 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 1.0743
2022-07-08 10:53:14 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 1.2636
2022-07-08 10:53:47 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 1.3426
2022-07-08 10:54:21 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 1.2246
2022-07-08 10:54:52 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 1.1344
2022-07-08 10:54:53 - train: epoch 078, train_loss: 1.1670
2022-07-08 10:56:07 - eval: epoch: 078, acc1: 72.102%, acc5: 90.570%, test_loss: 1.1193, per_image_load_time: 2.600ms, per_image_inference_time: 0.277ms
2022-07-08 10:56:07 - until epoch: 078, best_acc1: 72.176%
2022-07-08 10:56:07 - epoch 079 lr: 0.001000
2022-07-08 10:56:45 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 1.1209
2022-07-08 10:57:18 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 1.0770
2022-07-08 10:57:51 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 1.2703
2022-07-08 10:58:24 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 1.2934
2022-07-08 10:58:57 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 1.1826
2022-07-08 10:59:30 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 1.0202
2022-07-08 11:00:04 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 1.1306
2022-07-08 11:00:36 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 1.2573
2022-07-08 11:01:09 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 1.1019
2022-07-08 11:01:42 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 1.0176
2022-07-08 11:02:15 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 1.2857
2022-07-08 11:02:48 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 1.3493
2022-07-08 11:03:21 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 1.0351
2022-07-08 11:03:55 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 1.1466
2022-07-08 11:04:27 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 1.1208
2022-07-08 11:05:01 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 1.0349
2022-07-08 11:05:34 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 1.1946
2022-07-08 11:06:08 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 1.0704
2022-07-08 11:06:41 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 1.1965
2022-07-08 11:07:15 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 1.3046
2022-07-08 11:07:47 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 0.9856
2022-07-08 11:08:21 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 1.1874
2022-07-08 11:08:54 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 1.1069
2022-07-08 11:09:27 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 1.2242
2022-07-08 11:09:59 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 1.1180
2022-07-08 11:10:33 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 1.1484
2022-07-08 11:11:06 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 1.0105
2022-07-08 11:11:39 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 1.0803
2022-07-08 11:12:12 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 1.0249
2022-07-08 11:12:45 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 1.1511
2022-07-08 11:13:18 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 1.1441
2022-07-08 11:13:53 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 1.3470
2022-07-08 11:14:25 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 1.1910
2022-07-08 11:15:00 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 0.9628
2022-07-08 11:15:32 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 1.3719
2022-07-08 11:16:05 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 1.0632
2022-07-08 11:16:38 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 1.0126
2022-07-08 11:17:11 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 1.2731
2022-07-08 11:17:44 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 1.0493
2022-07-08 11:18:18 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 0.9628
2022-07-08 11:18:51 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 1.2933
2022-07-08 11:19:24 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 1.1279
2022-07-08 11:19:57 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 0.9174
2022-07-08 11:20:30 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 1.3226
2022-07-08 11:21:03 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 1.3816
2022-07-08 11:21:37 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 1.3436
2022-07-08 11:22:09 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 1.1383
2022-07-08 11:22:42 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 1.2978
2022-07-08 11:23:16 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 1.2309
2022-07-08 11:23:48 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 1.0458
2022-07-08 11:23:49 - train: epoch 079, train_loss: 1.1666
2022-07-08 11:25:01 - eval: epoch: 079, acc1: 72.158%, acc5: 90.654%, test_loss: 1.1209, per_image_load_time: 2.533ms, per_image_inference_time: 0.264ms
2022-07-08 11:25:01 - until epoch: 079, best_acc1: 72.176%
2022-07-08 11:25:01 - epoch 080 lr: 0.001000
2022-07-08 11:25:39 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 1.0736
2022-07-08 11:26:13 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 1.1258
2022-07-08 11:26:45 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 1.3294
2022-07-08 11:27:18 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 1.0448
2022-07-08 11:27:52 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 1.2089
2022-07-08 11:28:24 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 1.0697
2022-07-08 11:28:57 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 1.1101
2022-07-08 11:29:30 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 1.0064
2022-07-08 11:30:03 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 1.2066
2022-07-08 11:30:36 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 1.0827
2022-07-08 11:31:10 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 1.1682
2022-07-08 11:31:43 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 1.0939
2022-07-08 11:32:17 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 1.1112
2022-07-08 11:32:50 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 1.0978
2022-07-08 11:33:23 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 1.1040
2022-07-08 11:33:56 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 1.0910
2022-07-08 11:34:30 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 1.3116
2022-07-08 11:35:03 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 1.2509
2022-07-08 11:35:36 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 1.1757
2022-07-08 11:36:09 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 1.3071
2022-07-08 11:36:42 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 1.2025
2022-07-08 11:37:16 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 1.2952
2022-07-08 11:37:48 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 1.0342
2022-07-08 11:38:22 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 1.1548
2022-07-08 11:38:55 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 1.0791
2022-07-08 11:39:28 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 1.1232
2022-07-08 11:40:02 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 1.2771
2022-07-08 11:40:34 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 1.1761
2022-07-08 11:41:08 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 1.0803
2022-07-08 11:41:41 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 1.1399
2022-07-08 11:42:15 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 1.3240
2022-07-08 11:42:47 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 0.8027
2022-07-08 11:43:21 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 1.1663
2022-07-08 11:43:55 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 1.1065
2022-07-08 11:44:29 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 1.0275
2022-07-08 11:45:02 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 1.1505
2022-07-08 11:45:35 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 1.1409
2022-07-08 11:46:08 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 1.1723
2022-07-08 11:46:42 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 1.0718
2022-07-08 11:47:15 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 1.2329
2022-07-08 11:47:47 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 1.2268
2022-07-08 11:48:21 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 1.1676
2022-07-08 11:48:55 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 1.2755
2022-07-08 11:49:27 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 1.1907
2022-07-08 11:50:01 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 1.0709
2022-07-08 11:50:34 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 1.3277
2022-07-08 11:51:08 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 1.2330
2022-07-08 11:51:40 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 1.2056
2022-07-08 11:52:14 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 1.2453
2022-07-08 11:52:46 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 0.9428
2022-07-08 11:52:47 - train: epoch 080, train_loss: 1.1644
2022-07-08 11:54:00 - eval: epoch: 080, acc1: 72.220%, acc5: 90.672%, test_loss: 1.1191, per_image_load_time: 2.436ms, per_image_inference_time: 0.280ms
2022-07-08 11:54:00 - until epoch: 080, best_acc1: 72.220%
2022-07-08 11:54:00 - epoch 081 lr: 0.001000
2022-07-08 11:54:38 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 1.0295
2022-07-08 11:55:11 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 1.2243
2022-07-08 11:55:44 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 1.0845
2022-07-08 11:56:18 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 1.2921
2022-07-08 11:56:50 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 1.2916
2022-07-08 11:57:24 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 1.2148
2022-07-08 11:57:57 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 1.0802
2022-07-08 11:58:30 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 1.2901
2022-07-08 11:59:04 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 1.0693
2022-07-08 11:59:36 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 1.1039
2022-07-08 12:00:10 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 1.0994
2022-07-08 12:00:44 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 1.1638
2022-07-08 12:01:17 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 1.0240
2022-07-08 12:01:51 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 0.8500
2022-07-08 12:02:23 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 1.2352
2022-07-08 12:02:56 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 1.1562
2022-07-08 12:03:30 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 1.2831
2022-07-08 12:04:04 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 1.0722
2022-07-08 12:04:37 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 1.1236
2022-07-08 12:05:10 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 1.2682
2022-07-08 12:05:43 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 1.2250
2022-07-08 12:06:17 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 1.1759
2022-07-08 12:06:50 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 1.1301
2022-07-08 12:07:23 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 1.1036
2022-07-08 12:07:57 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 1.3197
2022-07-08 12:08:30 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 1.3170
2022-07-08 12:09:03 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 1.0681
2022-07-08 12:09:37 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 1.1011
2022-07-08 12:10:10 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 1.1044
2022-07-08 12:10:44 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 1.1807
2022-07-08 12:11:16 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 1.0683
2022-07-08 12:11:50 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 1.1481
2022-07-08 12:12:23 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 1.2527
2022-07-08 12:12:56 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 1.2377
2022-07-08 12:13:29 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 1.2231
2022-07-08 12:14:02 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 1.0503
2022-07-08 12:14:36 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 1.2552
2022-07-08 12:15:09 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 1.0051
2022-07-08 12:15:43 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 1.2689
2022-07-08 12:16:15 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 0.9952
2022-07-08 12:16:49 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 1.1898
2022-07-08 12:17:22 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 1.1837
2022-07-08 12:17:56 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 1.1856
2022-07-08 12:18:28 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 1.2306
2022-07-08 12:19:01 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 1.2481
2022-07-08 12:19:35 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 1.0085
2022-07-08 12:20:08 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 1.2492
2022-07-08 12:20:41 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 1.2043
2022-07-08 12:21:15 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 1.2011
2022-07-08 12:21:47 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 0.9658
2022-07-08 12:21:47 - train: epoch 081, train_loss: 1.1629
2022-07-08 12:23:01 - eval: epoch: 081, acc1: 72.292%, acc5: 90.710%, test_loss: 1.1161, per_image_load_time: 2.596ms, per_image_inference_time: 0.262ms
2022-07-08 12:23:01 - until epoch: 081, best_acc1: 72.292%
2022-07-08 12:23:01 - epoch 082 lr: 0.001000
2022-07-08 12:23:40 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 0.9432
2022-07-08 12:24:13 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 1.0093
2022-07-08 12:24:45 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 1.1855
2022-07-08 12:25:19 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 1.2378
2022-07-08 12:25:51 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 1.2450
2022-07-08 12:26:24 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 0.9959
2022-07-08 12:26:57 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 1.3073
2022-07-08 12:27:30 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 1.1153
2022-07-08 12:28:03 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 1.2766
2022-07-08 12:28:36 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 1.2698
2022-07-08 12:29:10 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 1.3196
2022-07-08 12:29:43 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 1.2325
2022-07-08 12:30:16 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 1.2994
2022-07-08 12:30:49 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 1.1770
2022-07-08 12:31:22 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 1.0537
2022-07-08 12:31:55 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 1.1592
2022-07-08 12:32:28 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 1.1009
2022-07-08 12:33:01 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 1.1229
2022-07-08 12:33:34 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 1.0830
2022-07-08 12:34:08 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 0.9751
2022-07-08 12:34:41 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 1.0917
2022-07-08 12:35:15 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 1.2144
2022-07-08 12:35:48 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 1.1837
2022-07-08 12:36:23 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 1.1608
2022-07-08 12:36:55 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 1.0437
2022-07-08 12:37:28 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 1.0322
2022-07-08 12:38:02 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 1.0802
2022-07-08 12:38:35 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 0.9395
2022-07-08 12:39:09 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 1.0422
2022-07-08 12:39:42 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 1.1392
2022-07-08 12:40:14 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 1.0128
2022-07-08 12:40:48 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 1.3919
2022-07-08 12:41:21 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 1.0775
2022-07-08 12:41:55 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 1.0623
2022-07-08 12:42:27 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 1.0640
2022-07-08 12:43:01 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 1.0390
2022-07-08 12:43:34 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 1.0965
2022-07-08 12:44:07 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 1.4189
2022-07-08 12:44:41 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 1.1975
2022-07-08 12:45:15 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 1.3354
2022-07-08 12:45:47 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 1.1463
2022-07-08 12:46:21 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 1.3720
2022-07-08 12:46:54 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 1.0639
2022-07-08 12:47:27 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 1.0755
2022-07-08 12:48:00 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 1.0922
2022-07-08 12:48:33 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 1.2564
2022-07-08 12:49:07 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 1.0960
2022-07-08 12:49:40 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 1.0095
2022-07-08 12:50:13 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 1.1139
2022-07-08 12:50:45 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 1.1065
2022-07-08 12:50:46 - train: epoch 082, train_loss: 1.1596
2022-07-08 12:51:59 - eval: epoch: 082, acc1: 72.084%, acc5: 90.722%, test_loss: 1.1203, per_image_load_time: 2.562ms, per_image_inference_time: 0.280ms
2022-07-08 12:51:59 - until epoch: 082, best_acc1: 72.292%
2022-07-08 12:51:59 - epoch 083 lr: 0.001000
2022-07-08 12:52:37 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 1.0379
2022-07-08 12:53:11 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 1.1114
2022-07-08 12:53:43 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 1.1923
2022-07-08 12:54:16 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 1.4260
2022-07-08 12:54:48 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 1.1725
2022-07-08 12:55:21 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 1.0344
2022-07-08 12:55:53 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 1.0559
2022-07-08 12:56:27 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 1.1093
2022-07-08 12:57:00 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 1.2594
2022-07-08 12:57:33 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 1.3143
2022-07-08 12:58:06 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 1.1280
2022-07-08 12:58:39 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 1.1886
2022-07-08 12:59:11 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 0.9646
2022-07-08 12:59:45 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 1.3321
2022-07-08 13:00:18 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 1.0866
2022-07-08 13:00:52 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 1.2030
2022-07-08 13:01:25 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 1.2620
2022-07-08 13:01:58 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 1.3112
2022-07-08 13:02:31 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 0.9895
2022-07-08 13:03:04 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 0.9563
2022-07-08 13:03:38 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 1.0641
2022-07-08 13:04:11 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 1.1909
2022-07-08 13:04:44 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 1.1884
2022-07-08 13:05:18 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 1.1420
2022-07-08 13:05:51 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 1.1258
2022-07-08 13:06:25 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 1.1121
2022-07-08 13:06:57 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 1.1731
2022-07-08 13:07:31 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 1.0644
2022-07-08 13:08:04 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 1.1378
2022-07-08 13:08:37 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 1.3081
2022-07-08 13:09:10 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 0.9975
2022-07-08 13:09:45 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 1.0422
2022-07-08 13:10:18 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 1.3937
2022-07-08 13:10:51 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 1.2340
2022-07-08 13:11:25 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 1.2534
2022-07-08 13:11:57 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 1.2106
2022-07-08 13:12:31 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 1.1730
2022-07-08 13:13:05 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 1.0381
2022-07-08 13:13:39 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 1.1460
2022-07-08 13:14:12 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 1.3667
2022-07-08 13:14:46 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 1.1495
2022-07-08 13:15:19 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 1.4319
2022-07-08 13:15:52 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 1.2040
2022-07-08 13:16:25 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 0.9735
2022-07-08 13:16:58 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 1.1647
2022-07-08 13:17:32 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 1.2316
2022-07-08 13:18:06 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 1.2938
2022-07-08 13:18:39 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 1.1775
2022-07-08 13:19:12 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 1.3646
2022-07-08 13:19:44 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 1.1775
2022-07-08 13:19:44 - train: epoch 083, train_loss: 1.1589
2022-07-08 13:20:59 - eval: epoch: 083, acc1: 72.220%, acc5: 90.740%, test_loss: 1.1155, per_image_load_time: 2.629ms, per_image_inference_time: 0.256ms
2022-07-08 13:20:59 - until epoch: 083, best_acc1: 72.292%
2022-07-08 13:20:59 - epoch 084 lr: 0.001000
2022-07-08 13:21:37 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 1.0818
2022-07-08 13:22:11 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 1.2550
2022-07-08 13:22:43 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 1.0248
2022-07-08 13:23:17 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 1.1235
2022-07-08 13:23:50 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 1.1567
2022-07-08 13:24:23 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 1.3940
2022-07-08 13:24:56 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 1.2342
2022-07-08 13:25:28 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 1.2675
2022-07-08 13:26:02 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 1.1445
2022-07-08 13:26:34 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 1.1919
2022-07-08 13:27:08 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 1.1762
2022-07-08 13:27:41 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 1.3725
2022-07-08 13:28:14 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 1.1540
2022-07-08 13:28:47 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 1.2353
2022-07-08 13:29:21 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 1.1691
2022-07-08 13:29:53 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 1.0641
2022-07-08 13:30:28 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 1.2322
2022-07-08 13:31:00 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 1.1771
2022-07-08 13:31:34 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 1.2042
2022-07-08 13:32:07 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 1.2649
2022-07-08 13:32:40 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 1.0828
2022-07-08 13:33:13 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 1.0429
2022-07-08 13:33:47 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 1.1418
2022-07-08 13:34:20 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 1.0355
2022-07-08 13:34:54 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 1.3042
2022-07-08 13:35:27 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 1.2184
2022-07-08 13:36:00 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 1.1889
2022-07-08 13:36:34 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 1.2832
2022-07-08 13:37:07 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 1.0670
2022-07-08 13:37:41 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 1.1072
2022-07-08 13:38:14 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 1.1372
2022-07-08 13:38:47 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 1.0844
2022-07-08 13:39:21 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 1.1220
2022-07-08 13:39:55 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 1.0491
2022-07-08 13:40:27 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 1.0030
2022-07-08 13:41:01 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 1.1100
2022-07-08 13:41:35 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 1.2341
2022-07-08 13:42:09 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 1.3278
2022-07-08 13:42:42 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 1.2286
2022-07-08 13:43:15 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 1.2019
2022-07-08 13:43:49 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 1.2659
2022-07-08 13:44:22 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 1.2370
2022-07-08 13:44:54 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 1.1285
2022-07-08 13:45:28 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 1.4128
2022-07-08 13:46:01 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 1.1238
2022-07-08 13:46:35 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 1.1758
2022-07-08 13:47:08 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 1.4366
2022-07-08 13:47:42 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 1.0470
2022-07-08 13:48:15 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 1.0178
2022-07-08 13:48:47 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 1.2400
2022-07-08 13:48:48 - train: epoch 084, train_loss: 1.1553
2022-07-08 13:50:01 - eval: epoch: 084, acc1: 72.288%, acc5: 90.774%, test_loss: 1.1167, per_image_load_time: 1.445ms, per_image_inference_time: 0.285ms
2022-07-08 13:50:01 - until epoch: 084, best_acc1: 72.292%
2022-07-08 13:50:01 - epoch 085 lr: 0.001000
2022-07-08 13:50:40 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 1.0625
2022-07-08 13:51:13 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 1.0071
2022-07-08 13:51:45 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 1.2870
2022-07-08 13:52:18 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 1.0952
2022-07-08 13:52:50 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 1.3453
2022-07-08 13:53:23 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 0.9622
2022-07-08 13:53:55 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 1.0627
2022-07-08 13:54:28 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 1.0405
2022-07-08 13:55:01 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 1.0336
2022-07-08 13:55:34 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 1.2756
2022-07-08 13:56:07 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 1.1531
2022-07-08 13:56:40 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 1.0065
2022-07-08 13:57:13 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 1.1144
2022-07-08 13:57:46 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 1.1905
2022-07-08 13:58:20 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 0.9919
2022-07-08 13:58:54 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 1.1624
2022-07-08 13:59:26 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 1.3985
2022-07-08 14:00:00 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 0.9860
2022-07-08 14:00:33 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 1.0631
2022-07-08 14:01:06 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 1.1618
2022-07-08 14:01:40 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 0.8979
2022-07-08 14:02:12 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 1.2458
2022-07-08 14:02:46 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 0.9893
2022-07-08 14:03:19 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 1.1596
2022-07-08 14:03:52 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 1.3606
2022-07-08 14:04:25 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 1.2012
2022-07-08 14:04:59 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 1.0577
2022-07-08 14:05:32 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 1.2709
2022-07-08 14:06:05 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 1.2650
2022-07-08 14:06:39 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 1.3308
2022-07-08 14:07:12 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 1.1327
2022-07-08 14:07:45 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 1.1032
2022-07-08 14:08:18 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 1.1096
2022-07-08 14:08:52 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 1.2531
2022-07-08 14:09:26 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 1.1860
2022-07-08 14:09:58 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 1.1687
2022-07-08 14:10:32 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 1.0088
2022-07-08 14:11:05 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 1.0752
2022-07-08 14:11:39 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 1.1213
2022-07-08 14:12:12 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 1.3385
2022-07-08 14:12:45 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 1.1730
2022-07-08 14:13:18 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 1.2521
2022-07-08 14:13:51 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 1.0851
2022-07-08 14:14:24 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 1.1302
2022-07-08 14:14:58 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 1.3171
2022-07-08 14:15:31 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 1.1466
2022-07-08 14:16:04 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 1.3957
2022-07-08 14:16:38 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 0.9904
2022-07-08 14:17:12 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 1.1448
2022-07-08 14:17:43 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 1.1105
2022-07-08 14:17:44 - train: epoch 085, train_loss: 1.1569
2022-07-08 14:18:58 - eval: epoch: 085, acc1: 72.226%, acc5: 90.650%, test_loss: 1.1190, per_image_load_time: 1.551ms, per_image_inference_time: 0.254ms
2022-07-08 14:18:58 - until epoch: 085, best_acc1: 72.292%
2022-07-08 14:18:58 - epoch 086 lr: 0.001000
2022-07-08 14:19:36 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 1.0200
2022-07-08 14:20:09 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 1.0381
2022-07-08 14:20:42 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 1.2720
2022-07-08 14:21:14 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 1.2514
2022-07-08 14:21:47 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 1.1196
2022-07-08 14:22:21 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 1.0675
2022-07-08 14:22:54 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 1.0978
2022-07-08 14:23:27 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 1.3012
2022-07-08 14:24:00 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 1.2793
2022-07-08 14:24:33 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 1.2042
2022-07-08 14:25:07 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 1.1756
2022-07-08 14:25:40 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 1.0240
2022-07-08 14:26:14 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 1.1977
2022-07-08 14:26:47 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 1.0579
2022-07-08 14:27:19 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 0.9490
2022-07-08 14:27:53 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 1.2020
2022-07-08 14:28:26 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 1.0799
2022-07-08 14:28:59 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 1.2184
2022-07-08 14:29:32 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 1.2889
2022-07-08 14:30:06 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 1.1959
2022-07-08 14:30:39 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 1.0020
2022-07-08 14:31:12 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 1.1953
2022-07-08 14:31:45 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 1.0323
2022-07-08 14:32:19 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 0.9191
2022-07-08 14:32:51 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 1.1098
2022-07-08 14:33:25 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 1.1339
2022-07-08 14:33:58 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 1.0465
2022-07-08 14:34:32 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 1.3119
2022-07-08 14:35:05 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 1.0390
2022-07-08 14:35:38 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 1.3129
2022-07-08 14:36:11 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 1.1704
2022-07-08 14:36:44 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 1.2504
2022-07-08 14:37:18 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 1.2779
2022-07-08 14:37:51 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 1.2467
2022-07-08 14:38:25 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 1.2316
2022-07-08 14:38:58 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 1.1396
2022-07-08 14:39:32 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 1.3066
2022-07-08 14:40:04 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 1.1815
2022-07-08 14:40:38 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 1.2218
2022-07-08 14:41:11 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 1.1833
2022-07-08 14:41:44 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 1.2418
2022-07-08 14:42:18 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 1.1781
2022-07-08 14:42:51 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 1.1734
2022-07-08 14:43:24 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 1.1115
2022-07-08 14:43:57 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 1.0837
2022-07-08 14:44:31 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 1.0981
2022-07-08 14:45:04 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 1.1060
2022-07-08 14:45:37 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 1.1594
2022-07-08 14:46:11 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 1.1896
2022-07-08 14:46:42 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 1.2805
2022-07-08 14:46:43 - train: epoch 086, train_loss: 1.1521
2022-07-08 14:47:56 - eval: epoch: 086, acc1: 72.274%, acc5: 90.720%, test_loss: 1.1184, per_image_load_time: 2.279ms, per_image_inference_time: 0.279ms
2022-07-08 14:47:56 - until epoch: 086, best_acc1: 72.292%
2022-07-08 14:47:56 - epoch 087 lr: 0.001000
2022-07-08 14:48:34 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 1.2042
2022-07-08 14:49:07 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 1.0025
2022-07-08 14:49:39 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 1.3849
2022-07-08 14:50:12 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 1.2725
2022-07-08 14:50:46 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 0.9459
2022-07-08 14:51:18 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 1.1285
2022-07-08 14:51:51 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 0.9556
2022-07-08 14:52:24 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 1.2164
2022-07-08 14:52:57 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 1.3273
2022-07-08 14:53:31 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 1.1804
2022-07-08 14:54:04 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 1.2152
2022-07-08 14:54:37 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 1.2233
2022-07-08 14:55:11 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 1.2727
2022-07-08 14:55:43 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 1.1473
2022-07-08 14:56:17 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 1.0732
2022-07-08 14:56:49 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 1.0093
2022-07-08 14:57:24 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 1.1764
2022-07-08 14:57:57 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 1.2143
2022-07-08 14:58:30 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 1.1955
2022-07-08 14:59:04 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 1.1649
2022-07-08 14:59:37 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 1.3296
2022-07-08 15:00:10 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 1.1490
2022-07-08 15:00:44 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 1.2773
2022-07-08 15:01:17 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 1.0979
2022-07-08 15:01:50 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 1.1337
2022-07-08 15:02:24 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 1.1561
2022-07-08 15:02:57 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 1.1476
2022-07-08 15:03:30 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 1.0063
2022-07-08 15:04:05 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 1.0452
2022-07-08 15:04:38 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 1.2057
2022-07-08 15:05:11 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 1.1903
2022-07-08 15:05:45 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 1.0988
2022-07-08 15:06:18 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 1.1385
2022-07-08 15:06:52 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 1.2191
2022-07-08 15:07:25 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 1.0451
2022-07-08 15:07:58 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 1.0510
2022-07-08 15:08:32 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 1.0857
2022-07-08 15:09:05 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 1.1204
2022-07-08 15:09:39 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 1.1330
2022-07-08 15:10:12 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 1.2362
2022-07-08 15:10:45 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 1.2376
2022-07-08 15:11:20 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 1.2634
2022-07-08 15:11:52 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 1.1577
2022-07-08 15:12:25 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 1.1776
2022-07-08 15:12:59 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 1.2360
2022-07-08 15:13:32 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 1.1150
2022-07-08 15:14:06 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 1.1673
2022-07-08 15:14:39 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 1.0538
2022-07-08 15:15:13 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 1.0953
2022-07-08 15:15:44 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 1.2080
2022-07-08 15:15:45 - train: epoch 087, train_loss: 1.1505
2022-07-08 15:16:58 - eval: epoch: 087, acc1: 72.268%, acc5: 90.632%, test_loss: 1.1197, per_image_load_time: 2.440ms, per_image_inference_time: 0.257ms
2022-07-08 15:16:58 - until epoch: 087, best_acc1: 72.292%
2022-07-08 15:16:58 - epoch 088 lr: 0.001000
2022-07-08 15:17:37 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 1.1601
2022-07-08 15:18:10 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 1.1090
2022-07-08 15:18:43 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 1.2175
2022-07-08 15:19:15 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 1.2347
2022-07-08 15:19:49 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 1.0260
2022-07-08 15:20:20 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 1.1590
2022-07-08 15:20:54 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 1.1466
2022-07-08 15:21:26 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 1.1327
2022-07-08 15:21:59 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 1.1857
2022-07-08 15:22:33 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 1.0444
2022-07-08 15:23:06 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 1.0883
2022-07-08 15:23:40 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 1.0720
2022-07-08 15:24:12 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 1.2409
2022-07-08 15:24:46 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 1.0791
2022-07-08 15:25:18 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 1.2439
2022-07-08 15:25:52 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 1.0070
2022-07-08 15:26:25 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 1.2590
2022-07-08 15:26:59 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 1.1145
2022-07-08 15:27:31 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 1.2597
2022-07-08 15:28:05 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 0.9813
2022-07-08 15:28:38 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 1.1578
2022-07-08 15:29:11 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 1.0716
2022-07-08 15:29:44 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 0.9868
2022-07-08 15:30:17 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 1.2712
2022-07-08 15:30:51 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 1.2136
2022-07-08 15:31:24 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 1.2863
2022-07-08 15:31:58 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 1.2223
2022-07-08 15:32:32 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 1.1487
2022-07-08 15:33:05 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 1.0985
2022-07-08 15:33:38 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 1.2799
2022-07-08 15:34:11 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 1.0474
2022-07-08 15:34:45 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 1.0402
2022-07-08 15:35:17 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 1.0173
2022-07-08 15:35:51 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 0.9341
2022-07-08 15:36:25 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 1.0543
2022-07-08 15:36:57 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 1.1909
2022-07-08 15:37:31 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 1.1728
2022-07-08 15:38:04 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 1.0906
2022-07-08 15:38:37 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 1.2828
2022-07-08 15:39:11 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 0.9661
2022-07-08 15:39:44 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 1.2844
2022-07-08 15:40:17 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 1.2359
2022-07-08 15:40:51 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 1.0865
2022-07-08 15:41:24 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 1.0471
2022-07-08 15:41:57 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 1.1408
2022-07-08 15:42:30 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 1.2363
2022-07-08 15:43:03 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 1.2059
2022-07-08 15:43:37 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 1.0115
2022-07-08 15:44:11 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 0.9380
2022-07-08 15:44:42 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 1.1868
2022-07-08 15:44:42 - train: epoch 088, train_loss: 1.1489
2022-07-08 15:45:55 - eval: epoch: 088, acc1: 72.442%, acc5: 90.640%, test_loss: 1.1147, per_image_load_time: 2.521ms, per_image_inference_time: 0.306ms
2022-07-08 15:45:56 - until epoch: 088, best_acc1: 72.442%
2022-07-08 15:45:56 - epoch 089 lr: 0.001000
2022-07-08 15:46:33 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 1.3978
2022-07-08 15:47:06 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 0.9048
2022-07-08 15:47:39 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 1.1786
2022-07-08 15:48:12 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 1.0846
2022-07-08 15:48:44 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 1.1337
2022-07-08 15:49:18 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 1.1559
2022-07-08 15:49:52 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 1.2088
2022-07-08 15:50:24 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 1.2773
2022-07-08 15:50:58 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 1.2444
2022-07-08 15:51:30 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 1.2989
2022-07-08 15:52:04 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 1.0799
2022-07-08 15:52:37 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 1.2766
2022-07-08 15:53:10 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 1.1347
2022-07-08 15:53:44 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 1.1963
2022-07-08 15:54:16 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 1.1281
2022-07-08 15:54:49 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 1.0477
2022-07-08 15:55:24 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 1.1970
2022-07-08 15:55:56 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 1.1643
2022-07-08 15:56:29 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 1.0362
2022-07-08 15:57:03 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 1.1329
2022-07-08 15:57:36 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 1.2895
2022-07-08 15:58:09 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 1.1894
2022-07-08 15:58:42 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 1.0863
2022-07-08 15:59:16 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 1.2322
2022-07-08 15:59:49 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 1.1488
2022-07-08 16:00:22 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 1.1460
2022-07-08 16:00:56 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 0.9644
2022-07-08 16:01:29 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 1.1611
2022-07-08 16:02:02 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 1.1113
2022-07-08 16:02:35 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 1.1844
2022-07-08 16:03:08 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 1.3090
2022-07-08 16:03:41 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 1.2403
2022-07-08 16:04:15 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 1.3204
2022-07-08 16:04:48 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 1.2093
2022-07-08 16:05:21 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 0.9693
2022-07-08 16:05:54 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 1.0813
2022-07-08 16:06:28 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 1.3168
2022-07-08 16:07:01 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 1.0496
2022-07-08 16:07:35 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 1.2373
2022-07-08 16:08:08 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 0.9677
2022-07-08 16:08:42 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 1.4140
2022-07-08 16:09:15 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 1.0821
2022-07-08 16:09:50 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 1.1765
2022-07-08 16:10:22 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 1.1126
2022-07-08 16:10:56 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 0.9803
2022-07-08 16:11:29 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 1.1210
2022-07-08 16:12:03 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 1.1833
2022-07-08 16:12:36 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 1.1635
2022-07-08 16:13:09 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 1.1672
2022-07-08 16:13:41 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 0.8868
2022-07-08 16:13:42 - train: epoch 089, train_loss: 1.1478
2022-07-08 16:14:55 - eval: epoch: 089, acc1: 72.314%, acc5: 90.796%, test_loss: 1.1119, per_image_load_time: 2.420ms, per_image_inference_time: 0.309ms
2022-07-08 16:14:55 - until epoch: 089, best_acc1: 72.442%
2022-07-08 16:14:55 - epoch 090 lr: 0.001000
2022-07-08 16:15:33 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 1.1710
2022-07-08 16:16:05 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 1.1827
2022-07-08 16:16:39 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 1.0584
2022-07-08 16:17:13 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 1.0311
2022-07-08 16:17:45 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 1.2134
2022-07-08 16:18:17 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 1.3007
2022-07-08 16:18:51 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 1.2067
2022-07-08 16:19:24 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 1.1108
2022-07-08 16:19:56 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 1.0987
2022-07-08 16:20:30 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 0.9624
2022-07-08 16:21:03 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 1.1055
2022-07-08 16:21:36 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 1.1352
2022-07-08 16:22:09 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 1.3230
2022-07-08 16:22:42 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 1.0673
2022-07-08 16:23:15 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 1.3608
2022-07-08 16:23:49 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 1.0630
2022-07-08 16:24:22 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 1.0028
2022-07-08 16:24:54 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 1.0425
2022-07-08 16:25:28 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 1.0297
2022-07-08 16:26:02 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 1.2828
2022-07-08 16:26:34 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 1.2458
2022-07-08 16:27:07 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 1.2695
2022-07-08 16:27:40 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 1.2671
2022-07-08 16:28:14 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 1.1824
2022-07-08 16:28:48 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 1.2784
2022-07-08 16:29:21 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 1.2135
2022-07-08 16:29:53 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 1.0702
2022-07-08 16:30:27 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 1.1816
2022-07-08 16:31:00 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 1.0996
2022-07-08 16:31:34 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 1.1245
2022-07-08 16:32:06 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 1.0454
2022-07-08 16:32:41 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 1.0724
2022-07-08 16:33:13 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 1.2190
2022-07-08 16:33:47 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 0.9929
2022-07-08 16:34:20 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 1.0824
2022-07-08 16:34:53 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 1.0310
2022-07-08 16:35:26 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 1.1158
2022-07-08 16:36:00 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 1.1566
2022-07-08 16:36:33 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 0.9160
2022-07-08 16:37:07 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 1.1722
2022-07-08 16:37:40 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 1.4946
2022-07-08 16:38:13 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 1.1859
2022-07-08 16:38:47 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 1.1774
2022-07-08 16:39:20 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 1.1748
2022-07-08 16:39:52 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 1.1472
2022-07-08 16:40:27 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 1.0802
2022-07-08 16:41:00 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 1.0364
2022-07-08 16:41:34 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 1.2330
2022-07-08 16:42:07 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 1.0255
2022-07-08 16:42:38 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 1.1046
2022-07-08 16:42:39 - train: epoch 090, train_loss: 1.1461
2022-07-08 16:43:53 - eval: epoch: 090, acc1: 72.372%, acc5: 90.620%, test_loss: 1.1127, per_image_load_time: 1.702ms, per_image_inference_time: 0.263ms
2022-07-08 16:43:53 - until epoch: 090, best_acc1: 72.442%
2022-07-08 16:43:53 - epoch 091 lr: 0.000100
2022-07-08 16:44:31 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 0.9835
2022-07-08 16:45:04 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 1.0580
2022-07-08 16:45:37 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 1.1644
2022-07-08 16:46:09 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 1.0126
2022-07-08 16:46:41 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 1.0232
2022-07-08 16:47:14 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 1.1807
2022-07-08 16:47:48 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 1.1166
2022-07-08 16:48:20 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 0.9813
2022-07-08 16:48:54 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 1.1474
2022-07-08 16:49:27 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 1.0086
2022-07-08 16:50:00 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 0.9102
2022-07-08 16:50:34 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 1.2048
2022-07-08 16:51:07 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 1.0919
2022-07-08 16:51:40 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 1.1428
2022-07-08 16:52:13 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 1.1117
2022-07-08 16:52:46 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 1.2479
2022-07-08 16:53:20 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 1.1760
2022-07-08 16:53:53 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 1.1528
2022-07-08 16:54:26 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 1.0271
2022-07-08 16:55:00 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 1.1061
2022-07-08 16:55:33 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 0.9127
2022-07-08 16:56:07 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 1.1865
2022-07-08 16:56:40 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 1.1647
2022-07-08 16:57:13 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 1.0603
2022-07-08 16:57:47 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 1.0752
2022-07-08 16:58:20 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 1.1208
2022-07-08 16:58:54 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 1.0616
2022-07-08 16:59:26 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 1.1435
2022-07-08 16:59:59 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 1.1974
2022-07-08 17:00:32 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 1.2060
2022-07-08 17:01:06 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 1.0279
2022-07-08 17:01:39 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 1.2199
2022-07-08 17:02:12 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 0.9963
2022-07-08 17:02:46 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 1.0116
2022-07-08 17:03:19 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 1.1452
2022-07-08 17:03:52 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 1.0919
2022-07-08 17:04:26 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 1.1454
2022-07-08 17:04:59 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 1.0952
2022-07-08 17:05:32 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 1.0968
2022-07-08 17:06:06 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 1.1238
2022-07-08 17:06:39 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 1.1517
2022-07-08 17:07:13 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 1.1778
2022-07-08 17:07:46 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 1.1775
2022-07-08 17:08:20 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 1.0148
2022-07-08 17:08:53 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 0.9816
2022-07-08 17:09:26 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 1.1485
2022-07-08 17:10:00 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 1.1989
2022-07-08 17:10:33 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 1.1468
2022-07-08 17:11:06 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 1.0381
2022-07-08 17:11:38 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 1.3963
2022-07-08 17:11:39 - train: epoch 091, train_loss: 1.1220
2022-07-08 17:12:52 - eval: epoch: 091, acc1: 72.728%, acc5: 90.888%, test_loss: 1.0983, per_image_load_time: 2.602ms, per_image_inference_time: 0.258ms
2022-07-08 17:12:52 - until epoch: 091, best_acc1: 72.728%
2022-07-08 17:12:52 - epoch 092 lr: 0.000100
2022-07-08 17:13:31 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 1.0550
2022-07-08 17:14:04 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 1.1783
2022-07-08 17:14:36 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 1.1693
2022-07-08 17:15:09 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 0.9498
2022-07-08 17:15:41 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 1.2558
2022-07-08 17:16:14 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 1.1809
2022-07-08 17:16:48 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 1.1290
2022-07-08 17:17:20 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 1.1768
2022-07-08 17:17:53 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 1.0666
2022-07-08 17:18:26 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 1.3826
2022-07-08 17:19:00 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 0.9992
2022-07-08 17:19:32 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 1.0501
2022-07-08 17:20:05 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 1.0263
2022-07-08 17:20:38 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 1.1130
2022-07-08 17:21:11 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 1.0587
2022-07-08 17:21:43 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 1.1206
2022-07-08 17:22:17 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 1.2246
2022-07-08 17:22:50 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 1.0312
2022-07-08 17:23:23 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 1.0265
2022-07-08 17:23:56 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 1.0664
2022-07-08 17:24:29 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 1.1558
2022-07-08 17:25:03 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 1.1884
2022-07-08 17:25:37 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 1.0694
2022-07-08 17:26:09 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 1.0368
2022-07-08 17:26:43 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 1.0291
2022-07-08 17:27:17 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 1.2739
2022-07-08 17:27:50 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 1.1339
2022-07-08 17:28:22 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 1.0342
2022-07-08 17:28:57 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 1.1773
2022-07-08 17:29:29 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 1.0265
2022-07-08 17:30:02 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 1.0839
2022-07-08 17:30:36 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 0.9256
2022-07-08 17:31:09 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 1.1907
2022-07-08 17:31:43 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 1.2729
2022-07-08 17:32:16 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 1.0190
2022-07-08 17:32:49 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 1.0425
2022-07-08 17:33:22 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 0.9488
2022-07-08 17:33:55 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 1.3085
2022-07-08 17:34:29 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 1.1556
2022-07-08 17:35:02 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 1.2393
2022-07-08 17:35:35 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 0.9297
2022-07-08 17:36:09 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 1.1338
2022-07-08 17:36:42 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 1.1893
2022-07-08 17:37:15 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 0.9488
2022-07-08 17:37:49 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 1.0537
2022-07-08 17:38:23 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 1.0145
2022-07-08 17:38:56 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 0.8400
2022-07-08 17:39:29 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 0.9886
2022-07-08 17:40:03 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 1.0683
2022-07-08 17:40:34 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 1.2129
2022-07-08 17:40:35 - train: epoch 092, train_loss: 1.1145
2022-07-08 17:41:48 - eval: epoch: 092, acc1: 72.780%, acc5: 90.922%, test_loss: 1.0971, per_image_load_time: 1.882ms, per_image_inference_time: 0.301ms
2022-07-08 17:41:48 - until epoch: 092, best_acc1: 72.780%
2022-07-08 17:41:48 - epoch 093 lr: 0.000100
2022-07-08 17:42:27 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 1.0582
2022-07-08 17:42:59 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 0.9999
2022-07-08 17:43:32 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 1.1406
2022-07-08 17:44:05 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 1.1120
2022-07-08 17:44:38 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 1.1849
2022-07-08 17:45:10 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 1.0805
2022-07-08 17:45:43 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 1.2070
2022-07-08 17:46:17 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 1.0282
2022-07-08 17:46:49 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 1.0379
2022-07-08 17:47:23 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.9298
2022-07-08 17:47:55 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 0.9714
2022-07-08 17:48:28 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 1.0699
2022-07-08 17:49:01 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 1.0891
2022-07-08 17:49:34 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 1.1344
2022-07-08 17:50:07 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 1.3391
2022-07-08 17:50:41 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 1.2257
2022-07-08 17:51:14 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 1.0078
2022-07-08 17:51:47 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 1.1345
2022-07-08 17:52:20 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 1.0592
2022-07-08 17:52:53 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 0.9995
2022-07-08 17:53:26 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 1.0618
2022-07-08 17:53:58 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 1.2919
2022-07-08 17:54:32 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 1.1330
2022-07-08 17:55:04 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 0.9654
2022-07-08 17:55:38 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 1.1029
2022-07-08 17:56:10 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 1.2601
2022-07-08 17:56:43 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 1.0369
2022-07-08 17:57:17 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 1.1339
2022-07-08 17:57:51 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 1.0420
2022-07-08 17:58:24 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 1.0333
2022-07-08 17:58:57 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 1.2759
2022-07-08 17:59:30 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 1.0243
2022-07-08 18:00:03 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 1.1352
2022-07-08 18:00:36 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 1.3316
2022-07-08 18:01:09 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 0.9419
2022-07-08 18:01:42 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 1.2111
2022-07-08 18:02:16 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 0.9833
2022-07-08 18:02:49 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 1.0039
2022-07-08 18:03:23 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 1.2085
2022-07-08 18:03:56 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 1.4037
2022-07-08 18:04:29 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 1.2348
2022-07-08 18:05:02 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 1.1990
2022-07-08 18:05:36 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 1.3080
2022-07-08 18:06:09 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 1.0580
2022-07-08 18:06:42 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 1.1235
2022-07-08 18:07:16 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 0.9703
2022-07-08 18:07:49 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 1.3352
2022-07-08 18:08:22 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 1.0917
2022-07-08 18:08:55 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 1.2507
2022-07-08 18:09:26 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 1.0897
2022-07-08 18:09:28 - train: epoch 093, train_loss: 1.1118
2022-07-08 18:10:42 - eval: epoch: 093, acc1: 72.854%, acc5: 90.956%, test_loss: 1.0956, per_image_load_time: 2.621ms, per_image_inference_time: 0.236ms
2022-07-08 18:10:42 - until epoch: 093, best_acc1: 72.854%
2022-07-08 18:10:42 - epoch 094 lr: 0.000100
2022-07-08 18:11:20 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 1.1782
2022-07-08 18:11:53 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 1.0913
2022-07-08 18:12:26 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 1.2716
2022-07-08 18:12:59 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 1.3320
2022-07-08 18:13:32 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 1.0168
2022-07-08 18:14:05 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 0.9945
2022-07-08 18:14:38 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 1.2300
2022-07-08 18:15:12 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 1.0214
2022-07-08 18:15:44 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 1.0528
2022-07-08 18:16:18 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 1.2040
2022-07-08 18:16:50 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 1.2016
2022-07-08 18:17:23 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 1.1584
2022-07-08 18:17:57 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 1.1051
2022-07-08 18:18:30 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 1.0489
2022-07-08 18:19:04 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 1.1571
2022-07-08 18:19:36 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 1.4685
2022-07-08 18:20:10 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 1.0035
2022-07-08 18:20:44 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 1.0170
2022-07-08 18:21:17 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 1.1177
2022-07-08 18:21:50 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 0.9511
2022-07-08 18:22:24 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 1.1053
2022-07-08 18:22:57 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 0.9430
2022-07-08 18:23:30 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 0.9982
2022-07-08 18:24:04 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 1.1219
2022-07-08 18:24:36 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 1.0352
2022-07-08 18:25:11 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 0.9219
2022-07-08 18:25:43 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 1.0552
2022-07-08 18:26:17 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 1.1086
2022-07-08 18:26:50 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 1.1081
2022-07-08 18:27:24 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 1.0647
2022-07-08 18:27:57 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 1.2399
2022-07-08 18:28:30 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 1.1072
2022-07-08 18:29:03 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 1.1223
2022-07-08 18:29:37 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 1.2299
2022-07-08 18:30:10 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 1.3197
2022-07-08 18:30:43 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 1.0845
2022-07-08 18:31:17 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 1.2353
2022-07-08 18:31:50 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 1.0518
2022-07-08 18:32:24 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 1.0752
2022-07-08 18:32:57 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 1.2694
2022-07-08 18:33:30 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 1.3197
2022-07-08 18:34:03 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 0.9233
2022-07-08 18:34:37 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 1.2415
2022-07-08 18:35:10 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 1.2597
2022-07-08 18:35:44 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 1.1561
2022-07-08 18:36:16 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 1.1115
2022-07-08 18:36:49 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 1.0937
2022-07-08 18:37:22 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 1.0108
2022-07-08 18:37:56 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 1.0451
2022-07-08 18:38:27 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 1.0224
2022-07-08 18:38:28 - train: epoch 094, train_loss: 1.1118
2022-07-08 18:39:41 - eval: epoch: 094, acc1: 72.894%, acc5: 90.944%, test_loss: 1.0948, per_image_load_time: 2.518ms, per_image_inference_time: 0.272ms
2022-07-08 18:39:42 - until epoch: 094, best_acc1: 72.894%
2022-07-08 18:39:42 - epoch 095 lr: 0.000100
2022-07-08 18:40:20 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 1.0668
2022-07-08 18:40:52 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 1.2635
2022-07-08 18:41:25 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 1.0462
2022-07-08 18:41:58 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 1.1614
2022-07-08 18:42:30 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 1.2236
2022-07-08 18:43:03 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 1.1366
2022-07-08 18:43:36 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 1.1879
2022-07-08 18:44:09 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 1.3201
2022-07-08 18:44:42 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 1.3828
2022-07-08 18:45:15 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 1.1822
2022-07-08 18:45:48 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 1.0756
2022-07-08 18:46:21 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 0.9849
2022-07-08 18:46:54 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 1.0843
2022-07-08 18:47:27 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 1.1616
2022-07-08 18:47:59 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 1.1368
2022-07-08 18:48:33 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.8145
2022-07-08 18:49:06 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 1.1573
2022-07-08 18:49:39 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 1.0920
2022-07-08 18:50:12 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 1.0342
2022-07-08 18:50:46 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 1.1648
2022-07-08 18:51:19 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 1.1139
2022-07-08 18:51:53 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 0.8878
2022-07-08 18:52:26 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 1.1025
2022-07-08 18:53:00 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 1.2043
2022-07-08 18:53:32 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 1.0123
2022-07-08 18:54:06 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 1.0025
2022-07-08 18:54:39 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 1.1002
2022-07-08 18:55:12 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 1.0155
2022-07-08 18:55:46 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 1.0999
2022-07-08 18:56:19 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 1.2350
2022-07-08 18:56:52 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 1.2590
2022-07-08 18:57:26 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 1.1760
2022-07-08 18:57:58 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 1.1537
2022-07-08 18:58:32 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 1.0498
2022-07-08 18:59:05 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 0.9790
2022-07-08 18:59:39 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 1.0580
2022-07-08 19:00:12 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 0.9810
2022-07-08 19:00:45 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 0.9135
2022-07-08 19:01:20 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 1.1640
2022-07-08 19:01:52 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 0.9048
2022-07-08 19:02:25 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 1.2258
2022-07-08 19:02:58 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 0.9883
2022-07-08 19:03:32 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 1.1716
2022-07-08 19:04:05 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 1.1449
2022-07-08 19:04:39 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 1.0371
2022-07-08 19:05:12 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 1.1449
2022-07-08 19:05:45 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 1.0632
2022-07-08 19:06:19 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 1.1095
2022-07-08 19:06:51 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 1.0428
2022-07-08 19:07:23 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 0.9578
2022-07-08 19:07:24 - train: epoch 095, train_loss: 1.1117
2022-07-08 19:08:37 - eval: epoch: 095, acc1: 72.864%, acc5: 90.956%, test_loss: 1.0955, per_image_load_time: 2.586ms, per_image_inference_time: 0.262ms
2022-07-08 19:08:37 - until epoch: 095, best_acc1: 72.894%
2022-07-08 19:08:37 - epoch 096 lr: 0.000100
2022-07-08 19:09:16 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 1.1684
2022-07-08 19:09:48 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 1.0273
2022-07-08 19:10:21 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 1.1713
2022-07-08 19:10:54 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 0.9502
2022-07-08 19:11:26 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 1.0940
2022-07-08 19:11:59 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 1.2104
2022-07-08 19:12:31 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 0.9989
2022-07-08 19:13:05 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 1.0202
2022-07-08 19:13:38 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 1.1020
2022-07-08 19:14:12 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 1.1145
2022-07-08 19:14:44 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 1.1913
2022-07-08 19:15:19 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 1.1614
2022-07-08 19:15:50 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 1.1380
2022-07-08 19:16:24 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 1.0322
2022-07-08 19:16:56 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 0.9830
2022-07-08 19:17:30 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 0.8364
2022-07-08 19:18:03 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 1.1808
2022-07-08 19:18:37 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 1.1633
2022-07-08 19:19:09 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 1.2355
2022-07-08 19:19:43 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 0.9345
2022-07-08 19:20:16 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 1.1570
2022-07-08 19:20:49 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.9313
2022-07-08 19:21:23 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 1.0436
2022-07-08 19:21:55 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 0.9667
2022-07-08 19:22:29 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 1.0012
2022-07-08 19:23:03 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 1.0531
2022-07-08 19:23:36 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 1.1041
2022-07-08 19:24:09 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 1.1296
2022-07-08 19:24:43 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 1.0385
2022-07-08 19:25:16 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 1.0899
2022-07-08 19:25:50 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 1.1940
2022-07-08 19:26:23 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 1.0983
2022-07-08 19:26:56 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 1.2756
2022-07-08 19:27:28 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 0.8635
2022-07-08 19:28:02 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 0.9862
2022-07-08 19:28:34 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 0.9770
2022-07-08 19:29:09 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 1.1199
2022-07-08 19:29:41 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 1.0400
2022-07-08 19:30:15 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 1.0544
2022-07-08 19:30:48 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 0.9475
2022-07-08 19:31:21 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 1.0181
2022-07-08 19:31:55 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 1.0972
2022-07-08 19:32:29 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.8646
2022-07-08 19:33:01 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 1.0862
2022-07-08 19:33:35 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 1.0984
2022-07-08 19:34:08 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 1.0576
2022-07-08 19:34:41 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 1.1256
2022-07-08 19:35:14 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 1.1920
2022-07-08 19:35:48 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 1.3209
2022-07-08 19:36:19 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 1.0754
2022-07-08 19:36:20 - train: epoch 096, train_loss: 1.1084
2022-07-08 19:37:33 - eval: epoch: 096, acc1: 72.828%, acc5: 90.966%, test_loss: 1.0945, per_image_load_time: 2.541ms, per_image_inference_time: 0.257ms
2022-07-08 19:37:33 - until epoch: 096, best_acc1: 72.894%
2022-07-08 19:37:33 - epoch 097 lr: 0.000100
2022-07-08 19:38:11 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 1.2118
2022-07-08 19:38:44 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 0.9372
2022-07-08 19:39:16 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 1.2365
2022-07-08 19:39:50 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 1.3421
2022-07-08 19:40:22 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 1.1329
2022-07-08 19:40:56 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 1.2746
2022-07-08 19:41:28 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 1.0781
2022-07-08 19:42:01 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.9598
2022-07-08 19:42:34 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 1.0494
2022-07-08 19:43:08 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 1.0175
2022-07-08 19:43:41 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 0.9508
2022-07-08 19:44:15 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 1.1029
2022-07-08 19:44:47 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 1.0217
2022-07-08 19:45:22 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 1.0520
2022-07-08 19:45:54 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 1.1117
2022-07-08 19:46:27 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 1.0045
2022-07-08 19:47:01 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 1.0136
2022-07-08 19:47:34 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 1.1176
2022-07-08 19:48:06 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 1.0750
2022-07-08 19:48:41 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 1.1261
2022-07-08 19:49:13 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 1.1388
2022-07-08 19:49:47 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 1.2178
2022-07-08 19:50:20 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 1.0115
2022-07-08 19:50:54 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 1.0979
2022-07-08 19:51:27 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 1.1569
2022-07-08 19:52:00 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 1.2100
2022-07-08 19:52:33 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 0.9247
2022-07-08 19:53:07 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 1.0212
2022-07-08 19:53:40 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 1.2644
2022-07-08 19:54:12 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 1.1450
2022-07-08 19:54:45 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 1.0718
2022-07-08 19:55:20 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 1.0854
2022-07-08 19:55:53 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 1.1666
2022-07-08 19:56:26 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 1.2829
2022-07-08 19:56:59 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 1.1704
2022-07-08 19:57:33 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 1.0414
2022-07-08 19:58:05 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 0.9438
2022-07-08 19:58:40 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 0.9745
2022-07-08 19:59:11 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 1.0672
2022-07-08 19:59:45 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 1.1481
2022-07-08 20:00:18 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 1.0412
2022-07-08 20:00:52 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 1.0893
2022-07-08 20:01:25 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 0.9863
2022-07-08 20:01:58 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 1.0361
2022-07-08 20:02:32 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 1.1307
2022-07-08 20:03:05 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 1.2351
2022-07-08 20:03:39 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 1.1297
2022-07-08 20:04:12 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 1.1242
2022-07-08 20:04:45 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 1.2698
2022-07-08 20:05:16 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 1.2448
2022-07-08 20:05:17 - train: epoch 097, train_loss: 1.1092
2022-07-08 20:06:30 - eval: epoch: 097, acc1: 72.902%, acc5: 90.970%, test_loss: 1.0922, per_image_load_time: 2.528ms, per_image_inference_time: 0.302ms
2022-07-08 20:06:30 - until epoch: 097, best_acc1: 72.902%
2022-07-08 20:06:30 - epoch 098 lr: 0.000100
2022-07-08 20:07:09 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 1.1889
2022-07-08 20:07:42 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 1.2102
2022-07-08 20:08:15 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 1.3215
2022-07-08 20:08:47 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 1.0460
2022-07-08 20:09:21 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 1.1385
2022-07-08 20:09:54 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 1.1314
2022-07-08 20:10:27 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 1.1461
2022-07-08 20:10:59 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 1.1709
2022-07-08 20:11:33 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 1.1342
2022-07-08 20:12:07 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 1.0140
2022-07-08 20:12:39 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 0.9492
2022-07-08 20:13:12 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 1.0028
2022-07-08 20:13:45 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 1.2308
2022-07-08 20:14:18 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 1.0809
2022-07-08 20:14:51 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 1.0715
2022-07-08 20:15:25 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 1.0693
2022-07-08 20:15:59 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 1.1415
2022-07-08 20:16:32 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 1.0452
2022-07-08 20:17:05 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 1.0057
2022-07-08 20:17:39 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 1.2606
2022-07-08 20:18:12 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 1.0413
2022-07-08 20:18:46 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 1.1018
2022-07-08 20:19:18 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 1.0313
2022-07-08 20:19:52 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 1.0227
2022-07-08 20:20:25 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 1.2483
2022-07-08 20:20:58 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 1.0985
2022-07-08 20:21:31 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 1.2104
2022-07-08 20:22:04 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 1.0880
2022-07-08 20:22:38 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 1.1428
2022-07-08 20:23:11 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 1.0846
2022-07-08 20:23:45 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 1.0011
2022-07-08 20:24:18 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 0.9305
2022-07-08 20:24:51 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 1.0343
2022-07-08 20:25:25 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 1.0898
2022-07-08 20:25:59 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 1.1001
2022-07-08 20:26:31 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 1.3518
2022-07-08 20:27:04 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 1.1495
2022-07-08 20:27:37 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 1.1244
2022-07-08 20:28:10 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 0.9943
2022-07-08 20:28:44 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 1.1908
2022-07-08 20:29:17 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 1.1708
2022-07-08 20:29:51 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 1.0570
2022-07-08 20:30:24 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 0.9627
2022-07-08 20:30:58 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 1.3178
2022-07-08 20:31:31 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 1.2262
2022-07-08 20:32:05 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 1.1701
2022-07-08 20:32:37 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 1.1050
2022-07-08 20:33:10 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 0.8755
2022-07-08 20:33:43 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 1.1468
2022-07-08 20:34:16 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 1.1963
2022-07-08 20:34:16 - train: epoch 098, train_loss: 1.1070
2022-07-08 20:35:30 - eval: epoch: 098, acc1: 72.856%, acc5: 91.020%, test_loss: 1.0930, per_image_load_time: 2.586ms, per_image_inference_time: 0.278ms
2022-07-08 20:35:30 - until epoch: 098, best_acc1: 72.902%
2022-07-08 20:35:30 - epoch 099 lr: 0.000100
2022-07-08 20:36:08 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 0.9971
2022-07-08 20:36:41 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 1.0376
2022-07-08 20:37:13 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 1.0390
2022-07-08 20:37:46 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 1.1764
2022-07-08 20:38:20 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 1.1964
2022-07-08 20:38:53 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 1.0396
2022-07-08 20:39:26 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 1.1048
2022-07-08 20:39:59 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 1.0233
2022-07-08 20:40:32 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 1.0185
2022-07-08 20:41:04 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 1.1193
2022-07-08 20:41:38 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 1.1372
2022-07-08 20:42:11 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 1.0495
2022-07-08 20:42:44 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 1.1883
2022-07-08 20:43:17 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 1.1802
2022-07-08 20:43:51 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 0.9432
2022-07-08 20:44:24 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 1.3300
2022-07-08 20:44:56 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 1.0059
2022-07-08 20:45:31 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 1.1392
2022-07-08 20:46:03 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 1.0588
2022-07-08 20:46:37 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 0.9898
2022-07-08 20:47:11 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 1.0275
2022-07-08 20:47:44 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 1.2150
2022-07-08 20:48:17 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 1.1109
2022-07-08 20:48:51 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 1.2933
2022-07-08 20:49:23 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 1.0697
2022-07-08 20:49:57 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 0.9966
2022-07-08 20:50:30 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 1.1198
2022-07-08 20:51:05 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 1.2267
2022-07-08 20:51:37 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 1.0801
2022-07-08 20:52:11 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 1.2299
2022-07-08 20:52:44 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 1.0025
2022-07-08 20:53:17 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 1.2154
2022-07-08 20:53:50 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 1.0023
2022-07-08 20:54:24 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 1.1161
2022-07-08 20:54:57 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 1.1302
2022-07-08 20:55:31 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 1.0815
2022-07-08 20:56:03 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 0.9398
2022-07-08 20:56:37 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 1.2478
2022-07-08 20:57:10 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 1.1679
2022-07-08 20:57:44 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 1.2007
2022-07-08 20:58:17 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 0.9580
2022-07-08 20:58:51 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 1.0755
2022-07-08 20:59:24 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 1.1878
2022-07-08 20:59:57 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 1.1488
2022-07-08 21:00:30 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 1.2607
2022-07-08 21:01:03 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 1.1660
2022-07-08 21:01:37 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 0.9861
2022-07-08 21:02:10 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 1.2711
2022-07-08 21:02:43 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 1.0807
2022-07-08 21:03:15 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 1.0993
2022-07-08 21:03:16 - train: epoch 099, train_loss: 1.1073
2022-07-08 21:04:29 - eval: epoch: 099, acc1: 72.892%, acc5: 90.964%, test_loss: 1.0931, per_image_load_time: 2.561ms, per_image_inference_time: 0.284ms
2022-07-08 21:04:29 - until epoch: 099, best_acc1: 72.902%
2022-07-08 21:04:29 - epoch 100 lr: 0.000100
2022-07-08 21:05:08 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 1.1057
2022-07-08 21:05:41 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 1.1515
2022-07-08 21:06:14 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 1.0259
2022-07-08 21:06:47 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 0.8763
2022-07-08 21:07:20 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 1.0903
2022-07-08 21:07:53 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 1.3357
2022-07-08 21:08:27 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 1.0197
2022-07-08 21:09:00 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 1.1298
2022-07-08 21:09:33 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 0.9503
2022-07-08 21:10:06 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 1.1132
2022-07-08 21:10:39 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 1.0124
2022-07-08 21:11:12 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 1.1758
2022-07-08 21:11:45 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 1.1458
2022-07-08 21:12:18 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 1.1324
2022-07-08 21:12:51 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 1.1500
2022-07-08 21:13:25 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 1.0250
2022-07-08 21:13:58 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 1.1397
2022-07-08 21:14:31 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 1.1464
2022-07-08 21:15:04 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 1.0838
2022-07-08 21:15:37 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 1.0613
2022-07-08 21:16:10 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 0.9818
2022-07-08 21:16:43 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 1.2547
