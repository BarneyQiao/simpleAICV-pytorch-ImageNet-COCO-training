2022-02-24 07:50:15 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 1.3476
2022-02-24 07:50:49 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 1.1286
2022-02-24 07:51:22 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 1.1641
2022-02-24 07:51:55 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 1.2124
2022-02-24 07:52:28 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 1.2273
2022-02-24 07:53:01 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 1.1511
2022-02-24 07:53:34 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 1.4455
2022-02-24 07:54:08 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 1.1904
2022-02-24 07:54:42 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 1.1284
2022-02-24 07:55:15 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 1.1110
2022-02-24 07:55:48 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 1.1442
2022-02-24 07:56:22 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 1.3007
2022-02-24 07:56:55 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 1.2130
2022-02-24 07:57:29 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 1.2424
2022-02-24 07:58:02 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 1.2453
2022-02-24 07:58:35 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 1.1183
2022-02-24 07:59:09 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 1.1920
2022-02-24 07:59:43 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 1.1993
2022-02-24 08:00:17 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 0.9692
2022-02-24 08:00:49 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 1.1548
2022-02-24 08:01:23 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 1.2562
2022-02-24 08:01:56 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 1.0515
2022-02-24 08:02:30 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 1.3333
2022-02-24 08:03:03 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 1.1635
2022-02-24 08:03:38 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 1.1870
2022-02-24 08:04:12 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 1.2544
2022-02-24 08:04:45 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 1.1770
2022-02-24 08:05:30 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 1.1239
2022-02-24 08:06:04 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 1.3663
2022-02-24 08:06:38 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 1.1006
2022-02-24 08:07:13 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 1.2556
2022-02-24 08:07:46 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 1.2341
2022-02-24 08:08:19 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 1.3564
2022-02-24 08:08:53 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 1.2443
2022-02-24 08:09:27 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 1.0559
2022-02-24 08:10:00 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 1.2567
2022-02-24 08:10:33 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 1.2174
2022-02-24 08:10:36 - train: epoch 098, train_loss: 1.2036
2022-02-24 08:11:51 - eval: epoch: 098, acc1: 72.028%, acc5: 90.790%, test_loss: 1.1081, per_image_load_time: 1.067ms, per_image_inference_time: 0.268ms
2022-02-24 08:11:52 - until epoch: 098, best_acc1: 72.074%
2022-02-24 21:52:28 - epoch 099 lr: 0.00010000000000000003
2022-02-24 21:53:07 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 1.2077
2022-02-24 21:53:40 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 1.1354
2022-02-24 21:54:13 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 1.0224
2022-02-24 21:54:48 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 1.1869
2022-02-24 21:55:21 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 1.1512
2022-02-24 21:55:54 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 1.2597
2022-02-24 21:56:28 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 1.1881
2022-02-24 21:57:02 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 1.1601
2022-02-24 21:57:35 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 1.2703
2022-02-24 21:58:09 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 1.1129
2022-02-24 21:58:41 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 1.1711
2022-02-24 21:59:15 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 0.9851
2022-02-24 21:59:49 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 1.1874
2022-02-24 22:00:23 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 1.2424
2022-02-24 22:00:56 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 1.0077
2022-02-24 22:01:29 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 1.2299
2022-02-24 22:02:03 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 1.0871
2022-02-24 22:02:35 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 1.2279
2022-02-24 22:03:10 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 1.1501
2022-02-24 22:03:43 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 1.1998
2022-02-24 22:04:17 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 1.1570
2022-02-24 22:04:51 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 1.1816
2022-02-24 22:05:25 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 1.1315
2022-02-24 22:05:58 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 1.4369
2022-02-24 22:06:32 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 1.2438
2022-02-24 22:07:06 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 1.0837
2022-02-24 22:07:39 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 1.1559
2022-02-24 22:08:12 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 1.1114
2022-02-24 22:08:46 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 1.0287
2022-02-24 22:09:19 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 1.3411
2022-02-24 22:09:52 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 0.9717
2022-02-24 22:10:26 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 1.2597
2022-02-24 22:10:59 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 1.1140
2022-02-24 22:11:33 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 1.2077
2022-02-24 22:12:07 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 1.3316
2022-02-24 22:12:40 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 1.1273
2022-02-24 22:13:13 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 1.0963
2022-02-24 22:13:46 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 1.2264
2022-02-24 22:14:21 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 1.2197
2022-02-24 22:14:53 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 1.2643
2022-02-24 22:15:27 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 1.1154
2022-02-24 22:16:01 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 1.2644
2022-02-24 22:16:35 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 1.1867
2022-02-24 22:17:09 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 1.2497
2022-02-24 22:17:42 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 1.3260
2022-02-24 22:18:16 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 1.2272
2022-02-24 22:18:49 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 1.2191
2022-02-24 22:19:23 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 1.4255
2022-02-24 22:19:56 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 1.2820
2022-02-24 22:20:30 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 1.2547
2022-02-24 22:20:31 - train: epoch 099, train_loss: 1.2064
2022-02-24 22:21:46 - eval: epoch: 099, acc1: 71.994%, acc5: 90.770%, test_loss: 1.1096, per_image_load_time: 2.007ms, per_image_inference_time: 0.280ms
2022-02-24 22:21:46 - until epoch: 099, best_acc1: 72.074%
2022-02-24 22:21:46 - epoch 100 lr: 0.00010000000000000003
2022-02-24 22:22:25 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 1.1844
2022-02-24 22:22:59 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 1.2771
2022-02-24 22:23:32 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 1.2428
2022-02-24 22:24:06 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 1.1060
2022-02-24 22:24:40 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 1.1180
2022-02-24 22:25:14 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 1.1167
2022-02-24 22:25:48 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 1.0960
2022-02-24 22:26:22 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 1.0843
2022-02-24 22:26:56 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 1.0767
2022-02-24 22:27:29 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 1.2067
2022-02-24 22:28:04 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 1.0140
2022-02-24 22:28:38 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 1.3056
2022-02-24 22:29:11 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 1.0516
2022-02-24 22:29:45 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 1.1310
2022-02-24 22:30:18 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 1.1985
2022-02-24 22:30:52 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 1.1549
2022-02-24 22:31:26 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 1.1940
2022-02-24 22:32:00 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 1.1002
2022-02-24 22:32:34 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 1.1659
2022-02-24 22:33:08 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 1.3272
2022-02-24 22:33:42 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 1.0978
2022-02-24 22:34:15 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 1.3398
2022-02-24 22:34:48 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 1.1989
2022-02-24 22:35:22 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 1.2990
2022-02-24 22:35:57 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 1.1415
2022-02-24 22:36:31 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 1.1118
2022-02-24 22:37:04 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 1.1305
2022-02-24 22:37:38 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 1.0973
2022-02-24 22:38:11 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 1.0618
2022-02-24 22:38:45 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 1.1447
2022-02-24 22:39:19 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 1.0720
2022-02-24 22:39:52 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 1.1269
2022-02-24 22:40:27 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 1.1987
2022-02-24 22:41:00 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 1.2948
2022-02-24 22:41:35 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 1.1649
2022-02-24 22:42:08 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 1.2389
2022-02-24 22:42:43 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 1.1523
2022-02-24 22:43:16 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 1.1222
2022-02-24 22:43:50 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 1.2279
2022-02-24 22:44:25 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 1.3001
2022-02-24 22:44:58 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 1.1976
2022-02-24 22:45:31 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 1.3060
2022-02-24 22:46:06 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 1.1342
2022-02-24 22:46:39 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 1.2873
2022-02-24 22:47:14 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 1.0387
2022-02-24 22:47:48 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 1.1618
2022-02-24 22:48:22 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 1.1444
2022-02-24 22:48:56 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 1.0034
2022-02-24 22:49:30 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 1.1955
2022-02-24 22:50:03 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 1.4027
2022-02-24 22:50:04 - train: epoch 100, train_loss: 1.2051
2022-02-24 22:51:19 - eval: epoch: 100, acc1: 72.018%, acc5: 90.806%, test_loss: 1.1085, per_image_load_time: 2.610ms, per_image_inference_time: 0.292ms
2022-02-24 22:51:19 - until epoch: 100, best_acc1: 72.074%
2022-02-24 22:51:19 - train done. model: resnet50half, macs: 1.063G, params: 6.918M, train time: 48.710 hours, best_acc1: 72.074%
