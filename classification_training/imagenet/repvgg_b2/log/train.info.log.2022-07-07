2022-07-07 07:53:47 - train: epoch 0037, iter [04000, 05004], lr: 0.078536, loss: 1.6929
2022-07-07 07:54:33 - train: epoch 0037, iter [04100, 05004], lr: 0.078515, loss: 1.6394
2022-07-07 07:55:18 - train: epoch 0037, iter [04200, 05004], lr: 0.078493, loss: 2.0025
2022-07-07 07:56:03 - train: epoch 0037, iter [04300, 05004], lr: 0.078472, loss: 1.8069
2022-07-07 07:56:48 - train: epoch 0037, iter [04400, 05004], lr: 0.078450, loss: 1.7236
2022-07-07 07:57:32 - train: epoch 0037, iter [04500, 05004], lr: 0.078429, loss: 1.7452
2022-07-07 07:58:17 - train: epoch 0037, iter [04600, 05004], lr: 0.078407, loss: 1.7586
2022-07-07 07:59:02 - train: epoch 0037, iter [04700, 05004], lr: 0.078386, loss: 1.7761
2022-07-07 07:59:47 - train: epoch 0037, iter [04800, 05004], lr: 0.078364, loss: 1.8001
2022-07-07 08:00:32 - train: epoch 0037, iter [04900, 05004], lr: 0.078343, loss: 1.8188
2022-07-07 08:01:18 - train: epoch 0037, iter [05000, 05004], lr: 0.078321, loss: 1.6660
2022-07-07 08:01:20 - train: epoch 037, train_loss: 1.7453
2022-07-07 08:02:36 - eval: epoch: 037, acc1: 64.236%, acc5: 86.700%, test_loss: 1.4681, per_image_load_time: 1.539ms, per_image_inference_time: 0.840ms
2022-07-07 08:02:38 - until epoch: 037, best_acc1: 64.236%
2022-07-07 08:02:38 - epoch 038 lr: 0.078320
2022-07-07 08:03:28 - train: epoch 0038, iter [00100, 05004], lr: 0.078299, loss: 1.6896
2022-07-07 08:04:13 - train: epoch 0038, iter [00200, 05004], lr: 0.078277, loss: 1.4736
2022-07-07 08:04:58 - train: epoch 0038, iter [00300, 05004], lr: 0.078256, loss: 1.4572
2022-07-07 08:05:43 - train: epoch 0038, iter [00400, 05004], lr: 0.078234, loss: 1.6343
2022-07-07 08:06:28 - train: epoch 0038, iter [00500, 05004], lr: 0.078212, loss: 1.5736
2022-07-07 08:07:13 - train: epoch 0038, iter [00600, 05004], lr: 0.078191, loss: 1.7786
2022-07-07 08:07:58 - train: epoch 0038, iter [00700, 05004], lr: 0.078169, loss: 1.5834
2022-07-07 08:08:43 - train: epoch 0038, iter [00800, 05004], lr: 0.078148, loss: 1.5696
2022-07-07 08:09:28 - train: epoch 0038, iter [00900, 05004], lr: 0.078126, loss: 1.6686
2022-07-07 08:10:12 - train: epoch 0038, iter [01000, 05004], lr: 0.078104, loss: 2.0372
2022-07-07 08:10:57 - train: epoch 0038, iter [01100, 05004], lr: 0.078083, loss: 1.7115
2022-07-07 08:11:42 - train: epoch 0038, iter [01200, 05004], lr: 0.078061, loss: 1.6992
2022-07-07 08:12:27 - train: epoch 0038, iter [01300, 05004], lr: 0.078039, loss: 1.8673
2022-07-07 08:13:12 - train: epoch 0038, iter [01400, 05004], lr: 0.078018, loss: 1.8627
2022-07-07 08:13:57 - train: epoch 0038, iter [01500, 05004], lr: 0.077996, loss: 1.8360
2022-07-07 08:14:42 - train: epoch 0038, iter [01600, 05004], lr: 0.077974, loss: 1.8612
2022-07-07 08:15:27 - train: epoch 0038, iter [01700, 05004], lr: 0.077953, loss: 1.8648
2022-07-07 08:16:12 - train: epoch 0038, iter [01800, 05004], lr: 0.077931, loss: 1.8594
2022-07-07 08:16:57 - train: epoch 0038, iter [01900, 05004], lr: 0.077909, loss: 1.7980
2022-07-07 08:17:42 - train: epoch 0038, iter [02000, 05004], lr: 0.077888, loss: 1.6545
2022-07-07 08:18:27 - train: epoch 0038, iter [02100, 05004], lr: 0.077866, loss: 1.7987
2022-07-07 08:19:12 - train: epoch 0038, iter [02200, 05004], lr: 0.077844, loss: 1.6280
2022-07-07 08:19:58 - train: epoch 0038, iter [02300, 05004], lr: 0.077822, loss: 1.9140
2022-07-07 08:20:43 - train: epoch 0038, iter [02400, 05004], lr: 0.077801, loss: 1.9551
2022-07-07 08:21:28 - train: epoch 0038, iter [02500, 05004], lr: 0.077779, loss: 1.7530
2022-07-07 08:22:13 - train: epoch 0038, iter [02600, 05004], lr: 0.077757, loss: 1.7576
2022-07-07 08:22:58 - train: epoch 0038, iter [02700, 05004], lr: 0.077735, loss: 1.8234
2022-07-07 08:23:43 - train: epoch 0038, iter [02800, 05004], lr: 0.077714, loss: 1.9189
2022-07-07 08:24:28 - train: epoch 0038, iter [02900, 05004], lr: 0.077692, loss: 1.9275
2022-07-07 08:25:13 - train: epoch 0038, iter [03000, 05004], lr: 0.077670, loss: 1.7875
2022-07-07 08:25:58 - train: epoch 0038, iter [03100, 05004], lr: 0.077648, loss: 1.7209
2022-07-07 08:26:43 - train: epoch 0038, iter [03200, 05004], lr: 0.077627, loss: 1.4096
2022-07-07 08:27:29 - train: epoch 0038, iter [03300, 05004], lr: 0.077605, loss: 1.4757
2022-07-07 08:28:14 - train: epoch 0038, iter [03400, 05004], lr: 0.077583, loss: 1.6686
2022-07-07 08:28:59 - train: epoch 0038, iter [03500, 05004], lr: 0.077561, loss: 1.7695
2022-07-07 08:29:44 - train: epoch 0038, iter [03600, 05004], lr: 0.077539, loss: 1.7778
2022-07-07 08:30:29 - train: epoch 0038, iter [03700, 05004], lr: 0.077517, loss: 1.5631
2022-07-07 08:31:14 - train: epoch 0038, iter [03800, 05004], lr: 0.077496, loss: 1.8907
2022-07-07 08:31:59 - train: epoch 0038, iter [03900, 05004], lr: 0.077474, loss: 1.8169
2022-07-07 08:32:44 - train: epoch 0038, iter [04000, 05004], lr: 0.077452, loss: 1.8225
2022-07-07 08:33:30 - train: epoch 0038, iter [04100, 05004], lr: 0.077430, loss: 1.5489
2022-07-07 08:34:15 - train: epoch 0038, iter [04200, 05004], lr: 0.077408, loss: 1.5414
2022-07-07 08:35:00 - train: epoch 0038, iter [04300, 05004], lr: 0.077386, loss: 1.9437
2022-07-07 08:35:45 - train: epoch 0038, iter [04400, 05004], lr: 0.077364, loss: 1.8561
2022-07-07 08:36:30 - train: epoch 0038, iter [04500, 05004], lr: 0.077342, loss: 1.7860
2022-07-07 08:37:15 - train: epoch 0038, iter [04600, 05004], lr: 0.077321, loss: 1.9867
2022-07-07 08:38:00 - train: epoch 0038, iter [04700, 05004], lr: 0.077299, loss: 1.5802
2022-07-07 08:38:46 - train: epoch 0038, iter [04800, 05004], lr: 0.077277, loss: 1.7795
2022-07-07 08:39:31 - train: epoch 0038, iter [04900, 05004], lr: 0.077255, loss: 1.7657
2022-07-07 08:40:16 - train: epoch 0038, iter [05000, 05004], lr: 0.077233, loss: 1.5493
2022-07-07 08:40:18 - train: epoch 038, train_loss: 1.7336
2022-07-07 08:41:35 - eval: epoch: 038, acc1: 63.108%, acc5: 85.686%, test_loss: 1.5283, per_image_load_time: 2.063ms, per_image_inference_time: 0.835ms
2022-07-07 08:41:35 - until epoch: 038, best_acc1: 64.236%
2022-07-07 08:41:35 - epoch 039 lr: 0.077232
2022-07-07 08:42:26 - train: epoch 0039, iter [00100, 05004], lr: 0.077210, loss: 1.7150
2022-07-07 08:43:11 - train: epoch 0039, iter [00200, 05004], lr: 0.077188, loss: 1.7442
2022-07-07 08:43:56 - train: epoch 0039, iter [00300, 05004], lr: 0.077166, loss: 1.5589
2022-07-07 08:44:41 - train: epoch 0039, iter [00400, 05004], lr: 0.077144, loss: 1.7749
2022-07-07 08:45:26 - train: epoch 0039, iter [00500, 05004], lr: 0.077122, loss: 1.6459
2022-07-07 08:46:11 - train: epoch 0039, iter [00600, 05004], lr: 0.077100, loss: 1.5845
2022-07-07 08:46:56 - train: epoch 0039, iter [00700, 05004], lr: 0.077078, loss: 1.8496
2022-07-07 08:47:41 - train: epoch 0039, iter [00800, 05004], lr: 0.077056, loss: 1.6083
2022-07-07 08:48:26 - train: epoch 0039, iter [00900, 05004], lr: 0.077034, loss: 1.7482
2022-07-07 08:49:11 - train: epoch 0039, iter [01000, 05004], lr: 0.077012, loss: 1.6947
2022-07-07 08:49:56 - train: epoch 0039, iter [01100, 05004], lr: 0.076990, loss: 1.7496
2022-07-07 08:50:41 - train: epoch 0039, iter [01200, 05004], lr: 0.076968, loss: 1.8188
2022-07-07 08:51:26 - train: epoch 0039, iter [01300, 05004], lr: 0.076946, loss: 1.9584
2022-07-07 08:52:11 - train: epoch 0039, iter [01400, 05004], lr: 0.076924, loss: 1.7773
2022-07-07 08:52:56 - train: epoch 0039, iter [01500, 05004], lr: 0.076902, loss: 1.7295
2022-07-07 08:53:41 - train: epoch 0039, iter [01600, 05004], lr: 0.076880, loss: 1.7896
2022-07-07 08:54:26 - train: epoch 0039, iter [01700, 05004], lr: 0.076858, loss: 1.4352
2022-07-07 08:55:11 - train: epoch 0039, iter [01800, 05004], lr: 0.076836, loss: 1.6526
2022-07-07 08:55:56 - train: epoch 0039, iter [01900, 05004], lr: 0.076814, loss: 1.4556
2022-07-07 08:56:42 - train: epoch 0039, iter [02000, 05004], lr: 0.076792, loss: 1.6225
2022-07-07 08:57:27 - train: epoch 0039, iter [02100, 05004], lr: 0.076770, loss: 1.8249
2022-07-07 08:58:12 - train: epoch 0039, iter [02200, 05004], lr: 0.076748, loss: 1.6468
2022-07-07 08:58:57 - train: epoch 0039, iter [02300, 05004], lr: 0.076725, loss: 1.9165
2022-07-07 08:59:42 - train: epoch 0039, iter [02400, 05004], lr: 0.076703, loss: 1.9113
2022-07-07 09:00:27 - train: epoch 0039, iter [02500, 05004], lr: 0.076681, loss: 1.7385
2022-07-07 09:01:13 - train: epoch 0039, iter [02600, 05004], lr: 0.076659, loss: 1.7277
2022-07-07 09:01:58 - train: epoch 0039, iter [02700, 05004], lr: 0.076637, loss: 1.8697
2022-07-07 09:02:43 - train: epoch 0039, iter [02800, 05004], lr: 0.076615, loss: 1.6538
2022-07-07 09:03:28 - train: epoch 0039, iter [02900, 05004], lr: 0.076593, loss: 1.5981
2022-07-07 09:04:14 - train: epoch 0039, iter [03000, 05004], lr: 0.076570, loss: 1.7592
2022-07-07 09:04:59 - train: epoch 0039, iter [03100, 05004], lr: 0.076548, loss: 1.5896
2022-07-07 09:05:44 - train: epoch 0039, iter [03200, 05004], lr: 0.076526, loss: 1.8012
2022-07-07 09:06:29 - train: epoch 0039, iter [03300, 05004], lr: 0.076504, loss: 1.8142
2022-07-07 09:07:15 - train: epoch 0039, iter [03400, 05004], lr: 0.076482, loss: 1.7655
2022-07-07 09:08:00 - train: epoch 0039, iter [03500, 05004], lr: 0.076460, loss: 1.9439
2022-07-07 09:08:45 - train: epoch 0039, iter [03600, 05004], lr: 0.076437, loss: 1.8753
2022-07-07 09:09:30 - train: epoch 0039, iter [03700, 05004], lr: 0.076415, loss: 1.7225
2022-07-07 09:10:15 - train: epoch 0039, iter [03800, 05004], lr: 0.076393, loss: 1.5232
2022-07-07 09:11:01 - train: epoch 0039, iter [03900, 05004], lr: 0.076371, loss: 1.8327
2022-07-07 09:11:46 - train: epoch 0039, iter [04000, 05004], lr: 0.076349, loss: 1.6472
2022-07-07 09:12:31 - train: epoch 0039, iter [04100, 05004], lr: 0.076326, loss: 1.7984
2022-07-07 09:13:16 - train: epoch 0039, iter [04200, 05004], lr: 0.076304, loss: 1.7615
2022-07-07 09:14:01 - train: epoch 0039, iter [04300, 05004], lr: 0.076282, loss: 1.6578
2022-07-07 09:14:46 - train: epoch 0039, iter [04400, 05004], lr: 0.076260, loss: 1.4333
2022-07-07 09:15:32 - train: epoch 0039, iter [04500, 05004], lr: 0.076237, loss: 1.6363
2022-07-07 09:16:17 - train: epoch 0039, iter [04600, 05004], lr: 0.076215, loss: 1.8430
2022-07-07 09:17:02 - train: epoch 0039, iter [04700, 05004], lr: 0.076193, loss: 1.7098
2022-07-07 09:17:47 - train: epoch 0039, iter [04800, 05004], lr: 0.076170, loss: 1.7159
2022-07-07 09:18:32 - train: epoch 0039, iter [04900, 05004], lr: 0.076148, loss: 1.5401
2022-07-07 09:19:17 - train: epoch 0039, iter [05000, 05004], lr: 0.076126, loss: 1.5912
2022-07-07 09:19:20 - train: epoch 039, train_loss: 1.7268
2022-07-07 09:20:36 - eval: epoch: 039, acc1: 63.986%, acc5: 86.366%, test_loss: 1.4877, per_image_load_time: 2.113ms, per_image_inference_time: 0.824ms
2022-07-07 09:20:37 - until epoch: 039, best_acc1: 64.236%
2022-07-07 09:20:37 - epoch 040 lr: 0.076125
2022-07-07 09:21:28 - train: epoch 0040, iter [00100, 05004], lr: 0.076103, loss: 1.9807
2022-07-07 09:22:13 - train: epoch 0040, iter [00200, 05004], lr: 0.076080, loss: 1.9488
2022-07-07 09:22:58 - train: epoch 0040, iter [00300, 05004], lr: 0.076058, loss: 1.7605
2022-07-07 09:23:43 - train: epoch 0040, iter [00400, 05004], lr: 0.076036, loss: 1.7517
2022-07-07 09:24:27 - train: epoch 0040, iter [00500, 05004], lr: 0.076013, loss: 1.6239
2022-07-07 09:25:12 - train: epoch 0040, iter [00600, 05004], lr: 0.075991, loss: 1.8316
2022-07-07 09:25:57 - train: epoch 0040, iter [00700, 05004], lr: 0.075969, loss: 1.7090
2022-07-07 09:26:42 - train: epoch 0040, iter [00800, 05004], lr: 0.075946, loss: 1.8671
2022-07-07 09:27:27 - train: epoch 0040, iter [00900, 05004], lr: 0.075924, loss: 1.6013
2022-07-07 09:28:12 - train: epoch 0040, iter [01000, 05004], lr: 0.075902, loss: 1.4314
2022-07-07 09:28:57 - train: epoch 0040, iter [01100, 05004], lr: 0.075879, loss: 1.6231
2022-07-07 09:29:42 - train: epoch 0040, iter [01200, 05004], lr: 0.075857, loss: 1.6334
2022-07-07 09:30:27 - train: epoch 0040, iter [01300, 05004], lr: 0.075834, loss: 1.5389
2022-07-07 09:31:12 - train: epoch 0040, iter [01400, 05004], lr: 0.075812, loss: 1.6362
2022-07-07 09:31:57 - train: epoch 0040, iter [01500, 05004], lr: 0.075790, loss: 1.8438
2022-07-07 09:32:41 - train: epoch 0040, iter [01600, 05004], lr: 0.075767, loss: 1.6423
2022-07-07 09:33:26 - train: epoch 0040, iter [01700, 05004], lr: 0.075745, loss: 1.8037
2022-07-07 09:34:11 - train: epoch 0040, iter [01800, 05004], lr: 0.075722, loss: 1.5489
2022-07-07 09:34:56 - train: epoch 0040, iter [01900, 05004], lr: 0.075700, loss: 1.6977
2022-07-07 09:35:41 - train: epoch 0040, iter [02000, 05004], lr: 0.075677, loss: 1.7290
2022-07-07 09:36:26 - train: epoch 0040, iter [02100, 05004], lr: 0.075655, loss: 1.5100
2022-07-07 09:37:11 - train: epoch 0040, iter [02200, 05004], lr: 0.075633, loss: 1.4878
2022-07-07 09:37:56 - train: epoch 0040, iter [02300, 05004], lr: 0.075610, loss: 1.6234
2022-07-07 09:38:41 - train: epoch 0040, iter [02400, 05004], lr: 0.075588, loss: 1.7455
2022-07-07 09:39:25 - train: epoch 0040, iter [02500, 05004], lr: 0.075565, loss: 1.8821
2022-07-07 09:40:10 - train: epoch 0040, iter [02600, 05004], lr: 0.075543, loss: 1.5307
2022-07-07 09:40:55 - train: epoch 0040, iter [02700, 05004], lr: 0.075520, loss: 1.8727
2022-07-07 09:41:40 - train: epoch 0040, iter [02800, 05004], lr: 0.075498, loss: 1.7515
2022-07-07 09:42:25 - train: epoch 0040, iter [02900, 05004], lr: 0.075475, loss: 1.9963
2022-07-07 09:43:10 - train: epoch 0040, iter [03000, 05004], lr: 0.075453, loss: 1.8117
2022-07-07 09:43:55 - train: epoch 0040, iter [03100, 05004], lr: 0.075430, loss: 1.5796
2022-07-07 09:44:40 - train: epoch 0040, iter [03200, 05004], lr: 0.075408, loss: 1.9028
2022-07-07 09:45:25 - train: epoch 0040, iter [03300, 05004], lr: 0.075385, loss: 1.7490
2022-07-07 09:46:10 - train: epoch 0040, iter [03400, 05004], lr: 0.075362, loss: 1.7169
2022-07-07 09:46:55 - train: epoch 0040, iter [03500, 05004], lr: 0.075340, loss: 1.7492
2022-07-07 09:47:40 - train: epoch 0040, iter [03600, 05004], lr: 0.075317, loss: 1.6652
2022-07-07 09:48:25 - train: epoch 0040, iter [03700, 05004], lr: 0.075295, loss: 1.7879
2022-07-07 09:49:10 - train: epoch 0040, iter [03800, 05004], lr: 0.075272, loss: 1.5934
2022-07-07 09:49:55 - train: epoch 0040, iter [03900, 05004], lr: 0.075250, loss: 1.7928
2022-07-07 09:50:40 - train: epoch 0040, iter [04000, 05004], lr: 0.075227, loss: 1.8730
2022-07-07 09:51:25 - train: epoch 0040, iter [04100, 05004], lr: 0.075205, loss: 1.7575
2022-07-07 09:52:10 - train: epoch 0040, iter [04200, 05004], lr: 0.075182, loss: 1.5714
2022-07-07 09:52:55 - train: epoch 0040, iter [04300, 05004], lr: 0.075159, loss: 1.7981
2022-07-07 09:53:40 - train: epoch 0040, iter [04400, 05004], lr: 0.075137, loss: 1.7448
2022-07-07 09:54:25 - train: epoch 0040, iter [04500, 05004], lr: 0.075114, loss: 1.4615
2022-07-07 09:55:11 - train: epoch 0040, iter [04600, 05004], lr: 0.075091, loss: 1.7117
2022-07-07 09:55:56 - train: epoch 0040, iter [04700, 05004], lr: 0.075069, loss: 1.7436
2022-07-07 09:56:41 - train: epoch 0040, iter [04800, 05004], lr: 0.075046, loss: 1.7823
2022-07-07 09:57:26 - train: epoch 0040, iter [04900, 05004], lr: 0.075024, loss: 1.7900
2022-07-07 09:58:11 - train: epoch 0040, iter [05000, 05004], lr: 0.075001, loss: 1.8060
2022-07-07 09:58:13 - train: epoch 040, train_loss: 1.7169
2022-07-07 09:59:30 - eval: epoch: 040, acc1: 64.524%, acc5: 86.602%, test_loss: 1.4616, per_image_load_time: 1.730ms, per_image_inference_time: 0.831ms
2022-07-07 09:59:31 - until epoch: 040, best_acc1: 64.524%
2022-07-07 09:59:31 - epoch 041 lr: 0.075000
2022-07-07 10:00:21 - train: epoch 0041, iter [00100, 05004], lr: 0.074977, loss: 1.7826
2022-07-07 10:01:06 - train: epoch 0041, iter [00200, 05004], lr: 0.074955, loss: 1.8394
2022-07-07 10:01:50 - train: epoch 0041, iter [00300, 05004], lr: 0.074932, loss: 1.6739
2022-07-07 10:02:35 - train: epoch 0041, iter [00400, 05004], lr: 0.074909, loss: 1.6717
2022-07-07 10:03:20 - train: epoch 0041, iter [00500, 05004], lr: 0.074887, loss: 1.4839
2022-07-07 10:04:05 - train: epoch 0041, iter [00600, 05004], lr: 0.074864, loss: 1.8671
2022-07-07 10:04:50 - train: epoch 0041, iter [00700, 05004], lr: 0.074841, loss: 1.5823
2022-07-07 10:05:35 - train: epoch 0041, iter [00800, 05004], lr: 0.074819, loss: 1.5326
2022-07-07 10:06:20 - train: epoch 0041, iter [00900, 05004], lr: 0.074796, loss: 1.4487
2022-07-07 10:07:05 - train: epoch 0041, iter [01000, 05004], lr: 0.074773, loss: 1.8824
2022-07-07 10:07:50 - train: epoch 0041, iter [01100, 05004], lr: 0.074750, loss: 1.6069
2022-07-07 10:08:35 - train: epoch 0041, iter [01200, 05004], lr: 0.074728, loss: 1.4474
2022-07-07 10:09:20 - train: epoch 0041, iter [01300, 05004], lr: 0.074705, loss: 1.7033
2022-07-07 10:10:05 - train: epoch 0041, iter [01400, 05004], lr: 0.074682, loss: 1.8081
2022-07-07 10:10:50 - train: epoch 0041, iter [01500, 05004], lr: 0.074659, loss: 1.9962
2022-07-07 10:11:35 - train: epoch 0041, iter [01600, 05004], lr: 0.074637, loss: 1.4371
2022-07-07 10:12:19 - train: epoch 0041, iter [01700, 05004], lr: 0.074614, loss: 1.8192
2022-07-07 10:13:04 - train: epoch 0041, iter [01800, 05004], lr: 0.074591, loss: 1.7892
2022-07-07 10:13:49 - train: epoch 0041, iter [01900, 05004], lr: 0.074568, loss: 1.8577
2022-07-07 10:14:34 - train: epoch 0041, iter [02000, 05004], lr: 0.074546, loss: 1.6506
2022-07-07 10:15:19 - train: epoch 0041, iter [02100, 05004], lr: 0.074523, loss: 1.4754
2022-07-07 10:16:04 - train: epoch 0041, iter [02200, 05004], lr: 0.074500, loss: 1.4886
2022-07-07 10:16:49 - train: epoch 0041, iter [02300, 05004], lr: 0.074477, loss: 1.4595
2022-07-07 10:17:34 - train: epoch 0041, iter [02400, 05004], lr: 0.074454, loss: 1.8553
2022-07-07 10:18:19 - train: epoch 0041, iter [02500, 05004], lr: 0.074432, loss: 1.5404
2022-07-07 10:19:04 - train: epoch 0041, iter [02600, 05004], lr: 0.074409, loss: 1.8781
2022-07-07 10:19:49 - train: epoch 0041, iter [02700, 05004], lr: 0.074386, loss: 1.9540
2022-07-07 10:20:33 - train: epoch 0041, iter [02800, 05004], lr: 0.074363, loss: 1.7059
2022-07-07 10:21:18 - train: epoch 0041, iter [02900, 05004], lr: 0.074340, loss: 1.9330
2022-07-07 10:22:03 - train: epoch 0041, iter [03000, 05004], lr: 0.074317, loss: 1.8100
2022-07-07 10:22:48 - train: epoch 0041, iter [03100, 05004], lr: 0.074294, loss: 1.8433
2022-07-07 10:23:33 - train: epoch 0041, iter [03200, 05004], lr: 0.074272, loss: 1.5506
2022-07-07 10:24:18 - train: epoch 0041, iter [03300, 05004], lr: 0.074249, loss: 1.5896
2022-07-07 10:25:03 - train: epoch 0041, iter [03400, 05004], lr: 0.074226, loss: 1.4780
2022-07-07 10:25:48 - train: epoch 0041, iter [03500, 05004], lr: 0.074203, loss: 1.8636
2022-07-07 10:26:33 - train: epoch 0041, iter [03600, 05004], lr: 0.074180, loss: 1.7884
2022-07-07 10:27:18 - train: epoch 0041, iter [03700, 05004], lr: 0.074157, loss: 1.8408
2022-07-07 10:28:02 - train: epoch 0041, iter [03800, 05004], lr: 0.074134, loss: 1.6333
2022-07-07 10:28:47 - train: epoch 0041, iter [03900, 05004], lr: 0.074111, loss: 1.8188
2022-07-07 10:29:32 - train: epoch 0041, iter [04000, 05004], lr: 0.074088, loss: 1.5763
2022-07-07 10:30:17 - train: epoch 0041, iter [04100, 05004], lr: 0.074065, loss: 1.6379
2022-07-07 10:31:02 - train: epoch 0041, iter [04200, 05004], lr: 0.074043, loss: 1.6714
2022-07-07 10:31:47 - train: epoch 0041, iter [04300, 05004], lr: 0.074020, loss: 1.8069
2022-07-07 10:32:32 - train: epoch 0041, iter [04400, 05004], lr: 0.073997, loss: 1.6055
2022-07-07 10:33:17 - train: epoch 0041, iter [04500, 05004], lr: 0.073974, loss: 1.7809
2022-07-07 10:34:02 - train: epoch 0041, iter [04600, 05004], lr: 0.073951, loss: 1.7740
2022-07-07 10:34:47 - train: epoch 0041, iter [04700, 05004], lr: 0.073928, loss: 1.8633
2022-07-07 10:35:32 - train: epoch 0041, iter [04800, 05004], lr: 0.073905, loss: 1.6819
2022-07-07 10:36:17 - train: epoch 0041, iter [04900, 05004], lr: 0.073882, loss: 1.7459
2022-07-07 10:37:02 - train: epoch 0041, iter [05000, 05004], lr: 0.073859, loss: 1.8418
2022-07-07 10:37:04 - train: epoch 041, train_loss: 1.7097
2022-07-07 10:38:21 - eval: epoch: 041, acc1: 64.682%, acc5: 86.702%, test_loss: 1.4666, per_image_load_time: 1.560ms, per_image_inference_time: 0.818ms
2022-07-07 10:38:22 - until epoch: 041, best_acc1: 64.682%
2022-07-07 10:38:22 - epoch 042 lr: 0.073858
2022-07-07 10:39:12 - train: epoch 0042, iter [00100, 05004], lr: 0.073835, loss: 1.3707
2022-07-07 10:39:57 - train: epoch 0042, iter [00200, 05004], lr: 0.073812, loss: 1.8242
2022-07-07 10:40:42 - train: epoch 0042, iter [00300, 05004], lr: 0.073789, loss: 1.8319
2022-07-07 10:41:27 - train: epoch 0042, iter [00400, 05004], lr: 0.073766, loss: 1.4260
2022-07-07 10:42:12 - train: epoch 0042, iter [00500, 05004], lr: 0.073743, loss: 1.7154
2022-07-07 10:42:57 - train: epoch 0042, iter [00600, 05004], lr: 0.073720, loss: 1.5811
2022-07-07 10:43:42 - train: epoch 0042, iter [00700, 05004], lr: 0.073697, loss: 1.6902
2022-07-07 10:44:27 - train: epoch 0042, iter [00800, 05004], lr: 0.073674, loss: 1.6600
2022-07-07 10:45:12 - train: epoch 0042, iter [00900, 05004], lr: 0.073651, loss: 1.8661
2022-07-07 10:45:57 - train: epoch 0042, iter [01000, 05004], lr: 0.073628, loss: 1.8121
2022-07-07 10:46:42 - train: epoch 0042, iter [01100, 05004], lr: 0.073605, loss: 1.4772
2022-07-07 10:47:27 - train: epoch 0042, iter [01200, 05004], lr: 0.073582, loss: 1.6511
2022-07-07 10:48:12 - train: epoch 0042, iter [01300, 05004], lr: 0.073559, loss: 1.8052
2022-07-07 10:48:57 - train: epoch 0042, iter [01400, 05004], lr: 0.073535, loss: 1.9441
2022-07-07 10:49:42 - train: epoch 0042, iter [01500, 05004], lr: 0.073512, loss: 1.6376
2022-07-07 10:50:26 - train: epoch 0042, iter [01600, 05004], lr: 0.073489, loss: 1.7294
2022-07-07 10:51:11 - train: epoch 0042, iter [01700, 05004], lr: 0.073466, loss: 1.6238
2022-07-07 10:51:56 - train: epoch 0042, iter [01800, 05004], lr: 0.073443, loss: 1.6137
2022-07-07 10:52:41 - train: epoch 0042, iter [01900, 05004], lr: 0.073420, loss: 1.8547
2022-07-07 10:53:26 - train: epoch 0042, iter [02000, 05004], lr: 0.073397, loss: 1.5734
2022-07-07 10:54:11 - train: epoch 0042, iter [02100, 05004], lr: 0.073374, loss: 1.3992
2022-07-07 10:54:56 - train: epoch 0042, iter [02200, 05004], lr: 0.073351, loss: 1.4983
2022-07-07 10:55:42 - train: epoch 0042, iter [02300, 05004], lr: 0.073327, loss: 1.5974
2022-07-07 10:56:27 - train: epoch 0042, iter [02400, 05004], lr: 0.073304, loss: 2.0518
2022-07-07 10:57:12 - train: epoch 0042, iter [02500, 05004], lr: 0.073281, loss: 1.8161
2022-07-07 10:57:57 - train: epoch 0042, iter [02600, 05004], lr: 0.073258, loss: 1.8039
2022-07-07 10:58:42 - train: epoch 0042, iter [02700, 05004], lr: 0.073235, loss: 1.5995
2022-07-07 10:59:27 - train: epoch 0042, iter [02800, 05004], lr: 0.073212, loss: 1.6488
2022-07-07 11:00:12 - train: epoch 0042, iter [02900, 05004], lr: 0.073189, loss: 1.6640
2022-07-07 11:00:57 - train: epoch 0042, iter [03000, 05004], lr: 0.073165, loss: 1.7261
2022-07-07 11:01:42 - train: epoch 0042, iter [03100, 05004], lr: 0.073142, loss: 1.6869
2022-07-07 11:02:27 - train: epoch 0042, iter [03200, 05004], lr: 0.073119, loss: 1.7978
2022-07-07 11:03:12 - train: epoch 0042, iter [03300, 05004], lr: 0.073096, loss: 1.8946
2022-07-07 11:03:57 - train: epoch 0042, iter [03400, 05004], lr: 0.073073, loss: 1.6333
2022-07-07 11:04:42 - train: epoch 0042, iter [03500, 05004], lr: 0.073049, loss: 1.7191
2022-07-07 11:05:27 - train: epoch 0042, iter [03600, 05004], lr: 0.073026, loss: 1.7730
2022-07-07 11:06:12 - train: epoch 0042, iter [03700, 05004], lr: 0.073003, loss: 1.6828
2022-07-07 11:06:57 - train: epoch 0042, iter [03800, 05004], lr: 0.072980, loss: 1.4380
2022-07-07 11:07:42 - train: epoch 0042, iter [03900, 05004], lr: 0.072956, loss: 1.7100
2022-07-07 11:08:27 - train: epoch 0042, iter [04000, 05004], lr: 0.072933, loss: 1.7059
2022-07-07 11:09:12 - train: epoch 0042, iter [04100, 05004], lr: 0.072910, loss: 1.8949
2022-07-07 11:09:58 - train: epoch 0042, iter [04200, 05004], lr: 0.072887, loss: 1.9129
2022-07-07 11:10:43 - train: epoch 0042, iter [04300, 05004], lr: 0.072863, loss: 1.7023
2022-07-07 11:11:28 - train: epoch 0042, iter [04400, 05004], lr: 0.072840, loss: 1.6366
2022-07-07 11:12:13 - train: epoch 0042, iter [04500, 05004], lr: 0.072817, loss: 1.7264
2022-07-07 11:12:58 - train: epoch 0042, iter [04600, 05004], lr: 0.072794, loss: 1.9855
2022-07-07 11:13:43 - train: epoch 0042, iter [04700, 05004], lr: 0.072770, loss: 1.6085
2022-07-07 11:14:29 - train: epoch 0042, iter [04800, 05004], lr: 0.072747, loss: 1.7868
2022-07-07 11:15:14 - train: epoch 0042, iter [04900, 05004], lr: 0.072724, loss: 1.7442
2022-07-07 11:15:59 - train: epoch 0042, iter [05000, 05004], lr: 0.072700, loss: 1.7674
2022-07-07 11:16:01 - train: epoch 042, train_loss: 1.7010
2022-07-07 11:17:17 - eval: epoch: 042, acc1: 65.220%, acc5: 87.030%, test_loss: 1.4362, per_image_load_time: 1.873ms, per_image_inference_time: 0.830ms
2022-07-07 11:17:19 - until epoch: 042, best_acc1: 65.220%
2022-07-07 11:17:19 - epoch 043 lr: 0.072699
2022-07-07 11:18:09 - train: epoch 0043, iter [00100, 05004], lr: 0.072676, loss: 1.7457
2022-07-07 11:18:54 - train: epoch 0043, iter [00200, 05004], lr: 0.072653, loss: 1.6849
2022-07-07 11:19:39 - train: epoch 0043, iter [00300, 05004], lr: 0.072630, loss: 1.3272
2022-07-07 11:20:24 - train: epoch 0043, iter [00400, 05004], lr: 0.072606, loss: 1.6352
2022-07-07 11:21:09 - train: epoch 0043, iter [00500, 05004], lr: 0.072583, loss: 1.6751
2022-07-07 11:21:53 - train: epoch 0043, iter [00600, 05004], lr: 0.072560, loss: 1.5801
2022-07-07 11:22:38 - train: epoch 0043, iter [00700, 05004], lr: 0.072536, loss: 1.9383
2022-07-07 11:23:23 - train: epoch 0043, iter [00800, 05004], lr: 0.072513, loss: 1.8280
2022-07-07 11:24:08 - train: epoch 0043, iter [00900, 05004], lr: 0.072490, loss: 1.7047
2022-07-07 11:24:53 - train: epoch 0043, iter [01000, 05004], lr: 0.072466, loss: 1.7557
2022-07-07 11:25:39 - train: epoch 0043, iter [01100, 05004], lr: 0.072443, loss: 1.7710
2022-07-07 11:26:23 - train: epoch 0043, iter [01200, 05004], lr: 0.072419, loss: 1.6721
2022-07-07 11:27:08 - train: epoch 0043, iter [01300, 05004], lr: 0.072396, loss: 1.7977
2022-07-07 11:27:53 - train: epoch 0043, iter [01400, 05004], lr: 0.072373, loss: 1.6695
2022-07-07 11:28:38 - train: epoch 0043, iter [01500, 05004], lr: 0.072349, loss: 1.5523
2022-07-07 11:29:22 - train: epoch 0043, iter [01600, 05004], lr: 0.072326, loss: 1.7345
2022-07-07 11:30:07 - train: epoch 0043, iter [01700, 05004], lr: 0.072302, loss: 1.7596
2022-07-07 11:30:52 - train: epoch 0043, iter [01800, 05004], lr: 0.072279, loss: 1.8478
2022-07-07 11:31:36 - train: epoch 0043, iter [01900, 05004], lr: 0.072256, loss: 1.7078
2022-07-07 11:32:21 - train: epoch 0043, iter [02000, 05004], lr: 0.072232, loss: 1.5571
2022-07-07 11:33:06 - train: epoch 0043, iter [02100, 05004], lr: 0.072209, loss: 1.5949
2022-07-07 11:33:51 - train: epoch 0043, iter [02200, 05004], lr: 0.072185, loss: 1.6987
2022-07-07 11:34:35 - train: epoch 0043, iter [02300, 05004], lr: 0.072162, loss: 1.8308
2022-07-07 11:35:20 - train: epoch 0043, iter [02400, 05004], lr: 0.072138, loss: 1.5370
2022-07-07 11:36:04 - train: epoch 0043, iter [02500, 05004], lr: 0.072115, loss: 1.8053
2022-07-07 11:36:49 - train: epoch 0043, iter [02600, 05004], lr: 0.072091, loss: 1.4321
2022-07-07 11:37:34 - train: epoch 0043, iter [02700, 05004], lr: 0.072068, loss: 1.7449
2022-07-07 11:38:19 - train: epoch 0043, iter [02800, 05004], lr: 0.072044, loss: 1.5968
2022-07-07 11:39:03 - train: epoch 0043, iter [02900, 05004], lr: 0.072021, loss: 1.8038
2022-07-07 11:39:48 - train: epoch 0043, iter [03000, 05004], lr: 0.071998, loss: 1.9989
2022-07-07 11:40:33 - train: epoch 0043, iter [03100, 05004], lr: 0.071974, loss: 1.9481
2022-07-07 11:41:17 - train: epoch 0043, iter [03200, 05004], lr: 0.071951, loss: 1.8405
2022-07-07 11:42:02 - train: epoch 0043, iter [03300, 05004], lr: 0.071927, loss: 1.8079
2022-07-07 11:42:47 - train: epoch 0043, iter [03400, 05004], lr: 0.071904, loss: 1.7805
2022-07-07 11:43:32 - train: epoch 0043, iter [03500, 05004], lr: 0.071880, loss: 1.7203
2022-07-07 11:44:16 - train: epoch 0043, iter [03600, 05004], lr: 0.071856, loss: 1.7038
2022-07-07 11:45:01 - train: epoch 0043, iter [03700, 05004], lr: 0.071833, loss: 1.7057
2022-07-07 11:45:46 - train: epoch 0043, iter [03800, 05004], lr: 0.071809, loss: 1.8118
2022-07-07 11:46:31 - train: epoch 0043, iter [03900, 05004], lr: 0.071786, loss: 1.9403
2022-07-07 11:47:15 - train: epoch 0043, iter [04000, 05004], lr: 0.071762, loss: 1.7134
2022-07-07 11:48:00 - train: epoch 0043, iter [04100, 05004], lr: 0.071739, loss: 2.0301
2022-07-07 11:48:45 - train: epoch 0043, iter [04200, 05004], lr: 0.071715, loss: 1.7426
2022-07-07 11:49:29 - train: epoch 0043, iter [04300, 05004], lr: 0.071692, loss: 1.7998
2022-07-07 11:50:14 - train: epoch 0043, iter [04400, 05004], lr: 0.071668, loss: 1.5921
2022-07-07 11:50:59 - train: epoch 0043, iter [04500, 05004], lr: 0.071644, loss: 1.6703
2022-07-07 11:51:44 - train: epoch 0043, iter [04600, 05004], lr: 0.071621, loss: 1.6714
2022-07-07 11:52:28 - train: epoch 0043, iter [04700, 05004], lr: 0.071597, loss: 1.5713
2022-07-07 11:53:13 - train: epoch 0043, iter [04800, 05004], lr: 0.071574, loss: 1.6493
2022-07-07 11:53:58 - train: epoch 0043, iter [04900, 05004], lr: 0.071550, loss: 1.5935
2022-07-07 11:54:42 - train: epoch 0043, iter [05000, 05004], lr: 0.071526, loss: 1.5527
2022-07-07 11:54:45 - train: epoch 043, train_loss: 1.6895
2022-07-07 11:56:02 - eval: epoch: 043, acc1: 64.290%, acc5: 86.860%, test_loss: 1.4874, per_image_load_time: 2.136ms, per_image_inference_time: 0.849ms
2022-07-07 11:56:03 - until epoch: 043, best_acc1: 65.220%
2022-07-07 11:56:03 - epoch 044 lr: 0.071525
2022-07-07 11:56:54 - train: epoch 0044, iter [00100, 05004], lr: 0.071502, loss: 1.7136
2022-07-07 11:57:38 - train: epoch 0044, iter [00200, 05004], lr: 0.071478, loss: 1.6786
2022-07-07 11:58:23 - train: epoch 0044, iter [00300, 05004], lr: 0.071455, loss: 1.7811
2022-07-07 11:59:07 - train: epoch 0044, iter [00400, 05004], lr: 0.071431, loss: 1.4201
2022-07-07 11:59:52 - train: epoch 0044, iter [00500, 05004], lr: 0.071407, loss: 1.5915
2022-07-07 12:00:36 - train: epoch 0044, iter [00600, 05004], lr: 0.071384, loss: 1.3745
2022-07-07 12:01:21 - train: epoch 0044, iter [00700, 05004], lr: 0.071360, loss: 1.5011
2022-07-07 12:02:05 - train: epoch 0044, iter [00800, 05004], lr: 0.071336, loss: 1.5721
2022-07-07 12:02:50 - train: epoch 0044, iter [00900, 05004], lr: 0.071313, loss: 1.6626
2022-07-07 12:03:34 - train: epoch 0044, iter [01000, 05004], lr: 0.071289, loss: 1.5806
2022-07-07 12:04:19 - train: epoch 0044, iter [01100, 05004], lr: 0.071265, loss: 1.6187
2022-07-07 12:05:03 - train: epoch 0044, iter [01200, 05004], lr: 0.071242, loss: 1.5694
2022-07-07 12:05:48 - train: epoch 0044, iter [01300, 05004], lr: 0.071218, loss: 1.6339
2022-07-07 12:06:32 - train: epoch 0044, iter [01400, 05004], lr: 0.071194, loss: 1.5667
2022-07-07 12:07:17 - train: epoch 0044, iter [01500, 05004], lr: 0.071171, loss: 1.5384
2022-07-07 12:08:01 - train: epoch 0044, iter [01600, 05004], lr: 0.071147, loss: 1.5291
2022-07-07 12:08:46 - train: epoch 0044, iter [01700, 05004], lr: 0.071123, loss: 1.5953
2022-07-07 12:09:30 - train: epoch 0044, iter [01800, 05004], lr: 0.071100, loss: 1.6593
2022-07-07 12:10:15 - train: epoch 0044, iter [01900, 05004], lr: 0.071076, loss: 1.8392
2022-07-07 12:10:59 - train: epoch 0044, iter [02000, 05004], lr: 0.071052, loss: 1.5536
2022-07-07 12:11:44 - train: epoch 0044, iter [02100, 05004], lr: 0.071028, loss: 1.8254
2022-07-07 12:12:28 - train: epoch 0044, iter [02200, 05004], lr: 0.071005, loss: 1.5811
2022-07-07 12:13:12 - train: epoch 0044, iter [02300, 05004], lr: 0.070981, loss: 1.8511
2022-07-07 12:13:57 - train: epoch 0044, iter [02400, 05004], lr: 0.070957, loss: 1.7176
2022-07-07 12:14:42 - train: epoch 0044, iter [02500, 05004], lr: 0.070933, loss: 1.7358
2022-07-07 12:15:26 - train: epoch 0044, iter [02600, 05004], lr: 0.070910, loss: 1.6139
2022-07-07 12:16:11 - train: epoch 0044, iter [02700, 05004], lr: 0.070886, loss: 1.6893
2022-07-07 12:16:56 - train: epoch 0044, iter [02800, 05004], lr: 0.070862, loss: 1.4672
2022-07-07 12:17:41 - train: epoch 0044, iter [02900, 05004], lr: 0.070838, loss: 1.4435
2022-07-07 12:18:26 - train: epoch 0044, iter [03000, 05004], lr: 0.070815, loss: 1.6526
2022-07-07 12:19:11 - train: epoch 0044, iter [03100, 05004], lr: 0.070791, loss: 1.6906
2022-07-07 12:19:56 - train: epoch 0044, iter [03200, 05004], lr: 0.070767, loss: 1.4367
2022-07-07 12:20:41 - train: epoch 0044, iter [03300, 05004], lr: 0.070743, loss: 1.6000
2022-07-07 12:21:26 - train: epoch 0044, iter [03400, 05004], lr: 0.070719, loss: 2.0358
2022-07-07 12:22:11 - train: epoch 0044, iter [03500, 05004], lr: 0.070696, loss: 1.4749
2022-07-07 12:22:56 - train: epoch 0044, iter [03600, 05004], lr: 0.070672, loss: 1.8772
2022-07-07 12:23:40 - train: epoch 0044, iter [03700, 05004], lr: 0.070648, loss: 1.7891
2022-07-07 12:24:25 - train: epoch 0044, iter [03800, 05004], lr: 0.070624, loss: 1.4851
2022-07-07 12:25:10 - train: epoch 0044, iter [03900, 05004], lr: 0.070600, loss: 1.8460
2022-07-07 12:25:54 - train: epoch 0044, iter [04000, 05004], lr: 0.070576, loss: 1.7338
2022-07-07 12:26:39 - train: epoch 0044, iter [04100, 05004], lr: 0.070553, loss: 1.6260
2022-07-07 12:27:24 - train: epoch 0044, iter [04200, 05004], lr: 0.070529, loss: 1.7965
2022-07-07 12:28:08 - train: epoch 0044, iter [04300, 05004], lr: 0.070505, loss: 1.9082
2022-07-07 12:28:53 - train: epoch 0044, iter [04400, 05004], lr: 0.070481, loss: 1.5306
2022-07-07 12:29:37 - train: epoch 0044, iter [04500, 05004], lr: 0.070457, loss: 1.8390
2022-07-07 12:30:22 - train: epoch 0044, iter [04600, 05004], lr: 0.070433, loss: 1.7593
2022-07-07 12:31:07 - train: epoch 0044, iter [04700, 05004], lr: 0.070409, loss: 1.8240
2022-07-07 12:31:52 - train: epoch 0044, iter [04800, 05004], lr: 0.070386, loss: 1.9058
2022-07-07 12:32:37 - train: epoch 0044, iter [04900, 05004], lr: 0.070362, loss: 1.4364
2022-07-07 12:33:22 - train: epoch 0044, iter [05000, 05004], lr: 0.070338, loss: 1.7400
2022-07-07 12:33:25 - train: epoch 044, train_loss: 1.6817
2022-07-07 12:34:40 - eval: epoch: 044, acc1: 64.870%, acc5: 86.776%, test_loss: 1.4634, per_image_load_time: 2.037ms, per_image_inference_time: 0.843ms
2022-07-07 12:34:41 - until epoch: 044, best_acc1: 65.220%
2022-07-07 12:34:41 - epoch 045 lr: 0.070337
2022-07-07 12:35:32 - train: epoch 0045, iter [00100, 05004], lr: 0.070313, loss: 1.5136
2022-07-07 12:36:16 - train: epoch 0045, iter [00200, 05004], lr: 0.070289, loss: 1.7582
2022-07-07 12:37:01 - train: epoch 0045, iter [00300, 05004], lr: 0.070265, loss: 1.7281
2022-07-07 12:37:46 - train: epoch 0045, iter [00400, 05004], lr: 0.070241, loss: 1.5163
2022-07-07 12:38:31 - train: epoch 0045, iter [00500, 05004], lr: 0.070217, loss: 1.7403
2022-07-07 12:39:16 - train: epoch 0045, iter [00600, 05004], lr: 0.070193, loss: 1.6751
2022-07-07 12:40:01 - train: epoch 0045, iter [00700, 05004], lr: 0.070169, loss: 1.3157
2022-07-07 12:40:46 - train: epoch 0045, iter [00800, 05004], lr: 0.070145, loss: 1.5419
2022-07-07 12:41:31 - train: epoch 0045, iter [00900, 05004], lr: 0.070122, loss: 1.6975
2022-07-07 12:42:17 - train: epoch 0045, iter [01000, 05004], lr: 0.070098, loss: 1.6787
2022-07-07 12:43:02 - train: epoch 0045, iter [01100, 05004], lr: 0.070074, loss: 1.8006
2022-07-07 12:43:47 - train: epoch 0045, iter [01200, 05004], lr: 0.070050, loss: 1.7835
2022-07-07 12:44:32 - train: epoch 0045, iter [01300, 05004], lr: 0.070026, loss: 1.7230
2022-07-07 12:45:17 - train: epoch 0045, iter [01400, 05004], lr: 0.070002, loss: 1.6891
2022-07-07 12:46:03 - train: epoch 0045, iter [01500, 05004], lr: 0.069978, loss: 1.7690
2022-07-07 12:46:48 - train: epoch 0045, iter [01600, 05004], lr: 0.069954, loss: 1.6442
2022-07-07 12:47:33 - train: epoch 0045, iter [01700, 05004], lr: 0.069930, loss: 1.5646
2022-07-07 12:48:18 - train: epoch 0045, iter [01800, 05004], lr: 0.069906, loss: 1.6296
2022-07-07 12:49:04 - train: epoch 0045, iter [01900, 05004], lr: 0.069882, loss: 1.7542
2022-07-07 12:49:49 - train: epoch 0045, iter [02000, 05004], lr: 0.069858, loss: 1.7203
2022-07-07 12:50:34 - train: epoch 0045, iter [02100, 05004], lr: 0.069834, loss: 1.8527
2022-07-07 12:51:19 - train: epoch 0045, iter [02200, 05004], lr: 0.069810, loss: 1.7277
2022-07-07 12:52:05 - train: epoch 0045, iter [02300, 05004], lr: 0.069786, loss: 1.5805
2022-07-07 12:52:50 - train: epoch 0045, iter [02400, 05004], lr: 0.069762, loss: 1.7586
2022-07-07 12:53:35 - train: epoch 0045, iter [02500, 05004], lr: 0.069738, loss: 1.6475
2022-07-07 12:54:20 - train: epoch 0045, iter [02600, 05004], lr: 0.069714, loss: 1.6954
2022-07-07 12:55:06 - train: epoch 0045, iter [02700, 05004], lr: 0.069690, loss: 1.5796
2022-07-07 12:55:51 - train: epoch 0045, iter [02800, 05004], lr: 0.069666, loss: 1.6467
2022-07-07 12:56:36 - train: epoch 0045, iter [02900, 05004], lr: 0.069641, loss: 1.8703
2022-07-07 12:57:21 - train: epoch 0045, iter [03000, 05004], lr: 0.069617, loss: 1.8152
2022-07-07 12:58:06 - train: epoch 0045, iter [03100, 05004], lr: 0.069593, loss: 1.6493
2022-07-07 12:58:51 - train: epoch 0045, iter [03200, 05004], lr: 0.069569, loss: 1.8305
2022-07-07 12:59:36 - train: epoch 0045, iter [03300, 05004], lr: 0.069545, loss: 1.8280
2022-07-07 13:00:21 - train: epoch 0045, iter [03400, 05004], lr: 0.069521, loss: 1.4111
2022-07-07 13:01:07 - train: epoch 0045, iter [03500, 05004], lr: 0.069497, loss: 1.9708
2022-07-07 13:01:52 - train: epoch 0045, iter [03600, 05004], lr: 0.069473, loss: 1.6900
2022-07-07 13:02:37 - train: epoch 0045, iter [03700, 05004], lr: 0.069449, loss: 1.5533
2022-07-07 13:03:23 - train: epoch 0045, iter [03800, 05004], lr: 0.069425, loss: 1.4873
2022-07-07 13:04:08 - train: epoch 0045, iter [03900, 05004], lr: 0.069401, loss: 1.7975
2022-07-07 13:04:53 - train: epoch 0045, iter [04000, 05004], lr: 0.069377, loss: 1.7943
2022-07-07 13:05:38 - train: epoch 0045, iter [04100, 05004], lr: 0.069352, loss: 1.6197
2022-07-07 13:06:23 - train: epoch 0045, iter [04200, 05004], lr: 0.069328, loss: 1.8291
2022-07-07 13:07:09 - train: epoch 0045, iter [04300, 05004], lr: 0.069304, loss: 1.9231
2022-07-07 13:07:54 - train: epoch 0045, iter [04400, 05004], lr: 0.069280, loss: 1.8305
2022-07-07 13:08:40 - train: epoch 0045, iter [04500, 05004], lr: 0.069256, loss: 1.5919
2022-07-07 13:09:26 - train: epoch 0045, iter [04600, 05004], lr: 0.069232, loss: 1.9488
2022-07-07 13:10:13 - train: epoch 0045, iter [04700, 05004], lr: 0.069208, loss: 1.6466
2022-07-07 13:10:59 - train: epoch 0045, iter [04800, 05004], lr: 0.069183, loss: 1.5723
2022-07-07 13:11:45 - train: epoch 0045, iter [04900, 05004], lr: 0.069159, loss: 1.6167
2022-07-07 13:12:30 - train: epoch 0045, iter [05000, 05004], lr: 0.069135, loss: 1.6709
2022-07-07 13:12:33 - train: epoch 045, train_loss: 1.6710
2022-07-07 13:13:48 - eval: epoch: 045, acc1: 65.158%, acc5: 87.110%, test_loss: 1.4281, per_image_load_time: 2.098ms, per_image_inference_time: 0.823ms
2022-07-07 13:13:49 - until epoch: 045, best_acc1: 65.220%
2022-07-07 13:13:49 - epoch 046 lr: 0.069134
2022-07-07 13:14:41 - train: epoch 0046, iter [00100, 05004], lr: 0.069110, loss: 1.3923
2022-07-07 13:15:26 - train: epoch 0046, iter [00200, 05004], lr: 0.069086, loss: 1.4876
2022-07-07 13:16:12 - train: epoch 0046, iter [00300, 05004], lr: 0.069062, loss: 1.7794
2022-07-07 13:16:57 - train: epoch 0046, iter [00400, 05004], lr: 0.069037, loss: 1.8249
2022-07-07 13:17:43 - train: epoch 0046, iter [00500, 05004], lr: 0.069013, loss: 1.3769
2022-07-07 13:18:29 - train: epoch 0046, iter [00600, 05004], lr: 0.068989, loss: 1.6515
2022-07-07 13:19:15 - train: epoch 0046, iter [00700, 05004], lr: 0.068965, loss: 1.5887
2022-07-07 13:20:01 - train: epoch 0046, iter [00800, 05004], lr: 0.068941, loss: 1.8108
2022-07-07 13:20:46 - train: epoch 0046, iter [00900, 05004], lr: 0.068916, loss: 1.7085
2022-07-07 13:21:32 - train: epoch 0046, iter [01000, 05004], lr: 0.068892, loss: 1.4478
2022-07-07 13:22:18 - train: epoch 0046, iter [01100, 05004], lr: 0.068868, loss: 1.7382
2022-07-07 13:23:03 - train: epoch 0046, iter [01200, 05004], lr: 0.068844, loss: 1.5917
2022-07-07 13:23:49 - train: epoch 0046, iter [01300, 05004], lr: 0.068820, loss: 1.6671
2022-07-07 13:24:35 - train: epoch 0046, iter [01400, 05004], lr: 0.068795, loss: 1.8682
2022-07-07 13:25:21 - train: epoch 0046, iter [01500, 05004], lr: 0.068771, loss: 1.5907
2022-07-07 13:26:07 - train: epoch 0046, iter [01600, 05004], lr: 0.068747, loss: 1.7735
2022-07-07 13:26:52 - train: epoch 0046, iter [01700, 05004], lr: 0.068723, loss: 1.5087
2022-07-07 13:27:38 - train: epoch 0046, iter [01800, 05004], lr: 0.068698, loss: 1.7439
2022-07-07 13:28:24 - train: epoch 0046, iter [01900, 05004], lr: 0.068674, loss: 1.4454
2022-07-07 13:29:10 - train: epoch 0046, iter [02000, 05004], lr: 0.068650, loss: 1.6947
2022-07-07 13:29:56 - train: epoch 0046, iter [02100, 05004], lr: 0.068626, loss: 1.7855
2022-07-07 13:30:42 - train: epoch 0046, iter [02200, 05004], lr: 0.068601, loss: 1.4343
2022-07-07 13:31:28 - train: epoch 0046, iter [02300, 05004], lr: 0.068577, loss: 1.8140
2022-07-07 13:32:13 - train: epoch 0046, iter [02400, 05004], lr: 0.068553, loss: 1.5830
2022-07-07 13:32:59 - train: epoch 0046, iter [02500, 05004], lr: 0.068528, loss: 1.7163
2022-07-07 13:33:45 - train: epoch 0046, iter [02600, 05004], lr: 0.068504, loss: 1.8415
2022-07-07 13:34:31 - train: epoch 0046, iter [02700, 05004], lr: 0.068480, loss: 1.5842
2022-07-07 13:35:17 - train: epoch 0046, iter [02800, 05004], lr: 0.068455, loss: 1.4989
2022-07-07 13:36:02 - train: epoch 0046, iter [02900, 05004], lr: 0.068431, loss: 1.8087
2022-07-07 13:36:48 - train: epoch 0046, iter [03000, 05004], lr: 0.068407, loss: 1.4580
2022-07-07 13:37:34 - train: epoch 0046, iter [03100, 05004], lr: 0.068382, loss: 1.5256
2022-07-07 13:38:20 - train: epoch 0046, iter [03200, 05004], lr: 0.068358, loss: 1.8577
2022-07-07 13:39:06 - train: epoch 0046, iter [03300, 05004], lr: 0.068334, loss: 1.6814
2022-07-07 13:39:51 - train: epoch 0046, iter [03400, 05004], lr: 0.068309, loss: 1.6574
2022-07-07 13:40:37 - train: epoch 0046, iter [03500, 05004], lr: 0.068285, loss: 1.7789
2022-07-07 13:41:23 - train: epoch 0046, iter [03600, 05004], lr: 0.068261, loss: 1.5422
2022-07-07 13:42:09 - train: epoch 0046, iter [03700, 05004], lr: 0.068236, loss: 1.5181
2022-07-07 13:42:55 - train: epoch 0046, iter [03800, 05004], lr: 0.068212, loss: 1.8288
2022-07-07 13:43:40 - train: epoch 0046, iter [03900, 05004], lr: 0.068188, loss: 1.7397
2022-07-07 13:44:26 - train: epoch 0046, iter [04000, 05004], lr: 0.068163, loss: 1.5024
2022-07-07 13:45:12 - train: epoch 0046, iter [04100, 05004], lr: 0.068139, loss: 1.8904
2022-07-07 13:45:57 - train: epoch 0046, iter [04200, 05004], lr: 0.068115, loss: 1.5814
2022-07-07 13:46:43 - train: epoch 0046, iter [04300, 05004], lr: 0.068090, loss: 1.8635
2022-07-07 13:47:29 - train: epoch 0046, iter [04400, 05004], lr: 0.068066, loss: 1.7729
2022-07-07 13:48:15 - train: epoch 0046, iter [04500, 05004], lr: 0.068041, loss: 1.6196
2022-07-07 13:49:01 - train: epoch 0046, iter [04600, 05004], lr: 0.068017, loss: 1.7944
2022-07-07 13:49:46 - train: epoch 0046, iter [04700, 05004], lr: 0.067993, loss: 1.6257
2022-07-07 13:50:32 - train: epoch 0046, iter [04800, 05004], lr: 0.067968, loss: 1.6629
2022-07-07 13:51:18 - train: epoch 0046, iter [04900, 05004], lr: 0.067944, loss: 1.6531
2022-07-07 13:52:04 - train: epoch 0046, iter [05000, 05004], lr: 0.067919, loss: 1.6287
2022-07-07 13:52:06 - train: epoch 046, train_loss: 1.6600
2022-07-07 13:53:21 - eval: epoch: 046, acc1: 65.736%, acc5: 87.264%, test_loss: 1.4187, per_image_load_time: 2.058ms, per_image_inference_time: 0.827ms
2022-07-07 13:53:22 - until epoch: 046, best_acc1: 65.736%
2022-07-07 13:53:22 - epoch 047 lr: 0.067918
2022-07-07 13:54:13 - train: epoch 0047, iter [00100, 05004], lr: 0.067894, loss: 1.5795
2022-07-07 13:54:59 - train: epoch 0047, iter [00200, 05004], lr: 0.067870, loss: 1.7705
2022-07-07 13:55:44 - train: epoch 0047, iter [00300, 05004], lr: 0.067845, loss: 1.6047
2022-07-07 13:56:30 - train: epoch 0047, iter [00400, 05004], lr: 0.067821, loss: 1.5657
2022-07-07 13:57:16 - train: epoch 0047, iter [00500, 05004], lr: 0.067796, loss: 1.8853
2022-07-07 13:58:02 - train: epoch 0047, iter [00600, 05004], lr: 0.067772, loss: 1.6770
2022-07-07 13:58:47 - train: epoch 0047, iter [00700, 05004], lr: 0.067747, loss: 1.7815
2022-07-07 13:59:33 - train: epoch 0047, iter [00800, 05004], lr: 0.067723, loss: 1.4643
2022-07-07 14:00:19 - train: epoch 0047, iter [00900, 05004], lr: 0.067698, loss: 1.8388
2022-07-07 14:01:05 - train: epoch 0047, iter [01000, 05004], lr: 0.067674, loss: 1.6874
2022-07-07 14:01:51 - train: epoch 0047, iter [01100, 05004], lr: 0.067649, loss: 1.7814
2022-07-07 14:02:36 - train: epoch 0047, iter [01200, 05004], lr: 0.067625, loss: 1.6466
2022-07-07 14:03:22 - train: epoch 0047, iter [01300, 05004], lr: 0.067601, loss: 1.6463
2022-07-07 14:04:07 - train: epoch 0047, iter [01400, 05004], lr: 0.067576, loss: 1.6176
2022-07-07 14:04:53 - train: epoch 0047, iter [01500, 05004], lr: 0.067552, loss: 1.4965
2022-07-07 14:05:39 - train: epoch 0047, iter [01600, 05004], lr: 0.067527, loss: 1.5347
2022-07-07 14:06:25 - train: epoch 0047, iter [01700, 05004], lr: 0.067503, loss: 1.4889
2022-07-07 14:07:10 - train: epoch 0047, iter [01800, 05004], lr: 0.067478, loss: 1.5412
2022-07-07 14:07:56 - train: epoch 0047, iter [01900, 05004], lr: 0.067454, loss: 1.5325
2022-07-07 14:08:41 - train: epoch 0047, iter [02000, 05004], lr: 0.067429, loss: 1.5789
2022-07-07 14:09:27 - train: epoch 0047, iter [02100, 05004], lr: 0.067404, loss: 1.7629
2022-07-07 14:10:13 - train: epoch 0047, iter [02200, 05004], lr: 0.067380, loss: 1.8360
2022-07-07 14:10:58 - train: epoch 0047, iter [02300, 05004], lr: 0.067355, loss: 1.7925
2022-07-07 14:11:44 - train: epoch 0047, iter [02400, 05004], lr: 0.067331, loss: 1.4729
2022-07-07 14:12:30 - train: epoch 0047, iter [02500, 05004], lr: 0.067306, loss: 1.6419
2022-07-07 14:13:15 - train: epoch 0047, iter [02600, 05004], lr: 0.067282, loss: 1.9397
2022-07-07 14:14:01 - train: epoch 0047, iter [02700, 05004], lr: 0.067257, loss: 1.6104
2022-07-07 14:14:47 - train: epoch 0047, iter [02800, 05004], lr: 0.067233, loss: 1.8000
2022-07-07 14:15:32 - train: epoch 0047, iter [02900, 05004], lr: 0.067208, loss: 1.5450
2022-07-07 14:16:18 - train: epoch 0047, iter [03000, 05004], lr: 0.067184, loss: 1.6840
2022-07-07 14:17:04 - train: epoch 0047, iter [03100, 05004], lr: 0.067159, loss: 1.5870
2022-07-07 14:17:49 - train: epoch 0047, iter [03200, 05004], lr: 0.067134, loss: 1.9229
2022-07-07 14:18:35 - train: epoch 0047, iter [03300, 05004], lr: 0.067110, loss: 1.5332
2022-07-07 14:19:21 - train: epoch 0047, iter [03400, 05004], lr: 0.067085, loss: 1.6848
2022-07-07 14:20:07 - train: epoch 0047, iter [03500, 05004], lr: 0.067061, loss: 1.9175
2022-07-07 14:20:52 - train: epoch 0047, iter [03600, 05004], lr: 0.067036, loss: 1.8777
2022-07-07 14:21:38 - train: epoch 0047, iter [03700, 05004], lr: 0.067011, loss: 1.9075
2022-07-07 14:22:24 - train: epoch 0047, iter [03800, 05004], lr: 0.066987, loss: 1.6781
2022-07-07 14:23:09 - train: epoch 0047, iter [03900, 05004], lr: 0.066962, loss: 1.5180
2022-07-07 14:23:55 - train: epoch 0047, iter [04000, 05004], lr: 0.066938, loss: 1.7782
2022-07-07 14:24:41 - train: epoch 0047, iter [04100, 05004], lr: 0.066913, loss: 1.7365
2022-07-07 14:25:27 - train: epoch 0047, iter [04200, 05004], lr: 0.066888, loss: 1.6759
2022-07-07 14:26:12 - train: epoch 0047, iter [04300, 05004], lr: 0.066864, loss: 1.6043
2022-07-07 14:26:58 - train: epoch 0047, iter [04400, 05004], lr: 0.066839, loss: 1.6481
2022-07-07 14:27:44 - train: epoch 0047, iter [04500, 05004], lr: 0.066815, loss: 1.6989
2022-07-07 14:28:30 - train: epoch 0047, iter [04600, 05004], lr: 0.066790, loss: 1.6602
2022-07-07 14:29:15 - train: epoch 0047, iter [04700, 05004], lr: 0.066765, loss: 1.7463
2022-07-07 14:30:01 - train: epoch 0047, iter [04800, 05004], lr: 0.066741, loss: 1.6321
2022-07-07 14:30:47 - train: epoch 0047, iter [04900, 05004], lr: 0.066716, loss: 1.8304
2022-07-07 14:31:32 - train: epoch 0047, iter [05000, 05004], lr: 0.066691, loss: 1.5424
2022-07-07 14:31:35 - train: epoch 047, train_loss: 1.6535
2022-07-07 14:32:50 - eval: epoch: 047, acc1: 65.626%, acc5: 87.314%, test_loss: 1.4293, per_image_load_time: 2.055ms, per_image_inference_time: 0.821ms
2022-07-07 14:32:51 - until epoch: 047, best_acc1: 65.736%
2022-07-07 14:32:51 - epoch 048 lr: 0.066690
2022-07-07 14:33:42 - train: epoch 0048, iter [00100, 05004], lr: 0.066666, loss: 1.7637
2022-07-07 14:34:28 - train: epoch 0048, iter [00200, 05004], lr: 0.066641, loss: 1.9096
2022-07-07 14:35:14 - train: epoch 0048, iter [00300, 05004], lr: 0.066616, loss: 1.6406
2022-07-07 14:36:00 - train: epoch 0048, iter [00400, 05004], lr: 0.066592, loss: 1.6324
2022-07-07 14:36:46 - train: epoch 0048, iter [00500, 05004], lr: 0.066567, loss: 1.4965
2022-07-07 14:37:32 - train: epoch 0048, iter [00600, 05004], lr: 0.066542, loss: 1.6213
2022-07-07 14:38:18 - train: epoch 0048, iter [00700, 05004], lr: 0.066518, loss: 1.6403
2022-07-07 14:39:04 - train: epoch 0048, iter [00800, 05004], lr: 0.066493, loss: 1.6656
2022-07-07 14:39:49 - train: epoch 0048, iter [00900, 05004], lr: 0.066468, loss: 1.7812
2022-07-07 14:40:35 - train: epoch 0048, iter [01000, 05004], lr: 0.066444, loss: 1.6613
2022-07-07 14:41:21 - train: epoch 0048, iter [01100, 05004], lr: 0.066419, loss: 1.7111
2022-07-07 14:42:07 - train: epoch 0048, iter [01200, 05004], lr: 0.066394, loss: 1.7285
2022-07-07 14:42:53 - train: epoch 0048, iter [01300, 05004], lr: 0.066369, loss: 1.3709
2022-07-07 14:43:39 - train: epoch 0048, iter [01400, 05004], lr: 0.066345, loss: 1.6278
2022-07-07 14:44:25 - train: epoch 0048, iter [01500, 05004], lr: 0.066320, loss: 1.7516
2022-07-07 14:45:10 - train: epoch 0048, iter [01600, 05004], lr: 0.066295, loss: 1.5865
2022-07-07 14:45:56 - train: epoch 0048, iter [01700, 05004], lr: 0.066270, loss: 1.7678
2022-07-07 14:46:43 - train: epoch 0048, iter [01800, 05004], lr: 0.066246, loss: 1.7598
2022-07-07 14:47:28 - train: epoch 0048, iter [01900, 05004], lr: 0.066221, loss: 1.6849
2022-07-07 14:48:14 - train: epoch 0048, iter [02000, 05004], lr: 0.066196, loss: 1.8164
2022-07-07 14:49:00 - train: epoch 0048, iter [02100, 05004], lr: 0.066172, loss: 1.5728
2022-07-07 14:49:46 - train: epoch 0048, iter [02200, 05004], lr: 0.066147, loss: 1.8675
2022-07-07 14:50:32 - train: epoch 0048, iter [02300, 05004], lr: 0.066122, loss: 1.4713
2022-07-07 14:51:18 - train: epoch 0048, iter [02400, 05004], lr: 0.066097, loss: 1.8297
2022-07-07 14:52:03 - train: epoch 0048, iter [02500, 05004], lr: 0.066072, loss: 1.6795
2022-07-07 14:52:49 - train: epoch 0048, iter [02600, 05004], lr: 0.066048, loss: 1.8397
2022-07-07 14:53:35 - train: epoch 0048, iter [02700, 05004], lr: 0.066023, loss: 1.7799
2022-07-07 14:54:21 - train: epoch 0048, iter [02800, 05004], lr: 0.065998, loss: 1.6244
2022-07-07 14:55:06 - train: epoch 0048, iter [02900, 05004], lr: 0.065973, loss: 1.7942
2022-07-07 14:55:52 - train: epoch 0048, iter [03000, 05004], lr: 0.065949, loss: 1.5902
2022-07-07 14:56:37 - train: epoch 0048, iter [03100, 05004], lr: 0.065924, loss: 1.6174
2022-07-07 14:57:22 - train: epoch 0048, iter [03200, 05004], lr: 0.065899, loss: 1.5289
2022-07-07 14:58:07 - train: epoch 0048, iter [03300, 05004], lr: 0.065874, loss: 1.8206
2022-07-07 14:58:51 - train: epoch 0048, iter [03400, 05004], lr: 0.065849, loss: 1.5555
2022-07-07 14:59:36 - train: epoch 0048, iter [03500, 05004], lr: 0.065825, loss: 1.7939
2022-07-07 15:00:21 - train: epoch 0048, iter [03600, 05004], lr: 0.065800, loss: 1.6903
2022-07-07 15:01:05 - train: epoch 0048, iter [03700, 05004], lr: 0.065775, loss: 1.7019
2022-07-07 15:01:50 - train: epoch 0048, iter [03800, 05004], lr: 0.065750, loss: 1.6305
2022-07-07 15:02:35 - train: epoch 0048, iter [03900, 05004], lr: 0.065725, loss: 1.8329
2022-07-07 15:03:20 - train: epoch 0048, iter [04000, 05004], lr: 0.065700, loss: 1.5035
2022-07-07 15:04:05 - train: epoch 0048, iter [04100, 05004], lr: 0.065676, loss: 1.8540
2022-07-07 15:04:49 - train: epoch 0048, iter [04200, 05004], lr: 0.065651, loss: 1.4399
2022-07-07 15:05:34 - train: epoch 0048, iter [04300, 05004], lr: 0.065626, loss: 1.6884
2022-07-07 15:06:19 - train: epoch 0048, iter [04400, 05004], lr: 0.065601, loss: 1.5350
2022-07-07 15:07:03 - train: epoch 0048, iter [04500, 05004], lr: 0.065576, loss: 1.6654
2022-07-07 15:07:48 - train: epoch 0048, iter [04600, 05004], lr: 0.065551, loss: 1.5211
2022-07-07 15:08:32 - train: epoch 0048, iter [04700, 05004], lr: 0.065526, loss: 1.5913
2022-07-07 15:09:17 - train: epoch 0048, iter [04800, 05004], lr: 0.065502, loss: 2.0002
2022-07-07 15:10:02 - train: epoch 0048, iter [04900, 05004], lr: 0.065477, loss: 1.7528
2022-07-07 15:10:46 - train: epoch 0048, iter [05000, 05004], lr: 0.065452, loss: 1.6436
2022-07-07 15:10:49 - train: epoch 048, train_loss: 1.6466
2022-07-07 15:12:05 - eval: epoch: 048, acc1: 65.766%, acc5: 87.474%, test_loss: 1.4037, per_image_load_time: 2.123ms, per_image_inference_time: 0.842ms
2022-07-07 15:12:06 - until epoch: 048, best_acc1: 65.766%
2022-07-07 15:12:06 - epoch 049 lr: 0.065451
2022-07-07 15:12:56 - train: epoch 0049, iter [00100, 05004], lr: 0.065426, loss: 1.8065
2022-07-07 15:13:41 - train: epoch 0049, iter [00200, 05004], lr: 0.065401, loss: 1.5855
2022-07-07 15:14:26 - train: epoch 0049, iter [00300, 05004], lr: 0.065376, loss: 1.6872
2022-07-07 15:15:10 - train: epoch 0049, iter [00400, 05004], lr: 0.065351, loss: 1.7196
2022-07-07 15:15:55 - train: epoch 0049, iter [00500, 05004], lr: 0.065326, loss: 1.5143
2022-07-07 15:16:40 - train: epoch 0049, iter [00600, 05004], lr: 0.065302, loss: 1.5941
2022-07-07 15:17:24 - train: epoch 0049, iter [00700, 05004], lr: 0.065277, loss: 1.6982
2022-07-07 15:18:09 - train: epoch 0049, iter [00800, 05004], lr: 0.065252, loss: 1.9725
2022-07-07 15:18:54 - train: epoch 0049, iter [00900, 05004], lr: 0.065227, loss: 1.5325
2022-07-07 15:19:38 - train: epoch 0049, iter [01000, 05004], lr: 0.065202, loss: 1.7999
2022-07-07 15:20:23 - train: epoch 0049, iter [01100, 05004], lr: 0.065177, loss: 1.4615
2022-07-07 15:21:08 - train: epoch 0049, iter [01200, 05004], lr: 0.065152, loss: 1.4126
2022-07-07 15:21:53 - train: epoch 0049, iter [01300, 05004], lr: 0.065127, loss: 1.7400
2022-07-07 15:22:37 - train: epoch 0049, iter [01400, 05004], lr: 0.065102, loss: 1.8384
2022-07-07 15:23:22 - train: epoch 0049, iter [01500, 05004], lr: 0.065077, loss: 1.5512
2022-07-07 15:24:07 - train: epoch 0049, iter [01600, 05004], lr: 0.065052, loss: 1.8188
2022-07-07 15:24:52 - train: epoch 0049, iter [01700, 05004], lr: 0.065027, loss: 1.7474
2022-07-07 15:25:37 - train: epoch 0049, iter [01800, 05004], lr: 0.065002, loss: 1.4621
2022-07-07 15:26:21 - train: epoch 0049, iter [01900, 05004], lr: 0.064977, loss: 1.5995
2022-07-07 15:27:06 - train: epoch 0049, iter [02000, 05004], lr: 0.064952, loss: 1.5337
2022-07-07 15:27:51 - train: epoch 0049, iter [02100, 05004], lr: 0.064927, loss: 1.5116
2022-07-07 15:28:35 - train: epoch 0049, iter [02200, 05004], lr: 0.064903, loss: 1.5998
2022-07-07 15:29:20 - train: epoch 0049, iter [02300, 05004], lr: 0.064878, loss: 1.4898
2022-07-07 15:30:05 - train: epoch 0049, iter [02400, 05004], lr: 0.064853, loss: 1.8402
2022-07-07 15:30:49 - train: epoch 0049, iter [02500, 05004], lr: 0.064828, loss: 1.7149
2022-07-07 15:31:34 - train: epoch 0049, iter [02600, 05004], lr: 0.064803, loss: 1.5980
2022-07-07 15:32:19 - train: epoch 0049, iter [02700, 05004], lr: 0.064778, loss: 1.5974
2022-07-07 15:33:04 - train: epoch 0049, iter [02800, 05004], lr: 0.064753, loss: 1.6296
2022-07-07 15:33:48 - train: epoch 0049, iter [02900, 05004], lr: 0.064728, loss: 1.6950
2022-07-07 15:34:33 - train: epoch 0049, iter [03000, 05004], lr: 0.064703, loss: 1.7476
2022-07-07 15:35:18 - train: epoch 0049, iter [03100, 05004], lr: 0.064678, loss: 1.7008
2022-07-07 15:36:03 - train: epoch 0049, iter [03200, 05004], lr: 0.064653, loss: 1.7312
2022-07-07 15:36:48 - train: epoch 0049, iter [03300, 05004], lr: 0.064628, loss: 1.7146
2022-07-07 15:37:33 - train: epoch 0049, iter [03400, 05004], lr: 0.064603, loss: 1.8642
2022-07-07 15:38:18 - train: epoch 0049, iter [03500, 05004], lr: 0.064578, loss: 1.8259
2022-07-07 15:39:03 - train: epoch 0049, iter [03600, 05004], lr: 0.064553, loss: 1.8057
2022-07-07 15:39:48 - train: epoch 0049, iter [03700, 05004], lr: 0.064528, loss: 1.6668
2022-07-07 15:40:33 - train: epoch 0049, iter [03800, 05004], lr: 0.064502, loss: 1.7903
2022-07-07 15:41:18 - train: epoch 0049, iter [03900, 05004], lr: 0.064477, loss: 1.9336
2022-07-07 15:42:03 - train: epoch 0049, iter [04000, 05004], lr: 0.064452, loss: 1.6483
2022-07-07 15:42:48 - train: epoch 0049, iter [04100, 05004], lr: 0.064427, loss: 1.4383
2022-07-07 15:43:33 - train: epoch 0049, iter [04200, 05004], lr: 0.064402, loss: 1.6821
2022-07-07 15:44:18 - train: epoch 0049, iter [04300, 05004], lr: 0.064377, loss: 1.8836
2022-07-07 15:45:03 - train: epoch 0049, iter [04400, 05004], lr: 0.064352, loss: 1.6223
2022-07-07 15:45:48 - train: epoch 0049, iter [04500, 05004], lr: 0.064327, loss: 1.6094
2022-07-07 15:46:33 - train: epoch 0049, iter [04600, 05004], lr: 0.064302, loss: 1.8582
2022-07-07 15:47:18 - train: epoch 0049, iter [04700, 05004], lr: 0.064277, loss: 1.7460
2022-07-07 15:48:03 - train: epoch 0049, iter [04800, 05004], lr: 0.064252, loss: 1.4794
2022-07-07 15:48:48 - train: epoch 0049, iter [04900, 05004], lr: 0.064227, loss: 1.4664
2022-07-07 15:49:33 - train: epoch 0049, iter [05000, 05004], lr: 0.064202, loss: 1.5732
2022-07-07 15:49:35 - train: epoch 049, train_loss: 1.6337
2022-07-07 15:50:52 - eval: epoch: 049, acc1: 65.590%, acc5: 87.248%, test_loss: 1.4242, per_image_load_time: 2.159ms, per_image_inference_time: 0.822ms
2022-07-07 15:50:53 - until epoch: 049, best_acc1: 65.766%
2022-07-07 15:50:53 - epoch 050 lr: 0.064201
2022-07-07 15:51:43 - train: epoch 0050, iter [00100, 05004], lr: 0.064176, loss: 1.6888
2022-07-07 15:52:28 - train: epoch 0050, iter [00200, 05004], lr: 0.064151, loss: 1.6356
2022-07-07 15:53:13 - train: epoch 0050, iter [00300, 05004], lr: 0.064126, loss: 1.5846
2022-07-07 15:53:57 - train: epoch 0050, iter [00400, 05004], lr: 0.064100, loss: 1.5156
2022-07-07 15:54:42 - train: epoch 0050, iter [00500, 05004], lr: 0.064075, loss: 1.6768
2022-07-07 15:55:27 - train: epoch 0050, iter [00600, 05004], lr: 0.064050, loss: 1.7180
2022-07-07 15:56:12 - train: epoch 0050, iter [00700, 05004], lr: 0.064025, loss: 1.5026
2022-07-07 15:56:57 - train: epoch 0050, iter [00800, 05004], lr: 0.064000, loss: 1.3676
2022-07-07 15:57:41 - train: epoch 0050, iter [00900, 05004], lr: 0.063975, loss: 1.5716
2022-07-07 15:58:26 - train: epoch 0050, iter [01000, 05004], lr: 0.063950, loss: 1.7775
2022-07-07 15:59:11 - train: epoch 0050, iter [01100, 05004], lr: 0.063925, loss: 1.7420
2022-07-07 15:59:55 - train: epoch 0050, iter [01200, 05004], lr: 0.063900, loss: 1.4744
2022-07-07 16:00:40 - train: epoch 0050, iter [01300, 05004], lr: 0.063874, loss: 1.4973
2022-07-07 16:01:25 - train: epoch 0050, iter [01400, 05004], lr: 0.063849, loss: 1.7169
2022-07-07 16:02:10 - train: epoch 0050, iter [01500, 05004], lr: 0.063824, loss: 1.6409
2022-07-07 16:02:55 - train: epoch 0050, iter [01600, 05004], lr: 0.063799, loss: 1.5943
2022-07-07 16:03:39 - train: epoch 0050, iter [01700, 05004], lr: 0.063774, loss: 1.7815
2022-07-07 16:04:24 - train: epoch 0050, iter [01800, 05004], lr: 0.063749, loss: 1.6259
2022-07-07 16:05:09 - train: epoch 0050, iter [01900, 05004], lr: 0.063724, loss: 1.6236
2022-07-07 16:05:54 - train: epoch 0050, iter [02000, 05004], lr: 0.063698, loss: 1.5859
2022-07-07 16:06:39 - train: epoch 0050, iter [02100, 05004], lr: 0.063673, loss: 1.3485
2022-07-07 16:07:24 - train: epoch 0050, iter [02200, 05004], lr: 0.063648, loss: 1.7373
2022-07-07 16:08:09 - train: epoch 0050, iter [02300, 05004], lr: 0.063623, loss: 1.5852
2022-07-07 16:08:53 - train: epoch 0050, iter [02400, 05004], lr: 0.063598, loss: 1.5289
2022-07-07 16:09:38 - train: epoch 0050, iter [02500, 05004], lr: 0.063573, loss: 1.6553
2022-07-07 16:10:23 - train: epoch 0050, iter [02600, 05004], lr: 0.063547, loss: 1.4849
2022-07-07 16:11:08 - train: epoch 0050, iter [02700, 05004], lr: 0.063522, loss: 1.6788
2022-07-07 16:11:53 - train: epoch 0050, iter [02800, 05004], lr: 0.063497, loss: 1.7591
2022-07-07 16:12:38 - train: epoch 0050, iter [02900, 05004], lr: 0.063472, loss: 1.8416
2022-07-07 16:13:23 - train: epoch 0050, iter [03000, 05004], lr: 0.063447, loss: 1.8106
2022-07-07 16:14:09 - train: epoch 0050, iter [03100, 05004], lr: 0.063421, loss: 1.5534
2022-07-07 16:14:54 - train: epoch 0050, iter [03200, 05004], lr: 0.063396, loss: 1.6130
2022-07-07 16:15:39 - train: epoch 0050, iter [03300, 05004], lr: 0.063371, loss: 1.5591
2022-07-07 16:16:24 - train: epoch 0050, iter [03400, 05004], lr: 0.063346, loss: 1.4301
2022-07-07 16:17:09 - train: epoch 0050, iter [03500, 05004], lr: 0.063321, loss: 1.5585
2022-07-07 16:17:55 - train: epoch 0050, iter [03600, 05004], lr: 0.063295, loss: 1.6932
2022-07-07 16:18:40 - train: epoch 0050, iter [03700, 05004], lr: 0.063270, loss: 1.6578
2022-07-07 16:19:25 - train: epoch 0050, iter [03800, 05004], lr: 0.063245, loss: 1.4653
2022-07-07 16:20:10 - train: epoch 0050, iter [03900, 05004], lr: 0.063220, loss: 1.3785
2022-07-07 16:20:55 - train: epoch 0050, iter [04000, 05004], lr: 0.063194, loss: 1.7711
2022-07-07 16:21:40 - train: epoch 0050, iter [04100, 05004], lr: 0.063169, loss: 1.6420
2022-07-07 16:22:25 - train: epoch 0050, iter [04200, 05004], lr: 0.063144, loss: 1.6687
2022-07-07 16:23:11 - train: epoch 0050, iter [04300, 05004], lr: 0.063119, loss: 1.6278
2022-07-07 16:23:56 - train: epoch 0050, iter [04400, 05004], lr: 0.063094, loss: 1.5503
2022-07-07 16:24:41 - train: epoch 0050, iter [04500, 05004], lr: 0.063068, loss: 1.6381
2022-07-07 16:25:26 - train: epoch 0050, iter [04600, 05004], lr: 0.063043, loss: 1.7067
2022-07-07 16:26:11 - train: epoch 0050, iter [04700, 05004], lr: 0.063018, loss: 1.6500
2022-07-07 16:26:56 - train: epoch 0050, iter [04800, 05004], lr: 0.062992, loss: 1.3865
2022-07-07 16:27:41 - train: epoch 0050, iter [04900, 05004], lr: 0.062967, loss: 1.4544
2022-07-07 16:28:26 - train: epoch 0050, iter [05000, 05004], lr: 0.062942, loss: 1.5631
2022-07-07 16:28:29 - train: epoch 050, train_loss: 1.6231
2022-07-07 16:29:45 - eval: epoch: 050, acc1: 66.136%, acc5: 87.436%, test_loss: 1.3979, per_image_load_time: 2.075ms, per_image_inference_time: 0.829ms
2022-07-07 16:29:46 - until epoch: 050, best_acc1: 66.136%
2022-07-07 16:29:46 - epoch 051 lr: 0.062941
2022-07-07 16:30:37 - train: epoch 0051, iter [00100, 05004], lr: 0.062916, loss: 1.7186
2022-07-07 16:31:22 - train: epoch 0051, iter [00200, 05004], lr: 0.062890, loss: 1.8949
2022-07-07 16:32:08 - train: epoch 0051, iter [00300, 05004], lr: 0.062865, loss: 1.7133
2022-07-07 16:32:54 - train: epoch 0051, iter [00400, 05004], lr: 0.062840, loss: 1.4660
2022-07-07 16:33:39 - train: epoch 0051, iter [00500, 05004], lr: 0.062815, loss: 1.6491
2022-07-07 16:34:25 - train: epoch 0051, iter [00600, 05004], lr: 0.062789, loss: 1.5512
2022-07-07 16:35:10 - train: epoch 0051, iter [00700, 05004], lr: 0.062764, loss: 1.5590
2022-07-07 16:35:56 - train: epoch 0051, iter [00800, 05004], lr: 0.062739, loss: 1.8725
2022-07-07 16:36:41 - train: epoch 0051, iter [00900, 05004], lr: 0.062713, loss: 1.4798
2022-07-07 16:37:27 - train: epoch 0051, iter [01000, 05004], lr: 0.062688, loss: 1.8971
2022-07-07 16:38:13 - train: epoch 0051, iter [01100, 05004], lr: 0.062663, loss: 1.7543
2022-07-07 16:38:58 - train: epoch 0051, iter [01200, 05004], lr: 0.062637, loss: 1.5388
2022-07-07 16:39:44 - train: epoch 0051, iter [01300, 05004], lr: 0.062612, loss: 1.3041
2022-07-07 16:40:29 - train: epoch 0051, iter [01400, 05004], lr: 0.062587, loss: 1.4486
2022-07-07 16:41:15 - train: epoch 0051, iter [01500, 05004], lr: 0.062562, loss: 1.6028
2022-07-07 16:42:00 - train: epoch 0051, iter [01600, 05004], lr: 0.062536, loss: 1.4878
2022-07-07 16:42:46 - train: epoch 0051, iter [01700, 05004], lr: 0.062511, loss: 1.7622
2022-07-07 16:43:31 - train: epoch 0051, iter [01800, 05004], lr: 0.062486, loss: 1.5353
2022-07-07 16:44:17 - train: epoch 0051, iter [01900, 05004], lr: 0.062460, loss: 1.3432
2022-07-07 16:45:02 - train: epoch 0051, iter [02000, 05004], lr: 0.062435, loss: 1.5232
2022-07-07 16:45:47 - train: epoch 0051, iter [02100, 05004], lr: 0.062410, loss: 1.5867
2022-07-07 16:46:33 - train: epoch 0051, iter [02200, 05004], lr: 0.062384, loss: 1.6222
2022-07-07 16:47:18 - train: epoch 0051, iter [02300, 05004], lr: 0.062359, loss: 1.6762
2022-07-07 16:48:04 - train: epoch 0051, iter [02400, 05004], lr: 0.062334, loss: 1.6950
2022-07-07 16:48:50 - train: epoch 0051, iter [02500, 05004], lr: 0.062308, loss: 1.5639
2022-07-07 16:49:35 - train: epoch 0051, iter [02600, 05004], lr: 0.062283, loss: 1.4951
2022-07-07 16:50:20 - train: epoch 0051, iter [02700, 05004], lr: 0.062257, loss: 1.6355
2022-07-07 16:51:06 - train: epoch 0051, iter [02800, 05004], lr: 0.062232, loss: 1.5051
2022-07-07 16:51:51 - train: epoch 0051, iter [02900, 05004], lr: 0.062207, loss: 1.6067
2022-07-07 16:52:37 - train: epoch 0051, iter [03000, 05004], lr: 0.062181, loss: 1.5457
2022-07-07 16:53:22 - train: epoch 0051, iter [03100, 05004], lr: 0.062156, loss: 1.5205
2022-07-07 16:54:07 - train: epoch 0051, iter [03200, 05004], lr: 0.062131, loss: 1.6713
2022-07-07 16:54:53 - train: epoch 0051, iter [03300, 05004], lr: 0.062105, loss: 1.6921
2022-07-07 16:55:38 - train: epoch 0051, iter [03400, 05004], lr: 0.062080, loss: 1.6562
2022-07-07 16:56:23 - train: epoch 0051, iter [03500, 05004], lr: 0.062054, loss: 1.5511
2022-07-07 16:57:09 - train: epoch 0051, iter [03600, 05004], lr: 0.062029, loss: 1.5343
2022-07-07 16:57:54 - train: epoch 0051, iter [03700, 05004], lr: 0.062004, loss: 1.7326
2022-07-07 16:58:40 - train: epoch 0051, iter [03800, 05004], lr: 0.061978, loss: 1.5970
2022-07-07 16:59:25 - train: epoch 0051, iter [03900, 05004], lr: 0.061953, loss: 1.7122
2022-07-07 17:00:10 - train: epoch 0051, iter [04000, 05004], lr: 0.061927, loss: 1.6247
2022-07-07 17:00:56 - train: epoch 0051, iter [04100, 05004], lr: 0.061902, loss: 1.6585
2022-07-07 17:01:41 - train: epoch 0051, iter [04200, 05004], lr: 0.061877, loss: 1.9396
2022-07-07 17:02:26 - train: epoch 0051, iter [04300, 05004], lr: 0.061851, loss: 1.5795
2022-07-07 17:03:11 - train: epoch 0051, iter [04400, 05004], lr: 0.061826, loss: 1.5303
2022-07-07 17:03:57 - train: epoch 0051, iter [04500, 05004], lr: 0.061800, loss: 1.5013
2022-07-07 17:04:42 - train: epoch 0051, iter [04600, 05004], lr: 0.061775, loss: 1.7151
2022-07-07 17:05:27 - train: epoch 0051, iter [04700, 05004], lr: 0.061750, loss: 1.6559
2022-07-07 17:06:13 - train: epoch 0051, iter [04800, 05004], lr: 0.061724, loss: 1.5352
2022-07-07 17:06:58 - train: epoch 0051, iter [04900, 05004], lr: 0.061699, loss: 1.7182
2022-07-07 17:07:43 - train: epoch 0051, iter [05000, 05004], lr: 0.061673, loss: 1.5576
2022-07-07 17:07:45 - train: epoch 051, train_loss: 1.6128
2022-07-07 17:09:02 - eval: epoch: 051, acc1: 66.108%, acc5: 87.700%, test_loss: 1.3957, per_image_load_time: 2.126ms, per_image_inference_time: 0.818ms
2022-07-07 17:09:03 - until epoch: 051, best_acc1: 66.136%
2022-07-07 17:09:03 - epoch 052 lr: 0.061672
2022-07-07 17:09:55 - train: epoch 0052, iter [00100, 05004], lr: 0.061647, loss: 1.4617
2022-07-07 17:10:40 - train: epoch 0052, iter [00200, 05004], lr: 0.061621, loss: 1.5720
2022-07-07 17:11:25 - train: epoch 0052, iter [00300, 05004], lr: 0.061596, loss: 1.5928
2022-07-07 17:12:10 - train: epoch 0052, iter [00400, 05004], lr: 0.061570, loss: 1.5265
2022-07-07 17:12:55 - train: epoch 0052, iter [00500, 05004], lr: 0.061545, loss: 1.6532
2022-07-07 17:13:40 - train: epoch 0052, iter [00600, 05004], lr: 0.061520, loss: 1.4662
2022-07-07 17:14:25 - train: epoch 0052, iter [00700, 05004], lr: 0.061494, loss: 1.6431
2022-07-07 17:15:10 - train: epoch 0052, iter [00800, 05004], lr: 0.061469, loss: 1.6172
2022-07-07 17:15:55 - train: epoch 0052, iter [00900, 05004], lr: 0.061443, loss: 1.7076
2022-07-07 17:16:40 - train: epoch 0052, iter [01000, 05004], lr: 0.061418, loss: 1.8713
2022-07-07 17:17:25 - train: epoch 0052, iter [01100, 05004], lr: 0.061392, loss: 1.5111
2022-07-07 17:18:10 - train: epoch 0052, iter [01200, 05004], lr: 0.061367, loss: 1.4718
2022-07-07 17:18:55 - train: epoch 0052, iter [01300, 05004], lr: 0.061341, loss: 1.4580
2022-07-07 17:19:40 - train: epoch 0052, iter [01400, 05004], lr: 0.061316, loss: 1.8833
2022-07-07 17:20:25 - train: epoch 0052, iter [01500, 05004], lr: 0.061290, loss: 1.4291
2022-07-07 17:21:10 - train: epoch 0052, iter [01600, 05004], lr: 0.061265, loss: 1.4012
2022-07-07 17:21:55 - train: epoch 0052, iter [01700, 05004], lr: 0.061239, loss: 1.4939
2022-07-07 17:22:40 - train: epoch 0052, iter [01800, 05004], lr: 0.061214, loss: 1.4996
2022-07-07 17:23:25 - train: epoch 0052, iter [01900, 05004], lr: 0.061188, loss: 1.6339
2022-07-07 17:24:10 - train: epoch 0052, iter [02000, 05004], lr: 0.061163, loss: 1.6843
2022-07-07 17:24:55 - train: epoch 0052, iter [02100, 05004], lr: 0.061137, loss: 1.5791
2022-07-07 17:25:40 - train: epoch 0052, iter [02200, 05004], lr: 0.061112, loss: 1.7312
2022-07-07 17:26:26 - train: epoch 0052, iter [02300, 05004], lr: 0.061086, loss: 1.3830
2022-07-07 17:27:11 - train: epoch 0052, iter [02400, 05004], lr: 0.061061, loss: 1.4029
2022-07-07 17:27:56 - train: epoch 0052, iter [02500, 05004], lr: 0.061035, loss: 1.4587
2022-07-07 17:28:41 - train: epoch 0052, iter [02600, 05004], lr: 0.061010, loss: 1.2609
2022-07-07 17:29:26 - train: epoch 0052, iter [02700, 05004], lr: 0.060984, loss: 1.5040
2022-07-07 17:30:11 - train: epoch 0052, iter [02800, 05004], lr: 0.060959, loss: 1.6478
2022-07-07 17:30:56 - train: epoch 0052, iter [02900, 05004], lr: 0.060933, loss: 1.4387
2022-07-07 17:31:41 - train: epoch 0052, iter [03000, 05004], lr: 0.060908, loss: 1.6213
2022-07-07 17:32:26 - train: epoch 0052, iter [03100, 05004], lr: 0.060882, loss: 1.7079
2022-07-07 17:33:11 - train: epoch 0052, iter [03200, 05004], lr: 0.060857, loss: 1.6621
2022-07-07 17:33:57 - train: epoch 0052, iter [03300, 05004], lr: 0.060831, loss: 1.5691
2022-07-07 17:34:42 - train: epoch 0052, iter [03400, 05004], lr: 0.060806, loss: 1.6344
2022-07-07 17:35:27 - train: epoch 0052, iter [03500, 05004], lr: 0.060780, loss: 1.6593
2022-07-07 17:36:12 - train: epoch 0052, iter [03600, 05004], lr: 0.060755, loss: 1.6502
2022-07-07 17:36:57 - train: epoch 0052, iter [03700, 05004], lr: 0.060729, loss: 1.7675
2022-07-07 17:37:42 - train: epoch 0052, iter [03800, 05004], lr: 0.060703, loss: 1.5131
2022-07-07 17:38:28 - train: epoch 0052, iter [03900, 05004], lr: 0.060678, loss: 1.5004
2022-07-07 17:39:13 - train: epoch 0052, iter [04000, 05004], lr: 0.060652, loss: 1.8090
2022-07-07 17:39:58 - train: epoch 0052, iter [04100, 05004], lr: 0.060627, loss: 1.4834
2022-07-07 17:40:44 - train: epoch 0052, iter [04200, 05004], lr: 0.060601, loss: 1.5691
2022-07-07 17:41:29 - train: epoch 0052, iter [04300, 05004], lr: 0.060576, loss: 1.6759
2022-07-07 17:42:14 - train: epoch 0052, iter [04400, 05004], lr: 0.060550, loss: 1.6242
2022-07-07 17:42:59 - train: epoch 0052, iter [04500, 05004], lr: 0.060525, loss: 1.4502
2022-07-07 17:43:44 - train: epoch 0052, iter [04600, 05004], lr: 0.060499, loss: 1.6948
2022-07-07 17:44:29 - train: epoch 0052, iter [04700, 05004], lr: 0.060473, loss: 1.6491
2022-07-07 17:45:14 - train: epoch 0052, iter [04800, 05004], lr: 0.060448, loss: 1.4735
2022-07-07 17:46:00 - train: epoch 0052, iter [04900, 05004], lr: 0.060422, loss: 1.4806
2022-07-07 17:46:45 - train: epoch 0052, iter [05000, 05004], lr: 0.060397, loss: 1.6224
2022-07-07 17:46:47 - train: epoch 052, train_loss: 1.6032
2022-07-07 17:48:03 - eval: epoch: 052, acc1: 66.436%, acc5: 88.118%, test_loss: 1.3647, per_image_load_time: 2.090ms, per_image_inference_time: 0.827ms
2022-07-07 17:48:05 - until epoch: 052, best_acc1: 66.436%
2022-07-07 17:48:05 - epoch 053 lr: 0.060395
2022-07-07 17:48:56 - train: epoch 0053, iter [00100, 05004], lr: 0.060370, loss: 1.5698
2022-07-07 17:49:42 - train: epoch 0053, iter [00200, 05004], lr: 0.060344, loss: 1.8203
2022-07-07 17:50:27 - train: epoch 0053, iter [00300, 05004], lr: 0.060319, loss: 1.6064
2022-07-07 17:51:12 - train: epoch 0053, iter [00400, 05004], lr: 0.060293, loss: 1.5809
2022-07-07 17:51:58 - train: epoch 0053, iter [00500, 05004], lr: 0.060268, loss: 1.7077
2022-07-07 17:52:43 - train: epoch 0053, iter [00600, 05004], lr: 0.060242, loss: 1.5770
2022-07-07 17:53:28 - train: epoch 0053, iter [00700, 05004], lr: 0.060216, loss: 1.3769
2022-07-07 17:54:14 - train: epoch 0053, iter [00800, 05004], lr: 0.060191, loss: 1.6320
2022-07-07 17:54:59 - train: epoch 0053, iter [00900, 05004], lr: 0.060165, loss: 1.5508
2022-07-07 17:55:44 - train: epoch 0053, iter [01000, 05004], lr: 0.060140, loss: 1.5219
2022-07-07 17:56:29 - train: epoch 0053, iter [01100, 05004], lr: 0.060114, loss: 1.5699
2022-07-07 17:57:14 - train: epoch 0053, iter [01200, 05004], lr: 0.060088, loss: 1.5295
2022-07-07 17:57:59 - train: epoch 0053, iter [01300, 05004], lr: 0.060063, loss: 1.5474
2022-07-07 17:58:45 - train: epoch 0053, iter [01400, 05004], lr: 0.060037, loss: 1.9099
2022-07-07 17:59:30 - train: epoch 0053, iter [01500, 05004], lr: 0.060011, loss: 1.6264
2022-07-07 18:00:15 - train: epoch 0053, iter [01600, 05004], lr: 0.059986, loss: 1.8788
2022-07-07 18:01:00 - train: epoch 0053, iter [01700, 05004], lr: 0.059960, loss: 1.7050
2022-07-07 18:01:45 - train: epoch 0053, iter [01800, 05004], lr: 0.059935, loss: 1.7384
2022-07-07 18:02:30 - train: epoch 0053, iter [01900, 05004], lr: 0.059909, loss: 1.3212
2022-07-07 18:03:15 - train: epoch 0053, iter [02000, 05004], lr: 0.059883, loss: 1.6213
2022-07-07 18:04:00 - train: epoch 0053, iter [02100, 05004], lr: 0.059858, loss: 1.6070
2022-07-07 18:04:45 - train: epoch 0053, iter [02200, 05004], lr: 0.059832, loss: 1.5459
2022-07-07 18:05:31 - train: epoch 0053, iter [02300, 05004], lr: 0.059806, loss: 1.5783
2022-07-07 18:06:16 - train: epoch 0053, iter [02400, 05004], lr: 0.059781, loss: 1.5893
2022-07-07 18:07:01 - train: epoch 0053, iter [02500, 05004], lr: 0.059755, loss: 1.8325
2022-07-07 18:07:46 - train: epoch 0053, iter [02600, 05004], lr: 0.059729, loss: 1.5935
2022-07-07 18:08:31 - train: epoch 0053, iter [02700, 05004], lr: 0.059704, loss: 1.9196
2022-07-07 18:09:16 - train: epoch 0053, iter [02800, 05004], lr: 0.059678, loss: 1.7778
2022-07-07 18:10:01 - train: epoch 0053, iter [02900, 05004], lr: 0.059652, loss: 1.4339
2022-07-07 18:10:46 - train: epoch 0053, iter [03000, 05004], lr: 0.059627, loss: 1.3759
2022-07-07 18:11:32 - train: epoch 0053, iter [03100, 05004], lr: 0.059601, loss: 1.8123
2022-07-07 18:12:17 - train: epoch 0053, iter [03200, 05004], lr: 0.059575, loss: 1.8641
2022-07-07 18:13:02 - train: epoch 0053, iter [03300, 05004], lr: 0.059550, loss: 1.6233
2022-07-07 18:13:47 - train: epoch 0053, iter [03400, 05004], lr: 0.059524, loss: 1.6653
2022-07-07 18:14:32 - train: epoch 0053, iter [03500, 05004], lr: 0.059498, loss: 1.7408
2022-07-07 18:15:17 - train: epoch 0053, iter [03600, 05004], lr: 0.059473, loss: 1.7156
2022-07-07 18:16:02 - train: epoch 0053, iter [03700, 05004], lr: 0.059447, loss: 1.8511
2022-07-07 18:16:48 - train: epoch 0053, iter [03800, 05004], lr: 0.059421, loss: 1.5728
2022-07-07 18:17:33 - train: epoch 0053, iter [03900, 05004], lr: 0.059396, loss: 1.7095
2022-07-07 18:18:18 - train: epoch 0053, iter [04000, 05004], lr: 0.059370, loss: 1.6543
2022-07-07 18:19:03 - train: epoch 0053, iter [04100, 05004], lr: 0.059344, loss: 1.6820
2022-07-07 18:19:48 - train: epoch 0053, iter [04200, 05004], lr: 0.059318, loss: 1.6766
2022-07-07 18:20:34 - train: epoch 0053, iter [04300, 05004], lr: 0.059293, loss: 1.8740
2022-07-07 18:21:19 - train: epoch 0053, iter [04400, 05004], lr: 0.059267, loss: 1.5376
2022-07-07 18:22:04 - train: epoch 0053, iter [04500, 05004], lr: 0.059241, loss: 1.7571
2022-07-07 18:22:49 - train: epoch 0053, iter [04600, 05004], lr: 0.059216, loss: 1.4965
2022-07-07 18:23:35 - train: epoch 0053, iter [04700, 05004], lr: 0.059190, loss: 1.7548
2022-07-07 18:24:20 - train: epoch 0053, iter [04800, 05004], lr: 0.059164, loss: 1.8876
2022-07-07 18:25:05 - train: epoch 0053, iter [04900, 05004], lr: 0.059139, loss: 1.4483
2022-07-07 18:25:50 - train: epoch 0053, iter [05000, 05004], lr: 0.059113, loss: 1.5327
2022-07-07 18:25:52 - train: epoch 053, train_loss: 1.5930
2022-07-07 18:27:09 - eval: epoch: 053, acc1: 66.630%, acc5: 87.996%, test_loss: 1.3624, per_image_load_time: 2.087ms, per_image_inference_time: 0.839ms
2022-07-07 18:27:10 - until epoch: 053, best_acc1: 66.630%
2022-07-07 18:27:10 - epoch 054 lr: 0.059112
2022-07-07 18:28:01 - train: epoch 0054, iter [00100, 05004], lr: 0.059086, loss: 1.3669
2022-07-07 18:28:47 - train: epoch 0054, iter [00200, 05004], lr: 0.059060, loss: 1.9680
2022-07-07 18:29:32 - train: epoch 0054, iter [00300, 05004], lr: 0.059035, loss: 1.5581
2022-07-07 18:30:17 - train: epoch 0054, iter [00400, 05004], lr: 0.059009, loss: 1.3589
2022-07-07 18:31:02 - train: epoch 0054, iter [00500, 05004], lr: 0.058983, loss: 1.6168
2022-07-07 18:31:47 - train: epoch 0054, iter [00600, 05004], lr: 0.058957, loss: 1.3389
2022-07-07 18:32:32 - train: epoch 0054, iter [00700, 05004], lr: 0.058932, loss: 1.5184
2022-07-07 18:33:18 - train: epoch 0054, iter [00800, 05004], lr: 0.058906, loss: 1.6207
2022-07-07 18:34:03 - train: epoch 0054, iter [00900, 05004], lr: 0.058880, loss: 1.3552
2022-07-07 18:34:48 - train: epoch 0054, iter [01000, 05004], lr: 0.058854, loss: 1.3849
2022-07-07 18:35:33 - train: epoch 0054, iter [01100, 05004], lr: 0.058829, loss: 1.4498
2022-07-07 18:36:18 - train: epoch 0054, iter [01200, 05004], lr: 0.058803, loss: 1.6862
2022-07-07 18:37:03 - train: epoch 0054, iter [01300, 05004], lr: 0.058777, loss: 1.5165
2022-07-07 18:37:48 - train: epoch 0054, iter [01400, 05004], lr: 0.058751, loss: 1.5724
2022-07-07 18:38:33 - train: epoch 0054, iter [01500, 05004], lr: 0.058726, loss: 1.6224
2022-07-07 18:39:19 - train: epoch 0054, iter [01600, 05004], lr: 0.058700, loss: 1.2525
2022-07-07 18:40:04 - train: epoch 0054, iter [01700, 05004], lr: 0.058674, loss: 1.6278
2022-07-07 18:40:49 - train: epoch 0054, iter [01800, 05004], lr: 0.058648, loss: 1.5142
2022-07-07 18:41:34 - train: epoch 0054, iter [01900, 05004], lr: 0.058623, loss: 1.9469
2022-07-07 18:42:19 - train: epoch 0054, iter [02000, 05004], lr: 0.058597, loss: 1.7125
2022-07-07 18:43:04 - train: epoch 0054, iter [02100, 05004], lr: 0.058571, loss: 1.3202
2022-07-07 18:43:49 - train: epoch 0054, iter [02200, 05004], lr: 0.058545, loss: 1.5668
2022-07-07 18:44:34 - train: epoch 0054, iter [02300, 05004], lr: 0.058520, loss: 1.6296
2022-07-07 18:45:19 - train: epoch 0054, iter [02400, 05004], lr: 0.058494, loss: 1.5613
2022-07-07 18:46:04 - train: epoch 0054, iter [02500, 05004], lr: 0.058468, loss: 1.6232
2022-07-07 18:46:49 - train: epoch 0054, iter [02600, 05004], lr: 0.058442, loss: 1.4798
2022-07-07 18:47:34 - train: epoch 0054, iter [02700, 05004], lr: 0.058416, loss: 1.7314
2022-07-07 18:48:19 - train: epoch 0054, iter [02800, 05004], lr: 0.058391, loss: 1.8853
2022-07-07 18:49:04 - train: epoch 0054, iter [02900, 05004], lr: 0.058365, loss: 1.4130
2022-07-07 18:49:49 - train: epoch 0054, iter [03000, 05004], lr: 0.058339, loss: 1.7088
2022-07-07 18:50:34 - train: epoch 0054, iter [03100, 05004], lr: 0.058313, loss: 1.5424
2022-07-07 18:51:19 - train: epoch 0054, iter [03200, 05004], lr: 0.058287, loss: 1.7874
2022-07-07 18:52:04 - train: epoch 0054, iter [03300, 05004], lr: 0.058262, loss: 1.4295
2022-07-07 18:52:49 - train: epoch 0054, iter [03400, 05004], lr: 0.058236, loss: 1.5924
2022-07-07 18:53:34 - train: epoch 0054, iter [03500, 05004], lr: 0.058210, loss: 1.6644
2022-07-07 18:54:20 - train: epoch 0054, iter [03600, 05004], lr: 0.058184, loss: 1.5451
2022-07-07 18:55:05 - train: epoch 0054, iter [03700, 05004], lr: 0.058158, loss: 1.4303
2022-07-07 18:55:50 - train: epoch 0054, iter [03800, 05004], lr: 0.058133, loss: 1.6210
2022-07-07 18:56:35 - train: epoch 0054, iter [03900, 05004], lr: 0.058107, loss: 1.5861
2022-07-07 18:57:20 - train: epoch 0054, iter [04000, 05004], lr: 0.058081, loss: 1.4437
2022-07-07 18:58:05 - train: epoch 0054, iter [04100, 05004], lr: 0.058055, loss: 1.5951
2022-07-07 18:58:51 - train: epoch 0054, iter [04200, 05004], lr: 0.058029, loss: 1.5287
2022-07-07 18:59:36 - train: epoch 0054, iter [04300, 05004], lr: 0.058004, loss: 1.5529
2022-07-07 19:00:21 - train: epoch 0054, iter [04400, 05004], lr: 0.057978, loss: 1.3842
2022-07-07 19:01:06 - train: epoch 0054, iter [04500, 05004], lr: 0.057952, loss: 1.4260
2022-07-07 19:01:52 - train: epoch 0054, iter [04600, 05004], lr: 0.057926, loss: 1.6337
2022-07-07 19:02:37 - train: epoch 0054, iter [04700, 05004], lr: 0.057900, loss: 1.8026
2022-07-07 19:03:22 - train: epoch 0054, iter [04800, 05004], lr: 0.057874, loss: 1.7916
2022-07-07 19:04:07 - train: epoch 0054, iter [04900, 05004], lr: 0.057849, loss: 1.4612
2022-07-07 19:04:52 - train: epoch 0054, iter [05000, 05004], lr: 0.057823, loss: 1.5991
2022-07-07 19:04:55 - train: epoch 054, train_loss: 1.5854
2022-07-07 19:06:13 - eval: epoch: 054, acc1: 66.764%, acc5: 88.118%, test_loss: 1.3671, per_image_load_time: 1.830ms, per_image_inference_time: 0.841ms
2022-07-07 19:06:14 - until epoch: 054, best_acc1: 66.764%
2022-07-07 19:06:14 - epoch 055 lr: 0.057821
2022-07-07 19:07:05 - train: epoch 0055, iter [00100, 05004], lr: 0.057796, loss: 1.5172
2022-07-07 19:07:50 - train: epoch 0055, iter [00200, 05004], lr: 0.057770, loss: 1.4245
2022-07-07 19:08:35 - train: epoch 0055, iter [00300, 05004], lr: 0.057744, loss: 1.3557
2022-07-07 19:09:21 - train: epoch 0055, iter [00400, 05004], lr: 0.057718, loss: 1.4782
2022-07-07 19:10:06 - train: epoch 0055, iter [00500, 05004], lr: 0.057693, loss: 1.2801
2022-07-07 19:10:51 - train: epoch 0055, iter [00600, 05004], lr: 0.057667, loss: 1.4856
2022-07-07 19:11:37 - train: epoch 0055, iter [00700, 05004], lr: 0.057641, loss: 1.7057
2022-07-07 19:12:22 - train: epoch 0055, iter [00800, 05004], lr: 0.057615, loss: 1.4109
2022-07-07 19:13:07 - train: epoch 0055, iter [00900, 05004], lr: 0.057589, loss: 1.5824
2022-07-07 19:13:53 - train: epoch 0055, iter [01000, 05004], lr: 0.057563, loss: 1.5631
2022-07-07 19:14:38 - train: epoch 0055, iter [01100, 05004], lr: 0.057537, loss: 1.5546
2022-07-07 19:15:23 - train: epoch 0055, iter [01200, 05004], lr: 0.057512, loss: 1.6220
2022-07-07 19:16:08 - train: epoch 0055, iter [01300, 05004], lr: 0.057486, loss: 1.7388
2022-07-07 19:16:53 - train: epoch 0055, iter [01400, 05004], lr: 0.057460, loss: 1.4948
2022-07-07 19:17:38 - train: epoch 0055, iter [01500, 05004], lr: 0.057434, loss: 1.5828
2022-07-07 19:18:23 - train: epoch 0055, iter [01600, 05004], lr: 0.057408, loss: 1.7154
2022-07-07 19:19:08 - train: epoch 0055, iter [01700, 05004], lr: 0.057382, loss: 1.7209
2022-07-07 19:19:53 - train: epoch 0055, iter [01800, 05004], lr: 0.057356, loss: 1.6721
2022-07-07 19:20:37 - train: epoch 0055, iter [01900, 05004], lr: 0.057330, loss: 1.5757
2022-07-07 19:21:22 - train: epoch 0055, iter [02000, 05004], lr: 0.057305, loss: 1.6076
2022-07-07 19:22:07 - train: epoch 0055, iter [02100, 05004], lr: 0.057279, loss: 1.4645
2022-07-07 19:22:52 - train: epoch 0055, iter [02200, 05004], lr: 0.057253, loss: 1.6600
2022-07-07 19:23:37 - train: epoch 0055, iter [02300, 05004], lr: 0.057227, loss: 1.5679
2022-07-07 19:24:22 - train: epoch 0055, iter [02400, 05004], lr: 0.057201, loss: 1.4703
2022-07-07 19:25:07 - train: epoch 0055, iter [02500, 05004], lr: 0.057175, loss: 1.5794
2022-07-07 19:25:52 - train: epoch 0055, iter [02600, 05004], lr: 0.057149, loss: 1.3277
2022-07-07 19:26:37 - train: epoch 0055, iter [02700, 05004], lr: 0.057123, loss: 1.3570
2022-07-07 19:27:22 - train: epoch 0055, iter [02800, 05004], lr: 0.057097, loss: 1.5717
2022-07-07 19:28:08 - train: epoch 0055, iter [02900, 05004], lr: 0.057072, loss: 1.6340
2022-07-07 19:28:53 - train: epoch 0055, iter [03000, 05004], lr: 0.057046, loss: 1.5040
2022-07-07 19:29:38 - train: epoch 0055, iter [03100, 05004], lr: 0.057020, loss: 1.7810
2022-07-07 19:30:23 - train: epoch 0055, iter [03200, 05004], lr: 0.056994, loss: 1.5386
2022-07-07 19:31:08 - train: epoch 0055, iter [03300, 05004], lr: 0.056968, loss: 1.4076
2022-07-07 19:31:53 - train: epoch 0055, iter [03400, 05004], lr: 0.056942, loss: 1.4739
2022-07-07 19:32:38 - train: epoch 0055, iter [03500, 05004], lr: 0.056916, loss: 1.4265
2022-07-07 19:33:23 - train: epoch 0055, iter [03600, 05004], lr: 0.056890, loss: 1.5719
2022-07-07 19:34:09 - train: epoch 0055, iter [03700, 05004], lr: 0.056864, loss: 1.5577
2022-07-07 19:34:54 - train: epoch 0055, iter [03800, 05004], lr: 0.056838, loss: 1.6420
2022-07-07 19:35:39 - train: epoch 0055, iter [03900, 05004], lr: 0.056813, loss: 1.9436
2022-07-07 19:36:24 - train: epoch 0055, iter [04000, 05004], lr: 0.056787, loss: 1.6486
2022-07-07 19:37:09 - train: epoch 0055, iter [04100, 05004], lr: 0.056761, loss: 1.5355
2022-07-07 19:37:55 - train: epoch 0055, iter [04200, 05004], lr: 0.056735, loss: 1.6360
2022-07-07 19:38:40 - train: epoch 0055, iter [04300, 05004], lr: 0.056709, loss: 1.7041
2022-07-07 19:39:25 - train: epoch 0055, iter [04400, 05004], lr: 0.056683, loss: 1.7427
2022-07-07 19:40:10 - train: epoch 0055, iter [04500, 05004], lr: 0.056657, loss: 1.6298
2022-07-07 19:40:56 - train: epoch 0055, iter [04600, 05004], lr: 0.056631, loss: 1.6488
2022-07-07 19:41:41 - train: epoch 0055, iter [04700, 05004], lr: 0.056605, loss: 1.5062
2022-07-07 19:42:26 - train: epoch 0055, iter [04800, 05004], lr: 0.056579, loss: 1.6277
2022-07-07 19:43:11 - train: epoch 0055, iter [04900, 05004], lr: 0.056553, loss: 1.4633
2022-07-07 19:43:57 - train: epoch 0055, iter [05000, 05004], lr: 0.056527, loss: 1.6850
2022-07-07 19:43:59 - train: epoch 055, train_loss: 1.5730
2022-07-07 19:45:14 - eval: epoch: 055, acc1: 66.936%, acc5: 88.284%, test_loss: 1.3429, per_image_load_time: 1.389ms, per_image_inference_time: 0.823ms
2022-07-07 19:45:16 - until epoch: 055, best_acc1: 66.936%
2022-07-07 19:45:16 - epoch 056 lr: 0.056526
2022-07-07 19:46:07 - train: epoch 0056, iter [00100, 05004], lr: 0.056500, loss: 1.6459
2022-07-07 19:46:52 - train: epoch 0056, iter [00200, 05004], lr: 0.056474, loss: 1.6954
2022-07-07 19:47:38 - train: epoch 0056, iter [00300, 05004], lr: 0.056448, loss: 1.5546
2022-07-07 19:48:23 - train: epoch 0056, iter [00400, 05004], lr: 0.056423, loss: 1.4865
2022-07-07 19:49:09 - train: epoch 0056, iter [00500, 05004], lr: 0.056397, loss: 1.4920
2022-07-07 19:49:54 - train: epoch 0056, iter [00600, 05004], lr: 0.056371, loss: 1.5963
2022-07-07 19:50:40 - train: epoch 0056, iter [00700, 05004], lr: 0.056345, loss: 1.5823
2022-07-07 19:51:25 - train: epoch 0056, iter [00800, 05004], lr: 0.056319, loss: 1.7743
2022-07-07 19:52:10 - train: epoch 0056, iter [00900, 05004], lr: 0.056293, loss: 1.6405
2022-07-07 19:52:56 - train: epoch 0056, iter [01000, 05004], lr: 0.056267, loss: 1.5013
2022-07-07 19:53:41 - train: epoch 0056, iter [01100, 05004], lr: 0.056241, loss: 1.4256
2022-07-07 19:54:27 - train: epoch 0056, iter [01200, 05004], lr: 0.056215, loss: 1.4350
2022-07-07 19:55:12 - train: epoch 0056, iter [01300, 05004], lr: 0.056189, loss: 1.6094
2022-07-07 19:55:57 - train: epoch 0056, iter [01400, 05004], lr: 0.056163, loss: 1.5216
2022-07-07 19:56:43 - train: epoch 0056, iter [01500, 05004], lr: 0.056137, loss: 1.7697
2022-07-07 19:57:29 - train: epoch 0056, iter [01600, 05004], lr: 0.056111, loss: 1.3874
2022-07-07 19:58:14 - train: epoch 0056, iter [01700, 05004], lr: 0.056085, loss: 1.6625
2022-07-07 19:59:00 - train: epoch 0056, iter [01800, 05004], lr: 0.056059, loss: 1.7548
2022-07-07 19:59:45 - train: epoch 0056, iter [01900, 05004], lr: 0.056033, loss: 1.4441
2022-07-07 20:00:31 - train: epoch 0056, iter [02000, 05004], lr: 0.056007, loss: 1.5047
2022-07-07 20:01:17 - train: epoch 0056, iter [02100, 05004], lr: 0.055981, loss: 1.6217
2022-07-07 20:02:02 - train: epoch 0056, iter [02200, 05004], lr: 0.055955, loss: 1.6864
2022-07-07 20:02:48 - train: epoch 0056, iter [02300, 05004], lr: 0.055929, loss: 1.7073
2022-07-07 20:03:33 - train: epoch 0056, iter [02400, 05004], lr: 0.055903, loss: 1.5443
2022-07-07 20:04:19 - train: epoch 0056, iter [02500, 05004], lr: 0.055877, loss: 1.8027
2022-07-07 20:05:04 - train: epoch 0056, iter [02600, 05004], lr: 0.055851, loss: 1.5405
2022-07-07 20:05:50 - train: epoch 0056, iter [02700, 05004], lr: 0.055825, loss: 1.6563
2022-07-07 20:06:35 - train: epoch 0056, iter [02800, 05004], lr: 0.055799, loss: 1.4678
2022-07-07 20:07:21 - train: epoch 0056, iter [02900, 05004], lr: 0.055773, loss: 1.6789
2022-07-07 20:08:06 - train: epoch 0056, iter [03000, 05004], lr: 0.055747, loss: 1.7317
2022-07-07 20:08:52 - train: epoch 0056, iter [03100, 05004], lr: 0.055721, loss: 1.4899
2022-07-07 20:09:38 - train: epoch 0056, iter [03200, 05004], lr: 0.055696, loss: 1.4082
2022-07-07 20:10:24 - train: epoch 0056, iter [03300, 05004], lr: 0.055670, loss: 1.7503
2022-07-07 20:11:09 - train: epoch 0056, iter [03400, 05004], lr: 0.055644, loss: 1.4822
2022-07-07 20:11:55 - train: epoch 0056, iter [03500, 05004], lr: 0.055618, loss: 1.4565
2022-07-07 20:12:41 - train: epoch 0056, iter [03600, 05004], lr: 0.055592, loss: 1.2899
2022-07-07 20:13:26 - train: epoch 0056, iter [03700, 05004], lr: 0.055566, loss: 1.4201
2022-07-07 20:14:12 - train: epoch 0056, iter [03800, 05004], lr: 0.055540, loss: 1.5111
2022-07-07 20:14:57 - train: epoch 0056, iter [03900, 05004], lr: 0.055514, loss: 1.7764
2022-07-07 20:15:43 - train: epoch 0056, iter [04000, 05004], lr: 0.055488, loss: 1.6057
2022-07-07 20:16:29 - train: epoch 0056, iter [04100, 05004], lr: 0.055462, loss: 1.8088
2022-07-07 20:17:14 - train: epoch 0056, iter [04200, 05004], lr: 0.055436, loss: 1.5948
2022-07-07 20:18:00 - train: epoch 0056, iter [04300, 05004], lr: 0.055410, loss: 1.4399
2022-07-07 20:18:46 - train: epoch 0056, iter [04400, 05004], lr: 0.055384, loss: 1.6081
2022-07-07 20:19:31 - train: epoch 0056, iter [04500, 05004], lr: 0.055358, loss: 1.5727
2022-07-07 20:20:17 - train: epoch 0056, iter [04600, 05004], lr: 0.055332, loss: 1.6477
2022-07-07 20:21:03 - train: epoch 0056, iter [04700, 05004], lr: 0.055306, loss: 1.6175
2022-07-07 20:21:48 - train: epoch 0056, iter [04800, 05004], lr: 0.055279, loss: 1.6884
2022-07-07 20:22:34 - train: epoch 0056, iter [04900, 05004], lr: 0.055253, loss: 1.5855
2022-07-07 20:23:19 - train: epoch 0056, iter [05000, 05004], lr: 0.055227, loss: 1.7237
2022-07-07 20:23:22 - train: epoch 056, train_loss: 1.5603
2022-07-07 20:24:40 - eval: epoch: 056, acc1: 66.894%, acc5: 88.284%, test_loss: 1.3764, per_image_load_time: 1.921ms, per_image_inference_time: 0.878ms
2022-07-07 20:24:41 - until epoch: 056, best_acc1: 66.936%
2022-07-07 20:24:41 - epoch 057 lr: 0.055226
2022-07-07 20:25:33 - train: epoch 0057, iter [00100, 05004], lr: 0.055200, loss: 1.7161
2022-07-07 20:26:18 - train: epoch 0057, iter [00200, 05004], lr: 0.055174, loss: 1.4095
2022-07-07 20:27:03 - train: epoch 0057, iter [00300, 05004], lr: 0.055148, loss: 1.3804
2022-07-07 20:27:48 - train: epoch 0057, iter [00400, 05004], lr: 0.055122, loss: 1.5771
2022-07-07 20:28:33 - train: epoch 0057, iter [00500, 05004], lr: 0.055096, loss: 1.3015
2022-07-07 20:29:19 - train: epoch 0057, iter [00600, 05004], lr: 0.055070, loss: 1.6533
2022-07-07 20:30:04 - train: epoch 0057, iter [00700, 05004], lr: 0.055044, loss: 1.3542
2022-07-07 20:30:49 - train: epoch 0057, iter [00800, 05004], lr: 0.055018, loss: 1.5153
2022-07-07 20:31:34 - train: epoch 0057, iter [00900, 05004], lr: 0.054992, loss: 1.6345
2022-07-07 20:32:19 - train: epoch 0057, iter [01000, 05004], lr: 0.054966, loss: 1.5009
2022-07-07 20:33:04 - train: epoch 0057, iter [01100, 05004], lr: 0.054940, loss: 1.4722
2022-07-07 20:33:50 - train: epoch 0057, iter [01200, 05004], lr: 0.054914, loss: 1.4820
2022-07-07 20:34:35 - train: epoch 0057, iter [01300, 05004], lr: 0.054888, loss: 1.4779
2022-07-07 20:35:20 - train: epoch 0057, iter [01400, 05004], lr: 0.054862, loss: 1.5217
2022-07-07 20:36:05 - train: epoch 0057, iter [01500, 05004], lr: 0.054836, loss: 1.7206
2022-07-07 20:36:50 - train: epoch 0057, iter [01600, 05004], lr: 0.054810, loss: 1.7765
2022-07-07 20:37:36 - train: epoch 0057, iter [01700, 05004], lr: 0.054784, loss: 1.6598
2022-07-07 20:38:21 - train: epoch 0057, iter [01800, 05004], lr: 0.054758, loss: 1.6223
2022-07-07 20:39:06 - train: epoch 0057, iter [01900, 05004], lr: 0.054732, loss: 1.4672
2022-07-07 20:39:52 - train: epoch 0057, iter [02000, 05004], lr: 0.054706, loss: 1.5546
2022-07-07 20:40:37 - train: epoch 0057, iter [02100, 05004], lr: 0.054680, loss: 1.6447
2022-07-07 20:41:22 - train: epoch 0057, iter [02200, 05004], lr: 0.054654, loss: 1.5882
2022-07-07 20:42:08 - train: epoch 0057, iter [02300, 05004], lr: 0.054628, loss: 1.4135
2022-07-07 20:42:53 - train: epoch 0057, iter [02400, 05004], lr: 0.054602, loss: 1.4645
2022-07-07 20:43:38 - train: epoch 0057, iter [02500, 05004], lr: 0.054576, loss: 1.5688
2022-07-07 20:44:24 - train: epoch 0057, iter [02600, 05004], lr: 0.054550, loss: 1.4180
2022-07-07 20:45:09 - train: epoch 0057, iter [02700, 05004], lr: 0.054524, loss: 1.2625
2022-07-07 20:45:55 - train: epoch 0057, iter [02800, 05004], lr: 0.054497, loss: 1.1974
2022-07-07 20:46:40 - train: epoch 0057, iter [02900, 05004], lr: 0.054471, loss: 1.6963
2022-07-07 20:47:25 - train: epoch 0057, iter [03000, 05004], lr: 0.054445, loss: 1.6442
2022-07-07 20:48:11 - train: epoch 0057, iter [03100, 05004], lr: 0.054419, loss: 1.7665
2022-07-07 20:48:56 - train: epoch 0057, iter [03200, 05004], lr: 0.054393, loss: 1.7193
2022-07-07 20:49:41 - train: epoch 0057, iter [03300, 05004], lr: 0.054367, loss: 1.4675
2022-07-07 20:50:27 - train: epoch 0057, iter [03400, 05004], lr: 0.054341, loss: 1.5924
2022-07-07 20:51:12 - train: epoch 0057, iter [03500, 05004], lr: 0.054315, loss: 1.5314
2022-07-07 20:51:58 - train: epoch 0057, iter [03600, 05004], lr: 0.054289, loss: 1.4684
2022-07-07 20:52:43 - train: epoch 0057, iter [03700, 05004], lr: 0.054263, loss: 1.4702
2022-07-07 20:53:28 - train: epoch 0057, iter [03800, 05004], lr: 0.054237, loss: 1.5169
2022-07-07 20:54:14 - train: epoch 0057, iter [03900, 05004], lr: 0.054211, loss: 1.7562
2022-07-07 20:54:59 - train: epoch 0057, iter [04000, 05004], lr: 0.054185, loss: 1.4798
2022-07-07 20:55:44 - train: epoch 0057, iter [04100, 05004], lr: 0.054159, loss: 1.7128
2022-07-07 20:56:30 - train: epoch 0057, iter [04200, 05004], lr: 0.054133, loss: 1.6808
2022-07-07 20:57:15 - train: epoch 0057, iter [04300, 05004], lr: 0.054107, loss: 1.4581
2022-07-07 20:58:00 - train: epoch 0057, iter [04400, 05004], lr: 0.054080, loss: 1.6459
2022-07-07 20:58:46 - train: epoch 0057, iter [04500, 05004], lr: 0.054054, loss: 1.6933
2022-07-07 20:59:31 - train: epoch 0057, iter [04600, 05004], lr: 0.054028, loss: 1.6612
2022-07-07 21:00:16 - train: epoch 0057, iter [04700, 05004], lr: 0.054002, loss: 1.5259
2022-07-07 21:01:02 - train: epoch 0057, iter [04800, 05004], lr: 0.053976, loss: 1.7704
2022-07-07 21:01:47 - train: epoch 0057, iter [04900, 05004], lr: 0.053950, loss: 1.8588
2022-07-07 21:02:32 - train: epoch 0057, iter [05000, 05004], lr: 0.053924, loss: 1.7344
2022-07-07 21:02:35 - train: epoch 057, train_loss: 1.5527
2022-07-07 21:03:51 - eval: epoch: 057, acc1: 66.948%, acc5: 87.920%, test_loss: 1.3624, per_image_load_time: 1.258ms, per_image_inference_time: 0.831ms
2022-07-07 21:03:52 - until epoch: 057, best_acc1: 66.948%
2022-07-07 21:03:52 - epoch 058 lr: 0.053923
2022-07-07 21:04:43 - train: epoch 0058, iter [00100, 05004], lr: 0.053897, loss: 1.4626
2022-07-07 21:05:28 - train: epoch 0058, iter [00200, 05004], lr: 0.053871, loss: 1.3854
2022-07-07 21:06:13 - train: epoch 0058, iter [00300, 05004], lr: 0.053845, loss: 1.5652
2022-07-07 21:06:58 - train: epoch 0058, iter [00400, 05004], lr: 0.053819, loss: 1.5870
2022-07-07 21:07:44 - train: epoch 0058, iter [00500, 05004], lr: 0.053793, loss: 1.3970
2022-07-07 21:08:29 - train: epoch 0058, iter [00600, 05004], lr: 0.053766, loss: 1.7499
2022-07-07 21:09:14 - train: epoch 0058, iter [00700, 05004], lr: 0.053740, loss: 1.5802
2022-07-07 21:09:59 - train: epoch 0058, iter [00800, 05004], lr: 0.053714, loss: 1.4040
2022-07-07 21:10:45 - train: epoch 0058, iter [00900, 05004], lr: 0.053688, loss: 1.3417
2022-07-07 21:11:30 - train: epoch 0058, iter [01000, 05004], lr: 0.053662, loss: 1.5953
2022-07-07 21:12:15 - train: epoch 0058, iter [01100, 05004], lr: 0.053636, loss: 1.3257
2022-07-07 21:13:00 - train: epoch 0058, iter [01200, 05004], lr: 0.053610, loss: 1.4242
2022-07-07 21:13:46 - train: epoch 0058, iter [01300, 05004], lr: 0.053584, loss: 1.5087
2022-07-07 21:14:31 - train: epoch 0058, iter [01400, 05004], lr: 0.053558, loss: 1.5431
2022-07-07 21:15:16 - train: epoch 0058, iter [01500, 05004], lr: 0.053532, loss: 1.5382
2022-07-07 21:16:01 - train: epoch 0058, iter [01600, 05004], lr: 0.053506, loss: 1.4380
2022-07-07 21:16:46 - train: epoch 0058, iter [01700, 05004], lr: 0.053479, loss: 1.6721
2022-07-07 21:17:31 - train: epoch 0058, iter [01800, 05004], lr: 0.053453, loss: 1.5593
2022-07-07 21:18:16 - train: epoch 0058, iter [01900, 05004], lr: 0.053427, loss: 1.7328
2022-07-07 21:19:02 - train: epoch 0058, iter [02000, 05004], lr: 0.053401, loss: 1.6994
2022-07-07 21:19:47 - train: epoch 0058, iter [02100, 05004], lr: 0.053375, loss: 1.4583
2022-07-07 21:20:32 - train: epoch 0058, iter [02200, 05004], lr: 0.053349, loss: 1.3976
2022-07-07 21:21:17 - train: epoch 0058, iter [02300, 05004], lr: 0.053323, loss: 1.4895
2022-07-07 21:22:03 - train: epoch 0058, iter [02400, 05004], lr: 0.053297, loss: 1.5109
2022-07-07 21:22:48 - train: epoch 0058, iter [02500, 05004], lr: 0.053271, loss: 1.6771
2022-07-07 21:23:33 - train: epoch 0058, iter [02600, 05004], lr: 0.053245, loss: 1.4017
2022-07-07 21:24:18 - train: epoch 0058, iter [02700, 05004], lr: 0.053218, loss: 1.7497
2022-07-07 21:25:04 - train: epoch 0058, iter [02800, 05004], lr: 0.053192, loss: 1.4186
2022-07-07 21:25:49 - train: epoch 0058, iter [02900, 05004], lr: 0.053166, loss: 1.4058
2022-07-07 21:26:34 - train: epoch 0058, iter [03000, 05004], lr: 0.053140, loss: 1.6269
2022-07-07 21:27:19 - train: epoch 0058, iter [03100, 05004], lr: 0.053114, loss: 1.3993
2022-07-07 21:28:04 - train: epoch 0058, iter [03200, 05004], lr: 0.053088, loss: 1.4329
2022-07-07 21:28:49 - train: epoch 0058, iter [03300, 05004], lr: 0.053062, loss: 1.5249
2022-07-07 21:29:34 - train: epoch 0058, iter [03400, 05004], lr: 0.053036, loss: 1.4754
2022-07-07 21:30:19 - train: epoch 0058, iter [03500, 05004], lr: 0.053010, loss: 1.3960
2022-07-07 21:31:03 - train: epoch 0058, iter [03600, 05004], lr: 0.052983, loss: 1.4196
2022-07-07 21:31:48 - train: epoch 0058, iter [03700, 05004], lr: 0.052957, loss: 1.5479
2022-07-07 21:32:33 - train: epoch 0058, iter [03800, 05004], lr: 0.052931, loss: 1.6521
2022-07-07 21:33:18 - train: epoch 0058, iter [03900, 05004], lr: 0.052905, loss: 1.6210
2022-07-07 21:34:03 - train: epoch 0058, iter [04000, 05004], lr: 0.052879, loss: 1.6685
2022-07-07 21:34:47 - train: epoch 0058, iter [04100, 05004], lr: 0.052853, loss: 1.6763
2022-07-07 21:35:32 - train: epoch 0058, iter [04200, 05004], lr: 0.052827, loss: 1.3198
2022-07-07 21:36:17 - train: epoch 0058, iter [04300, 05004], lr: 0.052801, loss: 1.8883
2022-07-07 21:37:02 - train: epoch 0058, iter [04400, 05004], lr: 0.052775, loss: 1.2692
2022-07-07 21:37:47 - train: epoch 0058, iter [04500, 05004], lr: 0.052748, loss: 1.5962
2022-07-07 21:38:32 - train: epoch 0058, iter [04600, 05004], lr: 0.052722, loss: 1.4550
2022-07-07 21:39:17 - train: epoch 0058, iter [04700, 05004], lr: 0.052696, loss: 1.5392
2022-07-07 21:40:02 - train: epoch 0058, iter [04800, 05004], lr: 0.052670, loss: 1.6622
2022-07-07 21:40:47 - train: epoch 0058, iter [04900, 05004], lr: 0.052644, loss: 1.3934
2022-07-07 21:41:32 - train: epoch 0058, iter [05000, 05004], lr: 0.052618, loss: 1.5286
2022-07-07 21:41:35 - train: epoch 058, train_loss: 1.5393
2022-07-07 21:42:52 - eval: epoch: 058, acc1: 68.062%, acc5: 88.826%, test_loss: 1.3199, per_image_load_time: 2.056ms, per_image_inference_time: 0.830ms
2022-07-07 21:42:53 - until epoch: 058, best_acc1: 68.062%
2022-07-07 21:42:53 - epoch 059 lr: 0.052617
2022-07-07 21:43:44 - train: epoch 0059, iter [00100, 05004], lr: 0.052591, loss: 1.6622
2022-07-07 21:44:30 - train: epoch 0059, iter [00200, 05004], lr: 0.052565, loss: 1.5126
2022-07-07 21:45:15 - train: epoch 0059, iter [00300, 05004], lr: 0.052538, loss: 1.6145
2022-07-07 21:46:01 - train: epoch 0059, iter [00400, 05004], lr: 0.052512, loss: 1.5129
2022-07-07 21:46:46 - train: epoch 0059, iter [00500, 05004], lr: 0.052486, loss: 1.8148
2022-07-07 21:47:32 - train: epoch 0059, iter [00600, 05004], lr: 0.052460, loss: 1.3972
2022-07-07 21:48:17 - train: epoch 0059, iter [00700, 05004], lr: 0.052434, loss: 1.4504
2022-07-07 21:49:03 - train: epoch 0059, iter [00800, 05004], lr: 0.052408, loss: 1.6412
2022-07-07 21:49:49 - train: epoch 0059, iter [00900, 05004], lr: 0.052382, loss: 1.5013
2022-07-07 21:50:34 - train: epoch 0059, iter [01000, 05004], lr: 0.052356, loss: 1.4789
2022-07-07 21:51:20 - train: epoch 0059, iter [01100, 05004], lr: 0.052329, loss: 1.7406
2022-07-07 21:52:05 - train: epoch 0059, iter [01200, 05004], lr: 0.052303, loss: 1.2597
2022-07-07 21:52:51 - train: epoch 0059, iter [01300, 05004], lr: 0.052277, loss: 1.7010
2022-07-07 21:53:37 - train: epoch 0059, iter [01400, 05004], lr: 0.052251, loss: 1.7505
2022-07-07 21:54:22 - train: epoch 0059, iter [01500, 05004], lr: 0.052225, loss: 1.6370
2022-07-07 21:55:08 - train: epoch 0059, iter [01600, 05004], lr: 0.052199, loss: 1.4107
2022-07-07 21:55:54 - train: epoch 0059, iter [01700, 05004], lr: 0.052173, loss: 1.5882
2022-07-07 21:56:39 - train: epoch 0059, iter [01800, 05004], lr: 0.052146, loss: 1.4859
2022-07-07 21:57:25 - train: epoch 0059, iter [01900, 05004], lr: 0.052120, loss: 1.5826
2022-07-07 21:58:10 - train: epoch 0059, iter [02000, 05004], lr: 0.052094, loss: 1.4442
2022-07-07 21:58:56 - train: epoch 0059, iter [02100, 05004], lr: 0.052068, loss: 1.7089
2022-07-07 21:59:42 - train: epoch 0059, iter [02200, 05004], lr: 0.052042, loss: 1.6679
2022-07-07 22:00:28 - train: epoch 0059, iter [02300, 05004], lr: 0.052016, loss: 1.4882
2022-07-07 22:01:13 - train: epoch 0059, iter [02400, 05004], lr: 0.051990, loss: 1.5840
2022-07-07 22:01:59 - train: epoch 0059, iter [02500, 05004], lr: 0.051964, loss: 1.5267
2022-07-07 22:02:44 - train: epoch 0059, iter [02600, 05004], lr: 0.051937, loss: 1.4610
2022-07-07 22:03:30 - train: epoch 0059, iter [02700, 05004], lr: 0.051911, loss: 1.4891
2022-07-07 22:04:15 - train: epoch 0059, iter [02800, 05004], lr: 0.051885, loss: 1.7982
2022-07-07 22:05:01 - train: epoch 0059, iter [02900, 05004], lr: 0.051859, loss: 1.4418
2022-07-07 22:05:46 - train: epoch 0059, iter [03000, 05004], lr: 0.051833, loss: 1.8980
2022-07-07 22:06:32 - train: epoch 0059, iter [03100, 05004], lr: 0.051807, loss: 1.5265
2022-07-07 22:07:17 - train: epoch 0059, iter [03200, 05004], lr: 0.051781, loss: 1.4789
2022-07-07 22:08:03 - train: epoch 0059, iter [03300, 05004], lr: 0.051754, loss: 1.6487
2022-07-07 22:08:49 - train: epoch 0059, iter [03400, 05004], lr: 0.051728, loss: 1.9252
2022-07-07 22:09:34 - train: epoch 0059, iter [03500, 05004], lr: 0.051702, loss: 1.4524
2022-07-07 22:10:20 - train: epoch 0059, iter [03600, 05004], lr: 0.051676, loss: 1.5109
2022-07-07 22:11:06 - train: epoch 0059, iter [03700, 05004], lr: 0.051650, loss: 1.3942
2022-07-07 22:11:51 - train: epoch 0059, iter [03800, 05004], lr: 0.051624, loss: 1.6465
2022-07-07 22:12:37 - train: epoch 0059, iter [03900, 05004], lr: 0.051598, loss: 1.5613
2022-07-07 22:13:23 - train: epoch 0059, iter [04000, 05004], lr: 0.051571, loss: 1.8367
2022-07-07 22:14:08 - train: epoch 0059, iter [04100, 05004], lr: 0.051545, loss: 1.6079
2022-07-07 22:14:54 - train: epoch 0059, iter [04200, 05004], lr: 0.051519, loss: 1.5158
2022-07-07 22:15:39 - train: epoch 0059, iter [04300, 05004], lr: 0.051493, loss: 1.7383
2022-07-07 22:16:25 - train: epoch 0059, iter [04400, 05004], lr: 0.051467, loss: 1.7637
2022-07-07 22:17:10 - train: epoch 0059, iter [04500, 05004], lr: 0.051441, loss: 1.6388
2022-07-07 22:17:56 - train: epoch 0059, iter [04600, 05004], lr: 0.051414, loss: 1.4803
2022-07-07 22:18:41 - train: epoch 0059, iter [04700, 05004], lr: 0.051388, loss: 1.5259
2022-07-07 22:19:27 - train: epoch 0059, iter [04800, 05004], lr: 0.051362, loss: 1.4652
2022-07-07 22:20:12 - train: epoch 0059, iter [04900, 05004], lr: 0.051336, loss: 1.7589
2022-07-07 22:20:58 - train: epoch 0059, iter [05000, 05004], lr: 0.051310, loss: 1.6670
2022-07-07 22:21:00 - train: epoch 059, train_loss: 1.5292
2022-07-07 22:22:17 - eval: epoch: 059, acc1: 67.336%, acc5: 88.394%, test_loss: 1.3401, per_image_load_time: 1.567ms, per_image_inference_time: 0.831ms
2022-07-07 22:22:18 - until epoch: 059, best_acc1: 68.062%
2022-07-07 22:22:18 - epoch 060 lr: 0.051309
2022-07-07 22:23:10 - train: epoch 0060, iter [00100, 05004], lr: 0.051283, loss: 1.3941
2022-07-07 22:23:55 - train: epoch 0060, iter [00200, 05004], lr: 0.051257, loss: 1.5685
2022-07-07 22:24:40 - train: epoch 0060, iter [00300, 05004], lr: 0.051230, loss: 1.5236
2022-07-07 22:25:25 - train: epoch 0060, iter [00400, 05004], lr: 0.051204, loss: 1.5462
2022-07-07 22:26:10 - train: epoch 0060, iter [00500, 05004], lr: 0.051178, loss: 1.6795
2022-07-07 22:26:56 - train: epoch 0060, iter [00600, 05004], lr: 0.051152, loss: 1.5983
2022-07-07 22:27:41 - train: epoch 0060, iter [00700, 05004], lr: 0.051126, loss: 1.4624
2022-07-07 22:28:27 - train: epoch 0060, iter [00800, 05004], lr: 0.051100, loss: 1.7215
2022-07-07 22:29:12 - train: epoch 0060, iter [00900, 05004], lr: 0.051073, loss: 1.2935
2022-07-07 22:29:58 - train: epoch 0060, iter [01000, 05004], lr: 0.051047, loss: 1.2430
2022-07-07 22:30:43 - train: epoch 0060, iter [01100, 05004], lr: 0.051021, loss: 1.3726
2022-07-07 22:31:29 - train: epoch 0060, iter [01200, 05004], lr: 0.050995, loss: 1.4752
2022-07-07 22:32:14 - train: epoch 0060, iter [01300, 05004], lr: 0.050969, loss: 1.4130
2022-07-07 22:33:00 - train: epoch 0060, iter [01400, 05004], lr: 0.050943, loss: 1.5892
2022-07-07 22:33:45 - train: epoch 0060, iter [01500, 05004], lr: 0.050917, loss: 1.5825
2022-07-07 22:34:31 - train: epoch 0060, iter [01600, 05004], lr: 0.050890, loss: 1.5761
2022-07-07 22:35:16 - train: epoch 0060, iter [01700, 05004], lr: 0.050864, loss: 1.5573
2022-07-07 22:36:01 - train: epoch 0060, iter [01800, 05004], lr: 0.050838, loss: 1.5574
2022-07-07 22:36:47 - train: epoch 0060, iter [01900, 05004], lr: 0.050812, loss: 1.6702
2022-07-07 22:37:32 - train: epoch 0060, iter [02000, 05004], lr: 0.050786, loss: 1.3968
2022-07-07 22:38:18 - train: epoch 0060, iter [02100, 05004], lr: 0.050760, loss: 1.4682
2022-07-07 22:39:03 - train: epoch 0060, iter [02200, 05004], lr: 0.050733, loss: 1.6125
2022-07-07 22:39:49 - train: epoch 0060, iter [02300, 05004], lr: 0.050707, loss: 1.2952
2022-07-07 22:40:34 - train: epoch 0060, iter [02400, 05004], lr: 0.050681, loss: 1.4138
2022-07-07 22:41:20 - train: epoch 0060, iter [02500, 05004], lr: 0.050655, loss: 1.5061
2022-07-07 22:42:05 - train: epoch 0060, iter [02600, 05004], lr: 0.050629, loss: 1.6086
2022-07-07 22:42:51 - train: epoch 0060, iter [02700, 05004], lr: 0.050603, loss: 1.5643
2022-07-07 22:43:36 - train: epoch 0060, iter [02800, 05004], lr: 0.050577, loss: 1.5167
2022-07-07 22:44:22 - train: epoch 0060, iter [02900, 05004], lr: 0.050550, loss: 1.5418
2022-07-07 22:45:07 - train: epoch 0060, iter [03000, 05004], lr: 0.050524, loss: 1.7939
2022-07-07 22:45:53 - train: epoch 0060, iter [03100, 05004], lr: 0.050498, loss: 1.5970
2022-07-07 22:46:38 - train: epoch 0060, iter [03200, 05004], lr: 0.050472, loss: 1.5337
2022-07-07 22:47:24 - train: epoch 0060, iter [03300, 05004], lr: 0.050446, loss: 1.3725
2022-07-07 22:48:09 - train: epoch 0060, iter [03400, 05004], lr: 0.050420, loss: 1.6277
2022-07-07 22:48:55 - train: epoch 0060, iter [03500, 05004], lr: 0.050393, loss: 1.5677
2022-07-07 22:49:40 - train: epoch 0060, iter [03600, 05004], lr: 0.050367, loss: 1.4706
2022-07-07 22:50:25 - train: epoch 0060, iter [03700, 05004], lr: 0.050341, loss: 1.5545
2022-07-07 22:51:11 - train: epoch 0060, iter [03800, 05004], lr: 0.050315, loss: 1.5293
2022-07-07 22:51:56 - train: epoch 0060, iter [03900, 05004], lr: 0.050289, loss: 1.9193
2022-07-07 22:52:42 - train: epoch 0060, iter [04000, 05004], lr: 0.050263, loss: 1.4623
2022-07-07 22:53:27 - train: epoch 0060, iter [04100, 05004], lr: 0.050236, loss: 1.6752
2022-07-07 22:54:12 - train: epoch 0060, iter [04200, 05004], lr: 0.050210, loss: 1.6114
2022-07-07 22:54:58 - train: epoch 0060, iter [04300, 05004], lr: 0.050184, loss: 1.5572
2022-07-07 22:55:43 - train: epoch 0060, iter [04400, 05004], lr: 0.050158, loss: 1.6516
2022-07-07 22:56:29 - train: epoch 0060, iter [04500, 05004], lr: 0.050132, loss: 1.4613
2022-07-07 22:57:14 - train: epoch 0060, iter [04600, 05004], lr: 0.050106, loss: 1.4139
2022-07-07 22:58:00 - train: epoch 0060, iter [04700, 05004], lr: 0.050080, loss: 1.7055
2022-07-07 22:58:45 - train: epoch 0060, iter [04800, 05004], lr: 0.050053, loss: 1.4052
2022-07-07 22:59:31 - train: epoch 0060, iter [04900, 05004], lr: 0.050027, loss: 1.5267
2022-07-07 23:00:16 - train: epoch 0060, iter [05000, 05004], lr: 0.050001, loss: 1.5558
2022-07-07 23:00:18 - train: epoch 060, train_loss: 1.5188
2022-07-07 23:01:36 - eval: epoch: 060, acc1: 67.750%, acc5: 88.764%, test_loss: 1.3093, per_image_load_time: 2.154ms, per_image_inference_time: 0.847ms
2022-07-07 23:01:37 - until epoch: 060, best_acc1: 68.062%
2022-07-07 23:01:37 - epoch 061 lr: 0.050000
2022-07-07 23:02:28 - train: epoch 0061, iter [00100, 05004], lr: 0.049974, loss: 1.3726
2022-07-07 23:03:13 - train: epoch 0061, iter [00200, 05004], lr: 0.049948, loss: 1.4757
2022-07-07 23:03:58 - train: epoch 0061, iter [00300, 05004], lr: 0.049922, loss: 1.3730
2022-07-07 23:04:43 - train: epoch 0061, iter [00400, 05004], lr: 0.049895, loss: 1.8669
2022-07-07 23:05:28 - train: epoch 0061, iter [00500, 05004], lr: 0.049869, loss: 1.4663
2022-07-07 23:06:14 - train: epoch 0061, iter [00600, 05004], lr: 0.049843, loss: 1.4330
2022-07-07 23:06:59 - train: epoch 0061, iter [00700, 05004], lr: 0.049817, loss: 1.2578
2022-07-07 23:07:44 - train: epoch 0061, iter [00800, 05004], lr: 0.049791, loss: 1.5134
2022-07-07 23:08:30 - train: epoch 0061, iter [00900, 05004], lr: 0.049765, loss: 1.3034
2022-07-07 23:09:15 - train: epoch 0061, iter [01000, 05004], lr: 0.049738, loss: 1.2850
2022-07-07 23:10:00 - train: epoch 0061, iter [01100, 05004], lr: 0.049712, loss: 1.3096
2022-07-07 23:10:46 - train: epoch 0061, iter [01200, 05004], lr: 0.049686, loss: 1.4797
2022-07-07 23:11:31 - train: epoch 0061, iter [01300, 05004], lr: 0.049660, loss: 1.5061
2022-07-07 23:12:16 - train: epoch 0061, iter [01400, 05004], lr: 0.049634, loss: 1.5027
2022-07-07 23:13:01 - train: epoch 0061, iter [01500, 05004], lr: 0.049608, loss: 1.5206
2022-07-07 23:13:47 - train: epoch 0061, iter [01600, 05004], lr: 0.049581, loss: 1.3285
2022-07-07 23:14:32 - train: epoch 0061, iter [01700, 05004], lr: 0.049555, loss: 1.4894
2022-07-07 23:15:17 - train: epoch 0061, iter [01800, 05004], lr: 0.049529, loss: 1.5608
2022-07-07 23:16:03 - train: epoch 0061, iter [01900, 05004], lr: 0.049503, loss: 1.7201
2022-07-07 23:16:48 - train: epoch 0061, iter [02000, 05004], lr: 0.049477, loss: 1.4177
2022-07-07 23:17:33 - train: epoch 0061, iter [02100, 05004], lr: 0.049451, loss: 1.8972
2022-07-07 23:18:19 - train: epoch 0061, iter [02200, 05004], lr: 0.049425, loss: 1.3512
2022-07-07 23:19:04 - train: epoch 0061, iter [02300, 05004], lr: 0.049398, loss: 1.4511
2022-07-07 23:19:49 - train: epoch 0061, iter [02400, 05004], lr: 0.049372, loss: 1.2957
2022-07-07 23:20:34 - train: epoch 0061, iter [02500, 05004], lr: 0.049346, loss: 1.4517
2022-07-07 23:21:19 - train: epoch 0061, iter [02600, 05004], lr: 0.049320, loss: 1.6407
2022-07-07 23:22:05 - train: epoch 0061, iter [02700, 05004], lr: 0.049294, loss: 1.6810
2022-07-07 23:22:50 - train: epoch 0061, iter [02800, 05004], lr: 0.049268, loss: 1.5496
2022-07-07 23:23:35 - train: epoch 0061, iter [02900, 05004], lr: 0.049241, loss: 1.6446
2022-07-07 23:24:20 - train: epoch 0061, iter [03000, 05004], lr: 0.049215, loss: 1.4598
2022-07-07 23:25:05 - train: epoch 0061, iter [03100, 05004], lr: 0.049189, loss: 1.6401
2022-07-07 23:25:51 - train: epoch 0061, iter [03200, 05004], lr: 0.049163, loss: 1.6146
2022-07-07 23:26:36 - train: epoch 0061, iter [03300, 05004], lr: 0.049137, loss: 1.4901
2022-07-07 23:27:21 - train: epoch 0061, iter [03400, 05004], lr: 0.049111, loss: 1.3136
2022-07-07 23:28:07 - train: epoch 0061, iter [03500, 05004], lr: 0.049084, loss: 1.5837
2022-07-07 23:28:52 - train: epoch 0061, iter [03600, 05004], lr: 0.049058, loss: 1.5754
2022-07-07 23:29:37 - train: epoch 0061, iter [03700, 05004], lr: 0.049032, loss: 1.6671
2022-07-07 23:30:22 - train: epoch 0061, iter [03800, 05004], lr: 0.049006, loss: 1.5552
2022-07-07 23:31:07 - train: epoch 0061, iter [03900, 05004], lr: 0.048980, loss: 1.4430
2022-07-07 23:31:53 - train: epoch 0061, iter [04000, 05004], lr: 0.048954, loss: 1.5507
2022-07-07 23:32:38 - train: epoch 0061, iter [04100, 05004], lr: 0.048928, loss: 1.6909
2022-07-07 23:33:23 - train: epoch 0061, iter [04200, 05004], lr: 0.048901, loss: 1.4725
2022-07-07 23:34:08 - train: epoch 0061, iter [04300, 05004], lr: 0.048875, loss: 1.5573
2022-07-07 23:34:53 - train: epoch 0061, iter [04400, 05004], lr: 0.048849, loss: 1.5760
2022-07-07 23:35:38 - train: epoch 0061, iter [04500, 05004], lr: 0.048823, loss: 1.5517
2022-07-07 23:36:23 - train: epoch 0061, iter [04600, 05004], lr: 0.048797, loss: 1.7008
2022-07-07 23:37:09 - train: epoch 0061, iter [04700, 05004], lr: 0.048771, loss: 1.4637
2022-07-07 23:37:54 - train: epoch 0061, iter [04800, 05004], lr: 0.048744, loss: 1.4222
2022-07-07 23:38:39 - train: epoch 0061, iter [04900, 05004], lr: 0.048718, loss: 1.5525
2022-07-07 23:39:24 - train: epoch 0061, iter [05000, 05004], lr: 0.048692, loss: 1.7332
2022-07-07 23:39:26 - train: epoch 061, train_loss: 1.5065
2022-07-07 23:40:43 - eval: epoch: 061, acc1: 67.546%, acc5: 88.390%, test_loss: 1.3444, per_image_load_time: 1.990ms, per_image_inference_time: 0.839ms
2022-07-07 23:40:44 - until epoch: 061, best_acc1: 68.062%
2022-07-07 23:40:44 - epoch 062 lr: 0.048691
2022-07-07 23:41:36 - train: epoch 0062, iter [00100, 05004], lr: 0.048665, loss: 1.5230
2022-07-07 23:42:21 - train: epoch 0062, iter [00200, 05004], lr: 0.048639, loss: 1.5552
2022-07-07 23:43:06 - train: epoch 0062, iter [00300, 05004], lr: 0.048613, loss: 1.4578
2022-07-07 23:43:51 - train: epoch 0062, iter [00400, 05004], lr: 0.048587, loss: 1.3886
2022-07-07 23:44:37 - train: epoch 0062, iter [00500, 05004], lr: 0.048560, loss: 1.4151
2022-07-07 23:45:22 - train: epoch 0062, iter [00600, 05004], lr: 0.048534, loss: 1.4728
2022-07-07 23:46:07 - train: epoch 0062, iter [00700, 05004], lr: 0.048508, loss: 1.6578
2022-07-07 23:46:53 - train: epoch 0062, iter [00800, 05004], lr: 0.048482, loss: 1.3687
2022-07-07 23:47:38 - train: epoch 0062, iter [00900, 05004], lr: 0.048456, loss: 1.5008
2022-07-07 23:48:24 - train: epoch 0062, iter [01000, 05004], lr: 0.048430, loss: 1.5187
2022-07-07 23:49:09 - train: epoch 0062, iter [01100, 05004], lr: 0.048404, loss: 1.3771
2022-07-07 23:49:54 - train: epoch 0062, iter [01200, 05004], lr: 0.048377, loss: 1.7658
2022-07-07 23:50:40 - train: epoch 0062, iter [01300, 05004], lr: 0.048351, loss: 1.4845
2022-07-07 23:51:25 - train: epoch 0062, iter [01400, 05004], lr: 0.048325, loss: 1.4444
2022-07-07 23:52:10 - train: epoch 0062, iter [01500, 05004], lr: 0.048299, loss: 1.5883
2022-07-07 23:52:55 - train: epoch 0062, iter [01600, 05004], lr: 0.048273, loss: 1.5606
2022-07-07 23:53:41 - train: epoch 0062, iter [01700, 05004], lr: 0.048247, loss: 1.6337
2022-07-07 23:54:26 - train: epoch 0062, iter [01800, 05004], lr: 0.048221, loss: 1.3660
2022-07-07 23:55:11 - train: epoch 0062, iter [01900, 05004], lr: 0.048194, loss: 1.4436
2022-07-07 23:55:57 - train: epoch 0062, iter [02000, 05004], lr: 0.048168, loss: 1.3864
2022-07-07 23:56:42 - train: epoch 0062, iter [02100, 05004], lr: 0.048142, loss: 1.6026
2022-07-07 23:57:27 - train: epoch 0062, iter [02200, 05004], lr: 0.048116, loss: 1.3373
2022-07-07 23:58:13 - train: epoch 0062, iter [02300, 05004], lr: 0.048090, loss: 1.5153
2022-07-07 23:58:58 - train: epoch 0062, iter [02400, 05004], lr: 0.048064, loss: 1.5871
2022-07-07 23:59:43 - train: epoch 0062, iter [02500, 05004], lr: 0.048038, loss: 1.6339
2022-07-08 00:00:28 - train: epoch 0062, iter [02600, 05004], lr: 0.048011, loss: 1.4169
2022-07-08 00:01:14 - train: epoch 0062, iter [02700, 05004], lr: 0.047985, loss: 1.4294
2022-07-08 00:01:59 - train: epoch 0062, iter [02800, 05004], lr: 0.047959, loss: 1.5830
2022-07-08 00:02:44 - train: epoch 0062, iter [02900, 05004], lr: 0.047933, loss: 1.5636
2022-07-08 00:03:29 - train: epoch 0062, iter [03000, 05004], lr: 0.047907, loss: 1.5892
2022-07-08 00:04:15 - train: epoch 0062, iter [03100, 05004], lr: 0.047881, loss: 1.6012
2022-07-08 00:05:00 - train: epoch 0062, iter [03200, 05004], lr: 0.047855, loss: 1.3652
2022-07-08 00:05:45 - train: epoch 0062, iter [03300, 05004], lr: 0.047828, loss: 1.5632
2022-07-08 00:06:30 - train: epoch 0062, iter [03400, 05004], lr: 0.047802, loss: 1.4547
2022-07-08 00:07:15 - train: epoch 0062, iter [03500, 05004], lr: 0.047776, loss: 1.5093
2022-07-08 00:08:01 - train: epoch 0062, iter [03600, 05004], lr: 0.047750, loss: 1.6009
2022-07-08 00:08:46 - train: epoch 0062, iter [03700, 05004], lr: 0.047724, loss: 1.5526
2022-07-08 00:09:31 - train: epoch 0062, iter [03800, 05004], lr: 0.047698, loss: 1.4892
2022-07-08 00:10:17 - train: epoch 0062, iter [03900, 05004], lr: 0.047672, loss: 1.4671
2022-07-08 00:11:02 - train: epoch 0062, iter [04000, 05004], lr: 0.047646, loss: 1.3126
2022-07-08 00:11:47 - train: epoch 0062, iter [04100, 05004], lr: 0.047619, loss: 1.6358
2022-07-08 00:12:33 - train: epoch 0062, iter [04200, 05004], lr: 0.047593, loss: 1.3482
2022-07-08 00:13:18 - train: epoch 0062, iter [04300, 05004], lr: 0.047567, loss: 1.4906
2022-07-08 00:14:04 - train: epoch 0062, iter [04400, 05004], lr: 0.047541, loss: 1.4514
2022-07-08 00:14:49 - train: epoch 0062, iter [04500, 05004], lr: 0.047515, loss: 1.4051
2022-07-08 00:15:34 - train: epoch 0062, iter [04600, 05004], lr: 0.047489, loss: 1.1871
2022-07-08 00:16:20 - train: epoch 0062, iter [04700, 05004], lr: 0.047463, loss: 1.4254
2022-07-08 00:17:05 - train: epoch 0062, iter [04800, 05004], lr: 0.047436, loss: 1.4727
2022-07-08 00:17:50 - train: epoch 0062, iter [04900, 05004], lr: 0.047410, loss: 1.4295
2022-07-08 00:18:35 - train: epoch 0062, iter [05000, 05004], lr: 0.047384, loss: 1.4714
2022-07-08 00:18:38 - train: epoch 062, train_loss: 1.4953
2022-07-08 00:19:54 - eval: epoch: 062, acc1: 67.900%, acc5: 88.912%, test_loss: 1.3013, per_image_load_time: 2.149ms, per_image_inference_time: 0.836ms
2022-07-08 00:19:55 - until epoch: 062, best_acc1: 68.062%
2022-07-08 00:19:55 - epoch 063 lr: 0.047383
2022-07-08 00:20:47 - train: epoch 0063, iter [00100, 05004], lr: 0.047357, loss: 1.3690
2022-07-08 00:21:32 - train: epoch 0063, iter [00200, 05004], lr: 0.047331, loss: 1.3860
2022-07-08 00:22:18 - train: epoch 0063, iter [00300, 05004], lr: 0.047305, loss: 1.6282
2022-07-08 00:23:03 - train: epoch 0063, iter [00400, 05004], lr: 0.047279, loss: 1.5362
2022-07-08 00:23:48 - train: epoch 0063, iter [00500, 05004], lr: 0.047253, loss: 1.3842
2022-07-08 00:24:34 - train: epoch 0063, iter [00600, 05004], lr: 0.047226, loss: 1.6016
2022-07-08 00:25:19 - train: epoch 0063, iter [00700, 05004], lr: 0.047200, loss: 1.3694
2022-07-08 00:26:05 - train: epoch 0063, iter [00800, 05004], lr: 0.047174, loss: 1.4244
2022-07-08 00:26:50 - train: epoch 0063, iter [00900, 05004], lr: 0.047148, loss: 1.4919
2022-07-08 00:27:35 - train: epoch 0063, iter [01000, 05004], lr: 0.047122, loss: 1.6169
2022-07-08 00:28:21 - train: epoch 0063, iter [01100, 05004], lr: 0.047096, loss: 1.4448
2022-07-08 00:29:06 - train: epoch 0063, iter [01200, 05004], lr: 0.047070, loss: 1.4472
2022-07-08 00:29:52 - train: epoch 0063, iter [01300, 05004], lr: 0.047044, loss: 1.4749
2022-07-08 00:30:37 - train: epoch 0063, iter [01400, 05004], lr: 0.047018, loss: 1.9435
2022-07-08 00:31:22 - train: epoch 0063, iter [01500, 05004], lr: 0.046991, loss: 1.5333
2022-07-08 00:32:08 - train: epoch 0063, iter [01600, 05004], lr: 0.046965, loss: 1.4307
2022-07-08 00:32:53 - train: epoch 0063, iter [01700, 05004], lr: 0.046939, loss: 1.2974
2022-07-08 00:33:39 - train: epoch 0063, iter [01800, 05004], lr: 0.046913, loss: 1.6531
2022-07-08 00:34:24 - train: epoch 0063, iter [01900, 05004], lr: 0.046887, loss: 1.6274
2022-07-08 00:35:10 - train: epoch 0063, iter [02000, 05004], lr: 0.046861, loss: 1.3891
2022-07-08 00:35:55 - train: epoch 0063, iter [02100, 05004], lr: 0.046835, loss: 1.4388
2022-07-08 00:36:41 - train: epoch 0063, iter [02200, 05004], lr: 0.046809, loss: 1.8682
2022-07-08 00:37:26 - train: epoch 0063, iter [02300, 05004], lr: 0.046783, loss: 1.4897
2022-07-08 00:38:11 - train: epoch 0063, iter [02400, 05004], lr: 0.046756, loss: 1.7601
2022-07-08 00:38:55 - train: epoch 0063, iter [02500, 05004], lr: 0.046730, loss: 1.4882
2022-07-08 00:39:40 - train: epoch 0063, iter [02600, 05004], lr: 0.046704, loss: 1.4003
2022-07-08 00:40:25 - train: epoch 0063, iter [02700, 05004], lr: 0.046678, loss: 1.6718
2022-07-08 00:41:10 - train: epoch 0063, iter [02800, 05004], lr: 0.046652, loss: 1.5613
2022-07-08 00:41:55 - train: epoch 0063, iter [02900, 05004], lr: 0.046626, loss: 1.4251
2022-07-08 00:42:39 - train: epoch 0063, iter [03000, 05004], lr: 0.046600, loss: 1.5742
2022-07-08 00:43:24 - train: epoch 0063, iter [03100, 05004], lr: 0.046574, loss: 1.8567
2022-07-08 00:44:09 - train: epoch 0063, iter [03200, 05004], lr: 0.046548, loss: 1.5507
2022-07-08 00:44:54 - train: epoch 0063, iter [03300, 05004], lr: 0.046522, loss: 1.4479
2022-07-08 00:45:39 - train: epoch 0063, iter [03400, 05004], lr: 0.046495, loss: 1.2675
2022-07-08 00:46:24 - train: epoch 0063, iter [03500, 05004], lr: 0.046469, loss: 1.6596
2022-07-08 00:47:09 - train: epoch 0063, iter [03600, 05004], lr: 0.046443, loss: 1.3244
2022-07-08 00:47:54 - train: epoch 0063, iter [03700, 05004], lr: 0.046417, loss: 1.6016
2022-07-08 00:48:39 - train: epoch 0063, iter [03800, 05004], lr: 0.046391, loss: 1.7321
2022-07-08 00:49:25 - train: epoch 0063, iter [03900, 05004], lr: 0.046365, loss: 1.2135
2022-07-08 00:50:10 - train: epoch 0063, iter [04000, 05004], lr: 0.046339, loss: 1.2523
2022-07-08 00:50:55 - train: epoch 0063, iter [04100, 05004], lr: 0.046313, loss: 1.6928
2022-07-08 00:51:41 - train: epoch 0063, iter [04200, 05004], lr: 0.046287, loss: 1.4174
2022-07-08 00:52:26 - train: epoch 0063, iter [04300, 05004], lr: 0.046261, loss: 1.5822
2022-07-08 00:53:11 - train: epoch 0063, iter [04400, 05004], lr: 0.046235, loss: 1.5300
2022-07-08 00:53:56 - train: epoch 0063, iter [04500, 05004], lr: 0.046208, loss: 1.3678
2022-07-08 00:54:41 - train: epoch 0063, iter [04600, 05004], lr: 0.046182, loss: 1.3919
2022-07-08 00:55:26 - train: epoch 0063, iter [04700, 05004], lr: 0.046156, loss: 1.3982
2022-07-08 00:56:11 - train: epoch 0063, iter [04800, 05004], lr: 0.046130, loss: 1.4279
2022-07-08 00:56:56 - train: epoch 0063, iter [04900, 05004], lr: 0.046104, loss: 1.4040
2022-07-08 00:57:40 - train: epoch 0063, iter [05000, 05004], lr: 0.046078, loss: 1.4855
2022-07-08 00:57:43 - train: epoch 063, train_loss: 1.4847
2022-07-08 00:59:00 - eval: epoch: 063, acc1: 68.570%, acc5: 89.120%, test_loss: 1.2805, per_image_load_time: 1.232ms, per_image_inference_time: 0.843ms
2022-07-08 00:59:01 - until epoch: 063, best_acc1: 68.570%
2022-07-08 00:59:01 - epoch 064 lr: 0.046077
2022-07-08 00:59:52 - train: epoch 0064, iter [00100, 05004], lr: 0.046051, loss: 1.4244
2022-07-08 01:00:37 - train: epoch 0064, iter [00200, 05004], lr: 0.046025, loss: 1.4330
2022-07-08 01:01:22 - train: epoch 0064, iter [00300, 05004], lr: 0.045999, loss: 1.1893
2022-07-08 01:02:07 - train: epoch 0064, iter [00400, 05004], lr: 0.045973, loss: 1.5497
2022-07-08 01:02:53 - train: epoch 0064, iter [00500, 05004], lr: 0.045947, loss: 1.3378
2022-07-08 01:03:38 - train: epoch 0064, iter [00600, 05004], lr: 0.045921, loss: 1.5881
2022-07-08 01:04:23 - train: epoch 0064, iter [00700, 05004], lr: 0.045895, loss: 1.5827
2022-07-08 01:05:08 - train: epoch 0064, iter [00800, 05004], lr: 0.045868, loss: 1.2821
2022-07-08 01:05:53 - train: epoch 0064, iter [00900, 05004], lr: 0.045842, loss: 1.4835
2022-07-08 01:06:39 - train: epoch 0064, iter [01000, 05004], lr: 0.045816, loss: 1.3735
2022-07-08 01:07:24 - train: epoch 0064, iter [01100, 05004], lr: 0.045790, loss: 1.3767
2022-07-08 01:08:09 - train: epoch 0064, iter [01200, 05004], lr: 0.045764, loss: 1.3024
2022-07-08 01:08:54 - train: epoch 0064, iter [01300, 05004], lr: 0.045738, loss: 1.4780
2022-07-08 01:09:40 - train: epoch 0064, iter [01400, 05004], lr: 0.045712, loss: 1.8298
2022-07-08 01:10:25 - train: epoch 0064, iter [01500, 05004], lr: 0.045686, loss: 1.5737
2022-07-08 01:11:10 - train: epoch 0064, iter [01600, 05004], lr: 0.045660, loss: 1.3627
2022-07-08 01:11:56 - train: epoch 0064, iter [01700, 05004], lr: 0.045634, loss: 1.3317
2022-07-08 01:12:41 - train: epoch 0064, iter [01800, 05004], lr: 0.045608, loss: 1.2898
2022-07-08 01:13:26 - train: epoch 0064, iter [01900, 05004], lr: 0.045582, loss: 1.4344
2022-07-08 01:14:12 - train: epoch 0064, iter [02000, 05004], lr: 0.045556, loss: 1.4080
2022-07-08 01:14:57 - train: epoch 0064, iter [02100, 05004], lr: 0.045530, loss: 1.4852
2022-07-08 01:15:42 - train: epoch 0064, iter [02200, 05004], lr: 0.045504, loss: 1.6630
2022-07-08 01:16:27 - train: epoch 0064, iter [02300, 05004], lr: 0.045478, loss: 1.4958
2022-07-08 01:17:12 - train: epoch 0064, iter [02400, 05004], lr: 0.045451, loss: 1.4428
2022-07-08 01:17:57 - train: epoch 0064, iter [02500, 05004], lr: 0.045425, loss: 1.3397
2022-07-08 01:18:42 - train: epoch 0064, iter [02600, 05004], lr: 0.045399, loss: 1.3526
2022-07-08 01:19:27 - train: epoch 0064, iter [02700, 05004], lr: 0.045373, loss: 1.4281
2022-07-08 01:20:13 - train: epoch 0064, iter [02800, 05004], lr: 0.045347, loss: 1.3690
2022-07-08 01:20:58 - train: epoch 0064, iter [02900, 05004], lr: 0.045321, loss: 1.8996
2022-07-08 01:21:43 - train: epoch 0064, iter [03000, 05004], lr: 0.045295, loss: 1.5416
2022-07-08 01:22:28 - train: epoch 0064, iter [03100, 05004], lr: 0.045269, loss: 1.3543
2022-07-08 01:23:13 - train: epoch 0064, iter [03200, 05004], lr: 0.045243, loss: 1.5265
2022-07-08 01:23:58 - train: epoch 0064, iter [03300, 05004], lr: 0.045217, loss: 1.4445
2022-07-08 01:24:43 - train: epoch 0064, iter [03400, 05004], lr: 0.045191, loss: 1.5536
2022-07-08 01:25:28 - train: epoch 0064, iter [03500, 05004], lr: 0.045165, loss: 1.3917
2022-07-08 01:26:13 - train: epoch 0064, iter [03600, 05004], lr: 0.045139, loss: 1.4528
2022-07-08 01:26:58 - train: epoch 0064, iter [03700, 05004], lr: 0.045113, loss: 1.1430
2022-07-08 01:27:44 - train: epoch 0064, iter [03800, 05004], lr: 0.045087, loss: 1.6074
2022-07-08 01:28:29 - train: epoch 0064, iter [03900, 05004], lr: 0.045061, loss: 1.3891
2022-07-08 01:29:14 - train: epoch 0064, iter [04000, 05004], lr: 0.045035, loss: 1.3715
2022-07-08 01:29:59 - train: epoch 0064, iter [04100, 05004], lr: 0.045009, loss: 1.5695
2022-07-08 01:30:44 - train: epoch 0064, iter [04200, 05004], lr: 0.044983, loss: 1.3518
2022-07-08 01:31:29 - train: epoch 0064, iter [04300, 05004], lr: 0.044957, loss: 1.6098
2022-07-08 01:32:15 - train: epoch 0064, iter [04400, 05004], lr: 0.044931, loss: 1.4913
2022-07-08 01:33:00 - train: epoch 0064, iter [04500, 05004], lr: 0.044905, loss: 1.4086
2022-07-08 01:33:45 - train: epoch 0064, iter [04600, 05004], lr: 0.044879, loss: 1.6751
2022-07-08 01:34:30 - train: epoch 0064, iter [04700, 05004], lr: 0.044853, loss: 1.8376
2022-07-08 01:35:16 - train: epoch 0064, iter [04800, 05004], lr: 0.044827, loss: 1.5800
2022-07-08 01:36:01 - train: epoch 0064, iter [04900, 05004], lr: 0.044801, loss: 1.6932
2022-07-08 01:36:46 - train: epoch 0064, iter [05000, 05004], lr: 0.044775, loss: 1.3350
2022-07-08 01:36:49 - train: epoch 064, train_loss: 1.4721
2022-07-08 01:38:07 - eval: epoch: 064, acc1: 68.096%, acc5: 88.822%, test_loss: 1.3066, per_image_load_time: 2.196ms, per_image_inference_time: 0.835ms
2022-07-08 01:38:07 - until epoch: 064, best_acc1: 68.570%
2022-07-08 01:38:07 - epoch 065 lr: 0.044773
2022-07-08 01:38:59 - train: epoch 0065, iter [00100, 05004], lr: 0.044748, loss: 1.5084
2022-07-08 01:39:44 - train: epoch 0065, iter [00200, 05004], lr: 0.044722, loss: 1.4651
2022-07-08 01:40:29 - train: epoch 0065, iter [00300, 05004], lr: 0.044696, loss: 1.3568
2022-07-08 01:41:14 - train: epoch 0065, iter [00400, 05004], lr: 0.044670, loss: 1.6405
2022-07-08 01:41:59 - train: epoch 0065, iter [00500, 05004], lr: 0.044644, loss: 1.3671
2022-07-08 01:42:44 - train: epoch 0065, iter [00600, 05004], lr: 0.044618, loss: 1.5521
2022-07-08 01:43:29 - train: epoch 0065, iter [00700, 05004], lr: 0.044592, loss: 1.3659
2022-07-08 01:44:14 - train: epoch 0065, iter [00800, 05004], lr: 0.044565, loss: 1.4003
2022-07-08 01:44:59 - train: epoch 0065, iter [00900, 05004], lr: 0.044539, loss: 1.3998
2022-07-08 01:45:44 - train: epoch 0065, iter [01000, 05004], lr: 0.044513, loss: 1.4182
2022-07-08 01:46:29 - train: epoch 0065, iter [01100, 05004], lr: 0.044487, loss: 1.3583
2022-07-08 01:47:14 - train: epoch 0065, iter [01200, 05004], lr: 0.044461, loss: 1.6381
2022-07-08 01:47:59 - train: epoch 0065, iter [01300, 05004], lr: 0.044435, loss: 1.3899
2022-07-08 01:48:44 - train: epoch 0065, iter [01400, 05004], lr: 0.044410, loss: 1.3200
2022-07-08 01:49:30 - train: epoch 0065, iter [01500, 05004], lr: 0.044384, loss: 1.3984
2022-07-08 01:50:15 - train: epoch 0065, iter [01600, 05004], lr: 0.044358, loss: 1.4690
2022-07-08 01:51:00 - train: epoch 0065, iter [01700, 05004], lr: 0.044332, loss: 1.4784
2022-07-08 01:51:45 - train: epoch 0065, iter [01800, 05004], lr: 0.044306, loss: 1.3773
2022-07-08 01:52:31 - train: epoch 0065, iter [01900, 05004], lr: 0.044280, loss: 1.2635
2022-07-08 01:53:16 - train: epoch 0065, iter [02000, 05004], lr: 0.044254, loss: 1.4707
2022-07-08 01:54:01 - train: epoch 0065, iter [02100, 05004], lr: 0.044228, loss: 1.3703
2022-07-08 01:54:46 - train: epoch 0065, iter [02200, 05004], lr: 0.044202, loss: 1.5172
2022-07-08 01:55:31 - train: epoch 0065, iter [02300, 05004], lr: 0.044176, loss: 1.4024
2022-07-08 01:56:17 - train: epoch 0065, iter [02400, 05004], lr: 0.044150, loss: 1.3701
2022-07-08 01:57:02 - train: epoch 0065, iter [02500, 05004], lr: 0.044124, loss: 1.4768
2022-07-08 01:57:47 - train: epoch 0065, iter [02600, 05004], lr: 0.044098, loss: 1.7070
2022-07-08 01:58:33 - train: epoch 0065, iter [02700, 05004], lr: 0.044072, loss: 1.5408
2022-07-08 01:59:18 - train: epoch 0065, iter [02800, 05004], lr: 0.044046, loss: 1.4082
2022-07-08 02:00:03 - train: epoch 0065, iter [02900, 05004], lr: 0.044020, loss: 1.5260
2022-07-08 02:00:48 - train: epoch 0065, iter [03000, 05004], lr: 0.043994, loss: 1.3230
2022-07-08 02:01:34 - train: epoch 0065, iter [03100, 05004], lr: 0.043968, loss: 1.4724
2022-07-08 02:02:19 - train: epoch 0065, iter [03200, 05004], lr: 0.043942, loss: 1.5292
2022-07-08 02:03:04 - train: epoch 0065, iter [03300, 05004], lr: 0.043916, loss: 1.5069
2022-07-08 02:03:49 - train: epoch 0065, iter [03400, 05004], lr: 0.043890, loss: 1.3664
2022-07-08 02:04:35 - train: epoch 0065, iter [03500, 05004], lr: 0.043864, loss: 1.7472
2022-07-08 02:05:20 - train: epoch 0065, iter [03600, 05004], lr: 0.043838, loss: 1.5137
2022-07-08 02:06:05 - train: epoch 0065, iter [03700, 05004], lr: 0.043812, loss: 1.4292
2022-07-08 02:06:50 - train: epoch 0065, iter [03800, 05004], lr: 0.043786, loss: 1.3269
2022-07-08 02:07:35 - train: epoch 0065, iter [03900, 05004], lr: 0.043760, loss: 1.5589
2022-07-08 02:08:21 - train: epoch 0065, iter [04000, 05004], lr: 0.043734, loss: 1.5605
2022-07-08 02:09:06 - train: epoch 0065, iter [04100, 05004], lr: 0.043708, loss: 1.3124
2022-07-08 02:09:51 - train: epoch 0065, iter [04200, 05004], lr: 0.043682, loss: 1.4537
2022-07-08 02:10:37 - train: epoch 0065, iter [04300, 05004], lr: 0.043656, loss: 1.3887
2022-07-08 02:11:22 - train: epoch 0065, iter [04400, 05004], lr: 0.043630, loss: 1.5824
2022-07-08 02:12:07 - train: epoch 0065, iter [04500, 05004], lr: 0.043604, loss: 1.5031
2022-07-08 02:12:53 - train: epoch 0065, iter [04600, 05004], lr: 0.043578, loss: 1.5083
2022-07-08 02:13:38 - train: epoch 0065, iter [04700, 05004], lr: 0.043553, loss: 1.5020
2022-07-08 02:14:23 - train: epoch 0065, iter [04800, 05004], lr: 0.043527, loss: 1.2540
2022-07-08 02:15:08 - train: epoch 0065, iter [04900, 05004], lr: 0.043501, loss: 1.3808
2022-07-08 02:15:54 - train: epoch 0065, iter [05000, 05004], lr: 0.043475, loss: 1.5269
2022-07-08 02:15:56 - train: epoch 065, train_loss: 1.4608
2022-07-08 02:17:13 - eval: epoch: 065, acc1: 68.736%, acc5: 89.108%, test_loss: 1.2841, per_image_load_time: 2.203ms, per_image_inference_time: 0.828ms
2022-07-08 02:17:15 - until epoch: 065, best_acc1: 68.736%
2022-07-08 02:17:15 - epoch 066 lr: 0.043473
2022-07-08 02:18:06 - train: epoch 0066, iter [00100, 05004], lr: 0.043448, loss: 1.3233
2022-07-08 02:18:51 - train: epoch 0066, iter [00200, 05004], lr: 0.043422, loss: 1.5895
2022-07-08 02:19:37 - train: epoch 0066, iter [00300, 05004], lr: 0.043396, loss: 1.2245
2022-07-08 02:20:22 - train: epoch 0066, iter [00400, 05004], lr: 0.043370, loss: 1.1876
2022-07-08 02:21:07 - train: epoch 0066, iter [00500, 05004], lr: 0.043344, loss: 1.4739
2022-07-08 02:21:53 - train: epoch 0066, iter [00600, 05004], lr: 0.043318, loss: 1.3735
2022-07-08 02:22:38 - train: epoch 0066, iter [00700, 05004], lr: 0.043292, loss: 1.4507
2022-07-08 02:23:23 - train: epoch 0066, iter [00800, 05004], lr: 0.043266, loss: 1.7841
2022-07-08 02:24:08 - train: epoch 0066, iter [00900, 05004], lr: 0.043240, loss: 1.5699
2022-07-08 02:24:54 - train: epoch 0066, iter [01000, 05004], lr: 0.043214, loss: 1.6307
2022-07-08 02:25:39 - train: epoch 0066, iter [01100, 05004], lr: 0.043189, loss: 1.4876
2022-07-08 02:26:24 - train: epoch 0066, iter [01200, 05004], lr: 0.043163, loss: 1.6272
2022-07-08 02:27:09 - train: epoch 0066, iter [01300, 05004], lr: 0.043137, loss: 1.5395
2022-07-08 02:27:55 - train: epoch 0066, iter [01400, 05004], lr: 0.043111, loss: 1.2033
2022-07-08 02:28:40 - train: epoch 0066, iter [01500, 05004], lr: 0.043085, loss: 1.4249
2022-07-08 02:29:25 - train: epoch 0066, iter [01600, 05004], lr: 0.043059, loss: 1.4271
2022-07-08 02:30:10 - train: epoch 0066, iter [01700, 05004], lr: 0.043033, loss: 1.3433
2022-07-08 02:30:55 - train: epoch 0066, iter [01800, 05004], lr: 0.043007, loss: 1.3188
2022-07-08 02:31:41 - train: epoch 0066, iter [01900, 05004], lr: 0.042981, loss: 1.6393
2022-07-08 02:32:26 - train: epoch 0066, iter [02000, 05004], lr: 0.042955, loss: 1.5184
2022-07-08 02:33:11 - train: epoch 0066, iter [02100, 05004], lr: 0.042929, loss: 1.4662
2022-07-08 02:33:56 - train: epoch 0066, iter [02200, 05004], lr: 0.042904, loss: 1.4483
2022-07-08 02:34:41 - train: epoch 0066, iter [02300, 05004], lr: 0.042878, loss: 1.5872
2022-07-08 02:35:26 - train: epoch 0066, iter [02400, 05004], lr: 0.042852, loss: 1.3266
2022-07-08 02:36:11 - train: epoch 0066, iter [02500, 05004], lr: 0.042826, loss: 1.4425
2022-07-08 02:36:56 - train: epoch 0066, iter [02600, 05004], lr: 0.042800, loss: 1.3413
2022-07-08 02:37:42 - train: epoch 0066, iter [02700, 05004], lr: 0.042774, loss: 1.6832
2022-07-08 02:38:27 - train: epoch 0066, iter [02800, 05004], lr: 0.042748, loss: 1.5923
2022-07-08 02:39:12 - train: epoch 0066, iter [02900, 05004], lr: 0.042722, loss: 1.4877
2022-07-08 02:39:57 - train: epoch 0066, iter [03000, 05004], lr: 0.042696, loss: 1.3813
2022-07-08 02:40:42 - train: epoch 0066, iter [03100, 05004], lr: 0.042671, loss: 1.6345
2022-07-08 02:41:27 - train: epoch 0066, iter [03200, 05004], lr: 0.042645, loss: 1.2660
2022-07-08 02:42:12 - train: epoch 0066, iter [03300, 05004], lr: 0.042619, loss: 1.3834
2022-07-08 02:42:57 - train: epoch 0066, iter [03400, 05004], lr: 0.042593, loss: 1.6653
2022-07-08 02:43:42 - train: epoch 0066, iter [03500, 05004], lr: 0.042567, loss: 1.4682
2022-07-08 02:44:27 - train: epoch 0066, iter [03600, 05004], lr: 0.042541, loss: 1.4663
2022-07-08 02:45:12 - train: epoch 0066, iter [03700, 05004], lr: 0.042515, loss: 1.4808
2022-07-08 02:45:57 - train: epoch 0066, iter [03800, 05004], lr: 0.042490, loss: 1.2815
2022-07-08 02:46:42 - train: epoch 0066, iter [03900, 05004], lr: 0.042464, loss: 1.3344
2022-07-08 02:47:27 - train: epoch 0066, iter [04000, 05004], lr: 0.042438, loss: 1.5987
2022-07-08 02:48:12 - train: epoch 0066, iter [04100, 05004], lr: 0.042412, loss: 1.2937
2022-07-08 02:48:57 - train: epoch 0066, iter [04200, 05004], lr: 0.042386, loss: 1.2592
2022-07-08 02:49:42 - train: epoch 0066, iter [04300, 05004], lr: 0.042360, loss: 1.2944
2022-07-08 02:50:27 - train: epoch 0066, iter [04400, 05004], lr: 0.042334, loss: 1.4115
2022-07-08 02:51:12 - train: epoch 0066, iter [04500, 05004], lr: 0.042309, loss: 1.5470
2022-07-08 02:51:57 - train: epoch 0066, iter [04600, 05004], lr: 0.042283, loss: 1.6168
2022-07-08 02:52:42 - train: epoch 0066, iter [04700, 05004], lr: 0.042257, loss: 1.3361
2022-07-08 02:53:27 - train: epoch 0066, iter [04800, 05004], lr: 0.042231, loss: 1.4344
2022-07-08 02:54:12 - train: epoch 0066, iter [04900, 05004], lr: 0.042205, loss: 1.4914
2022-07-08 02:54:57 - train: epoch 0066, iter [05000, 05004], lr: 0.042179, loss: 1.3186
2022-07-08 02:54:59 - train: epoch 066, train_loss: 1.4475
2022-07-08 02:56:17 - eval: epoch: 066, acc1: 68.640%, acc5: 89.458%, test_loss: 1.2662, per_image_load_time: 2.159ms, per_image_inference_time: 0.831ms
2022-07-08 02:56:18 - until epoch: 066, best_acc1: 68.736%
2022-07-08 02:56:18 - epoch 067 lr: 0.042178
2022-07-08 02:57:09 - train: epoch 0067, iter [00100, 05004], lr: 0.042152, loss: 1.3304
2022-07-08 02:57:54 - train: epoch 0067, iter [00200, 05004], lr: 0.042127, loss: 1.3797
2022-07-08 02:58:39 - train: epoch 0067, iter [00300, 05004], lr: 0.042101, loss: 1.6761
2022-07-08 02:59:24 - train: epoch 0067, iter [00400, 05004], lr: 0.042075, loss: 1.3665
2022-07-08 03:00:09 - train: epoch 0067, iter [00500, 05004], lr: 0.042049, loss: 1.3625
2022-07-08 03:00:55 - train: epoch 0067, iter [00600, 05004], lr: 0.042023, loss: 1.3020
2022-07-08 03:01:40 - train: epoch 0067, iter [00700, 05004], lr: 0.041997, loss: 1.4268
2022-07-08 03:02:25 - train: epoch 0067, iter [00800, 05004], lr: 0.041972, loss: 1.5007
2022-07-08 03:03:10 - train: epoch 0067, iter [00900, 05004], lr: 0.041946, loss: 1.5509
2022-07-08 03:03:56 - train: epoch 0067, iter [01000, 05004], lr: 0.041920, loss: 1.2517
2022-07-08 03:04:41 - train: epoch 0067, iter [01100, 05004], lr: 0.041894, loss: 1.4033
2022-07-08 03:05:26 - train: epoch 0067, iter [01200, 05004], lr: 0.041868, loss: 1.4727
2022-07-08 03:06:11 - train: epoch 0067, iter [01300, 05004], lr: 0.041843, loss: 1.5817
2022-07-08 03:06:56 - train: epoch 0067, iter [01400, 05004], lr: 0.041817, loss: 1.4216
2022-07-08 03:07:42 - train: epoch 0067, iter [01500, 05004], lr: 0.041791, loss: 1.4933
2022-07-08 03:08:27 - train: epoch 0067, iter [01600, 05004], lr: 0.041765, loss: 1.4639
2022-07-08 03:09:12 - train: epoch 0067, iter [01700, 05004], lr: 0.041739, loss: 1.3322
2022-07-08 03:09:57 - train: epoch 0067, iter [01800, 05004], lr: 0.041714, loss: 1.5980
2022-07-08 03:10:42 - train: epoch 0067, iter [01900, 05004], lr: 0.041688, loss: 1.3908
2022-07-08 03:11:27 - train: epoch 0067, iter [02000, 05004], lr: 0.041662, loss: 1.5905
2022-07-08 03:12:12 - train: epoch 0067, iter [02100, 05004], lr: 0.041636, loss: 1.1951
2022-07-08 03:12:58 - train: epoch 0067, iter [02200, 05004], lr: 0.041610, loss: 1.4713
2022-07-08 03:13:43 - train: epoch 0067, iter [02300, 05004], lr: 0.041585, loss: 1.3514
2022-07-08 03:14:28 - train: epoch 0067, iter [02400, 05004], lr: 0.041559, loss: 1.4603
2022-07-08 03:15:13 - train: epoch 0067, iter [02500, 05004], lr: 0.041533, loss: 1.3179
2022-07-08 03:15:58 - train: epoch 0067, iter [02600, 05004], lr: 0.041507, loss: 1.3010
2022-07-08 03:16:43 - train: epoch 0067, iter [02700, 05004], lr: 0.041481, loss: 1.3788
2022-07-08 03:17:29 - train: epoch 0067, iter [02800, 05004], lr: 0.041456, loss: 1.6246
2022-07-08 03:18:14 - train: epoch 0067, iter [02900, 05004], lr: 0.041430, loss: 1.3466
2022-07-08 03:18:59 - train: epoch 0067, iter [03000, 05004], lr: 0.041404, loss: 1.3200
2022-07-08 03:19:45 - train: epoch 0067, iter [03100, 05004], lr: 0.041378, loss: 1.2801
2022-07-08 03:20:30 - train: epoch 0067, iter [03200, 05004], lr: 0.041353, loss: 1.5794
2022-07-08 03:21:15 - train: epoch 0067, iter [03300, 05004], lr: 0.041327, loss: 1.2733
2022-07-08 03:22:00 - train: epoch 0067, iter [03400, 05004], lr: 0.041301, loss: 1.4064
2022-07-08 03:22:46 - train: epoch 0067, iter [03500, 05004], lr: 0.041275, loss: 1.3428
2022-07-08 03:23:31 - train: epoch 0067, iter [03600, 05004], lr: 0.041250, loss: 1.5596
2022-07-08 03:24:16 - train: epoch 0067, iter [03700, 05004], lr: 0.041224, loss: 1.5904
2022-07-08 03:25:01 - train: epoch 0067, iter [03800, 05004], lr: 0.041198, loss: 1.3560
2022-07-08 03:25:47 - train: epoch 0067, iter [03900, 05004], lr: 0.041172, loss: 1.4550
2022-07-08 03:26:32 - train: epoch 0067, iter [04000, 05004], lr: 0.041147, loss: 1.5550
2022-07-08 03:27:17 - train: epoch 0067, iter [04100, 05004], lr: 0.041121, loss: 1.5383
2022-07-08 03:28:03 - train: epoch 0067, iter [04200, 05004], lr: 0.041095, loss: 1.6187
2022-07-08 03:28:48 - train: epoch 0067, iter [04300, 05004], lr: 0.041069, loss: 1.3259
2022-07-08 03:29:33 - train: epoch 0067, iter [04400, 05004], lr: 0.041044, loss: 1.5083
2022-07-08 03:30:19 - train: epoch 0067, iter [04500, 05004], lr: 0.041018, loss: 1.3767
2022-07-08 03:31:04 - train: epoch 0067, iter [04600, 05004], lr: 0.040992, loss: 1.1761
2022-07-08 03:31:49 - train: epoch 0067, iter [04700, 05004], lr: 0.040966, loss: 1.4217
2022-07-08 03:32:35 - train: epoch 0067, iter [04800, 05004], lr: 0.040941, loss: 1.2702
2022-07-08 03:33:20 - train: epoch 0067, iter [04900, 05004], lr: 0.040915, loss: 1.5445
2022-07-08 03:34:05 - train: epoch 0067, iter [05000, 05004], lr: 0.040889, loss: 1.5136
2022-07-08 03:34:07 - train: epoch 067, train_loss: 1.4358
2022-07-08 03:35:24 - eval: epoch: 067, acc1: 69.198%, acc5: 89.494%, test_loss: 1.2551, per_image_load_time: 2.093ms, per_image_inference_time: 0.838ms
2022-07-08 03:35:25 - until epoch: 067, best_acc1: 69.198%
2022-07-08 03:35:25 - epoch 068 lr: 0.040888
2022-07-08 03:36:16 - train: epoch 0068, iter [00100, 05004], lr: 0.040863, loss: 1.4624
2022-07-08 03:37:01 - train: epoch 0068, iter [00200, 05004], lr: 0.040837, loss: 1.3804
2022-07-08 03:37:46 - train: epoch 0068, iter [00300, 05004], lr: 0.040811, loss: 1.5075
2022-07-08 03:38:31 - train: epoch 0068, iter [00400, 05004], lr: 0.040785, loss: 1.3068
2022-07-08 03:39:16 - train: epoch 0068, iter [00500, 05004], lr: 0.040760, loss: 1.3563
2022-07-08 03:40:01 - train: epoch 0068, iter [00600, 05004], lr: 0.040734, loss: 1.3931
2022-07-08 03:40:46 - train: epoch 0068, iter [00700, 05004], lr: 0.040708, loss: 1.6628
2022-07-08 03:41:32 - train: epoch 0068, iter [00800, 05004], lr: 0.040683, loss: 1.4726
2022-07-08 03:42:16 - train: epoch 0068, iter [00900, 05004], lr: 0.040657, loss: 1.2874
2022-07-08 03:43:02 - train: epoch 0068, iter [01000, 05004], lr: 0.040631, loss: 1.3461
2022-07-08 03:43:47 - train: epoch 0068, iter [01100, 05004], lr: 0.040605, loss: 1.5897
2022-07-08 03:44:32 - train: epoch 0068, iter [01200, 05004], lr: 0.040580, loss: 1.3433
2022-07-08 03:45:17 - train: epoch 0068, iter [01300, 05004], lr: 0.040554, loss: 1.2644
2022-07-08 03:46:02 - train: epoch 0068, iter [01400, 05004], lr: 0.040528, loss: 1.4420
2022-07-08 03:46:47 - train: epoch 0068, iter [01500, 05004], lr: 0.040503, loss: 1.5537
2022-07-08 03:47:32 - train: epoch 0068, iter [01600, 05004], lr: 0.040477, loss: 1.4535
2022-07-08 03:48:17 - train: epoch 0068, iter [01700, 05004], lr: 0.040451, loss: 1.4984
2022-07-08 03:49:02 - train: epoch 0068, iter [01800, 05004], lr: 0.040426, loss: 1.5050
2022-07-08 03:49:48 - train: epoch 0068, iter [01900, 05004], lr: 0.040400, loss: 1.4087
2022-07-08 03:50:33 - train: epoch 0068, iter [02000, 05004], lr: 0.040374, loss: 1.3763
2022-07-08 03:51:18 - train: epoch 0068, iter [02100, 05004], lr: 0.040349, loss: 1.4355
2022-07-08 03:52:03 - train: epoch 0068, iter [02200, 05004], lr: 0.040323, loss: 1.4228
2022-07-08 03:52:48 - train: epoch 0068, iter [02300, 05004], lr: 0.040297, loss: 1.2906
2022-07-08 03:53:33 - train: epoch 0068, iter [02400, 05004], lr: 0.040272, loss: 1.4819
2022-07-08 03:54:18 - train: epoch 0068, iter [02500, 05004], lr: 0.040246, loss: 1.5173
2022-07-08 03:55:03 - train: epoch 0068, iter [02600, 05004], lr: 0.040220, loss: 1.3985
2022-07-08 03:55:49 - train: epoch 0068, iter [02700, 05004], lr: 0.040195, loss: 1.4682
2022-07-08 03:56:34 - train: epoch 0068, iter [02800, 05004], lr: 0.040169, loss: 1.6022
2022-07-08 03:57:19 - train: epoch 0068, iter [02900, 05004], lr: 0.040143, loss: 1.5317
2022-07-08 03:58:04 - train: epoch 0068, iter [03000, 05004], lr: 0.040118, loss: 1.6729
2022-07-08 03:58:49 - train: epoch 0068, iter [03100, 05004], lr: 0.040092, loss: 1.2551
2022-07-08 03:59:35 - train: epoch 0068, iter [03200, 05004], lr: 0.040066, loss: 1.5717
2022-07-08 04:00:20 - train: epoch 0068, iter [03300, 05004], lr: 0.040041, loss: 1.3867
2022-07-08 04:01:05 - train: epoch 0068, iter [03400, 05004], lr: 0.040015, loss: 1.3386
2022-07-08 04:01:50 - train: epoch 0068, iter [03500, 05004], lr: 0.039990, loss: 1.5355
2022-07-08 04:02:35 - train: epoch 0068, iter [03600, 05004], lr: 0.039964, loss: 1.3552
2022-07-08 04:03:20 - train: epoch 0068, iter [03700, 05004], lr: 0.039938, loss: 1.4938
2022-07-08 04:04:05 - train: epoch 0068, iter [03800, 05004], lr: 0.039913, loss: 1.5258
2022-07-08 04:04:51 - train: epoch 0068, iter [03900, 05004], lr: 0.039887, loss: 1.5904
2022-07-08 04:05:36 - train: epoch 0068, iter [04000, 05004], lr: 0.039861, loss: 1.4143
2022-07-08 04:06:21 - train: epoch 0068, iter [04100, 05004], lr: 0.039836, loss: 1.1855
2022-07-08 04:07:06 - train: epoch 0068, iter [04200, 05004], lr: 0.039810, loss: 1.6068
2022-07-08 04:07:51 - train: epoch 0068, iter [04300, 05004], lr: 0.039785, loss: 1.4327
2022-07-08 04:08:37 - train: epoch 0068, iter [04400, 05004], lr: 0.039759, loss: 1.4884
2022-07-08 04:09:22 - train: epoch 0068, iter [04500, 05004], lr: 0.039733, loss: 1.4127
2022-07-08 04:10:07 - train: epoch 0068, iter [04600, 05004], lr: 0.039708, loss: 1.6024
2022-07-08 04:10:52 - train: epoch 0068, iter [04700, 05004], lr: 0.039682, loss: 1.7628
2022-07-08 04:11:37 - train: epoch 0068, iter [04800, 05004], lr: 0.039657, loss: 1.5689
2022-07-08 04:12:22 - train: epoch 0068, iter [04900, 05004], lr: 0.039631, loss: 1.6011
2022-07-08 04:13:08 - train: epoch 0068, iter [05000, 05004], lr: 0.039605, loss: 1.3879
2022-07-08 04:13:10 - train: epoch 068, train_loss: 1.4226
2022-07-08 04:14:26 - eval: epoch: 068, acc1: 69.212%, acc5: 89.672%, test_loss: 1.2373, per_image_load_time: 2.107ms, per_image_inference_time: 0.847ms
2022-07-08 04:14:27 - until epoch: 068, best_acc1: 69.212%
2022-07-08 04:14:27 - epoch 069 lr: 0.039604
2022-07-08 04:15:19 - train: epoch 0069, iter [00100, 05004], lr: 0.039579, loss: 1.6208
2022-07-08 04:16:04 - train: epoch 0069, iter [00200, 05004], lr: 0.039553, loss: 1.6230
2022-07-08 04:16:49 - train: epoch 0069, iter [00300, 05004], lr: 0.039528, loss: 1.3960
2022-07-08 04:17:35 - train: epoch 0069, iter [00400, 05004], lr: 0.039502, loss: 1.2687
2022-07-08 04:18:19 - train: epoch 0069, iter [00500, 05004], lr: 0.039477, loss: 1.2722
2022-07-08 04:19:05 - train: epoch 0069, iter [00600, 05004], lr: 0.039451, loss: 1.1751
2022-07-08 04:19:50 - train: epoch 0069, iter [00700, 05004], lr: 0.039425, loss: 1.3291
2022-07-08 04:20:35 - train: epoch 0069, iter [00800, 05004], lr: 0.039400, loss: 1.3817
2022-07-08 04:21:20 - train: epoch 0069, iter [00900, 05004], lr: 0.039374, loss: 1.3514
2022-07-08 04:22:04 - train: epoch 0069, iter [01000, 05004], lr: 0.039349, loss: 1.3299
2022-07-08 04:22:49 - train: epoch 0069, iter [01100, 05004], lr: 0.039323, loss: 1.4195
2022-07-08 04:23:34 - train: epoch 0069, iter [01200, 05004], lr: 0.039298, loss: 1.3980
2022-07-08 04:24:19 - train: epoch 0069, iter [01300, 05004], lr: 0.039272, loss: 1.6964
2022-07-08 04:25:03 - train: epoch 0069, iter [01400, 05004], lr: 0.039246, loss: 1.5234
2022-07-08 04:25:48 - train: epoch 0069, iter [01500, 05004], lr: 0.039221, loss: 1.4302
2022-07-08 04:26:33 - train: epoch 0069, iter [01600, 05004], lr: 0.039195, loss: 1.4948
2022-07-08 04:27:18 - train: epoch 0069, iter [01700, 05004], lr: 0.039170, loss: 1.4248
2022-07-08 04:28:03 - train: epoch 0069, iter [01800, 05004], lr: 0.039144, loss: 1.2993
2022-07-08 04:28:48 - train: epoch 0069, iter [01900, 05004], lr: 0.039119, loss: 1.3234
2022-07-08 04:29:32 - train: epoch 0069, iter [02000, 05004], lr: 0.039093, loss: 1.2840
2022-07-08 04:30:17 - train: epoch 0069, iter [02100, 05004], lr: 0.039068, loss: 1.3391
2022-07-08 04:31:02 - train: epoch 0069, iter [02200, 05004], lr: 0.039042, loss: 1.4255
2022-07-08 04:31:47 - train: epoch 0069, iter [02300, 05004], lr: 0.039017, loss: 1.4028
2022-07-08 04:32:32 - train: epoch 0069, iter [02400, 05004], lr: 0.038991, loss: 1.4776
2022-07-08 04:33:16 - train: epoch 0069, iter [02500, 05004], lr: 0.038966, loss: 1.3777
2022-07-08 04:34:01 - train: epoch 0069, iter [02600, 05004], lr: 0.038940, loss: 1.5171
2022-07-08 04:34:46 - train: epoch 0069, iter [02700, 05004], lr: 0.038915, loss: 1.6784
2022-07-08 04:35:31 - train: epoch 0069, iter [02800, 05004], lr: 0.038889, loss: 1.4967
2022-07-08 04:36:16 - train: epoch 0069, iter [02900, 05004], lr: 0.038864, loss: 1.2988
2022-07-08 04:37:00 - train: epoch 0069, iter [03000, 05004], lr: 0.038838, loss: 1.4206
2022-07-08 04:37:45 - train: epoch 0069, iter [03100, 05004], lr: 0.038813, loss: 1.4106
2022-07-08 04:38:30 - train: epoch 0069, iter [03200, 05004], lr: 0.038787, loss: 1.2945
2022-07-08 04:39:15 - train: epoch 0069, iter [03300, 05004], lr: 0.038762, loss: 1.2986
2022-07-08 04:40:00 - train: epoch 0069, iter [03400, 05004], lr: 0.038736, loss: 1.3122
2022-07-08 04:40:45 - train: epoch 0069, iter [03500, 05004], lr: 0.038711, loss: 1.3692
2022-07-08 04:41:30 - train: epoch 0069, iter [03600, 05004], lr: 0.038685, loss: 1.3619
2022-07-08 04:42:15 - train: epoch 0069, iter [03700, 05004], lr: 0.038660, loss: 1.5171
2022-07-08 04:43:00 - train: epoch 0069, iter [03800, 05004], lr: 0.038634, loss: 1.4497
2022-07-08 04:43:44 - train: epoch 0069, iter [03900, 05004], lr: 0.038609, loss: 1.4935
2022-07-08 04:44:29 - train: epoch 0069, iter [04000, 05004], lr: 0.038583, loss: 1.5435
2022-07-08 04:45:14 - train: epoch 0069, iter [04100, 05004], lr: 0.038558, loss: 1.5295
2022-07-08 04:45:59 - train: epoch 0069, iter [04200, 05004], lr: 0.038532, loss: 1.1103
2022-07-08 04:46:44 - train: epoch 0069, iter [04300, 05004], lr: 0.038507, loss: 1.4037
2022-07-08 04:47:29 - train: epoch 0069, iter [04400, 05004], lr: 0.038481, loss: 1.4652
2022-07-08 04:48:14 - train: epoch 0069, iter [04500, 05004], lr: 0.038456, loss: 1.4205
2022-07-08 04:48:59 - train: epoch 0069, iter [04600, 05004], lr: 0.038431, loss: 1.7094
2022-07-08 04:49:44 - train: epoch 0069, iter [04700, 05004], lr: 0.038405, loss: 1.4384
2022-07-08 04:50:29 - train: epoch 0069, iter [04800, 05004], lr: 0.038380, loss: 1.4362
2022-07-08 04:51:14 - train: epoch 0069, iter [04900, 05004], lr: 0.038354, loss: 1.3262
2022-07-08 04:51:59 - train: epoch 0069, iter [05000, 05004], lr: 0.038329, loss: 1.4329
2022-07-08 04:52:01 - train: epoch 069, train_loss: 1.4077
2022-07-08 04:53:18 - eval: epoch: 069, acc1: 69.628%, acc5: 89.820%, test_loss: 1.2308, per_image_load_time: 2.151ms, per_image_inference_time: 0.839ms
2022-07-08 04:53:19 - until epoch: 069, best_acc1: 69.628%
2022-07-08 04:53:19 - epoch 070 lr: 0.038327
2022-07-08 04:54:10 - train: epoch 0070, iter [00100, 05004], lr: 0.038302, loss: 1.4084
2022-07-08 04:54:55 - train: epoch 0070, iter [00200, 05004], lr: 0.038277, loss: 1.4837
2022-07-08 04:55:41 - train: epoch 0070, iter [00300, 05004], lr: 0.038251, loss: 1.5704
2022-07-08 04:56:26 - train: epoch 0070, iter [00400, 05004], lr: 0.038226, loss: 1.3332
2022-07-08 04:57:11 - train: epoch 0070, iter [00500, 05004], lr: 0.038201, loss: 1.4621
2022-07-08 04:57:56 - train: epoch 0070, iter [00600, 05004], lr: 0.038175, loss: 1.3172
2022-07-08 04:58:41 - train: epoch 0070, iter [00700, 05004], lr: 0.038150, loss: 1.3204
2022-07-08 04:59:26 - train: epoch 0070, iter [00800, 05004], lr: 0.038124, loss: 1.2829
2022-07-08 05:00:11 - train: epoch 0070, iter [00900, 05004], lr: 0.038099, loss: 1.4402
2022-07-08 05:00:57 - train: epoch 0070, iter [01000, 05004], lr: 0.038074, loss: 1.2761
2022-07-08 05:01:42 - train: epoch 0070, iter [01100, 05004], lr: 0.038048, loss: 1.7415
2022-07-08 05:02:27 - train: epoch 0070, iter [01200, 05004], lr: 0.038023, loss: 1.1236
2022-07-08 05:03:12 - train: epoch 0070, iter [01300, 05004], lr: 0.037997, loss: 1.2926
2022-07-08 05:03:57 - train: epoch 0070, iter [01400, 05004], lr: 0.037972, loss: 1.3143
2022-07-08 05:04:42 - train: epoch 0070, iter [01500, 05004], lr: 0.037947, loss: 1.2257
2022-07-08 05:05:27 - train: epoch 0070, iter [01600, 05004], lr: 0.037921, loss: 1.4037
2022-07-08 05:06:13 - train: epoch 0070, iter [01700, 05004], lr: 0.037896, loss: 1.4028
2022-07-08 05:06:58 - train: epoch 0070, iter [01800, 05004], lr: 0.037870, loss: 1.1839
2022-07-08 05:07:43 - train: epoch 0070, iter [01900, 05004], lr: 0.037845, loss: 1.2934
2022-07-08 05:08:28 - train: epoch 0070, iter [02000, 05004], lr: 0.037820, loss: 1.4123
2022-07-08 05:09:13 - train: epoch 0070, iter [02100, 05004], lr: 0.037794, loss: 1.4317
2022-07-08 05:09:59 - train: epoch 0070, iter [02200, 05004], lr: 0.037769, loss: 1.4170
2022-07-08 05:10:44 - train: epoch 0070, iter [02300, 05004], lr: 0.037744, loss: 1.3415
2022-07-08 05:11:29 - train: epoch 0070, iter [02400, 05004], lr: 0.037718, loss: 1.5049
2022-07-08 05:12:15 - train: epoch 0070, iter [02500, 05004], lr: 0.037693, loss: 1.4542
2022-07-08 05:13:00 - train: epoch 0070, iter [02600, 05004], lr: 0.037667, loss: 1.3846
2022-07-08 05:13:45 - train: epoch 0070, iter [02700, 05004], lr: 0.037642, loss: 1.3179
2022-07-08 05:14:30 - train: epoch 0070, iter [02800, 05004], lr: 0.037617, loss: 1.4792
2022-07-08 05:15:16 - train: epoch 0070, iter [02900, 05004], lr: 0.037591, loss: 1.6004
2022-07-08 05:16:01 - train: epoch 0070, iter [03000, 05004], lr: 0.037566, loss: 1.3283
2022-07-08 05:16:46 - train: epoch 0070, iter [03100, 05004], lr: 0.037541, loss: 1.4853
2022-07-08 05:17:31 - train: epoch 0070, iter [03200, 05004], lr: 0.037515, loss: 1.5476
2022-07-08 05:18:16 - train: epoch 0070, iter [03300, 05004], lr: 0.037490, loss: 1.3597
2022-07-08 05:19:02 - train: epoch 0070, iter [03400, 05004], lr: 0.037465, loss: 1.4595
2022-07-08 05:19:47 - train: epoch 0070, iter [03500, 05004], lr: 0.037439, loss: 1.4233
2022-07-08 05:20:32 - train: epoch 0070, iter [03600, 05004], lr: 0.037414, loss: 1.4989
2022-07-08 05:21:18 - train: epoch 0070, iter [03700, 05004], lr: 0.037389, loss: 1.4935
2022-07-08 05:22:03 - train: epoch 0070, iter [03800, 05004], lr: 0.037364, loss: 1.3513
2022-07-08 05:22:48 - train: epoch 0070, iter [03900, 05004], lr: 0.037338, loss: 1.2337
2022-07-08 05:23:33 - train: epoch 0070, iter [04000, 05004], lr: 0.037313, loss: 1.3144
2022-07-08 05:24:18 - train: epoch 0070, iter [04100, 05004], lr: 0.037288, loss: 1.3020
2022-07-08 05:25:04 - train: epoch 0070, iter [04200, 05004], lr: 0.037262, loss: 1.4584
2022-07-08 05:25:49 - train: epoch 0070, iter [04300, 05004], lr: 0.037237, loss: 1.4914
2022-07-08 05:26:34 - train: epoch 0070, iter [04400, 05004], lr: 0.037212, loss: 1.5075
2022-07-08 05:27:19 - train: epoch 0070, iter [04500, 05004], lr: 0.037186, loss: 1.4625
2022-07-08 05:28:04 - train: epoch 0070, iter [04600, 05004], lr: 0.037161, loss: 1.5342
2022-07-08 05:28:50 - train: epoch 0070, iter [04700, 05004], lr: 0.037136, loss: 1.5068
2022-07-08 05:29:35 - train: epoch 0070, iter [04800, 05004], lr: 0.037111, loss: 1.4645
2022-07-08 05:30:20 - train: epoch 0070, iter [04900, 05004], lr: 0.037085, loss: 1.4605
2022-07-08 05:31:05 - train: epoch 0070, iter [05000, 05004], lr: 0.037060, loss: 1.4427
2022-07-08 05:31:07 - train: epoch 070, train_loss: 1.3986
2022-07-08 05:32:25 - eval: epoch: 070, acc1: 69.674%, acc5: 89.788%, test_loss: 1.2260, per_image_load_time: 2.085ms, per_image_inference_time: 0.841ms
2022-07-08 05:32:26 - until epoch: 070, best_acc1: 69.674%
2022-07-08 05:32:26 - epoch 071 lr: 0.037059
2022-07-08 05:33:18 - train: epoch 0071, iter [00100, 05004], lr: 0.037034, loss: 1.1189
2022-07-08 05:34:03 - train: epoch 0071, iter [00200, 05004], lr: 0.037009, loss: 1.3665
2022-07-08 05:34:48 - train: epoch 0071, iter [00300, 05004], lr: 0.036983, loss: 1.2913
2022-07-08 05:35:33 - train: epoch 0071, iter [00400, 05004], lr: 0.036958, loss: 1.4451
2022-07-08 05:36:19 - train: epoch 0071, iter [00500, 05004], lr: 0.036933, loss: 1.3789
2022-07-08 05:37:04 - train: epoch 0071, iter [00600, 05004], lr: 0.036908, loss: 1.5740
2022-07-08 05:37:49 - train: epoch 0071, iter [00700, 05004], lr: 0.036882, loss: 1.5112
2022-07-08 05:38:34 - train: epoch 0071, iter [00800, 05004], lr: 0.036857, loss: 1.3357
2022-07-08 05:39:19 - train: epoch 0071, iter [00900, 05004], lr: 0.036832, loss: 1.5123
2022-07-08 05:40:05 - train: epoch 0071, iter [01000, 05004], lr: 0.036807, loss: 1.4456
2022-07-08 05:40:50 - train: epoch 0071, iter [01100, 05004], lr: 0.036781, loss: 1.5514
2022-07-08 05:41:35 - train: epoch 0071, iter [01200, 05004], lr: 0.036756, loss: 1.3065
2022-07-08 05:42:20 - train: epoch 0071, iter [01300, 05004], lr: 0.036731, loss: 1.4479
2022-07-08 05:43:05 - train: epoch 0071, iter [01400, 05004], lr: 0.036706, loss: 1.3323
2022-07-08 05:43:51 - train: epoch 0071, iter [01500, 05004], lr: 0.036680, loss: 1.2251
2022-07-08 05:44:36 - train: epoch 0071, iter [01600, 05004], lr: 0.036655, loss: 1.2952
2022-07-08 05:45:21 - train: epoch 0071, iter [01700, 05004], lr: 0.036630, loss: 1.4058
2022-07-08 05:46:07 - train: epoch 0071, iter [01800, 05004], lr: 0.036605, loss: 1.2937
2022-07-08 05:46:52 - train: epoch 0071, iter [01900, 05004], lr: 0.036580, loss: 1.3447
2022-07-08 05:47:37 - train: epoch 0071, iter [02000, 05004], lr: 0.036554, loss: 1.5041
2022-07-08 05:48:23 - train: epoch 0071, iter [02100, 05004], lr: 0.036529, loss: 1.2252
2022-07-08 05:49:08 - train: epoch 0071, iter [02200, 05004], lr: 0.036504, loss: 1.2690
2022-07-08 05:49:53 - train: epoch 0071, iter [02300, 05004], lr: 0.036479, loss: 1.2437
2022-07-08 05:50:38 - train: epoch 0071, iter [02400, 05004], lr: 0.036454, loss: 1.3088
2022-07-08 05:51:24 - train: epoch 0071, iter [02500, 05004], lr: 0.036428, loss: 1.5408
2022-07-08 05:52:09 - train: epoch 0071, iter [02600, 05004], lr: 0.036403, loss: 1.2765
2022-07-08 05:52:54 - train: epoch 0071, iter [02700, 05004], lr: 0.036378, loss: 1.4007
2022-07-08 05:53:39 - train: epoch 0071, iter [02800, 05004], lr: 0.036353, loss: 1.5625
2022-07-08 05:54:25 - train: epoch 0071, iter [02900, 05004], lr: 0.036328, loss: 1.4054
2022-07-08 05:55:10 - train: epoch 0071, iter [03000, 05004], lr: 0.036303, loss: 1.4876
2022-07-08 05:55:55 - train: epoch 0071, iter [03100, 05004], lr: 0.036277, loss: 1.4305
2022-07-08 05:56:41 - train: epoch 0071, iter [03200, 05004], lr: 0.036252, loss: 1.2963
2022-07-08 05:57:26 - train: epoch 0071, iter [03300, 05004], lr: 0.036227, loss: 1.2390
2022-07-08 05:58:12 - train: epoch 0071, iter [03400, 05004], lr: 0.036202, loss: 1.2286
2022-07-08 05:58:57 - train: epoch 0071, iter [03500, 05004], lr: 0.036177, loss: 1.5570
2022-07-08 05:59:42 - train: epoch 0071, iter [03600, 05004], lr: 0.036152, loss: 1.5270
2022-07-08 06:00:27 - train: epoch 0071, iter [03700, 05004], lr: 0.036127, loss: 1.2609
2022-07-08 06:01:13 - train: epoch 0071, iter [03800, 05004], lr: 0.036101, loss: 1.3085
2022-07-08 06:01:58 - train: epoch 0071, iter [03900, 05004], lr: 0.036076, loss: 1.4727
2022-07-08 06:02:43 - train: epoch 0071, iter [04000, 05004], lr: 0.036051, loss: 1.6676
2022-07-08 06:03:29 - train: epoch 0071, iter [04100, 05004], lr: 0.036026, loss: 1.3711
2022-07-08 06:04:14 - train: epoch 0071, iter [04200, 05004], lr: 0.036001, loss: 1.5467
2022-07-08 06:04:59 - train: epoch 0071, iter [04300, 05004], lr: 0.035976, loss: 1.4744
2022-07-08 06:05:45 - train: epoch 0071, iter [04400, 05004], lr: 0.035951, loss: 1.4281
2022-07-08 06:06:30 - train: epoch 0071, iter [04500, 05004], lr: 0.035926, loss: 1.3872
2022-07-08 06:07:16 - train: epoch 0071, iter [04600, 05004], lr: 0.035901, loss: 1.4663
2022-07-08 06:08:01 - train: epoch 0071, iter [04700, 05004], lr: 0.035875, loss: 1.3438
2022-07-08 06:08:46 - train: epoch 0071, iter [04800, 05004], lr: 0.035850, loss: 1.2058
2022-07-08 06:09:32 - train: epoch 0071, iter [04900, 05004], lr: 0.035825, loss: 1.1741
2022-07-08 06:10:17 - train: epoch 0071, iter [05000, 05004], lr: 0.035800, loss: 1.3097
2022-07-08 06:10:20 - train: epoch 071, train_loss: 1.3837
2022-07-08 06:11:36 - eval: epoch: 071, acc1: 69.962%, acc5: 89.928%, test_loss: 1.2186, per_image_load_time: 1.460ms, per_image_inference_time: 0.845ms
2022-07-08 06:11:37 - until epoch: 071, best_acc1: 69.962%
2022-07-08 06:11:37 - epoch 072 lr: 0.035799
2022-07-08 06:12:28 - train: epoch 0072, iter [00100, 05004], lr: 0.035774, loss: 1.4929
2022-07-08 06:13:13 - train: epoch 0072, iter [00200, 05004], lr: 0.035749, loss: 1.1278
2022-07-08 06:13:58 - train: epoch 0072, iter [00300, 05004], lr: 0.035724, loss: 1.2374
2022-07-08 06:14:43 - train: epoch 0072, iter [00400, 05004], lr: 0.035699, loss: 1.2476
2022-07-08 06:15:28 - train: epoch 0072, iter [00500, 05004], lr: 0.035674, loss: 1.1733
2022-07-08 06:16:13 - train: epoch 0072, iter [00600, 05004], lr: 0.035649, loss: 1.2484
2022-07-08 06:16:59 - train: epoch 0072, iter [00700, 05004], lr: 0.035624, loss: 1.4114
2022-07-08 06:17:44 - train: epoch 0072, iter [00800, 05004], lr: 0.035599, loss: 1.5444
2022-07-08 06:18:29 - train: epoch 0072, iter [00900, 05004], lr: 0.035574, loss: 1.2291
2022-07-08 06:19:14 - train: epoch 0072, iter [01000, 05004], lr: 0.035549, loss: 1.2756
2022-07-08 06:19:59 - train: epoch 0072, iter [01100, 05004], lr: 0.035524, loss: 1.4698
2022-07-08 06:20:44 - train: epoch 0072, iter [01200, 05004], lr: 0.035499, loss: 1.2330
2022-07-08 06:21:30 - train: epoch 0072, iter [01300, 05004], lr: 0.035474, loss: 1.2998
2022-07-08 06:22:15 - train: epoch 0072, iter [01400, 05004], lr: 0.035448, loss: 1.3857
2022-07-08 06:23:00 - train: epoch 0072, iter [01500, 05004], lr: 0.035423, loss: 1.2987
2022-07-08 06:23:45 - train: epoch 0072, iter [01600, 05004], lr: 0.035398, loss: 1.3991
2022-07-08 06:24:30 - train: epoch 0072, iter [01700, 05004], lr: 0.035373, loss: 1.2135
2022-07-08 06:25:16 - train: epoch 0072, iter [01800, 05004], lr: 0.035348, loss: 1.1835
2022-07-08 06:26:01 - train: epoch 0072, iter [01900, 05004], lr: 0.035323, loss: 1.2549
2022-07-08 06:26:46 - train: epoch 0072, iter [02000, 05004], lr: 0.035298, loss: 1.4709
2022-07-08 06:27:31 - train: epoch 0072, iter [02100, 05004], lr: 0.035273, loss: 1.4415
2022-07-08 06:28:16 - train: epoch 0072, iter [02200, 05004], lr: 0.035248, loss: 1.4460
2022-07-08 06:29:02 - train: epoch 0072, iter [02300, 05004], lr: 0.035223, loss: 1.5092
2022-07-08 06:29:47 - train: epoch 0072, iter [02400, 05004], lr: 0.035198, loss: 1.2375
2022-07-08 06:30:32 - train: epoch 0072, iter [02500, 05004], lr: 0.035173, loss: 1.2313
2022-07-08 06:31:17 - train: epoch 0072, iter [02600, 05004], lr: 0.035148, loss: 1.2727
2022-07-08 06:32:03 - train: epoch 0072, iter [02700, 05004], lr: 0.035123, loss: 1.3803
2022-07-08 06:32:48 - train: epoch 0072, iter [02800, 05004], lr: 0.035098, loss: 1.4032
2022-07-08 06:33:33 - train: epoch 0072, iter [02900, 05004], lr: 0.035074, loss: 1.3147
2022-07-08 06:34:18 - train: epoch 0072, iter [03000, 05004], lr: 0.035049, loss: 1.2875
2022-07-08 06:35:04 - train: epoch 0072, iter [03100, 05004], lr: 0.035024, loss: 1.5367
2022-07-08 06:35:49 - train: epoch 0072, iter [03200, 05004], lr: 0.034999, loss: 1.3435
2022-07-08 06:36:34 - train: epoch 0072, iter [03300, 05004], lr: 0.034974, loss: 1.3543
2022-07-08 06:37:19 - train: epoch 0072, iter [03400, 05004], lr: 0.034949, loss: 1.5581
2022-07-08 06:38:05 - train: epoch 0072, iter [03500, 05004], lr: 0.034924, loss: 1.3850
2022-07-08 06:38:50 - train: epoch 0072, iter [03600, 05004], lr: 0.034899, loss: 1.4004
2022-07-08 06:39:35 - train: epoch 0072, iter [03700, 05004], lr: 0.034874, loss: 1.2930
2022-07-08 06:40:20 - train: epoch 0072, iter [03800, 05004], lr: 0.034849, loss: 1.3812
2022-07-08 06:41:05 - train: epoch 0072, iter [03900, 05004], lr: 0.034824, loss: 1.4632
2022-07-08 06:41:51 - train: epoch 0072, iter [04000, 05004], lr: 0.034799, loss: 1.4651
2022-07-08 06:42:36 - train: epoch 0072, iter [04100, 05004], lr: 0.034774, loss: 1.5876
2022-07-08 06:43:21 - train: epoch 0072, iter [04200, 05004], lr: 0.034749, loss: 1.4411
2022-07-08 06:44:07 - train: epoch 0072, iter [04300, 05004], lr: 0.034724, loss: 1.3619
2022-07-08 06:44:52 - train: epoch 0072, iter [04400, 05004], lr: 0.034699, loss: 1.2377
2022-07-08 06:45:37 - train: epoch 0072, iter [04500, 05004], lr: 0.034675, loss: 1.6053
2022-07-08 06:46:23 - train: epoch 0072, iter [04600, 05004], lr: 0.034650, loss: 1.2901
2022-07-08 06:47:08 - train: epoch 0072, iter [04700, 05004], lr: 0.034625, loss: 1.4422
2022-07-08 06:47:53 - train: epoch 0072, iter [04800, 05004], lr: 0.034600, loss: 1.5867
2022-07-08 06:48:38 - train: epoch 0072, iter [04900, 05004], lr: 0.034575, loss: 1.5123
2022-07-08 06:49:23 - train: epoch 0072, iter [05000, 05004], lr: 0.034550, loss: 1.3736
2022-07-08 06:49:26 - train: epoch 072, train_loss: 1.3719
2022-07-08 06:50:42 - eval: epoch: 072, acc1: 70.028%, acc5: 89.962%, test_loss: 1.2151, per_image_load_time: 2.086ms, per_image_inference_time: 0.838ms
2022-07-08 06:50:44 - until epoch: 072, best_acc1: 70.028%
2022-07-08 06:50:44 - epoch 073 lr: 0.034549
2022-07-08 06:51:35 - train: epoch 0073, iter [00100, 05004], lr: 0.034524, loss: 1.5656
2022-07-08 06:52:20 - train: epoch 0073, iter [00200, 05004], lr: 0.034499, loss: 1.3801
2022-07-08 06:53:06 - train: epoch 0073, iter [00300, 05004], lr: 0.034475, loss: 1.4234
2022-07-08 06:53:51 - train: epoch 0073, iter [00400, 05004], lr: 0.034450, loss: 1.0707
2022-07-08 06:54:37 - train: epoch 0073, iter [00500, 05004], lr: 0.034425, loss: 1.1977
2022-07-08 06:55:22 - train: epoch 0073, iter [00600, 05004], lr: 0.034400, loss: 1.2154
2022-07-08 06:56:08 - train: epoch 0073, iter [00700, 05004], lr: 0.034375, loss: 1.3288
2022-07-08 06:56:53 - train: epoch 0073, iter [00800, 05004], lr: 0.034350, loss: 1.2684
2022-07-08 06:57:39 - train: epoch 0073, iter [00900, 05004], lr: 0.034325, loss: 1.1352
2022-07-08 06:58:24 - train: epoch 0073, iter [01000, 05004], lr: 0.034301, loss: 1.2220
2022-07-08 06:59:10 - train: epoch 0073, iter [01100, 05004], lr: 0.034276, loss: 1.4608
2022-07-08 06:59:55 - train: epoch 0073, iter [01200, 05004], lr: 0.034251, loss: 1.2223
2022-07-08 07:00:41 - train: epoch 0073, iter [01300, 05004], lr: 0.034226, loss: 1.3650
2022-07-08 07:01:26 - train: epoch 0073, iter [01400, 05004], lr: 0.034201, loss: 1.2177
2022-07-08 07:02:12 - train: epoch 0073, iter [01500, 05004], lr: 0.034176, loss: 1.4397
2022-07-08 07:02:57 - train: epoch 0073, iter [01600, 05004], lr: 0.034152, loss: 1.3868
2022-07-08 07:03:43 - train: epoch 0073, iter [01700, 05004], lr: 0.034127, loss: 1.5511
2022-07-08 07:04:28 - train: epoch 0073, iter [01800, 05004], lr: 0.034102, loss: 1.1427
2022-07-08 07:05:14 - train: epoch 0073, iter [01900, 05004], lr: 0.034077, loss: 1.3723
2022-07-08 07:05:59 - train: epoch 0073, iter [02000, 05004], lr: 0.034052, loss: 1.1882
2022-07-08 07:06:45 - train: epoch 0073, iter [02100, 05004], lr: 0.034028, loss: 1.4720
2022-07-08 07:07:30 - train: epoch 0073, iter [02200, 05004], lr: 0.034003, loss: 1.4941
2022-07-08 07:08:16 - train: epoch 0073, iter [02300, 05004], lr: 0.033978, loss: 1.4973
2022-07-08 07:09:01 - train: epoch 0073, iter [02400, 05004], lr: 0.033953, loss: 1.3343
2022-07-08 07:09:47 - train: epoch 0073, iter [02500, 05004], lr: 0.033929, loss: 1.5205
2022-07-08 07:10:32 - train: epoch 0073, iter [02600, 05004], lr: 0.033904, loss: 1.4307
2022-07-08 07:11:18 - train: epoch 0073, iter [02700, 05004], lr: 0.033879, loss: 1.4104
2022-07-08 07:12:03 - train: epoch 0073, iter [02800, 05004], lr: 0.033854, loss: 1.4012
2022-07-08 07:12:48 - train: epoch 0073, iter [02900, 05004], lr: 0.033829, loss: 1.5555
2022-07-08 07:13:34 - train: epoch 0073, iter [03000, 05004], lr: 0.033805, loss: 1.1928
2022-07-08 07:14:19 - train: epoch 0073, iter [03100, 05004], lr: 0.033780, loss: 1.2994
2022-07-08 07:15:04 - train: epoch 0073, iter [03200, 05004], lr: 0.033755, loss: 1.2501
2022-07-08 07:15:50 - train: epoch 0073, iter [03300, 05004], lr: 0.033730, loss: 1.4083
2022-07-08 07:16:35 - train: epoch 0073, iter [03400, 05004], lr: 0.033706, loss: 1.3866
2022-07-08 07:17:21 - train: epoch 0073, iter [03500, 05004], lr: 0.033681, loss: 1.3665
2022-07-08 07:18:06 - train: epoch 0073, iter [03600, 05004], lr: 0.033656, loss: 1.2657
2022-07-08 07:18:51 - train: epoch 0073, iter [03700, 05004], lr: 0.033632, loss: 1.4029
2022-07-08 07:19:37 - train: epoch 0073, iter [03800, 05004], lr: 0.033607, loss: 1.6477
2022-07-08 07:20:22 - train: epoch 0073, iter [03900, 05004], lr: 0.033582, loss: 1.3240
2022-07-08 07:21:08 - train: epoch 0073, iter [04000, 05004], lr: 0.033557, loss: 1.4706
2022-07-08 07:21:53 - train: epoch 0073, iter [04100, 05004], lr: 0.033533, loss: 1.3704
2022-07-08 07:22:38 - train: epoch 0073, iter [04200, 05004], lr: 0.033508, loss: 1.5046
2022-07-08 07:23:24 - train: epoch 0073, iter [04300, 05004], lr: 0.033483, loss: 1.3451
2022-07-08 07:24:09 - train: epoch 0073, iter [04400, 05004], lr: 0.033459, loss: 1.4178
2022-07-08 07:24:55 - train: epoch 0073, iter [04500, 05004], lr: 0.033434, loss: 1.3533
2022-07-08 07:25:40 - train: epoch 0073, iter [04600, 05004], lr: 0.033409, loss: 1.6306
2022-07-08 07:26:25 - train: epoch 0073, iter [04700, 05004], lr: 0.033385, loss: 1.1703
2022-07-08 07:27:11 - train: epoch 0073, iter [04800, 05004], lr: 0.033360, loss: 1.5097
2022-07-08 07:27:56 - train: epoch 0073, iter [04900, 05004], lr: 0.033335, loss: 1.2777
2022-07-08 07:28:42 - train: epoch 0073, iter [05000, 05004], lr: 0.033311, loss: 1.4809
2022-07-08 07:28:44 - train: epoch 073, train_loss: 1.3570
2022-07-08 07:30:01 - eval: epoch: 073, acc1: 70.366%, acc5: 90.014%, test_loss: 1.1985, per_image_load_time: 2.166ms, per_image_inference_time: 0.831ms
2022-07-08 07:30:03 - until epoch: 073, best_acc1: 70.366%
2022-07-08 07:30:03 - epoch 074 lr: 0.033309
2022-07-08 07:30:54 - train: epoch 0074, iter [00100, 05004], lr: 0.033285, loss: 1.1957
2022-07-08 07:31:39 - train: epoch 0074, iter [00200, 05004], lr: 0.033260, loss: 1.3653
2022-07-08 07:32:24 - train: epoch 0074, iter [00300, 05004], lr: 0.033236, loss: 1.4242
2022-07-08 07:33:09 - train: epoch 0074, iter [00400, 05004], lr: 0.033211, loss: 1.5253
2022-07-08 07:33:55 - train: epoch 0074, iter [00500, 05004], lr: 0.033186, loss: 1.3252
2022-07-08 07:34:39 - train: epoch 0074, iter [00600, 05004], lr: 0.033162, loss: 1.3404
2022-07-08 07:35:25 - train: epoch 0074, iter [00700, 05004], lr: 0.033137, loss: 1.2714
2022-07-08 07:36:10 - train: epoch 0074, iter [00800, 05004], lr: 0.033113, loss: 1.4306
2022-07-08 07:36:55 - train: epoch 0074, iter [00900, 05004], lr: 0.033088, loss: 1.2741
2022-07-08 07:37:40 - train: epoch 0074, iter [01000, 05004], lr: 0.033063, loss: 1.4982
2022-07-08 07:38:25 - train: epoch 0074, iter [01100, 05004], lr: 0.033039, loss: 1.4993
2022-07-08 07:39:10 - train: epoch 0074, iter [01200, 05004], lr: 0.033014, loss: 1.3182
2022-07-08 07:39:55 - train: epoch 0074, iter [01300, 05004], lr: 0.032989, loss: 1.4729
2022-07-08 07:40:40 - train: epoch 0074, iter [01400, 05004], lr: 0.032965, loss: 1.2886
2022-07-08 07:41:25 - train: epoch 0074, iter [01500, 05004], lr: 0.032940, loss: 1.4387
2022-07-08 07:42:10 - train: epoch 0074, iter [01600, 05004], lr: 0.032916, loss: 1.1377
2022-07-08 07:42:55 - train: epoch 0074, iter [01700, 05004], lr: 0.032891, loss: 1.4583
2022-07-08 07:43:40 - train: epoch 0074, iter [01800, 05004], lr: 0.032867, loss: 1.7838
2022-07-08 07:44:25 - train: epoch 0074, iter [01900, 05004], lr: 0.032842, loss: 1.4193
2022-07-08 07:45:10 - train: epoch 0074, iter [02000, 05004], lr: 0.032817, loss: 1.0792
2022-07-08 07:45:55 - train: epoch 0074, iter [02100, 05004], lr: 0.032793, loss: 1.3185
2022-07-08 07:46:40 - train: epoch 0074, iter [02200, 05004], lr: 0.032768, loss: 1.6666
2022-07-08 07:47:25 - train: epoch 0074, iter [02300, 05004], lr: 0.032744, loss: 1.3931
2022-07-08 07:48:10 - train: epoch 0074, iter [02400, 05004], lr: 0.032719, loss: 1.3312
2022-07-08 07:48:55 - train: epoch 0074, iter [02500, 05004], lr: 0.032695, loss: 1.2261
2022-07-08 07:49:41 - train: epoch 0074, iter [02600, 05004], lr: 0.032670, loss: 1.1501
2022-07-08 07:50:26 - train: epoch 0074, iter [02700, 05004], lr: 0.032646, loss: 1.3021
2022-07-08 07:51:11 - train: epoch 0074, iter [02800, 05004], lr: 0.032621, loss: 1.6579
2022-07-08 07:51:56 - train: epoch 0074, iter [02900, 05004], lr: 0.032597, loss: 1.3624
2022-07-08 07:52:41 - train: epoch 0074, iter [03000, 05004], lr: 0.032572, loss: 1.4350
2022-07-08 07:53:26 - train: epoch 0074, iter [03100, 05004], lr: 0.032547, loss: 1.3040
