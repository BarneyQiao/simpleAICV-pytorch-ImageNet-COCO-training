2022-10-11 00:00:03 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 0.6887
2022-10-11 00:00:37 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 0.5884
2022-10-11 00:01:11 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 0.7780
2022-10-11 00:01:45 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 0.8549
2022-10-11 00:02:40 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 0.8094
2022-10-11 00:03:14 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 0.7357
2022-10-11 00:03:50 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 0.5806
2022-10-11 00:04:24 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 0.8417
2022-10-11 00:04:59 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 0.7624
2022-10-11 00:05:33 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 0.7033
2022-10-11 00:06:12 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 0.7200
2022-10-11 00:06:48 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 0.6440
2022-10-11 00:07:23 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 0.7017
2022-10-11 00:07:57 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 0.7989
2022-10-11 00:08:36 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 0.8476
2022-10-11 00:09:18 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 0.6689
2022-10-11 00:09:58 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 0.7147
2022-10-11 00:10:55 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 0.7417
2022-10-11 00:11:37 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 0.7223
2022-10-11 00:12:23 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 0.8953
2022-10-11 00:12:57 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 0.8376
2022-10-11 00:13:31 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 0.6202
2022-10-11 00:14:05 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 0.7720
2022-10-11 00:14:40 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 0.6565
2022-10-11 00:15:14 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 0.8126
2022-10-11 00:15:53 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 0.6682
2022-10-11 00:16:26 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 0.6655
2022-10-11 00:17:01 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 0.8793
2022-10-11 00:17:35 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 0.8598
2022-10-11 00:18:21 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 0.6516
2022-10-11 00:19:01 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 0.5400
2022-10-11 00:19:59 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 0.5767
2022-10-11 00:20:42 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 0.7059
2022-10-11 00:21:18 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 0.6996
2022-10-11 00:21:52 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 0.9648
2022-10-11 00:22:32 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 0.6329
2022-10-11 00:23:12 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 0.7914
2022-10-11 00:24:08 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 0.8115
2022-10-11 00:24:55 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 0.9011
2022-10-11 00:25:59 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 0.7335
2022-10-11 00:27:16 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 0.5841
2022-10-11 00:28:19 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 0.7415
2022-10-11 00:29:07 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 0.6907
2022-10-11 00:30:17 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 0.6900
2022-10-11 00:31:23 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 0.7163
2022-10-11 00:32:30 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 0.5014
2022-10-11 00:32:33 - train: epoch 089, train_loss: 0.7332
2022-10-11 00:33:52 - eval: epoch: 089, acc1: 76.426%, acc5: 93.266%, test_loss: 0.9386, per_image_load_time: 1.475ms, per_image_inference_time: 0.611ms
2022-10-11 00:33:52 - until epoch: 089, best_acc1: 76.632%
2022-10-11 00:33:52 - epoch 090 lr: 0.001000
2022-10-11 00:34:32 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 0.6815
2022-10-11 00:35:07 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 0.8242
2022-10-11 00:35:42 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 0.6372
2022-10-11 00:36:16 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 0.7232
2022-10-11 00:36:52 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 0.6772
2022-10-11 00:37:26 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 0.9444
2022-10-11 00:38:01 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 0.7825
2022-10-11 00:38:36 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 0.7961
2022-10-11 00:39:10 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 0.7774
2022-10-11 00:39:47 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 0.7208
2022-10-11 00:40:22 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 0.5442
2022-10-11 00:40:59 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 0.6910
2022-10-11 00:41:36 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 0.6750
2022-10-11 00:42:14 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 0.8202
2022-10-11 00:42:55 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 0.7806
2022-10-11 00:43:34 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 0.8068
2022-10-11 00:44:11 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 0.8481
2022-10-11 00:44:54 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 0.8967
2022-10-11 00:45:48 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 0.6366
2022-10-11 00:46:23 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 0.6498
2022-10-11 00:46:58 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 0.8364
2022-10-11 00:47:47 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 0.7961
2022-10-11 00:48:36 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 0.7974
2022-10-11 00:49:40 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 0.8523
2022-10-11 00:50:15 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 0.8313
2022-10-11 00:51:05 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 0.7601
2022-10-11 00:51:53 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 0.6907
2022-10-11 00:52:32 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 0.6932
2022-10-11 00:53:26 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 0.7001
2022-10-11 00:54:09 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 0.7140
2022-10-11 00:54:59 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 0.6270
2022-10-11 00:55:48 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 0.7487
2022-10-11 00:56:32 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 0.9164
2022-10-11 00:57:06 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 0.7127
2022-10-11 00:57:50 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 0.6721
2022-10-11 00:58:39 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 0.6633
2022-10-11 00:59:23 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 0.6616
2022-10-11 01:00:19 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 0.8216
2022-10-11 01:01:11 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 0.7313
2022-10-11 01:02:26 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 0.7040
2022-10-11 01:03:26 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 1.0110
2022-10-11 01:04:42 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 0.7974
2022-10-11 01:05:51 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 0.7740
2022-10-11 01:06:58 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 0.6955
2022-10-11 01:08:00 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 0.6990
2022-10-11 01:08:51 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 0.7868
2022-10-11 01:09:45 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 0.8041
2022-10-11 01:10:26 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 0.7335
2022-10-11 01:11:28 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 0.6382
2022-10-11 01:12:12 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 0.6758
2022-10-11 01:12:14 - train: epoch 090, train_loss: 0.7284
2022-10-11 01:13:32 - eval: epoch: 090, acc1: 76.478%, acc5: 93.344%, test_loss: 0.9391, per_image_load_time: 2.295ms, per_image_inference_time: 0.595ms
2022-10-11 01:13:33 - until epoch: 090, best_acc1: 76.632%
2022-10-11 01:13:33 - epoch 091 lr: 0.000100
2022-10-11 01:14:13 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 0.6641
2022-10-11 01:14:48 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 0.7196
2022-10-11 01:15:22 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 0.7667
2022-10-11 01:15:57 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 0.6662
2022-10-11 01:16:31 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 0.6812
2022-10-11 01:17:05 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 0.8715
2022-10-11 01:17:41 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 0.7516
2022-10-11 01:18:15 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 0.7122
2022-10-11 01:18:50 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 0.7297
2022-10-11 01:19:24 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 0.8203
2022-10-11 01:20:00 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 0.6205
2022-10-11 01:20:38 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 0.8128
2022-10-11 01:21:17 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 0.5441
2022-10-11 01:21:57 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 0.7242
2022-10-11 01:22:45 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 0.7431
2022-10-11 01:23:31 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 0.6016
2022-10-11 01:24:23 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 0.6945
2022-10-11 01:25:04 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 0.6526
2022-10-11 01:25:52 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 0.7055
2022-10-11 01:26:43 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 0.6441
2022-10-11 01:27:29 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 0.6572
2022-10-11 01:28:15 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 0.7760
2022-10-11 01:28:48 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 0.7362
2022-10-11 01:29:57 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 0.6138
2022-10-11 01:30:46 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 0.7322
2022-10-11 01:31:35 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 0.5167
2022-10-11 01:32:28 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 0.6685
2022-10-11 01:33:45 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 0.7254
2022-10-11 01:35:06 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 0.7277
2022-10-11 01:36:16 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 0.8045
2022-10-11 01:37:32 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 0.6921
2022-10-11 01:38:37 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 0.7891
2022-10-11 01:39:53 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 0.6653
2022-10-11 01:41:17 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 0.6804
2022-10-11 01:42:43 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 0.7288
2022-10-11 01:43:59 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 0.7959
2022-10-11 01:45:03 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 0.6993
2022-10-11 01:45:47 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 0.8572
2022-10-11 01:47:01 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 0.6346
2022-10-11 01:48:26 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 0.5661
2022-10-11 01:49:26 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 0.7198
2022-10-11 01:50:22 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 0.6731
2022-10-11 01:51:18 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 0.8613
2022-10-11 01:52:29 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 0.6237
2022-10-11 01:53:27 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 0.7273
2022-10-11 01:54:17 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 0.7177
2022-10-11 01:55:00 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 0.6709
2022-10-11 01:55:52 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 0.6859
2022-10-11 01:57:10 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 0.7691
2022-10-11 01:58:25 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 0.7731
2022-10-11 01:58:28 - train: epoch 091, train_loss: 0.7062
2022-10-11 01:59:46 - eval: epoch: 091, acc1: 76.836%, acc5: 93.438%, test_loss: 0.9292, per_image_load_time: 1.761ms, per_image_inference_time: 0.607ms
2022-10-11 01:59:46 - until epoch: 091, best_acc1: 76.836%
2022-10-11 01:59:46 - epoch 092 lr: 0.000100
2022-10-11 02:00:26 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 0.7058
2022-10-11 02:01:02 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 0.7699
2022-10-11 02:01:36 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 0.7318
2022-10-11 02:02:11 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 0.5977
2022-10-11 02:02:45 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 0.6753
2022-10-11 02:03:19 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 0.6735
2022-10-11 02:03:58 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 0.7510
2022-10-11 02:04:42 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 0.7266
2022-10-11 02:05:17 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 0.7257
2022-10-11 02:05:52 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 0.7086
2022-10-11 02:06:27 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 0.6490
2022-10-11 02:07:03 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 0.5632
2022-10-11 02:07:37 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 0.5978
2022-10-11 02:08:23 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 0.5912
2022-10-11 02:08:57 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 0.6371
2022-10-11 02:09:33 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 0.6124
2022-10-11 02:10:07 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 0.8928
2022-10-11 02:11:00 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 0.7193
2022-10-11 02:11:43 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 0.6380
2022-10-11 02:12:36 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 0.8444
2022-10-11 02:13:23 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 0.5636
2022-10-11 02:14:03 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 0.7205
2022-10-11 02:14:41 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 0.6451
2022-10-11 02:15:18 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 0.7554
2022-10-11 02:15:53 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 0.6917
2022-10-11 02:16:39 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 0.6612
2022-10-11 02:17:45 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 0.7195
2022-10-11 02:18:33 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 0.6496
2022-10-11 02:19:10 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 0.7849
2022-10-11 02:19:44 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 0.6659
2022-10-11 02:20:20 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 0.7002
2022-10-11 02:21:01 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 0.7098
2022-10-11 02:21:48 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 0.7610
2022-10-11 02:22:52 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 0.8476
2022-10-11 02:23:50 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 0.7572
2022-10-11 02:24:51 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 0.6929
2022-10-11 02:25:55 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 0.6416
2022-10-11 02:26:56 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 0.7104
2022-10-11 02:27:36 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 0.6921
2022-10-11 02:28:21 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 0.7192
2022-10-11 02:29:03 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 0.5054
2022-10-11 02:29:39 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 0.7582
2022-10-11 02:30:15 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 0.6382
2022-10-11 02:31:00 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 0.7285
2022-10-11 02:31:53 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 0.6783
2022-10-11 02:32:31 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 0.7986
2022-10-11 02:33:16 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 0.5832
2022-10-11 02:34:15 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 0.8359
2022-10-11 02:35:10 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 0.6492
2022-10-11 02:35:46 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 0.7068
2022-10-11 02:35:48 - train: epoch 092, train_loss: 0.6990
2022-10-11 02:37:07 - eval: epoch: 092, acc1: 76.820%, acc5: 93.456%, test_loss: 0.9282, per_image_load_time: 1.114ms, per_image_inference_time: 0.606ms
2022-10-11 02:37:07 - until epoch: 092, best_acc1: 76.836%
2022-10-11 02:37:07 - epoch 093 lr: 0.000100
2022-10-11 02:37:47 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 0.7469
2022-10-11 02:38:23 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 0.6913
2022-10-11 02:38:58 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 0.6878
2022-10-11 02:39:32 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 0.7628
2022-10-11 02:40:07 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 0.6180
2022-10-11 02:40:41 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 0.6961
2022-10-11 02:41:16 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 0.6133
2022-10-11 02:41:51 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 0.5852
2022-10-11 02:42:25 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 0.7673
2022-10-11 02:43:01 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.6062
2022-10-11 02:43:36 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 0.5888
2022-10-11 02:44:10 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 0.6123
2022-10-11 02:44:45 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 0.6758
2022-10-11 02:45:20 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 0.8926
2022-10-11 02:45:55 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 0.8661
2022-10-11 02:46:29 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 0.6206
2022-10-11 02:47:04 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 0.6773
2022-10-11 02:47:41 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 0.7781
2022-10-11 02:48:14 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 0.6733
2022-10-11 02:48:49 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 0.6156
2022-10-11 02:49:25 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 0.7303
2022-10-11 02:49:59 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 0.7269
2022-10-11 02:50:34 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 0.7784
2022-10-11 02:51:08 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 0.6575
2022-10-11 02:51:48 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 0.7012
2022-10-11 02:52:32 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 0.7886
2022-10-11 02:53:06 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 0.6610
2022-10-11 02:54:28 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 0.6751
2022-10-11 02:55:27 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 0.7322
2022-10-11 02:56:32 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 0.7993
2022-10-11 02:57:30 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 0.7539
2022-10-11 02:58:47 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 0.6069
2022-10-11 02:59:46 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 0.8087
2022-10-11 03:01:12 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 1.0063
2022-10-11 03:02:05 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 0.7812
2022-10-11 03:02:54 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 0.7647
2022-10-11 03:03:41 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 0.6179
2022-10-11 03:04:26 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 0.6497
2022-10-11 03:05:05 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 0.6296
2022-10-11 03:05:48 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 0.7442
2022-10-11 03:06:32 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 0.7102
2022-10-11 03:07:06 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 0.6552
2022-10-11 03:07:50 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 0.7878
2022-10-11 03:09:00 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 0.5485
2022-10-11 03:09:55 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 0.5148
2022-10-11 03:10:35 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 0.6057
2022-10-11 03:11:29 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 0.8264
2022-10-11 03:12:19 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 0.5814
2022-10-11 03:13:23 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 0.7379
2022-10-11 03:14:16 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 0.6617
2022-10-11 03:14:19 - train: epoch 093, train_loss: 0.6965
2022-10-11 03:15:37 - eval: epoch: 093, acc1: 76.858%, acc5: 93.496%, test_loss: 0.9258, per_image_load_time: 1.477ms, per_image_inference_time: 0.600ms
2022-10-11 03:15:38 - until epoch: 093, best_acc1: 76.858%
2022-10-11 03:15:38 - epoch 094 lr: 0.000100
2022-10-11 03:16:18 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 0.7986
2022-10-11 03:16:54 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 0.6807
2022-10-11 03:17:28 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 0.7383
2022-10-11 03:18:02 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 0.8255
2022-10-11 03:18:37 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 0.5986
2022-10-11 03:19:11 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 0.5485
2022-10-11 03:19:46 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 0.6957
2022-10-11 03:20:21 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 0.6613
2022-10-11 03:20:55 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 0.7049
2022-10-11 03:21:30 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 0.6891
2022-10-11 03:22:05 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 0.9431
2022-10-11 03:22:39 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 0.7110
2022-10-11 03:23:17 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 0.7223
2022-10-11 03:23:59 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 0.5192
2022-10-11 03:24:34 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 0.6215
2022-10-11 03:25:09 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 0.8739
2022-10-11 03:25:49 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 0.6090
2022-10-11 03:26:31 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 0.6581
2022-10-11 03:27:11 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 0.7236
2022-10-11 03:27:50 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 0.6988
2022-10-11 03:28:25 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 0.6340
2022-10-11 03:29:00 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 0.7440
2022-10-11 03:29:34 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 0.6912
2022-10-11 03:30:09 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 0.7601
2022-10-11 03:30:44 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 0.6224
2022-10-11 03:31:19 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 0.7584
2022-10-11 03:31:54 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 0.5271
2022-10-11 03:32:44 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 0.7128
2022-10-11 03:33:18 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 0.8210
2022-10-11 03:33:53 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 0.6666
2022-10-11 03:34:38 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 0.7565
2022-10-11 03:35:16 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 0.6919
2022-10-11 03:36:24 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 0.8032
2022-10-11 03:37:10 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 0.7841
2022-10-11 03:38:13 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 0.8111
2022-10-11 03:39:09 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 0.5991
2022-10-11 03:39:44 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 0.6907
2022-10-11 03:40:28 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 0.6248
2022-10-11 03:41:36 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 0.5649
2022-10-11 03:42:51 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 0.7216
2022-10-11 03:44:11 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 0.8114
2022-10-11 03:45:16 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 0.6575
2022-10-11 03:46:15 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 0.7283
2022-10-11 03:47:27 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 0.8184
2022-10-11 03:48:23 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 0.6796
2022-10-11 03:49:25 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 0.7282
2022-10-11 03:50:24 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 0.8085
2022-10-11 03:51:30 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 0.5112
2022-10-11 03:52:24 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 0.7852
2022-10-11 03:53:28 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 0.5991
2022-10-11 03:53:30 - train: epoch 094, train_loss: 0.6950
2022-10-11 03:54:47 - eval: epoch: 094, acc1: 76.854%, acc5: 93.522%, test_loss: 0.9255, per_image_load_time: 1.362ms, per_image_inference_time: 0.608ms
2022-10-11 03:54:48 - until epoch: 094, best_acc1: 76.858%
2022-10-11 03:54:48 - epoch 095 lr: 0.000100
2022-10-11 03:55:28 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 0.7819
2022-10-11 03:56:03 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 0.7666
2022-10-11 03:56:37 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 0.5614
2022-10-11 03:57:11 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 0.6462
2022-10-11 03:57:47 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 0.6750
2022-10-11 03:58:21 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 0.6377
2022-10-11 03:58:56 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 0.7489
2022-10-11 03:59:30 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 0.6752
2022-10-11 04:00:05 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 0.8285
2022-10-11 04:00:39 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 0.6897
2022-10-11 04:01:14 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 0.6305
2022-10-11 04:01:49 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 0.6620
2022-10-11 04:02:24 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 0.6252
2022-10-11 04:02:59 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 0.5923
2022-10-11 04:03:34 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 0.7006
2022-10-11 04:04:12 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.6122
2022-10-11 04:04:46 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 0.6821
2022-10-11 04:05:21 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 0.7652
2022-10-11 04:05:56 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 0.6011
2022-10-11 04:06:31 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 0.7531
2022-10-11 04:07:05 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 0.6473
2022-10-11 04:07:40 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 0.5506
2022-10-11 04:08:16 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 0.7367
2022-10-11 04:08:50 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 0.7650
2022-10-11 04:09:27 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 0.5941
2022-10-11 04:10:04 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 0.6905
2022-10-11 04:10:50 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 0.7006
2022-10-11 04:11:37 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 0.5750
2022-10-11 04:12:11 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 0.7499
2022-10-11 04:12:56 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 0.7999
2022-10-11 04:14:05 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 0.8710
2022-10-11 04:14:47 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 0.6779
2022-10-11 04:15:29 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 0.7256
2022-10-11 04:16:12 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 0.7894
2022-10-11 04:17:01 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 0.4862
2022-10-11 04:17:54 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 0.6038
2022-10-11 04:18:54 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 0.6282
2022-10-11 04:19:45 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 0.6587
2022-10-11 04:20:30 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 0.5982
2022-10-11 04:21:25 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 0.7831
2022-10-11 04:22:17 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 0.5972
2022-10-11 04:22:56 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 0.7370
2022-10-11 04:23:41 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 0.7612
2022-10-11 04:24:15 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 0.7870
2022-10-11 04:24:54 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 0.6406
2022-10-11 04:25:30 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 0.7246
2022-10-11 04:26:09 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 0.6206
2022-10-11 04:27:05 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 0.6740
2022-10-11 04:27:49 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 0.5568
2022-10-11 04:28:59 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 0.4983
2022-10-11 04:29:01 - train: epoch 095, train_loss: 0.6922
2022-10-11 04:30:18 - eval: epoch: 095, acc1: 76.750%, acc5: 93.498%, test_loss: 0.9270, per_image_load_time: 2.063ms, per_image_inference_time: 0.622ms
2022-10-11 04:30:18 - until epoch: 095, best_acc1: 76.858%
2022-10-11 04:30:18 - epoch 096 lr: 0.000100
2022-10-11 04:30:59 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 0.7155
2022-10-11 04:31:34 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 0.5235
2022-10-11 04:32:09 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 0.6473
2022-10-11 04:32:43 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 0.5969
2022-10-11 04:33:18 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 0.5786
2022-10-11 04:33:53 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 0.6614
2022-10-11 04:34:27 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 0.6408
2022-10-11 04:35:02 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 0.7143
2022-10-11 04:35:37 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 0.6148
2022-10-11 04:36:11 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 0.6177
2022-10-11 04:36:46 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 0.7422
2022-10-11 04:37:21 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 0.7000
2022-10-11 04:38:01 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 0.6914
2022-10-11 04:38:42 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 0.7060
2022-10-11 04:39:16 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 0.8111
2022-10-11 04:39:52 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 0.5485
2022-10-11 04:40:29 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 0.6761
2022-10-11 04:41:04 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 0.6173
2022-10-11 04:41:39 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 0.8377
2022-10-11 04:42:18 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 0.7077
2022-10-11 04:42:59 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 0.6946
2022-10-11 04:43:36 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.5930
2022-10-11 04:44:12 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 0.7258
2022-10-11 04:44:48 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 0.6712
2022-10-11 04:45:22 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 0.6914
2022-10-11 04:46:05 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 0.6170
2022-10-11 04:46:45 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 0.8203
2022-10-11 04:47:23 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 0.8309
2022-10-11 04:48:02 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 0.5907
2022-10-11 04:48:44 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 0.7371
2022-10-11 04:49:29 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 0.6022
2022-10-11 04:50:07 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 0.6666
2022-10-11 04:50:46 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 0.8525
2022-10-11 04:51:20 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 0.6073
2022-10-11 04:51:58 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 0.6064
2022-10-11 04:52:34 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 0.5556
2022-10-11 04:53:14 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 0.8263
2022-10-11 04:53:50 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 0.5659
2022-10-11 04:54:26 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 0.5979
2022-10-11 04:55:03 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 0.6637
2022-10-11 04:55:38 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 0.5245
2022-10-11 04:56:16 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 0.6107
2022-10-11 04:56:50 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.6245
2022-10-11 04:57:26 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 0.6358
2022-10-11 04:58:00 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 0.8000
2022-10-11 04:58:35 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 0.5111
2022-10-11 04:59:10 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 0.7855
2022-10-11 04:59:45 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 0.6584
2022-10-11 05:00:22 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 0.7443
2022-10-11 05:00:54 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 0.6406
2022-10-11 05:00:56 - train: epoch 096, train_loss: 0.6933
2022-10-11 05:02:15 - eval: epoch: 096, acc1: 76.798%, acc5: 93.488%, test_loss: 0.9256, per_image_load_time: 2.125ms, per_image_inference_time: 0.613ms
2022-10-11 05:02:15 - until epoch: 096, best_acc1: 76.858%
2022-10-11 05:02:15 - epoch 097 lr: 0.000100
2022-10-11 05:02:55 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 0.6357
2022-10-11 05:03:31 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 0.7745
2022-10-11 05:04:05 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 0.7382
2022-10-11 05:04:40 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 0.7011
2022-10-11 05:05:15 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 0.6690
2022-10-11 05:05:49 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 0.5644
2022-10-11 05:06:23 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 0.7393
2022-10-11 05:06:59 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.6361
2022-10-11 05:07:32 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 0.6293
2022-10-11 05:08:07 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 0.7726
2022-10-11 05:08:43 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 0.6831
2022-10-11 05:09:20 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 0.6573
2022-10-11 05:09:53 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 0.6157
2022-10-11 05:10:29 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 0.6731
2022-10-11 05:11:03 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 0.5845
2022-10-11 05:11:38 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 0.8391
2022-10-11 05:12:20 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 0.6851
2022-10-11 05:12:58 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 0.7368
2022-10-11 05:13:40 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 0.5794
2022-10-11 05:14:25 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 0.6537
2022-10-11 05:15:05 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 0.6364
2022-10-11 05:15:47 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 0.7114
2022-10-11 05:16:24 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 0.6583
2022-10-11 05:17:01 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 0.6595
2022-10-11 05:17:39 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 0.5650
2022-10-11 05:18:12 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 0.5819
2022-10-11 05:18:50 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 0.6666
2022-10-11 05:19:23 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 0.7395
2022-10-11 05:19:59 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 0.7031
2022-10-11 05:20:33 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 0.6417
2022-10-11 05:21:08 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 0.6716
2022-10-11 05:21:50 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 0.7166
2022-10-11 05:22:28 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 0.8152
2022-10-11 05:23:06 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 0.6732
2022-10-11 05:23:41 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 0.7470
2022-10-11 05:24:17 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 0.7100
2022-10-11 05:24:50 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 0.5607
2022-10-11 05:25:25 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 0.7568
2022-10-11 05:26:04 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 0.6479
2022-10-11 05:26:45 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 0.6980
2022-10-11 05:27:28 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 0.6324
2022-10-11 05:28:24 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 0.7925
2022-10-11 05:29:00 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 0.5230
2022-10-11 05:29:49 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 0.6850
2022-10-11 05:30:37 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 0.6731
2022-10-11 05:31:27 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 0.6620
2022-10-11 05:32:18 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 0.5324
2022-10-11 05:32:56 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 0.7665
2022-10-11 05:33:44 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 0.7760
2022-10-11 05:34:27 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 0.6709
2022-10-11 05:34:29 - train: epoch 097, train_loss: 0.6894
2022-10-11 05:35:48 - eval: epoch: 097, acc1: 76.822%, acc5: 93.482%, test_loss: 0.9255, per_image_load_time: 1.799ms, per_image_inference_time: 0.613ms
2022-10-11 05:35:48 - until epoch: 097, best_acc1: 76.858%
2022-10-11 05:35:48 - epoch 098 lr: 0.000100
2022-10-11 05:36:28 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 0.5665
2022-10-11 05:37:02 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 0.8634
2022-10-11 05:37:37 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 0.6605
2022-10-11 05:38:12 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 0.6186
2022-10-11 05:38:47 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 0.6605
2022-10-11 05:39:22 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 0.5560
2022-10-11 05:39:56 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 0.7037
2022-10-11 05:40:30 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 0.6874
2022-10-11 05:41:05 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 0.7611
2022-10-11 05:41:39 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 0.7047
2022-10-11 05:42:14 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 0.5677
2022-10-11 05:42:49 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 0.6194
2022-10-11 05:43:23 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 0.9093
2022-10-11 05:43:58 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 0.8283
2022-10-11 05:44:33 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 0.6285
2022-10-11 05:45:07 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 0.7713
2022-10-11 05:45:42 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 0.6198
2022-10-11 05:46:17 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 0.5187
2022-10-11 05:46:53 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 0.5883
2022-10-11 05:47:27 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 0.8103
2022-10-11 05:48:02 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 0.8137
2022-10-11 05:48:37 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 0.5807
2022-10-11 05:49:11 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 0.6153
2022-10-11 05:49:45 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 0.6476
2022-10-11 05:50:20 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 0.6262
2022-10-11 05:50:55 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 0.6414
2022-10-11 05:51:30 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 0.6047
2022-10-11 05:52:04 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 0.5563
2022-10-11 05:52:39 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 0.7746
2022-10-11 05:53:16 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 0.7423
2022-10-11 05:53:55 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 0.7347
2022-10-11 05:54:30 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 0.5860
2022-10-11 05:55:07 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 0.5720
2022-10-11 05:55:46 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 0.7024
2022-10-11 05:56:23 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 0.7333
2022-10-11 05:56:59 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 0.7039
2022-10-11 05:57:35 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 0.7266
2022-10-11 05:58:10 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 0.6006
2022-10-11 05:58:46 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 0.6664
2022-10-11 05:59:23 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 0.8940
2022-10-11 05:59:59 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 0.6502
2022-10-11 06:00:37 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 0.6988
2022-10-11 06:01:11 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 0.5633
2022-10-11 06:01:49 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 0.7665
2022-10-11 06:02:22 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 0.7006
2022-10-11 06:02:59 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 0.5958
2022-10-11 06:03:34 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 0.7182
2022-10-11 06:04:12 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 0.4581
2022-10-11 06:04:48 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 0.6587
2022-10-11 06:05:24 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 0.7284
2022-10-11 06:05:27 - train: epoch 098, train_loss: 0.6903
2022-10-11 06:06:45 - eval: epoch: 098, acc1: 76.728%, acc5: 93.500%, test_loss: 0.9252, per_image_load_time: 2.314ms, per_image_inference_time: 0.621ms
2022-10-11 06:06:46 - until epoch: 098, best_acc1: 76.858%
2022-10-11 06:06:46 - epoch 099 lr: 0.000100
2022-10-11 06:07:25 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 0.8095
2022-10-11 06:08:01 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 0.6395
2022-10-11 06:08:36 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 0.5432
2022-10-11 06:09:10 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 0.6750
2022-10-11 06:09:45 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 0.6598
2022-10-11 06:10:19 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 0.7691
2022-10-11 06:10:54 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 0.7823
2022-10-11 06:11:29 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 0.7487
2022-10-11 06:12:03 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 0.8225
2022-10-11 06:12:38 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 0.6430
2022-10-11 06:13:13 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 0.6981
2022-10-11 06:13:51 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 0.6734
2022-10-11 06:14:28 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 0.7258
2022-10-11 06:15:03 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 0.5455
2022-10-11 06:15:38 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 0.5932
2022-10-11 06:16:13 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 0.7197
2022-10-11 06:16:47 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 0.5752
2022-10-11 06:17:22 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 0.8233
2022-10-11 06:17:57 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 0.7889
2022-10-11 06:18:31 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 0.7440
2022-10-11 06:19:06 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 0.6723
2022-10-11 06:19:42 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 0.6292
2022-10-11 06:20:16 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 0.6429
2022-10-11 06:20:52 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 0.6835
2022-10-11 06:21:28 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 0.6443
2022-10-11 06:22:02 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 0.6897
2022-10-11 06:22:37 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 0.6081
2022-10-11 06:23:11 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 0.8543
2022-10-11 06:23:49 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 0.6823
2022-10-11 06:24:35 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 0.8275
2022-10-11 06:25:24 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 0.6397
2022-10-11 06:26:12 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 0.8211
2022-10-11 06:26:58 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 0.5583
2022-10-11 06:27:46 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 0.7231
2022-10-11 06:28:19 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 0.6986
2022-10-11 06:29:04 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 0.5964
2022-10-11 06:29:53 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 0.6636
2022-10-11 06:30:35 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 0.6628
2022-10-11 06:31:19 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 0.6575
2022-10-11 06:31:58 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 0.6061
2022-10-11 06:32:41 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 0.3894
2022-10-11 06:33:17 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 0.7147
2022-10-11 06:33:51 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 0.6750
2022-10-11 06:34:34 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 0.7863
2022-10-11 06:35:39 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 0.8471
2022-10-11 06:36:17 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 0.7992
2022-10-11 06:36:55 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 0.5757
2022-10-11 06:37:30 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 0.8304
2022-10-11 06:38:36 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 0.7359
2022-10-11 06:39:27 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 0.6852
2022-10-11 06:39:29 - train: epoch 099, train_loss: 0.6903
2022-10-11 06:40:48 - eval: epoch: 099, acc1: 76.740%, acc5: 93.480%, test_loss: 0.9256, per_image_load_time: 2.105ms, per_image_inference_time: 0.612ms
2022-10-11 06:40:48 - until epoch: 099, best_acc1: 76.858%
2022-10-11 06:40:48 - epoch 100 lr: 0.000100
2022-10-11 06:41:28 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 0.7199
2022-10-11 06:42:03 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 0.6164
2022-10-11 06:42:38 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 0.8401
2022-10-11 06:43:13 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 0.6943
2022-10-11 06:43:47 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 0.6875
2022-10-11 06:44:22 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 0.7609
2022-10-11 06:44:57 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 0.6731
2022-10-11 06:45:32 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 0.6785
2022-10-11 06:46:06 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 0.6622
2022-10-11 06:46:41 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 0.7150
2022-10-11 06:47:15 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 0.5365
2022-10-11 06:47:49 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 0.5900
2022-10-11 06:48:24 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 0.6157
2022-10-11 06:48:59 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 0.6339
2022-10-11 06:49:35 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 0.6619
2022-10-11 06:50:09 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 0.5423
2022-10-11 06:50:46 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 0.5810
2022-10-11 06:51:24 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 0.6121
2022-10-11 06:52:02 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 0.7522
2022-10-11 06:52:43 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 0.5909
2022-10-11 06:53:19 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 0.7115
2022-10-11 06:53:54 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 0.7630
2022-10-11 06:54:33 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 0.6567
2022-10-11 06:55:09 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 0.6705
2022-10-11 06:55:48 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 0.7963
2022-10-11 06:56:25 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 0.6092
2022-10-11 06:57:10 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 0.7411
2022-10-11 06:57:49 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 0.5408
2022-10-11 06:58:31 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 0.6212
2022-10-11 06:59:13 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 0.6394
2022-10-11 06:59:52 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 0.5714
2022-10-11 07:00:33 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 0.8683
2022-10-11 07:01:24 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 0.6477
2022-10-11 07:02:12 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 0.7956
2022-10-11 07:02:57 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 0.4838
2022-10-11 07:03:36 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 0.6171
2022-10-11 07:04:23 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 0.6278
2022-10-11 07:05:07 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 0.6559
2022-10-11 07:05:57 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 0.7427
2022-10-11 07:06:35 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 0.6227
2022-10-11 07:07:31 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 0.7377
2022-10-11 07:08:19 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 0.8133
2022-10-11 07:09:18 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 0.4981
2022-10-11 07:10:13 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 0.8081
2022-10-11 07:11:21 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 0.4512
2022-10-11 07:12:11 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 0.5524
2022-10-11 07:12:50 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 0.8418
2022-10-11 07:13:26 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 0.4605
2022-10-11 07:14:06 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 0.6520
2022-10-11 07:14:49 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 0.7273
2022-10-11 07:14:51 - train: epoch 100, train_loss: 0.6863
2022-10-11 07:16:09 - eval: epoch: 100, acc1: 76.728%, acc5: 93.408%, test_loss: 0.9266, per_image_load_time: 1.393ms, per_image_inference_time: 0.649ms
2022-10-11 07:16:09 - until epoch: 100, best_acc1: 76.858%
2022-10-11 07:16:09 - train done. model: resnet50, train time: 57.277 hours, best_acc1: 76.858%
