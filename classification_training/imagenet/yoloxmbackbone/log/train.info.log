2022-03-16 23:24:56 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 1.2533
2022-03-16 23:25:30 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 1.1712
2022-03-16 23:26:04 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 1.1358
2022-03-16 23:26:37 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 1.0060
2022-03-16 23:27:11 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 1.2166
2022-03-16 23:27:44 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 1.2592
2022-03-16 23:28:17 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 1.3546
2022-03-16 23:28:51 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 1.1012
2022-03-16 23:29:24 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 1.1605
2022-03-16 23:29:58 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.9612
2022-03-16 23:30:31 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 1.1437
2022-03-16 23:31:04 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 1.0386
2022-03-16 23:31:38 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 1.0638
2022-03-16 23:32:12 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 1.0827
2022-03-16 23:32:45 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 1.3402
2022-03-16 23:33:20 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 1.2563
2022-03-16 23:33:53 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 1.1281
2022-03-16 23:34:27 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 1.2289
2022-03-16 23:35:01 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 1.2927
2022-03-16 23:35:34 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 1.2061
2022-03-16 23:36:08 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 1.3524
2022-03-16 23:36:41 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 0.9955
2022-03-16 23:37:15 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 1.1114
2022-03-16 23:37:49 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 1.0615
2022-03-16 23:38:22 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 1.2324
2022-03-16 23:38:56 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 1.1338
2022-03-16 23:39:30 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 1.1132
2022-03-16 23:40:03 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 1.0912
2022-03-16 23:40:37 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 1.2077
2022-03-16 23:41:11 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 1.1605
2022-03-16 23:41:44 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.9090
2022-03-16 23:42:18 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 1.1290
2022-03-16 23:42:51 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 1.0746
2022-03-16 23:43:24 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 1.1306
2022-03-16 23:43:58 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 1.2752
2022-03-16 23:44:32 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 1.3026
2022-03-16 23:45:05 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 1.3042
2022-03-16 23:45:37 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 1.1158
2022-03-16 23:45:38 - train: epoch 096, train_loss: 1.1851
2022-03-16 23:46:53 - eval: epoch: 096, acc1: 72.288%, acc5: 90.836%, test_loss: 1.0960, per_image_load_time: 2.509ms, per_image_inference_time: 0.341ms
2022-03-16 23:46:53 - until epoch: 096, best_acc1: 72.316%
2022-03-17 21:39:01 - epoch 097 lr: 0.00010000000000000003
2022-03-17 21:39:39 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 1.0791
2022-03-17 21:40:11 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 1.2452
2022-03-17 21:40:43 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 1.1918
2022-03-17 21:41:15 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 1.2875
2022-03-17 21:41:48 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 1.2751
2022-03-17 21:42:20 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 1.1487
2022-03-17 21:42:52 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 1.1212
2022-03-17 21:43:23 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.9956
2022-03-17 21:43:56 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 1.3259
2022-03-17 21:44:28 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 1.3229
2022-03-17 21:45:00 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 1.0581
2022-03-17 21:45:32 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 1.2375
2022-03-17 21:46:04 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 1.0259
2022-03-17 21:46:37 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 1.1844
2022-03-17 21:47:09 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 1.1627
2022-03-17 21:47:41 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 1.1354
2022-03-17 21:48:14 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 1.1343
2022-03-17 21:48:45 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 1.2535
2022-03-17 21:49:18 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 1.0529
2022-03-17 21:49:50 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 0.9729
2022-03-17 21:50:22 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 0.9959
2022-03-17 21:50:54 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 0.9291
2022-03-17 21:51:26 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 1.1066
2022-03-17 21:51:58 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 1.2776
2022-03-17 21:52:31 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 1.3160
2022-03-17 21:53:02 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 1.1538
2022-03-17 21:53:35 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 1.1257
2022-03-17 21:54:07 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 1.1811
2022-03-17 21:54:39 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 1.1167
2022-03-17 21:55:11 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 1.2656
2022-03-17 21:55:43 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 1.1108
2022-03-17 21:56:16 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 1.3202
2022-03-17 21:56:48 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 1.2822
2022-03-17 21:57:19 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 1.2781
2022-03-17 21:57:52 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 1.1413
2022-03-17 21:58:24 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 1.1315
2022-03-17 21:58:56 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 0.9671
2022-03-17 21:59:28 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 1.1430
2022-03-17 21:59:59 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 1.1247
2022-03-17 22:00:31 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 1.2997
2022-03-17 22:01:03 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 1.1834
2022-03-17 22:01:35 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 1.1561
2022-03-17 22:02:08 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 1.1185
2022-03-17 22:02:39 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 1.1509
2022-03-17 22:03:11 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 1.2923
2022-03-17 22:03:44 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 1.2163
2022-03-17 22:04:16 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 1.2451
2022-03-17 22:04:48 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 1.3167
2022-03-17 22:05:21 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 1.3678
2022-03-17 22:05:51 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 0.9318
2022-03-17 22:05:52 - train: epoch 097, train_loss: 1.1852
2022-03-17 22:07:05 - eval: epoch: 097, acc1: 72.362%, acc5: 90.856%, test_loss: 1.0950, per_image_load_time: 1.621ms, per_image_inference_time: 0.330ms
2022-03-17 22:07:05 - until epoch: 097, best_acc1: 72.362%
2022-03-17 22:07:05 - epoch 098 lr: 0.00010000000000000003
2022-03-17 22:07:42 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 1.2456
2022-03-17 22:08:14 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 1.4063
2022-03-17 22:08:47 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 1.2232
2022-03-17 22:09:18 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 1.0971
2022-03-17 22:09:51 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 1.1377
2022-03-17 22:10:23 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 1.0924
2022-03-17 22:10:56 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 1.2130
2022-03-17 22:11:28 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 1.1653
2022-03-17 22:12:00 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 1.3229
2022-03-17 22:12:33 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 1.2541
2022-03-17 22:13:04 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 1.1579
2022-03-17 22:13:37 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 1.1694
2022-03-17 22:14:09 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 1.3198
2022-03-17 22:14:41 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 1.2701
2022-03-17 22:15:13 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 1.2128
2022-03-17 22:15:46 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 1.0782
2022-03-17 22:16:17 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 1.2158
2022-03-17 22:16:50 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 1.2245
2022-03-17 22:17:22 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 1.0847
2022-03-17 22:17:55 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 1.3756
2022-03-17 22:18:27 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 1.1102
2022-03-17 22:18:59 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 1.1529
2022-03-17 22:19:31 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 1.1398
2022-03-17 22:20:03 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 1.2557
2022-03-17 22:20:35 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 1.0988
2022-03-17 22:21:07 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 1.0687
2022-03-17 22:21:39 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 1.2693
2022-03-17 22:22:11 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 1.0799
2022-03-17 22:22:43 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 1.1469
2022-03-17 22:23:16 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 1.0462
2022-03-17 22:23:48 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 1.2802
2022-03-17 22:24:21 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 1.0307
2022-03-17 22:24:52 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 0.9368
2022-03-17 22:25:25 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 1.1617
2022-03-17 22:25:57 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 1.3456
2022-03-17 22:26:29 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 1.4364
2022-03-17 22:27:01 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 1.1764
2022-03-17 22:27:33 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 1.0775
2022-03-17 22:28:06 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 1.1193
2022-03-17 22:28:38 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 1.1341
2022-03-17 22:29:10 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 1.3079
2022-03-17 22:29:42 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 1.1057
2022-03-17 22:30:15 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 0.9653
2022-03-17 22:30:48 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 1.3137
2022-03-17 22:31:20 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 1.2882
2022-03-17 22:31:51 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 1.1493
2022-03-17 22:32:24 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 1.2160
2022-03-17 22:32:56 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 0.9632
2022-03-17 22:33:28 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 1.1407
2022-03-17 22:33:59 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 1.1878
2022-03-17 22:34:00 - train: epoch 098, train_loss: 1.1843
2022-03-17 22:35:13 - eval: epoch: 098, acc1: 72.356%, acc5: 90.804%, test_loss: 1.0945, per_image_load_time: 2.350ms, per_image_inference_time: 0.342ms
2022-03-17 22:35:13 - until epoch: 098, best_acc1: 72.362%
2022-03-17 22:35:13 - epoch 099 lr: 0.00010000000000000003
2022-03-17 22:35:51 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 1.2764
2022-03-17 22:36:23 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 1.0740
2022-03-17 22:36:55 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 1.0701
2022-03-17 22:37:28 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 1.0863
2022-03-17 22:38:00 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 1.1801
2022-03-17 22:38:32 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 1.2510
2022-03-17 22:39:05 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 1.3085
2022-03-17 22:39:37 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 1.2084
2022-03-17 22:40:10 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 1.0461
2022-03-17 22:40:42 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 1.0978
2022-03-17 22:41:15 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 1.2819
2022-03-17 22:41:47 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 0.9712
2022-03-17 22:42:20 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 1.0823
2022-03-17 22:42:52 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 1.1852
2022-03-17 22:43:25 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 1.2605
2022-03-17 22:43:57 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 1.2356
2022-03-17 22:44:29 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 1.0024
2022-03-17 22:45:01 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 1.1290
2022-03-17 22:45:34 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 1.0655
2022-03-17 22:46:07 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 1.1697
2022-03-17 22:46:39 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 1.2429
2022-03-17 22:47:12 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 1.2367
2022-03-17 22:47:44 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 1.1783
2022-03-17 22:48:16 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 1.3017
2022-03-17 22:48:49 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 1.0845
2022-03-17 22:49:22 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 1.1605
2022-03-17 22:49:54 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 1.2681
2022-03-17 22:50:27 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 1.2484
2022-03-17 22:50:59 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 1.1420
2022-03-17 22:51:32 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 1.1461
2022-03-17 22:52:05 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 1.1925
2022-03-17 22:52:37 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 1.2932
2022-03-17 22:53:09 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 1.2668
2022-03-17 22:53:41 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 1.1036
2022-03-17 22:54:15 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 1.2314
2022-03-17 22:54:47 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 1.0614
2022-03-17 22:55:19 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 1.0014
2022-03-17 22:55:51 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 1.0829
2022-03-17 22:56:24 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 1.2077
2022-03-17 22:56:57 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 1.2020
2022-03-17 22:57:28 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 1.0248
2022-03-17 22:58:01 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 1.3502
2022-03-17 22:58:33 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 1.2230
2022-03-17 22:59:05 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 1.1313
2022-03-17 22:59:37 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 1.2148
2022-03-17 23:00:10 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 1.3117
2022-03-17 23:00:42 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 1.1819
2022-03-17 23:01:14 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 1.2961
2022-03-17 23:01:46 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 1.1698
2022-03-17 23:02:17 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 1.2335
2022-03-17 23:02:18 - train: epoch 099, train_loss: 1.1838
2022-03-17 23:03:31 - eval: epoch: 099, acc1: 72.342%, acc5: 90.762%, test_loss: 1.0949, per_image_load_time: 2.048ms, per_image_inference_time: 0.334ms
2022-03-17 23:03:31 - until epoch: 099, best_acc1: 72.362%
2022-03-17 23:03:31 - epoch 100 lr: 0.00010000000000000003
2022-03-17 23:04:08 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 1.3909
2022-03-17 23:04:41 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 1.3701
2022-03-17 23:05:14 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 1.2393
2022-03-17 23:05:45 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 1.0466
2022-03-17 23:06:18 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 1.2829
2022-03-17 23:06:49 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 1.3199
2022-03-17 23:07:22 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 1.2646
2022-03-17 23:07:54 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 1.1215
2022-03-17 23:08:27 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 0.9267
2022-03-17 23:08:59 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 1.2027
2022-03-17 23:09:31 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 1.1123
2022-03-17 23:10:03 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 1.2128
2022-03-17 23:10:36 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 1.1745
2022-03-17 23:11:08 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 1.4208
2022-03-17 23:11:41 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 1.2330
2022-03-17 23:12:12 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 0.9315
2022-03-17 23:12:45 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 1.1089
2022-03-17 23:13:17 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 1.1936
2022-03-17 23:13:49 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 1.2102
2022-03-17 23:14:21 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 1.2238
2022-03-17 23:14:53 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 1.1249
2022-03-17 23:15:26 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 1.3148
2022-03-17 23:15:59 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 1.2447
2022-03-17 23:16:30 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 1.1538
2022-03-17 23:17:03 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 1.3399
2022-03-17 23:17:37 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 1.1570
2022-03-17 23:18:11 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 1.0704
2022-03-17 23:18:45 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 1.1706
2022-03-17 23:19:19 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 1.2099
2022-03-17 23:19:53 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 1.0293
2022-03-17 23:20:28 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 1.1796
2022-03-17 23:21:01 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 1.2957
2022-03-17 23:21:35 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 1.1429
2022-03-17 23:22:08 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 1.2700
2022-03-17 23:22:43 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 1.0206
2022-03-17 23:23:17 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 1.0957
2022-03-17 23:23:51 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 1.0110
2022-03-17 23:24:25 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 1.2208
2022-03-17 23:24:59 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 1.2276
2022-03-17 23:25:33 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 1.0877
2022-03-17 23:26:07 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 1.2264
2022-03-17 23:26:41 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 1.1258
2022-03-17 23:27:15 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 1.3179
2022-03-17 23:27:49 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 1.0276
2022-03-17 23:28:24 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 0.9988
2022-03-17 23:28:58 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 1.1064
2022-03-17 23:29:32 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 1.3773
2022-03-17 23:30:05 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 1.0462
2022-03-17 23:30:40 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 1.1029
2022-03-17 23:31:11 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 1.3804
2022-03-17 23:31:12 - train: epoch 100, train_loss: 1.1831
2022-03-17 23:32:27 - eval: epoch: 100, acc1: 72.282%, acc5: 90.772%, test_loss: 1.0947, per_image_load_time: 1.453ms, per_image_inference_time: 0.351ms
2022-03-17 23:32:27 - until epoch: 100, best_acc1: 72.362%
2022-03-17 23:32:27 - train done. model: yoloxmbackbone, train time: 50.254 hours, best_acc1: 72.362%
