2022-07-16 00:05:30 - train: epoch 0050, iter [03300, 05004], lr: 0.010000, loss: 2.2648
2022-07-16 00:06:03 - train: epoch 0050, iter [03400, 05004], lr: 0.010000, loss: 2.3959
2022-07-16 00:06:36 - train: epoch 0050, iter [03500, 05004], lr: 0.010000, loss: 2.3871
2022-07-16 00:07:10 - train: epoch 0050, iter [03600, 05004], lr: 0.010000, loss: 2.4314
2022-07-16 00:07:43 - train: epoch 0050, iter [03700, 05004], lr: 0.010000, loss: 2.6438
2022-07-16 00:08:16 - train: epoch 0050, iter [03800, 05004], lr: 0.010000, loss: 2.2197
2022-07-16 00:08:49 - train: epoch 0050, iter [03900, 05004], lr: 0.010000, loss: 2.3222
2022-07-16 00:09:22 - train: epoch 0050, iter [04000, 05004], lr: 0.010000, loss: 2.5519
2022-07-16 00:09:56 - train: epoch 0050, iter [04100, 05004], lr: 0.010000, loss: 2.2887
2022-07-16 00:10:29 - train: epoch 0050, iter [04200, 05004], lr: 0.010000, loss: 2.5743
2022-07-16 00:11:02 - train: epoch 0050, iter [04300, 05004], lr: 0.010000, loss: 2.3537
2022-07-16 00:11:35 - train: epoch 0050, iter [04400, 05004], lr: 0.010000, loss: 2.3744
2022-07-16 00:12:10 - train: epoch 0050, iter [04500, 05004], lr: 0.010000, loss: 2.3679
2022-07-16 00:12:43 - train: epoch 0050, iter [04600, 05004], lr: 0.010000, loss: 2.4745
2022-07-16 00:13:17 - train: epoch 0050, iter [04700, 05004], lr: 0.010000, loss: 2.4487
2022-07-16 00:13:49 - train: epoch 0050, iter [04800, 05004], lr: 0.010000, loss: 2.2205
2022-07-16 00:14:23 - train: epoch 0050, iter [04900, 05004], lr: 0.010000, loss: 2.0907
2022-07-16 00:14:55 - train: epoch 0050, iter [05000, 05004], lr: 0.010000, loss: 2.2824
2022-07-16 00:14:55 - train: epoch 050, train_loss: 2.4052
2022-07-16 00:16:09 - eval: epoch: 050, acc1: 53.214%, acc5: 76.584%, test_loss: 2.1036, per_image_load_time: 2.069ms, per_image_inference_time: 0.135ms
2022-07-16 00:16:09 - until epoch: 050, best_acc1: 54.094%
2022-07-16 00:16:09 - epoch 051 lr: 0.010000
2022-07-16 00:16:48 - train: epoch 0051, iter [00100, 05004], lr: 0.010000, loss: 2.6361
2022-07-16 00:17:21 - train: epoch 0051, iter [00200, 05004], lr: 0.010000, loss: 2.7340
2022-07-16 00:17:54 - train: epoch 0051, iter [00300, 05004], lr: 0.010000, loss: 2.4404
2022-07-16 00:18:27 - train: epoch 0051, iter [00400, 05004], lr: 0.010000, loss: 2.1482
2022-07-16 00:19:01 - train: epoch 0051, iter [00500, 05004], lr: 0.010000, loss: 2.5180
2022-07-16 00:19:33 - train: epoch 0051, iter [00600, 05004], lr: 0.010000, loss: 2.4046
2022-07-16 00:20:06 - train: epoch 0051, iter [00700, 05004], lr: 0.010000, loss: 2.2962
2022-07-16 00:20:38 - train: epoch 0051, iter [00800, 05004], lr: 0.010000, loss: 2.7070
2022-07-16 00:21:12 - train: epoch 0051, iter [00900, 05004], lr: 0.010000, loss: 2.2685
2022-07-16 00:21:43 - train: epoch 0051, iter [01000, 05004], lr: 0.010000, loss: 2.9850
2022-07-16 00:22:16 - train: epoch 0051, iter [01100, 05004], lr: 0.010000, loss: 2.4979
2022-07-16 00:22:50 - train: epoch 0051, iter [01200, 05004], lr: 0.010000, loss: 2.1821
2022-07-16 00:23:22 - train: epoch 0051, iter [01300, 05004], lr: 0.010000, loss: 2.1568
2022-07-16 00:23:56 - train: epoch 0051, iter [01400, 05004], lr: 0.010000, loss: 2.2551
2022-07-16 00:24:28 - train: epoch 0051, iter [01500, 05004], lr: 0.010000, loss: 2.2971
2022-07-16 00:25:02 - train: epoch 0051, iter [01600, 05004], lr: 0.010000, loss: 2.2222
2022-07-16 00:25:34 - train: epoch 0051, iter [01700, 05004], lr: 0.010000, loss: 2.3285
2022-07-16 00:26:08 - train: epoch 0051, iter [01800, 05004], lr: 0.010000, loss: 2.2586
2022-07-16 00:26:39 - train: epoch 0051, iter [01900, 05004], lr: 0.010000, loss: 2.2239
2022-07-16 00:27:13 - train: epoch 0051, iter [02000, 05004], lr: 0.010000, loss: 2.5018
2022-07-16 00:27:45 - train: epoch 0051, iter [02100, 05004], lr: 0.010000, loss: 2.3417
2022-07-16 00:28:19 - train: epoch 0051, iter [02200, 05004], lr: 0.010000, loss: 2.3856
2022-07-16 00:28:51 - train: epoch 0051, iter [02300, 05004], lr: 0.010000, loss: 2.7182
2022-07-16 00:29:25 - train: epoch 0051, iter [02400, 05004], lr: 0.010000, loss: 2.4643
2022-07-16 00:29:57 - train: epoch 0051, iter [02500, 05004], lr: 0.010000, loss: 2.2325
2022-07-16 00:30:31 - train: epoch 0051, iter [02600, 05004], lr: 0.010000, loss: 2.2660
2022-07-16 00:31:03 - train: epoch 0051, iter [02700, 05004], lr: 0.010000, loss: 2.4137
2022-07-16 00:31:37 - train: epoch 0051, iter [02800, 05004], lr: 0.010000, loss: 2.3480
2022-07-16 00:32:10 - train: epoch 0051, iter [02900, 05004], lr: 0.010000, loss: 2.3949
2022-07-16 00:32:44 - train: epoch 0051, iter [03000, 05004], lr: 0.010000, loss: 2.5092
2022-07-16 00:33:16 - train: epoch 0051, iter [03100, 05004], lr: 0.010000, loss: 2.3235
2022-07-16 00:33:49 - train: epoch 0051, iter [03200, 05004], lr: 0.010000, loss: 2.3556
2022-07-16 00:34:22 - train: epoch 0051, iter [03300, 05004], lr: 0.010000, loss: 2.5627
2022-07-16 00:34:55 - train: epoch 0051, iter [03400, 05004], lr: 0.010000, loss: 2.4301
2022-07-16 00:35:29 - train: epoch 0051, iter [03500, 05004], lr: 0.010000, loss: 2.3006
2022-07-16 00:36:01 - train: epoch 0051, iter [03600, 05004], lr: 0.010000, loss: 2.3672
2022-07-16 00:36:35 - train: epoch 0051, iter [03700, 05004], lr: 0.010000, loss: 2.4865
2022-07-16 00:37:08 - train: epoch 0051, iter [03800, 05004], lr: 0.010000, loss: 2.4308
2022-07-16 00:37:41 - train: epoch 0051, iter [03900, 05004], lr: 0.010000, loss: 2.4977
2022-07-16 00:38:14 - train: epoch 0051, iter [04000, 05004], lr: 0.010000, loss: 2.4200
2022-07-16 00:38:48 - train: epoch 0051, iter [04100, 05004], lr: 0.010000, loss: 2.3698
2022-07-16 00:39:21 - train: epoch 0051, iter [04200, 05004], lr: 0.010000, loss: 2.5915
2022-07-16 00:39:53 - train: epoch 0051, iter [04300, 05004], lr: 0.010000, loss: 2.3955
2022-07-16 00:40:26 - train: epoch 0051, iter [04400, 05004], lr: 0.010000, loss: 2.4515
2022-07-16 00:40:59 - train: epoch 0051, iter [04500, 05004], lr: 0.010000, loss: 2.0149
2022-07-16 00:41:34 - train: epoch 0051, iter [04600, 05004], lr: 0.010000, loss: 2.5319
2022-07-16 00:42:08 - train: epoch 0051, iter [04700, 05004], lr: 0.010000, loss: 2.5260
2022-07-16 00:42:40 - train: epoch 0051, iter [04800, 05004], lr: 0.010000, loss: 2.4655
2022-07-16 00:43:14 - train: epoch 0051, iter [04900, 05004], lr: 0.010000, loss: 2.4191
2022-07-16 00:43:45 - train: epoch 0051, iter [05000, 05004], lr: 0.010000, loss: 2.3068
2022-07-16 00:43:45 - train: epoch 051, train_loss: 2.4047
2022-07-16 00:44:59 - eval: epoch: 051, acc1: 53.212%, acc5: 76.788%, test_loss: 2.0929, per_image_load_time: 2.238ms, per_image_inference_time: 0.123ms
2022-07-16 00:44:59 - until epoch: 051, best_acc1: 54.094%
2022-07-16 00:44:59 - epoch 052 lr: 0.010000
2022-07-16 00:45:37 - train: epoch 0052, iter [00100, 05004], lr: 0.010000, loss: 2.3923
2022-07-16 00:46:11 - train: epoch 0052, iter [00200, 05004], lr: 0.010000, loss: 2.4422
2022-07-16 00:46:44 - train: epoch 0052, iter [00300, 05004], lr: 0.010000, loss: 2.4092
2022-07-16 00:47:16 - train: epoch 0052, iter [00400, 05004], lr: 0.010000, loss: 2.4816
2022-07-16 00:47:50 - train: epoch 0052, iter [00500, 05004], lr: 0.010000, loss: 2.3481
2022-07-16 00:48:23 - train: epoch 0052, iter [00600, 05004], lr: 0.010000, loss: 2.2414
2022-07-16 00:48:56 - train: epoch 0052, iter [00700, 05004], lr: 0.010000, loss: 2.4298
2022-07-16 00:49:29 - train: epoch 0052, iter [00800, 05004], lr: 0.010000, loss: 2.3780
2022-07-16 00:50:01 - train: epoch 0052, iter [00900, 05004], lr: 0.010000, loss: 2.5535
2022-07-16 00:50:35 - train: epoch 0052, iter [01000, 05004], lr: 0.010000, loss: 2.5437
2022-07-16 00:51:07 - train: epoch 0052, iter [01100, 05004], lr: 0.010000, loss: 2.4687
2022-07-16 00:51:41 - train: epoch 0052, iter [01200, 05004], lr: 0.010000, loss: 2.2357
2022-07-16 00:52:13 - train: epoch 0052, iter [01300, 05004], lr: 0.010000, loss: 2.2669
2022-07-16 00:52:47 - train: epoch 0052, iter [01400, 05004], lr: 0.010000, loss: 2.6036
2022-07-16 00:53:20 - train: epoch 0052, iter [01500, 05004], lr: 0.010000, loss: 2.3046
2022-07-16 00:53:53 - train: epoch 0052, iter [01600, 05004], lr: 0.010000, loss: 2.1865
2022-07-16 00:54:26 - train: epoch 0052, iter [01700, 05004], lr: 0.010000, loss: 2.2490
2022-07-16 00:54:59 - train: epoch 0052, iter [01800, 05004], lr: 0.010000, loss: 2.3056
2022-07-16 00:55:32 - train: epoch 0052, iter [01900, 05004], lr: 0.010000, loss: 2.3232
2022-07-16 00:56:07 - train: epoch 0052, iter [02000, 05004], lr: 0.010000, loss: 2.8543
2022-07-16 00:56:38 - train: epoch 0052, iter [02100, 05004], lr: 0.010000, loss: 2.3687
2022-07-16 00:57:13 - train: epoch 0052, iter [02200, 05004], lr: 0.010000, loss: 2.3384
2022-07-16 00:57:45 - train: epoch 0052, iter [02300, 05004], lr: 0.010000, loss: 2.0869
2022-07-16 00:58:19 - train: epoch 0052, iter [02400, 05004], lr: 0.010000, loss: 2.2835
2022-07-16 00:58:51 - train: epoch 0052, iter [02500, 05004], lr: 0.010000, loss: 2.1888
2022-07-16 00:59:25 - train: epoch 0052, iter [02600, 05004], lr: 0.010000, loss: 2.1798
2022-07-16 00:59:57 - train: epoch 0052, iter [02700, 05004], lr: 0.010000, loss: 2.3172
2022-07-16 01:00:31 - train: epoch 0052, iter [02800, 05004], lr: 0.010000, loss: 2.3413
2022-07-16 01:01:05 - train: epoch 0052, iter [02900, 05004], lr: 0.010000, loss: 2.1909
2022-07-16 01:01:37 - train: epoch 0052, iter [03000, 05004], lr: 0.010000, loss: 2.4459
2022-07-16 01:02:11 - train: epoch 0052, iter [03100, 05004], lr: 0.010000, loss: 2.4543
2022-07-16 01:02:44 - train: epoch 0052, iter [03200, 05004], lr: 0.010000, loss: 2.5343
2022-07-16 01:03:16 - train: epoch 0052, iter [03300, 05004], lr: 0.010000, loss: 2.3504
2022-07-16 01:03:50 - train: epoch 0052, iter [03400, 05004], lr: 0.010000, loss: 2.4535
2022-07-16 01:04:22 - train: epoch 0052, iter [03500, 05004], lr: 0.010000, loss: 2.5343
2022-07-16 01:04:56 - train: epoch 0052, iter [03600, 05004], lr: 0.010000, loss: 2.4361
2022-07-16 01:05:29 - train: epoch 0052, iter [03700, 05004], lr: 0.010000, loss: 2.6405
2022-07-16 01:06:02 - train: epoch 0052, iter [03800, 05004], lr: 0.010000, loss: 2.4159
2022-07-16 01:06:35 - train: epoch 0052, iter [03900, 05004], lr: 0.010000, loss: 2.3195
2022-07-16 01:07:08 - train: epoch 0052, iter [04000, 05004], lr: 0.010000, loss: 2.4898
2022-07-16 01:07:41 - train: epoch 0052, iter [04100, 05004], lr: 0.010000, loss: 2.0584
2022-07-16 01:08:15 - train: epoch 0052, iter [04200, 05004], lr: 0.010000, loss: 2.3544
2022-07-16 01:08:46 - train: epoch 0052, iter [04300, 05004], lr: 0.010000, loss: 2.4087
2022-07-16 01:09:21 - train: epoch 0052, iter [04400, 05004], lr: 0.010000, loss: 2.5581
2022-07-16 01:09:54 - train: epoch 0052, iter [04500, 05004], lr: 0.010000, loss: 2.3764
2022-07-16 01:10:28 - train: epoch 0052, iter [04600, 05004], lr: 0.010000, loss: 2.4222
2022-07-16 01:11:00 - train: epoch 0052, iter [04700, 05004], lr: 0.010000, loss: 2.4161
2022-07-16 01:11:34 - train: epoch 0052, iter [04800, 05004], lr: 0.010000, loss: 2.1425
2022-07-16 01:12:07 - train: epoch 0052, iter [04900, 05004], lr: 0.010000, loss: 2.3949
2022-07-16 01:12:39 - train: epoch 0052, iter [05000, 05004], lr: 0.010000, loss: 2.4115
2022-07-16 01:12:39 - train: epoch 052, train_loss: 2.4065
2022-07-16 01:13:53 - eval: epoch: 052, acc1: 53.324%, acc5: 76.734%, test_loss: 2.0912, per_image_load_time: 2.690ms, per_image_inference_time: 0.126ms
2022-07-16 01:13:53 - until epoch: 052, best_acc1: 54.094%
2022-07-16 01:13:53 - epoch 053 lr: 0.010000
2022-07-16 01:14:32 - train: epoch 0053, iter [00100, 05004], lr: 0.010000, loss: 2.4525
2022-07-16 01:15:05 - train: epoch 0053, iter [00200, 05004], lr: 0.010000, loss: 2.5557
2022-07-16 01:15:38 - train: epoch 0053, iter [00300, 05004], lr: 0.010000, loss: 2.5814
2022-07-16 01:16:12 - train: epoch 0053, iter [00400, 05004], lr: 0.010000, loss: 2.4725
2022-07-16 01:16:44 - train: epoch 0053, iter [00500, 05004], lr: 0.010000, loss: 2.6575
2022-07-16 01:17:18 - train: epoch 0053, iter [00600, 05004], lr: 0.010000, loss: 2.4173
2022-07-16 01:17:51 - train: epoch 0053, iter [00700, 05004], lr: 0.010000, loss: 2.3417
2022-07-16 01:18:24 - train: epoch 0053, iter [00800, 05004], lr: 0.010000, loss: 2.4874
2022-07-16 01:18:58 - train: epoch 0053, iter [00900, 05004], lr: 0.010000, loss: 2.3283
2022-07-16 01:19:30 - train: epoch 0053, iter [01000, 05004], lr: 0.010000, loss: 2.3103
2022-07-16 01:20:04 - train: epoch 0053, iter [01100, 05004], lr: 0.010000, loss: 2.4637
2022-07-16 01:20:36 - train: epoch 0053, iter [01200, 05004], lr: 0.010000, loss: 2.2762
2022-07-16 01:21:10 - train: epoch 0053, iter [01300, 05004], lr: 0.010000, loss: 2.3686
2022-07-16 01:21:43 - train: epoch 0053, iter [01400, 05004], lr: 0.010000, loss: 2.8750
2022-07-16 01:22:16 - train: epoch 0053, iter [01500, 05004], lr: 0.010000, loss: 2.3636
2022-07-16 01:22:49 - train: epoch 0053, iter [01600, 05004], lr: 0.010000, loss: 2.6055
2022-07-16 01:23:23 - train: epoch 0053, iter [01700, 05004], lr: 0.010000, loss: 2.5664
2022-07-16 01:23:55 - train: epoch 0053, iter [01800, 05004], lr: 0.010000, loss: 2.4619
2022-07-16 01:24:30 - train: epoch 0053, iter [01900, 05004], lr: 0.010000, loss: 2.2997
2022-07-16 01:25:02 - train: epoch 0053, iter [02000, 05004], lr: 0.010000, loss: 2.5123
2022-07-16 01:25:35 - train: epoch 0053, iter [02100, 05004], lr: 0.010000, loss: 2.4965
2022-07-16 01:26:08 - train: epoch 0053, iter [02200, 05004], lr: 0.010000, loss: 2.4779
2022-07-16 01:26:42 - train: epoch 0053, iter [02300, 05004], lr: 0.010000, loss: 2.5877
2022-07-16 01:27:15 - train: epoch 0053, iter [02400, 05004], lr: 0.010000, loss: 2.4795
2022-07-16 01:27:49 - train: epoch 0053, iter [02500, 05004], lr: 0.010000, loss: 2.6184
2022-07-16 01:28:21 - train: epoch 0053, iter [02600, 05004], lr: 0.010000, loss: 2.3609
2022-07-16 01:28:55 - train: epoch 0053, iter [02700, 05004], lr: 0.010000, loss: 2.6273
2022-07-16 01:29:28 - train: epoch 0053, iter [02800, 05004], lr: 0.010000, loss: 2.5004
2022-07-16 01:30:01 - train: epoch 0053, iter [02900, 05004], lr: 0.010000, loss: 2.1516
2022-07-16 01:30:34 - train: epoch 0053, iter [03000, 05004], lr: 0.010000, loss: 2.1552
2022-07-16 01:31:07 - train: epoch 0053, iter [03100, 05004], lr: 0.010000, loss: 2.6253
2022-07-16 01:31:42 - train: epoch 0053, iter [03200, 05004], lr: 0.010000, loss: 2.6916
2022-07-16 01:32:14 - train: epoch 0053, iter [03300, 05004], lr: 0.010000, loss: 2.3900
2022-07-16 01:32:47 - train: epoch 0053, iter [03400, 05004], lr: 0.010000, loss: 2.5063
2022-07-16 01:33:22 - train: epoch 0053, iter [03500, 05004], lr: 0.010000, loss: 2.3752
2022-07-16 01:33:54 - train: epoch 0053, iter [03600, 05004], lr: 0.010000, loss: 2.4332
2022-07-16 01:34:28 - train: epoch 0053, iter [03700, 05004], lr: 0.010000, loss: 2.5950
2022-07-16 01:35:00 - train: epoch 0053, iter [03800, 05004], lr: 0.010000, loss: 2.2507
2022-07-16 01:35:34 - train: epoch 0053, iter [03900, 05004], lr: 0.010000, loss: 2.6409
2022-07-16 01:36:06 - train: epoch 0053, iter [04000, 05004], lr: 0.010000, loss: 2.3922
2022-07-16 01:36:40 - train: epoch 0053, iter [04100, 05004], lr: 0.010000, loss: 2.5952
2022-07-16 01:37:13 - train: epoch 0053, iter [04200, 05004], lr: 0.010000, loss: 2.3363
2022-07-16 01:37:46 - train: epoch 0053, iter [04300, 05004], lr: 0.010000, loss: 2.5528
2022-07-16 01:38:20 - train: epoch 0053, iter [04400, 05004], lr: 0.010000, loss: 2.4675
2022-07-16 01:38:53 - train: epoch 0053, iter [04500, 05004], lr: 0.010000, loss: 2.6221
2022-07-16 01:39:25 - train: epoch 0053, iter [04600, 05004], lr: 0.010000, loss: 2.3186
2022-07-16 01:39:59 - train: epoch 0053, iter [04700, 05004], lr: 0.010000, loss: 2.6187
2022-07-16 01:40:33 - train: epoch 0053, iter [04800, 05004], lr: 0.010000, loss: 2.5679
2022-07-16 01:41:05 - train: epoch 0053, iter [04900, 05004], lr: 0.010000, loss: 2.4104
2022-07-16 01:41:37 - train: epoch 0053, iter [05000, 05004], lr: 0.010000, loss: 2.3387
2022-07-16 01:41:38 - train: epoch 053, train_loss: 2.4037
2022-07-16 01:42:52 - eval: epoch: 053, acc1: 53.580%, acc5: 77.070%, test_loss: 2.0772, per_image_load_time: 0.969ms, per_image_inference_time: 0.126ms
2022-07-16 01:42:52 - until epoch: 053, best_acc1: 54.094%
2022-07-16 01:42:52 - epoch 054 lr: 0.010000
2022-07-16 01:43:31 - train: epoch 0054, iter [00100, 05004], lr: 0.010000, loss: 2.2963
2022-07-16 01:44:05 - train: epoch 0054, iter [00200, 05004], lr: 0.010000, loss: 2.6640
2022-07-16 01:44:36 - train: epoch 0054, iter [00300, 05004], lr: 0.010000, loss: 2.5116
2022-07-16 01:45:09 - train: epoch 0054, iter [00400, 05004], lr: 0.010000, loss: 2.2349
2022-07-16 01:45:42 - train: epoch 0054, iter [00500, 05004], lr: 0.010000, loss: 2.4300
2022-07-16 01:46:14 - train: epoch 0054, iter [00600, 05004], lr: 0.010000, loss: 2.3055
2022-07-16 01:46:47 - train: epoch 0054, iter [00700, 05004], lr: 0.010000, loss: 2.5455
2022-07-16 01:47:20 - train: epoch 0054, iter [00800, 05004], lr: 0.010000, loss: 2.4297
2022-07-16 01:47:54 - train: epoch 0054, iter [00900, 05004], lr: 0.010000, loss: 2.2022
2022-07-16 01:48:25 - train: epoch 0054, iter [01000, 05004], lr: 0.010000, loss: 2.1696
2022-07-16 01:49:00 - train: epoch 0054, iter [01100, 05004], lr: 0.010000, loss: 2.3933
2022-07-16 01:49:32 - train: epoch 0054, iter [01200, 05004], lr: 0.010000, loss: 2.6208
2022-07-16 01:50:05 - train: epoch 0054, iter [01300, 05004], lr: 0.010000, loss: 2.2976
2022-07-16 01:50:38 - train: epoch 0054, iter [01400, 05004], lr: 0.010000, loss: 2.4777
2022-07-16 01:51:12 - train: epoch 0054, iter [01500, 05004], lr: 0.010000, loss: 2.4029
2022-07-16 01:51:44 - train: epoch 0054, iter [01600, 05004], lr: 0.010000, loss: 2.1723
2022-07-16 01:52:16 - train: epoch 0054, iter [01700, 05004], lr: 0.010000, loss: 2.3781
2022-07-16 01:52:50 - train: epoch 0054, iter [01800, 05004], lr: 0.010000, loss: 2.2566
2022-07-16 01:53:22 - train: epoch 0054, iter [01900, 05004], lr: 0.010000, loss: 2.8092
2022-07-16 01:53:56 - train: epoch 0054, iter [02000, 05004], lr: 0.010000, loss: 2.4543
2022-07-16 01:54:28 - train: epoch 0054, iter [02100, 05004], lr: 0.010000, loss: 2.0566
2022-07-16 01:55:02 - train: epoch 0054, iter [02200, 05004], lr: 0.010000, loss: 2.5355
2022-07-16 01:55:35 - train: epoch 0054, iter [02300, 05004], lr: 0.010000, loss: 2.2913
2022-07-16 01:56:08 - train: epoch 0054, iter [02400, 05004], lr: 0.010000, loss: 2.4280
2022-07-16 01:56:42 - train: epoch 0054, iter [02500, 05004], lr: 0.010000, loss: 2.4570
2022-07-16 01:57:14 - train: epoch 0054, iter [02600, 05004], lr: 0.010000, loss: 2.3386
2022-07-16 01:57:47 - train: epoch 0054, iter [02700, 05004], lr: 0.010000, loss: 2.4609
2022-07-16 01:58:21 - train: epoch 0054, iter [02800, 05004], lr: 0.010000, loss: 2.6878
2022-07-16 01:58:54 - train: epoch 0054, iter [02900, 05004], lr: 0.010000, loss: 2.2648
2022-07-16 01:59:27 - train: epoch 0054, iter [03000, 05004], lr: 0.010000, loss: 2.5287
2022-07-16 02:00:00 - train: epoch 0054, iter [03100, 05004], lr: 0.010000, loss: 2.4308
2022-07-16 02:00:33 - train: epoch 0054, iter [03200, 05004], lr: 0.010000, loss: 2.6490
2022-07-16 02:01:06 - train: epoch 0054, iter [03300, 05004], lr: 0.010000, loss: 2.3166
2022-07-16 02:01:40 - train: epoch 0054, iter [03400, 05004], lr: 0.010000, loss: 2.4654
2022-07-16 02:02:12 - train: epoch 0054, iter [03500, 05004], lr: 0.010000, loss: 2.6095
2022-07-16 02:02:46 - train: epoch 0054, iter [03600, 05004], lr: 0.010000, loss: 2.3611
2022-07-16 02:03:19 - train: epoch 0054, iter [03700, 05004], lr: 0.010000, loss: 2.2348
2022-07-16 02:03:53 - train: epoch 0054, iter [03800, 05004], lr: 0.010000, loss: 2.2980
2022-07-16 02:04:25 - train: epoch 0054, iter [03900, 05004], lr: 0.010000, loss: 2.3351
2022-07-16 02:04:59 - train: epoch 0054, iter [04000, 05004], lr: 0.010000, loss: 2.3632
2022-07-16 02:05:32 - train: epoch 0054, iter [04100, 05004], lr: 0.010000, loss: 2.3256
2022-07-16 02:06:06 - train: epoch 0054, iter [04200, 05004], lr: 0.010000, loss: 2.3940
2022-07-16 02:06:40 - train: epoch 0054, iter [04300, 05004], lr: 0.010000, loss: 2.4686
2022-07-16 02:07:13 - train: epoch 0054, iter [04400, 05004], lr: 0.010000, loss: 2.1938
2022-07-16 02:07:47 - train: epoch 0054, iter [04500, 05004], lr: 0.010000, loss: 2.2250
2022-07-16 02:08:20 - train: epoch 0054, iter [04600, 05004], lr: 0.010000, loss: 2.4319
2022-07-16 02:08:52 - train: epoch 0054, iter [04700, 05004], lr: 0.010000, loss: 2.8759
2022-07-16 02:09:26 - train: epoch 0054, iter [04800, 05004], lr: 0.010000, loss: 2.6126
2022-07-16 02:09:59 - train: epoch 0054, iter [04900, 05004], lr: 0.010000, loss: 2.2190
2022-07-16 02:10:31 - train: epoch 0054, iter [05000, 05004], lr: 0.010000, loss: 2.4664
2022-07-16 02:10:31 - train: epoch 054, train_loss: 2.4077
2022-07-16 02:11:45 - eval: epoch: 054, acc1: 53.180%, acc5: 76.864%, test_loss: 2.0932, per_image_load_time: 2.681ms, per_image_inference_time: 0.122ms
2022-07-16 02:11:45 - until epoch: 054, best_acc1: 54.094%
2022-07-16 02:11:45 - epoch 055 lr: 0.010000
2022-07-16 02:12:23 - train: epoch 0055, iter [00100, 05004], lr: 0.010000, loss: 2.2356
2022-07-16 02:12:56 - train: epoch 0055, iter [00200, 05004], lr: 0.010000, loss: 2.4608
2022-07-16 02:13:29 - train: epoch 0055, iter [00300, 05004], lr: 0.010000, loss: 2.2053
2022-07-16 02:14:03 - train: epoch 0055, iter [00400, 05004], lr: 0.010000, loss: 2.3659
2022-07-16 02:14:34 - train: epoch 0055, iter [00500, 05004], lr: 0.010000, loss: 2.1893
2022-07-16 02:15:08 - train: epoch 0055, iter [00600, 05004], lr: 0.010000, loss: 2.2320
2022-07-16 02:15:41 - train: epoch 0055, iter [00700, 05004], lr: 0.010000, loss: 2.3993
2022-07-16 02:16:13 - train: epoch 0055, iter [00800, 05004], lr: 0.010000, loss: 2.4612
2022-07-16 02:16:46 - train: epoch 0055, iter [00900, 05004], lr: 0.010000, loss: 2.2975
2022-07-16 02:17:20 - train: epoch 0055, iter [01000, 05004], lr: 0.010000, loss: 2.3427
2022-07-16 02:17:53 - train: epoch 0055, iter [01100, 05004], lr: 0.010000, loss: 2.3710
2022-07-16 02:18:25 - train: epoch 0055, iter [01200, 05004], lr: 0.010000, loss: 2.4386
2022-07-16 02:18:59 - train: epoch 0055, iter [01300, 05004], lr: 0.010000, loss: 2.4728
2022-07-16 02:19:31 - train: epoch 0055, iter [01400, 05004], lr: 0.010000, loss: 2.3427
2022-07-16 02:20:04 - train: epoch 0055, iter [01500, 05004], lr: 0.010000, loss: 2.4867
2022-07-16 02:20:38 - train: epoch 0055, iter [01600, 05004], lr: 0.010000, loss: 2.5163
2022-07-16 02:21:10 - train: epoch 0055, iter [01700, 05004], lr: 0.010000, loss: 2.5817
2022-07-16 02:21:44 - train: epoch 0055, iter [01800, 05004], lr: 0.010000, loss: 2.5875
2022-07-16 02:22:16 - train: epoch 0055, iter [01900, 05004], lr: 0.010000, loss: 2.4959
2022-07-16 02:22:49 - train: epoch 0055, iter [02000, 05004], lr: 0.010000, loss: 2.4047
2022-07-16 02:23:22 - train: epoch 0055, iter [02100, 05004], lr: 0.010000, loss: 2.1251
2022-07-16 02:23:54 - train: epoch 0055, iter [02200, 05004], lr: 0.010000, loss: 2.5171
2022-07-16 02:24:27 - train: epoch 0055, iter [02300, 05004], lr: 0.010000, loss: 2.3511
2022-07-16 02:25:00 - train: epoch 0055, iter [02400, 05004], lr: 0.010000, loss: 2.2928
2022-07-16 02:25:34 - train: epoch 0055, iter [02500, 05004], lr: 0.010000, loss: 2.2624
2022-07-16 02:26:06 - train: epoch 0055, iter [02600, 05004], lr: 0.010000, loss: 2.3192
2022-07-16 02:26:40 - train: epoch 0055, iter [02700, 05004], lr: 0.010000, loss: 2.3166
2022-07-16 02:27:12 - train: epoch 0055, iter [02800, 05004], lr: 0.010000, loss: 2.3987
2022-07-16 02:27:45 - train: epoch 0055, iter [02900, 05004], lr: 0.010000, loss: 2.5118
2022-07-16 02:28:18 - train: epoch 0055, iter [03000, 05004], lr: 0.010000, loss: 2.1769
2022-07-16 02:28:51 - train: epoch 0055, iter [03100, 05004], lr: 0.010000, loss: 2.5240
2022-07-16 02:29:24 - train: epoch 0055, iter [03200, 05004], lr: 0.010000, loss: 2.2971
2022-07-16 02:29:58 - train: epoch 0055, iter [03300, 05004], lr: 0.010000, loss: 2.1682
2022-07-16 02:30:31 - train: epoch 0055, iter [03400, 05004], lr: 0.010000, loss: 2.3562
2022-07-16 02:31:05 - train: epoch 0055, iter [03500, 05004], lr: 0.010000, loss: 2.2488
2022-07-16 02:31:37 - train: epoch 0055, iter [03600, 05004], lr: 0.010000, loss: 2.5418
2022-07-16 02:32:11 - train: epoch 0055, iter [03700, 05004], lr: 0.010000, loss: 2.3878
2022-07-16 02:32:43 - train: epoch 0055, iter [03800, 05004], lr: 0.010000, loss: 2.4303
2022-07-16 02:33:17 - train: epoch 0055, iter [03900, 05004], lr: 0.010000, loss: 2.8176
2022-07-16 02:33:49 - train: epoch 0055, iter [04000, 05004], lr: 0.010000, loss: 2.3634
2022-07-16 02:34:23 - train: epoch 0055, iter [04100, 05004], lr: 0.010000, loss: 2.3804
2022-07-16 02:34:55 - train: epoch 0055, iter [04200, 05004], lr: 0.010000, loss: 2.4615
2022-07-16 02:35:30 - train: epoch 0055, iter [04300, 05004], lr: 0.010000, loss: 2.4754
2022-07-16 02:36:02 - train: epoch 0055, iter [04400, 05004], lr: 0.010000, loss: 2.4744
2022-07-16 02:36:35 - train: epoch 0055, iter [04500, 05004], lr: 0.010000, loss: 2.3797
2022-07-16 02:37:08 - train: epoch 0055, iter [04600, 05004], lr: 0.010000, loss: 2.5258
2022-07-16 02:37:42 - train: epoch 0055, iter [04700, 05004], lr: 0.010000, loss: 2.2969
2022-07-16 02:38:14 - train: epoch 0055, iter [04800, 05004], lr: 0.010000, loss: 2.5180
2022-07-16 02:38:48 - train: epoch 0055, iter [04900, 05004], lr: 0.010000, loss: 2.3660
2022-07-16 02:39:19 - train: epoch 0055, iter [05000, 05004], lr: 0.010000, loss: 2.5111
2022-07-16 02:39:20 - train: epoch 055, train_loss: 2.4038
2022-07-16 02:40:34 - eval: epoch: 055, acc1: 53.560%, acc5: 76.964%, test_loss: 2.0813, per_image_load_time: 2.760ms, per_image_inference_time: 0.136ms
2022-07-16 02:40:34 - until epoch: 055, best_acc1: 54.094%
2022-07-16 02:40:34 - epoch 056 lr: 0.010000
2022-07-16 02:41:13 - train: epoch 0056, iter [00100, 05004], lr: 0.010000, loss: 2.3591
2022-07-16 02:41:46 - train: epoch 0056, iter [00200, 05004], lr: 0.010000, loss: 2.5265
2022-07-16 02:42:19 - train: epoch 0056, iter [00300, 05004], lr: 0.010000, loss: 2.2813
2022-07-16 02:42:52 - train: epoch 0056, iter [00400, 05004], lr: 0.010000, loss: 2.3746
2022-07-16 02:43:26 - train: epoch 0056, iter [00500, 05004], lr: 0.010000, loss: 2.3032
2022-07-16 02:43:58 - train: epoch 0056, iter [00600, 05004], lr: 0.010000, loss: 2.2675
2022-07-16 02:44:32 - train: epoch 0056, iter [00700, 05004], lr: 0.010000, loss: 2.3142
2022-07-16 02:45:05 - train: epoch 0056, iter [00800, 05004], lr: 0.010000, loss: 2.5849
2022-07-16 02:45:39 - train: epoch 0056, iter [00900, 05004], lr: 0.010000, loss: 2.3539
2022-07-16 02:46:11 - train: epoch 0056, iter [01000, 05004], lr: 0.010000, loss: 2.2401
2022-07-16 02:46:45 - train: epoch 0056, iter [01100, 05004], lr: 0.010000, loss: 2.2367
2022-07-16 02:47:18 - train: epoch 0056, iter [01200, 05004], lr: 0.010000, loss: 2.2523
2022-07-16 02:47:52 - train: epoch 0056, iter [01300, 05004], lr: 0.010000, loss: 2.4971
2022-07-16 02:48:24 - train: epoch 0056, iter [01400, 05004], lr: 0.010000, loss: 2.2562
2022-07-16 02:48:58 - train: epoch 0056, iter [01500, 05004], lr: 0.010000, loss: 2.9074
2022-07-16 02:49:31 - train: epoch 0056, iter [01600, 05004], lr: 0.010000, loss: 2.2430
2022-07-16 02:50:04 - train: epoch 0056, iter [01700, 05004], lr: 0.010000, loss: 2.5203
2022-07-16 02:50:37 - train: epoch 0056, iter [01800, 05004], lr: 0.010000, loss: 2.7269
2022-07-16 02:51:11 - train: epoch 0056, iter [01900, 05004], lr: 0.010000, loss: 2.5307
2022-07-16 02:51:44 - train: epoch 0056, iter [02000, 05004], lr: 0.010000, loss: 2.3689
2022-07-16 02:52:18 - train: epoch 0056, iter [02100, 05004], lr: 0.010000, loss: 2.4526
2022-07-16 02:52:51 - train: epoch 0056, iter [02200, 05004], lr: 0.010000, loss: 2.5706
2022-07-16 02:53:25 - train: epoch 0056, iter [02300, 05004], lr: 0.010000, loss: 2.5203
2022-07-16 02:53:57 - train: epoch 0056, iter [02400, 05004], lr: 0.010000, loss: 2.4307
2022-07-16 02:54:31 - train: epoch 0056, iter [02500, 05004], lr: 0.010000, loss: 2.4895
2022-07-16 02:55:04 - train: epoch 0056, iter [02600, 05004], lr: 0.010000, loss: 2.3141
2022-07-16 02:55:37 - train: epoch 0056, iter [02700, 05004], lr: 0.010000, loss: 2.4763
2022-07-16 02:56:09 - train: epoch 0056, iter [02800, 05004], lr: 0.010000, loss: 2.2449
2022-07-16 02:56:43 - train: epoch 0056, iter [02900, 05004], lr: 0.010000, loss: 2.6486
2022-07-16 02:57:17 - train: epoch 0056, iter [03000, 05004], lr: 0.010000, loss: 2.7220
2022-07-16 02:57:51 - train: epoch 0056, iter [03100, 05004], lr: 0.010000, loss: 2.3506
2022-07-16 02:58:24 - train: epoch 0056, iter [03200, 05004], lr: 0.010000, loss: 2.3018
2022-07-16 02:58:57 - train: epoch 0056, iter [03300, 05004], lr: 0.010000, loss: 2.6805
2022-07-16 02:59:30 - train: epoch 0056, iter [03400, 05004], lr: 0.010000, loss: 2.4337
2022-07-16 03:00:03 - train: epoch 0056, iter [03500, 05004], lr: 0.010000, loss: 2.3415
2022-07-16 03:00:36 - train: epoch 0056, iter [03600, 05004], lr: 0.010000, loss: 2.1676
2022-07-16 03:01:09 - train: epoch 0056, iter [03700, 05004], lr: 0.010000, loss: 2.2450
2022-07-16 03:01:43 - train: epoch 0056, iter [03800, 05004], lr: 0.010000, loss: 2.1592
2022-07-16 03:02:16 - train: epoch 0056, iter [03900, 05004], lr: 0.010000, loss: 2.7298
2022-07-16 03:02:50 - train: epoch 0056, iter [04000, 05004], lr: 0.010000, loss: 2.6001
2022-07-16 03:03:23 - train: epoch 0056, iter [04100, 05004], lr: 0.010000, loss: 2.6769
2022-07-16 03:03:57 - train: epoch 0056, iter [04200, 05004], lr: 0.010000, loss: 2.3340
2022-07-16 03:04:30 - train: epoch 0056, iter [04300, 05004], lr: 0.010000, loss: 2.3243
2022-07-16 03:05:03 - train: epoch 0056, iter [04400, 05004], lr: 0.010000, loss: 2.5573
2022-07-16 03:05:36 - train: epoch 0056, iter [04500, 05004], lr: 0.010000, loss: 2.3908
2022-07-16 03:06:09 - train: epoch 0056, iter [04600, 05004], lr: 0.010000, loss: 2.4031
2022-07-16 03:06:43 - train: epoch 0056, iter [04700, 05004], lr: 0.010000, loss: 2.4748
2022-07-16 03:07:16 - train: epoch 0056, iter [04800, 05004], lr: 0.010000, loss: 2.5973
2022-07-16 03:07:48 - train: epoch 0056, iter [04900, 05004], lr: 0.010000, loss: 2.4747
2022-07-16 03:08:21 - train: epoch 0056, iter [05000, 05004], lr: 0.010000, loss: 2.5129
2022-07-16 03:08:21 - train: epoch 056, train_loss: 2.4029
2022-07-16 03:09:34 - eval: epoch: 056, acc1: 52.860%, acc5: 76.526%, test_loss: 2.1169, per_image_load_time: 2.349ms, per_image_inference_time: 0.136ms
2022-07-16 03:09:34 - until epoch: 056, best_acc1: 54.094%
2022-07-16 03:09:34 - epoch 057 lr: 0.010000
2022-07-16 03:10:12 - train: epoch 0057, iter [00100, 05004], lr: 0.010000, loss: 2.3789
2022-07-16 03:10:45 - train: epoch 0057, iter [00200, 05004], lr: 0.010000, loss: 2.3106
2022-07-16 03:11:18 - train: epoch 0057, iter [00300, 05004], lr: 0.010000, loss: 2.2742
2022-07-16 03:11:51 - train: epoch 0057, iter [00400, 05004], lr: 0.010000, loss: 2.4309
2022-07-16 03:12:24 - train: epoch 0057, iter [00500, 05004], lr: 0.010000, loss: 2.1940
2022-07-16 03:12:56 - train: epoch 0057, iter [00600, 05004], lr: 0.010000, loss: 2.5670
2022-07-16 03:13:29 - train: epoch 0057, iter [00700, 05004], lr: 0.010000, loss: 2.2095
2022-07-16 03:14:01 - train: epoch 0057, iter [00800, 05004], lr: 0.010000, loss: 2.3697
2022-07-16 03:14:34 - train: epoch 0057, iter [00900, 05004], lr: 0.010000, loss: 2.4719
2022-07-16 03:15:06 - train: epoch 0057, iter [01000, 05004], lr: 0.010000, loss: 2.3221
2022-07-16 03:15:40 - train: epoch 0057, iter [01100, 05004], lr: 0.010000, loss: 2.2754
2022-07-16 03:16:13 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 2.3572
2022-07-16 03:16:46 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 2.4227
2022-07-16 03:17:19 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 2.4735
2022-07-16 03:17:51 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 2.6736
2022-07-16 03:18:25 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 2.5154
2022-07-16 03:18:58 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 2.5124
2022-07-16 03:19:31 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 2.5560
2022-07-16 03:20:03 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 2.3196
2022-07-16 03:20:37 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 2.3443
2022-07-16 03:21:09 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 2.6012
2022-07-16 03:21:43 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 2.6815
2022-07-16 03:22:15 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 2.3869
2022-07-16 03:22:50 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 2.4292
2022-07-16 03:23:21 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 2.6250
2022-07-16 03:23:55 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 2.2150
2022-07-16 03:24:27 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 2.0910
2022-07-16 03:25:01 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 2.0994
2022-07-16 03:25:34 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 2.4190
2022-07-16 03:26:08 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 2.4101
2022-07-16 03:26:40 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 2.6306
2022-07-16 03:27:13 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 2.5243
2022-07-16 03:27:46 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 2.3156
2022-07-16 03:28:19 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 2.4996
2022-07-16 03:28:53 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 2.5533
2022-07-16 03:29:26 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 2.1816
2022-07-16 03:30:00 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 2.4155
2022-07-16 03:30:33 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 2.3506
2022-07-16 03:31:07 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 2.5036
2022-07-16 03:31:39 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 2.3108
2022-07-16 03:32:12 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 2.4187
2022-07-16 03:32:46 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 2.6339
2022-07-16 03:33:19 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 2.2880
2022-07-16 03:33:51 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 2.4347
2022-07-16 03:34:25 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 2.6884
2022-07-16 03:34:58 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 2.5467
2022-07-16 03:35:30 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 2.3259
2022-07-16 03:36:04 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 2.5616
2022-07-16 03:36:38 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 2.5757
2022-07-16 03:37:09 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 2.6368
2022-07-16 03:37:10 - train: epoch 057, train_loss: 2.4037
2022-07-16 03:38:24 - eval: epoch: 057, acc1: 53.080%, acc5: 76.826%, test_loss: 2.1015, per_image_load_time: 2.278ms, per_image_inference_time: 0.131ms
2022-07-16 03:38:24 - until epoch: 057, best_acc1: 54.094%
2022-07-16 03:38:24 - epoch 058 lr: 0.010000
2022-07-16 03:39:02 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 2.4577
2022-07-16 03:39:34 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 2.2577
2022-07-16 03:40:08 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 2.4254
2022-07-16 03:40:41 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 2.3819
2022-07-16 03:41:13 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 2.1544
2022-07-16 03:41:46 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 2.6028
2022-07-16 03:42:20 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 2.4308
2022-07-16 03:42:52 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 2.2430
2022-07-16 03:43:25 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 2.2617
2022-07-16 03:43:58 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 2.5022
2022-07-16 03:44:31 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 2.1706
2022-07-16 03:45:03 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 2.3583
2022-07-16 03:45:37 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 2.5441
2022-07-16 03:46:10 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 2.4305
2022-07-16 03:46:43 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 2.3236
2022-07-16 03:47:16 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 2.3101
2022-07-16 03:47:49 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 2.5477
2022-07-16 03:48:22 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 2.4066
2022-07-16 03:48:55 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 2.5471
2022-07-16 03:49:28 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 2.6119
2022-07-16 03:50:01 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 2.3577
2022-07-16 03:50:34 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 2.1805
2022-07-16 03:51:08 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 2.2488
2022-07-16 03:51:40 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 2.6122
2022-07-16 03:52:13 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 2.5971
2022-07-16 03:52:46 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 2.2749
2022-07-16 03:53:20 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 2.6849
2022-07-16 03:53:52 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 2.2778
2022-07-16 03:54:25 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 2.3536
2022-07-16 03:54:58 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 2.5009
2022-07-16 03:55:31 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 2.2956
2022-07-16 03:56:05 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 2.2615
2022-07-16 03:56:38 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 2.3712
2022-07-16 03:57:10 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 2.2405
2022-07-16 03:57:45 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 2.3485
2022-07-16 03:58:17 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 2.1346
2022-07-16 03:58:50 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 2.2974
2022-07-16 03:59:23 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 2.4903
2022-07-16 03:59:56 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 2.5567
2022-07-16 04:00:30 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 2.5279
2022-07-16 04:01:03 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 2.5035
2022-07-16 04:01:36 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 2.1496
2022-07-16 04:02:10 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 2.6383
2022-07-16 04:02:43 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 2.1916
2022-07-16 04:03:17 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 2.4848
2022-07-16 04:03:49 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 2.1901
2022-07-16 04:04:23 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 2.3803
2022-07-16 04:04:55 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 2.4661
2022-07-16 04:05:28 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 2.2719
2022-07-16 04:06:00 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 2.2998
2022-07-16 04:06:01 - train: epoch 058, train_loss: 2.4006
2022-07-16 04:07:15 - eval: epoch: 058, acc1: 53.654%, acc5: 76.958%, test_loss: 2.0770, per_image_load_time: 1.972ms, per_image_inference_time: 0.134ms
2022-07-16 04:07:15 - until epoch: 058, best_acc1: 54.094%
2022-07-16 04:07:15 - epoch 059 lr: 0.010000
2022-07-16 04:07:53 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 2.5950
2022-07-16 04:08:26 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 2.1745
2022-07-16 04:09:00 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 2.4794
2022-07-16 04:09:32 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 2.4993
2022-07-16 04:10:06 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 2.5521
2022-07-16 04:10:39 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 2.3071
2022-07-16 04:11:13 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 2.3224
2022-07-16 04:11:45 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 2.4579
2022-07-16 04:12:18 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 2.2634
2022-07-16 04:12:51 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 2.4681
2022-07-16 04:13:24 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 2.7800
2022-07-16 04:13:57 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 2.0652
2022-07-16 04:14:31 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 2.6306
2022-07-16 04:15:04 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 2.6545
2022-07-16 04:15:37 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 2.5179
2022-07-16 04:16:10 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 2.1635
2022-07-16 04:16:43 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 2.4597
2022-07-16 04:17:16 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 2.3222
2022-07-16 04:17:49 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 2.3675
2022-07-16 04:18:22 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 2.2391
2022-07-16 04:18:56 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 2.5719
2022-07-16 04:19:29 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 2.5271
2022-07-16 04:20:02 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 2.3642
2022-07-16 04:20:34 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 2.4482
2022-07-16 04:21:07 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 2.4000
2022-07-16 04:21:41 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 2.3689
2022-07-16 04:22:13 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 2.2623
2022-07-16 04:22:47 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 2.5761
2022-07-16 04:23:20 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 2.3786
2022-07-16 04:23:52 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 2.7853
2022-07-16 04:24:26 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 2.2878
2022-07-16 04:25:00 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 2.4269
2022-07-16 04:25:32 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 2.5180
2022-07-16 04:26:05 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 2.7437
2022-07-16 04:26:39 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 2.2897
2022-07-16 04:27:12 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 2.4877
2022-07-16 04:27:45 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 2.3696
2022-07-16 04:28:18 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 2.3864
2022-07-16 04:28:52 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 2.3540
2022-07-16 04:29:24 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 2.7252
2022-07-16 04:29:58 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 2.5478
2022-07-16 04:30:30 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 2.3061
2022-07-16 04:31:04 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 2.5599
2022-07-16 04:31:37 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 2.4761
2022-07-16 04:32:11 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 2.5129
2022-07-16 04:32:43 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 2.4563
2022-07-16 04:33:17 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 2.2909
2022-07-16 04:33:50 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 2.2898
2022-07-16 04:34:24 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 2.6673
2022-07-16 04:34:55 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 2.5780
2022-07-16 04:34:56 - train: epoch 059, train_loss: 2.4014
2022-07-16 04:36:11 - eval: epoch: 059, acc1: 53.376%, acc5: 76.896%, test_loss: 2.0845, per_image_load_time: 2.601ms, per_image_inference_time: 0.118ms
2022-07-16 04:36:11 - until epoch: 059, best_acc1: 54.094%
2022-07-16 04:36:11 - epoch 060 lr: 0.010000
2022-07-16 04:36:49 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 2.3754
2022-07-16 04:37:22 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 2.4983
2022-07-16 04:37:55 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 2.3449
2022-07-16 04:38:27 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 2.4412
2022-07-16 04:39:00 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 2.4875
2022-07-16 04:39:33 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 2.4434
2022-07-16 04:40:05 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 2.4723
2022-07-16 04:40:37 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 2.6333
2022-07-16 04:41:10 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 2.1243
2022-07-16 04:41:43 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 2.1236
2022-07-16 04:42:15 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 2.1463
2022-07-16 04:42:49 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 2.2622
2022-07-16 04:43:21 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 2.3218
2022-07-16 04:43:55 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 2.3254
2022-07-16 04:44:27 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 2.4808
2022-07-16 04:45:00 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 2.4373
2022-07-16 04:45:32 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 2.3815
2022-07-16 04:46:06 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 2.4370
2022-07-16 04:46:38 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 2.6142
2022-07-16 04:47:12 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 2.2108
2022-07-16 04:47:44 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 2.5694
2022-07-16 04:48:17 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 2.4464
2022-07-16 04:48:50 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 2.2065
2022-07-16 04:49:23 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 2.2175
2022-07-16 04:49:57 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 2.2645
2022-07-16 04:50:30 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 2.5901
2022-07-16 04:51:02 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 2.4205
2022-07-16 04:51:36 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 2.4593
2022-07-16 04:52:09 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 2.5795
2022-07-16 04:52:42 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 2.5333
2022-07-16 04:53:16 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 2.5558
2022-07-16 04:53:48 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 2.3924
2022-07-16 04:54:21 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 2.2842
2022-07-16 04:54:54 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 2.5433
2022-07-16 04:55:28 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 2.5464
2022-07-16 04:56:01 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 2.4462
2022-07-16 04:56:34 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 2.3076
2022-07-16 04:57:06 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 2.4664
2022-07-16 04:57:40 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 2.7208
2022-07-16 04:58:13 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 2.4261
2022-07-16 04:58:46 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 2.5699
2022-07-16 04:59:19 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 2.4333
2022-07-16 04:59:51 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 2.4174
2022-07-16 05:00:26 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 2.5136
2022-07-16 05:00:58 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 2.2097
2022-07-16 05:01:32 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 2.2618
2022-07-16 05:02:05 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 2.5173
2022-07-16 05:02:38 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 2.4140
2022-07-16 05:03:12 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 2.3996
2022-07-16 05:03:43 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 2.5060
2022-07-16 05:03:44 - train: epoch 060, train_loss: 2.3992
2022-07-16 05:04:57 - eval: epoch: 060, acc1: 53.070%, acc5: 76.952%, test_loss: 2.0969, per_image_load_time: 2.424ms, per_image_inference_time: 0.126ms
2022-07-16 05:04:57 - until epoch: 060, best_acc1: 54.094%
2022-07-16 05:04:57 - epoch 061 lr: 0.001000
2022-07-16 05:05:35 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 2.1874
2022-07-16 05:06:09 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 2.2909
2022-07-16 05:06:40 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 1.9983
2022-07-16 05:07:14 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 2.5026
2022-07-16 05:07:47 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 2.2750
2022-07-16 05:08:21 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 2.2208
2022-07-16 05:08:53 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 1.9866
2022-07-16 05:09:27 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 2.3510
2022-07-16 05:09:58 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 2.3543
2022-07-16 05:10:32 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 2.2338
2022-07-16 05:11:05 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 2.1446
2022-07-16 05:11:38 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 1.9963
2022-07-16 05:12:11 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 2.2291
2022-07-16 05:12:43 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 2.1271
2022-07-16 05:13:16 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 2.2384
2022-07-16 05:13:49 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 2.0165
2022-07-16 05:14:23 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 2.3202
2022-07-16 05:14:55 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 2.3293
2022-07-16 05:15:29 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 2.5093
2022-07-16 05:16:02 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 2.2328
2022-07-16 05:16:35 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 2.6445
2022-07-16 05:17:07 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 2.0741
2022-07-16 05:17:41 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 2.0284
2022-07-16 05:18:13 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 2.0357
2022-07-16 05:18:48 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 2.1169
2022-07-16 05:19:20 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 2.3430
2022-07-16 05:19:53 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 2.3081
2022-07-16 05:20:25 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 2.2640
2022-07-16 05:21:00 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 2.4424
2022-07-16 05:21:33 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 2.1844
2022-07-16 05:22:05 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 2.3681
2022-07-16 05:22:39 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 2.3210
2022-07-16 05:23:11 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 2.3057
2022-07-16 05:23:45 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 2.1935
2022-07-16 05:24:17 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 2.3346
2022-07-16 05:24:51 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 2.3352
2022-07-16 05:25:24 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 2.4674
2022-07-16 05:25:58 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 2.2139
2022-07-16 05:26:30 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 2.2663
2022-07-16 05:27:04 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 2.1705
2022-07-16 05:27:37 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 2.4729
2022-07-16 05:28:10 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 2.1337
2022-07-16 05:28:43 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 2.2324
2022-07-16 05:29:16 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 2.3090
2022-07-16 05:29:50 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 2.2567
2022-07-16 05:30:25 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 2.2823
2022-07-16 05:30:56 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 2.1964
2022-07-16 05:31:30 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 2.1267
2022-07-16 05:32:04 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 2.2380
2022-07-16 05:32:35 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 2.3027
2022-07-16 05:32:36 - train: epoch 061, train_loss: 2.2563
2022-07-16 05:33:50 - eval: epoch: 061, acc1: 56.122%, acc5: 78.870%, test_loss: 1.9533, per_image_load_time: 1.657ms, per_image_inference_time: 0.137ms
2022-07-16 05:33:50 - until epoch: 061, best_acc1: 56.122%
2022-07-16 05:33:50 - epoch 062 lr: 0.001000
2022-07-16 05:34:28 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 2.2674
2022-07-16 05:35:01 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 2.2342
2022-07-16 05:35:33 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 2.3292
2022-07-16 05:36:04 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 2.1724
2022-07-16 05:36:37 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 2.2539
2022-07-16 05:37:11 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 2.0455
2022-07-16 05:37:42 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 2.4573
2022-07-16 05:38:15 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 2.3536
2022-07-16 05:38:47 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 2.1832
2022-07-16 05:39:20 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 2.3673
2022-07-16 05:39:52 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 2.0730
2022-07-16 05:40:26 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 2.4797
2022-07-16 05:40:59 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 2.3673
2022-07-16 05:41:31 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 2.1193
2022-07-16 05:42:05 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 2.3614
2022-07-16 05:42:37 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 2.3584
2022-07-16 05:43:10 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 2.2672
2022-07-16 05:43:43 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 2.1587
2022-07-16 05:44:16 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 2.3391
2022-07-16 05:44:48 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 2.1653
2022-07-16 05:45:22 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 2.3825
2022-07-16 05:45:53 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 2.1252
2022-07-16 05:46:27 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 2.2918
2022-07-16 05:47:00 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 2.1526
2022-07-16 05:47:34 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 2.2922
2022-07-16 05:48:06 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 2.0699
2022-07-16 05:48:40 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 2.2229
2022-07-16 05:49:12 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 2.4775
2022-07-16 05:49:45 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 2.2679
2022-07-16 05:50:18 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 2.5935
2022-07-16 05:50:52 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 2.3465
2022-07-16 05:51:24 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 2.0074
2022-07-16 05:51:57 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 2.2515
2022-07-16 05:52:30 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 2.1391
2022-07-16 05:53:04 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 2.2332
2022-07-16 05:53:36 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 2.3722
2022-07-16 05:54:09 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 2.2507
2022-07-16 05:54:43 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 2.2230
2022-07-16 05:55:15 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 2.2581
2022-07-16 05:55:49 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 1.9371
2022-07-16 05:56:21 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 2.3313
2022-07-16 05:56:55 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 2.0562
2022-07-16 05:57:27 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 2.2889
2022-07-16 05:58:01 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 2.4301
2022-07-16 05:58:35 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 2.1132
2022-07-16 05:59:08 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 2.1322
2022-07-16 05:59:40 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 2.1033
2022-07-16 06:00:14 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 2.0936
2022-07-16 06:00:46 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 2.2678
2022-07-16 06:01:18 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 2.2223
2022-07-16 06:01:19 - train: epoch 062, train_loss: 2.2270
2022-07-16 06:02:33 - eval: epoch: 062, acc1: 56.414%, acc5: 79.218%, test_loss: 1.9365, per_image_load_time: 0.945ms, per_image_inference_time: 0.115ms
2022-07-16 06:02:33 - until epoch: 062, best_acc1: 56.414%
2022-07-16 06:02:33 - epoch 063 lr: 0.001000
2022-07-16 06:03:12 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 2.2445
2022-07-16 06:03:44 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 2.2876
2022-07-16 06:04:17 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 2.4345
2022-07-16 06:04:51 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 2.0664
2022-07-16 06:05:23 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 2.0580
2022-07-16 06:05:55 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 2.3597
2022-07-16 06:06:28 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 2.1348
2022-07-16 06:07:01 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 2.2122
2022-07-16 06:07:34 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 2.3541
2022-07-16 06:08:07 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 2.2999
2022-07-16 06:08:41 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 2.2054
2022-07-16 06:09:13 - train: epoch 0063, iter [01200, 05004], lr: 0.001000, loss: 2.1925
2022-07-16 06:09:47 - train: epoch 0063, iter [01300, 05004], lr: 0.001000, loss: 2.1029
2022-07-16 06:10:18 - train: epoch 0063, iter [01400, 05004], lr: 0.001000, loss: 2.3778
2022-07-16 06:10:52 - train: epoch 0063, iter [01500, 05004], lr: 0.001000, loss: 2.1062
2022-07-16 06:11:25 - train: epoch 0063, iter [01600, 05004], lr: 0.001000, loss: 2.1111
2022-07-16 06:11:58 - train: epoch 0063, iter [01700, 05004], lr: 0.001000, loss: 1.9964
2022-07-16 06:12:30 - train: epoch 0063, iter [01800, 05004], lr: 0.001000, loss: 2.3320
2022-07-16 06:13:04 - train: epoch 0063, iter [01900, 05004], lr: 0.001000, loss: 2.5049
2022-07-16 06:13:38 - train: epoch 0063, iter [02000, 05004], lr: 0.001000, loss: 2.1063
2022-07-16 06:14:10 - train: epoch 0063, iter [02100, 05004], lr: 0.001000, loss: 2.0143
2022-07-16 06:14:43 - train: epoch 0063, iter [02200, 05004], lr: 0.001000, loss: 2.5878
2022-07-16 06:15:16 - train: epoch 0063, iter [02300, 05004], lr: 0.001000, loss: 2.4688
2022-07-16 06:15:49 - train: epoch 0063, iter [02400, 05004], lr: 0.001000, loss: 2.4373
2022-07-16 06:16:25 - train: epoch 0063, iter [02500, 05004], lr: 0.001000, loss: 2.2246
2022-07-16 06:16:58 - train: epoch 0063, iter [02600, 05004], lr: 0.001000, loss: 2.0076
2022-07-16 06:17:31 - train: epoch 0063, iter [02700, 05004], lr: 0.001000, loss: 2.4351
2022-07-16 06:18:04 - train: epoch 0063, iter [02800, 05004], lr: 0.001000, loss: 2.3611
2022-07-16 06:18:37 - train: epoch 0063, iter [02900, 05004], lr: 0.001000, loss: 2.2301
2022-07-16 06:19:10 - train: epoch 0063, iter [03000, 05004], lr: 0.001000, loss: 2.4857
2022-07-16 06:19:44 - train: epoch 0063, iter [03100, 05004], lr: 0.001000, loss: 2.4630
2022-07-16 06:20:16 - train: epoch 0063, iter [03200, 05004], lr: 0.001000, loss: 2.2752
2022-07-16 06:20:50 - train: epoch 0063, iter [03300, 05004], lr: 0.001000, loss: 2.1344
2022-07-16 06:21:22 - train: epoch 0063, iter [03400, 05004], lr: 0.001000, loss: 1.8961
2022-07-16 06:21:55 - train: epoch 0063, iter [03500, 05004], lr: 0.001000, loss: 2.3597
2022-07-16 06:22:28 - train: epoch 0063, iter [03600, 05004], lr: 0.001000, loss: 2.1715
2022-07-16 06:23:01 - train: epoch 0063, iter [03700, 05004], lr: 0.001000, loss: 2.3309
2022-07-16 06:23:35 - train: epoch 0063, iter [03800, 05004], lr: 0.001000, loss: 2.4037
2022-07-16 06:24:08 - train: epoch 0063, iter [03900, 05004], lr: 0.001000, loss: 1.9455
2022-07-16 06:24:41 - train: epoch 0063, iter [04000, 05004], lr: 0.001000, loss: 1.9612
2022-07-16 06:25:13 - train: epoch 0063, iter [04100, 05004], lr: 0.001000, loss: 2.3297
2022-07-16 06:25:48 - train: epoch 0063, iter [04200, 05004], lr: 0.001000, loss: 2.0657
2022-07-16 06:26:20 - train: epoch 0063, iter [04300, 05004], lr: 0.001000, loss: 2.3278
2022-07-16 06:26:54 - train: epoch 0063, iter [04400, 05004], lr: 0.001000, loss: 2.2278
2022-07-16 06:27:27 - train: epoch 0063, iter [04500, 05004], lr: 0.001000, loss: 2.1382
2022-07-16 06:28:00 - train: epoch 0063, iter [04600, 05004], lr: 0.001000, loss: 2.3448
2022-07-16 06:28:32 - train: epoch 0063, iter [04700, 05004], lr: 0.001000, loss: 2.0927
2022-07-16 06:29:06 - train: epoch 0063, iter [04800, 05004], lr: 0.001000, loss: 2.3067
2022-07-16 06:29:38 - train: epoch 0063, iter [04900, 05004], lr: 0.001000, loss: 2.1511
2022-07-16 06:30:10 - train: epoch 0063, iter [05000, 05004], lr: 0.001000, loss: 2.1937
2022-07-16 06:30:11 - train: epoch 063, train_loss: 2.2164
2022-07-16 06:31:25 - eval: epoch: 063, acc1: 56.662%, acc5: 79.160%, test_loss: 1.9314, per_image_load_time: 2.746ms, per_image_inference_time: 0.132ms
2022-07-16 06:31:25 - until epoch: 063, best_acc1: 56.662%
2022-07-16 06:31:25 - epoch 064 lr: 0.001000
2022-07-16 06:32:03 - train: epoch 0064, iter [00100, 05004], lr: 0.001000, loss: 2.1886
2022-07-16 06:32:36 - train: epoch 0064, iter [00200, 05004], lr: 0.001000, loss: 2.1995
2022-07-16 06:33:09 - train: epoch 0064, iter [00300, 05004], lr: 0.001000, loss: 2.0389
2022-07-16 06:33:41 - train: epoch 0064, iter [00400, 05004], lr: 0.001000, loss: 2.2050
2022-07-16 06:34:15 - train: epoch 0064, iter [00500, 05004], lr: 0.001000, loss: 1.9537
2022-07-16 06:34:48 - train: epoch 0064, iter [00600, 05004], lr: 0.001000, loss: 2.5897
2022-07-16 06:35:20 - train: epoch 0064, iter [00700, 05004], lr: 0.001000, loss: 2.2609
2022-07-16 06:35:54 - train: epoch 0064, iter [00800, 05004], lr: 0.001000, loss: 1.9845
2022-07-16 06:36:26 - train: epoch 0064, iter [00900, 05004], lr: 0.001000, loss: 2.2384
2022-07-16 06:36:59 - train: epoch 0064, iter [01000, 05004], lr: 0.001000, loss: 2.1505
2022-07-16 06:37:33 - train: epoch 0064, iter [01100, 05004], lr: 0.001000, loss: 2.1584
2022-07-16 06:38:05 - train: epoch 0064, iter [01200, 05004], lr: 0.001000, loss: 1.9535
2022-07-16 06:38:40 - train: epoch 0064, iter [01300, 05004], lr: 0.001000, loss: 2.1784
2022-07-16 06:39:12 - train: epoch 0064, iter [01400, 05004], lr: 0.001000, loss: 2.4398
2022-07-16 06:39:44 - train: epoch 0064, iter [01500, 05004], lr: 0.001000, loss: 2.3626
2022-07-16 06:40:16 - train: epoch 0064, iter [01600, 05004], lr: 0.001000, loss: 2.0652
2022-07-16 06:40:50 - train: epoch 0064, iter [01700, 05004], lr: 0.001000, loss: 2.0371
2022-07-16 06:41:22 - train: epoch 0064, iter [01800, 05004], lr: 0.001000, loss: 2.1914
2022-07-16 06:41:56 - train: epoch 0064, iter [01900, 05004], lr: 0.001000, loss: 2.1509
2022-07-16 06:42:29 - train: epoch 0064, iter [02000, 05004], lr: 0.001000, loss: 2.0607
2022-07-16 06:43:02 - train: epoch 0064, iter [02100, 05004], lr: 0.001000, loss: 2.2862
2022-07-16 06:43:34 - train: epoch 0064, iter [02200, 05004], lr: 0.001000, loss: 2.4144
2022-07-16 06:44:09 - train: epoch 0064, iter [02300, 05004], lr: 0.001000, loss: 2.2873
2022-07-16 06:44:40 - train: epoch 0064, iter [02400, 05004], lr: 0.001000, loss: 2.3404
2022-07-16 06:45:13 - train: epoch 0064, iter [02500, 05004], lr: 0.001000, loss: 2.1756
2022-07-16 06:45:46 - train: epoch 0064, iter [02600, 05004], lr: 0.001000, loss: 2.1144
2022-07-16 06:46:19 - train: epoch 0064, iter [02700, 05004], lr: 0.001000, loss: 2.1385
2022-07-16 06:46:52 - train: epoch 0064, iter [02800, 05004], lr: 0.001000, loss: 2.0861
2022-07-16 06:47:25 - train: epoch 0064, iter [02900, 05004], lr: 0.001000, loss: 2.4152
2022-07-16 06:47:58 - train: epoch 0064, iter [03000, 05004], lr: 0.001000, loss: 2.1847
2022-07-16 06:48:31 - train: epoch 0064, iter [03100, 05004], lr: 0.001000, loss: 2.2588
2022-07-16 06:49:04 - train: epoch 0064, iter [03200, 05004], lr: 0.001000, loss: 2.1627
2022-07-16 06:49:36 - train: epoch 0064, iter [03300, 05004], lr: 0.001000, loss: 2.1019
2022-07-16 06:50:09 - train: epoch 0064, iter [03400, 05004], lr: 0.001000, loss: 2.2231
2022-07-16 06:50:43 - train: epoch 0064, iter [03500, 05004], lr: 0.001000, loss: 2.1777
2022-07-16 06:51:16 - train: epoch 0064, iter [03600, 05004], lr: 0.001000, loss: 2.1600
2022-07-16 06:51:49 - train: epoch 0064, iter [03700, 05004], lr: 0.001000, loss: 1.8005
2022-07-16 06:52:21 - train: epoch 0064, iter [03800, 05004], lr: 0.001000, loss: 2.3886
2022-07-16 06:52:55 - train: epoch 0064, iter [03900, 05004], lr: 0.001000, loss: 2.0286
2022-07-16 06:53:28 - train: epoch 0064, iter [04000, 05004], lr: 0.001000, loss: 2.1980
2022-07-16 06:54:02 - train: epoch 0064, iter [04100, 05004], lr: 0.001000, loss: 2.2852
2022-07-16 06:54:34 - train: epoch 0064, iter [04200, 05004], lr: 0.001000, loss: 2.0779
2022-07-16 06:55:08 - train: epoch 0064, iter [04300, 05004], lr: 0.001000, loss: 2.3828
2022-07-16 06:55:41 - train: epoch 0064, iter [04400, 05004], lr: 0.001000, loss: 2.1068
2022-07-16 06:56:14 - train: epoch 0064, iter [04500, 05004], lr: 0.001000, loss: 2.1116
2022-07-16 06:56:47 - train: epoch 0064, iter [04600, 05004], lr: 0.001000, loss: 2.4350
2022-07-16 06:57:20 - train: epoch 0064, iter [04700, 05004], lr: 0.001000, loss: 2.6165
2022-07-16 06:57:54 - train: epoch 0064, iter [04800, 05004], lr: 0.001000, loss: 2.1877
2022-07-16 06:58:26 - train: epoch 0064, iter [04900, 05004], lr: 0.001000, loss: 2.4164
2022-07-16 06:58:57 - train: epoch 0064, iter [05000, 05004], lr: 0.001000, loss: 2.0322
2022-07-16 06:58:58 - train: epoch 064, train_loss: 2.2115
2022-07-16 07:00:12 - eval: epoch: 064, acc1: 56.550%, acc5: 79.440%, test_loss: 1.9242, per_image_load_time: 2.699ms, per_image_inference_time: 0.144ms
2022-07-16 07:00:12 - until epoch: 064, best_acc1: 56.662%
2022-07-16 07:00:12 - epoch 065 lr: 0.001000
2022-07-16 07:00:50 - train: epoch 0065, iter [00100, 05004], lr: 0.001000, loss: 2.3200
2022-07-16 07:01:24 - train: epoch 0065, iter [00200, 05004], lr: 0.001000, loss: 2.0691
2022-07-16 07:01:56 - train: epoch 0065, iter [00300, 05004], lr: 0.001000, loss: 2.1519
2022-07-16 07:02:29 - train: epoch 0065, iter [00400, 05004], lr: 0.001000, loss: 2.2999
2022-07-16 07:03:01 - train: epoch 0065, iter [00500, 05004], lr: 0.001000, loss: 2.3367
2022-07-16 07:03:35 - train: epoch 0065, iter [00600, 05004], lr: 0.001000, loss: 2.3526
2022-07-16 07:04:07 - train: epoch 0065, iter [00700, 05004], lr: 0.001000, loss: 2.2229
2022-07-16 07:04:40 - train: epoch 0065, iter [00800, 05004], lr: 0.001000, loss: 2.1909
2022-07-16 07:05:13 - train: epoch 0065, iter [00900, 05004], lr: 0.001000, loss: 2.0120
2022-07-16 07:05:46 - train: epoch 0065, iter [01000, 05004], lr: 0.001000, loss: 2.1197
2022-07-16 07:06:19 - train: epoch 0065, iter [01100, 05004], lr: 0.001000, loss: 2.0548
2022-07-16 07:06:53 - train: epoch 0065, iter [01200, 05004], lr: 0.001000, loss: 2.4710
2022-07-16 07:07:26 - train: epoch 0065, iter [01300, 05004], lr: 0.001000, loss: 2.2193
2022-07-16 07:07:59 - train: epoch 0065, iter [01400, 05004], lr: 0.001000, loss: 2.0357
2022-07-16 07:08:32 - train: epoch 0065, iter [01500, 05004], lr: 0.001000, loss: 2.1955
2022-07-16 07:09:06 - train: epoch 0065, iter [01600, 05004], lr: 0.001000, loss: 2.4348
2022-07-16 07:09:39 - train: epoch 0065, iter [01700, 05004], lr: 0.001000, loss: 2.2292
2022-07-16 07:10:12 - train: epoch 0065, iter [01800, 05004], lr: 0.001000, loss: 2.0698
2022-07-16 07:10:46 - train: epoch 0065, iter [01900, 05004], lr: 0.001000, loss: 2.0497
2022-07-16 07:11:18 - train: epoch 0065, iter [02000, 05004], lr: 0.001000, loss: 2.2177
2022-07-16 07:11:53 - train: epoch 0065, iter [02100, 05004], lr: 0.001000, loss: 2.2067
2022-07-16 07:12:25 - train: epoch 0065, iter [02200, 05004], lr: 0.001000, loss: 2.1850
2022-07-16 07:12:59 - train: epoch 0065, iter [02300, 05004], lr: 0.001000, loss: 1.9460
2022-07-16 07:13:31 - train: epoch 0065, iter [02400, 05004], lr: 0.001000, loss: 2.1794
2022-07-16 07:14:05 - train: epoch 0065, iter [02500, 05004], lr: 0.001000, loss: 2.1276
2022-07-16 07:14:39 - train: epoch 0065, iter [02600, 05004], lr: 0.001000, loss: 2.3672
2022-07-16 07:15:12 - train: epoch 0065, iter [02700, 05004], lr: 0.001000, loss: 2.2729
2022-07-16 07:15:46 - train: epoch 0065, iter [02800, 05004], lr: 0.001000, loss: 2.1355
2022-07-16 07:16:19 - train: epoch 0065, iter [02900, 05004], lr: 0.001000, loss: 2.2227
2022-07-16 07:16:53 - train: epoch 0065, iter [03000, 05004], lr: 0.001000, loss: 2.0122
2022-07-16 07:17:25 - train: epoch 0065, iter [03100, 05004], lr: 0.001000, loss: 2.0915
2022-07-16 07:17:59 - train: epoch 0065, iter [03200, 05004], lr: 0.001000, loss: 2.2612
2022-07-16 07:18:32 - train: epoch 0065, iter [03300, 05004], lr: 0.001000, loss: 2.1413
2022-07-16 07:19:05 - train: epoch 0065, iter [03400, 05004], lr: 0.001000, loss: 1.9239
2022-07-16 07:19:40 - train: epoch 0065, iter [03500, 05004], lr: 0.001000, loss: 2.5600
2022-07-16 07:20:12 - train: epoch 0065, iter [03600, 05004], lr: 0.001000, loss: 2.3337
2022-07-16 07:20:46 - train: epoch 0065, iter [03700, 05004], lr: 0.001000, loss: 2.0771
2022-07-16 07:21:18 - train: epoch 0065, iter [03800, 05004], lr: 0.001000, loss: 2.1130
2022-07-16 07:21:52 - train: epoch 0065, iter [03900, 05004], lr: 0.001000, loss: 2.3924
2022-07-16 07:22:25 - train: epoch 0065, iter [04000, 05004], lr: 0.001000, loss: 2.1087
2022-07-16 07:22:58 - train: epoch 0065, iter [04100, 05004], lr: 0.001000, loss: 2.1280
2022-07-16 07:23:31 - train: epoch 0065, iter [04200, 05004], lr: 0.001000, loss: 2.2388
2022-07-16 07:24:05 - train: epoch 0065, iter [04300, 05004], lr: 0.001000, loss: 1.9804
2022-07-16 07:24:38 - train: epoch 0065, iter [04400, 05004], lr: 0.001000, loss: 2.1078
2022-07-16 07:25:10 - train: epoch 0065, iter [04500, 05004], lr: 0.001000, loss: 2.1316
2022-07-16 07:25:44 - train: epoch 0065, iter [04600, 05004], lr: 0.001000, loss: 2.1725
2022-07-16 07:26:18 - train: epoch 0065, iter [04700, 05004], lr: 0.001000, loss: 2.1656
2022-07-16 07:26:51 - train: epoch 0065, iter [04800, 05004], lr: 0.001000, loss: 1.9867
2022-07-16 07:27:25 - train: epoch 0065, iter [04900, 05004], lr: 0.001000, loss: 2.1401
2022-07-16 07:27:55 - train: epoch 0065, iter [05000, 05004], lr: 0.001000, loss: 2.1977
2022-07-16 07:27:56 - train: epoch 065, train_loss: 2.2053
2022-07-16 07:29:11 - eval: epoch: 065, acc1: 56.698%, acc5: 79.250%, test_loss: 1.9215, per_image_load_time: 1.723ms, per_image_inference_time: 0.136ms
2022-07-16 07:29:11 - until epoch: 065, best_acc1: 56.698%
2022-07-16 07:29:11 - epoch 066 lr: 0.001000
2022-07-16 07:29:49 - train: epoch 0066, iter [00100, 05004], lr: 0.001000, loss: 2.1690
2022-07-16 07:30:22 - train: epoch 0066, iter [00200, 05004], lr: 0.001000, loss: 2.3830
2022-07-16 07:30:56 - train: epoch 0066, iter [00300, 05004], lr: 0.001000, loss: 2.0884
2022-07-16 07:31:27 - train: epoch 0066, iter [00400, 05004], lr: 0.001000, loss: 1.9055
2022-07-16 07:32:02 - train: epoch 0066, iter [00500, 05004], lr: 0.001000, loss: 2.1874
2022-07-16 07:32:34 - train: epoch 0066, iter [00600, 05004], lr: 0.001000, loss: 2.2080
2022-07-16 07:33:07 - train: epoch 0066, iter [00700, 05004], lr: 0.001000, loss: 2.0835
2022-07-16 07:33:39 - train: epoch 0066, iter [00800, 05004], lr: 0.001000, loss: 2.6496
2022-07-16 07:34:12 - train: epoch 0066, iter [00900, 05004], lr: 0.001000, loss: 2.3473
2022-07-16 07:34:46 - train: epoch 0066, iter [01000, 05004], lr: 0.001000, loss: 2.3101
2022-07-16 07:35:18 - train: epoch 0066, iter [01100, 05004], lr: 0.001000, loss: 2.2535
2022-07-16 07:35:51 - train: epoch 0066, iter [01200, 05004], lr: 0.001000, loss: 2.3975
2022-07-16 07:36:24 - train: epoch 0066, iter [01300, 05004], lr: 0.001000, loss: 2.4650
2022-07-16 07:36:57 - train: epoch 0066, iter [01400, 05004], lr: 0.001000, loss: 2.0270
2022-07-16 07:37:30 - train: epoch 0066, iter [01500, 05004], lr: 0.001000, loss: 2.2506
2022-07-16 07:38:02 - train: epoch 0066, iter [01600, 05004], lr: 0.001000, loss: 2.3639
2022-07-16 07:38:36 - train: epoch 0066, iter [01700, 05004], lr: 0.001000, loss: 2.2179
2022-07-16 07:39:09 - train: epoch 0066, iter [01800, 05004], lr: 0.001000, loss: 1.8358
2022-07-16 07:39:41 - train: epoch 0066, iter [01900, 05004], lr: 0.001000, loss: 2.3929
2022-07-16 07:40:14 - train: epoch 0066, iter [02000, 05004], lr: 0.001000, loss: 2.2092
2022-07-16 07:40:47 - train: epoch 0066, iter [02100, 05004], lr: 0.001000, loss: 2.1933
2022-07-16 07:41:20 - train: epoch 0066, iter [02200, 05004], lr: 0.001000, loss: 2.2504
2022-07-16 07:41:54 - train: epoch 0066, iter [02300, 05004], lr: 0.001000, loss: 2.4163
2022-07-16 07:42:27 - train: epoch 0066, iter [02400, 05004], lr: 0.001000, loss: 2.0755
2022-07-16 07:43:00 - train: epoch 0066, iter [02500, 05004], lr: 0.001000, loss: 2.1479
2022-07-16 07:43:32 - train: epoch 0066, iter [02600, 05004], lr: 0.001000, loss: 2.1290
2022-07-16 07:44:06 - train: epoch 0066, iter [02700, 05004], lr: 0.001000, loss: 2.2814
2022-07-16 07:44:38 - train: epoch 0066, iter [02800, 05004], lr: 0.001000, loss: 2.3189
2022-07-16 07:45:11 - train: epoch 0066, iter [02900, 05004], lr: 0.001000, loss: 2.3319
2022-07-16 07:45:44 - train: epoch 0066, iter [03000, 05004], lr: 0.001000, loss: 2.0387
2022-07-16 07:46:17 - train: epoch 0066, iter [03100, 05004], lr: 0.001000, loss: 2.1794
2022-07-16 07:46:50 - train: epoch 0066, iter [03200, 05004], lr: 0.001000, loss: 2.0936
2022-07-16 07:47:24 - train: epoch 0066, iter [03300, 05004], lr: 0.001000, loss: 2.1143
2022-07-16 07:47:56 - train: epoch 0066, iter [03400, 05004], lr: 0.001000, loss: 2.3762
2022-07-16 07:48:30 - train: epoch 0066, iter [03500, 05004], lr: 0.001000, loss: 2.3002
2022-07-16 07:49:03 - train: epoch 0066, iter [03600, 05004], lr: 0.001000, loss: 2.1739
2022-07-16 07:49:36 - train: epoch 0066, iter [03700, 05004], lr: 0.001000, loss: 2.0790
2022-07-16 07:50:10 - train: epoch 0066, iter [03800, 05004], lr: 0.001000, loss: 2.1006
2022-07-16 07:50:42 - train: epoch 0066, iter [03900, 05004], lr: 0.001000, loss: 2.0770
2022-07-16 07:51:16 - train: epoch 0066, iter [04000, 05004], lr: 0.001000, loss: 2.2434
2022-07-16 07:51:48 - train: epoch 0066, iter [04100, 05004], lr: 0.001000, loss: 2.1496
2022-07-16 07:52:21 - train: epoch 0066, iter [04200, 05004], lr: 0.001000, loss: 2.0728
2022-07-16 07:52:55 - train: epoch 0066, iter [04300, 05004], lr: 0.001000, loss: 1.9456
2022-07-16 07:53:26 - train: epoch 0066, iter [04400, 05004], lr: 0.001000, loss: 2.1072
2022-07-16 07:54:00 - train: epoch 0066, iter [04500, 05004], lr: 0.001000, loss: 2.3679
2022-07-16 07:54:34 - train: epoch 0066, iter [04600, 05004], lr: 0.001000, loss: 2.4438
2022-07-16 07:55:07 - train: epoch 0066, iter [04700, 05004], lr: 0.001000, loss: 2.1845
2022-07-16 07:55:41 - train: epoch 0066, iter [04800, 05004], lr: 0.001000, loss: 2.1661
2022-07-16 07:56:14 - train: epoch 0066, iter [04900, 05004], lr: 0.001000, loss: 2.1685
2022-07-16 07:56:45 - train: epoch 0066, iter [05000, 05004], lr: 0.001000, loss: 2.0211
2022-07-16 07:56:46 - train: epoch 066, train_loss: 2.2022
2022-07-16 07:58:00 - eval: epoch: 066, acc1: 56.680%, acc5: 79.386%, test_loss: 1.9193, per_image_load_time: 2.749ms, per_image_inference_time: 0.126ms
2022-07-16 07:58:00 - until epoch: 066, best_acc1: 56.698%
2022-07-16 07:58:00 - epoch 067 lr: 0.001000
2022-07-16 07:58:37 - train: epoch 0067, iter [00100, 05004], lr: 0.001000, loss: 2.2535
2022-07-16 07:59:10 - train: epoch 0067, iter [00200, 05004], lr: 0.001000, loss: 2.2166
2022-07-16 07:59:43 - train: epoch 0067, iter [00300, 05004], lr: 0.001000, loss: 2.4756
2022-07-16 08:00:14 - train: epoch 0067, iter [00400, 05004], lr: 0.001000, loss: 2.0181
2022-07-16 08:00:48 - train: epoch 0067, iter [00500, 05004], lr: 0.001000, loss: 2.0601
2022-07-16 08:01:20 - train: epoch 0067, iter [00600, 05004], lr: 0.001000, loss: 2.1491
2022-07-16 08:01:52 - train: epoch 0067, iter [00700, 05004], lr: 0.001000, loss: 2.2180
2022-07-16 08:02:25 - train: epoch 0067, iter [00800, 05004], lr: 0.001000, loss: 2.4161
2022-07-16 08:02:59 - train: epoch 0067, iter [00900, 05004], lr: 0.001000, loss: 2.4928
2022-07-16 08:03:31 - train: epoch 0067, iter [01000, 05004], lr: 0.001000, loss: 1.9845
2022-07-16 08:04:04 - train: epoch 0067, iter [01100, 05004], lr: 0.001000, loss: 2.1490
2022-07-16 08:04:36 - train: epoch 0067, iter [01200, 05004], lr: 0.001000, loss: 2.1481
2022-07-16 08:05:10 - train: epoch 0067, iter [01300, 05004], lr: 0.001000, loss: 2.3791
2022-07-16 08:05:42 - train: epoch 0067, iter [01400, 05004], lr: 0.001000, loss: 2.1152
2022-07-16 08:06:16 - train: epoch 0067, iter [01500, 05004], lr: 0.001000, loss: 2.1739
2022-07-16 08:06:48 - train: epoch 0067, iter [01600, 05004], lr: 0.001000, loss: 2.0813
2022-07-16 08:07:22 - train: epoch 0067, iter [01700, 05004], lr: 0.001000, loss: 2.0881
2022-07-16 08:07:54 - train: epoch 0067, iter [01800, 05004], lr: 0.001000, loss: 2.4634
2022-07-16 08:08:29 - train: epoch 0067, iter [01900, 05004], lr: 0.001000, loss: 2.1052
2022-07-16 08:09:01 - train: epoch 0067, iter [02000, 05004], lr: 0.001000, loss: 2.4122
2022-07-16 08:09:34 - train: epoch 0067, iter [02100, 05004], lr: 0.001000, loss: 1.9854
2022-07-16 08:10:07 - train: epoch 0067, iter [02200, 05004], lr: 0.001000, loss: 2.2432
2022-07-16 08:10:42 - train: epoch 0067, iter [02300, 05004], lr: 0.001000, loss: 2.1518
2022-07-16 08:11:13 - train: epoch 0067, iter [02400, 05004], lr: 0.001000, loss: 2.2584
2022-07-16 08:11:47 - train: epoch 0067, iter [02500, 05004], lr: 0.001000, loss: 2.1528
2022-07-16 08:12:20 - train: epoch 0067, iter [02600, 05004], lr: 0.001000, loss: 2.1460
2022-07-16 08:12:54 - train: epoch 0067, iter [02700, 05004], lr: 0.001000, loss: 1.9304
2022-07-16 08:13:26 - train: epoch 0067, iter [02800, 05004], lr: 0.001000, loss: 2.4153
2022-07-16 08:14:00 - train: epoch 0067, iter [02900, 05004], lr: 0.001000, loss: 2.2928
2022-07-16 08:14:33 - train: epoch 0067, iter [03000, 05004], lr: 0.001000, loss: 2.1170
2022-07-16 08:15:06 - train: epoch 0067, iter [03100, 05004], lr: 0.001000, loss: 1.9281
2022-07-16 08:15:39 - train: epoch 0067, iter [03200, 05004], lr: 0.001000, loss: 2.3258
2022-07-16 08:16:13 - train: epoch 0067, iter [03300, 05004], lr: 0.001000, loss: 1.9697
2022-07-16 08:16:45 - train: epoch 0067, iter [03400, 05004], lr: 0.001000, loss: 2.1957
2022-07-16 08:17:19 - train: epoch 0067, iter [03500, 05004], lr: 0.001000, loss: 2.1919
2022-07-16 08:17:52 - train: epoch 0067, iter [03600, 05004], lr: 0.001000, loss: 2.1885
2022-07-16 08:18:26 - train: epoch 0067, iter [03700, 05004], lr: 0.001000, loss: 2.3004
2022-07-16 08:18:59 - train: epoch 0067, iter [03800, 05004], lr: 0.001000, loss: 2.1009
2022-07-16 08:19:31 - train: epoch 0067, iter [03900, 05004], lr: 0.001000, loss: 2.3732
2022-07-16 08:20:05 - train: epoch 0067, iter [04000, 05004], lr: 0.001000, loss: 2.2332
2022-07-16 08:20:37 - train: epoch 0067, iter [04100, 05004], lr: 0.001000, loss: 2.4331
2022-07-16 08:21:10 - train: epoch 0067, iter [04200, 05004], lr: 0.001000, loss: 2.4069
2022-07-16 08:21:44 - train: epoch 0067, iter [04300, 05004], lr: 0.001000, loss: 1.9477
2022-07-16 08:22:17 - train: epoch 0067, iter [04400, 05004], lr: 0.001000, loss: 2.3264
2022-07-16 08:22:51 - train: epoch 0067, iter [04500, 05004], lr: 0.001000, loss: 2.1374
2022-07-16 08:23:24 - train: epoch 0067, iter [04600, 05004], lr: 0.001000, loss: 1.8231
2022-07-16 08:23:59 - train: epoch 0067, iter [04700, 05004], lr: 0.001000, loss: 2.1029
2022-07-16 08:24:30 - train: epoch 0067, iter [04800, 05004], lr: 0.001000, loss: 1.8871
2022-07-16 08:25:05 - train: epoch 0067, iter [04900, 05004], lr: 0.001000, loss: 2.1625
2022-07-16 08:25:36 - train: epoch 0067, iter [05000, 05004], lr: 0.001000, loss: 2.3089
2022-07-16 08:25:36 - train: epoch 067, train_loss: 2.1982
2022-07-16 08:26:50 - eval: epoch: 067, acc1: 56.688%, acc5: 79.438%, test_loss: 1.9195, per_image_load_time: 1.717ms, per_image_inference_time: 0.135ms
2022-07-16 08:26:50 - until epoch: 067, best_acc1: 56.698%
2022-07-16 08:26:50 - epoch 068 lr: 0.001000
2022-07-16 08:27:29 - train: epoch 0068, iter [00100, 05004], lr: 0.001000, loss: 2.3682
2022-07-16 08:28:02 - train: epoch 0068, iter [00200, 05004], lr: 0.001000, loss: 2.2665
2022-07-16 08:28:35 - train: epoch 0068, iter [00300, 05004], lr: 0.001000, loss: 2.4063
2022-07-16 08:29:08 - train: epoch 0068, iter [00400, 05004], lr: 0.001000, loss: 2.1556
2022-07-16 08:29:41 - train: epoch 0068, iter [00500, 05004], lr: 0.001000, loss: 2.1161
2022-07-16 08:30:14 - train: epoch 0068, iter [00600, 05004], lr: 0.001000, loss: 2.1759
2022-07-16 08:30:47 - train: epoch 0068, iter [00700, 05004], lr: 0.001000, loss: 2.4479
2022-07-16 08:31:20 - train: epoch 0068, iter [00800, 05004], lr: 0.001000, loss: 2.0761
2022-07-16 08:31:53 - train: epoch 0068, iter [00900, 05004], lr: 0.001000, loss: 2.0622
2022-07-16 08:32:26 - train: epoch 0068, iter [01000, 05004], lr: 0.001000, loss: 2.1565
2022-07-16 08:32:58 - train: epoch 0068, iter [01100, 05004], lr: 0.001000, loss: 2.3917
2022-07-16 08:33:32 - train: epoch 0068, iter [01200, 05004], lr: 0.001000, loss: 2.0208
2022-07-16 08:34:04 - train: epoch 0068, iter [01300, 05004], lr: 0.001000, loss: 2.0784
2022-07-16 08:34:38 - train: epoch 0068, iter [01400, 05004], lr: 0.001000, loss: 2.2069
2022-07-16 08:35:10 - train: epoch 0068, iter [01500, 05004], lr: 0.001000, loss: 2.3258
2022-07-16 08:35:44 - train: epoch 0068, iter [01600, 05004], lr: 0.001000, loss: 1.9676
2022-07-16 08:36:16 - train: epoch 0068, iter [01700, 05004], lr: 0.001000, loss: 2.3685
2022-07-16 08:36:50 - train: epoch 0068, iter [01800, 05004], lr: 0.001000, loss: 2.2751
2022-07-16 08:37:22 - train: epoch 0068, iter [01900, 05004], lr: 0.001000, loss: 2.2514
2022-07-16 08:37:56 - train: epoch 0068, iter [02000, 05004], lr: 0.001000, loss: 2.2031
2022-07-16 08:38:27 - train: epoch 0068, iter [02100, 05004], lr: 0.001000, loss: 2.1495
2022-07-16 08:39:01 - train: epoch 0068, iter [02200, 05004], lr: 0.001000, loss: 2.1443
2022-07-16 08:39:35 - train: epoch 0068, iter [02300, 05004], lr: 0.001000, loss: 2.1034
2022-07-16 08:40:08 - train: epoch 0068, iter [02400, 05004], lr: 0.001000, loss: 2.2859
2022-07-16 08:40:41 - train: epoch 0068, iter [02500, 05004], lr: 0.001000, loss: 2.2405
2022-07-16 08:41:14 - train: epoch 0068, iter [02600, 05004], lr: 0.001000, loss: 2.1047
2022-07-16 08:41:48 - train: epoch 0068, iter [02700, 05004], lr: 0.001000, loss: 2.2372
2022-07-16 08:42:20 - train: epoch 0068, iter [02800, 05004], lr: 0.001000, loss: 2.2723
2022-07-16 08:42:53 - train: epoch 0068, iter [02900, 05004], lr: 0.001000, loss: 2.1609
2022-07-16 08:43:25 - train: epoch 0068, iter [03000, 05004], lr: 0.001000, loss: 2.4693
2022-07-16 08:43:59 - train: epoch 0068, iter [03100, 05004], lr: 0.001000, loss: 1.9611
2022-07-16 08:44:32 - train: epoch 0068, iter [03200, 05004], lr: 0.001000, loss: 2.4411
2022-07-16 08:45:06 - train: epoch 0068, iter [03300, 05004], lr: 0.001000, loss: 2.3711
2022-07-16 08:45:39 - train: epoch 0068, iter [03400, 05004], lr: 0.001000, loss: 2.0663
2022-07-16 08:46:11 - train: epoch 0068, iter [03500, 05004], lr: 0.001000, loss: 2.2966
2022-07-16 08:46:44 - train: epoch 0068, iter [03600, 05004], lr: 0.001000, loss: 1.9856
2022-07-16 08:47:19 - train: epoch 0068, iter [03700, 05004], lr: 0.001000, loss: 2.2433
2022-07-16 08:47:51 - train: epoch 0068, iter [03800, 05004], lr: 0.001000, loss: 2.3230
2022-07-16 08:48:25 - train: epoch 0068, iter [03900, 05004], lr: 0.001000, loss: 2.3019
2022-07-16 08:48:58 - train: epoch 0068, iter [04000, 05004], lr: 0.001000, loss: 2.2053
2022-07-16 08:49:30 - train: epoch 0068, iter [04100, 05004], lr: 0.001000, loss: 1.9826
2022-07-16 08:50:04 - train: epoch 0068, iter [04200, 05004], lr: 0.001000, loss: 2.2727
2022-07-16 08:50:38 - train: epoch 0068, iter [04300, 05004], lr: 0.001000, loss: 2.2140
2022-07-16 08:51:11 - train: epoch 0068, iter [04400, 05004], lr: 0.001000, loss: 2.2485
2022-07-16 08:51:44 - train: epoch 0068, iter [04500, 05004], lr: 0.001000, loss: 2.3140
2022-07-16 08:52:18 - train: epoch 0068, iter [04600, 05004], lr: 0.001000, loss: 2.2699
2022-07-16 08:52:50 - train: epoch 0068, iter [04700, 05004], lr: 0.001000, loss: 2.4493
2022-07-16 08:53:24 - train: epoch 0068, iter [04800, 05004], lr: 0.001000, loss: 2.3791
2022-07-16 08:53:57 - train: epoch 0068, iter [04900, 05004], lr: 0.001000, loss: 2.4177
2022-07-16 08:54:29 - train: epoch 0068, iter [05000, 05004], lr: 0.001000, loss: 2.3703
2022-07-16 08:54:29 - train: epoch 068, train_loss: 2.1948
2022-07-16 08:55:43 - eval: epoch: 068, acc1: 56.816%, acc5: 79.416%, test_loss: 1.9166, per_image_load_time: 2.751ms, per_image_inference_time: 0.124ms
2022-07-16 08:55:43 - until epoch: 068, best_acc1: 56.816%
2022-07-16 08:55:43 - epoch 069 lr: 0.001000
2022-07-16 08:56:22 - train: epoch 0069, iter [00100, 05004], lr: 0.001000, loss: 2.4834
2022-07-16 08:56:55 - train: epoch 0069, iter [00200, 05004], lr: 0.001000, loss: 2.4225
2022-07-16 08:57:28 - train: epoch 0069, iter [00300, 05004], lr: 0.001000, loss: 2.0942
2022-07-16 08:58:01 - train: epoch 0069, iter [00400, 05004], lr: 0.001000, loss: 2.0333
2022-07-16 08:58:34 - train: epoch 0069, iter [00500, 05004], lr: 0.001000, loss: 2.0344
2022-07-16 08:59:07 - train: epoch 0069, iter [00600, 05004], lr: 0.001000, loss: 2.0099
2022-07-16 08:59:40 - train: epoch 0069, iter [00700, 05004], lr: 0.001000, loss: 2.1830
2022-07-16 09:00:14 - train: epoch 0069, iter [00800, 05004], lr: 0.001000, loss: 2.2967
2022-07-16 09:00:47 - train: epoch 0069, iter [00900, 05004], lr: 0.001000, loss: 1.9909
2022-07-16 09:01:21 - train: epoch 0069, iter [01000, 05004], lr: 0.001000, loss: 2.1358
2022-07-16 09:01:54 - train: epoch 0069, iter [01100, 05004], lr: 0.001000, loss: 2.1725
2022-07-16 09:02:28 - train: epoch 0069, iter [01200, 05004], lr: 0.001000, loss: 2.0597
2022-07-16 09:03:00 - train: epoch 0069, iter [01300, 05004], lr: 0.001000, loss: 2.5574
2022-07-16 09:03:33 - train: epoch 0069, iter [01400, 05004], lr: 0.001000, loss: 2.2334
2022-07-16 09:04:06 - train: epoch 0069, iter [01500, 05004], lr: 0.001000, loss: 2.1451
2022-07-16 09:04:39 - train: epoch 0069, iter [01600, 05004], lr: 0.001000, loss: 2.3678
2022-07-16 09:05:11 - train: epoch 0069, iter [01700, 05004], lr: 0.001000, loss: 2.2148
2022-07-16 09:05:45 - train: epoch 0069, iter [01800, 05004], lr: 0.001000, loss: 1.9314
2022-07-16 09:06:18 - train: epoch 0069, iter [01900, 05004], lr: 0.001000, loss: 2.2815
2022-07-16 09:06:52 - train: epoch 0069, iter [02000, 05004], lr: 0.001000, loss: 2.0220
2022-07-16 09:07:25 - train: epoch 0069, iter [02100, 05004], lr: 0.001000, loss: 2.2528
2022-07-16 09:07:58 - train: epoch 0069, iter [02200, 05004], lr: 0.001000, loss: 2.2270
2022-07-16 09:08:31 - train: epoch 0069, iter [02300, 05004], lr: 0.001000, loss: 2.0804
2022-07-16 09:09:05 - train: epoch 0069, iter [02400, 05004], lr: 0.001000, loss: 2.2265
2022-07-16 09:09:38 - train: epoch 0069, iter [02500, 05004], lr: 0.001000, loss: 2.0943
2022-07-16 09:10:12 - train: epoch 0069, iter [02600, 05004], lr: 0.001000, loss: 2.3121
2022-07-16 09:10:45 - train: epoch 0069, iter [02700, 05004], lr: 0.001000, loss: 2.4811
2022-07-16 09:11:18 - train: epoch 0069, iter [02800, 05004], lr: 0.001000, loss: 2.4304
2022-07-16 09:11:51 - train: epoch 0069, iter [02900, 05004], lr: 0.001000, loss: 2.0997
2022-07-16 09:12:24 - train: epoch 0069, iter [03000, 05004], lr: 0.001000, loss: 2.0551
2022-07-16 09:12:57 - train: epoch 0069, iter [03100, 05004], lr: 0.001000, loss: 2.1219
2022-07-16 09:13:31 - train: epoch 0069, iter [03200, 05004], lr: 0.001000, loss: 2.1161
2022-07-16 09:14:03 - train: epoch 0069, iter [03300, 05004], lr: 0.001000, loss: 2.1655
2022-07-16 09:14:37 - train: epoch 0069, iter [03400, 05004], lr: 0.001000, loss: 2.1818
2022-07-16 09:15:11 - train: epoch 0069, iter [03500, 05004], lr: 0.001000, loss: 2.0274
2022-07-16 09:15:43 - train: epoch 0069, iter [03600, 05004], lr: 0.001000, loss: 1.9661
2022-07-16 09:16:17 - train: epoch 0069, iter [03700, 05004], lr: 0.001000, loss: 2.2652
2022-07-16 09:16:51 - train: epoch 0069, iter [03800, 05004], lr: 0.001000, loss: 2.3436
2022-07-16 09:17:23 - train: epoch 0069, iter [03900, 05004], lr: 0.001000, loss: 2.4011
2022-07-16 09:17:56 - train: epoch 0069, iter [04000, 05004], lr: 0.001000, loss: 2.3221
2022-07-16 09:18:28 - train: epoch 0069, iter [04100, 05004], lr: 0.001000, loss: 2.3099
2022-07-16 09:19:02 - train: epoch 0069, iter [04200, 05004], lr: 0.001000, loss: 2.0682
2022-07-16 09:19:35 - train: epoch 0069, iter [04300, 05004], lr: 0.001000, loss: 2.2682
2022-07-16 09:20:08 - train: epoch 0069, iter [04400, 05004], lr: 0.001000, loss: 2.1527
2022-07-16 09:20:41 - train: epoch 0069, iter [04500, 05004], lr: 0.001000, loss: 2.3252
2022-07-16 09:21:15 - train: epoch 0069, iter [04600, 05004], lr: 0.001000, loss: 2.3488
2022-07-16 09:21:47 - train: epoch 0069, iter [04700, 05004], lr: 0.001000, loss: 2.2271
2022-07-16 09:22:22 - train: epoch 0069, iter [04800, 05004], lr: 0.001000, loss: 2.1222
2022-07-16 09:22:54 - train: epoch 0069, iter [04900, 05004], lr: 0.001000, loss: 2.2218
2022-07-16 09:23:26 - train: epoch 0069, iter [05000, 05004], lr: 0.001000, loss: 2.4980
2022-07-16 09:23:26 - train: epoch 069, train_loss: 2.1944
2022-07-16 09:24:41 - eval: epoch: 069, acc1: 56.892%, acc5: 79.522%, test_loss: 1.9140, per_image_load_time: 2.540ms, per_image_inference_time: 0.123ms
2022-07-16 09:24:41 - until epoch: 069, best_acc1: 56.892%
2022-07-16 09:24:41 - epoch 070 lr: 0.001000
2022-07-16 09:25:19 - train: epoch 0070, iter [00100, 05004], lr: 0.001000, loss: 2.2862
2022-07-16 09:25:52 - train: epoch 0070, iter [00200, 05004], lr: 0.001000, loss: 2.2249
2022-07-16 09:26:27 - train: epoch 0070, iter [00300, 05004], lr: 0.001000, loss: 2.3733
2022-07-16 09:27:01 - train: epoch 0070, iter [00400, 05004], lr: 0.001000, loss: 2.1012
2022-07-16 09:27:34 - train: epoch 0070, iter [00500, 05004], lr: 0.001000, loss: 2.0534
2022-07-16 09:28:08 - train: epoch 0070, iter [00600, 05004], lr: 0.001000, loss: 2.0154
2022-07-16 09:28:42 - train: epoch 0070, iter [00700, 05004], lr: 0.001000, loss: 2.0172
2022-07-16 09:29:14 - train: epoch 0070, iter [00800, 05004], lr: 0.001000, loss: 2.1118
2022-07-16 09:29:47 - train: epoch 0070, iter [00900, 05004], lr: 0.001000, loss: 2.2622
2022-07-16 09:30:20 - train: epoch 0070, iter [01000, 05004], lr: 0.001000, loss: 2.1637
2022-07-16 09:30:53 - train: epoch 0070, iter [01100, 05004], lr: 0.001000, loss: 2.5194
2022-07-16 09:31:27 - train: epoch 0070, iter [01200, 05004], lr: 0.001000, loss: 2.0712
2022-07-16 09:31:59 - train: epoch 0070, iter [01300, 05004], lr: 0.001000, loss: 2.3369
2022-07-16 09:32:32 - train: epoch 0070, iter [01400, 05004], lr: 0.001000, loss: 2.2510
2022-07-16 09:33:06 - train: epoch 0070, iter [01500, 05004], lr: 0.001000, loss: 2.2129
2022-07-16 09:33:37 - train: epoch 0070, iter [01600, 05004], lr: 0.001000, loss: 2.2071
2022-07-16 09:34:12 - train: epoch 0070, iter [01700, 05004], lr: 0.001000, loss: 2.0731
2022-07-16 09:34:44 - train: epoch 0070, iter [01800, 05004], lr: 0.001000, loss: 1.9924
2022-07-16 09:35:17 - train: epoch 0070, iter [01900, 05004], lr: 0.001000, loss: 2.0265
2022-07-16 09:35:49 - train: epoch 0070, iter [02000, 05004], lr: 0.001000, loss: 2.2438
2022-07-16 09:36:23 - train: epoch 0070, iter [02100, 05004], lr: 0.001000, loss: 2.3319
2022-07-16 09:36:57 - train: epoch 0070, iter [02200, 05004], lr: 0.001000, loss: 2.3494
2022-07-16 09:37:29 - train: epoch 0070, iter [02300, 05004], lr: 0.001000, loss: 2.2775
2022-07-16 09:38:03 - train: epoch 0070, iter [02400, 05004], lr: 0.001000, loss: 2.4130
2022-07-16 09:38:36 - train: epoch 0070, iter [02500, 05004], lr: 0.001000, loss: 2.1082
2022-07-16 09:39:10 - train: epoch 0070, iter [02600, 05004], lr: 0.001000, loss: 2.3404
2022-07-16 09:39:42 - train: epoch 0070, iter [02700, 05004], lr: 0.001000, loss: 2.2298
2022-07-16 09:40:16 - train: epoch 0070, iter [02800, 05004], lr: 0.001000, loss: 2.1825
2022-07-16 09:40:48 - train: epoch 0070, iter [02900, 05004], lr: 0.001000, loss: 2.3583
2022-07-16 09:41:21 - train: epoch 0070, iter [03000, 05004], lr: 0.001000, loss: 2.1042
2022-07-16 09:41:54 - train: epoch 0070, iter [03100, 05004], lr: 0.001000, loss: 2.1518
2022-07-16 09:42:27 - train: epoch 0070, iter [03200, 05004], lr: 0.001000, loss: 2.2822
2022-07-16 09:43:00 - train: epoch 0070, iter [03300, 05004], lr: 0.001000, loss: 2.0253
2022-07-16 09:43:33 - train: epoch 0070, iter [03400, 05004], lr: 0.001000, loss: 2.1623
2022-07-16 09:44:07 - train: epoch 0070, iter [03500, 05004], lr: 0.001000, loss: 2.3265
2022-07-16 09:44:39 - train: epoch 0070, iter [03600, 05004], lr: 0.001000, loss: 2.2956
2022-07-16 09:45:14 - train: epoch 0070, iter [03700, 05004], lr: 0.001000, loss: 2.2011
2022-07-16 09:45:46 - train: epoch 0070, iter [03800, 05004], lr: 0.001000, loss: 2.1508
2022-07-16 09:46:19 - train: epoch 0070, iter [03900, 05004], lr: 0.001000, loss: 2.0804
2022-07-16 09:46:53 - train: epoch 0070, iter [04000, 05004], lr: 0.001000, loss: 1.9870
2022-07-16 09:47:25 - train: epoch 0070, iter [04100, 05004], lr: 0.001000, loss: 2.1374
2022-07-16 09:47:59 - train: epoch 0070, iter [04200, 05004], lr: 0.001000, loss: 2.0957
2022-07-16 09:48:32 - train: epoch 0070, iter [04300, 05004], lr: 0.001000, loss: 2.1961
2022-07-16 09:49:05 - train: epoch 0070, iter [04400, 05004], lr: 0.001000, loss: 2.2331
2022-07-16 09:49:38 - train: epoch 0070, iter [04500, 05004], lr: 0.001000, loss: 2.1985
2022-07-16 09:50:11 - train: epoch 0070, iter [04600, 05004], lr: 0.001000, loss: 2.4583
2022-07-16 09:50:45 - train: epoch 0070, iter [04700, 05004], lr: 0.001000, loss: 2.1660
2022-07-16 09:51:18 - train: epoch 0070, iter [04800, 05004], lr: 0.001000, loss: 2.3159
2022-07-16 09:51:52 - train: epoch 0070, iter [04900, 05004], lr: 0.001000, loss: 2.3337
2022-07-16 09:52:23 - train: epoch 0070, iter [05000, 05004], lr: 0.001000, loss: 2.2820
2022-07-16 09:52:24 - train: epoch 070, train_loss: 2.1913
2022-07-16 09:53:37 - eval: epoch: 070, acc1: 56.964%, acc5: 79.444%, test_loss: 1.9080, per_image_load_time: 2.270ms, per_image_inference_time: 0.133ms
2022-07-16 09:53:37 - until epoch: 070, best_acc1: 56.964%
2022-07-16 09:53:37 - epoch 071 lr: 0.001000
2022-07-16 09:54:15 - train: epoch 0071, iter [00100, 05004], lr: 0.001000, loss: 1.9488
2022-07-16 09:54:48 - train: epoch 0071, iter [00200, 05004], lr: 0.001000, loss: 2.1305
2022-07-16 09:55:21 - train: epoch 0071, iter [00300, 05004], lr: 0.001000, loss: 2.2122
2022-07-16 09:55:54 - train: epoch 0071, iter [00400, 05004], lr: 0.001000, loss: 2.2691
2022-07-16 09:56:28 - train: epoch 0071, iter [00500, 05004], lr: 0.001000, loss: 2.2484
2022-07-16 09:56:59 - train: epoch 0071, iter [00600, 05004], lr: 0.001000, loss: 2.2918
2022-07-16 09:57:32 - train: epoch 0071, iter [00700, 05004], lr: 0.001000, loss: 2.4388
2022-07-16 09:58:05 - train: epoch 0071, iter [00800, 05004], lr: 0.001000, loss: 2.0806
2022-07-16 09:58:39 - train: epoch 0071, iter [00900, 05004], lr: 0.001000, loss: 2.4514
2022-07-16 09:59:11 - train: epoch 0071, iter [01000, 05004], lr: 0.001000, loss: 2.3528
2022-07-16 09:59:44 - train: epoch 0071, iter [01100, 05004], lr: 0.001000, loss: 2.4986
2022-07-16 10:00:18 - train: epoch 0071, iter [01200, 05004], lr: 0.001000, loss: 2.3249
2022-07-16 10:00:50 - train: epoch 0071, iter [01300, 05004], lr: 0.001000, loss: 2.1188
2022-07-16 10:01:24 - train: epoch 0071, iter [01400, 05004], lr: 0.001000, loss: 2.2194
2022-07-16 10:01:56 - train: epoch 0071, iter [01500, 05004], lr: 0.001000, loss: 1.9546
2022-07-16 10:02:30 - train: epoch 0071, iter [01600, 05004], lr: 0.001000, loss: 1.9870
2022-07-16 10:03:02 - train: epoch 0071, iter [01700, 05004], lr: 0.001000, loss: 2.2352
2022-07-16 10:03:36 - train: epoch 0071, iter [01800, 05004], lr: 0.001000, loss: 2.1137
2022-07-16 10:04:08 - train: epoch 0071, iter [01900, 05004], lr: 0.001000, loss: 2.1324
2022-07-16 10:04:41 - train: epoch 0071, iter [02000, 05004], lr: 0.001000, loss: 2.2740
2022-07-16 10:05:13 - train: epoch 0071, iter [02100, 05004], lr: 0.001000, loss: 1.9584
2022-07-16 10:05:46 - train: epoch 0071, iter [02200, 05004], lr: 0.001000, loss: 1.9999
2022-07-16 10:06:19 - train: epoch 0071, iter [02300, 05004], lr: 0.001000, loss: 2.1433
2022-07-16 10:06:53 - train: epoch 0071, iter [02400, 05004], lr: 0.001000, loss: 2.1013
2022-07-16 10:07:25 - train: epoch 0071, iter [02500, 05004], lr: 0.001000, loss: 2.2388
2022-07-16 10:07:59 - train: epoch 0071, iter [02600, 05004], lr: 0.001000, loss: 1.9980
2022-07-16 10:08:32 - train: epoch 0071, iter [02700, 05004], lr: 0.001000, loss: 2.1563
2022-07-16 10:09:04 - train: epoch 0071, iter [02800, 05004], lr: 0.001000, loss: 2.3901
2022-07-16 10:09:37 - train: epoch 0071, iter [02900, 05004], lr: 0.001000, loss: 2.0730
2022-07-16 10:10:10 - train: epoch 0071, iter [03000, 05004], lr: 0.001000, loss: 2.3281
2022-07-16 10:10:43 - train: epoch 0071, iter [03100, 05004], lr: 0.001000, loss: 1.9980
2022-07-16 10:11:17 - train: epoch 0071, iter [03200, 05004], lr: 0.001000, loss: 2.0268
2022-07-16 10:11:49 - train: epoch 0071, iter [03300, 05004], lr: 0.001000, loss: 2.1662
2022-07-16 10:12:23 - train: epoch 0071, iter [03400, 05004], lr: 0.001000, loss: 2.0598
2022-07-16 10:12:56 - train: epoch 0071, iter [03500, 05004], lr: 0.001000, loss: 2.4956
2022-07-16 10:13:29 - train: epoch 0071, iter [03600, 05004], lr: 0.001000, loss: 2.3969
2022-07-16 10:14:01 - train: epoch 0071, iter [03700, 05004], lr: 0.001000, loss: 2.2649
2022-07-16 10:14:35 - train: epoch 0071, iter [03800, 05004], lr: 0.001000, loss: 2.0772
2022-07-16 10:15:07 - train: epoch 0071, iter [03900, 05004], lr: 0.001000, loss: 2.0462
2022-07-16 10:15:41 - train: epoch 0071, iter [04000, 05004], lr: 0.001000, loss: 2.3185
2022-07-16 10:16:13 - train: epoch 0071, iter [04100, 05004], lr: 0.001000, loss: 2.1409
2022-07-16 10:16:48 - train: epoch 0071, iter [04200, 05004], lr: 0.001000, loss: 2.4091
2022-07-16 10:17:19 - train: epoch 0071, iter [04300, 05004], lr: 0.001000, loss: 2.1791
2022-07-16 10:17:53 - train: epoch 0071, iter [04400, 05004], lr: 0.001000, loss: 2.3358
2022-07-16 10:18:26 - train: epoch 0071, iter [04500, 05004], lr: 0.001000, loss: 2.2750
2022-07-16 10:19:00 - train: epoch 0071, iter [04600, 05004], lr: 0.001000, loss: 2.1870
2022-07-16 10:19:33 - train: epoch 0071, iter [04700, 05004], lr: 0.001000, loss: 2.0754
2022-07-16 10:20:06 - train: epoch 0071, iter [04800, 05004], lr: 0.001000, loss: 2.1835
2022-07-16 10:20:39 - train: epoch 0071, iter [04900, 05004], lr: 0.001000, loss: 1.9184
2022-07-16 10:21:11 - train: epoch 0071, iter [05000, 05004], lr: 0.001000, loss: 2.1196
2022-07-16 10:21:11 - train: epoch 071, train_loss: 2.1889
2022-07-16 10:22:27 - eval: epoch: 071, acc1: 56.854%, acc5: 79.596%, test_loss: 1.9079, per_image_load_time: 2.788ms, per_image_inference_time: 0.123ms
2022-07-16 10:22:27 - until epoch: 071, best_acc1: 56.964%
2022-07-16 10:22:27 - epoch 072 lr: 0.001000
2022-07-16 10:23:05 - train: epoch 0072, iter [00100, 05004], lr: 0.001000, loss: 2.3678
2022-07-16 10:23:39 - train: epoch 0072, iter [00200, 05004], lr: 0.001000, loss: 2.0150
2022-07-16 10:24:12 - train: epoch 0072, iter [00300, 05004], lr: 0.001000, loss: 2.0435
2022-07-16 10:24:45 - train: epoch 0072, iter [00400, 05004], lr: 0.001000, loss: 2.2560
2022-07-16 10:25:18 - train: epoch 0072, iter [00500, 05004], lr: 0.001000, loss: 2.0469
2022-07-16 10:25:52 - train: epoch 0072, iter [00600, 05004], lr: 0.001000, loss: 2.1101
2022-07-16 10:26:24 - train: epoch 0072, iter [00700, 05004], lr: 0.001000, loss: 2.1100
2022-07-16 10:26:57 - train: epoch 0072, iter [00800, 05004], lr: 0.001000, loss: 2.3609
2022-07-16 10:27:29 - train: epoch 0072, iter [00900, 05004], lr: 0.001000, loss: 1.9599
2022-07-16 10:28:02 - train: epoch 0072, iter [01000, 05004], lr: 0.001000, loss: 2.0681
2022-07-16 10:28:36 - train: epoch 0072, iter [01100, 05004], lr: 0.001000, loss: 2.3340
2022-07-16 10:29:08 - train: epoch 0072, iter [01200, 05004], lr: 0.001000, loss: 2.0181
2022-07-16 10:29:42 - train: epoch 0072, iter [01300, 05004], lr: 0.001000, loss: 2.2253
2022-07-16 10:30:14 - train: epoch 0072, iter [01400, 05004], lr: 0.001000, loss: 2.1431
2022-07-16 10:30:48 - train: epoch 0072, iter [01500, 05004], lr: 0.001000, loss: 2.0326
2022-07-16 10:31:21 - train: epoch 0072, iter [01600, 05004], lr: 0.001000, loss: 2.1845
2022-07-16 10:31:55 - train: epoch 0072, iter [01700, 05004], lr: 0.001000, loss: 2.0837
2022-07-16 10:32:27 - train: epoch 0072, iter [01800, 05004], lr: 0.001000, loss: 1.9406
2022-07-16 10:33:00 - train: epoch 0072, iter [01900, 05004], lr: 0.001000, loss: 2.2340
2022-07-16 10:33:34 - train: epoch 0072, iter [02000, 05004], lr: 0.001000, loss: 2.2706
2022-07-16 10:34:07 - train: epoch 0072, iter [02100, 05004], lr: 0.001000, loss: 2.2678
2022-07-16 10:34:40 - train: epoch 0072, iter [02200, 05004], lr: 0.001000, loss: 2.3818
2022-07-16 10:35:14 - train: epoch 0072, iter [02300, 05004], lr: 0.001000, loss: 2.2875
2022-07-16 10:35:47 - train: epoch 0072, iter [02400, 05004], lr: 0.001000, loss: 2.1915
2022-07-16 10:36:20 - train: epoch 0072, iter [02500, 05004], lr: 0.001000, loss: 2.1842
2022-07-16 10:36:53 - train: epoch 0072, iter [02600, 05004], lr: 0.001000, loss: 2.0638
2022-07-16 10:37:25 - train: epoch 0072, iter [02700, 05004], lr: 0.001000, loss: 2.1915
2022-07-16 10:37:59 - train: epoch 0072, iter [02800, 05004], lr: 0.001000, loss: 2.2735
2022-07-16 10:38:32 - train: epoch 0072, iter [02900, 05004], lr: 0.001000, loss: 2.1108
2022-07-16 10:39:06 - train: epoch 0072, iter [03000, 05004], lr: 0.001000, loss: 2.1875
2022-07-16 10:39:38 - train: epoch 0072, iter [03100, 05004], lr: 0.001000, loss: 2.1823
2022-07-16 10:40:12 - train: epoch 0072, iter [03200, 05004], lr: 0.001000, loss: 2.0180
2022-07-16 10:40:44 - train: epoch 0072, iter [03300, 05004], lr: 0.001000, loss: 2.3064
2022-07-16 10:41:18 - train: epoch 0072, iter [03400, 05004], lr: 0.001000, loss: 2.4205
2022-07-16 10:41:51 - train: epoch 0072, iter [03500, 05004], lr: 0.001000, loss: 2.2756
2022-07-16 10:42:24 - train: epoch 0072, iter [03600, 05004], lr: 0.001000, loss: 2.2206
2022-07-16 10:42:57 - train: epoch 0072, iter [03700, 05004], lr: 0.001000, loss: 2.2846
2022-07-16 10:43:31 - train: epoch 0072, iter [03800, 05004], lr: 0.001000, loss: 2.3738
2022-07-16 10:44:03 - train: epoch 0072, iter [03900, 05004], lr: 0.001000, loss: 2.2866
2022-07-16 10:44:37 - train: epoch 0072, iter [04000, 05004], lr: 0.001000, loss: 2.1541
2022-07-16 10:45:09 - train: epoch 0072, iter [04100, 05004], lr: 0.001000, loss: 2.3813
2022-07-16 10:45:43 - train: epoch 0072, iter [04200, 05004], lr: 0.001000, loss: 2.1586
2022-07-16 10:46:16 - train: epoch 0072, iter [04300, 05004], lr: 0.001000, loss: 2.2081
2022-07-16 10:46:49 - train: epoch 0072, iter [04400, 05004], lr: 0.001000, loss: 2.0237
2022-07-16 10:47:22 - train: epoch 0072, iter [04500, 05004], lr: 0.001000, loss: 2.3144
2022-07-16 10:47:56 - train: epoch 0072, iter [04600, 05004], lr: 0.001000, loss: 2.1499
2022-07-16 10:48:28 - train: epoch 0072, iter [04700, 05004], lr: 0.001000, loss: 2.2425
2022-07-16 10:49:02 - train: epoch 0072, iter [04800, 05004], lr: 0.001000, loss: 2.3442
2022-07-16 10:49:35 - train: epoch 0072, iter [04900, 05004], lr: 0.001000, loss: 2.1695
2022-07-16 10:50:06 - train: epoch 0072, iter [05000, 05004], lr: 0.001000, loss: 2.1330
2022-07-16 10:50:07 - train: epoch 072, train_loss: 2.1889
2022-07-16 10:51:22 - eval: epoch: 072, acc1: 56.950%, acc5: 79.646%, test_loss: 1.9087, per_image_load_time: 1.217ms, per_image_inference_time: 0.139ms
2022-07-16 10:51:22 - until epoch: 072, best_acc1: 56.964%
2022-07-16 10:51:22 - epoch 073 lr: 0.001000
2022-07-16 10:52:01 - train: epoch 0073, iter [00100, 05004], lr: 0.001000, loss: 2.4719
2022-07-16 10:52:34 - train: epoch 0073, iter [00200, 05004], lr: 0.001000, loss: 2.1296
2022-07-16 10:53:07 - train: epoch 0073, iter [00300, 05004], lr: 0.001000, loss: 2.1753
2022-07-16 10:53:40 - train: epoch 0073, iter [00400, 05004], lr: 0.001000, loss: 1.9652
2022-07-16 10:54:13 - train: epoch 0073, iter [00500, 05004], lr: 0.001000, loss: 2.0163
2022-07-16 10:54:47 - train: epoch 0073, iter [00600, 05004], lr: 0.001000, loss: 2.0990
2022-07-16 10:55:20 - train: epoch 0073, iter [00700, 05004], lr: 0.001000, loss: 2.2536
2022-07-16 10:55:53 - train: epoch 0073, iter [00800, 05004], lr: 0.001000, loss: 2.0109
2022-07-16 10:56:26 - train: epoch 0073, iter [00900, 05004], lr: 0.001000, loss: 1.9122
2022-07-16 10:57:00 - train: epoch 0073, iter [01000, 05004], lr: 0.001000, loss: 1.9743
2022-07-16 10:57:32 - train: epoch 0073, iter [01100, 05004], lr: 0.001000, loss: 2.3117
2022-07-16 10:58:05 - train: epoch 0073, iter [01200, 05004], lr: 0.001000, loss: 2.0372
2022-07-16 10:58:39 - train: epoch 0073, iter [01300, 05004], lr: 0.001000, loss: 2.1696
2022-07-16 10:59:12 - train: epoch 0073, iter [01400, 05004], lr: 0.001000, loss: 2.0431
2022-07-16 10:59:46 - train: epoch 0073, iter [01500, 05004], lr: 0.001000, loss: 2.0545
2022-07-16 11:00:18 - train: epoch 0073, iter [01600, 05004], lr: 0.001000, loss: 2.2138
2022-07-16 11:00:52 - train: epoch 0073, iter [01700, 05004], lr: 0.001000, loss: 2.5194
2022-07-16 11:01:24 - train: epoch 0073, iter [01800, 05004], lr: 0.001000, loss: 1.8295
2022-07-16 11:01:58 - train: epoch 0073, iter [01900, 05004], lr: 0.001000, loss: 2.2966
2022-07-16 11:02:31 - train: epoch 0073, iter [02000, 05004], lr: 0.001000, loss: 1.8396
2022-07-16 11:03:05 - train: epoch 0073, iter [02100, 05004], lr: 0.001000, loss: 2.1588
2022-07-16 11:03:37 - train: epoch 0073, iter [02200, 05004], lr: 0.001000, loss: 2.2227
2022-07-16 11:04:11 - train: epoch 0073, iter [02300, 05004], lr: 0.001000, loss: 2.3315
2022-07-16 11:04:44 - train: epoch 0073, iter [02400, 05004], lr: 0.001000, loss: 2.2143
2022-07-16 11:05:18 - train: epoch 0073, iter [02500, 05004], lr: 0.001000, loss: 2.3881
2022-07-16 11:05:50 - train: epoch 0073, iter [02600, 05004], lr: 0.001000, loss: 2.1268
2022-07-16 11:06:25 - train: epoch 0073, iter [02700, 05004], lr: 0.001000, loss: 2.1421
2022-07-16 11:06:57 - train: epoch 0073, iter [02800, 05004], lr: 0.001000, loss: 2.3059
2022-07-16 11:07:31 - train: epoch 0073, iter [02900, 05004], lr: 0.001000, loss: 2.1540
2022-07-16 11:08:05 - train: epoch 0073, iter [03000, 05004], lr: 0.001000, loss: 1.9807
2022-07-16 11:08:38 - train: epoch 0073, iter [03100, 05004], lr: 0.001000, loss: 2.2423
2022-07-16 11:09:10 - train: epoch 0073, iter [03200, 05004], lr: 0.001000, loss: 2.0631
2022-07-16 11:09:44 - train: epoch 0073, iter [03300, 05004], lr: 0.001000, loss: 2.4050
2022-07-16 11:10:18 - train: epoch 0073, iter [03400, 05004], lr: 0.001000, loss: 2.1082
2022-07-16 11:10:51 - train: epoch 0073, iter [03500, 05004], lr: 0.001000, loss: 2.2258
2022-07-16 11:11:23 - train: epoch 0073, iter [03600, 05004], lr: 0.001000, loss: 2.0594
2022-07-16 11:11:57 - train: epoch 0073, iter [03700, 05004], lr: 0.001000, loss: 2.1968
2022-07-16 11:12:31 - train: epoch 0073, iter [03800, 05004], lr: 0.001000, loss: 2.4521
2022-07-16 11:13:04 - train: epoch 0073, iter [03900, 05004], lr: 0.001000, loss: 2.1919
2022-07-16 11:13:38 - train: epoch 0073, iter [04000, 05004], lr: 0.001000, loss: 2.4014
2022-07-16 11:14:11 - train: epoch 0073, iter [04100, 05004], lr: 0.001000, loss: 2.1535
2022-07-16 11:14:44 - train: epoch 0073, iter [04200, 05004], lr: 0.001000, loss: 2.5492
2022-07-16 11:15:18 - train: epoch 0073, iter [04300, 05004], lr: 0.001000, loss: 2.0679
2022-07-16 11:15:51 - train: epoch 0073, iter [04400, 05004], lr: 0.001000, loss: 2.1914
2022-07-16 11:16:24 - train: epoch 0073, iter [04500, 05004], lr: 0.001000, loss: 2.1157
2022-07-16 11:16:57 - train: epoch 0073, iter [04600, 05004], lr: 0.001000, loss: 2.3931
2022-07-16 11:17:32 - train: epoch 0073, iter [04700, 05004], lr: 0.001000, loss: 1.8561
2022-07-16 11:18:03 - train: epoch 0073, iter [04800, 05004], lr: 0.001000, loss: 2.1695
2022-07-16 11:18:38 - train: epoch 0073, iter [04900, 05004], lr: 0.001000, loss: 2.0601
2022-07-16 11:19:09 - train: epoch 0073, iter [05000, 05004], lr: 0.001000, loss: 2.3976
2022-07-16 11:19:10 - train: epoch 073, train_loss: 2.1874
2022-07-16 11:20:24 - eval: epoch: 073, acc1: 56.900%, acc5: 79.522%, test_loss: 1.9114, per_image_load_time: 2.129ms, per_image_inference_time: 0.131ms
2022-07-16 11:20:24 - until epoch: 073, best_acc1: 56.964%
2022-07-16 11:20:24 - epoch 074 lr: 0.001000
2022-07-16 11:21:02 - train: epoch 0074, iter [00100, 05004], lr: 0.001000, loss: 2.1133
2022-07-16 11:21:35 - train: epoch 0074, iter [00200, 05004], lr: 0.001000, loss: 2.4108
2022-07-16 11:22:08 - train: epoch 0074, iter [00300, 05004], lr: 0.001000, loss: 2.2747
2022-07-16 11:22:42 - train: epoch 0074, iter [00400, 05004], lr: 0.001000, loss: 2.4586
2022-07-16 11:23:16 - train: epoch 0074, iter [00500, 05004], lr: 0.001000, loss: 2.0929
2022-07-16 11:23:48 - train: epoch 0074, iter [00600, 05004], lr: 0.001000, loss: 2.1149
2022-07-16 11:24:21 - train: epoch 0074, iter [00700, 05004], lr: 0.001000, loss: 2.1443
2022-07-16 11:24:54 - train: epoch 0074, iter [00800, 05004], lr: 0.001000, loss: 2.2736
2022-07-16 11:25:28 - train: epoch 0074, iter [00900, 05004], lr: 0.001000, loss: 2.0160
2022-07-16 11:26:01 - train: epoch 0074, iter [01000, 05004], lr: 0.001000, loss: 2.3285
2022-07-16 11:26:35 - train: epoch 0074, iter [01100, 05004], lr: 0.001000, loss: 2.4940
2022-07-16 11:27:08 - train: epoch 0074, iter [01200, 05004], lr: 0.001000, loss: 2.1005
2022-07-16 11:27:41 - train: epoch 0074, iter [01300, 05004], lr: 0.001000, loss: 2.2450
2022-07-16 11:28:14 - train: epoch 0074, iter [01400, 05004], lr: 0.001000, loss: 2.0247
2022-07-16 11:28:48 - train: epoch 0074, iter [01500, 05004], lr: 0.001000, loss: 2.1922
2022-07-16 11:29:21 - train: epoch 0074, iter [01600, 05004], lr: 0.001000, loss: 1.9442
2022-07-16 11:29:55 - train: epoch 0074, iter [01700, 05004], lr: 0.001000, loss: 2.2709
2022-07-16 11:30:27 - train: epoch 0074, iter [01800, 05004], lr: 0.001000, loss: 2.5673
2022-07-16 11:31:01 - train: epoch 0074, iter [01900, 05004], lr: 0.001000, loss: 2.1908
2022-07-16 11:31:35 - train: epoch 0074, iter [02000, 05004], lr: 0.001000, loss: 1.9449
2022-07-16 11:32:09 - train: epoch 0074, iter [02100, 05004], lr: 0.001000, loss: 2.1243
2022-07-16 11:32:41 - train: epoch 0074, iter [02200, 05004], lr: 0.001000, loss: 2.5528
2022-07-16 11:33:15 - train: epoch 0074, iter [02300, 05004], lr: 0.001000, loss: 2.4090
2022-07-16 11:33:48 - train: epoch 0074, iter [02400, 05004], lr: 0.001000, loss: 2.1649
2022-07-16 11:34:21 - train: epoch 0074, iter [02500, 05004], lr: 0.001000, loss: 2.0479
2022-07-16 11:34:53 - train: epoch 0074, iter [02600, 05004], lr: 0.001000, loss: 1.8494
2022-07-16 11:35:27 - train: epoch 0074, iter [02700, 05004], lr: 0.001000, loss: 2.1746
2022-07-16 11:36:00 - train: epoch 0074, iter [02800, 05004], lr: 0.001000, loss: 2.5351
2022-07-16 11:36:34 - train: epoch 0074, iter [02900, 05004], lr: 0.001000, loss: 2.1835
2022-07-16 11:37:07 - train: epoch 0074, iter [03000, 05004], lr: 0.001000, loss: 2.2094
2022-07-16 11:37:40 - train: epoch 0074, iter [03100, 05004], lr: 0.001000, loss: 2.3000
2022-07-16 11:38:13 - train: epoch 0074, iter [03200, 05004], lr: 0.001000, loss: 2.0709
2022-07-16 11:38:47 - train: epoch 0074, iter [03300, 05004], lr: 0.001000, loss: 2.2787
2022-07-16 11:39:21 - train: epoch 0074, iter [03400, 05004], lr: 0.001000, loss: 2.2942
2022-07-16 11:39:53 - train: epoch 0074, iter [03500, 05004], lr: 0.001000, loss: 2.1376
2022-07-16 11:40:27 - train: epoch 0074, iter [03600, 05004], lr: 0.001000, loss: 2.2053
2022-07-16 11:41:00 - train: epoch 0074, iter [03700, 05004], lr: 0.001000, loss: 2.2950
2022-07-16 11:41:34 - train: epoch 0074, iter [03800, 05004], lr: 0.001000, loss: 1.9966
2022-07-16 11:42:06 - train: epoch 0074, iter [03900, 05004], lr: 0.001000, loss: 1.8415
2022-07-16 11:42:41 - train: epoch 0074, iter [04000, 05004], lr: 0.001000, loss: 2.1520
2022-07-16 11:43:13 - train: epoch 0074, iter [04100, 05004], lr: 0.001000, loss: 2.2474
2022-07-16 11:43:47 - train: epoch 0074, iter [04200, 05004], lr: 0.001000, loss: 2.1721
2022-07-16 11:44:20 - train: epoch 0074, iter [04300, 05004], lr: 0.001000, loss: 2.2039
2022-07-16 11:44:54 - train: epoch 0074, iter [04400, 05004], lr: 0.001000, loss: 2.1360
2022-07-16 11:45:27 - train: epoch 0074, iter [04500, 05004], lr: 0.001000, loss: 1.9726
2022-07-16 11:46:00 - train: epoch 0074, iter [04600, 05004], lr: 0.001000, loss: 2.2468
2022-07-16 11:46:34 - train: epoch 0074, iter [04700, 05004], lr: 0.001000, loss: 2.1185
2022-07-16 11:47:08 - train: epoch 0074, iter [04800, 05004], lr: 0.001000, loss: 2.3094
2022-07-16 11:47:41 - train: epoch 0074, iter [04900, 05004], lr: 0.001000, loss: 2.3305
2022-07-16 11:48:14 - train: epoch 0074, iter [05000, 05004], lr: 0.001000, loss: 2.2131
2022-07-16 11:48:14 - train: epoch 074, train_loss: 2.1849
2022-07-16 11:49:27 - eval: epoch: 074, acc1: 56.908%, acc5: 79.664%, test_loss: 1.9056, per_image_load_time: 1.819ms, per_image_inference_time: 0.121ms
2022-07-16 11:49:28 - until epoch: 074, best_acc1: 56.964%
2022-07-16 11:49:28 - epoch 075 lr: 0.001000
2022-07-16 11:50:05 - train: epoch 0075, iter [00100, 05004], lr: 0.001000, loss: 2.2555
2022-07-16 11:50:39 - train: epoch 0075, iter [00200, 05004], lr: 0.001000, loss: 2.1740
2022-07-16 11:51:11 - train: epoch 0075, iter [00300, 05004], lr: 0.001000, loss: 2.1440
2022-07-16 11:51:45 - train: epoch 0075, iter [00400, 05004], lr: 0.001000, loss: 2.2217
2022-07-16 11:52:19 - train: epoch 0075, iter [00500, 05004], lr: 0.001000, loss: 2.0489
2022-07-16 11:52:51 - train: epoch 0075, iter [00600, 05004], lr: 0.001000, loss: 2.0871
2022-07-16 11:53:25 - train: epoch 0075, iter [00700, 05004], lr: 0.001000, loss: 2.3812
2022-07-16 11:53:57 - train: epoch 0075, iter [00800, 05004], lr: 0.001000, loss: 2.2733
2022-07-16 11:54:31 - train: epoch 0075, iter [00900, 05004], lr: 0.001000, loss: 2.2548
2022-07-16 11:55:04 - train: epoch 0075, iter [01000, 05004], lr: 0.001000, loss: 1.9384
2022-07-16 11:55:37 - train: epoch 0075, iter [01100, 05004], lr: 0.001000, loss: 2.3173
2022-07-16 11:56:10 - train: epoch 0075, iter [01200, 05004], lr: 0.001000, loss: 2.1201
2022-07-16 11:56:44 - train: epoch 0075, iter [01300, 05004], lr: 0.001000, loss: 1.9581
2022-07-16 11:57:16 - train: epoch 0075, iter [01400, 05004], lr: 0.001000, loss: 2.1059
2022-07-16 11:57:49 - train: epoch 0075, iter [01500, 05004], lr: 0.001000, loss: 2.4129
2022-07-16 11:58:22 - train: epoch 0075, iter [01600, 05004], lr: 0.001000, loss: 1.7539
2022-07-16 11:58:55 - train: epoch 0075, iter [01700, 05004], lr: 0.001000, loss: 2.1950
2022-07-16 11:59:29 - train: epoch 0075, iter [01800, 05004], lr: 0.001000, loss: 2.1735
2022-07-16 12:00:03 - train: epoch 0075, iter [01900, 05004], lr: 0.001000, loss: 2.1013
2022-07-16 12:00:36 - train: epoch 0075, iter [02000, 05004], lr: 0.001000, loss: 2.2058
2022-07-16 12:01:09 - train: epoch 0075, iter [02100, 05004], lr: 0.001000, loss: 2.0067
2022-07-16 12:01:44 - train: epoch 0075, iter [02200, 05004], lr: 0.001000, loss: 2.2714
2022-07-16 12:02:15 - train: epoch 0075, iter [02300, 05004], lr: 0.001000, loss: 2.0231
2022-07-16 12:02:50 - train: epoch 0075, iter [02400, 05004], lr: 0.001000, loss: 2.2891
2022-07-16 12:03:22 - train: epoch 0075, iter [02500, 05004], lr: 0.001000, loss: 2.2330
2022-07-16 12:03:56 - train: epoch 0075, iter [02600, 05004], lr: 0.001000, loss: 2.3231
2022-07-16 12:04:28 - train: epoch 0075, iter [02700, 05004], lr: 0.001000, loss: 1.9454
2022-07-16 12:05:03 - train: epoch 0075, iter [02800, 05004], lr: 0.001000, loss: 2.2915
2022-07-16 12:05:35 - train: epoch 0075, iter [02900, 05004], lr: 0.001000, loss: 2.2835
2022-07-16 12:06:10 - train: epoch 0075, iter [03000, 05004], lr: 0.001000, loss: 2.2957
2022-07-16 12:06:43 - train: epoch 0075, iter [03100, 05004], lr: 0.001000, loss: 2.5253
2022-07-16 12:07:17 - train: epoch 0075, iter [03200, 05004], lr: 0.001000, loss: 2.0266
2022-07-16 12:07:50 - train: epoch 0075, iter [03300, 05004], lr: 0.001000, loss: 2.2736
2022-07-16 12:08:24 - train: epoch 0075, iter [03400, 05004], lr: 0.001000, loss: 1.9542
2022-07-16 12:08:56 - train: epoch 0075, iter [03500, 05004], lr: 0.001000, loss: 1.9522
2022-07-16 12:09:31 - train: epoch 0075, iter [03600, 05004], lr: 0.001000, loss: 2.2354
2022-07-16 12:10:03 - train: epoch 0075, iter [03700, 05004], lr: 0.001000, loss: 2.1852
2022-07-16 12:10:37 - train: epoch 0075, iter [03800, 05004], lr: 0.001000, loss: 2.1161
2022-07-16 12:11:10 - train: epoch 0075, iter [03900, 05004], lr: 0.001000, loss: 2.4203
2022-07-16 12:11:44 - train: epoch 0075, iter [04000, 05004], lr: 0.001000, loss: 2.1166
2022-07-16 12:12:17 - train: epoch 0075, iter [04100, 05004], lr: 0.001000, loss: 1.8979
2022-07-16 12:12:50 - train: epoch 0075, iter [04200, 05004], lr: 0.001000, loss: 2.3078
2022-07-16 12:13:24 - train: epoch 0075, iter [04300, 05004], lr: 0.001000, loss: 2.3141
2022-07-16 12:13:57 - train: epoch 0075, iter [04400, 05004], lr: 0.001000, loss: 2.0485
2022-07-16 12:14:31 - train: epoch 0075, iter [04500, 05004], lr: 0.001000, loss: 2.1484
2022-07-16 12:15:04 - train: epoch 0075, iter [04600, 05004], lr: 0.001000, loss: 2.0352
2022-07-16 12:15:37 - train: epoch 0075, iter [04700, 05004], lr: 0.001000, loss: 2.4241
2022-07-16 12:16:10 - train: epoch 0075, iter [04800, 05004], lr: 0.001000, loss: 2.2526
2022-07-16 12:16:44 - train: epoch 0075, iter [04900, 05004], lr: 0.001000, loss: 2.0033
2022-07-16 12:17:16 - train: epoch 0075, iter [05000, 05004], lr: 0.001000, loss: 2.1247
2022-07-16 12:17:17 - train: epoch 075, train_loss: 2.1845
2022-07-16 12:18:31 - eval: epoch: 075, acc1: 57.046%, acc5: 79.734%, test_loss: 1.9051, per_image_load_time: 2.697ms, per_image_inference_time: 0.134ms
2022-07-16 12:18:31 - until epoch: 075, best_acc1: 57.046%
2022-07-16 12:18:31 - epoch 076 lr: 0.001000
2022-07-16 12:19:10 - train: epoch 0076, iter [00100, 05004], lr: 0.001000, loss: 1.9429
2022-07-16 12:19:42 - train: epoch 0076, iter [00200, 05004], lr: 0.001000, loss: 2.1774
2022-07-16 12:20:15 - train: epoch 0076, iter [00300, 05004], lr: 0.001000, loss: 2.2577
2022-07-16 12:20:47 - train: epoch 0076, iter [00400, 05004], lr: 0.001000, loss: 2.1892
2022-07-16 12:21:20 - train: epoch 0076, iter [00500, 05004], lr: 0.001000, loss: 2.1453
2022-07-16 12:21:54 - train: epoch 0076, iter [00600, 05004], lr: 0.001000, loss: 2.1678
2022-07-16 12:22:26 - train: epoch 0076, iter [00700, 05004], lr: 0.001000, loss: 2.1521
2022-07-16 12:22:59 - train: epoch 0076, iter [00800, 05004], lr: 0.001000, loss: 2.1512
2022-07-16 12:23:33 - train: epoch 0076, iter [00900, 05004], lr: 0.001000, loss: 2.0135
2022-07-16 12:24:05 - train: epoch 0076, iter [01000, 05004], lr: 0.001000, loss: 2.1275
2022-07-16 12:24:38 - train: epoch 0076, iter [01100, 05004], lr: 0.001000, loss: 1.9454
2022-07-16 12:25:11 - train: epoch 0076, iter [01200, 05004], lr: 0.001000, loss: 2.0605
2022-07-16 12:25:45 - train: epoch 0076, iter [01300, 05004], lr: 0.001000, loss: 2.2887
2022-07-16 12:26:19 - train: epoch 0076, iter [01400, 05004], lr: 0.001000, loss: 2.0730
2022-07-16 12:26:51 - train: epoch 0076, iter [01500, 05004], lr: 0.001000, loss: 2.1553
2022-07-16 12:27:25 - train: epoch 0076, iter [01600, 05004], lr: 0.001000, loss: 2.0448
2022-07-16 12:27:58 - train: epoch 0076, iter [01700, 05004], lr: 0.001000, loss: 2.1571
2022-07-16 12:28:31 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 1.8853
2022-07-16 12:29:04 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 2.3600
2022-07-16 12:29:38 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 2.3068
2022-07-16 12:30:11 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 2.3087
2022-07-16 12:30:44 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 2.4902
2022-07-16 12:31:17 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 2.0799
2022-07-16 12:31:52 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 2.4179
2022-07-16 12:32:24 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 2.0997
2022-07-16 12:32:59 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 2.4357
2022-07-16 12:33:31 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 2.3972
2022-07-16 12:34:04 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 2.1959
2022-07-16 12:34:38 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 2.3006
2022-07-16 12:35:10 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 2.1432
2022-07-16 12:35:44 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 2.2544
2022-07-16 12:36:17 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 2.2116
2022-07-16 12:36:50 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 1.9565
2022-07-16 12:37:23 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 2.0632
2022-07-16 12:37:56 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 2.0598
2022-07-16 12:38:31 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 1.9621
2022-07-16 12:39:03 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 2.0644
2022-07-16 12:39:38 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 1.9177
2022-07-16 12:40:10 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 2.1949
2022-07-16 12:40:44 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 2.2291
2022-07-16 12:41:16 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 2.2567
2022-07-16 12:41:50 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 2.2837
2022-07-16 12:42:23 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 2.2434
2022-07-16 12:42:58 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 2.1069
2022-07-16 12:43:30 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 2.2486
2022-07-16 12:44:04 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 2.1534
2022-07-16 12:44:37 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 2.2661
2022-07-16 12:45:11 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 2.0290
2022-07-16 12:45:43 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 2.1664
2022-07-16 12:46:15 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 2.1416
2022-07-16 12:46:16 - train: epoch 076, train_loss: 2.1822
2022-07-16 12:47:30 - eval: epoch: 076, acc1: 56.990%, acc5: 79.730%, test_loss: 1.9043, per_image_load_time: 2.070ms, per_image_inference_time: 0.138ms
2022-07-16 12:47:30 - until epoch: 076, best_acc1: 57.046%
2022-07-16 12:47:30 - epoch 077 lr: 0.001000
2022-07-16 12:48:09 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 2.4169
2022-07-16 12:48:41 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 2.2918
2022-07-16 12:49:14 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 1.8983
2022-07-16 12:49:48 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 2.3161
2022-07-16 12:50:20 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 2.0448
2022-07-16 12:50:54 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 2.0463
2022-07-16 12:51:27 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 2.2648
2022-07-16 12:52:00 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 2.4722
2022-07-16 12:52:34 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 2.3172
2022-07-16 12:53:06 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 2.0101
2022-07-16 12:53:40 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 2.2294
2022-07-16 12:54:13 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 2.2775
2022-07-16 12:54:47 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 1.9585
2022-07-16 12:55:19 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 2.1119
2022-07-16 12:55:54 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 1.9530
2022-07-16 12:56:27 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 2.0332
2022-07-16 12:57:00 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 2.5155
2022-07-16 12:57:33 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 1.9966
2022-07-16 12:58:06 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 2.1313
2022-07-16 12:58:39 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 2.0797
2022-07-16 12:59:14 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 2.4057
2022-07-16 12:59:46 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 2.1582
2022-07-16 13:00:21 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 2.3875
2022-07-16 13:00:53 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 2.0142
2022-07-16 13:01:26 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 2.3711
2022-07-16 13:02:00 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 1.9812
2022-07-16 13:02:33 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 2.1448
2022-07-16 13:03:07 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 2.2945
2022-07-16 13:03:40 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 2.5193
2022-07-16 13:04:13 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 1.9643
2022-07-16 13:04:48 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 2.0992
2022-07-16 13:05:20 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 2.3871
2022-07-16 13:05:53 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 2.0273
2022-07-16 13:06:27 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 2.4650
2022-07-16 13:07:01 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 1.9663
2022-07-16 13:07:36 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 2.2144
2022-07-16 13:08:08 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 2.3318
2022-07-16 13:08:42 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 2.0729
2022-07-16 13:09:14 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 2.2835
2022-07-16 13:09:48 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 2.2676
2022-07-16 13:10:21 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 2.2185
2022-07-16 13:10:55 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 2.3761
2022-07-16 13:11:27 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 2.1261
2022-07-16 13:12:01 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 2.1235
2022-07-16 13:12:35 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 2.4255
2022-07-16 13:13:08 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 2.2374
2022-07-16 13:13:41 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 1.9619
2022-07-16 13:14:15 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 2.1922
2022-07-16 13:14:47 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 2.3931
2022-07-16 13:15:20 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 2.3980
2022-07-16 13:15:21 - train: epoch 077, train_loss: 2.1798
2022-07-16 13:16:36 - eval: epoch: 077, acc1: 57.102%, acc5: 79.720%, test_loss: 1.8986, per_image_load_time: 1.084ms, per_image_inference_time: 0.133ms
2022-07-16 13:16:36 - until epoch: 077, best_acc1: 57.102%
2022-07-16 13:16:36 - epoch 078 lr: 0.001000
2022-07-16 13:17:14 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 2.2594
2022-07-16 13:17:46 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 2.1891
2022-07-16 13:18:19 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 2.2557
2022-07-16 13:18:53 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 2.1057
2022-07-16 13:19:25 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 2.1921
2022-07-16 13:19:57 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 2.0223
2022-07-16 13:20:30 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 2.4124
2022-07-16 13:21:02 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 2.4095
2022-07-16 13:21:36 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 2.2620
2022-07-16 13:22:08 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 2.3093
2022-07-16 13:22:42 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 1.9132
2022-07-16 13:23:15 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 1.9304
2022-07-16 13:23:48 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 2.0993
2022-07-16 13:24:20 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 1.9704
2022-07-16 13:24:54 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 2.1381
2022-07-16 13:25:27 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 2.4087
2022-07-16 13:26:00 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 2.2242
2022-07-16 13:26:34 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 2.1358
2022-07-16 13:27:08 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 2.1505
2022-07-16 13:27:40 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 2.1057
2022-07-16 13:28:13 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 2.5227
2022-07-16 13:28:48 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 2.1498
2022-07-16 13:29:20 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 2.2392
2022-07-16 13:29:53 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 2.1506
2022-07-16 13:30:27 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 2.0992
2022-07-16 13:31:01 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 2.0576
2022-07-16 13:31:33 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 1.9673
2022-07-16 13:32:07 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 2.2587
2022-07-16 13:32:40 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 2.1316
2022-07-16 13:33:13 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 2.2800
2022-07-16 13:33:46 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 2.2861
2022-07-16 13:34:20 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 2.2660
2022-07-16 13:34:53 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 2.3579
2022-07-16 13:35:27 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 2.0833
2022-07-16 13:36:00 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 2.0769
2022-07-16 13:36:35 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 2.1579
2022-07-16 13:37:08 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 2.0087
2022-07-16 13:37:42 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 2.0675
2022-07-16 13:38:14 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 2.1380
2022-07-16 13:38:48 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 2.2786
2022-07-16 13:39:21 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 2.0639
2022-07-16 13:39:55 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 2.3565
2022-07-16 13:40:28 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 2.1109
2022-07-16 13:41:03 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 2.2210
2022-07-16 13:41:35 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 2.2360
2022-07-16 13:42:10 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 1.9265
2022-07-16 13:42:42 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 2.2156
2022-07-16 13:43:16 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 2.4250
2022-07-16 13:43:49 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 2.2546
2022-07-16 13:44:21 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 2.2319
2022-07-16 13:44:22 - train: epoch 078, train_loss: 2.1771
2022-07-16 13:45:36 - eval: epoch: 078, acc1: 56.958%, acc5: 79.674%, test_loss: 1.9030, per_image_load_time: 2.756ms, per_image_inference_time: 0.138ms
2022-07-16 13:45:36 - until epoch: 078, best_acc1: 57.102%
2022-07-16 13:45:36 - epoch 079 lr: 0.001000
2022-07-16 13:46:14 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 2.1729
2022-07-16 13:46:48 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 2.0880
2022-07-16 13:47:20 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 2.3264
2022-07-16 13:47:53 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 2.3213
2022-07-16 13:48:26 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 2.1156
2022-07-16 13:48:59 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 2.0917
2022-07-16 13:49:33 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 1.9899
2022-07-16 13:50:05 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 2.2459
2022-07-16 13:50:38 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 2.1793
2022-07-16 13:51:12 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 2.0830
2022-07-16 13:51:45 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 2.3810
2022-07-16 13:52:18 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 2.3963
2022-07-16 13:52:51 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 2.0211
2022-07-16 13:53:24 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 2.0218
2022-07-16 13:53:57 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 2.2171
2022-07-16 13:54:31 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 1.8188
2022-07-16 13:55:05 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 2.1758
2022-07-16 13:55:38 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 2.1783
2022-07-16 13:56:12 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 2.1397
2022-07-16 13:56:44 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 2.3114
2022-07-16 13:57:18 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 2.0030
2022-07-16 13:57:52 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 2.1668
2022-07-16 13:58:26 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 2.1599
2022-07-16 13:58:58 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 2.1491
2022-07-16 13:59:32 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 2.0985
2022-07-16 14:00:05 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 2.0836
2022-07-16 14:00:38 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 1.8819
2022-07-16 14:01:12 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 2.0598
2022-07-16 14:01:44 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 2.0747
2022-07-16 14:02:18 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 2.1152
2022-07-16 14:02:51 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 2.0255
2022-07-16 14:03:26 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 2.3177
2022-07-16 14:03:58 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 2.1692
2022-07-16 14:04:32 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 2.0282
2022-07-16 14:05:04 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 2.2725
2022-07-16 14:05:38 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 2.0874
2022-07-16 14:06:11 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 2.0025
2022-07-16 14:06:45 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 2.2167
2022-07-16 14:07:18 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 2.1133
2022-07-16 14:07:52 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 2.0400
2022-07-16 14:08:25 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 2.3422
2022-07-16 14:08:59 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 1.9403
2022-07-16 14:09:32 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 1.9089
2022-07-16 14:10:05 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 2.4116
2022-07-16 14:10:39 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 2.4885
2022-07-16 14:11:13 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 2.3084
2022-07-16 14:11:46 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 2.1798
2022-07-16 14:12:19 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 2.1831
2022-07-16 14:12:52 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 2.3244
2022-07-16 14:13:24 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 1.8900
2022-07-16 14:13:25 - train: epoch 079, train_loss: 2.1787
2022-07-16 14:14:38 - eval: epoch: 079, acc1: 57.062%, acc5: 79.620%, test_loss: 1.9062, per_image_load_time: 1.975ms, per_image_inference_time: 0.139ms
2022-07-16 14:14:39 - until epoch: 079, best_acc1: 57.102%
2022-07-16 14:14:39 - epoch 080 lr: 0.001000
2022-07-16 14:15:17 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 2.0064
2022-07-16 14:15:49 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 2.2475
2022-07-16 14:16:22 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 2.1761
2022-07-16 14:16:54 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 1.9953
2022-07-16 14:17:28 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 2.1952
2022-07-16 14:17:59 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 1.9921
2022-07-16 14:18:34 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 2.0433
2022-07-16 14:19:06 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 2.0079
2022-07-16 14:19:39 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 2.2261
2022-07-16 14:20:12 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 2.1302
2022-07-16 14:20:46 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 2.1339
2022-07-16 14:21:18 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 2.0383
2022-07-16 14:21:51 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 2.1333
2022-07-16 14:22:24 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 2.1517
2022-07-16 14:22:56 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 2.1416
2022-07-16 14:23:31 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 2.0755
2022-07-16 14:24:03 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 2.2184
2022-07-16 14:24:36 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 2.4215
2022-07-16 14:25:09 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 2.1878
2022-07-16 14:25:43 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 2.3019
2022-07-16 14:26:15 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 2.2910
2022-07-16 14:26:49 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 2.3489
2022-07-16 14:27:21 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 2.1222
2022-07-16 14:27:55 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 2.2972
2022-07-16 14:28:28 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 2.0042
2022-07-16 14:29:02 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 2.2163
2022-07-16 14:29:35 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 2.3157
2022-07-16 14:30:08 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 2.2093
2022-07-16 14:30:41 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 2.2201
2022-07-16 14:31:14 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 2.1589
2022-07-16 14:31:48 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 2.3937
2022-07-16 14:32:21 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 1.8346
2022-07-16 14:32:54 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 2.0431
2022-07-16 14:33:27 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 2.0088
2022-07-16 14:34:00 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 2.0227
2022-07-16 14:34:34 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 2.2221
2022-07-16 14:35:06 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 2.1718
2022-07-16 14:35:40 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 2.3129
2022-07-16 14:36:13 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 2.0435
2022-07-16 14:36:46 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 2.2822
2022-07-16 14:37:20 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 2.1498
2022-07-16 14:37:52 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 2.1014
2022-07-16 14:38:26 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 2.4491
2022-07-16 14:38:58 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 2.1321
2022-07-16 14:39:33 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 2.0729
2022-07-16 14:40:05 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 2.2541
2022-07-16 14:40:39 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 2.3328
2022-07-16 14:41:11 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 2.0329
2022-07-16 14:41:46 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 2.3734
2022-07-16 14:42:17 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 1.9555
2022-07-16 14:42:18 - train: epoch 080, train_loss: 2.1778
2022-07-16 14:43:32 - eval: epoch: 080, acc1: 57.038%, acc5: 79.734%, test_loss: 1.9025, per_image_load_time: 2.752ms, per_image_inference_time: 0.115ms
2022-07-16 14:43:32 - until epoch: 080, best_acc1: 57.102%
2022-07-16 14:43:32 - epoch 081 lr: 0.001000
2022-07-16 14:44:10 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 2.0575
2022-07-16 14:44:42 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 2.3265
2022-07-16 14:45:16 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 2.1758
2022-07-16 14:45:48 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 2.3799
2022-07-16 14:46:22 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 2.4625
2022-07-16 14:46:54 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 2.1307
2022-07-16 14:47:28 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 2.0427
2022-07-16 14:48:00 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 2.2483
2022-07-16 14:48:33 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 2.1552
2022-07-16 14:49:06 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 2.1690
2022-07-16 14:49:39 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 2.0804
2022-07-16 14:50:13 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 2.2003
2022-07-16 14:50:46 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 1.8855
2022-07-16 14:51:18 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 1.8490
2022-07-16 14:51:52 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 2.1163
2022-07-16 14:52:25 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 1.9684
2022-07-16 14:52:58 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 2.2723
2022-07-16 14:53:31 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 2.1883
2022-07-16 14:54:05 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 1.9967
2022-07-16 14:54:38 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 2.1311
2022-07-16 14:55:12 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 2.2422
2022-07-16 14:55:44 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 2.2322
2022-07-16 14:56:18 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 1.9382
2022-07-16 14:56:51 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 2.2186
2022-07-16 14:57:24 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 2.4446
2022-07-16 14:57:58 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 2.4168
2022-07-16 14:58:30 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 2.1481
2022-07-16 14:59:04 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 2.1105
2022-07-16 14:59:37 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 1.9998
2022-07-16 15:00:10 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 2.1558
2022-07-16 15:00:43 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 2.0373
2022-07-16 15:01:16 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 2.1538
2022-07-16 15:01:50 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 1.9564
2022-07-16 15:02:23 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 2.3222
2022-07-16 15:02:56 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 2.0695
2022-07-16 15:03:29 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 2.1573
2022-07-16 15:04:03 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 2.2561
2022-07-16 15:04:36 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 2.0887
2022-07-16 15:05:10 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 2.2670
2022-07-16 15:05:43 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 2.0623
2022-07-16 15:06:16 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 2.1075
2022-07-16 15:06:50 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 2.1909
2022-07-16 15:07:23 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 2.1619
2022-07-16 15:07:56 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 2.3901
2022-07-16 15:08:29 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 2.2278
2022-07-16 15:09:02 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 2.2070
2022-07-16 15:09:36 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 2.3242
2022-07-16 15:10:09 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 2.2175
2022-07-16 15:10:42 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 2.3861
2022-07-16 15:11:14 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 1.9363
2022-07-16 15:11:15 - train: epoch 081, train_loss: 2.1759
2022-07-16 15:12:30 - eval: epoch: 081, acc1: 57.066%, acc5: 79.678%, test_loss: 1.8992, per_image_load_time: 2.728ms, per_image_inference_time: 0.118ms
2022-07-16 15:12:30 - until epoch: 081, best_acc1: 57.102%
2022-07-16 15:12:30 - epoch 082 lr: 0.001000
2022-07-16 15:13:09 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 1.8843
2022-07-16 15:13:41 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 2.0604
2022-07-16 15:14:14 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 2.1780
2022-07-16 15:14:48 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 2.2494
2022-07-16 15:15:20 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 2.2772
2022-07-16 15:15:55 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 2.1529
2022-07-16 15:16:27 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 2.3703
2022-07-16 15:17:01 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 2.1351
2022-07-16 15:17:32 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 2.4026
2022-07-16 15:18:07 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 2.3785
2022-07-16 15:18:40 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 2.2395
2022-07-16 15:19:13 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 2.2782
2022-07-16 15:19:45 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 2.3554
2022-07-16 15:20:19 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 2.0625
2022-07-16 15:20:52 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 2.1016
2022-07-16 15:21:25 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 2.1350
2022-07-16 15:21:58 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 2.2060
2022-07-16 15:22:32 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 2.1355
2022-07-16 15:23:05 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 2.0383
2022-07-16 15:23:38 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 1.8405
2022-07-16 15:24:10 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 2.1268
2022-07-16 15:24:44 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 2.0824
2022-07-16 15:25:18 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 2.0637
2022-07-16 15:25:50 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 2.2261
2022-07-16 15:26:23 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 2.1898
2022-07-16 15:26:57 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 2.1463
2022-07-16 15:27:30 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 2.0053
2022-07-16 15:28:04 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 1.8427
2022-07-16 15:28:37 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 1.9852
2022-07-16 15:29:10 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 2.1021
2022-07-16 15:29:43 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 2.1607
2022-07-16 15:30:17 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 2.2857
2022-07-16 15:30:51 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 2.1883
2022-07-16 15:31:23 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 2.1563
2022-07-16 15:31:57 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 2.1091
2022-07-16 15:32:30 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 2.1214
2022-07-16 15:33:03 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 1.9532
2022-07-16 15:33:36 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 2.3660
2022-07-16 15:34:09 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 2.1399
2022-07-16 15:34:43 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 2.1862
2022-07-16 15:35:16 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 2.2568
2022-07-16 15:35:49 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 2.3913
2022-07-16 15:36:24 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 2.0075
2022-07-16 15:36:57 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 2.1113
2022-07-16 15:37:30 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 2.1978
2022-07-16 15:38:03 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 2.0920
2022-07-16 15:38:36 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 2.0248
2022-07-16 15:39:09 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 2.0448
2022-07-16 15:39:43 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 2.1764
2022-07-16 15:40:15 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 2.1281
2022-07-16 15:40:16 - train: epoch 082, train_loss: 2.1739
2022-07-16 15:41:31 - eval: epoch: 082, acc1: 57.012%, acc5: 79.582%, test_loss: 1.9037, per_image_load_time: 2.611ms, per_image_inference_time: 0.137ms
2022-07-16 15:41:31 - until epoch: 082, best_acc1: 57.102%
2022-07-16 15:41:31 - epoch 083 lr: 0.001000
2022-07-16 15:42:09 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 2.1575
2022-07-16 15:42:43 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 2.1314
2022-07-16 15:43:16 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 2.2150
2022-07-16 15:43:49 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 2.2015
2022-07-16 15:44:23 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 2.3253
2022-07-16 15:44:55 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 2.1102
2022-07-16 15:45:29 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 2.1521
2022-07-16 15:46:02 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 2.0543
2022-07-16 15:46:35 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 2.1249
2022-07-16 15:47:08 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 2.3254
2022-07-16 15:47:41 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 2.2043
2022-07-16 15:48:15 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 2.2203
2022-07-16 15:48:48 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 2.1316
2022-07-16 15:49:21 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 2.1876
2022-07-16 15:49:55 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 1.9751
2022-07-16 15:50:28 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 2.1322
2022-07-16 15:51:02 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 2.3717
2022-07-16 15:51:34 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 2.4755
2022-07-16 15:52:08 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 2.0197
2022-07-16 15:52:41 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 1.8825
2022-07-16 15:53:14 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 2.1243
2022-07-16 15:53:47 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 2.1307
2022-07-16 15:54:20 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 2.3619
2022-07-16 15:54:53 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 2.0215
2022-07-16 15:55:26 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 2.1240
2022-07-16 15:56:01 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 1.9411
2022-07-16 15:56:32 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 2.1607
2022-07-16 15:57:06 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 1.9833
2022-07-16 15:57:40 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 2.1802
2022-07-16 15:58:13 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 2.3238
2022-07-16 15:58:47 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 1.9474
2022-07-16 15:59:19 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 2.0635
2022-07-16 15:59:54 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 2.3378
2022-07-16 16:00:27 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 2.2206
2022-07-16 16:01:00 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 2.1775
2022-07-16 16:01:33 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 2.1438
2022-07-16 16:02:07 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 2.2036
2022-07-16 16:02:40 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 1.9952
2022-07-16 16:03:14 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 2.2770
2022-07-16 16:03:47 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 2.3648
2022-07-16 16:04:22 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 2.1983
2022-07-16 16:04:54 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 2.4776
2022-07-16 16:05:28 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 2.0632
2022-07-16 16:06:01 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 2.0787
2022-07-16 16:06:34 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 2.2864
2022-07-16 16:07:08 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 2.1964
2022-07-16 16:07:41 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 2.4804
2022-07-16 16:08:14 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 2.3244
2022-07-16 16:08:48 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 2.4388
2022-07-16 16:09:20 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 2.1685
2022-07-16 16:09:20 - train: epoch 083, train_loss: 2.1746
2022-07-16 16:10:35 - eval: epoch: 083, acc1: 57.078%, acc5: 79.816%, test_loss: 1.9003, per_image_load_time: 2.100ms, per_image_inference_time: 0.135ms
2022-07-16 16:10:35 - until epoch: 083, best_acc1: 57.102%
2022-07-16 16:10:35 - epoch 084 lr: 0.001000
2022-07-16 16:11:13 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 2.1585
2022-07-16 16:11:47 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 2.1751
2022-07-16 16:12:20 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 1.9718
2022-07-16 16:12:52 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 2.2267
2022-07-16 16:13:26 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 2.1875
2022-07-16 16:13:58 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 2.4031
2022-07-16 16:14:32 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 2.2026
2022-07-16 16:15:04 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 2.3325
2022-07-16 16:15:38 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 2.1482
2022-07-16 16:16:11 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 2.3391
2022-07-16 16:16:43 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 2.1702
2022-07-16 16:17:17 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 2.5144
2022-07-16 16:17:51 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 2.1225
2022-07-16 16:18:24 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 2.2392
2022-07-16 16:18:58 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 2.3242
2022-07-16 16:19:30 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 2.1883
2022-07-16 16:20:04 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 2.1938
2022-07-16 16:20:38 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 2.2890
2022-07-16 16:21:11 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 2.1018
2022-07-16 16:21:44 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 2.1790
2022-07-16 16:22:17 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 2.1020
2022-07-16 16:22:51 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 1.9291
2022-07-16 16:23:24 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 2.1990
2022-07-16 16:23:59 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 2.0226
2022-07-16 16:24:31 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 2.2835
2022-07-16 16:25:05 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 2.2474
2022-07-16 16:25:38 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 2.0947
2022-07-16 16:26:11 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 2.2855
2022-07-16 16:26:45 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 2.0727
2022-07-16 16:27:18 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 2.2312
2022-07-16 16:27:52 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 2.0818
2022-07-16 16:28:25 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 2.0889
2022-07-16 16:28:59 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 2.1074
2022-07-16 16:29:32 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 1.9851
2022-07-16 16:30:06 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 2.2232
2022-07-16 16:30:38 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 2.2445
2022-07-16 16:31:12 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 2.3209
2022-07-16 16:31:45 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 2.3621
2022-07-16 16:32:19 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 2.2003
2022-07-16 16:32:52 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 2.1348
2022-07-16 16:33:26 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 2.2814
2022-07-16 16:33:59 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 2.2497
2022-07-16 16:34:32 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 2.1761
2022-07-16 16:35:07 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 2.5085
2022-07-16 16:35:39 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 2.0659
2022-07-16 16:36:13 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 2.1536
2022-07-16 16:36:46 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 2.4327
2022-07-16 16:37:19 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 2.1966
2022-07-16 16:37:52 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 1.9119
2022-07-16 16:38:25 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 2.0543
2022-07-16 16:38:25 - train: epoch 084, train_loss: 2.1704
2022-07-16 16:39:40 - eval: epoch: 084, acc1: 57.084%, acc5: 79.754%, test_loss: 1.8981, per_image_load_time: 2.402ms, per_image_inference_time: 0.139ms
2022-07-16 16:39:40 - until epoch: 084, best_acc1: 57.102%
2022-07-16 16:39:40 - epoch 085 lr: 0.001000
2022-07-16 16:40:18 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 1.9809
2022-07-16 16:40:52 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 2.0554
2022-07-16 16:41:25 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 2.3120
2022-07-16 16:41:58 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 2.0711
2022-07-16 16:42:32 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 2.2639
2022-07-16 16:43:04 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 2.0101
2022-07-16 16:43:36 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 1.9504
2022-07-16 16:44:10 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 2.0533
2022-07-16 16:44:43 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 2.0879
2022-07-16 16:45:17 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 2.3184
2022-07-16 16:45:51 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 2.2350
2022-07-16 16:46:23 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 1.9619
2022-07-16 16:46:57 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 2.1669
2022-07-16 16:47:30 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 2.1036
2022-07-16 16:48:04 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 1.9846
2022-07-16 16:48:37 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 2.1421
2022-07-16 16:49:10 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 2.4433
2022-07-16 16:49:43 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 2.0330
2022-07-16 16:50:16 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 1.9465
2022-07-16 16:50:50 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 2.1738
2022-07-16 16:51:23 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 1.7619
2022-07-16 16:51:55 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 2.2413
2022-07-16 16:52:30 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 2.0134
2022-07-16 16:53:02 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 2.2853
2022-07-16 16:53:35 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 2.5283
2022-07-16 16:54:09 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 2.2588
2022-07-16 16:54:43 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 2.1087
2022-07-16 16:55:15 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 2.4528
2022-07-16 16:55:49 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 2.3693
2022-07-16 16:56:23 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 2.4177
2022-07-16 16:56:56 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 2.1836
2022-07-16 16:57:31 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 2.2665
2022-07-16 16:58:03 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 2.1836
2022-07-16 16:58:37 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 2.2060
2022-07-16 16:59:11 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 2.3411
2022-07-16 16:59:44 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 2.2732
2022-07-16 17:00:17 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 1.9641
2022-07-16 17:00:50 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 2.2415
2022-07-16 17:01:24 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 2.2360
2022-07-16 17:01:57 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 2.4787
2022-07-16 17:02:30 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 2.0741
2022-07-16 17:03:03 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 2.3299
2022-07-16 17:03:37 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 2.1267
2022-07-16 17:04:10 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 2.1792
2022-07-16 17:04:43 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 2.3226
2022-07-16 17:05:17 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 2.2847
2022-07-16 17:05:50 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 2.5579
2022-07-16 17:06:24 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 1.8877
2022-07-16 17:06:57 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 2.2075
2022-07-16 17:07:29 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 2.1279
2022-07-16 17:07:30 - train: epoch 085, train_loss: 2.1738
2022-07-16 17:08:44 - eval: epoch: 085, acc1: 57.052%, acc5: 79.550%, test_loss: 1.9012, per_image_load_time: 2.719ms, per_image_inference_time: 0.127ms
2022-07-16 17:08:45 - until epoch: 085, best_acc1: 57.102%
2022-07-16 17:08:45 - epoch 086 lr: 0.001000
2022-07-16 17:09:22 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 2.0201
2022-07-16 17:09:56 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 1.9711
2022-07-16 17:10:31 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 2.3018
2022-07-16 17:11:03 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 2.1980
2022-07-16 17:11:37 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 2.2298
2022-07-16 17:12:10 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 2.0176
2022-07-16 17:12:42 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 2.0148
2022-07-16 17:13:16 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 2.3583
2022-07-16 17:13:49 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 2.2384
2022-07-16 17:14:21 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 2.2445
2022-07-16 17:14:55 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 2.3071
2022-07-16 17:15:28 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 1.9704
2022-07-16 17:16:01 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 2.1448
2022-07-16 17:16:34 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 2.1093
2022-07-16 17:17:08 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 2.0504
2022-07-16 17:17:41 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 2.2495
2022-07-16 17:18:14 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 2.0067
2022-07-16 17:18:47 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 2.3905
2022-07-16 17:19:21 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 2.2475
2022-07-16 17:19:53 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 2.1490
2022-07-16 17:20:27 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 1.9428
2022-07-16 17:20:59 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 2.1868
2022-07-16 17:21:32 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 2.1840
2022-07-16 17:22:06 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 1.9737
2022-07-16 17:22:39 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 2.1546
2022-07-16 17:23:12 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 2.2425
2022-07-16 17:23:46 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 2.1372
2022-07-16 17:24:19 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 2.1717
2022-07-16 17:24:52 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 1.9079
2022-07-16 17:25:25 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 2.2663
2022-07-16 17:25:59 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 2.0330
2022-07-16 17:26:31 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 2.2199
2022-07-16 17:27:06 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 2.4388
2022-07-16 17:27:39 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 2.3359
2022-07-16 17:28:13 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 2.2299
2022-07-16 17:28:46 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 2.2364
2022-07-16 17:29:20 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 2.2805
2022-07-16 17:29:52 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 2.3172
2022-07-16 17:30:26 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 2.2624
2022-07-16 17:30:59 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 2.2796
2022-07-16 17:31:33 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 2.1532
2022-07-16 17:32:07 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 2.2611
2022-07-16 17:32:40 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 2.2028
2022-07-16 17:33:13 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 2.0622
2022-07-16 17:33:46 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 1.9453
2022-07-16 17:34:20 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 2.1984
2022-07-16 17:34:53 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 2.1688
2022-07-16 17:35:27 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 2.1721
2022-07-16 17:36:00 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 2.1678
2022-07-16 17:36:32 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 2.1403
2022-07-16 17:36:32 - train: epoch 086, train_loss: 2.1713
2022-07-16 17:37:47 - eval: epoch: 086, acc1: 56.838%, acc5: 79.716%, test_loss: 1.8986, per_image_load_time: 2.629ms, per_image_inference_time: 0.135ms
2022-07-16 17:37:48 - until epoch: 086, best_acc1: 57.102%
2022-07-16 17:37:48 - epoch 087 lr: 0.001000
2022-07-16 17:38:26 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 2.1287
2022-07-16 17:39:00 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 1.9428
2022-07-16 17:39:32 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 2.3230
2022-07-16 17:40:06 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 2.3684
2022-07-16 17:40:41 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 1.8276
2022-07-16 17:41:13 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 2.2531
2022-07-16 17:41:47 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 2.0178
2022-07-16 17:42:19 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 2.0904
2022-07-16 17:42:53 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 2.2946
2022-07-16 17:43:26 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 2.1726
2022-07-16 17:43:58 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 2.1949
2022-07-16 17:44:31 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 2.2831
2022-07-16 17:45:04 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 2.3891
2022-07-16 17:45:39 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 2.0738
2022-07-16 17:46:11 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 2.0770
2022-07-16 17:46:44 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 2.0072
2022-07-16 17:47:17 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 2.1917
2022-07-16 17:47:50 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 2.2063
2022-07-16 17:48:24 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 2.2498
2022-07-16 17:48:56 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 2.1189
2022-07-16 17:49:30 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 2.2134
2022-07-16 17:50:03 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 2.1784
2022-07-16 17:50:37 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 2.3759
2022-07-16 17:51:11 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 2.1046
2022-07-16 17:51:44 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 2.2346
2022-07-16 17:52:17 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 2.2024
2022-07-16 17:52:51 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 2.2816
2022-07-16 17:53:24 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 1.9503
2022-07-16 17:53:56 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 2.0521
2022-07-16 17:54:30 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 2.3041
2022-07-16 17:55:02 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 2.2400
2022-07-16 17:55:37 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 2.3097
2022-07-16 17:56:10 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 2.1700
2022-07-16 17:56:43 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 2.2098
2022-07-16 17:57:16 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 2.0762
2022-07-16 17:57:49 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 2.0395
2022-07-16 17:58:23 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 2.2386
2022-07-16 17:58:56 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 2.1984
2022-07-16 17:59:29 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 2.0349
2022-07-16 18:00:03 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 2.2039
2022-07-16 18:00:36 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 2.3312
2022-07-16 18:01:09 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 2.1705
2022-07-16 18:01:43 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 2.2012
2022-07-16 18:02:15 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 2.1517
2022-07-16 18:02:49 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 2.1792
2022-07-16 18:03:22 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 2.1843
2022-07-16 18:03:56 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 2.2120
2022-07-16 18:04:29 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 2.0126
2022-07-16 18:05:02 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 2.0963
2022-07-16 18:05:35 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 2.1228
2022-07-16 18:05:35 - train: epoch 087, train_loss: 2.1711
2022-07-16 18:06:50 - eval: epoch: 087, acc1: 57.108%, acc5: 79.748%, test_loss: 1.8970, per_image_load_time: 2.135ms, per_image_inference_time: 0.132ms
2022-07-16 18:06:50 - until epoch: 087, best_acc1: 57.108%
2022-07-16 18:26:30 - epoch 088 lr: 0.001000
2022-07-16 18:27:09 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 2.0942
2022-07-16 18:27:43 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 2.1684
2022-07-16 18:28:15 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 2.3755
2022-07-16 18:28:51 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 2.3727
2022-07-16 18:29:24 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 2.3598
2022-07-16 18:29:58 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 2.1985
2022-07-16 18:30:32 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 2.1765
2022-07-16 18:31:07 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 2.2046
2022-07-16 18:31:40 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 2.1926
2022-07-16 18:32:13 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 2.1355
2022-07-16 18:32:46 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 2.2094
2022-07-16 18:33:20 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 2.3191
2022-07-16 18:33:54 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 2.0639
2022-07-16 18:34:29 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 2.0028
2022-07-16 18:35:01 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 2.0989
2022-07-16 18:35:35 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 2.0558
2022-07-16 18:36:07 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 2.2320
2022-07-16 18:36:42 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 1.8850
2022-07-16 18:37:15 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 2.1970
2022-07-16 18:37:48 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 2.1244
2022-07-16 18:38:21 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 2.2772
2022-07-16 18:38:55 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 2.2331
2022-07-16 18:39:28 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 2.0792
2022-07-16 18:40:02 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 2.2719
2022-07-16 18:40:35 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 2.5233
2022-07-16 18:41:10 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 2.1378
2022-07-16 18:41:42 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 2.1314
2022-07-16 18:42:17 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 2.4393
2022-07-16 18:42:50 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 1.9245
2022-07-16 18:43:23 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 2.5442
2022-07-16 18:43:57 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 1.9316
2022-07-16 18:44:30 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 2.0310
2022-07-16 18:45:04 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 1.9189
2022-07-16 18:45:37 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 2.1083
2022-07-16 18:46:12 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 2.2242
2022-07-16 18:46:44 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 2.1842
2022-07-16 18:47:18 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 2.2989
2022-07-16 18:47:53 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 2.4422
2022-07-16 18:48:25 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 2.4073
2022-07-16 18:48:59 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 1.9212
2022-07-16 18:49:32 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 2.1745
2022-07-16 18:50:07 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 2.3051
2022-07-16 18:50:39 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 1.9435
2022-07-16 18:51:14 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 2.0190
2022-07-16 18:51:47 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 2.0587
2022-07-16 18:52:21 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 2.3930
2022-07-16 18:52:53 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 2.3560
2022-07-16 18:53:27 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 2.0382
2022-07-16 18:54:00 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 1.9995
2022-07-16 18:54:32 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 2.4213
2022-07-16 18:54:33 - train: epoch 088, train_loss: 2.1722
2022-07-16 18:55:48 - eval: epoch: 088, acc1: 57.090%, acc5: 79.708%, test_loss: 1.8957, per_image_load_time: 2.807ms, per_image_inference_time: 0.140ms
2022-07-16 18:55:48 - until epoch: 088, best_acc1: 57.108%
2022-07-16 18:55:48 - epoch 089 lr: 0.001000
2022-07-16 18:56:26 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 2.5202
2022-07-16 18:57:00 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 2.0066
2022-07-16 18:57:32 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 2.1616
2022-07-16 18:58:07 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 2.0894
2022-07-16 18:58:39 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 2.2039
2022-07-16 18:59:12 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 2.0511
2022-07-16 18:59:46 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 2.0902
2022-07-16 19:00:19 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 2.5298
2022-07-16 19:00:53 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 2.2078
2022-07-16 19:01:26 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 2.2669
2022-07-16 19:02:00 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 2.3295
2022-07-16 19:02:33 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 2.3299
2022-07-16 19:03:06 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 2.0007
2022-07-16 19:03:40 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 2.2772
2022-07-16 19:04:13 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 2.0862
2022-07-16 19:04:47 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 2.0350
2022-07-16 19:05:21 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 2.3189
2022-07-16 19:05:55 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 2.5137
2022-07-16 19:06:29 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 2.0671
2022-07-16 19:07:03 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 2.2084
2022-07-16 19:07:35 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 2.2332
2022-07-16 19:08:09 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 2.2232
2022-07-16 19:08:43 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 2.1319
2022-07-16 19:09:17 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 2.4093
2022-07-16 19:09:51 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 2.1960
2022-07-16 19:10:24 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 2.0135
2022-07-16 19:10:57 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 2.0856
2022-07-16 19:11:31 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 2.2035
2022-07-16 19:12:05 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 2.3033
2022-07-16 19:12:38 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 2.1116
2022-07-16 19:13:12 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 2.0291
2022-07-16 19:13:45 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 2.3905
2022-07-16 19:14:19 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 2.2575
2022-07-16 19:14:52 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 2.0997
2022-07-16 19:15:26 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 1.9424
2022-07-16 19:16:00 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 2.0877
2022-07-16 19:16:34 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 2.2048
2022-07-16 19:17:07 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 2.1887
2022-07-16 19:17:43 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 2.4014
2022-07-16 19:18:15 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 2.0591
2022-07-16 19:18:49 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 2.3404
2022-07-16 19:19:23 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 2.1012
2022-07-16 19:19:57 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 2.3474
2022-07-16 19:20:30 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 2.2752
2022-07-16 19:21:04 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 1.9140
2022-07-16 19:21:37 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 2.2748
2022-07-16 19:22:14 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 2.2976
2022-07-16 19:22:47 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 2.2429
2022-07-16 19:23:21 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 2.2479
2022-07-16 19:23:53 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 1.7053
2022-07-16 19:23:53 - train: epoch 089, train_loss: 2.1694
2022-07-16 19:25:09 - eval: epoch: 089, acc1: 57.044%, acc5: 79.754%, test_loss: 1.8958, per_image_load_time: 2.591ms, per_image_inference_time: 0.148ms
2022-07-16 19:25:09 - until epoch: 089, best_acc1: 57.108%
2022-07-16 19:25:09 - epoch 090 lr: 0.001000
2022-07-16 19:25:48 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 2.4634
2022-07-16 19:26:20 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 2.0013
2022-07-16 19:26:54 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 1.9637
2022-07-16 19:27:28 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 2.0993
2022-07-16 19:28:01 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 2.1966
2022-07-16 19:28:35 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 2.5099
2022-07-16 19:29:07 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 2.1835
2022-07-16 19:29:41 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 2.1286
2022-07-16 19:30:15 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 2.2940
2022-07-16 19:30:48 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 2.0855
2022-07-16 19:31:22 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 2.2660
2022-07-16 19:31:54 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 1.9447
2022-07-16 19:32:28 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 2.3095
2022-07-16 19:33:01 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 1.9664
2022-07-16 19:33:35 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 2.3258
2022-07-16 19:34:10 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 2.1964
2022-07-16 19:34:43 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 1.9456
2022-07-16 19:35:17 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 2.0694
2022-07-16 19:35:49 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 2.2106
2022-07-16 19:36:23 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 2.2511
2022-07-16 19:36:57 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 2.2937
2022-07-16 19:37:30 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 2.1882
2022-07-16 19:38:05 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 2.4274
2022-07-16 19:38:38 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 2.1473
2022-07-16 19:39:11 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 2.2205
2022-07-16 19:39:45 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 2.0046
2022-07-16 19:40:18 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 2.0822
2022-07-16 19:40:52 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 2.3196
2022-07-16 19:41:25 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 2.0473
2022-07-16 19:42:00 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 2.1132
2022-07-16 19:42:34 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 2.0928
2022-07-16 19:43:07 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 2.2365
2022-07-16 19:43:40 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 2.4718
2022-07-16 19:44:14 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 2.1775
2022-07-16 19:44:47 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 1.9938
2022-07-16 19:45:22 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 2.0387
2022-07-16 19:45:56 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 2.3456
2022-07-16 19:46:30 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 2.2020
2022-07-16 19:47:04 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 1.8839
2022-07-16 19:47:38 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 2.1381
2022-07-16 19:48:11 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 2.3358
2022-07-16 19:48:46 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 2.2331
2022-07-16 19:49:19 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 2.1443
2022-07-16 19:49:53 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 2.0229
2022-07-16 19:50:27 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 2.1293
2022-07-16 19:51:00 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 2.3075
2022-07-16 19:51:34 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 1.9089
2022-07-16 19:52:07 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 2.4226
2022-07-16 19:52:42 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 2.0195
2022-07-16 19:53:14 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 2.0079
2022-07-16 19:53:14 - train: epoch 090, train_loss: 2.1696
2022-07-16 19:54:30 - eval: epoch: 090, acc1: 57.090%, acc5: 79.648%, test_loss: 1.8969, per_image_load_time: 2.689ms, per_image_inference_time: 0.125ms
2022-07-16 19:54:30 - until epoch: 090, best_acc1: 57.108%
2022-07-16 19:54:30 - epoch 091 lr: 0.000100
2022-07-16 19:55:08 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 1.9581
2022-07-16 19:55:42 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 1.9949
2022-07-16 19:56:15 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 2.1386
2022-07-16 19:56:49 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 2.3738
2022-07-16 19:57:22 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 2.1887
2022-07-16 19:57:55 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 2.2870
2022-07-16 19:58:29 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 2.2527
2022-07-16 19:59:03 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 2.0679
2022-07-16 19:59:37 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 2.0792
2022-07-16 20:00:10 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 1.9630
2022-07-16 20:00:43 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 1.8222
2022-07-16 20:01:17 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 2.1577
2022-07-16 20:01:52 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 2.0401
2022-07-16 20:02:25 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 2.1578
2022-07-16 20:02:59 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 2.0826
2022-07-16 20:03:33 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 2.0542
2022-07-16 20:04:07 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 2.0541
2022-07-16 20:04:41 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 2.3463
2022-07-16 20:05:14 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 2.2961
2022-07-16 20:05:50 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 2.1288
2022-07-16 20:06:23 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 1.9745
2022-07-16 20:06:57 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 2.4441
2022-07-16 20:07:30 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 2.0836
2022-07-16 20:08:04 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 1.9901
2022-07-16 20:08:39 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 2.1566
2022-07-16 20:09:12 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 1.9590
2022-07-16 20:09:46 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 2.2623
2022-07-16 20:10:19 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 2.3399
2022-07-16 20:10:53 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 2.3169
2022-07-16 20:11:28 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 2.2068
2022-07-16 20:12:00 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 2.3728
2022-07-16 20:12:34 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 2.3265
2022-07-16 20:13:07 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 2.3322
2022-07-16 20:13:42 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 2.2398
2022-07-16 20:14:15 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 2.1974
2022-07-16 20:14:51 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 2.1625
2022-07-16 20:15:23 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 2.3464
2022-07-16 20:15:58 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 2.2089
2022-07-16 20:16:31 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 2.0345
2022-07-16 20:17:06 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 2.0492
2022-07-16 20:17:38 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 1.9915
2022-07-16 20:18:13 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 2.0899
2022-07-16 20:18:46 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 2.0763
2022-07-16 20:19:20 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 1.9908
2022-07-16 20:19:53 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 1.8986
2022-07-16 20:20:27 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 2.1367
2022-07-16 20:21:02 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 1.9956
2022-07-16 20:21:36 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 2.2386
2022-07-16 20:22:09 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 2.2313
2022-07-16 20:22:42 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 2.4112
2022-07-16 20:22:43 - train: epoch 091, train_loss: 2.1459
2022-07-16 20:23:58 - eval: epoch: 091, acc1: 57.454%, acc5: 79.992%, test_loss: 1.8803, per_image_load_time: 2.701ms, per_image_inference_time: 0.129ms
2022-07-16 20:23:58 - until epoch: 091, best_acc1: 57.454%
2022-07-16 20:23:58 - epoch 092 lr: 0.000100
2022-07-16 20:24:36 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 1.9791
2022-07-16 20:25:11 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 2.2447
2022-07-16 20:25:43 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 2.1369
2022-07-16 20:26:18 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 2.0785
2022-07-16 20:26:50 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 2.1799
2022-07-16 20:27:25 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 2.1399
2022-07-16 20:27:59 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 1.9417
2022-07-16 20:28:31 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 2.2236
2022-07-16 20:29:05 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 2.2397
2022-07-16 20:29:38 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 2.1959
2022-07-16 20:30:12 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 1.9517
2022-07-16 20:30:45 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 2.0661
2022-07-16 20:31:19 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 2.0454
2022-07-16 20:31:52 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 1.9970
2022-07-16 20:32:26 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 1.9034
2022-07-16 20:32:59 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 2.1286
2022-07-16 20:33:32 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 2.0514
2022-07-16 20:34:06 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 2.1553
2022-07-16 20:34:39 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 2.0589
2022-07-16 20:35:13 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 2.2042
2022-07-16 20:35:44 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 2.2083
2022-07-16 20:36:19 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 2.0335
2022-07-16 20:36:52 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 2.1360
2022-07-16 20:37:26 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 2.1664
2022-07-16 20:37:59 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 2.2198
2022-07-16 20:38:33 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 2.1019
2022-07-16 20:39:07 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 2.2273
2022-07-16 20:39:41 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 2.1120
2022-07-16 20:40:14 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 2.4112
2022-07-16 20:40:47 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 2.0044
2022-07-16 20:41:21 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 2.2588
2022-07-16 20:41:55 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 2.0480
2022-07-16 20:42:29 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 1.8700
2022-07-16 20:43:03 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 2.2635
2022-07-16 20:43:36 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 2.2205
2022-07-16 20:44:11 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 2.1164
2022-07-16 20:44:44 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 1.9982
2022-07-16 20:45:17 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 2.0792
2022-07-16 20:45:52 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 2.3305
2022-07-16 20:46:26 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 2.1799
2022-07-16 20:47:00 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 1.9790
2022-07-16 20:47:34 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 2.3050
2022-07-16 20:48:08 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 2.2850
2022-07-16 20:48:41 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 2.2422
2022-07-16 20:49:15 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 2.2299
2022-07-16 20:49:49 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 2.2057
2022-07-16 20:50:22 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 2.1373
2022-07-16 20:50:57 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 2.1139
2022-07-16 20:51:30 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 1.8551
2022-07-16 20:52:02 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 2.0072
2022-07-16 20:52:03 - train: epoch 092, train_loss: 2.1425
2022-07-16 20:53:18 - eval: epoch: 092, acc1: 57.408%, acc5: 80.012%, test_loss: 1.8806, per_image_load_time: 2.752ms, per_image_inference_time: 0.131ms
2022-07-16 20:53:18 - until epoch: 092, best_acc1: 57.454%
2022-07-16 20:53:18 - epoch 093 lr: 0.000100
2022-07-16 20:53:57 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 2.3707
2022-07-16 20:54:30 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 2.0061
2022-07-16 20:55:03 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 2.0840
2022-07-16 20:55:38 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 2.3103
2022-07-16 20:56:11 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 2.1851
2022-07-16 20:56:43 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 1.9976
2022-07-16 20:57:17 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 2.2216
2022-07-16 20:57:51 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 2.1347
2022-07-16 20:58:24 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 1.8944
2022-07-16 20:58:57 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 2.0146
2022-07-16 20:59:31 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 2.4231
2022-07-16 21:00:05 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 2.2638
2022-07-16 21:00:38 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 2.0280
2022-07-16 21:01:13 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 2.2517
2022-07-16 21:01:46 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 2.1655
2022-07-16 21:02:20 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 2.1539
2022-07-16 21:02:52 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 2.2396
2022-07-16 21:03:26 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 2.1389
2022-07-16 21:04:00 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 1.8358
2022-07-16 21:04:33 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 1.9414
2022-07-16 21:05:07 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 1.9998
2022-07-16 21:05:42 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 2.2539
2022-07-16 21:06:16 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 2.2208
2022-07-16 21:06:48 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 2.0868
2022-07-16 21:07:23 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 2.1936
2022-07-16 21:07:56 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 2.2160
2022-07-16 21:08:30 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 2.1020
2022-07-16 21:09:04 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 2.1089
2022-07-16 21:09:38 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 1.8170
2022-07-16 21:10:11 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 1.9727
2022-07-16 21:10:45 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 2.1779
2022-07-16 21:11:18 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 2.0927
2022-07-16 21:11:53 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 2.0906
2022-07-16 21:12:26 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 2.3954
2022-07-16 21:13:01 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 2.2415
2022-07-16 21:13:34 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 2.2238
2022-07-16 21:14:09 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 2.1552
2022-07-16 21:14:41 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 2.1745
2022-07-16 21:15:16 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 2.0253
2022-07-16 21:15:49 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 2.3409
2022-07-16 21:16:22 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 2.3151
2022-07-16 21:16:56 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 2.2001
2022-07-16 21:17:30 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 2.2093
2022-07-16 21:18:04 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 2.0440
2022-07-16 21:18:38 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 2.1332
2022-07-16 21:19:10 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 1.9840
2022-07-16 21:19:46 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 2.5249
2022-07-16 21:20:18 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 2.1330
2022-07-16 21:20:52 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 2.0218
2022-07-16 21:21:24 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 2.2316
2022-07-16 21:21:25 - train: epoch 093, train_loss: 2.1403
2022-07-16 21:22:41 - eval: epoch: 093, acc1: 57.480%, acc5: 80.036%, test_loss: 1.8781, per_image_load_time: 2.752ms, per_image_inference_time: 0.146ms
2022-07-16 21:22:41 - until epoch: 093, best_acc1: 57.480%
2022-07-16 21:22:41 - epoch 094 lr: 0.000100
2022-07-16 21:23:19 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 2.0607
2022-07-16 21:23:53 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 2.1653
2022-07-16 21:24:26 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 2.3433
2022-07-16 21:24:59 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 2.3165
2022-07-16 21:25:33 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 1.9689
2022-07-16 21:26:07 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 2.0397
2022-07-16 21:26:40 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 2.2428
2022-07-16 21:27:14 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 2.2481
2022-07-16 21:27:48 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 2.2791
2022-07-16 21:28:21 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 2.2132
2022-07-16 21:28:55 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 2.0760
2022-07-16 21:29:28 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 2.2019
2022-07-16 21:30:02 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 2.0122
2022-07-16 21:30:35 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 2.2620
2022-07-16 21:31:08 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 2.1449
2022-07-16 21:31:43 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 2.5333
2022-07-16 21:32:16 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 1.9743
2022-07-16 21:32:49 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 2.0556
2022-07-16 21:33:23 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 2.0467
2022-07-16 21:33:56 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 1.9917
2022-07-16 21:34:30 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 1.9471
2022-07-16 21:35:03 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 1.8240
2022-07-16 21:35:38 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 2.1185
2022-07-16 21:36:12 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 2.0348
2022-07-16 21:36:46 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 2.1870
2022-07-16 21:37:19 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 2.2086
2022-07-16 21:37:54 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 2.1899
2022-07-16 21:38:27 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 2.4755
2022-07-16 21:39:00 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 2.0431
2022-07-16 21:39:35 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 2.0961
2022-07-16 21:40:07 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 2.2385
2022-07-16 21:40:41 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 2.1343
2022-07-16 21:41:15 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 2.0454
2022-07-16 21:41:49 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 2.2758
2022-07-16 21:42:22 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 2.4439
2022-07-16 21:42:57 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 2.1729
2022-07-16 21:43:30 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 2.1954
2022-07-16 21:44:04 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 1.9572
2022-07-16 21:44:38 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 2.0921
2022-07-16 21:45:11 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 2.2522
2022-07-16 21:45:46 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 2.0600
2022-07-16 21:46:20 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 2.1897
2022-07-16 21:46:53 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 2.2951
2022-07-16 21:47:28 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 2.3760
2022-07-16 21:48:01 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 2.1693
2022-07-16 21:48:33 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 2.2403
2022-07-16 21:49:09 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 2.2989
2022-07-16 21:49:41 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 1.9695
2022-07-16 21:50:16 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 2.1027
2022-07-16 21:50:47 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 1.9320
2022-07-16 21:50:48 - train: epoch 094, train_loss: 2.1405
2022-07-16 21:52:02 - eval: epoch: 094, acc1: 57.526%, acc5: 80.034%, test_loss: 1.8780, per_image_load_time: 2.745ms, per_image_inference_time: 0.133ms
2022-07-16 21:52:02 - until epoch: 094, best_acc1: 57.526%
2022-07-16 21:52:02 - epoch 095 lr: 0.000100
2022-07-16 21:52:41 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 2.2707
2022-07-16 21:53:14 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 2.3526
2022-07-16 21:53:48 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 2.0714
2022-07-16 21:54:20 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 2.2450
2022-07-16 21:54:55 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 2.3621
2022-07-16 21:55:27 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 2.0600
2022-07-16 21:56:01 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 2.1476
2022-07-16 21:56:36 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 2.2006
2022-07-16 21:57:08 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 2.4050
2022-07-16 21:57:42 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 2.3208
2022-07-16 21:58:15 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 1.8436
2022-07-16 21:58:48 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 2.1005
2022-07-16 21:59:23 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 2.1281
2022-07-16 21:59:55 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 2.0755
2022-07-16 22:00:29 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 2.2658
2022-07-16 22:01:03 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 1.6992
2022-07-16 22:01:37 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 2.2320
2022-07-16 22:02:10 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 2.1629
2022-07-16 22:02:44 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 1.9428
2022-07-16 22:03:17 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 2.3125
2022-07-16 22:03:50 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 2.1132
2022-07-16 22:04:25 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 1.7845
2022-07-16 22:04:59 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 2.2581
2022-07-16 22:05:32 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 2.1892
2022-07-16 22:06:05 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 2.0868
2022-07-16 22:06:39 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 2.1666
2022-07-16 22:07:13 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 2.0952
2022-07-16 22:07:47 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 1.9489
2022-07-16 22:08:20 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 2.2316
2022-07-16 22:08:54 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 2.3168
2022-07-16 22:09:27 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 2.1698
2022-07-16 22:10:01 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 2.1885
2022-07-16 22:10:35 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 2.2183
2022-07-16 22:11:08 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 1.9976
2022-07-16 22:11:42 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 2.0679
2022-07-16 22:12:15 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 1.9132
2022-07-16 22:12:49 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 2.1922
2022-07-16 22:13:22 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 1.8328
2022-07-16 22:13:57 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 2.2293
2022-07-16 22:14:29 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 1.9969
2022-07-16 22:15:04 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 2.2391
2022-07-16 22:15:37 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 2.1219
2022-07-16 22:16:11 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 2.1952
2022-07-16 22:16:45 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 2.4026
2022-07-16 22:17:19 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 1.9931
2022-07-16 22:17:52 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 2.0175
2022-07-16 22:18:25 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 2.0581
2022-07-16 22:18:59 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 1.9791
2022-07-16 22:19:32 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 2.0628
2022-07-16 22:20:05 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 1.9259
2022-07-16 22:20:05 - train: epoch 095, train_loss: 2.1396
2022-07-16 22:21:20 - eval: epoch: 095, acc1: 57.502%, acc5: 80.064%, test_loss: 1.8787, per_image_load_time: 2.769ms, per_image_inference_time: 0.143ms
2022-07-16 22:21:20 - until epoch: 095, best_acc1: 57.526%
2022-07-16 22:21:20 - epoch 096 lr: 0.000100
2022-07-16 22:21:59 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 2.2767
2022-07-16 22:22:32 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 1.9539
2022-07-16 22:23:05 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 2.0903
2022-07-16 22:23:38 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 2.0248
2022-07-16 22:24:11 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 2.2001
2022-07-16 22:24:46 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 2.1466
2022-07-16 22:25:19 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 2.1388
2022-07-16 22:25:52 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 2.0140
2022-07-16 22:26:26 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 2.1894
2022-07-16 22:27:00 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 2.2247
2022-07-16 22:27:32 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 2.2000
2022-07-16 22:28:08 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 1.9651
2022-07-16 22:28:39 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 2.1203
2022-07-16 22:29:13 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 2.1842
2022-07-16 22:29:47 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 2.0703
2022-07-16 22:30:20 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 1.9516
2022-07-16 22:30:54 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 1.9558
2022-07-16 22:31:27 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 2.2948
2022-07-16 22:32:01 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 2.1861
2022-07-16 22:32:34 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 2.1072
2022-07-16 22:33:09 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 2.1337
2022-07-16 22:33:43 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 1.7401
2022-07-16 22:34:18 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 1.9135
2022-07-16 22:34:50 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 1.9829
2022-07-16 22:35:25 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 1.9826
2022-07-16 22:35:59 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 2.1273
2022-07-16 22:36:33 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 2.2221
2022-07-16 22:37:07 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 2.1321
2022-07-16 22:37:41 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 2.4364
2022-07-16 22:38:15 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 2.2047
2022-07-16 22:38:49 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 2.1022
2022-07-16 22:39:22 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 2.3648
2022-07-16 22:39:57 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 2.3860
2022-07-16 22:40:30 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 2.0697
2022-07-16 22:41:04 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 2.1656
2022-07-16 22:41:37 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 1.9492
2022-07-16 22:42:13 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 2.0602
2022-07-16 22:42:45 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 2.0006
2022-07-16 22:43:19 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 1.7543
2022-07-16 22:43:55 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 2.0613
2022-07-16 22:44:29 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 2.2379
2022-07-16 22:45:02 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 2.0029
2022-07-16 22:45:36 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 1.8186
2022-07-16 22:46:09 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 2.0327
2022-07-16 22:46:44 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 2.1128
2022-07-16 22:47:16 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 1.9755
2022-07-16 22:47:51 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 2.1653
2022-07-16 22:48:25 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 2.0388
2022-07-16 22:48:59 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 2.4196
2022-07-16 22:49:31 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 2.1279
2022-07-16 22:49:32 - train: epoch 096, train_loss: 2.1384
2022-07-16 22:50:47 - eval: epoch: 096, acc1: 57.562%, acc5: 80.040%, test_loss: 1.8763, per_image_load_time: 2.593ms, per_image_inference_time: 0.127ms
2022-07-16 22:50:47 - until epoch: 096, best_acc1: 57.562%
2022-07-16 22:50:47 - epoch 097 lr: 0.000100
2022-07-16 22:51:25 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 2.0748
2022-07-16 22:51:59 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 2.0563
2022-07-16 22:52:32 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 2.0901
2022-07-16 22:53:06 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 2.3150
2022-07-16 22:53:39 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 2.2743
2022-07-16 22:54:12 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 2.2397
2022-07-16 22:54:47 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 2.0643
2022-07-16 22:55:19 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 2.1126
2022-07-16 22:55:53 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 2.0462
2022-07-16 22:56:28 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 2.3496
2022-07-16 22:57:01 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 1.9273
2022-07-16 22:57:34 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 2.2717
2022-07-16 22:58:08 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 2.2221
2022-07-16 22:58:43 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 2.1564
2022-07-16 22:59:15 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 2.0356
2022-07-16 22:59:49 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 2.0477
2022-07-16 23:00:23 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 2.0950
2022-07-16 23:00:57 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 2.3031
2022-07-16 23:01:30 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 2.0624
2022-07-16 23:02:05 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 2.1217
2022-07-16 23:02:38 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 2.0925
2022-07-16 23:03:11 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 2.1350
2022-07-16 23:03:45 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 1.9987
2022-07-16 23:04:19 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 2.2830
2022-07-16 23:04:54 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 2.2756
2022-07-16 23:05:27 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 2.2394
2022-07-16 23:06:00 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 2.2797
2022-07-16 23:06:35 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 2.1944
2022-07-16 23:07:08 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 2.0687
2022-07-16 23:07:43 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 2.2746
2022-07-16 23:08:16 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 2.2286
2022-07-16 23:08:50 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 2.1153
2022-07-16 23:09:23 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 2.3120
2022-07-16 23:09:56 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 2.2462
2022-07-16 23:10:30 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 2.1491
2022-07-16 23:11:06 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 2.2734
2022-07-16 23:11:38 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 1.7414
2022-07-16 23:12:13 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 1.7931
2022-07-16 23:12:45 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 2.1233
2022-07-16 23:13:20 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 2.3320
2022-07-16 23:13:54 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 2.1586
2022-07-16 23:14:27 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 1.9878
2022-07-16 23:15:01 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 1.9610
2022-07-16 23:15:36 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 2.0411
2022-07-16 23:16:09 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 2.2499
2022-07-16 23:16:42 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 2.2485
2022-07-16 23:17:17 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 2.1718
2022-07-16 23:17:51 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 2.2026
2022-07-16 23:18:25 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 2.2211
2022-07-16 23:18:57 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 1.8206
2022-07-16 23:18:57 - train: epoch 097, train_loss: 2.1415
2022-07-16 23:20:12 - eval: epoch: 097, acc1: 57.602%, acc5: 80.020%, test_loss: 1.8740, per_image_load_time: 2.793ms, per_image_inference_time: 0.135ms
2022-07-16 23:20:12 - until epoch: 097, best_acc1: 57.602%
2022-07-16 23:20:12 - epoch 098 lr: 0.000100
2022-07-16 23:20:51 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 2.2132
2022-07-16 23:21:24 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 2.4173
2022-07-16 23:21:59 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 2.0647
2022-07-16 23:22:31 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 2.1440
2022-07-16 23:23:05 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 1.9918
2022-07-16 23:23:38 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 2.1248
2022-07-16 23:24:13 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 1.9565
2022-07-16 23:24:46 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 2.1796
2022-07-16 23:25:20 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 2.1407
2022-07-16 23:25:53 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 2.2554
2022-07-16 23:26:27 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 1.9025
2022-07-16 23:27:00 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 2.2313
2022-07-16 23:27:33 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 2.1161
2022-07-16 23:28:07 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 2.1007
2022-07-16 23:28:41 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 2.1245
2022-07-16 23:29:14 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 2.0428
2022-07-16 23:29:48 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 1.9398
2022-07-16 23:30:22 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 2.2056
2022-07-16 23:30:56 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 2.0317
2022-07-16 23:31:30 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 1.9980
2022-07-16 23:32:03 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 2.3561
2022-07-16 23:32:37 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 2.0857
2022-07-16 23:33:10 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 2.0689
2022-07-16 23:33:44 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 2.2697
2022-07-16 23:34:17 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 2.1189
2022-07-16 23:34:51 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 2.0370
2022-07-16 23:35:26 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 2.1505
2022-07-16 23:35:59 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 2.2172
2022-07-16 23:36:32 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 2.1107
2022-07-16 23:37:07 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 2.0242
2022-07-16 23:37:41 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 2.1622
2022-07-16 23:38:14 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 1.8499
2022-07-16 23:38:48 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 2.0012
2022-07-16 23:39:21 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 2.2228
2022-07-16 23:39:56 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 1.9743
2022-07-16 23:40:29 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 2.3803
2022-07-16 23:41:02 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 1.8881
2022-07-16 23:41:36 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 2.0537
2022-07-16 23:42:09 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 2.2789
2022-07-16 23:42:44 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 2.0970
2022-07-16 23:43:16 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 2.1014
2022-07-16 23:43:51 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 2.0827
2022-07-16 23:44:25 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 2.0045
2022-07-16 23:44:58 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 2.4006
2022-07-16 23:45:32 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 2.0870
2022-07-16 23:46:06 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 2.0851
2022-07-16 23:46:41 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 2.0494
2022-07-16 23:47:14 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 1.9916
2022-07-16 23:47:47 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 2.0969
2022-07-16 23:48:19 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 2.1145
2022-07-16 23:48:20 - train: epoch 098, train_loss: 2.1397
2022-07-16 23:49:35 - eval: epoch: 098, acc1: 57.580%, acc5: 80.002%, test_loss: 1.8759, per_image_load_time: 2.775ms, per_image_inference_time: 0.141ms
2022-07-16 23:49:35 - until epoch: 098, best_acc1: 57.602%
2022-07-16 23:49:35 - epoch 099 lr: 0.000100
2022-07-16 23:50:13 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 2.1750
2022-07-16 23:50:47 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 2.1084
2022-07-16 23:51:21 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 1.9501
2022-07-16 23:51:55 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 2.1203
2022-07-16 23:52:28 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 2.3437
2022-07-16 23:53:00 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 2.2553
2022-07-16 23:53:34 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 2.2997
2022-07-16 23:54:07 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 2.2238
2022-07-16 23:54:41 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 2.0449
2022-07-16 23:55:14 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 2.0322
2022-07-16 23:55:49 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 2.1108
2022-07-16 23:56:24 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 2.0651
2022-07-16 23:56:56 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 2.3180
2022-07-16 23:57:31 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 2.1240
2022-07-16 23:58:04 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 2.1433
2022-07-16 23:58:38 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 2.0748
2022-07-16 23:59:11 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 2.1011
2022-07-16 23:59:45 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 2.1383
2022-07-17 00:00:18 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 1.9528
2022-07-17 00:00:53 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 1.9785
2022-07-17 00:01:26 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 2.0783
2022-07-17 00:01:59 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 1.9140
2022-07-17 00:02:34 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 2.0472
2022-07-17 00:03:08 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 2.4261
2022-07-17 00:03:42 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 2.0537
2022-07-17 00:04:15 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 1.9735
2022-07-17 00:04:49 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 2.2151
2022-07-17 00:05:23 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 2.1144
2022-07-17 00:05:57 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 2.0678
2022-07-17 00:06:32 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 2.2795
2022-07-17 00:07:05 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 2.0511
2022-07-17 00:07:39 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 2.3073
2022-07-17 00:08:12 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 2.2240
2022-07-17 00:08:46 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 2.3005
2022-07-17 00:09:19 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 2.3821
2022-07-17 00:09:52 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 1.9935
2022-07-17 00:10:26 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 2.0928
2022-07-17 00:11:00 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 2.2423
2022-07-17 00:11:34 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 2.1745
2022-07-17 00:12:07 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 2.1577
2022-07-17 00:12:43 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 1.9224
2022-07-17 00:13:15 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 2.3588
2022-07-17 00:13:50 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 2.1976
2022-07-17 00:14:23 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 2.2319
2022-07-17 00:14:57 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 2.1404
2022-07-17 00:15:31 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 2.2887
2022-07-17 00:16:04 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 1.9508
2022-07-17 00:16:39 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 2.2892
2022-07-17 00:17:12 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 2.0426
2022-07-17 00:17:45 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 2.3728
2022-07-17 00:17:46 - train: epoch 099, train_loss: 2.1361
2022-07-17 00:19:00 - eval: epoch: 099, acc1: 57.596%, acc5: 79.956%, test_loss: 1.8767, per_image_load_time: 2.668ms, per_image_inference_time: 0.134ms
2022-07-17 00:19:00 - until epoch: 099, best_acc1: 57.602%
2022-07-17 00:19:00 - epoch 100 lr: 0.000100
2022-07-17 00:19:39 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 2.2078
2022-07-17 00:20:13 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 2.0997
2022-07-17 00:20:46 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 2.1989
2022-07-17 00:21:19 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 1.9098
2022-07-17 00:21:53 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 2.1201
2022-07-17 00:22:26 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 2.2330
2022-07-17 00:23:00 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 2.0196
2022-07-17 00:23:35 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 2.3011
2022-07-17 00:24:08 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 2.1500
2022-07-17 00:24:40 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 2.0804
2022-07-17 00:25:14 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 2.0579
2022-07-17 00:25:48 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 2.2669
2022-07-17 00:26:21 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 2.2481
2022-07-17 00:26:55 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 2.2610
2022-07-17 00:27:29 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 2.1310
2022-07-17 00:28:02 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 1.9411
2022-07-17 00:28:36 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 2.0498
2022-07-17 00:29:09 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 1.9995
2022-07-17 00:29:43 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 2.0952
2022-07-17 00:30:17 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 2.2158
2022-07-17 00:30:50 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 2.0741
2022-07-17 00:31:24 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 2.4006
2022-07-17 00:31:57 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 1.9211
2022-07-17 00:32:31 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 2.4180
2022-07-17 00:33:05 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 2.1144
2022-07-17 00:33:39 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 2.1485
2022-07-17 00:34:12 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 2.1869
2022-07-17 00:34:46 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 2.1179
2022-07-17 00:35:20 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 2.3346
2022-07-17 00:35:54 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 2.0986
2022-07-17 00:36:27 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 2.0154
2022-07-17 00:37:01 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 2.5202
2022-07-17 00:37:34 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 2.2857
2022-07-17 00:38:08 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 2.2213
2022-07-17 00:38:42 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 2.0679
2022-07-17 00:39:16 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 2.0414
2022-07-17 00:39:50 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 1.9311
2022-07-17 00:40:24 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 1.9769
2022-07-17 00:40:57 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 2.1465
2022-07-17 00:41:32 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 2.0822
2022-07-17 00:42:05 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 2.1839
2022-07-17 00:42:39 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 2.1455
2022-07-17 00:43:13 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 2.0725
2022-07-17 00:43:47 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 2.3665
2022-07-17 00:44:20 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 1.9498
2022-07-17 00:44:55 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 2.1594
2022-07-17 00:45:28 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 2.5986
2022-07-17 00:46:02 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 2.0198
2022-07-17 00:46:36 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 2.1361
2022-07-17 00:47:08 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 2.1533
2022-07-17 00:47:09 - train: epoch 100, train_loss: 2.1379
2022-07-17 00:48:24 - eval: epoch: 100, acc1: 57.526%, acc5: 80.082%, test_loss: 1.8759, per_image_load_time: 2.805ms, per_image_inference_time: 0.133ms
2022-07-17 00:48:24 - until epoch: 100, best_acc1: 57.602%
2022-07-17 00:48:24 - train done. model: darknettiny, train time: 48.395 hours, best_acc1: 57.602%
