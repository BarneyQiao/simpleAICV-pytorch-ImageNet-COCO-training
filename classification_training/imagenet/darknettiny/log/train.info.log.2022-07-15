2022-07-15 00:04:59 - network: darknettiny
2022-07-15 00:04:59 - num_classes: 1000
2022-07-15 00:04:59 - input_image_size: 256
2022-07-15 00:04:59 - scale: 1.1428571428571428
2022-07-15 00:04:59 - trained_model_path: 
2022-07-15 00:04:59 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-07-15 00:04:59 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-07-15 00:04:59 - train_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7f15cf196700>
2022-07-15 00:04:59 - test_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7f15cf1969d0>
2022-07-15 00:04:59 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f15cf196a00>
2022-07-15 00:04:59 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f15cf196a60>
2022-07-15 00:04:59 - seed: 0
2022-07-15 00:04:59 - batch_size: 256
2022-07-15 00:04:59 - num_workers: 16
2022-07-15 00:04:59 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0001, 'no_weight_decay_layer_name_list': []})
2022-07-15 00:04:59 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [30, 60, 90]})
2022-07-15 00:04:59 - epochs: 100
2022-07-15 00:04:59 - print_interval: 100
2022-07-15 00:04:59 - accumulation_steps: 1
2022-07-15 00:04:59 - sync_bn: False
2022-07-15 00:04:59 - apex: True
2022-07-15 00:04:59 - use_ema_model: False
2022-07-15 00:04:59 - ema_model_decay: 0.9999
2022-07-15 00:04:59 - gpus_type: NVIDIA RTX A5000
2022-07-15 00:04:59 - gpus_num: 2
2022-07-15 00:04:59 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f15b9fc12f0>
2022-07-15 00:04:59 - --------------------parameters--------------------
2022-07-15 00:04:59 - name: conv1.layer.0.weight, grad: True
2022-07-15 00:04:59 - name: conv1.layer.1.weight, grad: True
2022-07-15 00:04:59 - name: conv1.layer.1.bias, grad: True
2022-07-15 00:04:59 - name: conv2.layer.0.weight, grad: True
2022-07-15 00:04:59 - name: conv2.layer.1.weight, grad: True
2022-07-15 00:04:59 - name: conv2.layer.1.bias, grad: True
2022-07-15 00:04:59 - name: conv3.layer.0.weight, grad: True
2022-07-15 00:04:59 - name: conv3.layer.1.weight, grad: True
2022-07-15 00:04:59 - name: conv3.layer.1.bias, grad: True
2022-07-15 00:04:59 - name: conv4.layer.0.weight, grad: True
2022-07-15 00:04:59 - name: conv4.layer.1.weight, grad: True
2022-07-15 00:04:59 - name: conv4.layer.1.bias, grad: True
2022-07-15 00:04:59 - name: conv5.layer.0.weight, grad: True
2022-07-15 00:04:59 - name: conv5.layer.1.weight, grad: True
2022-07-15 00:04:59 - name: conv5.layer.1.bias, grad: True
2022-07-15 00:04:59 - name: conv6.layer.0.weight, grad: True
2022-07-15 00:04:59 - name: conv6.layer.1.weight, grad: True
2022-07-15 00:04:59 - name: conv6.layer.1.bias, grad: True
2022-07-15 00:04:59 - name: fc.weight, grad: True
2022-07-15 00:04:59 - name: fc.bias, grad: True
2022-07-15 00:04:59 - --------------------buffers--------------------
2022-07-15 00:04:59 - name: conv1.layer.1.running_mean, grad: False
2022-07-15 00:04:59 - name: conv1.layer.1.running_var, grad: False
2022-07-15 00:04:59 - name: conv1.layer.1.num_batches_tracked, grad: False
2022-07-15 00:04:59 - name: conv2.layer.1.running_mean, grad: False
2022-07-15 00:04:59 - name: conv2.layer.1.running_var, grad: False
2022-07-15 00:04:59 - name: conv2.layer.1.num_batches_tracked, grad: False
2022-07-15 00:04:59 - name: conv3.layer.1.running_mean, grad: False
2022-07-15 00:04:59 - name: conv3.layer.1.running_var, grad: False
2022-07-15 00:04:59 - name: conv3.layer.1.num_batches_tracked, grad: False
2022-07-15 00:04:59 - name: conv4.layer.1.running_mean, grad: False
2022-07-15 00:04:59 - name: conv4.layer.1.running_var, grad: False
2022-07-15 00:04:59 - name: conv4.layer.1.num_batches_tracked, grad: False
2022-07-15 00:04:59 - name: conv5.layer.1.running_mean, grad: False
2022-07-15 00:04:59 - name: conv5.layer.1.running_var, grad: False
2022-07-15 00:04:59 - name: conv5.layer.1.num_batches_tracked, grad: False
2022-07-15 00:04:59 - name: conv6.layer.1.running_mean, grad: False
2022-07-15 00:04:59 - name: conv6.layer.1.running_var, grad: False
2022-07-15 00:04:59 - name: conv6.layer.1.num_batches_tracked, grad: False
2022-07-15 00:04:59 - -----------no weight decay layers--------------
2022-07-15 00:04:59 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv4.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv4.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv5.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv5.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv6.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv6.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-15 00:04:59 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-15 00:04:59 - -------------weight decay layers---------------
2022-07-15 00:04:59 - name: conv1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv4.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv5.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-15 00:04:59 - name: conv6.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-15 00:04:59 - name: fc.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-15 00:04:59 - epoch 001 lr: 0.100000
2022-07-15 00:05:37 - train: epoch 0001, iter [00100, 05004], lr: 0.100000, loss: 6.7184
2022-07-15 00:06:10 - train: epoch 0001, iter [00200, 05004], lr: 0.100000, loss: 6.4649
2022-07-15 00:06:43 - train: epoch 0001, iter [00300, 05004], lr: 0.100000, loss: 6.3328
2022-07-15 00:07:16 - train: epoch 0001, iter [00400, 05004], lr: 0.100000, loss: 6.1369
2022-07-15 00:07:48 - train: epoch 0001, iter [00500, 05004], lr: 0.100000, loss: 5.9481
2022-07-15 00:08:21 - train: epoch 0001, iter [00600, 05004], lr: 0.100000, loss: 5.7196
2022-07-15 00:08:55 - train: epoch 0001, iter [00700, 05004], lr: 0.100000, loss: 5.7622
2022-07-15 00:09:27 - train: epoch 0001, iter [00800, 05004], lr: 0.100000, loss: 5.6835
2022-07-15 00:10:01 - train: epoch 0001, iter [00900, 05004], lr: 0.100000, loss: 5.7240
2022-07-15 00:10:34 - train: epoch 0001, iter [01000, 05004], lr: 0.100000, loss: 5.5225
2022-07-15 00:11:07 - train: epoch 0001, iter [01100, 05004], lr: 0.100000, loss: 5.5444
2022-07-15 00:11:40 - train: epoch 0001, iter [01200, 05004], lr: 0.100000, loss: 5.3793
2022-07-15 00:12:13 - train: epoch 0001, iter [01300, 05004], lr: 0.100000, loss: 5.2700
2022-07-15 00:12:47 - train: epoch 0001, iter [01400, 05004], lr: 0.100000, loss: 5.2615
2022-07-15 00:13:19 - train: epoch 0001, iter [01500, 05004], lr: 0.100000, loss: 5.1117
2022-07-15 00:13:53 - train: epoch 0001, iter [01600, 05004], lr: 0.100000, loss: 5.2169
2022-07-15 00:14:27 - train: epoch 0001, iter [01700, 05004], lr: 0.100000, loss: 4.9330
2022-07-15 00:14:59 - train: epoch 0001, iter [01800, 05004], lr: 0.100000, loss: 5.0718
2022-07-15 00:15:34 - train: epoch 0001, iter [01900, 05004], lr: 0.100000, loss: 4.8791
2022-07-15 00:16:06 - train: epoch 0001, iter [02000, 05004], lr: 0.100000, loss: 4.8994
2022-07-15 00:16:41 - train: epoch 0001, iter [02100, 05004], lr: 0.100000, loss: 4.8262
2022-07-15 00:17:12 - train: epoch 0001, iter [02200, 05004], lr: 0.100000, loss: 4.8307
2022-07-15 00:17:47 - train: epoch 0001, iter [02300, 05004], lr: 0.100000, loss: 4.7184
2022-07-15 00:18:19 - train: epoch 0001, iter [02400, 05004], lr: 0.100000, loss: 4.7206
2022-07-15 00:18:53 - train: epoch 0001, iter [02500, 05004], lr: 0.100000, loss: 4.8416
2022-07-15 00:19:25 - train: epoch 0001, iter [02600, 05004], lr: 0.100000, loss: 4.8917
2022-07-15 00:20:00 - train: epoch 0001, iter [02700, 05004], lr: 0.100000, loss: 4.7881
2022-07-15 00:20:33 - train: epoch 0001, iter [02800, 05004], lr: 0.100000, loss: 4.5141
2022-07-15 00:21:06 - train: epoch 0001, iter [02900, 05004], lr: 0.100000, loss: 4.5097
2022-07-15 00:21:39 - train: epoch 0001, iter [03000, 05004], lr: 0.100000, loss: 4.6363
2022-07-15 00:22:14 - train: epoch 0001, iter [03100, 05004], lr: 0.100000, loss: 4.7042
2022-07-15 00:22:46 - train: epoch 0001, iter [03200, 05004], lr: 0.100000, loss: 4.5682
2022-07-15 00:23:20 - train: epoch 0001, iter [03300, 05004], lr: 0.100000, loss: 4.3954
2022-07-15 00:23:52 - train: epoch 0001, iter [03400, 05004], lr: 0.100000, loss: 4.4500
2022-07-15 00:24:26 - train: epoch 0001, iter [03500, 05004], lr: 0.100000, loss: 4.4910
2022-07-15 00:24:59 - train: epoch 0001, iter [03600, 05004], lr: 0.100000, loss: 4.3252
2022-07-15 00:25:33 - train: epoch 0001, iter [03700, 05004], lr: 0.100000, loss: 4.5635
2022-07-15 00:26:06 - train: epoch 0001, iter [03800, 05004], lr: 0.100000, loss: 4.1809
2022-07-15 00:26:40 - train: epoch 0001, iter [03900, 05004], lr: 0.100000, loss: 4.3493
2022-07-15 00:27:13 - train: epoch 0001, iter [04000, 05004], lr: 0.100000, loss: 4.3807
2022-07-15 00:27:47 - train: epoch 0001, iter [04100, 05004], lr: 0.100000, loss: 4.5404
2022-07-15 00:28:19 - train: epoch 0001, iter [04200, 05004], lr: 0.100000, loss: 4.2199
2022-07-15 00:28:52 - train: epoch 0001, iter [04300, 05004], lr: 0.100000, loss: 4.1794
2022-07-15 00:29:25 - train: epoch 0001, iter [04400, 05004], lr: 0.100000, loss: 4.0637
2022-07-15 00:30:00 - train: epoch 0001, iter [04500, 05004], lr: 0.100000, loss: 4.3996
2022-07-15 00:30:33 - train: epoch 0001, iter [04600, 05004], lr: 0.100000, loss: 4.4782
2022-07-15 00:31:07 - train: epoch 0001, iter [04700, 05004], lr: 0.100000, loss: 4.2410
2022-07-15 00:31:40 - train: epoch 0001, iter [04800, 05004], lr: 0.100000, loss: 4.4264
2022-07-15 00:32:13 - train: epoch 0001, iter [04900, 05004], lr: 0.100000, loss: 4.1582
2022-07-15 00:32:45 - train: epoch 0001, iter [05000, 05004], lr: 0.100000, loss: 4.0006
2022-07-15 00:32:46 - train: epoch 001, train_loss: 4.9045
2022-07-15 00:34:00 - eval: epoch: 001, acc1: 20.518%, acc5: 41.666%, test_loss: 4.1001, per_image_load_time: 2.756ms, per_image_inference_time: 0.129ms
2022-07-15 00:34:00 - until epoch: 001, best_acc1: 20.518%
2022-07-15 00:34:00 - epoch 002 lr: 0.100000
2022-07-15 00:34:40 - train: epoch 0002, iter [00100, 05004], lr: 0.100000, loss: 4.2649
2022-07-15 00:35:11 - train: epoch 0002, iter [00200, 05004], lr: 0.100000, loss: 3.9492
2022-07-15 00:35:44 - train: epoch 0002, iter [00300, 05004], lr: 0.100000, loss: 4.2535
2022-07-15 00:36:15 - train: epoch 0002, iter [00400, 05004], lr: 0.100000, loss: 4.2149
2022-07-15 00:36:48 - train: epoch 0002, iter [00500, 05004], lr: 0.100000, loss: 3.8808
2022-07-15 00:37:21 - train: epoch 0002, iter [00600, 05004], lr: 0.100000, loss: 3.9364
2022-07-15 00:37:53 - train: epoch 0002, iter [00700, 05004], lr: 0.100000, loss: 4.2040
2022-07-15 00:38:28 - train: epoch 0002, iter [00800, 05004], lr: 0.100000, loss: 3.8822
2022-07-15 00:39:00 - train: epoch 0002, iter [00900, 05004], lr: 0.100000, loss: 3.6623
2022-07-15 00:39:34 - train: epoch 0002, iter [01000, 05004], lr: 0.100000, loss: 4.1666
2022-07-15 00:40:06 - train: epoch 0002, iter [01100, 05004], lr: 0.100000, loss: 4.1350
2022-07-15 00:40:39 - train: epoch 0002, iter [01200, 05004], lr: 0.100000, loss: 3.9521
2022-07-15 00:41:12 - train: epoch 0002, iter [01300, 05004], lr: 0.100000, loss: 3.9338
2022-07-15 00:41:46 - train: epoch 0002, iter [01400, 05004], lr: 0.100000, loss: 4.1372
2022-07-15 00:42:19 - train: epoch 0002, iter [01500, 05004], lr: 0.100000, loss: 4.1520
2022-07-15 00:42:54 - train: epoch 0002, iter [01600, 05004], lr: 0.100000, loss: 3.8364
2022-07-15 00:43:25 - train: epoch 0002, iter [01700, 05004], lr: 0.100000, loss: 3.9960
2022-07-15 00:43:59 - train: epoch 0002, iter [01800, 05004], lr: 0.100000, loss: 3.9523
2022-07-15 00:44:32 - train: epoch 0002, iter [01900, 05004], lr: 0.100000, loss: 3.8292
2022-07-15 00:45:06 - train: epoch 0002, iter [02000, 05004], lr: 0.100000, loss: 3.6613
2022-07-15 00:45:38 - train: epoch 0002, iter [02100, 05004], lr: 0.100000, loss: 3.8327
2022-07-15 00:46:12 - train: epoch 0002, iter [02200, 05004], lr: 0.100000, loss: 3.6568
2022-07-15 00:46:45 - train: epoch 0002, iter [02300, 05004], lr: 0.100000, loss: 3.8442
2022-07-15 00:47:18 - train: epoch 0002, iter [02400, 05004], lr: 0.100000, loss: 3.7582
2022-07-15 00:47:51 - train: epoch 0002, iter [02500, 05004], lr: 0.100000, loss: 3.6909
2022-07-15 00:48:24 - train: epoch 0002, iter [02600, 05004], lr: 0.100000, loss: 3.8105
2022-07-15 00:48:58 - train: epoch 0002, iter [02700, 05004], lr: 0.100000, loss: 3.9766
2022-07-15 00:49:31 - train: epoch 0002, iter [02800, 05004], lr: 0.100000, loss: 3.8028
2022-07-15 00:50:04 - train: epoch 0002, iter [02900, 05004], lr: 0.100000, loss: 3.7974
2022-07-15 00:50:36 - train: epoch 0002, iter [03000, 05004], lr: 0.100000, loss: 3.7254
2022-07-15 00:51:10 - train: epoch 0002, iter [03100, 05004], lr: 0.100000, loss: 3.7502
2022-07-15 00:51:43 - train: epoch 0002, iter [03200, 05004], lr: 0.100000, loss: 3.7802
2022-07-15 00:52:17 - train: epoch 0002, iter [03300, 05004], lr: 0.100000, loss: 3.7775
2022-07-15 00:52:49 - train: epoch 0002, iter [03400, 05004], lr: 0.100000, loss: 3.9430
2022-07-15 00:53:23 - train: epoch 0002, iter [03500, 05004], lr: 0.100000, loss: 3.6784
2022-07-15 00:53:56 - train: epoch 0002, iter [03600, 05004], lr: 0.100000, loss: 3.7604
2022-07-15 00:54:29 - train: epoch 0002, iter [03700, 05004], lr: 0.100000, loss: 3.7998
2022-07-15 00:55:03 - train: epoch 0002, iter [03800, 05004], lr: 0.100000, loss: 3.5552
2022-07-15 00:55:36 - train: epoch 0002, iter [03900, 05004], lr: 0.100000, loss: 3.8350
2022-07-15 00:56:11 - train: epoch 0002, iter [04000, 05004], lr: 0.100000, loss: 3.5962
2022-07-15 00:56:43 - train: epoch 0002, iter [04100, 05004], lr: 0.100000, loss: 3.7161
2022-07-15 00:57:17 - train: epoch 0002, iter [04200, 05004], lr: 0.100000, loss: 3.5943
2022-07-15 00:57:49 - train: epoch 0002, iter [04300, 05004], lr: 0.100000, loss: 3.6451
2022-07-15 00:58:24 - train: epoch 0002, iter [04400, 05004], lr: 0.100000, loss: 3.6794
2022-07-15 00:58:57 - train: epoch 0002, iter [04500, 05004], lr: 0.100000, loss: 3.4841
2022-07-15 00:59:31 - train: epoch 0002, iter [04600, 05004], lr: 0.100000, loss: 3.7094
2022-07-15 01:00:03 - train: epoch 0002, iter [04700, 05004], lr: 0.100000, loss: 3.6551
2022-07-15 01:00:37 - train: epoch 0002, iter [04800, 05004], lr: 0.100000, loss: 3.6312
2022-07-15 01:01:09 - train: epoch 0002, iter [04900, 05004], lr: 0.100000, loss: 3.5441
2022-07-15 01:01:42 - train: epoch 0002, iter [05000, 05004], lr: 0.100000, loss: 3.5603
2022-07-15 01:01:42 - train: epoch 002, train_loss: 3.8444
2022-07-15 01:02:56 - eval: epoch: 002, acc1: 28.874%, acc5: 53.372%, test_loss: 3.4659, per_image_load_time: 1.427ms, per_image_inference_time: 0.139ms
2022-07-15 01:02:56 - until epoch: 002, best_acc1: 28.874%
2022-07-15 01:02:56 - epoch 003 lr: 0.100000
2022-07-15 01:03:34 - train: epoch 0003, iter [00100, 05004], lr: 0.100000, loss: 3.6609
2022-07-15 01:04:07 - train: epoch 0003, iter [00200, 05004], lr: 0.100000, loss: 3.7318
2022-07-15 01:04:40 - train: epoch 0003, iter [00300, 05004], lr: 0.100000, loss: 3.5334
2022-07-15 01:05:12 - train: epoch 0003, iter [00400, 05004], lr: 0.100000, loss: 3.5724
2022-07-15 01:05:46 - train: epoch 0003, iter [00500, 05004], lr: 0.100000, loss: 3.6934
2022-07-15 01:06:19 - train: epoch 0003, iter [00600, 05004], lr: 0.100000, loss: 3.5469
2022-07-15 01:06:51 - train: epoch 0003, iter [00700, 05004], lr: 0.100000, loss: 3.7221
2022-07-15 01:07:24 - train: epoch 0003, iter [00800, 05004], lr: 0.100000, loss: 3.7049
2022-07-15 01:07:56 - train: epoch 0003, iter [00900, 05004], lr: 0.100000, loss: 3.5081
2022-07-15 01:08:30 - train: epoch 0003, iter [01000, 05004], lr: 0.100000, loss: 3.6708
2022-07-15 01:09:04 - train: epoch 0003, iter [01100, 05004], lr: 0.100000, loss: 3.4417
2022-07-15 01:09:37 - train: epoch 0003, iter [01200, 05004], lr: 0.100000, loss: 3.4374
2022-07-15 01:10:09 - train: epoch 0003, iter [01300, 05004], lr: 0.100000, loss: 3.5543
2022-07-15 01:10:43 - train: epoch 0003, iter [01400, 05004], lr: 0.100000, loss: 3.3956
2022-07-15 01:11:16 - train: epoch 0003, iter [01500, 05004], lr: 0.100000, loss: 3.7735
2022-07-15 01:11:49 - train: epoch 0003, iter [01600, 05004], lr: 0.100000, loss: 3.4703
2022-07-15 01:12:23 - train: epoch 0003, iter [01700, 05004], lr: 0.100000, loss: 3.4706
2022-07-15 01:12:55 - train: epoch 0003, iter [01800, 05004], lr: 0.100000, loss: 3.5258
2022-07-15 01:13:29 - train: epoch 0003, iter [01900, 05004], lr: 0.100000, loss: 3.5006
2022-07-15 01:14:01 - train: epoch 0003, iter [02000, 05004], lr: 0.100000, loss: 3.8411
2022-07-15 01:14:35 - train: epoch 0003, iter [02100, 05004], lr: 0.100000, loss: 3.7655
2022-07-15 01:15:08 - train: epoch 0003, iter [02200, 05004], lr: 0.100000, loss: 3.7797
2022-07-15 01:15:42 - train: epoch 0003, iter [02300, 05004], lr: 0.100000, loss: 3.4946
2022-07-15 01:16:14 - train: epoch 0003, iter [02400, 05004], lr: 0.100000, loss: 3.4942
2022-07-15 01:16:48 - train: epoch 0003, iter [02500, 05004], lr: 0.100000, loss: 3.6274
2022-07-15 01:17:21 - train: epoch 0003, iter [02600, 05004], lr: 0.100000, loss: 3.5879
2022-07-15 01:17:55 - train: epoch 0003, iter [02700, 05004], lr: 0.100000, loss: 3.8294
2022-07-15 01:18:27 - train: epoch 0003, iter [02800, 05004], lr: 0.100000, loss: 3.3729
2022-07-15 01:19:00 - train: epoch 0003, iter [02900, 05004], lr: 0.100000, loss: 3.3571
2022-07-15 01:19:34 - train: epoch 0003, iter [03000, 05004], lr: 0.100000, loss: 3.6590
2022-07-15 01:20:08 - train: epoch 0003, iter [03100, 05004], lr: 0.100000, loss: 3.6914
2022-07-15 01:20:40 - train: epoch 0003, iter [03200, 05004], lr: 0.100000, loss: 3.4855
2022-07-15 01:21:14 - train: epoch 0003, iter [03300, 05004], lr: 0.100000, loss: 3.4528
2022-07-15 01:21:46 - train: epoch 0003, iter [03400, 05004], lr: 0.100000, loss: 3.5782
2022-07-15 01:22:20 - train: epoch 0003, iter [03500, 05004], lr: 0.100000, loss: 3.2095
2022-07-15 01:22:53 - train: epoch 0003, iter [03600, 05004], lr: 0.100000, loss: 3.4376
2022-07-15 01:23:27 - train: epoch 0003, iter [03700, 05004], lr: 0.100000, loss: 3.5624
2022-07-15 01:24:00 - train: epoch 0003, iter [03800, 05004], lr: 0.100000, loss: 3.6131
2022-07-15 01:24:33 - train: epoch 0003, iter [03900, 05004], lr: 0.100000, loss: 3.7982
2022-07-15 01:25:06 - train: epoch 0003, iter [04000, 05004], lr: 0.100000, loss: 3.4263
2022-07-15 01:25:40 - train: epoch 0003, iter [04100, 05004], lr: 0.100000, loss: 3.4331
2022-07-15 01:26:12 - train: epoch 0003, iter [04200, 05004], lr: 0.100000, loss: 3.4136
2022-07-15 01:26:46 - train: epoch 0003, iter [04300, 05004], lr: 0.100000, loss: 3.1926
2022-07-15 01:27:20 - train: epoch 0003, iter [04400, 05004], lr: 0.100000, loss: 3.3162
2022-07-15 01:27:53 - train: epoch 0003, iter [04500, 05004], lr: 0.100000, loss: 3.4640
2022-07-15 01:28:26 - train: epoch 0003, iter [04600, 05004], lr: 0.100000, loss: 3.4217
2022-07-15 01:28:59 - train: epoch 0003, iter [04700, 05004], lr: 0.100000, loss: 3.3104
2022-07-15 01:29:33 - train: epoch 0003, iter [04800, 05004], lr: 0.100000, loss: 3.5866
2022-07-15 01:30:06 - train: epoch 0003, iter [04900, 05004], lr: 0.100000, loss: 3.5301
2022-07-15 01:30:37 - train: epoch 0003, iter [05000, 05004], lr: 0.100000, loss: 3.5111
2022-07-15 01:30:38 - train: epoch 003, train_loss: 3.5364
2022-07-15 01:31:53 - eval: epoch: 003, acc1: 34.484%, acc5: 59.120%, test_loss: 3.1514, per_image_load_time: 2.799ms, per_image_inference_time: 0.133ms
2022-07-15 01:31:53 - until epoch: 003, best_acc1: 34.484%
2022-07-15 01:31:53 - epoch 004 lr: 0.100000
2022-07-15 01:32:32 - train: epoch 0004, iter [00100, 05004], lr: 0.100000, loss: 3.4932
2022-07-15 01:33:04 - train: epoch 0004, iter [00200, 05004], lr: 0.100000, loss: 3.4019
2022-07-15 01:33:38 - train: epoch 0004, iter [00300, 05004], lr: 0.100000, loss: 3.4852
2022-07-15 01:34:10 - train: epoch 0004, iter [00400, 05004], lr: 0.100000, loss: 3.3317
2022-07-15 01:34:44 - train: epoch 0004, iter [00500, 05004], lr: 0.100000, loss: 3.2520
2022-07-15 01:35:16 - train: epoch 0004, iter [00600, 05004], lr: 0.100000, loss: 3.6319
2022-07-15 01:35:50 - train: epoch 0004, iter [00700, 05004], lr: 0.100000, loss: 3.4350
2022-07-15 01:36:22 - train: epoch 0004, iter [00800, 05004], lr: 0.100000, loss: 3.3160
2022-07-15 01:36:55 - train: epoch 0004, iter [00900, 05004], lr: 0.100000, loss: 3.1037
2022-07-15 01:37:29 - train: epoch 0004, iter [01000, 05004], lr: 0.100000, loss: 3.5004
2022-07-15 01:38:02 - train: epoch 0004, iter [01100, 05004], lr: 0.100000, loss: 3.5076
2022-07-15 01:38:35 - train: epoch 0004, iter [01200, 05004], lr: 0.100000, loss: 3.2351
2022-07-15 01:39:09 - train: epoch 0004, iter [01300, 05004], lr: 0.100000, loss: 3.2520
2022-07-15 01:39:42 - train: epoch 0004, iter [01400, 05004], lr: 0.100000, loss: 3.4834
2022-07-15 01:40:15 - train: epoch 0004, iter [01500, 05004], lr: 0.100000, loss: 3.4727
2022-07-15 01:40:48 - train: epoch 0004, iter [01600, 05004], lr: 0.100000, loss: 3.2235
2022-07-15 01:41:22 - train: epoch 0004, iter [01700, 05004], lr: 0.100000, loss: 3.5384
2022-07-15 01:41:55 - train: epoch 0004, iter [01800, 05004], lr: 0.100000, loss: 3.6620
2022-07-15 01:42:29 - train: epoch 0004, iter [01900, 05004], lr: 0.100000, loss: 3.5328
2022-07-15 01:43:03 - train: epoch 0004, iter [02000, 05004], lr: 0.100000, loss: 3.4682
2022-07-15 01:43:35 - train: epoch 0004, iter [02100, 05004], lr: 0.100000, loss: 3.4891
2022-07-15 01:44:09 - train: epoch 0004, iter [02200, 05004], lr: 0.100000, loss: 3.2885
2022-07-15 01:44:42 - train: epoch 0004, iter [02300, 05004], lr: 0.100000, loss: 3.2333
2022-07-15 01:45:15 - train: epoch 0004, iter [02400, 05004], lr: 0.100000, loss: 3.1575
2022-07-15 01:45:48 - train: epoch 0004, iter [02500, 05004], lr: 0.100000, loss: 3.3317
2022-07-15 01:46:21 - train: epoch 0004, iter [02600, 05004], lr: 0.100000, loss: 3.4635
2022-07-15 01:46:55 - train: epoch 0004, iter [02700, 05004], lr: 0.100000, loss: 3.2960
2022-07-15 01:47:29 - train: epoch 0004, iter [02800, 05004], lr: 0.100000, loss: 3.4461
2022-07-15 01:48:01 - train: epoch 0004, iter [02900, 05004], lr: 0.100000, loss: 3.3730
2022-07-15 01:48:35 - train: epoch 0004, iter [03000, 05004], lr: 0.100000, loss: 3.3849
2022-07-15 01:49:07 - train: epoch 0004, iter [03100, 05004], lr: 0.100000, loss: 3.4534
2022-07-15 01:49:41 - train: epoch 0004, iter [03200, 05004], lr: 0.100000, loss: 3.3519
2022-07-15 01:50:13 - train: epoch 0004, iter [03300, 05004], lr: 0.100000, loss: 3.5026
2022-07-15 01:50:47 - train: epoch 0004, iter [03400, 05004], lr: 0.100000, loss: 3.3447
2022-07-15 01:51:20 - train: epoch 0004, iter [03500, 05004], lr: 0.100000, loss: 3.2485
2022-07-15 01:51:54 - train: epoch 0004, iter [03600, 05004], lr: 0.100000, loss: 3.1305
2022-07-15 01:52:28 - train: epoch 0004, iter [03700, 05004], lr: 0.100000, loss: 3.4138
2022-07-15 01:53:02 - train: epoch 0004, iter [03800, 05004], lr: 0.100000, loss: 3.1987
2022-07-15 01:53:34 - train: epoch 0004, iter [03900, 05004], lr: 0.100000, loss: 3.1808
2022-07-15 01:54:08 - train: epoch 0004, iter [04000, 05004], lr: 0.100000, loss: 3.1085
2022-07-15 01:54:41 - train: epoch 0004, iter [04100, 05004], lr: 0.100000, loss: 3.4680
2022-07-15 01:55:14 - train: epoch 0004, iter [04200, 05004], lr: 0.100000, loss: 3.3193
2022-07-15 01:55:48 - train: epoch 0004, iter [04300, 05004], lr: 0.100000, loss: 3.1391
2022-07-15 01:56:21 - train: epoch 0004, iter [04400, 05004], lr: 0.100000, loss: 3.1201
2022-07-15 01:56:55 - train: epoch 0004, iter [04500, 05004], lr: 0.100000, loss: 2.8928
2022-07-15 01:57:27 - train: epoch 0004, iter [04600, 05004], lr: 0.100000, loss: 3.3235
2022-07-15 01:58:00 - train: epoch 0004, iter [04700, 05004], lr: 0.100000, loss: 3.2225
2022-07-15 01:58:34 - train: epoch 0004, iter [04800, 05004], lr: 0.100000, loss: 3.1952
2022-07-15 01:59:08 - train: epoch 0004, iter [04900, 05004], lr: 0.100000, loss: 3.3048
2022-07-15 01:59:39 - train: epoch 0004, iter [05000, 05004], lr: 0.100000, loss: 3.3887
2022-07-15 01:59:40 - train: epoch 004, train_loss: 3.3834
2022-07-15 02:00:54 - eval: epoch: 004, acc1: 33.482%, acc5: 58.242%, test_loss: 3.2300, per_image_load_time: 2.700ms, per_image_inference_time: 0.122ms
2022-07-15 02:00:54 - until epoch: 004, best_acc1: 34.484%
2022-07-15 02:00:54 - epoch 005 lr: 0.100000
2022-07-15 02:01:32 - train: epoch 0005, iter [00100, 05004], lr: 0.100000, loss: 3.4822
2022-07-15 02:02:06 - train: epoch 0005, iter [00200, 05004], lr: 0.100000, loss: 3.3271
2022-07-15 02:02:39 - train: epoch 0005, iter [00300, 05004], lr: 0.100000, loss: 3.4403
2022-07-15 02:03:11 - train: epoch 0005, iter [00400, 05004], lr: 0.100000, loss: 3.3264
2022-07-15 02:03:45 - train: epoch 0005, iter [00500, 05004], lr: 0.100000, loss: 3.1034
2022-07-15 02:04:18 - train: epoch 0005, iter [00600, 05004], lr: 0.100000, loss: 3.2125
2022-07-15 02:04:51 - train: epoch 0005, iter [00700, 05004], lr: 0.100000, loss: 3.4059
2022-07-15 02:05:25 - train: epoch 0005, iter [00800, 05004], lr: 0.100000, loss: 3.4150
2022-07-15 02:05:57 - train: epoch 0005, iter [00900, 05004], lr: 0.100000, loss: 3.2316
2022-07-15 02:06:30 - train: epoch 0005, iter [01000, 05004], lr: 0.100000, loss: 3.3371
2022-07-15 02:07:04 - train: epoch 0005, iter [01100, 05004], lr: 0.100000, loss: 3.4413
2022-07-15 02:07:37 - train: epoch 0005, iter [01200, 05004], lr: 0.100000, loss: 3.3111
2022-07-15 02:08:10 - train: epoch 0005, iter [01300, 05004], lr: 0.100000, loss: 3.1513
2022-07-15 02:08:43 - train: epoch 0005, iter [01400, 05004], lr: 0.100000, loss: 3.3571
2022-07-15 02:09:16 - train: epoch 0005, iter [01500, 05004], lr: 0.100000, loss: 3.1611
2022-07-15 02:09:50 - train: epoch 0005, iter [01600, 05004], lr: 0.100000, loss: 3.0205
2022-07-15 02:10:23 - train: epoch 0005, iter [01700, 05004], lr: 0.100000, loss: 3.1553
2022-07-15 02:10:56 - train: epoch 0005, iter [01800, 05004], lr: 0.100000, loss: 3.4177
2022-07-15 02:11:29 - train: epoch 0005, iter [01900, 05004], lr: 0.100000, loss: 3.1025
2022-07-15 02:12:03 - train: epoch 0005, iter [02000, 05004], lr: 0.100000, loss: 3.2180
2022-07-15 02:12:37 - train: epoch 0005, iter [02100, 05004], lr: 0.100000, loss: 2.9550
2022-07-15 02:13:10 - train: epoch 0005, iter [02200, 05004], lr: 0.100000, loss: 3.1594
2022-07-15 02:13:43 - train: epoch 0005, iter [02300, 05004], lr: 0.100000, loss: 3.0427
2022-07-15 02:14:17 - train: epoch 0005, iter [02400, 05004], lr: 0.100000, loss: 3.3174
2022-07-15 02:14:50 - train: epoch 0005, iter [02500, 05004], lr: 0.100000, loss: 3.2724
2022-07-15 02:15:24 - train: epoch 0005, iter [02600, 05004], lr: 0.100000, loss: 3.3949
2022-07-15 02:15:56 - train: epoch 0005, iter [02700, 05004], lr: 0.100000, loss: 3.3948
2022-07-15 02:16:31 - train: epoch 0005, iter [02800, 05004], lr: 0.100000, loss: 3.3074
2022-07-15 02:17:04 - train: epoch 0005, iter [02900, 05004], lr: 0.100000, loss: 3.0323
2022-07-15 02:17:37 - train: epoch 0005, iter [03000, 05004], lr: 0.100000, loss: 3.1673
2022-07-15 02:18:10 - train: epoch 0005, iter [03100, 05004], lr: 0.100000, loss: 3.3939
2022-07-15 02:18:44 - train: epoch 0005, iter [03200, 05004], lr: 0.100000, loss: 3.3575
2022-07-15 02:19:17 - train: epoch 0005, iter [03300, 05004], lr: 0.100000, loss: 3.1545
2022-07-15 02:19:51 - train: epoch 0005, iter [03400, 05004], lr: 0.100000, loss: 3.2328
2022-07-15 02:20:24 - train: epoch 0005, iter [03500, 05004], lr: 0.100000, loss: 3.2376
2022-07-15 02:20:57 - train: epoch 0005, iter [03600, 05004], lr: 0.100000, loss: 3.3065
2022-07-15 02:21:30 - train: epoch 0005, iter [03700, 05004], lr: 0.100000, loss: 3.1682
2022-07-15 02:22:04 - train: epoch 0005, iter [03800, 05004], lr: 0.100000, loss: 3.1095
2022-07-15 02:22:37 - train: epoch 0005, iter [03900, 05004], lr: 0.100000, loss: 3.5617
2022-07-15 02:23:10 - train: epoch 0005, iter [04000, 05004], lr: 0.100000, loss: 3.2338
2022-07-15 02:23:43 - train: epoch 0005, iter [04100, 05004], lr: 0.100000, loss: 3.3102
2022-07-15 02:24:17 - train: epoch 0005, iter [04200, 05004], lr: 0.100000, loss: 3.2689
2022-07-15 02:24:51 - train: epoch 0005, iter [04300, 05004], lr: 0.100000, loss: 3.0913
2022-07-15 02:25:24 - train: epoch 0005, iter [04400, 05004], lr: 0.100000, loss: 3.3596
2022-07-15 02:25:58 - train: epoch 0005, iter [04500, 05004], lr: 0.100000, loss: 3.4224
2022-07-15 02:26:30 - train: epoch 0005, iter [04600, 05004], lr: 0.100000, loss: 3.2127
2022-07-15 02:27:05 - train: epoch 0005, iter [04700, 05004], lr: 0.100000, loss: 3.0361
2022-07-15 02:27:37 - train: epoch 0005, iter [04800, 05004], lr: 0.100000, loss: 2.9695
2022-07-15 02:28:11 - train: epoch 0005, iter [04900, 05004], lr: 0.100000, loss: 3.3795
2022-07-15 02:28:42 - train: epoch 0005, iter [05000, 05004], lr: 0.100000, loss: 3.3261
2022-07-15 02:28:43 - train: epoch 005, train_loss: 3.2906
2022-07-15 02:29:57 - eval: epoch: 005, acc1: 34.730%, acc5: 59.760%, test_loss: 3.1433, per_image_load_time: 2.186ms, per_image_inference_time: 0.130ms
2022-07-15 02:29:57 - until epoch: 005, best_acc1: 34.730%
2022-07-15 02:29:57 - epoch 006 lr: 0.100000
2022-07-15 02:30:35 - train: epoch 0006, iter [00100, 05004], lr: 0.100000, loss: 3.1040
2022-07-15 02:31:08 - train: epoch 0006, iter [00200, 05004], lr: 0.100000, loss: 3.2838
2022-07-15 02:31:41 - train: epoch 0006, iter [00300, 05004], lr: 0.100000, loss: 3.1998
2022-07-15 02:32:14 - train: epoch 0006, iter [00400, 05004], lr: 0.100000, loss: 3.3102
2022-07-15 02:32:46 - train: epoch 0006, iter [00500, 05004], lr: 0.100000, loss: 3.1666
2022-07-15 02:33:20 - train: epoch 0006, iter [00600, 05004], lr: 0.100000, loss: 3.1676
2022-07-15 02:33:51 - train: epoch 0006, iter [00700, 05004], lr: 0.100000, loss: 3.1869
2022-07-15 02:34:25 - train: epoch 0006, iter [00800, 05004], lr: 0.100000, loss: 3.2218
2022-07-15 02:34:58 - train: epoch 0006, iter [00900, 05004], lr: 0.100000, loss: 3.1262
2022-07-15 02:35:32 - train: epoch 0006, iter [01000, 05004], lr: 0.100000, loss: 3.1703
2022-07-15 02:36:03 - train: epoch 0006, iter [01100, 05004], lr: 0.100000, loss: 3.1490
2022-07-15 02:36:37 - train: epoch 0006, iter [01200, 05004], lr: 0.100000, loss: 3.3082
2022-07-15 02:37:09 - train: epoch 0006, iter [01300, 05004], lr: 0.100000, loss: 3.4531
2022-07-15 02:37:43 - train: epoch 0006, iter [01400, 05004], lr: 0.100000, loss: 3.3051
2022-07-15 02:38:15 - train: epoch 0006, iter [01500, 05004], lr: 0.100000, loss: 3.3769
2022-07-15 02:38:49 - train: epoch 0006, iter [01600, 05004], lr: 0.100000, loss: 3.0329
2022-07-15 02:39:22 - train: epoch 0006, iter [01700, 05004], lr: 0.100000, loss: 3.3035
2022-07-15 02:39:56 - train: epoch 0006, iter [01800, 05004], lr: 0.100000, loss: 3.3054
2022-07-15 02:40:29 - train: epoch 0006, iter [01900, 05004], lr: 0.100000, loss: 3.0361
2022-07-15 02:41:02 - train: epoch 0006, iter [02000, 05004], lr: 0.100000, loss: 3.3728
2022-07-15 02:41:35 - train: epoch 0006, iter [02100, 05004], lr: 0.100000, loss: 3.1984
2022-07-15 02:42:09 - train: epoch 0006, iter [02200, 05004], lr: 0.100000, loss: 3.0269
2022-07-15 02:42:41 - train: epoch 0006, iter [02300, 05004], lr: 0.100000, loss: 3.1421
2022-07-15 02:43:15 - train: epoch 0006, iter [02400, 05004], lr: 0.100000, loss: 3.2563
2022-07-15 02:43:48 - train: epoch 0006, iter [02500, 05004], lr: 0.100000, loss: 3.3563
2022-07-15 02:44:21 - train: epoch 0006, iter [02600, 05004], lr: 0.100000, loss: 3.1979
2022-07-15 02:44:55 - train: epoch 0006, iter [02700, 05004], lr: 0.100000, loss: 3.2887
2022-07-15 02:45:28 - train: epoch 0006, iter [02800, 05004], lr: 0.100000, loss: 3.0377
2022-07-15 02:46:01 - train: epoch 0006, iter [02900, 05004], lr: 0.100000, loss: 3.2366
2022-07-15 02:46:35 - train: epoch 0006, iter [03000, 05004], lr: 0.100000, loss: 3.0604
2022-07-15 02:47:07 - train: epoch 0006, iter [03100, 05004], lr: 0.100000, loss: 2.9654
2022-07-15 02:47:41 - train: epoch 0006, iter [03200, 05004], lr: 0.100000, loss: 3.1288
2022-07-15 02:48:13 - train: epoch 0006, iter [03300, 05004], lr: 0.100000, loss: 3.0225
2022-07-15 02:48:48 - train: epoch 0006, iter [03400, 05004], lr: 0.100000, loss: 3.3736
2022-07-15 02:49:21 - train: epoch 0006, iter [03500, 05004], lr: 0.100000, loss: 3.3028
2022-07-15 02:49:54 - train: epoch 0006, iter [03600, 05004], lr: 0.100000, loss: 3.4215
2022-07-15 02:50:28 - train: epoch 0006, iter [03700, 05004], lr: 0.100000, loss: 3.2472
2022-07-15 02:51:02 - train: epoch 0006, iter [03800, 05004], lr: 0.100000, loss: 3.0750
2022-07-15 02:51:34 - train: epoch 0006, iter [03900, 05004], lr: 0.100000, loss: 3.0129
2022-07-15 02:52:09 - train: epoch 0006, iter [04000, 05004], lr: 0.100000, loss: 3.5672
2022-07-15 02:52:41 - train: epoch 0006, iter [04100, 05004], lr: 0.100000, loss: 3.2327
2022-07-15 02:53:15 - train: epoch 0006, iter [04200, 05004], lr: 0.100000, loss: 3.1070
2022-07-15 02:53:48 - train: epoch 0006, iter [04300, 05004], lr: 0.100000, loss: 3.0149
2022-07-15 02:54:22 - train: epoch 0006, iter [04400, 05004], lr: 0.100000, loss: 3.2694
2022-07-15 02:54:56 - train: epoch 0006, iter [04500, 05004], lr: 0.100000, loss: 3.2523
2022-07-15 02:55:28 - train: epoch 0006, iter [04600, 05004], lr: 0.100000, loss: 3.2505
2022-07-15 02:56:02 - train: epoch 0006, iter [04700, 05004], lr: 0.100000, loss: 3.3265
2022-07-15 02:56:36 - train: epoch 0006, iter [04800, 05004], lr: 0.100000, loss: 3.3640
2022-07-15 02:57:08 - train: epoch 0006, iter [04900, 05004], lr: 0.100000, loss: 3.3210
2022-07-15 02:57:41 - train: epoch 0006, iter [05000, 05004], lr: 0.100000, loss: 3.0750
2022-07-15 02:57:42 - train: epoch 006, train_loss: 3.2318
2022-07-15 02:58:55 - eval: epoch: 006, acc1: 37.034%, acc5: 62.008%, test_loss: 3.0010, per_image_load_time: 2.246ms, per_image_inference_time: 0.137ms
2022-07-15 02:58:55 - until epoch: 006, best_acc1: 37.034%
2022-07-15 02:58:55 - epoch 007 lr: 0.100000
2022-07-15 02:59:34 - train: epoch 0007, iter [00100, 05004], lr: 0.100000, loss: 3.0437
2022-07-15 03:00:06 - train: epoch 0007, iter [00200, 05004], lr: 0.100000, loss: 3.4511
2022-07-15 03:00:39 - train: epoch 0007, iter [00300, 05004], lr: 0.100000, loss: 3.5285
2022-07-15 03:01:12 - train: epoch 0007, iter [00400, 05004], lr: 0.100000, loss: 3.1805
2022-07-15 03:01:45 - train: epoch 0007, iter [00500, 05004], lr: 0.100000, loss: 3.1187
2022-07-15 03:02:19 - train: epoch 0007, iter [00600, 05004], lr: 0.100000, loss: 3.3459
2022-07-15 03:02:52 - train: epoch 0007, iter [00700, 05004], lr: 0.100000, loss: 3.2125
2022-07-15 03:03:25 - train: epoch 0007, iter [00800, 05004], lr: 0.100000, loss: 3.2365
2022-07-15 03:03:58 - train: epoch 0007, iter [00900, 05004], lr: 0.100000, loss: 3.1860
2022-07-15 03:04:30 - train: epoch 0007, iter [01000, 05004], lr: 0.100000, loss: 3.1685
2022-07-15 03:05:03 - train: epoch 0007, iter [01100, 05004], lr: 0.100000, loss: 3.0824
2022-07-15 03:05:37 - train: epoch 0007, iter [01200, 05004], lr: 0.100000, loss: 3.1491
2022-07-15 03:06:10 - train: epoch 0007, iter [01300, 05004], lr: 0.100000, loss: 2.9806
2022-07-15 03:06:42 - train: epoch 0007, iter [01400, 05004], lr: 0.100000, loss: 3.3311
2022-07-15 03:07:16 - train: epoch 0007, iter [01500, 05004], lr: 0.100000, loss: 3.3074
2022-07-15 03:07:50 - train: epoch 0007, iter [01600, 05004], lr: 0.100000, loss: 3.2090
2022-07-15 03:08:22 - train: epoch 0007, iter [01700, 05004], lr: 0.100000, loss: 3.3761
2022-07-15 03:08:56 - train: epoch 0007, iter [01800, 05004], lr: 0.100000, loss: 3.0763
2022-07-15 03:09:29 - train: epoch 0007, iter [01900, 05004], lr: 0.100000, loss: 3.3038
2022-07-15 03:10:02 - train: epoch 0007, iter [02000, 05004], lr: 0.100000, loss: 2.9775
2022-07-15 03:10:36 - train: epoch 0007, iter [02100, 05004], lr: 0.100000, loss: 3.3933
2022-07-15 03:11:09 - train: epoch 0007, iter [02200, 05004], lr: 0.100000, loss: 2.9932
2022-07-15 03:11:43 - train: epoch 0007, iter [02300, 05004], lr: 0.100000, loss: 3.2365
2022-07-15 03:12:15 - train: epoch 0007, iter [02400, 05004], lr: 0.100000, loss: 3.2266
2022-07-15 03:12:49 - train: epoch 0007, iter [02500, 05004], lr: 0.100000, loss: 3.1388
2022-07-15 03:13:22 - train: epoch 0007, iter [02600, 05004], lr: 0.100000, loss: 2.9882
2022-07-15 03:13:56 - train: epoch 0007, iter [02700, 05004], lr: 0.100000, loss: 3.0207
2022-07-15 03:14:28 - train: epoch 0007, iter [02800, 05004], lr: 0.100000, loss: 3.0866
2022-07-15 03:15:02 - train: epoch 0007, iter [02900, 05004], lr: 0.100000, loss: 3.3397
2022-07-15 03:15:34 - train: epoch 0007, iter [03000, 05004], lr: 0.100000, loss: 3.3401
2022-07-15 03:16:08 - train: epoch 0007, iter [03100, 05004], lr: 0.100000, loss: 3.0982
2022-07-15 03:16:41 - train: epoch 0007, iter [03200, 05004], lr: 0.100000, loss: 3.1027
2022-07-15 03:17:16 - train: epoch 0007, iter [03300, 05004], lr: 0.100000, loss: 3.4663
2022-07-15 03:17:48 - train: epoch 0007, iter [03400, 05004], lr: 0.100000, loss: 3.0714
2022-07-15 03:18:22 - train: epoch 0007, iter [03500, 05004], lr: 0.100000, loss: 3.3207
2022-07-15 03:18:54 - train: epoch 0007, iter [03600, 05004], lr: 0.100000, loss: 3.0613
2022-07-15 03:19:28 - train: epoch 0007, iter [03700, 05004], lr: 0.100000, loss: 3.3117
2022-07-15 03:20:01 - train: epoch 0007, iter [03800, 05004], lr: 0.100000, loss: 3.4375
2022-07-15 03:20:35 - train: epoch 0007, iter [03900, 05004], lr: 0.100000, loss: 3.2566
2022-07-15 03:21:07 - train: epoch 0007, iter [04000, 05004], lr: 0.100000, loss: 3.3160
2022-07-15 03:21:41 - train: epoch 0007, iter [04100, 05004], lr: 0.100000, loss: 3.2098
2022-07-15 03:22:14 - train: epoch 0007, iter [04200, 05004], lr: 0.100000, loss: 3.0010
2022-07-15 03:22:49 - train: epoch 0007, iter [04300, 05004], lr: 0.100000, loss: 3.3029
2022-07-15 03:23:21 - train: epoch 0007, iter [04400, 05004], lr: 0.100000, loss: 2.9444
2022-07-15 03:23:56 - train: epoch 0007, iter [04500, 05004], lr: 0.100000, loss: 3.4366
2022-07-15 03:24:29 - train: epoch 0007, iter [04600, 05004], lr: 0.100000, loss: 3.2723
2022-07-15 03:25:03 - train: epoch 0007, iter [04700, 05004], lr: 0.100000, loss: 3.3547
2022-07-15 03:25:35 - train: epoch 0007, iter [04800, 05004], lr: 0.100000, loss: 3.4671
2022-07-15 03:26:09 - train: epoch 0007, iter [04900, 05004], lr: 0.100000, loss: 3.1872
2022-07-15 03:26:41 - train: epoch 0007, iter [05000, 05004], lr: 0.100000, loss: 3.2673
2022-07-15 03:26:42 - train: epoch 007, train_loss: 3.1876
2022-07-15 03:27:57 - eval: epoch: 007, acc1: 37.612%, acc5: 63.036%, test_loss: 2.9368, per_image_load_time: 2.798ms, per_image_inference_time: 0.118ms
2022-07-15 03:27:57 - until epoch: 007, best_acc1: 37.612%
2022-07-15 03:27:57 - epoch 008 lr: 0.100000
2022-07-15 03:28:35 - train: epoch 0008, iter [00100, 05004], lr: 0.100000, loss: 3.0335
2022-07-15 03:29:10 - train: epoch 0008, iter [00200, 05004], lr: 0.100000, loss: 3.3677
2022-07-15 03:29:42 - train: epoch 0008, iter [00300, 05004], lr: 0.100000, loss: 2.8926
2022-07-15 03:30:15 - train: epoch 0008, iter [00400, 05004], lr: 0.100000, loss: 2.8962
2022-07-15 03:30:48 - train: epoch 0008, iter [00500, 05004], lr: 0.100000, loss: 3.0592
2022-07-15 03:31:22 - train: epoch 0008, iter [00600, 05004], lr: 0.100000, loss: 3.1732
2022-07-15 03:31:54 - train: epoch 0008, iter [00700, 05004], lr: 0.100000, loss: 3.3393
2022-07-15 03:32:28 - train: epoch 0008, iter [00800, 05004], lr: 0.100000, loss: 3.0407
2022-07-15 03:33:00 - train: epoch 0008, iter [00900, 05004], lr: 0.100000, loss: 3.0327
2022-07-15 03:33:34 - train: epoch 0008, iter [01000, 05004], lr: 0.100000, loss: 3.1902
2022-07-15 03:34:08 - train: epoch 0008, iter [01100, 05004], lr: 0.100000, loss: 2.8801
2022-07-15 03:34:41 - train: epoch 0008, iter [01200, 05004], lr: 0.100000, loss: 2.9829
2022-07-15 03:35:14 - train: epoch 0008, iter [01300, 05004], lr: 0.100000, loss: 3.1987
2022-07-15 03:35:47 - train: epoch 0008, iter [01400, 05004], lr: 0.100000, loss: 3.1997
2022-07-15 03:36:21 - train: epoch 0008, iter [01500, 05004], lr: 0.100000, loss: 3.1467
2022-07-15 03:36:54 - train: epoch 0008, iter [01600, 05004], lr: 0.100000, loss: 3.1857
2022-07-15 03:37:28 - train: epoch 0008, iter [01700, 05004], lr: 0.100000, loss: 3.1129
2022-07-15 03:38:00 - train: epoch 0008, iter [01800, 05004], lr: 0.100000, loss: 3.3779
2022-07-15 03:38:33 - train: epoch 0008, iter [01900, 05004], lr: 0.100000, loss: 2.8920
2022-07-15 03:39:08 - train: epoch 0008, iter [02000, 05004], lr: 0.100000, loss: 3.2033
2022-07-15 03:39:41 - train: epoch 0008, iter [02100, 05004], lr: 0.100000, loss: 3.1818
2022-07-15 03:40:15 - train: epoch 0008, iter [02200, 05004], lr: 0.100000, loss: 3.1045
2022-07-15 03:40:48 - train: epoch 0008, iter [02300, 05004], lr: 0.100000, loss: 3.1703
2022-07-15 03:41:22 - train: epoch 0008, iter [02400, 05004], lr: 0.100000, loss: 3.0090
2022-07-15 03:41:55 - train: epoch 0008, iter [02500, 05004], lr: 0.100000, loss: 3.1498
2022-07-15 03:42:29 - train: epoch 0008, iter [02600, 05004], lr: 0.100000, loss: 3.2932
2022-07-15 03:43:02 - train: epoch 0008, iter [02700, 05004], lr: 0.100000, loss: 3.2700
2022-07-15 03:43:36 - train: epoch 0008, iter [02800, 05004], lr: 0.100000, loss: 3.2118
2022-07-15 03:44:08 - train: epoch 0008, iter [02900, 05004], lr: 0.100000, loss: 3.1812
2022-07-15 03:44:42 - train: epoch 0008, iter [03000, 05004], lr: 0.100000, loss: 3.2574
2022-07-15 03:45:14 - train: epoch 0008, iter [03100, 05004], lr: 0.100000, loss: 3.1411
2022-07-15 03:45:48 - train: epoch 0008, iter [03200, 05004], lr: 0.100000, loss: 3.4657
2022-07-15 03:46:22 - train: epoch 0008, iter [03300, 05004], lr: 0.100000, loss: 3.4485
2022-07-15 03:46:54 - train: epoch 0008, iter [03400, 05004], lr: 0.100000, loss: 3.2463
2022-07-15 03:47:27 - train: epoch 0008, iter [03500, 05004], lr: 0.100000, loss: 3.2249
2022-07-15 03:48:01 - train: epoch 0008, iter [03600, 05004], lr: 0.100000, loss: 3.2727
2022-07-15 03:48:34 - train: epoch 0008, iter [03700, 05004], lr: 0.100000, loss: 3.0605
2022-07-15 03:49:08 - train: epoch 0008, iter [03800, 05004], lr: 0.100000, loss: 3.1747
2022-07-15 03:49:41 - train: epoch 0008, iter [03900, 05004], lr: 0.100000, loss: 3.2336
2022-07-15 03:50:15 - train: epoch 0008, iter [04000, 05004], lr: 0.100000, loss: 3.5493
2022-07-15 03:50:48 - train: epoch 0008, iter [04100, 05004], lr: 0.100000, loss: 3.0503
2022-07-15 03:51:21 - train: epoch 0008, iter [04200, 05004], lr: 0.100000, loss: 3.1780
2022-07-15 03:51:56 - train: epoch 0008, iter [04300, 05004], lr: 0.100000, loss: 3.0003
2022-07-15 03:52:29 - train: epoch 0008, iter [04400, 05004], lr: 0.100000, loss: 3.2162
2022-07-15 03:53:01 - train: epoch 0008, iter [04500, 05004], lr: 0.100000, loss: 3.3189
2022-07-15 03:53:36 - train: epoch 0008, iter [04600, 05004], lr: 0.100000, loss: 3.4259
2022-07-15 03:54:09 - train: epoch 0008, iter [04700, 05004], lr: 0.100000, loss: 3.1831
2022-07-15 03:54:42 - train: epoch 0008, iter [04800, 05004], lr: 0.100000, loss: 3.1745
2022-07-15 03:55:15 - train: epoch 0008, iter [04900, 05004], lr: 0.100000, loss: 3.2242
2022-07-15 03:55:47 - train: epoch 0008, iter [05000, 05004], lr: 0.100000, loss: 3.0392
2022-07-15 03:55:48 - train: epoch 008, train_loss: 3.1547
2022-07-15 03:57:02 - eval: epoch: 008, acc1: 39.688%, acc5: 64.866%, test_loss: 2.8297, per_image_load_time: 2.740ms, per_image_inference_time: 0.119ms
2022-07-15 03:57:02 - until epoch: 008, best_acc1: 39.688%
2022-07-15 03:57:02 - epoch 009 lr: 0.100000
2022-07-15 03:57:40 - train: epoch 0009, iter [00100, 05004], lr: 0.100000, loss: 2.9048
2022-07-15 03:58:13 - train: epoch 0009, iter [00200, 05004], lr: 0.100000, loss: 2.9408
2022-07-15 03:58:46 - train: epoch 0009, iter [00300, 05004], lr: 0.100000, loss: 2.7914
2022-07-15 03:59:20 - train: epoch 0009, iter [00400, 05004], lr: 0.100000, loss: 3.3100
2022-07-15 03:59:52 - train: epoch 0009, iter [00500, 05004], lr: 0.100000, loss: 3.1051
2022-07-15 04:00:25 - train: epoch 0009, iter [00600, 05004], lr: 0.100000, loss: 3.1116
2022-07-15 04:00:59 - train: epoch 0009, iter [00700, 05004], lr: 0.100000, loss: 3.1438
2022-07-15 04:01:30 - train: epoch 0009, iter [00800, 05004], lr: 0.100000, loss: 2.9262
2022-07-15 04:02:04 - train: epoch 0009, iter [00900, 05004], lr: 0.100000, loss: 3.0014
2022-07-15 04:02:36 - train: epoch 0009, iter [01000, 05004], lr: 0.100000, loss: 2.9858
2022-07-15 04:03:11 - train: epoch 0009, iter [01100, 05004], lr: 0.100000, loss: 3.4061
2022-07-15 04:03:42 - train: epoch 0009, iter [01200, 05004], lr: 0.100000, loss: 3.2227
2022-07-15 04:04:16 - train: epoch 0009, iter [01300, 05004], lr: 0.100000, loss: 3.2535
2022-07-15 04:04:48 - train: epoch 0009, iter [01400, 05004], lr: 0.100000, loss: 2.9289
2022-07-15 04:05:22 - train: epoch 0009, iter [01500, 05004], lr: 0.100000, loss: 3.0028
2022-07-15 04:05:55 - train: epoch 0009, iter [01600, 05004], lr: 0.100000, loss: 3.1108
2022-07-15 04:06:27 - train: epoch 0009, iter [01700, 05004], lr: 0.100000, loss: 3.3334
2022-07-15 04:07:01 - train: epoch 0009, iter [01800, 05004], lr: 0.100000, loss: 2.9906
2022-07-15 04:07:35 - train: epoch 0009, iter [01900, 05004], lr: 0.100000, loss: 2.8877
2022-07-15 04:08:08 - train: epoch 0009, iter [02000, 05004], lr: 0.100000, loss: 3.0430
2022-07-15 04:08:41 - train: epoch 0009, iter [02100, 05004], lr: 0.100000, loss: 3.2465
2022-07-15 04:09:15 - train: epoch 0009, iter [02200, 05004], lr: 0.100000, loss: 3.3532
2022-07-15 04:09:47 - train: epoch 0009, iter [02300, 05004], lr: 0.100000, loss: 2.8529
2022-07-15 04:10:21 - train: epoch 0009, iter [02400, 05004], lr: 0.100000, loss: 3.0473
2022-07-15 04:10:53 - train: epoch 0009, iter [02500, 05004], lr: 0.100000, loss: 2.9235
2022-07-15 04:11:27 - train: epoch 0009, iter [02600, 05004], lr: 0.100000, loss: 3.2709
2022-07-15 04:12:01 - train: epoch 0009, iter [02700, 05004], lr: 0.100000, loss: 2.9921
2022-07-15 04:12:34 - train: epoch 0009, iter [02800, 05004], lr: 0.100000, loss: 3.1304
2022-07-15 04:13:07 - train: epoch 0009, iter [02900, 05004], lr: 0.100000, loss: 2.8444
2022-07-15 04:13:40 - train: epoch 0009, iter [03000, 05004], lr: 0.100000, loss: 3.1592
2022-07-15 04:14:13 - train: epoch 0009, iter [03100, 05004], lr: 0.100000, loss: 3.2942
2022-07-15 04:14:47 - train: epoch 0009, iter [03200, 05004], lr: 0.100000, loss: 3.1581
2022-07-15 04:15:20 - train: epoch 0009, iter [03300, 05004], lr: 0.100000, loss: 3.1724
2022-07-15 04:15:53 - train: epoch 0009, iter [03400, 05004], lr: 0.100000, loss: 3.1958
2022-07-15 04:16:27 - train: epoch 0009, iter [03500, 05004], lr: 0.100000, loss: 3.2041
2022-07-15 04:17:00 - train: epoch 0009, iter [03600, 05004], lr: 0.100000, loss: 2.9758
2022-07-15 04:17:34 - train: epoch 0009, iter [03700, 05004], lr: 0.100000, loss: 3.3283
2022-07-15 04:18:06 - train: epoch 0009, iter [03800, 05004], lr: 0.100000, loss: 3.3654
2022-07-15 04:18:40 - train: epoch 0009, iter [03900, 05004], lr: 0.100000, loss: 2.7687
2022-07-15 04:19:13 - train: epoch 0009, iter [04000, 05004], lr: 0.100000, loss: 3.2149
2022-07-15 04:19:46 - train: epoch 0009, iter [04100, 05004], lr: 0.100000, loss: 3.1284
2022-07-15 04:20:21 - train: epoch 0009, iter [04200, 05004], lr: 0.100000, loss: 2.9798
2022-07-15 04:20:53 - train: epoch 0009, iter [04300, 05004], lr: 0.100000, loss: 3.2174
2022-07-15 04:21:28 - train: epoch 0009, iter [04400, 05004], lr: 0.100000, loss: 3.1201
2022-07-15 04:22:00 - train: epoch 0009, iter [04500, 05004], lr: 0.100000, loss: 3.2427
2022-07-15 04:22:33 - train: epoch 0009, iter [04600, 05004], lr: 0.100000, loss: 3.1505
2022-07-15 04:23:07 - train: epoch 0009, iter [04700, 05004], lr: 0.100000, loss: 3.2657
2022-07-15 04:23:40 - train: epoch 0009, iter [04800, 05004], lr: 0.100000, loss: 3.2716
2022-07-15 04:24:15 - train: epoch 0009, iter [04900, 05004], lr: 0.100000, loss: 3.1771
2022-07-15 04:24:45 - train: epoch 0009, iter [05000, 05004], lr: 0.100000, loss: 2.9844
2022-07-15 04:24:46 - train: epoch 009, train_loss: 3.1269
2022-07-15 04:26:00 - eval: epoch: 009, acc1: 39.628%, acc5: 64.754%, test_loss: 2.8477, per_image_load_time: 2.231ms, per_image_inference_time: 0.132ms
2022-07-15 04:26:00 - until epoch: 009, best_acc1: 39.688%
2022-07-15 04:26:00 - epoch 010 lr: 0.100000
2022-07-15 04:26:39 - train: epoch 0010, iter [00100, 05004], lr: 0.100000, loss: 3.0548
2022-07-15 04:27:10 - train: epoch 0010, iter [00200, 05004], lr: 0.100000, loss: 3.2206
2022-07-15 04:27:44 - train: epoch 0010, iter [00300, 05004], lr: 0.100000, loss: 3.1744
2022-07-15 04:28:16 - train: epoch 0010, iter [00400, 05004], lr: 0.100000, loss: 3.0352
2022-07-15 04:28:51 - train: epoch 0010, iter [00500, 05004], lr: 0.100000, loss: 2.9305
2022-07-15 04:29:24 - train: epoch 0010, iter [00600, 05004], lr: 0.100000, loss: 3.3237
2022-07-15 04:29:57 - train: epoch 0010, iter [00700, 05004], lr: 0.100000, loss: 3.1728
2022-07-15 04:30:29 - train: epoch 0010, iter [00800, 05004], lr: 0.100000, loss: 3.0707
2022-07-15 04:31:02 - train: epoch 0010, iter [00900, 05004], lr: 0.100000, loss: 2.8356
2022-07-15 04:31:35 - train: epoch 0010, iter [01000, 05004], lr: 0.100000, loss: 3.0294
2022-07-15 04:32:09 - train: epoch 0010, iter [01100, 05004], lr: 0.100000, loss: 3.0974
2022-07-15 04:32:42 - train: epoch 0010, iter [01200, 05004], lr: 0.100000, loss: 2.9543
2022-07-15 04:33:15 - train: epoch 0010, iter [01300, 05004], lr: 0.100000, loss: 2.8917
2022-07-15 04:33:48 - train: epoch 0010, iter [01400, 05004], lr: 0.100000, loss: 3.2420
2022-07-15 04:34:21 - train: epoch 0010, iter [01500, 05004], lr: 0.100000, loss: 2.8960
2022-07-15 04:34:54 - train: epoch 0010, iter [01600, 05004], lr: 0.100000, loss: 3.0527
2022-07-15 04:35:28 - train: epoch 0010, iter [01700, 05004], lr: 0.100000, loss: 3.1758
2022-07-15 04:36:00 - train: epoch 0010, iter [01800, 05004], lr: 0.100000, loss: 3.0508
2022-07-15 04:36:34 - train: epoch 0010, iter [01900, 05004], lr: 0.100000, loss: 3.1427
2022-07-15 04:37:07 - train: epoch 0010, iter [02000, 05004], lr: 0.100000, loss: 3.1786
2022-07-15 04:37:40 - train: epoch 0010, iter [02100, 05004], lr: 0.100000, loss: 3.0898
2022-07-15 04:38:12 - train: epoch 0010, iter [02200, 05004], lr: 0.100000, loss: 3.3108
2022-07-15 04:38:46 - train: epoch 0010, iter [02300, 05004], lr: 0.100000, loss: 3.3105
2022-07-15 04:39:19 - train: epoch 0010, iter [02400, 05004], lr: 0.100000, loss: 3.2741
2022-07-15 04:39:53 - train: epoch 0010, iter [02500, 05004], lr: 0.100000, loss: 3.1179
2022-07-15 04:40:26 - train: epoch 0010, iter [02600, 05004], lr: 0.100000, loss: 3.1475
2022-07-15 04:41:00 - train: epoch 0010, iter [02700, 05004], lr: 0.100000, loss: 3.0862
2022-07-15 04:41:33 - train: epoch 0010, iter [02800, 05004], lr: 0.100000, loss: 3.1354
2022-07-15 04:42:07 - train: epoch 0010, iter [02900, 05004], lr: 0.100000, loss: 3.1950
2022-07-15 04:42:39 - train: epoch 0010, iter [03000, 05004], lr: 0.100000, loss: 3.0850
2022-07-15 04:43:12 - train: epoch 0010, iter [03100, 05004], lr: 0.100000, loss: 3.1643
2022-07-15 04:43:45 - train: epoch 0010, iter [03200, 05004], lr: 0.100000, loss: 3.2522
2022-07-15 04:44:19 - train: epoch 0010, iter [03300, 05004], lr: 0.100000, loss: 3.2377
2022-07-15 04:44:52 - train: epoch 0010, iter [03400, 05004], lr: 0.100000, loss: 3.2396
2022-07-15 04:45:27 - train: epoch 0010, iter [03500, 05004], lr: 0.100000, loss: 3.1983
2022-07-15 04:45:59 - train: epoch 0010, iter [03600, 05004], lr: 0.100000, loss: 3.3680
2022-07-15 04:46:33 - train: epoch 0010, iter [03700, 05004], lr: 0.100000, loss: 2.9659
2022-07-15 04:47:06 - train: epoch 0010, iter [03800, 05004], lr: 0.100000, loss: 3.1738
2022-07-15 04:47:39 - train: epoch 0010, iter [03900, 05004], lr: 0.100000, loss: 2.7989
2022-07-15 04:48:12 - train: epoch 0010, iter [04000, 05004], lr: 0.100000, loss: 3.0806
2022-07-15 04:48:46 - train: epoch 0010, iter [04100, 05004], lr: 0.100000, loss: 3.0306
2022-07-15 04:49:18 - train: epoch 0010, iter [04200, 05004], lr: 0.100000, loss: 3.2138
2022-07-15 04:49:52 - train: epoch 0010, iter [04300, 05004], lr: 0.100000, loss: 3.0419
2022-07-15 04:50:25 - train: epoch 0010, iter [04400, 05004], lr: 0.100000, loss: 3.0162
2022-07-15 04:51:00 - train: epoch 0010, iter [04500, 05004], lr: 0.100000, loss: 2.9938
2022-07-15 04:51:32 - train: epoch 0010, iter [04600, 05004], lr: 0.100000, loss: 3.2824
2022-07-15 04:52:06 - train: epoch 0010, iter [04700, 05004], lr: 0.100000, loss: 3.0774
2022-07-15 04:52:39 - train: epoch 0010, iter [04800, 05004], lr: 0.100000, loss: 3.0816
2022-07-15 04:53:14 - train: epoch 0010, iter [04900, 05004], lr: 0.100000, loss: 2.9586
2022-07-15 04:53:45 - train: epoch 0010, iter [05000, 05004], lr: 0.100000, loss: 2.8553
2022-07-15 04:53:45 - train: epoch 010, train_loss: 3.1031
2022-07-15 04:55:00 - eval: epoch: 010, acc1: 41.204%, acc5: 66.114%, test_loss: 2.7619, per_image_load_time: 1.500ms, per_image_inference_time: 0.131ms
2022-07-15 04:55:00 - until epoch: 010, best_acc1: 41.204%
2022-07-15 04:55:00 - epoch 011 lr: 0.100000
2022-07-15 04:55:37 - train: epoch 0011, iter [00100, 05004], lr: 0.100000, loss: 3.0740
2022-07-15 04:56:11 - train: epoch 0011, iter [00200, 05004], lr: 0.100000, loss: 3.1414
2022-07-15 04:56:44 - train: epoch 0011, iter [00300, 05004], lr: 0.100000, loss: 2.9636
2022-07-15 04:57:17 - train: epoch 0011, iter [00400, 05004], lr: 0.100000, loss: 3.1870
2022-07-15 04:57:50 - train: epoch 0011, iter [00500, 05004], lr: 0.100000, loss: 3.0024
2022-07-15 04:58:23 - train: epoch 0011, iter [00600, 05004], lr: 0.100000, loss: 3.1759
2022-07-15 04:58:56 - train: epoch 0011, iter [00700, 05004], lr: 0.100000, loss: 3.0771
2022-07-15 04:59:29 - train: epoch 0011, iter [00800, 05004], lr: 0.100000, loss: 3.0170
2022-07-15 05:00:03 - train: epoch 0011, iter [00900, 05004], lr: 0.100000, loss: 3.1790
2022-07-15 05:00:35 - train: epoch 0011, iter [01000, 05004], lr: 0.100000, loss: 3.0733
2022-07-15 05:01:09 - train: epoch 0011, iter [01100, 05004], lr: 0.100000, loss: 3.1639
2022-07-15 05:01:42 - train: epoch 0011, iter [01200, 05004], lr: 0.100000, loss: 3.5376
2022-07-15 05:02:16 - train: epoch 0011, iter [01300, 05004], lr: 0.100000, loss: 3.1616
2022-07-15 05:02:48 - train: epoch 0011, iter [01400, 05004], lr: 0.100000, loss: 3.0248
2022-07-15 05:03:22 - train: epoch 0011, iter [01500, 05004], lr: 0.100000, loss: 2.7996
2022-07-15 05:03:54 - train: epoch 0011, iter [01600, 05004], lr: 0.100000, loss: 3.0355
2022-07-15 05:04:28 - train: epoch 0011, iter [01700, 05004], lr: 0.100000, loss: 3.1808
2022-07-15 05:05:01 - train: epoch 0011, iter [01800, 05004], lr: 0.100000, loss: 2.9733
2022-07-15 05:05:34 - train: epoch 0011, iter [01900, 05004], lr: 0.100000, loss: 2.8358
2022-07-15 05:06:08 - train: epoch 0011, iter [02000, 05004], lr: 0.100000, loss: 3.0475
2022-07-15 05:06:40 - train: epoch 0011, iter [02100, 05004], lr: 0.100000, loss: 3.1060
2022-07-15 05:07:14 - train: epoch 0011, iter [02200, 05004], lr: 0.100000, loss: 3.0749
2022-07-15 05:07:46 - train: epoch 0011, iter [02300, 05004], lr: 0.100000, loss: 3.3005
2022-07-15 05:08:20 - train: epoch 0011, iter [02400, 05004], lr: 0.100000, loss: 2.9923
2022-07-15 05:08:53 - train: epoch 0011, iter [02500, 05004], lr: 0.100000, loss: 3.4280
2022-07-15 05:09:27 - train: epoch 0011, iter [02600, 05004], lr: 0.100000, loss: 3.0677
2022-07-15 05:09:59 - train: epoch 0011, iter [02700, 05004], lr: 0.100000, loss: 3.0804
2022-07-15 05:10:33 - train: epoch 0011, iter [02800, 05004], lr: 0.100000, loss: 2.8223
2022-07-15 05:11:06 - train: epoch 0011, iter [02900, 05004], lr: 0.100000, loss: 3.0216
2022-07-15 05:11:40 - train: epoch 0011, iter [03000, 05004], lr: 0.100000, loss: 3.3451
2022-07-15 05:12:13 - train: epoch 0011, iter [03100, 05004], lr: 0.100000, loss: 3.2317
2022-07-15 05:12:47 - train: epoch 0011, iter [03200, 05004], lr: 0.100000, loss: 2.7946
2022-07-15 05:13:20 - train: epoch 0011, iter [03300, 05004], lr: 0.100000, loss: 3.2671
2022-07-15 05:13:54 - train: epoch 0011, iter [03400, 05004], lr: 0.100000, loss: 3.1371
2022-07-15 05:14:26 - train: epoch 0011, iter [03500, 05004], lr: 0.100000, loss: 3.1079
2022-07-15 05:15:01 - train: epoch 0011, iter [03600, 05004], lr: 0.100000, loss: 3.1227
2022-07-15 05:15:34 - train: epoch 0011, iter [03700, 05004], lr: 0.100000, loss: 3.3997
2022-07-15 05:16:07 - train: epoch 0011, iter [03800, 05004], lr: 0.100000, loss: 2.7252
2022-07-15 05:16:40 - train: epoch 0011, iter [03900, 05004], lr: 0.100000, loss: 3.1057
2022-07-15 05:17:13 - train: epoch 0011, iter [04000, 05004], lr: 0.100000, loss: 2.9967
2022-07-15 05:17:47 - train: epoch 0011, iter [04100, 05004], lr: 0.100000, loss: 2.8722
2022-07-15 05:18:20 - train: epoch 0011, iter [04200, 05004], lr: 0.100000, loss: 2.9570
2022-07-15 05:18:53 - train: epoch 0011, iter [04300, 05004], lr: 0.100000, loss: 3.2458
2022-07-15 05:19:27 - train: epoch 0011, iter [04400, 05004], lr: 0.100000, loss: 3.1994
2022-07-15 05:20:00 - train: epoch 0011, iter [04500, 05004], lr: 0.100000, loss: 2.8807
2022-07-15 05:20:34 - train: epoch 0011, iter [04600, 05004], lr: 0.100000, loss: 3.0175
2022-07-15 05:21:06 - train: epoch 0011, iter [04700, 05004], lr: 0.100000, loss: 2.7677
2022-07-15 05:21:39 - train: epoch 0011, iter [04800, 05004], lr: 0.100000, loss: 2.9325
2022-07-15 05:22:13 - train: epoch 0011, iter [04900, 05004], lr: 0.100000, loss: 2.9609
2022-07-15 05:22:45 - train: epoch 0011, iter [05000, 05004], lr: 0.100000, loss: 2.9183
2022-07-15 05:22:46 - train: epoch 011, train_loss: 3.0856
2022-07-15 05:24:00 - eval: epoch: 011, acc1: 40.220%, acc5: 65.424%, test_loss: 2.7972, per_image_load_time: 1.856ms, per_image_inference_time: 0.144ms
2022-07-15 05:24:00 - until epoch: 011, best_acc1: 41.204%
2022-07-15 05:24:00 - epoch 012 lr: 0.100000
2022-07-15 05:24:39 - train: epoch 0012, iter [00100, 05004], lr: 0.100000, loss: 3.0565
2022-07-15 05:25:11 - train: epoch 0012, iter [00200, 05004], lr: 0.100000, loss: 2.9507
2022-07-15 05:25:45 - train: epoch 0012, iter [00300, 05004], lr: 0.100000, loss: 3.0686
2022-07-15 05:26:18 - train: epoch 0012, iter [00400, 05004], lr: 0.100000, loss: 3.1235
2022-07-15 05:26:52 - train: epoch 0012, iter [00500, 05004], lr: 0.100000, loss: 3.3769
2022-07-15 05:27:25 - train: epoch 0012, iter [00600, 05004], lr: 0.100000, loss: 2.9938
2022-07-15 05:27:58 - train: epoch 0012, iter [00700, 05004], lr: 0.100000, loss: 2.8615
2022-07-15 05:28:31 - train: epoch 0012, iter [00800, 05004], lr: 0.100000, loss: 2.9944
2022-07-15 05:29:04 - train: epoch 0012, iter [00900, 05004], lr: 0.100000, loss: 3.1539
2022-07-15 05:29:37 - train: epoch 0012, iter [01000, 05004], lr: 0.100000, loss: 2.7271
2022-07-15 05:30:10 - train: epoch 0012, iter [01100, 05004], lr: 0.100000, loss: 3.5223
2022-07-15 05:30:43 - train: epoch 0012, iter [01200, 05004], lr: 0.100000, loss: 2.8938
2022-07-15 05:31:15 - train: epoch 0012, iter [01300, 05004], lr: 0.100000, loss: 2.9865
2022-07-15 05:31:49 - train: epoch 0012, iter [01400, 05004], lr: 0.100000, loss: 3.1253
2022-07-15 05:32:22 - train: epoch 0012, iter [01500, 05004], lr: 0.100000, loss: 2.8244
2022-07-15 05:32:56 - train: epoch 0012, iter [01600, 05004], lr: 0.100000, loss: 2.8944
2022-07-15 05:33:29 - train: epoch 0012, iter [01700, 05004], lr: 0.100000, loss: 2.8338
2022-07-15 05:34:01 - train: epoch 0012, iter [01800, 05004], lr: 0.100000, loss: 3.0650
2022-07-15 05:34:35 - train: epoch 0012, iter [01900, 05004], lr: 0.100000, loss: 3.1664
2022-07-15 05:35:08 - train: epoch 0012, iter [02000, 05004], lr: 0.100000, loss: 3.2953
2022-07-15 05:35:42 - train: epoch 0012, iter [02100, 05004], lr: 0.100000, loss: 3.0919
2022-07-15 05:36:15 - train: epoch 0012, iter [02200, 05004], lr: 0.100000, loss: 3.2307
2022-07-15 05:36:48 - train: epoch 0012, iter [02300, 05004], lr: 0.100000, loss: 3.0116
2022-07-15 05:37:22 - train: epoch 0012, iter [02400, 05004], lr: 0.100000, loss: 3.1189
2022-07-15 05:37:55 - train: epoch 0012, iter [02500, 05004], lr: 0.100000, loss: 2.9585
2022-07-15 05:38:28 - train: epoch 0012, iter [02600, 05004], lr: 0.100000, loss: 2.9119
2022-07-15 05:39:01 - train: epoch 0012, iter [02700, 05004], lr: 0.100000, loss: 3.0867
2022-07-15 05:39:34 - train: epoch 0012, iter [02800, 05004], lr: 0.100000, loss: 3.0489
2022-07-15 05:40:09 - train: epoch 0012, iter [02900, 05004], lr: 0.100000, loss: 2.8694
2022-07-15 05:40:41 - train: epoch 0012, iter [03000, 05004], lr: 0.100000, loss: 2.9516
2022-07-15 05:41:16 - train: epoch 0012, iter [03100, 05004], lr: 0.100000, loss: 3.3763
2022-07-15 05:41:48 - train: epoch 0012, iter [03200, 05004], lr: 0.100000, loss: 2.8210
2022-07-15 05:42:21 - train: epoch 0012, iter [03300, 05004], lr: 0.100000, loss: 3.0249
2022-07-15 05:42:55 - train: epoch 0012, iter [03400, 05004], lr: 0.100000, loss: 3.1548
2022-07-15 05:43:28 - train: epoch 0012, iter [03500, 05004], lr: 0.100000, loss: 3.1634
2022-07-15 05:44:01 - train: epoch 0012, iter [03600, 05004], lr: 0.100000, loss: 3.1001
2022-07-15 05:44:34 - train: epoch 0012, iter [03700, 05004], lr: 0.100000, loss: 3.1179
2022-07-15 05:45:09 - train: epoch 0012, iter [03800, 05004], lr: 0.100000, loss: 3.0174
2022-07-15 05:45:42 - train: epoch 0012, iter [03900, 05004], lr: 0.100000, loss: 3.0043
2022-07-15 05:46:15 - train: epoch 0012, iter [04000, 05004], lr: 0.100000, loss: 3.0162
2022-07-15 05:46:49 - train: epoch 0012, iter [04100, 05004], lr: 0.100000, loss: 3.0460
2022-07-15 05:47:22 - train: epoch 0012, iter [04200, 05004], lr: 0.100000, loss: 2.9307
2022-07-15 05:47:56 - train: epoch 0012, iter [04300, 05004], lr: 0.100000, loss: 3.1941
2022-07-15 05:48:29 - train: epoch 0012, iter [04400, 05004], lr: 0.100000, loss: 2.9862
2022-07-15 05:49:02 - train: epoch 0012, iter [04500, 05004], lr: 0.100000, loss: 2.8822
2022-07-15 05:49:36 - train: epoch 0012, iter [04600, 05004], lr: 0.100000, loss: 3.3519
2022-07-15 05:50:09 - train: epoch 0012, iter [04700, 05004], lr: 0.100000, loss: 3.0897
2022-07-15 05:50:43 - train: epoch 0012, iter [04800, 05004], lr: 0.100000, loss: 3.2126
2022-07-15 05:51:16 - train: epoch 0012, iter [04900, 05004], lr: 0.100000, loss: 3.0829
2022-07-15 05:51:47 - train: epoch 0012, iter [05000, 05004], lr: 0.100000, loss: 2.8302
2022-07-15 05:51:48 - train: epoch 012, train_loss: 3.0689
2022-07-15 05:53:03 - eval: epoch: 012, acc1: 40.380%, acc5: 65.682%, test_loss: 2.7938, per_image_load_time: 2.261ms, per_image_inference_time: 0.137ms
2022-07-15 05:53:03 - until epoch: 012, best_acc1: 41.204%
2022-07-15 05:53:03 - epoch 013 lr: 0.100000
2022-07-15 05:53:41 - train: epoch 0013, iter [00100, 05004], lr: 0.100000, loss: 2.9823
2022-07-15 05:54:16 - train: epoch 0013, iter [00200, 05004], lr: 0.100000, loss: 3.1500
2022-07-15 05:54:49 - train: epoch 0013, iter [00300, 05004], lr: 0.100000, loss: 2.9067
2022-07-15 05:55:23 - train: epoch 0013, iter [00400, 05004], lr: 0.100000, loss: 3.0031
2022-07-15 05:55:56 - train: epoch 0013, iter [00500, 05004], lr: 0.100000, loss: 3.0027
2022-07-15 05:56:29 - train: epoch 0013, iter [00600, 05004], lr: 0.100000, loss: 3.2095
2022-07-15 05:57:02 - train: epoch 0013, iter [00700, 05004], lr: 0.100000, loss: 2.9277
2022-07-15 05:57:33 - train: epoch 0013, iter [00800, 05004], lr: 0.100000, loss: 3.1787
2022-07-15 05:58:07 - train: epoch 0013, iter [00900, 05004], lr: 0.100000, loss: 3.0761
2022-07-15 05:58:40 - train: epoch 0013, iter [01000, 05004], lr: 0.100000, loss: 3.0987
2022-07-15 05:59:15 - train: epoch 0013, iter [01100, 05004], lr: 0.100000, loss: 3.1372
2022-07-15 05:59:47 - train: epoch 0013, iter [01200, 05004], lr: 0.100000, loss: 3.2461
2022-07-15 06:00:20 - train: epoch 0013, iter [01300, 05004], lr: 0.100000, loss: 3.2358
2022-07-15 06:00:53 - train: epoch 0013, iter [01400, 05004], lr: 0.100000, loss: 3.0596
2022-07-15 06:01:28 - train: epoch 0013, iter [01500, 05004], lr: 0.100000, loss: 3.1132
2022-07-15 06:02:00 - train: epoch 0013, iter [01600, 05004], lr: 0.100000, loss: 2.8902
2022-07-15 06:02:34 - train: epoch 0013, iter [01700, 05004], lr: 0.100000, loss: 3.0005
2022-07-15 06:03:07 - train: epoch 0013, iter [01800, 05004], lr: 0.100000, loss: 2.9382
2022-07-15 06:03:40 - train: epoch 0013, iter [01900, 05004], lr: 0.100000, loss: 2.9950
2022-07-15 06:04:13 - train: epoch 0013, iter [02000, 05004], lr: 0.100000, loss: 3.2903
2022-07-15 06:04:47 - train: epoch 0013, iter [02100, 05004], lr: 0.100000, loss: 3.3661
2022-07-15 06:05:20 - train: epoch 0013, iter [02200, 05004], lr: 0.100000, loss: 3.0068
2022-07-15 06:05:54 - train: epoch 0013, iter [02300, 05004], lr: 0.100000, loss: 2.9827
2022-07-15 06:06:26 - train: epoch 0013, iter [02400, 05004], lr: 0.100000, loss: 3.0525
2022-07-15 06:07:00 - train: epoch 0013, iter [02500, 05004], lr: 0.100000, loss: 2.9749
2022-07-15 06:07:34 - train: epoch 0013, iter [02600, 05004], lr: 0.100000, loss: 2.8923
2022-07-15 06:08:08 - train: epoch 0013, iter [02700, 05004], lr: 0.100000, loss: 2.9865
2022-07-15 06:08:41 - train: epoch 0013, iter [02800, 05004], lr: 0.100000, loss: 3.1052
2022-07-15 06:09:15 - train: epoch 0013, iter [02900, 05004], lr: 0.100000, loss: 3.0938
2022-07-15 06:09:46 - train: epoch 0013, iter [03000, 05004], lr: 0.100000, loss: 3.0861
2022-07-15 06:10:21 - train: epoch 0013, iter [03100, 05004], lr: 0.100000, loss: 2.8670
2022-07-15 06:10:53 - train: epoch 0013, iter [03200, 05004], lr: 0.100000, loss: 3.0328
2022-07-15 06:11:27 - train: epoch 0013, iter [03300, 05004], lr: 0.100000, loss: 2.8486
2022-07-15 06:12:00 - train: epoch 0013, iter [03400, 05004], lr: 0.100000, loss: 3.0776
2022-07-15 06:12:33 - train: epoch 0013, iter [03500, 05004], lr: 0.100000, loss: 2.8775
2022-07-15 06:13:07 - train: epoch 0013, iter [03600, 05004], lr: 0.100000, loss: 3.2025
2022-07-15 06:13:40 - train: epoch 0013, iter [03700, 05004], lr: 0.100000, loss: 2.8854
2022-07-15 06:14:13 - train: epoch 0013, iter [03800, 05004], lr: 0.100000, loss: 3.2080
2022-07-15 06:14:47 - train: epoch 0013, iter [03900, 05004], lr: 0.100000, loss: 3.1782
2022-07-15 06:15:20 - train: epoch 0013, iter [04000, 05004], lr: 0.100000, loss: 3.0574
2022-07-15 06:15:53 - train: epoch 0013, iter [04100, 05004], lr: 0.100000, loss: 3.0259
2022-07-15 06:16:27 - train: epoch 0013, iter [04200, 05004], lr: 0.100000, loss: 3.1160
2022-07-15 06:17:01 - train: epoch 0013, iter [04300, 05004], lr: 0.100000, loss: 3.1002
2022-07-15 06:17:33 - train: epoch 0013, iter [04400, 05004], lr: 0.100000, loss: 2.9736
2022-07-15 06:18:08 - train: epoch 0013, iter [04500, 05004], lr: 0.100000, loss: 3.1110
2022-07-15 06:18:40 - train: epoch 0013, iter [04600, 05004], lr: 0.100000, loss: 2.9971
2022-07-15 06:19:13 - train: epoch 0013, iter [04700, 05004], lr: 0.100000, loss: 3.1737
2022-07-15 06:19:47 - train: epoch 0013, iter [04800, 05004], lr: 0.100000, loss: 3.0138
2022-07-15 06:20:22 - train: epoch 0013, iter [04900, 05004], lr: 0.100000, loss: 3.0261
2022-07-15 06:20:52 - train: epoch 0013, iter [05000, 05004], lr: 0.100000, loss: 3.1337
2022-07-15 06:20:53 - train: epoch 013, train_loss: 3.0545
2022-07-15 06:22:07 - eval: epoch: 013, acc1: 41.818%, acc5: 66.560%, test_loss: 2.7200, per_image_load_time: 2.110ms, per_image_inference_time: 0.125ms
2022-07-15 06:22:07 - until epoch: 013, best_acc1: 41.818%
2022-07-15 06:22:07 - epoch 014 lr: 0.100000
2022-07-15 06:22:45 - train: epoch 0014, iter [00100, 05004], lr: 0.100000, loss: 2.8801
2022-07-15 06:23:19 - train: epoch 0014, iter [00200, 05004], lr: 0.100000, loss: 3.1555
2022-07-15 06:23:52 - train: epoch 0014, iter [00300, 05004], lr: 0.100000, loss: 2.7992
2022-07-15 06:24:26 - train: epoch 0014, iter [00400, 05004], lr: 0.100000, loss: 2.9621
2022-07-15 06:24:58 - train: epoch 0014, iter [00500, 05004], lr: 0.100000, loss: 3.0472
2022-07-15 06:25:32 - train: epoch 0014, iter [00600, 05004], lr: 0.100000, loss: 2.9654
2022-07-15 06:26:05 - train: epoch 0014, iter [00700, 05004], lr: 0.100000, loss: 3.0259
2022-07-15 06:26:38 - train: epoch 0014, iter [00800, 05004], lr: 0.100000, loss: 3.0209
2022-07-15 06:27:11 - train: epoch 0014, iter [00900, 05004], lr: 0.100000, loss: 3.0185
2022-07-15 06:27:45 - train: epoch 0014, iter [01000, 05004], lr: 0.100000, loss: 3.1438
2022-07-15 06:28:17 - train: epoch 0014, iter [01100, 05004], lr: 0.100000, loss: 2.8326
2022-07-15 06:28:51 - train: epoch 0014, iter [01200, 05004], lr: 0.100000, loss: 3.0523
2022-07-15 06:29:25 - train: epoch 0014, iter [01300, 05004], lr: 0.100000, loss: 3.0247
2022-07-15 06:29:57 - train: epoch 0014, iter [01400, 05004], lr: 0.100000, loss: 3.1215
2022-07-15 06:30:30 - train: epoch 0014, iter [01500, 05004], lr: 0.100000, loss: 3.2940
2022-07-15 06:31:03 - train: epoch 0014, iter [01600, 05004], lr: 0.100000, loss: 2.9380
2022-07-15 06:31:36 - train: epoch 0014, iter [01700, 05004], lr: 0.100000, loss: 3.2634
2022-07-15 06:32:10 - train: epoch 0014, iter [01800, 05004], lr: 0.100000, loss: 3.2426
2022-07-15 06:32:42 - train: epoch 0014, iter [01900, 05004], lr: 0.100000, loss: 2.8183
2022-07-15 06:33:16 - train: epoch 0014, iter [02000, 05004], lr: 0.100000, loss: 2.9384
2022-07-15 06:33:49 - train: epoch 0014, iter [02100, 05004], lr: 0.100000, loss: 3.0899
2022-07-15 06:34:22 - train: epoch 0014, iter [02200, 05004], lr: 0.100000, loss: 2.9670
2022-07-15 06:34:55 - train: epoch 0014, iter [02300, 05004], lr: 0.100000, loss: 3.0732
2022-07-15 06:35:28 - train: epoch 0014, iter [02400, 05004], lr: 0.100000, loss: 3.2487
2022-07-15 06:36:01 - train: epoch 0014, iter [02500, 05004], lr: 0.100000, loss: 2.9502
2022-07-15 06:36:34 - train: epoch 0014, iter [02600, 05004], lr: 0.100000, loss: 3.0234
2022-07-15 06:37:09 - train: epoch 0014, iter [02700, 05004], lr: 0.100000, loss: 3.0526
2022-07-15 06:37:40 - train: epoch 0014, iter [02800, 05004], lr: 0.100000, loss: 3.2954
2022-07-15 06:38:14 - train: epoch 0014, iter [02900, 05004], lr: 0.100000, loss: 2.9120
2022-07-15 06:38:47 - train: epoch 0014, iter [03000, 05004], lr: 0.100000, loss: 3.3007
2022-07-15 06:39:20 - train: epoch 0014, iter [03100, 05004], lr: 0.100000, loss: 2.9925
2022-07-15 06:39:53 - train: epoch 0014, iter [03200, 05004], lr: 0.100000, loss: 2.9595
2022-07-15 06:40:26 - train: epoch 0014, iter [03300, 05004], lr: 0.100000, loss: 2.8342
2022-07-15 06:41:01 - train: epoch 0014, iter [03400, 05004], lr: 0.100000, loss: 2.8817
2022-07-15 06:41:33 - train: epoch 0014, iter [03500, 05004], lr: 0.100000, loss: 3.0877
2022-07-15 06:42:07 - train: epoch 0014, iter [03600, 05004], lr: 0.100000, loss: 2.9192
2022-07-15 06:42:40 - train: epoch 0014, iter [03700, 05004], lr: 0.100000, loss: 3.0655
2022-07-15 06:43:13 - train: epoch 0014, iter [03800, 05004], lr: 0.100000, loss: 3.3027
2022-07-15 06:43:47 - train: epoch 0014, iter [03900, 05004], lr: 0.100000, loss: 3.0621
2022-07-15 06:44:19 - train: epoch 0014, iter [04000, 05004], lr: 0.100000, loss: 3.1688
2022-07-15 06:44:54 - train: epoch 0014, iter [04100, 05004], lr: 0.100000, loss: 3.0032
2022-07-15 06:45:27 - train: epoch 0014, iter [04200, 05004], lr: 0.100000, loss: 2.8900
2022-07-15 06:46:01 - train: epoch 0014, iter [04300, 05004], lr: 0.100000, loss: 2.9799
2022-07-15 06:46:33 - train: epoch 0014, iter [04400, 05004], lr: 0.100000, loss: 2.9231
2022-07-15 06:47:07 - train: epoch 0014, iter [04500, 05004], lr: 0.100000, loss: 3.0152
2022-07-15 06:47:39 - train: epoch 0014, iter [04600, 05004], lr: 0.100000, loss: 2.9385
2022-07-15 06:48:13 - train: epoch 0014, iter [04700, 05004], lr: 0.100000, loss: 3.0867
2022-07-15 06:48:47 - train: epoch 0014, iter [04800, 05004], lr: 0.100000, loss: 2.9336
2022-07-15 06:49:20 - train: epoch 0014, iter [04900, 05004], lr: 0.100000, loss: 2.8553
2022-07-15 06:49:52 - train: epoch 0014, iter [05000, 05004], lr: 0.100000, loss: 3.1044
2022-07-15 06:49:52 - train: epoch 014, train_loss: 3.0419
2022-07-15 06:51:07 - eval: epoch: 014, acc1: 39.790%, acc5: 65.106%, test_loss: 2.8195, per_image_load_time: 2.014ms, per_image_inference_time: 0.134ms
2022-07-15 06:51:07 - until epoch: 014, best_acc1: 41.818%
2022-07-15 06:51:07 - epoch 015 lr: 0.100000
2022-07-15 06:51:45 - train: epoch 0015, iter [00100, 05004], lr: 0.100000, loss: 2.8538
2022-07-15 06:52:20 - train: epoch 0015, iter [00200, 05004], lr: 0.100000, loss: 3.2088
2022-07-15 06:52:52 - train: epoch 0015, iter [00300, 05004], lr: 0.100000, loss: 3.1254
2022-07-15 06:53:25 - train: epoch 0015, iter [00400, 05004], lr: 0.100000, loss: 2.9920
2022-07-15 06:53:58 - train: epoch 0015, iter [00500, 05004], lr: 0.100000, loss: 2.9849
2022-07-15 06:54:32 - train: epoch 0015, iter [00600, 05004], lr: 0.100000, loss: 3.1434
2022-07-15 06:55:05 - train: epoch 0015, iter [00700, 05004], lr: 0.100000, loss: 3.0428
2022-07-15 06:55:37 - train: epoch 0015, iter [00800, 05004], lr: 0.100000, loss: 2.8325
2022-07-15 06:56:12 - train: epoch 0015, iter [00900, 05004], lr: 0.100000, loss: 2.8446
2022-07-15 06:56:44 - train: epoch 0015, iter [01000, 05004], lr: 0.100000, loss: 3.1194
2022-07-15 06:57:17 - train: epoch 0015, iter [01100, 05004], lr: 0.100000, loss: 2.9279
2022-07-15 06:57:51 - train: epoch 0015, iter [01200, 05004], lr: 0.100000, loss: 3.1499
2022-07-15 06:58:23 - train: epoch 0015, iter [01300, 05004], lr: 0.100000, loss: 3.1496
2022-07-15 06:58:57 - train: epoch 0015, iter [01400, 05004], lr: 0.100000, loss: 2.9254
2022-07-15 06:59:30 - train: epoch 0015, iter [01500, 05004], lr: 0.100000, loss: 2.8451
2022-07-15 07:00:04 - train: epoch 0015, iter [01600, 05004], lr: 0.100000, loss: 2.9875
2022-07-15 07:00:36 - train: epoch 0015, iter [01700, 05004], lr: 0.100000, loss: 3.3059
2022-07-15 07:01:10 - train: epoch 0015, iter [01800, 05004], lr: 0.100000, loss: 2.8590
2022-07-15 07:01:43 - train: epoch 0015, iter [01900, 05004], lr: 0.100000, loss: 2.8164
2022-07-15 07:02:16 - train: epoch 0015, iter [02000, 05004], lr: 0.100000, loss: 2.9879
2022-07-15 07:02:49 - train: epoch 0015, iter [02100, 05004], lr: 0.100000, loss: 2.8582
2022-07-15 07:03:23 - train: epoch 0015, iter [02200, 05004], lr: 0.100000, loss: 3.2619
2022-07-15 07:03:56 - train: epoch 0015, iter [02300, 05004], lr: 0.100000, loss: 2.6709
2022-07-15 07:04:29 - train: epoch 0015, iter [02400, 05004], lr: 0.100000, loss: 3.0327
2022-07-15 07:05:01 - train: epoch 0015, iter [02500, 05004], lr: 0.100000, loss: 3.2124
2022-07-15 07:05:35 - train: epoch 0015, iter [02600, 05004], lr: 0.100000, loss: 2.7549
2022-07-15 07:06:08 - train: epoch 0015, iter [02700, 05004], lr: 0.100000, loss: 3.0197
2022-07-15 07:06:42 - train: epoch 0015, iter [02800, 05004], lr: 0.100000, loss: 3.2820
2022-07-15 07:07:14 - train: epoch 0015, iter [02900, 05004], lr: 0.100000, loss: 3.0551
2022-07-15 07:07:48 - train: epoch 0015, iter [03000, 05004], lr: 0.100000, loss: 2.7735
2022-07-15 07:08:21 - train: epoch 0015, iter [03100, 05004], lr: 0.100000, loss: 2.9331
2022-07-15 07:08:54 - train: epoch 0015, iter [03200, 05004], lr: 0.100000, loss: 2.8845
2022-07-15 07:09:27 - train: epoch 0015, iter [03300, 05004], lr: 0.100000, loss: 2.9220
2022-07-15 07:10:02 - train: epoch 0015, iter [03400, 05004], lr: 0.100000, loss: 3.0506
2022-07-15 07:10:34 - train: epoch 0015, iter [03500, 05004], lr: 0.100000, loss: 3.2294
2022-07-15 07:11:08 - train: epoch 0015, iter [03600, 05004], lr: 0.100000, loss: 3.1199
2022-07-15 07:11:41 - train: epoch 0015, iter [03700, 05004], lr: 0.100000, loss: 3.0667
2022-07-15 07:12:15 - train: epoch 0015, iter [03800, 05004], lr: 0.100000, loss: 3.0881
2022-07-15 07:12:47 - train: epoch 0015, iter [03900, 05004], lr: 0.100000, loss: 3.2195
2022-07-15 07:13:21 - train: epoch 0015, iter [04000, 05004], lr: 0.100000, loss: 3.1117
2022-07-15 07:13:55 - train: epoch 0015, iter [04100, 05004], lr: 0.100000, loss: 3.1142
2022-07-15 07:14:28 - train: epoch 0015, iter [04200, 05004], lr: 0.100000, loss: 2.7244
2022-07-15 07:15:01 - train: epoch 0015, iter [04300, 05004], lr: 0.100000, loss: 2.9834
2022-07-15 07:15:35 - train: epoch 0015, iter [04400, 05004], lr: 0.100000, loss: 2.9765
2022-07-15 07:16:07 - train: epoch 0015, iter [04500, 05004], lr: 0.100000, loss: 3.1070
2022-07-15 07:16:41 - train: epoch 0015, iter [04600, 05004], lr: 0.100000, loss: 2.9371
2022-07-15 07:17:13 - train: epoch 0015, iter [04700, 05004], lr: 0.100000, loss: 3.1811
2022-07-15 07:17:48 - train: epoch 0015, iter [04800, 05004], lr: 0.100000, loss: 3.0633
2022-07-15 07:18:21 - train: epoch 0015, iter [04900, 05004], lr: 0.100000, loss: 3.1574
2022-07-15 07:18:52 - train: epoch 0015, iter [05000, 05004], lr: 0.100000, loss: 3.1884
2022-07-15 07:18:53 - train: epoch 015, train_loss: 3.0312
2022-07-15 07:20:07 - eval: epoch: 015, acc1: 41.378%, acc5: 66.278%, test_loss: 2.7501, per_image_load_time: 1.978ms, per_image_inference_time: 0.135ms
2022-07-15 07:20:07 - until epoch: 015, best_acc1: 41.818%
2022-07-15 07:20:07 - epoch 016 lr: 0.100000
2022-07-15 07:20:45 - train: epoch 0016, iter [00100, 05004], lr: 0.100000, loss: 2.9310
2022-07-15 07:21:18 - train: epoch 0016, iter [00200, 05004], lr: 0.100000, loss: 2.8540
2022-07-15 07:21:52 - train: epoch 0016, iter [00300, 05004], lr: 0.100000, loss: 3.0734
2022-07-15 07:22:25 - train: epoch 0016, iter [00400, 05004], lr: 0.100000, loss: 3.2971
2022-07-15 07:22:59 - train: epoch 0016, iter [00500, 05004], lr: 0.100000, loss: 2.7394
2022-07-15 07:23:31 - train: epoch 0016, iter [00600, 05004], lr: 0.100000, loss: 3.2844
2022-07-15 07:24:05 - train: epoch 0016, iter [00700, 05004], lr: 0.100000, loss: 2.8710
2022-07-15 07:24:37 - train: epoch 0016, iter [00800, 05004], lr: 0.100000, loss: 3.0115
2022-07-15 07:25:11 - train: epoch 0016, iter [00900, 05004], lr: 0.100000, loss: 3.1113
2022-07-15 07:25:45 - train: epoch 0016, iter [01000, 05004], lr: 0.100000, loss: 2.8328
2022-07-15 07:26:18 - train: epoch 0016, iter [01100, 05004], lr: 0.100000, loss: 2.8772
2022-07-15 07:26:50 - train: epoch 0016, iter [01200, 05004], lr: 0.100000, loss: 2.8881
2022-07-15 07:27:24 - train: epoch 0016, iter [01300, 05004], lr: 0.100000, loss: 3.2025
2022-07-15 07:27:58 - train: epoch 0016, iter [01400, 05004], lr: 0.100000, loss: 2.8634
2022-07-15 07:28:30 - train: epoch 0016, iter [01500, 05004], lr: 0.100000, loss: 3.0064
2022-07-15 07:29:05 - train: epoch 0016, iter [01600, 05004], lr: 0.100000, loss: 3.1564
2022-07-15 07:29:37 - train: epoch 0016, iter [01700, 05004], lr: 0.100000, loss: 2.9592
2022-07-15 07:30:11 - train: epoch 0016, iter [01800, 05004], lr: 0.100000, loss: 3.0271
2022-07-15 07:30:43 - train: epoch 0016, iter [01900, 05004], lr: 0.100000, loss: 2.9761
2022-07-15 07:31:18 - train: epoch 0016, iter [02000, 05004], lr: 0.100000, loss: 2.6201
2022-07-15 07:31:50 - train: epoch 0016, iter [02100, 05004], lr: 0.100000, loss: 3.1557
2022-07-15 07:32:25 - train: epoch 0016, iter [02200, 05004], lr: 0.100000, loss: 3.0022
2022-07-15 07:32:57 - train: epoch 0016, iter [02300, 05004], lr: 0.100000, loss: 3.2824
2022-07-15 07:33:31 - train: epoch 0016, iter [02400, 05004], lr: 0.100000, loss: 3.1350
2022-07-15 07:34:04 - train: epoch 0016, iter [02500, 05004], lr: 0.100000, loss: 2.8051
2022-07-15 07:34:38 - train: epoch 0016, iter [02600, 05004], lr: 0.100000, loss: 3.1010
2022-07-15 07:35:11 - train: epoch 0016, iter [02700, 05004], lr: 0.100000, loss: 2.9689
2022-07-15 07:35:44 - train: epoch 0016, iter [02800, 05004], lr: 0.100000, loss: 2.7995
2022-07-15 07:36:17 - train: epoch 0016, iter [02900, 05004], lr: 0.100000, loss: 3.0638
2022-07-15 07:36:51 - train: epoch 0016, iter [03000, 05004], lr: 0.100000, loss: 3.2436
2022-07-15 07:37:23 - train: epoch 0016, iter [03100, 05004], lr: 0.100000, loss: 3.0703
2022-07-15 07:37:56 - train: epoch 0016, iter [03200, 05004], lr: 0.100000, loss: 3.1055
2022-07-15 07:38:30 - train: epoch 0016, iter [03300, 05004], lr: 0.100000, loss: 3.0617
2022-07-15 07:39:03 - train: epoch 0016, iter [03400, 05004], lr: 0.100000, loss: 3.0631
2022-07-15 07:39:36 - train: epoch 0016, iter [03500, 05004], lr: 0.100000, loss: 3.0618
2022-07-15 07:40:11 - train: epoch 0016, iter [03600, 05004], lr: 0.100000, loss: 3.0411
2022-07-15 07:40:43 - train: epoch 0016, iter [03700, 05004], lr: 0.100000, loss: 3.1208
2022-07-15 07:41:17 - train: epoch 0016, iter [03800, 05004], lr: 0.100000, loss: 3.4124
2022-07-15 07:41:49 - train: epoch 0016, iter [03900, 05004], lr: 0.100000, loss: 3.0816
2022-07-15 07:42:23 - train: epoch 0016, iter [04000, 05004], lr: 0.100000, loss: 3.1699
2022-07-15 07:42:55 - train: epoch 0016, iter [04100, 05004], lr: 0.100000, loss: 2.9984
2022-07-15 07:43:29 - train: epoch 0016, iter [04200, 05004], lr: 0.100000, loss: 2.9802
2022-07-15 07:44:02 - train: epoch 0016, iter [04300, 05004], lr: 0.100000, loss: 2.8930
2022-07-15 07:44:36 - train: epoch 0016, iter [04400, 05004], lr: 0.100000, loss: 2.8726
2022-07-15 07:45:09 - train: epoch 0016, iter [04500, 05004], lr: 0.100000, loss: 3.1546
2022-07-15 07:45:42 - train: epoch 0016, iter [04600, 05004], lr: 0.100000, loss: 2.9110
2022-07-15 07:46:15 - train: epoch 0016, iter [04700, 05004], lr: 0.100000, loss: 3.2944
2022-07-15 07:46:49 - train: epoch 0016, iter [04800, 05004], lr: 0.100000, loss: 2.8857
2022-07-15 07:47:21 - train: epoch 0016, iter [04900, 05004], lr: 0.100000, loss: 3.0768
2022-07-15 07:47:53 - train: epoch 0016, iter [05000, 05004], lr: 0.100000, loss: 3.0832
2022-07-15 07:47:54 - train: epoch 016, train_loss: 3.0231
2022-07-15 07:49:09 - eval: epoch: 016, acc1: 42.416%, acc5: 67.706%, test_loss: 2.6688, per_image_load_time: 2.376ms, per_image_inference_time: 0.147ms
2022-07-15 07:49:09 - until epoch: 016, best_acc1: 42.416%
2022-07-15 07:49:09 - epoch 017 lr: 0.100000
2022-07-15 07:49:46 - train: epoch 0017, iter [00100, 05004], lr: 0.100000, loss: 2.9579
2022-07-15 07:50:21 - train: epoch 0017, iter [00200, 05004], lr: 0.100000, loss: 3.2146
2022-07-15 07:50:55 - train: epoch 0017, iter [00300, 05004], lr: 0.100000, loss: 3.2495
2022-07-15 07:51:26 - train: epoch 0017, iter [00400, 05004], lr: 0.100000, loss: 2.7552
2022-07-15 07:52:00 - train: epoch 0017, iter [00500, 05004], lr: 0.100000, loss: 2.9527
2022-07-15 07:52:33 - train: epoch 0017, iter [00600, 05004], lr: 0.100000, loss: 3.4005
2022-07-15 07:53:06 - train: epoch 0017, iter [00700, 05004], lr: 0.100000, loss: 3.0248
2022-07-15 07:53:40 - train: epoch 0017, iter [00800, 05004], lr: 0.100000, loss: 2.9338
2022-07-15 07:54:12 - train: epoch 0017, iter [00900, 05004], lr: 0.100000, loss: 2.9360
2022-07-15 07:54:46 - train: epoch 0017, iter [01000, 05004], lr: 0.100000, loss: 2.9299
2022-07-15 07:55:18 - train: epoch 0017, iter [01100, 05004], lr: 0.100000, loss: 3.3351
2022-07-15 07:55:51 - train: epoch 0017, iter [01200, 05004], lr: 0.100000, loss: 3.2888
2022-07-15 07:56:25 - train: epoch 0017, iter [01300, 05004], lr: 0.100000, loss: 3.0496
2022-07-15 07:56:58 - train: epoch 0017, iter [01400, 05004], lr: 0.100000, loss: 3.1024
2022-07-15 07:57:31 - train: epoch 0017, iter [01500, 05004], lr: 0.100000, loss: 2.6940
2022-07-15 07:58:04 - train: epoch 0017, iter [01600, 05004], lr: 0.100000, loss: 2.9277
2022-07-15 07:58:37 - train: epoch 0017, iter [01700, 05004], lr: 0.100000, loss: 3.1264
2022-07-15 07:59:08 - train: epoch 0017, iter [01800, 05004], lr: 0.100000, loss: 3.1511
2022-07-15 07:59:43 - train: epoch 0017, iter [01900, 05004], lr: 0.100000, loss: 2.7112
2022-07-15 08:00:15 - train: epoch 0017, iter [02000, 05004], lr: 0.100000, loss: 3.2055
2022-07-15 08:00:49 - train: epoch 0017, iter [02100, 05004], lr: 0.100000, loss: 3.0783
2022-07-15 08:01:22 - train: epoch 0017, iter [02200, 05004], lr: 0.100000, loss: 2.9489
2022-07-15 08:01:56 - train: epoch 0017, iter [02300, 05004], lr: 0.100000, loss: 3.0873
2022-07-15 08:02:28 - train: epoch 0017, iter [02400, 05004], lr: 0.100000, loss: 2.8506
2022-07-15 08:03:02 - train: epoch 0017, iter [02500, 05004], lr: 0.100000, loss: 3.1824
2022-07-15 08:03:35 - train: epoch 0017, iter [02600, 05004], lr: 0.100000, loss: 3.0748
2022-07-15 08:04:08 - train: epoch 0017, iter [02700, 05004], lr: 0.100000, loss: 2.9170
2022-07-15 08:04:41 - train: epoch 0017, iter [02800, 05004], lr: 0.100000, loss: 3.2708
2022-07-15 08:05:15 - train: epoch 0017, iter [02900, 05004], lr: 0.100000, loss: 3.1734
2022-07-15 08:05:48 - train: epoch 0017, iter [03000, 05004], lr: 0.100000, loss: 2.7009
2022-07-15 08:06:21 - train: epoch 0017, iter [03100, 05004], lr: 0.100000, loss: 3.2319
2022-07-15 08:06:55 - train: epoch 0017, iter [03200, 05004], lr: 0.100000, loss: 2.8008
2022-07-15 08:07:27 - train: epoch 0017, iter [03300, 05004], lr: 0.100000, loss: 3.0175
2022-07-15 08:08:01 - train: epoch 0017, iter [03400, 05004], lr: 0.100000, loss: 2.9150
2022-07-15 08:08:35 - train: epoch 0017, iter [03500, 05004], lr: 0.100000, loss: 3.0325
2022-07-15 08:09:08 - train: epoch 0017, iter [03600, 05004], lr: 0.100000, loss: 3.1599
2022-07-15 08:09:41 - train: epoch 0017, iter [03700, 05004], lr: 0.100000, loss: 2.9837
2022-07-15 08:10:15 - train: epoch 0017, iter [03800, 05004], lr: 0.100000, loss: 3.2510
2022-07-15 08:10:49 - train: epoch 0017, iter [03900, 05004], lr: 0.100000, loss: 2.9074
2022-07-15 08:11:22 - train: epoch 0017, iter [04000, 05004], lr: 0.100000, loss: 2.8196
2022-07-15 08:11:55 - train: epoch 0017, iter [04100, 05004], lr: 0.100000, loss: 3.0488
2022-07-15 08:12:29 - train: epoch 0017, iter [04200, 05004], lr: 0.100000, loss: 2.8770
2022-07-15 08:13:01 - train: epoch 0017, iter [04300, 05004], lr: 0.100000, loss: 2.8220
2022-07-15 08:13:36 - train: epoch 0017, iter [04400, 05004], lr: 0.100000, loss: 2.9934
2022-07-15 08:14:09 - train: epoch 0017, iter [04500, 05004], lr: 0.100000, loss: 3.0904
2022-07-15 08:14:43 - train: epoch 0017, iter [04600, 05004], lr: 0.100000, loss: 3.0246
2022-07-15 08:15:15 - train: epoch 0017, iter [04700, 05004], lr: 0.100000, loss: 3.0778
2022-07-15 08:15:50 - train: epoch 0017, iter [04800, 05004], lr: 0.100000, loss: 3.1231
2022-07-15 08:16:22 - train: epoch 0017, iter [04900, 05004], lr: 0.100000, loss: 2.7952
2022-07-15 08:16:55 - train: epoch 0017, iter [05000, 05004], lr: 0.100000, loss: 2.7765
2022-07-15 08:16:55 - train: epoch 017, train_loss: 3.0135
2022-07-15 08:18:10 - eval: epoch: 017, acc1: 41.272%, acc5: 66.624%, test_loss: 2.7421, per_image_load_time: 1.991ms, per_image_inference_time: 0.125ms
2022-07-15 08:18:10 - until epoch: 017, best_acc1: 42.416%
2022-07-15 08:18:10 - epoch 018 lr: 0.100000
2022-07-15 08:18:49 - train: epoch 0018, iter [00100, 05004], lr: 0.100000, loss: 3.0777
2022-07-15 08:19:22 - train: epoch 0018, iter [00200, 05004], lr: 0.100000, loss: 3.1178
2022-07-15 08:19:56 - train: epoch 0018, iter [00300, 05004], lr: 0.100000, loss: 3.2229
2022-07-15 08:20:29 - train: epoch 0018, iter [00400, 05004], lr: 0.100000, loss: 3.0036
2022-07-15 08:21:02 - train: epoch 0018, iter [00500, 05004], lr: 0.100000, loss: 2.9329
2022-07-15 08:21:35 - train: epoch 0018, iter [00600, 05004], lr: 0.100000, loss: 3.1449
2022-07-15 08:22:09 - train: epoch 0018, iter [00700, 05004], lr: 0.100000, loss: 2.7811
2022-07-15 08:22:41 - train: epoch 0018, iter [00800, 05004], lr: 0.100000, loss: 2.8809
2022-07-15 08:23:15 - train: epoch 0018, iter [00900, 05004], lr: 0.100000, loss: 3.0803
2022-07-15 08:23:47 - train: epoch 0018, iter [01000, 05004], lr: 0.100000, loss: 2.8249
2022-07-15 08:24:20 - train: epoch 0018, iter [01100, 05004], lr: 0.100000, loss: 3.3749
2022-07-15 08:24:53 - train: epoch 0018, iter [01200, 05004], lr: 0.100000, loss: 2.9562
2022-07-15 08:25:27 - train: epoch 0018, iter [01300, 05004], lr: 0.100000, loss: 3.3443
2022-07-15 08:26:00 - train: epoch 0018, iter [01400, 05004], lr: 0.100000, loss: 2.9112
2022-07-15 08:26:34 - train: epoch 0018, iter [01500, 05004], lr: 0.100000, loss: 3.0771
2022-07-15 08:27:05 - train: epoch 0018, iter [01600, 05004], lr: 0.100000, loss: 3.1059
2022-07-15 08:27:39 - train: epoch 0018, iter [01700, 05004], lr: 0.100000, loss: 2.8647
2022-07-15 08:28:12 - train: epoch 0018, iter [01800, 05004], lr: 0.100000, loss: 2.7142
2022-07-15 08:28:46 - train: epoch 0018, iter [01900, 05004], lr: 0.100000, loss: 3.1475
2022-07-15 08:29:18 - train: epoch 0018, iter [02000, 05004], lr: 0.100000, loss: 3.2824
2022-07-15 08:29:53 - train: epoch 0018, iter [02100, 05004], lr: 0.100000, loss: 3.2757
2022-07-15 08:30:26 - train: epoch 0018, iter [02200, 05004], lr: 0.100000, loss: 3.0592
2022-07-15 08:30:59 - train: epoch 0018, iter [02300, 05004], lr: 0.100000, loss: 2.9530
2022-07-15 08:31:33 - train: epoch 0018, iter [02400, 05004], lr: 0.100000, loss: 2.8159
2022-07-15 08:32:06 - train: epoch 0018, iter [02500, 05004], lr: 0.100000, loss: 2.7253
2022-07-15 08:32:40 - train: epoch 0018, iter [02600, 05004], lr: 0.100000, loss: 2.7965
2022-07-15 08:33:12 - train: epoch 0018, iter [02700, 05004], lr: 0.100000, loss: 3.1731
2022-07-15 08:33:46 - train: epoch 0018, iter [02800, 05004], lr: 0.100000, loss: 2.6961
2022-07-15 08:34:19 - train: epoch 0018, iter [02900, 05004], lr: 0.100000, loss: 3.0442
2022-07-15 08:34:52 - train: epoch 0018, iter [03000, 05004], lr: 0.100000, loss: 2.8989
2022-07-15 08:35:26 - train: epoch 0018, iter [03100, 05004], lr: 0.100000, loss: 3.4393
2022-07-15 08:35:59 - train: epoch 0018, iter [03200, 05004], lr: 0.100000, loss: 2.9231
2022-07-15 08:36:32 - train: epoch 0018, iter [03300, 05004], lr: 0.100000, loss: 3.0501
2022-07-15 08:37:05 - train: epoch 0018, iter [03400, 05004], lr: 0.100000, loss: 2.9574
2022-07-15 08:37:39 - train: epoch 0018, iter [03500, 05004], lr: 0.100000, loss: 3.0475
2022-07-15 08:38:12 - train: epoch 0018, iter [03600, 05004], lr: 0.100000, loss: 3.1434
2022-07-15 08:38:46 - train: epoch 0018, iter [03700, 05004], lr: 0.100000, loss: 3.4911
2022-07-15 08:39:20 - train: epoch 0018, iter [03800, 05004], lr: 0.100000, loss: 3.1302
2022-07-15 08:39:53 - train: epoch 0018, iter [03900, 05004], lr: 0.100000, loss: 2.9698
2022-07-15 08:40:27 - train: epoch 0018, iter [04000, 05004], lr: 0.100000, loss: 2.9580
2022-07-15 08:40:59 - train: epoch 0018, iter [04100, 05004], lr: 0.100000, loss: 2.9337
2022-07-15 08:41:34 - train: epoch 0018, iter [04200, 05004], lr: 0.100000, loss: 2.9624
2022-07-15 08:42:06 - train: epoch 0018, iter [04300, 05004], lr: 0.100000, loss: 2.7951
2022-07-15 08:42:40 - train: epoch 0018, iter [04400, 05004], lr: 0.100000, loss: 3.2058
2022-07-15 08:43:13 - train: epoch 0018, iter [04500, 05004], lr: 0.100000, loss: 3.0220
2022-07-15 08:43:47 - train: epoch 0018, iter [04600, 05004], lr: 0.100000, loss: 2.8637
2022-07-15 08:44:20 - train: epoch 0018, iter [04700, 05004], lr: 0.100000, loss: 3.1197
2022-07-15 08:44:54 - train: epoch 0018, iter [04800, 05004], lr: 0.100000, loss: 3.1949
2022-07-15 08:45:27 - train: epoch 0018, iter [04900, 05004], lr: 0.100000, loss: 3.0338
2022-07-15 08:45:59 - train: epoch 0018, iter [05000, 05004], lr: 0.100000, loss: 3.1784
2022-07-15 08:45:59 - train: epoch 018, train_loss: 3.0048
2022-07-15 08:47:14 - eval: epoch: 018, acc1: 41.608%, acc5: 67.050%, test_loss: 2.7128, per_image_load_time: 2.208ms, per_image_inference_time: 0.130ms
2022-07-15 08:47:14 - until epoch: 018, best_acc1: 42.416%
2022-07-15 08:47:14 - epoch 019 lr: 0.100000
2022-07-15 08:47:53 - train: epoch 0019, iter [00100, 05004], lr: 0.100000, loss: 2.8277
2022-07-15 08:48:27 - train: epoch 0019, iter [00200, 05004], lr: 0.100000, loss: 3.2093
2022-07-15 08:48:59 - train: epoch 0019, iter [00300, 05004], lr: 0.100000, loss: 3.2961
2022-07-15 08:49:33 - train: epoch 0019, iter [00400, 05004], lr: 0.100000, loss: 2.7816
2022-07-15 08:50:06 - train: epoch 0019, iter [00500, 05004], lr: 0.100000, loss: 2.8708
2022-07-15 08:50:39 - train: epoch 0019, iter [00600, 05004], lr: 0.100000, loss: 2.9720
2022-07-15 08:51:12 - train: epoch 0019, iter [00700, 05004], lr: 0.100000, loss: 2.7876
2022-07-15 08:51:46 - train: epoch 0019, iter [00800, 05004], lr: 0.100000, loss: 3.3228
2022-07-15 08:52:18 - train: epoch 0019, iter [00900, 05004], lr: 0.100000, loss: 2.9299
2022-07-15 08:52:52 - train: epoch 0019, iter [01000, 05004], lr: 0.100000, loss: 3.1562
2022-07-15 08:53:25 - train: epoch 0019, iter [01100, 05004], lr: 0.100000, loss: 2.7968
2022-07-15 08:53:59 - train: epoch 0019, iter [01200, 05004], lr: 0.100000, loss: 3.1016
2022-07-15 08:54:31 - train: epoch 0019, iter [01300, 05004], lr: 0.100000, loss: 3.0334
2022-07-15 08:55:05 - train: epoch 0019, iter [01400, 05004], lr: 0.100000, loss: 3.0676
2022-07-15 08:55:37 - train: epoch 0019, iter [01500, 05004], lr: 0.100000, loss: 3.3833
2022-07-15 08:56:11 - train: epoch 0019, iter [01600, 05004], lr: 0.100000, loss: 2.7880
2022-07-15 08:56:44 - train: epoch 0019, iter [01700, 05004], lr: 0.100000, loss: 3.1627
2022-07-15 08:57:17 - train: epoch 0019, iter [01800, 05004], lr: 0.100000, loss: 2.8945
2022-07-15 08:57:50 - train: epoch 0019, iter [01900, 05004], lr: 0.100000, loss: 3.2608
2022-07-15 08:58:24 - train: epoch 0019, iter [02000, 05004], lr: 0.100000, loss: 3.0659
2022-07-15 08:58:57 - train: epoch 0019, iter [02100, 05004], lr: 0.100000, loss: 3.0164
2022-07-15 08:59:30 - train: epoch 0019, iter [02200, 05004], lr: 0.100000, loss: 2.9644
2022-07-15 09:00:03 - train: epoch 0019, iter [02300, 05004], lr: 0.100000, loss: 2.9843
2022-07-15 09:00:37 - train: epoch 0019, iter [02400, 05004], lr: 0.100000, loss: 3.1745
2022-07-15 09:01:10 - train: epoch 0019, iter [02500, 05004], lr: 0.100000, loss: 3.0108
2022-07-15 09:01:43 - train: epoch 0019, iter [02600, 05004], lr: 0.100000, loss: 3.1156
2022-07-15 09:02:15 - train: epoch 0019, iter [02700, 05004], lr: 0.100000, loss: 3.1198
2022-07-15 09:02:50 - train: epoch 0019, iter [02800, 05004], lr: 0.100000, loss: 3.0451
2022-07-15 09:03:22 - train: epoch 0019, iter [02900, 05004], lr: 0.100000, loss: 3.0553
2022-07-15 09:03:56 - train: epoch 0019, iter [03000, 05004], lr: 0.100000, loss: 3.2389
2022-07-15 09:04:29 - train: epoch 0019, iter [03100, 05004], lr: 0.100000, loss: 3.1167
2022-07-15 09:05:02 - train: epoch 0019, iter [03200, 05004], lr: 0.100000, loss: 2.7125
2022-07-15 09:05:36 - train: epoch 0019, iter [03300, 05004], lr: 0.100000, loss: 2.9495
2022-07-15 09:06:09 - train: epoch 0019, iter [03400, 05004], lr: 0.100000, loss: 3.1585
2022-07-15 09:06:42 - train: epoch 0019, iter [03500, 05004], lr: 0.100000, loss: 3.0210
2022-07-15 09:07:16 - train: epoch 0019, iter [03600, 05004], lr: 0.100000, loss: 2.9166
2022-07-15 09:07:48 - train: epoch 0019, iter [03700, 05004], lr: 0.100000, loss: 3.1223
2022-07-15 09:08:22 - train: epoch 0019, iter [03800, 05004], lr: 0.100000, loss: 3.1754
2022-07-15 09:08:55 - train: epoch 0019, iter [03900, 05004], lr: 0.100000, loss: 2.9040
2022-07-15 09:09:30 - train: epoch 0019, iter [04000, 05004], lr: 0.100000, loss: 2.7428
2022-07-15 09:10:02 - train: epoch 0019, iter [04100, 05004], lr: 0.100000, loss: 3.0694
2022-07-15 09:10:36 - train: epoch 0019, iter [04200, 05004], lr: 0.100000, loss: 2.8970
2022-07-15 09:11:08 - train: epoch 0019, iter [04300, 05004], lr: 0.100000, loss: 3.0576
2022-07-15 09:11:43 - train: epoch 0019, iter [04400, 05004], lr: 0.100000, loss: 3.1362
2022-07-15 09:12:15 - train: epoch 0019, iter [04500, 05004], lr: 0.100000, loss: 3.3199
2022-07-15 09:12:49 - train: epoch 0019, iter [04600, 05004], lr: 0.100000, loss: 2.9136
2022-07-15 09:13:22 - train: epoch 0019, iter [04700, 05004], lr: 0.100000, loss: 3.0368
2022-07-15 09:13:56 - train: epoch 0019, iter [04800, 05004], lr: 0.100000, loss: 2.9963
2022-07-15 09:14:29 - train: epoch 0019, iter [04900, 05004], lr: 0.100000, loss: 2.8311
2022-07-15 09:15:01 - train: epoch 0019, iter [05000, 05004], lr: 0.100000, loss: 2.9244
2022-07-15 09:15:02 - train: epoch 019, train_loss: 3.0035
2022-07-15 09:16:17 - eval: epoch: 019, acc1: 42.004%, acc5: 67.004%, test_loss: 2.6974, per_image_load_time: 1.860ms, per_image_inference_time: 0.118ms
2022-07-15 09:16:17 - until epoch: 019, best_acc1: 42.416%
2022-07-15 09:16:17 - epoch 020 lr: 0.100000
2022-07-15 09:16:55 - train: epoch 0020, iter [00100, 05004], lr: 0.100000, loss: 3.2912
2022-07-15 09:17:29 - train: epoch 0020, iter [00200, 05004], lr: 0.100000, loss: 2.8687
2022-07-15 09:18:02 - train: epoch 0020, iter [00300, 05004], lr: 0.100000, loss: 3.1104
2022-07-15 09:18:36 - train: epoch 0020, iter [00400, 05004], lr: 0.100000, loss: 2.8488
2022-07-15 09:19:10 - train: epoch 0020, iter [00500, 05004], lr: 0.100000, loss: 2.9711
2022-07-15 09:19:42 - train: epoch 0020, iter [00600, 05004], lr: 0.100000, loss: 3.1876
2022-07-15 09:20:16 - train: epoch 0020, iter [00700, 05004], lr: 0.100000, loss: 2.8799
2022-07-15 09:20:49 - train: epoch 0020, iter [00800, 05004], lr: 0.100000, loss: 3.0642
2022-07-15 09:21:23 - train: epoch 0020, iter [00900, 05004], lr: 0.100000, loss: 3.0829
2022-07-15 09:21:57 - train: epoch 0020, iter [01000, 05004], lr: 0.100000, loss: 2.9990
2022-07-15 09:22:29 - train: epoch 0020, iter [01100, 05004], lr: 0.100000, loss: 2.7907
2022-07-15 09:23:02 - train: epoch 0020, iter [01200, 05004], lr: 0.100000, loss: 2.7622
2022-07-15 09:23:35 - train: epoch 0020, iter [01300, 05004], lr: 0.100000, loss: 2.8717
2022-07-15 09:24:09 - train: epoch 0020, iter [01400, 05004], lr: 0.100000, loss: 3.1079
2022-07-15 09:24:42 - train: epoch 0020, iter [01500, 05004], lr: 0.100000, loss: 2.9098
2022-07-15 09:25:15 - train: epoch 0020, iter [01600, 05004], lr: 0.100000, loss: 2.7942
2022-07-15 09:25:48 - train: epoch 0020, iter [01700, 05004], lr: 0.100000, loss: 2.6445
2022-07-15 09:26:22 - train: epoch 0020, iter [01800, 05004], lr: 0.100000, loss: 3.1092
2022-07-15 09:26:55 - train: epoch 0020, iter [01900, 05004], lr: 0.100000, loss: 2.9682
2022-07-15 09:27:28 - train: epoch 0020, iter [02000, 05004], lr: 0.100000, loss: 3.0773
2022-07-15 09:28:01 - train: epoch 0020, iter [02100, 05004], lr: 0.100000, loss: 3.1576
2022-07-15 09:28:34 - train: epoch 0020, iter [02200, 05004], lr: 0.100000, loss: 2.8195
2022-07-15 09:29:07 - train: epoch 0020, iter [02300, 05004], lr: 0.100000, loss: 2.9055
2022-07-15 09:29:41 - train: epoch 0020, iter [02400, 05004], lr: 0.100000, loss: 3.0269
2022-07-15 09:30:13 - train: epoch 0020, iter [02500, 05004], lr: 0.100000, loss: 2.8284
2022-07-15 09:30:48 - train: epoch 0020, iter [02600, 05004], lr: 0.100000, loss: 2.7640
2022-07-15 09:31:20 - train: epoch 0020, iter [02700, 05004], lr: 0.100000, loss: 3.0557
2022-07-15 09:31:54 - train: epoch 0020, iter [02800, 05004], lr: 0.100000, loss: 3.0862
2022-07-15 09:32:27 - train: epoch 0020, iter [02900, 05004], lr: 0.100000, loss: 3.0850
2022-07-15 09:33:01 - train: epoch 0020, iter [03000, 05004], lr: 0.100000, loss: 3.0941
2022-07-15 09:33:34 - train: epoch 0020, iter [03100, 05004], lr: 0.100000, loss: 3.0044
2022-07-15 09:34:08 - train: epoch 0020, iter [03200, 05004], lr: 0.100000, loss: 3.1733
2022-07-15 09:34:40 - train: epoch 0020, iter [03300, 05004], lr: 0.100000, loss: 2.8330
2022-07-15 09:35:13 - train: epoch 0020, iter [03400, 05004], lr: 0.100000, loss: 2.9477
2022-07-15 09:35:48 - train: epoch 0020, iter [03500, 05004], lr: 0.100000, loss: 2.8835
2022-07-15 09:36:20 - train: epoch 0020, iter [03600, 05004], lr: 0.100000, loss: 3.0100
2022-07-15 09:36:54 - train: epoch 0020, iter [03700, 05004], lr: 0.100000, loss: 2.9004
2022-07-15 09:37:27 - train: epoch 0020, iter [03800, 05004], lr: 0.100000, loss: 2.9248
2022-07-15 09:38:01 - train: epoch 0020, iter [03900, 05004], lr: 0.100000, loss: 3.1096
2022-07-15 09:38:34 - train: epoch 0020, iter [04000, 05004], lr: 0.100000, loss: 2.9877
2022-07-15 09:39:07 - train: epoch 0020, iter [04100, 05004], lr: 0.100000, loss: 2.8751
2022-07-15 09:39:41 - train: epoch 0020, iter [04200, 05004], lr: 0.100000, loss: 2.8086
2022-07-15 09:40:14 - train: epoch 0020, iter [04300, 05004], lr: 0.100000, loss: 3.0882
2022-07-15 09:40:48 - train: epoch 0020, iter [04400, 05004], lr: 0.100000, loss: 2.9565
2022-07-15 09:41:22 - train: epoch 0020, iter [04500, 05004], lr: 0.100000, loss: 2.9997
2022-07-15 09:41:55 - train: epoch 0020, iter [04600, 05004], lr: 0.100000, loss: 3.1111
2022-07-15 09:42:28 - train: epoch 0020, iter [04700, 05004], lr: 0.100000, loss: 2.7571
2022-07-15 09:43:02 - train: epoch 0020, iter [04800, 05004], lr: 0.100000, loss: 3.0402
2022-07-15 09:43:34 - train: epoch 0020, iter [04900, 05004], lr: 0.100000, loss: 3.1372
2022-07-15 09:44:07 - train: epoch 0020, iter [05000, 05004], lr: 0.100000, loss: 2.7784
2022-07-15 09:44:07 - train: epoch 020, train_loss: 2.9938
2022-07-15 09:45:22 - eval: epoch: 020, acc1: 42.030%, acc5: 67.174%, test_loss: 2.6944, per_image_load_time: 1.479ms, per_image_inference_time: 0.137ms
2022-07-15 09:45:22 - until epoch: 020, best_acc1: 42.416%
2022-07-15 09:45:22 - epoch 021 lr: 0.100000
2022-07-15 09:46:01 - train: epoch 0021, iter [00100, 05004], lr: 0.100000, loss: 2.8793
2022-07-15 09:46:35 - train: epoch 0021, iter [00200, 05004], lr: 0.100000, loss: 3.0373
2022-07-15 09:47:09 - train: epoch 0021, iter [00300, 05004], lr: 0.100000, loss: 2.5959
2022-07-15 09:47:41 - train: epoch 0021, iter [00400, 05004], lr: 0.100000, loss: 2.9594
2022-07-15 09:48:14 - train: epoch 0021, iter [00500, 05004], lr: 0.100000, loss: 2.8141
2022-07-15 09:48:48 - train: epoch 0021, iter [00600, 05004], lr: 0.100000, loss: 2.8112
2022-07-15 09:49:22 - train: epoch 0021, iter [00700, 05004], lr: 0.100000, loss: 2.8262
2022-07-15 09:49:54 - train: epoch 0021, iter [00800, 05004], lr: 0.100000, loss: 3.1649
2022-07-15 09:50:28 - train: epoch 0021, iter [00900, 05004], lr: 0.100000, loss: 3.0214
2022-07-15 09:51:00 - train: epoch 0021, iter [01000, 05004], lr: 0.100000, loss: 2.8425
2022-07-15 09:51:34 - train: epoch 0021, iter [01100, 05004], lr: 0.100000, loss: 3.0253
2022-07-15 09:52:06 - train: epoch 0021, iter [01200, 05004], lr: 0.100000, loss: 2.8635
2022-07-15 09:52:40 - train: epoch 0021, iter [01300, 05004], lr: 0.100000, loss: 2.9705
2022-07-15 09:53:14 - train: epoch 0021, iter [01400, 05004], lr: 0.100000, loss: 2.9655
2022-07-15 09:53:47 - train: epoch 0021, iter [01500, 05004], lr: 0.100000, loss: 2.8274
2022-07-15 09:54:21 - train: epoch 0021, iter [01600, 05004], lr: 0.100000, loss: 2.9719
2022-07-15 09:54:53 - train: epoch 0021, iter [01700, 05004], lr: 0.100000, loss: 3.0255
2022-07-15 09:55:25 - train: epoch 0021, iter [01800, 05004], lr: 0.100000, loss: 2.9514
2022-07-15 09:56:00 - train: epoch 0021, iter [01900, 05004], lr: 0.100000, loss: 3.1568
2022-07-15 09:56:32 - train: epoch 0021, iter [02000, 05004], lr: 0.100000, loss: 3.1264
2022-07-15 09:57:06 - train: epoch 0021, iter [02100, 05004], lr: 0.100000, loss: 2.7433
2022-07-15 09:57:39 - train: epoch 0021, iter [02200, 05004], lr: 0.100000, loss: 3.1757
2022-07-15 09:58:13 - train: epoch 0021, iter [02300, 05004], lr: 0.100000, loss: 2.7651
2022-07-15 09:58:45 - train: epoch 0021, iter [02400, 05004], lr: 0.100000, loss: 2.9320
2022-07-15 09:59:20 - train: epoch 0021, iter [02500, 05004], lr: 0.100000, loss: 2.9181
2022-07-15 09:59:52 - train: epoch 0021, iter [02600, 05004], lr: 0.100000, loss: 3.1180
2022-07-15 10:00:27 - train: epoch 0021, iter [02700, 05004], lr: 0.100000, loss: 2.8014
2022-07-15 10:00:59 - train: epoch 0021, iter [02800, 05004], lr: 0.100000, loss: 2.9921
2022-07-15 10:01:33 - train: epoch 0021, iter [02900, 05004], lr: 0.100000, loss: 2.9298
2022-07-15 10:02:06 - train: epoch 0021, iter [03000, 05004], lr: 0.100000, loss: 3.1361
2022-07-15 10:02:40 - train: epoch 0021, iter [03100, 05004], lr: 0.100000, loss: 3.1057
2022-07-15 10:03:12 - train: epoch 0021, iter [03200, 05004], lr: 0.100000, loss: 3.0641
2022-07-15 10:03:46 - train: epoch 0021, iter [03300, 05004], lr: 0.100000, loss: 3.3146
2022-07-15 10:04:18 - train: epoch 0021, iter [03400, 05004], lr: 0.100000, loss: 3.0871
2022-07-15 10:04:51 - train: epoch 0021, iter [03500, 05004], lr: 0.100000, loss: 2.9074
2022-07-15 10:05:25 - train: epoch 0021, iter [03600, 05004], lr: 0.100000, loss: 2.8765
2022-07-15 10:05:58 - train: epoch 0021, iter [03700, 05004], lr: 0.100000, loss: 3.0844
2022-07-15 10:06:32 - train: epoch 0021, iter [03800, 05004], lr: 0.100000, loss: 2.8536
2022-07-15 10:07:06 - train: epoch 0021, iter [03900, 05004], lr: 0.100000, loss: 2.8777
2022-07-15 10:07:39 - train: epoch 0021, iter [04000, 05004], lr: 0.100000, loss: 3.2101
2022-07-15 10:08:13 - train: epoch 0021, iter [04100, 05004], lr: 0.100000, loss: 2.9054
2022-07-15 10:08:45 - train: epoch 0021, iter [04200, 05004], lr: 0.100000, loss: 2.9859
2022-07-15 10:09:19 - train: epoch 0021, iter [04300, 05004], lr: 0.100000, loss: 3.0214
2022-07-15 10:09:53 - train: epoch 0021, iter [04400, 05004], lr: 0.100000, loss: 3.0488
2022-07-15 10:10:27 - train: epoch 0021, iter [04500, 05004], lr: 0.100000, loss: 3.0261
2022-07-15 10:10:59 - train: epoch 0021, iter [04600, 05004], lr: 0.100000, loss: 2.9963
2022-07-15 10:11:33 - train: epoch 0021, iter [04700, 05004], lr: 0.100000, loss: 3.1058
2022-07-15 10:12:06 - train: epoch 0021, iter [04800, 05004], lr: 0.100000, loss: 3.1514
2022-07-15 10:12:41 - train: epoch 0021, iter [04900, 05004], lr: 0.100000, loss: 2.8731
2022-07-15 10:13:12 - train: epoch 0021, iter [05000, 05004], lr: 0.100000, loss: 3.0201
2022-07-15 10:13:13 - train: epoch 021, train_loss: 2.9906
2022-07-15 10:14:27 - eval: epoch: 021, acc1: 42.554%, acc5: 67.786%, test_loss: 2.6589, per_image_load_time: 2.294ms, per_image_inference_time: 0.135ms
2022-07-15 10:14:27 - until epoch: 021, best_acc1: 42.554%
2022-07-15 10:14:27 - epoch 022 lr: 0.100000
2022-07-15 10:15:06 - train: epoch 0022, iter [00100, 05004], lr: 0.100000, loss: 2.6821
2022-07-15 10:15:39 - train: epoch 0022, iter [00200, 05004], lr: 0.100000, loss: 2.9353
2022-07-15 10:16:13 - train: epoch 0022, iter [00300, 05004], lr: 0.100000, loss: 2.6651
2022-07-15 10:16:46 - train: epoch 0022, iter [00400, 05004], lr: 0.100000, loss: 2.8497
2022-07-15 10:17:19 - train: epoch 0022, iter [00500, 05004], lr: 0.100000, loss: 2.9821
2022-07-15 10:17:54 - train: epoch 0022, iter [00600, 05004], lr: 0.100000, loss: 3.0273
2022-07-15 10:18:26 - train: epoch 0022, iter [00700, 05004], lr: 0.100000, loss: 3.1208
2022-07-15 10:18:58 - train: epoch 0022, iter [00800, 05004], lr: 0.100000, loss: 3.1024
2022-07-15 10:19:32 - train: epoch 0022, iter [00900, 05004], lr: 0.100000, loss: 3.0922
2022-07-15 10:20:05 - train: epoch 0022, iter [01000, 05004], lr: 0.100000, loss: 2.9121
2022-07-15 10:20:38 - train: epoch 0022, iter [01100, 05004], lr: 0.100000, loss: 2.9529
2022-07-15 10:21:12 - train: epoch 0022, iter [01200, 05004], lr: 0.100000, loss: 2.5690
2022-07-15 10:21:45 - train: epoch 0022, iter [01300, 05004], lr: 0.100000, loss: 2.9414
2022-07-15 10:22:18 - train: epoch 0022, iter [01400, 05004], lr: 0.100000, loss: 3.1969
2022-07-15 10:22:52 - train: epoch 0022, iter [01500, 05004], lr: 0.100000, loss: 3.0046
2022-07-15 10:23:24 - train: epoch 0022, iter [01600, 05004], lr: 0.100000, loss: 2.9206
2022-07-15 10:23:58 - train: epoch 0022, iter [01700, 05004], lr: 0.100000, loss: 2.6328
2022-07-15 10:24:31 - train: epoch 0022, iter [01800, 05004], lr: 0.100000, loss: 3.2615
2022-07-15 10:25:04 - train: epoch 0022, iter [01900, 05004], lr: 0.100000, loss: 2.8489
2022-07-15 10:25:38 - train: epoch 0022, iter [02000, 05004], lr: 0.100000, loss: 3.0721
2022-07-15 10:26:11 - train: epoch 0022, iter [02100, 05004], lr: 0.100000, loss: 3.0496
2022-07-15 10:26:44 - train: epoch 0022, iter [02200, 05004], lr: 0.100000, loss: 2.6735
2022-07-15 10:27:18 - train: epoch 0022, iter [02300, 05004], lr: 0.100000, loss: 3.1413
2022-07-15 10:27:51 - train: epoch 0022, iter [02400, 05004], lr: 0.100000, loss: 2.9062
2022-07-15 10:28:25 - train: epoch 0022, iter [02500, 05004], lr: 0.100000, loss: 2.8612
2022-07-15 10:28:58 - train: epoch 0022, iter [02600, 05004], lr: 0.100000, loss: 2.8390
2022-07-15 10:29:32 - train: epoch 0022, iter [02700, 05004], lr: 0.100000, loss: 2.7879
2022-07-15 10:30:05 - train: epoch 0022, iter [02800, 05004], lr: 0.100000, loss: 3.2730
2022-07-15 10:30:38 - train: epoch 0022, iter [02900, 05004], lr: 0.100000, loss: 2.7608
2022-07-15 10:31:12 - train: epoch 0022, iter [03000, 05004], lr: 0.100000, loss: 3.0471
2022-07-15 10:31:45 - train: epoch 0022, iter [03100, 05004], lr: 0.100000, loss: 3.1685
2022-07-15 10:32:19 - train: epoch 0022, iter [03200, 05004], lr: 0.100000, loss: 3.0766
2022-07-15 10:32:52 - train: epoch 0022, iter [03300, 05004], lr: 0.100000, loss: 3.0165
2022-07-15 10:33:25 - train: epoch 0022, iter [03400, 05004], lr: 0.100000, loss: 2.8919
2022-07-15 10:33:59 - train: epoch 0022, iter [03500, 05004], lr: 0.100000, loss: 3.1098
2022-07-15 10:34:32 - train: epoch 0022, iter [03600, 05004], lr: 0.100000, loss: 3.0259
2022-07-15 10:35:06 - train: epoch 0022, iter [03700, 05004], lr: 0.100000, loss: 3.0487
2022-07-15 10:35:38 - train: epoch 0022, iter [03800, 05004], lr: 0.100000, loss: 3.2491
2022-07-15 10:36:11 - train: epoch 0022, iter [03900, 05004], lr: 0.100000, loss: 2.9660
2022-07-15 10:36:46 - train: epoch 0022, iter [04000, 05004], lr: 0.100000, loss: 2.9734
2022-07-15 10:37:18 - train: epoch 0022, iter [04100, 05004], lr: 0.100000, loss: 2.8169
2022-07-15 10:37:52 - train: epoch 0022, iter [04200, 05004], lr: 0.100000, loss: 3.0107
2022-07-15 10:38:25 - train: epoch 0022, iter [04300, 05004], lr: 0.100000, loss: 3.1684
2022-07-15 10:38:59 - train: epoch 0022, iter [04400, 05004], lr: 0.100000, loss: 2.9552
2022-07-15 10:39:33 - train: epoch 0022, iter [04500, 05004], lr: 0.100000, loss: 2.9266
2022-07-15 10:40:05 - train: epoch 0022, iter [04600, 05004], lr: 0.100000, loss: 3.1667
2022-07-15 10:40:39 - train: epoch 0022, iter [04700, 05004], lr: 0.100000, loss: 3.2213
2022-07-15 10:41:12 - train: epoch 0022, iter [04800, 05004], lr: 0.100000, loss: 2.7439
2022-07-15 10:41:45 - train: epoch 0022, iter [04900, 05004], lr: 0.100000, loss: 2.9726
2022-07-15 10:42:17 - train: epoch 0022, iter [05000, 05004], lr: 0.100000, loss: 2.9077
2022-07-15 10:42:17 - train: epoch 022, train_loss: 2.9867
2022-07-15 10:43:32 - eval: epoch: 022, acc1: 42.374%, acc5: 67.656%, test_loss: 2.6729, per_image_load_time: 2.538ms, per_image_inference_time: 0.136ms
2022-07-15 10:43:32 - until epoch: 022, best_acc1: 42.554%
2022-07-15 10:43:32 - epoch 023 lr: 0.100000
2022-07-15 10:44:10 - train: epoch 0023, iter [00100, 05004], lr: 0.100000, loss: 2.8376
2022-07-15 10:44:44 - train: epoch 0023, iter [00200, 05004], lr: 0.100000, loss: 2.6831
2022-07-15 10:45:18 - train: epoch 0023, iter [00300, 05004], lr: 0.100000, loss: 2.8051
2022-07-15 10:45:50 - train: epoch 0023, iter [00400, 05004], lr: 0.100000, loss: 3.0927
2022-07-15 10:46:24 - train: epoch 0023, iter [00500, 05004], lr: 0.100000, loss: 3.0063
2022-07-15 10:46:57 - train: epoch 0023, iter [00600, 05004], lr: 0.100000, loss: 2.8708
2022-07-15 10:47:31 - train: epoch 0023, iter [00700, 05004], lr: 0.100000, loss: 2.8317
2022-07-15 10:48:04 - train: epoch 0023, iter [00800, 05004], lr: 0.100000, loss: 2.9787
2022-07-15 10:48:37 - train: epoch 0023, iter [00900, 05004], lr: 0.100000, loss: 3.0323
2022-07-15 10:49:11 - train: epoch 0023, iter [01000, 05004], lr: 0.100000, loss: 2.8249
2022-07-15 10:49:44 - train: epoch 0023, iter [01100, 05004], lr: 0.100000, loss: 3.0311
2022-07-15 10:50:17 - train: epoch 0023, iter [01200, 05004], lr: 0.100000, loss: 2.5775
2022-07-15 10:50:50 - train: epoch 0023, iter [01300, 05004], lr: 0.100000, loss: 2.7994
2022-07-15 10:51:24 - train: epoch 0023, iter [01400, 05004], lr: 0.100000, loss: 2.9143
2022-07-15 10:51:56 - train: epoch 0023, iter [01500, 05004], lr: 0.100000, loss: 2.7208
2022-07-15 10:52:30 - train: epoch 0023, iter [01600, 05004], lr: 0.100000, loss: 2.9514
2022-07-15 10:53:02 - train: epoch 0023, iter [01700, 05004], lr: 0.100000, loss: 3.1848
2022-07-15 10:53:37 - train: epoch 0023, iter [01800, 05004], lr: 0.100000, loss: 2.9497
2022-07-15 10:54:09 - train: epoch 0023, iter [01900, 05004], lr: 0.100000, loss: 3.0770
2022-07-15 10:54:44 - train: epoch 0023, iter [02000, 05004], lr: 0.100000, loss: 2.6464
2022-07-15 10:55:16 - train: epoch 0023, iter [02100, 05004], lr: 0.100000, loss: 3.0948
2022-07-15 10:55:50 - train: epoch 0023, iter [02200, 05004], lr: 0.100000, loss: 2.6697
2022-07-15 10:56:24 - train: epoch 0023, iter [02300, 05004], lr: 0.100000, loss: 2.7942
2022-07-15 10:56:57 - train: epoch 0023, iter [02400, 05004], lr: 0.100000, loss: 3.0264
2022-07-15 10:57:30 - train: epoch 0023, iter [02500, 05004], lr: 0.100000, loss: 2.9985
2022-07-15 10:58:03 - train: epoch 0023, iter [02600, 05004], lr: 0.100000, loss: 2.9715
2022-07-15 10:58:37 - train: epoch 0023, iter [02700, 05004], lr: 0.100000, loss: 2.8539
2022-07-15 10:59:10 - train: epoch 0023, iter [02800, 05004], lr: 0.100000, loss: 2.9655
2022-07-15 10:59:43 - train: epoch 0023, iter [02900, 05004], lr: 0.100000, loss: 3.0432
2022-07-15 11:00:18 - train: epoch 0023, iter [03000, 05004], lr: 0.100000, loss: 3.1481
2022-07-15 11:00:51 - train: epoch 0023, iter [03100, 05004], lr: 0.100000, loss: 2.9690
2022-07-15 11:01:25 - train: epoch 0023, iter [03200, 05004], lr: 0.100000, loss: 3.0606
2022-07-15 11:01:57 - train: epoch 0023, iter [03300, 05004], lr: 0.100000, loss: 3.1416
2022-07-15 11:02:31 - train: epoch 0023, iter [03400, 05004], lr: 0.100000, loss: 3.1445
2022-07-15 11:03:03 - train: epoch 0023, iter [03500, 05004], lr: 0.100000, loss: 2.8292
2022-07-15 11:03:37 - train: epoch 0023, iter [03600, 05004], lr: 0.100000, loss: 2.7625
2022-07-15 11:04:10 - train: epoch 0023, iter [03700, 05004], lr: 0.100000, loss: 3.0326
2022-07-15 11:04:44 - train: epoch 0023, iter [03800, 05004], lr: 0.100000, loss: 3.0506
2022-07-15 11:05:17 - train: epoch 0023, iter [03900, 05004], lr: 0.100000, loss: 3.0082
2022-07-15 11:05:51 - train: epoch 0023, iter [04000, 05004], lr: 0.100000, loss: 2.9849
2022-07-15 11:06:24 - train: epoch 0023, iter [04100, 05004], lr: 0.100000, loss: 2.8331
2022-07-15 11:06:57 - train: epoch 0023, iter [04200, 05004], lr: 0.100000, loss: 2.7870
2022-07-15 11:07:29 - train: epoch 0023, iter [04300, 05004], lr: 0.100000, loss: 2.6857
2022-07-15 11:08:03 - train: epoch 0023, iter [04400, 05004], lr: 0.100000, loss: 2.9091
2022-07-15 11:08:36 - train: epoch 0023, iter [04500, 05004], lr: 0.100000, loss: 2.8934
2022-07-15 11:09:10 - train: epoch 0023, iter [04600, 05004], lr: 0.100000, loss: 3.0548
2022-07-15 11:09:42 - train: epoch 0023, iter [04700, 05004], lr: 0.100000, loss: 2.8697
2022-07-15 11:10:16 - train: epoch 0023, iter [04800, 05004], lr: 0.100000, loss: 2.9198
2022-07-15 11:10:49 - train: epoch 0023, iter [04900, 05004], lr: 0.100000, loss: 2.8680
2022-07-15 11:11:21 - train: epoch 0023, iter [05000, 05004], lr: 0.100000, loss: 3.0085
2022-07-15 11:11:21 - train: epoch 023, train_loss: 2.9834
2022-07-15 11:12:35 - eval: epoch: 023, acc1: 40.766%, acc5: 66.120%, test_loss: 2.7821, per_image_load_time: 1.525ms, per_image_inference_time: 0.149ms
2022-07-15 11:12:35 - until epoch: 023, best_acc1: 42.554%
2022-07-15 11:12:35 - epoch 024 lr: 0.100000
2022-07-15 11:13:14 - train: epoch 0024, iter [00100, 05004], lr: 0.100000, loss: 2.8664
2022-07-15 11:13:48 - train: epoch 0024, iter [00200, 05004], lr: 0.100000, loss: 3.0388
2022-07-15 11:14:21 - train: epoch 0024, iter [00300, 05004], lr: 0.100000, loss: 2.9229
2022-07-15 11:14:54 - train: epoch 0024, iter [00400, 05004], lr: 0.100000, loss: 2.9983
2022-07-15 11:15:26 - train: epoch 0024, iter [00500, 05004], lr: 0.100000, loss: 2.9859
2022-07-15 11:16:00 - train: epoch 0024, iter [00600, 05004], lr: 0.100000, loss: 2.6096
2022-07-15 11:16:33 - train: epoch 0024, iter [00700, 05004], lr: 0.100000, loss: 2.9857
2022-07-15 11:17:06 - train: epoch 0024, iter [00800, 05004], lr: 0.100000, loss: 2.9339
2022-07-15 11:17:39 - train: epoch 0024, iter [00900, 05004], lr: 0.100000, loss: 2.9467
2022-07-15 11:18:11 - train: epoch 0024, iter [01000, 05004], lr: 0.100000, loss: 2.9715
2022-07-15 11:18:45 - train: epoch 0024, iter [01100, 05004], lr: 0.100000, loss: 2.8163
2022-07-15 11:19:17 - train: epoch 0024, iter [01200, 05004], lr: 0.100000, loss: 2.8060
2022-07-15 11:19:50 - train: epoch 0024, iter [01300, 05004], lr: 0.100000, loss: 3.4430
2022-07-15 11:20:24 - train: epoch 0024, iter [01400, 05004], lr: 0.100000, loss: 2.9220
2022-07-15 11:20:56 - train: epoch 0024, iter [01500, 05004], lr: 0.100000, loss: 3.1994
2022-07-15 11:21:30 - train: epoch 0024, iter [01600, 05004], lr: 0.100000, loss: 2.9767
2022-07-15 11:22:03 - train: epoch 0024, iter [01700, 05004], lr: 0.100000, loss: 2.9038
2022-07-15 11:22:37 - train: epoch 0024, iter [01800, 05004], lr: 0.100000, loss: 3.1604
2022-07-15 11:23:09 - train: epoch 0024, iter [01900, 05004], lr: 0.100000, loss: 2.7165
2022-07-15 11:23:43 - train: epoch 0024, iter [02000, 05004], lr: 0.100000, loss: 3.0998
2022-07-15 11:24:16 - train: epoch 0024, iter [02100, 05004], lr: 0.100000, loss: 2.7287
2022-07-15 11:24:49 - train: epoch 0024, iter [02200, 05004], lr: 0.100000, loss: 2.8683
2022-07-15 11:25:23 - train: epoch 0024, iter [02300, 05004], lr: 0.100000, loss: 2.9742
2022-07-15 11:25:56 - train: epoch 0024, iter [02400, 05004], lr: 0.100000, loss: 2.9238
2022-07-15 11:26:30 - train: epoch 0024, iter [02500, 05004], lr: 0.100000, loss: 2.8848
2022-07-15 11:27:02 - train: epoch 0024, iter [02600, 05004], lr: 0.100000, loss: 2.7994
2022-07-15 11:27:36 - train: epoch 0024, iter [02700, 05004], lr: 0.100000, loss: 3.0433
2022-07-15 11:28:09 - train: epoch 0024, iter [02800, 05004], lr: 0.100000, loss: 3.1114
2022-07-15 11:28:42 - train: epoch 0024, iter [02900, 05004], lr: 0.100000, loss: 3.2208
2022-07-15 11:29:15 - train: epoch 0024, iter [03000, 05004], lr: 0.100000, loss: 2.9174
2022-07-15 11:29:49 - train: epoch 0024, iter [03100, 05004], lr: 0.100000, loss: 2.8769
2022-07-15 11:30:22 - train: epoch 0024, iter [03200, 05004], lr: 0.100000, loss: 3.2220
2022-07-15 11:30:56 - train: epoch 0024, iter [03300, 05004], lr: 0.100000, loss: 2.6673
2022-07-15 11:31:28 - train: epoch 0024, iter [03400, 05004], lr: 0.100000, loss: 3.2062
2022-07-15 11:32:02 - train: epoch 0024, iter [03500, 05004], lr: 0.100000, loss: 2.8346
2022-07-15 11:32:34 - train: epoch 0024, iter [03600, 05004], lr: 0.100000, loss: 3.0372
2022-07-15 11:33:09 - train: epoch 0024, iter [03700, 05004], lr: 0.100000, loss: 2.9726
2022-07-15 11:33:42 - train: epoch 0024, iter [03800, 05004], lr: 0.100000, loss: 3.0687
2022-07-15 11:34:15 - train: epoch 0024, iter [03900, 05004], lr: 0.100000, loss: 3.1286
2022-07-15 11:34:48 - train: epoch 0024, iter [04000, 05004], lr: 0.100000, loss: 2.8042
2022-07-15 11:35:22 - train: epoch 0024, iter [04100, 05004], lr: 0.100000, loss: 2.9164
2022-07-15 11:35:55 - train: epoch 0024, iter [04200, 05004], lr: 0.100000, loss: 3.0217
2022-07-15 11:36:29 - train: epoch 0024, iter [04300, 05004], lr: 0.100000, loss: 2.9841
2022-07-15 11:37:01 - train: epoch 0024, iter [04400, 05004], lr: 0.100000, loss: 3.0725
2022-07-15 11:37:36 - train: epoch 0024, iter [04500, 05004], lr: 0.100000, loss: 2.8304
2022-07-15 11:38:09 - train: epoch 0024, iter [04600, 05004], lr: 0.100000, loss: 3.0617
2022-07-15 11:38:45 - train: epoch 0024, iter [04700, 05004], lr: 0.100000, loss: 2.9955
2022-07-15 11:39:17 - train: epoch 0024, iter [04800, 05004], lr: 0.100000, loss: 2.9021
2022-07-15 11:39:51 - train: epoch 0024, iter [04900, 05004], lr: 0.100000, loss: 3.1164
2022-07-15 11:40:22 - train: epoch 0024, iter [05000, 05004], lr: 0.100000, loss: 3.2543
2022-07-15 11:40:23 - train: epoch 024, train_loss: 2.9788
2022-07-15 11:41:38 - eval: epoch: 024, acc1: 41.760%, acc5: 66.950%, test_loss: 2.7125, per_image_load_time: 1.175ms, per_image_inference_time: 0.124ms
2022-07-15 11:41:38 - until epoch: 024, best_acc1: 42.554%
2022-07-15 11:41:38 - epoch 025 lr: 0.100000
2022-07-15 11:42:17 - train: epoch 0025, iter [00100, 05004], lr: 0.100000, loss: 2.8575
2022-07-15 11:42:51 - train: epoch 0025, iter [00200, 05004], lr: 0.100000, loss: 2.6848
2022-07-15 11:43:24 - train: epoch 0025, iter [00300, 05004], lr: 0.100000, loss: 2.8049
2022-07-15 11:43:56 - train: epoch 0025, iter [00400, 05004], lr: 0.100000, loss: 2.9681
2022-07-15 11:44:30 - train: epoch 0025, iter [00500, 05004], lr: 0.100000, loss: 2.7946
2022-07-15 11:45:04 - train: epoch 0025, iter [00600, 05004], lr: 0.100000, loss: 2.9690
2022-07-15 11:45:36 - train: epoch 0025, iter [00700, 05004], lr: 0.100000, loss: 3.0222
2022-07-15 11:46:10 - train: epoch 0025, iter [00800, 05004], lr: 0.100000, loss: 3.0287
2022-07-15 11:46:43 - train: epoch 0025, iter [00900, 05004], lr: 0.100000, loss: 2.8899
2022-07-15 11:47:16 - train: epoch 0025, iter [01000, 05004], lr: 0.100000, loss: 2.9160
2022-07-15 11:47:49 - train: epoch 0025, iter [01100, 05004], lr: 0.100000, loss: 2.9142
2022-07-15 11:48:23 - train: epoch 0025, iter [01200, 05004], lr: 0.100000, loss: 2.9652
2022-07-15 11:48:55 - train: epoch 0025, iter [01300, 05004], lr: 0.100000, loss: 3.0423
2022-07-15 11:49:29 - train: epoch 0025, iter [01400, 05004], lr: 0.100000, loss: 2.9199
2022-07-15 11:50:02 - train: epoch 0025, iter [01500, 05004], lr: 0.100000, loss: 2.8535
2022-07-15 11:50:36 - train: epoch 0025, iter [01600, 05004], lr: 0.100000, loss: 2.7737
2022-07-15 11:51:08 - train: epoch 0025, iter [01700, 05004], lr: 0.100000, loss: 2.9479
2022-07-15 11:51:42 - train: epoch 0025, iter [01800, 05004], lr: 0.100000, loss: 2.7352
2022-07-15 11:52:14 - train: epoch 0025, iter [01900, 05004], lr: 0.100000, loss: 2.8198
2022-07-15 11:52:49 - train: epoch 0025, iter [02000, 05004], lr: 0.100000, loss: 2.9959
2022-07-15 11:53:22 - train: epoch 0025, iter [02100, 05004], lr: 0.100000, loss: 2.7687
2022-07-15 11:53:55 - train: epoch 0025, iter [02200, 05004], lr: 0.100000, loss: 2.8419
2022-07-15 11:54:28 - train: epoch 0025, iter [02300, 05004], lr: 0.100000, loss: 3.0075
2022-07-15 11:55:02 - train: epoch 0025, iter [02400, 05004], lr: 0.100000, loss: 2.6812
2022-07-15 11:55:36 - train: epoch 0025, iter [02500, 05004], lr: 0.100000, loss: 3.0783
2022-07-15 11:56:09 - train: epoch 0025, iter [02600, 05004], lr: 0.100000, loss: 2.9388
2022-07-15 11:56:43 - train: epoch 0025, iter [02700, 05004], lr: 0.100000, loss: 2.9985
2022-07-15 11:57:16 - train: epoch 0025, iter [02800, 05004], lr: 0.100000, loss: 2.8943
2022-07-15 11:57:50 - train: epoch 0025, iter [02900, 05004], lr: 0.100000, loss: 3.1653
2022-07-15 11:58:22 - train: epoch 0025, iter [03000, 05004], lr: 0.100000, loss: 3.1558
2022-07-15 11:58:56 - train: epoch 0025, iter [03100, 05004], lr: 0.100000, loss: 2.9661
2022-07-15 11:59:28 - train: epoch 0025, iter [03200, 05004], lr: 0.100000, loss: 3.1028
2022-07-15 12:00:02 - train: epoch 0025, iter [03300, 05004], lr: 0.100000, loss: 3.0466
2022-07-15 12:00:35 - train: epoch 0025, iter [03400, 05004], lr: 0.100000, loss: 3.1861
2022-07-15 12:01:08 - train: epoch 0025, iter [03500, 05004], lr: 0.100000, loss: 2.8175
2022-07-15 12:01:42 - train: epoch 0025, iter [03600, 05004], lr: 0.100000, loss: 3.0671
2022-07-15 12:02:16 - train: epoch 0025, iter [03700, 05004], lr: 0.100000, loss: 2.9276
2022-07-15 12:02:48 - train: epoch 0025, iter [03800, 05004], lr: 0.100000, loss: 2.8938
2022-07-15 12:03:22 - train: epoch 0025, iter [03900, 05004], lr: 0.100000, loss: 3.2151
2022-07-15 12:03:55 - train: epoch 0025, iter [04000, 05004], lr: 0.100000, loss: 2.9506
2022-07-15 12:04:29 - train: epoch 0025, iter [04100, 05004], lr: 0.100000, loss: 3.2477
2022-07-15 12:05:01 - train: epoch 0025, iter [04200, 05004], lr: 0.100000, loss: 3.0593
2022-07-15 12:05:35 - train: epoch 0025, iter [04300, 05004], lr: 0.100000, loss: 2.7031
2022-07-15 12:06:08 - train: epoch 0025, iter [04400, 05004], lr: 0.100000, loss: 2.8420
2022-07-15 12:06:42 - train: epoch 0025, iter [04500, 05004], lr: 0.100000, loss: 2.9493
2022-07-15 12:07:15 - train: epoch 0025, iter [04600, 05004], lr: 0.100000, loss: 2.9521
2022-07-15 12:07:48 - train: epoch 0025, iter [04700, 05004], lr: 0.100000, loss: 2.9340
2022-07-15 12:08:22 - train: epoch 0025, iter [04800, 05004], lr: 0.100000, loss: 2.7520
2022-07-15 12:08:55 - train: epoch 0025, iter [04900, 05004], lr: 0.100000, loss: 2.9233
2022-07-15 12:09:26 - train: epoch 0025, iter [05000, 05004], lr: 0.100000, loss: 3.0187
2022-07-15 12:09:27 - train: epoch 025, train_loss: 2.9766
2022-07-15 12:10:42 - eval: epoch: 025, acc1: 43.290%, acc5: 68.590%, test_loss: 2.6290, per_image_load_time: 2.497ms, per_image_inference_time: 0.141ms
2022-07-15 12:10:42 - until epoch: 025, best_acc1: 43.290%
2022-07-15 12:10:42 - epoch 026 lr: 0.100000
2022-07-15 12:11:20 - train: epoch 0026, iter [00100, 05004], lr: 0.100000, loss: 2.8364
2022-07-15 12:11:53 - train: epoch 0026, iter [00200, 05004], lr: 0.100000, loss: 2.7825
2022-07-15 12:12:26 - train: epoch 0026, iter [00300, 05004], lr: 0.100000, loss: 2.9787
2022-07-15 12:12:59 - train: epoch 0026, iter [00400, 05004], lr: 0.100000, loss: 2.8994
2022-07-15 12:13:33 - train: epoch 0026, iter [00500, 05004], lr: 0.100000, loss: 3.0655
2022-07-15 12:14:05 - train: epoch 0026, iter [00600, 05004], lr: 0.100000, loss: 3.1477
2022-07-15 12:14:38 - train: epoch 0026, iter [00700, 05004], lr: 0.100000, loss: 2.8602
2022-07-15 12:15:11 - train: epoch 0026, iter [00800, 05004], lr: 0.100000, loss: 2.7252
2022-07-15 12:15:45 - train: epoch 0026, iter [00900, 05004], lr: 0.100000, loss: 3.1343
2022-07-15 12:16:17 - train: epoch 0026, iter [01000, 05004], lr: 0.100000, loss: 2.9266
2022-07-15 12:16:51 - train: epoch 0026, iter [01100, 05004], lr: 0.100000, loss: 2.9470
2022-07-15 12:17:24 - train: epoch 0026, iter [01200, 05004], lr: 0.100000, loss: 3.0763
2022-07-15 12:17:57 - train: epoch 0026, iter [01300, 05004], lr: 0.100000, loss: 2.8837
2022-07-15 12:18:30 - train: epoch 0026, iter [01400, 05004], lr: 0.100000, loss: 2.9947
2022-07-15 12:19:04 - train: epoch 0026, iter [01500, 05004], lr: 0.100000, loss: 2.9184
2022-07-15 12:19:36 - train: epoch 0026, iter [01600, 05004], lr: 0.100000, loss: 3.2239
2022-07-15 12:20:11 - train: epoch 0026, iter [01700, 05004], lr: 0.100000, loss: 2.8455
2022-07-15 12:20:43 - train: epoch 0026, iter [01800, 05004], lr: 0.100000, loss: 3.1428
2022-07-15 12:21:17 - train: epoch 0026, iter [01900, 05004], lr: 0.100000, loss: 3.2600
2022-07-15 12:21:50 - train: epoch 0026, iter [02000, 05004], lr: 0.100000, loss: 3.1735
2022-07-15 12:22:24 - train: epoch 0026, iter [02100, 05004], lr: 0.100000, loss: 3.0591
2022-07-15 12:22:57 - train: epoch 0026, iter [02200, 05004], lr: 0.100000, loss: 2.9231
2022-07-15 12:23:32 - train: epoch 0026, iter [02300, 05004], lr: 0.100000, loss: 2.8597
2022-07-15 12:24:04 - train: epoch 0026, iter [02400, 05004], lr: 0.100000, loss: 3.1735
2022-07-15 12:24:38 - train: epoch 0026, iter [02500, 05004], lr: 0.100000, loss: 3.1969
2022-07-15 12:25:11 - train: epoch 0026, iter [02600, 05004], lr: 0.100000, loss: 3.0055
2022-07-15 12:25:44 - train: epoch 0026, iter [02700, 05004], lr: 0.100000, loss: 2.9857
2022-07-15 12:26:17 - train: epoch 0026, iter [02800, 05004], lr: 0.100000, loss: 2.7507
2022-07-15 12:26:51 - train: epoch 0026, iter [02900, 05004], lr: 0.100000, loss: 3.0903
2022-07-15 12:27:23 - train: epoch 0026, iter [03000, 05004], lr: 0.100000, loss: 3.0223
2022-07-15 12:27:57 - train: epoch 0026, iter [03100, 05004], lr: 0.100000, loss: 2.9849
2022-07-15 12:28:30 - train: epoch 0026, iter [03200, 05004], lr: 0.100000, loss: 3.0199
2022-07-15 12:29:04 - train: epoch 0026, iter [03300, 05004], lr: 0.100000, loss: 2.7063
2022-07-15 12:29:36 - train: epoch 0026, iter [03400, 05004], lr: 0.100000, loss: 3.0346
2022-07-15 12:30:11 - train: epoch 0026, iter [03500, 05004], lr: 0.100000, loss: 2.8803
2022-07-15 12:30:43 - train: epoch 0026, iter [03600, 05004], lr: 0.100000, loss: 2.9959
2022-07-15 12:31:17 - train: epoch 0026, iter [03700, 05004], lr: 0.100000, loss: 3.1056
2022-07-15 12:31:50 - train: epoch 0026, iter [03800, 05004], lr: 0.100000, loss: 3.0647
2022-07-15 12:32:23 - train: epoch 0026, iter [03900, 05004], lr: 0.100000, loss: 3.0892
2022-07-15 12:32:56 - train: epoch 0026, iter [04000, 05004], lr: 0.100000, loss: 3.1223
2022-07-15 12:33:30 - train: epoch 0026, iter [04100, 05004], lr: 0.100000, loss: 3.0517
2022-07-15 12:34:03 - train: epoch 0026, iter [04200, 05004], lr: 0.100000, loss: 2.9510
2022-07-15 12:34:37 - train: epoch 0026, iter [04300, 05004], lr: 0.100000, loss: 3.0050
2022-07-15 12:35:10 - train: epoch 0026, iter [04400, 05004], lr: 0.100000, loss: 3.1937
2022-07-15 12:35:43 - train: epoch 0026, iter [04500, 05004], lr: 0.100000, loss: 3.2144
2022-07-15 12:36:16 - train: epoch 0026, iter [04600, 05004], lr: 0.100000, loss: 2.9475
2022-07-15 12:36:51 - train: epoch 0026, iter [04700, 05004], lr: 0.100000, loss: 2.8834
2022-07-15 12:37:24 - train: epoch 0026, iter [04800, 05004], lr: 0.100000, loss: 2.8023
2022-07-15 12:37:58 - train: epoch 0026, iter [04900, 05004], lr: 0.100000, loss: 3.0151
2022-07-15 12:38:29 - train: epoch 0026, iter [05000, 05004], lr: 0.100000, loss: 3.0441
2022-07-15 12:38:30 - train: epoch 026, train_loss: 2.9708
2022-07-15 12:39:44 - eval: epoch: 026, acc1: 42.392%, acc5: 67.370%, test_loss: 2.6815, per_image_load_time: 2.537ms, per_image_inference_time: 0.138ms
2022-07-15 12:39:44 - until epoch: 026, best_acc1: 43.290%
2022-07-15 12:39:44 - epoch 027 lr: 0.100000
2022-07-15 12:40:23 - train: epoch 0027, iter [00100, 05004], lr: 0.100000, loss: 3.0876
2022-07-15 12:40:56 - train: epoch 0027, iter [00200, 05004], lr: 0.100000, loss: 2.8508
2022-07-15 12:41:30 - train: epoch 0027, iter [00300, 05004], lr: 0.100000, loss: 3.0379
2022-07-15 12:42:04 - train: epoch 0027, iter [00400, 05004], lr: 0.100000, loss: 3.0762
2022-07-15 12:42:36 - train: epoch 0027, iter [00500, 05004], lr: 0.100000, loss: 3.0305
2022-07-15 12:43:09 - train: epoch 0027, iter [00600, 05004], lr: 0.100000, loss: 3.1561
2022-07-15 12:43:42 - train: epoch 0027, iter [00700, 05004], lr: 0.100000, loss: 3.1926
2022-07-15 12:44:16 - train: epoch 0027, iter [00800, 05004], lr: 0.100000, loss: 3.0426
2022-07-15 12:44:48 - train: epoch 0027, iter [00900, 05004], lr: 0.100000, loss: 2.9132
2022-07-15 12:45:21 - train: epoch 0027, iter [01000, 05004], lr: 0.100000, loss: 3.0968
2022-07-15 12:45:54 - train: epoch 0027, iter [01100, 05004], lr: 0.100000, loss: 2.7413
2022-07-15 12:46:28 - train: epoch 0027, iter [01200, 05004], lr: 0.100000, loss: 3.2536
2022-07-15 12:47:02 - train: epoch 0027, iter [01300, 05004], lr: 0.100000, loss: 3.0978
2022-07-15 12:47:33 - train: epoch 0027, iter [01400, 05004], lr: 0.100000, loss: 3.2364
2022-07-15 12:48:08 - train: epoch 0027, iter [01500, 05004], lr: 0.100000, loss: 3.0098
2022-07-15 12:48:40 - train: epoch 0027, iter [01600, 05004], lr: 0.100000, loss: 3.0945
2022-07-15 12:49:13 - train: epoch 0027, iter [01700, 05004], lr: 0.100000, loss: 2.9810
2022-07-15 12:49:47 - train: epoch 0027, iter [01800, 05004], lr: 0.100000, loss: 3.0370
2022-07-15 12:50:19 - train: epoch 0027, iter [01900, 05004], lr: 0.100000, loss: 3.0383
2022-07-15 12:50:54 - train: epoch 0027, iter [02000, 05004], lr: 0.100000, loss: 2.9913
2022-07-15 12:51:26 - train: epoch 0027, iter [02100, 05004], lr: 0.100000, loss: 3.1985
2022-07-15 12:52:00 - train: epoch 0027, iter [02200, 05004], lr: 0.100000, loss: 3.1425
2022-07-15 12:52:32 - train: epoch 0027, iter [02300, 05004], lr: 0.100000, loss: 3.4187
2022-07-15 12:53:07 - train: epoch 0027, iter [02400, 05004], lr: 0.100000, loss: 2.9103
2022-07-15 12:53:40 - train: epoch 0027, iter [02500, 05004], lr: 0.100000, loss: 2.9488
2022-07-15 12:54:14 - train: epoch 0027, iter [02600, 05004], lr: 0.100000, loss: 3.2643
2022-07-15 12:54:46 - train: epoch 0027, iter [02700, 05004], lr: 0.100000, loss: 2.8226
2022-07-15 12:55:20 - train: epoch 0027, iter [02800, 05004], lr: 0.100000, loss: 3.1073
2022-07-15 12:55:53 - train: epoch 0027, iter [02900, 05004], lr: 0.100000, loss: 2.9255
2022-07-15 12:56:26 - train: epoch 0027, iter [03000, 05004], lr: 0.100000, loss: 2.8303
2022-07-15 12:56:59 - train: epoch 0027, iter [03100, 05004], lr: 0.100000, loss: 2.8532
2022-07-15 12:57:34 - train: epoch 0027, iter [03200, 05004], lr: 0.100000, loss: 2.8825
2022-07-15 12:58:06 - train: epoch 0027, iter [03300, 05004], lr: 0.100000, loss: 2.9865
2022-07-15 12:58:40 - train: epoch 0027, iter [03400, 05004], lr: 0.100000, loss: 2.9105
2022-07-15 12:59:12 - train: epoch 0027, iter [03500, 05004], lr: 0.100000, loss: 3.1919
2022-07-15 12:59:46 - train: epoch 0027, iter [03600, 05004], lr: 0.100000, loss: 2.8728
2022-07-15 13:00:19 - train: epoch 0027, iter [03700, 05004], lr: 0.100000, loss: 2.9763
2022-07-15 13:00:52 - train: epoch 0027, iter [03800, 05004], lr: 0.100000, loss: 2.7525
2022-07-15 13:01:26 - train: epoch 0027, iter [03900, 05004], lr: 0.100000, loss: 2.8070
2022-07-15 13:01:59 - train: epoch 0027, iter [04000, 05004], lr: 0.100000, loss: 3.1100
2022-07-15 13:02:33 - train: epoch 0027, iter [04100, 05004], lr: 0.100000, loss: 2.9591
2022-07-15 13:03:06 - train: epoch 0027, iter [04200, 05004], lr: 0.100000, loss: 3.0285
2022-07-15 13:03:40 - train: epoch 0027, iter [04300, 05004], lr: 0.100000, loss: 2.9379
2022-07-15 13:04:12 - train: epoch 0027, iter [04400, 05004], lr: 0.100000, loss: 2.8965
2022-07-15 13:04:45 - train: epoch 0027, iter [04500, 05004], lr: 0.100000, loss: 2.8414
2022-07-15 13:05:18 - train: epoch 0027, iter [04600, 05004], lr: 0.100000, loss: 2.8872
2022-07-15 13:05:51 - train: epoch 0027, iter [04700, 05004], lr: 0.100000, loss: 3.0212
2022-07-15 13:06:26 - train: epoch 0027, iter [04800, 05004], lr: 0.100000, loss: 3.0940
2022-07-15 13:06:58 - train: epoch 0027, iter [04900, 05004], lr: 0.100000, loss: 3.0837
2022-07-15 13:07:29 - train: epoch 0027, iter [05000, 05004], lr: 0.100000, loss: 2.6311
2022-07-15 13:07:30 - train: epoch 027, train_loss: 2.9686
2022-07-15 13:08:44 - eval: epoch: 027, acc1: 43.264%, acc5: 68.400%, test_loss: 2.6286, per_image_load_time: 1.545ms, per_image_inference_time: 0.124ms
2022-07-15 13:08:44 - until epoch: 027, best_acc1: 43.290%
2022-07-15 13:08:44 - epoch 028 lr: 0.100000
2022-07-15 13:09:23 - train: epoch 0028, iter [00100, 05004], lr: 0.100000, loss: 2.7621
2022-07-15 13:09:56 - train: epoch 0028, iter [00200, 05004], lr: 0.100000, loss: 2.8765
2022-07-15 13:10:31 - train: epoch 0028, iter [00300, 05004], lr: 0.100000, loss: 2.9093
2022-07-15 13:11:04 - train: epoch 0028, iter [00400, 05004], lr: 0.100000, loss: 2.9887
2022-07-15 13:11:38 - train: epoch 0028, iter [00500, 05004], lr: 0.100000, loss: 2.9419
2022-07-15 13:12:11 - train: epoch 0028, iter [00600, 05004], lr: 0.100000, loss: 2.9988
2022-07-15 13:12:44 - train: epoch 0028, iter [00700, 05004], lr: 0.100000, loss: 3.2404
2022-07-15 13:13:16 - train: epoch 0028, iter [00800, 05004], lr: 0.100000, loss: 2.8039
2022-07-15 13:13:50 - train: epoch 0028, iter [00900, 05004], lr: 0.100000, loss: 2.7574
2022-07-15 13:14:23 - train: epoch 0028, iter [01000, 05004], lr: 0.100000, loss: 2.9586
2022-07-15 13:14:56 - train: epoch 0028, iter [01100, 05004], lr: 0.100000, loss: 2.9296
2022-07-15 13:15:30 - train: epoch 0028, iter [01200, 05004], lr: 0.100000, loss: 2.7707
2022-07-15 13:16:02 - train: epoch 0028, iter [01300, 05004], lr: 0.100000, loss: 3.0809
2022-07-15 13:16:37 - train: epoch 0028, iter [01400, 05004], lr: 0.100000, loss: 3.2616
2022-07-15 13:17:09 - train: epoch 0028, iter [01500, 05004], lr: 0.100000, loss: 3.0017
2022-07-15 13:17:42 - train: epoch 0028, iter [01600, 05004], lr: 0.100000, loss: 2.9737
2022-07-15 13:18:15 - train: epoch 0028, iter [01700, 05004], lr: 0.100000, loss: 2.9253
2022-07-15 13:18:49 - train: epoch 0028, iter [01800, 05004], lr: 0.100000, loss: 2.7676
2022-07-15 13:19:22 - train: epoch 0028, iter [01900, 05004], lr: 0.100000, loss: 2.7809
2022-07-15 13:19:56 - train: epoch 0028, iter [02000, 05004], lr: 0.100000, loss: 3.1139
2022-07-15 13:20:28 - train: epoch 0028, iter [02100, 05004], lr: 0.100000, loss: 3.1755
2022-07-15 13:21:02 - train: epoch 0028, iter [02200, 05004], lr: 0.100000, loss: 3.0296
2022-07-15 13:21:35 - train: epoch 0028, iter [02300, 05004], lr: 0.100000, loss: 3.2038
2022-07-15 13:22:09 - train: epoch 0028, iter [02400, 05004], lr: 0.100000, loss: 3.3148
2022-07-15 13:22:42 - train: epoch 0028, iter [02500, 05004], lr: 0.100000, loss: 2.9012
2022-07-15 13:23:16 - train: epoch 0028, iter [02600, 05004], lr: 0.100000, loss: 2.6733
2022-07-15 13:23:50 - train: epoch 0028, iter [02700, 05004], lr: 0.100000, loss: 3.0366
2022-07-15 13:24:23 - train: epoch 0028, iter [02800, 05004], lr: 0.100000, loss: 2.8862
2022-07-15 13:24:55 - train: epoch 0028, iter [02900, 05004], lr: 0.100000, loss: 2.9506
2022-07-15 13:25:30 - train: epoch 0028, iter [03000, 05004], lr: 0.100000, loss: 3.1137
2022-07-15 13:26:03 - train: epoch 0028, iter [03100, 05004], lr: 0.100000, loss: 3.3521
2022-07-15 13:26:36 - train: epoch 0028, iter [03200, 05004], lr: 0.100000, loss: 2.8541
2022-07-15 13:27:09 - train: epoch 0028, iter [03300, 05004], lr: 0.100000, loss: 2.9423
2022-07-15 13:27:43 - train: epoch 0028, iter [03400, 05004], lr: 0.100000, loss: 2.9971
2022-07-15 13:28:17 - train: epoch 0028, iter [03500, 05004], lr: 0.100000, loss: 2.6977
2022-07-15 13:28:50 - train: epoch 0028, iter [03600, 05004], lr: 0.100000, loss: 2.7962
2022-07-15 13:29:23 - train: epoch 0028, iter [03700, 05004], lr: 0.100000, loss: 3.0218
2022-07-15 13:29:57 - train: epoch 0028, iter [03800, 05004], lr: 0.100000, loss: 2.5946
2022-07-15 13:30:29 - train: epoch 0028, iter [03900, 05004], lr: 0.100000, loss: 2.9771
2022-07-15 13:31:03 - train: epoch 0028, iter [04000, 05004], lr: 0.100000, loss: 3.0759
2022-07-15 13:31:37 - train: epoch 0028, iter [04100, 05004], lr: 0.100000, loss: 3.0489
2022-07-15 13:32:10 - train: epoch 0028, iter [04200, 05004], lr: 0.100000, loss: 2.9941
2022-07-15 13:32:43 - train: epoch 0028, iter [04300, 05004], lr: 0.100000, loss: 2.8269
2022-07-15 13:33:16 - train: epoch 0028, iter [04400, 05004], lr: 0.100000, loss: 2.8426
2022-07-15 13:33:50 - train: epoch 0028, iter [04500, 05004], lr: 0.100000, loss: 3.0019
2022-07-15 13:34:23 - train: epoch 0028, iter [04600, 05004], lr: 0.100000, loss: 2.9800
2022-07-15 13:34:57 - train: epoch 0028, iter [04700, 05004], lr: 0.100000, loss: 2.8026
2022-07-15 13:35:30 - train: epoch 0028, iter [04800, 05004], lr: 0.100000, loss: 2.8146
2022-07-15 13:36:04 - train: epoch 0028, iter [04900, 05004], lr: 0.100000, loss: 2.9738
2022-07-15 13:36:35 - train: epoch 0028, iter [05000, 05004], lr: 0.100000, loss: 2.8445
2022-07-15 13:36:36 - train: epoch 028, train_loss: 2.9636
2022-07-15 13:37:51 - eval: epoch: 028, acc1: 43.274%, acc5: 67.894%, test_loss: 2.6621, per_image_load_time: 2.268ms, per_image_inference_time: 0.120ms
2022-07-15 13:37:51 - until epoch: 028, best_acc1: 43.290%
2022-07-15 13:37:51 - epoch 029 lr: 0.100000
2022-07-15 13:38:30 - train: epoch 0029, iter [00100, 05004], lr: 0.100000, loss: 3.0790
2022-07-15 13:39:03 - train: epoch 0029, iter [00200, 05004], lr: 0.100000, loss: 2.9928
2022-07-15 13:39:37 - train: epoch 0029, iter [00300, 05004], lr: 0.100000, loss: 3.0572
2022-07-15 13:40:09 - train: epoch 0029, iter [00400, 05004], lr: 0.100000, loss: 2.8593
2022-07-15 13:40:42 - train: epoch 0029, iter [00500, 05004], lr: 0.100000, loss: 3.0918
2022-07-15 13:41:15 - train: epoch 0029, iter [00600, 05004], lr: 0.100000, loss: 3.2431
2022-07-15 13:41:49 - train: epoch 0029, iter [00700, 05004], lr: 0.100000, loss: 2.6347
2022-07-15 13:42:22 - train: epoch 0029, iter [00800, 05004], lr: 0.100000, loss: 3.0970
2022-07-15 13:42:54 - train: epoch 0029, iter [00900, 05004], lr: 0.100000, loss: 2.8636
2022-07-15 13:43:27 - train: epoch 0029, iter [01000, 05004], lr: 0.100000, loss: 2.8571
2022-07-15 13:44:00 - train: epoch 0029, iter [01100, 05004], lr: 0.100000, loss: 2.9255
2022-07-15 13:44:33 - train: epoch 0029, iter [01200, 05004], lr: 0.100000, loss: 3.0883
2022-07-15 13:45:06 - train: epoch 0029, iter [01300, 05004], lr: 0.100000, loss: 3.0035
2022-07-15 13:45:40 - train: epoch 0029, iter [01400, 05004], lr: 0.100000, loss: 3.1446
2022-07-15 13:46:13 - train: epoch 0029, iter [01500, 05004], lr: 0.100000, loss: 2.9589
2022-07-15 13:46:48 - train: epoch 0029, iter [01600, 05004], lr: 0.100000, loss: 2.9247
2022-07-15 13:47:19 - train: epoch 0029, iter [01700, 05004], lr: 0.100000, loss: 3.0249
2022-07-15 13:47:54 - train: epoch 0029, iter [01800, 05004], lr: 0.100000, loss: 3.1538
2022-07-15 13:48:26 - train: epoch 0029, iter [01900, 05004], lr: 0.100000, loss: 2.7675
2022-07-15 13:49:00 - train: epoch 0029, iter [02000, 05004], lr: 0.100000, loss: 3.0174
2022-07-15 13:49:33 - train: epoch 0029, iter [02100, 05004], lr: 0.100000, loss: 2.8512
2022-07-15 13:50:06 - train: epoch 0029, iter [02200, 05004], lr: 0.100000, loss: 3.1402
2022-07-15 13:50:40 - train: epoch 0029, iter [02300, 05004], lr: 0.100000, loss: 2.9881
2022-07-15 13:51:13 - train: epoch 0029, iter [02400, 05004], lr: 0.100000, loss: 2.9369
2022-07-15 13:51:46 - train: epoch 0029, iter [02500, 05004], lr: 0.100000, loss: 2.8703
2022-07-15 13:52:20 - train: epoch 0029, iter [02600, 05004], lr: 0.100000, loss: 2.9555
2022-07-15 13:52:53 - train: epoch 0029, iter [02700, 05004], lr: 0.100000, loss: 2.8697
2022-07-15 13:53:27 - train: epoch 0029, iter [02800, 05004], lr: 0.100000, loss: 2.9352
2022-07-15 13:53:59 - train: epoch 0029, iter [02900, 05004], lr: 0.100000, loss: 2.8943
2022-07-15 13:54:32 - train: epoch 0029, iter [03000, 05004], lr: 0.100000, loss: 2.9409
2022-07-15 13:55:07 - train: epoch 0029, iter [03100, 05004], lr: 0.100000, loss: 3.0593
2022-07-15 13:55:39 - train: epoch 0029, iter [03200, 05004], lr: 0.100000, loss: 3.0210
2022-07-15 13:56:13 - train: epoch 0029, iter [03300, 05004], lr: 0.100000, loss: 2.7589
2022-07-15 13:56:46 - train: epoch 0029, iter [03400, 05004], lr: 0.100000, loss: 2.9107
2022-07-15 13:57:20 - train: epoch 0029, iter [03500, 05004], lr: 0.100000, loss: 3.2532
2022-07-15 13:57:53 - train: epoch 0029, iter [03600, 05004], lr: 0.100000, loss: 2.9338
2022-07-15 13:58:27 - train: epoch 0029, iter [03700, 05004], lr: 0.100000, loss: 2.9264
2022-07-15 13:58:59 - train: epoch 0029, iter [03800, 05004], lr: 0.100000, loss: 3.0015
2022-07-15 13:59:34 - train: epoch 0029, iter [03900, 05004], lr: 0.100000, loss: 2.6689
2022-07-15 14:00:07 - train: epoch 0029, iter [04000, 05004], lr: 0.100000, loss: 2.9287
2022-07-15 14:00:40 - train: epoch 0029, iter [04100, 05004], lr: 0.100000, loss: 2.9920
2022-07-15 14:01:13 - train: epoch 0029, iter [04200, 05004], lr: 0.100000, loss: 2.8773
2022-07-15 14:01:47 - train: epoch 0029, iter [04300, 05004], lr: 0.100000, loss: 3.0290
2022-07-15 14:02:20 - train: epoch 0029, iter [04400, 05004], lr: 0.100000, loss: 2.9777
2022-07-15 14:02:54 - train: epoch 0029, iter [04500, 05004], lr: 0.100000, loss: 3.1616
2022-07-15 14:03:27 - train: epoch 0029, iter [04600, 05004], lr: 0.100000, loss: 3.1710
2022-07-15 14:04:01 - train: epoch 0029, iter [04700, 05004], lr: 0.100000, loss: 2.8095
2022-07-15 14:04:33 - train: epoch 0029, iter [04800, 05004], lr: 0.100000, loss: 2.9251
2022-07-15 14:05:08 - train: epoch 0029, iter [04900, 05004], lr: 0.100000, loss: 3.4677
2022-07-15 14:05:38 - train: epoch 0029, iter [05000, 05004], lr: 0.100000, loss: 2.6588
2022-07-15 14:05:39 - train: epoch 029, train_loss: 2.9632
2022-07-15 14:06:54 - eval: epoch: 029, acc1: 42.390%, acc5: 67.348%, test_loss: 2.6826, per_image_load_time: 1.367ms, per_image_inference_time: 0.138ms
2022-07-15 14:06:54 - until epoch: 029, best_acc1: 43.290%
2022-07-15 14:06:54 - epoch 030 lr: 0.100000
2022-07-15 14:07:34 - train: epoch 0030, iter [00100, 05004], lr: 0.100000, loss: 3.0801
2022-07-15 14:08:06 - train: epoch 0030, iter [00200, 05004], lr: 0.100000, loss: 3.1145
2022-07-15 14:08:39 - train: epoch 0030, iter [00300, 05004], lr: 0.100000, loss: 2.8905
2022-07-15 14:09:13 - train: epoch 0030, iter [00400, 05004], lr: 0.100000, loss: 2.6334
2022-07-15 14:09:46 - train: epoch 0030, iter [00500, 05004], lr: 0.100000, loss: 3.2658
2022-07-15 14:10:19 - train: epoch 0030, iter [00600, 05004], lr: 0.100000, loss: 2.7259
2022-07-15 14:10:51 - train: epoch 0030, iter [00700, 05004], lr: 0.100000, loss: 2.8612
2022-07-15 14:11:24 - train: epoch 0030, iter [00800, 05004], lr: 0.100000, loss: 3.0423
2022-07-15 14:11:58 - train: epoch 0030, iter [00900, 05004], lr: 0.100000, loss: 2.8581
2022-07-15 14:12:31 - train: epoch 0030, iter [01000, 05004], lr: 0.100000, loss: 2.7122
2022-07-15 14:13:04 - train: epoch 0030, iter [01100, 05004], lr: 0.100000, loss: 2.7779
2022-07-15 14:13:36 - train: epoch 0030, iter [01200, 05004], lr: 0.100000, loss: 3.0409
2022-07-15 14:14:10 - train: epoch 0030, iter [01300, 05004], lr: 0.100000, loss: 2.7096
2022-07-15 14:14:43 - train: epoch 0030, iter [01400, 05004], lr: 0.100000, loss: 2.9634
2022-07-15 14:15:16 - train: epoch 0030, iter [01500, 05004], lr: 0.100000, loss: 2.8578
2022-07-15 14:15:49 - train: epoch 0030, iter [01600, 05004], lr: 0.100000, loss: 2.9065
2022-07-15 14:16:22 - train: epoch 0030, iter [01700, 05004], lr: 0.100000, loss: 3.0951
2022-07-15 14:16:56 - train: epoch 0030, iter [01800, 05004], lr: 0.100000, loss: 3.0450
2022-07-15 14:17:28 - train: epoch 0030, iter [01900, 05004], lr: 0.100000, loss: 3.1252
2022-07-15 14:18:00 - train: epoch 0030, iter [02000, 05004], lr: 0.100000, loss: 3.0008
2022-07-15 14:18:34 - train: epoch 0030, iter [02100, 05004], lr: 0.100000, loss: 3.1163
2022-07-15 14:19:06 - train: epoch 0030, iter [02200, 05004], lr: 0.100000, loss: 2.9295
2022-07-15 14:19:39 - train: epoch 0030, iter [02300, 05004], lr: 0.100000, loss: 3.0190
2022-07-15 14:20:11 - train: epoch 0030, iter [02400, 05004], lr: 0.100000, loss: 3.0847
2022-07-15 14:20:45 - train: epoch 0030, iter [02500, 05004], lr: 0.100000, loss: 2.9151
2022-07-15 14:21:19 - train: epoch 0030, iter [02600, 05004], lr: 0.100000, loss: 2.9629
2022-07-15 14:21:52 - train: epoch 0030, iter [02700, 05004], lr: 0.100000, loss: 2.9550
2022-07-15 14:22:25 - train: epoch 0030, iter [02800, 05004], lr: 0.100000, loss: 2.9624
2022-07-15 14:22:58 - train: epoch 0030, iter [02900, 05004], lr: 0.100000, loss: 2.8946
2022-07-15 14:23:31 - train: epoch 0030, iter [03000, 05004], lr: 0.100000, loss: 3.1458
2022-07-15 14:24:04 - train: epoch 0030, iter [03100, 05004], lr: 0.100000, loss: 3.0002
2022-07-15 14:24:37 - train: epoch 0030, iter [03200, 05004], lr: 0.100000, loss: 2.7596
2022-07-15 14:25:10 - train: epoch 0030, iter [03300, 05004], lr: 0.100000, loss: 3.2479
2022-07-15 14:25:45 - train: epoch 0030, iter [03400, 05004], lr: 0.100000, loss: 3.0810
2022-07-15 14:26:17 - train: epoch 0030, iter [03500, 05004], lr: 0.100000, loss: 2.8803
2022-07-15 14:26:51 - train: epoch 0030, iter [03600, 05004], lr: 0.100000, loss: 2.9032
2022-07-15 14:27:23 - train: epoch 0030, iter [03700, 05004], lr: 0.100000, loss: 2.7905
2022-07-15 14:27:57 - train: epoch 0030, iter [03800, 05004], lr: 0.100000, loss: 3.0543
2022-07-15 14:28:29 - train: epoch 0030, iter [03900, 05004], lr: 0.100000, loss: 2.9549
2022-07-15 14:29:02 - train: epoch 0030, iter [04000, 05004], lr: 0.100000, loss: 2.8491
2022-07-15 14:29:36 - train: epoch 0030, iter [04100, 05004], lr: 0.100000, loss: 2.7925
2022-07-15 14:30:09 - train: epoch 0030, iter [04200, 05004], lr: 0.100000, loss: 3.1887
2022-07-15 14:30:42 - train: epoch 0030, iter [04300, 05004], lr: 0.100000, loss: 2.9369
2022-07-15 14:31:15 - train: epoch 0030, iter [04400, 05004], lr: 0.100000, loss: 2.8679
2022-07-15 14:31:50 - train: epoch 0030, iter [04500, 05004], lr: 0.100000, loss: 3.1536
2022-07-15 14:32:22 - train: epoch 0030, iter [04600, 05004], lr: 0.100000, loss: 2.7915
2022-07-15 14:32:56 - train: epoch 0030, iter [04700, 05004], lr: 0.100000, loss: 2.9996
2022-07-15 14:33:28 - train: epoch 0030, iter [04800, 05004], lr: 0.100000, loss: 3.0509
2022-07-15 14:34:03 - train: epoch 0030, iter [04900, 05004], lr: 0.100000, loss: 3.0904
2022-07-15 14:34:34 - train: epoch 0030, iter [05000, 05004], lr: 0.100000, loss: 3.1459
2022-07-15 14:34:35 - train: epoch 030, train_loss: 2.9617
2022-07-15 14:35:49 - eval: epoch: 030, acc1: 42.614%, acc5: 67.684%, test_loss: 2.6684, per_image_load_time: 1.904ms, per_image_inference_time: 0.134ms
2022-07-15 14:35:49 - until epoch: 030, best_acc1: 43.290%
2022-07-15 14:35:49 - epoch 031 lr: 0.010000
2022-07-15 14:36:28 - train: epoch 0031, iter [00100, 05004], lr: 0.010000, loss: 2.8066
2022-07-15 14:37:01 - train: epoch 0031, iter [00200, 05004], lr: 0.010000, loss: 2.8174
2022-07-15 14:37:34 - train: epoch 0031, iter [00300, 05004], lr: 0.010000, loss: 2.6765
2022-07-15 14:38:07 - train: epoch 0031, iter [00400, 05004], lr: 0.010000, loss: 2.6258
2022-07-15 14:38:42 - train: epoch 0031, iter [00500, 05004], lr: 0.010000, loss: 2.5528
2022-07-15 14:39:15 - train: epoch 0031, iter [00600, 05004], lr: 0.010000, loss: 2.7025
2022-07-15 14:39:48 - train: epoch 0031, iter [00700, 05004], lr: 0.010000, loss: 2.5821
2022-07-15 14:40:21 - train: epoch 0031, iter [00800, 05004], lr: 0.010000, loss: 2.5687
2022-07-15 14:40:54 - train: epoch 0031, iter [00900, 05004], lr: 0.010000, loss: 2.4518
2022-07-15 14:41:27 - train: epoch 0031, iter [01000, 05004], lr: 0.010000, loss: 2.8912
2022-07-15 14:42:01 - train: epoch 0031, iter [01100, 05004], lr: 0.010000, loss: 2.8103
2022-07-15 14:42:34 - train: epoch 0031, iter [01200, 05004], lr: 0.010000, loss: 2.6833
2022-07-15 14:43:08 - train: epoch 0031, iter [01300, 05004], lr: 0.010000, loss: 2.4131
2022-07-15 14:43:41 - train: epoch 0031, iter [01400, 05004], lr: 0.010000, loss: 2.6049
2022-07-15 14:44:15 - train: epoch 0031, iter [01500, 05004], lr: 0.010000, loss: 2.9003
2022-07-15 14:44:48 - train: epoch 0031, iter [01600, 05004], lr: 0.010000, loss: 2.5902
2022-07-15 14:45:21 - train: epoch 0031, iter [01700, 05004], lr: 0.010000, loss: 2.4557
2022-07-15 14:45:54 - train: epoch 0031, iter [01800, 05004], lr: 0.010000, loss: 2.4170
2022-07-15 14:46:29 - train: epoch 0031, iter [01900, 05004], lr: 0.010000, loss: 2.6474
2022-07-15 14:47:01 - train: epoch 0031, iter [02000, 05004], lr: 0.010000, loss: 2.6837
2022-07-15 14:47:35 - train: epoch 0031, iter [02100, 05004], lr: 0.010000, loss: 2.4613
2022-07-15 14:48:08 - train: epoch 0031, iter [02200, 05004], lr: 0.010000, loss: 2.3897
2022-07-15 14:48:42 - train: epoch 0031, iter [02300, 05004], lr: 0.010000, loss: 2.4198
2022-07-15 14:49:15 - train: epoch 0031, iter [02400, 05004], lr: 0.010000, loss: 2.5441
2022-07-15 14:49:48 - train: epoch 0031, iter [02500, 05004], lr: 0.010000, loss: 2.4199
2022-07-15 14:50:21 - train: epoch 0031, iter [02600, 05004], lr: 0.010000, loss: 2.4458
2022-07-15 14:50:54 - train: epoch 0031, iter [02700, 05004], lr: 0.010000, loss: 2.4918
2022-07-15 14:51:28 - train: epoch 0031, iter [02800, 05004], lr: 0.010000, loss: 2.8168
2022-07-15 14:52:02 - train: epoch 0031, iter [02900, 05004], lr: 0.010000, loss: 2.5294
2022-07-15 14:52:34 - train: epoch 0031, iter [03000, 05004], lr: 0.010000, loss: 2.6842
2022-07-15 14:53:08 - train: epoch 0031, iter [03100, 05004], lr: 0.010000, loss: 2.4862
2022-07-15 14:53:41 - train: epoch 0031, iter [03200, 05004], lr: 0.010000, loss: 2.5450
2022-07-15 14:54:15 - train: epoch 0031, iter [03300, 05004], lr: 0.010000, loss: 2.4996
2022-07-15 14:54:48 - train: epoch 0031, iter [03400, 05004], lr: 0.010000, loss: 2.6992
2022-07-15 14:55:22 - train: epoch 0031, iter [03500, 05004], lr: 0.010000, loss: 2.6881
2022-07-15 14:55:54 - train: epoch 0031, iter [03600, 05004], lr: 0.010000, loss: 2.5334
2022-07-15 14:56:28 - train: epoch 0031, iter [03700, 05004], lr: 0.010000, loss: 2.5850
2022-07-15 14:57:02 - train: epoch 0031, iter [03800, 05004], lr: 0.010000, loss: 2.3929
2022-07-15 14:57:35 - train: epoch 0031, iter [03900, 05004], lr: 0.010000, loss: 2.4937
2022-07-15 14:58:09 - train: epoch 0031, iter [04000, 05004], lr: 0.010000, loss: 2.4794
2022-07-15 14:58:41 - train: epoch 0031, iter [04100, 05004], lr: 0.010000, loss: 2.5342
2022-07-15 14:59:15 - train: epoch 0031, iter [04200, 05004], lr: 0.010000, loss: 2.5636
2022-07-15 14:59:49 - train: epoch 0031, iter [04300, 05004], lr: 0.010000, loss: 2.4808
2022-07-15 15:00:21 - train: epoch 0031, iter [04400, 05004], lr: 0.010000, loss: 2.7070
2022-07-15 15:00:56 - train: epoch 0031, iter [04500, 05004], lr: 0.010000, loss: 2.5892
2022-07-15 15:01:28 - train: epoch 0031, iter [04600, 05004], lr: 0.010000, loss: 2.5832
2022-07-15 15:02:03 - train: epoch 0031, iter [04700, 05004], lr: 0.010000, loss: 2.4999
2022-07-15 15:02:36 - train: epoch 0031, iter [04800, 05004], lr: 0.010000, loss: 2.5238
2022-07-15 15:03:10 - train: epoch 0031, iter [04900, 05004], lr: 0.010000, loss: 2.4196
2022-07-15 15:03:40 - train: epoch 0031, iter [05000, 05004], lr: 0.010000, loss: 2.4935
2022-07-15 15:03:41 - train: epoch 031, train_loss: 2.5725
2022-07-15 15:04:55 - eval: epoch: 031, acc1: 52.318%, acc5: 75.892%, test_loss: 2.1540, per_image_load_time: 2.399ms, per_image_inference_time: 0.122ms
2022-07-15 15:04:55 - until epoch: 031, best_acc1: 52.318%
2022-07-15 15:04:55 - epoch 032 lr: 0.010000
2022-07-15 15:05:33 - train: epoch 0032, iter [00100, 05004], lr: 0.010000, loss: 2.4329
2022-07-15 15:06:06 - train: epoch 0032, iter [00200, 05004], lr: 0.010000, loss: 2.6414
2022-07-15 15:06:41 - train: epoch 0032, iter [00300, 05004], lr: 0.010000, loss: 2.4871
2022-07-15 15:07:13 - train: epoch 0032, iter [00400, 05004], lr: 0.010000, loss: 2.5615
2022-07-15 15:07:47 - train: epoch 0032, iter [00500, 05004], lr: 0.010000, loss: 2.6870
2022-07-15 15:08:19 - train: epoch 0032, iter [00600, 05004], lr: 0.010000, loss: 2.6159
2022-07-15 15:08:53 - train: epoch 0032, iter [00700, 05004], lr: 0.010000, loss: 2.5168
2022-07-15 15:09:26 - train: epoch 0032, iter [00800, 05004], lr: 0.010000, loss: 2.4979
2022-07-15 15:09:59 - train: epoch 0032, iter [00900, 05004], lr: 0.010000, loss: 2.5145
2022-07-15 15:10:32 - train: epoch 0032, iter [01000, 05004], lr: 0.010000, loss: 2.4730
2022-07-15 15:11:05 - train: epoch 0032, iter [01100, 05004], lr: 0.010000, loss: 2.5513
2022-07-15 15:11:39 - train: epoch 0032, iter [01200, 05004], lr: 0.010000, loss: 2.6569
2022-07-15 15:12:12 - train: epoch 0032, iter [01300, 05004], lr: 0.010000, loss: 2.3835
2022-07-15 15:12:44 - train: epoch 0032, iter [01400, 05004], lr: 0.010000, loss: 2.7679
2022-07-15 15:13:17 - train: epoch 0032, iter [01500, 05004], lr: 0.010000, loss: 2.4820
2022-07-15 15:13:50 - train: epoch 0032, iter [01600, 05004], lr: 0.010000, loss: 2.5389
2022-07-15 15:14:23 - train: epoch 0032, iter [01700, 05004], lr: 0.010000, loss: 2.7514
2022-07-15 15:14:58 - train: epoch 0032, iter [01800, 05004], lr: 0.010000, loss: 2.8461
2022-07-15 15:15:30 - train: epoch 0032, iter [01900, 05004], lr: 0.010000, loss: 2.1992
2022-07-15 15:16:04 - train: epoch 0032, iter [02000, 05004], lr: 0.010000, loss: 2.3565
2022-07-15 15:16:36 - train: epoch 0032, iter [02100, 05004], lr: 0.010000, loss: 2.4313
2022-07-15 15:17:10 - train: epoch 0032, iter [02200, 05004], lr: 0.010000, loss: 2.3540
2022-07-15 15:17:43 - train: epoch 0032, iter [02300, 05004], lr: 0.010000, loss: 2.5365
2022-07-15 15:18:17 - train: epoch 0032, iter [02400, 05004], lr: 0.010000, loss: 2.4554
2022-07-15 15:18:50 - train: epoch 0032, iter [02500, 05004], lr: 0.010000, loss: 2.5831
2022-07-15 15:19:24 - train: epoch 0032, iter [02600, 05004], lr: 0.010000, loss: 2.1449
2022-07-15 15:19:57 - train: epoch 0032, iter [02700, 05004], lr: 0.010000, loss: 2.6173
2022-07-15 15:20:31 - train: epoch 0032, iter [02800, 05004], lr: 0.010000, loss: 2.4721
2022-07-15 15:21:04 - train: epoch 0032, iter [02900, 05004], lr: 0.010000, loss: 2.3095
2022-07-15 15:21:38 - train: epoch 0032, iter [03000, 05004], lr: 0.010000, loss: 2.2235
2022-07-15 15:22:10 - train: epoch 0032, iter [03100, 05004], lr: 0.010000, loss: 2.5712
2022-07-15 15:22:44 - train: epoch 0032, iter [03200, 05004], lr: 0.010000, loss: 2.4723
2022-07-15 15:23:16 - train: epoch 0032, iter [03300, 05004], lr: 0.010000, loss: 2.3116
2022-07-15 15:23:51 - train: epoch 0032, iter [03400, 05004], lr: 0.010000, loss: 2.3109
2022-07-15 15:24:24 - train: epoch 0032, iter [03500, 05004], lr: 0.010000, loss: 2.4708
2022-07-15 15:24:57 - train: epoch 0032, iter [03600, 05004], lr: 0.010000, loss: 2.5445
2022-07-15 15:25:31 - train: epoch 0032, iter [03700, 05004], lr: 0.010000, loss: 2.7048
2022-07-15 15:26:05 - train: epoch 0032, iter [03800, 05004], lr: 0.010000, loss: 2.3251
2022-07-15 15:26:39 - train: epoch 0032, iter [03900, 05004], lr: 0.010000, loss: 2.5685
2022-07-15 15:27:12 - train: epoch 0032, iter [04000, 05004], lr: 0.010000, loss: 2.3023
2022-07-15 15:27:46 - train: epoch 0032, iter [04100, 05004], lr: 0.010000, loss: 2.4168
2022-07-15 15:28:19 - train: epoch 0032, iter [04200, 05004], lr: 0.010000, loss: 2.4774
2022-07-15 15:28:53 - train: epoch 0032, iter [04300, 05004], lr: 0.010000, loss: 2.6673
2022-07-15 15:29:26 - train: epoch 0032, iter [04400, 05004], lr: 0.010000, loss: 2.4041
2022-07-15 15:30:00 - train: epoch 0032, iter [04500, 05004], lr: 0.010000, loss: 2.6489
2022-07-15 15:30:33 - train: epoch 0032, iter [04600, 05004], lr: 0.010000, loss: 2.4342
2022-07-15 15:31:07 - train: epoch 0032, iter [04700, 05004], lr: 0.010000, loss: 2.6998
2022-07-15 15:31:40 - train: epoch 0032, iter [04800, 05004], lr: 0.010000, loss: 2.4349
2022-07-15 15:32:14 - train: epoch 0032, iter [04900, 05004], lr: 0.010000, loss: 2.6599
2022-07-15 15:32:45 - train: epoch 0032, iter [05000, 05004], lr: 0.010000, loss: 2.4258
2022-07-15 15:32:47 - train: epoch 032, train_loss: 2.4806
2022-07-15 15:34:01 - eval: epoch: 032, acc1: 52.828%, acc5: 76.242%, test_loss: 2.1184, per_image_load_time: 2.011ms, per_image_inference_time: 0.129ms
2022-07-15 15:34:01 - until epoch: 032, best_acc1: 52.828%
2022-07-15 15:34:01 - epoch 033 lr: 0.010000
2022-07-15 15:34:39 - train: epoch 0033, iter [00100, 05004], lr: 0.010000, loss: 2.3343
2022-07-15 15:35:13 - train: epoch 0033, iter [00200, 05004], lr: 0.010000, loss: 2.5093
2022-07-15 15:35:46 - train: epoch 0033, iter [00300, 05004], lr: 0.010000, loss: 2.3311
2022-07-15 15:36:19 - train: epoch 0033, iter [00400, 05004], lr: 0.010000, loss: 2.2958
2022-07-15 15:36:53 - train: epoch 0033, iter [00500, 05004], lr: 0.010000, loss: 2.6161
2022-07-15 15:37:27 - train: epoch 0033, iter [00600, 05004], lr: 0.010000, loss: 2.3638
2022-07-15 15:37:59 - train: epoch 0033, iter [00700, 05004], lr: 0.010000, loss: 2.5647
2022-07-15 15:38:33 - train: epoch 0033, iter [00800, 05004], lr: 0.010000, loss: 2.5118
2022-07-15 15:39:05 - train: epoch 0033, iter [00900, 05004], lr: 0.010000, loss: 2.5481
2022-07-15 15:39:41 - train: epoch 0033, iter [01000, 05004], lr: 0.010000, loss: 2.5025
2022-07-15 15:40:12 - train: epoch 0033, iter [01100, 05004], lr: 0.010000, loss: 2.2533
2022-07-15 15:40:45 - train: epoch 0033, iter [01200, 05004], lr: 0.010000, loss: 2.4603
2022-07-15 15:41:18 - train: epoch 0033, iter [01300, 05004], lr: 0.010000, loss: 2.4976
2022-07-15 15:41:53 - train: epoch 0033, iter [01400, 05004], lr: 0.010000, loss: 2.5570
2022-07-15 15:42:24 - train: epoch 0033, iter [01500, 05004], lr: 0.010000, loss: 2.7729
2022-07-15 15:42:58 - train: epoch 0033, iter [01600, 05004], lr: 0.010000, loss: 2.6215
2022-07-15 15:43:31 - train: epoch 0033, iter [01700, 05004], lr: 0.010000, loss: 2.3642
2022-07-15 15:44:04 - train: epoch 0033, iter [01800, 05004], lr: 0.010000, loss: 2.6052
2022-07-15 15:44:37 - train: epoch 0033, iter [01900, 05004], lr: 0.010000, loss: 2.4933
2022-07-15 15:45:10 - train: epoch 0033, iter [02000, 05004], lr: 0.010000, loss: 2.4232
2022-07-15 15:45:43 - train: epoch 0033, iter [02100, 05004], lr: 0.010000, loss: 2.4575
2022-07-15 15:46:16 - train: epoch 0033, iter [02200, 05004], lr: 0.010000, loss: 2.4332
2022-07-15 15:46:49 - train: epoch 0033, iter [02300, 05004], lr: 0.010000, loss: 2.2185
2022-07-15 15:47:23 - train: epoch 0033, iter [02400, 05004], lr: 0.010000, loss: 2.5553
2022-07-15 15:47:56 - train: epoch 0033, iter [02500, 05004], lr: 0.010000, loss: 2.4395
2022-07-15 15:48:30 - train: epoch 0033, iter [02600, 05004], lr: 0.010000, loss: 2.1737
2022-07-15 15:49:03 - train: epoch 0033, iter [02700, 05004], lr: 0.010000, loss: 2.6436
2022-07-15 15:49:36 - train: epoch 0033, iter [02800, 05004], lr: 0.010000, loss: 2.5121
2022-07-15 15:50:09 - train: epoch 0033, iter [02900, 05004], lr: 0.010000, loss: 2.5153
2022-07-15 15:50:42 - train: epoch 0033, iter [03000, 05004], lr: 0.010000, loss: 2.4977
2022-07-15 15:51:16 - train: epoch 0033, iter [03100, 05004], lr: 0.010000, loss: 2.4000
2022-07-15 15:51:49 - train: epoch 0033, iter [03200, 05004], lr: 0.010000, loss: 2.3722
2022-07-15 15:52:22 - train: epoch 0033, iter [03300, 05004], lr: 0.010000, loss: 2.3859
2022-07-15 15:52:56 - train: epoch 0033, iter [03400, 05004], lr: 0.010000, loss: 2.2480
2022-07-15 15:53:28 - train: epoch 0033, iter [03500, 05004], lr: 0.010000, loss: 2.6534
2022-07-15 15:54:02 - train: epoch 0033, iter [03600, 05004], lr: 0.010000, loss: 2.6357
2022-07-15 15:54:34 - train: epoch 0033, iter [03700, 05004], lr: 0.010000, loss: 2.3914
2022-07-15 15:55:08 - train: epoch 0033, iter [03800, 05004], lr: 0.010000, loss: 2.4731
2022-07-15 15:55:41 - train: epoch 0033, iter [03900, 05004], lr: 0.010000, loss: 2.4680
2022-07-15 15:56:16 - train: epoch 0033, iter [04000, 05004], lr: 0.010000, loss: 2.3965
2022-07-15 15:56:49 - train: epoch 0033, iter [04100, 05004], lr: 0.010000, loss: 2.5097
2022-07-15 15:57:23 - train: epoch 0033, iter [04200, 05004], lr: 0.010000, loss: 2.3637
2022-07-15 15:57:55 - train: epoch 0033, iter [04300, 05004], lr: 0.010000, loss: 2.4641
2022-07-15 15:58:29 - train: epoch 0033, iter [04400, 05004], lr: 0.010000, loss: 2.5249
2022-07-15 15:59:01 - train: epoch 0033, iter [04500, 05004], lr: 0.010000, loss: 2.6763
2022-07-15 15:59:35 - train: epoch 0033, iter [04600, 05004], lr: 0.010000, loss: 2.3170
2022-07-15 16:00:08 - train: epoch 0033, iter [04700, 05004], lr: 0.010000, loss: 2.3443
2022-07-15 16:00:42 - train: epoch 0033, iter [04800, 05004], lr: 0.010000, loss: 2.7781
2022-07-15 16:01:15 - train: epoch 0033, iter [04900, 05004], lr: 0.010000, loss: 2.2885
2022-07-15 16:01:46 - train: epoch 0033, iter [05000, 05004], lr: 0.010000, loss: 2.2761
2022-07-15 16:01:47 - train: epoch 033, train_loss: 2.4459
2022-07-15 16:03:02 - eval: epoch: 033, acc1: 53.474%, acc5: 76.638%, test_loss: 2.0938, per_image_load_time: 2.304ms, per_image_inference_time: 0.140ms
2022-07-15 16:03:02 - until epoch: 033, best_acc1: 53.474%
2022-07-15 16:03:02 - epoch 034 lr: 0.010000
2022-07-15 16:03:40 - train: epoch 0034, iter [00100, 05004], lr: 0.010000, loss: 2.5215
2022-07-15 16:04:14 - train: epoch 0034, iter [00200, 05004], lr: 0.010000, loss: 2.3305
2022-07-15 16:04:46 - train: epoch 0034, iter [00300, 05004], lr: 0.010000, loss: 2.3263
2022-07-15 16:05:19 - train: epoch 0034, iter [00400, 05004], lr: 0.010000, loss: 2.2876
2022-07-15 16:05:52 - train: epoch 0034, iter [00500, 05004], lr: 0.010000, loss: 2.3487
2022-07-15 16:06:25 - train: epoch 0034, iter [00600, 05004], lr: 0.010000, loss: 2.6115
2022-07-15 16:06:58 - train: epoch 0034, iter [00700, 05004], lr: 0.010000, loss: 2.1478
2022-07-15 16:07:31 - train: epoch 0034, iter [00800, 05004], lr: 0.010000, loss: 2.5669
2022-07-15 16:08:04 - train: epoch 0034, iter [00900, 05004], lr: 0.010000, loss: 2.3065
2022-07-15 16:08:37 - train: epoch 0034, iter [01000, 05004], lr: 0.010000, loss: 2.3960
2022-07-15 16:09:11 - train: epoch 0034, iter [01100, 05004], lr: 0.010000, loss: 2.3938
2022-07-15 16:09:43 - train: epoch 0034, iter [01200, 05004], lr: 0.010000, loss: 2.4225
2022-07-15 16:10:17 - train: epoch 0034, iter [01300, 05004], lr: 0.010000, loss: 2.3415
2022-07-15 16:10:50 - train: epoch 0034, iter [01400, 05004], lr: 0.010000, loss: 2.4239
2022-07-15 16:11:24 - train: epoch 0034, iter [01500, 05004], lr: 0.010000, loss: 2.3201
2022-07-15 16:11:56 - train: epoch 0034, iter [01600, 05004], lr: 0.010000, loss: 2.3301
2022-07-15 16:12:29 - train: epoch 0034, iter [01700, 05004], lr: 0.010000, loss: 2.4161
2022-07-15 16:13:02 - train: epoch 0034, iter [01800, 05004], lr: 0.010000, loss: 2.6218
2022-07-15 16:13:36 - train: epoch 0034, iter [01900, 05004], lr: 0.010000, loss: 2.5717
2022-07-15 16:14:09 - train: epoch 0034, iter [02000, 05004], lr: 0.010000, loss: 2.3953
2022-07-15 16:14:42 - train: epoch 0034, iter [02100, 05004], lr: 0.010000, loss: 2.5726
2022-07-15 16:15:15 - train: epoch 0034, iter [02200, 05004], lr: 0.010000, loss: 2.2602
2022-07-15 16:15:49 - train: epoch 0034, iter [02300, 05004], lr: 0.010000, loss: 2.5562
2022-07-15 16:16:21 - train: epoch 0034, iter [02400, 05004], lr: 0.010000, loss: 2.3173
2022-07-15 16:16:55 - train: epoch 0034, iter [02500, 05004], lr: 0.010000, loss: 2.4026
2022-07-15 16:17:27 - train: epoch 0034, iter [02600, 05004], lr: 0.010000, loss: 2.5504
2022-07-15 16:18:01 - train: epoch 0034, iter [02700, 05004], lr: 0.010000, loss: 2.3846
2022-07-15 16:18:33 - train: epoch 0034, iter [02800, 05004], lr: 0.010000, loss: 2.2848
2022-07-15 16:19:08 - train: epoch 0034, iter [02900, 05004], lr: 0.010000, loss: 2.0519
2022-07-15 16:19:40 - train: epoch 0034, iter [03000, 05004], lr: 0.010000, loss: 2.2950
2022-07-15 16:20:14 - train: epoch 0034, iter [03100, 05004], lr: 0.010000, loss: 2.2894
2022-07-15 16:20:46 - train: epoch 0034, iter [03200, 05004], lr: 0.010000, loss: 2.3182
2022-07-15 16:21:21 - train: epoch 0034, iter [03300, 05004], lr: 0.010000, loss: 2.2590
2022-07-15 16:21:53 - train: epoch 0034, iter [03400, 05004], lr: 0.010000, loss: 2.4443
2022-07-15 16:22:28 - train: epoch 0034, iter [03500, 05004], lr: 0.010000, loss: 2.2700
2022-07-15 16:23:01 - train: epoch 0034, iter [03600, 05004], lr: 0.010000, loss: 2.2347
2022-07-15 16:23:35 - train: epoch 0034, iter [03700, 05004], lr: 0.010000, loss: 2.1229
2022-07-15 16:24:07 - train: epoch 0034, iter [03800, 05004], lr: 0.010000, loss: 2.3444
2022-07-15 16:24:41 - train: epoch 0034, iter [03900, 05004], lr: 0.010000, loss: 2.6527
2022-07-15 16:25:15 - train: epoch 0034, iter [04000, 05004], lr: 0.010000, loss: 2.2140
2022-07-15 16:25:48 - train: epoch 0034, iter [04100, 05004], lr: 0.010000, loss: 2.4264
2022-07-15 16:26:21 - train: epoch 0034, iter [04200, 05004], lr: 0.010000, loss: 2.3462
2022-07-15 16:26:55 - train: epoch 0034, iter [04300, 05004], lr: 0.010000, loss: 2.3414
2022-07-15 16:27:28 - train: epoch 0034, iter [04400, 05004], lr: 0.010000, loss: 2.4648
2022-07-15 16:28:02 - train: epoch 0034, iter [04500, 05004], lr: 0.010000, loss: 2.4923
2022-07-15 16:28:34 - train: epoch 0034, iter [04600, 05004], lr: 0.010000, loss: 2.5112
2022-07-15 16:29:09 - train: epoch 0034, iter [04700, 05004], lr: 0.010000, loss: 2.3897
2022-07-15 16:29:42 - train: epoch 0034, iter [04800, 05004], lr: 0.010000, loss: 2.3185
2022-07-15 16:30:15 - train: epoch 0034, iter [04900, 05004], lr: 0.010000, loss: 2.3387
2022-07-15 16:30:47 - train: epoch 0034, iter [05000, 05004], lr: 0.010000, loss: 2.3767
2022-07-15 16:30:49 - train: epoch 034, train_loss: 2.4279
2022-07-15 16:32:03 - eval: epoch: 034, acc1: 53.720%, acc5: 77.068%, test_loss: 2.0754, per_image_load_time: 2.381ms, per_image_inference_time: 0.147ms
2022-07-15 16:32:03 - until epoch: 034, best_acc1: 53.720%
2022-07-15 16:32:03 - epoch 035 lr: 0.010000
2022-07-15 16:32:42 - train: epoch 0035, iter [00100, 05004], lr: 0.010000, loss: 2.2576
2022-07-15 16:33:15 - train: epoch 0035, iter [00200, 05004], lr: 0.010000, loss: 2.2390
2022-07-15 16:33:50 - train: epoch 0035, iter [00300, 05004], lr: 0.010000, loss: 2.5328
2022-07-15 16:34:22 - train: epoch 0035, iter [00400, 05004], lr: 0.010000, loss: 2.3906
2022-07-15 16:34:55 - train: epoch 0035, iter [00500, 05004], lr: 0.010000, loss: 2.4756
2022-07-15 16:35:29 - train: epoch 0035, iter [00600, 05004], lr: 0.010000, loss: 2.3012
2022-07-15 16:36:02 - train: epoch 0035, iter [00700, 05004], lr: 0.010000, loss: 2.4170
2022-07-15 16:36:36 - train: epoch 0035, iter [00800, 05004], lr: 0.010000, loss: 2.3613
2022-07-15 16:37:08 - train: epoch 0035, iter [00900, 05004], lr: 0.010000, loss: 2.5842
2022-07-15 16:37:42 - train: epoch 0035, iter [01000, 05004], lr: 0.010000, loss: 2.6315
2022-07-15 16:38:16 - train: epoch 0035, iter [01100, 05004], lr: 0.010000, loss: 2.5209
2022-07-15 16:38:49 - train: epoch 0035, iter [01200, 05004], lr: 0.010000, loss: 2.4728
2022-07-15 16:39:22 - train: epoch 0035, iter [01300, 05004], lr: 0.010000, loss: 2.4868
2022-07-15 16:39:55 - train: epoch 0035, iter [01400, 05004], lr: 0.010000, loss: 2.3341
2022-07-15 16:40:28 - train: epoch 0035, iter [01500, 05004], lr: 0.010000, loss: 2.5090
2022-07-15 16:41:03 - train: epoch 0035, iter [01600, 05004], lr: 0.010000, loss: 2.2699
2022-07-15 16:41:35 - train: epoch 0035, iter [01700, 05004], lr: 0.010000, loss: 2.2124
2022-07-15 16:42:09 - train: epoch 0035, iter [01800, 05004], lr: 0.010000, loss: 2.4991
2022-07-15 16:42:42 - train: epoch 0035, iter [01900, 05004], lr: 0.010000, loss: 2.4759
2022-07-15 16:43:15 - train: epoch 0035, iter [02000, 05004], lr: 0.010000, loss: 2.4837
2022-07-15 16:43:49 - train: epoch 0035, iter [02100, 05004], lr: 0.010000, loss: 2.1591
2022-07-15 16:44:22 - train: epoch 0035, iter [02200, 05004], lr: 0.010000, loss: 2.4753
2022-07-15 16:44:56 - train: epoch 0035, iter [02300, 05004], lr: 0.010000, loss: 2.4151
2022-07-15 16:45:28 - train: epoch 0035, iter [02400, 05004], lr: 0.010000, loss: 2.4598
2022-07-15 16:46:03 - train: epoch 0035, iter [02500, 05004], lr: 0.010000, loss: 2.3113
2022-07-15 16:46:36 - train: epoch 0035, iter [02600, 05004], lr: 0.010000, loss: 2.6184
2022-07-15 16:47:09 - train: epoch 0035, iter [02700, 05004], lr: 0.010000, loss: 2.4664
2022-07-15 16:47:43 - train: epoch 0035, iter [02800, 05004], lr: 0.010000, loss: 2.4634
2022-07-15 16:48:15 - train: epoch 0035, iter [02900, 05004], lr: 0.010000, loss: 2.4303
2022-07-15 16:48:49 - train: epoch 0035, iter [03000, 05004], lr: 0.010000, loss: 2.4581
2022-07-15 16:49:21 - train: epoch 0035, iter [03100, 05004], lr: 0.010000, loss: 2.5073
2022-07-15 16:49:56 - train: epoch 0035, iter [03200, 05004], lr: 0.010000, loss: 2.2538
2022-07-15 16:50:28 - train: epoch 0035, iter [03300, 05004], lr: 0.010000, loss: 2.3701
2022-07-15 16:51:01 - train: epoch 0035, iter [03400, 05004], lr: 0.010000, loss: 2.4515
2022-07-15 16:51:34 - train: epoch 0035, iter [03500, 05004], lr: 0.010000, loss: 2.0374
2022-07-15 16:52:09 - train: epoch 0035, iter [03600, 05004], lr: 0.010000, loss: 2.3834
2022-07-15 16:52:41 - train: epoch 0035, iter [03700, 05004], lr: 0.010000, loss: 2.3032
2022-07-15 16:53:15 - train: epoch 0035, iter [03800, 05004], lr: 0.010000, loss: 2.3006
2022-07-15 16:53:48 - train: epoch 0035, iter [03900, 05004], lr: 0.010000, loss: 2.6559
2022-07-15 16:54:21 - train: epoch 0035, iter [04000, 05004], lr: 0.010000, loss: 2.1837
2022-07-15 16:54:54 - train: epoch 0035, iter [04100, 05004], lr: 0.010000, loss: 2.7798
2022-07-15 16:55:28 - train: epoch 0035, iter [04200, 05004], lr: 0.010000, loss: 2.3359
2022-07-15 16:56:00 - train: epoch 0035, iter [04300, 05004], lr: 0.010000, loss: 2.5892
2022-07-15 16:56:35 - train: epoch 0035, iter [04400, 05004], lr: 0.010000, loss: 2.5505
2022-07-15 16:57:08 - train: epoch 0035, iter [04500, 05004], lr: 0.010000, loss: 2.5761
2022-07-15 16:57:41 - train: epoch 0035, iter [04600, 05004], lr: 0.010000, loss: 2.3496
2022-07-15 16:58:13 - train: epoch 0035, iter [04700, 05004], lr: 0.010000, loss: 2.7696
2022-07-15 16:58:47 - train: epoch 0035, iter [04800, 05004], lr: 0.010000, loss: 2.6066
2022-07-15 16:59:20 - train: epoch 0035, iter [04900, 05004], lr: 0.010000, loss: 2.4953
2022-07-15 16:59:52 - train: epoch 0035, iter [05000, 05004], lr: 0.010000, loss: 2.1970
2022-07-15 16:59:52 - train: epoch 035, train_loss: 2.4148
2022-07-15 17:01:07 - eval: epoch: 035, acc1: 53.714%, acc5: 77.124%, test_loss: 2.0751, per_image_load_time: 2.743ms, per_image_inference_time: 0.132ms
2022-07-15 17:01:07 - until epoch: 035, best_acc1: 53.720%
2022-07-15 17:01:07 - epoch 036 lr: 0.010000
2022-07-15 17:01:46 - train: epoch 0036, iter [00100, 05004], lr: 0.010000, loss: 2.5814
2022-07-15 17:02:19 - train: epoch 0036, iter [00200, 05004], lr: 0.010000, loss: 2.2049
2022-07-15 17:02:53 - train: epoch 0036, iter [00300, 05004], lr: 0.010000, loss: 2.3439
2022-07-15 17:03:25 - train: epoch 0036, iter [00400, 05004], lr: 0.010000, loss: 2.4029
2022-07-15 17:03:59 - train: epoch 0036, iter [00500, 05004], lr: 0.010000, loss: 2.3345
2022-07-15 17:04:31 - train: epoch 0036, iter [00600, 05004], lr: 0.010000, loss: 2.3690
2022-07-15 17:05:06 - train: epoch 0036, iter [00700, 05004], lr: 0.010000, loss: 2.3647
2022-07-15 17:05:39 - train: epoch 0036, iter [00800, 05004], lr: 0.010000, loss: 2.2261
2022-07-15 17:06:11 - train: epoch 0036, iter [00900, 05004], lr: 0.010000, loss: 2.3652
2022-07-15 17:06:44 - train: epoch 0036, iter [01000, 05004], lr: 0.010000, loss: 2.5273
2022-07-15 17:07:17 - train: epoch 0036, iter [01100, 05004], lr: 0.010000, loss: 2.4479
2022-07-15 17:07:52 - train: epoch 0036, iter [01200, 05004], lr: 0.010000, loss: 2.4937
2022-07-15 17:08:23 - train: epoch 0036, iter [01300, 05004], lr: 0.010000, loss: 2.2755
2022-07-15 17:08:57 - train: epoch 0036, iter [01400, 05004], lr: 0.010000, loss: 2.5234
2022-07-15 17:09:30 - train: epoch 0036, iter [01500, 05004], lr: 0.010000, loss: 2.4843
2022-07-15 17:10:04 - train: epoch 0036, iter [01600, 05004], lr: 0.010000, loss: 2.5476
2022-07-15 17:10:36 - train: epoch 0036, iter [01700, 05004], lr: 0.010000, loss: 2.3769
2022-07-15 17:11:10 - train: epoch 0036, iter [01800, 05004], lr: 0.010000, loss: 2.2269
2022-07-15 17:11:43 - train: epoch 0036, iter [01900, 05004], lr: 0.010000, loss: 2.5424
2022-07-15 17:12:16 - train: epoch 0036, iter [02000, 05004], lr: 0.010000, loss: 2.2870
2022-07-15 17:12:48 - train: epoch 0036, iter [02100, 05004], lr: 0.010000, loss: 2.4218
2022-07-15 17:13:22 - train: epoch 0036, iter [02200, 05004], lr: 0.010000, loss: 2.3072
2022-07-15 17:13:55 - train: epoch 0036, iter [02300, 05004], lr: 0.010000, loss: 2.4639
2022-07-15 17:14:29 - train: epoch 0036, iter [02400, 05004], lr: 0.010000, loss: 2.5138
2022-07-15 17:15:02 - train: epoch 0036, iter [02500, 05004], lr: 0.010000, loss: 2.1323
2022-07-15 17:15:36 - train: epoch 0036, iter [02600, 05004], lr: 0.010000, loss: 2.5128
2022-07-15 17:16:08 - train: epoch 0036, iter [02700, 05004], lr: 0.010000, loss: 2.3556
2022-07-15 17:16:42 - train: epoch 0036, iter [02800, 05004], lr: 0.010000, loss: 2.3207
2022-07-15 17:17:15 - train: epoch 0036, iter [02900, 05004], lr: 0.010000, loss: 2.1603
2022-07-15 17:17:49 - train: epoch 0036, iter [03000, 05004], lr: 0.010000, loss: 2.5200
2022-07-15 17:18:22 - train: epoch 0036, iter [03100, 05004], lr: 0.010000, loss: 2.5764
2022-07-15 17:18:56 - train: epoch 0036, iter [03200, 05004], lr: 0.010000, loss: 2.3803
2022-07-15 17:19:28 - train: epoch 0036, iter [03300, 05004], lr: 0.010000, loss: 2.3234
2022-07-15 17:20:02 - train: epoch 0036, iter [03400, 05004], lr: 0.010000, loss: 2.2134
2022-07-15 17:20:34 - train: epoch 0036, iter [03500, 05004], lr: 0.010000, loss: 2.5577
2022-07-15 17:21:07 - train: epoch 0036, iter [03600, 05004], lr: 0.010000, loss: 2.6681
2022-07-15 17:21:41 - train: epoch 0036, iter [03700, 05004], lr: 0.010000, loss: 2.4085
2022-07-15 17:22:15 - train: epoch 0036, iter [03800, 05004], lr: 0.010000, loss: 2.4974
2022-07-15 17:22:50 - train: epoch 0036, iter [03900, 05004], lr: 0.010000, loss: 2.3369
2022-07-15 17:23:22 - train: epoch 0036, iter [04000, 05004], lr: 0.010000, loss: 2.4764
2022-07-15 17:23:56 - train: epoch 0036, iter [04100, 05004], lr: 0.010000, loss: 2.3974
2022-07-15 17:24:28 - train: epoch 0036, iter [04200, 05004], lr: 0.010000, loss: 2.3032
2022-07-15 17:25:02 - train: epoch 0036, iter [04300, 05004], lr: 0.010000, loss: 2.4908
2022-07-15 17:25:35 - train: epoch 0036, iter [04400, 05004], lr: 0.010000, loss: 2.4079
2022-07-15 17:26:08 - train: epoch 0036, iter [04500, 05004], lr: 0.010000, loss: 2.0735
2022-07-15 17:26:42 - train: epoch 0036, iter [04600, 05004], lr: 0.010000, loss: 2.2566
2022-07-15 17:27:15 - train: epoch 0036, iter [04700, 05004], lr: 0.010000, loss: 2.5012
2022-07-15 17:27:49 - train: epoch 0036, iter [04800, 05004], lr: 0.010000, loss: 2.3098
2022-07-15 17:28:23 - train: epoch 0036, iter [04900, 05004], lr: 0.010000, loss: 2.2997
2022-07-15 17:28:54 - train: epoch 0036, iter [05000, 05004], lr: 0.010000, loss: 2.4634
2022-07-15 17:28:55 - train: epoch 036, train_loss: 2.4066
2022-07-15 17:30:10 - eval: epoch: 036, acc1: 53.624%, acc5: 76.968%, test_loss: 2.0720, per_image_load_time: 2.417ms, per_image_inference_time: 0.144ms
2022-07-15 17:30:10 - until epoch: 036, best_acc1: 53.720%
2022-07-15 17:30:10 - epoch 037 lr: 0.010000
2022-07-15 17:30:48 - train: epoch 0037, iter [00100, 05004], lr: 0.010000, loss: 2.2190
2022-07-15 17:31:22 - train: epoch 0037, iter [00200, 05004], lr: 0.010000, loss: 2.1413
2022-07-15 17:31:56 - train: epoch 0037, iter [00300, 05004], lr: 0.010000, loss: 2.2946
2022-07-15 17:32:30 - train: epoch 0037, iter [00400, 05004], lr: 0.010000, loss: 2.3044
2022-07-15 17:33:03 - train: epoch 0037, iter [00500, 05004], lr: 0.010000, loss: 2.4287
2022-07-15 17:33:36 - train: epoch 0037, iter [00600, 05004], lr: 0.010000, loss: 2.5525
2022-07-15 17:34:10 - train: epoch 0037, iter [00700, 05004], lr: 0.010000, loss: 2.3189
2022-07-15 17:34:43 - train: epoch 0037, iter [00800, 05004], lr: 0.010000, loss: 2.5011
2022-07-15 17:35:16 - train: epoch 0037, iter [00900, 05004], lr: 0.010000, loss: 2.6457
2022-07-15 17:35:49 - train: epoch 0037, iter [01000, 05004], lr: 0.010000, loss: 2.2143
2022-07-15 17:36:23 - train: epoch 0037, iter [01100, 05004], lr: 0.010000, loss: 2.4587
2022-07-15 17:36:55 - train: epoch 0037, iter [01200, 05004], lr: 0.010000, loss: 2.5137
2022-07-15 17:37:29 - train: epoch 0037, iter [01300, 05004], lr: 0.010000, loss: 2.4308
2022-07-15 17:38:02 - train: epoch 0037, iter [01400, 05004], lr: 0.010000, loss: 2.6184
2022-07-15 17:38:35 - train: epoch 0037, iter [01500, 05004], lr: 0.010000, loss: 2.2854
2022-07-15 17:39:08 - train: epoch 0037, iter [01600, 05004], lr: 0.010000, loss: 2.1804
2022-07-15 17:39:42 - train: epoch 0037, iter [01700, 05004], lr: 0.010000, loss: 2.4673
2022-07-15 17:40:16 - train: epoch 0037, iter [01800, 05004], lr: 0.010000, loss: 2.5114
2022-07-15 17:40:48 - train: epoch 0037, iter [01900, 05004], lr: 0.010000, loss: 2.4335
2022-07-15 17:41:21 - train: epoch 0037, iter [02000, 05004], lr: 0.010000, loss: 2.4770
2022-07-15 17:41:54 - train: epoch 0037, iter [02100, 05004], lr: 0.010000, loss: 2.4585
2022-07-15 17:42:28 - train: epoch 0037, iter [02200, 05004], lr: 0.010000, loss: 2.3588
2022-07-15 17:43:01 - train: epoch 0037, iter [02300, 05004], lr: 0.010000, loss: 2.2912
2022-07-15 17:43:34 - train: epoch 0037, iter [02400, 05004], lr: 0.010000, loss: 2.5681
2022-07-15 17:44:07 - train: epoch 0037, iter [02500, 05004], lr: 0.010000, loss: 2.3556
2022-07-15 17:44:42 - train: epoch 0037, iter [02600, 05004], lr: 0.010000, loss: 2.5620
2022-07-15 17:45:14 - train: epoch 0037, iter [02700, 05004], lr: 0.010000, loss: 2.5460
2022-07-15 17:45:49 - train: epoch 0037, iter [02800, 05004], lr: 0.010000, loss: 2.2880
2022-07-15 17:46:21 - train: epoch 0037, iter [02900, 05004], lr: 0.010000, loss: 2.3347
2022-07-15 17:46:55 - train: epoch 0037, iter [03000, 05004], lr: 0.010000, loss: 2.5107
2022-07-15 17:47:28 - train: epoch 0037, iter [03100, 05004], lr: 0.010000, loss: 2.2464
2022-07-15 17:48:02 - train: epoch 0037, iter [03200, 05004], lr: 0.010000, loss: 2.3910
2022-07-15 17:48:35 - train: epoch 0037, iter [03300, 05004], lr: 0.010000, loss: 2.2963
2022-07-15 17:49:09 - train: epoch 0037, iter [03400, 05004], lr: 0.010000, loss: 2.2500
2022-07-15 17:49:42 - train: epoch 0037, iter [03500, 05004], lr: 0.010000, loss: 2.4735
2022-07-15 17:50:16 - train: epoch 0037, iter [03600, 05004], lr: 0.010000, loss: 2.5361
2022-07-15 17:50:48 - train: epoch 0037, iter [03700, 05004], lr: 0.010000, loss: 2.4751
2022-07-15 17:51:22 - train: epoch 0037, iter [03800, 05004], lr: 0.010000, loss: 2.2470
2022-07-15 17:51:54 - train: epoch 0037, iter [03900, 05004], lr: 0.010000, loss: 2.5560
2022-07-15 17:52:28 - train: epoch 0037, iter [04000, 05004], lr: 0.010000, loss: 2.4081
2022-07-15 17:53:01 - train: epoch 0037, iter [04100, 05004], lr: 0.010000, loss: 2.4351
2022-07-15 17:53:34 - train: epoch 0037, iter [04200, 05004], lr: 0.010000, loss: 2.7227
2022-07-15 17:54:08 - train: epoch 0037, iter [04300, 05004], lr: 0.010000, loss: 2.3538
2022-07-15 17:54:41 - train: epoch 0037, iter [04400, 05004], lr: 0.010000, loss: 2.4033
2022-07-15 17:55:15 - train: epoch 0037, iter [04500, 05004], lr: 0.010000, loss: 2.3423
2022-07-15 17:55:48 - train: epoch 0037, iter [04600, 05004], lr: 0.010000, loss: 2.2756
2022-07-15 17:56:22 - train: epoch 0037, iter [04700, 05004], lr: 0.010000, loss: 2.3544
2022-07-15 17:56:55 - train: epoch 0037, iter [04800, 05004], lr: 0.010000, loss: 2.2924
2022-07-15 17:57:29 - train: epoch 0037, iter [04900, 05004], lr: 0.010000, loss: 2.3178
2022-07-15 17:58:00 - train: epoch 0037, iter [05000, 05004], lr: 0.010000, loss: 2.3672
2022-07-15 17:58:01 - train: epoch 037, train_loss: 2.4050
2022-07-15 17:59:16 - eval: epoch: 037, acc1: 53.740%, acc5: 77.170%, test_loss: 2.0660, per_image_load_time: 2.171ms, per_image_inference_time: 0.132ms
2022-07-15 17:59:16 - until epoch: 037, best_acc1: 53.740%
2022-07-15 17:59:16 - epoch 038 lr: 0.010000
2022-07-15 17:59:54 - train: epoch 0038, iter [00100, 05004], lr: 0.010000, loss: 2.3558
2022-07-15 18:00:28 - train: epoch 0038, iter [00200, 05004], lr: 0.010000, loss: 2.3184
2022-07-15 18:01:00 - train: epoch 0038, iter [00300, 05004], lr: 0.010000, loss: 2.1075
2022-07-15 18:01:34 - train: epoch 0038, iter [00400, 05004], lr: 0.010000, loss: 2.3172
2022-07-15 18:02:08 - train: epoch 0038, iter [00500, 05004], lr: 0.010000, loss: 2.2396
2022-07-15 18:02:40 - train: epoch 0038, iter [00600, 05004], lr: 0.010000, loss: 2.6208
2022-07-15 18:03:13 - train: epoch 0038, iter [00700, 05004], lr: 0.010000, loss: 2.1303
2022-07-15 18:03:46 - train: epoch 0038, iter [00800, 05004], lr: 0.010000, loss: 2.2439
2022-07-15 18:04:20 - train: epoch 0038, iter [00900, 05004], lr: 0.010000, loss: 2.4253
2022-07-15 18:04:53 - train: epoch 0038, iter [01000, 05004], lr: 0.010000, loss: 2.5366
2022-07-15 18:05:26 - train: epoch 0038, iter [01100, 05004], lr: 0.010000, loss: 2.4823
2022-07-15 18:05:58 - train: epoch 0038, iter [01200, 05004], lr: 0.010000, loss: 2.4024
2022-07-15 18:06:31 - train: epoch 0038, iter [01300, 05004], lr: 0.010000, loss: 2.6835
2022-07-15 18:07:06 - train: epoch 0038, iter [01400, 05004], lr: 0.010000, loss: 2.4111
2022-07-15 18:07:39 - train: epoch 0038, iter [01500, 05004], lr: 0.010000, loss: 2.4270
2022-07-15 18:08:11 - train: epoch 0038, iter [01600, 05004], lr: 0.010000, loss: 2.4996
2022-07-15 18:08:46 - train: epoch 0038, iter [01700, 05004], lr: 0.010000, loss: 2.5265
2022-07-15 18:09:18 - train: epoch 0038, iter [01800, 05004], lr: 0.010000, loss: 2.4850
2022-07-15 18:09:52 - train: epoch 0038, iter [01900, 05004], lr: 0.010000, loss: 2.4048
2022-07-15 18:10:24 - train: epoch 0038, iter [02000, 05004], lr: 0.010000, loss: 2.2246
2022-07-15 18:10:58 - train: epoch 0038, iter [02100, 05004], lr: 0.010000, loss: 2.3385
2022-07-15 18:11:31 - train: epoch 0038, iter [02200, 05004], lr: 0.010000, loss: 2.2215
2022-07-15 18:12:04 - train: epoch 0038, iter [02300, 05004], lr: 0.010000, loss: 2.6405
2022-07-15 18:12:38 - train: epoch 0038, iter [02400, 05004], lr: 0.010000, loss: 2.7144
2022-07-15 18:13:12 - train: epoch 0038, iter [02500, 05004], lr: 0.010000, loss: 2.3839
2022-07-15 18:13:44 - train: epoch 0038, iter [02600, 05004], lr: 0.010000, loss: 2.3552
2022-07-15 18:14:18 - train: epoch 0038, iter [02700, 05004], lr: 0.010000, loss: 2.4374
2022-07-15 18:14:51 - train: epoch 0038, iter [02800, 05004], lr: 0.010000, loss: 2.5872
2022-07-15 18:15:26 - train: epoch 0038, iter [02900, 05004], lr: 0.010000, loss: 2.4659
2022-07-15 18:15:58 - train: epoch 0038, iter [03000, 05004], lr: 0.010000, loss: 2.2992
2022-07-15 18:16:31 - train: epoch 0038, iter [03100, 05004], lr: 0.010000, loss: 2.4488
2022-07-15 18:17:04 - train: epoch 0038, iter [03200, 05004], lr: 0.010000, loss: 2.0544
2022-07-15 18:17:38 - train: epoch 0038, iter [03300, 05004], lr: 0.010000, loss: 2.2592
2022-07-15 18:18:11 - train: epoch 0038, iter [03400, 05004], lr: 0.010000, loss: 2.3655
2022-07-15 18:18:44 - train: epoch 0038, iter [03500, 05004], lr: 0.010000, loss: 2.2878
2022-07-15 18:19:17 - train: epoch 0038, iter [03600, 05004], lr: 0.010000, loss: 2.4449
2022-07-15 18:19:52 - train: epoch 0038, iter [03700, 05004], lr: 0.010000, loss: 2.1238
2022-07-15 18:20:25 - train: epoch 0038, iter [03800, 05004], lr: 0.010000, loss: 2.6636
2022-07-15 18:20:57 - train: epoch 0038, iter [03900, 05004], lr: 0.010000, loss: 2.4742
2022-07-15 18:21:31 - train: epoch 0038, iter [04000, 05004], lr: 0.010000, loss: 2.4963
2022-07-15 18:22:04 - train: epoch 0038, iter [04100, 05004], lr: 0.010000, loss: 2.3185
2022-07-15 18:22:38 - train: epoch 0038, iter [04200, 05004], lr: 0.010000, loss: 2.1437
2022-07-15 18:23:11 - train: epoch 0038, iter [04300, 05004], lr: 0.010000, loss: 2.4578
2022-07-15 18:23:45 - train: epoch 0038, iter [04400, 05004], lr: 0.010000, loss: 2.4492
2022-07-15 18:24:18 - train: epoch 0038, iter [04500, 05004], lr: 0.010000, loss: 2.5143
2022-07-15 18:24:51 - train: epoch 0038, iter [04600, 05004], lr: 0.010000, loss: 2.5700
2022-07-15 18:25:24 - train: epoch 0038, iter [04700, 05004], lr: 0.010000, loss: 2.2786
2022-07-15 18:25:57 - train: epoch 0038, iter [04800, 05004], lr: 0.010000, loss: 2.4116
2022-07-15 18:26:31 - train: epoch 0038, iter [04900, 05004], lr: 0.010000, loss: 2.2942
2022-07-15 18:27:02 - train: epoch 0038, iter [05000, 05004], lr: 0.010000, loss: 2.2576
2022-07-15 18:27:03 - train: epoch 038, train_loss: 2.4013
2022-07-15 18:28:18 - eval: epoch: 038, acc1: 54.094%, acc5: 77.178%, test_loss: 2.0665, per_image_load_time: 2.036ms, per_image_inference_time: 0.125ms
2022-07-15 18:28:18 - until epoch: 038, best_acc1: 54.094%
2022-07-15 18:28:18 - epoch 039 lr: 0.010000
2022-07-15 18:28:57 - train: epoch 0039, iter [00100, 05004], lr: 0.010000, loss: 2.4786
2022-07-15 18:29:31 - train: epoch 0039, iter [00200, 05004], lr: 0.010000, loss: 2.4253
2022-07-15 18:30:03 - train: epoch 0039, iter [00300, 05004], lr: 0.010000, loss: 2.1454
2022-07-15 18:30:37 - train: epoch 0039, iter [00400, 05004], lr: 0.010000, loss: 2.4411
2022-07-15 18:31:09 - train: epoch 0039, iter [00500, 05004], lr: 0.010000, loss: 2.4084
2022-07-15 18:31:42 - train: epoch 0039, iter [00600, 05004], lr: 0.010000, loss: 2.3010
2022-07-15 18:32:16 - train: epoch 0039, iter [00700, 05004], lr: 0.010000, loss: 2.5792
2022-07-15 18:32:49 - train: epoch 0039, iter [00800, 05004], lr: 0.010000, loss: 2.3167
2022-07-15 18:33:23 - train: epoch 0039, iter [00900, 05004], lr: 0.010000, loss: 2.5270
2022-07-15 18:33:56 - train: epoch 0039, iter [01000, 05004], lr: 0.010000, loss: 2.2107
2022-07-15 18:34:29 - train: epoch 0039, iter [01100, 05004], lr: 0.010000, loss: 2.4729
2022-07-15 18:35:03 - train: epoch 0039, iter [01200, 05004], lr: 0.010000, loss: 2.6103
2022-07-15 18:35:35 - train: epoch 0039, iter [01300, 05004], lr: 0.010000, loss: 2.7057
2022-07-15 18:36:09 - train: epoch 0039, iter [01400, 05004], lr: 0.010000, loss: 2.5543
2022-07-15 18:36:41 - train: epoch 0039, iter [01500, 05004], lr: 0.010000, loss: 2.4277
2022-07-15 18:37:14 - train: epoch 0039, iter [01600, 05004], lr: 0.010000, loss: 2.4411
2022-07-15 18:37:48 - train: epoch 0039, iter [01700, 05004], lr: 0.010000, loss: 2.1910
2022-07-15 18:38:21 - train: epoch 0039, iter [01800, 05004], lr: 0.010000, loss: 2.2702
2022-07-15 18:38:54 - train: epoch 0039, iter [01900, 05004], lr: 0.010000, loss: 2.1129
2022-07-15 18:39:27 - train: epoch 0039, iter [02000, 05004], lr: 0.010000, loss: 2.4602
2022-07-15 18:40:00 - train: epoch 0039, iter [02100, 05004], lr: 0.010000, loss: 2.5181
2022-07-15 18:40:33 - train: epoch 0039, iter [02200, 05004], lr: 0.010000, loss: 2.4615
2022-07-15 18:41:06 - train: epoch 0039, iter [02300, 05004], lr: 0.010000, loss: 2.6974
2022-07-15 18:41:40 - train: epoch 0039, iter [02400, 05004], lr: 0.010000, loss: 2.4936
2022-07-15 18:42:12 - train: epoch 0039, iter [02500, 05004], lr: 0.010000, loss: 2.2810
2022-07-15 18:42:46 - train: epoch 0039, iter [02600, 05004], lr: 0.010000, loss: 2.3852
2022-07-15 18:43:19 - train: epoch 0039, iter [02700, 05004], lr: 0.010000, loss: 2.5221
2022-07-15 18:43:52 - train: epoch 0039, iter [02800, 05004], lr: 0.010000, loss: 2.3820
2022-07-15 18:44:26 - train: epoch 0039, iter [02900, 05004], lr: 0.010000, loss: 2.1425
2022-07-15 18:45:00 - train: epoch 0039, iter [03000, 05004], lr: 0.010000, loss: 2.4964
2022-07-15 18:45:33 - train: epoch 0039, iter [03100, 05004], lr: 0.010000, loss: 2.3966
2022-07-15 18:46:06 - train: epoch 0039, iter [03200, 05004], lr: 0.010000, loss: 2.3919
2022-07-15 18:46:39 - train: epoch 0039, iter [03300, 05004], lr: 0.010000, loss: 2.4215
2022-07-15 18:47:13 - train: epoch 0039, iter [03400, 05004], lr: 0.010000, loss: 2.5191
2022-07-15 18:47:45 - train: epoch 0039, iter [03500, 05004], lr: 0.010000, loss: 2.7172
2022-07-15 18:48:19 - train: epoch 0039, iter [03600, 05004], lr: 0.010000, loss: 2.5569
2022-07-15 18:48:52 - train: epoch 0039, iter [03700, 05004], lr: 0.010000, loss: 2.3900
2022-07-15 18:49:25 - train: epoch 0039, iter [03800, 05004], lr: 0.010000, loss: 2.2760
2022-07-15 18:49:58 - train: epoch 0039, iter [03900, 05004], lr: 0.010000, loss: 2.6057
2022-07-15 18:50:33 - train: epoch 0039, iter [04000, 05004], lr: 0.010000, loss: 2.2828
2022-07-15 18:51:05 - train: epoch 0039, iter [04100, 05004], lr: 0.010000, loss: 2.5006
2022-07-15 18:51:39 - train: epoch 0039, iter [04200, 05004], lr: 0.010000, loss: 2.4812
2022-07-15 18:52:11 - train: epoch 0039, iter [04300, 05004], lr: 0.010000, loss: 2.4796
2022-07-15 18:52:45 - train: epoch 0039, iter [04400, 05004], lr: 0.010000, loss: 2.1604
2022-07-15 18:53:17 - train: epoch 0039, iter [04500, 05004], lr: 0.010000, loss: 2.2979
2022-07-15 18:53:52 - train: epoch 0039, iter [04600, 05004], lr: 0.010000, loss: 2.5921
2022-07-15 18:54:24 - train: epoch 0039, iter [04700, 05004], lr: 0.010000, loss: 2.4749
2022-07-15 18:54:57 - train: epoch 0039, iter [04800, 05004], lr: 0.010000, loss: 2.4000
2022-07-15 18:55:31 - train: epoch 0039, iter [04900, 05004], lr: 0.010000, loss: 2.3876
2022-07-15 18:56:03 - train: epoch 0039, iter [05000, 05004], lr: 0.010000, loss: 2.2422
2022-07-15 18:56:04 - train: epoch 039, train_loss: 2.3998
2022-07-15 18:57:18 - eval: epoch: 039, acc1: 53.110%, acc5: 77.070%, test_loss: 2.0885, per_image_load_time: 2.059ms, per_image_inference_time: 0.138ms
2022-07-15 18:57:18 - until epoch: 039, best_acc1: 54.094%
2022-07-15 18:57:18 - epoch 040 lr: 0.010000
2022-07-15 18:57:57 - train: epoch 0040, iter [00100, 05004], lr: 0.010000, loss: 2.7630
2022-07-15 18:58:30 - train: epoch 0040, iter [00200, 05004], lr: 0.010000, loss: 2.6602
2022-07-15 18:59:05 - train: epoch 0040, iter [00300, 05004], lr: 0.010000, loss: 2.4289
2022-07-15 18:59:37 - train: epoch 0040, iter [00400, 05004], lr: 0.010000, loss: 2.4449
2022-07-15 19:00:10 - train: epoch 0040, iter [00500, 05004], lr: 0.010000, loss: 2.2391
2022-07-15 19:00:43 - train: epoch 0040, iter [00600, 05004], lr: 0.010000, loss: 2.5188
2022-07-15 19:01:16 - train: epoch 0040, iter [00700, 05004], lr: 0.010000, loss: 2.4718
2022-07-15 19:01:49 - train: epoch 0040, iter [00800, 05004], lr: 0.010000, loss: 2.5750
2022-07-15 19:02:21 - train: epoch 0040, iter [00900, 05004], lr: 0.010000, loss: 2.3285
2022-07-15 19:02:55 - train: epoch 0040, iter [01000, 05004], lr: 0.010000, loss: 2.1074
2022-07-15 19:03:27 - train: epoch 0040, iter [01100, 05004], lr: 0.010000, loss: 2.4540
2022-07-15 19:04:01 - train: epoch 0040, iter [01200, 05004], lr: 0.010000, loss: 2.3957
2022-07-15 19:04:33 - train: epoch 0040, iter [01300, 05004], lr: 0.010000, loss: 2.2148
2022-07-15 19:05:06 - train: epoch 0040, iter [01400, 05004], lr: 0.010000, loss: 2.1865
2022-07-15 19:05:39 - train: epoch 0040, iter [01500, 05004], lr: 0.010000, loss: 2.4938
2022-07-15 19:06:12 - train: epoch 0040, iter [01600, 05004], lr: 0.010000, loss: 2.4218
2022-07-15 19:06:45 - train: epoch 0040, iter [01700, 05004], lr: 0.010000, loss: 2.5728
2022-07-15 19:07:18 - train: epoch 0040, iter [01800, 05004], lr: 0.010000, loss: 2.2875
2022-07-15 19:07:52 - train: epoch 0040, iter [01900, 05004], lr: 0.010000, loss: 2.2865
2022-07-15 19:08:24 - train: epoch 0040, iter [02000, 05004], lr: 0.010000, loss: 2.4609
2022-07-15 19:08:58 - train: epoch 0040, iter [02100, 05004], lr: 0.010000, loss: 2.3041
2022-07-15 19:09:31 - train: epoch 0040, iter [02200, 05004], lr: 0.010000, loss: 2.2356
2022-07-15 19:10:04 - train: epoch 0040, iter [02300, 05004], lr: 0.010000, loss: 2.3698
2022-07-15 19:10:38 - train: epoch 0040, iter [02400, 05004], lr: 0.010000, loss: 2.4060
2022-07-15 19:11:11 - train: epoch 0040, iter [02500, 05004], lr: 0.010000, loss: 2.5961
2022-07-15 19:11:44 - train: epoch 0040, iter [02600, 05004], lr: 0.010000, loss: 2.3266
2022-07-15 19:12:17 - train: epoch 0040, iter [02700, 05004], lr: 0.010000, loss: 2.6501
2022-07-15 19:12:50 - train: epoch 0040, iter [02800, 05004], lr: 0.010000, loss: 2.4354
2022-07-15 19:13:24 - train: epoch 0040, iter [02900, 05004], lr: 0.010000, loss: 2.6416
2022-07-15 19:13:56 - train: epoch 0040, iter [03000, 05004], lr: 0.010000, loss: 2.3731
2022-07-15 19:14:30 - train: epoch 0040, iter [03100, 05004], lr: 0.010000, loss: 2.3721
2022-07-15 19:15:03 - train: epoch 0040, iter [03200, 05004], lr: 0.010000, loss: 2.6321
2022-07-15 19:15:37 - train: epoch 0040, iter [03300, 05004], lr: 0.010000, loss: 2.3560
2022-07-15 19:16:09 - train: epoch 0040, iter [03400, 05004], lr: 0.010000, loss: 2.3396
2022-07-15 19:16:42 - train: epoch 0040, iter [03500, 05004], lr: 0.010000, loss: 2.4094
2022-07-15 19:17:16 - train: epoch 0040, iter [03600, 05004], lr: 0.010000, loss: 2.4246
2022-07-15 19:17:49 - train: epoch 0040, iter [03700, 05004], lr: 0.010000, loss: 2.4911
2022-07-15 19:18:23 - train: epoch 0040, iter [03800, 05004], lr: 0.010000, loss: 2.2718
2022-07-15 19:18:55 - train: epoch 0040, iter [03900, 05004], lr: 0.010000, loss: 2.4135
2022-07-15 19:19:30 - train: epoch 0040, iter [04000, 05004], lr: 0.010000, loss: 2.4780
2022-07-15 19:20:02 - train: epoch 0040, iter [04100, 05004], lr: 0.010000, loss: 2.5347
2022-07-15 19:20:36 - train: epoch 0040, iter [04200, 05004], lr: 0.010000, loss: 2.2596
2022-07-15 19:21:08 - train: epoch 0040, iter [04300, 05004], lr: 0.010000, loss: 2.3040
2022-07-15 19:21:43 - train: epoch 0040, iter [04400, 05004], lr: 0.010000, loss: 2.4379
2022-07-15 19:22:15 - train: epoch 0040, iter [04500, 05004], lr: 0.010000, loss: 2.1555
2022-07-15 19:22:49 - train: epoch 0040, iter [04600, 05004], lr: 0.010000, loss: 2.3644
2022-07-15 19:23:22 - train: epoch 0040, iter [04700, 05004], lr: 0.010000, loss: 2.3622
2022-07-15 19:23:56 - train: epoch 0040, iter [04800, 05004], lr: 0.010000, loss: 2.3571
2022-07-15 19:24:29 - train: epoch 0040, iter [04900, 05004], lr: 0.010000, loss: 2.5552
2022-07-15 19:25:01 - train: epoch 0040, iter [05000, 05004], lr: 0.010000, loss: 2.4576
2022-07-15 19:25:01 - train: epoch 040, train_loss: 2.4004
2022-07-15 19:26:16 - eval: epoch: 040, acc1: 53.560%, acc5: 76.730%, test_loss: 2.0856, per_image_load_time: 2.210ms, per_image_inference_time: 0.133ms
2022-07-15 19:26:16 - until epoch: 040, best_acc1: 54.094%
2022-07-15 19:26:16 - epoch 041 lr: 0.010000
2022-07-15 19:26:54 - train: epoch 0041, iter [00100, 05004], lr: 0.010000, loss: 2.5511
2022-07-15 19:27:28 - train: epoch 0041, iter [00200, 05004], lr: 0.010000, loss: 2.6808
2022-07-15 19:28:01 - train: epoch 0041, iter [00300, 05004], lr: 0.010000, loss: 2.3832
2022-07-15 19:28:35 - train: epoch 0041, iter [00400, 05004], lr: 0.010000, loss: 2.4254
2022-07-15 19:29:08 - train: epoch 0041, iter [00500, 05004], lr: 0.010000, loss: 2.0514
2022-07-15 19:29:41 - train: epoch 0041, iter [00600, 05004], lr: 0.010000, loss: 2.4803
2022-07-15 19:30:14 - train: epoch 0041, iter [00700, 05004], lr: 0.010000, loss: 2.3084
2022-07-15 19:30:48 - train: epoch 0041, iter [00800, 05004], lr: 0.010000, loss: 2.1259
2022-07-15 19:31:21 - train: epoch 0041, iter [00900, 05004], lr: 0.010000, loss: 2.1041
2022-07-15 19:31:54 - train: epoch 0041, iter [01000, 05004], lr: 0.010000, loss: 2.5394
2022-07-15 19:32:27 - train: epoch 0041, iter [01100, 05004], lr: 0.010000, loss: 2.4073
2022-07-15 19:33:01 - train: epoch 0041, iter [01200, 05004], lr: 0.010000, loss: 2.0699
2022-07-15 19:33:33 - train: epoch 0041, iter [01300, 05004], lr: 0.010000, loss: 2.5842
2022-07-15 19:34:07 - train: epoch 0041, iter [01400, 05004], lr: 0.010000, loss: 2.4958
2022-07-15 19:34:40 - train: epoch 0041, iter [01500, 05004], lr: 0.010000, loss: 2.6955
2022-07-15 19:35:14 - train: epoch 0041, iter [01600, 05004], lr: 0.010000, loss: 2.1435
2022-07-15 19:35:47 - train: epoch 0041, iter [01700, 05004], lr: 0.010000, loss: 2.3973
2022-07-15 19:36:21 - train: epoch 0041, iter [01800, 05004], lr: 0.010000, loss: 2.3988
2022-07-15 19:36:54 - train: epoch 0041, iter [01900, 05004], lr: 0.010000, loss: 2.6476
2022-07-15 19:37:27 - train: epoch 0041, iter [02000, 05004], lr: 0.010000, loss: 2.4086
2022-07-15 19:38:00 - train: epoch 0041, iter [02100, 05004], lr: 0.010000, loss: 2.2741
2022-07-15 19:38:33 - train: epoch 0041, iter [02200, 05004], lr: 0.010000, loss: 2.3028
2022-07-15 19:39:06 - train: epoch 0041, iter [02300, 05004], lr: 0.010000, loss: 2.1948
2022-07-15 19:39:40 - train: epoch 0041, iter [02400, 05004], lr: 0.010000, loss: 2.6743
2022-07-15 19:40:12 - train: epoch 0041, iter [02500, 05004], lr: 0.010000, loss: 2.0664
2022-07-15 19:40:47 - train: epoch 0041, iter [02600, 05004], lr: 0.010000, loss: 2.6311
2022-07-15 19:41:19 - train: epoch 0041, iter [02700, 05004], lr: 0.010000, loss: 2.5741
2022-07-15 19:41:53 - train: epoch 0041, iter [02800, 05004], lr: 0.010000, loss: 2.3750
2022-07-15 19:42:27 - train: epoch 0041, iter [02900, 05004], lr: 0.010000, loss: 2.4375
2022-07-15 19:43:00 - train: epoch 0041, iter [03000, 05004], lr: 0.010000, loss: 2.5313
2022-07-15 19:43:33 - train: epoch 0041, iter [03100, 05004], lr: 0.010000, loss: 2.4799
2022-07-15 19:44:06 - train: epoch 0041, iter [03200, 05004], lr: 0.010000, loss: 2.4552
2022-07-15 19:44:39 - train: epoch 0041, iter [03300, 05004], lr: 0.010000, loss: 2.1991
2022-07-15 19:45:14 - train: epoch 0041, iter [03400, 05004], lr: 0.010000, loss: 2.1620
2022-07-15 19:45:47 - train: epoch 0041, iter [03500, 05004], lr: 0.010000, loss: 2.4009
2022-07-15 19:46:20 - train: epoch 0041, iter [03600, 05004], lr: 0.010000, loss: 2.6301
2022-07-15 19:46:53 - train: epoch 0041, iter [03700, 05004], lr: 0.010000, loss: 2.5935
2022-07-15 19:47:27 - train: epoch 0041, iter [03800, 05004], lr: 0.010000, loss: 2.2862
2022-07-15 19:48:00 - train: epoch 0041, iter [03900, 05004], lr: 0.010000, loss: 2.4960
2022-07-15 19:48:34 - train: epoch 0041, iter [04000, 05004], lr: 0.010000, loss: 2.3144
2022-07-15 19:49:06 - train: epoch 0041, iter [04100, 05004], lr: 0.010000, loss: 2.4255
2022-07-15 19:49:39 - train: epoch 0041, iter [04200, 05004], lr: 0.010000, loss: 2.3704
2022-07-15 19:50:13 - train: epoch 0041, iter [04300, 05004], lr: 0.010000, loss: 2.4516
2022-07-15 19:50:46 - train: epoch 0041, iter [04400, 05004], lr: 0.010000, loss: 2.3735
2022-07-15 19:51:18 - train: epoch 0041, iter [04500, 05004], lr: 0.010000, loss: 2.3634
2022-07-15 19:51:52 - train: epoch 0041, iter [04600, 05004], lr: 0.010000, loss: 2.4952
2022-07-15 19:52:26 - train: epoch 0041, iter [04700, 05004], lr: 0.010000, loss: 2.5225
2022-07-15 19:52:58 - train: epoch 0041, iter [04800, 05004], lr: 0.010000, loss: 2.4941
2022-07-15 19:53:33 - train: epoch 0041, iter [04900, 05004], lr: 0.010000, loss: 2.3827
2022-07-15 19:54:04 - train: epoch 0041, iter [05000, 05004], lr: 0.010000, loss: 2.3969
2022-07-15 19:54:04 - train: epoch 041, train_loss: 2.4032
2022-07-15 19:55:18 - eval: epoch: 041, acc1: 53.766%, acc5: 77.084%, test_loss: 2.0689, per_image_load_time: 2.496ms, per_image_inference_time: 0.129ms
2022-07-15 19:55:18 - until epoch: 041, best_acc1: 54.094%
2022-07-15 19:55:18 - epoch 042 lr: 0.010000
2022-07-15 19:55:57 - train: epoch 0042, iter [00100, 05004], lr: 0.010000, loss: 2.1537
2022-07-15 19:56:31 - train: epoch 0042, iter [00200, 05004], lr: 0.010000, loss: 2.6492
2022-07-15 19:57:05 - train: epoch 0042, iter [00300, 05004], lr: 0.010000, loss: 2.3874
2022-07-15 19:57:38 - train: epoch 0042, iter [00400, 05004], lr: 0.010000, loss: 2.0462
2022-07-15 19:58:11 - train: epoch 0042, iter [00500, 05004], lr: 0.010000, loss: 2.4758
2022-07-15 19:58:45 - train: epoch 0042, iter [00600, 05004], lr: 0.010000, loss: 2.2511
2022-07-15 19:59:17 - train: epoch 0042, iter [00700, 05004], lr: 0.010000, loss: 2.4389
2022-07-15 19:59:51 - train: epoch 0042, iter [00800, 05004], lr: 0.010000, loss: 2.2920
2022-07-15 20:00:23 - train: epoch 0042, iter [00900, 05004], lr: 0.010000, loss: 2.6021
2022-07-15 20:00:57 - train: epoch 0042, iter [01000, 05004], lr: 0.010000, loss: 2.6081
2022-07-15 20:01:30 - train: epoch 0042, iter [01100, 05004], lr: 0.010000, loss: 2.2781
2022-07-15 20:02:03 - train: epoch 0042, iter [01200, 05004], lr: 0.010000, loss: 2.2652
2022-07-15 20:02:37 - train: epoch 0042, iter [01300, 05004], lr: 0.010000, loss: 2.4559
2022-07-15 20:03:09 - train: epoch 0042, iter [01400, 05004], lr: 0.010000, loss: 2.7512
2022-07-15 20:03:44 - train: epoch 0042, iter [01500, 05004], lr: 0.010000, loss: 2.2549
2022-07-15 20:04:16 - train: epoch 0042, iter [01600, 05004], lr: 0.010000, loss: 2.4342
2022-07-15 20:04:50 - train: epoch 0042, iter [01700, 05004], lr: 0.010000, loss: 2.3563
2022-07-15 20:05:22 - train: epoch 0042, iter [01800, 05004], lr: 0.010000, loss: 2.4687
2022-07-15 20:05:55 - train: epoch 0042, iter [01900, 05004], lr: 0.010000, loss: 2.4717
2022-07-15 20:06:29 - train: epoch 0042, iter [02000, 05004], lr: 0.010000, loss: 2.2257
2022-07-15 20:07:02 - train: epoch 0042, iter [02100, 05004], lr: 0.010000, loss: 2.1101
2022-07-15 20:07:35 - train: epoch 0042, iter [02200, 05004], lr: 0.010000, loss: 2.2977
2022-07-15 20:08:09 - train: epoch 0042, iter [02300, 05004], lr: 0.010000, loss: 2.2944
2022-07-15 20:08:41 - train: epoch 0042, iter [02400, 05004], lr: 0.010000, loss: 2.7832
2022-07-15 20:09:16 - train: epoch 0042, iter [02500, 05004], lr: 0.010000, loss: 2.6129
2022-07-15 20:09:48 - train: epoch 0042, iter [02600, 05004], lr: 0.010000, loss: 2.3649
2022-07-15 20:10:22 - train: epoch 0042, iter [02700, 05004], lr: 0.010000, loss: 2.2828
2022-07-15 20:10:55 - train: epoch 0042, iter [02800, 05004], lr: 0.010000, loss: 2.2428
2022-07-15 20:11:30 - train: epoch 0042, iter [02900, 05004], lr: 0.010000, loss: 2.4633
2022-07-15 20:12:02 - train: epoch 0042, iter [03000, 05004], lr: 0.010000, loss: 2.4314
2022-07-15 20:12:36 - train: epoch 0042, iter [03100, 05004], lr: 0.010000, loss: 2.5232
2022-07-15 20:13:09 - train: epoch 0042, iter [03200, 05004], lr: 0.010000, loss: 2.5561
2022-07-15 20:13:43 - train: epoch 0042, iter [03300, 05004], lr: 0.010000, loss: 2.6079
2022-07-15 20:14:15 - train: epoch 0042, iter [03400, 05004], lr: 0.010000, loss: 2.1665
2022-07-15 20:14:49 - train: epoch 0042, iter [03500, 05004], lr: 0.010000, loss: 2.5336
2022-07-15 20:15:22 - train: epoch 0042, iter [03600, 05004], lr: 0.010000, loss: 2.5724
2022-07-15 20:15:54 - train: epoch 0042, iter [03700, 05004], lr: 0.010000, loss: 2.3685
2022-07-15 20:16:28 - train: epoch 0042, iter [03800, 05004], lr: 0.010000, loss: 2.2331
2022-07-15 20:17:02 - train: epoch 0042, iter [03900, 05004], lr: 0.010000, loss: 2.4185
2022-07-15 20:17:36 - train: epoch 0042, iter [04000, 05004], lr: 0.010000, loss: 2.4550
2022-07-15 20:18:09 - train: epoch 0042, iter [04100, 05004], lr: 0.010000, loss: 2.5815
2022-07-15 20:18:44 - train: epoch 0042, iter [04200, 05004], lr: 0.010000, loss: 2.3806
2022-07-15 20:19:16 - train: epoch 0042, iter [04300, 05004], lr: 0.010000, loss: 2.1983
2022-07-15 20:19:49 - train: epoch 0042, iter [04400, 05004], lr: 0.010000, loss: 2.2676
2022-07-15 20:20:22 - train: epoch 0042, iter [04500, 05004], lr: 0.010000, loss: 2.4073
2022-07-15 20:20:57 - train: epoch 0042, iter [04600, 05004], lr: 0.010000, loss: 2.6909
2022-07-15 20:21:29 - train: epoch 0042, iter [04700, 05004], lr: 0.010000, loss: 2.3390
2022-07-15 20:22:02 - train: epoch 0042, iter [04800, 05004], lr: 0.010000, loss: 2.5404
2022-07-15 20:22:36 - train: epoch 0042, iter [04900, 05004], lr: 0.010000, loss: 2.3798
2022-07-15 20:23:08 - train: epoch 0042, iter [05000, 05004], lr: 0.010000, loss: 2.4033
2022-07-15 20:23:08 - train: epoch 042, train_loss: 2.4017
2022-07-15 20:24:23 - eval: epoch: 042, acc1: 53.402%, acc5: 76.702%, test_loss: 2.0916, per_image_load_time: 2.299ms, per_image_inference_time: 0.125ms
2022-07-15 20:24:23 - until epoch: 042, best_acc1: 54.094%
2022-07-15 20:24:23 - epoch 043 lr: 0.010000
2022-07-15 20:25:02 - train: epoch 0043, iter [00100, 05004], lr: 0.010000, loss: 2.5065
2022-07-15 20:25:35 - train: epoch 0043, iter [00200, 05004], lr: 0.010000, loss: 2.4740
2022-07-15 20:26:09 - train: epoch 0043, iter [00300, 05004], lr: 0.010000, loss: 2.2426
2022-07-15 20:26:41 - train: epoch 0043, iter [00400, 05004], lr: 0.010000, loss: 2.3591
2022-07-15 20:27:16 - train: epoch 0043, iter [00500, 05004], lr: 0.010000, loss: 2.2163
2022-07-15 20:27:48 - train: epoch 0043, iter [00600, 05004], lr: 0.010000, loss: 2.3961
2022-07-15 20:28:22 - train: epoch 0043, iter [00700, 05004], lr: 0.010000, loss: 2.4625
2022-07-15 20:28:56 - train: epoch 0043, iter [00800, 05004], lr: 0.010000, loss: 2.4859
2022-07-15 20:29:28 - train: epoch 0043, iter [00900, 05004], lr: 0.010000, loss: 2.3946
2022-07-15 20:30:02 - train: epoch 0043, iter [01000, 05004], lr: 0.010000, loss: 2.5658
2022-07-15 20:30:34 - train: epoch 0043, iter [01100, 05004], lr: 0.010000, loss: 2.3483
2022-07-15 20:31:08 - train: epoch 0043, iter [01200, 05004], lr: 0.010000, loss: 2.3193
2022-07-15 20:31:41 - train: epoch 0043, iter [01300, 05004], lr: 0.010000, loss: 2.4748
2022-07-15 20:32:15 - train: epoch 0043, iter [01400, 05004], lr: 0.010000, loss: 2.3524
2022-07-15 20:32:48 - train: epoch 0043, iter [01500, 05004], lr: 0.010000, loss: 2.2535
2022-07-15 20:33:20 - train: epoch 0043, iter [01600, 05004], lr: 0.010000, loss: 2.3714
2022-07-15 20:33:54 - train: epoch 0043, iter [01700, 05004], lr: 0.010000, loss: 2.3661
2022-07-15 20:34:27 - train: epoch 0043, iter [01800, 05004], lr: 0.010000, loss: 2.5207
2022-07-15 20:35:01 - train: epoch 0043, iter [01900, 05004], lr: 0.010000, loss: 2.4690
2022-07-15 20:35:34 - train: epoch 0043, iter [02000, 05004], lr: 0.010000, loss: 2.1845
2022-07-15 20:36:07 - train: epoch 0043, iter [02100, 05004], lr: 0.010000, loss: 2.2324
2022-07-15 20:36:40 - train: epoch 0043, iter [02200, 05004], lr: 0.010000, loss: 2.5075
2022-07-15 20:37:14 - train: epoch 0043, iter [02300, 05004], lr: 0.010000, loss: 2.5549
2022-07-15 20:37:47 - train: epoch 0043, iter [02400, 05004], lr: 0.010000, loss: 2.2464
2022-07-15 20:38:20 - train: epoch 0043, iter [02500, 05004], lr: 0.010000, loss: 2.7565
2022-07-15 20:38:54 - train: epoch 0043, iter [02600, 05004], lr: 0.010000, loss: 2.1011
2022-07-15 20:39:26 - train: epoch 0043, iter [02700, 05004], lr: 0.010000, loss: 2.4787
2022-07-15 20:40:00 - train: epoch 0043, iter [02800, 05004], lr: 0.010000, loss: 2.2644
2022-07-15 20:40:34 - train: epoch 0043, iter [02900, 05004], lr: 0.010000, loss: 2.3773
2022-07-15 20:41:07 - train: epoch 0043, iter [03000, 05004], lr: 0.010000, loss: 2.7094
2022-07-15 20:41:40 - train: epoch 0043, iter [03100, 05004], lr: 0.010000, loss: 2.6368
2022-07-15 20:42:14 - train: epoch 0043, iter [03200, 05004], lr: 0.010000, loss: 2.5803
2022-07-15 20:42:48 - train: epoch 0043, iter [03300, 05004], lr: 0.010000, loss: 2.4611
2022-07-15 20:43:20 - train: epoch 0043, iter [03400, 05004], lr: 0.010000, loss: 2.4900
2022-07-15 20:43:54 - train: epoch 0043, iter [03500, 05004], lr: 0.010000, loss: 2.3916
2022-07-15 20:44:27 - train: epoch 0043, iter [03600, 05004], lr: 0.010000, loss: 2.4492
2022-07-15 20:45:00 - train: epoch 0043, iter [03700, 05004], lr: 0.010000, loss: 2.3581
2022-07-15 20:45:34 - train: epoch 0043, iter [03800, 05004], lr: 0.010000, loss: 2.5471
2022-07-15 20:46:07 - train: epoch 0043, iter [03900, 05004], lr: 0.010000, loss: 2.6715
2022-07-15 20:46:40 - train: epoch 0043, iter [04000, 05004], lr: 0.010000, loss: 2.3171
2022-07-15 20:47:14 - train: epoch 0043, iter [04100, 05004], lr: 0.010000, loss: 2.6381
2022-07-15 20:47:48 - train: epoch 0043, iter [04200, 05004], lr: 0.010000, loss: 2.4674
2022-07-15 20:48:21 - train: epoch 0043, iter [04300, 05004], lr: 0.010000, loss: 2.3495
2022-07-15 20:48:55 - train: epoch 0043, iter [04400, 05004], lr: 0.010000, loss: 2.5272
2022-07-15 20:49:28 - train: epoch 0043, iter [04500, 05004], lr: 0.010000, loss: 2.3937
2022-07-15 20:50:02 - train: epoch 0043, iter [04600, 05004], lr: 0.010000, loss: 2.3384
2022-07-15 20:50:35 - train: epoch 0043, iter [04700, 05004], lr: 0.010000, loss: 2.3615
2022-07-15 20:51:08 - train: epoch 0043, iter [04800, 05004], lr: 0.010000, loss: 2.4666
2022-07-15 20:51:42 - train: epoch 0043, iter [04900, 05004], lr: 0.010000, loss: 2.3343
2022-07-15 20:52:14 - train: epoch 0043, iter [05000, 05004], lr: 0.010000, loss: 2.4297
2022-07-15 20:52:14 - train: epoch 043, train_loss: 2.4038
2022-07-15 20:53:29 - eval: epoch: 043, acc1: 53.562%, acc5: 76.968%, test_loss: 2.0834, per_image_load_time: 2.489ms, per_image_inference_time: 0.113ms
2022-07-15 20:53:29 - until epoch: 043, best_acc1: 54.094%
2022-07-15 20:53:29 - epoch 044 lr: 0.010000
2022-07-15 20:54:08 - train: epoch 0044, iter [00100, 05004], lr: 0.010000, loss: 2.4090
2022-07-15 20:54:42 - train: epoch 0044, iter [00200, 05004], lr: 0.010000, loss: 2.5663
2022-07-15 20:55:15 - train: epoch 0044, iter [00300, 05004], lr: 0.010000, loss: 2.2860
2022-07-15 20:55:49 - train: epoch 0044, iter [00400, 05004], lr: 0.010000, loss: 2.1191
2022-07-15 20:56:22 - train: epoch 0044, iter [00500, 05004], lr: 0.010000, loss: 2.2477
2022-07-15 20:56:55 - train: epoch 0044, iter [00600, 05004], lr: 0.010000, loss: 2.0908
2022-07-15 20:57:28 - train: epoch 0044, iter [00700, 05004], lr: 0.010000, loss: 2.2224
2022-07-15 20:58:00 - train: epoch 0044, iter [00800, 05004], lr: 0.010000, loss: 2.4317
2022-07-15 20:58:34 - train: epoch 0044, iter [00900, 05004], lr: 0.010000, loss: 2.4169
2022-07-15 20:59:07 - train: epoch 0044, iter [01000, 05004], lr: 0.010000, loss: 2.3397
2022-07-15 20:59:40 - train: epoch 0044, iter [01100, 05004], lr: 0.010000, loss: 2.1668
2022-07-15 21:00:14 - train: epoch 0044, iter [01200, 05004], lr: 0.010000, loss: 2.2378
2022-07-15 21:00:47 - train: epoch 0044, iter [01300, 05004], lr: 0.010000, loss: 2.2411
2022-07-15 21:01:20 - train: epoch 0044, iter [01400, 05004], lr: 0.010000, loss: 2.2877
2022-07-15 21:01:53 - train: epoch 0044, iter [01500, 05004], lr: 0.010000, loss: 2.2419
2022-07-15 21:02:27 - train: epoch 0044, iter [01600, 05004], lr: 0.010000, loss: 2.4807
2022-07-15 21:03:00 - train: epoch 0044, iter [01700, 05004], lr: 0.010000, loss: 2.2665
2022-07-15 21:03:34 - train: epoch 0044, iter [01800, 05004], lr: 0.010000, loss: 2.3632
2022-07-15 21:04:06 - train: epoch 0044, iter [01900, 05004], lr: 0.010000, loss: 2.5726
2022-07-15 21:04:40 - train: epoch 0044, iter [02000, 05004], lr: 0.010000, loss: 2.3410
2022-07-15 21:05:13 - train: epoch 0044, iter [02100, 05004], lr: 0.010000, loss: 2.5454
2022-07-15 21:05:47 - train: epoch 0044, iter [02200, 05004], lr: 0.010000, loss: 2.3790
2022-07-15 21:06:20 - train: epoch 0044, iter [02300, 05004], lr: 0.010000, loss: 2.4987
2022-07-15 21:06:54 - train: epoch 0044, iter [02400, 05004], lr: 0.010000, loss: 2.3717
2022-07-15 21:07:27 - train: epoch 0044, iter [02500, 05004], lr: 0.010000, loss: 2.4752
2022-07-15 21:08:00 - train: epoch 0044, iter [02600, 05004], lr: 0.010000, loss: 2.3126
2022-07-15 21:08:33 - train: epoch 0044, iter [02700, 05004], lr: 0.010000, loss: 2.4588
2022-07-15 21:09:07 - train: epoch 0044, iter [02800, 05004], lr: 0.010000, loss: 2.1336
2022-07-15 21:09:40 - train: epoch 0044, iter [02900, 05004], lr: 0.010000, loss: 2.2916
2022-07-15 21:10:14 - train: epoch 0044, iter [03000, 05004], lr: 0.010000, loss: 2.2842
2022-07-15 21:10:47 - train: epoch 0044, iter [03100, 05004], lr: 0.010000, loss: 2.3419
2022-07-15 21:11:20 - train: epoch 0044, iter [03200, 05004], lr: 0.010000, loss: 2.3284
2022-07-15 21:11:53 - train: epoch 0044, iter [03300, 05004], lr: 0.010000, loss: 2.2548
2022-07-15 21:12:26 - train: epoch 0044, iter [03400, 05004], lr: 0.010000, loss: 2.7354
2022-07-15 21:13:01 - train: epoch 0044, iter [03500, 05004], lr: 0.010000, loss: 2.2478
2022-07-15 21:13:33 - train: epoch 0044, iter [03600, 05004], lr: 0.010000, loss: 2.6482
2022-07-15 21:14:07 - train: epoch 0044, iter [03700, 05004], lr: 0.010000, loss: 2.4117
2022-07-15 21:14:41 - train: epoch 0044, iter [03800, 05004], lr: 0.010000, loss: 2.0498
2022-07-15 21:15:13 - train: epoch 0044, iter [03900, 05004], lr: 0.010000, loss: 2.5139
2022-07-15 21:15:46 - train: epoch 0044, iter [04000, 05004], lr: 0.010000, loss: 2.4198
2022-07-15 21:16:19 - train: epoch 0044, iter [04100, 05004], lr: 0.010000, loss: 2.2185
2022-07-15 21:16:52 - train: epoch 0044, iter [04200, 05004], lr: 0.010000, loss: 2.5717
2022-07-15 21:17:26 - train: epoch 0044, iter [04300, 05004], lr: 0.010000, loss: 2.6546
2022-07-15 21:17:58 - train: epoch 0044, iter [04400, 05004], lr: 0.010000, loss: 2.1911
2022-07-15 21:18:33 - train: epoch 0044, iter [04500, 05004], lr: 0.010000, loss: 2.6062
2022-07-15 21:19:06 - train: epoch 0044, iter [04600, 05004], lr: 0.010000, loss: 2.5810
2022-07-15 21:19:40 - train: epoch 0044, iter [04700, 05004], lr: 0.010000, loss: 2.4179
2022-07-15 21:20:13 - train: epoch 0044, iter [04800, 05004], lr: 0.010000, loss: 2.6465
2022-07-15 21:20:47 - train: epoch 0044, iter [04900, 05004], lr: 0.010000, loss: 2.2457
2022-07-15 21:21:18 - train: epoch 0044, iter [05000, 05004], lr: 0.010000, loss: 2.5111
2022-07-15 21:21:19 - train: epoch 044, train_loss: 2.4057
2022-07-15 21:22:33 - eval: epoch: 044, acc1: 53.280%, acc5: 76.612%, test_loss: 2.1058, per_image_load_time: 2.220ms, per_image_inference_time: 0.127ms
2022-07-15 21:22:33 - until epoch: 044, best_acc1: 54.094%
2022-07-15 21:22:33 - epoch 045 lr: 0.010000
2022-07-15 21:23:11 - train: epoch 0045, iter [00100, 05004], lr: 0.010000, loss: 2.3084
2022-07-15 21:23:45 - train: epoch 0045, iter [00200, 05004], lr: 0.010000, loss: 2.3788
2022-07-15 21:24:18 - train: epoch 0045, iter [00300, 05004], lr: 0.010000, loss: 2.4722
2022-07-15 21:24:51 - train: epoch 0045, iter [00400, 05004], lr: 0.010000, loss: 2.2773
2022-07-15 21:25:24 - train: epoch 0045, iter [00500, 05004], lr: 0.010000, loss: 2.5982
2022-07-15 21:25:58 - train: epoch 0045, iter [00600, 05004], lr: 0.010000, loss: 2.4435
2022-07-15 21:26:30 - train: epoch 0045, iter [00700, 05004], lr: 0.010000, loss: 2.1380
2022-07-15 21:27:05 - train: epoch 0045, iter [00800, 05004], lr: 0.010000, loss: 2.2705
2022-07-15 21:27:37 - train: epoch 0045, iter [00900, 05004], lr: 0.010000, loss: 2.4181
2022-07-15 21:28:10 - train: epoch 0045, iter [01000, 05004], lr: 0.010000, loss: 2.2763
2022-07-15 21:28:43 - train: epoch 0045, iter [01100, 05004], lr: 0.010000, loss: 2.6165
2022-07-15 21:29:16 - train: epoch 0045, iter [01200, 05004], lr: 0.010000, loss: 2.5172
2022-07-15 21:29:49 - train: epoch 0045, iter [01300, 05004], lr: 0.010000, loss: 2.4274
2022-07-15 21:30:23 - train: epoch 0045, iter [01400, 05004], lr: 0.010000, loss: 2.4940
2022-07-15 21:30:56 - train: epoch 0045, iter [01500, 05004], lr: 0.010000, loss: 2.4204
2022-07-15 21:31:30 - train: epoch 0045, iter [01600, 05004], lr: 0.010000, loss: 2.2713
2022-07-15 21:32:03 - train: epoch 0045, iter [01700, 05004], lr: 0.010000, loss: 2.2863
2022-07-15 21:32:37 - train: epoch 0045, iter [01800, 05004], lr: 0.010000, loss: 2.2551
2022-07-15 21:33:10 - train: epoch 0045, iter [01900, 05004], lr: 0.010000, loss: 2.6545
2022-07-15 21:33:43 - train: epoch 0045, iter [02000, 05004], lr: 0.010000, loss: 2.6415
2022-07-15 21:34:17 - train: epoch 0045, iter [02100, 05004], lr: 0.010000, loss: 2.4725
2022-07-15 21:34:49 - train: epoch 0045, iter [02200, 05004], lr: 0.010000, loss: 2.3981
2022-07-15 21:35:23 - train: epoch 0045, iter [02300, 05004], lr: 0.010000, loss: 2.1495
2022-07-15 21:35:57 - train: epoch 0045, iter [02400, 05004], lr: 0.010000, loss: 2.4919
2022-07-15 21:36:30 - train: epoch 0045, iter [02500, 05004], lr: 0.010000, loss: 2.3567
2022-07-15 21:37:03 - train: epoch 0045, iter [02600, 05004], lr: 0.010000, loss: 2.3816
2022-07-15 21:37:37 - train: epoch 0045, iter [02700, 05004], lr: 0.010000, loss: 2.1957
2022-07-15 21:38:11 - train: epoch 0045, iter [02800, 05004], lr: 0.010000, loss: 2.2846
2022-07-15 21:38:43 - train: epoch 0045, iter [02900, 05004], lr: 0.010000, loss: 2.5374
2022-07-15 21:39:17 - train: epoch 0045, iter [03000, 05004], lr: 0.010000, loss: 2.7718
2022-07-15 21:39:51 - train: epoch 0045, iter [03100, 05004], lr: 0.010000, loss: 2.4256
2022-07-15 21:40:23 - train: epoch 0045, iter [03200, 05004], lr: 0.010000, loss: 2.4910
2022-07-15 21:40:57 - train: epoch 0045, iter [03300, 05004], lr: 0.010000, loss: 2.3258
2022-07-15 21:41:29 - train: epoch 0045, iter [03400, 05004], lr: 0.010000, loss: 2.2111
2022-07-15 21:42:04 - train: epoch 0045, iter [03500, 05004], lr: 0.010000, loss: 2.5801
2022-07-15 21:42:36 - train: epoch 0045, iter [03600, 05004], lr: 0.010000, loss: 2.5334
2022-07-15 21:43:10 - train: epoch 0045, iter [03700, 05004], lr: 0.010000, loss: 2.3607
2022-07-15 21:43:43 - train: epoch 0045, iter [03800, 05004], lr: 0.010000, loss: 2.2316
2022-07-15 21:44:17 - train: epoch 0045, iter [03900, 05004], lr: 0.010000, loss: 2.4884
2022-07-15 21:44:50 - train: epoch 0045, iter [04000, 05004], lr: 0.010000, loss: 2.4624
2022-07-15 21:45:23 - train: epoch 0045, iter [04100, 05004], lr: 0.010000, loss: 2.3179
2022-07-15 21:45:56 - train: epoch 0045, iter [04200, 05004], lr: 0.010000, loss: 2.6798
2022-07-15 21:46:30 - train: epoch 0045, iter [04300, 05004], lr: 0.010000, loss: 2.5746
2022-07-15 21:47:03 - train: epoch 0045, iter [04400, 05004], lr: 0.010000, loss: 2.5708
2022-07-15 21:47:37 - train: epoch 0045, iter [04500, 05004], lr: 0.010000, loss: 2.2052
2022-07-15 21:48:09 - train: epoch 0045, iter [04600, 05004], lr: 0.010000, loss: 2.6414
2022-07-15 21:48:44 - train: epoch 0045, iter [04700, 05004], lr: 0.010000, loss: 2.4375
2022-07-15 21:49:16 - train: epoch 0045, iter [04800, 05004], lr: 0.010000, loss: 2.2065
2022-07-15 21:49:49 - train: epoch 0045, iter [04900, 05004], lr: 0.010000, loss: 2.4000
2022-07-15 21:50:21 - train: epoch 0045, iter [05000, 05004], lr: 0.010000, loss: 2.2347
2022-07-15 21:50:22 - train: epoch 045, train_loss: 2.4030
2022-07-15 21:51:35 - eval: epoch: 045, acc1: 52.940%, acc5: 76.542%, test_loss: 2.1027, per_image_load_time: 1.830ms, per_image_inference_time: 0.127ms
2022-07-15 21:51:35 - until epoch: 045, best_acc1: 54.094%
2022-07-15 21:51:35 - epoch 046 lr: 0.010000
2022-07-15 21:52:14 - train: epoch 0046, iter [00100, 05004], lr: 0.010000, loss: 2.0621
2022-07-15 21:52:47 - train: epoch 0046, iter [00200, 05004], lr: 0.010000, loss: 2.1744
2022-07-15 21:53:21 - train: epoch 0046, iter [00300, 05004], lr: 0.010000, loss: 2.2781
2022-07-15 21:53:54 - train: epoch 0046, iter [00400, 05004], lr: 0.010000, loss: 2.5471
2022-07-15 21:54:27 - train: epoch 0046, iter [00500, 05004], lr: 0.010000, loss: 2.1789
2022-07-15 21:55:00 - train: epoch 0046, iter [00600, 05004], lr: 0.010000, loss: 2.4067
2022-07-15 21:55:32 - train: epoch 0046, iter [00700, 05004], lr: 0.010000, loss: 2.3626
2022-07-15 21:56:06 - train: epoch 0046, iter [00800, 05004], lr: 0.010000, loss: 2.6236
2022-07-15 21:56:38 - train: epoch 0046, iter [00900, 05004], lr: 0.010000, loss: 2.4860
2022-07-15 21:57:11 - train: epoch 0046, iter [01000, 05004], lr: 0.010000, loss: 2.2047
2022-07-15 21:57:43 - train: epoch 0046, iter [01100, 05004], lr: 0.010000, loss: 2.3622
2022-07-15 21:58:17 - train: epoch 0046, iter [01200, 05004], lr: 0.010000, loss: 2.3580
2022-07-15 21:58:49 - train: epoch 0046, iter [01300, 05004], lr: 0.010000, loss: 2.4692
2022-07-15 21:59:23 - train: epoch 0046, iter [01400, 05004], lr: 0.010000, loss: 2.6984
2022-07-15 21:59:55 - train: epoch 0046, iter [01500, 05004], lr: 0.010000, loss: 2.3212
2022-07-15 22:00:29 - train: epoch 0046, iter [01600, 05004], lr: 0.010000, loss: 2.4108
2022-07-15 22:01:01 - train: epoch 0046, iter [01700, 05004], lr: 0.010000, loss: 2.2659
2022-07-15 22:01:35 - train: epoch 0046, iter [01800, 05004], lr: 0.010000, loss: 2.3693
2022-07-15 22:02:07 - train: epoch 0046, iter [01900, 05004], lr: 0.010000, loss: 2.2712
2022-07-15 22:02:40 - train: epoch 0046, iter [02000, 05004], lr: 0.010000, loss: 2.2645
2022-07-15 22:03:14 - train: epoch 0046, iter [02100, 05004], lr: 0.010000, loss: 2.4521
2022-07-15 22:03:46 - train: epoch 0046, iter [02200, 05004], lr: 0.010000, loss: 2.0258
2022-07-15 22:04:20 - train: epoch 0046, iter [02300, 05004], lr: 0.010000, loss: 2.7599
2022-07-15 22:04:53 - train: epoch 0046, iter [02400, 05004], lr: 0.010000, loss: 2.3956
2022-07-15 22:05:26 - train: epoch 0046, iter [02500, 05004], lr: 0.010000, loss: 2.4977
2022-07-15 22:05:59 - train: epoch 0046, iter [02600, 05004], lr: 0.010000, loss: 2.5502
2022-07-15 22:06:33 - train: epoch 0046, iter [02700, 05004], lr: 0.010000, loss: 2.3909
2022-07-15 22:07:05 - train: epoch 0046, iter [02800, 05004], lr: 0.010000, loss: 2.2296
2022-07-15 22:07:39 - train: epoch 0046, iter [02900, 05004], lr: 0.010000, loss: 2.4908
2022-07-15 22:08:11 - train: epoch 0046, iter [03000, 05004], lr: 0.010000, loss: 2.4039
2022-07-15 22:08:45 - train: epoch 0046, iter [03100, 05004], lr: 0.010000, loss: 2.1369
2022-07-15 22:09:17 - train: epoch 0046, iter [03200, 05004], lr: 0.010000, loss: 2.4992
2022-07-15 22:09:52 - train: epoch 0046, iter [03300, 05004], lr: 0.010000, loss: 2.4897
2022-07-15 22:10:24 - train: epoch 0046, iter [03400, 05004], lr: 0.010000, loss: 2.3142
2022-07-15 22:10:59 - train: epoch 0046, iter [03500, 05004], lr: 0.010000, loss: 2.4928
2022-07-15 22:11:31 - train: epoch 0046, iter [03600, 05004], lr: 0.010000, loss: 2.3517
2022-07-15 22:12:04 - train: epoch 0046, iter [03700, 05004], lr: 0.010000, loss: 2.2061
2022-07-15 22:12:37 - train: epoch 0046, iter [03800, 05004], lr: 0.010000, loss: 2.6403
2022-07-15 22:13:10 - train: epoch 0046, iter [03900, 05004], lr: 0.010000, loss: 2.3225
2022-07-15 22:13:44 - train: epoch 0046, iter [04000, 05004], lr: 0.010000, loss: 2.2504
2022-07-15 22:14:17 - train: epoch 0046, iter [04100, 05004], lr: 0.010000, loss: 2.5547
2022-07-15 22:14:50 - train: epoch 0046, iter [04200, 05004], lr: 0.010000, loss: 2.4303
2022-07-15 22:15:23 - train: epoch 0046, iter [04300, 05004], lr: 0.010000, loss: 2.5816
2022-07-15 22:15:56 - train: epoch 0046, iter [04400, 05004], lr: 0.010000, loss: 2.5677
2022-07-15 22:16:30 - train: epoch 0046, iter [04500, 05004], lr: 0.010000, loss: 2.4317
2022-07-15 22:17:03 - train: epoch 0046, iter [04600, 05004], lr: 0.010000, loss: 2.5119
2022-07-15 22:17:36 - train: epoch 0046, iter [04700, 05004], lr: 0.010000, loss: 2.4376
2022-07-15 22:18:09 - train: epoch 0046, iter [04800, 05004], lr: 0.010000, loss: 2.3285
2022-07-15 22:18:43 - train: epoch 0046, iter [04900, 05004], lr: 0.010000, loss: 2.5114
2022-07-15 22:19:14 - train: epoch 0046, iter [05000, 05004], lr: 0.010000, loss: 2.3854
2022-07-15 22:19:15 - train: epoch 046, train_loss: 2.4048
2022-07-15 22:20:30 - eval: epoch: 046, acc1: 53.350%, acc5: 76.786%, test_loss: 2.0911, per_image_load_time: 2.628ms, per_image_inference_time: 0.134ms
2022-07-15 22:20:30 - until epoch: 046, best_acc1: 54.094%
2022-07-15 22:20:30 - epoch 047 lr: 0.010000
2022-07-15 22:21:08 - train: epoch 0047, iter [00100, 05004], lr: 0.010000, loss: 2.2149
2022-07-15 22:21:42 - train: epoch 0047, iter [00200, 05004], lr: 0.010000, loss: 2.6524
2022-07-15 22:22:15 - train: epoch 0047, iter [00300, 05004], lr: 0.010000, loss: 2.2182
2022-07-15 22:22:48 - train: epoch 0047, iter [00400, 05004], lr: 0.010000, loss: 2.2008
2022-07-15 22:23:22 - train: epoch 0047, iter [00500, 05004], lr: 0.010000, loss: 2.4001
2022-07-15 22:23:55 - train: epoch 0047, iter [00600, 05004], lr: 0.010000, loss: 2.4503
2022-07-15 22:24:28 - train: epoch 0047, iter [00700, 05004], lr: 0.010000, loss: 2.3842
2022-07-15 22:25:01 - train: epoch 0047, iter [00800, 05004], lr: 0.010000, loss: 2.3899
2022-07-15 22:25:33 - train: epoch 0047, iter [00900, 05004], lr: 0.010000, loss: 2.5026
2022-07-15 22:26:06 - train: epoch 0047, iter [01000, 05004], lr: 0.010000, loss: 2.3917
2022-07-15 22:26:39 - train: epoch 0047, iter [01100, 05004], lr: 0.010000, loss: 2.5477
2022-07-15 22:27:12 - train: epoch 0047, iter [01200, 05004], lr: 0.010000, loss: 2.4687
2022-07-15 22:27:46 - train: epoch 0047, iter [01300, 05004], lr: 0.010000, loss: 2.5790
2022-07-15 22:28:18 - train: epoch 0047, iter [01400, 05004], lr: 0.010000, loss: 2.3299
2022-07-15 22:28:51 - train: epoch 0047, iter [01500, 05004], lr: 0.010000, loss: 2.2937
2022-07-15 22:29:24 - train: epoch 0047, iter [01600, 05004], lr: 0.010000, loss: 2.3395
2022-07-15 22:29:58 - train: epoch 0047, iter [01700, 05004], lr: 0.010000, loss: 2.2107
2022-07-15 22:30:30 - train: epoch 0047, iter [01800, 05004], lr: 0.010000, loss: 2.2685
2022-07-15 22:31:04 - train: epoch 0047, iter [01900, 05004], lr: 0.010000, loss: 2.3736
2022-07-15 22:31:36 - train: epoch 0047, iter [02000, 05004], lr: 0.010000, loss: 2.3902
2022-07-15 22:32:10 - train: epoch 0047, iter [02100, 05004], lr: 0.010000, loss: 2.5555
2022-07-15 22:32:42 - train: epoch 0047, iter [02200, 05004], lr: 0.010000, loss: 2.5726
2022-07-15 22:33:15 - train: epoch 0047, iter [02300, 05004], lr: 0.010000, loss: 2.3545
2022-07-15 22:33:48 - train: epoch 0047, iter [02400, 05004], lr: 0.010000, loss: 2.2169
2022-07-15 22:34:20 - train: epoch 0047, iter [02500, 05004], lr: 0.010000, loss: 2.2965
2022-07-15 22:34:54 - train: epoch 0047, iter [02600, 05004], lr: 0.010000, loss: 2.6788
2022-07-15 22:35:26 - train: epoch 0047, iter [02700, 05004], lr: 0.010000, loss: 2.3548
2022-07-15 22:36:00 - train: epoch 0047, iter [02800, 05004], lr: 0.010000, loss: 2.5821
2022-07-15 22:36:32 - train: epoch 0047, iter [02900, 05004], lr: 0.010000, loss: 2.3375
2022-07-15 22:37:06 - train: epoch 0047, iter [03000, 05004], lr: 0.010000, loss: 2.5751
2022-07-15 22:37:39 - train: epoch 0047, iter [03100, 05004], lr: 0.010000, loss: 2.2600
2022-07-15 22:38:11 - train: epoch 0047, iter [03200, 05004], lr: 0.010000, loss: 2.7359
2022-07-15 22:38:44 - train: epoch 0047, iter [03300, 05004], lr: 0.010000, loss: 2.3329
2022-07-15 22:39:17 - train: epoch 0047, iter [03400, 05004], lr: 0.010000, loss: 2.2760
2022-07-15 22:39:49 - train: epoch 0047, iter [03500, 05004], lr: 0.010000, loss: 2.5719
2022-07-15 22:40:24 - train: epoch 0047, iter [03600, 05004], lr: 0.010000, loss: 2.5302
2022-07-15 22:40:57 - train: epoch 0047, iter [03700, 05004], lr: 0.010000, loss: 2.7655
2022-07-15 22:41:30 - train: epoch 0047, iter [03800, 05004], lr: 0.010000, loss: 2.4528
2022-07-15 22:42:03 - train: epoch 0047, iter [03900, 05004], lr: 0.010000, loss: 2.2872
2022-07-15 22:42:36 - train: epoch 0047, iter [04000, 05004], lr: 0.010000, loss: 2.4488
2022-07-15 22:43:08 - train: epoch 0047, iter [04100, 05004], lr: 0.010000, loss: 2.4680
2022-07-15 22:43:42 - train: epoch 0047, iter [04200, 05004], lr: 0.010000, loss: 2.5275
2022-07-15 22:44:16 - train: epoch 0047, iter [04300, 05004], lr: 0.010000, loss: 2.3796
2022-07-15 22:44:49 - train: epoch 0047, iter [04400, 05004], lr: 0.010000, loss: 2.3797
2022-07-15 22:45:22 - train: epoch 0047, iter [04500, 05004], lr: 0.010000, loss: 2.4865
2022-07-15 22:45:54 - train: epoch 0047, iter [04600, 05004], lr: 0.010000, loss: 2.4656
2022-07-15 22:46:28 - train: epoch 0047, iter [04700, 05004], lr: 0.010000, loss: 2.3975
2022-07-15 22:47:00 - train: epoch 0047, iter [04800, 05004], lr: 0.010000, loss: 2.3528
2022-07-15 22:47:33 - train: epoch 0047, iter [04900, 05004], lr: 0.010000, loss: 2.6633
2022-07-15 22:48:05 - train: epoch 0047, iter [05000, 05004], lr: 0.010000, loss: 2.3886
2022-07-15 22:48:06 - train: epoch 047, train_loss: 2.4058
2022-07-15 22:49:21 - eval: epoch: 047, acc1: 53.244%, acc5: 76.656%, test_loss: 2.1020, per_image_load_time: 1.866ms, per_image_inference_time: 0.136ms
2022-07-15 22:49:21 - until epoch: 047, best_acc1: 54.094%
2022-07-15 22:49:21 - epoch 048 lr: 0.010000
2022-07-15 22:50:00 - train: epoch 0048, iter [00100, 05004], lr: 0.010000, loss: 2.4653
2022-07-15 22:50:33 - train: epoch 0048, iter [00200, 05004], lr: 0.010000, loss: 2.8236
2022-07-15 22:51:06 - train: epoch 0048, iter [00300, 05004], lr: 0.010000, loss: 2.3096
2022-07-15 22:51:41 - train: epoch 0048, iter [00400, 05004], lr: 0.010000, loss: 2.3635
2022-07-15 22:52:13 - train: epoch 0048, iter [00500, 05004], lr: 0.010000, loss: 2.3296
2022-07-15 22:52:47 - train: epoch 0048, iter [00600, 05004], lr: 0.010000, loss: 2.3089
2022-07-15 22:53:19 - train: epoch 0048, iter [00700, 05004], lr: 0.010000, loss: 2.3905
2022-07-15 22:53:53 - train: epoch 0048, iter [00800, 05004], lr: 0.010000, loss: 2.3960
2022-07-15 22:54:26 - train: epoch 0048, iter [00900, 05004], lr: 0.010000, loss: 2.5542
2022-07-15 22:54:59 - train: epoch 0048, iter [01000, 05004], lr: 0.010000, loss: 2.4909
2022-07-15 22:55:32 - train: epoch 0048, iter [01100, 05004], lr: 0.010000, loss: 2.5193
2022-07-15 22:56:05 - train: epoch 0048, iter [01200, 05004], lr: 0.010000, loss: 2.5387
2022-07-15 22:56:38 - train: epoch 0048, iter [01300, 05004], lr: 0.010000, loss: 2.0558
2022-07-15 22:57:11 - train: epoch 0048, iter [01400, 05004], lr: 0.010000, loss: 2.2029
2022-07-15 22:57:44 - train: epoch 0048, iter [01500, 05004], lr: 0.010000, loss: 2.4400
2022-07-15 22:58:17 - train: epoch 0048, iter [01600, 05004], lr: 0.010000, loss: 2.3109
2022-07-15 22:58:50 - train: epoch 0048, iter [01700, 05004], lr: 0.010000, loss: 2.6239
2022-07-15 22:59:23 - train: epoch 0048, iter [01800, 05004], lr: 0.010000, loss: 2.4224
2022-07-15 22:59:56 - train: epoch 0048, iter [01900, 05004], lr: 0.010000, loss: 2.5050
2022-07-15 23:00:30 - train: epoch 0048, iter [02000, 05004], lr: 0.010000, loss: 2.6324
2022-07-15 23:01:02 - train: epoch 0048, iter [02100, 05004], lr: 0.010000, loss: 2.3708
2022-07-15 23:01:35 - train: epoch 0048, iter [02200, 05004], lr: 0.010000, loss: 2.6051
2022-07-15 23:02:08 - train: epoch 0048, iter [02300, 05004], lr: 0.010000, loss: 2.2256
2022-07-15 23:02:41 - train: epoch 0048, iter [02400, 05004], lr: 0.010000, loss: 2.3454
2022-07-15 23:03:15 - train: epoch 0048, iter [02500, 05004], lr: 0.010000, loss: 2.4590
2022-07-15 23:03:47 - train: epoch 0048, iter [02600, 05004], lr: 0.010000, loss: 2.6312
2022-07-15 23:04:21 - train: epoch 0048, iter [02700, 05004], lr: 0.010000, loss: 2.5352
2022-07-15 23:04:54 - train: epoch 0048, iter [02800, 05004], lr: 0.010000, loss: 2.4042
2022-07-15 23:05:27 - train: epoch 0048, iter [02900, 05004], lr: 0.010000, loss: 2.4426
2022-07-15 23:06:00 - train: epoch 0048, iter [03000, 05004], lr: 0.010000, loss: 2.4237
2022-07-15 23:06:33 - train: epoch 0048, iter [03100, 05004], lr: 0.010000, loss: 2.5070
2022-07-15 23:07:06 - train: epoch 0048, iter [03200, 05004], lr: 0.010000, loss: 2.2478
2022-07-15 23:07:39 - train: epoch 0048, iter [03300, 05004], lr: 0.010000, loss: 2.4441
2022-07-15 23:08:12 - train: epoch 0048, iter [03400, 05004], lr: 0.010000, loss: 2.4651
2022-07-15 23:08:45 - train: epoch 0048, iter [03500, 05004], lr: 0.010000, loss: 2.7750
2022-07-15 23:09:18 - train: epoch 0048, iter [03600, 05004], lr: 0.010000, loss: 2.3546
2022-07-15 23:09:52 - train: epoch 0048, iter [03700, 05004], lr: 0.010000, loss: 2.4821
2022-07-15 23:10:24 - train: epoch 0048, iter [03800, 05004], lr: 0.010000, loss: 2.4560
2022-07-15 23:10:59 - train: epoch 0048, iter [03900, 05004], lr: 0.010000, loss: 2.4550
2022-07-15 23:11:30 - train: epoch 0048, iter [04000, 05004], lr: 0.010000, loss: 2.2319
2022-07-15 23:12:04 - train: epoch 0048, iter [04100, 05004], lr: 0.010000, loss: 2.6039
2022-07-15 23:12:36 - train: epoch 0048, iter [04200, 05004], lr: 0.010000, loss: 2.2801
2022-07-15 23:13:10 - train: epoch 0048, iter [04300, 05004], lr: 0.010000, loss: 2.2933
2022-07-15 23:13:43 - train: epoch 0048, iter [04400, 05004], lr: 0.010000, loss: 2.1794
2022-07-15 23:14:17 - train: epoch 0048, iter [04500, 05004], lr: 0.010000, loss: 2.5461
2022-07-15 23:14:49 - train: epoch 0048, iter [04600, 05004], lr: 0.010000, loss: 2.4546
2022-07-15 23:15:24 - train: epoch 0048, iter [04700, 05004], lr: 0.010000, loss: 2.6010
2022-07-15 23:15:56 - train: epoch 0048, iter [04800, 05004], lr: 0.010000, loss: 2.7784
2022-07-15 23:16:30 - train: epoch 0048, iter [04900, 05004], lr: 0.010000, loss: 2.4424
2022-07-15 23:17:01 - train: epoch 0048, iter [05000, 05004], lr: 0.010000, loss: 2.5437
2022-07-15 23:17:01 - train: epoch 048, train_loss: 2.4080
2022-07-15 23:18:17 - eval: epoch: 048, acc1: 53.370%, acc5: 76.942%, test_loss: 2.0843, per_image_load_time: 1.946ms, per_image_inference_time: 0.123ms
2022-07-15 23:18:17 - until epoch: 048, best_acc1: 54.094%
2022-07-15 23:18:17 - epoch 049 lr: 0.010000
2022-07-15 23:18:55 - train: epoch 0049, iter [00100, 05004], lr: 0.010000, loss: 2.5333
2022-07-15 23:19:29 - train: epoch 0049, iter [00200, 05004], lr: 0.010000, loss: 2.3173
2022-07-15 23:20:02 - train: epoch 0049, iter [00300, 05004], lr: 0.010000, loss: 2.5179
2022-07-15 23:20:35 - train: epoch 0049, iter [00400, 05004], lr: 0.010000, loss: 2.4576
2022-07-15 23:21:08 - train: epoch 0049, iter [00500, 05004], lr: 0.010000, loss: 2.4255
2022-07-15 23:21:41 - train: epoch 0049, iter [00600, 05004], lr: 0.010000, loss: 2.3205
2022-07-15 23:22:14 - train: epoch 0049, iter [00700, 05004], lr: 0.010000, loss: 2.3435
2022-07-15 23:22:47 - train: epoch 0049, iter [00800, 05004], lr: 0.010000, loss: 2.7531
2022-07-15 23:23:20 - train: epoch 0049, iter [00900, 05004], lr: 0.010000, loss: 2.3440
2022-07-15 23:23:53 - train: epoch 0049, iter [01000, 05004], lr: 0.010000, loss: 2.5808
2022-07-15 23:24:27 - train: epoch 0049, iter [01100, 05004], lr: 0.010000, loss: 2.2637
2022-07-15 23:24:59 - train: epoch 0049, iter [01200, 05004], lr: 0.010000, loss: 2.1478
2022-07-15 23:25:33 - train: epoch 0049, iter [01300, 05004], lr: 0.010000, loss: 2.4152
2022-07-15 23:26:04 - train: epoch 0049, iter [01400, 05004], lr: 0.010000, loss: 2.6028
2022-07-15 23:26:38 - train: epoch 0049, iter [01500, 05004], lr: 0.010000, loss: 2.3054
2022-07-15 23:27:11 - train: epoch 0049, iter [01600, 05004], lr: 0.010000, loss: 2.6877
2022-07-15 23:27:45 - train: epoch 0049, iter [01700, 05004], lr: 0.010000, loss: 2.4922
2022-07-15 23:28:17 - train: epoch 0049, iter [01800, 05004], lr: 0.010000, loss: 2.2519
2022-07-15 23:28:50 - train: epoch 0049, iter [01900, 05004], lr: 0.010000, loss: 2.3142
2022-07-15 23:29:24 - train: epoch 0049, iter [02000, 05004], lr: 0.010000, loss: 2.3412
2022-07-15 23:29:56 - train: epoch 0049, iter [02100, 05004], lr: 0.010000, loss: 2.4085
2022-07-15 23:30:31 - train: epoch 0049, iter [02200, 05004], lr: 0.010000, loss: 2.2595
2022-07-15 23:31:03 - train: epoch 0049, iter [02300, 05004], lr: 0.010000, loss: 2.2915
2022-07-15 23:31:36 - train: epoch 0049, iter [02400, 05004], lr: 0.010000, loss: 2.7054
2022-07-15 23:32:09 - train: epoch 0049, iter [02500, 05004], lr: 0.010000, loss: 2.4512
2022-07-15 23:32:42 - train: epoch 0049, iter [02600, 05004], lr: 0.010000, loss: 2.4060
2022-07-15 23:33:15 - train: epoch 0049, iter [02700, 05004], lr: 0.010000, loss: 2.3603
2022-07-15 23:33:49 - train: epoch 0049, iter [02800, 05004], lr: 0.010000, loss: 2.4094
2022-07-15 23:34:22 - train: epoch 0049, iter [02900, 05004], lr: 0.010000, loss: 2.4926
2022-07-15 23:34:55 - train: epoch 0049, iter [03000, 05004], lr: 0.010000, loss: 2.5436
2022-07-15 23:35:29 - train: epoch 0049, iter [03100, 05004], lr: 0.010000, loss: 2.4402
2022-07-15 23:36:01 - train: epoch 0049, iter [03200, 05004], lr: 0.010000, loss: 2.4844
2022-07-15 23:36:35 - train: epoch 0049, iter [03300, 05004], lr: 0.010000, loss: 2.3450
2022-07-15 23:37:08 - train: epoch 0049, iter [03400, 05004], lr: 0.010000, loss: 2.5496
2022-07-15 23:37:41 - train: epoch 0049, iter [03500, 05004], lr: 0.010000, loss: 2.2568
2022-07-15 23:38:14 - train: epoch 0049, iter [03600, 05004], lr: 0.010000, loss: 2.5284
2022-07-15 23:38:47 - train: epoch 0049, iter [03700, 05004], lr: 0.010000, loss: 2.3785
2022-07-15 23:39:21 - train: epoch 0049, iter [03800, 05004], lr: 0.010000, loss: 2.5879
2022-07-15 23:39:55 - train: epoch 0049, iter [03900, 05004], lr: 0.010000, loss: 2.6608
2022-07-15 23:40:27 - train: epoch 0049, iter [04000, 05004], lr: 0.010000, loss: 2.2658
2022-07-15 23:41:01 - train: epoch 0049, iter [04100, 05004], lr: 0.010000, loss: 2.2487
2022-07-15 23:41:34 - train: epoch 0049, iter [04200, 05004], lr: 0.010000, loss: 2.4406
2022-07-15 23:42:08 - train: epoch 0049, iter [04300, 05004], lr: 0.010000, loss: 2.6817
2022-07-15 23:42:40 - train: epoch 0049, iter [04400, 05004], lr: 0.010000, loss: 2.3827
2022-07-15 23:43:14 - train: epoch 0049, iter [04500, 05004], lr: 0.010000, loss: 2.3298
2022-07-15 23:43:47 - train: epoch 0049, iter [04600, 05004], lr: 0.010000, loss: 2.5730
2022-07-15 23:44:20 - train: epoch 0049, iter [04700, 05004], lr: 0.010000, loss: 2.5880
2022-07-15 23:44:54 - train: epoch 0049, iter [04800, 05004], lr: 0.010000, loss: 2.2737
2022-07-15 23:45:28 - train: epoch 0049, iter [04900, 05004], lr: 0.010000, loss: 2.3380
2022-07-15 23:45:58 - train: epoch 0049, iter [05000, 05004], lr: 0.010000, loss: 2.2694
2022-07-15 23:45:59 - train: epoch 049, train_loss: 2.4056
2022-07-15 23:47:14 - eval: epoch: 049, acc1: 53.232%, acc5: 76.718%, test_loss: 2.0958, per_image_load_time: 1.777ms, per_image_inference_time: 0.121ms
2022-07-15 23:47:14 - until epoch: 049, best_acc1: 54.094%
2022-07-15 23:47:14 - epoch 050 lr: 0.010000
2022-07-15 23:47:51 - train: epoch 0050, iter [00100, 05004], lr: 0.010000, loss: 2.7893
2022-07-15 23:48:25 - train: epoch 0050, iter [00200, 05004], lr: 0.010000, loss: 2.4577
2022-07-15 23:48:58 - train: epoch 0050, iter [00300, 05004], lr: 0.010000, loss: 2.6190
2022-07-15 23:49:31 - train: epoch 0050, iter [00400, 05004], lr: 0.010000, loss: 2.4480
2022-07-15 23:50:05 - train: epoch 0050, iter [00500, 05004], lr: 0.010000, loss: 2.4234
2022-07-15 23:50:37 - train: epoch 0050, iter [00600, 05004], lr: 0.010000, loss: 2.6705
2022-07-15 23:51:11 - train: epoch 0050, iter [00700, 05004], lr: 0.010000, loss: 2.0910
2022-07-15 23:51:42 - train: epoch 0050, iter [00800, 05004], lr: 0.010000, loss: 2.0629
2022-07-15 23:52:15 - train: epoch 0050, iter [00900, 05004], lr: 0.010000, loss: 2.2398
2022-07-15 23:52:48 - train: epoch 0050, iter [01000, 05004], lr: 0.010000, loss: 2.6104
2022-07-15 23:53:21 - train: epoch 0050, iter [01100, 05004], lr: 0.010000, loss: 2.6703
2022-07-15 23:53:54 - train: epoch 0050, iter [01200, 05004], lr: 0.010000, loss: 2.4957
2022-07-15 23:54:27 - train: epoch 0050, iter [01300, 05004], lr: 0.010000, loss: 2.2202
2022-07-15 23:55:00 - train: epoch 0050, iter [01400, 05004], lr: 0.010000, loss: 2.4681
2022-07-15 23:55:34 - train: epoch 0050, iter [01500, 05004], lr: 0.010000, loss: 2.3802
2022-07-15 23:56:07 - train: epoch 0050, iter [01600, 05004], lr: 0.010000, loss: 2.3214
2022-07-15 23:56:40 - train: epoch 0050, iter [01700, 05004], lr: 0.010000, loss: 2.3174
2022-07-15 23:57:13 - train: epoch 0050, iter [01800, 05004], lr: 0.010000, loss: 2.4930
2022-07-15 23:57:46 - train: epoch 0050, iter [01900, 05004], lr: 0.010000, loss: 2.2642
2022-07-15 23:58:19 - train: epoch 0050, iter [02000, 05004], lr: 0.010000, loss: 2.3889
2022-07-15 23:58:53 - train: epoch 0050, iter [02100, 05004], lr: 0.010000, loss: 1.8897
2022-07-15 23:59:25 - train: epoch 0050, iter [02200, 05004], lr: 0.010000, loss: 2.4071
2022-07-15 23:59:59 - train: epoch 0050, iter [02300, 05004], lr: 0.010000, loss: 2.3218
2022-07-16 00:00:31 - train: epoch 0050, iter [02400, 05004], lr: 0.010000, loss: 2.5747
2022-07-16 00:01:05 - train: epoch 0050, iter [02500, 05004], lr: 0.010000, loss: 2.6167
2022-07-16 00:01:38 - train: epoch 0050, iter [02600, 05004], lr: 0.010000, loss: 2.3501
2022-07-16 00:02:11 - train: epoch 0050, iter [02700, 05004], lr: 0.010000, loss: 2.4397
2022-07-16 00:02:43 - train: epoch 0050, iter [02800, 05004], lr: 0.010000, loss: 2.5646
2022-07-16 00:03:16 - train: epoch 0050, iter [02900, 05004], lr: 0.010000, loss: 2.5361
2022-07-16 00:03:50 - train: epoch 0050, iter [03000, 05004], lr: 0.010000, loss: 2.6886
2022-07-16 00:04:23 - train: epoch 0050, iter [03100, 05004], lr: 0.010000, loss: 2.4123
2022-07-16 00:04:57 - train: epoch 0050, iter [03200, 05004], lr: 0.010000, loss: 2.4800
