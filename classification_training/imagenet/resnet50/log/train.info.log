2022-06-27 17:37:40 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 0.8006
2022-06-27 17:38:14 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 0.6868
2022-06-27 17:38:47 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 0.7713
2022-06-27 17:39:20 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 0.9162
2022-06-27 17:39:54 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 0.8345
2022-06-27 17:40:28 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 0.7895
2022-06-27 17:41:02 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 0.7927
2022-06-27 17:41:36 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 0.7574
2022-06-27 17:42:09 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 0.7754
2022-06-27 17:42:43 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 0.7320
2022-06-27 17:43:17 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 0.9729
2022-06-27 17:43:51 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 0.8596
2022-06-27 17:44:24 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 0.8437
2022-06-27 17:44:58 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 0.7035
2022-06-27 17:45:32 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 0.6559
2022-06-27 17:46:05 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 0.7321
2022-06-27 17:46:38 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 0.7667
2022-06-27 17:47:12 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 0.8608
2022-06-27 17:47:46 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 0.7528
2022-06-27 17:48:19 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 0.7029
2022-06-27 17:48:52 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 0.7191
2022-06-27 17:48:53 - train: epoch 085, train_loss: 0.7796
2022-06-27 17:50:09 - eval: epoch: 085, acc1: 76.036%, acc5: 92.910%, test_loss: 0.9658, per_image_load_time: 2.396ms, per_image_inference_time: 0.478ms
2022-06-27 17:50:09 - until epoch: 085, best_acc1: 76.036%
2022-06-27 17:50:09 - epoch 086 lr: 0.001000
2022-06-27 17:50:48 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 0.6926
2022-06-27 17:51:22 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 0.6551
2022-06-27 17:51:56 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 0.9021
2022-06-27 17:52:29 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 0.8531
2022-06-27 17:53:02 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 0.7467
2022-06-27 17:53:35 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 0.7107
2022-06-27 17:54:08 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 0.7717
2022-06-27 17:54:41 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 0.8204
2022-06-27 17:55:15 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 0.7273
2022-06-27 17:55:48 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 0.9600
2022-06-27 17:56:22 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 0.9845
2022-06-27 17:56:55 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 0.6689
2022-06-27 17:57:28 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 0.9502
2022-06-27 17:58:02 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 0.7058
2022-06-27 17:58:35 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 0.6340
2022-06-27 17:59:09 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 0.7544
2022-06-27 17:59:43 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 0.8828
2022-06-27 18:00:17 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 0.7649
2022-06-27 18:00:50 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 0.7167
2022-06-27 18:01:23 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 0.8407
2022-06-27 18:01:57 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 0.5562
2022-06-27 18:02:31 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 0.9126
2022-06-27 18:03:05 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 0.7302
2022-06-27 18:03:38 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 0.7311
2022-06-27 18:04:12 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 0.8378
2022-06-27 18:04:46 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 0.8961
2022-06-27 18:05:19 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 0.6363
2022-06-27 18:05:52 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 0.7331
2022-06-27 18:06:27 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 0.6553
2022-06-27 18:07:00 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 0.7339
2022-06-27 18:07:33 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 0.8281
2022-06-27 18:08:07 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 0.9220
2022-06-27 18:08:41 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 0.7695
2022-06-27 18:09:15 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 0.8691
2022-06-27 18:09:49 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 0.6932
2022-06-27 18:10:22 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 0.7936
2022-06-27 18:10:57 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 0.8276
2022-06-27 18:11:30 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 0.7799
2022-06-27 18:12:04 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 0.8844
2022-06-27 18:12:37 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 0.6772
2022-06-27 18:13:11 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 0.8206
2022-06-27 18:13:44 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 0.9582
2022-06-27 18:14:17 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 0.9916
2022-06-27 18:14:50 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 0.8217
2022-06-27 18:15:24 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 0.6299
2022-06-27 18:15:58 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 0.7547
2022-06-27 18:16:32 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 0.7872
2022-06-27 18:17:05 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 0.7978
2022-06-27 18:17:39 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 0.8762
2022-06-27 18:18:11 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 0.6843
2022-06-27 18:18:12 - train: epoch 086, train_loss: 0.7751
2022-06-27 18:19:28 - eval: epoch: 086, acc1: 75.920%, acc5: 92.854%, test_loss: 0.9713, per_image_load_time: 2.004ms, per_image_inference_time: 0.484ms
2022-06-27 18:19:28 - until epoch: 086, best_acc1: 76.036%
2022-06-27 18:19:28 - epoch 087 lr: 0.001000
2022-06-27 18:20:07 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 0.7970
2022-06-27 18:20:41 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 0.6698
2022-06-27 18:21:14 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 0.7847
2022-06-27 18:21:48 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 0.8608
2022-06-27 18:22:21 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 0.5984
2022-06-27 18:22:55 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 0.8432
2022-06-27 18:23:29 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 0.7017
2022-06-27 18:24:02 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 0.7349
2022-06-27 18:24:36 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 0.7257
2022-06-27 18:25:10 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 0.8961
2022-06-27 18:25:44 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 0.7494
2022-06-27 18:26:18 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 0.7881
2022-06-27 18:26:52 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 0.8870
2022-06-27 18:27:26 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 0.8177
2022-06-27 18:28:01 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 0.7383
2022-06-27 18:28:34 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 0.7750
2022-06-27 18:29:08 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 0.8141
2022-06-27 18:29:42 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 1.0055
2022-06-27 18:30:16 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 0.8673
2022-06-27 18:30:50 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 0.7604
2022-06-27 18:31:24 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 0.8571
2022-06-27 18:31:58 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 0.7781
2022-06-27 18:32:33 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 0.7934
2022-06-27 18:33:06 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 0.8009
2022-06-27 18:33:41 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 0.7764
2022-06-27 18:34:14 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 0.7305
2022-06-27 18:34:49 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 0.6705
2022-06-27 18:35:23 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 0.7406
2022-06-27 18:35:56 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 0.6870
2022-06-27 18:36:30 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 0.8233
2022-06-27 18:37:05 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 0.7979
2022-06-27 18:37:38 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 0.7784
2022-06-27 18:38:12 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 0.7972
2022-06-27 18:38:45 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 0.6877
2022-06-27 18:39:18 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 0.8060
2022-06-27 18:39:51 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 0.7899
2022-06-27 18:40:24 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 0.7200
2022-06-27 18:40:58 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 0.7699
2022-06-27 18:41:31 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 0.7427
2022-06-27 18:42:05 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 0.7397
2022-06-27 18:42:39 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 0.7263
2022-06-27 18:43:12 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 0.9551
2022-06-27 18:43:46 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 0.6515
2022-06-27 18:44:19 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 0.7246
2022-06-27 18:44:53 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 0.7311
2022-06-27 18:45:27 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 0.8630
2022-06-27 18:46:00 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 0.7492
2022-06-27 18:46:35 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 0.7450
2022-06-27 18:47:08 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 0.7843
2022-06-27 18:47:40 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 0.7710
2022-06-27 18:47:42 - train: epoch 087, train_loss: 0.7757
2022-06-27 18:48:57 - eval: epoch: 087, acc1: 75.786%, acc5: 92.812%, test_loss: 0.9725, per_image_load_time: 1.373ms, per_image_inference_time: 0.483ms
2022-06-27 18:48:58 - until epoch: 087, best_acc1: 76.036%
2022-06-27 18:48:58 - epoch 088 lr: 0.001000
2022-06-27 18:49:37 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 0.6207
2022-06-27 18:50:11 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 0.8066
2022-06-27 18:50:44 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 0.8711
2022-06-27 18:51:18 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 0.7914
2022-06-27 18:51:51 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 0.7665
2022-06-27 18:52:25 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 0.7364
2022-06-27 18:52:59 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 0.7227
2022-06-27 18:53:31 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 0.8212
2022-06-27 18:54:06 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 0.8311
2022-06-27 18:54:39 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 0.6659
2022-06-27 18:55:13 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 0.7765
2022-06-27 18:55:48 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 0.7255
2022-06-27 18:56:22 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 0.7225
2022-06-27 18:56:55 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 0.7324
2022-06-27 18:57:29 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 0.7737
2022-06-27 18:58:03 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 0.6652
2022-06-27 18:58:37 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 0.8876
2022-06-27 18:59:11 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 0.7078
2022-06-27 18:59:44 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 0.7217
2022-06-27 19:00:18 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 0.6489
2022-06-27 19:00:52 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 0.8308
2022-06-27 19:01:26 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 0.8036
2022-06-27 19:02:00 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 0.7921
2022-06-27 19:02:34 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 0.7462
2022-06-27 19:03:08 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 0.8385
2022-06-27 19:03:42 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 0.5840
2022-06-27 19:04:15 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 0.7289
2022-06-27 19:04:49 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 0.8611
2022-06-27 19:05:23 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 0.7387
2022-06-27 19:05:58 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 0.8639
2022-06-27 19:06:32 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 0.7084
2022-06-27 19:07:06 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 0.7767
2022-06-27 19:07:40 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 0.6684
2022-06-27 19:08:14 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 0.7689
2022-06-27 19:08:47 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 0.6696
2022-06-27 19:09:21 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 0.7967
2022-06-27 19:09:56 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 1.0313
2022-06-27 19:10:30 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 0.7753
2022-06-27 19:11:04 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 0.7679
2022-06-27 19:11:39 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 0.7087
2022-06-27 19:12:13 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 0.7371
2022-06-27 19:12:46 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 0.8823
2022-06-27 19:13:22 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 0.6518
2022-06-27 19:13:55 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 0.7937
2022-06-27 19:14:30 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 0.6731
2022-06-27 19:15:03 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 0.8888
2022-06-27 19:15:38 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 0.7039
2022-06-27 19:16:12 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 0.8418
2022-06-27 19:16:46 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 0.6683
2022-06-27 19:17:18 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 0.7127
2022-06-27 19:17:20 - train: epoch 088, train_loss: 0.7710
2022-06-27 19:18:35 - eval: epoch: 088, acc1: 75.924%, acc5: 92.794%, test_loss: 0.9697, per_image_load_time: 2.381ms, per_image_inference_time: 0.505ms
2022-06-27 19:18:35 - until epoch: 088, best_acc1: 76.036%
2022-06-27 19:18:35 - epoch 089 lr: 0.001000
2022-06-27 19:19:14 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 0.7973
2022-06-27 19:19:47 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 0.6963
2022-06-27 19:20:19 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 0.8498
2022-06-27 19:20:52 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 0.7182
2022-06-27 19:21:24 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 0.7891
2022-06-27 19:21:57 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 0.8788
2022-06-27 19:22:29 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 0.6114
2022-06-27 19:23:01 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 0.7226
2022-06-27 19:23:34 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 0.7834
2022-06-27 19:24:08 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 0.8252
2022-06-27 19:24:40 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 0.6118
2022-06-27 19:25:12 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 0.9206
2022-06-27 19:25:45 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 0.7549
2022-06-27 19:26:17 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 0.9364
2022-06-27 19:26:50 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 0.8132
2022-06-27 19:27:23 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 0.7643
2022-06-27 19:27:57 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 0.7720
2022-06-27 19:28:30 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 0.7745
2022-06-27 19:29:02 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 0.6665
2022-06-27 19:29:37 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 0.8233
2022-06-27 19:30:11 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 0.7341
2022-06-27 19:30:44 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 0.7301
2022-06-27 19:31:19 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 0.7850
2022-06-27 19:31:52 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 1.0787
2022-06-27 19:32:27 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 0.8478
2022-06-27 19:33:00 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 0.7649
2022-06-27 19:33:33 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 0.7881
2022-06-27 19:34:08 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 0.8096
2022-06-27 19:34:41 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 0.6843
2022-06-27 19:35:16 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 0.6907
2022-06-27 19:35:50 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 0.7576
2022-06-27 19:36:23 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 0.7778
2022-06-27 19:36:57 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 0.9388
2022-06-27 19:37:30 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 0.8327
2022-06-27 19:38:04 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 0.7643
2022-06-27 19:38:38 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 0.7490
2022-06-27 19:39:12 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 0.7421
2022-06-27 19:39:45 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 0.6606
2022-06-27 19:40:20 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 0.7032
2022-06-27 19:40:53 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 0.6661
2022-06-27 19:41:28 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 0.8195
2022-06-27 19:42:01 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 0.7918
2022-06-27 19:42:36 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 0.7762
2022-06-27 19:43:11 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 0.7719
2022-06-27 19:43:44 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 0.7065
2022-06-27 19:44:17 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 0.7092
2022-06-27 19:44:51 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 0.8121
2022-06-27 19:45:25 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 0.9047
2022-06-27 19:45:59 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 0.7553
2022-06-27 19:46:31 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 0.5578
2022-06-27 19:46:32 - train: epoch 089, train_loss: 0.7677
2022-06-27 19:47:47 - eval: epoch: 089, acc1: 75.812%, acc5: 92.756%, test_loss: 0.9669, per_image_load_time: 2.359ms, per_image_inference_time: 0.473ms
2022-06-27 19:47:47 - until epoch: 089, best_acc1: 76.036%
2022-06-27 19:47:47 - epoch 090 lr: 0.001000
2022-06-27 19:48:26 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 0.7499
2022-06-27 19:48:58 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 0.7619
2022-06-27 19:49:31 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 0.5782
2022-06-27 19:50:05 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 0.7753
2022-06-27 19:50:38 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 0.7984
2022-06-27 19:51:11 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 0.9169
2022-06-27 19:51:43 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 0.6217
2022-06-27 19:52:17 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 0.8987
2022-06-27 19:52:51 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 0.8216
2022-06-27 19:53:24 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 0.5621
2022-06-27 19:53:57 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 0.8423
2022-06-27 19:54:30 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 0.6210
2022-06-27 19:55:05 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 0.7553
2022-06-27 19:55:38 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 0.7674
2022-06-27 19:56:11 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 1.0429
2022-06-27 19:56:46 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 0.6433
2022-06-27 19:57:20 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 0.6144
2022-06-27 19:57:52 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 0.7197
2022-06-27 19:58:26 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 0.7523
2022-06-27 19:59:01 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 0.7668
2022-06-27 19:59:34 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 0.7672
2022-06-27 20:00:07 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 0.6611
2022-06-27 20:00:42 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 0.8841
2022-06-27 20:01:16 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 0.6946
2022-06-27 20:01:50 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 0.9892
2022-06-27 20:02:24 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 0.8498
2022-06-27 20:02:57 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 0.6349
2022-06-27 20:03:32 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 0.8038
2022-06-27 20:04:05 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 0.7380
2022-06-27 20:04:39 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 0.6658
2022-06-27 20:05:13 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 0.6876
2022-06-27 20:05:48 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 0.7226
2022-06-27 20:06:22 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 0.8099
2022-06-27 20:06:55 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 0.6832
2022-06-27 20:07:28 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 0.6945
2022-06-27 20:08:02 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 0.6390
2022-06-27 20:08:36 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 0.7796
2022-06-27 20:09:09 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 0.7212
2022-06-27 20:09:44 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 0.7730
2022-06-27 20:10:17 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 0.7987
2022-06-27 20:10:53 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 0.8500
2022-06-27 20:11:26 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 0.7383
2022-06-27 20:12:00 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 0.8494
2022-06-27 20:12:35 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 0.7045
2022-06-27 20:13:08 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 0.8388
2022-06-27 20:13:43 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 0.7536
2022-06-27 20:14:17 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 0.8450
2022-06-27 20:14:52 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 0.8207
2022-06-27 20:15:26 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 0.7451
2022-06-27 20:15:59 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 0.8402
2022-06-27 20:16:00 - train: epoch 090, train_loss: 0.7659
2022-06-27 20:17:15 - eval: epoch: 090, acc1: 75.864%, acc5: 92.812%, test_loss: 0.9693, per_image_load_time: 2.425ms, per_image_inference_time: 0.484ms
2022-06-27 20:17:16 - until epoch: 090, best_acc1: 76.036%
2022-06-27 20:17:16 - epoch 091 lr: 0.000100
2022-06-27 20:17:54 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 0.6909
2022-06-27 20:18:28 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 0.7677
2022-06-27 20:19:02 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 0.8272
2022-06-27 20:19:36 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 0.8177
2022-06-27 20:20:09 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 0.7761
2022-06-27 20:20:42 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 0.7991
2022-06-27 20:21:16 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 0.9672
2022-06-27 20:21:51 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 0.6519
2022-06-27 20:22:24 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 0.6919
2022-06-27 20:22:58 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 0.7252
2022-06-27 20:23:32 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 0.5308
2022-06-27 20:24:06 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 0.7844
2022-06-27 20:24:39 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 0.8019
2022-06-27 20:25:14 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 0.7649
2022-06-27 20:25:48 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 0.8199
2022-06-27 20:26:21 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 0.7911
2022-06-27 20:26:55 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 0.7919
2022-06-27 20:27:30 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 0.6719
2022-06-27 20:28:04 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 0.8023
2022-06-27 20:28:39 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 0.5526
2022-06-27 20:29:13 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 0.7350
2022-06-27 20:29:46 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 0.7342
2022-06-27 20:30:20 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 0.7268
2022-06-27 20:30:54 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 0.6730
2022-06-27 20:31:30 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 0.7504
2022-06-27 20:32:03 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 0.6801
2022-06-27 20:32:38 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 0.6084
2022-06-27 20:33:11 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 0.7023
2022-06-27 20:33:45 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 0.8170
2022-06-27 20:34:21 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 0.7871
2022-06-27 20:34:55 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 0.7114
2022-06-27 20:35:29 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 0.7897
2022-06-27 20:36:03 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 0.5424
2022-06-27 20:36:37 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 0.7306
2022-06-27 20:37:12 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 0.8109
2022-06-27 20:37:46 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 0.8577
2022-06-27 20:38:20 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 0.7509
2022-06-27 20:38:54 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 0.9408
2022-06-27 20:39:28 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 0.6826
2022-06-27 20:40:03 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 0.6520
2022-06-27 20:40:37 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 0.7089
2022-06-27 20:41:12 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 0.7482
2022-06-27 20:41:46 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 0.5727
2022-06-27 20:42:19 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 0.6313
2022-06-27 20:42:54 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 0.6744
2022-06-27 20:43:28 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 0.7086
2022-06-27 20:44:02 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 0.7544
2022-06-27 20:44:37 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 0.6946
2022-06-27 20:45:10 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 0.7218
2022-06-27 20:45:43 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 0.8112
2022-06-27 20:45:45 - train: epoch 091, train_loss: 0.7451
2022-06-27 20:47:00 - eval: epoch: 091, acc1: 76.120%, acc5: 92.932%, test_loss: 0.9577, per_image_load_time: 2.446ms, per_image_inference_time: 0.444ms
2022-06-27 20:47:00 - until epoch: 091, best_acc1: 76.120%
2022-06-27 20:47:00 - epoch 092 lr: 0.000100
2022-06-27 20:47:40 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 0.8245
2022-06-27 20:48:14 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 0.7460
2022-06-27 20:48:47 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 0.9101
2022-06-27 20:49:21 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 0.6923
2022-06-27 20:49:55 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 0.6889
2022-06-27 20:50:28 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 0.7913
2022-06-27 20:51:02 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 0.7747
2022-06-27 20:51:36 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 0.7568
2022-06-27 20:52:09 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 0.8646
2022-06-27 20:52:43 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 0.8068
2022-06-27 20:53:17 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 0.6467
2022-06-27 20:53:50 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 0.6876
2022-06-27 20:54:24 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 0.6206
2022-06-27 20:54:59 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 0.7198
2022-06-27 20:55:33 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 0.7722
2022-06-27 20:56:06 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 0.5882
2022-06-27 20:56:41 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 0.7619
2022-06-27 20:57:14 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 0.7621
2022-06-27 20:57:47 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 0.8376
2022-06-27 20:58:20 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 0.8040
2022-06-27 20:58:53 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 0.7376
2022-06-27 20:59:27 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 0.6602
2022-06-27 21:00:01 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 0.6233
2022-06-27 21:00:34 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 0.7013
2022-06-27 21:01:07 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 0.7604
2022-06-27 21:01:40 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 0.8008
2022-06-27 21:02:14 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 0.7203
2022-06-27 21:02:48 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 0.7851
2022-06-27 21:03:20 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 0.7292
2022-06-27 21:03:53 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 0.6889
2022-06-27 21:04:27 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 0.7373
2022-06-27 21:05:00 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 0.6848
2022-06-27 21:05:34 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 0.8428
2022-06-27 21:06:07 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 0.8962
2022-06-27 21:06:41 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 0.7131
2022-06-27 21:07:15 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 0.7934
2022-06-27 21:07:48 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 0.6792
2022-06-27 21:08:21 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 0.7681
2022-06-27 21:08:55 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 0.7863
2022-06-27 21:09:29 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 0.7490
2022-06-27 21:10:02 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 0.5830
2022-06-27 21:10:36 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 0.9457
2022-06-27 21:11:10 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 0.8018
2022-06-27 21:11:43 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 0.7382
2022-06-27 21:12:17 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 0.6282
2022-06-27 21:12:51 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 0.6030
2022-06-27 21:13:24 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 0.5750
2022-06-27 21:13:57 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 0.7106
2022-06-27 21:14:31 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 0.5685
2022-06-27 21:15:04 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 0.7221
2022-06-27 21:15:05 - train: epoch 092, train_loss: 0.7348
2022-06-27 21:16:20 - eval: epoch: 092, acc1: 76.142%, acc5: 92.944%, test_loss: 0.9565, per_image_load_time: 2.506ms, per_image_inference_time: 0.433ms
2022-06-27 21:16:20 - until epoch: 092, best_acc1: 76.142%
2022-06-27 21:16:20 - epoch 093 lr: 0.000100
2022-06-27 21:16:59 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 0.6825
2022-06-27 21:17:33 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 0.7157
2022-06-27 21:18:06 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 0.7228
2022-06-27 21:18:41 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 0.6926
2022-06-27 21:19:13 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 0.6900
2022-06-27 21:19:47 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 0.5815
2022-06-27 21:20:21 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 0.6661
2022-06-27 21:20:54 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 0.4940
2022-06-27 21:21:28 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 0.8929
2022-06-27 21:22:01 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.7123
2022-06-27 21:22:34 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 0.6122
2022-06-27 21:23:07 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 0.6538
2022-06-27 21:23:41 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 0.8669
2022-06-27 21:24:15 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 0.7057
2022-06-27 21:24:49 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 0.8331
2022-06-27 21:25:23 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 0.6870
2022-06-27 21:25:57 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 0.7490
2022-06-27 21:26:30 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 0.7998
2022-06-27 21:27:04 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 0.6459
2022-06-27 21:27:37 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 0.5656
2022-06-27 21:28:11 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 0.6422
2022-06-27 21:28:45 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 0.9313
2022-06-27 21:29:19 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 0.7211
2022-06-27 21:29:52 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 0.6473
2022-06-27 21:30:27 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 0.7978
2022-06-27 21:31:00 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 0.8482
2022-06-27 21:31:35 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 0.6772
2022-06-27 21:32:09 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 0.7162
2022-06-27 21:32:43 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 0.6103
2022-06-27 21:33:16 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 0.7263
2022-06-27 21:33:50 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 0.6625
2022-06-27 21:34:23 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 0.5772
2022-06-27 21:34:56 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 0.7923
2022-06-27 21:35:30 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 0.8153
2022-06-27 21:36:05 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 0.7453
2022-06-27 21:36:39 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 0.7603
2022-06-27 21:37:12 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 0.7621
2022-06-27 21:37:46 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 0.5987
2022-06-27 21:38:20 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 0.8051
2022-06-27 21:38:54 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 0.7802
2022-06-27 21:39:27 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 0.7681
2022-06-27 21:40:02 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 0.7192
2022-06-27 21:40:36 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 0.7806
2022-06-27 21:41:09 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 0.7599
2022-06-27 21:41:43 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 0.7015
2022-06-27 21:42:18 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 0.6571
2022-06-27 21:42:52 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 0.6644
2022-06-27 21:43:26 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 0.5822
2022-06-27 21:44:00 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 0.8371
2022-06-27 21:44:32 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 0.6439
2022-06-27 21:44:33 - train: epoch 093, train_loss: 0.7328
2022-06-27 21:45:48 - eval: epoch: 093, acc1: 76.200%, acc5: 92.958%, test_loss: 0.9552, per_image_load_time: 1.117ms, per_image_inference_time: 0.505ms
2022-06-27 21:45:49 - until epoch: 093, best_acc1: 76.200%
2022-06-27 21:45:49 - epoch 094 lr: 0.000100
2022-06-27 21:46:28 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 0.7641
2022-06-27 21:47:02 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 0.7381
2022-06-27 21:47:35 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 0.8810
2022-06-27 21:48:09 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 0.7356
2022-06-27 21:48:43 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 0.8023
2022-06-27 21:49:17 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 0.6556
2022-06-27 21:49:51 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 0.8482
2022-06-27 21:50:25 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 0.6288
2022-06-27 21:50:58 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 0.8035
2022-06-27 21:51:32 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 0.8715
2022-06-27 21:52:05 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 0.8252
2022-06-27 21:52:39 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 0.7180
2022-06-27 21:53:12 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 0.6758
2022-06-27 21:53:45 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 0.7095
2022-06-27 21:54:19 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 0.7803
2022-06-27 21:54:53 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 0.9207
2022-06-27 21:55:26 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 0.8090
2022-06-27 21:56:01 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 0.6580
2022-06-27 21:56:35 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 0.8010
2022-06-27 21:57:09 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 0.5197
2022-06-27 21:57:42 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 0.6441
2022-06-27 21:58:16 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 0.7547
2022-06-27 21:58:50 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 0.5946
2022-06-27 21:59:23 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 0.8502
2022-06-27 21:59:56 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 0.6808
2022-06-27 22:00:30 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 0.5693
2022-06-27 22:01:04 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 0.7618
2022-06-27 22:01:38 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 0.6795
2022-06-27 22:02:11 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 0.6646
2022-06-27 22:02:45 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 1.0332
2022-06-27 22:03:19 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 0.9124
2022-06-27 22:03:52 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 0.7187
2022-06-27 22:04:27 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 0.7011
2022-06-27 22:05:01 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 0.7540
2022-06-27 22:05:35 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 0.6742
2022-06-27 22:06:09 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 0.7667
2022-06-27 22:06:43 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 0.7552
2022-06-27 22:07:16 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 0.6567
2022-06-27 22:07:51 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 0.7916
2022-06-27 22:08:25 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 0.8338
2022-06-27 22:08:57 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 0.8641
2022-06-27 22:09:31 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 0.6495
2022-06-27 22:10:05 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 0.6603
2022-06-27 22:10:38 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 0.7496
2022-06-27 22:11:13 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 0.7381
2022-06-27 22:11:46 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 0.8891
2022-06-27 22:12:20 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 0.9432
2022-06-27 22:12:54 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 0.7143
2022-06-27 22:13:28 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 0.7151
2022-06-27 22:14:00 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 0.6793
2022-06-27 22:14:01 - train: epoch 094, train_loss: 0.7304
2022-06-27 22:15:17 - eval: epoch: 094, acc1: 76.222%, acc5: 92.996%, test_loss: 0.9563, per_image_load_time: 2.389ms, per_image_inference_time: 0.504ms
2022-06-27 22:15:17 - until epoch: 094, best_acc1: 76.222%
2022-06-27 22:15:17 - epoch 095 lr: 0.000100
2022-06-27 22:15:56 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 0.7662
2022-06-27 22:16:31 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 0.6505
2022-06-27 22:17:04 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 0.6951
2022-06-27 22:17:38 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 0.6847
2022-06-27 22:18:11 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 0.7940
2022-06-27 22:18:45 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 0.6938
2022-06-27 22:19:17 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 0.7796
2022-06-27 22:19:52 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 0.7529
2022-06-27 22:20:26 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 0.7958
2022-06-27 22:21:00 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 0.7245
2022-06-27 22:21:34 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 0.7087
2022-06-27 22:22:08 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 0.7437
2022-06-27 22:22:42 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 0.7052
2022-06-27 22:23:16 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 0.6569
2022-06-27 22:23:50 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 0.8280
2022-06-27 22:24:24 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.6090
2022-06-27 22:24:58 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 0.7278
2022-06-27 22:25:33 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 0.5513
2022-06-27 22:26:06 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 0.8135
2022-06-27 22:26:41 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 0.7915
2022-06-27 22:27:15 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 0.6646
2022-06-27 22:27:50 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 0.6816
2022-06-27 22:28:23 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 0.5773
2022-06-27 22:28:58 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 0.8051
2022-06-27 22:29:32 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 0.6591
2022-06-27 22:30:06 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 0.7102
2022-06-27 22:30:41 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 0.7689
2022-06-27 22:31:14 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 0.6147
2022-06-27 22:31:48 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 0.9125
2022-06-27 22:32:23 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 0.9399
2022-06-27 22:32:57 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 0.7774
2022-06-27 22:33:31 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 0.6999
2022-06-27 22:34:04 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 0.7647
2022-06-27 22:34:39 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 0.5593
2022-06-27 22:35:13 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 0.6395
2022-06-27 22:35:46 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 0.6186
2022-06-27 22:36:20 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 0.8687
2022-06-27 22:36:53 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 0.6441
2022-06-27 22:37:27 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 0.7137
2022-06-27 22:38:02 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 0.7187
2022-06-27 22:38:37 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 0.7941
2022-06-27 22:39:10 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 0.5550
2022-06-27 22:39:44 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 0.7501
2022-06-27 22:40:18 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 0.8618
2022-06-27 22:40:53 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 0.6815
2022-06-27 22:41:27 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 0.7175
2022-06-27 22:42:00 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 0.6624
2022-06-27 22:42:34 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 0.8032
2022-06-27 22:43:08 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 0.7473
2022-06-27 22:43:40 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 0.6474
2022-06-27 22:43:42 - train: epoch 095, train_loss: 0.7313
2022-06-27 22:44:57 - eval: epoch: 095, acc1: 76.198%, acc5: 92.968%, test_loss: 0.9573, per_image_load_time: 2.395ms, per_image_inference_time: 0.493ms
2022-06-27 22:44:57 - until epoch: 095, best_acc1: 76.222%
2022-06-27 22:44:57 - epoch 096 lr: 0.000100
2022-06-27 22:45:36 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 0.7633
2022-06-27 22:46:10 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 0.6951
2022-06-27 22:46:43 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 0.5566
2022-06-27 22:47:17 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 0.6837
2022-06-27 22:47:51 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 0.6836
2022-06-27 22:48:25 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 0.6467
2022-06-27 22:48:59 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 0.6134
2022-06-27 22:49:33 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 0.6214
2022-06-27 22:50:07 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 0.8489
2022-06-27 22:50:40 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 0.6107
2022-06-27 22:51:14 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 0.6750
2022-06-27 22:51:49 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 0.5613
2022-06-27 22:52:24 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 0.8598
2022-06-27 22:52:58 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 0.8389
2022-06-27 22:53:31 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 0.6534
2022-06-27 22:54:06 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 0.7702
2022-06-27 22:54:40 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 0.6154
2022-06-27 22:55:14 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 0.7287
2022-06-27 22:55:49 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 0.7282
2022-06-27 22:56:23 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 0.5602
2022-06-27 22:56:57 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 0.7490
2022-06-27 22:57:31 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.6062
2022-06-27 22:58:05 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 0.6942
2022-06-27 22:58:38 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 0.6720
2022-06-27 22:59:12 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 0.5826
2022-06-27 22:59:47 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 0.7926
2022-06-27 23:00:21 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 0.7697
2022-06-27 23:00:55 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 0.6101
2022-06-27 23:01:29 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 0.8052
2022-06-27 23:02:03 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 0.7728
2022-06-27 23:02:37 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 0.7414
2022-06-27 23:03:11 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 0.7730
2022-06-27 23:03:44 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 0.7598
2022-06-27 23:04:17 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 0.7091
2022-06-27 23:04:52 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 0.6287
2022-06-27 23:05:25 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 0.6022
2022-06-27 23:06:00 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 0.7674
2022-06-27 23:06:33 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 0.6711
2022-06-27 23:07:08 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 0.6698
2022-06-27 23:07:41 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 0.7747
2022-06-27 23:08:15 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 0.7021
2022-06-27 23:08:49 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 0.6319
2022-06-27 23:09:24 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.5326
2022-06-27 23:09:57 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 0.6032
2022-06-27 23:10:32 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 0.7552
2022-06-27 23:11:04 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 0.4961
2022-06-27 23:11:39 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 0.7304
2022-06-27 23:12:14 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 0.8329
2022-06-27 23:12:48 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 0.7428
2022-06-27 23:13:21 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 0.7438
2022-06-27 23:13:22 - train: epoch 096, train_loss: 0.7266
2022-06-27 23:14:37 - eval: epoch: 096, acc1: 76.220%, acc5: 92.926%, test_loss: 0.9556, per_image_load_time: 1.927ms, per_image_inference_time: 0.502ms
2022-06-27 23:14:37 - until epoch: 096, best_acc1: 76.222%
2022-06-27 23:14:37 - epoch 097 lr: 0.000100
2022-06-27 23:15:16 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 0.7377
2022-06-27 23:15:50 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 0.8010
2022-06-27 23:16:24 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 0.8591
2022-06-27 23:16:58 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 0.7355
2022-06-27 23:17:31 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 0.7934
2022-06-27 23:18:05 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 0.8583
2022-06-27 23:18:38 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 0.7728
2022-06-27 23:19:12 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.8478
2022-06-27 23:19:46 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 0.6314
2022-06-27 23:20:21 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 0.7167
2022-06-27 23:20:54 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 0.6611
2022-06-27 23:21:27 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 0.6302
2022-06-27 23:22:02 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 0.6954
2022-06-27 23:22:36 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 0.7369
2022-06-27 23:23:08 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 0.6525
2022-06-27 23:23:42 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 0.6993
2022-06-27 23:24:17 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 0.7042
2022-06-27 23:24:50 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 0.6971
2022-06-27 23:25:24 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 0.7846
2022-06-27 23:25:57 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 0.7447
2022-06-27 23:26:32 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 0.8021
2022-06-27 23:27:04 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 0.7819
2022-06-27 23:27:38 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 0.6786
2022-06-27 23:28:12 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 0.6432
2022-06-27 23:28:45 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 0.6683
2022-06-27 23:29:19 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 0.8368
2022-06-27 23:29:52 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 0.6922
2022-06-27 23:30:27 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 0.9004
2022-06-27 23:31:00 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 0.6565
2022-06-27 23:31:34 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 0.8508
2022-06-27 23:32:06 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 0.7172
2022-06-27 23:32:40 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 0.7619
2022-06-27 23:33:14 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 0.7368
2022-06-27 23:33:48 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 0.7792
2022-06-27 23:34:22 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 0.6952
2022-06-27 23:34:56 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 0.6993
2022-06-27 23:35:29 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 0.6732
2022-06-27 23:36:03 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 0.5957
2022-06-27 23:36:36 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 0.6890
2022-06-27 23:37:09 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 0.7378
2022-06-27 23:37:44 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 0.6833
2022-06-27 23:38:17 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 0.7096
2022-06-27 23:38:51 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 0.7250
2022-06-27 23:39:25 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 0.7179
2022-06-27 23:39:59 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 0.8397
2022-06-27 23:40:32 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 0.7256
2022-06-27 23:41:06 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 0.6791
2022-06-27 23:41:40 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 0.6616
2022-06-27 23:42:14 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 0.8234
2022-06-27 23:42:46 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 0.6002
2022-06-27 23:42:47 - train: epoch 097, train_loss: 0.7264
2022-06-27 23:44:03 - eval: epoch: 097, acc1: 76.264%, acc5: 92.970%, test_loss: 0.9544, per_image_load_time: 2.065ms, per_image_inference_time: 0.495ms
2022-06-27 23:44:03 - until epoch: 097, best_acc1: 76.264%
2022-06-27 23:44:03 - epoch 098 lr: 0.000100
2022-06-27 23:44:42 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 0.8701
2022-06-27 23:45:15 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 0.7555
2022-06-27 23:45:48 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 0.6961
2022-06-27 23:46:21 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 0.5941
2022-06-27 23:46:54 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 0.9041
2022-06-27 23:47:28 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 0.6480
2022-06-27 23:48:02 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 0.7995
2022-06-27 23:48:34 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 0.7220
2022-06-27 23:49:07 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 0.8868
2022-06-27 23:49:41 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 0.6342
2022-06-27 23:50:15 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 0.6165
2022-06-27 23:50:48 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 0.8728
2022-06-27 23:51:22 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 0.7861
2022-06-27 23:51:55 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 0.6927
2022-06-27 23:52:29 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 0.6427
2022-06-27 23:53:02 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 0.7060
2022-06-27 23:53:36 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 0.7167
2022-06-27 23:54:11 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 0.7130
2022-06-27 23:54:43 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 0.6299
2022-06-27 23:55:17 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 0.7832
2022-06-27 23:55:51 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 0.7386
2022-06-27 23:56:24 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 0.5733
2022-06-27 23:56:57 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 0.8061
2022-06-27 23:57:30 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 0.6216
2022-06-27 23:58:04 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 0.7252
2022-06-27 23:58:38 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 0.5671
2022-06-27 23:59:11 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 0.7395
2022-06-27 23:59:44 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 0.7607
2022-06-28 00:00:18 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 0.7971
2022-06-28 00:00:52 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 0.7035
2022-06-28 00:01:26 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 0.6024
2022-06-28 00:01:58 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 0.7433
2022-06-28 00:02:33 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 0.7799
2022-06-28 00:03:06 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 0.8277
2022-06-28 00:03:39 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 0.8402
2022-06-28 00:04:13 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 0.7874
2022-06-28 00:04:46 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 0.7684
2022-06-28 00:05:20 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 0.6279
2022-06-28 00:05:53 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 0.6769
2022-06-28 00:06:28 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 0.9156
2022-06-28 00:07:02 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 0.6062
2022-06-28 00:07:36 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 0.6437
2022-06-28 00:08:09 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 0.5553
2022-06-28 00:08:42 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 0.7122
2022-06-28 00:09:17 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 0.6490
2022-06-28 00:09:50 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 0.7716
2022-06-28 00:10:24 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 0.8558
2022-06-28 00:10:58 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 0.5356
2022-06-28 00:11:32 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 0.6876
2022-06-28 00:12:05 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 0.9142
2022-06-28 00:12:06 - train: epoch 098, train_loss: 0.7248
2022-06-28 00:13:21 - eval: epoch: 098, acc1: 76.234%, acc5: 92.978%, test_loss: 0.9567, per_image_load_time: 2.392ms, per_image_inference_time: 0.482ms
2022-06-28 00:13:21 - until epoch: 098, best_acc1: 76.264%
2022-06-28 00:13:21 - epoch 099 lr: 0.000100
2022-06-28 00:14:01 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 0.6936
2022-06-28 00:14:34 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 0.7072
2022-06-28 00:15:07 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 0.7221
2022-06-28 00:15:41 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 0.6634
2022-06-28 00:16:15 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 0.7753
2022-06-28 00:16:49 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 0.7363
2022-06-28 00:17:22 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 0.7401
2022-06-28 00:17:58 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 0.7113
2022-06-28 00:18:31 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 0.7932
2022-06-28 00:19:05 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 0.7186
2022-06-28 00:19:40 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 0.6076
2022-06-28 00:20:14 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 0.5749
2022-06-28 00:20:48 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 0.6639
2022-06-28 00:21:23 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 0.8879
2022-06-28 00:21:56 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 0.7169
2022-06-28 00:22:30 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 0.8399
2022-06-28 00:23:04 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 0.7022
2022-06-28 00:23:37 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 0.7056
2022-06-28 00:24:12 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 0.6860
2022-06-28 00:24:47 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 0.5921
2022-06-28 00:25:21 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 0.6340
2022-06-28 00:25:55 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 0.6750
2022-06-28 00:26:30 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 0.6119
2022-06-28 00:27:04 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 0.8540
2022-06-28 00:27:37 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 0.7105
2022-06-28 00:28:12 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 0.7380
2022-06-28 00:28:46 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 0.7654
2022-06-28 00:29:20 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 0.7249
2022-06-28 00:29:54 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 0.5927
2022-06-28 00:30:28 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 0.7931
2022-06-28 00:31:02 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 0.6370
2022-06-28 00:31:37 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 0.7351
2022-06-28 00:32:11 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 0.6575
2022-06-28 00:32:46 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 0.6432
2022-06-28 00:33:19 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 0.7707
2022-06-28 00:33:53 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 0.6834
2022-06-28 00:34:27 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 0.6573
2022-06-28 00:35:01 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 0.8469
2022-06-28 00:35:35 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 0.7251
2022-06-28 00:36:10 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 0.8237
2022-06-28 00:36:44 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 0.6508
2022-06-28 00:37:19 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 0.7793
2022-06-28 00:37:52 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 0.6963
2022-06-28 00:38:26 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 0.6594
2022-06-28 00:39:01 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 0.7706
2022-06-28 00:39:36 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 0.7632
2022-06-28 00:40:10 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 0.7084
2022-06-28 00:40:44 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 1.0257
2022-06-28 00:41:18 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 0.7675
2022-06-28 00:41:51 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 0.7770
2022-06-28 00:41:52 - train: epoch 099, train_loss: 0.7222
2022-06-28 00:43:07 - eval: epoch: 099, acc1: 76.232%, acc5: 92.958%, test_loss: 0.9561, per_image_load_time: 2.390ms, per_image_inference_time: 0.494ms
2022-06-28 00:43:07 - until epoch: 099, best_acc1: 76.264%
2022-06-28 00:43:07 - epoch 100 lr: 0.000100
2022-06-28 00:43:46 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 0.6318
2022-06-28 00:44:20 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 0.7384
2022-06-28 00:44:54 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 0.6159
2022-06-28 00:45:28 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 0.7492
2022-06-28 00:46:02 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 0.7580
2022-06-28 00:46:35 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 0.7596
2022-06-28 00:47:10 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 0.6984
2022-06-28 00:47:43 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 0.7409
2022-06-28 00:48:18 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 0.6888
2022-06-28 00:48:51 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 0.7279
2022-06-28 00:49:26 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 0.6533
2022-06-28 00:49:59 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 0.6207
2022-06-28 00:50:34 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 0.7310
2022-06-28 00:51:08 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 0.6641
2022-06-28 00:51:41 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 0.7881
2022-06-28 00:52:16 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 0.7267
2022-06-28 00:52:50 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 0.5768
2022-06-28 00:53:24 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 0.7242
2022-06-28 00:53:58 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 0.8136
2022-06-28 00:54:33 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 0.7065
2022-06-28 00:55:06 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 0.6698
2022-06-28 00:55:39 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 0.8341
2022-06-28 00:56:14 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 0.9704
2022-06-28 00:56:48 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 0.7610
2022-06-28 00:57:22 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 0.5673
2022-06-28 00:57:56 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 0.7511
2022-06-28 00:58:30 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 0.7370
2022-06-28 00:59:04 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 0.7251
2022-06-28 00:59:39 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 0.6427
2022-06-28 01:00:13 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 0.7804
2022-06-28 01:00:47 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 0.6498
2022-06-28 01:01:21 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 0.8072
2022-06-28 01:01:55 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 0.6644
2022-06-28 01:02:30 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 0.6583
2022-06-28 01:03:04 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 0.6584
2022-06-28 01:03:38 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 0.6740
2022-06-28 01:04:12 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 0.7389
2022-06-28 01:04:46 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 0.6316
2022-06-28 01:05:21 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 0.6971
2022-06-28 01:05:55 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 0.7067
2022-06-28 01:06:30 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 0.7231
2022-06-28 01:07:04 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 0.7600
2022-06-28 01:07:38 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 0.6535
2022-06-28 01:08:12 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 0.8538
2022-06-28 01:08:47 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 0.6461
2022-06-28 01:09:21 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 0.7001
2022-06-28 01:09:55 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 0.7024
2022-06-28 01:10:30 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 0.5728
2022-06-28 01:11:04 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 0.7152
2022-06-28 01:11:37 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 0.8291
2022-06-28 01:11:38 - train: epoch 100, train_loss: 0.7244
2022-06-28 01:12:54 - eval: epoch: 100, acc1: 76.178%, acc5: 92.946%, test_loss: 0.9572, per_image_load_time: 2.361ms, per_image_inference_time: 0.509ms
2022-06-28 01:12:54 - until epoch: 100, best_acc1: 76.264%
2022-06-28 01:12:54 - train done. model: resnet50, train time: 49.466 hours, best_acc1: 76.264%
