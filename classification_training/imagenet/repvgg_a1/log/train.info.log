2022-07-14 08:11:05 - train: epoch 0099, iter [02000, 05004], lr: 0.007784, loss: 1.1086
2022-07-14 08:11:38 - train: epoch 0099, iter [02100, 05004], lr: 0.007770, loss: 1.1928
2022-07-14 08:12:12 - train: epoch 0099, iter [02200, 05004], lr: 0.007756, loss: 1.3174
2022-07-14 08:12:46 - train: epoch 0099, iter [02300, 05004], lr: 0.007742, loss: 1.3530
2022-07-14 08:13:21 - train: epoch 0099, iter [02400, 05004], lr: 0.007728, loss: 1.5220
2022-07-14 08:13:54 - train: epoch 0099, iter [02500, 05004], lr: 0.007714, loss: 1.2064
2022-07-14 08:14:28 - train: epoch 0099, iter [02600, 05004], lr: 0.007700, loss: 1.1601
2022-07-14 08:15:02 - train: epoch 0099, iter [02700, 05004], lr: 0.007686, loss: 1.3494
2022-07-14 08:15:37 - train: epoch 0099, iter [02800, 05004], lr: 0.007672, loss: 1.5614
2022-07-14 08:16:11 - train: epoch 0099, iter [02900, 05004], lr: 0.007658, loss: 1.3455
2022-07-14 08:16:46 - train: epoch 0099, iter [03000, 05004], lr: 0.007644, loss: 1.4941
2022-07-14 08:17:20 - train: epoch 0099, iter [03100, 05004], lr: 0.007630, loss: 1.1809
2022-07-14 08:17:54 - train: epoch 0099, iter [03200, 05004], lr: 0.007616, loss: 1.4757
2022-07-14 08:18:28 - train: epoch 0099, iter [03300, 05004], lr: 0.007603, loss: 1.2200
2022-07-14 08:19:02 - train: epoch 0099, iter [03400, 05004], lr: 0.007589, loss: 1.3265
2022-07-14 08:19:37 - train: epoch 0099, iter [03500, 05004], lr: 0.007575, loss: 1.3848
2022-07-14 08:20:10 - train: epoch 0099, iter [03600, 05004], lr: 0.007561, loss: 1.3375
2022-07-14 08:20:45 - train: epoch 0099, iter [03700, 05004], lr: 0.007547, loss: 1.1983
2022-07-14 08:21:19 - train: epoch 0099, iter [03800, 05004], lr: 0.007533, loss: 1.4647
2022-07-14 08:21:54 - train: epoch 0099, iter [03900, 05004], lr: 0.007520, loss: 1.3216
2022-07-14 08:22:28 - train: epoch 0099, iter [04000, 05004], lr: 0.007506, loss: 1.3852
2022-07-14 08:23:03 - train: epoch 0099, iter [04100, 05004], lr: 0.007492, loss: 1.2531
2022-07-14 08:23:36 - train: epoch 0099, iter [04200, 05004], lr: 0.007478, loss: 1.3305
2022-07-14 08:24:11 - train: epoch 0099, iter [04300, 05004], lr: 0.007465, loss: 1.3323
2022-07-14 08:24:45 - train: epoch 0099, iter [04400, 05004], lr: 0.007451, loss: 1.3883
2022-07-14 08:25:19 - train: epoch 0099, iter [04500, 05004], lr: 0.007437, loss: 1.3798
2022-07-14 08:25:53 - train: epoch 0099, iter [04600, 05004], lr: 0.007423, loss: 1.4037
2022-07-14 08:26:27 - train: epoch 0099, iter [04700, 05004], lr: 0.007410, loss: 1.2908
2022-07-14 08:27:02 - train: epoch 0099, iter [04800, 05004], lr: 0.007396, loss: 1.4170
2022-07-14 08:27:36 - train: epoch 0099, iter [04900, 05004], lr: 0.007382, loss: 1.1761
2022-07-14 08:28:08 - train: epoch 0099, iter [05000, 05004], lr: 0.007369, loss: 1.3734
2022-07-14 08:28:09 - train: epoch 099, train_loss: 1.3199
2022-07-14 08:29:25 - eval: epoch: 099, acc1: 70.484%, acc5: 89.634%, test_loss: 1.1998, per_image_load_time: 2.657ms, per_image_inference_time: 0.277ms
2022-07-14 08:29:26 - until epoch: 099, best_acc1: 70.484%
2022-07-14 08:29:26 - epoch 100 lr: 0.007368
2022-07-14 08:30:05 - train: epoch 0100, iter [00100, 05004], lr: 0.007354, loss: 1.2118
2022-07-14 08:30:39 - train: epoch 0100, iter [00200, 05004], lr: 0.007341, loss: 1.3375
2022-07-14 08:31:14 - train: epoch 0100, iter [00300, 05004], lr: 0.007327, loss: 1.2688
2022-07-14 08:31:48 - train: epoch 0100, iter [00400, 05004], lr: 0.007313, loss: 1.0460
2022-07-14 08:32:21 - train: epoch 0100, iter [00500, 05004], lr: 0.007300, loss: 1.3907
2022-07-14 08:32:55 - train: epoch 0100, iter [00600, 05004], lr: 0.007286, loss: 1.5101
2022-07-14 08:33:30 - train: epoch 0100, iter [00700, 05004], lr: 0.007273, loss: 1.0667
2022-07-14 08:34:04 - train: epoch 0100, iter [00800, 05004], lr: 0.007259, loss: 1.3305
2022-07-14 08:34:38 - train: epoch 0100, iter [00900, 05004], lr: 0.007245, loss: 1.1930
2022-07-14 08:35:11 - train: epoch 0100, iter [01000, 05004], lr: 0.007232, loss: 1.3621
2022-07-14 08:35:46 - train: epoch 0100, iter [01100, 05004], lr: 0.007218, loss: 1.2098
2022-07-14 08:36:20 - train: epoch 0100, iter [01200, 05004], lr: 0.007205, loss: 1.3847
2022-07-14 08:36:54 - train: epoch 0100, iter [01300, 05004], lr: 0.007191, loss: 1.3653
2022-07-14 08:37:28 - train: epoch 0100, iter [01400, 05004], lr: 0.007178, loss: 1.4154
2022-07-14 08:38:02 - train: epoch 0100, iter [01500, 05004], lr: 0.007164, loss: 1.3373
2022-07-14 08:38:35 - train: epoch 0100, iter [01600, 05004], lr: 0.007151, loss: 1.2293
2022-07-14 08:39:10 - train: epoch 0100, iter [01700, 05004], lr: 0.007137, loss: 1.2903
2022-07-14 08:39:44 - train: epoch 0100, iter [01800, 05004], lr: 0.007124, loss: 1.3107
2022-07-14 08:40:17 - train: epoch 0100, iter [01900, 05004], lr: 0.007110, loss: 1.2715
2022-07-14 08:40:51 - train: epoch 0100, iter [02000, 05004], lr: 0.007097, loss: 1.2846
2022-07-14 08:41:26 - train: epoch 0100, iter [02100, 05004], lr: 0.007084, loss: 1.2817
2022-07-14 08:42:00 - train: epoch 0100, iter [02200, 05004], lr: 0.007070, loss: 1.4651
2022-07-14 08:42:35 - train: epoch 0100, iter [02300, 05004], lr: 0.007057, loss: 1.2180
2022-07-14 08:43:08 - train: epoch 0100, iter [02400, 05004], lr: 0.007043, loss: 1.2317
2022-07-14 08:43:43 - train: epoch 0100, iter [02500, 05004], lr: 0.007030, loss: 1.2494
2022-07-14 08:44:17 - train: epoch 0100, iter [02600, 05004], lr: 0.007017, loss: 1.3164
2022-07-14 08:44:51 - train: epoch 0100, iter [02700, 05004], lr: 0.007003, loss: 1.2785
2022-07-14 08:45:24 - train: epoch 0100, iter [02800, 05004], lr: 0.006990, loss: 1.4577
2022-07-14 08:45:59 - train: epoch 0100, iter [02900, 05004], lr: 0.006977, loss: 1.3526
2022-07-14 08:46:33 - train: epoch 0100, iter [03000, 05004], lr: 0.006963, loss: 1.1083
2022-07-14 08:47:08 - train: epoch 0100, iter [03100, 05004], lr: 0.006950, loss: 1.3131
2022-07-14 08:47:42 - train: epoch 0100, iter [03200, 05004], lr: 0.006937, loss: 1.4267
2022-07-14 08:48:17 - train: epoch 0100, iter [03300, 05004], lr: 0.006923, loss: 1.4431
2022-07-14 08:48:51 - train: epoch 0100, iter [03400, 05004], lr: 0.006910, loss: 1.3676
2022-07-14 08:49:26 - train: epoch 0100, iter [03500, 05004], lr: 0.006897, loss: 1.1548
2022-07-14 08:49:59 - train: epoch 0100, iter [03600, 05004], lr: 0.006884, loss: 1.3230
2022-07-14 08:50:33 - train: epoch 0100, iter [03700, 05004], lr: 0.006870, loss: 1.2695
2022-07-14 08:51:07 - train: epoch 0100, iter [03800, 05004], lr: 0.006857, loss: 1.2914
2022-07-14 08:51:42 - train: epoch 0100, iter [03900, 05004], lr: 0.006844, loss: 1.3986
2022-07-14 08:52:15 - train: epoch 0100, iter [04000, 05004], lr: 0.006831, loss: 1.2362
2022-07-14 08:52:50 - train: epoch 0100, iter [04100, 05004], lr: 0.006817, loss: 1.3090
2022-07-14 08:53:24 - train: epoch 0100, iter [04200, 05004], lr: 0.006804, loss: 1.3602
2022-07-14 08:53:59 - train: epoch 0100, iter [04300, 05004], lr: 0.006791, loss: 1.2285
2022-07-14 08:54:33 - train: epoch 0100, iter [04400, 05004], lr: 0.006778, loss: 1.4239
2022-07-14 08:55:08 - train: epoch 0100, iter [04500, 05004], lr: 0.006765, loss: 1.2728
2022-07-14 08:55:42 - train: epoch 0100, iter [04600, 05004], lr: 0.006752, loss: 1.1310
2022-07-14 08:56:16 - train: epoch 0100, iter [04700, 05004], lr: 0.006739, loss: 1.3442
2022-07-14 08:56:51 - train: epoch 0100, iter [04800, 05004], lr: 0.006725, loss: 1.0733
2022-07-14 08:57:24 - train: epoch 0100, iter [04900, 05004], lr: 0.006712, loss: 1.2429
2022-07-14 08:57:57 - train: epoch 0100, iter [05000, 05004], lr: 0.006699, loss: 1.4933
2022-07-14 08:57:58 - train: epoch 100, train_loss: 1.3020
2022-07-14 08:59:14 - eval: epoch: 100, acc1: 70.838%, acc5: 89.650%, test_loss: 1.1914, per_image_load_time: 2.032ms, per_image_inference_time: 0.287ms
2022-07-14 08:59:14 - until epoch: 100, best_acc1: 70.838%
2022-07-14 08:59:14 - epoch 101 lr: 0.006699
2022-07-14 08:59:53 - train: epoch 0101, iter [00100, 05004], lr: 0.006686, loss: 1.1891
2022-07-14 09:00:28 - train: epoch 0101, iter [00200, 05004], lr: 0.006673, loss: 1.1528
2022-07-14 09:01:01 - train: epoch 0101, iter [00300, 05004], lr: 0.006660, loss: 1.0316
2022-07-14 09:01:36 - train: epoch 0101, iter [00400, 05004], lr: 0.006647, loss: 1.1350
2022-07-14 09:02:09 - train: epoch 0101, iter [00500, 05004], lr: 0.006633, loss: 1.2118
2022-07-14 09:02:43 - train: epoch 0101, iter [00600, 05004], lr: 0.006620, loss: 1.1489
2022-07-14 09:03:18 - train: epoch 0101, iter [00700, 05004], lr: 0.006607, loss: 1.4626
2022-07-14 09:03:52 - train: epoch 0101, iter [00800, 05004], lr: 0.006594, loss: 1.3653
2022-07-14 09:04:26 - train: epoch 0101, iter [00900, 05004], lr: 0.006581, loss: 1.3727
2022-07-14 09:05:00 - train: epoch 0101, iter [01000, 05004], lr: 0.006569, loss: 1.4716
2022-07-14 09:05:34 - train: epoch 0101, iter [01100, 05004], lr: 0.006556, loss: 1.3429
2022-07-14 09:06:08 - train: epoch 0101, iter [01200, 05004], lr: 0.006543, loss: 1.2533
2022-07-14 09:06:42 - train: epoch 0101, iter [01300, 05004], lr: 0.006530, loss: 1.5036
2022-07-14 09:07:15 - train: epoch 0101, iter [01400, 05004], lr: 0.006517, loss: 1.2731
2022-07-14 09:07:50 - train: epoch 0101, iter [01500, 05004], lr: 0.006504, loss: 1.1402
2022-07-14 09:08:24 - train: epoch 0101, iter [01600, 05004], lr: 0.006491, loss: 1.0617
2022-07-14 09:08:58 - train: epoch 0101, iter [01700, 05004], lr: 0.006478, loss: 1.1350
2022-07-14 09:09:33 - train: epoch 0101, iter [01800, 05004], lr: 0.006465, loss: 1.5212
2022-07-14 09:10:07 - train: epoch 0101, iter [01900, 05004], lr: 0.006452, loss: 1.1258
2022-07-14 09:10:40 - train: epoch 0101, iter [02000, 05004], lr: 0.006440, loss: 1.1453
2022-07-14 09:11:15 - train: epoch 0101, iter [02100, 05004], lr: 0.006427, loss: 1.2146
2022-07-14 09:11:49 - train: epoch 0101, iter [02200, 05004], lr: 0.006414, loss: 1.2183
2022-07-14 09:12:23 - train: epoch 0101, iter [02300, 05004], lr: 0.006401, loss: 1.2353
2022-07-14 09:12:57 - train: epoch 0101, iter [02400, 05004], lr: 0.006388, loss: 1.2974
2022-07-14 09:13:32 - train: epoch 0101, iter [02500, 05004], lr: 0.006375, loss: 1.2609
2022-07-14 09:14:06 - train: epoch 0101, iter [02600, 05004], lr: 0.006363, loss: 1.3620
2022-07-14 09:14:41 - train: epoch 0101, iter [02700, 05004], lr: 0.006350, loss: 1.4971
2022-07-14 09:15:15 - train: epoch 0101, iter [02800, 05004], lr: 0.006337, loss: 1.3028
2022-07-14 09:15:50 - train: epoch 0101, iter [02900, 05004], lr: 0.006324, loss: 1.4510
2022-07-14 09:16:24 - train: epoch 0101, iter [03000, 05004], lr: 0.006312, loss: 1.4395
2022-07-14 09:16:58 - train: epoch 0101, iter [03100, 05004], lr: 0.006299, loss: 1.4361
2022-07-14 09:17:33 - train: epoch 0101, iter [03200, 05004], lr: 0.006286, loss: 1.3774
2022-07-14 09:18:07 - train: epoch 0101, iter [03300, 05004], lr: 0.006274, loss: 1.3076
2022-07-14 09:18:41 - train: epoch 0101, iter [03400, 05004], lr: 0.006261, loss: 1.3475
2022-07-14 09:19:16 - train: epoch 0101, iter [03500, 05004], lr: 0.006248, loss: 1.1151
2022-07-14 09:19:50 - train: epoch 0101, iter [03600, 05004], lr: 0.006236, loss: 1.3434
2022-07-14 09:20:24 - train: epoch 0101, iter [03700, 05004], lr: 0.006223, loss: 1.4851
2022-07-14 09:20:58 - train: epoch 0101, iter [03800, 05004], lr: 0.006210, loss: 1.3424
2022-07-14 09:21:33 - train: epoch 0101, iter [03900, 05004], lr: 0.006198, loss: 1.3687
2022-07-14 09:22:07 - train: epoch 0101, iter [04000, 05004], lr: 0.006185, loss: 1.3982
2022-07-14 09:22:41 - train: epoch 0101, iter [04100, 05004], lr: 0.006172, loss: 1.2708
2022-07-14 09:23:17 - train: epoch 0101, iter [04200, 05004], lr: 0.006160, loss: 1.3376
2022-07-14 09:23:51 - train: epoch 0101, iter [04300, 05004], lr: 0.006147, loss: 1.2951
2022-07-14 09:24:25 - train: epoch 0101, iter [04400, 05004], lr: 0.006135, loss: 1.2584
2022-07-14 09:25:00 - train: epoch 0101, iter [04500, 05004], lr: 0.006122, loss: 1.5424
2022-07-14 09:25:34 - train: epoch 0101, iter [04600, 05004], lr: 0.006110, loss: 1.2970
2022-07-14 09:26:08 - train: epoch 0101, iter [04700, 05004], lr: 0.006097, loss: 1.3039
2022-07-14 09:26:43 - train: epoch 0101, iter [04800, 05004], lr: 0.006085, loss: 1.3050
2022-07-14 09:27:17 - train: epoch 0101, iter [04900, 05004], lr: 0.006072, loss: 1.2341
2022-07-14 09:27:49 - train: epoch 0101, iter [05000, 05004], lr: 0.006060, loss: 1.2747
2022-07-14 09:27:50 - train: epoch 101, train_loss: 1.2812
2022-07-14 09:29:06 - eval: epoch: 101, acc1: 70.818%, acc5: 89.974%, test_loss: 1.1797, per_image_load_time: 2.311ms, per_image_inference_time: 0.299ms
2022-07-14 09:29:06 - until epoch: 101, best_acc1: 70.838%
2022-07-14 09:29:06 - epoch 102 lr: 0.006059
2022-07-14 09:29:45 - train: epoch 0102, iter [00100, 05004], lr: 0.006047, loss: 1.3112
2022-07-14 09:30:19 - train: epoch 0102, iter [00200, 05004], lr: 0.006034, loss: 1.1698
2022-07-14 09:30:53 - train: epoch 0102, iter [00300, 05004], lr: 0.006022, loss: 1.3088
2022-07-14 09:31:28 - train: epoch 0102, iter [00400, 05004], lr: 0.006009, loss: 1.2024
2022-07-14 09:32:02 - train: epoch 0102, iter [00500, 05004], lr: 0.005997, loss: 1.3626
2022-07-14 09:32:36 - train: epoch 0102, iter [00600, 05004], lr: 0.005984, loss: 1.1436
2022-07-14 09:33:09 - train: epoch 0102, iter [00700, 05004], lr: 0.005972, loss: 1.1846
2022-07-14 09:33:43 - train: epoch 0102, iter [00800, 05004], lr: 0.005960, loss: 1.1992
2022-07-14 09:34:18 - train: epoch 0102, iter [00900, 05004], lr: 0.005947, loss: 1.1808
2022-07-14 09:34:52 - train: epoch 0102, iter [01000, 05004], lr: 0.005935, loss: 1.2780
2022-07-14 09:35:27 - train: epoch 0102, iter [01100, 05004], lr: 0.005923, loss: 1.0487
2022-07-14 09:36:01 - train: epoch 0102, iter [01200, 05004], lr: 0.005910, loss: 1.3684
2022-07-14 09:36:35 - train: epoch 0102, iter [01300, 05004], lr: 0.005898, loss: 1.3424
2022-07-14 09:37:09 - train: epoch 0102, iter [01400, 05004], lr: 0.005886, loss: 1.2981
2022-07-14 09:37:44 - train: epoch 0102, iter [01500, 05004], lr: 0.005873, loss: 1.2162
2022-07-14 09:38:18 - train: epoch 0102, iter [01600, 05004], lr: 0.005861, loss: 1.3790
2022-07-14 09:38:52 - train: epoch 0102, iter [01700, 05004], lr: 0.005849, loss: 1.2014
2022-07-14 09:39:27 - train: epoch 0102, iter [01800, 05004], lr: 0.005836, loss: 1.3850
2022-07-14 09:40:01 - train: epoch 0102, iter [01900, 05004], lr: 0.005824, loss: 1.2119
2022-07-14 09:40:36 - train: epoch 0102, iter [02000, 05004], lr: 0.005812, loss: 1.2155
2022-07-14 09:41:09 - train: epoch 0102, iter [02100, 05004], lr: 0.005800, loss: 1.1495
2022-07-14 09:41:44 - train: epoch 0102, iter [02200, 05004], lr: 0.005787, loss: 1.1019
2022-07-14 09:42:18 - train: epoch 0102, iter [02300, 05004], lr: 0.005775, loss: 1.2942
2022-07-14 09:42:51 - train: epoch 0102, iter [02400, 05004], lr: 0.005763, loss: 1.3866
2022-07-14 09:43:26 - train: epoch 0102, iter [02500, 05004], lr: 0.005751, loss: 1.2382
2022-07-14 09:44:01 - train: epoch 0102, iter [02600, 05004], lr: 0.005739, loss: 1.2921
2022-07-14 09:44:35 - train: epoch 0102, iter [02700, 05004], lr: 0.005727, loss: 1.6240
2022-07-14 09:45:10 - train: epoch 0102, iter [02800, 05004], lr: 0.005714, loss: 1.2519
2022-07-14 09:45:43 - train: epoch 0102, iter [02900, 05004], lr: 0.005702, loss: 1.2469
2022-07-14 09:46:18 - train: epoch 0102, iter [03000, 05004], lr: 0.005690, loss: 1.1562
2022-07-14 09:46:52 - train: epoch 0102, iter [03100, 05004], lr: 0.005678, loss: 1.1925
2022-07-14 09:47:27 - train: epoch 0102, iter [03200, 05004], lr: 0.005666, loss: 1.0968
2022-07-14 09:48:00 - train: epoch 0102, iter [03300, 05004], lr: 0.005654, loss: 1.2284
2022-07-14 09:48:35 - train: epoch 0102, iter [03400, 05004], lr: 0.005642, loss: 1.2611
2022-07-14 09:49:08 - train: epoch 0102, iter [03500, 05004], lr: 0.005630, loss: 1.2532
2022-07-14 09:49:43 - train: epoch 0102, iter [03600, 05004], lr: 0.005618, loss: 1.3741
2022-07-14 09:50:16 - train: epoch 0102, iter [03700, 05004], lr: 0.005606, loss: 1.2842
2022-07-14 09:50:51 - train: epoch 0102, iter [03800, 05004], lr: 0.005594, loss: 1.3080
2022-07-14 09:51:25 - train: epoch 0102, iter [03900, 05004], lr: 0.005582, loss: 1.3368
2022-07-14 09:51:59 - train: epoch 0102, iter [04000, 05004], lr: 0.005570, loss: 1.1481
2022-07-14 09:52:33 - train: epoch 0102, iter [04100, 05004], lr: 0.005558, loss: 1.2688
2022-07-14 09:53:07 - train: epoch 0102, iter [04200, 05004], lr: 0.005546, loss: 1.5146
2022-07-14 09:53:39 - train: epoch 0102, iter [04300, 05004], lr: 0.005534, loss: 1.1414
2022-07-14 09:54:12 - train: epoch 0102, iter [04400, 05004], lr: 0.005522, loss: 1.0052
2022-07-14 09:54:45 - train: epoch 0102, iter [04500, 05004], lr: 0.005510, loss: 1.3293
2022-07-14 09:55:20 - train: epoch 0102, iter [04600, 05004], lr: 0.005498, loss: 1.5019
2022-07-14 09:55:53 - train: epoch 0102, iter [04700, 05004], lr: 0.005486, loss: 1.2705
2022-07-14 09:56:27 - train: epoch 0102, iter [04800, 05004], lr: 0.005474, loss: 1.4668
2022-07-14 09:56:59 - train: epoch 0102, iter [04900, 05004], lr: 0.005462, loss: 1.2496
2022-07-14 09:57:31 - train: epoch 0102, iter [05000, 05004], lr: 0.005450, loss: 1.0606
2022-07-14 09:57:32 - train: epoch 102, train_loss: 1.2602
2022-07-14 09:58:45 - eval: epoch: 102, acc1: 71.296%, acc5: 90.176%, test_loss: 1.1661, per_image_load_time: 2.553ms, per_image_inference_time: 0.303ms
2022-07-14 09:58:46 - until epoch: 102, best_acc1: 71.296%
2022-07-14 09:58:46 - epoch 103 lr: 0.005450
2022-07-14 09:59:23 - train: epoch 0103, iter [00100, 05004], lr: 0.005438, loss: 1.1428
2022-07-14 09:59:56 - train: epoch 0103, iter [00200, 05004], lr: 0.005426, loss: 1.2673
2022-07-14 10:00:28 - train: epoch 0103, iter [00300, 05004], lr: 0.005414, loss: 1.2003
2022-07-14 10:01:01 - train: epoch 0103, iter [00400, 05004], lr: 0.005402, loss: 1.2947
2022-07-14 10:01:33 - train: epoch 0103, iter [00500, 05004], lr: 0.005390, loss: 1.1569
2022-07-14 10:02:06 - train: epoch 0103, iter [00600, 05004], lr: 0.005379, loss: 1.0291
2022-07-14 10:02:38 - train: epoch 0103, iter [00700, 05004], lr: 0.005367, loss: 1.1822
2022-07-14 10:03:12 - train: epoch 0103, iter [00800, 05004], lr: 0.005355, loss: 1.2284
2022-07-14 10:03:45 - train: epoch 0103, iter [00900, 05004], lr: 0.005343, loss: 1.1893
2022-07-14 10:04:18 - train: epoch 0103, iter [01000, 05004], lr: 0.005332, loss: 1.2254
2022-07-14 10:04:50 - train: epoch 0103, iter [01100, 05004], lr: 0.005320, loss: 1.1807
2022-07-14 10:05:23 - train: epoch 0103, iter [01200, 05004], lr: 0.005308, loss: 1.1688
2022-07-14 10:05:56 - train: epoch 0103, iter [01300, 05004], lr: 0.005296, loss: 1.3525
2022-07-14 10:06:28 - train: epoch 0103, iter [01400, 05004], lr: 0.005285, loss: 1.3714
2022-07-14 10:07:01 - train: epoch 0103, iter [01500, 05004], lr: 0.005273, loss: 1.4400
2022-07-14 10:07:34 - train: epoch 0103, iter [01600, 05004], lr: 0.005261, loss: 0.9496
2022-07-14 10:08:06 - train: epoch 0103, iter [01700, 05004], lr: 0.005250, loss: 1.2713
2022-07-14 10:08:39 - train: epoch 0103, iter [01800, 05004], lr: 0.005238, loss: 1.1285
2022-07-14 10:09:11 - train: epoch 0103, iter [01900, 05004], lr: 0.005226, loss: 1.1716
2022-07-14 10:09:45 - train: epoch 0103, iter [02000, 05004], lr: 0.005215, loss: 1.0374
2022-07-14 10:10:17 - train: epoch 0103, iter [02100, 05004], lr: 0.005203, loss: 1.3153
2022-07-14 10:10:50 - train: epoch 0103, iter [02200, 05004], lr: 0.005191, loss: 1.1818
2022-07-14 10:11:23 - train: epoch 0103, iter [02300, 05004], lr: 0.005180, loss: 1.2706
2022-07-14 10:11:55 - train: epoch 0103, iter [02400, 05004], lr: 0.005168, loss: 1.2962
2022-07-14 10:12:28 - train: epoch 0103, iter [02500, 05004], lr: 0.005157, loss: 1.1858
2022-07-14 10:13:02 - train: epoch 0103, iter [02600, 05004], lr: 0.005145, loss: 1.2218
2022-07-14 10:13:35 - train: epoch 0103, iter [02700, 05004], lr: 0.005133, loss: 1.2284
2022-07-14 10:14:07 - train: epoch 0103, iter [02800, 05004], lr: 0.005122, loss: 0.9574
2022-07-14 10:14:40 - train: epoch 0103, iter [02900, 05004], lr: 0.005110, loss: 1.2705
2022-07-14 10:15:13 - train: epoch 0103, iter [03000, 05004], lr: 0.005099, loss: 1.3302
2022-07-14 10:15:46 - train: epoch 0103, iter [03100, 05004], lr: 0.005087, loss: 1.2250
2022-07-14 10:16:19 - train: epoch 0103, iter [03200, 05004], lr: 0.005076, loss: 1.1523
2022-07-14 10:16:52 - train: epoch 0103, iter [03300, 05004], lr: 0.005064, loss: 1.2226
2022-07-14 10:17:25 - train: epoch 0103, iter [03400, 05004], lr: 0.005053, loss: 1.3183
2022-07-14 10:17:58 - train: epoch 0103, iter [03500, 05004], lr: 0.005042, loss: 1.3010
2022-07-14 10:18:31 - train: epoch 0103, iter [03600, 05004], lr: 0.005030, loss: 1.2028
2022-07-14 10:19:04 - train: epoch 0103, iter [03700, 05004], lr: 0.005019, loss: 1.1625
2022-07-14 10:19:36 - train: epoch 0103, iter [03800, 05004], lr: 0.005007, loss: 1.2443
2022-07-14 10:20:10 - train: epoch 0103, iter [03900, 05004], lr: 0.004996, loss: 1.1924
2022-07-14 10:20:42 - train: epoch 0103, iter [04000, 05004], lr: 0.004984, loss: 1.2001
2022-07-14 10:21:15 - train: epoch 0103, iter [04100, 05004], lr: 0.004973, loss: 1.1697
2022-07-14 10:21:47 - train: epoch 0103, iter [04200, 05004], lr: 0.004962, loss: 1.2290
2022-07-14 10:22:20 - train: epoch 0103, iter [04300, 05004], lr: 0.004950, loss: 1.3132
2022-07-14 10:22:53 - train: epoch 0103, iter [04400, 05004], lr: 0.004939, loss: 1.2887
2022-07-14 10:23:25 - train: epoch 0103, iter [04500, 05004], lr: 0.004928, loss: 1.3548
2022-07-14 10:23:58 - train: epoch 0103, iter [04600, 05004], lr: 0.004916, loss: 1.3702
2022-07-14 10:24:32 - train: epoch 0103, iter [04700, 05004], lr: 0.004905, loss: 1.1907
2022-07-14 10:25:03 - train: epoch 0103, iter [04800, 05004], lr: 0.004894, loss: 1.4972
2022-07-14 10:25:37 - train: epoch 0103, iter [04900, 05004], lr: 0.004882, loss: 1.1496
2022-07-14 10:26:08 - train: epoch 0103, iter [05000, 05004], lr: 0.004871, loss: 1.2103
2022-07-14 10:26:09 - train: epoch 103, train_loss: 1.2451
2022-07-14 10:27:23 - eval: epoch: 103, acc1: 71.586%, acc5: 90.260%, test_loss: 1.1556, per_image_load_time: 2.517ms, per_image_inference_time: 0.262ms
2022-07-14 10:27:23 - until epoch: 103, best_acc1: 71.586%
2022-07-14 10:27:23 - epoch 104 lr: 0.004871
2022-07-14 10:28:01 - train: epoch 0104, iter [00100, 05004], lr: 0.004859, loss: 1.1679
2022-07-14 10:28:34 - train: epoch 0104, iter [00200, 05004], lr: 0.004848, loss: 1.1989
2022-07-14 10:29:07 - train: epoch 0104, iter [00300, 05004], lr: 0.004837, loss: 1.4768
2022-07-14 10:29:40 - train: epoch 0104, iter [00400, 05004], lr: 0.004826, loss: 1.2759
2022-07-14 10:30:12 - train: epoch 0104, iter [00500, 05004], lr: 0.004815, loss: 1.1849
2022-07-14 10:30:45 - train: epoch 0104, iter [00600, 05004], lr: 0.004803, loss: 1.4744
2022-07-14 10:31:18 - train: epoch 0104, iter [00700, 05004], lr: 0.004792, loss: 1.3999
2022-07-14 10:31:50 - train: epoch 0104, iter [00800, 05004], lr: 0.004781, loss: 1.2705
2022-07-14 10:32:23 - train: epoch 0104, iter [00900, 05004], lr: 0.004770, loss: 1.1876
2022-07-14 10:32:56 - train: epoch 0104, iter [01000, 05004], lr: 0.004759, loss: 1.1832
2022-07-14 10:33:28 - train: epoch 0104, iter [01100, 05004], lr: 0.004748, loss: 1.1667
2022-07-14 10:34:02 - train: epoch 0104, iter [01200, 05004], lr: 0.004736, loss: 1.0870
2022-07-14 10:34:34 - train: epoch 0104, iter [01300, 05004], lr: 0.004725, loss: 1.2527
2022-07-14 10:35:07 - train: epoch 0104, iter [01400, 05004], lr: 0.004714, loss: 1.1730
2022-07-14 10:35:40 - train: epoch 0104, iter [01500, 05004], lr: 0.004703, loss: 1.3184
2022-07-14 10:36:13 - train: epoch 0104, iter [01600, 05004], lr: 0.004692, loss: 1.0742
2022-07-14 10:36:45 - train: epoch 0104, iter [01700, 05004], lr: 0.004681, loss: 1.1350
2022-07-14 10:37:19 - train: epoch 0104, iter [01800, 05004], lr: 0.004670, loss: 1.4008
2022-07-14 10:37:51 - train: epoch 0104, iter [01900, 05004], lr: 0.004659, loss: 1.0034
2022-07-14 10:38:24 - train: epoch 0104, iter [02000, 05004], lr: 0.004648, loss: 1.1794
2022-07-14 10:38:57 - train: epoch 0104, iter [02100, 05004], lr: 0.004637, loss: 1.0463
2022-07-14 10:39:30 - train: epoch 0104, iter [02200, 05004], lr: 0.004626, loss: 1.3699
2022-07-14 10:40:03 - train: epoch 0104, iter [02300, 05004], lr: 0.004615, loss: 1.3013
2022-07-14 10:40:37 - train: epoch 0104, iter [02400, 05004], lr: 0.004604, loss: 1.4823
2022-07-14 10:41:10 - train: epoch 0104, iter [02500, 05004], lr: 0.004593, loss: 1.2690
2022-07-14 10:41:44 - train: epoch 0104, iter [02600, 05004], lr: 0.004582, loss: 1.1194
2022-07-14 10:42:17 - train: epoch 0104, iter [02700, 05004], lr: 0.004571, loss: 1.2679
2022-07-14 10:42:51 - train: epoch 0104, iter [02800, 05004], lr: 0.004560, loss: 1.2624
2022-07-14 10:43:25 - train: epoch 0104, iter [02900, 05004], lr: 0.004549, loss: 1.3526
2022-07-14 10:43:59 - train: epoch 0104, iter [03000, 05004], lr: 0.004538, loss: 1.3295
2022-07-14 10:44:32 - train: epoch 0104, iter [03100, 05004], lr: 0.004528, loss: 1.0541
2022-07-14 10:45:05 - train: epoch 0104, iter [03200, 05004], lr: 0.004517, loss: 1.2309
2022-07-14 10:45:40 - train: epoch 0104, iter [03300, 05004], lr: 0.004506, loss: 1.4336
2022-07-14 10:46:13 - train: epoch 0104, iter [03400, 05004], lr: 0.004495, loss: 1.1363
2022-07-14 10:46:47 - train: epoch 0104, iter [03500, 05004], lr: 0.004484, loss: 1.1629
2022-07-14 10:47:20 - train: epoch 0104, iter [03600, 05004], lr: 0.004473, loss: 1.1907
2022-07-14 10:47:53 - train: epoch 0104, iter [03700, 05004], lr: 0.004463, loss: 1.3218
2022-07-14 10:48:26 - train: epoch 0104, iter [03800, 05004], lr: 0.004452, loss: 1.0239
2022-07-14 10:49:00 - train: epoch 0104, iter [03900, 05004], lr: 0.004441, loss: 1.1665
2022-07-14 10:49:33 - train: epoch 0104, iter [04000, 05004], lr: 0.004430, loss: 1.0722
2022-07-14 10:50:07 - train: epoch 0104, iter [04100, 05004], lr: 0.004419, loss: 1.1897
2022-07-14 10:50:40 - train: epoch 0104, iter [04200, 05004], lr: 0.004409, loss: 1.2801
2022-07-14 10:51:14 - train: epoch 0104, iter [04300, 05004], lr: 0.004398, loss: 1.1750
2022-07-14 10:51:48 - train: epoch 0104, iter [04400, 05004], lr: 0.004387, loss: 1.2343
2022-07-14 10:52:21 - train: epoch 0104, iter [04500, 05004], lr: 0.004377, loss: 1.3791
2022-07-14 10:52:55 - train: epoch 0104, iter [04600, 05004], lr: 0.004366, loss: 1.1458
2022-07-14 10:53:27 - train: epoch 0104, iter [04700, 05004], lr: 0.004355, loss: 1.0674
2022-07-14 10:54:02 - train: epoch 0104, iter [04800, 05004], lr: 0.004344, loss: 1.3412
2022-07-14 10:54:35 - train: epoch 0104, iter [04900, 05004], lr: 0.004334, loss: 1.2293
2022-07-14 10:55:06 - train: epoch 0104, iter [05000, 05004], lr: 0.004323, loss: 1.2877
2022-07-14 10:55:07 - train: epoch 104, train_loss: 1.2246
2022-07-14 10:56:22 - eval: epoch: 104, acc1: 72.000%, acc5: 90.396%, test_loss: 1.1410, per_image_load_time: 2.623ms, per_image_inference_time: 0.290ms
2022-07-14 10:56:22 - until epoch: 104, best_acc1: 72.000%
2022-07-14 10:56:22 - epoch 105 lr: 0.004323
2022-07-14 10:57:01 - train: epoch 0105, iter [00100, 05004], lr: 0.004312, loss: 1.2356
2022-07-14 10:57:34 - train: epoch 0105, iter [00200, 05004], lr: 0.004301, loss: 1.3708
2022-07-14 10:58:08 - train: epoch 0105, iter [00300, 05004], lr: 0.004291, loss: 1.2869
2022-07-14 10:58:40 - train: epoch 0105, iter [00400, 05004], lr: 0.004280, loss: 1.1832
2022-07-14 10:59:14 - train: epoch 0105, iter [00500, 05004], lr: 0.004270, loss: 1.1318
2022-07-14 10:59:47 - train: epoch 0105, iter [00600, 05004], lr: 0.004259, loss: 1.3490
2022-07-14 11:00:21 - train: epoch 0105, iter [00700, 05004], lr: 0.004249, loss: 1.0522
2022-07-14 11:00:54 - train: epoch 0105, iter [00800, 05004], lr: 0.004238, loss: 1.1906
2022-07-14 11:01:27 - train: epoch 0105, iter [00900, 05004], lr: 0.004227, loss: 1.1751
2022-07-14 11:02:01 - train: epoch 0105, iter [01000, 05004], lr: 0.004217, loss: 1.1757
2022-07-14 11:02:34 - train: epoch 0105, iter [01100, 05004], lr: 0.004206, loss: 1.3830
2022-07-14 11:03:08 - train: epoch 0105, iter [01200, 05004], lr: 0.004196, loss: 1.2680
2022-07-14 11:03:42 - train: epoch 0105, iter [01300, 05004], lr: 0.004185, loss: 1.0833
2022-07-14 11:04:15 - train: epoch 0105, iter [01400, 05004], lr: 0.004175, loss: 1.3028
2022-07-14 11:04:49 - train: epoch 0105, iter [01500, 05004], lr: 0.004165, loss: 1.1410
2022-07-14 11:05:23 - train: epoch 0105, iter [01600, 05004], lr: 0.004154, loss: 0.9729
2022-07-14 11:05:56 - train: epoch 0105, iter [01700, 05004], lr: 0.004144, loss: 1.1524
2022-07-14 11:06:29 - train: epoch 0105, iter [01800, 05004], lr: 0.004133, loss: 1.1992
2022-07-14 11:07:03 - train: epoch 0105, iter [01900, 05004], lr: 0.004123, loss: 1.2297
2022-07-14 11:07:37 - train: epoch 0105, iter [02000, 05004], lr: 0.004112, loss: 1.1645
2022-07-14 11:08:11 - train: epoch 0105, iter [02100, 05004], lr: 0.004102, loss: 1.2938
2022-07-14 11:08:45 - train: epoch 0105, iter [02200, 05004], lr: 0.004092, loss: 1.3999
2022-07-14 11:09:18 - train: epoch 0105, iter [02300, 05004], lr: 0.004081, loss: 1.2575
2022-07-14 11:09:52 - train: epoch 0105, iter [02400, 05004], lr: 0.004071, loss: 1.1885
2022-07-14 11:10:25 - train: epoch 0105, iter [02500, 05004], lr: 0.004061, loss: 1.0083
2022-07-14 11:10:59 - train: epoch 0105, iter [02600, 05004], lr: 0.004050, loss: 1.0883
2022-07-14 11:11:32 - train: epoch 0105, iter [02700, 05004], lr: 0.004040, loss: 1.4418
2022-07-14 11:12:06 - train: epoch 0105, iter [02800, 05004], lr: 0.004030, loss: 1.4201
2022-07-14 11:12:40 - train: epoch 0105, iter [02900, 05004], lr: 0.004019, loss: 1.3179
2022-07-14 11:13:14 - train: epoch 0105, iter [03000, 05004], lr: 0.004009, loss: 1.1974
2022-07-14 11:13:48 - train: epoch 0105, iter [03100, 05004], lr: 0.003999, loss: 1.3263
2022-07-14 11:14:21 - train: epoch 0105, iter [03200, 05004], lr: 0.003989, loss: 1.4492
2022-07-14 11:14:56 - train: epoch 0105, iter [03300, 05004], lr: 0.003978, loss: 1.1015
2022-07-14 11:15:30 - train: epoch 0105, iter [03400, 05004], lr: 0.003968, loss: 1.0971
2022-07-14 11:16:04 - train: epoch 0105, iter [03500, 05004], lr: 0.003958, loss: 1.3528
2022-07-14 11:16:38 - train: epoch 0105, iter [03600, 05004], lr: 0.003948, loss: 1.4012
2022-07-14 11:17:11 - train: epoch 0105, iter [03700, 05004], lr: 0.003938, loss: 1.1884
2022-07-14 11:17:45 - train: epoch 0105, iter [03800, 05004], lr: 0.003927, loss: 1.4343
2022-07-14 11:18:18 - train: epoch 0105, iter [03900, 05004], lr: 0.003917, loss: 1.2882
2022-07-14 11:18:53 - train: epoch 0105, iter [04000, 05004], lr: 0.003907, loss: 1.0803
2022-07-14 11:19:26 - train: epoch 0105, iter [04100, 05004], lr: 0.003897, loss: 0.9799
2022-07-14 11:20:00 - train: epoch 0105, iter [04200, 05004], lr: 0.003887, loss: 1.1691
2022-07-14 11:20:33 - train: epoch 0105, iter [04300, 05004], lr: 0.003877, loss: 1.3833
2022-07-14 11:21:06 - train: epoch 0105, iter [04400, 05004], lr: 0.003867, loss: 1.1013
2022-07-14 11:21:40 - train: epoch 0105, iter [04500, 05004], lr: 0.003857, loss: 1.4307
2022-07-14 11:22:12 - train: epoch 0105, iter [04600, 05004], lr: 0.003847, loss: 1.2597
2022-07-14 11:22:46 - train: epoch 0105, iter [04700, 05004], lr: 0.003837, loss: 1.2610
2022-07-14 11:23:19 - train: epoch 0105, iter [04800, 05004], lr: 0.003826, loss: 1.2616
2022-07-14 11:23:52 - train: epoch 0105, iter [04900, 05004], lr: 0.003816, loss: 1.1899
2022-07-14 11:24:24 - train: epoch 0105, iter [05000, 05004], lr: 0.003806, loss: 1.0189
2022-07-14 11:24:25 - train: epoch 105, train_loss: 1.2070
2022-07-14 11:25:39 - eval: epoch: 105, acc1: 72.242%, acc5: 90.632%, test_loss: 1.1305, per_image_load_time: 2.589ms, per_image_inference_time: 0.288ms
2022-07-14 11:25:39 - until epoch: 105, best_acc1: 72.242%
2022-07-14 11:25:39 - epoch 106 lr: 0.003806
2022-07-14 11:26:17 - train: epoch 0106, iter [00100, 05004], lr: 0.003796, loss: 0.9919
2022-07-14 11:26:51 - train: epoch 0106, iter [00200, 05004], lr: 0.003786, loss: 1.0364
2022-07-14 11:27:24 - train: epoch 0106, iter [00300, 05004], lr: 0.003776, loss: 1.0008
2022-07-14 11:27:56 - train: epoch 0106, iter [00400, 05004], lr: 0.003766, loss: 1.2344
2022-07-14 11:28:30 - train: epoch 0106, iter [00500, 05004], lr: 0.003756, loss: 1.3273
2022-07-14 11:29:02 - train: epoch 0106, iter [00600, 05004], lr: 0.003746, loss: 1.1405
2022-07-14 11:29:36 - train: epoch 0106, iter [00700, 05004], lr: 0.003736, loss: 1.1753
2022-07-14 11:30:09 - train: epoch 0106, iter [00800, 05004], lr: 0.003726, loss: 1.0395
2022-07-14 11:30:41 - train: epoch 0106, iter [00900, 05004], lr: 0.003716, loss: 1.3326
2022-07-14 11:31:14 - train: epoch 0106, iter [01000, 05004], lr: 0.003707, loss: 1.3697
2022-07-14 11:31:47 - train: epoch 0106, iter [01100, 05004], lr: 0.003697, loss: 0.9564
2022-07-14 11:32:21 - train: epoch 0106, iter [01200, 05004], lr: 0.003687, loss: 1.0643
2022-07-14 11:32:54 - train: epoch 0106, iter [01300, 05004], lr: 0.003677, loss: 1.1527
2022-07-14 11:33:27 - train: epoch 0106, iter [01400, 05004], lr: 0.003667, loss: 1.2158
2022-07-14 11:33:59 - train: epoch 0106, iter [01500, 05004], lr: 0.003657, loss: 1.2835
2022-07-14 11:34:32 - train: epoch 0106, iter [01600, 05004], lr: 0.003647, loss: 1.2442
2022-07-14 11:35:05 - train: epoch 0106, iter [01700, 05004], lr: 0.003638, loss: 1.1278
2022-07-14 11:35:38 - train: epoch 0106, iter [01800, 05004], lr: 0.003628, loss: 1.1026
2022-07-14 11:36:12 - train: epoch 0106, iter [01900, 05004], lr: 0.003618, loss: 1.1474
2022-07-14 11:36:44 - train: epoch 0106, iter [02000, 05004], lr: 0.003608, loss: 1.1735
2022-07-14 11:37:17 - train: epoch 0106, iter [02100, 05004], lr: 0.003599, loss: 1.0841
2022-07-14 11:37:50 - train: epoch 0106, iter [02200, 05004], lr: 0.003589, loss: 1.2277
2022-07-14 11:38:23 - train: epoch 0106, iter [02300, 05004], lr: 0.003579, loss: 1.1494
2022-07-14 11:38:56 - train: epoch 0106, iter [02400, 05004], lr: 0.003569, loss: 1.2227
2022-07-14 11:39:29 - train: epoch 0106, iter [02500, 05004], lr: 0.003560, loss: 1.1745
2022-07-14 11:40:03 - train: epoch 0106, iter [02600, 05004], lr: 0.003550, loss: 0.9620
2022-07-14 11:40:36 - train: epoch 0106, iter [02700, 05004], lr: 0.003540, loss: 1.1458
2022-07-14 11:41:08 - train: epoch 0106, iter [02800, 05004], lr: 0.003531, loss: 1.2089
2022-07-14 11:41:40 - train: epoch 0106, iter [02900, 05004], lr: 0.003521, loss: 1.0201
2022-07-14 11:42:14 - train: epoch 0106, iter [03000, 05004], lr: 0.003511, loss: 1.3612
2022-07-14 11:42:47 - train: epoch 0106, iter [03100, 05004], lr: 0.003502, loss: 1.1987
2022-07-14 11:43:20 - train: epoch 0106, iter [03200, 05004], lr: 0.003492, loss: 0.9409
2022-07-14 11:43:52 - train: epoch 0106, iter [03300, 05004], lr: 0.003483, loss: 1.1712
2022-07-14 11:44:26 - train: epoch 0106, iter [03400, 05004], lr: 0.003473, loss: 1.0794
2022-07-14 11:44:59 - train: epoch 0106, iter [03500, 05004], lr: 0.003463, loss: 1.0822
2022-07-14 11:45:33 - train: epoch 0106, iter [03600, 05004], lr: 0.003454, loss: 1.1048
2022-07-14 11:46:05 - train: epoch 0106, iter [03700, 05004], lr: 0.003444, loss: 1.3513
2022-07-14 11:46:39 - train: epoch 0106, iter [03800, 05004], lr: 0.003435, loss: 1.3514
2022-07-14 11:47:11 - train: epoch 0106, iter [03900, 05004], lr: 0.003425, loss: 1.3182
2022-07-14 11:47:44 - train: epoch 0106, iter [04000, 05004], lr: 0.003416, loss: 1.1604
2022-07-14 11:48:17 - train: epoch 0106, iter [04100, 05004], lr: 0.003406, loss: 1.2897
2022-07-14 11:48:51 - train: epoch 0106, iter [04200, 05004], lr: 0.003397, loss: 1.1014
2022-07-14 11:49:23 - train: epoch 0106, iter [04300, 05004], lr: 0.003387, loss: 0.8928
2022-07-14 11:49:57 - train: epoch 0106, iter [04400, 05004], lr: 0.003378, loss: 1.2357
2022-07-14 11:50:29 - train: epoch 0106, iter [04500, 05004], lr: 0.003368, loss: 1.2480
2022-07-14 11:51:02 - train: epoch 0106, iter [04600, 05004], lr: 0.003359, loss: 1.4732
2022-07-14 11:51:35 - train: epoch 0106, iter [04700, 05004], lr: 0.003350, loss: 1.2015
2022-07-14 11:52:08 - train: epoch 0106, iter [04800, 05004], lr: 0.003340, loss: 1.3268
2022-07-14 11:52:41 - train: epoch 0106, iter [04900, 05004], lr: 0.003331, loss: 1.1850
2022-07-14 11:53:13 - train: epoch 0106, iter [05000, 05004], lr: 0.003321, loss: 1.2448
2022-07-14 11:53:14 - train: epoch 106, train_loss: 1.1884
2022-07-14 11:54:28 - eval: epoch: 106, acc1: 72.540%, acc5: 90.878%, test_loss: 1.1148, per_image_load_time: 2.544ms, per_image_inference_time: 0.292ms
2022-07-14 11:54:28 - until epoch: 106, best_acc1: 72.540%
2022-07-14 11:54:28 - epoch 107 lr: 0.003321
2022-07-14 11:55:07 - train: epoch 0107, iter [00100, 05004], lr: 0.003312, loss: 1.0462
2022-07-14 11:55:40 - train: epoch 0107, iter [00200, 05004], lr: 0.003302, loss: 1.2879
2022-07-14 11:56:14 - train: epoch 0107, iter [00300, 05004], lr: 0.003293, loss: 1.2209
2022-07-14 11:56:46 - train: epoch 0107, iter [00400, 05004], lr: 0.003284, loss: 1.1301
2022-07-14 11:57:19 - train: epoch 0107, iter [00500, 05004], lr: 0.003274, loss: 1.0156
2022-07-14 11:57:53 - train: epoch 0107, iter [00600, 05004], lr: 0.003265, loss: 1.0104
2022-07-14 11:58:26 - train: epoch 0107, iter [00700, 05004], lr: 0.003256, loss: 1.0955
2022-07-14 11:58:59 - train: epoch 0107, iter [00800, 05004], lr: 0.003246, loss: 0.9301
2022-07-14 11:59:31 - train: epoch 0107, iter [00900, 05004], lr: 0.003237, loss: 1.2397
2022-07-14 12:00:04 - train: epoch 0107, iter [01000, 05004], lr: 0.003228, loss: 1.1481
2022-07-14 12:00:37 - train: epoch 0107, iter [01100, 05004], lr: 0.003219, loss: 1.3171
2022-07-14 12:01:10 - train: epoch 0107, iter [01200, 05004], lr: 0.003209, loss: 1.1199
2022-07-14 12:01:43 - train: epoch 0107, iter [01300, 05004], lr: 0.003200, loss: 1.0873
2022-07-14 12:02:15 - train: epoch 0107, iter [01400, 05004], lr: 0.003191, loss: 1.1657
2022-07-14 12:02:48 - train: epoch 0107, iter [01500, 05004], lr: 0.003182, loss: 1.1331
2022-07-14 12:03:21 - train: epoch 0107, iter [01600, 05004], lr: 0.003173, loss: 1.0337
2022-07-14 12:03:54 - train: epoch 0107, iter [01700, 05004], lr: 0.003163, loss: 1.1226
2022-07-14 12:04:27 - train: epoch 0107, iter [01800, 05004], lr: 0.003154, loss: 1.2731
2022-07-14 12:05:01 - train: epoch 0107, iter [01900, 05004], lr: 0.003145, loss: 1.2648
2022-07-14 12:05:33 - train: epoch 0107, iter [02000, 05004], lr: 0.003136, loss: 1.0155
2022-07-14 12:06:05 - train: epoch 0107, iter [02100, 05004], lr: 0.003127, loss: 1.1586
2022-07-14 12:06:39 - train: epoch 0107, iter [02200, 05004], lr: 0.003118, loss: 1.1073
2022-07-14 12:07:12 - train: epoch 0107, iter [02300, 05004], lr: 0.003109, loss: 1.1372
2022-07-14 12:07:44 - train: epoch 0107, iter [02400, 05004], lr: 0.003100, loss: 1.2153
2022-07-14 12:08:18 - train: epoch 0107, iter [02500, 05004], lr: 0.003091, loss: 1.1862
2022-07-14 12:08:51 - train: epoch 0107, iter [02600, 05004], lr: 0.003082, loss: 1.2214
2022-07-14 12:09:24 - train: epoch 0107, iter [02700, 05004], lr: 0.003073, loss: 1.1231
2022-07-14 12:09:58 - train: epoch 0107, iter [02800, 05004], lr: 0.003064, loss: 1.2355
2022-07-14 12:10:32 - train: epoch 0107, iter [02900, 05004], lr: 0.003054, loss: 1.0845
2022-07-14 12:11:05 - train: epoch 0107, iter [03000, 05004], lr: 0.003046, loss: 1.2638
2022-07-14 12:11:38 - train: epoch 0107, iter [03100, 05004], lr: 0.003037, loss: 1.2766
2022-07-14 12:12:12 - train: epoch 0107, iter [03200, 05004], lr: 0.003028, loss: 1.1240
2022-07-14 12:12:45 - train: epoch 0107, iter [03300, 05004], lr: 0.003019, loss: 1.2144
2022-07-14 12:13:18 - train: epoch 0107, iter [03400, 05004], lr: 0.003010, loss: 1.0611
2022-07-14 12:13:52 - train: epoch 0107, iter [03500, 05004], lr: 0.003001, loss: 1.0761
2022-07-14 12:14:24 - train: epoch 0107, iter [03600, 05004], lr: 0.002992, loss: 1.1554
2022-07-14 12:14:58 - train: epoch 0107, iter [03700, 05004], lr: 0.002983, loss: 1.1476
2022-07-14 12:15:31 - train: epoch 0107, iter [03800, 05004], lr: 0.002974, loss: 1.0576
2022-07-14 12:16:05 - train: epoch 0107, iter [03900, 05004], lr: 0.002965, loss: 1.0545
2022-07-14 12:16:38 - train: epoch 0107, iter [04000, 05004], lr: 0.002956, loss: 1.2108
2022-07-14 12:17:12 - train: epoch 0107, iter [04100, 05004], lr: 0.002947, loss: 1.0713
2022-07-14 12:17:45 - train: epoch 0107, iter [04200, 05004], lr: 0.002939, loss: 1.2843
2022-07-14 12:18:19 - train: epoch 0107, iter [04300, 05004], lr: 0.002930, loss: 1.2839
2022-07-14 12:18:53 - train: epoch 0107, iter [04400, 05004], lr: 0.002921, loss: 1.1388
2022-07-14 12:19:26 - train: epoch 0107, iter [04500, 05004], lr: 0.002912, loss: 1.1312
2022-07-14 12:20:00 - train: epoch 0107, iter [04600, 05004], lr: 0.002903, loss: 1.0101
2022-07-14 12:20:34 - train: epoch 0107, iter [04700, 05004], lr: 0.002895, loss: 1.2265
2022-07-14 12:21:07 - train: epoch 0107, iter [04800, 05004], lr: 0.002886, loss: 1.2109
2022-07-14 12:21:41 - train: epoch 0107, iter [04900, 05004], lr: 0.002877, loss: 1.0154
2022-07-14 12:22:12 - train: epoch 0107, iter [05000, 05004], lr: 0.002868, loss: 1.0293
2022-07-14 12:22:13 - train: epoch 107, train_loss: 1.1711
2022-07-14 12:23:28 - eval: epoch: 107, acc1: 72.624%, acc5: 90.918%, test_loss: 1.1047, per_image_load_time: 2.617ms, per_image_inference_time: 0.286ms
2022-07-14 12:23:29 - until epoch: 107, best_acc1: 72.624%
2022-07-14 12:23:29 - epoch 108 lr: 0.002868
2022-07-14 12:24:07 - train: epoch 0108, iter [00100, 05004], lr: 0.002859, loss: 1.0203
2022-07-14 12:24:42 - train: epoch 0108, iter [00200, 05004], lr: 0.002850, loss: 1.0394
2022-07-14 12:25:15 - train: epoch 0108, iter [00300, 05004], lr: 0.002842, loss: 1.1580
2022-07-14 12:25:48 - train: epoch 0108, iter [00400, 05004], lr: 0.002833, loss: 1.3786
2022-07-14 12:26:22 - train: epoch 0108, iter [00500, 05004], lr: 0.002824, loss: 1.0110
2022-07-14 12:26:55 - train: epoch 0108, iter [00600, 05004], lr: 0.002816, loss: 1.1971
2022-07-14 12:27:30 - train: epoch 0108, iter [00700, 05004], lr: 0.002807, loss: 1.1691
2022-07-14 12:28:03 - train: epoch 0108, iter [00800, 05004], lr: 0.002798, loss: 1.1381
2022-07-14 12:28:38 - train: epoch 0108, iter [00900, 05004], lr: 0.002790, loss: 1.2954
2022-07-14 12:29:11 - train: epoch 0108, iter [01000, 05004], lr: 0.002781, loss: 1.1665
2022-07-14 12:29:44 - train: epoch 0108, iter [01100, 05004], lr: 0.002773, loss: 1.1518
2022-07-14 12:30:18 - train: epoch 0108, iter [01200, 05004], lr: 0.002764, loss: 1.1883
2022-07-14 12:30:52 - train: epoch 0108, iter [01300, 05004], lr: 0.002755, loss: 1.1422
2022-07-14 12:31:24 - train: epoch 0108, iter [01400, 05004], lr: 0.002747, loss: 1.1689
2022-07-14 12:31:59 - train: epoch 0108, iter [01500, 05004], lr: 0.002738, loss: 1.3149
2022-07-14 12:32:32 - train: epoch 0108, iter [01600, 05004], lr: 0.002730, loss: 1.1606
2022-07-14 12:33:06 - train: epoch 0108, iter [01700, 05004], lr: 0.002721, loss: 1.1938
2022-07-14 12:33:41 - train: epoch 0108, iter [01800, 05004], lr: 0.002713, loss: 1.1498
2022-07-14 12:34:13 - train: epoch 0108, iter [01900, 05004], lr: 0.002704, loss: 1.1145
2022-07-14 12:34:48 - train: epoch 0108, iter [02000, 05004], lr: 0.002696, loss: 1.2207
2022-07-14 12:35:22 - train: epoch 0108, iter [02100, 05004], lr: 0.002687, loss: 1.1561
2022-07-14 12:35:55 - train: epoch 0108, iter [02200, 05004], lr: 0.002679, loss: 1.1751
2022-07-14 12:36:29 - train: epoch 0108, iter [02300, 05004], lr: 0.002671, loss: 1.1182
2022-07-14 12:37:03 - train: epoch 0108, iter [02400, 05004], lr: 0.002662, loss: 1.3217
2022-07-14 12:37:38 - train: epoch 0108, iter [02500, 05004], lr: 0.002654, loss: 1.4707
2022-07-14 12:38:11 - train: epoch 0108, iter [02600, 05004], lr: 0.002645, loss: 1.2595
2022-07-14 12:38:45 - train: epoch 0108, iter [02700, 05004], lr: 0.002637, loss: 1.2303
2022-07-14 12:39:19 - train: epoch 0108, iter [02800, 05004], lr: 0.002628, loss: 1.1606
2022-07-14 12:39:52 - train: epoch 0108, iter [02900, 05004], lr: 0.002620, loss: 1.2127
2022-07-14 12:40:26 - train: epoch 0108, iter [03000, 05004], lr: 0.002612, loss: 1.2643
2022-07-14 12:41:00 - train: epoch 0108, iter [03100, 05004], lr: 0.002603, loss: 1.0434
2022-07-14 12:41:35 - train: epoch 0108, iter [03200, 05004], lr: 0.002595, loss: 0.9869
2022-07-14 12:42:09 - train: epoch 0108, iter [03300, 05004], lr: 0.002587, loss: 0.9977
2022-07-14 12:42:42 - train: epoch 0108, iter [03400, 05004], lr: 0.002579, loss: 1.3216
2022-07-14 12:43:17 - train: epoch 0108, iter [03500, 05004], lr: 0.002570, loss: 1.1202
2022-07-14 12:43:50 - train: epoch 0108, iter [03600, 05004], lr: 0.002562, loss: 1.2013
2022-07-14 12:44:23 - train: epoch 0108, iter [03700, 05004], lr: 0.002554, loss: 1.1400
2022-07-14 12:44:57 - train: epoch 0108, iter [03800, 05004], lr: 0.002545, loss: 1.1172
2022-07-14 12:45:30 - train: epoch 0108, iter [03900, 05004], lr: 0.002537, loss: 1.2432
2022-07-14 12:46:05 - train: epoch 0108, iter [04000, 05004], lr: 0.002529, loss: 1.1619
2022-07-14 12:46:38 - train: epoch 0108, iter [04100, 05004], lr: 0.002521, loss: 1.1527
2022-07-14 12:47:11 - train: epoch 0108, iter [04200, 05004], lr: 0.002513, loss: 1.1158
2022-07-14 12:47:44 - train: epoch 0108, iter [04300, 05004], lr: 0.002504, loss: 1.1006
2022-07-14 12:48:18 - train: epoch 0108, iter [04400, 05004], lr: 0.002496, loss: 1.1600
2022-07-14 12:48:51 - train: epoch 0108, iter [04500, 05004], lr: 0.002488, loss: 1.2084
2022-07-14 12:49:25 - train: epoch 0108, iter [04600, 05004], lr: 0.002480, loss: 1.1470
2022-07-14 12:49:59 - train: epoch 0108, iter [04700, 05004], lr: 0.002472, loss: 1.1363
2022-07-14 12:50:34 - train: epoch 0108, iter [04800, 05004], lr: 0.002464, loss: 1.0475
2022-07-14 12:51:08 - train: epoch 0108, iter [04900, 05004], lr: 0.002456, loss: 1.1672
2022-07-14 12:51:40 - train: epoch 0108, iter [05000, 05004], lr: 0.002447, loss: 1.1251
2022-07-14 12:51:41 - train: epoch 108, train_loss: 1.1541
2022-07-14 12:52:56 - eval: epoch: 108, acc1: 72.734%, acc5: 90.956%, test_loss: 1.0968, per_image_load_time: 2.600ms, per_image_inference_time: 0.308ms
2022-07-14 12:52:56 - until epoch: 108, best_acc1: 72.734%
2022-07-14 12:52:56 - epoch 109 lr: 0.002447
2022-07-14 12:53:36 - train: epoch 0109, iter [00100, 05004], lr: 0.002439, loss: 1.1959
2022-07-14 12:54:09 - train: epoch 0109, iter [00200, 05004], lr: 0.002431, loss: 1.3212
2022-07-14 12:54:44 - train: epoch 0109, iter [00300, 05004], lr: 0.002423, loss: 1.1680
2022-07-14 12:55:17 - train: epoch 0109, iter [00400, 05004], lr: 0.002415, loss: 1.1242
2022-07-14 12:55:51 - train: epoch 0109, iter [00500, 05004], lr: 0.002407, loss: 1.2388
2022-07-14 12:56:24 - train: epoch 0109, iter [00600, 05004], lr: 0.002399, loss: 1.0818
2022-07-14 12:56:58 - train: epoch 0109, iter [00700, 05004], lr: 0.002391, loss: 1.1055
2022-07-14 12:57:32 - train: epoch 0109, iter [00800, 05004], lr: 0.002383, loss: 1.1791
2022-07-14 12:58:06 - train: epoch 0109, iter [00900, 05004], lr: 0.002375, loss: 1.0976
2022-07-14 12:58:40 - train: epoch 0109, iter [01000, 05004], lr: 0.002367, loss: 0.9457
2022-07-14 12:59:13 - train: epoch 0109, iter [01100, 05004], lr: 0.002359, loss: 0.9902
2022-07-14 12:59:47 - train: epoch 0109, iter [01200, 05004], lr: 0.002351, loss: 1.0604
2022-07-14 13:00:21 - train: epoch 0109, iter [01300, 05004], lr: 0.002343, loss: 0.9252
2022-07-14 13:00:55 - train: epoch 0109, iter [01400, 05004], lr: 0.002335, loss: 1.0854
2022-07-14 13:01:29 - train: epoch 0109, iter [01500, 05004], lr: 0.002327, loss: 1.3175
2022-07-14 13:02:02 - train: epoch 0109, iter [01600, 05004], lr: 0.002320, loss: 1.0690
2022-07-14 13:02:36 - train: epoch 0109, iter [01700, 05004], lr: 0.002312, loss: 1.3456
2022-07-14 13:03:09 - train: epoch 0109, iter [01800, 05004], lr: 0.002304, loss: 1.2220
2022-07-14 13:03:42 - train: epoch 0109, iter [01900, 05004], lr: 0.002296, loss: 1.1363
2022-07-14 13:04:16 - train: epoch 0109, iter [02000, 05004], lr: 0.002288, loss: 1.1789
2022-07-14 13:04:49 - train: epoch 0109, iter [02100, 05004], lr: 0.002280, loss: 1.1861
2022-07-14 13:05:24 - train: epoch 0109, iter [02200, 05004], lr: 0.002272, loss: 1.0645
2022-07-14 13:05:58 - train: epoch 0109, iter [02300, 05004], lr: 0.002265, loss: 1.0635
2022-07-14 13:06:31 - train: epoch 0109, iter [02400, 05004], lr: 0.002257, loss: 1.2723
2022-07-14 13:07:05 - train: epoch 0109, iter [02500, 05004], lr: 0.002249, loss: 1.1042
2022-07-14 13:07:39 - train: epoch 0109, iter [02600, 05004], lr: 0.002241, loss: 1.2886
2022-07-14 13:08:13 - train: epoch 0109, iter [02700, 05004], lr: 0.002234, loss: 1.1089
2022-07-14 13:08:47 - train: epoch 0109, iter [02800, 05004], lr: 0.002226, loss: 1.1956
2022-07-14 13:09:21 - train: epoch 0109, iter [02900, 05004], lr: 0.002218, loss: 1.0769
2022-07-14 13:09:55 - train: epoch 0109, iter [03000, 05004], lr: 0.002211, loss: 1.0129
2022-07-14 13:10:29 - train: epoch 0109, iter [03100, 05004], lr: 0.002203, loss: 1.1284
2022-07-14 13:11:02 - train: epoch 0109, iter [03200, 05004], lr: 0.002195, loss: 0.9823
2022-07-14 13:11:36 - train: epoch 0109, iter [03300, 05004], lr: 0.002188, loss: 1.2167
2022-07-14 13:12:10 - train: epoch 0109, iter [03400, 05004], lr: 0.002180, loss: 1.1914
2022-07-14 13:12:44 - train: epoch 0109, iter [03500, 05004], lr: 0.002172, loss: 1.0403
2022-07-14 13:13:18 - train: epoch 0109, iter [03600, 05004], lr: 0.002165, loss: 1.0715
2022-07-14 13:13:52 - train: epoch 0109, iter [03700, 05004], lr: 0.002157, loss: 0.8299
2022-07-14 13:14:25 - train: epoch 0109, iter [03800, 05004], lr: 0.002149, loss: 1.1641
2022-07-14 13:15:00 - train: epoch 0109, iter [03900, 05004], lr: 0.002142, loss: 1.1935
2022-07-14 13:15:35 - train: epoch 0109, iter [04000, 05004], lr: 0.002134, loss: 1.1046
2022-07-14 13:16:07 - train: epoch 0109, iter [04100, 05004], lr: 0.002127, loss: 1.1194
2022-07-14 13:16:42 - train: epoch 0109, iter [04200, 05004], lr: 0.002119, loss: 1.2891
2022-07-14 13:17:16 - train: epoch 0109, iter [04300, 05004], lr: 0.002112, loss: 1.0557
2022-07-14 13:17:50 - train: epoch 0109, iter [04400, 05004], lr: 0.002104, loss: 0.9992
2022-07-14 13:18:23 - train: epoch 0109, iter [04500, 05004], lr: 0.002097, loss: 1.0348
2022-07-14 13:18:58 - train: epoch 0109, iter [04600, 05004], lr: 0.002089, loss: 1.1463
2022-07-14 13:19:31 - train: epoch 0109, iter [04700, 05004], lr: 0.002082, loss: 1.0598
2022-07-14 13:20:05 - train: epoch 0109, iter [04800, 05004], lr: 0.002074, loss: 1.2093
2022-07-14 13:20:39 - train: epoch 0109, iter [04900, 05004], lr: 0.002067, loss: 1.1567
2022-07-14 13:21:11 - train: epoch 0109, iter [05000, 05004], lr: 0.002059, loss: 0.9798
2022-07-14 13:21:12 - train: epoch 109, train_loss: 1.1359
2022-07-14 13:22:27 - eval: epoch: 109, acc1: 72.902%, acc5: 91.086%, test_loss: 1.0898, per_image_load_time: 1.896ms, per_image_inference_time: 0.304ms
2022-07-14 13:22:27 - until epoch: 109, best_acc1: 72.902%
2022-07-14 13:22:27 - epoch 110 lr: 0.002059
2022-07-14 13:23:07 - train: epoch 0110, iter [00100, 05004], lr: 0.002052, loss: 0.9408
2022-07-14 13:23:42 - train: epoch 0110, iter [00200, 05004], lr: 0.002044, loss: 0.9849
2022-07-14 13:24:15 - train: epoch 0110, iter [00300, 05004], lr: 0.002037, loss: 1.2184
2022-07-14 13:24:49 - train: epoch 0110, iter [00400, 05004], lr: 0.002029, loss: 1.0837
2022-07-14 13:25:23 - train: epoch 0110, iter [00500, 05004], lr: 0.002022, loss: 1.0053
2022-07-14 13:25:57 - train: epoch 0110, iter [00600, 05004], lr: 0.002015, loss: 1.1388
2022-07-14 13:26:31 - train: epoch 0110, iter [00700, 05004], lr: 0.002007, loss: 1.0766
2022-07-14 13:27:05 - train: epoch 0110, iter [00800, 05004], lr: 0.002000, loss: 1.1029
2022-07-14 13:27:39 - train: epoch 0110, iter [00900, 05004], lr: 0.001993, loss: 1.1031
2022-07-14 13:28:12 - train: epoch 0110, iter [01000, 05004], lr: 0.001985, loss: 0.9806
2022-07-14 13:28:47 - train: epoch 0110, iter [01100, 05004], lr: 0.001978, loss: 1.5676
2022-07-14 13:29:20 - train: epoch 0110, iter [01200, 05004], lr: 0.001971, loss: 1.0758
2022-07-14 13:29:55 - train: epoch 0110, iter [01300, 05004], lr: 0.001964, loss: 1.0336
2022-07-14 13:30:29 - train: epoch 0110, iter [01400, 05004], lr: 0.001956, loss: 0.9234
2022-07-14 13:31:04 - train: epoch 0110, iter [01500, 05004], lr: 0.001949, loss: 1.2881
2022-07-14 13:31:38 - train: epoch 0110, iter [01600, 05004], lr: 0.001942, loss: 1.1749
2022-07-14 13:32:11 - train: epoch 0110, iter [01700, 05004], lr: 0.001935, loss: 1.0844
2022-07-14 13:32:46 - train: epoch 0110, iter [01800, 05004], lr: 0.001927, loss: 1.1318
2022-07-14 13:33:19 - train: epoch 0110, iter [01900, 05004], lr: 0.001920, loss: 1.3278
2022-07-14 13:33:54 - train: epoch 0110, iter [02000, 05004], lr: 0.001913, loss: 1.1216
2022-07-14 13:34:28 - train: epoch 0110, iter [02100, 05004], lr: 0.001906, loss: 1.1756
2022-07-14 13:35:02 - train: epoch 0110, iter [02200, 05004], lr: 0.001899, loss: 1.1498
2022-07-14 13:35:35 - train: epoch 0110, iter [02300, 05004], lr: 0.001892, loss: 1.0438
2022-07-14 13:36:10 - train: epoch 0110, iter [02400, 05004], lr: 0.001884, loss: 1.0446
2022-07-14 13:36:44 - train: epoch 0110, iter [02500, 05004], lr: 0.001877, loss: 1.0431
2022-07-14 13:37:20 - train: epoch 0110, iter [02600, 05004], lr: 0.001870, loss: 1.3252
2022-07-14 13:37:54 - train: epoch 0110, iter [02700, 05004], lr: 0.001863, loss: 1.0435
2022-07-14 13:38:28 - train: epoch 0110, iter [02800, 05004], lr: 0.001856, loss: 1.1658
2022-07-14 13:39:02 - train: epoch 0110, iter [02900, 05004], lr: 0.001849, loss: 1.1236
2022-07-14 13:39:36 - train: epoch 0110, iter [03000, 05004], lr: 0.001842, loss: 1.0983
2022-07-14 13:40:11 - train: epoch 0110, iter [03100, 05004], lr: 0.001835, loss: 1.2417
2022-07-14 13:40:45 - train: epoch 0110, iter [03200, 05004], lr: 0.001828, loss: 1.3187
2022-07-14 13:41:19 - train: epoch 0110, iter [03300, 05004], lr: 0.001821, loss: 1.1373
2022-07-14 13:41:54 - train: epoch 0110, iter [03400, 05004], lr: 0.001814, loss: 0.9745
2022-07-14 13:42:28 - train: epoch 0110, iter [03500, 05004], lr: 0.001807, loss: 1.4199
2022-07-14 13:43:02 - train: epoch 0110, iter [03600, 05004], lr: 0.001800, loss: 1.3592
2022-07-14 13:43:37 - train: epoch 0110, iter [03700, 05004], lr: 0.001793, loss: 1.2467
2022-07-14 13:44:11 - train: epoch 0110, iter [03800, 05004], lr: 0.001786, loss: 1.0744
2022-07-14 13:44:45 - train: epoch 0110, iter [03900, 05004], lr: 0.001779, loss: 1.2072
2022-07-14 13:45:19 - train: epoch 0110, iter [04000, 05004], lr: 0.001772, loss: 1.0741
2022-07-14 13:45:54 - train: epoch 0110, iter [04100, 05004], lr: 0.001765, loss: 1.0999
2022-07-14 13:46:28 - train: epoch 0110, iter [04200, 05004], lr: 0.001759, loss: 1.1614
2022-07-14 13:47:03 - train: epoch 0110, iter [04300, 05004], lr: 0.001752, loss: 1.0518
2022-07-14 13:47:36 - train: epoch 0110, iter [04400, 05004], lr: 0.001745, loss: 1.2757
2022-07-14 13:48:10 - train: epoch 0110, iter [04500, 05004], lr: 0.001738, loss: 1.0459
2022-07-14 13:48:45 - train: epoch 0110, iter [04600, 05004], lr: 0.001731, loss: 0.9248
2022-07-14 13:49:18 - train: epoch 0110, iter [04700, 05004], lr: 0.001724, loss: 1.2308
2022-07-14 13:49:52 - train: epoch 0110, iter [04800, 05004], lr: 0.001718, loss: 1.3666
2022-07-14 13:50:24 - train: epoch 0110, iter [04900, 05004], lr: 0.001711, loss: 1.1216
2022-07-14 13:50:56 - train: epoch 0110, iter [05000, 05004], lr: 0.001704, loss: 1.1196
2022-07-14 13:50:57 - train: epoch 110, train_loss: 1.1204
2022-07-14 13:52:11 - eval: epoch: 110, acc1: 73.420%, acc5: 91.212%, test_loss: 1.0786, per_image_load_time: 2.033ms, per_image_inference_time: 0.295ms
2022-07-14 13:52:11 - until epoch: 110, best_acc1: 73.420%
2022-07-14 13:52:11 - epoch 111 lr: 0.001704
2022-07-14 13:52:49 - train: epoch 0111, iter [00100, 05004], lr: 0.001697, loss: 0.9830
2022-07-14 13:53:22 - train: epoch 0111, iter [00200, 05004], lr: 0.001690, loss: 1.1304
2022-07-14 13:53:56 - train: epoch 0111, iter [00300, 05004], lr: 0.001683, loss: 1.2155
2022-07-14 13:54:30 - train: epoch 0111, iter [00400, 05004], lr: 0.001677, loss: 1.1254
2022-07-14 13:55:03 - train: epoch 0111, iter [00500, 05004], lr: 0.001670, loss: 1.1125
2022-07-14 13:55:36 - train: epoch 0111, iter [00600, 05004], lr: 0.001663, loss: 1.3249
2022-07-14 13:56:09 - train: epoch 0111, iter [00700, 05004], lr: 0.001657, loss: 1.1717
2022-07-14 13:56:43 - train: epoch 0111, iter [00800, 05004], lr: 0.001650, loss: 1.1805
2022-07-14 13:57:15 - train: epoch 0111, iter [00900, 05004], lr: 0.001643, loss: 1.0400
2022-07-14 13:57:49 - train: epoch 0111, iter [01000, 05004], lr: 0.001637, loss: 1.0036
2022-07-14 13:58:23 - train: epoch 0111, iter [01100, 05004], lr: 0.001630, loss: 1.1084
2022-07-14 13:58:57 - train: epoch 0111, iter [01200, 05004], lr: 0.001623, loss: 1.0320
2022-07-14 13:59:30 - train: epoch 0111, iter [01300, 05004], lr: 0.001617, loss: 1.1336
2022-07-14 14:00:03 - train: epoch 0111, iter [01400, 05004], lr: 0.001610, loss: 0.9381
2022-07-14 14:00:35 - train: epoch 0111, iter [01500, 05004], lr: 0.001604, loss: 1.0710
2022-07-14 14:01:09 - train: epoch 0111, iter [01600, 05004], lr: 0.001597, loss: 0.9822
2022-07-14 14:01:42 - train: epoch 0111, iter [01700, 05004], lr: 0.001591, loss: 1.1751
2022-07-14 14:02:17 - train: epoch 0111, iter [01800, 05004], lr: 0.001584, loss: 1.0213
2022-07-14 14:02:50 - train: epoch 0111, iter [01900, 05004], lr: 0.001577, loss: 1.0267
2022-07-14 14:03:23 - train: epoch 0111, iter [02000, 05004], lr: 0.001571, loss: 1.0941
2022-07-14 14:03:56 - train: epoch 0111, iter [02100, 05004], lr: 0.001564, loss: 1.3021
2022-07-14 14:04:29 - train: epoch 0111, iter [02200, 05004], lr: 0.001558, loss: 1.2438
2022-07-14 14:05:02 - train: epoch 0111, iter [02300, 05004], lr: 0.001551, loss: 1.0048
2022-07-14 14:05:35 - train: epoch 0111, iter [02400, 05004], lr: 0.001545, loss: 1.1037
2022-07-14 14:06:08 - train: epoch 0111, iter [02500, 05004], lr: 0.001539, loss: 1.1175
2022-07-14 14:06:40 - train: epoch 0111, iter [02600, 05004], lr: 0.001532, loss: 0.9432
2022-07-14 14:07:13 - train: epoch 0111, iter [02700, 05004], lr: 0.001526, loss: 1.2819
2022-07-14 14:07:46 - train: epoch 0111, iter [02800, 05004], lr: 0.001519, loss: 1.0470
2022-07-14 14:08:18 - train: epoch 0111, iter [02900, 05004], lr: 0.001513, loss: 0.9645
2022-07-14 14:08:50 - train: epoch 0111, iter [03000, 05004], lr: 0.001507, loss: 1.2273
2022-07-14 14:09:23 - train: epoch 0111, iter [03100, 05004], lr: 0.001500, loss: 1.0912
2022-07-14 14:09:56 - train: epoch 0111, iter [03200, 05004], lr: 0.001494, loss: 1.1974
2022-07-14 14:10:29 - train: epoch 0111, iter [03300, 05004], lr: 0.001487, loss: 1.3470
2022-07-14 14:11:02 - train: epoch 0111, iter [03400, 05004], lr: 0.001481, loss: 1.3564
2022-07-14 14:11:35 - train: epoch 0111, iter [03500, 05004], lr: 0.001475, loss: 1.2675
2022-07-14 14:12:08 - train: epoch 0111, iter [03600, 05004], lr: 0.001469, loss: 1.0230
2022-07-14 14:12:40 - train: epoch 0111, iter [03700, 05004], lr: 0.001462, loss: 1.0530
2022-07-14 14:13:13 - train: epoch 0111, iter [03800, 05004], lr: 0.001456, loss: 1.0185
2022-07-14 14:13:46 - train: epoch 0111, iter [03900, 05004], lr: 0.001450, loss: 1.0032
2022-07-14 14:14:20 - train: epoch 0111, iter [04000, 05004], lr: 0.001443, loss: 1.1218
2022-07-14 14:14:53 - train: epoch 0111, iter [04100, 05004], lr: 0.001437, loss: 1.4407
2022-07-14 14:15:26 - train: epoch 0111, iter [04200, 05004], lr: 0.001431, loss: 1.1440
2022-07-14 14:15:59 - train: epoch 0111, iter [04300, 05004], lr: 0.001425, loss: 1.0392
2022-07-14 14:16:33 - train: epoch 0111, iter [04400, 05004], lr: 0.001419, loss: 0.9472
2022-07-14 14:17:06 - train: epoch 0111, iter [04500, 05004], lr: 0.001412, loss: 1.1079
2022-07-14 14:17:38 - train: epoch 0111, iter [04600, 05004], lr: 0.001406, loss: 1.1049
2022-07-14 14:18:12 - train: epoch 0111, iter [04700, 05004], lr: 0.001400, loss: 1.1486
2022-07-14 14:18:45 - train: epoch 0111, iter [04800, 05004], lr: 0.001394, loss: 1.1849
2022-07-14 14:19:18 - train: epoch 0111, iter [04900, 05004], lr: 0.001388, loss: 1.0596
2022-07-14 14:19:50 - train: epoch 0111, iter [05000, 05004], lr: 0.001382, loss: 1.2075
2022-07-14 14:19:51 - train: epoch 111, train_loss: 1.1066
2022-07-14 14:21:05 - eval: epoch: 111, acc1: 73.456%, acc5: 91.330%, test_loss: 1.0704, per_image_load_time: 2.565ms, per_image_inference_time: 0.291ms
2022-07-14 14:21:05 - until epoch: 111, best_acc1: 73.456%
2022-07-14 14:21:05 - epoch 112 lr: 0.001381
2022-07-14 14:21:44 - train: epoch 0112, iter [00100, 05004], lr: 0.001375, loss: 1.1471
2022-07-14 14:22:16 - train: epoch 0112, iter [00200, 05004], lr: 0.001369, loss: 1.0708
2022-07-14 14:22:49 - train: epoch 0112, iter [00300, 05004], lr: 0.001363, loss: 0.9221
2022-07-14 14:23:23 - train: epoch 0112, iter [00400, 05004], lr: 0.001357, loss: 0.9231
2022-07-14 14:23:55 - train: epoch 0112, iter [00500, 05004], lr: 0.001351, loss: 1.1414
2022-07-14 14:24:28 - train: epoch 0112, iter [00600, 05004], lr: 0.001345, loss: 1.1090
2022-07-14 14:25:00 - train: epoch 0112, iter [00700, 05004], lr: 0.001339, loss: 1.1502
2022-07-14 14:25:33 - train: epoch 0112, iter [00800, 05004], lr: 0.001333, loss: 0.9824
2022-07-14 14:26:06 - train: epoch 0112, iter [00900, 05004], lr: 0.001327, loss: 0.9522
2022-07-14 14:26:39 - train: epoch 0112, iter [01000, 05004], lr: 0.001321, loss: 1.1511
2022-07-14 14:27:12 - train: epoch 0112, iter [01100, 05004], lr: 0.001315, loss: 1.0032
2022-07-14 14:27:45 - train: epoch 0112, iter [01200, 05004], lr: 0.001309, loss: 1.2469
2022-07-14 14:28:18 - train: epoch 0112, iter [01300, 05004], lr: 0.001303, loss: 1.1888
2022-07-14 14:28:51 - train: epoch 0112, iter [01400, 05004], lr: 0.001297, loss: 0.9967
2022-07-14 14:29:24 - train: epoch 0112, iter [01500, 05004], lr: 0.001291, loss: 1.1958
2022-07-14 14:29:57 - train: epoch 0112, iter [01600, 05004], lr: 0.001286, loss: 1.1448
2022-07-14 14:30:31 - train: epoch 0112, iter [01700, 05004], lr: 0.001280, loss: 0.9810
2022-07-14 14:31:03 - train: epoch 0112, iter [01800, 05004], lr: 0.001274, loss: 0.9029
2022-07-14 14:31:36 - train: epoch 0112, iter [01900, 05004], lr: 0.001268, loss: 0.8817
2022-07-14 14:32:09 - train: epoch 0112, iter [02000, 05004], lr: 0.001262, loss: 1.0511
2022-07-14 14:32:43 - train: epoch 0112, iter [02100, 05004], lr: 0.001256, loss: 1.0956
2022-07-14 14:33:15 - train: epoch 0112, iter [02200, 05004], lr: 0.001250, loss: 0.9290
2022-07-14 14:33:48 - train: epoch 0112, iter [02300, 05004], lr: 0.001245, loss: 0.9606
2022-07-14 14:34:21 - train: epoch 0112, iter [02400, 05004], lr: 0.001239, loss: 0.9263
2022-07-14 14:34:55 - train: epoch 0112, iter [02500, 05004], lr: 0.001233, loss: 1.0813
2022-07-14 14:35:29 - train: epoch 0112, iter [02600, 05004], lr: 0.001227, loss: 0.9830
2022-07-14 14:36:02 - train: epoch 0112, iter [02700, 05004], lr: 0.001221, loss: 1.1695
2022-07-14 14:36:35 - train: epoch 0112, iter [02800, 05004], lr: 0.001216, loss: 1.1230
2022-07-14 14:37:08 - train: epoch 0112, iter [02900, 05004], lr: 0.001210, loss: 1.1829
2022-07-14 14:37:42 - train: epoch 0112, iter [03000, 05004], lr: 0.001204, loss: 1.2054
2022-07-14 14:38:15 - train: epoch 0112, iter [03100, 05004], lr: 0.001199, loss: 1.1340
2022-07-14 14:38:48 - train: epoch 0112, iter [03200, 05004], lr: 0.001193, loss: 1.0458
2022-07-14 14:39:22 - train: epoch 0112, iter [03300, 05004], lr: 0.001187, loss: 1.1081
2022-07-14 14:39:55 - train: epoch 0112, iter [03400, 05004], lr: 0.001182, loss: 1.1072
2022-07-14 14:40:29 - train: epoch 0112, iter [03500, 05004], lr: 0.001176, loss: 0.9577
2022-07-14 14:41:02 - train: epoch 0112, iter [03600, 05004], lr: 0.001170, loss: 1.1907
2022-07-14 14:41:35 - train: epoch 0112, iter [03700, 05004], lr: 0.001165, loss: 1.1454
2022-07-14 14:42:08 - train: epoch 0112, iter [03800, 05004], lr: 0.001159, loss: 1.0845
2022-07-14 14:42:42 - train: epoch 0112, iter [03900, 05004], lr: 0.001153, loss: 1.0843
2022-07-14 14:43:16 - train: epoch 0112, iter [04000, 05004], lr: 0.001148, loss: 1.0257
2022-07-14 14:43:48 - train: epoch 0112, iter [04100, 05004], lr: 0.001142, loss: 0.9333
2022-07-14 14:44:22 - train: epoch 0112, iter [04200, 05004], lr: 0.001137, loss: 0.9352
2022-07-14 14:44:54 - train: epoch 0112, iter [04300, 05004], lr: 0.001131, loss: 1.0559
2022-07-14 14:45:27 - train: epoch 0112, iter [04400, 05004], lr: 0.001126, loss: 1.2985
2022-07-14 14:46:02 - train: epoch 0112, iter [04500, 05004], lr: 0.001120, loss: 1.0261
2022-07-14 14:46:34 - train: epoch 0112, iter [04600, 05004], lr: 0.001115, loss: 1.1816
2022-07-14 14:47:07 - train: epoch 0112, iter [04700, 05004], lr: 0.001109, loss: 0.9922
2022-07-14 14:47:40 - train: epoch 0112, iter [04800, 05004], lr: 0.001104, loss: 1.1303
2022-07-14 14:48:13 - train: epoch 0112, iter [04900, 05004], lr: 0.001098, loss: 1.0122
2022-07-14 14:48:45 - train: epoch 0112, iter [05000, 05004], lr: 0.001093, loss: 0.9467
2022-07-14 14:48:45 - train: epoch 112, train_loss: 1.0931
2022-07-14 14:49:59 - eval: epoch: 112, acc1: 73.602%, acc5: 91.320%, test_loss: 1.0657, per_image_load_time: 2.579ms, per_image_inference_time: 0.275ms
2022-07-14 14:49:59 - until epoch: 112, best_acc1: 73.602%
2022-07-14 14:49:59 - epoch 113 lr: 0.001093
2022-07-14 14:50:39 - train: epoch 0113, iter [00100, 05004], lr: 0.001087, loss: 1.2118
2022-07-14 14:51:11 - train: epoch 0113, iter [00200, 05004], lr: 0.001082, loss: 1.0372
2022-07-14 14:51:44 - train: epoch 0113, iter [00300, 05004], lr: 0.001076, loss: 0.9455
2022-07-14 14:52:17 - train: epoch 0113, iter [00400, 05004], lr: 0.001071, loss: 1.1598
2022-07-14 14:52:50 - train: epoch 0113, iter [00500, 05004], lr: 0.001066, loss: 1.2055
2022-07-14 14:53:22 - train: epoch 0113, iter [00600, 05004], lr: 0.001060, loss: 1.0654
2022-07-14 14:53:55 - train: epoch 0113, iter [00700, 05004], lr: 0.001055, loss: 1.0306
2022-07-14 14:54:27 - train: epoch 0113, iter [00800, 05004], lr: 0.001050, loss: 1.1675
2022-07-14 14:55:01 - train: epoch 0113, iter [00900, 05004], lr: 0.001044, loss: 0.9639
2022-07-14 14:55:34 - train: epoch 0113, iter [01000, 05004], lr: 0.001039, loss: 1.1336
2022-07-14 14:56:06 - train: epoch 0113, iter [01100, 05004], lr: 0.001034, loss: 1.0870
2022-07-14 14:56:40 - train: epoch 0113, iter [01200, 05004], lr: 0.001028, loss: 1.1752
2022-07-14 14:57:13 - train: epoch 0113, iter [01300, 05004], lr: 0.001023, loss: 0.9678
2022-07-14 14:57:45 - train: epoch 0113, iter [01400, 05004], lr: 0.001018, loss: 1.1913
2022-07-14 14:58:18 - train: epoch 0113, iter [01500, 05004], lr: 0.001013, loss: 1.1462
2022-07-14 14:58:51 - train: epoch 0113, iter [01600, 05004], lr: 0.001007, loss: 1.0825
2022-07-14 14:59:23 - train: epoch 0113, iter [01700, 05004], lr: 0.001002, loss: 1.0173
2022-07-14 14:59:57 - train: epoch 0113, iter [01800, 05004], lr: 0.000997, loss: 0.8968
2022-07-14 15:00:31 - train: epoch 0113, iter [01900, 05004], lr: 0.000992, loss: 1.0398
2022-07-14 15:01:03 - train: epoch 0113, iter [02000, 05004], lr: 0.000987, loss: 1.1139
2022-07-14 15:01:37 - train: epoch 0113, iter [02100, 05004], lr: 0.000981, loss: 1.2828
2022-07-14 15:02:09 - train: epoch 0113, iter [02200, 05004], lr: 0.000976, loss: 1.1384
2022-07-14 15:02:42 - train: epoch 0113, iter [02300, 05004], lr: 0.000971, loss: 1.1724
2022-07-14 15:03:15 - train: epoch 0113, iter [02400, 05004], lr: 0.000966, loss: 1.1190
2022-07-14 15:03:48 - train: epoch 0113, iter [02500, 05004], lr: 0.000961, loss: 1.1311
2022-07-14 15:04:21 - train: epoch 0113, iter [02600, 05004], lr: 0.000956, loss: 0.8780
2022-07-14 15:04:54 - train: epoch 0113, iter [02700, 05004], lr: 0.000951, loss: 1.0327
2022-07-14 15:05:27 - train: epoch 0113, iter [02800, 05004], lr: 0.000946, loss: 1.1002
2022-07-14 15:05:59 - train: epoch 0113, iter [02900, 05004], lr: 0.000941, loss: 1.0838
2022-07-14 15:06:31 - train: epoch 0113, iter [03000, 05004], lr: 0.000935, loss: 1.0226
2022-07-14 15:07:05 - train: epoch 0113, iter [03100, 05004], lr: 0.000930, loss: 0.9236
2022-07-14 15:07:38 - train: epoch 0113, iter [03200, 05004], lr: 0.000925, loss: 0.9195
2022-07-14 15:08:10 - train: epoch 0113, iter [03300, 05004], lr: 0.000920, loss: 1.1063
2022-07-14 15:08:43 - train: epoch 0113, iter [03400, 05004], lr: 0.000915, loss: 0.9626
2022-07-14 15:09:16 - train: epoch 0113, iter [03500, 05004], lr: 0.000910, loss: 1.0741
2022-07-14 15:09:49 - train: epoch 0113, iter [03600, 05004], lr: 0.000906, loss: 1.3388
2022-07-14 15:10:22 - train: epoch 0113, iter [03700, 05004], lr: 0.000901, loss: 0.8769
2022-07-14 15:10:54 - train: epoch 0113, iter [03800, 05004], lr: 0.000896, loss: 1.1489
2022-07-14 15:11:29 - train: epoch 0113, iter [03900, 05004], lr: 0.000891, loss: 1.2180
2022-07-14 15:12:00 - train: epoch 0113, iter [04000, 05004], lr: 0.000886, loss: 1.0262
2022-07-14 15:12:33 - train: epoch 0113, iter [04100, 05004], lr: 0.000881, loss: 1.1155
2022-07-14 15:13:06 - train: epoch 0113, iter [04200, 05004], lr: 0.000876, loss: 1.1853
2022-07-14 15:13:40 - train: epoch 0113, iter [04300, 05004], lr: 0.000871, loss: 0.9658
2022-07-14 15:14:12 - train: epoch 0113, iter [04400, 05004], lr: 0.000866, loss: 0.9670
2022-07-14 15:14:45 - train: epoch 0113, iter [04500, 05004], lr: 0.000861, loss: 1.0970
2022-07-14 15:15:19 - train: epoch 0113, iter [04600, 05004], lr: 0.000857, loss: 1.3110
2022-07-14 15:15:51 - train: epoch 0113, iter [04700, 05004], lr: 0.000852, loss: 1.0291
2022-07-14 15:16:25 - train: epoch 0113, iter [04800, 05004], lr: 0.000847, loss: 1.2244
2022-07-14 15:16:58 - train: epoch 0113, iter [04900, 05004], lr: 0.000842, loss: 0.9999
2022-07-14 15:17:29 - train: epoch 0113, iter [05000, 05004], lr: 0.000837, loss: 1.1297
2022-07-14 15:17:30 - train: epoch 113, train_loss: 1.0798
2022-07-14 15:18:45 - eval: epoch: 113, acc1: 73.588%, acc5: 91.392%, test_loss: 1.0595, per_image_load_time: 2.626ms, per_image_inference_time: 0.270ms
2022-07-14 15:18:45 - until epoch: 113, best_acc1: 73.602%
2022-07-14 15:18:45 - epoch 114 lr: 0.000837
2022-07-14 15:19:24 - train: epoch 0114, iter [00100, 05004], lr: 0.000832, loss: 1.1957
2022-07-14 15:19:56 - train: epoch 0114, iter [00200, 05004], lr: 0.000828, loss: 1.0320
2022-07-14 15:20:30 - train: epoch 0114, iter [00300, 05004], lr: 0.000823, loss: 1.2058
2022-07-14 15:21:04 - train: epoch 0114, iter [00400, 05004], lr: 0.000818, loss: 1.2155
2022-07-14 15:21:36 - train: epoch 0114, iter [00500, 05004], lr: 0.000814, loss: 1.0542
2022-07-14 15:22:10 - train: epoch 0114, iter [00600, 05004], lr: 0.000809, loss: 1.1340
2022-07-14 15:22:41 - train: epoch 0114, iter [00700, 05004], lr: 0.000804, loss: 1.1020
2022-07-14 15:23:15 - train: epoch 0114, iter [00800, 05004], lr: 0.000800, loss: 1.0586
2022-07-14 15:23:47 - train: epoch 0114, iter [00900, 05004], lr: 0.000795, loss: 1.0027
2022-07-14 15:24:21 - train: epoch 0114, iter [01000, 05004], lr: 0.000790, loss: 1.1005
2022-07-14 15:24:54 - train: epoch 0114, iter [01100, 05004], lr: 0.000786, loss: 1.0459
2022-07-14 15:25:28 - train: epoch 0114, iter [01200, 05004], lr: 0.000781, loss: 1.1072
2022-07-14 15:26:00 - train: epoch 0114, iter [01300, 05004], lr: 0.000776, loss: 0.8787
2022-07-14 15:26:34 - train: epoch 0114, iter [01400, 05004], lr: 0.000772, loss: 1.1047
2022-07-14 15:27:07 - train: epoch 0114, iter [01500, 05004], lr: 0.000767, loss: 0.9958
2022-07-14 15:27:40 - train: epoch 0114, iter [01600, 05004], lr: 0.000763, loss: 0.8966
2022-07-14 15:28:12 - train: epoch 0114, iter [01700, 05004], lr: 0.000758, loss: 0.8865
2022-07-14 15:28:45 - train: epoch 0114, iter [01800, 05004], lr: 0.000754, loss: 1.1142
2022-07-14 15:29:18 - train: epoch 0114, iter [01900, 05004], lr: 0.000749, loss: 0.7543
2022-07-14 15:29:51 - train: epoch 0114, iter [02000, 05004], lr: 0.000745, loss: 1.1071
2022-07-14 15:30:24 - train: epoch 0114, iter [02100, 05004], lr: 0.000740, loss: 1.0634
2022-07-14 15:30:58 - train: epoch 0114, iter [02200, 05004], lr: 0.000736, loss: 1.0735
2022-07-14 15:31:32 - train: epoch 0114, iter [02300, 05004], lr: 0.000731, loss: 1.1482
2022-07-14 15:32:05 - train: epoch 0114, iter [02400, 05004], lr: 0.000727, loss: 1.1157
2022-07-14 15:32:38 - train: epoch 0114, iter [02500, 05004], lr: 0.000722, loss: 0.9876
2022-07-14 15:33:11 - train: epoch 0114, iter [02600, 05004], lr: 0.000718, loss: 0.9169
2022-07-14 15:33:45 - train: epoch 0114, iter [02700, 05004], lr: 0.000713, loss: 1.0440
2022-07-14 15:34:18 - train: epoch 0114, iter [02800, 05004], lr: 0.000709, loss: 1.2443
2022-07-14 15:34:51 - train: epoch 0114, iter [02900, 05004], lr: 0.000705, loss: 0.9693
2022-07-14 15:35:25 - train: epoch 0114, iter [03000, 05004], lr: 0.000700, loss: 0.9832
2022-07-14 15:35:59 - train: epoch 0114, iter [03100, 05004], lr: 0.000696, loss: 1.2281
2022-07-14 15:36:32 - train: epoch 0114, iter [03200, 05004], lr: 0.000692, loss: 1.1451
2022-07-14 15:37:05 - train: epoch 0114, iter [03300, 05004], lr: 0.000687, loss: 1.2642
2022-07-14 15:37:38 - train: epoch 0114, iter [03400, 05004], lr: 0.000683, loss: 0.9365
2022-07-14 15:38:12 - train: epoch 0114, iter [03500, 05004], lr: 0.000679, loss: 0.8986
2022-07-14 15:38:45 - train: epoch 0114, iter [03600, 05004], lr: 0.000674, loss: 1.0925
2022-07-14 15:39:19 - train: epoch 0114, iter [03700, 05004], lr: 0.000670, loss: 1.0355
2022-07-14 15:39:52 - train: epoch 0114, iter [03800, 05004], lr: 0.000666, loss: 1.1003
2022-07-14 15:40:25 - train: epoch 0114, iter [03900, 05004], lr: 0.000662, loss: 1.1092
2022-07-14 15:40:57 - train: epoch 0114, iter [04000, 05004], lr: 0.000657, loss: 0.9406
2022-07-14 15:41:31 - train: epoch 0114, iter [04100, 05004], lr: 0.000653, loss: 1.0497
2022-07-14 15:42:05 - train: epoch 0114, iter [04200, 05004], lr: 0.000649, loss: 1.0874
2022-07-14 15:42:38 - train: epoch 0114, iter [04300, 05004], lr: 0.000645, loss: 1.0476
2022-07-14 15:43:12 - train: epoch 0114, iter [04400, 05004], lr: 0.000641, loss: 1.1325
2022-07-14 15:43:46 - train: epoch 0114, iter [04500, 05004], lr: 0.000636, loss: 1.1152
2022-07-14 15:44:19 - train: epoch 0114, iter [04600, 05004], lr: 0.000632, loss: 1.0164
2022-07-14 15:44:53 - train: epoch 0114, iter [04700, 05004], lr: 0.000628, loss: 1.0676
2022-07-14 15:45:26 - train: epoch 0114, iter [04800, 05004], lr: 0.000624, loss: 1.3032
2022-07-14 15:45:59 - train: epoch 0114, iter [04900, 05004], lr: 0.000620, loss: 1.1096
2022-07-14 15:46:30 - train: epoch 0114, iter [05000, 05004], lr: 0.000616, loss: 1.1614
2022-07-14 15:46:31 - train: epoch 114, train_loss: 1.0693
2022-07-14 15:47:46 - eval: epoch: 114, acc1: 73.828%, acc5: 91.454%, test_loss: 1.0535, per_image_load_time: 2.588ms, per_image_inference_time: 0.325ms
2022-07-14 15:47:46 - until epoch: 114, best_acc1: 73.828%
2022-07-14 15:47:46 - epoch 115 lr: 0.000616
2022-07-14 15:48:25 - train: epoch 0115, iter [00100, 05004], lr: 0.000611, loss: 1.0426
2022-07-14 15:48:59 - train: epoch 0115, iter [00200, 05004], lr: 0.000607, loss: 1.0878
2022-07-14 15:49:33 - train: epoch 0115, iter [00300, 05004], lr: 0.000603, loss: 1.2111
2022-07-14 15:50:06 - train: epoch 0115, iter [00400, 05004], lr: 0.000599, loss: 0.9028
2022-07-14 15:50:39 - train: epoch 0115, iter [00500, 05004], lr: 0.000595, loss: 1.0353
2022-07-14 15:51:13 - train: epoch 0115, iter [00600, 05004], lr: 0.000591, loss: 1.1147
2022-07-14 15:51:47 - train: epoch 0115, iter [00700, 05004], lr: 0.000587, loss: 1.0836
2022-07-14 15:52:21 - train: epoch 0115, iter [00800, 05004], lr: 0.000583, loss: 0.9035
2022-07-14 15:52:55 - train: epoch 0115, iter [00900, 05004], lr: 0.000579, loss: 1.1587
2022-07-14 15:53:29 - train: epoch 0115, iter [01000, 05004], lr: 0.000575, loss: 0.8915
2022-07-14 15:54:03 - train: epoch 0115, iter [01100, 05004], lr: 0.000571, loss: 0.9997
2022-07-14 15:54:37 - train: epoch 0115, iter [01200, 05004], lr: 0.000567, loss: 1.0430
2022-07-14 15:55:11 - train: epoch 0115, iter [01300, 05004], lr: 0.000564, loss: 1.0678
2022-07-14 15:55:44 - train: epoch 0115, iter [01400, 05004], lr: 0.000560, loss: 1.0484
2022-07-14 15:56:18 - train: epoch 0115, iter [01500, 05004], lr: 0.000556, loss: 1.2599
2022-07-14 15:56:52 - train: epoch 0115, iter [01600, 05004], lr: 0.000552, loss: 0.9767
2022-07-14 15:57:26 - train: epoch 0115, iter [01700, 05004], lr: 0.000548, loss: 0.9628
2022-07-14 15:58:00 - train: epoch 0115, iter [01800, 05004], lr: 0.000544, loss: 0.9717
2022-07-14 15:58:34 - train: epoch 0115, iter [01900, 05004], lr: 0.000540, loss: 0.9614
2022-07-14 15:59:08 - train: epoch 0115, iter [02000, 05004], lr: 0.000536, loss: 1.1549
2022-07-14 15:59:41 - train: epoch 0115, iter [02100, 05004], lr: 0.000533, loss: 1.0346
2022-07-14 16:00:15 - train: epoch 0115, iter [02200, 05004], lr: 0.000529, loss: 1.1644
2022-07-14 16:00:49 - train: epoch 0115, iter [02300, 05004], lr: 0.000525, loss: 1.1490
2022-07-14 16:01:23 - train: epoch 0115, iter [02400, 05004], lr: 0.000521, loss: 1.0831
2022-07-14 16:01:57 - train: epoch 0115, iter [02500, 05004], lr: 0.000518, loss: 0.9617
2022-07-14 16:02:31 - train: epoch 0115, iter [02600, 05004], lr: 0.000514, loss: 1.0515
2022-07-14 16:03:05 - train: epoch 0115, iter [02700, 05004], lr: 0.000510, loss: 1.0058
2022-07-14 16:03:39 - train: epoch 0115, iter [02800, 05004], lr: 0.000506, loss: 1.1006
2022-07-14 16:04:13 - train: epoch 0115, iter [02900, 05004], lr: 0.000503, loss: 0.9686
2022-07-14 16:04:46 - train: epoch 0115, iter [03000, 05004], lr: 0.000499, loss: 0.8825
2022-07-14 16:05:20 - train: epoch 0115, iter [03100, 05004], lr: 0.000495, loss: 1.1059
2022-07-14 16:05:54 - train: epoch 0115, iter [03200, 05004], lr: 0.000492, loss: 1.0930
2022-07-14 16:06:28 - train: epoch 0115, iter [03300, 05004], lr: 0.000488, loss: 1.0746
2022-07-14 16:07:02 - train: epoch 0115, iter [03400, 05004], lr: 0.000484, loss: 0.9878
2022-07-14 16:07:36 - train: epoch 0115, iter [03500, 05004], lr: 0.000481, loss: 1.0444
2022-07-14 16:08:10 - train: epoch 0115, iter [03600, 05004], lr: 0.000477, loss: 0.9433
2022-07-14 16:08:44 - train: epoch 0115, iter [03700, 05004], lr: 0.000473, loss: 0.9655
2022-07-14 16:09:19 - train: epoch 0115, iter [03800, 05004], lr: 0.000470, loss: 1.1314
2022-07-14 16:09:52 - train: epoch 0115, iter [03900, 05004], lr: 0.000466, loss: 1.0807
2022-07-14 16:10:26 - train: epoch 0115, iter [04000, 05004], lr: 0.000463, loss: 1.1957
2022-07-14 16:11:01 - train: epoch 0115, iter [04100, 05004], lr: 0.000459, loss: 1.0485
2022-07-14 16:11:33 - train: epoch 0115, iter [04200, 05004], lr: 0.000456, loss: 0.8960
2022-07-14 16:12:07 - train: epoch 0115, iter [04300, 05004], lr: 0.000452, loss: 1.0361
2022-07-14 16:12:42 - train: epoch 0115, iter [04400, 05004], lr: 0.000449, loss: 1.1403
2022-07-14 16:13:16 - train: epoch 0115, iter [04500, 05004], lr: 0.000445, loss: 0.9484
2022-07-14 16:13:50 - train: epoch 0115, iter [04600, 05004], lr: 0.000442, loss: 1.1044
2022-07-14 16:14:23 - train: epoch 0115, iter [04700, 05004], lr: 0.000438, loss: 1.0567
2022-07-14 16:14:58 - train: epoch 0115, iter [04800, 05004], lr: 0.000435, loss: 0.9488
2022-07-14 16:15:32 - train: epoch 0115, iter [04900, 05004], lr: 0.000431, loss: 1.0181
2022-07-14 16:16:04 - train: epoch 0115, iter [05000, 05004], lr: 0.000428, loss: 1.0798
2022-07-14 16:16:05 - train: epoch 115, train_loss: 1.0600
2022-07-14 16:17:20 - eval: epoch: 115, acc1: 73.832%, acc5: 91.458%, test_loss: 1.0499, per_image_load_time: 2.334ms, per_image_inference_time: 0.264ms
2022-07-14 16:17:21 - until epoch: 115, best_acc1: 73.832%
2022-07-14 16:17:21 - epoch 116 lr: 0.000428
2022-07-14 16:18:00 - train: epoch 0116, iter [00100, 05004], lr: 0.000424, loss: 0.9896
2022-07-14 16:18:33 - train: epoch 0116, iter [00200, 05004], lr: 0.000421, loss: 1.1726
2022-07-14 16:19:08 - train: epoch 0116, iter [00300, 05004], lr: 0.000418, loss: 0.8727
2022-07-14 16:19:41 - train: epoch 0116, iter [00400, 05004], lr: 0.000414, loss: 1.1503
2022-07-14 16:20:15 - train: epoch 0116, iter [00500, 05004], lr: 0.000411, loss: 1.1775
2022-07-14 16:20:48 - train: epoch 0116, iter [00600, 05004], lr: 0.000408, loss: 1.0650
2022-07-14 16:21:22 - train: epoch 0116, iter [00700, 05004], lr: 0.000404, loss: 1.1777
2022-07-14 16:21:56 - train: epoch 0116, iter [00800, 05004], lr: 0.000401, loss: 1.1257
2022-07-14 16:22:30 - train: epoch 0116, iter [00900, 05004], lr: 0.000398, loss: 1.1864
2022-07-14 16:23:04 - train: epoch 0116, iter [01000, 05004], lr: 0.000394, loss: 1.1380
2022-07-14 16:23:39 - train: epoch 0116, iter [01100, 05004], lr: 0.000391, loss: 1.0055
2022-07-14 16:24:13 - train: epoch 0116, iter [01200, 05004], lr: 0.000388, loss: 1.0567
2022-07-14 16:24:47 - train: epoch 0116, iter [01300, 05004], lr: 0.000385, loss: 1.2132
2022-07-14 16:25:20 - train: epoch 0116, iter [01400, 05004], lr: 0.000381, loss: 1.2053
2022-07-14 16:25:55 - train: epoch 0116, iter [01500, 05004], lr: 0.000378, loss: 0.9494
2022-07-14 16:26:30 - train: epoch 0116, iter [01600, 05004], lr: 0.000375, loss: 1.0569
2022-07-14 16:27:03 - train: epoch 0116, iter [01700, 05004], lr: 0.000372, loss: 1.0539
2022-07-14 16:27:37 - train: epoch 0116, iter [01800, 05004], lr: 0.000368, loss: 1.1360
2022-07-14 16:28:11 - train: epoch 0116, iter [01900, 05004], lr: 0.000365, loss: 0.9473
2022-07-14 16:28:46 - train: epoch 0116, iter [02000, 05004], lr: 0.000362, loss: 0.9410
2022-07-14 16:29:20 - train: epoch 0116, iter [02100, 05004], lr: 0.000359, loss: 1.1309
2022-07-14 16:29:55 - train: epoch 0116, iter [02200, 05004], lr: 0.000356, loss: 1.1342
2022-07-14 16:30:28 - train: epoch 0116, iter [02300, 05004], lr: 0.000353, loss: 1.1978
2022-07-14 16:31:03 - train: epoch 0116, iter [02400, 05004], lr: 0.000350, loss: 1.1008
2022-07-14 16:31:36 - train: epoch 0116, iter [02500, 05004], lr: 0.000347, loss: 0.8852
2022-07-14 16:32:11 - train: epoch 0116, iter [02600, 05004], lr: 0.000344, loss: 0.9868
2022-07-14 16:32:45 - train: epoch 0116, iter [02700, 05004], lr: 0.000341, loss: 1.1457
2022-07-14 16:33:18 - train: epoch 0116, iter [02800, 05004], lr: 0.000337, loss: 1.2457
2022-07-14 16:33:53 - train: epoch 0116, iter [02900, 05004], lr: 0.000334, loss: 1.2478
2022-07-14 16:34:28 - train: epoch 0116, iter [03000, 05004], lr: 0.000331, loss: 1.1261
2022-07-14 16:35:02 - train: epoch 0116, iter [03100, 05004], lr: 0.000328, loss: 1.1601
2022-07-14 16:35:36 - train: epoch 0116, iter [03200, 05004], lr: 0.000325, loss: 1.1243
2022-07-14 16:36:10 - train: epoch 0116, iter [03300, 05004], lr: 0.000322, loss: 1.3485
2022-07-14 16:36:44 - train: epoch 0116, iter [03400, 05004], lr: 0.000320, loss: 1.1830
2022-07-14 16:37:18 - train: epoch 0116, iter [03500, 05004], lr: 0.000317, loss: 1.0683
2022-07-14 16:37:51 - train: epoch 0116, iter [03600, 05004], lr: 0.000314, loss: 1.1804
2022-07-14 16:38:26 - train: epoch 0116, iter [03700, 05004], lr: 0.000311, loss: 1.0091
2022-07-14 16:39:00 - train: epoch 0116, iter [03800, 05004], lr: 0.000308, loss: 0.9394
2022-07-14 16:39:35 - train: epoch 0116, iter [03900, 05004], lr: 0.000305, loss: 1.1560
2022-07-14 16:40:09 - train: epoch 0116, iter [04000, 05004], lr: 0.000302, loss: 0.9544
2022-07-14 16:40:44 - train: epoch 0116, iter [04100, 05004], lr: 0.000299, loss: 1.2123
2022-07-14 16:41:18 - train: epoch 0116, iter [04200, 05004], lr: 0.000296, loss: 1.0548
2022-07-14 16:41:51 - train: epoch 0116, iter [04300, 05004], lr: 0.000293, loss: 1.0666
2022-07-14 16:42:25 - train: epoch 0116, iter [04400, 05004], lr: 0.000291, loss: 0.9613
2022-07-14 16:42:59 - train: epoch 0116, iter [04500, 05004], lr: 0.000288, loss: 1.0774
2022-07-14 16:43:33 - train: epoch 0116, iter [04600, 05004], lr: 0.000285, loss: 1.2888
2022-07-14 16:44:07 - train: epoch 0116, iter [04700, 05004], lr: 0.000282, loss: 1.0582
2022-07-14 16:44:42 - train: epoch 0116, iter [04800, 05004], lr: 0.000280, loss: 1.0423
2022-07-14 16:45:16 - train: epoch 0116, iter [04900, 05004], lr: 0.000277, loss: 0.8755
2022-07-14 16:45:49 - train: epoch 0116, iter [05000, 05004], lr: 0.000274, loss: 0.9832
2022-07-14 16:45:49 - train: epoch 116, train_loss: 1.0527
2022-07-14 16:47:06 - eval: epoch: 116, acc1: 73.852%, acc5: 91.568%, test_loss: 1.0464, per_image_load_time: 2.644ms, per_image_inference_time: 0.306ms
2022-07-14 16:47:06 - until epoch: 116, best_acc1: 73.852%
2022-07-14 16:47:06 - epoch 117 lr: 0.000274
2022-07-14 16:47:45 - train: epoch 0117, iter [00100, 05004], lr: 0.000271, loss: 1.3214
2022-07-14 16:48:19 - train: epoch 0117, iter [00200, 05004], lr: 0.000268, loss: 1.0025
2022-07-14 16:48:53 - train: epoch 0117, iter [00300, 05004], lr: 0.000266, loss: 1.2274
2022-07-14 16:49:27 - train: epoch 0117, iter [00400, 05004], lr: 0.000263, loss: 0.9038
2022-07-14 16:50:01 - train: epoch 0117, iter [00500, 05004], lr: 0.000260, loss: 0.9978
2022-07-14 16:50:35 - train: epoch 0117, iter [00600, 05004], lr: 0.000258, loss: 1.0828
2022-07-14 16:51:09 - train: epoch 0117, iter [00700, 05004], lr: 0.000255, loss: 1.0925
2022-07-14 16:51:43 - train: epoch 0117, iter [00800, 05004], lr: 0.000252, loss: 0.9887
2022-07-14 16:52:18 - train: epoch 0117, iter [00900, 05004], lr: 0.000250, loss: 0.8619
2022-07-14 16:52:51 - train: epoch 0117, iter [01000, 05004], lr: 0.000247, loss: 0.9657
2022-07-14 16:53:25 - train: epoch 0117, iter [01100, 05004], lr: 0.000245, loss: 1.0523
2022-07-14 16:53:59 - train: epoch 0117, iter [01200, 05004], lr: 0.000242, loss: 1.1216
2022-07-14 16:54:34 - train: epoch 0117, iter [01300, 05004], lr: 0.000240, loss: 1.0943
2022-07-14 16:55:07 - train: epoch 0117, iter [01400, 05004], lr: 0.000237, loss: 1.1791
2022-07-14 16:55:41 - train: epoch 0117, iter [01500, 05004], lr: 0.000234, loss: 1.0248
2022-07-14 16:56:16 - train: epoch 0117, iter [01600, 05004], lr: 0.000232, loss: 0.8373
2022-07-14 16:56:50 - train: epoch 0117, iter [01700, 05004], lr: 0.000229, loss: 1.0338
2022-07-14 16:57:24 - train: epoch 0117, iter [01800, 05004], lr: 0.000227, loss: 1.0005
2022-07-14 16:57:58 - train: epoch 0117, iter [01900, 05004], lr: 0.000224, loss: 0.8857
2022-07-14 16:58:32 - train: epoch 0117, iter [02000, 05004], lr: 0.000222, loss: 1.0517
2022-07-14 16:59:07 - train: epoch 0117, iter [02100, 05004], lr: 0.000219, loss: 1.0674
2022-07-14 16:59:41 - train: epoch 0117, iter [02200, 05004], lr: 0.000217, loss: 0.8756
2022-07-14 17:00:15 - train: epoch 0117, iter [02300, 05004], lr: 0.000215, loss: 1.0283
2022-07-14 17:00:51 - train: epoch 0117, iter [02400, 05004], lr: 0.000212, loss: 0.9152
2022-07-14 17:01:24 - train: epoch 0117, iter [02500, 05004], lr: 0.000210, loss: 1.1776
2022-07-14 17:01:58 - train: epoch 0117, iter [02600, 05004], lr: 0.000207, loss: 0.9738
2022-07-14 17:02:32 - train: epoch 0117, iter [02700, 05004], lr: 0.000205, loss: 0.9068
2022-07-14 17:03:06 - train: epoch 0117, iter [02800, 05004], lr: 0.000203, loss: 0.9608
2022-07-14 17:03:40 - train: epoch 0117, iter [02900, 05004], lr: 0.000200, loss: 1.0409
2022-07-14 17:04:15 - train: epoch 0117, iter [03000, 05004], lr: 0.000198, loss: 0.8381
2022-07-14 17:04:49 - train: epoch 0117, iter [03100, 05004], lr: 0.000196, loss: 1.0352
2022-07-14 17:05:23 - train: epoch 0117, iter [03200, 05004], lr: 0.000193, loss: 1.0419
2022-07-14 17:05:57 - train: epoch 0117, iter [03300, 05004], lr: 0.000191, loss: 0.9446
2022-07-14 17:06:31 - train: epoch 0117, iter [03400, 05004], lr: 0.000189, loss: 0.9311
2022-07-14 17:07:06 - train: epoch 0117, iter [03500, 05004], lr: 0.000187, loss: 1.1441
2022-07-14 17:07:41 - train: epoch 0117, iter [03600, 05004], lr: 0.000184, loss: 1.2473
2022-07-14 17:08:15 - train: epoch 0117, iter [03700, 05004], lr: 0.000182, loss: 1.0421
2022-07-14 17:08:49 - train: epoch 0117, iter [03800, 05004], lr: 0.000180, loss: 1.0701
2022-07-14 17:09:23 - train: epoch 0117, iter [03900, 05004], lr: 0.000178, loss: 0.8752
2022-07-14 17:09:58 - train: epoch 0117, iter [04000, 05004], lr: 0.000175, loss: 0.9476
2022-07-14 17:10:33 - train: epoch 0117, iter [04100, 05004], lr: 0.000173, loss: 1.1499
2022-07-14 17:11:06 - train: epoch 0117, iter [04200, 05004], lr: 0.000171, loss: 1.1249
2022-07-14 17:11:41 - train: epoch 0117, iter [04300, 05004], lr: 0.000169, loss: 0.9272
2022-07-14 17:12:15 - train: epoch 0117, iter [04400, 05004], lr: 0.000167, loss: 0.9444
2022-07-14 17:12:50 - train: epoch 0117, iter [04500, 05004], lr: 0.000165, loss: 1.0206
2022-07-14 17:13:24 - train: epoch 0117, iter [04600, 05004], lr: 0.000163, loss: 1.0243
2022-07-14 17:13:58 - train: epoch 0117, iter [04700, 05004], lr: 0.000160, loss: 1.1436
2022-07-14 17:14:32 - train: epoch 0117, iter [04800, 05004], lr: 0.000158, loss: 1.0985
2022-07-14 17:15:06 - train: epoch 0117, iter [04900, 05004], lr: 0.000156, loss: 1.1500
2022-07-14 17:15:39 - train: epoch 0117, iter [05000, 05004], lr: 0.000154, loss: 1.1746
2022-07-14 17:15:40 - train: epoch 117, train_loss: 1.0461
2022-07-14 17:16:56 - eval: epoch: 117, acc1: 74.040%, acc5: 91.588%, test_loss: 1.0438, per_image_load_time: 2.338ms, per_image_inference_time: 0.297ms
2022-07-14 17:16:56 - until epoch: 117, best_acc1: 74.040%
2022-07-14 17:16:56 - epoch 118 lr: 0.000154
2022-07-14 17:17:36 - train: epoch 0118, iter [00100, 05004], lr: 0.000152, loss: 0.9919
2022-07-14 17:18:10 - train: epoch 0118, iter [00200, 05004], lr: 0.000150, loss: 0.8902
2022-07-14 17:18:44 - train: epoch 0118, iter [00300, 05004], lr: 0.000148, loss: 1.1144
2022-07-14 17:19:18 - train: epoch 0118, iter [00400, 05004], lr: 0.000146, loss: 1.0952
2022-07-14 17:19:52 - train: epoch 0118, iter [00500, 05004], lr: 0.000144, loss: 0.9826
2022-07-14 17:20:25 - train: epoch 0118, iter [00600, 05004], lr: 0.000142, loss: 1.0535
2022-07-14 17:20:59 - train: epoch 0118, iter [00700, 05004], lr: 0.000140, loss: 1.1013
2022-07-14 17:21:33 - train: epoch 0118, iter [00800, 05004], lr: 0.000138, loss: 1.0802
2022-07-14 17:22:08 - train: epoch 0118, iter [00900, 05004], lr: 0.000136, loss: 0.9602
2022-07-14 17:22:42 - train: epoch 0118, iter [01000, 05004], lr: 0.000134, loss: 1.4021
2022-07-14 17:23:15 - train: epoch 0118, iter [01100, 05004], lr: 0.000132, loss: 1.0907
2022-07-14 17:23:49 - train: epoch 0118, iter [01200, 05004], lr: 0.000130, loss: 1.2357
2022-07-14 17:24:23 - train: epoch 0118, iter [01300, 05004], lr: 0.000129, loss: 1.1493
2022-07-14 17:24:57 - train: epoch 0118, iter [01400, 05004], lr: 0.000127, loss: 0.9369
2022-07-14 17:25:32 - train: epoch 0118, iter [01500, 05004], lr: 0.000125, loss: 0.9603
2022-07-14 17:26:06 - train: epoch 0118, iter [01600, 05004], lr: 0.000123, loss: 0.9814
2022-07-14 17:26:40 - train: epoch 0118, iter [01700, 05004], lr: 0.000121, loss: 1.0934
2022-07-14 17:27:13 - train: epoch 0118, iter [01800, 05004], lr: 0.000119, loss: 0.9451
2022-07-14 17:27:48 - train: epoch 0118, iter [01900, 05004], lr: 0.000118, loss: 1.2509
2022-07-14 17:28:23 - train: epoch 0118, iter [02000, 05004], lr: 0.000116, loss: 0.9627
2022-07-14 17:28:56 - train: epoch 0118, iter [02100, 05004], lr: 0.000114, loss: 1.0102
2022-07-14 17:29:30 - train: epoch 0118, iter [02200, 05004], lr: 0.000112, loss: 0.9764
2022-07-14 17:30:05 - train: epoch 0118, iter [02300, 05004], lr: 0.000111, loss: 0.9655
2022-07-14 17:30:41 - train: epoch 0118, iter [02400, 05004], lr: 0.000109, loss: 1.1810
2022-07-14 17:31:13 - train: epoch 0118, iter [02500, 05004], lr: 0.000107, loss: 1.2107
2022-07-14 17:31:47 - train: epoch 0118, iter [02600, 05004], lr: 0.000105, loss: 0.9664
2022-07-14 17:32:21 - train: epoch 0118, iter [02700, 05004], lr: 0.000104, loss: 1.1771
2022-07-14 17:32:55 - train: epoch 0118, iter [02800, 05004], lr: 0.000102, loss: 0.9902
2022-07-14 17:33:28 - train: epoch 0118, iter [02900, 05004], lr: 0.000100, loss: 1.0319
2022-07-14 17:34:04 - train: epoch 0118, iter [03000, 05004], lr: 0.000099, loss: 1.0037
2022-07-14 17:34:38 - train: epoch 0118, iter [03100, 05004], lr: 0.000097, loss: 1.1054
2022-07-14 17:35:11 - train: epoch 0118, iter [03200, 05004], lr: 0.000095, loss: 1.0252
2022-07-14 17:35:46 - train: epoch 0118, iter [03300, 05004], lr: 0.000094, loss: 1.1355
2022-07-14 17:36:21 - train: epoch 0118, iter [03400, 05004], lr: 0.000092, loss: 1.0477
2022-07-14 17:36:54 - train: epoch 0118, iter [03500, 05004], lr: 0.000091, loss: 0.9457
2022-07-14 17:37:29 - train: epoch 0118, iter [03600, 05004], lr: 0.000089, loss: 1.1121
2022-07-14 17:38:03 - train: epoch 0118, iter [03700, 05004], lr: 0.000088, loss: 1.1872
2022-07-14 17:38:37 - train: epoch 0118, iter [03800, 05004], lr: 0.000086, loss: 1.0593
2022-07-14 17:39:12 - train: epoch 0118, iter [03900, 05004], lr: 0.000084, loss: 1.0951
2022-07-14 17:39:46 - train: epoch 0118, iter [04000, 05004], lr: 0.000083, loss: 1.0993
2022-07-14 17:40:20 - train: epoch 0118, iter [04100, 05004], lr: 0.000081, loss: 1.1580
2022-07-14 17:40:55 - train: epoch 0118, iter [04200, 05004], lr: 0.000080, loss: 1.0328
2022-07-14 17:41:28 - train: epoch 0118, iter [04300, 05004], lr: 0.000079, loss: 0.7992
2022-07-14 17:42:03 - train: epoch 0118, iter [04400, 05004], lr: 0.000077, loss: 1.0381
2022-07-14 17:42:37 - train: epoch 0118, iter [04500, 05004], lr: 0.000076, loss: 0.9860
2022-07-14 17:43:11 - train: epoch 0118, iter [04600, 05004], lr: 0.000074, loss: 1.1388
2022-07-14 17:43:45 - train: epoch 0118, iter [04700, 05004], lr: 0.000073, loss: 0.8460
2022-07-14 17:44:19 - train: epoch 0118, iter [04800, 05004], lr: 0.000071, loss: 0.9032
2022-07-14 17:44:54 - train: epoch 0118, iter [04900, 05004], lr: 0.000070, loss: 1.0142
2022-07-14 17:45:26 - train: epoch 0118, iter [05000, 05004], lr: 0.000069, loss: 1.1006
2022-07-14 17:45:27 - train: epoch 118, train_loss: 1.0412
2022-07-14 17:46:42 - eval: epoch: 118, acc1: 74.062%, acc5: 91.632%, test_loss: 1.0430, per_image_load_time: 2.342ms, per_image_inference_time: 0.324ms
2022-07-14 17:46:43 - until epoch: 118, best_acc1: 74.062%
2022-07-14 17:46:43 - epoch 119 lr: 0.000069
2022-07-14 17:47:22 - train: epoch 0119, iter [00100, 05004], lr: 0.000067, loss: 1.1650
2022-07-14 17:47:56 - train: epoch 0119, iter [00200, 05004], lr: 0.000066, loss: 1.0138
2022-07-14 17:48:31 - train: epoch 0119, iter [00300, 05004], lr: 0.000064, loss: 1.2766
2022-07-14 17:49:04 - train: epoch 0119, iter [00400, 05004], lr: 0.000063, loss: 0.9288
2022-07-14 17:49:38 - train: epoch 0119, iter [00500, 05004], lr: 0.000062, loss: 0.8715
2022-07-14 17:50:12 - train: epoch 0119, iter [00600, 05004], lr: 0.000061, loss: 1.1074
2022-07-14 17:50:46 - train: epoch 0119, iter [00700, 05004], lr: 0.000059, loss: 1.0817
2022-07-14 17:51:20 - train: epoch 0119, iter [00800, 05004], lr: 0.000058, loss: 1.0812
2022-07-14 17:51:55 - train: epoch 0119, iter [00900, 05004], lr: 0.000057, loss: 1.1843
2022-07-14 17:52:29 - train: epoch 0119, iter [01000, 05004], lr: 0.000056, loss: 0.9032
2022-07-14 17:53:04 - train: epoch 0119, iter [01100, 05004], lr: 0.000054, loss: 1.2611
2022-07-14 17:53:37 - train: epoch 0119, iter [01200, 05004], lr: 0.000053, loss: 1.2211
2022-07-14 17:54:13 - train: epoch 0119, iter [01300, 05004], lr: 0.000052, loss: 0.9232
2022-07-14 17:54:46 - train: epoch 0119, iter [01400, 05004], lr: 0.000051, loss: 1.0001
2022-07-14 17:55:20 - train: epoch 0119, iter [01500, 05004], lr: 0.000050, loss: 1.0064
2022-07-14 17:55:53 - train: epoch 0119, iter [01600, 05004], lr: 0.000048, loss: 1.0625
2022-07-14 17:56:29 - train: epoch 0119, iter [01700, 05004], lr: 0.000047, loss: 1.0694
2022-07-14 17:57:01 - train: epoch 0119, iter [01800, 05004], lr: 0.000046, loss: 0.9864
2022-07-14 17:57:35 - train: epoch 0119, iter [01900, 05004], lr: 0.000045, loss: 1.0029
2022-07-14 17:58:09 - train: epoch 0119, iter [02000, 05004], lr: 0.000044, loss: 0.8746
2022-07-14 17:58:43 - train: epoch 0119, iter [02100, 05004], lr: 0.000043, loss: 1.1710
2022-07-14 17:59:18 - train: epoch 0119, iter [02200, 05004], lr: 0.000042, loss: 1.1105
2022-07-14 17:59:53 - train: epoch 0119, iter [02300, 05004], lr: 0.000041, loss: 1.0061
2022-07-14 18:00:27 - train: epoch 0119, iter [02400, 05004], lr: 0.000040, loss: 0.9735
2022-07-14 18:01:01 - train: epoch 0119, iter [02500, 05004], lr: 0.000039, loss: 1.1623
2022-07-14 18:01:35 - train: epoch 0119, iter [02600, 05004], lr: 0.000038, loss: 1.1076
2022-07-14 18:02:10 - train: epoch 0119, iter [02700, 05004], lr: 0.000037, loss: 1.0692
2022-07-14 18:02:44 - train: epoch 0119, iter [02800, 05004], lr: 0.000036, loss: 1.1770
2022-07-14 18:03:18 - train: epoch 0119, iter [02900, 05004], lr: 0.000035, loss: 1.0355
2022-07-14 18:03:52 - train: epoch 0119, iter [03000, 05004], lr: 0.000034, loss: 0.9043
2022-07-14 18:04:27 - train: epoch 0119, iter [03100, 05004], lr: 0.000033, loss: 0.9474
2022-07-14 18:05:01 - train: epoch 0119, iter [03200, 05004], lr: 0.000032, loss: 0.9399
2022-07-14 18:05:35 - train: epoch 0119, iter [03300, 05004], lr: 0.000031, loss: 0.9856
2022-07-14 18:06:10 - train: epoch 0119, iter [03400, 05004], lr: 0.000030, loss: 1.1126
2022-07-14 18:06:44 - train: epoch 0119, iter [03500, 05004], lr: 0.000029, loss: 0.9580
2022-07-14 18:07:18 - train: epoch 0119, iter [03600, 05004], lr: 0.000028, loss: 1.1094
2022-07-14 18:07:52 - train: epoch 0119, iter [03700, 05004], lr: 0.000027, loss: 1.1132
2022-07-14 18:08:27 - train: epoch 0119, iter [03800, 05004], lr: 0.000026, loss: 0.9885
2022-07-14 18:09:00 - train: epoch 0119, iter [03900, 05004], lr: 0.000026, loss: 1.4345
2022-07-14 18:09:34 - train: epoch 0119, iter [04000, 05004], lr: 0.000025, loss: 0.9224
2022-07-14 18:10:08 - train: epoch 0119, iter [04100, 05004], lr: 0.000024, loss: 1.3595
2022-07-14 18:10:42 - train: epoch 0119, iter [04200, 05004], lr: 0.000023, loss: 0.9704
2022-07-14 18:11:16 - train: epoch 0119, iter [04300, 05004], lr: 0.000022, loss: 0.9349
2022-07-14 18:11:50 - train: epoch 0119, iter [04400, 05004], lr: 0.000022, loss: 1.0855
2022-07-14 18:12:24 - train: epoch 0119, iter [04500, 05004], lr: 0.000021, loss: 0.9360
2022-07-14 18:12:59 - train: epoch 0119, iter [04600, 05004], lr: 0.000020, loss: 1.0385
2022-07-14 18:13:33 - train: epoch 0119, iter [04700, 05004], lr: 0.000019, loss: 0.8547
2022-07-14 18:14:07 - train: epoch 0119, iter [04800, 05004], lr: 0.000019, loss: 1.1316
2022-07-14 18:14:41 - train: epoch 0119, iter [04900, 05004], lr: 0.000018, loss: 1.2272
2022-07-14 18:15:14 - train: epoch 0119, iter [05000, 05004], lr: 0.000017, loss: 1.1214
2022-07-14 18:15:15 - train: epoch 119, train_loss: 1.0375
2022-07-14 18:16:30 - eval: epoch: 119, acc1: 74.038%, acc5: 91.608%, test_loss: 1.0432, per_image_load_time: 2.121ms, per_image_inference_time: 0.323ms
2022-07-14 18:16:30 - until epoch: 119, best_acc1: 74.062%
2022-07-14 18:16:30 - epoch 120 lr: 0.000017
2022-07-14 18:17:09 - train: epoch 0120, iter [00100, 05004], lr: 0.000016, loss: 1.0656
2022-07-14 18:17:43 - train: epoch 0120, iter [00200, 05004], lr: 0.000016, loss: 1.1407
2022-07-14 18:18:17 - train: epoch 0120, iter [00300, 05004], lr: 0.000015, loss: 1.0497
2022-07-14 18:18:51 - train: epoch 0120, iter [00400, 05004], lr: 0.000015, loss: 1.0557
2022-07-14 18:19:25 - train: epoch 0120, iter [00500, 05004], lr: 0.000014, loss: 0.8733
2022-07-14 18:19:59 - train: epoch 0120, iter [00600, 05004], lr: 0.000013, loss: 0.8855
2022-07-14 18:20:33 - train: epoch 0120, iter [00700, 05004], lr: 0.000013, loss: 1.1945
2022-07-14 18:21:06 - train: epoch 0120, iter [00800, 05004], lr: 0.000012, loss: 0.8931
2022-07-14 18:21:39 - train: epoch 0120, iter [00900, 05004], lr: 0.000012, loss: 0.9472
2022-07-14 18:22:12 - train: epoch 0120, iter [01000, 05004], lr: 0.000011, loss: 0.9646
2022-07-14 18:22:48 - train: epoch 0120, iter [01100, 05004], lr: 0.000010, loss: 1.0189
2022-07-14 18:23:22 - train: epoch 0120, iter [01200, 05004], lr: 0.000010, loss: 1.1053
2022-07-14 18:23:56 - train: epoch 0120, iter [01300, 05004], lr: 0.000009, loss: 0.9532
2022-07-14 18:24:30 - train: epoch 0120, iter [01400, 05004], lr: 0.000009, loss: 1.0221
2022-07-14 18:25:05 - train: epoch 0120, iter [01500, 05004], lr: 0.000008, loss: 1.0063
2022-07-14 18:25:40 - train: epoch 0120, iter [01600, 05004], lr: 0.000008, loss: 0.9988
2022-07-14 18:26:14 - train: epoch 0120, iter [01700, 05004], lr: 0.000007, loss: 1.0839
2022-07-14 18:26:49 - train: epoch 0120, iter [01800, 05004], lr: 0.000007, loss: 0.9840
2022-07-14 18:27:23 - train: epoch 0120, iter [01900, 05004], lr: 0.000007, loss: 1.0339
2022-07-14 18:27:58 - train: epoch 0120, iter [02000, 05004], lr: 0.000006, loss: 1.0269
2022-07-14 18:28:33 - train: epoch 0120, iter [02100, 05004], lr: 0.000006, loss: 1.1376
2022-07-14 18:29:07 - train: epoch 0120, iter [02200, 05004], lr: 0.000005, loss: 0.9823
2022-07-14 18:29:42 - train: epoch 0120, iter [02300, 05004], lr: 0.000005, loss: 0.9357
2022-07-14 18:30:17 - train: epoch 0120, iter [02400, 05004], lr: 0.000005, loss: 1.0523
2022-07-14 18:30:52 - train: epoch 0120, iter [02500, 05004], lr: 0.000004, loss: 1.1026
2022-07-14 18:31:27 - train: epoch 0120, iter [02600, 05004], lr: 0.000004, loss: 1.0977
2022-07-14 18:32:01 - train: epoch 0120, iter [02700, 05004], lr: 0.000004, loss: 1.2544
2022-07-14 18:32:36 - train: epoch 0120, iter [02800, 05004], lr: 0.000003, loss: 0.9799
2022-07-14 18:33:12 - train: epoch 0120, iter [02900, 05004], lr: 0.000003, loss: 0.7974
2022-07-14 18:33:47 - train: epoch 0120, iter [03000, 05004], lr: 0.000003, loss: 0.9823
2022-07-14 18:34:21 - train: epoch 0120, iter [03100, 05004], lr: 0.000002, loss: 0.8405
2022-07-14 18:34:58 - train: epoch 0120, iter [03200, 05004], lr: 0.000002, loss: 1.0308
2022-07-14 18:35:31 - train: epoch 0120, iter [03300, 05004], lr: 0.000002, loss: 0.8842
2022-07-14 18:36:07 - train: epoch 0120, iter [03400, 05004], lr: 0.000002, loss: 0.9152
2022-07-14 18:36:42 - train: epoch 0120, iter [03500, 05004], lr: 0.000002, loss: 1.0688
2022-07-14 18:37:17 - train: epoch 0120, iter [03600, 05004], lr: 0.000001, loss: 1.0350
2022-07-14 18:37:51 - train: epoch 0120, iter [03700, 05004], lr: 0.000001, loss: 0.8932
2022-07-14 18:38:27 - train: epoch 0120, iter [03800, 05004], lr: 0.000001, loss: 0.9799
2022-07-14 18:39:00 - train: epoch 0120, iter [03900, 05004], lr: 0.000001, loss: 0.9899
2022-07-14 18:39:35 - train: epoch 0120, iter [04000, 05004], lr: 0.000001, loss: 0.9697
2022-07-14 18:40:10 - train: epoch 0120, iter [04100, 05004], lr: 0.000001, loss: 1.2577
2022-07-14 18:40:46 - train: epoch 0120, iter [04200, 05004], lr: 0.000000, loss: 1.2348
2022-07-14 18:41:20 - train: epoch 0120, iter [04300, 05004], lr: 0.000000, loss: 1.0582
2022-07-14 18:41:56 - train: epoch 0120, iter [04400, 05004], lr: 0.000000, loss: 1.0425
2022-07-14 18:42:30 - train: epoch 0120, iter [04500, 05004], lr: 0.000000, loss: 1.0767
2022-07-14 18:43:04 - train: epoch 0120, iter [04600, 05004], lr: 0.000000, loss: 0.9567
2022-07-14 18:43:40 - train: epoch 0120, iter [04700, 05004], lr: 0.000000, loss: 1.1392
2022-07-14 18:44:15 - train: epoch 0120, iter [04800, 05004], lr: 0.000000, loss: 1.2567
2022-07-14 18:44:49 - train: epoch 0120, iter [04900, 05004], lr: 0.000000, loss: 1.0596
2022-07-14 18:45:22 - train: epoch 0120, iter [05000, 05004], lr: 0.000000, loss: 0.9473
2022-07-14 18:45:23 - train: epoch 120, train_loss: 1.0378
2022-07-14 18:46:40 - eval: epoch: 120, acc1: 74.082%, acc5: 91.636%, test_loss: 1.0422, per_image_load_time: 2.696ms, per_image_inference_time: 0.283ms
2022-07-14 18:46:40 - until epoch: 120, best_acc1: 74.082%
2022-07-14 18:46:40 - train done. model: RepVGG_A1, train time: 58.594 hours, best_acc1: 74.082%
