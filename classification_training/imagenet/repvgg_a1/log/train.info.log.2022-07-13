2022-07-13 08:10:42 - train: epoch 0050, iter [01200, 05004], lr: 0.063900, loss: 1.9912
2022-07-13 08:11:16 - train: epoch 0050, iter [01300, 05004], lr: 0.063874, loss: 1.7935
2022-07-13 08:11:50 - train: epoch 0050, iter [01400, 05004], lr: 0.063849, loss: 2.0131
2022-07-13 08:12:24 - train: epoch 0050, iter [01500, 05004], lr: 0.063824, loss: 1.9000
2022-07-13 08:12:57 - train: epoch 0050, iter [01600, 05004], lr: 0.063799, loss: 1.8541
2022-07-13 08:13:31 - train: epoch 0050, iter [01700, 05004], lr: 0.063774, loss: 2.1946
2022-07-13 08:14:04 - train: epoch 0050, iter [01800, 05004], lr: 0.063749, loss: 2.0003
2022-07-13 08:14:38 - train: epoch 0050, iter [01900, 05004], lr: 0.063724, loss: 1.9620
2022-07-13 08:15:11 - train: epoch 0050, iter [02000, 05004], lr: 0.063698, loss: 2.0319
2022-07-13 08:15:45 - train: epoch 0050, iter [02100, 05004], lr: 0.063673, loss: 1.5662
2022-07-13 08:16:19 - train: epoch 0050, iter [02200, 05004], lr: 0.063648, loss: 1.9271
2022-07-13 08:16:52 - train: epoch 0050, iter [02300, 05004], lr: 0.063623, loss: 1.8480
2022-07-13 08:17:26 - train: epoch 0050, iter [02400, 05004], lr: 0.063598, loss: 1.9163
2022-07-13 08:17:59 - train: epoch 0050, iter [02500, 05004], lr: 0.063573, loss: 1.9933
2022-07-13 08:18:33 - train: epoch 0050, iter [02600, 05004], lr: 0.063547, loss: 1.8297
2022-07-13 08:19:05 - train: epoch 0050, iter [02700, 05004], lr: 0.063522, loss: 2.1052
2022-07-13 08:19:40 - train: epoch 0050, iter [02800, 05004], lr: 0.063497, loss: 2.1209
2022-07-13 08:20:13 - train: epoch 0050, iter [02900, 05004], lr: 0.063472, loss: 2.1964
2022-07-13 08:20:47 - train: epoch 0050, iter [03000, 05004], lr: 0.063447, loss: 2.1571
2022-07-13 08:21:21 - train: epoch 0050, iter [03100, 05004], lr: 0.063421, loss: 2.0113
2022-07-13 08:21:54 - train: epoch 0050, iter [03200, 05004], lr: 0.063396, loss: 1.8828
2022-07-13 08:22:28 - train: epoch 0050, iter [03300, 05004], lr: 0.063371, loss: 1.8088
2022-07-13 08:23:02 - train: epoch 0050, iter [03400, 05004], lr: 0.063346, loss: 1.7991
2022-07-13 08:23:35 - train: epoch 0050, iter [03500, 05004], lr: 0.063321, loss: 1.8948
2022-07-13 08:24:09 - train: epoch 0050, iter [03600, 05004], lr: 0.063295, loss: 2.0615
2022-07-13 08:24:43 - train: epoch 0050, iter [03700, 05004], lr: 0.063270, loss: 2.0731
2022-07-13 08:25:16 - train: epoch 0050, iter [03800, 05004], lr: 0.063245, loss: 1.9190
2022-07-13 08:25:50 - train: epoch 0050, iter [03900, 05004], lr: 0.063220, loss: 1.7728
2022-07-13 08:26:24 - train: epoch 0050, iter [04000, 05004], lr: 0.063194, loss: 2.1103
2022-07-13 08:26:58 - train: epoch 0050, iter [04100, 05004], lr: 0.063169, loss: 1.9758
2022-07-13 08:27:31 - train: epoch 0050, iter [04200, 05004], lr: 0.063144, loss: 2.0173
2022-07-13 08:28:04 - train: epoch 0050, iter [04300, 05004], lr: 0.063119, loss: 1.8585
2022-07-13 08:28:38 - train: epoch 0050, iter [04400, 05004], lr: 0.063094, loss: 1.9257
2022-07-13 08:29:12 - train: epoch 0050, iter [04500, 05004], lr: 0.063068, loss: 1.9126
2022-07-13 08:29:45 - train: epoch 0050, iter [04600, 05004], lr: 0.063043, loss: 1.9598
2022-07-13 08:30:18 - train: epoch 0050, iter [04700, 05004], lr: 0.063018, loss: 2.0386
2022-07-13 08:30:52 - train: epoch 0050, iter [04800, 05004], lr: 0.062992, loss: 1.7030
2022-07-13 08:31:26 - train: epoch 0050, iter [04900, 05004], lr: 0.062967, loss: 1.7540
2022-07-13 08:31:58 - train: epoch 0050, iter [05000, 05004], lr: 0.062942, loss: 1.8972
2022-07-13 08:31:59 - train: epoch 050, train_loss: 1.9751
2022-07-13 08:33:14 - eval: epoch: 050, acc1: 59.852%, acc5: 83.180%, test_loss: 1.7016, per_image_load_time: 2.627ms, per_image_inference_time: 0.269ms
2022-07-13 08:33:14 - until epoch: 050, best_acc1: 59.852%
2022-07-13 08:33:14 - epoch 051 lr: 0.062941
2022-07-13 08:33:54 - train: epoch 0051, iter [00100, 05004], lr: 0.062916, loss: 2.2644
2022-07-13 08:34:27 - train: epoch 0051, iter [00200, 05004], lr: 0.062890, loss: 2.3080
2022-07-13 08:35:00 - train: epoch 0051, iter [00300, 05004], lr: 0.062865, loss: 1.9372
2022-07-13 08:35:34 - train: epoch 0051, iter [00400, 05004], lr: 0.062840, loss: 1.7183
2022-07-13 08:36:06 - train: epoch 0051, iter [00500, 05004], lr: 0.062815, loss: 1.9271
2022-07-13 08:36:40 - train: epoch 0051, iter [00600, 05004], lr: 0.062789, loss: 1.8297
2022-07-13 08:37:13 - train: epoch 0051, iter [00700, 05004], lr: 0.062764, loss: 1.9405
2022-07-13 08:37:47 - train: epoch 0051, iter [00800, 05004], lr: 0.062739, loss: 2.1581
2022-07-13 08:38:20 - train: epoch 0051, iter [00900, 05004], lr: 0.062713, loss: 1.8647
2022-07-13 08:38:53 - train: epoch 0051, iter [01000, 05004], lr: 0.062688, loss: 2.1688
2022-07-13 08:39:27 - train: epoch 0051, iter [01100, 05004], lr: 0.062663, loss: 2.1303
2022-07-13 08:40:00 - train: epoch 0051, iter [01200, 05004], lr: 0.062637, loss: 1.8351
2022-07-13 08:40:34 - train: epoch 0051, iter [01300, 05004], lr: 0.062612, loss: 1.6531
2022-07-13 08:41:08 - train: epoch 0051, iter [01400, 05004], lr: 0.062587, loss: 1.7775
2022-07-13 08:41:41 - train: epoch 0051, iter [01500, 05004], lr: 0.062562, loss: 1.8641
2022-07-13 08:42:15 - train: epoch 0051, iter [01600, 05004], lr: 0.062536, loss: 1.7733
2022-07-13 08:42:48 - train: epoch 0051, iter [01700, 05004], lr: 0.062511, loss: 1.9944
2022-07-13 08:43:22 - train: epoch 0051, iter [01800, 05004], lr: 0.062486, loss: 1.8901
2022-07-13 08:43:55 - train: epoch 0051, iter [01900, 05004], lr: 0.062460, loss: 1.6521
2022-07-13 08:44:28 - train: epoch 0051, iter [02000, 05004], lr: 0.062435, loss: 1.9678
2022-07-13 08:45:02 - train: epoch 0051, iter [02100, 05004], lr: 0.062410, loss: 1.8785
2022-07-13 08:45:37 - train: epoch 0051, iter [02200, 05004], lr: 0.062384, loss: 2.0040
2022-07-13 08:46:10 - train: epoch 0051, iter [02300, 05004], lr: 0.062359, loss: 2.1465
2022-07-13 08:46:44 - train: epoch 0051, iter [02400, 05004], lr: 0.062334, loss: 2.0514
2022-07-13 08:47:17 - train: epoch 0051, iter [02500, 05004], lr: 0.062308, loss: 1.8812
2022-07-13 08:47:51 - train: epoch 0051, iter [02600, 05004], lr: 0.062283, loss: 1.7522
2022-07-13 08:48:25 - train: epoch 0051, iter [02700, 05004], lr: 0.062257, loss: 2.0570
2022-07-13 08:48:59 - train: epoch 0051, iter [02800, 05004], lr: 0.062232, loss: 1.9412
2022-07-13 08:49:32 - train: epoch 0051, iter [02900, 05004], lr: 0.062207, loss: 2.0168
2022-07-13 08:50:06 - train: epoch 0051, iter [03000, 05004], lr: 0.062181, loss: 1.9439
2022-07-13 08:50:39 - train: epoch 0051, iter [03100, 05004], lr: 0.062156, loss: 1.8923
2022-07-13 08:51:13 - train: epoch 0051, iter [03200, 05004], lr: 0.062131, loss: 2.0127
2022-07-13 08:51:46 - train: epoch 0051, iter [03300, 05004], lr: 0.062105, loss: 2.0757
2022-07-13 08:52:20 - train: epoch 0051, iter [03400, 05004], lr: 0.062080, loss: 1.9819
2022-07-13 08:52:54 - train: epoch 0051, iter [03500, 05004], lr: 0.062054, loss: 1.8575
2022-07-13 08:53:28 - train: epoch 0051, iter [03600, 05004], lr: 0.062029, loss: 1.9673
2022-07-13 08:54:01 - train: epoch 0051, iter [03700, 05004], lr: 0.062004, loss: 2.0823
2022-07-13 08:54:35 - train: epoch 0051, iter [03800, 05004], lr: 0.061978, loss: 1.9244
2022-07-13 08:55:08 - train: epoch 0051, iter [03900, 05004], lr: 0.061953, loss: 2.0887
2022-07-13 08:55:41 - train: epoch 0051, iter [04000, 05004], lr: 0.061927, loss: 1.9848
2022-07-13 08:56:15 - train: epoch 0051, iter [04100, 05004], lr: 0.061902, loss: 2.0772
2022-07-13 08:56:49 - train: epoch 0051, iter [04200, 05004], lr: 0.061877, loss: 2.1996
2022-07-13 08:57:23 - train: epoch 0051, iter [04300, 05004], lr: 0.061851, loss: 1.8416
2022-07-13 08:57:56 - train: epoch 0051, iter [04400, 05004], lr: 0.061826, loss: 2.0704
2022-07-13 08:58:30 - train: epoch 0051, iter [04500, 05004], lr: 0.061800, loss: 1.6948
2022-07-13 08:59:04 - train: epoch 0051, iter [04600, 05004], lr: 0.061775, loss: 2.1184
2022-07-13 08:59:38 - train: epoch 0051, iter [04700, 05004], lr: 0.061750, loss: 2.0037
2022-07-13 09:00:11 - train: epoch 0051, iter [04800, 05004], lr: 0.061724, loss: 1.9674
2022-07-13 09:00:44 - train: epoch 0051, iter [04900, 05004], lr: 0.061699, loss: 1.9913
2022-07-13 09:01:17 - train: epoch 0051, iter [05000, 05004], lr: 0.061673, loss: 1.8500
2022-07-13 09:01:18 - train: epoch 051, train_loss: 1.9664
2022-07-13 09:02:33 - eval: epoch: 051, acc1: 59.128%, acc5: 82.438%, test_loss: 1.7322, per_image_load_time: 2.628ms, per_image_inference_time: 0.281ms
2022-07-13 09:02:33 - until epoch: 051, best_acc1: 59.852%
2022-07-13 09:02:33 - epoch 052 lr: 0.061672
2022-07-13 09:03:12 - train: epoch 0052, iter [00100, 05004], lr: 0.061647, loss: 1.7742
2022-07-13 09:03:45 - train: epoch 0052, iter [00200, 05004], lr: 0.061621, loss: 1.9492
2022-07-13 09:04:18 - train: epoch 0052, iter [00300, 05004], lr: 0.061596, loss: 2.0197
2022-07-13 09:04:52 - train: epoch 0052, iter [00400, 05004], lr: 0.061570, loss: 2.0420
2022-07-13 09:05:26 - train: epoch 0052, iter [00500, 05004], lr: 0.061545, loss: 1.8567
2022-07-13 09:06:00 - train: epoch 0052, iter [00600, 05004], lr: 0.061520, loss: 1.6879
2022-07-13 09:06:33 - train: epoch 0052, iter [00700, 05004], lr: 0.061494, loss: 1.9666
2022-07-13 09:07:06 - train: epoch 0052, iter [00800, 05004], lr: 0.061469, loss: 1.9339
2022-07-13 09:07:39 - train: epoch 0052, iter [00900, 05004], lr: 0.061443, loss: 1.9874
2022-07-13 09:08:13 - train: epoch 0052, iter [01000, 05004], lr: 0.061418, loss: 2.2274
2022-07-13 09:08:47 - train: epoch 0052, iter [01100, 05004], lr: 0.061392, loss: 1.8572
2022-07-13 09:09:21 - train: epoch 0052, iter [01200, 05004], lr: 0.061367, loss: 1.7468
2022-07-13 09:09:54 - train: epoch 0052, iter [01300, 05004], lr: 0.061341, loss: 1.8681
2022-07-13 09:10:26 - train: epoch 0052, iter [01400, 05004], lr: 0.061316, loss: 2.2584
2022-07-13 09:11:01 - train: epoch 0052, iter [01500, 05004], lr: 0.061290, loss: 1.9016
2022-07-13 09:11:34 - train: epoch 0052, iter [01600, 05004], lr: 0.061265, loss: 1.8325
2022-07-13 09:12:08 - train: epoch 0052, iter [01700, 05004], lr: 0.061239, loss: 1.7413
2022-07-13 09:12:41 - train: epoch 0052, iter [01800, 05004], lr: 0.061214, loss: 1.8816
2022-07-13 09:13:15 - train: epoch 0052, iter [01900, 05004], lr: 0.061188, loss: 1.8979
2022-07-13 09:13:49 - train: epoch 0052, iter [02000, 05004], lr: 0.061163, loss: 2.1464
2022-07-13 09:14:21 - train: epoch 0052, iter [02100, 05004], lr: 0.061137, loss: 1.9327
2022-07-13 09:14:56 - train: epoch 0052, iter [02200, 05004], lr: 0.061112, loss: 1.9804
2022-07-13 09:15:29 - train: epoch 0052, iter [02300, 05004], lr: 0.061086, loss: 1.7885
2022-07-13 09:16:02 - train: epoch 0052, iter [02400, 05004], lr: 0.061061, loss: 1.7669
2022-07-13 09:16:36 - train: epoch 0052, iter [02500, 05004], lr: 0.061035, loss: 1.7511
2022-07-13 09:17:10 - train: epoch 0052, iter [02600, 05004], lr: 0.061010, loss: 1.6366
2022-07-13 09:17:42 - train: epoch 0052, iter [02700, 05004], lr: 0.060984, loss: 1.8687
2022-07-13 09:18:16 - train: epoch 0052, iter [02800, 05004], lr: 0.060959, loss: 2.0087
2022-07-13 09:18:50 - train: epoch 0052, iter [02900, 05004], lr: 0.060933, loss: 1.8002
2022-07-13 09:19:23 - train: epoch 0052, iter [03000, 05004], lr: 0.060908, loss: 1.9217
2022-07-13 09:19:57 - train: epoch 0052, iter [03100, 05004], lr: 0.060882, loss: 2.0004
2022-07-13 09:20:30 - train: epoch 0052, iter [03200, 05004], lr: 0.060857, loss: 2.0397
2022-07-13 09:21:04 - train: epoch 0052, iter [03300, 05004], lr: 0.060831, loss: 1.9496
2022-07-13 09:21:38 - train: epoch 0052, iter [03400, 05004], lr: 0.060806, loss: 2.0521
2022-07-13 09:22:11 - train: epoch 0052, iter [03500, 05004], lr: 0.060780, loss: 2.1034
2022-07-13 09:22:45 - train: epoch 0052, iter [03600, 05004], lr: 0.060755, loss: 2.0511
2022-07-13 09:23:18 - train: epoch 0052, iter [03700, 05004], lr: 0.060729, loss: 2.1472
2022-07-13 09:23:51 - train: epoch 0052, iter [03800, 05004], lr: 0.060703, loss: 1.7574
2022-07-13 09:24:24 - train: epoch 0052, iter [03900, 05004], lr: 0.060678, loss: 1.8251
2022-07-13 09:24:59 - train: epoch 0052, iter [04000, 05004], lr: 0.060652, loss: 2.1130
2022-07-13 09:25:32 - train: epoch 0052, iter [04100, 05004], lr: 0.060627, loss: 1.7323
2022-07-13 09:26:05 - train: epoch 0052, iter [04200, 05004], lr: 0.060601, loss: 1.8723
2022-07-13 09:26:40 - train: epoch 0052, iter [04300, 05004], lr: 0.060576, loss: 1.9921
2022-07-13 09:27:13 - train: epoch 0052, iter [04400, 05004], lr: 0.060550, loss: 2.0301
2022-07-13 09:27:45 - train: epoch 0052, iter [04500, 05004], lr: 0.060525, loss: 1.8363
2022-07-13 09:28:19 - train: epoch 0052, iter [04600, 05004], lr: 0.060499, loss: 2.0253
2022-07-13 09:28:51 - train: epoch 0052, iter [04700, 05004], lr: 0.060473, loss: 2.0574
2022-07-13 09:29:25 - train: epoch 0052, iter [04800, 05004], lr: 0.060448, loss: 1.7461
2022-07-13 09:29:58 - train: epoch 0052, iter [04900, 05004], lr: 0.060422, loss: 1.8198
2022-07-13 09:30:30 - train: epoch 0052, iter [05000, 05004], lr: 0.060397, loss: 1.9718
2022-07-13 09:30:30 - train: epoch 052, train_loss: 1.9578
2022-07-13 09:31:44 - eval: epoch: 052, acc1: 58.736%, acc5: 82.454%, test_loss: 1.7443, per_image_load_time: 2.590ms, per_image_inference_time: 0.273ms
2022-07-13 09:31:45 - until epoch: 052, best_acc1: 59.852%
2022-07-13 09:31:45 - epoch 053 lr: 0.060395
2022-07-13 09:32:23 - train: epoch 0053, iter [00100, 05004], lr: 0.060370, loss: 1.9440
2022-07-13 09:32:57 - train: epoch 0053, iter [00200, 05004], lr: 0.060344, loss: 2.1060
2022-07-13 09:33:29 - train: epoch 0053, iter [00300, 05004], lr: 0.060319, loss: 1.9683
2022-07-13 09:34:02 - train: epoch 0053, iter [00400, 05004], lr: 0.060293, loss: 2.0580
2022-07-13 09:34:34 - train: epoch 0053, iter [00500, 05004], lr: 0.060268, loss: 2.0471
2022-07-13 09:35:08 - train: epoch 0053, iter [00600, 05004], lr: 0.060242, loss: 1.9402
2022-07-13 09:35:41 - train: epoch 0053, iter [00700, 05004], lr: 0.060216, loss: 1.8161
2022-07-13 09:36:14 - train: epoch 0053, iter [00800, 05004], lr: 0.060191, loss: 1.9086
2022-07-13 09:36:46 - train: epoch 0053, iter [00900, 05004], lr: 0.060165, loss: 1.8269
2022-07-13 09:37:20 - train: epoch 0053, iter [01000, 05004], lr: 0.060140, loss: 1.8839
2022-07-13 09:37:53 - train: epoch 0053, iter [01100, 05004], lr: 0.060114, loss: 1.9131
2022-07-13 09:38:26 - train: epoch 0053, iter [01200, 05004], lr: 0.060088, loss: 1.8627
2022-07-13 09:38:58 - train: epoch 0053, iter [01300, 05004], lr: 0.060063, loss: 1.8520
2022-07-13 09:39:32 - train: epoch 0053, iter [01400, 05004], lr: 0.060037, loss: 2.4009
2022-07-13 09:40:04 - train: epoch 0053, iter [01500, 05004], lr: 0.060011, loss: 1.9098
2022-07-13 09:40:38 - train: epoch 0053, iter [01600, 05004], lr: 0.059986, loss: 2.2850
2022-07-13 09:41:11 - train: epoch 0053, iter [01700, 05004], lr: 0.059960, loss: 2.1742
2022-07-13 09:41:43 - train: epoch 0053, iter [01800, 05004], lr: 0.059935, loss: 2.0959
2022-07-13 09:42:17 - train: epoch 0053, iter [01900, 05004], lr: 0.059909, loss: 1.7765
2022-07-13 09:42:49 - train: epoch 0053, iter [02000, 05004], lr: 0.059883, loss: 2.0331
2022-07-13 09:43:23 - train: epoch 0053, iter [02100, 05004], lr: 0.059858, loss: 2.0095
2022-07-13 09:43:56 - train: epoch 0053, iter [02200, 05004], lr: 0.059832, loss: 1.9243
2022-07-13 09:44:30 - train: epoch 0053, iter [02300, 05004], lr: 0.059806, loss: 2.0973
2022-07-13 09:45:03 - train: epoch 0053, iter [02400, 05004], lr: 0.059781, loss: 1.9596
2022-07-13 09:45:37 - train: epoch 0053, iter [02500, 05004], lr: 0.059755, loss: 2.1479
2022-07-13 09:46:09 - train: epoch 0053, iter [02600, 05004], lr: 0.059729, loss: 2.0484
2022-07-13 09:46:42 - train: epoch 0053, iter [02700, 05004], lr: 0.059704, loss: 2.2463
2022-07-13 09:47:15 - train: epoch 0053, iter [02800, 05004], lr: 0.059678, loss: 2.0877
2022-07-13 09:47:49 - train: epoch 0053, iter [02900, 05004], lr: 0.059652, loss: 1.6858
2022-07-13 09:48:22 - train: epoch 0053, iter [03000, 05004], lr: 0.059627, loss: 1.6641
2022-07-13 09:48:55 - train: epoch 0053, iter [03100, 05004], lr: 0.059601, loss: 2.1452
2022-07-13 09:49:28 - train: epoch 0053, iter [03200, 05004], lr: 0.059575, loss: 2.2129
2022-07-13 09:50:01 - train: epoch 0053, iter [03300, 05004], lr: 0.059550, loss: 1.8304
2022-07-13 09:50:34 - train: epoch 0053, iter [03400, 05004], lr: 0.059524, loss: 2.0703
2022-07-13 09:51:07 - train: epoch 0053, iter [03500, 05004], lr: 0.059498, loss: 2.0078
2022-07-13 09:51:40 - train: epoch 0053, iter [03600, 05004], lr: 0.059473, loss: 2.0257
2022-07-13 09:52:13 - train: epoch 0053, iter [03700, 05004], lr: 0.059447, loss: 2.1920
2022-07-13 09:52:46 - train: epoch 0053, iter [03800, 05004], lr: 0.059421, loss: 1.7980
2022-07-13 09:53:19 - train: epoch 0053, iter [03900, 05004], lr: 0.059396, loss: 2.1222
2022-07-13 09:53:52 - train: epoch 0053, iter [04000, 05004], lr: 0.059370, loss: 1.9007
2022-07-13 09:54:25 - train: epoch 0053, iter [04100, 05004], lr: 0.059344, loss: 2.1127
2022-07-13 09:54:58 - train: epoch 0053, iter [04200, 05004], lr: 0.059318, loss: 1.9581
2022-07-13 09:55:30 - train: epoch 0053, iter [04300, 05004], lr: 0.059293, loss: 2.2505
2022-07-13 09:56:04 - train: epoch 0053, iter [04400, 05004], lr: 0.059267, loss: 1.9601
2022-07-13 09:56:37 - train: epoch 0053, iter [04500, 05004], lr: 0.059241, loss: 2.0382
2022-07-13 09:57:10 - train: epoch 0053, iter [04600, 05004], lr: 0.059216, loss: 1.7679
2022-07-13 09:57:42 - train: epoch 0053, iter [04700, 05004], lr: 0.059190, loss: 2.1171
2022-07-13 09:58:16 - train: epoch 0053, iter [04800, 05004], lr: 0.059164, loss: 2.1772
2022-07-13 09:58:48 - train: epoch 0053, iter [04900, 05004], lr: 0.059139, loss: 1.8721
2022-07-13 09:59:19 - train: epoch 0053, iter [05000, 05004], lr: 0.059113, loss: 1.8437
2022-07-13 09:59:20 - train: epoch 053, train_loss: 1.9465
2022-07-13 10:00:34 - eval: epoch: 053, acc1: 59.756%, acc5: 83.142%, test_loss: 1.6947, per_image_load_time: 2.583ms, per_image_inference_time: 0.258ms
2022-07-13 10:00:34 - until epoch: 053, best_acc1: 59.852%
2022-07-13 10:00:34 - epoch 054 lr: 0.059112
2022-07-13 10:01:13 - train: epoch 0054, iter [00100, 05004], lr: 0.059086, loss: 1.7573
2022-07-13 10:01:46 - train: epoch 0054, iter [00200, 05004], lr: 0.059060, loss: 2.3287
2022-07-13 10:02:19 - train: epoch 0054, iter [00300, 05004], lr: 0.059035, loss: 2.0199
2022-07-13 10:02:51 - train: epoch 0054, iter [00400, 05004], lr: 0.059009, loss: 1.7399
2022-07-13 10:03:24 - train: epoch 0054, iter [00500, 05004], lr: 0.058983, loss: 1.9562
2022-07-13 10:03:56 - train: epoch 0054, iter [00600, 05004], lr: 0.058957, loss: 1.8426
2022-07-13 10:04:30 - train: epoch 0054, iter [00700, 05004], lr: 0.058932, loss: 1.9797
2022-07-13 10:05:01 - train: epoch 0054, iter [00800, 05004], lr: 0.058906, loss: 2.0276
2022-07-13 10:05:35 - train: epoch 0054, iter [00900, 05004], lr: 0.058880, loss: 1.7669
2022-07-13 10:06:07 - train: epoch 0054, iter [01000, 05004], lr: 0.058854, loss: 1.7011
2022-07-13 10:06:40 - train: epoch 0054, iter [01100, 05004], lr: 0.058829, loss: 1.8451
2022-07-13 10:07:14 - train: epoch 0054, iter [01200, 05004], lr: 0.058803, loss: 2.0927
2022-07-13 10:07:46 - train: epoch 0054, iter [01300, 05004], lr: 0.058777, loss: 1.8838
2022-07-13 10:08:20 - train: epoch 0054, iter [01400, 05004], lr: 0.058751, loss: 2.0040
2022-07-13 10:08:53 - train: epoch 0054, iter [01500, 05004], lr: 0.058726, loss: 1.8934
2022-07-13 10:09:26 - train: epoch 0054, iter [01600, 05004], lr: 0.058700, loss: 1.7378
2022-07-13 10:09:58 - train: epoch 0054, iter [01700, 05004], lr: 0.058674, loss: 1.9800
2022-07-13 10:10:31 - train: epoch 0054, iter [01800, 05004], lr: 0.058648, loss: 1.8867
2022-07-13 10:11:05 - train: epoch 0054, iter [01900, 05004], lr: 0.058623, loss: 2.2217
2022-07-13 10:11:37 - train: epoch 0054, iter [02000, 05004], lr: 0.058597, loss: 2.0668
2022-07-13 10:12:10 - train: epoch 0054, iter [02100, 05004], lr: 0.058571, loss: 1.6764
2022-07-13 10:12:43 - train: epoch 0054, iter [02200, 05004], lr: 0.058545, loss: 2.0337
2022-07-13 10:13:16 - train: epoch 0054, iter [02300, 05004], lr: 0.058520, loss: 1.8204
2022-07-13 10:13:49 - train: epoch 0054, iter [02400, 05004], lr: 0.058494, loss: 1.8809
2022-07-13 10:14:23 - train: epoch 0054, iter [02500, 05004], lr: 0.058468, loss: 2.0544
2022-07-13 10:14:54 - train: epoch 0054, iter [02600, 05004], lr: 0.058442, loss: 1.8601
2022-07-13 10:15:29 - train: epoch 0054, iter [02700, 05004], lr: 0.058416, loss: 1.9422
2022-07-13 10:16:00 - train: epoch 0054, iter [02800, 05004], lr: 0.058391, loss: 2.2522
2022-07-13 10:16:34 - train: epoch 0054, iter [02900, 05004], lr: 0.058365, loss: 1.8240
2022-07-13 10:17:07 - train: epoch 0054, iter [03000, 05004], lr: 0.058339, loss: 2.0919
2022-07-13 10:17:39 - train: epoch 0054, iter [03100, 05004], lr: 0.058313, loss: 1.9861
2022-07-13 10:18:12 - train: epoch 0054, iter [03200, 05004], lr: 0.058287, loss: 2.1240
2022-07-13 10:18:44 - train: epoch 0054, iter [03300, 05004], lr: 0.058262, loss: 1.8359
2022-07-13 10:19:18 - train: epoch 0054, iter [03400, 05004], lr: 0.058236, loss: 1.9653
2022-07-13 10:19:50 - train: epoch 0054, iter [03500, 05004], lr: 0.058210, loss: 2.1093
2022-07-13 10:20:23 - train: epoch 0054, iter [03600, 05004], lr: 0.058184, loss: 1.8614
2022-07-13 10:20:57 - train: epoch 0054, iter [03700, 05004], lr: 0.058158, loss: 1.8217
2022-07-13 10:21:29 - train: epoch 0054, iter [03800, 05004], lr: 0.058133, loss: 2.0011
2022-07-13 10:22:03 - train: epoch 0054, iter [03900, 05004], lr: 0.058107, loss: 1.9552
2022-07-13 10:22:35 - train: epoch 0054, iter [04000, 05004], lr: 0.058081, loss: 1.8297
2022-07-13 10:23:09 - train: epoch 0054, iter [04100, 05004], lr: 0.058055, loss: 1.9871
2022-07-13 10:23:41 - train: epoch 0054, iter [04200, 05004], lr: 0.058029, loss: 1.9283
2022-07-13 10:24:15 - train: epoch 0054, iter [04300, 05004], lr: 0.058004, loss: 2.0366
2022-07-13 10:24:47 - train: epoch 0054, iter [04400, 05004], lr: 0.057978, loss: 1.7464
2022-07-13 10:25:21 - train: epoch 0054, iter [04500, 05004], lr: 0.057952, loss: 1.8319
2022-07-13 10:25:52 - train: epoch 0054, iter [04600, 05004], lr: 0.057926, loss: 1.9851
2022-07-13 10:26:26 - train: epoch 0054, iter [04700, 05004], lr: 0.057900, loss: 2.2433
2022-07-13 10:26:59 - train: epoch 0054, iter [04800, 05004], lr: 0.057874, loss: 2.1305
2022-07-13 10:27:32 - train: epoch 0054, iter [04900, 05004], lr: 0.057849, loss: 1.7683
2022-07-13 10:28:04 - train: epoch 0054, iter [05000, 05004], lr: 0.057823, loss: 1.9364
2022-07-13 10:28:05 - train: epoch 054, train_loss: 1.9406
2022-07-13 10:29:18 - eval: epoch: 054, acc1: 59.270%, acc5: 83.022%, test_loss: 1.7169, per_image_load_time: 2.580ms, per_image_inference_time: 0.276ms
2022-07-13 10:29:18 - until epoch: 054, best_acc1: 59.852%
2022-07-13 10:29:18 - epoch 055 lr: 0.057821
2022-07-13 10:29:58 - train: epoch 0055, iter [00100, 05004], lr: 0.057796, loss: 1.7730
2022-07-13 10:30:30 - train: epoch 0055, iter [00200, 05004], lr: 0.057770, loss: 1.8799
2022-07-13 10:31:03 - train: epoch 0055, iter [00300, 05004], lr: 0.057744, loss: 1.7632
2022-07-13 10:31:36 - train: epoch 0055, iter [00400, 05004], lr: 0.057718, loss: 1.9116
2022-07-13 10:32:09 - train: epoch 0055, iter [00500, 05004], lr: 0.057693, loss: 1.6999
2022-07-13 10:32:41 - train: epoch 0055, iter [00600, 05004], lr: 0.057667, loss: 1.8269
2022-07-13 10:33:14 - train: epoch 0055, iter [00700, 05004], lr: 0.057641, loss: 2.0552
2022-07-13 10:33:46 - train: epoch 0055, iter [00800, 05004], lr: 0.057615, loss: 1.7418
2022-07-13 10:34:20 - train: epoch 0055, iter [00900, 05004], lr: 0.057589, loss: 2.0232
2022-07-13 10:34:52 - train: epoch 0055, iter [01000, 05004], lr: 0.057563, loss: 1.9789
2022-07-13 10:35:25 - train: epoch 0055, iter [01100, 05004], lr: 0.057537, loss: 2.0016
2022-07-13 10:35:58 - train: epoch 0055, iter [01200, 05004], lr: 0.057512, loss: 1.9256
2022-07-13 10:36:31 - train: epoch 0055, iter [01300, 05004], lr: 0.057486, loss: 2.0540
2022-07-13 10:37:04 - train: epoch 0055, iter [01400, 05004], lr: 0.057460, loss: 1.8881
2022-07-13 10:37:37 - train: epoch 0055, iter [01500, 05004], lr: 0.057434, loss: 1.9574
2022-07-13 10:38:10 - train: epoch 0055, iter [01600, 05004], lr: 0.057408, loss: 2.0283
2022-07-13 10:38:43 - train: epoch 0055, iter [01700, 05004], lr: 0.057382, loss: 2.0785
2022-07-13 10:39:16 - train: epoch 0055, iter [01800, 05004], lr: 0.057356, loss: 2.0849
2022-07-13 10:39:50 - train: epoch 0055, iter [01900, 05004], lr: 0.057330, loss: 1.9453
2022-07-13 10:40:23 - train: epoch 0055, iter [02000, 05004], lr: 0.057305, loss: 1.8954
2022-07-13 10:40:56 - train: epoch 0055, iter [02100, 05004], lr: 0.057279, loss: 1.6723
2022-07-13 10:41:30 - train: epoch 0055, iter [02200, 05004], lr: 0.057253, loss: 2.0421
2022-07-13 10:42:03 - train: epoch 0055, iter [02300, 05004], lr: 0.057227, loss: 1.7967
2022-07-13 10:42:36 - train: epoch 0055, iter [02400, 05004], lr: 0.057201, loss: 1.7766
2022-07-13 10:43:09 - train: epoch 0055, iter [02500, 05004], lr: 0.057175, loss: 1.9542
2022-07-13 10:43:42 - train: epoch 0055, iter [02600, 05004], lr: 0.057149, loss: 1.7704
2022-07-13 10:44:16 - train: epoch 0055, iter [02700, 05004], lr: 0.057123, loss: 1.8812
2022-07-13 10:44:49 - train: epoch 0055, iter [02800, 05004], lr: 0.057097, loss: 1.8954
2022-07-13 10:45:22 - train: epoch 0055, iter [02900, 05004], lr: 0.057072, loss: 2.0892
2022-07-13 10:45:55 - train: epoch 0055, iter [03000, 05004], lr: 0.057046, loss: 1.8979
2022-07-13 10:46:28 - train: epoch 0055, iter [03100, 05004], lr: 0.057020, loss: 1.9997
2022-07-13 10:47:02 - train: epoch 0055, iter [03200, 05004], lr: 0.056994, loss: 1.9035
2022-07-13 10:47:34 - train: epoch 0055, iter [03300, 05004], lr: 0.056968, loss: 1.6789
2022-07-13 10:48:07 - train: epoch 0055, iter [03400, 05004], lr: 0.056942, loss: 1.8344
2022-07-13 10:48:41 - train: epoch 0055, iter [03500, 05004], lr: 0.056916, loss: 1.7250
2022-07-13 10:49:14 - train: epoch 0055, iter [03600, 05004], lr: 0.056890, loss: 2.0029
2022-07-13 10:49:47 - train: epoch 0055, iter [03700, 05004], lr: 0.056864, loss: 1.9559
2022-07-13 10:50:20 - train: epoch 0055, iter [03800, 05004], lr: 0.056838, loss: 1.9955
2022-07-13 10:50:54 - train: epoch 0055, iter [03900, 05004], lr: 0.056813, loss: 2.3641
2022-07-13 10:51:27 - train: epoch 0055, iter [04000, 05004], lr: 0.056787, loss: 1.8823
2022-07-13 10:52:01 - train: epoch 0055, iter [04100, 05004], lr: 0.056761, loss: 1.9338
2022-07-13 10:52:34 - train: epoch 0055, iter [04200, 05004], lr: 0.056735, loss: 2.0377
2022-07-13 10:53:07 - train: epoch 0055, iter [04300, 05004], lr: 0.056709, loss: 1.9863
2022-07-13 10:53:42 - train: epoch 0055, iter [04400, 05004], lr: 0.056683, loss: 2.0412
2022-07-13 10:54:15 - train: epoch 0055, iter [04500, 05004], lr: 0.056657, loss: 1.9247
2022-07-13 10:54:48 - train: epoch 0055, iter [04600, 05004], lr: 0.056631, loss: 1.9927
2022-07-13 10:55:22 - train: epoch 0055, iter [04700, 05004], lr: 0.056605, loss: 1.7274
2022-07-13 10:55:55 - train: epoch 0055, iter [04800, 05004], lr: 0.056579, loss: 1.9410
2022-07-13 10:56:29 - train: epoch 0055, iter [04900, 05004], lr: 0.056553, loss: 1.8151
2022-07-13 10:57:00 - train: epoch 0055, iter [05000, 05004], lr: 0.056527, loss: 1.9555
2022-07-13 10:57:01 - train: epoch 055, train_loss: 1.9281
2022-07-13 10:58:14 - eval: epoch: 055, acc1: 60.726%, acc5: 83.980%, test_loss: 1.6436, per_image_load_time: 2.507ms, per_image_inference_time: 0.296ms
2022-07-13 10:58:15 - until epoch: 055, best_acc1: 60.726%
2022-07-13 10:58:15 - epoch 056 lr: 0.056526
2022-07-13 10:58:53 - train: epoch 0056, iter [00100, 05004], lr: 0.056500, loss: 1.8718
2022-07-13 10:59:26 - train: epoch 0056, iter [00200, 05004], lr: 0.056474, loss: 2.0589
2022-07-13 10:59:59 - train: epoch 0056, iter [00300, 05004], lr: 0.056448, loss: 1.8162
2022-07-13 11:00:33 - train: epoch 0056, iter [00400, 05004], lr: 0.056423, loss: 1.9083
2022-07-13 11:01:05 - train: epoch 0056, iter [00500, 05004], lr: 0.056397, loss: 1.8967
2022-07-13 11:01:39 - train: epoch 0056, iter [00600, 05004], lr: 0.056371, loss: 1.7315
2022-07-13 11:02:13 - train: epoch 0056, iter [00700, 05004], lr: 0.056345, loss: 2.0399
2022-07-13 11:02:45 - train: epoch 0056, iter [00800, 05004], lr: 0.056319, loss: 2.0335
2022-07-13 11:03:19 - train: epoch 0056, iter [00900, 05004], lr: 0.056293, loss: 2.0395
2022-07-13 11:03:51 - train: epoch 0056, iter [01000, 05004], lr: 0.056267, loss: 1.9087
2022-07-13 11:04:26 - train: epoch 0056, iter [01100, 05004], lr: 0.056241, loss: 1.7893
2022-07-13 11:04:59 - train: epoch 0056, iter [01200, 05004], lr: 0.056215, loss: 1.8459
2022-07-13 11:05:32 - train: epoch 0056, iter [01300, 05004], lr: 0.056189, loss: 2.0421
2022-07-13 11:06:05 - train: epoch 0056, iter [01400, 05004], lr: 0.056163, loss: 1.7710
2022-07-13 11:06:39 - train: epoch 0056, iter [01500, 05004], lr: 0.056137, loss: 2.2091
2022-07-13 11:07:12 - train: epoch 0056, iter [01600, 05004], lr: 0.056111, loss: 1.6577
2022-07-13 11:07:45 - train: epoch 0056, iter [01700, 05004], lr: 0.056085, loss: 2.0615
2022-07-13 11:08:18 - train: epoch 0056, iter [01800, 05004], lr: 0.056059, loss: 2.1458
2022-07-13 11:08:51 - train: epoch 0056, iter [01900, 05004], lr: 0.056033, loss: 1.9281
2022-07-13 11:09:24 - train: epoch 0056, iter [02000, 05004], lr: 0.056007, loss: 1.8631
2022-07-13 11:09:58 - train: epoch 0056, iter [02100, 05004], lr: 0.055981, loss: 1.9263
2022-07-13 11:10:31 - train: epoch 0056, iter [02200, 05004], lr: 0.055955, loss: 2.0315
2022-07-13 11:11:05 - train: epoch 0056, iter [02300, 05004], lr: 0.055929, loss: 2.1261
2022-07-13 11:11:37 - train: epoch 0056, iter [02400, 05004], lr: 0.055903, loss: 1.8489
2022-07-13 11:12:11 - train: epoch 0056, iter [02500, 05004], lr: 0.055877, loss: 2.1448
2022-07-13 11:12:43 - train: epoch 0056, iter [02600, 05004], lr: 0.055851, loss: 1.8623
2022-07-13 11:13:16 - train: epoch 0056, iter [02700, 05004], lr: 0.055825, loss: 1.9464
2022-07-13 11:13:50 - train: epoch 0056, iter [02800, 05004], lr: 0.055799, loss: 1.8385
2022-07-13 11:14:25 - train: epoch 0056, iter [02900, 05004], lr: 0.055773, loss: 1.9742
2022-07-13 11:14:58 - train: epoch 0056, iter [03000, 05004], lr: 0.055747, loss: 2.2066
2022-07-13 11:15:33 - train: epoch 0056, iter [03100, 05004], lr: 0.055721, loss: 1.8283
2022-07-13 11:16:05 - train: epoch 0056, iter [03200, 05004], lr: 0.055696, loss: 1.7736
2022-07-13 11:16:39 - train: epoch 0056, iter [03300, 05004], lr: 0.055670, loss: 2.2232
2022-07-13 11:17:12 - train: epoch 0056, iter [03400, 05004], lr: 0.055644, loss: 1.9181
2022-07-13 11:17:45 - train: epoch 0056, iter [03500, 05004], lr: 0.055618, loss: 1.8968
2022-07-13 11:18:18 - train: epoch 0056, iter [03600, 05004], lr: 0.055592, loss: 1.6973
2022-07-13 11:18:52 - train: epoch 0056, iter [03700, 05004], lr: 0.055566, loss: 1.9056
2022-07-13 11:19:24 - train: epoch 0056, iter [03800, 05004], lr: 0.055540, loss: 1.7859
2022-07-13 11:19:58 - train: epoch 0056, iter [03900, 05004], lr: 0.055514, loss: 2.1087
2022-07-13 11:20:31 - train: epoch 0056, iter [04000, 05004], lr: 0.055488, loss: 1.9179
2022-07-13 11:21:05 - train: epoch 0056, iter [04100, 05004], lr: 0.055462, loss: 2.0418
2022-07-13 11:21:37 - train: epoch 0056, iter [04200, 05004], lr: 0.055436, loss: 1.9438
2022-07-13 11:22:11 - train: epoch 0056, iter [04300, 05004], lr: 0.055410, loss: 1.8473
2022-07-13 11:22:44 - train: epoch 0056, iter [04400, 05004], lr: 0.055384, loss: 2.0043
2022-07-13 11:23:17 - train: epoch 0056, iter [04500, 05004], lr: 0.055358, loss: 1.8577
2022-07-13 11:23:50 - train: epoch 0056, iter [04600, 05004], lr: 0.055332, loss: 1.9441
2022-07-13 11:24:24 - train: epoch 0056, iter [04700, 05004], lr: 0.055306, loss: 1.9210
2022-07-13 11:24:57 - train: epoch 0056, iter [04800, 05004], lr: 0.055279, loss: 2.1223
2022-07-13 11:25:30 - train: epoch 0056, iter [04900, 05004], lr: 0.055253, loss: 1.9645
2022-07-13 11:26:03 - train: epoch 0056, iter [05000, 05004], lr: 0.055227, loss: 1.9694
2022-07-13 11:26:04 - train: epoch 056, train_loss: 1.9170
2022-07-13 11:27:19 - eval: epoch: 056, acc1: 60.510%, acc5: 83.626%, test_loss: 1.6650, per_image_load_time: 2.603ms, per_image_inference_time: 0.283ms
2022-07-13 11:27:19 - until epoch: 056, best_acc1: 60.726%
2022-07-13 11:27:19 - epoch 057 lr: 0.055226
2022-07-13 11:27:57 - train: epoch 0057, iter [00100, 05004], lr: 0.055200, loss: 2.0184
2022-07-13 11:28:31 - train: epoch 0057, iter [00200, 05004], lr: 0.055174, loss: 1.7828
2022-07-13 11:29:04 - train: epoch 0057, iter [00300, 05004], lr: 0.055148, loss: 1.7926
2022-07-13 11:29:37 - train: epoch 0057, iter [00400, 05004], lr: 0.055122, loss: 1.9673
2022-07-13 11:30:10 - train: epoch 0057, iter [00500, 05004], lr: 0.055096, loss: 1.6409
2022-07-13 11:30:43 - train: epoch 0057, iter [00600, 05004], lr: 0.055070, loss: 2.0592
2022-07-13 11:31:16 - train: epoch 0057, iter [00700, 05004], lr: 0.055044, loss: 1.5869
2022-07-13 11:31:49 - train: epoch 0057, iter [00800, 05004], lr: 0.055018, loss: 1.9489
2022-07-13 11:32:22 - train: epoch 0057, iter [00900, 05004], lr: 0.054992, loss: 1.9939
2022-07-13 11:32:55 - train: epoch 0057, iter [01000, 05004], lr: 0.054966, loss: 1.8809
2022-07-13 11:33:28 - train: epoch 0057, iter [01100, 05004], lr: 0.054940, loss: 1.8057
2022-07-13 11:34:02 - train: epoch 0057, iter [01200, 05004], lr: 0.054914, loss: 1.7433
2022-07-13 11:34:35 - train: epoch 0057, iter [01300, 05004], lr: 0.054888, loss: 2.0335
2022-07-13 11:35:08 - train: epoch 0057, iter [01400, 05004], lr: 0.054862, loss: 2.1105
2022-07-13 11:35:42 - train: epoch 0057, iter [01500, 05004], lr: 0.054836, loss: 2.1730
2022-07-13 11:36:14 - train: epoch 0057, iter [01600, 05004], lr: 0.054810, loss: 1.9703
2022-07-13 11:36:48 - train: epoch 0057, iter [01700, 05004], lr: 0.054784, loss: 2.0998
2022-07-13 11:37:21 - train: epoch 0057, iter [01800, 05004], lr: 0.054758, loss: 2.0595
2022-07-13 11:37:55 - train: epoch 0057, iter [01900, 05004], lr: 0.054732, loss: 1.8177
2022-07-13 11:38:27 - train: epoch 0057, iter [02000, 05004], lr: 0.054706, loss: 1.9582
2022-07-13 11:39:01 - train: epoch 0057, iter [02100, 05004], lr: 0.054680, loss: 2.0342
2022-07-13 11:39:33 - train: epoch 0057, iter [02200, 05004], lr: 0.054654, loss: 1.9540
2022-07-13 11:40:07 - train: epoch 0057, iter [02300, 05004], lr: 0.054628, loss: 1.8451
2022-07-13 11:40:40 - train: epoch 0057, iter [02400, 05004], lr: 0.054602, loss: 1.7636
2022-07-13 11:41:13 - train: epoch 0057, iter [02500, 05004], lr: 0.054576, loss: 1.9202
2022-07-13 11:41:46 - train: epoch 0057, iter [02600, 05004], lr: 0.054550, loss: 1.6527
2022-07-13 11:42:20 - train: epoch 0057, iter [02700, 05004], lr: 0.054524, loss: 1.6964
2022-07-13 11:42:53 - train: epoch 0057, iter [02800, 05004], lr: 0.054497, loss: 1.5048
2022-07-13 11:43:27 - train: epoch 0057, iter [02900, 05004], lr: 0.054471, loss: 2.0251
2022-07-13 11:44:00 - train: epoch 0057, iter [03000, 05004], lr: 0.054445, loss: 1.9652
2022-07-13 11:44:33 - train: epoch 0057, iter [03100, 05004], lr: 0.054419, loss: 2.1639
2022-07-13 11:45:07 - train: epoch 0057, iter [03200, 05004], lr: 0.054393, loss: 2.0146
2022-07-13 11:45:40 - train: epoch 0057, iter [03300, 05004], lr: 0.054367, loss: 1.8734
2022-07-13 11:46:13 - train: epoch 0057, iter [03400, 05004], lr: 0.054341, loss: 2.0279
2022-07-13 11:46:47 - train: epoch 0057, iter [03500, 05004], lr: 0.054315, loss: 2.0108
2022-07-13 11:47:20 - train: epoch 0057, iter [03600, 05004], lr: 0.054289, loss: 1.8266
2022-07-13 11:47:53 - train: epoch 0057, iter [03700, 05004], lr: 0.054263, loss: 1.7669
2022-07-13 11:48:25 - train: epoch 0057, iter [03800, 05004], lr: 0.054237, loss: 1.8339
2022-07-13 11:48:59 - train: epoch 0057, iter [03900, 05004], lr: 0.054211, loss: 2.0736
2022-07-13 11:49:32 - train: epoch 0057, iter [04000, 05004], lr: 0.054185, loss: 1.7996
2022-07-13 11:50:05 - train: epoch 0057, iter [04100, 05004], lr: 0.054159, loss: 1.9585
2022-07-13 11:50:38 - train: epoch 0057, iter [04200, 05004], lr: 0.054133, loss: 2.0097
2022-07-13 11:51:10 - train: epoch 0057, iter [04300, 05004], lr: 0.054107, loss: 1.8323
2022-07-13 11:51:43 - train: epoch 0057, iter [04400, 05004], lr: 0.054080, loss: 1.8853
2022-07-13 11:52:17 - train: epoch 0057, iter [04500, 05004], lr: 0.054054, loss: 2.0858
2022-07-13 11:52:50 - train: epoch 0057, iter [04600, 05004], lr: 0.054028, loss: 1.9213
2022-07-13 11:53:23 - train: epoch 0057, iter [04700, 05004], lr: 0.054002, loss: 1.8258
2022-07-13 11:53:56 - train: epoch 0057, iter [04800, 05004], lr: 0.053976, loss: 2.0906
2022-07-13 11:54:30 - train: epoch 0057, iter [04900, 05004], lr: 0.053950, loss: 2.0285
2022-07-13 11:55:01 - train: epoch 0057, iter [05000, 05004], lr: 0.053924, loss: 2.0774
2022-07-13 11:55:02 - train: epoch 057, train_loss: 1.9094
2022-07-13 11:56:16 - eval: epoch: 057, acc1: 60.678%, acc5: 83.906%, test_loss: 1.6517, per_image_load_time: 2.600ms, per_image_inference_time: 0.252ms
2022-07-13 11:56:16 - until epoch: 057, best_acc1: 60.726%
2022-07-13 11:56:16 - epoch 058 lr: 0.053923
2022-07-13 11:56:54 - train: epoch 0058, iter [00100, 05004], lr: 0.053897, loss: 1.9274
2022-07-13 11:57:28 - train: epoch 0058, iter [00200, 05004], lr: 0.053871, loss: 1.7518
2022-07-13 11:58:01 - train: epoch 0058, iter [00300, 05004], lr: 0.053845, loss: 1.8923
2022-07-13 11:58:34 - train: epoch 0058, iter [00400, 05004], lr: 0.053819, loss: 1.9200
2022-07-13 11:59:07 - train: epoch 0058, iter [00500, 05004], lr: 0.053793, loss: 1.7493
2022-07-13 11:59:41 - train: epoch 0058, iter [00600, 05004], lr: 0.053766, loss: 2.0191
2022-07-13 12:00:13 - train: epoch 0058, iter [00700, 05004], lr: 0.053740, loss: 1.8336
2022-07-13 12:00:45 - train: epoch 0058, iter [00800, 05004], lr: 0.053714, loss: 1.7364
2022-07-13 12:01:19 - train: epoch 0058, iter [00900, 05004], lr: 0.053688, loss: 1.6327
2022-07-13 12:01:51 - train: epoch 0058, iter [01000, 05004], lr: 0.053662, loss: 1.9666
2022-07-13 12:02:25 - train: epoch 0058, iter [01100, 05004], lr: 0.053636, loss: 1.6131
2022-07-13 12:02:57 - train: epoch 0058, iter [01200, 05004], lr: 0.053610, loss: 1.8414
2022-07-13 12:03:31 - train: epoch 0058, iter [01300, 05004], lr: 0.053584, loss: 1.9884
2022-07-13 12:04:03 - train: epoch 0058, iter [01400, 05004], lr: 0.053558, loss: 1.9198
2022-07-13 12:04:37 - train: epoch 0058, iter [01500, 05004], lr: 0.053532, loss: 1.7514
2022-07-13 12:05:09 - train: epoch 0058, iter [01600, 05004], lr: 0.053506, loss: 1.8060
2022-07-13 12:05:41 - train: epoch 0058, iter [01700, 05004], lr: 0.053479, loss: 2.0743
2022-07-13 12:06:14 - train: epoch 0058, iter [01800, 05004], lr: 0.053453, loss: 1.9478
2022-07-13 12:06:47 - train: epoch 0058, iter [01900, 05004], lr: 0.053427, loss: 2.0348
2022-07-13 12:07:20 - train: epoch 0058, iter [02000, 05004], lr: 0.053401, loss: 2.1409
2022-07-13 12:07:53 - train: epoch 0058, iter [02100, 05004], lr: 0.053375, loss: 1.7859
2022-07-13 12:08:25 - train: epoch 0058, iter [02200, 05004], lr: 0.053349, loss: 1.7245
2022-07-13 12:08:59 - train: epoch 0058, iter [02300, 05004], lr: 0.053323, loss: 1.8047
2022-07-13 12:09:31 - train: epoch 0058, iter [02400, 05004], lr: 0.053297, loss: 1.9576
2022-07-13 12:10:04 - train: epoch 0058, iter [02500, 05004], lr: 0.053271, loss: 2.0076
2022-07-13 12:10:37 - train: epoch 0058, iter [02600, 05004], lr: 0.053245, loss: 1.6601
2022-07-13 12:11:10 - train: epoch 0058, iter [02700, 05004], lr: 0.053218, loss: 2.0784
2022-07-13 12:11:43 - train: epoch 0058, iter [02800, 05004], lr: 0.053192, loss: 1.6190
2022-07-13 12:12:15 - train: epoch 0058, iter [02900, 05004], lr: 0.053166, loss: 1.7549
2022-07-13 12:12:48 - train: epoch 0058, iter [03000, 05004], lr: 0.053140, loss: 2.0896
2022-07-13 12:13:21 - train: epoch 0058, iter [03100, 05004], lr: 0.053114, loss: 1.7678
2022-07-13 12:13:54 - train: epoch 0058, iter [03200, 05004], lr: 0.053088, loss: 1.6723
2022-07-13 12:14:27 - train: epoch 0058, iter [03300, 05004], lr: 0.053062, loss: 1.8902
2022-07-13 12:14:59 - train: epoch 0058, iter [03400, 05004], lr: 0.053036, loss: 1.7266
2022-07-13 12:15:33 - train: epoch 0058, iter [03500, 05004], lr: 0.053010, loss: 1.8233
2022-07-13 12:16:06 - train: epoch 0058, iter [03600, 05004], lr: 0.052983, loss: 1.7923
2022-07-13 12:16:38 - train: epoch 0058, iter [03700, 05004], lr: 0.052957, loss: 1.9596
2022-07-13 12:17:10 - train: epoch 0058, iter [03800, 05004], lr: 0.052931, loss: 1.9335
2022-07-13 12:17:44 - train: epoch 0058, iter [03900, 05004], lr: 0.052905, loss: 1.9822
2022-07-13 12:18:16 - train: epoch 0058, iter [04000, 05004], lr: 0.052879, loss: 2.0043
2022-07-13 12:18:50 - train: epoch 0058, iter [04100, 05004], lr: 0.052853, loss: 2.0142
2022-07-13 12:19:22 - train: epoch 0058, iter [04200, 05004], lr: 0.052827, loss: 1.6185
2022-07-13 12:19:55 - train: epoch 0058, iter [04300, 05004], lr: 0.052801, loss: 2.1531
2022-07-13 12:20:28 - train: epoch 0058, iter [04400, 05004], lr: 0.052775, loss: 1.6657
2022-07-13 12:21:00 - train: epoch 0058, iter [04500, 05004], lr: 0.052748, loss: 1.9620
2022-07-13 12:21:33 - train: epoch 0058, iter [04600, 05004], lr: 0.052722, loss: 1.7880
2022-07-13 12:22:06 - train: epoch 0058, iter [04700, 05004], lr: 0.052696, loss: 1.9194
2022-07-13 12:22:39 - train: epoch 0058, iter [04800, 05004], lr: 0.052670, loss: 2.0153
2022-07-13 12:23:12 - train: epoch 0058, iter [04900, 05004], lr: 0.052644, loss: 1.7863
2022-07-13 12:23:43 - train: epoch 0058, iter [05000, 05004], lr: 0.052618, loss: 1.8346
2022-07-13 12:23:44 - train: epoch 058, train_loss: 1.8968
2022-07-13 12:24:57 - eval: epoch: 058, acc1: 61.076%, acc5: 84.036%, test_loss: 1.6412, per_image_load_time: 2.333ms, per_image_inference_time: 0.278ms
2022-07-13 12:24:58 - until epoch: 058, best_acc1: 61.076%
2022-07-13 12:24:58 - epoch 059 lr: 0.052617
2022-07-13 12:25:37 - train: epoch 0059, iter [00100, 05004], lr: 0.052591, loss: 1.9527
2022-07-13 12:26:10 - train: epoch 0059, iter [00200, 05004], lr: 0.052565, loss: 1.7816
2022-07-13 12:26:42 - train: epoch 0059, iter [00300, 05004], lr: 0.052538, loss: 1.8771
2022-07-13 12:27:15 - train: epoch 0059, iter [00400, 05004], lr: 0.052512, loss: 2.0156
2022-07-13 12:27:48 - train: epoch 0059, iter [00500, 05004], lr: 0.052486, loss: 2.1369
2022-07-13 12:28:21 - train: epoch 0059, iter [00600, 05004], lr: 0.052460, loss: 1.8398
2022-07-13 12:28:54 - train: epoch 0059, iter [00700, 05004], lr: 0.052434, loss: 1.7619
2022-07-13 12:29:26 - train: epoch 0059, iter [00800, 05004], lr: 0.052408, loss: 1.9619
2022-07-13 12:29:59 - train: epoch 0059, iter [00900, 05004], lr: 0.052382, loss: 1.7748
2022-07-13 12:30:32 - train: epoch 0059, iter [01000, 05004], lr: 0.052356, loss: 1.9336
2022-07-13 12:31:04 - train: epoch 0059, iter [01100, 05004], lr: 0.052329, loss: 2.1448
2022-07-13 12:31:38 - train: epoch 0059, iter [01200, 05004], lr: 0.052303, loss: 1.5289
2022-07-13 12:32:11 - train: epoch 0059, iter [01300, 05004], lr: 0.052277, loss: 2.1226
2022-07-13 12:32:44 - train: epoch 0059, iter [01400, 05004], lr: 0.052251, loss: 2.0973
2022-07-13 12:33:16 - train: epoch 0059, iter [01500, 05004], lr: 0.052225, loss: 2.0678
2022-07-13 12:33:49 - train: epoch 0059, iter [01600, 05004], lr: 0.052199, loss: 1.7521
2022-07-13 12:34:22 - train: epoch 0059, iter [01700, 05004], lr: 0.052173, loss: 1.9718
2022-07-13 12:34:55 - train: epoch 0059, iter [01800, 05004], lr: 0.052146, loss: 1.8229
2022-07-13 12:35:28 - train: epoch 0059, iter [01900, 05004], lr: 0.052120, loss: 1.9364
2022-07-13 12:36:00 - train: epoch 0059, iter [02000, 05004], lr: 0.052094, loss: 1.7663
2022-07-13 12:36:34 - train: epoch 0059, iter [02100, 05004], lr: 0.052068, loss: 2.1060
2022-07-13 12:37:07 - train: epoch 0059, iter [02200, 05004], lr: 0.052042, loss: 2.1091
2022-07-13 12:37:40 - train: epoch 0059, iter [02300, 05004], lr: 0.052016, loss: 1.8140
2022-07-13 12:38:12 - train: epoch 0059, iter [02400, 05004], lr: 0.051990, loss: 1.9985
2022-07-13 12:38:45 - train: epoch 0059, iter [02500, 05004], lr: 0.051964, loss: 1.8839
2022-07-13 12:39:18 - train: epoch 0059, iter [02600, 05004], lr: 0.051937, loss: 1.8338
2022-07-13 12:39:50 - train: epoch 0059, iter [02700, 05004], lr: 0.051911, loss: 1.8476
2022-07-13 12:40:24 - train: epoch 0059, iter [02800, 05004], lr: 0.051885, loss: 2.0866
2022-07-13 12:40:56 - train: epoch 0059, iter [02900, 05004], lr: 0.051859, loss: 1.8906
2022-07-13 12:41:29 - train: epoch 0059, iter [03000, 05004], lr: 0.051833, loss: 2.3026
2022-07-13 12:42:02 - train: epoch 0059, iter [03100, 05004], lr: 0.051807, loss: 1.7739
2022-07-13 12:42:35 - train: epoch 0059, iter [03200, 05004], lr: 0.051781, loss: 1.8465
2022-07-13 12:43:07 - train: epoch 0059, iter [03300, 05004], lr: 0.051754, loss: 1.9580
2022-07-13 12:43:41 - train: epoch 0059, iter [03400, 05004], lr: 0.051728, loss: 2.2692
2022-07-13 12:44:14 - train: epoch 0059, iter [03500, 05004], lr: 0.051702, loss: 1.7739
2022-07-13 12:44:47 - train: epoch 0059, iter [03600, 05004], lr: 0.051676, loss: 1.9095
2022-07-13 12:45:20 - train: epoch 0059, iter [03700, 05004], lr: 0.051650, loss: 1.7187
2022-07-13 12:45:52 - train: epoch 0059, iter [03800, 05004], lr: 0.051624, loss: 1.8837
2022-07-13 12:46:26 - train: epoch 0059, iter [03900, 05004], lr: 0.051598, loss: 1.7600
2022-07-13 12:46:59 - train: epoch 0059, iter [04000, 05004], lr: 0.051571, loss: 2.2111
2022-07-13 12:47:32 - train: epoch 0059, iter [04100, 05004], lr: 0.051545, loss: 1.8401
2022-07-13 12:48:05 - train: epoch 0059, iter [04200, 05004], lr: 0.051519, loss: 1.9338
2022-07-13 12:48:38 - train: epoch 0059, iter [04300, 05004], lr: 0.051493, loss: 2.1011
2022-07-13 12:49:10 - train: epoch 0059, iter [04400, 05004], lr: 0.051467, loss: 2.0809
2022-07-13 12:49:43 - train: epoch 0059, iter [04500, 05004], lr: 0.051441, loss: 2.0283
2022-07-13 12:50:16 - train: epoch 0059, iter [04600, 05004], lr: 0.051414, loss: 1.8876
2022-07-13 12:50:48 - train: epoch 0059, iter [04700, 05004], lr: 0.051388, loss: 1.8698
2022-07-13 12:51:22 - train: epoch 0059, iter [04800, 05004], lr: 0.051362, loss: 1.8582
2022-07-13 12:51:55 - train: epoch 0059, iter [04900, 05004], lr: 0.051336, loss: 2.1005
2022-07-13 12:52:26 - train: epoch 0059, iter [05000, 05004], lr: 0.051310, loss: 2.1481
2022-07-13 12:52:27 - train: epoch 059, train_loss: 1.8870
2022-07-13 12:53:41 - eval: epoch: 059, acc1: 60.740%, acc5: 83.486%, test_loss: 1.6559, per_image_load_time: 1.385ms, per_image_inference_time: 0.288ms
2022-07-13 12:53:41 - until epoch: 059, best_acc1: 61.076%
2022-07-13 12:53:41 - epoch 060 lr: 0.051309
2022-07-13 12:54:20 - train: epoch 0060, iter [00100, 05004], lr: 0.051283, loss: 1.7368
2022-07-13 12:54:53 - train: epoch 0060, iter [00200, 05004], lr: 0.051257, loss: 1.9746
2022-07-13 12:55:25 - train: epoch 0060, iter [00300, 05004], lr: 0.051230, loss: 1.8524
2022-07-13 12:55:58 - train: epoch 0060, iter [00400, 05004], lr: 0.051204, loss: 1.8281
2022-07-13 12:56:31 - train: epoch 0060, iter [00500, 05004], lr: 0.051178, loss: 2.0424
2022-07-13 12:57:03 - train: epoch 0060, iter [00600, 05004], lr: 0.051152, loss: 1.9519
2022-07-13 12:57:37 - train: epoch 0060, iter [00700, 05004], lr: 0.051126, loss: 1.8560
2022-07-13 12:58:09 - train: epoch 0060, iter [00800, 05004], lr: 0.051100, loss: 2.1642
2022-07-13 12:58:43 - train: epoch 0060, iter [00900, 05004], lr: 0.051073, loss: 1.6687
2022-07-13 12:59:16 - train: epoch 0060, iter [01000, 05004], lr: 0.051047, loss: 1.5556
2022-07-13 12:59:48 - train: epoch 0060, iter [01100, 05004], lr: 0.051021, loss: 1.6338
2022-07-13 13:00:21 - train: epoch 0060, iter [01200, 05004], lr: 0.050995, loss: 1.7892
2022-07-13 13:00:54 - train: epoch 0060, iter [01300, 05004], lr: 0.050969, loss: 1.7633
2022-07-13 13:01:27 - train: epoch 0060, iter [01400, 05004], lr: 0.050943, loss: 1.8679
2022-07-13 13:01:59 - train: epoch 0060, iter [01500, 05004], lr: 0.050917, loss: 1.9600
2022-07-13 13:02:32 - train: epoch 0060, iter [01600, 05004], lr: 0.050890, loss: 1.9124
2022-07-13 13:03:05 - train: epoch 0060, iter [01700, 05004], lr: 0.050864, loss: 1.9770
2022-07-13 13:03:38 - train: epoch 0060, iter [01800, 05004], lr: 0.050838, loss: 1.8764
2022-07-13 13:04:11 - train: epoch 0060, iter [01900, 05004], lr: 0.050812, loss: 2.1044
2022-07-13 13:04:44 - train: epoch 0060, iter [02000, 05004], lr: 0.050786, loss: 1.6689
2022-07-13 13:05:16 - train: epoch 0060, iter [02100, 05004], lr: 0.050760, loss: 1.9986
2022-07-13 13:05:49 - train: epoch 0060, iter [02200, 05004], lr: 0.050733, loss: 2.0204
2022-07-13 13:06:22 - train: epoch 0060, iter [02300, 05004], lr: 0.050707, loss: 1.5780
2022-07-13 13:06:54 - train: epoch 0060, iter [02400, 05004], lr: 0.050681, loss: 1.7483
2022-07-13 13:07:28 - train: epoch 0060, iter [02500, 05004], lr: 0.050655, loss: 1.8945
2022-07-13 13:08:00 - train: epoch 0060, iter [02600, 05004], lr: 0.050629, loss: 1.9648
2022-07-13 13:08:33 - train: epoch 0060, iter [02700, 05004], lr: 0.050603, loss: 1.9306
2022-07-13 13:09:06 - train: epoch 0060, iter [02800, 05004], lr: 0.050577, loss: 1.8859
2022-07-13 13:09:39 - train: epoch 0060, iter [02900, 05004], lr: 0.050550, loss: 1.9607
2022-07-13 13:10:12 - train: epoch 0060, iter [03000, 05004], lr: 0.050524, loss: 2.1524
2022-07-13 13:10:44 - train: epoch 0060, iter [03100, 05004], lr: 0.050498, loss: 2.0343
2022-07-13 13:11:17 - train: epoch 0060, iter [03200, 05004], lr: 0.050472, loss: 1.9307
2022-07-13 13:11:50 - train: epoch 0060, iter [03300, 05004], lr: 0.050446, loss: 1.7049
2022-07-13 13:12:23 - train: epoch 0060, iter [03400, 05004], lr: 0.050420, loss: 1.9668
2022-07-13 13:12:56 - train: epoch 0060, iter [03500, 05004], lr: 0.050393, loss: 1.9678
2022-07-13 13:13:29 - train: epoch 0060, iter [03600, 05004], lr: 0.050367, loss: 1.9462
2022-07-13 13:14:01 - train: epoch 0060, iter [03700, 05004], lr: 0.050341, loss: 1.9457
2022-07-13 13:14:34 - train: epoch 0060, iter [03800, 05004], lr: 0.050315, loss: 1.9181
2022-07-13 13:15:07 - train: epoch 0060, iter [03900, 05004], lr: 0.050289, loss: 2.2404
2022-07-13 13:15:40 - train: epoch 0060, iter [04000, 05004], lr: 0.050263, loss: 1.8810
2022-07-13 13:16:13 - train: epoch 0060, iter [04100, 05004], lr: 0.050236, loss: 2.0233
2022-07-13 13:16:46 - train: epoch 0060, iter [04200, 05004], lr: 0.050210, loss: 1.9656
2022-07-13 13:17:19 - train: epoch 0060, iter [04300, 05004], lr: 0.050184, loss: 1.9838
2022-07-13 13:17:53 - train: epoch 0060, iter [04400, 05004], lr: 0.050158, loss: 2.0624
2022-07-13 13:18:25 - train: epoch 0060, iter [04500, 05004], lr: 0.050132, loss: 1.7924
2022-07-13 13:18:59 - train: epoch 0060, iter [04600, 05004], lr: 0.050106, loss: 1.6803
2022-07-13 13:19:32 - train: epoch 0060, iter [04700, 05004], lr: 0.050080, loss: 1.9934
2022-07-13 13:20:05 - train: epoch 0060, iter [04800, 05004], lr: 0.050053, loss: 1.7573
2022-07-13 13:20:40 - train: epoch 0060, iter [04900, 05004], lr: 0.050027, loss: 1.8343
2022-07-13 13:21:12 - train: epoch 0060, iter [05000, 05004], lr: 0.050001, loss: 1.8671
2022-07-13 13:21:12 - train: epoch 060, train_loss: 1.8775
2022-07-13 13:22:28 - eval: epoch: 060, acc1: 60.748%, acc5: 83.782%, test_loss: 1.6360, per_image_load_time: 2.665ms, per_image_inference_time: 0.282ms
2022-07-13 13:22:28 - until epoch: 060, best_acc1: 61.076%
2022-07-13 13:22:28 - epoch 061 lr: 0.050000
2022-07-13 13:23:07 - train: epoch 0061, iter [00100, 05004], lr: 0.049974, loss: 1.6735
2022-07-13 13:23:41 - train: epoch 0061, iter [00200, 05004], lr: 0.049948, loss: 1.8929
2022-07-13 13:24:15 - train: epoch 0061, iter [00300, 05004], lr: 0.049922, loss: 1.6184
2022-07-13 13:24:48 - train: epoch 0061, iter [00400, 05004], lr: 0.049895, loss: 2.1023
2022-07-13 13:25:22 - train: epoch 0061, iter [00500, 05004], lr: 0.049869, loss: 1.8655
2022-07-13 13:25:55 - train: epoch 0061, iter [00600, 05004], lr: 0.049843, loss: 1.8969
2022-07-13 13:26:29 - train: epoch 0061, iter [00700, 05004], lr: 0.049817, loss: 1.6403
2022-07-13 13:27:03 - train: epoch 0061, iter [00800, 05004], lr: 0.049791, loss: 1.9127
2022-07-13 13:27:36 - train: epoch 0061, iter [00900, 05004], lr: 0.049765, loss: 1.7708
2022-07-13 13:28:10 - train: epoch 0061, iter [01000, 05004], lr: 0.049738, loss: 1.6855
2022-07-13 13:28:44 - train: epoch 0061, iter [01100, 05004], lr: 0.049712, loss: 1.6738
2022-07-13 13:29:17 - train: epoch 0061, iter [01200, 05004], lr: 0.049686, loss: 1.7736
2022-07-13 13:29:51 - train: epoch 0061, iter [01300, 05004], lr: 0.049660, loss: 1.7368
2022-07-13 13:30:25 - train: epoch 0061, iter [01400, 05004], lr: 0.049634, loss: 1.8808
2022-07-13 13:30:57 - train: epoch 0061, iter [01500, 05004], lr: 0.049608, loss: 1.9090
2022-07-13 13:31:31 - train: epoch 0061, iter [01600, 05004], lr: 0.049581, loss: 1.6519
2022-07-13 13:32:04 - train: epoch 0061, iter [01700, 05004], lr: 0.049555, loss: 1.8762
2022-07-13 13:32:37 - train: epoch 0061, iter [01800, 05004], lr: 0.049529, loss: 1.9862
2022-07-13 13:33:11 - train: epoch 0061, iter [01900, 05004], lr: 0.049503, loss: 1.9809
2022-07-13 13:33:44 - train: epoch 0061, iter [02000, 05004], lr: 0.049477, loss: 1.8212
2022-07-13 13:34:18 - train: epoch 0061, iter [02100, 05004], lr: 0.049451, loss: 2.2616
2022-07-13 13:34:51 - train: epoch 0061, iter [02200, 05004], lr: 0.049425, loss: 1.7681
2022-07-13 13:35:24 - train: epoch 0061, iter [02300, 05004], lr: 0.049398, loss: 1.7514
2022-07-13 13:35:58 - train: epoch 0061, iter [02400, 05004], lr: 0.049372, loss: 1.6783
2022-07-13 13:36:31 - train: epoch 0061, iter [02500, 05004], lr: 0.049346, loss: 1.7493
2022-07-13 13:37:04 - train: epoch 0061, iter [02600, 05004], lr: 0.049320, loss: 1.8815
2022-07-13 13:37:38 - train: epoch 0061, iter [02700, 05004], lr: 0.049294, loss: 2.0603
2022-07-13 13:38:10 - train: epoch 0061, iter [02800, 05004], lr: 0.049268, loss: 1.8153
2022-07-13 13:38:44 - train: epoch 0061, iter [02900, 05004], lr: 0.049241, loss: 1.9713
2022-07-13 13:39:18 - train: epoch 0061, iter [03000, 05004], lr: 0.049215, loss: 1.8102
2022-07-13 13:39:51 - train: epoch 0061, iter [03100, 05004], lr: 0.049189, loss: 2.0018
2022-07-13 13:40:24 - train: epoch 0061, iter [03200, 05004], lr: 0.049163, loss: 1.8994
2022-07-13 13:40:58 - train: epoch 0061, iter [03300, 05004], lr: 0.049137, loss: 1.8068
2022-07-13 13:41:31 - train: epoch 0061, iter [03400, 05004], lr: 0.049111, loss: 1.6322
2022-07-13 13:42:05 - train: epoch 0061, iter [03500, 05004], lr: 0.049084, loss: 2.0308
2022-07-13 13:42:39 - train: epoch 0061, iter [03600, 05004], lr: 0.049058, loss: 1.9241
2022-07-13 13:43:13 - train: epoch 0061, iter [03700, 05004], lr: 0.049032, loss: 2.0287
2022-07-13 13:43:46 - train: epoch 0061, iter [03800, 05004], lr: 0.049006, loss: 1.8777
2022-07-13 13:44:18 - train: epoch 0061, iter [03900, 05004], lr: 0.048980, loss: 1.8090
2022-07-13 13:44:52 - train: epoch 0061, iter [04000, 05004], lr: 0.048954, loss: 1.9097
2022-07-13 13:45:25 - train: epoch 0061, iter [04100, 05004], lr: 0.048928, loss: 2.1564
2022-07-13 13:45:59 - train: epoch 0061, iter [04200, 05004], lr: 0.048901, loss: 1.8192
2022-07-13 13:46:32 - train: epoch 0061, iter [04300, 05004], lr: 0.048875, loss: 1.9522
2022-07-13 13:47:07 - train: epoch 0061, iter [04400, 05004], lr: 0.048849, loss: 1.9068
2022-07-13 13:47:40 - train: epoch 0061, iter [04500, 05004], lr: 0.048823, loss: 1.8782
2022-07-13 13:48:14 - train: epoch 0061, iter [04600, 05004], lr: 0.048797, loss: 1.9363
2022-07-13 13:48:47 - train: epoch 0061, iter [04700, 05004], lr: 0.048771, loss: 1.9160
2022-07-13 13:49:21 - train: epoch 0061, iter [04800, 05004], lr: 0.048744, loss: 1.8287
2022-07-13 13:49:54 - train: epoch 0061, iter [04900, 05004], lr: 0.048718, loss: 1.8449
2022-07-13 13:50:26 - train: epoch 0061, iter [05000, 05004], lr: 0.048692, loss: 2.0585
2022-07-13 13:50:27 - train: epoch 061, train_loss: 1.8670
2022-07-13 13:51:42 - eval: epoch: 061, acc1: 61.402%, acc5: 84.264%, test_loss: 1.6189, per_image_load_time: 2.581ms, per_image_inference_time: 0.288ms
2022-07-13 13:51:42 - until epoch: 061, best_acc1: 61.402%
2022-07-13 13:51:42 - epoch 062 lr: 0.048691
2022-07-13 13:52:21 - train: epoch 0062, iter [00100, 05004], lr: 0.048665, loss: 1.8482
2022-07-13 13:52:54 - train: epoch 0062, iter [00200, 05004], lr: 0.048639, loss: 2.0260
2022-07-13 13:53:27 - train: epoch 0062, iter [00300, 05004], lr: 0.048613, loss: 1.8289
2022-07-13 13:54:01 - train: epoch 0062, iter [00400, 05004], lr: 0.048587, loss: 1.7134
2022-07-13 13:54:34 - train: epoch 0062, iter [00500, 05004], lr: 0.048560, loss: 1.8122
2022-07-13 13:55:08 - train: epoch 0062, iter [00600, 05004], lr: 0.048534, loss: 1.6876
2022-07-13 13:55:40 - train: epoch 0062, iter [00700, 05004], lr: 0.048508, loss: 1.9592
2022-07-13 13:56:14 - train: epoch 0062, iter [00800, 05004], lr: 0.048482, loss: 1.7563
2022-07-13 13:56:47 - train: epoch 0062, iter [00900, 05004], lr: 0.048456, loss: 1.7911
2022-07-13 13:57:21 - train: epoch 0062, iter [01000, 05004], lr: 0.048430, loss: 1.9045
2022-07-13 13:57:54 - train: epoch 0062, iter [01100, 05004], lr: 0.048404, loss: 1.7414
2022-07-13 13:58:28 - train: epoch 0062, iter [01200, 05004], lr: 0.048377, loss: 2.0918
2022-07-13 13:59:01 - train: epoch 0062, iter [01300, 05004], lr: 0.048351, loss: 1.9443
2022-07-13 13:59:35 - train: epoch 0062, iter [01400, 05004], lr: 0.048325, loss: 1.6923
2022-07-13 14:00:07 - train: epoch 0062, iter [01500, 05004], lr: 0.048299, loss: 1.9151
2022-07-13 14:00:41 - train: epoch 0062, iter [01600, 05004], lr: 0.048273, loss: 1.9654
2022-07-13 14:01:14 - train: epoch 0062, iter [01700, 05004], lr: 0.048247, loss: 1.8860
2022-07-13 14:01:48 - train: epoch 0062, iter [01800, 05004], lr: 0.048221, loss: 1.6837
2022-07-13 14:02:21 - train: epoch 0062, iter [01900, 05004], lr: 0.048194, loss: 1.8998
2022-07-13 14:02:55 - train: epoch 0062, iter [02000, 05004], lr: 0.048168, loss: 1.7721
2022-07-13 14:03:28 - train: epoch 0062, iter [02100, 05004], lr: 0.048142, loss: 1.8626
2022-07-13 14:04:01 - train: epoch 0062, iter [02200, 05004], lr: 0.048116, loss: 1.7395
2022-07-13 14:04:35 - train: epoch 0062, iter [02300, 05004], lr: 0.048090, loss: 1.8563
2022-07-13 14:05:09 - train: epoch 0062, iter [02400, 05004], lr: 0.048064, loss: 1.9105
2022-07-13 14:05:42 - train: epoch 0062, iter [02500, 05004], lr: 0.048038, loss: 2.0582
2022-07-13 14:06:15 - train: epoch 0062, iter [02600, 05004], lr: 0.048011, loss: 1.7525
2022-07-13 14:06:48 - train: epoch 0062, iter [02700, 05004], lr: 0.047985, loss: 1.8584
2022-07-13 14:07:22 - train: epoch 0062, iter [02800, 05004], lr: 0.047959, loss: 1.9857
2022-07-13 14:07:55 - train: epoch 0062, iter [02900, 05004], lr: 0.047933, loss: 1.8264
2022-07-13 14:08:29 - train: epoch 0062, iter [03000, 05004], lr: 0.047907, loss: 2.0522
2022-07-13 14:09:02 - train: epoch 0062, iter [03100, 05004], lr: 0.047881, loss: 2.0205
2022-07-13 14:09:35 - train: epoch 0062, iter [03200, 05004], lr: 0.047855, loss: 1.6207
2022-07-13 14:10:09 - train: epoch 0062, iter [03300, 05004], lr: 0.047828, loss: 2.0044
2022-07-13 14:10:42 - train: epoch 0062, iter [03400, 05004], lr: 0.047802, loss: 1.8589
2022-07-13 14:11:16 - train: epoch 0062, iter [03500, 05004], lr: 0.047776, loss: 1.8902
2022-07-13 14:11:49 - train: epoch 0062, iter [03600, 05004], lr: 0.047750, loss: 1.8437
2022-07-13 14:12:23 - train: epoch 0062, iter [03700, 05004], lr: 0.047724, loss: 1.8540
2022-07-13 14:12:57 - train: epoch 0062, iter [03800, 05004], lr: 0.047698, loss: 1.8830
2022-07-13 14:13:30 - train: epoch 0062, iter [03900, 05004], lr: 0.047672, loss: 1.8740
2022-07-13 14:14:03 - train: epoch 0062, iter [04000, 05004], lr: 0.047646, loss: 1.6006
2022-07-13 14:14:37 - train: epoch 0062, iter [04100, 05004], lr: 0.047619, loss: 2.0436
2022-07-13 14:15:10 - train: epoch 0062, iter [04200, 05004], lr: 0.047593, loss: 1.7156
2022-07-13 14:15:43 - train: epoch 0062, iter [04300, 05004], lr: 0.047567, loss: 1.9307
2022-07-13 14:16:16 - train: epoch 0062, iter [04400, 05004], lr: 0.047541, loss: 1.9338
2022-07-13 14:16:50 - train: epoch 0062, iter [04500, 05004], lr: 0.047515, loss: 1.7207
2022-07-13 14:17:23 - train: epoch 0062, iter [04600, 05004], lr: 0.047489, loss: 1.5405
2022-07-13 14:17:56 - train: epoch 0062, iter [04700, 05004], lr: 0.047463, loss: 1.8028
2022-07-13 14:18:30 - train: epoch 0062, iter [04800, 05004], lr: 0.047436, loss: 1.8876
2022-07-13 14:19:04 - train: epoch 0062, iter [04900, 05004], lr: 0.047410, loss: 1.7744
2022-07-13 14:19:36 - train: epoch 0062, iter [05000, 05004], lr: 0.047384, loss: 1.9476
2022-07-13 14:19:37 - train: epoch 062, train_loss: 1.8540
2022-07-13 14:20:52 - eval: epoch: 062, acc1: 60.994%, acc5: 83.854%, test_loss: 1.6368, per_image_load_time: 1.862ms, per_image_inference_time: 0.298ms
2022-07-13 14:20:52 - until epoch: 062, best_acc1: 61.402%
2022-07-13 14:20:52 - epoch 063 lr: 0.047383
2022-07-13 14:21:31 - train: epoch 0063, iter [00100, 05004], lr: 0.047357, loss: 1.7921
2022-07-13 14:22:05 - train: epoch 0063, iter [00200, 05004], lr: 0.047331, loss: 1.7753
2022-07-13 14:22:38 - train: epoch 0063, iter [00300, 05004], lr: 0.047305, loss: 1.9612
2022-07-13 14:23:12 - train: epoch 0063, iter [00400, 05004], lr: 0.047279, loss: 1.8948
2022-07-13 14:23:45 - train: epoch 0063, iter [00500, 05004], lr: 0.047253, loss: 1.6980
2022-07-13 14:24:18 - train: epoch 0063, iter [00600, 05004], lr: 0.047226, loss: 1.9134
2022-07-13 14:24:51 - train: epoch 0063, iter [00700, 05004], lr: 0.047200, loss: 1.7554
2022-07-13 14:25:24 - train: epoch 0063, iter [00800, 05004], lr: 0.047174, loss: 1.8052
2022-07-13 14:25:57 - train: epoch 0063, iter [00900, 05004], lr: 0.047148, loss: 1.7726
2022-07-13 14:26:31 - train: epoch 0063, iter [01000, 05004], lr: 0.047122, loss: 2.0076
2022-07-13 14:27:03 - train: epoch 0063, iter [01100, 05004], lr: 0.047096, loss: 1.8126
2022-07-13 14:27:36 - train: epoch 0063, iter [01200, 05004], lr: 0.047070, loss: 1.8113
2022-07-13 14:28:10 - train: epoch 0063, iter [01300, 05004], lr: 0.047044, loss: 1.8412
2022-07-13 14:28:44 - train: epoch 0063, iter [01400, 05004], lr: 0.047018, loss: 2.2147
2022-07-13 14:29:18 - train: epoch 0063, iter [01500, 05004], lr: 0.046991, loss: 1.7852
2022-07-13 14:29:50 - train: epoch 0063, iter [01600, 05004], lr: 0.046965, loss: 1.7537
2022-07-13 14:30:23 - train: epoch 0063, iter [01700, 05004], lr: 0.046939, loss: 1.6709
2022-07-13 14:30:56 - train: epoch 0063, iter [01800, 05004], lr: 0.046913, loss: 2.0365
2022-07-13 14:31:30 - train: epoch 0063, iter [01900, 05004], lr: 0.046887, loss: 2.0073
2022-07-13 14:32:04 - train: epoch 0063, iter [02000, 05004], lr: 0.046861, loss: 1.7744
2022-07-13 14:32:37 - train: epoch 0063, iter [02100, 05004], lr: 0.046835, loss: 1.7660
2022-07-13 14:33:11 - train: epoch 0063, iter [02200, 05004], lr: 0.046809, loss: 2.1964
2022-07-13 14:33:45 - train: epoch 0063, iter [02300, 05004], lr: 0.046783, loss: 1.8968
2022-07-13 14:34:19 - train: epoch 0063, iter [02400, 05004], lr: 0.046756, loss: 2.1010
2022-07-13 14:34:53 - train: epoch 0063, iter [02500, 05004], lr: 0.046730, loss: 1.8209
2022-07-13 14:35:26 - train: epoch 0063, iter [02600, 05004], lr: 0.046704, loss: 1.7586
2022-07-13 14:36:00 - train: epoch 0063, iter [02700, 05004], lr: 0.046678, loss: 1.9714
2022-07-13 14:36:34 - train: epoch 0063, iter [02800, 05004], lr: 0.046652, loss: 1.8654
2022-07-13 14:37:07 - train: epoch 0063, iter [02900, 05004], lr: 0.046626, loss: 1.7781
2022-07-13 14:37:40 - train: epoch 0063, iter [03000, 05004], lr: 0.046600, loss: 2.0240
2022-07-13 14:38:14 - train: epoch 0063, iter [03100, 05004], lr: 0.046574, loss: 2.3439
2022-07-13 14:38:46 - train: epoch 0063, iter [03200, 05004], lr: 0.046548, loss: 1.9244
2022-07-13 14:39:21 - train: epoch 0063, iter [03300, 05004], lr: 0.046522, loss: 1.7021
2022-07-13 14:39:55 - train: epoch 0063, iter [03400, 05004], lr: 0.046495, loss: 1.6476
2022-07-13 14:40:29 - train: epoch 0063, iter [03500, 05004], lr: 0.046469, loss: 2.0167
2022-07-13 14:41:01 - train: epoch 0063, iter [03600, 05004], lr: 0.046443, loss: 1.7071
2022-07-13 14:41:35 - train: epoch 0063, iter [03700, 05004], lr: 0.046417, loss: 1.9692
2022-07-13 14:42:09 - train: epoch 0063, iter [03800, 05004], lr: 0.046391, loss: 2.0079
2022-07-13 14:42:42 - train: epoch 0063, iter [03900, 05004], lr: 0.046365, loss: 1.5655
2022-07-13 14:43:16 - train: epoch 0063, iter [04000, 05004], lr: 0.046339, loss: 1.6030
2022-07-13 14:43:49 - train: epoch 0063, iter [04100, 05004], lr: 0.046313, loss: 1.9803
2022-07-13 14:44:23 - train: epoch 0063, iter [04200, 05004], lr: 0.046287, loss: 1.6899
2022-07-13 14:44:57 - train: epoch 0063, iter [04300, 05004], lr: 0.046261, loss: 1.9901
2022-07-13 14:45:30 - train: epoch 0063, iter [04400, 05004], lr: 0.046235, loss: 1.8643
2022-07-13 14:46:04 - train: epoch 0063, iter [04500, 05004], lr: 0.046208, loss: 1.6454
2022-07-13 14:46:37 - train: epoch 0063, iter [04600, 05004], lr: 0.046182, loss: 1.8226
2022-07-13 14:47:10 - train: epoch 0063, iter [04700, 05004], lr: 0.046156, loss: 1.7361
2022-07-13 14:47:44 - train: epoch 0063, iter [04800, 05004], lr: 0.046130, loss: 1.8814
2022-07-13 14:48:17 - train: epoch 0063, iter [04900, 05004], lr: 0.046104, loss: 1.8026
2022-07-13 14:48:49 - train: epoch 0063, iter [05000, 05004], lr: 0.046078, loss: 1.8465
2022-07-13 14:48:50 - train: epoch 063, train_loss: 1.8450
2022-07-13 14:50:06 - eval: epoch: 063, acc1: 61.562%, acc5: 84.118%, test_loss: 1.6257, per_image_load_time: 2.535ms, per_image_inference_time: 0.287ms
2022-07-13 14:50:06 - until epoch: 063, best_acc1: 61.562%
2022-07-13 14:50:06 - epoch 064 lr: 0.046077
2022-07-13 14:50:45 - train: epoch 0064, iter [00100, 05004], lr: 0.046051, loss: 1.7741
2022-07-13 14:51:19 - train: epoch 0064, iter [00200, 05004], lr: 0.046025, loss: 1.8203
2022-07-13 14:51:53 - train: epoch 0064, iter [00300, 05004], lr: 0.045999, loss: 1.6239
2022-07-13 14:52:27 - train: epoch 0064, iter [00400, 05004], lr: 0.045973, loss: 1.8589
2022-07-13 14:53:00 - train: epoch 0064, iter [00500, 05004], lr: 0.045947, loss: 1.6940
2022-07-13 14:53:34 - train: epoch 0064, iter [00600, 05004], lr: 0.045921, loss: 2.0591
2022-07-13 14:54:08 - train: epoch 0064, iter [00700, 05004], lr: 0.045895, loss: 1.9288
2022-07-13 14:54:41 - train: epoch 0064, iter [00800, 05004], lr: 0.045868, loss: 1.6570
2022-07-13 14:55:16 - train: epoch 0064, iter [00900, 05004], lr: 0.045842, loss: 1.8462
2022-07-13 14:55:49 - train: epoch 0064, iter [01000, 05004], lr: 0.045816, loss: 1.6365
2022-07-13 14:56:22 - train: epoch 0064, iter [01100, 05004], lr: 0.045790, loss: 1.7948
2022-07-13 14:56:57 - train: epoch 0064, iter [01200, 05004], lr: 0.045764, loss: 1.7403
2022-07-13 14:57:31 - train: epoch 0064, iter [01300, 05004], lr: 0.045738, loss: 1.7952
2022-07-13 14:58:05 - train: epoch 0064, iter [01400, 05004], lr: 0.045712, loss: 2.0502
2022-07-13 14:58:38 - train: epoch 0064, iter [01500, 05004], lr: 0.045686, loss: 1.9275
2022-07-13 14:59:12 - train: epoch 0064, iter [01600, 05004], lr: 0.045660, loss: 1.7701
2022-07-13 14:59:47 - train: epoch 0064, iter [01700, 05004], lr: 0.045634, loss: 1.6113
2022-07-13 15:00:20 - train: epoch 0064, iter [01800, 05004], lr: 0.045608, loss: 1.6993
2022-07-13 15:00:54 - train: epoch 0064, iter [01900, 05004], lr: 0.045582, loss: 1.8262
2022-07-13 15:01:28 - train: epoch 0064, iter [02000, 05004], lr: 0.045556, loss: 1.6956
2022-07-13 15:02:03 - train: epoch 0064, iter [02100, 05004], lr: 0.045530, loss: 1.8254
2022-07-13 15:02:36 - train: epoch 0064, iter [02200, 05004], lr: 0.045504, loss: 1.9825
2022-07-13 15:03:10 - train: epoch 0064, iter [02300, 05004], lr: 0.045478, loss: 1.8223
2022-07-13 15:03:44 - train: epoch 0064, iter [02400, 05004], lr: 0.045451, loss: 1.8094
2022-07-13 15:04:18 - train: epoch 0064, iter [02500, 05004], lr: 0.045425, loss: 1.7330
2022-07-13 15:04:51 - train: epoch 0064, iter [02600, 05004], lr: 0.045399, loss: 1.8631
2022-07-13 15:05:26 - train: epoch 0064, iter [02700, 05004], lr: 0.045373, loss: 1.7436
2022-07-13 15:06:00 - train: epoch 0064, iter [02800, 05004], lr: 0.045347, loss: 1.6577
2022-07-13 15:06:34 - train: epoch 0064, iter [02900, 05004], lr: 0.045321, loss: 2.1018
2022-07-13 15:07:08 - train: epoch 0064, iter [03000, 05004], lr: 0.045295, loss: 1.9358
2022-07-13 15:07:41 - train: epoch 0064, iter [03100, 05004], lr: 0.045269, loss: 1.8095
2022-07-13 15:08:16 - train: epoch 0064, iter [03200, 05004], lr: 0.045243, loss: 1.8655
2022-07-13 15:08:49 - train: epoch 0064, iter [03300, 05004], lr: 0.045217, loss: 1.7538
2022-07-13 15:09:24 - train: epoch 0064, iter [03400, 05004], lr: 0.045191, loss: 1.9822
2022-07-13 15:09:57 - train: epoch 0064, iter [03500, 05004], lr: 0.045165, loss: 1.7028
2022-07-13 15:10:32 - train: epoch 0064, iter [03600, 05004], lr: 0.045139, loss: 1.8636
2022-07-13 15:11:06 - train: epoch 0064, iter [03700, 05004], lr: 0.045113, loss: 1.4675
2022-07-13 15:11:40 - train: epoch 0064, iter [03800, 05004], lr: 0.045087, loss: 2.0707
2022-07-13 15:12:13 - train: epoch 0064, iter [03900, 05004], lr: 0.045061, loss: 1.8399
2022-07-13 15:12:47 - train: epoch 0064, iter [04000, 05004], lr: 0.045035, loss: 1.7789
2022-07-13 15:13:21 - train: epoch 0064, iter [04100, 05004], lr: 0.045009, loss: 1.8574
2022-07-13 15:13:55 - train: epoch 0064, iter [04200, 05004], lr: 0.044983, loss: 1.6720
2022-07-13 15:14:29 - train: epoch 0064, iter [04300, 05004], lr: 0.044957, loss: 1.9706
2022-07-13 15:15:03 - train: epoch 0064, iter [04400, 05004], lr: 0.044931, loss: 1.7564
2022-07-13 15:15:36 - train: epoch 0064, iter [04500, 05004], lr: 0.044905, loss: 1.6804
2022-07-13 15:16:10 - train: epoch 0064, iter [04600, 05004], lr: 0.044879, loss: 2.0664
2022-07-13 15:16:45 - train: epoch 0064, iter [04700, 05004], lr: 0.044853, loss: 2.1937
2022-07-13 15:17:18 - train: epoch 0064, iter [04800, 05004], lr: 0.044827, loss: 1.8925
2022-07-13 15:17:52 - train: epoch 0064, iter [04900, 05004], lr: 0.044801, loss: 2.0463
2022-07-13 15:18:25 - train: epoch 0064, iter [05000, 05004], lr: 0.044775, loss: 1.7139
2022-07-13 15:18:26 - train: epoch 064, train_loss: 1.8341
2022-07-13 15:19:42 - eval: epoch: 064, acc1: 61.766%, acc5: 84.656%, test_loss: 1.5942, per_image_load_time: 2.663ms, per_image_inference_time: 0.282ms
2022-07-13 15:19:42 - until epoch: 064, best_acc1: 61.766%
2022-07-13 15:19:42 - epoch 065 lr: 0.044773
2022-07-13 15:20:21 - train: epoch 0065, iter [00100, 05004], lr: 0.044748, loss: 1.8903
2022-07-13 15:20:55 - train: epoch 0065, iter [00200, 05004], lr: 0.044722, loss: 1.8214
2022-07-13 15:21:29 - train: epoch 0065, iter [00300, 05004], lr: 0.044696, loss: 1.8222
2022-07-13 15:22:01 - train: epoch 0065, iter [00400, 05004], lr: 0.044670, loss: 1.9257
2022-07-13 15:22:35 - train: epoch 0065, iter [00500, 05004], lr: 0.044644, loss: 1.7474
2022-07-13 15:23:10 - train: epoch 0065, iter [00600, 05004], lr: 0.044618, loss: 1.9457
2022-07-13 15:23:44 - train: epoch 0065, iter [00700, 05004], lr: 0.044592, loss: 1.8986
2022-07-13 15:24:17 - train: epoch 0065, iter [00800, 05004], lr: 0.044565, loss: 1.7359
2022-07-13 15:24:51 - train: epoch 0065, iter [00900, 05004], lr: 0.044539, loss: 1.6881
2022-07-13 15:25:25 - train: epoch 0065, iter [01000, 05004], lr: 0.044513, loss: 1.7901
2022-07-13 15:25:59 - train: epoch 0065, iter [01100, 05004], lr: 0.044487, loss: 1.7044
2022-07-13 15:26:33 - train: epoch 0065, iter [01200, 05004], lr: 0.044461, loss: 2.0970
2022-07-13 15:27:06 - train: epoch 0065, iter [01300, 05004], lr: 0.044435, loss: 1.8350
2022-07-13 15:27:40 - train: epoch 0065, iter [01400, 05004], lr: 0.044410, loss: 1.5895
2022-07-13 15:28:14 - train: epoch 0065, iter [01500, 05004], lr: 0.044384, loss: 1.7927
2022-07-13 15:28:49 - train: epoch 0065, iter [01600, 05004], lr: 0.044358, loss: 1.8870
2022-07-13 15:29:22 - train: epoch 0065, iter [01700, 05004], lr: 0.044332, loss: 1.7583
2022-07-13 15:29:56 - train: epoch 0065, iter [01800, 05004], lr: 0.044306, loss: 1.5848
2022-07-13 15:30:30 - train: epoch 0065, iter [01900, 05004], lr: 0.044280, loss: 1.5807
2022-07-13 15:31:04 - train: epoch 0065, iter [02000, 05004], lr: 0.044254, loss: 1.8325
2022-07-13 15:31:38 - train: epoch 0065, iter [02100, 05004], lr: 0.044228, loss: 1.7191
2022-07-13 15:32:13 - train: epoch 0065, iter [02200, 05004], lr: 0.044202, loss: 1.7936
2022-07-13 15:32:47 - train: epoch 0065, iter [02300, 05004], lr: 0.044176, loss: 1.7040
2022-07-13 15:33:21 - train: epoch 0065, iter [02400, 05004], lr: 0.044150, loss: 1.7307
2022-07-13 15:33:55 - train: epoch 0065, iter [02500, 05004], lr: 0.044124, loss: 1.7506
2022-07-13 15:34:30 - train: epoch 0065, iter [02600, 05004], lr: 0.044098, loss: 2.0226
2022-07-13 15:35:03 - train: epoch 0065, iter [02700, 05004], lr: 0.044072, loss: 1.8651
2022-07-13 15:35:37 - train: epoch 0065, iter [02800, 05004], lr: 0.044046, loss: 1.7416
2022-07-13 15:36:12 - train: epoch 0065, iter [02900, 05004], lr: 0.044020, loss: 1.8872
2022-07-13 15:36:46 - train: epoch 0065, iter [03000, 05004], lr: 0.043994, loss: 1.6959
2022-07-13 15:37:20 - train: epoch 0065, iter [03100, 05004], lr: 0.043968, loss: 1.8220
2022-07-13 15:37:54 - train: epoch 0065, iter [03200, 05004], lr: 0.043942, loss: 1.9246
2022-07-13 15:38:29 - train: epoch 0065, iter [03300, 05004], lr: 0.043916, loss: 1.7498
2022-07-13 15:39:03 - train: epoch 0065, iter [03400, 05004], lr: 0.043890, loss: 1.8097
2022-07-13 15:39:37 - train: epoch 0065, iter [03500, 05004], lr: 0.043864, loss: 2.0601
2022-07-13 15:40:11 - train: epoch 0065, iter [03600, 05004], lr: 0.043838, loss: 1.9232
2022-07-13 15:40:45 - train: epoch 0065, iter [03700, 05004], lr: 0.043812, loss: 1.7774
2022-07-13 15:41:19 - train: epoch 0065, iter [03800, 05004], lr: 0.043786, loss: 1.7006
2022-07-13 15:41:53 - train: epoch 0065, iter [03900, 05004], lr: 0.043760, loss: 1.9284
2022-07-13 15:42:28 - train: epoch 0065, iter [04000, 05004], lr: 0.043734, loss: 1.9009
2022-07-13 15:43:01 - train: epoch 0065, iter [04100, 05004], lr: 0.043708, loss: 1.6551
2022-07-13 15:43:36 - train: epoch 0065, iter [04200, 05004], lr: 0.043682, loss: 1.8537
2022-07-13 15:44:11 - train: epoch 0065, iter [04300, 05004], lr: 0.043656, loss: 1.8070
2022-07-13 15:44:45 - train: epoch 0065, iter [04400, 05004], lr: 0.043630, loss: 1.9359
2022-07-13 15:45:19 - train: epoch 0065, iter [04500, 05004], lr: 0.043604, loss: 1.8561
2022-07-13 15:45:53 - train: epoch 0065, iter [04600, 05004], lr: 0.043578, loss: 1.8570
2022-07-13 15:46:28 - train: epoch 0065, iter [04700, 05004], lr: 0.043553, loss: 1.8446
2022-07-13 15:47:02 - train: epoch 0065, iter [04800, 05004], lr: 0.043527, loss: 1.5330
2022-07-13 15:47:36 - train: epoch 0065, iter [04900, 05004], lr: 0.043501, loss: 1.8950
2022-07-13 15:48:09 - train: epoch 0065, iter [05000, 05004], lr: 0.043475, loss: 1.8966
2022-07-13 15:48:10 - train: epoch 065, train_loss: 1.8226
2022-07-13 15:49:26 - eval: epoch: 065, acc1: 62.186%, acc5: 84.590%, test_loss: 1.5914, per_image_load_time: 2.687ms, per_image_inference_time: 0.286ms
2022-07-13 15:49:26 - until epoch: 065, best_acc1: 62.186%
2022-07-13 15:49:26 - epoch 066 lr: 0.043473
2022-07-13 15:50:06 - train: epoch 0066, iter [00100, 05004], lr: 0.043448, loss: 1.6777
2022-07-13 15:50:39 - train: epoch 0066, iter [00200, 05004], lr: 0.043422, loss: 1.9035
2022-07-13 15:51:13 - train: epoch 0066, iter [00300, 05004], lr: 0.043396, loss: 1.7130
2022-07-13 15:51:47 - train: epoch 0066, iter [00400, 05004], lr: 0.043370, loss: 1.5826
2022-07-13 15:52:21 - train: epoch 0066, iter [00500, 05004], lr: 0.043344, loss: 1.9082
2022-07-13 15:52:55 - train: epoch 0066, iter [00600, 05004], lr: 0.043318, loss: 1.7970
2022-07-13 15:53:29 - train: epoch 0066, iter [00700, 05004], lr: 0.043292, loss: 1.7009
2022-07-13 15:54:03 - train: epoch 0066, iter [00800, 05004], lr: 0.043266, loss: 2.2675
2022-07-13 15:54:37 - train: epoch 0066, iter [00900, 05004], lr: 0.043240, loss: 1.9107
2022-07-13 15:55:11 - train: epoch 0066, iter [01000, 05004], lr: 0.043214, loss: 1.9428
2022-07-13 15:55:44 - train: epoch 0066, iter [01100, 05004], lr: 0.043189, loss: 1.9188
2022-07-13 15:56:19 - train: epoch 0066, iter [01200, 05004], lr: 0.043163, loss: 1.9442
2022-07-13 15:56:54 - train: epoch 0066, iter [01300, 05004], lr: 0.043137, loss: 1.9933
2022-07-13 15:57:28 - train: epoch 0066, iter [01400, 05004], lr: 0.043111, loss: 1.6626
2022-07-13 15:58:01 - train: epoch 0066, iter [01500, 05004], lr: 0.043085, loss: 1.8711
2022-07-13 15:58:35 - train: epoch 0066, iter [01600, 05004], lr: 0.043059, loss: 1.8733
2022-07-13 15:59:09 - train: epoch 0066, iter [01700, 05004], lr: 0.043033, loss: 1.7302
2022-07-13 15:59:44 - train: epoch 0066, iter [01800, 05004], lr: 0.043007, loss: 1.6087
2022-07-13 16:00:18 - train: epoch 0066, iter [01900, 05004], lr: 0.042981, loss: 2.0694
2022-07-13 16:00:52 - train: epoch 0066, iter [02000, 05004], lr: 0.042955, loss: 1.8573
2022-07-13 16:01:26 - train: epoch 0066, iter [02100, 05004], lr: 0.042929, loss: 1.8872
2022-07-13 16:01:59 - train: epoch 0066, iter [02200, 05004], lr: 0.042904, loss: 1.7540
2022-07-13 16:02:34 - train: epoch 0066, iter [02300, 05004], lr: 0.042878, loss: 2.0210
2022-07-13 16:03:08 - train: epoch 0066, iter [02400, 05004], lr: 0.042852, loss: 1.6712
2022-07-13 16:03:43 - train: epoch 0066, iter [02500, 05004], lr: 0.042826, loss: 1.8292
2022-07-13 16:04:16 - train: epoch 0066, iter [02600, 05004], lr: 0.042800, loss: 1.7016
2022-07-13 16:04:50 - train: epoch 0066, iter [02700, 05004], lr: 0.042774, loss: 2.0888
2022-07-13 16:05:24 - train: epoch 0066, iter [02800, 05004], lr: 0.042748, loss: 1.8477
2022-07-13 16:05:59 - train: epoch 0066, iter [02900, 05004], lr: 0.042722, loss: 1.8450
2022-07-13 16:06:32 - train: epoch 0066, iter [03000, 05004], lr: 0.042696, loss: 1.7340
2022-07-13 16:07:06 - train: epoch 0066, iter [03100, 05004], lr: 0.042671, loss: 1.8632
2022-07-13 16:07:40 - train: epoch 0066, iter [03200, 05004], lr: 0.042645, loss: 1.6539
2022-07-13 16:08:15 - train: epoch 0066, iter [03300, 05004], lr: 0.042619, loss: 1.7745
2022-07-13 16:08:48 - train: epoch 0066, iter [03400, 05004], lr: 0.042593, loss: 2.1244
2022-07-13 16:09:22 - train: epoch 0066, iter [03500, 05004], lr: 0.042567, loss: 1.8175
2022-07-13 16:09:56 - train: epoch 0066, iter [03600, 05004], lr: 0.042541, loss: 1.9411
2022-07-13 16:10:30 - train: epoch 0066, iter [03700, 05004], lr: 0.042515, loss: 1.7546
2022-07-13 16:11:04 - train: epoch 0066, iter [03800, 05004], lr: 0.042490, loss: 1.6026
2022-07-13 16:11:38 - train: epoch 0066, iter [03900, 05004], lr: 0.042464, loss: 1.6030
2022-07-13 16:12:12 - train: epoch 0066, iter [04000, 05004], lr: 0.042438, loss: 1.8909
2022-07-13 16:12:46 - train: epoch 0066, iter [04100, 05004], lr: 0.042412, loss: 1.6264
2022-07-13 16:13:20 - train: epoch 0066, iter [04200, 05004], lr: 0.042386, loss: 1.5730
2022-07-13 16:13:54 - train: epoch 0066, iter [04300, 05004], lr: 0.042360, loss: 1.6466
2022-07-13 16:14:27 - train: epoch 0066, iter [04400, 05004], lr: 0.042334, loss: 1.7248
2022-07-13 16:15:01 - train: epoch 0066, iter [04500, 05004], lr: 0.042309, loss: 1.9255
2022-07-13 16:15:36 - train: epoch 0066, iter [04600, 05004], lr: 0.042283, loss: 1.9823
2022-07-13 16:16:11 - train: epoch 0066, iter [04700, 05004], lr: 0.042257, loss: 1.7043
2022-07-13 16:16:44 - train: epoch 0066, iter [04800, 05004], lr: 0.042231, loss: 1.7805
2022-07-13 16:17:19 - train: epoch 0066, iter [04900, 05004], lr: 0.042205, loss: 1.8633
2022-07-13 16:17:51 - train: epoch 0066, iter [05000, 05004], lr: 0.042179, loss: 1.7229
2022-07-13 16:17:52 - train: epoch 066, train_loss: 1.8118
2022-07-13 16:19:07 - eval: epoch: 066, acc1: 62.666%, acc5: 85.226%, test_loss: 1.5527, per_image_load_time: 2.655ms, per_image_inference_time: 0.273ms
2022-07-13 16:19:08 - until epoch: 066, best_acc1: 62.666%
2022-07-13 16:19:08 - epoch 067 lr: 0.042178
2022-07-13 16:19:48 - train: epoch 0067, iter [00100, 05004], lr: 0.042152, loss: 1.7212
2022-07-13 16:20:21 - train: epoch 0067, iter [00200, 05004], lr: 0.042127, loss: 1.6708
2022-07-13 16:20:54 - train: epoch 0067, iter [00300, 05004], lr: 0.042101, loss: 2.0120
2022-07-13 16:21:27 - train: epoch 0067, iter [00400, 05004], lr: 0.042075, loss: 1.7391
2022-07-13 16:22:00 - train: epoch 0067, iter [00500, 05004], lr: 0.042049, loss: 1.6856
2022-07-13 16:22:33 - train: epoch 0067, iter [00600, 05004], lr: 0.042023, loss: 1.7427
2022-07-13 16:23:07 - train: epoch 0067, iter [00700, 05004], lr: 0.041997, loss: 1.8220
2022-07-13 16:23:40 - train: epoch 0067, iter [00800, 05004], lr: 0.041972, loss: 1.9243
2022-07-13 16:24:14 - train: epoch 0067, iter [00900, 05004], lr: 0.041946, loss: 2.0135
2022-07-13 16:24:47 - train: epoch 0067, iter [01000, 05004], lr: 0.041920, loss: 1.6598
2022-07-13 16:25:21 - train: epoch 0067, iter [01100, 05004], lr: 0.041894, loss: 1.8247
2022-07-13 16:25:53 - train: epoch 0067, iter [01200, 05004], lr: 0.041868, loss: 1.7305
2022-07-13 16:26:28 - train: epoch 0067, iter [01300, 05004], lr: 0.041843, loss: 1.9496
2022-07-13 16:27:01 - train: epoch 0067, iter [01400, 05004], lr: 0.041817, loss: 1.7999
2022-07-13 16:27:35 - train: epoch 0067, iter [01500, 05004], lr: 0.041791, loss: 1.7806
2022-07-13 16:28:07 - train: epoch 0067, iter [01600, 05004], lr: 0.041765, loss: 1.7233
2022-07-13 16:28:41 - train: epoch 0067, iter [01700, 05004], lr: 0.041739, loss: 1.6553
2022-07-13 16:29:14 - train: epoch 0067, iter [01800, 05004], lr: 0.041714, loss: 1.9485
2022-07-13 16:29:48 - train: epoch 0067, iter [01900, 05004], lr: 0.041688, loss: 1.7885
2022-07-13 16:30:20 - train: epoch 0067, iter [02000, 05004], lr: 0.041662, loss: 1.8089
2022-07-13 16:30:55 - train: epoch 0067, iter [02100, 05004], lr: 0.041636, loss: 1.5712
2022-07-13 16:31:27 - train: epoch 0067, iter [02200, 05004], lr: 0.041610, loss: 1.7864
2022-07-13 16:32:01 - train: epoch 0067, iter [02300, 05004], lr: 0.041585, loss: 1.7762
2022-07-13 16:32:33 - train: epoch 0067, iter [02400, 05004], lr: 0.041559, loss: 1.8062
2022-07-13 16:33:07 - train: epoch 0067, iter [02500, 05004], lr: 0.041533, loss: 1.7274
2022-07-13 16:33:39 - train: epoch 0067, iter [02600, 05004], lr: 0.041507, loss: 1.7567
2022-07-13 16:34:13 - train: epoch 0067, iter [02700, 05004], lr: 0.041481, loss: 1.7136
2022-07-13 16:34:46 - train: epoch 0067, iter [02800, 05004], lr: 0.041456, loss: 1.8856
2022-07-13 16:35:18 - train: epoch 0067, iter [02900, 05004], lr: 0.041430, loss: 1.7215
2022-07-13 16:35:51 - train: epoch 0067, iter [03000, 05004], lr: 0.041404, loss: 1.7493
2022-07-13 16:36:24 - train: epoch 0067, iter [03100, 05004], lr: 0.041378, loss: 1.6268
2022-07-13 16:36:57 - train: epoch 0067, iter [03200, 05004], lr: 0.041353, loss: 1.8863
2022-07-13 16:37:30 - train: epoch 0067, iter [03300, 05004], lr: 0.041327, loss: 1.5970
2022-07-13 16:38:02 - train: epoch 0067, iter [03400, 05004], lr: 0.041301, loss: 1.7538
2022-07-13 16:38:37 - train: epoch 0067, iter [03500, 05004], lr: 0.041275, loss: 1.7313
2022-07-13 16:39:09 - train: epoch 0067, iter [03600, 05004], lr: 0.041250, loss: 1.8589
2022-07-13 16:39:43 - train: epoch 0067, iter [03700, 05004], lr: 0.041224, loss: 1.9690
2022-07-13 16:40:15 - train: epoch 0067, iter [03800, 05004], lr: 0.041198, loss: 1.7594
2022-07-13 16:40:49 - train: epoch 0067, iter [03900, 05004], lr: 0.041172, loss: 1.9288
2022-07-13 16:41:21 - train: epoch 0067, iter [04000, 05004], lr: 0.041147, loss: 1.8570
2022-07-13 16:41:54 - train: epoch 0067, iter [04100, 05004], lr: 0.041121, loss: 1.8422
2022-07-13 16:42:26 - train: epoch 0067, iter [04200, 05004], lr: 0.041095, loss: 2.1037
2022-07-13 16:42:59 - train: epoch 0067, iter [04300, 05004], lr: 0.041069, loss: 1.6393
2022-07-13 16:43:31 - train: epoch 0067, iter [04400, 05004], lr: 0.041044, loss: 1.9220
2022-07-13 16:44:04 - train: epoch 0067, iter [04500, 05004], lr: 0.041018, loss: 1.6604
2022-07-13 16:44:37 - train: epoch 0067, iter [04600, 05004], lr: 0.040992, loss: 1.5141
2022-07-13 16:45:10 - train: epoch 0067, iter [04700, 05004], lr: 0.040966, loss: 1.7435
2022-07-13 16:45:42 - train: epoch 0067, iter [04800, 05004], lr: 0.040941, loss: 1.4376
2022-07-13 16:46:15 - train: epoch 0067, iter [04900, 05004], lr: 0.040915, loss: 1.7703
2022-07-13 16:46:46 - train: epoch 0067, iter [05000, 05004], lr: 0.040889, loss: 1.9854
2022-07-13 16:46:46 - train: epoch 067, train_loss: 1.7980
2022-07-13 16:48:00 - eval: epoch: 067, acc1: 62.336%, acc5: 84.902%, test_loss: 1.5674, per_image_load_time: 2.629ms, per_image_inference_time: 0.256ms
2022-07-13 16:48:01 - until epoch: 067, best_acc1: 62.666%
2022-07-13 16:48:01 - epoch 068 lr: 0.040888
2022-07-13 16:48:38 - train: epoch 0068, iter [00100, 05004], lr: 0.040863, loss: 1.7877
2022-07-13 16:49:11 - train: epoch 0068, iter [00200, 05004], lr: 0.040837, loss: 1.8369
2022-07-13 16:49:44 - train: epoch 0068, iter [00300, 05004], lr: 0.040811, loss: 1.9462
2022-07-13 16:50:16 - train: epoch 0068, iter [00400, 05004], lr: 0.040785, loss: 1.7273
2022-07-13 16:50:48 - train: epoch 0068, iter [00500, 05004], lr: 0.040760, loss: 1.6648
2022-07-13 16:51:21 - train: epoch 0068, iter [00600, 05004], lr: 0.040734, loss: 1.7822
2022-07-13 16:51:52 - train: epoch 0068, iter [00700, 05004], lr: 0.040708, loss: 1.9859
2022-07-13 16:52:24 - train: epoch 0068, iter [00800, 05004], lr: 0.040683, loss: 1.7921
2022-07-13 16:52:57 - train: epoch 0068, iter [00900, 05004], lr: 0.040657, loss: 1.6350
2022-07-13 16:53:29 - train: epoch 0068, iter [01000, 05004], lr: 0.040631, loss: 1.8056
2022-07-13 16:54:01 - train: epoch 0068, iter [01100, 05004], lr: 0.040605, loss: 2.1057
2022-07-13 16:54:33 - train: epoch 0068, iter [01200, 05004], lr: 0.040580, loss: 1.6786
2022-07-13 16:55:06 - train: epoch 0068, iter [01300, 05004], lr: 0.040554, loss: 1.6622
2022-07-13 16:55:38 - train: epoch 0068, iter [01400, 05004], lr: 0.040528, loss: 1.7461
2022-07-13 16:56:10 - train: epoch 0068, iter [01500, 05004], lr: 0.040503, loss: 1.8824
2022-07-13 16:56:43 - train: epoch 0068, iter [01600, 05004], lr: 0.040477, loss: 1.6749
2022-07-13 16:57:16 - train: epoch 0068, iter [01700, 05004], lr: 0.040451, loss: 1.9967
2022-07-13 16:57:48 - train: epoch 0068, iter [01800, 05004], lr: 0.040426, loss: 1.9115
2022-07-13 16:58:21 - train: epoch 0068, iter [01900, 05004], lr: 0.040400, loss: 1.8482
2022-07-13 16:58:53 - train: epoch 0068, iter [02000, 05004], lr: 0.040374, loss: 1.8060
2022-07-13 16:59:25 - train: epoch 0068, iter [02100, 05004], lr: 0.040349, loss: 1.7785
2022-07-13 16:59:58 - train: epoch 0068, iter [02200, 05004], lr: 0.040323, loss: 1.6936
2022-07-13 17:00:30 - train: epoch 0068, iter [02300, 05004], lr: 0.040297, loss: 1.7266
2022-07-13 17:01:02 - train: epoch 0068, iter [02400, 05004], lr: 0.040272, loss: 1.9526
2022-07-13 17:01:35 - train: epoch 0068, iter [02500, 05004], lr: 0.040246, loss: 1.8034
2022-07-13 17:02:08 - train: epoch 0068, iter [02600, 05004], lr: 0.040220, loss: 1.7305
2022-07-13 17:02:40 - train: epoch 0068, iter [02700, 05004], lr: 0.040195, loss: 1.8818
2022-07-13 17:03:12 - train: epoch 0068, iter [02800, 05004], lr: 0.040169, loss: 1.9290
2022-07-13 17:03:44 - train: epoch 0068, iter [02900, 05004], lr: 0.040143, loss: 1.9645
2022-07-13 17:04:16 - train: epoch 0068, iter [03000, 05004], lr: 0.040118, loss: 2.0851
2022-07-13 17:04:49 - train: epoch 0068, iter [03100, 05004], lr: 0.040092, loss: 1.5513
2022-07-13 17:05:21 - train: epoch 0068, iter [03200, 05004], lr: 0.040066, loss: 2.0518
2022-07-13 17:05:54 - train: epoch 0068, iter [03300, 05004], lr: 0.040041, loss: 1.7422
2022-07-13 17:06:25 - train: epoch 0068, iter [03400, 05004], lr: 0.040015, loss: 1.7057
2022-07-13 17:06:58 - train: epoch 0068, iter [03500, 05004], lr: 0.039990, loss: 1.8674
2022-07-13 17:07:29 - train: epoch 0068, iter [03600, 05004], lr: 0.039964, loss: 1.6602
2022-07-13 17:08:02 - train: epoch 0068, iter [03700, 05004], lr: 0.039938, loss: 1.8587
2022-07-13 17:08:34 - train: epoch 0068, iter [03800, 05004], lr: 0.039913, loss: 1.9234
2022-07-13 17:09:07 - train: epoch 0068, iter [03900, 05004], lr: 0.039887, loss: 1.8530
2022-07-13 17:09:40 - train: epoch 0068, iter [04000, 05004], lr: 0.039861, loss: 1.8731
2022-07-13 17:10:12 - train: epoch 0068, iter [04100, 05004], lr: 0.039836, loss: 1.4866
2022-07-13 17:10:45 - train: epoch 0068, iter [04200, 05004], lr: 0.039810, loss: 1.8716
2022-07-13 17:11:18 - train: epoch 0068, iter [04300, 05004], lr: 0.039785, loss: 1.8795
2022-07-13 17:11:50 - train: epoch 0068, iter [04400, 05004], lr: 0.039759, loss: 1.8192
2022-07-13 17:12:23 - train: epoch 0068, iter [04500, 05004], lr: 0.039733, loss: 1.9066
2022-07-13 17:12:55 - train: epoch 0068, iter [04600, 05004], lr: 0.039708, loss: 1.9309
2022-07-13 17:13:28 - train: epoch 0068, iter [04700, 05004], lr: 0.039682, loss: 2.1343
2022-07-13 17:14:00 - train: epoch 0068, iter [04800, 05004], lr: 0.039657, loss: 1.8681
2022-07-13 17:14:33 - train: epoch 0068, iter [04900, 05004], lr: 0.039631, loss: 1.9928
2022-07-13 17:15:04 - train: epoch 0068, iter [05000, 05004], lr: 0.039605, loss: 1.7420
2022-07-13 17:15:05 - train: epoch 068, train_loss: 1.7877
2022-07-13 17:16:18 - eval: epoch: 068, acc1: 62.330%, acc5: 84.866%, test_loss: 1.5678, per_image_load_time: 2.650ms, per_image_inference_time: 0.232ms
2022-07-13 17:16:19 - until epoch: 068, best_acc1: 62.666%
2022-07-13 17:16:19 - epoch 069 lr: 0.039604
2022-07-13 17:16:57 - train: epoch 0069, iter [00100, 05004], lr: 0.039579, loss: 1.9947
2022-07-13 17:17:29 - train: epoch 0069, iter [00200, 05004], lr: 0.039553, loss: 2.0408
2022-07-13 17:18:02 - train: epoch 0069, iter [00300, 05004], lr: 0.039528, loss: 1.7485
2022-07-13 17:18:35 - train: epoch 0069, iter [00400, 05004], lr: 0.039502, loss: 1.6550
2022-07-13 17:19:07 - train: epoch 0069, iter [00500, 05004], lr: 0.039477, loss: 1.6410
2022-07-13 17:19:40 - train: epoch 0069, iter [00600, 05004], lr: 0.039451, loss: 1.6743
2022-07-13 17:20:12 - train: epoch 0069, iter [00700, 05004], lr: 0.039425, loss: 1.8492
2022-07-13 17:20:45 - train: epoch 0069, iter [00800, 05004], lr: 0.039400, loss: 1.8260
2022-07-13 17:21:17 - train: epoch 0069, iter [00900, 05004], lr: 0.039374, loss: 1.6745
2022-07-13 17:21:50 - train: epoch 0069, iter [01000, 05004], lr: 0.039349, loss: 1.6517
2022-07-13 17:22:22 - train: epoch 0069, iter [01100, 05004], lr: 0.039323, loss: 1.6608
2022-07-13 17:22:55 - train: epoch 0069, iter [01200, 05004], lr: 0.039298, loss: 1.7790
2022-07-13 17:23:27 - train: epoch 0069, iter [01300, 05004], lr: 0.039272, loss: 2.0898
2022-07-13 17:24:00 - train: epoch 0069, iter [01400, 05004], lr: 0.039246, loss: 1.8105
2022-07-13 17:24:31 - train: epoch 0069, iter [01500, 05004], lr: 0.039221, loss: 1.7158
2022-07-13 17:25:04 - train: epoch 0069, iter [01600, 05004], lr: 0.039195, loss: 1.9087
2022-07-13 17:25:36 - train: epoch 0069, iter [01700, 05004], lr: 0.039170, loss: 1.6792
2022-07-13 17:26:09 - train: epoch 0069, iter [01800, 05004], lr: 0.039144, loss: 1.5896
2022-07-13 17:26:40 - train: epoch 0069, iter [01900, 05004], lr: 0.039119, loss: 1.7233
2022-07-13 17:27:13 - train: epoch 0069, iter [02000, 05004], lr: 0.039093, loss: 1.6367
2022-07-13 17:27:45 - train: epoch 0069, iter [02100, 05004], lr: 0.039068, loss: 1.8323
2022-07-13 17:28:18 - train: epoch 0069, iter [02200, 05004], lr: 0.039042, loss: 1.7402
2022-07-13 17:28:50 - train: epoch 0069, iter [02300, 05004], lr: 0.039017, loss: 1.7708
2022-07-13 17:29:23 - train: epoch 0069, iter [02400, 05004], lr: 0.038991, loss: 1.8745
2022-07-13 17:29:55 - train: epoch 0069, iter [02500, 05004], lr: 0.038966, loss: 1.7015
2022-07-13 17:30:29 - train: epoch 0069, iter [02600, 05004], lr: 0.038940, loss: 1.8392
2022-07-13 17:31:01 - train: epoch 0069, iter [02700, 05004], lr: 0.038915, loss: 2.0141
2022-07-13 17:31:35 - train: epoch 0069, iter [02800, 05004], lr: 0.038889, loss: 1.8541
2022-07-13 17:32:08 - train: epoch 0069, iter [02900, 05004], lr: 0.038864, loss: 1.5712
2022-07-13 17:32:41 - train: epoch 0069, iter [03000, 05004], lr: 0.038838, loss: 1.7461
2022-07-13 17:33:14 - train: epoch 0069, iter [03100, 05004], lr: 0.038813, loss: 1.7317
2022-07-13 17:33:47 - train: epoch 0069, iter [03200, 05004], lr: 0.038787, loss: 1.6646
2022-07-13 17:34:19 - train: epoch 0069, iter [03300, 05004], lr: 0.038762, loss: 1.6916
2022-07-13 17:34:52 - train: epoch 0069, iter [03400, 05004], lr: 0.038736, loss: 1.7197
2022-07-13 17:35:25 - train: epoch 0069, iter [03500, 05004], lr: 0.038711, loss: 1.5908
2022-07-13 17:35:58 - train: epoch 0069, iter [03600, 05004], lr: 0.038685, loss: 1.6713
2022-07-13 17:36:31 - train: epoch 0069, iter [03700, 05004], lr: 0.038660, loss: 1.9408
2022-07-13 17:37:04 - train: epoch 0069, iter [03800, 05004], lr: 0.038634, loss: 1.8080
2022-07-13 17:37:37 - train: epoch 0069, iter [03900, 05004], lr: 0.038609, loss: 1.8556
2022-07-13 17:38:10 - train: epoch 0069, iter [04000, 05004], lr: 0.038583, loss: 1.8517
2022-07-13 17:38:43 - train: epoch 0069, iter [04100, 05004], lr: 0.038558, loss: 1.9064
2022-07-13 17:39:17 - train: epoch 0069, iter [04200, 05004], lr: 0.038532, loss: 1.5173
2022-07-13 17:39:50 - train: epoch 0069, iter [04300, 05004], lr: 0.038507, loss: 1.8312
2022-07-13 17:40:24 - train: epoch 0069, iter [04400, 05004], lr: 0.038481, loss: 1.7949
2022-07-13 17:40:56 - train: epoch 0069, iter [04500, 05004], lr: 0.038456, loss: 1.8123
2022-07-13 17:41:29 - train: epoch 0069, iter [04600, 05004], lr: 0.038431, loss: 1.9884
2022-07-13 17:42:02 - train: epoch 0069, iter [04700, 05004], lr: 0.038405, loss: 1.7730
2022-07-13 17:42:36 - train: epoch 0069, iter [04800, 05004], lr: 0.038380, loss: 1.7741
2022-07-13 17:43:10 - train: epoch 0069, iter [04900, 05004], lr: 0.038354, loss: 1.7023
2022-07-13 17:43:41 - train: epoch 0069, iter [05000, 05004], lr: 0.038329, loss: 1.8338
2022-07-13 17:43:42 - train: epoch 069, train_loss: 1.7743
2022-07-13 17:44:56 - eval: epoch: 069, acc1: 62.986%, acc5: 85.270%, test_loss: 1.5446, per_image_load_time: 2.643ms, per_image_inference_time: 0.265ms
2022-07-13 17:44:57 - until epoch: 069, best_acc1: 62.986%
2022-07-13 17:44:57 - epoch 070 lr: 0.038327
2022-07-13 17:45:36 - train: epoch 0070, iter [00100, 05004], lr: 0.038302, loss: 1.8394
2022-07-13 17:46:09 - train: epoch 0070, iter [00200, 05004], lr: 0.038277, loss: 1.7419
2022-07-13 17:46:42 - train: epoch 0070, iter [00300, 05004], lr: 0.038251, loss: 1.8756
2022-07-13 17:47:15 - train: epoch 0070, iter [00400, 05004], lr: 0.038226, loss: 1.6707
2022-07-13 17:47:49 - train: epoch 0070, iter [00500, 05004], lr: 0.038201, loss: 1.7579
2022-07-13 17:48:24 - train: epoch 0070, iter [00600, 05004], lr: 0.038175, loss: 1.7549
2022-07-13 17:48:58 - train: epoch 0070, iter [00700, 05004], lr: 0.038150, loss: 1.6662
2022-07-13 17:49:32 - train: epoch 0070, iter [00800, 05004], lr: 0.038124, loss: 1.5911
2022-07-13 17:50:05 - train: epoch 0070, iter [00900, 05004], lr: 0.038099, loss: 1.8130
2022-07-13 17:50:39 - train: epoch 0070, iter [01000, 05004], lr: 0.038074, loss: 1.7650
2022-07-13 17:51:13 - train: epoch 0070, iter [01100, 05004], lr: 0.038048, loss: 2.2041
2022-07-13 17:51:47 - train: epoch 0070, iter [01200, 05004], lr: 0.038023, loss: 1.5427
2022-07-13 17:52:20 - train: epoch 0070, iter [01300, 05004], lr: 0.037997, loss: 1.7146
2022-07-13 17:52:53 - train: epoch 0070, iter [01400, 05004], lr: 0.037972, loss: 1.7712
2022-07-13 17:53:27 - train: epoch 0070, iter [01500, 05004], lr: 0.037947, loss: 1.7876
2022-07-13 17:54:00 - train: epoch 0070, iter [01600, 05004], lr: 0.037921, loss: 1.7935
2022-07-13 17:54:35 - train: epoch 0070, iter [01700, 05004], lr: 0.037896, loss: 1.6392
2022-07-13 17:55:08 - train: epoch 0070, iter [01800, 05004], lr: 0.037870, loss: 1.6069
2022-07-13 17:55:42 - train: epoch 0070, iter [01900, 05004], lr: 0.037845, loss: 1.5872
2022-07-13 17:56:16 - train: epoch 0070, iter [02000, 05004], lr: 0.037820, loss: 1.7520
2022-07-13 17:56:50 - train: epoch 0070, iter [02100, 05004], lr: 0.037794, loss: 1.8678
2022-07-13 17:57:24 - train: epoch 0070, iter [02200, 05004], lr: 0.037769, loss: 1.8256
2022-07-13 17:57:58 - train: epoch 0070, iter [02300, 05004], lr: 0.037744, loss: 1.7396
2022-07-13 17:58:32 - train: epoch 0070, iter [02400, 05004], lr: 0.037718, loss: 1.8688
2022-07-13 17:59:07 - train: epoch 0070, iter [02500, 05004], lr: 0.037693, loss: 1.7903
2022-07-13 17:59:40 - train: epoch 0070, iter [02600, 05004], lr: 0.037667, loss: 1.7201
2022-07-13 18:00:13 - train: epoch 0070, iter [02700, 05004], lr: 0.037642, loss: 1.7914
2022-07-13 18:00:48 - train: epoch 0070, iter [02800, 05004], lr: 0.037617, loss: 1.8379
2022-07-13 18:01:22 - train: epoch 0070, iter [02900, 05004], lr: 0.037591, loss: 1.9387
2022-07-13 18:01:55 - train: epoch 0070, iter [03000, 05004], lr: 0.037566, loss: 1.7145
2022-07-13 18:02:30 - train: epoch 0070, iter [03100, 05004], lr: 0.037541, loss: 1.7487
2022-07-13 18:03:03 - train: epoch 0070, iter [03200, 05004], lr: 0.037515, loss: 1.9709
2022-07-13 18:03:37 - train: epoch 0070, iter [03300, 05004], lr: 0.037490, loss: 1.7449
2022-07-13 18:04:11 - train: epoch 0070, iter [03400, 05004], lr: 0.037465, loss: 1.8425
2022-07-13 18:04:45 - train: epoch 0070, iter [03500, 05004], lr: 0.037439, loss: 1.7486
2022-07-13 18:05:20 - train: epoch 0070, iter [03600, 05004], lr: 0.037414, loss: 1.9426
2022-07-13 18:05:53 - train: epoch 0070, iter [03700, 05004], lr: 0.037389, loss: 1.7673
2022-07-13 18:06:27 - train: epoch 0070, iter [03800, 05004], lr: 0.037364, loss: 1.7820
2022-07-13 18:07:01 - train: epoch 0070, iter [03900, 05004], lr: 0.037338, loss: 1.6718
2022-07-13 18:07:34 - train: epoch 0070, iter [04000, 05004], lr: 0.037313, loss: 1.6386
2022-07-13 18:08:08 - train: epoch 0070, iter [04100, 05004], lr: 0.037288, loss: 1.6981
2022-07-13 18:08:42 - train: epoch 0070, iter [04200, 05004], lr: 0.037262, loss: 1.7490
2022-07-13 18:09:16 - train: epoch 0070, iter [04300, 05004], lr: 0.037237, loss: 1.8299
2022-07-13 18:09:50 - train: epoch 0070, iter [04400, 05004], lr: 0.037212, loss: 1.8522
2022-07-13 18:10:23 - train: epoch 0070, iter [04500, 05004], lr: 0.037186, loss: 1.8915
2022-07-13 18:10:57 - train: epoch 0070, iter [04600, 05004], lr: 0.037161, loss: 1.9482
2022-07-13 18:11:32 - train: epoch 0070, iter [04700, 05004], lr: 0.037136, loss: 1.8222
2022-07-13 18:12:06 - train: epoch 0070, iter [04800, 05004], lr: 0.037111, loss: 1.9160
2022-07-13 18:12:40 - train: epoch 0070, iter [04900, 05004], lr: 0.037085, loss: 1.9012
2022-07-13 18:13:11 - train: epoch 0070, iter [05000, 05004], lr: 0.037060, loss: 1.6946
2022-07-13 18:13:12 - train: epoch 070, train_loss: 1.7641
2022-07-13 18:14:27 - eval: epoch: 070, acc1: 63.302%, acc5: 85.528%, test_loss: 1.5258, per_image_load_time: 2.650ms, per_image_inference_time: 0.276ms
2022-07-13 18:14:28 - until epoch: 070, best_acc1: 63.302%
2022-07-13 18:14:28 - epoch 071 lr: 0.037059
2022-07-13 18:15:06 - train: epoch 0071, iter [00100, 05004], lr: 0.037034, loss: 1.5653
2022-07-13 18:15:41 - train: epoch 0071, iter [00200, 05004], lr: 0.037009, loss: 1.7245
2022-07-13 18:16:15 - train: epoch 0071, iter [00300, 05004], lr: 0.036983, loss: 1.7062
2022-07-13 18:16:49 - train: epoch 0071, iter [00400, 05004], lr: 0.036958, loss: 1.8022
2022-07-13 18:17:23 - train: epoch 0071, iter [00500, 05004], lr: 0.036933, loss: 1.7132
2022-07-13 18:17:56 - train: epoch 0071, iter [00600, 05004], lr: 0.036908, loss: 1.8640
2022-07-13 18:18:31 - train: epoch 0071, iter [00700, 05004], lr: 0.036882, loss: 1.8800
2022-07-13 18:19:03 - train: epoch 0071, iter [00800, 05004], lr: 0.036857, loss: 1.6539
2022-07-13 18:19:38 - train: epoch 0071, iter [00900, 05004], lr: 0.036832, loss: 1.8371
2022-07-13 18:20:11 - train: epoch 0071, iter [01000, 05004], lr: 0.036807, loss: 1.7925
2022-07-13 18:20:44 - train: epoch 0071, iter [01100, 05004], lr: 0.036781, loss: 1.9269
2022-07-13 18:21:18 - train: epoch 0071, iter [01200, 05004], lr: 0.036756, loss: 1.7022
2022-07-13 18:21:52 - train: epoch 0071, iter [01300, 05004], lr: 0.036731, loss: 1.7995
2022-07-13 18:22:24 - train: epoch 0071, iter [01400, 05004], lr: 0.036706, loss: 1.7388
2022-07-13 18:22:59 - train: epoch 0071, iter [01500, 05004], lr: 0.036680, loss: 1.5468
2022-07-13 18:23:33 - train: epoch 0071, iter [01600, 05004], lr: 0.036655, loss: 1.5575
2022-07-13 18:24:07 - train: epoch 0071, iter [01700, 05004], lr: 0.036630, loss: 1.8721
2022-07-13 18:24:40 - train: epoch 0071, iter [01800, 05004], lr: 0.036605, loss: 1.7386
2022-07-13 18:25:14 - train: epoch 0071, iter [01900, 05004], lr: 0.036580, loss: 1.7198
2022-07-13 18:25:48 - train: epoch 0071, iter [02000, 05004], lr: 0.036554, loss: 1.8380
2022-07-13 18:26:22 - train: epoch 0071, iter [02100, 05004], lr: 0.036529, loss: 1.6291
2022-07-13 18:26:56 - train: epoch 0071, iter [02200, 05004], lr: 0.036504, loss: 1.6028
2022-07-13 18:27:30 - train: epoch 0071, iter [02300, 05004], lr: 0.036479, loss: 1.7424
2022-07-13 18:28:04 - train: epoch 0071, iter [02400, 05004], lr: 0.036454, loss: 1.6381
2022-07-13 18:28:37 - train: epoch 0071, iter [02500, 05004], lr: 0.036428, loss: 1.9827
2022-07-13 18:29:11 - train: epoch 0071, iter [02600, 05004], lr: 0.036403, loss: 1.6496
2022-07-13 18:29:45 - train: epoch 0071, iter [02700, 05004], lr: 0.036378, loss: 1.8439
2022-07-13 18:30:20 - train: epoch 0071, iter [02800, 05004], lr: 0.036353, loss: 1.7807
2022-07-13 18:30:53 - train: epoch 0071, iter [02900, 05004], lr: 0.036328, loss: 1.7679
2022-07-13 18:31:28 - train: epoch 0071, iter [03000, 05004], lr: 0.036303, loss: 1.8118
2022-07-13 18:32:01 - train: epoch 0071, iter [03100, 05004], lr: 0.036277, loss: 1.6358
2022-07-13 18:32:35 - train: epoch 0071, iter [03200, 05004], lr: 0.036252, loss: 1.5149
2022-07-13 18:33:09 - train: epoch 0071, iter [03300, 05004], lr: 0.036227, loss: 1.6619
2022-07-13 18:33:42 - train: epoch 0071, iter [03400, 05004], lr: 0.036202, loss: 1.6416
2022-07-13 18:34:16 - train: epoch 0071, iter [03500, 05004], lr: 0.036177, loss: 1.9902
2022-07-13 18:34:50 - train: epoch 0071, iter [03600, 05004], lr: 0.036152, loss: 1.9776
2022-07-13 18:35:24 - train: epoch 0071, iter [03700, 05004], lr: 0.036127, loss: 1.7180
2022-07-13 18:35:58 - train: epoch 0071, iter [03800, 05004], lr: 0.036101, loss: 1.6813
2022-07-13 18:36:32 - train: epoch 0071, iter [03900, 05004], lr: 0.036076, loss: 1.7326
2022-07-13 18:37:06 - train: epoch 0071, iter [04000, 05004], lr: 0.036051, loss: 2.0155
2022-07-13 18:37:40 - train: epoch 0071, iter [04100, 05004], lr: 0.036026, loss: 1.6196
2022-07-13 18:38:13 - train: epoch 0071, iter [04200, 05004], lr: 0.036001, loss: 1.9109
2022-07-13 18:38:48 - train: epoch 0071, iter [04300, 05004], lr: 0.035976, loss: 1.7551
2022-07-13 18:39:21 - train: epoch 0071, iter [04400, 05004], lr: 0.035951, loss: 1.8925
2022-07-13 18:39:55 - train: epoch 0071, iter [04500, 05004], lr: 0.035926, loss: 1.8288
2022-07-13 18:40:29 - train: epoch 0071, iter [04600, 05004], lr: 0.035901, loss: 1.7905
2022-07-13 18:41:03 - train: epoch 0071, iter [04700, 05004], lr: 0.035875, loss: 1.7352
2022-07-13 18:41:36 - train: epoch 0071, iter [04800, 05004], lr: 0.035850, loss: 1.6822
2022-07-13 18:42:09 - train: epoch 0071, iter [04900, 05004], lr: 0.035825, loss: 1.5412
2022-07-13 18:42:42 - train: epoch 0071, iter [05000, 05004], lr: 0.035800, loss: 1.6337
2022-07-13 18:42:42 - train: epoch 071, train_loss: 1.7515
2022-07-13 18:43:58 - eval: epoch: 071, acc1: 63.292%, acc5: 85.536%, test_loss: 1.5292, per_image_load_time: 2.665ms, per_image_inference_time: 0.267ms
2022-07-13 18:43:58 - until epoch: 071, best_acc1: 63.302%
2022-07-13 18:43:58 - epoch 072 lr: 0.035799
2022-07-13 18:44:38 - train: epoch 0072, iter [00100, 05004], lr: 0.035774, loss: 1.9086
2022-07-13 18:45:11 - train: epoch 0072, iter [00200, 05004], lr: 0.035749, loss: 1.5219
2022-07-13 18:45:45 - train: epoch 0072, iter [00300, 05004], lr: 0.035724, loss: 1.6208
2022-07-13 18:46:19 - train: epoch 0072, iter [00400, 05004], lr: 0.035699, loss: 1.7315
2022-07-13 18:46:53 - train: epoch 0072, iter [00500, 05004], lr: 0.035674, loss: 1.5802
2022-07-13 18:47:27 - train: epoch 0072, iter [00600, 05004], lr: 0.035649, loss: 1.6835
2022-07-13 18:48:00 - train: epoch 0072, iter [00700, 05004], lr: 0.035624, loss: 1.7262
2022-07-13 18:48:34 - train: epoch 0072, iter [00800, 05004], lr: 0.035599, loss: 1.8756
2022-07-13 18:49:07 - train: epoch 0072, iter [00900, 05004], lr: 0.035574, loss: 1.5299
2022-07-13 18:49:42 - train: epoch 0072, iter [01000, 05004], lr: 0.035549, loss: 1.6747
2022-07-13 18:50:16 - train: epoch 0072, iter [01100, 05004], lr: 0.035524, loss: 1.8487
2022-07-13 18:50:49 - train: epoch 0072, iter [01200, 05004], lr: 0.035499, loss: 1.7204
2022-07-13 18:51:24 - train: epoch 0072, iter [01300, 05004], lr: 0.035474, loss: 1.7093
2022-07-13 18:51:57 - train: epoch 0072, iter [01400, 05004], lr: 0.035448, loss: 1.7900
2022-07-13 18:52:31 - train: epoch 0072, iter [01500, 05004], lr: 0.035423, loss: 1.7125
2022-07-13 18:53:05 - train: epoch 0072, iter [01600, 05004], lr: 0.035398, loss: 1.7618
2022-07-13 18:53:39 - train: epoch 0072, iter [01700, 05004], lr: 0.035373, loss: 1.6031
2022-07-13 18:54:13 - train: epoch 0072, iter [01800, 05004], lr: 0.035348, loss: 1.5124
2022-07-13 18:54:48 - train: epoch 0072, iter [01900, 05004], lr: 0.035323, loss: 1.6536
2022-07-13 18:55:21 - train: epoch 0072, iter [02000, 05004], lr: 0.035298, loss: 1.9003
2022-07-13 18:55:55 - train: epoch 0072, iter [02100, 05004], lr: 0.035273, loss: 1.8433
2022-07-13 18:56:29 - train: epoch 0072, iter [02200, 05004], lr: 0.035248, loss: 1.8133
2022-07-13 18:57:03 - train: epoch 0072, iter [02300, 05004], lr: 0.035223, loss: 1.9778
2022-07-13 18:57:37 - train: epoch 0072, iter [02400, 05004], lr: 0.035198, loss: 1.6756
2022-07-13 18:58:11 - train: epoch 0072, iter [02500, 05004], lr: 0.035173, loss: 1.5665
2022-07-13 18:58:45 - train: epoch 0072, iter [02600, 05004], lr: 0.035148, loss: 1.5970
2022-07-13 18:59:18 - train: epoch 0072, iter [02700, 05004], lr: 0.035123, loss: 1.7117
2022-07-13 18:59:53 - train: epoch 0072, iter [02800, 05004], lr: 0.035098, loss: 1.8933
2022-07-13 19:00:26 - train: epoch 0072, iter [02900, 05004], lr: 0.035074, loss: 1.6164
2022-07-13 19:01:01 - train: epoch 0072, iter [03000, 05004], lr: 0.035049, loss: 1.6996
2022-07-13 19:01:34 - train: epoch 0072, iter [03100, 05004], lr: 0.035024, loss: 1.9108
2022-07-13 19:02:08 - train: epoch 0072, iter [03200, 05004], lr: 0.034999, loss: 1.6184
2022-07-13 19:02:42 - train: epoch 0072, iter [03300, 05004], lr: 0.034974, loss: 1.7510
2022-07-13 19:03:15 - train: epoch 0072, iter [03400, 05004], lr: 0.034949, loss: 1.9597
2022-07-13 19:03:49 - train: epoch 0072, iter [03500, 05004], lr: 0.034924, loss: 1.8623
2022-07-13 19:04:23 - train: epoch 0072, iter [03600, 05004], lr: 0.034899, loss: 1.7846
2022-07-13 19:04:57 - train: epoch 0072, iter [03700, 05004], lr: 0.034874, loss: 1.8276
2022-07-13 19:05:31 - train: epoch 0072, iter [03800, 05004], lr: 0.034849, loss: 1.8345
2022-07-13 19:06:06 - train: epoch 0072, iter [03900, 05004], lr: 0.034824, loss: 1.8931
2022-07-13 19:06:39 - train: epoch 0072, iter [04000, 05004], lr: 0.034799, loss: 1.7057
2022-07-13 19:07:14 - train: epoch 0072, iter [04100, 05004], lr: 0.034774, loss: 1.9540
2022-07-13 19:07:47 - train: epoch 0072, iter [04200, 05004], lr: 0.034749, loss: 1.7606
2022-07-13 19:08:22 - train: epoch 0072, iter [04300, 05004], lr: 0.034724, loss: 1.7776
2022-07-13 19:08:55 - train: epoch 0072, iter [04400, 05004], lr: 0.034699, loss: 1.5214
2022-07-13 19:09:29 - train: epoch 0072, iter [04500, 05004], lr: 0.034675, loss: 2.0356
2022-07-13 19:10:03 - train: epoch 0072, iter [04600, 05004], lr: 0.034650, loss: 1.6304
2022-07-13 19:10:36 - train: epoch 0072, iter [04700, 05004], lr: 0.034625, loss: 1.7754
2022-07-13 19:11:10 - train: epoch 0072, iter [04800, 05004], lr: 0.034600, loss: 2.0171
2022-07-13 19:11:44 - train: epoch 0072, iter [04900, 05004], lr: 0.034575, loss: 1.8261
2022-07-13 19:12:16 - train: epoch 0072, iter [05000, 05004], lr: 0.034550, loss: 1.6592
2022-07-13 19:12:17 - train: epoch 072, train_loss: 1.7405
2022-07-13 19:13:32 - eval: epoch: 072, acc1: 63.052%, acc5: 85.402%, test_loss: 1.5346, per_image_load_time: 2.669ms, per_image_inference_time: 0.258ms
2022-07-13 19:13:32 - until epoch: 072, best_acc1: 63.302%
2022-07-13 19:13:32 - epoch 073 lr: 0.034549
2022-07-13 19:14:12 - train: epoch 0073, iter [00100, 05004], lr: 0.034524, loss: 1.9960
2022-07-13 19:14:46 - train: epoch 0073, iter [00200, 05004], lr: 0.034499, loss: 1.7789
2022-07-13 19:15:19 - train: epoch 0073, iter [00300, 05004], lr: 0.034475, loss: 1.7809
2022-07-13 19:15:53 - train: epoch 0073, iter [00400, 05004], lr: 0.034450, loss: 1.3542
2022-07-13 19:16:26 - train: epoch 0073, iter [00500, 05004], lr: 0.034425, loss: 1.5858
2022-07-13 19:17:01 - train: epoch 0073, iter [00600, 05004], lr: 0.034400, loss: 1.6506
2022-07-13 19:17:35 - train: epoch 0073, iter [00700, 05004], lr: 0.034375, loss: 1.7541
2022-07-13 19:18:09 - train: epoch 0073, iter [00800, 05004], lr: 0.034350, loss: 1.5530
2022-07-13 19:18:42 - train: epoch 0073, iter [00900, 05004], lr: 0.034325, loss: 1.5340
2022-07-13 19:19:15 - train: epoch 0073, iter [01000, 05004], lr: 0.034301, loss: 1.5232
2022-07-13 19:19:51 - train: epoch 0073, iter [01100, 05004], lr: 0.034276, loss: 1.7789
2022-07-13 19:20:25 - train: epoch 0073, iter [01200, 05004], lr: 0.034251, loss: 1.6601
2022-07-13 19:20:58 - train: epoch 0073, iter [01300, 05004], lr: 0.034226, loss: 1.7874
2022-07-13 19:21:32 - train: epoch 0073, iter [01400, 05004], lr: 0.034201, loss: 1.6399
2022-07-13 19:22:06 - train: epoch 0073, iter [01500, 05004], lr: 0.034176, loss: 1.6763
2022-07-13 19:22:40 - train: epoch 0073, iter [01600, 05004], lr: 0.034152, loss: 1.7486
2022-07-13 19:23:14 - train: epoch 0073, iter [01700, 05004], lr: 0.034127, loss: 2.0560
2022-07-13 19:23:47 - train: epoch 0073, iter [01800, 05004], lr: 0.034102, loss: 1.5281
2022-07-13 19:24:21 - train: epoch 0073, iter [01900, 05004], lr: 0.034077, loss: 1.8601
2022-07-13 19:24:55 - train: epoch 0073, iter [02000, 05004], lr: 0.034052, loss: 1.5137
2022-07-13 19:25:28 - train: epoch 0073, iter [02100, 05004], lr: 0.034028, loss: 1.7889
2022-07-13 19:26:03 - train: epoch 0073, iter [02200, 05004], lr: 0.034003, loss: 1.8310
2022-07-13 19:26:36 - train: epoch 0073, iter [02300, 05004], lr: 0.033978, loss: 1.8811
2022-07-13 19:27:10 - train: epoch 0073, iter [02400, 05004], lr: 0.033953, loss: 1.6679
2022-07-13 19:27:44 - train: epoch 0073, iter [02500, 05004], lr: 0.033929, loss: 1.9133
2022-07-13 19:28:18 - train: epoch 0073, iter [02600, 05004], lr: 0.033904, loss: 1.7382
2022-07-13 19:28:52 - train: epoch 0073, iter [02700, 05004], lr: 0.033879, loss: 1.7194
2022-07-13 19:29:26 - train: epoch 0073, iter [02800, 05004], lr: 0.033854, loss: 1.6105
2022-07-13 19:29:59 - train: epoch 0073, iter [02900, 05004], lr: 0.033829, loss: 1.7791
2022-07-13 19:30:33 - train: epoch 0073, iter [03000, 05004], lr: 0.033805, loss: 1.6362
2022-07-13 19:31:06 - train: epoch 0073, iter [03100, 05004], lr: 0.033780, loss: 1.6753
2022-07-13 19:31:40 - train: epoch 0073, iter [03200, 05004], lr: 0.033755, loss: 1.5882
2022-07-13 19:32:14 - train: epoch 0073, iter [03300, 05004], lr: 0.033730, loss: 1.8074
2022-07-13 19:32:48 - train: epoch 0073, iter [03400, 05004], lr: 0.033706, loss: 1.7130
2022-07-13 19:33:22 - train: epoch 0073, iter [03500, 05004], lr: 0.033681, loss: 1.8213
2022-07-13 19:33:56 - train: epoch 0073, iter [03600, 05004], lr: 0.033656, loss: 1.6952
2022-07-13 19:34:29 - train: epoch 0073, iter [03700, 05004], lr: 0.033632, loss: 1.8049
2022-07-13 19:35:03 - train: epoch 0073, iter [03800, 05004], lr: 0.033607, loss: 1.9106
2022-07-13 19:35:37 - train: epoch 0073, iter [03900, 05004], lr: 0.033582, loss: 1.7315
2022-07-13 19:36:10 - train: epoch 0073, iter [04000, 05004], lr: 0.033557, loss: 1.8309
2022-07-13 19:36:45 - train: epoch 0073, iter [04100, 05004], lr: 0.033533, loss: 1.6872
2022-07-13 19:37:18 - train: epoch 0073, iter [04200, 05004], lr: 0.033508, loss: 2.0068
2022-07-13 19:37:52 - train: epoch 0073, iter [04300, 05004], lr: 0.033483, loss: 1.6301
2022-07-13 19:38:26 - train: epoch 0073, iter [04400, 05004], lr: 0.033459, loss: 1.8084
2022-07-13 19:38:59 - train: epoch 0073, iter [04500, 05004], lr: 0.033434, loss: 1.6624
2022-07-13 19:39:31 - train: epoch 0073, iter [04600, 05004], lr: 0.033409, loss: 1.8916
2022-07-13 19:40:04 - train: epoch 0073, iter [04700, 05004], lr: 0.033385, loss: 1.5449
2022-07-13 19:40:37 - train: epoch 0073, iter [04800, 05004], lr: 0.033360, loss: 1.8218
2022-07-13 19:41:11 - train: epoch 0073, iter [04900, 05004], lr: 0.033335, loss: 1.6784
2022-07-13 19:41:42 - train: epoch 0073, iter [05000, 05004], lr: 0.033311, loss: 1.8403
2022-07-13 19:41:43 - train: epoch 073, train_loss: 1.7282
2022-07-13 19:42:57 - eval: epoch: 073, acc1: 63.848%, acc5: 85.422%, test_loss: 1.5083, per_image_load_time: 2.543ms, per_image_inference_time: 0.274ms
2022-07-13 19:42:57 - until epoch: 073, best_acc1: 63.848%
2022-07-13 19:42:57 - epoch 074 lr: 0.033309
2022-07-13 19:43:36 - train: epoch 0074, iter [00100, 05004], lr: 0.033285, loss: 1.5977
2022-07-13 19:44:08 - train: epoch 0074, iter [00200, 05004], lr: 0.033260, loss: 1.7529
2022-07-13 19:44:41 - train: epoch 0074, iter [00300, 05004], lr: 0.033236, loss: 1.7666
2022-07-13 19:45:14 - train: epoch 0074, iter [00400, 05004], lr: 0.033211, loss: 1.9239
2022-07-13 19:45:48 - train: epoch 0074, iter [00500, 05004], lr: 0.033186, loss: 1.6760
2022-07-13 19:46:20 - train: epoch 0074, iter [00600, 05004], lr: 0.033162, loss: 1.7862
2022-07-13 19:46:54 - train: epoch 0074, iter [00700, 05004], lr: 0.033137, loss: 1.6413
2022-07-13 19:47:27 - train: epoch 0074, iter [00800, 05004], lr: 0.033113, loss: 1.8289
2022-07-13 19:48:00 - train: epoch 0074, iter [00900, 05004], lr: 0.033088, loss: 1.6416
2022-07-13 19:48:34 - train: epoch 0074, iter [01000, 05004], lr: 0.033063, loss: 1.8562
2022-07-13 19:49:05 - train: epoch 0074, iter [01100, 05004], lr: 0.033039, loss: 1.8748
2022-07-13 19:49:39 - train: epoch 0074, iter [01200, 05004], lr: 0.033014, loss: 1.6648
2022-07-13 19:50:12 - train: epoch 0074, iter [01300, 05004], lr: 0.032989, loss: 1.8261
2022-07-13 19:50:45 - train: epoch 0074, iter [01400, 05004], lr: 0.032965, loss: 1.6358
2022-07-13 19:51:17 - train: epoch 0074, iter [01500, 05004], lr: 0.032940, loss: 1.8409
2022-07-13 19:51:51 - train: epoch 0074, iter [01600, 05004], lr: 0.032916, loss: 1.5908
2022-07-13 19:52:23 - train: epoch 0074, iter [01700, 05004], lr: 0.032891, loss: 1.7294
2022-07-13 19:52:56 - train: epoch 0074, iter [01800, 05004], lr: 0.032867, loss: 2.0760
2022-07-13 19:53:28 - train: epoch 0074, iter [01900, 05004], lr: 0.032842, loss: 1.7696
2022-07-13 19:54:01 - train: epoch 0074, iter [02000, 05004], lr: 0.032817, loss: 1.5074
2022-07-13 19:54:33 - train: epoch 0074, iter [02100, 05004], lr: 0.032793, loss: 1.5934
2022-07-13 19:55:06 - train: epoch 0074, iter [02200, 05004], lr: 0.032768, loss: 2.0276
2022-07-13 19:55:40 - train: epoch 0074, iter [02300, 05004], lr: 0.032744, loss: 1.8245
2022-07-13 19:56:12 - train: epoch 0074, iter [02400, 05004], lr: 0.032719, loss: 1.7251
2022-07-13 19:56:45 - train: epoch 0074, iter [02500, 05004], lr: 0.032695, loss: 1.5333
2022-07-13 19:57:18 - train: epoch 0074, iter [02600, 05004], lr: 0.032670, loss: 1.3860
2022-07-13 19:57:51 - train: epoch 0074, iter [02700, 05004], lr: 0.032646, loss: 1.6789
2022-07-13 19:58:24 - train: epoch 0074, iter [02800, 05004], lr: 0.032621, loss: 1.9975
2022-07-13 19:58:57 - train: epoch 0074, iter [02900, 05004], lr: 0.032597, loss: 1.7148
2022-07-13 19:59:30 - train: epoch 0074, iter [03000, 05004], lr: 0.032572, loss: 1.8128
2022-07-13 20:00:03 - train: epoch 0074, iter [03100, 05004], lr: 0.032547, loss: 1.6783
2022-07-13 20:00:35 - train: epoch 0074, iter [03200, 05004], lr: 0.032523, loss: 1.6470
2022-07-13 20:01:09 - train: epoch 0074, iter [03300, 05004], lr: 0.032498, loss: 1.7113
2022-07-13 20:01:41 - train: epoch 0074, iter [03400, 05004], lr: 0.032474, loss: 1.7684
2022-07-13 20:02:14 - train: epoch 0074, iter [03500, 05004], lr: 0.032449, loss: 1.5493
2022-07-13 20:02:47 - train: epoch 0074, iter [03600, 05004], lr: 0.032425, loss: 1.7645
2022-07-13 20:03:19 - train: epoch 0074, iter [03700, 05004], lr: 0.032400, loss: 1.8156
2022-07-13 20:03:52 - train: epoch 0074, iter [03800, 05004], lr: 0.032376, loss: 1.7174
2022-07-13 20:04:26 - train: epoch 0074, iter [03900, 05004], lr: 0.032352, loss: 1.5414
2022-07-13 20:04:59 - train: epoch 0074, iter [04000, 05004], lr: 0.032327, loss: 1.6616
2022-07-13 20:05:32 - train: epoch 0074, iter [04100, 05004], lr: 0.032303, loss: 1.9477
2022-07-13 20:06:05 - train: epoch 0074, iter [04200, 05004], lr: 0.032278, loss: 1.6706
2022-07-13 20:06:38 - train: epoch 0074, iter [04300, 05004], lr: 0.032254, loss: 1.6595
2022-07-13 20:07:11 - train: epoch 0074, iter [04400, 05004], lr: 0.032229, loss: 1.5429
2022-07-13 20:07:44 - train: epoch 0074, iter [04500, 05004], lr: 0.032205, loss: 1.5687
2022-07-13 20:08:16 - train: epoch 0074, iter [04600, 05004], lr: 0.032180, loss: 1.8107
2022-07-13 20:08:48 - train: epoch 0074, iter [04700, 05004], lr: 0.032156, loss: 1.7365
2022-07-13 20:09:21 - train: epoch 0074, iter [04800, 05004], lr: 0.032131, loss: 1.7785
2022-07-13 20:09:56 - train: epoch 0074, iter [04900, 05004], lr: 0.032107, loss: 2.0098
2022-07-13 20:10:27 - train: epoch 0074, iter [05000, 05004], lr: 0.032083, loss: 1.7659
2022-07-13 20:10:27 - train: epoch 074, train_loss: 1.7135
2022-07-13 20:11:41 - eval: epoch: 074, acc1: 63.858%, acc5: 85.844%, test_loss: 1.5033, per_image_load_time: 2.487ms, per_image_inference_time: 0.283ms
2022-07-13 20:11:42 - until epoch: 074, best_acc1: 63.858%
2022-07-13 20:11:42 - epoch 075 lr: 0.032081
2022-07-13 20:12:20 - train: epoch 0075, iter [00100, 05004], lr: 0.032057, loss: 1.8467
2022-07-13 20:12:54 - train: epoch 0075, iter [00200, 05004], lr: 0.032033, loss: 1.7092
2022-07-13 20:13:26 - train: epoch 0075, iter [00300, 05004], lr: 0.032008, loss: 1.7253
2022-07-13 20:13:59 - train: epoch 0075, iter [00400, 05004], lr: 0.031984, loss: 1.7672
2022-07-13 20:14:32 - train: epoch 0075, iter [00500, 05004], lr: 0.031960, loss: 1.5733
2022-07-13 20:15:05 - train: epoch 0075, iter [00600, 05004], lr: 0.031935, loss: 1.6012
2022-07-13 20:15:38 - train: epoch 0075, iter [00700, 05004], lr: 0.031911, loss: 1.8465
2022-07-13 20:16:11 - train: epoch 0075, iter [00800, 05004], lr: 0.031886, loss: 1.8092
2022-07-13 20:16:44 - train: epoch 0075, iter [00900, 05004], lr: 0.031862, loss: 1.7532
2022-07-13 20:17:18 - train: epoch 0075, iter [01000, 05004], lr: 0.031838, loss: 1.5546
2022-07-13 20:17:51 - train: epoch 0075, iter [01100, 05004], lr: 0.031813, loss: 1.7494
2022-07-13 20:18:24 - train: epoch 0075, iter [01200, 05004], lr: 0.031789, loss: 1.5289
2022-07-13 20:18:56 - train: epoch 0075, iter [01300, 05004], lr: 0.031765, loss: 1.4486
2022-07-13 20:19:30 - train: epoch 0075, iter [01400, 05004], lr: 0.031740, loss: 1.6443
2022-07-13 20:20:03 - train: epoch 0075, iter [01500, 05004], lr: 0.031716, loss: 1.8525
2022-07-13 20:20:35 - train: epoch 0075, iter [01600, 05004], lr: 0.031691, loss: 1.3738
2022-07-13 20:21:08 - train: epoch 0075, iter [01700, 05004], lr: 0.031667, loss: 1.7204
2022-07-13 20:21:42 - train: epoch 0075, iter [01800, 05004], lr: 0.031643, loss: 1.7515
2022-07-13 20:22:15 - train: epoch 0075, iter [01900, 05004], lr: 0.031618, loss: 1.5458
2022-07-13 20:22:48 - train: epoch 0075, iter [02000, 05004], lr: 0.031594, loss: 1.7171
2022-07-13 20:23:21 - train: epoch 0075, iter [02100, 05004], lr: 0.031570, loss: 1.5198
2022-07-13 20:23:53 - train: epoch 0075, iter [02200, 05004], lr: 0.031546, loss: 1.7428
2022-07-13 20:24:26 - train: epoch 0075, iter [02300, 05004], lr: 0.031521, loss: 1.5618
2022-07-13 20:25:00 - train: epoch 0075, iter [02400, 05004], lr: 0.031497, loss: 1.7554
2022-07-13 20:25:33 - train: epoch 0075, iter [02500, 05004], lr: 0.031473, loss: 1.8393
2022-07-13 20:26:06 - train: epoch 0075, iter [02600, 05004], lr: 0.031448, loss: 1.8106
2022-07-13 20:26:40 - train: epoch 0075, iter [02700, 05004], lr: 0.031424, loss: 1.5143
2022-07-13 20:27:12 - train: epoch 0075, iter [02800, 05004], lr: 0.031400, loss: 1.6864
2022-07-13 20:27:45 - train: epoch 0075, iter [02900, 05004], lr: 0.031375, loss: 1.8345
2022-07-13 20:28:18 - train: epoch 0075, iter [03000, 05004], lr: 0.031351, loss: 1.8455
2022-07-13 20:28:51 - train: epoch 0075, iter [03100, 05004], lr: 0.031327, loss: 1.8319
2022-07-13 20:29:24 - train: epoch 0075, iter [03200, 05004], lr: 0.031303, loss: 1.6639
2022-07-13 20:29:58 - train: epoch 0075, iter [03300, 05004], lr: 0.031278, loss: 1.7216
2022-07-13 20:30:31 - train: epoch 0075, iter [03400, 05004], lr: 0.031254, loss: 1.6073
2022-07-13 20:31:03 - train: epoch 0075, iter [03500, 05004], lr: 0.031230, loss: 1.6279
2022-07-13 20:31:36 - train: epoch 0075, iter [03600, 05004], lr: 0.031206, loss: 1.7381
2022-07-13 20:32:10 - train: epoch 0075, iter [03700, 05004], lr: 0.031181, loss: 1.7607
2022-07-13 20:32:43 - train: epoch 0075, iter [03800, 05004], lr: 0.031157, loss: 1.6229
2022-07-13 20:33:16 - train: epoch 0075, iter [03900, 05004], lr: 0.031133, loss: 1.8571
2022-07-13 20:33:49 - train: epoch 0075, iter [04000, 05004], lr: 0.031109, loss: 1.5143
2022-07-13 20:34:22 - train: epoch 0075, iter [04100, 05004], lr: 0.031085, loss: 1.4508
2022-07-13 20:34:55 - train: epoch 0075, iter [04200, 05004], lr: 0.031060, loss: 1.7772
2022-07-13 20:35:28 - train: epoch 0075, iter [04300, 05004], lr: 0.031036, loss: 1.9586
2022-07-13 20:36:02 - train: epoch 0075, iter [04400, 05004], lr: 0.031012, loss: 1.4518
2022-07-13 20:36:35 - train: epoch 0075, iter [04500, 05004], lr: 0.030988, loss: 1.6550
2022-07-13 20:37:08 - train: epoch 0075, iter [04600, 05004], lr: 0.030964, loss: 1.5563
2022-07-13 20:37:41 - train: epoch 0075, iter [04700, 05004], lr: 0.030939, loss: 1.8608
2022-07-13 20:38:14 - train: epoch 0075, iter [04800, 05004], lr: 0.030915, loss: 1.8462
2022-07-13 20:38:47 - train: epoch 0075, iter [04900, 05004], lr: 0.030891, loss: 1.5336
2022-07-13 20:39:19 - train: epoch 0075, iter [05000, 05004], lr: 0.030867, loss: 1.6555
2022-07-13 20:39:20 - train: epoch 075, train_loss: 1.7017
2022-07-13 20:40:34 - eval: epoch: 075, acc1: 64.198%, acc5: 85.852%, test_loss: 1.4906, per_image_load_time: 2.575ms, per_image_inference_time: 0.285ms
2022-07-13 20:40:34 - until epoch: 075, best_acc1: 64.198%
2022-07-13 20:40:34 - epoch 076 lr: 0.030866
2022-07-13 20:41:12 - train: epoch 0076, iter [00100, 05004], lr: 0.030842, loss: 1.4666
2022-07-13 20:41:45 - train: epoch 0076, iter [00200, 05004], lr: 0.030818, loss: 1.6563
2022-07-13 20:42:18 - train: epoch 0076, iter [00300, 05004], lr: 0.030793, loss: 1.7496
2022-07-13 20:42:52 - train: epoch 0076, iter [00400, 05004], lr: 0.030769, loss: 1.6835
2022-07-13 20:43:25 - train: epoch 0076, iter [00500, 05004], lr: 0.030745, loss: 1.6944
2022-07-13 20:43:58 - train: epoch 0076, iter [00600, 05004], lr: 0.030721, loss: 1.6391
2022-07-13 20:44:31 - train: epoch 0076, iter [00700, 05004], lr: 0.030697, loss: 1.7300
2022-07-13 20:45:04 - train: epoch 0076, iter [00800, 05004], lr: 0.030673, loss: 1.5908
2022-07-13 20:45:37 - train: epoch 0076, iter [00900, 05004], lr: 0.030649, loss: 1.5961
2022-07-13 20:46:11 - train: epoch 0076, iter [01000, 05004], lr: 0.030624, loss: 1.5480
2022-07-13 20:46:44 - train: epoch 0076, iter [01100, 05004], lr: 0.030600, loss: 1.5242
2022-07-13 20:47:16 - train: epoch 0076, iter [01200, 05004], lr: 0.030576, loss: 1.6582
2022-07-13 20:47:49 - train: epoch 0076, iter [01300, 05004], lr: 0.030552, loss: 1.6852
2022-07-13 20:48:24 - train: epoch 0076, iter [01400, 05004], lr: 0.030528, loss: 1.5762
2022-07-13 20:48:57 - train: epoch 0076, iter [01500, 05004], lr: 0.030504, loss: 1.7108
2022-07-13 20:49:30 - train: epoch 0076, iter [01600, 05004], lr: 0.030480, loss: 1.5684
2022-07-13 20:50:03 - train: epoch 0076, iter [01700, 05004], lr: 0.030456, loss: 1.6716
2022-07-13 20:50:36 - train: epoch 0076, iter [01800, 05004], lr: 0.030432, loss: 1.4997
2022-07-13 20:51:09 - train: epoch 0076, iter [01900, 05004], lr: 0.030408, loss: 1.8077
2022-07-13 20:51:42 - train: epoch 0076, iter [02000, 05004], lr: 0.030384, loss: 1.7388
2022-07-13 20:52:14 - train: epoch 0076, iter [02100, 05004], lr: 0.030359, loss: 1.7545
2022-07-13 20:52:47 - train: epoch 0076, iter [02200, 05004], lr: 0.030335, loss: 1.8318
2022-07-13 20:53:21 - train: epoch 0076, iter [02300, 05004], lr: 0.030311, loss: 1.5429
2022-07-13 20:53:55 - train: epoch 0076, iter [02400, 05004], lr: 0.030287, loss: 1.8627
2022-07-13 20:54:28 - train: epoch 0076, iter [02500, 05004], lr: 0.030263, loss: 1.6275
2022-07-13 20:55:01 - train: epoch 0076, iter [02600, 05004], lr: 0.030239, loss: 1.9744
2022-07-13 20:55:34 - train: epoch 0076, iter [02700, 05004], lr: 0.030215, loss: 1.7600
2022-07-13 20:56:06 - train: epoch 0076, iter [02800, 05004], lr: 0.030191, loss: 1.7076
2022-07-13 20:56:40 - train: epoch 0076, iter [02900, 05004], lr: 0.030167, loss: 1.7355
2022-07-13 20:57:13 - train: epoch 0076, iter [03000, 05004], lr: 0.030143, loss: 1.4804
2022-07-13 20:57:46 - train: epoch 0076, iter [03100, 05004], lr: 0.030119, loss: 1.8021
2022-07-13 20:58:19 - train: epoch 0076, iter [03200, 05004], lr: 0.030095, loss: 1.7466
2022-07-13 20:58:52 - train: epoch 0076, iter [03300, 05004], lr: 0.030071, loss: 1.5155
2022-07-13 20:59:26 - train: epoch 0076, iter [03400, 05004], lr: 0.030047, loss: 1.6158
2022-07-13 20:59:58 - train: epoch 0076, iter [03500, 05004], lr: 0.030023, loss: 1.5352
2022-07-13 21:00:31 - train: epoch 0076, iter [03600, 05004], lr: 0.029999, loss: 1.4794
2022-07-13 21:01:05 - train: epoch 0076, iter [03700, 05004], lr: 0.029975, loss: 1.6220
2022-07-13 21:01:38 - train: epoch 0076, iter [03800, 05004], lr: 0.029951, loss: 1.5405
2022-07-13 21:02:11 - train: epoch 0076, iter [03900, 05004], lr: 0.029927, loss: 1.6607
2022-07-13 21:02:44 - train: epoch 0076, iter [04000, 05004], lr: 0.029903, loss: 1.6438
2022-07-13 21:03:17 - train: epoch 0076, iter [04100, 05004], lr: 0.029879, loss: 1.5787
2022-07-13 21:03:51 - train: epoch 0076, iter [04200, 05004], lr: 0.029855, loss: 1.7900
2022-07-13 21:04:23 - train: epoch 0076, iter [04300, 05004], lr: 0.029832, loss: 1.8247
2022-07-13 21:04:57 - train: epoch 0076, iter [04400, 05004], lr: 0.029808, loss: 1.6440
2022-07-13 21:05:30 - train: epoch 0076, iter [04500, 05004], lr: 0.029784, loss: 1.7450
2022-07-13 21:06:04 - train: epoch 0076, iter [04600, 05004], lr: 0.029760, loss: 1.7448
2022-07-13 21:06:37 - train: epoch 0076, iter [04700, 05004], lr: 0.029736, loss: 1.8122
2022-07-13 21:07:10 - train: epoch 0076, iter [04800, 05004], lr: 0.029712, loss: 1.4926
2022-07-13 21:07:44 - train: epoch 0076, iter [04900, 05004], lr: 0.029688, loss: 1.6722
2022-07-13 21:08:15 - train: epoch 0076, iter [05000, 05004], lr: 0.029664, loss: 1.8046
2022-07-13 21:08:15 - train: epoch 076, train_loss: 1.6879
2022-07-13 21:09:29 - eval: epoch: 076, acc1: 64.360%, acc5: 86.004%, test_loss: 1.4832, per_image_load_time: 2.345ms, per_image_inference_time: 0.287ms
2022-07-13 21:09:29 - until epoch: 076, best_acc1: 64.360%
2022-07-13 21:09:29 - epoch 077 lr: 0.029663
2022-07-13 21:10:08 - train: epoch 0077, iter [00100, 05004], lr: 0.029639, loss: 1.8724
2022-07-13 21:10:40 - train: epoch 0077, iter [00200, 05004], lr: 0.029615, loss: 1.7488
2022-07-13 21:11:14 - train: epoch 0077, iter [00300, 05004], lr: 0.029592, loss: 1.4403
2022-07-13 21:11:46 - train: epoch 0077, iter [00400, 05004], lr: 0.029568, loss: 1.8249
2022-07-13 21:12:20 - train: epoch 0077, iter [00500, 05004], lr: 0.029544, loss: 1.4546
2022-07-13 21:12:53 - train: epoch 0077, iter [00600, 05004], lr: 0.029520, loss: 1.4692
2022-07-13 21:13:25 - train: epoch 0077, iter [00700, 05004], lr: 0.029496, loss: 1.6946
2022-07-13 21:13:59 - train: epoch 0077, iter [00800, 05004], lr: 0.029472, loss: 1.8245
2022-07-13 21:14:32 - train: epoch 0077, iter [00900, 05004], lr: 0.029448, loss: 1.8591
2022-07-13 21:15:06 - train: epoch 0077, iter [01000, 05004], lr: 0.029424, loss: 1.4710
2022-07-13 21:15:39 - train: epoch 0077, iter [01100, 05004], lr: 0.029401, loss: 1.6826
2022-07-13 21:16:12 - train: epoch 0077, iter [01200, 05004], lr: 0.029377, loss: 1.7653
2022-07-13 21:16:46 - train: epoch 0077, iter [01300, 05004], lr: 0.029353, loss: 1.2810
2022-07-13 21:17:19 - train: epoch 0077, iter [01400, 05004], lr: 0.029329, loss: 1.8032
2022-07-13 21:17:53 - train: epoch 0077, iter [01500, 05004], lr: 0.029305, loss: 1.5116
2022-07-13 21:18:25 - train: epoch 0077, iter [01600, 05004], lr: 0.029282, loss: 1.6637
2022-07-13 21:18:58 - train: epoch 0077, iter [01700, 05004], lr: 0.029258, loss: 2.0654
2022-07-13 21:19:32 - train: epoch 0077, iter [01800, 05004], lr: 0.029234, loss: 1.5878
2022-07-13 21:20:05 - train: epoch 0077, iter [01900, 05004], lr: 0.029210, loss: 1.6484
2022-07-13 21:20:38 - train: epoch 0077, iter [02000, 05004], lr: 0.029186, loss: 1.5033
2022-07-13 21:21:11 - train: epoch 0077, iter [02100, 05004], lr: 0.029163, loss: 1.7717
2022-07-13 21:21:45 - train: epoch 0077, iter [02200, 05004], lr: 0.029139, loss: 1.7048
2022-07-13 21:22:18 - train: epoch 0077, iter [02300, 05004], lr: 0.029115, loss: 1.9258
2022-07-13 21:22:52 - train: epoch 0077, iter [02400, 05004], lr: 0.029091, loss: 1.6163
2022-07-13 21:23:25 - train: epoch 0077, iter [02500, 05004], lr: 0.029067, loss: 1.9295
2022-07-13 21:23:58 - train: epoch 0077, iter [02600, 05004], lr: 0.029044, loss: 1.5696
2022-07-13 21:24:32 - train: epoch 0077, iter [02700, 05004], lr: 0.029020, loss: 1.6018
2022-07-13 21:25:05 - train: epoch 0077, iter [02800, 05004], lr: 0.028996, loss: 1.8414
2022-07-13 21:25:38 - train: epoch 0077, iter [02900, 05004], lr: 0.028973, loss: 1.9627
2022-07-13 21:26:11 - train: epoch 0077, iter [03000, 05004], lr: 0.028949, loss: 1.5525
2022-07-13 21:26:44 - train: epoch 0077, iter [03100, 05004], lr: 0.028925, loss: 1.6828
2022-07-13 21:27:18 - train: epoch 0077, iter [03200, 05004], lr: 0.028901, loss: 1.7348
2022-07-13 21:27:51 - train: epoch 0077, iter [03300, 05004], lr: 0.028878, loss: 1.5503
2022-07-13 21:28:24 - train: epoch 0077, iter [03400, 05004], lr: 0.028854, loss: 1.9758
2022-07-13 21:28:58 - train: epoch 0077, iter [03500, 05004], lr: 0.028830, loss: 1.4715
2022-07-13 21:29:32 - train: epoch 0077, iter [03600, 05004], lr: 0.028807, loss: 1.6507
2022-07-13 21:30:04 - train: epoch 0077, iter [03700, 05004], lr: 0.028783, loss: 1.6763
2022-07-13 21:30:37 - train: epoch 0077, iter [03800, 05004], lr: 0.028759, loss: 1.6441
2022-07-13 21:31:11 - train: epoch 0077, iter [03900, 05004], lr: 0.028735, loss: 1.6702
2022-07-13 21:31:45 - train: epoch 0077, iter [04000, 05004], lr: 0.028712, loss: 1.7271
2022-07-13 21:32:19 - train: epoch 0077, iter [04100, 05004], lr: 0.028688, loss: 1.7950
2022-07-13 21:32:52 - train: epoch 0077, iter [04200, 05004], lr: 0.028664, loss: 1.7633
2022-07-13 21:33:26 - train: epoch 0077, iter [04300, 05004], lr: 0.028641, loss: 1.5706
2022-07-13 21:34:00 - train: epoch 0077, iter [04400, 05004], lr: 0.028617, loss: 1.5685
2022-07-13 21:34:34 - train: epoch 0077, iter [04500, 05004], lr: 0.028594, loss: 1.8860
2022-07-13 21:35:08 - train: epoch 0077, iter [04600, 05004], lr: 0.028570, loss: 1.6339
2022-07-13 21:35:42 - train: epoch 0077, iter [04700, 05004], lr: 0.028546, loss: 1.4545
2022-07-13 21:36:16 - train: epoch 0077, iter [04800, 05004], lr: 0.028523, loss: 1.7109
2022-07-13 21:36:50 - train: epoch 0077, iter [04900, 05004], lr: 0.028499, loss: 1.8953
2022-07-13 21:37:22 - train: epoch 0077, iter [05000, 05004], lr: 0.028475, loss: 1.9569
2022-07-13 21:37:23 - train: epoch 077, train_loss: 1.6729
2022-07-13 21:38:38 - eval: epoch: 077, acc1: 64.910%, acc5: 86.654%, test_loss: 1.4517, per_image_load_time: 2.642ms, per_image_inference_time: 0.282ms
2022-07-13 21:38:39 - until epoch: 077, best_acc1: 64.910%
2022-07-13 21:38:39 - epoch 078 lr: 0.028474
2022-07-13 21:39:17 - train: epoch 0078, iter [00100, 05004], lr: 0.028451, loss: 1.6303
2022-07-13 21:39:51 - train: epoch 0078, iter [00200, 05004], lr: 0.028427, loss: 1.7993
2022-07-13 21:40:25 - train: epoch 0078, iter [00300, 05004], lr: 0.028404, loss: 1.6747
2022-07-13 21:41:00 - train: epoch 0078, iter [00400, 05004], lr: 0.028380, loss: 1.6193
2022-07-13 21:41:33 - train: epoch 0078, iter [00500, 05004], lr: 0.028356, loss: 1.5247
2022-07-13 21:42:06 - train: epoch 0078, iter [00600, 05004], lr: 0.028333, loss: 1.5675
2022-07-13 21:42:40 - train: epoch 0078, iter [00700, 05004], lr: 0.028309, loss: 1.6633
2022-07-13 21:43:14 - train: epoch 0078, iter [00800, 05004], lr: 0.028286, loss: 1.9013
2022-07-13 21:43:48 - train: epoch 0078, iter [00900, 05004], lr: 0.028262, loss: 1.8707
2022-07-13 21:44:21 - train: epoch 0078, iter [01000, 05004], lr: 0.028239, loss: 1.8224
2022-07-13 21:44:55 - train: epoch 0078, iter [01100, 05004], lr: 0.028215, loss: 1.4067
2022-07-13 21:45:28 - train: epoch 0078, iter [01200, 05004], lr: 0.028192, loss: 1.3719
2022-07-13 21:46:02 - train: epoch 0078, iter [01300, 05004], lr: 0.028168, loss: 1.6670
2022-07-13 21:46:37 - train: epoch 0078, iter [01400, 05004], lr: 0.028144, loss: 1.4638
2022-07-13 21:47:09 - train: epoch 0078, iter [01500, 05004], lr: 0.028121, loss: 1.6285
2022-07-13 21:47:44 - train: epoch 0078, iter [01600, 05004], lr: 0.028097, loss: 1.8438
2022-07-13 21:48:17 - train: epoch 0078, iter [01700, 05004], lr: 0.028074, loss: 1.6446
2022-07-13 21:48:52 - train: epoch 0078, iter [01800, 05004], lr: 0.028050, loss: 1.6024
2022-07-13 21:49:26 - train: epoch 0078, iter [01900, 05004], lr: 0.028027, loss: 1.4746
2022-07-13 21:50:00 - train: epoch 0078, iter [02000, 05004], lr: 0.028003, loss: 1.6173
2022-07-13 21:50:34 - train: epoch 0078, iter [02100, 05004], lr: 0.027980, loss: 2.0319
2022-07-13 21:51:08 - train: epoch 0078, iter [02200, 05004], lr: 0.027956, loss: 1.6691
2022-07-13 21:51:43 - train: epoch 0078, iter [02300, 05004], lr: 0.027933, loss: 1.7937
2022-07-13 21:52:17 - train: epoch 0078, iter [02400, 05004], lr: 0.027909, loss: 1.5998
2022-07-13 21:52:52 - train: epoch 0078, iter [02500, 05004], lr: 0.027886, loss: 1.7215
2022-07-13 21:53:27 - train: epoch 0078, iter [02600, 05004], lr: 0.027863, loss: 1.5963
2022-07-13 21:54:02 - train: epoch 0078, iter [02700, 05004], lr: 0.027839, loss: 1.4892
2022-07-13 21:54:35 - train: epoch 0078, iter [02800, 05004], lr: 0.027816, loss: 1.6728
2022-07-13 21:55:10 - train: epoch 0078, iter [02900, 05004], lr: 0.027792, loss: 1.5418
2022-07-13 21:55:45 - train: epoch 0078, iter [03000, 05004], lr: 0.027769, loss: 1.6926
2022-07-13 21:56:20 - train: epoch 0078, iter [03100, 05004], lr: 0.027745, loss: 1.8020
2022-07-13 21:56:53 - train: epoch 0078, iter [03200, 05004], lr: 0.027722, loss: 1.7276
2022-07-13 21:57:28 - train: epoch 0078, iter [03300, 05004], lr: 0.027699, loss: 1.7998
2022-07-13 21:58:02 - train: epoch 0078, iter [03400, 05004], lr: 0.027675, loss: 1.6050
2022-07-13 21:58:38 - train: epoch 0078, iter [03500, 05004], lr: 0.027652, loss: 1.5752
2022-07-13 21:59:13 - train: epoch 0078, iter [03600, 05004], lr: 0.027628, loss: 1.7060
2022-07-13 21:59:47 - train: epoch 0078, iter [03700, 05004], lr: 0.027605, loss: 1.5561
2022-07-13 22:00:21 - train: epoch 0078, iter [03800, 05004], lr: 0.027582, loss: 1.5474
2022-07-13 22:00:55 - train: epoch 0078, iter [03900, 05004], lr: 0.027558, loss: 1.6942
2022-07-13 22:01:30 - train: epoch 0078, iter [04000, 05004], lr: 0.027535, loss: 1.6113
2022-07-13 22:02:05 - train: epoch 0078, iter [04100, 05004], lr: 0.027511, loss: 1.8204
2022-07-13 22:02:39 - train: epoch 0078, iter [04200, 05004], lr: 0.027488, loss: 1.8182
2022-07-13 22:03:14 - train: epoch 0078, iter [04300, 05004], lr: 0.027465, loss: 1.5915
2022-07-13 22:03:49 - train: epoch 0078, iter [04400, 05004], lr: 0.027441, loss: 1.6108
2022-07-13 22:04:22 - train: epoch 0078, iter [04500, 05004], lr: 0.027418, loss: 1.6852
2022-07-13 22:04:56 - train: epoch 0078, iter [04600, 05004], lr: 0.027395, loss: 1.4401
2022-07-13 22:05:29 - train: epoch 0078, iter [04700, 05004], lr: 0.027371, loss: 1.7771
2022-07-13 22:06:02 - train: epoch 0078, iter [04800, 05004], lr: 0.027348, loss: 1.8513
2022-07-13 22:06:34 - train: epoch 0078, iter [04900, 05004], lr: 0.027325, loss: 1.7646
2022-07-13 22:07:07 - train: epoch 0078, iter [05000, 05004], lr: 0.027301, loss: 1.5967
2022-07-13 22:07:08 - train: epoch 078, train_loss: 1.6571
2022-07-13 22:08:21 - eval: epoch: 078, acc1: 65.036%, acc5: 86.612%, test_loss: 1.4412, per_image_load_time: 1.698ms, per_image_inference_time: 0.282ms
2022-07-13 22:08:21 - until epoch: 078, best_acc1: 65.036%
2022-07-13 22:08:21 - epoch 079 lr: 0.027300
2022-07-13 22:08:59 - train: epoch 0079, iter [00100, 05004], lr: 0.027277, loss: 1.5631
2022-07-13 22:09:32 - train: epoch 0079, iter [00200, 05004], lr: 0.027254, loss: 1.5727
2022-07-13 22:10:04 - train: epoch 0079, iter [00300, 05004], lr: 0.027231, loss: 1.6370
2022-07-13 22:10:37 - train: epoch 0079, iter [00400, 05004], lr: 0.027207, loss: 1.7662
2022-07-13 22:11:12 - train: epoch 0079, iter [00500, 05004], lr: 0.027184, loss: 1.6411
2022-07-13 22:11:44 - train: epoch 0079, iter [00600, 05004], lr: 0.027161, loss: 1.5342
2022-07-13 22:12:17 - train: epoch 0079, iter [00700, 05004], lr: 0.027137, loss: 1.5687
2022-07-13 22:12:50 - train: epoch 0079, iter [00800, 05004], lr: 0.027114, loss: 1.6976
2022-07-13 22:13:22 - train: epoch 0079, iter [00900, 05004], lr: 0.027091, loss: 1.4953
2022-07-13 22:13:56 - train: epoch 0079, iter [01000, 05004], lr: 0.027068, loss: 1.5414
2022-07-13 22:14:29 - train: epoch 0079, iter [01100, 05004], lr: 0.027044, loss: 1.8288
2022-07-13 22:15:02 - train: epoch 0079, iter [01200, 05004], lr: 0.027021, loss: 1.9048
2022-07-13 22:15:34 - train: epoch 0079, iter [01300, 05004], lr: 0.026998, loss: 1.3973
2022-07-13 22:16:07 - train: epoch 0079, iter [01400, 05004], lr: 0.026975, loss: 1.5568
2022-07-13 22:16:40 - train: epoch 0079, iter [01500, 05004], lr: 0.026952, loss: 1.4596
2022-07-13 22:17:13 - train: epoch 0079, iter [01600, 05004], lr: 0.026928, loss: 1.3190
2022-07-13 22:17:47 - train: epoch 0079, iter [01700, 05004], lr: 0.026905, loss: 1.6469
2022-07-13 22:18:20 - train: epoch 0079, iter [01800, 05004], lr: 0.026882, loss: 1.5757
2022-07-13 22:18:53 - train: epoch 0079, iter [01900, 05004], lr: 0.026859, loss: 1.6757
2022-07-13 22:19:26 - train: epoch 0079, iter [02000, 05004], lr: 0.026836, loss: 1.8318
2022-07-13 22:19:58 - train: epoch 0079, iter [02100, 05004], lr: 0.026812, loss: 1.4615
2022-07-13 22:20:32 - train: epoch 0079, iter [02200, 05004], lr: 0.026789, loss: 1.7486
2022-07-13 22:21:06 - train: epoch 0079, iter [02300, 05004], lr: 0.026766, loss: 1.5651
2022-07-13 22:21:39 - train: epoch 0079, iter [02400, 05004], lr: 0.026743, loss: 1.6310
2022-07-13 22:22:11 - train: epoch 0079, iter [02500, 05004], lr: 0.026720, loss: 1.6108
2022-07-13 22:22:44 - train: epoch 0079, iter [02600, 05004], lr: 0.026697, loss: 1.5792
2022-07-13 22:23:17 - train: epoch 0079, iter [02700, 05004], lr: 0.026673, loss: 1.3792
2022-07-13 22:23:50 - train: epoch 0079, iter [02800, 05004], lr: 0.026650, loss: 1.4658
2022-07-13 22:24:23 - train: epoch 0079, iter [02900, 05004], lr: 0.026627, loss: 1.4970
2022-07-13 22:24:56 - train: epoch 0079, iter [03000, 05004], lr: 0.026604, loss: 1.6298
2022-07-13 22:25:29 - train: epoch 0079, iter [03100, 05004], lr: 0.026581, loss: 1.6508
2022-07-13 22:26:02 - train: epoch 0079, iter [03200, 05004], lr: 0.026558, loss: 1.9747
2022-07-13 22:26:35 - train: epoch 0079, iter [03300, 05004], lr: 0.026535, loss: 1.6541
2022-07-13 22:27:08 - train: epoch 0079, iter [03400, 05004], lr: 0.026512, loss: 1.5003
2022-07-13 22:27:41 - train: epoch 0079, iter [03500, 05004], lr: 0.026489, loss: 1.8475
2022-07-13 22:28:14 - train: epoch 0079, iter [03600, 05004], lr: 0.026465, loss: 1.5797
2022-07-13 22:28:46 - train: epoch 0079, iter [03700, 05004], lr: 0.026442, loss: 1.5801
2022-07-13 22:29:20 - train: epoch 0079, iter [03800, 05004], lr: 0.026419, loss: 1.6821
2022-07-13 22:29:52 - train: epoch 0079, iter [03900, 05004], lr: 0.026396, loss: 1.5123
2022-07-13 22:30:25 - train: epoch 0079, iter [04000, 05004], lr: 0.026373, loss: 1.5165
2022-07-13 22:30:58 - train: epoch 0079, iter [04100, 05004], lr: 0.026350, loss: 1.8380
2022-07-13 22:31:31 - train: epoch 0079, iter [04200, 05004], lr: 0.026327, loss: 1.5271
2022-07-13 22:32:04 - train: epoch 0079, iter [04300, 05004], lr: 0.026304, loss: 1.2643
2022-07-13 22:32:37 - train: epoch 0079, iter [04400, 05004], lr: 0.026281, loss: 1.8436
2022-07-13 22:33:10 - train: epoch 0079, iter [04500, 05004], lr: 0.026258, loss: 1.9644
2022-07-13 22:33:43 - train: epoch 0079, iter [04600, 05004], lr: 0.026235, loss: 1.8942
2022-07-13 22:34:15 - train: epoch 0079, iter [04700, 05004], lr: 0.026212, loss: 1.6852
2022-07-13 22:34:48 - train: epoch 0079, iter [04800, 05004], lr: 0.026189, loss: 1.7902
2022-07-13 22:35:20 - train: epoch 0079, iter [04900, 05004], lr: 0.026166, loss: 1.7582
2022-07-13 22:35:52 - train: epoch 0079, iter [05000, 05004], lr: 0.026143, loss: 1.4384
2022-07-13 22:35:53 - train: epoch 079, train_loss: 1.6468
2022-07-13 22:37:06 - eval: epoch: 079, acc1: 64.970%, acc5: 86.702%, test_loss: 1.4436, per_image_load_time: 2.050ms, per_image_inference_time: 0.286ms
2022-07-13 22:37:07 - until epoch: 079, best_acc1: 65.036%
2022-07-13 22:37:07 - epoch 080 lr: 0.026142
2022-07-13 22:37:45 - train: epoch 0080, iter [00100, 05004], lr: 0.026119, loss: 1.5270
2022-07-13 22:38:18 - train: epoch 0080, iter [00200, 05004], lr: 0.026096, loss: 1.5712
2022-07-13 22:38:51 - train: epoch 0080, iter [00300, 05004], lr: 0.026073, loss: 1.6571
2022-07-13 22:39:24 - train: epoch 0080, iter [00400, 05004], lr: 0.026050, loss: 1.5240
2022-07-13 22:39:57 - train: epoch 0080, iter [00500, 05004], lr: 0.026027, loss: 1.6710
2022-07-13 22:40:30 - train: epoch 0080, iter [00600, 05004], lr: 0.026004, loss: 1.5003
2022-07-13 22:41:02 - train: epoch 0080, iter [00700, 05004], lr: 0.025981, loss: 1.5469
2022-07-13 22:41:35 - train: epoch 0080, iter [00800, 05004], lr: 0.025958, loss: 1.5050
2022-07-13 22:42:08 - train: epoch 0080, iter [00900, 05004], lr: 0.025935, loss: 1.6366
2022-07-13 22:42:41 - train: epoch 0080, iter [01000, 05004], lr: 0.025912, loss: 1.5528
2022-07-13 22:43:13 - train: epoch 0080, iter [01100, 05004], lr: 0.025890, loss: 1.6976
2022-07-13 22:43:46 - train: epoch 0080, iter [01200, 05004], lr: 0.025867, loss: 1.6316
2022-07-13 22:44:20 - train: epoch 0080, iter [01300, 05004], lr: 0.025844, loss: 1.6068
2022-07-13 22:44:53 - train: epoch 0080, iter [01400, 05004], lr: 0.025821, loss: 1.5603
2022-07-13 22:45:25 - train: epoch 0080, iter [01500, 05004], lr: 0.025798, loss: 1.5259
2022-07-13 22:45:58 - train: epoch 0080, iter [01600, 05004], lr: 0.025775, loss: 1.5432
2022-07-13 22:46:32 - train: epoch 0080, iter [01700, 05004], lr: 0.025752, loss: 1.6940
2022-07-13 22:47:04 - train: epoch 0080, iter [01800, 05004], lr: 0.025729, loss: 1.7427
2022-07-13 22:47:37 - train: epoch 0080, iter [01900, 05004], lr: 0.025706, loss: 1.6095
2022-07-13 22:48:10 - train: epoch 0080, iter [02000, 05004], lr: 0.025684, loss: 1.6921
2022-07-13 22:48:44 - train: epoch 0080, iter [02100, 05004], lr: 0.025661, loss: 1.7525
2022-07-13 22:49:16 - train: epoch 0080, iter [02200, 05004], lr: 0.025638, loss: 1.6747
2022-07-13 22:49:49 - train: epoch 0080, iter [02300, 05004], lr: 0.025615, loss: 1.5321
2022-07-13 22:50:23 - train: epoch 0080, iter [02400, 05004], lr: 0.025592, loss: 1.6993
2022-07-13 22:50:55 - train: epoch 0080, iter [02500, 05004], lr: 0.025569, loss: 1.5317
2022-07-13 22:51:29 - train: epoch 0080, iter [02600, 05004], lr: 0.025547, loss: 1.6586
2022-07-13 22:52:01 - train: epoch 0080, iter [02700, 05004], lr: 0.025524, loss: 1.7397
2022-07-13 22:52:35 - train: epoch 0080, iter [02800, 05004], lr: 0.025501, loss: 1.7418
2022-07-13 22:53:08 - train: epoch 0080, iter [02900, 05004], lr: 0.025478, loss: 1.5504
2022-07-13 22:53:41 - train: epoch 0080, iter [03000, 05004], lr: 0.025455, loss: 1.5948
2022-07-13 22:54:15 - train: epoch 0080, iter [03100, 05004], lr: 0.025433, loss: 1.8719
2022-07-13 22:54:48 - train: epoch 0080, iter [03200, 05004], lr: 0.025410, loss: 1.2507
2022-07-13 22:55:21 - train: epoch 0080, iter [03300, 05004], lr: 0.025387, loss: 1.6325
2022-07-13 22:55:54 - train: epoch 0080, iter [03400, 05004], lr: 0.025364, loss: 1.5821
2022-07-13 22:56:26 - train: epoch 0080, iter [03500, 05004], lr: 0.025341, loss: 1.3591
2022-07-13 22:57:00 - train: epoch 0080, iter [03600, 05004], lr: 0.025319, loss: 1.6421
2022-07-13 22:57:32 - train: epoch 0080, iter [03700, 05004], lr: 0.025296, loss: 1.5879
2022-07-13 22:58:05 - train: epoch 0080, iter [03800, 05004], lr: 0.025273, loss: 1.7742
2022-07-13 22:58:39 - train: epoch 0080, iter [03900, 05004], lr: 0.025251, loss: 1.5755
2022-07-13 22:59:11 - train: epoch 0080, iter [04000, 05004], lr: 0.025228, loss: 1.7852
2022-07-13 22:59:44 - train: epoch 0080, iter [04100, 05004], lr: 0.025205, loss: 1.7963
2022-07-13 23:00:17 - train: epoch 0080, iter [04200, 05004], lr: 0.025182, loss: 1.5765
2022-07-13 23:00:50 - train: epoch 0080, iter [04300, 05004], lr: 0.025160, loss: 1.8522
2022-07-13 23:01:23 - train: epoch 0080, iter [04400, 05004], lr: 0.025137, loss: 1.7306
2022-07-13 23:01:57 - train: epoch 0080, iter [04500, 05004], lr: 0.025114, loss: 1.5688
2022-07-13 23:02:31 - train: epoch 0080, iter [04600, 05004], lr: 0.025092, loss: 1.7098
2022-07-13 23:03:04 - train: epoch 0080, iter [04700, 05004], lr: 0.025069, loss: 1.6997
2022-07-13 23:03:39 - train: epoch 0080, iter [04800, 05004], lr: 0.025046, loss: 1.7154
2022-07-13 23:04:13 - train: epoch 0080, iter [04900, 05004], lr: 0.025024, loss: 1.7994
2022-07-13 23:04:47 - train: epoch 0080, iter [05000, 05004], lr: 0.025001, loss: 1.4974
2022-07-13 23:04:48 - train: epoch 080, train_loss: 1.6341
2022-07-13 23:06:05 - eval: epoch: 080, acc1: 65.716%, acc5: 87.040%, test_loss: 1.4077, per_image_load_time: 2.696ms, per_image_inference_time: 0.303ms
2022-07-13 23:06:05 - until epoch: 080, best_acc1: 65.716%
2022-07-13 23:06:05 - epoch 081 lr: 0.025000
2022-07-13 23:06:44 - train: epoch 0081, iter [00100, 05004], lr: 0.024977, loss: 1.5003
2022-07-13 23:07:19 - train: epoch 0081, iter [00200, 05004], lr: 0.024955, loss: 1.6871
2022-07-13 23:07:53 - train: epoch 0081, iter [00300, 05004], lr: 0.024932, loss: 1.6258
2022-07-13 23:08:28 - train: epoch 0081, iter [00400, 05004], lr: 0.024909, loss: 1.7892
2022-07-13 23:09:03 - train: epoch 0081, iter [00500, 05004], lr: 0.024887, loss: 1.6875
2022-07-13 23:09:36 - train: epoch 0081, iter [00600, 05004], lr: 0.024864, loss: 1.6265
2022-07-13 23:10:10 - train: epoch 0081, iter [00700, 05004], lr: 0.024842, loss: 1.5394
2022-07-13 23:10:44 - train: epoch 0081, iter [00800, 05004], lr: 0.024819, loss: 1.8239
2022-07-13 23:11:18 - train: epoch 0081, iter [00900, 05004], lr: 0.024796, loss: 1.5722
2022-07-13 23:11:52 - train: epoch 0081, iter [01000, 05004], lr: 0.024774, loss: 1.5884
2022-07-13 23:12:25 - train: epoch 0081, iter [01100, 05004], lr: 0.024751, loss: 1.5343
2022-07-13 23:13:00 - train: epoch 0081, iter [01200, 05004], lr: 0.024729, loss: 1.6395
2022-07-13 23:13:33 - train: epoch 0081, iter [01300, 05004], lr: 0.024706, loss: 1.4924
2022-07-13 23:14:07 - train: epoch 0081, iter [01400, 05004], lr: 0.024684, loss: 1.3300
2022-07-13 23:14:40 - train: epoch 0081, iter [01500, 05004], lr: 0.024661, loss: 1.6855
2022-07-13 23:15:14 - train: epoch 0081, iter [01600, 05004], lr: 0.024638, loss: 1.4350
2022-07-13 23:15:48 - train: epoch 0081, iter [01700, 05004], lr: 0.024616, loss: 1.7028
2022-07-13 23:16:22 - train: epoch 0081, iter [01800, 05004], lr: 0.024593, loss: 1.5950
2022-07-13 23:16:55 - train: epoch 0081, iter [01900, 05004], lr: 0.024571, loss: 1.5746
2022-07-13 23:17:29 - train: epoch 0081, iter [02000, 05004], lr: 0.024548, loss: 1.7107
2022-07-13 23:18:02 - train: epoch 0081, iter [02100, 05004], lr: 0.024526, loss: 1.6404
2022-07-13 23:18:35 - train: epoch 0081, iter [02200, 05004], lr: 0.024503, loss: 1.5783
2022-07-13 23:19:09 - train: epoch 0081, iter [02300, 05004], lr: 0.024481, loss: 1.6190
2022-07-13 23:19:42 - train: epoch 0081, iter [02400, 05004], lr: 0.024458, loss: 1.6301
2022-07-13 23:20:16 - train: epoch 0081, iter [02500, 05004], lr: 0.024436, loss: 1.7941
2022-07-13 23:20:49 - train: epoch 0081, iter [02600, 05004], lr: 0.024413, loss: 1.8974
2022-07-13 23:21:23 - train: epoch 0081, iter [02700, 05004], lr: 0.024391, loss: 1.6015
2022-07-13 23:21:56 - train: epoch 0081, iter [02800, 05004], lr: 0.024368, loss: 1.6021
2022-07-13 23:22:31 - train: epoch 0081, iter [02900, 05004], lr: 0.024346, loss: 1.4725
2022-07-13 23:23:03 - train: epoch 0081, iter [03000, 05004], lr: 0.024323, loss: 1.6419
2022-07-13 23:23:37 - train: epoch 0081, iter [03100, 05004], lr: 0.024301, loss: 1.5401
2022-07-13 23:24:09 - train: epoch 0081, iter [03200, 05004], lr: 0.024279, loss: 1.5910
2022-07-13 23:24:44 - train: epoch 0081, iter [03300, 05004], lr: 0.024256, loss: 1.6377
2022-07-13 23:25:17 - train: epoch 0081, iter [03400, 05004], lr: 0.024234, loss: 1.7684
2022-07-13 23:25:51 - train: epoch 0081, iter [03500, 05004], lr: 0.024211, loss: 1.6905
2022-07-13 23:26:24 - train: epoch 0081, iter [03600, 05004], lr: 0.024189, loss: 1.4458
2022-07-13 23:26:59 - train: epoch 0081, iter [03700, 05004], lr: 0.024167, loss: 1.8426
2022-07-13 23:27:31 - train: epoch 0081, iter [03800, 05004], lr: 0.024144, loss: 1.4781
2022-07-13 23:28:04 - train: epoch 0081, iter [03900, 05004], lr: 0.024122, loss: 1.6305
2022-07-13 23:28:38 - train: epoch 0081, iter [04000, 05004], lr: 0.024099, loss: 1.5011
2022-07-13 23:29:12 - train: epoch 0081, iter [04100, 05004], lr: 0.024077, loss: 1.6354
2022-07-13 23:29:46 - train: epoch 0081, iter [04200, 05004], lr: 0.024055, loss: 1.7097
2022-07-13 23:30:19 - train: epoch 0081, iter [04300, 05004], lr: 0.024032, loss: 1.5663
2022-07-13 23:30:52 - train: epoch 0081, iter [04400, 05004], lr: 0.024010, loss: 1.7139
2022-07-13 23:31:26 - train: epoch 0081, iter [04500, 05004], lr: 0.023988, loss: 1.7985
2022-07-13 23:31:59 - train: epoch 0081, iter [04600, 05004], lr: 0.023965, loss: 1.4718
2022-07-13 23:32:33 - train: epoch 0081, iter [04700, 05004], lr: 0.023943, loss: 1.6758
2022-07-13 23:33:06 - train: epoch 0081, iter [04800, 05004], lr: 0.023921, loss: 1.6794
2022-07-13 23:33:40 - train: epoch 0081, iter [04900, 05004], lr: 0.023898, loss: 1.6571
2022-07-13 23:34:12 - train: epoch 0081, iter [05000, 05004], lr: 0.023876, loss: 1.4283
2022-07-13 23:34:13 - train: epoch 081, train_loss: 1.6177
2022-07-13 23:35:28 - eval: epoch: 081, acc1: 65.980%, acc5: 87.020%, test_loss: 1.4150, per_image_load_time: 2.651ms, per_image_inference_time: 0.283ms
2022-07-13 23:35:28 - until epoch: 081, best_acc1: 65.980%
2022-07-13 23:35:28 - epoch 082 lr: 0.023875
2022-07-13 23:36:07 - train: epoch 0082, iter [00100, 05004], lr: 0.023853, loss: 1.3497
2022-07-13 23:36:41 - train: epoch 0082, iter [00200, 05004], lr: 0.023830, loss: 1.4546
2022-07-13 23:37:14 - train: epoch 0082, iter [00300, 05004], lr: 0.023808, loss: 1.5855
2022-07-13 23:37:48 - train: epoch 0082, iter [00400, 05004], lr: 0.023786, loss: 1.6171
2022-07-13 23:38:20 - train: epoch 0082, iter [00500, 05004], lr: 0.023764, loss: 1.6746
2022-07-13 23:38:54 - train: epoch 0082, iter [00600, 05004], lr: 0.023741, loss: 1.3759
2022-07-13 23:39:27 - train: epoch 0082, iter [00700, 05004], lr: 0.023719, loss: 1.8051
2022-07-13 23:40:01 - train: epoch 0082, iter [00800, 05004], lr: 0.023697, loss: 1.6199
2022-07-13 23:40:34 - train: epoch 0082, iter [00900, 05004], lr: 0.023675, loss: 1.8393
2022-07-13 23:41:07 - train: epoch 0082, iter [01000, 05004], lr: 0.023652, loss: 1.6233
2022-07-13 23:41:40 - train: epoch 0082, iter [01100, 05004], lr: 0.023630, loss: 1.7442
2022-07-13 23:42:14 - train: epoch 0082, iter [01200, 05004], lr: 0.023608, loss: 1.5450
2022-07-13 23:42:48 - train: epoch 0082, iter [01300, 05004], lr: 0.023586, loss: 1.8063
2022-07-13 23:43:20 - train: epoch 0082, iter [01400, 05004], lr: 0.023564, loss: 1.5456
2022-07-13 23:43:54 - train: epoch 0082, iter [01500, 05004], lr: 0.023541, loss: 1.4490
2022-07-13 23:44:29 - train: epoch 0082, iter [01600, 05004], lr: 0.023519, loss: 1.6441
2022-07-13 23:45:02 - train: epoch 0082, iter [01700, 05004], lr: 0.023497, loss: 1.5311
2022-07-13 23:45:35 - train: epoch 0082, iter [01800, 05004], lr: 0.023475, loss: 1.4235
2022-07-13 23:46:09 - train: epoch 0082, iter [01900, 05004], lr: 0.023453, loss: 1.4999
2022-07-13 23:46:43 - train: epoch 0082, iter [02000, 05004], lr: 0.023430, loss: 1.2896
2022-07-13 23:47:16 - train: epoch 0082, iter [02100, 05004], lr: 0.023408, loss: 1.4995
2022-07-13 23:47:48 - train: epoch 0082, iter [02200, 05004], lr: 0.023386, loss: 1.6168
2022-07-13 23:48:23 - train: epoch 0082, iter [02300, 05004], lr: 0.023364, loss: 1.5791
2022-07-13 23:48:55 - train: epoch 0082, iter [02400, 05004], lr: 0.023342, loss: 1.7260
2022-07-13 23:49:30 - train: epoch 0082, iter [02500, 05004], lr: 0.023320, loss: 1.5338
2022-07-13 23:50:03 - train: epoch 0082, iter [02600, 05004], lr: 0.023298, loss: 1.4943
2022-07-13 23:50:37 - train: epoch 0082, iter [02700, 05004], lr: 0.023275, loss: 1.5342
2022-07-13 23:51:09 - train: epoch 0082, iter [02800, 05004], lr: 0.023253, loss: 1.3852
2022-07-13 23:51:43 - train: epoch 0082, iter [02900, 05004], lr: 0.023231, loss: 1.4183
2022-07-13 23:52:17 - train: epoch 0082, iter [03000, 05004], lr: 0.023209, loss: 1.6340
2022-07-13 23:52:50 - train: epoch 0082, iter [03100, 05004], lr: 0.023187, loss: 1.5179
2022-07-13 23:53:23 - train: epoch 0082, iter [03200, 05004], lr: 0.023165, loss: 1.8050
2022-07-13 23:53:58 - train: epoch 0082, iter [03300, 05004], lr: 0.023143, loss: 1.5211
2022-07-13 23:54:31 - train: epoch 0082, iter [03400, 05004], lr: 0.023121, loss: 1.5921
2022-07-13 23:55:05 - train: epoch 0082, iter [03500, 05004], lr: 0.023099, loss: 1.5545
2022-07-13 23:55:37 - train: epoch 0082, iter [03600, 05004], lr: 0.023077, loss: 1.4786
2022-07-13 23:56:12 - train: epoch 0082, iter [03700, 05004], lr: 0.023055, loss: 1.5599
2022-07-13 23:56:45 - train: epoch 0082, iter [03800, 05004], lr: 0.023033, loss: 1.8185
2022-07-13 23:57:19 - train: epoch 0082, iter [03900, 05004], lr: 0.023011, loss: 1.5918
2022-07-13 23:57:54 - train: epoch 0082, iter [04000, 05004], lr: 0.022989, loss: 1.6293
2022-07-13 23:58:26 - train: epoch 0082, iter [04100, 05004], lr: 0.022967, loss: 1.5992
2022-07-13 23:59:01 - train: epoch 0082, iter [04200, 05004], lr: 0.022945, loss: 1.8094
2022-07-13 23:59:35 - train: epoch 0082, iter [04300, 05004], lr: 0.022923, loss: 1.4661
2022-07-14 00:00:09 - train: epoch 0082, iter [04400, 05004], lr: 0.022901, loss: 1.5543
2022-07-14 00:00:42 - train: epoch 0082, iter [04500, 05004], lr: 0.022879, loss: 1.6730
2022-07-14 00:01:16 - train: epoch 0082, iter [04600, 05004], lr: 0.022857, loss: 1.5549
2022-07-14 00:01:50 - train: epoch 0082, iter [04700, 05004], lr: 0.022835, loss: 1.4696
2022-07-14 00:02:25 - train: epoch 0082, iter [04800, 05004], lr: 0.022813, loss: 1.5046
2022-07-14 00:02:58 - train: epoch 0082, iter [04900, 05004], lr: 0.022791, loss: 1.6640
2022-07-14 00:03:31 - train: epoch 0082, iter [05000, 05004], lr: 0.022769, loss: 1.5398
2022-07-14 00:03:32 - train: epoch 082, train_loss: 1.6020
2022-07-14 00:04:48 - eval: epoch: 082, acc1: 66.126%, acc5: 87.312%, test_loss: 1.3951, per_image_load_time: 2.518ms, per_image_inference_time: 0.304ms
2022-07-14 00:04:48 - until epoch: 082, best_acc1: 66.126%
2022-07-14 00:04:48 - epoch 083 lr: 0.022768
2022-07-14 00:05:27 - train: epoch 0083, iter [00100, 05004], lr: 0.022746, loss: 1.5423
2022-07-14 00:06:02 - train: epoch 0083, iter [00200, 05004], lr: 0.022724, loss: 1.5330
2022-07-14 00:06:36 - train: epoch 0083, iter [00300, 05004], lr: 0.022702, loss: 1.5803
2022-07-14 00:07:10 - train: epoch 0083, iter [00400, 05004], lr: 0.022680, loss: 1.7203
2022-07-14 00:07:45 - train: epoch 0083, iter [00500, 05004], lr: 0.022658, loss: 1.6221
2022-07-14 00:08:19 - train: epoch 0083, iter [00600, 05004], lr: 0.022637, loss: 1.5081
2022-07-14 00:08:54 - train: epoch 0083, iter [00700, 05004], lr: 0.022615, loss: 1.5479
2022-07-14 00:09:29 - train: epoch 0083, iter [00800, 05004], lr: 0.022593, loss: 1.5992
2022-07-14 00:10:02 - train: epoch 0083, iter [00900, 05004], lr: 0.022571, loss: 1.6830
2022-07-14 00:10:37 - train: epoch 0083, iter [01000, 05004], lr: 0.022549, loss: 1.7499
2022-07-14 00:11:12 - train: epoch 0083, iter [01100, 05004], lr: 0.022527, loss: 1.5748
2022-07-14 00:11:45 - train: epoch 0083, iter [01200, 05004], lr: 0.022505, loss: 1.5020
2022-07-14 00:12:19 - train: epoch 0083, iter [01300, 05004], lr: 0.022483, loss: 1.4699
2022-07-14 00:12:55 - train: epoch 0083, iter [01400, 05004], lr: 0.022462, loss: 1.6409
2022-07-14 00:13:28 - train: epoch 0083, iter [01500, 05004], lr: 0.022440, loss: 1.4498
2022-07-14 00:14:03 - train: epoch 0083, iter [01600, 05004], lr: 0.022418, loss: 1.6980
2022-07-14 00:14:37 - train: epoch 0083, iter [01700, 05004], lr: 0.022396, loss: 1.7015
2022-07-14 00:15:12 - train: epoch 0083, iter [01800, 05004], lr: 0.022374, loss: 1.8977
2022-07-14 00:15:46 - train: epoch 0083, iter [01900, 05004], lr: 0.022353, loss: 1.4036
2022-07-14 00:16:21 - train: epoch 0083, iter [02000, 05004], lr: 0.022331, loss: 1.3283
2022-07-14 00:16:55 - train: epoch 0083, iter [02100, 05004], lr: 0.022309, loss: 1.4738
2022-07-14 00:17:30 - train: epoch 0083, iter [02200, 05004], lr: 0.022287, loss: 1.5763
2022-07-14 00:18:04 - train: epoch 0083, iter [02300, 05004], lr: 0.022265, loss: 1.7345
2022-07-14 00:18:39 - train: epoch 0083, iter [02400, 05004], lr: 0.022244, loss: 1.4866
2022-07-14 00:19:14 - train: epoch 0083, iter [02500, 05004], lr: 0.022222, loss: 1.6160
2022-07-14 00:19:48 - train: epoch 0083, iter [02600, 05004], lr: 0.022200, loss: 1.5186
2022-07-14 00:20:23 - train: epoch 0083, iter [02700, 05004], lr: 0.022178, loss: 1.5608
2022-07-14 00:20:56 - train: epoch 0083, iter [02800, 05004], lr: 0.022157, loss: 1.4941
2022-07-14 00:21:31 - train: epoch 0083, iter [02900, 05004], lr: 0.022135, loss: 1.6178
2022-07-14 00:22:04 - train: epoch 0083, iter [03000, 05004], lr: 0.022113, loss: 1.7216
2022-07-14 00:22:40 - train: epoch 0083, iter [03100, 05004], lr: 0.022092, loss: 1.4828
2022-07-14 00:23:14 - train: epoch 0083, iter [03200, 05004], lr: 0.022070, loss: 1.4013
2022-07-14 00:23:49 - train: epoch 0083, iter [03300, 05004], lr: 0.022048, loss: 1.7456
2022-07-14 00:24:24 - train: epoch 0083, iter [03400, 05004], lr: 0.022026, loss: 1.7017
2022-07-14 00:24:59 - train: epoch 0083, iter [03500, 05004], lr: 0.022005, loss: 1.6729
2022-07-14 00:25:33 - train: epoch 0083, iter [03600, 05004], lr: 0.021983, loss: 1.6805
2022-07-14 00:26:08 - train: epoch 0083, iter [03700, 05004], lr: 0.021961, loss: 1.6061
2022-07-14 00:26:44 - train: epoch 0083, iter [03800, 05004], lr: 0.021940, loss: 1.4868
2022-07-14 00:27:18 - train: epoch 0083, iter [03900, 05004], lr: 0.021918, loss: 1.6603
2022-07-14 00:27:52 - train: epoch 0083, iter [04000, 05004], lr: 0.021897, loss: 1.7561
2022-07-14 00:28:27 - train: epoch 0083, iter [04100, 05004], lr: 0.021875, loss: 1.5459
2022-07-14 00:29:01 - train: epoch 0083, iter [04200, 05004], lr: 0.021853, loss: 1.9690
2022-07-14 00:29:36 - train: epoch 0083, iter [04300, 05004], lr: 0.021832, loss: 1.6681
2022-07-14 00:30:10 - train: epoch 0083, iter [04400, 05004], lr: 0.021810, loss: 1.4594
2022-07-14 00:30:44 - train: epoch 0083, iter [04500, 05004], lr: 0.021788, loss: 1.6810
2022-07-14 00:31:19 - train: epoch 0083, iter [04600, 05004], lr: 0.021767, loss: 1.6424
2022-07-14 00:31:52 - train: epoch 0083, iter [04700, 05004], lr: 0.021745, loss: 1.7154
2022-07-14 00:32:27 - train: epoch 0083, iter [04800, 05004], lr: 0.021724, loss: 1.7064
2022-07-14 00:33:00 - train: epoch 0083, iter [04900, 05004], lr: 0.021702, loss: 1.8217
2022-07-14 00:33:33 - train: epoch 0083, iter [05000, 05004], lr: 0.021681, loss: 1.6575
2022-07-14 00:33:33 - train: epoch 083, train_loss: 1.5894
2022-07-14 00:34:49 - eval: epoch: 083, acc1: 66.044%, acc5: 87.212%, test_loss: 1.3986, per_image_load_time: 2.327ms, per_image_inference_time: 0.301ms
2022-07-14 00:34:49 - until epoch: 083, best_acc1: 66.126%
2022-07-14 00:34:49 - epoch 084 lr: 0.021679
2022-07-14 00:35:28 - train: epoch 0084, iter [00100, 05004], lr: 0.021658, loss: 1.5385
2022-07-14 00:36:02 - train: epoch 0084, iter [00200, 05004], lr: 0.021637, loss: 1.6163
2022-07-14 00:36:35 - train: epoch 0084, iter [00300, 05004], lr: 0.021615, loss: 1.3658
2022-07-14 00:37:09 - train: epoch 0084, iter [00400, 05004], lr: 0.021594, loss: 1.5522
2022-07-14 00:37:44 - train: epoch 0084, iter [00500, 05004], lr: 0.021572, loss: 1.5333
2022-07-14 00:38:17 - train: epoch 0084, iter [00600, 05004], lr: 0.021550, loss: 1.8222
2022-07-14 00:38:51 - train: epoch 0084, iter [00700, 05004], lr: 0.021529, loss: 1.6452
2022-07-14 00:39:24 - train: epoch 0084, iter [00800, 05004], lr: 0.021507, loss: 1.6825
2022-07-14 00:39:58 - train: epoch 0084, iter [00900, 05004], lr: 0.021486, loss: 1.5675
2022-07-14 00:40:31 - train: epoch 0084, iter [01000, 05004], lr: 0.021464, loss: 1.6767
2022-07-14 00:41:06 - train: epoch 0084, iter [01100, 05004], lr: 0.021443, loss: 1.5210
2022-07-14 00:41:39 - train: epoch 0084, iter [01200, 05004], lr: 0.021422, loss: 1.8796
2022-07-14 00:42:13 - train: epoch 0084, iter [01300, 05004], lr: 0.021400, loss: 1.5957
2022-07-14 00:42:47 - train: epoch 0084, iter [01400, 05004], lr: 0.021379, loss: 1.6786
2022-07-14 00:43:21 - train: epoch 0084, iter [01500, 05004], lr: 0.021357, loss: 1.5778
2022-07-14 00:43:55 - train: epoch 0084, iter [01600, 05004], lr: 0.021336, loss: 1.4804
2022-07-14 00:44:28 - train: epoch 0084, iter [01700, 05004], lr: 0.021314, loss: 1.6625
2022-07-14 00:45:01 - train: epoch 0084, iter [01800, 05004], lr: 0.021293, loss: 1.5381
2022-07-14 00:45:35 - train: epoch 0084, iter [01900, 05004], lr: 0.021271, loss: 1.4861
2022-07-14 00:46:07 - train: epoch 0084, iter [02000, 05004], lr: 0.021250, loss: 1.6444
2022-07-14 00:46:41 - train: epoch 0084, iter [02100, 05004], lr: 0.021229, loss: 1.4560
2022-07-14 00:47:15 - train: epoch 0084, iter [02200, 05004], lr: 0.021207, loss: 1.3782
2022-07-14 00:47:49 - train: epoch 0084, iter [02300, 05004], lr: 0.021186, loss: 1.5990
2022-07-14 00:48:23 - train: epoch 0084, iter [02400, 05004], lr: 0.021165, loss: 1.5149
2022-07-14 00:48:56 - train: epoch 0084, iter [02500, 05004], lr: 0.021143, loss: 1.7123
2022-07-14 00:49:29 - train: epoch 0084, iter [02600, 05004], lr: 0.021122, loss: 1.6484
2022-07-14 00:50:02 - train: epoch 0084, iter [02700, 05004], lr: 0.021100, loss: 1.5786
2022-07-14 00:50:35 - train: epoch 0084, iter [02800, 05004], lr: 0.021079, loss: 1.6696
2022-07-14 00:51:09 - train: epoch 0084, iter [02900, 05004], lr: 0.021058, loss: 1.4064
2022-07-14 00:51:42 - train: epoch 0084, iter [03000, 05004], lr: 0.021036, loss: 1.6527
2022-07-14 00:52:16 - train: epoch 0084, iter [03100, 05004], lr: 0.021015, loss: 1.4357
2022-07-14 00:52:49 - train: epoch 0084, iter [03200, 05004], lr: 0.020994, loss: 1.5563
2022-07-14 00:53:22 - train: epoch 0084, iter [03300, 05004], lr: 0.020973, loss: 1.6980
2022-07-14 00:53:56 - train: epoch 0084, iter [03400, 05004], lr: 0.020951, loss: 1.5234
2022-07-14 00:54:29 - train: epoch 0084, iter [03500, 05004], lr: 0.020930, loss: 1.4099
2022-07-14 00:55:02 - train: epoch 0084, iter [03600, 05004], lr: 0.020909, loss: 1.6576
2022-07-14 00:55:35 - train: epoch 0084, iter [03700, 05004], lr: 0.020887, loss: 1.6634
2022-07-14 00:56:10 - train: epoch 0084, iter [03800, 05004], lr: 0.020866, loss: 1.8395
2022-07-14 00:56:43 - train: epoch 0084, iter [03900, 05004], lr: 0.020845, loss: 1.6484
2022-07-14 00:57:16 - train: epoch 0084, iter [04000, 05004], lr: 0.020824, loss: 1.6583
2022-07-14 00:57:49 - train: epoch 0084, iter [04100, 05004], lr: 0.020802, loss: 1.5040
2022-07-14 00:58:23 - train: epoch 0084, iter [04200, 05004], lr: 0.020781, loss: 1.6715
2022-07-14 00:58:56 - train: epoch 0084, iter [04300, 05004], lr: 0.020760, loss: 1.6730
2022-07-14 00:59:30 - train: epoch 0084, iter [04400, 05004], lr: 0.020739, loss: 1.9099
2022-07-14 01:00:02 - train: epoch 0084, iter [04500, 05004], lr: 0.020718, loss: 1.5068
2022-07-14 01:00:36 - train: epoch 0084, iter [04600, 05004], lr: 0.020696, loss: 1.5970
2022-07-14 01:01:09 - train: epoch 0084, iter [04700, 05004], lr: 0.020675, loss: 1.7809
2022-07-14 01:01:42 - train: epoch 0084, iter [04800, 05004], lr: 0.020654, loss: 1.4725
2022-07-14 01:02:15 - train: epoch 0084, iter [04900, 05004], lr: 0.020633, loss: 1.4394
2022-07-14 01:02:48 - train: epoch 0084, iter [05000, 05004], lr: 0.020612, loss: 1.5743
2022-07-14 01:02:49 - train: epoch 084, train_loss: 1.5710
2022-07-14 01:04:02 - eval: epoch: 084, acc1: 66.472%, acc5: 87.522%, test_loss: 1.3781, per_image_load_time: 2.593ms, per_image_inference_time: 0.265ms
2022-07-14 01:04:03 - until epoch: 084, best_acc1: 66.472%
2022-07-14 01:04:03 - epoch 085 lr: 0.020611
2022-07-14 01:04:41 - train: epoch 0085, iter [00100, 05004], lr: 0.020590, loss: 1.3707
2022-07-14 01:05:14 - train: epoch 0085, iter [00200, 05004], lr: 0.020568, loss: 1.3678
2022-07-14 01:05:47 - train: epoch 0085, iter [00300, 05004], lr: 0.020547, loss: 1.6347
2022-07-14 01:06:21 - train: epoch 0085, iter [00400, 05004], lr: 0.020526, loss: 1.4719
2022-07-14 01:06:53 - train: epoch 0085, iter [00500, 05004], lr: 0.020505, loss: 1.6842
2022-07-14 01:07:26 - train: epoch 0085, iter [00600, 05004], lr: 0.020484, loss: 1.3541
2022-07-14 01:08:00 - train: epoch 0085, iter [00700, 05004], lr: 0.020463, loss: 1.3556
2022-07-14 01:08:32 - train: epoch 0085, iter [00800, 05004], lr: 0.020442, loss: 1.3432
2022-07-14 01:09:06 - train: epoch 0085, iter [00900, 05004], lr: 0.020421, loss: 1.4068
2022-07-14 01:09:39 - train: epoch 0085, iter [01000, 05004], lr: 0.020400, loss: 1.6832
2022-07-14 01:10:12 - train: epoch 0085, iter [01100, 05004], lr: 0.020378, loss: 1.6114
2022-07-14 01:10:45 - train: epoch 0085, iter [01200, 05004], lr: 0.020357, loss: 1.3871
2022-07-14 01:11:19 - train: epoch 0085, iter [01300, 05004], lr: 0.020336, loss: 1.4664
2022-07-14 01:11:52 - train: epoch 0085, iter [01400, 05004], lr: 0.020315, loss: 1.4831
2022-07-14 01:12:25 - train: epoch 0085, iter [01500, 05004], lr: 0.020294, loss: 1.4712
2022-07-14 01:12:59 - train: epoch 0085, iter [01600, 05004], lr: 0.020273, loss: 1.5573
2022-07-14 01:13:32 - train: epoch 0085, iter [01700, 05004], lr: 0.020252, loss: 1.8344
2022-07-14 01:14:04 - train: epoch 0085, iter [01800, 05004], lr: 0.020231, loss: 1.3705
2022-07-14 01:14:37 - train: epoch 0085, iter [01900, 05004], lr: 0.020210, loss: 1.4080
2022-07-14 01:15:10 - train: epoch 0085, iter [02000, 05004], lr: 0.020189, loss: 1.5119
2022-07-14 01:15:43 - train: epoch 0085, iter [02100, 05004], lr: 0.020168, loss: 1.2162
2022-07-14 01:16:17 - train: epoch 0085, iter [02200, 05004], lr: 0.020147, loss: 1.6716
2022-07-14 01:16:50 - train: epoch 0085, iter [02300, 05004], lr: 0.020126, loss: 1.3378
2022-07-14 01:17:23 - train: epoch 0085, iter [02400, 05004], lr: 0.020105, loss: 1.6781
2022-07-14 01:17:56 - train: epoch 0085, iter [02500, 05004], lr: 0.020084, loss: 1.8604
2022-07-14 01:18:29 - train: epoch 0085, iter [02600, 05004], lr: 0.020063, loss: 1.5762
2022-07-14 01:19:03 - train: epoch 0085, iter [02700, 05004], lr: 0.020042, loss: 1.4083
2022-07-14 01:19:37 - train: epoch 0085, iter [02800, 05004], lr: 0.020021, loss: 1.8151
2022-07-14 01:20:12 - train: epoch 0085, iter [02900, 05004], lr: 0.020000, loss: 1.6375
2022-07-14 01:20:45 - train: epoch 0085, iter [03000, 05004], lr: 0.019979, loss: 1.7708
2022-07-14 01:21:19 - train: epoch 0085, iter [03100, 05004], lr: 0.019959, loss: 1.5749
2022-07-14 01:21:52 - train: epoch 0085, iter [03200, 05004], lr: 0.019938, loss: 1.4434
2022-07-14 01:22:25 - train: epoch 0085, iter [03300, 05004], lr: 0.019917, loss: 1.5983
2022-07-14 01:22:59 - train: epoch 0085, iter [03400, 05004], lr: 0.019896, loss: 1.7011
2022-07-14 01:23:34 - train: epoch 0085, iter [03500, 05004], lr: 0.019875, loss: 1.6172
2022-07-14 01:24:06 - train: epoch 0085, iter [03600, 05004], lr: 0.019854, loss: 1.6005
2022-07-14 01:24:39 - train: epoch 0085, iter [03700, 05004], lr: 0.019833, loss: 1.3691
2022-07-14 01:25:13 - train: epoch 0085, iter [03800, 05004], lr: 0.019812, loss: 1.4761
2022-07-14 01:25:46 - train: epoch 0085, iter [03900, 05004], lr: 0.019792, loss: 1.5911
2022-07-14 01:26:20 - train: epoch 0085, iter [04000, 05004], lr: 0.019771, loss: 1.8453
2022-07-14 01:26:53 - train: epoch 0085, iter [04100, 05004], lr: 0.019750, loss: 1.5456
2022-07-14 01:27:26 - train: epoch 0085, iter [04200, 05004], lr: 0.019729, loss: 1.7131
2022-07-14 01:28:00 - train: epoch 0085, iter [04300, 05004], lr: 0.019708, loss: 1.5067
2022-07-14 01:28:33 - train: epoch 0085, iter [04400, 05004], lr: 0.019687, loss: 1.5733
2022-07-14 01:29:06 - train: epoch 0085, iter [04500, 05004], lr: 0.019667, loss: 1.6785
2022-07-14 01:29:40 - train: epoch 0085, iter [04600, 05004], lr: 0.019646, loss: 1.5794
2022-07-14 01:30:13 - train: epoch 0085, iter [04700, 05004], lr: 0.019625, loss: 1.8663
2022-07-14 01:30:47 - train: epoch 0085, iter [04800, 05004], lr: 0.019604, loss: 1.3324
2022-07-14 01:31:21 - train: epoch 0085, iter [04900, 05004], lr: 0.019584, loss: 1.5023
2022-07-14 01:31:53 - train: epoch 0085, iter [05000, 05004], lr: 0.019563, loss: 1.4693
2022-07-14 01:31:54 - train: epoch 085, train_loss: 1.5594
2022-07-14 01:33:08 - eval: epoch: 085, acc1: 67.064%, acc5: 87.752%, test_loss: 1.3574, per_image_load_time: 2.603ms, per_image_inference_time: 0.268ms
2022-07-14 01:33:08 - until epoch: 085, best_acc1: 67.064%
2022-07-14 01:33:08 - epoch 086 lr: 0.019562
2022-07-14 01:33:47 - train: epoch 0086, iter [00100, 05004], lr: 0.019541, loss: 1.3874
2022-07-14 01:34:20 - train: epoch 0086, iter [00200, 05004], lr: 0.019520, loss: 1.3928
2022-07-14 01:34:53 - train: epoch 0086, iter [00300, 05004], lr: 0.019500, loss: 1.7073
2022-07-14 01:35:27 - train: epoch 0086, iter [00400, 05004], lr: 0.019479, loss: 1.5497
2022-07-14 01:36:01 - train: epoch 0086, iter [00500, 05004], lr: 0.019458, loss: 1.4754
2022-07-14 01:36:34 - train: epoch 0086, iter [00600, 05004], lr: 0.019438, loss: 1.4572
2022-07-14 01:37:07 - train: epoch 0086, iter [00700, 05004], lr: 0.019417, loss: 1.4085
2022-07-14 01:37:41 - train: epoch 0086, iter [00800, 05004], lr: 0.019396, loss: 1.7532
2022-07-14 01:38:14 - train: epoch 0086, iter [00900, 05004], lr: 0.019375, loss: 1.5930
2022-07-14 01:38:47 - train: epoch 0086, iter [01000, 05004], lr: 0.019355, loss: 1.5509
2022-07-14 01:39:21 - train: epoch 0086, iter [01100, 05004], lr: 0.019334, loss: 1.6513
2022-07-14 01:39:54 - train: epoch 0086, iter [01200, 05004], lr: 0.019313, loss: 1.3262
2022-07-14 01:40:28 - train: epoch 0086, iter [01300, 05004], lr: 0.019293, loss: 1.5673
2022-07-14 01:41:01 - train: epoch 0086, iter [01400, 05004], lr: 0.019272, loss: 1.4264
2022-07-14 01:41:34 - train: epoch 0086, iter [01500, 05004], lr: 0.019252, loss: 1.4031
2022-07-14 01:42:07 - train: epoch 0086, iter [01600, 05004], lr: 0.019231, loss: 1.5852
2022-07-14 01:42:41 - train: epoch 0086, iter [01700, 05004], lr: 0.019210, loss: 1.4272
2022-07-14 01:43:15 - train: epoch 0086, iter [01800, 05004], lr: 0.019190, loss: 1.6387
2022-07-14 01:43:48 - train: epoch 0086, iter [01900, 05004], lr: 0.019169, loss: 1.6846
2022-07-14 01:44:22 - train: epoch 0086, iter [02000, 05004], lr: 0.019149, loss: 1.5146
2022-07-14 01:44:56 - train: epoch 0086, iter [02100, 05004], lr: 0.019128, loss: 1.3800
2022-07-14 01:45:29 - train: epoch 0086, iter [02200, 05004], lr: 0.019107, loss: 1.5659
2022-07-14 01:46:02 - train: epoch 0086, iter [02300, 05004], lr: 0.019087, loss: 1.4962
2022-07-14 01:46:35 - train: epoch 0086, iter [02400, 05004], lr: 0.019066, loss: 1.2985
2022-07-14 01:47:09 - train: epoch 0086, iter [02500, 05004], lr: 0.019046, loss: 1.5049
2022-07-14 01:47:42 - train: epoch 0086, iter [02600, 05004], lr: 0.019025, loss: 1.5558
2022-07-14 01:48:16 - train: epoch 0086, iter [02700, 05004], lr: 0.019005, loss: 1.4607
2022-07-14 01:48:49 - train: epoch 0086, iter [02800, 05004], lr: 0.018984, loss: 1.6177
2022-07-14 01:49:23 - train: epoch 0086, iter [02900, 05004], lr: 0.018964, loss: 1.3075
2022-07-14 01:49:56 - train: epoch 0086, iter [03000, 05004], lr: 0.018943, loss: 1.6387
2022-07-14 01:50:29 - train: epoch 0086, iter [03100, 05004], lr: 0.018923, loss: 1.4953
2022-07-14 01:51:02 - train: epoch 0086, iter [03200, 05004], lr: 0.018902, loss: 1.6273
2022-07-14 01:51:37 - train: epoch 0086, iter [03300, 05004], lr: 0.018882, loss: 1.6622
2022-07-14 01:52:10 - train: epoch 0086, iter [03400, 05004], lr: 0.018861, loss: 1.6556
2022-07-14 01:52:44 - train: epoch 0086, iter [03500, 05004], lr: 0.018841, loss: 1.5140
2022-07-14 01:53:18 - train: epoch 0086, iter [03600, 05004], lr: 0.018820, loss: 1.5825
2022-07-14 01:53:51 - train: epoch 0086, iter [03700, 05004], lr: 0.018800, loss: 1.6553
2022-07-14 01:54:24 - train: epoch 0086, iter [03800, 05004], lr: 0.018779, loss: 1.4864
2022-07-14 01:54:58 - train: epoch 0086, iter [03900, 05004], lr: 0.018759, loss: 1.5596
2022-07-14 01:55:31 - train: epoch 0086, iter [04000, 05004], lr: 0.018739, loss: 1.5796
2022-07-14 01:56:05 - train: epoch 0086, iter [04100, 05004], lr: 0.018718, loss: 1.4489
2022-07-14 01:56:39 - train: epoch 0086, iter [04200, 05004], lr: 0.018698, loss: 1.5963
2022-07-14 01:57:13 - train: epoch 0086, iter [04300, 05004], lr: 0.018677, loss: 1.6838
2022-07-14 01:57:46 - train: epoch 0086, iter [04400, 05004], lr: 0.018657, loss: 1.5242
2022-07-14 01:58:20 - train: epoch 0086, iter [04500, 05004], lr: 0.018637, loss: 1.4121
2022-07-14 01:58:54 - train: epoch 0086, iter [04600, 05004], lr: 0.018616, loss: 1.5425
2022-07-14 01:59:27 - train: epoch 0086, iter [04700, 05004], lr: 0.018596, loss: 1.5467
2022-07-14 02:00:01 - train: epoch 0086, iter [04800, 05004], lr: 0.018575, loss: 1.6181
2022-07-14 02:00:35 - train: epoch 0086, iter [04900, 05004], lr: 0.018555, loss: 1.5885
2022-07-14 02:01:07 - train: epoch 0086, iter [05000, 05004], lr: 0.018535, loss: 1.5846
2022-07-14 02:01:08 - train: epoch 086, train_loss: 1.5427
2022-07-14 02:02:22 - eval: epoch: 086, acc1: 66.788%, acc5: 87.490%, test_loss: 1.3668, per_image_load_time: 2.622ms, per_image_inference_time: 0.279ms
2022-07-14 02:02:22 - until epoch: 086, best_acc1: 67.064%
2022-07-14 02:02:22 - epoch 087 lr: 0.018534
2022-07-14 02:03:01 - train: epoch 0087, iter [00100, 05004], lr: 0.018514, loss: 1.5610
2022-07-14 02:03:34 - train: epoch 0087, iter [00200, 05004], lr: 0.018493, loss: 1.3361
2022-07-14 02:04:07 - train: epoch 0087, iter [00300, 05004], lr: 0.018473, loss: 1.7641
2022-07-14 02:04:40 - train: epoch 0087, iter [00400, 05004], lr: 0.018453, loss: 1.6273
2022-07-14 02:05:14 - train: epoch 0087, iter [00500, 05004], lr: 0.018432, loss: 1.2151
2022-07-14 02:05:47 - train: epoch 0087, iter [00600, 05004], lr: 0.018412, loss: 1.5231
2022-07-14 02:06:21 - train: epoch 0087, iter [00700, 05004], lr: 0.018392, loss: 1.3193
2022-07-14 02:06:54 - train: epoch 0087, iter [00800, 05004], lr: 0.018372, loss: 1.4893
2022-07-14 02:07:28 - train: epoch 0087, iter [00900, 05004], lr: 0.018351, loss: 1.6527
2022-07-14 02:08:01 - train: epoch 0087, iter [01000, 05004], lr: 0.018331, loss: 1.5428
2022-07-14 02:08:35 - train: epoch 0087, iter [01100, 05004], lr: 0.018311, loss: 1.6411
2022-07-14 02:09:08 - train: epoch 0087, iter [01200, 05004], lr: 0.018291, loss: 1.5882
2022-07-14 02:09:42 - train: epoch 0087, iter [01300, 05004], lr: 0.018270, loss: 1.7133
2022-07-14 02:10:15 - train: epoch 0087, iter [01400, 05004], lr: 0.018250, loss: 1.5359
2022-07-14 02:10:49 - train: epoch 0087, iter [01500, 05004], lr: 0.018230, loss: 1.4242
2022-07-14 02:11:23 - train: epoch 0087, iter [01600, 05004], lr: 0.018210, loss: 1.4195
2022-07-14 02:11:57 - train: epoch 0087, iter [01700, 05004], lr: 0.018190, loss: 1.5507
2022-07-14 02:12:30 - train: epoch 0087, iter [01800, 05004], lr: 0.018169, loss: 1.5423
2022-07-14 02:13:04 - train: epoch 0087, iter [01900, 05004], lr: 0.018149, loss: 1.5410
2022-07-14 02:13:37 - train: epoch 0087, iter [02000, 05004], lr: 0.018129, loss: 1.4880
2022-07-14 02:14:11 - train: epoch 0087, iter [02100, 05004], lr: 0.018109, loss: 1.5931
2022-07-14 02:14:44 - train: epoch 0087, iter [02200, 05004], lr: 0.018089, loss: 1.6234
2022-07-14 02:15:18 - train: epoch 0087, iter [02300, 05004], lr: 0.018069, loss: 1.6082
2022-07-14 02:15:52 - train: epoch 0087, iter [02400, 05004], lr: 0.018049, loss: 1.4343
2022-07-14 02:16:26 - train: epoch 0087, iter [02500, 05004], lr: 0.018028, loss: 1.4934
2022-07-14 02:16:59 - train: epoch 0087, iter [02600, 05004], lr: 0.018008, loss: 1.5524
2022-07-14 02:17:34 - train: epoch 0087, iter [02700, 05004], lr: 0.017988, loss: 1.5043
2022-07-14 02:18:06 - train: epoch 0087, iter [02800, 05004], lr: 0.017968, loss: 1.4175
2022-07-14 02:18:40 - train: epoch 0087, iter [02900, 05004], lr: 0.017948, loss: 1.3502
2022-07-14 02:19:13 - train: epoch 0087, iter [03000, 05004], lr: 0.017928, loss: 1.6661
2022-07-14 02:19:47 - train: epoch 0087, iter [03100, 05004], lr: 0.017908, loss: 1.6086
2022-07-14 02:20:21 - train: epoch 0087, iter [03200, 05004], lr: 0.017888, loss: 1.4939
2022-07-14 02:20:56 - train: epoch 0087, iter [03300, 05004], lr: 0.017868, loss: 1.4896
2022-07-14 02:21:29 - train: epoch 0087, iter [03400, 05004], lr: 0.017848, loss: 1.5549
2022-07-14 02:22:03 - train: epoch 0087, iter [03500, 05004], lr: 0.017828, loss: 1.3891
2022-07-14 02:22:37 - train: epoch 0087, iter [03600, 05004], lr: 0.017808, loss: 1.3572
2022-07-14 02:23:11 - train: epoch 0087, iter [03700, 05004], lr: 0.017788, loss: 1.5090
2022-07-14 02:23:44 - train: epoch 0087, iter [03800, 05004], lr: 0.017768, loss: 1.7324
2022-07-14 02:24:19 - train: epoch 0087, iter [03900, 05004], lr: 0.017748, loss: 1.4145
2022-07-14 02:24:53 - train: epoch 0087, iter [04000, 05004], lr: 0.017728, loss: 1.6400
2022-07-14 02:25:26 - train: epoch 0087, iter [04100, 05004], lr: 0.017708, loss: 1.6723
2022-07-14 02:25:59 - train: epoch 0087, iter [04200, 05004], lr: 0.017688, loss: 1.5850
2022-07-14 02:26:34 - train: epoch 0087, iter [04300, 05004], lr: 0.017668, loss: 1.4914
2022-07-14 02:27:08 - train: epoch 0087, iter [04400, 05004], lr: 0.017648, loss: 1.5625
2022-07-14 02:27:43 - train: epoch 0087, iter [04500, 05004], lr: 0.017628, loss: 1.6147
2022-07-14 02:28:17 - train: epoch 0087, iter [04600, 05004], lr: 0.017608, loss: 1.5889
2022-07-14 02:28:51 - train: epoch 0087, iter [04700, 05004], lr: 0.017588, loss: 1.5750
2022-07-14 02:29:25 - train: epoch 0087, iter [04800, 05004], lr: 0.017568, loss: 1.4619
2022-07-14 02:29:59 - train: epoch 0087, iter [04900, 05004], lr: 0.017548, loss: 1.5110
2022-07-14 02:30:31 - train: epoch 0087, iter [05000, 05004], lr: 0.017528, loss: 1.5773
2022-07-14 02:30:32 - train: epoch 087, train_loss: 1.5273
2022-07-14 02:31:47 - eval: epoch: 087, acc1: 67.276%, acc5: 87.904%, test_loss: 1.3482, per_image_load_time: 2.563ms, per_image_inference_time: 0.296ms
2022-07-14 02:31:48 - until epoch: 087, best_acc1: 67.276%
2022-07-14 02:31:48 - epoch 088 lr: 0.017527
2022-07-14 02:32:27 - train: epoch 0088, iter [00100, 05004], lr: 0.017508, loss: 1.3587
2022-07-14 02:33:01 - train: epoch 0088, iter [00200, 05004], lr: 0.017488, loss: 1.4308
2022-07-14 02:33:32 - train: epoch 0088, iter [00300, 05004], lr: 0.017468, loss: 1.4829
2022-07-14 02:34:08 - train: epoch 0088, iter [00400, 05004], lr: 0.017448, loss: 1.4959
2022-07-14 02:34:40 - train: epoch 0088, iter [00500, 05004], lr: 0.017428, loss: 1.4692
2022-07-14 02:35:15 - train: epoch 0088, iter [00600, 05004], lr: 0.017408, loss: 1.5650
2022-07-14 02:35:50 - train: epoch 0088, iter [00700, 05004], lr: 0.017389, loss: 1.4775
2022-07-14 02:36:23 - train: epoch 0088, iter [00800, 05004], lr: 0.017369, loss: 1.4613
2022-07-14 02:36:58 - train: epoch 0088, iter [00900, 05004], lr: 0.017349, loss: 1.5741
2022-07-14 02:37:31 - train: epoch 0088, iter [01000, 05004], lr: 0.017329, loss: 1.4153
2022-07-14 02:38:05 - train: epoch 0088, iter [01100, 05004], lr: 0.017309, loss: 1.5885
2022-07-14 02:38:40 - train: epoch 0088, iter [01200, 05004], lr: 0.017290, loss: 1.4609
2022-07-14 02:39:15 - train: epoch 0088, iter [01300, 05004], lr: 0.017270, loss: 1.5822
2022-07-14 02:39:48 - train: epoch 0088, iter [01400, 05004], lr: 0.017250, loss: 1.3613
2022-07-14 02:40:22 - train: epoch 0088, iter [01500, 05004], lr: 0.017230, loss: 1.5414
2022-07-14 02:40:58 - train: epoch 0088, iter [01600, 05004], lr: 0.017210, loss: 1.3357
2022-07-14 02:41:31 - train: epoch 0088, iter [01700, 05004], lr: 0.017191, loss: 1.5099
2022-07-14 02:42:05 - train: epoch 0088, iter [01800, 05004], lr: 0.017171, loss: 1.4708
2022-07-14 02:42:39 - train: epoch 0088, iter [01900, 05004], lr: 0.017151, loss: 1.6540
2022-07-14 02:43:14 - train: epoch 0088, iter [02000, 05004], lr: 0.017132, loss: 1.4045
2022-07-14 02:43:48 - train: epoch 0088, iter [02100, 05004], lr: 0.017112, loss: 1.5834
2022-07-14 02:44:21 - train: epoch 0088, iter [02200, 05004], lr: 0.017092, loss: 1.4848
2022-07-14 02:44:56 - train: epoch 0088, iter [02300, 05004], lr: 0.017072, loss: 1.2916
2022-07-14 02:45:30 - train: epoch 0088, iter [02400, 05004], lr: 0.017053, loss: 1.6127
2022-07-14 02:46:04 - train: epoch 0088, iter [02500, 05004], lr: 0.017033, loss: 1.6453
2022-07-14 02:46:39 - train: epoch 0088, iter [02600, 05004], lr: 0.017013, loss: 1.5365
2022-07-14 02:47:13 - train: epoch 0088, iter [02700, 05004], lr: 0.016994, loss: 1.6297
2022-07-14 02:47:47 - train: epoch 0088, iter [02800, 05004], lr: 0.016974, loss: 1.5896
2022-07-14 02:48:21 - train: epoch 0088, iter [02900, 05004], lr: 0.016955, loss: 1.4014
2022-07-14 02:48:56 - train: epoch 0088, iter [03000, 05004], lr: 0.016935, loss: 1.6343
2022-07-14 02:49:30 - train: epoch 0088, iter [03100, 05004], lr: 0.016915, loss: 1.4158
2022-07-14 02:50:04 - train: epoch 0088, iter [03200, 05004], lr: 0.016896, loss: 1.3672
2022-07-14 02:50:38 - train: epoch 0088, iter [03300, 05004], lr: 0.016876, loss: 1.3349
2022-07-14 02:51:13 - train: epoch 0088, iter [03400, 05004], lr: 0.016856, loss: 1.3731
2022-07-14 02:51:47 - train: epoch 0088, iter [03500, 05004], lr: 0.016837, loss: 1.3576
2022-07-14 02:52:21 - train: epoch 0088, iter [03600, 05004], lr: 0.016817, loss: 1.5104
2022-07-14 02:52:55 - train: epoch 0088, iter [03700, 05004], lr: 0.016798, loss: 1.5601
2022-07-14 02:53:29 - train: epoch 0088, iter [03800, 05004], lr: 0.016778, loss: 1.5930
2022-07-14 02:54:03 - train: epoch 0088, iter [03900, 05004], lr: 0.016759, loss: 1.6918
2022-07-14 02:54:38 - train: epoch 0088, iter [04000, 05004], lr: 0.016739, loss: 1.3266
2022-07-14 02:55:14 - train: epoch 0088, iter [04100, 05004], lr: 0.016720, loss: 1.5872
2022-07-14 02:55:47 - train: epoch 0088, iter [04200, 05004], lr: 0.016700, loss: 1.6905
2022-07-14 02:56:20 - train: epoch 0088, iter [04300, 05004], lr: 0.016681, loss: 1.5565
2022-07-14 02:56:56 - train: epoch 0088, iter [04400, 05004], lr: 0.016661, loss: 1.3236
2022-07-14 02:57:29 - train: epoch 0088, iter [04500, 05004], lr: 0.016642, loss: 1.4714
2022-07-14 02:58:04 - train: epoch 0088, iter [04600, 05004], lr: 0.016622, loss: 1.6402
2022-07-14 02:58:37 - train: epoch 0088, iter [04700, 05004], lr: 0.016603, loss: 1.6101
2022-07-14 02:59:12 - train: epoch 0088, iter [04800, 05004], lr: 0.016583, loss: 1.4729
2022-07-14 02:59:46 - train: epoch 0088, iter [04900, 05004], lr: 0.016564, loss: 1.3390
2022-07-14 03:00:19 - train: epoch 0088, iter [05000, 05004], lr: 0.016544, loss: 1.5074
2022-07-14 03:00:20 - train: epoch 088, train_loss: 1.5110
2022-07-14 03:01:36 - eval: epoch: 088, acc1: 67.726%, acc5: 88.202%, test_loss: 1.3215, per_image_load_time: 2.640ms, per_image_inference_time: 0.306ms
2022-07-14 03:01:36 - until epoch: 088, best_acc1: 67.726%
2022-07-14 03:01:36 - epoch 089 lr: 0.016543
2022-07-14 03:02:15 - train: epoch 0089, iter [00100, 05004], lr: 0.016524, loss: 1.6852
2022-07-14 03:02:49 - train: epoch 0089, iter [00200, 05004], lr: 0.016505, loss: 1.2187
2022-07-14 03:03:23 - train: epoch 0089, iter [00300, 05004], lr: 0.016485, loss: 1.5387
2022-07-14 03:03:57 - train: epoch 0089, iter [00400, 05004], lr: 0.016466, loss: 1.3624
2022-07-14 03:04:31 - train: epoch 0089, iter [00500, 05004], lr: 0.016446, loss: 1.4490
2022-07-14 03:05:05 - train: epoch 0089, iter [00600, 05004], lr: 0.016427, loss: 1.3456
2022-07-14 03:05:39 - train: epoch 0089, iter [00700, 05004], lr: 0.016408, loss: 1.5158
2022-07-14 03:06:13 - train: epoch 0089, iter [00800, 05004], lr: 0.016388, loss: 1.7688
2022-07-14 03:06:47 - train: epoch 0089, iter [00900, 05004], lr: 0.016369, loss: 1.5179
2022-07-14 03:07:22 - train: epoch 0089, iter [01000, 05004], lr: 0.016350, loss: 1.6239
2022-07-14 03:07:56 - train: epoch 0089, iter [01100, 05004], lr: 0.016330, loss: 1.4430
2022-07-14 03:08:30 - train: epoch 0089, iter [01200, 05004], lr: 0.016311, loss: 1.6211
2022-07-14 03:09:05 - train: epoch 0089, iter [01300, 05004], lr: 0.016292, loss: 1.4713
2022-07-14 03:09:38 - train: epoch 0089, iter [01400, 05004], lr: 0.016272, loss: 1.4735
2022-07-14 03:10:12 - train: epoch 0089, iter [01500, 05004], lr: 0.016253, loss: 1.5227
2022-07-14 03:10:47 - train: epoch 0089, iter [01600, 05004], lr: 0.016234, loss: 1.4212
2022-07-14 03:11:22 - train: epoch 0089, iter [01700, 05004], lr: 0.016214, loss: 1.4645
2022-07-14 03:11:56 - train: epoch 0089, iter [01800, 05004], lr: 0.016195, loss: 1.4395
2022-07-14 03:12:31 - train: epoch 0089, iter [01900, 05004], lr: 0.016176, loss: 1.3783
2022-07-14 03:13:05 - train: epoch 0089, iter [02000, 05004], lr: 0.016157, loss: 1.4570
2022-07-14 03:13:39 - train: epoch 0089, iter [02100, 05004], lr: 0.016137, loss: 1.6281
2022-07-14 03:14:14 - train: epoch 0089, iter [02200, 05004], lr: 0.016118, loss: 1.4987
2022-07-14 03:14:48 - train: epoch 0089, iter [02300, 05004], lr: 0.016099, loss: 1.3249
2022-07-14 03:15:21 - train: epoch 0089, iter [02400, 05004], lr: 0.016080, loss: 1.6108
2022-07-14 03:15:56 - train: epoch 0089, iter [02500, 05004], lr: 0.016060, loss: 1.5228
2022-07-14 03:16:30 - train: epoch 0089, iter [02600, 05004], lr: 0.016041, loss: 1.4358
2022-07-14 03:17:04 - train: epoch 0089, iter [02700, 05004], lr: 0.016022, loss: 1.4182
2022-07-14 03:17:39 - train: epoch 0089, iter [02800, 05004], lr: 0.016003, loss: 1.4796
2022-07-14 03:18:12 - train: epoch 0089, iter [02900, 05004], lr: 0.015984, loss: 1.5274
2022-07-14 03:18:46 - train: epoch 0089, iter [03000, 05004], lr: 0.015964, loss: 1.5755
2022-07-14 03:19:21 - train: epoch 0089, iter [03100, 05004], lr: 0.015945, loss: 1.5936
2022-07-14 03:19:55 - train: epoch 0089, iter [03200, 05004], lr: 0.015926, loss: 1.5787
2022-07-14 03:20:30 - train: epoch 0089, iter [03300, 05004], lr: 0.015907, loss: 1.7920
2022-07-14 03:21:03 - train: epoch 0089, iter [03400, 05004], lr: 0.015888, loss: 1.4483
2022-07-14 03:21:37 - train: epoch 0089, iter [03500, 05004], lr: 0.015869, loss: 1.3112
2022-07-14 03:22:11 - train: epoch 0089, iter [03600, 05004], lr: 0.015850, loss: 1.4748
2022-07-14 03:22:45 - train: epoch 0089, iter [03700, 05004], lr: 0.015831, loss: 1.6887
2022-07-14 03:23:19 - train: epoch 0089, iter [03800, 05004], lr: 0.015811, loss: 1.3972
2022-07-14 03:23:54 - train: epoch 0089, iter [03900, 05004], lr: 0.015792, loss: 1.6319
2022-07-14 03:24:29 - train: epoch 0089, iter [04000, 05004], lr: 0.015773, loss: 1.3991
2022-07-14 03:25:02 - train: epoch 0089, iter [04100, 05004], lr: 0.015754, loss: 1.6872
2022-07-14 03:25:36 - train: epoch 0089, iter [04200, 05004], lr: 0.015735, loss: 1.4762
2022-07-14 03:26:10 - train: epoch 0089, iter [04300, 05004], lr: 0.015716, loss: 1.4698
2022-07-14 03:26:45 - train: epoch 0089, iter [04400, 05004], lr: 0.015697, loss: 1.4851
2022-07-14 03:27:17 - train: epoch 0089, iter [04500, 05004], lr: 0.015678, loss: 1.2668
2022-07-14 03:27:51 - train: epoch 0089, iter [04600, 05004], lr: 0.015659, loss: 1.5578
2022-07-14 03:28:27 - train: epoch 0089, iter [04700, 05004], lr: 0.015640, loss: 1.4631
2022-07-14 03:29:01 - train: epoch 0089, iter [04800, 05004], lr: 0.015621, loss: 1.5723
2022-07-14 03:29:35 - train: epoch 0089, iter [04900, 05004], lr: 0.015602, loss: 1.5639
2022-07-14 03:30:08 - train: epoch 0089, iter [05000, 05004], lr: 0.015583, loss: 1.2661
2022-07-14 03:30:09 - train: epoch 089, train_loss: 1.4958
2022-07-14 03:31:24 - eval: epoch: 089, acc1: 67.770%, acc5: 88.178%, test_loss: 1.3220, per_image_load_time: 2.229ms, per_image_inference_time: 0.299ms
2022-07-14 03:31:25 - until epoch: 089, best_acc1: 67.770%
2022-07-14 03:31:25 - epoch 090 lr: 0.015582
2022-07-14 03:32:04 - train: epoch 0090, iter [00100, 05004], lr: 0.015563, loss: 1.4963
2022-07-14 03:32:36 - train: epoch 0090, iter [00200, 05004], lr: 0.015544, loss: 1.5229
2022-07-14 03:33:11 - train: epoch 0090, iter [00300, 05004], lr: 0.015525, loss: 1.3707
2022-07-14 03:33:45 - train: epoch 0090, iter [00400, 05004], lr: 0.015506, loss: 1.3035
2022-07-14 03:34:19 - train: epoch 0090, iter [00500, 05004], lr: 0.015488, loss: 1.5691
2022-07-14 03:34:53 - train: epoch 0090, iter [00600, 05004], lr: 0.015469, loss: 1.5196
2022-07-14 03:35:27 - train: epoch 0090, iter [00700, 05004], lr: 0.015450, loss: 1.3944
2022-07-14 03:36:01 - train: epoch 0090, iter [00800, 05004], lr: 0.015431, loss: 1.4182
2022-07-14 03:36:35 - train: epoch 0090, iter [00900, 05004], lr: 0.015412, loss: 1.3588
2022-07-14 03:37:10 - train: epoch 0090, iter [01000, 05004], lr: 0.015393, loss: 1.3692
2022-07-14 03:37:43 - train: epoch 0090, iter [01100, 05004], lr: 0.015374, loss: 1.5764
2022-07-14 03:38:18 - train: epoch 0090, iter [01200, 05004], lr: 0.015355, loss: 1.4273
2022-07-14 03:38:51 - train: epoch 0090, iter [01300, 05004], lr: 0.015336, loss: 1.5953
2022-07-14 03:39:25 - train: epoch 0090, iter [01400, 05004], lr: 0.015318, loss: 1.2411
2022-07-14 03:40:00 - train: epoch 0090, iter [01500, 05004], lr: 0.015299, loss: 1.7234
2022-07-14 03:40:35 - train: epoch 0090, iter [01600, 05004], lr: 0.015280, loss: 1.4622
2022-07-14 03:41:08 - train: epoch 0090, iter [01700, 05004], lr: 0.015261, loss: 1.2195
2022-07-14 03:41:42 - train: epoch 0090, iter [01800, 05004], lr: 0.015242, loss: 1.2981
2022-07-14 03:42:16 - train: epoch 0090, iter [01900, 05004], lr: 0.015223, loss: 1.3496
2022-07-14 03:42:50 - train: epoch 0090, iter [02000, 05004], lr: 0.015205, loss: 1.5747
2022-07-14 03:43:24 - train: epoch 0090, iter [02100, 05004], lr: 0.015186, loss: 1.6418
2022-07-14 03:43:58 - train: epoch 0090, iter [02200, 05004], lr: 0.015167, loss: 1.5744
2022-07-14 03:44:33 - train: epoch 0090, iter [02300, 05004], lr: 0.015148, loss: 1.6595
2022-07-14 03:45:07 - train: epoch 0090, iter [02400, 05004], lr: 0.015130, loss: 1.5343
2022-07-14 03:45:42 - train: epoch 0090, iter [02500, 05004], lr: 0.015111, loss: 1.4974
2022-07-14 03:46:16 - train: epoch 0090, iter [02600, 05004], lr: 0.015092, loss: 1.5011
2022-07-14 03:46:50 - train: epoch 0090, iter [02700, 05004], lr: 0.015073, loss: 1.3377
2022-07-14 03:47:25 - train: epoch 0090, iter [02800, 05004], lr: 0.015055, loss: 1.4602
2022-07-14 03:47:59 - train: epoch 0090, iter [02900, 05004], lr: 0.015036, loss: 1.4136
2022-07-14 03:48:34 - train: epoch 0090, iter [03000, 05004], lr: 0.015017, loss: 1.5262
2022-07-14 03:49:08 - train: epoch 0090, iter [03100, 05004], lr: 0.014999, loss: 1.3182
2022-07-14 03:49:42 - train: epoch 0090, iter [03200, 05004], lr: 0.014980, loss: 1.3381
2022-07-14 03:50:15 - train: epoch 0090, iter [03300, 05004], lr: 0.014961, loss: 1.5533
2022-07-14 03:50:50 - train: epoch 0090, iter [03400, 05004], lr: 0.014943, loss: 1.2604
2022-07-14 03:51:24 - train: epoch 0090, iter [03500, 05004], lr: 0.014924, loss: 1.4924
2022-07-14 03:51:59 - train: epoch 0090, iter [03600, 05004], lr: 0.014905, loss: 1.2966
2022-07-14 03:52:33 - train: epoch 0090, iter [03700, 05004], lr: 0.014887, loss: 1.6103
2022-07-14 03:53:07 - train: epoch 0090, iter [03800, 05004], lr: 0.014868, loss: 1.4787
2022-07-14 03:53:42 - train: epoch 0090, iter [03900, 05004], lr: 0.014849, loss: 1.3092
2022-07-14 03:54:16 - train: epoch 0090, iter [04000, 05004], lr: 0.014831, loss: 1.5076
2022-07-14 03:54:50 - train: epoch 0090, iter [04100, 05004], lr: 0.014812, loss: 1.7683
2022-07-14 03:55:25 - train: epoch 0090, iter [04200, 05004], lr: 0.014794, loss: 1.6508
2022-07-14 03:55:58 - train: epoch 0090, iter [04300, 05004], lr: 0.014775, loss: 1.6054
2022-07-14 03:56:33 - train: epoch 0090, iter [04400, 05004], lr: 0.014757, loss: 1.4494
2022-07-14 03:57:07 - train: epoch 0090, iter [04500, 05004], lr: 0.014738, loss: 1.4100
2022-07-14 03:57:41 - train: epoch 0090, iter [04600, 05004], lr: 0.014719, loss: 1.4955
2022-07-14 03:58:16 - train: epoch 0090, iter [04700, 05004], lr: 0.014701, loss: 1.3355
2022-07-14 03:58:49 - train: epoch 0090, iter [04800, 05004], lr: 0.014682, loss: 1.6249
2022-07-14 03:59:25 - train: epoch 0090, iter [04900, 05004], lr: 0.014664, loss: 1.4226
2022-07-14 03:59:56 - train: epoch 0090, iter [05000, 05004], lr: 0.014645, loss: 1.4650
2022-07-14 03:59:57 - train: epoch 090, train_loss: 1.4777
2022-07-14 04:01:12 - eval: epoch: 090, acc1: 67.644%, acc5: 88.278%, test_loss: 1.3134, per_image_load_time: 2.320ms, per_image_inference_time: 0.295ms
2022-07-14 04:01:12 - until epoch: 090, best_acc1: 67.770%
2022-07-14 04:01:12 - epoch 091 lr: 0.014644
2022-07-14 04:01:50 - train: epoch 0091, iter [00100, 05004], lr: 0.014626, loss: 1.3898
2022-07-14 04:02:25 - train: epoch 0091, iter [00200, 05004], lr: 0.014608, loss: 1.3946
2022-07-14 04:02:59 - train: epoch 0091, iter [00300, 05004], lr: 0.014589, loss: 1.4739
2022-07-14 04:03:33 - train: epoch 0091, iter [00400, 05004], lr: 0.014571, loss: 1.3778
2022-07-14 04:04:06 - train: epoch 0091, iter [00500, 05004], lr: 0.014552, loss: 1.3805
2022-07-14 04:04:40 - train: epoch 0091, iter [00600, 05004], lr: 0.014534, loss: 1.3909
2022-07-14 04:05:15 - train: epoch 0091, iter [00700, 05004], lr: 0.014515, loss: 1.4036
2022-07-14 04:05:49 - train: epoch 0091, iter [00800, 05004], lr: 0.014497, loss: 1.3221
2022-07-14 04:06:23 - train: epoch 0091, iter [00900, 05004], lr: 0.014479, loss: 1.4700
2022-07-14 04:06:57 - train: epoch 0091, iter [01000, 05004], lr: 0.014460, loss: 1.4167
2022-07-14 04:07:31 - train: epoch 0091, iter [01100, 05004], lr: 0.014442, loss: 1.3024
2022-07-14 04:08:05 - train: epoch 0091, iter [01200, 05004], lr: 0.014423, loss: 1.4964
2022-07-14 04:08:40 - train: epoch 0091, iter [01300, 05004], lr: 0.014405, loss: 1.3473
2022-07-14 04:09:14 - train: epoch 0091, iter [01400, 05004], lr: 0.014387, loss: 1.4724
2022-07-14 04:09:48 - train: epoch 0091, iter [01500, 05004], lr: 0.014368, loss: 1.4586
2022-07-14 04:10:22 - train: epoch 0091, iter [01600, 05004], lr: 0.014350, loss: 1.5637
2022-07-14 04:10:56 - train: epoch 0091, iter [01700, 05004], lr: 0.014332, loss: 1.5295
2022-07-14 04:11:31 - train: epoch 0091, iter [01800, 05004], lr: 0.014313, loss: 1.5341
2022-07-14 04:12:05 - train: epoch 0091, iter [01900, 05004], lr: 0.014295, loss: 1.3252
2022-07-14 04:12:39 - train: epoch 0091, iter [02000, 05004], lr: 0.014277, loss: 1.4563
2022-07-14 04:13:14 - train: epoch 0091, iter [02100, 05004], lr: 0.014258, loss: 1.2590
2022-07-14 04:13:48 - train: epoch 0091, iter [02200, 05004], lr: 0.014240, loss: 1.5386
2022-07-14 04:14:21 - train: epoch 0091, iter [02300, 05004], lr: 0.014222, loss: 1.4959
2022-07-14 04:14:57 - train: epoch 0091, iter [02400, 05004], lr: 0.014204, loss: 1.3428
2022-07-14 04:15:31 - train: epoch 0091, iter [02500, 05004], lr: 0.014185, loss: 1.4137
2022-07-14 04:16:05 - train: epoch 0091, iter [02600, 05004], lr: 0.014167, loss: 1.4889
2022-07-14 04:16:39 - train: epoch 0091, iter [02700, 05004], lr: 0.014149, loss: 1.3688
2022-07-14 04:17:13 - train: epoch 0091, iter [02800, 05004], lr: 0.014131, loss: 1.5389
2022-07-14 04:17:47 - train: epoch 0091, iter [02900, 05004], lr: 0.014112, loss: 1.5228
2022-07-14 04:18:22 - train: epoch 0091, iter [03000, 05004], lr: 0.014094, loss: 1.5912
2022-07-14 04:18:56 - train: epoch 0091, iter [03100, 05004], lr: 0.014076, loss: 1.3606
2022-07-14 04:19:30 - train: epoch 0091, iter [03200, 05004], lr: 0.014058, loss: 1.5391
2022-07-14 04:20:04 - train: epoch 0091, iter [03300, 05004], lr: 0.014040, loss: 1.3580
2022-07-14 04:20:38 - train: epoch 0091, iter [03400, 05004], lr: 0.014021, loss: 1.3465
2022-07-14 04:21:13 - train: epoch 0091, iter [03500, 05004], lr: 0.014003, loss: 1.4978
2022-07-14 04:21:46 - train: epoch 0091, iter [03600, 05004], lr: 0.013985, loss: 1.3373
2022-07-14 04:22:21 - train: epoch 0091, iter [03700, 05004], lr: 0.013967, loss: 1.5564
2022-07-14 04:22:55 - train: epoch 0091, iter [03800, 05004], lr: 0.013949, loss: 1.4578
2022-07-14 04:23:30 - train: epoch 0091, iter [03900, 05004], lr: 0.013931, loss: 1.4256
2022-07-14 04:24:03 - train: epoch 0091, iter [04000, 05004], lr: 0.013913, loss: 1.4030
2022-07-14 04:24:38 - train: epoch 0091, iter [04100, 05004], lr: 0.013894, loss: 1.4324
2022-07-14 04:25:12 - train: epoch 0091, iter [04200, 05004], lr: 0.013876, loss: 1.5087
2022-07-14 04:25:46 - train: epoch 0091, iter [04300, 05004], lr: 0.013858, loss: 1.5144
2022-07-14 04:26:20 - train: epoch 0091, iter [04400, 05004], lr: 0.013840, loss: 1.2461
2022-07-14 04:26:54 - train: epoch 0091, iter [04500, 05004], lr: 0.013822, loss: 1.3906
2022-07-14 04:27:28 - train: epoch 0091, iter [04600, 05004], lr: 0.013804, loss: 1.4407
2022-07-14 04:28:03 - train: epoch 0091, iter [04700, 05004], lr: 0.013786, loss: 1.5560
2022-07-14 04:28:37 - train: epoch 0091, iter [04800, 05004], lr: 0.013768, loss: 1.5010
2022-07-14 04:29:12 - train: epoch 0091, iter [04900, 05004], lr: 0.013750, loss: 1.4053
2022-07-14 04:29:45 - train: epoch 0091, iter [05000, 05004], lr: 0.013732, loss: 1.6304
2022-07-14 04:29:46 - train: epoch 091, train_loss: 1.4607
2022-07-14 04:31:01 - eval: epoch: 091, acc1: 68.142%, acc5: 88.352%, test_loss: 1.3090, per_image_load_time: 2.630ms, per_image_inference_time: 0.298ms
2022-07-14 04:31:01 - until epoch: 091, best_acc1: 68.142%
2022-07-14 04:31:01 - epoch 092 lr: 0.013731
2022-07-14 04:31:41 - train: epoch 0092, iter [00100, 05004], lr: 0.013713, loss: 1.4442
2022-07-14 04:32:15 - train: epoch 0092, iter [00200, 05004], lr: 0.013695, loss: 1.5185
2022-07-14 04:32:48 - train: epoch 0092, iter [00300, 05004], lr: 0.013677, loss: 1.4307
2022-07-14 04:33:24 - train: epoch 0092, iter [00400, 05004], lr: 0.013659, loss: 1.3569
2022-07-14 04:33:57 - train: epoch 0092, iter [00500, 05004], lr: 0.013641, loss: 1.5104
2022-07-14 04:34:32 - train: epoch 0092, iter [00600, 05004], lr: 0.013623, loss: 1.4482
2022-07-14 04:35:06 - train: epoch 0092, iter [00700, 05004], lr: 0.013605, loss: 1.4426
2022-07-14 04:35:40 - train: epoch 0092, iter [00800, 05004], lr: 0.013588, loss: 1.5413
2022-07-14 04:36:13 - train: epoch 0092, iter [00900, 05004], lr: 0.013570, loss: 1.4196
2022-07-14 04:36:47 - train: epoch 0092, iter [01000, 05004], lr: 0.013552, loss: 1.6733
2022-07-14 04:37:22 - train: epoch 0092, iter [01100, 05004], lr: 0.013534, loss: 1.3744
2022-07-14 04:37:55 - train: epoch 0092, iter [01200, 05004], lr: 0.013516, loss: 1.3729
2022-07-14 04:38:29 - train: epoch 0092, iter [01300, 05004], lr: 0.013498, loss: 1.4243
2022-07-14 04:39:04 - train: epoch 0092, iter [01400, 05004], lr: 0.013480, loss: 1.3651
2022-07-14 04:39:38 - train: epoch 0092, iter [01500, 05004], lr: 0.013462, loss: 1.3139
2022-07-14 04:40:12 - train: epoch 0092, iter [01600, 05004], lr: 0.013444, loss: 1.4940
2022-07-14 04:40:46 - train: epoch 0092, iter [01700, 05004], lr: 0.013427, loss: 1.4274
2022-07-14 04:41:21 - train: epoch 0092, iter [01800, 05004], lr: 0.013409, loss: 1.3975
2022-07-14 04:41:54 - train: epoch 0092, iter [01900, 05004], lr: 0.013391, loss: 1.3095
2022-07-14 04:42:29 - train: epoch 0092, iter [02000, 05004], lr: 0.013373, loss: 1.3276
2022-07-14 04:43:03 - train: epoch 0092, iter [02100, 05004], lr: 0.013355, loss: 1.3905
2022-07-14 04:43:37 - train: epoch 0092, iter [02200, 05004], lr: 0.013338, loss: 1.4368
2022-07-14 04:44:11 - train: epoch 0092, iter [02300, 05004], lr: 0.013320, loss: 1.4896
2022-07-14 04:44:46 - train: epoch 0092, iter [02400, 05004], lr: 0.013302, loss: 1.3426
2022-07-14 04:45:20 - train: epoch 0092, iter [02500, 05004], lr: 0.013284, loss: 1.4565
2022-07-14 04:45:54 - train: epoch 0092, iter [02600, 05004], lr: 0.013266, loss: 1.4976
2022-07-14 04:46:28 - train: epoch 0092, iter [02700, 05004], lr: 0.013249, loss: 1.5417
2022-07-14 04:47:03 - train: epoch 0092, iter [02800, 05004], lr: 0.013231, loss: 1.4099
2022-07-14 04:47:36 - train: epoch 0092, iter [02900, 05004], lr: 0.013213, loss: 1.5082
2022-07-14 04:48:11 - train: epoch 0092, iter [03000, 05004], lr: 0.013196, loss: 1.2756
2022-07-14 04:48:44 - train: epoch 0092, iter [03100, 05004], lr: 0.013178, loss: 1.3957
2022-07-14 04:49:19 - train: epoch 0092, iter [03200, 05004], lr: 0.013160, loss: 1.3521
2022-07-14 04:49:52 - train: epoch 0092, iter [03300, 05004], lr: 0.013142, loss: 1.4757
2022-07-14 04:50:26 - train: epoch 0092, iter [03400, 05004], lr: 0.013125, loss: 1.6422
2022-07-14 04:51:00 - train: epoch 0092, iter [03500, 05004], lr: 0.013107, loss: 1.3978
2022-07-14 04:51:35 - train: epoch 0092, iter [03600, 05004], lr: 0.013090, loss: 1.3892
2022-07-14 04:52:08 - train: epoch 0092, iter [03700, 05004], lr: 0.013072, loss: 1.3715
2022-07-14 04:52:43 - train: epoch 0092, iter [03800, 05004], lr: 0.013054, loss: 1.6329
2022-07-14 04:53:16 - train: epoch 0092, iter [03900, 05004], lr: 0.013037, loss: 1.4559
2022-07-14 04:53:51 - train: epoch 0092, iter [04000, 05004], lr: 0.013019, loss: 1.6513
2022-07-14 04:54:24 - train: epoch 0092, iter [04100, 05004], lr: 0.013001, loss: 1.2236
2022-07-14 04:55:00 - train: epoch 0092, iter [04200, 05004], lr: 0.012984, loss: 1.4678
2022-07-14 04:55:34 - train: epoch 0092, iter [04300, 05004], lr: 0.012966, loss: 1.4697
2022-07-14 04:56:08 - train: epoch 0092, iter [04400, 05004], lr: 0.012949, loss: 1.2999
2022-07-14 04:56:42 - train: epoch 0092, iter [04500, 05004], lr: 0.012931, loss: 1.3750
2022-07-14 04:57:17 - train: epoch 0092, iter [04600, 05004], lr: 0.012914, loss: 1.4304
2022-07-14 04:57:50 - train: epoch 0092, iter [04700, 05004], lr: 0.012896, loss: 1.1209
2022-07-14 04:58:25 - train: epoch 0092, iter [04800, 05004], lr: 0.012878, loss: 1.3608
2022-07-14 04:58:58 - train: epoch 0092, iter [04900, 05004], lr: 0.012861, loss: 1.4272
2022-07-14 04:59:31 - train: epoch 0092, iter [05000, 05004], lr: 0.012843, loss: 1.5713
2022-07-14 04:59:32 - train: epoch 092, train_loss: 1.4433
2022-07-14 05:00:48 - eval: epoch: 092, acc1: 68.384%, acc5: 88.506%, test_loss: 1.2970, per_image_load_time: 2.566ms, per_image_inference_time: 0.296ms
2022-07-14 05:00:48 - until epoch: 092, best_acc1: 68.384%
2022-07-14 05:00:48 - epoch 093 lr: 0.012843
2022-07-14 05:01:27 - train: epoch 0093, iter [00100, 05004], lr: 0.012825, loss: 1.3105
2022-07-14 05:02:01 - train: epoch 0093, iter [00200, 05004], lr: 0.012808, loss: 1.2736
2022-07-14 05:02:35 - train: epoch 0093, iter [00300, 05004], lr: 0.012790, loss: 1.4879
2022-07-14 05:03:10 - train: epoch 0093, iter [00400, 05004], lr: 0.012773, loss: 1.3628
2022-07-14 05:03:44 - train: epoch 0093, iter [00500, 05004], lr: 0.012755, loss: 1.6029
2022-07-14 05:04:18 - train: epoch 0093, iter [00600, 05004], lr: 0.012738, loss: 1.3042
2022-07-14 05:04:51 - train: epoch 0093, iter [00700, 05004], lr: 0.012720, loss: 1.4650
2022-07-14 05:05:25 - train: epoch 0093, iter [00800, 05004], lr: 0.012703, loss: 1.3372
2022-07-14 05:05:59 - train: epoch 0093, iter [00900, 05004], lr: 0.012686, loss: 1.4121
2022-07-14 05:06:33 - train: epoch 0093, iter [01000, 05004], lr: 0.012668, loss: 1.2173
2022-07-14 05:07:07 - train: epoch 0093, iter [01100, 05004], lr: 0.012651, loss: 1.3090
2022-07-14 05:07:41 - train: epoch 0093, iter [01200, 05004], lr: 0.012633, loss: 1.2936
2022-07-14 05:08:16 - train: epoch 0093, iter [01300, 05004], lr: 0.012616, loss: 1.5058
2022-07-14 05:08:49 - train: epoch 0093, iter [01400, 05004], lr: 0.012599, loss: 1.3223
2022-07-14 05:09:23 - train: epoch 0093, iter [01500, 05004], lr: 0.012581, loss: 1.5992
2022-07-14 05:09:58 - train: epoch 0093, iter [01600, 05004], lr: 0.012564, loss: 1.4884
2022-07-14 05:10:32 - train: epoch 0093, iter [01700, 05004], lr: 0.012547, loss: 1.3473
2022-07-14 05:11:06 - train: epoch 0093, iter [01800, 05004], lr: 0.012529, loss: 1.4596
2022-07-14 05:11:41 - train: epoch 0093, iter [01900, 05004], lr: 0.012512, loss: 1.3095
2022-07-14 05:12:15 - train: epoch 0093, iter [02000, 05004], lr: 0.012495, loss: 1.3287
2022-07-14 05:12:50 - train: epoch 0093, iter [02100, 05004], lr: 0.012477, loss: 1.2657
2022-07-14 05:13:24 - train: epoch 0093, iter [02200, 05004], lr: 0.012460, loss: 1.5284
2022-07-14 05:13:59 - train: epoch 0093, iter [02300, 05004], lr: 0.012443, loss: 1.5901
2022-07-14 05:14:32 - train: epoch 0093, iter [02400, 05004], lr: 0.012426, loss: 1.3254
2022-07-14 05:15:06 - train: epoch 0093, iter [02500, 05004], lr: 0.012408, loss: 1.3770
2022-07-14 05:15:41 - train: epoch 0093, iter [02600, 05004], lr: 0.012391, loss: 1.6859
2022-07-14 05:16:15 - train: epoch 0093, iter [02700, 05004], lr: 0.012374, loss: 1.2721
2022-07-14 05:16:49 - train: epoch 0093, iter [02800, 05004], lr: 0.012357, loss: 1.3690
2022-07-14 05:17:23 - train: epoch 0093, iter [02900, 05004], lr: 0.012339, loss: 1.4586
2022-07-14 05:17:58 - train: epoch 0093, iter [03000, 05004], lr: 0.012322, loss: 1.3205
2022-07-14 05:18:32 - train: epoch 0093, iter [03100, 05004], lr: 0.012305, loss: 1.6120
2022-07-14 05:19:06 - train: epoch 0093, iter [03200, 05004], lr: 0.012288, loss: 1.2928
2022-07-14 05:19:41 - train: epoch 0093, iter [03300, 05004], lr: 0.012271, loss: 1.4293
2022-07-14 05:20:16 - train: epoch 0093, iter [03400, 05004], lr: 0.012254, loss: 1.6675
2022-07-14 05:20:50 - train: epoch 0093, iter [03500, 05004], lr: 0.012236, loss: 1.2094
2022-07-14 05:21:25 - train: epoch 0093, iter [03600, 05004], lr: 0.012219, loss: 1.5130
2022-07-14 05:21:58 - train: epoch 0093, iter [03700, 05004], lr: 0.012202, loss: 1.3510
2022-07-14 05:22:33 - train: epoch 0093, iter [03800, 05004], lr: 0.012185, loss: 1.3153
2022-07-14 05:23:07 - train: epoch 0093, iter [03900, 05004], lr: 0.012168, loss: 1.3910
2022-07-14 05:23:42 - train: epoch 0093, iter [04000, 05004], lr: 0.012151, loss: 1.6758
2022-07-14 05:24:16 - train: epoch 0093, iter [04100, 05004], lr: 0.012134, loss: 1.6248
2022-07-14 05:24:50 - train: epoch 0093, iter [04200, 05004], lr: 0.012117, loss: 1.4495
2022-07-14 05:25:24 - train: epoch 0093, iter [04300, 05004], lr: 0.012100, loss: 1.6004
2022-07-14 05:25:59 - train: epoch 0093, iter [04400, 05004], lr: 0.012083, loss: 1.3169
2022-07-14 05:26:33 - train: epoch 0093, iter [04500, 05004], lr: 0.012065, loss: 1.4271
2022-07-14 05:27:08 - train: epoch 0093, iter [04600, 05004], lr: 0.012048, loss: 1.2777
2022-07-14 05:27:42 - train: epoch 0093, iter [04700, 05004], lr: 0.012031, loss: 1.8275
2022-07-14 05:28:16 - train: epoch 0093, iter [04800, 05004], lr: 0.012014, loss: 1.4556
2022-07-14 05:28:50 - train: epoch 0093, iter [04900, 05004], lr: 0.011997, loss: 1.5664
2022-07-14 05:29:23 - train: epoch 0093, iter [05000, 05004], lr: 0.011980, loss: 1.3368
2022-07-14 05:29:24 - train: epoch 093, train_loss: 1.4262
2022-07-14 05:30:40 - eval: epoch: 093, acc1: 68.724%, acc5: 88.796%, test_loss: 1.2757, per_image_load_time: 2.419ms, per_image_inference_time: 0.308ms
2022-07-14 05:30:40 - until epoch: 093, best_acc1: 68.724%
2022-07-14 05:30:40 - epoch 094 lr: 0.011980
2022-07-14 05:31:19 - train: epoch 0094, iter [00100, 05004], lr: 0.011963, loss: 1.4636
2022-07-14 05:31:53 - train: epoch 0094, iter [00200, 05004], lr: 0.011946, loss: 1.4653
2022-07-14 05:32:27 - train: epoch 0094, iter [00300, 05004], lr: 0.011929, loss: 1.5112
2022-07-14 05:33:02 - train: epoch 0094, iter [00400, 05004], lr: 0.011912, loss: 1.5551
2022-07-14 05:33:35 - train: epoch 0094, iter [00500, 05004], lr: 0.011895, loss: 1.3300
2022-07-14 05:34:09 - train: epoch 0094, iter [00600, 05004], lr: 0.011878, loss: 1.1714
2022-07-14 05:34:43 - train: epoch 0094, iter [00700, 05004], lr: 0.011861, loss: 1.4619
2022-07-14 05:35:18 - train: epoch 0094, iter [00800, 05004], lr: 0.011844, loss: 1.2639
2022-07-14 05:35:50 - train: epoch 0094, iter [00900, 05004], lr: 0.011827, loss: 1.4003
2022-07-14 05:36:25 - train: epoch 0094, iter [01000, 05004], lr: 0.011810, loss: 1.4192
2022-07-14 05:36:59 - train: epoch 0094, iter [01100, 05004], lr: 0.011793, loss: 1.6680
2022-07-14 05:37:34 - train: epoch 0094, iter [01200, 05004], lr: 0.011777, loss: 1.3382
2022-07-14 05:38:07 - train: epoch 0094, iter [01300, 05004], lr: 0.011760, loss: 1.4553
2022-07-14 05:38:41 - train: epoch 0094, iter [01400, 05004], lr: 0.011743, loss: 1.4056
2022-07-14 05:39:15 - train: epoch 0094, iter [01500, 05004], lr: 0.011726, loss: 1.4493
2022-07-14 05:39:50 - train: epoch 0094, iter [01600, 05004], lr: 0.011709, loss: 1.7969
2022-07-14 05:40:24 - train: epoch 0094, iter [01700, 05004], lr: 0.011692, loss: 1.2922
2022-07-14 05:40:59 - train: epoch 0094, iter [01800, 05004], lr: 0.011676, loss: 1.3774
2022-07-14 05:41:32 - train: epoch 0094, iter [01900, 05004], lr: 0.011659, loss: 1.4086
2022-07-14 05:42:07 - train: epoch 0094, iter [02000, 05004], lr: 0.011642, loss: 1.2415
2022-07-14 05:42:41 - train: epoch 0094, iter [02100, 05004], lr: 0.011625, loss: 1.4520
2022-07-14 05:43:16 - train: epoch 0094, iter [02200, 05004], lr: 0.011608, loss: 1.1879
2022-07-14 05:43:50 - train: epoch 0094, iter [02300, 05004], lr: 0.011592, loss: 1.2768
2022-07-14 05:44:25 - train: epoch 0094, iter [02400, 05004], lr: 0.011575, loss: 1.3945
2022-07-14 05:44:59 - train: epoch 0094, iter [02500, 05004], lr: 0.011558, loss: 1.3400
2022-07-14 05:45:33 - train: epoch 0094, iter [02600, 05004], lr: 0.011542, loss: 1.3022
2022-07-14 05:46:08 - train: epoch 0094, iter [02700, 05004], lr: 0.011525, loss: 1.4255
2022-07-14 05:46:42 - train: epoch 0094, iter [02800, 05004], lr: 0.011508, loss: 1.4543
2022-07-14 05:47:17 - train: epoch 0094, iter [02900, 05004], lr: 0.011491, loss: 1.3533
2022-07-14 05:47:51 - train: epoch 0094, iter [03000, 05004], lr: 0.011475, loss: 1.2976
2022-07-14 05:48:25 - train: epoch 0094, iter [03100, 05004], lr: 0.011458, loss: 1.5616
2022-07-14 05:49:00 - train: epoch 0094, iter [03200, 05004], lr: 0.011441, loss: 1.4240
2022-07-14 05:49:34 - train: epoch 0094, iter [03300, 05004], lr: 0.011425, loss: 1.3340
2022-07-14 05:50:09 - train: epoch 0094, iter [03400, 05004], lr: 0.011408, loss: 1.4915
2022-07-14 05:50:42 - train: epoch 0094, iter [03500, 05004], lr: 0.011391, loss: 1.6376
2022-07-14 05:51:17 - train: epoch 0094, iter [03600, 05004], lr: 0.011375, loss: 1.3952
2022-07-14 05:51:50 - train: epoch 0094, iter [03700, 05004], lr: 0.011358, loss: 1.5935
2022-07-14 05:52:26 - train: epoch 0094, iter [03800, 05004], lr: 0.011342, loss: 1.3502
2022-07-14 05:52:59 - train: epoch 0094, iter [03900, 05004], lr: 0.011325, loss: 1.3367
2022-07-14 05:53:34 - train: epoch 0094, iter [04000, 05004], lr: 0.011309, loss: 1.6312
2022-07-14 05:54:08 - train: epoch 0094, iter [04100, 05004], lr: 0.011292, loss: 1.6719
2022-07-14 05:54:42 - train: epoch 0094, iter [04200, 05004], lr: 0.011275, loss: 1.2259
2022-07-14 05:55:17 - train: epoch 0094, iter [04300, 05004], lr: 0.011259, loss: 1.5400
2022-07-14 05:55:51 - train: epoch 0094, iter [04400, 05004], lr: 0.011242, loss: 1.5617
2022-07-14 05:56:25 - train: epoch 0094, iter [04500, 05004], lr: 0.011226, loss: 1.4341
2022-07-14 05:57:00 - train: epoch 0094, iter [04600, 05004], lr: 0.011209, loss: 1.5214
2022-07-14 05:57:33 - train: epoch 0094, iter [04700, 05004], lr: 0.011193, loss: 1.4247
2022-07-14 05:58:09 - train: epoch 0094, iter [04800, 05004], lr: 0.011176, loss: 1.5454
2022-07-14 05:58:42 - train: epoch 0094, iter [04900, 05004], lr: 0.011160, loss: 1.3787
2022-07-14 05:59:14 - train: epoch 0094, iter [05000, 05004], lr: 0.011143, loss: 1.3304
2022-07-14 05:59:15 - train: epoch 094, train_loss: 1.4110
2022-07-14 06:00:30 - eval: epoch: 094, acc1: 68.770%, acc5: 88.758%, test_loss: 1.2766, per_image_load_time: 1.036ms, per_image_inference_time: 0.310ms
2022-07-14 06:00:30 - until epoch: 094, best_acc1: 68.770%
2022-07-14 06:00:30 - epoch 095 lr: 0.011143
2022-07-14 06:01:11 - train: epoch 0095, iter [00100, 05004], lr: 0.011126, loss: 1.2175
2022-07-14 06:01:45 - train: epoch 0095, iter [00200, 05004], lr: 0.011110, loss: 1.5437
2022-07-14 06:02:18 - train: epoch 0095, iter [00300, 05004], lr: 0.011093, loss: 1.2917
2022-07-14 06:02:52 - train: epoch 0095, iter [00400, 05004], lr: 0.011077, loss: 1.4799
2022-07-14 06:03:26 - train: epoch 0095, iter [00500, 05004], lr: 0.011061, loss: 1.4752
2022-07-14 06:04:00 - train: epoch 0095, iter [00600, 05004], lr: 0.011044, loss: 1.4042
2022-07-14 06:04:33 - train: epoch 0095, iter [00700, 05004], lr: 0.011028, loss: 1.5262
2022-07-14 06:05:08 - train: epoch 0095, iter [00800, 05004], lr: 0.011011, loss: 1.6091
2022-07-14 06:05:41 - train: epoch 0095, iter [00900, 05004], lr: 0.010995, loss: 1.6547
2022-07-14 06:06:15 - train: epoch 0095, iter [01000, 05004], lr: 0.010979, loss: 1.5553
2022-07-14 06:06:49 - train: epoch 0095, iter [01100, 05004], lr: 0.010962, loss: 1.2538
2022-07-14 06:07:23 - train: epoch 0095, iter [01200, 05004], lr: 0.010946, loss: 1.2680
2022-07-14 06:07:57 - train: epoch 0095, iter [01300, 05004], lr: 0.010930, loss: 1.3325
2022-07-14 06:08:31 - train: epoch 0095, iter [01400, 05004], lr: 0.010913, loss: 1.4697
2022-07-14 06:09:05 - train: epoch 0095, iter [01500, 05004], lr: 0.010897, loss: 1.5342
2022-07-14 06:09:39 - train: epoch 0095, iter [01600, 05004], lr: 0.010881, loss: 1.0791
2022-07-14 06:10:13 - train: epoch 0095, iter [01700, 05004], lr: 0.010864, loss: 1.4091
2022-07-14 06:10:48 - train: epoch 0095, iter [01800, 05004], lr: 0.010848, loss: 1.4369
2022-07-14 06:11:22 - train: epoch 0095, iter [01900, 05004], lr: 0.010832, loss: 1.2442
2022-07-14 06:11:56 - train: epoch 0095, iter [02000, 05004], lr: 0.010816, loss: 1.4292
2022-07-14 06:12:30 - train: epoch 0095, iter [02100, 05004], lr: 0.010799, loss: 1.5538
2022-07-14 06:13:04 - train: epoch 0095, iter [02200, 05004], lr: 0.010783, loss: 1.0747
2022-07-14 06:13:39 - train: epoch 0095, iter [02300, 05004], lr: 0.010767, loss: 1.3018
2022-07-14 06:14:14 - train: epoch 0095, iter [02400, 05004], lr: 0.010751, loss: 1.4853
2022-07-14 06:14:47 - train: epoch 0095, iter [02500, 05004], lr: 0.010734, loss: 1.3131
2022-07-14 06:15:22 - train: epoch 0095, iter [02600, 05004], lr: 0.010718, loss: 1.4006
2022-07-14 06:15:56 - train: epoch 0095, iter [02700, 05004], lr: 0.010702, loss: 1.4323
2022-07-14 06:16:29 - train: epoch 0095, iter [02800, 05004], lr: 0.010686, loss: 1.2358
2022-07-14 06:17:05 - train: epoch 0095, iter [02900, 05004], lr: 0.010670, loss: 1.3294
2022-07-14 06:17:39 - train: epoch 0095, iter [03000, 05004], lr: 0.010654, loss: 1.6317
2022-07-14 06:18:13 - train: epoch 0095, iter [03100, 05004], lr: 0.010638, loss: 1.5817
2022-07-14 06:18:47 - train: epoch 0095, iter [03200, 05004], lr: 0.010621, loss: 1.4170
2022-07-14 06:19:21 - train: epoch 0095, iter [03300, 05004], lr: 0.010605, loss: 1.4094
2022-07-14 06:19:55 - train: epoch 0095, iter [03400, 05004], lr: 0.010589, loss: 1.3158
2022-07-14 06:20:30 - train: epoch 0095, iter [03500, 05004], lr: 0.010573, loss: 1.3612
2022-07-14 06:21:04 - train: epoch 0095, iter [03600, 05004], lr: 0.010557, loss: 1.3284
2022-07-14 06:21:38 - train: epoch 0095, iter [03700, 05004], lr: 0.010541, loss: 1.3155
2022-07-14 06:22:12 - train: epoch 0095, iter [03800, 05004], lr: 0.010525, loss: 1.1365
2022-07-14 06:22:46 - train: epoch 0095, iter [03900, 05004], lr: 0.010509, loss: 1.3931
2022-07-14 06:23:20 - train: epoch 0095, iter [04000, 05004], lr: 0.010493, loss: 1.2169
2022-07-14 06:23:54 - train: epoch 0095, iter [04100, 05004], lr: 0.010477, loss: 1.3935
2022-07-14 06:24:28 - train: epoch 0095, iter [04200, 05004], lr: 0.010461, loss: 1.2834
2022-07-14 06:25:02 - train: epoch 0095, iter [04300, 05004], lr: 0.010445, loss: 1.5244
2022-07-14 06:25:37 - train: epoch 0095, iter [04400, 05004], lr: 0.010429, loss: 1.4433
2022-07-14 06:26:11 - train: epoch 0095, iter [04500, 05004], lr: 0.010413, loss: 1.2713
2022-07-14 06:26:45 - train: epoch 0095, iter [04600, 05004], lr: 0.010397, loss: 1.3752
2022-07-14 06:27:19 - train: epoch 0095, iter [04700, 05004], lr: 0.010381, loss: 1.2951
2022-07-14 06:27:53 - train: epoch 0095, iter [04800, 05004], lr: 0.010365, loss: 1.5593
2022-07-14 06:28:27 - train: epoch 0095, iter [04900, 05004], lr: 0.010349, loss: 1.2657
2022-07-14 06:29:00 - train: epoch 0095, iter [05000, 05004], lr: 0.010333, loss: 1.1787
2022-07-14 06:29:01 - train: epoch 095, train_loss: 1.3943
2022-07-14 06:30:16 - eval: epoch: 095, acc1: 69.478%, acc5: 89.208%, test_loss: 1.2422, per_image_load_time: 2.191ms, per_image_inference_time: 0.313ms
2022-07-14 06:30:16 - until epoch: 095, best_acc1: 69.478%
2022-07-14 06:30:16 - epoch 096 lr: 0.010332
2022-07-14 06:30:55 - train: epoch 0096, iter [00100, 05004], lr: 0.010316, loss: 1.3648
2022-07-14 06:31:29 - train: epoch 0096, iter [00200, 05004], lr: 0.010301, loss: 1.2809
2022-07-14 06:32:02 - train: epoch 0096, iter [00300, 05004], lr: 0.010285, loss: 1.3964
2022-07-14 06:32:36 - train: epoch 0096, iter [00400, 05004], lr: 0.010269, loss: 1.2886
2022-07-14 06:33:10 - train: epoch 0096, iter [00500, 05004], lr: 0.010253, loss: 1.3012
2022-07-14 06:33:44 - train: epoch 0096, iter [00600, 05004], lr: 0.010237, loss: 1.4726
2022-07-14 06:34:18 - train: epoch 0096, iter [00700, 05004], lr: 0.010221, loss: 1.2451
2022-07-14 06:34:53 - train: epoch 0096, iter [00800, 05004], lr: 0.010205, loss: 1.3442
2022-07-14 06:35:26 - train: epoch 0096, iter [00900, 05004], lr: 0.010189, loss: 1.3864
2022-07-14 06:36:00 - train: epoch 0096, iter [01000, 05004], lr: 0.010174, loss: 1.3658
2022-07-14 06:36:33 - train: epoch 0096, iter [01100, 05004], lr: 0.010158, loss: 1.4004
2022-07-14 06:37:09 - train: epoch 0096, iter [01200, 05004], lr: 0.010142, loss: 1.4157
2022-07-14 06:37:42 - train: epoch 0096, iter [01300, 05004], lr: 0.010126, loss: 1.3901
2022-07-14 06:38:16 - train: epoch 0096, iter [01400, 05004], lr: 0.010110, loss: 1.2409
2022-07-14 06:38:50 - train: epoch 0096, iter [01500, 05004], lr: 0.010095, loss: 1.2683
2022-07-14 06:39:25 - train: epoch 0096, iter [01600, 05004], lr: 0.010079, loss: 1.1108
2022-07-14 06:39:59 - train: epoch 0096, iter [01700, 05004], lr: 0.010063, loss: 1.3494
2022-07-14 06:40:33 - train: epoch 0096, iter [01800, 05004], lr: 0.010047, loss: 1.5227
2022-07-14 06:41:07 - train: epoch 0096, iter [01900, 05004], lr: 0.010032, loss: 1.5585
2022-07-14 06:41:41 - train: epoch 0096, iter [02000, 05004], lr: 0.010016, loss: 1.3169
2022-07-14 06:42:15 - train: epoch 0096, iter [02100, 05004], lr: 0.010000, loss: 1.3579
2022-07-14 06:42:49 - train: epoch 0096, iter [02200, 05004], lr: 0.009985, loss: 1.2387
2022-07-14 06:43:23 - train: epoch 0096, iter [02300, 05004], lr: 0.009969, loss: 1.3313
2022-07-14 06:43:56 - train: epoch 0096, iter [02400, 05004], lr: 0.009953, loss: 1.1825
2022-07-14 06:44:31 - train: epoch 0096, iter [02500, 05004], lr: 0.009938, loss: 1.3071
2022-07-14 06:45:04 - train: epoch 0096, iter [02600, 05004], lr: 0.009922, loss: 1.2458
2022-07-14 06:45:39 - train: epoch 0096, iter [02700, 05004], lr: 0.009906, loss: 1.4384
2022-07-14 06:46:13 - train: epoch 0096, iter [02800, 05004], lr: 0.009891, loss: 1.5089
2022-07-14 06:46:47 - train: epoch 0096, iter [02900, 05004], lr: 0.009875, loss: 1.3334
2022-07-14 06:47:22 - train: epoch 0096, iter [03000, 05004], lr: 0.009860, loss: 1.3408
2022-07-14 06:47:56 - train: epoch 0096, iter [03100, 05004], lr: 0.009844, loss: 1.4392
2022-07-14 06:48:30 - train: epoch 0096, iter [03200, 05004], lr: 0.009828, loss: 1.3860
2022-07-14 06:49:05 - train: epoch 0096, iter [03300, 05004], lr: 0.009813, loss: 1.5448
2022-07-14 06:49:38 - train: epoch 0096, iter [03400, 05004], lr: 0.009797, loss: 1.1648
2022-07-14 06:50:13 - train: epoch 0096, iter [03500, 05004], lr: 0.009782, loss: 1.3467
2022-07-14 06:50:46 - train: epoch 0096, iter [03600, 05004], lr: 0.009766, loss: 1.1591
2022-07-14 06:51:21 - train: epoch 0096, iter [03700, 05004], lr: 0.009751, loss: 1.4085
2022-07-14 06:51:55 - train: epoch 0096, iter [03800, 05004], lr: 0.009735, loss: 1.3248
2022-07-14 06:52:29 - train: epoch 0096, iter [03900, 05004], lr: 0.009720, loss: 1.2842
2022-07-14 06:53:04 - train: epoch 0096, iter [04000, 05004], lr: 0.009704, loss: 1.1903
2022-07-14 06:53:37 - train: epoch 0096, iter [04100, 05004], lr: 0.009689, loss: 1.3803
2022-07-14 06:54:12 - train: epoch 0096, iter [04200, 05004], lr: 0.009673, loss: 1.4213
2022-07-14 06:54:46 - train: epoch 0096, iter [04300, 05004], lr: 0.009658, loss: 1.1309
2022-07-14 06:55:20 - train: epoch 0096, iter [04400, 05004], lr: 0.009642, loss: 1.2851
2022-07-14 06:55:55 - train: epoch 0096, iter [04500, 05004], lr: 0.009627, loss: 1.2681
2022-07-14 06:56:27 - train: epoch 0096, iter [04600, 05004], lr: 0.009611, loss: 1.2943
2022-07-14 06:57:02 - train: epoch 0096, iter [04700, 05004], lr: 0.009596, loss: 1.4056
2022-07-14 06:57:36 - train: epoch 0096, iter [04800, 05004], lr: 0.009581, loss: 1.4157
2022-07-14 06:58:11 - train: epoch 0096, iter [04900, 05004], lr: 0.009565, loss: 1.6292
2022-07-14 06:58:43 - train: epoch 0096, iter [05000, 05004], lr: 0.009550, loss: 1.3130
2022-07-14 06:58:44 - train: epoch 096, train_loss: 1.3733
2022-07-14 06:59:59 - eval: epoch: 096, acc1: 69.542%, acc5: 89.256%, test_loss: 1.2416, per_image_load_time: 1.309ms, per_image_inference_time: 0.331ms
2022-07-14 06:59:59 - until epoch: 096, best_acc1: 69.542%
2022-07-14 06:59:59 - epoch 097 lr: 0.009549
2022-07-14 07:00:38 - train: epoch 0097, iter [00100, 05004], lr: 0.009534, loss: 1.4711
2022-07-14 07:01:12 - train: epoch 0097, iter [00200, 05004], lr: 0.009518, loss: 1.1111
2022-07-14 07:01:46 - train: epoch 0097, iter [00300, 05004], lr: 0.009503, loss: 1.5328
2022-07-14 07:02:20 - train: epoch 0097, iter [00400, 05004], lr: 0.009488, loss: 1.6313
2022-07-14 07:02:54 - train: epoch 0097, iter [00500, 05004], lr: 0.009472, loss: 1.2643
2022-07-14 07:03:28 - train: epoch 0097, iter [00600, 05004], lr: 0.009457, loss: 1.3921
2022-07-14 07:04:03 - train: epoch 0097, iter [00700, 05004], lr: 0.009442, loss: 1.3262
2022-07-14 07:04:37 - train: epoch 0097, iter [00800, 05004], lr: 0.009426, loss: 1.1995
2022-07-14 07:05:11 - train: epoch 0097, iter [00900, 05004], lr: 0.009411, loss: 1.2454
2022-07-14 07:05:45 - train: epoch 0097, iter [01000, 05004], lr: 0.009396, loss: 1.3327
2022-07-14 07:06:20 - train: epoch 0097, iter [01100, 05004], lr: 0.009381, loss: 1.1666
2022-07-14 07:06:53 - train: epoch 0097, iter [01200, 05004], lr: 0.009365, loss: 1.3069
2022-07-14 07:07:28 - train: epoch 0097, iter [01300, 05004], lr: 0.009350, loss: 1.3627
2022-07-14 07:08:02 - train: epoch 0097, iter [01400, 05004], lr: 0.009335, loss: 1.3409
2022-07-14 07:08:36 - train: epoch 0097, iter [01500, 05004], lr: 0.009320, loss: 1.3695
2022-07-14 07:09:11 - train: epoch 0097, iter [01600, 05004], lr: 0.009305, loss: 1.3744
2022-07-14 07:09:46 - train: epoch 0097, iter [01700, 05004], lr: 0.009289, loss: 1.2458
2022-07-14 07:10:20 - train: epoch 0097, iter [01800, 05004], lr: 0.009274, loss: 1.4089
2022-07-14 07:10:54 - train: epoch 0097, iter [01900, 05004], lr: 0.009259, loss: 1.3654
2022-07-14 07:11:29 - train: epoch 0097, iter [02000, 05004], lr: 0.009244, loss: 1.2785
2022-07-14 07:12:03 - train: epoch 0097, iter [02100, 05004], lr: 0.009229, loss: 1.3479
2022-07-14 07:12:37 - train: epoch 0097, iter [02200, 05004], lr: 0.009214, loss: 1.5380
2022-07-14 07:13:11 - train: epoch 0097, iter [02300, 05004], lr: 0.009198, loss: 1.3083
2022-07-14 07:13:45 - train: epoch 0097, iter [02400, 05004], lr: 0.009183, loss: 1.3725
2022-07-14 07:14:19 - train: epoch 0097, iter [02500, 05004], lr: 0.009168, loss: 1.3289
2022-07-14 07:14:53 - train: epoch 0097, iter [02600, 05004], lr: 0.009153, loss: 1.4691
2022-07-14 07:15:28 - train: epoch 0097, iter [02700, 05004], lr: 0.009138, loss: 1.1995
2022-07-14 07:16:02 - train: epoch 0097, iter [02800, 05004], lr: 0.009123, loss: 1.3161
2022-07-14 07:16:37 - train: epoch 0097, iter [02900, 05004], lr: 0.009108, loss: 1.4830
2022-07-14 07:17:11 - train: epoch 0097, iter [03000, 05004], lr: 0.009093, loss: 1.3923
2022-07-14 07:17:45 - train: epoch 0097, iter [03100, 05004], lr: 0.009078, loss: 1.3017
2022-07-14 07:18:19 - train: epoch 0097, iter [03200, 05004], lr: 0.009063, loss: 1.4295
2022-07-14 07:18:54 - train: epoch 0097, iter [03300, 05004], lr: 0.009048, loss: 1.4999
2022-07-14 07:19:28 - train: epoch 0097, iter [03400, 05004], lr: 0.009033, loss: 1.5430
2022-07-14 07:20:02 - train: epoch 0097, iter [03500, 05004], lr: 0.009018, loss: 1.4395
2022-07-14 07:20:37 - train: epoch 0097, iter [03600, 05004], lr: 0.009003, loss: 1.3232
2022-07-14 07:21:10 - train: epoch 0097, iter [03700, 05004], lr: 0.008988, loss: 1.1842
2022-07-14 07:21:44 - train: epoch 0097, iter [03800, 05004], lr: 0.008973, loss: 1.2216
2022-07-14 07:22:18 - train: epoch 0097, iter [03900, 05004], lr: 0.008958, loss: 1.3734
2022-07-14 07:22:54 - train: epoch 0097, iter [04000, 05004], lr: 0.008943, loss: 1.3690
2022-07-14 07:23:27 - train: epoch 0097, iter [04100, 05004], lr: 0.008928, loss: 1.3531
2022-07-14 07:24:02 - train: epoch 0097, iter [04200, 05004], lr: 0.008913, loss: 1.3558
2022-07-14 07:24:36 - train: epoch 0097, iter [04300, 05004], lr: 0.008898, loss: 1.2726
2022-07-14 07:25:10 - train: epoch 0097, iter [04400, 05004], lr: 0.008883, loss: 1.3636
2022-07-14 07:25:44 - train: epoch 0097, iter [04500, 05004], lr: 0.008869, loss: 1.3753
2022-07-14 07:26:18 - train: epoch 0097, iter [04600, 05004], lr: 0.008854, loss: 1.4975
2022-07-14 07:26:53 - train: epoch 0097, iter [04700, 05004], lr: 0.008839, loss: 1.3588
2022-07-14 07:27:27 - train: epoch 0097, iter [04800, 05004], lr: 0.008824, loss: 1.3708
2022-07-14 07:28:02 - train: epoch 0097, iter [04900, 05004], lr: 0.008809, loss: 1.6031
2022-07-14 07:28:34 - train: epoch 0097, iter [05000, 05004], lr: 0.008794, loss: 1.4043
2022-07-14 07:28:35 - train: epoch 097, train_loss: 1.3567
2022-07-14 07:29:51 - eval: epoch: 097, acc1: 69.774%, acc5: 89.516%, test_loss: 1.2224, per_image_load_time: 1.633ms, per_image_inference_time: 0.282ms
2022-07-14 07:29:51 - until epoch: 097, best_acc1: 69.774%
2022-07-14 07:29:51 - epoch 098 lr: 0.008794
2022-07-14 07:30:30 - train: epoch 0098, iter [00100, 05004], lr: 0.008779, loss: 1.6388
2022-07-14 07:31:05 - train: epoch 0098, iter [00200, 05004], lr: 0.008764, loss: 1.4351
2022-07-14 07:31:38 - train: epoch 0098, iter [00300, 05004], lr: 0.008749, loss: 1.4991
2022-07-14 07:32:13 - train: epoch 0098, iter [00400, 05004], lr: 0.008735, loss: 1.2199
2022-07-14 07:32:46 - train: epoch 0098, iter [00500, 05004], lr: 0.008720, loss: 1.2884
2022-07-14 07:33:21 - train: epoch 0098, iter [00600, 05004], lr: 0.008705, loss: 1.4585
2022-07-14 07:33:54 - train: epoch 0098, iter [00700, 05004], lr: 0.008690, loss: 1.2877
2022-07-14 07:34:29 - train: epoch 0098, iter [00800, 05004], lr: 0.008676, loss: 1.3592
2022-07-14 07:35:02 - train: epoch 0098, iter [00900, 05004], lr: 0.008661, loss: 1.3189
2022-07-14 07:35:36 - train: epoch 0098, iter [01000, 05004], lr: 0.008646, loss: 1.1320
2022-07-14 07:36:10 - train: epoch 0098, iter [01100, 05004], lr: 0.008631, loss: 1.0549
2022-07-14 07:36:44 - train: epoch 0098, iter [01200, 05004], lr: 0.008617, loss: 1.1886
2022-07-14 07:37:19 - train: epoch 0098, iter [01300, 05004], lr: 0.008602, loss: 1.4847
2022-07-14 07:37:53 - train: epoch 0098, iter [01400, 05004], lr: 0.008587, loss: 1.2549
2022-07-14 07:38:26 - train: epoch 0098, iter [01500, 05004], lr: 0.008573, loss: 1.2061
2022-07-14 07:39:01 - train: epoch 0098, iter [01600, 05004], lr: 0.008558, loss: 1.2634
2022-07-14 07:39:35 - train: epoch 0098, iter [01700, 05004], lr: 0.008543, loss: 1.3941
2022-07-14 07:40:10 - train: epoch 0098, iter [01800, 05004], lr: 0.008529, loss: 1.2226
2022-07-14 07:40:43 - train: epoch 0098, iter [01900, 05004], lr: 0.008514, loss: 1.1982
2022-07-14 07:41:17 - train: epoch 0098, iter [02000, 05004], lr: 0.008500, loss: 1.4384
2022-07-14 07:41:51 - train: epoch 0098, iter [02100, 05004], lr: 0.008485, loss: 1.2165
2022-07-14 07:42:25 - train: epoch 0098, iter [02200, 05004], lr: 0.008470, loss: 1.3687
2022-07-14 07:42:59 - train: epoch 0098, iter [02300, 05004], lr: 0.008456, loss: 1.1932
2022-07-14 07:43:34 - train: epoch 0098, iter [02400, 05004], lr: 0.008441, loss: 1.2738
2022-07-14 07:44:07 - train: epoch 0098, iter [02500, 05004], lr: 0.008427, loss: 1.4853
2022-07-14 07:44:42 - train: epoch 0098, iter [02600, 05004], lr: 0.008412, loss: 1.3320
2022-07-14 07:45:16 - train: epoch 0098, iter [02700, 05004], lr: 0.008398, loss: 1.4252
2022-07-14 07:45:50 - train: epoch 0098, iter [02800, 05004], lr: 0.008383, loss: 1.2975
2022-07-14 07:46:24 - train: epoch 0098, iter [02900, 05004], lr: 0.008369, loss: 1.2722
2022-07-14 07:46:58 - train: epoch 0098, iter [03000, 05004], lr: 0.008354, loss: 1.2726
2022-07-14 07:47:33 - train: epoch 0098, iter [03100, 05004], lr: 0.008340, loss: 1.3283
2022-07-14 07:48:06 - train: epoch 0098, iter [03200, 05004], lr: 0.008325, loss: 1.1558
2022-07-14 07:48:41 - train: epoch 0098, iter [03300, 05004], lr: 0.008311, loss: 1.2465
2022-07-14 07:49:15 - train: epoch 0098, iter [03400, 05004], lr: 0.008296, loss: 1.3533
2022-07-14 07:49:50 - train: epoch 0098, iter [03500, 05004], lr: 0.008282, loss: 1.3480
2022-07-14 07:50:23 - train: epoch 0098, iter [03600, 05004], lr: 0.008268, loss: 1.6703
2022-07-14 07:50:58 - train: epoch 0098, iter [03700, 05004], lr: 0.008253, loss: 1.3887
2022-07-14 07:51:31 - train: epoch 0098, iter [03800, 05004], lr: 0.008239, loss: 1.3348
2022-07-14 07:52:06 - train: epoch 0098, iter [03900, 05004], lr: 0.008224, loss: 1.3465
2022-07-14 07:52:40 - train: epoch 0098, iter [04000, 05004], lr: 0.008210, loss: 1.4532
2022-07-14 07:53:16 - train: epoch 0098, iter [04100, 05004], lr: 0.008196, loss: 1.4704
2022-07-14 07:53:49 - train: epoch 0098, iter [04200, 05004], lr: 0.008181, loss: 1.3206
2022-07-14 07:54:24 - train: epoch 0098, iter [04300, 05004], lr: 0.008167, loss: 1.2238
2022-07-14 07:54:57 - train: epoch 0098, iter [04400, 05004], lr: 0.008153, loss: 1.5124
2022-07-14 07:55:31 - train: epoch 0098, iter [04500, 05004], lr: 0.008138, loss: 1.4788
2022-07-14 07:56:06 - train: epoch 0098, iter [04600, 05004], lr: 0.008124, loss: 1.4489
2022-07-14 07:56:40 - train: epoch 0098, iter [04700, 05004], lr: 0.008110, loss: 1.2447
2022-07-14 07:57:14 - train: epoch 0098, iter [04800, 05004], lr: 0.008096, loss: 1.0998
2022-07-14 07:57:48 - train: epoch 0098, iter [04900, 05004], lr: 0.008081, loss: 1.3848
2022-07-14 07:58:21 - train: epoch 0098, iter [05000, 05004], lr: 0.008067, loss: 1.4068
2022-07-14 07:58:22 - train: epoch 098, train_loss: 1.3375
2022-07-14 07:59:38 - eval: epoch: 098, acc1: 70.308%, acc5: 89.596%, test_loss: 1.2159, per_image_load_time: 2.072ms, per_image_inference_time: 0.297ms
2022-07-14 07:59:38 - until epoch: 098, best_acc1: 70.308%
2022-07-14 07:59:38 - epoch 099 lr: 0.008066
2022-07-14 08:00:17 - train: epoch 0099, iter [00100, 05004], lr: 0.008052, loss: 1.1657
2022-07-14 08:00:51 - train: epoch 0099, iter [00200, 05004], lr: 0.008038, loss: 1.1921
2022-07-14 08:01:25 - train: epoch 0099, iter [00300, 05004], lr: 0.008024, loss: 1.2557
2022-07-14 08:01:59 - train: epoch 0099, iter [00400, 05004], lr: 0.008010, loss: 1.4091
2022-07-14 08:02:33 - train: epoch 0099, iter [00500, 05004], lr: 0.007995, loss: 1.4221
2022-07-14 08:03:06 - train: epoch 0099, iter [00600, 05004], lr: 0.007981, loss: 1.2943
2022-07-14 08:03:41 - train: epoch 0099, iter [00700, 05004], lr: 0.007967, loss: 1.2699
2022-07-14 08:04:14 - train: epoch 0099, iter [00800, 05004], lr: 0.007953, loss: 1.3138
2022-07-14 08:04:48 - train: epoch 0099, iter [00900, 05004], lr: 0.007939, loss: 1.2036
2022-07-14 08:05:23 - train: epoch 0099, iter [01000, 05004], lr: 0.007925, loss: 1.2703
2022-07-14 08:05:57 - train: epoch 0099, iter [01100, 05004], lr: 0.007910, loss: 1.3322
2022-07-14 08:06:31 - train: epoch 0099, iter [01200, 05004], lr: 0.007896, loss: 1.2083
2022-07-14 08:07:06 - train: epoch 0099, iter [01300, 05004], lr: 0.007882, loss: 1.4532
2022-07-14 08:07:40 - train: epoch 0099, iter [01400, 05004], lr: 0.007868, loss: 1.2992
2022-07-14 08:08:14 - train: epoch 0099, iter [01500, 05004], lr: 0.007854, loss: 1.1544
2022-07-14 08:08:47 - train: epoch 0099, iter [01600, 05004], lr: 0.007840, loss: 1.6243
2022-07-14 08:09:22 - train: epoch 0099, iter [01700, 05004], lr: 0.007826, loss: 1.1336
2022-07-14 08:09:55 - train: epoch 0099, iter [01800, 05004], lr: 0.007812, loss: 1.3800
2022-07-14 08:10:30 - train: epoch 0099, iter [01900, 05004], lr: 0.007798, loss: 1.2756
