2022-03-07 10:55:51 - train: epoch 0082, iter [04400, 10009], lr: 0.001000, loss: 1.4143
2022-03-07 10:56:11 - train: epoch 0082, iter [04500, 10009], lr: 0.001000, loss: 0.7817
2022-03-07 10:56:31 - train: epoch 0082, iter [04600, 10009], lr: 0.001000, loss: 1.4199
2022-03-07 10:56:51 - train: epoch 0082, iter [04700, 10009], lr: 0.001000, loss: 1.2636
2022-03-07 10:57:11 - train: epoch 0082, iter [04800, 10009], lr: 0.001000, loss: 1.3656
2022-03-07 10:57:30 - train: epoch 0082, iter [04900, 10009], lr: 0.001000, loss: 1.0410
2022-03-07 10:57:50 - train: epoch 0082, iter [05000, 10009], lr: 0.001000, loss: 1.3612
2022-03-07 10:58:10 - train: epoch 0082, iter [05100, 10009], lr: 0.001000, loss: 1.2566
2022-03-07 10:58:29 - train: epoch 0082, iter [05200, 10009], lr: 0.001000, loss: 1.2594
2022-03-07 10:58:49 - train: epoch 0082, iter [05300, 10009], lr: 0.001000, loss: 1.5079
2022-03-07 10:59:09 - train: epoch 0082, iter [05400, 10009], lr: 0.001000, loss: 1.0261
2022-03-07 10:59:29 - train: epoch 0082, iter [05500, 10009], lr: 0.001000, loss: 1.1584
2022-03-07 10:59:49 - train: epoch 0082, iter [05600, 10009], lr: 0.001000, loss: 1.2321
2022-03-07 11:00:08 - train: epoch 0082, iter [05700, 10009], lr: 0.001000, loss: 1.5305
2022-03-07 11:00:28 - train: epoch 0082, iter [05800, 10009], lr: 0.001000, loss: 1.1881
2022-03-07 11:00:48 - train: epoch 0082, iter [05900, 10009], lr: 0.001000, loss: 1.1408
2022-03-07 11:01:08 - train: epoch 0082, iter [06000, 10009], lr: 0.001000, loss: 1.1556
2022-03-07 11:01:28 - train: epoch 0082, iter [06100, 10009], lr: 0.001000, loss: 0.9932
2022-03-07 11:01:47 - train: epoch 0082, iter [06200, 10009], lr: 0.001000, loss: 1.2812
2022-03-07 11:02:07 - train: epoch 0082, iter [06300, 10009], lr: 0.001000, loss: 1.2688
2022-03-07 11:02:27 - train: epoch 0082, iter [06400, 10009], lr: 0.001000, loss: 1.2017
2022-03-07 11:02:47 - train: epoch 0082, iter [06500, 10009], lr: 0.001000, loss: 1.2058
2022-03-07 11:03:07 - train: epoch 0082, iter [06600, 10009], lr: 0.001000, loss: 1.2942
2022-03-07 11:03:26 - train: epoch 0082, iter [06700, 10009], lr: 0.001000, loss: 1.0009
2022-03-07 11:03:46 - train: epoch 0082, iter [06800, 10009], lr: 0.001000, loss: 1.3782
2022-03-07 11:04:06 - train: epoch 0082, iter [06900, 10009], lr: 0.001000, loss: 1.4268
2022-03-07 11:04:26 - train: epoch 0082, iter [07000, 10009], lr: 0.001000, loss: 1.0999
2022-03-07 11:04:46 - train: epoch 0082, iter [07100, 10009], lr: 0.001000, loss: 1.3230
2022-03-07 11:05:06 - train: epoch 0082, iter [07200, 10009], lr: 0.001000, loss: 1.0760
2022-03-07 11:05:26 - train: epoch 0082, iter [07300, 10009], lr: 0.001000, loss: 1.2340
2022-03-07 11:05:46 - train: epoch 0082, iter [07400, 10009], lr: 0.001000, loss: 1.0282
2022-03-07 11:06:05 - train: epoch 0082, iter [07500, 10009], lr: 0.001000, loss: 1.4924
2022-03-07 11:06:25 - train: epoch 0082, iter [07600, 10009], lr: 0.001000, loss: 1.1785
2022-03-07 11:06:45 - train: epoch 0082, iter [07700, 10009], lr: 0.001000, loss: 1.3476
2022-03-07 11:07:05 - train: epoch 0082, iter [07800, 10009], lr: 0.001000, loss: 1.1515
2022-03-07 11:07:25 - train: epoch 0082, iter [07900, 10009], lr: 0.001000, loss: 1.2368
2022-03-07 11:07:45 - train: epoch 0082, iter [08000, 10009], lr: 0.001000, loss: 1.0465
2022-03-07 11:08:05 - train: epoch 0082, iter [08100, 10009], lr: 0.001000, loss: 1.1424
2022-03-07 11:08:24 - train: epoch 0082, iter [08200, 10009], lr: 0.001000, loss: 1.3411
2022-03-07 11:08:44 - train: epoch 0082, iter [08300, 10009], lr: 0.001000, loss: 1.3897
2022-03-07 11:09:04 - train: epoch 0082, iter [08400, 10009], lr: 0.001000, loss: 1.3150
2022-03-07 11:09:24 - train: epoch 0082, iter [08500, 10009], lr: 0.001000, loss: 1.2595
2022-03-07 11:09:44 - train: epoch 0082, iter [08600, 10009], lr: 0.001000, loss: 1.1774
2022-03-07 11:10:04 - train: epoch 0082, iter [08700, 10009], lr: 0.001000, loss: 1.2284
2022-03-07 11:10:25 - train: epoch 0082, iter [08800, 10009], lr: 0.001000, loss: 1.2177
2022-03-07 11:10:44 - train: epoch 0082, iter [08900, 10009], lr: 0.001000, loss: 1.4356
2022-03-07 11:11:05 - train: epoch 0082, iter [09000, 10009], lr: 0.001000, loss: 0.9640
2022-03-07 11:11:25 - train: epoch 0082, iter [09100, 10009], lr: 0.001000, loss: 1.0298
2022-03-07 11:11:45 - train: epoch 0082, iter [09200, 10009], lr: 0.001000, loss: 1.1075
2022-03-07 11:12:05 - train: epoch 0082, iter [09300, 10009], lr: 0.001000, loss: 1.3006
2022-03-07 11:12:24 - train: epoch 0082, iter [09400, 10009], lr: 0.001000, loss: 1.0695
2022-03-07 11:12:45 - train: epoch 0082, iter [09500, 10009], lr: 0.001000, loss: 1.0213
2022-03-07 11:13:05 - train: epoch 0082, iter [09600, 10009], lr: 0.001000, loss: 1.0502
2022-03-07 11:13:24 - train: epoch 0082, iter [09700, 10009], lr: 0.001000, loss: 0.7891
2022-03-07 11:13:44 - train: epoch 0082, iter [09800, 10009], lr: 0.001000, loss: 1.3425
2022-03-07 11:14:04 - train: epoch 0082, iter [09900, 10009], lr: 0.001000, loss: 1.3413
2022-03-07 11:14:24 - train: epoch 0082, iter [10000, 10009], lr: 0.001000, loss: 1.1009
2022-03-07 11:14:27 - train: epoch 082, train_loss: 1.2504
2022-03-07 11:15:42 - eval: epoch: 082, acc1: 72.524%, acc5: 90.644%, test_loss: 1.1077, per_image_load_time: 1.484ms, per_image_inference_time: 0.908ms
2022-03-07 11:15:43 - until epoch: 082, best_acc1: 72.524%
2022-03-07 11:15:43 - epoch 083 lr: 0.0010000000000000002
2022-03-07 11:16:06 - train: epoch 0083, iter [00100, 10009], lr: 0.001000, loss: 1.2938
2022-03-07 11:16:25 - train: epoch 0083, iter [00200, 10009], lr: 0.001000, loss: 1.4435
2022-03-07 11:16:45 - train: epoch 0083, iter [00300, 10009], lr: 0.001000, loss: 1.3964
2022-03-07 11:17:05 - train: epoch 0083, iter [00400, 10009], lr: 0.001000, loss: 1.1438
2022-03-07 11:17:24 - train: epoch 0083, iter [00500, 10009], lr: 0.001000, loss: 1.1999
2022-03-07 11:17:44 - train: epoch 0083, iter [00600, 10009], lr: 0.001000, loss: 1.2654
2022-03-07 11:18:04 - train: epoch 0083, iter [00700, 10009], lr: 0.001000, loss: 1.0782
2022-03-07 11:18:23 - train: epoch 0083, iter [00800, 10009], lr: 0.001000, loss: 1.4858
2022-03-07 11:18:43 - train: epoch 0083, iter [00900, 10009], lr: 0.001000, loss: 1.1910
2022-03-07 11:19:03 - train: epoch 0083, iter [01000, 10009], lr: 0.001000, loss: 1.1764
2022-03-07 11:19:23 - train: epoch 0083, iter [01100, 10009], lr: 0.001000, loss: 1.2459
2022-03-07 11:19:43 - train: epoch 0083, iter [01200, 10009], lr: 0.001000, loss: 1.2406
2022-03-07 11:20:03 - train: epoch 0083, iter [01300, 10009], lr: 0.001000, loss: 1.4967
2022-03-07 11:20:22 - train: epoch 0083, iter [01400, 10009], lr: 0.001000, loss: 1.1672
2022-03-07 11:20:42 - train: epoch 0083, iter [01500, 10009], lr: 0.001000, loss: 1.4926
2022-03-07 11:21:02 - train: epoch 0083, iter [01600, 10009], lr: 0.001000, loss: 1.2967
2022-03-07 11:21:22 - train: epoch 0083, iter [01700, 10009], lr: 0.001000, loss: 1.3162
2022-03-07 11:21:42 - train: epoch 0083, iter [01800, 10009], lr: 0.001000, loss: 1.1939
2022-03-07 11:22:02 - train: epoch 0083, iter [01900, 10009], lr: 0.001000, loss: 1.5702
2022-03-07 11:22:21 - train: epoch 0083, iter [02000, 10009], lr: 0.001000, loss: 1.3933
2022-03-07 11:22:41 - train: epoch 0083, iter [02100, 10009], lr: 0.001000, loss: 1.0254
2022-03-07 11:23:01 - train: epoch 0083, iter [02200, 10009], lr: 0.001000, loss: 1.2735
2022-03-07 11:23:21 - train: epoch 0083, iter [02300, 10009], lr: 0.001000, loss: 1.5338
2022-03-07 11:23:41 - train: epoch 0083, iter [02400, 10009], lr: 0.001000, loss: 1.3538
2022-03-07 11:24:01 - train: epoch 0083, iter [02500, 10009], lr: 0.001000, loss: 1.4288
2022-03-07 11:24:21 - train: epoch 0083, iter [02600, 10009], lr: 0.001000, loss: 1.4732
2022-03-07 11:24:41 - train: epoch 0083, iter [02700, 10009], lr: 0.001000, loss: 1.6254
2022-03-07 11:25:00 - train: epoch 0083, iter [02800, 10009], lr: 0.001000, loss: 1.4890
2022-03-07 11:25:20 - train: epoch 0083, iter [02900, 10009], lr: 0.001000, loss: 1.1645
2022-03-07 11:25:40 - train: epoch 0083, iter [03000, 10009], lr: 0.001000, loss: 1.3424
2022-03-07 11:26:00 - train: epoch 0083, iter [03100, 10009], lr: 0.001000, loss: 1.1621
2022-03-07 11:26:20 - train: epoch 0083, iter [03200, 10009], lr: 0.001000, loss: 1.3178
2022-03-07 11:26:40 - train: epoch 0083, iter [03300, 10009], lr: 0.001000, loss: 1.0994
2022-03-07 11:27:00 - train: epoch 0083, iter [03400, 10009], lr: 0.001000, loss: 1.1008
2022-03-07 11:27:19 - train: epoch 0083, iter [03500, 10009], lr: 0.001000, loss: 1.0903
2022-03-07 11:27:39 - train: epoch 0083, iter [03600, 10009], lr: 0.001000, loss: 1.3445
2022-03-07 11:27:59 - train: epoch 0083, iter [03700, 10009], lr: 0.001000, loss: 1.2482
2022-03-07 11:28:19 - train: epoch 0083, iter [03800, 10009], lr: 0.001000, loss: 1.1362
2022-03-07 11:28:39 - train: epoch 0083, iter [03900, 10009], lr: 0.001000, loss: 1.2286
2022-03-07 11:28:59 - train: epoch 0083, iter [04000, 10009], lr: 0.001000, loss: 0.9863
2022-03-07 11:29:19 - train: epoch 0083, iter [04100, 10009], lr: 0.001000, loss: 1.2748
2022-03-07 11:29:39 - train: epoch 0083, iter [04200, 10009], lr: 0.001000, loss: 1.2664
2022-03-07 11:29:59 - train: epoch 0083, iter [04300, 10009], lr: 0.001000, loss: 1.0501
2022-03-07 11:30:19 - train: epoch 0083, iter [04400, 10009], lr: 0.001000, loss: 1.1506
2022-03-07 11:30:39 - train: epoch 0083, iter [04500, 10009], lr: 0.001000, loss: 1.1626
2022-03-07 11:30:59 - train: epoch 0083, iter [04600, 10009], lr: 0.001000, loss: 1.3882
2022-03-07 11:31:19 - train: epoch 0083, iter [04700, 10009], lr: 0.001000, loss: 1.4348
2022-03-07 11:31:39 - train: epoch 0083, iter [04800, 10009], lr: 0.001000, loss: 1.2963
2022-03-07 11:31:59 - train: epoch 0083, iter [04900, 10009], lr: 0.001000, loss: 1.1065
2022-03-07 11:32:18 - train: epoch 0083, iter [05000, 10009], lr: 0.001000, loss: 0.9602
2022-03-07 11:32:38 - train: epoch 0083, iter [05100, 10009], lr: 0.001000, loss: 1.3210
2022-03-07 11:32:58 - train: epoch 0083, iter [05200, 10009], lr: 0.001000, loss: 1.2294
2022-03-07 11:33:18 - train: epoch 0083, iter [05300, 10009], lr: 0.001000, loss: 1.3369
2022-03-07 11:33:38 - train: epoch 0083, iter [05400, 10009], lr: 0.001000, loss: 1.3156
2022-03-07 11:33:58 - train: epoch 0083, iter [05500, 10009], lr: 0.001000, loss: 1.2411
2022-03-07 11:34:18 - train: epoch 0083, iter [05600, 10009], lr: 0.001000, loss: 1.2080
2022-03-07 11:34:38 - train: epoch 0083, iter [05700, 10009], lr: 0.001000, loss: 1.1963
2022-03-07 11:34:58 - train: epoch 0083, iter [05800, 10009], lr: 0.001000, loss: 1.1557
2022-03-07 11:35:18 - train: epoch 0083, iter [05900, 10009], lr: 0.001000, loss: 1.0216
2022-03-07 11:35:38 - train: epoch 0083, iter [06000, 10009], lr: 0.001000, loss: 1.4045
2022-03-07 11:35:58 - train: epoch 0083, iter [06100, 10009], lr: 0.001000, loss: 1.0655
2022-03-07 11:36:18 - train: epoch 0083, iter [06200, 10009], lr: 0.001000, loss: 1.3377
2022-03-07 11:36:38 - train: epoch 0083, iter [06300, 10009], lr: 0.001000, loss: 1.0892
2022-03-07 11:36:58 - train: epoch 0083, iter [06400, 10009], lr: 0.001000, loss: 1.2269
2022-03-07 11:37:18 - train: epoch 0083, iter [06500, 10009], lr: 0.001000, loss: 1.0340
2022-03-07 11:37:38 - train: epoch 0083, iter [06600, 10009], lr: 0.001000, loss: 1.3537
2022-03-07 11:37:58 - train: epoch 0083, iter [06700, 10009], lr: 0.001000, loss: 1.0643
2022-03-07 11:38:17 - train: epoch 0083, iter [06800, 10009], lr: 0.001000, loss: 1.6055
2022-03-07 11:38:37 - train: epoch 0083, iter [06900, 10009], lr: 0.001000, loss: 1.3178
2022-03-07 11:38:57 - train: epoch 0083, iter [07000, 10009], lr: 0.001000, loss: 1.2516
2022-03-07 11:39:17 - train: epoch 0083, iter [07100, 10009], lr: 0.001000, loss: 1.1711
2022-03-07 11:39:37 - train: epoch 0083, iter [07200, 10009], lr: 0.001000, loss: 1.3242
2022-03-07 11:39:57 - train: epoch 0083, iter [07300, 10009], lr: 0.001000, loss: 1.4527
2022-03-07 11:40:17 - train: epoch 0083, iter [07400, 10009], lr: 0.001000, loss: 0.9854
2022-03-07 11:40:37 - train: epoch 0083, iter [07500, 10009], lr: 0.001000, loss: 0.9184
2022-03-07 11:40:57 - train: epoch 0083, iter [07600, 10009], lr: 0.001000, loss: 1.3080
2022-03-07 11:41:17 - train: epoch 0083, iter [07700, 10009], lr: 0.001000, loss: 1.1600
2022-03-07 11:41:37 - train: epoch 0083, iter [07800, 10009], lr: 0.001000, loss: 1.5186
2022-03-07 11:41:57 - train: epoch 0083, iter [07900, 10009], lr: 0.001000, loss: 0.9796
2022-03-07 11:42:17 - train: epoch 0083, iter [08000, 10009], lr: 0.001000, loss: 1.3764
2022-03-07 11:42:37 - train: epoch 0083, iter [08100, 10009], lr: 0.001000, loss: 1.1710
2022-03-07 11:42:57 - train: epoch 0083, iter [08200, 10009], lr: 0.001000, loss: 1.2269
2022-03-07 11:43:16 - train: epoch 0083, iter [08300, 10009], lr: 0.001000, loss: 1.3146
2022-03-07 11:43:36 - train: epoch 0083, iter [08400, 10009], lr: 0.001000, loss: 1.4222
2022-03-07 11:43:56 - train: epoch 0083, iter [08500, 10009], lr: 0.001000, loss: 1.1555
2022-03-07 11:44:16 - train: epoch 0083, iter [08600, 10009], lr: 0.001000, loss: 1.1428
2022-03-07 11:44:36 - train: epoch 0083, iter [08700, 10009], lr: 0.001000, loss: 1.1346
2022-03-07 11:44:56 - train: epoch 0083, iter [08800, 10009], lr: 0.001000, loss: 1.2394
2022-03-07 11:45:16 - train: epoch 0083, iter [08900, 10009], lr: 0.001000, loss: 1.0992
2022-03-07 11:45:35 - train: epoch 0083, iter [09000, 10009], lr: 0.001000, loss: 1.0874
2022-03-07 11:45:55 - train: epoch 0083, iter [09100, 10009], lr: 0.001000, loss: 1.2783
2022-03-07 11:46:15 - train: epoch 0083, iter [09200, 10009], lr: 0.001000, loss: 1.1346
2022-03-07 11:46:35 - train: epoch 0083, iter [09300, 10009], lr: 0.001000, loss: 1.4105
2022-03-07 11:46:54 - train: epoch 0083, iter [09400, 10009], lr: 0.001000, loss: 1.4104
2022-03-07 11:47:14 - train: epoch 0083, iter [09500, 10009], lr: 0.001000, loss: 1.2872
2022-03-07 11:47:34 - train: epoch 0083, iter [09600, 10009], lr: 0.001000, loss: 1.3353
2022-03-07 11:47:54 - train: epoch 0083, iter [09700, 10009], lr: 0.001000, loss: 1.4946
2022-03-07 11:48:13 - train: epoch 0083, iter [09800, 10009], lr: 0.001000, loss: 1.0674
2022-03-07 11:48:33 - train: epoch 0083, iter [09900, 10009], lr: 0.001000, loss: 1.2197
2022-03-07 11:48:53 - train: epoch 0083, iter [10000, 10009], lr: 0.001000, loss: 0.8598
2022-03-07 11:48:56 - train: epoch 083, train_loss: 1.2461
2022-03-07 11:50:11 - eval: epoch: 083, acc1: 72.470%, acc5: 90.666%, test_loss: 1.1076, per_image_load_time: 1.968ms, per_image_inference_time: 0.850ms
2022-03-07 11:50:12 - until epoch: 083, best_acc1: 72.524%
2022-03-07 11:50:12 - epoch 084 lr: 0.0010000000000000002
2022-03-07 11:50:35 - train: epoch 0084, iter [00100, 10009], lr: 0.001000, loss: 1.1958
2022-03-07 11:50:54 - train: epoch 0084, iter [00200, 10009], lr: 0.001000, loss: 1.4383
2022-03-07 11:51:14 - train: epoch 0084, iter [00300, 10009], lr: 0.001000, loss: 1.2142
2022-03-07 11:51:34 - train: epoch 0084, iter [00400, 10009], lr: 0.001000, loss: 1.1278
2022-03-07 11:51:53 - train: epoch 0084, iter [00500, 10009], lr: 0.001000, loss: 1.1533
2022-03-07 11:52:13 - train: epoch 0084, iter [00600, 10009], lr: 0.001000, loss: 1.2033
2022-03-07 11:52:33 - train: epoch 0084, iter [00700, 10009], lr: 0.001000, loss: 1.0377
2022-03-07 11:52:53 - train: epoch 0084, iter [00800, 10009], lr: 0.001000, loss: 1.2346
2022-03-07 11:53:12 - train: epoch 0084, iter [00900, 10009], lr: 0.001000, loss: 1.2896
2022-03-07 11:53:32 - train: epoch 0084, iter [01000, 10009], lr: 0.001000, loss: 1.3732
2022-03-07 11:53:52 - train: epoch 0084, iter [01100, 10009], lr: 0.001000, loss: 1.3911
2022-03-07 11:54:11 - train: epoch 0084, iter [01200, 10009], lr: 0.001000, loss: 1.5595
2022-03-07 11:54:31 - train: epoch 0084, iter [01300, 10009], lr: 0.001000, loss: 1.1731
2022-03-07 11:54:51 - train: epoch 0084, iter [01400, 10009], lr: 0.001000, loss: 1.5130
2022-03-07 11:55:10 - train: epoch 0084, iter [01500, 10009], lr: 0.001000, loss: 1.3082
2022-03-07 11:55:30 - train: epoch 0084, iter [01600, 10009], lr: 0.001000, loss: 1.2425
2022-03-07 11:55:49 - train: epoch 0084, iter [01700, 10009], lr: 0.001000, loss: 1.2184
2022-03-07 11:56:09 - train: epoch 0084, iter [01800, 10009], lr: 0.001000, loss: 1.2646
2022-03-07 11:56:29 - train: epoch 0084, iter [01900, 10009], lr: 0.001000, loss: 1.0550
2022-03-07 11:56:48 - train: epoch 0084, iter [02000, 10009], lr: 0.001000, loss: 1.6225
2022-03-07 11:57:08 - train: epoch 0084, iter [02100, 10009], lr: 0.001000, loss: 1.2581
2022-03-07 11:57:28 - train: epoch 0084, iter [02200, 10009], lr: 0.001000, loss: 1.2044
2022-03-07 11:57:47 - train: epoch 0084, iter [02300, 10009], lr: 0.001000, loss: 1.0403
2022-03-07 11:58:07 - train: epoch 0084, iter [02400, 10009], lr: 0.001000, loss: 1.2974
2022-03-07 11:58:27 - train: epoch 0084, iter [02500, 10009], lr: 0.001000, loss: 0.8983
2022-03-07 11:58:46 - train: epoch 0084, iter [02600, 10009], lr: 0.001000, loss: 1.4065
2022-03-07 11:59:06 - train: epoch 0084, iter [02700, 10009], lr: 0.001000, loss: 1.0739
2022-03-07 11:59:26 - train: epoch 0084, iter [02800, 10009], lr: 0.001000, loss: 1.0491
2022-03-07 11:59:45 - train: epoch 0084, iter [02900, 10009], lr: 0.001000, loss: 1.3936
2022-03-07 12:00:05 - train: epoch 0084, iter [03000, 10009], lr: 0.001000, loss: 1.4232
2022-03-07 12:00:25 - train: epoch 0084, iter [03100, 10009], lr: 0.001000, loss: 1.5580
2022-03-07 12:00:44 - train: epoch 0084, iter [03200, 10009], lr: 0.001000, loss: 1.3468
2022-03-07 12:01:04 - train: epoch 0084, iter [03300, 10009], lr: 0.001000, loss: 1.3848
2022-03-07 12:01:24 - train: epoch 0084, iter [03400, 10009], lr: 0.001000, loss: 1.1517
2022-03-07 12:01:43 - train: epoch 0084, iter [03500, 10009], lr: 0.001000, loss: 0.9405
2022-03-07 12:02:03 - train: epoch 0084, iter [03600, 10009], lr: 0.001000, loss: 1.5919
2022-03-07 12:02:23 - train: epoch 0084, iter [03700, 10009], lr: 0.001000, loss: 1.2351
2022-03-07 12:02:42 - train: epoch 0084, iter [03800, 10009], lr: 0.001000, loss: 1.3574
2022-03-07 12:03:02 - train: epoch 0084, iter [03900, 10009], lr: 0.001000, loss: 1.2372
2022-03-07 12:03:22 - train: epoch 0084, iter [04000, 10009], lr: 0.001000, loss: 1.0607
2022-03-07 12:03:42 - train: epoch 0084, iter [04100, 10009], lr: 0.001000, loss: 1.4384
2022-03-07 12:04:01 - train: epoch 0084, iter [04200, 10009], lr: 0.001000, loss: 1.1968
2022-03-07 12:04:21 - train: epoch 0084, iter [04300, 10009], lr: 0.001000, loss: 1.2089
2022-03-07 12:04:41 - train: epoch 0084, iter [04400, 10009], lr: 0.001000, loss: 1.3022
2022-03-07 12:05:00 - train: epoch 0084, iter [04500, 10009], lr: 0.001000, loss: 1.1964
2022-03-07 12:05:20 - train: epoch 0084, iter [04600, 10009], lr: 0.001000, loss: 0.9823
2022-03-07 12:05:40 - train: epoch 0084, iter [04700, 10009], lr: 0.001000, loss: 1.4081
2022-03-07 12:05:59 - train: epoch 0084, iter [04800, 10009], lr: 0.001000, loss: 1.1599
2022-03-07 12:06:19 - train: epoch 0084, iter [04900, 10009], lr: 0.001000, loss: 0.9260
2022-03-07 12:06:39 - train: epoch 0084, iter [05000, 10009], lr: 0.001000, loss: 1.1622
2022-03-07 12:06:59 - train: epoch 0084, iter [05100, 10009], lr: 0.001000, loss: 1.3821
2022-03-07 12:07:19 - train: epoch 0084, iter [05200, 10009], lr: 0.001000, loss: 1.0592
2022-03-07 12:07:38 - train: epoch 0084, iter [05300, 10009], lr: 0.001000, loss: 1.4367
2022-03-07 12:07:58 - train: epoch 0084, iter [05400, 10009], lr: 0.001000, loss: 1.2991
2022-03-07 12:08:18 - train: epoch 0084, iter [05500, 10009], lr: 0.001000, loss: 1.0059
2022-03-07 12:08:38 - train: epoch 0084, iter [05600, 10009], lr: 0.001000, loss: 0.9775
2022-03-07 12:08:57 - train: epoch 0084, iter [05700, 10009], lr: 0.001000, loss: 1.3887
2022-03-07 12:09:17 - train: epoch 0084, iter [05800, 10009], lr: 0.001000, loss: 1.0386
2022-03-07 12:09:37 - train: epoch 0084, iter [05900, 10009], lr: 0.001000, loss: 1.4410
2022-03-07 12:09:56 - train: epoch 0084, iter [06000, 10009], lr: 0.001000, loss: 1.0215
2022-03-07 12:10:16 - train: epoch 0084, iter [06100, 10009], lr: 0.001000, loss: 1.0640
2022-03-07 12:10:36 - train: epoch 0084, iter [06200, 10009], lr: 0.001000, loss: 1.4115
2022-03-07 12:10:55 - train: epoch 0084, iter [06300, 10009], lr: 0.001000, loss: 1.1311
2022-03-07 12:11:15 - train: epoch 0084, iter [06400, 10009], lr: 0.001000, loss: 1.0941
2022-03-07 12:11:35 - train: epoch 0084, iter [06500, 10009], lr: 0.001000, loss: 1.3583
2022-03-07 12:11:54 - train: epoch 0084, iter [06600, 10009], lr: 0.001000, loss: 1.1517
2022-03-07 12:12:14 - train: epoch 0084, iter [06700, 10009], lr: 0.001000, loss: 1.5043
2022-03-07 12:12:34 - train: epoch 0084, iter [06800, 10009], lr: 0.001000, loss: 1.1923
2022-03-07 12:12:53 - train: epoch 0084, iter [06900, 10009], lr: 0.001000, loss: 1.4316
2022-03-07 12:13:13 - train: epoch 0084, iter [07000, 10009], lr: 0.001000, loss: 1.1109
2022-03-07 12:13:33 - train: epoch 0084, iter [07100, 10009], lr: 0.001000, loss: 1.2958
2022-03-07 12:13:53 - train: epoch 0084, iter [07200, 10009], lr: 0.001000, loss: 1.0164
2022-03-07 12:14:12 - train: epoch 0084, iter [07300, 10009], lr: 0.001000, loss: 1.5394
2022-03-07 12:14:32 - train: epoch 0084, iter [07400, 10009], lr: 0.001000, loss: 1.6188
2022-03-07 12:14:52 - train: epoch 0084, iter [07500, 10009], lr: 0.001000, loss: 0.8042
2022-03-07 12:15:12 - train: epoch 0084, iter [07600, 10009], lr: 0.001000, loss: 1.4027
2022-03-07 12:15:32 - train: epoch 0084, iter [07700, 10009], lr: 0.001000, loss: 1.1851
2022-03-07 12:15:51 - train: epoch 0084, iter [07800, 10009], lr: 0.001000, loss: 1.1116
2022-03-07 12:16:11 - train: epoch 0084, iter [07900, 10009], lr: 0.001000, loss: 1.0545
2022-03-07 12:16:31 - train: epoch 0084, iter [08000, 10009], lr: 0.001000, loss: 1.0655
2022-03-07 12:16:51 - train: epoch 0084, iter [08100, 10009], lr: 0.001000, loss: 1.3195
2022-03-07 12:17:10 - train: epoch 0084, iter [08200, 10009], lr: 0.001000, loss: 1.1200
2022-03-07 12:17:30 - train: epoch 0084, iter [08300, 10009], lr: 0.001000, loss: 1.2527
2022-03-07 12:17:50 - train: epoch 0084, iter [08400, 10009], lr: 0.001000, loss: 1.3641
2022-03-07 12:18:10 - train: epoch 0084, iter [08500, 10009], lr: 0.001000, loss: 1.2103
2022-03-07 12:18:30 - train: epoch 0084, iter [08600, 10009], lr: 0.001000, loss: 1.3510
2022-03-07 12:18:50 - train: epoch 0084, iter [08700, 10009], lr: 0.001000, loss: 1.4137
2022-03-07 12:19:10 - train: epoch 0084, iter [08800, 10009], lr: 0.001000, loss: 1.5471
2022-03-07 12:19:30 - train: epoch 0084, iter [08900, 10009], lr: 0.001000, loss: 1.2192
2022-03-07 12:19:50 - train: epoch 0084, iter [09000, 10009], lr: 0.001000, loss: 1.1053
2022-03-07 12:20:09 - train: epoch 0084, iter [09100, 10009], lr: 0.001000, loss: 1.3102
2022-03-07 12:20:29 - train: epoch 0084, iter [09200, 10009], lr: 0.001000, loss: 1.1948
2022-03-07 12:20:49 - train: epoch 0084, iter [09300, 10009], lr: 0.001000, loss: 1.2717
2022-03-07 12:21:09 - train: epoch 0084, iter [09400, 10009], lr: 0.001000, loss: 1.2332
2022-03-07 12:21:29 - train: epoch 0084, iter [09500, 10009], lr: 0.001000, loss: 1.3298
2022-03-07 12:21:49 - train: epoch 0084, iter [09600, 10009], lr: 0.001000, loss: 0.9486
2022-03-07 12:22:08 - train: epoch 0084, iter [09700, 10009], lr: 0.001000, loss: 1.1199
2022-03-07 12:22:28 - train: epoch 0084, iter [09800, 10009], lr: 0.001000, loss: 1.0485
2022-03-07 12:22:48 - train: epoch 0084, iter [09900, 10009], lr: 0.001000, loss: 1.0920
2022-03-07 12:23:08 - train: epoch 0084, iter [10000, 10009], lr: 0.001000, loss: 1.2158
2022-03-07 12:23:11 - train: epoch 084, train_loss: 1.2467
2022-03-07 12:24:26 - eval: epoch: 084, acc1: 72.580%, acc5: 90.704%, test_loss: 1.1037, per_image_load_time: 1.946ms, per_image_inference_time: 0.788ms
2022-03-07 12:24:27 - until epoch: 084, best_acc1: 72.580%
2022-03-07 12:24:27 - epoch 085 lr: 0.0010000000000000002
2022-03-07 12:24:50 - train: epoch 0085, iter [00100, 10009], lr: 0.001000, loss: 1.2512
2022-03-07 12:25:10 - train: epoch 0085, iter [00200, 10009], lr: 0.001000, loss: 1.1726
2022-03-07 12:25:29 - train: epoch 0085, iter [00300, 10009], lr: 0.001000, loss: 1.5244
2022-03-07 12:25:49 - train: epoch 0085, iter [00400, 10009], lr: 0.001000, loss: 1.4469
2022-03-07 12:26:09 - train: epoch 0085, iter [00500, 10009], lr: 0.001000, loss: 1.4308
2022-03-07 12:26:28 - train: epoch 0085, iter [00600, 10009], lr: 0.001000, loss: 1.5152
2022-03-07 12:26:48 - train: epoch 0085, iter [00700, 10009], lr: 0.001000, loss: 1.0363
2022-03-07 12:27:08 - train: epoch 0085, iter [00800, 10009], lr: 0.001000, loss: 1.2262
2022-03-07 12:27:27 - train: epoch 0085, iter [00900, 10009], lr: 0.001000, loss: 1.4016
2022-03-07 12:27:47 - train: epoch 0085, iter [01000, 10009], lr: 0.001000, loss: 1.3070
2022-03-07 12:28:07 - train: epoch 0085, iter [01100, 10009], lr: 0.001000, loss: 1.2511
2022-03-07 12:28:26 - train: epoch 0085, iter [01200, 10009], lr: 0.001000, loss: 0.9084
2022-03-07 12:28:46 - train: epoch 0085, iter [01300, 10009], lr: 0.001000, loss: 1.0000
2022-03-07 12:29:06 - train: epoch 0085, iter [01400, 10009], lr: 0.001000, loss: 1.2037
2022-03-07 12:29:26 - train: epoch 0085, iter [01500, 10009], lr: 0.001000, loss: 1.1926
2022-03-07 12:29:45 - train: epoch 0085, iter [01600, 10009], lr: 0.001000, loss: 1.0264
2022-03-07 12:30:05 - train: epoch 0085, iter [01700, 10009], lr: 0.001000, loss: 1.2216
2022-03-07 12:30:25 - train: epoch 0085, iter [01800, 10009], lr: 0.001000, loss: 1.1804
2022-03-07 12:30:45 - train: epoch 0085, iter [01900, 10009], lr: 0.001000, loss: 1.4765
2022-03-07 12:31:04 - train: epoch 0085, iter [02000, 10009], lr: 0.001000, loss: 1.3807
2022-03-07 12:31:24 - train: epoch 0085, iter [02100, 10009], lr: 0.001000, loss: 1.0851
2022-03-07 12:31:44 - train: epoch 0085, iter [02200, 10009], lr: 0.001000, loss: 1.3136
2022-03-07 12:32:03 - train: epoch 0085, iter [02300, 10009], lr: 0.001000, loss: 1.0525
2022-03-07 12:32:23 - train: epoch 0085, iter [02400, 10009], lr: 0.001000, loss: 1.3179
2022-03-07 12:32:43 - train: epoch 0085, iter [02500, 10009], lr: 0.001000, loss: 1.2583
2022-03-07 12:33:02 - train: epoch 0085, iter [02600, 10009], lr: 0.001000, loss: 1.1542
2022-03-07 12:33:22 - train: epoch 0085, iter [02700, 10009], lr: 0.001000, loss: 1.6085
2022-03-07 12:33:42 - train: epoch 0085, iter [02800, 10009], lr: 0.001000, loss: 1.1534
2022-03-07 12:34:02 - train: epoch 0085, iter [02900, 10009], lr: 0.001000, loss: 1.5073
2022-03-07 12:34:22 - train: epoch 0085, iter [03000, 10009], lr: 0.001000, loss: 1.1185
2022-03-07 12:34:42 - train: epoch 0085, iter [03100, 10009], lr: 0.001000, loss: 1.4839
2022-03-07 12:35:02 - train: epoch 0085, iter [03200, 10009], lr: 0.001000, loss: 1.3578
2022-03-07 12:35:21 - train: epoch 0085, iter [03300, 10009], lr: 0.001000, loss: 1.0820
2022-03-07 12:35:41 - train: epoch 0085, iter [03400, 10009], lr: 0.001000, loss: 1.6407
2022-03-07 12:36:01 - train: epoch 0085, iter [03500, 10009], lr: 0.001000, loss: 1.3831
2022-03-07 12:36:20 - train: epoch 0085, iter [03600, 10009], lr: 0.001000, loss: 1.0767
2022-03-07 12:36:40 - train: epoch 0085, iter [03700, 10009], lr: 0.001000, loss: 1.6322
2022-03-07 12:37:00 - train: epoch 0085, iter [03800, 10009], lr: 0.001000, loss: 1.2150
2022-03-07 12:37:20 - train: epoch 0085, iter [03900, 10009], lr: 0.001000, loss: 1.0939
2022-03-07 12:37:39 - train: epoch 0085, iter [04000, 10009], lr: 0.001000, loss: 1.2214
2022-03-07 12:37:59 - train: epoch 0085, iter [04100, 10009], lr: 0.001000, loss: 1.1317
2022-03-07 12:38:19 - train: epoch 0085, iter [04200, 10009], lr: 0.001000, loss: 1.1428
2022-03-07 12:38:39 - train: epoch 0085, iter [04300, 10009], lr: 0.001000, loss: 1.1579
2022-03-07 12:38:58 - train: epoch 0085, iter [04400, 10009], lr: 0.001000, loss: 1.2579
2022-03-07 12:39:18 - train: epoch 0085, iter [04500, 10009], lr: 0.001000, loss: 1.2847
2022-03-07 12:39:38 - train: epoch 0085, iter [04600, 10009], lr: 0.001000, loss: 1.2622
2022-03-07 12:39:58 - train: epoch 0085, iter [04700, 10009], lr: 0.001000, loss: 1.1715
2022-03-07 12:40:18 - train: epoch 0085, iter [04800, 10009], lr: 0.001000, loss: 1.3192
2022-03-07 12:40:38 - train: epoch 0085, iter [04900, 10009], lr: 0.001000, loss: 1.3106
2022-03-07 12:40:58 - train: epoch 0085, iter [05000, 10009], lr: 0.001000, loss: 1.3134
2022-03-07 12:41:18 - train: epoch 0085, iter [05100, 10009], lr: 0.001000, loss: 1.1176
2022-03-07 12:41:37 - train: epoch 0085, iter [05200, 10009], lr: 0.001000, loss: 1.5227
2022-03-07 12:41:57 - train: epoch 0085, iter [05300, 10009], lr: 0.001000, loss: 1.1935
2022-03-07 12:42:17 - train: epoch 0085, iter [05400, 10009], lr: 0.001000, loss: 1.2140
2022-03-07 12:42:37 - train: epoch 0085, iter [05500, 10009], lr: 0.001000, loss: 1.1693
2022-03-07 12:42:56 - train: epoch 0085, iter [05600, 10009], lr: 0.001000, loss: 1.5205
2022-03-07 12:43:16 - train: epoch 0085, iter [05700, 10009], lr: 0.001000, loss: 1.2756
2022-03-07 12:43:36 - train: epoch 0085, iter [05800, 10009], lr: 0.001000, loss: 1.3027
2022-03-07 12:43:56 - train: epoch 0085, iter [05900, 10009], lr: 0.001000, loss: 1.3246
2022-03-07 12:44:15 - train: epoch 0085, iter [06000, 10009], lr: 0.001000, loss: 1.1438
2022-03-07 12:44:35 - train: epoch 0085, iter [06100, 10009], lr: 0.001000, loss: 1.0321
2022-03-07 12:44:55 - train: epoch 0085, iter [06200, 10009], lr: 0.001000, loss: 1.2248
2022-03-07 12:45:15 - train: epoch 0085, iter [06300, 10009], lr: 0.001000, loss: 1.0485
2022-03-07 12:45:35 - train: epoch 0085, iter [06400, 10009], lr: 0.001000, loss: 1.4449
2022-03-07 12:45:54 - train: epoch 0085, iter [06500, 10009], lr: 0.001000, loss: 1.0020
2022-03-07 12:46:14 - train: epoch 0085, iter [06600, 10009], lr: 0.001000, loss: 1.1646
2022-03-07 12:46:34 - train: epoch 0085, iter [06700, 10009], lr: 0.001000, loss: 1.3283
2022-03-07 12:46:54 - train: epoch 0085, iter [06800, 10009], lr: 0.001000, loss: 1.3780
2022-03-07 12:47:14 - train: epoch 0085, iter [06900, 10009], lr: 0.001000, loss: 1.1332
2022-03-07 12:47:34 - train: epoch 0085, iter [07000, 10009], lr: 0.001000, loss: 1.1074
2022-03-07 12:47:54 - train: epoch 0085, iter [07100, 10009], lr: 0.001000, loss: 1.4011
2022-03-07 12:48:13 - train: epoch 0085, iter [07200, 10009], lr: 0.001000, loss: 1.1812
2022-03-07 12:48:33 - train: epoch 0085, iter [07300, 10009], lr: 0.001000, loss: 1.2921
2022-03-07 12:48:53 - train: epoch 0085, iter [07400, 10009], lr: 0.001000, loss: 1.0506
2022-03-07 12:49:12 - train: epoch 0085, iter [07500, 10009], lr: 0.001000, loss: 1.3005
2022-03-07 12:49:32 - train: epoch 0085, iter [07600, 10009], lr: 0.001000, loss: 1.2263
2022-03-07 12:49:52 - train: epoch 0085, iter [07700, 10009], lr: 0.001000, loss: 1.1492
2022-03-07 12:50:12 - train: epoch 0085, iter [07800, 10009], lr: 0.001000, loss: 1.3037
2022-03-07 12:50:32 - train: epoch 0085, iter [07900, 10009], lr: 0.001000, loss: 1.5019
2022-03-07 12:50:51 - train: epoch 0085, iter [08000, 10009], lr: 0.001000, loss: 1.2655
2022-03-07 12:51:11 - train: epoch 0085, iter [08100, 10009], lr: 0.001000, loss: 1.0870
2022-03-07 12:51:31 - train: epoch 0085, iter [08200, 10009], lr: 0.001000, loss: 1.2622
2022-03-07 12:51:51 - train: epoch 0085, iter [08300, 10009], lr: 0.001000, loss: 1.2277
2022-03-07 12:52:11 - train: epoch 0085, iter [08400, 10009], lr: 0.001000, loss: 1.4838
2022-03-07 12:52:30 - train: epoch 0085, iter [08500, 10009], lr: 0.001000, loss: 1.1647
2022-03-07 12:52:50 - train: epoch 0085, iter [08600, 10009], lr: 0.001000, loss: 1.1375
2022-03-07 12:53:10 - train: epoch 0085, iter [08700, 10009], lr: 0.001000, loss: 1.2397
2022-03-07 12:53:30 - train: epoch 0085, iter [08800, 10009], lr: 0.001000, loss: 1.2056
2022-03-07 12:53:50 - train: epoch 0085, iter [08900, 10009], lr: 0.001000, loss: 1.4455
2022-03-07 12:54:10 - train: epoch 0085, iter [09000, 10009], lr: 0.001000, loss: 1.0362
2022-03-07 12:54:30 - train: epoch 0085, iter [09100, 10009], lr: 0.001000, loss: 1.1621
2022-03-07 12:54:50 - train: epoch 0085, iter [09200, 10009], lr: 0.001000, loss: 1.2918
2022-03-07 12:55:10 - train: epoch 0085, iter [09300, 10009], lr: 0.001000, loss: 1.3883
2022-03-07 12:55:30 - train: epoch 0085, iter [09400, 10009], lr: 0.001000, loss: 1.5572
2022-03-07 12:55:50 - train: epoch 0085, iter [09500, 10009], lr: 0.001000, loss: 1.1924
2022-03-07 12:56:10 - train: epoch 0085, iter [09600, 10009], lr: 0.001000, loss: 1.3274
2022-03-07 12:56:30 - train: epoch 0085, iter [09700, 10009], lr: 0.001000, loss: 1.1842
2022-03-07 12:56:50 - train: epoch 0085, iter [09800, 10009], lr: 0.001000, loss: 0.9577
2022-03-07 12:57:10 - train: epoch 0085, iter [09900, 10009], lr: 0.001000, loss: 1.4186
2022-03-07 12:57:30 - train: epoch 0085, iter [10000, 10009], lr: 0.001000, loss: 0.9561
2022-03-07 12:57:33 - train: epoch 085, train_loss: 1.2439
2022-03-07 12:58:48 - eval: epoch: 085, acc1: 72.390%, acc5: 90.686%, test_loss: 1.1043, per_image_load_time: 1.984ms, per_image_inference_time: 0.851ms
2022-03-07 12:58:48 - until epoch: 085, best_acc1: 72.580%
2022-03-07 12:58:48 - epoch 086 lr: 0.0010000000000000002
2022-03-07 12:59:12 - train: epoch 0086, iter [00100, 10009], lr: 0.001000, loss: 1.2651
2022-03-07 12:59:31 - train: epoch 0086, iter [00200, 10009], lr: 0.001000, loss: 1.1178
2022-03-07 12:59:51 - train: epoch 0086, iter [00300, 10009], lr: 0.001000, loss: 1.3908
2022-03-07 13:00:11 - train: epoch 0086, iter [00400, 10009], lr: 0.001000, loss: 1.2695
2022-03-07 13:00:31 - train: epoch 0086, iter [00500, 10009], lr: 0.001000, loss: 1.7459
2022-03-07 13:00:51 - train: epoch 0086, iter [00600, 10009], lr: 0.001000, loss: 1.5031
2022-03-07 13:01:11 - train: epoch 0086, iter [00700, 10009], lr: 0.001000, loss: 1.2611
2022-03-07 13:01:30 - train: epoch 0086, iter [00800, 10009], lr: 0.001000, loss: 1.5055
2022-03-07 13:01:50 - train: epoch 0086, iter [00900, 10009], lr: 0.001000, loss: 1.2246
2022-03-07 13:02:10 - train: epoch 0086, iter [01000, 10009], lr: 0.001000, loss: 1.3421
2022-03-07 13:02:30 - train: epoch 0086, iter [01100, 10009], lr: 0.001000, loss: 1.5177
2022-03-07 13:02:50 - train: epoch 0086, iter [01200, 10009], lr: 0.001000, loss: 1.0579
2022-03-07 13:03:10 - train: epoch 0086, iter [01300, 10009], lr: 0.001000, loss: 1.1408
2022-03-07 13:03:30 - train: epoch 0086, iter [01400, 10009], lr: 0.001000, loss: 1.1429
2022-03-07 13:03:50 - train: epoch 0086, iter [01500, 10009], lr: 0.001000, loss: 1.1326
2022-03-07 13:04:10 - train: epoch 0086, iter [01600, 10009], lr: 0.001000, loss: 1.2610
2022-03-07 13:04:30 - train: epoch 0086, iter [01700, 10009], lr: 0.001000, loss: 1.0639
2022-03-07 13:04:50 - train: epoch 0086, iter [01800, 10009], lr: 0.001000, loss: 1.1959
2022-03-07 13:05:10 - train: epoch 0086, iter [01900, 10009], lr: 0.001000, loss: 1.3734
2022-03-07 13:05:30 - train: epoch 0086, iter [02000, 10009], lr: 0.001000, loss: 1.1389
2022-03-07 13:05:49 - train: epoch 0086, iter [02100, 10009], lr: 0.001000, loss: 1.3212
2022-03-07 13:06:09 - train: epoch 0086, iter [02200, 10009], lr: 0.001000, loss: 1.2317
2022-03-07 13:06:29 - train: epoch 0086, iter [02300, 10009], lr: 0.001000, loss: 1.5239
2022-03-07 13:06:48 - train: epoch 0086, iter [02400, 10009], lr: 0.001000, loss: 1.0638
2022-03-07 13:07:08 - train: epoch 0086, iter [02500, 10009], lr: 0.001000, loss: 0.9993
2022-03-07 13:07:28 - train: epoch 0086, iter [02600, 10009], lr: 0.001000, loss: 1.3001
2022-03-07 13:07:48 - train: epoch 0086, iter [02700, 10009], lr: 0.001000, loss: 1.3063
2022-03-07 13:08:07 - train: epoch 0086, iter [02800, 10009], lr: 0.001000, loss: 1.2698
2022-03-07 13:08:27 - train: epoch 0086, iter [02900, 10009], lr: 0.001000, loss: 1.2108
2022-03-07 13:08:47 - train: epoch 0086, iter [03000, 10009], lr: 0.001000, loss: 1.1182
2022-03-07 13:09:07 - train: epoch 0086, iter [03100, 10009], lr: 0.001000, loss: 1.5128
2022-03-07 13:09:26 - train: epoch 0086, iter [03200, 10009], lr: 0.001000, loss: 1.3805
2022-03-07 13:09:46 - train: epoch 0086, iter [03300, 10009], lr: 0.001000, loss: 1.1921
2022-03-07 13:10:06 - train: epoch 0086, iter [03400, 10009], lr: 0.001000, loss: 1.3435
2022-03-07 13:10:26 - train: epoch 0086, iter [03500, 10009], lr: 0.001000, loss: 1.2820
2022-03-07 13:10:46 - train: epoch 0086, iter [03600, 10009], lr: 0.001000, loss: 1.6238
2022-03-07 13:11:05 - train: epoch 0086, iter [03700, 10009], lr: 0.001000, loss: 1.3439
2022-03-07 13:11:25 - train: epoch 0086, iter [03800, 10009], lr: 0.001000, loss: 1.4988
2022-03-07 13:11:45 - train: epoch 0086, iter [03900, 10009], lr: 0.001000, loss: 1.0917
2022-03-07 13:12:05 - train: epoch 0086, iter [04000, 10009], lr: 0.001000, loss: 1.6842
2022-03-07 13:12:25 - train: epoch 0086, iter [04100, 10009], lr: 0.001000, loss: 1.1831
2022-03-07 13:12:45 - train: epoch 0086, iter [04200, 10009], lr: 0.001000, loss: 1.2936
2022-03-07 13:13:05 - train: epoch 0086, iter [04300, 10009], lr: 0.001000, loss: 1.2384
2022-03-07 13:13:24 - train: epoch 0086, iter [04400, 10009], lr: 0.001000, loss: 1.3506
2022-03-07 13:13:44 - train: epoch 0086, iter [04500, 10009], lr: 0.001000, loss: 1.3569
2022-03-07 13:14:04 - train: epoch 0086, iter [04600, 10009], lr: 0.001000, loss: 1.1144
2022-03-07 13:14:24 - train: epoch 0086, iter [04700, 10009], lr: 0.001000, loss: 1.4395
2022-03-07 13:14:44 - train: epoch 0086, iter [04800, 10009], lr: 0.001000, loss: 1.3974
2022-03-07 13:15:04 - train: epoch 0086, iter [04900, 10009], lr: 0.001000, loss: 1.0848
2022-03-07 13:15:24 - train: epoch 0086, iter [05000, 10009], lr: 0.001000, loss: 1.3823
2022-03-07 13:15:44 - train: epoch 0086, iter [05100, 10009], lr: 0.001000, loss: 1.1072
2022-03-07 13:16:03 - train: epoch 0086, iter [05200, 10009], lr: 0.001000, loss: 1.2424
2022-03-07 13:16:23 - train: epoch 0086, iter [05300, 10009], lr: 0.001000, loss: 1.3786
2022-03-07 13:16:43 - train: epoch 0086, iter [05400, 10009], lr: 0.001000, loss: 1.0512
2022-03-07 13:17:03 - train: epoch 0086, iter [05500, 10009], lr: 0.001000, loss: 1.3302
2022-03-07 13:17:23 - train: epoch 0086, iter [05600, 10009], lr: 0.001000, loss: 1.3819
2022-03-07 13:17:42 - train: epoch 0086, iter [05700, 10009], lr: 0.001000, loss: 1.2956
2022-03-07 13:18:02 - train: epoch 0086, iter [05800, 10009], lr: 0.001000, loss: 1.1216
2022-03-07 13:18:22 - train: epoch 0086, iter [05900, 10009], lr: 0.001000, loss: 1.3727
2022-03-07 13:18:42 - train: epoch 0086, iter [06000, 10009], lr: 0.001000, loss: 1.0491
2022-03-07 13:19:02 - train: epoch 0086, iter [06100, 10009], lr: 0.001000, loss: 1.0716
2022-03-07 13:19:22 - train: epoch 0086, iter [06200, 10009], lr: 0.001000, loss: 1.3646
2022-03-07 13:19:41 - train: epoch 0086, iter [06300, 10009], lr: 0.001000, loss: 1.3347
2022-03-07 13:20:01 - train: epoch 0086, iter [06400, 10009], lr: 0.001000, loss: 1.5608
2022-03-07 13:20:21 - train: epoch 0086, iter [06500, 10009], lr: 0.001000, loss: 1.2443
2022-03-07 13:20:41 - train: epoch 0086, iter [06600, 10009], lr: 0.001000, loss: 1.0270
2022-03-07 13:21:01 - train: epoch 0086, iter [06700, 10009], lr: 0.001000, loss: 1.0324
2022-03-07 13:21:21 - train: epoch 0086, iter [06800, 10009], lr: 0.001000, loss: 1.2030
2022-03-07 13:21:41 - train: epoch 0086, iter [06900, 10009], lr: 0.001000, loss: 1.0808
2022-03-07 13:22:00 - train: epoch 0086, iter [07000, 10009], lr: 0.001000, loss: 1.4771
2022-03-07 13:22:20 - train: epoch 0086, iter [07100, 10009], lr: 0.001000, loss: 1.3793
2022-03-07 13:22:40 - train: epoch 0086, iter [07200, 10009], lr: 0.001000, loss: 1.1473
2022-03-07 13:23:00 - train: epoch 0086, iter [07300, 10009], lr: 0.001000, loss: 1.0471
2022-03-07 13:23:20 - train: epoch 0086, iter [07400, 10009], lr: 0.001000, loss: 1.4306
2022-03-07 13:23:40 - train: epoch 0086, iter [07500, 10009], lr: 0.001000, loss: 1.4535
2022-03-07 13:24:00 - train: epoch 0086, iter [07600, 10009], lr: 0.001000, loss: 1.1333
2022-03-07 13:24:19 - train: epoch 0086, iter [07700, 10009], lr: 0.001000, loss: 1.2579
2022-03-07 13:24:39 - train: epoch 0086, iter [07800, 10009], lr: 0.001000, loss: 1.1773
2022-03-07 13:24:59 - train: epoch 0086, iter [07900, 10009], lr: 0.001000, loss: 1.2519
2022-03-07 13:25:19 - train: epoch 0086, iter [08000, 10009], lr: 0.001000, loss: 1.3578
2022-03-07 13:25:39 - train: epoch 0086, iter [08100, 10009], lr: 0.001000, loss: 1.4735
2022-03-07 13:25:59 - train: epoch 0086, iter [08200, 10009], lr: 0.001000, loss: 1.2693
2022-03-07 13:26:18 - train: epoch 0086, iter [08300, 10009], lr: 0.001000, loss: 1.3440
2022-03-07 13:26:38 - train: epoch 0086, iter [08400, 10009], lr: 0.001000, loss: 1.2237
2022-03-07 13:26:58 - train: epoch 0086, iter [08500, 10009], lr: 0.001000, loss: 0.9120
2022-03-07 13:27:18 - train: epoch 0086, iter [08600, 10009], lr: 0.001000, loss: 1.4043
2022-03-07 13:27:38 - train: epoch 0086, iter [08700, 10009], lr: 0.001000, loss: 1.5418
2022-03-07 13:27:58 - train: epoch 0086, iter [08800, 10009], lr: 0.001000, loss: 1.1429
2022-03-07 13:28:18 - train: epoch 0086, iter [08900, 10009], lr: 0.001000, loss: 1.2410
2022-03-07 13:28:38 - train: epoch 0086, iter [09000, 10009], lr: 0.001000, loss: 1.3976
2022-03-07 13:28:57 - train: epoch 0086, iter [09100, 10009], lr: 0.001000, loss: 1.4407
2022-03-07 13:29:17 - train: epoch 0086, iter [09200, 10009], lr: 0.001000, loss: 1.2912
2022-03-07 13:29:37 - train: epoch 0086, iter [09300, 10009], lr: 0.001000, loss: 1.1014
2022-03-07 13:29:58 - train: epoch 0086, iter [09400, 10009], lr: 0.001000, loss: 1.2546
2022-03-07 13:30:17 - train: epoch 0086, iter [09500, 10009], lr: 0.001000, loss: 1.2151
2022-03-07 13:30:37 - train: epoch 0086, iter [09600, 10009], lr: 0.001000, loss: 1.2762
2022-03-07 13:30:57 - train: epoch 0086, iter [09700, 10009], lr: 0.001000, loss: 1.1755
2022-03-07 13:31:17 - train: epoch 0086, iter [09800, 10009], lr: 0.001000, loss: 1.1132
2022-03-07 13:31:37 - train: epoch 0086, iter [09900, 10009], lr: 0.001000, loss: 1.0598
2022-03-07 13:31:57 - train: epoch 0086, iter [10000, 10009], lr: 0.001000, loss: 1.5293
2022-03-07 13:32:00 - train: epoch 086, train_loss: 1.2432
2022-03-07 13:33:15 - eval: epoch: 086, acc1: 72.394%, acc5: 90.614%, test_loss: 1.1100, per_image_load_time: 0.920ms, per_image_inference_time: 0.932ms
2022-03-07 13:33:16 - until epoch: 086, best_acc1: 72.580%
2022-03-07 13:33:16 - epoch 087 lr: 0.0010000000000000002
2022-03-07 13:33:39 - train: epoch 0087, iter [00100, 10009], lr: 0.001000, loss: 1.3387
2022-03-07 13:33:59 - train: epoch 0087, iter [00200, 10009], lr: 0.001000, loss: 1.2198
2022-03-07 13:34:18 - train: epoch 0087, iter [00300, 10009], lr: 0.001000, loss: 1.2238
2022-03-07 13:34:38 - train: epoch 0087, iter [00400, 10009], lr: 0.001000, loss: 1.1987
2022-03-07 13:34:57 - train: epoch 0087, iter [00500, 10009], lr: 0.001000, loss: 1.1685
2022-03-07 13:35:17 - train: epoch 0087, iter [00600, 10009], lr: 0.001000, loss: 1.1534
2022-03-07 13:35:37 - train: epoch 0087, iter [00700, 10009], lr: 0.001000, loss: 1.1502
2022-03-07 13:35:56 - train: epoch 0087, iter [00800, 10009], lr: 0.001000, loss: 1.5595
2022-03-07 13:36:16 - train: epoch 0087, iter [00900, 10009], lr: 0.001000, loss: 1.2663
2022-03-07 13:36:36 - train: epoch 0087, iter [01000, 10009], lr: 0.001000, loss: 0.8955
2022-03-07 13:36:55 - train: epoch 0087, iter [01100, 10009], lr: 0.001000, loss: 1.2870
2022-03-07 13:37:15 - train: epoch 0087, iter [01200, 10009], lr: 0.001000, loss: 1.4727
2022-03-07 13:37:35 - train: epoch 0087, iter [01300, 10009], lr: 0.001000, loss: 1.1399
2022-03-07 13:37:55 - train: epoch 0087, iter [01400, 10009], lr: 0.001000, loss: 1.1179
2022-03-07 13:38:14 - train: epoch 0087, iter [01500, 10009], lr: 0.001000, loss: 1.4644
2022-03-07 13:38:34 - train: epoch 0087, iter [01600, 10009], lr: 0.001000, loss: 1.0860
2022-03-07 13:38:54 - train: epoch 0087, iter [01700, 10009], lr: 0.001000, loss: 1.0580
2022-03-07 13:39:13 - train: epoch 0087, iter [01800, 10009], lr: 0.001000, loss: 1.2339
2022-03-07 13:39:33 - train: epoch 0087, iter [01900, 10009], lr: 0.001000, loss: 1.2646
2022-03-07 13:39:53 - train: epoch 0087, iter [02000, 10009], lr: 0.001000, loss: 1.1694
2022-03-07 13:40:12 - train: epoch 0087, iter [02100, 10009], lr: 0.001000, loss: 1.1680
2022-03-07 13:40:32 - train: epoch 0087, iter [02200, 10009], lr: 0.001000, loss: 1.1596
2022-03-07 13:40:52 - train: epoch 0087, iter [02300, 10009], lr: 0.001000, loss: 1.3271
2022-03-07 13:41:12 - train: epoch 0087, iter [02400, 10009], lr: 0.001000, loss: 0.9892
2022-03-07 13:41:31 - train: epoch 0087, iter [02500, 10009], lr: 0.001000, loss: 1.0161
2022-03-07 13:41:51 - train: epoch 0087, iter [02600, 10009], lr: 0.001000, loss: 1.4735
2022-03-07 13:42:11 - train: epoch 0087, iter [02700, 10009], lr: 0.001000, loss: 1.4054
2022-03-07 13:42:31 - train: epoch 0087, iter [02800, 10009], lr: 0.001000, loss: 1.0653
2022-03-07 13:42:50 - train: epoch 0087, iter [02900, 10009], lr: 0.001000, loss: 1.2739
2022-03-07 13:43:10 - train: epoch 0087, iter [03000, 10009], lr: 0.001000, loss: 1.3712
2022-03-07 13:43:30 - train: epoch 0087, iter [03100, 10009], lr: 0.001000, loss: 1.2615
2022-03-07 13:43:49 - train: epoch 0087, iter [03200, 10009], lr: 0.001000, loss: 0.9593
2022-03-07 13:44:09 - train: epoch 0087, iter [03300, 10009], lr: 0.001000, loss: 1.1984
2022-03-07 13:44:29 - train: epoch 0087, iter [03400, 10009], lr: 0.001000, loss: 1.0618
2022-03-07 13:44:48 - train: epoch 0087, iter [03500, 10009], lr: 0.001000, loss: 1.0902
2022-03-07 13:45:08 - train: epoch 0087, iter [03600, 10009], lr: 0.001000, loss: 1.2914
2022-03-07 13:45:28 - train: epoch 0087, iter [03700, 10009], lr: 0.001000, loss: 1.2222
2022-03-07 13:45:48 - train: epoch 0087, iter [03800, 10009], lr: 0.001000, loss: 1.2076
2022-03-07 13:46:07 - train: epoch 0087, iter [03900, 10009], lr: 0.001000, loss: 1.0554
2022-03-07 13:46:27 - train: epoch 0087, iter [04000, 10009], lr: 0.001000, loss: 1.2118
2022-03-07 13:46:47 - train: epoch 0087, iter [04100, 10009], lr: 0.001000, loss: 1.2597
2022-03-07 13:47:07 - train: epoch 0087, iter [04200, 10009], lr: 0.001000, loss: 1.1482
2022-03-07 13:47:27 - train: epoch 0087, iter [04300, 10009], lr: 0.001000, loss: 1.4280
2022-03-07 13:47:46 - train: epoch 0087, iter [04400, 10009], lr: 0.001000, loss: 1.4330
2022-03-07 13:48:06 - train: epoch 0087, iter [04500, 10009], lr: 0.001000, loss: 1.1909
2022-03-07 13:48:26 - train: epoch 0087, iter [04600, 10009], lr: 0.001000, loss: 1.3700
2022-03-07 13:48:46 - train: epoch 0087, iter [04700, 10009], lr: 0.001000, loss: 1.0952
2022-03-07 13:49:06 - train: epoch 0087, iter [04800, 10009], lr: 0.001000, loss: 1.2100
2022-03-07 13:49:25 - train: epoch 0087, iter [04900, 10009], lr: 0.001000, loss: 1.2950
2022-03-07 13:49:45 - train: epoch 0087, iter [05000, 10009], lr: 0.001000, loss: 1.1605
2022-03-07 13:50:05 - train: epoch 0087, iter [05100, 10009], lr: 0.001000, loss: 1.1052
2022-03-07 13:50:24 - train: epoch 0087, iter [05200, 10009], lr: 0.001000, loss: 1.4913
2022-03-07 13:50:44 - train: epoch 0087, iter [05300, 10009], lr: 0.001000, loss: 1.5408
2022-03-07 13:51:04 - train: epoch 0087, iter [05400, 10009], lr: 0.001000, loss: 1.1731
2022-03-07 13:51:24 - train: epoch 0087, iter [05500, 10009], lr: 0.001000, loss: 1.2538
2022-03-07 13:51:43 - train: epoch 0087, iter [05600, 10009], lr: 0.001000, loss: 1.3605
2022-03-07 13:52:03 - train: epoch 0087, iter [05700, 10009], lr: 0.001000, loss: 1.1909
2022-03-07 13:52:23 - train: epoch 0087, iter [05800, 10009], lr: 0.001000, loss: 1.1397
2022-03-07 13:52:43 - train: epoch 0087, iter [05900, 10009], lr: 0.001000, loss: 1.2999
2022-03-07 13:53:02 - train: epoch 0087, iter [06000, 10009], lr: 0.001000, loss: 1.5213
2022-03-07 13:53:22 - train: epoch 0087, iter [06100, 10009], lr: 0.001000, loss: 1.0427
2022-03-07 13:53:42 - train: epoch 0087, iter [06200, 10009], lr: 0.001000, loss: 1.1213
2022-03-07 13:54:02 - train: epoch 0087, iter [06300, 10009], lr: 0.001000, loss: 1.1709
2022-03-07 13:54:21 - train: epoch 0087, iter [06400, 10009], lr: 0.001000, loss: 1.2656
2022-03-07 13:54:41 - train: epoch 0087, iter [06500, 10009], lr: 0.001000, loss: 1.2424
2022-03-07 13:55:01 - train: epoch 0087, iter [06600, 10009], lr: 0.001000, loss: 1.1529
2022-03-07 13:55:21 - train: epoch 0087, iter [06700, 10009], lr: 0.001000, loss: 1.2315
2022-03-07 13:55:41 - train: epoch 0087, iter [06800, 10009], lr: 0.001000, loss: 1.2296
2022-03-07 13:56:01 - train: epoch 0087, iter [06900, 10009], lr: 0.001000, loss: 1.4211
2022-03-07 13:56:20 - train: epoch 0087, iter [07000, 10009], lr: 0.001000, loss: 1.0180
2022-03-07 13:56:40 - train: epoch 0087, iter [07100, 10009], lr: 0.001000, loss: 1.3774
2022-03-07 13:57:00 - train: epoch 0087, iter [07200, 10009], lr: 0.001000, loss: 1.2585
2022-03-07 13:57:20 - train: epoch 0087, iter [07300, 10009], lr: 0.001000, loss: 1.6459
2022-03-07 13:57:40 - train: epoch 0087, iter [07400, 10009], lr: 0.001000, loss: 1.1943
2022-03-07 13:58:00 - train: epoch 0087, iter [07500, 10009], lr: 0.001000, loss: 1.2857
2022-03-07 13:58:20 - train: epoch 0087, iter [07600, 10009], lr: 0.001000, loss: 1.2778
2022-03-07 13:58:39 - train: epoch 0087, iter [07700, 10009], lr: 0.001000, loss: 0.9069
2022-03-07 13:58:59 - train: epoch 0087, iter [07800, 10009], lr: 0.001000, loss: 1.2609
2022-03-07 13:59:19 - train: epoch 0087, iter [07900, 10009], lr: 0.001000, loss: 1.1881
2022-03-07 13:59:39 - train: epoch 0087, iter [08000, 10009], lr: 0.001000, loss: 1.2372
2022-03-07 13:59:59 - train: epoch 0087, iter [08100, 10009], lr: 0.001000, loss: 1.3286
2022-03-07 14:00:19 - train: epoch 0087, iter [08200, 10009], lr: 0.001000, loss: 1.4590
2022-03-07 14:00:39 - train: epoch 0087, iter [08300, 10009], lr: 0.001000, loss: 1.1712
2022-03-07 14:00:59 - train: epoch 0087, iter [08400, 10009], lr: 0.001000, loss: 1.4894
2022-03-07 14:01:18 - train: epoch 0087, iter [08500, 10009], lr: 0.001000, loss: 1.1427
2022-03-07 14:01:38 - train: epoch 0087, iter [08600, 10009], lr: 0.001000, loss: 1.5342
2022-03-07 14:01:58 - train: epoch 0087, iter [08700, 10009], lr: 0.001000, loss: 1.0907
2022-03-07 14:02:18 - train: epoch 0087, iter [08800, 10009], lr: 0.001000, loss: 1.0508
2022-03-07 14:02:38 - train: epoch 0087, iter [08900, 10009], lr: 0.001000, loss: 1.3615
2022-03-07 14:02:58 - train: epoch 0087, iter [09000, 10009], lr: 0.001000, loss: 1.2914
2022-03-07 14:03:18 - train: epoch 0087, iter [09100, 10009], lr: 0.001000, loss: 1.2704
2022-03-07 14:03:38 - train: epoch 0087, iter [09200, 10009], lr: 0.001000, loss: 1.1397
2022-03-07 14:03:57 - train: epoch 0087, iter [09300, 10009], lr: 0.001000, loss: 1.0678
2022-03-07 14:04:17 - train: epoch 0087, iter [09400, 10009], lr: 0.001000, loss: 1.1148
2022-03-07 14:04:37 - train: epoch 0087, iter [09500, 10009], lr: 0.001000, loss: 1.0262
2022-03-07 14:04:57 - train: epoch 0087, iter [09600, 10009], lr: 0.001000, loss: 1.2257
2022-03-07 14:05:16 - train: epoch 0087, iter [09700, 10009], lr: 0.001000, loss: 1.2422
2022-03-07 14:05:36 - train: epoch 0087, iter [09800, 10009], lr: 0.001000, loss: 1.2759
2022-03-07 14:05:56 - train: epoch 0087, iter [09900, 10009], lr: 0.001000, loss: 1.2734
2022-03-07 14:06:16 - train: epoch 0087, iter [10000, 10009], lr: 0.001000, loss: 1.1426
2022-03-07 14:06:19 - train: epoch 087, train_loss: 1.2407
2022-03-07 14:07:35 - eval: epoch: 087, acc1: 72.362%, acc5: 90.812%, test_loss: 1.1041, per_image_load_time: 1.992ms, per_image_inference_time: 0.854ms
2022-03-07 14:07:36 - until epoch: 087, best_acc1: 72.580%
2022-03-07 14:07:36 - epoch 088 lr: 0.0010000000000000002
2022-03-07 14:07:59 - train: epoch 0088, iter [00100, 10009], lr: 0.001000, loss: 1.0968
2022-03-07 14:08:19 - train: epoch 0088, iter [00200, 10009], lr: 0.001000, loss: 1.1210
2022-03-07 14:08:39 - train: epoch 0088, iter [00300, 10009], lr: 0.001000, loss: 1.3496
2022-03-07 14:08:59 - train: epoch 0088, iter [00400, 10009], lr: 0.001000, loss: 1.1483
2022-03-07 14:09:18 - train: epoch 0088, iter [00500, 10009], lr: 0.001000, loss: 1.0775
2022-03-07 14:09:38 - train: epoch 0088, iter [00600, 10009], lr: 0.001000, loss: 1.5575
2022-03-07 14:09:58 - train: epoch 0088, iter [00700, 10009], lr: 0.001000, loss: 1.0801
2022-03-07 14:10:17 - train: epoch 0088, iter [00800, 10009], lr: 0.001000, loss: 1.1471
2022-03-07 14:10:37 - train: epoch 0088, iter [00900, 10009], lr: 0.001000, loss: 1.2245
2022-03-07 14:10:56 - train: epoch 0088, iter [01000, 10009], lr: 0.001000, loss: 1.4558
2022-03-07 14:11:16 - train: epoch 0088, iter [01100, 10009], lr: 0.001000, loss: 1.2013
2022-03-07 14:11:36 - train: epoch 0088, iter [01200, 10009], lr: 0.001000, loss: 1.0324
2022-03-07 14:11:55 - train: epoch 0088, iter [01300, 10009], lr: 0.001000, loss: 0.9025
2022-03-07 14:12:15 - train: epoch 0088, iter [01400, 10009], lr: 0.001000, loss: 1.2265
2022-03-07 14:12:34 - train: epoch 0088, iter [01500, 10009], lr: 0.001000, loss: 1.1209
2022-03-07 14:12:54 - train: epoch 0088, iter [01600, 10009], lr: 0.001000, loss: 1.3398
2022-03-07 14:13:14 - train: epoch 0088, iter [01700, 10009], lr: 0.001000, loss: 1.3456
2022-03-07 14:13:33 - train: epoch 0088, iter [01800, 10009], lr: 0.001000, loss: 1.1089
2022-03-07 14:13:53 - train: epoch 0088, iter [01900, 10009], lr: 0.001000, loss: 1.5084
2022-03-07 14:14:12 - train: epoch 0088, iter [02000, 10009], lr: 0.001000, loss: 1.1844
2022-03-07 14:14:32 - train: epoch 0088, iter [02100, 10009], lr: 0.001000, loss: 1.0029
2022-03-07 14:14:52 - train: epoch 0088, iter [02200, 10009], lr: 0.001000, loss: 1.0930
2022-03-07 14:15:12 - train: epoch 0088, iter [02300, 10009], lr: 0.001000, loss: 1.1033
2022-03-07 14:15:32 - train: epoch 0088, iter [02400, 10009], lr: 0.001000, loss: 1.1828
2022-03-07 14:15:52 - train: epoch 0088, iter [02500, 10009], lr: 0.001000, loss: 1.3691
2022-03-07 14:16:12 - train: epoch 0088, iter [02600, 10009], lr: 0.001000, loss: 1.1314
2022-03-07 14:16:31 - train: epoch 0088, iter [02700, 10009], lr: 0.001000, loss: 1.2304
2022-03-07 14:16:51 - train: epoch 0088, iter [02800, 10009], lr: 0.001000, loss: 1.0950
2022-03-07 14:17:11 - train: epoch 0088, iter [02900, 10009], lr: 0.001000, loss: 1.1949
2022-03-07 14:17:31 - train: epoch 0088, iter [03000, 10009], lr: 0.001000, loss: 0.9860
2022-03-07 14:17:51 - train: epoch 0088, iter [03100, 10009], lr: 0.001000, loss: 1.2902
2022-03-07 14:18:11 - train: epoch 0088, iter [03200, 10009], lr: 0.001000, loss: 0.9538
2022-03-07 14:18:31 - train: epoch 0088, iter [03300, 10009], lr: 0.001000, loss: 1.1097
2022-03-07 14:18:51 - train: epoch 0088, iter [03400, 10009], lr: 0.001000, loss: 1.5769
2022-03-07 14:19:10 - train: epoch 0088, iter [03500, 10009], lr: 0.001000, loss: 1.4324
2022-03-07 14:19:30 - train: epoch 0088, iter [03600, 10009], lr: 0.001000, loss: 1.0737
2022-03-07 14:19:50 - train: epoch 0088, iter [03700, 10009], lr: 0.001000, loss: 1.3083
2022-03-07 14:20:10 - train: epoch 0088, iter [03800, 10009], lr: 0.001000, loss: 1.3841
2022-03-07 14:20:30 - train: epoch 0088, iter [03900, 10009], lr: 0.001000, loss: 0.9294
2022-03-07 14:20:50 - train: epoch 0088, iter [04000, 10009], lr: 0.001000, loss: 1.4758
2022-03-07 14:21:10 - train: epoch 0088, iter [04100, 10009], lr: 0.001000, loss: 1.2462
2022-03-07 14:21:30 - train: epoch 0088, iter [04200, 10009], lr: 0.001000, loss: 1.2291
2022-03-07 14:21:50 - train: epoch 0088, iter [04300, 10009], lr: 0.001000, loss: 1.1279
2022-03-07 14:22:10 - train: epoch 0088, iter [04400, 10009], lr: 0.001000, loss: 1.3207
2022-03-07 14:22:30 - train: epoch 0088, iter [04500, 10009], lr: 0.001000, loss: 1.3050
2022-03-07 14:22:50 - train: epoch 0088, iter [04600, 10009], lr: 0.001000, loss: 1.2208
2022-03-07 14:23:10 - train: epoch 0088, iter [04700, 10009], lr: 0.001000, loss: 1.2632
2022-03-07 14:23:30 - train: epoch 0088, iter [04800, 10009], lr: 0.001000, loss: 1.3401
2022-03-07 14:23:50 - train: epoch 0088, iter [04900, 10009], lr: 0.001000, loss: 1.2491
2022-03-07 14:24:10 - train: epoch 0088, iter [05000, 10009], lr: 0.001000, loss: 1.4737
2022-03-07 14:24:30 - train: epoch 0088, iter [05100, 10009], lr: 0.001000, loss: 1.1441
2022-03-07 14:24:50 - train: epoch 0088, iter [05200, 10009], lr: 0.001000, loss: 1.2289
2022-03-07 14:25:10 - train: epoch 0088, iter [05300, 10009], lr: 0.001000, loss: 1.4321
2022-03-07 14:25:30 - train: epoch 0088, iter [05400, 10009], lr: 0.001000, loss: 1.4514
2022-03-07 14:25:50 - train: epoch 0088, iter [05500, 10009], lr: 0.001000, loss: 1.0367
2022-03-07 14:26:10 - train: epoch 0088, iter [05600, 10009], lr: 0.001000, loss: 1.2951
2022-03-07 14:26:30 - train: epoch 0088, iter [05700, 10009], lr: 0.001000, loss: 1.1074
2022-03-07 14:26:49 - train: epoch 0088, iter [05800, 10009], lr: 0.001000, loss: 1.0528
2022-03-07 14:27:09 - train: epoch 0088, iter [05900, 10009], lr: 0.001000, loss: 1.1819
2022-03-07 14:27:29 - train: epoch 0088, iter [06000, 10009], lr: 0.001000, loss: 1.3627
2022-03-07 14:27:49 - train: epoch 0088, iter [06100, 10009], lr: 0.001000, loss: 1.3698
2022-03-07 14:28:09 - train: epoch 0088, iter [06200, 10009], lr: 0.001000, loss: 1.4345
2022-03-07 14:28:29 - train: epoch 0088, iter [06300, 10009], lr: 0.001000, loss: 1.4527
2022-03-07 14:28:49 - train: epoch 0088, iter [06400, 10009], lr: 0.001000, loss: 0.9220
2022-03-07 14:29:09 - train: epoch 0088, iter [06500, 10009], lr: 0.001000, loss: 1.2392
2022-03-07 14:29:29 - train: epoch 0088, iter [06600, 10009], lr: 0.001000, loss: 0.7921
2022-03-07 14:29:49 - train: epoch 0088, iter [06700, 10009], lr: 0.001000, loss: 0.9808
2022-03-07 14:30:09 - train: epoch 0088, iter [06800, 10009], lr: 0.001000, loss: 1.2215
2022-03-07 14:30:29 - train: epoch 0088, iter [06900, 10009], lr: 0.001000, loss: 1.2346
2022-03-07 14:30:49 - train: epoch 0088, iter [07000, 10009], lr: 0.001000, loss: 1.0406
2022-03-07 14:31:09 - train: epoch 0088, iter [07100, 10009], lr: 0.001000, loss: 1.0047
2022-03-07 14:31:29 - train: epoch 0088, iter [07200, 10009], lr: 0.001000, loss: 1.3559
2022-03-07 14:31:50 - train: epoch 0088, iter [07300, 10009], lr: 0.001000, loss: 1.1979
2022-03-07 14:32:10 - train: epoch 0088, iter [07400, 10009], lr: 0.001000, loss: 1.5551
2022-03-07 14:32:30 - train: epoch 0088, iter [07500, 10009], lr: 0.001000, loss: 1.1232
2022-03-07 14:32:50 - train: epoch 0088, iter [07600, 10009], lr: 0.001000, loss: 1.5024
2022-03-07 14:33:10 - train: epoch 0088, iter [07700, 10009], lr: 0.001000, loss: 1.1743
2022-03-07 14:33:30 - train: epoch 0088, iter [07800, 10009], lr: 0.001000, loss: 1.4655
2022-03-07 14:33:50 - train: epoch 0088, iter [07900, 10009], lr: 0.001000, loss: 1.1111
2022-03-07 14:34:11 - train: epoch 0088, iter [08000, 10009], lr: 0.001000, loss: 1.0412
2022-03-07 14:34:31 - train: epoch 0088, iter [08100, 10009], lr: 0.001000, loss: 1.2907
2022-03-07 14:34:51 - train: epoch 0088, iter [08200, 10009], lr: 0.001000, loss: 1.1677
2022-03-07 14:35:11 - train: epoch 0088, iter [08300, 10009], lr: 0.001000, loss: 1.0887
2022-03-07 14:35:31 - train: epoch 0088, iter [08400, 10009], lr: 0.001000, loss: 1.1484
2022-03-07 14:35:52 - train: epoch 0088, iter [08500, 10009], lr: 0.001000, loss: 1.2964
2022-03-07 14:36:12 - train: epoch 0088, iter [08600, 10009], lr: 0.001000, loss: 1.1322
2022-03-07 14:36:32 - train: epoch 0088, iter [08700, 10009], lr: 0.001000, loss: 1.1959
2022-03-07 14:36:52 - train: epoch 0088, iter [08800, 10009], lr: 0.001000, loss: 0.9089
2022-03-07 14:37:12 - train: epoch 0088, iter [08900, 10009], lr: 0.001000, loss: 1.4943
2022-03-07 14:37:32 - train: epoch 0088, iter [09000, 10009], lr: 0.001000, loss: 1.1813
2022-03-07 14:37:53 - train: epoch 0088, iter [09100, 10009], lr: 0.001000, loss: 1.4096
2022-03-07 14:38:13 - train: epoch 0088, iter [09200, 10009], lr: 0.001000, loss: 1.4896
2022-03-07 14:38:33 - train: epoch 0088, iter [09300, 10009], lr: 0.001000, loss: 1.2688
2022-03-07 14:38:53 - train: epoch 0088, iter [09400, 10009], lr: 0.001000, loss: 1.2960
2022-03-07 14:39:13 - train: epoch 0088, iter [09500, 10009], lr: 0.001000, loss: 1.5260
2022-03-07 14:39:33 - train: epoch 0088, iter [09600, 10009], lr: 0.001000, loss: 1.2134
2022-03-07 14:39:53 - train: epoch 0088, iter [09700, 10009], lr: 0.001000, loss: 1.4703
2022-03-07 14:40:14 - train: epoch 0088, iter [09800, 10009], lr: 0.001000, loss: 1.0474
2022-03-07 14:40:34 - train: epoch 0088, iter [09900, 10009], lr: 0.001000, loss: 1.1775
2022-03-07 14:40:54 - train: epoch 0088, iter [10000, 10009], lr: 0.001000, loss: 1.2862
2022-03-07 14:40:57 - train: epoch 088, train_loss: 1.2375
2022-03-07 14:42:13 - eval: epoch: 088, acc1: 72.552%, acc5: 90.764%, test_loss: 1.0996, per_image_load_time: 2.023ms, per_image_inference_time: 0.842ms
2022-03-07 14:42:14 - until epoch: 088, best_acc1: 72.580%
2022-03-07 14:42:14 - epoch 089 lr: 0.0010000000000000002
2022-03-07 14:42:37 - train: epoch 0089, iter [00100, 10009], lr: 0.001000, loss: 1.0776
2022-03-07 14:42:57 - train: epoch 0089, iter [00200, 10009], lr: 0.001000, loss: 1.1724
2022-03-07 14:43:16 - train: epoch 0089, iter [00300, 10009], lr: 0.001000, loss: 1.1367
2022-03-07 14:43:36 - train: epoch 0089, iter [00400, 10009], lr: 0.001000, loss: 1.0152
2022-03-07 14:43:56 - train: epoch 0089, iter [00500, 10009], lr: 0.001000, loss: 1.0171
2022-03-07 14:44:16 - train: epoch 0089, iter [00600, 10009], lr: 0.001000, loss: 1.3410
2022-03-07 14:44:35 - train: epoch 0089, iter [00700, 10009], lr: 0.001000, loss: 1.4105
2022-03-07 14:44:55 - train: epoch 0089, iter [00800, 10009], lr: 0.001000, loss: 1.1358
2022-03-07 14:45:15 - train: epoch 0089, iter [00900, 10009], lr: 0.001000, loss: 1.0440
2022-03-07 14:45:34 - train: epoch 0089, iter [01000, 10009], lr: 0.001000, loss: 0.9047
2022-03-07 14:45:54 - train: epoch 0089, iter [01100, 10009], lr: 0.001000, loss: 1.0487
2022-03-07 14:46:14 - train: epoch 0089, iter [01200, 10009], lr: 0.001000, loss: 1.2045
2022-03-07 14:46:33 - train: epoch 0089, iter [01300, 10009], lr: 0.001000, loss: 1.1261
2022-03-07 14:46:53 - train: epoch 0089, iter [01400, 10009], lr: 0.001000, loss: 1.2356
2022-03-07 14:47:13 - train: epoch 0089, iter [01500, 10009], lr: 0.001000, loss: 0.9858
2022-03-07 14:47:32 - train: epoch 0089, iter [01600, 10009], lr: 0.001000, loss: 1.4679
2022-03-07 14:47:52 - train: epoch 0089, iter [01700, 10009], lr: 0.001000, loss: 1.3191
2022-03-07 14:48:12 - train: epoch 0089, iter [01800, 10009], lr: 0.001000, loss: 1.0480
2022-03-07 14:48:31 - train: epoch 0089, iter [01900, 10009], lr: 0.001000, loss: 1.4749
2022-03-07 14:48:51 - train: epoch 0089, iter [02000, 10009], lr: 0.001000, loss: 1.2661
2022-03-07 14:49:11 - train: epoch 0089, iter [02100, 10009], lr: 0.001000, loss: 1.3672
2022-03-07 14:49:30 - train: epoch 0089, iter [02200, 10009], lr: 0.001000, loss: 1.2019
2022-03-07 14:49:50 - train: epoch 0089, iter [02300, 10009], lr: 0.001000, loss: 1.3382
2022-03-07 14:50:10 - train: epoch 0089, iter [02400, 10009], lr: 0.001000, loss: 1.5577
2022-03-07 14:50:29 - train: epoch 0089, iter [02500, 10009], lr: 0.001000, loss: 1.1321
2022-03-07 14:50:49 - train: epoch 0089, iter [02600, 10009], lr: 0.001000, loss: 1.2172
2022-03-07 14:51:08 - train: epoch 0089, iter [02700, 10009], lr: 0.001000, loss: 1.5038
2022-03-07 14:51:28 - train: epoch 0089, iter [02800, 10009], lr: 0.001000, loss: 1.2548
2022-03-07 14:51:47 - train: epoch 0089, iter [02900, 10009], lr: 0.001000, loss: 1.2515
2022-03-07 14:52:07 - train: epoch 0089, iter [03000, 10009], lr: 0.001000, loss: 1.1981
2022-03-07 14:52:27 - train: epoch 0089, iter [03100, 10009], lr: 0.001000, loss: 1.1256
2022-03-07 14:52:46 - train: epoch 0089, iter [03200, 10009], lr: 0.001000, loss: 1.1142
2022-03-07 14:53:06 - train: epoch 0089, iter [03300, 10009], lr: 0.001000, loss: 1.0973
2022-03-07 14:53:25 - train: epoch 0089, iter [03400, 10009], lr: 0.001000, loss: 1.1837
2022-03-07 14:53:45 - train: epoch 0089, iter [03500, 10009], lr: 0.001000, loss: 1.7325
2022-03-07 14:54:04 - train: epoch 0089, iter [03600, 10009], lr: 0.001000, loss: 1.2795
2022-03-07 14:54:24 - train: epoch 0089, iter [03700, 10009], lr: 0.001000, loss: 1.2006
2022-03-07 14:54:44 - train: epoch 0089, iter [03800, 10009], lr: 0.001000, loss: 1.0447
2022-03-07 14:55:03 - train: epoch 0089, iter [03900, 10009], lr: 0.001000, loss: 1.3098
2022-03-07 14:55:23 - train: epoch 0089, iter [04000, 10009], lr: 0.001000, loss: 1.3574
2022-03-07 14:55:42 - train: epoch 0089, iter [04100, 10009], lr: 0.001000, loss: 1.2946
2022-03-07 14:56:02 - train: epoch 0089, iter [04200, 10009], lr: 0.001000, loss: 1.1649
2022-03-07 14:56:22 - train: epoch 0089, iter [04300, 10009], lr: 0.001000, loss: 1.2296
2022-03-07 14:56:41 - train: epoch 0089, iter [04400, 10009], lr: 0.001000, loss: 1.1736
2022-03-07 14:57:01 - train: epoch 0089, iter [04500, 10009], lr: 0.001000, loss: 1.3066
2022-03-07 14:57:20 - train: epoch 0089, iter [04600, 10009], lr: 0.001000, loss: 1.1747
2022-03-07 14:57:40 - train: epoch 0089, iter [04700, 10009], lr: 0.001000, loss: 1.1994
2022-03-07 14:58:00 - train: epoch 0089, iter [04800, 10009], lr: 0.001000, loss: 1.6651
2022-03-07 14:58:19 - train: epoch 0089, iter [04900, 10009], lr: 0.001000, loss: 1.2850
2022-03-07 14:58:39 - train: epoch 0089, iter [05000, 10009], lr: 0.001000, loss: 1.2531
2022-03-07 14:58:58 - train: epoch 0089, iter [05100, 10009], lr: 0.001000, loss: 1.2546
2022-03-07 14:59:18 - train: epoch 0089, iter [05200, 10009], lr: 0.001000, loss: 1.2869
2022-03-07 14:59:38 - train: epoch 0089, iter [05300, 10009], lr: 0.001000, loss: 1.5106
2022-03-07 14:59:57 - train: epoch 0089, iter [05400, 10009], lr: 0.001000, loss: 1.1576
2022-03-07 15:00:17 - train: epoch 0089, iter [05500, 10009], lr: 0.001000, loss: 1.3103
2022-03-07 15:00:37 - train: epoch 0089, iter [05600, 10009], lr: 0.001000, loss: 1.2475
2022-03-07 15:00:56 - train: epoch 0089, iter [05700, 10009], lr: 0.001000, loss: 0.9818
2022-03-07 15:01:16 - train: epoch 0089, iter [05800, 10009], lr: 0.001000, loss: 1.4206
2022-03-07 15:01:35 - train: epoch 0089, iter [05900, 10009], lr: 0.001000, loss: 1.3977
2022-03-07 15:01:55 - train: epoch 0089, iter [06000, 10009], lr: 0.001000, loss: 1.1764
2022-03-07 15:02:14 - train: epoch 0089, iter [06100, 10009], lr: 0.001000, loss: 1.2127
2022-03-07 15:02:34 - train: epoch 0089, iter [06200, 10009], lr: 0.001000, loss: 1.2827
2022-03-07 15:02:54 - train: epoch 0089, iter [06300, 10009], lr: 0.001000, loss: 1.1411
2022-03-07 15:03:13 - train: epoch 0089, iter [06400, 10009], lr: 0.001000, loss: 1.3653
2022-03-07 15:03:33 - train: epoch 0089, iter [06500, 10009], lr: 0.001000, loss: 1.4754
2022-03-07 15:03:53 - train: epoch 0089, iter [06600, 10009], lr: 0.001000, loss: 1.4247
2022-03-07 15:04:12 - train: epoch 0089, iter [06700, 10009], lr: 0.001000, loss: 1.4936
2022-03-07 15:04:32 - train: epoch 0089, iter [06800, 10009], lr: 0.001000, loss: 1.2829
2022-03-07 15:04:51 - train: epoch 0089, iter [06900, 10009], lr: 0.001000, loss: 1.1146
2022-03-07 15:05:11 - train: epoch 0089, iter [07000, 10009], lr: 0.001000, loss: 1.1208
2022-03-07 15:05:31 - train: epoch 0089, iter [07100, 10009], lr: 0.001000, loss: 1.2155
2022-03-07 15:05:51 - train: epoch 0089, iter [07200, 10009], lr: 0.001000, loss: 1.1662
2022-03-07 15:06:10 - train: epoch 0089, iter [07300, 10009], lr: 0.001000, loss: 1.3980
2022-03-07 15:06:30 - train: epoch 0089, iter [07400, 10009], lr: 0.001000, loss: 1.1439
2022-03-07 15:06:50 - train: epoch 0089, iter [07500, 10009], lr: 0.001000, loss: 1.2963
2022-03-07 15:07:09 - train: epoch 0089, iter [07600, 10009], lr: 0.001000, loss: 0.9153
2022-03-07 15:07:29 - train: epoch 0089, iter [07700, 10009], lr: 0.001000, loss: 1.2946
2022-03-07 15:07:49 - train: epoch 0089, iter [07800, 10009], lr: 0.001000, loss: 1.3561
2022-03-07 15:08:08 - train: epoch 0089, iter [07900, 10009], lr: 0.001000, loss: 1.0859
2022-03-07 15:08:28 - train: epoch 0089, iter [08000, 10009], lr: 0.001000, loss: 1.4254
2022-03-07 15:08:48 - train: epoch 0089, iter [08100, 10009], lr: 0.001000, loss: 1.5098
2022-03-07 15:09:07 - train: epoch 0089, iter [08200, 10009], lr: 0.001000, loss: 1.1935
2022-03-07 15:09:27 - train: epoch 0089, iter [08300, 10009], lr: 0.001000, loss: 1.1420
2022-03-07 15:09:47 - train: epoch 0089, iter [08400, 10009], lr: 0.001000, loss: 1.2173
2022-03-07 15:10:06 - train: epoch 0089, iter [08500, 10009], lr: 0.001000, loss: 1.2155
2022-03-07 15:10:26 - train: epoch 0089, iter [08600, 10009], lr: 0.001000, loss: 1.3048
2022-03-07 15:10:46 - train: epoch 0089, iter [08700, 10009], lr: 0.001000, loss: 0.9922
2022-03-07 15:11:05 - train: epoch 0089, iter [08800, 10009], lr: 0.001000, loss: 1.2273
2022-03-07 15:11:25 - train: epoch 0089, iter [08900, 10009], lr: 0.001000, loss: 1.3369
2022-03-07 15:11:45 - train: epoch 0089, iter [09000, 10009], lr: 0.001000, loss: 1.1057
2022-03-07 15:12:05 - train: epoch 0089, iter [09100, 10009], lr: 0.001000, loss: 1.2064
2022-03-07 15:12:24 - train: epoch 0089, iter [09200, 10009], lr: 0.001000, loss: 1.1171
2022-03-07 15:12:44 - train: epoch 0089, iter [09300, 10009], lr: 0.001000, loss: 0.9884
2022-03-07 15:13:04 - train: epoch 0089, iter [09400, 10009], lr: 0.001000, loss: 1.1327
2022-03-07 15:13:24 - train: epoch 0089, iter [09500, 10009], lr: 0.001000, loss: 1.2498
2022-03-07 15:13:43 - train: epoch 0089, iter [09600, 10009], lr: 0.001000, loss: 1.4380
2022-03-07 15:14:03 - train: epoch 0089, iter [09700, 10009], lr: 0.001000, loss: 1.1616
2022-03-07 15:14:23 - train: epoch 0089, iter [09800, 10009], lr: 0.001000, loss: 1.3959
2022-03-07 15:14:43 - train: epoch 0089, iter [09900, 10009], lr: 0.001000, loss: 1.3937
2022-03-07 15:15:02 - train: epoch 0089, iter [10000, 10009], lr: 0.001000, loss: 1.0985
2022-03-07 15:15:06 - train: epoch 089, train_loss: 1.2387
2022-03-07 15:16:21 - eval: epoch: 089, acc1: 72.542%, acc5: 90.702%, test_loss: 1.1035, per_image_load_time: 1.754ms, per_image_inference_time: 0.899ms
2022-03-07 15:16:22 - until epoch: 089, best_acc1: 72.580%
2022-03-07 15:16:22 - epoch 090 lr: 0.0010000000000000002
2022-03-07 15:16:45 - train: epoch 0090, iter [00100, 10009], lr: 0.001000, loss: 1.2180
2022-03-07 15:17:05 - train: epoch 0090, iter [00200, 10009], lr: 0.001000, loss: 1.1388
2022-03-07 15:17:24 - train: epoch 0090, iter [00300, 10009], lr: 0.001000, loss: 1.2625
2022-03-07 15:17:43 - train: epoch 0090, iter [00400, 10009], lr: 0.001000, loss: 1.2279
2022-03-07 15:18:03 - train: epoch 0090, iter [00500, 10009], lr: 0.001000, loss: 1.3389
2022-03-07 15:18:22 - train: epoch 0090, iter [00600, 10009], lr: 0.001000, loss: 1.2495
2022-03-07 15:18:42 - train: epoch 0090, iter [00700, 10009], lr: 0.001000, loss: 1.1601
2022-03-07 15:19:02 - train: epoch 0090, iter [00800, 10009], lr: 0.001000, loss: 1.2439
2022-03-07 15:19:22 - train: epoch 0090, iter [00900, 10009], lr: 0.001000, loss: 1.4822
2022-03-07 15:19:41 - train: epoch 0090, iter [01000, 10009], lr: 0.001000, loss: 1.1687
2022-03-07 15:20:01 - train: epoch 0090, iter [01100, 10009], lr: 0.001000, loss: 1.1238
2022-03-07 15:20:20 - train: epoch 0090, iter [01200, 10009], lr: 0.001000, loss: 1.4645
2022-03-07 15:20:40 - train: epoch 0090, iter [01300, 10009], lr: 0.001000, loss: 1.3611
2022-03-07 15:21:00 - train: epoch 0090, iter [01400, 10009], lr: 0.001000, loss: 1.1434
2022-03-07 15:21:19 - train: epoch 0090, iter [01500, 10009], lr: 0.001000, loss: 1.1433
2022-03-07 15:21:39 - train: epoch 0090, iter [01600, 10009], lr: 0.001000, loss: 1.2364
2022-03-07 15:21:58 - train: epoch 0090, iter [01700, 10009], lr: 0.001000, loss: 1.5045
2022-03-07 15:22:18 - train: epoch 0090, iter [01800, 10009], lr: 0.001000, loss: 1.4086
2022-03-07 15:22:38 - train: epoch 0090, iter [01900, 10009], lr: 0.001000, loss: 1.1826
2022-03-07 15:22:57 - train: epoch 0090, iter [02000, 10009], lr: 0.001000, loss: 1.2439
2022-03-07 15:23:17 - train: epoch 0090, iter [02100, 10009], lr: 0.001000, loss: 1.3217
2022-03-07 15:23:37 - train: epoch 0090, iter [02200, 10009], lr: 0.001000, loss: 1.1602
2022-03-07 15:23:57 - train: epoch 0090, iter [02300, 10009], lr: 0.001000, loss: 1.5426
2022-03-07 15:24:16 - train: epoch 0090, iter [02400, 10009], lr: 0.001000, loss: 1.1598
2022-03-07 15:24:36 - train: epoch 0090, iter [02500, 10009], lr: 0.001000, loss: 1.1270
2022-03-07 15:24:56 - train: epoch 0090, iter [02600, 10009], lr: 0.001000, loss: 1.3093
2022-03-07 15:25:16 - train: epoch 0090, iter [02700, 10009], lr: 0.001000, loss: 1.5676
2022-03-07 15:25:35 - train: epoch 0090, iter [02800, 10009], lr: 0.001000, loss: 1.1981
2022-03-07 15:25:55 - train: epoch 0090, iter [02900, 10009], lr: 0.001000, loss: 1.2194
2022-03-07 15:26:15 - train: epoch 0090, iter [03000, 10009], lr: 0.001000, loss: 1.5425
2022-03-07 15:26:34 - train: epoch 0090, iter [03100, 10009], lr: 0.001000, loss: 1.0878
2022-03-07 15:26:54 - train: epoch 0090, iter [03200, 10009], lr: 0.001000, loss: 1.1231
2022-03-07 15:27:14 - train: epoch 0090, iter [03300, 10009], lr: 0.001000, loss: 1.1486
2022-03-07 15:27:33 - train: epoch 0090, iter [03400, 10009], lr: 0.001000, loss: 1.1420
2022-03-07 15:27:53 - train: epoch 0090, iter [03500, 10009], lr: 0.001000, loss: 1.3834
2022-03-07 15:28:13 - train: epoch 0090, iter [03600, 10009], lr: 0.001000, loss: 1.3981
2022-03-07 15:28:33 - train: epoch 0090, iter [03700, 10009], lr: 0.001000, loss: 1.4216
2022-03-07 15:28:52 - train: epoch 0090, iter [03800, 10009], lr: 0.001000, loss: 1.6307
2022-03-07 15:29:12 - train: epoch 0090, iter [03900, 10009], lr: 0.001000, loss: 0.9514
2022-03-07 15:29:32 - train: epoch 0090, iter [04000, 10009], lr: 0.001000, loss: 1.2337
2022-03-07 15:29:51 - train: epoch 0090, iter [04100, 10009], lr: 0.001000, loss: 1.3683
2022-03-07 15:30:11 - train: epoch 0090, iter [04200, 10009], lr: 0.001000, loss: 1.5248
2022-03-07 15:30:31 - train: epoch 0090, iter [04300, 10009], lr: 0.001000, loss: 1.1755
2022-03-07 15:30:51 - train: epoch 0090, iter [04400, 10009], lr: 0.001000, loss: 1.2896
2022-03-07 15:31:10 - train: epoch 0090, iter [04500, 10009], lr: 0.001000, loss: 1.3167
2022-03-07 15:31:30 - train: epoch 0090, iter [04600, 10009], lr: 0.001000, loss: 1.4172
2022-03-07 15:31:50 - train: epoch 0090, iter [04700, 10009], lr: 0.001000, loss: 1.3587
2022-03-07 15:32:10 - train: epoch 0090, iter [04800, 10009], lr: 0.001000, loss: 1.3059
2022-03-07 15:32:29 - train: epoch 0090, iter [04900, 10009], lr: 0.001000, loss: 1.2676
2022-03-07 15:32:49 - train: epoch 0090, iter [05000, 10009], lr: 0.001000, loss: 1.1934
2022-03-07 15:33:09 - train: epoch 0090, iter [05100, 10009], lr: 0.001000, loss: 1.2896
2022-03-07 15:33:29 - train: epoch 0090, iter [05200, 10009], lr: 0.001000, loss: 1.1935
2022-03-07 15:33:48 - train: epoch 0090, iter [05300, 10009], lr: 0.001000, loss: 1.2059
2022-03-07 15:34:08 - train: epoch 0090, iter [05400, 10009], lr: 0.001000, loss: 1.2121
2022-03-07 15:34:28 - train: epoch 0090, iter [05500, 10009], lr: 0.001000, loss: 1.4515
2022-03-07 15:34:48 - train: epoch 0090, iter [05600, 10009], lr: 0.001000, loss: 1.1759
2022-03-07 15:35:07 - train: epoch 0090, iter [05700, 10009], lr: 0.001000, loss: 1.2712
2022-03-07 15:35:27 - train: epoch 0090, iter [05800, 10009], lr: 0.001000, loss: 1.2478
2022-03-07 15:35:47 - train: epoch 0090, iter [05900, 10009], lr: 0.001000, loss: 1.0880
2022-03-07 15:36:07 - train: epoch 0090, iter [06000, 10009], lr: 0.001000, loss: 1.1986
2022-03-07 15:36:26 - train: epoch 0090, iter [06100, 10009], lr: 0.001000, loss: 1.0766
2022-03-07 15:36:46 - train: epoch 0090, iter [06200, 10009], lr: 0.001000, loss: 1.0663
2022-03-07 15:37:06 - train: epoch 0090, iter [06300, 10009], lr: 0.001000, loss: 0.9965
2022-03-07 15:37:26 - train: epoch 0090, iter [06400, 10009], lr: 0.001000, loss: 1.3438
2022-03-07 15:37:45 - train: epoch 0090, iter [06500, 10009], lr: 0.001000, loss: 1.3255
2022-03-07 15:38:05 - train: epoch 0090, iter [06600, 10009], lr: 0.001000, loss: 1.4881
2022-03-07 15:38:25 - train: epoch 0090, iter [06700, 10009], lr: 0.001000, loss: 1.0343
2022-03-07 15:38:45 - train: epoch 0090, iter [06800, 10009], lr: 0.001000, loss: 1.3886
2022-03-07 15:39:04 - train: epoch 0090, iter [06900, 10009], lr: 0.001000, loss: 1.0821
2022-03-07 15:39:24 - train: epoch 0090, iter [07000, 10009], lr: 0.001000, loss: 1.2190
2022-03-07 15:39:44 - train: epoch 0090, iter [07100, 10009], lr: 0.001000, loss: 1.1821
2022-03-07 15:40:04 - train: epoch 0090, iter [07200, 10009], lr: 0.001000, loss: 1.0900
2022-03-07 15:40:24 - train: epoch 0090, iter [07300, 10009], lr: 0.001000, loss: 1.1338
2022-03-07 15:40:43 - train: epoch 0090, iter [07400, 10009], lr: 0.001000, loss: 1.2255
2022-03-07 15:41:03 - train: epoch 0090, iter [07500, 10009], lr: 0.001000, loss: 1.2980
2022-03-07 15:41:23 - train: epoch 0090, iter [07600, 10009], lr: 0.001000, loss: 1.1781
2022-03-07 15:41:42 - train: epoch 0090, iter [07700, 10009], lr: 0.001000, loss: 1.2934
2022-03-07 15:42:02 - train: epoch 0090, iter [07800, 10009], lr: 0.001000, loss: 1.1503
2022-03-07 15:42:22 - train: epoch 0090, iter [07900, 10009], lr: 0.001000, loss: 1.3156
2022-03-07 15:42:42 - train: epoch 0090, iter [08000, 10009], lr: 0.001000, loss: 1.4647
2022-03-07 15:43:01 - train: epoch 0090, iter [08100, 10009], lr: 0.001000, loss: 1.3605
2022-03-07 15:43:21 - train: epoch 0090, iter [08200, 10009], lr: 0.001000, loss: 1.3411
2022-03-07 15:43:41 - train: epoch 0090, iter [08300, 10009], lr: 0.001000, loss: 1.4046
2022-03-07 15:44:01 - train: epoch 0090, iter [08400, 10009], lr: 0.001000, loss: 1.5919
2022-03-07 15:44:20 - train: epoch 0090, iter [08500, 10009], lr: 0.001000, loss: 1.4195
2022-03-07 15:44:40 - train: epoch 0090, iter [08600, 10009], lr: 0.001000, loss: 1.3352
2022-03-07 15:45:00 - train: epoch 0090, iter [08700, 10009], lr: 0.001000, loss: 1.0536
2022-03-07 15:45:20 - train: epoch 0090, iter [08800, 10009], lr: 0.001000, loss: 1.0965
2022-03-07 15:45:39 - train: epoch 0090, iter [08900, 10009], lr: 0.001000, loss: 1.4360
2022-03-07 15:45:59 - train: epoch 0090, iter [09000, 10009], lr: 0.001000, loss: 1.4728
2022-03-07 15:46:19 - train: epoch 0090, iter [09100, 10009], lr: 0.001000, loss: 1.0786
2022-03-07 15:46:38 - train: epoch 0090, iter [09200, 10009], lr: 0.001000, loss: 1.1187
2022-03-07 15:46:58 - train: epoch 0090, iter [09300, 10009], lr: 0.001000, loss: 1.4868
2022-03-07 15:47:18 - train: epoch 0090, iter [09400, 10009], lr: 0.001000, loss: 1.1966
2022-03-07 15:47:38 - train: epoch 0090, iter [09500, 10009], lr: 0.001000, loss: 1.4449
2022-03-07 15:47:58 - train: epoch 0090, iter [09600, 10009], lr: 0.001000, loss: 1.2450
2022-03-07 15:48:17 - train: epoch 0090, iter [09700, 10009], lr: 0.001000, loss: 1.4611
2022-03-07 15:48:37 - train: epoch 0090, iter [09800, 10009], lr: 0.001000, loss: 1.2614
2022-03-07 15:48:57 - train: epoch 0090, iter [09900, 10009], lr: 0.001000, loss: 1.1821
2022-03-07 15:49:17 - train: epoch 0090, iter [10000, 10009], lr: 0.001000, loss: 1.1246
2022-03-07 15:49:20 - train: epoch 090, train_loss: 1.2366
2022-03-07 15:50:35 - eval: epoch: 090, acc1: 72.444%, acc5: 90.828%, test_loss: 1.1022, per_image_load_time: 1.665ms, per_image_inference_time: 0.907ms
2022-03-07 15:50:35 - until epoch: 090, best_acc1: 72.580%
2022-03-07 15:50:35 - epoch 091 lr: 0.00010000000000000003
2022-03-07 15:50:59 - train: epoch 0091, iter [00100, 10009], lr: 0.000100, loss: 0.9381
2022-03-07 15:51:18 - train: epoch 0091, iter [00200, 10009], lr: 0.000100, loss: 0.9758
2022-03-07 15:51:38 - train: epoch 0091, iter [00300, 10009], lr: 0.000100, loss: 1.0820
2022-03-07 15:51:57 - train: epoch 0091, iter [00400, 10009], lr: 0.000100, loss: 1.3864
2022-03-07 15:52:16 - train: epoch 0091, iter [00500, 10009], lr: 0.000100, loss: 1.0710
2022-03-07 15:52:36 - train: epoch 0091, iter [00600, 10009], lr: 0.000100, loss: 1.2682
2022-03-07 15:52:55 - train: epoch 0091, iter [00700, 10009], lr: 0.000100, loss: 1.2204
2022-03-07 15:53:15 - train: epoch 0091, iter [00800, 10009], lr: 0.000100, loss: 0.9378
2022-03-07 15:53:34 - train: epoch 0091, iter [00900, 10009], lr: 0.000100, loss: 1.3072
2022-03-07 15:53:54 - train: epoch 0091, iter [01000, 10009], lr: 0.000100, loss: 1.2219
2022-03-07 15:54:13 - train: epoch 0091, iter [01100, 10009], lr: 0.000100, loss: 0.9998
2022-03-07 15:54:32 - train: epoch 0091, iter [01200, 10009], lr: 0.000100, loss: 1.4040
2022-03-07 15:54:52 - train: epoch 0091, iter [01300, 10009], lr: 0.000100, loss: 1.1216
2022-03-07 15:55:11 - train: epoch 0091, iter [01400, 10009], lr: 0.000100, loss: 1.2769
2022-03-07 15:55:31 - train: epoch 0091, iter [01500, 10009], lr: 0.000100, loss: 1.2814
2022-03-07 15:55:50 - train: epoch 0091, iter [01600, 10009], lr: 0.000100, loss: 1.0898
2022-03-07 15:56:10 - train: epoch 0091, iter [01700, 10009], lr: 0.000100, loss: 1.3134
2022-03-07 15:56:29 - train: epoch 0091, iter [01800, 10009], lr: 0.000100, loss: 1.4993
2022-03-07 15:56:49 - train: epoch 0091, iter [01900, 10009], lr: 0.000100, loss: 1.1101
2022-03-07 15:57:08 - train: epoch 0091, iter [02000, 10009], lr: 0.000100, loss: 1.1971
2022-03-07 15:57:27 - train: epoch 0091, iter [02100, 10009], lr: 0.000100, loss: 1.0916
2022-03-07 15:57:47 - train: epoch 0091, iter [02200, 10009], lr: 0.000100, loss: 1.0631
2022-03-07 15:58:07 - train: epoch 0091, iter [02300, 10009], lr: 0.000100, loss: 1.1136
2022-03-07 15:58:26 - train: epoch 0091, iter [02400, 10009], lr: 0.000100, loss: 1.3317
2022-03-07 15:58:46 - train: epoch 0091, iter [02500, 10009], lr: 0.000100, loss: 1.4085
2022-03-07 15:59:06 - train: epoch 0091, iter [02600, 10009], lr: 0.000100, loss: 1.1500
2022-03-07 15:59:25 - train: epoch 0091, iter [02700, 10009], lr: 0.000100, loss: 1.0967
2022-03-07 15:59:45 - train: epoch 0091, iter [02800, 10009], lr: 0.000100, loss: 1.2981
2022-03-07 16:00:04 - train: epoch 0091, iter [02900, 10009], lr: 0.000100, loss: 1.3181
2022-03-07 16:00:24 - train: epoch 0091, iter [03000, 10009], lr: 0.000100, loss: 1.1313
2022-03-07 16:00:43 - train: epoch 0091, iter [03100, 10009], lr: 0.000100, loss: 0.9557
2022-03-07 16:01:03 - train: epoch 0091, iter [03200, 10009], lr: 0.000100, loss: 1.3096
2022-03-07 16:01:22 - train: epoch 0091, iter [03300, 10009], lr: 0.000100, loss: 1.3842
2022-03-07 16:01:42 - train: epoch 0091, iter [03400, 10009], lr: 0.000100, loss: 1.1506
2022-03-07 16:02:01 - train: epoch 0091, iter [03500, 10009], lr: 0.000100, loss: 1.1546
2022-03-07 16:02:21 - train: epoch 0091, iter [03600, 10009], lr: 0.000100, loss: 1.1126
2022-03-07 16:02:40 - train: epoch 0091, iter [03700, 10009], lr: 0.000100, loss: 1.4271
2022-03-07 16:03:00 - train: epoch 0091, iter [03800, 10009], lr: 0.000100, loss: 1.5479
2022-03-07 16:03:20 - train: epoch 0091, iter [03900, 10009], lr: 0.000100, loss: 1.0277
2022-03-07 16:03:39 - train: epoch 0091, iter [04000, 10009], lr: 0.000100, loss: 1.1233
2022-03-07 16:03:59 - train: epoch 0091, iter [04100, 10009], lr: 0.000100, loss: 1.2743
2022-03-07 16:04:18 - train: epoch 0091, iter [04200, 10009], lr: 0.000100, loss: 0.9737
2022-03-07 16:04:38 - train: epoch 0091, iter [04300, 10009], lr: 0.000100, loss: 1.1718
2022-03-07 16:04:57 - train: epoch 0091, iter [04400, 10009], lr: 0.000100, loss: 1.4758
2022-03-07 16:05:17 - train: epoch 0091, iter [04500, 10009], lr: 0.000100, loss: 1.1528
2022-03-07 16:05:37 - train: epoch 0091, iter [04600, 10009], lr: 0.000100, loss: 1.1818
2022-03-07 16:05:56 - train: epoch 0091, iter [04700, 10009], lr: 0.000100, loss: 0.8924
2022-03-07 16:06:16 - train: epoch 0091, iter [04800, 10009], lr: 0.000100, loss: 1.1902
2022-03-07 16:06:35 - train: epoch 0091, iter [04900, 10009], lr: 0.000100, loss: 1.3447
2022-03-07 16:06:55 - train: epoch 0091, iter [05000, 10009], lr: 0.000100, loss: 1.2141
2022-03-07 16:07:15 - train: epoch 0091, iter [05100, 10009], lr: 0.000100, loss: 1.2467
2022-03-07 16:07:34 - train: epoch 0091, iter [05200, 10009], lr: 0.000100, loss: 1.1726
2022-03-07 16:07:54 - train: epoch 0091, iter [05300, 10009], lr: 0.000100, loss: 1.1297
2022-03-07 16:08:13 - train: epoch 0091, iter [05400, 10009], lr: 0.000100, loss: 0.9720
2022-03-07 16:08:33 - train: epoch 0091, iter [05500, 10009], lr: 0.000100, loss: 1.1210
2022-03-07 16:08:53 - train: epoch 0091, iter [05600, 10009], lr: 0.000100, loss: 1.1872
2022-03-07 16:09:12 - train: epoch 0091, iter [05700, 10009], lr: 0.000100, loss: 1.1967
2022-03-07 16:09:32 - train: epoch 0091, iter [05800, 10009], lr: 0.000100, loss: 1.3773
2022-03-07 16:09:52 - train: epoch 0091, iter [05900, 10009], lr: 0.000100, loss: 1.3714
2022-03-07 16:10:11 - train: epoch 0091, iter [06000, 10009], lr: 0.000100, loss: 1.2785
2022-03-07 16:10:31 - train: epoch 0091, iter [06100, 10009], lr: 0.000100, loss: 1.0428
2022-03-07 16:10:50 - train: epoch 0091, iter [06200, 10009], lr: 0.000100, loss: 1.4084
2022-03-07 16:11:10 - train: epoch 0091, iter [06300, 10009], lr: 0.000100, loss: 1.1721
2022-03-07 16:11:30 - train: epoch 0091, iter [06400, 10009], lr: 0.000100, loss: 1.3670
2022-03-07 16:11:49 - train: epoch 0091, iter [06500, 10009], lr: 0.000100, loss: 0.9364
2022-03-07 16:12:09 - train: epoch 0091, iter [06600, 10009], lr: 0.000100, loss: 1.1634
2022-03-07 16:12:29 - train: epoch 0091, iter [06700, 10009], lr: 0.000100, loss: 1.1930
2022-03-07 16:12:48 - train: epoch 0091, iter [06800, 10009], lr: 0.000100, loss: 1.1392
2022-03-07 16:13:08 - train: epoch 0091, iter [06900, 10009], lr: 0.000100, loss: 1.1337
2022-03-07 16:13:28 - train: epoch 0091, iter [07000, 10009], lr: 0.000100, loss: 1.3706
2022-03-07 16:13:47 - train: epoch 0091, iter [07100, 10009], lr: 0.000100, loss: 1.5796
2022-03-07 16:14:07 - train: epoch 0091, iter [07200, 10009], lr: 0.000100, loss: 1.0647
2022-03-07 16:14:26 - train: epoch 0091, iter [07300, 10009], lr: 0.000100, loss: 1.3723
2022-03-07 16:14:46 - train: epoch 0091, iter [07400, 10009], lr: 0.000100, loss: 1.4339
2022-03-07 16:15:06 - train: epoch 0091, iter [07500, 10009], lr: 0.000100, loss: 1.2521
2022-03-07 16:15:25 - train: epoch 0091, iter [07600, 10009], lr: 0.000100, loss: 1.2576
2022-03-07 16:15:45 - train: epoch 0091, iter [07700, 10009], lr: 0.000100, loss: 1.1594
2022-03-07 16:16:04 - train: epoch 0091, iter [07800, 10009], lr: 0.000100, loss: 1.2346
2022-03-07 16:16:24 - train: epoch 0091, iter [07900, 10009], lr: 0.000100, loss: 1.2442
2022-03-07 16:16:44 - train: epoch 0091, iter [08000, 10009], lr: 0.000100, loss: 1.2578
2022-03-07 16:17:03 - train: epoch 0091, iter [08100, 10009], lr: 0.000100, loss: 1.2723
2022-03-07 16:17:23 - train: epoch 0091, iter [08200, 10009], lr: 0.000100, loss: 1.2695
2022-03-07 16:17:42 - train: epoch 0091, iter [08300, 10009], lr: 0.000100, loss: 1.5150
2022-03-07 16:18:02 - train: epoch 0091, iter [08400, 10009], lr: 0.000100, loss: 1.2501
2022-03-07 16:18:22 - train: epoch 0091, iter [08500, 10009], lr: 0.000100, loss: 1.2874
2022-03-07 16:18:42 - train: epoch 0091, iter [08600, 10009], lr: 0.000100, loss: 1.2674
2022-03-07 16:19:02 - train: epoch 0091, iter [08700, 10009], lr: 0.000100, loss: 1.1950
2022-03-07 16:19:22 - train: epoch 0091, iter [08800, 10009], lr: 0.000100, loss: 1.1163
2022-03-07 16:19:42 - train: epoch 0091, iter [08900, 10009], lr: 0.000100, loss: 1.0186
2022-03-07 16:20:02 - train: epoch 0091, iter [09000, 10009], lr: 0.000100, loss: 1.2989
2022-03-07 16:20:22 - train: epoch 0091, iter [09100, 10009], lr: 0.000100, loss: 0.8908
2022-03-07 16:20:42 - train: epoch 0091, iter [09200, 10009], lr: 0.000100, loss: 1.0930
2022-03-07 16:21:05 - train: epoch 0091, iter [09300, 10009], lr: 0.000100, loss: 1.0872
2022-03-07 16:21:29 - train: epoch 0091, iter [09400, 10009], lr: 0.000100, loss: 1.5260
2022-03-07 16:21:49 - train: epoch 0091, iter [09500, 10009], lr: 0.000100, loss: 1.5960
2022-03-07 16:22:09 - train: epoch 0091, iter [09600, 10009], lr: 0.000100, loss: 1.2407
2022-03-07 16:22:29 - train: epoch 0091, iter [09700, 10009], lr: 0.000100, loss: 1.4792
2022-03-07 16:22:49 - train: epoch 0091, iter [09800, 10009], lr: 0.000100, loss: 1.2518
2022-03-07 16:23:09 - train: epoch 0091, iter [09900, 10009], lr: 0.000100, loss: 1.1944
2022-03-07 16:23:29 - train: epoch 0091, iter [10000, 10009], lr: 0.000100, loss: 1.3926
2022-03-07 16:23:32 - train: epoch 091, train_loss: 1.1848
2022-03-07 16:24:51 - eval: epoch: 091, acc1: 73.350%, acc5: 91.188%, test_loss: 1.0692, per_image_load_time: 1.010ms, per_image_inference_time: 0.885ms
2022-03-07 16:24:51 - until epoch: 091, best_acc1: 73.350%
2022-03-07 16:24:51 - epoch 092 lr: 0.00010000000000000003
2022-03-07 16:25:15 - train: epoch 0092, iter [00100, 10009], lr: 0.000100, loss: 1.2962
2022-03-07 16:25:35 - train: epoch 0092, iter [00200, 10009], lr: 0.000100, loss: 1.3936
2022-03-07 16:25:54 - train: epoch 0092, iter [00300, 10009], lr: 0.000100, loss: 1.5819
2022-03-07 16:26:14 - train: epoch 0092, iter [00400, 10009], lr: 0.000100, loss: 1.4568
2022-03-07 16:26:34 - train: epoch 0092, iter [00500, 10009], lr: 0.000100, loss: 1.0925
2022-03-07 16:26:55 - train: epoch 0092, iter [00600, 10009], lr: 0.000100, loss: 1.3043
2022-03-07 16:27:15 - train: epoch 0092, iter [00700, 10009], lr: 0.000100, loss: 0.8447
2022-03-07 16:27:34 - train: epoch 0092, iter [00800, 10009], lr: 0.000100, loss: 1.0668
2022-03-07 16:27:54 - train: epoch 0092, iter [00900, 10009], lr: 0.000100, loss: 0.8888
2022-03-07 16:28:14 - train: epoch 0092, iter [01000, 10009], lr: 0.000100, loss: 1.0831
2022-03-07 16:28:33 - train: epoch 0092, iter [01100, 10009], lr: 0.000100, loss: 1.1896
2022-03-07 16:28:53 - train: epoch 0092, iter [01200, 10009], lr: 0.000100, loss: 1.1792
2022-03-07 16:29:12 - train: epoch 0092, iter [01300, 10009], lr: 0.000100, loss: 1.1258
2022-03-07 16:29:32 - train: epoch 0092, iter [01400, 10009], lr: 0.000100, loss: 1.2579
2022-03-07 16:29:51 - train: epoch 0092, iter [01500, 10009], lr: 0.000100, loss: 1.2009
2022-03-07 16:30:11 - train: epoch 0092, iter [01600, 10009], lr: 0.000100, loss: 1.3532
2022-03-07 16:30:31 - train: epoch 0092, iter [01700, 10009], lr: 0.000100, loss: 0.8797
2022-03-07 16:30:51 - train: epoch 0092, iter [01800, 10009], lr: 0.000100, loss: 1.1127
2022-03-07 16:31:11 - train: epoch 0092, iter [01900, 10009], lr: 0.000100, loss: 1.2712
2022-03-07 16:31:30 - train: epoch 0092, iter [02000, 10009], lr: 0.000100, loss: 1.1999
2022-03-07 16:31:50 - train: epoch 0092, iter [02100, 10009], lr: 0.000100, loss: 1.0757
2022-03-07 16:32:10 - train: epoch 0092, iter [02200, 10009], lr: 0.000100, loss: 1.0638
2022-03-07 16:32:30 - train: epoch 0092, iter [02300, 10009], lr: 0.000100, loss: 1.0844
2022-03-07 16:32:50 - train: epoch 0092, iter [02400, 10009], lr: 0.000100, loss: 1.0848
2022-03-07 16:33:10 - train: epoch 0092, iter [02500, 10009], lr: 0.000100, loss: 0.8756
2022-03-07 16:33:30 - train: epoch 0092, iter [02600, 10009], lr: 0.000100, loss: 1.0026
2022-03-07 16:33:50 - train: epoch 0092, iter [02700, 10009], lr: 0.000100, loss: 1.1823
2022-03-07 16:34:10 - train: epoch 0092, iter [02800, 10009], lr: 0.000100, loss: 1.1686
2022-03-07 16:34:30 - train: epoch 0092, iter [02900, 10009], lr: 0.000100, loss: 1.1189
2022-03-07 16:34:50 - train: epoch 0092, iter [03000, 10009], lr: 0.000100, loss: 0.9436
2022-03-07 16:35:10 - train: epoch 0092, iter [03100, 10009], lr: 0.000100, loss: 1.4293
2022-03-07 16:35:30 - train: epoch 0092, iter [03200, 10009], lr: 0.000100, loss: 1.0479
2022-03-07 16:35:50 - train: epoch 0092, iter [03300, 10009], lr: 0.000100, loss: 0.8490
2022-03-07 16:36:10 - train: epoch 0092, iter [03400, 10009], lr: 0.000100, loss: 1.1793
2022-03-07 16:36:30 - train: epoch 0092, iter [03500, 10009], lr: 0.000100, loss: 1.2291
2022-03-07 16:36:50 - train: epoch 0092, iter [03600, 10009], lr: 0.000100, loss: 0.9755
2022-03-07 16:37:09 - train: epoch 0092, iter [03700, 10009], lr: 0.000100, loss: 1.4482
2022-03-07 16:37:29 - train: epoch 0092, iter [03800, 10009], lr: 0.000100, loss: 1.2572
2022-03-07 16:37:49 - train: epoch 0092, iter [03900, 10009], lr: 0.000100, loss: 1.2319
2022-03-07 16:38:09 - train: epoch 0092, iter [04000, 10009], lr: 0.000100, loss: 0.9801
2022-03-07 16:38:30 - train: epoch 0092, iter [04100, 10009], lr: 0.000100, loss: 1.2648
2022-03-07 16:38:49 - train: epoch 0092, iter [04200, 10009], lr: 0.000100, loss: 1.1488
2022-03-07 16:39:09 - train: epoch 0092, iter [04300, 10009], lr: 0.000100, loss: 1.0046
2022-03-07 16:39:30 - train: epoch 0092, iter [04400, 10009], lr: 0.000100, loss: 1.1331
2022-03-07 16:39:49 - train: epoch 0092, iter [04500, 10009], lr: 0.000100, loss: 1.2790
2022-03-07 16:40:09 - train: epoch 0092, iter [04600, 10009], lr: 0.000100, loss: 1.1395
2022-03-07 16:40:29 - train: epoch 0092, iter [04700, 10009], lr: 0.000100, loss: 1.0846
2022-03-07 16:40:49 - train: epoch 0092, iter [04800, 10009], lr: 0.000100, loss: 1.2019
2022-03-07 16:41:08 - train: epoch 0092, iter [04900, 10009], lr: 0.000100, loss: 1.2170
2022-03-07 16:41:28 - train: epoch 0092, iter [05000, 10009], lr: 0.000100, loss: 1.1846
2022-03-07 16:41:48 - train: epoch 0092, iter [05100, 10009], lr: 0.000100, loss: 1.0767
2022-03-07 16:42:08 - train: epoch 0092, iter [05200, 10009], lr: 0.000100, loss: 1.4955
2022-03-07 16:42:28 - train: epoch 0092, iter [05300, 10009], lr: 0.000100, loss: 1.1009
2022-03-07 16:42:48 - train: epoch 0092, iter [05400, 10009], lr: 0.000100, loss: 1.1424
2022-03-07 16:43:09 - train: epoch 0092, iter [05500, 10009], lr: 0.000100, loss: 1.2276
2022-03-07 16:43:29 - train: epoch 0092, iter [05600, 10009], lr: 0.000100, loss: 1.1913
2022-03-07 16:43:49 - train: epoch 0092, iter [05700, 10009], lr: 0.000100, loss: 1.2625
2022-03-07 16:44:10 - train: epoch 0092, iter [05800, 10009], lr: 0.000100, loss: 1.1907
2022-03-07 16:44:30 - train: epoch 0092, iter [05900, 10009], lr: 0.000100, loss: 1.1858
2022-03-07 16:44:50 - train: epoch 0092, iter [06000, 10009], lr: 0.000100, loss: 1.1287
2022-03-07 16:45:10 - train: epoch 0092, iter [06100, 10009], lr: 0.000100, loss: 1.4868
2022-03-07 16:45:30 - train: epoch 0092, iter [06200, 10009], lr: 0.000100, loss: 1.1912
2022-03-07 16:45:50 - train: epoch 0092, iter [06300, 10009], lr: 0.000100, loss: 1.1249
2022-03-07 16:46:10 - train: epoch 0092, iter [06400, 10009], lr: 0.000100, loss: 1.1533
2022-03-07 16:46:31 - train: epoch 0092, iter [06500, 10009], lr: 0.000100, loss: 1.0978
2022-03-07 16:46:51 - train: epoch 0092, iter [06600, 10009], lr: 0.000100, loss: 1.2270
2022-03-07 16:47:11 - train: epoch 0092, iter [06700, 10009], lr: 0.000100, loss: 1.2133
2022-03-07 16:47:31 - train: epoch 0092, iter [06800, 10009], lr: 0.000100, loss: 1.4219
2022-03-07 16:47:52 - train: epoch 0092, iter [06900, 10009], lr: 0.000100, loss: 1.2293
2022-03-07 16:48:12 - train: epoch 0092, iter [07000, 10009], lr: 0.000100, loss: 1.1312
2022-03-07 16:48:32 - train: epoch 0092, iter [07100, 10009], lr: 0.000100, loss: 1.1255
2022-03-07 16:48:52 - train: epoch 0092, iter [07200, 10009], lr: 0.000100, loss: 1.1746
2022-03-07 16:49:12 - train: epoch 0092, iter [07300, 10009], lr: 0.000100, loss: 1.0767
2022-03-07 16:49:32 - train: epoch 0092, iter [07400, 10009], lr: 0.000100, loss: 1.4478
2022-03-07 16:49:52 - train: epoch 0092, iter [07500, 10009], lr: 0.000100, loss: 1.4684
2022-03-07 16:50:12 - train: epoch 0092, iter [07600, 10009], lr: 0.000100, loss: 1.1043
2022-03-07 16:50:32 - train: epoch 0092, iter [07700, 10009], lr: 0.000100, loss: 1.4373
2022-03-07 16:50:52 - train: epoch 0092, iter [07800, 10009], lr: 0.000100, loss: 1.3394
2022-03-07 16:51:13 - train: epoch 0092, iter [07900, 10009], lr: 0.000100, loss: 1.1686
2022-03-07 16:51:33 - train: epoch 0092, iter [08000, 10009], lr: 0.000100, loss: 1.1832
2022-03-07 16:51:53 - train: epoch 0092, iter [08100, 10009], lr: 0.000100, loss: 1.0826
2022-03-07 16:52:13 - train: epoch 0092, iter [08200, 10009], lr: 0.000100, loss: 0.9092
2022-03-07 16:52:33 - train: epoch 0092, iter [08300, 10009], lr: 0.000100, loss: 1.3092
2022-03-07 16:52:53 - train: epoch 0092, iter [08400, 10009], lr: 0.000100, loss: 1.0302
2022-03-07 16:53:13 - train: epoch 0092, iter [08500, 10009], lr: 0.000100, loss: 1.0553
2022-03-07 16:53:33 - train: epoch 0092, iter [08600, 10009], lr: 0.000100, loss: 1.1884
2022-03-07 16:53:53 - train: epoch 0092, iter [08700, 10009], lr: 0.000100, loss: 0.9729
2022-03-07 16:54:13 - train: epoch 0092, iter [08800, 10009], lr: 0.000100, loss: 1.2396
2022-03-07 16:54:33 - train: epoch 0092, iter [08900, 10009], lr: 0.000100, loss: 1.2299
2022-03-07 16:54:53 - train: epoch 0092, iter [09000, 10009], lr: 0.000100, loss: 1.1873
2022-03-07 16:55:13 - train: epoch 0092, iter [09100, 10009], lr: 0.000100, loss: 1.3313
2022-03-07 16:55:33 - train: epoch 0092, iter [09200, 10009], lr: 0.000100, loss: 1.0710
2022-03-07 16:55:52 - train: epoch 0092, iter [09300, 10009], lr: 0.000100, loss: 1.1112
2022-03-07 16:56:12 - train: epoch 0092, iter [09400, 10009], lr: 0.000100, loss: 1.0159
2022-03-07 16:56:32 - train: epoch 0092, iter [09500, 10009], lr: 0.000100, loss: 1.1944
2022-03-07 16:56:52 - train: epoch 0092, iter [09600, 10009], lr: 0.000100, loss: 1.0521
2022-03-07 16:57:11 - train: epoch 0092, iter [09700, 10009], lr: 0.000100, loss: 1.2416
2022-03-07 16:57:31 - train: epoch 0092, iter [09800, 10009], lr: 0.000100, loss: 1.1749
2022-03-07 16:57:51 - train: epoch 0092, iter [09900, 10009], lr: 0.000100, loss: 1.1065
2022-03-07 16:58:11 - train: epoch 0092, iter [10000, 10009], lr: 0.000100, loss: 1.1628
2022-03-07 16:58:14 - train: epoch 092, train_loss: 1.1708
2022-03-07 16:59:30 - eval: epoch: 092, acc1: 73.372%, acc5: 91.198%, test_loss: 1.0671, per_image_load_time: 1.354ms, per_image_inference_time: 0.908ms
2022-03-07 16:59:31 - until epoch: 092, best_acc1: 73.372%
2022-03-07 16:59:31 - epoch 093 lr: 0.00010000000000000003
2022-03-07 16:59:54 - train: epoch 0093, iter [00100, 10009], lr: 0.000100, loss: 1.0582
2022-03-07 17:00:13 - train: epoch 0093, iter [00200, 10009], lr: 0.000100, loss: 1.1046
2022-03-07 17:00:32 - train: epoch 0093, iter [00300, 10009], lr: 0.000100, loss: 1.1770
2022-03-07 17:00:52 - train: epoch 0093, iter [00400, 10009], lr: 0.000100, loss: 0.7990
2022-03-07 17:01:11 - train: epoch 0093, iter [00500, 10009], lr: 0.000100, loss: 1.2846
2022-03-07 17:01:31 - train: epoch 0093, iter [00600, 10009], lr: 0.000100, loss: 1.1011
2022-03-07 17:01:50 - train: epoch 0093, iter [00700, 10009], lr: 0.000100, loss: 1.0645
2022-03-07 17:02:10 - train: epoch 0093, iter [00800, 10009], lr: 0.000100, loss: 1.4967
2022-03-07 17:02:29 - train: epoch 0093, iter [00900, 10009], lr: 0.000100, loss: 1.4054
2022-03-07 17:02:49 - train: epoch 0093, iter [01000, 10009], lr: 0.000100, loss: 1.3170
2022-03-07 17:03:08 - train: epoch 0093, iter [01100, 10009], lr: 0.000100, loss: 0.9283
2022-03-07 17:03:28 - train: epoch 0093, iter [01200, 10009], lr: 0.000100, loss: 1.0194
2022-03-07 17:03:47 - train: epoch 0093, iter [01300, 10009], lr: 0.000100, loss: 1.2008
2022-03-07 17:04:07 - train: epoch 0093, iter [01400, 10009], lr: 0.000100, loss: 1.0417
2022-03-07 17:04:26 - train: epoch 0093, iter [01500, 10009], lr: 0.000100, loss: 1.3777
2022-03-07 17:04:46 - train: epoch 0093, iter [01600, 10009], lr: 0.000100, loss: 0.9431
2022-03-07 17:05:06 - train: epoch 0093, iter [01700, 10009], lr: 0.000100, loss: 1.4543
2022-03-07 17:05:25 - train: epoch 0093, iter [01800, 10009], lr: 0.000100, loss: 1.1952
2022-03-07 17:05:45 - train: epoch 0093, iter [01900, 10009], lr: 0.000100, loss: 0.8561
2022-03-07 17:06:04 - train: epoch 0093, iter [02000, 10009], lr: 0.000100, loss: 0.9418
2022-03-07 17:06:24 - train: epoch 0093, iter [02100, 10009], lr: 0.000100, loss: 0.9456
2022-03-07 17:06:43 - train: epoch 0093, iter [02200, 10009], lr: 0.000100, loss: 1.0976
2022-03-07 17:07:03 - train: epoch 0093, iter [02300, 10009], lr: 0.000100, loss: 1.3620
2022-03-07 17:07:22 - train: epoch 0093, iter [02400, 10009], lr: 0.000100, loss: 1.3574
2022-03-07 17:07:42 - train: epoch 0093, iter [02500, 10009], lr: 0.000100, loss: 1.3754
2022-03-07 17:08:01 - train: epoch 0093, iter [02600, 10009], lr: 0.000100, loss: 1.2061
2022-03-07 17:08:21 - train: epoch 0093, iter [02700, 10009], lr: 0.000100, loss: 0.9334
2022-03-07 17:08:40 - train: epoch 0093, iter [02800, 10009], lr: 0.000100, loss: 1.2029
2022-03-07 17:09:00 - train: epoch 0093, iter [02900, 10009], lr: 0.000100, loss: 1.1966
2022-03-07 17:09:19 - train: epoch 0093, iter [03000, 10009], lr: 0.000100, loss: 1.2490
2022-03-07 17:09:39 - train: epoch 0093, iter [03100, 10009], lr: 0.000100, loss: 1.1700
2022-03-07 17:09:58 - train: epoch 0093, iter [03200, 10009], lr: 0.000100, loss: 1.0987
2022-03-07 17:10:18 - train: epoch 0093, iter [03300, 10009], lr: 0.000100, loss: 1.1495
2022-03-07 17:10:37 - train: epoch 0093, iter [03400, 10009], lr: 0.000100, loss: 1.1127
2022-03-07 17:10:57 - train: epoch 0093, iter [03500, 10009], lr: 0.000100, loss: 0.9608
2022-03-07 17:11:17 - train: epoch 0093, iter [03600, 10009], lr: 0.000100, loss: 1.1169
2022-03-07 17:11:36 - train: epoch 0093, iter [03700, 10009], lr: 0.000100, loss: 1.2755
2022-03-07 17:11:56 - train: epoch 0093, iter [03800, 10009], lr: 0.000100, loss: 1.0929
2022-03-07 17:12:15 - train: epoch 0093, iter [03900, 10009], lr: 0.000100, loss: 0.8935
2022-03-07 17:12:35 - train: epoch 0093, iter [04000, 10009], lr: 0.000100, loss: 1.1519
2022-03-07 17:12:55 - train: epoch 0093, iter [04100, 10009], lr: 0.000100, loss: 0.8976
2022-03-07 17:13:14 - train: epoch 0093, iter [04200, 10009], lr: 0.000100, loss: 0.9626
2022-03-07 17:13:34 - train: epoch 0093, iter [04300, 10009], lr: 0.000100, loss: 0.9238
2022-03-07 17:13:54 - train: epoch 0093, iter [04400, 10009], lr: 0.000100, loss: 1.1145
2022-03-07 17:14:14 - train: epoch 0093, iter [04500, 10009], lr: 0.000100, loss: 1.1962
2022-03-07 17:14:33 - train: epoch 0093, iter [04600, 10009], lr: 0.000100, loss: 1.1586
2022-03-07 17:14:53 - train: epoch 0093, iter [04700, 10009], lr: 0.000100, loss: 0.9139
2022-03-07 17:15:13 - train: epoch 0093, iter [04800, 10009], lr: 0.000100, loss: 1.1699
2022-03-07 17:15:33 - train: epoch 0093, iter [04900, 10009], lr: 0.000100, loss: 1.2487
2022-03-07 17:15:52 - train: epoch 0093, iter [05000, 10009], lr: 0.000100, loss: 1.2077
2022-03-07 17:16:12 - train: epoch 0093, iter [05100, 10009], lr: 0.000100, loss: 1.3020
2022-03-07 17:16:32 - train: epoch 0093, iter [05200, 10009], lr: 0.000100, loss: 1.2174
2022-03-07 17:16:51 - train: epoch 0093, iter [05300, 10009], lr: 0.000100, loss: 1.1136
2022-03-07 17:17:11 - train: epoch 0093, iter [05400, 10009], lr: 0.000100, loss: 1.0055
2022-03-07 17:17:31 - train: epoch 0093, iter [05500, 10009], lr: 0.000100, loss: 1.4087
2022-03-07 17:17:51 - train: epoch 0093, iter [05600, 10009], lr: 0.000100, loss: 1.2156
2022-03-07 17:18:11 - train: epoch 0093, iter [05700, 10009], lr: 0.000100, loss: 1.4195
2022-03-07 17:18:31 - train: epoch 0093, iter [05800, 10009], lr: 0.000100, loss: 1.3407
2022-03-07 17:18:50 - train: epoch 0093, iter [05900, 10009], lr: 0.000100, loss: 1.0023
2022-03-07 17:19:10 - train: epoch 0093, iter [06000, 10009], lr: 0.000100, loss: 1.4030
2022-03-07 17:19:30 - train: epoch 0093, iter [06100, 10009], lr: 0.000100, loss: 0.9990
2022-03-07 17:19:50 - train: epoch 0093, iter [06200, 10009], lr: 0.000100, loss: 1.1297
2022-03-07 17:20:09 - train: epoch 0093, iter [06300, 10009], lr: 0.000100, loss: 1.0230
2022-03-07 17:20:29 - train: epoch 0093, iter [06400, 10009], lr: 0.000100, loss: 1.1497
2022-03-07 17:20:49 - train: epoch 0093, iter [06500, 10009], lr: 0.000100, loss: 1.1173
2022-03-07 17:21:09 - train: epoch 0093, iter [06600, 10009], lr: 0.000100, loss: 1.2494
2022-03-07 17:21:28 - train: epoch 0093, iter [06700, 10009], lr: 0.000100, loss: 1.0776
2022-03-07 17:21:48 - train: epoch 0093, iter [06800, 10009], lr: 0.000100, loss: 1.6548
2022-03-07 17:22:08 - train: epoch 0093, iter [06900, 10009], lr: 0.000100, loss: 1.1751
2022-03-07 17:22:28 - train: epoch 0093, iter [07000, 10009], lr: 0.000100, loss: 0.9978
2022-03-07 17:22:47 - train: epoch 0093, iter [07100, 10009], lr: 0.000100, loss: 1.1573
2022-03-07 17:23:07 - train: epoch 0093, iter [07200, 10009], lr: 0.000100, loss: 1.3136
2022-03-07 17:23:27 - train: epoch 0093, iter [07300, 10009], lr: 0.000100, loss: 1.1147
2022-03-07 17:23:47 - train: epoch 0093, iter [07400, 10009], lr: 0.000100, loss: 1.3318
2022-03-07 17:24:07 - train: epoch 0093, iter [07500, 10009], lr: 0.000100, loss: 0.9841
2022-03-07 17:24:26 - train: epoch 0093, iter [07600, 10009], lr: 0.000100, loss: 1.2201
2022-03-07 17:24:46 - train: epoch 0093, iter [07700, 10009], lr: 0.000100, loss: 1.0808
2022-03-07 17:25:06 - train: epoch 0093, iter [07800, 10009], lr: 0.000100, loss: 1.0415
2022-03-07 17:25:25 - train: epoch 0093, iter [07900, 10009], lr: 0.000100, loss: 1.4823
2022-03-07 17:25:45 - train: epoch 0093, iter [08000, 10009], lr: 0.000100, loss: 1.3113
2022-03-07 17:26:05 - train: epoch 0093, iter [08100, 10009], lr: 0.000100, loss: 1.0474
2022-03-07 17:26:25 - train: epoch 0093, iter [08200, 10009], lr: 0.000100, loss: 1.1144
2022-03-07 17:26:44 - train: epoch 0093, iter [08300, 10009], lr: 0.000100, loss: 1.2704
2022-03-07 17:27:04 - train: epoch 0093, iter [08400, 10009], lr: 0.000100, loss: 1.0974
2022-03-07 17:27:24 - train: epoch 0093, iter [08500, 10009], lr: 0.000100, loss: 1.0623
2022-03-07 17:27:43 - train: epoch 0093, iter [08600, 10009], lr: 0.000100, loss: 1.5517
2022-03-07 17:28:03 - train: epoch 0093, iter [08700, 10009], lr: 0.000100, loss: 1.3281
2022-03-07 17:28:23 - train: epoch 0093, iter [08800, 10009], lr: 0.000100, loss: 1.3011
2022-03-07 17:28:43 - train: epoch 0093, iter [08900, 10009], lr: 0.000100, loss: 1.2636
2022-03-07 17:29:03 - train: epoch 0093, iter [09000, 10009], lr: 0.000100, loss: 0.9968
2022-03-07 17:29:22 - train: epoch 0093, iter [09100, 10009], lr: 0.000100, loss: 1.3896
2022-03-07 17:29:42 - train: epoch 0093, iter [09200, 10009], lr: 0.000100, loss: 0.9376
2022-03-07 17:30:02 - train: epoch 0093, iter [09300, 10009], lr: 0.000100, loss: 1.3046
2022-03-07 17:30:22 - train: epoch 0093, iter [09400, 10009], lr: 0.000100, loss: 1.1550
2022-03-07 17:30:41 - train: epoch 0093, iter [09500, 10009], lr: 0.000100, loss: 1.1223
2022-03-07 17:31:01 - train: epoch 0093, iter [09600, 10009], lr: 0.000100, loss: 1.1930
2022-03-07 17:31:21 - train: epoch 0093, iter [09700, 10009], lr: 0.000100, loss: 1.0753
2022-03-07 17:31:41 - train: epoch 0093, iter [09800, 10009], lr: 0.000100, loss: 1.2487
2022-03-07 17:32:00 - train: epoch 0093, iter [09900, 10009], lr: 0.000100, loss: 0.9626
2022-03-07 17:32:20 - train: epoch 0093, iter [10000, 10009], lr: 0.000100, loss: 1.2917
2022-03-07 17:32:23 - train: epoch 093, train_loss: 1.1640
2022-03-07 17:33:39 - eval: epoch: 093, acc1: 73.420%, acc5: 91.246%, test_loss: 1.0645, per_image_load_time: 1.462ms, per_image_inference_time: 0.879ms
2022-03-07 17:33:40 - until epoch: 093, best_acc1: 73.420%
2022-03-07 17:33:40 - epoch 094 lr: 0.00010000000000000003
2022-03-07 17:34:03 - train: epoch 0094, iter [00100, 10009], lr: 0.000100, loss: 1.1303
2022-03-07 17:34:22 - train: epoch 0094, iter [00200, 10009], lr: 0.000100, loss: 1.1177
2022-03-07 17:34:42 - train: epoch 0094, iter [00300, 10009], lr: 0.000100, loss: 1.3659
2022-03-07 17:35:02 - train: epoch 0094, iter [00400, 10009], lr: 0.000100, loss: 1.0355
2022-03-07 17:35:21 - train: epoch 0094, iter [00500, 10009], lr: 0.000100, loss: 1.3454
2022-03-07 17:35:41 - train: epoch 0094, iter [00600, 10009], lr: 0.000100, loss: 1.2644
2022-03-07 17:36:00 - train: epoch 0094, iter [00700, 10009], lr: 0.000100, loss: 1.0016
2022-03-07 17:36:20 - train: epoch 0094, iter [00800, 10009], lr: 0.000100, loss: 1.3981
2022-03-07 17:36:39 - train: epoch 0094, iter [00900, 10009], lr: 0.000100, loss: 1.3562
2022-03-07 17:36:59 - train: epoch 0094, iter [01000, 10009], lr: 0.000100, loss: 1.2585
2022-03-07 17:37:19 - train: epoch 0094, iter [01100, 10009], lr: 0.000100, loss: 0.9955
2022-03-07 17:37:38 - train: epoch 0094, iter [01200, 10009], lr: 0.000100, loss: 1.2995
2022-03-07 17:37:58 - train: epoch 0094, iter [01300, 10009], lr: 0.000100, loss: 1.0540
2022-03-07 17:38:18 - train: epoch 0094, iter [01400, 10009], lr: 0.000100, loss: 1.0534
2022-03-07 17:38:37 - train: epoch 0094, iter [01500, 10009], lr: 0.000100, loss: 1.2631
2022-03-07 17:38:57 - train: epoch 0094, iter [01600, 10009], lr: 0.000100, loss: 1.0311
2022-03-07 17:39:17 - train: epoch 0094, iter [01700, 10009], lr: 0.000100, loss: 1.1235
2022-03-07 17:39:36 - train: epoch 0094, iter [01800, 10009], lr: 0.000100, loss: 1.3405
2022-03-07 17:39:56 - train: epoch 0094, iter [01900, 10009], lr: 0.000100, loss: 1.1738
2022-03-07 17:40:16 - train: epoch 0094, iter [02000, 10009], lr: 0.000100, loss: 1.3320
2022-03-07 17:40:35 - train: epoch 0094, iter [02100, 10009], lr: 0.000100, loss: 1.3523
2022-03-07 17:40:55 - train: epoch 0094, iter [02200, 10009], lr: 0.000100, loss: 1.2709
2022-03-07 17:41:15 - train: epoch 0094, iter [02300, 10009], lr: 0.000100, loss: 1.3298
2022-03-07 17:41:34 - train: epoch 0094, iter [02400, 10009], lr: 0.000100, loss: 1.0544
2022-03-07 17:41:54 - train: epoch 0094, iter [02500, 10009], lr: 0.000100, loss: 1.0418
2022-03-07 17:42:14 - train: epoch 0094, iter [02600, 10009], lr: 0.000100, loss: 1.4028
2022-03-07 17:42:34 - train: epoch 0094, iter [02700, 10009], lr: 0.000100, loss: 0.9645
2022-03-07 17:42:53 - train: epoch 0094, iter [02800, 10009], lr: 0.000100, loss: 0.9067
2022-03-07 17:43:13 - train: epoch 0094, iter [02900, 10009], lr: 0.000100, loss: 1.1815
2022-03-07 17:43:33 - train: epoch 0094, iter [03000, 10009], lr: 0.000100, loss: 1.3288
2022-03-07 17:43:53 - train: epoch 0094, iter [03100, 10009], lr: 0.000100, loss: 1.2067
2022-03-07 17:44:13 - train: epoch 0094, iter [03200, 10009], lr: 0.000100, loss: 1.3871
2022-03-07 17:44:32 - train: epoch 0094, iter [03300, 10009], lr: 0.000100, loss: 1.1189
2022-03-07 17:44:52 - train: epoch 0094, iter [03400, 10009], lr: 0.000100, loss: 0.8799
2022-03-07 17:45:12 - train: epoch 0094, iter [03500, 10009], lr: 0.000100, loss: 1.1419
2022-03-07 17:45:31 - train: epoch 0094, iter [03600, 10009], lr: 0.000100, loss: 1.2953
2022-03-07 17:45:51 - train: epoch 0094, iter [03700, 10009], lr: 0.000100, loss: 1.3202
2022-03-07 17:46:11 - train: epoch 0094, iter [03800, 10009], lr: 0.000100, loss: 1.1237
2022-03-07 17:46:30 - train: epoch 0094, iter [03900, 10009], lr: 0.000100, loss: 0.9970
2022-03-07 17:46:50 - train: epoch 0094, iter [04000, 10009], lr: 0.000100, loss: 1.0609
2022-03-07 17:47:10 - train: epoch 0094, iter [04100, 10009], lr: 0.000100, loss: 1.1819
2022-03-07 17:47:30 - train: epoch 0094, iter [04200, 10009], lr: 0.000100, loss: 0.9915
2022-03-07 17:47:49 - train: epoch 0094, iter [04300, 10009], lr: 0.000100, loss: 1.0605
2022-03-07 17:48:09 - train: epoch 0094, iter [04400, 10009], lr: 0.000100, loss: 1.0747
2022-03-07 17:48:29 - train: epoch 0094, iter [04500, 10009], lr: 0.000100, loss: 1.2772
2022-03-07 17:48:49 - train: epoch 0094, iter [04600, 10009], lr: 0.000100, loss: 1.0693
2022-03-07 17:49:08 - train: epoch 0094, iter [04700, 10009], lr: 0.000100, loss: 1.1654
2022-03-07 17:49:28 - train: epoch 0094, iter [04800, 10009], lr: 0.000100, loss: 1.0847
2022-03-07 17:49:48 - train: epoch 0094, iter [04900, 10009], lr: 0.000100, loss: 1.2028
2022-03-07 17:50:08 - train: epoch 0094, iter [05000, 10009], lr: 0.000100, loss: 0.9639
2022-03-07 17:50:27 - train: epoch 0094, iter [05100, 10009], lr: 0.000100, loss: 1.0613
2022-03-07 17:50:47 - train: epoch 0094, iter [05200, 10009], lr: 0.000100, loss: 1.2403
2022-03-07 17:51:07 - train: epoch 0094, iter [05300, 10009], lr: 0.000100, loss: 1.2827
2022-03-07 17:51:27 - train: epoch 0094, iter [05400, 10009], lr: 0.000100, loss: 0.9853
2022-03-07 17:51:47 - train: epoch 0094, iter [05500, 10009], lr: 0.000100, loss: 1.0704
2022-03-07 17:52:06 - train: epoch 0094, iter [05600, 10009], lr: 0.000100, loss: 0.9072
2022-03-07 17:52:26 - train: epoch 0094, iter [05700, 10009], lr: 0.000100, loss: 0.9925
2022-03-07 17:52:46 - train: epoch 0094, iter [05800, 10009], lr: 0.000100, loss: 1.1275
2022-03-07 17:53:06 - train: epoch 0094, iter [05900, 10009], lr: 0.000100, loss: 0.9855
2022-03-07 17:53:25 - train: epoch 0094, iter [06000, 10009], lr: 0.000100, loss: 1.3250
2022-03-07 17:53:45 - train: epoch 0094, iter [06100, 10009], lr: 0.000100, loss: 0.9626
2022-03-07 17:54:05 - train: epoch 0094, iter [06200, 10009], lr: 0.000100, loss: 1.0557
2022-03-07 17:54:24 - train: epoch 0094, iter [06300, 10009], lr: 0.000100, loss: 1.0529
2022-03-07 17:54:44 - train: epoch 0094, iter [06400, 10009], lr: 0.000100, loss: 0.9415
2022-03-07 17:55:04 - train: epoch 0094, iter [06500, 10009], lr: 0.000100, loss: 1.0323
2022-03-07 17:55:23 - train: epoch 0094, iter [06600, 10009], lr: 0.000100, loss: 1.0250
2022-03-07 17:55:43 - train: epoch 0094, iter [06700, 10009], lr: 0.000100, loss: 1.1909
2022-03-07 17:56:03 - train: epoch 0094, iter [06800, 10009], lr: 0.000100, loss: 0.9794
2022-03-07 17:56:23 - train: epoch 0094, iter [06900, 10009], lr: 0.000100, loss: 1.3166
2022-03-07 17:56:42 - train: epoch 0094, iter [07000, 10009], lr: 0.000100, loss: 1.1703
2022-03-07 17:57:02 - train: epoch 0094, iter [07100, 10009], lr: 0.000100, loss: 1.1793
2022-03-07 17:57:22 - train: epoch 0094, iter [07200, 10009], lr: 0.000100, loss: 1.2208
2022-03-07 17:57:42 - train: epoch 0094, iter [07300, 10009], lr: 0.000100, loss: 1.2769
2022-03-07 17:58:02 - train: epoch 0094, iter [07400, 10009], lr: 0.000100, loss: 1.2793
2022-03-07 17:58:21 - train: epoch 0094, iter [07500, 10009], lr: 0.000100, loss: 0.9130
2022-03-07 17:58:41 - train: epoch 0094, iter [07600, 10009], lr: 0.000100, loss: 0.8421
2022-03-07 17:59:01 - train: epoch 0094, iter [07700, 10009], lr: 0.000100, loss: 0.8660
2022-03-07 17:59:21 - train: epoch 0094, iter [07800, 10009], lr: 0.000100, loss: 1.1602
2022-03-07 17:59:41 - train: epoch 0094, iter [07900, 10009], lr: 0.000100, loss: 1.1287
2022-03-07 18:00:00 - train: epoch 0094, iter [08000, 10009], lr: 0.000100, loss: 1.0142
2022-03-07 18:00:20 - train: epoch 0094, iter [08100, 10009], lr: 0.000100, loss: 1.2482
2022-03-07 18:00:40 - train: epoch 0094, iter [08200, 10009], lr: 0.000100, loss: 1.4546
2022-03-07 18:01:00 - train: epoch 0094, iter [08300, 10009], lr: 0.000100, loss: 0.9246
2022-03-07 18:01:19 - train: epoch 0094, iter [08400, 10009], lr: 0.000100, loss: 0.9381
2022-03-07 18:01:39 - train: epoch 0094, iter [08500, 10009], lr: 0.000100, loss: 1.3874
2022-03-07 18:01:59 - train: epoch 0094, iter [08600, 10009], lr: 0.000100, loss: 1.1838
2022-03-07 18:02:19 - train: epoch 0094, iter [08700, 10009], lr: 0.000100, loss: 1.2758
2022-03-07 18:02:39 - train: epoch 0094, iter [08800, 10009], lr: 0.000100, loss: 1.2173
2022-03-07 18:02:58 - train: epoch 0094, iter [08900, 10009], lr: 0.000100, loss: 1.0528
2022-03-07 18:03:18 - train: epoch 0094, iter [09000, 10009], lr: 0.000100, loss: 1.0191
2022-03-07 18:03:38 - train: epoch 0094, iter [09100, 10009], lr: 0.000100, loss: 1.2661
2022-03-07 18:03:58 - train: epoch 0094, iter [09200, 10009], lr: 0.000100, loss: 1.2316
2022-03-07 18:04:18 - train: epoch 0094, iter [09300, 10009], lr: 0.000100, loss: 1.0444
2022-03-07 18:04:38 - train: epoch 0094, iter [09400, 10009], lr: 0.000100, loss: 0.9278
2022-03-07 18:04:58 - train: epoch 0094, iter [09500, 10009], lr: 0.000100, loss: 1.1288
2022-03-07 18:05:17 - train: epoch 0094, iter [09600, 10009], lr: 0.000100, loss: 0.7934
2022-03-07 18:05:37 - train: epoch 0094, iter [09700, 10009], lr: 0.000100, loss: 1.2424
2022-03-07 18:05:57 - train: epoch 0094, iter [09800, 10009], lr: 0.000100, loss: 1.0374
2022-03-07 18:06:17 - train: epoch 0094, iter [09900, 10009], lr: 0.000100, loss: 1.0676
2022-03-07 18:06:37 - train: epoch 0094, iter [10000, 10009], lr: 0.000100, loss: 1.1024
2022-03-07 18:06:40 - train: epoch 094, train_loss: 1.1641
2022-03-07 18:07:56 - eval: epoch: 094, acc1: 73.580%, acc5: 91.236%, test_loss: 1.0643, per_image_load_time: 1.984ms, per_image_inference_time: 0.865ms
2022-03-07 18:07:57 - until epoch: 094, best_acc1: 73.580%
2022-03-07 18:07:57 - epoch 095 lr: 0.00010000000000000003
2022-03-07 18:08:20 - train: epoch 0095, iter [00100, 10009], lr: 0.000100, loss: 1.3155
2022-03-07 18:08:40 - train: epoch 0095, iter [00200, 10009], lr: 0.000100, loss: 0.9412
2022-03-07 18:08:59 - train: epoch 0095, iter [00300, 10009], lr: 0.000100, loss: 0.8513
2022-03-07 18:09:19 - train: epoch 0095, iter [00400, 10009], lr: 0.000100, loss: 1.4155
2022-03-07 18:09:39 - train: epoch 0095, iter [00500, 10009], lr: 0.000100, loss: 1.0540
2022-03-07 18:09:59 - train: epoch 0095, iter [00600, 10009], lr: 0.000100, loss: 1.2327
2022-03-07 18:10:19 - train: epoch 0095, iter [00700, 10009], lr: 0.000100, loss: 1.3515
2022-03-07 18:10:39 - train: epoch 0095, iter [00800, 10009], lr: 0.000100, loss: 1.3211
2022-03-07 18:10:59 - train: epoch 0095, iter [00900, 10009], lr: 0.000100, loss: 1.1834
2022-03-07 18:11:19 - train: epoch 0095, iter [01000, 10009], lr: 0.000100, loss: 1.2110
2022-03-07 18:11:39 - train: epoch 0095, iter [01100, 10009], lr: 0.000100, loss: 1.1170
2022-03-07 18:11:59 - train: epoch 0095, iter [01200, 10009], lr: 0.000100, loss: 1.3665
2022-03-07 18:12:19 - train: epoch 0095, iter [01300, 10009], lr: 0.000100, loss: 1.3722
2022-03-07 18:12:39 - train: epoch 0095, iter [01400, 10009], lr: 0.000100, loss: 1.0887
2022-03-07 18:12:59 - train: epoch 0095, iter [01500, 10009], lr: 0.000100, loss: 1.1756
2022-03-07 18:13:19 - train: epoch 0095, iter [01600, 10009], lr: 0.000100, loss: 1.1682
2022-03-07 18:13:39 - train: epoch 0095, iter [01700, 10009], lr: 0.000100, loss: 1.0233
2022-03-07 18:13:59 - train: epoch 0095, iter [01800, 10009], lr: 0.000100, loss: 1.4590
2022-03-07 18:14:19 - train: epoch 0095, iter [01900, 10009], lr: 0.000100, loss: 1.0580
2022-03-07 18:14:39 - train: epoch 0095, iter [02000, 10009], lr: 0.000100, loss: 1.1780
2022-03-07 18:14:59 - train: epoch 0095, iter [02100, 10009], lr: 0.000100, loss: 1.2360
2022-03-07 18:15:19 - train: epoch 0095, iter [02200, 10009], lr: 0.000100, loss: 0.9513
2022-03-07 18:15:39 - train: epoch 0095, iter [02300, 10009], lr: 0.000100, loss: 1.2834
2022-03-07 18:15:59 - train: epoch 0095, iter [02400, 10009], lr: 0.000100, loss: 0.9138
2022-03-07 18:16:19 - train: epoch 0095, iter [02500, 10009], lr: 0.000100, loss: 1.1484
2022-03-07 18:16:39 - train: epoch 0095, iter [02600, 10009], lr: 0.000100, loss: 1.4903
2022-03-07 18:16:59 - train: epoch 0095, iter [02700, 10009], lr: 0.000100, loss: 1.0554
2022-03-07 18:17:19 - train: epoch 0095, iter [02800, 10009], lr: 0.000100, loss: 1.1846
2022-03-07 18:17:39 - train: epoch 0095, iter [02900, 10009], lr: 0.000100, loss: 0.9042
2022-03-07 18:17:59 - train: epoch 0095, iter [03000, 10009], lr: 0.000100, loss: 1.0436
2022-03-07 18:18:19 - train: epoch 0095, iter [03100, 10009], lr: 0.000100, loss: 1.0469
2022-03-07 18:18:39 - train: epoch 0095, iter [03200, 10009], lr: 0.000100, loss: 0.7669
2022-03-07 18:18:59 - train: epoch 0095, iter [03300, 10009], lr: 0.000100, loss: 1.0680
2022-03-07 18:19:19 - train: epoch 0095, iter [03400, 10009], lr: 0.000100, loss: 1.1300
2022-03-07 18:19:39 - train: epoch 0095, iter [03500, 10009], lr: 0.000100, loss: 0.7836
2022-03-07 18:19:59 - train: epoch 0095, iter [03600, 10009], lr: 0.000100, loss: 1.2558
2022-03-07 18:20:19 - train: epoch 0095, iter [03700, 10009], lr: 0.000100, loss: 1.4488
2022-03-07 18:20:39 - train: epoch 0095, iter [03800, 10009], lr: 0.000100, loss: 1.2116
2022-03-07 18:20:59 - train: epoch 0095, iter [03900, 10009], lr: 0.000100, loss: 1.1078
2022-03-07 18:21:19 - train: epoch 0095, iter [04000, 10009], lr: 0.000100, loss: 1.2724
2022-03-07 18:21:38 - train: epoch 0095, iter [04100, 10009], lr: 0.000100, loss: 1.3144
2022-03-07 18:21:58 - train: epoch 0095, iter [04200, 10009], lr: 0.000100, loss: 1.0108
2022-03-07 18:22:18 - train: epoch 0095, iter [04300, 10009], lr: 0.000100, loss: 0.9446
2022-03-07 18:22:38 - train: epoch 0095, iter [04400, 10009], lr: 0.000100, loss: 0.9254
2022-03-07 18:22:58 - train: epoch 0095, iter [04500, 10009], lr: 0.000100, loss: 1.2576
2022-03-07 18:23:18 - train: epoch 0095, iter [04600, 10009], lr: 0.000100, loss: 1.1093
2022-03-07 18:23:38 - train: epoch 0095, iter [04700, 10009], lr: 0.000100, loss: 1.4145
2022-03-07 18:23:58 - train: epoch 0095, iter [04800, 10009], lr: 0.000100, loss: 0.8986
2022-03-07 18:24:18 - train: epoch 0095, iter [04900, 10009], lr: 0.000100, loss: 1.1259
2022-03-07 18:24:38 - train: epoch 0095, iter [05000, 10009], lr: 0.000100, loss: 1.0862
2022-03-07 18:24:58 - train: epoch 0095, iter [05100, 10009], lr: 0.000100, loss: 1.1915
2022-03-07 18:25:18 - train: epoch 0095, iter [05200, 10009], lr: 0.000100, loss: 1.1102
2022-03-07 18:25:37 - train: epoch 0095, iter [05300, 10009], lr: 0.000100, loss: 1.1678
2022-03-07 18:25:57 - train: epoch 0095, iter [05400, 10009], lr: 0.000100, loss: 1.0586
2022-03-07 18:26:17 - train: epoch 0095, iter [05500, 10009], lr: 0.000100, loss: 1.3609
2022-03-07 18:26:37 - train: epoch 0095, iter [05600, 10009], lr: 0.000100, loss: 0.8986
2022-03-07 18:26:57 - train: epoch 0095, iter [05700, 10009], lr: 0.000100, loss: 0.9186
2022-03-07 18:27:17 - train: epoch 0095, iter [05800, 10009], lr: 0.000100, loss: 1.2180
2022-03-07 18:27:37 - train: epoch 0095, iter [05900, 10009], lr: 0.000100, loss: 1.1818
2022-03-07 18:27:56 - train: epoch 0095, iter [06000, 10009], lr: 0.000100, loss: 1.2487
2022-03-07 18:28:16 - train: epoch 0095, iter [06100, 10009], lr: 0.000100, loss: 1.4646
2022-03-07 18:28:36 - train: epoch 0095, iter [06200, 10009], lr: 0.000100, loss: 1.1878
2022-03-07 18:28:56 - train: epoch 0095, iter [06300, 10009], lr: 0.000100, loss: 1.2225
2022-03-07 18:29:16 - train: epoch 0095, iter [06400, 10009], lr: 0.000100, loss: 1.4531
2022-03-07 18:29:36 - train: epoch 0095, iter [06500, 10009], lr: 0.000100, loss: 1.2164
2022-03-07 18:29:56 - train: epoch 0095, iter [06600, 10009], lr: 0.000100, loss: 1.1320
2022-03-07 18:30:16 - train: epoch 0095, iter [06700, 10009], lr: 0.000100, loss: 0.8510
2022-03-07 18:30:36 - train: epoch 0095, iter [06800, 10009], lr: 0.000100, loss: 1.0764
2022-03-07 18:30:56 - train: epoch 0095, iter [06900, 10009], lr: 0.000100, loss: 1.0979
2022-03-07 18:31:16 - train: epoch 0095, iter [07000, 10009], lr: 0.000100, loss: 1.0023
2022-03-07 18:31:36 - train: epoch 0095, iter [07100, 10009], lr: 0.000100, loss: 1.3741
2022-03-07 18:31:55 - train: epoch 0095, iter [07200, 10009], lr: 0.000100, loss: 1.0550
2022-03-07 18:32:15 - train: epoch 0095, iter [07300, 10009], lr: 0.000100, loss: 1.1157
2022-03-07 18:32:35 - train: epoch 0095, iter [07400, 10009], lr: 0.000100, loss: 0.9947
2022-03-07 18:32:55 - train: epoch 0095, iter [07500, 10009], lr: 0.000100, loss: 1.2709
2022-03-07 18:33:15 - train: epoch 0095, iter [07600, 10009], lr: 0.000100, loss: 0.9349
2022-03-07 18:33:35 - train: epoch 0095, iter [07700, 10009], lr: 0.000100, loss: 1.1509
2022-03-07 18:33:55 - train: epoch 0095, iter [07800, 10009], lr: 0.000100, loss: 1.3885
2022-03-07 18:34:15 - train: epoch 0095, iter [07900, 10009], lr: 0.000100, loss: 1.2926
2022-03-07 18:34:35 - train: epoch 0095, iter [08000, 10009], lr: 0.000100, loss: 0.9468
2022-03-07 18:34:55 - train: epoch 0095, iter [08100, 10009], lr: 0.000100, loss: 1.2801
2022-03-07 18:35:15 - train: epoch 0095, iter [08200, 10009], lr: 0.000100, loss: 1.0723
2022-03-07 18:35:35 - train: epoch 0095, iter [08300, 10009], lr: 0.000100, loss: 1.1753
2022-03-07 18:35:55 - train: epoch 0095, iter [08400, 10009], lr: 0.000100, loss: 1.2214
2022-03-07 18:36:15 - train: epoch 0095, iter [08500, 10009], lr: 0.000100, loss: 1.3041
2022-03-07 18:36:35 - train: epoch 0095, iter [08600, 10009], lr: 0.000100, loss: 1.3851
2022-03-07 18:36:55 - train: epoch 0095, iter [08700, 10009], lr: 0.000100, loss: 1.2634
2022-03-07 18:37:15 - train: epoch 0095, iter [08800, 10009], lr: 0.000100, loss: 1.1297
2022-03-07 18:37:35 - train: epoch 0095, iter [08900, 10009], lr: 0.000100, loss: 1.3727
2022-03-07 18:37:55 - train: epoch 0095, iter [09000, 10009], lr: 0.000100, loss: 0.9894
2022-03-07 18:38:14 - train: epoch 0095, iter [09100, 10009], lr: 0.000100, loss: 1.1665
2022-03-07 18:38:35 - train: epoch 0095, iter [09200, 10009], lr: 0.000100, loss: 1.1922
2022-03-07 18:38:55 - train: epoch 0095, iter [09300, 10009], lr: 0.000100, loss: 1.1002
2022-03-07 18:39:15 - train: epoch 0095, iter [09400, 10009], lr: 0.000100, loss: 1.0543
2022-03-07 18:39:36 - train: epoch 0095, iter [09500, 10009], lr: 0.000100, loss: 1.0740
2022-03-07 18:39:56 - train: epoch 0095, iter [09600, 10009], lr: 0.000100, loss: 0.9769
2022-03-07 18:40:16 - train: epoch 0095, iter [09700, 10009], lr: 0.000100, loss: 1.2337
2022-03-07 18:40:36 - train: epoch 0095, iter [09800, 10009], lr: 0.000100, loss: 0.8977
2022-03-07 18:40:57 - train: epoch 0095, iter [09900, 10009], lr: 0.000100, loss: 1.3669
2022-03-07 18:41:17 - train: epoch 0095, iter [10000, 10009], lr: 0.000100, loss: 1.1636
2022-03-07 18:41:20 - train: epoch 095, train_loss: 1.1595
2022-03-07 18:42:34 - eval: epoch: 095, acc1: 73.412%, acc5: 91.222%, test_loss: 1.0614, per_image_load_time: 1.826ms, per_image_inference_time: 0.801ms
2022-03-07 18:42:35 - until epoch: 095, best_acc1: 73.580%
2022-03-07 18:42:35 - epoch 096 lr: 0.00010000000000000003
2022-03-07 18:42:59 - train: epoch 0096, iter [00100, 10009], lr: 0.000100, loss: 1.0859
2022-03-07 18:43:19 - train: epoch 0096, iter [00200, 10009], lr: 0.000100, loss: 1.3210
2022-03-07 18:43:39 - train: epoch 0096, iter [00300, 10009], lr: 0.000100, loss: 1.1861
2022-03-07 18:43:59 - train: epoch 0096, iter [00400, 10009], lr: 0.000100, loss: 1.2185
2022-03-07 18:44:19 - train: epoch 0096, iter [00500, 10009], lr: 0.000100, loss: 0.9342
2022-03-07 18:44:39 - train: epoch 0096, iter [00600, 10009], lr: 0.000100, loss: 1.1138
2022-03-07 18:44:59 - train: epoch 0096, iter [00700, 10009], lr: 0.000100, loss: 0.9366
2022-03-07 18:45:19 - train: epoch 0096, iter [00800, 10009], lr: 0.000100, loss: 0.9799
2022-03-07 18:45:39 - train: epoch 0096, iter [00900, 10009], lr: 0.000100, loss: 1.5115
2022-03-07 18:45:59 - train: epoch 0096, iter [01000, 10009], lr: 0.000100, loss: 1.2931
2022-03-07 18:46:19 - train: epoch 0096, iter [01100, 10009], lr: 0.000100, loss: 1.0416
2022-03-07 18:46:39 - train: epoch 0096, iter [01200, 10009], lr: 0.000100, loss: 1.2478
2022-03-07 18:46:59 - train: epoch 0096, iter [01300, 10009], lr: 0.000100, loss: 1.1826
2022-03-07 18:47:19 - train: epoch 0096, iter [01400, 10009], lr: 0.000100, loss: 1.1250
2022-03-07 18:47:39 - train: epoch 0096, iter [01500, 10009], lr: 0.000100, loss: 1.1801
2022-03-07 18:48:00 - train: epoch 0096, iter [01600, 10009], lr: 0.000100, loss: 1.0289
2022-03-07 18:48:19 - train: epoch 0096, iter [01700, 10009], lr: 0.000100, loss: 1.3372
2022-03-07 18:48:40 - train: epoch 0096, iter [01800, 10009], lr: 0.000100, loss: 1.0484
2022-03-07 18:49:00 - train: epoch 0096, iter [01900, 10009], lr: 0.000100, loss: 1.0811
2022-03-07 18:49:20 - train: epoch 0096, iter [02000, 10009], lr: 0.000100, loss: 0.8660
2022-03-07 18:49:40 - train: epoch 0096, iter [02100, 10009], lr: 0.000100, loss: 1.1045
2022-03-07 18:50:00 - train: epoch 0096, iter [02200, 10009], lr: 0.000100, loss: 1.1474
2022-03-07 18:50:20 - train: epoch 0096, iter [02300, 10009], lr: 0.000100, loss: 1.1159
2022-03-07 18:50:40 - train: epoch 0096, iter [02400, 10009], lr: 0.000100, loss: 1.0036
2022-03-07 18:51:00 - train: epoch 0096, iter [02500, 10009], lr: 0.000100, loss: 1.1290
2022-03-07 18:51:20 - train: epoch 0096, iter [02600, 10009], lr: 0.000100, loss: 1.1033
2022-03-07 18:51:40 - train: epoch 0096, iter [02700, 10009], lr: 0.000100, loss: 1.3196
2022-03-07 18:52:00 - train: epoch 0096, iter [02800, 10009], lr: 0.000100, loss: 1.2327
2022-03-07 18:52:20 - train: epoch 0096, iter [02900, 10009], lr: 0.000100, loss: 1.1239
2022-03-07 18:52:40 - train: epoch 0096, iter [03000, 10009], lr: 0.000100, loss: 1.1150
2022-03-07 18:53:00 - train: epoch 0096, iter [03100, 10009], lr: 0.000100, loss: 1.4243
2022-03-07 18:53:20 - train: epoch 0096, iter [03200, 10009], lr: 0.000100, loss: 0.9019
2022-03-07 18:53:40 - train: epoch 0096, iter [03300, 10009], lr: 0.000100, loss: 0.9531
2022-03-07 18:54:00 - train: epoch 0096, iter [03400, 10009], lr: 0.000100, loss: 1.1060
2022-03-07 18:54:20 - train: epoch 0096, iter [03500, 10009], lr: 0.000100, loss: 1.1535
2022-03-07 18:54:40 - train: epoch 0096, iter [03600, 10009], lr: 0.000100, loss: 1.0659
2022-03-07 18:55:00 - train: epoch 0096, iter [03700, 10009], lr: 0.000100, loss: 1.1957
2022-03-07 18:55:20 - train: epoch 0096, iter [03800, 10009], lr: 0.000100, loss: 1.1860
2022-03-07 18:55:40 - train: epoch 0096, iter [03900, 10009], lr: 0.000100, loss: 1.1747
2022-03-07 18:56:00 - train: epoch 0096, iter [04000, 10009], lr: 0.000100, loss: 1.0893
2022-03-07 18:56:20 - train: epoch 0096, iter [04100, 10009], lr: 0.000100, loss: 1.3956
2022-03-07 18:56:40 - train: epoch 0096, iter [04200, 10009], lr: 0.000100, loss: 1.1538
2022-03-07 18:57:00 - train: epoch 0096, iter [04300, 10009], lr: 0.000100, loss: 0.9968
2022-03-07 18:57:20 - train: epoch 0096, iter [04400, 10009], lr: 0.000100, loss: 0.7884
2022-03-07 18:57:40 - train: epoch 0096, iter [04500, 10009], lr: 0.000100, loss: 1.0462
2022-03-07 18:58:00 - train: epoch 0096, iter [04600, 10009], lr: 0.000100, loss: 0.9654
2022-03-07 18:58:20 - train: epoch 0096, iter [04700, 10009], lr: 0.000100, loss: 1.2473
2022-03-07 18:58:39 - train: epoch 0096, iter [04800, 10009], lr: 0.000100, loss: 1.3238
2022-03-07 18:58:59 - train: epoch 0096, iter [04900, 10009], lr: 0.000100, loss: 1.2685
2022-03-07 18:59:19 - train: epoch 0096, iter [05000, 10009], lr: 0.000100, loss: 1.1833
2022-03-07 18:59:39 - train: epoch 0096, iter [05100, 10009], lr: 0.000100, loss: 0.8642
2022-03-07 18:59:59 - train: epoch 0096, iter [05200, 10009], lr: 0.000100, loss: 1.3691
2022-03-07 19:00:19 - train: epoch 0096, iter [05300, 10009], lr: 0.000100, loss: 0.9607
2022-03-07 19:00:39 - train: epoch 0096, iter [05400, 10009], lr: 0.000100, loss: 1.4328
2022-03-07 19:00:59 - train: epoch 0096, iter [05500, 10009], lr: 0.000100, loss: 1.0034
2022-03-07 19:01:19 - train: epoch 0096, iter [05600, 10009], lr: 0.000100, loss: 1.2072
2022-03-07 19:01:39 - train: epoch 0096, iter [05700, 10009], lr: 0.000100, loss: 1.2751
2022-03-07 19:01:59 - train: epoch 0096, iter [05800, 10009], lr: 0.000100, loss: 1.2229
2022-03-07 19:02:19 - train: epoch 0096, iter [05900, 10009], lr: 0.000100, loss: 1.3058
2022-03-07 19:02:39 - train: epoch 0096, iter [06000, 10009], lr: 0.000100, loss: 1.0620
2022-03-07 19:02:58 - train: epoch 0096, iter [06100, 10009], lr: 0.000100, loss: 1.2444
2022-03-07 19:03:18 - train: epoch 0096, iter [06200, 10009], lr: 0.000100, loss: 1.4242
2022-03-07 19:03:38 - train: epoch 0096, iter [06300, 10009], lr: 0.000100, loss: 1.1113
2022-03-07 19:03:58 - train: epoch 0096, iter [06400, 10009], lr: 0.000100, loss: 1.2444
2022-03-07 19:04:18 - train: epoch 0096, iter [06500, 10009], lr: 0.000100, loss: 1.1631
2022-03-07 19:04:38 - train: epoch 0096, iter [06600, 10009], lr: 0.000100, loss: 1.5200
2022-03-07 19:04:58 - train: epoch 0096, iter [06700, 10009], lr: 0.000100, loss: 1.0157
2022-03-07 19:05:18 - train: epoch 0096, iter [06800, 10009], lr: 0.000100, loss: 1.1484
2022-03-07 19:05:38 - train: epoch 0096, iter [06900, 10009], lr: 0.000100, loss: 1.3235
2022-03-07 19:05:58 - train: epoch 0096, iter [07000, 10009], lr: 0.000100, loss: 0.9633
2022-03-07 19:06:18 - train: epoch 0096, iter [07100, 10009], lr: 0.000100, loss: 1.0091
2022-03-07 19:06:38 - train: epoch 0096, iter [07200, 10009], lr: 0.000100, loss: 0.8496
2022-03-07 19:06:57 - train: epoch 0096, iter [07300, 10009], lr: 0.000100, loss: 1.4465
2022-03-07 19:07:17 - train: epoch 0096, iter [07400, 10009], lr: 0.000100, loss: 1.1864
2022-03-07 19:07:37 - train: epoch 0096, iter [07500, 10009], lr: 0.000100, loss: 1.3386
2022-03-07 19:07:57 - train: epoch 0096, iter [07600, 10009], lr: 0.000100, loss: 1.1604
2022-03-07 19:08:17 - train: epoch 0096, iter [07700, 10009], lr: 0.000100, loss: 1.0616
2022-03-07 19:08:37 - train: epoch 0096, iter [07800, 10009], lr: 0.000100, loss: 1.1004
2022-03-07 19:08:57 - train: epoch 0096, iter [07900, 10009], lr: 0.000100, loss: 1.2120
2022-03-07 19:09:16 - train: epoch 0096, iter [08000, 10009], lr: 0.000100, loss: 1.0796
2022-03-07 19:09:36 - train: epoch 0096, iter [08100, 10009], lr: 0.000100, loss: 1.3310
2022-03-07 19:09:56 - train: epoch 0096, iter [08200, 10009], lr: 0.000100, loss: 1.2801
2022-03-07 19:10:16 - train: epoch 0096, iter [08300, 10009], lr: 0.000100, loss: 1.1381
2022-03-07 19:10:36 - train: epoch 0096, iter [08400, 10009], lr: 0.000100, loss: 1.1839
2022-03-07 19:10:56 - train: epoch 0096, iter [08500, 10009], lr: 0.000100, loss: 0.9067
2022-03-07 19:11:16 - train: epoch 0096, iter [08600, 10009], lr: 0.000100, loss: 1.0380
2022-03-07 19:11:36 - train: epoch 0096, iter [08700, 10009], lr: 0.000100, loss: 1.2362
2022-03-07 19:11:56 - train: epoch 0096, iter [08800, 10009], lr: 0.000100, loss: 1.1910
2022-03-07 19:12:15 - train: epoch 0096, iter [08900, 10009], lr: 0.000100, loss: 1.0772
2022-03-07 19:12:35 - train: epoch 0096, iter [09000, 10009], lr: 0.000100, loss: 1.3678
2022-03-07 19:12:55 - train: epoch 0096, iter [09100, 10009], lr: 0.000100, loss: 1.2036
2022-03-07 19:13:15 - train: epoch 0096, iter [09200, 10009], lr: 0.000100, loss: 0.9399
2022-03-07 19:13:35 - train: epoch 0096, iter [09300, 10009], lr: 0.000100, loss: 0.9642
2022-03-07 19:13:55 - train: epoch 0096, iter [09400, 10009], lr: 0.000100, loss: 1.4780
2022-03-07 19:14:15 - train: epoch 0096, iter [09500, 10009], lr: 0.000100, loss: 1.0720
2022-03-07 19:14:35 - train: epoch 0096, iter [09600, 10009], lr: 0.000100, loss: 1.2010
2022-03-07 19:14:55 - train: epoch 0096, iter [09700, 10009], lr: 0.000100, loss: 1.2871
2022-03-07 19:15:15 - train: epoch 0096, iter [09800, 10009], lr: 0.000100, loss: 1.0702
2022-03-07 19:15:35 - train: epoch 0096, iter [09900, 10009], lr: 0.000100, loss: 1.2832
2022-03-07 19:15:55 - train: epoch 0096, iter [10000, 10009], lr: 0.000100, loss: 1.0445
2022-03-07 19:15:58 - train: epoch 096, train_loss: 1.1549
2022-03-07 19:17:13 - eval: epoch: 096, acc1: 73.478%, acc5: 91.258%, test_loss: 1.0611, per_image_load_time: 1.988ms, per_image_inference_time: 0.845ms
2022-03-07 19:17:14 - until epoch: 096, best_acc1: 73.580%
2022-03-07 19:17:14 - epoch 097 lr: 0.00010000000000000003
2022-03-07 19:17:38 - train: epoch 0097, iter [00100, 10009], lr: 0.000100, loss: 1.0119
2022-03-07 19:17:57 - train: epoch 0097, iter [00200, 10009], lr: 0.000100, loss: 1.2740
2022-03-07 19:18:17 - train: epoch 0097, iter [00300, 10009], lr: 0.000100, loss: 1.4502
2022-03-07 19:18:37 - train: epoch 0097, iter [00400, 10009], lr: 0.000100, loss: 1.1007
2022-03-07 19:18:57 - train: epoch 0097, iter [00500, 10009], lr: 0.000100, loss: 1.0266
2022-03-07 19:19:17 - train: epoch 0097, iter [00600, 10009], lr: 0.000100, loss: 1.0515
2022-03-07 19:19:37 - train: epoch 0097, iter [00700, 10009], lr: 0.000100, loss: 1.1192
2022-03-07 19:19:57 - train: epoch 0097, iter [00800, 10009], lr: 0.000100, loss: 1.1840
2022-03-07 19:20:17 - train: epoch 0097, iter [00900, 10009], lr: 0.000100, loss: 1.2459
2022-03-07 19:20:37 - train: epoch 0097, iter [01000, 10009], lr: 0.000100, loss: 1.0749
2022-03-07 19:20:57 - train: epoch 0097, iter [01100, 10009], lr: 0.000100, loss: 0.9104
2022-03-07 19:21:17 - train: epoch 0097, iter [01200, 10009], lr: 0.000100, loss: 1.1849
2022-03-07 19:21:36 - train: epoch 0097, iter [01300, 10009], lr: 0.000100, loss: 1.1553
2022-03-07 19:21:56 - train: epoch 0097, iter [01400, 10009], lr: 0.000100, loss: 0.9724
2022-03-07 19:22:16 - train: epoch 0097, iter [01500, 10009], lr: 0.000100, loss: 1.4183
2022-03-07 19:22:36 - train: epoch 0097, iter [01600, 10009], lr: 0.000100, loss: 1.0995
2022-03-07 19:22:56 - train: epoch 0097, iter [01700, 10009], lr: 0.000100, loss: 1.2567
2022-03-07 19:23:16 - train: epoch 0097, iter [01800, 10009], lr: 0.000100, loss: 1.5087
2022-03-07 19:23:36 - train: epoch 0097, iter [01900, 10009], lr: 0.000100, loss: 0.9836
2022-03-07 19:23:56 - train: epoch 0097, iter [02000, 10009], lr: 0.000100, loss: 1.2668
2022-03-07 19:24:15 - train: epoch 0097, iter [02100, 10009], lr: 0.000100, loss: 1.3140
2022-03-07 19:24:35 - train: epoch 0097, iter [02200, 10009], lr: 0.000100, loss: 1.0036
2022-03-07 19:24:55 - train: epoch 0097, iter [02300, 10009], lr: 0.000100, loss: 0.9537
2022-03-07 19:25:15 - train: epoch 0097, iter [02400, 10009], lr: 0.000100, loss: 1.2883
2022-03-07 19:25:35 - train: epoch 0097, iter [02500, 10009], lr: 0.000100, loss: 0.9630
2022-03-07 19:25:54 - train: epoch 0097, iter [02600, 10009], lr: 0.000100, loss: 1.0680
2022-03-07 19:26:14 - train: epoch 0097, iter [02700, 10009], lr: 0.000100, loss: 1.1081
2022-03-07 19:26:34 - train: epoch 0097, iter [02800, 10009], lr: 0.000100, loss: 1.1904
2022-03-07 19:26:54 - train: epoch 0097, iter [02900, 10009], lr: 0.000100, loss: 1.1622
2022-03-07 19:27:14 - train: epoch 0097, iter [03000, 10009], lr: 0.000100, loss: 0.9379
2022-03-07 19:27:34 - train: epoch 0097, iter [03100, 10009], lr: 0.000100, loss: 1.1222
2022-03-07 19:27:54 - train: epoch 0097, iter [03200, 10009], lr: 0.000100, loss: 1.0111
2022-03-07 19:28:14 - train: epoch 0097, iter [03300, 10009], lr: 0.000100, loss: 1.1460
2022-03-07 19:28:33 - train: epoch 0097, iter [03400, 10009], lr: 0.000100, loss: 0.9825
2022-03-07 19:28:53 - train: epoch 0097, iter [03500, 10009], lr: 0.000100, loss: 1.2218
2022-03-07 19:29:13 - train: epoch 0097, iter [03600, 10009], lr: 0.000100, loss: 1.4330
2022-03-07 19:29:33 - train: epoch 0097, iter [03700, 10009], lr: 0.000100, loss: 1.1999
2022-03-07 19:29:53 - train: epoch 0097, iter [03800, 10009], lr: 0.000100, loss: 1.2516
2022-03-07 19:30:13 - train: epoch 0097, iter [03900, 10009], lr: 0.000100, loss: 1.0722
2022-03-07 19:30:33 - train: epoch 0097, iter [04000, 10009], lr: 0.000100, loss: 0.9167
2022-03-07 19:30:53 - train: epoch 0097, iter [04100, 10009], lr: 0.000100, loss: 1.2853
2022-03-07 19:31:13 - train: epoch 0097, iter [04200, 10009], lr: 0.000100, loss: 1.0349
2022-03-07 19:31:33 - train: epoch 0097, iter [04300, 10009], lr: 0.000100, loss: 1.0733
2022-03-07 19:31:53 - train: epoch 0097, iter [04400, 10009], lr: 0.000100, loss: 0.9945
2022-03-07 19:32:13 - train: epoch 0097, iter [04500, 10009], lr: 0.000100, loss: 1.1997
2022-03-07 19:32:33 - train: epoch 0097, iter [04600, 10009], lr: 0.000100, loss: 1.0689
2022-03-07 19:32:53 - train: epoch 0097, iter [04700, 10009], lr: 0.000100, loss: 1.1060
2022-03-07 19:33:12 - train: epoch 0097, iter [04800, 10009], lr: 0.000100, loss: 1.0248
2022-03-07 19:33:32 - train: epoch 0097, iter [04900, 10009], lr: 0.000100, loss: 1.0853
2022-03-07 19:33:52 - train: epoch 0097, iter [05000, 10009], lr: 0.000100, loss: 0.9737
2022-03-07 19:34:12 - train: epoch 0097, iter [05100, 10009], lr: 0.000100, loss: 1.2214
2022-03-07 19:34:32 - train: epoch 0097, iter [05200, 10009], lr: 0.000100, loss: 1.3530
2022-03-07 19:34:52 - train: epoch 0097, iter [05300, 10009], lr: 0.000100, loss: 1.0976
2022-03-07 19:35:12 - train: epoch 0097, iter [05400, 10009], lr: 0.000100, loss: 1.1056
2022-03-07 19:35:32 - train: epoch 0097, iter [05500, 10009], lr: 0.000100, loss: 0.9883
2022-03-07 19:35:52 - train: epoch 0097, iter [05600, 10009], lr: 0.000100, loss: 1.0606
2022-03-07 19:36:12 - train: epoch 0097, iter [05700, 10009], lr: 0.000100, loss: 1.3250
2022-03-07 19:36:32 - train: epoch 0097, iter [05800, 10009], lr: 0.000100, loss: 1.1013
2022-03-07 19:36:52 - train: epoch 0097, iter [05900, 10009], lr: 0.000100, loss: 1.0746
2022-03-07 19:37:13 - train: epoch 0097, iter [06000, 10009], lr: 0.000100, loss: 1.0746
2022-03-07 19:37:32 - train: epoch 0097, iter [06100, 10009], lr: 0.000100, loss: 1.0587
2022-03-07 19:37:52 - train: epoch 0097, iter [06200, 10009], lr: 0.000100, loss: 0.9550
2022-03-07 19:38:12 - train: epoch 0097, iter [06300, 10009], lr: 0.000100, loss: 1.2702
2022-03-07 19:38:32 - train: epoch 0097, iter [06400, 10009], lr: 0.000100, loss: 1.2267
2022-03-07 19:38:52 - train: epoch 0097, iter [06500, 10009], lr: 0.000100, loss: 1.1722
2022-03-07 19:39:12 - train: epoch 0097, iter [06600, 10009], lr: 0.000100, loss: 1.4401
2022-03-07 19:39:32 - train: epoch 0097, iter [06700, 10009], lr: 0.000100, loss: 1.1056
2022-03-07 19:39:52 - train: epoch 0097, iter [06800, 10009], lr: 0.000100, loss: 1.2120
2022-03-07 19:40:12 - train: epoch 0097, iter [06900, 10009], lr: 0.000100, loss: 1.1144
2022-03-07 19:40:32 - train: epoch 0097, iter [07000, 10009], lr: 0.000100, loss: 0.9118
2022-03-07 19:40:52 - train: epoch 0097, iter [07100, 10009], lr: 0.000100, loss: 0.8211
2022-03-07 19:41:12 - train: epoch 0097, iter [07200, 10009], lr: 0.000100, loss: 1.0709
2022-03-07 19:41:32 - train: epoch 0097, iter [07300, 10009], lr: 0.000100, loss: 1.0528
2022-03-07 19:41:52 - train: epoch 0097, iter [07400, 10009], lr: 0.000100, loss: 1.1952
2022-03-07 19:42:12 - train: epoch 0097, iter [07500, 10009], lr: 0.000100, loss: 1.2851
2022-03-07 19:42:32 - train: epoch 0097, iter [07600, 10009], lr: 0.000100, loss: 1.0228
2022-03-07 19:42:52 - train: epoch 0097, iter [07700, 10009], lr: 0.000100, loss: 1.1178
2022-03-07 19:43:12 - train: epoch 0097, iter [07800, 10009], lr: 0.000100, loss: 1.1452
2022-03-07 19:43:32 - train: epoch 0097, iter [07900, 10009], lr: 0.000100, loss: 1.2237
2022-03-07 19:43:52 - train: epoch 0097, iter [08000, 10009], lr: 0.000100, loss: 1.0648
2022-03-07 19:44:12 - train: epoch 0097, iter [08100, 10009], lr: 0.000100, loss: 1.1415
2022-03-07 19:44:32 - train: epoch 0097, iter [08200, 10009], lr: 0.000100, loss: 1.1681
2022-03-07 19:44:52 - train: epoch 0097, iter [08300, 10009], lr: 0.000100, loss: 1.1122
2022-03-07 19:45:12 - train: epoch 0097, iter [08400, 10009], lr: 0.000100, loss: 1.0913
2022-03-07 19:45:32 - train: epoch 0097, iter [08500, 10009], lr: 0.000100, loss: 0.9381
2022-03-07 19:45:52 - train: epoch 0097, iter [08600, 10009], lr: 0.000100, loss: 1.1920
2022-03-07 19:46:12 - train: epoch 0097, iter [08700, 10009], lr: 0.000100, loss: 1.1853
2022-03-07 19:46:32 - train: epoch 0097, iter [08800, 10009], lr: 0.000100, loss: 1.2543
2022-03-07 19:46:52 - train: epoch 0097, iter [08900, 10009], lr: 0.000100, loss: 0.9041
2022-03-07 19:47:12 - train: epoch 0097, iter [09000, 10009], lr: 0.000100, loss: 1.3080
2022-03-07 19:47:32 - train: epoch 0097, iter [09100, 10009], lr: 0.000100, loss: 1.3602
2022-03-07 19:47:52 - train: epoch 0097, iter [09200, 10009], lr: 0.000100, loss: 1.1139
2022-03-07 19:48:12 - train: epoch 0097, iter [09300, 10009], lr: 0.000100, loss: 1.0771
2022-03-07 19:48:32 - train: epoch 0097, iter [09400, 10009], lr: 0.000100, loss: 1.1342
2022-03-07 19:48:52 - train: epoch 0097, iter [09500, 10009], lr: 0.000100, loss: 1.2397
2022-03-07 19:49:12 - train: epoch 0097, iter [09600, 10009], lr: 0.000100, loss: 1.3539
2022-03-07 19:49:32 - train: epoch 0097, iter [09700, 10009], lr: 0.000100, loss: 0.9950
2022-03-07 19:49:52 - train: epoch 0097, iter [09800, 10009], lr: 0.000100, loss: 1.2373
2022-03-07 19:50:12 - train: epoch 0097, iter [09900, 10009], lr: 0.000100, loss: 1.0252
2022-03-07 19:50:32 - train: epoch 0097, iter [10000, 10009], lr: 0.000100, loss: 1.0866
2022-03-07 19:50:35 - train: epoch 097, train_loss: 1.1561
2022-03-07 19:51:50 - eval: epoch: 097, acc1: 73.536%, acc5: 91.188%, test_loss: 1.0602, per_image_load_time: 1.216ms, per_image_inference_time: 0.936ms
2022-03-07 19:51:50 - until epoch: 097, best_acc1: 73.580%
2022-03-07 19:51:50 - epoch 098 lr: 0.00010000000000000003
2022-03-07 19:52:14 - train: epoch 0098, iter [00100, 10009], lr: 0.000100, loss: 0.9636
2022-03-07 19:52:34 - train: epoch 0098, iter [00200, 10009], lr: 0.000100, loss: 1.2816
2022-03-07 19:52:54 - train: epoch 0098, iter [00300, 10009], lr: 0.000100, loss: 1.1392
2022-03-07 19:53:13 - train: epoch 0098, iter [00400, 10009], lr: 0.000100, loss: 1.3071
2022-03-07 19:53:33 - train: epoch 0098, iter [00500, 10009], lr: 0.000100, loss: 1.0056
2022-03-07 19:53:53 - train: epoch 0098, iter [00600, 10009], lr: 0.000100, loss: 1.1624
2022-03-07 19:54:13 - train: epoch 0098, iter [00700, 10009], lr: 0.000100, loss: 1.3400
2022-03-07 19:54:32 - train: epoch 0098, iter [00800, 10009], lr: 0.000100, loss: 0.9819
2022-03-07 19:54:52 - train: epoch 0098, iter [00900, 10009], lr: 0.000100, loss: 0.8622
2022-03-07 19:55:12 - train: epoch 0098, iter [01000, 10009], lr: 0.000100, loss: 1.2174
2022-03-07 19:55:32 - train: epoch 0098, iter [01100, 10009], lr: 0.000100, loss: 1.0611
2022-03-07 19:55:52 - train: epoch 0098, iter [01200, 10009], lr: 0.000100, loss: 1.1007
2022-03-07 19:56:11 - train: epoch 0098, iter [01300, 10009], lr: 0.000100, loss: 1.0732
2022-03-07 19:56:31 - train: epoch 0098, iter [01400, 10009], lr: 0.000100, loss: 1.2670
2022-03-07 19:56:51 - train: epoch 0098, iter [01500, 10009], lr: 0.000100, loss: 1.2529
2022-03-07 19:57:11 - train: epoch 0098, iter [01600, 10009], lr: 0.000100, loss: 1.1871
2022-03-07 19:57:31 - train: epoch 0098, iter [01700, 10009], lr: 0.000100, loss: 1.0880
2022-03-07 19:57:50 - train: epoch 0098, iter [01800, 10009], lr: 0.000100, loss: 1.0589
2022-03-07 19:58:10 - train: epoch 0098, iter [01900, 10009], lr: 0.000100, loss: 0.9726
2022-03-07 19:58:30 - train: epoch 0098, iter [02000, 10009], lr: 0.000100, loss: 0.8374
2022-03-07 19:58:50 - train: epoch 0098, iter [02100, 10009], lr: 0.000100, loss: 1.1919
2022-03-07 19:59:10 - train: epoch 0098, iter [02200, 10009], lr: 0.000100, loss: 1.2077
2022-03-07 19:59:29 - train: epoch 0098, iter [02300, 10009], lr: 0.000100, loss: 1.1254
2022-03-07 19:59:49 - train: epoch 0098, iter [02400, 10009], lr: 0.000100, loss: 1.2086
2022-03-07 20:00:09 - train: epoch 0098, iter [02500, 10009], lr: 0.000100, loss: 1.0845
2022-03-07 20:00:29 - train: epoch 0098, iter [02600, 10009], lr: 0.000100, loss: 1.1978
2022-03-07 20:00:49 - train: epoch 0098, iter [02700, 10009], lr: 0.000100, loss: 1.2278
2022-03-07 20:01:09 - train: epoch 0098, iter [02800, 10009], lr: 0.000100, loss: 1.0695
2022-03-07 20:01:28 - train: epoch 0098, iter [02900, 10009], lr: 0.000100, loss: 0.9456
2022-03-07 20:01:48 - train: epoch 0098, iter [03000, 10009], lr: 0.000100, loss: 1.1787
2022-03-07 20:02:08 - train: epoch 0098, iter [03100, 10009], lr: 0.000100, loss: 1.0578
2022-03-07 20:02:28 - train: epoch 0098, iter [03200, 10009], lr: 0.000100, loss: 1.2450
2022-03-07 20:02:48 - train: epoch 0098, iter [03300, 10009], lr: 0.000100, loss: 1.0842
2022-03-07 20:03:08 - train: epoch 0098, iter [03400, 10009], lr: 0.000100, loss: 1.0939
2022-03-07 20:03:28 - train: epoch 0098, iter [03500, 10009], lr: 0.000100, loss: 1.3134
2022-03-07 20:03:48 - train: epoch 0098, iter [03600, 10009], lr: 0.000100, loss: 1.0325
2022-03-07 20:04:08 - train: epoch 0098, iter [03700, 10009], lr: 0.000100, loss: 1.1480
2022-03-07 20:04:28 - train: epoch 0098, iter [03800, 10009], lr: 0.000100, loss: 0.9262
2022-03-07 20:04:47 - train: epoch 0098, iter [03900, 10009], lr: 0.000100, loss: 1.2003
2022-03-07 20:05:07 - train: epoch 0098, iter [04000, 10009], lr: 0.000100, loss: 1.2674
2022-03-07 20:05:27 - train: epoch 0098, iter [04100, 10009], lr: 0.000100, loss: 1.0966
2022-03-07 20:05:47 - train: epoch 0098, iter [04200, 10009], lr: 0.000100, loss: 1.3823
2022-03-07 20:06:07 - train: epoch 0098, iter [04300, 10009], lr: 0.000100, loss: 1.1404
2022-03-07 20:06:27 - train: epoch 0098, iter [04400, 10009], lr: 0.000100, loss: 1.0319
2022-03-07 20:06:47 - train: epoch 0098, iter [04500, 10009], lr: 0.000100, loss: 1.1186
2022-03-07 20:07:07 - train: epoch 0098, iter [04600, 10009], lr: 0.000100, loss: 1.2644
2022-03-07 20:07:27 - train: epoch 0098, iter [04700, 10009], lr: 0.000100, loss: 1.3091
2022-03-07 20:07:47 - train: epoch 0098, iter [04800, 10009], lr: 0.000100, loss: 1.1950
2022-03-07 20:08:07 - train: epoch 0098, iter [04900, 10009], lr: 0.000100, loss: 1.2526
2022-03-07 20:08:27 - train: epoch 0098, iter [05000, 10009], lr: 0.000100, loss: 1.2469
2022-03-07 20:08:47 - train: epoch 0098, iter [05100, 10009], lr: 0.000100, loss: 1.0799
2022-03-07 20:09:06 - train: epoch 0098, iter [05200, 10009], lr: 0.000100, loss: 1.1222
2022-03-07 20:09:26 - train: epoch 0098, iter [05300, 10009], lr: 0.000100, loss: 1.2608
2022-03-07 20:09:46 - train: epoch 0098, iter [05400, 10009], lr: 0.000100, loss: 1.1897
2022-03-07 20:10:06 - train: epoch 0098, iter [05500, 10009], lr: 0.000100, loss: 1.2168
2022-03-07 20:10:26 - train: epoch 0098, iter [05600, 10009], lr: 0.000100, loss: 1.1790
2022-03-07 20:10:46 - train: epoch 0098, iter [05700, 10009], lr: 0.000100, loss: 0.9951
2022-03-07 20:11:06 - train: epoch 0098, iter [05800, 10009], lr: 0.000100, loss: 1.2877
2022-03-07 20:11:26 - train: epoch 0098, iter [05900, 10009], lr: 0.000100, loss: 0.8761
2022-03-07 20:11:46 - train: epoch 0098, iter [06000, 10009], lr: 0.000100, loss: 1.0824
2022-03-07 20:12:06 - train: epoch 0098, iter [06100, 10009], lr: 0.000100, loss: 1.2566
2022-03-07 20:12:26 - train: epoch 0098, iter [06200, 10009], lr: 0.000100, loss: 1.1963
2022-03-07 20:12:46 - train: epoch 0098, iter [06300, 10009], lr: 0.000100, loss: 0.9804
2022-03-07 20:13:06 - train: epoch 0098, iter [06400, 10009], lr: 0.000100, loss: 0.9083
2022-03-07 20:13:26 - train: epoch 0098, iter [06500, 10009], lr: 0.000100, loss: 1.0468
2022-03-07 20:13:46 - train: epoch 0098, iter [06600, 10009], lr: 0.000100, loss: 0.9239
2022-03-07 20:14:06 - train: epoch 0098, iter [06700, 10009], lr: 0.000100, loss: 0.9919
2022-03-07 20:14:26 - train: epoch 0098, iter [06800, 10009], lr: 0.000100, loss: 1.1431
2022-03-07 20:14:46 - train: epoch 0098, iter [06900, 10009], lr: 0.000100, loss: 1.1167
2022-03-07 20:15:05 - train: epoch 0098, iter [07000, 10009], lr: 0.000100, loss: 1.0859
2022-03-07 20:15:25 - train: epoch 0098, iter [07100, 10009], lr: 0.000100, loss: 0.9126
2022-03-07 20:15:45 - train: epoch 0098, iter [07200, 10009], lr: 0.000100, loss: 1.4730
2022-03-07 20:16:05 - train: epoch 0098, iter [07300, 10009], lr: 0.000100, loss: 1.3014
2022-03-07 20:16:25 - train: epoch 0098, iter [07400, 10009], lr: 0.000100, loss: 1.3421
2022-03-07 20:16:45 - train: epoch 0098, iter [07500, 10009], lr: 0.000100, loss: 1.1655
2022-03-07 20:17:05 - train: epoch 0098, iter [07600, 10009], lr: 0.000100, loss: 0.9198
2022-03-07 20:17:25 - train: epoch 0098, iter [07700, 10009], lr: 0.000100, loss: 1.2434
2022-03-07 20:17:46 - train: epoch 0098, iter [07800, 10009], lr: 0.000100, loss: 1.4042
2022-03-07 20:18:06 - train: epoch 0098, iter [07900, 10009], lr: 0.000100, loss: 1.2528
2022-03-07 20:18:26 - train: epoch 0098, iter [08000, 10009], lr: 0.000100, loss: 1.3680
2022-03-07 20:18:46 - train: epoch 0098, iter [08100, 10009], lr: 0.000100, loss: 1.0412
2022-03-07 20:19:06 - train: epoch 0098, iter [08200, 10009], lr: 0.000100, loss: 1.2157
2022-03-07 20:19:26 - train: epoch 0098, iter [08300, 10009], lr: 0.000100, loss: 1.2613
2022-03-07 20:19:46 - train: epoch 0098, iter [08400, 10009], lr: 0.000100, loss: 1.1437
2022-03-07 20:20:06 - train: epoch 0098, iter [08500, 10009], lr: 0.000100, loss: 1.1360
2022-03-07 20:20:26 - train: epoch 0098, iter [08600, 10009], lr: 0.000100, loss: 0.8965
2022-03-07 20:20:46 - train: epoch 0098, iter [08700, 10009], lr: 0.000100, loss: 1.0784
2022-03-07 20:21:06 - train: epoch 0098, iter [08800, 10009], lr: 0.000100, loss: 1.2453
2022-03-07 20:21:25 - train: epoch 0098, iter [08900, 10009], lr: 0.000100, loss: 1.0763
2022-03-07 20:21:45 - train: epoch 0098, iter [09000, 10009], lr: 0.000100, loss: 1.2988
2022-03-07 20:22:06 - train: epoch 0098, iter [09100, 10009], lr: 0.000100, loss: 1.2315
2022-03-07 20:22:26 - train: epoch 0098, iter [09200, 10009], lr: 0.000100, loss: 1.5151
2022-03-07 20:22:46 - train: epoch 0098, iter [09300, 10009], lr: 0.000100, loss: 1.3947
2022-03-07 20:23:06 - train: epoch 0098, iter [09400, 10009], lr: 0.000100, loss: 1.3005
2022-03-07 20:23:26 - train: epoch 0098, iter [09500, 10009], lr: 0.000100, loss: 1.1552
2022-03-07 20:23:46 - train: epoch 0098, iter [09600, 10009], lr: 0.000100, loss: 1.2252
2022-03-07 20:24:06 - train: epoch 0098, iter [09700, 10009], lr: 0.000100, loss: 1.0581
2022-03-07 20:24:26 - train: epoch 0098, iter [09800, 10009], lr: 0.000100, loss: 1.1713
2022-03-07 20:24:46 - train: epoch 0098, iter [09900, 10009], lr: 0.000100, loss: 1.2063
2022-03-07 20:25:06 - train: epoch 0098, iter [10000, 10009], lr: 0.000100, loss: 1.1645
2022-03-07 20:25:09 - train: epoch 098, train_loss: 1.1540
2022-03-07 20:26:24 - eval: epoch: 098, acc1: 73.560%, acc5: 91.378%, test_loss: 1.0582, per_image_load_time: 1.843ms, per_image_inference_time: 0.883ms
2022-03-07 20:26:25 - until epoch: 098, best_acc1: 73.580%
2022-03-07 20:26:25 - epoch 099 lr: 0.00010000000000000003
2022-03-07 20:26:49 - train: epoch 0099, iter [00100, 10009], lr: 0.000100, loss: 1.1544
2022-03-07 20:27:09 - train: epoch 0099, iter [00200, 10009], lr: 0.000100, loss: 0.9310
2022-03-07 20:27:29 - train: epoch 0099, iter [00300, 10009], lr: 0.000100, loss: 0.8766
2022-03-07 20:27:49 - train: epoch 0099, iter [00400, 10009], lr: 0.000100, loss: 1.1302
2022-03-07 20:28:09 - train: epoch 0099, iter [00500, 10009], lr: 0.000100, loss: 1.0766
2022-03-07 20:28:29 - train: epoch 0099, iter [00600, 10009], lr: 0.000100, loss: 0.9293
2022-03-07 20:28:49 - train: epoch 0099, iter [00700, 10009], lr: 0.000100, loss: 1.0184
2022-03-07 20:29:09 - train: epoch 0099, iter [00800, 10009], lr: 0.000100, loss: 1.4722
2022-03-07 20:29:28 - train: epoch 0099, iter [00900, 10009], lr: 0.000100, loss: 1.1771
2022-03-07 20:29:48 - train: epoch 0099, iter [01000, 10009], lr: 0.000100, loss: 1.2437
2022-03-07 20:30:08 - train: epoch 0099, iter [01100, 10009], lr: 0.000100, loss: 1.6030
2022-03-07 20:30:28 - train: epoch 0099, iter [01200, 10009], lr: 0.000100, loss: 1.1298
2022-03-07 20:30:48 - train: epoch 0099, iter [01300, 10009], lr: 0.000100, loss: 1.1462
2022-03-07 20:31:08 - train: epoch 0099, iter [01400, 10009], lr: 0.000100, loss: 1.3275
2022-03-07 20:31:28 - train: epoch 0099, iter [01500, 10009], lr: 0.000100, loss: 1.2258
2022-03-07 20:31:48 - train: epoch 0099, iter [01600, 10009], lr: 0.000100, loss: 1.1123
2022-03-07 20:32:08 - train: epoch 0099, iter [01700, 10009], lr: 0.000100, loss: 1.3168
2022-03-07 20:32:28 - train: epoch 0099, iter [01800, 10009], lr: 0.000100, loss: 0.9755
2022-03-07 20:32:48 - train: epoch 0099, iter [01900, 10009], lr: 0.000100, loss: 1.2790
2022-03-07 20:33:07 - train: epoch 0099, iter [02000, 10009], lr: 0.000100, loss: 1.0730
2022-03-07 20:33:27 - train: epoch 0099, iter [02100, 10009], lr: 0.000100, loss: 1.1899
2022-03-07 20:33:47 - train: epoch 0099, iter [02200, 10009], lr: 0.000100, loss: 1.3022
2022-03-07 20:34:07 - train: epoch 0099, iter [02300, 10009], lr: 0.000100, loss: 1.1441
2022-03-07 20:34:27 - train: epoch 0099, iter [02400, 10009], lr: 0.000100, loss: 0.8717
2022-03-07 20:34:47 - train: epoch 0099, iter [02500, 10009], lr: 0.000100, loss: 1.3013
2022-03-07 20:35:07 - train: epoch 0099, iter [02600, 10009], lr: 0.000100, loss: 1.2085
2022-03-07 20:35:27 - train: epoch 0099, iter [02700, 10009], lr: 0.000100, loss: 1.4062
2022-03-07 20:35:47 - train: epoch 0099, iter [02800, 10009], lr: 0.000100, loss: 1.0533
2022-03-07 20:36:06 - train: epoch 0099, iter [02900, 10009], lr: 0.000100, loss: 1.2408
2022-03-07 20:36:26 - train: epoch 0099, iter [03000, 10009], lr: 0.000100, loss: 1.1487
2022-03-07 20:36:46 - train: epoch 0099, iter [03100, 10009], lr: 0.000100, loss: 1.2733
2022-03-07 20:37:06 - train: epoch 0099, iter [03200, 10009], lr: 0.000100, loss: 1.1797
2022-03-07 20:37:26 - train: epoch 0099, iter [03300, 10009], lr: 0.000100, loss: 1.1957
2022-03-07 20:37:46 - train: epoch 0099, iter [03400, 10009], lr: 0.000100, loss: 1.0662
2022-03-07 20:38:06 - train: epoch 0099, iter [03500, 10009], lr: 0.000100, loss: 0.8975
2022-03-07 20:38:26 - train: epoch 0099, iter [03600, 10009], lr: 0.000100, loss: 0.9299
2022-03-07 20:38:46 - train: epoch 0099, iter [03700, 10009], lr: 0.000100, loss: 1.0896
2022-03-07 20:39:06 - train: epoch 0099, iter [03800, 10009], lr: 0.000100, loss: 1.1437
2022-03-07 20:39:25 - train: epoch 0099, iter [03900, 10009], lr: 0.000100, loss: 1.1994
2022-03-07 20:39:45 - train: epoch 0099, iter [04000, 10009], lr: 0.000100, loss: 1.1837
2022-03-07 20:40:05 - train: epoch 0099, iter [04100, 10009], lr: 0.000100, loss: 1.3477
2022-03-07 20:40:25 - train: epoch 0099, iter [04200, 10009], lr: 0.000100, loss: 0.9757
2022-03-07 20:40:45 - train: epoch 0099, iter [04300, 10009], lr: 0.000100, loss: 1.0951
2022-03-07 20:41:05 - train: epoch 0099, iter [04400, 10009], lr: 0.000100, loss: 1.0522
2022-03-07 20:41:25 - train: epoch 0099, iter [04500, 10009], lr: 0.000100, loss: 1.0937
2022-03-07 20:41:45 - train: epoch 0099, iter [04600, 10009], lr: 0.000100, loss: 0.9996
2022-03-07 20:42:05 - train: epoch 0099, iter [04700, 10009], lr: 0.000100, loss: 1.1096
2022-03-07 20:42:25 - train: epoch 0099, iter [04800, 10009], lr: 0.000100, loss: 1.6087
2022-03-07 20:42:45 - train: epoch 0099, iter [04900, 10009], lr: 0.000100, loss: 1.1246
2022-03-07 20:43:05 - train: epoch 0099, iter [05000, 10009], lr: 0.000100, loss: 1.1097
2022-03-07 20:43:25 - train: epoch 0099, iter [05100, 10009], lr: 0.000100, loss: 0.9875
2022-03-07 20:43:45 - train: epoch 0099, iter [05200, 10009], lr: 0.000100, loss: 1.2518
2022-03-07 20:44:05 - train: epoch 0099, iter [05300, 10009], lr: 0.000100, loss: 0.9226
2022-03-07 20:44:25 - train: epoch 0099, iter [05400, 10009], lr: 0.000100, loss: 1.1759
2022-03-07 20:44:45 - train: epoch 0099, iter [05500, 10009], lr: 0.000100, loss: 1.1221
2022-03-07 20:45:05 - train: epoch 0099, iter [05600, 10009], lr: 0.000100, loss: 1.0127
2022-03-07 20:45:25 - train: epoch 0099, iter [05700, 10009], lr: 0.000100, loss: 0.9045
2022-03-07 20:45:45 - train: epoch 0099, iter [05800, 10009], lr: 0.000100, loss: 1.0716
2022-03-07 20:46:05 - train: epoch 0099, iter [05900, 10009], lr: 0.000100, loss: 1.2490
2022-03-07 20:46:25 - train: epoch 0099, iter [06000, 10009], lr: 0.000100, loss: 1.2757
2022-03-07 20:46:45 - train: epoch 0099, iter [06100, 10009], lr: 0.000100, loss: 1.2967
2022-03-07 20:47:05 - train: epoch 0099, iter [06200, 10009], lr: 0.000100, loss: 1.2455
2022-03-07 20:47:26 - train: epoch 0099, iter [06300, 10009], lr: 0.000100, loss: 1.3236
2022-03-07 20:47:46 - train: epoch 0099, iter [06400, 10009], lr: 0.000100, loss: 1.3101
2022-03-07 20:48:06 - train: epoch 0099, iter [06500, 10009], lr: 0.000100, loss: 1.1072
2022-03-07 20:48:26 - train: epoch 0099, iter [06600, 10009], lr: 0.000100, loss: 1.2736
2022-03-07 20:48:46 - train: epoch 0099, iter [06700, 10009], lr: 0.000100, loss: 1.5205
2022-03-07 20:49:06 - train: epoch 0099, iter [06800, 10009], lr: 0.000100, loss: 1.3526
2022-03-07 20:49:26 - train: epoch 0099, iter [06900, 10009], lr: 0.000100, loss: 1.2516
2022-03-07 20:49:46 - train: epoch 0099, iter [07000, 10009], lr: 0.000100, loss: 1.2872
2022-03-07 20:50:06 - train: epoch 0099, iter [07100, 10009], lr: 0.000100, loss: 1.2224
2022-03-07 20:50:26 - train: epoch 0099, iter [07200, 10009], lr: 0.000100, loss: 0.9903
2022-03-07 20:50:46 - train: epoch 0099, iter [07300, 10009], lr: 0.000100, loss: 1.2467
2022-03-07 20:51:06 - train: epoch 0099, iter [07400, 10009], lr: 0.000100, loss: 1.0530
2022-03-07 20:51:27 - train: epoch 0099, iter [07500, 10009], lr: 0.000100, loss: 1.3810
2022-03-07 20:51:47 - train: epoch 0099, iter [07600, 10009], lr: 0.000100, loss: 1.1746
2022-03-07 20:52:07 - train: epoch 0099, iter [07700, 10009], lr: 0.000100, loss: 1.1393
2022-03-07 20:52:27 - train: epoch 0099, iter [07800, 10009], lr: 0.000100, loss: 1.3009
2022-03-07 20:52:47 - train: epoch 0099, iter [07900, 10009], lr: 0.000100, loss: 0.9643
2022-03-07 20:53:07 - train: epoch 0099, iter [08000, 10009], lr: 0.000100, loss: 1.4184
2022-03-07 20:53:27 - train: epoch 0099, iter [08100, 10009], lr: 0.000100, loss: 1.3442
2022-03-07 20:53:47 - train: epoch 0099, iter [08200, 10009], lr: 0.000100, loss: 1.1207
2022-03-07 20:54:08 - train: epoch 0099, iter [08300, 10009], lr: 0.000100, loss: 1.0550
2022-03-07 20:54:28 - train: epoch 0099, iter [08400, 10009], lr: 0.000100, loss: 1.3840
2022-03-07 20:54:48 - train: epoch 0099, iter [08500, 10009], lr: 0.000100, loss: 1.1506
2022-03-07 20:55:08 - train: epoch 0099, iter [08600, 10009], lr: 0.000100, loss: 1.2354
2022-03-07 20:55:28 - train: epoch 0099, iter [08700, 10009], lr: 0.000100, loss: 1.1419
2022-03-07 20:55:48 - train: epoch 0099, iter [08800, 10009], lr: 0.000100, loss: 0.9719
2022-03-07 20:56:08 - train: epoch 0099, iter [08900, 10009], lr: 0.000100, loss: 1.3332
2022-03-07 20:56:27 - train: epoch 0099, iter [09000, 10009], lr: 0.000100, loss: 1.4997
2022-03-07 20:56:48 - train: epoch 0099, iter [09100, 10009], lr: 0.000100, loss: 1.0170
2022-03-07 20:57:08 - train: epoch 0099, iter [09200, 10009], lr: 0.000100, loss: 1.2303
2022-03-07 20:57:28 - train: epoch 0099, iter [09300, 10009], lr: 0.000100, loss: 1.5175
2022-03-07 20:57:48 - train: epoch 0099, iter [09400, 10009], lr: 0.000100, loss: 1.2019
2022-03-07 20:58:08 - train: epoch 0099, iter [09500, 10009], lr: 0.000100, loss: 1.2270
2022-03-07 20:58:28 - train: epoch 0099, iter [09600, 10009], lr: 0.000100, loss: 1.3221
2022-03-07 20:58:48 - train: epoch 0099, iter [09700, 10009], lr: 0.000100, loss: 1.2277
2022-03-07 20:59:08 - train: epoch 0099, iter [09800, 10009], lr: 0.000100, loss: 1.1650
2022-03-07 20:59:28 - train: epoch 0099, iter [09900, 10009], lr: 0.000100, loss: 1.1605
2022-03-07 20:59:48 - train: epoch 0099, iter [10000, 10009], lr: 0.000100, loss: 1.4036
2022-03-07 20:59:51 - train: epoch 099, train_loss: 1.1522
2022-03-07 21:01:07 - eval: epoch: 099, acc1: 73.624%, acc5: 91.278%, test_loss: 1.0585, per_image_load_time: 1.875ms, per_image_inference_time: 0.887ms
2022-03-07 21:01:07 - until epoch: 099, best_acc1: 73.624%
2022-03-07 21:01:07 - epoch 100 lr: 0.00010000000000000003
2022-03-07 21:01:31 - train: epoch 0100, iter [00100, 10009], lr: 0.000100, loss: 1.3488
2022-03-07 21:01:51 - train: epoch 0100, iter [00200, 10009], lr: 0.000100, loss: 1.1220
2022-03-07 21:02:11 - train: epoch 0100, iter [00300, 10009], lr: 0.000100, loss: 1.2070
2022-03-07 21:02:31 - train: epoch 0100, iter [00400, 10009], lr: 0.000100, loss: 1.2885
2022-03-07 21:02:51 - train: epoch 0100, iter [00500, 10009], lr: 0.000100, loss: 1.2955
2022-03-07 21:03:11 - train: epoch 0100, iter [00600, 10009], lr: 0.000100, loss: 1.3366
2022-03-07 21:03:31 - train: epoch 0100, iter [00700, 10009], lr: 0.000100, loss: 1.1691
2022-03-07 21:03:51 - train: epoch 0100, iter [00800, 10009], lr: 0.000100, loss: 1.2580
2022-03-07 21:04:11 - train: epoch 0100, iter [00900, 10009], lr: 0.000100, loss: 1.1955
2022-03-07 21:04:31 - train: epoch 0100, iter [01000, 10009], lr: 0.000100, loss: 1.1762
2022-03-07 21:04:50 - train: epoch 0100, iter [01100, 10009], lr: 0.000100, loss: 1.0621
2022-03-07 21:05:10 - train: epoch 0100, iter [01200, 10009], lr: 0.000100, loss: 1.2409
2022-03-07 21:05:30 - train: epoch 0100, iter [01300, 10009], lr: 0.000100, loss: 1.0365
2022-03-07 21:05:50 - train: epoch 0100, iter [01400, 10009], lr: 0.000100, loss: 1.3480
2022-03-07 21:06:10 - train: epoch 0100, iter [01500, 10009], lr: 0.000100, loss: 1.5148
2022-03-07 21:06:30 - train: epoch 0100, iter [01600, 10009], lr: 0.000100, loss: 0.9959
2022-03-07 21:06:50 - train: epoch 0100, iter [01700, 10009], lr: 0.000100, loss: 0.9895
2022-03-07 21:07:10 - train: epoch 0100, iter [01800, 10009], lr: 0.000100, loss: 1.0827
2022-03-07 21:07:30 - train: epoch 0100, iter [01900, 10009], lr: 0.000100, loss: 1.0681
2022-03-07 21:07:50 - train: epoch 0100, iter [02000, 10009], lr: 0.000100, loss: 1.3677
2022-03-07 21:08:10 - train: epoch 0100, iter [02100, 10009], lr: 0.000100, loss: 1.0029
2022-03-07 21:08:30 - train: epoch 0100, iter [02200, 10009], lr: 0.000100, loss: 0.8673
2022-03-07 21:08:50 - train: epoch 0100, iter [02300, 10009], lr: 0.000100, loss: 1.2048
2022-03-07 21:09:10 - train: epoch 0100, iter [02400, 10009], lr: 0.000100, loss: 1.0333
2022-03-07 21:09:30 - train: epoch 0100, iter [02500, 10009], lr: 0.000100, loss: 1.1007
2022-03-07 21:09:50 - train: epoch 0100, iter [02600, 10009], lr: 0.000100, loss: 1.0202
2022-03-07 21:10:10 - train: epoch 0100, iter [02700, 10009], lr: 0.000100, loss: 1.1747
2022-03-07 21:10:30 - train: epoch 0100, iter [02800, 10009], lr: 0.000100, loss: 1.1224
2022-03-07 21:10:50 - train: epoch 0100, iter [02900, 10009], lr: 0.000100, loss: 0.9752
2022-03-07 21:11:10 - train: epoch 0100, iter [03000, 10009], lr: 0.000100, loss: 1.1466
2022-03-07 21:11:30 - train: epoch 0100, iter [03100, 10009], lr: 0.000100, loss: 1.2192
2022-03-07 21:11:50 - train: epoch 0100, iter [03200, 10009], lr: 0.000100, loss: 1.1712
2022-03-07 21:12:10 - train: epoch 0100, iter [03300, 10009], lr: 0.000100, loss: 1.3691
2022-03-07 21:12:30 - train: epoch 0100, iter [03400, 10009], lr: 0.000100, loss: 1.3556
2022-03-07 21:12:49 - train: epoch 0100, iter [03500, 10009], lr: 0.000100, loss: 1.0874
2022-03-07 21:13:09 - train: epoch 0100, iter [03600, 10009], lr: 0.000100, loss: 1.0538
2022-03-07 21:13:29 - train: epoch 0100, iter [03700, 10009], lr: 0.000100, loss: 0.9567
2022-03-07 21:13:49 - train: epoch 0100, iter [03800, 10009], lr: 0.000100, loss: 1.1293
2022-03-07 21:14:09 - train: epoch 0100, iter [03900, 10009], lr: 0.000100, loss: 1.3341
2022-03-07 21:14:29 - train: epoch 0100, iter [04000, 10009], lr: 0.000100, loss: 1.2071
2022-03-07 21:14:49 - train: epoch 0100, iter [04100, 10009], lr: 0.000100, loss: 1.0747
2022-03-07 21:15:09 - train: epoch 0100, iter [04200, 10009], lr: 0.000100, loss: 1.2248
2022-03-07 21:15:29 - train: epoch 0100, iter [04300, 10009], lr: 0.000100, loss: 0.9943
2022-03-07 21:15:49 - train: epoch 0100, iter [04400, 10009], lr: 0.000100, loss: 1.1213
2022-03-07 21:16:09 - train: epoch 0100, iter [04500, 10009], lr: 0.000100, loss: 1.2361
2022-03-07 21:16:29 - train: epoch 0100, iter [04600, 10009], lr: 0.000100, loss: 1.1620
2022-03-07 21:16:49 - train: epoch 0100, iter [04700, 10009], lr: 0.000100, loss: 0.9719
2022-03-07 21:17:09 - train: epoch 0100, iter [04800, 10009], lr: 0.000100, loss: 0.9187
2022-03-07 21:17:29 - train: epoch 0100, iter [04900, 10009], lr: 0.000100, loss: 0.9149
2022-03-07 21:17:49 - train: epoch 0100, iter [05000, 10009], lr: 0.000100, loss: 1.2635
2022-03-07 21:18:09 - train: epoch 0100, iter [05100, 10009], lr: 0.000100, loss: 1.1307
2022-03-07 21:18:29 - train: epoch 0100, iter [05200, 10009], lr: 0.000100, loss: 1.3015
2022-03-07 21:18:49 - train: epoch 0100, iter [05300, 10009], lr: 0.000100, loss: 1.2579
2022-03-07 21:19:09 - train: epoch 0100, iter [05400, 10009], lr: 0.000100, loss: 1.1760
2022-03-07 21:19:29 - train: epoch 0100, iter [05500, 10009], lr: 0.000100, loss: 1.3198
2022-03-07 21:19:49 - train: epoch 0100, iter [05600, 10009], lr: 0.000100, loss: 1.0762
2022-03-07 21:20:09 - train: epoch 0100, iter [05700, 10009], lr: 0.000100, loss: 1.3978
2022-03-07 21:20:29 - train: epoch 0100, iter [05800, 10009], lr: 0.000100, loss: 0.9581
2022-03-07 21:20:48 - train: epoch 0100, iter [05900, 10009], lr: 0.000100, loss: 0.9590
2022-03-07 21:21:08 - train: epoch 0100, iter [06000, 10009], lr: 0.000100, loss: 1.0686
2022-03-07 21:21:28 - train: epoch 0100, iter [06100, 10009], lr: 0.000100, loss: 1.0668
2022-03-07 21:21:48 - train: epoch 0100, iter [06200, 10009], lr: 0.000100, loss: 0.9629
2022-03-07 21:22:08 - train: epoch 0100, iter [06300, 10009], lr: 0.000100, loss: 1.2066
2022-03-07 21:22:28 - train: epoch 0100, iter [06400, 10009], lr: 0.000100, loss: 1.2588
2022-03-07 21:22:48 - train: epoch 0100, iter [06500, 10009], lr: 0.000100, loss: 1.1244
2022-03-07 21:23:08 - train: epoch 0100, iter [06600, 10009], lr: 0.000100, loss: 1.0351
2022-03-07 21:23:28 - train: epoch 0100, iter [06700, 10009], lr: 0.000100, loss: 1.1339
2022-03-07 21:23:48 - train: epoch 0100, iter [06800, 10009], lr: 0.000100, loss: 1.3123
2022-03-07 21:24:08 - train: epoch 0100, iter [06900, 10009], lr: 0.000100, loss: 1.2829
2022-03-07 21:24:28 - train: epoch 0100, iter [07000, 10009], lr: 0.000100, loss: 1.0096
2022-03-07 21:24:48 - train: epoch 0100, iter [07100, 10009], lr: 0.000100, loss: 1.2062
2022-03-07 21:25:08 - train: epoch 0100, iter [07200, 10009], lr: 0.000100, loss: 1.2544
2022-03-07 21:25:28 - train: epoch 0100, iter [07300, 10009], lr: 0.000100, loss: 0.9131
2022-03-07 21:25:48 - train: epoch 0100, iter [07400, 10009], lr: 0.000100, loss: 1.1972
2022-03-07 21:26:08 - train: epoch 0100, iter [07500, 10009], lr: 0.000100, loss: 1.0722
2022-03-07 21:26:28 - train: epoch 0100, iter [07600, 10009], lr: 0.000100, loss: 1.1285
2022-03-07 21:26:48 - train: epoch 0100, iter [07700, 10009], lr: 0.000100, loss: 1.0511
2022-03-07 21:27:08 - train: epoch 0100, iter [07800, 10009], lr: 0.000100, loss: 1.3257
2022-03-07 21:27:28 - train: epoch 0100, iter [07900, 10009], lr: 0.000100, loss: 1.2641
2022-03-07 21:27:48 - train: epoch 0100, iter [08000, 10009], lr: 0.000100, loss: 0.9789
2022-03-07 21:28:08 - train: epoch 0100, iter [08100, 10009], lr: 0.000100, loss: 1.2048
2022-03-07 21:28:28 - train: epoch 0100, iter [08200, 10009], lr: 0.000100, loss: 1.1457
2022-03-07 21:28:48 - train: epoch 0100, iter [08300, 10009], lr: 0.000100, loss: 1.2024
2022-03-07 21:29:08 - train: epoch 0100, iter [08400, 10009], lr: 0.000100, loss: 1.2238
2022-03-07 21:29:29 - train: epoch 0100, iter [08500, 10009], lr: 0.000100, loss: 1.0125
2022-03-07 21:29:48 - train: epoch 0100, iter [08600, 10009], lr: 0.000100, loss: 1.2834
2022-03-07 21:30:09 - train: epoch 0100, iter [08700, 10009], lr: 0.000100, loss: 1.1532
2022-03-07 21:30:29 - train: epoch 0100, iter [08800, 10009], lr: 0.000100, loss: 1.3705
2022-03-07 21:30:49 - train: epoch 0100, iter [08900, 10009], lr: 0.000100, loss: 1.1533
2022-03-07 21:31:09 - train: epoch 0100, iter [09000, 10009], lr: 0.000100, loss: 1.2285
2022-03-07 21:31:29 - train: epoch 0100, iter [09100, 10009], lr: 0.000100, loss: 1.1705
2022-03-07 21:31:49 - train: epoch 0100, iter [09200, 10009], lr: 0.000100, loss: 1.2375
2022-03-07 21:32:09 - train: epoch 0100, iter [09300, 10009], lr: 0.000100, loss: 1.2659
2022-03-07 21:32:29 - train: epoch 0100, iter [09400, 10009], lr: 0.000100, loss: 1.4954
2022-03-07 21:32:50 - train: epoch 0100, iter [09500, 10009], lr: 0.000100, loss: 1.1062
2022-03-07 21:33:10 - train: epoch 0100, iter [09600, 10009], lr: 0.000100, loss: 1.1963
2022-03-07 21:33:30 - train: epoch 0100, iter [09700, 10009], lr: 0.000100, loss: 1.2549
2022-03-07 21:33:50 - train: epoch 0100, iter [09800, 10009], lr: 0.000100, loss: 1.2933
2022-03-07 21:34:10 - train: epoch 0100, iter [09900, 10009], lr: 0.000100, loss: 1.3488
2022-03-07 21:34:30 - train: epoch 0100, iter [10000, 10009], lr: 0.000100, loss: 1.3114
2022-03-07 21:34:34 - train: epoch 100, train_loss: 1.1486
2022-03-07 21:35:50 - eval: epoch: 100, acc1: 73.640%, acc5: 91.280%, test_loss: 1.0574, per_image_load_time: 1.711ms, per_image_inference_time: 0.916ms
2022-03-07 21:35:51 - until epoch: 100, best_acc1: 73.640%
2022-03-07 21:35:51 - train done. model: yolov5xbackbone, train time: 71.939 hours, best_acc1: 73.640%
