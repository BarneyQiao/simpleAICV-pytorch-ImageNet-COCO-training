2022-07-11 20:48:16 - eval: epoch: 107, acc1: 73.296%, acc5: 91.376%, test_loss: 1.0657, per_image_load_time: 1.456ms, per_image_inference_time: 0.383ms
2022-07-11 20:48:17 - until epoch: 107, best_acc1: 73.296%
2022-07-11 20:48:17 - epoch 108 lr: 0.002868
2022-07-11 20:48:56 - train: epoch 0108, iter [00100, 05004], lr: 0.002859, loss: 1.0861
2022-07-11 20:49:31 - train: epoch 0108, iter [00200, 05004], lr: 0.002850, loss: 1.1241
2022-07-11 20:50:05 - train: epoch 0108, iter [00300, 05004], lr: 0.002842, loss: 1.1020
2022-07-11 20:50:39 - train: epoch 0108, iter [00400, 05004], lr: 0.002833, loss: 1.3722
2022-07-11 20:51:13 - train: epoch 0108, iter [00500, 05004], lr: 0.002824, loss: 1.0957
2022-07-11 20:51:47 - train: epoch 0108, iter [00600, 05004], lr: 0.002816, loss: 1.1326
2022-07-11 20:52:21 - train: epoch 0108, iter [00700, 05004], lr: 0.002807, loss: 0.9926
2022-07-11 20:52:54 - train: epoch 0108, iter [00800, 05004], lr: 0.002798, loss: 1.0429
2022-07-11 20:53:30 - train: epoch 0108, iter [00900, 05004], lr: 0.002790, loss: 1.0497
2022-07-11 20:54:03 - train: epoch 0108, iter [01000, 05004], lr: 0.002781, loss: 1.0894
2022-07-11 20:54:38 - train: epoch 0108, iter [01100, 05004], lr: 0.002773, loss: 0.9901
2022-07-11 20:55:11 - train: epoch 0108, iter [01200, 05004], lr: 0.002764, loss: 1.0729
2022-07-11 20:55:45 - train: epoch 0108, iter [01300, 05004], lr: 0.002755, loss: 0.9726
2022-07-11 20:56:19 - train: epoch 0108, iter [01400, 05004], lr: 0.002747, loss: 0.9334
2022-07-11 20:56:53 - train: epoch 0108, iter [01500, 05004], lr: 0.002738, loss: 1.1404
2022-07-11 20:57:27 - train: epoch 0108, iter [01600, 05004], lr: 0.002730, loss: 1.2024
2022-07-11 20:58:02 - train: epoch 0108, iter [01700, 05004], lr: 0.002721, loss: 1.0891
2022-07-11 20:58:36 - train: epoch 0108, iter [01800, 05004], lr: 0.002713, loss: 1.1626
2022-07-11 20:59:11 - train: epoch 0108, iter [01900, 05004], lr: 0.002704, loss: 1.0336
2022-07-11 20:59:45 - train: epoch 0108, iter [02000, 05004], lr: 0.002696, loss: 1.0913
2022-07-11 21:00:19 - train: epoch 0108, iter [02100, 05004], lr: 0.002687, loss: 1.0411
2022-07-11 21:00:53 - train: epoch 0108, iter [02200, 05004], lr: 0.002679, loss: 0.9755
2022-07-11 21:01:28 - train: epoch 0108, iter [02300, 05004], lr: 0.002671, loss: 1.0800
2022-07-11 21:02:03 - train: epoch 0108, iter [02400, 05004], lr: 0.002662, loss: 1.1580
2022-07-11 21:02:37 - train: epoch 0108, iter [02500, 05004], lr: 0.002654, loss: 1.1469
2022-07-11 21:03:10 - train: epoch 0108, iter [02600, 05004], lr: 0.002645, loss: 1.2369
2022-07-11 21:03:45 - train: epoch 0108, iter [02700, 05004], lr: 0.002637, loss: 1.2514
2022-07-11 21:04:19 - train: epoch 0108, iter [02800, 05004], lr: 0.002628, loss: 1.1737
2022-07-11 21:04:52 - train: epoch 0108, iter [02900, 05004], lr: 0.002620, loss: 1.1146
2022-07-11 21:05:27 - train: epoch 0108, iter [03000, 05004], lr: 0.002612, loss: 1.2228
2022-07-11 21:06:01 - train: epoch 0108, iter [03100, 05004], lr: 0.002603, loss: 1.0689
2022-07-11 21:06:35 - train: epoch 0108, iter [03200, 05004], lr: 0.002595, loss: 1.0383
2022-07-11 21:07:08 - train: epoch 0108, iter [03300, 05004], lr: 0.002587, loss: 1.1866
2022-07-11 21:07:43 - train: epoch 0108, iter [03400, 05004], lr: 0.002579, loss: 1.1996
2022-07-11 21:08:18 - train: epoch 0108, iter [03500, 05004], lr: 0.002570, loss: 1.1914
2022-07-11 21:08:52 - train: epoch 0108, iter [03600, 05004], lr: 0.002562, loss: 0.9886
2022-07-11 21:09:26 - train: epoch 0108, iter [03700, 05004], lr: 0.002554, loss: 1.0296
2022-07-11 21:10:00 - train: epoch 0108, iter [03800, 05004], lr: 0.002545, loss: 1.2613
2022-07-11 21:10:34 - train: epoch 0108, iter [03900, 05004], lr: 0.002537, loss: 1.1169
2022-07-11 21:11:09 - train: epoch 0108, iter [04000, 05004], lr: 0.002529, loss: 1.1923
2022-07-11 21:11:43 - train: epoch 0108, iter [04100, 05004], lr: 0.002521, loss: 1.1229
2022-07-11 21:12:16 - train: epoch 0108, iter [04200, 05004], lr: 0.002513, loss: 0.9967
2022-07-11 21:12:51 - train: epoch 0108, iter [04300, 05004], lr: 0.002504, loss: 1.0718
2022-07-11 21:13:25 - train: epoch 0108, iter [04400, 05004], lr: 0.002496, loss: 1.0566
2022-07-11 21:13:59 - train: epoch 0108, iter [04500, 05004], lr: 0.002488, loss: 1.1542
2022-07-11 21:14:33 - train: epoch 0108, iter [04600, 05004], lr: 0.002480, loss: 1.1310
2022-07-11 21:15:08 - train: epoch 0108, iter [04700, 05004], lr: 0.002472, loss: 1.1760
2022-07-11 21:15:42 - train: epoch 0108, iter [04800, 05004], lr: 0.002464, loss: 1.1835
2022-07-11 21:16:17 - train: epoch 0108, iter [04900, 05004], lr: 0.002456, loss: 1.1785
2022-07-11 21:16:50 - train: epoch 0108, iter [05000, 05004], lr: 0.002447, loss: 0.9348
2022-07-11 21:16:51 - train: epoch 108, train_loss: 1.1200
2022-07-11 21:18:07 - eval: epoch: 108, acc1: 73.668%, acc5: 91.588%, test_loss: 1.0540, per_image_load_time: 2.497ms, per_image_inference_time: 0.383ms
2022-07-11 21:18:07 - until epoch: 108, best_acc1: 73.668%
2022-07-11 21:18:07 - epoch 109 lr: 0.002447
2022-07-11 21:18:48 - train: epoch 0109, iter [00100, 05004], lr: 0.002439, loss: 1.2021
2022-07-11 21:19:22 - train: epoch 0109, iter [00200, 05004], lr: 0.002431, loss: 1.3226
2022-07-11 21:19:56 - train: epoch 0109, iter [00300, 05004], lr: 0.002423, loss: 1.1658
2022-07-11 21:20:30 - train: epoch 0109, iter [00400, 05004], lr: 0.002415, loss: 0.9937
2022-07-11 21:21:04 - train: epoch 0109, iter [00500, 05004], lr: 0.002407, loss: 1.2263
2022-07-11 21:21:39 - train: epoch 0109, iter [00600, 05004], lr: 0.002399, loss: 0.8937
2022-07-11 21:22:13 - train: epoch 0109, iter [00700, 05004], lr: 0.002391, loss: 1.0813
2022-07-11 21:22:48 - train: epoch 0109, iter [00800, 05004], lr: 0.002383, loss: 1.1061
2022-07-11 21:23:22 - train: epoch 0109, iter [00900, 05004], lr: 0.002375, loss: 1.0995
2022-07-11 21:23:58 - train: epoch 0109, iter [01000, 05004], lr: 0.002367, loss: 0.9046
2022-07-11 21:24:32 - train: epoch 0109, iter [01100, 05004], lr: 0.002359, loss: 1.1692
2022-07-11 21:25:06 - train: epoch 0109, iter [01200, 05004], lr: 0.002351, loss: 0.9427
2022-07-11 21:25:41 - train: epoch 0109, iter [01300, 05004], lr: 0.002343, loss: 1.0295
2022-07-11 21:26:16 - train: epoch 0109, iter [01400, 05004], lr: 0.002335, loss: 1.1292
2022-07-11 21:26:50 - train: epoch 0109, iter [01500, 05004], lr: 0.002327, loss: 1.1935
2022-07-11 21:27:25 - train: epoch 0109, iter [01600, 05004], lr: 0.002320, loss: 0.9699
2022-07-11 21:28:00 - train: epoch 0109, iter [01700, 05004], lr: 0.002312, loss: 1.1097
2022-07-11 21:28:34 - train: epoch 0109, iter [01800, 05004], lr: 0.002304, loss: 1.1285
2022-07-11 21:29:08 - train: epoch 0109, iter [01900, 05004], lr: 0.002296, loss: 1.3049
2022-07-11 21:29:43 - train: epoch 0109, iter [02000, 05004], lr: 0.002288, loss: 1.3243
2022-07-11 21:30:17 - train: epoch 0109, iter [02100, 05004], lr: 0.002280, loss: 1.0359
2022-07-11 21:30:53 - train: epoch 0109, iter [02200, 05004], lr: 0.002272, loss: 1.0976
2022-07-11 21:31:27 - train: epoch 0109, iter [02300, 05004], lr: 0.002265, loss: 1.1049
2022-07-11 21:32:02 - train: epoch 0109, iter [02400, 05004], lr: 0.002257, loss: 1.2123
2022-07-11 21:32:36 - train: epoch 0109, iter [02500, 05004], lr: 0.002249, loss: 1.2342
2022-07-11 21:33:11 - train: epoch 0109, iter [02600, 05004], lr: 0.002241, loss: 1.2631
2022-07-11 21:33:46 - train: epoch 0109, iter [02700, 05004], lr: 0.002234, loss: 1.0905
2022-07-11 21:34:21 - train: epoch 0109, iter [02800, 05004], lr: 0.002226, loss: 1.0658
2022-07-11 21:34:55 - train: epoch 0109, iter [02900, 05004], lr: 0.002218, loss: 0.9161
2022-07-11 21:35:29 - train: epoch 0109, iter [03000, 05004], lr: 0.002211, loss: 1.0893
2022-07-11 21:36:04 - train: epoch 0109, iter [03100, 05004], lr: 0.002203, loss: 1.1614
2022-07-11 21:36:38 - train: epoch 0109, iter [03200, 05004], lr: 0.002195, loss: 1.1732
2022-07-11 21:37:13 - train: epoch 0109, iter [03300, 05004], lr: 0.002188, loss: 1.2183
2022-07-11 21:37:48 - train: epoch 0109, iter [03400, 05004], lr: 0.002180, loss: 0.9789
2022-07-11 21:38:22 - train: epoch 0109, iter [03500, 05004], lr: 0.002172, loss: 0.9765
2022-07-11 21:38:57 - train: epoch 0109, iter [03600, 05004], lr: 0.002165, loss: 1.0296
2022-07-11 21:39:32 - train: epoch 0109, iter [03700, 05004], lr: 0.002157, loss: 1.0926
2022-07-11 21:40:06 - train: epoch 0109, iter [03800, 05004], lr: 0.002149, loss: 1.4635
2022-07-11 21:40:41 - train: epoch 0109, iter [03900, 05004], lr: 0.002142, loss: 1.1770
2022-07-11 21:41:15 - train: epoch 0109, iter [04000, 05004], lr: 0.002134, loss: 1.1736
2022-07-11 21:41:50 - train: epoch 0109, iter [04100, 05004], lr: 0.002127, loss: 1.0584
2022-07-11 21:42:25 - train: epoch 0109, iter [04200, 05004], lr: 0.002119, loss: 1.1845
2022-07-11 21:42:59 - train: epoch 0109, iter [04300, 05004], lr: 0.002112, loss: 1.0361
2022-07-11 21:43:34 - train: epoch 0109, iter [04400, 05004], lr: 0.002104, loss: 0.9460
2022-07-11 21:44:08 - train: epoch 0109, iter [04500, 05004], lr: 0.002097, loss: 0.9729
2022-07-11 21:44:43 - train: epoch 0109, iter [04600, 05004], lr: 0.002089, loss: 1.0869
2022-07-11 21:45:17 - train: epoch 0109, iter [04700, 05004], lr: 0.002082, loss: 1.0178
2022-07-11 21:45:51 - train: epoch 0109, iter [04800, 05004], lr: 0.002074, loss: 1.2017
2022-07-11 21:46:26 - train: epoch 0109, iter [04900, 05004], lr: 0.002067, loss: 1.1989
2022-07-11 21:46:59 - train: epoch 0109, iter [05000, 05004], lr: 0.002059, loss: 1.0179
2022-07-11 21:47:00 - train: epoch 109, train_loss: 1.1019
2022-07-11 21:48:17 - eval: epoch: 109, acc1: 73.654%, acc5: 91.602%, test_loss: 1.0530, per_image_load_time: 2.543ms, per_image_inference_time: 0.375ms
2022-07-11 21:48:17 - until epoch: 109, best_acc1: 73.668%
2022-07-11 21:48:17 - epoch 110 lr: 0.002059
2022-07-11 21:48:57 - train: epoch 0110, iter [00100, 05004], lr: 0.002052, loss: 0.9768
2022-07-11 21:49:31 - train: epoch 0110, iter [00200, 05004], lr: 0.002044, loss: 0.9668
2022-07-11 21:50:05 - train: epoch 0110, iter [00300, 05004], lr: 0.002037, loss: 1.2066
2022-07-11 21:50:39 - train: epoch 0110, iter [00400, 05004], lr: 0.002029, loss: 1.3295
2022-07-11 21:51:13 - train: epoch 0110, iter [00500, 05004], lr: 0.002022, loss: 0.8655
2022-07-11 21:51:47 - train: epoch 0110, iter [00600, 05004], lr: 0.002015, loss: 1.1537
2022-07-11 21:52:22 - train: epoch 0110, iter [00700, 05004], lr: 0.002007, loss: 1.0882
2022-07-11 21:52:56 - train: epoch 0110, iter [00800, 05004], lr: 0.002000, loss: 1.1379
2022-07-11 21:53:31 - train: epoch 0110, iter [00900, 05004], lr: 0.001993, loss: 1.0205
2022-07-11 21:54:05 - train: epoch 0110, iter [01000, 05004], lr: 0.001985, loss: 1.0729
2022-07-11 21:54:39 - train: epoch 0110, iter [01100, 05004], lr: 0.001978, loss: 1.2043
2022-07-11 21:55:14 - train: epoch 0110, iter [01200, 05004], lr: 0.001971, loss: 0.9808
2022-07-11 21:55:48 - train: epoch 0110, iter [01300, 05004], lr: 0.001964, loss: 1.0486
2022-07-11 21:56:22 - train: epoch 0110, iter [01400, 05004], lr: 0.001956, loss: 1.0273
2022-07-11 21:56:57 - train: epoch 0110, iter [01500, 05004], lr: 0.001949, loss: 1.2448
2022-07-11 21:57:32 - train: epoch 0110, iter [01600, 05004], lr: 0.001942, loss: 1.0667
2022-07-11 21:58:06 - train: epoch 0110, iter [01700, 05004], lr: 0.001935, loss: 0.9625
2022-07-11 21:58:41 - train: epoch 0110, iter [01800, 05004], lr: 0.001927, loss: 1.0185
2022-07-11 21:59:14 - train: epoch 0110, iter [01900, 05004], lr: 0.001920, loss: 1.1981
2022-07-11 21:59:50 - train: epoch 0110, iter [02000, 05004], lr: 0.001913, loss: 1.1162
2022-07-11 22:00:23 - train: epoch 0110, iter [02100, 05004], lr: 0.001906, loss: 1.1967
2022-07-11 22:00:57 - train: epoch 0110, iter [02200, 05004], lr: 0.001899, loss: 1.1623
2022-07-11 22:01:32 - train: epoch 0110, iter [02300, 05004], lr: 0.001892, loss: 0.8785
2022-07-11 22:02:07 - train: epoch 0110, iter [02400, 05004], lr: 0.001884, loss: 1.1239
2022-07-11 22:02:41 - train: epoch 0110, iter [02500, 05004], lr: 0.001877, loss: 0.9089
2022-07-11 22:03:15 - train: epoch 0110, iter [02600, 05004], lr: 0.001870, loss: 1.4154
2022-07-11 22:03:50 - train: epoch 0110, iter [02700, 05004], lr: 0.001863, loss: 1.1999
2022-07-11 22:04:24 - train: epoch 0110, iter [02800, 05004], lr: 0.001856, loss: 1.0525
2022-07-11 22:04:58 - train: epoch 0110, iter [02900, 05004], lr: 0.001849, loss: 1.2466
2022-07-11 22:05:33 - train: epoch 0110, iter [03000, 05004], lr: 0.001842, loss: 1.0989
2022-07-11 22:06:07 - train: epoch 0110, iter [03100, 05004], lr: 0.001835, loss: 0.9804
2022-07-11 22:06:41 - train: epoch 0110, iter [03200, 05004], lr: 0.001828, loss: 1.2191
2022-07-11 22:07:16 - train: epoch 0110, iter [03300, 05004], lr: 0.001821, loss: 0.9400
2022-07-11 22:07:51 - train: epoch 0110, iter [03400, 05004], lr: 0.001814, loss: 0.9299
2022-07-11 22:08:25 - train: epoch 0110, iter [03500, 05004], lr: 0.001807, loss: 1.3477
2022-07-11 22:08:59 - train: epoch 0110, iter [03600, 05004], lr: 0.001800, loss: 1.0650
2022-07-11 22:09:34 - train: epoch 0110, iter [03700, 05004], lr: 0.001793, loss: 1.1661
2022-07-11 22:10:08 - train: epoch 0110, iter [03800, 05004], lr: 0.001786, loss: 0.9828
2022-07-11 22:10:42 - train: epoch 0110, iter [03900, 05004], lr: 0.001779, loss: 1.0064
2022-07-11 22:11:16 - train: epoch 0110, iter [04000, 05004], lr: 0.001772, loss: 1.1429
2022-07-11 22:11:52 - train: epoch 0110, iter [04100, 05004], lr: 0.001765, loss: 1.1655
2022-07-11 22:12:25 - train: epoch 0110, iter [04200, 05004], lr: 0.001759, loss: 1.0666
2022-07-11 22:13:00 - train: epoch 0110, iter [04300, 05004], lr: 0.001752, loss: 0.9489
2022-07-11 22:13:34 - train: epoch 0110, iter [04400, 05004], lr: 0.001745, loss: 1.0501
2022-07-11 22:14:09 - train: epoch 0110, iter [04500, 05004], lr: 0.001738, loss: 0.8279
2022-07-11 22:14:43 - train: epoch 0110, iter [04600, 05004], lr: 0.001731, loss: 0.9797
2022-07-11 22:15:18 - train: epoch 0110, iter [04700, 05004], lr: 0.001724, loss: 1.0635
2022-07-11 22:15:52 - train: epoch 0110, iter [04800, 05004], lr: 0.001718, loss: 1.1097
2022-07-11 22:16:26 - train: epoch 0110, iter [04900, 05004], lr: 0.001711, loss: 1.0072
2022-07-11 22:16:59 - train: epoch 0110, iter [05000, 05004], lr: 0.001704, loss: 1.2579
2022-07-11 22:17:00 - train: epoch 110, train_loss: 1.0880
2022-07-11 22:18:17 - eval: epoch: 110, acc1: 73.954%, acc5: 91.692%, test_loss: 1.0382, per_image_load_time: 1.929ms, per_image_inference_time: 0.415ms
2022-07-11 22:18:17 - until epoch: 110, best_acc1: 73.954%
2022-07-11 22:18:17 - epoch 111 lr: 0.001704
2022-07-11 22:18:56 - train: epoch 0111, iter [00100, 05004], lr: 0.001697, loss: 1.0144
2022-07-11 22:19:31 - train: epoch 0111, iter [00200, 05004], lr: 0.001690, loss: 1.0440
2022-07-11 22:20:04 - train: epoch 0111, iter [00300, 05004], lr: 0.001683, loss: 1.0113
2022-07-11 22:20:39 - train: epoch 0111, iter [00400, 05004], lr: 0.001677, loss: 1.0784
2022-07-11 22:21:14 - train: epoch 0111, iter [00500, 05004], lr: 0.001670, loss: 0.9282
2022-07-11 22:21:47 - train: epoch 0111, iter [00600, 05004], lr: 0.001663, loss: 1.1031
2022-07-11 22:22:21 - train: epoch 0111, iter [00700, 05004], lr: 0.001657, loss: 1.1980
2022-07-11 22:22:55 - train: epoch 0111, iter [00800, 05004], lr: 0.001650, loss: 1.0799
2022-07-11 22:23:30 - train: epoch 0111, iter [00900, 05004], lr: 0.001643, loss: 1.0373
2022-07-11 22:24:05 - train: epoch 0111, iter [01000, 05004], lr: 0.001637, loss: 1.0322
2022-07-11 22:24:39 - train: epoch 0111, iter [01100, 05004], lr: 0.001630, loss: 1.0159
2022-07-11 22:25:14 - train: epoch 0111, iter [01200, 05004], lr: 0.001623, loss: 0.9302
2022-07-11 22:25:48 - train: epoch 0111, iter [01300, 05004], lr: 0.001617, loss: 1.1441
2022-07-11 22:26:22 - train: epoch 0111, iter [01400, 05004], lr: 0.001610, loss: 1.0084
2022-07-11 22:26:57 - train: epoch 0111, iter [01500, 05004], lr: 0.001604, loss: 1.2568
2022-07-11 22:27:31 - train: epoch 0111, iter [01600, 05004], lr: 0.001597, loss: 1.0537
2022-07-11 22:28:05 - train: epoch 0111, iter [01700, 05004], lr: 0.001591, loss: 1.2019
2022-07-11 22:28:40 - train: epoch 0111, iter [01800, 05004], lr: 0.001584, loss: 1.0624
2022-07-11 22:29:15 - train: epoch 0111, iter [01900, 05004], lr: 0.001577, loss: 0.8908
2022-07-11 22:29:49 - train: epoch 0111, iter [02000, 05004], lr: 0.001571, loss: 0.9957
2022-07-11 22:30:23 - train: epoch 0111, iter [02100, 05004], lr: 0.001564, loss: 1.3752
2022-07-11 22:30:58 - train: epoch 0111, iter [02200, 05004], lr: 0.001558, loss: 1.1611
2022-07-11 22:31:32 - train: epoch 0111, iter [02300, 05004], lr: 0.001551, loss: 0.9919
2022-07-11 22:32:07 - train: epoch 0111, iter [02400, 05004], lr: 0.001545, loss: 0.9722
2022-07-11 22:32:41 - train: epoch 0111, iter [02500, 05004], lr: 0.001539, loss: 1.1781
2022-07-11 22:33:15 - train: epoch 0111, iter [02600, 05004], lr: 0.001532, loss: 1.0307
2022-07-11 22:33:50 - train: epoch 0111, iter [02700, 05004], lr: 0.001526, loss: 1.2132
2022-07-11 22:34:24 - train: epoch 0111, iter [02800, 05004], lr: 0.001519, loss: 0.9975
2022-07-11 22:34:58 - train: epoch 0111, iter [02900, 05004], lr: 0.001513, loss: 0.9014
2022-07-11 22:35:33 - train: epoch 0111, iter [03000, 05004], lr: 0.001507, loss: 1.2184
2022-07-11 22:36:07 - train: epoch 0111, iter [03100, 05004], lr: 0.001500, loss: 1.1397
2022-07-11 22:36:42 - train: epoch 0111, iter [03200, 05004], lr: 0.001494, loss: 1.1128
2022-07-11 22:37:17 - train: epoch 0111, iter [03300, 05004], lr: 0.001487, loss: 1.2319
2022-07-11 22:37:50 - train: epoch 0111, iter [03400, 05004], lr: 0.001481, loss: 1.3340
2022-07-11 22:38:25 - train: epoch 0111, iter [03500, 05004], lr: 0.001475, loss: 1.0463
2022-07-11 22:38:59 - train: epoch 0111, iter [03600, 05004], lr: 0.001469, loss: 1.1573
2022-07-11 22:39:33 - train: epoch 0111, iter [03700, 05004], lr: 0.001462, loss: 1.2126
2022-07-11 22:40:08 - train: epoch 0111, iter [03800, 05004], lr: 0.001456, loss: 1.0051
2022-07-11 22:40:41 - train: epoch 0111, iter [03900, 05004], lr: 0.001450, loss: 0.9643
2022-07-11 22:41:15 - train: epoch 0111, iter [04000, 05004], lr: 0.001443, loss: 1.0029
2022-07-11 22:41:49 - train: epoch 0111, iter [04100, 05004], lr: 0.001437, loss: 1.1275
2022-07-11 22:42:23 - train: epoch 0111, iter [04200, 05004], lr: 0.001431, loss: 1.1661
2022-07-11 22:42:58 - train: epoch 0111, iter [04300, 05004], lr: 0.001425, loss: 1.0925
2022-07-11 22:43:32 - train: epoch 0111, iter [04400, 05004], lr: 0.001419, loss: 1.0917
2022-07-11 22:44:08 - train: epoch 0111, iter [04500, 05004], lr: 0.001412, loss: 1.0376
2022-07-11 22:44:42 - train: epoch 0111, iter [04600, 05004], lr: 0.001406, loss: 0.9481
2022-07-11 22:45:16 - train: epoch 0111, iter [04700, 05004], lr: 0.001400, loss: 1.1089
2022-07-11 22:45:51 - train: epoch 0111, iter [04800, 05004], lr: 0.001394, loss: 1.0267
2022-07-11 22:46:25 - train: epoch 0111, iter [04900, 05004], lr: 0.001388, loss: 0.9912
2022-07-11 22:46:59 - train: epoch 0111, iter [05000, 05004], lr: 0.001382, loss: 1.1202
2022-07-11 22:47:00 - train: epoch 111, train_loss: 1.0719
2022-07-11 22:48:18 - eval: epoch: 111, acc1: 73.952%, acc5: 91.722%, test_loss: 1.0320, per_image_load_time: 2.236ms, per_image_inference_time: 0.389ms
2022-07-11 22:48:18 - until epoch: 111, best_acc1: 73.954%
2022-07-11 22:48:18 - epoch 112 lr: 0.001381
2022-07-11 22:48:58 - train: epoch 0112, iter [00100, 05004], lr: 0.001375, loss: 1.1105
2022-07-11 22:49:33 - train: epoch 0112, iter [00200, 05004], lr: 0.001369, loss: 1.0988
2022-07-11 22:50:08 - train: epoch 0112, iter [00300, 05004], lr: 0.001363, loss: 0.9498
2022-07-11 22:50:43 - train: epoch 0112, iter [00400, 05004], lr: 0.001357, loss: 1.1210
2022-07-11 22:51:17 - train: epoch 0112, iter [00500, 05004], lr: 0.001351, loss: 1.2431
2022-07-11 22:51:52 - train: epoch 0112, iter [00600, 05004], lr: 0.001345, loss: 1.1330
2022-07-11 22:52:27 - train: epoch 0112, iter [00700, 05004], lr: 0.001339, loss: 1.1266
2022-07-11 22:53:01 - train: epoch 0112, iter [00800, 05004], lr: 0.001333, loss: 0.9023
2022-07-11 22:53:36 - train: epoch 0112, iter [00900, 05004], lr: 0.001327, loss: 0.9005
2022-07-11 22:54:10 - train: epoch 0112, iter [01000, 05004], lr: 0.001321, loss: 0.8471
2022-07-11 22:54:46 - train: epoch 0112, iter [01100, 05004], lr: 0.001315, loss: 0.7918
2022-07-11 22:55:21 - train: epoch 0112, iter [01200, 05004], lr: 0.001309, loss: 1.0010
2022-07-11 22:55:55 - train: epoch 0112, iter [01300, 05004], lr: 0.001303, loss: 1.1019
2022-07-11 22:56:30 - train: epoch 0112, iter [01400, 05004], lr: 0.001297, loss: 1.0530
2022-07-11 22:57:05 - train: epoch 0112, iter [01500, 05004], lr: 0.001291, loss: 1.2157
2022-07-11 22:57:40 - train: epoch 0112, iter [01600, 05004], lr: 0.001286, loss: 1.0855
2022-07-11 22:58:15 - train: epoch 0112, iter [01700, 05004], lr: 0.001280, loss: 0.9596
2022-07-11 22:58:50 - train: epoch 0112, iter [01800, 05004], lr: 0.001274, loss: 0.7851
2022-07-11 22:59:25 - train: epoch 0112, iter [01900, 05004], lr: 0.001268, loss: 0.8587
2022-07-11 23:00:00 - train: epoch 0112, iter [02000, 05004], lr: 0.001262, loss: 1.1207
2022-07-11 23:00:35 - train: epoch 0112, iter [02100, 05004], lr: 0.001256, loss: 1.0273
2022-07-11 23:01:10 - train: epoch 0112, iter [02200, 05004], lr: 0.001250, loss: 1.0016
2022-07-11 23:01:45 - train: epoch 0112, iter [02300, 05004], lr: 0.001245, loss: 1.1092
2022-07-11 23:02:20 - train: epoch 0112, iter [02400, 05004], lr: 0.001239, loss: 0.9810
2022-07-11 23:02:55 - train: epoch 0112, iter [02500, 05004], lr: 0.001233, loss: 1.1447
2022-07-11 23:03:30 - train: epoch 0112, iter [02600, 05004], lr: 0.001227, loss: 0.9999
2022-07-11 23:04:04 - train: epoch 0112, iter [02700, 05004], lr: 0.001221, loss: 1.0966
2022-07-11 23:04:39 - train: epoch 0112, iter [02800, 05004], lr: 0.001216, loss: 0.9742
2022-07-11 23:05:14 - train: epoch 0112, iter [02900, 05004], lr: 0.001210, loss: 1.2353
2022-07-11 23:05:50 - train: epoch 0112, iter [03000, 05004], lr: 0.001204, loss: 1.2018
2022-07-11 23:06:24 - train: epoch 0112, iter [03100, 05004], lr: 0.001199, loss: 0.8798
2022-07-11 23:06:59 - train: epoch 0112, iter [03200, 05004], lr: 0.001193, loss: 1.2013
2022-07-11 23:07:33 - train: epoch 0112, iter [03300, 05004], lr: 0.001187, loss: 0.8862
2022-07-11 23:08:08 - train: epoch 0112, iter [03400, 05004], lr: 0.001182, loss: 1.0721
2022-07-11 23:08:42 - train: epoch 0112, iter [03500, 05004], lr: 0.001176, loss: 0.9817
2022-07-11 23:09:17 - train: epoch 0112, iter [03600, 05004], lr: 0.001170, loss: 1.1028
2022-07-11 23:09:51 - train: epoch 0112, iter [03700, 05004], lr: 0.001165, loss: 1.1327
2022-07-11 23:10:26 - train: epoch 0112, iter [03800, 05004], lr: 0.001159, loss: 1.0952
2022-07-11 23:11:00 - train: epoch 0112, iter [03900, 05004], lr: 0.001153, loss: 0.9271
2022-07-11 23:11:35 - train: epoch 0112, iter [04000, 05004], lr: 0.001148, loss: 1.0370
2022-07-11 23:12:09 - train: epoch 0112, iter [04100, 05004], lr: 0.001142, loss: 0.9055
2022-07-11 23:12:44 - train: epoch 0112, iter [04200, 05004], lr: 0.001137, loss: 1.0288
2022-07-11 23:13:17 - train: epoch 0112, iter [04300, 05004], lr: 0.001131, loss: 0.9417
2022-07-11 23:13:52 - train: epoch 0112, iter [04400, 05004], lr: 0.001126, loss: 1.3188
2022-07-11 23:14:27 - train: epoch 0112, iter [04500, 05004], lr: 0.001120, loss: 1.0121
2022-07-11 23:15:01 - train: epoch 0112, iter [04600, 05004], lr: 0.001115, loss: 1.1428
2022-07-11 23:15:35 - train: epoch 0112, iter [04700, 05004], lr: 0.001109, loss: 1.1225
2022-07-11 23:16:09 - train: epoch 0112, iter [04800, 05004], lr: 0.001104, loss: 1.0746
2022-07-11 23:16:44 - train: epoch 0112, iter [04900, 05004], lr: 0.001098, loss: 0.7324
2022-07-11 23:17:16 - train: epoch 0112, iter [05000, 05004], lr: 0.001093, loss: 1.0537
2022-07-11 23:17:17 - train: epoch 112, train_loss: 1.0590
2022-07-11 23:18:32 - eval: epoch: 112, acc1: 74.224%, acc5: 91.904%, test_loss: 1.0254, per_image_load_time: 2.498ms, per_image_inference_time: 0.365ms
2022-07-11 23:18:32 - until epoch: 112, best_acc1: 74.224%
2022-07-11 23:18:32 - epoch 113 lr: 0.001093
2022-07-11 23:19:12 - train: epoch 0113, iter [00100, 05004], lr: 0.001087, loss: 1.0472
2022-07-11 23:19:45 - train: epoch 0113, iter [00200, 05004], lr: 0.001082, loss: 0.8999
2022-07-11 23:20:20 - train: epoch 0113, iter [00300, 05004], lr: 0.001076, loss: 1.0278
2022-07-11 23:20:53 - train: epoch 0113, iter [00400, 05004], lr: 0.001071, loss: 1.0477
2022-07-11 23:21:28 - train: epoch 0113, iter [00500, 05004], lr: 0.001066, loss: 1.0064
2022-07-11 23:22:02 - train: epoch 0113, iter [00600, 05004], lr: 0.001060, loss: 1.1782
2022-07-11 23:22:36 - train: epoch 0113, iter [00700, 05004], lr: 0.001055, loss: 1.0186
2022-07-11 23:23:09 - train: epoch 0113, iter [00800, 05004], lr: 0.001050, loss: 1.1331
2022-07-11 23:23:43 - train: epoch 0113, iter [00900, 05004], lr: 0.001044, loss: 1.1746
2022-07-11 23:24:18 - train: epoch 0113, iter [01000, 05004], lr: 0.001039, loss: 1.0074
2022-07-11 23:24:51 - train: epoch 0113, iter [01100, 05004], lr: 0.001034, loss: 1.1946
2022-07-11 23:25:25 - train: epoch 0113, iter [01200, 05004], lr: 0.001028, loss: 1.0175
2022-07-11 23:26:00 - train: epoch 0113, iter [01300, 05004], lr: 0.001023, loss: 0.9520
2022-07-11 23:26:33 - train: epoch 0113, iter [01400, 05004], lr: 0.001018, loss: 0.9779
2022-07-11 23:27:07 - train: epoch 0113, iter [01500, 05004], lr: 0.001013, loss: 1.0502
2022-07-11 23:27:41 - train: epoch 0113, iter [01600, 05004], lr: 0.001007, loss: 1.0406
2022-07-11 23:28:15 - train: epoch 0113, iter [01700, 05004], lr: 0.001002, loss: 0.9892
2022-07-11 23:28:48 - train: epoch 0113, iter [01800, 05004], lr: 0.000997, loss: 1.0198
2022-07-11 23:29:23 - train: epoch 0113, iter [01900, 05004], lr: 0.000992, loss: 0.9661
2022-07-11 23:29:56 - train: epoch 0113, iter [02000, 05004], lr: 0.000987, loss: 0.9850
2022-07-11 23:30:30 - train: epoch 0113, iter [02100, 05004], lr: 0.000981, loss: 0.9977
2022-07-11 23:31:04 - train: epoch 0113, iter [02200, 05004], lr: 0.000976, loss: 1.0954
2022-07-11 23:31:38 - train: epoch 0113, iter [02300, 05004], lr: 0.000971, loss: 1.0117
2022-07-11 23:32:12 - train: epoch 0113, iter [02400, 05004], lr: 0.000966, loss: 1.0169
2022-07-11 23:32:46 - train: epoch 0113, iter [02500, 05004], lr: 0.000961, loss: 1.0942
2022-07-11 23:33:20 - train: epoch 0113, iter [02600, 05004], lr: 0.000956, loss: 1.1080
2022-07-11 23:33:54 - train: epoch 0113, iter [02700, 05004], lr: 0.000951, loss: 1.0414
2022-07-11 23:34:28 - train: epoch 0113, iter [02800, 05004], lr: 0.000946, loss: 1.0304
2022-07-11 23:35:02 - train: epoch 0113, iter [02900, 05004], lr: 0.000941, loss: 0.9153
2022-07-11 23:35:35 - train: epoch 0113, iter [03000, 05004], lr: 0.000935, loss: 0.9699
2022-07-11 23:36:09 - train: epoch 0113, iter [03100, 05004], lr: 0.000930, loss: 0.9070
2022-07-11 23:36:43 - train: epoch 0113, iter [03200, 05004], lr: 0.000925, loss: 0.8623
2022-07-11 23:37:17 - train: epoch 0113, iter [03300, 05004], lr: 0.000920, loss: 0.9582
2022-07-11 23:37:50 - train: epoch 0113, iter [03400, 05004], lr: 0.000915, loss: 0.9857
2022-07-11 23:38:24 - train: epoch 0113, iter [03500, 05004], lr: 0.000910, loss: 1.0272
2022-07-11 23:38:58 - train: epoch 0113, iter [03600, 05004], lr: 0.000906, loss: 1.1236
2022-07-11 23:39:32 - train: epoch 0113, iter [03700, 05004], lr: 0.000901, loss: 0.8329
2022-07-11 23:40:06 - train: epoch 0113, iter [03800, 05004], lr: 0.000896, loss: 1.0777
2022-07-11 23:40:40 - train: epoch 0113, iter [03900, 05004], lr: 0.000891, loss: 1.0606
2022-07-11 23:41:15 - train: epoch 0113, iter [04000, 05004], lr: 0.000886, loss: 1.1303
2022-07-11 23:41:48 - train: epoch 0113, iter [04100, 05004], lr: 0.000881, loss: 1.0151
2022-07-11 23:42:25 - train: epoch 0113, iter [04200, 05004], lr: 0.000876, loss: 1.2221
2022-07-11 23:42:58 - train: epoch 0113, iter [04300, 05004], lr: 0.000871, loss: 0.9430
2022-07-11 23:43:33 - train: epoch 0113, iter [04400, 05004], lr: 0.000866, loss: 0.9385
2022-07-11 23:44:08 - train: epoch 0113, iter [04500, 05004], lr: 0.000861, loss: 1.1437
2022-07-11 23:44:43 - train: epoch 0113, iter [04600, 05004], lr: 0.000857, loss: 0.9829
2022-07-11 23:45:17 - train: epoch 0113, iter [04700, 05004], lr: 0.000852, loss: 0.9885
2022-07-11 23:45:53 - train: epoch 0113, iter [04800, 05004], lr: 0.000847, loss: 1.1114
2022-07-11 23:46:28 - train: epoch 0113, iter [04900, 05004], lr: 0.000842, loss: 1.0756
2022-07-11 23:47:01 - train: epoch 0113, iter [05000, 05004], lr: 0.000837, loss: 0.9020
2022-07-11 23:47:02 - train: epoch 113, train_loss: 1.0478
2022-07-11 23:48:19 - eval: epoch: 113, acc1: 74.336%, acc5: 92.028%, test_loss: 1.0190, per_image_load_time: 2.552ms, per_image_inference_time: 0.416ms
2022-07-11 23:48:19 - until epoch: 113, best_acc1: 74.336%
2022-07-11 23:48:19 - epoch 114 lr: 0.000837
2022-07-11 23:48:59 - train: epoch 0114, iter [00100, 05004], lr: 0.000832, loss: 1.2151
2022-07-11 23:49:34 - train: epoch 0114, iter [00200, 05004], lr: 0.000828, loss: 1.1114
2022-07-11 23:50:09 - train: epoch 0114, iter [00300, 05004], lr: 0.000823, loss: 1.0022
2022-07-11 23:50:43 - train: epoch 0114, iter [00400, 05004], lr: 0.000818, loss: 1.2404
2022-07-11 23:51:17 - train: epoch 0114, iter [00500, 05004], lr: 0.000814, loss: 1.0553
2022-07-11 23:51:53 - train: epoch 0114, iter [00600, 05004], lr: 0.000809, loss: 1.0751
2022-07-11 23:52:27 - train: epoch 0114, iter [00700, 05004], lr: 0.000804, loss: 0.9780
2022-07-11 23:53:01 - train: epoch 0114, iter [00800, 05004], lr: 0.000800, loss: 0.9355
2022-07-11 23:53:36 - train: epoch 0114, iter [00900, 05004], lr: 0.000795, loss: 0.7379
2022-07-11 23:54:11 - train: epoch 0114, iter [01000, 05004], lr: 0.000790, loss: 0.9344
2022-07-11 23:54:45 - train: epoch 0114, iter [01100, 05004], lr: 0.000786, loss: 1.0589
2022-07-11 23:55:20 - train: epoch 0114, iter [01200, 05004], lr: 0.000781, loss: 1.0699
2022-07-11 23:55:55 - train: epoch 0114, iter [01300, 05004], lr: 0.000776, loss: 0.9549
2022-07-11 23:56:29 - train: epoch 0114, iter [01400, 05004], lr: 0.000772, loss: 1.1094
2022-07-11 23:57:04 - train: epoch 0114, iter [01500, 05004], lr: 0.000767, loss: 0.9413
2022-07-11 23:57:39 - train: epoch 0114, iter [01600, 05004], lr: 0.000763, loss: 1.0011
2022-07-11 23:58:13 - train: epoch 0114, iter [01700, 05004], lr: 0.000758, loss: 0.9551
2022-07-11 23:58:48 - train: epoch 0114, iter [01800, 05004], lr: 0.000754, loss: 1.0047
2022-07-11 23:59:22 - train: epoch 0114, iter [01900, 05004], lr: 0.000749, loss: 0.9034
2022-07-11 23:59:57 - train: epoch 0114, iter [02000, 05004], lr: 0.000745, loss: 0.9903
2022-07-12 00:00:31 - train: epoch 0114, iter [02100, 05004], lr: 0.000740, loss: 0.9568
2022-07-12 00:01:07 - train: epoch 0114, iter [02200, 05004], lr: 0.000736, loss: 1.0728
2022-07-12 00:01:42 - train: epoch 0114, iter [02300, 05004], lr: 0.000731, loss: 1.1354
2022-07-12 00:02:16 - train: epoch 0114, iter [02400, 05004], lr: 0.000727, loss: 1.0891
2022-07-12 00:02:51 - train: epoch 0114, iter [02500, 05004], lr: 0.000722, loss: 1.1164
2022-07-12 00:03:25 - train: epoch 0114, iter [02600, 05004], lr: 0.000718, loss: 1.0554
2022-07-12 00:04:00 - train: epoch 0114, iter [02700, 05004], lr: 0.000713, loss: 0.9756
2022-07-12 00:04:34 - train: epoch 0114, iter [02800, 05004], lr: 0.000709, loss: 1.0368
2022-07-12 00:05:09 - train: epoch 0114, iter [02900, 05004], lr: 0.000705, loss: 0.9692
2022-07-12 00:05:43 - train: epoch 0114, iter [03000, 05004], lr: 0.000700, loss: 0.8163
2022-07-12 00:06:18 - train: epoch 0114, iter [03100, 05004], lr: 0.000696, loss: 1.1025
2022-07-12 00:06:53 - train: epoch 0114, iter [03200, 05004], lr: 0.000692, loss: 1.0852
2022-07-12 00:07:28 - train: epoch 0114, iter [03300, 05004], lr: 0.000687, loss: 1.1847
2022-07-12 00:08:03 - train: epoch 0114, iter [03400, 05004], lr: 0.000683, loss: 0.9447
2022-07-12 00:08:38 - train: epoch 0114, iter [03500, 05004], lr: 0.000679, loss: 0.9251
2022-07-12 00:09:12 - train: epoch 0114, iter [03600, 05004], lr: 0.000674, loss: 0.9668
2022-07-12 00:09:48 - train: epoch 0114, iter [03700, 05004], lr: 0.000670, loss: 0.9503
2022-07-12 00:10:23 - train: epoch 0114, iter [03800, 05004], lr: 0.000666, loss: 1.1315
2022-07-12 00:10:57 - train: epoch 0114, iter [03900, 05004], lr: 0.000662, loss: 0.9876
2022-07-12 00:11:32 - train: epoch 0114, iter [04000, 05004], lr: 0.000657, loss: 1.0392
2022-07-12 00:12:07 - train: epoch 0114, iter [04100, 05004], lr: 0.000653, loss: 1.0764
2022-07-12 00:12:42 - train: epoch 0114, iter [04200, 05004], lr: 0.000649, loss: 1.1102
2022-07-12 00:13:17 - train: epoch 0114, iter [04300, 05004], lr: 0.000645, loss: 1.0651
2022-07-12 00:13:51 - train: epoch 0114, iter [04400, 05004], lr: 0.000641, loss: 1.2697
2022-07-12 00:14:26 - train: epoch 0114, iter [04500, 05004], lr: 0.000636, loss: 1.0459
2022-07-12 00:15:01 - train: epoch 0114, iter [04600, 05004], lr: 0.000632, loss: 1.1914
2022-07-12 00:15:36 - train: epoch 0114, iter [04700, 05004], lr: 0.000628, loss: 1.0261
2022-07-12 00:16:11 - train: epoch 0114, iter [04800, 05004], lr: 0.000624, loss: 1.2311
2022-07-12 00:16:45 - train: epoch 0114, iter [04900, 05004], lr: 0.000620, loss: 1.0371
2022-07-12 00:17:18 - train: epoch 0114, iter [05000, 05004], lr: 0.000616, loss: 1.0275
2022-07-12 00:17:19 - train: epoch 114, train_loss: 1.0363
2022-07-12 00:18:36 - eval: epoch: 114, acc1: 74.552%, acc5: 91.954%, test_loss: 1.0150, per_image_load_time: 2.610ms, per_image_inference_time: 0.377ms
2022-07-12 00:18:36 - until epoch: 114, best_acc1: 74.552%
2022-07-12 00:18:36 - epoch 115 lr: 0.000616
2022-07-12 00:19:16 - train: epoch 0115, iter [00100, 05004], lr: 0.000611, loss: 1.0233
2022-07-12 00:19:50 - train: epoch 0115, iter [00200, 05004], lr: 0.000607, loss: 1.0501
2022-07-12 00:20:25 - train: epoch 0115, iter [00300, 05004], lr: 0.000603, loss: 1.0884
2022-07-12 00:20:59 - train: epoch 0115, iter [00400, 05004], lr: 0.000599, loss: 0.9090
2022-07-12 00:21:33 - train: epoch 0115, iter [00500, 05004], lr: 0.000595, loss: 0.8646
2022-07-12 00:22:07 - train: epoch 0115, iter [00600, 05004], lr: 0.000591, loss: 1.1047
2022-07-12 00:22:42 - train: epoch 0115, iter [00700, 05004], lr: 0.000587, loss: 1.0597
2022-07-12 00:23:16 - train: epoch 0115, iter [00800, 05004], lr: 0.000583, loss: 0.8881
2022-07-12 00:23:52 - train: epoch 0115, iter [00900, 05004], lr: 0.000579, loss: 1.1644
2022-07-12 00:24:26 - train: epoch 0115, iter [01000, 05004], lr: 0.000575, loss: 0.7982
2022-07-12 00:25:00 - train: epoch 0115, iter [01100, 05004], lr: 0.000571, loss: 0.8747
2022-07-12 00:25:34 - train: epoch 0115, iter [01200, 05004], lr: 0.000567, loss: 1.0219
2022-07-12 00:26:09 - train: epoch 0115, iter [01300, 05004], lr: 0.000564, loss: 1.2462
2022-07-12 00:26:44 - train: epoch 0115, iter [01400, 05004], lr: 0.000560, loss: 1.1916
2022-07-12 00:27:19 - train: epoch 0115, iter [01500, 05004], lr: 0.000556, loss: 1.2064
2022-07-12 00:27:53 - train: epoch 0115, iter [01600, 05004], lr: 0.000552, loss: 0.9387
2022-07-12 00:28:28 - train: epoch 0115, iter [01700, 05004], lr: 0.000548, loss: 1.1736
2022-07-12 00:29:02 - train: epoch 0115, iter [01800, 05004], lr: 0.000544, loss: 0.9330
2022-07-12 00:29:37 - train: epoch 0115, iter [01900, 05004], lr: 0.000540, loss: 1.0409
2022-07-12 00:30:12 - train: epoch 0115, iter [02000, 05004], lr: 0.000536, loss: 1.0331
2022-07-12 00:30:46 - train: epoch 0115, iter [02100, 05004], lr: 0.000533, loss: 1.0571
2022-07-12 00:31:21 - train: epoch 0115, iter [02200, 05004], lr: 0.000529, loss: 1.1600
2022-07-12 00:31:54 - train: epoch 0115, iter [02300, 05004], lr: 0.000525, loss: 1.1889
2022-07-12 00:32:28 - train: epoch 0115, iter [02400, 05004], lr: 0.000521, loss: 1.0750
2022-07-12 00:33:02 - train: epoch 0115, iter [02500, 05004], lr: 0.000518, loss: 0.8520
2022-07-12 00:33:37 - train: epoch 0115, iter [02600, 05004], lr: 0.000514, loss: 1.0955
2022-07-12 00:34:11 - train: epoch 0115, iter [02700, 05004], lr: 0.000510, loss: 0.8610
2022-07-12 00:34:46 - train: epoch 0115, iter [02800, 05004], lr: 0.000506, loss: 0.9419
2022-07-12 00:35:21 - train: epoch 0115, iter [02900, 05004], lr: 0.000503, loss: 1.1133
2022-07-12 00:35:55 - train: epoch 0115, iter [03000, 05004], lr: 0.000499, loss: 0.7822
2022-07-12 00:36:30 - train: epoch 0115, iter [03100, 05004], lr: 0.000495, loss: 1.1365
2022-07-12 00:37:04 - train: epoch 0115, iter [03200, 05004], lr: 0.000492, loss: 1.1635
2022-07-12 00:37:39 - train: epoch 0115, iter [03300, 05004], lr: 0.000488, loss: 1.0768
2022-07-12 00:38:14 - train: epoch 0115, iter [03400, 05004], lr: 0.000484, loss: 0.9368
2022-07-12 00:38:48 - train: epoch 0115, iter [03500, 05004], lr: 0.000481, loss: 0.9193
2022-07-12 00:39:22 - train: epoch 0115, iter [03600, 05004], lr: 0.000477, loss: 1.0230
2022-07-12 00:39:57 - train: epoch 0115, iter [03700, 05004], lr: 0.000473, loss: 0.9343
2022-07-12 00:40:31 - train: epoch 0115, iter [03800, 05004], lr: 0.000470, loss: 1.1031
2022-07-12 00:41:05 - train: epoch 0115, iter [03900, 05004], lr: 0.000466, loss: 0.9627
2022-07-12 00:41:39 - train: epoch 0115, iter [04000, 05004], lr: 0.000463, loss: 1.0320
2022-07-12 00:42:13 - train: epoch 0115, iter [04100, 05004], lr: 0.000459, loss: 0.9586
2022-07-12 00:42:48 - train: epoch 0115, iter [04200, 05004], lr: 0.000456, loss: 1.0194
2022-07-12 00:43:22 - train: epoch 0115, iter [04300, 05004], lr: 0.000452, loss: 0.9917
2022-07-12 00:43:56 - train: epoch 0115, iter [04400, 05004], lr: 0.000449, loss: 1.0070
2022-07-12 00:44:30 - train: epoch 0115, iter [04500, 05004], lr: 0.000445, loss: 1.1176
2022-07-12 00:45:05 - train: epoch 0115, iter [04600, 05004], lr: 0.000442, loss: 0.8349
2022-07-12 00:45:38 - train: epoch 0115, iter [04700, 05004], lr: 0.000438, loss: 1.0387
2022-07-12 00:46:13 - train: epoch 0115, iter [04800, 05004], lr: 0.000435, loss: 1.1843
2022-07-12 00:46:47 - train: epoch 0115, iter [04900, 05004], lr: 0.000431, loss: 0.9829
2022-07-12 00:47:20 - train: epoch 0115, iter [05000, 05004], lr: 0.000428, loss: 0.9711
2022-07-12 00:47:21 - train: epoch 115, train_loss: 1.0285
2022-07-12 00:48:37 - eval: epoch: 115, acc1: 74.606%, acc5: 92.032%, test_loss: 1.0097, per_image_load_time: 2.557ms, per_image_inference_time: 0.360ms
2022-07-12 00:48:37 - until epoch: 115, best_acc1: 74.606%
2022-07-12 00:48:37 - epoch 116 lr: 0.000428
2022-07-12 00:49:17 - train: epoch 0116, iter [00100, 05004], lr: 0.000424, loss: 0.9595
2022-07-12 00:49:51 - train: epoch 0116, iter [00200, 05004], lr: 0.000421, loss: 0.9847
2022-07-12 00:50:26 - train: epoch 0116, iter [00300, 05004], lr: 0.000418, loss: 0.8751
2022-07-12 00:51:00 - train: epoch 0116, iter [00400, 05004], lr: 0.000414, loss: 1.0650
2022-07-12 00:51:35 - train: epoch 0116, iter [00500, 05004], lr: 0.000411, loss: 0.9761
2022-07-12 00:52:08 - train: epoch 0116, iter [00600, 05004], lr: 0.000408, loss: 1.0083
2022-07-12 00:52:43 - train: epoch 0116, iter [00700, 05004], lr: 0.000404, loss: 1.0849
2022-07-12 00:53:17 - train: epoch 0116, iter [00800, 05004], lr: 0.000401, loss: 0.9861
2022-07-12 00:53:51 - train: epoch 0116, iter [00900, 05004], lr: 0.000398, loss: 1.1368
2022-07-12 00:54:26 - train: epoch 0116, iter [01000, 05004], lr: 0.000394, loss: 1.0145
2022-07-12 00:55:00 - train: epoch 0116, iter [01100, 05004], lr: 0.000391, loss: 1.0623
2022-07-12 00:55:35 - train: epoch 0116, iter [01200, 05004], lr: 0.000388, loss: 0.9517
2022-07-12 00:56:09 - train: epoch 0116, iter [01300, 05004], lr: 0.000385, loss: 1.1379
2022-07-12 00:56:44 - train: epoch 0116, iter [01400, 05004], lr: 0.000381, loss: 1.1376
2022-07-12 00:57:18 - train: epoch 0116, iter [01500, 05004], lr: 0.000378, loss: 0.9240
2022-07-12 00:57:53 - train: epoch 0116, iter [01600, 05004], lr: 0.000375, loss: 0.8654
2022-07-12 00:58:27 - train: epoch 0116, iter [01700, 05004], lr: 0.000372, loss: 1.0105
2022-07-12 00:59:01 - train: epoch 0116, iter [01800, 05004], lr: 0.000368, loss: 1.0475
2022-07-12 00:59:36 - train: epoch 0116, iter [01900, 05004], lr: 0.000365, loss: 0.7873
2022-07-12 01:00:10 - train: epoch 0116, iter [02000, 05004], lr: 0.000362, loss: 1.0116
2022-07-12 01:00:44 - train: epoch 0116, iter [02100, 05004], lr: 0.000359, loss: 0.9738
2022-07-12 01:01:18 - train: epoch 0116, iter [02200, 05004], lr: 0.000356, loss: 1.0195
2022-07-12 01:01:53 - train: epoch 0116, iter [02300, 05004], lr: 0.000353, loss: 1.1386
2022-07-12 01:02:27 - train: epoch 0116, iter [02400, 05004], lr: 0.000350, loss: 1.0671
2022-07-12 01:03:02 - train: epoch 0116, iter [02500, 05004], lr: 0.000347, loss: 0.8710
2022-07-12 01:03:36 - train: epoch 0116, iter [02600, 05004], lr: 0.000344, loss: 1.0880
2022-07-12 01:04:10 - train: epoch 0116, iter [02700, 05004], lr: 0.000341, loss: 1.0454
2022-07-12 01:04:45 - train: epoch 0116, iter [02800, 05004], lr: 0.000337, loss: 1.0984
2022-07-12 01:05:20 - train: epoch 0116, iter [02900, 05004], lr: 0.000334, loss: 1.1907
2022-07-12 01:05:53 - train: epoch 0116, iter [03000, 05004], lr: 0.000331, loss: 0.9799
2022-07-12 01:06:28 - train: epoch 0116, iter [03100, 05004], lr: 0.000328, loss: 1.1249
2022-07-12 01:07:02 - train: epoch 0116, iter [03200, 05004], lr: 0.000325, loss: 1.0967
2022-07-12 01:07:38 - train: epoch 0116, iter [03300, 05004], lr: 0.000322, loss: 1.1520
2022-07-12 01:08:10 - train: epoch 0116, iter [03400, 05004], lr: 0.000320, loss: 0.8569
2022-07-12 01:08:45 - train: epoch 0116, iter [03500, 05004], lr: 0.000317, loss: 1.0747
2022-07-12 01:09:19 - train: epoch 0116, iter [03600, 05004], lr: 0.000314, loss: 1.2021
2022-07-12 01:09:54 - train: epoch 0116, iter [03700, 05004], lr: 0.000311, loss: 0.8226
2022-07-12 01:10:28 - train: epoch 0116, iter [03800, 05004], lr: 0.000308, loss: 0.8809
2022-07-12 01:11:02 - train: epoch 0116, iter [03900, 05004], lr: 0.000305, loss: 1.1814
2022-07-12 01:11:36 - train: epoch 0116, iter [04000, 05004], lr: 0.000302, loss: 1.0396
2022-07-12 01:12:11 - train: epoch 0116, iter [04100, 05004], lr: 0.000299, loss: 1.0900
2022-07-12 01:12:46 - train: epoch 0116, iter [04200, 05004], lr: 0.000296, loss: 0.8577
2022-07-12 01:13:20 - train: epoch 0116, iter [04300, 05004], lr: 0.000293, loss: 1.0517
2022-07-12 01:13:54 - train: epoch 0116, iter [04400, 05004], lr: 0.000291, loss: 0.8802
2022-07-12 01:14:29 - train: epoch 0116, iter [04500, 05004], lr: 0.000288, loss: 0.9699
2022-07-12 01:15:03 - train: epoch 0116, iter [04600, 05004], lr: 0.000285, loss: 1.2798
2022-07-12 01:15:38 - train: epoch 0116, iter [04700, 05004], lr: 0.000282, loss: 0.9902
2022-07-12 01:16:11 - train: epoch 0116, iter [04800, 05004], lr: 0.000280, loss: 0.9205
2022-07-12 01:16:46 - train: epoch 0116, iter [04900, 05004], lr: 0.000277, loss: 1.0148
2022-07-12 01:17:19 - train: epoch 0116, iter [05000, 05004], lr: 0.000274, loss: 1.0191
2022-07-12 01:17:20 - train: epoch 116, train_loss: 1.0242
2022-07-12 01:18:36 - eval: epoch: 116, acc1: 74.708%, acc5: 92.020%, test_loss: 1.0073, per_image_load_time: 2.590ms, per_image_inference_time: 0.360ms
2022-07-12 01:18:37 - until epoch: 116, best_acc1: 74.708%
2022-07-12 01:18:37 - epoch 117 lr: 0.000274
2022-07-12 01:19:16 - train: epoch 0117, iter [00100, 05004], lr: 0.000271, loss: 1.2383
2022-07-12 01:19:51 - train: epoch 0117, iter [00200, 05004], lr: 0.000268, loss: 1.0544
2022-07-12 01:20:24 - train: epoch 0117, iter [00300, 05004], lr: 0.000266, loss: 1.1093
2022-07-12 01:20:59 - train: epoch 0117, iter [00400, 05004], lr: 0.000263, loss: 0.9311
2022-07-12 01:21:32 - train: epoch 0117, iter [00500, 05004], lr: 0.000260, loss: 1.0128
2022-07-12 01:22:07 - train: epoch 0117, iter [00600, 05004], lr: 0.000258, loss: 1.0557
2022-07-12 01:22:41 - train: epoch 0117, iter [00700, 05004], lr: 0.000255, loss: 1.0097
2022-07-12 01:23:15 - train: epoch 0117, iter [00800, 05004], lr: 0.000252, loss: 1.0556
2022-07-12 01:23:50 - train: epoch 0117, iter [00900, 05004], lr: 0.000250, loss: 1.1054
2022-07-12 01:24:24 - train: epoch 0117, iter [01000, 05004], lr: 0.000247, loss: 0.8200
2022-07-12 01:24:59 - train: epoch 0117, iter [01100, 05004], lr: 0.000245, loss: 1.1256
2022-07-12 01:25:33 - train: epoch 0117, iter [01200, 05004], lr: 0.000242, loss: 1.1380
2022-07-12 01:26:06 - train: epoch 0117, iter [01300, 05004], lr: 0.000240, loss: 1.1239
2022-07-12 01:26:41 - train: epoch 0117, iter [01400, 05004], lr: 0.000237, loss: 1.0050
2022-07-12 01:27:15 - train: epoch 0117, iter [01500, 05004], lr: 0.000234, loss: 0.9603
2022-07-12 01:27:50 - train: epoch 0117, iter [01600, 05004], lr: 0.000232, loss: 0.8977
2022-07-12 01:28:24 - train: epoch 0117, iter [01700, 05004], lr: 0.000229, loss: 1.0974
2022-07-12 01:28:58 - train: epoch 0117, iter [01800, 05004], lr: 0.000227, loss: 1.0200
2022-07-12 01:29:33 - train: epoch 0117, iter [01900, 05004], lr: 0.000224, loss: 0.7846
2022-07-12 01:30:07 - train: epoch 0117, iter [02000, 05004], lr: 0.000222, loss: 0.9806
2022-07-12 01:30:42 - train: epoch 0117, iter [02100, 05004], lr: 0.000219, loss: 1.1810
2022-07-12 01:31:16 - train: epoch 0117, iter [02200, 05004], lr: 0.000217, loss: 0.9495
2022-07-12 01:31:51 - train: epoch 0117, iter [02300, 05004], lr: 0.000215, loss: 1.0095
2022-07-12 01:32:26 - train: epoch 0117, iter [02400, 05004], lr: 0.000212, loss: 0.9507
2022-07-12 01:33:00 - train: epoch 0117, iter [02500, 05004], lr: 0.000210, loss: 1.0250
2022-07-12 01:33:35 - train: epoch 0117, iter [02600, 05004], lr: 0.000207, loss: 0.8517
2022-07-12 01:34:10 - train: epoch 0117, iter [02700, 05004], lr: 0.000205, loss: 1.1029
2022-07-12 01:34:44 - train: epoch 0117, iter [02800, 05004], lr: 0.000203, loss: 0.8713
2022-07-12 01:35:19 - train: epoch 0117, iter [02900, 05004], lr: 0.000200, loss: 1.0370
2022-07-12 01:35:54 - train: epoch 0117, iter [03000, 05004], lr: 0.000198, loss: 0.9102
2022-07-12 01:36:27 - train: epoch 0117, iter [03100, 05004], lr: 0.000196, loss: 1.0748
2022-07-12 01:37:02 - train: epoch 0117, iter [03200, 05004], lr: 0.000193, loss: 1.0542
2022-07-12 01:37:36 - train: epoch 0117, iter [03300, 05004], lr: 0.000191, loss: 0.8736
2022-07-12 01:38:11 - train: epoch 0117, iter [03400, 05004], lr: 0.000189, loss: 1.0071
2022-07-12 01:38:45 - train: epoch 0117, iter [03500, 05004], lr: 0.000187, loss: 1.1358
2022-07-12 01:39:20 - train: epoch 0117, iter [03600, 05004], lr: 0.000184, loss: 1.0373
2022-07-12 01:39:53 - train: epoch 0117, iter [03700, 05004], lr: 0.000182, loss: 1.0016
2022-07-12 01:40:28 - train: epoch 0117, iter [03800, 05004], lr: 0.000180, loss: 1.0707
2022-07-12 01:41:03 - train: epoch 0117, iter [03900, 05004], lr: 0.000178, loss: 1.0189
2022-07-12 01:41:37 - train: epoch 0117, iter [04000, 05004], lr: 0.000175, loss: 0.8737
2022-07-12 01:42:12 - train: epoch 0117, iter [04100, 05004], lr: 0.000173, loss: 1.0560
2022-07-12 01:42:45 - train: epoch 0117, iter [04200, 05004], lr: 0.000171, loss: 1.1186
2022-07-12 01:43:21 - train: epoch 0117, iter [04300, 05004], lr: 0.000169, loss: 0.9045
2022-07-12 01:43:54 - train: epoch 0117, iter [04400, 05004], lr: 0.000167, loss: 1.0150
2022-07-12 01:44:29 - train: epoch 0117, iter [04500, 05004], lr: 0.000165, loss: 1.0953
2022-07-12 01:45:04 - train: epoch 0117, iter [04600, 05004], lr: 0.000163, loss: 1.0184
2022-07-12 01:45:38 - train: epoch 0117, iter [04700, 05004], lr: 0.000160, loss: 1.0253
2022-07-12 01:46:12 - train: epoch 0117, iter [04800, 05004], lr: 0.000158, loss: 0.9759
2022-07-12 01:46:46 - train: epoch 0117, iter [04900, 05004], lr: 0.000156, loss: 1.0340
2022-07-12 01:47:19 - train: epoch 0117, iter [05000, 05004], lr: 0.000154, loss: 1.0304
2022-07-12 01:47:20 - train: epoch 117, train_loss: 1.0153
2022-07-12 01:48:36 - eval: epoch: 117, acc1: 74.694%, acc5: 92.070%, test_loss: 1.0061, per_image_load_time: 2.593ms, per_image_inference_time: 0.361ms
2022-07-12 01:48:36 - until epoch: 117, best_acc1: 74.708%
2022-07-12 01:48:36 - epoch 118 lr: 0.000154
2022-07-12 01:49:17 - train: epoch 0118, iter [00100, 05004], lr: 0.000152, loss: 1.0895
2022-07-12 01:49:51 - train: epoch 0118, iter [00200, 05004], lr: 0.000150, loss: 1.0711
2022-07-12 01:50:25 - train: epoch 0118, iter [00300, 05004], lr: 0.000148, loss: 1.2599
2022-07-12 01:50:59 - train: epoch 0118, iter [00400, 05004], lr: 0.000146, loss: 1.1853
2022-07-12 01:51:33 - train: epoch 0118, iter [00500, 05004], lr: 0.000144, loss: 0.9795
2022-07-12 01:52:06 - train: epoch 0118, iter [00600, 05004], lr: 0.000142, loss: 0.9040
2022-07-12 01:52:40 - train: epoch 0118, iter [00700, 05004], lr: 0.000140, loss: 1.1139
2022-07-12 01:53:14 - train: epoch 0118, iter [00800, 05004], lr: 0.000138, loss: 1.0089
2022-07-12 01:53:49 - train: epoch 0118, iter [00900, 05004], lr: 0.000136, loss: 0.8787
2022-07-12 01:54:22 - train: epoch 0118, iter [01000, 05004], lr: 0.000134, loss: 1.0048
2022-07-12 01:54:56 - train: epoch 0118, iter [01100, 05004], lr: 0.000132, loss: 1.1165
2022-07-12 01:55:30 - train: epoch 0118, iter [01200, 05004], lr: 0.000130, loss: 0.9573
2022-07-12 01:56:04 - train: epoch 0118, iter [01300, 05004], lr: 0.000129, loss: 0.9927
2022-07-12 01:56:38 - train: epoch 0118, iter [01400, 05004], lr: 0.000127, loss: 1.0055
2022-07-12 01:57:12 - train: epoch 0118, iter [01500, 05004], lr: 0.000125, loss: 1.0011
2022-07-12 01:57:46 - train: epoch 0118, iter [01600, 05004], lr: 0.000123, loss: 0.9511
2022-07-12 01:58:21 - train: epoch 0118, iter [01700, 05004], lr: 0.000121, loss: 0.9057
2022-07-12 01:58:55 - train: epoch 0118, iter [01800, 05004], lr: 0.000119, loss: 0.8509
2022-07-12 01:59:29 - train: epoch 0118, iter [01900, 05004], lr: 0.000118, loss: 1.0653
2022-07-12 02:00:03 - train: epoch 0118, iter [02000, 05004], lr: 0.000116, loss: 0.9590
2022-07-12 02:00:38 - train: epoch 0118, iter [02100, 05004], lr: 0.000114, loss: 0.8656
2022-07-12 02:01:12 - train: epoch 0118, iter [02200, 05004], lr: 0.000112, loss: 1.0247
2022-07-12 02:01:46 - train: epoch 0118, iter [02300, 05004], lr: 0.000111, loss: 1.0299
2022-07-12 02:02:20 - train: epoch 0118, iter [02400, 05004], lr: 0.000109, loss: 1.0441
2022-07-12 02:02:54 - train: epoch 0118, iter [02500, 05004], lr: 0.000107, loss: 1.0440
2022-07-12 02:03:28 - train: epoch 0118, iter [02600, 05004], lr: 0.000105, loss: 1.0184
2022-07-12 02:04:02 - train: epoch 0118, iter [02700, 05004], lr: 0.000104, loss: 1.0116
2022-07-12 02:04:36 - train: epoch 0118, iter [02800, 05004], lr: 0.000102, loss: 1.0777
2022-07-12 02:05:10 - train: epoch 0118, iter [02900, 05004], lr: 0.000100, loss: 1.0176
2022-07-12 02:05:45 - train: epoch 0118, iter [03000, 05004], lr: 0.000099, loss: 0.9814
2022-07-12 02:06:18 - train: epoch 0118, iter [03100, 05004], lr: 0.000097, loss: 1.0564
2022-07-12 02:06:53 - train: epoch 0118, iter [03200, 05004], lr: 0.000095, loss: 1.0918
2022-07-12 02:07:27 - train: epoch 0118, iter [03300, 05004], lr: 0.000094, loss: 1.0274
2022-07-12 02:08:01 - train: epoch 0118, iter [03400, 05004], lr: 0.000092, loss: 1.0774
2022-07-12 02:08:35 - train: epoch 0118, iter [03500, 05004], lr: 0.000091, loss: 1.1170
2022-07-12 02:09:10 - train: epoch 0118, iter [03600, 05004], lr: 0.000089, loss: 1.2278
2022-07-12 02:09:44 - train: epoch 0118, iter [03700, 05004], lr: 0.000088, loss: 0.9398
2022-07-12 02:10:18 - train: epoch 0118, iter [03800, 05004], lr: 0.000086, loss: 1.1004
2022-07-12 02:10:52 - train: epoch 0118, iter [03900, 05004], lr: 0.000084, loss: 1.0000
2022-07-12 02:11:26 - train: epoch 0118, iter [04000, 05004], lr: 0.000083, loss: 1.1319
2022-07-12 02:12:00 - train: epoch 0118, iter [04100, 05004], lr: 0.000081, loss: 1.1377
2022-07-12 02:12:35 - train: epoch 0118, iter [04200, 05004], lr: 0.000080, loss: 1.2122
2022-07-12 02:13:08 - train: epoch 0118, iter [04300, 05004], lr: 0.000079, loss: 0.7968
2022-07-12 02:13:43 - train: epoch 0118, iter [04400, 05004], lr: 0.000077, loss: 1.1272
2022-07-12 02:14:16 - train: epoch 0118, iter [04500, 05004], lr: 0.000076, loss: 1.0818
2022-07-12 02:14:52 - train: epoch 0118, iter [04600, 05004], lr: 0.000074, loss: 0.8998
2022-07-12 02:15:25 - train: epoch 0118, iter [04700, 05004], lr: 0.000073, loss: 0.9985
2022-07-12 02:16:00 - train: epoch 0118, iter [04800, 05004], lr: 0.000071, loss: 1.0745
2022-07-12 02:16:34 - train: epoch 0118, iter [04900, 05004], lr: 0.000070, loss: 1.0652
2022-07-12 02:17:06 - train: epoch 0118, iter [05000, 05004], lr: 0.000069, loss: 1.1113
2022-07-12 02:17:07 - train: epoch 118, train_loss: 1.0101
2022-07-12 02:18:23 - eval: epoch: 118, acc1: 74.766%, acc5: 92.130%, test_loss: 1.0043, per_image_load_time: 1.902ms, per_image_inference_time: 0.394ms
2022-07-12 02:18:23 - until epoch: 118, best_acc1: 74.766%
2022-07-12 02:18:23 - epoch 119 lr: 0.000069
2022-07-12 02:19:03 - train: epoch 0119, iter [00100, 05004], lr: 0.000067, loss: 1.1499
2022-07-12 02:19:38 - train: epoch 0119, iter [00200, 05004], lr: 0.000066, loss: 1.0994
2022-07-12 02:20:13 - train: epoch 0119, iter [00300, 05004], lr: 0.000064, loss: 0.9478
2022-07-12 02:20:47 - train: epoch 0119, iter [00400, 05004], lr: 0.000063, loss: 0.9097
2022-07-12 02:21:21 - train: epoch 0119, iter [00500, 05004], lr: 0.000062, loss: 0.8224
2022-07-12 02:21:55 - train: epoch 0119, iter [00600, 05004], lr: 0.000061, loss: 0.9010
2022-07-12 02:22:30 - train: epoch 0119, iter [00700, 05004], lr: 0.000059, loss: 0.9362
2022-07-12 02:23:04 - train: epoch 0119, iter [00800, 05004], lr: 0.000058, loss: 0.9167
2022-07-12 02:23:39 - train: epoch 0119, iter [00900, 05004], lr: 0.000057, loss: 1.0087
2022-07-12 02:24:13 - train: epoch 0119, iter [01000, 05004], lr: 0.000056, loss: 0.8438
2022-07-12 02:24:49 - train: epoch 0119, iter [01100, 05004], lr: 0.000054, loss: 0.9322
2022-07-12 02:25:23 - train: epoch 0119, iter [01200, 05004], lr: 0.000053, loss: 0.9151
2022-07-12 02:25:58 - train: epoch 0119, iter [01300, 05004], lr: 0.000052, loss: 0.8729
2022-07-12 02:26:32 - train: epoch 0119, iter [01400, 05004], lr: 0.000051, loss: 1.0455
2022-07-12 02:27:06 - train: epoch 0119, iter [01500, 05004], lr: 0.000050, loss: 1.0426
2022-07-12 02:27:41 - train: epoch 0119, iter [01600, 05004], lr: 0.000048, loss: 0.9566
2022-07-12 02:28:17 - train: epoch 0119, iter [01700, 05004], lr: 0.000047, loss: 1.0212
2022-07-12 02:28:50 - train: epoch 0119, iter [01800, 05004], lr: 0.000046, loss: 1.1084
2022-07-12 02:29:24 - train: epoch 0119, iter [01900, 05004], lr: 0.000045, loss: 1.0633
2022-07-12 02:30:00 - train: epoch 0119, iter [02000, 05004], lr: 0.000044, loss: 0.7978
2022-07-12 02:30:35 - train: epoch 0119, iter [02100, 05004], lr: 0.000043, loss: 1.1026
2022-07-12 02:31:10 - train: epoch 0119, iter [02200, 05004], lr: 0.000042, loss: 1.0085
2022-07-12 02:31:44 - train: epoch 0119, iter [02300, 05004], lr: 0.000041, loss: 0.8284
2022-07-12 02:32:19 - train: epoch 0119, iter [02400, 05004], lr: 0.000040, loss: 0.9968
2022-07-12 02:32:55 - train: epoch 0119, iter [02500, 05004], lr: 0.000039, loss: 1.0311
2022-07-12 02:33:29 - train: epoch 0119, iter [02600, 05004], lr: 0.000038, loss: 1.2279
2022-07-12 02:34:04 - train: epoch 0119, iter [02700, 05004], lr: 0.000037, loss: 1.0120
2022-07-12 02:34:39 - train: epoch 0119, iter [02800, 05004], lr: 0.000036, loss: 1.2006
2022-07-12 02:35:13 - train: epoch 0119, iter [02900, 05004], lr: 0.000035, loss: 0.9733
2022-07-12 02:35:48 - train: epoch 0119, iter [03000, 05004], lr: 0.000034, loss: 0.8770
2022-07-12 02:36:24 - train: epoch 0119, iter [03100, 05004], lr: 0.000033, loss: 1.0185
2022-07-12 02:36:58 - train: epoch 0119, iter [03200, 05004], lr: 0.000032, loss: 0.7781
2022-07-12 02:37:32 - train: epoch 0119, iter [03300, 05004], lr: 0.000031, loss: 0.9681
2022-07-12 02:38:07 - train: epoch 0119, iter [03400, 05004], lr: 0.000030, loss: 0.9489
2022-07-12 02:38:41 - train: epoch 0119, iter [03500, 05004], lr: 0.000029, loss: 0.9979
2022-07-12 02:39:16 - train: epoch 0119, iter [03600, 05004], lr: 0.000028, loss: 1.0356
2022-07-12 02:39:51 - train: epoch 0119, iter [03700, 05004], lr: 0.000027, loss: 1.0880
2022-07-12 02:40:25 - train: epoch 0119, iter [03800, 05004], lr: 0.000026, loss: 0.9595
2022-07-12 02:41:00 - train: epoch 0119, iter [03900, 05004], lr: 0.000026, loss: 1.3161
2022-07-12 02:41:35 - train: epoch 0119, iter [04000, 05004], lr: 0.000025, loss: 0.7570
2022-07-12 02:42:10 - train: epoch 0119, iter [04100, 05004], lr: 0.000024, loss: 1.0331
2022-07-12 02:42:45 - train: epoch 0119, iter [04200, 05004], lr: 0.000023, loss: 1.0665
2022-07-12 02:43:20 - train: epoch 0119, iter [04300, 05004], lr: 0.000022, loss: 0.7983
2022-07-12 02:43:54 - train: epoch 0119, iter [04400, 05004], lr: 0.000022, loss: 0.9313
2022-07-12 02:44:30 - train: epoch 0119, iter [04500, 05004], lr: 0.000021, loss: 1.0411
2022-07-12 02:45:04 - train: epoch 0119, iter [04600, 05004], lr: 0.000020, loss: 0.8941
2022-07-12 02:45:38 - train: epoch 0119, iter [04700, 05004], lr: 0.000019, loss: 0.9424
2022-07-12 02:46:14 - train: epoch 0119, iter [04800, 05004], lr: 0.000019, loss: 1.0400
2022-07-12 02:46:49 - train: epoch 0119, iter [04900, 05004], lr: 0.000018, loss: 1.1946
2022-07-12 02:47:22 - train: epoch 0119, iter [05000, 05004], lr: 0.000017, loss: 1.0916
2022-07-12 02:47:23 - train: epoch 119, train_loss: 1.0075
2022-07-12 02:48:39 - eval: epoch: 119, acc1: 74.704%, acc5: 92.094%, test_loss: 1.0053, per_image_load_time: 2.481ms, per_image_inference_time: 0.424ms
2022-07-12 02:48:40 - until epoch: 119, best_acc1: 74.766%
2022-07-12 02:48:40 - epoch 120 lr: 0.000017
2022-07-12 02:49:19 - train: epoch 0120, iter [00100, 05004], lr: 0.000016, loss: 1.0589
2022-07-12 02:49:54 - train: epoch 0120, iter [00200, 05004], lr: 0.000016, loss: 0.8238
2022-07-12 02:50:29 - train: epoch 0120, iter [00300, 05004], lr: 0.000015, loss: 1.1535
2022-07-12 02:51:02 - train: epoch 0120, iter [00400, 05004], lr: 0.000015, loss: 1.0263
2022-07-12 02:51:37 - train: epoch 0120, iter [00500, 05004], lr: 0.000014, loss: 0.9752
2022-07-12 02:52:10 - train: epoch 0120, iter [00600, 05004], lr: 0.000013, loss: 0.8421
2022-07-12 02:52:45 - train: epoch 0120, iter [00700, 05004], lr: 0.000013, loss: 1.0660
2022-07-12 02:53:20 - train: epoch 0120, iter [00800, 05004], lr: 0.000012, loss: 0.8705
2022-07-12 02:53:54 - train: epoch 0120, iter [00900, 05004], lr: 0.000012, loss: 1.0325
2022-07-12 02:54:29 - train: epoch 0120, iter [01000, 05004], lr: 0.000011, loss: 0.9486
2022-07-12 02:55:03 - train: epoch 0120, iter [01100, 05004], lr: 0.000010, loss: 1.0521
2022-07-12 02:55:38 - train: epoch 0120, iter [01200, 05004], lr: 0.000010, loss: 1.0493
2022-07-12 02:56:12 - train: epoch 0120, iter [01300, 05004], lr: 0.000009, loss: 0.9879
2022-07-12 02:56:47 - train: epoch 0120, iter [01400, 05004], lr: 0.000009, loss: 1.0729
2022-07-12 02:57:22 - train: epoch 0120, iter [01500, 05004], lr: 0.000008, loss: 1.0804
2022-07-12 02:57:56 - train: epoch 0120, iter [01600, 05004], lr: 0.000008, loss: 0.9184
2022-07-12 02:58:31 - train: epoch 0120, iter [01700, 05004], lr: 0.000007, loss: 1.1466
2022-07-12 02:59:05 - train: epoch 0120, iter [01800, 05004], lr: 0.000007, loss: 0.9017
2022-07-12 02:59:41 - train: epoch 0120, iter [01900, 05004], lr: 0.000007, loss: 1.1575
2022-07-12 03:00:15 - train: epoch 0120, iter [02000, 05004], lr: 0.000006, loss: 1.0024
2022-07-12 03:00:50 - train: epoch 0120, iter [02100, 05004], lr: 0.000006, loss: 1.1709
2022-07-12 03:01:24 - train: epoch 0120, iter [02200, 05004], lr: 0.000005, loss: 0.8515
2022-07-12 03:01:58 - train: epoch 0120, iter [02300, 05004], lr: 0.000005, loss: 1.0451
2022-07-12 03:02:33 - train: epoch 0120, iter [02400, 05004], lr: 0.000005, loss: 1.0572
2022-07-12 03:03:08 - train: epoch 0120, iter [02500, 05004], lr: 0.000004, loss: 1.0249
2022-07-12 03:03:43 - train: epoch 0120, iter [02600, 05004], lr: 0.000004, loss: 1.0860
2022-07-12 03:04:18 - train: epoch 0120, iter [02700, 05004], lr: 0.000004, loss: 1.0383
2022-07-12 03:04:52 - train: epoch 0120, iter [02800, 05004], lr: 0.000003, loss: 1.0057
2022-07-12 03:05:27 - train: epoch 0120, iter [02900, 05004], lr: 0.000003, loss: 0.9450
2022-07-12 03:06:01 - train: epoch 0120, iter [03000, 05004], lr: 0.000003, loss: 0.9996
2022-07-12 03:06:35 - train: epoch 0120, iter [03100, 05004], lr: 0.000002, loss: 0.8902
2022-07-12 03:07:10 - train: epoch 0120, iter [03200, 05004], lr: 0.000002, loss: 1.0406
2022-07-12 03:07:44 - train: epoch 0120, iter [03300, 05004], lr: 0.000002, loss: 0.9867
2022-07-12 03:08:18 - train: epoch 0120, iter [03400, 05004], lr: 0.000002, loss: 0.9245
2022-07-12 03:08:53 - train: epoch 0120, iter [03500, 05004], lr: 0.000002, loss: 1.0969
2022-07-12 03:09:28 - train: epoch 0120, iter [03600, 05004], lr: 0.000001, loss: 0.8267
2022-07-12 03:10:01 - train: epoch 0120, iter [03700, 05004], lr: 0.000001, loss: 0.8371
2022-07-12 03:10:36 - train: epoch 0120, iter [03800, 05004], lr: 0.000001, loss: 0.8389
2022-07-12 03:11:10 - train: epoch 0120, iter [03900, 05004], lr: 0.000001, loss: 1.0641
2022-07-12 03:11:45 - train: epoch 0120, iter [04000, 05004], lr: 0.000001, loss: 0.9903
2022-07-12 03:12:20 - train: epoch 0120, iter [04100, 05004], lr: 0.000001, loss: 1.2447
2022-07-12 03:12:54 - train: epoch 0120, iter [04200, 05004], lr: 0.000000, loss: 0.8688
2022-07-12 03:13:29 - train: epoch 0120, iter [04300, 05004], lr: 0.000000, loss: 1.0151
2022-07-12 03:14:04 - train: epoch 0120, iter [04400, 05004], lr: 0.000000, loss: 1.1702
2022-07-12 03:14:38 - train: epoch 0120, iter [04500, 05004], lr: 0.000000, loss: 1.1870
2022-07-12 03:15:12 - train: epoch 0120, iter [04600, 05004], lr: 0.000000, loss: 1.2828
2022-07-12 03:15:47 - train: epoch 0120, iter [04700, 05004], lr: 0.000000, loss: 1.0803
2022-07-12 03:16:21 - train: epoch 0120, iter [04800, 05004], lr: 0.000000, loss: 1.3348
2022-07-12 03:16:55 - train: epoch 0120, iter [04900, 05004], lr: 0.000000, loss: 1.1151
2022-07-12 03:17:29 - train: epoch 0120, iter [05000, 05004], lr: 0.000000, loss: 1.0214
2022-07-12 03:17:30 - train: epoch 120, train_loss: 1.0062
2022-07-12 03:18:45 - eval: epoch: 120, acc1: 74.728%, acc5: 92.136%, test_loss: 1.0044, per_image_load_time: 1.615ms, per_image_inference_time: 0.385ms
2022-07-12 03:18:46 - until epoch: 120, best_acc1: 74.766%
2022-07-12 03:18:46 - train done. model: RepVGG_B0, train time: 59.881 hours, best_acc1: 74.766%
