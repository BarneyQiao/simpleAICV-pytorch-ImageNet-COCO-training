2022-07-01 08:45:06 - train: epoch 0100, iter [02600, 05004], lr: 0.007017, loss: 1.0148
2022-07-01 08:45:39 - train: epoch 0100, iter [02700, 05004], lr: 0.007003, loss: 0.8902
2022-07-01 08:46:12 - train: epoch 0100, iter [02800, 05004], lr: 0.006990, loss: 0.9377
2022-07-01 08:46:46 - train: epoch 0100, iter [02900, 05004], lr: 0.006977, loss: 1.0770
2022-07-01 08:47:19 - train: epoch 0100, iter [03000, 05004], lr: 0.006963, loss: 0.8621
2022-07-01 08:47:53 - train: epoch 0100, iter [03100, 05004], lr: 0.006950, loss: 0.8932
2022-07-01 08:48:26 - train: epoch 0100, iter [03200, 05004], lr: 0.006937, loss: 1.0029
2022-07-01 08:48:59 - train: epoch 0100, iter [03300, 05004], lr: 0.006923, loss: 1.0549
2022-07-01 08:49:32 - train: epoch 0100, iter [03400, 05004], lr: 0.006910, loss: 1.1536
2022-07-01 08:50:06 - train: epoch 0100, iter [03500, 05004], lr: 0.006897, loss: 0.8522
2022-07-01 08:50:39 - train: epoch 0100, iter [03600, 05004], lr: 0.006884, loss: 0.9983
2022-07-01 08:51:12 - train: epoch 0100, iter [03700, 05004], lr: 0.006870, loss: 0.9023
2022-07-01 08:51:46 - train: epoch 0100, iter [03800, 05004], lr: 0.006857, loss: 1.0541
2022-07-01 08:52:19 - train: epoch 0100, iter [03900, 05004], lr: 0.006844, loss: 1.0652
2022-07-01 08:52:52 - train: epoch 0100, iter [04000, 05004], lr: 0.006831, loss: 0.9121
2022-07-01 08:53:25 - train: epoch 0100, iter [04100, 05004], lr: 0.006817, loss: 1.0218
2022-07-01 08:53:59 - train: epoch 0100, iter [04200, 05004], lr: 0.006804, loss: 1.0699
2022-07-01 08:54:32 - train: epoch 0100, iter [04300, 05004], lr: 0.006791, loss: 0.9223
2022-07-01 08:55:06 - train: epoch 0100, iter [04400, 05004], lr: 0.006778, loss: 1.1031
2022-07-01 08:55:39 - train: epoch 0100, iter [04500, 05004], lr: 0.006765, loss: 0.9545
2022-07-01 08:56:13 - train: epoch 0100, iter [04600, 05004], lr: 0.006752, loss: 0.8228
2022-07-01 08:56:46 - train: epoch 0100, iter [04700, 05004], lr: 0.006739, loss: 1.0219
2022-07-01 08:57:19 - train: epoch 0100, iter [04800, 05004], lr: 0.006725, loss: 0.7320
2022-07-01 08:57:53 - train: epoch 0100, iter [04900, 05004], lr: 0.006712, loss: 0.9350
2022-07-01 08:58:26 - train: epoch 0100, iter [05000, 05004], lr: 0.006699, loss: 1.0862
2022-07-01 08:58:27 - train: epoch 100, train_loss: 0.9738
2022-07-01 08:59:45 - eval: epoch: 100, acc1: 75.254%, acc5: 92.554%, test_loss: 0.9894, per_image_load_time: 1.010ms, per_image_inference_time: 0.660ms
2022-07-01 08:59:46 - until epoch: 100, best_acc1: 75.254%
2022-07-01 08:59:46 - epoch 101 lr: 0.006699
2022-07-01 09:00:26 - train: epoch 0101, iter [00100, 05004], lr: 0.006686, loss: 0.8653
2022-07-01 09:00:59 - train: epoch 0101, iter [00200, 05004], lr: 0.006673, loss: 0.8536
2022-07-01 09:01:31 - train: epoch 0101, iter [00300, 05004], lr: 0.006660, loss: 0.7982
2022-07-01 09:02:04 - train: epoch 0101, iter [00400, 05004], lr: 0.006647, loss: 0.8245
2022-07-01 09:02:37 - train: epoch 0101, iter [00500, 05004], lr: 0.006633, loss: 0.9166
2022-07-01 09:03:09 - train: epoch 0101, iter [00600, 05004], lr: 0.006620, loss: 0.8498
2022-07-01 09:03:43 - train: epoch 0101, iter [00700, 05004], lr: 0.006607, loss: 1.0264
2022-07-01 09:04:16 - train: epoch 0101, iter [00800, 05004], lr: 0.006594, loss: 0.9118
2022-07-01 09:04:49 - train: epoch 0101, iter [00900, 05004], lr: 0.006581, loss: 1.0314
2022-07-01 09:05:22 - train: epoch 0101, iter [01000, 05004], lr: 0.006569, loss: 1.1047
2022-07-01 09:05:56 - train: epoch 0101, iter [01100, 05004], lr: 0.006556, loss: 0.9652
2022-07-01 09:06:29 - train: epoch 0101, iter [01200, 05004], lr: 0.006543, loss: 0.8540
2022-07-01 09:07:02 - train: epoch 0101, iter [01300, 05004], lr: 0.006530, loss: 1.1289
2022-07-01 09:07:35 - train: epoch 0101, iter [01400, 05004], lr: 0.006517, loss: 0.9454
2022-07-01 09:08:08 - train: epoch 0101, iter [01500, 05004], lr: 0.006504, loss: 0.9935
2022-07-01 09:08:41 - train: epoch 0101, iter [01600, 05004], lr: 0.006491, loss: 0.7874
2022-07-01 09:09:14 - train: epoch 0101, iter [01700, 05004], lr: 0.006478, loss: 0.8729
2022-07-01 09:09:47 - train: epoch 0101, iter [01800, 05004], lr: 0.006465, loss: 1.1052
2022-07-01 09:10:20 - train: epoch 0101, iter [01900, 05004], lr: 0.006452, loss: 0.7374
2022-07-01 09:10:53 - train: epoch 0101, iter [02000, 05004], lr: 0.006440, loss: 0.8620
2022-07-01 09:11:26 - train: epoch 0101, iter [02100, 05004], lr: 0.006427, loss: 0.9765
2022-07-01 09:11:59 - train: epoch 0101, iter [02200, 05004], lr: 0.006414, loss: 0.7613
2022-07-01 09:12:32 - train: epoch 0101, iter [02300, 05004], lr: 0.006401, loss: 0.8843
2022-07-01 09:13:06 - train: epoch 0101, iter [02400, 05004], lr: 0.006388, loss: 0.9195
2022-07-01 09:13:39 - train: epoch 0101, iter [02500, 05004], lr: 0.006375, loss: 0.8991
2022-07-01 09:14:12 - train: epoch 0101, iter [02600, 05004], lr: 0.006363, loss: 0.9656
2022-07-01 09:14:45 - train: epoch 0101, iter [02700, 05004], lr: 0.006350, loss: 1.1839
2022-07-01 09:15:18 - train: epoch 0101, iter [02800, 05004], lr: 0.006337, loss: 0.9915
2022-07-01 09:15:51 - train: epoch 0101, iter [02900, 05004], lr: 0.006324, loss: 1.1503
2022-07-01 09:16:25 - train: epoch 0101, iter [03000, 05004], lr: 0.006312, loss: 1.0974
2022-07-01 09:16:58 - train: epoch 0101, iter [03100, 05004], lr: 0.006299, loss: 1.1376
2022-07-01 09:17:31 - train: epoch 0101, iter [03200, 05004], lr: 0.006286, loss: 0.9259
2022-07-01 09:18:04 - train: epoch 0101, iter [03300, 05004], lr: 0.006274, loss: 0.9522
2022-07-01 09:18:37 - train: epoch 0101, iter [03400, 05004], lr: 0.006261, loss: 0.9764
2022-07-01 09:19:10 - train: epoch 0101, iter [03500, 05004], lr: 0.006248, loss: 0.7837
2022-07-01 09:19:43 - train: epoch 0101, iter [03600, 05004], lr: 0.006236, loss: 0.9869
2022-07-01 09:20:16 - train: epoch 0101, iter [03700, 05004], lr: 0.006223, loss: 1.1177
2022-07-01 09:20:50 - train: epoch 0101, iter [03800, 05004], lr: 0.006210, loss: 0.9553
2022-07-01 09:21:23 - train: epoch 0101, iter [03900, 05004], lr: 0.006198, loss: 1.0397
2022-07-01 09:21:57 - train: epoch 0101, iter [04000, 05004], lr: 0.006185, loss: 1.0442
2022-07-01 09:22:30 - train: epoch 0101, iter [04100, 05004], lr: 0.006172, loss: 0.9836
2022-07-01 09:23:03 - train: epoch 0101, iter [04200, 05004], lr: 0.006160, loss: 0.9871
2022-07-01 09:23:36 - train: epoch 0101, iter [04300, 05004], lr: 0.006147, loss: 0.9966
2022-07-01 09:24:09 - train: epoch 0101, iter [04400, 05004], lr: 0.006135, loss: 0.9142
2022-07-01 09:24:43 - train: epoch 0101, iter [04500, 05004], lr: 0.006122, loss: 1.2408
2022-07-01 09:25:16 - train: epoch 0101, iter [04600, 05004], lr: 0.006110, loss: 0.9532
2022-07-01 09:25:49 - train: epoch 0101, iter [04700, 05004], lr: 0.006097, loss: 1.0019
2022-07-01 09:26:22 - train: epoch 0101, iter [04800, 05004], lr: 0.006085, loss: 0.9858
2022-07-01 09:26:54 - train: epoch 0101, iter [04900, 05004], lr: 0.006072, loss: 0.9409
2022-07-01 09:27:27 - train: epoch 0101, iter [05000, 05004], lr: 0.006060, loss: 0.9321
2022-07-01 09:27:29 - train: epoch 101, train_loss: 0.9516
2022-07-01 09:28:45 - eval: epoch: 101, acc1: 75.344%, acc5: 92.598%, test_loss: 0.9848, per_image_load_time: 2.341ms, per_image_inference_time: 0.644ms
2022-07-01 09:28:46 - until epoch: 101, best_acc1: 75.344%
2022-07-01 09:28:46 - epoch 102 lr: 0.006059
2022-07-01 09:29:27 - train: epoch 0102, iter [00100, 05004], lr: 0.006047, loss: 0.9794
2022-07-01 09:29:59 - train: epoch 0102, iter [00200, 05004], lr: 0.006034, loss: 0.8452
2022-07-01 09:30:31 - train: epoch 0102, iter [00300, 05004], lr: 0.006022, loss: 0.9680
2022-07-01 09:31:04 - train: epoch 0102, iter [00400, 05004], lr: 0.006009, loss: 0.8678
2022-07-01 09:31:37 - train: epoch 0102, iter [00500, 05004], lr: 0.005997, loss: 0.9878
2022-07-01 09:32:10 - train: epoch 0102, iter [00600, 05004], lr: 0.005984, loss: 0.7809
2022-07-01 09:32:43 - train: epoch 0102, iter [00700, 05004], lr: 0.005972, loss: 0.8823
2022-07-01 09:33:16 - train: epoch 0102, iter [00800, 05004], lr: 0.005960, loss: 0.8763
2022-07-01 09:33:49 - train: epoch 0102, iter [00900, 05004], lr: 0.005947, loss: 0.7946
2022-07-01 09:34:23 - train: epoch 0102, iter [01000, 05004], lr: 0.005935, loss: 0.9005
2022-07-01 09:34:56 - train: epoch 0102, iter [01100, 05004], lr: 0.005923, loss: 0.7695
2022-07-01 09:35:29 - train: epoch 0102, iter [01200, 05004], lr: 0.005910, loss: 1.0380
2022-07-01 09:36:03 - train: epoch 0102, iter [01300, 05004], lr: 0.005898, loss: 0.9634
2022-07-01 09:36:36 - train: epoch 0102, iter [01400, 05004], lr: 0.005886, loss: 1.0516
2022-07-01 09:37:09 - train: epoch 0102, iter [01500, 05004], lr: 0.005873, loss: 0.8955
2022-07-01 09:37:43 - train: epoch 0102, iter [01600, 05004], lr: 0.005861, loss: 1.0096
2022-07-01 09:38:16 - train: epoch 0102, iter [01700, 05004], lr: 0.005849, loss: 0.8984
2022-07-01 09:38:50 - train: epoch 0102, iter [01800, 05004], lr: 0.005836, loss: 1.0439
2022-07-01 09:39:23 - train: epoch 0102, iter [01900, 05004], lr: 0.005824, loss: 0.9119
2022-07-01 09:39:56 - train: epoch 0102, iter [02000, 05004], lr: 0.005812, loss: 0.8504
2022-07-01 09:40:29 - train: epoch 0102, iter [02100, 05004], lr: 0.005800, loss: 0.8497
2022-07-01 09:41:02 - train: epoch 0102, iter [02200, 05004], lr: 0.005787, loss: 0.8529
2022-07-01 09:41:35 - train: epoch 0102, iter [02300, 05004], lr: 0.005775, loss: 0.9275
2022-07-01 09:42:08 - train: epoch 0102, iter [02400, 05004], lr: 0.005763, loss: 1.0524
2022-07-01 09:42:42 - train: epoch 0102, iter [02500, 05004], lr: 0.005751, loss: 0.9356
2022-07-01 09:43:15 - train: epoch 0102, iter [02600, 05004], lr: 0.005739, loss: 0.9174
2022-07-01 09:43:48 - train: epoch 0102, iter [02700, 05004], lr: 0.005727, loss: 1.1928
2022-07-01 09:44:22 - train: epoch 0102, iter [02800, 05004], lr: 0.005714, loss: 0.9470
2022-07-01 09:44:55 - train: epoch 0102, iter [02900, 05004], lr: 0.005702, loss: 0.9324
2022-07-01 09:45:28 - train: epoch 0102, iter [03000, 05004], lr: 0.005690, loss: 0.8135
2022-07-01 09:46:01 - train: epoch 0102, iter [03100, 05004], lr: 0.005678, loss: 0.8970
2022-07-01 09:46:34 - train: epoch 0102, iter [03200, 05004], lr: 0.005666, loss: 0.7890
2022-07-01 09:47:07 - train: epoch 0102, iter [03300, 05004], lr: 0.005654, loss: 0.9574
2022-07-01 09:47:41 - train: epoch 0102, iter [03400, 05004], lr: 0.005642, loss: 0.9776
2022-07-01 09:48:14 - train: epoch 0102, iter [03500, 05004], lr: 0.005630, loss: 0.9697
2022-07-01 09:48:47 - train: epoch 0102, iter [03600, 05004], lr: 0.005618, loss: 1.1096
2022-07-01 09:49:20 - train: epoch 0102, iter [03700, 05004], lr: 0.005606, loss: 1.0201
2022-07-01 09:49:53 - train: epoch 0102, iter [03800, 05004], lr: 0.005594, loss: 0.9751
2022-07-01 09:50:27 - train: epoch 0102, iter [03900, 05004], lr: 0.005582, loss: 0.9946
2022-07-01 09:51:00 - train: epoch 0102, iter [04000, 05004], lr: 0.005570, loss: 0.8230
2022-07-01 09:51:33 - train: epoch 0102, iter [04100, 05004], lr: 0.005558, loss: 0.8795
2022-07-01 09:52:06 - train: epoch 0102, iter [04200, 05004], lr: 0.005546, loss: 1.0728
2022-07-01 09:52:39 - train: epoch 0102, iter [04300, 05004], lr: 0.005534, loss: 0.8001
2022-07-01 09:53:13 - train: epoch 0102, iter [04400, 05004], lr: 0.005522, loss: 0.8352
2022-07-01 09:53:46 - train: epoch 0102, iter [04500, 05004], lr: 0.005510, loss: 1.0651
2022-07-01 09:54:19 - train: epoch 0102, iter [04600, 05004], lr: 0.005498, loss: 1.1114
2022-07-01 09:54:52 - train: epoch 0102, iter [04700, 05004], lr: 0.005486, loss: 0.9573
2022-07-01 09:55:25 - train: epoch 0102, iter [04800, 05004], lr: 0.005474, loss: 1.0505
2022-07-01 09:55:59 - train: epoch 0102, iter [04900, 05004], lr: 0.005462, loss: 1.0531
2022-07-01 09:56:32 - train: epoch 0102, iter [05000, 05004], lr: 0.005450, loss: 0.7831
2022-07-01 09:56:33 - train: epoch 102, train_loss: 0.9299
2022-07-01 09:57:51 - eval: epoch: 102, acc1: 75.712%, acc5: 92.680%, test_loss: 0.9799, per_image_load_time: 2.381ms, per_image_inference_time: 0.629ms
2022-07-01 09:57:52 - until epoch: 102, best_acc1: 75.712%
2022-07-01 09:57:52 - epoch 103 lr: 0.005450
2022-07-01 09:58:33 - train: epoch 0103, iter [00100, 05004], lr: 0.005438, loss: 0.8322
2022-07-01 09:59:06 - train: epoch 0103, iter [00200, 05004], lr: 0.005426, loss: 0.9277
2022-07-01 09:59:39 - train: epoch 0103, iter [00300, 05004], lr: 0.005414, loss: 0.8835
2022-07-01 10:00:12 - train: epoch 0103, iter [00400, 05004], lr: 0.005402, loss: 1.0780
2022-07-01 10:00:45 - train: epoch 0103, iter [00500, 05004], lr: 0.005390, loss: 0.7951
2022-07-01 10:01:17 - train: epoch 0103, iter [00600, 05004], lr: 0.005379, loss: 0.7966
2022-07-01 10:01:50 - train: epoch 0103, iter [00700, 05004], lr: 0.005367, loss: 0.8465
2022-07-01 10:02:23 - train: epoch 0103, iter [00800, 05004], lr: 0.005355, loss: 0.9074
2022-07-01 10:02:56 - train: epoch 0103, iter [00900, 05004], lr: 0.005343, loss: 0.9257
2022-07-01 10:03:29 - train: epoch 0103, iter [01000, 05004], lr: 0.005332, loss: 0.8492
2022-07-01 10:04:02 - train: epoch 0103, iter [01100, 05004], lr: 0.005320, loss: 0.8695
2022-07-01 10:04:35 - train: epoch 0103, iter [01200, 05004], lr: 0.005308, loss: 0.9138
2022-07-01 10:05:08 - train: epoch 0103, iter [01300, 05004], lr: 0.005296, loss: 1.0292
2022-07-01 10:05:41 - train: epoch 0103, iter [01400, 05004], lr: 0.005285, loss: 0.9805
2022-07-01 10:06:14 - train: epoch 0103, iter [01500, 05004], lr: 0.005273, loss: 1.0519
2022-07-01 10:06:48 - train: epoch 0103, iter [01600, 05004], lr: 0.005261, loss: 0.6436
2022-07-01 10:07:21 - train: epoch 0103, iter [01700, 05004], lr: 0.005250, loss: 0.9344
2022-07-01 10:07:54 - train: epoch 0103, iter [01800, 05004], lr: 0.005238, loss: 0.8599
2022-07-01 10:08:28 - train: epoch 0103, iter [01900, 05004], lr: 0.005226, loss: 0.8574
2022-07-01 10:09:01 - train: epoch 0103, iter [02000, 05004], lr: 0.005215, loss: 0.7386
2022-07-01 10:09:34 - train: epoch 0103, iter [02100, 05004], lr: 0.005203, loss: 0.8318
2022-07-01 10:10:07 - train: epoch 0103, iter [02200, 05004], lr: 0.005191, loss: 0.8586
2022-07-01 10:10:40 - train: epoch 0103, iter [02300, 05004], lr: 0.005180, loss: 0.9204
2022-07-01 10:11:14 - train: epoch 0103, iter [02400, 05004], lr: 0.005168, loss: 0.9334
2022-07-01 10:11:47 - train: epoch 0103, iter [02500, 05004], lr: 0.005157, loss: 0.9204
2022-07-01 10:12:20 - train: epoch 0103, iter [02600, 05004], lr: 0.005145, loss: 0.9554
2022-07-01 10:12:54 - train: epoch 0103, iter [02700, 05004], lr: 0.005133, loss: 0.9067
2022-07-01 10:13:27 - train: epoch 0103, iter [02800, 05004], lr: 0.005122, loss: 0.6545
2022-07-01 10:14:00 - train: epoch 0103, iter [02900, 05004], lr: 0.005110, loss: 0.8829
2022-07-01 10:14:34 - train: epoch 0103, iter [03000, 05004], lr: 0.005099, loss: 0.9485
2022-07-01 10:15:07 - train: epoch 0103, iter [03100, 05004], lr: 0.005087, loss: 0.8308
2022-07-01 10:15:40 - train: epoch 0103, iter [03200, 05004], lr: 0.005076, loss: 0.9319
2022-07-01 10:16:13 - train: epoch 0103, iter [03300, 05004], lr: 0.005064, loss: 0.8612
2022-07-01 10:16:46 - train: epoch 0103, iter [03400, 05004], lr: 0.005053, loss: 0.9534
2022-07-01 10:17:19 - train: epoch 0103, iter [03500, 05004], lr: 0.005042, loss: 1.0235
2022-07-01 10:17:53 - train: epoch 0103, iter [03600, 05004], lr: 0.005030, loss: 0.8689
2022-07-01 10:18:26 - train: epoch 0103, iter [03700, 05004], lr: 0.005019, loss: 0.7936
2022-07-01 10:18:59 - train: epoch 0103, iter [03800, 05004], lr: 0.005007, loss: 0.9124
2022-07-01 10:19:32 - train: epoch 0103, iter [03900, 05004], lr: 0.004996, loss: 0.8967
2022-07-01 10:20:05 - train: epoch 0103, iter [04000, 05004], lr: 0.004984, loss: 0.8783
2022-07-01 10:20:38 - train: epoch 0103, iter [04100, 05004], lr: 0.004973, loss: 0.8561
2022-07-01 10:21:11 - train: epoch 0103, iter [04200, 05004], lr: 0.004962, loss: 0.8591
2022-07-01 10:21:44 - train: epoch 0103, iter [04300, 05004], lr: 0.004950, loss: 0.9760
2022-07-01 10:22:17 - train: epoch 0103, iter [04400, 05004], lr: 0.004939, loss: 0.9666
2022-07-01 10:22:50 - train: epoch 0103, iter [04500, 05004], lr: 0.004928, loss: 0.9840
2022-07-01 10:23:24 - train: epoch 0103, iter [04600, 05004], lr: 0.004916, loss: 1.0975
2022-07-01 10:23:57 - train: epoch 0103, iter [04700, 05004], lr: 0.004905, loss: 0.7990
2022-07-01 10:24:30 - train: epoch 0103, iter [04800, 05004], lr: 0.004894, loss: 1.1597
2022-07-01 10:25:03 - train: epoch 0103, iter [04900, 05004], lr: 0.004882, loss: 0.7978
2022-07-01 10:25:36 - train: epoch 0103, iter [05000, 05004], lr: 0.004871, loss: 0.9215
2022-07-01 10:25:38 - train: epoch 103, train_loss: 0.9120
2022-07-01 10:26:55 - eval: epoch: 103, acc1: 76.024%, acc5: 92.854%, test_loss: 0.9624, per_image_load_time: 2.213ms, per_image_inference_time: 0.661ms
2022-07-01 10:26:56 - until epoch: 103, best_acc1: 76.024%
2022-07-01 10:26:56 - epoch 104 lr: 0.004871
2022-07-01 10:27:37 - train: epoch 0104, iter [00100, 05004], lr: 0.004859, loss: 0.8687
2022-07-01 10:28:10 - train: epoch 0104, iter [00200, 05004], lr: 0.004848, loss: 0.7468
2022-07-01 10:28:43 - train: epoch 0104, iter [00300, 05004], lr: 0.004837, loss: 1.0188
2022-07-01 10:29:16 - train: epoch 0104, iter [00400, 05004], lr: 0.004826, loss: 0.8659
2022-07-01 10:29:49 - train: epoch 0104, iter [00500, 05004], lr: 0.004815, loss: 0.7679
2022-07-01 10:30:22 - train: epoch 0104, iter [00600, 05004], lr: 0.004803, loss: 1.0125
2022-07-01 10:30:55 - train: epoch 0104, iter [00700, 05004], lr: 0.004792, loss: 1.0007
2022-07-01 10:31:28 - train: epoch 0104, iter [00800, 05004], lr: 0.004781, loss: 0.8641
2022-07-01 10:32:01 - train: epoch 0104, iter [00900, 05004], lr: 0.004770, loss: 0.8381
2022-07-01 10:32:35 - train: epoch 0104, iter [01000, 05004], lr: 0.004759, loss: 0.8191
2022-07-01 10:33:08 - train: epoch 0104, iter [01100, 05004], lr: 0.004748, loss: 0.8485
2022-07-01 10:33:42 - train: epoch 0104, iter [01200, 05004], lr: 0.004736, loss: 0.7977
2022-07-01 10:34:16 - train: epoch 0104, iter [01300, 05004], lr: 0.004725, loss: 0.8632
2022-07-01 10:34:49 - train: epoch 0104, iter [01400, 05004], lr: 0.004714, loss: 0.8588
2022-07-01 10:35:22 - train: epoch 0104, iter [01500, 05004], lr: 0.004703, loss: 1.0147
2022-07-01 10:35:55 - train: epoch 0104, iter [01600, 05004], lr: 0.004692, loss: 0.7185
2022-07-01 10:36:29 - train: epoch 0104, iter [01700, 05004], lr: 0.004681, loss: 0.7906
2022-07-01 10:37:02 - train: epoch 0104, iter [01800, 05004], lr: 0.004670, loss: 0.9461
2022-07-01 10:37:34 - train: epoch 0104, iter [01900, 05004], lr: 0.004659, loss: 0.7416
2022-07-01 10:38:08 - train: epoch 0104, iter [02000, 05004], lr: 0.004648, loss: 0.9020
2022-07-01 10:38:41 - train: epoch 0104, iter [02100, 05004], lr: 0.004637, loss: 0.8282
2022-07-01 10:39:14 - train: epoch 0104, iter [02200, 05004], lr: 0.004626, loss: 0.9398
2022-07-01 10:39:48 - train: epoch 0104, iter [02300, 05004], lr: 0.004615, loss: 0.9117
2022-07-01 10:40:21 - train: epoch 0104, iter [02400, 05004], lr: 0.004604, loss: 1.0895
2022-07-01 10:40:55 - train: epoch 0104, iter [02500, 05004], lr: 0.004593, loss: 0.9561
2022-07-01 10:41:28 - train: epoch 0104, iter [02600, 05004], lr: 0.004582, loss: 0.8462
2022-07-01 10:42:02 - train: epoch 0104, iter [02700, 05004], lr: 0.004571, loss: 0.9992
2022-07-01 10:42:35 - train: epoch 0104, iter [02800, 05004], lr: 0.004560, loss: 0.9319
2022-07-01 10:43:08 - train: epoch 0104, iter [02900, 05004], lr: 0.004549, loss: 0.9262
2022-07-01 10:43:42 - train: epoch 0104, iter [03000, 05004], lr: 0.004538, loss: 0.9250
2022-07-01 10:44:15 - train: epoch 0104, iter [03100, 05004], lr: 0.004528, loss: 0.7829
2022-07-01 10:44:49 - train: epoch 0104, iter [03200, 05004], lr: 0.004517, loss: 0.9662
2022-07-01 10:45:22 - train: epoch 0104, iter [03300, 05004], lr: 0.004506, loss: 1.1524
2022-07-01 10:45:56 - train: epoch 0104, iter [03400, 05004], lr: 0.004495, loss: 0.7631
2022-07-01 10:46:29 - train: epoch 0104, iter [03500, 05004], lr: 0.004484, loss: 0.8721
2022-07-01 10:47:02 - train: epoch 0104, iter [03600, 05004], lr: 0.004473, loss: 0.8684
2022-07-01 10:47:36 - train: epoch 0104, iter [03700, 05004], lr: 0.004463, loss: 0.9482
2022-07-01 10:48:10 - train: epoch 0104, iter [03800, 05004], lr: 0.004452, loss: 0.7169
2022-07-01 10:48:43 - train: epoch 0104, iter [03900, 05004], lr: 0.004441, loss: 0.9034
2022-07-01 10:49:16 - train: epoch 0104, iter [04000, 05004], lr: 0.004430, loss: 0.7411
2022-07-01 10:49:50 - train: epoch 0104, iter [04100, 05004], lr: 0.004419, loss: 0.8706
2022-07-01 10:50:23 - train: epoch 0104, iter [04200, 05004], lr: 0.004409, loss: 0.9952
2022-07-01 10:50:56 - train: epoch 0104, iter [04300, 05004], lr: 0.004398, loss: 0.7421
2022-07-01 10:51:30 - train: epoch 0104, iter [04400, 05004], lr: 0.004387, loss: 0.9763
2022-07-01 10:52:03 - train: epoch 0104, iter [04500, 05004], lr: 0.004377, loss: 1.0423
2022-07-01 10:52:35 - train: epoch 0104, iter [04600, 05004], lr: 0.004366, loss: 0.8207
2022-07-01 10:53:08 - train: epoch 0104, iter [04700, 05004], lr: 0.004355, loss: 0.8511
2022-07-01 10:53:41 - train: epoch 0104, iter [04800, 05004], lr: 0.004344, loss: 0.9536
2022-07-01 10:54:13 - train: epoch 0104, iter [04900, 05004], lr: 0.004334, loss: 0.9101
2022-07-01 10:54:46 - train: epoch 0104, iter [05000, 05004], lr: 0.004323, loss: 1.0377
2022-07-01 10:54:47 - train: epoch 104, train_loss: 0.8911
2022-07-01 10:56:05 - eval: epoch: 104, acc1: 76.076%, acc5: 92.974%, test_loss: 0.9536, per_image_load_time: 2.110ms, per_image_inference_time: 0.657ms
2022-07-01 10:56:06 - until epoch: 104, best_acc1: 76.076%
2022-07-01 10:56:06 - epoch 105 lr: 0.004323
2022-07-01 10:56:45 - train: epoch 0105, iter [00100, 05004], lr: 0.004312, loss: 0.9298
2022-07-01 10:57:17 - train: epoch 0105, iter [00200, 05004], lr: 0.004301, loss: 1.0013
2022-07-01 10:57:50 - train: epoch 0105, iter [00300, 05004], lr: 0.004291, loss: 0.9965
2022-07-01 10:58:22 - train: epoch 0105, iter [00400, 05004], lr: 0.004280, loss: 0.8905
2022-07-01 10:58:55 - train: epoch 0105, iter [00500, 05004], lr: 0.004270, loss: 0.7887
2022-07-01 10:59:27 - train: epoch 0105, iter [00600, 05004], lr: 0.004259, loss: 0.9215
2022-07-01 11:00:00 - train: epoch 0105, iter [00700, 05004], lr: 0.004249, loss: 0.7585
2022-07-01 11:00:33 - train: epoch 0105, iter [00800, 05004], lr: 0.004238, loss: 0.8605
2022-07-01 11:01:06 - train: epoch 0105, iter [00900, 05004], lr: 0.004227, loss: 0.8839
2022-07-01 11:01:39 - train: epoch 0105, iter [01000, 05004], lr: 0.004217, loss: 0.9220
2022-07-01 11:02:11 - train: epoch 0105, iter [01100, 05004], lr: 0.004206, loss: 1.0563
2022-07-01 11:02:44 - train: epoch 0105, iter [01200, 05004], lr: 0.004196, loss: 0.9259
2022-07-01 11:03:17 - train: epoch 0105, iter [01300, 05004], lr: 0.004185, loss: 0.8144
2022-07-01 11:03:50 - train: epoch 0105, iter [01400, 05004], lr: 0.004175, loss: 0.9208
2022-07-01 11:04:23 - train: epoch 0105, iter [01500, 05004], lr: 0.004165, loss: 0.8133
2022-07-01 11:04:56 - train: epoch 0105, iter [01600, 05004], lr: 0.004154, loss: 0.6842
2022-07-01 11:05:28 - train: epoch 0105, iter [01700, 05004], lr: 0.004144, loss: 0.9176
2022-07-01 11:06:01 - train: epoch 0105, iter [01800, 05004], lr: 0.004133, loss: 0.9352
2022-07-01 11:06:34 - train: epoch 0105, iter [01900, 05004], lr: 0.004123, loss: 0.9434
2022-07-01 11:07:07 - train: epoch 0105, iter [02000, 05004], lr: 0.004112, loss: 0.7974
2022-07-01 11:07:40 - train: epoch 0105, iter [02100, 05004], lr: 0.004102, loss: 0.9185
2022-07-01 11:08:13 - train: epoch 0105, iter [02200, 05004], lr: 0.004092, loss: 1.0288
2022-07-01 11:08:46 - train: epoch 0105, iter [02300, 05004], lr: 0.004081, loss: 0.8474
2022-07-01 11:09:19 - train: epoch 0105, iter [02400, 05004], lr: 0.004071, loss: 0.8391
2022-07-01 11:09:52 - train: epoch 0105, iter [02500, 05004], lr: 0.004061, loss: 0.7686
2022-07-01 11:10:26 - train: epoch 0105, iter [02600, 05004], lr: 0.004050, loss: 0.7164
2022-07-01 11:10:59 - train: epoch 0105, iter [02700, 05004], lr: 0.004040, loss: 1.0702
2022-07-01 11:11:32 - train: epoch 0105, iter [02800, 05004], lr: 0.004030, loss: 1.1271
2022-07-01 11:12:04 - train: epoch 0105, iter [02900, 05004], lr: 0.004019, loss: 0.9412
2022-07-01 11:12:37 - train: epoch 0105, iter [03000, 05004], lr: 0.004009, loss: 0.8048
2022-07-01 11:13:10 - train: epoch 0105, iter [03100, 05004], lr: 0.003999, loss: 0.9157
2022-07-01 11:13:43 - train: epoch 0105, iter [03200, 05004], lr: 0.003989, loss: 1.0641
2022-07-01 11:14:16 - train: epoch 0105, iter [03300, 05004], lr: 0.003978, loss: 0.7345
2022-07-01 11:14:49 - train: epoch 0105, iter [03400, 05004], lr: 0.003968, loss: 0.7871
2022-07-01 11:15:22 - train: epoch 0105, iter [03500, 05004], lr: 0.003958, loss: 0.9982
2022-07-01 11:15:55 - train: epoch 0105, iter [03600, 05004], lr: 0.003948, loss: 0.9812
2022-07-01 11:16:29 - train: epoch 0105, iter [03700, 05004], lr: 0.003938, loss: 0.8270
2022-07-01 11:17:02 - train: epoch 0105, iter [03800, 05004], lr: 0.003927, loss: 1.0469
2022-07-01 11:17:35 - train: epoch 0105, iter [03900, 05004], lr: 0.003917, loss: 0.8365
2022-07-01 11:18:08 - train: epoch 0105, iter [04000, 05004], lr: 0.003907, loss: 0.7459
2022-07-01 11:18:42 - train: epoch 0105, iter [04100, 05004], lr: 0.003897, loss: 0.8355
2022-07-01 11:19:15 - train: epoch 0105, iter [04200, 05004], lr: 0.003887, loss: 0.8427
2022-07-01 11:19:48 - train: epoch 0105, iter [04300, 05004], lr: 0.003877, loss: 1.0330
2022-07-01 11:20:21 - train: epoch 0105, iter [04400, 05004], lr: 0.003867, loss: 0.7957
2022-07-01 11:20:54 - train: epoch 0105, iter [04500, 05004], lr: 0.003857, loss: 1.0649
2022-07-01 11:21:27 - train: epoch 0105, iter [04600, 05004], lr: 0.003847, loss: 0.9745
2022-07-01 11:22:00 - train: epoch 0105, iter [04700, 05004], lr: 0.003837, loss: 0.8288
2022-07-01 11:22:33 - train: epoch 0105, iter [04800, 05004], lr: 0.003826, loss: 0.9573
2022-07-01 11:23:06 - train: epoch 0105, iter [04900, 05004], lr: 0.003816, loss: 0.7891
2022-07-01 11:23:39 - train: epoch 0105, iter [05000, 05004], lr: 0.003806, loss: 0.7040
2022-07-01 11:23:41 - train: epoch 105, train_loss: 0.8716
2022-07-01 11:24:57 - eval: epoch: 105, acc1: 76.210%, acc5: 93.104%, test_loss: 0.9474, per_image_load_time: 1.798ms, per_image_inference_time: 0.657ms
2022-07-01 11:24:58 - until epoch: 105, best_acc1: 76.210%
2022-07-01 11:24:58 - epoch 106 lr: 0.003806
2022-07-01 11:25:37 - train: epoch 0106, iter [00100, 05004], lr: 0.003796, loss: 0.7486
2022-07-01 11:26:09 - train: epoch 0106, iter [00200, 05004], lr: 0.003786, loss: 0.7016
2022-07-01 11:26:42 - train: epoch 0106, iter [00300, 05004], lr: 0.003776, loss: 0.7092
2022-07-01 11:27:14 - train: epoch 0106, iter [00400, 05004], lr: 0.003766, loss: 0.9331
2022-07-01 11:27:47 - train: epoch 0106, iter [00500, 05004], lr: 0.003756, loss: 0.9330
2022-07-01 11:28:19 - train: epoch 0106, iter [00600, 05004], lr: 0.003746, loss: 0.7701
2022-07-01 11:28:51 - train: epoch 0106, iter [00700, 05004], lr: 0.003736, loss: 0.8163
2022-07-01 11:29:24 - train: epoch 0106, iter [00800, 05004], lr: 0.003726, loss: 0.7305
2022-07-01 11:29:57 - train: epoch 0106, iter [00900, 05004], lr: 0.003716, loss: 1.0040
2022-07-01 11:30:29 - train: epoch 0106, iter [01000, 05004], lr: 0.003707, loss: 1.0299
2022-07-01 11:31:02 - train: epoch 0106, iter [01100, 05004], lr: 0.003697, loss: 0.6655
2022-07-01 11:31:35 - train: epoch 0106, iter [01200, 05004], lr: 0.003687, loss: 0.7074
2022-07-01 11:32:08 - train: epoch 0106, iter [01300, 05004], lr: 0.003677, loss: 0.7973
2022-07-01 11:32:40 - train: epoch 0106, iter [01400, 05004], lr: 0.003667, loss: 0.9085
2022-07-01 11:33:14 - train: epoch 0106, iter [01500, 05004], lr: 0.003657, loss: 0.8469
2022-07-01 11:33:47 - train: epoch 0106, iter [01600, 05004], lr: 0.003647, loss: 0.8631
2022-07-01 11:34:20 - train: epoch 0106, iter [01700, 05004], lr: 0.003638, loss: 0.7459
2022-07-01 11:34:53 - train: epoch 0106, iter [01800, 05004], lr: 0.003628, loss: 0.7744
2022-07-01 11:35:27 - train: epoch 0106, iter [01900, 05004], lr: 0.003618, loss: 0.7904
2022-07-01 11:36:00 - train: epoch 0106, iter [02000, 05004], lr: 0.003608, loss: 0.8732
2022-07-01 11:36:33 - train: epoch 0106, iter [02100, 05004], lr: 0.003599, loss: 0.7853
2022-07-01 11:37:05 - train: epoch 0106, iter [02200, 05004], lr: 0.003589, loss: 0.8582
2022-07-01 11:37:38 - train: epoch 0106, iter [02300, 05004], lr: 0.003579, loss: 0.8465
2022-07-01 11:38:11 - train: epoch 0106, iter [02400, 05004], lr: 0.003569, loss: 0.8962
2022-07-01 11:38:44 - train: epoch 0106, iter [02500, 05004], lr: 0.003560, loss: 0.7983
2022-07-01 11:39:16 - train: epoch 0106, iter [02600, 05004], lr: 0.003550, loss: 0.6001
2022-07-01 11:39:49 - train: epoch 0106, iter [02700, 05004], lr: 0.003540, loss: 0.7791
2022-07-01 11:40:22 - train: epoch 0106, iter [02800, 05004], lr: 0.003531, loss: 0.8152
2022-07-01 11:40:55 - train: epoch 0106, iter [02900, 05004], lr: 0.003521, loss: 0.6993
2022-07-01 11:41:28 - train: epoch 0106, iter [03000, 05004], lr: 0.003511, loss: 0.9717
2022-07-01 11:42:01 - train: epoch 0106, iter [03100, 05004], lr: 0.003502, loss: 0.8366
2022-07-01 11:42:34 - train: epoch 0106, iter [03200, 05004], lr: 0.003492, loss: 0.6364
2022-07-01 11:43:08 - train: epoch 0106, iter [03300, 05004], lr: 0.003483, loss: 0.8851
2022-07-01 11:43:40 - train: epoch 0106, iter [03400, 05004], lr: 0.003473, loss: 0.7938
2022-07-01 11:44:14 - train: epoch 0106, iter [03500, 05004], lr: 0.003463, loss: 0.7973
2022-07-01 11:44:47 - train: epoch 0106, iter [03600, 05004], lr: 0.003454, loss: 0.7516
2022-07-01 11:45:20 - train: epoch 0106, iter [03700, 05004], lr: 0.003444, loss: 1.0147
2022-07-01 11:45:53 - train: epoch 0106, iter [03800, 05004], lr: 0.003435, loss: 0.9649
2022-07-01 11:46:26 - train: epoch 0106, iter [03900, 05004], lr: 0.003425, loss: 0.9342
2022-07-01 11:46:59 - train: epoch 0106, iter [04000, 05004], lr: 0.003416, loss: 0.7592
2022-07-01 11:47:32 - train: epoch 0106, iter [04100, 05004], lr: 0.003406, loss: 0.8799
2022-07-01 11:48:05 - train: epoch 0106, iter [04200, 05004], lr: 0.003397, loss: 0.7387
2022-07-01 11:48:39 - train: epoch 0106, iter [04300, 05004], lr: 0.003387, loss: 0.6300
2022-07-01 11:49:12 - train: epoch 0106, iter [04400, 05004], lr: 0.003378, loss: 0.8296
2022-07-01 11:49:45 - train: epoch 0106, iter [04500, 05004], lr: 0.003368, loss: 0.9175
2022-07-01 11:50:19 - train: epoch 0106, iter [04600, 05004], lr: 0.003359, loss: 1.0965
2022-07-01 11:50:52 - train: epoch 0106, iter [04700, 05004], lr: 0.003350, loss: 0.7421
2022-07-01 11:51:25 - train: epoch 0106, iter [04800, 05004], lr: 0.003340, loss: 0.9629
2022-07-01 11:51:59 - train: epoch 0106, iter [04900, 05004], lr: 0.003331, loss: 0.7685
2022-07-01 11:52:32 - train: epoch 0106, iter [05000, 05004], lr: 0.003321, loss: 0.8508
2022-07-01 11:52:33 - train: epoch 106, train_loss: 0.8508
2022-07-01 11:53:50 - eval: epoch: 106, acc1: 76.712%, acc5: 93.092%, test_loss: 0.9373, per_image_load_time: 2.183ms, per_image_inference_time: 0.665ms
2022-07-01 11:53:51 - until epoch: 106, best_acc1: 76.712%
2022-07-01 11:53:51 - epoch 107 lr: 0.003321
2022-07-01 11:54:30 - train: epoch 0107, iter [00100, 05004], lr: 0.003312, loss: 0.6974
2022-07-01 11:55:03 - train: epoch 0107, iter [00200, 05004], lr: 0.003302, loss: 0.8342
2022-07-01 11:55:35 - train: epoch 0107, iter [00300, 05004], lr: 0.003293, loss: 0.8717
2022-07-01 11:56:08 - train: epoch 0107, iter [00400, 05004], lr: 0.003284, loss: 0.7788
2022-07-01 11:56:40 - train: epoch 0107, iter [00500, 05004], lr: 0.003274, loss: 0.6042
2022-07-01 11:57:13 - train: epoch 0107, iter [00600, 05004], lr: 0.003265, loss: 0.7186
2022-07-01 11:57:45 - train: epoch 0107, iter [00700, 05004], lr: 0.003256, loss: 0.8043
2022-07-01 11:58:18 - train: epoch 0107, iter [00800, 05004], lr: 0.003246, loss: 0.6531
2022-07-01 11:58:50 - train: epoch 0107, iter [00900, 05004], lr: 0.003237, loss: 0.8415
2022-07-01 11:59:23 - train: epoch 0107, iter [01000, 05004], lr: 0.003228, loss: 0.7777
2022-07-01 11:59:55 - train: epoch 0107, iter [01100, 05004], lr: 0.003219, loss: 0.8908
2022-07-01 12:00:28 - train: epoch 0107, iter [01200, 05004], lr: 0.003209, loss: 0.7983
2022-07-01 12:01:00 - train: epoch 0107, iter [01300, 05004], lr: 0.003200, loss: 0.8160
2022-07-01 12:01:33 - train: epoch 0107, iter [01400, 05004], lr: 0.003191, loss: 0.7678
2022-07-01 12:02:05 - train: epoch 0107, iter [01500, 05004], lr: 0.003182, loss: 0.8079
2022-07-01 12:02:37 - train: epoch 0107, iter [01600, 05004], lr: 0.003173, loss: 0.6591
2022-07-01 12:03:10 - train: epoch 0107, iter [01700, 05004], lr: 0.003163, loss: 0.7446
2022-07-01 12:03:42 - train: epoch 0107, iter [01800, 05004], lr: 0.003154, loss: 0.9453
2022-07-01 12:04:15 - train: epoch 0107, iter [01900, 05004], lr: 0.003145, loss: 0.8688
2022-07-01 12:04:47 - train: epoch 0107, iter [02000, 05004], lr: 0.003136, loss: 0.6819
2022-07-01 12:05:20 - train: epoch 0107, iter [02100, 05004], lr: 0.003127, loss: 0.9068
2022-07-01 12:05:52 - train: epoch 0107, iter [02200, 05004], lr: 0.003118, loss: 0.7726
2022-07-01 12:06:24 - train: epoch 0107, iter [02300, 05004], lr: 0.003109, loss: 0.8423
2022-07-01 12:06:57 - train: epoch 0107, iter [02400, 05004], lr: 0.003100, loss: 0.8691
2022-07-01 12:07:29 - train: epoch 0107, iter [02500, 05004], lr: 0.003091, loss: 0.7865
2022-07-01 12:08:02 - train: epoch 0107, iter [02600, 05004], lr: 0.003082, loss: 0.9038
2022-07-01 12:08:34 - train: epoch 0107, iter [02700, 05004], lr: 0.003073, loss: 0.7550
2022-07-01 12:09:07 - train: epoch 0107, iter [02800, 05004], lr: 0.003064, loss: 0.8609
2022-07-01 12:09:40 - train: epoch 0107, iter [02900, 05004], lr: 0.003054, loss: 0.8000
2022-07-01 12:10:13 - train: epoch 0107, iter [03000, 05004], lr: 0.003046, loss: 0.9807
2022-07-01 12:10:45 - train: epoch 0107, iter [03100, 05004], lr: 0.003037, loss: 0.9767
2022-07-01 12:11:18 - train: epoch 0107, iter [03200, 05004], lr: 0.003028, loss: 0.7707
2022-07-01 12:11:50 - train: epoch 0107, iter [03300, 05004], lr: 0.003019, loss: 0.8591
2022-07-01 12:12:23 - train: epoch 0107, iter [03400, 05004], lr: 0.003010, loss: 0.7503
2022-07-01 12:12:56 - train: epoch 0107, iter [03500, 05004], lr: 0.003001, loss: 0.7797
2022-07-01 12:13:29 - train: epoch 0107, iter [03600, 05004], lr: 0.002992, loss: 0.8215
2022-07-01 12:14:01 - train: epoch 0107, iter [03700, 05004], lr: 0.002983, loss: 0.8700
2022-07-01 12:14:34 - train: epoch 0107, iter [03800, 05004], lr: 0.002974, loss: 0.7587
2022-07-01 12:15:06 - train: epoch 0107, iter [03900, 05004], lr: 0.002965, loss: 0.7182
2022-07-01 12:15:39 - train: epoch 0107, iter [04000, 05004], lr: 0.002956, loss: 0.8593
2022-07-01 12:16:12 - train: epoch 0107, iter [04100, 05004], lr: 0.002947, loss: 0.7558
2022-07-01 12:16:45 - train: epoch 0107, iter [04200, 05004], lr: 0.002939, loss: 0.9421
2022-07-01 12:17:18 - train: epoch 0107, iter [04300, 05004], lr: 0.002930, loss: 0.8349
2022-07-01 12:17:51 - train: epoch 0107, iter [04400, 05004], lr: 0.002921, loss: 0.7512
2022-07-01 12:18:24 - train: epoch 0107, iter [04500, 05004], lr: 0.002912, loss: 0.8293
2022-07-01 12:18:57 - train: epoch 0107, iter [04600, 05004], lr: 0.002903, loss: 0.7605
2022-07-01 12:19:31 - train: epoch 0107, iter [04700, 05004], lr: 0.002895, loss: 0.8536
2022-07-01 12:20:04 - train: epoch 0107, iter [04800, 05004], lr: 0.002886, loss: 0.8917
2022-07-01 12:20:36 - train: epoch 0107, iter [04900, 05004], lr: 0.002877, loss: 0.6770
2022-07-01 12:21:09 - train: epoch 0107, iter [05000, 05004], lr: 0.002868, loss: 0.7098
2022-07-01 12:21:11 - train: epoch 107, train_loss: 0.8314
2022-07-01 12:22:27 - eval: epoch: 107, acc1: 76.520%, acc5: 93.336%, test_loss: 0.9382, per_image_load_time: 2.240ms, per_image_inference_time: 0.637ms
2022-07-01 12:22:28 - until epoch: 107, best_acc1: 76.712%
2022-07-01 12:22:28 - epoch 108 lr: 0.002868
2022-07-01 12:23:07 - train: epoch 0108, iter [00100, 05004], lr: 0.002859, loss: 0.7072
2022-07-01 12:23:40 - train: epoch 0108, iter [00200, 05004], lr: 0.002850, loss: 0.7452
2022-07-01 12:24:12 - train: epoch 0108, iter [00300, 05004], lr: 0.002842, loss: 0.7737
2022-07-01 12:24:45 - train: epoch 0108, iter [00400, 05004], lr: 0.002833, loss: 0.9557
2022-07-01 12:25:18 - train: epoch 0108, iter [00500, 05004], lr: 0.002824, loss: 0.6897
2022-07-01 12:25:51 - train: epoch 0108, iter [00600, 05004], lr: 0.002816, loss: 0.7826
2022-07-01 12:26:23 - train: epoch 0108, iter [00700, 05004], lr: 0.002807, loss: 0.8566
2022-07-01 12:26:57 - train: epoch 0108, iter [00800, 05004], lr: 0.002798, loss: 0.8068
2022-07-01 12:27:29 - train: epoch 0108, iter [00900, 05004], lr: 0.002790, loss: 0.9957
2022-07-01 12:28:02 - train: epoch 0108, iter [01000, 05004], lr: 0.002781, loss: 0.7867
2022-07-01 12:28:35 - train: epoch 0108, iter [01100, 05004], lr: 0.002773, loss: 0.8215
2022-07-01 12:29:08 - train: epoch 0108, iter [01200, 05004], lr: 0.002764, loss: 0.7096
2022-07-01 12:29:40 - train: epoch 0108, iter [01300, 05004], lr: 0.002755, loss: 0.7394
2022-07-01 12:30:13 - train: epoch 0108, iter [01400, 05004], lr: 0.002747, loss: 0.9501
2022-07-01 12:30:45 - train: epoch 0108, iter [01500, 05004], lr: 0.002738, loss: 0.9747
2022-07-01 12:31:19 - train: epoch 0108, iter [01600, 05004], lr: 0.002730, loss: 0.7779
2022-07-01 12:31:52 - train: epoch 0108, iter [01700, 05004], lr: 0.002721, loss: 0.8946
2022-07-01 12:32:24 - train: epoch 0108, iter [01800, 05004], lr: 0.002713, loss: 0.7687
2022-07-01 12:32:57 - train: epoch 0108, iter [01900, 05004], lr: 0.002704, loss: 0.7450
2022-07-01 12:33:30 - train: epoch 0108, iter [02000, 05004], lr: 0.002696, loss: 0.8958
2022-07-01 12:34:03 - train: epoch 0108, iter [02100, 05004], lr: 0.002687, loss: 0.8108
2022-07-01 12:34:36 - train: epoch 0108, iter [02200, 05004], lr: 0.002679, loss: 0.7915
2022-07-01 12:35:09 - train: epoch 0108, iter [02300, 05004], lr: 0.002671, loss: 0.7538
2022-07-01 12:35:42 - train: epoch 0108, iter [02400, 05004], lr: 0.002662, loss: 0.9642
2022-07-01 12:36:16 - train: epoch 0108, iter [02500, 05004], lr: 0.002654, loss: 1.0941
2022-07-01 12:36:48 - train: epoch 0108, iter [02600, 05004], lr: 0.002645, loss: 0.8039
2022-07-01 12:37:21 - train: epoch 0108, iter [02700, 05004], lr: 0.002637, loss: 0.9340
2022-07-01 12:37:54 - train: epoch 0108, iter [02800, 05004], lr: 0.002628, loss: 0.8133
2022-07-01 12:38:26 - train: epoch 0108, iter [02900, 05004], lr: 0.002620, loss: 0.9321
2022-07-01 12:38:59 - train: epoch 0108, iter [03000, 05004], lr: 0.002612, loss: 0.9171
2022-07-01 12:39:32 - train: epoch 0108, iter [03100, 05004], lr: 0.002603, loss: 0.7606
2022-07-01 12:40:05 - train: epoch 0108, iter [03200, 05004], lr: 0.002595, loss: 0.7631
2022-07-01 12:40:38 - train: epoch 0108, iter [03300, 05004], lr: 0.002587, loss: 0.6481
2022-07-01 12:41:11 - train: epoch 0108, iter [03400, 05004], lr: 0.002579, loss: 0.9160
2022-07-01 12:41:44 - train: epoch 0108, iter [03500, 05004], lr: 0.002570, loss: 0.7921
2022-07-01 12:42:17 - train: epoch 0108, iter [03600, 05004], lr: 0.002562, loss: 0.8747
2022-07-01 12:42:50 - train: epoch 0108, iter [03700, 05004], lr: 0.002554, loss: 0.7714
2022-07-01 12:43:23 - train: epoch 0108, iter [03800, 05004], lr: 0.002545, loss: 0.7508
2022-07-01 12:43:56 - train: epoch 0108, iter [03900, 05004], lr: 0.002537, loss: 0.9666
2022-07-01 12:44:29 - train: epoch 0108, iter [04000, 05004], lr: 0.002529, loss: 0.7876
2022-07-01 12:45:02 - train: epoch 0108, iter [04100, 05004], lr: 0.002521, loss: 0.7850
2022-07-01 12:45:34 - train: epoch 0108, iter [04200, 05004], lr: 0.002513, loss: 0.7941
2022-07-01 12:46:08 - train: epoch 0108, iter [04300, 05004], lr: 0.002504, loss: 0.7934
2022-07-01 12:46:41 - train: epoch 0108, iter [04400, 05004], lr: 0.002496, loss: 0.7966
2022-07-01 12:47:14 - train: epoch 0108, iter [04500, 05004], lr: 0.002488, loss: 0.8336
2022-07-01 12:47:47 - train: epoch 0108, iter [04600, 05004], lr: 0.002480, loss: 0.8191
2022-07-01 12:48:20 - train: epoch 0108, iter [04700, 05004], lr: 0.002472, loss: 0.7999
2022-07-01 12:48:52 - train: epoch 0108, iter [04800, 05004], lr: 0.002464, loss: 0.7766
2022-07-01 12:49:26 - train: epoch 0108, iter [04900, 05004], lr: 0.002456, loss: 0.8442
2022-07-01 12:49:58 - train: epoch 0108, iter [05000, 05004], lr: 0.002447, loss: 0.8187
2022-07-01 12:50:00 - train: epoch 108, train_loss: 0.8139
2022-07-01 12:51:16 - eval: epoch: 108, acc1: 76.864%, acc5: 93.342%, test_loss: 0.9310, per_image_load_time: 1.879ms, per_image_inference_time: 0.637ms
2022-07-01 12:51:17 - until epoch: 108, best_acc1: 76.864%
2022-07-01 12:51:17 - epoch 109 lr: 0.002447
2022-07-01 12:51:56 - train: epoch 0109, iter [00100, 05004], lr: 0.002439, loss: 0.7338
2022-07-01 12:52:29 - train: epoch 0109, iter [00200, 05004], lr: 0.002431, loss: 0.9023
2022-07-01 12:53:03 - train: epoch 0109, iter [00300, 05004], lr: 0.002423, loss: 0.7661
2022-07-01 12:53:35 - train: epoch 0109, iter [00400, 05004], lr: 0.002415, loss: 0.7379
2022-07-01 12:54:08 - train: epoch 0109, iter [00500, 05004], lr: 0.002407, loss: 0.8251
2022-07-01 12:54:41 - train: epoch 0109, iter [00600, 05004], lr: 0.002399, loss: 0.8223
2022-07-01 12:55:14 - train: epoch 0109, iter [00700, 05004], lr: 0.002391, loss: 0.6885
2022-07-01 12:55:47 - train: epoch 0109, iter [00800, 05004], lr: 0.002383, loss: 0.9045
2022-07-01 12:56:20 - train: epoch 0109, iter [00900, 05004], lr: 0.002375, loss: 0.7989
2022-07-01 12:56:52 - train: epoch 0109, iter [01000, 05004], lr: 0.002367, loss: 0.5963
2022-07-01 12:57:24 - train: epoch 0109, iter [01100, 05004], lr: 0.002359, loss: 0.7593
2022-07-01 12:57:57 - train: epoch 0109, iter [01200, 05004], lr: 0.002351, loss: 0.7232
2022-07-01 12:58:29 - train: epoch 0109, iter [01300, 05004], lr: 0.002343, loss: 0.6246
2022-07-01 12:59:02 - train: epoch 0109, iter [01400, 05004], lr: 0.002335, loss: 0.7057
2022-07-01 12:59:34 - train: epoch 0109, iter [01500, 05004], lr: 0.002327, loss: 0.8769
2022-07-01 13:00:07 - train: epoch 0109, iter [01600, 05004], lr: 0.002320, loss: 0.7709
2022-07-01 13:00:40 - train: epoch 0109, iter [01700, 05004], lr: 0.002312, loss: 0.9807
2022-07-01 13:01:13 - train: epoch 0109, iter [01800, 05004], lr: 0.002304, loss: 0.8589
2022-07-01 13:01:45 - train: epoch 0109, iter [01900, 05004], lr: 0.002296, loss: 0.7117
2022-07-01 13:02:18 - train: epoch 0109, iter [02000, 05004], lr: 0.002288, loss: 0.8780
2022-07-01 13:02:51 - train: epoch 0109, iter [02100, 05004], lr: 0.002280, loss: 0.8033
2022-07-01 13:03:23 - train: epoch 0109, iter [02200, 05004], lr: 0.002272, loss: 0.7147
2022-07-01 13:03:56 - train: epoch 0109, iter [02300, 05004], lr: 0.002265, loss: 0.6693
2022-07-01 13:04:29 - train: epoch 0109, iter [02400, 05004], lr: 0.002257, loss: 0.8708
2022-07-01 13:05:02 - train: epoch 0109, iter [02500, 05004], lr: 0.002249, loss: 0.8263
2022-07-01 13:05:35 - train: epoch 0109, iter [02600, 05004], lr: 0.002241, loss: 0.9746
2022-07-01 13:06:08 - train: epoch 0109, iter [02700, 05004], lr: 0.002234, loss: 0.7555
2022-07-01 13:06:40 - train: epoch 0109, iter [02800, 05004], lr: 0.002226, loss: 0.8707
2022-07-01 13:07:13 - train: epoch 0109, iter [02900, 05004], lr: 0.002218, loss: 0.8087
2022-07-01 13:07:45 - train: epoch 0109, iter [03000, 05004], lr: 0.002211, loss: 0.6162
2022-07-01 13:08:18 - train: epoch 0109, iter [03100, 05004], lr: 0.002203, loss: 0.8247
2022-07-01 13:08:51 - train: epoch 0109, iter [03200, 05004], lr: 0.002195, loss: 0.6161
2022-07-01 13:09:24 - train: epoch 0109, iter [03300, 05004], lr: 0.002188, loss: 0.8782
2022-07-01 13:09:57 - train: epoch 0109, iter [03400, 05004], lr: 0.002180, loss: 0.7872
2022-07-01 13:10:30 - train: epoch 0109, iter [03500, 05004], lr: 0.002172, loss: 0.7331
2022-07-01 13:11:03 - train: epoch 0109, iter [03600, 05004], lr: 0.002165, loss: 0.8148
2022-07-01 13:11:35 - train: epoch 0109, iter [03700, 05004], lr: 0.002157, loss: 0.6009
2022-07-01 13:12:08 - train: epoch 0109, iter [03800, 05004], lr: 0.002149, loss: 0.7777
2022-07-01 13:12:40 - train: epoch 0109, iter [03900, 05004], lr: 0.002142, loss: 0.8601
2022-07-01 13:13:13 - train: epoch 0109, iter [04000, 05004], lr: 0.002134, loss: 0.7417
2022-07-01 13:13:46 - train: epoch 0109, iter [04100, 05004], lr: 0.002127, loss: 0.7514
2022-07-01 13:14:19 - train: epoch 0109, iter [04200, 05004], lr: 0.002119, loss: 0.8817
2022-07-01 13:14:51 - train: epoch 0109, iter [04300, 05004], lr: 0.002112, loss: 0.6977
2022-07-01 13:15:24 - train: epoch 0109, iter [04400, 05004], lr: 0.002104, loss: 0.8029
2022-07-01 13:15:56 - train: epoch 0109, iter [04500, 05004], lr: 0.002097, loss: 0.7837
2022-07-01 13:16:29 - train: epoch 0109, iter [04600, 05004], lr: 0.002089, loss: 0.7947
2022-07-01 13:17:02 - train: epoch 0109, iter [04700, 05004], lr: 0.002082, loss: 0.7358
2022-07-01 13:17:35 - train: epoch 0109, iter [04800, 05004], lr: 0.002074, loss: 0.7955
2022-07-01 13:18:08 - train: epoch 0109, iter [04900, 05004], lr: 0.002067, loss: 0.8265
2022-07-01 13:18:40 - train: epoch 0109, iter [05000, 05004], lr: 0.002059, loss: 0.6607
2022-07-01 13:18:42 - train: epoch 109, train_loss: 0.7957
2022-07-01 13:19:59 - eval: epoch: 109, acc1: 77.098%, acc5: 93.352%, test_loss: 0.9245, per_image_load_time: 2.317ms, per_image_inference_time: 0.628ms
2022-07-01 13:19:59 - until epoch: 109, best_acc1: 77.098%
2022-07-01 13:19:59 - epoch 110 lr: 0.002059
2022-07-01 13:20:38 - train: epoch 0110, iter [00100, 05004], lr: 0.002052, loss: 0.6710
2022-07-01 13:21:11 - train: epoch 0110, iter [00200, 05004], lr: 0.002044, loss: 0.6832
2022-07-01 13:21:44 - train: epoch 0110, iter [00300, 05004], lr: 0.002037, loss: 0.9158
2022-07-01 13:22:16 - train: epoch 0110, iter [00400, 05004], lr: 0.002029, loss: 0.7218
2022-07-01 13:22:49 - train: epoch 0110, iter [00500, 05004], lr: 0.002022, loss: 0.7513
2022-07-01 13:23:22 - train: epoch 0110, iter [00600, 05004], lr: 0.002015, loss: 0.8384
2022-07-01 13:23:54 - train: epoch 0110, iter [00700, 05004], lr: 0.002007, loss: 0.7740
2022-07-01 13:24:27 - train: epoch 0110, iter [00800, 05004], lr: 0.002000, loss: 0.8297
2022-07-01 13:25:00 - train: epoch 0110, iter [00900, 05004], lr: 0.001993, loss: 0.7177
2022-07-01 13:25:32 - train: epoch 0110, iter [01000, 05004], lr: 0.001985, loss: 0.6835
2022-07-01 13:26:04 - train: epoch 0110, iter [01100, 05004], lr: 0.001978, loss: 1.0755
2022-07-01 13:26:36 - train: epoch 0110, iter [01200, 05004], lr: 0.001971, loss: 0.7832
2022-07-01 13:27:09 - train: epoch 0110, iter [01300, 05004], lr: 0.001964, loss: 0.7187
2022-07-01 13:27:41 - train: epoch 0110, iter [01400, 05004], lr: 0.001956, loss: 0.5456
2022-07-01 13:28:14 - train: epoch 0110, iter [01500, 05004], lr: 0.001949, loss: 0.9315
2022-07-01 13:28:46 - train: epoch 0110, iter [01600, 05004], lr: 0.001942, loss: 0.7815
2022-07-01 13:29:18 - train: epoch 0110, iter [01700, 05004], lr: 0.001935, loss: 0.7245
2022-07-01 13:29:51 - train: epoch 0110, iter [01800, 05004], lr: 0.001927, loss: 0.7719
2022-07-01 13:30:24 - train: epoch 0110, iter [01900, 05004], lr: 0.001920, loss: 0.8756
2022-07-01 13:30:56 - train: epoch 0110, iter [02000, 05004], lr: 0.001913, loss: 0.8056
2022-07-01 13:31:29 - train: epoch 0110, iter [02100, 05004], lr: 0.001906, loss: 0.8947
2022-07-01 13:32:01 - train: epoch 0110, iter [02200, 05004], lr: 0.001899, loss: 0.7579
2022-07-01 13:32:34 - train: epoch 0110, iter [02300, 05004], lr: 0.001892, loss: 0.7746
2022-07-01 13:33:07 - train: epoch 0110, iter [02400, 05004], lr: 0.001884, loss: 0.7574
2022-07-01 13:33:40 - train: epoch 0110, iter [02500, 05004], lr: 0.001877, loss: 0.6703
2022-07-01 13:34:13 - train: epoch 0110, iter [02600, 05004], lr: 0.001870, loss: 0.7806
2022-07-01 13:34:45 - train: epoch 0110, iter [02700, 05004], lr: 0.001863, loss: 0.7043
2022-07-01 13:35:18 - train: epoch 0110, iter [02800, 05004], lr: 0.001856, loss: 0.7795
2022-07-01 13:35:51 - train: epoch 0110, iter [02900, 05004], lr: 0.001849, loss: 0.8118
2022-07-01 13:36:23 - train: epoch 0110, iter [03000, 05004], lr: 0.001842, loss: 0.7432
2022-07-01 13:36:56 - train: epoch 0110, iter [03100, 05004], lr: 0.001835, loss: 0.8239
2022-07-01 13:37:29 - train: epoch 0110, iter [03200, 05004], lr: 0.001828, loss: 0.9503
2022-07-01 13:38:02 - train: epoch 0110, iter [03300, 05004], lr: 0.001821, loss: 0.7235
2022-07-01 13:38:34 - train: epoch 0110, iter [03400, 05004], lr: 0.001814, loss: 0.6797
2022-07-01 13:39:07 - train: epoch 0110, iter [03500, 05004], lr: 0.001807, loss: 1.1275
2022-07-01 13:39:40 - train: epoch 0110, iter [03600, 05004], lr: 0.001800, loss: 0.9717
2022-07-01 13:40:12 - train: epoch 0110, iter [03700, 05004], lr: 0.001793, loss: 0.8822
2022-07-01 13:40:45 - train: epoch 0110, iter [03800, 05004], lr: 0.001786, loss: 0.7313
2022-07-01 13:41:18 - train: epoch 0110, iter [03900, 05004], lr: 0.001779, loss: 0.9012
2022-07-01 13:41:50 - train: epoch 0110, iter [04000, 05004], lr: 0.001772, loss: 0.7796
2022-07-01 13:42:23 - train: epoch 0110, iter [04100, 05004], lr: 0.001765, loss: 0.7741
2022-07-01 13:42:55 - train: epoch 0110, iter [04200, 05004], lr: 0.001759, loss: 0.7691
2022-07-01 13:43:28 - train: epoch 0110, iter [04300, 05004], lr: 0.001752, loss: 0.8076
2022-07-01 13:44:00 - train: epoch 0110, iter [04400, 05004], lr: 0.001745, loss: 0.9061
2022-07-01 13:44:33 - train: epoch 0110, iter [04500, 05004], lr: 0.001738, loss: 0.7957
2022-07-01 13:45:06 - train: epoch 0110, iter [04600, 05004], lr: 0.001731, loss: 0.6742
2022-07-01 13:45:38 - train: epoch 0110, iter [04700, 05004], lr: 0.001724, loss: 0.8831
2022-07-01 13:46:11 - train: epoch 0110, iter [04800, 05004], lr: 0.001718, loss: 0.9643
2022-07-01 13:46:43 - train: epoch 0110, iter [04900, 05004], lr: 0.001711, loss: 0.7088
2022-07-01 13:47:15 - train: epoch 0110, iter [05000, 05004], lr: 0.001704, loss: 0.7144
2022-07-01 13:47:17 - train: epoch 110, train_loss: 0.7791
2022-07-01 13:48:32 - eval: epoch: 110, acc1: 77.016%, acc5: 93.416%, test_loss: 0.9214, per_image_load_time: 2.263ms, per_image_inference_time: 0.611ms
2022-07-01 13:48:33 - until epoch: 110, best_acc1: 77.098%
2022-07-01 13:48:33 - epoch 111 lr: 0.001704
2022-07-01 13:49:12 - train: epoch 0111, iter [00100, 05004], lr: 0.001697, loss: 0.7197
2022-07-01 13:49:44 - train: epoch 0111, iter [00200, 05004], lr: 0.001690, loss: 0.8101
2022-07-01 13:50:16 - train: epoch 0111, iter [00300, 05004], lr: 0.001683, loss: 0.8278
2022-07-01 13:50:48 - train: epoch 0111, iter [00400, 05004], lr: 0.001677, loss: 0.7546
2022-07-01 13:51:21 - train: epoch 0111, iter [00500, 05004], lr: 0.001670, loss: 0.7836
2022-07-01 13:51:53 - train: epoch 0111, iter [00600, 05004], lr: 0.001663, loss: 0.9000
2022-07-01 13:52:26 - train: epoch 0111, iter [00700, 05004], lr: 0.001657, loss: 0.7904
2022-07-01 13:52:58 - train: epoch 0111, iter [00800, 05004], lr: 0.001650, loss: 0.7601
2022-07-01 13:53:31 - train: epoch 0111, iter [00900, 05004], lr: 0.001643, loss: 0.7175
2022-07-01 13:54:04 - train: epoch 0111, iter [01000, 05004], lr: 0.001637, loss: 0.6778
2022-07-01 13:54:37 - train: epoch 0111, iter [01100, 05004], lr: 0.001630, loss: 0.8030
2022-07-01 13:55:09 - train: epoch 0111, iter [01200, 05004], lr: 0.001623, loss: 0.7270
2022-07-01 13:55:42 - train: epoch 0111, iter [01300, 05004], lr: 0.001617, loss: 0.7834
2022-07-01 13:56:15 - train: epoch 0111, iter [01400, 05004], lr: 0.001610, loss: 0.6204
2022-07-01 13:56:49 - train: epoch 0111, iter [01500, 05004], lr: 0.001604, loss: 0.7461
2022-07-01 13:57:21 - train: epoch 0111, iter [01600, 05004], lr: 0.001597, loss: 0.6622
2022-07-01 13:57:55 - train: epoch 0111, iter [01700, 05004], lr: 0.001591, loss: 0.8222
2022-07-01 13:58:28 - train: epoch 0111, iter [01800, 05004], lr: 0.001584, loss: 0.6808
2022-07-01 13:59:01 - train: epoch 0111, iter [01900, 05004], lr: 0.001577, loss: 0.6929
2022-07-01 13:59:34 - train: epoch 0111, iter [02000, 05004], lr: 0.001571, loss: 0.7555
2022-07-01 14:00:07 - train: epoch 0111, iter [02100, 05004], lr: 0.001564, loss: 0.9619
2022-07-01 14:00:39 - train: epoch 0111, iter [02200, 05004], lr: 0.001558, loss: 0.7701
2022-07-01 14:01:13 - train: epoch 0111, iter [02300, 05004], lr: 0.001551, loss: 0.6543
2022-07-01 14:01:46 - train: epoch 0111, iter [02400, 05004], lr: 0.001545, loss: 0.8255
2022-07-01 14:02:18 - train: epoch 0111, iter [02500, 05004], lr: 0.001539, loss: 0.8254
2022-07-01 14:02:51 - train: epoch 0111, iter [02600, 05004], lr: 0.001532, loss: 0.5791
2022-07-01 14:03:24 - train: epoch 0111, iter [02700, 05004], lr: 0.001526, loss: 0.9144
2022-07-01 14:03:57 - train: epoch 0111, iter [02800, 05004], lr: 0.001519, loss: 0.8144
2022-07-01 14:04:30 - train: epoch 0111, iter [02900, 05004], lr: 0.001513, loss: 0.6686
2022-07-01 14:05:03 - train: epoch 0111, iter [03000, 05004], lr: 0.001507, loss: 0.8240
2022-07-01 14:05:35 - train: epoch 0111, iter [03100, 05004], lr: 0.001500, loss: 0.8026
2022-07-01 14:06:08 - train: epoch 0111, iter [03200, 05004], lr: 0.001494, loss: 0.8542
2022-07-01 14:06:41 - train: epoch 0111, iter [03300, 05004], lr: 0.001487, loss: 0.9650
2022-07-01 14:07:14 - train: epoch 0111, iter [03400, 05004], lr: 0.001481, loss: 0.9477
2022-07-01 14:07:47 - train: epoch 0111, iter [03500, 05004], lr: 0.001475, loss: 0.7116
2022-07-01 14:08:19 - train: epoch 0111, iter [03600, 05004], lr: 0.001469, loss: 0.6977
2022-07-01 14:08:52 - train: epoch 0111, iter [03700, 05004], lr: 0.001462, loss: 0.7362
2022-07-01 14:09:25 - train: epoch 0111, iter [03800, 05004], lr: 0.001456, loss: 0.6764
2022-07-01 14:09:58 - train: epoch 0111, iter [03900, 05004], lr: 0.001450, loss: 0.6061
2022-07-01 14:10:31 - train: epoch 0111, iter [04000, 05004], lr: 0.001443, loss: 0.8294
2022-07-01 14:11:04 - train: epoch 0111, iter [04100, 05004], lr: 0.001437, loss: 1.0822
2022-07-01 14:11:38 - train: epoch 0111, iter [04200, 05004], lr: 0.001431, loss: 0.7618
2022-07-01 14:12:11 - train: epoch 0111, iter [04300, 05004], lr: 0.001425, loss: 0.7775
2022-07-01 14:12:44 - train: epoch 0111, iter [04400, 05004], lr: 0.001419, loss: 0.5462
2022-07-01 14:13:17 - train: epoch 0111, iter [04500, 05004], lr: 0.001412, loss: 0.7716
2022-07-01 14:13:50 - train: epoch 0111, iter [04600, 05004], lr: 0.001406, loss: 0.7349
2022-07-01 14:14:23 - train: epoch 0111, iter [04700, 05004], lr: 0.001400, loss: 0.7577
2022-07-01 14:14:55 - train: epoch 0111, iter [04800, 05004], lr: 0.001394, loss: 0.8111
2022-07-01 14:15:28 - train: epoch 0111, iter [04900, 05004], lr: 0.001388, loss: 0.6853
2022-07-01 14:16:01 - train: epoch 0111, iter [05000, 05004], lr: 0.001382, loss: 0.8133
2022-07-01 14:16:02 - train: epoch 111, train_loss: 0.7637
2022-07-01 14:17:18 - eval: epoch: 111, acc1: 77.320%, acc5: 93.538%, test_loss: 0.9099, per_image_load_time: 2.275ms, per_image_inference_time: 0.620ms
2022-07-01 14:17:19 - until epoch: 111, best_acc1: 77.320%
2022-07-01 14:17:19 - epoch 112 lr: 0.001381
2022-07-01 14:17:58 - train: epoch 0112, iter [00100, 05004], lr: 0.001375, loss: 0.7865
2022-07-01 14:18:30 - train: epoch 0112, iter [00200, 05004], lr: 0.001369, loss: 0.7362
2022-07-01 14:19:03 - train: epoch 0112, iter [00300, 05004], lr: 0.001363, loss: 0.6389
2022-07-01 14:19:36 - train: epoch 0112, iter [00400, 05004], lr: 0.001357, loss: 0.6564
2022-07-01 14:20:08 - train: epoch 0112, iter [00500, 05004], lr: 0.001351, loss: 0.8363
2022-07-01 14:20:41 - train: epoch 0112, iter [00600, 05004], lr: 0.001345, loss: 0.6905
2022-07-01 14:21:14 - train: epoch 0112, iter [00700, 05004], lr: 0.001339, loss: 0.8157
2022-07-01 14:21:47 - train: epoch 0112, iter [00800, 05004], lr: 0.001333, loss: 0.6690
2022-07-01 14:22:20 - train: epoch 0112, iter [00900, 05004], lr: 0.001327, loss: 0.6922
2022-07-01 14:22:53 - train: epoch 0112, iter [01000, 05004], lr: 0.001321, loss: 0.8034
2022-07-01 14:23:25 - train: epoch 0112, iter [01100, 05004], lr: 0.001315, loss: 0.7140
2022-07-01 14:23:58 - train: epoch 0112, iter [01200, 05004], lr: 0.001309, loss: 0.8793
2022-07-01 14:24:30 - train: epoch 0112, iter [01300, 05004], lr: 0.001303, loss: 0.7923
2022-07-01 14:25:03 - train: epoch 0112, iter [01400, 05004], lr: 0.001297, loss: 0.6525
2022-07-01 14:25:35 - train: epoch 0112, iter [01500, 05004], lr: 0.001291, loss: 0.7831
2022-07-01 14:26:08 - train: epoch 0112, iter [01600, 05004], lr: 0.001286, loss: 0.7432
2022-07-01 14:26:42 - train: epoch 0112, iter [01700, 05004], lr: 0.001280, loss: 0.7418
2022-07-01 14:27:15 - train: epoch 0112, iter [01800, 05004], lr: 0.001274, loss: 0.6211
2022-07-01 14:27:47 - train: epoch 0112, iter [01900, 05004], lr: 0.001268, loss: 0.5516
2022-07-01 14:28:20 - train: epoch 0112, iter [02000, 05004], lr: 0.001262, loss: 0.6918
2022-07-01 14:28:52 - train: epoch 0112, iter [02100, 05004], lr: 0.001256, loss: 0.7101
2022-07-01 14:29:25 - train: epoch 0112, iter [02200, 05004], lr: 0.001250, loss: 0.6077
2022-07-01 14:29:58 - train: epoch 0112, iter [02300, 05004], lr: 0.001245, loss: 0.6507
2022-07-01 14:30:30 - train: epoch 0112, iter [02400, 05004], lr: 0.001239, loss: 0.5891
2022-07-01 14:31:03 - train: epoch 0112, iter [02500, 05004], lr: 0.001233, loss: 0.7695
2022-07-01 14:31:36 - train: epoch 0112, iter [02600, 05004], lr: 0.001227, loss: 0.7066
2022-07-01 14:32:09 - train: epoch 0112, iter [02700, 05004], lr: 0.001221, loss: 0.8224
2022-07-01 14:32:41 - train: epoch 0112, iter [02800, 05004], lr: 0.001216, loss: 0.7773
2022-07-01 14:33:14 - train: epoch 0112, iter [02900, 05004], lr: 0.001210, loss: 0.8375
2022-07-01 14:33:47 - train: epoch 0112, iter [03000, 05004], lr: 0.001204, loss: 0.8309
2022-07-01 14:34:20 - train: epoch 0112, iter [03100, 05004], lr: 0.001199, loss: 0.7606
2022-07-01 14:34:53 - train: epoch 0112, iter [03200, 05004], lr: 0.001193, loss: 0.7060
2022-07-01 14:35:26 - train: epoch 0112, iter [03300, 05004], lr: 0.001187, loss: 0.7712
2022-07-01 14:35:59 - train: epoch 0112, iter [03400, 05004], lr: 0.001182, loss: 0.6477
2022-07-01 14:36:32 - train: epoch 0112, iter [03500, 05004], lr: 0.001176, loss: 0.6242
2022-07-01 14:37:05 - train: epoch 0112, iter [03600, 05004], lr: 0.001170, loss: 0.8288
2022-07-01 14:37:37 - train: epoch 0112, iter [03700, 05004], lr: 0.001165, loss: 0.7965
2022-07-01 14:38:10 - train: epoch 0112, iter [03800, 05004], lr: 0.001159, loss: 0.7438
2022-07-01 14:38:43 - train: epoch 0112, iter [03900, 05004], lr: 0.001153, loss: 0.7392
2022-07-01 14:39:16 - train: epoch 0112, iter [04000, 05004], lr: 0.001148, loss: 0.6851
2022-07-01 14:39:50 - train: epoch 0112, iter [04100, 05004], lr: 0.001142, loss: 0.6686
2022-07-01 14:40:23 - train: epoch 0112, iter [04200, 05004], lr: 0.001137, loss: 0.6403
2022-07-01 14:40:56 - train: epoch 0112, iter [04300, 05004], lr: 0.001131, loss: 0.7054
2022-07-01 14:41:28 - train: epoch 0112, iter [04400, 05004], lr: 0.001126, loss: 0.9252
2022-07-01 14:42:01 - train: epoch 0112, iter [04500, 05004], lr: 0.001120, loss: 0.6100
2022-07-01 14:42:34 - train: epoch 0112, iter [04600, 05004], lr: 0.001115, loss: 0.8371
2022-07-01 14:43:07 - train: epoch 0112, iter [04700, 05004], lr: 0.001109, loss: 0.5870
2022-07-01 14:43:41 - train: epoch 0112, iter [04800, 05004], lr: 0.001104, loss: 0.7466
2022-07-01 14:44:14 - train: epoch 0112, iter [04900, 05004], lr: 0.001098, loss: 0.7726
2022-07-01 14:44:47 - train: epoch 0112, iter [05000, 05004], lr: 0.001093, loss: 0.6147
2022-07-01 14:44:49 - train: epoch 112, train_loss: 0.7505
2022-07-01 14:46:05 - eval: epoch: 112, acc1: 77.350%, acc5: 93.564%, test_loss: 0.9089, per_image_load_time: 2.366ms, per_image_inference_time: 0.606ms
2022-07-01 14:46:06 - until epoch: 112, best_acc1: 77.350%
2022-07-01 14:46:06 - epoch 113 lr: 0.001093
2022-07-01 14:46:45 - train: epoch 0113, iter [00100, 05004], lr: 0.001087, loss: 0.8438
2022-07-01 14:47:17 - train: epoch 0113, iter [00200, 05004], lr: 0.001082, loss: 0.7277
2022-07-01 14:47:50 - train: epoch 0113, iter [00300, 05004], lr: 0.001076, loss: 0.6291
2022-07-01 14:48:23 - train: epoch 0113, iter [00400, 05004], lr: 0.001071, loss: 0.7222
2022-07-01 14:48:56 - train: epoch 0113, iter [00500, 05004], lr: 0.001066, loss: 0.8644
2022-07-01 14:49:29 - train: epoch 0113, iter [00600, 05004], lr: 0.001060, loss: 0.6650
2022-07-01 14:50:01 - train: epoch 0113, iter [00700, 05004], lr: 0.001055, loss: 0.6278
2022-07-01 14:50:34 - train: epoch 0113, iter [00800, 05004], lr: 0.001050, loss: 0.7839
2022-07-01 14:51:07 - train: epoch 0113, iter [00900, 05004], lr: 0.001044, loss: 0.5593
2022-07-01 14:51:40 - train: epoch 0113, iter [01000, 05004], lr: 0.001039, loss: 0.7547
2022-07-01 14:52:12 - train: epoch 0113, iter [01100, 05004], lr: 0.001034, loss: 0.7096
2022-07-01 14:52:45 - train: epoch 0113, iter [01200, 05004], lr: 0.001028, loss: 0.8738
2022-07-01 14:53:18 - train: epoch 0113, iter [01300, 05004], lr: 0.001023, loss: 0.5884
2022-07-01 14:53:50 - train: epoch 0113, iter [01400, 05004], lr: 0.001018, loss: 0.8166
2022-07-01 14:54:23 - train: epoch 0113, iter [01500, 05004], lr: 0.001013, loss: 0.7878
2022-07-01 14:54:56 - train: epoch 0113, iter [01600, 05004], lr: 0.001007, loss: 0.7343
2022-07-01 14:55:29 - train: epoch 0113, iter [01700, 05004], lr: 0.001002, loss: 0.7029
2022-07-01 14:56:01 - train: epoch 0113, iter [01800, 05004], lr: 0.000997, loss: 0.6266
2022-07-01 14:56:34 - train: epoch 0113, iter [01900, 05004], lr: 0.000992, loss: 0.7047
2022-07-01 14:57:07 - train: epoch 0113, iter [02000, 05004], lr: 0.000987, loss: 0.7573
2022-07-01 14:57:40 - train: epoch 0113, iter [02100, 05004], lr: 0.000981, loss: 0.8754
2022-07-01 14:58:13 - train: epoch 0113, iter [02200, 05004], lr: 0.000976, loss: 0.7535
2022-07-01 14:58:46 - train: epoch 0113, iter [02300, 05004], lr: 0.000971, loss: 0.8582
2022-07-01 14:59:19 - train: epoch 0113, iter [02400, 05004], lr: 0.000966, loss: 0.8786
2022-07-01 14:59:52 - train: epoch 0113, iter [02500, 05004], lr: 0.000961, loss: 0.8150
2022-07-01 15:00:25 - train: epoch 0113, iter [02600, 05004], lr: 0.000956, loss: 0.5942
2022-07-01 15:00:58 - train: epoch 0113, iter [02700, 05004], lr: 0.000951, loss: 0.7249
2022-07-01 15:01:31 - train: epoch 0113, iter [02800, 05004], lr: 0.000946, loss: 0.7622
2022-07-01 15:02:04 - train: epoch 0113, iter [02900, 05004], lr: 0.000941, loss: 0.8036
2022-07-01 15:02:37 - train: epoch 0113, iter [03000, 05004], lr: 0.000935, loss: 0.7234
2022-07-01 15:03:10 - train: epoch 0113, iter [03100, 05004], lr: 0.000930, loss: 0.5774
2022-07-01 15:03:43 - train: epoch 0113, iter [03200, 05004], lr: 0.000925, loss: 0.6277
2022-07-01 15:04:16 - train: epoch 0113, iter [03300, 05004], lr: 0.000920, loss: 0.7957
2022-07-01 15:04:49 - train: epoch 0113, iter [03400, 05004], lr: 0.000915, loss: 0.6134
2022-07-01 15:05:22 - train: epoch 0113, iter [03500, 05004], lr: 0.000910, loss: 0.7211
2022-07-01 15:05:55 - train: epoch 0113, iter [03600, 05004], lr: 0.000906, loss: 1.0021
2022-07-01 15:06:28 - train: epoch 0113, iter [03700, 05004], lr: 0.000901, loss: 0.5315
2022-07-01 15:07:00 - train: epoch 0113, iter [03800, 05004], lr: 0.000896, loss: 0.8783
2022-07-01 15:07:34 - train: epoch 0113, iter [03900, 05004], lr: 0.000891, loss: 0.7883
2022-07-01 15:08:06 - train: epoch 0113, iter [04000, 05004], lr: 0.000886, loss: 0.6960
2022-07-01 15:08:39 - train: epoch 0113, iter [04100, 05004], lr: 0.000881, loss: 0.7759
2022-07-01 15:09:12 - train: epoch 0113, iter [04200, 05004], lr: 0.000876, loss: 0.8027
2022-07-01 15:09:45 - train: epoch 0113, iter [04300, 05004], lr: 0.000871, loss: 0.6949
2022-07-01 15:10:18 - train: epoch 0113, iter [04400, 05004], lr: 0.000866, loss: 0.6842
2022-07-01 15:10:51 - train: epoch 0113, iter [04500, 05004], lr: 0.000861, loss: 0.7097
2022-07-01 15:11:23 - train: epoch 0113, iter [04600, 05004], lr: 0.000857, loss: 0.9520
2022-07-01 15:11:56 - train: epoch 0113, iter [04700, 05004], lr: 0.000852, loss: 0.6210
2022-07-01 15:12:29 - train: epoch 0113, iter [04800, 05004], lr: 0.000847, loss: 0.8965
2022-07-01 15:13:02 - train: epoch 0113, iter [04900, 05004], lr: 0.000842, loss: 0.7221
2022-07-01 15:13:35 - train: epoch 0113, iter [05000, 05004], lr: 0.000837, loss: 0.7336
2022-07-01 15:13:37 - train: epoch 113, train_loss: 0.7369
2022-07-01 15:14:53 - eval: epoch: 113, acc1: 77.502%, acc5: 93.612%, test_loss: 0.9026, per_image_load_time: 2.327ms, per_image_inference_time: 0.587ms
2022-07-01 15:14:54 - until epoch: 113, best_acc1: 77.502%
2022-07-01 15:14:54 - epoch 114 lr: 0.000837
2022-07-01 15:15:32 - train: epoch 0114, iter [00100, 05004], lr: 0.000832, loss: 0.9076
2022-07-01 15:16:05 - train: epoch 0114, iter [00200, 05004], lr: 0.000828, loss: 0.7306
2022-07-01 15:16:37 - train: epoch 0114, iter [00300, 05004], lr: 0.000823, loss: 0.7681
2022-07-01 15:17:09 - train: epoch 0114, iter [00400, 05004], lr: 0.000818, loss: 0.9022
2022-07-01 15:17:42 - train: epoch 0114, iter [00500, 05004], lr: 0.000814, loss: 0.7134
2022-07-01 15:18:15 - train: epoch 0114, iter [00600, 05004], lr: 0.000809, loss: 0.7594
2022-07-01 15:18:47 - train: epoch 0114, iter [00700, 05004], lr: 0.000804, loss: 0.7092
2022-07-01 15:19:20 - train: epoch 0114, iter [00800, 05004], lr: 0.000800, loss: 0.7145
2022-07-01 15:19:52 - train: epoch 0114, iter [00900, 05004], lr: 0.000795, loss: 0.6772
2022-07-01 15:20:25 - train: epoch 0114, iter [01000, 05004], lr: 0.000790, loss: 0.7323
2022-07-01 15:20:57 - train: epoch 0114, iter [01100, 05004], lr: 0.000786, loss: 0.6482
2022-07-01 15:21:30 - train: epoch 0114, iter [01200, 05004], lr: 0.000781, loss: 0.7724
2022-07-01 15:22:02 - train: epoch 0114, iter [01300, 05004], lr: 0.000776, loss: 0.5562
2022-07-01 15:22:35 - train: epoch 0114, iter [01400, 05004], lr: 0.000772, loss: 0.7418
2022-07-01 15:23:08 - train: epoch 0114, iter [01500, 05004], lr: 0.000767, loss: 0.6619
2022-07-01 15:23:41 - train: epoch 0114, iter [01600, 05004], lr: 0.000763, loss: 0.6253
2022-07-01 15:24:14 - train: epoch 0114, iter [01700, 05004], lr: 0.000758, loss: 0.5901
2022-07-01 15:24:46 - train: epoch 0114, iter [01800, 05004], lr: 0.000754, loss: 0.7664
2022-07-01 15:25:19 - train: epoch 0114, iter [01900, 05004], lr: 0.000749, loss: 0.5458
2022-07-01 15:25:52 - train: epoch 0114, iter [02000, 05004], lr: 0.000745, loss: 0.8441
2022-07-01 15:26:24 - train: epoch 0114, iter [02100, 05004], lr: 0.000740, loss: 0.7559
2022-07-01 15:26:57 - train: epoch 0114, iter [02200, 05004], lr: 0.000736, loss: 0.7840
2022-07-01 15:27:30 - train: epoch 0114, iter [02300, 05004], lr: 0.000731, loss: 0.7790
2022-07-01 15:28:03 - train: epoch 0114, iter [02400, 05004], lr: 0.000727, loss: 0.7601
2022-07-01 15:28:36 - train: epoch 0114, iter [02500, 05004], lr: 0.000722, loss: 0.5994
2022-07-01 15:29:09 - train: epoch 0114, iter [02600, 05004], lr: 0.000718, loss: 0.5990
2022-07-01 15:29:41 - train: epoch 0114, iter [02700, 05004], lr: 0.000713, loss: 0.6881
2022-07-01 15:30:14 - train: epoch 0114, iter [02800, 05004], lr: 0.000709, loss: 0.8491
2022-07-01 15:30:47 - train: epoch 0114, iter [02900, 05004], lr: 0.000705, loss: 0.5817
2022-07-01 15:31:20 - train: epoch 0114, iter [03000, 05004], lr: 0.000700, loss: 0.6517
2022-07-01 15:31:53 - train: epoch 0114, iter [03100, 05004], lr: 0.000696, loss: 0.8741
2022-07-01 15:32:26 - train: epoch 0114, iter [03200, 05004], lr: 0.000692, loss: 0.7740
2022-07-01 15:32:59 - train: epoch 0114, iter [03300, 05004], lr: 0.000687, loss: 0.9013
2022-07-01 15:33:32 - train: epoch 0114, iter [03400, 05004], lr: 0.000683, loss: 0.6295
2022-07-01 15:34:05 - train: epoch 0114, iter [03500, 05004], lr: 0.000679, loss: 0.6047
2022-07-01 15:34:37 - train: epoch 0114, iter [03600, 05004], lr: 0.000674, loss: 0.7134
2022-07-01 15:35:10 - train: epoch 0114, iter [03700, 05004], lr: 0.000670, loss: 0.7035
2022-07-01 15:35:43 - train: epoch 0114, iter [03800, 05004], lr: 0.000666, loss: 0.7318
2022-07-01 15:36:16 - train: epoch 0114, iter [03900, 05004], lr: 0.000662, loss: 0.6719
2022-07-01 15:36:49 - train: epoch 0114, iter [04000, 05004], lr: 0.000657, loss: 0.6059
2022-07-01 15:37:22 - train: epoch 0114, iter [04100, 05004], lr: 0.000653, loss: 0.7767
2022-07-01 15:37:55 - train: epoch 0114, iter [04200, 05004], lr: 0.000649, loss: 0.7475
2022-07-01 15:38:28 - train: epoch 0114, iter [04300, 05004], lr: 0.000645, loss: 0.6757
2022-07-01 15:39:01 - train: epoch 0114, iter [04400, 05004], lr: 0.000641, loss: 0.7665
2022-07-01 15:39:34 - train: epoch 0114, iter [04500, 05004], lr: 0.000636, loss: 0.8062
2022-07-01 15:40:07 - train: epoch 0114, iter [04600, 05004], lr: 0.000632, loss: 0.6701
2022-07-01 15:40:40 - train: epoch 0114, iter [04700, 05004], lr: 0.000628, loss: 0.7196
2022-07-01 15:41:13 - train: epoch 0114, iter [04800, 05004], lr: 0.000624, loss: 0.9293
2022-07-01 15:41:46 - train: epoch 0114, iter [04900, 05004], lr: 0.000620, loss: 0.7124
2022-07-01 15:42:18 - train: epoch 0114, iter [05000, 05004], lr: 0.000616, loss: 0.7383
2022-07-01 15:42:20 - train: epoch 114, train_loss: 0.7260
2022-07-01 15:43:35 - eval: epoch: 114, acc1: 77.596%, acc5: 93.600%, test_loss: 0.8999, per_image_load_time: 2.325ms, per_image_inference_time: 0.601ms
2022-07-01 15:43:36 - until epoch: 114, best_acc1: 77.596%
2022-07-01 15:43:36 - epoch 115 lr: 0.000616
2022-07-01 15:44:14 - train: epoch 0115, iter [00100, 05004], lr: 0.000611, loss: 0.6687
2022-07-01 15:44:47 - train: epoch 0115, iter [00200, 05004], lr: 0.000607, loss: 0.7132
2022-07-01 15:45:20 - train: epoch 0115, iter [00300, 05004], lr: 0.000603, loss: 0.7866
2022-07-01 15:45:53 - train: epoch 0115, iter [00400, 05004], lr: 0.000599, loss: 0.5726
2022-07-01 15:46:25 - train: epoch 0115, iter [00500, 05004], lr: 0.000595, loss: 0.7279
2022-07-01 15:46:58 - train: epoch 0115, iter [00600, 05004], lr: 0.000591, loss: 0.7190
2022-07-01 15:47:31 - train: epoch 0115, iter [00700, 05004], lr: 0.000587, loss: 0.6185
2022-07-01 15:48:04 - train: epoch 0115, iter [00800, 05004], lr: 0.000583, loss: 0.5790
2022-07-01 15:48:37 - train: epoch 0115, iter [00900, 05004], lr: 0.000579, loss: 0.8600
2022-07-01 15:49:10 - train: epoch 0115, iter [01000, 05004], lr: 0.000575, loss: 0.6612
2022-07-01 15:49:43 - train: epoch 0115, iter [01100, 05004], lr: 0.000571, loss: 0.5754
2022-07-01 15:50:16 - train: epoch 0115, iter [01200, 05004], lr: 0.000567, loss: 0.7905
2022-07-01 15:50:49 - train: epoch 0115, iter [01300, 05004], lr: 0.000564, loss: 0.7487
2022-07-01 15:51:21 - train: epoch 0115, iter [01400, 05004], lr: 0.000560, loss: 0.6667
2022-07-01 15:51:54 - train: epoch 0115, iter [01500, 05004], lr: 0.000556, loss: 0.8500
2022-07-01 15:52:26 - train: epoch 0115, iter [01600, 05004], lr: 0.000552, loss: 0.6745
2022-07-01 15:52:59 - train: epoch 0115, iter [01700, 05004], lr: 0.000548, loss: 0.6432
2022-07-01 15:53:32 - train: epoch 0115, iter [01800, 05004], lr: 0.000544, loss: 0.6464
2022-07-01 15:54:05 - train: epoch 0115, iter [01900, 05004], lr: 0.000540, loss: 0.6619
2022-07-01 15:54:38 - train: epoch 0115, iter [02000, 05004], lr: 0.000536, loss: 0.8387
2022-07-01 15:55:11 - train: epoch 0115, iter [02100, 05004], lr: 0.000533, loss: 0.6881
2022-07-01 15:55:44 - train: epoch 0115, iter [02200, 05004], lr: 0.000529, loss: 0.8014
2022-07-01 15:56:17 - train: epoch 0115, iter [02300, 05004], lr: 0.000525, loss: 0.7974
2022-07-01 15:56:50 - train: epoch 0115, iter [02400, 05004], lr: 0.000521, loss: 0.7144
2022-07-01 15:57:23 - train: epoch 0115, iter [02500, 05004], lr: 0.000518, loss: 0.6797
2022-07-01 15:57:56 - train: epoch 0115, iter [02600, 05004], lr: 0.000514, loss: 0.7320
2022-07-01 15:58:29 - train: epoch 0115, iter [02700, 05004], lr: 0.000510, loss: 0.6792
2022-07-01 15:59:02 - train: epoch 0115, iter [02800, 05004], lr: 0.000506, loss: 0.7090
2022-07-01 15:59:35 - train: epoch 0115, iter [02900, 05004], lr: 0.000503, loss: 0.6110
2022-07-01 16:00:08 - train: epoch 0115, iter [03000, 05004], lr: 0.000499, loss: 0.6144
2022-07-01 16:00:41 - train: epoch 0115, iter [03100, 05004], lr: 0.000495, loss: 0.7384
2022-07-01 16:01:13 - train: epoch 0115, iter [03200, 05004], lr: 0.000492, loss: 0.7649
2022-07-01 16:01:46 - train: epoch 0115, iter [03300, 05004], lr: 0.000488, loss: 0.7261
2022-07-01 16:02:19 - train: epoch 0115, iter [03400, 05004], lr: 0.000484, loss: 0.7011
2022-07-01 16:02:52 - train: epoch 0115, iter [03500, 05004], lr: 0.000481, loss: 0.7411
2022-07-01 16:03:25 - train: epoch 0115, iter [03600, 05004], lr: 0.000477, loss: 0.6313
2022-07-01 16:03:58 - train: epoch 0115, iter [03700, 05004], lr: 0.000473, loss: 0.6848
2022-07-01 16:04:31 - train: epoch 0115, iter [03800, 05004], lr: 0.000470, loss: 0.8067
2022-07-01 16:05:04 - train: epoch 0115, iter [03900, 05004], lr: 0.000466, loss: 0.6687
2022-07-01 16:05:37 - train: epoch 0115, iter [04000, 05004], lr: 0.000463, loss: 0.8316
2022-07-01 16:06:10 - train: epoch 0115, iter [04100, 05004], lr: 0.000459, loss: 0.7362
2022-07-01 16:06:43 - train: epoch 0115, iter [04200, 05004], lr: 0.000456, loss: 0.6338
2022-07-01 16:07:16 - train: epoch 0115, iter [04300, 05004], lr: 0.000452, loss: 0.7213
2022-07-01 16:07:49 - train: epoch 0115, iter [04400, 05004], lr: 0.000449, loss: 0.7915
2022-07-01 16:08:22 - train: epoch 0115, iter [04500, 05004], lr: 0.000445, loss: 0.5915
2022-07-01 16:08:54 - train: epoch 0115, iter [04600, 05004], lr: 0.000442, loss: 0.7848
2022-07-01 16:09:27 - train: epoch 0115, iter [04700, 05004], lr: 0.000438, loss: 0.7451
2022-07-01 16:10:00 - train: epoch 0115, iter [04800, 05004], lr: 0.000435, loss: 0.6396
2022-07-01 16:10:32 - train: epoch 0115, iter [04900, 05004], lr: 0.000431, loss: 0.7270
2022-07-01 16:11:05 - train: epoch 0115, iter [05000, 05004], lr: 0.000428, loss: 0.8082
2022-07-01 16:11:07 - train: epoch 115, train_loss: 0.7166
2022-07-01 16:12:22 - eval: epoch: 115, acc1: 77.688%, acc5: 93.556%, test_loss: 0.8969, per_image_load_time: 2.298ms, per_image_inference_time: 0.595ms
2022-07-01 16:12:23 - until epoch: 115, best_acc1: 77.688%
2022-07-01 16:12:23 - epoch 116 lr: 0.000428
2022-07-01 16:13:03 - train: epoch 0116, iter [00100, 05004], lr: 0.000424, loss: 0.6872
2022-07-01 16:13:35 - train: epoch 0116, iter [00200, 05004], lr: 0.000421, loss: 0.7951
2022-07-01 16:14:07 - train: epoch 0116, iter [00300, 05004], lr: 0.000418, loss: 0.5607
2022-07-01 16:14:40 - train: epoch 0116, iter [00400, 05004], lr: 0.000414, loss: 0.6892
2022-07-01 16:15:12 - train: epoch 0116, iter [00500, 05004], lr: 0.000411, loss: 0.8032
2022-07-01 16:15:45 - train: epoch 0116, iter [00600, 05004], lr: 0.000408, loss: 0.7417
2022-07-01 16:16:18 - train: epoch 0116, iter [00700, 05004], lr: 0.000404, loss: 0.8297
2022-07-01 16:16:51 - train: epoch 0116, iter [00800, 05004], lr: 0.000401, loss: 0.7703
2022-07-01 16:17:23 - train: epoch 0116, iter [00900, 05004], lr: 0.000398, loss: 0.7895
2022-07-01 16:17:56 - train: epoch 0116, iter [01000, 05004], lr: 0.000394, loss: 0.7333
2022-07-01 16:18:29 - train: epoch 0116, iter [01100, 05004], lr: 0.000391, loss: 0.6201
2022-07-01 16:19:01 - train: epoch 0116, iter [01200, 05004], lr: 0.000388, loss: 0.7752
2022-07-01 16:19:35 - train: epoch 0116, iter [01300, 05004], lr: 0.000385, loss: 0.8438
2022-07-01 16:20:07 - train: epoch 0116, iter [01400, 05004], lr: 0.000381, loss: 0.7299
2022-07-01 16:20:40 - train: epoch 0116, iter [01500, 05004], lr: 0.000378, loss: 0.6099
2022-07-01 16:21:13 - train: epoch 0116, iter [01600, 05004], lr: 0.000375, loss: 0.7707
2022-07-01 16:21:45 - train: epoch 0116, iter [01700, 05004], lr: 0.000372, loss: 0.6451
2022-07-01 16:22:18 - train: epoch 0116, iter [01800, 05004], lr: 0.000368, loss: 0.8636
2022-07-01 16:22:51 - train: epoch 0116, iter [01900, 05004], lr: 0.000365, loss: 0.6287
2022-07-01 16:23:24 - train: epoch 0116, iter [02000, 05004], lr: 0.000362, loss: 0.6216
2022-07-01 16:23:56 - train: epoch 0116, iter [02100, 05004], lr: 0.000359, loss: 0.7957
2022-07-01 16:24:29 - train: epoch 0116, iter [02200, 05004], lr: 0.000356, loss: 0.6795
2022-07-01 16:25:02 - train: epoch 0116, iter [02300, 05004], lr: 0.000353, loss: 0.8749
2022-07-01 16:25:34 - train: epoch 0116, iter [02400, 05004], lr: 0.000350, loss: 0.7619
2022-07-01 16:26:07 - train: epoch 0116, iter [02500, 05004], lr: 0.000347, loss: 0.6180
2022-07-01 16:26:40 - train: epoch 0116, iter [02600, 05004], lr: 0.000344, loss: 0.6642
2022-07-01 16:27:12 - train: epoch 0116, iter [02700, 05004], lr: 0.000341, loss: 0.7595
2022-07-01 16:27:45 - train: epoch 0116, iter [02800, 05004], lr: 0.000337, loss: 0.8582
2022-07-01 16:28:18 - train: epoch 0116, iter [02900, 05004], lr: 0.000334, loss: 0.8225
2022-07-01 16:28:51 - train: epoch 0116, iter [03000, 05004], lr: 0.000331, loss: 0.7696
2022-07-01 16:29:24 - train: epoch 0116, iter [03100, 05004], lr: 0.000328, loss: 0.8256
2022-07-01 16:29:57 - train: epoch 0116, iter [03200, 05004], lr: 0.000325, loss: 0.8305
2022-07-01 16:30:30 - train: epoch 0116, iter [03300, 05004], lr: 0.000322, loss: 0.9010
2022-07-01 16:31:03 - train: epoch 0116, iter [03400, 05004], lr: 0.000320, loss: 0.8692
2022-07-01 16:31:35 - train: epoch 0116, iter [03500, 05004], lr: 0.000317, loss: 0.7624
2022-07-01 16:32:08 - train: epoch 0116, iter [03600, 05004], lr: 0.000314, loss: 0.8981
2022-07-01 16:32:41 - train: epoch 0116, iter [03700, 05004], lr: 0.000311, loss: 0.7042
2022-07-01 16:33:14 - train: epoch 0116, iter [03800, 05004], lr: 0.000308, loss: 0.6279
2022-07-01 16:33:47 - train: epoch 0116, iter [03900, 05004], lr: 0.000305, loss: 0.7614
2022-07-01 16:34:20 - train: epoch 0116, iter [04000, 05004], lr: 0.000302, loss: 0.6057
2022-07-01 16:34:53 - train: epoch 0116, iter [04100, 05004], lr: 0.000299, loss: 0.7882
2022-07-01 16:35:26 - train: epoch 0116, iter [04200, 05004], lr: 0.000296, loss: 0.7718
2022-07-01 16:35:59 - train: epoch 0116, iter [04300, 05004], lr: 0.000293, loss: 0.6676
2022-07-01 16:36:32 - train: epoch 0116, iter [04400, 05004], lr: 0.000291, loss: 0.6522
2022-07-01 16:37:04 - train: epoch 0116, iter [04500, 05004], lr: 0.000288, loss: 0.6747
2022-07-01 16:37:37 - train: epoch 0116, iter [04600, 05004], lr: 0.000285, loss: 0.8794
2022-07-01 16:38:10 - train: epoch 0116, iter [04700, 05004], lr: 0.000282, loss: 0.7018
2022-07-01 16:38:43 - train: epoch 0116, iter [04800, 05004], lr: 0.000280, loss: 0.7100
2022-07-01 16:39:16 - train: epoch 0116, iter [04900, 05004], lr: 0.000277, loss: 0.5741
2022-07-01 16:39:49 - train: epoch 0116, iter [05000, 05004], lr: 0.000274, loss: 0.6687
2022-07-01 16:39:50 - train: epoch 116, train_loss: 0.7090
2022-07-01 16:41:05 - eval: epoch: 116, acc1: 77.692%, acc5: 93.616%, test_loss: 0.8953, per_image_load_time: 2.302ms, per_image_inference_time: 0.599ms
2022-07-01 16:41:06 - until epoch: 116, best_acc1: 77.692%
2022-07-01 16:41:06 - epoch 117 lr: 0.000274
2022-07-01 16:41:45 - train: epoch 0117, iter [00100, 05004], lr: 0.000271, loss: 0.8772
2022-07-01 16:42:17 - train: epoch 0117, iter [00200, 05004], lr: 0.000268, loss: 0.6422
2022-07-01 16:42:50 - train: epoch 0117, iter [00300, 05004], lr: 0.000266, loss: 0.8586
2022-07-01 16:43:22 - train: epoch 0117, iter [00400, 05004], lr: 0.000263, loss: 0.6097
2022-07-01 16:43:55 - train: epoch 0117, iter [00500, 05004], lr: 0.000260, loss: 0.5664
2022-07-01 16:44:28 - train: epoch 0117, iter [00600, 05004], lr: 0.000258, loss: 0.7742
2022-07-01 16:45:01 - train: epoch 0117, iter [00700, 05004], lr: 0.000255, loss: 0.7193
2022-07-01 16:45:33 - train: epoch 0117, iter [00800, 05004], lr: 0.000252, loss: 0.6193
2022-07-01 16:46:06 - train: epoch 0117, iter [00900, 05004], lr: 0.000250, loss: 0.5832
2022-07-01 16:46:39 - train: epoch 0117, iter [01000, 05004], lr: 0.000247, loss: 0.6458
2022-07-01 16:47:12 - train: epoch 0117, iter [01100, 05004], lr: 0.000245, loss: 0.6938
2022-07-01 16:47:45 - train: epoch 0117, iter [01200, 05004], lr: 0.000242, loss: 0.7078
2022-07-01 16:48:17 - train: epoch 0117, iter [01300, 05004], lr: 0.000240, loss: 0.8266
2022-07-01 16:48:50 - train: epoch 0117, iter [01400, 05004], lr: 0.000237, loss: 0.8667
2022-07-01 16:49:23 - train: epoch 0117, iter [01500, 05004], lr: 0.000234, loss: 0.6823
2022-07-01 16:49:57 - train: epoch 0117, iter [01600, 05004], lr: 0.000232, loss: 0.6324
2022-07-01 16:50:29 - train: epoch 0117, iter [01700, 05004], lr: 0.000229, loss: 0.6833
2022-07-01 16:51:03 - train: epoch 0117, iter [01800, 05004], lr: 0.000227, loss: 0.6828
2022-07-01 16:51:36 - train: epoch 0117, iter [01900, 05004], lr: 0.000224, loss: 0.5851
2022-07-01 16:52:09 - train: epoch 0117, iter [02000, 05004], lr: 0.000222, loss: 0.7605
2022-07-01 16:52:41 - train: epoch 0117, iter [02100, 05004], lr: 0.000219, loss: 0.6674
2022-07-01 16:53:14 - train: epoch 0117, iter [02200, 05004], lr: 0.000217, loss: 0.6170
2022-07-01 16:53:47 - train: epoch 0117, iter [02300, 05004], lr: 0.000215, loss: 0.7502
2022-07-01 16:54:20 - train: epoch 0117, iter [02400, 05004], lr: 0.000212, loss: 0.5679
2022-07-01 16:54:54 - train: epoch 0117, iter [02500, 05004], lr: 0.000210, loss: 0.8438
2022-07-01 16:55:27 - train: epoch 0117, iter [02600, 05004], lr: 0.000207, loss: 0.6908
2022-07-01 16:56:00 - train: epoch 0117, iter [02700, 05004], lr: 0.000205, loss: 0.5496
2022-07-01 16:56:33 - train: epoch 0117, iter [02800, 05004], lr: 0.000203, loss: 0.5688
2022-07-01 16:57:05 - train: epoch 0117, iter [02900, 05004], lr: 0.000200, loss: 0.7009
2022-07-01 16:57:38 - train: epoch 0117, iter [03000, 05004], lr: 0.000198, loss: 0.5297
2022-07-01 16:58:10 - train: epoch 0117, iter [03100, 05004], lr: 0.000196, loss: 0.6780
2022-07-01 16:58:43 - train: epoch 0117, iter [03200, 05004], lr: 0.000193, loss: 0.7611
2022-07-01 16:59:16 - train: epoch 0117, iter [03300, 05004], lr: 0.000191, loss: 0.6823
2022-07-01 16:59:49 - train: epoch 0117, iter [03400, 05004], lr: 0.000189, loss: 0.6529
2022-07-01 17:00:22 - train: epoch 0117, iter [03500, 05004], lr: 0.000187, loss: 0.8595
2022-07-01 17:00:55 - train: epoch 0117, iter [03600, 05004], lr: 0.000184, loss: 0.8340
2022-07-01 17:01:28 - train: epoch 0117, iter [03700, 05004], lr: 0.000182, loss: 0.6773
2022-07-01 17:02:01 - train: epoch 0117, iter [03800, 05004], lr: 0.000180, loss: 0.6785
2022-07-01 17:02:34 - train: epoch 0117, iter [03900, 05004], lr: 0.000178, loss: 0.5585
2022-07-01 17:03:07 - train: epoch 0117, iter [04000, 05004], lr: 0.000175, loss: 0.6689
2022-07-01 17:03:40 - train: epoch 0117, iter [04100, 05004], lr: 0.000173, loss: 0.7193
2022-07-01 17:04:13 - train: epoch 0117, iter [04200, 05004], lr: 0.000171, loss: 0.7865
2022-07-01 17:04:46 - train: epoch 0117, iter [04300, 05004], lr: 0.000169, loss: 0.6767
2022-07-01 17:05:19 - train: epoch 0117, iter [04400, 05004], lr: 0.000167, loss: 0.5861
2022-07-01 17:05:52 - train: epoch 0117, iter [04500, 05004], lr: 0.000165, loss: 0.5745
2022-07-01 17:06:25 - train: epoch 0117, iter [04600, 05004], lr: 0.000163, loss: 0.5978
2022-07-01 17:06:58 - train: epoch 0117, iter [04700, 05004], lr: 0.000160, loss: 0.7668
2022-07-01 17:07:32 - train: epoch 0117, iter [04800, 05004], lr: 0.000158, loss: 0.7948
2022-07-01 17:08:06 - train: epoch 0117, iter [04900, 05004], lr: 0.000156, loss: 0.8396
2022-07-01 17:08:38 - train: epoch 0117, iter [05000, 05004], lr: 0.000154, loss: 0.8074
2022-07-01 17:08:40 - train: epoch 117, train_loss: 0.7027
2022-07-01 17:09:57 - eval: epoch: 117, acc1: 77.712%, acc5: 93.656%, test_loss: 0.8941, per_image_load_time: 2.312ms, per_image_inference_time: 0.626ms
2022-07-01 17:09:58 - until epoch: 117, best_acc1: 77.712%
2022-07-01 17:09:58 - epoch 118 lr: 0.000154
2022-07-01 17:10:37 - train: epoch 0118, iter [00100, 05004], lr: 0.000152, loss: 0.6767
2022-07-01 17:11:09 - train: epoch 0118, iter [00200, 05004], lr: 0.000150, loss: 0.6413
2022-07-01 17:11:42 - train: epoch 0118, iter [00300, 05004], lr: 0.000148, loss: 0.7817
2022-07-01 17:12:15 - train: epoch 0118, iter [00400, 05004], lr: 0.000146, loss: 0.8329
2022-07-01 17:12:48 - train: epoch 0118, iter [00500, 05004], lr: 0.000144, loss: 0.6143
2022-07-01 17:13:21 - train: epoch 0118, iter [00600, 05004], lr: 0.000142, loss: 0.7298
2022-07-01 17:13:54 - train: epoch 0118, iter [00700, 05004], lr: 0.000140, loss: 0.6724
2022-07-01 17:14:27 - train: epoch 0118, iter [00800, 05004], lr: 0.000138, loss: 0.6593
2022-07-01 17:15:00 - train: epoch 0118, iter [00900, 05004], lr: 0.000136, loss: 0.6737
2022-07-01 17:15:33 - train: epoch 0118, iter [01000, 05004], lr: 0.000134, loss: 0.9196
2022-07-01 17:16:06 - train: epoch 0118, iter [01100, 05004], lr: 0.000132, loss: 0.7235
2022-07-01 17:16:39 - train: epoch 0118, iter [01200, 05004], lr: 0.000130, loss: 0.8059
2022-07-01 17:17:13 - train: epoch 0118, iter [01300, 05004], lr: 0.000129, loss: 0.9093
2022-07-01 17:17:46 - train: epoch 0118, iter [01400, 05004], lr: 0.000127, loss: 0.6299
2022-07-01 17:18:19 - train: epoch 0118, iter [01500, 05004], lr: 0.000125, loss: 0.6251
2022-07-01 17:18:53 - train: epoch 0118, iter [01600, 05004], lr: 0.000123, loss: 0.6442
2022-07-01 17:19:26 - train: epoch 0118, iter [01700, 05004], lr: 0.000121, loss: 0.7385
2022-07-01 17:19:59 - train: epoch 0118, iter [01800, 05004], lr: 0.000119, loss: 0.7015
2022-07-01 17:20:32 - train: epoch 0118, iter [01900, 05004], lr: 0.000118, loss: 0.8492
2022-07-01 17:21:05 - train: epoch 0118, iter [02000, 05004], lr: 0.000116, loss: 0.6599
2022-07-01 17:21:38 - train: epoch 0118, iter [02100, 05004], lr: 0.000114, loss: 0.7246
2022-07-01 17:22:12 - train: epoch 0118, iter [02200, 05004], lr: 0.000112, loss: 0.6309
2022-07-01 17:22:45 - train: epoch 0118, iter [02300, 05004], lr: 0.000111, loss: 0.6427
2022-07-01 17:23:18 - train: epoch 0118, iter [02400, 05004], lr: 0.000109, loss: 0.7859
2022-07-01 17:23:51 - train: epoch 0118, iter [02500, 05004], lr: 0.000107, loss: 0.7766
2022-07-01 17:24:23 - train: epoch 0118, iter [02600, 05004], lr: 0.000105, loss: 0.6196
2022-07-01 17:24:56 - train: epoch 0118, iter [02700, 05004], lr: 0.000104, loss: 0.7943
2022-07-01 17:25:29 - train: epoch 0118, iter [02800, 05004], lr: 0.000102, loss: 0.6426
2022-07-01 17:26:02 - train: epoch 0118, iter [02900, 05004], lr: 0.000100, loss: 0.6455
2022-07-01 17:26:35 - train: epoch 0118, iter [03000, 05004], lr: 0.000099, loss: 0.6720
2022-07-01 17:27:08 - train: epoch 0118, iter [03100, 05004], lr: 0.000097, loss: 0.8195
2022-07-01 17:27:42 - train: epoch 0118, iter [03200, 05004], lr: 0.000095, loss: 0.6093
2022-07-01 17:28:14 - train: epoch 0118, iter [03300, 05004], lr: 0.000094, loss: 0.7739
2022-07-01 17:28:48 - train: epoch 0118, iter [03400, 05004], lr: 0.000092, loss: 0.6344
2022-07-01 17:29:21 - train: epoch 0118, iter [03500, 05004], lr: 0.000091, loss: 0.6119
2022-07-01 17:29:54 - train: epoch 0118, iter [03600, 05004], lr: 0.000089, loss: 0.6457
2022-07-01 17:30:27 - train: epoch 0118, iter [03700, 05004], lr: 0.000088, loss: 0.8267
2022-07-01 17:31:01 - train: epoch 0118, iter [03800, 05004], lr: 0.000086, loss: 0.6468
2022-07-01 17:31:34 - train: epoch 0118, iter [03900, 05004], lr: 0.000084, loss: 0.7529
2022-07-01 17:32:07 - train: epoch 0118, iter [04000, 05004], lr: 0.000083, loss: 0.7096
2022-07-01 17:32:40 - train: epoch 0118, iter [04100, 05004], lr: 0.000081, loss: 0.8280
2022-07-01 17:33:13 - train: epoch 0118, iter [04200, 05004], lr: 0.000080, loss: 0.7326
2022-07-01 17:33:46 - train: epoch 0118, iter [04300, 05004], lr: 0.000079, loss: 0.5615
2022-07-01 17:34:20 - train: epoch 0118, iter [04400, 05004], lr: 0.000077, loss: 0.6527
2022-07-01 17:34:53 - train: epoch 0118, iter [04500, 05004], lr: 0.000076, loss: 0.6742
2022-07-01 17:35:26 - train: epoch 0118, iter [04600, 05004], lr: 0.000074, loss: 0.8226
2022-07-01 17:35:59 - train: epoch 0118, iter [04700, 05004], lr: 0.000073, loss: 0.5877
2022-07-01 17:36:33 - train: epoch 0118, iter [04800, 05004], lr: 0.000071, loss: 0.6197
2022-07-01 17:37:06 - train: epoch 0118, iter [04900, 05004], lr: 0.000070, loss: 0.6231
2022-07-01 17:37:39 - train: epoch 0118, iter [05000, 05004], lr: 0.000069, loss: 0.6732
2022-07-01 17:37:40 - train: epoch 118, train_loss: 0.6988
2022-07-01 17:38:57 - eval: epoch: 118, acc1: 77.738%, acc5: 93.642%, test_loss: 0.8940, per_image_load_time: 2.264ms, per_image_inference_time: 0.634ms
2022-07-01 17:38:58 - until epoch: 118, best_acc1: 77.738%
2022-07-01 17:38:58 - epoch 119 lr: 0.000069
2022-07-01 17:39:36 - train: epoch 0119, iter [00100, 05004], lr: 0.000067, loss: 0.8067
2022-07-01 17:40:08 - train: epoch 0119, iter [00200, 05004], lr: 0.000066, loss: 0.7492
2022-07-01 17:40:41 - train: epoch 0119, iter [00300, 05004], lr: 0.000064, loss: 0.8396
2022-07-01 17:41:14 - train: epoch 0119, iter [00400, 05004], lr: 0.000063, loss: 0.6391
2022-07-01 17:41:46 - train: epoch 0119, iter [00500, 05004], lr: 0.000062, loss: 0.5978
2022-07-01 17:42:19 - train: epoch 0119, iter [00600, 05004], lr: 0.000061, loss: 0.6814
2022-07-01 17:42:52 - train: epoch 0119, iter [00700, 05004], lr: 0.000059, loss: 0.7126
2022-07-01 17:43:24 - train: epoch 0119, iter [00800, 05004], lr: 0.000058, loss: 0.7598
2022-07-01 17:43:57 - train: epoch 0119, iter [00900, 05004], lr: 0.000057, loss: 0.8026
2022-07-01 17:44:30 - train: epoch 0119, iter [01000, 05004], lr: 0.000056, loss: 0.5933
2022-07-01 17:45:03 - train: epoch 0119, iter [01100, 05004], lr: 0.000054, loss: 0.8518
2022-07-01 17:45:36 - train: epoch 0119, iter [01200, 05004], lr: 0.000053, loss: 0.8100
2022-07-01 17:46:09 - train: epoch 0119, iter [01300, 05004], lr: 0.000052, loss: 0.5947
2022-07-01 17:46:41 - train: epoch 0119, iter [01400, 05004], lr: 0.000051, loss: 0.6139
2022-07-01 17:47:14 - train: epoch 0119, iter [01500, 05004], lr: 0.000050, loss: 0.6620
2022-07-01 17:47:47 - train: epoch 0119, iter [01600, 05004], lr: 0.000048, loss: 0.7198
2022-07-01 17:48:20 - train: epoch 0119, iter [01700, 05004], lr: 0.000047, loss: 0.7909
2022-07-01 17:48:54 - train: epoch 0119, iter [01800, 05004], lr: 0.000046, loss: 0.6230
2022-07-01 17:49:27 - train: epoch 0119, iter [01900, 05004], lr: 0.000045, loss: 0.7047
2022-07-01 17:50:00 - train: epoch 0119, iter [02000, 05004], lr: 0.000044, loss: 0.6244
2022-07-01 17:50:33 - train: epoch 0119, iter [02100, 05004], lr: 0.000043, loss: 0.8921
2022-07-01 17:51:06 - train: epoch 0119, iter [02200, 05004], lr: 0.000042, loss: 0.7724
2022-07-01 17:51:39 - train: epoch 0119, iter [02300, 05004], lr: 0.000041, loss: 0.6617
2022-07-01 17:52:12 - train: epoch 0119, iter [02400, 05004], lr: 0.000040, loss: 0.6444
2022-07-01 17:52:45 - train: epoch 0119, iter [02500, 05004], lr: 0.000039, loss: 0.7802
2022-07-01 17:53:18 - train: epoch 0119, iter [02600, 05004], lr: 0.000038, loss: 0.6821
2022-07-01 17:53:51 - train: epoch 0119, iter [02700, 05004], lr: 0.000037, loss: 0.7072
2022-07-01 17:54:25 - train: epoch 0119, iter [02800, 05004], lr: 0.000036, loss: 0.8267
2022-07-01 17:54:58 - train: epoch 0119, iter [02900, 05004], lr: 0.000035, loss: 0.7312
2022-07-01 17:55:31 - train: epoch 0119, iter [03000, 05004], lr: 0.000034, loss: 0.6429
2022-07-01 17:56:04 - train: epoch 0119, iter [03100, 05004], lr: 0.000033, loss: 0.6598
2022-07-01 17:56:37 - train: epoch 0119, iter [03200, 05004], lr: 0.000032, loss: 0.5864
2022-07-01 17:57:10 - train: epoch 0119, iter [03300, 05004], lr: 0.000031, loss: 0.6183
2022-07-01 17:57:43 - train: epoch 0119, iter [03400, 05004], lr: 0.000030, loss: 0.7816
2022-07-01 17:58:16 - train: epoch 0119, iter [03500, 05004], lr: 0.000029, loss: 0.5749
2022-07-01 17:58:49 - train: epoch 0119, iter [03600, 05004], lr: 0.000028, loss: 0.8110
2022-07-01 17:59:22 - train: epoch 0119, iter [03700, 05004], lr: 0.000027, loss: 0.7498
2022-07-01 17:59:55 - train: epoch 0119, iter [03800, 05004], lr: 0.000026, loss: 0.5849
2022-07-01 18:00:27 - train: epoch 0119, iter [03900, 05004], lr: 0.000026, loss: 1.0458
2022-07-01 18:01:00 - train: epoch 0119, iter [04000, 05004], lr: 0.000025, loss: 0.5987
2022-07-01 18:01:34 - train: epoch 0119, iter [04100, 05004], lr: 0.000024, loss: 0.8816
2022-07-01 18:02:07 - train: epoch 0119, iter [04200, 05004], lr: 0.000023, loss: 0.7118
2022-07-01 18:02:40 - train: epoch 0119, iter [04300, 05004], lr: 0.000022, loss: 0.6424
2022-07-01 18:03:13 - train: epoch 0119, iter [04400, 05004], lr: 0.000022, loss: 0.8200
2022-07-01 18:03:46 - train: epoch 0119, iter [04500, 05004], lr: 0.000021, loss: 0.6022
2022-07-01 18:04:19 - train: epoch 0119, iter [04600, 05004], lr: 0.000020, loss: 0.6900
2022-07-01 18:04:52 - train: epoch 0119, iter [04700, 05004], lr: 0.000019, loss: 0.5143
2022-07-01 18:05:25 - train: epoch 0119, iter [04800, 05004], lr: 0.000019, loss: 0.7996
2022-07-01 18:05:57 - train: epoch 0119, iter [04900, 05004], lr: 0.000018, loss: 0.8382
2022-07-01 18:06:30 - train: epoch 0119, iter [05000, 05004], lr: 0.000017, loss: 0.7572
2022-07-01 18:06:32 - train: epoch 119, train_loss: 0.6943
2022-07-01 18:07:49 - eval: epoch: 119, acc1: 77.708%, acc5: 93.672%, test_loss: 0.8934, per_image_load_time: 2.317ms, per_image_inference_time: 0.637ms
2022-07-01 18:07:49 - until epoch: 119, best_acc1: 77.738%
2022-07-01 18:07:49 - epoch 120 lr: 0.000017
2022-07-01 18:08:28 - train: epoch 0120, iter [00100, 05004], lr: 0.000016, loss: 0.6580
2022-07-01 18:09:00 - train: epoch 0120, iter [00200, 05004], lr: 0.000016, loss: 0.8215
2022-07-01 18:09:33 - train: epoch 0120, iter [00300, 05004], lr: 0.000015, loss: 0.8174
2022-07-01 18:10:05 - train: epoch 0120, iter [00400, 05004], lr: 0.000015, loss: 0.6854
2022-07-01 18:10:38 - train: epoch 0120, iter [00500, 05004], lr: 0.000014, loss: 0.6077
2022-07-01 18:11:11 - train: epoch 0120, iter [00600, 05004], lr: 0.000013, loss: 0.6631
2022-07-01 18:11:43 - train: epoch 0120, iter [00700, 05004], lr: 0.000013, loss: 0.9098
2022-07-01 18:12:16 - train: epoch 0120, iter [00800, 05004], lr: 0.000012, loss: 0.6042
2022-07-01 18:12:48 - train: epoch 0120, iter [00900, 05004], lr: 0.000012, loss: 0.6818
2022-07-01 18:13:21 - train: epoch 0120, iter [01000, 05004], lr: 0.000011, loss: 0.6068
2022-07-01 18:13:54 - train: epoch 0120, iter [01100, 05004], lr: 0.000010, loss: 0.5347
2022-07-01 18:14:27 - train: epoch 0120, iter [01200, 05004], lr: 0.000010, loss: 0.7746
2022-07-01 18:15:00 - train: epoch 0120, iter [01300, 05004], lr: 0.000009, loss: 0.6337
2022-07-01 18:15:33 - train: epoch 0120, iter [01400, 05004], lr: 0.000009, loss: 0.6956
2022-07-01 18:16:06 - train: epoch 0120, iter [01500, 05004], lr: 0.000008, loss: 0.6810
2022-07-01 18:16:39 - train: epoch 0120, iter [01600, 05004], lr: 0.000008, loss: 0.6539
2022-07-01 18:17:12 - train: epoch 0120, iter [01700, 05004], lr: 0.000007, loss: 0.6972
2022-07-01 18:17:46 - train: epoch 0120, iter [01800, 05004], lr: 0.000007, loss: 0.7086
2022-07-01 18:18:19 - train: epoch 0120, iter [01900, 05004], lr: 0.000007, loss: 0.6955
2022-07-01 18:18:52 - train: epoch 0120, iter [02000, 05004], lr: 0.000006, loss: 0.6829
2022-07-01 18:19:25 - train: epoch 0120, iter [02100, 05004], lr: 0.000006, loss: 0.8364
2022-07-01 18:19:58 - train: epoch 0120, iter [02200, 05004], lr: 0.000005, loss: 0.7063
2022-07-01 18:20:31 - train: epoch 0120, iter [02300, 05004], lr: 0.000005, loss: 0.6147
2022-07-01 18:21:03 - train: epoch 0120, iter [02400, 05004], lr: 0.000005, loss: 0.7098
2022-07-01 18:21:36 - train: epoch 0120, iter [02500, 05004], lr: 0.000004, loss: 0.7430
2022-07-01 18:22:10 - train: epoch 0120, iter [02600, 05004], lr: 0.000004, loss: 0.6767
2022-07-01 18:22:43 - train: epoch 0120, iter [02700, 05004], lr: 0.000004, loss: 0.8823
2022-07-01 18:23:16 - train: epoch 0120, iter [02800, 05004], lr: 0.000003, loss: 0.6289
2022-07-01 18:23:49 - train: epoch 0120, iter [02900, 05004], lr: 0.000003, loss: 0.4811
2022-07-01 18:24:22 - train: epoch 0120, iter [03000, 05004], lr: 0.000003, loss: 0.6196
2022-07-01 18:24:55 - train: epoch 0120, iter [03100, 05004], lr: 0.000002, loss: 0.6217
2022-07-01 18:25:28 - train: epoch 0120, iter [03200, 05004], lr: 0.000002, loss: 0.7453
2022-07-01 18:26:01 - train: epoch 0120, iter [03300, 05004], lr: 0.000002, loss: 0.6143
2022-07-01 18:26:34 - train: epoch 0120, iter [03400, 05004], lr: 0.000002, loss: 0.5910
2022-07-01 18:27:07 - train: epoch 0120, iter [03500, 05004], lr: 0.000002, loss: 0.6913
2022-07-01 18:27:40 - train: epoch 0120, iter [03600, 05004], lr: 0.000001, loss: 0.7545
2022-07-01 18:28:13 - train: epoch 0120, iter [03700, 05004], lr: 0.000001, loss: 0.5919
2022-07-01 18:28:46 - train: epoch 0120, iter [03800, 05004], lr: 0.000001, loss: 0.6604
2022-07-01 18:29:19 - train: epoch 0120, iter [03900, 05004], lr: 0.000001, loss: 0.6052
2022-07-01 18:29:52 - train: epoch 0120, iter [04000, 05004], lr: 0.000001, loss: 0.6402
2022-07-01 18:30:25 - train: epoch 0120, iter [04100, 05004], lr: 0.000001, loss: 0.8023
2022-07-01 18:30:58 - train: epoch 0120, iter [04200, 05004], lr: 0.000000, loss: 0.7711
2022-07-01 18:31:31 - train: epoch 0120, iter [04300, 05004], lr: 0.000000, loss: 0.7762
2022-07-01 18:32:04 - train: epoch 0120, iter [04400, 05004], lr: 0.000000, loss: 0.7416
2022-07-01 18:32:36 - train: epoch 0120, iter [04500, 05004], lr: 0.000000, loss: 0.7401
2022-07-01 18:33:09 - train: epoch 0120, iter [04600, 05004], lr: 0.000000, loss: 0.6556
2022-07-01 18:33:42 - train: epoch 0120, iter [04700, 05004], lr: 0.000000, loss: 0.8083
2022-07-01 18:34:15 - train: epoch 0120, iter [04800, 05004], lr: 0.000000, loss: 0.8446
2022-07-01 18:34:48 - train: epoch 0120, iter [04900, 05004], lr: 0.000000, loss: 0.7364
2022-07-01 18:35:21 - train: epoch 0120, iter [05000, 05004], lr: 0.000000, loss: 0.6402
2022-07-01 18:35:23 - train: epoch 120, train_loss: 0.6956
2022-07-01 18:36:39 - eval: epoch: 120, acc1: 77.804%, acc5: 93.680%, test_loss: 0.8934, per_image_load_time: 2.339ms, per_image_inference_time: 0.612ms
2022-07-01 18:36:40 - until epoch: 120, best_acc1: 77.804%
2022-07-01 18:36:40 - train done. model: RepVGG_B1, train time: 57.838 hours, best_acc1: 77.804%
