2022-07-12 20:46:38 - train: epoch 0063, iter [03500, 05004], lr: 0.066907, loss: 1.5523
2022-07-12 20:47:33 - train: epoch 0063, iter [03600, 05004], lr: 0.066845, loss: 1.3746
2022-07-12 20:48:29 - train: epoch 0063, iter [03700, 05004], lr: 0.066782, loss: 1.5535
2022-07-12 20:49:25 - train: epoch 0063, iter [03800, 05004], lr: 0.066720, loss: 1.5348
2022-07-12 20:50:19 - train: epoch 0063, iter [03900, 05004], lr: 0.066658, loss: 1.4266
2022-07-12 20:51:16 - train: epoch 0063, iter [04000, 05004], lr: 0.066595, loss: 1.3913
2022-07-12 20:52:10 - train: epoch 0063, iter [04100, 05004], lr: 0.066533, loss: 1.4265
2022-07-12 20:53:06 - train: epoch 0063, iter [04200, 05004], lr: 0.066471, loss: 1.4761
2022-07-12 20:54:01 - train: epoch 0063, iter [04300, 05004], lr: 0.066409, loss: 1.8207
2022-07-12 20:54:57 - train: epoch 0063, iter [04400, 05004], lr: 0.066346, loss: 1.7410
2022-07-12 20:55:53 - train: epoch 0063, iter [04500, 05004], lr: 0.066284, loss: 1.6592
2022-07-12 20:56:49 - train: epoch 0063, iter [04600, 05004], lr: 0.066222, loss: 1.4320
2022-07-12 20:57:47 - train: epoch 0063, iter [04700, 05004], lr: 0.066160, loss: 1.5942
2022-07-12 20:58:44 - train: epoch 0063, iter [04800, 05004], lr: 0.066097, loss: 1.2865
2022-07-12 20:59:43 - train: epoch 0063, iter [04900, 05004], lr: 0.066035, loss: 1.3252
2022-07-12 21:00:39 - train: epoch 0063, iter [05000, 05004], lr: 0.065973, loss: 1.5638
2022-07-12 21:00:41 - train: epoch 063, train_loss: 1.4883
2022-07-12 21:02:46 - eval: epoch: 063, acc1: 68.538%, acc5: 88.962%, test_loss: 1.2920, per_image_load_time: 2.052ms, per_image_inference_time: 0.789ms
2022-07-12 21:02:46 - until epoch: 063, best_acc1: 68.538%
2022-07-12 21:02:46 - epoch 064 lr: 0.065970
2022-07-12 21:03:52 - train: epoch 0064, iter [00100, 05004], lr: 0.065909, loss: 1.2104
2022-07-12 21:04:46 - train: epoch 0064, iter [00200, 05004], lr: 0.065846, loss: 1.4925
2022-07-12 21:05:40 - train: epoch 0064, iter [00300, 05004], lr: 0.065784, loss: 1.4224
2022-07-12 21:06:36 - train: epoch 0064, iter [00400, 05004], lr: 0.065722, loss: 1.2753
2022-07-12 21:07:30 - train: epoch 0064, iter [00500, 05004], lr: 0.065660, loss: 1.3713
2022-07-12 21:08:26 - train: epoch 0064, iter [00600, 05004], lr: 0.065598, loss: 1.4083
2022-07-12 21:09:22 - train: epoch 0064, iter [00700, 05004], lr: 0.065536, loss: 1.5949
2022-07-12 21:10:18 - train: epoch 0064, iter [00800, 05004], lr: 0.065474, loss: 1.2961
2022-07-12 21:11:12 - train: epoch 0064, iter [00900, 05004], lr: 0.065412, loss: 1.2139
2022-07-12 21:12:07 - train: epoch 0064, iter [01000, 05004], lr: 0.065350, loss: 1.4083
2022-07-12 21:13:02 - train: epoch 0064, iter [01100, 05004], lr: 0.065288, loss: 1.6069
2022-07-12 21:13:58 - train: epoch 0064, iter [01200, 05004], lr: 0.065226, loss: 1.4470
2022-07-12 21:14:55 - train: epoch 0064, iter [01300, 05004], lr: 0.065164, loss: 1.5797
2022-07-12 21:15:50 - train: epoch 0064, iter [01400, 05004], lr: 0.065102, loss: 1.6882
2022-07-12 21:16:45 - train: epoch 0064, iter [01500, 05004], lr: 0.065040, loss: 1.4461
2022-07-12 21:17:39 - train: epoch 0064, iter [01600, 05004], lr: 0.064978, loss: 1.3855
2022-07-12 21:18:32 - train: epoch 0064, iter [01700, 05004], lr: 0.064916, loss: 1.4130
2022-07-12 21:19:28 - train: epoch 0064, iter [01800, 05004], lr: 0.064855, loss: 1.4253
2022-07-12 21:20:22 - train: epoch 0064, iter [01900, 05004], lr: 0.064793, loss: 1.4327
2022-07-12 21:21:16 - train: epoch 0064, iter [02000, 05004], lr: 0.064731, loss: 1.4278
2022-07-12 21:22:10 - train: epoch 0064, iter [02100, 05004], lr: 0.064669, loss: 1.5330
2022-07-12 21:23:05 - train: epoch 0064, iter [02200, 05004], lr: 0.064607, loss: 1.4536
2022-07-12 21:24:00 - train: epoch 0064, iter [02300, 05004], lr: 0.064545, loss: 1.5816
2022-07-12 21:24:56 - train: epoch 0064, iter [02400, 05004], lr: 0.064484, loss: 1.4206
2022-07-12 21:25:53 - train: epoch 0064, iter [02500, 05004], lr: 0.064422, loss: 1.4082
2022-07-12 21:26:52 - train: epoch 0064, iter [02600, 05004], lr: 0.064360, loss: 1.5335
2022-07-12 21:27:51 - train: epoch 0064, iter [02700, 05004], lr: 0.064298, loss: 1.4354
2022-07-12 21:28:46 - train: epoch 0064, iter [02800, 05004], lr: 0.064237, loss: 1.4892
2022-07-12 21:29:42 - train: epoch 0064, iter [02900, 05004], lr: 0.064175, loss: 1.5589
2022-07-12 21:30:36 - train: epoch 0064, iter [03000, 05004], lr: 0.064113, loss: 1.3065
2022-07-12 21:31:31 - train: epoch 0064, iter [03100, 05004], lr: 0.064052, loss: 1.5565
2022-07-12 21:32:27 - train: epoch 0064, iter [03200, 05004], lr: 0.063990, loss: 1.6475
2022-07-12 21:33:22 - train: epoch 0064, iter [03300, 05004], lr: 0.063928, loss: 1.4655
2022-07-12 21:34:17 - train: epoch 0064, iter [03400, 05004], lr: 0.063867, loss: 1.4426
2022-07-12 21:35:10 - train: epoch 0064, iter [03500, 05004], lr: 0.063805, loss: 1.5009
2022-07-12 21:36:05 - train: epoch 0064, iter [03600, 05004], lr: 0.063743, loss: 1.3626
2022-07-12 21:36:59 - train: epoch 0064, iter [03700, 05004], lr: 0.063682, loss: 1.3675
2022-07-12 21:37:54 - train: epoch 0064, iter [03800, 05004], lr: 0.063620, loss: 1.4760
2022-07-12 21:38:48 - train: epoch 0064, iter [03900, 05004], lr: 0.063559, loss: 1.4957
2022-07-12 21:39:42 - train: epoch 0064, iter [04000, 05004], lr: 0.063497, loss: 1.4013
2022-07-12 21:40:39 - train: epoch 0064, iter [04100, 05004], lr: 0.063436, loss: 1.4006
2022-07-12 21:41:36 - train: epoch 0064, iter [04200, 05004], lr: 0.063374, loss: 1.2711
2022-07-12 21:42:32 - train: epoch 0064, iter [04300, 05004], lr: 0.063313, loss: 1.5503
2022-07-12 21:43:30 - train: epoch 0064, iter [04400, 05004], lr: 0.063251, loss: 1.3779
2022-07-12 21:44:30 - train: epoch 0064, iter [04500, 05004], lr: 0.063190, loss: 1.3223
2022-07-12 21:45:28 - train: epoch 0064, iter [04600, 05004], lr: 0.063128, loss: 1.4497
2022-07-12 21:46:25 - train: epoch 0064, iter [04700, 05004], lr: 0.063067, loss: 1.6441
2022-07-12 21:47:23 - train: epoch 0064, iter [04800, 05004], lr: 0.063005, loss: 1.5842
2022-07-12 21:48:21 - train: epoch 0064, iter [04900, 05004], lr: 0.062944, loss: 1.4788
2022-07-12 21:49:19 - train: epoch 0064, iter [05000, 05004], lr: 0.062883, loss: 1.3376
2022-07-12 21:49:22 - train: epoch 064, train_loss: 1.4719
2022-07-12 21:51:26 - eval: epoch: 064, acc1: 68.638%, acc5: 88.996%, test_loss: 1.2797, per_image_load_time: 2.230ms, per_image_inference_time: 0.805ms
2022-07-12 21:51:26 - until epoch: 064, best_acc1: 68.638%
2022-07-12 21:51:26 - epoch 065 lr: 0.062880
2022-07-12 21:52:34 - train: epoch 0065, iter [00100, 05004], lr: 0.062819, loss: 1.3463
2022-07-12 21:53:34 - train: epoch 0065, iter [00200, 05004], lr: 0.062758, loss: 1.4433
2022-07-12 21:54:30 - train: epoch 0065, iter [00300, 05004], lr: 0.062696, loss: 1.4356
2022-07-12 21:55:28 - train: epoch 0065, iter [00400, 05004], lr: 0.062635, loss: 1.6156
2022-07-12 21:56:22 - train: epoch 0065, iter [00500, 05004], lr: 0.062574, loss: 1.6213
2022-07-12 21:57:18 - train: epoch 0065, iter [00600, 05004], lr: 0.062512, loss: 1.3801
2022-07-12 21:58:14 - train: epoch 0065, iter [00700, 05004], lr: 0.062451, loss: 1.3523
2022-07-12 21:59:10 - train: epoch 0065, iter [00800, 05004], lr: 0.062390, loss: 1.1798
2022-07-12 22:00:07 - train: epoch 0065, iter [00900, 05004], lr: 0.062329, loss: 1.4070
2022-07-12 22:01:02 - train: epoch 0065, iter [01000, 05004], lr: 0.062267, loss: 1.4878
2022-07-12 22:01:58 - train: epoch 0065, iter [01100, 05004], lr: 0.062206, loss: 1.5039
2022-07-12 22:02:54 - train: epoch 0065, iter [01200, 05004], lr: 0.062145, loss: 1.5553
2022-07-12 22:03:51 - train: epoch 0065, iter [01300, 05004], lr: 0.062084, loss: 1.5933
2022-07-12 22:04:46 - train: epoch 0065, iter [01400, 05004], lr: 0.062023, loss: 1.5249
2022-07-12 22:05:41 - train: epoch 0065, iter [01500, 05004], lr: 0.061962, loss: 1.3659
2022-07-12 22:06:38 - train: epoch 0065, iter [01600, 05004], lr: 0.061901, loss: 1.3814
2022-07-12 22:07:36 - train: epoch 0065, iter [01700, 05004], lr: 0.061839, loss: 1.4242
2022-07-12 22:08:34 - train: epoch 0065, iter [01800, 05004], lr: 0.061778, loss: 1.3834
2022-07-12 22:09:33 - train: epoch 0065, iter [01900, 05004], lr: 0.061717, loss: 1.2851
2022-07-12 22:10:34 - train: epoch 0065, iter [02000, 05004], lr: 0.061656, loss: 1.4289
2022-07-12 22:11:30 - train: epoch 0065, iter [02100, 05004], lr: 0.061595, loss: 1.4640
2022-07-12 22:12:29 - train: epoch 0065, iter [02200, 05004], lr: 0.061534, loss: 1.4769
2022-07-12 22:13:28 - train: epoch 0065, iter [02300, 05004], lr: 0.061473, loss: 1.4420
2022-07-12 22:14:25 - train: epoch 0065, iter [02400, 05004], lr: 0.061412, loss: 1.2350
2022-07-12 22:15:22 - train: epoch 0065, iter [02500, 05004], lr: 0.061351, loss: 1.4530
2022-07-12 22:16:17 - train: epoch 0065, iter [02600, 05004], lr: 0.061290, loss: 1.5784
2022-07-12 22:17:12 - train: epoch 0065, iter [02700, 05004], lr: 0.061229, loss: 1.4746
2022-07-12 22:18:07 - train: epoch 0065, iter [02800, 05004], lr: 0.061169, loss: 1.5047
2022-07-12 22:19:03 - train: epoch 0065, iter [02900, 05004], lr: 0.061108, loss: 1.3347
2022-07-12 22:19:59 - train: epoch 0065, iter [03000, 05004], lr: 0.061047, loss: 1.5601
2022-07-12 22:20:54 - train: epoch 0065, iter [03100, 05004], lr: 0.060986, loss: 1.3789
2022-07-12 22:21:50 - train: epoch 0065, iter [03200, 05004], lr: 0.060925, loss: 1.4875
2022-07-12 22:22:44 - train: epoch 0065, iter [03300, 05004], lr: 0.060864, loss: 1.5791
2022-07-12 22:23:39 - train: epoch 0065, iter [03400, 05004], lr: 0.060803, loss: 1.3954
2022-07-12 22:24:35 - train: epoch 0065, iter [03500, 05004], lr: 0.060743, loss: 1.6097
2022-07-12 22:25:32 - train: epoch 0065, iter [03600, 05004], lr: 0.060682, loss: 1.5964
2022-07-12 22:26:29 - train: epoch 0065, iter [03700, 05004], lr: 0.060621, loss: 1.4754
2022-07-12 22:27:24 - train: epoch 0065, iter [03800, 05004], lr: 0.060560, loss: 1.3470
2022-07-12 22:28:17 - train: epoch 0065, iter [03900, 05004], lr: 0.060500, loss: 1.6196
2022-07-12 22:29:09 - train: epoch 0065, iter [04000, 05004], lr: 0.060439, loss: 1.6560
2022-07-12 22:30:01 - train: epoch 0065, iter [04100, 05004], lr: 0.060378, loss: 1.5095
2022-07-12 22:30:55 - train: epoch 0065, iter [04200, 05004], lr: 0.060318, loss: 1.4233
2022-07-12 22:31:50 - train: epoch 0065, iter [04300, 05004], lr: 0.060257, loss: 1.6025
2022-07-12 22:32:43 - train: epoch 0065, iter [04400, 05004], lr: 0.060196, loss: 1.5710
2022-07-12 22:33:37 - train: epoch 0065, iter [04500, 05004], lr: 0.060136, loss: 1.4371
2022-07-12 22:34:35 - train: epoch 0065, iter [04600, 05004], lr: 0.060075, loss: 1.5070
2022-07-12 22:35:33 - train: epoch 0065, iter [04700, 05004], lr: 0.060015, loss: 1.4652
2022-07-12 22:36:26 - train: epoch 0065, iter [04800, 05004], lr: 0.059954, loss: 1.1581
2022-07-12 22:37:17 - train: epoch 0065, iter [04900, 05004], lr: 0.059893, loss: 1.5671
2022-07-12 22:38:09 - train: epoch 0065, iter [05000, 05004], lr: 0.059833, loss: 1.4320
2022-07-12 22:38:12 - train: epoch 065, train_loss: 1.4554
2022-07-12 22:40:10 - eval: epoch: 065, acc1: 68.572%, acc5: 89.152%, test_loss: 1.2736, per_image_load_time: 3.307ms, per_image_inference_time: 0.756ms
2022-07-12 22:40:11 - until epoch: 065, best_acc1: 68.638%
2022-07-12 22:40:11 - epoch 066 lr: 0.059830
2022-07-12 22:41:17 - train: epoch 0066, iter [00100, 05004], lr: 0.059770, loss: 1.3730
2022-07-12 22:42:11 - train: epoch 0066, iter [00200, 05004], lr: 0.059709, loss: 1.4966
2022-07-12 22:43:05 - train: epoch 0066, iter [00300, 05004], lr: 0.059649, loss: 1.3560
2022-07-12 22:44:02 - train: epoch 0066, iter [00400, 05004], lr: 0.059589, loss: 1.2958
2022-07-12 22:44:54 - train: epoch 0066, iter [00500, 05004], lr: 0.059528, loss: 1.5247
2022-07-12 22:45:47 - train: epoch 0066, iter [00600, 05004], lr: 0.059468, loss: 1.0754
2022-07-12 22:46:42 - train: epoch 0066, iter [00700, 05004], lr: 0.059407, loss: 1.6136
2022-07-12 22:47:44 - train: epoch 0066, iter [00800, 05004], lr: 0.059347, loss: 1.6764
2022-07-12 22:48:41 - train: epoch 0066, iter [00900, 05004], lr: 0.059286, loss: 1.4728
2022-07-12 22:49:35 - train: epoch 0066, iter [01000, 05004], lr: 0.059226, loss: 1.4467
2022-07-12 22:50:30 - train: epoch 0066, iter [01100, 05004], lr: 0.059166, loss: 1.5653
2022-07-12 22:51:29 - train: epoch 0066, iter [01200, 05004], lr: 0.059105, loss: 1.5240
2022-07-12 22:52:33 - train: epoch 0066, iter [01300, 05004], lr: 0.059045, loss: 1.5350
2022-07-12 22:53:27 - train: epoch 0066, iter [01400, 05004], lr: 0.058985, loss: 1.3740
2022-07-12 22:54:21 - train: epoch 0066, iter [01500, 05004], lr: 0.058925, loss: 1.2828
2022-07-12 22:55:18 - train: epoch 0066, iter [01600, 05004], lr: 0.058864, loss: 1.4285
2022-07-12 22:56:22 - train: epoch 0066, iter [01700, 05004], lr: 0.058804, loss: 1.4646
2022-07-12 22:57:17 - train: epoch 0066, iter [01800, 05004], lr: 0.058744, loss: 1.3816
2022-07-12 22:58:12 - train: epoch 0066, iter [01900, 05004], lr: 0.058684, loss: 1.7942
2022-07-12 22:59:09 - train: epoch 0066, iter [02000, 05004], lr: 0.058624, loss: 1.2587
2022-07-12 23:00:11 - train: epoch 0066, iter [02100, 05004], lr: 0.058563, loss: 1.4593
2022-07-12 23:01:12 - train: epoch 0066, iter [02200, 05004], lr: 0.058503, loss: 1.3897
2022-07-12 23:02:06 - train: epoch 0066, iter [02300, 05004], lr: 0.058443, loss: 1.4660
2022-07-12 23:03:01 - train: epoch 0066, iter [02400, 05004], lr: 0.058383, loss: 1.4387
2022-07-12 23:04:01 - train: epoch 0066, iter [02500, 05004], lr: 0.058323, loss: 1.4758
2022-07-12 23:05:03 - train: epoch 0066, iter [02600, 05004], lr: 0.058263, loss: 1.4939
2022-07-12 23:05:59 - train: epoch 0066, iter [02700, 05004], lr: 0.058203, loss: 1.6694
2022-07-12 23:06:53 - train: epoch 0066, iter [02800, 05004], lr: 0.058143, loss: 1.3955
2022-07-12 23:07:52 - train: epoch 0066, iter [02900, 05004], lr: 0.058083, loss: 1.2533
2022-07-12 23:08:54 - train: epoch 0066, iter [03000, 05004], lr: 0.058023, loss: 1.4980
2022-07-12 23:09:50 - train: epoch 0066, iter [03100, 05004], lr: 0.057963, loss: 1.6050
2022-07-12 23:10:45 - train: epoch 0066, iter [03200, 05004], lr: 0.057903, loss: 1.3987
2022-07-12 23:11:43 - train: epoch 0066, iter [03300, 05004], lr: 0.057843, loss: 1.4974
2022-07-12 23:12:45 - train: epoch 0066, iter [03400, 05004], lr: 0.057783, loss: 1.6777
2022-07-12 23:13:40 - train: epoch 0066, iter [03500, 05004], lr: 0.057723, loss: 1.6108
2022-07-12 23:14:34 - train: epoch 0066, iter [03600, 05004], lr: 0.057663, loss: 1.5999
2022-07-12 23:15:30 - train: epoch 0066, iter [03700, 05004], lr: 0.057603, loss: 1.5495
2022-07-12 23:16:31 - train: epoch 0066, iter [03800, 05004], lr: 0.057544, loss: 1.3547
2022-07-12 23:17:28 - train: epoch 0066, iter [03900, 05004], lr: 0.057484, loss: 1.4419
2022-07-12 23:18:20 - train: epoch 0066, iter [04000, 05004], lr: 0.057424, loss: 1.5660
2022-07-12 23:19:17 - train: epoch 0066, iter [04100, 05004], lr: 0.057364, loss: 1.5135
2022-07-12 23:20:15 - train: epoch 0066, iter [04200, 05004], lr: 0.057304, loss: 1.4285
2022-07-12 23:21:14 - train: epoch 0066, iter [04300, 05004], lr: 0.057245, loss: 1.1871
2022-07-12 23:22:08 - train: epoch 0066, iter [04400, 05004], lr: 0.057185, loss: 1.4825
2022-07-12 23:23:02 - train: epoch 0066, iter [04500, 05004], lr: 0.057125, loss: 1.7017
2022-07-12 23:23:59 - train: epoch 0066, iter [04600, 05004], lr: 0.057066, loss: 1.4648
2022-07-12 23:24:58 - train: epoch 0066, iter [04700, 05004], lr: 0.057006, loss: 1.3761
2022-07-12 23:25:56 - train: epoch 0066, iter [04800, 05004], lr: 0.056946, loss: 1.4897
2022-07-12 23:26:50 - train: epoch 0066, iter [04900, 05004], lr: 0.056887, loss: 1.4477
2022-07-12 23:27:45 - train: epoch 0066, iter [05000, 05004], lr: 0.056827, loss: 1.3460
2022-07-12 23:27:48 - train: epoch 066, train_loss: 1.4389
2022-07-12 23:29:57 - eval: epoch: 066, acc1: 69.268%, acc5: 89.306%, test_loss: 1.2584, per_image_load_time: 2.601ms, per_image_inference_time: 0.832ms
2022-07-12 23:29:57 - until epoch: 066, best_acc1: 69.268%
2022-07-12 23:29:57 - epoch 067 lr: 0.056824
2022-07-12 23:31:05 - train: epoch 0067, iter [00100, 05004], lr: 0.056765, loss: 1.1477
2022-07-12 23:32:04 - train: epoch 0067, iter [00200, 05004], lr: 0.056705, loss: 1.4398
2022-07-12 23:33:02 - train: epoch 0067, iter [00300, 05004], lr: 0.056646, loss: 1.4452
2022-07-12 23:34:01 - train: epoch 0067, iter [00400, 05004], lr: 0.056586, loss: 1.3375
2022-07-12 23:35:00 - train: epoch 0067, iter [00500, 05004], lr: 0.056527, loss: 1.3612
2022-07-12 23:36:01 - train: epoch 0067, iter [00600, 05004], lr: 0.056467, loss: 1.3146
2022-07-12 23:36:58 - train: epoch 0067, iter [00700, 05004], lr: 0.056408, loss: 1.3968
2022-07-12 23:37:57 - train: epoch 0067, iter [00800, 05004], lr: 0.056348, loss: 1.4736
2022-07-12 23:38:56 - train: epoch 0067, iter [00900, 05004], lr: 0.056289, loss: 1.4989
2022-07-12 23:39:56 - train: epoch 0067, iter [01000, 05004], lr: 0.056229, loss: 1.4140
2022-07-12 23:40:54 - train: epoch 0067, iter [01100, 05004], lr: 0.056170, loss: 1.3185
2022-07-12 23:41:53 - train: epoch 0067, iter [01200, 05004], lr: 0.056111, loss: 1.4832
2022-07-12 23:42:51 - train: epoch 0067, iter [01300, 05004], lr: 0.056051, loss: 1.4907
2022-07-12 23:43:51 - train: epoch 0067, iter [01400, 05004], lr: 0.055992, loss: 1.5382
2022-07-12 23:44:47 - train: epoch 0067, iter [01500, 05004], lr: 0.055933, loss: 1.2934
2022-07-12 23:45:46 - train: epoch 0067, iter [01600, 05004], lr: 0.055873, loss: 1.5229
2022-07-12 23:46:42 - train: epoch 0067, iter [01700, 05004], lr: 0.055814, loss: 1.1563
2022-07-12 23:47:35 - train: epoch 0067, iter [01800, 05004], lr: 0.055755, loss: 1.7461
2022-07-12 23:48:27 - train: epoch 0067, iter [01900, 05004], lr: 0.055695, loss: 1.6069
2022-07-12 23:49:20 - train: epoch 0067, iter [02000, 05004], lr: 0.055636, loss: 1.4814
2022-07-12 23:50:16 - train: epoch 0067, iter [02100, 05004], lr: 0.055577, loss: 1.1097
2022-07-12 23:51:10 - train: epoch 0067, iter [02200, 05004], lr: 0.055518, loss: 1.3872
2022-07-12 23:52:03 - train: epoch 0067, iter [02300, 05004], lr: 0.055459, loss: 1.3588
2022-07-12 23:52:54 - train: epoch 0067, iter [02400, 05004], lr: 0.055399, loss: 1.3588
2022-07-12 23:53:47 - train: epoch 0067, iter [02500, 05004], lr: 0.055340, loss: 1.3840
2022-07-12 23:54:40 - train: epoch 0067, iter [02600, 05004], lr: 0.055281, loss: 1.3185
2022-07-12 23:55:33 - train: epoch 0067, iter [02700, 05004], lr: 0.055222, loss: 1.2945
2022-07-12 23:56:26 - train: epoch 0067, iter [02800, 05004], lr: 0.055163, loss: 1.6891
2022-07-12 23:57:19 - train: epoch 0067, iter [02900, 05004], lr: 0.055104, loss: 1.6192
2022-07-12 23:58:12 - train: epoch 0067, iter [03000, 05004], lr: 0.055045, loss: 1.4801
2022-07-12 23:59:04 - train: epoch 0067, iter [03100, 05004], lr: 0.054986, loss: 1.4482
2022-07-12 23:59:56 - train: epoch 0067, iter [03200, 05004], lr: 0.054927, loss: 1.5766
2022-07-13 00:00:49 - train: epoch 0067, iter [03300, 05004], lr: 0.054868, loss: 1.3822
2022-07-13 00:01:41 - train: epoch 0067, iter [03400, 05004], lr: 0.054809, loss: 1.5409
2022-07-13 00:02:34 - train: epoch 0067, iter [03500, 05004], lr: 0.054750, loss: 1.2674
2022-07-13 00:03:27 - train: epoch 0067, iter [03600, 05004], lr: 0.054691, loss: 1.4131
2022-07-13 00:04:20 - train: epoch 0067, iter [03700, 05004], lr: 0.054632, loss: 1.4573
2022-07-13 00:05:14 - train: epoch 0067, iter [03800, 05004], lr: 0.054573, loss: 1.5999
2022-07-13 00:06:06 - train: epoch 0067, iter [03900, 05004], lr: 0.054514, loss: 1.5261
2022-07-13 00:07:00 - train: epoch 0067, iter [04000, 05004], lr: 0.054456, loss: 1.5303
2022-07-13 00:07:52 - train: epoch 0067, iter [04100, 05004], lr: 0.054397, loss: 1.5326
2022-07-13 00:08:46 - train: epoch 0067, iter [04200, 05004], lr: 0.054338, loss: 1.3768
2022-07-13 00:09:39 - train: epoch 0067, iter [04300, 05004], lr: 0.054279, loss: 1.3288
2022-07-13 00:10:31 - train: epoch 0067, iter [04400, 05004], lr: 0.054220, loss: 1.3088
2022-07-13 00:11:24 - train: epoch 0067, iter [04500, 05004], lr: 0.054162, loss: 1.5072
2022-07-13 00:12:16 - train: epoch 0067, iter [04600, 05004], lr: 0.054103, loss: 1.1996
2022-07-13 00:13:09 - train: epoch 0067, iter [04700, 05004], lr: 0.054044, loss: 1.4869
2022-07-13 00:14:02 - train: epoch 0067, iter [04800, 05004], lr: 0.053986, loss: 1.4193
2022-07-13 00:14:55 - train: epoch 0067, iter [04900, 05004], lr: 0.053927, loss: 1.3584
2022-07-13 00:15:47 - train: epoch 0067, iter [05000, 05004], lr: 0.053868, loss: 1.5556
2022-07-13 00:15:49 - train: epoch 067, train_loss: 1.4193
2022-07-13 00:17:58 - eval: epoch: 067, acc1: 69.404%, acc5: 89.400%, test_loss: 1.2601, per_image_load_time: 4.032ms, per_image_inference_time: 0.844ms
2022-07-13 00:17:58 - until epoch: 067, best_acc1: 69.404%
2022-07-13 00:17:58 - epoch 068 lr: 0.053865
2022-07-13 00:19:04 - train: epoch 0068, iter [00100, 05004], lr: 0.053807, loss: 1.4664
2022-07-13 00:19:57 - train: epoch 0068, iter [00200, 05004], lr: 0.053749, loss: 1.3291
2022-07-13 00:20:49 - train: epoch 0068, iter [00300, 05004], lr: 0.053690, loss: 1.3906
2022-07-13 00:21:41 - train: epoch 0068, iter [00400, 05004], lr: 0.053632, loss: 1.2040
2022-07-13 00:22:33 - train: epoch 0068, iter [00500, 05004], lr: 0.053573, loss: 1.3658
2022-07-13 00:23:26 - train: epoch 0068, iter [00600, 05004], lr: 0.053514, loss: 1.3917
2022-07-13 00:24:19 - train: epoch 0068, iter [00700, 05004], lr: 0.053456, loss: 1.4106
2022-07-13 00:25:11 - train: epoch 0068, iter [00800, 05004], lr: 0.053397, loss: 1.2545
2022-07-13 00:26:04 - train: epoch 0068, iter [00900, 05004], lr: 0.053339, loss: 1.3186
2022-07-13 00:26:57 - train: epoch 0068, iter [01000, 05004], lr: 0.053281, loss: 1.2642
2022-07-13 00:27:50 - train: epoch 0068, iter [01100, 05004], lr: 0.053222, loss: 1.4629
2022-07-13 00:28:43 - train: epoch 0068, iter [01200, 05004], lr: 0.053164, loss: 1.2605
2022-07-13 00:29:37 - train: epoch 0068, iter [01300, 05004], lr: 0.053105, loss: 1.3664
2022-07-13 00:30:31 - train: epoch 0068, iter [01400, 05004], lr: 0.053047, loss: 1.4140
2022-07-13 00:31:24 - train: epoch 0068, iter [01500, 05004], lr: 0.052989, loss: 1.4871
2022-07-13 00:32:18 - train: epoch 0068, iter [01600, 05004], lr: 0.052930, loss: 1.3539
2022-07-13 00:33:11 - train: epoch 0068, iter [01700, 05004], lr: 0.052872, loss: 1.3909
2022-07-13 00:34:05 - train: epoch 0068, iter [01800, 05004], lr: 0.052814, loss: 1.4557
2022-07-13 00:34:58 - train: epoch 0068, iter [01900, 05004], lr: 0.052756, loss: 1.3875
2022-07-13 00:35:51 - train: epoch 0068, iter [02000, 05004], lr: 0.052697, loss: 1.4392
2022-07-13 00:36:45 - train: epoch 0068, iter [02100, 05004], lr: 0.052639, loss: 1.4514
2022-07-13 00:37:39 - train: epoch 0068, iter [02200, 05004], lr: 0.052581, loss: 1.2931
2022-07-13 00:38:33 - train: epoch 0068, iter [02300, 05004], lr: 0.052523, loss: 1.2943
2022-07-13 00:39:26 - train: epoch 0068, iter [02400, 05004], lr: 0.052465, loss: 1.2717
2022-07-13 00:40:20 - train: epoch 0068, iter [02500, 05004], lr: 0.052406, loss: 1.5023
2022-07-13 00:41:14 - train: epoch 0068, iter [02600, 05004], lr: 0.052348, loss: 1.2802
2022-07-13 00:42:07 - train: epoch 0068, iter [02700, 05004], lr: 0.052290, loss: 1.3815
2022-07-13 00:43:01 - train: epoch 0068, iter [02800, 05004], lr: 0.052232, loss: 1.4379
2022-07-13 00:43:54 - train: epoch 0068, iter [02900, 05004], lr: 0.052174, loss: 1.5296
2022-07-13 00:44:48 - train: epoch 0068, iter [03000, 05004], lr: 0.052116, loss: 1.4449
2022-07-13 00:45:41 - train: epoch 0068, iter [03100, 05004], lr: 0.052058, loss: 1.1961
2022-07-13 00:46:34 - train: epoch 0068, iter [03200, 05004], lr: 0.052000, loss: 1.4850
2022-07-13 00:47:28 - train: epoch 0068, iter [03300, 05004], lr: 0.051942, loss: 1.3712
2022-07-13 00:48:21 - train: epoch 0068, iter [03400, 05004], lr: 0.051884, loss: 1.3826
2022-07-13 00:49:14 - train: epoch 0068, iter [03500, 05004], lr: 0.051826, loss: 1.4933
2022-07-13 00:50:08 - train: epoch 0068, iter [03600, 05004], lr: 0.051768, loss: 1.5005
2022-07-13 00:51:02 - train: epoch 0068, iter [03700, 05004], lr: 0.051710, loss: 1.4210
2022-07-13 00:51:56 - train: epoch 0068, iter [03800, 05004], lr: 0.051653, loss: 1.5833
2022-07-13 00:52:51 - train: epoch 0068, iter [03900, 05004], lr: 0.051595, loss: 1.5301
2022-07-13 00:53:44 - train: epoch 0068, iter [04000, 05004], lr: 0.051537, loss: 1.2317
2022-07-13 00:54:38 - train: epoch 0068, iter [04100, 05004], lr: 0.051479, loss: 1.1891
2022-07-13 00:55:31 - train: epoch 0068, iter [04200, 05004], lr: 0.051421, loss: 1.3931
2022-07-13 00:56:25 - train: epoch 0068, iter [04300, 05004], lr: 0.051364, loss: 1.3673
2022-07-13 00:57:19 - train: epoch 0068, iter [04400, 05004], lr: 0.051306, loss: 1.2452
2022-07-13 00:58:12 - train: epoch 0068, iter [04500, 05004], lr: 0.051248, loss: 1.4415
2022-07-13 00:59:05 - train: epoch 0068, iter [04600, 05004], lr: 0.051190, loss: 1.4350
2022-07-13 00:59:57 - train: epoch 0068, iter [04700, 05004], lr: 0.051133, loss: 1.5580
2022-07-13 01:00:51 - train: epoch 0068, iter [04800, 05004], lr: 0.051075, loss: 1.4109
2022-07-13 01:01:44 - train: epoch 0068, iter [04900, 05004], lr: 0.051018, loss: 1.3693
2022-07-13 01:02:36 - train: epoch 0068, iter [05000, 05004], lr: 0.050960, loss: 1.4334
2022-07-13 01:02:38 - train: epoch 068, train_loss: 1.4024
2022-07-13 01:04:47 - eval: epoch: 068, acc1: 69.448%, acc5: 89.638%, test_loss: 1.2318, per_image_load_time: 4.102ms, per_image_inference_time: 0.898ms
2022-07-13 01:04:47 - until epoch: 068, best_acc1: 69.448%
2022-07-13 01:04:47 - epoch 069 lr: 0.050957
2022-07-13 01:05:53 - train: epoch 0069, iter [00100, 05004], lr: 0.050900, loss: 1.5509
2022-07-13 01:06:46 - train: epoch 0069, iter [00200, 05004], lr: 0.050843, loss: 1.5001
2022-07-13 01:07:39 - train: epoch 0069, iter [00300, 05004], lr: 0.050785, loss: 1.4532
2022-07-13 01:08:32 - train: epoch 0069, iter [00400, 05004], lr: 0.050727, loss: 1.3642
2022-07-13 01:09:24 - train: epoch 0069, iter [00500, 05004], lr: 0.050670, loss: 1.4292
2022-07-13 01:10:17 - train: epoch 0069, iter [00600, 05004], lr: 0.050612, loss: 1.1958
2022-07-13 01:11:10 - train: epoch 0069, iter [00700, 05004], lr: 0.050555, loss: 1.3082
2022-07-13 01:12:03 - train: epoch 0069, iter [00800, 05004], lr: 0.050498, loss: 1.5408
2022-07-13 01:12:56 - train: epoch 0069, iter [00900, 05004], lr: 0.050440, loss: 1.2403
2022-07-13 01:13:50 - train: epoch 0069, iter [01000, 05004], lr: 0.050383, loss: 1.3463
2022-07-13 01:14:42 - train: epoch 0069, iter [01100, 05004], lr: 0.050325, loss: 1.3822
2022-07-13 01:15:36 - train: epoch 0069, iter [01200, 05004], lr: 0.050268, loss: 1.2223
2022-07-13 01:16:30 - train: epoch 0069, iter [01300, 05004], lr: 0.050211, loss: 1.5662
2022-07-13 01:17:24 - train: epoch 0069, iter [01400, 05004], lr: 0.050153, loss: 1.4084
2022-07-13 01:18:18 - train: epoch 0069, iter [01500, 05004], lr: 0.050096, loss: 1.3090
2022-07-13 01:19:13 - train: epoch 0069, iter [01600, 05004], lr: 0.050039, loss: 1.4086
2022-07-13 01:20:06 - train: epoch 0069, iter [01700, 05004], lr: 0.049982, loss: 1.5524
2022-07-13 01:21:00 - train: epoch 0069, iter [01800, 05004], lr: 0.049924, loss: 1.4150
2022-07-13 01:21:54 - train: epoch 0069, iter [01900, 05004], lr: 0.049867, loss: 1.4786
2022-07-13 01:22:48 - train: epoch 0069, iter [02000, 05004], lr: 0.049810, loss: 1.3155
2022-07-13 01:23:42 - train: epoch 0069, iter [02100, 05004], lr: 0.049753, loss: 1.5212
2022-07-13 01:24:35 - train: epoch 0069, iter [02200, 05004], lr: 0.049696, loss: 1.5453
2022-07-13 01:25:29 - train: epoch 0069, iter [02300, 05004], lr: 0.049639, loss: 1.2551
2022-07-13 01:26:22 - train: epoch 0069, iter [02400, 05004], lr: 0.049582, loss: 1.5722
2022-07-13 01:27:15 - train: epoch 0069, iter [02500, 05004], lr: 0.049525, loss: 1.2917
2022-07-13 01:28:09 - train: epoch 0069, iter [02600, 05004], lr: 0.049468, loss: 1.3855
2022-07-13 01:29:03 - train: epoch 0069, iter [02700, 05004], lr: 0.049411, loss: 1.6154
2022-07-13 01:29:56 - train: epoch 0069, iter [02800, 05004], lr: 0.049354, loss: 1.3999
2022-07-13 01:30:50 - train: epoch 0069, iter [02900, 05004], lr: 0.049297, loss: 1.4020
2022-07-13 01:31:44 - train: epoch 0069, iter [03000, 05004], lr: 0.049240, loss: 1.4059
2022-07-13 01:32:39 - train: epoch 0069, iter [03100, 05004], lr: 0.049183, loss: 1.5290
2022-07-13 01:33:32 - train: epoch 0069, iter [03200, 05004], lr: 0.049126, loss: 1.4051
2022-07-13 01:34:25 - train: epoch 0069, iter [03300, 05004], lr: 0.049069, loss: 1.3578
2022-07-13 01:35:18 - train: epoch 0069, iter [03400, 05004], lr: 0.049012, loss: 1.4259
2022-07-13 01:36:13 - train: epoch 0069, iter [03500, 05004], lr: 0.048955, loss: 1.3562
2022-07-13 01:37:06 - train: epoch 0069, iter [03600, 05004], lr: 0.048898, loss: 1.2602
2022-07-13 01:38:00 - train: epoch 0069, iter [03700, 05004], lr: 0.048842, loss: 1.4157
2022-07-13 01:38:53 - train: epoch 0069, iter [03800, 05004], lr: 0.048785, loss: 1.2830
2022-07-13 01:39:46 - train: epoch 0069, iter [03900, 05004], lr: 0.048728, loss: 1.3072
2022-07-13 01:40:39 - train: epoch 0069, iter [04000, 05004], lr: 0.048671, loss: 1.4440
2022-07-13 01:41:32 - train: epoch 0069, iter [04100, 05004], lr: 0.048615, loss: 1.2760
2022-07-13 01:42:25 - train: epoch 0069, iter [04200, 05004], lr: 0.048558, loss: 1.3926
2022-07-13 01:43:18 - train: epoch 0069, iter [04300, 05004], lr: 0.048501, loss: 1.3695
2022-07-13 01:44:12 - train: epoch 0069, iter [04400, 05004], lr: 0.048445, loss: 1.4743
2022-07-13 01:45:05 - train: epoch 0069, iter [04500, 05004], lr: 0.048388, loss: 1.3864
2022-07-13 01:45:59 - train: epoch 0069, iter [04600, 05004], lr: 0.048331, loss: 1.7033
2022-07-13 01:46:53 - train: epoch 0069, iter [04700, 05004], lr: 0.048275, loss: 1.4026
2022-07-13 01:47:47 - train: epoch 0069, iter [04800, 05004], lr: 0.048218, loss: 1.5684
2022-07-13 01:48:40 - train: epoch 0069, iter [04900, 05004], lr: 0.048162, loss: 1.2292
2022-07-13 01:49:32 - train: epoch 0069, iter [05000, 05004], lr: 0.048105, loss: 1.4314
2022-07-13 01:49:34 - train: epoch 069, train_loss: 1.3821
2022-07-13 01:51:42 - eval: epoch: 069, acc1: 69.960%, acc5: 89.764%, test_loss: 1.2175, per_image_load_time: 2.158ms, per_image_inference_time: 0.840ms
2022-07-13 01:51:42 - until epoch: 069, best_acc1: 69.960%
2022-07-13 01:51:42 - epoch 070 lr: 0.048102
2022-07-13 01:52:53 - train: epoch 0070, iter [00100, 05004], lr: 0.048047, loss: 1.0834
2022-07-13 01:53:49 - train: epoch 0070, iter [00200, 05004], lr: 0.047990, loss: 1.2588
2022-07-13 01:54:44 - train: epoch 0070, iter [00300, 05004], lr: 0.047934, loss: 1.4829
2022-07-13 01:55:39 - train: epoch 0070, iter [00400, 05004], lr: 0.047877, loss: 1.3364
2022-07-13 01:56:32 - train: epoch 0070, iter [00500, 05004], lr: 0.047821, loss: 1.1780
2022-07-13 01:57:25 - train: epoch 0070, iter [00600, 05004], lr: 0.047765, loss: 1.1540
2022-07-13 01:58:19 - train: epoch 0070, iter [00700, 05004], lr: 0.047708, loss: 1.3166
2022-07-13 01:59:13 - train: epoch 0070, iter [00800, 05004], lr: 0.047652, loss: 1.4120
2022-07-13 02:00:07 - train: epoch 0070, iter [00900, 05004], lr: 0.047596, loss: 1.3889
2022-07-13 02:01:00 - train: epoch 0070, iter [01000, 05004], lr: 0.047539, loss: 1.2875
2022-07-13 02:01:54 - train: epoch 0070, iter [01100, 05004], lr: 0.047483, loss: 1.4536
2022-07-13 02:02:48 - train: epoch 0070, iter [01200, 05004], lr: 0.047427, loss: 1.3029
2022-07-13 02:03:43 - train: epoch 0070, iter [01300, 05004], lr: 0.047371, loss: 1.2396
2022-07-13 02:04:36 - train: epoch 0070, iter [01400, 05004], lr: 0.047314, loss: 1.4087
2022-07-13 02:05:29 - train: epoch 0070, iter [01500, 05004], lr: 0.047258, loss: 1.2649
2022-07-13 02:06:23 - train: epoch 0070, iter [01600, 05004], lr: 0.047202, loss: 1.2439
2022-07-13 02:07:17 - train: epoch 0070, iter [01700, 05004], lr: 0.047146, loss: 1.2386
2022-07-13 02:08:11 - train: epoch 0070, iter [01800, 05004], lr: 0.047090, loss: 1.1468
2022-07-13 02:09:04 - train: epoch 0070, iter [01900, 05004], lr: 0.047034, loss: 1.4094
2022-07-13 02:09:59 - train: epoch 0070, iter [02000, 05004], lr: 0.046978, loss: 1.2881
2022-07-13 02:10:53 - train: epoch 0070, iter [02100, 05004], lr: 0.046922, loss: 1.2747
2022-07-13 02:11:46 - train: epoch 0070, iter [02200, 05004], lr: 0.046866, loss: 1.2534
2022-07-13 02:12:40 - train: epoch 0070, iter [02300, 05004], lr: 0.046810, loss: 1.3114
2022-07-13 02:13:35 - train: epoch 0070, iter [02400, 05004], lr: 0.046754, loss: 1.2322
2022-07-13 02:14:29 - train: epoch 0070, iter [02500, 05004], lr: 0.046698, loss: 1.2536
2022-07-13 02:15:24 - train: epoch 0070, iter [02600, 05004], lr: 0.046642, loss: 1.2046
2022-07-13 02:16:17 - train: epoch 0070, iter [02700, 05004], lr: 0.046586, loss: 1.4404
2022-07-13 02:17:12 - train: epoch 0070, iter [02800, 05004], lr: 0.046530, loss: 1.5644
2022-07-13 02:18:06 - train: epoch 0070, iter [02900, 05004], lr: 0.046474, loss: 1.5059
2022-07-13 02:19:00 - train: epoch 0070, iter [03000, 05004], lr: 0.046419, loss: 1.2671
2022-07-13 02:19:54 - train: epoch 0070, iter [03100, 05004], lr: 0.046363, loss: 1.3540
2022-07-13 02:20:47 - train: epoch 0070, iter [03200, 05004], lr: 0.046307, loss: 1.4133
2022-07-13 02:21:41 - train: epoch 0070, iter [03300, 05004], lr: 0.046251, loss: 1.3519
2022-07-13 02:22:35 - train: epoch 0070, iter [03400, 05004], lr: 0.046196, loss: 1.4210
2022-07-13 02:23:29 - train: epoch 0070, iter [03500, 05004], lr: 0.046140, loss: 1.4950
2022-07-13 02:24:22 - train: epoch 0070, iter [03600, 05004], lr: 0.046084, loss: 1.4137
2022-07-13 02:25:16 - train: epoch 0070, iter [03700, 05004], lr: 0.046029, loss: 1.3537
2022-07-13 02:26:10 - train: epoch 0070, iter [03800, 05004], lr: 0.045973, loss: 1.3219
2022-07-13 02:27:03 - train: epoch 0070, iter [03900, 05004], lr: 0.045917, loss: 1.3598
2022-07-13 02:27:57 - train: epoch 0070, iter [04000, 05004], lr: 0.045862, loss: 1.3273
2022-07-13 02:28:50 - train: epoch 0070, iter [04100, 05004], lr: 0.045806, loss: 1.2332
2022-07-13 02:29:44 - train: epoch 0070, iter [04200, 05004], lr: 0.045751, loss: 1.3651
2022-07-13 02:30:38 - train: epoch 0070, iter [04300, 05004], lr: 0.045695, loss: 1.4299
2022-07-13 02:31:32 - train: epoch 0070, iter [04400, 05004], lr: 0.045640, loss: 1.3667
2022-07-13 02:32:27 - train: epoch 0070, iter [04500, 05004], lr: 0.045584, loss: 1.4742
2022-07-13 02:33:21 - train: epoch 0070, iter [04600, 05004], lr: 0.045529, loss: 1.5175
2022-07-13 02:34:15 - train: epoch 0070, iter [04700, 05004], lr: 0.045473, loss: 1.3408
2022-07-13 02:35:09 - train: epoch 0070, iter [04800, 05004], lr: 0.045418, loss: 1.3229
2022-07-13 02:36:03 - train: epoch 0070, iter [04900, 05004], lr: 0.045363, loss: 1.3087
2022-07-13 02:36:56 - train: epoch 0070, iter [05000, 05004], lr: 0.045307, loss: 1.4607
2022-07-13 02:36:58 - train: epoch 070, train_loss: 1.3651
2022-07-13 02:39:09 - eval: epoch: 070, acc1: 70.144%, acc5: 89.928%, test_loss: 1.2179, per_image_load_time: 3.866ms, per_image_inference_time: 0.824ms
2022-07-13 02:39:10 - until epoch: 070, best_acc1: 70.144%
2022-07-13 02:39:10 - epoch 071 lr: 0.045305
2022-07-13 02:40:14 - train: epoch 0071, iter [00100, 05004], lr: 0.045250, loss: 1.1581
2022-07-13 02:41:07 - train: epoch 0071, iter [00200, 05004], lr: 0.045195, loss: 1.4229
2022-07-13 02:42:00 - train: epoch 0071, iter [00300, 05004], lr: 0.045139, loss: 1.3622
2022-07-13 02:42:54 - train: epoch 0071, iter [00400, 05004], lr: 0.045084, loss: 1.5784
2022-07-13 02:43:46 - train: epoch 0071, iter [00500, 05004], lr: 0.045029, loss: 1.3731
2022-07-13 02:44:39 - train: epoch 0071, iter [00600, 05004], lr: 0.044974, loss: 1.5035
2022-07-13 02:45:31 - train: epoch 0071, iter [00700, 05004], lr: 0.044918, loss: 1.3236
2022-07-13 02:46:24 - train: epoch 0071, iter [00800, 05004], lr: 0.044863, loss: 1.4363
2022-07-13 02:47:18 - train: epoch 0071, iter [00900, 05004], lr: 0.044808, loss: 1.6070
2022-07-13 02:48:10 - train: epoch 0071, iter [01000, 05004], lr: 0.044753, loss: 1.2615
2022-07-13 02:49:04 - train: epoch 0071, iter [01100, 05004], lr: 0.044698, loss: 1.4105
2022-07-13 02:49:57 - train: epoch 0071, iter [01200, 05004], lr: 0.044643, loss: 1.2453
2022-07-13 02:50:50 - train: epoch 0071, iter [01300, 05004], lr: 0.044588, loss: 1.3368
2022-07-13 02:51:43 - train: epoch 0071, iter [01400, 05004], lr: 0.044533, loss: 1.3391
2022-07-13 02:52:37 - train: epoch 0071, iter [01500, 05004], lr: 0.044478, loss: 1.3082
2022-07-13 02:53:30 - train: epoch 0071, iter [01600, 05004], lr: 0.044423, loss: 1.1814
2022-07-13 02:54:24 - train: epoch 0071, iter [01700, 05004], lr: 0.044368, loss: 1.2719
2022-07-13 02:55:18 - train: epoch 0071, iter [01800, 05004], lr: 0.044313, loss: 1.5320
2022-07-13 02:56:11 - train: epoch 0071, iter [01900, 05004], lr: 0.044258, loss: 1.3166
2022-07-13 02:57:05 - train: epoch 0071, iter [02000, 05004], lr: 0.044203, loss: 1.3887
2022-07-13 02:58:00 - train: epoch 0071, iter [02100, 05004], lr: 0.044149, loss: 1.2587
2022-07-13 02:58:54 - train: epoch 0071, iter [02200, 05004], lr: 0.044094, loss: 1.2725
2022-07-13 02:59:48 - train: epoch 0071, iter [02300, 05004], lr: 0.044039, loss: 1.3224
2022-07-13 03:00:42 - train: epoch 0071, iter [02400, 05004], lr: 0.043984, loss: 1.2323
2022-07-13 03:01:36 - train: epoch 0071, iter [02500, 05004], lr: 0.043930, loss: 1.5044
2022-07-13 03:02:31 - train: epoch 0071, iter [02600, 05004], lr: 0.043875, loss: 1.1253
2022-07-13 03:03:24 - train: epoch 0071, iter [02700, 05004], lr: 0.043820, loss: 1.4871
2022-07-13 03:04:19 - train: epoch 0071, iter [02800, 05004], lr: 0.043766, loss: 1.4803
2022-07-13 03:05:12 - train: epoch 0071, iter [02900, 05004], lr: 0.043711, loss: 1.2213
2022-07-13 03:06:05 - train: epoch 0071, iter [03000, 05004], lr: 0.043656, loss: 1.5283
2022-07-13 03:06:59 - train: epoch 0071, iter [03100, 05004], lr: 0.043602, loss: 1.4607
2022-07-13 03:07:52 - train: epoch 0071, iter [03200, 05004], lr: 0.043547, loss: 1.4522
2022-07-13 03:08:46 - train: epoch 0071, iter [03300, 05004], lr: 0.043493, loss: 1.2199
2022-07-13 03:09:40 - train: epoch 0071, iter [03400, 05004], lr: 0.043438, loss: 1.1947
2022-07-13 03:10:35 - train: epoch 0071, iter [03500, 05004], lr: 0.043384, loss: 1.3887
2022-07-13 03:11:29 - train: epoch 0071, iter [03600, 05004], lr: 0.043329, loss: 1.4479
2022-07-13 03:12:24 - train: epoch 0071, iter [03700, 05004], lr: 0.043275, loss: 1.2398
2022-07-13 03:13:19 - train: epoch 0071, iter [03800, 05004], lr: 0.043220, loss: 1.5478
2022-07-13 03:14:13 - train: epoch 0071, iter [03900, 05004], lr: 0.043166, loss: 1.4455
2022-07-13 03:15:08 - train: epoch 0071, iter [04000, 05004], lr: 0.043112, loss: 1.4608
2022-07-13 03:16:03 - train: epoch 0071, iter [04100, 05004], lr: 0.043057, loss: 1.2898
2022-07-13 03:16:57 - train: epoch 0071, iter [04200, 05004], lr: 0.043003, loss: 1.5842
2022-07-13 03:17:50 - train: epoch 0071, iter [04300, 05004], lr: 0.042949, loss: 1.1548
2022-07-13 03:18:44 - train: epoch 0071, iter [04400, 05004], lr: 0.042894, loss: 1.3206
2022-07-13 03:19:38 - train: epoch 0071, iter [04500, 05004], lr: 0.042840, loss: 1.4928
2022-07-13 03:20:31 - train: epoch 0071, iter [04600, 05004], lr: 0.042786, loss: 1.2583
2022-07-13 03:21:26 - train: epoch 0071, iter [04700, 05004], lr: 0.042732, loss: 1.2988
2022-07-13 03:22:21 - train: epoch 0071, iter [04800, 05004], lr: 0.042678, loss: 1.3428
2022-07-13 03:23:14 - train: epoch 0071, iter [04900, 05004], lr: 0.042623, loss: 1.2339
2022-07-13 03:24:07 - train: epoch 0071, iter [05000, 05004], lr: 0.042569, loss: 1.4094
2022-07-13 03:24:10 - train: epoch 071, train_loss: 1.3462
2022-07-13 03:26:20 - eval: epoch: 071, acc1: 70.552%, acc5: 90.024%, test_loss: 1.2018, per_image_load_time: 3.606ms, per_image_inference_time: 0.898ms
2022-07-13 03:26:20 - until epoch: 071, best_acc1: 70.552%
2022-07-13 03:26:20 - epoch 072 lr: 0.042567
2022-07-13 03:27:26 - train: epoch 0072, iter [00100, 05004], lr: 0.042513, loss: 1.2693
2022-07-13 03:28:20 - train: epoch 0072, iter [00200, 05004], lr: 0.042459, loss: 1.1956
2022-07-13 03:29:14 - train: epoch 0072, iter [00300, 05004], lr: 0.042405, loss: 1.1528
2022-07-13 03:30:07 - train: epoch 0072, iter [00400, 05004], lr: 0.042351, loss: 1.2549
2022-07-13 03:31:00 - train: epoch 0072, iter [00500, 05004], lr: 0.042297, loss: 1.2679
2022-07-13 03:31:54 - train: epoch 0072, iter [00600, 05004], lr: 0.042243, loss: 1.2181
2022-07-13 03:32:46 - train: epoch 0072, iter [00700, 05004], lr: 0.042189, loss: 1.2645
2022-07-13 03:33:39 - train: epoch 0072, iter [00800, 05004], lr: 0.042135, loss: 1.5237
2022-07-13 03:34:33 - train: epoch 0072, iter [00900, 05004], lr: 0.042081, loss: 1.3451
2022-07-13 03:35:28 - train: epoch 0072, iter [01000, 05004], lr: 0.042027, loss: 1.3309
2022-07-13 03:36:22 - train: epoch 0072, iter [01100, 05004], lr: 0.041974, loss: 1.4715
2022-07-13 03:37:16 - train: epoch 0072, iter [01200, 05004], lr: 0.041920, loss: 1.2027
2022-07-13 03:38:11 - train: epoch 0072, iter [01300, 05004], lr: 0.041866, loss: 1.2575
2022-07-13 03:39:05 - train: epoch 0072, iter [01400, 05004], lr: 0.041812, loss: 1.2224
2022-07-13 03:40:00 - train: epoch 0072, iter [01500, 05004], lr: 0.041758, loss: 1.3162
2022-07-13 03:40:53 - train: epoch 0072, iter [01600, 05004], lr: 0.041705, loss: 1.2039
2022-07-13 03:41:47 - train: epoch 0072, iter [01700, 05004], lr: 0.041651, loss: 1.2746
2022-07-13 03:42:41 - train: epoch 0072, iter [01800, 05004], lr: 0.041597, loss: 1.2075
2022-07-13 03:43:36 - train: epoch 0072, iter [01900, 05004], lr: 0.041544, loss: 1.4736
2022-07-13 03:44:30 - train: epoch 0072, iter [02000, 05004], lr: 0.041490, loss: 1.1651
2022-07-13 03:45:24 - train: epoch 0072, iter [02100, 05004], lr: 0.041437, loss: 1.3851
2022-07-13 03:46:19 - train: epoch 0072, iter [02200, 05004], lr: 0.041383, loss: 1.5836
2022-07-13 03:47:13 - train: epoch 0072, iter [02300, 05004], lr: 0.041330, loss: 1.4980
2022-07-13 03:48:07 - train: epoch 0072, iter [02400, 05004], lr: 0.041276, loss: 1.2196
2022-07-13 03:49:01 - train: epoch 0072, iter [02500, 05004], lr: 0.041223, loss: 1.2917
2022-07-13 03:49:56 - train: epoch 0072, iter [02600, 05004], lr: 0.041169, loss: 1.3959
2022-07-13 03:50:50 - train: epoch 0072, iter [02700, 05004], lr: 0.041116, loss: 1.2658
2022-07-13 03:51:43 - train: epoch 0072, iter [02800, 05004], lr: 0.041062, loss: 1.2705
2022-07-13 03:52:37 - train: epoch 0072, iter [02900, 05004], lr: 0.041009, loss: 1.2367
2022-07-13 03:53:32 - train: epoch 0072, iter [03000, 05004], lr: 0.040956, loss: 1.1741
2022-07-13 03:54:26 - train: epoch 0072, iter [03100, 05004], lr: 0.040902, loss: 1.4306
2022-07-13 03:55:20 - train: epoch 0072, iter [03200, 05004], lr: 0.040849, loss: 1.2603
2022-07-13 03:56:15 - train: epoch 0072, iter [03300, 05004], lr: 0.040796, loss: 1.3926
2022-07-13 03:57:09 - train: epoch 0072, iter [03400, 05004], lr: 0.040742, loss: 1.5373
2022-07-13 03:58:03 - train: epoch 0072, iter [03500, 05004], lr: 0.040689, loss: 1.2844
2022-07-13 03:58:58 - train: epoch 0072, iter [03600, 05004], lr: 0.040636, loss: 1.4274
2022-07-13 03:59:51 - train: epoch 0072, iter [03700, 05004], lr: 0.040583, loss: 1.5207
2022-07-13 04:00:45 - train: epoch 0072, iter [03800, 05004], lr: 0.040530, loss: 1.3458
2022-07-13 04:01:38 - train: epoch 0072, iter [03900, 05004], lr: 0.040477, loss: 1.3080
2022-07-13 04:02:32 - train: epoch 0072, iter [04000, 05004], lr: 0.040423, loss: 1.2662
2022-07-13 04:03:28 - train: epoch 0072, iter [04100, 05004], lr: 0.040370, loss: 1.2612
2022-07-13 04:04:22 - train: epoch 0072, iter [04200, 05004], lr: 0.040317, loss: 1.2972
2022-07-13 04:05:16 - train: epoch 0072, iter [04300, 05004], lr: 0.040264, loss: 1.2363
2022-07-13 04:06:10 - train: epoch 0072, iter [04400, 05004], lr: 0.040211, loss: 1.4188
2022-07-13 04:07:04 - train: epoch 0072, iter [04500, 05004], lr: 0.040158, loss: 1.5968
2022-07-13 04:07:58 - train: epoch 0072, iter [04600, 05004], lr: 0.040105, loss: 1.1204
2022-07-13 04:08:52 - train: epoch 0072, iter [04700, 05004], lr: 0.040053, loss: 1.2880
2022-07-13 04:09:47 - train: epoch 0072, iter [04800, 05004], lr: 0.040000, loss: 1.4749
2022-07-13 04:10:42 - train: epoch 0072, iter [04900, 05004], lr: 0.039947, loss: 1.4733
2022-07-13 04:11:36 - train: epoch 0072, iter [05000, 05004], lr: 0.039894, loss: 1.3376
2022-07-13 04:11:38 - train: epoch 072, train_loss: 1.3254
2022-07-13 04:13:49 - eval: epoch: 072, acc1: 70.524%, acc5: 90.234%, test_loss: 1.1887, per_image_load_time: 2.517ms, per_image_inference_time: 0.872ms
2022-07-13 04:13:49 - until epoch: 072, best_acc1: 70.552%
2022-07-13 04:13:49 - epoch 073 lr: 0.039891
2022-07-13 04:14:56 - train: epoch 0073, iter [00100, 05004], lr: 0.039839, loss: 1.4274
2022-07-13 04:15:50 - train: epoch 0073, iter [00200, 05004], lr: 0.039786, loss: 1.5277
2022-07-13 04:16:43 - train: epoch 0073, iter [00300, 05004], lr: 0.039734, loss: 1.3440
2022-07-13 04:17:36 - train: epoch 0073, iter [00400, 05004], lr: 0.039681, loss: 1.0012
2022-07-13 04:18:28 - train: epoch 0073, iter [00500, 05004], lr: 0.039628, loss: 1.2543
2022-07-13 04:19:21 - train: epoch 0073, iter [00600, 05004], lr: 0.039575, loss: 1.2047
2022-07-13 04:20:14 - train: epoch 0073, iter [00700, 05004], lr: 0.039523, loss: 1.2982
2022-07-13 04:21:07 - train: epoch 0073, iter [00800, 05004], lr: 0.039470, loss: 1.3170
2022-07-13 04:22:01 - train: epoch 0073, iter [00900, 05004], lr: 0.039418, loss: 1.3050
2022-07-13 04:22:54 - train: epoch 0073, iter [01000, 05004], lr: 0.039365, loss: 1.2032
2022-07-13 04:23:48 - train: epoch 0073, iter [01100, 05004], lr: 0.039313, loss: 1.2454
2022-07-13 04:24:42 - train: epoch 0073, iter [01200, 05004], lr: 0.039260, loss: 1.3249
2022-07-13 04:25:36 - train: epoch 0073, iter [01300, 05004], lr: 0.039208, loss: 1.5865
2022-07-13 04:26:30 - train: epoch 0073, iter [01400, 05004], lr: 0.039155, loss: 1.1735
2022-07-13 04:27:25 - train: epoch 0073, iter [01500, 05004], lr: 0.039103, loss: 1.4792
2022-07-13 04:28:18 - train: epoch 0073, iter [01600, 05004], lr: 0.039050, loss: 1.3864
2022-07-13 04:29:12 - train: epoch 0073, iter [01700, 05004], lr: 0.038998, loss: 1.2788
2022-07-13 04:30:06 - train: epoch 0073, iter [01800, 05004], lr: 0.038945, loss: 1.1394
2022-07-13 04:31:00 - train: epoch 0073, iter [01900, 05004], lr: 0.038893, loss: 1.2989
2022-07-13 04:31:54 - train: epoch 0073, iter [02000, 05004], lr: 0.038841, loss: 1.2737
2022-07-13 04:32:48 - train: epoch 0073, iter [02100, 05004], lr: 0.038789, loss: 1.4991
2022-07-13 04:33:42 - train: epoch 0073, iter [02200, 05004], lr: 0.038736, loss: 1.4455
2022-07-13 04:34:37 - train: epoch 0073, iter [02300, 05004], lr: 0.038684, loss: 1.2277
2022-07-13 04:35:31 - train: epoch 0073, iter [02400, 05004], lr: 0.038632, loss: 1.3011
2022-07-13 04:36:27 - train: epoch 0073, iter [02500, 05004], lr: 0.038580, loss: 1.2510
2022-07-13 04:37:21 - train: epoch 0073, iter [02600, 05004], lr: 0.038528, loss: 1.1346
2022-07-13 04:38:15 - train: epoch 0073, iter [02700, 05004], lr: 0.038476, loss: 1.4545
2022-07-13 04:39:09 - train: epoch 0073, iter [02800, 05004], lr: 0.038423, loss: 1.3753
2022-07-13 04:40:04 - train: epoch 0073, iter [02900, 05004], lr: 0.038371, loss: 1.4175
2022-07-13 04:40:57 - train: epoch 0073, iter [03000, 05004], lr: 0.038319, loss: 1.1361
2022-07-13 04:41:51 - train: epoch 0073, iter [03100, 05004], lr: 0.038267, loss: 1.2138
2022-07-13 04:42:45 - train: epoch 0073, iter [03200, 05004], lr: 0.038215, loss: 1.1663
2022-07-13 04:43:39 - train: epoch 0073, iter [03300, 05004], lr: 0.038163, loss: 1.0503
2022-07-13 04:44:33 - train: epoch 0073, iter [03400, 05004], lr: 0.038111, loss: 1.1064
2022-07-13 04:45:26 - train: epoch 0073, iter [03500, 05004], lr: 0.038060, loss: 1.3052
2022-07-13 04:46:20 - train: epoch 0073, iter [03600, 05004], lr: 0.038008, loss: 1.2361
2022-07-13 04:47:14 - train: epoch 0073, iter [03700, 05004], lr: 0.037956, loss: 1.3069
2022-07-13 04:48:08 - train: epoch 0073, iter [03800, 05004], lr: 0.037904, loss: 1.4152
2022-07-13 04:49:02 - train: epoch 0073, iter [03900, 05004], lr: 0.037852, loss: 1.1935
2022-07-13 04:49:56 - train: epoch 0073, iter [04000, 05004], lr: 0.037801, loss: 1.2105
2022-07-13 04:50:49 - train: epoch 0073, iter [04100, 05004], lr: 0.037749, loss: 1.2978
2022-07-13 04:51:43 - train: epoch 0073, iter [04200, 05004], lr: 0.037697, loss: 1.5687
2022-07-13 04:52:38 - train: epoch 0073, iter [04300, 05004], lr: 0.037645, loss: 1.4431
2022-07-13 04:53:32 - train: epoch 0073, iter [04400, 05004], lr: 0.037594, loss: 1.4025
2022-07-13 04:54:26 - train: epoch 0073, iter [04500, 05004], lr: 0.037542, loss: 1.2091
2022-07-13 04:55:20 - train: epoch 0073, iter [04600, 05004], lr: 0.037491, loss: 1.3701
2022-07-13 04:56:13 - train: epoch 0073, iter [04700, 05004], lr: 0.037439, loss: 1.1859
2022-07-13 04:57:07 - train: epoch 0073, iter [04800, 05004], lr: 0.037387, loss: 1.3843
2022-07-13 04:58:01 - train: epoch 0073, iter [04900, 05004], lr: 0.037336, loss: 1.4053
2022-07-13 04:58:53 - train: epoch 0073, iter [05000, 05004], lr: 0.037284, loss: 1.2961
2022-07-13 04:58:55 - train: epoch 073, train_loss: 1.3074
2022-07-13 05:01:06 - eval: epoch: 073, acc1: 70.918%, acc5: 90.212%, test_loss: 1.1753, per_image_load_time: 4.160ms, per_image_inference_time: 0.864ms
2022-07-13 05:01:06 - until epoch: 073, best_acc1: 70.918%
2022-07-13 05:01:06 - epoch 074 lr: 0.037282
2022-07-13 05:02:14 - train: epoch 0074, iter [00100, 05004], lr: 0.037231, loss: 1.1865
2022-07-13 05:03:08 - train: epoch 0074, iter [00200, 05004], lr: 0.037179, loss: 1.3734
2022-07-13 05:04:01 - train: epoch 0074, iter [00300, 05004], lr: 0.037128, loss: 1.1737
2022-07-13 05:04:54 - train: epoch 0074, iter [00400, 05004], lr: 0.037077, loss: 1.3970
2022-07-13 05:05:47 - train: epoch 0074, iter [00500, 05004], lr: 0.037025, loss: 1.1444
2022-07-13 05:06:39 - train: epoch 0074, iter [00600, 05004], lr: 0.036974, loss: 1.2214
2022-07-13 05:07:32 - train: epoch 0074, iter [00700, 05004], lr: 0.036923, loss: 1.2058
2022-07-13 05:08:26 - train: epoch 0074, iter [00800, 05004], lr: 0.036871, loss: 1.3210
2022-07-13 05:09:20 - train: epoch 0074, iter [00900, 05004], lr: 0.036820, loss: 1.1480
2022-07-13 05:10:13 - train: epoch 0074, iter [01000, 05004], lr: 0.036769, loss: 1.4190
2022-07-13 05:11:06 - train: epoch 0074, iter [01100, 05004], lr: 0.036718, loss: 1.3122
2022-07-13 05:12:00 - train: epoch 0074, iter [01200, 05004], lr: 0.036667, loss: 1.0991
2022-07-13 05:12:54 - train: epoch 0074, iter [01300, 05004], lr: 0.036616, loss: 1.2215
2022-07-13 05:13:49 - train: epoch 0074, iter [01400, 05004], lr: 0.036564, loss: 1.2552
2022-07-13 05:14:42 - train: epoch 0074, iter [01500, 05004], lr: 0.036513, loss: 1.3033
2022-07-13 05:15:37 - train: epoch 0074, iter [01600, 05004], lr: 0.036462, loss: 1.4287
2022-07-13 05:16:30 - train: epoch 0074, iter [01700, 05004], lr: 0.036411, loss: 1.5076
2022-07-13 05:17:24 - train: epoch 0074, iter [01800, 05004], lr: 0.036360, loss: 1.3602
2022-07-13 05:18:18 - train: epoch 0074, iter [01900, 05004], lr: 0.036309, loss: 1.3964
2022-07-13 05:19:12 - train: epoch 0074, iter [02000, 05004], lr: 0.036258, loss: 1.2324
2022-07-13 05:20:05 - train: epoch 0074, iter [02100, 05004], lr: 0.036208, loss: 1.1580
2022-07-13 05:20:59 - train: epoch 0074, iter [02200, 05004], lr: 0.036157, loss: 1.6433
2022-07-13 05:21:53 - train: epoch 0074, iter [02300, 05004], lr: 0.036106, loss: 1.4610
2022-07-13 05:22:46 - train: epoch 0074, iter [02400, 05004], lr: 0.036055, loss: 1.4114
2022-07-13 05:23:38 - train: epoch 0074, iter [02500, 05004], lr: 0.036004, loss: 1.3288
2022-07-13 05:24:31 - train: epoch 0074, iter [02600, 05004], lr: 0.035953, loss: 0.9883
2022-07-13 05:25:25 - train: epoch 0074, iter [02700, 05004], lr: 0.035903, loss: 1.0881
2022-07-13 05:26:19 - train: epoch 0074, iter [02800, 05004], lr: 0.035852, loss: 1.5071
2022-07-13 05:27:11 - train: epoch 0074, iter [02900, 05004], lr: 0.035801, loss: 1.3473
2022-07-13 05:28:05 - train: epoch 0074, iter [03000, 05004], lr: 0.035751, loss: 1.3034
2022-07-13 05:28:58 - train: epoch 0074, iter [03100, 05004], lr: 0.035700, loss: 1.3606
2022-07-13 05:29:53 - train: epoch 0074, iter [03200, 05004], lr: 0.035649, loss: 1.1398
2022-07-13 05:30:46 - train: epoch 0074, iter [03300, 05004], lr: 0.035599, loss: 1.2246
2022-07-13 05:31:40 - train: epoch 0074, iter [03400, 05004], lr: 0.035548, loss: 1.3819
2022-07-13 05:32:33 - train: epoch 0074, iter [03500, 05004], lr: 0.035498, loss: 1.1195
2022-07-13 05:33:27 - train: epoch 0074, iter [03600, 05004], lr: 0.035447, loss: 1.5639
2022-07-13 05:34:21 - train: epoch 0074, iter [03700, 05004], lr: 0.035397, loss: 1.2984
2022-07-13 05:35:14 - train: epoch 0074, iter [03800, 05004], lr: 0.035346, loss: 1.2716
2022-07-13 05:36:08 - train: epoch 0074, iter [03900, 05004], lr: 0.035296, loss: 1.2182
2022-07-13 05:37:03 - train: epoch 0074, iter [04000, 05004], lr: 0.035246, loss: 1.3663
2022-07-13 05:37:56 - train: epoch 0074, iter [04100, 05004], lr: 0.035195, loss: 1.2910
2022-07-13 05:38:49 - train: epoch 0074, iter [04200, 05004], lr: 0.035145, loss: 1.2093
2022-07-13 05:39:44 - train: epoch 0074, iter [04300, 05004], lr: 0.035095, loss: 1.3303
2022-07-13 05:40:38 - train: epoch 0074, iter [04400, 05004], lr: 0.035044, loss: 1.0389
2022-07-13 05:41:33 - train: epoch 0074, iter [04500, 05004], lr: 0.034994, loss: 1.2599
2022-07-13 05:42:26 - train: epoch 0074, iter [04600, 05004], lr: 0.034944, loss: 1.4227
2022-07-13 05:43:20 - train: epoch 0074, iter [04700, 05004], lr: 0.034894, loss: 1.2227
2022-07-13 05:44:13 - train: epoch 0074, iter [04800, 05004], lr: 0.034844, loss: 1.4917
2022-07-13 05:45:07 - train: epoch 0074, iter [04900, 05004], lr: 0.034794, loss: 1.5315
2022-07-13 05:46:00 - train: epoch 0074, iter [05000, 05004], lr: 0.034743, loss: 1.3028
2022-07-13 05:46:03 - train: epoch 074, train_loss: 1.2857
2022-07-13 05:48:13 - eval: epoch: 074, acc1: 71.416%, acc5: 90.690%, test_loss: 1.1456, per_image_load_time: 2.024ms, per_image_inference_time: 0.892ms
2022-07-13 05:48:13 - until epoch: 074, best_acc1: 71.416%
2022-07-13 05:48:13 - epoch 075 lr: 0.034741
2022-07-13 05:49:22 - train: epoch 0075, iter [00100, 05004], lr: 0.034691, loss: 1.3754
2022-07-13 05:50:16 - train: epoch 0075, iter [00200, 05004], lr: 0.034641, loss: 1.1229
2022-07-13 05:51:10 - train: epoch 0075, iter [00300, 05004], lr: 0.034591, loss: 1.1879
2022-07-13 05:52:03 - train: epoch 0075, iter [00400, 05004], lr: 0.034541, loss: 1.3383
2022-07-13 05:52:57 - train: epoch 0075, iter [00500, 05004], lr: 0.034491, loss: 1.3247
2022-07-13 05:53:51 - train: epoch 0075, iter [00600, 05004], lr: 0.034441, loss: 1.1901
2022-07-13 05:54:44 - train: epoch 0075, iter [00700, 05004], lr: 0.034392, loss: 1.4773
2022-07-13 05:55:37 - train: epoch 0075, iter [00800, 05004], lr: 0.034342, loss: 1.1724
2022-07-13 05:56:31 - train: epoch 0075, iter [00900, 05004], lr: 0.034292, loss: 1.3332
2022-07-13 05:57:24 - train: epoch 0075, iter [01000, 05004], lr: 0.034242, loss: 1.1881
2022-07-13 05:58:18 - train: epoch 0075, iter [01100, 05004], lr: 0.034192, loss: 1.4003
2022-07-13 05:59:12 - train: epoch 0075, iter [01200, 05004], lr: 0.034143, loss: 0.9265
2022-07-13 06:00:06 - train: epoch 0075, iter [01300, 05004], lr: 0.034093, loss: 1.3041
2022-07-13 06:00:59 - train: epoch 0075, iter [01400, 05004], lr: 0.034043, loss: 1.0273
2022-07-13 06:01:52 - train: epoch 0075, iter [01500, 05004], lr: 0.033994, loss: 1.3604
2022-07-13 06:02:46 - train: epoch 0075, iter [01600, 05004], lr: 0.033944, loss: 1.1481
2022-07-13 06:03:40 - train: epoch 0075, iter [01700, 05004], lr: 0.033894, loss: 1.2472
2022-07-13 06:04:34 - train: epoch 0075, iter [01800, 05004], lr: 0.033845, loss: 1.2928
2022-07-13 06:05:28 - train: epoch 0075, iter [01900, 05004], lr: 0.033795, loss: 1.0943
2022-07-13 06:06:22 - train: epoch 0075, iter [02000, 05004], lr: 0.033746, loss: 1.1588
2022-07-13 06:07:16 - train: epoch 0075, iter [02100, 05004], lr: 0.033696, loss: 1.1230
2022-07-13 06:08:10 - train: epoch 0075, iter [02200, 05004], lr: 0.033647, loss: 1.4097
2022-07-13 06:09:04 - train: epoch 0075, iter [02300, 05004], lr: 0.033597, loss: 1.1642
2022-07-13 06:09:58 - train: epoch 0075, iter [02400, 05004], lr: 0.033548, loss: 1.3070
2022-07-13 06:10:51 - train: epoch 0075, iter [02500, 05004], lr: 0.033499, loss: 1.2060
2022-07-13 06:11:45 - train: epoch 0075, iter [02600, 05004], lr: 0.033449, loss: 1.2795
2022-07-13 06:12:39 - train: epoch 0075, iter [02700, 05004], lr: 0.033400, loss: 1.2986
2022-07-13 06:13:33 - train: epoch 0075, iter [02800, 05004], lr: 0.033351, loss: 1.1484
2022-07-13 06:14:26 - train: epoch 0075, iter [02900, 05004], lr: 0.033301, loss: 1.3661
2022-07-13 06:15:20 - train: epoch 0075, iter [03000, 05004], lr: 0.033252, loss: 1.5006
2022-07-13 06:16:15 - train: epoch 0075, iter [03100, 05004], lr: 0.033203, loss: 1.2324
2022-07-13 06:17:10 - train: epoch 0075, iter [03200, 05004], lr: 0.033154, loss: 1.2867
2022-07-13 06:18:04 - train: epoch 0075, iter [03300, 05004], lr: 0.033105, loss: 1.1238
2022-07-13 06:18:58 - train: epoch 0075, iter [03400, 05004], lr: 0.033056, loss: 1.3208
2022-07-13 06:19:51 - train: epoch 0075, iter [03500, 05004], lr: 0.033006, loss: 1.2864
2022-07-13 06:20:45 - train: epoch 0075, iter [03600, 05004], lr: 0.032957, loss: 1.4514
2022-07-13 06:21:39 - train: epoch 0075, iter [03700, 05004], lr: 0.032908, loss: 1.3014
2022-07-13 06:22:34 - train: epoch 0075, iter [03800, 05004], lr: 0.032859, loss: 1.1371
2022-07-13 06:23:27 - train: epoch 0075, iter [03900, 05004], lr: 0.032810, loss: 1.1756
2022-07-13 06:24:22 - train: epoch 0075, iter [04000, 05004], lr: 0.032761, loss: 1.2082
2022-07-13 06:25:16 - train: epoch 0075, iter [04100, 05004], lr: 0.032713, loss: 0.9553
2022-07-13 06:26:10 - train: epoch 0075, iter [04200, 05004], lr: 0.032664, loss: 1.4062
2022-07-13 06:27:05 - train: epoch 0075, iter [04300, 05004], lr: 0.032615, loss: 1.3087
2022-07-13 06:27:58 - train: epoch 0075, iter [04400, 05004], lr: 0.032566, loss: 1.2053
2022-07-13 06:28:52 - train: epoch 0075, iter [04500, 05004], lr: 0.032517, loss: 1.3630
2022-07-13 06:29:47 - train: epoch 0075, iter [04600, 05004], lr: 0.032469, loss: 1.2298
2022-07-13 06:30:41 - train: epoch 0075, iter [04700, 05004], lr: 0.032420, loss: 1.2414
2022-07-13 06:31:35 - train: epoch 0075, iter [04800, 05004], lr: 0.032371, loss: 1.1462
2022-07-13 06:32:29 - train: epoch 0075, iter [04900, 05004], lr: 0.032322, loss: 1.1879
2022-07-13 06:33:21 - train: epoch 0075, iter [05000, 05004], lr: 0.032274, loss: 1.0426
2022-07-13 06:33:24 - train: epoch 075, train_loss: 1.2642
2022-07-13 06:35:33 - eval: epoch: 075, acc1: 71.780%, acc5: 90.630%, test_loss: 1.1510, per_image_load_time: 3.943ms, per_image_inference_time: 0.871ms
2022-07-13 06:35:33 - until epoch: 075, best_acc1: 71.780%
2022-07-13 06:35:33 - epoch 076 lr: 0.032271
2022-07-13 06:36:40 - train: epoch 0076, iter [00100, 05004], lr: 0.032223, loss: 1.2035
2022-07-13 06:37:32 - train: epoch 0076, iter [00200, 05004], lr: 0.032175, loss: 1.2288
2022-07-13 06:38:25 - train: epoch 0076, iter [00300, 05004], lr: 0.032126, loss: 1.4775
2022-07-13 06:39:18 - train: epoch 0076, iter [00400, 05004], lr: 0.032078, loss: 1.2413
2022-07-13 06:40:11 - train: epoch 0076, iter [00500, 05004], lr: 0.032029, loss: 1.2473
2022-07-13 06:41:04 - train: epoch 0076, iter [00600, 05004], lr: 0.031981, loss: 1.3356
2022-07-13 06:41:57 - train: epoch 0076, iter [00700, 05004], lr: 0.031932, loss: 1.1741
2022-07-13 06:42:50 - train: epoch 0076, iter [00800, 05004], lr: 0.031884, loss: 1.2754
2022-07-13 06:43:43 - train: epoch 0076, iter [00900, 05004], lr: 0.031835, loss: 1.1253
2022-07-13 06:44:37 - train: epoch 0076, iter [01000, 05004], lr: 0.031787, loss: 1.2628
2022-07-13 06:45:31 - train: epoch 0076, iter [01100, 05004], lr: 0.031739, loss: 1.0248
2022-07-13 06:46:24 - train: epoch 0076, iter [01200, 05004], lr: 0.031691, loss: 1.2181
2022-07-13 06:47:18 - train: epoch 0076, iter [01300, 05004], lr: 0.031642, loss: 1.2649
2022-07-13 06:48:12 - train: epoch 0076, iter [01400, 05004], lr: 0.031594, loss: 1.1718
2022-07-13 06:49:05 - train: epoch 0076, iter [01500, 05004], lr: 0.031546, loss: 1.1952
2022-07-13 06:50:00 - train: epoch 0076, iter [01600, 05004], lr: 0.031498, loss: 1.1418
2022-07-13 06:50:52 - train: epoch 0076, iter [01700, 05004], lr: 0.031450, loss: 1.3005
2022-07-13 06:51:46 - train: epoch 0076, iter [01800, 05004], lr: 0.031401, loss: 1.1736
2022-07-13 06:52:40 - train: epoch 0076, iter [01900, 05004], lr: 0.031353, loss: 1.2417
2022-07-13 06:53:35 - train: epoch 0076, iter [02000, 05004], lr: 0.031305, loss: 1.2172
2022-07-13 06:54:29 - train: epoch 0076, iter [02100, 05004], lr: 0.031257, loss: 1.3082
2022-07-13 06:55:24 - train: epoch 0076, iter [02200, 05004], lr: 0.031209, loss: 1.0854
2022-07-13 06:56:17 - train: epoch 0076, iter [02300, 05004], lr: 0.031161, loss: 1.1927
2022-07-13 06:57:10 - train: epoch 0076, iter [02400, 05004], lr: 0.031114, loss: 1.2220
2022-07-13 06:58:04 - train: epoch 0076, iter [02500, 05004], lr: 0.031066, loss: 1.2321
2022-07-13 06:58:59 - train: epoch 0076, iter [02600, 05004], lr: 0.031018, loss: 1.4764
2022-07-13 06:59:52 - train: epoch 0076, iter [02700, 05004], lr: 0.030970, loss: 1.2696
2022-07-13 07:00:46 - train: epoch 0076, iter [02800, 05004], lr: 0.030922, loss: 1.1271
2022-07-13 07:01:41 - train: epoch 0076, iter [02900, 05004], lr: 0.030874, loss: 1.3120
2022-07-13 07:02:36 - train: epoch 0076, iter [03000, 05004], lr: 0.030827, loss: 1.0820
2022-07-13 07:03:30 - train: epoch 0076, iter [03100, 05004], lr: 0.030779, loss: 1.3876
2022-07-13 07:04:24 - train: epoch 0076, iter [03200, 05004], lr: 0.030731, loss: 1.1328
2022-07-13 07:05:17 - train: epoch 0076, iter [03300, 05004], lr: 0.030684, loss: 1.2996
2022-07-13 07:06:10 - train: epoch 0076, iter [03400, 05004], lr: 0.030636, loss: 1.2115
2022-07-13 07:07:04 - train: epoch 0076, iter [03500, 05004], lr: 0.030588, loss: 1.0680
2022-07-13 07:07:57 - train: epoch 0076, iter [03600, 05004], lr: 0.030541, loss: 1.1534
2022-07-13 07:08:51 - train: epoch 0076, iter [03700, 05004], lr: 0.030493, loss: 1.0998
2022-07-13 07:09:45 - train: epoch 0076, iter [03800, 05004], lr: 0.030446, loss: 1.2979
2022-07-13 07:10:38 - train: epoch 0076, iter [03900, 05004], lr: 0.030398, loss: 1.2433
2022-07-13 07:11:31 - train: epoch 0076, iter [04000, 05004], lr: 0.030351, loss: 1.4167
2022-07-13 07:12:24 - train: epoch 0076, iter [04100, 05004], lr: 0.030303, loss: 1.3151
2022-07-13 07:13:17 - train: epoch 0076, iter [04200, 05004], lr: 0.030256, loss: 1.2940
2022-07-13 07:14:10 - train: epoch 0076, iter [04300, 05004], lr: 0.030209, loss: 1.2771
2022-07-13 07:15:04 - train: epoch 0076, iter [04400, 05004], lr: 0.030161, loss: 1.2395
2022-07-13 07:15:57 - train: epoch 0076, iter [04500, 05004], lr: 0.030114, loss: 1.4292
2022-07-13 07:16:50 - train: epoch 0076, iter [04600, 05004], lr: 0.030067, loss: 1.2033
2022-07-13 07:17:43 - train: epoch 0076, iter [04700, 05004], lr: 0.030020, loss: 1.2572
2022-07-13 07:18:37 - train: epoch 0076, iter [04800, 05004], lr: 0.029972, loss: 1.0436
2022-07-13 07:19:31 - train: epoch 0076, iter [04900, 05004], lr: 0.029925, loss: 1.3561
2022-07-13 07:20:22 - train: epoch 0076, iter [05000, 05004], lr: 0.029878, loss: 1.4925
2022-07-13 07:20:25 - train: epoch 076, train_loss: 1.2424
2022-07-13 07:22:36 - eval: epoch: 076, acc1: 71.520%, acc5: 90.530%, test_loss: 1.1551, per_image_load_time: 2.884ms, per_image_inference_time: 0.860ms
2022-07-13 07:22:36 - until epoch: 076, best_acc1: 71.780%
2022-07-13 07:22:36 - epoch 077 lr: 0.029876
2022-07-13 07:23:45 - train: epoch 0077, iter [00100, 05004], lr: 0.029829, loss: 1.2123
2022-07-13 07:24:38 - train: epoch 0077, iter [00200, 05004], lr: 0.029782, loss: 1.3662
2022-07-13 07:25:31 - train: epoch 0077, iter [00300, 05004], lr: 0.029735, loss: 1.1297
2022-07-13 07:26:23 - train: epoch 0077, iter [00400, 05004], lr: 0.029688, loss: 1.4187
2022-07-13 07:27:15 - train: epoch 0077, iter [00500, 05004], lr: 0.029641, loss: 1.0570
2022-07-13 07:28:08 - train: epoch 0077, iter [00600, 05004], lr: 0.029594, loss: 1.0393
2022-07-13 07:29:01 - train: epoch 0077, iter [00700, 05004], lr: 0.029547, loss: 1.1052
2022-07-13 07:29:54 - train: epoch 0077, iter [00800, 05004], lr: 0.029500, loss: 1.1002
2022-07-13 07:30:47 - train: epoch 0077, iter [00900, 05004], lr: 0.029454, loss: 1.4087
2022-07-13 07:31:40 - train: epoch 0077, iter [01000, 05004], lr: 0.029407, loss: 1.0819
2022-07-13 07:32:34 - train: epoch 0077, iter [01100, 05004], lr: 0.029360, loss: 1.3267
2022-07-13 07:33:28 - train: epoch 0077, iter [01200, 05004], lr: 0.029313, loss: 1.3210
2022-07-13 07:34:23 - train: epoch 0077, iter [01300, 05004], lr: 0.029266, loss: 1.0154
2022-07-13 07:35:17 - train: epoch 0077, iter [01400, 05004], lr: 0.029220, loss: 1.2457
2022-07-13 07:36:10 - train: epoch 0077, iter [01500, 05004], lr: 0.029173, loss: 1.1946
2022-07-13 07:37:03 - train: epoch 0077, iter [01600, 05004], lr: 0.029126, loss: 1.1004
2022-07-13 07:37:56 - train: epoch 0077, iter [01700, 05004], lr: 0.029080, loss: 1.2189
2022-07-13 07:38:50 - train: epoch 0077, iter [01800, 05004], lr: 0.029033, loss: 1.1040
2022-07-13 07:39:43 - train: epoch 0077, iter [01900, 05004], lr: 0.028987, loss: 1.1006
2022-07-13 07:40:35 - train: epoch 0077, iter [02000, 05004], lr: 0.028940, loss: 1.1646
2022-07-13 07:41:29 - train: epoch 0077, iter [02100, 05004], lr: 0.028894, loss: 1.3743
2022-07-13 07:42:24 - train: epoch 0077, iter [02200, 05004], lr: 0.028847, loss: 1.1783
2022-07-13 07:43:17 - train: epoch 0077, iter [02300, 05004], lr: 0.028801, loss: 1.2960
2022-07-13 07:44:11 - train: epoch 0077, iter [02400, 05004], lr: 0.028754, loss: 1.0902
2022-07-13 07:45:05 - train: epoch 0077, iter [02500, 05004], lr: 0.028708, loss: 1.2199
2022-07-13 07:45:59 - train: epoch 0077, iter [02600, 05004], lr: 0.028662, loss: 1.0787
2022-07-13 07:46:53 - train: epoch 0077, iter [02700, 05004], lr: 0.028615, loss: 1.2059
2022-07-13 07:47:47 - train: epoch 0077, iter [02800, 05004], lr: 0.028569, loss: 1.2115
2022-07-13 07:48:41 - train: epoch 0077, iter [02900, 05004], lr: 0.028523, loss: 1.2362
2022-07-13 07:49:35 - train: epoch 0077, iter [03000, 05004], lr: 0.028477, loss: 1.2585
2022-07-13 07:50:29 - train: epoch 0077, iter [03100, 05004], lr: 0.028431, loss: 1.2157
2022-07-13 07:51:22 - train: epoch 0077, iter [03200, 05004], lr: 0.028384, loss: 1.3281
2022-07-13 07:52:16 - train: epoch 0077, iter [03300, 05004], lr: 0.028338, loss: 1.1925
2022-07-13 07:53:11 - train: epoch 0077, iter [03400, 05004], lr: 0.028292, loss: 1.1699
2022-07-13 07:54:04 - train: epoch 0077, iter [03500, 05004], lr: 0.028246, loss: 1.2427
2022-07-13 07:54:58 - train: epoch 0077, iter [03600, 05004], lr: 0.028200, loss: 1.0460
2022-07-13 07:55:53 - train: epoch 0077, iter [03700, 05004], lr: 0.028154, loss: 0.9597
2022-07-13 07:56:47 - train: epoch 0077, iter [03800, 05004], lr: 0.028108, loss: 1.1958
2022-07-13 07:57:42 - train: epoch 0077, iter [03900, 05004], lr: 0.028062, loss: 1.1036
2022-07-13 07:58:37 - train: epoch 0077, iter [04000, 05004], lr: 0.028016, loss: 1.3004
2022-07-13 07:59:32 - train: epoch 0077, iter [04100, 05004], lr: 0.027971, loss: 1.1375
2022-07-13 08:00:27 - train: epoch 0077, iter [04200, 05004], lr: 0.027925, loss: 1.3459
2022-07-13 08:01:21 - train: epoch 0077, iter [04300, 05004], lr: 0.027879, loss: 1.3337
2022-07-13 08:02:15 - train: epoch 0077, iter [04400, 05004], lr: 0.027833, loss: 1.2898
2022-07-13 08:03:09 - train: epoch 0077, iter [04500, 05004], lr: 0.027787, loss: 1.2958
2022-07-13 08:04:03 - train: epoch 0077, iter [04600, 05004], lr: 0.027742, loss: 1.2017
2022-07-13 08:04:57 - train: epoch 0077, iter [04700, 05004], lr: 0.027696, loss: 1.0904
2022-07-13 08:05:51 - train: epoch 0077, iter [04800, 05004], lr: 0.027650, loss: 1.2888
2022-07-13 08:06:45 - train: epoch 0077, iter [04900, 05004], lr: 0.027605, loss: 1.4570
2022-07-13 08:07:37 - train: epoch 0077, iter [05000, 05004], lr: 0.027559, loss: 1.3292
2022-07-13 08:07:40 - train: epoch 077, train_loss: 1.2182
2022-07-13 08:09:52 - eval: epoch: 077, acc1: 72.214%, acc5: 91.056%, test_loss: 1.1207, per_image_load_time: 4.137ms, per_image_inference_time: 0.851ms
2022-07-13 08:09:52 - until epoch: 077, best_acc1: 72.214%
2022-07-13 08:09:52 - epoch 078 lr: 0.027557
2022-07-13 08:10:57 - train: epoch 0078, iter [00100, 05004], lr: 0.027512, loss: 1.2798
2022-07-13 08:11:50 - train: epoch 0078, iter [00200, 05004], lr: 0.027466, loss: 1.3046
2022-07-13 08:12:42 - train: epoch 0078, iter [00300, 05004], lr: 0.027421, loss: 1.2419
2022-07-13 08:13:35 - train: epoch 0078, iter [00400, 05004], lr: 0.027376, loss: 1.2433
2022-07-13 08:14:28 - train: epoch 0078, iter [00500, 05004], lr: 0.027330, loss: 1.0310
2022-07-13 08:15:20 - train: epoch 0078, iter [00600, 05004], lr: 0.027285, loss: 1.1390
2022-07-13 08:16:12 - train: epoch 0078, iter [00700, 05004], lr: 0.027239, loss: 1.2983
2022-07-13 08:17:05 - train: epoch 0078, iter [00800, 05004], lr: 0.027194, loss: 1.1389
2022-07-13 08:17:58 - train: epoch 0078, iter [00900, 05004], lr: 0.027149, loss: 1.2491
2022-07-13 08:18:51 - train: epoch 0078, iter [01000, 05004], lr: 0.027103, loss: 1.1716
2022-07-13 08:19:44 - train: epoch 0078, iter [01100, 05004], lr: 0.027058, loss: 1.1023
2022-07-13 08:20:37 - train: epoch 0078, iter [01200, 05004], lr: 0.027013, loss: 1.1717
2022-07-13 08:21:30 - train: epoch 0078, iter [01300, 05004], lr: 0.026968, loss: 1.0885
2022-07-13 08:22:23 - train: epoch 0078, iter [01400, 05004], lr: 0.026923, loss: 1.0333
2022-07-13 08:23:17 - train: epoch 0078, iter [01500, 05004], lr: 0.026878, loss: 1.1836
2022-07-13 08:24:11 - train: epoch 0078, iter [01600, 05004], lr: 0.026833, loss: 1.1463
2022-07-13 08:25:04 - train: epoch 0078, iter [01700, 05004], lr: 0.026788, loss: 1.1305
2022-07-13 08:25:59 - train: epoch 0078, iter [01800, 05004], lr: 0.026743, loss: 1.3770
2022-07-13 08:26:53 - train: epoch 0078, iter [01900, 05004], lr: 0.026698, loss: 1.0970
2022-07-13 08:27:47 - train: epoch 0078, iter [02000, 05004], lr: 0.026653, loss: 1.1413
2022-07-13 08:28:40 - train: epoch 0078, iter [02100, 05004], lr: 0.026608, loss: 1.3642
2022-07-13 08:29:36 - train: epoch 0078, iter [02200, 05004], lr: 0.026563, loss: 1.0980
2022-07-13 08:30:31 - train: epoch 0078, iter [02300, 05004], lr: 0.026518, loss: 1.1698
2022-07-13 08:31:26 - train: epoch 0078, iter [02400, 05004], lr: 0.026473, loss: 1.0136
2022-07-13 08:32:20 - train: epoch 0078, iter [02500, 05004], lr: 0.026429, loss: 1.0947
2022-07-13 08:33:16 - train: epoch 0078, iter [02600, 05004], lr: 0.026384, loss: 1.2990
2022-07-13 08:34:11 - train: epoch 0078, iter [02700, 05004], lr: 0.026339, loss: 1.3121
2022-07-13 08:35:05 - train: epoch 0078, iter [02800, 05004], lr: 0.026294, loss: 1.3565
2022-07-13 08:35:59 - train: epoch 0078, iter [02900, 05004], lr: 0.026250, loss: 1.2920
2022-07-13 08:36:54 - train: epoch 0078, iter [03000, 05004], lr: 0.026205, loss: 1.2461
2022-07-13 08:37:48 - train: epoch 0078, iter [03100, 05004], lr: 0.026161, loss: 1.2068
2022-07-13 08:38:42 - train: epoch 0078, iter [03200, 05004], lr: 0.026116, loss: 1.3600
2022-07-13 08:39:36 - train: epoch 0078, iter [03300, 05004], lr: 0.026071, loss: 1.2719
2022-07-13 08:40:31 - train: epoch 0078, iter [03400, 05004], lr: 0.026027, loss: 1.0745
2022-07-13 08:41:25 - train: epoch 0078, iter [03500, 05004], lr: 0.025983, loss: 1.2353
2022-07-13 08:42:19 - train: epoch 0078, iter [03600, 05004], lr: 0.025938, loss: 1.3087
2022-07-13 08:43:13 - train: epoch 0078, iter [03700, 05004], lr: 0.025894, loss: 1.1088
2022-07-13 08:44:07 - train: epoch 0078, iter [03800, 05004], lr: 0.025849, loss: 1.1906
2022-07-13 08:45:01 - train: epoch 0078, iter [03900, 05004], lr: 0.025805, loss: 1.2428
2022-07-13 08:45:55 - train: epoch 0078, iter [04000, 05004], lr: 0.025761, loss: 1.1943
2022-07-13 08:46:50 - train: epoch 0078, iter [04100, 05004], lr: 0.025716, loss: 1.1575
2022-07-13 08:47:45 - train: epoch 0078, iter [04200, 05004], lr: 0.025672, loss: 1.1507
2022-07-13 08:48:39 - train: epoch 0078, iter [04300, 05004], lr: 0.025628, loss: 1.2805
2022-07-13 08:49:35 - train: epoch 0078, iter [04400, 05004], lr: 0.025584, loss: 1.1421
2022-07-13 08:50:29 - train: epoch 0078, iter [04500, 05004], lr: 0.025540, loss: 1.3050
2022-07-13 08:51:23 - train: epoch 0078, iter [04600, 05004], lr: 0.025496, loss: 0.9708
2022-07-13 08:52:17 - train: epoch 0078, iter [04700, 05004], lr: 0.025452, loss: 1.1786
2022-07-13 08:53:11 - train: epoch 0078, iter [04800, 05004], lr: 0.025408, loss: 1.4785
2022-07-13 08:54:05 - train: epoch 0078, iter [04900, 05004], lr: 0.025364, loss: 1.1957
2022-07-13 08:54:58 - train: epoch 0078, iter [05000, 05004], lr: 0.025320, loss: 1.3072
2022-07-13 08:55:00 - train: epoch 078, train_loss: 1.1968
2022-07-13 08:57:11 - eval: epoch: 078, acc1: 72.390%, acc5: 91.000%, test_loss: 1.1169, per_image_load_time: 4.165ms, per_image_inference_time: 0.905ms
2022-07-13 08:57:11 - until epoch: 078, best_acc1: 72.390%
2022-07-13 08:57:11 - epoch 079 lr: 0.025317
2022-07-13 08:58:18 - train: epoch 0079, iter [00100, 05004], lr: 0.025274, loss: 1.1819
2022-07-13 08:59:11 - train: epoch 0079, iter [00200, 05004], lr: 0.025230, loss: 1.1894
2022-07-13 09:00:04 - train: epoch 0079, iter [00300, 05004], lr: 0.025186, loss: 0.9844
2022-07-13 09:00:58 - train: epoch 0079, iter [00400, 05004], lr: 0.025142, loss: 1.2787
2022-07-13 09:01:52 - train: epoch 0079, iter [00500, 05004], lr: 0.025099, loss: 1.3696
2022-07-13 09:02:46 - train: epoch 0079, iter [00600, 05004], lr: 0.025055, loss: 1.0202
2022-07-13 09:03:39 - train: epoch 0079, iter [00700, 05004], lr: 0.025011, loss: 1.2046
2022-07-13 09:04:32 - train: epoch 0079, iter [00800, 05004], lr: 0.024967, loss: 1.1770
2022-07-13 09:05:25 - train: epoch 0079, iter [00900, 05004], lr: 0.024924, loss: 1.2220
2022-07-13 09:06:18 - train: epoch 0079, iter [01000, 05004], lr: 0.024880, loss: 1.1936
2022-07-13 09:07:11 - train: epoch 0079, iter [01100, 05004], lr: 0.024836, loss: 1.1921
2022-07-13 09:08:05 - train: epoch 0079, iter [01200, 05004], lr: 0.024793, loss: 1.1970
2022-07-13 09:08:58 - train: epoch 0079, iter [01300, 05004], lr: 0.024749, loss: 0.9347
2022-07-13 09:09:51 - train: epoch 0079, iter [01400, 05004], lr: 0.024706, loss: 1.2404
2022-07-13 09:10:45 - train: epoch 0079, iter [01500, 05004], lr: 0.024662, loss: 1.1743
2022-07-13 09:11:39 - train: epoch 0079, iter [01600, 05004], lr: 0.024619, loss: 1.0797
2022-07-13 09:12:33 - train: epoch 0079, iter [01700, 05004], lr: 0.024575, loss: 1.1850
2022-07-13 09:13:27 - train: epoch 0079, iter [01800, 05004], lr: 0.024532, loss: 1.1521
2022-07-13 09:14:21 - train: epoch 0079, iter [01900, 05004], lr: 0.024489, loss: 1.0167
2022-07-13 09:15:15 - train: epoch 0079, iter [02000, 05004], lr: 0.024445, loss: 1.3952
2022-07-13 09:16:08 - train: epoch 0079, iter [02100, 05004], lr: 0.024402, loss: 0.9390
2022-07-13 09:17:02 - train: epoch 0079, iter [02200, 05004], lr: 0.024359, loss: 1.2421
2022-07-13 09:17:55 - train: epoch 0079, iter [02300, 05004], lr: 0.024316, loss: 1.1171
2022-07-13 09:18:49 - train: epoch 0079, iter [02400, 05004], lr: 0.024273, loss: 1.0673
2022-07-13 09:19:44 - train: epoch 0079, iter [02500, 05004], lr: 0.024229, loss: 1.2330
2022-07-13 09:20:37 - train: epoch 0079, iter [02600, 05004], lr: 0.024186, loss: 1.0755
2022-07-13 09:21:31 - train: epoch 0079, iter [02700, 05004], lr: 0.024143, loss: 1.1221
2022-07-13 09:22:24 - train: epoch 0079, iter [02800, 05004], lr: 0.024100, loss: 1.1132
2022-07-13 09:23:17 - train: epoch 0079, iter [02900, 05004], lr: 0.024057, loss: 1.1295
2022-07-13 09:24:11 - train: epoch 0079, iter [03000, 05004], lr: 0.024014, loss: 1.1946
2022-07-13 09:25:05 - train: epoch 0079, iter [03100, 05004], lr: 0.023971, loss: 1.0011
2022-07-13 09:25:59 - train: epoch 0079, iter [03200, 05004], lr: 0.023928, loss: 1.2766
2022-07-13 09:26:53 - train: epoch 0079, iter [03300, 05004], lr: 0.023885, loss: 1.1574
2022-07-13 09:27:46 - train: epoch 0079, iter [03400, 05004], lr: 0.023843, loss: 1.0823
2022-07-13 09:28:40 - train: epoch 0079, iter [03500, 05004], lr: 0.023800, loss: 1.2893
2022-07-13 09:29:34 - train: epoch 0079, iter [03600, 05004], lr: 0.023757, loss: 1.0387
2022-07-13 09:30:27 - train: epoch 0079, iter [03700, 05004], lr: 0.023714, loss: 1.1361
2022-07-13 09:31:20 - train: epoch 0079, iter [03800, 05004], lr: 0.023672, loss: 1.0766
2022-07-13 09:32:14 - train: epoch 0079, iter [03900, 05004], lr: 0.023629, loss: 1.1620
2022-07-13 09:33:07 - train: epoch 0079, iter [04000, 05004], lr: 0.023586, loss: 1.1938
2022-07-13 09:34:01 - train: epoch 0079, iter [04100, 05004], lr: 0.023544, loss: 1.3285
2022-07-13 09:34:54 - train: epoch 0079, iter [04200, 05004], lr: 0.023501, loss: 1.0565
2022-07-13 09:35:47 - train: epoch 0079, iter [04300, 05004], lr: 0.023458, loss: 1.0096
2022-07-13 09:36:40 - train: epoch 0079, iter [04400, 05004], lr: 0.023416, loss: 1.3425
2022-07-13 09:37:33 - train: epoch 0079, iter [04500, 05004], lr: 0.023373, loss: 1.2459
2022-07-13 09:38:28 - train: epoch 0079, iter [04600, 05004], lr: 0.023331, loss: 1.2257
2022-07-13 09:39:23 - train: epoch 0079, iter [04700, 05004], lr: 0.023289, loss: 1.0758
2022-07-13 09:40:18 - train: epoch 0079, iter [04800, 05004], lr: 0.023246, loss: 1.2939
2022-07-13 09:41:11 - train: epoch 0079, iter [04900, 05004], lr: 0.023204, loss: 1.2325
2022-07-13 09:42:04 - train: epoch 0079, iter [05000, 05004], lr: 0.023162, loss: 1.0750
2022-07-13 09:42:06 - train: epoch 079, train_loss: 1.1720
2022-07-13 09:44:19 - eval: epoch: 079, acc1: 72.854%, acc5: 91.400%, test_loss: 1.1058, per_image_load_time: 3.855ms, per_image_inference_time: 0.867ms
2022-07-13 09:44:19 - until epoch: 079, best_acc1: 72.854%
2022-07-13 09:44:19 - epoch 080 lr: 0.023159
2022-07-13 09:45:26 - train: epoch 0080, iter [00100, 05004], lr: 0.023118, loss: 1.0550
2022-07-13 09:46:19 - train: epoch 0080, iter [00200, 05004], lr: 0.023075, loss: 1.2896
2022-07-13 09:47:11 - train: epoch 0080, iter [00300, 05004], lr: 0.023033, loss: 1.1356
2022-07-13 09:48:03 - train: epoch 0080, iter [00400, 05004], lr: 0.022991, loss: 1.0167
2022-07-13 09:48:56 - train: epoch 0080, iter [00500, 05004], lr: 0.022949, loss: 0.8513
2022-07-13 09:49:47 - train: epoch 0080, iter [00600, 05004], lr: 0.022907, loss: 1.0829
2022-07-13 09:50:40 - train: epoch 0080, iter [00700, 05004], lr: 0.022865, loss: 1.1098
2022-07-13 09:51:33 - train: epoch 0080, iter [00800, 05004], lr: 0.022823, loss: 0.9537
2022-07-13 09:52:26 - train: epoch 0080, iter [00900, 05004], lr: 0.022781, loss: 1.2948
2022-07-13 09:53:19 - train: epoch 0080, iter [01000, 05004], lr: 0.022739, loss: 1.1360
2022-07-13 09:54:12 - train: epoch 0080, iter [01100, 05004], lr: 0.022697, loss: 1.2454
2022-07-13 09:55:05 - train: epoch 0080, iter [01200, 05004], lr: 0.022655, loss: 1.2534
2022-07-13 09:55:58 - train: epoch 0080, iter [01300, 05004], lr: 0.022613, loss: 1.0721
2022-07-13 09:56:52 - train: epoch 0080, iter [01400, 05004], lr: 0.022571, loss: 1.1535
2022-07-13 09:57:47 - train: epoch 0080, iter [01500, 05004], lr: 0.022529, loss: 1.1602
2022-07-13 09:58:40 - train: epoch 0080, iter [01600, 05004], lr: 0.022488, loss: 1.3714
2022-07-13 09:59:34 - train: epoch 0080, iter [01700, 05004], lr: 0.022446, loss: 1.3252
2022-07-13 10:00:28 - train: epoch 0080, iter [01800, 05004], lr: 0.022404, loss: 1.1670
2022-07-13 10:01:22 - train: epoch 0080, iter [01900, 05004], lr: 0.022362, loss: 1.0906
2022-07-13 10:02:16 - train: epoch 0080, iter [02000, 05004], lr: 0.022321, loss: 1.1543
2022-07-13 10:03:09 - train: epoch 0080, iter [02100, 05004], lr: 0.022279, loss: 1.4987
2022-07-13 10:04:02 - train: epoch 0080, iter [02200, 05004], lr: 0.022238, loss: 1.1746
2022-07-13 10:04:56 - train: epoch 0080, iter [02300, 05004], lr: 0.022196, loss: 1.1183
2022-07-13 10:05:50 - train: epoch 0080, iter [02400, 05004], lr: 0.022155, loss: 1.1634
2022-07-13 10:06:44 - train: epoch 0080, iter [02500, 05004], lr: 0.022113, loss: 1.0186
2022-07-13 10:07:38 - train: epoch 0080, iter [02600, 05004], lr: 0.022072, loss: 1.3548
2022-07-13 10:08:32 - train: epoch 0080, iter [02700, 05004], lr: 0.022030, loss: 1.1990
2022-07-13 10:09:26 - train: epoch 0080, iter [02800, 05004], lr: 0.021989, loss: 0.9553
2022-07-13 10:10:20 - train: epoch 0080, iter [02900, 05004], lr: 0.021948, loss: 1.0426
2022-07-13 10:11:14 - train: epoch 0080, iter [03000, 05004], lr: 0.021906, loss: 1.0225
2022-07-13 10:12:09 - train: epoch 0080, iter [03100, 05004], lr: 0.021865, loss: 1.1348
2022-07-13 10:13:02 - train: epoch 0080, iter [03200, 05004], lr: 0.021824, loss: 1.0403
2022-07-13 10:13:56 - train: epoch 0080, iter [03300, 05004], lr: 0.021783, loss: 1.2118
2022-07-13 10:14:50 - train: epoch 0080, iter [03400, 05004], lr: 0.021741, loss: 1.0526
2022-07-13 10:15:44 - train: epoch 0080, iter [03500, 05004], lr: 0.021700, loss: 1.1774
2022-07-13 10:16:38 - train: epoch 0080, iter [03600, 05004], lr: 0.021659, loss: 1.1140
2022-07-13 10:17:32 - train: epoch 0080, iter [03700, 05004], lr: 0.021618, loss: 0.8597
2022-07-13 10:18:25 - train: epoch 0080, iter [03800, 05004], lr: 0.021577, loss: 1.2484
2022-07-13 10:19:19 - train: epoch 0080, iter [03900, 05004], lr: 0.021536, loss: 1.1381
2022-07-13 10:20:13 - train: epoch 0080, iter [04000, 05004], lr: 0.021495, loss: 1.2004
2022-07-13 10:21:07 - train: epoch 0080, iter [04100, 05004], lr: 0.021454, loss: 1.2816
2022-07-13 10:22:01 - train: epoch 0080, iter [04200, 05004], lr: 0.021413, loss: 1.1851
2022-07-13 10:22:55 - train: epoch 0080, iter [04300, 05004], lr: 0.021373, loss: 1.3367
2022-07-13 10:23:49 - train: epoch 0080, iter [04400, 05004], lr: 0.021332, loss: 1.1710
2022-07-13 10:24:43 - train: epoch 0080, iter [04500, 05004], lr: 0.021291, loss: 1.3292
2022-07-13 10:25:36 - train: epoch 0080, iter [04600, 05004], lr: 0.021250, loss: 1.2141
2022-07-13 10:26:29 - train: epoch 0080, iter [04700, 05004], lr: 0.021210, loss: 1.1591
2022-07-13 10:27:22 - train: epoch 0080, iter [04800, 05004], lr: 0.021169, loss: 1.2968
2022-07-13 10:28:16 - train: epoch 0080, iter [04900, 05004], lr: 0.021128, loss: 1.2900
2022-07-13 10:29:10 - train: epoch 0080, iter [05000, 05004], lr: 0.021088, loss: 1.0448
2022-07-13 10:29:12 - train: epoch 080, train_loss: 1.1495
2022-07-13 10:31:22 - eval: epoch: 080, acc1: 72.914%, acc5: 91.358%, test_loss: 1.0997, per_image_load_time: 3.161ms, per_image_inference_time: 0.905ms
2022-07-13 10:31:22 - until epoch: 080, best_acc1: 72.914%
2022-07-13 10:31:22 - epoch 081 lr: 0.021086
2022-07-13 10:32:29 - train: epoch 0081, iter [00100, 05004], lr: 0.021045, loss: 1.1220
2022-07-13 10:33:23 - train: epoch 0081, iter [00200, 05004], lr: 0.021005, loss: 0.8926
2022-07-13 10:34:16 - train: epoch 0081, iter [00300, 05004], lr: 0.020964, loss: 1.0999
2022-07-13 10:35:10 - train: epoch 0081, iter [00400, 05004], lr: 0.020924, loss: 1.0063
2022-07-13 10:36:03 - train: epoch 0081, iter [00500, 05004], lr: 0.020883, loss: 1.1345
2022-07-13 10:36:57 - train: epoch 0081, iter [00600, 05004], lr: 0.020843, loss: 1.0088
2022-07-13 10:37:51 - train: epoch 0081, iter [00700, 05004], lr: 0.020803, loss: 1.0700
2022-07-13 10:38:45 - train: epoch 0081, iter [00800, 05004], lr: 0.020762, loss: 1.0072
2022-07-13 10:39:39 - train: epoch 0081, iter [00900, 05004], lr: 0.020722, loss: 1.2105
2022-07-13 10:40:33 - train: epoch 0081, iter [01000, 05004], lr: 0.020682, loss: 1.1827
2022-07-13 10:41:26 - train: epoch 0081, iter [01100, 05004], lr: 0.020642, loss: 1.0474
2022-07-13 10:42:21 - train: epoch 0081, iter [01200, 05004], lr: 0.020601, loss: 1.1869
2022-07-13 10:43:16 - train: epoch 0081, iter [01300, 05004], lr: 0.020561, loss: 0.9992
2022-07-13 10:44:10 - train: epoch 0081, iter [01400, 05004], lr: 0.020521, loss: 0.9265
2022-07-13 10:45:04 - train: epoch 0081, iter [01500, 05004], lr: 0.020481, loss: 1.2255
2022-07-13 10:45:58 - train: epoch 0081, iter [01600, 05004], lr: 0.020441, loss: 1.0210
2022-07-13 10:46:53 - train: epoch 0081, iter [01700, 05004], lr: 0.020401, loss: 1.0510
2022-07-13 10:47:48 - train: epoch 0081, iter [01800, 05004], lr: 0.020361, loss: 1.1151
2022-07-13 10:48:43 - train: epoch 0081, iter [01900, 05004], lr: 0.020321, loss: 1.2768
2022-07-13 10:49:37 - train: epoch 0081, iter [02000, 05004], lr: 0.020281, loss: 1.2280
2022-07-13 10:50:30 - train: epoch 0081, iter [02100, 05004], lr: 0.020241, loss: 1.1522
2022-07-13 10:51:24 - train: epoch 0081, iter [02200, 05004], lr: 0.020201, loss: 1.1495
2022-07-13 10:52:18 - train: epoch 0081, iter [02300, 05004], lr: 0.020162, loss: 0.9481
2022-07-13 10:53:12 - train: epoch 0081, iter [02400, 05004], lr: 0.020122, loss: 1.0898
2022-07-13 10:54:06 - train: epoch 0081, iter [02500, 05004], lr: 0.020082, loss: 1.3881
2022-07-13 10:55:01 - train: epoch 0081, iter [02600, 05004], lr: 0.020042, loss: 1.2047
2022-07-13 10:55:55 - train: epoch 0081, iter [02700, 05004], lr: 0.020003, loss: 1.1485
2022-07-13 10:56:48 - train: epoch 0081, iter [02800, 05004], lr: 0.019963, loss: 1.1153
2022-07-13 10:57:42 - train: epoch 0081, iter [02900, 05004], lr: 0.019923, loss: 1.1449
2022-07-13 10:58:37 - train: epoch 0081, iter [03000, 05004], lr: 0.019884, loss: 1.1422
2022-07-13 10:59:31 - train: epoch 0081, iter [03100, 05004], lr: 0.019844, loss: 1.1042
2022-07-13 11:00:25 - train: epoch 0081, iter [03200, 05004], lr: 0.019805, loss: 1.0580
2022-07-13 11:01:19 - train: epoch 0081, iter [03300, 05004], lr: 0.019765, loss: 1.2688
2022-07-13 11:02:13 - train: epoch 0081, iter [03400, 05004], lr: 0.019726, loss: 1.0524
2022-07-13 11:03:07 - train: epoch 0081, iter [03500, 05004], lr: 0.019687, loss: 1.3440
2022-07-13 11:04:01 - train: epoch 0081, iter [03600, 05004], lr: 0.019647, loss: 1.0699
2022-07-13 11:04:56 - train: epoch 0081, iter [03700, 05004], lr: 0.019608, loss: 1.1871
2022-07-13 11:05:50 - train: epoch 0081, iter [03800, 05004], lr: 0.019569, loss: 1.1689
2022-07-13 11:06:43 - train: epoch 0081, iter [03900, 05004], lr: 0.019529, loss: 1.2809
2022-07-13 11:07:37 - train: epoch 0081, iter [04000, 05004], lr: 0.019490, loss: 0.9015
2022-07-13 11:08:31 - train: epoch 0081, iter [04100, 05004], lr: 0.019451, loss: 1.0399
2022-07-13 11:09:25 - train: epoch 0081, iter [04200, 05004], lr: 0.019412, loss: 1.0143
2022-07-13 11:10:19 - train: epoch 0081, iter [04300, 05004], lr: 0.019373, loss: 1.2117
2022-07-13 11:11:12 - train: epoch 0081, iter [04400, 05004], lr: 0.019334, loss: 1.1762
2022-07-13 11:12:05 - train: epoch 0081, iter [04500, 05004], lr: 0.019295, loss: 1.2964
2022-07-13 11:12:58 - train: epoch 0081, iter [04600, 05004], lr: 0.019256, loss: 1.1092
2022-07-13 11:13:52 - train: epoch 0081, iter [04700, 05004], lr: 0.019217, loss: 1.1949
2022-07-13 11:14:46 - train: epoch 0081, iter [04800, 05004], lr: 0.019178, loss: 1.1455
2022-07-13 11:15:40 - train: epoch 0081, iter [04900, 05004], lr: 0.019139, loss: 1.0218
2022-07-13 11:16:33 - train: epoch 0081, iter [05000, 05004], lr: 0.019100, loss: 0.8956
2022-07-13 11:16:35 - train: epoch 081, train_loss: 1.1239
2022-07-13 11:18:47 - eval: epoch: 081, acc1: 73.386%, acc5: 91.528%, test_loss: 1.0856, per_image_load_time: 2.926ms, per_image_inference_time: 0.893ms
2022-07-13 11:18:47 - until epoch: 081, best_acc1: 73.386%
2022-07-13 11:18:47 - epoch 082 lr: 0.019098
2022-07-13 11:19:57 - train: epoch 0082, iter [00100, 05004], lr: 0.019059, loss: 0.9210
2022-07-13 11:20:50 - train: epoch 0082, iter [00200, 05004], lr: 0.019021, loss: 1.0689
2022-07-13 11:21:43 - train: epoch 0082, iter [00300, 05004], lr: 0.018982, loss: 1.1223
2022-07-13 11:22:36 - train: epoch 0082, iter [00400, 05004], lr: 0.018943, loss: 1.2333
2022-07-13 11:23:27 - train: epoch 0082, iter [00500, 05004], lr: 0.018905, loss: 1.1898
2022-07-13 11:24:21 - train: epoch 0082, iter [00600, 05004], lr: 0.018866, loss: 0.9198
2022-07-13 11:25:14 - train: epoch 0082, iter [00700, 05004], lr: 0.018827, loss: 1.2672
2022-07-13 11:26:08 - train: epoch 0082, iter [00800, 05004], lr: 0.018789, loss: 1.1522
2022-07-13 11:27:01 - train: epoch 0082, iter [00900, 05004], lr: 0.018750, loss: 1.3346
2022-07-13 11:27:54 - train: epoch 0082, iter [01000, 05004], lr: 0.018712, loss: 0.9972
2022-07-13 11:28:48 - train: epoch 0082, iter [01100, 05004], lr: 0.018673, loss: 1.2719
2022-07-13 11:29:42 - train: epoch 0082, iter [01200, 05004], lr: 0.018635, loss: 1.0298
2022-07-13 11:30:37 - train: epoch 0082, iter [01300, 05004], lr: 0.018596, loss: 1.1988
2022-07-13 11:31:30 - train: epoch 0082, iter [01400, 05004], lr: 0.018558, loss: 1.0230
2022-07-13 11:32:25 - train: epoch 0082, iter [01500, 05004], lr: 0.018520, loss: 1.0855
2022-07-13 11:33:19 - train: epoch 0082, iter [01600, 05004], lr: 0.018481, loss: 1.0746
2022-07-13 11:34:12 - train: epoch 0082, iter [01700, 05004], lr: 0.018443, loss: 1.0126
2022-07-13 11:35:06 - train: epoch 0082, iter [01800, 05004], lr: 0.018405, loss: 1.1767
2022-07-13 11:36:00 - train: epoch 0082, iter [01900, 05004], lr: 0.018367, loss: 0.9992
2022-07-13 11:36:55 - train: epoch 0082, iter [02000, 05004], lr: 0.018329, loss: 1.0752
2022-07-13 11:37:49 - train: epoch 0082, iter [02100, 05004], lr: 0.018290, loss: 1.1308
2022-07-13 11:38:44 - train: epoch 0082, iter [02200, 05004], lr: 0.018252, loss: 1.1458
2022-07-13 11:39:37 - train: epoch 0082, iter [02300, 05004], lr: 0.018214, loss: 1.0990
2022-07-13 11:40:31 - train: epoch 0082, iter [02400, 05004], lr: 0.018176, loss: 1.2246
2022-07-13 11:41:24 - train: epoch 0082, iter [02500, 05004], lr: 0.018138, loss: 1.0065
2022-07-13 11:42:18 - train: epoch 0082, iter [02600, 05004], lr: 0.018100, loss: 1.1612
2022-07-13 11:43:12 - train: epoch 0082, iter [02700, 05004], lr: 0.018062, loss: 0.9956
2022-07-13 11:44:06 - train: epoch 0082, iter [02800, 05004], lr: 0.018025, loss: 0.9891
2022-07-13 11:45:01 - train: epoch 0082, iter [02900, 05004], lr: 0.017987, loss: 0.8982
2022-07-13 11:45:55 - train: epoch 0082, iter [03000, 05004], lr: 0.017949, loss: 1.0692
2022-07-13 11:46:49 - train: epoch 0082, iter [03100, 05004], lr: 0.017911, loss: 0.9154
2022-07-13 11:47:44 - train: epoch 0082, iter [03200, 05004], lr: 0.017873, loss: 1.2536
2022-07-13 11:48:39 - train: epoch 0082, iter [03300, 05004], lr: 0.017836, loss: 1.0381
2022-07-13 11:49:33 - train: epoch 0082, iter [03400, 05004], lr: 0.017798, loss: 0.9534
2022-07-13 11:50:27 - train: epoch 0082, iter [03500, 05004], lr: 0.017761, loss: 1.0761
2022-07-13 11:51:20 - train: epoch 0082, iter [03600, 05004], lr: 0.017723, loss: 1.1285
2022-07-13 11:52:13 - train: epoch 0082, iter [03700, 05004], lr: 0.017685, loss: 0.8365
2022-07-13 11:53:06 - train: epoch 0082, iter [03800, 05004], lr: 0.017648, loss: 1.1970
2022-07-13 11:53:59 - train: epoch 0082, iter [03900, 05004], lr: 0.017610, loss: 1.0409
2022-07-13 11:54:52 - train: epoch 0082, iter [04000, 05004], lr: 0.017573, loss: 1.0843
2022-07-13 11:55:45 - train: epoch 0082, iter [04100, 05004], lr: 0.017536, loss: 1.1056
2022-07-13 11:56:39 - train: epoch 0082, iter [04200, 05004], lr: 0.017498, loss: 1.0054
2022-07-13 11:57:33 - train: epoch 0082, iter [04300, 05004], lr: 0.017461, loss: 1.0850
2022-07-13 11:58:27 - train: epoch 0082, iter [04400, 05004], lr: 0.017424, loss: 0.9739
2022-07-13 11:59:21 - train: epoch 0082, iter [04500, 05004], lr: 0.017386, loss: 1.0331
2022-07-13 12:00:15 - train: epoch 0082, iter [04600, 05004], lr: 0.017349, loss: 1.0253
2022-07-13 12:01:08 - train: epoch 0082, iter [04700, 05004], lr: 0.017312, loss: 1.0505
2022-07-13 12:02:01 - train: epoch 0082, iter [04800, 05004], lr: 0.017275, loss: 1.0108
2022-07-13 12:02:54 - train: epoch 0082, iter [04900, 05004], lr: 0.017238, loss: 1.1346
2022-07-13 12:03:47 - train: epoch 0082, iter [05000, 05004], lr: 0.017201, loss: 1.1280
2022-07-13 12:03:49 - train: epoch 082, train_loss: 1.0988
2022-07-13 12:05:58 - eval: epoch: 082, acc1: 73.594%, acc5: 91.630%, test_loss: 1.0706, per_image_load_time: 1.559ms, per_image_inference_time: 0.859ms
2022-07-13 12:05:59 - until epoch: 082, best_acc1: 73.594%
2022-07-13 12:05:59 - epoch 083 lr: 0.017199
2022-07-13 12:07:06 - train: epoch 0083, iter [00100, 05004], lr: 0.017162, loss: 0.8554
2022-07-13 12:08:00 - train: epoch 0083, iter [00200, 05004], lr: 0.017125, loss: 0.9787
2022-07-13 12:08:54 - train: epoch 0083, iter [00300, 05004], lr: 0.017088, loss: 1.2584
2022-07-13 12:09:47 - train: epoch 0083, iter [00400, 05004], lr: 0.017051, loss: 1.0563
2022-07-13 12:10:44 - train: epoch 0083, iter [00500, 05004], lr: 0.017014, loss: 1.1453
2022-07-13 12:11:38 - train: epoch 0083, iter [00600, 05004], lr: 0.016977, loss: 1.0065
2022-07-13 12:12:32 - train: epoch 0083, iter [00700, 05004], lr: 0.016941, loss: 1.0363
2022-07-13 12:13:29 - train: epoch 0083, iter [00800, 05004], lr: 0.016904, loss: 1.1453
2022-07-13 12:14:28 - train: epoch 0083, iter [00900, 05004], lr: 0.016867, loss: 1.0000
2022-07-13 12:15:29 - train: epoch 0083, iter [01000, 05004], lr: 0.016830, loss: 1.2491
2022-07-13 12:16:28 - train: epoch 0083, iter [01100, 05004], lr: 0.016794, loss: 0.9456
2022-07-13 12:17:26 - train: epoch 0083, iter [01200, 05004], lr: 0.016757, loss: 0.9085
2022-07-13 12:18:24 - train: epoch 0083, iter [01300, 05004], lr: 0.016720, loss: 1.0114
2022-07-13 12:19:24 - train: epoch 0083, iter [01400, 05004], lr: 0.016684, loss: 1.1246
2022-07-13 12:20:23 - train: epoch 0083, iter [01500, 05004], lr: 0.016647, loss: 1.1017
2022-07-13 12:21:20 - train: epoch 0083, iter [01600, 05004], lr: 0.016611, loss: 1.0891
2022-07-13 12:22:20 - train: epoch 0083, iter [01700, 05004], lr: 0.016574, loss: 1.1094
2022-07-13 12:23:21 - train: epoch 0083, iter [01800, 05004], lr: 0.016538, loss: 1.3507
2022-07-13 12:24:20 - train: epoch 0083, iter [01900, 05004], lr: 0.016502, loss: 1.1234
2022-07-13 12:25:18 - train: epoch 0083, iter [02000, 05004], lr: 0.016465, loss: 0.8386
2022-07-13 12:26:18 - train: epoch 0083, iter [02100, 05004], lr: 0.016429, loss: 1.0006
2022-07-13 12:27:19 - train: epoch 0083, iter [02200, 05004], lr: 0.016393, loss: 0.8012
2022-07-13 12:28:18 - train: epoch 0083, iter [02300, 05004], lr: 0.016356, loss: 1.0651
2022-07-13 12:29:17 - train: epoch 0083, iter [02400, 05004], lr: 0.016320, loss: 1.0196
2022-07-13 12:30:15 - train: epoch 0083, iter [02500, 05004], lr: 0.016284, loss: 1.0248
2022-07-13 12:31:17 - train: epoch 0083, iter [02600, 05004], lr: 0.016248, loss: 1.1542
2022-07-13 12:32:16 - train: epoch 0083, iter [02700, 05004], lr: 0.016212, loss: 0.8715
2022-07-13 12:33:14 - train: epoch 0083, iter [02800, 05004], lr: 0.016176, loss: 0.9842
2022-07-13 12:34:12 - train: epoch 0083, iter [02900, 05004], lr: 0.016140, loss: 1.2264
2022-07-13 12:35:13 - train: epoch 0083, iter [03000, 05004], lr: 0.016104, loss: 1.0864
2022-07-13 12:36:11 - train: epoch 0083, iter [03100, 05004], lr: 0.016068, loss: 1.1189
2022-07-13 12:37:08 - train: epoch 0083, iter [03200, 05004], lr: 0.016032, loss: 1.0049
2022-07-13 12:38:04 - train: epoch 0083, iter [03300, 05004], lr: 0.015996, loss: 1.1256
2022-07-13 12:39:02 - train: epoch 0083, iter [03400, 05004], lr: 0.015960, loss: 1.0148
2022-07-13 12:40:01 - train: epoch 0083, iter [03500, 05004], lr: 0.015924, loss: 1.0667
2022-07-13 12:40:57 - train: epoch 0083, iter [03600, 05004], lr: 0.015889, loss: 1.1898
2022-07-13 12:41:54 - train: epoch 0083, iter [03700, 05004], lr: 0.015853, loss: 1.0003
2022-07-13 12:42:52 - train: epoch 0083, iter [03800, 05004], lr: 0.015817, loss: 1.0869
2022-07-13 12:43:50 - train: epoch 0083, iter [03900, 05004], lr: 0.015782, loss: 1.1789
2022-07-13 12:44:48 - train: epoch 0083, iter [04000, 05004], lr: 0.015746, loss: 1.3150
2022-07-13 12:45:43 - train: epoch 0083, iter [04100, 05004], lr: 0.015710, loss: 1.2966
2022-07-13 12:46:39 - train: epoch 0083, iter [04200, 05004], lr: 0.015675, loss: 1.2566
2022-07-13 12:47:37 - train: epoch 0083, iter [04300, 05004], lr: 0.015639, loss: 0.9811
2022-07-13 12:48:38 - train: epoch 0083, iter [04400, 05004], lr: 0.015604, loss: 1.1178
2022-07-13 12:49:34 - train: epoch 0083, iter [04500, 05004], lr: 0.015568, loss: 1.2715
2022-07-13 12:50:30 - train: epoch 0083, iter [04600, 05004], lr: 0.015533, loss: 1.1077
2022-07-13 12:51:26 - train: epoch 0083, iter [04700, 05004], lr: 0.015498, loss: 1.3368
2022-07-13 12:52:27 - train: epoch 0083, iter [04800, 05004], lr: 0.015462, loss: 1.1600
2022-07-13 12:53:23 - train: epoch 0083, iter [04900, 05004], lr: 0.015427, loss: 1.0013
2022-07-13 12:54:16 - train: epoch 0083, iter [05000, 05004], lr: 0.015392, loss: 1.1173
2022-07-13 12:54:18 - train: epoch 083, train_loss: 1.0753
2022-07-13 12:56:27 - eval: epoch: 083, acc1: 74.080%, acc5: 92.020%, test_loss: 1.0524, per_image_load_time: 3.918ms, per_image_inference_time: 0.792ms
2022-07-13 12:56:27 - until epoch: 083, best_acc1: 74.080%
2022-07-13 12:56:27 - epoch 084 lr: 0.015390
2022-07-13 12:57:37 - train: epoch 0084, iter [00100, 05004], lr: 0.015355, loss: 1.0647
2022-07-13 12:58:33 - train: epoch 0084, iter [00200, 05004], lr: 0.015320, loss: 0.9050
2022-07-13 12:59:26 - train: epoch 0084, iter [00300, 05004], lr: 0.015285, loss: 0.8713
2022-07-13 13:00:23 - train: epoch 0084, iter [00400, 05004], lr: 0.015250, loss: 0.8401
2022-07-13 13:01:23 - train: epoch 0084, iter [00500, 05004], lr: 0.015215, loss: 1.0385
2022-07-13 13:02:21 - train: epoch 0084, iter [00600, 05004], lr: 0.015180, loss: 1.0548
2022-07-13 13:03:15 - train: epoch 0084, iter [00700, 05004], lr: 0.015145, loss: 1.0320
2022-07-13 13:04:12 - train: epoch 0084, iter [00800, 05004], lr: 0.015110, loss: 1.1659
2022-07-13 13:05:11 - train: epoch 0084, iter [00900, 05004], lr: 0.015075, loss: 1.0899
2022-07-13 13:06:09 - train: epoch 0084, iter [01000, 05004], lr: 0.015040, loss: 1.0855
2022-07-13 13:07:06 - train: epoch 0084, iter [01100, 05004], lr: 0.015005, loss: 0.8971
2022-07-13 13:08:01 - train: epoch 0084, iter [01200, 05004], lr: 0.014970, loss: 1.2872
2022-07-13 13:08:57 - train: epoch 0084, iter [01300, 05004], lr: 0.014936, loss: 1.1101
2022-07-13 13:09:57 - train: epoch 0084, iter [01400, 05004], lr: 0.014901, loss: 1.1380
2022-07-13 13:10:55 - train: epoch 0084, iter [01500, 05004], lr: 0.014866, loss: 1.1343
2022-07-13 13:11:49 - train: epoch 0084, iter [01600, 05004], lr: 0.014832, loss: 1.0160
2022-07-13 13:12:44 - train: epoch 0084, iter [01700, 05004], lr: 0.014797, loss: 1.1622
2022-07-13 13:13:43 - train: epoch 0084, iter [01800, 05004], lr: 0.014762, loss: 1.1749
2022-07-13 13:14:40 - train: epoch 0084, iter [01900, 05004], lr: 0.014728, loss: 1.0818
2022-07-13 13:15:38 - train: epoch 0084, iter [02000, 05004], lr: 0.014693, loss: 1.1404
2022-07-13 13:16:32 - train: epoch 0084, iter [02100, 05004], lr: 0.014659, loss: 0.9617
2022-07-13 13:17:29 - train: epoch 0084, iter [02200, 05004], lr: 0.014624, loss: 0.8694
2022-07-13 13:18:28 - train: epoch 0084, iter [02300, 05004], lr: 0.014590, loss: 1.1215
2022-07-13 13:19:23 - train: epoch 0084, iter [02400, 05004], lr: 0.014556, loss: 0.9946
2022-07-13 13:20:19 - train: epoch 0084, iter [02500, 05004], lr: 0.014521, loss: 1.1416
2022-07-13 13:21:13 - train: epoch 0084, iter [02600, 05004], lr: 0.014487, loss: 0.9607
2022-07-13 13:22:10 - train: epoch 0084, iter [02700, 05004], lr: 0.014453, loss: 0.9953
2022-07-13 13:23:07 - train: epoch 0084, iter [02800, 05004], lr: 0.014419, loss: 1.0363
2022-07-13 13:24:04 - train: epoch 0084, iter [02900, 05004], lr: 0.014385, loss: 1.1115
2022-07-13 13:25:00 - train: epoch 0084, iter [03000, 05004], lr: 0.014350, loss: 0.9854
2022-07-13 13:25:55 - train: epoch 0084, iter [03100, 05004], lr: 0.014316, loss: 1.0176
2022-07-13 13:26:55 - train: epoch 0084, iter [03200, 05004], lr: 0.014282, loss: 1.1220
2022-07-13 13:27:48 - train: epoch 0084, iter [03300, 05004], lr: 0.014248, loss: 1.1500
2022-07-13 13:28:42 - train: epoch 0084, iter [03400, 05004], lr: 0.014214, loss: 0.9818
2022-07-13 13:29:37 - train: epoch 0084, iter [03500, 05004], lr: 0.014180, loss: 0.9396
2022-07-13 13:30:33 - train: epoch 0084, iter [03600, 05004], lr: 0.014146, loss: 1.1176
2022-07-13 13:31:32 - train: epoch 0084, iter [03700, 05004], lr: 0.014113, loss: 1.1146
2022-07-13 13:32:27 - train: epoch 0084, iter [03800, 05004], lr: 0.014079, loss: 1.0052
2022-07-13 13:33:20 - train: epoch 0084, iter [03900, 05004], lr: 0.014045, loss: 1.0176
2022-07-13 13:34:15 - train: epoch 0084, iter [04000, 05004], lr: 0.014011, loss: 1.0389
2022-07-13 13:35:12 - train: epoch 0084, iter [04100, 05004], lr: 0.013977, loss: 0.9680
2022-07-13 13:36:10 - train: epoch 0084, iter [04200, 05004], lr: 0.013944, loss: 1.1430
2022-07-13 13:37:05 - train: epoch 0084, iter [04300, 05004], lr: 0.013910, loss: 1.1251
2022-07-13 13:37:58 - train: epoch 0084, iter [04400, 05004], lr: 0.013877, loss: 1.1856
2022-07-13 13:38:54 - train: epoch 0084, iter [04500, 05004], lr: 0.013843, loss: 1.1043
2022-07-13 13:39:50 - train: epoch 0084, iter [04600, 05004], lr: 0.013809, loss: 1.0685
2022-07-13 13:40:44 - train: epoch 0084, iter [04700, 05004], lr: 0.013776, loss: 0.9382
2022-07-13 13:41:38 - train: epoch 0084, iter [04800, 05004], lr: 0.013742, loss: 0.9499
2022-07-13 13:42:32 - train: epoch 0084, iter [04900, 05004], lr: 0.013709, loss: 1.1635
2022-07-13 13:43:28 - train: epoch 0084, iter [05000, 05004], lr: 0.013676, loss: 1.1452
2022-07-13 13:43:30 - train: epoch 084, train_loss: 1.0482
2022-07-13 13:45:38 - eval: epoch: 084, acc1: 74.084%, acc5: 92.084%, test_loss: 1.0489, per_image_load_time: 4.111ms, per_image_inference_time: 0.815ms
2022-07-13 13:45:39 - until epoch: 084, best_acc1: 74.084%
2022-07-13 13:45:39 - epoch 085 lr: 0.013674
2022-07-13 13:46:48 - train: epoch 0085, iter [00100, 05004], lr: 0.013641, loss: 0.7672
2022-07-13 13:47:46 - train: epoch 0085, iter [00200, 05004], lr: 0.013608, loss: 0.9126
2022-07-13 13:48:46 - train: epoch 0085, iter [00300, 05004], lr: 0.013574, loss: 1.1284
2022-07-13 13:49:43 - train: epoch 0085, iter [00400, 05004], lr: 0.013541, loss: 0.8992
2022-07-13 13:50:37 - train: epoch 0085, iter [00500, 05004], lr: 0.013508, loss: 1.2573
2022-07-13 13:51:33 - train: epoch 0085, iter [00600, 05004], lr: 0.013475, loss: 0.9090
2022-07-13 13:52:33 - train: epoch 0085, iter [00700, 05004], lr: 0.013442, loss: 0.9576
2022-07-13 13:53:31 - train: epoch 0085, iter [00800, 05004], lr: 0.013409, loss: 0.8232
2022-07-13 13:54:24 - train: epoch 0085, iter [00900, 05004], lr: 0.013376, loss: 1.0179
2022-07-13 13:55:19 - train: epoch 0085, iter [01000, 05004], lr: 0.013343, loss: 1.0878
2022-07-13 13:56:15 - train: epoch 0085, iter [01100, 05004], lr: 0.013310, loss: 1.0413
2022-07-13 13:57:16 - train: epoch 0085, iter [01200, 05004], lr: 0.013277, loss: 0.9432
2022-07-13 13:58:14 - train: epoch 0085, iter [01300, 05004], lr: 0.013244, loss: 1.1939
2022-07-13 13:59:08 - train: epoch 0085, iter [01400, 05004], lr: 0.013211, loss: 0.9771
2022-07-13 14:00:04 - train: epoch 0085, iter [01500, 05004], lr: 0.013178, loss: 1.1079
2022-07-13 14:01:04 - train: epoch 0085, iter [01600, 05004], lr: 0.013145, loss: 0.9873
2022-07-13 14:02:04 - train: epoch 0085, iter [01700, 05004], lr: 0.013113, loss: 1.2636
2022-07-13 14:02:57 - train: epoch 0085, iter [01800, 05004], lr: 0.013080, loss: 0.8566
2022-07-13 14:03:51 - train: epoch 0085, iter [01900, 05004], lr: 0.013047, loss: 1.0943
2022-07-13 14:04:49 - train: epoch 0085, iter [02000, 05004], lr: 0.013015, loss: 0.7879
2022-07-13 14:05:49 - train: epoch 0085, iter [02100, 05004], lr: 0.012982, loss: 0.9587
2022-07-13 14:06:48 - train: epoch 0085, iter [02200, 05004], lr: 0.012950, loss: 1.0204
2022-07-13 14:07:42 - train: epoch 0085, iter [02300, 05004], lr: 0.012917, loss: 1.2059
2022-07-13 14:08:37 - train: epoch 0085, iter [02400, 05004], lr: 0.012885, loss: 1.1748
2022-07-13 14:09:39 - train: epoch 0085, iter [02500, 05004], lr: 0.012852, loss: 1.3201
2022-07-13 14:10:40 - train: epoch 0085, iter [02600, 05004], lr: 0.012820, loss: 1.1295
2022-07-13 14:11:34 - train: epoch 0085, iter [02700, 05004], lr: 0.012787, loss: 0.9073
2022-07-13 14:12:28 - train: epoch 0085, iter [02800, 05004], lr: 0.012755, loss: 1.3125
2022-07-13 14:13:25 - train: epoch 0085, iter [02900, 05004], lr: 0.012723, loss: 1.1087
2022-07-13 14:14:26 - train: epoch 0085, iter [03000, 05004], lr: 0.012691, loss: 1.1912
2022-07-13 14:15:25 - train: epoch 0085, iter [03100, 05004], lr: 0.012658, loss: 1.0024
2022-07-13 14:16:20 - train: epoch 0085, iter [03200, 05004], lr: 0.012626, loss: 1.0445
2022-07-13 14:17:18 - train: epoch 0085, iter [03300, 05004], lr: 0.012594, loss: 1.0771
2022-07-13 14:18:18 - train: epoch 0085, iter [03400, 05004], lr: 0.012562, loss: 1.0707
2022-07-13 14:19:19 - train: epoch 0085, iter [03500, 05004], lr: 0.012530, loss: 1.1768
2022-07-13 14:20:12 - train: epoch 0085, iter [03600, 05004], lr: 0.012498, loss: 1.0787
2022-07-13 14:21:07 - train: epoch 0085, iter [03700, 05004], lr: 0.012466, loss: 1.0024
2022-07-13 14:22:05 - train: epoch 0085, iter [03800, 05004], lr: 0.012434, loss: 1.1385
2022-07-13 14:23:06 - train: epoch 0085, iter [03900, 05004], lr: 0.012402, loss: 0.9990
2022-07-13 14:24:05 - train: epoch 0085, iter [04000, 05004], lr: 0.012370, loss: 1.1229
2022-07-13 14:24:58 - train: epoch 0085, iter [04100, 05004], lr: 0.012339, loss: 1.0578
2022-07-13 14:25:56 - train: epoch 0085, iter [04200, 05004], lr: 0.012307, loss: 1.0797
2022-07-13 14:26:55 - train: epoch 0085, iter [04300, 05004], lr: 0.012275, loss: 0.9483
2022-07-13 14:27:57 - train: epoch 0085, iter [04400, 05004], lr: 0.012243, loss: 1.1398
2022-07-13 14:28:50 - train: epoch 0085, iter [04500, 05004], lr: 0.012212, loss: 1.0175
2022-07-13 14:29:46 - train: epoch 0085, iter [04600, 05004], lr: 0.012180, loss: 0.9538
2022-07-13 14:30:46 - train: epoch 0085, iter [04700, 05004], lr: 0.012148, loss: 1.3710
2022-07-13 14:31:44 - train: epoch 0085, iter [04800, 05004], lr: 0.012117, loss: 0.8702
2022-07-13 14:32:44 - train: epoch 0085, iter [04900, 05004], lr: 0.012085, loss: 0.9926
2022-07-13 14:33:37 - train: epoch 0085, iter [05000, 05004], lr: 0.012054, loss: 0.8300
2022-07-13 14:33:39 - train: epoch 085, train_loss: 1.0253
2022-07-13 14:35:48 - eval: epoch: 085, acc1: 74.606%, acc5: 92.098%, test_loss: 1.0356, per_image_load_time: 3.078ms, per_image_inference_time: 0.800ms
2022-07-13 14:35:48 - until epoch: 085, best_acc1: 74.606%
2022-07-13 14:35:48 - epoch 086 lr: 0.012052
2022-07-13 14:37:00 - train: epoch 0086, iter [00100, 05004], lr: 0.012021, loss: 0.9094
2022-07-13 14:37:56 - train: epoch 0086, iter [00200, 05004], lr: 0.011990, loss: 0.9285
2022-07-13 14:38:54 - train: epoch 0086, iter [00300, 05004], lr: 0.011958, loss: 1.0763
2022-07-13 14:39:52 - train: epoch 0086, iter [00400, 05004], lr: 0.011927, loss: 1.1029
2022-07-13 14:40:54 - train: epoch 0086, iter [00500, 05004], lr: 0.011896, loss: 1.0905
2022-07-13 14:41:49 - train: epoch 0086, iter [00600, 05004], lr: 0.011865, loss: 0.9356
2022-07-13 14:42:48 - train: epoch 0086, iter [00700, 05004], lr: 0.011833, loss: 1.0496
2022-07-13 14:43:47 - train: epoch 0086, iter [00800, 05004], lr: 0.011802, loss: 1.0076
2022-07-13 14:44:48 - train: epoch 0086, iter [00900, 05004], lr: 0.011771, loss: 0.8917
2022-07-13 14:45:46 - train: epoch 0086, iter [01000, 05004], lr: 0.011740, loss: 0.9399
2022-07-13 14:46:44 - train: epoch 0086, iter [01100, 05004], lr: 0.011709, loss: 1.0753
2022-07-13 14:47:45 - train: epoch 0086, iter [01200, 05004], lr: 0.011678, loss: 0.8599
2022-07-13 14:48:44 - train: epoch 0086, iter [01300, 05004], lr: 0.011647, loss: 1.0275
2022-07-13 14:49:44 - train: epoch 0086, iter [01400, 05004], lr: 0.011616, loss: 1.1273
2022-07-13 14:50:42 - train: epoch 0086, iter [01500, 05004], lr: 0.011585, loss: 0.7769
2022-07-13 14:51:42 - train: epoch 0086, iter [01600, 05004], lr: 0.011554, loss: 0.9457
2022-07-13 14:52:39 - train: epoch 0086, iter [01700, 05004], lr: 0.011523, loss: 1.0531
2022-07-13 14:53:40 - train: epoch 0086, iter [01800, 05004], lr: 0.011493, loss: 0.8769
2022-07-13 14:54:37 - train: epoch 0086, iter [01900, 05004], lr: 0.011462, loss: 0.8356
2022-07-13 14:55:38 - train: epoch 0086, iter [02000, 05004], lr: 0.011431, loss: 1.0653
2022-07-13 14:56:35 - train: epoch 0086, iter [02100, 05004], lr: 0.011401, loss: 0.9559
2022-07-13 14:57:34 - train: epoch 0086, iter [02200, 05004], lr: 0.011370, loss: 0.9763
2022-07-13 14:58:32 - train: epoch 0086, iter [02300, 05004], lr: 0.011339, loss: 1.0268
2022-07-13 14:59:30 - train: epoch 0086, iter [02400, 05004], lr: 0.011309, loss: 0.7742
2022-07-13 15:00:29 - train: epoch 0086, iter [02500, 05004], lr: 0.011278, loss: 0.9728
2022-07-13 15:01:28 - train: epoch 0086, iter [02600, 05004], lr: 0.011248, loss: 1.0520
2022-07-13 15:02:26 - train: epoch 0086, iter [02700, 05004], lr: 0.011217, loss: 0.8454
2022-07-13 15:03:24 - train: epoch 0086, iter [02800, 05004], lr: 0.011187, loss: 1.1602
2022-07-13 15:04:24 - train: epoch 0086, iter [02900, 05004], lr: 0.011157, loss: 0.8448
2022-07-13 15:05:20 - train: epoch 0086, iter [03000, 05004], lr: 0.011126, loss: 0.8786
2022-07-13 15:06:20 - train: epoch 0086, iter [03100, 05004], lr: 0.011096, loss: 1.0653
2022-07-13 15:07:15 - train: epoch 0086, iter [03200, 05004], lr: 0.011066, loss: 0.8672
2022-07-13 15:08:14 - train: epoch 0086, iter [03300, 05004], lr: 0.011036, loss: 1.0360
2022-07-13 15:09:10 - train: epoch 0086, iter [03400, 05004], lr: 0.011005, loss: 1.0382
2022-07-13 15:10:09 - train: epoch 0086, iter [03500, 05004], lr: 0.010975, loss: 1.1541
2022-07-13 15:11:08 - train: epoch 0086, iter [03600, 05004], lr: 0.010945, loss: 0.9758
2022-07-13 15:12:07 - train: epoch 0086, iter [03700, 05004], lr: 0.010915, loss: 1.0038
2022-07-13 15:13:06 - train: epoch 0086, iter [03800, 05004], lr: 0.010885, loss: 1.1137
2022-07-13 15:14:04 - train: epoch 0086, iter [03900, 05004], lr: 0.010855, loss: 0.9771
2022-07-13 15:15:04 - train: epoch 0086, iter [04000, 05004], lr: 0.010825, loss: 0.9142
2022-07-13 15:16:01 - train: epoch 0086, iter [04100, 05004], lr: 0.010795, loss: 1.0507
2022-07-13 15:17:02 - train: epoch 0086, iter [04200, 05004], lr: 0.010766, loss: 0.9671
2022-07-13 15:17:59 - train: epoch 0086, iter [04300, 05004], lr: 0.010736, loss: 0.9599
2022-07-13 15:18:58 - train: epoch 0086, iter [04400, 05004], lr: 0.010706, loss: 1.0784
2022-07-13 15:19:55 - train: epoch 0086, iter [04500, 05004], lr: 0.010676, loss: 0.9057
2022-07-13 15:20:55 - train: epoch 0086, iter [04600, 05004], lr: 0.010647, loss: 1.1499
2022-07-13 15:21:51 - train: epoch 0086, iter [04700, 05004], lr: 0.010617, loss: 1.0685
2022-07-13 15:22:48 - train: epoch 0086, iter [04800, 05004], lr: 0.010587, loss: 0.9730
2022-07-13 15:23:47 - train: epoch 0086, iter [04900, 05004], lr: 0.010558, loss: 0.9670
2022-07-13 15:24:45 - train: epoch 0086, iter [05000, 05004], lr: 0.010528, loss: 0.9005
2022-07-13 15:24:47 - train: epoch 086, train_loss: 0.9971
2022-07-13 15:26:55 - eval: epoch: 086, acc1: 74.746%, acc5: 92.156%, test_loss: 1.0290, per_image_load_time: 3.978ms, per_image_inference_time: 0.804ms
2022-07-13 15:26:55 - until epoch: 086, best_acc1: 74.746%
2022-07-13 15:26:55 - epoch 087 lr: 0.010527
2022-07-13 15:28:03 - train: epoch 0087, iter [00100, 05004], lr: 0.010498, loss: 0.8582
2022-07-13 15:29:05 - train: epoch 0087, iter [00200, 05004], lr: 0.010468, loss: 0.9090
2022-07-13 15:30:00 - train: epoch 0087, iter [00300, 05004], lr: 0.010439, loss: 1.0000
2022-07-13 15:30:59 - train: epoch 0087, iter [00400, 05004], lr: 0.010409, loss: 0.9097
2022-07-13 15:31:58 - train: epoch 0087, iter [00500, 05004], lr: 0.010380, loss: 0.8026
2022-07-13 15:32:55 - train: epoch 0087, iter [00600, 05004], lr: 0.010351, loss: 1.0601
2022-07-13 15:33:56 - train: epoch 0087, iter [00700, 05004], lr: 0.010321, loss: 0.9461
2022-07-13 15:34:53 - train: epoch 0087, iter [00800, 05004], lr: 0.010292, loss: 0.9905
2022-07-13 15:35:51 - train: epoch 0087, iter [00900, 05004], lr: 0.010263, loss: 1.1077
2022-07-13 15:36:47 - train: epoch 0087, iter [01000, 05004], lr: 0.010234, loss: 0.8906
2022-07-13 15:37:43 - train: epoch 0087, iter [01100, 05004], lr: 0.010205, loss: 1.0203
2022-07-13 15:38:39 - train: epoch 0087, iter [01200, 05004], lr: 0.010176, loss: 0.8153
2022-07-13 15:39:38 - train: epoch 0087, iter [01300, 05004], lr: 0.010147, loss: 1.2182
2022-07-13 15:40:36 - train: epoch 0087, iter [01400, 05004], lr: 0.010118, loss: 0.8042
2022-07-13 15:41:34 - train: epoch 0087, iter [01500, 05004], lr: 0.010089, loss: 0.8733
2022-07-13 15:42:34 - train: epoch 0087, iter [01600, 05004], lr: 0.010060, loss: 0.9005
2022-07-13 15:43:31 - train: epoch 0087, iter [01700, 05004], lr: 0.010031, loss: 0.9983
2022-07-13 15:44:29 - train: epoch 0087, iter [01800, 05004], lr: 0.010002, loss: 1.0479
2022-07-13 15:45:26 - train: epoch 0087, iter [01900, 05004], lr: 0.009973, loss: 1.1114
2022-07-13 15:46:26 - train: epoch 0087, iter [02000, 05004], lr: 0.009945, loss: 0.9245
2022-07-13 15:47:22 - train: epoch 0087, iter [02100, 05004], lr: 0.009916, loss: 1.0145
2022-07-13 15:48:18 - train: epoch 0087, iter [02200, 05004], lr: 0.009887, loss: 1.1493
2022-07-13 15:49:15 - train: epoch 0087, iter [02300, 05004], lr: 0.009859, loss: 1.0940
2022-07-13 15:50:16 - train: epoch 0087, iter [02400, 05004], lr: 0.009830, loss: 0.9167
2022-07-13 15:51:15 - train: epoch 0087, iter [02500, 05004], lr: 0.009801, loss: 0.9984
2022-07-13 15:52:12 - train: epoch 0087, iter [02600, 05004], lr: 0.009773, loss: 0.9415
2022-07-13 15:53:08 - train: epoch 0087, iter [02700, 05004], lr: 0.009744, loss: 0.8493
2022-07-13 15:54:03 - train: epoch 0087, iter [02800, 05004], lr: 0.009716, loss: 0.8413
2022-07-13 15:55:00 - train: epoch 0087, iter [02900, 05004], lr: 0.009688, loss: 0.8118
2022-07-13 15:55:58 - train: epoch 0087, iter [03000, 05004], lr: 0.009659, loss: 1.1845
2022-07-13 15:56:54 - train: epoch 0087, iter [03100, 05004], lr: 0.009631, loss: 1.0681
2022-07-13 15:57:51 - train: epoch 0087, iter [03200, 05004], lr: 0.009603, loss: 1.0177
2022-07-13 15:58:50 - train: epoch 0087, iter [03300, 05004], lr: 0.009574, loss: 0.9637
2022-07-13 15:59:48 - train: epoch 0087, iter [03400, 05004], lr: 0.009546, loss: 0.9005
2022-07-13 16:00:45 - train: epoch 0087, iter [03500, 05004], lr: 0.009518, loss: 0.8351
2022-07-13 16:01:42 - train: epoch 0087, iter [03600, 05004], lr: 0.009490, loss: 0.8584
2022-07-13 16:02:39 - train: epoch 0087, iter [03700, 05004], lr: 0.009462, loss: 0.9158
2022-07-13 16:03:40 - train: epoch 0087, iter [03800, 05004], lr: 0.009434, loss: 0.9745
2022-07-13 16:04:35 - train: epoch 0087, iter [03900, 05004], lr: 0.009406, loss: 0.9862
2022-07-13 16:05:32 - train: epoch 0087, iter [04000, 05004], lr: 0.009378, loss: 1.0827
2022-07-13 16:06:28 - train: epoch 0087, iter [04100, 05004], lr: 0.009350, loss: 1.2375
2022-07-13 16:07:25 - train: epoch 0087, iter [04200, 05004], lr: 0.009322, loss: 1.0629
2022-07-13 16:08:21 - train: epoch 0087, iter [04300, 05004], lr: 0.009294, loss: 0.9285
2022-07-13 16:09:20 - train: epoch 0087, iter [04400, 05004], lr: 0.009266, loss: 1.0172
2022-07-13 16:10:17 - train: epoch 0087, iter [04500, 05004], lr: 0.009239, loss: 1.0346
2022-07-13 16:11:13 - train: epoch 0087, iter [04600, 05004], lr: 0.009211, loss: 1.0566
2022-07-13 16:12:13 - train: epoch 0087, iter [04700, 05004], lr: 0.009183, loss: 1.0525
2022-07-13 16:13:09 - train: epoch 0087, iter [04800, 05004], lr: 0.009156, loss: 0.9692
2022-07-13 16:14:07 - train: epoch 0087, iter [04900, 05004], lr: 0.009128, loss: 0.8244
2022-07-13 16:15:02 - train: epoch 0087, iter [05000, 05004], lr: 0.009100, loss: 0.8206
2022-07-13 16:15:05 - train: epoch 087, train_loss: 0.9723
2022-07-13 16:17:12 - eval: epoch: 087, acc1: 74.902%, acc5: 92.328%, test_loss: 1.0228, per_image_load_time: 3.570ms, per_image_inference_time: 0.799ms
2022-07-13 16:17:12 - until epoch: 087, best_acc1: 74.902%
2022-07-13 16:17:12 - epoch 088 lr: 0.009099
2022-07-13 16:18:24 - train: epoch 0088, iter [00100, 05004], lr: 0.009072, loss: 0.8118
2022-07-13 16:19:20 - train: epoch 0088, iter [00200, 05004], lr: 0.009044, loss: 0.8855
2022-07-13 16:20:14 - train: epoch 0088, iter [00300, 05004], lr: 0.009017, loss: 0.9722
2022-07-13 16:21:13 - train: epoch 0088, iter [00400, 05004], lr: 0.008989, loss: 0.8871
2022-07-13 16:22:12 - train: epoch 0088, iter [00500, 05004], lr: 0.008962, loss: 1.0386
2022-07-13 16:23:06 - train: epoch 0088, iter [00600, 05004], lr: 0.008935, loss: 0.9545
2022-07-13 16:24:02 - train: epoch 0088, iter [00700, 05004], lr: 0.008908, loss: 0.8251
2022-07-13 16:24:57 - train: epoch 0088, iter [00800, 05004], lr: 0.008880, loss: 1.1595
2022-07-13 16:25:53 - train: epoch 0088, iter [00900, 05004], lr: 0.008853, loss: 1.1094
2022-07-13 16:26:52 - train: epoch 0088, iter [01000, 05004], lr: 0.008826, loss: 0.8545
2022-07-13 16:27:46 - train: epoch 0088, iter [01100, 05004], lr: 0.008799, loss: 0.9258
2022-07-13 16:28:41 - train: epoch 0088, iter [01200, 05004], lr: 0.008772, loss: 1.0304
2022-07-13 16:29:37 - train: epoch 0088, iter [01300, 05004], lr: 0.008745, loss: 0.9430
2022-07-13 16:30:34 - train: epoch 0088, iter [01400, 05004], lr: 0.008718, loss: 0.8971
2022-07-13 16:31:30 - train: epoch 0088, iter [01500, 05004], lr: 0.008691, loss: 1.0166
2022-07-13 16:32:27 - train: epoch 0088, iter [01600, 05004], lr: 0.008664, loss: 0.8761
2022-07-13 16:33:23 - train: epoch 0088, iter [01700, 05004], lr: 0.008637, loss: 1.0550
2022-07-13 16:34:18 - train: epoch 0088, iter [01800, 05004], lr: 0.008610, loss: 0.9379
2022-07-13 16:35:14 - train: epoch 0088, iter [01900, 05004], lr: 0.008583, loss: 0.9501
2022-07-13 16:36:12 - train: epoch 0088, iter [02000, 05004], lr: 0.008556, loss: 0.7440
2022-07-13 16:37:05 - train: epoch 0088, iter [02100, 05004], lr: 0.008530, loss: 1.0929
2022-07-13 16:38:00 - train: epoch 0088, iter [02200, 05004], lr: 0.008503, loss: 0.9817
2022-07-13 16:38:54 - train: epoch 0088, iter [02300, 05004], lr: 0.008476, loss: 0.8763
2022-07-13 16:39:51 - train: epoch 0088, iter [02400, 05004], lr: 0.008450, loss: 0.8989
2022-07-13 16:40:45 - train: epoch 0088, iter [02500, 05004], lr: 0.008423, loss: 1.0684
2022-07-13 16:41:37 - train: epoch 0088, iter [02600, 05004], lr: 0.008397, loss: 0.8040
2022-07-13 16:42:31 - train: epoch 0088, iter [02700, 05004], lr: 0.008370, loss: 1.0931
2022-07-13 16:43:26 - train: epoch 0088, iter [02800, 05004], lr: 0.008344, loss: 0.9410
2022-07-13 16:44:23 - train: epoch 0088, iter [02900, 05004], lr: 0.008317, loss: 0.8289
2022-07-13 16:45:17 - train: epoch 0088, iter [03000, 05004], lr: 0.008291, loss: 0.9935
2022-07-13 16:46:10 - train: epoch 0088, iter [03100, 05004], lr: 0.008265, loss: 0.7718
2022-07-13 16:47:08 - train: epoch 0088, iter [03200, 05004], lr: 0.008238, loss: 0.8691
2022-07-13 16:48:05 - train: epoch 0088, iter [03300, 05004], lr: 0.008212, loss: 0.7844
2022-07-13 16:49:01 - train: epoch 0088, iter [03400, 05004], lr: 0.008186, loss: 0.8307
2022-07-13 16:49:54 - train: epoch 0088, iter [03500, 05004], lr: 0.008160, loss: 1.0421
2022-07-13 16:50:48 - train: epoch 0088, iter [03600, 05004], lr: 0.008134, loss: 1.0625
2022-07-13 16:51:47 - train: epoch 0088, iter [03700, 05004], lr: 0.008108, loss: 1.0855
2022-07-13 16:52:44 - train: epoch 0088, iter [03800, 05004], lr: 0.008081, loss: 0.8638
2022-07-13 16:53:41 - train: epoch 0088, iter [03900, 05004], lr: 0.008055, loss: 1.0480
2022-07-13 16:54:34 - train: epoch 0088, iter [04000, 05004], lr: 0.008029, loss: 1.0169
2022-07-13 16:55:30 - train: epoch 0088, iter [04100, 05004], lr: 0.008004, loss: 0.9178
2022-07-13 16:56:26 - train: epoch 0088, iter [04200, 05004], lr: 0.007978, loss: 1.0806
2022-07-13 16:57:26 - train: epoch 0088, iter [04300, 05004], lr: 0.007952, loss: 1.0008
2022-07-13 16:58:21 - train: epoch 0088, iter [04400, 05004], lr: 0.007926, loss: 0.8917
2022-07-13 16:59:14 - train: epoch 0088, iter [04500, 05004], lr: 0.007900, loss: 0.9607
2022-07-13 17:00:12 - train: epoch 0088, iter [04600, 05004], lr: 0.007875, loss: 1.2209
2022-07-13 17:01:09 - train: epoch 0088, iter [04700, 05004], lr: 0.007849, loss: 0.9811
2022-07-13 17:02:08 - train: epoch 0088, iter [04800, 05004], lr: 0.007823, loss: 0.9856
2022-07-13 17:03:01 - train: epoch 0088, iter [04900, 05004], lr: 0.007798, loss: 1.0478
2022-07-13 17:03:54 - train: epoch 0088, iter [05000, 05004], lr: 0.007772, loss: 0.9463
2022-07-13 17:03:57 - train: epoch 088, train_loss: 0.9462
2022-07-13 17:06:05 - eval: epoch: 088, acc1: 75.230%, acc5: 92.486%, test_loss: 1.0088, per_image_load_time: 2.667ms, per_image_inference_time: 0.771ms
2022-07-13 17:06:05 - until epoch: 088, best_acc1: 75.230%
2022-07-13 17:06:05 - epoch 089 lr: 0.007771
2022-07-13 17:07:11 - train: epoch 0089, iter [00100, 05004], lr: 0.007746, loss: 0.7687
2022-07-13 17:08:08 - train: epoch 0089, iter [00200, 05004], lr: 0.007720, loss: 0.7060
2022-07-13 17:09:06 - train: epoch 0089, iter [00300, 05004], lr: 0.007695, loss: 0.9915
2022-07-13 17:10:05 - train: epoch 0089, iter [00400, 05004], lr: 0.007669, loss: 1.0345
2022-07-13 17:11:04 - train: epoch 0089, iter [00500, 05004], lr: 0.007644, loss: 0.8978
2022-07-13 17:11:58 - train: epoch 0089, iter [00600, 05004], lr: 0.007618, loss: 0.9860
2022-07-13 17:12:58 - train: epoch 0089, iter [00700, 05004], lr: 0.007593, loss: 1.0444
2022-07-13 17:13:55 - train: epoch 0089, iter [00800, 05004], lr: 0.007568, loss: 0.9961
2022-07-13 17:14:56 - train: epoch 0089, iter [00900, 05004], lr: 0.007543, loss: 0.8923
2022-07-13 17:15:50 - train: epoch 0089, iter [01000, 05004], lr: 0.007518, loss: 1.0653
2022-07-13 17:16:49 - train: epoch 0089, iter [01100, 05004], lr: 0.007493, loss: 0.8369
2022-07-13 17:17:45 - train: epoch 0089, iter [01200, 05004], lr: 0.007467, loss: 1.0998
2022-07-13 17:18:46 - train: epoch 0089, iter [01300, 05004], lr: 0.007442, loss: 1.2136
2022-07-13 17:19:44 - train: epoch 0089, iter [01400, 05004], lr: 0.007417, loss: 1.1654
2022-07-13 17:20:38 - train: epoch 0089, iter [01500, 05004], lr: 0.007392, loss: 0.9057
2022-07-13 17:21:34 - train: epoch 0089, iter [01600, 05004], lr: 0.007368, loss: 0.6307
2022-07-13 17:22:34 - train: epoch 0089, iter [01700, 05004], lr: 0.007343, loss: 1.0040
2022-07-13 17:23:35 - train: epoch 0089, iter [01800, 05004], lr: 0.007318, loss: 0.9774
2022-07-13 17:24:28 - train: epoch 0089, iter [01900, 05004], lr: 0.007293, loss: 0.9744
2022-07-13 17:25:24 - train: epoch 0089, iter [02000, 05004], lr: 0.007268, loss: 0.9587
2022-07-13 17:26:22 - train: epoch 0089, iter [02100, 05004], lr: 0.007244, loss: 0.9719
2022-07-13 17:27:22 - train: epoch 0089, iter [02200, 05004], lr: 0.007219, loss: 0.7988
2022-07-13 17:28:20 - train: epoch 0089, iter [02300, 05004], lr: 0.007194, loss: 0.9527
2022-07-13 17:29:17 - train: epoch 0089, iter [02400, 05004], lr: 0.007170, loss: 0.9911
2022-07-13 17:30:13 - train: epoch 0089, iter [02500, 05004], lr: 0.007145, loss: 0.9469
2022-07-13 17:31:11 - train: epoch 0089, iter [02600, 05004], lr: 0.007121, loss: 0.7444
2022-07-13 17:32:10 - train: epoch 0089, iter [02700, 05004], lr: 0.007096, loss: 0.8835
2022-07-13 17:33:06 - train: epoch 0089, iter [02800, 05004], lr: 0.007072, loss: 0.8208
2022-07-13 17:34:03 - train: epoch 0089, iter [02900, 05004], lr: 0.007047, loss: 0.9562
2022-07-13 17:35:02 - train: epoch 0089, iter [03000, 05004], lr: 0.007023, loss: 1.0584
2022-07-13 17:36:04 - train: epoch 0089, iter [03100, 05004], lr: 0.006999, loss: 0.8542
2022-07-13 17:36:59 - train: epoch 0089, iter [03200, 05004], lr: 0.006974, loss: 0.9848
2022-07-13 17:37:57 - train: epoch 0089, iter [03300, 05004], lr: 0.006950, loss: 0.9933
2022-07-13 17:38:56 - train: epoch 0089, iter [03400, 05004], lr: 0.006926, loss: 0.8989
2022-07-13 17:39:57 - train: epoch 0089, iter [03500, 05004], lr: 0.006902, loss: 0.8215
2022-07-13 17:40:53 - train: epoch 0089, iter [03600, 05004], lr: 0.006878, loss: 0.9718
2022-07-13 17:41:47 - train: epoch 0089, iter [03700, 05004], lr: 0.006854, loss: 0.8238
2022-07-13 17:42:43 - train: epoch 0089, iter [03800, 05004], lr: 0.006830, loss: 0.8363
2022-07-13 17:43:45 - train: epoch 0089, iter [03900, 05004], lr: 0.006806, loss: 1.0637
2022-07-13 17:44:45 - train: epoch 0089, iter [04000, 05004], lr: 0.006782, loss: 0.8988
2022-07-13 17:45:41 - train: epoch 0089, iter [04100, 05004], lr: 0.006758, loss: 1.1113
2022-07-13 17:46:36 - train: epoch 0089, iter [04200, 05004], lr: 0.006734, loss: 0.8262
2022-07-13 17:47:36 - train: epoch 0089, iter [04300, 05004], lr: 0.006710, loss: 0.8988
2022-07-13 17:48:37 - train: epoch 0089, iter [04400, 05004], lr: 0.006686, loss: 0.9910
2022-07-13 17:49:34 - train: epoch 0089, iter [04500, 05004], lr: 0.006663, loss: 0.8090
2022-07-13 17:50:29 - train: epoch 0089, iter [04600, 05004], lr: 0.006639, loss: 0.9447
2022-07-13 17:51:26 - train: epoch 0089, iter [04700, 05004], lr: 0.006615, loss: 0.8539
2022-07-13 17:52:29 - train: epoch 0089, iter [04800, 05004], lr: 0.006592, loss: 0.9483
2022-07-13 17:53:25 - train: epoch 0089, iter [04900, 05004], lr: 0.006568, loss: 0.9119
2022-07-13 17:54:21 - train: epoch 0089, iter [05000, 05004], lr: 0.006544, loss: 0.8735
2022-07-13 17:54:24 - train: epoch 089, train_loss: 0.9224
2022-07-13 17:56:33 - eval: epoch: 089, acc1: 75.448%, acc5: 92.638%, test_loss: 0.9993, per_image_load_time: 3.116ms, per_image_inference_time: 0.780ms
2022-07-13 17:56:34 - until epoch: 089, best_acc1: 75.448%
2022-07-13 17:56:34 - epoch 090 lr: 0.006543
2022-07-13 17:57:40 - train: epoch 0090, iter [00100, 05004], lr: 0.006520, loss: 0.9106
2022-07-13 17:58:35 - train: epoch 0090, iter [00200, 05004], lr: 0.006497, loss: 0.9624
2022-07-13 17:59:29 - train: epoch 0090, iter [00300, 05004], lr: 0.006473, loss: 0.8807
2022-07-13 18:00:29 - train: epoch 0090, iter [00400, 05004], lr: 0.006450, loss: 0.8941
2022-07-13 18:01:26 - train: epoch 0090, iter [00500, 05004], lr: 0.006426, loss: 0.9116
2022-07-13 18:02:23 - train: epoch 0090, iter [00600, 05004], lr: 0.006403, loss: 1.2331
2022-07-13 18:03:20 - train: epoch 0090, iter [00700, 05004], lr: 0.006380, loss: 0.9156
2022-07-13 18:04:18 - train: epoch 0090, iter [00800, 05004], lr: 0.006357, loss: 0.9147
2022-07-13 18:05:21 - train: epoch 0090, iter [00900, 05004], lr: 0.006334, loss: 0.9755
2022-07-13 18:06:17 - train: epoch 0090, iter [01000, 05004], lr: 0.006310, loss: 0.7925
2022-07-13 18:07:14 - train: epoch 0090, iter [01100, 05004], lr: 0.006287, loss: 1.0236
2022-07-13 18:08:10 - train: epoch 0090, iter [01200, 05004], lr: 0.006264, loss: 0.7367
2022-07-13 18:09:13 - train: epoch 0090, iter [01300, 05004], lr: 0.006241, loss: 0.8400
2022-07-13 18:10:09 - train: epoch 0090, iter [01400, 05004], lr: 0.006218, loss: 0.9005
2022-07-13 18:11:07 - train: epoch 0090, iter [01500, 05004], lr: 0.006195, loss: 1.0409
2022-07-13 18:12:05 - train: epoch 0090, iter [01600, 05004], lr: 0.006173, loss: 0.7633
2022-07-13 18:13:04 - train: epoch 0090, iter [01700, 05004], lr: 0.006150, loss: 0.8020
2022-07-13 18:14:03 - train: epoch 0090, iter [01800, 05004], lr: 0.006127, loss: 0.9442
2022-07-13 18:14:59 - train: epoch 0090, iter [01900, 05004], lr: 0.006104, loss: 0.7933
2022-07-13 18:15:56 - train: epoch 0090, iter [02000, 05004], lr: 0.006081, loss: 1.0804
2022-07-13 18:16:54 - train: epoch 0090, iter [02100, 05004], lr: 0.006059, loss: 0.8462
2022-07-13 18:17:56 - train: epoch 0090, iter [02200, 05004], lr: 0.006036, loss: 0.9564
2022-07-13 18:18:53 - train: epoch 0090, iter [02300, 05004], lr: 0.006014, loss: 0.8692
2022-07-13 18:19:52 - train: epoch 0090, iter [02400, 05004], lr: 0.005991, loss: 0.8354
2022-07-13 18:20:51 - train: epoch 0090, iter [02500, 05004], lr: 0.005969, loss: 0.8272
2022-07-13 18:21:52 - train: epoch 0090, iter [02600, 05004], lr: 0.005946, loss: 0.8070
2022-07-13 18:22:48 - train: epoch 0090, iter [02700, 05004], lr: 0.005924, loss: 0.7796
2022-07-13 18:23:46 - train: epoch 0090, iter [02800, 05004], lr: 0.005901, loss: 0.9121
2022-07-13 18:24:45 - train: epoch 0090, iter [02900, 05004], lr: 0.005879, loss: 0.9111
2022-07-13 18:25:44 - train: epoch 0090, iter [03000, 05004], lr: 0.005857, loss: 0.9661
2022-07-13 18:26:43 - train: epoch 0090, iter [03100, 05004], lr: 0.005834, loss: 0.9042
2022-07-13 18:27:40 - train: epoch 0090, iter [03200, 05004], lr: 0.005812, loss: 0.8229
2022-07-13 18:28:37 - train: epoch 0090, iter [03300, 05004], lr: 0.005790, loss: 1.2445
2022-07-13 18:29:36 - train: epoch 0090, iter [03400, 05004], lr: 0.005768, loss: 0.8725
2022-07-13 18:30:36 - train: epoch 0090, iter [03500, 05004], lr: 0.005746, loss: 0.9033
2022-07-13 18:31:33 - train: epoch 0090, iter [03600, 05004], lr: 0.005724, loss: 0.7862
2022-07-13 18:32:31 - train: epoch 0090, iter [03700, 05004], lr: 0.005702, loss: 0.9552
2022-07-13 18:33:29 - train: epoch 0090, iter [03800, 05004], lr: 0.005680, loss: 0.9423
2022-07-13 18:34:29 - train: epoch 0090, iter [03900, 05004], lr: 0.005658, loss: 0.9768
2022-07-13 18:35:28 - train: epoch 0090, iter [04000, 05004], lr: 0.005636, loss: 0.9351
2022-07-13 18:36:26 - train: epoch 0090, iter [04100, 05004], lr: 0.005614, loss: 0.9800
2022-07-13 18:37:26 - train: epoch 0090, iter [04200, 05004], lr: 0.005592, loss: 0.9366
2022-07-13 18:38:25 - train: epoch 0090, iter [04300, 05004], lr: 0.005570, loss: 0.9531
2022-07-13 18:39:25 - train: epoch 0090, iter [04400, 05004], lr: 0.005549, loss: 0.7901
2022-07-13 18:40:22 - train: epoch 0090, iter [04500, 05004], lr: 0.005527, loss: 0.8309
2022-07-13 18:41:20 - train: epoch 0090, iter [04600, 05004], lr: 0.005505, loss: 0.8178
2022-07-13 18:42:20 - train: epoch 0090, iter [04700, 05004], lr: 0.005484, loss: 0.8242
2022-07-13 18:43:20 - train: epoch 0090, iter [04800, 05004], lr: 0.005462, loss: 1.0462
2022-07-13 18:44:18 - train: epoch 0090, iter [04900, 05004], lr: 0.005441, loss: 0.7273
2022-07-13 18:45:16 - train: epoch 0090, iter [05000, 05004], lr: 0.005419, loss: 0.9099
2022-07-13 18:45:18 - train: epoch 090, train_loss: 0.8977
2022-07-13 18:47:25 - eval: epoch: 090, acc1: 75.628%, acc5: 92.598%, test_loss: 0.9967, per_image_load_time: 1.213ms, per_image_inference_time: 0.790ms
2022-07-13 18:47:25 - until epoch: 090, best_acc1: 75.628%
2022-07-13 18:47:25 - epoch 091 lr: 0.005418
2022-07-13 18:48:34 - train: epoch 0091, iter [00100, 05004], lr: 0.005397, loss: 0.8008
2022-07-13 18:49:32 - train: epoch 0091, iter [00200, 05004], lr: 0.005375, loss: 0.7784
2022-07-13 18:50:32 - train: epoch 0091, iter [00300, 05004], lr: 0.005354, loss: 1.0001
2022-07-13 18:51:31 - train: epoch 0091, iter [00400, 05004], lr: 0.005333, loss: 0.9448
2022-07-13 18:52:28 - train: epoch 0091, iter [00500, 05004], lr: 0.005312, loss: 0.8831
2022-07-13 18:53:22 - train: epoch 0091, iter [00600, 05004], lr: 0.005290, loss: 0.7420
2022-07-13 18:54:22 - train: epoch 0091, iter [00700, 05004], lr: 0.005269, loss: 0.9451
2022-07-13 18:55:23 - train: epoch 0091, iter [00800, 05004], lr: 0.005248, loss: 0.7960
2022-07-13 18:56:21 - train: epoch 0091, iter [00900, 05004], lr: 0.005227, loss: 0.9318
2022-07-13 18:57:17 - train: epoch 0091, iter [01000, 05004], lr: 0.005206, loss: 0.8597
2022-07-13 18:58:17 - train: epoch 0091, iter [01100, 05004], lr: 0.005185, loss: 0.8414
2022-07-13 18:59:18 - train: epoch 0091, iter [01200, 05004], lr: 0.005164, loss: 1.0737
2022-07-13 19:00:17 - train: epoch 0091, iter [01300, 05004], lr: 0.005143, loss: 0.7378
2022-07-13 19:01:14 - train: epoch 0091, iter [01400, 05004], lr: 0.005122, loss: 0.9272
2022-07-13 19:02:12 - train: epoch 0091, iter [01500, 05004], lr: 0.005101, loss: 1.0396
2022-07-13 19:03:13 - train: epoch 0091, iter [01600, 05004], lr: 0.005080, loss: 0.8022
2022-07-13 19:04:10 - train: epoch 0091, iter [01700, 05004], lr: 0.005059, loss: 0.8903
2022-07-13 19:05:10 - train: epoch 0091, iter [01800, 05004], lr: 0.005039, loss: 0.9625
2022-07-13 19:06:07 - train: epoch 0091, iter [01900, 05004], lr: 0.005018, loss: 0.8958
2022-07-13 19:07:07 - train: epoch 0091, iter [02000, 05004], lr: 0.004997, loss: 0.8140
2022-07-13 19:08:05 - train: epoch 0091, iter [02100, 05004], lr: 0.004977, loss: 0.8459
2022-07-13 19:09:04 - train: epoch 0091, iter [02200, 05004], lr: 0.004956, loss: 0.9016
2022-07-13 19:10:01 - train: epoch 0091, iter [02300, 05004], lr: 0.004936, loss: 0.8293
2022-07-13 19:11:01 - train: epoch 0091, iter [02400, 05004], lr: 0.004915, loss: 0.7581
2022-07-13 19:11:57 - train: epoch 0091, iter [02500, 05004], lr: 0.004895, loss: 0.9403
2022-07-13 19:12:54 - train: epoch 0091, iter [02600, 05004], lr: 0.004874, loss: 0.8302
2022-07-13 19:13:51 - train: epoch 0091, iter [02700, 05004], lr: 0.004854, loss: 0.8947
2022-07-13 19:14:48 - train: epoch 0091, iter [02800, 05004], lr: 0.004834, loss: 0.8253
2022-07-13 19:15:46 - train: epoch 0091, iter [02900, 05004], lr: 0.004813, loss: 0.9242
2022-07-13 19:16:43 - train: epoch 0091, iter [03000, 05004], lr: 0.004793, loss: 1.1334
2022-07-13 19:17:39 - train: epoch 0091, iter [03100, 05004], lr: 0.004773, loss: 0.8905
2022-07-13 19:18:37 - train: epoch 0091, iter [03200, 05004], lr: 0.004753, loss: 0.8290
2022-07-13 19:19:36 - train: epoch 0091, iter [03300, 05004], lr: 0.004733, loss: 0.7870
2022-07-13 19:20:30 - train: epoch 0091, iter [03400, 05004], lr: 0.004713, loss: 0.9123
2022-07-13 19:21:24 - train: epoch 0091, iter [03500, 05004], lr: 0.004693, loss: 0.8560
2022-07-13 19:22:17 - train: epoch 0091, iter [03600, 05004], lr: 0.004673, loss: 0.9524
2022-07-13 19:23:13 - train: epoch 0091, iter [03700, 05004], lr: 0.004653, loss: 0.9371
2022-07-13 19:24:06 - train: epoch 0091, iter [03800, 05004], lr: 0.004633, loss: 0.8648
2022-07-13 19:25:01 - train: epoch 0091, iter [03900, 05004], lr: 0.004613, loss: 0.9118
2022-07-13 19:25:56 - train: epoch 0091, iter [04000, 05004], lr: 0.004593, loss: 0.7741
2022-07-13 19:26:49 - train: epoch 0091, iter [04100, 05004], lr: 0.004573, loss: 0.8543
2022-07-13 19:27:43 - train: epoch 0091, iter [04200, 05004], lr: 0.004554, loss: 0.9898
2022-07-13 19:28:37 - train: epoch 0091, iter [04300, 05004], lr: 0.004534, loss: 0.9616
2022-07-13 19:29:30 - train: epoch 0091, iter [04400, 05004], lr: 0.004514, loss: 0.7732
2022-07-13 19:30:24 - train: epoch 0091, iter [04500, 05004], lr: 0.004495, loss: 0.9525
2022-07-13 19:31:17 - train: epoch 0091, iter [04600, 05004], lr: 0.004475, loss: 0.8208
2022-07-13 19:32:10 - train: epoch 0091, iter [04700, 05004], lr: 0.004456, loss: 0.9815
2022-07-13 19:33:04 - train: epoch 0091, iter [04800, 05004], lr: 0.004436, loss: 0.9006
2022-07-13 19:33:56 - train: epoch 0091, iter [04900, 05004], lr: 0.004417, loss: 0.8237
2022-07-13 19:34:48 - train: epoch 0091, iter [05000, 05004], lr: 0.004397, loss: 1.0516
2022-07-13 19:34:50 - train: epoch 091, train_loss: 0.8781
2022-07-13 19:37:01 - eval: epoch: 091, acc1: 75.736%, acc5: 92.850%, test_loss: 0.9863, per_image_load_time: 4.106ms, per_image_inference_time: 0.904ms
2022-07-13 19:37:01 - until epoch: 091, best_acc1: 75.736%
2022-07-13 19:37:01 - epoch 092 lr: 0.004396
2022-07-13 19:38:08 - train: epoch 0092, iter [00100, 05004], lr: 0.004377, loss: 0.7873
2022-07-13 19:39:03 - train: epoch 0092, iter [00200, 05004], lr: 0.004358, loss: 0.8244
2022-07-13 19:39:59 - train: epoch 0092, iter [00300, 05004], lr: 0.004338, loss: 1.0321
2022-07-13 19:40:53 - train: epoch 0092, iter [00400, 05004], lr: 0.004319, loss: 0.8874
2022-07-13 19:41:47 - train: epoch 0092, iter [00500, 05004], lr: 0.004300, loss: 0.8691
2022-07-13 19:42:42 - train: epoch 0092, iter [00600, 05004], lr: 0.004281, loss: 0.9339
2022-07-13 19:43:35 - train: epoch 0092, iter [00700, 05004], lr: 0.004262, loss: 0.8983
2022-07-13 19:44:29 - train: epoch 0092, iter [00800, 05004], lr: 0.004243, loss: 0.9843
2022-07-13 19:45:22 - train: epoch 0092, iter [00900, 05004], lr: 0.004224, loss: 0.8070
2022-07-13 19:46:15 - train: epoch 0092, iter [01000, 05004], lr: 0.004205, loss: 0.8881
2022-07-13 19:47:09 - train: epoch 0092, iter [01100, 05004], lr: 0.004186, loss: 0.8233
2022-07-13 19:48:02 - train: epoch 0092, iter [01200, 05004], lr: 0.004167, loss: 0.7791
2022-07-13 19:48:56 - train: epoch 0092, iter [01300, 05004], lr: 0.004148, loss: 0.7976
2022-07-13 19:49:51 - train: epoch 0092, iter [01400, 05004], lr: 0.004129, loss: 0.7882
2022-07-13 19:50:45 - train: epoch 0092, iter [01500, 05004], lr: 0.004110, loss: 0.7333
2022-07-13 19:51:40 - train: epoch 0092, iter [01600, 05004], lr: 0.004092, loss: 0.7026
2022-07-13 19:52:33 - train: epoch 0092, iter [01700, 05004], lr: 0.004073, loss: 0.9640
2022-07-13 19:53:27 - train: epoch 0092, iter [01800, 05004], lr: 0.004054, loss: 0.8512
2022-07-13 19:54:21 - train: epoch 0092, iter [01900, 05004], lr: 0.004036, loss: 0.7962
2022-07-13 19:55:14 - train: epoch 0092, iter [02000, 05004], lr: 0.004017, loss: 0.7770
2022-07-13 19:56:08 - train: epoch 0092, iter [02100, 05004], lr: 0.003999, loss: 1.0229
2022-07-13 19:57:01 - train: epoch 0092, iter [02200, 05004], lr: 0.003980, loss: 0.9351
2022-07-13 19:57:55 - train: epoch 0092, iter [02300, 05004], lr: 0.003962, loss: 0.7689
2022-07-13 19:58:49 - train: epoch 0092, iter [02400, 05004], lr: 0.003943, loss: 0.7239
2022-07-13 19:59:43 - train: epoch 0092, iter [02500, 05004], lr: 0.003925, loss: 0.8578
2022-07-13 20:00:37 - train: epoch 0092, iter [02600, 05004], lr: 0.003907, loss: 0.9988
2022-07-13 20:01:32 - train: epoch 0092, iter [02700, 05004], lr: 0.003888, loss: 0.8859
2022-07-13 20:02:27 - train: epoch 0092, iter [02800, 05004], lr: 0.003870, loss: 0.8221
2022-07-13 20:03:20 - train: epoch 0092, iter [02900, 05004], lr: 0.003852, loss: 1.1553
2022-07-13 20:04:13 - train: epoch 0092, iter [03000, 05004], lr: 0.003834, loss: 0.8666
2022-07-13 20:05:06 - train: epoch 0092, iter [03100, 05004], lr: 0.003816, loss: 0.8960
2022-07-13 20:06:00 - train: epoch 0092, iter [03200, 05004], lr: 0.003798, loss: 0.7676
2022-07-13 20:06:56 - train: epoch 0092, iter [03300, 05004], lr: 0.003780, loss: 0.7638
2022-07-13 20:07:51 - train: epoch 0092, iter [03400, 05004], lr: 0.003762, loss: 0.7972
2022-07-13 20:08:45 - train: epoch 0092, iter [03500, 05004], lr: 0.003744, loss: 0.7470
2022-07-13 20:09:38 - train: epoch 0092, iter [03600, 05004], lr: 0.003726, loss: 0.8498
2022-07-13 20:10:30 - train: epoch 0092, iter [03700, 05004], lr: 0.003708, loss: 0.8835
2022-07-13 20:11:25 - train: epoch 0092, iter [03800, 05004], lr: 0.003690, loss: 0.8970
2022-07-13 20:12:18 - train: epoch 0092, iter [03900, 05004], lr: 0.003672, loss: 0.8456
2022-07-13 20:13:11 - train: epoch 0092, iter [04000, 05004], lr: 0.003655, loss: 0.8726
2022-07-13 20:14:05 - train: epoch 0092, iter [04100, 05004], lr: 0.003637, loss: 0.7757
2022-07-13 20:14:59 - train: epoch 0092, iter [04200, 05004], lr: 0.003619, loss: 0.7680
2022-07-13 20:15:53 - train: epoch 0092, iter [04300, 05004], lr: 0.003602, loss: 0.8973
2022-07-13 20:16:47 - train: epoch 0092, iter [04400, 05004], lr: 0.003584, loss: 0.8061
2022-07-13 20:17:40 - train: epoch 0092, iter [04500, 05004], lr: 0.003567, loss: 0.7490
2022-07-13 20:18:34 - train: epoch 0092, iter [04600, 05004], lr: 0.003549, loss: 1.0408
2022-07-13 20:19:28 - train: epoch 0092, iter [04700, 05004], lr: 0.003532, loss: 0.7411
2022-07-13 20:20:21 - train: epoch 0092, iter [04800, 05004], lr: 0.003514, loss: 0.9409
2022-07-13 20:21:15 - train: epoch 0092, iter [04900, 05004], lr: 0.003497, loss: 0.9235
2022-07-13 20:22:07 - train: epoch 0092, iter [05000, 05004], lr: 0.003480, loss: 0.7927
2022-07-13 20:22:09 - train: epoch 092, train_loss: 0.8539
2022-07-13 20:24:24 - eval: epoch: 092, acc1: 76.040%, acc5: 92.892%, test_loss: 0.9812, per_image_load_time: 2.128ms, per_image_inference_time: 0.899ms
2022-07-13 20:24:25 - until epoch: 092, best_acc1: 76.040%
2022-07-13 20:24:25 - epoch 093 lr: 0.003479
2022-07-13 20:25:34 - train: epoch 0093, iter [00100, 05004], lr: 0.003462, loss: 0.8384
2022-07-13 20:26:27 - train: epoch 0093, iter [00200, 05004], lr: 0.003445, loss: 0.7944
2022-07-13 20:27:21 - train: epoch 0093, iter [00300, 05004], lr: 0.003427, loss: 0.8843
2022-07-13 20:28:14 - train: epoch 0093, iter [00400, 05004], lr: 0.003410, loss: 0.8704
2022-07-13 20:29:07 - train: epoch 0093, iter [00500, 05004], lr: 0.003393, loss: 0.7809
2022-07-13 20:30:00 - train: epoch 0093, iter [00600, 05004], lr: 0.003376, loss: 0.8971
2022-07-13 20:30:54 - train: epoch 0093, iter [00700, 05004], lr: 0.003359, loss: 0.8169
2022-07-13 20:31:48 - train: epoch 0093, iter [00800, 05004], lr: 0.003342, loss: 0.6892
2022-07-13 20:32:41 - train: epoch 0093, iter [00900, 05004], lr: 0.003325, loss: 0.9458
2022-07-13 20:33:34 - train: epoch 0093, iter [01000, 05004], lr: 0.003308, loss: 0.5600
2022-07-13 20:34:29 - train: epoch 0093, iter [01100, 05004], lr: 0.003292, loss: 0.7731
2022-07-13 20:35:23 - train: epoch 0093, iter [01200, 05004], lr: 0.003275, loss: 0.8036
2022-07-13 20:36:17 - train: epoch 0093, iter [01300, 05004], lr: 0.003258, loss: 0.7300
2022-07-13 20:37:11 - train: epoch 0093, iter [01400, 05004], lr: 0.003241, loss: 0.8407
2022-07-13 20:38:06 - train: epoch 0093, iter [01500, 05004], lr: 0.003225, loss: 0.9581
2022-07-13 20:39:00 - train: epoch 0093, iter [01600, 05004], lr: 0.003208, loss: 0.9428
2022-07-13 20:39:54 - train: epoch 0093, iter [01700, 05004], lr: 0.003191, loss: 0.9190
2022-07-13 20:40:48 - train: epoch 0093, iter [01800, 05004], lr: 0.003175, loss: 0.8245
2022-07-13 20:41:41 - train: epoch 0093, iter [01900, 05004], lr: 0.003158, loss: 0.7340
2022-07-13 20:42:35 - train: epoch 0093, iter [02000, 05004], lr: 0.003142, loss: 0.7534
2022-07-13 20:43:30 - train: epoch 0093, iter [02100, 05004], lr: 0.003126, loss: 0.8041
2022-07-13 20:44:23 - train: epoch 0093, iter [02200, 05004], lr: 0.003109, loss: 1.0272
2022-07-13 20:45:14 - train: epoch 0093, iter [02300, 05004], lr: 0.003093, loss: 0.8326
2022-07-13 20:46:05 - train: epoch 0093, iter [02400, 05004], lr: 0.003077, loss: 0.8848
