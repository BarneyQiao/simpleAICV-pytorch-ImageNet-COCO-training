2022-07-13 20:46:57 - train: epoch 0093, iter [02500, 05004], lr: 0.003060, loss: 0.8057
2022-07-13 20:47:49 - train: epoch 0093, iter [02600, 05004], lr: 0.003044, loss: 1.1064
2022-07-13 20:48:40 - train: epoch 0093, iter [02700, 05004], lr: 0.003028, loss: 0.7781
2022-07-13 20:49:33 - train: epoch 0093, iter [02800, 05004], lr: 0.003012, loss: 0.9639
2022-07-13 20:50:25 - train: epoch 0093, iter [02900, 05004], lr: 0.002996, loss: 0.7840
2022-07-13 20:51:17 - train: epoch 0093, iter [03000, 05004], lr: 0.002980, loss: 0.7907
2022-07-13 20:52:09 - train: epoch 0093, iter [03100, 05004], lr: 0.002964, loss: 0.8267
2022-07-13 20:53:02 - train: epoch 0093, iter [03200, 05004], lr: 0.002948, loss: 0.7983
2022-07-13 20:53:54 - train: epoch 0093, iter [03300, 05004], lr: 0.002932, loss: 0.9607
2022-07-13 20:54:47 - train: epoch 0093, iter [03400, 05004], lr: 0.002916, loss: 0.9229
2022-07-13 20:55:39 - train: epoch 0093, iter [03500, 05004], lr: 0.002900, loss: 0.6479
2022-07-13 20:56:32 - train: epoch 0093, iter [03600, 05004], lr: 0.002884, loss: 0.9009
2022-07-13 20:57:24 - train: epoch 0093, iter [03700, 05004], lr: 0.002869, loss: 0.7299
2022-07-13 20:58:16 - train: epoch 0093, iter [03800, 05004], lr: 0.002853, loss: 0.8500
2022-07-13 20:59:08 - train: epoch 0093, iter [03900, 05004], lr: 0.002837, loss: 0.7836
2022-07-13 21:00:03 - train: epoch 0093, iter [04000, 05004], lr: 0.002822, loss: 0.9340
2022-07-13 21:00:58 - train: epoch 0093, iter [04100, 05004], lr: 0.002806, loss: 0.9550
2022-07-13 21:01:50 - train: epoch 0093, iter [04200, 05004], lr: 0.002791, loss: 0.8230
2022-07-13 21:02:42 - train: epoch 0093, iter [04300, 05004], lr: 0.002775, loss: 0.9239
2022-07-13 21:03:34 - train: epoch 0093, iter [04400, 05004], lr: 0.002760, loss: 0.8149
2022-07-13 21:04:25 - train: epoch 0093, iter [04500, 05004], lr: 0.002744, loss: 0.8190
2022-07-13 21:05:18 - train: epoch 0093, iter [04600, 05004], lr: 0.002729, loss: 0.9076
2022-07-13 21:06:09 - train: epoch 0093, iter [04700, 05004], lr: 0.002714, loss: 0.8748
2022-07-13 21:07:00 - train: epoch 0093, iter [04800, 05004], lr: 0.002698, loss: 0.9483
2022-07-13 21:07:51 - train: epoch 0093, iter [04900, 05004], lr: 0.002683, loss: 0.8920
2022-07-13 21:08:42 - train: epoch 0093, iter [05000, 05004], lr: 0.002668, loss: 0.8373
2022-07-13 21:08:44 - train: epoch 093, train_loss: 0.8359
2022-07-13 21:10:51 - eval: epoch: 093, acc1: 76.172%, acc5: 92.968%, test_loss: 0.9764, per_image_load_time: 3.144ms, per_image_inference_time: 0.886ms
2022-07-13 21:10:51 - until epoch: 093, best_acc1: 76.172%
2022-07-13 21:10:51 - epoch 094 lr: 0.002667
2022-07-13 21:11:59 - train: epoch 0094, iter [00100, 05004], lr: 0.002652, loss: 0.7997
2022-07-13 21:12:53 - train: epoch 0094, iter [00200, 05004], lr: 0.002637, loss: 0.7089
2022-07-13 21:13:47 - train: epoch 0094, iter [00300, 05004], lr: 0.002622, loss: 0.9446
2022-07-13 21:14:39 - train: epoch 0094, iter [00400, 05004], lr: 0.002607, loss: 0.9352
2022-07-13 21:15:31 - train: epoch 0094, iter [00500, 05004], lr: 0.002592, loss: 0.7860
2022-07-13 21:16:23 - train: epoch 0094, iter [00600, 05004], lr: 0.002577, loss: 0.7064
2022-07-13 21:17:14 - train: epoch 0094, iter [00700, 05004], lr: 0.002562, loss: 1.0030
2022-07-13 21:18:06 - train: epoch 0094, iter [00800, 05004], lr: 0.002547, loss: 0.8202
2022-07-13 21:18:59 - train: epoch 0094, iter [00900, 05004], lr: 0.002533, loss: 0.7970
2022-07-13 21:19:52 - train: epoch 0094, iter [01000, 05004], lr: 0.002518, loss: 0.8706
2022-07-13 21:20:46 - train: epoch 0094, iter [01100, 05004], lr: 0.002503, loss: 1.0027
2022-07-13 21:21:40 - train: epoch 0094, iter [01200, 05004], lr: 0.002488, loss: 0.7919
2022-07-13 21:22:34 - train: epoch 0094, iter [01300, 05004], lr: 0.002474, loss: 0.8007
2022-07-13 21:23:26 - train: epoch 0094, iter [01400, 05004], lr: 0.002459, loss: 0.7841
2022-07-13 21:24:18 - train: epoch 0094, iter [01500, 05004], lr: 0.002445, loss: 0.8212
2022-07-13 21:25:11 - train: epoch 0094, iter [01600, 05004], lr: 0.002430, loss: 0.9868
2022-07-13 21:26:04 - train: epoch 0094, iter [01700, 05004], lr: 0.002416, loss: 0.8071
2022-07-13 21:26:57 - train: epoch 0094, iter [01800, 05004], lr: 0.002401, loss: 0.9282
2022-07-13 21:27:50 - train: epoch 0094, iter [01900, 05004], lr: 0.002387, loss: 0.7746
2022-07-13 21:28:42 - train: epoch 0094, iter [02000, 05004], lr: 0.002373, loss: 0.6936
2022-07-13 21:29:35 - train: epoch 0094, iter [02100, 05004], lr: 0.002358, loss: 0.7998
2022-07-13 21:30:29 - train: epoch 0094, iter [02200, 05004], lr: 0.002344, loss: 0.7813
2022-07-13 21:31:22 - train: epoch 0094, iter [02300, 05004], lr: 0.002330, loss: 0.7529
2022-07-13 21:32:15 - train: epoch 0094, iter [02400, 05004], lr: 0.002316, loss: 0.8111
2022-07-13 21:33:08 - train: epoch 0094, iter [02500, 05004], lr: 0.002302, loss: 0.6920
2022-07-13 21:34:01 - train: epoch 0094, iter [02600, 05004], lr: 0.002288, loss: 0.7350
2022-07-13 21:34:54 - train: epoch 0094, iter [02700, 05004], lr: 0.002273, loss: 0.7126
2022-07-13 21:35:48 - train: epoch 0094, iter [02800, 05004], lr: 0.002260, loss: 0.9662
2022-07-13 21:36:40 - train: epoch 0094, iter [02900, 05004], lr: 0.002246, loss: 0.7850
2022-07-13 21:37:33 - train: epoch 0094, iter [03000, 05004], lr: 0.002232, loss: 0.8798
2022-07-13 21:38:26 - train: epoch 0094, iter [03100, 05004], lr: 0.002218, loss: 0.9779
2022-07-13 21:39:19 - train: epoch 0094, iter [03200, 05004], lr: 0.002204, loss: 0.8154
2022-07-13 21:40:12 - train: epoch 0094, iter [03300, 05004], lr: 0.002190, loss: 0.6945
2022-07-13 21:41:06 - train: epoch 0094, iter [03400, 05004], lr: 0.002176, loss: 0.7124
2022-07-13 21:41:59 - train: epoch 0094, iter [03500, 05004], lr: 0.002163, loss: 0.9700
2022-07-13 21:42:52 - train: epoch 0094, iter [03600, 05004], lr: 0.002149, loss: 0.6592
2022-07-13 21:43:45 - train: epoch 0094, iter [03700, 05004], lr: 0.002136, loss: 0.8445
2022-07-13 21:44:38 - train: epoch 0094, iter [03800, 05004], lr: 0.002122, loss: 0.7764
2022-07-13 21:45:32 - train: epoch 0094, iter [03900, 05004], lr: 0.002108, loss: 0.6189
2022-07-13 21:46:26 - train: epoch 0094, iter [04000, 05004], lr: 0.002095, loss: 0.8486
2022-07-13 21:47:19 - train: epoch 0094, iter [04100, 05004], lr: 0.002082, loss: 0.8144
2022-07-13 21:48:11 - train: epoch 0094, iter [04200, 05004], lr: 0.002068, loss: 0.8234
2022-07-13 21:49:04 - train: epoch 0094, iter [04300, 05004], lr: 0.002055, loss: 0.8966
2022-07-13 21:49:56 - train: epoch 0094, iter [04400, 05004], lr: 0.002041, loss: 0.7173
2022-07-13 21:50:49 - train: epoch 0094, iter [04500, 05004], lr: 0.002028, loss: 0.9449
2022-07-13 21:51:42 - train: epoch 0094, iter [04600, 05004], lr: 0.002015, loss: 0.9539
2022-07-13 21:52:34 - train: epoch 0094, iter [04700, 05004], lr: 0.002002, loss: 0.9554
2022-07-13 21:53:26 - train: epoch 0094, iter [04800, 05004], lr: 0.001989, loss: 0.6561
2022-07-13 21:54:19 - train: epoch 0094, iter [04900, 05004], lr: 0.001976, loss: 0.9315
2022-07-13 21:55:10 - train: epoch 0094, iter [05000, 05004], lr: 0.001963, loss: 0.6856
2022-07-13 21:55:12 - train: epoch 094, train_loss: 0.8188
2022-07-13 21:57:25 - eval: epoch: 094, acc1: 76.270%, acc5: 93.042%, test_loss: 0.9705, per_image_load_time: 3.483ms, per_image_inference_time: 0.870ms
2022-07-13 21:57:26 - until epoch: 094, best_acc1: 76.270%
2022-07-13 21:57:26 - epoch 095 lr: 0.001962
2022-07-13 21:58:34 - train: epoch 0095, iter [00100, 05004], lr: 0.001949, loss: 0.8314
2022-07-13 21:59:31 - train: epoch 0095, iter [00200, 05004], lr: 0.001936, loss: 0.8065
2022-07-13 22:00:26 - train: epoch 0095, iter [00300, 05004], lr: 0.001923, loss: 0.7346
2022-07-13 22:01:20 - train: epoch 0095, iter [00400, 05004], lr: 0.001910, loss: 1.0140
2022-07-13 22:02:13 - train: epoch 0095, iter [00500, 05004], lr: 0.001897, loss: 0.9657
2022-07-13 22:03:06 - train: epoch 0095, iter [00600, 05004], lr: 0.001885, loss: 0.7925
2022-07-13 22:03:58 - train: epoch 0095, iter [00700, 05004], lr: 0.001872, loss: 0.8886
2022-07-13 22:04:51 - train: epoch 0095, iter [00800, 05004], lr: 0.001859, loss: 0.8351
2022-07-13 22:05:44 - train: epoch 0095, iter [00900, 05004], lr: 0.001846, loss: 1.0281
2022-07-13 22:06:36 - train: epoch 0095, iter [01000, 05004], lr: 0.001834, loss: 0.9157
2022-07-13 22:07:29 - train: epoch 0095, iter [01100, 05004], lr: 0.001821, loss: 0.9446
2022-07-13 22:08:22 - train: epoch 0095, iter [01200, 05004], lr: 0.001809, loss: 0.7886
2022-07-13 22:09:14 - train: epoch 0095, iter [01300, 05004], lr: 0.001796, loss: 0.7973
2022-07-13 22:10:08 - train: epoch 0095, iter [01400, 05004], lr: 0.001784, loss: 0.8786
2022-07-13 22:11:01 - train: epoch 0095, iter [01500, 05004], lr: 0.001771, loss: 0.8301
2022-07-13 22:11:54 - train: epoch 0095, iter [01600, 05004], lr: 0.001759, loss: 0.5656
2022-07-13 22:12:47 - train: epoch 0095, iter [01700, 05004], lr: 0.001747, loss: 0.7225
2022-07-13 22:13:40 - train: epoch 0095, iter [01800, 05004], lr: 0.001734, loss: 0.8819
2022-07-13 22:14:34 - train: epoch 0095, iter [01900, 05004], lr: 0.001722, loss: 0.7896
2022-07-13 22:15:27 - train: epoch 0095, iter [02000, 05004], lr: 0.001710, loss: 0.8978
2022-07-13 22:16:21 - train: epoch 0095, iter [02100, 05004], lr: 0.001698, loss: 0.7781
2022-07-13 22:17:15 - train: epoch 0095, iter [02200, 05004], lr: 0.001686, loss: 0.6638
2022-07-13 22:18:08 - train: epoch 0095, iter [02300, 05004], lr: 0.001674, loss: 0.7669
2022-07-13 22:19:02 - train: epoch 0095, iter [02400, 05004], lr: 0.001662, loss: 0.7368
2022-07-13 22:19:55 - train: epoch 0095, iter [02500, 05004], lr: 0.001650, loss: 0.9253
2022-07-13 22:20:49 - train: epoch 0095, iter [02600, 05004], lr: 0.001638, loss: 0.8639
2022-07-13 22:21:42 - train: epoch 0095, iter [02700, 05004], lr: 0.001626, loss: 0.8407
2022-07-13 22:22:36 - train: epoch 0095, iter [02800, 05004], lr: 0.001614, loss: 0.7571
2022-07-13 22:23:30 - train: epoch 0095, iter [02900, 05004], lr: 0.001602, loss: 0.9266
2022-07-13 22:24:23 - train: epoch 0095, iter [03000, 05004], lr: 0.001590, loss: 1.0115
2022-07-13 22:25:17 - train: epoch 0095, iter [03100, 05004], lr: 0.001579, loss: 0.8597
2022-07-13 22:26:10 - train: epoch 0095, iter [03200, 05004], lr: 0.001567, loss: 0.7939
2022-07-13 22:27:04 - train: epoch 0095, iter [03300, 05004], lr: 0.001555, loss: 0.8275
2022-07-13 22:27:58 - train: epoch 0095, iter [03400, 05004], lr: 0.001544, loss: 0.7472
2022-07-13 22:28:51 - train: epoch 0095, iter [03500, 05004], lr: 0.001532, loss: 0.7478
2022-07-13 22:29:44 - train: epoch 0095, iter [03600, 05004], lr: 0.001521, loss: 0.6776
2022-07-13 22:30:37 - train: epoch 0095, iter [03700, 05004], lr: 0.001509, loss: 0.6659
2022-07-13 22:31:30 - train: epoch 0095, iter [03800, 05004], lr: 0.001498, loss: 0.8397
2022-07-13 22:32:23 - train: epoch 0095, iter [03900, 05004], lr: 0.001487, loss: 0.8868
2022-07-13 22:33:16 - train: epoch 0095, iter [04000, 05004], lr: 0.001475, loss: 0.7012
2022-07-13 22:34:08 - train: epoch 0095, iter [04100, 05004], lr: 0.001464, loss: 0.9326
2022-07-13 22:35:01 - train: epoch 0095, iter [04200, 05004], lr: 0.001453, loss: 0.7707
2022-07-13 22:35:54 - train: epoch 0095, iter [04300, 05004], lr: 0.001442, loss: 0.8763
2022-07-13 22:36:47 - train: epoch 0095, iter [04400, 05004], lr: 0.001430, loss: 0.9232
2022-07-13 22:37:40 - train: epoch 0095, iter [04500, 05004], lr: 0.001419, loss: 0.6559
2022-07-13 22:38:33 - train: epoch 0095, iter [04600, 05004], lr: 0.001408, loss: 0.8719
2022-07-13 22:39:26 - train: epoch 0095, iter [04700, 05004], lr: 0.001397, loss: 0.7905
2022-07-13 22:40:19 - train: epoch 0095, iter [04800, 05004], lr: 0.001386, loss: 0.8282
2022-07-13 22:41:12 - train: epoch 0095, iter [04900, 05004], lr: 0.001375, loss: 0.6330
2022-07-13 22:42:04 - train: epoch 0095, iter [05000, 05004], lr: 0.001364, loss: 0.8901
2022-07-13 22:42:06 - train: epoch 095, train_loss: 0.8063
2022-07-13 22:44:17 - eval: epoch: 095, acc1: 76.476%, acc5: 93.084%, test_loss: 0.9646, per_image_load_time: 3.898ms, per_image_inference_time: 0.810ms
2022-07-13 22:44:17 - until epoch: 095, best_acc1: 76.476%
2022-07-13 22:44:17 - epoch 096 lr: 0.001364
2022-07-13 22:45:24 - train: epoch 0096, iter [00100, 05004], lr: 0.001353, loss: 0.7834
2022-07-13 22:46:19 - train: epoch 0096, iter [00200, 05004], lr: 0.001342, loss: 0.9040
2022-07-13 22:47:14 - train: epoch 0096, iter [00300, 05004], lr: 0.001331, loss: 0.8645
2022-07-13 22:48:08 - train: epoch 0096, iter [00400, 05004], lr: 0.001321, loss: 0.6000
2022-07-13 22:49:04 - train: epoch 0096, iter [00500, 05004], lr: 0.001310, loss: 0.7648
2022-07-13 22:49:57 - train: epoch 0096, iter [00600, 05004], lr: 0.001299, loss: 0.7137
2022-07-13 22:50:51 - train: epoch 0096, iter [00700, 05004], lr: 0.001289, loss: 0.7027
2022-07-13 22:51:46 - train: epoch 0096, iter [00800, 05004], lr: 0.001278, loss: 0.7400
2022-07-13 22:52:39 - train: epoch 0096, iter [00900, 05004], lr: 0.001268, loss: 0.8160
2022-07-13 22:53:33 - train: epoch 0096, iter [01000, 05004], lr: 0.001257, loss: 0.7945
2022-07-13 22:54:28 - train: epoch 0096, iter [01100, 05004], lr: 0.001247, loss: 0.7415
2022-07-13 22:55:21 - train: epoch 0096, iter [01200, 05004], lr: 0.001236, loss: 0.7997
2022-07-13 22:56:15 - train: epoch 0096, iter [01300, 05004], lr: 0.001226, loss: 0.9318
2022-07-13 22:57:08 - train: epoch 0096, iter [01400, 05004], lr: 0.001216, loss: 0.8012
2022-07-13 22:58:01 - train: epoch 0096, iter [01500, 05004], lr: 0.001206, loss: 0.7075
2022-07-13 22:58:55 - train: epoch 0096, iter [01600, 05004], lr: 0.001195, loss: 0.7610
2022-07-13 22:59:49 - train: epoch 0096, iter [01700, 05004], lr: 0.001185, loss: 0.6510
2022-07-13 23:00:43 - train: epoch 0096, iter [01800, 05004], lr: 0.001175, loss: 0.8317
2022-07-13 23:01:36 - train: epoch 0096, iter [01900, 05004], lr: 0.001165, loss: 0.8214
2022-07-13 23:02:30 - train: epoch 0096, iter [02000, 05004], lr: 0.001155, loss: 0.7108
2022-07-13 23:03:23 - train: epoch 0096, iter [02100, 05004], lr: 0.001145, loss: 0.7989
2022-07-13 23:04:17 - train: epoch 0096, iter [02200, 05004], lr: 0.001135, loss: 0.5509
2022-07-13 23:05:11 - train: epoch 0096, iter [02300, 05004], lr: 0.001125, loss: 0.8226
2022-07-13 23:06:05 - train: epoch 0096, iter [02400, 05004], lr: 0.001115, loss: 0.8439
2022-07-13 23:06:59 - train: epoch 0096, iter [02500, 05004], lr: 0.001105, loss: 0.6394
2022-07-13 23:07:52 - train: epoch 0096, iter [02600, 05004], lr: 0.001096, loss: 0.8900
2022-07-13 23:08:46 - train: epoch 0096, iter [02700, 05004], lr: 0.001086, loss: 0.8502
2022-07-13 23:09:39 - train: epoch 0096, iter [02800, 05004], lr: 0.001076, loss: 0.9111
2022-07-13 23:10:33 - train: epoch 0096, iter [02900, 05004], lr: 0.001067, loss: 0.7215
2022-07-13 23:11:27 - train: epoch 0096, iter [03000, 05004], lr: 0.001057, loss: 0.7055
2022-07-13 23:12:21 - train: epoch 0096, iter [03100, 05004], lr: 0.001047, loss: 0.7053
2022-07-13 23:13:14 - train: epoch 0096, iter [03200, 05004], lr: 0.001038, loss: 0.8269
2022-07-13 23:14:07 - train: epoch 0096, iter [03300, 05004], lr: 0.001028, loss: 0.8811
2022-07-13 23:15:00 - train: epoch 0096, iter [03400, 05004], lr: 0.001019, loss: 0.7820
2022-07-13 23:15:53 - train: epoch 0096, iter [03500, 05004], lr: 0.001010, loss: 0.8127
2022-07-13 23:16:47 - train: epoch 0096, iter [03600, 05004], lr: 0.001000, loss: 0.7622
2022-07-13 23:17:40 - train: epoch 0096, iter [03700, 05004], lr: 0.000991, loss: 0.8939
2022-07-13 23:18:32 - train: epoch 0096, iter [03800, 05004], lr: 0.000982, loss: 0.7933
2022-07-13 23:19:26 - train: epoch 0096, iter [03900, 05004], lr: 0.000972, loss: 0.7104
2022-07-13 23:20:20 - train: epoch 0096, iter [04000, 05004], lr: 0.000963, loss: 0.7349
2022-07-13 23:21:13 - train: epoch 0096, iter [04100, 05004], lr: 0.000954, loss: 0.7704
2022-07-13 23:22:06 - train: epoch 0096, iter [04200, 05004], lr: 0.000945, loss: 0.7933
2022-07-13 23:23:00 - train: epoch 0096, iter [04300, 05004], lr: 0.000936, loss: 0.4481
2022-07-13 23:23:54 - train: epoch 0096, iter [04400, 05004], lr: 0.000927, loss: 0.7565
2022-07-13 23:24:48 - train: epoch 0096, iter [04500, 05004], lr: 0.000918, loss: 0.9646
2022-07-13 23:25:43 - train: epoch 0096, iter [04600, 05004], lr: 0.000909, loss: 0.8648
2022-07-13 23:26:37 - train: epoch 0096, iter [04700, 05004], lr: 0.000900, loss: 0.7644
2022-07-13 23:27:32 - train: epoch 0096, iter [04800, 05004], lr: 0.000891, loss: 0.9250
2022-07-13 23:28:26 - train: epoch 0096, iter [04900, 05004], lr: 0.000883, loss: 0.7310
2022-07-13 23:29:19 - train: epoch 0096, iter [05000, 05004], lr: 0.000874, loss: 0.8065
2022-07-13 23:29:21 - train: epoch 096, train_loss: 0.7934
2022-07-13 23:31:31 - eval: epoch: 096, acc1: 76.470%, acc5: 93.132%, test_loss: 0.9637, per_image_load_time: 2.361ms, per_image_inference_time: 0.850ms
2022-07-13 23:31:31 - until epoch: 096, best_acc1: 76.476%
2022-07-13 23:31:31 - epoch 097 lr: 0.000874
2022-07-13 23:32:40 - train: epoch 0097, iter [00100, 05004], lr: 0.000865, loss: 0.7597
2022-07-13 23:33:34 - train: epoch 0097, iter [00200, 05004], lr: 0.000856, loss: 0.7623
2022-07-13 23:34:27 - train: epoch 0097, iter [00300, 05004], lr: 0.000848, loss: 0.9744
2022-07-13 23:35:21 - train: epoch 0097, iter [00400, 05004], lr: 0.000839, loss: 0.9474
2022-07-13 23:36:13 - train: epoch 0097, iter [00500, 05004], lr: 0.000831, loss: 0.8060
2022-07-13 23:37:07 - train: epoch 0097, iter [00600, 05004], lr: 0.000822, loss: 0.9846
2022-07-13 23:37:59 - train: epoch 0097, iter [00700, 05004], lr: 0.000814, loss: 0.8640
2022-07-13 23:38:52 - train: epoch 0097, iter [00800, 05004], lr: 0.000805, loss: 0.6440
2022-07-13 23:39:44 - train: epoch 0097, iter [00900, 05004], lr: 0.000797, loss: 0.8454
2022-07-13 23:40:37 - train: epoch 0097, iter [01000, 05004], lr: 0.000789, loss: 0.9392
2022-07-13 23:41:30 - train: epoch 0097, iter [01100, 05004], lr: 0.000780, loss: 0.8609
2022-07-13 23:42:24 - train: epoch 0097, iter [01200, 05004], lr: 0.000772, loss: 0.8507
2022-07-13 23:43:18 - train: epoch 0097, iter [01300, 05004], lr: 0.000764, loss: 0.6449
2022-07-13 23:44:11 - train: epoch 0097, iter [01400, 05004], lr: 0.000756, loss: 0.7746
2022-07-13 23:45:05 - train: epoch 0097, iter [01500, 05004], lr: 0.000748, loss: 0.6182
2022-07-13 23:46:00 - train: epoch 0097, iter [01600, 05004], lr: 0.000740, loss: 0.7684
2022-07-13 23:46:54 - train: epoch 0097, iter [01700, 05004], lr: 0.000732, loss: 0.8396
2022-07-13 23:47:48 - train: epoch 0097, iter [01800, 05004], lr: 0.000724, loss: 0.9917
2022-07-13 23:48:43 - train: epoch 0097, iter [01900, 05004], lr: 0.000716, loss: 0.7744
2022-07-13 23:49:38 - train: epoch 0097, iter [02000, 05004], lr: 0.000708, loss: 0.7582
2022-07-13 23:50:31 - train: epoch 0097, iter [02100, 05004], lr: 0.000700, loss: 0.7576
2022-07-13 23:51:26 - train: epoch 0097, iter [02200, 05004], lr: 0.000692, loss: 0.7897
2022-07-13 23:52:18 - train: epoch 0097, iter [02300, 05004], lr: 0.000685, loss: 0.7951
2022-07-13 23:53:13 - train: epoch 0097, iter [02400, 05004], lr: 0.000677, loss: 0.8394
2022-07-13 23:54:06 - train: epoch 0097, iter [02500, 05004], lr: 0.000669, loss: 0.8043
2022-07-13 23:54:59 - train: epoch 0097, iter [02600, 05004], lr: 0.000662, loss: 0.8668
2022-07-13 23:55:54 - train: epoch 0097, iter [02700, 05004], lr: 0.000654, loss: 0.7431
2022-07-13 23:56:48 - train: epoch 0097, iter [02800, 05004], lr: 0.000647, loss: 0.8895
2022-07-13 23:57:43 - train: epoch 0097, iter [02900, 05004], lr: 0.000639, loss: 0.8374
2022-07-13 23:58:37 - train: epoch 0097, iter [03000, 05004], lr: 0.000632, loss: 0.7044
2022-07-13 23:59:29 - train: epoch 0097, iter [03100, 05004], lr: 0.000624, loss: 0.7685
2022-07-14 00:00:22 - train: epoch 0097, iter [03200, 05004], lr: 0.000617, loss: 0.8440
2022-07-14 00:01:15 - train: epoch 0097, iter [03300, 05004], lr: 0.000610, loss: 0.8538
2022-07-14 00:02:07 - train: epoch 0097, iter [03400, 05004], lr: 0.000602, loss: 0.7836
2022-07-14 00:03:00 - train: epoch 0097, iter [03500, 05004], lr: 0.000595, loss: 0.7076
2022-07-14 00:03:53 - train: epoch 0097, iter [03600, 05004], lr: 0.000588, loss: 0.8476
2022-07-14 00:04:45 - train: epoch 0097, iter [03700, 05004], lr: 0.000581, loss: 0.6076
2022-07-14 00:05:38 - train: epoch 0097, iter [03800, 05004], lr: 0.000574, loss: 0.7726
2022-07-14 00:06:30 - train: epoch 0097, iter [03900, 05004], lr: 0.000567, loss: 0.7688
2022-07-14 00:07:22 - train: epoch 0097, iter [04000, 05004], lr: 0.000560, loss: 0.8231
2022-07-14 00:08:15 - train: epoch 0097, iter [04100, 05004], lr: 0.000553, loss: 0.6934
2022-07-14 00:09:08 - train: epoch 0097, iter [04200, 05004], lr: 0.000546, loss: 0.6988
2022-07-14 00:10:01 - train: epoch 0097, iter [04300, 05004], lr: 0.000539, loss: 0.8057
2022-07-14 00:10:54 - train: epoch 0097, iter [04400, 05004], lr: 0.000532, loss: 0.7297
2022-07-14 00:11:45 - train: epoch 0097, iter [04500, 05004], lr: 0.000525, loss: 0.8000
2022-07-14 00:12:38 - train: epoch 0097, iter [04600, 05004], lr: 0.000519, loss: 0.7461
2022-07-14 00:13:31 - train: epoch 0097, iter [04700, 05004], lr: 0.000512, loss: 0.7650
2022-07-14 00:14:25 - train: epoch 0097, iter [04800, 05004], lr: 0.000505, loss: 0.8252
2022-07-14 00:15:18 - train: epoch 0097, iter [04900, 05004], lr: 0.000499, loss: 0.9250
2022-07-14 00:16:10 - train: epoch 0097, iter [05000, 05004], lr: 0.000492, loss: 0.6573
2022-07-14 00:16:12 - train: epoch 097, train_loss: 0.7839
2022-07-14 00:18:22 - eval: epoch: 097, acc1: 76.514%, acc5: 93.158%, test_loss: 0.9601, per_image_load_time: 2.113ms, per_image_inference_time: 0.869ms
2022-07-14 00:18:22 - until epoch: 097, best_acc1: 76.514%
2022-07-14 00:18:22 - epoch 098 lr: 0.000492
2022-07-14 00:19:29 - train: epoch 0098, iter [00100, 05004], lr: 0.000485, loss: 0.8296
2022-07-14 00:20:22 - train: epoch 0098, iter [00200, 05004], lr: 0.000479, loss: 1.0422
2022-07-14 00:21:15 - train: epoch 0098, iter [00300, 05004], lr: 0.000472, loss: 0.8415
2022-07-14 00:22:09 - train: epoch 0098, iter [00400, 05004], lr: 0.000466, loss: 0.6470
2022-07-14 00:23:03 - train: epoch 0098, iter [00500, 05004], lr: 0.000460, loss: 0.8999
2022-07-14 00:23:57 - train: epoch 0098, iter [00600, 05004], lr: 0.000453, loss: 0.8809
2022-07-14 00:24:51 - train: epoch 0098, iter [00700, 05004], lr: 0.000447, loss: 0.9372
2022-07-14 00:25:44 - train: epoch 0098, iter [00800, 05004], lr: 0.000441, loss: 0.8652
2022-07-14 00:26:38 - train: epoch 0098, iter [00900, 05004], lr: 0.000435, loss: 0.9225
2022-07-14 00:27:32 - train: epoch 0098, iter [01000, 05004], lr: 0.000428, loss: 1.0643
2022-07-14 00:28:25 - train: epoch 0098, iter [01100, 05004], lr: 0.000422, loss: 0.7599
2022-07-14 00:29:19 - train: epoch 0098, iter [01200, 05004], lr: 0.000416, loss: 0.7062
2022-07-14 00:30:12 - train: epoch 0098, iter [01300, 05004], lr: 0.000410, loss: 0.6980
2022-07-14 00:31:05 - train: epoch 0098, iter [01400, 05004], lr: 0.000404, loss: 0.8387
2022-07-14 00:31:59 - train: epoch 0098, iter [01500, 05004], lr: 0.000398, loss: 0.7433
2022-07-14 00:32:52 - train: epoch 0098, iter [01600, 05004], lr: 0.000393, loss: 0.7042
2022-07-14 00:33:45 - train: epoch 0098, iter [01700, 05004], lr: 0.000387, loss: 0.8491
2022-07-14 00:34:39 - train: epoch 0098, iter [01800, 05004], lr: 0.000381, loss: 0.6859
2022-07-14 00:35:33 - train: epoch 0098, iter [01900, 05004], lr: 0.000375, loss: 0.6163
2022-07-14 00:36:27 - train: epoch 0098, iter [02000, 05004], lr: 0.000369, loss: 0.9090
2022-07-14 00:37:21 - train: epoch 0098, iter [02100, 05004], lr: 0.000364, loss: 0.8707
2022-07-14 00:38:15 - train: epoch 0098, iter [02200, 05004], lr: 0.000358, loss: 0.6931
2022-07-14 00:39:08 - train: epoch 0098, iter [02300, 05004], lr: 0.000353, loss: 0.7038
2022-07-14 00:40:01 - train: epoch 0098, iter [02400, 05004], lr: 0.000347, loss: 0.7208
2022-07-14 00:40:54 - train: epoch 0098, iter [02500, 05004], lr: 0.000342, loss: 0.7935
2022-07-14 00:41:48 - train: epoch 0098, iter [02600, 05004], lr: 0.000336, loss: 0.7144
2022-07-14 00:42:42 - train: epoch 0098, iter [02700, 05004], lr: 0.000331, loss: 0.7389
2022-07-14 00:43:35 - train: epoch 0098, iter [02800, 05004], lr: 0.000325, loss: 0.7488
2022-07-14 00:44:29 - train: epoch 0098, iter [02900, 05004], lr: 0.000320, loss: 0.6712
2022-07-14 00:45:22 - train: epoch 0098, iter [03000, 05004], lr: 0.000315, loss: 0.8950
2022-07-14 00:46:17 - train: epoch 0098, iter [03100, 05004], lr: 0.000310, loss: 0.8321
2022-07-14 00:47:10 - train: epoch 0098, iter [03200, 05004], lr: 0.000305, loss: 0.7614
2022-07-14 00:48:03 - train: epoch 0098, iter [03300, 05004], lr: 0.000299, loss: 0.8485
2022-07-14 00:48:56 - train: epoch 0098, iter [03400, 05004], lr: 0.000294, loss: 0.8562
2022-07-14 00:49:50 - train: epoch 0098, iter [03500, 05004], lr: 0.000289, loss: 0.8052
2022-07-14 00:50:44 - train: epoch 0098, iter [03600, 05004], lr: 0.000284, loss: 0.9017
2022-07-14 00:51:36 - train: epoch 0098, iter [03700, 05004], lr: 0.000279, loss: 0.7419
2022-07-14 00:52:29 - train: epoch 0098, iter [03800, 05004], lr: 0.000274, loss: 0.6903
2022-07-14 00:53:23 - train: epoch 0098, iter [03900, 05004], lr: 0.000270, loss: 0.8128
2022-07-14 00:54:16 - train: epoch 0098, iter [04000, 05004], lr: 0.000265, loss: 0.9899
2022-07-14 00:55:10 - train: epoch 0098, iter [04100, 05004], lr: 0.000260, loss: 0.6394
2022-07-14 00:56:04 - train: epoch 0098, iter [04200, 05004], lr: 0.000255, loss: 0.7189
2022-07-14 00:56:58 - train: epoch 0098, iter [04300, 05004], lr: 0.000250, loss: 0.6626
2022-07-14 00:57:52 - train: epoch 0098, iter [04400, 05004], lr: 0.000246, loss: 0.7596
2022-07-14 00:58:46 - train: epoch 0098, iter [04500, 05004], lr: 0.000241, loss: 0.7072
2022-07-14 00:59:40 - train: epoch 0098, iter [04600, 05004], lr: 0.000237, loss: 0.7762
2022-07-14 01:00:34 - train: epoch 0098, iter [04700, 05004], lr: 0.000232, loss: 0.7338
2022-07-14 01:01:28 - train: epoch 0098, iter [04800, 05004], lr: 0.000228, loss: 0.6309
2022-07-14 01:02:21 - train: epoch 0098, iter [04900, 05004], lr: 0.000223, loss: 0.8465
2022-07-14 01:03:14 - train: epoch 0098, iter [05000, 05004], lr: 0.000219, loss: 0.7710
2022-07-14 01:03:16 - train: epoch 098, train_loss: 0.7773
2022-07-14 01:05:25 - eval: epoch: 098, acc1: 76.506%, acc5: 93.132%, test_loss: 0.9603, per_image_load_time: 1.988ms, per_image_inference_time: 0.897ms
2022-07-14 01:05:25 - until epoch: 098, best_acc1: 76.514%
2022-07-14 01:05:25 - epoch 099 lr: 0.000219
2022-07-14 01:06:33 - train: epoch 0099, iter [00100, 05004], lr: 0.000214, loss: 0.8944
2022-07-14 01:07:26 - train: epoch 0099, iter [00200, 05004], lr: 0.000210, loss: 0.7528
2022-07-14 01:08:18 - train: epoch 0099, iter [00300, 05004], lr: 0.000206, loss: 0.7157
2022-07-14 01:09:11 - train: epoch 0099, iter [00400, 05004], lr: 0.000202, loss: 0.7783
2022-07-14 01:10:04 - train: epoch 0099, iter [00500, 05004], lr: 0.000197, loss: 0.8541
2022-07-14 01:10:58 - train: epoch 0099, iter [00600, 05004], lr: 0.000193, loss: 0.8044
2022-07-14 01:11:50 - train: epoch 0099, iter [00700, 05004], lr: 0.000189, loss: 0.7922
2022-07-14 01:12:43 - train: epoch 0099, iter [00800, 05004], lr: 0.000185, loss: 0.8553
2022-07-14 01:13:35 - train: epoch 0099, iter [00900, 05004], lr: 0.000181, loss: 0.6961
2022-07-14 01:14:28 - train: epoch 0099, iter [01000, 05004], lr: 0.000177, loss: 0.7016
2022-07-14 01:15:22 - train: epoch 0099, iter [01100, 05004], lr: 0.000173, loss: 0.6444
2022-07-14 01:16:15 - train: epoch 0099, iter [01200, 05004], lr: 0.000169, loss: 0.6358
2022-07-14 01:17:08 - train: epoch 0099, iter [01300, 05004], lr: 0.000166, loss: 0.6695
2022-07-14 01:18:02 - train: epoch 0099, iter [01400, 05004], lr: 0.000162, loss: 0.8097
2022-07-14 01:18:55 - train: epoch 0099, iter [01500, 05004], lr: 0.000158, loss: 0.7814
2022-07-14 01:19:47 - train: epoch 0099, iter [01600, 05004], lr: 0.000154, loss: 0.7972
2022-07-14 01:20:40 - train: epoch 0099, iter [01700, 05004], lr: 0.000151, loss: 0.6518
2022-07-14 01:21:34 - train: epoch 0099, iter [01800, 05004], lr: 0.000147, loss: 0.8527
2022-07-14 01:22:28 - train: epoch 0099, iter [01900, 05004], lr: 0.000144, loss: 0.8662
2022-07-14 01:23:22 - train: epoch 0099, iter [02000, 05004], lr: 0.000140, loss: 0.7735
2022-07-14 01:24:15 - train: epoch 0099, iter [02100, 05004], lr: 0.000137, loss: 0.8173
2022-07-14 01:25:09 - train: epoch 0099, iter [02200, 05004], lr: 0.000133, loss: 0.7334
2022-07-14 01:26:02 - train: epoch 0099, iter [02300, 05004], lr: 0.000130, loss: 0.7757
2022-07-14 01:26:56 - train: epoch 0099, iter [02400, 05004], lr: 0.000126, loss: 0.8025
2022-07-14 01:27:50 - train: epoch 0099, iter [02500, 05004], lr: 0.000123, loss: 0.6651
2022-07-14 01:28:44 - train: epoch 0099, iter [02600, 05004], lr: 0.000120, loss: 0.7344
2022-07-14 01:29:37 - train: epoch 0099, iter [02700, 05004], lr: 0.000117, loss: 0.6149
2022-07-14 01:30:32 - train: epoch 0099, iter [02800, 05004], lr: 0.000113, loss: 0.9167
2022-07-14 01:31:26 - train: epoch 0099, iter [02900, 05004], lr: 0.000110, loss: 0.8483
2022-07-14 01:32:19 - train: epoch 0099, iter [03000, 05004], lr: 0.000107, loss: 0.7838
2022-07-14 01:33:13 - train: epoch 0099, iter [03100, 05004], lr: 0.000104, loss: 0.6536
2022-07-14 01:34:07 - train: epoch 0099, iter [03200, 05004], lr: 0.000101, loss: 0.7637
2022-07-14 01:35:01 - train: epoch 0099, iter [03300, 05004], lr: 0.000098, loss: 0.6778
2022-07-14 01:35:54 - train: epoch 0099, iter [03400, 05004], lr: 0.000095, loss: 0.8028
2022-07-14 01:36:48 - train: epoch 0099, iter [03500, 05004], lr: 0.000092, loss: 0.6983
2022-07-14 01:37:41 - train: epoch 0099, iter [03600, 05004], lr: 0.000090, loss: 0.7348
2022-07-14 01:38:35 - train: epoch 0099, iter [03700, 05004], lr: 0.000087, loss: 0.5456
2022-07-14 01:39:28 - train: epoch 0099, iter [03800, 05004], lr: 0.000084, loss: 0.8153
2022-07-14 01:40:22 - train: epoch 0099, iter [03900, 05004], lr: 0.000081, loss: 0.7669
2022-07-14 01:41:15 - train: epoch 0099, iter [04000, 05004], lr: 0.000079, loss: 0.8963
2022-07-14 01:42:09 - train: epoch 0099, iter [04100, 05004], lr: 0.000076, loss: 0.6914
2022-07-14 01:43:02 - train: epoch 0099, iter [04200, 05004], lr: 0.000074, loss: 0.8062
2022-07-14 01:43:56 - train: epoch 0099, iter [04300, 05004], lr: 0.000071, loss: 0.8268
2022-07-14 01:44:50 - train: epoch 0099, iter [04400, 05004], lr: 0.000069, loss: 0.6726
2022-07-14 01:45:44 - train: epoch 0099, iter [04500, 05004], lr: 0.000066, loss: 0.8565
2022-07-14 01:46:37 - train: epoch 0099, iter [04600, 05004], lr: 0.000064, loss: 0.8378
2022-07-14 01:47:30 - train: epoch 0099, iter [04700, 05004], lr: 0.000062, loss: 0.8466
2022-07-14 01:48:24 - train: epoch 0099, iter [04800, 05004], lr: 0.000059, loss: 0.7895
2022-07-14 01:49:17 - train: epoch 0099, iter [04900, 05004], lr: 0.000057, loss: 0.8703
2022-07-14 01:50:10 - train: epoch 0099, iter [05000, 05004], lr: 0.000055, loss: 0.7659
2022-07-14 01:50:12 - train: epoch 099, train_loss: 0.7734
2022-07-14 01:52:24 - eval: epoch: 099, acc1: 76.586%, acc5: 93.140%, test_loss: 0.9604, per_image_load_time: 3.960ms, per_image_inference_time: 0.840ms
2022-07-14 01:52:24 - until epoch: 099, best_acc1: 76.586%
2022-07-14 01:52:24 - epoch 100 lr: 0.000055
2022-07-14 01:53:31 - train: epoch 0100, iter [00100, 05004], lr: 0.000053, loss: 0.8326
2022-07-14 01:54:23 - train: epoch 0100, iter [00200, 05004], lr: 0.000050, loss: 0.7524
2022-07-14 01:55:17 - train: epoch 0100, iter [00300, 05004], lr: 0.000048, loss: 0.8373
2022-07-14 01:56:11 - train: epoch 0100, iter [00400, 05004], lr: 0.000046, loss: 0.6591
2022-07-14 01:57:04 - train: epoch 0100, iter [00500, 05004], lr: 0.000044, loss: 0.7744
2022-07-14 01:57:58 - train: epoch 0100, iter [00600, 05004], lr: 0.000042, loss: 0.7730
2022-07-14 01:58:51 - train: epoch 0100, iter [00700, 05004], lr: 0.000040, loss: 0.7398
2022-07-14 01:59:44 - train: epoch 0100, iter [00800, 05004], lr: 0.000039, loss: 0.6585
2022-07-14 02:00:38 - train: epoch 0100, iter [00900, 05004], lr: 0.000037, loss: 0.7371
2022-07-14 02:01:31 - train: epoch 0100, iter [01000, 05004], lr: 0.000035, loss: 0.7996
2022-07-14 02:02:25 - train: epoch 0100, iter [01100, 05004], lr: 0.000033, loss: 0.6544
2022-07-14 02:03:19 - train: epoch 0100, iter [01200, 05004], lr: 0.000032, loss: 0.6481
2022-07-14 02:04:12 - train: epoch 0100, iter [01300, 05004], lr: 0.000030, loss: 0.6876
2022-07-14 02:05:06 - train: epoch 0100, iter [01400, 05004], lr: 0.000028, loss: 0.7139
2022-07-14 02:05:59 - train: epoch 0100, iter [01500, 05004], lr: 0.000027, loss: 0.7444
2022-07-14 02:06:53 - train: epoch 0100, iter [01600, 05004], lr: 0.000025, loss: 0.7317
2022-07-14 02:07:47 - train: epoch 0100, iter [01700, 05004], lr: 0.000024, loss: 0.7571
2022-07-14 02:08:41 - train: epoch 0100, iter [01800, 05004], lr: 0.000022, loss: 0.6804
2022-07-14 02:09:35 - train: epoch 0100, iter [01900, 05004], lr: 0.000021, loss: 0.8146
2022-07-14 02:10:28 - train: epoch 0100, iter [02000, 05004], lr: 0.000020, loss: 0.8767
2022-07-14 02:11:23 - train: epoch 0100, iter [02100, 05004], lr: 0.000018, loss: 0.7712
2022-07-14 02:12:17 - train: epoch 0100, iter [02200, 05004], lr: 0.000017, loss: 0.8093
2022-07-14 02:13:12 - train: epoch 0100, iter [02300, 05004], lr: 0.000016, loss: 0.7461
2022-07-14 02:14:06 - train: epoch 0100, iter [02400, 05004], lr: 0.000015, loss: 0.9901
2022-07-14 02:15:01 - train: epoch 0100, iter [02500, 05004], lr: 0.000014, loss: 0.8016
2022-07-14 02:15:55 - train: epoch 0100, iter [02600, 05004], lr: 0.000013, loss: 0.7578
2022-07-14 02:16:49 - train: epoch 0100, iter [02700, 05004], lr: 0.000012, loss: 0.7611
2022-07-14 02:17:43 - train: epoch 0100, iter [02800, 05004], lr: 0.000011, loss: 0.6853
2022-07-14 02:18:37 - train: epoch 0100, iter [02900, 05004], lr: 0.000010, loss: 0.7158
2022-07-14 02:19:32 - train: epoch 0100, iter [03000, 05004], lr: 0.000009, loss: 0.7360
2022-07-14 02:20:26 - train: epoch 0100, iter [03100, 05004], lr: 0.000008, loss: 0.6033
2022-07-14 02:21:20 - train: epoch 0100, iter [03200, 05004], lr: 0.000007, loss: 0.8782
2022-07-14 02:22:14 - train: epoch 0100, iter [03300, 05004], lr: 0.000006, loss: 0.7403
2022-07-14 02:23:08 - train: epoch 0100, iter [03400, 05004], lr: 0.000006, loss: 0.7049
2022-07-14 02:24:02 - train: epoch 0100, iter [03500, 05004], lr: 0.000005, loss: 0.7017
2022-07-14 02:24:57 - train: epoch 0100, iter [03600, 05004], lr: 0.000004, loss: 0.8121
2022-07-14 02:25:50 - train: epoch 0100, iter [03700, 05004], lr: 0.000004, loss: 0.6366
2022-07-14 02:26:44 - train: epoch 0100, iter [03800, 05004], lr: 0.000003, loss: 0.7828
2022-07-14 02:27:39 - train: epoch 0100, iter [03900, 05004], lr: 0.000003, loss: 0.7454
2022-07-14 02:28:34 - train: epoch 0100, iter [04000, 05004], lr: 0.000002, loss: 0.6643
2022-07-14 02:29:28 - train: epoch 0100, iter [04100, 05004], lr: 0.000002, loss: 1.0192
2022-07-14 02:30:23 - train: epoch 0100, iter [04200, 05004], lr: 0.000001, loss: 0.8635
2022-07-14 02:31:18 - train: epoch 0100, iter [04300, 05004], lr: 0.000001, loss: 0.7247
2022-07-14 02:32:11 - train: epoch 0100, iter [04400, 05004], lr: 0.000001, loss: 0.7600
2022-07-14 02:33:06 - train: epoch 0100, iter [04500, 05004], lr: 0.000001, loss: 0.6123
2022-07-14 02:34:01 - train: epoch 0100, iter [04600, 05004], lr: 0.000000, loss: 0.7013
2022-07-14 02:34:55 - train: epoch 0100, iter [04700, 05004], lr: 0.000000, loss: 0.7996
2022-07-14 02:35:50 - train: epoch 0100, iter [04800, 05004], lr: 0.000000, loss: 0.6040
2022-07-14 02:36:44 - train: epoch 0100, iter [04900, 05004], lr: 0.000000, loss: 0.7084
2022-07-14 02:37:37 - train: epoch 0100, iter [05000, 05004], lr: 0.000000, loss: 0.9081
2022-07-14 02:37:40 - train: epoch 100, train_loss: 0.7711
2022-07-14 02:39:51 - eval: epoch: 100, acc1: 76.522%, acc5: 93.128%, test_loss: 0.9604, per_image_load_time: 4.179ms, per_image_inference_time: 0.905ms
2022-07-14 02:39:51 - until epoch: 100, best_acc1: 76.586%
2022-07-14 02:39:51 - train done. model: RegNetX_1_6GF, train time: 82.450 hours, best_acc1: 76.586%
