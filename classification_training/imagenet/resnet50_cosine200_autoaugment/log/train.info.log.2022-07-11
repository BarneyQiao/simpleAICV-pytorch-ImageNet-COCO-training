2022-07-11 20:50:07 - train: epoch 0118, iter [00100, 05004], lr: 0.038410, loss: 1.8355
2022-07-11 20:50:43 - train: epoch 0118, iter [00200, 05004], lr: 0.038394, loss: 2.0869
2022-07-11 20:51:17 - train: epoch 0118, iter [00300, 05004], lr: 0.038379, loss: 2.2003
2022-07-11 20:51:52 - train: epoch 0118, iter [00400, 05004], lr: 0.038363, loss: 2.1895
2022-07-11 20:52:25 - train: epoch 0118, iter [00500, 05004], lr: 0.038347, loss: 1.9168
2022-07-11 20:53:00 - train: epoch 0118, iter [00600, 05004], lr: 0.038332, loss: 1.9611
2022-07-11 20:53:35 - train: epoch 0118, iter [00700, 05004], lr: 0.038316, loss: 2.2444
2022-07-11 20:54:10 - train: epoch 0118, iter [00800, 05004], lr: 0.038300, loss: 2.1180
2022-07-11 20:54:45 - train: epoch 0118, iter [00900, 05004], lr: 0.038285, loss: 2.2267
2022-07-11 20:55:19 - train: epoch 0118, iter [01000, 05004], lr: 0.038269, loss: 2.1508
2022-07-11 20:55:54 - train: epoch 0118, iter [01100, 05004], lr: 0.038253, loss: 2.2472
2022-07-11 20:56:28 - train: epoch 0118, iter [01200, 05004], lr: 0.038238, loss: 2.1504
2022-07-11 20:57:03 - train: epoch 0118, iter [01300, 05004], lr: 0.038222, loss: 2.1815
2022-07-11 20:57:37 - train: epoch 0118, iter [01400, 05004], lr: 0.038207, loss: 1.9558
2022-07-11 20:58:13 - train: epoch 0118, iter [01500, 05004], lr: 0.038191, loss: 2.2675
2022-07-11 20:58:48 - train: epoch 0118, iter [01600, 05004], lr: 0.038175, loss: 2.0826
2022-07-11 20:59:23 - train: epoch 0118, iter [01700, 05004], lr: 0.038160, loss: 1.9868
2022-07-11 20:59:57 - train: epoch 0118, iter [01800, 05004], lr: 0.038144, loss: 1.9658
2022-07-11 21:00:32 - train: epoch 0118, iter [01900, 05004], lr: 0.038128, loss: 2.1831
2022-07-11 21:01:06 - train: epoch 0118, iter [02000, 05004], lr: 0.038113, loss: 1.7242
2022-07-11 21:01:40 - train: epoch 0118, iter [02100, 05004], lr: 0.038097, loss: 1.7677
2022-07-11 21:02:15 - train: epoch 0118, iter [02200, 05004], lr: 0.038081, loss: 2.0969
2022-07-11 21:02:49 - train: epoch 0118, iter [02300, 05004], lr: 0.038066, loss: 1.8691
2022-07-11 21:03:23 - train: epoch 0118, iter [02400, 05004], lr: 0.038050, loss: 2.0678
2022-07-11 21:03:59 - train: epoch 0118, iter [02500, 05004], lr: 0.038035, loss: 2.1071
2022-07-11 21:04:33 - train: epoch 0118, iter [02600, 05004], lr: 0.038019, loss: 1.7446
2022-07-11 21:05:07 - train: epoch 0118, iter [02700, 05004], lr: 0.038003, loss: 2.1025
2022-07-11 21:05:41 - train: epoch 0118, iter [02800, 05004], lr: 0.037988, loss: 2.0542
2022-07-11 21:06:17 - train: epoch 0118, iter [02900, 05004], lr: 0.037972, loss: 2.1979
2022-07-11 21:06:52 - train: epoch 0118, iter [03000, 05004], lr: 0.037956, loss: 1.9044
2022-07-11 21:07:26 - train: epoch 0118, iter [03100, 05004], lr: 0.037941, loss: 2.2126
2022-07-11 21:08:01 - train: epoch 0118, iter [03200, 05004], lr: 0.037925, loss: 2.0579
2022-07-11 21:08:36 - train: epoch 0118, iter [03300, 05004], lr: 0.037910, loss: 2.1525
2022-07-11 21:09:11 - train: epoch 0118, iter [03400, 05004], lr: 0.037894, loss: 2.2231
2022-07-11 21:09:44 - train: epoch 0118, iter [03500, 05004], lr: 0.037878, loss: 2.0556
2022-07-11 21:10:20 - train: epoch 0118, iter [03600, 05004], lr: 0.037863, loss: 2.0657
2022-07-11 21:10:55 - train: epoch 0118, iter [03700, 05004], lr: 0.037847, loss: 1.8750
2022-07-11 21:11:30 - train: epoch 0118, iter [03800, 05004], lr: 0.037831, loss: 2.2832
2022-07-11 21:12:05 - train: epoch 0118, iter [03900, 05004], lr: 0.037816, loss: 2.2583
2022-07-11 21:12:40 - train: epoch 0118, iter [04000, 05004], lr: 0.037800, loss: 2.3840
2022-07-11 21:13:14 - train: epoch 0118, iter [04100, 05004], lr: 0.037785, loss: 2.2385
2022-07-11 21:13:49 - train: epoch 0118, iter [04200, 05004], lr: 0.037769, loss: 2.2892
2022-07-11 21:14:24 - train: epoch 0118, iter [04300, 05004], lr: 0.037753, loss: 2.0678
2022-07-11 21:14:59 - train: epoch 0118, iter [04400, 05004], lr: 0.037738, loss: 2.2787
2022-07-11 21:15:34 - train: epoch 0118, iter [04500, 05004], lr: 0.037722, loss: 1.9905
2022-07-11 21:16:09 - train: epoch 0118, iter [04600, 05004], lr: 0.037707, loss: 2.1636
2022-07-11 21:16:43 - train: epoch 0118, iter [04700, 05004], lr: 0.037691, loss: 2.1976
2022-07-11 21:17:18 - train: epoch 0118, iter [04800, 05004], lr: 0.037675, loss: 2.1443
2022-07-11 21:17:52 - train: epoch 0118, iter [04900, 05004], lr: 0.037660, loss: 2.3068
2022-07-11 21:18:26 - train: epoch 0118, iter [05000, 05004], lr: 0.037644, loss: 2.1206
2022-07-11 21:18:27 - train: epoch 118, train_loss: 2.0909
2022-07-11 21:19:42 - eval: epoch: 118, acc1: 65.868%, acc5: 87.658%, test_loss: 1.3868, per_image_load_time: 0.884ms, per_image_inference_time: 0.458ms
2022-07-11 21:19:42 - until epoch: 118, best_acc1: 66.242%
2022-07-11 21:19:42 - epoch 119 lr: 0.037643
2022-07-11 21:20:23 - train: epoch 0119, iter [00100, 05004], lr: 0.037628, loss: 2.3295
2022-07-11 21:20:57 - train: epoch 0119, iter [00200, 05004], lr: 0.037612, loss: 2.0923
2022-07-11 21:21:32 - train: epoch 0119, iter [00300, 05004], lr: 0.037597, loss: 1.9755
2022-07-11 21:22:05 - train: epoch 0119, iter [00400, 05004], lr: 0.037581, loss: 1.7140
2022-07-11 21:22:39 - train: epoch 0119, iter [00500, 05004], lr: 0.037566, loss: 1.8742
2022-07-11 21:23:13 - train: epoch 0119, iter [00600, 05004], lr: 0.037550, loss: 1.9794
2022-07-11 21:23:47 - train: epoch 0119, iter [00700, 05004], lr: 0.037534, loss: 2.0192
2022-07-11 21:24:22 - train: epoch 0119, iter [00800, 05004], lr: 0.037519, loss: 1.9098
2022-07-11 21:24:56 - train: epoch 0119, iter [00900, 05004], lr: 0.037503, loss: 2.1189
2022-07-11 21:25:31 - train: epoch 0119, iter [01000, 05004], lr: 0.037488, loss: 2.0157
2022-07-11 21:26:06 - train: epoch 0119, iter [01100, 05004], lr: 0.037472, loss: 2.0847
2022-07-11 21:26:40 - train: epoch 0119, iter [01200, 05004], lr: 0.037456, loss: 1.9793
2022-07-11 21:27:15 - train: epoch 0119, iter [01300, 05004], lr: 0.037441, loss: 2.2175
2022-07-11 21:27:49 - train: epoch 0119, iter [01400, 05004], lr: 0.037425, loss: 2.1679
2022-07-11 21:28:24 - train: epoch 0119, iter [01500, 05004], lr: 0.037410, loss: 1.9031
2022-07-11 21:28:58 - train: epoch 0119, iter [01600, 05004], lr: 0.037394, loss: 2.0642
2022-07-11 21:29:33 - train: epoch 0119, iter [01700, 05004], lr: 0.037379, loss: 2.2707
2022-07-11 21:30:07 - train: epoch 0119, iter [01800, 05004], lr: 0.037363, loss: 2.1170
2022-07-11 21:30:41 - train: epoch 0119, iter [01900, 05004], lr: 0.037347, loss: 2.1814
2022-07-11 21:31:15 - train: epoch 0119, iter [02000, 05004], lr: 0.037332, loss: 1.9477
2022-07-11 21:31:51 - train: epoch 0119, iter [02100, 05004], lr: 0.037316, loss: 2.1296
2022-07-11 21:32:25 - train: epoch 0119, iter [02200, 05004], lr: 0.037301, loss: 2.0467
2022-07-11 21:33:00 - train: epoch 0119, iter [02300, 05004], lr: 0.037285, loss: 1.5330
2022-07-11 21:33:35 - train: epoch 0119, iter [02400, 05004], lr: 0.037270, loss: 2.0955
2022-07-11 21:34:10 - train: epoch 0119, iter [02500, 05004], lr: 0.037254, loss: 2.2786
2022-07-11 21:34:45 - train: epoch 0119, iter [02600, 05004], lr: 0.037238, loss: 2.3850
2022-07-11 21:35:20 - train: epoch 0119, iter [02700, 05004], lr: 0.037223, loss: 2.2884
2022-07-11 21:35:54 - train: epoch 0119, iter [02800, 05004], lr: 0.037207, loss: 2.1998
2022-07-11 21:36:28 - train: epoch 0119, iter [02900, 05004], lr: 0.037192, loss: 2.1330
2022-07-11 21:37:03 - train: epoch 0119, iter [03000, 05004], lr: 0.037176, loss: 1.7617
2022-07-11 21:37:38 - train: epoch 0119, iter [03100, 05004], lr: 0.037161, loss: 1.9786
2022-07-11 21:38:12 - train: epoch 0119, iter [03200, 05004], lr: 0.037145, loss: 2.0952
2022-07-11 21:38:48 - train: epoch 0119, iter [03300, 05004], lr: 0.037129, loss: 2.0327
2022-07-11 21:39:22 - train: epoch 0119, iter [03400, 05004], lr: 0.037114, loss: 2.3302
2022-07-11 21:39:57 - train: epoch 0119, iter [03500, 05004], lr: 0.037098, loss: 1.7437
2022-07-11 21:40:31 - train: epoch 0119, iter [03600, 05004], lr: 0.037083, loss: 2.2945
2022-07-11 21:41:06 - train: epoch 0119, iter [03700, 05004], lr: 0.037067, loss: 2.0253
2022-07-11 21:41:41 - train: epoch 0119, iter [03800, 05004], lr: 0.037052, loss: 2.1655
2022-07-11 21:42:16 - train: epoch 0119, iter [03900, 05004], lr: 0.037036, loss: 2.5130
2022-07-11 21:42:50 - train: epoch 0119, iter [04000, 05004], lr: 0.037021, loss: 1.8684
2022-07-11 21:43:25 - train: epoch 0119, iter [04100, 05004], lr: 0.037005, loss: 2.0977
2022-07-11 21:44:00 - train: epoch 0119, iter [04200, 05004], lr: 0.036990, loss: 2.1175
2022-07-11 21:44:35 - train: epoch 0119, iter [04300, 05004], lr: 0.036974, loss: 1.9595
2022-07-11 21:45:09 - train: epoch 0119, iter [04400, 05004], lr: 0.036958, loss: 1.9385
2022-07-11 21:45:44 - train: epoch 0119, iter [04500, 05004], lr: 0.036943, loss: 2.0997
2022-07-11 21:46:19 - train: epoch 0119, iter [04600, 05004], lr: 0.036927, loss: 2.1269
2022-07-11 21:46:54 - train: epoch 0119, iter [04700, 05004], lr: 0.036912, loss: 1.9552
2022-07-11 21:47:29 - train: epoch 0119, iter [04800, 05004], lr: 0.036896, loss: 2.2031
2022-07-11 21:48:04 - train: epoch 0119, iter [04900, 05004], lr: 0.036881, loss: 2.3142
2022-07-11 21:48:37 - train: epoch 0119, iter [05000, 05004], lr: 0.036865, loss: 2.2444
2022-07-11 21:48:38 - train: epoch 119, train_loss: 2.0799
2022-07-11 21:49:53 - eval: epoch: 119, acc1: 65.334%, acc5: 87.088%, test_loss: 1.4214, per_image_load_time: 2.466ms, per_image_inference_time: 0.431ms
2022-07-11 21:49:53 - until epoch: 119, best_acc1: 66.242%
2022-07-11 21:49:53 - epoch 120 lr: 0.036864
2022-07-11 21:50:33 - train: epoch 0120, iter [00100, 05004], lr: 0.036849, loss: 2.3605
2022-07-11 21:51:08 - train: epoch 0120, iter [00200, 05004], lr: 0.036834, loss: 1.9547
2022-07-11 21:51:42 - train: epoch 0120, iter [00300, 05004], lr: 0.036818, loss: 2.2150
2022-07-11 21:52:16 - train: epoch 0120, iter [00400, 05004], lr: 0.036803, loss: 2.0496
2022-07-11 21:52:52 - train: epoch 0120, iter [00500, 05004], lr: 0.036787, loss: 1.9266
2022-07-11 21:53:26 - train: epoch 0120, iter [00600, 05004], lr: 0.036771, loss: 1.8976
2022-07-11 21:54:01 - train: epoch 0120, iter [00700, 05004], lr: 0.036756, loss: 2.1285
2022-07-11 21:54:35 - train: epoch 0120, iter [00800, 05004], lr: 0.036740, loss: 1.9614
2022-07-11 21:55:10 - train: epoch 0120, iter [00900, 05004], lr: 0.036725, loss: 2.1028
2022-07-11 21:55:44 - train: epoch 0120, iter [01000, 05004], lr: 0.036709, loss: 2.1290
2022-07-11 21:56:19 - train: epoch 0120, iter [01100, 05004], lr: 0.036694, loss: 1.9283
2022-07-11 21:56:54 - train: epoch 0120, iter [01200, 05004], lr: 0.036678, loss: 2.0746
2022-07-11 21:57:29 - train: epoch 0120, iter [01300, 05004], lr: 0.036663, loss: 1.7499
2022-07-11 21:58:04 - train: epoch 0120, iter [01400, 05004], lr: 0.036647, loss: 2.0520
2022-07-11 21:58:39 - train: epoch 0120, iter [01500, 05004], lr: 0.036632, loss: 2.2988
2022-07-11 21:59:13 - train: epoch 0120, iter [01600, 05004], lr: 0.036616, loss: 2.3322
2022-07-11 21:59:48 - train: epoch 0120, iter [01700, 05004], lr: 0.036601, loss: 2.3749
2022-07-11 22:00:22 - train: epoch 0120, iter [01800, 05004], lr: 0.036585, loss: 2.2554
2022-07-11 22:00:57 - train: epoch 0120, iter [01900, 05004], lr: 0.036570, loss: 2.2257
2022-07-11 22:01:32 - train: epoch 0120, iter [02000, 05004], lr: 0.036554, loss: 2.0794
2022-07-11 22:02:06 - train: epoch 0120, iter [02100, 05004], lr: 0.036539, loss: 2.2649
2022-07-11 22:02:40 - train: epoch 0120, iter [02200, 05004], lr: 0.036523, loss: 1.9081
2022-07-11 22:03:15 - train: epoch 0120, iter [02300, 05004], lr: 0.036508, loss: 2.2343
2022-07-11 22:03:50 - train: epoch 0120, iter [02400, 05004], lr: 0.036492, loss: 2.4052
2022-07-11 22:04:25 - train: epoch 0120, iter [02500, 05004], lr: 0.036477, loss: 2.1776
2022-07-11 22:05:00 - train: epoch 0120, iter [02600, 05004], lr: 0.036461, loss: 1.9784
2022-07-11 22:05:35 - train: epoch 0120, iter [02700, 05004], lr: 0.036446, loss: 1.9879
2022-07-11 22:06:09 - train: epoch 0120, iter [02800, 05004], lr: 0.036430, loss: 1.9837
2022-07-11 22:06:44 - train: epoch 0120, iter [02900, 05004], lr: 0.036415, loss: 1.8261
2022-07-11 22:07:18 - train: epoch 0120, iter [03000, 05004], lr: 0.036399, loss: 2.1210
2022-07-11 22:07:53 - train: epoch 0120, iter [03100, 05004], lr: 0.036384, loss: 1.8507
2022-07-11 22:08:28 - train: epoch 0120, iter [03200, 05004], lr: 0.036368, loss: 2.1187
2022-07-11 22:09:03 - train: epoch 0120, iter [03300, 05004], lr: 0.036353, loss: 1.9628
2022-07-11 22:09:38 - train: epoch 0120, iter [03400, 05004], lr: 0.036337, loss: 1.9673
2022-07-11 22:10:12 - train: epoch 0120, iter [03500, 05004], lr: 0.036322, loss: 2.0765
2022-07-11 22:10:47 - train: epoch 0120, iter [03600, 05004], lr: 0.036306, loss: 2.0287
2022-07-11 22:11:22 - train: epoch 0120, iter [03700, 05004], lr: 0.036291, loss: 2.1249
2022-07-11 22:11:57 - train: epoch 0120, iter [03800, 05004], lr: 0.036275, loss: 1.8538
2022-07-11 22:12:31 - train: epoch 0120, iter [03900, 05004], lr: 0.036260, loss: 2.0832
2022-07-11 22:13:06 - train: epoch 0120, iter [04000, 05004], lr: 0.036244, loss: 2.2661
2022-07-11 22:13:41 - train: epoch 0120, iter [04100, 05004], lr: 0.036229, loss: 2.0658
2022-07-11 22:14:16 - train: epoch 0120, iter [04200, 05004], lr: 0.036213, loss: 2.2765
2022-07-11 22:14:51 - train: epoch 0120, iter [04300, 05004], lr: 0.036198, loss: 2.2502
2022-07-11 22:15:26 - train: epoch 0120, iter [04400, 05004], lr: 0.036183, loss: 1.9849
2022-07-11 22:16:00 - train: epoch 0120, iter [04500, 05004], lr: 0.036167, loss: 2.3028
2022-07-11 22:16:35 - train: epoch 0120, iter [04600, 05004], lr: 0.036152, loss: 2.1546
2022-07-11 22:17:10 - train: epoch 0120, iter [04700, 05004], lr: 0.036136, loss: 2.0575
2022-07-11 22:17:44 - train: epoch 0120, iter [04800, 05004], lr: 0.036121, loss: 2.1634
2022-07-11 22:18:19 - train: epoch 0120, iter [04900, 05004], lr: 0.036105, loss: 2.2429
2022-07-11 22:18:52 - train: epoch 0120, iter [05000, 05004], lr: 0.036090, loss: 2.0542
2022-07-11 22:18:53 - train: epoch 120, train_loss: 2.0719
2022-07-11 22:20:08 - eval: epoch: 120, acc1: 65.742%, acc5: 87.344%, test_loss: 1.3972, per_image_load_time: 2.396ms, per_image_inference_time: 0.456ms
2022-07-11 22:20:08 - until epoch: 120, best_acc1: 66.242%
2022-07-11 22:20:08 - epoch 121 lr: 0.036089
2022-07-11 22:20:48 - train: epoch 0121, iter [00100, 05004], lr: 0.036074, loss: 1.9834
2022-07-11 22:21:22 - train: epoch 0121, iter [00200, 05004], lr: 0.036058, loss: 2.1889
2022-07-11 22:21:58 - train: epoch 0121, iter [00300, 05004], lr: 0.036043, loss: 2.1969
2022-07-11 22:22:31 - train: epoch 0121, iter [00400, 05004], lr: 0.036027, loss: 1.9822
2022-07-11 22:23:06 - train: epoch 0121, iter [00500, 05004], lr: 0.036012, loss: 2.0725
2022-07-11 22:23:40 - train: epoch 0121, iter [00600, 05004], lr: 0.035996, loss: 2.0809
2022-07-11 22:24:15 - train: epoch 0121, iter [00700, 05004], lr: 0.035981, loss: 1.7229
2022-07-11 22:24:50 - train: epoch 0121, iter [00800, 05004], lr: 0.035965, loss: 2.0350
2022-07-11 22:25:25 - train: epoch 0121, iter [00900, 05004], lr: 0.035950, loss: 2.1932
2022-07-11 22:25:59 - train: epoch 0121, iter [01000, 05004], lr: 0.035935, loss: 2.0834
2022-07-11 22:26:34 - train: epoch 0121, iter [01100, 05004], lr: 0.035919, loss: 2.2435
2022-07-11 22:27:09 - train: epoch 0121, iter [01200, 05004], lr: 0.035904, loss: 2.2121
2022-07-11 22:27:43 - train: epoch 0121, iter [01300, 05004], lr: 0.035888, loss: 2.0438
2022-07-11 22:28:17 - train: epoch 0121, iter [01400, 05004], lr: 0.035873, loss: 2.0043
2022-07-11 22:28:52 - train: epoch 0121, iter [01500, 05004], lr: 0.035857, loss: 2.1155
2022-07-11 22:29:27 - train: epoch 0121, iter [01600, 05004], lr: 0.035842, loss: 1.9943
2022-07-11 22:30:03 - train: epoch 0121, iter [01700, 05004], lr: 0.035826, loss: 2.1168
2022-07-11 22:30:36 - train: epoch 0121, iter [01800, 05004], lr: 0.035811, loss: 2.1160
2022-07-11 22:31:11 - train: epoch 0121, iter [01900, 05004], lr: 0.035796, loss: 2.0642
2022-07-11 22:31:45 - train: epoch 0121, iter [02000, 05004], lr: 0.035780, loss: 2.2006
2022-07-11 22:32:20 - train: epoch 0121, iter [02100, 05004], lr: 0.035765, loss: 2.0953
2022-07-11 22:32:55 - train: epoch 0121, iter [02200, 05004], lr: 0.035749, loss: 2.0114
2022-07-11 22:33:29 - train: epoch 0121, iter [02300, 05004], lr: 0.035734, loss: 1.9734
2022-07-11 22:34:04 - train: epoch 0121, iter [02400, 05004], lr: 0.035718, loss: 2.0125
2022-07-11 22:34:39 - train: epoch 0121, iter [02500, 05004], lr: 0.035703, loss: 1.7874
2022-07-11 22:35:14 - train: epoch 0121, iter [02600, 05004], lr: 0.035688, loss: 2.1169
2022-07-11 22:35:49 - train: epoch 0121, iter [02700, 05004], lr: 0.035672, loss: 2.3760
2022-07-11 22:36:23 - train: epoch 0121, iter [02800, 05004], lr: 0.035657, loss: 2.3557
2022-07-11 22:36:57 - train: epoch 0121, iter [02900, 05004], lr: 0.035641, loss: 2.1446
2022-07-11 22:37:33 - train: epoch 0121, iter [03000, 05004], lr: 0.035626, loss: 1.9084
2022-07-11 22:38:08 - train: epoch 0121, iter [03100, 05004], lr: 0.035610, loss: 1.8413
2022-07-11 22:38:43 - train: epoch 0121, iter [03200, 05004], lr: 0.035595, loss: 2.0950
2022-07-11 22:39:18 - train: epoch 0121, iter [03300, 05004], lr: 0.035580, loss: 1.9148
2022-07-11 22:39:53 - train: epoch 0121, iter [03400, 05004], lr: 0.035564, loss: 2.2396
2022-07-11 22:40:28 - train: epoch 0121, iter [03500, 05004], lr: 0.035549, loss: 2.1035
2022-07-11 22:41:03 - train: epoch 0121, iter [03600, 05004], lr: 0.035533, loss: 2.1363
2022-07-11 22:41:39 - train: epoch 0121, iter [03700, 05004], lr: 0.035518, loss: 2.0323
2022-07-11 22:42:13 - train: epoch 0121, iter [03800, 05004], lr: 0.035503, loss: 2.3246
2022-07-11 22:42:48 - train: epoch 0121, iter [03900, 05004], lr: 0.035487, loss: 2.0645
2022-07-11 22:43:23 - train: epoch 0121, iter [04000, 05004], lr: 0.035472, loss: 2.1102
2022-07-11 22:43:57 - train: epoch 0121, iter [04100, 05004], lr: 0.035456, loss: 2.0878
2022-07-11 22:44:32 - train: epoch 0121, iter [04200, 05004], lr: 0.035441, loss: 2.0276
2022-07-11 22:45:06 - train: epoch 0121, iter [04300, 05004], lr: 0.035426, loss: 2.0054
2022-07-11 22:45:41 - train: epoch 0121, iter [04400, 05004], lr: 0.035410, loss: 2.0604
2022-07-11 22:46:16 - train: epoch 0121, iter [04500, 05004], lr: 0.035395, loss: 2.1769
2022-07-11 22:46:51 - train: epoch 0121, iter [04600, 05004], lr: 0.035379, loss: 2.0047
2022-07-11 22:47:26 - train: epoch 0121, iter [04700, 05004], lr: 0.035364, loss: 2.2986
2022-07-11 22:48:00 - train: epoch 0121, iter [04800, 05004], lr: 0.035349, loss: 1.8667
2022-07-11 22:48:35 - train: epoch 0121, iter [04900, 05004], lr: 0.035333, loss: 1.9599
2022-07-11 22:49:08 - train: epoch 0121, iter [05000, 05004], lr: 0.035318, loss: 2.0846
2022-07-11 22:49:09 - train: epoch 121, train_loss: 2.0652
2022-07-11 22:50:24 - eval: epoch: 121, acc1: 66.116%, acc5: 87.538%, test_loss: 1.3942, per_image_load_time: 2.423ms, per_image_inference_time: 0.435ms
2022-07-11 22:50:24 - until epoch: 121, best_acc1: 66.242%
2022-07-11 22:50:24 - epoch 122 lr: 0.035317
2022-07-11 22:51:04 - train: epoch 0122, iter [00100, 05004], lr: 0.035302, loss: 1.8324
2022-07-11 22:51:39 - train: epoch 0122, iter [00200, 05004], lr: 0.035286, loss: 1.6864
2022-07-11 22:52:14 - train: epoch 0122, iter [00300, 05004], lr: 0.035271, loss: 2.0072
2022-07-11 22:52:48 - train: epoch 0122, iter [00400, 05004], lr: 0.035256, loss: 2.0477
2022-07-11 22:53:23 - train: epoch 0122, iter [00500, 05004], lr: 0.035240, loss: 1.8462
2022-07-11 22:53:57 - train: epoch 0122, iter [00600, 05004], lr: 0.035225, loss: 2.0250
2022-07-11 22:54:31 - train: epoch 0122, iter [00700, 05004], lr: 0.035210, loss: 1.8630
2022-07-11 22:55:06 - train: epoch 0122, iter [00800, 05004], lr: 0.035194, loss: 1.9440
2022-07-11 22:55:41 - train: epoch 0122, iter [00900, 05004], lr: 0.035179, loss: 2.1982
2022-07-11 22:56:15 - train: epoch 0122, iter [01000, 05004], lr: 0.035163, loss: 1.9040
2022-07-11 22:56:48 - train: epoch 0122, iter [01100, 05004], lr: 0.035148, loss: 1.9499
2022-07-11 22:57:23 - train: epoch 0122, iter [01200, 05004], lr: 0.035133, loss: 2.1585
2022-07-11 22:57:58 - train: epoch 0122, iter [01300, 05004], lr: 0.035117, loss: 2.0312
2022-07-11 22:58:32 - train: epoch 0122, iter [01400, 05004], lr: 0.035102, loss: 1.9343
2022-07-11 22:59:06 - train: epoch 0122, iter [01500, 05004], lr: 0.035087, loss: 2.1773
2022-07-11 22:59:41 - train: epoch 0122, iter [01600, 05004], lr: 0.035071, loss: 1.9302
2022-07-11 23:00:15 - train: epoch 0122, iter [01700, 05004], lr: 0.035056, loss: 2.1119
2022-07-11 23:00:48 - train: epoch 0122, iter [01800, 05004], lr: 0.035040, loss: 1.9449
2022-07-11 23:01:22 - train: epoch 0122, iter [01900, 05004], lr: 0.035025, loss: 1.9651
2022-07-11 23:01:57 - train: epoch 0122, iter [02000, 05004], lr: 0.035010, loss: 2.1042
2022-07-11 23:02:31 - train: epoch 0122, iter [02100, 05004], lr: 0.034994, loss: 2.1687
2022-07-11 23:03:05 - train: epoch 0122, iter [02200, 05004], lr: 0.034979, loss: 2.0782
2022-07-11 23:03:40 - train: epoch 0122, iter [02300, 05004], lr: 0.034964, loss: 2.0297
2022-07-11 23:04:14 - train: epoch 0122, iter [02400, 05004], lr: 0.034948, loss: 2.0041
2022-07-11 23:04:49 - train: epoch 0122, iter [02500, 05004], lr: 0.034933, loss: 2.0219
2022-07-11 23:05:23 - train: epoch 0122, iter [02600, 05004], lr: 0.034918, loss: 1.8337
2022-07-11 23:05:58 - train: epoch 0122, iter [02700, 05004], lr: 0.034902, loss: 2.2597
2022-07-11 23:06:32 - train: epoch 0122, iter [02800, 05004], lr: 0.034887, loss: 2.1770
2022-07-11 23:07:07 - train: epoch 0122, iter [02900, 05004], lr: 0.034872, loss: 2.0479
2022-07-11 23:07:41 - train: epoch 0122, iter [03000, 05004], lr: 0.034856, loss: 2.1621
2022-07-11 23:08:16 - train: epoch 0122, iter [03100, 05004], lr: 0.034841, loss: 2.1760
2022-07-11 23:08:51 - train: epoch 0122, iter [03200, 05004], lr: 0.034826, loss: 2.0564
2022-07-11 23:09:25 - train: epoch 0122, iter [03300, 05004], lr: 0.034810, loss: 1.7609
2022-07-11 23:10:00 - train: epoch 0122, iter [03400, 05004], lr: 0.034795, loss: 2.2038
2022-07-11 23:10:35 - train: epoch 0122, iter [03500, 05004], lr: 0.034780, loss: 2.4303
2022-07-11 23:11:09 - train: epoch 0122, iter [03600, 05004], lr: 0.034764, loss: 2.0328
2022-07-11 23:11:44 - train: epoch 0122, iter [03700, 05004], lr: 0.034749, loss: 2.1406
2022-07-11 23:12:19 - train: epoch 0122, iter [03800, 05004], lr: 0.034734, loss: 1.9845
2022-07-11 23:12:53 - train: epoch 0122, iter [03900, 05004], lr: 0.034718, loss: 1.9981
2022-07-11 23:13:28 - train: epoch 0122, iter [04000, 05004], lr: 0.034703, loss: 2.0404
2022-07-11 23:14:02 - train: epoch 0122, iter [04100, 05004], lr: 0.034688, loss: 1.9551
2022-07-11 23:14:37 - train: epoch 0122, iter [04200, 05004], lr: 0.034672, loss: 2.0569
2022-07-11 23:15:12 - train: epoch 0122, iter [04300, 05004], lr: 0.034657, loss: 2.0979
2022-07-11 23:15:47 - train: epoch 0122, iter [04400, 05004], lr: 0.034642, loss: 2.4409
2022-07-11 23:16:21 - train: epoch 0122, iter [04500, 05004], lr: 0.034626, loss: 1.9613
2022-07-11 23:16:55 - train: epoch 0122, iter [04600, 05004], lr: 0.034611, loss: 2.2112
2022-07-11 23:17:29 - train: epoch 0122, iter [04700, 05004], lr: 0.034596, loss: 1.9822
2022-07-11 23:18:05 - train: epoch 0122, iter [04800, 05004], lr: 0.034580, loss: 1.9988
2022-07-11 23:18:40 - train: epoch 0122, iter [04900, 05004], lr: 0.034565, loss: 1.8716
2022-07-11 23:19:13 - train: epoch 0122, iter [05000, 05004], lr: 0.034550, loss: 2.1100
2022-07-11 23:19:14 - train: epoch 122, train_loss: 2.0564
2022-07-11 23:20:29 - eval: epoch: 122, acc1: 67.550%, acc5: 88.388%, test_loss: 1.3240, per_image_load_time: 2.454ms, per_image_inference_time: 0.456ms
2022-07-11 23:20:30 - until epoch: 122, best_acc1: 67.550%
2022-07-11 23:20:30 - epoch 123 lr: 0.034549
2022-07-11 23:21:10 - train: epoch 0123, iter [00100, 05004], lr: 0.034534, loss: 2.0997
2022-07-11 23:21:44 - train: epoch 0123, iter [00200, 05004], lr: 0.034519, loss: 1.9359
2022-07-11 23:22:19 - train: epoch 0123, iter [00300, 05004], lr: 0.034503, loss: 2.0105
2022-07-11 23:22:53 - train: epoch 0123, iter [00400, 05004], lr: 0.034488, loss: 1.9019
2022-07-11 23:23:28 - train: epoch 0123, iter [00500, 05004], lr: 0.034473, loss: 1.9929
2022-07-11 23:24:03 - train: epoch 0123, iter [00600, 05004], lr: 0.034457, loss: 2.2748
2022-07-11 23:24:37 - train: epoch 0123, iter [00700, 05004], lr: 0.034442, loss: 2.2691
2022-07-11 23:25:12 - train: epoch 0123, iter [00800, 05004], lr: 0.034427, loss: 2.0524
2022-07-11 23:25:46 - train: epoch 0123, iter [00900, 05004], lr: 0.034411, loss: 2.2846
2022-07-11 23:26:21 - train: epoch 0123, iter [01000, 05004], lr: 0.034396, loss: 2.0456
2022-07-11 23:26:56 - train: epoch 0123, iter [01100, 05004], lr: 0.034381, loss: 2.1400
2022-07-11 23:27:30 - train: epoch 0123, iter [01200, 05004], lr: 0.034366, loss: 2.0054
2022-07-11 23:28:05 - train: epoch 0123, iter [01300, 05004], lr: 0.034350, loss: 2.1508
2022-07-11 23:28:39 - train: epoch 0123, iter [01400, 05004], lr: 0.034335, loss: 2.0720
2022-07-11 23:29:14 - train: epoch 0123, iter [01500, 05004], lr: 0.034320, loss: 2.1720
2022-07-11 23:29:48 - train: epoch 0123, iter [01600, 05004], lr: 0.034304, loss: 2.2951
2022-07-11 23:30:24 - train: epoch 0123, iter [01700, 05004], lr: 0.034289, loss: 1.8841
2022-07-11 23:30:59 - train: epoch 0123, iter [01800, 05004], lr: 0.034274, loss: 2.0390
2022-07-11 23:31:33 - train: epoch 0123, iter [01900, 05004], lr: 0.034259, loss: 2.1390
2022-07-11 23:32:09 - train: epoch 0123, iter [02000, 05004], lr: 0.034243, loss: 2.3188
2022-07-11 23:32:42 - train: epoch 0123, iter [02100, 05004], lr: 0.034228, loss: 2.3008
2022-07-11 23:33:17 - train: epoch 0123, iter [02200, 05004], lr: 0.034213, loss: 2.1578
2022-07-11 23:33:52 - train: epoch 0123, iter [02300, 05004], lr: 0.034197, loss: 2.1623
2022-07-11 23:34:27 - train: epoch 0123, iter [02400, 05004], lr: 0.034182, loss: 2.2050
2022-07-11 23:35:02 - train: epoch 0123, iter [02500, 05004], lr: 0.034167, loss: 2.2482
2022-07-11 23:35:37 - train: epoch 0123, iter [02600, 05004], lr: 0.034152, loss: 2.0095
2022-07-11 23:36:11 - train: epoch 0123, iter [02700, 05004], lr: 0.034136, loss: 2.1687
2022-07-11 23:36:46 - train: epoch 0123, iter [02800, 05004], lr: 0.034121, loss: 1.9150
2022-07-11 23:37:21 - train: epoch 0123, iter [02900, 05004], lr: 0.034106, loss: 2.1993
2022-07-11 23:37:57 - train: epoch 0123, iter [03000, 05004], lr: 0.034091, loss: 1.8437
2022-07-11 23:38:31 - train: epoch 0123, iter [03100, 05004], lr: 0.034075, loss: 2.0881
2022-07-11 23:39:07 - train: epoch 0123, iter [03200, 05004], lr: 0.034060, loss: 2.0057
2022-07-11 23:39:41 - train: epoch 0123, iter [03300, 05004], lr: 0.034045, loss: 2.0660
2022-07-11 23:40:16 - train: epoch 0123, iter [03400, 05004], lr: 0.034030, loss: 2.0392
2022-07-11 23:40:51 - train: epoch 0123, iter [03500, 05004], lr: 0.034014, loss: 1.9248
2022-07-11 23:41:26 - train: epoch 0123, iter [03600, 05004], lr: 0.033999, loss: 2.0536
2022-07-11 23:42:01 - train: epoch 0123, iter [03700, 05004], lr: 0.033984, loss: 2.0627
2022-07-11 23:42:35 - train: epoch 0123, iter [03800, 05004], lr: 0.033969, loss: 2.2976
2022-07-11 23:43:11 - train: epoch 0123, iter [03900, 05004], lr: 0.033953, loss: 2.1504
2022-07-11 23:43:45 - train: epoch 0123, iter [04000, 05004], lr: 0.033938, loss: 2.0691
2022-07-11 23:44:20 - train: epoch 0123, iter [04100, 05004], lr: 0.033923, loss: 2.0049
2022-07-11 23:44:55 - train: epoch 0123, iter [04200, 05004], lr: 0.033908, loss: 1.9631
2022-07-11 23:45:31 - train: epoch 0123, iter [04300, 05004], lr: 0.033892, loss: 2.0105
2022-07-11 23:46:05 - train: epoch 0123, iter [04400, 05004], lr: 0.033877, loss: 2.1264
2022-07-11 23:46:40 - train: epoch 0123, iter [04500, 05004], lr: 0.033862, loss: 1.7163
2022-07-11 23:47:15 - train: epoch 0123, iter [04600, 05004], lr: 0.033847, loss: 2.0316
2022-07-11 23:47:50 - train: epoch 0123, iter [04700, 05004], lr: 0.033831, loss: 2.0009
2022-07-11 23:48:24 - train: epoch 0123, iter [04800, 05004], lr: 0.033816, loss: 2.0806
2022-07-11 23:48:59 - train: epoch 0123, iter [04900, 05004], lr: 0.033801, loss: 2.1668
2022-07-11 23:49:32 - train: epoch 0123, iter [05000, 05004], lr: 0.033786, loss: 2.3714
2022-07-11 23:49:34 - train: epoch 123, train_loss: 2.0514
2022-07-11 23:50:48 - eval: epoch: 123, acc1: 65.210%, acc5: 86.888%, test_loss: 1.4292, per_image_load_time: 2.439ms, per_image_inference_time: 0.451ms
2022-07-11 23:50:49 - until epoch: 123, best_acc1: 67.550%
2022-07-11 23:50:49 - epoch 124 lr: 0.033785
2022-07-11 23:51:28 - train: epoch 0124, iter [00100, 05004], lr: 0.033770, loss: 1.7217
2022-07-11 23:52:02 - train: epoch 0124, iter [00200, 05004], lr: 0.033755, loss: 2.1297
2022-07-11 23:52:37 - train: epoch 0124, iter [00300, 05004], lr: 0.033739, loss: 2.0571
2022-07-11 23:53:11 - train: epoch 0124, iter [00400, 05004], lr: 0.033724, loss: 1.7336
2022-07-11 23:53:46 - train: epoch 0124, iter [00500, 05004], lr: 0.033709, loss: 1.9182
2022-07-11 23:54:21 - train: epoch 0124, iter [00600, 05004], lr: 0.033694, loss: 2.2416
2022-07-11 23:54:56 - train: epoch 0124, iter [00700, 05004], lr: 0.033679, loss: 2.0804
2022-07-11 23:55:30 - train: epoch 0124, iter [00800, 05004], lr: 0.033663, loss: 1.9814
2022-07-11 23:56:05 - train: epoch 0124, iter [00900, 05004], lr: 0.033648, loss: 2.0351
2022-07-11 23:56:40 - train: epoch 0124, iter [01000, 05004], lr: 0.033633, loss: 1.8896
2022-07-11 23:57:14 - train: epoch 0124, iter [01100, 05004], lr: 0.033618, loss: 2.2138
2022-07-11 23:57:50 - train: epoch 0124, iter [01200, 05004], lr: 0.033602, loss: 1.9666
2022-07-11 23:58:25 - train: epoch 0124, iter [01300, 05004], lr: 0.033587, loss: 2.0525
2022-07-11 23:58:59 - train: epoch 0124, iter [01400, 05004], lr: 0.033572, loss: 2.2504
2022-07-11 23:59:34 - train: epoch 0124, iter [01500, 05004], lr: 0.033557, loss: 1.8397
2022-07-12 00:00:08 - train: epoch 0124, iter [01600, 05004], lr: 0.033542, loss: 1.9401
2022-07-12 00:00:43 - train: epoch 0124, iter [01700, 05004], lr: 0.033526, loss: 1.8557
2022-07-12 00:01:18 - train: epoch 0124, iter [01800, 05004], lr: 0.033511, loss: 2.1335
2022-07-12 00:01:52 - train: epoch 0124, iter [01900, 05004], lr: 0.033496, loss: 2.1650
2022-07-12 00:02:27 - train: epoch 0124, iter [02000, 05004], lr: 0.033481, loss: 1.9730
2022-07-12 00:03:02 - train: epoch 0124, iter [02100, 05004], lr: 0.033466, loss: 1.7869
2022-07-12 00:03:37 - train: epoch 0124, iter [02200, 05004], lr: 0.033450, loss: 2.0324
2022-07-12 00:04:11 - train: epoch 0124, iter [02300, 05004], lr: 0.033435, loss: 2.2057
2022-07-12 00:04:46 - train: epoch 0124, iter [02400, 05004], lr: 0.033420, loss: 1.8984
2022-07-12 00:05:21 - train: epoch 0124, iter [02500, 05004], lr: 0.033405, loss: 1.9959
2022-07-12 00:05:56 - train: epoch 0124, iter [02600, 05004], lr: 0.033390, loss: 1.8511
2022-07-12 00:06:30 - train: epoch 0124, iter [02700, 05004], lr: 0.033375, loss: 2.1564
2022-07-12 00:07:04 - train: epoch 0124, iter [02800, 05004], lr: 0.033359, loss: 2.0655
2022-07-12 00:07:39 - train: epoch 0124, iter [02900, 05004], lr: 0.033344, loss: 2.0183
2022-07-12 00:08:14 - train: epoch 0124, iter [03000, 05004], lr: 0.033329, loss: 1.8069
2022-07-12 00:08:49 - train: epoch 0124, iter [03100, 05004], lr: 0.033314, loss: 2.1093
2022-07-12 00:09:23 - train: epoch 0124, iter [03200, 05004], lr: 0.033299, loss: 2.1388
2022-07-12 00:09:58 - train: epoch 0124, iter [03300, 05004], lr: 0.033283, loss: 2.1597
2022-07-12 00:10:34 - train: epoch 0124, iter [03400, 05004], lr: 0.033268, loss: 1.9419
2022-07-12 00:11:08 - train: epoch 0124, iter [03500, 05004], lr: 0.033253, loss: 2.1520
2022-07-12 00:11:43 - train: epoch 0124, iter [03600, 05004], lr: 0.033238, loss: 1.9886
2022-07-12 00:12:18 - train: epoch 0124, iter [03700, 05004], lr: 0.033223, loss: 1.8993
2022-07-12 00:12:52 - train: epoch 0124, iter [03800, 05004], lr: 0.033208, loss: 1.9017
2022-07-12 00:13:27 - train: epoch 0124, iter [03900, 05004], lr: 0.033192, loss: 1.9602
2022-07-12 00:14:02 - train: epoch 0124, iter [04000, 05004], lr: 0.033177, loss: 1.8452
2022-07-12 00:14:36 - train: epoch 0124, iter [04100, 05004], lr: 0.033162, loss: 2.1831
2022-07-12 00:15:11 - train: epoch 0124, iter [04200, 05004], lr: 0.033147, loss: 2.0184
2022-07-12 00:15:46 - train: epoch 0124, iter [04300, 05004], lr: 0.033132, loss: 1.9322
2022-07-12 00:16:21 - train: epoch 0124, iter [04400, 05004], lr: 0.033117, loss: 1.9078
2022-07-12 00:16:56 - train: epoch 0124, iter [04500, 05004], lr: 0.033102, loss: 2.0557
2022-07-12 00:17:31 - train: epoch 0124, iter [04600, 05004], lr: 0.033086, loss: 1.7700
2022-07-12 00:18:05 - train: epoch 0124, iter [04700, 05004], lr: 0.033071, loss: 2.0227
2022-07-12 00:18:40 - train: epoch 0124, iter [04800, 05004], lr: 0.033056, loss: 2.1007
2022-07-12 00:19:15 - train: epoch 0124, iter [04900, 05004], lr: 0.033041, loss: 1.8694
2022-07-12 00:19:49 - train: epoch 0124, iter [05000, 05004], lr: 0.033026, loss: 2.2000
2022-07-12 00:19:50 - train: epoch 124, train_loss: 2.0402
2022-07-12 00:21:04 - eval: epoch: 124, acc1: 66.800%, acc5: 87.778%, test_loss: 1.3636, per_image_load_time: 2.469ms, per_image_inference_time: 0.435ms
2022-07-12 00:21:05 - until epoch: 124, best_acc1: 67.550%
2022-07-12 00:21:05 - epoch 125 lr: 0.033025
2022-07-12 00:21:45 - train: epoch 0125, iter [00100, 05004], lr: 0.033010, loss: 1.8513
2022-07-12 00:22:19 - train: epoch 0125, iter [00200, 05004], lr: 0.032995, loss: 1.9711
2022-07-12 00:22:54 - train: epoch 0125, iter [00300, 05004], lr: 0.032980, loss: 2.0925
2022-07-12 00:23:29 - train: epoch 0125, iter [00400, 05004], lr: 0.032965, loss: 1.6849
2022-07-12 00:24:03 - train: epoch 0125, iter [00500, 05004], lr: 0.032950, loss: 2.1071
2022-07-12 00:24:38 - train: epoch 0125, iter [00600, 05004], lr: 0.032934, loss: 2.0157
2022-07-12 00:25:13 - train: epoch 0125, iter [00700, 05004], lr: 0.032919, loss: 2.0794
2022-07-12 00:25:47 - train: epoch 0125, iter [00800, 05004], lr: 0.032904, loss: 1.8222
2022-07-12 00:26:22 - train: epoch 0125, iter [00900, 05004], lr: 0.032889, loss: 1.7419
2022-07-12 00:26:57 - train: epoch 0125, iter [01000, 05004], lr: 0.032874, loss: 1.9061
2022-07-12 00:27:32 - train: epoch 0125, iter [01100, 05004], lr: 0.032859, loss: 2.0078
2022-07-12 00:28:06 - train: epoch 0125, iter [01200, 05004], lr: 0.032844, loss: 2.2037
2022-07-12 00:28:42 - train: epoch 0125, iter [01300, 05004], lr: 0.032829, loss: 1.9735
2022-07-12 00:29:16 - train: epoch 0125, iter [01400, 05004], lr: 0.032813, loss: 2.3111
2022-07-12 00:29:51 - train: epoch 0125, iter [01500, 05004], lr: 0.032798, loss: 2.3617
2022-07-12 00:30:25 - train: epoch 0125, iter [01600, 05004], lr: 0.032783, loss: 2.0474
2022-07-12 00:30:59 - train: epoch 0125, iter [01700, 05004], lr: 0.032768, loss: 2.0276
2022-07-12 00:31:34 - train: epoch 0125, iter [01800, 05004], lr: 0.032753, loss: 1.8594
2022-07-12 00:32:09 - train: epoch 0125, iter [01900, 05004], lr: 0.032738, loss: 2.2037
2022-07-12 00:32:43 - train: epoch 0125, iter [02000, 05004], lr: 0.032723, loss: 1.7922
2022-07-12 00:33:17 - train: epoch 0125, iter [02100, 05004], lr: 0.032708, loss: 2.1196
2022-07-12 00:33:52 - train: epoch 0125, iter [02200, 05004], lr: 0.032693, loss: 2.4414
2022-07-12 00:34:27 - train: epoch 0125, iter [02300, 05004], lr: 0.032677, loss: 2.0072
2022-07-12 00:35:00 - train: epoch 0125, iter [02400, 05004], lr: 0.032662, loss: 2.1032
2022-07-12 00:35:35 - train: epoch 0125, iter [02500, 05004], lr: 0.032647, loss: 1.8775
2022-07-12 00:36:10 - train: epoch 0125, iter [02600, 05004], lr: 0.032632, loss: 2.2124
2022-07-12 00:36:45 - train: epoch 0125, iter [02700, 05004], lr: 0.032617, loss: 2.0127
2022-07-12 00:37:19 - train: epoch 0125, iter [02800, 05004], lr: 0.032602, loss: 2.0928
2022-07-12 00:37:54 - train: epoch 0125, iter [02900, 05004], lr: 0.032587, loss: 1.9032
2022-07-12 00:38:28 - train: epoch 0125, iter [03000, 05004], lr: 0.032572, loss: 1.9783
2022-07-12 00:39:03 - train: epoch 0125, iter [03100, 05004], lr: 0.032557, loss: 1.9851
2022-07-12 00:39:37 - train: epoch 0125, iter [03200, 05004], lr: 0.032542, loss: 2.2935
2022-07-12 00:40:12 - train: epoch 0125, iter [03300, 05004], lr: 0.032527, loss: 2.0835
2022-07-12 00:40:46 - train: epoch 0125, iter [03400, 05004], lr: 0.032511, loss: 1.9627
2022-07-12 00:41:22 - train: epoch 0125, iter [03500, 05004], lr: 0.032496, loss: 2.1046
2022-07-12 00:41:57 - train: epoch 0125, iter [03600, 05004], lr: 0.032481, loss: 1.9966
2022-07-12 00:42:31 - train: epoch 0125, iter [03700, 05004], lr: 0.032466, loss: 2.1723
2022-07-12 00:43:06 - train: epoch 0125, iter [03800, 05004], lr: 0.032451, loss: 2.0409
2022-07-12 00:43:40 - train: epoch 0125, iter [03900, 05004], lr: 0.032436, loss: 1.9744
2022-07-12 00:44:15 - train: epoch 0125, iter [04000, 05004], lr: 0.032421, loss: 2.1694
2022-07-12 00:44:50 - train: epoch 0125, iter [04100, 05004], lr: 0.032406, loss: 1.9393
2022-07-12 00:45:25 - train: epoch 0125, iter [04200, 05004], lr: 0.032391, loss: 2.1226
2022-07-12 00:45:59 - train: epoch 0125, iter [04300, 05004], lr: 0.032376, loss: 1.5933
2022-07-12 00:46:34 - train: epoch 0125, iter [04400, 05004], lr: 0.032361, loss: 1.9408
2022-07-12 00:47:08 - train: epoch 0125, iter [04500, 05004], lr: 0.032346, loss: 2.1287
2022-07-12 00:47:43 - train: epoch 0125, iter [04600, 05004], lr: 0.032331, loss: 1.7281
2022-07-12 00:48:18 - train: epoch 0125, iter [04700, 05004], lr: 0.032316, loss: 2.1432
2022-07-12 00:48:53 - train: epoch 0125, iter [04800, 05004], lr: 0.032300, loss: 2.3705
2022-07-12 00:49:27 - train: epoch 0125, iter [04900, 05004], lr: 0.032285, loss: 2.1340
2022-07-12 00:50:01 - train: epoch 0125, iter [05000, 05004], lr: 0.032270, loss: 2.1281
2022-07-12 00:50:02 - train: epoch 125, train_loss: 2.0298
2022-07-12 00:51:17 - eval: epoch: 125, acc1: 65.946%, acc5: 87.318%, test_loss: 1.3976, per_image_load_time: 2.512ms, per_image_inference_time: 0.442ms
2022-07-12 00:51:18 - until epoch: 125, best_acc1: 67.550%
2022-07-12 00:51:18 - epoch 126 lr: 0.032270
2022-07-12 00:51:58 - train: epoch 0126, iter [00100, 05004], lr: 0.032255, loss: 1.7975
2022-07-12 00:52:32 - train: epoch 0126, iter [00200, 05004], lr: 0.032240, loss: 1.9656
2022-07-12 00:53:07 - train: epoch 0126, iter [00300, 05004], lr: 0.032225, loss: 1.8384
2022-07-12 00:53:41 - train: epoch 0126, iter [00400, 05004], lr: 0.032210, loss: 2.1479
2022-07-12 00:54:16 - train: epoch 0126, iter [00500, 05004], lr: 0.032195, loss: 1.8548
2022-07-12 00:54:50 - train: epoch 0126, iter [00600, 05004], lr: 0.032179, loss: 1.9587
2022-07-12 00:55:25 - train: epoch 0126, iter [00700, 05004], lr: 0.032164, loss: 1.7407
2022-07-12 00:55:59 - train: epoch 0126, iter [00800, 05004], lr: 0.032149, loss: 2.0012
2022-07-12 00:56:34 - train: epoch 0126, iter [00900, 05004], lr: 0.032134, loss: 2.2704
2022-07-12 00:57:09 - train: epoch 0126, iter [01000, 05004], lr: 0.032119, loss: 2.0389
2022-07-12 00:57:44 - train: epoch 0126, iter [01100, 05004], lr: 0.032104, loss: 2.1846
2022-07-12 00:58:18 - train: epoch 0126, iter [01200, 05004], lr: 0.032089, loss: 2.0042
2022-07-12 00:58:54 - train: epoch 0126, iter [01300, 05004], lr: 0.032074, loss: 2.4117
2022-07-12 00:59:28 - train: epoch 0126, iter [01400, 05004], lr: 0.032059, loss: 1.9640
2022-07-12 01:00:03 - train: epoch 0126, iter [01500, 05004], lr: 0.032044, loss: 2.0968
2022-07-12 01:00:38 - train: epoch 0126, iter [01600, 05004], lr: 0.032029, loss: 1.9200
2022-07-12 01:01:14 - train: epoch 0126, iter [01700, 05004], lr: 0.032014, loss: 1.9925
2022-07-12 01:01:48 - train: epoch 0126, iter [01800, 05004], lr: 0.031999, loss: 1.8910
2022-07-12 01:02:23 - train: epoch 0126, iter [01900, 05004], lr: 0.031984, loss: 2.0555
2022-07-12 01:02:58 - train: epoch 0126, iter [02000, 05004], lr: 0.031969, loss: 1.9425
2022-07-12 01:03:33 - train: epoch 0126, iter [02100, 05004], lr: 0.031954, loss: 1.8577
2022-07-12 01:04:08 - train: epoch 0126, iter [02200, 05004], lr: 0.031939, loss: 2.1410
2022-07-12 01:04:43 - train: epoch 0126, iter [02300, 05004], lr: 0.031924, loss: 2.1876
2022-07-12 01:05:17 - train: epoch 0126, iter [02400, 05004], lr: 0.031909, loss: 1.8201
2022-07-12 01:05:52 - train: epoch 0126, iter [02500, 05004], lr: 0.031894, loss: 2.2423
2022-07-12 01:06:28 - train: epoch 0126, iter [02600, 05004], lr: 0.031879, loss: 2.1945
2022-07-12 01:07:02 - train: epoch 0126, iter [02700, 05004], lr: 0.031864, loss: 2.0249
2022-07-12 01:07:37 - train: epoch 0126, iter [02800, 05004], lr: 0.031849, loss: 2.0688
2022-07-12 01:08:12 - train: epoch 0126, iter [02900, 05004], lr: 0.031834, loss: 2.0217
2022-07-12 01:08:47 - train: epoch 0126, iter [03000, 05004], lr: 0.031819, loss: 1.6443
2022-07-12 01:09:22 - train: epoch 0126, iter [03100, 05004], lr: 0.031804, loss: 2.0643
2022-07-12 01:09:57 - train: epoch 0126, iter [03200, 05004], lr: 0.031789, loss: 2.1297
2022-07-12 01:10:32 - train: epoch 0126, iter [03300, 05004], lr: 0.031774, loss: 1.9494
2022-07-12 01:11:08 - train: epoch 0126, iter [03400, 05004], lr: 0.031759, loss: 2.1760
2022-07-12 01:11:42 - train: epoch 0126, iter [03500, 05004], lr: 0.031744, loss: 1.8660
2022-07-12 01:12:18 - train: epoch 0126, iter [03600, 05004], lr: 0.031729, loss: 2.0628
2022-07-12 01:12:52 - train: epoch 0126, iter [03700, 05004], lr: 0.031714, loss: 2.0772
2022-07-12 01:13:27 - train: epoch 0126, iter [03800, 05004], lr: 0.031699, loss: 1.9140
2022-07-12 01:14:02 - train: epoch 0126, iter [03900, 05004], lr: 0.031684, loss: 2.0476
2022-07-12 01:14:38 - train: epoch 0126, iter [04000, 05004], lr: 0.031669, loss: 2.0623
2022-07-12 01:15:13 - train: epoch 0126, iter [04100, 05004], lr: 0.031654, loss: 2.0633
2022-07-12 01:15:48 - train: epoch 0126, iter [04200, 05004], lr: 0.031639, loss: 1.8894
2022-07-12 01:16:23 - train: epoch 0126, iter [04300, 05004], lr: 0.031624, loss: 1.9613
2022-07-12 01:16:58 - train: epoch 0126, iter [04400, 05004], lr: 0.031609, loss: 2.1321
2022-07-12 01:17:33 - train: epoch 0126, iter [04500, 05004], lr: 0.031594, loss: 1.8218
2022-07-12 01:18:07 - train: epoch 0126, iter [04600, 05004], lr: 0.031579, loss: 1.9241
2022-07-12 01:18:42 - train: epoch 0126, iter [04700, 05004], lr: 0.031564, loss: 2.0328
2022-07-12 01:19:17 - train: epoch 0126, iter [04800, 05004], lr: 0.031549, loss: 2.2047
2022-07-12 01:19:52 - train: epoch 0126, iter [04900, 05004], lr: 0.031534, loss: 2.1518
2022-07-12 01:20:25 - train: epoch 0126, iter [05000, 05004], lr: 0.031519, loss: 1.8671
2022-07-12 01:20:26 - train: epoch 126, train_loss: 2.0208
2022-07-12 01:21:41 - eval: epoch: 126, acc1: 64.400%, acc5: 86.272%, test_loss: 1.4694, per_image_load_time: 2.433ms, per_image_inference_time: 0.469ms
2022-07-12 01:21:42 - until epoch: 126, best_acc1: 67.550%
2022-07-12 01:21:42 - epoch 127 lr: 0.031519
2022-07-12 01:22:22 - train: epoch 0127, iter [00100, 05004], lr: 0.031504, loss: 2.1594
2022-07-12 01:22:56 - train: epoch 0127, iter [00200, 05004], lr: 0.031489, loss: 1.7404
2022-07-12 01:23:30 - train: epoch 0127, iter [00300, 05004], lr: 0.031474, loss: 1.8787
2022-07-12 01:24:05 - train: epoch 0127, iter [00400, 05004], lr: 0.031459, loss: 2.2480
2022-07-12 01:24:40 - train: epoch 0127, iter [00500, 05004], lr: 0.031444, loss: 2.1193
2022-07-12 01:25:15 - train: epoch 0127, iter [00600, 05004], lr: 0.031429, loss: 2.0797
2022-07-12 01:25:49 - train: epoch 0127, iter [00700, 05004], lr: 0.031414, loss: 2.0911
2022-07-12 01:26:24 - train: epoch 0127, iter [00800, 05004], lr: 0.031399, loss: 2.2257
2022-07-12 01:26:58 - train: epoch 0127, iter [00900, 05004], lr: 0.031384, loss: 1.9800
2022-07-12 01:27:33 - train: epoch 0127, iter [01000, 05004], lr: 0.031369, loss: 1.9111
2022-07-12 01:28:08 - train: epoch 0127, iter [01100, 05004], lr: 0.031354, loss: 2.0373
2022-07-12 01:28:44 - train: epoch 0127, iter [01200, 05004], lr: 0.031340, loss: 1.8797
2022-07-12 01:29:18 - train: epoch 0127, iter [01300, 05004], lr: 0.031325, loss: 2.1963
2022-07-12 01:29:53 - train: epoch 0127, iter [01400, 05004], lr: 0.031310, loss: 1.8426
2022-07-12 01:30:27 - train: epoch 0127, iter [01500, 05004], lr: 0.031295, loss: 1.9684
2022-07-12 01:31:02 - train: epoch 0127, iter [01600, 05004], lr: 0.031280, loss: 2.0627
2022-07-12 01:31:37 - train: epoch 0127, iter [01700, 05004], lr: 0.031265, loss: 1.9703
2022-07-12 01:32:12 - train: epoch 0127, iter [01800, 05004], lr: 0.031250, loss: 2.0520
2022-07-12 01:32:46 - train: epoch 0127, iter [01900, 05004], lr: 0.031235, loss: 2.1252
2022-07-12 01:33:21 - train: epoch 0127, iter [02000, 05004], lr: 0.031220, loss: 1.9397
2022-07-12 01:33:55 - train: epoch 0127, iter [02100, 05004], lr: 0.031205, loss: 2.1592
2022-07-12 01:34:30 - train: epoch 0127, iter [02200, 05004], lr: 0.031190, loss: 2.0273
2022-07-12 01:35:05 - train: epoch 0127, iter [02300, 05004], lr: 0.031175, loss: 1.8516
2022-07-12 01:35:39 - train: epoch 0127, iter [02400, 05004], lr: 0.031160, loss: 2.0470
2022-07-12 01:36:15 - train: epoch 0127, iter [02500, 05004], lr: 0.031146, loss: 2.0400
2022-07-12 01:36:49 - train: epoch 0127, iter [02600, 05004], lr: 0.031131, loss: 1.7700
2022-07-12 01:37:25 - train: epoch 0127, iter [02700, 05004], lr: 0.031116, loss: 2.1422
2022-07-12 01:37:59 - train: epoch 0127, iter [02800, 05004], lr: 0.031101, loss: 1.9544
2022-07-12 01:38:34 - train: epoch 0127, iter [02900, 05004], lr: 0.031086, loss: 2.1124
2022-07-12 01:39:09 - train: epoch 0127, iter [03000, 05004], lr: 0.031071, loss: 1.9187
2022-07-12 01:39:43 - train: epoch 0127, iter [03100, 05004], lr: 0.031056, loss: 2.1791
2022-07-12 01:40:18 - train: epoch 0127, iter [03200, 05004], lr: 0.031041, loss: 1.9977
2022-07-12 01:40:53 - train: epoch 0127, iter [03300, 05004], lr: 0.031026, loss: 2.3234
2022-07-12 01:41:28 - train: epoch 0127, iter [03400, 05004], lr: 0.031011, loss: 2.2102
2022-07-12 01:42:04 - train: epoch 0127, iter [03500, 05004], lr: 0.030997, loss: 2.0933
2022-07-12 01:42:38 - train: epoch 0127, iter [03600, 05004], lr: 0.030982, loss: 2.3594
2022-07-12 01:43:13 - train: epoch 0127, iter [03700, 05004], lr: 0.030967, loss: 2.0616
2022-07-12 01:43:48 - train: epoch 0127, iter [03800, 05004], lr: 0.030952, loss: 2.1728
2022-07-12 01:44:22 - train: epoch 0127, iter [03900, 05004], lr: 0.030937, loss: 2.1470
2022-07-12 01:44:57 - train: epoch 0127, iter [04000, 05004], lr: 0.030922, loss: 1.9998
2022-07-12 01:45:31 - train: epoch 0127, iter [04100, 05004], lr: 0.030907, loss: 1.8415
2022-07-12 01:46:06 - train: epoch 0127, iter [04200, 05004], lr: 0.030892, loss: 2.0805
2022-07-12 01:46:40 - train: epoch 0127, iter [04300, 05004], lr: 0.030878, loss: 2.0913
2022-07-12 01:47:15 - train: epoch 0127, iter [04400, 05004], lr: 0.030863, loss: 1.8870
2022-07-12 01:47:50 - train: epoch 0127, iter [04500, 05004], lr: 0.030848, loss: 1.7266
2022-07-12 01:48:26 - train: epoch 0127, iter [04600, 05004], lr: 0.030833, loss: 1.9222
2022-07-12 01:49:00 - train: epoch 0127, iter [04700, 05004], lr: 0.030818, loss: 1.8638
2022-07-12 01:49:34 - train: epoch 0127, iter [04800, 05004], lr: 0.030803, loss: 1.9161
2022-07-12 01:50:09 - train: epoch 0127, iter [04900, 05004], lr: 0.030788, loss: 2.0887
2022-07-12 01:50:43 - train: epoch 0127, iter [05000, 05004], lr: 0.030773, loss: 2.4029
2022-07-12 01:50:44 - train: epoch 127, train_loss: 2.0176
2022-07-12 01:51:58 - eval: epoch: 127, acc1: 66.322%, acc5: 87.576%, test_loss: 1.3823, per_image_load_time: 2.374ms, per_image_inference_time: 0.449ms
2022-07-12 01:51:59 - until epoch: 127, best_acc1: 67.550%
2022-07-12 01:51:59 - epoch 128 lr: 0.030773
2022-07-12 01:52:38 - train: epoch 0128, iter [00100, 05004], lr: 0.030758, loss: 2.0951
2022-07-12 01:53:13 - train: epoch 0128, iter [00200, 05004], lr: 0.030743, loss: 1.9034
2022-07-12 01:53:47 - train: epoch 0128, iter [00300, 05004], lr: 0.030728, loss: 2.2611
2022-07-12 01:54:23 - train: epoch 0128, iter [00400, 05004], lr: 0.030713, loss: 1.6693
2022-07-12 01:54:57 - train: epoch 0128, iter [00500, 05004], lr: 0.030699, loss: 2.0115
2022-07-12 01:55:31 - train: epoch 0128, iter [00600, 05004], lr: 0.030684, loss: 1.8519
2022-07-12 01:56:07 - train: epoch 0128, iter [00700, 05004], lr: 0.030669, loss: 2.1108
2022-07-12 01:56:41 - train: epoch 0128, iter [00800, 05004], lr: 0.030654, loss: 1.9743
2022-07-12 01:57:16 - train: epoch 0128, iter [00900, 05004], lr: 0.030639, loss: 2.0425
2022-07-12 01:57:51 - train: epoch 0128, iter [01000, 05004], lr: 0.030624, loss: 1.9494
2022-07-12 01:58:26 - train: epoch 0128, iter [01100, 05004], lr: 0.030610, loss: 1.9424
2022-07-12 01:59:01 - train: epoch 0128, iter [01200, 05004], lr: 0.030595, loss: 1.9514
2022-07-12 01:59:35 - train: epoch 0128, iter [01300, 05004], lr: 0.030580, loss: 2.0252
2022-07-12 02:00:10 - train: epoch 0128, iter [01400, 05004], lr: 0.030565, loss: 1.7284
2022-07-12 02:00:45 - train: epoch 0128, iter [01500, 05004], lr: 0.030550, loss: 2.1592
2022-07-12 02:01:20 - train: epoch 0128, iter [01600, 05004], lr: 0.030535, loss: 1.9670
2022-07-12 02:01:54 - train: epoch 0128, iter [01700, 05004], lr: 0.030521, loss: 1.7443
2022-07-12 02:02:30 - train: epoch 0128, iter [01800, 05004], lr: 0.030506, loss: 1.8575
2022-07-12 02:03:04 - train: epoch 0128, iter [01900, 05004], lr: 0.030491, loss: 1.9748
2022-07-12 02:03:39 - train: epoch 0128, iter [02000, 05004], lr: 0.030476, loss: 1.8464
2022-07-12 02:04:15 - train: epoch 0128, iter [02100, 05004], lr: 0.030461, loss: 2.0495
2022-07-12 02:04:49 - train: epoch 0128, iter [02200, 05004], lr: 0.030446, loss: 1.9981
2022-07-12 02:05:25 - train: epoch 0128, iter [02300, 05004], lr: 0.030432, loss: 1.9129
2022-07-12 02:05:59 - train: epoch 0128, iter [02400, 05004], lr: 0.030417, loss: 2.1956
2022-07-12 02:06:34 - train: epoch 0128, iter [02500, 05004], lr: 0.030402, loss: 1.7887
2022-07-12 02:07:09 - train: epoch 0128, iter [02600, 05004], lr: 0.030387, loss: 2.0247
2022-07-12 02:07:43 - train: epoch 0128, iter [02700, 05004], lr: 0.030372, loss: 1.7551
2022-07-12 02:08:18 - train: epoch 0128, iter [02800, 05004], lr: 0.030358, loss: 2.0764
2022-07-12 02:08:53 - train: epoch 0128, iter [02900, 05004], lr: 0.030343, loss: 2.2470
2022-07-12 02:09:29 - train: epoch 0128, iter [03000, 05004], lr: 0.030328, loss: 1.8354
2022-07-12 02:10:04 - train: epoch 0128, iter [03100, 05004], lr: 0.030313, loss: 2.1654
2022-07-12 02:10:39 - train: epoch 0128, iter [03200, 05004], lr: 0.030298, loss: 2.2474
2022-07-12 02:11:14 - train: epoch 0128, iter [03300, 05004], lr: 0.030284, loss: 2.3276
2022-07-12 02:11:48 - train: epoch 0128, iter [03400, 05004], lr: 0.030269, loss: 1.8739
2022-07-12 02:12:23 - train: epoch 0128, iter [03500, 05004], lr: 0.030254, loss: 2.1245
2022-07-12 02:12:58 - train: epoch 0128, iter [03600, 05004], lr: 0.030239, loss: 2.0611
2022-07-12 02:13:33 - train: epoch 0128, iter [03700, 05004], lr: 0.030224, loss: 2.0358
2022-07-12 02:14:08 - train: epoch 0128, iter [03800, 05004], lr: 0.030210, loss: 2.1425
2022-07-12 02:14:43 - train: epoch 0128, iter [03900, 05004], lr: 0.030195, loss: 1.7822
2022-07-12 02:15:17 - train: epoch 0128, iter [04000, 05004], lr: 0.030180, loss: 2.0916
2022-07-12 02:15:53 - train: epoch 0128, iter [04100, 05004], lr: 0.030165, loss: 2.1761
2022-07-12 02:16:27 - train: epoch 0128, iter [04200, 05004], lr: 0.030150, loss: 2.0093
2022-07-12 02:17:02 - train: epoch 0128, iter [04300, 05004], lr: 0.030136, loss: 2.0930
2022-07-12 02:17:37 - train: epoch 0128, iter [04400, 05004], lr: 0.030121, loss: 1.9573
2022-07-12 02:18:12 - train: epoch 0128, iter [04500, 05004], lr: 0.030106, loss: 2.2741
2022-07-12 02:18:47 - train: epoch 0128, iter [04600, 05004], lr: 0.030091, loss: 1.9656
2022-07-12 02:19:22 - train: epoch 0128, iter [04700, 05004], lr: 0.030077, loss: 2.1345
2022-07-12 02:19:57 - train: epoch 0128, iter [04800, 05004], lr: 0.030062, loss: 2.0448
2022-07-12 02:20:31 - train: epoch 0128, iter [04900, 05004], lr: 0.030047, loss: 1.8947
2022-07-12 02:21:05 - train: epoch 0128, iter [05000, 05004], lr: 0.030032, loss: 1.9195
2022-07-12 02:21:06 - train: epoch 128, train_loss: 2.0054
2022-07-12 02:22:22 - eval: epoch: 128, acc1: 65.746%, acc5: 87.084%, test_loss: 1.4116, per_image_load_time: 1.308ms, per_image_inference_time: 0.439ms
2022-07-12 02:22:22 - until epoch: 128, best_acc1: 67.550%
2022-07-12 02:22:22 - epoch 129 lr: 0.030032
2022-07-12 02:23:02 - train: epoch 0129, iter [00100, 05004], lr: 0.030017, loss: 2.0949
2022-07-12 02:23:37 - train: epoch 0129, iter [00200, 05004], lr: 0.030002, loss: 2.2743
2022-07-12 02:24:11 - train: epoch 0129, iter [00300, 05004], lr: 0.029988, loss: 2.0263
2022-07-12 02:24:46 - train: epoch 0129, iter [00400, 05004], lr: 0.029973, loss: 2.1414
2022-07-12 02:25:20 - train: epoch 0129, iter [00500, 05004], lr: 0.029958, loss: 1.9657
2022-07-12 02:25:55 - train: epoch 0129, iter [00600, 05004], lr: 0.029943, loss: 2.4094
2022-07-12 02:26:29 - train: epoch 0129, iter [00700, 05004], lr: 0.029929, loss: 1.9228
2022-07-12 02:27:04 - train: epoch 0129, iter [00800, 05004], lr: 0.029914, loss: 2.0171
2022-07-12 02:27:38 - train: epoch 0129, iter [00900, 05004], lr: 0.029899, loss: 1.9343
2022-07-12 02:28:13 - train: epoch 0129, iter [01000, 05004], lr: 0.029884, loss: 2.1290
2022-07-12 02:28:48 - train: epoch 0129, iter [01100, 05004], lr: 0.029870, loss: 2.0709
2022-07-12 02:29:23 - train: epoch 0129, iter [01200, 05004], lr: 0.029855, loss: 1.9632
2022-07-12 02:29:58 - train: epoch 0129, iter [01300, 05004], lr: 0.029840, loss: 1.8254
2022-07-12 02:30:33 - train: epoch 0129, iter [01400, 05004], lr: 0.029825, loss: 2.0493
2022-07-12 02:31:08 - train: epoch 0129, iter [01500, 05004], lr: 0.029811, loss: 1.8321
2022-07-12 02:31:43 - train: epoch 0129, iter [01600, 05004], lr: 0.029796, loss: 2.2389
2022-07-12 02:32:16 - train: epoch 0129, iter [01700, 05004], lr: 0.029781, loss: 1.6995
2022-07-12 02:32:51 - train: epoch 0129, iter [01800, 05004], lr: 0.029766, loss: 2.0585
2022-07-12 02:33:25 - train: epoch 0129, iter [01900, 05004], lr: 0.029752, loss: 2.2672
2022-07-12 02:34:01 - train: epoch 0129, iter [02000, 05004], lr: 0.029737, loss: 1.8535
2022-07-12 02:34:35 - train: epoch 0129, iter [02100, 05004], lr: 0.029722, loss: 2.0588
2022-07-12 02:35:09 - train: epoch 0129, iter [02200, 05004], lr: 0.029708, loss: 1.8745
2022-07-12 02:35:44 - train: epoch 0129, iter [02300, 05004], lr: 0.029693, loss: 2.1394
2022-07-12 02:36:20 - train: epoch 0129, iter [02400, 05004], lr: 0.029678, loss: 2.0261
2022-07-12 02:36:54 - train: epoch 0129, iter [02500, 05004], lr: 0.029663, loss: 2.3375
2022-07-12 02:37:29 - train: epoch 0129, iter [02600, 05004], lr: 0.029649, loss: 1.9657
2022-07-12 02:38:04 - train: epoch 0129, iter [02700, 05004], lr: 0.029634, loss: 1.9127
2022-07-12 02:38:39 - train: epoch 0129, iter [02800, 05004], lr: 0.029619, loss: 2.0716
2022-07-12 02:39:14 - train: epoch 0129, iter [02900, 05004], lr: 0.029605, loss: 1.9816
2022-07-12 02:39:49 - train: epoch 0129, iter [03000, 05004], lr: 0.029590, loss: 1.8844
2022-07-12 02:40:24 - train: epoch 0129, iter [03100, 05004], lr: 0.029575, loss: 2.0723
2022-07-12 02:40:59 - train: epoch 0129, iter [03200, 05004], lr: 0.029561, loss: 1.7524
2022-07-12 02:41:33 - train: epoch 0129, iter [03300, 05004], lr: 0.029546, loss: 1.8826
2022-07-12 02:42:08 - train: epoch 0129, iter [03400, 05004], lr: 0.029531, loss: 1.9668
2022-07-12 02:42:43 - train: epoch 0129, iter [03500, 05004], lr: 0.029517, loss: 1.9324
2022-07-12 02:43:17 - train: epoch 0129, iter [03600, 05004], lr: 0.029502, loss: 2.0076
2022-07-12 02:43:53 - train: epoch 0129, iter [03700, 05004], lr: 0.029487, loss: 2.0424
2022-07-12 02:44:27 - train: epoch 0129, iter [03800, 05004], lr: 0.029472, loss: 1.7437
2022-07-12 02:45:03 - train: epoch 0129, iter [03900, 05004], lr: 0.029458, loss: 1.8950
2022-07-12 02:45:38 - train: epoch 0129, iter [04000, 05004], lr: 0.029443, loss: 2.0976
2022-07-12 02:46:13 - train: epoch 0129, iter [04100, 05004], lr: 0.029428, loss: 2.0023
2022-07-12 02:46:48 - train: epoch 0129, iter [04200, 05004], lr: 0.029414, loss: 2.3344
2022-07-12 02:47:22 - train: epoch 0129, iter [04300, 05004], lr: 0.029399, loss: 1.9764
2022-07-12 02:47:57 - train: epoch 0129, iter [04400, 05004], lr: 0.029384, loss: 2.1203
2022-07-12 02:48:32 - train: epoch 0129, iter [04500, 05004], lr: 0.029370, loss: 1.8593
2022-07-12 02:49:06 - train: epoch 0129, iter [04600, 05004], lr: 0.029355, loss: 1.8670
2022-07-12 02:49:42 - train: epoch 0129, iter [04700, 05004], lr: 0.029340, loss: 2.0651
2022-07-12 02:50:16 - train: epoch 0129, iter [04800, 05004], lr: 0.029326, loss: 1.8580
2022-07-12 02:50:51 - train: epoch 0129, iter [04900, 05004], lr: 0.029311, loss: 2.0950
2022-07-12 02:51:25 - train: epoch 0129, iter [05000, 05004], lr: 0.029296, loss: 2.1212
2022-07-12 02:51:26 - train: epoch 129, train_loss: 1.9953
2022-07-12 02:52:41 - eval: epoch: 129, acc1: 67.764%, acc5: 88.420%, test_loss: 1.3151, per_image_load_time: 2.430ms, per_image_inference_time: 0.473ms
2022-07-12 02:52:42 - until epoch: 129, best_acc1: 67.764%
2022-07-12 02:52:42 - epoch 130 lr: 0.029296
2022-07-12 02:53:22 - train: epoch 0130, iter [00100, 05004], lr: 0.029281, loss: 1.9786
2022-07-12 02:53:57 - train: epoch 0130, iter [00200, 05004], lr: 0.029267, loss: 1.9057
2022-07-12 02:54:31 - train: epoch 0130, iter [00300, 05004], lr: 0.029252, loss: 1.9114
2022-07-12 02:55:06 - train: epoch 0130, iter [00400, 05004], lr: 0.029237, loss: 2.0827
2022-07-12 02:55:41 - train: epoch 0130, iter [00500, 05004], lr: 0.029223, loss: 1.9034
2022-07-12 02:56:15 - train: epoch 0130, iter [00600, 05004], lr: 0.029208, loss: 1.8582
2022-07-12 02:56:49 - train: epoch 0130, iter [00700, 05004], lr: 0.029193, loss: 1.9294
2022-07-12 02:57:24 - train: epoch 0130, iter [00800, 05004], lr: 0.029179, loss: 1.8610
2022-07-12 02:57:59 - train: epoch 0130, iter [00900, 05004], lr: 0.029164, loss: 2.0324
2022-07-12 02:58:34 - train: epoch 0130, iter [01000, 05004], lr: 0.029149, loss: 2.0242
2022-07-12 02:59:08 - train: epoch 0130, iter [01100, 05004], lr: 0.029135, loss: 2.0602
2022-07-12 02:59:43 - train: epoch 0130, iter [01200, 05004], lr: 0.029120, loss: 2.1627
2022-07-12 03:00:18 - train: epoch 0130, iter [01300, 05004], lr: 0.029106, loss: 1.9043
2022-07-12 03:00:53 - train: epoch 0130, iter [01400, 05004], lr: 0.029091, loss: 2.0126
2022-07-12 03:01:27 - train: epoch 0130, iter [01500, 05004], lr: 0.029076, loss: 2.0534
2022-07-12 03:02:02 - train: epoch 0130, iter [01600, 05004], lr: 0.029062, loss: 1.9457
2022-07-12 03:02:36 - train: epoch 0130, iter [01700, 05004], lr: 0.029047, loss: 1.9069
2022-07-12 03:03:11 - train: epoch 0130, iter [01800, 05004], lr: 0.029032, loss: 2.1613
2022-07-12 03:03:46 - train: epoch 0130, iter [01900, 05004], lr: 0.029018, loss: 1.8940
2022-07-12 03:04:20 - train: epoch 0130, iter [02000, 05004], lr: 0.029003, loss: 2.1948
2022-07-12 03:04:55 - train: epoch 0130, iter [02100, 05004], lr: 0.028989, loss: 2.3545
2022-07-12 03:05:29 - train: epoch 0130, iter [02200, 05004], lr: 0.028974, loss: 2.0984
2022-07-12 03:06:04 - train: epoch 0130, iter [02300, 05004], lr: 0.028959, loss: 2.1181
2022-07-12 03:06:39 - train: epoch 0130, iter [02400, 05004], lr: 0.028945, loss: 2.1092
2022-07-12 03:07:12 - train: epoch 0130, iter [02500, 05004], lr: 0.028930, loss: 1.9297
2022-07-12 03:07:47 - train: epoch 0130, iter [02600, 05004], lr: 0.028916, loss: 2.0085
2022-07-12 03:08:23 - train: epoch 0130, iter [02700, 05004], lr: 0.028901, loss: 2.0803
2022-07-12 03:08:58 - train: epoch 0130, iter [02800, 05004], lr: 0.028886, loss: 1.9134
2022-07-12 03:09:33 - train: epoch 0130, iter [02900, 05004], lr: 0.028872, loss: 2.1907
2022-07-12 03:10:08 - train: epoch 0130, iter [03000, 05004], lr: 0.028857, loss: 1.6762
2022-07-12 03:10:43 - train: epoch 0130, iter [03100, 05004], lr: 0.028843, loss: 2.1554
2022-07-12 03:11:18 - train: epoch 0130, iter [03200, 05004], lr: 0.028828, loss: 1.8515
2022-07-12 03:11:53 - train: epoch 0130, iter [03300, 05004], lr: 0.028814, loss: 2.0754
2022-07-12 03:12:27 - train: epoch 0130, iter [03400, 05004], lr: 0.028799, loss: 2.0709
2022-07-12 03:13:02 - train: epoch 0130, iter [03500, 05004], lr: 0.028784, loss: 2.0674
2022-07-12 03:13:38 - train: epoch 0130, iter [03600, 05004], lr: 0.028770, loss: 2.3248
2022-07-12 03:14:13 - train: epoch 0130, iter [03700, 05004], lr: 0.028755, loss: 2.1235
2022-07-12 03:14:47 - train: epoch 0130, iter [03800, 05004], lr: 0.028741, loss: 1.9944
2022-07-12 03:15:23 - train: epoch 0130, iter [03900, 05004], lr: 0.028726, loss: 1.9512
2022-07-12 03:15:58 - train: epoch 0130, iter [04000, 05004], lr: 0.028712, loss: 1.7929
2022-07-12 03:16:32 - train: epoch 0130, iter [04100, 05004], lr: 0.028697, loss: 2.2704
2022-07-12 03:17:08 - train: epoch 0130, iter [04200, 05004], lr: 0.028682, loss: 1.8272
2022-07-12 03:17:42 - train: epoch 0130, iter [04300, 05004], lr: 0.028668, loss: 1.9054
2022-07-12 03:18:18 - train: epoch 0130, iter [04400, 05004], lr: 0.028653, loss: 2.2584
2022-07-12 03:18:53 - train: epoch 0130, iter [04500, 05004], lr: 0.028639, loss: 2.0239
2022-07-12 03:19:28 - train: epoch 0130, iter [04600, 05004], lr: 0.028624, loss: 1.8836
2022-07-12 03:20:04 - train: epoch 0130, iter [04700, 05004], lr: 0.028610, loss: 2.2182
2022-07-12 03:20:39 - train: epoch 0130, iter [04800, 05004], lr: 0.028595, loss: 1.7586
2022-07-12 03:21:14 - train: epoch 0130, iter [04900, 05004], lr: 0.028580, loss: 1.9082
2022-07-12 03:21:48 - train: epoch 0130, iter [05000, 05004], lr: 0.028566, loss: 2.1169
2022-07-12 03:21:50 - train: epoch 130, train_loss: 1.9859
2022-07-12 03:23:04 - eval: epoch: 130, acc1: 67.746%, acc5: 88.638%, test_loss: 1.3116, per_image_load_time: 2.255ms, per_image_inference_time: 0.520ms
2022-07-12 03:23:05 - until epoch: 130, best_acc1: 67.764%
2022-07-12 03:23:05 - epoch 131 lr: 0.028565
2022-07-12 03:23:45 - train: epoch 0131, iter [00100, 05004], lr: 0.028551, loss: 2.0033
2022-07-12 03:24:19 - train: epoch 0131, iter [00200, 05004], lr: 0.028536, loss: 1.9915
2022-07-12 03:24:54 - train: epoch 0131, iter [00300, 05004], lr: 0.028522, loss: 2.0640
2022-07-12 03:25:29 - train: epoch 0131, iter [00400, 05004], lr: 0.028507, loss: 2.0672
2022-07-12 03:26:03 - train: epoch 0131, iter [00500, 05004], lr: 0.028493, loss: 1.9717
2022-07-12 03:26:38 - train: epoch 0131, iter [00600, 05004], lr: 0.028478, loss: 1.8571
2022-07-12 03:27:13 - train: epoch 0131, iter [00700, 05004], lr: 0.028464, loss: 2.2621
2022-07-12 03:27:47 - train: epoch 0131, iter [00800, 05004], lr: 0.028449, loss: 1.9304
2022-07-12 03:28:23 - train: epoch 0131, iter [00900, 05004], lr: 0.028435, loss: 1.9541
2022-07-12 03:28:58 - train: epoch 0131, iter [01000, 05004], lr: 0.028420, loss: 2.0771
2022-07-12 03:29:32 - train: epoch 0131, iter [01100, 05004], lr: 0.028406, loss: 1.9649
2022-07-12 03:30:07 - train: epoch 0131, iter [01200, 05004], lr: 0.028391, loss: 2.1248
2022-07-12 03:30:42 - train: epoch 0131, iter [01300, 05004], lr: 0.028376, loss: 2.2035
2022-07-12 03:31:18 - train: epoch 0131, iter [01400, 05004], lr: 0.028362, loss: 1.9467
2022-07-12 03:31:52 - train: epoch 0131, iter [01500, 05004], lr: 0.028347, loss: 2.1365
2022-07-12 03:32:27 - train: epoch 0131, iter [01600, 05004], lr: 0.028333, loss: 2.0014
2022-07-12 03:33:01 - train: epoch 0131, iter [01700, 05004], lr: 0.028318, loss: 2.0051
2022-07-12 03:33:36 - train: epoch 0131, iter [01800, 05004], lr: 0.028304, loss: 2.0185
2022-07-12 03:34:12 - train: epoch 0131, iter [01900, 05004], lr: 0.028289, loss: 2.0701
2022-07-12 03:34:46 - train: epoch 0131, iter [02000, 05004], lr: 0.028275, loss: 2.1813
2022-07-12 03:35:21 - train: epoch 0131, iter [02100, 05004], lr: 0.028260, loss: 2.2673
2022-07-12 03:35:57 - train: epoch 0131, iter [02200, 05004], lr: 0.028246, loss: 1.8883
2022-07-12 03:36:31 - train: epoch 0131, iter [02300, 05004], lr: 0.028231, loss: 2.0529
2022-07-12 03:37:06 - train: epoch 0131, iter [02400, 05004], lr: 0.028217, loss: 1.8345
2022-07-12 03:37:41 - train: epoch 0131, iter [02500, 05004], lr: 0.028202, loss: 1.9423
2022-07-12 03:38:16 - train: epoch 0131, iter [02600, 05004], lr: 0.028188, loss: 1.9249
2022-07-12 03:38:50 - train: epoch 0131, iter [02700, 05004], lr: 0.028174, loss: 2.1095
2022-07-12 03:39:25 - train: epoch 0131, iter [02800, 05004], lr: 0.028159, loss: 2.0248
2022-07-12 03:40:00 - train: epoch 0131, iter [02900, 05004], lr: 0.028145, loss: 2.1163
2022-07-12 03:40:35 - train: epoch 0131, iter [03000, 05004], lr: 0.028130, loss: 1.9334
2022-07-12 03:41:10 - train: epoch 0131, iter [03100, 05004], lr: 0.028116, loss: 1.9427
2022-07-12 03:41:45 - train: epoch 0131, iter [03200, 05004], lr: 0.028101, loss: 2.0812
2022-07-12 03:42:20 - train: epoch 0131, iter [03300, 05004], lr: 0.028087, loss: 1.9710
2022-07-12 03:42:56 - train: epoch 0131, iter [03400, 05004], lr: 0.028072, loss: 1.7510
2022-07-12 03:43:30 - train: epoch 0131, iter [03500, 05004], lr: 0.028058, loss: 2.0296
2022-07-12 03:44:06 - train: epoch 0131, iter [03600, 05004], lr: 0.028043, loss: 2.0964
2022-07-12 03:44:40 - train: epoch 0131, iter [03700, 05004], lr: 0.028029, loss: 2.2644
2022-07-12 03:45:16 - train: epoch 0131, iter [03800, 05004], lr: 0.028014, loss: 2.1774
2022-07-12 03:45:51 - train: epoch 0131, iter [03900, 05004], lr: 0.028000, loss: 1.9194
2022-07-12 03:46:27 - train: epoch 0131, iter [04000, 05004], lr: 0.027985, loss: 2.0863
2022-07-12 03:47:02 - train: epoch 0131, iter [04100, 05004], lr: 0.027971, loss: 1.9983
2022-07-12 03:47:37 - train: epoch 0131, iter [04200, 05004], lr: 0.027957, loss: 1.9263
2022-07-12 03:48:12 - train: epoch 0131, iter [04300, 05004], lr: 0.027942, loss: 2.0644
2022-07-12 03:48:47 - train: epoch 0131, iter [04400, 05004], lr: 0.027928, loss: 2.2058
2022-07-12 03:49:23 - train: epoch 0131, iter [04500, 05004], lr: 0.027913, loss: 1.7089
2022-07-12 03:49:57 - train: epoch 0131, iter [04600, 05004], lr: 0.027899, loss: 1.8322
2022-07-12 03:50:33 - train: epoch 0131, iter [04700, 05004], lr: 0.027884, loss: 1.8826
2022-07-12 03:51:08 - train: epoch 0131, iter [04800, 05004], lr: 0.027870, loss: 2.2554
2022-07-12 03:51:43 - train: epoch 0131, iter [04900, 05004], lr: 0.027855, loss: 2.2024
2022-07-12 03:52:17 - train: epoch 0131, iter [05000, 05004], lr: 0.027841, loss: 1.6626
2022-07-12 03:52:18 - train: epoch 131, train_loss: 1.9782
2022-07-12 03:53:34 - eval: epoch: 131, acc1: 68.210%, acc5: 88.558%, test_loss: 1.3046, per_image_load_time: 2.179ms, per_image_inference_time: 0.513ms
2022-07-12 03:53:34 - until epoch: 131, best_acc1: 68.210%
2022-07-12 03:53:34 - epoch 132 lr: 0.027840
2022-07-12 03:54:13 - train: epoch 0132, iter [00100, 05004], lr: 0.027826, loss: 1.8153
2022-07-12 03:54:47 - train: epoch 0132, iter [00200, 05004], lr: 0.027812, loss: 2.2241
2022-07-12 03:55:21 - train: epoch 0132, iter [00300, 05004], lr: 0.027797, loss: 2.3915
2022-07-12 03:55:55 - train: epoch 0132, iter [00400, 05004], lr: 0.027783, loss: 1.6076
2022-07-12 03:56:30 - train: epoch 0132, iter [00500, 05004], lr: 0.027768, loss: 1.8449
2022-07-12 03:57:04 - train: epoch 0132, iter [00600, 05004], lr: 0.027754, loss: 1.9016
2022-07-12 03:57:39 - train: epoch 0132, iter [00700, 05004], lr: 0.027739, loss: 1.8600
2022-07-12 03:58:13 - train: epoch 0132, iter [00800, 05004], lr: 0.027725, loss: 1.8558
2022-07-12 03:58:49 - train: epoch 0132, iter [00900, 05004], lr: 0.027711, loss: 1.8778
2022-07-12 03:59:24 - train: epoch 0132, iter [01000, 05004], lr: 0.027696, loss: 2.0681
2022-07-12 03:59:59 - train: epoch 0132, iter [01100, 05004], lr: 0.027682, loss: 1.9306
2022-07-12 04:00:34 - train: epoch 0132, iter [01200, 05004], lr: 0.027667, loss: 2.0928
2022-07-12 04:01:10 - train: epoch 0132, iter [01300, 05004], lr: 0.027653, loss: 1.7998
2022-07-12 04:01:44 - train: epoch 0132, iter [01400, 05004], lr: 0.027639, loss: 1.8110
2022-07-12 04:02:18 - train: epoch 0132, iter [01500, 05004], lr: 0.027624, loss: 2.0789
2022-07-12 04:02:54 - train: epoch 0132, iter [01600, 05004], lr: 0.027610, loss: 1.9228
2022-07-12 04:03:30 - train: epoch 0132, iter [01700, 05004], lr: 0.027595, loss: 2.3769
2022-07-12 04:04:04 - train: epoch 0132, iter [01800, 05004], lr: 0.027581, loss: 2.1394
2022-07-12 04:04:40 - train: epoch 0132, iter [01900, 05004], lr: 0.027567, loss: 1.6679
2022-07-12 04:05:15 - train: epoch 0132, iter [02000, 05004], lr: 0.027552, loss: 1.8504
2022-07-12 04:05:50 - train: epoch 0132, iter [02100, 05004], lr: 0.027538, loss: 1.9563
2022-07-12 04:06:25 - train: epoch 0132, iter [02200, 05004], lr: 0.027524, loss: 1.9645
2022-07-12 04:07:00 - train: epoch 0132, iter [02300, 05004], lr: 0.027509, loss: 1.9559
2022-07-12 04:07:34 - train: epoch 0132, iter [02400, 05004], lr: 0.027495, loss: 1.8998
2022-07-12 04:08:09 - train: epoch 0132, iter [02500, 05004], lr: 0.027480, loss: 2.0805
2022-07-12 04:08:45 - train: epoch 0132, iter [02600, 05004], lr: 0.027466, loss: 2.0178
2022-07-12 04:09:20 - train: epoch 0132, iter [02700, 05004], lr: 0.027452, loss: 1.8849
2022-07-12 04:09:54 - train: epoch 0132, iter [02800, 05004], lr: 0.027437, loss: 2.0620
2022-07-12 04:10:30 - train: epoch 0132, iter [02900, 05004], lr: 0.027423, loss: 1.8495
2022-07-12 04:11:06 - train: epoch 0132, iter [03000, 05004], lr: 0.027409, loss: 1.9985
2022-07-12 04:11:40 - train: epoch 0132, iter [03100, 05004], lr: 0.027394, loss: 1.9840
2022-07-12 04:12:14 - train: epoch 0132, iter [03200, 05004], lr: 0.027380, loss: 1.7381
2022-07-12 04:12:51 - train: epoch 0132, iter [03300, 05004], lr: 0.027365, loss: 2.0381
2022-07-12 04:13:26 - train: epoch 0132, iter [03400, 05004], lr: 0.027351, loss: 2.1205
2022-07-12 04:14:01 - train: epoch 0132, iter [03500, 05004], lr: 0.027337, loss: 1.8870
2022-07-12 04:14:36 - train: epoch 0132, iter [03600, 05004], lr: 0.027322, loss: 1.9172
2022-07-12 04:15:11 - train: epoch 0132, iter [03700, 05004], lr: 0.027308, loss: 2.1372
2022-07-12 04:15:47 - train: epoch 0132, iter [03800, 05004], lr: 0.027294, loss: 2.1749
2022-07-12 04:16:22 - train: epoch 0132, iter [03900, 05004], lr: 0.027279, loss: 2.0033
2022-07-12 04:16:57 - train: epoch 0132, iter [04000, 05004], lr: 0.027265, loss: 2.0039
2022-07-12 04:17:30 - train: epoch 0132, iter [04100, 05004], lr: 0.027251, loss: 1.8299
2022-07-12 04:18:06 - train: epoch 0132, iter [04200, 05004], lr: 0.027236, loss: 1.8494
2022-07-12 04:18:42 - train: epoch 0132, iter [04300, 05004], lr: 0.027222, loss: 1.9251
2022-07-12 04:19:17 - train: epoch 0132, iter [04400, 05004], lr: 0.027208, loss: 1.9452
2022-07-12 04:19:53 - train: epoch 0132, iter [04500, 05004], lr: 0.027193, loss: 2.1209
2022-07-12 04:20:27 - train: epoch 0132, iter [04600, 05004], lr: 0.027179, loss: 1.9885
2022-07-12 04:21:02 - train: epoch 0132, iter [04700, 05004], lr: 0.027165, loss: 1.9504
2022-07-12 04:21:38 - train: epoch 0132, iter [04800, 05004], lr: 0.027150, loss: 2.0316
2022-07-12 04:22:12 - train: epoch 0132, iter [04900, 05004], lr: 0.027136, loss: 2.1069
2022-07-12 04:22:46 - train: epoch 0132, iter [05000, 05004], lr: 0.027122, loss: 2.1234
2022-07-12 04:22:47 - train: epoch 132, train_loss: 1.9706
2022-07-12 04:24:02 - eval: epoch: 132, acc1: 67.472%, acc5: 88.346%, test_loss: 1.3219, per_image_load_time: 2.063ms, per_image_inference_time: 0.521ms
2022-07-12 04:24:03 - until epoch: 132, best_acc1: 68.210%
2022-07-12 04:24:03 - epoch 133 lr: 0.027121
2022-07-12 04:24:43 - train: epoch 0133, iter [00100, 05004], lr: 0.027107, loss: 1.9219
2022-07-12 04:25:17 - train: epoch 0133, iter [00200, 05004], lr: 0.027093, loss: 1.9205
2022-07-12 04:25:51 - train: epoch 0133, iter [00300, 05004], lr: 0.027078, loss: 2.0022
2022-07-12 04:26:25 - train: epoch 0133, iter [00400, 05004], lr: 0.027064, loss: 2.0271
2022-07-12 04:27:00 - train: epoch 0133, iter [00500, 05004], lr: 0.027050, loss: 2.1016
2022-07-12 04:27:34 - train: epoch 0133, iter [00600, 05004], lr: 0.027035, loss: 2.0937
2022-07-12 04:28:09 - train: epoch 0133, iter [00700, 05004], lr: 0.027021, loss: 1.7794
2022-07-12 04:28:44 - train: epoch 0133, iter [00800, 05004], lr: 0.027007, loss: 1.8782
2022-07-12 04:29:19 - train: epoch 0133, iter [00900, 05004], lr: 0.026992, loss: 2.0092
2022-07-12 04:29:54 - train: epoch 0133, iter [01000, 05004], lr: 0.026978, loss: 1.7837
2022-07-12 04:30:29 - train: epoch 0133, iter [01100, 05004], lr: 0.026964, loss: 2.1149
2022-07-12 04:31:04 - train: epoch 0133, iter [01200, 05004], lr: 0.026950, loss: 1.8420
2022-07-12 04:31:39 - train: epoch 0133, iter [01300, 05004], lr: 0.026935, loss: 1.7964
2022-07-12 04:32:14 - train: epoch 0133, iter [01400, 05004], lr: 0.026921, loss: 1.6346
2022-07-12 04:32:50 - train: epoch 0133, iter [01500, 05004], lr: 0.026907, loss: 1.9610
2022-07-12 04:33:25 - train: epoch 0133, iter [01600, 05004], lr: 0.026893, loss: 2.0287
2022-07-12 04:34:00 - train: epoch 0133, iter [01700, 05004], lr: 0.026878, loss: 2.4004
2022-07-12 04:34:34 - train: epoch 0133, iter [01800, 05004], lr: 0.026864, loss: 1.9630
2022-07-12 04:35:10 - train: epoch 0133, iter [01900, 05004], lr: 0.026850, loss: 1.6955
2022-07-12 04:35:45 - train: epoch 0133, iter [02000, 05004], lr: 0.026835, loss: 1.9811
2022-07-12 04:36:20 - train: epoch 0133, iter [02100, 05004], lr: 0.026821, loss: 2.0492
2022-07-12 04:36:55 - train: epoch 0133, iter [02200, 05004], lr: 0.026807, loss: 1.9487
2022-07-12 04:37:30 - train: epoch 0133, iter [02300, 05004], lr: 0.026793, loss: 1.8441
2022-07-12 04:38:05 - train: epoch 0133, iter [02400, 05004], lr: 0.026778, loss: 2.0330
2022-07-12 04:38:41 - train: epoch 0133, iter [02500, 05004], lr: 0.026764, loss: 1.8058
2022-07-12 04:39:15 - train: epoch 0133, iter [02600, 05004], lr: 0.026750, loss: 1.9384
2022-07-12 04:39:50 - train: epoch 0133, iter [02700, 05004], lr: 0.026736, loss: 1.9919
2022-07-12 04:40:26 - train: epoch 0133, iter [02800, 05004], lr: 0.026721, loss: 1.9986
2022-07-12 04:41:02 - train: epoch 0133, iter [02900, 05004], lr: 0.026707, loss: 1.8813
2022-07-12 04:41:37 - train: epoch 0133, iter [03000, 05004], lr: 0.026693, loss: 1.9136
2022-07-12 04:42:12 - train: epoch 0133, iter [03100, 05004], lr: 0.026679, loss: 1.9079
2022-07-12 04:42:47 - train: epoch 0133, iter [03200, 05004], lr: 0.026664, loss: 1.7597
2022-07-12 04:43:22 - train: epoch 0133, iter [03300, 05004], lr: 0.026650, loss: 1.7759
2022-07-12 04:43:57 - train: epoch 0133, iter [03400, 05004], lr: 0.026636, loss: 2.0776
2022-07-12 04:44:33 - train: epoch 0133, iter [03500, 05004], lr: 0.026622, loss: 2.0390
2022-07-12 04:45:07 - train: epoch 0133, iter [03600, 05004], lr: 0.026607, loss: 2.0559
2022-07-12 04:45:43 - train: epoch 0133, iter [03700, 05004], lr: 0.026593, loss: 2.1938
2022-07-12 04:46:18 - train: epoch 0133, iter [03800, 05004], lr: 0.026579, loss: 1.9439
2022-07-12 04:46:54 - train: epoch 0133, iter [03900, 05004], lr: 0.026565, loss: 1.7796
2022-07-12 04:47:28 - train: epoch 0133, iter [04000, 05004], lr: 0.026551, loss: 1.8641
2022-07-12 04:48:04 - train: epoch 0133, iter [04100, 05004], lr: 0.026536, loss: 1.9857
2022-07-12 04:48:39 - train: epoch 0133, iter [04200, 05004], lr: 0.026522, loss: 1.7651
2022-07-12 04:49:14 - train: epoch 0133, iter [04300, 05004], lr: 0.026508, loss: 2.1598
2022-07-12 04:49:50 - train: epoch 0133, iter [04400, 05004], lr: 0.026494, loss: 1.9772
2022-07-12 04:50:25 - train: epoch 0133, iter [04500, 05004], lr: 0.026480, loss: 2.1079
2022-07-12 04:50:59 - train: epoch 0133, iter [04600, 05004], lr: 0.026465, loss: 1.7738
2022-07-12 04:51:36 - train: epoch 0133, iter [04700, 05004], lr: 0.026451, loss: 2.0289
2022-07-12 04:52:11 - train: epoch 0133, iter [04800, 05004], lr: 0.026437, loss: 1.6164
2022-07-12 04:52:46 - train: epoch 0133, iter [04900, 05004], lr: 0.026423, loss: 2.0223
2022-07-12 04:53:19 - train: epoch 0133, iter [05000, 05004], lr: 0.026409, loss: 1.9091
2022-07-12 04:53:20 - train: epoch 133, train_loss: 1.9597
2022-07-12 04:54:36 - eval: epoch: 133, acc1: 68.844%, acc5: 89.070%, test_loss: 1.2754, per_image_load_time: 2.362ms, per_image_inference_time: 0.497ms
2022-07-12 04:54:36 - until epoch: 133, best_acc1: 68.844%
2022-07-12 04:54:36 - epoch 134 lr: 0.026408
2022-07-12 04:55:16 - train: epoch 0134, iter [00100, 05004], lr: 0.026394, loss: 1.7933
2022-07-12 04:55:50 - train: epoch 0134, iter [00200, 05004], lr: 0.026380, loss: 2.0344
2022-07-12 04:56:25 - train: epoch 0134, iter [00300, 05004], lr: 0.026365, loss: 2.0730
2022-07-12 04:57:00 - train: epoch 0134, iter [00400, 05004], lr: 0.026351, loss: 1.9079
2022-07-12 04:57:34 - train: epoch 0134, iter [00500, 05004], lr: 0.026337, loss: 1.8949
2022-07-12 04:58:10 - train: epoch 0134, iter [00600, 05004], lr: 0.026323, loss: 1.9671
2022-07-12 04:58:44 - train: epoch 0134, iter [00700, 05004], lr: 0.026309, loss: 2.0058
2022-07-12 04:59:18 - train: epoch 0134, iter [00800, 05004], lr: 0.026294, loss: 2.0243
2022-07-12 04:59:54 - train: epoch 0134, iter [00900, 05004], lr: 0.026280, loss: 2.0678
2022-07-12 05:00:28 - train: epoch 0134, iter [01000, 05004], lr: 0.026266, loss: 2.1790
2022-07-12 05:01:02 - train: epoch 0134, iter [01100, 05004], lr: 0.026252, loss: 2.1727
2022-07-12 05:01:38 - train: epoch 0134, iter [01200, 05004], lr: 0.026238, loss: 1.7447
2022-07-12 05:02:13 - train: epoch 0134, iter [01300, 05004], lr: 0.026224, loss: 2.0500
2022-07-12 05:02:47 - train: epoch 0134, iter [01400, 05004], lr: 0.026210, loss: 1.8358
2022-07-12 05:03:22 - train: epoch 0134, iter [01500, 05004], lr: 0.026195, loss: 1.9094
2022-07-12 05:03:57 - train: epoch 0134, iter [01600, 05004], lr: 0.026181, loss: 2.0304
2022-07-12 05:04:31 - train: epoch 0134, iter [01700, 05004], lr: 0.026167, loss: 2.0799
2022-07-12 05:05:06 - train: epoch 0134, iter [01800, 05004], lr: 0.026153, loss: 1.9332
2022-07-12 05:05:41 - train: epoch 0134, iter [01900, 05004], lr: 0.026139, loss: 1.6653
2022-07-12 05:06:16 - train: epoch 0134, iter [02000, 05004], lr: 0.026125, loss: 1.7178
2022-07-12 05:06:51 - train: epoch 0134, iter [02100, 05004], lr: 0.026110, loss: 1.7835
2022-07-12 05:07:27 - train: epoch 0134, iter [02200, 05004], lr: 0.026096, loss: 2.0977
2022-07-12 05:08:01 - train: epoch 0134, iter [02300, 05004], lr: 0.026082, loss: 2.0189
2022-07-12 05:08:37 - train: epoch 0134, iter [02400, 05004], lr: 0.026068, loss: 1.5187
2022-07-12 05:09:12 - train: epoch 0134, iter [02500, 05004], lr: 0.026054, loss: 2.1909
2022-07-12 05:09:47 - train: epoch 0134, iter [02600, 05004], lr: 0.026040, loss: 2.0083
2022-07-12 05:10:22 - train: epoch 0134, iter [02700, 05004], lr: 0.026026, loss: 1.8391
2022-07-12 05:10:58 - train: epoch 0134, iter [02800, 05004], lr: 0.026012, loss: 1.8926
2022-07-12 05:11:34 - train: epoch 0134, iter [02900, 05004], lr: 0.025997, loss: 1.7727
2022-07-12 05:12:08 - train: epoch 0134, iter [03000, 05004], lr: 0.025983, loss: 1.7927
2022-07-12 05:12:43 - train: epoch 0134, iter [03100, 05004], lr: 0.025969, loss: 1.8043
2022-07-12 05:13:19 - train: epoch 0134, iter [03200, 05004], lr: 0.025955, loss: 1.8454
2022-07-12 05:13:54 - train: epoch 0134, iter [03300, 05004], lr: 0.025941, loss: 2.0643
2022-07-12 05:14:28 - train: epoch 0134, iter [03400, 05004], lr: 0.025927, loss: 1.9809
2022-07-12 05:15:04 - train: epoch 0134, iter [03500, 05004], lr: 0.025913, loss: 1.9160
2022-07-12 05:15:39 - train: epoch 0134, iter [03600, 05004], lr: 0.025899, loss: 1.7832
2022-07-12 05:16:14 - train: epoch 0134, iter [03700, 05004], lr: 0.025885, loss: 1.8120
2022-07-12 05:16:50 - train: epoch 0134, iter [03800, 05004], lr: 0.025870, loss: 1.7752
2022-07-12 05:17:25 - train: epoch 0134, iter [03900, 05004], lr: 0.025856, loss: 2.0948
2022-07-12 05:18:00 - train: epoch 0134, iter [04000, 05004], lr: 0.025842, loss: 1.9020
2022-07-12 05:18:34 - train: epoch 0134, iter [04100, 05004], lr: 0.025828, loss: 2.2993
2022-07-12 05:19:09 - train: epoch 0134, iter [04200, 05004], lr: 0.025814, loss: 1.8524
2022-07-12 05:19:45 - train: epoch 0134, iter [04300, 05004], lr: 0.025800, loss: 1.9624
2022-07-12 05:20:20 - train: epoch 0134, iter [04400, 05004], lr: 0.025786, loss: 1.9741
2022-07-12 05:20:55 - train: epoch 0134, iter [04500, 05004], lr: 0.025772, loss: 2.0536
2022-07-12 05:21:31 - train: epoch 0134, iter [04600, 05004], lr: 0.025758, loss: 2.0570
2022-07-12 05:22:05 - train: epoch 0134, iter [04700, 05004], lr: 0.025744, loss: 2.1213
2022-07-12 05:22:40 - train: epoch 0134, iter [04800, 05004], lr: 0.025730, loss: 1.8617
2022-07-12 05:23:15 - train: epoch 0134, iter [04900, 05004], lr: 0.025715, loss: 1.7837
2022-07-12 05:23:50 - train: epoch 0134, iter [05000, 05004], lr: 0.025701, loss: 1.9887
2022-07-12 05:23:51 - train: epoch 134, train_loss: 1.9515
2022-07-12 05:25:07 - eval: epoch: 134, acc1: 68.928%, acc5: 89.190%, test_loss: 1.2581, per_image_load_time: 2.354ms, per_image_inference_time: 0.516ms
2022-07-12 05:25:08 - until epoch: 134, best_acc1: 68.928%
2022-07-12 05:25:08 - epoch 135 lr: 0.025701
2022-07-12 05:25:48 - train: epoch 0135, iter [00100, 05004], lr: 0.025687, loss: 1.7787
2022-07-12 05:26:21 - train: epoch 0135, iter [00200, 05004], lr: 0.025673, loss: 1.9803
2022-07-12 05:26:56 - train: epoch 0135, iter [00300, 05004], lr: 0.025659, loss: 1.5494
2022-07-12 05:27:30 - train: epoch 0135, iter [00400, 05004], lr: 0.025645, loss: 1.9390
2022-07-12 05:28:05 - train: epoch 0135, iter [00500, 05004], lr: 0.025631, loss: 2.1136
2022-07-12 05:28:40 - train: epoch 0135, iter [00600, 05004], lr: 0.025616, loss: 1.9038
2022-07-12 05:29:15 - train: epoch 0135, iter [00700, 05004], lr: 0.025602, loss: 2.0557
2022-07-12 05:29:49 - train: epoch 0135, iter [00800, 05004], lr: 0.025588, loss: 2.1490
2022-07-12 05:30:25 - train: epoch 0135, iter [00900, 05004], lr: 0.025574, loss: 2.0290
2022-07-12 05:30:59 - train: epoch 0135, iter [01000, 05004], lr: 0.025560, loss: 2.2795
2022-07-12 05:31:35 - train: epoch 0135, iter [01100, 05004], lr: 0.025546, loss: 1.7666
2022-07-12 05:32:10 - train: epoch 0135, iter [01200, 05004], lr: 0.025532, loss: 1.6892
2022-07-12 05:32:45 - train: epoch 0135, iter [01300, 05004], lr: 0.025518, loss: 2.0638
2022-07-12 05:33:20 - train: epoch 0135, iter [01400, 05004], lr: 0.025504, loss: 1.9144
2022-07-12 05:33:54 - train: epoch 0135, iter [01500, 05004], lr: 0.025490, loss: 1.9608
2022-07-12 05:34:29 - train: epoch 0135, iter [01600, 05004], lr: 0.025476, loss: 1.7765
2022-07-12 05:35:04 - train: epoch 0135, iter [01700, 05004], lr: 0.025462, loss: 2.3581
2022-07-12 05:35:38 - train: epoch 0135, iter [01800, 05004], lr: 0.025448, loss: 1.8760
2022-07-12 05:36:15 - train: epoch 0135, iter [01900, 05004], lr: 0.025434, loss: 2.1236
2022-07-12 05:36:49 - train: epoch 0135, iter [02000, 05004], lr: 0.025420, loss: 1.6391
2022-07-12 05:37:23 - train: epoch 0135, iter [02100, 05004], lr: 0.025406, loss: 2.1906
2022-07-12 05:37:58 - train: epoch 0135, iter [02200, 05004], lr: 0.025392, loss: 2.0899
2022-07-12 05:38:33 - train: epoch 0135, iter [02300, 05004], lr: 0.025378, loss: 2.1364
2022-07-12 05:39:08 - train: epoch 0135, iter [02400, 05004], lr: 0.025364, loss: 1.8309
2022-07-12 05:39:42 - train: epoch 0135, iter [02500, 05004], lr: 0.025350, loss: 2.2422
2022-07-12 05:40:17 - train: epoch 0135, iter [02600, 05004], lr: 0.025336, loss: 1.9648
2022-07-12 05:40:52 - train: epoch 0135, iter [02700, 05004], lr: 0.025322, loss: 1.9644
2022-07-12 05:41:28 - train: epoch 0135, iter [02800, 05004], lr: 0.025308, loss: 2.1901
2022-07-12 05:42:02 - train: epoch 0135, iter [02900, 05004], lr: 0.025294, loss: 1.8523
2022-07-12 05:42:38 - train: epoch 0135, iter [03000, 05004], lr: 0.025280, loss: 2.0835
2022-07-12 05:43:12 - train: epoch 0135, iter [03100, 05004], lr: 0.025266, loss: 1.9447
2022-07-12 05:43:48 - train: epoch 0135, iter [03200, 05004], lr: 0.025252, loss: 2.1509
2022-07-12 05:44:23 - train: epoch 0135, iter [03300, 05004], lr: 0.025238, loss: 1.9051
2022-07-12 05:44:58 - train: epoch 0135, iter [03400, 05004], lr: 0.025224, loss: 2.1795
2022-07-12 05:45:33 - train: epoch 0135, iter [03500, 05004], lr: 0.025210, loss: 1.9426
2022-07-12 05:46:08 - train: epoch 0135, iter [03600, 05004], lr: 0.025196, loss: 1.8326
2022-07-12 05:46:43 - train: epoch 0135, iter [03700, 05004], lr: 0.025182, loss: 2.0923
2022-07-12 05:47:19 - train: epoch 0135, iter [03800, 05004], lr: 0.025168, loss: 2.0864
2022-07-12 05:47:53 - train: epoch 0135, iter [03900, 05004], lr: 0.025154, loss: 1.8281
2022-07-12 05:48:28 - train: epoch 0135, iter [04000, 05004], lr: 0.025140, loss: 1.9528
2022-07-12 05:49:05 - train: epoch 0135, iter [04100, 05004], lr: 0.025126, loss: 1.9319
2022-07-12 05:49:39 - train: epoch 0135, iter [04200, 05004], lr: 0.025112, loss: 1.9915
2022-07-12 05:50:15 - train: epoch 0135, iter [04300, 05004], lr: 0.025098, loss: 2.0043
2022-07-12 05:50:50 - train: epoch 0135, iter [04400, 05004], lr: 0.025084, loss: 2.0666
2022-07-12 05:51:25 - train: epoch 0135, iter [04500, 05004], lr: 0.025070, loss: 1.8563
2022-07-12 05:52:01 - train: epoch 0135, iter [04600, 05004], lr: 0.025056, loss: 2.1548
2022-07-12 05:52:36 - train: epoch 0135, iter [04700, 05004], lr: 0.025042, loss: 1.9042
2022-07-12 05:53:10 - train: epoch 0135, iter [04800, 05004], lr: 0.025028, loss: 1.7205
2022-07-12 05:53:46 - train: epoch 0135, iter [04900, 05004], lr: 0.025015, loss: 2.0550
2022-07-12 05:54:20 - train: epoch 0135, iter [05000, 05004], lr: 0.025001, loss: 1.6124
2022-07-12 05:54:21 - train: epoch 135, train_loss: 1.9365
2022-07-12 05:55:37 - eval: epoch: 135, acc1: 68.610%, acc5: 89.108%, test_loss: 1.2792, per_image_load_time: 2.252ms, per_image_inference_time: 0.494ms
2022-07-12 05:55:37 - until epoch: 135, best_acc1: 68.928%
2022-07-12 05:55:37 - epoch 136 lr: 0.025000
2022-07-12 05:56:17 - train: epoch 0136, iter [00100, 05004], lr: 0.024986, loss: 1.8262
2022-07-12 05:56:51 - train: epoch 0136, iter [00200, 05004], lr: 0.024972, loss: 1.9766
2022-07-12 05:57:25 - train: epoch 0136, iter [00300, 05004], lr: 0.024958, loss: 2.0340
2022-07-12 05:57:59 - train: epoch 0136, iter [00400, 05004], lr: 0.024944, loss: 1.9316
2022-07-12 05:58:34 - train: epoch 0136, iter [00500, 05004], lr: 0.024930, loss: 2.0324
2022-07-12 05:59:09 - train: epoch 0136, iter [00600, 05004], lr: 0.024916, loss: 1.6848
2022-07-12 05:59:43 - train: epoch 0136, iter [00700, 05004], lr: 0.024902, loss: 2.0003
2022-07-12 06:00:19 - train: epoch 0136, iter [00800, 05004], lr: 0.024889, loss: 2.1596
2022-07-12 06:00:53 - train: epoch 0136, iter [00900, 05004], lr: 0.024875, loss: 1.9742
2022-07-12 06:01:28 - train: epoch 0136, iter [01000, 05004], lr: 0.024861, loss: 1.9461
2022-07-12 06:02:02 - train: epoch 0136, iter [01100, 05004], lr: 0.024847, loss: 1.8879
2022-07-12 06:02:37 - train: epoch 0136, iter [01200, 05004], lr: 0.024833, loss: 2.0347
2022-07-12 06:03:12 - train: epoch 0136, iter [01300, 05004], lr: 0.024819, loss: 1.7406
2022-07-12 06:03:47 - train: epoch 0136, iter [01400, 05004], lr: 0.024805, loss: 1.8305
2022-07-12 06:04:22 - train: epoch 0136, iter [01500, 05004], lr: 0.024791, loss: 2.0359
2022-07-12 06:04:56 - train: epoch 0136, iter [01600, 05004], lr: 0.024777, loss: 1.8461
2022-07-12 06:05:32 - train: epoch 0136, iter [01700, 05004], lr: 0.024763, loss: 1.9791
2022-07-12 06:06:07 - train: epoch 0136, iter [01800, 05004], lr: 0.024749, loss: 1.8908
2022-07-12 06:06:42 - train: epoch 0136, iter [01900, 05004], lr: 0.024736, loss: 1.8612
2022-07-12 06:07:16 - train: epoch 0136, iter [02000, 05004], lr: 0.024722, loss: 1.6153
2022-07-12 06:07:51 - train: epoch 0136, iter [02100, 05004], lr: 0.024708, loss: 1.7366
2022-07-12 06:08:26 - train: epoch 0136, iter [02200, 05004], lr: 0.024694, loss: 1.6608
2022-07-12 06:09:01 - train: epoch 0136, iter [02300, 05004], lr: 0.024680, loss: 2.1196
2022-07-12 06:09:36 - train: epoch 0136, iter [02400, 05004], lr: 0.024666, loss: 1.6098
2022-07-12 06:10:11 - train: epoch 0136, iter [02500, 05004], lr: 0.024652, loss: 2.1971
2022-07-12 06:10:45 - train: epoch 0136, iter [02600, 05004], lr: 0.024638, loss: 1.8817
2022-07-12 06:11:20 - train: epoch 0136, iter [02700, 05004], lr: 0.024625, loss: 1.6071
2022-07-12 06:11:55 - train: epoch 0136, iter [02800, 05004], lr: 0.024611, loss: 1.8803
2022-07-12 06:12:31 - train: epoch 0136, iter [02900, 05004], lr: 0.024597, loss: 1.7964
2022-07-12 06:13:05 - train: epoch 0136, iter [03000, 05004], lr: 0.024583, loss: 2.1354
2022-07-12 06:13:41 - train: epoch 0136, iter [03100, 05004], lr: 0.024569, loss: 1.7681
2022-07-12 06:14:16 - train: epoch 0136, iter [03200, 05004], lr: 0.024555, loss: 2.1219
2022-07-12 06:14:51 - train: epoch 0136, iter [03300, 05004], lr: 0.024541, loss: 1.9162
2022-07-12 06:15:26 - train: epoch 0136, iter [03400, 05004], lr: 0.024528, loss: 2.0005
2022-07-12 06:16:01 - train: epoch 0136, iter [03500, 05004], lr: 0.024514, loss: 1.7293
2022-07-12 06:16:36 - train: epoch 0136, iter [03600, 05004], lr: 0.024500, loss: 2.0109
2022-07-12 06:17:12 - train: epoch 0136, iter [03700, 05004], lr: 0.024486, loss: 1.7130
2022-07-12 06:17:47 - train: epoch 0136, iter [03800, 05004], lr: 0.024472, loss: 1.8193
2022-07-12 06:18:21 - train: epoch 0136, iter [03900, 05004], lr: 0.024458, loss: 1.9583
2022-07-12 06:18:56 - train: epoch 0136, iter [04000, 05004], lr: 0.024444, loss: 1.9166
2022-07-12 06:19:31 - train: epoch 0136, iter [04100, 05004], lr: 0.024431, loss: 1.9524
2022-07-12 06:20:07 - train: epoch 0136, iter [04200, 05004], lr: 0.024417, loss: 1.6815
2022-07-12 06:20:42 - train: epoch 0136, iter [04300, 05004], lr: 0.024403, loss: 2.0318
2022-07-12 06:21:18 - train: epoch 0136, iter [04400, 05004], lr: 0.024389, loss: 1.7190
2022-07-12 06:21:53 - train: epoch 0136, iter [04500, 05004], lr: 0.024375, loss: 1.9761
2022-07-12 06:22:28 - train: epoch 0136, iter [04600, 05004], lr: 0.024361, loss: 1.7379
2022-07-12 06:23:03 - train: epoch 0136, iter [04700, 05004], lr: 0.024348, loss: 2.0421
2022-07-12 06:23:39 - train: epoch 0136, iter [04800, 05004], lr: 0.024334, loss: 1.9728
2022-07-12 06:24:14 - train: epoch 0136, iter [04900, 05004], lr: 0.024320, loss: 2.0532
2022-07-12 06:24:48 - train: epoch 0136, iter [05000, 05004], lr: 0.024306, loss: 1.9205
2022-07-12 06:24:49 - train: epoch 136, train_loss: 1.9316
2022-07-12 06:26:04 - eval: epoch: 136, acc1: 69.162%, acc5: 89.132%, test_loss: 1.2545, per_image_load_time: 2.382ms, per_image_inference_time: 0.489ms
2022-07-12 06:26:04 - until epoch: 136, best_acc1: 69.162%
2022-07-12 06:26:04 - epoch 137 lr: 0.024306
2022-07-12 06:26:44 - train: epoch 0137, iter [00100, 05004], lr: 0.024292, loss: 1.8399
2022-07-12 06:27:17 - train: epoch 0137, iter [00200, 05004], lr: 0.024278, loss: 2.0287
2022-07-12 06:27:52 - train: epoch 0137, iter [00300, 05004], lr: 0.024264, loss: 1.9223
2022-07-12 06:28:27 - train: epoch 0137, iter [00400, 05004], lr: 0.024250, loss: 1.8871
2022-07-12 06:29:02 - train: epoch 0137, iter [00500, 05004], lr: 0.024237, loss: 1.8708
2022-07-12 06:29:36 - train: epoch 0137, iter [00600, 05004], lr: 0.024223, loss: 1.7440
2022-07-12 06:30:11 - train: epoch 0137, iter [00700, 05004], lr: 0.024209, loss: 1.7952
2022-07-12 06:30:45 - train: epoch 0137, iter [00800, 05004], lr: 0.024195, loss: 1.9289
2022-07-12 06:31:20 - train: epoch 0137, iter [00900, 05004], lr: 0.024181, loss: 2.0038
2022-07-12 06:31:56 - train: epoch 0137, iter [01000, 05004], lr: 0.024168, loss: 1.8635
2022-07-12 06:32:30 - train: epoch 0137, iter [01100, 05004], lr: 0.024154, loss: 2.0636
2022-07-12 06:33:05 - train: epoch 0137, iter [01200, 05004], lr: 0.024140, loss: 2.1346
2022-07-12 06:33:40 - train: epoch 0137, iter [01300, 05004], lr: 0.024126, loss: 1.7592
2022-07-12 06:34:15 - train: epoch 0137, iter [01400, 05004], lr: 0.024113, loss: 1.9944
2022-07-12 06:34:50 - train: epoch 0137, iter [01500, 05004], lr: 0.024099, loss: 2.0987
2022-07-12 06:35:25 - train: epoch 0137, iter [01600, 05004], lr: 0.024085, loss: 1.9139
2022-07-12 06:36:00 - train: epoch 0137, iter [01700, 05004], lr: 0.024071, loss: 1.9621
2022-07-12 06:36:35 - train: epoch 0137, iter [01800, 05004], lr: 0.024058, loss: 2.2668
2022-07-12 06:37:09 - train: epoch 0137, iter [01900, 05004], lr: 0.024044, loss: 1.7134
2022-07-12 06:37:45 - train: epoch 0137, iter [02000, 05004], lr: 0.024030, loss: 1.8172
2022-07-12 06:38:19 - train: epoch 0137, iter [02100, 05004], lr: 0.024016, loss: 1.8512
2022-07-12 06:38:54 - train: epoch 0137, iter [02200, 05004], lr: 0.024002, loss: 2.0078
2022-07-12 06:39:29 - train: epoch 0137, iter [02300, 05004], lr: 0.023989, loss: 1.7711
2022-07-12 06:40:05 - train: epoch 0137, iter [02400, 05004], lr: 0.023975, loss: 1.9411
2022-07-12 06:40:39 - train: epoch 0137, iter [02500, 05004], lr: 0.023961, loss: 1.6673
2022-07-12 06:41:15 - train: epoch 0137, iter [02600, 05004], lr: 0.023948, loss: 2.0189
2022-07-12 06:41:50 - train: epoch 0137, iter [02700, 05004], lr: 0.023934, loss: 1.6474
2022-07-12 06:42:25 - train: epoch 0137, iter [02800, 05004], lr: 0.023920, loss: 1.7107
2022-07-12 06:43:00 - train: epoch 0137, iter [02900, 05004], lr: 0.023906, loss: 1.9154
2022-07-12 06:43:35 - train: epoch 0137, iter [03000, 05004], lr: 0.023893, loss: 1.8963
2022-07-12 06:44:11 - train: epoch 0137, iter [03100, 05004], lr: 0.023879, loss: 2.0028
2022-07-12 06:44:46 - train: epoch 0137, iter [03200, 05004], lr: 0.023865, loss: 2.0044
2022-07-12 06:45:21 - train: epoch 0137, iter [03300, 05004], lr: 0.023851, loss: 1.7971
2022-07-12 06:45:56 - train: epoch 0137, iter [03400, 05004], lr: 0.023838, loss: 1.9524
2022-07-12 06:46:31 - train: epoch 0137, iter [03500, 05004], lr: 0.023824, loss: 1.7797
2022-07-12 06:47:06 - train: epoch 0137, iter [03600, 05004], lr: 0.023810, loss: 1.7494
2022-07-12 06:47:41 - train: epoch 0137, iter [03700, 05004], lr: 0.023797, loss: 2.1049
2022-07-12 06:48:17 - train: epoch 0137, iter [03800, 05004], lr: 0.023783, loss: 1.9168
2022-07-12 06:48:52 - train: epoch 0137, iter [03900, 05004], lr: 0.023769, loss: 2.0179
2022-07-12 06:49:26 - train: epoch 0137, iter [04000, 05004], lr: 0.023755, loss: 2.0915
2022-07-12 06:50:02 - train: epoch 0137, iter [04100, 05004], lr: 0.023742, loss: 1.7752
2022-07-12 06:50:37 - train: epoch 0137, iter [04200, 05004], lr: 0.023728, loss: 2.2164
2022-07-12 06:51:12 - train: epoch 0137, iter [04300, 05004], lr: 0.023714, loss: 1.7303
2022-07-12 06:51:48 - train: epoch 0137, iter [04400, 05004], lr: 0.023701, loss: 2.0857
2022-07-12 06:52:23 - train: epoch 0137, iter [04500, 05004], lr: 0.023687, loss: 1.9838
2022-07-12 06:52:58 - train: epoch 0137, iter [04600, 05004], lr: 0.023673, loss: 1.8319
2022-07-12 06:53:33 - train: epoch 0137, iter [04700, 05004], lr: 0.023660, loss: 1.8664
2022-07-12 06:54:08 - train: epoch 0137, iter [04800, 05004], lr: 0.023646, loss: 1.6698
2022-07-12 06:54:43 - train: epoch 0137, iter [04900, 05004], lr: 0.023632, loss: 1.9783
2022-07-12 06:55:17 - train: epoch 0137, iter [05000, 05004], lr: 0.023619, loss: 1.9196
2022-07-12 06:55:18 - train: epoch 137, train_loss: 1.9208
2022-07-12 06:56:33 - eval: epoch: 137, acc1: 66.368%, acc5: 87.598%, test_loss: 1.3777, per_image_load_time: 2.449ms, per_image_inference_time: 0.474ms
2022-07-12 06:56:34 - until epoch: 137, best_acc1: 69.162%
2022-07-12 06:56:34 - epoch 138 lr: 0.023618
2022-07-12 06:57:13 - train: epoch 0138, iter [00100, 05004], lr: 0.023604, loss: 1.7647
2022-07-12 06:57:48 - train: epoch 0138, iter [00200, 05004], lr: 0.023591, loss: 1.9901
2022-07-12 06:58:23 - train: epoch 0138, iter [00300, 05004], lr: 0.023577, loss: 2.1172
2022-07-12 06:58:58 - train: epoch 0138, iter [00400, 05004], lr: 0.023563, loss: 2.0483
2022-07-12 06:59:32 - train: epoch 0138, iter [00500, 05004], lr: 0.023550, loss: 1.5907
2022-07-12 07:00:06 - train: epoch 0138, iter [00600, 05004], lr: 0.023536, loss: 1.9909
2022-07-12 07:00:42 - train: epoch 0138, iter [00700, 05004], lr: 0.023522, loss: 1.7013
2022-07-12 07:01:16 - train: epoch 0138, iter [00800, 05004], lr: 0.023509, loss: 1.6304
2022-07-12 07:01:52 - train: epoch 0138, iter [00900, 05004], lr: 0.023495, loss: 1.7232
2022-07-12 07:02:27 - train: epoch 0138, iter [01000, 05004], lr: 0.023481, loss: 1.7858
2022-07-12 07:03:02 - train: epoch 0138, iter [01100, 05004], lr: 0.023468, loss: 1.8074
2022-07-12 07:03:36 - train: epoch 0138, iter [01200, 05004], lr: 0.023454, loss: 2.2284
2022-07-12 07:04:12 - train: epoch 0138, iter [01300, 05004], lr: 0.023440, loss: 1.9392
2022-07-12 07:04:48 - train: epoch 0138, iter [01400, 05004], lr: 0.023427, loss: 1.8899
2022-07-12 07:05:23 - train: epoch 0138, iter [01500, 05004], lr: 0.023413, loss: 1.8534
2022-07-12 07:05:58 - train: epoch 0138, iter [01600, 05004], lr: 0.023400, loss: 1.8417
2022-07-12 07:06:33 - train: epoch 0138, iter [01700, 05004], lr: 0.023386, loss: 1.8573
2022-07-12 07:07:08 - train: epoch 0138, iter [01800, 05004], lr: 0.023372, loss: 1.7652
2022-07-12 07:07:42 - train: epoch 0138, iter [01900, 05004], lr: 0.023359, loss: 2.0591
2022-07-12 07:08:17 - train: epoch 0138, iter [02000, 05004], lr: 0.023345, loss: 1.9662
2022-07-12 07:08:53 - train: epoch 0138, iter [02100, 05004], lr: 0.023331, loss: 1.8704
2022-07-12 07:09:28 - train: epoch 0138, iter [02200, 05004], lr: 0.023318, loss: 1.6020
2022-07-12 07:10:03 - train: epoch 0138, iter [02300, 05004], lr: 0.023304, loss: 1.9422
2022-07-12 07:10:37 - train: epoch 0138, iter [02400, 05004], lr: 0.023291, loss: 1.8865
2022-07-12 07:11:13 - train: epoch 0138, iter [02500, 05004], lr: 0.023277, loss: 2.0556
2022-07-12 07:11:49 - train: epoch 0138, iter [02600, 05004], lr: 0.023263, loss: 2.1074
2022-07-12 07:12:24 - train: epoch 0138, iter [02700, 05004], lr: 0.023250, loss: 1.9127
2022-07-12 07:12:59 - train: epoch 0138, iter [02800, 05004], lr: 0.023236, loss: 1.8337
2022-07-12 07:13:34 - train: epoch 0138, iter [02900, 05004], lr: 0.023223, loss: 1.8710
2022-07-12 07:14:10 - train: epoch 0138, iter [03000, 05004], lr: 0.023209, loss: 1.9707
2022-07-12 07:14:46 - train: epoch 0138, iter [03100, 05004], lr: 0.023195, loss: 1.9334
2022-07-12 07:15:21 - train: epoch 0138, iter [03200, 05004], lr: 0.023182, loss: 1.8116
2022-07-12 07:15:56 - train: epoch 0138, iter [03300, 05004], lr: 0.023168, loss: 2.0434
2022-07-12 07:16:31 - train: epoch 0138, iter [03400, 05004], lr: 0.023155, loss: 1.8197
2022-07-12 07:17:06 - train: epoch 0138, iter [03500, 05004], lr: 0.023141, loss: 1.6361
2022-07-12 07:17:41 - train: epoch 0138, iter [03600, 05004], lr: 0.023127, loss: 1.9874
2022-07-12 07:18:16 - train: epoch 0138, iter [03700, 05004], lr: 0.023114, loss: 1.8435
2022-07-12 07:18:51 - train: epoch 0138, iter [03800, 05004], lr: 0.023100, loss: 1.9088
2022-07-12 07:19:27 - train: epoch 0138, iter [03900, 05004], lr: 0.023087, loss: 1.9621
2022-07-12 07:20:02 - train: epoch 0138, iter [04000, 05004], lr: 0.023073, loss: 2.0682
2022-07-12 07:20:37 - train: epoch 0138, iter [04100, 05004], lr: 0.023060, loss: 1.7710
2022-07-12 07:21:12 - train: epoch 0138, iter [04200, 05004], lr: 0.023046, loss: 2.0103
2022-07-12 07:21:48 - train: epoch 0138, iter [04300, 05004], lr: 0.023033, loss: 1.7212
2022-07-12 07:22:23 - train: epoch 0138, iter [04400, 05004], lr: 0.023019, loss: 2.0794
2022-07-12 07:22:58 - train: epoch 0138, iter [04500, 05004], lr: 0.023005, loss: 2.1014
2022-07-12 07:23:34 - train: epoch 0138, iter [04600, 05004], lr: 0.022992, loss: 1.8764
2022-07-12 07:24:08 - train: epoch 0138, iter [04700, 05004], lr: 0.022978, loss: 1.8152
2022-07-12 07:24:44 - train: epoch 0138, iter [04800, 05004], lr: 0.022965, loss: 2.0428
2022-07-12 07:25:19 - train: epoch 0138, iter [04900, 05004], lr: 0.022951, loss: 1.8240
2022-07-12 07:25:52 - train: epoch 0138, iter [05000, 05004], lr: 0.022938, loss: 2.2269
2022-07-12 07:25:53 - train: epoch 138, train_loss: 1.9100
2022-07-12 07:27:08 - eval: epoch: 138, acc1: 68.770%, acc5: 89.202%, test_loss: 1.2664, per_image_load_time: 1.997ms, per_image_inference_time: 0.503ms
2022-07-12 07:27:09 - until epoch: 138, best_acc1: 69.162%
2022-07-12 07:27:09 - epoch 139 lr: 0.022937
2022-07-12 07:27:49 - train: epoch 0139, iter [00100, 05004], lr: 0.022924, loss: 1.8577
2022-07-12 07:28:23 - train: epoch 0139, iter [00200, 05004], lr: 0.022910, loss: 1.7924
2022-07-12 07:28:56 - train: epoch 0139, iter [00300, 05004], lr: 0.022897, loss: 1.6656
2022-07-12 07:29:31 - train: epoch 0139, iter [00400, 05004], lr: 0.022883, loss: 2.0193
2022-07-12 07:30:07 - train: epoch 0139, iter [00500, 05004], lr: 0.022870, loss: 1.9968
2022-07-12 07:30:40 - train: epoch 0139, iter [00600, 05004], lr: 0.022856, loss: 1.8312
2022-07-12 07:31:15 - train: epoch 0139, iter [00700, 05004], lr: 0.022842, loss: 1.9424
2022-07-12 07:31:50 - train: epoch 0139, iter [00800, 05004], lr: 0.022829, loss: 2.3315
2022-07-12 07:32:25 - train: epoch 0139, iter [00900, 05004], lr: 0.022815, loss: 2.0068
2022-07-12 07:33:00 - train: epoch 0139, iter [01000, 05004], lr: 0.022802, loss: 1.8865
2022-07-12 07:33:36 - train: epoch 0139, iter [01100, 05004], lr: 0.022788, loss: 1.8617
2022-07-12 07:34:10 - train: epoch 0139, iter [01200, 05004], lr: 0.022775, loss: 1.8466
2022-07-12 07:34:46 - train: epoch 0139, iter [01300, 05004], lr: 0.022761, loss: 1.8003
2022-07-12 07:35:20 - train: epoch 0139, iter [01400, 05004], lr: 0.022748, loss: 1.8363
2022-07-12 07:35:55 - train: epoch 0139, iter [01500, 05004], lr: 0.022734, loss: 1.9691
2022-07-12 07:36:30 - train: epoch 0139, iter [01600, 05004], lr: 0.022721, loss: 1.8582
2022-07-12 07:37:05 - train: epoch 0139, iter [01700, 05004], lr: 0.022707, loss: 2.1098
2022-07-12 07:37:40 - train: epoch 0139, iter [01800, 05004], lr: 0.022694, loss: 1.7291
2022-07-12 07:38:15 - train: epoch 0139, iter [01900, 05004], lr: 0.022680, loss: 2.0756
2022-07-12 07:38:50 - train: epoch 0139, iter [02000, 05004], lr: 0.022667, loss: 1.9243
2022-07-12 07:39:26 - train: epoch 0139, iter [02100, 05004], lr: 0.022654, loss: 1.7119
2022-07-12 07:40:01 - train: epoch 0139, iter [02200, 05004], lr: 0.022640, loss: 2.1149
2022-07-12 07:40:36 - train: epoch 0139, iter [02300, 05004], lr: 0.022627, loss: 1.9385
2022-07-12 07:41:11 - train: epoch 0139, iter [02400, 05004], lr: 0.022613, loss: 2.0297
2022-07-12 07:41:46 - train: epoch 0139, iter [02500, 05004], lr: 0.022600, loss: 1.8581
2022-07-12 07:42:21 - train: epoch 0139, iter [02600, 05004], lr: 0.022586, loss: 1.9059
2022-07-12 07:42:56 - train: epoch 0139, iter [02700, 05004], lr: 0.022573, loss: 1.9698
2022-07-12 07:43:31 - train: epoch 0139, iter [02800, 05004], lr: 0.022559, loss: 2.0274
2022-07-12 07:44:06 - train: epoch 0139, iter [02900, 05004], lr: 0.022546, loss: 1.9706
2022-07-12 07:44:41 - train: epoch 0139, iter [03000, 05004], lr: 0.022532, loss: 1.8293
2022-07-12 07:45:17 - train: epoch 0139, iter [03100, 05004], lr: 0.022519, loss: 2.1892
2022-07-12 07:45:53 - train: epoch 0139, iter [03200, 05004], lr: 0.022505, loss: 1.7877
2022-07-12 07:46:27 - train: epoch 0139, iter [03300, 05004], lr: 0.022492, loss: 1.9593
2022-07-12 07:47:02 - train: epoch 0139, iter [03400, 05004], lr: 0.022479, loss: 1.9176
2022-07-12 07:47:38 - train: epoch 0139, iter [03500, 05004], lr: 0.022465, loss: 1.9853
2022-07-12 07:48:13 - train: epoch 0139, iter [03600, 05004], lr: 0.022452, loss: 1.6820
2022-07-12 07:48:48 - train: epoch 0139, iter [03700, 05004], lr: 0.022438, loss: 1.7740
2022-07-12 07:49:23 - train: epoch 0139, iter [03800, 05004], lr: 0.022425, loss: 2.0961
2022-07-12 07:50:00 - train: epoch 0139, iter [03900, 05004], lr: 0.022411, loss: 1.8709
2022-07-12 07:50:35 - train: epoch 0139, iter [04000, 05004], lr: 0.022398, loss: 1.9998
2022-07-12 07:51:10 - train: epoch 0139, iter [04100, 05004], lr: 0.022385, loss: 1.7479
2022-07-12 07:51:45 - train: epoch 0139, iter [04200, 05004], lr: 0.022371, loss: 2.0239
2022-07-12 07:52:21 - train: epoch 0139, iter [04300, 05004], lr: 0.022358, loss: 1.7937
2022-07-12 07:52:56 - train: epoch 0139, iter [04400, 05004], lr: 0.022344, loss: 1.8554
2022-07-12 07:53:32 - train: epoch 0139, iter [04500, 05004], lr: 0.022331, loss: 1.9365
2022-07-12 07:54:07 - train: epoch 0139, iter [04600, 05004], lr: 0.022317, loss: 2.0005
2022-07-12 07:54:42 - train: epoch 0139, iter [04700, 05004], lr: 0.022304, loss: 2.0926
2022-07-12 07:55:18 - train: epoch 0139, iter [04800, 05004], lr: 0.022291, loss: 1.9788
2022-07-12 07:55:52 - train: epoch 0139, iter [04900, 05004], lr: 0.022277, loss: 1.9429
2022-07-12 07:56:26 - train: epoch 0139, iter [05000, 05004], lr: 0.022264, loss: 1.8608
2022-07-12 07:56:27 - train: epoch 139, train_loss: 1.8935
2022-07-12 07:57:42 - eval: epoch: 139, acc1: 69.448%, acc5: 89.428%, test_loss: 1.2448, per_image_load_time: 2.205ms, per_image_inference_time: 0.523ms
2022-07-12 07:57:42 - until epoch: 139, best_acc1: 69.448%
2022-07-12 07:57:42 - epoch 140 lr: 0.022263
2022-07-12 07:58:22 - train: epoch 0140, iter [00100, 05004], lr: 0.022250, loss: 1.5036
2022-07-12 07:58:56 - train: epoch 0140, iter [00200, 05004], lr: 0.022237, loss: 2.0625
2022-07-12 07:59:30 - train: epoch 0140, iter [00300, 05004], lr: 0.022223, loss: 1.8372
2022-07-12 08:00:04 - train: epoch 0140, iter [00400, 05004], lr: 0.022210, loss: 1.7465
2022-07-12 08:00:38 - train: epoch 0140, iter [00500, 05004], lr: 0.022196, loss: 1.7654
2022-07-12 08:01:13 - train: epoch 0140, iter [00600, 05004], lr: 0.022183, loss: 1.9973
2022-07-12 08:01:46 - train: epoch 0140, iter [00700, 05004], lr: 0.022170, loss: 1.7417
2022-07-12 08:02:20 - train: epoch 0140, iter [00800, 05004], lr: 0.022156, loss: 1.8711
2022-07-12 08:02:55 - train: epoch 0140, iter [00900, 05004], lr: 0.022143, loss: 2.1257
2022-07-12 08:03:29 - train: epoch 0140, iter [01000, 05004], lr: 0.022130, loss: 2.1053
2022-07-12 08:04:03 - train: epoch 0140, iter [01100, 05004], lr: 0.022116, loss: 1.7373
2022-07-12 08:04:38 - train: epoch 0140, iter [01200, 05004], lr: 0.022103, loss: 2.0152
2022-07-12 08:05:12 - train: epoch 0140, iter [01300, 05004], lr: 0.022089, loss: 1.9721
2022-07-12 08:05:46 - train: epoch 0140, iter [01400, 05004], lr: 0.022076, loss: 1.6713
2022-07-12 08:06:20 - train: epoch 0140, iter [01500, 05004], lr: 0.022063, loss: 1.7528
2022-07-12 08:06:56 - train: epoch 0140, iter [01600, 05004], lr: 0.022049, loss: 1.8502
2022-07-12 08:07:29 - train: epoch 0140, iter [01700, 05004], lr: 0.022036, loss: 1.8516
2022-07-12 08:08:03 - train: epoch 0140, iter [01800, 05004], lr: 0.022023, loss: 1.9820
2022-07-12 08:08:38 - train: epoch 0140, iter [01900, 05004], lr: 0.022009, loss: 2.0922
2022-07-12 08:09:12 - train: epoch 0140, iter [02000, 05004], lr: 0.021996, loss: 1.9577
2022-07-12 08:09:46 - train: epoch 0140, iter [02100, 05004], lr: 0.021983, loss: 2.0197
2022-07-12 08:10:22 - train: epoch 0140, iter [02200, 05004], lr: 0.021969, loss: 1.8154
2022-07-12 08:10:56 - train: epoch 0140, iter [02300, 05004], lr: 0.021956, loss: 1.6101
2022-07-12 08:11:31 - train: epoch 0140, iter [02400, 05004], lr: 0.021943, loss: 1.7759
2022-07-12 08:12:06 - train: epoch 0140, iter [02500, 05004], lr: 0.021929, loss: 1.9462
2022-07-12 08:12:40 - train: epoch 0140, iter [02600, 05004], lr: 0.021916, loss: 1.9223
2022-07-12 08:13:15 - train: epoch 0140, iter [02700, 05004], lr: 0.021903, loss: 1.8141
2022-07-12 08:13:50 - train: epoch 0140, iter [02800, 05004], lr: 0.021889, loss: 1.9866
2022-07-12 08:14:24 - train: epoch 0140, iter [02900, 05004], lr: 0.021876, loss: 1.9674
2022-07-12 08:14:59 - train: epoch 0140, iter [03000, 05004], lr: 0.021863, loss: 1.8810
2022-07-12 08:15:33 - train: epoch 0140, iter [03100, 05004], lr: 0.021850, loss: 1.7957
2022-07-12 08:16:08 - train: epoch 0140, iter [03200, 05004], lr: 0.021836, loss: 1.9159
2022-07-12 08:16:41 - train: epoch 0140, iter [03300, 05004], lr: 0.021823, loss: 1.8520
2022-07-12 08:17:17 - train: epoch 0140, iter [03400, 05004], lr: 0.021810, loss: 1.8147
2022-07-12 08:17:52 - train: epoch 0140, iter [03500, 05004], lr: 0.021796, loss: 1.9030
2022-07-12 08:18:26 - train: epoch 0140, iter [03600, 05004], lr: 0.021783, loss: 2.0310
2022-07-12 08:18:59 - train: epoch 0140, iter [03700, 05004], lr: 0.021770, loss: 1.5492
2022-07-12 08:19:34 - train: epoch 0140, iter [03800, 05004], lr: 0.021756, loss: 2.1581
2022-07-12 08:20:09 - train: epoch 0140, iter [03900, 05004], lr: 0.021743, loss: 2.0449
2022-07-12 08:20:43 - train: epoch 0140, iter [04000, 05004], lr: 0.021730, loss: 2.0256
2022-07-12 08:21:18 - train: epoch 0140, iter [04100, 05004], lr: 0.021717, loss: 2.0274
2022-07-12 08:21:53 - train: epoch 0140, iter [04200, 05004], lr: 0.021703, loss: 1.8958
2022-07-12 08:22:27 - train: epoch 0140, iter [04300, 05004], lr: 0.021690, loss: 2.2609
2022-07-12 08:23:02 - train: epoch 0140, iter [04400, 05004], lr: 0.021677, loss: 1.8329
2022-07-12 08:23:37 - train: epoch 0140, iter [04500, 05004], lr: 0.021664, loss: 1.8584
2022-07-12 08:24:11 - train: epoch 0140, iter [04600, 05004], lr: 0.021650, loss: 1.9685
2022-07-12 08:24:46 - train: epoch 0140, iter [04700, 05004], lr: 0.021637, loss: 1.9867
2022-07-12 08:25:21 - train: epoch 0140, iter [04800, 05004], lr: 0.021624, loss: 2.1396
2022-07-12 08:25:56 - train: epoch 0140, iter [04900, 05004], lr: 0.021611, loss: 1.7773
2022-07-12 08:26:29 - train: epoch 0140, iter [05000, 05004], lr: 0.021597, loss: 1.9623
2022-07-12 08:26:30 - train: epoch 140, train_loss: 1.8866
2022-07-12 08:27:45 - eval: epoch: 140, acc1: 67.748%, acc5: 88.494%, test_loss: 1.3146, per_image_load_time: 2.128ms, per_image_inference_time: 0.489ms
2022-07-12 08:27:45 - until epoch: 140, best_acc1: 69.448%
2022-07-12 08:27:45 - epoch 141 lr: 0.021597
2022-07-12 08:28:25 - train: epoch 0141, iter [00100, 05004], lr: 0.021584, loss: 1.8181
2022-07-12 08:28:59 - train: epoch 0141, iter [00200, 05004], lr: 0.021570, loss: 1.7878
2022-07-12 08:29:34 - train: epoch 0141, iter [00300, 05004], lr: 0.021557, loss: 1.8567
2022-07-12 08:30:09 - train: epoch 0141, iter [00400, 05004], lr: 0.021544, loss: 1.8221
2022-07-12 08:30:43 - train: epoch 0141, iter [00500, 05004], lr: 0.021531, loss: 1.7912
2022-07-12 08:31:18 - train: epoch 0141, iter [00600, 05004], lr: 0.021517, loss: 1.9443
2022-07-12 08:31:53 - train: epoch 0141, iter [00700, 05004], lr: 0.021504, loss: 1.9142
2022-07-12 08:32:28 - train: epoch 0141, iter [00800, 05004], lr: 0.021491, loss: 1.6068
2022-07-12 08:33:03 - train: epoch 0141, iter [00900, 05004], lr: 0.021478, loss: 1.7675
2022-07-12 08:33:38 - train: epoch 0141, iter [01000, 05004], lr: 0.021464, loss: 1.8391
2022-07-12 08:34:13 - train: epoch 0141, iter [01100, 05004], lr: 0.021451, loss: 1.8198
2022-07-12 08:34:47 - train: epoch 0141, iter [01200, 05004], lr: 0.021438, loss: 2.1322
2022-07-12 08:35:21 - train: epoch 0141, iter [01300, 05004], lr: 0.021425, loss: 1.9756
2022-07-12 08:35:57 - train: epoch 0141, iter [01400, 05004], lr: 0.021412, loss: 1.8018
2022-07-12 08:36:31 - train: epoch 0141, iter [01500, 05004], lr: 0.021398, loss: 1.6769
2022-07-12 08:37:06 - train: epoch 0141, iter [01600, 05004], lr: 0.021385, loss: 1.6725
2022-07-12 08:37:40 - train: epoch 0141, iter [01700, 05004], lr: 0.021372, loss: 1.8964
2022-07-12 08:38:16 - train: epoch 0141, iter [01800, 05004], lr: 0.021359, loss: 1.7581
2022-07-12 08:38:50 - train: epoch 0141, iter [01900, 05004], lr: 0.021346, loss: 1.6836
2022-07-12 08:39:25 - train: epoch 0141, iter [02000, 05004], lr: 0.021332, loss: 2.0319
2022-07-12 08:39:59 - train: epoch 0141, iter [02100, 05004], lr: 0.021319, loss: 1.7656
2022-07-12 08:40:34 - train: epoch 0141, iter [02200, 05004], lr: 0.021306, loss: 1.9275
2022-07-12 08:41:08 - train: epoch 0141, iter [02300, 05004], lr: 0.021293, loss: 1.8862
2022-07-12 08:41:43 - train: epoch 0141, iter [02400, 05004], lr: 0.021280, loss: 2.0709
2022-07-12 08:42:17 - train: epoch 0141, iter [02500, 05004], lr: 0.021266, loss: 2.1902
2022-07-12 08:42:52 - train: epoch 0141, iter [02600, 05004], lr: 0.021253, loss: 2.0323
2022-07-12 08:43:26 - train: epoch 0141, iter [02700, 05004], lr: 0.021240, loss: 1.8039
2022-07-12 08:44:01 - train: epoch 0141, iter [02800, 05004], lr: 0.021227, loss: 1.8740
2022-07-12 08:44:36 - train: epoch 0141, iter [02900, 05004], lr: 0.021214, loss: 1.5711
2022-07-12 08:45:10 - train: epoch 0141, iter [03000, 05004], lr: 0.021201, loss: 1.6785
2022-07-12 08:45:45 - train: epoch 0141, iter [03100, 05004], lr: 0.021187, loss: 2.1328
2022-07-12 08:46:20 - train: epoch 0141, iter [03200, 05004], lr: 0.021174, loss: 1.6929
2022-07-12 08:46:56 - train: epoch 0141, iter [03300, 05004], lr: 0.021161, loss: 2.1755
2022-07-12 08:47:30 - train: epoch 0141, iter [03400, 05004], lr: 0.021148, loss: 1.7615
2022-07-12 08:48:05 - train: epoch 0141, iter [03500, 05004], lr: 0.021135, loss: 2.0950
2022-07-12 08:48:40 - train: epoch 0141, iter [03600, 05004], lr: 0.021122, loss: 1.9225
2022-07-12 08:49:16 - train: epoch 0141, iter [03700, 05004], lr: 0.021109, loss: 1.6621
2022-07-12 08:49:51 - train: epoch 0141, iter [03800, 05004], lr: 0.021095, loss: 1.9461
2022-07-12 08:50:26 - train: epoch 0141, iter [03900, 05004], lr: 0.021082, loss: 1.6637
2022-07-12 08:51:01 - train: epoch 0141, iter [04000, 05004], lr: 0.021069, loss: 1.9364
2022-07-12 08:51:36 - train: epoch 0141, iter [04100, 05004], lr: 0.021056, loss: 1.8378
2022-07-12 08:52:12 - train: epoch 0141, iter [04200, 05004], lr: 0.021043, loss: 2.1775
2022-07-12 08:52:46 - train: epoch 0141, iter [04300, 05004], lr: 0.021030, loss: 2.0820
2022-07-12 08:53:22 - train: epoch 0141, iter [04400, 05004], lr: 0.021017, loss: 2.0371
2022-07-12 08:53:56 - train: epoch 0141, iter [04500, 05004], lr: 0.021004, loss: 1.7768
2022-07-12 08:54:32 - train: epoch 0141, iter [04600, 05004], lr: 0.020990, loss: 1.8568
2022-07-12 08:55:07 - train: epoch 0141, iter [04700, 05004], lr: 0.020977, loss: 2.0099
2022-07-12 08:55:42 - train: epoch 0141, iter [04800, 05004], lr: 0.020964, loss: 1.9303
2022-07-12 08:56:17 - train: epoch 0141, iter [04900, 05004], lr: 0.020951, loss: 2.0461
2022-07-12 08:56:51 - train: epoch 0141, iter [05000, 05004], lr: 0.020938, loss: 2.0360
2022-07-12 08:56:52 - train: epoch 141, train_loss: 1.8776
2022-07-12 08:58:06 - eval: epoch: 141, acc1: 70.036%, acc5: 89.936%, test_loss: 1.2068, per_image_load_time: 1.495ms, per_image_inference_time: 0.484ms
2022-07-12 08:58:07 - until epoch: 141, best_acc1: 70.036%
2022-07-12 08:58:07 - epoch 142 lr: 0.020937
2022-07-12 08:58:47 - train: epoch 0142, iter [00100, 05004], lr: 0.020924, loss: 2.0300
2022-07-12 08:59:21 - train: epoch 0142, iter [00200, 05004], lr: 0.020911, loss: 1.6816
2022-07-12 08:59:57 - train: epoch 0142, iter [00300, 05004], lr: 0.020898, loss: 1.7733
2022-07-12 09:00:31 - train: epoch 0142, iter [00400, 05004], lr: 0.020885, loss: 1.7995
2022-07-12 09:01:07 - train: epoch 0142, iter [00500, 05004], lr: 0.020872, loss: 1.8212
2022-07-12 09:01:41 - train: epoch 0142, iter [00600, 05004], lr: 0.020859, loss: 1.7586
2022-07-12 09:02:15 - train: epoch 0142, iter [00700, 05004], lr: 0.020846, loss: 1.7632
2022-07-12 09:02:49 - train: epoch 0142, iter [00800, 05004], lr: 0.020833, loss: 2.0098
2022-07-12 09:03:25 - train: epoch 0142, iter [00900, 05004], lr: 0.020820, loss: 1.4765
2022-07-12 09:04:00 - train: epoch 0142, iter [01000, 05004], lr: 0.020807, loss: 1.8595
2022-07-12 09:04:34 - train: epoch 0142, iter [01100, 05004], lr: 0.020794, loss: 1.8352
2022-07-12 09:05:09 - train: epoch 0142, iter [01200, 05004], lr: 0.020781, loss: 1.8604
2022-07-12 09:05:44 - train: epoch 0142, iter [01300, 05004], lr: 0.020767, loss: 1.9852
2022-07-12 09:06:18 - train: epoch 0142, iter [01400, 05004], lr: 0.020754, loss: 2.0220
2022-07-12 09:06:52 - train: epoch 0142, iter [01500, 05004], lr: 0.020741, loss: 2.2115
2022-07-12 09:07:27 - train: epoch 0142, iter [01600, 05004], lr: 0.020728, loss: 2.1072
2022-07-12 09:08:01 - train: epoch 0142, iter [01700, 05004], lr: 0.020715, loss: 1.9898
2022-07-12 09:08:35 - train: epoch 0142, iter [01800, 05004], lr: 0.020702, loss: 1.8886
2022-07-12 09:09:09 - train: epoch 0142, iter [01900, 05004], lr: 0.020689, loss: 1.9762
2022-07-12 09:09:44 - train: epoch 0142, iter [02000, 05004], lr: 0.020676, loss: 1.7947
2022-07-12 09:10:19 - train: epoch 0142, iter [02100, 05004], lr: 0.020663, loss: 1.8503
2022-07-12 09:10:53 - train: epoch 0142, iter [02200, 05004], lr: 0.020650, loss: 1.5407
2022-07-12 09:11:28 - train: epoch 0142, iter [02300, 05004], lr: 0.020637, loss: 1.6712
2022-07-12 09:12:03 - train: epoch 0142, iter [02400, 05004], lr: 0.020624, loss: 2.0219
2022-07-12 09:12:38 - train: epoch 0142, iter [02500, 05004], lr: 0.020611, loss: 1.8157
2022-07-12 09:13:13 - train: epoch 0142, iter [02600, 05004], lr: 0.020598, loss: 1.8195
2022-07-12 09:13:47 - train: epoch 0142, iter [02700, 05004], lr: 0.020585, loss: 1.8168
2022-07-12 09:14:22 - train: epoch 0142, iter [02800, 05004], lr: 0.020572, loss: 1.7329
2022-07-12 09:14:57 - train: epoch 0142, iter [02900, 05004], lr: 0.020559, loss: 1.6468
2022-07-12 09:15:32 - train: epoch 0142, iter [03000, 05004], lr: 0.020546, loss: 2.0254
2022-07-12 09:16:07 - train: epoch 0142, iter [03100, 05004], lr: 0.020533, loss: 1.7663
2022-07-12 09:16:42 - train: epoch 0142, iter [03200, 05004], lr: 0.020520, loss: 2.0550
2022-07-12 09:17:17 - train: epoch 0142, iter [03300, 05004], lr: 0.020507, loss: 1.9588
2022-07-12 09:17:51 - train: epoch 0142, iter [03400, 05004], lr: 0.020494, loss: 1.7953
2022-07-12 09:18:26 - train: epoch 0142, iter [03500, 05004], lr: 0.020481, loss: 1.9584
2022-07-12 09:19:02 - train: epoch 0142, iter [03600, 05004], lr: 0.020468, loss: 1.8938
2022-07-12 09:19:37 - train: epoch 0142, iter [03700, 05004], lr: 0.020455, loss: 2.1704
2022-07-12 09:20:12 - train: epoch 0142, iter [03800, 05004], lr: 0.020442, loss: 2.0715
2022-07-12 09:20:47 - train: epoch 0142, iter [03900, 05004], lr: 0.020429, loss: 1.7899
2022-07-12 09:21:22 - train: epoch 0142, iter [04000, 05004], lr: 0.020416, loss: 1.7847
2022-07-12 09:21:58 - train: epoch 0142, iter [04100, 05004], lr: 0.020403, loss: 1.8350
2022-07-12 09:22:33 - train: epoch 0142, iter [04200, 05004], lr: 0.020390, loss: 1.8620
2022-07-12 09:23:08 - train: epoch 0142, iter [04300, 05004], lr: 0.020377, loss: 1.5205
2022-07-12 09:23:43 - train: epoch 0142, iter [04400, 05004], lr: 0.020364, loss: 1.9097
2022-07-12 09:24:19 - train: epoch 0142, iter [04500, 05004], lr: 0.020351, loss: 1.7137
2022-07-12 09:24:55 - train: epoch 0142, iter [04600, 05004], lr: 0.020338, loss: 1.7384
2022-07-12 09:25:29 - train: epoch 0142, iter [04700, 05004], lr: 0.020325, loss: 2.0215
2022-07-12 09:26:06 - train: epoch 0142, iter [04800, 05004], lr: 0.020312, loss: 1.6962
2022-07-12 09:26:40 - train: epoch 0142, iter [04900, 05004], lr: 0.020299, loss: 1.9784
2022-07-12 09:27:14 - train: epoch 0142, iter [05000, 05004], lr: 0.020286, loss: 1.7081
2022-07-12 09:27:15 - train: epoch 142, train_loss: 1.8685
2022-07-12 09:28:31 - eval: epoch: 142, acc1: 68.802%, acc5: 89.226%, test_loss: 1.2678, per_image_load_time: 2.491ms, per_image_inference_time: 0.470ms
2022-07-12 09:28:31 - until epoch: 142, best_acc1: 70.036%
2022-07-12 09:28:31 - epoch 143 lr: 0.020286
2022-07-12 09:29:11 - train: epoch 0143, iter [00100, 05004], lr: 0.020273, loss: 1.9961
2022-07-12 09:29:46 - train: epoch 0143, iter [00200, 05004], lr: 0.020260, loss: 1.5317
2022-07-12 09:30:21 - train: epoch 0143, iter [00300, 05004], lr: 0.020247, loss: 1.7408
2022-07-12 09:30:54 - train: epoch 0143, iter [00400, 05004], lr: 0.020234, loss: 1.6449
2022-07-12 09:31:28 - train: epoch 0143, iter [00500, 05004], lr: 0.020221, loss: 2.0440
2022-07-12 09:32:02 - train: epoch 0143, iter [00600, 05004], lr: 0.020208, loss: 2.0942
2022-07-12 09:32:37 - train: epoch 0143, iter [00700, 05004], lr: 0.020195, loss: 1.8974
2022-07-12 09:33:11 - train: epoch 0143, iter [00800, 05004], lr: 0.020182, loss: 1.7797
2022-07-12 09:33:46 - train: epoch 0143, iter [00900, 05004], lr: 0.020169, loss: 2.0046
2022-07-12 09:34:20 - train: epoch 0143, iter [01000, 05004], lr: 0.020157, loss: 1.7809
2022-07-12 09:34:55 - train: epoch 0143, iter [01100, 05004], lr: 0.020144, loss: 1.9491
2022-07-12 09:35:30 - train: epoch 0143, iter [01200, 05004], lr: 0.020131, loss: 1.9690
2022-07-12 09:36:04 - train: epoch 0143, iter [01300, 05004], lr: 0.020118, loss: 1.6583
2022-07-12 09:36:39 - train: epoch 0143, iter [01400, 05004], lr: 0.020105, loss: 2.0007
2022-07-12 09:37:13 - train: epoch 0143, iter [01500, 05004], lr: 0.020092, loss: 1.8492
2022-07-12 09:37:47 - train: epoch 0143, iter [01600, 05004], lr: 0.020079, loss: 1.8593
2022-07-12 09:38:22 - train: epoch 0143, iter [01700, 05004], lr: 0.020066, loss: 1.9267
2022-07-12 09:38:56 - train: epoch 0143, iter [01800, 05004], lr: 0.020053, loss: 1.9318
2022-07-12 09:39:31 - train: epoch 0143, iter [01900, 05004], lr: 0.020040, loss: 1.6214
2022-07-12 09:40:05 - train: epoch 0143, iter [02000, 05004], lr: 0.020028, loss: 1.8678
2022-07-12 09:40:40 - train: epoch 0143, iter [02100, 05004], lr: 0.020015, loss: 1.8607
2022-07-12 09:41:14 - train: epoch 0143, iter [02200, 05004], lr: 0.020002, loss: 1.7679
2022-07-12 09:41:49 - train: epoch 0143, iter [02300, 05004], lr: 0.019989, loss: 2.0206
2022-07-12 09:42:24 - train: epoch 0143, iter [02400, 05004], lr: 0.019976, loss: 1.8155
2022-07-12 09:42:59 - train: epoch 0143, iter [02500, 05004], lr: 0.019963, loss: 2.1315
2022-07-12 09:43:33 - train: epoch 0143, iter [02600, 05004], lr: 0.019950, loss: 1.7414
2022-07-12 09:44:08 - train: epoch 0143, iter [02700, 05004], lr: 0.019937, loss: 1.8370
2022-07-12 09:44:43 - train: epoch 0143, iter [02800, 05004], lr: 0.019925, loss: 1.8455
2022-07-12 09:45:18 - train: epoch 0143, iter [02900, 05004], lr: 0.019912, loss: 2.0372
2022-07-12 09:45:53 - train: epoch 0143, iter [03000, 05004], lr: 0.019899, loss: 1.9541
2022-07-12 09:46:28 - train: epoch 0143, iter [03100, 05004], lr: 0.019886, loss: 1.7356
2022-07-12 09:47:02 - train: epoch 0143, iter [03200, 05004], lr: 0.019873, loss: 2.1376
2022-07-12 09:47:37 - train: epoch 0143, iter [03300, 05004], lr: 0.019860, loss: 1.7531
2022-07-12 09:48:12 - train: epoch 0143, iter [03400, 05004], lr: 0.019847, loss: 1.7861
2022-07-12 09:48:49 - train: epoch 0143, iter [03500, 05004], lr: 0.019835, loss: 1.9251
2022-07-12 09:49:22 - train: epoch 0143, iter [03600, 05004], lr: 0.019822, loss: 1.9638
2022-07-12 09:49:58 - train: epoch 0143, iter [03700, 05004], lr: 0.019809, loss: 1.7744
2022-07-12 09:50:33 - train: epoch 0143, iter [03800, 05004], lr: 0.019796, loss: 1.7294
2022-07-12 09:51:07 - train: epoch 0143, iter [03900, 05004], lr: 0.019783, loss: 1.8119
2022-07-12 09:51:43 - train: epoch 0143, iter [04000, 05004], lr: 0.019770, loss: 2.0485
2022-07-12 09:52:18 - train: epoch 0143, iter [04100, 05004], lr: 0.019758, loss: 1.7414
2022-07-12 09:52:52 - train: epoch 0143, iter [04200, 05004], lr: 0.019745, loss: 1.9380
2022-07-12 09:53:27 - train: epoch 0143, iter [04300, 05004], lr: 0.019732, loss: 1.9517
2022-07-12 09:54:02 - train: epoch 0143, iter [04400, 05004], lr: 0.019719, loss: 1.7561
2022-07-12 09:54:37 - train: epoch 0143, iter [04500, 05004], lr: 0.019706, loss: 1.8932
2022-07-12 09:55:11 - train: epoch 0143, iter [04600, 05004], lr: 0.019694, loss: 2.1115
2022-07-12 09:55:45 - train: epoch 0143, iter [04700, 05004], lr: 0.019681, loss: 1.6604
2022-07-12 09:56:20 - train: epoch 0143, iter [04800, 05004], lr: 0.019668, loss: 1.6887
2022-07-12 09:56:55 - train: epoch 0143, iter [04900, 05004], lr: 0.019655, loss: 1.7265
2022-07-12 09:57:29 - train: epoch 0143, iter [05000, 05004], lr: 0.019642, loss: 2.1412
2022-07-12 09:57:30 - train: epoch 143, train_loss: 1.8583
2022-07-12 09:58:46 - eval: epoch: 143, acc1: 69.170%, acc5: 89.378%, test_loss: 1.2395, per_image_load_time: 2.479ms, per_image_inference_time: 0.489ms
2022-07-12 09:58:47 - until epoch: 143, best_acc1: 70.036%
2022-07-12 09:58:47 - epoch 144 lr: 0.019642
2022-07-12 09:59:26 - train: epoch 0144, iter [00100, 05004], lr: 0.019629, loss: 1.5996
2022-07-12 10:00:00 - train: epoch 0144, iter [00200, 05004], lr: 0.019616, loss: 1.7081
2022-07-12 10:00:34 - train: epoch 0144, iter [00300, 05004], lr: 0.019604, loss: 1.8009
2022-07-12 10:01:08 - train: epoch 0144, iter [00400, 05004], lr: 0.019591, loss: 1.9472
2022-07-12 10:01:42 - train: epoch 0144, iter [00500, 05004], lr: 0.019578, loss: 1.8587
2022-07-12 10:02:16 - train: epoch 0144, iter [00600, 05004], lr: 0.019565, loss: 1.8971
2022-07-12 10:02:50 - train: epoch 0144, iter [00700, 05004], lr: 0.019552, loss: 1.6716
2022-07-12 10:03:24 - train: epoch 0144, iter [00800, 05004], lr: 0.019540, loss: 2.1596
2022-07-12 10:03:58 - train: epoch 0144, iter [00900, 05004], lr: 0.019527, loss: 1.8562
2022-07-12 10:04:32 - train: epoch 0144, iter [01000, 05004], lr: 0.019514, loss: 1.7939
2022-07-12 10:05:05 - train: epoch 0144, iter [01100, 05004], lr: 0.019501, loss: 1.8219
2022-07-12 10:05:40 - train: epoch 0144, iter [01200, 05004], lr: 0.019489, loss: 1.8277
2022-07-12 10:06:14 - train: epoch 0144, iter [01300, 05004], lr: 0.019476, loss: 1.8806
2022-07-12 10:06:48 - train: epoch 0144, iter [01400, 05004], lr: 0.019463, loss: 1.8183
2022-07-12 10:07:23 - train: epoch 0144, iter [01500, 05004], lr: 0.019450, loss: 2.0190
2022-07-12 10:07:57 - train: epoch 0144, iter [01600, 05004], lr: 0.019438, loss: 1.7008
2022-07-12 10:08:32 - train: epoch 0144, iter [01700, 05004], lr: 0.019425, loss: 1.8482
2022-07-12 10:09:07 - train: epoch 0144, iter [01800, 05004], lr: 0.019412, loss: 1.6028
2022-07-12 10:09:41 - train: epoch 0144, iter [01900, 05004], lr: 0.019399, loss: 1.8156
2022-07-12 10:10:16 - train: epoch 0144, iter [02000, 05004], lr: 0.019387, loss: 1.9534
2022-07-12 10:10:51 - train: epoch 0144, iter [02100, 05004], lr: 0.019374, loss: 2.0342
2022-07-12 10:11:25 - train: epoch 0144, iter [02200, 05004], lr: 0.019361, loss: 1.8710
2022-07-12 10:12:00 - train: epoch 0144, iter [02300, 05004], lr: 0.019349, loss: 1.6060
2022-07-12 10:12:34 - train: epoch 0144, iter [02400, 05004], lr: 0.019336, loss: 1.9565
2022-07-12 10:13:09 - train: epoch 0144, iter [02500, 05004], lr: 0.019323, loss: 1.7578
2022-07-12 10:13:45 - train: epoch 0144, iter [02600, 05004], lr: 0.019310, loss: 1.8150
2022-07-12 10:14:20 - train: epoch 0144, iter [02700, 05004], lr: 0.019298, loss: 1.6367
2022-07-12 10:14:54 - train: epoch 0144, iter [02800, 05004], lr: 0.019285, loss: 1.6921
2022-07-12 10:15:29 - train: epoch 0144, iter [02900, 05004], lr: 0.019272, loss: 2.0054
2022-07-12 10:16:04 - train: epoch 0144, iter [03000, 05004], lr: 0.019260, loss: 2.1970
2022-07-12 10:16:39 - train: epoch 0144, iter [03100, 05004], lr: 0.019247, loss: 2.1208
2022-07-12 10:17:14 - train: epoch 0144, iter [03200, 05004], lr: 0.019234, loss: 1.9179
2022-07-12 10:17:47 - train: epoch 0144, iter [03300, 05004], lr: 0.019221, loss: 1.9179
2022-07-12 10:18:23 - train: epoch 0144, iter [03400, 05004], lr: 0.019209, loss: 2.0143
2022-07-12 10:18:57 - train: epoch 0144, iter [03500, 05004], lr: 0.019196, loss: 1.8706
2022-07-12 10:19:33 - train: epoch 0144, iter [03600, 05004], lr: 0.019183, loss: 1.7217
2022-07-12 10:20:07 - train: epoch 0144, iter [03700, 05004], lr: 0.019171, loss: 1.8740
2022-07-12 10:20:42 - train: epoch 0144, iter [03800, 05004], lr: 0.019158, loss: 1.7575
2022-07-12 10:21:17 - train: epoch 0144, iter [03900, 05004], lr: 0.019145, loss: 1.4796
2022-07-12 10:21:52 - train: epoch 0144, iter [04000, 05004], lr: 0.019133, loss: 1.8864
2022-07-12 10:22:26 - train: epoch 0144, iter [04100, 05004], lr: 0.019120, loss: 1.8034
2022-07-12 10:23:01 - train: epoch 0144, iter [04200, 05004], lr: 0.019107, loss: 1.7489
2022-07-12 10:23:36 - train: epoch 0144, iter [04300, 05004], lr: 0.019095, loss: 1.9471
2022-07-12 10:24:11 - train: epoch 0144, iter [04400, 05004], lr: 0.019082, loss: 2.2652
2022-07-12 10:24:46 - train: epoch 0144, iter [04500, 05004], lr: 0.019069, loss: 1.9149
2022-07-12 10:25:20 - train: epoch 0144, iter [04600, 05004], lr: 0.019057, loss: 1.8328
2022-07-12 10:25:56 - train: epoch 0144, iter [04700, 05004], lr: 0.019044, loss: 1.9174
2022-07-12 10:26:29 - train: epoch 0144, iter [04800, 05004], lr: 0.019032, loss: 2.0384
2022-07-12 10:27:05 - train: epoch 0144, iter [04900, 05004], lr: 0.019019, loss: 2.1027
2022-07-12 10:27:37 - train: epoch 0144, iter [05000, 05004], lr: 0.019006, loss: 1.9182
2022-07-12 10:27:38 - train: epoch 144, train_loss: 1.8498
2022-07-12 10:28:53 - eval: epoch: 144, acc1: 68.802%, acc5: 89.092%, test_loss: 1.2638, per_image_load_time: 2.350ms, per_image_inference_time: 0.471ms
2022-07-12 10:28:53 - until epoch: 144, best_acc1: 70.036%
2022-07-12 10:28:53 - epoch 145 lr: 0.019006
2022-07-12 10:29:32 - train: epoch 0145, iter [00100, 05004], lr: 0.018993, loss: 1.4911
2022-07-12 10:30:07 - train: epoch 0145, iter [00200, 05004], lr: 0.018981, loss: 1.5470
2022-07-12 10:30:41 - train: epoch 0145, iter [00300, 05004], lr: 0.018968, loss: 1.6223
2022-07-12 10:31:15 - train: epoch 0145, iter [00400, 05004], lr: 0.018955, loss: 1.8379
2022-07-12 10:31:50 - train: epoch 0145, iter [00500, 05004], lr: 0.018943, loss: 2.0104
2022-07-12 10:32:24 - train: epoch 0145, iter [00600, 05004], lr: 0.018930, loss: 2.0861
2022-07-12 10:32:58 - train: epoch 0145, iter [00700, 05004], lr: 0.018917, loss: 1.8308
2022-07-12 10:33:32 - train: epoch 0145, iter [00800, 05004], lr: 0.018905, loss: 1.9002
2022-07-12 10:34:07 - train: epoch 0145, iter [00900, 05004], lr: 0.018892, loss: 1.7475
2022-07-12 10:34:42 - train: epoch 0145, iter [01000, 05004], lr: 0.018880, loss: 1.8010
2022-07-12 10:35:17 - train: epoch 0145, iter [01100, 05004], lr: 0.018867, loss: 1.7738
2022-07-12 10:35:51 - train: epoch 0145, iter [01200, 05004], lr: 0.018854, loss: 1.9054
2022-07-12 10:36:26 - train: epoch 0145, iter [01300, 05004], lr: 0.018842, loss: 1.8351
2022-07-12 10:37:00 - train: epoch 0145, iter [01400, 05004], lr: 0.018829, loss: 1.8487
2022-07-12 10:37:36 - train: epoch 0145, iter [01500, 05004], lr: 0.018817, loss: 1.8228
2022-07-12 10:38:10 - train: epoch 0145, iter [01600, 05004], lr: 0.018804, loss: 1.7489
2022-07-12 10:38:45 - train: epoch 0145, iter [01700, 05004], lr: 0.018792, loss: 1.8435
2022-07-12 10:39:21 - train: epoch 0145, iter [01800, 05004], lr: 0.018779, loss: 1.6849
2022-07-12 10:39:55 - train: epoch 0145, iter [01900, 05004], lr: 0.018766, loss: 1.8076
2022-07-12 10:40:31 - train: epoch 0145, iter [02000, 05004], lr: 0.018754, loss: 2.0217
2022-07-12 10:41:06 - train: epoch 0145, iter [02100, 05004], lr: 0.018741, loss: 1.9571
2022-07-12 10:41:41 - train: epoch 0145, iter [02200, 05004], lr: 0.018729, loss: 1.6479
2022-07-12 10:42:17 - train: epoch 0145, iter [02300, 05004], lr: 0.018716, loss: 1.8771
2022-07-12 10:42:52 - train: epoch 0145, iter [02400, 05004], lr: 0.018704, loss: 2.0013
2022-07-12 10:43:27 - train: epoch 0145, iter [02500, 05004], lr: 0.018691, loss: 1.7827
2022-07-12 10:44:02 - train: epoch 0145, iter [02600, 05004], lr: 0.018678, loss: 2.0054
2022-07-12 10:44:38 - train: epoch 0145, iter [02700, 05004], lr: 0.018666, loss: 1.9997
2022-07-12 10:45:12 - train: epoch 0145, iter [02800, 05004], lr: 0.018653, loss: 1.7277
2022-07-12 10:45:47 - train: epoch 0145, iter [02900, 05004], lr: 0.018641, loss: 1.8536
2022-07-12 10:46:23 - train: epoch 0145, iter [03000, 05004], lr: 0.018628, loss: 1.7928
2022-07-12 10:46:58 - train: epoch 0145, iter [03100, 05004], lr: 0.018616, loss: 1.6374
2022-07-12 10:47:33 - train: epoch 0145, iter [03200, 05004], lr: 0.018603, loss: 1.7843
2022-07-12 10:48:08 - train: epoch 0145, iter [03300, 05004], lr: 0.018591, loss: 1.9261
2022-07-12 10:48:43 - train: epoch 0145, iter [03400, 05004], lr: 0.018578, loss: 1.6371
2022-07-12 10:49:18 - train: epoch 0145, iter [03500, 05004], lr: 0.018566, loss: 1.8896
2022-07-12 10:49:53 - train: epoch 0145, iter [03600, 05004], lr: 0.018553, loss: 1.5958
2022-07-12 10:50:28 - train: epoch 0145, iter [03700, 05004], lr: 0.018541, loss: 1.7510
2022-07-12 10:51:04 - train: epoch 0145, iter [03800, 05004], lr: 0.018528, loss: 1.9910
2022-07-12 10:51:39 - train: epoch 0145, iter [03900, 05004], lr: 0.018516, loss: 1.8397
2022-07-12 10:52:14 - train: epoch 0145, iter [04000, 05004], lr: 0.018503, loss: 1.6924
2022-07-12 10:52:48 - train: epoch 0145, iter [04100, 05004], lr: 0.018491, loss: 1.8627
2022-07-12 10:53:23 - train: epoch 0145, iter [04200, 05004], lr: 0.018478, loss: 2.0988
2022-07-12 10:53:57 - train: epoch 0145, iter [04300, 05004], lr: 0.018466, loss: 2.0243
2022-07-12 10:54:32 - train: epoch 0145, iter [04400, 05004], lr: 0.018453, loss: 1.7097
2022-07-12 10:55:07 - train: epoch 0145, iter [04500, 05004], lr: 0.018441, loss: 1.5755
2022-07-12 10:55:41 - train: epoch 0145, iter [04600, 05004], lr: 0.018428, loss: 1.6113
2022-07-12 10:56:16 - train: epoch 0145, iter [04700, 05004], lr: 0.018416, loss: 1.7415
2022-07-12 10:56:50 - train: epoch 0145, iter [04800, 05004], lr: 0.018403, loss: 2.0317
2022-07-12 10:57:25 - train: epoch 0145, iter [04900, 05004], lr: 0.018391, loss: 1.9987
2022-07-12 10:57:58 - train: epoch 0145, iter [05000, 05004], lr: 0.018378, loss: 1.7577
2022-07-12 10:57:59 - train: epoch 145, train_loss: 1.8359
2022-07-12 10:59:13 - eval: epoch: 145, acc1: 69.086%, acc5: 89.384%, test_loss: 1.2494, per_image_load_time: 1.795ms, per_image_inference_time: 0.487ms
2022-07-12 10:59:13 - until epoch: 145, best_acc1: 70.036%
2022-07-12 10:59:13 - epoch 146 lr: 0.018378
2022-07-12 10:59:53 - train: epoch 0146, iter [00100, 05004], lr: 0.018365, loss: 1.6302
2022-07-12 11:00:28 - train: epoch 0146, iter [00200, 05004], lr: 0.018353, loss: 1.8157
2022-07-12 11:01:03 - train: epoch 0146, iter [00300, 05004], lr: 0.018340, loss: 1.8058
2022-07-12 11:01:37 - train: epoch 0146, iter [00400, 05004], lr: 0.018328, loss: 2.0378
2022-07-12 11:02:12 - train: epoch 0146, iter [00500, 05004], lr: 0.018315, loss: 1.6551
2022-07-12 11:02:48 - train: epoch 0146, iter [00600, 05004], lr: 0.018303, loss: 1.7720
2022-07-12 11:03:23 - train: epoch 0146, iter [00700, 05004], lr: 0.018291, loss: 1.8136
2022-07-12 11:03:58 - train: epoch 0146, iter [00800, 05004], lr: 0.018278, loss: 1.5431
2022-07-12 11:04:33 - train: epoch 0146, iter [00900, 05004], lr: 0.018266, loss: 2.1302
2022-07-12 11:05:08 - train: epoch 0146, iter [01000, 05004], lr: 0.018253, loss: 1.9140
2022-07-12 11:05:43 - train: epoch 0146, iter [01100, 05004], lr: 0.018241, loss: 1.9804
2022-07-12 11:06:19 - train: epoch 0146, iter [01200, 05004], lr: 0.018228, loss: 1.4773
2022-07-12 11:06:54 - train: epoch 0146, iter [01300, 05004], lr: 0.018216, loss: 1.6672
2022-07-12 11:07:30 - train: epoch 0146, iter [01400, 05004], lr: 0.018203, loss: 2.0415
2022-07-12 11:08:04 - train: epoch 0146, iter [01500, 05004], lr: 0.018191, loss: 1.8254
2022-07-12 11:08:40 - train: epoch 0146, iter [01600, 05004], lr: 0.018179, loss: 1.7824
2022-07-12 11:09:15 - train: epoch 0146, iter [01700, 05004], lr: 0.018166, loss: 1.8432
2022-07-12 11:09:49 - train: epoch 0146, iter [01800, 05004], lr: 0.018154, loss: 2.0078
2022-07-12 11:10:25 - train: epoch 0146, iter [01900, 05004], lr: 0.018141, loss: 2.0058
2022-07-12 11:11:01 - train: epoch 0146, iter [02000, 05004], lr: 0.018129, loss: 1.7557
2022-07-12 11:11:36 - train: epoch 0146, iter [02100, 05004], lr: 0.018117, loss: 1.8575
2022-07-12 11:12:12 - train: epoch 0146, iter [02200, 05004], lr: 0.018104, loss: 1.7846
2022-07-12 11:12:47 - train: epoch 0146, iter [02300, 05004], lr: 0.018092, loss: 1.8706
2022-07-12 11:13:23 - train: epoch 0146, iter [02400, 05004], lr: 0.018079, loss: 1.7813
2022-07-12 11:13:57 - train: epoch 0146, iter [02500, 05004], lr: 0.018067, loss: 1.8676
2022-07-12 11:14:32 - train: epoch 0146, iter [02600, 05004], lr: 0.018055, loss: 1.8313
2022-07-12 11:15:07 - train: epoch 0146, iter [02700, 05004], lr: 0.018042, loss: 1.6214
2022-07-12 11:15:42 - train: epoch 0146, iter [02800, 05004], lr: 0.018030, loss: 2.0255
2022-07-12 11:16:17 - train: epoch 0146, iter [02900, 05004], lr: 0.018017, loss: 1.8893
2022-07-12 11:16:54 - train: epoch 0146, iter [03000, 05004], lr: 0.018005, loss: 1.8972
2022-07-12 11:17:28 - train: epoch 0146, iter [03100, 05004], lr: 0.017993, loss: 1.7977
2022-07-12 11:18:03 - train: epoch 0146, iter [03200, 05004], lr: 0.017980, loss: 1.7331
2022-07-12 11:18:39 - train: epoch 0146, iter [03300, 05004], lr: 0.017968, loss: 1.7987
2022-07-12 11:19:14 - train: epoch 0146, iter [03400, 05004], lr: 0.017956, loss: 1.9397
2022-07-12 11:19:49 - train: epoch 0146, iter [03500, 05004], lr: 0.017943, loss: 1.6211
2022-07-12 11:20:24 - train: epoch 0146, iter [03600, 05004], lr: 0.017931, loss: 1.7110
2022-07-12 11:21:00 - train: epoch 0146, iter [03700, 05004], lr: 0.017919, loss: 1.8368
2022-07-12 11:21:34 - train: epoch 0146, iter [03800, 05004], lr: 0.017906, loss: 1.7477
2022-07-12 11:22:09 - train: epoch 0146, iter [03900, 05004], lr: 0.017894, loss: 1.9944
2022-07-12 11:22:46 - train: epoch 0146, iter [04000, 05004], lr: 0.017882, loss: 1.8560
2022-07-12 11:23:20 - train: epoch 0146, iter [04100, 05004], lr: 0.017869, loss: 1.8244
2022-07-12 11:23:55 - train: epoch 0146, iter [04200, 05004], lr: 0.017857, loss: 1.8526
2022-07-12 11:24:31 - train: epoch 0146, iter [04300, 05004], lr: 0.017845, loss: 1.8097
2022-07-12 11:25:05 - train: epoch 0146, iter [04400, 05004], lr: 0.017832, loss: 1.7500
2022-07-12 11:25:39 - train: epoch 0146, iter [04500, 05004], lr: 0.017820, loss: 1.7740
2022-07-12 11:26:14 - train: epoch 0146, iter [04600, 05004], lr: 0.017808, loss: 1.9589
2022-07-12 11:26:49 - train: epoch 0146, iter [04700, 05004], lr: 0.017795, loss: 1.7423
2022-07-12 11:27:23 - train: epoch 0146, iter [04800, 05004], lr: 0.017783, loss: 2.0138
2022-07-12 11:27:57 - train: epoch 0146, iter [04900, 05004], lr: 0.017771, loss: 1.9249
2022-07-12 11:28:31 - train: epoch 0146, iter [05000, 05004], lr: 0.017758, loss: 1.7612
2022-07-12 11:28:32 - train: epoch 146, train_loss: 1.8238
2022-07-12 11:29:46 - eval: epoch: 146, acc1: 70.786%, acc5: 90.078%, test_loss: 1.1835, per_image_load_time: 2.131ms, per_image_inference_time: 0.474ms
2022-07-12 11:29:47 - until epoch: 146, best_acc1: 70.786%
2022-07-12 11:29:47 - epoch 147 lr: 0.017758
2022-07-12 11:30:27 - train: epoch 0147, iter [00100, 05004], lr: 0.017746, loss: 2.0190
2022-07-12 11:31:01 - train: epoch 0147, iter [00200, 05004], lr: 0.017733, loss: 1.7236
2022-07-12 11:31:35 - train: epoch 0147, iter [00300, 05004], lr: 0.017721, loss: 1.8494
2022-07-12 11:32:10 - train: epoch 0147, iter [00400, 05004], lr: 0.017709, loss: 2.0117
2022-07-12 11:32:44 - train: epoch 0147, iter [00500, 05004], lr: 0.017696, loss: 1.8213
2022-07-12 11:33:18 - train: epoch 0147, iter [00600, 05004], lr: 0.017684, loss: 1.7799
2022-07-12 11:33:52 - train: epoch 0147, iter [00700, 05004], lr: 0.017672, loss: 1.7492
2022-07-12 11:34:27 - train: epoch 0147, iter [00800, 05004], lr: 0.017660, loss: 1.6768
2022-07-12 11:35:01 - train: epoch 0147, iter [00900, 05004], lr: 0.017647, loss: 1.9528
2022-07-12 11:35:36 - train: epoch 0147, iter [01000, 05004], lr: 0.017635, loss: 1.8207
2022-07-12 11:36:11 - train: epoch 0147, iter [01100, 05004], lr: 0.017623, loss: 2.0698
2022-07-12 11:36:46 - train: epoch 0147, iter [01200, 05004], lr: 0.017610, loss: 1.7020
2022-07-12 11:37:20 - train: epoch 0147, iter [01300, 05004], lr: 0.017598, loss: 2.0901
2022-07-12 11:37:54 - train: epoch 0147, iter [01400, 05004], lr: 0.017586, loss: 1.8365
2022-07-12 11:38:28 - train: epoch 0147, iter [01500, 05004], lr: 0.017574, loss: 1.7769
2022-07-12 11:39:03 - train: epoch 0147, iter [01600, 05004], lr: 0.017561, loss: 1.8073
2022-07-12 11:39:38 - train: epoch 0147, iter [01700, 05004], lr: 0.017549, loss: 2.0489
2022-07-12 11:40:13 - train: epoch 0147, iter [01800, 05004], lr: 0.017537, loss: 1.4383
2022-07-12 11:40:47 - train: epoch 0147, iter [01900, 05004], lr: 0.017525, loss: 1.8334
2022-07-12 11:41:23 - train: epoch 0147, iter [02000, 05004], lr: 0.017512, loss: 1.6752
2022-07-12 11:41:57 - train: epoch 0147, iter [02100, 05004], lr: 0.017500, loss: 1.7475
2022-07-12 11:42:32 - train: epoch 0147, iter [02200, 05004], lr: 0.017488, loss: 2.0703
2022-07-12 11:43:07 - train: epoch 0147, iter [02300, 05004], lr: 0.017476, loss: 1.9945
2022-07-12 11:43:41 - train: epoch 0147, iter [02400, 05004], lr: 0.017464, loss: 1.9660
2022-07-12 11:44:16 - train: epoch 0147, iter [02500, 05004], lr: 0.017451, loss: 1.9080
2022-07-12 11:44:51 - train: epoch 0147, iter [02600, 05004], lr: 0.017439, loss: 1.7642
2022-07-12 11:45:25 - train: epoch 0147, iter [02700, 05004], lr: 0.017427, loss: 1.9267
2022-07-12 11:46:00 - train: epoch 0147, iter [02800, 05004], lr: 0.017415, loss: 1.7451
2022-07-12 11:46:35 - train: epoch 0147, iter [02900, 05004], lr: 0.017402, loss: 1.8171
2022-07-12 11:47:10 - train: epoch 0147, iter [03000, 05004], lr: 0.017390, loss: 1.8739
2022-07-12 11:47:44 - train: epoch 0147, iter [03100, 05004], lr: 0.017378, loss: 2.0071
2022-07-12 11:48:19 - train: epoch 0147, iter [03200, 05004], lr: 0.017366, loss: 1.6932
2022-07-12 11:48:54 - train: epoch 0147, iter [03300, 05004], lr: 0.017354, loss: 1.8239
2022-07-12 11:49:29 - train: epoch 0147, iter [03400, 05004], lr: 0.017341, loss: 1.8542
2022-07-12 11:50:03 - train: epoch 0147, iter [03500, 05004], lr: 0.017329, loss: 1.8185
2022-07-12 11:50:39 - train: epoch 0147, iter [03600, 05004], lr: 0.017317, loss: 1.6619
2022-07-12 11:51:12 - train: epoch 0147, iter [03700, 05004], lr: 0.017305, loss: 1.7111
2022-07-12 11:51:48 - train: epoch 0147, iter [03800, 05004], lr: 0.017293, loss: 1.7707
2022-07-12 11:52:23 - train: epoch 0147, iter [03900, 05004], lr: 0.017281, loss: 1.9447
2022-07-12 11:52:57 - train: epoch 0147, iter [04000, 05004], lr: 0.017268, loss: 1.7456
2022-07-12 11:53:32 - train: epoch 0147, iter [04100, 05004], lr: 0.017256, loss: 1.9940
2022-07-12 11:54:06 - train: epoch 0147, iter [04200, 05004], lr: 0.017244, loss: 1.7150
2022-07-12 11:54:40 - train: epoch 0147, iter [04300, 05004], lr: 0.017232, loss: 1.7291
2022-07-12 11:55:14 - train: epoch 0147, iter [04400, 05004], lr: 0.017220, loss: 1.6991
2022-07-12 11:55:49 - train: epoch 0147, iter [04500, 05004], lr: 0.017208, loss: 2.0939
2022-07-12 11:56:24 - train: epoch 0147, iter [04600, 05004], lr: 0.017195, loss: 2.0321
2022-07-12 11:56:58 - train: epoch 0147, iter [04700, 05004], lr: 0.017183, loss: 1.9249
2022-07-12 11:57:33 - train: epoch 0147, iter [04800, 05004], lr: 0.017171, loss: 1.9445
2022-07-12 11:58:07 - train: epoch 0147, iter [04900, 05004], lr: 0.017159, loss: 1.5674
2022-07-12 11:58:40 - train: epoch 0147, iter [05000, 05004], lr: 0.017147, loss: 1.7311
2022-07-12 11:58:41 - train: epoch 147, train_loss: 1.8140
2022-07-12 11:59:56 - eval: epoch: 147, acc1: 71.052%, acc5: 90.296%, test_loss: 1.1698, per_image_load_time: 2.478ms, per_image_inference_time: 0.434ms
2022-07-12 11:59:57 - until epoch: 147, best_acc1: 71.052%
2022-07-12 11:59:57 - epoch 148 lr: 0.017146
2022-07-12 12:00:37 - train: epoch 0148, iter [00100, 05004], lr: 0.017134, loss: 1.9012
2022-07-12 12:01:11 - train: epoch 0148, iter [00200, 05004], lr: 0.017122, loss: 1.7493
2022-07-12 12:01:45 - train: epoch 0148, iter [00300, 05004], lr: 0.017110, loss: 1.6296
2022-07-12 12:02:19 - train: epoch 0148, iter [00400, 05004], lr: 0.017098, loss: 1.8893
2022-07-12 12:02:55 - train: epoch 0148, iter [00500, 05004], lr: 0.017086, loss: 1.4933
2022-07-12 12:03:30 - train: epoch 0148, iter [00600, 05004], lr: 0.017074, loss: 1.8119
2022-07-12 12:04:04 - train: epoch 0148, iter [00700, 05004], lr: 0.017062, loss: 1.9068
2022-07-12 12:04:38 - train: epoch 0148, iter [00800, 05004], lr: 0.017049, loss: 1.7369
2022-07-12 12:05:14 - train: epoch 0148, iter [00900, 05004], lr: 0.017037, loss: 1.5806
2022-07-12 12:05:49 - train: epoch 0148, iter [01000, 05004], lr: 0.017025, loss: 1.7796
2022-07-12 12:06:23 - train: epoch 0148, iter [01100, 05004], lr: 0.017013, loss: 1.5315
2022-07-12 12:06:59 - train: epoch 0148, iter [01200, 05004], lr: 0.017001, loss: 1.6469
2022-07-12 12:07:33 - train: epoch 0148, iter [01300, 05004], lr: 0.016989, loss: 1.9089
2022-07-12 12:08:09 - train: epoch 0148, iter [01400, 05004], lr: 0.016977, loss: 1.7663
2022-07-12 12:08:42 - train: epoch 0148, iter [01500, 05004], lr: 0.016965, loss: 1.6106
2022-07-12 12:09:18 - train: epoch 0148, iter [01600, 05004], lr: 0.016953, loss: 1.7140
2022-07-12 12:09:53 - train: epoch 0148, iter [01700, 05004], lr: 0.016941, loss: 1.8293
2022-07-12 12:10:27 - train: epoch 0148, iter [01800, 05004], lr: 0.016929, loss: 1.8504
2022-07-12 12:11:02 - train: epoch 0148, iter [01900, 05004], lr: 0.016916, loss: 1.7930
2022-07-12 12:11:37 - train: epoch 0148, iter [02000, 05004], lr: 0.016904, loss: 2.0562
2022-07-12 12:12:12 - train: epoch 0148, iter [02100, 05004], lr: 0.016892, loss: 1.7541
2022-07-12 12:12:48 - train: epoch 0148, iter [02200, 05004], lr: 0.016880, loss: 1.5441
2022-07-12 12:13:22 - train: epoch 0148, iter [02300, 05004], lr: 0.016868, loss: 1.7185
2022-07-12 12:13:57 - train: epoch 0148, iter [02400, 05004], lr: 0.016856, loss: 2.0668
2022-07-12 12:14:33 - train: epoch 0148, iter [02500, 05004], lr: 0.016844, loss: 1.8600
2022-07-12 12:15:08 - train: epoch 0148, iter [02600, 05004], lr: 0.016832, loss: 2.0322
2022-07-12 12:15:43 - train: epoch 0148, iter [02700, 05004], lr: 0.016820, loss: 1.9329
2022-07-12 12:16:18 - train: epoch 0148, iter [02800, 05004], lr: 0.016808, loss: 2.2328
2022-07-12 12:16:54 - train: epoch 0148, iter [02900, 05004], lr: 0.016796, loss: 1.8728
2022-07-12 12:17:28 - train: epoch 0148, iter [03000, 05004], lr: 0.016784, loss: 1.9550
2022-07-12 12:18:03 - train: epoch 0148, iter [03100, 05004], lr: 0.016772, loss: 1.7459
2022-07-12 12:18:38 - train: epoch 0148, iter [03200, 05004], lr: 0.016760, loss: 1.6015
2022-07-12 12:19:13 - train: epoch 0148, iter [03300, 05004], lr: 0.016748, loss: 1.6149
2022-07-12 12:19:47 - train: epoch 0148, iter [03400, 05004], lr: 0.016736, loss: 1.8200
2022-07-12 12:20:22 - train: epoch 0148, iter [03500, 05004], lr: 0.016724, loss: 1.3967
2022-07-12 12:20:56 - train: epoch 0148, iter [03600, 05004], lr: 0.016712, loss: 1.7189
2022-07-12 12:21:30 - train: epoch 0148, iter [03700, 05004], lr: 0.016700, loss: 1.9572
2022-07-12 12:22:05 - train: epoch 0148, iter [03800, 05004], lr: 0.016688, loss: 1.6771
2022-07-12 12:22:39 - train: epoch 0148, iter [03900, 05004], lr: 0.016676, loss: 1.7033
2022-07-12 12:23:14 - train: epoch 0148, iter [04000, 05004], lr: 0.016664, loss: 1.9399
2022-07-12 12:23:49 - train: epoch 0148, iter [04100, 05004], lr: 0.016652, loss: 1.6041
2022-07-12 12:24:23 - train: epoch 0148, iter [04200, 05004], lr: 0.016640, loss: 1.6570
2022-07-12 12:24:57 - train: epoch 0148, iter [04300, 05004], lr: 0.016628, loss: 1.7794
2022-07-12 12:25:31 - train: epoch 0148, iter [04400, 05004], lr: 0.016616, loss: 1.4966
2022-07-12 12:26:06 - train: epoch 0148, iter [04500, 05004], lr: 0.016604, loss: 2.1148
2022-07-12 12:26:41 - train: epoch 0148, iter [04600, 05004], lr: 0.016592, loss: 1.7708
2022-07-12 12:27:15 - train: epoch 0148, iter [04700, 05004], lr: 0.016580, loss: 1.9756
2022-07-12 12:27:49 - train: epoch 0148, iter [04800, 05004], lr: 0.016568, loss: 1.8347
2022-07-12 12:28:24 - train: epoch 0148, iter [04900, 05004], lr: 0.016556, loss: 1.9406
2022-07-12 12:28:58 - train: epoch 0148, iter [05000, 05004], lr: 0.016544, loss: 1.5807
2022-07-12 12:28:59 - train: epoch 148, train_loss: 1.8026
2022-07-12 12:30:14 - eval: epoch: 148, acc1: 70.492%, acc5: 90.018%, test_loss: 1.1955, per_image_load_time: 2.484ms, per_image_inference_time: 0.456ms
2022-07-12 12:30:14 - until epoch: 148, best_acc1: 71.052%
2022-07-12 12:30:14 - epoch 149 lr: 0.016543
2022-07-12 12:30:55 - train: epoch 0149, iter [00100, 05004], lr: 0.016532, loss: 1.7974
2022-07-12 12:31:30 - train: epoch 0149, iter [00200, 05004], lr: 0.016520, loss: 1.7461
2022-07-12 12:32:05 - train: epoch 0149, iter [00300, 05004], lr: 0.016508, loss: 1.9824
2022-07-12 12:32:39 - train: epoch 0149, iter [00400, 05004], lr: 0.016496, loss: 1.7700
2022-07-12 12:33:13 - train: epoch 0149, iter [00500, 05004], lr: 0.016484, loss: 1.6550
2022-07-12 12:33:48 - train: epoch 0149, iter [00600, 05004], lr: 0.016472, loss: 1.9365
2022-07-12 12:34:22 - train: epoch 0149, iter [00700, 05004], lr: 0.016460, loss: 2.0385
2022-07-12 12:34:58 - train: epoch 0149, iter [00800, 05004], lr: 0.016448, loss: 1.8802
2022-07-12 12:35:32 - train: epoch 0149, iter [00900, 05004], lr: 0.016436, loss: 1.9023
2022-07-12 12:36:07 - train: epoch 0149, iter [01000, 05004], lr: 0.016424, loss: 1.7256
2022-07-12 12:36:42 - train: epoch 0149, iter [01100, 05004], lr: 0.016412, loss: 1.6724
2022-07-12 12:37:16 - train: epoch 0149, iter [01200, 05004], lr: 0.016400, loss: 1.6672
2022-07-12 12:37:51 - train: epoch 0149, iter [01300, 05004], lr: 0.016388, loss: 1.8752
2022-07-12 12:38:27 - train: epoch 0149, iter [01400, 05004], lr: 0.016376, loss: 1.9228
2022-07-12 12:39:01 - train: epoch 0149, iter [01500, 05004], lr: 0.016364, loss: 1.6659
2022-07-12 12:39:36 - train: epoch 0149, iter [01600, 05004], lr: 0.016353, loss: 1.7298
2022-07-12 12:40:11 - train: epoch 0149, iter [01700, 05004], lr: 0.016341, loss: 1.5346
2022-07-12 12:40:46 - train: epoch 0149, iter [01800, 05004], lr: 0.016329, loss: 1.7974
2022-07-12 12:41:20 - train: epoch 0149, iter [01900, 05004], lr: 0.016317, loss: 1.9419
2022-07-12 12:41:56 - train: epoch 0149, iter [02000, 05004], lr: 0.016305, loss: 1.7651
2022-07-12 12:42:31 - train: epoch 0149, iter [02100, 05004], lr: 0.016293, loss: 1.5951
2022-07-12 12:43:05 - train: epoch 0149, iter [02200, 05004], lr: 0.016281, loss: 1.7842
2022-07-12 12:43:41 - train: epoch 0149, iter [02300, 05004], lr: 0.016269, loss: 1.5769
2022-07-12 12:44:16 - train: epoch 0149, iter [02400, 05004], lr: 0.016257, loss: 1.7319
2022-07-12 12:44:51 - train: epoch 0149, iter [02500, 05004], lr: 0.016245, loss: 1.7714
2022-07-12 12:45:26 - train: epoch 0149, iter [02600, 05004], lr: 0.016234, loss: 1.9561
2022-07-12 12:46:01 - train: epoch 0149, iter [02700, 05004], lr: 0.016222, loss: 1.7127
2022-07-12 12:46:37 - train: epoch 0149, iter [02800, 05004], lr: 0.016210, loss: 1.8419
2022-07-12 12:47:12 - train: epoch 0149, iter [02900, 05004], lr: 0.016198, loss: 1.8657
2022-07-12 12:47:47 - train: epoch 0149, iter [03000, 05004], lr: 0.016186, loss: 1.9434
2022-07-12 12:48:22 - train: epoch 0149, iter [03100, 05004], lr: 0.016174, loss: 1.9324
2022-07-12 12:48:57 - train: epoch 0149, iter [03200, 05004], lr: 0.016162, loss: 1.7872
2022-07-12 12:49:33 - train: epoch 0149, iter [03300, 05004], lr: 0.016151, loss: 1.7089
2022-07-12 12:50:08 - train: epoch 0149, iter [03400, 05004], lr: 0.016139, loss: 1.7066
2022-07-12 12:50:43 - train: epoch 0149, iter [03500, 05004], lr: 0.016127, loss: 1.7430
2022-07-12 12:51:19 - train: epoch 0149, iter [03600, 05004], lr: 0.016115, loss: 1.6749
2022-07-12 12:51:53 - train: epoch 0149, iter [03700, 05004], lr: 0.016103, loss: 1.6975
2022-07-12 12:52:28 - train: epoch 0149, iter [03800, 05004], lr: 0.016091, loss: 1.7651
2022-07-12 12:53:03 - train: epoch 0149, iter [03900, 05004], lr: 0.016080, loss: 1.9255
2022-07-12 12:53:38 - train: epoch 0149, iter [04000, 05004], lr: 0.016068, loss: 1.8257
2022-07-12 12:54:13 - train: epoch 0149, iter [04100, 05004], lr: 0.016056, loss: 1.6600
2022-07-12 12:54:48 - train: epoch 0149, iter [04200, 05004], lr: 0.016044, loss: 1.6957
2022-07-12 12:55:23 - train: epoch 0149, iter [04300, 05004], lr: 0.016032, loss: 1.9897
2022-07-12 12:55:59 - train: epoch 0149, iter [04400, 05004], lr: 0.016020, loss: 1.9107
2022-07-12 12:56:34 - train: epoch 0149, iter [04500, 05004], lr: 0.016009, loss: 1.6106
2022-07-12 12:57:09 - train: epoch 0149, iter [04600, 05004], lr: 0.015997, loss: 1.7476
2022-07-12 12:57:44 - train: epoch 0149, iter [04700, 05004], lr: 0.015985, loss: 1.7368
2022-07-12 12:58:19 - train: epoch 0149, iter [04800, 05004], lr: 0.015973, loss: 1.6833
2022-07-12 12:58:54 - train: epoch 0149, iter [04900, 05004], lr: 0.015961, loss: 1.8845
2022-07-12 12:59:28 - train: epoch 0149, iter [05000, 05004], lr: 0.015950, loss: 2.0102
2022-07-12 12:59:29 - train: epoch 149, train_loss: 1.7916
2022-07-12 13:00:43 - eval: epoch: 149, acc1: 68.898%, acc5: 89.136%, test_loss: 1.2583, per_image_load_time: 1.447ms, per_image_inference_time: 0.469ms
2022-07-12 13:00:43 - until epoch: 149, best_acc1: 71.052%
2022-07-12 13:00:43 - epoch 150 lr: 0.015949
2022-07-12 13:01:23 - train: epoch 0150, iter [00100, 05004], lr: 0.015937, loss: 1.7122
2022-07-12 13:01:57 - train: epoch 0150, iter [00200, 05004], lr: 0.015926, loss: 1.7036
2022-07-12 13:02:33 - train: epoch 0150, iter [00300, 05004], lr: 0.015914, loss: 1.6937
2022-07-12 13:03:08 - train: epoch 0150, iter [00400, 05004], lr: 0.015902, loss: 1.7412
2022-07-12 13:03:43 - train: epoch 0150, iter [00500, 05004], lr: 0.015890, loss: 1.6420
2022-07-12 13:04:18 - train: epoch 0150, iter [00600, 05004], lr: 0.015879, loss: 1.7861
2022-07-12 13:04:52 - train: epoch 0150, iter [00700, 05004], lr: 0.015867, loss: 1.9218
2022-07-12 13:05:27 - train: epoch 0150, iter [00800, 05004], lr: 0.015855, loss: 1.7825
2022-07-12 13:06:02 - train: epoch 0150, iter [00900, 05004], lr: 0.015843, loss: 2.0647
2022-07-12 13:06:37 - train: epoch 0150, iter [01000, 05004], lr: 0.015832, loss: 1.6251
2022-07-12 13:07:12 - train: epoch 0150, iter [01100, 05004], lr: 0.015820, loss: 1.8042
2022-07-12 13:07:47 - train: epoch 0150, iter [01200, 05004], lr: 0.015808, loss: 1.8871
2022-07-12 13:08:22 - train: epoch 0150, iter [01300, 05004], lr: 0.015796, loss: 1.7009
2022-07-12 13:08:58 - train: epoch 0150, iter [01400, 05004], lr: 0.015785, loss: 1.9295
2022-07-12 13:09:32 - train: epoch 0150, iter [01500, 05004], lr: 0.015773, loss: 2.0089
2022-07-12 13:10:08 - train: epoch 0150, iter [01600, 05004], lr: 0.015761, loss: 1.7130
2022-07-12 13:10:42 - train: epoch 0150, iter [01700, 05004], lr: 0.015749, loss: 2.1768
2022-07-12 13:11:18 - train: epoch 0150, iter [01800, 05004], lr: 0.015738, loss: 1.8884
2022-07-12 13:11:53 - train: epoch 0150, iter [01900, 05004], lr: 0.015726, loss: 1.5781
2022-07-12 13:12:28 - train: epoch 0150, iter [02000, 05004], lr: 0.015714, loss: 2.0196
2022-07-12 13:13:03 - train: epoch 0150, iter [02100, 05004], lr: 0.015702, loss: 1.6833
2022-07-12 13:13:39 - train: epoch 0150, iter [02200, 05004], lr: 0.015691, loss: 1.5567
2022-07-12 13:14:13 - train: epoch 0150, iter [02300, 05004], lr: 0.015679, loss: 1.7005
2022-07-12 13:14:50 - train: epoch 0150, iter [02400, 05004], lr: 0.015667, loss: 1.8526
2022-07-12 13:15:24 - train: epoch 0150, iter [02500, 05004], lr: 0.015656, loss: 1.7013
2022-07-12 13:16:00 - train: epoch 0150, iter [02600, 05004], lr: 0.015644, loss: 1.6651
2022-07-12 13:16:34 - train: epoch 0150, iter [02700, 05004], lr: 0.015632, loss: 1.7087
2022-07-12 13:17:10 - train: epoch 0150, iter [02800, 05004], lr: 0.015621, loss: 1.7662
2022-07-12 13:17:45 - train: epoch 0150, iter [02900, 05004], lr: 0.015609, loss: 1.8236
2022-07-12 13:18:20 - train: epoch 0150, iter [03000, 05004], lr: 0.015597, loss: 1.6676
2022-07-12 13:18:56 - train: epoch 0150, iter [03100, 05004], lr: 0.015585, loss: 1.7546
2022-07-12 13:19:31 - train: epoch 0150, iter [03200, 05004], lr: 0.015574, loss: 1.7091
2022-07-12 13:20:06 - train: epoch 0150, iter [03300, 05004], lr: 0.015562, loss: 1.7729
2022-07-12 13:20:41 - train: epoch 0150, iter [03400, 05004], lr: 0.015550, loss: 1.5727
2022-07-12 13:21:16 - train: epoch 0150, iter [03500, 05004], lr: 0.015539, loss: 1.8491
2022-07-12 13:21:51 - train: epoch 0150, iter [03600, 05004], lr: 0.015527, loss: 1.7212
2022-07-12 13:22:26 - train: epoch 0150, iter [03700, 05004], lr: 0.015515, loss: 1.8702
2022-07-12 13:23:01 - train: epoch 0150, iter [03800, 05004], lr: 0.015504, loss: 1.7097
2022-07-12 13:23:36 - train: epoch 0150, iter [03900, 05004], lr: 0.015492, loss: 1.8107
2022-07-12 13:24:11 - train: epoch 0150, iter [04000, 05004], lr: 0.015481, loss: 1.6505
2022-07-12 13:24:46 - train: epoch 0150, iter [04100, 05004], lr: 0.015469, loss: 1.6516
2022-07-12 13:25:21 - train: epoch 0150, iter [04200, 05004], lr: 0.015457, loss: 1.6945
2022-07-12 13:25:57 - train: epoch 0150, iter [04300, 05004], lr: 0.015446, loss: 1.9132
2022-07-12 13:26:31 - train: epoch 0150, iter [04400, 05004], lr: 0.015434, loss: 1.6834
2022-07-12 13:27:06 - train: epoch 0150, iter [04500, 05004], lr: 0.015422, loss: 1.8621
2022-07-12 13:27:41 - train: epoch 0150, iter [04600, 05004], lr: 0.015411, loss: 1.9910
2022-07-12 13:28:16 - train: epoch 0150, iter [04700, 05004], lr: 0.015399, loss: 1.4607
2022-07-12 13:28:51 - train: epoch 0150, iter [04800, 05004], lr: 0.015387, loss: 1.8942
2022-07-12 13:29:26 - train: epoch 0150, iter [04900, 05004], lr: 0.015376, loss: 1.8211
2022-07-12 13:30:00 - train: epoch 0150, iter [05000, 05004], lr: 0.015364, loss: 1.9309
2022-07-12 13:30:01 - train: epoch 150, train_loss: 1.7782
2022-07-12 13:31:16 - eval: epoch: 150, acc1: 70.668%, acc5: 90.280%, test_loss: 1.1873, per_image_load_time: 2.418ms, per_image_inference_time: 0.494ms
2022-07-12 13:31:16 - until epoch: 150, best_acc1: 71.052%
2022-07-12 13:31:16 - epoch 151 lr: 0.015364
2022-07-12 13:31:56 - train: epoch 0151, iter [00100, 05004], lr: 0.015352, loss: 1.9906
2022-07-12 13:32:32 - train: epoch 0151, iter [00200, 05004], lr: 0.015341, loss: 1.6457
2022-07-12 13:33:07 - train: epoch 0151, iter [00300, 05004], lr: 0.015329, loss: 1.7182
2022-07-12 13:33:42 - train: epoch 0151, iter [00400, 05004], lr: 0.015317, loss: 1.7033
2022-07-12 13:34:17 - train: epoch 0151, iter [00500, 05004], lr: 0.015306, loss: 1.8191
2022-07-12 13:34:52 - train: epoch 0151, iter [00600, 05004], lr: 0.015294, loss: 1.5508
2022-07-12 13:35:26 - train: epoch 0151, iter [00700, 05004], lr: 0.015283, loss: 1.6845
2022-07-12 13:36:02 - train: epoch 0151, iter [00800, 05004], lr: 0.015271, loss: 1.7913
2022-07-12 13:36:37 - train: epoch 0151, iter [00900, 05004], lr: 0.015259, loss: 1.8268
2022-07-12 13:37:12 - train: epoch 0151, iter [01000, 05004], lr: 0.015248, loss: 1.8424
2022-07-12 13:37:48 - train: epoch 0151, iter [01100, 05004], lr: 0.015236, loss: 1.7317
2022-07-12 13:38:23 - train: epoch 0151, iter [01200, 05004], lr: 0.015225, loss: 1.6399
2022-07-12 13:38:59 - train: epoch 0151, iter [01300, 05004], lr: 0.015213, loss: 1.5183
2022-07-12 13:39:34 - train: epoch 0151, iter [01400, 05004], lr: 0.015202, loss: 1.8096
2022-07-12 13:40:09 - train: epoch 0151, iter [01500, 05004], lr: 0.015190, loss: 2.1221
2022-07-12 13:40:44 - train: epoch 0151, iter [01600, 05004], lr: 0.015178, loss: 1.9006
2022-07-12 13:41:19 - train: epoch 0151, iter [01700, 05004], lr: 0.015167, loss: 1.6192
2022-07-12 13:41:55 - train: epoch 0151, iter [01800, 05004], lr: 0.015155, loss: 1.6494
2022-07-12 13:42:31 - train: epoch 0151, iter [01900, 05004], lr: 0.015144, loss: 2.0586
2022-07-12 13:43:05 - train: epoch 0151, iter [02000, 05004], lr: 0.015132, loss: 1.8936
2022-07-12 13:43:41 - train: epoch 0151, iter [02100, 05004], lr: 0.015121, loss: 1.6938
2022-07-12 13:44:16 - train: epoch 0151, iter [02200, 05004], lr: 0.015109, loss: 1.7132
2022-07-12 13:44:51 - train: epoch 0151, iter [02300, 05004], lr: 0.015098, loss: 1.9145
2022-07-12 13:45:26 - train: epoch 0151, iter [02400, 05004], lr: 0.015086, loss: 1.7197
2022-07-12 13:46:01 - train: epoch 0151, iter [02500, 05004], lr: 0.015075, loss: 1.8123
2022-07-12 13:46:37 - train: epoch 0151, iter [02600, 05004], lr: 0.015063, loss: 1.9904
2022-07-12 13:47:13 - train: epoch 0151, iter [02700, 05004], lr: 0.015052, loss: 1.7674
2022-07-12 13:47:46 - train: epoch 0151, iter [02800, 05004], lr: 0.015040, loss: 1.9000
2022-07-12 13:48:22 - train: epoch 0151, iter [02900, 05004], lr: 0.015029, loss: 1.9850
2022-07-12 13:48:56 - train: epoch 0151, iter [03000, 05004], lr: 0.015017, loss: 1.7163
2022-07-12 13:49:31 - train: epoch 0151, iter [03100, 05004], lr: 0.015006, loss: 1.7682
2022-07-12 13:50:05 - train: epoch 0151, iter [03200, 05004], lr: 0.014994, loss: 1.7959
2022-07-12 13:50:39 - train: epoch 0151, iter [03300, 05004], lr: 0.014983, loss: 1.7187
2022-07-12 13:51:14 - train: epoch 0151, iter [03400, 05004], lr: 0.014971, loss: 1.6296
2022-07-12 13:51:48 - train: epoch 0151, iter [03500, 05004], lr: 0.014960, loss: 1.7430
2022-07-12 13:52:23 - train: epoch 0151, iter [03600, 05004], lr: 0.014948, loss: 1.9261
2022-07-12 13:52:57 - train: epoch 0151, iter [03700, 05004], lr: 0.014937, loss: 1.6520
2022-07-12 13:53:32 - train: epoch 0151, iter [03800, 05004], lr: 0.014925, loss: 1.7691
2022-07-12 13:54:06 - train: epoch 0151, iter [03900, 05004], lr: 0.014914, loss: 1.6303
2022-07-12 13:54:40 - train: epoch 0151, iter [04000, 05004], lr: 0.014902, loss: 1.8374
2022-07-12 13:55:15 - train: epoch 0151, iter [04100, 05004], lr: 0.014891, loss: 1.9653
2022-07-12 13:55:50 - train: epoch 0151, iter [04200, 05004], lr: 0.014879, loss: 1.9223
2022-07-12 13:56:24 - train: epoch 0151, iter [04300, 05004], lr: 0.014868, loss: 1.6437
2022-07-12 13:56:59 - train: epoch 0151, iter [04400, 05004], lr: 0.014856, loss: 1.6913
2022-07-12 13:57:35 - train: epoch 0151, iter [04500, 05004], lr: 0.014845, loss: 1.6878
2022-07-12 13:58:08 - train: epoch 0151, iter [04600, 05004], lr: 0.014834, loss: 1.9613
2022-07-12 13:58:43 - train: epoch 0151, iter [04700, 05004], lr: 0.014822, loss: 1.4908
2022-07-12 13:59:18 - train: epoch 0151, iter [04800, 05004], lr: 0.014811, loss: 2.0465
2022-07-12 13:59:52 - train: epoch 0151, iter [04900, 05004], lr: 0.014799, loss: 1.8722
2022-07-12 14:00:25 - train: epoch 0151, iter [05000, 05004], lr: 0.014788, loss: 1.8992
2022-07-12 14:00:26 - train: epoch 151, train_loss: 1.7676
2022-07-12 14:01:40 - eval: epoch: 151, acc1: 69.746%, acc5: 89.476%, test_loss: 1.2304, per_image_load_time: 2.064ms, per_image_inference_time: 0.455ms
2022-07-12 14:01:40 - until epoch: 151, best_acc1: 71.052%
2022-07-12 14:01:40 - epoch 152 lr: 0.014787
2022-07-12 14:02:20 - train: epoch 0152, iter [00100, 05004], lr: 0.014776, loss: 1.9464
2022-07-12 14:02:53 - train: epoch 0152, iter [00200, 05004], lr: 0.014764, loss: 1.6933
2022-07-12 14:03:27 - train: epoch 0152, iter [00300, 05004], lr: 0.014753, loss: 2.1511
2022-07-12 14:04:00 - train: epoch 0152, iter [00400, 05004], lr: 0.014742, loss: 1.5915
2022-07-12 14:04:34 - train: epoch 0152, iter [00500, 05004], lr: 0.014730, loss: 1.7033
2022-07-12 14:05:08 - train: epoch 0152, iter [00600, 05004], lr: 0.014719, loss: 1.7172
2022-07-12 14:05:41 - train: epoch 0152, iter [00700, 05004], lr: 0.014707, loss: 1.6739
2022-07-12 14:06:15 - train: epoch 0152, iter [00800, 05004], lr: 0.014696, loss: 1.5674
2022-07-12 14:06:49 - train: epoch 0152, iter [00900, 05004], lr: 0.014685, loss: 1.8397
2022-07-12 14:07:23 - train: epoch 0152, iter [01000, 05004], lr: 0.014673, loss: 1.7980
2022-07-12 14:07:57 - train: epoch 0152, iter [01100, 05004], lr: 0.014662, loss: 1.8665
2022-07-12 14:08:30 - train: epoch 0152, iter [01200, 05004], lr: 0.014650, loss: 1.7886
2022-07-12 14:09:04 - train: epoch 0152, iter [01300, 05004], lr: 0.014639, loss: 1.4515
2022-07-12 14:09:38 - train: epoch 0152, iter [01400, 05004], lr: 0.014628, loss: 1.6786
2022-07-12 14:10:12 - train: epoch 0152, iter [01500, 05004], lr: 0.014616, loss: 1.5565
2022-07-12 14:10:46 - train: epoch 0152, iter [01600, 05004], lr: 0.014605, loss: 1.6501
2022-07-12 14:11:20 - train: epoch 0152, iter [01700, 05004], lr: 0.014594, loss: 1.7213
2022-07-12 14:11:53 - train: epoch 0152, iter [01800, 05004], lr: 0.014582, loss: 1.7125
2022-07-12 14:12:28 - train: epoch 0152, iter [01900, 05004], lr: 0.014571, loss: 1.8054
2022-07-12 14:13:01 - train: epoch 0152, iter [02000, 05004], lr: 0.014560, loss: 1.6546
2022-07-12 14:13:34 - train: epoch 0152, iter [02100, 05004], lr: 0.014548, loss: 1.6976
2022-07-12 14:14:08 - train: epoch 0152, iter [02200, 05004], lr: 0.014537, loss: 1.6369
2022-07-12 14:14:41 - train: epoch 0152, iter [02300, 05004], lr: 0.014525, loss: 2.0936
2022-07-12 14:15:15 - train: epoch 0152, iter [02400, 05004], lr: 0.014514, loss: 1.6441
2022-07-12 14:15:49 - train: epoch 0152, iter [02500, 05004], lr: 0.014503, loss: 1.5582
2022-07-12 14:16:23 - train: epoch 0152, iter [02600, 05004], lr: 0.014491, loss: 1.6409
2022-07-12 14:16:56 - train: epoch 0152, iter [02700, 05004], lr: 0.014480, loss: 1.8221
2022-07-12 14:17:30 - train: epoch 0152, iter [02800, 05004], lr: 0.014469, loss: 1.8136
2022-07-12 14:18:03 - train: epoch 0152, iter [02900, 05004], lr: 0.014457, loss: 1.6183
2022-07-12 14:18:38 - train: epoch 0152, iter [03000, 05004], lr: 0.014446, loss: 1.9172
2022-07-12 14:19:11 - train: epoch 0152, iter [03100, 05004], lr: 0.014435, loss: 1.8892
2022-07-12 14:19:45 - train: epoch 0152, iter [03200, 05004], lr: 0.014424, loss: 1.4239
2022-07-12 14:20:19 - train: epoch 0152, iter [03300, 05004], lr: 0.014412, loss: 1.9068
2022-07-12 14:20:54 - train: epoch 0152, iter [03400, 05004], lr: 0.014401, loss: 1.6496
2022-07-12 14:21:27 - train: epoch 0152, iter [03500, 05004], lr: 0.014390, loss: 1.8468
2022-07-12 14:22:01 - train: epoch 0152, iter [03600, 05004], lr: 0.014378, loss: 1.8633
2022-07-12 14:22:34 - train: epoch 0152, iter [03700, 05004], lr: 0.014367, loss: 1.6441
2022-07-12 14:23:08 - train: epoch 0152, iter [03800, 05004], lr: 0.014356, loss: 1.7171
2022-07-12 14:23:42 - train: epoch 0152, iter [03900, 05004], lr: 0.014344, loss: 1.7630
2022-07-12 14:24:16 - train: epoch 0152, iter [04000, 05004], lr: 0.014333, loss: 1.4925
2022-07-12 14:24:50 - train: epoch 0152, iter [04100, 05004], lr: 0.014322, loss: 1.7142
2022-07-12 14:25:24 - train: epoch 0152, iter [04200, 05004], lr: 0.014311, loss: 1.6728
2022-07-12 14:25:58 - train: epoch 0152, iter [04300, 05004], lr: 0.014299, loss: 1.9350
2022-07-12 14:26:32 - train: epoch 0152, iter [04400, 05004], lr: 0.014288, loss: 1.9318
2022-07-12 14:27:06 - train: epoch 0152, iter [04500, 05004], lr: 0.014277, loss: 1.7805
2022-07-12 14:27:39 - train: epoch 0152, iter [04600, 05004], lr: 0.014266, loss: 1.9556
2022-07-12 14:28:13 - train: epoch 0152, iter [04700, 05004], lr: 0.014254, loss: 1.9082
2022-07-12 14:28:47 - train: epoch 0152, iter [04800, 05004], lr: 0.014243, loss: 1.9985
2022-07-12 14:29:22 - train: epoch 0152, iter [04900, 05004], lr: 0.014232, loss: 1.8074
2022-07-12 14:29:54 - train: epoch 0152, iter [05000, 05004], lr: 0.014221, loss: 1.8027
2022-07-12 14:29:55 - train: epoch 152, train_loss: 1.7551
2022-07-12 14:31:09 - eval: epoch: 152, acc1: 70.832%, acc5: 90.332%, test_loss: 1.1808, per_image_load_time: 2.416ms, per_image_inference_time: 0.464ms
2022-07-12 14:31:09 - until epoch: 152, best_acc1: 71.052%
2022-07-12 14:31:09 - epoch 153 lr: 0.014220
2022-07-12 14:31:48 - train: epoch 0153, iter [00100, 05004], lr: 0.014209, loss: 1.6099
2022-07-12 14:32:24 - train: epoch 0153, iter [00200, 05004], lr: 0.014198, loss: 1.5441
2022-07-12 14:32:57 - train: epoch 0153, iter [00300, 05004], lr: 0.014186, loss: 1.7419
2022-07-12 14:33:31 - train: epoch 0153, iter [00400, 05004], lr: 0.014175, loss: 1.6933
2022-07-12 14:34:06 - train: epoch 0153, iter [00500, 05004], lr: 0.014164, loss: 1.9897
2022-07-12 14:34:40 - train: epoch 0153, iter [00600, 05004], lr: 0.014153, loss: 1.9552
2022-07-12 14:35:15 - train: epoch 0153, iter [00700, 05004], lr: 0.014141, loss: 1.7174
2022-07-12 14:35:49 - train: epoch 0153, iter [00800, 05004], lr: 0.014130, loss: 1.8269
2022-07-12 14:36:25 - train: epoch 0153, iter [00900, 05004], lr: 0.014119, loss: 1.7663
2022-07-12 14:36:59 - train: epoch 0153, iter [01000, 05004], lr: 0.014108, loss: 1.9763
2022-07-12 14:37:33 - train: epoch 0153, iter [01100, 05004], lr: 0.014097, loss: 1.6660
2022-07-12 14:38:08 - train: epoch 0153, iter [01200, 05004], lr: 0.014085, loss: 1.6048
2022-07-12 14:38:42 - train: epoch 0153, iter [01300, 05004], lr: 0.014074, loss: 2.0139
2022-07-12 14:39:17 - train: epoch 0153, iter [01400, 05004], lr: 0.014063, loss: 1.5919
2022-07-12 14:39:51 - train: epoch 0153, iter [01500, 05004], lr: 0.014052, loss: 1.4661
2022-07-12 14:40:26 - train: epoch 0153, iter [01600, 05004], lr: 0.014041, loss: 1.5866
2022-07-12 14:41:00 - train: epoch 0153, iter [01700, 05004], lr: 0.014029, loss: 1.7230
2022-07-12 14:41:35 - train: epoch 0153, iter [01800, 05004], lr: 0.014018, loss: 1.6271
2022-07-12 14:42:11 - train: epoch 0153, iter [01900, 05004], lr: 0.014007, loss: 1.6431
2022-07-12 14:42:44 - train: epoch 0153, iter [02000, 05004], lr: 0.013996, loss: 1.4632
2022-07-12 14:43:19 - train: epoch 0153, iter [02100, 05004], lr: 0.013985, loss: 1.6472
2022-07-12 14:43:54 - train: epoch 0153, iter [02200, 05004], lr: 0.013974, loss: 1.5134
2022-07-12 14:44:29 - train: epoch 0153, iter [02300, 05004], lr: 0.013962, loss: 1.9683
2022-07-12 14:45:04 - train: epoch 0153, iter [02400, 05004], lr: 0.013951, loss: 1.4887
2022-07-12 14:45:39 - train: epoch 0153, iter [02500, 05004], lr: 0.013940, loss: 1.4948
2022-07-12 14:46:14 - train: epoch 0153, iter [02600, 05004], lr: 0.013929, loss: 1.7305
2022-07-12 14:46:47 - train: epoch 0153, iter [02700, 05004], lr: 0.013918, loss: 1.5650
2022-07-12 14:47:23 - train: epoch 0153, iter [02800, 05004], lr: 0.013907, loss: 1.7807
2022-07-12 14:47:57 - train: epoch 0153, iter [02900, 05004], lr: 0.013896, loss: 1.6194
2022-07-12 14:48:31 - train: epoch 0153, iter [03000, 05004], lr: 0.013884, loss: 1.7633
2022-07-12 14:49:06 - train: epoch 0153, iter [03100, 05004], lr: 0.013873, loss: 1.8136
2022-07-12 14:49:39 - train: epoch 0153, iter [03200, 05004], lr: 0.013862, loss: 1.8993
2022-07-12 14:50:14 - train: epoch 0153, iter [03300, 05004], lr: 0.013851, loss: 1.7614
2022-07-12 14:50:48 - train: epoch 0153, iter [03400, 05004], lr: 0.013840, loss: 1.5017
2022-07-12 14:51:22 - train: epoch 0153, iter [03500, 05004], lr: 0.013829, loss: 2.0229
2022-07-12 14:51:56 - train: epoch 0153, iter [03600, 05004], lr: 0.013818, loss: 1.5702
2022-07-12 14:52:30 - train: epoch 0153, iter [03700, 05004], lr: 0.013807, loss: 1.7817
2022-07-12 14:53:05 - train: epoch 0153, iter [03800, 05004], lr: 0.013795, loss: 1.5460
2022-07-12 14:53:39 - train: epoch 0153, iter [03900, 05004], lr: 0.013784, loss: 1.6613
2022-07-12 14:54:12 - train: epoch 0153, iter [04000, 05004], lr: 0.013773, loss: 1.7116
2022-07-12 14:54:47 - train: epoch 0153, iter [04100, 05004], lr: 0.013762, loss: 1.6683
2022-07-12 14:55:21 - train: epoch 0153, iter [04200, 05004], lr: 0.013751, loss: 1.6395
2022-07-12 14:55:55 - train: epoch 0153, iter [04300, 05004], lr: 0.013740, loss: 1.8252
2022-07-12 14:56:29 - train: epoch 0153, iter [04400, 05004], lr: 0.013729, loss: 1.8220
2022-07-12 14:57:04 - train: epoch 0153, iter [04500, 05004], lr: 0.013718, loss: 1.8323
2022-07-12 14:57:38 - train: epoch 0153, iter [04600, 05004], lr: 0.013707, loss: 1.7301
2022-07-12 14:58:13 - train: epoch 0153, iter [04700, 05004], lr: 0.013696, loss: 1.8934
2022-07-12 14:58:47 - train: epoch 0153, iter [04800, 05004], lr: 0.013685, loss: 1.9560
2022-07-12 14:59:21 - train: epoch 0153, iter [04900, 05004], lr: 0.013674, loss: 1.9478
2022-07-12 14:59:55 - train: epoch 0153, iter [05000, 05004], lr: 0.013662, loss: 1.6658
2022-07-12 14:59:56 - train: epoch 153, train_loss: 1.7413
2022-07-12 15:01:10 - eval: epoch: 153, acc1: 71.700%, acc5: 90.828%, test_loss: 1.1356, per_image_load_time: 1.945ms, per_image_inference_time: 0.480ms
2022-07-12 15:01:11 - until epoch: 153, best_acc1: 71.700%
2022-07-12 15:01:11 - epoch 154 lr: 0.013662
2022-07-12 15:01:50 - train: epoch 0154, iter [00100, 05004], lr: 0.013651, loss: 1.5567
2022-07-12 15:02:24 - train: epoch 0154, iter [00200, 05004], lr: 0.013640, loss: 1.4048
2022-07-12 15:02:58 - train: epoch 0154, iter [00300, 05004], lr: 0.013629, loss: 1.7429
2022-07-12 15:03:32 - train: epoch 0154, iter [00400, 05004], lr: 0.013618, loss: 1.7162
2022-07-12 15:04:06 - train: epoch 0154, iter [00500, 05004], lr: 0.013607, loss: 1.8855
2022-07-12 15:04:40 - train: epoch 0154, iter [00600, 05004], lr: 0.013596, loss: 1.8242
2022-07-12 15:05:14 - train: epoch 0154, iter [00700, 05004], lr: 0.013585, loss: 1.8309
2022-07-12 15:05:49 - train: epoch 0154, iter [00800, 05004], lr: 0.013574, loss: 1.7823
2022-07-12 15:06:23 - train: epoch 0154, iter [00900, 05004], lr: 0.013563, loss: 1.6509
2022-07-12 15:06:58 - train: epoch 0154, iter [01000, 05004], lr: 0.013552, loss: 1.5327
2022-07-12 15:07:32 - train: epoch 0154, iter [01100, 05004], lr: 0.013541, loss: 1.6848
2022-07-12 15:08:07 - train: epoch 0154, iter [01200, 05004], lr: 0.013530, loss: 1.3698
2022-07-12 15:08:40 - train: epoch 0154, iter [01300, 05004], lr: 0.013519, loss: 1.4992
2022-07-12 15:09:16 - train: epoch 0154, iter [01400, 05004], lr: 0.013508, loss: 1.7307
2022-07-12 15:09:50 - train: epoch 0154, iter [01500, 05004], lr: 0.013497, loss: 1.4886
2022-07-12 15:10:24 - train: epoch 0154, iter [01600, 05004], lr: 0.013486, loss: 1.6039
2022-07-12 15:10:59 - train: epoch 0154, iter [01700, 05004], lr: 0.013475, loss: 1.4458
2022-07-12 15:11:33 - train: epoch 0154, iter [01800, 05004], lr: 0.013464, loss: 1.7449
2022-07-12 15:12:08 - train: epoch 0154, iter [01900, 05004], lr: 0.013453, loss: 1.7535
2022-07-12 15:12:43 - train: epoch 0154, iter [02000, 05004], lr: 0.013442, loss: 1.7103
2022-07-12 15:13:16 - train: epoch 0154, iter [02100, 05004], lr: 0.013431, loss: 1.7412
2022-07-12 15:13:51 - train: epoch 0154, iter [02200, 05004], lr: 0.013420, loss: 1.6625
2022-07-12 15:14:25 - train: epoch 0154, iter [02300, 05004], lr: 0.013409, loss: 1.9091
2022-07-12 15:14:58 - train: epoch 0154, iter [02400, 05004], lr: 0.013398, loss: 1.7991
2022-07-12 15:15:33 - train: epoch 0154, iter [02500, 05004], lr: 0.013387, loss: 1.8733
2022-07-12 15:16:06 - train: epoch 0154, iter [02600, 05004], lr: 0.013376, loss: 1.6223
2022-07-12 15:16:40 - train: epoch 0154, iter [02700, 05004], lr: 0.013365, loss: 1.7445
2022-07-12 15:17:14 - train: epoch 0154, iter [02800, 05004], lr: 0.013354, loss: 2.0471
2022-07-12 15:17:48 - train: epoch 0154, iter [02900, 05004], lr: 0.013343, loss: 1.6033
2022-07-12 15:18:22 - train: epoch 0154, iter [03000, 05004], lr: 0.013332, loss: 1.8181
2022-07-12 15:18:57 - train: epoch 0154, iter [03100, 05004], lr: 0.013321, loss: 1.8292
2022-07-12 15:19:31 - train: epoch 0154, iter [03200, 05004], lr: 0.013310, loss: 1.7403
2022-07-12 15:20:06 - train: epoch 0154, iter [03300, 05004], lr: 0.013299, loss: 1.8433
2022-07-12 15:20:39 - train: epoch 0154, iter [03400, 05004], lr: 0.013288, loss: 1.6715
2022-07-12 15:21:14 - train: epoch 0154, iter [03500, 05004], lr: 0.013277, loss: 1.8271
2022-07-12 15:21:48 - train: epoch 0154, iter [03600, 05004], lr: 0.013266, loss: 1.7943
2022-07-12 15:22:23 - train: epoch 0154, iter [03700, 05004], lr: 0.013256, loss: 1.6549
2022-07-12 15:22:57 - train: epoch 0154, iter [03800, 05004], lr: 0.013245, loss: 1.4033
2022-07-12 15:23:32 - train: epoch 0154, iter [03900, 05004], lr: 0.013234, loss: 1.9429
2022-07-12 15:24:05 - train: epoch 0154, iter [04000, 05004], lr: 0.013223, loss: 1.7697
2022-07-12 15:24:40 - train: epoch 0154, iter [04100, 05004], lr: 0.013212, loss: 1.4721
2022-07-12 15:25:15 - train: epoch 0154, iter [04200, 05004], lr: 0.013201, loss: 1.7688
2022-07-12 15:25:49 - train: epoch 0154, iter [04300, 05004], lr: 0.013190, loss: 1.6448
2022-07-12 15:26:23 - train: epoch 0154, iter [04400, 05004], lr: 0.013179, loss: 1.8110
2022-07-12 15:26:58 - train: epoch 0154, iter [04500, 05004], lr: 0.013168, loss: 1.6330
2022-07-12 15:27:33 - train: epoch 0154, iter [04600, 05004], lr: 0.013157, loss: 1.7913
2022-07-12 15:28:07 - train: epoch 0154, iter [04700, 05004], lr: 0.013147, loss: 1.8459
2022-07-12 15:28:42 - train: epoch 0154, iter [04800, 05004], lr: 0.013136, loss: 1.8630
2022-07-12 15:29:16 - train: epoch 0154, iter [04900, 05004], lr: 0.013125, loss: 1.8588
2022-07-12 15:29:49 - train: epoch 0154, iter [05000, 05004], lr: 0.013114, loss: 1.7090
2022-07-12 15:29:50 - train: epoch 154, train_loss: 1.7299
2022-07-12 15:31:05 - eval: epoch: 154, acc1: 71.536%, acc5: 90.586%, test_loss: 1.1456, per_image_load_time: 2.351ms, per_image_inference_time: 0.487ms
2022-07-12 15:31:05 - until epoch: 154, best_acc1: 71.700%
2022-07-12 15:31:05 - epoch 155 lr: 0.013113
2022-07-12 15:31:44 - train: epoch 0155, iter [00100, 05004], lr: 0.013103, loss: 1.8936
2022-07-12 15:32:19 - train: epoch 0155, iter [00200, 05004], lr: 0.013092, loss: 1.8479
2022-07-12 15:32:53 - train: epoch 0155, iter [00300, 05004], lr: 0.013081, loss: 1.6420
2022-07-12 15:33:27 - train: epoch 0155, iter [00400, 05004], lr: 0.013070, loss: 1.7641
2022-07-12 15:34:01 - train: epoch 0155, iter [00500, 05004], lr: 0.013059, loss: 1.8947
2022-07-12 15:34:35 - train: epoch 0155, iter [00600, 05004], lr: 0.013048, loss: 1.7901
2022-07-12 15:35:09 - train: epoch 0155, iter [00700, 05004], lr: 0.013037, loss: 1.5634
2022-07-12 15:35:43 - train: epoch 0155, iter [00800, 05004], lr: 0.013027, loss: 1.6220
2022-07-12 15:36:18 - train: epoch 0155, iter [00900, 05004], lr: 0.013016, loss: 1.5822
2022-07-12 15:36:53 - train: epoch 0155, iter [01000, 05004], lr: 0.013005, loss: 1.9484
2022-07-12 15:37:28 - train: epoch 0155, iter [01100, 05004], lr: 0.012994, loss: 1.6843
2022-07-12 15:38:02 - train: epoch 0155, iter [01200, 05004], lr: 0.012983, loss: 1.7528
2022-07-12 15:38:37 - train: epoch 0155, iter [01300, 05004], lr: 0.012973, loss: 1.6209
2022-07-12 15:39:11 - train: epoch 0155, iter [01400, 05004], lr: 0.012962, loss: 1.8505
2022-07-12 15:39:46 - train: epoch 0155, iter [01500, 05004], lr: 0.012951, loss: 1.6019
2022-07-12 15:40:21 - train: epoch 0155, iter [01600, 05004], lr: 0.012940, loss: 1.8141
2022-07-12 15:40:56 - train: epoch 0155, iter [01700, 05004], lr: 0.012929, loss: 1.8050
2022-07-12 15:41:31 - train: epoch 0155, iter [01800, 05004], lr: 0.012918, loss: 1.8395
2022-07-12 15:42:06 - train: epoch 0155, iter [01900, 05004], lr: 0.012908, loss: 1.6213
2022-07-12 15:42:40 - train: epoch 0155, iter [02000, 05004], lr: 0.012897, loss: 1.7421
2022-07-12 15:43:15 - train: epoch 0155, iter [02100, 05004], lr: 0.012886, loss: 1.5570
2022-07-12 15:43:49 - train: epoch 0155, iter [02200, 05004], lr: 0.012875, loss: 1.6014
2022-07-12 15:44:24 - train: epoch 0155, iter [02300, 05004], lr: 0.012865, loss: 1.5868
2022-07-12 15:44:59 - train: epoch 0155, iter [02400, 05004], lr: 0.012854, loss: 1.6237
2022-07-12 15:45:35 - train: epoch 0155, iter [02500, 05004], lr: 0.012843, loss: 1.6789
2022-07-12 15:46:09 - train: epoch 0155, iter [02600, 05004], lr: 0.012832, loss: 1.9306
2022-07-12 15:46:44 - train: epoch 0155, iter [02700, 05004], lr: 0.012821, loss: 1.6965
2022-07-12 15:47:17 - train: epoch 0155, iter [02800, 05004], lr: 0.012811, loss: 1.6768
2022-07-12 15:47:51 - train: epoch 0155, iter [02900, 05004], lr: 0.012800, loss: 1.7560
2022-07-12 15:48:25 - train: epoch 0155, iter [03000, 05004], lr: 0.012789, loss: 1.5653
2022-07-12 15:49:00 - train: epoch 0155, iter [03100, 05004], lr: 0.012778, loss: 1.9373
2022-07-12 15:49:34 - train: epoch 0155, iter [03200, 05004], lr: 0.012768, loss: 1.5706
2022-07-12 15:50:08 - train: epoch 0155, iter [03300, 05004], lr: 0.012757, loss: 1.7783
2022-07-12 15:50:42 - train: epoch 0155, iter [03400, 05004], lr: 0.012746, loss: 1.8037
2022-07-12 15:51:16 - train: epoch 0155, iter [03500, 05004], lr: 0.012735, loss: 1.5622
2022-07-12 15:51:50 - train: epoch 0155, iter [03600, 05004], lr: 0.012725, loss: 1.8904
2022-07-12 15:52:25 - train: epoch 0155, iter [03700, 05004], lr: 0.012714, loss: 1.6985
2022-07-12 15:52:58 - train: epoch 0155, iter [03800, 05004], lr: 0.012703, loss: 1.8740
2022-07-12 15:53:33 - train: epoch 0155, iter [03900, 05004], lr: 0.012693, loss: 1.5348
2022-07-12 15:54:08 - train: epoch 0155, iter [04000, 05004], lr: 0.012682, loss: 1.9122
2022-07-12 15:54:42 - train: epoch 0155, iter [04100, 05004], lr: 0.012671, loss: 1.6424
2022-07-12 15:55:15 - train: epoch 0155, iter [04200, 05004], lr: 0.012660, loss: 1.7175
2022-07-12 15:55:49 - train: epoch 0155, iter [04300, 05004], lr: 0.012650, loss: 1.9052
2022-07-12 15:56:24 - train: epoch 0155, iter [04400, 05004], lr: 0.012639, loss: 1.8634
2022-07-12 15:56:59 - train: epoch 0155, iter [04500, 05004], lr: 0.012628, loss: 1.5102
2022-07-12 15:57:33 - train: epoch 0155, iter [04600, 05004], lr: 0.012618, loss: 1.7342
2022-07-12 15:58:08 - train: epoch 0155, iter [04700, 05004], lr: 0.012607, loss: 1.7435
2022-07-12 15:58:41 - train: epoch 0155, iter [04800, 05004], lr: 0.012596, loss: 1.6629
2022-07-12 15:59:16 - train: epoch 0155, iter [04900, 05004], lr: 0.012586, loss: 1.6721
2022-07-12 15:59:49 - train: epoch 0155, iter [05000, 05004], lr: 0.012575, loss: 1.7488
2022-07-12 15:59:50 - train: epoch 155, train_loss: 1.7173
2022-07-12 16:01:04 - eval: epoch: 155, acc1: 71.776%, acc5: 90.768%, test_loss: 1.1363, per_image_load_time: 2.055ms, per_image_inference_time: 0.477ms
2022-07-12 16:01:05 - until epoch: 155, best_acc1: 71.776%
2022-07-12 16:01:05 - epoch 156 lr: 0.012574
2022-07-12 16:01:44 - train: epoch 0156, iter [00100, 05004], lr: 0.012564, loss: 1.8053
2022-07-12 16:02:18 - train: epoch 0156, iter [00200, 05004], lr: 0.012553, loss: 1.6303
2022-07-12 16:02:53 - train: epoch 0156, iter [00300, 05004], lr: 0.012542, loss: 1.7206
2022-07-12 16:03:25 - train: epoch 0156, iter [00400, 05004], lr: 0.012532, loss: 1.5891
2022-07-12 16:03:59 - train: epoch 0156, iter [00500, 05004], lr: 0.012521, loss: 1.7847
2022-07-12 16:04:33 - train: epoch 0156, iter [00600, 05004], lr: 0.012510, loss: 1.8549
2022-07-12 16:05:07 - train: epoch 0156, iter [00700, 05004], lr: 0.012500, loss: 1.6335
2022-07-12 16:05:42 - train: epoch 0156, iter [00800, 05004], lr: 0.012489, loss: 1.7937
2022-07-12 16:06:16 - train: epoch 0156, iter [00900, 05004], lr: 0.012479, loss: 1.9526
2022-07-12 16:06:51 - train: epoch 0156, iter [01000, 05004], lr: 0.012468, loss: 1.7683
2022-07-12 16:07:24 - train: epoch 0156, iter [01100, 05004], lr: 0.012457, loss: 1.5105
2022-07-12 16:07:59 - train: epoch 0156, iter [01200, 05004], lr: 0.012447, loss: 1.5267
2022-07-12 16:08:33 - train: epoch 0156, iter [01300, 05004], lr: 0.012436, loss: 1.6889
2022-07-12 16:09:08 - train: epoch 0156, iter [01400, 05004], lr: 0.012425, loss: 1.6350
2022-07-12 16:09:43 - train: epoch 0156, iter [01500, 05004], lr: 0.012415, loss: 1.8093
2022-07-12 16:10:17 - train: epoch 0156, iter [01600, 05004], lr: 0.012404, loss: 1.5083
2022-07-12 16:10:51 - train: epoch 0156, iter [01700, 05004], lr: 0.012394, loss: 1.6745
2022-07-12 16:11:25 - train: epoch 0156, iter [01800, 05004], lr: 0.012383, loss: 1.6964
2022-07-12 16:11:59 - train: epoch 0156, iter [01900, 05004], lr: 0.012372, loss: 1.5679
2022-07-12 16:12:32 - train: epoch 0156, iter [02000, 05004], lr: 0.012362, loss: 1.5981
2022-07-12 16:13:07 - train: epoch 0156, iter [02100, 05004], lr: 0.012351, loss: 1.7756
2022-07-12 16:13:41 - train: epoch 0156, iter [02200, 05004], lr: 0.012341, loss: 1.8005
2022-07-12 16:14:15 - train: epoch 0156, iter [02300, 05004], lr: 0.012330, loss: 2.1627
2022-07-12 16:14:49 - train: epoch 0156, iter [02400, 05004], lr: 0.012319, loss: 1.5842
2022-07-12 16:15:24 - train: epoch 0156, iter [02500, 05004], lr: 0.012309, loss: 1.8650
2022-07-12 16:15:58 - train: epoch 0156, iter [02600, 05004], lr: 0.012298, loss: 1.6687
2022-07-12 16:16:32 - train: epoch 0156, iter [02700, 05004], lr: 0.012288, loss: 1.6030
2022-07-12 16:17:07 - train: epoch 0156, iter [02800, 05004], lr: 0.012277, loss: 1.8768
2022-07-12 16:17:42 - train: epoch 0156, iter [02900, 05004], lr: 0.012267, loss: 1.5123
2022-07-12 16:18:16 - train: epoch 0156, iter [03000, 05004], lr: 0.012256, loss: 1.6902
2022-07-12 16:18:50 - train: epoch 0156, iter [03100, 05004], lr: 0.012245, loss: 1.7598
2022-07-12 16:19:25 - train: epoch 0156, iter [03200, 05004], lr: 0.012235, loss: 1.6721
2022-07-12 16:19:59 - train: epoch 0156, iter [03300, 05004], lr: 0.012224, loss: 1.6518
2022-07-12 16:20:34 - train: epoch 0156, iter [03400, 05004], lr: 0.012214, loss: 1.7687
2022-07-12 16:21:08 - train: epoch 0156, iter [03500, 05004], lr: 0.012203, loss: 1.6693
2022-07-12 16:21:43 - train: epoch 0156, iter [03600, 05004], lr: 0.012193, loss: 2.2100
2022-07-12 16:22:18 - train: epoch 0156, iter [03700, 05004], lr: 0.012182, loss: 1.9142
2022-07-12 16:22:53 - train: epoch 0156, iter [03800, 05004], lr: 0.012172, loss: 1.8182
2022-07-12 16:23:27 - train: epoch 0156, iter [03900, 05004], lr: 0.012161, loss: 1.8056
2022-07-12 16:24:02 - train: epoch 0156, iter [04000, 05004], lr: 0.012151, loss: 1.8531
2022-07-12 16:24:37 - train: epoch 0156, iter [04100, 05004], lr: 0.012140, loss: 1.8547
2022-07-12 16:25:11 - train: epoch 0156, iter [04200, 05004], lr: 0.012130, loss: 1.5495
2022-07-12 16:25:46 - train: epoch 0156, iter [04300, 05004], lr: 0.012119, loss: 1.7131
2022-07-12 16:26:21 - train: epoch 0156, iter [04400, 05004], lr: 0.012109, loss: 1.6853
2022-07-12 16:26:56 - train: epoch 0156, iter [04500, 05004], lr: 0.012098, loss: 1.8667
2022-07-12 16:27:31 - train: epoch 0156, iter [04600, 05004], lr: 0.012088, loss: 1.6671
2022-07-12 16:28:06 - train: epoch 0156, iter [04700, 05004], lr: 0.012077, loss: 1.3877
2022-07-12 16:28:41 - train: epoch 0156, iter [04800, 05004], lr: 0.012067, loss: 1.6504
2022-07-12 16:29:16 - train: epoch 0156, iter [04900, 05004], lr: 0.012056, loss: 1.8915
2022-07-12 16:29:50 - train: epoch 0156, iter [05000, 05004], lr: 0.012046, loss: 1.5667
2022-07-12 16:29:51 - train: epoch 156, train_loss: 1.7065
2022-07-12 16:31:06 - eval: epoch: 156, acc1: 71.602%, acc5: 90.744%, test_loss: 1.1432, per_image_load_time: 2.154ms, per_image_inference_time: 0.498ms
2022-07-12 16:31:06 - until epoch: 156, best_acc1: 71.776%
2022-07-12 16:31:06 - epoch 157 lr: 0.012045
2022-07-12 16:31:46 - train: epoch 0157, iter [00100, 05004], lr: 0.012035, loss: 1.8611
2022-07-12 16:32:20 - train: epoch 0157, iter [00200, 05004], lr: 0.012024, loss: 1.5318
2022-07-12 16:32:54 - train: epoch 0157, iter [00300, 05004], lr: 0.012014, loss: 1.9317
2022-07-12 16:33:30 - train: epoch 0157, iter [00400, 05004], lr: 0.012003, loss: 1.6822
2022-07-12 16:34:03 - train: epoch 0157, iter [00500, 05004], lr: 0.011993, loss: 1.5951
2022-07-12 16:34:38 - train: epoch 0157, iter [00600, 05004], lr: 0.011982, loss: 1.8709
2022-07-12 16:35:13 - train: epoch 0157, iter [00700, 05004], lr: 0.011972, loss: 1.6529
2022-07-12 16:35:47 - train: epoch 0157, iter [00800, 05004], lr: 0.011961, loss: 1.6448
2022-07-12 16:36:22 - train: epoch 0157, iter [00900, 05004], lr: 0.011951, loss: 1.7445
2022-07-12 16:36:58 - train: epoch 0157, iter [01000, 05004], lr: 0.011941, loss: 1.6591
2022-07-12 16:37:32 - train: epoch 0157, iter [01100, 05004], lr: 0.011930, loss: 1.3680
2022-07-12 16:38:07 - train: epoch 0157, iter [01200, 05004], lr: 0.011920, loss: 1.5435
2022-07-12 16:38:41 - train: epoch 0157, iter [01300, 05004], lr: 0.011909, loss: 1.7000
2022-07-12 16:39:16 - train: epoch 0157, iter [01400, 05004], lr: 0.011899, loss: 2.0392
2022-07-12 16:39:51 - train: epoch 0157, iter [01500, 05004], lr: 0.011888, loss: 1.6812
2022-07-12 16:40:25 - train: epoch 0157, iter [01600, 05004], lr: 0.011878, loss: 1.7703
2022-07-12 16:41:00 - train: epoch 0157, iter [01700, 05004], lr: 0.011868, loss: 1.5848
2022-07-12 16:41:34 - train: epoch 0157, iter [01800, 05004], lr: 0.011857, loss: 1.6454
2022-07-12 16:42:09 - train: epoch 0157, iter [01900, 05004], lr: 0.011847, loss: 1.6823
2022-07-12 16:42:43 - train: epoch 0157, iter [02000, 05004], lr: 0.011836, loss: 1.6793
2022-07-12 16:43:18 - train: epoch 0157, iter [02100, 05004], lr: 0.011826, loss: 1.5948
2022-07-12 16:43:53 - train: epoch 0157, iter [02200, 05004], lr: 0.011816, loss: 1.5671
2022-07-12 16:44:28 - train: epoch 0157, iter [02300, 05004], lr: 0.011805, loss: 1.8684
2022-07-12 16:45:02 - train: epoch 0157, iter [02400, 05004], lr: 0.011795, loss: 1.8280
2022-07-12 16:45:37 - train: epoch 0157, iter [02500, 05004], lr: 0.011784, loss: 1.7843
2022-07-12 16:46:12 - train: epoch 0157, iter [02600, 05004], lr: 0.011774, loss: 1.8331
2022-07-12 16:46:47 - train: epoch 0157, iter [02700, 05004], lr: 0.011764, loss: 1.8348
2022-07-12 16:47:22 - train: epoch 0157, iter [02800, 05004], lr: 0.011753, loss: 1.4920
2022-07-12 16:47:57 - train: epoch 0157, iter [02900, 05004], lr: 0.011743, loss: 1.5299
2022-07-12 16:48:32 - train: epoch 0157, iter [03000, 05004], lr: 0.011733, loss: 1.6901
2022-07-12 16:49:07 - train: epoch 0157, iter [03100, 05004], lr: 0.011722, loss: 1.5172
2022-07-12 16:49:41 - train: epoch 0157, iter [03200, 05004], lr: 0.011712, loss: 1.5749
2022-07-12 16:50:15 - train: epoch 0157, iter [03300, 05004], lr: 0.011702, loss: 1.7416
2022-07-12 16:50:50 - train: epoch 0157, iter [03400, 05004], lr: 0.011691, loss: 1.4013
2022-07-12 16:51:25 - train: epoch 0157, iter [03500, 05004], lr: 0.011681, loss: 1.6927
2022-07-12 16:52:00 - train: epoch 0157, iter [03600, 05004], lr: 0.011670, loss: 1.5192
2022-07-12 16:52:34 - train: epoch 0157, iter [03700, 05004], lr: 0.011660, loss: 1.5150
2022-07-12 16:53:09 - train: epoch 0157, iter [03800, 05004], lr: 0.011650, loss: 1.7093
2022-07-12 16:53:43 - train: epoch 0157, iter [03900, 05004], lr: 0.011639, loss: 1.8164
2022-07-12 16:54:18 - train: epoch 0157, iter [04000, 05004], lr: 0.011629, loss: 1.6768
2022-07-12 16:54:52 - train: epoch 0157, iter [04100, 05004], lr: 0.011619, loss: 1.4916
2022-07-12 16:55:28 - train: epoch 0157, iter [04200, 05004], lr: 0.011609, loss: 1.6808
2022-07-12 16:56:02 - train: epoch 0157, iter [04300, 05004], lr: 0.011598, loss: 1.8755
2022-07-12 16:56:38 - train: epoch 0157, iter [04400, 05004], lr: 0.011588, loss: 1.9405
2022-07-12 16:57:13 - train: epoch 0157, iter [04500, 05004], lr: 0.011578, loss: 2.0058
2022-07-12 16:57:48 - train: epoch 0157, iter [04600, 05004], lr: 0.011567, loss: 1.6212
2022-07-12 16:58:22 - train: epoch 0157, iter [04700, 05004], lr: 0.011557, loss: 1.9271
2022-07-12 16:58:57 - train: epoch 0157, iter [04800, 05004], lr: 0.011547, loss: 1.6080
2022-07-12 16:59:32 - train: epoch 0157, iter [04900, 05004], lr: 0.011536, loss: 1.6012
2022-07-12 17:00:05 - train: epoch 0157, iter [05000, 05004], lr: 0.011526, loss: 1.5983
2022-07-12 17:00:06 - train: epoch 157, train_loss: 1.6974
2022-07-12 17:01:21 - eval: epoch: 157, acc1: 72.402%, acc5: 91.316%, test_loss: 1.0917, per_image_load_time: 1.820ms, per_image_inference_time: 0.466ms
2022-07-12 17:01:21 - until epoch: 157, best_acc1: 72.402%
2022-07-12 17:01:21 - epoch 158 lr: 0.011526
2022-07-12 17:02:00 - train: epoch 0158, iter [00100, 05004], lr: 0.011515, loss: 1.7731
2022-07-12 17:02:35 - train: epoch 0158, iter [00200, 05004], lr: 0.011505, loss: 1.3897
2022-07-12 17:03:08 - train: epoch 0158, iter [00300, 05004], lr: 0.011495, loss: 1.5782
2022-07-12 17:03:42 - train: epoch 0158, iter [00400, 05004], lr: 0.011485, loss: 1.7837
2022-07-12 17:04:16 - train: epoch 0158, iter [00500, 05004], lr: 0.011474, loss: 1.5748
2022-07-12 17:04:50 - train: epoch 0158, iter [00600, 05004], lr: 0.011464, loss: 1.4641
2022-07-12 17:05:24 - train: epoch 0158, iter [00700, 05004], lr: 0.011454, loss: 1.4893
2022-07-12 17:05:58 - train: epoch 0158, iter [00800, 05004], lr: 0.011444, loss: 1.8812
2022-07-12 17:06:31 - train: epoch 0158, iter [00900, 05004], lr: 0.011433, loss: 1.8326
2022-07-12 17:07:05 - train: epoch 0158, iter [01000, 05004], lr: 0.011423, loss: 1.5715
2022-07-12 17:07:39 - train: epoch 0158, iter [01100, 05004], lr: 0.011413, loss: 1.4564
2022-07-12 17:08:13 - train: epoch 0158, iter [01200, 05004], lr: 0.011403, loss: 1.5924
2022-07-12 17:08:47 - train: epoch 0158, iter [01300, 05004], lr: 0.011392, loss: 1.9878
2022-07-12 17:09:21 - train: epoch 0158, iter [01400, 05004], lr: 0.011382, loss: 1.8071
2022-07-12 17:09:55 - train: epoch 0158, iter [01500, 05004], lr: 0.011372, loss: 1.7690
2022-07-12 17:10:29 - train: epoch 0158, iter [01600, 05004], lr: 0.011362, loss: 1.8049
2022-07-12 17:11:04 - train: epoch 0158, iter [01700, 05004], lr: 0.011352, loss: 1.8712
2022-07-12 17:11:37 - train: epoch 0158, iter [01800, 05004], lr: 0.011341, loss: 1.6493
2022-07-12 17:12:13 - train: epoch 0158, iter [01900, 05004], lr: 0.011331, loss: 1.6592
2022-07-12 17:12:46 - train: epoch 0158, iter [02000, 05004], lr: 0.011321, loss: 1.9779
2022-07-12 17:13:21 - train: epoch 0158, iter [02100, 05004], lr: 0.011311, loss: 1.7537
2022-07-12 17:13:56 - train: epoch 0158, iter [02200, 05004], lr: 0.011301, loss: 1.6537
2022-07-12 17:14:30 - train: epoch 0158, iter [02300, 05004], lr: 0.011290, loss: 1.5504
2022-07-12 17:15:04 - train: epoch 0158, iter [02400, 05004], lr: 0.011280, loss: 1.5964
2022-07-12 17:15:39 - train: epoch 0158, iter [02500, 05004], lr: 0.011270, loss: 1.4783
2022-07-12 17:16:13 - train: epoch 0158, iter [02600, 05004], lr: 0.011260, loss: 1.5961
2022-07-12 17:16:47 - train: epoch 0158, iter [02700, 05004], lr: 0.011250, loss: 1.8431
2022-07-12 17:17:22 - train: epoch 0158, iter [02800, 05004], lr: 0.011239, loss: 1.8065
2022-07-12 17:17:57 - train: epoch 0158, iter [02900, 05004], lr: 0.011229, loss: 1.4517
2022-07-12 17:18:31 - train: epoch 0158, iter [03000, 05004], lr: 0.011219, loss: 1.6176
2022-07-12 17:19:06 - train: epoch 0158, iter [03100, 05004], lr: 0.011209, loss: 1.6164
2022-07-12 17:19:40 - train: epoch 0158, iter [03200, 05004], lr: 0.011199, loss: 1.6208
2022-07-12 17:20:15 - train: epoch 0158, iter [03300, 05004], lr: 0.011189, loss: 1.4711
2022-07-12 17:20:49 - train: epoch 0158, iter [03400, 05004], lr: 0.011178, loss: 1.6459
2022-07-12 17:21:23 - train: epoch 0158, iter [03500, 05004], lr: 0.011168, loss: 1.7578
2022-07-12 17:21:58 - train: epoch 0158, iter [03600, 05004], lr: 0.011158, loss: 1.5949
2022-07-12 17:22:33 - train: epoch 0158, iter [03700, 05004], lr: 0.011148, loss: 1.8772
2022-07-12 17:23:08 - train: epoch 0158, iter [03800, 05004], lr: 0.011138, loss: 1.8625
2022-07-12 17:23:43 - train: epoch 0158, iter [03900, 05004], lr: 0.011128, loss: 1.4954
2022-07-12 17:24:16 - train: epoch 0158, iter [04000, 05004], lr: 0.011118, loss: 1.4585
2022-07-12 17:24:51 - train: epoch 0158, iter [04100, 05004], lr: 0.011108, loss: 1.7713
2022-07-12 17:25:24 - train: epoch 0158, iter [04200, 05004], lr: 0.011097, loss: 1.5901
2022-07-12 17:25:58 - train: epoch 0158, iter [04300, 05004], lr: 0.011087, loss: 1.8298
2022-07-12 17:26:31 - train: epoch 0158, iter [04400, 05004], lr: 0.011077, loss: 1.5101
2022-07-12 17:27:05 - train: epoch 0158, iter [04500, 05004], lr: 0.011067, loss: 1.5138
2022-07-12 17:27:39 - train: epoch 0158, iter [04600, 05004], lr: 0.011057, loss: 1.6252
2022-07-12 17:28:13 - train: epoch 0158, iter [04700, 05004], lr: 0.011047, loss: 1.5597
2022-07-12 17:28:48 - train: epoch 0158, iter [04800, 05004], lr: 0.011037, loss: 1.7042
2022-07-12 17:29:22 - train: epoch 0158, iter [04900, 05004], lr: 0.011027, loss: 1.6470
2022-07-12 17:29:54 - train: epoch 0158, iter [05000, 05004], lr: 0.011017, loss: 1.4393
2022-07-12 17:29:55 - train: epoch 158, train_loss: 1.6836
2022-07-12 17:31:09 - eval: epoch: 158, acc1: 72.306%, acc5: 91.038%, test_loss: 1.1112, per_image_load_time: 1.449ms, per_image_inference_time: 0.469ms
2022-07-12 17:31:09 - until epoch: 158, best_acc1: 72.402%
2022-07-12 17:31:09 - epoch 159 lr: 0.011016
2022-07-12 17:31:48 - train: epoch 0159, iter [00100, 05004], lr: 0.011006, loss: 1.5655
2022-07-12 17:32:23 - train: epoch 0159, iter [00200, 05004], lr: 0.010996, loss: 1.9227
2022-07-12 17:32:58 - train: epoch 0159, iter [00300, 05004], lr: 0.010986, loss: 1.8125
2022-07-12 17:33:31 - train: epoch 0159, iter [00400, 05004], lr: 0.010976, loss: 1.5755
2022-07-12 17:34:05 - train: epoch 0159, iter [00500, 05004], lr: 0.010966, loss: 1.7308
2022-07-12 17:34:38 - train: epoch 0159, iter [00600, 05004], lr: 0.010956, loss: 1.4404
2022-07-12 17:35:12 - train: epoch 0159, iter [00700, 05004], lr: 0.010946, loss: 1.6362
2022-07-12 17:35:46 - train: epoch 0159, iter [00800, 05004], lr: 0.010936, loss: 1.6489
2022-07-12 17:36:20 - train: epoch 0159, iter [00900, 05004], lr: 0.010926, loss: 1.5652
2022-07-12 17:36:54 - train: epoch 0159, iter [01000, 05004], lr: 0.010916, loss: 1.7121
2022-07-12 17:37:29 - train: epoch 0159, iter [01100, 05004], lr: 0.010906, loss: 1.7701
2022-07-12 17:38:03 - train: epoch 0159, iter [01200, 05004], lr: 0.010896, loss: 1.4176
2022-07-12 17:38:36 - train: epoch 0159, iter [01300, 05004], lr: 0.010886, loss: 1.7637
2022-07-12 17:39:10 - train: epoch 0159, iter [01400, 05004], lr: 0.010876, loss: 1.7679
2022-07-12 17:39:44 - train: epoch 0159, iter [01500, 05004], lr: 0.010866, loss: 1.6874
2022-07-12 17:40:18 - train: epoch 0159, iter [01600, 05004], lr: 0.010856, loss: 1.8392
2022-07-12 17:40:51 - train: epoch 0159, iter [01700, 05004], lr: 0.010846, loss: 1.4271
2022-07-12 17:41:26 - train: epoch 0159, iter [01800, 05004], lr: 0.010835, loss: 1.5645
2022-07-12 17:42:00 - train: epoch 0159, iter [01900, 05004], lr: 0.010825, loss: 1.4898
2022-07-12 17:42:34 - train: epoch 0159, iter [02000, 05004], lr: 0.010815, loss: 1.5263
2022-07-12 17:43:07 - train: epoch 0159, iter [02100, 05004], lr: 0.010805, loss: 1.6607
2022-07-12 17:43:41 - train: epoch 0159, iter [02200, 05004], lr: 0.010795, loss: 1.5692
2022-07-12 17:44:16 - train: epoch 0159, iter [02300, 05004], lr: 0.010786, loss: 1.7260
2022-07-12 17:44:50 - train: epoch 0159, iter [02400, 05004], lr: 0.010776, loss: 1.6322
2022-07-12 17:45:25 - train: epoch 0159, iter [02500, 05004], lr: 0.010766, loss: 1.7844
2022-07-12 17:45:59 - train: epoch 0159, iter [02600, 05004], lr: 0.010756, loss: 1.6345
2022-07-12 17:46:34 - train: epoch 0159, iter [02700, 05004], lr: 0.010746, loss: 1.5635
2022-07-12 17:47:08 - train: epoch 0159, iter [02800, 05004], lr: 0.010736, loss: 1.8580
2022-07-12 17:47:43 - train: epoch 0159, iter [02900, 05004], lr: 0.010726, loss: 1.9150
2022-07-12 17:48:17 - train: epoch 0159, iter [03000, 05004], lr: 0.010716, loss: 1.8680
2022-07-12 17:48:52 - train: epoch 0159, iter [03100, 05004], lr: 0.010706, loss: 1.5313
2022-07-12 17:49:26 - train: epoch 0159, iter [03200, 05004], lr: 0.010696, loss: 1.6089
2022-07-12 17:50:00 - train: epoch 0159, iter [03300, 05004], lr: 0.010686, loss: 1.6711
2022-07-12 17:50:35 - train: epoch 0159, iter [03400, 05004], lr: 0.010676, loss: 1.7508
2022-07-12 17:51:09 - train: epoch 0159, iter [03500, 05004], lr: 0.010666, loss: 1.7767
2022-07-12 17:51:44 - train: epoch 0159, iter [03600, 05004], lr: 0.010656, loss: 1.7373
2022-07-12 17:52:19 - train: epoch 0159, iter [03700, 05004], lr: 0.010646, loss: 1.8117
2022-07-12 17:52:54 - train: epoch 0159, iter [03800, 05004], lr: 0.010636, loss: 1.5598
2022-07-12 17:53:29 - train: epoch 0159, iter [03900, 05004], lr: 0.010626, loss: 1.8683
2022-07-12 17:54:03 - train: epoch 0159, iter [04000, 05004], lr: 0.010616, loss: 1.6619
2022-07-12 17:54:38 - train: epoch 0159, iter [04100, 05004], lr: 0.010606, loss: 1.6167
2022-07-12 17:55:13 - train: epoch 0159, iter [04200, 05004], lr: 0.010596, loss: 1.5535
2022-07-12 17:55:48 - train: epoch 0159, iter [04300, 05004], lr: 0.010587, loss: 1.7716
2022-07-12 17:56:22 - train: epoch 0159, iter [04400, 05004], lr: 0.010577, loss: 1.6972
2022-07-12 17:56:58 - train: epoch 0159, iter [04500, 05004], lr: 0.010567, loss: 1.8237
2022-07-12 17:57:32 - train: epoch 0159, iter [04600, 05004], lr: 0.010557, loss: 1.9356
2022-07-12 17:58:07 - train: epoch 0159, iter [04700, 05004], lr: 0.010547, loss: 1.5086
2022-07-12 17:58:41 - train: epoch 0159, iter [04800, 05004], lr: 0.010537, loss: 1.7783
2022-07-12 17:59:16 - train: epoch 0159, iter [04900, 05004], lr: 0.010527, loss: 1.6203
2022-07-12 17:59:49 - train: epoch 0159, iter [05000, 05004], lr: 0.010517, loss: 1.7096
2022-07-12 17:59:51 - train: epoch 159, train_loss: 1.6715
2022-07-12 18:01:05 - eval: epoch: 159, acc1: 71.802%, acc5: 90.734%, test_loss: 1.1324, per_image_load_time: 1.961ms, per_image_inference_time: 0.475ms
2022-07-12 18:01:06 - until epoch: 159, best_acc1: 72.402%
2022-07-12 18:01:06 - epoch 160 lr: 0.010517
2022-07-12 18:01:46 - train: epoch 0160, iter [00100, 05004], lr: 0.010507, loss: 1.7011
2022-07-12 18:02:20 - train: epoch 0160, iter [00200, 05004], lr: 0.010497, loss: 1.5677
2022-07-12 18:02:54 - train: epoch 0160, iter [00300, 05004], lr: 0.010487, loss: 1.5311
2022-07-12 18:03:28 - train: epoch 0160, iter [00400, 05004], lr: 0.010477, loss: 1.3094
2022-07-12 18:04:04 - train: epoch 0160, iter [00500, 05004], lr: 0.010468, loss: 1.6869
2022-07-12 18:04:38 - train: epoch 0160, iter [00600, 05004], lr: 0.010458, loss: 1.6133
2022-07-12 18:05:12 - train: epoch 0160, iter [00700, 05004], lr: 0.010448, loss: 1.3845
2022-07-12 18:05:47 - train: epoch 0160, iter [00800, 05004], lr: 0.010438, loss: 1.4849
2022-07-12 18:06:21 - train: epoch 0160, iter [00900, 05004], lr: 0.010428, loss: 1.6870
2022-07-12 18:06:55 - train: epoch 0160, iter [01000, 05004], lr: 0.010418, loss: 1.7500
2022-07-12 18:07:30 - train: epoch 0160, iter [01100, 05004], lr: 0.010409, loss: 1.8389
2022-07-12 18:08:04 - train: epoch 0160, iter [01200, 05004], lr: 0.010399, loss: 1.5932
2022-07-12 18:08:38 - train: epoch 0160, iter [01300, 05004], lr: 0.010389, loss: 1.7258
2022-07-12 18:09:12 - train: epoch 0160, iter [01400, 05004], lr: 0.010379, loss: 1.7450
2022-07-12 18:09:47 - train: epoch 0160, iter [01500, 05004], lr: 0.010369, loss: 1.5133
2022-07-12 18:10:21 - train: epoch 0160, iter [01600, 05004], lr: 0.010359, loss: 1.8247
2022-07-12 18:10:56 - train: epoch 0160, iter [01700, 05004], lr: 0.010350, loss: 1.9092
2022-07-12 18:11:30 - train: epoch 0160, iter [01800, 05004], lr: 0.010340, loss: 1.5215
2022-07-12 18:12:05 - train: epoch 0160, iter [01900, 05004], lr: 0.010330, loss: 1.8351
2022-07-12 18:12:38 - train: epoch 0160, iter [02000, 05004], lr: 0.010320, loss: 1.7128
2022-07-12 18:13:12 - train: epoch 0160, iter [02100, 05004], lr: 0.010310, loss: 1.5582
2022-07-12 18:13:47 - train: epoch 0160, iter [02200, 05004], lr: 0.010301, loss: 1.6418
2022-07-12 18:14:22 - train: epoch 0160, iter [02300, 05004], lr: 0.010291, loss: 1.4245
2022-07-12 18:14:56 - train: epoch 0160, iter [02400, 05004], lr: 0.010281, loss: 1.4574
2022-07-12 18:15:30 - train: epoch 0160, iter [02500, 05004], lr: 0.010271, loss: 1.5744
2022-07-12 18:16:05 - train: epoch 0160, iter [02600, 05004], lr: 0.010262, loss: 1.5352
2022-07-12 18:16:39 - train: epoch 0160, iter [02700, 05004], lr: 0.010252, loss: 1.6824
2022-07-12 18:17:13 - train: epoch 0160, iter [02800, 05004], lr: 0.010242, loss: 1.6979
2022-07-12 18:17:48 - train: epoch 0160, iter [02900, 05004], lr: 0.010232, loss: 1.6209
2022-07-12 18:18:22 - train: epoch 0160, iter [03000, 05004], lr: 0.010222, loss: 1.9676
2022-07-12 18:18:57 - train: epoch 0160, iter [03100, 05004], lr: 0.010213, loss: 1.7969
2022-07-12 18:19:32 - train: epoch 0160, iter [03200, 05004], lr: 0.010203, loss: 1.5573
2022-07-12 18:20:05 - train: epoch 0160, iter [03300, 05004], lr: 0.010193, loss: 1.6218
2022-07-12 18:20:39 - train: epoch 0160, iter [03400, 05004], lr: 0.010184, loss: 1.8709
2022-07-12 18:21:14 - train: epoch 0160, iter [03500, 05004], lr: 0.010174, loss: 1.5633
2022-07-12 18:21:48 - train: epoch 0160, iter [03600, 05004], lr: 0.010164, loss: 1.3224
2022-07-12 18:22:22 - train: epoch 0160, iter [03700, 05004], lr: 0.010154, loss: 1.6598
2022-07-12 18:22:58 - train: epoch 0160, iter [03800, 05004], lr: 0.010145, loss: 1.7327
2022-07-12 18:23:31 - train: epoch 0160, iter [03900, 05004], lr: 0.010135, loss: 1.8651
2022-07-12 18:24:07 - train: epoch 0160, iter [04000, 05004], lr: 0.010125, loss: 1.7686
2022-07-12 18:24:40 - train: epoch 0160, iter [04100, 05004], lr: 0.010115, loss: 1.7134
2022-07-12 18:25:15 - train: epoch 0160, iter [04200, 05004], lr: 0.010106, loss: 1.6098
2022-07-12 18:25:49 - train: epoch 0160, iter [04300, 05004], lr: 0.010096, loss: 1.4447
2022-07-12 18:26:23 - train: epoch 0160, iter [04400, 05004], lr: 0.010086, loss: 1.7195
2022-07-12 18:26:58 - train: epoch 0160, iter [04500, 05004], lr: 0.010077, loss: 2.0112
2022-07-12 18:27:32 - train: epoch 0160, iter [04600, 05004], lr: 0.010067, loss: 1.6320
2022-07-12 18:28:06 - train: epoch 0160, iter [04700, 05004], lr: 0.010057, loss: 1.5991
2022-07-12 18:28:41 - train: epoch 0160, iter [04800, 05004], lr: 0.010048, loss: 1.6400
2022-07-12 18:29:16 - train: epoch 0160, iter [04900, 05004], lr: 0.010038, loss: 1.4525
2022-07-12 18:29:48 - train: epoch 0160, iter [05000, 05004], lr: 0.010028, loss: 1.4429
2022-07-12 18:29:49 - train: epoch 160, train_loss: 1.6574
2022-07-12 18:31:04 - eval: epoch: 160, acc1: 72.266%, acc5: 90.984%, test_loss: 1.1180, per_image_load_time: 0.779ms, per_image_inference_time: 0.457ms
2022-07-12 18:31:04 - until epoch: 160, best_acc1: 72.402%
2022-07-12 18:31:04 - epoch 161 lr: 0.010028
2022-07-12 18:31:44 - train: epoch 0161, iter [00100, 05004], lr: 0.010018, loss: 1.5304
2022-07-12 18:32:18 - train: epoch 0161, iter [00200, 05004], lr: 0.010009, loss: 1.7575
2022-07-12 18:32:52 - train: epoch 0161, iter [00300, 05004], lr: 0.009999, loss: 1.6747
2022-07-12 18:33:27 - train: epoch 0161, iter [00400, 05004], lr: 0.009989, loss: 1.4071
2022-07-12 18:34:01 - train: epoch 0161, iter [00500, 05004], lr: 0.009980, loss: 1.5122
2022-07-12 18:34:35 - train: epoch 0161, iter [00600, 05004], lr: 0.009970, loss: 1.6371
2022-07-12 18:35:09 - train: epoch 0161, iter [00700, 05004], lr: 0.009960, loss: 1.8331
2022-07-12 18:35:42 - train: epoch 0161, iter [00800, 05004], lr: 0.009951, loss: 1.6661
2022-07-12 18:36:16 - train: epoch 0161, iter [00900, 05004], lr: 0.009941, loss: 1.1314
2022-07-12 18:36:49 - train: epoch 0161, iter [01000, 05004], lr: 0.009931, loss: 1.5045
2022-07-12 18:37:23 - train: epoch 0161, iter [01100, 05004], lr: 0.009922, loss: 1.7452
2022-07-12 18:37:56 - train: epoch 0161, iter [01200, 05004], lr: 0.009912, loss: 1.5406
2022-07-12 18:38:30 - train: epoch 0161, iter [01300, 05004], lr: 0.009902, loss: 1.7611
2022-07-12 18:39:04 - train: epoch 0161, iter [01400, 05004], lr: 0.009893, loss: 1.8874
2022-07-12 18:39:38 - train: epoch 0161, iter [01500, 05004], lr: 0.009883, loss: 1.8285
2022-07-12 18:40:11 - train: epoch 0161, iter [01600, 05004], lr: 0.009874, loss: 1.4177
2022-07-12 18:40:45 - train: epoch 0161, iter [01700, 05004], lr: 0.009864, loss: 1.9866
2022-07-12 18:41:18 - train: epoch 0161, iter [01800, 05004], lr: 0.009854, loss: 1.6296
2022-07-12 18:41:52 - train: epoch 0161, iter [01900, 05004], lr: 0.009845, loss: 1.7730
2022-07-12 18:42:26 - train: epoch 0161, iter [02000, 05004], lr: 0.009835, loss: 1.5568
2022-07-12 18:43:00 - train: epoch 0161, iter [02100, 05004], lr: 0.009826, loss: 1.8241
2022-07-12 18:43:34 - train: epoch 0161, iter [02200, 05004], lr: 0.009816, loss: 1.3863
2022-07-12 18:44:08 - train: epoch 0161, iter [02300, 05004], lr: 0.009807, loss: 1.6087
2022-07-12 18:44:42 - train: epoch 0161, iter [02400, 05004], lr: 0.009797, loss: 1.4826
2022-07-12 18:45:16 - train: epoch 0161, iter [02500, 05004], lr: 0.009787, loss: 1.7780
2022-07-12 18:45:50 - train: epoch 0161, iter [02600, 05004], lr: 0.009778, loss: 1.5419
2022-07-12 18:46:23 - train: epoch 0161, iter [02700, 05004], lr: 0.009768, loss: 1.6489
2022-07-12 18:46:57 - train: epoch 0161, iter [02800, 05004], lr: 0.009759, loss: 1.6034
2022-07-12 18:47:31 - train: epoch 0161, iter [02900, 05004], lr: 0.009749, loss: 1.6274
2022-07-12 18:48:05 - train: epoch 0161, iter [03000, 05004], lr: 0.009740, loss: 1.5227
2022-07-12 18:48:39 - train: epoch 0161, iter [03100, 05004], lr: 0.009730, loss: 1.6382
2022-07-12 18:49:13 - train: epoch 0161, iter [03200, 05004], lr: 0.009721, loss: 1.6440
2022-07-12 18:49:47 - train: epoch 0161, iter [03300, 05004], lr: 0.009711, loss: 1.6296
2022-07-12 18:50:22 - train: epoch 0161, iter [03400, 05004], lr: 0.009701, loss: 1.8331
2022-07-12 18:50:56 - train: epoch 0161, iter [03500, 05004], lr: 0.009692, loss: 1.6698
2022-07-12 18:51:30 - train: epoch 0161, iter [03600, 05004], lr: 0.009682, loss: 2.0609
2022-07-12 18:52:04 - train: epoch 0161, iter [03700, 05004], lr: 0.009673, loss: 1.4779
2022-07-12 18:52:38 - train: epoch 0161, iter [03800, 05004], lr: 0.009663, loss: 1.7638
2022-07-12 18:53:12 - train: epoch 0161, iter [03900, 05004], lr: 0.009654, loss: 1.5647
2022-07-12 18:53:47 - train: epoch 0161, iter [04000, 05004], lr: 0.009644, loss: 1.7423
2022-07-12 18:54:21 - train: epoch 0161, iter [04100, 05004], lr: 0.009635, loss: 1.4920
2022-07-12 18:54:55 - train: epoch 0161, iter [04200, 05004], lr: 0.009625, loss: 1.7291
2022-07-12 18:55:29 - train: epoch 0161, iter [04300, 05004], lr: 0.009616, loss: 1.5409
2022-07-12 18:56:03 - train: epoch 0161, iter [04400, 05004], lr: 0.009606, loss: 1.4963
2022-07-12 18:56:37 - train: epoch 0161, iter [04500, 05004], lr: 0.009597, loss: 1.8071
2022-07-12 18:57:12 - train: epoch 0161, iter [04600, 05004], lr: 0.009587, loss: 1.7508
2022-07-12 18:57:46 - train: epoch 0161, iter [04700, 05004], lr: 0.009578, loss: 1.6708
2022-07-12 18:58:20 - train: epoch 0161, iter [04800, 05004], lr: 0.009568, loss: 1.7120
2022-07-12 18:58:53 - train: epoch 0161, iter [04900, 05004], lr: 0.009559, loss: 1.5645
2022-07-12 18:59:26 - train: epoch 0161, iter [05000, 05004], lr: 0.009550, loss: 1.5381
2022-07-12 18:59:27 - train: epoch 161, train_loss: 1.6431
2022-07-12 19:00:40 - eval: epoch: 161, acc1: 72.890%, acc5: 91.238%, test_loss: 1.0952, per_image_load_time: 2.406ms, per_image_inference_time: 0.452ms
2022-07-12 19:00:41 - until epoch: 161, best_acc1: 72.890%
2022-07-12 19:00:41 - epoch 162 lr: 0.009549
2022-07-12 19:01:20 - train: epoch 0162, iter [00100, 05004], lr: 0.009540, loss: 1.5826
2022-07-12 19:01:54 - train: epoch 0162, iter [00200, 05004], lr: 0.009530, loss: 1.6460
2022-07-12 19:02:27 - train: epoch 0162, iter [00300, 05004], lr: 0.009521, loss: 1.4719
2022-07-12 19:03:01 - train: epoch 0162, iter [00400, 05004], lr: 0.009511, loss: 1.6657
2022-07-12 19:03:35 - train: epoch 0162, iter [00500, 05004], lr: 0.009502, loss: 1.7163
2022-07-12 19:04:09 - train: epoch 0162, iter [00600, 05004], lr: 0.009492, loss: 1.6264
2022-07-12 19:04:43 - train: epoch 0162, iter [00700, 05004], lr: 0.009483, loss: 1.8924
2022-07-12 19:05:17 - train: epoch 0162, iter [00800, 05004], lr: 0.009474, loss: 1.6300
2022-07-12 19:05:51 - train: epoch 0162, iter [00900, 05004], lr: 0.009464, loss: 1.6701
2022-07-12 19:06:25 - train: epoch 0162, iter [01000, 05004], lr: 0.009455, loss: 1.7080
2022-07-12 19:07:00 - train: epoch 0162, iter [01100, 05004], lr: 0.009445, loss: 1.7620
2022-07-12 19:07:33 - train: epoch 0162, iter [01200, 05004], lr: 0.009436, loss: 1.4557
2022-07-12 19:08:07 - train: epoch 0162, iter [01300, 05004], lr: 0.009426, loss: 1.6101
2022-07-12 19:08:41 - train: epoch 0162, iter [01400, 05004], lr: 0.009417, loss: 1.7072
2022-07-12 19:09:16 - train: epoch 0162, iter [01500, 05004], lr: 0.009408, loss: 2.0009
2022-07-12 19:09:50 - train: epoch 0162, iter [01600, 05004], lr: 0.009398, loss: 1.7204
2022-07-12 19:10:23 - train: epoch 0162, iter [01700, 05004], lr: 0.009389, loss: 1.4789
2022-07-12 19:10:57 - train: epoch 0162, iter [01800, 05004], lr: 0.009380, loss: 1.6156
2022-07-12 19:11:31 - train: epoch 0162, iter [01900, 05004], lr: 0.009370, loss: 1.8100
2022-07-12 19:12:05 - train: epoch 0162, iter [02000, 05004], lr: 0.009361, loss: 1.6233
2022-07-12 19:12:39 - train: epoch 0162, iter [02100, 05004], lr: 0.009351, loss: 1.4494
2022-07-12 19:13:13 - train: epoch 0162, iter [02200, 05004], lr: 0.009342, loss: 1.6500
2022-07-12 19:13:48 - train: epoch 0162, iter [02300, 05004], lr: 0.009333, loss: 1.8563
2022-07-12 19:14:23 - train: epoch 0162, iter [02400, 05004], lr: 0.009323, loss: 1.6890
2022-07-12 19:14:57 - train: epoch 0162, iter [02500, 05004], lr: 0.009314, loss: 1.5655
2022-07-12 19:15:32 - train: epoch 0162, iter [02600, 05004], lr: 0.009305, loss: 1.5219
2022-07-12 19:16:06 - train: epoch 0162, iter [02700, 05004], lr: 0.009295, loss: 1.6339
2022-07-12 19:16:40 - train: epoch 0162, iter [02800, 05004], lr: 0.009286, loss: 1.7595
2022-07-12 19:17:15 - train: epoch 0162, iter [02900, 05004], lr: 0.009277, loss: 1.5462
2022-07-12 19:17:49 - train: epoch 0162, iter [03000, 05004], lr: 0.009267, loss: 1.5249
2022-07-12 19:18:24 - train: epoch 0162, iter [03100, 05004], lr: 0.009258, loss: 1.5929
2022-07-12 19:18:58 - train: epoch 0162, iter [03200, 05004], lr: 0.009249, loss: 1.4442
2022-07-12 19:19:33 - train: epoch 0162, iter [03300, 05004], lr: 0.009239, loss: 1.7249
2022-07-12 19:20:08 - train: epoch 0162, iter [03400, 05004], lr: 0.009230, loss: 1.7910
2022-07-12 19:20:41 - train: epoch 0162, iter [03500, 05004], lr: 0.009221, loss: 1.6656
2022-07-12 19:21:17 - train: epoch 0162, iter [03600, 05004], lr: 0.009211, loss: 1.9123
2022-07-12 19:21:51 - train: epoch 0162, iter [03700, 05004], lr: 0.009202, loss: 1.4184
2022-07-12 19:22:26 - train: epoch 0162, iter [03800, 05004], lr: 0.009193, loss: 1.3166
2022-07-12 19:23:00 - train: epoch 0162, iter [03900, 05004], lr: 0.009183, loss: 1.7862
2022-07-12 19:23:35 - train: epoch 0162, iter [04000, 05004], lr: 0.009174, loss: 1.5531
2022-07-12 19:24:09 - train: epoch 0162, iter [04100, 05004], lr: 0.009165, loss: 1.7735
2022-07-12 19:24:43 - train: epoch 0162, iter [04200, 05004], lr: 0.009155, loss: 2.0023
2022-07-12 19:25:18 - train: epoch 0162, iter [04300, 05004], lr: 0.009146, loss: 1.8161
2022-07-12 19:25:53 - train: epoch 0162, iter [04400, 05004], lr: 0.009137, loss: 1.7484
2022-07-12 19:26:28 - train: epoch 0162, iter [04500, 05004], lr: 0.009128, loss: 1.8367
2022-07-12 19:27:02 - train: epoch 0162, iter [04600, 05004], lr: 0.009118, loss: 1.6927
2022-07-12 19:27:36 - train: epoch 0162, iter [04700, 05004], lr: 0.009109, loss: 1.6284
2022-07-12 19:28:12 - train: epoch 0162, iter [04800, 05004], lr: 0.009100, loss: 1.4993
2022-07-12 19:28:46 - train: epoch 0162, iter [04900, 05004], lr: 0.009091, loss: 1.8439
2022-07-12 19:29:19 - train: epoch 0162, iter [05000, 05004], lr: 0.009081, loss: 1.5558
2022-07-12 19:29:20 - train: epoch 162, train_loss: 1.6338
2022-07-12 19:30:34 - eval: epoch: 162, acc1: 73.170%, acc5: 91.640%, test_loss: 1.0732, per_image_load_time: 1.216ms, per_image_inference_time: 0.479ms
2022-07-12 19:30:35 - until epoch: 162, best_acc1: 73.170%
2022-07-12 19:30:35 - epoch 163 lr: 0.009081
2022-07-12 19:31:14 - train: epoch 0163, iter [00100, 05004], lr: 0.009072, loss: 1.7866
2022-07-12 19:31:48 - train: epoch 0163, iter [00200, 05004], lr: 0.009062, loss: 1.8256
2022-07-12 19:32:23 - train: epoch 0163, iter [00300, 05004], lr: 0.009053, loss: 1.4723
2022-07-12 19:32:57 - train: epoch 0163, iter [00400, 05004], lr: 0.009044, loss: 1.9512
2022-07-12 19:33:32 - train: epoch 0163, iter [00500, 05004], lr: 0.009035, loss: 1.4505
2022-07-12 19:34:07 - train: epoch 0163, iter [00600, 05004], lr: 0.009026, loss: 1.6925
2022-07-12 19:34:41 - train: epoch 0163, iter [00700, 05004], lr: 0.009016, loss: 1.5957
2022-07-12 19:35:16 - train: epoch 0163, iter [00800, 05004], lr: 0.009007, loss: 1.4370
2022-07-12 19:35:50 - train: epoch 0163, iter [00900, 05004], lr: 0.008998, loss: 1.7213
2022-07-12 19:36:27 - train: epoch 0163, iter [01000, 05004], lr: 0.008989, loss: 1.5312
2022-07-12 19:37:01 - train: epoch 0163, iter [01100, 05004], lr: 0.008979, loss: 1.6469
2022-07-12 19:37:36 - train: epoch 0163, iter [01200, 05004], lr: 0.008970, loss: 1.5493
2022-07-12 19:38:10 - train: epoch 0163, iter [01300, 05004], lr: 0.008961, loss: 1.5154
2022-07-12 19:38:46 - train: epoch 0163, iter [01400, 05004], lr: 0.008952, loss: 1.5716
2022-07-12 19:39:20 - train: epoch 0163, iter [01500, 05004], lr: 0.008943, loss: 1.8070
2022-07-12 19:39:54 - train: epoch 0163, iter [01600, 05004], lr: 0.008933, loss: 1.5842
2022-07-12 19:40:27 - train: epoch 0163, iter [01700, 05004], lr: 0.008924, loss: 1.2933
2022-07-12 19:41:02 - train: epoch 0163, iter [01800, 05004], lr: 0.008915, loss: 1.6679
2022-07-12 19:41:35 - train: epoch 0163, iter [01900, 05004], lr: 0.008906, loss: 1.7719
2022-07-12 19:42:09 - train: epoch 0163, iter [02000, 05004], lr: 0.008897, loss: 1.3456
2022-07-12 19:42:43 - train: epoch 0163, iter [02100, 05004], lr: 0.008888, loss: 1.6442
2022-07-12 19:43:17 - train: epoch 0163, iter [02200, 05004], lr: 0.008878, loss: 1.5144
2022-07-12 19:43:51 - train: epoch 0163, iter [02300, 05004], lr: 0.008869, loss: 1.3131
2022-07-12 19:44:24 - train: epoch 0163, iter [02400, 05004], lr: 0.008860, loss: 1.5983
2022-07-12 19:44:59 - train: epoch 0163, iter [02500, 05004], lr: 0.008851, loss: 1.4959
2022-07-12 19:45:33 - train: epoch 0163, iter [02600, 05004], lr: 0.008842, loss: 1.6304
2022-07-12 19:46:07 - train: epoch 0163, iter [02700, 05004], lr: 0.008833, loss: 1.4014
2022-07-12 19:46:41 - train: epoch 0163, iter [02800, 05004], lr: 0.008824, loss: 1.7115
2022-07-12 19:47:16 - train: epoch 0163, iter [02900, 05004], lr: 0.008814, loss: 1.5176
2022-07-12 19:47:49 - train: epoch 0163, iter [03000, 05004], lr: 0.008805, loss: 1.6795
2022-07-12 19:48:23 - train: epoch 0163, iter [03100, 05004], lr: 0.008796, loss: 1.4989
2022-07-12 19:48:58 - train: epoch 0163, iter [03200, 05004], lr: 0.008787, loss: 1.7024
2022-07-12 19:49:32 - train: epoch 0163, iter [03300, 05004], lr: 0.008778, loss: 1.5672
2022-07-12 19:50:07 - train: epoch 0163, iter [03400, 05004], lr: 0.008769, loss: 1.7214
2022-07-12 19:50:41 - train: epoch 0163, iter [03500, 05004], lr: 0.008760, loss: 1.7107
2022-07-12 19:51:16 - train: epoch 0163, iter [03600, 05004], lr: 0.008751, loss: 1.6799
2022-07-12 19:51:50 - train: epoch 0163, iter [03700, 05004], lr: 0.008742, loss: 1.7678
2022-07-12 19:52:24 - train: epoch 0163, iter [03800, 05004], lr: 0.008732, loss: 1.3132
2022-07-12 19:52:59 - train: epoch 0163, iter [03900, 05004], lr: 0.008723, loss: 1.6869
2022-07-12 19:53:34 - train: epoch 0163, iter [04000, 05004], lr: 0.008714, loss: 1.7322
2022-07-12 19:54:09 - train: epoch 0163, iter [04100, 05004], lr: 0.008705, loss: 1.5231
2022-07-12 19:54:43 - train: epoch 0163, iter [04200, 05004], lr: 0.008696, loss: 1.6719
2022-07-12 19:55:18 - train: epoch 0163, iter [04300, 05004], lr: 0.008687, loss: 1.5752
2022-07-12 19:55:51 - train: epoch 0163, iter [04400, 05004], lr: 0.008678, loss: 1.4468
2022-07-12 19:56:26 - train: epoch 0163, iter [04500, 05004], lr: 0.008669, loss: 1.5819
2022-07-12 19:57:01 - train: epoch 0163, iter [04600, 05004], lr: 0.008660, loss: 1.5629
2022-07-12 19:57:35 - train: epoch 0163, iter [04700, 05004], lr: 0.008651, loss: 1.7776
2022-07-12 19:58:10 - train: epoch 0163, iter [04800, 05004], lr: 0.008642, loss: 1.8742
2022-07-12 19:58:44 - train: epoch 0163, iter [04900, 05004], lr: 0.008633, loss: 1.9025
2022-07-12 19:59:18 - train: epoch 0163, iter [05000, 05004], lr: 0.008624, loss: 1.7666
2022-07-12 19:59:19 - train: epoch 163, train_loss: 1.6184
2022-07-12 20:00:33 - eval: epoch: 163, acc1: 73.470%, acc5: 91.682%, test_loss: 1.0664, per_image_load_time: 1.990ms, per_image_inference_time: 0.489ms
2022-07-12 20:00:34 - until epoch: 163, best_acc1: 73.470%
2022-07-12 20:00:34 - epoch 164 lr: 0.008623
2022-07-12 20:01:14 - train: epoch 0164, iter [00100, 05004], lr: 0.008614, loss: 1.5159
2022-07-12 20:01:49 - train: epoch 0164, iter [00200, 05004], lr: 0.008605, loss: 1.4364
2022-07-12 20:02:23 - train: epoch 0164, iter [00300, 05004], lr: 0.008596, loss: 1.6697
2022-07-12 20:02:56 - train: epoch 0164, iter [00400, 05004], lr: 0.008587, loss: 1.4842
2022-07-12 20:03:30 - train: epoch 0164, iter [00500, 05004], lr: 0.008578, loss: 1.4430
2022-07-12 20:04:03 - train: epoch 0164, iter [00600, 05004], lr: 0.008569, loss: 1.5641
2022-07-12 20:04:37 - train: epoch 0164, iter [00700, 05004], lr: 0.008560, loss: 1.7570
2022-07-12 20:05:11 - train: epoch 0164, iter [00800, 05004], lr: 0.008551, loss: 1.6741
2022-07-12 20:05:45 - train: epoch 0164, iter [00900, 05004], lr: 0.008542, loss: 1.8195
2022-07-12 20:06:19 - train: epoch 0164, iter [01000, 05004], lr: 0.008533, loss: 1.4585
2022-07-12 20:06:52 - train: epoch 0164, iter [01100, 05004], lr: 0.008524, loss: 1.5969
2022-07-12 20:07:26 - train: epoch 0164, iter [01200, 05004], lr: 0.008515, loss: 1.6405
2022-07-12 20:08:01 - train: epoch 0164, iter [01300, 05004], lr: 0.008506, loss: 1.5600
2022-07-12 20:08:35 - train: epoch 0164, iter [01400, 05004], lr: 0.008497, loss: 1.5225
2022-07-12 20:09:08 - train: epoch 0164, iter [01500, 05004], lr: 0.008488, loss: 1.8225
2022-07-12 20:09:43 - train: epoch 0164, iter [01600, 05004], lr: 0.008479, loss: 1.3786
2022-07-12 20:10:17 - train: epoch 0164, iter [01700, 05004], lr: 0.008470, loss: 1.7594
2022-07-12 20:10:51 - train: epoch 0164, iter [01800, 05004], lr: 0.008461, loss: 1.2407
2022-07-12 20:11:25 - train: epoch 0164, iter [01900, 05004], lr: 0.008452, loss: 1.5135
2022-07-12 20:11:59 - train: epoch 0164, iter [02000, 05004], lr: 0.008443, loss: 1.2654
2022-07-12 20:12:33 - train: epoch 0164, iter [02100, 05004], lr: 0.008435, loss: 1.7579
2022-07-12 20:13:07 - train: epoch 0164, iter [02200, 05004], lr: 0.008426, loss: 1.4665
2022-07-12 20:13:41 - train: epoch 0164, iter [02300, 05004], lr: 0.008417, loss: 1.7514
2022-07-12 20:14:15 - train: epoch 0164, iter [02400, 05004], lr: 0.008408, loss: 1.5698
2022-07-12 20:14:49 - train: epoch 0164, iter [02500, 05004], lr: 0.008399, loss: 1.7213
2022-07-12 20:15:23 - train: epoch 0164, iter [02600, 05004], lr: 0.008390, loss: 1.6246
2022-07-12 20:15:57 - train: epoch 0164, iter [02700, 05004], lr: 0.008381, loss: 1.7136
2022-07-12 20:16:30 - train: epoch 0164, iter [02800, 05004], lr: 0.008372, loss: 1.6950
2022-07-12 20:17:05 - train: epoch 0164, iter [02900, 05004], lr: 0.008363, loss: 1.5594
2022-07-12 20:17:39 - train: epoch 0164, iter [03000, 05004], lr: 0.008354, loss: 1.8011
2022-07-12 20:18:13 - train: epoch 0164, iter [03100, 05004], lr: 0.008345, loss: 1.7708
2022-07-12 20:18:47 - train: epoch 0164, iter [03200, 05004], lr: 0.008336, loss: 1.6867
2022-07-12 20:19:22 - train: epoch 0164, iter [03300, 05004], lr: 0.008327, loss: 1.7097
2022-07-12 20:19:56 - train: epoch 0164, iter [03400, 05004], lr: 0.008319, loss: 1.6699
2022-07-12 20:20:32 - train: epoch 0164, iter [03500, 05004], lr: 0.008310, loss: 1.5687
2022-07-12 20:21:06 - train: epoch 0164, iter [03600, 05004], lr: 0.008301, loss: 1.4349
2022-07-12 20:21:40 - train: epoch 0164, iter [03700, 05004], lr: 0.008292, loss: 1.7132
2022-07-12 20:22:14 - train: epoch 0164, iter [03800, 05004], lr: 0.008283, loss: 1.4674
2022-07-12 20:22:49 - train: epoch 0164, iter [03900, 05004], lr: 0.008274, loss: 1.5379
2022-07-12 20:23:23 - train: epoch 0164, iter [04000, 05004], lr: 0.008265, loss: 1.4782
2022-07-12 20:23:58 - train: epoch 0164, iter [04100, 05004], lr: 0.008256, loss: 1.5511
2022-07-12 20:24:31 - train: epoch 0164, iter [04200, 05004], lr: 0.008248, loss: 1.7833
2022-07-12 20:25:06 - train: epoch 0164, iter [04300, 05004], lr: 0.008239, loss: 1.6458
2022-07-12 20:25:40 - train: epoch 0164, iter [04400, 05004], lr: 0.008230, loss: 1.3889
2022-07-12 20:26:15 - train: epoch 0164, iter [04500, 05004], lr: 0.008221, loss: 1.7681
2022-07-12 20:26:49 - train: epoch 0164, iter [04600, 05004], lr: 0.008212, loss: 1.4509
2022-07-12 20:27:23 - train: epoch 0164, iter [04700, 05004], lr: 0.008203, loss: 1.6981
2022-07-12 20:27:57 - train: epoch 0164, iter [04800, 05004], lr: 0.008194, loss: 1.5096
2022-07-12 20:28:31 - train: epoch 0164, iter [04900, 05004], lr: 0.008186, loss: 1.8795
2022-07-12 20:29:03 - train: epoch 0164, iter [05000, 05004], lr: 0.008177, loss: 1.4915
2022-07-12 20:29:05 - train: epoch 164, train_loss: 1.6030
2022-07-12 20:30:18 - eval: epoch: 164, acc1: 73.262%, acc5: 91.466%, test_loss: 1.0768, per_image_load_time: 2.398ms, per_image_inference_time: 0.471ms
2022-07-12 20:30:19 - until epoch: 164, best_acc1: 73.470%
2022-07-12 20:30:19 - epoch 165 lr: 0.008176
2022-07-12 20:30:58 - train: epoch 0165, iter [00100, 05004], lr: 0.008168, loss: 1.6230
2022-07-12 20:31:32 - train: epoch 0165, iter [00200, 05004], lr: 0.008159, loss: 1.6285
2022-07-12 20:32:06 - train: epoch 0165, iter [00300, 05004], lr: 0.008150, loss: 1.4000
2022-07-12 20:32:40 - train: epoch 0165, iter [00400, 05004], lr: 0.008141, loss: 1.6440
2022-07-12 20:33:15 - train: epoch 0165, iter [00500, 05004], lr: 0.008132, loss: 1.5581
2022-07-12 20:33:49 - train: epoch 0165, iter [00600, 05004], lr: 0.008124, loss: 1.4097
2022-07-12 20:34:24 - train: epoch 0165, iter [00700, 05004], lr: 0.008115, loss: 1.6040
2022-07-12 20:34:58 - train: epoch 0165, iter [00800, 05004], lr: 0.008106, loss: 1.6054
2022-07-12 20:35:32 - train: epoch 0165, iter [00900, 05004], lr: 0.008097, loss: 1.6738
2022-07-12 20:36:06 - train: epoch 0165, iter [01000, 05004], lr: 0.008088, loss: 1.5035
2022-07-12 20:36:41 - train: epoch 0165, iter [01100, 05004], lr: 0.008080, loss: 1.7483
2022-07-12 20:37:15 - train: epoch 0165, iter [01200, 05004], lr: 0.008071, loss: 1.6380
2022-07-12 20:37:50 - train: epoch 0165, iter [01300, 05004], lr: 0.008062, loss: 1.5217
2022-07-12 20:38:24 - train: epoch 0165, iter [01400, 05004], lr: 0.008053, loss: 1.6346
2022-07-12 20:38:57 - train: epoch 0165, iter [01500, 05004], lr: 0.008045, loss: 1.4879
2022-07-12 20:39:31 - train: epoch 0165, iter [01600, 05004], lr: 0.008036, loss: 1.6169
2022-07-12 20:40:06 - train: epoch 0165, iter [01700, 05004], lr: 0.008027, loss: 1.7546
2022-07-12 20:40:40 - train: epoch 0165, iter [01800, 05004], lr: 0.008018, loss: 1.5256
2022-07-12 20:41:14 - train: epoch 0165, iter [01900, 05004], lr: 0.008010, loss: 1.3790
2022-07-12 20:41:48 - train: epoch 0165, iter [02000, 05004], lr: 0.008001, loss: 1.6665
2022-07-12 20:42:22 - train: epoch 0165, iter [02100, 05004], lr: 0.007992, loss: 1.4336
2022-07-12 20:42:55 - train: epoch 0165, iter [02200, 05004], lr: 0.007983, loss: 1.5692
2022-07-12 20:43:28 - train: epoch 0165, iter [02300, 05004], lr: 0.007975, loss: 1.6888
2022-07-12 20:44:02 - train: epoch 0165, iter [02400, 05004], lr: 0.007966, loss: 1.6383
2022-07-12 20:44:36 - train: epoch 0165, iter [02500, 05004], lr: 0.007957, loss: 1.4345
2022-07-12 20:45:09 - train: epoch 0165, iter [02600, 05004], lr: 0.007949, loss: 1.5940
2022-07-12 20:45:42 - train: epoch 0165, iter [02700, 05004], lr: 0.007940, loss: 1.5755
2022-07-12 20:46:15 - train: epoch 0165, iter [02800, 05004], lr: 0.007931, loss: 1.7145
2022-07-12 20:46:49 - train: epoch 0165, iter [02900, 05004], lr: 0.007922, loss: 1.7280
2022-07-12 20:47:22 - train: epoch 0165, iter [03000, 05004], lr: 0.007914, loss: 1.7595
2022-07-12 20:47:56 - train: epoch 0165, iter [03100, 05004], lr: 0.007905, loss: 1.2142
2022-07-12 20:48:29 - train: epoch 0165, iter [03200, 05004], lr: 0.007896, loss: 1.6065
2022-07-12 20:49:03 - train: epoch 0165, iter [03300, 05004], lr: 0.007888, loss: 1.5285
2022-07-12 20:49:37 - train: epoch 0165, iter [03400, 05004], lr: 0.007879, loss: 1.7778
