2022-07-12 20:50:11 - train: epoch 0165, iter [03500, 05004], lr: 0.007870, loss: 2.0552
2022-07-12 20:50:44 - train: epoch 0165, iter [03600, 05004], lr: 0.007862, loss: 1.8280
2022-07-12 20:51:19 - train: epoch 0165, iter [03700, 05004], lr: 0.007853, loss: 1.3143
2022-07-12 20:51:52 - train: epoch 0165, iter [03800, 05004], lr: 0.007844, loss: 1.7506
2022-07-12 20:52:27 - train: epoch 0165, iter [03900, 05004], lr: 0.007836, loss: 1.6726
2022-07-12 20:53:00 - train: epoch 0165, iter [04000, 05004], lr: 0.007827, loss: 1.5762
2022-07-12 20:53:34 - train: epoch 0165, iter [04100, 05004], lr: 0.007818, loss: 1.5475
2022-07-12 20:54:08 - train: epoch 0165, iter [04200, 05004], lr: 0.007810, loss: 1.8628
2022-07-12 20:54:42 - train: epoch 0165, iter [04300, 05004], lr: 0.007801, loss: 1.5774
2022-07-12 20:55:15 - train: epoch 0165, iter [04400, 05004], lr: 0.007793, loss: 1.4629
2022-07-12 20:55:49 - train: epoch 0165, iter [04500, 05004], lr: 0.007784, loss: 1.5216
2022-07-12 20:56:23 - train: epoch 0165, iter [04600, 05004], lr: 0.007775, loss: 1.5951
2022-07-12 20:56:57 - train: epoch 0165, iter [04700, 05004], lr: 0.007767, loss: 1.5258
2022-07-12 20:57:30 - train: epoch 0165, iter [04800, 05004], lr: 0.007758, loss: 1.3275
2022-07-12 20:58:04 - train: epoch 0165, iter [04900, 05004], lr: 0.007749, loss: 1.4985
2022-07-12 20:58:37 - train: epoch 0165, iter [05000, 05004], lr: 0.007741, loss: 1.6063
2022-07-12 20:58:38 - train: epoch 165, train_loss: 1.5880
2022-07-12 20:59:51 - eval: epoch: 165, acc1: 74.102%, acc5: 91.896%, test_loss: 1.0412, per_image_load_time: 1.745ms, per_image_inference_time: 0.470ms
2022-07-12 20:59:51 - until epoch: 165, best_acc1: 74.102%
2022-07-12 20:59:51 - epoch 166 lr: 0.007740
2022-07-12 21:00:31 - train: epoch 0166, iter [00100, 05004], lr: 0.007732, loss: 1.6381
2022-07-12 21:01:04 - train: epoch 0166, iter [00200, 05004], lr: 0.007723, loss: 1.5376
2022-07-12 21:01:39 - train: epoch 0166, iter [00300, 05004], lr: 0.007715, loss: 1.7136
2022-07-12 21:02:12 - train: epoch 0166, iter [00400, 05004], lr: 0.007706, loss: 1.5836
2022-07-12 21:02:46 - train: epoch 0166, iter [00500, 05004], lr: 0.007698, loss: 1.4476
2022-07-12 21:03:19 - train: epoch 0166, iter [00600, 05004], lr: 0.007689, loss: 1.5964
2022-07-12 21:03:53 - train: epoch 0166, iter [00700, 05004], lr: 0.007680, loss: 1.7208
2022-07-12 21:04:27 - train: epoch 0166, iter [00800, 05004], lr: 0.007672, loss: 1.6228
2022-07-12 21:05:02 - train: epoch 0166, iter [00900, 05004], lr: 0.007663, loss: 1.6002
2022-07-12 21:05:35 - train: epoch 0166, iter [01000, 05004], lr: 0.007655, loss: 1.6761
2022-07-12 21:06:09 - train: epoch 0166, iter [01100, 05004], lr: 0.007646, loss: 1.6751
2022-07-12 21:06:43 - train: epoch 0166, iter [01200, 05004], lr: 0.007638, loss: 1.6392
2022-07-12 21:07:17 - train: epoch 0166, iter [01300, 05004], lr: 0.007629, loss: 1.6629
2022-07-12 21:07:50 - train: epoch 0166, iter [01400, 05004], lr: 0.007620, loss: 1.7486
2022-07-12 21:08:23 - train: epoch 0166, iter [01500, 05004], lr: 0.007612, loss: 1.7244
2022-07-12 21:08:56 - train: epoch 0166, iter [01600, 05004], lr: 0.007603, loss: 1.8221
2022-07-12 21:09:30 - train: epoch 0166, iter [01700, 05004], lr: 0.007595, loss: 1.5732
2022-07-12 21:10:03 - train: epoch 0166, iter [01800, 05004], lr: 0.007586, loss: 1.6860
2022-07-12 21:10:37 - train: epoch 0166, iter [01900, 05004], lr: 0.007578, loss: 1.6964
2022-07-12 21:11:11 - train: epoch 0166, iter [02000, 05004], lr: 0.007569, loss: 1.3426
2022-07-12 21:11:45 - train: epoch 0166, iter [02100, 05004], lr: 0.007561, loss: 1.4248
2022-07-12 21:12:19 - train: epoch 0166, iter [02200, 05004], lr: 0.007552, loss: 1.3672
2022-07-12 21:12:52 - train: epoch 0166, iter [02300, 05004], lr: 0.007544, loss: 1.5832
2022-07-12 21:13:26 - train: epoch 0166, iter [02400, 05004], lr: 0.007535, loss: 1.7809
2022-07-12 21:13:59 - train: epoch 0166, iter [02500, 05004], lr: 0.007527, loss: 1.7810
2022-07-12 21:14:33 - train: epoch 0166, iter [02600, 05004], lr: 0.007518, loss: 1.5017
2022-07-12 21:15:07 - train: epoch 0166, iter [02700, 05004], lr: 0.007510, loss: 1.3689
2022-07-12 21:15:40 - train: epoch 0166, iter [02800, 05004], lr: 0.007501, loss: 1.8445
2022-07-12 21:16:14 - train: epoch 0166, iter [02900, 05004], lr: 0.007493, loss: 1.6161
2022-07-12 21:16:48 - train: epoch 0166, iter [03000, 05004], lr: 0.007484, loss: 1.7069
2022-07-12 21:17:22 - train: epoch 0166, iter [03100, 05004], lr: 0.007476, loss: 1.4850
2022-07-12 21:17:57 - train: epoch 0166, iter [03200, 05004], lr: 0.007467, loss: 1.5239
2022-07-12 21:18:30 - train: epoch 0166, iter [03300, 05004], lr: 0.007459, loss: 1.4519
2022-07-12 21:19:05 - train: epoch 0166, iter [03400, 05004], lr: 0.007451, loss: 1.6838
2022-07-12 21:19:39 - train: epoch 0166, iter [03500, 05004], lr: 0.007442, loss: 1.8814
2022-07-12 21:20:12 - train: epoch 0166, iter [03600, 05004], lr: 0.007434, loss: 1.5258
2022-07-12 21:20:46 - train: epoch 0166, iter [03700, 05004], lr: 0.007425, loss: 1.6233
2022-07-12 21:21:20 - train: epoch 0166, iter [03800, 05004], lr: 0.007417, loss: 1.3203
2022-07-12 21:21:54 - train: epoch 0166, iter [03900, 05004], lr: 0.007408, loss: 1.5308
2022-07-12 21:22:28 - train: epoch 0166, iter [04000, 05004], lr: 0.007400, loss: 1.5320
2022-07-12 21:23:03 - train: epoch 0166, iter [04100, 05004], lr: 0.007391, loss: 1.4972
2022-07-12 21:23:38 - train: epoch 0166, iter [04200, 05004], lr: 0.007383, loss: 1.7598
2022-07-12 21:24:12 - train: epoch 0166, iter [04300, 05004], lr: 0.007375, loss: 1.5781
2022-07-12 21:24:46 - train: epoch 0166, iter [04400, 05004], lr: 0.007366, loss: 1.6508
2022-07-12 21:25:21 - train: epoch 0166, iter [04500, 05004], lr: 0.007358, loss: 1.5009
2022-07-12 21:25:55 - train: epoch 0166, iter [04600, 05004], lr: 0.007349, loss: 1.5168
2022-07-12 21:26:30 - train: epoch 0166, iter [04700, 05004], lr: 0.007341, loss: 1.7938
2022-07-12 21:27:03 - train: epoch 0166, iter [04800, 05004], lr: 0.007333, loss: 1.5882
2022-07-12 21:27:38 - train: epoch 0166, iter [04900, 05004], lr: 0.007324, loss: 1.5861
2022-07-12 21:28:11 - train: epoch 0166, iter [05000, 05004], lr: 0.007316, loss: 1.6736
2022-07-12 21:28:12 - train: epoch 166, train_loss: 1.5793
2022-07-12 21:29:26 - eval: epoch: 166, acc1: 74.166%, acc5: 91.960%, test_loss: 1.0389, per_image_load_time: 2.035ms, per_image_inference_time: 0.478ms
2022-07-12 21:29:27 - until epoch: 166, best_acc1: 74.166%
2022-07-12 21:29:27 - epoch 167 lr: 0.007315
2022-07-12 21:30:07 - train: epoch 0167, iter [00100, 05004], lr: 0.007307, loss: 1.5994
2022-07-12 21:30:41 - train: epoch 0167, iter [00200, 05004], lr: 0.007299, loss: 1.4234
2022-07-12 21:31:15 - train: epoch 0167, iter [00300, 05004], lr: 0.007290, loss: 1.4780
2022-07-12 21:31:51 - train: epoch 0167, iter [00400, 05004], lr: 0.007282, loss: 1.4470
2022-07-12 21:32:26 - train: epoch 0167, iter [00500, 05004], lr: 0.007274, loss: 1.4866
2022-07-12 21:33:01 - train: epoch 0167, iter [00600, 05004], lr: 0.007265, loss: 1.5591
2022-07-12 21:33:35 - train: epoch 0167, iter [00700, 05004], lr: 0.007257, loss: 1.3329
2022-07-12 21:34:09 - train: epoch 0167, iter [00800, 05004], lr: 0.007249, loss: 1.6164
2022-07-12 21:34:45 - train: epoch 0167, iter [00900, 05004], lr: 0.007240, loss: 1.6656
2022-07-12 21:35:19 - train: epoch 0167, iter [01000, 05004], lr: 0.007232, loss: 1.4003
2022-07-12 21:35:54 - train: epoch 0167, iter [01100, 05004], lr: 0.007224, loss: 1.3990
2022-07-12 21:36:28 - train: epoch 0167, iter [01200, 05004], lr: 0.007215, loss: 1.5232
2022-07-12 21:37:03 - train: epoch 0167, iter [01300, 05004], lr: 0.007207, loss: 1.6934
2022-07-12 21:37:37 - train: epoch 0167, iter [01400, 05004], lr: 0.007199, loss: 1.2459
2022-07-12 21:38:12 - train: epoch 0167, iter [01500, 05004], lr: 0.007190, loss: 1.4420
2022-07-12 21:38:46 - train: epoch 0167, iter [01600, 05004], lr: 0.007182, loss: 1.4203
2022-07-12 21:39:21 - train: epoch 0167, iter [01700, 05004], lr: 0.007174, loss: 1.6354
2022-07-12 21:39:56 - train: epoch 0167, iter [01800, 05004], lr: 0.007165, loss: 1.4679
2022-07-12 21:40:31 - train: epoch 0167, iter [01900, 05004], lr: 0.007157, loss: 1.6683
2022-07-12 21:41:06 - train: epoch 0167, iter [02000, 05004], lr: 0.007149, loss: 1.6652
2022-07-12 21:41:40 - train: epoch 0167, iter [02100, 05004], lr: 0.007140, loss: 1.5499
2022-07-12 21:42:15 - train: epoch 0167, iter [02200, 05004], lr: 0.007132, loss: 1.6841
2022-07-12 21:42:50 - train: epoch 0167, iter [02300, 05004], lr: 0.007124, loss: 1.6357
2022-07-12 21:43:24 - train: epoch 0167, iter [02400, 05004], lr: 0.007116, loss: 1.4909
2022-07-12 21:43:59 - train: epoch 0167, iter [02500, 05004], lr: 0.007107, loss: 1.7323
2022-07-12 21:44:34 - train: epoch 0167, iter [02600, 05004], lr: 0.007099, loss: 1.4029
2022-07-12 21:45:09 - train: epoch 0167, iter [02700, 05004], lr: 0.007091, loss: 1.3896
2022-07-12 21:45:44 - train: epoch 0167, iter [02800, 05004], lr: 0.007082, loss: 1.4927
2022-07-12 21:46:18 - train: epoch 0167, iter [02900, 05004], lr: 0.007074, loss: 1.4815
2022-07-12 21:46:54 - train: epoch 0167, iter [03000, 05004], lr: 0.007066, loss: 1.4721
2022-07-12 21:47:28 - train: epoch 0167, iter [03100, 05004], lr: 0.007058, loss: 1.5047
2022-07-12 21:48:03 - train: epoch 0167, iter [03200, 05004], lr: 0.007049, loss: 1.3892
2022-07-12 21:48:37 - train: epoch 0167, iter [03300, 05004], lr: 0.007041, loss: 1.5481
2022-07-12 21:49:12 - train: epoch 0167, iter [03400, 05004], lr: 0.007033, loss: 1.2233
2022-07-12 21:49:47 - train: epoch 0167, iter [03500, 05004], lr: 0.007025, loss: 1.5199
2022-07-12 21:50:22 - train: epoch 0167, iter [03600, 05004], lr: 0.007017, loss: 1.3557
2022-07-12 21:50:56 - train: epoch 0167, iter [03700, 05004], lr: 0.007008, loss: 1.5919
2022-07-12 21:51:31 - train: epoch 0167, iter [03800, 05004], lr: 0.007000, loss: 1.5614
2022-07-12 21:52:06 - train: epoch 0167, iter [03900, 05004], lr: 0.006992, loss: 1.8537
2022-07-12 21:52:41 - train: epoch 0167, iter [04000, 05004], lr: 0.006984, loss: 1.7611
2022-07-12 21:53:16 - train: epoch 0167, iter [04100, 05004], lr: 0.006975, loss: 1.5526
2022-07-12 21:53:51 - train: epoch 0167, iter [04200, 05004], lr: 0.006967, loss: 1.6231
2022-07-12 21:54:25 - train: epoch 0167, iter [04300, 05004], lr: 0.006959, loss: 1.4620
2022-07-12 21:54:59 - train: epoch 0167, iter [04400, 05004], lr: 0.006951, loss: 1.4112
2022-07-12 21:55:33 - train: epoch 0167, iter [04500, 05004], lr: 0.006943, loss: 1.4253
2022-07-12 21:56:07 - train: epoch 0167, iter [04600, 05004], lr: 0.006935, loss: 1.7064
2022-07-12 21:56:41 - train: epoch 0167, iter [04700, 05004], lr: 0.006926, loss: 1.6857
2022-07-12 21:57:15 - train: epoch 0167, iter [04800, 05004], lr: 0.006918, loss: 1.6738
2022-07-12 21:57:50 - train: epoch 0167, iter [04900, 05004], lr: 0.006910, loss: 1.3703
2022-07-12 21:58:23 - train: epoch 0167, iter [05000, 05004], lr: 0.006902, loss: 1.6668
2022-07-12 21:58:24 - train: epoch 167, train_loss: 1.5635
2022-07-12 21:59:38 - eval: epoch: 167, acc1: 74.090%, acc5: 92.000%, test_loss: 1.0380, per_image_load_time: 1.210ms, per_image_inference_time: 0.450ms
2022-07-12 21:59:38 - until epoch: 167, best_acc1: 74.166%
2022-07-12 21:59:38 - epoch 168 lr: 0.006901
2022-07-12 22:00:18 - train: epoch 0168, iter [00100, 05004], lr: 0.006893, loss: 1.3457
2022-07-12 22:00:52 - train: epoch 0168, iter [00200, 05004], lr: 0.006885, loss: 1.4245
2022-07-12 22:01:27 - train: epoch 0168, iter [00300, 05004], lr: 0.006877, loss: 1.6353
2022-07-12 22:02:02 - train: epoch 0168, iter [00400, 05004], lr: 0.006869, loss: 1.4138
2022-07-12 22:02:36 - train: epoch 0168, iter [00500, 05004], lr: 0.006861, loss: 1.5291
2022-07-12 22:03:11 - train: epoch 0168, iter [00600, 05004], lr: 0.006853, loss: 1.7076
2022-07-12 22:03:44 - train: epoch 0168, iter [00700, 05004], lr: 0.006844, loss: 1.6591
2022-07-12 22:04:20 - train: epoch 0168, iter [00800, 05004], lr: 0.006836, loss: 1.8042
2022-07-12 22:04:54 - train: epoch 0168, iter [00900, 05004], lr: 0.006828, loss: 1.6053
2022-07-12 22:05:30 - train: epoch 0168, iter [01000, 05004], lr: 0.006820, loss: 1.3377
2022-07-12 22:06:04 - train: epoch 0168, iter [01100, 05004], lr: 0.006812, loss: 1.4337
2022-07-12 22:06:39 - train: epoch 0168, iter [01200, 05004], lr: 0.006804, loss: 1.4359
2022-07-12 22:07:13 - train: epoch 0168, iter [01300, 05004], lr: 0.006796, loss: 1.5306
2022-07-12 22:07:48 - train: epoch 0168, iter [01400, 05004], lr: 0.006788, loss: 1.6216
2022-07-12 22:08:23 - train: epoch 0168, iter [01500, 05004], lr: 0.006780, loss: 1.4155
2022-07-12 22:08:58 - train: epoch 0168, iter [01600, 05004], lr: 0.006772, loss: 1.4210
2022-07-12 22:09:32 - train: epoch 0168, iter [01700, 05004], lr: 0.006763, loss: 1.4707
2022-07-12 22:10:08 - train: epoch 0168, iter [01800, 05004], lr: 0.006755, loss: 1.7795
2022-07-12 22:10:41 - train: epoch 0168, iter [01900, 05004], lr: 0.006747, loss: 1.8626
2022-07-12 22:11:17 - train: epoch 0168, iter [02000, 05004], lr: 0.006739, loss: 1.5699
2022-07-12 22:11:51 - train: epoch 0168, iter [02100, 05004], lr: 0.006731, loss: 1.5295
2022-07-12 22:12:26 - train: epoch 0168, iter [02200, 05004], lr: 0.006723, loss: 1.4061
2022-07-12 22:13:00 - train: epoch 0168, iter [02300, 05004], lr: 0.006715, loss: 1.4305
2022-07-12 22:13:35 - train: epoch 0168, iter [02400, 05004], lr: 0.006707, loss: 1.5442
2022-07-12 22:14:09 - train: epoch 0168, iter [02500, 05004], lr: 0.006699, loss: 1.4763
2022-07-12 22:14:44 - train: epoch 0168, iter [02600, 05004], lr: 0.006691, loss: 1.3642
2022-07-12 22:15:18 - train: epoch 0168, iter [02700, 05004], lr: 0.006683, loss: 1.4503
2022-07-12 22:15:53 - train: epoch 0168, iter [02800, 05004], lr: 0.006675, loss: 1.5816
2022-07-12 22:16:27 - train: epoch 0168, iter [02900, 05004], lr: 0.006667, loss: 1.5037
2022-07-12 22:17:01 - train: epoch 0168, iter [03000, 05004], lr: 0.006659, loss: 1.5732
2022-07-12 22:17:35 - train: epoch 0168, iter [03100, 05004], lr: 0.006651, loss: 1.3700
2022-07-12 22:18:09 - train: epoch 0168, iter [03200, 05004], lr: 0.006643, loss: 1.3626
2022-07-12 22:18:43 - train: epoch 0168, iter [03300, 05004], lr: 0.006635, loss: 1.5532
2022-07-12 22:19:16 - train: epoch 0168, iter [03400, 05004], lr: 0.006627, loss: 1.4999
2022-07-12 22:19:49 - train: epoch 0168, iter [03500, 05004], lr: 0.006619, loss: 1.5922
2022-07-12 22:20:24 - train: epoch 0168, iter [03600, 05004], lr: 0.006611, loss: 1.8334
2022-07-12 22:20:58 - train: epoch 0168, iter [03700, 05004], lr: 0.006603, loss: 1.2148
2022-07-12 22:21:32 - train: epoch 0168, iter [03800, 05004], lr: 0.006595, loss: 1.6984
2022-07-12 22:22:06 - train: epoch 0168, iter [03900, 05004], lr: 0.006587, loss: 1.6945
2022-07-12 22:22:39 - train: epoch 0168, iter [04000, 05004], lr: 0.006579, loss: 1.6373
2022-07-12 22:23:14 - train: epoch 0168, iter [04100, 05004], lr: 0.006571, loss: 1.4597
2022-07-12 22:23:47 - train: epoch 0168, iter [04200, 05004], lr: 0.006563, loss: 1.8065
2022-07-12 22:24:21 - train: epoch 0168, iter [04300, 05004], lr: 0.006555, loss: 1.4397
2022-07-12 22:24:55 - train: epoch 0168, iter [04400, 05004], lr: 0.006547, loss: 1.6417
2022-07-12 22:25:29 - train: epoch 0168, iter [04500, 05004], lr: 0.006539, loss: 1.6925
2022-07-12 22:26:03 - train: epoch 0168, iter [04600, 05004], lr: 0.006531, loss: 1.4836
2022-07-12 22:26:37 - train: epoch 0168, iter [04700, 05004], lr: 0.006523, loss: 1.3910
2022-07-12 22:27:12 - train: epoch 0168, iter [04800, 05004], lr: 0.006515, loss: 1.3987
2022-07-12 22:27:45 - train: epoch 0168, iter [04900, 05004], lr: 0.006507, loss: 1.7491
2022-07-12 22:28:18 - train: epoch 0168, iter [05000, 05004], lr: 0.006499, loss: 1.3966
2022-07-12 22:28:19 - train: epoch 168, train_loss: 1.5511
2022-07-12 22:29:34 - eval: epoch: 168, acc1: 74.778%, acc5: 92.276%, test_loss: 1.0116, per_image_load_time: 2.019ms, per_image_inference_time: 0.466ms
2022-07-12 22:29:34 - until epoch: 168, best_acc1: 74.778%
2022-07-12 22:29:34 - epoch 169 lr: 0.006499
2022-07-12 22:30:14 - train: epoch 0169, iter [00100, 05004], lr: 0.006491, loss: 1.4307
2022-07-12 22:30:49 - train: epoch 0169, iter [00200, 05004], lr: 0.006483, loss: 1.5740
2022-07-12 22:31:22 - train: epoch 0169, iter [00300, 05004], lr: 0.006475, loss: 1.5490
2022-07-12 22:31:57 - train: epoch 0169, iter [00400, 05004], lr: 0.006467, loss: 1.2680
2022-07-12 22:32:31 - train: epoch 0169, iter [00500, 05004], lr: 0.006459, loss: 1.8235
2022-07-12 22:33:06 - train: epoch 0169, iter [00600, 05004], lr: 0.006451, loss: 1.4156
2022-07-12 22:33:40 - train: epoch 0169, iter [00700, 05004], lr: 0.006443, loss: 1.6426
2022-07-12 22:34:15 - train: epoch 0169, iter [00800, 05004], lr: 0.006435, loss: 1.4919
2022-07-12 22:34:49 - train: epoch 0169, iter [00900, 05004], lr: 0.006428, loss: 1.5967
2022-07-12 22:35:24 - train: epoch 0169, iter [01000, 05004], lr: 0.006420, loss: 1.3603
2022-07-12 22:35:58 - train: epoch 0169, iter [01100, 05004], lr: 0.006412, loss: 1.3932
2022-07-12 22:36:33 - train: epoch 0169, iter [01200, 05004], lr: 0.006404, loss: 1.5320
2022-07-12 22:37:07 - train: epoch 0169, iter [01300, 05004], lr: 0.006396, loss: 1.6801
2022-07-12 22:37:42 - train: epoch 0169, iter [01400, 05004], lr: 0.006388, loss: 1.6419
2022-07-12 22:38:16 - train: epoch 0169, iter [01500, 05004], lr: 0.006380, loss: 1.4454
2022-07-12 22:38:51 - train: epoch 0169, iter [01600, 05004], lr: 0.006372, loss: 1.3981
2022-07-12 22:39:25 - train: epoch 0169, iter [01700, 05004], lr: 0.006364, loss: 1.4827
2022-07-12 22:40:01 - train: epoch 0169, iter [01800, 05004], lr: 0.006357, loss: 1.6967
2022-07-12 22:40:35 - train: epoch 0169, iter [01900, 05004], lr: 0.006349, loss: 1.6541
2022-07-12 22:41:10 - train: epoch 0169, iter [02000, 05004], lr: 0.006341, loss: 1.5758
2022-07-12 22:41:44 - train: epoch 0169, iter [02100, 05004], lr: 0.006333, loss: 1.5355
2022-07-12 22:42:19 - train: epoch 0169, iter [02200, 05004], lr: 0.006325, loss: 1.4371
2022-07-12 22:42:54 - train: epoch 0169, iter [02300, 05004], lr: 0.006317, loss: 1.6163
2022-07-12 22:43:28 - train: epoch 0169, iter [02400, 05004], lr: 0.006310, loss: 1.6290
2022-07-12 22:44:03 - train: epoch 0169, iter [02500, 05004], lr: 0.006302, loss: 1.3501
2022-07-12 22:44:37 - train: epoch 0169, iter [02600, 05004], lr: 0.006294, loss: 1.4243
2022-07-12 22:45:12 - train: epoch 0169, iter [02700, 05004], lr: 0.006286, loss: 1.4034
2022-07-12 22:45:47 - train: epoch 0169, iter [02800, 05004], lr: 0.006278, loss: 1.5593
2022-07-12 22:46:21 - train: epoch 0169, iter [02900, 05004], lr: 0.006270, loss: 1.6473
2022-07-12 22:46:56 - train: epoch 0169, iter [03000, 05004], lr: 0.006263, loss: 1.5262
2022-07-12 22:47:30 - train: epoch 0169, iter [03100, 05004], lr: 0.006255, loss: 1.5634
2022-07-12 22:48:06 - train: epoch 0169, iter [03200, 05004], lr: 0.006247, loss: 1.5354
2022-07-12 22:48:40 - train: epoch 0169, iter [03300, 05004], lr: 0.006239, loss: 1.3935
2022-07-12 22:49:14 - train: epoch 0169, iter [03400, 05004], lr: 0.006232, loss: 1.4285
2022-07-12 22:49:49 - train: epoch 0169, iter [03500, 05004], lr: 0.006224, loss: 1.5006
2022-07-12 22:50:24 - train: epoch 0169, iter [03600, 05004], lr: 0.006216, loss: 1.4961
2022-07-12 22:50:59 - train: epoch 0169, iter [03700, 05004], lr: 0.006208, loss: 1.5725
2022-07-12 22:51:33 - train: epoch 0169, iter [03800, 05004], lr: 0.006200, loss: 1.4277
2022-07-12 22:52:08 - train: epoch 0169, iter [03900, 05004], lr: 0.006193, loss: 1.4304
2022-07-12 22:52:43 - train: epoch 0169, iter [04000, 05004], lr: 0.006185, loss: 1.7684
2022-07-12 22:53:18 - train: epoch 0169, iter [04100, 05004], lr: 0.006177, loss: 1.4747
2022-07-12 22:53:52 - train: epoch 0169, iter [04200, 05004], lr: 0.006169, loss: 1.6026
2022-07-12 22:54:27 - train: epoch 0169, iter [04300, 05004], lr: 0.006162, loss: 1.3788
2022-07-12 22:55:02 - train: epoch 0169, iter [04400, 05004], lr: 0.006154, loss: 1.6382
2022-07-12 22:55:36 - train: epoch 0169, iter [04500, 05004], lr: 0.006146, loss: 1.6445
2022-07-12 22:56:10 - train: epoch 0169, iter [04600, 05004], lr: 0.006138, loss: 1.7404
2022-07-12 22:56:46 - train: epoch 0169, iter [04700, 05004], lr: 0.006131, loss: 1.6563
2022-07-12 22:57:20 - train: epoch 0169, iter [04800, 05004], lr: 0.006123, loss: 1.4203
2022-07-12 22:57:54 - train: epoch 0169, iter [04900, 05004], lr: 0.006115, loss: 1.4755
2022-07-12 22:58:27 - train: epoch 0169, iter [05000, 05004], lr: 0.006108, loss: 1.4431
2022-07-12 22:58:29 - train: epoch 169, train_loss: 1.5354
2022-07-12 22:59:44 - eval: epoch: 169, acc1: 74.610%, acc5: 92.330%, test_loss: 1.0115, per_image_load_time: 2.272ms, per_image_inference_time: 0.486ms
2022-07-12 22:59:44 - until epoch: 169, best_acc1: 74.778%
2022-07-12 22:59:44 - epoch 170 lr: 0.006107
2022-07-12 23:00:24 - train: epoch 0170, iter [00100, 05004], lr: 0.006100, loss: 1.6055
2022-07-12 23:00:58 - train: epoch 0170, iter [00200, 05004], lr: 0.006092, loss: 1.6927
2022-07-12 23:01:33 - train: epoch 0170, iter [00300, 05004], lr: 0.006084, loss: 1.6324
2022-07-12 23:02:08 - train: epoch 0170, iter [00400, 05004], lr: 0.006076, loss: 1.5489
2022-07-12 23:02:43 - train: epoch 0170, iter [00500, 05004], lr: 0.006069, loss: 1.5669
2022-07-12 23:03:17 - train: epoch 0170, iter [00600, 05004], lr: 0.006061, loss: 1.5447
2022-07-12 23:03:52 - train: epoch 0170, iter [00700, 05004], lr: 0.006053, loss: 1.6272
2022-07-12 23:04:27 - train: epoch 0170, iter [00800, 05004], lr: 0.006046, loss: 1.5387
2022-07-12 23:05:01 - train: epoch 0170, iter [00900, 05004], lr: 0.006038, loss: 1.2835
2022-07-12 23:05:36 - train: epoch 0170, iter [01000, 05004], lr: 0.006030, loss: 1.3679
2022-07-12 23:06:10 - train: epoch 0170, iter [01100, 05004], lr: 0.006023, loss: 1.3793
2022-07-12 23:06:45 - train: epoch 0170, iter [01200, 05004], lr: 0.006015, loss: 1.5945
2022-07-12 23:07:20 - train: epoch 0170, iter [01300, 05004], lr: 0.006007, loss: 1.3701
2022-07-12 23:07:54 - train: epoch 0170, iter [01400, 05004], lr: 0.006000, loss: 1.3725
2022-07-12 23:08:29 - train: epoch 0170, iter [01500, 05004], lr: 0.005992, loss: 1.6099
2022-07-12 23:09:03 - train: epoch 0170, iter [01600, 05004], lr: 0.005985, loss: 1.6585
2022-07-12 23:09:38 - train: epoch 0170, iter [01700, 05004], lr: 0.005977, loss: 1.6032
2022-07-12 23:10:14 - train: epoch 0170, iter [01800, 05004], lr: 0.005969, loss: 1.5438
2022-07-12 23:10:48 - train: epoch 0170, iter [01900, 05004], lr: 0.005962, loss: 1.6457
2022-07-12 23:11:23 - train: epoch 0170, iter [02000, 05004], lr: 0.005954, loss: 1.6141
2022-07-12 23:11:57 - train: epoch 0170, iter [02100, 05004], lr: 0.005946, loss: 1.7304
2022-07-12 23:12:32 - train: epoch 0170, iter [02200, 05004], lr: 0.005939, loss: 1.5511
2022-07-12 23:13:07 - train: epoch 0170, iter [02300, 05004], lr: 0.005931, loss: 1.4389
2022-07-12 23:13:41 - train: epoch 0170, iter [02400, 05004], lr: 0.005924, loss: 1.5616
2022-07-12 23:14:15 - train: epoch 0170, iter [02500, 05004], lr: 0.005916, loss: 1.5979
2022-07-12 23:14:49 - train: epoch 0170, iter [02600, 05004], lr: 0.005908, loss: 1.5578
2022-07-12 23:15:22 - train: epoch 0170, iter [02700, 05004], lr: 0.005901, loss: 1.2778
2022-07-12 23:15:56 - train: epoch 0170, iter [02800, 05004], lr: 0.005893, loss: 1.8741
2022-07-12 23:16:30 - train: epoch 0170, iter [02900, 05004], lr: 0.005886, loss: 1.5237
2022-07-12 23:17:03 - train: epoch 0170, iter [03000, 05004], lr: 0.005878, loss: 1.6181
2022-07-12 23:17:36 - train: epoch 0170, iter [03100, 05004], lr: 0.005870, loss: 1.5740
2022-07-12 23:18:10 - train: epoch 0170, iter [03200, 05004], lr: 0.005863, loss: 1.6806
2022-07-12 23:18:45 - train: epoch 0170, iter [03300, 05004], lr: 0.005855, loss: 1.3889
2022-07-12 23:19:18 - train: epoch 0170, iter [03400, 05004], lr: 0.005848, loss: 1.5402
2022-07-12 23:19:52 - train: epoch 0170, iter [03500, 05004], lr: 0.005840, loss: 1.4707
2022-07-12 23:20:25 - train: epoch 0170, iter [03600, 05004], lr: 0.005833, loss: 1.3521
2022-07-12 23:20:59 - train: epoch 0170, iter [03700, 05004], lr: 0.005825, loss: 1.3275
2022-07-12 23:21:33 - train: epoch 0170, iter [03800, 05004], lr: 0.005818, loss: 1.8151
2022-07-12 23:22:07 - train: epoch 0170, iter [03900, 05004], lr: 0.005810, loss: 1.7542
2022-07-12 23:22:40 - train: epoch 0170, iter [04000, 05004], lr: 0.005803, loss: 1.4216
2022-07-12 23:23:15 - train: epoch 0170, iter [04100, 05004], lr: 0.005795, loss: 1.3051
2022-07-12 23:23:48 - train: epoch 0170, iter [04200, 05004], lr: 0.005787, loss: 1.5307
2022-07-12 23:24:23 - train: epoch 0170, iter [04300, 05004], lr: 0.005780, loss: 1.3426
2022-07-12 23:24:56 - train: epoch 0170, iter [04400, 05004], lr: 0.005772, loss: 1.3564
2022-07-12 23:25:31 - train: epoch 0170, iter [04500, 05004], lr: 0.005765, loss: 1.5029
2022-07-12 23:26:04 - train: epoch 0170, iter [04600, 05004], lr: 0.005757, loss: 1.6243
2022-07-12 23:26:39 - train: epoch 0170, iter [04700, 05004], lr: 0.005750, loss: 1.5046
2022-07-12 23:27:12 - train: epoch 0170, iter [04800, 05004], lr: 0.005742, loss: 1.6559
2022-07-12 23:27:47 - train: epoch 0170, iter [04900, 05004], lr: 0.005735, loss: 1.5144
2022-07-12 23:28:19 - train: epoch 0170, iter [05000, 05004], lr: 0.005727, loss: 1.5260
2022-07-12 23:28:20 - train: epoch 170, train_loss: 1.5225
2022-07-12 23:29:34 - eval: epoch: 170, acc1: 74.522%, acc5: 92.262%, test_loss: 1.0121, per_image_load_time: 2.295ms, per_image_inference_time: 0.485ms
2022-07-12 23:29:34 - until epoch: 170, best_acc1: 74.778%
2022-07-12 23:29:34 - epoch 171 lr: 0.005727
2022-07-12 23:30:14 - train: epoch 0171, iter [00100, 05004], lr: 0.005720, loss: 1.4913
2022-07-12 23:30:49 - train: epoch 0171, iter [00200, 05004], lr: 0.005712, loss: 1.6075
2022-07-12 23:31:24 - train: epoch 0171, iter [00300, 05004], lr: 0.005705, loss: 1.5613
2022-07-12 23:31:58 - train: epoch 0171, iter [00400, 05004], lr: 0.005697, loss: 1.4247
2022-07-12 23:32:32 - train: epoch 0171, iter [00500, 05004], lr: 0.005690, loss: 1.7048
2022-07-12 23:33:06 - train: epoch 0171, iter [00600, 05004], lr: 0.005682, loss: 1.4981
2022-07-12 23:33:41 - train: epoch 0171, iter [00700, 05004], lr: 0.005675, loss: 1.4408
2022-07-12 23:34:16 - train: epoch 0171, iter [00800, 05004], lr: 0.005667, loss: 1.5228
2022-07-12 23:34:50 - train: epoch 0171, iter [00900, 05004], lr: 0.005660, loss: 1.4027
2022-07-12 23:35:24 - train: epoch 0171, iter [01000, 05004], lr: 0.005653, loss: 1.3359
2022-07-12 23:35:58 - train: epoch 0171, iter [01100, 05004], lr: 0.005645, loss: 1.3038
2022-07-12 23:36:32 - train: epoch 0171, iter [01200, 05004], lr: 0.005638, loss: 1.9281
2022-07-12 23:37:07 - train: epoch 0171, iter [01300, 05004], lr: 0.005630, loss: 1.5041
2022-07-12 23:37:40 - train: epoch 0171, iter [01400, 05004], lr: 0.005623, loss: 1.4172
2022-07-12 23:38:14 - train: epoch 0171, iter [01500, 05004], lr: 0.005615, loss: 1.5045
2022-07-12 23:38:47 - train: epoch 0171, iter [01600, 05004], lr: 0.005608, loss: 1.4799
2022-07-12 23:39:21 - train: epoch 0171, iter [01700, 05004], lr: 0.005601, loss: 1.2876
2022-07-12 23:39:54 - train: epoch 0171, iter [01800, 05004], lr: 0.005593, loss: 1.4838
2022-07-12 23:40:28 - train: epoch 0171, iter [01900, 05004], lr: 0.005586, loss: 1.7169
2022-07-12 23:41:02 - train: epoch 0171, iter [02000, 05004], lr: 0.005578, loss: 1.3186
2022-07-12 23:41:36 - train: epoch 0171, iter [02100, 05004], lr: 0.005571, loss: 1.3924
2022-07-12 23:42:09 - train: epoch 0171, iter [02200, 05004], lr: 0.005564, loss: 1.3974
2022-07-12 23:42:43 - train: epoch 0171, iter [02300, 05004], lr: 0.005556, loss: 1.3888
2022-07-12 23:43:17 - train: epoch 0171, iter [02400, 05004], lr: 0.005549, loss: 1.6992
2022-07-12 23:43:51 - train: epoch 0171, iter [02500, 05004], lr: 0.005542, loss: 1.5268
2022-07-12 23:44:24 - train: epoch 0171, iter [02600, 05004], lr: 0.005534, loss: 1.3765
2022-07-12 23:44:58 - train: epoch 0171, iter [02700, 05004], lr: 0.005527, loss: 1.3531
2022-07-12 23:45:32 - train: epoch 0171, iter [02800, 05004], lr: 0.005520, loss: 1.4770
2022-07-12 23:46:05 - train: epoch 0171, iter [02900, 05004], lr: 0.005512, loss: 1.4352
2022-07-12 23:46:40 - train: epoch 0171, iter [03000, 05004], lr: 0.005505, loss: 1.5347
2022-07-12 23:47:14 - train: epoch 0171, iter [03100, 05004], lr: 0.005497, loss: 1.6277
2022-07-12 23:47:48 - train: epoch 0171, iter [03200, 05004], lr: 0.005490, loss: 1.5070
2022-07-12 23:48:21 - train: epoch 0171, iter [03300, 05004], lr: 0.005483, loss: 1.7259
2022-07-12 23:48:56 - train: epoch 0171, iter [03400, 05004], lr: 0.005476, loss: 1.3477
2022-07-12 23:49:29 - train: epoch 0171, iter [03500, 05004], lr: 0.005468, loss: 1.5471
2022-07-12 23:50:03 - train: epoch 0171, iter [03600, 05004], lr: 0.005461, loss: 1.6516
2022-07-12 23:50:37 - train: epoch 0171, iter [03700, 05004], lr: 0.005454, loss: 1.5699
2022-07-12 23:51:12 - train: epoch 0171, iter [03800, 05004], lr: 0.005446, loss: 1.6049
2022-07-12 23:51:46 - train: epoch 0171, iter [03900, 05004], lr: 0.005439, loss: 1.5461
2022-07-12 23:52:21 - train: epoch 0171, iter [04000, 05004], lr: 0.005432, loss: 1.2869
2022-07-12 23:52:54 - train: epoch 0171, iter [04100, 05004], lr: 0.005424, loss: 1.5906
2022-07-12 23:53:28 - train: epoch 0171, iter [04200, 05004], lr: 0.005417, loss: 1.7031
2022-07-12 23:54:02 - train: epoch 0171, iter [04300, 05004], lr: 0.005410, loss: 1.7393
2022-07-12 23:54:36 - train: epoch 0171, iter [04400, 05004], lr: 0.005402, loss: 1.4324
2022-07-12 23:55:10 - train: epoch 0171, iter [04500, 05004], lr: 0.005395, loss: 1.6340
2022-07-12 23:55:44 - train: epoch 0171, iter [04600, 05004], lr: 0.005388, loss: 1.2866
2022-07-12 23:56:19 - train: epoch 0171, iter [04700, 05004], lr: 0.005381, loss: 1.5725
2022-07-12 23:56:53 - train: epoch 0171, iter [04800, 05004], lr: 0.005373, loss: 1.5241
2022-07-12 23:57:27 - train: epoch 0171, iter [04900, 05004], lr: 0.005366, loss: 1.6201
2022-07-12 23:58:00 - train: epoch 0171, iter [05000, 05004], lr: 0.005359, loss: 1.5648
2022-07-12 23:58:01 - train: epoch 171, train_loss: 1.5049
2022-07-12 23:59:16 - eval: epoch: 171, acc1: 74.878%, acc5: 92.322%, test_loss: 1.0122, per_image_load_time: 2.385ms, per_image_inference_time: 0.486ms
2022-07-12 23:59:17 - until epoch: 171, best_acc1: 74.878%
2022-07-12 23:59:17 - epoch 172 lr: 0.005359
2022-07-12 23:59:56 - train: epoch 0172, iter [00100, 05004], lr: 0.005351, loss: 1.4034
2022-07-13 00:00:31 - train: epoch 0172, iter [00200, 05004], lr: 0.005344, loss: 1.4518
2022-07-13 00:01:05 - train: epoch 0172, iter [00300, 05004], lr: 0.005337, loss: 1.5844
2022-07-13 00:01:40 - train: epoch 0172, iter [00400, 05004], lr: 0.005330, loss: 1.5599
2022-07-13 00:02:14 - train: epoch 0172, iter [00500, 05004], lr: 0.005322, loss: 1.5620
2022-07-13 00:02:48 - train: epoch 0172, iter [00600, 05004], lr: 0.005315, loss: 1.3014
2022-07-13 00:03:22 - train: epoch 0172, iter [00700, 05004], lr: 0.005308, loss: 1.2009
2022-07-13 00:03:56 - train: epoch 0172, iter [00800, 05004], lr: 0.005301, loss: 1.2687
2022-07-13 00:04:30 - train: epoch 0172, iter [00900, 05004], lr: 0.005294, loss: 1.2149
2022-07-13 00:05:04 - train: epoch 0172, iter [01000, 05004], lr: 0.005286, loss: 1.3547
2022-07-13 00:05:37 - train: epoch 0172, iter [01100, 05004], lr: 0.005279, loss: 1.4203
2022-07-13 00:06:12 - train: epoch 0172, iter [01200, 05004], lr: 0.005272, loss: 1.6426
2022-07-13 00:06:45 - train: epoch 0172, iter [01300, 05004], lr: 0.005265, loss: 1.3824
2022-07-13 00:07:20 - train: epoch 0172, iter [01400, 05004], lr: 0.005258, loss: 1.6165
2022-07-13 00:07:53 - train: epoch 0172, iter [01500, 05004], lr: 0.005250, loss: 1.5962
2022-07-13 00:08:27 - train: epoch 0172, iter [01600, 05004], lr: 0.005243, loss: 1.5839
2022-07-13 00:09:01 - train: epoch 0172, iter [01700, 05004], lr: 0.005236, loss: 1.7492
2022-07-13 00:09:35 - train: epoch 0172, iter [01800, 05004], lr: 0.005229, loss: 1.3838
2022-07-13 00:10:09 - train: epoch 0172, iter [01900, 05004], lr: 0.005222, loss: 1.3938
2022-07-13 00:10:44 - train: epoch 0172, iter [02000, 05004], lr: 0.005215, loss: 1.4295
2022-07-13 00:11:19 - train: epoch 0172, iter [02100, 05004], lr: 0.005207, loss: 1.7085
2022-07-13 00:11:52 - train: epoch 0172, iter [02200, 05004], lr: 0.005200, loss: 1.4940
2022-07-13 00:12:27 - train: epoch 0172, iter [02300, 05004], lr: 0.005193, loss: 1.4770
2022-07-13 00:13:00 - train: epoch 0172, iter [02400, 05004], lr: 0.005186, loss: 1.4995
2022-07-13 00:13:34 - train: epoch 0172, iter [02500, 05004], lr: 0.005179, loss: 1.4436
2022-07-13 00:14:09 - train: epoch 0172, iter [02600, 05004], lr: 0.005172, loss: 1.3533
2022-07-13 00:14:43 - train: epoch 0172, iter [02700, 05004], lr: 0.005165, loss: 1.4386
2022-07-13 00:15:18 - train: epoch 0172, iter [02800, 05004], lr: 0.005157, loss: 1.6983
2022-07-13 00:15:52 - train: epoch 0172, iter [02900, 05004], lr: 0.005150, loss: 1.6194
2022-07-13 00:16:26 - train: epoch 0172, iter [03000, 05004], lr: 0.005143, loss: 1.3781
2022-07-13 00:17:01 - train: epoch 0172, iter [03100, 05004], lr: 0.005136, loss: 1.3541
2022-07-13 00:17:35 - train: epoch 0172, iter [03200, 05004], lr: 0.005129, loss: 1.4308
2022-07-13 00:18:09 - train: epoch 0172, iter [03300, 05004], lr: 0.005122, loss: 1.5152
2022-07-13 00:18:43 - train: epoch 0172, iter [03400, 05004], lr: 0.005115, loss: 1.5232
2022-07-13 00:19:17 - train: epoch 0172, iter [03500, 05004], lr: 0.005108, loss: 1.3451
2022-07-13 00:19:52 - train: epoch 0172, iter [03600, 05004], lr: 0.005101, loss: 1.6487
2022-07-13 00:20:27 - train: epoch 0172, iter [03700, 05004], lr: 0.005094, loss: 1.4015
2022-07-13 00:21:02 - train: epoch 0172, iter [03800, 05004], lr: 0.005086, loss: 1.3622
2022-07-13 00:21:36 - train: epoch 0172, iter [03900, 05004], lr: 0.005079, loss: 1.5328
2022-07-13 00:22:10 - train: epoch 0172, iter [04000, 05004], lr: 0.005072, loss: 1.5089
2022-07-13 00:22:45 - train: epoch 0172, iter [04100, 05004], lr: 0.005065, loss: 1.5355
2022-07-13 00:23:19 - train: epoch 0172, iter [04200, 05004], lr: 0.005058, loss: 1.3044
2022-07-13 00:23:53 - train: epoch 0172, iter [04300, 05004], lr: 0.005051, loss: 1.3418
2022-07-13 00:24:28 - train: epoch 0172, iter [04400, 05004], lr: 0.005044, loss: 1.3214
2022-07-13 00:25:03 - train: epoch 0172, iter [04500, 05004], lr: 0.005037, loss: 1.7633
2022-07-13 00:25:38 - train: epoch 0172, iter [04600, 05004], lr: 0.005030, loss: 1.6976
2022-07-13 00:26:12 - train: epoch 0172, iter [04700, 05004], lr: 0.005023, loss: 1.4157
2022-07-13 00:26:47 - train: epoch 0172, iter [04800, 05004], lr: 0.005016, loss: 1.3842
2022-07-13 00:27:21 - train: epoch 0172, iter [04900, 05004], lr: 0.005009, loss: 1.3034
2022-07-13 00:27:53 - train: epoch 0172, iter [05000, 05004], lr: 0.005002, loss: 1.3374
2022-07-13 00:27:54 - train: epoch 172, train_loss: 1.4926
2022-07-13 00:29:08 - eval: epoch: 172, acc1: 75.158%, acc5: 92.506%, test_loss: 0.9977, per_image_load_time: 2.301ms, per_image_inference_time: 0.477ms
2022-07-13 00:29:08 - until epoch: 172, best_acc1: 75.158%
2022-07-13 00:29:08 - epoch 173 lr: 0.005002
2022-07-13 00:29:47 - train: epoch 0173, iter [00100, 05004], lr: 0.004995, loss: 1.5606
2022-07-13 00:30:21 - train: epoch 0173, iter [00200, 05004], lr: 0.004988, loss: 1.7199
2022-07-13 00:30:55 - train: epoch 0173, iter [00300, 05004], lr: 0.004981, loss: 1.4424
2022-07-13 00:31:29 - train: epoch 0173, iter [00400, 05004], lr: 0.004974, loss: 1.3715
2022-07-13 00:32:02 - train: epoch 0173, iter [00500, 05004], lr: 0.004967, loss: 1.4652
2022-07-13 00:32:36 - train: epoch 0173, iter [00600, 05004], lr: 0.004960, loss: 1.5243
2022-07-13 00:33:09 - train: epoch 0173, iter [00700, 05004], lr: 0.004953, loss: 1.5868
2022-07-13 00:33:44 - train: epoch 0173, iter [00800, 05004], lr: 0.004946, loss: 1.4237
2022-07-13 00:34:18 - train: epoch 0173, iter [00900, 05004], lr: 0.004939, loss: 1.4037
2022-07-13 00:34:51 - train: epoch 0173, iter [01000, 05004], lr: 0.004932, loss: 1.6580
2022-07-13 00:35:25 - train: epoch 0173, iter [01100, 05004], lr: 0.004925, loss: 1.2258
2022-07-13 00:35:59 - train: epoch 0173, iter [01200, 05004], lr: 0.004918, loss: 1.3839
2022-07-13 00:36:33 - train: epoch 0173, iter [01300, 05004], lr: 0.004911, loss: 1.5157
2022-07-13 00:37:07 - train: epoch 0173, iter [01400, 05004], lr: 0.004904, loss: 1.4693
2022-07-13 00:37:41 - train: epoch 0173, iter [01500, 05004], lr: 0.004897, loss: 1.6188
2022-07-13 00:38:14 - train: epoch 0173, iter [01600, 05004], lr: 0.004890, loss: 1.3128
2022-07-13 00:38:48 - train: epoch 0173, iter [01700, 05004], lr: 0.004883, loss: 1.4854
2022-07-13 00:39:22 - train: epoch 0173, iter [01800, 05004], lr: 0.004876, loss: 1.3649
2022-07-13 00:39:55 - train: epoch 0173, iter [01900, 05004], lr: 0.004869, loss: 1.2732
2022-07-13 00:40:30 - train: epoch 0173, iter [02000, 05004], lr: 0.004862, loss: 1.5984
2022-07-13 00:41:03 - train: epoch 0173, iter [02100, 05004], lr: 0.004855, loss: 1.3278
2022-07-13 00:41:37 - train: epoch 0173, iter [02200, 05004], lr: 0.004848, loss: 1.4159
2022-07-13 00:42:11 - train: epoch 0173, iter [02300, 05004], lr: 0.004841, loss: 1.5203
2022-07-13 00:42:45 - train: epoch 0173, iter [02400, 05004], lr: 0.004835, loss: 1.4549
2022-07-13 00:43:19 - train: epoch 0173, iter [02500, 05004], lr: 0.004828, loss: 1.6478
2022-07-13 00:43:53 - train: epoch 0173, iter [02600, 05004], lr: 0.004821, loss: 1.4310
2022-07-13 00:44:28 - train: epoch 0173, iter [02700, 05004], lr: 0.004814, loss: 1.7668
2022-07-13 00:45:02 - train: epoch 0173, iter [02800, 05004], lr: 0.004807, loss: 1.6098
2022-07-13 00:45:37 - train: epoch 0173, iter [02900, 05004], lr: 0.004800, loss: 1.4301
2022-07-13 00:46:12 - train: epoch 0173, iter [03000, 05004], lr: 0.004793, loss: 1.4145
2022-07-13 00:46:47 - train: epoch 0173, iter [03100, 05004], lr: 0.004786, loss: 1.3406
2022-07-13 00:47:21 - train: epoch 0173, iter [03200, 05004], lr: 0.004779, loss: 1.7668
2022-07-13 00:47:56 - train: epoch 0173, iter [03300, 05004], lr: 0.004773, loss: 1.4192
2022-07-13 00:48:30 - train: epoch 0173, iter [03400, 05004], lr: 0.004766, loss: 1.4978
2022-07-13 00:49:04 - train: epoch 0173, iter [03500, 05004], lr: 0.004759, loss: 1.7182
2022-07-13 00:49:40 - train: epoch 0173, iter [03600, 05004], lr: 0.004752, loss: 1.6827
2022-07-13 00:50:15 - train: epoch 0173, iter [03700, 05004], lr: 0.004745, loss: 1.5269
2022-07-13 00:50:49 - train: epoch 0173, iter [03800, 05004], lr: 0.004738, loss: 1.5490
2022-07-13 00:51:25 - train: epoch 0173, iter [03900, 05004], lr: 0.004731, loss: 1.4029
2022-07-13 00:51:59 - train: epoch 0173, iter [04000, 05004], lr: 0.004725, loss: 1.7949
2022-07-13 00:52:34 - train: epoch 0173, iter [04100, 05004], lr: 0.004718, loss: 1.5791
2022-07-13 00:53:09 - train: epoch 0173, iter [04200, 05004], lr: 0.004711, loss: 1.3780
2022-07-13 00:53:43 - train: epoch 0173, iter [04300, 05004], lr: 0.004704, loss: 1.4465
2022-07-13 00:54:19 - train: epoch 0173, iter [04400, 05004], lr: 0.004697, loss: 1.6261
2022-07-13 00:54:54 - train: epoch 0173, iter [04500, 05004], lr: 0.004691, loss: 1.6145
2022-07-13 00:55:28 - train: epoch 0173, iter [04600, 05004], lr: 0.004684, loss: 1.3853
2022-07-13 00:56:04 - train: epoch 0173, iter [04700, 05004], lr: 0.004677, loss: 1.5797
2022-07-13 00:56:38 - train: epoch 0173, iter [04800, 05004], lr: 0.004670, loss: 1.5068
2022-07-13 00:57:12 - train: epoch 0173, iter [04900, 05004], lr: 0.004663, loss: 1.6882
2022-07-13 00:57:47 - train: epoch 0173, iter [05000, 05004], lr: 0.004657, loss: 1.5308
2022-07-13 00:57:48 - train: epoch 173, train_loss: 1.4761
2022-07-13 00:59:03 - eval: epoch: 173, acc1: 74.902%, acc5: 92.458%, test_loss: 1.0016, per_image_load_time: 2.269ms, per_image_inference_time: 0.461ms
2022-07-13 00:59:03 - until epoch: 173, best_acc1: 75.158%
2022-07-13 00:59:03 - epoch 174 lr: 0.004656
2022-07-13 00:59:44 - train: epoch 0174, iter [00100, 05004], lr: 0.004650, loss: 1.3563
2022-07-13 01:00:19 - train: epoch 0174, iter [00200, 05004], lr: 0.004643, loss: 1.3858
2022-07-13 01:00:53 - train: epoch 0174, iter [00300, 05004], lr: 0.004636, loss: 1.8005
2022-07-13 01:01:28 - train: epoch 0174, iter [00400, 05004], lr: 0.004629, loss: 1.3829
2022-07-13 01:02:03 - train: epoch 0174, iter [00500, 05004], lr: 0.004622, loss: 1.4789
2022-07-13 01:02:38 - train: epoch 0174, iter [00600, 05004], lr: 0.004616, loss: 1.6234
2022-07-13 01:03:12 - train: epoch 0174, iter [00700, 05004], lr: 0.004609, loss: 1.1793
2022-07-13 01:03:47 - train: epoch 0174, iter [00800, 05004], lr: 0.004602, loss: 1.4743
2022-07-13 01:04:21 - train: epoch 0174, iter [00900, 05004], lr: 0.004595, loss: 1.5128
2022-07-13 01:04:55 - train: epoch 0174, iter [01000, 05004], lr: 0.004589, loss: 1.5465
2022-07-13 01:05:30 - train: epoch 0174, iter [01100, 05004], lr: 0.004582, loss: 1.4198
2022-07-13 01:06:03 - train: epoch 0174, iter [01200, 05004], lr: 0.004575, loss: 1.5013
2022-07-13 01:06:38 - train: epoch 0174, iter [01300, 05004], lr: 0.004568, loss: 1.4322
2022-07-13 01:07:13 - train: epoch 0174, iter [01400, 05004], lr: 0.004562, loss: 1.4982
2022-07-13 01:07:47 - train: epoch 0174, iter [01500, 05004], lr: 0.004555, loss: 1.5445
2022-07-13 01:08:21 - train: epoch 0174, iter [01600, 05004], lr: 0.004548, loss: 1.5263
2022-07-13 01:08:56 - train: epoch 0174, iter [01700, 05004], lr: 0.004542, loss: 1.2970
2022-07-13 01:09:31 - train: epoch 0174, iter [01800, 05004], lr: 0.004535, loss: 1.4380
2022-07-13 01:10:04 - train: epoch 0174, iter [01900, 05004], lr: 0.004528, loss: 1.5317
2022-07-13 01:10:38 - train: epoch 0174, iter [02000, 05004], lr: 0.004522, loss: 1.7020
2022-07-13 01:11:12 - train: epoch 0174, iter [02100, 05004], lr: 0.004515, loss: 1.4854
2022-07-13 01:11:47 - train: epoch 0174, iter [02200, 05004], lr: 0.004508, loss: 1.5007
2022-07-13 01:12:22 - train: epoch 0174, iter [02300, 05004], lr: 0.004502, loss: 1.6114
2022-07-13 01:12:57 - train: epoch 0174, iter [02400, 05004], lr: 0.004495, loss: 1.4104
2022-07-13 01:13:31 - train: epoch 0174, iter [02500, 05004], lr: 0.004488, loss: 1.1905
2022-07-13 01:14:06 - train: epoch 0174, iter [02600, 05004], lr: 0.004481, loss: 1.3551
2022-07-13 01:14:39 - train: epoch 0174, iter [02700, 05004], lr: 0.004475, loss: 1.4280
2022-07-13 01:15:15 - train: epoch 0174, iter [02800, 05004], lr: 0.004468, loss: 1.3014
2022-07-13 01:15:49 - train: epoch 0174, iter [02900, 05004], lr: 0.004462, loss: 1.5746
2022-07-13 01:16:24 - train: epoch 0174, iter [03000, 05004], lr: 0.004455, loss: 1.3307
2022-07-13 01:16:58 - train: epoch 0174, iter [03100, 05004], lr: 0.004448, loss: 1.5834
2022-07-13 01:17:33 - train: epoch 0174, iter [03200, 05004], lr: 0.004442, loss: 1.6434
2022-07-13 01:18:08 - train: epoch 0174, iter [03300, 05004], lr: 0.004435, loss: 1.3338
2022-07-13 01:18:43 - train: epoch 0174, iter [03400, 05004], lr: 0.004428, loss: 1.3239
2022-07-13 01:19:18 - train: epoch 0174, iter [03500, 05004], lr: 0.004422, loss: 1.6200
2022-07-13 01:19:53 - train: epoch 0174, iter [03600, 05004], lr: 0.004415, loss: 1.2632
2022-07-13 01:20:27 - train: epoch 0174, iter [03700, 05004], lr: 0.004409, loss: 1.5400
2022-07-13 01:21:02 - train: epoch 0174, iter [03800, 05004], lr: 0.004402, loss: 1.6598
2022-07-13 01:21:37 - train: epoch 0174, iter [03900, 05004], lr: 0.004395, loss: 1.7345
2022-07-13 01:22:12 - train: epoch 0174, iter [04000, 05004], lr: 0.004389, loss: 1.3946
2022-07-13 01:22:46 - train: epoch 0174, iter [04100, 05004], lr: 0.004382, loss: 1.5049
2022-07-13 01:23:21 - train: epoch 0174, iter [04200, 05004], lr: 0.004376, loss: 1.3641
2022-07-13 01:23:56 - train: epoch 0174, iter [04300, 05004], lr: 0.004369, loss: 1.3445
2022-07-13 01:24:30 - train: epoch 0174, iter [04400, 05004], lr: 0.004362, loss: 1.6959
2022-07-13 01:25:05 - train: epoch 0174, iter [04500, 05004], lr: 0.004356, loss: 1.9746
2022-07-13 01:25:39 - train: epoch 0174, iter [04600, 05004], lr: 0.004349, loss: 1.3750
2022-07-13 01:26:14 - train: epoch 0174, iter [04700, 05004], lr: 0.004343, loss: 1.6316
2022-07-13 01:26:49 - train: epoch 0174, iter [04800, 05004], lr: 0.004336, loss: 1.5965
2022-07-13 01:27:22 - train: epoch 0174, iter [04900, 05004], lr: 0.004330, loss: 1.4991
2022-07-13 01:27:55 - train: epoch 0174, iter [05000, 05004], lr: 0.004323, loss: 1.5526
2022-07-13 01:27:57 - train: epoch 174, train_loss: 1.4638
2022-07-13 01:29:11 - eval: epoch: 174, acc1: 75.300%, acc5: 92.486%, test_loss: 0.9904, per_image_load_time: 1.341ms, per_image_inference_time: 0.472ms
2022-07-13 01:29:11 - until epoch: 174, best_acc1: 75.300%
2022-07-13 01:29:11 - epoch 175 lr: 0.004323
2022-07-13 01:29:51 - train: epoch 0175, iter [00100, 05004], lr: 0.004316, loss: 1.2411
2022-07-13 01:30:26 - train: epoch 0175, iter [00200, 05004], lr: 0.004310, loss: 1.3170
2022-07-13 01:31:00 - train: epoch 0175, iter [00300, 05004], lr: 0.004303, loss: 1.4757
2022-07-13 01:31:34 - train: epoch 0175, iter [00400, 05004], lr: 0.004297, loss: 1.5083
2022-07-13 01:32:09 - train: epoch 0175, iter [00500, 05004], lr: 0.004290, loss: 1.3745
2022-07-13 01:32:43 - train: epoch 0175, iter [00600, 05004], lr: 0.004284, loss: 1.2912
2022-07-13 01:33:18 - train: epoch 0175, iter [00700, 05004], lr: 0.004277, loss: 1.4523
2022-07-13 01:33:51 - train: epoch 0175, iter [00800, 05004], lr: 0.004270, loss: 1.6069
2022-07-13 01:34:27 - train: epoch 0175, iter [00900, 05004], lr: 0.004264, loss: 1.7034
2022-07-13 01:35:00 - train: epoch 0175, iter [01000, 05004], lr: 0.004257, loss: 1.3943
2022-07-13 01:35:35 - train: epoch 0175, iter [01100, 05004], lr: 0.004251, loss: 1.1431
2022-07-13 01:36:09 - train: epoch 0175, iter [01200, 05004], lr: 0.004244, loss: 1.3988
2022-07-13 01:36:44 - train: epoch 0175, iter [01300, 05004], lr: 0.004238, loss: 1.4260
2022-07-13 01:37:18 - train: epoch 0175, iter [01400, 05004], lr: 0.004232, loss: 1.5150
2022-07-13 01:37:53 - train: epoch 0175, iter [01500, 05004], lr: 0.004225, loss: 1.5047
2022-07-13 01:38:28 - train: epoch 0175, iter [01600, 05004], lr: 0.004219, loss: 1.5700
2022-07-13 01:39:02 - train: epoch 0175, iter [01700, 05004], lr: 0.004212, loss: 1.2398
2022-07-13 01:39:37 - train: epoch 0175, iter [01800, 05004], lr: 0.004206, loss: 1.5832
2022-07-13 01:40:10 - train: epoch 0175, iter [01900, 05004], lr: 0.004199, loss: 1.4196
2022-07-13 01:40:46 - train: epoch 0175, iter [02000, 05004], lr: 0.004193, loss: 1.2565
2022-07-13 01:41:20 - train: epoch 0175, iter [02100, 05004], lr: 0.004186, loss: 1.3455
2022-07-13 01:41:56 - train: epoch 0175, iter [02200, 05004], lr: 0.004180, loss: 1.2593
2022-07-13 01:42:31 - train: epoch 0175, iter [02300, 05004], lr: 0.004173, loss: 1.2651
2022-07-13 01:43:06 - train: epoch 0175, iter [02400, 05004], lr: 0.004167, loss: 1.3928
2022-07-13 01:43:40 - train: epoch 0175, iter [02500, 05004], lr: 0.004161, loss: 1.3577
2022-07-13 01:44:15 - train: epoch 0175, iter [02600, 05004], lr: 0.004154, loss: 1.4524
2022-07-13 01:44:50 - train: epoch 0175, iter [02700, 05004], lr: 0.004148, loss: 1.7118
2022-07-13 01:45:24 - train: epoch 0175, iter [02800, 05004], lr: 0.004141, loss: 1.4349
2022-07-13 01:45:59 - train: epoch 0175, iter [02900, 05004], lr: 0.004135, loss: 1.3041
2022-07-13 01:46:34 - train: epoch 0175, iter [03000, 05004], lr: 0.004128, loss: 1.5272
2022-07-13 01:47:10 - train: epoch 0175, iter [03100, 05004], lr: 0.004122, loss: 1.5255
2022-07-13 01:47:43 - train: epoch 0175, iter [03200, 05004], lr: 0.004116, loss: 1.4483
2022-07-13 01:48:18 - train: epoch 0175, iter [03300, 05004], lr: 0.004109, loss: 1.7083
2022-07-13 01:48:54 - train: epoch 0175, iter [03400, 05004], lr: 0.004103, loss: 1.5798
2022-07-13 01:49:29 - train: epoch 0175, iter [03500, 05004], lr: 0.004096, loss: 1.3049
2022-07-13 01:50:04 - train: epoch 0175, iter [03600, 05004], lr: 0.004090, loss: 1.4520
2022-07-13 01:50:38 - train: epoch 0175, iter [03700, 05004], lr: 0.004084, loss: 1.6383
2022-07-13 01:51:13 - train: epoch 0175, iter [03800, 05004], lr: 0.004077, loss: 1.4029
2022-07-13 01:51:48 - train: epoch 0175, iter [03900, 05004], lr: 0.004071, loss: 1.3514
2022-07-13 01:52:23 - train: epoch 0175, iter [04000, 05004], lr: 0.004065, loss: 1.7293
2022-07-13 01:52:57 - train: epoch 0175, iter [04100, 05004], lr: 0.004058, loss: 1.4289
2022-07-13 01:53:32 - train: epoch 0175, iter [04200, 05004], lr: 0.004052, loss: 1.3045
2022-07-13 01:54:08 - train: epoch 0175, iter [04300, 05004], lr: 0.004046, loss: 1.3125
2022-07-13 01:54:43 - train: epoch 0175, iter [04400, 05004], lr: 0.004039, loss: 1.4857
2022-07-13 01:55:18 - train: epoch 0175, iter [04500, 05004], lr: 0.004033, loss: 1.3485
2022-07-13 01:55:53 - train: epoch 0175, iter [04600, 05004], lr: 0.004027, loss: 1.1951
2022-07-13 01:56:27 - train: epoch 0175, iter [04700, 05004], lr: 0.004020, loss: 1.3659
2022-07-13 01:57:02 - train: epoch 0175, iter [04800, 05004], lr: 0.004014, loss: 1.6036
2022-07-13 01:57:37 - train: epoch 0175, iter [04900, 05004], lr: 0.004008, loss: 1.8063
2022-07-13 01:58:10 - train: epoch 0175, iter [05000, 05004], lr: 0.004001, loss: 1.5060
2022-07-13 01:58:11 - train: epoch 175, train_loss: 1.4492
2022-07-13 01:59:26 - eval: epoch: 175, acc1: 75.324%, acc5: 92.684%, test_loss: 0.9896, per_image_load_time: 1.499ms, per_image_inference_time: 0.499ms
2022-07-13 01:59:26 - until epoch: 175, best_acc1: 75.324%
2022-07-13 01:59:26 - epoch 176 lr: 0.004001
2022-07-13 02:00:06 - train: epoch 0176, iter [00100, 05004], lr: 0.003995, loss: 1.7647
2022-07-13 02:00:41 - train: epoch 0176, iter [00200, 05004], lr: 0.003988, loss: 1.6897
2022-07-13 02:01:15 - train: epoch 0176, iter [00300, 05004], lr: 0.003982, loss: 1.3736
2022-07-13 02:01:51 - train: epoch 0176, iter [00400, 05004], lr: 0.003976, loss: 1.3948
2022-07-13 02:02:25 - train: epoch 0176, iter [00500, 05004], lr: 0.003970, loss: 1.6042
2022-07-13 02:03:01 - train: epoch 0176, iter [00600, 05004], lr: 0.003963, loss: 1.4515
2022-07-13 02:03:35 - train: epoch 0176, iter [00700, 05004], lr: 0.003957, loss: 1.2867
2022-07-13 02:04:10 - train: epoch 0176, iter [00800, 05004], lr: 0.003951, loss: 1.2741
2022-07-13 02:04:45 - train: epoch 0176, iter [00900, 05004], lr: 0.003944, loss: 1.5261
2022-07-13 02:05:20 - train: epoch 0176, iter [01000, 05004], lr: 0.003938, loss: 1.5150
2022-07-13 02:05:54 - train: epoch 0176, iter [01100, 05004], lr: 0.003932, loss: 1.3653
2022-07-13 02:06:29 - train: epoch 0176, iter [01200, 05004], lr: 0.003926, loss: 1.6295
2022-07-13 02:07:03 - train: epoch 0176, iter [01300, 05004], lr: 0.003919, loss: 1.4602
2022-07-13 02:07:37 - train: epoch 0176, iter [01400, 05004], lr: 0.003913, loss: 1.2651
2022-07-13 02:08:12 - train: epoch 0176, iter [01500, 05004], lr: 0.003907, loss: 1.4592
2022-07-13 02:08:46 - train: epoch 0176, iter [01600, 05004], lr: 0.003901, loss: 1.5508
2022-07-13 02:09:21 - train: epoch 0176, iter [01700, 05004], lr: 0.003894, loss: 1.4578
2022-07-13 02:09:55 - train: epoch 0176, iter [01800, 05004], lr: 0.003888, loss: 1.2948
2022-07-13 02:10:30 - train: epoch 0176, iter [01900, 05004], lr: 0.003882, loss: 1.3228
2022-07-13 02:11:03 - train: epoch 0176, iter [02000, 05004], lr: 0.003876, loss: 1.3378
2022-07-13 02:11:37 - train: epoch 0176, iter [02100, 05004], lr: 0.003870, loss: 1.4927
2022-07-13 02:12:12 - train: epoch 0176, iter [02200, 05004], lr: 0.003863, loss: 1.2888
2022-07-13 02:12:47 - train: epoch 0176, iter [02300, 05004], lr: 0.003857, loss: 1.3288
2022-07-13 02:13:21 - train: epoch 0176, iter [02400, 05004], lr: 0.003851, loss: 1.1892
2022-07-13 02:13:55 - train: epoch 0176, iter [02500, 05004], lr: 0.003845, loss: 1.5468
2022-07-13 02:14:29 - train: epoch 0176, iter [02600, 05004], lr: 0.003839, loss: 1.2686
2022-07-13 02:15:04 - train: epoch 0176, iter [02700, 05004], lr: 0.003832, loss: 1.6091
2022-07-13 02:15:38 - train: epoch 0176, iter [02800, 05004], lr: 0.003826, loss: 1.4163
2022-07-13 02:16:13 - train: epoch 0176, iter [02900, 05004], lr: 0.003820, loss: 1.5529
2022-07-13 02:16:47 - train: epoch 0176, iter [03000, 05004], lr: 0.003814, loss: 1.3285
2022-07-13 02:17:21 - train: epoch 0176, iter [03100, 05004], lr: 0.003808, loss: 1.3472
2022-07-13 02:17:56 - train: epoch 0176, iter [03200, 05004], lr: 0.003802, loss: 1.6004
2022-07-13 02:18:30 - train: epoch 0176, iter [03300, 05004], lr: 0.003795, loss: 1.2553
2022-07-13 02:19:04 - train: epoch 0176, iter [03400, 05004], lr: 0.003789, loss: 1.4747
2022-07-13 02:19:39 - train: epoch 0176, iter [03500, 05004], lr: 0.003783, loss: 1.3916
2022-07-13 02:20:13 - train: epoch 0176, iter [03600, 05004], lr: 0.003777, loss: 1.4151
2022-07-13 02:20:48 - train: epoch 0176, iter [03700, 05004], lr: 0.003771, loss: 1.2628
2022-07-13 02:21:23 - train: epoch 0176, iter [03800, 05004], lr: 0.003765, loss: 1.4471
2022-07-13 02:21:57 - train: epoch 0176, iter [03900, 05004], lr: 0.003759, loss: 1.3125
2022-07-13 02:22:32 - train: epoch 0176, iter [04000, 05004], lr: 0.003752, loss: 1.4346
2022-07-13 02:23:06 - train: epoch 0176, iter [04100, 05004], lr: 0.003746, loss: 1.4930
2022-07-13 02:23:41 - train: epoch 0176, iter [04200, 05004], lr: 0.003740, loss: 1.5105
2022-07-13 02:24:15 - train: epoch 0176, iter [04300, 05004], lr: 0.003734, loss: 1.5734
2022-07-13 02:24:50 - train: epoch 0176, iter [04400, 05004], lr: 0.003728, loss: 1.7199
2022-07-13 02:25:25 - train: epoch 0176, iter [04500, 05004], lr: 0.003722, loss: 1.5469
2022-07-13 02:25:59 - train: epoch 0176, iter [04600, 05004], lr: 0.003716, loss: 1.4588
2022-07-13 02:26:34 - train: epoch 0176, iter [04700, 05004], lr: 0.003710, loss: 1.5577
2022-07-13 02:27:08 - train: epoch 0176, iter [04800, 05004], lr: 0.003704, loss: 1.3496
2022-07-13 02:27:43 - train: epoch 0176, iter [04900, 05004], lr: 0.003698, loss: 1.5148
2022-07-13 02:28:16 - train: epoch 0176, iter [05000, 05004], lr: 0.003692, loss: 1.3554
2022-07-13 02:28:17 - train: epoch 176, train_loss: 1.4356
2022-07-13 02:29:33 - eval: epoch: 176, acc1: 75.504%, acc5: 92.760%, test_loss: 0.9775, per_image_load_time: 1.121ms, per_image_inference_time: 0.476ms
2022-07-13 02:29:33 - until epoch: 176, best_acc1: 75.504%
2022-07-13 02:29:33 - epoch 177 lr: 0.003691
2022-07-13 02:30:13 - train: epoch 0177, iter [00100, 05004], lr: 0.003685, loss: 1.2671
2022-07-13 02:30:48 - train: epoch 0177, iter [00200, 05004], lr: 0.003679, loss: 1.3742
2022-07-13 02:31:22 - train: epoch 0177, iter [00300, 05004], lr: 0.003673, loss: 1.3432
2022-07-13 02:31:56 - train: epoch 0177, iter [00400, 05004], lr: 0.003667, loss: 1.3412
2022-07-13 02:32:31 - train: epoch 0177, iter [00500, 05004], lr: 0.003661, loss: 1.3219
2022-07-13 02:33:06 - train: epoch 0177, iter [00600, 05004], lr: 0.003655, loss: 1.3496
2022-07-13 02:33:40 - train: epoch 0177, iter [00700, 05004], lr: 0.003649, loss: 1.6092
2022-07-13 02:34:15 - train: epoch 0177, iter [00800, 05004], lr: 0.003643, loss: 1.4859
2022-07-13 02:34:49 - train: epoch 0177, iter [00900, 05004], lr: 0.003637, loss: 1.2077
2022-07-13 02:35:24 - train: epoch 0177, iter [01000, 05004], lr: 0.003631, loss: 1.4134
2022-07-13 02:35:59 - train: epoch 0177, iter [01100, 05004], lr: 0.003625, loss: 1.4636
2022-07-13 02:36:34 - train: epoch 0177, iter [01200, 05004], lr: 0.003619, loss: 1.7534
2022-07-13 02:37:08 - train: epoch 0177, iter [01300, 05004], lr: 0.003613, loss: 1.5129
2022-07-13 02:37:43 - train: epoch 0177, iter [01400, 05004], lr: 0.003607, loss: 1.2811
2022-07-13 02:38:18 - train: epoch 0177, iter [01500, 05004], lr: 0.003601, loss: 1.4336
2022-07-13 02:38:54 - train: epoch 0177, iter [01600, 05004], lr: 0.003595, loss: 1.4805
2022-07-13 02:39:28 - train: epoch 0177, iter [01700, 05004], lr: 0.003589, loss: 1.4262
2022-07-13 02:40:03 - train: epoch 0177, iter [01800, 05004], lr: 0.003583, loss: 1.3432
2022-07-13 02:40:38 - train: epoch 0177, iter [01900, 05004], lr: 0.003577, loss: 1.1320
2022-07-13 02:41:13 - train: epoch 0177, iter [02000, 05004], lr: 0.003571, loss: 1.3732
2022-07-13 02:41:48 - train: epoch 0177, iter [02100, 05004], lr: 0.003565, loss: 1.5040
2022-07-13 02:42:22 - train: epoch 0177, iter [02200, 05004], lr: 0.003559, loss: 1.6068
2022-07-13 02:42:58 - train: epoch 0177, iter [02300, 05004], lr: 0.003553, loss: 1.4135
2022-07-13 02:43:32 - train: epoch 0177, iter [02400, 05004], lr: 0.003547, loss: 1.3904
2022-07-13 02:44:08 - train: epoch 0177, iter [02500, 05004], lr: 0.003541, loss: 1.3592
2022-07-13 02:44:42 - train: epoch 0177, iter [02600, 05004], lr: 0.003535, loss: 1.2559
2022-07-13 02:45:17 - train: epoch 0177, iter [02700, 05004], lr: 0.003529, loss: 1.5924
2022-07-13 02:45:53 - train: epoch 0177, iter [02800, 05004], lr: 0.003523, loss: 1.2565
2022-07-13 02:46:27 - train: epoch 0177, iter [02900, 05004], lr: 0.003517, loss: 1.6748
2022-07-13 02:47:03 - train: epoch 0177, iter [03000, 05004], lr: 0.003511, loss: 1.3564
2022-07-13 02:47:38 - train: epoch 0177, iter [03100, 05004], lr: 0.003505, loss: 1.3116
2022-07-13 02:48:13 - train: epoch 0177, iter [03200, 05004], lr: 0.003499, loss: 1.6097
2022-07-13 02:48:48 - train: epoch 0177, iter [03300, 05004], lr: 0.003494, loss: 1.3543
2022-07-13 02:49:23 - train: epoch 0177, iter [03400, 05004], lr: 0.003488, loss: 1.6698
2022-07-13 02:49:59 - train: epoch 0177, iter [03500, 05004], lr: 0.003482, loss: 1.3819
2022-07-13 02:50:34 - train: epoch 0177, iter [03600, 05004], lr: 0.003476, loss: 1.2985
2022-07-13 02:51:10 - train: epoch 0177, iter [03700, 05004], lr: 0.003470, loss: 1.4569
2022-07-13 02:51:44 - train: epoch 0177, iter [03800, 05004], lr: 0.003464, loss: 1.3866
2022-07-13 02:52:19 - train: epoch 0177, iter [03900, 05004], lr: 0.003458, loss: 1.2669
2022-07-13 02:52:55 - train: epoch 0177, iter [04000, 05004], lr: 0.003452, loss: 1.3291
2022-07-13 02:53:30 - train: epoch 0177, iter [04100, 05004], lr: 0.003446, loss: 1.3037
2022-07-13 02:54:06 - train: epoch 0177, iter [04200, 05004], lr: 0.003441, loss: 1.7635
2022-07-13 02:54:40 - train: epoch 0177, iter [04300, 05004], lr: 0.003435, loss: 1.6236
2022-07-13 02:55:16 - train: epoch 0177, iter [04400, 05004], lr: 0.003429, loss: 1.6000
2022-07-13 02:55:51 - train: epoch 0177, iter [04500, 05004], lr: 0.003423, loss: 1.2881
2022-07-13 02:56:26 - train: epoch 0177, iter [04600, 05004], lr: 0.003417, loss: 1.4145
2022-07-13 02:57:01 - train: epoch 0177, iter [04700, 05004], lr: 0.003411, loss: 1.1879
2022-07-13 02:57:36 - train: epoch 0177, iter [04800, 05004], lr: 0.003405, loss: 1.4614
2022-07-13 02:58:11 - train: epoch 0177, iter [04900, 05004], lr: 0.003400, loss: 1.4383
2022-07-13 02:58:46 - train: epoch 0177, iter [05000, 05004], lr: 0.003394, loss: 1.5821
2022-07-13 02:58:47 - train: epoch 177, train_loss: 1.4180
2022-07-13 03:00:02 - eval: epoch: 177, acc1: 75.572%, acc5: 92.902%, test_loss: 0.9709, per_image_load_time: 1.936ms, per_image_inference_time: 0.501ms
2022-07-13 03:00:03 - until epoch: 177, best_acc1: 75.572%
2022-07-13 03:00:03 - epoch 178 lr: 0.003393
2022-07-13 03:00:42 - train: epoch 0178, iter [00100, 05004], lr: 0.003388, loss: 1.0994
2022-07-13 03:01:17 - train: epoch 0178, iter [00200, 05004], lr: 0.003382, loss: 1.4477
2022-07-13 03:01:51 - train: epoch 0178, iter [00300, 05004], lr: 0.003376, loss: 1.4274
2022-07-13 03:02:26 - train: epoch 0178, iter [00400, 05004], lr: 0.003370, loss: 1.5996
2022-07-13 03:03:00 - train: epoch 0178, iter [00500, 05004], lr: 0.003364, loss: 1.2062
2022-07-13 03:03:34 - train: epoch 0178, iter [00600, 05004], lr: 0.003359, loss: 1.3654
2022-07-13 03:04:09 - train: epoch 0178, iter [00700, 05004], lr: 0.003353, loss: 1.2509
2022-07-13 03:04:42 - train: epoch 0178, iter [00800, 05004], lr: 0.003347, loss: 1.4229
2022-07-13 03:05:16 - train: epoch 0178, iter [00900, 05004], lr: 0.003341, loss: 1.3877
2022-07-13 03:05:50 - train: epoch 0178, iter [01000, 05004], lr: 0.003335, loss: 1.4032
2022-07-13 03:06:23 - train: epoch 0178, iter [01100, 05004], lr: 0.003330, loss: 1.4158
2022-07-13 03:06:58 - train: epoch 0178, iter [01200, 05004], lr: 0.003324, loss: 1.4123
2022-07-13 03:07:32 - train: epoch 0178, iter [01300, 05004], lr: 0.003318, loss: 1.3602
2022-07-13 03:08:07 - train: epoch 0178, iter [01400, 05004], lr: 0.003312, loss: 1.3421
2022-07-13 03:08:41 - train: epoch 0178, iter [01500, 05004], lr: 0.003307, loss: 1.6676
2022-07-13 03:09:16 - train: epoch 0178, iter [01600, 05004], lr: 0.003301, loss: 1.4667
2022-07-13 03:09:50 - train: epoch 0178, iter [01700, 05004], lr: 0.003295, loss: 1.4224
2022-07-13 03:10:24 - train: epoch 0178, iter [01800, 05004], lr: 0.003289, loss: 1.3881
2022-07-13 03:10:58 - train: epoch 0178, iter [01900, 05004], lr: 0.003284, loss: 1.2395
2022-07-13 03:11:33 - train: epoch 0178, iter [02000, 05004], lr: 0.003278, loss: 1.4948
2022-07-13 03:12:07 - train: epoch 0178, iter [02100, 05004], lr: 0.003272, loss: 1.5121
2022-07-13 03:12:42 - train: epoch 0178, iter [02200, 05004], lr: 0.003266, loss: 1.2589
2022-07-13 03:13:17 - train: epoch 0178, iter [02300, 05004], lr: 0.003261, loss: 1.3678
2022-07-13 03:13:51 - train: epoch 0178, iter [02400, 05004], lr: 0.003255, loss: 1.2114
2022-07-13 03:14:27 - train: epoch 0178, iter [02500, 05004], lr: 0.003249, loss: 1.0737
2022-07-13 03:15:01 - train: epoch 0178, iter [02600, 05004], lr: 0.003244, loss: 1.1763
2022-07-13 03:15:36 - train: epoch 0178, iter [02700, 05004], lr: 0.003238, loss: 1.3267
2022-07-13 03:16:11 - train: epoch 0178, iter [02800, 05004], lr: 0.003232, loss: 1.2131
2022-07-13 03:16:46 - train: epoch 0178, iter [02900, 05004], lr: 0.003227, loss: 1.3099
2022-07-13 03:17:21 - train: epoch 0178, iter [03000, 05004], lr: 0.003221, loss: 1.4604
2022-07-13 03:17:55 - train: epoch 0178, iter [03100, 05004], lr: 0.003215, loss: 1.5434
2022-07-13 03:18:30 - train: epoch 0178, iter [03200, 05004], lr: 0.003209, loss: 1.4136
2022-07-13 03:19:05 - train: epoch 0178, iter [03300, 05004], lr: 0.003204, loss: 1.3410
2022-07-13 03:19:40 - train: epoch 0178, iter [03400, 05004], lr: 0.003198, loss: 1.3141
2022-07-13 03:20:14 - train: epoch 0178, iter [03500, 05004], lr: 0.003192, loss: 1.5056
2022-07-13 03:20:49 - train: epoch 0178, iter [03600, 05004], lr: 0.003187, loss: 1.4771
2022-07-13 03:21:23 - train: epoch 0178, iter [03700, 05004], lr: 0.003181, loss: 1.6911
2022-07-13 03:21:58 - train: epoch 0178, iter [03800, 05004], lr: 0.003176, loss: 1.5772
2022-07-13 03:22:33 - train: epoch 0178, iter [03900, 05004], lr: 0.003170, loss: 1.4733
2022-07-13 03:23:07 - train: epoch 0178, iter [04000, 05004], lr: 0.003164, loss: 1.6511
2022-07-13 03:23:42 - train: epoch 0178, iter [04100, 05004], lr: 0.003159, loss: 1.3438
2022-07-13 03:24:16 - train: epoch 0178, iter [04200, 05004], lr: 0.003153, loss: 1.3024
2022-07-13 03:24:50 - train: epoch 0178, iter [04300, 05004], lr: 0.003147, loss: 1.4682
2022-07-13 03:25:25 - train: epoch 0178, iter [04400, 05004], lr: 0.003142, loss: 1.3153
2022-07-13 03:25:59 - train: epoch 0178, iter [04500, 05004], lr: 0.003136, loss: 1.6280
2022-07-13 03:26:34 - train: epoch 0178, iter [04600, 05004], lr: 0.003130, loss: 1.5177
2022-07-13 03:27:08 - train: epoch 0178, iter [04700, 05004], lr: 0.003125, loss: 1.4768
2022-07-13 03:27:42 - train: epoch 0178, iter [04800, 05004], lr: 0.003119, loss: 1.3971
2022-07-13 03:28:18 - train: epoch 0178, iter [04900, 05004], lr: 0.003114, loss: 1.4722
2022-07-13 03:28:50 - train: epoch 0178, iter [05000, 05004], lr: 0.003108, loss: 1.4161
2022-07-13 03:28:51 - train: epoch 178, train_loss: 1.4066
2022-07-13 03:30:06 - eval: epoch: 178, acc1: 75.764%, acc5: 92.986%, test_loss: 0.9604, per_image_load_time: 1.793ms, per_image_inference_time: 0.493ms
2022-07-13 03:30:06 - until epoch: 178, best_acc1: 75.764%
2022-07-13 03:30:06 - epoch 179 lr: 0.003108
2022-07-13 03:30:45 - train: epoch 0179, iter [00100, 05004], lr: 0.003102, loss: 1.6113
2022-07-13 03:31:20 - train: epoch 0179, iter [00200, 05004], lr: 0.003097, loss: 1.3136
2022-07-13 03:31:55 - train: epoch 0179, iter [00300, 05004], lr: 0.003091, loss: 1.6342
2022-07-13 03:32:30 - train: epoch 0179, iter [00400, 05004], lr: 0.003086, loss: 1.5235
2022-07-13 03:33:04 - train: epoch 0179, iter [00500, 05004], lr: 0.003080, loss: 1.3302
2022-07-13 03:33:39 - train: epoch 0179, iter [00600, 05004], lr: 0.003074, loss: 1.4135
2022-07-13 03:34:15 - train: epoch 0179, iter [00700, 05004], lr: 0.003069, loss: 1.3130
2022-07-13 03:34:49 - train: epoch 0179, iter [00800, 05004], lr: 0.003063, loss: 1.1251
2022-07-13 03:35:24 - train: epoch 0179, iter [00900, 05004], lr: 0.003058, loss: 1.6154
2022-07-13 03:35:59 - train: epoch 0179, iter [01000, 05004], lr: 0.003052, loss: 1.3927
2022-07-13 03:36:34 - train: epoch 0179, iter [01100, 05004], lr: 0.003047, loss: 1.4322
2022-07-13 03:37:09 - train: epoch 0179, iter [01200, 05004], lr: 0.003041, loss: 1.2380
2022-07-13 03:37:44 - train: epoch 0179, iter [01300, 05004], lr: 0.003036, loss: 1.6482
2022-07-13 03:38:20 - train: epoch 0179, iter [01400, 05004], lr: 0.003030, loss: 1.4054
2022-07-13 03:38:55 - train: epoch 0179, iter [01500, 05004], lr: 0.003025, loss: 1.1051
2022-07-13 03:39:30 - train: epoch 0179, iter [01600, 05004], lr: 0.003019, loss: 1.2248
2022-07-13 03:40:04 - train: epoch 0179, iter [01700, 05004], lr: 0.003014, loss: 1.4258
2022-07-13 03:40:39 - train: epoch 0179, iter [01800, 05004], lr: 0.003008, loss: 1.2185
2022-07-13 03:41:14 - train: epoch 0179, iter [01900, 05004], lr: 0.003003, loss: 1.5163
2022-07-13 03:41:49 - train: epoch 0179, iter [02000, 05004], lr: 0.002997, loss: 1.4491
2022-07-13 03:42:24 - train: epoch 0179, iter [02100, 05004], lr: 0.002992, loss: 1.5987
2022-07-13 03:43:00 - train: epoch 0179, iter [02200, 05004], lr: 0.002986, loss: 1.2853
2022-07-13 03:43:35 - train: epoch 0179, iter [02300, 05004], lr: 0.002981, loss: 1.4003
2022-07-13 03:44:10 - train: epoch 0179, iter [02400, 05004], lr: 0.002975, loss: 1.4079
2022-07-13 03:44:46 - train: epoch 0179, iter [02500, 05004], lr: 0.002970, loss: 1.4699
2022-07-13 03:45:20 - train: epoch 0179, iter [02600, 05004], lr: 0.002964, loss: 1.2158
2022-07-13 03:45:56 - train: epoch 0179, iter [02700, 05004], lr: 0.002959, loss: 1.4344
2022-07-13 03:46:31 - train: epoch 0179, iter [02800, 05004], lr: 0.002953, loss: 1.3346
2022-07-13 03:47:06 - train: epoch 0179, iter [02900, 05004], lr: 0.002948, loss: 1.7819
2022-07-13 03:47:41 - train: epoch 0179, iter [03000, 05004], lr: 0.002942, loss: 1.1355
2022-07-13 03:48:17 - train: epoch 0179, iter [03100, 05004], lr: 0.002937, loss: 1.6117
2022-07-13 03:48:52 - train: epoch 0179, iter [03200, 05004], lr: 0.002932, loss: 1.4954
2022-07-13 03:49:27 - train: epoch 0179, iter [03300, 05004], lr: 0.002926, loss: 1.3347
2022-07-13 03:50:02 - train: epoch 0179, iter [03400, 05004], lr: 0.002921, loss: 1.2055
2022-07-13 03:50:37 - train: epoch 0179, iter [03500, 05004], lr: 0.002915, loss: 1.5644
2022-07-13 03:51:12 - train: epoch 0179, iter [03600, 05004], lr: 0.002910, loss: 1.4394
2022-07-13 03:51:48 - train: epoch 0179, iter [03700, 05004], lr: 0.002904, loss: 1.4808
2022-07-13 03:52:23 - train: epoch 0179, iter [03800, 05004], lr: 0.002899, loss: 1.4323
2022-07-13 03:52:59 - train: epoch 0179, iter [03900, 05004], lr: 0.002894, loss: 1.5018
2022-07-13 03:53:34 - train: epoch 0179, iter [04000, 05004], lr: 0.002888, loss: 1.3677
2022-07-13 03:54:09 - train: epoch 0179, iter [04100, 05004], lr: 0.002883, loss: 1.2209
2022-07-13 03:54:45 - train: epoch 0179, iter [04200, 05004], lr: 0.002878, loss: 1.3538
2022-07-13 03:55:20 - train: epoch 0179, iter [04300, 05004], lr: 0.002872, loss: 1.4050
2022-07-13 03:55:55 - train: epoch 0179, iter [04400, 05004], lr: 0.002867, loss: 1.6081
2022-07-13 03:56:31 - train: epoch 0179, iter [04500, 05004], lr: 0.002861, loss: 1.5265
2022-07-13 03:57:06 - train: epoch 0179, iter [04600, 05004], lr: 0.002856, loss: 1.2804
2022-07-13 03:57:42 - train: epoch 0179, iter [04700, 05004], lr: 0.002851, loss: 1.3085
2022-07-13 03:58:16 - train: epoch 0179, iter [04800, 05004], lr: 0.002845, loss: 1.4544
2022-07-13 03:58:52 - train: epoch 0179, iter [04900, 05004], lr: 0.002840, loss: 1.3486
2022-07-13 03:59:25 - train: epoch 0179, iter [05000, 05004], lr: 0.002835, loss: 1.5127
2022-07-13 03:59:26 - train: epoch 179, train_loss: 1.3911
2022-07-13 04:00:41 - eval: epoch: 179, acc1: 76.152%, acc5: 92.972%, test_loss: 0.9516, per_image_load_time: 2.263ms, per_image_inference_time: 0.501ms
2022-07-13 04:00:42 - until epoch: 179, best_acc1: 76.152%
2022-07-13 04:00:42 - epoch 180 lr: 0.002834
2022-07-13 04:01:21 - train: epoch 0180, iter [00100, 05004], lr: 0.002829, loss: 1.1063
2022-07-13 04:01:56 - train: epoch 0180, iter [00200, 05004], lr: 0.002824, loss: 1.4424
2022-07-13 04:02:31 - train: epoch 0180, iter [00300, 05004], lr: 0.002818, loss: 1.7353
2022-07-13 04:03:06 - train: epoch 0180, iter [00400, 05004], lr: 0.002813, loss: 1.3195
2022-07-13 04:03:41 - train: epoch 0180, iter [00500, 05004], lr: 0.002808, loss: 1.6838
2022-07-13 04:04:15 - train: epoch 0180, iter [00600, 05004], lr: 0.002802, loss: 1.3354
2022-07-13 04:04:50 - train: epoch 0180, iter [00700, 05004], lr: 0.002797, loss: 1.4772
2022-07-13 04:05:24 - train: epoch 0180, iter [00800, 05004], lr: 0.002792, loss: 1.3484
2022-07-13 04:05:59 - train: epoch 0180, iter [00900, 05004], lr: 0.002787, loss: 1.2515
2022-07-13 04:06:32 - train: epoch 0180, iter [01000, 05004], lr: 0.002781, loss: 1.4016
2022-07-13 04:07:06 - train: epoch 0180, iter [01100, 05004], lr: 0.002776, loss: 1.2788
2022-07-13 04:07:40 - train: epoch 0180, iter [01200, 05004], lr: 0.002771, loss: 1.2593
2022-07-13 04:08:14 - train: epoch 0180, iter [01300, 05004], lr: 0.002765, loss: 1.4481
2022-07-13 04:08:48 - train: epoch 0180, iter [01400, 05004], lr: 0.002760, loss: 1.3470
2022-07-13 04:09:23 - train: epoch 0180, iter [01500, 05004], lr: 0.002755, loss: 1.5293
2022-07-13 04:09:57 - train: epoch 0180, iter [01600, 05004], lr: 0.002750, loss: 1.3832
2022-07-13 04:10:31 - train: epoch 0180, iter [01700, 05004], lr: 0.002744, loss: 1.3624
2022-07-13 04:11:06 - train: epoch 0180, iter [01800, 05004], lr: 0.002739, loss: 1.4756
2022-07-13 04:11:41 - train: epoch 0180, iter [01900, 05004], lr: 0.002734, loss: 1.5186
2022-07-13 04:12:16 - train: epoch 0180, iter [02000, 05004], lr: 0.002729, loss: 1.3540
2022-07-13 04:12:50 - train: epoch 0180, iter [02100, 05004], lr: 0.002723, loss: 1.3886
2022-07-13 04:13:24 - train: epoch 0180, iter [02200, 05004], lr: 0.002718, loss: 1.1355
2022-07-13 04:13:58 - train: epoch 0180, iter [02300, 05004], lr: 0.002713, loss: 1.7238
2022-07-13 04:14:33 - train: epoch 0180, iter [02400, 05004], lr: 0.002708, loss: 1.3069
2022-07-13 04:15:07 - train: epoch 0180, iter [02500, 05004], lr: 0.002702, loss: 1.2564
2022-07-13 04:15:41 - train: epoch 0180, iter [02600, 05004], lr: 0.002697, loss: 1.2849
2022-07-13 04:16:15 - train: epoch 0180, iter [02700, 05004], lr: 0.002692, loss: 1.3581
2022-07-13 04:16:49 - train: epoch 0180, iter [02800, 05004], lr: 0.002687, loss: 1.3424
2022-07-13 04:17:24 - train: epoch 0180, iter [02900, 05004], lr: 0.002682, loss: 1.2745
2022-07-13 04:17:58 - train: epoch 0180, iter [03000, 05004], lr: 0.002676, loss: 1.5040
2022-07-13 04:18:32 - train: epoch 0180, iter [03100, 05004], lr: 0.002671, loss: 1.1716
2022-07-13 04:19:06 - train: epoch 0180, iter [03200, 05004], lr: 0.002666, loss: 1.6167
2022-07-13 04:19:40 - train: epoch 0180, iter [03300, 05004], lr: 0.002661, loss: 1.4261
2022-07-13 04:20:15 - train: epoch 0180, iter [03400, 05004], lr: 0.002656, loss: 1.3463
2022-07-13 04:20:50 - train: epoch 0180, iter [03500, 05004], lr: 0.002650, loss: 1.3574
2022-07-13 04:21:24 - train: epoch 0180, iter [03600, 05004], lr: 0.002645, loss: 1.4046
2022-07-13 04:21:59 - train: epoch 0180, iter [03700, 05004], lr: 0.002640, loss: 1.4222
2022-07-13 04:22:33 - train: epoch 0180, iter [03800, 05004], lr: 0.002635, loss: 1.3090
2022-07-13 04:23:07 - train: epoch 0180, iter [03900, 05004], lr: 0.002630, loss: 1.4325
2022-07-13 04:23:42 - train: epoch 0180, iter [04000, 05004], lr: 0.002625, loss: 1.2975
2022-07-13 04:24:17 - train: epoch 0180, iter [04100, 05004], lr: 0.002619, loss: 1.2611
2022-07-13 04:24:51 - train: epoch 0180, iter [04200, 05004], lr: 0.002614, loss: 1.4795
2022-07-13 04:25:26 - train: epoch 0180, iter [04300, 05004], lr: 0.002609, loss: 1.5821
2022-07-13 04:26:01 - train: epoch 0180, iter [04400, 05004], lr: 0.002604, loss: 1.5135
2022-07-13 04:26:35 - train: epoch 0180, iter [04500, 05004], lr: 0.002599, loss: 1.3917
2022-07-13 04:27:10 - train: epoch 0180, iter [04600, 05004], lr: 0.002594, loss: 1.4104
2022-07-13 04:27:44 - train: epoch 0180, iter [04700, 05004], lr: 0.002589, loss: 1.5499
2022-07-13 04:28:19 - train: epoch 0180, iter [04800, 05004], lr: 0.002584, loss: 1.5364
2022-07-13 04:28:54 - train: epoch 0180, iter [04900, 05004], lr: 0.002578, loss: 1.3721
2022-07-13 04:29:27 - train: epoch 0180, iter [05000, 05004], lr: 0.002573, loss: 1.3312
2022-07-13 04:29:28 - train: epoch 180, train_loss: 1.3769
2022-07-13 04:30:43 - eval: epoch: 180, acc1: 76.200%, acc5: 93.068%, test_loss: 0.9543, per_image_load_time: 2.109ms, per_image_inference_time: 0.486ms
2022-07-13 04:30:44 - until epoch: 180, best_acc1: 76.200%
2022-07-13 04:30:44 - epoch 181 lr: 0.002573
2022-07-13 04:31:24 - train: epoch 0181, iter [00100, 05004], lr: 0.002568, loss: 1.5374
2022-07-13 04:31:59 - train: epoch 0181, iter [00200, 05004], lr: 0.002563, loss: 1.5015
2022-07-13 04:32:33 - train: epoch 0181, iter [00300, 05004], lr: 0.002558, loss: 1.4268
2022-07-13 04:33:07 - train: epoch 0181, iter [00400, 05004], lr: 0.002553, loss: 1.0228
2022-07-13 04:33:41 - train: epoch 0181, iter [00500, 05004], lr: 0.002548, loss: 1.2946
2022-07-13 04:34:15 - train: epoch 0181, iter [00600, 05004], lr: 0.002543, loss: 1.4598
2022-07-13 04:34:50 - train: epoch 0181, iter [00700, 05004], lr: 0.002538, loss: 1.2962
2022-07-13 04:35:24 - train: epoch 0181, iter [00800, 05004], lr: 0.002533, loss: 1.3320
2022-07-13 04:35:58 - train: epoch 0181, iter [00900, 05004], lr: 0.002527, loss: 1.2412
2022-07-13 04:36:32 - train: epoch 0181, iter [01000, 05004], lr: 0.002522, loss: 1.1821
2022-07-13 04:37:06 - train: epoch 0181, iter [01100, 05004], lr: 0.002517, loss: 1.2432
2022-07-13 04:37:41 - train: epoch 0181, iter [01200, 05004], lr: 0.002512, loss: 1.1610
2022-07-13 04:38:15 - train: epoch 0181, iter [01300, 05004], lr: 0.002507, loss: 1.4245
2022-07-13 04:38:51 - train: epoch 0181, iter [01400, 05004], lr: 0.002502, loss: 1.3971
2022-07-13 04:39:25 - train: epoch 0181, iter [01500, 05004], lr: 0.002497, loss: 1.4849
2022-07-13 04:40:00 - train: epoch 0181, iter [01600, 05004], lr: 0.002492, loss: 1.4467
2022-07-13 04:40:34 - train: epoch 0181, iter [01700, 05004], lr: 0.002487, loss: 1.3830
2022-07-13 04:41:09 - train: epoch 0181, iter [01800, 05004], lr: 0.002482, loss: 1.2360
2022-07-13 04:41:43 - train: epoch 0181, iter [01900, 05004], lr: 0.002477, loss: 1.3311
2022-07-13 04:42:18 - train: epoch 0181, iter [02000, 05004], lr: 0.002472, loss: 1.5522
2022-07-13 04:42:53 - train: epoch 0181, iter [02100, 05004], lr: 0.002467, loss: 1.4644
2022-07-13 04:43:27 - train: epoch 0181, iter [02200, 05004], lr: 0.002462, loss: 1.4184
2022-07-13 04:44:02 - train: epoch 0181, iter [02300, 05004], lr: 0.002457, loss: 1.6028
2022-07-13 04:44:37 - train: epoch 0181, iter [02400, 05004], lr: 0.002452, loss: 1.3182
2022-07-13 04:45:11 - train: epoch 0181, iter [02500, 05004], lr: 0.002447, loss: 1.2782
2022-07-13 04:45:46 - train: epoch 0181, iter [02600, 05004], lr: 0.002442, loss: 1.2866
2022-07-13 04:46:20 - train: epoch 0181, iter [02700, 05004], lr: 0.002437, loss: 1.2385
2022-07-13 04:46:56 - train: epoch 0181, iter [02800, 05004], lr: 0.002432, loss: 1.3835
2022-07-13 04:47:30 - train: epoch 0181, iter [02900, 05004], lr: 0.002427, loss: 1.3791
2022-07-13 04:48:05 - train: epoch 0181, iter [03000, 05004], lr: 0.002422, loss: 1.4042
2022-07-13 04:48:40 - train: epoch 0181, iter [03100, 05004], lr: 0.002418, loss: 1.4598
2022-07-13 04:49:15 - train: epoch 0181, iter [03200, 05004], lr: 0.002413, loss: 1.3224
2022-07-13 04:49:50 - train: epoch 0181, iter [03300, 05004], lr: 0.002408, loss: 1.5944
2022-07-13 04:50:25 - train: epoch 0181, iter [03400, 05004], lr: 0.002403, loss: 1.6024
2022-07-13 04:50:59 - train: epoch 0181, iter [03500, 05004], lr: 0.002398, loss: 1.2610
2022-07-13 04:51:34 - train: epoch 0181, iter [03600, 05004], lr: 0.002393, loss: 1.6136
2022-07-13 04:52:09 - train: epoch 0181, iter [03700, 05004], lr: 0.002388, loss: 1.2631
2022-07-13 04:52:44 - train: epoch 0181, iter [03800, 05004], lr: 0.002383, loss: 1.3073
2022-07-13 04:53:18 - train: epoch 0181, iter [03900, 05004], lr: 0.002378, loss: 1.4996
2022-07-13 04:53:53 - train: epoch 0181, iter [04000, 05004], lr: 0.002373, loss: 1.3656
2022-07-13 04:54:28 - train: epoch 0181, iter [04100, 05004], lr: 0.002368, loss: 1.1988
2022-07-13 04:55:03 - train: epoch 0181, iter [04200, 05004], lr: 0.002363, loss: 1.3409
2022-07-13 04:55:38 - train: epoch 0181, iter [04300, 05004], lr: 0.002359, loss: 1.4277
2022-07-13 04:56:12 - train: epoch 0181, iter [04400, 05004], lr: 0.002354, loss: 1.7167
2022-07-13 04:56:48 - train: epoch 0181, iter [04500, 05004], lr: 0.002349, loss: 1.4512
2022-07-13 04:57:23 - train: epoch 0181, iter [04600, 05004], lr: 0.002344, loss: 1.4605
2022-07-13 04:57:57 - train: epoch 0181, iter [04700, 05004], lr: 0.002339, loss: 1.5620
2022-07-13 04:58:32 - train: epoch 0181, iter [04800, 05004], lr: 0.002334, loss: 1.3716
2022-07-13 04:59:07 - train: epoch 0181, iter [04900, 05004], lr: 0.002329, loss: 1.2708
2022-07-13 04:59:41 - train: epoch 0181, iter [05000, 05004], lr: 0.002324, loss: 1.3889
2022-07-13 04:59:42 - train: epoch 181, train_loss: 1.3639
2022-07-13 05:00:57 - eval: epoch: 181, acc1: 76.284%, acc5: 93.226%, test_loss: 0.9435, per_image_load_time: 2.013ms, per_image_inference_time: 0.499ms
2022-07-13 05:00:58 - until epoch: 181, best_acc1: 76.284%
2022-07-13 05:00:58 - epoch 182 lr: 0.002324
2022-07-13 05:01:39 - train: epoch 0182, iter [00100, 05004], lr: 0.002319, loss: 1.3032
2022-07-13 05:02:13 - train: epoch 0182, iter [00200, 05004], lr: 0.002315, loss: 1.3843
2022-07-13 05:02:48 - train: epoch 0182, iter [00300, 05004], lr: 0.002310, loss: 1.1553
2022-07-13 05:03:22 - train: epoch 0182, iter [00400, 05004], lr: 0.002305, loss: 1.3728
2022-07-13 05:03:57 - train: epoch 0182, iter [00500, 05004], lr: 0.002300, loss: 1.4084
2022-07-13 05:04:32 - train: epoch 0182, iter [00600, 05004], lr: 0.002295, loss: 1.0140
2022-07-13 05:05:06 - train: epoch 0182, iter [00700, 05004], lr: 0.002290, loss: 1.1253
2022-07-13 05:05:41 - train: epoch 0182, iter [00800, 05004], lr: 0.002286, loss: 1.3402
2022-07-13 05:06:17 - train: epoch 0182, iter [00900, 05004], lr: 0.002281, loss: 1.2897
2022-07-13 05:06:51 - train: epoch 0182, iter [01000, 05004], lr: 0.002276, loss: 1.2284
2022-07-13 05:07:26 - train: epoch 0182, iter [01100, 05004], lr: 0.002271, loss: 1.4365
2022-07-13 05:08:02 - train: epoch 0182, iter [01200, 05004], lr: 0.002266, loss: 1.4228
2022-07-13 05:08:37 - train: epoch 0182, iter [01300, 05004], lr: 0.002262, loss: 1.2571
2022-07-13 05:09:12 - train: epoch 0182, iter [01400, 05004], lr: 0.002257, loss: 1.5423
2022-07-13 05:09:47 - train: epoch 0182, iter [01500, 05004], lr: 0.002252, loss: 1.5825
2022-07-13 05:10:22 - train: epoch 0182, iter [01600, 05004], lr: 0.002247, loss: 1.4658
2022-07-13 05:10:58 - train: epoch 0182, iter [01700, 05004], lr: 0.002243, loss: 1.6029
2022-07-13 05:11:33 - train: epoch 0182, iter [01800, 05004], lr: 0.002238, loss: 1.6193
2022-07-13 05:12:09 - train: epoch 0182, iter [01900, 05004], lr: 0.002233, loss: 1.3565
2022-07-13 05:12:43 - train: epoch 0182, iter [02000, 05004], lr: 0.002228, loss: 1.2787
2022-07-13 05:13:19 - train: epoch 0182, iter [02100, 05004], lr: 0.002223, loss: 1.5564
2022-07-13 05:13:53 - train: epoch 0182, iter [02200, 05004], lr: 0.002219, loss: 1.4514
2022-07-13 05:14:27 - train: epoch 0182, iter [02300, 05004], lr: 0.002214, loss: 1.3237
2022-07-13 05:15:02 - train: epoch 0182, iter [02400, 05004], lr: 0.002209, loss: 1.4518
2022-07-13 05:15:38 - train: epoch 0182, iter [02500, 05004], lr: 0.002205, loss: 1.0991
2022-07-13 05:16:11 - train: epoch 0182, iter [02600, 05004], lr: 0.002200, loss: 1.3240
2022-07-13 05:16:47 - train: epoch 0182, iter [02700, 05004], lr: 0.002195, loss: 1.0558
2022-07-13 05:17:21 - train: epoch 0182, iter [02800, 05004], lr: 0.002190, loss: 1.2346
2022-07-13 05:17:56 - train: epoch 0182, iter [02900, 05004], lr: 0.002186, loss: 1.3533
2022-07-13 05:18:31 - train: epoch 0182, iter [03000, 05004], lr: 0.002181, loss: 1.3081
2022-07-13 05:19:05 - train: epoch 0182, iter [03100, 05004], lr: 0.002176, loss: 1.2813
2022-07-13 05:19:40 - train: epoch 0182, iter [03200, 05004], lr: 0.002172, loss: 1.3832
2022-07-13 05:20:15 - train: epoch 0182, iter [03300, 05004], lr: 0.002167, loss: 1.3942
2022-07-13 05:20:50 - train: epoch 0182, iter [03400, 05004], lr: 0.002162, loss: 1.4869
2022-07-13 05:21:25 - train: epoch 0182, iter [03500, 05004], lr: 0.002158, loss: 1.4376
2022-07-13 05:21:59 - train: epoch 0182, iter [03600, 05004], lr: 0.002153, loss: 1.3723
2022-07-13 05:22:35 - train: epoch 0182, iter [03700, 05004], lr: 0.002148, loss: 1.4293
2022-07-13 05:23:09 - train: epoch 0182, iter [03800, 05004], lr: 0.002143, loss: 1.4624
2022-07-13 05:23:44 - train: epoch 0182, iter [03900, 05004], lr: 0.002139, loss: 1.4079
2022-07-13 05:24:19 - train: epoch 0182, iter [04000, 05004], lr: 0.002134, loss: 1.0986
2022-07-13 05:24:53 - train: epoch 0182, iter [04100, 05004], lr: 0.002130, loss: 1.4906
2022-07-13 05:25:29 - train: epoch 0182, iter [04200, 05004], lr: 0.002125, loss: 1.3348
2022-07-13 05:26:03 - train: epoch 0182, iter [04300, 05004], lr: 0.002120, loss: 1.4787
2022-07-13 05:26:38 - train: epoch 0182, iter [04400, 05004], lr: 0.002116, loss: 1.4134
2022-07-13 05:27:13 - train: epoch 0182, iter [04500, 05004], lr: 0.002111, loss: 1.1895
2022-07-13 05:27:48 - train: epoch 0182, iter [04600, 05004], lr: 0.002106, loss: 1.3304
2022-07-13 05:28:23 - train: epoch 0182, iter [04700, 05004], lr: 0.002102, loss: 1.3737
2022-07-13 05:28:58 - train: epoch 0182, iter [04800, 05004], lr: 0.002097, loss: 1.6688
2022-07-13 05:29:34 - train: epoch 0182, iter [04900, 05004], lr: 0.002092, loss: 1.2098
2022-07-13 05:30:07 - train: epoch 0182, iter [05000, 05004], lr: 0.002088, loss: 1.0794
2022-07-13 05:30:08 - train: epoch 182, train_loss: 1.3520
2022-07-13 05:31:24 - eval: epoch: 182, acc1: 76.574%, acc5: 93.278%, test_loss: 0.9353, per_image_load_time: 2.352ms, per_image_inference_time: 0.506ms
2022-07-13 05:31:24 - until epoch: 182, best_acc1: 76.574%
2022-07-13 05:31:24 - epoch 183 lr: 0.002088
2022-07-13 05:32:04 - train: epoch 0183, iter [00100, 05004], lr: 0.002083, loss: 1.2404
2022-07-13 05:32:38 - train: epoch 0183, iter [00200, 05004], lr: 0.002079, loss: 1.1989
2022-07-13 05:33:13 - train: epoch 0183, iter [00300, 05004], lr: 0.002074, loss: 1.1794
2022-07-13 05:33:47 - train: epoch 0183, iter [00400, 05004], lr: 0.002069, loss: 1.2306
2022-07-13 05:34:21 - train: epoch 0183, iter [00500, 05004], lr: 0.002065, loss: 1.4610
2022-07-13 05:34:55 - train: epoch 0183, iter [00600, 05004], lr: 0.002060, loss: 1.2480
2022-07-13 05:35:30 - train: epoch 0183, iter [00700, 05004], lr: 0.002056, loss: 1.4565
2022-07-13 05:36:04 - train: epoch 0183, iter [00800, 05004], lr: 0.002051, loss: 1.4918
2022-07-13 05:36:39 - train: epoch 0183, iter [00900, 05004], lr: 0.002046, loss: 1.4533
2022-07-13 05:37:12 - train: epoch 0183, iter [01000, 05004], lr: 0.002042, loss: 1.4307
2022-07-13 05:37:47 - train: epoch 0183, iter [01100, 05004], lr: 0.002037, loss: 1.6147
2022-07-13 05:38:21 - train: epoch 0183, iter [01200, 05004], lr: 0.002033, loss: 1.7264
2022-07-13 05:38:55 - train: epoch 0183, iter [01300, 05004], lr: 0.002028, loss: 1.2876
2022-07-13 05:39:28 - train: epoch 0183, iter [01400, 05004], lr: 0.002024, loss: 1.2160
2022-07-13 05:40:03 - train: epoch 0183, iter [01500, 05004], lr: 0.002019, loss: 1.4554
2022-07-13 05:40:38 - train: epoch 0183, iter [01600, 05004], lr: 0.002015, loss: 1.1690
2022-07-13 05:41:12 - train: epoch 0183, iter [01700, 05004], lr: 0.002010, loss: 1.1950
2022-07-13 05:41:46 - train: epoch 0183, iter [01800, 05004], lr: 0.002006, loss: 1.2828
2022-07-13 05:42:20 - train: epoch 0183, iter [01900, 05004], lr: 0.002001, loss: 1.0579
2022-07-13 05:42:55 - train: epoch 0183, iter [02000, 05004], lr: 0.001997, loss: 1.3809
2022-07-13 05:43:29 - train: epoch 0183, iter [02100, 05004], lr: 0.001992, loss: 1.3197
2022-07-13 05:44:03 - train: epoch 0183, iter [02200, 05004], lr: 0.001988, loss: 1.5144
2022-07-13 05:44:39 - train: epoch 0183, iter [02300, 05004], lr: 0.001983, loss: 1.3484
2022-07-13 05:45:13 - train: epoch 0183, iter [02400, 05004], lr: 0.001979, loss: 1.5234
2022-07-13 05:45:49 - train: epoch 0183, iter [02500, 05004], lr: 0.001974, loss: 1.1479
2022-07-13 05:46:23 - train: epoch 0183, iter [02600, 05004], lr: 0.001970, loss: 1.5598
2022-07-13 05:46:57 - train: epoch 0183, iter [02700, 05004], lr: 0.001965, loss: 1.5723
2022-07-13 05:47:32 - train: epoch 0183, iter [02800, 05004], lr: 0.001961, loss: 1.4022
2022-07-13 05:48:07 - train: epoch 0183, iter [02900, 05004], lr: 0.001956, loss: 1.4011
2022-07-13 05:48:42 - train: epoch 0183, iter [03000, 05004], lr: 0.001952, loss: 1.5227
2022-07-13 05:49:17 - train: epoch 0183, iter [03100, 05004], lr: 0.001947, loss: 1.0364
2022-07-13 05:49:51 - train: epoch 0183, iter [03200, 05004], lr: 0.001943, loss: 1.2212
2022-07-13 05:50:26 - train: epoch 0183, iter [03300, 05004], lr: 0.001939, loss: 1.1459
2022-07-13 05:51:02 - train: epoch 0183, iter [03400, 05004], lr: 0.001934, loss: 1.2956
2022-07-13 05:51:37 - train: epoch 0183, iter [03500, 05004], lr: 0.001930, loss: 1.3660
2022-07-13 05:52:12 - train: epoch 0183, iter [03600, 05004], lr: 0.001925, loss: 1.4939
2022-07-13 05:52:47 - train: epoch 0183, iter [03700, 05004], lr: 0.001921, loss: 1.5417
2022-07-13 05:53:22 - train: epoch 0183, iter [03800, 05004], lr: 0.001916, loss: 1.1123
2022-07-13 05:53:57 - train: epoch 0183, iter [03900, 05004], lr: 0.001912, loss: 1.5336
2022-07-13 05:54:32 - train: epoch 0183, iter [04000, 05004], lr: 0.001908, loss: 1.1544
2022-07-13 05:55:07 - train: epoch 0183, iter [04100, 05004], lr: 0.001903, loss: 1.5023
2022-07-13 05:55:42 - train: epoch 0183, iter [04200, 05004], lr: 0.001899, loss: 1.3342
2022-07-13 05:56:16 - train: epoch 0183, iter [04300, 05004], lr: 0.001894, loss: 1.4096
2022-07-13 05:56:51 - train: epoch 0183, iter [04400, 05004], lr: 0.001890, loss: 1.3620
2022-07-13 05:57:26 - train: epoch 0183, iter [04500, 05004], lr: 0.001886, loss: 1.4802
2022-07-13 05:58:02 - train: epoch 0183, iter [04600, 05004], lr: 0.001881, loss: 1.3096
2022-07-13 05:58:37 - train: epoch 0183, iter [04700, 05004], lr: 0.001877, loss: 1.5163
2022-07-13 05:59:12 - train: epoch 0183, iter [04800, 05004], lr: 0.001872, loss: 1.2064
2022-07-13 05:59:47 - train: epoch 0183, iter [04900, 05004], lr: 0.001868, loss: 1.2678
2022-07-13 06:00:21 - train: epoch 0183, iter [05000, 05004], lr: 0.001864, loss: 1.3106
2022-07-13 06:00:22 - train: epoch 183, train_loss: 1.3376
2022-07-13 06:01:38 - eval: epoch: 183, acc1: 76.612%, acc5: 93.228%, test_loss: 0.9399, per_image_load_time: 2.453ms, per_image_inference_time: 0.480ms
2022-07-13 06:01:38 - until epoch: 183, best_acc1: 76.612%
2022-07-13 06:01:38 - epoch 184 lr: 0.001864
2022-07-13 06:02:18 - train: epoch 0184, iter [00100, 05004], lr: 0.001859, loss: 1.4780
2022-07-13 06:02:53 - train: epoch 0184, iter [00200, 05004], lr: 0.001855, loss: 1.2584
2022-07-13 06:03:28 - train: epoch 0184, iter [00300, 05004], lr: 0.001851, loss: 1.3491
2022-07-13 06:04:03 - train: epoch 0184, iter [00400, 05004], lr: 0.001846, loss: 1.4282
2022-07-13 06:04:37 - train: epoch 0184, iter [00500, 05004], lr: 0.001842, loss: 1.4602
2022-07-13 06:05:11 - train: epoch 0184, iter [00600, 05004], lr: 0.001838, loss: 1.3020
2022-07-13 06:05:46 - train: epoch 0184, iter [00700, 05004], lr: 0.001833, loss: 1.3652
2022-07-13 06:06:21 - train: epoch 0184, iter [00800, 05004], lr: 0.001829, loss: 1.0894
2022-07-13 06:06:56 - train: epoch 0184, iter [00900, 05004], lr: 0.001825, loss: 1.1668
2022-07-13 06:07:32 - train: epoch 0184, iter [01000, 05004], lr: 0.001820, loss: 0.8296
2022-07-13 06:08:06 - train: epoch 0184, iter [01100, 05004], lr: 0.001816, loss: 1.3388
2022-07-13 06:08:42 - train: epoch 0184, iter [01200, 05004], lr: 0.001812, loss: 1.2810
2022-07-13 06:09:16 - train: epoch 0184, iter [01300, 05004], lr: 0.001807, loss: 1.4532
2022-07-13 06:09:50 - train: epoch 0184, iter [01400, 05004], lr: 0.001803, loss: 1.1526
2022-07-13 06:10:25 - train: epoch 0184, iter [01500, 05004], lr: 0.001799, loss: 1.5049
2022-07-13 06:10:59 - train: epoch 0184, iter [01600, 05004], lr: 0.001795, loss: 1.3147
2022-07-13 06:11:34 - train: epoch 0184, iter [01700, 05004], lr: 0.001790, loss: 1.5251
2022-07-13 06:12:09 - train: epoch 0184, iter [01800, 05004], lr: 0.001786, loss: 1.3667
2022-07-13 06:12:44 - train: epoch 0184, iter [01900, 05004], lr: 0.001782, loss: 1.0099
2022-07-13 06:13:18 - train: epoch 0184, iter [02000, 05004], lr: 0.001778, loss: 1.1363
2022-07-13 06:13:53 - train: epoch 0184, iter [02100, 05004], lr: 0.001773, loss: 1.4797
2022-07-13 06:14:28 - train: epoch 0184, iter [02200, 05004], lr: 0.001769, loss: 1.4922
2022-07-13 06:15:02 - train: epoch 0184, iter [02300, 05004], lr: 0.001765, loss: 1.5435
2022-07-13 06:15:37 - train: epoch 0184, iter [02400, 05004], lr: 0.001761, loss: 1.3361
2022-07-13 06:16:11 - train: epoch 0184, iter [02500, 05004], lr: 0.001756, loss: 1.3067
2022-07-13 06:16:47 - train: epoch 0184, iter [02600, 05004], lr: 0.001752, loss: 1.3242
2022-07-13 06:17:21 - train: epoch 0184, iter [02700, 05004], lr: 0.001748, loss: 1.5824
2022-07-13 06:17:57 - train: epoch 0184, iter [02800, 05004], lr: 0.001744, loss: 1.3470
2022-07-13 06:18:30 - train: epoch 0184, iter [02900, 05004], lr: 0.001739, loss: 1.4706
2022-07-13 06:19:06 - train: epoch 0184, iter [03000, 05004], lr: 0.001735, loss: 1.2296
2022-07-13 06:19:41 - train: epoch 0184, iter [03100, 05004], lr: 0.001731, loss: 1.5303
2022-07-13 06:20:16 - train: epoch 0184, iter [03200, 05004], lr: 0.001727, loss: 1.2324
2022-07-13 06:20:51 - train: epoch 0184, iter [03300, 05004], lr: 0.001723, loss: 1.3853
2022-07-13 06:21:26 - train: epoch 0184, iter [03400, 05004], lr: 0.001718, loss: 1.2074
2022-07-13 06:22:01 - train: epoch 0184, iter [03500, 05004], lr: 0.001714, loss: 1.3408
2022-07-13 06:22:36 - train: epoch 0184, iter [03600, 05004], lr: 0.001710, loss: 1.2207
2022-07-13 06:23:11 - train: epoch 0184, iter [03700, 05004], lr: 0.001706, loss: 1.4225
2022-07-13 06:23:46 - train: epoch 0184, iter [03800, 05004], lr: 0.001702, loss: 1.3480
2022-07-13 06:24:21 - train: epoch 0184, iter [03900, 05004], lr: 0.001698, loss: 1.4538
2022-07-13 06:24:56 - train: epoch 0184, iter [04000, 05004], lr: 0.001693, loss: 1.8306
2022-07-13 06:25:31 - train: epoch 0184, iter [04100, 05004], lr: 0.001689, loss: 1.3218
2022-07-13 06:26:06 - train: epoch 0184, iter [04200, 05004], lr: 0.001685, loss: 1.2154
2022-07-13 06:26:41 - train: epoch 0184, iter [04300, 05004], lr: 0.001681, loss: 1.4310
2022-07-13 06:27:17 - train: epoch 0184, iter [04400, 05004], lr: 0.001677, loss: 1.1859
2022-07-13 06:27:52 - train: epoch 0184, iter [04500, 05004], lr: 0.001673, loss: 1.3947
2022-07-13 06:28:27 - train: epoch 0184, iter [04600, 05004], lr: 0.001669, loss: 1.2790
2022-07-13 06:29:01 - train: epoch 0184, iter [04700, 05004], lr: 0.001664, loss: 1.3219
2022-07-13 06:29:37 - train: epoch 0184, iter [04800, 05004], lr: 0.001660, loss: 1.3760
2022-07-13 06:30:12 - train: epoch 0184, iter [04900, 05004], lr: 0.001656, loss: 1.3621
2022-07-13 06:30:45 - train: epoch 0184, iter [05000, 05004], lr: 0.001652, loss: 1.3857
2022-07-13 06:30:46 - train: epoch 184, train_loss: 1.3268
2022-07-13 06:32:02 - eval: epoch: 184, acc1: 76.738%, acc5: 93.398%, test_loss: 0.9305, per_image_load_time: 2.258ms, per_image_inference_time: 0.497ms
2022-07-13 06:32:02 - until epoch: 184, best_acc1: 76.738%
2022-07-13 06:32:02 - epoch 185 lr: 0.001652
2022-07-13 06:32:42 - train: epoch 0185, iter [00100, 05004], lr: 0.001648, loss: 1.3603
2022-07-13 06:33:17 - train: epoch 0185, iter [00200, 05004], lr: 0.001644, loss: 1.1625
2022-07-13 06:33:51 - train: epoch 0185, iter [00300, 05004], lr: 0.001640, loss: 1.3354
2022-07-13 06:34:26 - train: epoch 0185, iter [00400, 05004], lr: 0.001636, loss: 1.1193
2022-07-13 06:34:59 - train: epoch 0185, iter [00500, 05004], lr: 0.001632, loss: 1.5315
2022-07-13 06:35:34 - train: epoch 0185, iter [00600, 05004], lr: 0.001627, loss: 1.5858
2022-07-13 06:36:09 - train: epoch 0185, iter [00700, 05004], lr: 0.001623, loss: 1.1747
2022-07-13 06:36:43 - train: epoch 0185, iter [00800, 05004], lr: 0.001619, loss: 1.4151
2022-07-13 06:37:17 - train: epoch 0185, iter [00900, 05004], lr: 0.001615, loss: 1.1115
2022-07-13 06:37:51 - train: epoch 0185, iter [01000, 05004], lr: 0.001611, loss: 1.1410
2022-07-13 06:38:25 - train: epoch 0185, iter [01100, 05004], lr: 0.001607, loss: 1.1158
2022-07-13 06:38:59 - train: epoch 0185, iter [01200, 05004], lr: 0.001603, loss: 1.3833
2022-07-13 06:39:34 - train: epoch 0185, iter [01300, 05004], lr: 0.001599, loss: 1.1543
2022-07-13 06:40:07 - train: epoch 0185, iter [01400, 05004], lr: 0.001595, loss: 1.1346
2022-07-13 06:40:41 - train: epoch 0185, iter [01500, 05004], lr: 0.001591, loss: 1.3637
2022-07-13 06:41:15 - train: epoch 0185, iter [01600, 05004], lr: 0.001587, loss: 1.2845
2022-07-13 06:41:49 - train: epoch 0185, iter [01700, 05004], lr: 0.001583, loss: 1.1346
2022-07-13 06:42:24 - train: epoch 0185, iter [01800, 05004], lr: 0.001579, loss: 1.5795
2022-07-13 06:42:58 - train: epoch 0185, iter [01900, 05004], lr: 0.001575, loss: 1.4279
2022-07-13 06:43:32 - train: epoch 0185, iter [02000, 05004], lr: 0.001571, loss: 1.0014
2022-07-13 06:44:06 - train: epoch 0185, iter [02100, 05004], lr: 0.001567, loss: 1.2093
2022-07-13 06:44:40 - train: epoch 0185, iter [02200, 05004], lr: 0.001563, loss: 1.5663
2022-07-13 06:45:14 - train: epoch 0185, iter [02300, 05004], lr: 0.001559, loss: 1.2474
2022-07-13 06:45:48 - train: epoch 0185, iter [02400, 05004], lr: 0.001555, loss: 1.4954
2022-07-13 06:46:22 - train: epoch 0185, iter [02500, 05004], lr: 0.001551, loss: 1.2138
2022-07-13 06:46:57 - train: epoch 0185, iter [02600, 05004], lr: 0.001547, loss: 1.0687
2022-07-13 06:47:31 - train: epoch 0185, iter [02700, 05004], lr: 0.001543, loss: 1.2265
2022-07-13 06:48:06 - train: epoch 0185, iter [02800, 05004], lr: 0.001539, loss: 1.5481
2022-07-13 06:48:39 - train: epoch 0185, iter [02900, 05004], lr: 0.001535, loss: 1.1006
2022-07-13 06:49:15 - train: epoch 0185, iter [03000, 05004], lr: 0.001531, loss: 1.2122
2022-07-13 06:49:49 - train: epoch 0185, iter [03100, 05004], lr: 0.001527, loss: 1.4793
2022-07-13 06:50:23 - train: epoch 0185, iter [03200, 05004], lr: 0.001523, loss: 1.1151
2022-07-13 06:50:59 - train: epoch 0185, iter [03300, 05004], lr: 0.001519, loss: 1.1079
2022-07-13 06:51:33 - train: epoch 0185, iter [03400, 05004], lr: 0.001515, loss: 1.2507
2022-07-13 06:52:08 - train: epoch 0185, iter [03500, 05004], lr: 0.001511, loss: 1.3415
2022-07-13 06:52:42 - train: epoch 0185, iter [03600, 05004], lr: 0.001507, loss: 1.1947
2022-07-13 06:53:17 - train: epoch 0185, iter [03700, 05004], lr: 0.001504, loss: 1.0984
2022-07-13 06:53:52 - train: epoch 0185, iter [03800, 05004], lr: 0.001500, loss: 1.1861
2022-07-13 06:54:27 - train: epoch 0185, iter [03900, 05004], lr: 0.001496, loss: 1.3334
2022-07-13 06:55:01 - train: epoch 0185, iter [04000, 05004], lr: 0.001492, loss: 1.1932
2022-07-13 06:55:36 - train: epoch 0185, iter [04100, 05004], lr: 0.001488, loss: 1.5741
2022-07-13 06:56:10 - train: epoch 0185, iter [04200, 05004], lr: 0.001484, loss: 1.4434
2022-07-13 06:56:45 - train: epoch 0185, iter [04300, 05004], lr: 0.001480, loss: 1.2531
2022-07-13 06:57:19 - train: epoch 0185, iter [04400, 05004], lr: 0.001476, loss: 1.5433
2022-07-13 06:57:54 - train: epoch 0185, iter [04500, 05004], lr: 0.001472, loss: 1.4429
2022-07-13 06:58:28 - train: epoch 0185, iter [04600, 05004], lr: 0.001469, loss: 1.1685
2022-07-13 06:59:04 - train: epoch 0185, iter [04700, 05004], lr: 0.001465, loss: 1.4596
2022-07-13 06:59:38 - train: epoch 0185, iter [04800, 05004], lr: 0.001461, loss: 1.2548
2022-07-13 07:00:13 - train: epoch 0185, iter [04900, 05004], lr: 0.001457, loss: 1.2306
2022-07-13 07:00:47 - train: epoch 0185, iter [05000, 05004], lr: 0.001453, loss: 1.3026
2022-07-13 07:00:48 - train: epoch 185, train_loss: 1.3107
2022-07-13 07:02:04 - eval: epoch: 185, acc1: 76.900%, acc5: 93.436%, test_loss: 0.9192, per_image_load_time: 2.254ms, per_image_inference_time: 0.468ms
2022-07-13 07:02:05 - until epoch: 185, best_acc1: 76.900%
2022-07-13 07:02:05 - epoch 186 lr: 0.001453
2022-07-13 07:02:45 - train: epoch 0186, iter [00100, 05004], lr: 0.001449, loss: 1.6376
2022-07-13 07:03:20 - train: epoch 0186, iter [00200, 05004], lr: 0.001445, loss: 1.4015
2022-07-13 07:03:55 - train: epoch 0186, iter [00300, 05004], lr: 0.001441, loss: 1.2768
2022-07-13 07:04:29 - train: epoch 0186, iter [00400, 05004], lr: 0.001438, loss: 1.2332
2022-07-13 07:05:04 - train: epoch 0186, iter [00500, 05004], lr: 0.001434, loss: 1.3587
2022-07-13 07:05:39 - train: epoch 0186, iter [00600, 05004], lr: 0.001430, loss: 1.3907
2022-07-13 07:06:13 - train: epoch 0186, iter [00700, 05004], lr: 0.001426, loss: 1.1639
2022-07-13 07:06:49 - train: epoch 0186, iter [00800, 05004], lr: 0.001422, loss: 1.2684
2022-07-13 07:07:23 - train: epoch 0186, iter [00900, 05004], lr: 0.001418, loss: 1.2205
2022-07-13 07:07:58 - train: epoch 0186, iter [01000, 05004], lr: 0.001415, loss: 1.1277
2022-07-13 07:08:34 - train: epoch 0186, iter [01100, 05004], lr: 0.001411, loss: 1.2634
2022-07-13 07:09:08 - train: epoch 0186, iter [01200, 05004], lr: 0.001407, loss: 1.3694
2022-07-13 07:09:44 - train: epoch 0186, iter [01300, 05004], lr: 0.001403, loss: 1.3277
2022-07-13 07:10:18 - train: epoch 0186, iter [01400, 05004], lr: 0.001399, loss: 1.1747
2022-07-13 07:10:52 - train: epoch 0186, iter [01500, 05004], lr: 0.001396, loss: 1.1824
2022-07-13 07:11:26 - train: epoch 0186, iter [01600, 05004], lr: 0.001392, loss: 1.2713
2022-07-13 07:12:01 - train: epoch 0186, iter [01700, 05004], lr: 0.001388, loss: 1.2475
2022-07-13 07:12:36 - train: epoch 0186, iter [01800, 05004], lr: 0.001384, loss: 1.1986
2022-07-13 07:13:10 - train: epoch 0186, iter [01900, 05004], lr: 0.001381, loss: 1.1413
2022-07-13 07:13:45 - train: epoch 0186, iter [02000, 05004], lr: 0.001377, loss: 1.3233
2022-07-13 07:14:19 - train: epoch 0186, iter [02100, 05004], lr: 0.001373, loss: 1.2838
2022-07-13 07:14:53 - train: epoch 0186, iter [02200, 05004], lr: 0.001369, loss: 1.4199
2022-07-13 07:15:27 - train: epoch 0186, iter [02300, 05004], lr: 0.001366, loss: 1.2251
2022-07-13 07:16:01 - train: epoch 0186, iter [02400, 05004], lr: 0.001362, loss: 1.3674
2022-07-13 07:16:36 - train: epoch 0186, iter [02500, 05004], lr: 0.001358, loss: 1.3740
2022-07-13 07:17:11 - train: epoch 0186, iter [02600, 05004], lr: 0.001354, loss: 1.3963
2022-07-13 07:17:45 - train: epoch 0186, iter [02700, 05004], lr: 0.001351, loss: 1.4799
2022-07-13 07:18:20 - train: epoch 0186, iter [02800, 05004], lr: 0.001347, loss: 1.3752
2022-07-13 07:18:54 - train: epoch 0186, iter [02900, 05004], lr: 0.001343, loss: 1.2535
2022-07-13 07:19:28 - train: epoch 0186, iter [03000, 05004], lr: 0.001340, loss: 1.5332
2022-07-13 07:20:03 - train: epoch 0186, iter [03100, 05004], lr: 0.001336, loss: 1.1927
2022-07-13 07:20:38 - train: epoch 0186, iter [03200, 05004], lr: 0.001332, loss: 1.4404
2022-07-13 07:21:12 - train: epoch 0186, iter [03300, 05004], lr: 0.001329, loss: 1.1844
2022-07-13 07:21:47 - train: epoch 0186, iter [03400, 05004], lr: 0.001325, loss: 1.4738
2022-07-13 07:22:22 - train: epoch 0186, iter [03500, 05004], lr: 0.001321, loss: 1.4673
2022-07-13 07:22:56 - train: epoch 0186, iter [03600, 05004], lr: 0.001317, loss: 1.2867
2022-07-13 07:23:31 - train: epoch 0186, iter [03700, 05004], lr: 0.001314, loss: 1.3957
2022-07-13 07:24:05 - train: epoch 0186, iter [03800, 05004], lr: 0.001310, loss: 1.0491
2022-07-13 07:24:41 - train: epoch 0186, iter [03900, 05004], lr: 0.001306, loss: 1.1853
2022-07-13 07:25:16 - train: epoch 0186, iter [04000, 05004], lr: 0.001303, loss: 1.3210
2022-07-13 07:25:50 - train: epoch 0186, iter [04100, 05004], lr: 0.001299, loss: 1.1574
2022-07-13 07:26:25 - train: epoch 0186, iter [04200, 05004], lr: 0.001296, loss: 1.3107
2022-07-13 07:27:00 - train: epoch 0186, iter [04300, 05004], lr: 0.001292, loss: 1.1367
2022-07-13 07:27:35 - train: epoch 0186, iter [04400, 05004], lr: 0.001288, loss: 1.2618
2022-07-13 07:28:10 - train: epoch 0186, iter [04500, 05004], lr: 0.001285, loss: 1.2410
2022-07-13 07:28:45 - train: epoch 0186, iter [04600, 05004], lr: 0.001281, loss: 1.3019
2022-07-13 07:29:20 - train: epoch 0186, iter [04700, 05004], lr: 0.001277, loss: 1.5228
2022-07-13 07:29:55 - train: epoch 0186, iter [04800, 05004], lr: 0.001274, loss: 1.4174
2022-07-13 07:30:30 - train: epoch 0186, iter [04900, 05004], lr: 0.001270, loss: 1.2599
2022-07-13 07:31:04 - train: epoch 0186, iter [05000, 05004], lr: 0.001267, loss: 1.4074
2022-07-13 07:31:05 - train: epoch 186, train_loss: 1.2990
2022-07-13 07:32:21 - eval: epoch: 186, acc1: 77.016%, acc5: 93.456%, test_loss: 0.9142, per_image_load_time: 1.640ms, per_image_inference_time: 0.511ms
2022-07-13 07:32:22 - until epoch: 186, best_acc1: 77.016%
2022-07-13 07:32:22 - epoch 187 lr: 0.001266
2022-07-13 07:33:02 - train: epoch 0187, iter [00100, 05004], lr: 0.001263, loss: 1.4677
2022-07-13 07:33:35 - train: epoch 0187, iter [00200, 05004], lr: 0.001259, loss: 1.2706
2022-07-13 07:34:09 - train: epoch 0187, iter [00300, 05004], lr: 0.001256, loss: 1.4869
2022-07-13 07:34:44 - train: epoch 0187, iter [00400, 05004], lr: 0.001252, loss: 1.1958
2022-07-13 07:35:17 - train: epoch 0187, iter [00500, 05004], lr: 0.001249, loss: 1.1833
2022-07-13 07:35:51 - train: epoch 0187, iter [00600, 05004], lr: 0.001245, loss: 1.3515
2022-07-13 07:36:26 - train: epoch 0187, iter [00700, 05004], lr: 0.001241, loss: 1.1803
2022-07-13 07:37:00 - train: epoch 0187, iter [00800, 05004], lr: 0.001238, loss: 1.5694
2022-07-13 07:37:34 - train: epoch 0187, iter [00900, 05004], lr: 0.001234, loss: 1.5728
2022-07-13 07:38:08 - train: epoch 0187, iter [01000, 05004], lr: 0.001231, loss: 1.3608
2022-07-13 07:38:43 - train: epoch 0187, iter [01100, 05004], lr: 0.001227, loss: 1.2311
2022-07-13 07:39:18 - train: epoch 0187, iter [01200, 05004], lr: 0.001224, loss: 1.3047
2022-07-13 07:39:51 - train: epoch 0187, iter [01300, 05004], lr: 0.001220, loss: 1.4271
2022-07-13 07:40:25 - train: epoch 0187, iter [01400, 05004], lr: 0.001217, loss: 1.2493
2022-07-13 07:41:00 - train: epoch 0187, iter [01500, 05004], lr: 0.001213, loss: 1.4045
2022-07-13 07:41:34 - train: epoch 0187, iter [01600, 05004], lr: 0.001209, loss: 1.2232
2022-07-13 07:42:09 - train: epoch 0187, iter [01700, 05004], lr: 0.001206, loss: 1.3419
2022-07-13 07:42:44 - train: epoch 0187, iter [01800, 05004], lr: 0.001202, loss: 1.3149
2022-07-13 07:43:18 - train: epoch 0187, iter [01900, 05004], lr: 0.001199, loss: 1.4144
2022-07-13 07:43:53 - train: epoch 0187, iter [02000, 05004], lr: 0.001195, loss: 1.3623
2022-07-13 07:44:27 - train: epoch 0187, iter [02100, 05004], lr: 0.001192, loss: 1.5525
2022-07-13 07:45:02 - train: epoch 0187, iter [02200, 05004], lr: 0.001188, loss: 1.0766
2022-07-13 07:45:36 - train: epoch 0187, iter [02300, 05004], lr: 0.001185, loss: 1.3656
2022-07-13 07:46:11 - train: epoch 0187, iter [02400, 05004], lr: 0.001181, loss: 1.4915
2022-07-13 07:46:45 - train: epoch 0187, iter [02500, 05004], lr: 0.001178, loss: 1.3861
2022-07-13 07:47:19 - train: epoch 0187, iter [02600, 05004], lr: 0.001175, loss: 1.1583
2022-07-13 07:47:55 - train: epoch 0187, iter [02700, 05004], lr: 0.001171, loss: 1.4140
2022-07-13 07:48:29 - train: epoch 0187, iter [02800, 05004], lr: 0.001168, loss: 1.1504
2022-07-13 07:49:03 - train: epoch 0187, iter [02900, 05004], lr: 0.001164, loss: 1.2126
2022-07-13 07:49:39 - train: epoch 0187, iter [03000, 05004], lr: 0.001161, loss: 1.3737
2022-07-13 07:50:14 - train: epoch 0187, iter [03100, 05004], lr: 0.001157, loss: 1.1745
2022-07-13 07:50:49 - train: epoch 0187, iter [03200, 05004], lr: 0.001154, loss: 1.5217
2022-07-13 07:51:24 - train: epoch 0187, iter [03300, 05004], lr: 0.001150, loss: 1.3091
2022-07-13 07:51:59 - train: epoch 0187, iter [03400, 05004], lr: 0.001147, loss: 1.3173
2022-07-13 07:52:34 - train: epoch 0187, iter [03500, 05004], lr: 0.001144, loss: 1.1447
2022-07-13 07:53:08 - train: epoch 0187, iter [03600, 05004], lr: 0.001140, loss: 1.3434
2022-07-13 07:53:43 - train: epoch 0187, iter [03700, 05004], lr: 0.001137, loss: 1.3148
2022-07-13 07:54:17 - train: epoch 0187, iter [03800, 05004], lr: 0.001133, loss: 1.2320
2022-07-13 07:54:53 - train: epoch 0187, iter [03900, 05004], lr: 0.001130, loss: 1.3042
2022-07-13 07:55:27 - train: epoch 0187, iter [04000, 05004], lr: 0.001126, loss: 1.6336
2022-07-13 07:56:02 - train: epoch 0187, iter [04100, 05004], lr: 0.001123, loss: 1.4139
2022-07-13 07:56:36 - train: epoch 0187, iter [04200, 05004], lr: 0.001120, loss: 1.2495
2022-07-13 07:57:11 - train: epoch 0187, iter [04300, 05004], lr: 0.001116, loss: 1.4489
2022-07-13 07:57:46 - train: epoch 0187, iter [04400, 05004], lr: 0.001113, loss: 1.3409
2022-07-13 07:58:21 - train: epoch 0187, iter [04500, 05004], lr: 0.001110, loss: 1.2631
2022-07-13 07:58:55 - train: epoch 0187, iter [04600, 05004], lr: 0.001106, loss: 1.2127
2022-07-13 07:59:30 - train: epoch 0187, iter [04700, 05004], lr: 0.001103, loss: 1.2892
2022-07-13 08:00:06 - train: epoch 0187, iter [04800, 05004], lr: 0.001099, loss: 1.3366
2022-07-13 08:00:40 - train: epoch 0187, iter [04900, 05004], lr: 0.001096, loss: 1.2398
2022-07-13 08:01:13 - train: epoch 0187, iter [05000, 05004], lr: 0.001093, loss: 1.1498
2022-07-13 08:01:14 - train: epoch 187, train_loss: 1.2888
2022-07-13 08:02:30 - eval: epoch: 187, acc1: 77.066%, acc5: 93.574%, test_loss: 0.9113, per_image_load_time: 1.334ms, per_image_inference_time: 0.492ms
2022-07-13 08:02:31 - until epoch: 187, best_acc1: 77.066%
2022-07-13 21:26:46 - epoch 188 lr: 0.001093
2022-07-13 21:27:25 - train: epoch 0188, iter [00100, 05004], lr: 0.001089, loss: 1.5147
2022-07-13 21:27:58 - train: epoch 0188, iter [00200, 05004], lr: 0.001086, loss: 1.4342
2022-07-13 21:28:33 - train: epoch 0188, iter [00300, 05004], lr: 0.001083, loss: 1.4499
2022-07-13 21:29:05 - train: epoch 0188, iter [00400, 05004], lr: 0.001079, loss: 1.2830
2022-07-13 21:29:39 - train: epoch 0188, iter [00500, 05004], lr: 0.001076, loss: 1.2034
2022-07-13 21:30:13 - train: epoch 0188, iter [00600, 05004], lr: 0.001073, loss: 1.0368
2022-07-13 21:30:47 - train: epoch 0188, iter [00700, 05004], lr: 0.001069, loss: 1.0417
2022-07-13 21:31:21 - train: epoch 0188, iter [00800, 05004], lr: 0.001066, loss: 1.4688
2022-07-13 21:31:55 - train: epoch 0188, iter [00900, 05004], lr: 0.001063, loss: 1.2712
2022-07-13 21:32:29 - train: epoch 0188, iter [01000, 05004], lr: 0.001059, loss: 1.3449
2022-07-13 21:33:04 - train: epoch 0188, iter [01100, 05004], lr: 0.001056, loss: 1.3118
2022-07-13 21:33:38 - train: epoch 0188, iter [01200, 05004], lr: 0.001053, loss: 1.1181
2022-07-13 21:34:12 - train: epoch 0188, iter [01300, 05004], lr: 0.001050, loss: 1.1142
2022-07-13 21:34:46 - train: epoch 0188, iter [01400, 05004], lr: 0.001046, loss: 1.1951
2022-07-13 21:35:20 - train: epoch 0188, iter [01500, 05004], lr: 0.001043, loss: 1.0604
2022-07-13 21:35:54 - train: epoch 0188, iter [01600, 05004], lr: 0.001040, loss: 1.3703
2022-07-13 21:36:28 - train: epoch 0188, iter [01700, 05004], lr: 0.001036, loss: 1.0907
2022-07-13 21:37:03 - train: epoch 0188, iter [01800, 05004], lr: 0.001033, loss: 1.0277
2022-07-13 21:37:37 - train: epoch 0188, iter [01900, 05004], lr: 0.001030, loss: 1.3190
2022-07-13 21:38:11 - train: epoch 0188, iter [02000, 05004], lr: 0.001027, loss: 1.1742
2022-07-13 21:38:45 - train: epoch 0188, iter [02100, 05004], lr: 0.001023, loss: 1.2549
2022-07-13 21:39:19 - train: epoch 0188, iter [02200, 05004], lr: 0.001020, loss: 1.1799
2022-07-13 21:39:52 - train: epoch 0188, iter [02300, 05004], lr: 0.001017, loss: 1.2598
2022-07-13 21:40:27 - train: epoch 0188, iter [02400, 05004], lr: 0.001014, loss: 1.4655
2022-07-13 21:41:01 - train: epoch 0188, iter [02500, 05004], lr: 0.001011, loss: 1.2748
2022-07-13 21:41:35 - train: epoch 0188, iter [02600, 05004], lr: 0.001007, loss: 1.2336
2022-07-13 21:42:09 - train: epoch 0188, iter [02700, 05004], lr: 0.001004, loss: 1.4109
2022-07-13 21:42:44 - train: epoch 0188, iter [02800, 05004], lr: 0.001001, loss: 1.3564
2022-07-13 21:43:17 - train: epoch 0188, iter [02900, 05004], lr: 0.000998, loss: 1.4210
2022-07-13 21:43:51 - train: epoch 0188, iter [03000, 05004], lr: 0.000994, loss: 1.1782
2022-07-13 21:44:25 - train: epoch 0188, iter [03100, 05004], lr: 0.000991, loss: 1.2837
2022-07-13 21:44:59 - train: epoch 0188, iter [03200, 05004], lr: 0.000988, loss: 1.1084
2022-07-13 21:45:33 - train: epoch 0188, iter [03300, 05004], lr: 0.000985, loss: 1.2389
2022-07-13 21:46:08 - train: epoch 0188, iter [03400, 05004], lr: 0.000982, loss: 1.4018
2022-07-13 21:46:41 - train: epoch 0188, iter [03500, 05004], lr: 0.000979, loss: 1.1882
2022-07-13 21:47:16 - train: epoch 0188, iter [03600, 05004], lr: 0.000975, loss: 1.4883
2022-07-13 21:47:50 - train: epoch 0188, iter [03700, 05004], lr: 0.000972, loss: 1.4466
2022-07-13 21:48:25 - train: epoch 0188, iter [03800, 05004], lr: 0.000969, loss: 1.3924
2022-07-13 21:48:59 - train: epoch 0188, iter [03900, 05004], lr: 0.000966, loss: 1.1580
2022-07-13 21:49:34 - train: epoch 0188, iter [04000, 05004], lr: 0.000963, loss: 1.1179
2022-07-13 21:50:08 - train: epoch 0188, iter [04100, 05004], lr: 0.000960, loss: 1.6122
2022-07-13 21:50:43 - train: epoch 0188, iter [04200, 05004], lr: 0.000957, loss: 1.4687
2022-07-13 21:51:18 - train: epoch 0188, iter [04300, 05004], lr: 0.000953, loss: 1.4443
2022-07-13 21:51:52 - train: epoch 0188, iter [04400, 05004], lr: 0.000950, loss: 1.5052
2022-07-13 21:52:26 - train: epoch 0188, iter [04500, 05004], lr: 0.000947, loss: 1.2068
2022-07-13 21:52:59 - train: epoch 0188, iter [04600, 05004], lr: 0.000944, loss: 1.3891
2022-07-13 21:53:33 - train: epoch 0188, iter [04700, 05004], lr: 0.000941, loss: 1.4628
2022-07-13 21:54:08 - train: epoch 0188, iter [04800, 05004], lr: 0.000938, loss: 1.1401
2022-07-13 21:54:40 - train: epoch 0188, iter [04900, 05004], lr: 0.000935, loss: 1.1103
2022-07-13 21:55:13 - train: epoch 0188, iter [05000, 05004], lr: 0.000932, loss: 1.3337
2022-07-13 21:55:14 - train: epoch 188, train_loss: 1.2792
2022-07-13 21:56:28 - eval: epoch: 188, acc1: 77.198%, acc5: 93.622%, test_loss: 0.9105, per_image_load_time: 2.380ms, per_image_inference_time: 0.447ms
2022-07-13 21:56:28 - until epoch: 188, best_acc1: 77.198%
2022-07-13 21:56:28 - epoch 189 lr: 0.000931
2022-07-13 21:57:08 - train: epoch 0189, iter [00100, 05004], lr: 0.000928, loss: 1.4328
2022-07-13 21:57:41 - train: epoch 0189, iter [00200, 05004], lr: 0.000925, loss: 1.4412
2022-07-13 21:58:14 - train: epoch 0189, iter [00300, 05004], lr: 0.000922, loss: 1.3290
2022-07-13 21:58:48 - train: epoch 0189, iter [00400, 05004], lr: 0.000919, loss: 1.3851
2022-07-13 21:59:22 - train: epoch 0189, iter [00500, 05004], lr: 0.000916, loss: 1.2940
2022-07-13 21:59:56 - train: epoch 0189, iter [00600, 05004], lr: 0.000913, loss: 1.1991
2022-07-13 22:00:31 - train: epoch 0189, iter [00700, 05004], lr: 0.000910, loss: 1.2793
2022-07-13 22:01:04 - train: epoch 0189, iter [00800, 05004], lr: 0.000907, loss: 1.5045
2022-07-13 22:01:38 - train: epoch 0189, iter [00900, 05004], lr: 0.000904, loss: 1.4166
2022-07-13 22:02:13 - train: epoch 0189, iter [01000, 05004], lr: 0.000901, loss: 1.2009
2022-07-13 22:02:46 - train: epoch 0189, iter [01100, 05004], lr: 0.000898, loss: 1.3255
2022-07-13 22:03:22 - train: epoch 0189, iter [01200, 05004], lr: 0.000895, loss: 1.1476
2022-07-13 22:03:56 - train: epoch 0189, iter [01300, 05004], lr: 0.000892, loss: 1.3893
2022-07-13 22:04:30 - train: epoch 0189, iter [01400, 05004], lr: 0.000889, loss: 1.0751
2022-07-13 22:05:04 - train: epoch 0189, iter [01500, 05004], lr: 0.000886, loss: 1.1470
2022-07-13 22:05:39 - train: epoch 0189, iter [01600, 05004], lr: 0.000883, loss: 1.1124
2022-07-13 22:06:13 - train: epoch 0189, iter [01700, 05004], lr: 0.000880, loss: 1.4712
2022-07-13 22:06:48 - train: epoch 0189, iter [01800, 05004], lr: 0.000877, loss: 1.3922
2022-07-13 22:07:22 - train: epoch 0189, iter [01900, 05004], lr: 0.000874, loss: 1.1183
2022-07-13 22:07:56 - train: epoch 0189, iter [02000, 05004], lr: 0.000871, loss: 1.1244
2022-07-13 22:08:30 - train: epoch 0189, iter [02100, 05004], lr: 0.000868, loss: 1.1729
2022-07-13 22:09:05 - train: epoch 0189, iter [02200, 05004], lr: 0.000865, loss: 1.2271
2022-07-13 22:09:39 - train: epoch 0189, iter [02300, 05004], lr: 0.000862, loss: 1.0490
2022-07-13 22:10:13 - train: epoch 0189, iter [02400, 05004], lr: 0.000859, loss: 1.0973
2022-07-13 22:10:48 - train: epoch 0189, iter [02500, 05004], lr: 0.000856, loss: 1.1325
2022-07-13 22:11:21 - train: epoch 0189, iter [02600, 05004], lr: 0.000853, loss: 1.3906
2022-07-13 22:11:56 - train: epoch 0189, iter [02700, 05004], lr: 0.000850, loss: 1.0453
2022-07-13 22:12:30 - train: epoch 0189, iter [02800, 05004], lr: 0.000847, loss: 1.2243
2022-07-13 22:13:04 - train: epoch 0189, iter [02900, 05004], lr: 0.000844, loss: 1.2692
2022-07-13 22:13:39 - train: epoch 0189, iter [03000, 05004], lr: 0.000841, loss: 1.2725
2022-07-13 22:14:14 - train: epoch 0189, iter [03100, 05004], lr: 0.000838, loss: 1.1755
2022-07-13 22:14:50 - train: epoch 0189, iter [03200, 05004], lr: 0.000835, loss: 1.5448
2022-07-13 22:15:25 - train: epoch 0189, iter [03300, 05004], lr: 0.000832, loss: 1.2972
2022-07-13 22:16:00 - train: epoch 0189, iter [03400, 05004], lr: 0.000829, loss: 1.3208
2022-07-13 22:16:35 - train: epoch 0189, iter [03500, 05004], lr: 0.000826, loss: 1.1990
2022-07-13 22:17:11 - train: epoch 0189, iter [03600, 05004], lr: 0.000823, loss: 1.4484
2022-07-13 22:17:45 - train: epoch 0189, iter [03700, 05004], lr: 0.000821, loss: 1.0726
2022-07-13 22:18:19 - train: epoch 0189, iter [03800, 05004], lr: 0.000818, loss: 1.1687
2022-07-13 22:18:54 - train: epoch 0189, iter [03900, 05004], lr: 0.000815, loss: 1.1058
2022-07-13 22:19:29 - train: epoch 0189, iter [04000, 05004], lr: 0.000812, loss: 1.2942
2022-07-13 22:20:04 - train: epoch 0189, iter [04100, 05004], lr: 0.000809, loss: 1.1737
2022-07-13 22:20:39 - train: epoch 0189, iter [04200, 05004], lr: 0.000806, loss: 1.3009
2022-07-13 22:21:15 - train: epoch 0189, iter [04300, 05004], lr: 0.000803, loss: 1.2826
2022-07-13 22:21:50 - train: epoch 0189, iter [04400, 05004], lr: 0.000800, loss: 1.1634
2022-07-13 22:22:24 - train: epoch 0189, iter [04500, 05004], lr: 0.000797, loss: 1.2333
2022-07-13 22:22:59 - train: epoch 0189, iter [04600, 05004], lr: 0.000795, loss: 1.2727
2022-07-13 22:23:34 - train: epoch 0189, iter [04700, 05004], lr: 0.000792, loss: 1.3921
2022-07-13 22:24:08 - train: epoch 0189, iter [04800, 05004], lr: 0.000789, loss: 1.0728
2022-07-13 22:24:43 - train: epoch 0189, iter [04900, 05004], lr: 0.000786, loss: 1.2472
2022-07-13 22:25:17 - train: epoch 0189, iter [05000, 05004], lr: 0.000783, loss: 1.3629
2022-07-13 22:25:18 - train: epoch 189, train_loss: 1.2703
2022-07-13 22:26:31 - eval: epoch: 189, acc1: 77.316%, acc5: 93.624%, test_loss: 0.9059, per_image_load_time: 1.704ms, per_image_inference_time: 0.450ms
2022-07-13 22:26:32 - until epoch: 189, best_acc1: 77.316%
2022-07-13 22:26:32 - epoch 190 lr: 0.000783
2022-07-13 22:27:11 - train: epoch 0190, iter [00100, 05004], lr: 0.000780, loss: 1.3185
2022-07-13 22:27:45 - train: epoch 0190, iter [00200, 05004], lr: 0.000777, loss: 1.2372
2022-07-13 22:28:18 - train: epoch 0190, iter [00300, 05004], lr: 0.000775, loss: 1.3824
2022-07-13 22:28:52 - train: epoch 0190, iter [00400, 05004], lr: 0.000772, loss: 1.2608
2022-07-13 22:29:26 - train: epoch 0190, iter [00500, 05004], lr: 0.000769, loss: 1.3194
2022-07-13 22:30:01 - train: epoch 0190, iter [00600, 05004], lr: 0.000766, loss: 1.2428
2022-07-13 22:30:36 - train: epoch 0190, iter [00700, 05004], lr: 0.000763, loss: 1.3082
2022-07-13 22:31:10 - train: epoch 0190, iter [00800, 05004], lr: 0.000761, loss: 1.0700
2022-07-13 22:31:44 - train: epoch 0190, iter [00900, 05004], lr: 0.000758, loss: 1.2125
2022-07-13 22:32:18 - train: epoch 0190, iter [01000, 05004], lr: 0.000755, loss: 1.2076
2022-07-13 22:32:52 - train: epoch 0190, iter [01100, 05004], lr: 0.000752, loss: 1.4242
2022-07-13 22:33:27 - train: epoch 0190, iter [01200, 05004], lr: 0.000749, loss: 1.5440
2022-07-13 22:34:01 - train: epoch 0190, iter [01300, 05004], lr: 0.000747, loss: 1.3467
2022-07-13 22:34:34 - train: epoch 0190, iter [01400, 05004], lr: 0.000744, loss: 1.5003
2022-07-13 22:35:08 - train: epoch 0190, iter [01500, 05004], lr: 0.000741, loss: 1.2076
2022-07-13 22:35:42 - train: epoch 0190, iter [01600, 05004], lr: 0.000738, loss: 1.2987
2022-07-13 22:36:16 - train: epoch 0190, iter [01700, 05004], lr: 0.000736, loss: 1.2967
2022-07-13 22:36:51 - train: epoch 0190, iter [01800, 05004], lr: 0.000733, loss: 1.4682
2022-07-13 22:37:25 - train: epoch 0190, iter [01900, 05004], lr: 0.000730, loss: 1.3444
2022-07-13 22:37:59 - train: epoch 0190, iter [02000, 05004], lr: 0.000727, loss: 1.4042
2022-07-13 22:38:34 - train: epoch 0190, iter [02100, 05004], lr: 0.000725, loss: 1.3216
2022-07-13 22:39:08 - train: epoch 0190, iter [02200, 05004], lr: 0.000722, loss: 1.3125
2022-07-13 22:39:42 - train: epoch 0190, iter [02300, 05004], lr: 0.000719, loss: 1.2247
2022-07-13 22:40:18 - train: epoch 0190, iter [02400, 05004], lr: 0.000716, loss: 1.0616
2022-07-13 22:40:52 - train: epoch 0190, iter [02500, 05004], lr: 0.000714, loss: 1.5963
2022-07-13 22:41:27 - train: epoch 0190, iter [02600, 05004], lr: 0.000711, loss: 1.0407
2022-07-13 22:42:01 - train: epoch 0190, iter [02700, 05004], lr: 0.000708, loss: 1.2145
2022-07-13 22:42:36 - train: epoch 0190, iter [02800, 05004], lr: 0.000706, loss: 1.1235
2022-07-13 22:43:10 - train: epoch 0190, iter [02900, 05004], lr: 0.000703, loss: 1.2409
2022-07-13 22:43:45 - train: epoch 0190, iter [03000, 05004], lr: 0.000700, loss: 0.9965
2022-07-13 22:44:20 - train: epoch 0190, iter [03100, 05004], lr: 0.000698, loss: 1.2253
2022-07-13 22:44:54 - train: epoch 0190, iter [03200, 05004], lr: 0.000695, loss: 1.3676
2022-07-13 22:45:28 - train: epoch 0190, iter [03300, 05004], lr: 0.000692, loss: 1.4142
2022-07-13 22:46:03 - train: epoch 0190, iter [03400, 05004], lr: 0.000690, loss: 1.4866
2022-07-13 22:46:38 - train: epoch 0190, iter [03500, 05004], lr: 0.000687, loss: 0.9823
2022-07-13 22:47:12 - train: epoch 0190, iter [03600, 05004], lr: 0.000684, loss: 1.0929
2022-07-13 22:47:47 - train: epoch 0190, iter [03700, 05004], lr: 0.000682, loss: 1.2527
2022-07-13 22:48:22 - train: epoch 0190, iter [03800, 05004], lr: 0.000679, loss: 1.2284
2022-07-13 22:48:56 - train: epoch 0190, iter [03900, 05004], lr: 0.000676, loss: 1.1014
2022-07-13 22:49:32 - train: epoch 0190, iter [04000, 05004], lr: 0.000674, loss: 1.2759
2022-07-13 22:50:06 - train: epoch 0190, iter [04100, 05004], lr: 0.000671, loss: 1.2944
2022-07-13 22:50:41 - train: epoch 0190, iter [04200, 05004], lr: 0.000668, loss: 1.2046
2022-07-13 22:51:15 - train: epoch 0190, iter [04300, 05004], lr: 0.000666, loss: 1.1848
2022-07-13 22:51:51 - train: epoch 0190, iter [04400, 05004], lr: 0.000663, loss: 1.1745
2022-07-13 22:52:25 - train: epoch 0190, iter [04500, 05004], lr: 0.000661, loss: 1.1572
2022-07-13 22:53:00 - train: epoch 0190, iter [04600, 05004], lr: 0.000658, loss: 1.1816
2022-07-13 22:53:34 - train: epoch 0190, iter [04700, 05004], lr: 0.000655, loss: 1.4116
2022-07-13 22:54:08 - train: epoch 0190, iter [04800, 05004], lr: 0.000653, loss: 1.2089
2022-07-13 22:54:43 - train: epoch 0190, iter [04900, 05004], lr: 0.000650, loss: 1.2887
2022-07-13 22:55:16 - train: epoch 0190, iter [05000, 05004], lr: 0.000648, loss: 1.4891
2022-07-13 22:55:17 - train: epoch 190, train_loss: 1.2621
2022-07-13 22:56:33 - eval: epoch: 190, acc1: 77.350%, acc5: 93.716%, test_loss: 0.9021, per_image_load_time: 2.423ms, per_image_inference_time: 0.448ms
2022-07-13 22:56:33 - until epoch: 190, best_acc1: 77.350%
2022-07-13 22:56:33 - epoch 191 lr: 0.000647
2022-07-13 22:57:14 - train: epoch 0191, iter [00100, 05004], lr: 0.000645, loss: 1.2444
2022-07-13 22:57:47 - train: epoch 0191, iter [00200, 05004], lr: 0.000642, loss: 1.3414
2022-07-13 22:58:22 - train: epoch 0191, iter [00300, 05004], lr: 0.000640, loss: 1.4774
2022-07-13 22:58:56 - train: epoch 0191, iter [00400, 05004], lr: 0.000637, loss: 0.9868
2022-07-13 22:59:30 - train: epoch 0191, iter [00500, 05004], lr: 0.000635, loss: 1.2133
2022-07-13 23:00:03 - train: epoch 0191, iter [00600, 05004], lr: 0.000632, loss: 1.0917
2022-07-13 23:00:37 - train: epoch 0191, iter [00700, 05004], lr: 0.000630, loss: 1.3084
2022-07-13 23:01:11 - train: epoch 0191, iter [00800, 05004], lr: 0.000627, loss: 1.1425
2022-07-13 23:01:45 - train: epoch 0191, iter [00900, 05004], lr: 0.000624, loss: 1.1471
2022-07-13 23:02:19 - train: epoch 0191, iter [01000, 05004], lr: 0.000622, loss: 1.3214
2022-07-13 23:02:54 - train: epoch 0191, iter [01100, 05004], lr: 0.000619, loss: 1.2747
2022-07-13 23:03:28 - train: epoch 0191, iter [01200, 05004], lr: 0.000617, loss: 1.1200
2022-07-13 23:04:03 - train: epoch 0191, iter [01300, 05004], lr: 0.000614, loss: 1.3130
2022-07-13 23:04:37 - train: epoch 0191, iter [01400, 05004], lr: 0.000612, loss: 0.8753
2022-07-13 23:05:11 - train: epoch 0191, iter [01500, 05004], lr: 0.000609, loss: 1.2297
2022-07-13 23:05:46 - train: epoch 0191, iter [01600, 05004], lr: 0.000607, loss: 0.9989
2022-07-13 23:06:20 - train: epoch 0191, iter [01700, 05004], lr: 0.000604, loss: 1.3874
2022-07-13 23:06:55 - train: epoch 0191, iter [01800, 05004], lr: 0.000602, loss: 1.2992
2022-07-13 23:07:29 - train: epoch 0191, iter [01900, 05004], lr: 0.000599, loss: 1.2161
2022-07-13 23:08:03 - train: epoch 0191, iter [02000, 05004], lr: 0.000597, loss: 1.2741
2022-07-13 23:08:37 - train: epoch 0191, iter [02100, 05004], lr: 0.000594, loss: 1.3963
2022-07-13 23:09:12 - train: epoch 0191, iter [02200, 05004], lr: 0.000592, loss: 1.2522
2022-07-13 23:09:46 - train: epoch 0191, iter [02300, 05004], lr: 0.000589, loss: 1.2087
2022-07-13 23:10:21 - train: epoch 0191, iter [02400, 05004], lr: 0.000587, loss: 1.3478
2022-07-13 23:10:55 - train: epoch 0191, iter [02500, 05004], lr: 0.000585, loss: 1.3422
2022-07-13 23:11:30 - train: epoch 0191, iter [02600, 05004], lr: 0.000582, loss: 1.3338
2022-07-13 23:12:04 - train: epoch 0191, iter [02700, 05004], lr: 0.000580, loss: 1.3508
2022-07-13 23:12:39 - train: epoch 0191, iter [02800, 05004], lr: 0.000577, loss: 1.5604
2022-07-13 23:13:14 - train: epoch 0191, iter [02900, 05004], lr: 0.000575, loss: 1.0037
2022-07-13 23:13:48 - train: epoch 0191, iter [03000, 05004], lr: 0.000572, loss: 1.3827
2022-07-13 23:14:24 - train: epoch 0191, iter [03100, 05004], lr: 0.000570, loss: 1.3518
2022-07-13 23:14:59 - train: epoch 0191, iter [03200, 05004], lr: 0.000567, loss: 1.0588
2022-07-13 23:15:33 - train: epoch 0191, iter [03300, 05004], lr: 0.000565, loss: 1.2895
2022-07-13 23:16:08 - train: epoch 0191, iter [03400, 05004], lr: 0.000563, loss: 1.2316
2022-07-13 23:16:42 - train: epoch 0191, iter [03500, 05004], lr: 0.000560, loss: 1.4358
2022-07-13 23:17:17 - train: epoch 0191, iter [03600, 05004], lr: 0.000558, loss: 1.0718
2022-07-13 23:17:52 - train: epoch 0191, iter [03700, 05004], lr: 0.000555, loss: 1.1285
2022-07-13 23:18:27 - train: epoch 0191, iter [03800, 05004], lr: 0.000553, loss: 1.3445
2022-07-13 23:19:02 - train: epoch 0191, iter [03900, 05004], lr: 0.000551, loss: 1.0920
2022-07-13 23:19:36 - train: epoch 0191, iter [04000, 05004], lr: 0.000548, loss: 1.3626
2022-07-13 23:20:11 - train: epoch 0191, iter [04100, 05004], lr: 0.000546, loss: 1.2637
2022-07-13 23:20:46 - train: epoch 0191, iter [04200, 05004], lr: 0.000544, loss: 1.3165
2022-07-13 23:21:21 - train: epoch 0191, iter [04300, 05004], lr: 0.000541, loss: 1.3297
2022-07-13 23:21:56 - train: epoch 0191, iter [04400, 05004], lr: 0.000539, loss: 1.2268
2022-07-13 23:22:31 - train: epoch 0191, iter [04500, 05004], lr: 0.000536, loss: 1.0380
2022-07-13 23:23:06 - train: epoch 0191, iter [04600, 05004], lr: 0.000534, loss: 1.2931
2022-07-13 23:23:41 - train: epoch 0191, iter [04700, 05004], lr: 0.000532, loss: 1.3100
2022-07-13 23:24:16 - train: epoch 0191, iter [04800, 05004], lr: 0.000529, loss: 1.3361
2022-07-13 23:24:50 - train: epoch 0191, iter [04900, 05004], lr: 0.000527, loss: 1.2644
2022-07-13 23:25:25 - train: epoch 0191, iter [05000, 05004], lr: 0.000525, loss: 1.1345
2022-07-13 23:25:26 - train: epoch 191, train_loss: 1.2577
2022-07-13 23:26:40 - eval: epoch: 191, acc1: 77.506%, acc5: 93.732%, test_loss: 0.9008, per_image_load_time: 1.576ms, per_image_inference_time: 0.472ms
2022-07-13 23:26:40 - until epoch: 191, best_acc1: 77.506%
2022-07-13 23:26:40 - epoch 192 lr: 0.000525
2022-07-13 23:27:20 - train: epoch 0192, iter [00100, 05004], lr: 0.000522, loss: 1.2452
2022-07-13 23:27:54 - train: epoch 0192, iter [00200, 05004], lr: 0.000520, loss: 1.2901
2022-07-13 23:28:28 - train: epoch 0192, iter [00300, 05004], lr: 0.000518, loss: 1.0697
2022-07-13 23:29:03 - train: epoch 0192, iter [00400, 05004], lr: 0.000515, loss: 1.1247
2022-07-13 23:29:36 - train: epoch 0192, iter [00500, 05004], lr: 0.000513, loss: 1.2681
2022-07-13 23:30:11 - train: epoch 0192, iter [00600, 05004], lr: 0.000511, loss: 1.0652
2022-07-13 23:30:45 - train: epoch 0192, iter [00700, 05004], lr: 0.000509, loss: 1.2583
2022-07-13 23:31:20 - train: epoch 0192, iter [00800, 05004], lr: 0.000506, loss: 1.0986
2022-07-13 23:31:53 - train: epoch 0192, iter [00900, 05004], lr: 0.000504, loss: 1.3708
2022-07-13 23:32:29 - train: epoch 0192, iter [01000, 05004], lr: 0.000502, loss: 1.2611
2022-07-13 23:33:01 - train: epoch 0192, iter [01100, 05004], lr: 0.000499, loss: 1.4441
2022-07-13 23:33:36 - train: epoch 0192, iter [01200, 05004], lr: 0.000497, loss: 1.2885
2022-07-13 23:34:10 - train: epoch 0192, iter [01300, 05004], lr: 0.000495, loss: 1.2953
2022-07-13 23:34:44 - train: epoch 0192, iter [01400, 05004], lr: 0.000493, loss: 1.2656
2022-07-13 23:35:18 - train: epoch 0192, iter [01500, 05004], lr: 0.000490, loss: 0.9899
2022-07-13 23:35:52 - train: epoch 0192, iter [01600, 05004], lr: 0.000488, loss: 1.1208
2022-07-13 23:36:27 - train: epoch 0192, iter [01700, 05004], lr: 0.000486, loss: 1.5865
2022-07-13 23:37:02 - train: epoch 0192, iter [01800, 05004], lr: 0.000484, loss: 0.9698
2022-07-13 23:37:36 - train: epoch 0192, iter [01900, 05004], lr: 0.000481, loss: 1.3073
2022-07-13 23:38:10 - train: epoch 0192, iter [02000, 05004], lr: 0.000479, loss: 1.1635
2022-07-13 23:38:45 - train: epoch 0192, iter [02100, 05004], lr: 0.000477, loss: 1.3066
2022-07-13 23:39:19 - train: epoch 0192, iter [02200, 05004], lr: 0.000475, loss: 1.1770
2022-07-13 23:39:54 - train: epoch 0192, iter [02300, 05004], lr: 0.000473, loss: 1.0642
2022-07-13 23:40:28 - train: epoch 0192, iter [02400, 05004], lr: 0.000470, loss: 1.1678
2022-07-13 23:41:02 - train: epoch 0192, iter [02500, 05004], lr: 0.000468, loss: 1.3124
2022-07-13 23:41:37 - train: epoch 0192, iter [02600, 05004], lr: 0.000466, loss: 1.2652
2022-07-13 23:42:11 - train: epoch 0192, iter [02700, 05004], lr: 0.000464, loss: 1.2433
2022-07-13 23:42:46 - train: epoch 0192, iter [02800, 05004], lr: 0.000462, loss: 1.2250
2022-07-13 23:43:20 - train: epoch 0192, iter [02900, 05004], lr: 0.000459, loss: 1.3557
2022-07-13 23:43:55 - train: epoch 0192, iter [03000, 05004], lr: 0.000457, loss: 1.5406
2022-07-13 23:44:29 - train: epoch 0192, iter [03100, 05004], lr: 0.000455, loss: 1.0877
2022-07-13 23:45:04 - train: epoch 0192, iter [03200, 05004], lr: 0.000453, loss: 1.1771
2022-07-13 23:45:38 - train: epoch 0192, iter [03300, 05004], lr: 0.000451, loss: 1.1529
2022-07-13 23:46:12 - train: epoch 0192, iter [03400, 05004], lr: 0.000449, loss: 1.0794
2022-07-13 23:46:47 - train: epoch 0192, iter [03500, 05004], lr: 0.000446, loss: 1.1399
2022-07-13 23:47:21 - train: epoch 0192, iter [03600, 05004], lr: 0.000444, loss: 1.2266
2022-07-13 23:47:56 - train: epoch 0192, iter [03700, 05004], lr: 0.000442, loss: 1.0457
2022-07-13 23:48:30 - train: epoch 0192, iter [03800, 05004], lr: 0.000440, loss: 1.0588
2022-07-13 23:49:04 - train: epoch 0192, iter [03900, 05004], lr: 0.000438, loss: 1.3553
2022-07-13 23:49:38 - train: epoch 0192, iter [04000, 05004], lr: 0.000436, loss: 1.2350
2022-07-13 23:50:12 - train: epoch 0192, iter [04100, 05004], lr: 0.000434, loss: 1.3180
2022-07-13 23:50:47 - train: epoch 0192, iter [04200, 05004], lr: 0.000432, loss: 1.4585
2022-07-13 23:51:22 - train: epoch 0192, iter [04300, 05004], lr: 0.000429, loss: 1.1990
2022-07-13 23:51:56 - train: epoch 0192, iter [04400, 05004], lr: 0.000427, loss: 1.2577
2022-07-13 23:52:30 - train: epoch 0192, iter [04500, 05004], lr: 0.000425, loss: 1.3077
2022-07-13 23:53:05 - train: epoch 0192, iter [04600, 05004], lr: 0.000423, loss: 1.4911
2022-07-13 23:53:39 - train: epoch 0192, iter [04700, 05004], lr: 0.000421, loss: 1.3097
2022-07-13 23:54:14 - train: epoch 0192, iter [04800, 05004], lr: 0.000419, loss: 1.4083
2022-07-13 23:54:48 - train: epoch 0192, iter [04900, 05004], lr: 0.000417, loss: 1.5095
2022-07-13 23:55:21 - train: epoch 0192, iter [05000, 05004], lr: 0.000415, loss: 1.2930
2022-07-13 23:55:22 - train: epoch 192, train_loss: 1.2436
2022-07-13 23:56:36 - eval: epoch: 192, acc1: 77.496%, acc5: 93.724%, test_loss: 0.8989, per_image_load_time: 2.227ms, per_image_inference_time: 0.467ms
2022-07-13 23:56:37 - until epoch: 192, best_acc1: 77.506%
2022-07-13 23:56:37 - epoch 193 lr: 0.000415
2022-07-13 23:57:17 - train: epoch 0193, iter [00100, 05004], lr: 0.000413, loss: 1.2840
2022-07-13 23:57:51 - train: epoch 0193, iter [00200, 05004], lr: 0.000411, loss: 1.3602
2022-07-13 23:58:25 - train: epoch 0193, iter [00300, 05004], lr: 0.000409, loss: 1.0380
2022-07-13 23:59:00 - train: epoch 0193, iter [00400, 05004], lr: 0.000406, loss: 1.2272
2022-07-13 23:59:34 - train: epoch 0193, iter [00500, 05004], lr: 0.000404, loss: 1.2028
2022-07-14 00:00:09 - train: epoch 0193, iter [00600, 05004], lr: 0.000402, loss: 1.2168
2022-07-14 00:00:43 - train: epoch 0193, iter [00700, 05004], lr: 0.000400, loss: 1.5454
2022-07-14 00:01:17 - train: epoch 0193, iter [00800, 05004], lr: 0.000398, loss: 1.2133
2022-07-14 00:01:51 - train: epoch 0193, iter [00900, 05004], lr: 0.000396, loss: 1.0918
2022-07-14 00:02:25 - train: epoch 0193, iter [01000, 05004], lr: 0.000394, loss: 1.3061
2022-07-14 00:02:59 - train: epoch 0193, iter [01100, 05004], lr: 0.000392, loss: 1.2046
2022-07-14 00:03:33 - train: epoch 0193, iter [01200, 05004], lr: 0.000390, loss: 1.2044
2022-07-14 00:04:07 - train: epoch 0193, iter [01300, 05004], lr: 0.000388, loss: 1.3921
2022-07-14 00:04:41 - train: epoch 0193, iter [01400, 05004], lr: 0.000386, loss: 1.2890
2022-07-14 00:05:16 - train: epoch 0193, iter [01500, 05004], lr: 0.000384, loss: 1.1602
2022-07-14 00:05:51 - train: epoch 0193, iter [01600, 05004], lr: 0.000382, loss: 1.0943
2022-07-14 00:06:25 - train: epoch 0193, iter [01700, 05004], lr: 0.000380, loss: 1.4673
2022-07-14 00:06:58 - train: epoch 0193, iter [01800, 05004], lr: 0.000378, loss: 1.0071
2022-07-14 00:07:32 - train: epoch 0193, iter [01900, 05004], lr: 0.000376, loss: 1.3406
2022-07-14 00:08:06 - train: epoch 0193, iter [02000, 05004], lr: 0.000374, loss: 1.0733
2022-07-14 00:08:39 - train: epoch 0193, iter [02100, 05004], lr: 0.000372, loss: 1.3559
2022-07-14 00:09:13 - train: epoch 0193, iter [02200, 05004], lr: 0.000370, loss: 1.3650
2022-07-14 00:09:47 - train: epoch 0193, iter [02300, 05004], lr: 0.000368, loss: 1.5185
2022-07-14 00:10:22 - train: epoch 0193, iter [02400, 05004], lr: 0.000367, loss: 1.2701
2022-07-14 00:10:56 - train: epoch 0193, iter [02500, 05004], lr: 0.000365, loss: 1.2224
2022-07-14 00:11:29 - train: epoch 0193, iter [02600, 05004], lr: 0.000363, loss: 1.2409
2022-07-14 00:12:03 - train: epoch 0193, iter [02700, 05004], lr: 0.000361, loss: 1.2622
2022-07-14 00:12:37 - train: epoch 0193, iter [02800, 05004], lr: 0.000359, loss: 1.2696
2022-07-14 00:13:11 - train: epoch 0193, iter [02900, 05004], lr: 0.000357, loss: 1.6182
2022-07-14 00:13:45 - train: epoch 0193, iter [03000, 05004], lr: 0.000355, loss: 0.9646
2022-07-14 00:14:19 - train: epoch 0193, iter [03100, 05004], lr: 0.000353, loss: 1.1571
2022-07-14 00:14:53 - train: epoch 0193, iter [03200, 05004], lr: 0.000351, loss: 1.2805
2022-07-14 00:15:27 - train: epoch 0193, iter [03300, 05004], lr: 0.000349, loss: 1.2929
2022-07-14 00:16:02 - train: epoch 0193, iter [03400, 05004], lr: 0.000347, loss: 1.1872
2022-07-14 00:16:36 - train: epoch 0193, iter [03500, 05004], lr: 0.000345, loss: 1.3340
2022-07-14 00:17:11 - train: epoch 0193, iter [03600, 05004], lr: 0.000344, loss: 1.3883
2022-07-14 00:17:45 - train: epoch 0193, iter [03700, 05004], lr: 0.000342, loss: 1.0889
2022-07-14 00:18:19 - train: epoch 0193, iter [03800, 05004], lr: 0.000340, loss: 1.1944
2022-07-14 00:18:53 - train: epoch 0193, iter [03900, 05004], lr: 0.000338, loss: 1.1802
2022-07-14 00:19:27 - train: epoch 0193, iter [04000, 05004], lr: 0.000336, loss: 1.0336
2022-07-14 00:20:01 - train: epoch 0193, iter [04100, 05004], lr: 0.000334, loss: 1.2645
2022-07-14 00:20:35 - train: epoch 0193, iter [04200, 05004], lr: 0.000332, loss: 1.0150
2022-07-14 00:21:10 - train: epoch 0193, iter [04300, 05004], lr: 0.000331, loss: 1.2933
2022-07-14 00:21:44 - train: epoch 0193, iter [04400, 05004], lr: 0.000329, loss: 1.2664
2022-07-14 00:22:19 - train: epoch 0193, iter [04500, 05004], lr: 0.000327, loss: 0.9270
2022-07-14 00:22:52 - train: epoch 0193, iter [04600, 05004], lr: 0.000325, loss: 1.1995
2022-07-14 00:23:26 - train: epoch 0193, iter [04700, 05004], lr: 0.000323, loss: 1.1522
2022-07-14 00:24:00 - train: epoch 0193, iter [04800, 05004], lr: 0.000321, loss: 1.2751
2022-07-14 00:24:35 - train: epoch 0193, iter [04900, 05004], lr: 0.000320, loss: 1.2773
2022-07-14 00:25:08 - train: epoch 0193, iter [05000, 05004], lr: 0.000318, loss: 1.2812
2022-07-14 00:25:09 - train: epoch 193, train_loss: 1.2414
2022-07-14 00:26:23 - eval: epoch: 193, acc1: 77.564%, acc5: 93.772%, test_loss: 0.8984, per_image_load_time: 1.054ms, per_image_inference_time: 0.445ms
2022-07-14 00:26:23 - until epoch: 193, best_acc1: 77.564%
2022-07-14 00:26:23 - epoch 194 lr: 0.000318
2022-07-14 00:27:03 - train: epoch 0194, iter [00100, 05004], lr: 0.000316, loss: 1.2547
2022-07-14 00:27:36 - train: epoch 0194, iter [00200, 05004], lr: 0.000314, loss: 1.0990
2022-07-14 00:28:11 - train: epoch 0194, iter [00300, 05004], lr: 0.000312, loss: 1.1804
2022-07-14 00:28:44 - train: epoch 0194, iter [00400, 05004], lr: 0.000310, loss: 1.2078
2022-07-14 00:29:18 - train: epoch 0194, iter [00500, 05004], lr: 0.000309, loss: 1.4460
2022-07-14 00:29:52 - train: epoch 0194, iter [00600, 05004], lr: 0.000307, loss: 1.3543
2022-07-14 00:30:25 - train: epoch 0194, iter [00700, 05004], lr: 0.000305, loss: 1.1004
2022-07-14 00:30:59 - train: epoch 0194, iter [00800, 05004], lr: 0.000303, loss: 1.3549
2022-07-14 00:31:34 - train: epoch 0194, iter [00900, 05004], lr: 0.000302, loss: 1.1951
2022-07-14 00:32:08 - train: epoch 0194, iter [01000, 05004], lr: 0.000300, loss: 1.2360
2022-07-14 00:32:41 - train: epoch 0194, iter [01100, 05004], lr: 0.000298, loss: 1.1373
2022-07-14 00:33:15 - train: epoch 0194, iter [01200, 05004], lr: 0.000296, loss: 1.4849
2022-07-14 00:33:49 - train: epoch 0194, iter [01300, 05004], lr: 0.000295, loss: 1.2952
2022-07-14 00:34:23 - train: epoch 0194, iter [01400, 05004], lr: 0.000293, loss: 1.2607
2022-07-14 00:34:56 - train: epoch 0194, iter [01500, 05004], lr: 0.000291, loss: 1.2292
2022-07-14 00:35:30 - train: epoch 0194, iter [01600, 05004], lr: 0.000289, loss: 1.2108
2022-07-14 00:36:04 - train: epoch 0194, iter [01700, 05004], lr: 0.000288, loss: 1.3754
2022-07-14 00:36:38 - train: epoch 0194, iter [01800, 05004], lr: 0.000286, loss: 1.1965
2022-07-14 00:37:12 - train: epoch 0194, iter [01900, 05004], lr: 0.000284, loss: 1.0266
2022-07-14 00:37:46 - train: epoch 0194, iter [02000, 05004], lr: 0.000282, loss: 1.2947
2022-07-14 00:38:20 - train: epoch 0194, iter [02100, 05004], lr: 0.000281, loss: 1.1591
2022-07-14 00:38:54 - train: epoch 0194, iter [02200, 05004], lr: 0.000279, loss: 1.3829
2022-07-14 00:39:29 - train: epoch 0194, iter [02300, 05004], lr: 0.000277, loss: 1.2394
2022-07-14 00:40:03 - train: epoch 0194, iter [02400, 05004], lr: 0.000276, loss: 1.1302
2022-07-14 00:40:37 - train: epoch 0194, iter [02500, 05004], lr: 0.000274, loss: 1.2682
2022-07-14 00:41:10 - train: epoch 0194, iter [02600, 05004], lr: 0.000272, loss: 1.3487
2022-07-14 00:41:43 - train: epoch 0194, iter [02700, 05004], lr: 0.000271, loss: 1.0838
2022-07-14 00:42:17 - train: epoch 0194, iter [02800, 05004], lr: 0.000269, loss: 1.1159
2022-07-14 00:42:51 - train: epoch 0194, iter [02900, 05004], lr: 0.000267, loss: 1.5205
2022-07-14 00:43:25 - train: epoch 0194, iter [03000, 05004], lr: 0.000266, loss: 1.2049
2022-07-14 00:43:57 - train: epoch 0194, iter [03100, 05004], lr: 0.000264, loss: 1.1033
2022-07-14 00:44:31 - train: epoch 0194, iter [03200, 05004], lr: 0.000262, loss: 1.1034
2022-07-14 00:45:04 - train: epoch 0194, iter [03300, 05004], lr: 0.000261, loss: 1.2563
2022-07-14 00:45:38 - train: epoch 0194, iter [03400, 05004], lr: 0.000259, loss: 0.9236
2022-07-14 00:46:11 - train: epoch 0194, iter [03500, 05004], lr: 0.000257, loss: 1.4695
2022-07-14 00:46:45 - train: epoch 0194, iter [03600, 05004], lr: 0.000256, loss: 1.2023
2022-07-14 00:47:18 - train: epoch 0194, iter [03700, 05004], lr: 0.000254, loss: 1.0207
2022-07-14 00:47:51 - train: epoch 0194, iter [03800, 05004], lr: 0.000252, loss: 1.1875
2022-07-14 00:48:25 - train: epoch 0194, iter [03900, 05004], lr: 0.000251, loss: 1.1653
2022-07-14 00:48:58 - train: epoch 0194, iter [04000, 05004], lr: 0.000249, loss: 1.2982
2022-07-14 00:49:32 - train: epoch 0194, iter [04100, 05004], lr: 0.000248, loss: 1.0111
2022-07-14 00:50:06 - train: epoch 0194, iter [04200, 05004], lr: 0.000246, loss: 1.2942
2022-07-14 00:50:39 - train: epoch 0194, iter [04300, 05004], lr: 0.000244, loss: 1.1600
2022-07-14 00:51:14 - train: epoch 0194, iter [04400, 05004], lr: 0.000243, loss: 1.2717
2022-07-14 00:51:47 - train: epoch 0194, iter [04500, 05004], lr: 0.000241, loss: 1.2205
2022-07-14 00:52:20 - train: epoch 0194, iter [04600, 05004], lr: 0.000240, loss: 1.2464
2022-07-14 00:52:54 - train: epoch 0194, iter [04700, 05004], lr: 0.000238, loss: 1.1219
2022-07-14 00:53:28 - train: epoch 0194, iter [04800, 05004], lr: 0.000237, loss: 1.2850
2022-07-14 00:54:01 - train: epoch 0194, iter [04900, 05004], lr: 0.000235, loss: 1.1686
2022-07-14 00:54:34 - train: epoch 0194, iter [05000, 05004], lr: 0.000233, loss: 1.3016
2022-07-14 00:54:35 - train: epoch 194, train_loss: 1.2327
2022-07-14 00:55:50 - eval: epoch: 194, acc1: 77.722%, acc5: 93.770%, test_loss: 0.8952, per_image_load_time: 2.349ms, per_image_inference_time: 0.464ms
2022-07-14 00:55:50 - until epoch: 194, best_acc1: 77.722%
2022-07-14 00:55:50 - epoch 195 lr: 0.000233
2022-07-14 00:56:29 - train: epoch 0195, iter [00100, 05004], lr: 0.000232, loss: 1.1843
2022-07-14 00:57:04 - train: epoch 0195, iter [00200, 05004], lr: 0.000230, loss: 1.1376
2022-07-14 00:57:37 - train: epoch 0195, iter [00300, 05004], lr: 0.000229, loss: 1.1059
2022-07-14 00:58:11 - train: epoch 0195, iter [00400, 05004], lr: 0.000227, loss: 1.2569
2022-07-14 00:58:45 - train: epoch 0195, iter [00500, 05004], lr: 0.000226, loss: 1.4449
2022-07-14 00:59:19 - train: epoch 0195, iter [00600, 05004], lr: 0.000224, loss: 1.3148
2022-07-14 00:59:54 - train: epoch 0195, iter [00700, 05004], lr: 0.000223, loss: 1.1918
2022-07-14 01:00:29 - train: epoch 0195, iter [00800, 05004], lr: 0.000221, loss: 1.0371
2022-07-14 01:01:04 - train: epoch 0195, iter [00900, 05004], lr: 0.000220, loss: 1.1277
2022-07-14 01:01:37 - train: epoch 0195, iter [01000, 05004], lr: 0.000218, loss: 1.3698
2022-07-14 01:02:12 - train: epoch 0195, iter [01100, 05004], lr: 0.000217, loss: 0.9990
2022-07-14 01:02:46 - train: epoch 0195, iter [01200, 05004], lr: 0.000215, loss: 1.2910
2022-07-14 01:03:21 - train: epoch 0195, iter [01300, 05004], lr: 0.000214, loss: 1.3365
2022-07-14 01:03:55 - train: epoch 0195, iter [01400, 05004], lr: 0.000212, loss: 1.4189
2022-07-14 01:04:30 - train: epoch 0195, iter [01500, 05004], lr: 0.000211, loss: 1.0439
2022-07-14 01:05:05 - train: epoch 0195, iter [01600, 05004], lr: 0.000209, loss: 1.2213
2022-07-14 01:05:40 - train: epoch 0195, iter [01700, 05004], lr: 0.000208, loss: 1.2866
2022-07-14 01:06:14 - train: epoch 0195, iter [01800, 05004], lr: 0.000206, loss: 1.3158
2022-07-14 01:06:49 - train: epoch 0195, iter [01900, 05004], lr: 0.000205, loss: 1.2790
2022-07-14 01:07:23 - train: epoch 0195, iter [02000, 05004], lr: 0.000203, loss: 1.0032
2022-07-14 01:07:58 - train: epoch 0195, iter [02100, 05004], lr: 0.000202, loss: 1.2248
2022-07-14 01:08:33 - train: epoch 0195, iter [02200, 05004], lr: 0.000200, loss: 1.2277
2022-07-14 01:09:08 - train: epoch 0195, iter [02300, 05004], lr: 0.000199, loss: 1.1467
2022-07-14 01:09:42 - train: epoch 0195, iter [02400, 05004], lr: 0.000198, loss: 1.1745
2022-07-14 01:10:17 - train: epoch 0195, iter [02500, 05004], lr: 0.000196, loss: 1.2694
2022-07-14 01:10:51 - train: epoch 0195, iter [02600, 05004], lr: 0.000195, loss: 1.2712
2022-07-14 01:11:26 - train: epoch 0195, iter [02700, 05004], lr: 0.000193, loss: 1.1973
2022-07-14 01:12:02 - train: epoch 0195, iter [02800, 05004], lr: 0.000192, loss: 1.0813
2022-07-14 01:12:36 - train: epoch 0195, iter [02900, 05004], lr: 0.000191, loss: 1.2433
2022-07-14 01:13:11 - train: epoch 0195, iter [03000, 05004], lr: 0.000189, loss: 1.3044
2022-07-14 01:13:45 - train: epoch 0195, iter [03100, 05004], lr: 0.000188, loss: 1.3543
2022-07-14 01:14:19 - train: epoch 0195, iter [03200, 05004], lr: 0.000186, loss: 1.2424
2022-07-14 01:14:53 - train: epoch 0195, iter [03300, 05004], lr: 0.000185, loss: 1.3360
2022-07-14 01:15:27 - train: epoch 0195, iter [03400, 05004], lr: 0.000184, loss: 1.1743
2022-07-14 01:16:02 - train: epoch 0195, iter [03500, 05004], lr: 0.000182, loss: 1.1166
2022-07-14 01:16:35 - train: epoch 0195, iter [03600, 05004], lr: 0.000181, loss: 1.2081
2022-07-14 01:17:09 - train: epoch 0195, iter [03700, 05004], lr: 0.000179, loss: 1.3401
2022-07-14 01:17:43 - train: epoch 0195, iter [03800, 05004], lr: 0.000178, loss: 1.1125
2022-07-14 01:18:16 - train: epoch 0195, iter [03900, 05004], lr: 0.000177, loss: 1.3359
2022-07-14 01:18:51 - train: epoch 0195, iter [04000, 05004], lr: 0.000175, loss: 1.1816
2022-07-14 01:19:24 - train: epoch 0195, iter [04100, 05004], lr: 0.000174, loss: 1.0566
2022-07-14 01:19:58 - train: epoch 0195, iter [04200, 05004], lr: 0.000173, loss: 1.3540
2022-07-14 01:20:31 - train: epoch 0195, iter [04300, 05004], lr: 0.000171, loss: 1.1463
2022-07-14 01:21:05 - train: epoch 0195, iter [04400, 05004], lr: 0.000170, loss: 1.2947
2022-07-14 01:21:38 - train: epoch 0195, iter [04500, 05004], lr: 0.000169, loss: 1.4036
2022-07-14 01:22:13 - train: epoch 0195, iter [04600, 05004], lr: 0.000167, loss: 1.0487
2022-07-14 01:22:47 - train: epoch 0195, iter [04700, 05004], lr: 0.000166, loss: 1.2445
2022-07-14 01:23:22 - train: epoch 0195, iter [04800, 05004], lr: 0.000165, loss: 1.1172
2022-07-14 01:23:55 - train: epoch 0195, iter [04900, 05004], lr: 0.000163, loss: 1.3472
2022-07-14 01:24:29 - train: epoch 0195, iter [05000, 05004], lr: 0.000162, loss: 1.2168
2022-07-14 01:24:30 - train: epoch 195, train_loss: 1.2277
2022-07-14 01:25:44 - eval: epoch: 195, acc1: 77.704%, acc5: 93.776%, test_loss: 0.8937, per_image_load_time: 2.286ms, per_image_inference_time: 0.472ms
2022-07-14 01:25:44 - until epoch: 195, best_acc1: 77.722%
2022-07-14 01:25:44 - epoch 196 lr: 0.000162
2022-07-14 01:26:23 - train: epoch 0196, iter [00100, 05004], lr: 0.000161, loss: 1.2496
2022-07-14 01:26:57 - train: epoch 0196, iter [00200, 05004], lr: 0.000160, loss: 1.0998
2022-07-14 01:27:31 - train: epoch 0196, iter [00300, 05004], lr: 0.000158, loss: 1.2767
2022-07-14 01:28:06 - train: epoch 0196, iter [00400, 05004], lr: 0.000157, loss: 1.3153
2022-07-14 01:28:38 - train: epoch 0196, iter [00500, 05004], lr: 0.000156, loss: 1.1840
2022-07-14 01:29:13 - train: epoch 0196, iter [00600, 05004], lr: 0.000154, loss: 1.2357
2022-07-14 01:29:47 - train: epoch 0196, iter [00700, 05004], lr: 0.000153, loss: 1.0935
2022-07-14 01:30:22 - train: epoch 0196, iter [00800, 05004], lr: 0.000152, loss: 1.0956
2022-07-14 01:30:56 - train: epoch 0196, iter [00900, 05004], lr: 0.000151, loss: 1.1951
2022-07-14 01:31:30 - train: epoch 0196, iter [01000, 05004], lr: 0.000149, loss: 1.2550
2022-07-14 01:32:04 - train: epoch 0196, iter [01100, 05004], lr: 0.000148, loss: 1.2043
2022-07-14 01:32:38 - train: epoch 0196, iter [01200, 05004], lr: 0.000147, loss: 1.6321
2022-07-14 01:33:14 - train: epoch 0196, iter [01300, 05004], lr: 0.000146, loss: 1.1782
2022-07-14 01:33:48 - train: epoch 0196, iter [01400, 05004], lr: 0.000145, loss: 1.2395
2022-07-14 01:34:22 - train: epoch 0196, iter [01500, 05004], lr: 0.000143, loss: 1.2940
2022-07-14 01:34:57 - train: epoch 0196, iter [01600, 05004], lr: 0.000142, loss: 1.2783
2022-07-14 01:35:31 - train: epoch 0196, iter [01700, 05004], lr: 0.000141, loss: 1.1786
2022-07-14 01:36:06 - train: epoch 0196, iter [01800, 05004], lr: 0.000140, loss: 1.0956
2022-07-14 01:36:40 - train: epoch 0196, iter [01900, 05004], lr: 0.000138, loss: 1.2506
2022-07-14 01:37:15 - train: epoch 0196, iter [02000, 05004], lr: 0.000137, loss: 1.3715
2022-07-14 01:37:49 - train: epoch 0196, iter [02100, 05004], lr: 0.000136, loss: 1.3563
2022-07-14 01:38:24 - train: epoch 0196, iter [02200, 05004], lr: 0.000135, loss: 1.3428
2022-07-14 01:38:58 - train: epoch 0196, iter [02300, 05004], lr: 0.000134, loss: 1.0988
2022-07-14 01:39:32 - train: epoch 0196, iter [02400, 05004], lr: 0.000133, loss: 1.1586
2022-07-14 01:40:07 - train: epoch 0196, iter [02500, 05004], lr: 0.000131, loss: 1.2064
2022-07-14 01:40:41 - train: epoch 0196, iter [02600, 05004], lr: 0.000130, loss: 1.0295
2022-07-14 01:41:16 - train: epoch 0196, iter [02700, 05004], lr: 0.000129, loss: 1.3426
2022-07-14 01:41:51 - train: epoch 0196, iter [02800, 05004], lr: 0.000128, loss: 1.1493
2022-07-14 01:42:25 - train: epoch 0196, iter [02900, 05004], lr: 0.000127, loss: 1.2942
2022-07-14 01:43:00 - train: epoch 0196, iter [03000, 05004], lr: 0.000126, loss: 1.1592
2022-07-14 01:43:35 - train: epoch 0196, iter [03100, 05004], lr: 0.000124, loss: 1.2562
2022-07-14 01:44:10 - train: epoch 0196, iter [03200, 05004], lr: 0.000123, loss: 1.2548
2022-07-14 01:44:43 - train: epoch 0196, iter [03300, 05004], lr: 0.000122, loss: 1.2843
2022-07-14 01:45:19 - train: epoch 0196, iter [03400, 05004], lr: 0.000121, loss: 1.2224
2022-07-14 01:45:54 - train: epoch 0196, iter [03500, 05004], lr: 0.000120, loss: 1.2161
2022-07-14 01:46:28 - train: epoch 0196, iter [03600, 05004], lr: 0.000119, loss: 1.3235
2022-07-14 01:47:02 - train: epoch 0196, iter [03700, 05004], lr: 0.000118, loss: 1.0818
2022-07-14 01:47:35 - train: epoch 0196, iter [03800, 05004], lr: 0.000117, loss: 1.3458
2022-07-14 01:48:09 - train: epoch 0196, iter [03900, 05004], lr: 0.000116, loss: 1.1011
2022-07-14 01:48:44 - train: epoch 0196, iter [04000, 05004], lr: 0.000114, loss: 1.0253
2022-07-14 01:49:18 - train: epoch 0196, iter [04100, 05004], lr: 0.000113, loss: 1.2557
2022-07-14 01:49:51 - train: epoch 0196, iter [04200, 05004], lr: 0.000112, loss: 1.3627
2022-07-14 01:50:26 - train: epoch 0196, iter [04300, 05004], lr: 0.000111, loss: 1.4196
2022-07-14 01:51:00 - train: epoch 0196, iter [04400, 05004], lr: 0.000110, loss: 1.3920
2022-07-14 01:51:34 - train: epoch 0196, iter [04500, 05004], lr: 0.000109, loss: 1.0143
2022-07-14 01:52:08 - train: epoch 0196, iter [04600, 05004], lr: 0.000108, loss: 0.9582
2022-07-14 01:52:42 - train: epoch 0196, iter [04700, 05004], lr: 0.000107, loss: 1.4350
2022-07-14 01:53:17 - train: epoch 0196, iter [04800, 05004], lr: 0.000106, loss: 1.1560
2022-07-14 01:53:51 - train: epoch 0196, iter [04900, 05004], lr: 0.000105, loss: 1.0568
2022-07-14 01:54:24 - train: epoch 0196, iter [05000, 05004], lr: 0.000104, loss: 1.0185
2022-07-14 01:54:25 - train: epoch 196, train_loss: 1.2235
2022-07-14 01:55:38 - eval: epoch: 196, acc1: 77.648%, acc5: 93.852%, test_loss: 0.8911, per_image_load_time: 1.866ms, per_image_inference_time: 0.462ms
2022-07-14 01:55:38 - until epoch: 196, best_acc1: 77.722%
2022-07-14 01:55:38 - epoch 197 lr: 0.000104
2022-07-14 01:56:18 - train: epoch 0197, iter [00100, 05004], lr: 0.000103, loss: 1.0602
2022-07-14 01:56:51 - train: epoch 0197, iter [00200, 05004], lr: 0.000102, loss: 1.1434
2022-07-14 01:57:25 - train: epoch 0197, iter [00300, 05004], lr: 0.000101, loss: 1.1259
2022-07-14 01:57:59 - train: epoch 0197, iter [00400, 05004], lr: 0.000100, loss: 1.2330
2022-07-14 01:58:33 - train: epoch 0197, iter [00500, 05004], lr: 0.000099, loss: 1.2155
2022-07-14 01:59:07 - train: epoch 0197, iter [00600, 05004], lr: 0.000098, loss: 1.2342
2022-07-14 01:59:41 - train: epoch 0197, iter [00700, 05004], lr: 0.000097, loss: 1.2620
2022-07-14 02:00:15 - train: epoch 0197, iter [00800, 05004], lr: 0.000096, loss: 1.2965
2022-07-14 02:00:49 - train: epoch 0197, iter [00900, 05004], lr: 0.000095, loss: 0.9130
2022-07-14 02:01:24 - train: epoch 0197, iter [01000, 05004], lr: 0.000094, loss: 1.3051
2022-07-14 02:01:57 - train: epoch 0197, iter [01100, 05004], lr: 0.000093, loss: 1.4358
2022-07-14 02:02:32 - train: epoch 0197, iter [01200, 05004], lr: 0.000092, loss: 1.2763
2022-07-14 02:03:07 - train: epoch 0197, iter [01300, 05004], lr: 0.000091, loss: 1.3034
2022-07-14 02:03:41 - train: epoch 0197, iter [01400, 05004], lr: 0.000090, loss: 1.2198
2022-07-14 02:04:15 - train: epoch 0197, iter [01500, 05004], lr: 0.000089, loss: 1.1511
2022-07-14 02:04:49 - train: epoch 0197, iter [01600, 05004], lr: 0.000088, loss: 1.1438
2022-07-14 02:05:23 - train: epoch 0197, iter [01700, 05004], lr: 0.000087, loss: 1.1405
2022-07-14 02:05:58 - train: epoch 0197, iter [01800, 05004], lr: 0.000086, loss: 1.1676
2022-07-14 02:06:33 - train: epoch 0197, iter [01900, 05004], lr: 0.000085, loss: 1.0997
2022-07-14 02:07:07 - train: epoch 0197, iter [02000, 05004], lr: 0.000084, loss: 1.4084
2022-07-14 02:07:41 - train: epoch 0197, iter [02100, 05004], lr: 0.000083, loss: 1.2542
2022-07-14 02:08:16 - train: epoch 0197, iter [02200, 05004], lr: 0.000082, loss: 1.2731
2022-07-14 02:08:50 - train: epoch 0197, iter [02300, 05004], lr: 0.000081, loss: 1.1532
2022-07-14 02:09:24 - train: epoch 0197, iter [02400, 05004], lr: 0.000080, loss: 1.0951
2022-07-14 02:09:59 - train: epoch 0197, iter [02500, 05004], lr: 0.000079, loss: 1.2803
2022-07-14 02:10:34 - train: epoch 0197, iter [02600, 05004], lr: 0.000079, loss: 1.4523
2022-07-14 02:11:08 - train: epoch 0197, iter [02700, 05004], lr: 0.000078, loss: 1.3145
2022-07-14 02:11:43 - train: epoch 0197, iter [02800, 05004], lr: 0.000077, loss: 1.0319
2022-07-14 02:12:17 - train: epoch 0197, iter [02900, 05004], lr: 0.000076, loss: 1.1102
2022-07-14 02:12:51 - train: epoch 0197, iter [03000, 05004], lr: 0.000075, loss: 0.9214
2022-07-14 02:13:26 - train: epoch 0197, iter [03100, 05004], lr: 0.000074, loss: 1.2315
2022-07-14 02:14:00 - train: epoch 0197, iter [03200, 05004], lr: 0.000073, loss: 1.0905
2022-07-14 02:14:34 - train: epoch 0197, iter [03300, 05004], lr: 0.000072, loss: 1.1288
2022-07-14 02:15:08 - train: epoch 0197, iter [03400, 05004], lr: 0.000072, loss: 1.0431
2022-07-14 02:15:43 - train: epoch 0197, iter [03500, 05004], lr: 0.000071, loss: 1.4200
2022-07-14 02:16:17 - train: epoch 0197, iter [03600, 05004], lr: 0.000070, loss: 1.0333
2022-07-14 02:16:53 - train: epoch 0197, iter [03700, 05004], lr: 0.000069, loss: 1.1972
2022-07-14 02:17:27 - train: epoch 0197, iter [03800, 05004], lr: 0.000068, loss: 1.3414
2022-07-14 02:18:01 - train: epoch 0197, iter [03900, 05004], lr: 0.000067, loss: 1.1306
2022-07-14 02:18:36 - train: epoch 0197, iter [04000, 05004], lr: 0.000066, loss: 1.5024
2022-07-14 02:19:09 - train: epoch 0197, iter [04100, 05004], lr: 0.000066, loss: 1.0244
2022-07-14 02:19:44 - train: epoch 0197, iter [04200, 05004], lr: 0.000065, loss: 1.0738
2022-07-14 02:20:18 - train: epoch 0197, iter [04300, 05004], lr: 0.000064, loss: 1.5108
2022-07-14 02:20:52 - train: epoch 0197, iter [04400, 05004], lr: 0.000063, loss: 1.3197
2022-07-14 02:21:26 - train: epoch 0197, iter [04500, 05004], lr: 0.000062, loss: 1.0240
2022-07-14 02:22:00 - train: epoch 0197, iter [04600, 05004], lr: 0.000062, loss: 1.1462
2022-07-14 02:22:33 - train: epoch 0197, iter [04700, 05004], lr: 0.000061, loss: 1.3759
2022-07-14 02:23:07 - train: epoch 0197, iter [04800, 05004], lr: 0.000060, loss: 1.1600
2022-07-14 02:23:41 - train: epoch 0197, iter [04900, 05004], lr: 0.000059, loss: 1.2231
2022-07-14 02:24:14 - train: epoch 0197, iter [05000, 05004], lr: 0.000058, loss: 1.1885
2022-07-14 02:24:15 - train: epoch 197, train_loss: 1.2225
2022-07-14 02:25:27 - eval: epoch: 197, acc1: 77.732%, acc5: 93.802%, test_loss: 0.8916, per_image_load_time: 1.924ms, per_image_inference_time: 0.466ms
2022-07-14 02:25:28 - until epoch: 197, best_acc1: 77.732%
2022-07-14 02:25:28 - epoch 198 lr: 0.000058
2022-07-14 02:26:07 - train: epoch 0198, iter [00100, 05004], lr: 0.000058, loss: 1.1621
2022-07-14 02:26:41 - train: epoch 0198, iter [00200, 05004], lr: 0.000057, loss: 1.2387
2022-07-14 02:27:14 - train: epoch 0198, iter [00300, 05004], lr: 0.000056, loss: 1.3267
2022-07-14 02:27:49 - train: epoch 0198, iter [00400, 05004], lr: 0.000055, loss: 1.0953
2022-07-14 02:28:22 - train: epoch 0198, iter [00500, 05004], lr: 0.000055, loss: 1.6325
2022-07-14 02:28:57 - train: epoch 0198, iter [00600, 05004], lr: 0.000054, loss: 1.1648
2022-07-14 02:29:30 - train: epoch 0198, iter [00700, 05004], lr: 0.000053, loss: 1.3134
2022-07-14 02:30:04 - train: epoch 0198, iter [00800, 05004], lr: 0.000052, loss: 1.0276
2022-07-14 02:30:38 - train: epoch 0198, iter [00900, 05004], lr: 0.000052, loss: 1.0365
2022-07-14 02:31:12 - train: epoch 0198, iter [01000, 05004], lr: 0.000051, loss: 1.2199
2022-07-14 02:31:47 - train: epoch 0198, iter [01100, 05004], lr: 0.000050, loss: 0.9650
2022-07-14 02:32:21 - train: epoch 0198, iter [01200, 05004], lr: 0.000049, loss: 1.4373
2022-07-14 02:32:55 - train: epoch 0198, iter [01300, 05004], lr: 0.000049, loss: 1.1006
2022-07-14 02:33:29 - train: epoch 0198, iter [01400, 05004], lr: 0.000048, loss: 1.1363
2022-07-14 02:34:04 - train: epoch 0198, iter [01500, 05004], lr: 0.000047, loss: 1.3288
2022-07-14 02:34:37 - train: epoch 0198, iter [01600, 05004], lr: 0.000047, loss: 1.0614
2022-07-14 02:35:12 - train: epoch 0198, iter [01700, 05004], lr: 0.000046, loss: 1.2381
2022-07-14 02:35:47 - train: epoch 0198, iter [01800, 05004], lr: 0.000045, loss: 1.2721
2022-07-14 02:36:21 - train: epoch 0198, iter [01900, 05004], lr: 0.000045, loss: 1.2513
2022-07-14 02:36:57 - train: epoch 0198, iter [02000, 05004], lr: 0.000044, loss: 1.3566
2022-07-14 02:37:31 - train: epoch 0198, iter [02100, 05004], lr: 0.000043, loss: 1.2502
2022-07-14 02:38:05 - train: epoch 0198, iter [02200, 05004], lr: 0.000043, loss: 1.0881
2022-07-14 02:38:40 - train: epoch 0198, iter [02300, 05004], lr: 0.000042, loss: 1.1135
2022-07-14 02:39:14 - train: epoch 0198, iter [02400, 05004], lr: 0.000041, loss: 1.4544
2022-07-14 02:39:48 - train: epoch 0198, iter [02500, 05004], lr: 0.000041, loss: 1.2845
2022-07-14 02:40:23 - train: epoch 0198, iter [02600, 05004], lr: 0.000040, loss: 1.1555
2022-07-14 02:40:57 - train: epoch 0198, iter [02700, 05004], lr: 0.000039, loss: 1.1490
2022-07-14 02:41:32 - train: epoch 0198, iter [02800, 05004], lr: 0.000039, loss: 1.3340
2022-07-14 02:42:07 - train: epoch 0198, iter [02900, 05004], lr: 0.000038, loss: 1.3659
2022-07-14 02:42:41 - train: epoch 0198, iter [03000, 05004], lr: 0.000037, loss: 1.4996
2022-07-14 02:43:16 - train: epoch 0198, iter [03100, 05004], lr: 0.000037, loss: 1.4665
2022-07-14 02:43:52 - train: epoch 0198, iter [03200, 05004], lr: 0.000036, loss: 1.3152
2022-07-14 02:44:26 - train: epoch 0198, iter [03300, 05004], lr: 0.000036, loss: 1.2434
2022-07-14 02:45:00 - train: epoch 0198, iter [03400, 05004], lr: 0.000035, loss: 1.0452
2022-07-14 02:45:35 - train: epoch 0198, iter [03500, 05004], lr: 0.000034, loss: 1.3279
2022-07-14 02:46:10 - train: epoch 0198, iter [03600, 05004], lr: 0.000034, loss: 1.3494
2022-07-14 02:46:44 - train: epoch 0198, iter [03700, 05004], lr: 0.000033, loss: 1.1666
2022-07-14 02:47:19 - train: epoch 0198, iter [03800, 05004], lr: 0.000033, loss: 1.3736
2022-07-14 02:47:53 - train: epoch 0198, iter [03900, 05004], lr: 0.000032, loss: 1.2092
2022-07-14 02:48:27 - train: epoch 0198, iter [04000, 05004], lr: 0.000031, loss: 1.2949
2022-07-14 02:49:01 - train: epoch 0198, iter [04100, 05004], lr: 0.000031, loss: 1.1200
2022-07-14 02:49:36 - train: epoch 0198, iter [04200, 05004], lr: 0.000030, loss: 1.1951
2022-07-14 02:50:11 - train: epoch 0198, iter [04300, 05004], lr: 0.000030, loss: 1.1476
2022-07-14 02:50:45 - train: epoch 0198, iter [04400, 05004], lr: 0.000029, loss: 1.1422
2022-07-14 02:51:20 - train: epoch 0198, iter [04500, 05004], lr: 0.000029, loss: 1.2650
2022-07-14 02:51:53 - train: epoch 0198, iter [04600, 05004], lr: 0.000028, loss: 1.2939
2022-07-14 02:52:28 - train: epoch 0198, iter [04700, 05004], lr: 0.000028, loss: 1.3505
2022-07-14 02:53:03 - train: epoch 0198, iter [04800, 05004], lr: 0.000027, loss: 1.3886
2022-07-14 02:53:37 - train: epoch 0198, iter [04900, 05004], lr: 0.000026, loss: 1.1638
2022-07-14 02:54:10 - train: epoch 0198, iter [05000, 05004], lr: 0.000026, loss: 1.3405
2022-07-14 02:54:11 - train: epoch 198, train_loss: 1.2190
2022-07-14 02:55:24 - eval: epoch: 198, acc1: 77.736%, acc5: 93.828%, test_loss: 0.8931, per_image_load_time: 2.411ms, per_image_inference_time: 0.452ms
2022-07-14 02:55:25 - until epoch: 198, best_acc1: 77.736%
2022-07-14 02:55:25 - epoch 199 lr: 0.000026
2022-07-14 02:56:05 - train: epoch 0199, iter [00100, 05004], lr: 0.000025, loss: 1.3213
2022-07-14 02:56:38 - train: epoch 0199, iter [00200, 05004], lr: 0.000025, loss: 1.2807
2022-07-14 02:57:12 - train: epoch 0199, iter [00300, 05004], lr: 0.000024, loss: 1.1564
2022-07-14 02:57:46 - train: epoch 0199, iter [00400, 05004], lr: 0.000024, loss: 1.2318
2022-07-14 02:58:20 - train: epoch 0199, iter [00500, 05004], lr: 0.000023, loss: 1.2358
2022-07-14 02:58:54 - train: epoch 0199, iter [00600, 05004], lr: 0.000023, loss: 1.3775
2022-07-14 02:59:28 - train: epoch 0199, iter [00700, 05004], lr: 0.000022, loss: 1.1016
2022-07-14 03:00:02 - train: epoch 0199, iter [00800, 05004], lr: 0.000022, loss: 0.9588
2022-07-14 03:00:36 - train: epoch 0199, iter [00900, 05004], lr: 0.000021, loss: 1.1614
2022-07-14 03:01:11 - train: epoch 0199, iter [01000, 05004], lr: 0.000021, loss: 1.5108
2022-07-14 03:01:46 - train: epoch 0199, iter [01100, 05004], lr: 0.000021, loss: 1.2892
2022-07-14 03:02:20 - train: epoch 0199, iter [01200, 05004], lr: 0.000020, loss: 1.3354
2022-07-14 03:02:55 - train: epoch 0199, iter [01300, 05004], lr: 0.000020, loss: 1.2519
2022-07-14 03:03:30 - train: epoch 0199, iter [01400, 05004], lr: 0.000019, loss: 1.2468
2022-07-14 03:04:04 - train: epoch 0199, iter [01500, 05004], lr: 0.000019, loss: 1.3373
2022-07-14 03:04:39 - train: epoch 0199, iter [01600, 05004], lr: 0.000018, loss: 1.0894
2022-07-14 03:05:14 - train: epoch 0199, iter [01700, 05004], lr: 0.000018, loss: 1.2777
2022-07-14 03:05:50 - train: epoch 0199, iter [01800, 05004], lr: 0.000017, loss: 1.5742
2022-07-14 03:06:25 - train: epoch 0199, iter [01900, 05004], lr: 0.000017, loss: 1.2645
2022-07-14 03:06:58 - train: epoch 0199, iter [02000, 05004], lr: 0.000017, loss: 1.2873
2022-07-14 03:07:33 - train: epoch 0199, iter [02100, 05004], lr: 0.000016, loss: 1.2588
2022-07-14 03:08:08 - train: epoch 0199, iter [02200, 05004], lr: 0.000016, loss: 1.1117
2022-07-14 03:08:42 - train: epoch 0199, iter [02300, 05004], lr: 0.000015, loss: 1.1767
2022-07-14 03:09:17 - train: epoch 0199, iter [02400, 05004], lr: 0.000015, loss: 1.2062
2022-07-14 03:09:52 - train: epoch 0199, iter [02500, 05004], lr: 0.000015, loss: 1.0783
2022-07-14 03:10:27 - train: epoch 0199, iter [02600, 05004], lr: 0.000014, loss: 1.2722
2022-07-14 03:11:01 - train: epoch 0199, iter [02700, 05004], lr: 0.000014, loss: 1.3007
2022-07-14 03:11:36 - train: epoch 0199, iter [02800, 05004], lr: 0.000013, loss: 1.0104
2022-07-14 03:12:11 - train: epoch 0199, iter [02900, 05004], lr: 0.000013, loss: 1.2776
2022-07-14 03:12:45 - train: epoch 0199, iter [03000, 05004], lr: 0.000013, loss: 1.2760
2022-07-14 03:13:20 - train: epoch 0199, iter [03100, 05004], lr: 0.000012, loss: 1.3989
2022-07-14 03:13:55 - train: epoch 0199, iter [03200, 05004], lr: 0.000012, loss: 1.1243
2022-07-14 03:14:30 - train: epoch 0199, iter [03300, 05004], lr: 0.000012, loss: 1.5258
2022-07-14 03:15:05 - train: epoch 0199, iter [03400, 05004], lr: 0.000011, loss: 1.4031
2022-07-14 03:15:40 - train: epoch 0199, iter [03500, 05004], lr: 0.000011, loss: 1.2103
2022-07-14 03:16:14 - train: epoch 0199, iter [03600, 05004], lr: 0.000011, loss: 1.1998
2022-07-14 03:16:49 - train: epoch 0199, iter [03700, 05004], lr: 0.000010, loss: 1.1915
2022-07-14 03:17:23 - train: epoch 0199, iter [03800, 05004], lr: 0.000010, loss: 1.3523
2022-07-14 03:17:58 - train: epoch 0199, iter [03900, 05004], lr: 0.000010, loss: 1.2087
2022-07-14 03:18:33 - train: epoch 0199, iter [04000, 05004], lr: 0.000009, loss: 1.0810
2022-07-14 03:19:08 - train: epoch 0199, iter [04100, 05004], lr: 0.000009, loss: 1.4162
2022-07-14 03:19:42 - train: epoch 0199, iter [04200, 05004], lr: 0.000009, loss: 1.1132
2022-07-14 03:20:17 - train: epoch 0199, iter [04300, 05004], lr: 0.000008, loss: 1.2210
2022-07-14 03:20:51 - train: epoch 0199, iter [04400, 05004], lr: 0.000008, loss: 1.0549
2022-07-14 03:21:26 - train: epoch 0199, iter [04500, 05004], lr: 0.000008, loss: 1.0570
2022-07-14 03:22:01 - train: epoch 0199, iter [04600, 05004], lr: 0.000008, loss: 1.2421
2022-07-14 03:22:36 - train: epoch 0199, iter [04700, 05004], lr: 0.000007, loss: 1.1776
2022-07-14 03:23:11 - train: epoch 0199, iter [04800, 05004], lr: 0.000007, loss: 1.1661
2022-07-14 03:23:46 - train: epoch 0199, iter [04900, 05004], lr: 0.000007, loss: 1.2540
2022-07-14 03:24:19 - train: epoch 0199, iter [05000, 05004], lr: 0.000006, loss: 1.1624
2022-07-14 03:24:20 - train: epoch 199, train_loss: 1.2192
2022-07-14 03:25:34 - eval: epoch: 199, acc1: 77.696%, acc5: 93.824%, test_loss: 0.8916, per_image_load_time: 2.412ms, per_image_inference_time: 0.458ms
2022-07-14 03:25:34 - until epoch: 199, best_acc1: 77.736%
2022-07-14 03:25:34 - epoch 200 lr: 0.000006
2022-07-14 03:26:13 - train: epoch 0200, iter [00100, 05004], lr: 0.000006, loss: 1.1835
2022-07-14 03:26:47 - train: epoch 0200, iter [00200, 05004], lr: 0.000006, loss: 1.3361
2022-07-14 03:27:20 - train: epoch 0200, iter [00300, 05004], lr: 0.000006, loss: 1.0159
2022-07-14 03:27:53 - train: epoch 0200, iter [00400, 05004], lr: 0.000005, loss: 1.3151
2022-07-14 03:28:27 - train: epoch 0200, iter [00500, 05004], lr: 0.000005, loss: 0.9705
2022-07-14 03:29:01 - train: epoch 0200, iter [00600, 05004], lr: 0.000005, loss: 1.2926
2022-07-14 03:29:33 - train: epoch 0200, iter [00700, 05004], lr: 0.000005, loss: 1.2363
2022-07-14 03:30:08 - train: epoch 0200, iter [00800, 05004], lr: 0.000005, loss: 1.3082
2022-07-14 03:30:41 - train: epoch 0200, iter [00900, 05004], lr: 0.000004, loss: 1.2569
2022-07-14 03:31:14 - train: epoch 0200, iter [01000, 05004], lr: 0.000004, loss: 1.2897
2022-07-14 03:31:47 - train: epoch 0200, iter [01100, 05004], lr: 0.000004, loss: 1.2295
2022-07-14 03:32:21 - train: epoch 0200, iter [01200, 05004], lr: 0.000004, loss: 1.0532
2022-07-14 03:32:54 - train: epoch 0200, iter [01300, 05004], lr: 0.000004, loss: 1.2032
2022-07-14 03:33:28 - train: epoch 0200, iter [01400, 05004], lr: 0.000003, loss: 1.1108
2022-07-14 03:34:02 - train: epoch 0200, iter [01500, 05004], lr: 0.000003, loss: 1.3793
2022-07-14 03:34:35 - train: epoch 0200, iter [01600, 05004], lr: 0.000003, loss: 1.1137
2022-07-14 03:35:09 - train: epoch 0200, iter [01700, 05004], lr: 0.000003, loss: 1.3456
2022-07-14 03:35:42 - train: epoch 0200, iter [01800, 05004], lr: 0.000003, loss: 1.4552
2022-07-14 03:36:15 - train: epoch 0200, iter [01900, 05004], lr: 0.000002, loss: 1.1498
2022-07-14 03:36:50 - train: epoch 0200, iter [02000, 05004], lr: 0.000002, loss: 1.2738
2022-07-14 03:37:23 - train: epoch 0200, iter [02100, 05004], lr: 0.000002, loss: 1.3184
2022-07-14 03:37:58 - train: epoch 0200, iter [02200, 05004], lr: 0.000002, loss: 1.3603
2022-07-14 03:38:31 - train: epoch 0200, iter [02300, 05004], lr: 0.000002, loss: 1.3104
2022-07-14 03:39:05 - train: epoch 0200, iter [02400, 05004], lr: 0.000002, loss: 1.3734
2022-07-14 03:39:39 - train: epoch 0200, iter [02500, 05004], lr: 0.000002, loss: 1.1499
2022-07-14 03:40:13 - train: epoch 0200, iter [02600, 05004], lr: 0.000001, loss: 1.0057
2022-07-14 03:40:48 - train: epoch 0200, iter [02700, 05004], lr: 0.000001, loss: 1.1896
2022-07-14 03:41:21 - train: epoch 0200, iter [02800, 05004], lr: 0.000001, loss: 1.0998
2022-07-14 03:41:56 - train: epoch 0200, iter [02900, 05004], lr: 0.000001, loss: 1.0351
2022-07-14 03:42:30 - train: epoch 0200, iter [03000, 05004], lr: 0.000001, loss: 1.0839
2022-07-14 03:43:04 - train: epoch 0200, iter [03100, 05004], lr: 0.000001, loss: 1.2337
2022-07-14 03:43:38 - train: epoch 0200, iter [03200, 05004], lr: 0.000001, loss: 1.2933
2022-07-14 03:44:12 - train: epoch 0200, iter [03300, 05004], lr: 0.000001, loss: 1.4386
2022-07-14 03:44:46 - train: epoch 0200, iter [03400, 05004], lr: 0.000001, loss: 1.2694
2022-07-14 03:45:20 - train: epoch 0200, iter [03500, 05004], lr: 0.000001, loss: 1.2361
2022-07-14 03:45:55 - train: epoch 0200, iter [03600, 05004], lr: 0.000001, loss: 1.1879
2022-07-14 03:46:29 - train: epoch 0200, iter [03700, 05004], lr: 0.000000, loss: 1.1578
2022-07-14 03:47:03 - train: epoch 0200, iter [03800, 05004], lr: 0.000000, loss: 1.1347
2022-07-14 03:47:37 - train: epoch 0200, iter [03900, 05004], lr: 0.000000, loss: 1.1473
2022-07-14 03:48:11 - train: epoch 0200, iter [04000, 05004], lr: 0.000000, loss: 0.9433
2022-07-14 03:48:46 - train: epoch 0200, iter [04100, 05004], lr: 0.000000, loss: 1.3123
2022-07-14 03:49:19 - train: epoch 0200, iter [04200, 05004], lr: 0.000000, loss: 1.1355
2022-07-14 03:49:54 - train: epoch 0200, iter [04300, 05004], lr: 0.000000, loss: 1.3529
2022-07-14 03:50:29 - train: epoch 0200, iter [04400, 05004], lr: 0.000000, loss: 1.3563
2022-07-14 03:51:03 - train: epoch 0200, iter [04500, 05004], lr: 0.000000, loss: 1.0406
2022-07-14 03:51:38 - train: epoch 0200, iter [04600, 05004], lr: 0.000000, loss: 1.2213
2022-07-14 03:52:12 - train: epoch 0200, iter [04700, 05004], lr: 0.000000, loss: 1.1880
2022-07-14 03:52:46 - train: epoch 0200, iter [04800, 05004], lr: 0.000000, loss: 1.3122
2022-07-14 03:53:21 - train: epoch 0200, iter [04900, 05004], lr: 0.000000, loss: 1.1571
2022-07-14 03:53:54 - train: epoch 0200, iter [05000, 05004], lr: 0.000000, loss: 1.4485
2022-07-14 03:53:55 - train: epoch 200, train_loss: 1.2178
2022-07-14 03:55:09 - eval: epoch: 200, acc1: 77.648%, acc5: 93.820%, test_loss: 0.8913, per_image_load_time: 2.388ms, per_image_inference_time: 0.450ms
2022-07-14 03:55:09 - until epoch: 200, best_acc1: 77.736%
2022-07-14 03:55:09 - train done. model: resnet50, train time: 100.232 hours, best_acc1: 77.736%
