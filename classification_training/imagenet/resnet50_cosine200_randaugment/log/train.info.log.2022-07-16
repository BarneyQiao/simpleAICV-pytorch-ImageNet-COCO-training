2022-07-16 07:41:17 - train: epoch 0127, iter [01600, 05004], lr: 0.031280, loss: 2.1653
2022-07-16 07:41:51 - train: epoch 0127, iter [01700, 05004], lr: 0.031265, loss: 2.2516
2022-07-16 07:42:26 - train: epoch 0127, iter [01800, 05004], lr: 0.031250, loss: 2.3213
2022-07-16 07:43:01 - train: epoch 0127, iter [01900, 05004], lr: 0.031235, loss: 2.3829
2022-07-16 07:43:34 - train: epoch 0127, iter [02000, 05004], lr: 0.031220, loss: 2.1105
2022-07-16 07:44:10 - train: epoch 0127, iter [02100, 05004], lr: 0.031205, loss: 2.4389
2022-07-16 07:44:44 - train: epoch 0127, iter [02200, 05004], lr: 0.031190, loss: 2.2850
2022-07-16 07:45:19 - train: epoch 0127, iter [02300, 05004], lr: 0.031175, loss: 2.0509
2022-07-16 07:45:52 - train: epoch 0127, iter [02400, 05004], lr: 0.031160, loss: 2.5053
2022-07-16 07:46:28 - train: epoch 0127, iter [02500, 05004], lr: 0.031146, loss: 2.3641
2022-07-16 07:47:02 - train: epoch 0127, iter [02600, 05004], lr: 0.031131, loss: 1.9869
2022-07-16 07:47:37 - train: epoch 0127, iter [02700, 05004], lr: 0.031116, loss: 2.4012
2022-07-16 07:48:12 - train: epoch 0127, iter [02800, 05004], lr: 0.031101, loss: 2.2652
2022-07-16 07:48:46 - train: epoch 0127, iter [02900, 05004], lr: 0.031086, loss: 2.4180
2022-07-16 07:49:21 - train: epoch 0127, iter [03000, 05004], lr: 0.031071, loss: 2.4827
2022-07-16 07:49:56 - train: epoch 0127, iter [03100, 05004], lr: 0.031056, loss: 2.4361
2022-07-16 07:50:31 - train: epoch 0127, iter [03200, 05004], lr: 0.031041, loss: 2.2696
2022-07-16 07:51:05 - train: epoch 0127, iter [03300, 05004], lr: 0.031026, loss: 2.6599
2022-07-16 07:51:40 - train: epoch 0127, iter [03400, 05004], lr: 0.031011, loss: 2.4139
2022-07-16 07:52:14 - train: epoch 0127, iter [03500, 05004], lr: 0.030997, loss: 2.2920
2022-07-16 07:52:49 - train: epoch 0127, iter [03600, 05004], lr: 0.030982, loss: 2.3812
2022-07-16 07:53:24 - train: epoch 0127, iter [03700, 05004], lr: 0.030967, loss: 2.7081
2022-07-16 07:53:59 - train: epoch 0127, iter [03800, 05004], lr: 0.030952, loss: 2.1562
2022-07-16 07:54:33 - train: epoch 0127, iter [03900, 05004], lr: 0.030937, loss: 2.4434
2022-07-16 07:55:08 - train: epoch 0127, iter [04000, 05004], lr: 0.030922, loss: 1.9569
2022-07-16 07:55:42 - train: epoch 0127, iter [04100, 05004], lr: 0.030907, loss: 2.4170
2022-07-16 07:56:18 - train: epoch 0127, iter [04200, 05004], lr: 0.030892, loss: 2.2977
2022-07-16 07:56:53 - train: epoch 0127, iter [04300, 05004], lr: 0.030878, loss: 2.1634
2022-07-16 07:57:27 - train: epoch 0127, iter [04400, 05004], lr: 0.030863, loss: 2.4027
2022-07-16 07:58:02 - train: epoch 0127, iter [04500, 05004], lr: 0.030848, loss: 2.4176
2022-07-16 07:58:37 - train: epoch 0127, iter [04600, 05004], lr: 0.030833, loss: 2.0914
2022-07-16 07:59:12 - train: epoch 0127, iter [04700, 05004], lr: 0.030818, loss: 2.4504
2022-07-16 07:59:47 - train: epoch 0127, iter [04800, 05004], lr: 0.030803, loss: 2.3708
2022-07-16 08:00:22 - train: epoch 0127, iter [04900, 05004], lr: 0.030788, loss: 2.4470
2022-07-16 08:00:56 - train: epoch 0127, iter [05000, 05004], lr: 0.030773, loss: 2.2092
2022-07-16 08:00:57 - train: epoch 127, train_loss: 2.3472
2022-07-16 08:02:12 - eval: epoch: 127, acc1: 66.422%, acc5: 87.660%, test_loss: 1.3741, per_image_load_time: 1.691ms, per_image_inference_time: 0.468ms
2022-07-16 08:02:12 - until epoch: 127, best_acc1: 66.782%
2022-07-16 08:02:12 - epoch 128 lr: 0.030773
2022-07-16 08:02:51 - train: epoch 0128, iter [00100, 05004], lr: 0.030758, loss: 2.5134
2022-07-16 08:03:25 - train: epoch 0128, iter [00200, 05004], lr: 0.030743, loss: 2.1669
2022-07-16 08:03:59 - train: epoch 0128, iter [00300, 05004], lr: 0.030728, loss: 2.2520
2022-07-16 08:04:34 - train: epoch 0128, iter [00400, 05004], lr: 0.030713, loss: 1.9716
2022-07-16 08:05:07 - train: epoch 0128, iter [00500, 05004], lr: 0.030699, loss: 2.6008
2022-07-16 08:05:41 - train: epoch 0128, iter [00600, 05004], lr: 0.030684, loss: 2.1394
2022-07-16 08:06:15 - train: epoch 0128, iter [00700, 05004], lr: 0.030669, loss: 2.5561
2022-07-16 08:06:49 - train: epoch 0128, iter [00800, 05004], lr: 0.030654, loss: 2.3370
2022-07-16 08:07:24 - train: epoch 0128, iter [00900, 05004], lr: 0.030639, loss: 2.3333
2022-07-16 08:07:59 - train: epoch 0128, iter [01000, 05004], lr: 0.030624, loss: 2.4799
2022-07-16 08:08:33 - train: epoch 0128, iter [01100, 05004], lr: 0.030610, loss: 2.6524
2022-07-16 08:09:07 - train: epoch 0128, iter [01200, 05004], lr: 0.030595, loss: 2.0529
2022-07-16 08:09:41 - train: epoch 0128, iter [01300, 05004], lr: 0.030580, loss: 2.1902
2022-07-16 08:10:16 - train: epoch 0128, iter [01400, 05004], lr: 0.030565, loss: 2.1821
2022-07-16 08:10:49 - train: epoch 0128, iter [01500, 05004], lr: 0.030550, loss: 2.4119
2022-07-16 08:11:24 - train: epoch 0128, iter [01600, 05004], lr: 0.030535, loss: 2.1553
2022-07-16 08:11:58 - train: epoch 0128, iter [01700, 05004], lr: 0.030521, loss: 2.2418
2022-07-16 08:12:34 - train: epoch 0128, iter [01800, 05004], lr: 0.030506, loss: 2.2437
2022-07-16 08:13:07 - train: epoch 0128, iter [01900, 05004], lr: 0.030491, loss: 2.8080
2022-07-16 08:13:42 - train: epoch 0128, iter [02000, 05004], lr: 0.030476, loss: 2.3414
2022-07-16 08:14:16 - train: epoch 0128, iter [02100, 05004], lr: 0.030461, loss: 2.4584
2022-07-16 08:14:49 - train: epoch 0128, iter [02200, 05004], lr: 0.030446, loss: 2.6404
2022-07-16 08:15:24 - train: epoch 0128, iter [02300, 05004], lr: 0.030432, loss: 2.3685
2022-07-16 08:15:58 - train: epoch 0128, iter [02400, 05004], lr: 0.030417, loss: 2.1684
2022-07-16 08:16:33 - train: epoch 0128, iter [02500, 05004], lr: 0.030402, loss: 2.5166
2022-07-16 08:17:08 - train: epoch 0128, iter [02600, 05004], lr: 0.030387, loss: 2.0425
2022-07-16 08:17:42 - train: epoch 0128, iter [02700, 05004], lr: 0.030372, loss: 2.3693
2022-07-16 08:18:17 - train: epoch 0128, iter [02800, 05004], lr: 0.030358, loss: 2.2143
2022-07-16 08:18:51 - train: epoch 0128, iter [02900, 05004], lr: 0.030343, loss: 2.5690
2022-07-16 08:19:26 - train: epoch 0128, iter [03000, 05004], lr: 0.030328, loss: 2.0124
2022-07-16 08:20:00 - train: epoch 0128, iter [03100, 05004], lr: 0.030313, loss: 2.3483
2022-07-16 08:20:34 - train: epoch 0128, iter [03200, 05004], lr: 0.030298, loss: 2.7791
2022-07-16 08:21:09 - train: epoch 0128, iter [03300, 05004], lr: 0.030284, loss: 2.2266
2022-07-16 08:21:43 - train: epoch 0128, iter [03400, 05004], lr: 0.030269, loss: 2.2183
2022-07-16 08:22:16 - train: epoch 0128, iter [03500, 05004], lr: 0.030254, loss: 2.1170
2022-07-16 08:22:52 - train: epoch 0128, iter [03600, 05004], lr: 0.030239, loss: 2.5790
2022-07-16 08:23:27 - train: epoch 0128, iter [03700, 05004], lr: 0.030224, loss: 2.4606
2022-07-16 08:24:01 - train: epoch 0128, iter [03800, 05004], lr: 0.030210, loss: 2.3713
2022-07-16 08:24:35 - train: epoch 0128, iter [03900, 05004], lr: 0.030195, loss: 2.0003
2022-07-16 08:25:10 - train: epoch 0128, iter [04000, 05004], lr: 0.030180, loss: 2.2659
2022-07-16 08:25:44 - train: epoch 0128, iter [04100, 05004], lr: 0.030165, loss: 2.1309
2022-07-16 08:26:19 - train: epoch 0128, iter [04200, 05004], lr: 0.030150, loss: 2.3253
2022-07-16 08:26:53 - train: epoch 0128, iter [04300, 05004], lr: 0.030136, loss: 2.5402
2022-07-16 08:27:28 - train: epoch 0128, iter [04400, 05004], lr: 0.030121, loss: 2.2401
2022-07-16 08:28:02 - train: epoch 0128, iter [04500, 05004], lr: 0.030106, loss: 2.2917
2022-07-16 08:28:36 - train: epoch 0128, iter [04600, 05004], lr: 0.030091, loss: 2.2799
2022-07-16 08:29:11 - train: epoch 0128, iter [04700, 05004], lr: 0.030077, loss: 2.3487
2022-07-16 08:29:46 - train: epoch 0128, iter [04800, 05004], lr: 0.030062, loss: 2.0931
2022-07-16 08:30:21 - train: epoch 0128, iter [04900, 05004], lr: 0.030047, loss: 2.3722
2022-07-16 08:30:53 - train: epoch 0128, iter [05000, 05004], lr: 0.030032, loss: 2.4194
2022-07-16 08:30:54 - train: epoch 128, train_loss: 2.3396
2022-07-16 08:32:09 - eval: epoch: 128, acc1: 67.324%, acc5: 88.200%, test_loss: 1.3437, per_image_load_time: 1.554ms, per_image_inference_time: 0.484ms
2022-07-16 08:32:10 - until epoch: 128, best_acc1: 67.324%
2022-07-16 08:32:10 - epoch 129 lr: 0.030032
2022-07-16 08:32:50 - train: epoch 0129, iter [00100, 05004], lr: 0.030017, loss: 2.2268
2022-07-16 08:33:24 - train: epoch 0129, iter [00200, 05004], lr: 0.030002, loss: 2.4321
2022-07-16 08:33:59 - train: epoch 0129, iter [00300, 05004], lr: 0.029988, loss: 2.2606
2022-07-16 08:34:34 - train: epoch 0129, iter [00400, 05004], lr: 0.029973, loss: 2.2673
2022-07-16 08:35:09 - train: epoch 0129, iter [00500, 05004], lr: 0.029958, loss: 2.1534
2022-07-16 08:35:44 - train: epoch 0129, iter [00600, 05004], lr: 0.029943, loss: 2.6714
2022-07-16 08:36:19 - train: epoch 0129, iter [00700, 05004], lr: 0.029929, loss: 2.4689
2022-07-16 08:36:54 - train: epoch 0129, iter [00800, 05004], lr: 0.029914, loss: 2.2345
2022-07-16 08:37:28 - train: epoch 0129, iter [00900, 05004], lr: 0.029899, loss: 2.2353
2022-07-16 08:38:03 - train: epoch 0129, iter [01000, 05004], lr: 0.029884, loss: 2.3753
2022-07-16 08:38:38 - train: epoch 0129, iter [01100, 05004], lr: 0.029870, loss: 2.4587
2022-07-16 08:39:13 - train: epoch 0129, iter [01200, 05004], lr: 0.029855, loss: 2.2759
2022-07-16 08:39:48 - train: epoch 0129, iter [01300, 05004], lr: 0.029840, loss: 2.0051
2022-07-16 08:40:23 - train: epoch 0129, iter [01400, 05004], lr: 0.029825, loss: 2.4313
2022-07-16 08:40:57 - train: epoch 0129, iter [01500, 05004], lr: 0.029811, loss: 2.0974
2022-07-16 08:41:32 - train: epoch 0129, iter [01600, 05004], lr: 0.029796, loss: 2.3076
2022-07-16 08:42:05 - train: epoch 0129, iter [01700, 05004], lr: 0.029781, loss: 2.2632
2022-07-16 08:42:39 - train: epoch 0129, iter [01800, 05004], lr: 0.029766, loss: 2.4264
2022-07-16 08:43:13 - train: epoch 0129, iter [01900, 05004], lr: 0.029752, loss: 2.5217
2022-07-16 08:43:48 - train: epoch 0129, iter [02000, 05004], lr: 0.029737, loss: 2.1976
2022-07-16 08:44:22 - train: epoch 0129, iter [02100, 05004], lr: 0.029722, loss: 2.2099
2022-07-16 08:44:57 - train: epoch 0129, iter [02200, 05004], lr: 0.029708, loss: 2.1833
2022-07-16 08:45:31 - train: epoch 0129, iter [02300, 05004], lr: 0.029693, loss: 2.3982
2022-07-16 08:46:06 - train: epoch 0129, iter [02400, 05004], lr: 0.029678, loss: 2.3580
2022-07-16 08:46:40 - train: epoch 0129, iter [02500, 05004], lr: 0.029663, loss: 2.5527
2022-07-16 08:47:14 - train: epoch 0129, iter [02600, 05004], lr: 0.029649, loss: 2.2880
2022-07-16 08:47:49 - train: epoch 0129, iter [02700, 05004], lr: 0.029634, loss: 2.0489
2022-07-16 08:48:23 - train: epoch 0129, iter [02800, 05004], lr: 0.029619, loss: 2.1949
2022-07-16 08:48:58 - train: epoch 0129, iter [02900, 05004], lr: 0.029605, loss: 2.5338
2022-07-16 08:49:32 - train: epoch 0129, iter [03000, 05004], lr: 0.029590, loss: 2.2684
2022-07-16 08:50:07 - train: epoch 0129, iter [03100, 05004], lr: 0.029575, loss: 1.9922
2022-07-16 08:50:42 - train: epoch 0129, iter [03200, 05004], lr: 0.029561, loss: 2.0840
2022-07-16 08:51:17 - train: epoch 0129, iter [03300, 05004], lr: 0.029546, loss: 2.3818
2022-07-16 08:51:52 - train: epoch 0129, iter [03400, 05004], lr: 0.029531, loss: 2.3645
2022-07-16 08:52:26 - train: epoch 0129, iter [03500, 05004], lr: 0.029517, loss: 2.3101
2022-07-16 08:53:01 - train: epoch 0129, iter [03600, 05004], lr: 0.029502, loss: 2.2668
2022-07-16 08:53:34 - train: epoch 0129, iter [03700, 05004], lr: 0.029487, loss: 2.0764
2022-07-16 08:54:10 - train: epoch 0129, iter [03800, 05004], lr: 0.029472, loss: 2.1605
2022-07-16 08:54:44 - train: epoch 0129, iter [03900, 05004], lr: 0.029458, loss: 2.2431
2022-07-16 08:55:19 - train: epoch 0129, iter [04000, 05004], lr: 0.029443, loss: 2.5062
2022-07-16 08:55:53 - train: epoch 0129, iter [04100, 05004], lr: 0.029428, loss: 2.3978
2022-07-16 08:56:28 - train: epoch 0129, iter [04200, 05004], lr: 0.029414, loss: 2.2849
2022-07-16 08:57:03 - train: epoch 0129, iter [04300, 05004], lr: 0.029399, loss: 2.2810
2022-07-16 08:57:37 - train: epoch 0129, iter [04400, 05004], lr: 0.029384, loss: 2.2042
2022-07-16 08:58:12 - train: epoch 0129, iter [04500, 05004], lr: 0.029370, loss: 2.3288
2022-07-16 08:58:46 - train: epoch 0129, iter [04600, 05004], lr: 0.029355, loss: 2.2020
2022-07-16 08:59:22 - train: epoch 0129, iter [04700, 05004], lr: 0.029340, loss: 2.4551
2022-07-16 08:59:56 - train: epoch 0129, iter [04800, 05004], lr: 0.029326, loss: 2.1830
2022-07-16 09:00:30 - train: epoch 0129, iter [04900, 05004], lr: 0.029311, loss: 2.3467
2022-07-16 09:01:04 - train: epoch 0129, iter [05000, 05004], lr: 0.029296, loss: 2.3583
2022-07-16 09:01:05 - train: epoch 129, train_loss: 2.3297
2022-07-16 09:02:20 - eval: epoch: 129, acc1: 67.672%, acc5: 88.438%, test_loss: 1.3111, per_image_load_time: 2.297ms, per_image_inference_time: 0.473ms
2022-07-16 09:02:20 - until epoch: 129, best_acc1: 67.672%
2022-07-16 09:02:20 - epoch 130 lr: 0.029296
2022-07-16 09:03:00 - train: epoch 0130, iter [00100, 05004], lr: 0.029281, loss: 2.4871
2022-07-16 09:03:35 - train: epoch 0130, iter [00200, 05004], lr: 0.029267, loss: 2.2015
2022-07-16 09:04:09 - train: epoch 0130, iter [00300, 05004], lr: 0.029252, loss: 2.5605
2022-07-16 09:04:43 - train: epoch 0130, iter [00400, 05004], lr: 0.029237, loss: 2.4491
2022-07-16 09:05:17 - train: epoch 0130, iter [00500, 05004], lr: 0.029223, loss: 2.5405
2022-07-16 09:05:51 - train: epoch 0130, iter [00600, 05004], lr: 0.029208, loss: 2.5573
2022-07-16 09:06:27 - train: epoch 0130, iter [00700, 05004], lr: 0.029193, loss: 2.1007
2022-07-16 09:07:01 - train: epoch 0130, iter [00800, 05004], lr: 0.029179, loss: 2.1694
2022-07-16 09:07:35 - train: epoch 0130, iter [00900, 05004], lr: 0.029164, loss: 2.1415
2022-07-16 09:08:09 - train: epoch 0130, iter [01000, 05004], lr: 0.029149, loss: 2.3795
2022-07-16 09:08:43 - train: epoch 0130, iter [01100, 05004], lr: 0.029135, loss: 2.5204
2022-07-16 09:09:17 - train: epoch 0130, iter [01200, 05004], lr: 0.029120, loss: 2.3724
2022-07-16 09:09:52 - train: epoch 0130, iter [01300, 05004], lr: 0.029106, loss: 2.3558
2022-07-16 09:10:26 - train: epoch 0130, iter [01400, 05004], lr: 0.029091, loss: 2.5710
2022-07-16 09:11:00 - train: epoch 0130, iter [01500, 05004], lr: 0.029076, loss: 2.3804
2022-07-16 09:11:33 - train: epoch 0130, iter [01600, 05004], lr: 0.029062, loss: 2.3405
2022-07-16 09:12:08 - train: epoch 0130, iter [01700, 05004], lr: 0.029047, loss: 2.2942
2022-07-16 09:12:43 - train: epoch 0130, iter [01800, 05004], lr: 0.029032, loss: 2.2648
2022-07-16 09:13:17 - train: epoch 0130, iter [01900, 05004], lr: 0.029018, loss: 2.1881
2022-07-16 09:13:52 - train: epoch 0130, iter [02000, 05004], lr: 0.029003, loss: 1.9734
2022-07-16 09:14:26 - train: epoch 0130, iter [02100, 05004], lr: 0.028989, loss: 2.4753
2022-07-16 09:15:00 - train: epoch 0130, iter [02200, 05004], lr: 0.028974, loss: 2.2901
2022-07-16 09:15:36 - train: epoch 0130, iter [02300, 05004], lr: 0.028959, loss: 2.4938
2022-07-16 09:16:10 - train: epoch 0130, iter [02400, 05004], lr: 0.028945, loss: 2.5118
2022-07-16 09:16:45 - train: epoch 0130, iter [02500, 05004], lr: 0.028930, loss: 2.4127
2022-07-16 09:17:20 - train: epoch 0130, iter [02600, 05004], lr: 0.028916, loss: 2.3978
2022-07-16 09:17:53 - train: epoch 0130, iter [02700, 05004], lr: 0.028901, loss: 2.3979
2022-07-16 09:18:28 - train: epoch 0130, iter [02800, 05004], lr: 0.028886, loss: 2.0490
2022-07-16 09:19:02 - train: epoch 0130, iter [02900, 05004], lr: 0.028872, loss: 2.3663
2022-07-16 09:19:36 - train: epoch 0130, iter [03000, 05004], lr: 0.028857, loss: 2.2763
2022-07-16 09:20:11 - train: epoch 0130, iter [03100, 05004], lr: 0.028843, loss: 2.1896
2022-07-16 09:20:46 - train: epoch 0130, iter [03200, 05004], lr: 0.028828, loss: 2.3217
2022-07-16 09:21:21 - train: epoch 0130, iter [03300, 05004], lr: 0.028814, loss: 2.8089
2022-07-16 09:21:56 - train: epoch 0130, iter [03400, 05004], lr: 0.028799, loss: 2.6503
2022-07-16 09:22:30 - train: epoch 0130, iter [03500, 05004], lr: 0.028784, loss: 1.9126
2022-07-16 09:23:05 - train: epoch 0130, iter [03600, 05004], lr: 0.028770, loss: 2.3793
2022-07-16 09:23:39 - train: epoch 0130, iter [03700, 05004], lr: 0.028755, loss: 2.3263
2022-07-16 09:24:13 - train: epoch 0130, iter [03800, 05004], lr: 0.028741, loss: 2.2363
2022-07-16 09:24:48 - train: epoch 0130, iter [03900, 05004], lr: 0.028726, loss: 2.0960
2022-07-16 09:25:23 - train: epoch 0130, iter [04000, 05004], lr: 0.028712, loss: 2.0678
2022-07-16 09:25:57 - train: epoch 0130, iter [04100, 05004], lr: 0.028697, loss: 2.2800
2022-07-16 09:26:32 - train: epoch 0130, iter [04200, 05004], lr: 0.028682, loss: 2.3534
2022-07-16 09:27:06 - train: epoch 0130, iter [04300, 05004], lr: 0.028668, loss: 2.2750
2022-07-16 09:27:41 - train: epoch 0130, iter [04400, 05004], lr: 0.028653, loss: 2.3018
2022-07-16 09:28:15 - train: epoch 0130, iter [04500, 05004], lr: 0.028639, loss: 2.3847
2022-07-16 09:28:50 - train: epoch 0130, iter [04600, 05004], lr: 0.028624, loss: 2.2783
2022-07-16 09:29:24 - train: epoch 0130, iter [04700, 05004], lr: 0.028610, loss: 2.3403
2022-07-16 09:29:59 - train: epoch 0130, iter [04800, 05004], lr: 0.028595, loss: 2.2361
2022-07-16 09:30:34 - train: epoch 0130, iter [04900, 05004], lr: 0.028580, loss: 2.1320
2022-07-16 09:31:07 - train: epoch 0130, iter [05000, 05004], lr: 0.028566, loss: 2.4532
2022-07-16 09:31:08 - train: epoch 130, train_loss: 2.3245
2022-07-16 09:32:22 - eval: epoch: 130, acc1: 67.412%, acc5: 88.498%, test_loss: 1.3159, per_image_load_time: 2.243ms, per_image_inference_time: 0.468ms
2022-07-16 09:32:23 - until epoch: 130, best_acc1: 67.672%
2022-07-16 09:32:23 - epoch 131 lr: 0.028565
2022-07-16 09:33:03 - train: epoch 0131, iter [00100, 05004], lr: 0.028551, loss: 2.6586
2022-07-16 09:33:37 - train: epoch 0131, iter [00200, 05004], lr: 0.028536, loss: 2.2385
2022-07-16 09:34:10 - train: epoch 0131, iter [00300, 05004], lr: 0.028522, loss: 2.1713
2022-07-16 09:34:45 - train: epoch 0131, iter [00400, 05004], lr: 0.028507, loss: 2.4095
2022-07-16 09:35:20 - train: epoch 0131, iter [00500, 05004], lr: 0.028493, loss: 2.4505
2022-07-16 09:35:54 - train: epoch 0131, iter [00600, 05004], lr: 0.028478, loss: 2.7339
2022-07-16 09:36:28 - train: epoch 0131, iter [00700, 05004], lr: 0.028464, loss: 2.2931
2022-07-16 09:37:03 - train: epoch 0131, iter [00800, 05004], lr: 0.028449, loss: 2.3086
2022-07-16 09:37:37 - train: epoch 0131, iter [00900, 05004], lr: 0.028435, loss: 2.5381
2022-07-16 09:38:11 - train: epoch 0131, iter [01000, 05004], lr: 0.028420, loss: 2.4384
2022-07-16 09:38:46 - train: epoch 0131, iter [01100, 05004], lr: 0.028406, loss: 1.9120
2022-07-16 09:39:20 - train: epoch 0131, iter [01200, 05004], lr: 0.028391, loss: 2.1317
2022-07-16 09:39:54 - train: epoch 0131, iter [01300, 05004], lr: 0.028376, loss: 1.9332
2022-07-16 09:40:29 - train: epoch 0131, iter [01400, 05004], lr: 0.028362, loss: 2.1287
2022-07-16 09:41:04 - train: epoch 0131, iter [01500, 05004], lr: 0.028347, loss: 1.9659
2022-07-16 09:41:38 - train: epoch 0131, iter [01600, 05004], lr: 0.028333, loss: 2.5470
2022-07-16 09:42:13 - train: epoch 0131, iter [01700, 05004], lr: 0.028318, loss: 2.5882
2022-07-16 09:42:47 - train: epoch 0131, iter [01800, 05004], lr: 0.028304, loss: 2.1278
2022-07-16 09:43:21 - train: epoch 0131, iter [01900, 05004], lr: 0.028289, loss: 2.3692
2022-07-16 09:43:56 - train: epoch 0131, iter [02000, 05004], lr: 0.028275, loss: 2.4692
2022-07-16 09:44:30 - train: epoch 0131, iter [02100, 05004], lr: 0.028260, loss: 2.4329
2022-07-16 09:45:04 - train: epoch 0131, iter [02200, 05004], lr: 0.028246, loss: 2.4367
2022-07-16 09:45:38 - train: epoch 0131, iter [02300, 05004], lr: 0.028231, loss: 2.3715
2022-07-16 09:46:14 - train: epoch 0131, iter [02400, 05004], lr: 0.028217, loss: 2.4203
2022-07-16 09:46:48 - train: epoch 0131, iter [02500, 05004], lr: 0.028202, loss: 2.2278
2022-07-16 09:47:22 - train: epoch 0131, iter [02600, 05004], lr: 0.028188, loss: 2.5605
2022-07-16 09:47:57 - train: epoch 0131, iter [02700, 05004], lr: 0.028174, loss: 2.3417
2022-07-16 09:48:31 - train: epoch 0131, iter [02800, 05004], lr: 0.028159, loss: 2.2235
2022-07-16 09:49:05 - train: epoch 0131, iter [02900, 05004], lr: 0.028145, loss: 2.2615
2022-07-16 09:49:40 - train: epoch 0131, iter [03000, 05004], lr: 0.028130, loss: 2.1082
2022-07-16 09:50:15 - train: epoch 0131, iter [03100, 05004], lr: 0.028116, loss: 2.2704
2022-07-16 09:50:49 - train: epoch 0131, iter [03200, 05004], lr: 0.028101, loss: 2.3789
2022-07-16 09:51:24 - train: epoch 0131, iter [03300, 05004], lr: 0.028087, loss: 2.3305
2022-07-16 09:51:59 - train: epoch 0131, iter [03400, 05004], lr: 0.028072, loss: 2.1785
2022-07-16 09:52:34 - train: epoch 0131, iter [03500, 05004], lr: 0.028058, loss: 2.4371
2022-07-16 09:53:09 - train: epoch 0131, iter [03600, 05004], lr: 0.028043, loss: 2.3498
2022-07-16 09:53:43 - train: epoch 0131, iter [03700, 05004], lr: 0.028029, loss: 2.1467
2022-07-16 09:54:18 - train: epoch 0131, iter [03800, 05004], lr: 0.028014, loss: 2.3908
2022-07-16 09:54:51 - train: epoch 0131, iter [03900, 05004], lr: 0.028000, loss: 2.0518
2022-07-16 09:55:26 - train: epoch 0131, iter [04000, 05004], lr: 0.027985, loss: 2.2132
2022-07-16 09:56:01 - train: epoch 0131, iter [04100, 05004], lr: 0.027971, loss: 2.1812
2022-07-16 09:56:35 - train: epoch 0131, iter [04200, 05004], lr: 0.027957, loss: 2.3858
2022-07-16 09:57:09 - train: epoch 0131, iter [04300, 05004], lr: 0.027942, loss: 2.3928
2022-07-16 09:57:44 - train: epoch 0131, iter [04400, 05004], lr: 0.027928, loss: 2.6592
2022-07-16 09:58:19 - train: epoch 0131, iter [04500, 05004], lr: 0.027913, loss: 2.2826
2022-07-16 09:58:53 - train: epoch 0131, iter [04600, 05004], lr: 0.027899, loss: 2.2561
2022-07-16 09:59:27 - train: epoch 0131, iter [04700, 05004], lr: 0.027884, loss: 2.2748
2022-07-16 10:00:02 - train: epoch 0131, iter [04800, 05004], lr: 0.027870, loss: 2.4935
2022-07-16 10:00:36 - train: epoch 0131, iter [04900, 05004], lr: 0.027855, loss: 2.1134
2022-07-16 10:01:10 - train: epoch 0131, iter [05000, 05004], lr: 0.027841, loss: 2.2808
2022-07-16 10:01:11 - train: epoch 131, train_loss: 2.3138
2022-07-16 10:02:26 - eval: epoch: 131, acc1: 67.860%, acc5: 88.730%, test_loss: 1.3083, per_image_load_time: 1.619ms, per_image_inference_time: 0.482ms
2022-07-16 10:02:26 - until epoch: 131, best_acc1: 67.860%
2022-07-16 10:02:26 - epoch 132 lr: 0.027840
2022-07-16 10:03:06 - train: epoch 0132, iter [00100, 05004], lr: 0.027826, loss: 2.3886
2022-07-16 10:03:40 - train: epoch 0132, iter [00200, 05004], lr: 0.027812, loss: 2.1280
2022-07-16 10:04:15 - train: epoch 0132, iter [00300, 05004], lr: 0.027797, loss: 2.3740
2022-07-16 10:04:49 - train: epoch 0132, iter [00400, 05004], lr: 0.027783, loss: 2.4392
2022-07-16 10:05:24 - train: epoch 0132, iter [00500, 05004], lr: 0.027768, loss: 2.5392
2022-07-16 10:05:58 - train: epoch 0132, iter [00600, 05004], lr: 0.027754, loss: 2.4736
2022-07-16 10:06:33 - train: epoch 0132, iter [00700, 05004], lr: 0.027739, loss: 2.3085
2022-07-16 10:07:07 - train: epoch 0132, iter [00800, 05004], lr: 0.027725, loss: 2.0923
2022-07-16 10:07:42 - train: epoch 0132, iter [00900, 05004], lr: 0.027711, loss: 2.3391
2022-07-16 10:08:16 - train: epoch 0132, iter [01000, 05004], lr: 0.027696, loss: 2.0441
2022-07-16 10:08:50 - train: epoch 0132, iter [01100, 05004], lr: 0.027682, loss: 2.4484
2022-07-16 10:09:25 - train: epoch 0132, iter [01200, 05004], lr: 0.027667, loss: 2.2388
2022-07-16 10:09:59 - train: epoch 0132, iter [01300, 05004], lr: 0.027653, loss: 2.1132
2022-07-16 10:10:34 - train: epoch 0132, iter [01400, 05004], lr: 0.027639, loss: 2.2413
2022-07-16 10:11:08 - train: epoch 0132, iter [01500, 05004], lr: 0.027624, loss: 2.2753
2022-07-16 10:11:43 - train: epoch 0132, iter [01600, 05004], lr: 0.027610, loss: 1.9387
2022-07-16 10:12:18 - train: epoch 0132, iter [01700, 05004], lr: 0.027595, loss: 2.1167
2022-07-16 10:12:53 - train: epoch 0132, iter [01800, 05004], lr: 0.027581, loss: 2.6731
2022-07-16 10:13:27 - train: epoch 0132, iter [01900, 05004], lr: 0.027567, loss: 2.3162
2022-07-16 10:14:02 - train: epoch 0132, iter [02000, 05004], lr: 0.027552, loss: 2.2815
2022-07-16 10:14:36 - train: epoch 0132, iter [02100, 05004], lr: 0.027538, loss: 2.2559
2022-07-16 10:15:11 - train: epoch 0132, iter [02200, 05004], lr: 0.027524, loss: 2.1386
2022-07-16 10:15:45 - train: epoch 0132, iter [02300, 05004], lr: 0.027509, loss: 2.5958
2022-07-16 10:16:19 - train: epoch 0132, iter [02400, 05004], lr: 0.027495, loss: 2.2476
2022-07-16 10:16:54 - train: epoch 0132, iter [02500, 05004], lr: 0.027480, loss: 2.5057
2022-07-16 10:17:28 - train: epoch 0132, iter [02600, 05004], lr: 0.027466, loss: 2.4152
2022-07-16 10:18:02 - train: epoch 0132, iter [02700, 05004], lr: 0.027452, loss: 2.2481
2022-07-16 10:18:37 - train: epoch 0132, iter [02800, 05004], lr: 0.027437, loss: 2.3700
2022-07-16 10:19:11 - train: epoch 0132, iter [02900, 05004], lr: 0.027423, loss: 2.3411
2022-07-16 10:19:45 - train: epoch 0132, iter [03000, 05004], lr: 0.027409, loss: 2.4097
2022-07-16 10:20:20 - train: epoch 0132, iter [03100, 05004], lr: 0.027394, loss: 2.5059
2022-07-16 10:20:55 - train: epoch 0132, iter [03200, 05004], lr: 0.027380, loss: 2.2680
2022-07-16 10:21:29 - train: epoch 0132, iter [03300, 05004], lr: 0.027365, loss: 2.3785
2022-07-16 10:22:04 - train: epoch 0132, iter [03400, 05004], lr: 0.027351, loss: 2.3528
2022-07-16 10:22:38 - train: epoch 0132, iter [03500, 05004], lr: 0.027337, loss: 2.2701
2022-07-16 10:23:13 - train: epoch 0132, iter [03600, 05004], lr: 0.027322, loss: 2.3861
2022-07-16 10:23:47 - train: epoch 0132, iter [03700, 05004], lr: 0.027308, loss: 2.3673
2022-07-16 10:24:21 - train: epoch 0132, iter [03800, 05004], lr: 0.027294, loss: 2.4306
2022-07-16 10:24:56 - train: epoch 0132, iter [03900, 05004], lr: 0.027279, loss: 2.4182
2022-07-16 10:25:31 - train: epoch 0132, iter [04000, 05004], lr: 0.027265, loss: 2.5255
2022-07-16 10:26:04 - train: epoch 0132, iter [04100, 05004], lr: 0.027251, loss: 2.5039
2022-07-16 10:26:40 - train: epoch 0132, iter [04200, 05004], lr: 0.027236, loss: 2.3493
2022-07-16 10:27:14 - train: epoch 0132, iter [04300, 05004], lr: 0.027222, loss: 2.6123
2022-07-16 10:27:48 - train: epoch 0132, iter [04400, 05004], lr: 0.027208, loss: 2.0164
2022-07-16 10:28:23 - train: epoch 0132, iter [04500, 05004], lr: 0.027193, loss: 2.1404
2022-07-16 10:28:57 - train: epoch 0132, iter [04600, 05004], lr: 0.027179, loss: 2.5072
2022-07-16 10:29:32 - train: epoch 0132, iter [04700, 05004], lr: 0.027165, loss: 2.5280
2022-07-16 10:30:05 - train: epoch 0132, iter [04800, 05004], lr: 0.027150, loss: 2.3024
2022-07-16 10:30:40 - train: epoch 0132, iter [04900, 05004], lr: 0.027136, loss: 2.4240
2022-07-16 10:31:13 - train: epoch 0132, iter [05000, 05004], lr: 0.027122, loss: 2.6280
2022-07-16 10:31:14 - train: epoch 132, train_loss: 2.3022
2022-07-16 10:32:30 - eval: epoch: 132, acc1: 67.544%, acc5: 88.344%, test_loss: 1.3170, per_image_load_time: 1.237ms, per_image_inference_time: 0.480ms
2022-07-16 10:32:30 - until epoch: 132, best_acc1: 67.860%
2022-07-16 10:32:30 - epoch 133 lr: 0.027121
2022-07-16 10:33:10 - train: epoch 0133, iter [00100, 05004], lr: 0.027107, loss: 2.3905
2022-07-16 10:33:44 - train: epoch 0133, iter [00200, 05004], lr: 0.027093, loss: 2.2988
2022-07-16 10:34:18 - train: epoch 0133, iter [00300, 05004], lr: 0.027078, loss: 2.4411
2022-07-16 10:34:53 - train: epoch 0133, iter [00400, 05004], lr: 0.027064, loss: 2.5021
2022-07-16 10:35:27 - train: epoch 0133, iter [00500, 05004], lr: 0.027050, loss: 2.3640
2022-07-16 10:36:03 - train: epoch 0133, iter [00600, 05004], lr: 0.027035, loss: 2.1637
2022-07-16 10:36:37 - train: epoch 0133, iter [00700, 05004], lr: 0.027021, loss: 2.3903
2022-07-16 10:37:11 - train: epoch 0133, iter [00800, 05004], lr: 0.027007, loss: 2.5617
2022-07-16 10:37:45 - train: epoch 0133, iter [00900, 05004], lr: 0.026992, loss: 2.0512
2022-07-16 10:38:20 - train: epoch 0133, iter [01000, 05004], lr: 0.026978, loss: 2.2831
2022-07-16 10:38:54 - train: epoch 0133, iter [01100, 05004], lr: 0.026964, loss: 2.2145
2022-07-16 10:39:27 - train: epoch 0133, iter [01200, 05004], lr: 0.026950, loss: 2.3231
2022-07-16 10:40:01 - train: epoch 0133, iter [01300, 05004], lr: 0.026935, loss: 2.2256
2022-07-16 10:40:35 - train: epoch 0133, iter [01400, 05004], lr: 0.026921, loss: 2.1392
2022-07-16 10:41:10 - train: epoch 0133, iter [01500, 05004], lr: 0.026907, loss: 2.3551
2022-07-16 10:41:44 - train: epoch 0133, iter [01600, 05004], lr: 0.026893, loss: 2.4046
2022-07-16 10:42:18 - train: epoch 0133, iter [01700, 05004], lr: 0.026878, loss: 2.5997
2022-07-16 10:42:52 - train: epoch 0133, iter [01800, 05004], lr: 0.026864, loss: 2.1625
2022-07-16 10:43:26 - train: epoch 0133, iter [01900, 05004], lr: 0.026850, loss: 1.9779
2022-07-16 10:44:01 - train: epoch 0133, iter [02000, 05004], lr: 0.026835, loss: 2.2814
2022-07-16 10:44:36 - train: epoch 0133, iter [02100, 05004], lr: 0.026821, loss: 2.4658
2022-07-16 10:45:10 - train: epoch 0133, iter [02200, 05004], lr: 0.026807, loss: 2.5226
2022-07-16 10:45:45 - train: epoch 0133, iter [02300, 05004], lr: 0.026793, loss: 2.2812
2022-07-16 10:46:20 - train: epoch 0133, iter [02400, 05004], lr: 0.026778, loss: 2.2257
2022-07-16 10:46:55 - train: epoch 0133, iter [02500, 05004], lr: 0.026764, loss: 1.8738
2022-07-16 10:47:29 - train: epoch 0133, iter [02600, 05004], lr: 0.026750, loss: 2.4524
2022-07-16 10:48:04 - train: epoch 0133, iter [02700, 05004], lr: 0.026736, loss: 2.5627
2022-07-16 10:48:38 - train: epoch 0133, iter [02800, 05004], lr: 0.026721, loss: 2.1542
2022-07-16 10:49:12 - train: epoch 0133, iter [02900, 05004], lr: 0.026707, loss: 2.1976
2022-07-16 10:49:46 - train: epoch 0133, iter [03000, 05004], lr: 0.026693, loss: 1.9198
2022-07-16 10:50:21 - train: epoch 0133, iter [03100, 05004], lr: 0.026679, loss: 2.2256
2022-07-16 10:50:55 - train: epoch 0133, iter [03200, 05004], lr: 0.026664, loss: 2.2841
2022-07-16 10:51:29 - train: epoch 0133, iter [03300, 05004], lr: 0.026650, loss: 2.1290
2022-07-16 10:52:04 - train: epoch 0133, iter [03400, 05004], lr: 0.026636, loss: 2.4485
2022-07-16 10:52:38 - train: epoch 0133, iter [03500, 05004], lr: 0.026622, loss: 2.3598
2022-07-16 10:53:13 - train: epoch 0133, iter [03600, 05004], lr: 0.026607, loss: 2.3033
2022-07-16 10:53:47 - train: epoch 0133, iter [03700, 05004], lr: 0.026593, loss: 2.2918
2022-07-16 10:54:22 - train: epoch 0133, iter [03800, 05004], lr: 0.026579, loss: 2.2928
2022-07-16 10:54:56 - train: epoch 0133, iter [03900, 05004], lr: 0.026565, loss: 2.4151
2022-07-16 10:55:31 - train: epoch 0133, iter [04000, 05004], lr: 0.026551, loss: 2.1472
2022-07-16 10:56:05 - train: epoch 0133, iter [04100, 05004], lr: 0.026536, loss: 2.2343
2022-07-16 10:56:40 - train: epoch 0133, iter [04200, 05004], lr: 0.026522, loss: 2.2953
2022-07-16 10:57:15 - train: epoch 0133, iter [04300, 05004], lr: 0.026508, loss: 2.3411
2022-07-16 10:57:49 - train: epoch 0133, iter [04400, 05004], lr: 0.026494, loss: 2.4305
2022-07-16 10:58:23 - train: epoch 0133, iter [04500, 05004], lr: 0.026480, loss: 2.6756
2022-07-16 10:58:58 - train: epoch 0133, iter [04600, 05004], lr: 0.026465, loss: 2.3241
2022-07-16 10:59:33 - train: epoch 0133, iter [04700, 05004], lr: 0.026451, loss: 2.1403
2022-07-16 11:00:07 - train: epoch 0133, iter [04800, 05004], lr: 0.026437, loss: 2.0474
2022-07-16 11:00:41 - train: epoch 0133, iter [04900, 05004], lr: 0.026423, loss: 2.1463
2022-07-16 11:01:14 - train: epoch 0133, iter [05000, 05004], lr: 0.026409, loss: 2.4358
2022-07-16 11:01:15 - train: epoch 133, train_loss: 2.2924
2022-07-16 11:02:30 - eval: epoch: 133, acc1: 68.612%, acc5: 88.938%, test_loss: 1.2840, per_image_load_time: 2.302ms, per_image_inference_time: 0.464ms
2022-07-16 11:02:30 - until epoch: 133, best_acc1: 68.612%
2022-07-16 11:02:30 - epoch 134 lr: 0.026408
2022-07-16 11:03:10 - train: epoch 0134, iter [00100, 05004], lr: 0.026394, loss: 2.2228
2022-07-16 11:03:45 - train: epoch 0134, iter [00200, 05004], lr: 0.026380, loss: 2.1366
2022-07-16 11:04:19 - train: epoch 0134, iter [00300, 05004], lr: 0.026365, loss: 2.3691
2022-07-16 11:04:53 - train: epoch 0134, iter [00400, 05004], lr: 0.026351, loss: 2.2125
2022-07-16 11:05:28 - train: epoch 0134, iter [00500, 05004], lr: 0.026337, loss: 2.4234
2022-07-16 11:06:02 - train: epoch 0134, iter [00600, 05004], lr: 0.026323, loss: 2.4932
2022-07-16 11:06:36 - train: epoch 0134, iter [00700, 05004], lr: 0.026309, loss: 2.4584
2022-07-16 11:07:11 - train: epoch 0134, iter [00800, 05004], lr: 0.026294, loss: 2.3971
2022-07-16 11:07:46 - train: epoch 0134, iter [00900, 05004], lr: 0.026280, loss: 2.4143
2022-07-16 11:08:20 - train: epoch 0134, iter [01000, 05004], lr: 0.026266, loss: 2.1933
2022-07-16 11:08:54 - train: epoch 0134, iter [01100, 05004], lr: 0.026252, loss: 2.4307
2022-07-16 11:09:29 - train: epoch 0134, iter [01200, 05004], lr: 0.026238, loss: 2.4095
2022-07-16 11:10:04 - train: epoch 0134, iter [01300, 05004], lr: 0.026224, loss: 2.4780
2022-07-16 11:10:38 - train: epoch 0134, iter [01400, 05004], lr: 0.026210, loss: 2.2100
2022-07-16 11:11:12 - train: epoch 0134, iter [01500, 05004], lr: 0.026195, loss: 2.1473
2022-07-16 11:11:47 - train: epoch 0134, iter [01600, 05004], lr: 0.026181, loss: 2.4504
2022-07-16 11:12:21 - train: epoch 0134, iter [01700, 05004], lr: 0.026167, loss: 2.1048
2022-07-16 11:12:55 - train: epoch 0134, iter [01800, 05004], lr: 0.026153, loss: 2.4385
2022-07-16 11:13:30 - train: epoch 0134, iter [01900, 05004], lr: 0.026139, loss: 2.3769
2022-07-16 11:14:05 - train: epoch 0134, iter [02000, 05004], lr: 0.026125, loss: 2.2515
2022-07-16 11:14:39 - train: epoch 0134, iter [02100, 05004], lr: 0.026110, loss: 2.1627
2022-07-16 11:15:15 - train: epoch 0134, iter [02200, 05004], lr: 0.026096, loss: 2.4011
2022-07-16 11:15:49 - train: epoch 0134, iter [02300, 05004], lr: 0.026082, loss: 2.5322
2022-07-16 11:16:24 - train: epoch 0134, iter [02400, 05004], lr: 0.026068, loss: 1.8148
2022-07-16 11:16:59 - train: epoch 0134, iter [02500, 05004], lr: 0.026054, loss: 2.5646
2022-07-16 11:17:33 - train: epoch 0134, iter [02600, 05004], lr: 0.026040, loss: 2.1959
2022-07-16 11:18:08 - train: epoch 0134, iter [02700, 05004], lr: 0.026026, loss: 2.1768
2022-07-16 11:18:43 - train: epoch 0134, iter [02800, 05004], lr: 0.026012, loss: 2.3525
2022-07-16 11:19:17 - train: epoch 0134, iter [02900, 05004], lr: 0.025997, loss: 2.3427
2022-07-16 11:19:52 - train: epoch 0134, iter [03000, 05004], lr: 0.025983, loss: 2.2489
2022-07-16 11:20:27 - train: epoch 0134, iter [03100, 05004], lr: 0.025969, loss: 2.2586
2022-07-16 11:21:02 - train: epoch 0134, iter [03200, 05004], lr: 0.025955, loss: 2.2894
2022-07-16 11:21:37 - train: epoch 0134, iter [03300, 05004], lr: 0.025941, loss: 2.4784
2022-07-16 11:22:11 - train: epoch 0134, iter [03400, 05004], lr: 0.025927, loss: 1.9405
2022-07-16 11:22:46 - train: epoch 0134, iter [03500, 05004], lr: 0.025913, loss: 2.4830
2022-07-16 11:23:21 - train: epoch 0134, iter [03600, 05004], lr: 0.025899, loss: 2.3440
2022-07-16 11:23:55 - train: epoch 0134, iter [03700, 05004], lr: 0.025885, loss: 2.3227
2022-07-16 11:24:31 - train: epoch 0134, iter [03800, 05004], lr: 0.025870, loss: 2.2389
2022-07-16 11:25:05 - train: epoch 0134, iter [03900, 05004], lr: 0.025856, loss: 2.5802
2022-07-16 11:25:40 - train: epoch 0134, iter [04000, 05004], lr: 0.025842, loss: 2.4590
2022-07-16 11:26:15 - train: epoch 0134, iter [04100, 05004], lr: 0.025828, loss: 2.3569
2022-07-16 11:26:50 - train: epoch 0134, iter [04200, 05004], lr: 0.025814, loss: 2.1484
2022-07-16 11:27:24 - train: epoch 0134, iter [04300, 05004], lr: 0.025800, loss: 2.0014
2022-07-16 11:27:59 - train: epoch 0134, iter [04400, 05004], lr: 0.025786, loss: 2.2147
2022-07-16 11:28:34 - train: epoch 0134, iter [04500, 05004], lr: 0.025772, loss: 2.2972
2022-07-16 11:29:08 - train: epoch 0134, iter [04600, 05004], lr: 0.025758, loss: 2.0631
2022-07-16 11:29:43 - train: epoch 0134, iter [04700, 05004], lr: 0.025744, loss: 2.2057
2022-07-16 11:30:18 - train: epoch 0134, iter [04800, 05004], lr: 0.025730, loss: 2.1509
2022-07-16 11:30:53 - train: epoch 0134, iter [04900, 05004], lr: 0.025715, loss: 2.2716
2022-07-16 11:31:26 - train: epoch 0134, iter [05000, 05004], lr: 0.025701, loss: 2.3629
2022-07-16 11:31:27 - train: epoch 134, train_loss: 2.2912
2022-07-16 11:32:42 - eval: epoch: 134, acc1: 68.246%, acc5: 88.716%, test_loss: 1.2945, per_image_load_time: 1.765ms, per_image_inference_time: 0.484ms
2022-07-16 11:32:43 - until epoch: 134, best_acc1: 68.612%
2022-07-16 11:32:43 - epoch 135 lr: 0.025701
2022-07-16 11:33:23 - train: epoch 0135, iter [00100, 05004], lr: 0.025687, loss: 2.1786
2022-07-16 11:33:57 - train: epoch 0135, iter [00200, 05004], lr: 0.025673, loss: 2.3281
2022-07-16 11:34:32 - train: epoch 0135, iter [00300, 05004], lr: 0.025659, loss: 2.1177
2022-07-16 11:35:06 - train: epoch 0135, iter [00400, 05004], lr: 0.025645, loss: 2.1463
2022-07-16 11:35:41 - train: epoch 0135, iter [00500, 05004], lr: 0.025631, loss: 2.1376
2022-07-16 11:36:15 - train: epoch 0135, iter [00600, 05004], lr: 0.025616, loss: 2.1148
2022-07-16 11:36:50 - train: epoch 0135, iter [00700, 05004], lr: 0.025602, loss: 2.5829
2022-07-16 11:37:24 - train: epoch 0135, iter [00800, 05004], lr: 0.025588, loss: 2.7185
2022-07-16 11:37:59 - train: epoch 0135, iter [00900, 05004], lr: 0.025574, loss: 2.2596
2022-07-16 11:38:33 - train: epoch 0135, iter [01000, 05004], lr: 0.025560, loss: 2.1000
2022-07-16 11:39:08 - train: epoch 0135, iter [01100, 05004], lr: 0.025546, loss: 2.4018
2022-07-16 11:39:42 - train: epoch 0135, iter [01200, 05004], lr: 0.025532, loss: 2.3159
2022-07-16 11:40:17 - train: epoch 0135, iter [01300, 05004], lr: 0.025518, loss: 2.3115
2022-07-16 11:40:52 - train: epoch 0135, iter [01400, 05004], lr: 0.025504, loss: 1.9878
2022-07-16 11:41:26 - train: epoch 0135, iter [01500, 05004], lr: 0.025490, loss: 2.4146
2022-07-16 11:42:01 - train: epoch 0135, iter [01600, 05004], lr: 0.025476, loss: 1.9065
2022-07-16 11:42:36 - train: epoch 0135, iter [01700, 05004], lr: 0.025462, loss: 2.5284
2022-07-16 11:43:10 - train: epoch 0135, iter [01800, 05004], lr: 0.025448, loss: 2.4226
2022-07-16 11:43:45 - train: epoch 0135, iter [01900, 05004], lr: 0.025434, loss: 2.5253
2022-07-16 11:44:19 - train: epoch 0135, iter [02000, 05004], lr: 0.025420, loss: 2.1308
2022-07-16 11:44:54 - train: epoch 0135, iter [02100, 05004], lr: 0.025406, loss: 2.5404
2022-07-16 11:45:28 - train: epoch 0135, iter [02200, 05004], lr: 0.025392, loss: 2.3291
2022-07-16 11:46:02 - train: epoch 0135, iter [02300, 05004], lr: 0.025378, loss: 2.3024
2022-07-16 11:46:36 - train: epoch 0135, iter [02400, 05004], lr: 0.025364, loss: 2.3767
2022-07-16 11:47:11 - train: epoch 0135, iter [02500, 05004], lr: 0.025350, loss: 2.3792
2022-07-16 11:47:45 - train: epoch 0135, iter [02600, 05004], lr: 0.025336, loss: 2.1963
2022-07-16 11:48:20 - train: epoch 0135, iter [02700, 05004], lr: 0.025322, loss: 2.2318
2022-07-16 11:48:54 - train: epoch 0135, iter [02800, 05004], lr: 0.025308, loss: 2.4279
2022-07-16 11:49:29 - train: epoch 0135, iter [02900, 05004], lr: 0.025294, loss: 2.2597
2022-07-16 11:50:05 - train: epoch 0135, iter [03000, 05004], lr: 0.025280, loss: 2.5097
2022-07-16 11:50:39 - train: epoch 0135, iter [03100, 05004], lr: 0.025266, loss: 2.2509
2022-07-16 11:51:14 - train: epoch 0135, iter [03200, 05004], lr: 0.025252, loss: 2.2893
2022-07-16 11:51:48 - train: epoch 0135, iter [03300, 05004], lr: 0.025238, loss: 2.6305
2022-07-16 11:52:22 - train: epoch 0135, iter [03400, 05004], lr: 0.025224, loss: 2.6479
2022-07-16 11:52:57 - train: epoch 0135, iter [03500, 05004], lr: 0.025210, loss: 2.2932
2022-07-16 11:53:31 - train: epoch 0135, iter [03600, 05004], lr: 0.025196, loss: 2.1032
2022-07-16 11:54:06 - train: epoch 0135, iter [03700, 05004], lr: 0.025182, loss: 2.2870
2022-07-16 11:54:41 - train: epoch 0135, iter [03800, 05004], lr: 0.025168, loss: 2.2726
2022-07-16 11:55:15 - train: epoch 0135, iter [03900, 05004], lr: 0.025154, loss: 2.3999
2022-07-16 11:55:50 - train: epoch 0135, iter [04000, 05004], lr: 0.025140, loss: 2.2910
2022-07-16 11:56:24 - train: epoch 0135, iter [04100, 05004], lr: 0.025126, loss: 2.5525
2022-07-16 11:57:00 - train: epoch 0135, iter [04200, 05004], lr: 0.025112, loss: 2.4319
2022-07-16 11:57:35 - train: epoch 0135, iter [04300, 05004], lr: 0.025098, loss: 2.2802
2022-07-16 11:58:10 - train: epoch 0135, iter [04400, 05004], lr: 0.025084, loss: 2.6201
2022-07-16 11:58:44 - train: epoch 0135, iter [04500, 05004], lr: 0.025070, loss: 2.5551
2022-07-16 11:59:19 - train: epoch 0135, iter [04600, 05004], lr: 0.025056, loss: 2.3738
2022-07-16 11:59:54 - train: epoch 0135, iter [04700, 05004], lr: 0.025042, loss: 2.3683
2022-07-16 12:00:27 - train: epoch 0135, iter [04800, 05004], lr: 0.025028, loss: 2.2789
2022-07-16 12:01:01 - train: epoch 0135, iter [04900, 05004], lr: 0.025015, loss: 2.2461
2022-07-16 12:01:34 - train: epoch 0135, iter [05000, 05004], lr: 0.025001, loss: 2.3753
2022-07-16 12:01:35 - train: epoch 135, train_loss: 2.2792
2022-07-16 12:02:51 - eval: epoch: 135, acc1: 68.480%, acc5: 88.804%, test_loss: 1.2819, per_image_load_time: 2.407ms, per_image_inference_time: 0.477ms
2022-07-16 12:02:51 - until epoch: 135, best_acc1: 68.612%
2022-07-16 12:02:51 - epoch 136 lr: 0.025000
2022-07-16 12:03:30 - train: epoch 0136, iter [00100, 05004], lr: 0.024986, loss: 2.0554
2022-07-16 12:04:06 - train: epoch 0136, iter [00200, 05004], lr: 0.024972, loss: 2.3826
2022-07-16 12:04:39 - train: epoch 0136, iter [00300, 05004], lr: 0.024958, loss: 2.5038
2022-07-16 12:05:14 - train: epoch 0136, iter [00400, 05004], lr: 0.024944, loss: 2.2400
2022-07-16 12:05:48 - train: epoch 0136, iter [00500, 05004], lr: 0.024930, loss: 2.3170
2022-07-16 12:06:22 - train: epoch 0136, iter [00600, 05004], lr: 0.024916, loss: 2.0982
2022-07-16 12:06:57 - train: epoch 0136, iter [00700, 05004], lr: 0.024902, loss: 2.2518
2022-07-16 12:07:30 - train: epoch 0136, iter [00800, 05004], lr: 0.024889, loss: 2.1481
2022-07-16 12:08:04 - train: epoch 0136, iter [00900, 05004], lr: 0.024875, loss: 2.6351
2022-07-16 12:08:39 - train: epoch 0136, iter [01000, 05004], lr: 0.024861, loss: 2.2181
2022-07-16 12:09:13 - train: epoch 0136, iter [01100, 05004], lr: 0.024847, loss: 1.9951
2022-07-16 12:09:48 - train: epoch 0136, iter [01200, 05004], lr: 0.024833, loss: 2.4565
2022-07-16 12:10:22 - train: epoch 0136, iter [01300, 05004], lr: 0.024819, loss: 2.1193
2022-07-16 12:10:57 - train: epoch 0136, iter [01400, 05004], lr: 0.024805, loss: 2.1931
2022-07-16 12:11:32 - train: epoch 0136, iter [01500, 05004], lr: 0.024791, loss: 2.3749
2022-07-16 12:12:06 - train: epoch 0136, iter [01600, 05004], lr: 0.024777, loss: 2.2588
2022-07-16 12:12:41 - train: epoch 0136, iter [01700, 05004], lr: 0.024763, loss: 2.4729
2022-07-16 12:13:16 - train: epoch 0136, iter [01800, 05004], lr: 0.024749, loss: 2.3877
2022-07-16 12:13:50 - train: epoch 0136, iter [01900, 05004], lr: 0.024736, loss: 2.2015
2022-07-16 12:14:25 - train: epoch 0136, iter [02000, 05004], lr: 0.024722, loss: 2.1709
2022-07-16 12:15:00 - train: epoch 0136, iter [02100, 05004], lr: 0.024708, loss: 2.3398
2022-07-16 12:15:35 - train: epoch 0136, iter [02200, 05004], lr: 0.024694, loss: 2.2024
2022-07-16 12:16:08 - train: epoch 0136, iter [02300, 05004], lr: 0.024680, loss: 2.5448
2022-07-16 12:16:44 - train: epoch 0136, iter [02400, 05004], lr: 0.024666, loss: 2.1769
2022-07-16 12:17:18 - train: epoch 0136, iter [02500, 05004], lr: 0.024652, loss: 2.4414
2022-07-16 12:17:53 - train: epoch 0136, iter [02600, 05004], lr: 0.024638, loss: 2.3776
2022-07-16 12:18:27 - train: epoch 0136, iter [02700, 05004], lr: 0.024625, loss: 2.2955
2022-07-16 12:19:03 - train: epoch 0136, iter [02800, 05004], lr: 0.024611, loss: 2.4675
2022-07-16 12:19:37 - train: epoch 0136, iter [02900, 05004], lr: 0.024597, loss: 2.1902
2022-07-16 12:20:12 - train: epoch 0136, iter [03000, 05004], lr: 0.024583, loss: 2.2198
2022-07-16 12:20:46 - train: epoch 0136, iter [03100, 05004], lr: 0.024569, loss: 2.4023
2022-07-16 12:21:21 - train: epoch 0136, iter [03200, 05004], lr: 0.024555, loss: 2.4437
2022-07-16 12:21:56 - train: epoch 0136, iter [03300, 05004], lr: 0.024541, loss: 2.3083
2022-07-16 12:22:32 - train: epoch 0136, iter [03400, 05004], lr: 0.024528, loss: 2.3017
2022-07-16 12:23:06 - train: epoch 0136, iter [03500, 05004], lr: 0.024514, loss: 2.1028
2022-07-16 12:23:40 - train: epoch 0136, iter [03600, 05004], lr: 0.024500, loss: 2.1165
2022-07-16 12:24:14 - train: epoch 0136, iter [03700, 05004], lr: 0.024486, loss: 2.3605
2022-07-16 12:24:50 - train: epoch 0136, iter [03800, 05004], lr: 0.024472, loss: 2.3369
2022-07-16 12:25:24 - train: epoch 0136, iter [03900, 05004], lr: 0.024458, loss: 2.3252
2022-07-16 12:25:59 - train: epoch 0136, iter [04000, 05004], lr: 0.024444, loss: 2.3257
2022-07-16 12:26:34 - train: epoch 0136, iter [04100, 05004], lr: 0.024431, loss: 2.0784
2022-07-16 12:27:09 - train: epoch 0136, iter [04200, 05004], lr: 0.024417, loss: 2.3841
2022-07-16 12:27:44 - train: epoch 0136, iter [04300, 05004], lr: 0.024403, loss: 2.2841
2022-07-16 12:28:19 - train: epoch 0136, iter [04400, 05004], lr: 0.024389, loss: 2.1547
2022-07-16 12:28:53 - train: epoch 0136, iter [04500, 05004], lr: 0.024375, loss: 2.3842
2022-07-16 12:29:28 - train: epoch 0136, iter [04600, 05004], lr: 0.024361, loss: 2.2693
2022-07-16 12:30:03 - train: epoch 0136, iter [04700, 05004], lr: 0.024348, loss: 2.2763
2022-07-16 12:30:38 - train: epoch 0136, iter [04800, 05004], lr: 0.024334, loss: 2.3476
2022-07-16 12:31:12 - train: epoch 0136, iter [04900, 05004], lr: 0.024320, loss: 2.2211
2022-07-16 12:31:46 - train: epoch 0136, iter [05000, 05004], lr: 0.024306, loss: 2.1572
2022-07-16 12:31:47 - train: epoch 136, train_loss: 2.2697
2022-07-16 12:33:02 - eval: epoch: 136, acc1: 68.506%, acc5: 89.000%, test_loss: 1.2736, per_image_load_time: 2.260ms, per_image_inference_time: 0.489ms
2022-07-16 12:33:02 - until epoch: 136, best_acc1: 68.612%
2022-07-16 12:33:02 - epoch 137 lr: 0.024306
2022-07-16 12:33:41 - train: epoch 0137, iter [00100, 05004], lr: 0.024292, loss: 2.0349
2022-07-16 12:34:17 - train: epoch 0137, iter [00200, 05004], lr: 0.024278, loss: 2.4285
2022-07-16 12:34:51 - train: epoch 0137, iter [00300, 05004], lr: 0.024264, loss: 2.2021
2022-07-16 12:35:25 - train: epoch 0137, iter [00400, 05004], lr: 0.024250, loss: 1.9527
2022-07-16 12:36:00 - train: epoch 0137, iter [00500, 05004], lr: 0.024237, loss: 2.3856
2022-07-16 12:36:35 - train: epoch 0137, iter [00600, 05004], lr: 0.024223, loss: 2.4183
2022-07-16 12:37:09 - train: epoch 0137, iter [00700, 05004], lr: 0.024209, loss: 2.3270
2022-07-16 12:37:44 - train: epoch 0137, iter [00800, 05004], lr: 0.024195, loss: 2.3757
2022-07-16 12:38:18 - train: epoch 0137, iter [00900, 05004], lr: 0.024181, loss: 2.1148
2022-07-16 12:38:55 - train: epoch 0137, iter [01000, 05004], lr: 0.024168, loss: 2.0218
2022-07-16 12:39:28 - train: epoch 0137, iter [01100, 05004], lr: 0.024154, loss: 2.2996
2022-07-16 12:40:03 - train: epoch 0137, iter [01200, 05004], lr: 0.024140, loss: 2.6092
2022-07-16 12:40:38 - train: epoch 0137, iter [01300, 05004], lr: 0.024126, loss: 2.1170
2022-07-16 12:41:12 - train: epoch 0137, iter [01400, 05004], lr: 0.024113, loss: 2.4273
2022-07-16 12:41:47 - train: epoch 0137, iter [01500, 05004], lr: 0.024099, loss: 2.3715
2022-07-16 12:42:22 - train: epoch 0137, iter [01600, 05004], lr: 0.024085, loss: 2.0249
2022-07-16 12:42:56 - train: epoch 0137, iter [01700, 05004], lr: 0.024071, loss: 2.4815
2022-07-16 12:43:30 - train: epoch 0137, iter [01800, 05004], lr: 0.024058, loss: 2.2393
2022-07-16 12:44:05 - train: epoch 0137, iter [01900, 05004], lr: 0.024044, loss: 2.3405
2022-07-16 12:44:40 - train: epoch 0137, iter [02000, 05004], lr: 0.024030, loss: 2.2155
2022-07-16 12:45:14 - train: epoch 0137, iter [02100, 05004], lr: 0.024016, loss: 2.3992
2022-07-16 12:45:49 - train: epoch 0137, iter [02200, 05004], lr: 0.024002, loss: 2.3659
2022-07-16 12:46:24 - train: epoch 0137, iter [02300, 05004], lr: 0.023989, loss: 2.3286
2022-07-16 12:46:59 - train: epoch 0137, iter [02400, 05004], lr: 0.023975, loss: 2.2208
2022-07-16 12:47:34 - train: epoch 0137, iter [02500, 05004], lr: 0.023961, loss: 2.1150
2022-07-16 12:48:08 - train: epoch 0137, iter [02600, 05004], lr: 0.023948, loss: 2.3879
2022-07-16 12:48:43 - train: epoch 0137, iter [02700, 05004], lr: 0.023934, loss: 2.2239
2022-07-16 12:49:18 - train: epoch 0137, iter [02800, 05004], lr: 0.023920, loss: 1.9743
2022-07-16 12:49:53 - train: epoch 0137, iter [02900, 05004], lr: 0.023906, loss: 2.0322
2022-07-16 12:50:28 - train: epoch 0137, iter [03000, 05004], lr: 0.023893, loss: 2.3384
2022-07-16 12:51:02 - train: epoch 0137, iter [03100, 05004], lr: 0.023879, loss: 2.2769
2022-07-16 12:51:37 - train: epoch 0137, iter [03200, 05004], lr: 0.023865, loss: 2.3318
2022-07-16 12:52:11 - train: epoch 0137, iter [03300, 05004], lr: 0.023851, loss: 2.2137
2022-07-16 12:52:45 - train: epoch 0137, iter [03400, 05004], lr: 0.023838, loss: 2.6917
2022-07-16 12:53:20 - train: epoch 0137, iter [03500, 05004], lr: 0.023824, loss: 2.3100
2022-07-16 12:53:55 - train: epoch 0137, iter [03600, 05004], lr: 0.023810, loss: 2.2158
2022-07-16 12:54:30 - train: epoch 0137, iter [03700, 05004], lr: 0.023797, loss: 2.3055
2022-07-16 12:55:05 - train: epoch 0137, iter [03800, 05004], lr: 0.023783, loss: 2.0482
2022-07-16 12:55:40 - train: epoch 0137, iter [03900, 05004], lr: 0.023769, loss: 2.0577
2022-07-16 12:56:15 - train: epoch 0137, iter [04000, 05004], lr: 0.023755, loss: 2.2136
2022-07-16 12:56:50 - train: epoch 0137, iter [04100, 05004], lr: 0.023742, loss: 2.0487
2022-07-16 12:57:25 - train: epoch 0137, iter [04200, 05004], lr: 0.023728, loss: 2.6197
2022-07-16 12:57:59 - train: epoch 0137, iter [04300, 05004], lr: 0.023714, loss: 1.9555
2022-07-16 12:58:35 - train: epoch 0137, iter [04400, 05004], lr: 0.023701, loss: 2.4873
2022-07-16 12:59:10 - train: epoch 0137, iter [04500, 05004], lr: 0.023687, loss: 2.3229
2022-07-16 12:59:45 - train: epoch 0137, iter [04600, 05004], lr: 0.023673, loss: 2.3929
2022-07-16 13:00:19 - train: epoch 0137, iter [04700, 05004], lr: 0.023660, loss: 2.5581
2022-07-16 13:00:54 - train: epoch 0137, iter [04800, 05004], lr: 0.023646, loss: 2.3061
2022-07-16 13:01:29 - train: epoch 0137, iter [04900, 05004], lr: 0.023632, loss: 2.4098
2022-07-16 13:02:02 - train: epoch 0137, iter [05000, 05004], lr: 0.023619, loss: 1.9548
2022-07-16 13:02:03 - train: epoch 137, train_loss: 2.2608
2022-07-16 13:03:18 - eval: epoch: 137, acc1: 68.750%, acc5: 89.014%, test_loss: 1.2704, per_image_load_time: 2.038ms, per_image_inference_time: 0.492ms
2022-07-16 13:03:19 - until epoch: 137, best_acc1: 68.750%
2022-07-16 13:03:19 - epoch 138 lr: 0.023618
2022-07-16 13:03:59 - train: epoch 0138, iter [00100, 05004], lr: 0.023604, loss: 1.8939
2022-07-16 13:04:33 - train: epoch 0138, iter [00200, 05004], lr: 0.023591, loss: 2.4998
2022-07-16 13:05:07 - train: epoch 0138, iter [00300, 05004], lr: 0.023577, loss: 2.3106
2022-07-16 13:05:42 - train: epoch 0138, iter [00400, 05004], lr: 0.023563, loss: 2.1663
2022-07-16 13:06:17 - train: epoch 0138, iter [00500, 05004], lr: 0.023550, loss: 2.0930
2022-07-16 13:06:51 - train: epoch 0138, iter [00600, 05004], lr: 0.023536, loss: 2.1260
2022-07-16 13:07:26 - train: epoch 0138, iter [00700, 05004], lr: 0.023522, loss: 1.9048
2022-07-16 13:08:00 - train: epoch 0138, iter [00800, 05004], lr: 0.023509, loss: 2.2441
2022-07-16 13:08:35 - train: epoch 0138, iter [00900, 05004], lr: 0.023495, loss: 2.3513
2022-07-16 13:09:09 - train: epoch 0138, iter [01000, 05004], lr: 0.023481, loss: 2.0532
2022-07-16 13:09:45 - train: epoch 0138, iter [01100, 05004], lr: 0.023468, loss: 2.2121
2022-07-16 13:10:19 - train: epoch 0138, iter [01200, 05004], lr: 0.023454, loss: 2.3386
2022-07-16 13:10:54 - train: epoch 0138, iter [01300, 05004], lr: 0.023440, loss: 2.1838
2022-07-16 13:11:27 - train: epoch 0138, iter [01400, 05004], lr: 0.023427, loss: 2.3929
2022-07-16 13:12:02 - train: epoch 0138, iter [01500, 05004], lr: 0.023413, loss: 2.0623
2022-07-16 13:12:37 - train: epoch 0138, iter [01600, 05004], lr: 0.023400, loss: 2.0846
2022-07-16 13:13:12 - train: epoch 0138, iter [01700, 05004], lr: 0.023386, loss: 2.1991
2022-07-16 13:13:47 - train: epoch 0138, iter [01800, 05004], lr: 0.023372, loss: 1.9645
2022-07-16 13:14:21 - train: epoch 0138, iter [01900, 05004], lr: 0.023359, loss: 2.0383
2022-07-16 13:14:55 - train: epoch 0138, iter [02000, 05004], lr: 0.023345, loss: 2.0451
2022-07-16 13:15:30 - train: epoch 0138, iter [02100, 05004], lr: 0.023331, loss: 2.2078
2022-07-16 13:16:04 - train: epoch 0138, iter [02200, 05004], lr: 0.023318, loss: 1.9120
2022-07-16 13:16:38 - train: epoch 0138, iter [02300, 05004], lr: 0.023304, loss: 2.3801
2022-07-16 13:17:12 - train: epoch 0138, iter [02400, 05004], lr: 0.023291, loss: 2.2111
2022-07-16 13:17:47 - train: epoch 0138, iter [02500, 05004], lr: 0.023277, loss: 2.3583
2022-07-16 13:18:21 - train: epoch 0138, iter [02600, 05004], lr: 0.023263, loss: 2.1478
2022-07-16 13:18:56 - train: epoch 0138, iter [02700, 05004], lr: 0.023250, loss: 2.5787
2022-07-16 13:19:30 - train: epoch 0138, iter [02800, 05004], lr: 0.023236, loss: 1.9743
2022-07-16 13:20:04 - train: epoch 0138, iter [02900, 05004], lr: 0.023223, loss: 2.3684
2022-07-16 13:20:39 - train: epoch 0138, iter [03000, 05004], lr: 0.023209, loss: 2.4116
2022-07-16 13:21:13 - train: epoch 0138, iter [03100, 05004], lr: 0.023195, loss: 2.3565
2022-07-16 13:21:49 - train: epoch 0138, iter [03200, 05004], lr: 0.023182, loss: 2.2170
2022-07-16 13:22:22 - train: epoch 0138, iter [03300, 05004], lr: 0.023168, loss: 2.3073
2022-07-16 13:22:57 - train: epoch 0138, iter [03400, 05004], lr: 0.023155, loss: 2.1579
2022-07-16 13:23:32 - train: epoch 0138, iter [03500, 05004], lr: 0.023141, loss: 1.9156
2022-07-16 13:24:06 - train: epoch 0138, iter [03600, 05004], lr: 0.023127, loss: 2.2502
2022-07-16 13:24:41 - train: epoch 0138, iter [03700, 05004], lr: 0.023114, loss: 2.2978
2022-07-16 13:25:16 - train: epoch 0138, iter [03800, 05004], lr: 0.023100, loss: 2.6252
2022-07-16 13:25:50 - train: epoch 0138, iter [03900, 05004], lr: 0.023087, loss: 2.2940
2022-07-16 13:26:25 - train: epoch 0138, iter [04000, 05004], lr: 0.023073, loss: 2.5924
2022-07-16 13:26:59 - train: epoch 0138, iter [04100, 05004], lr: 0.023060, loss: 2.1572
2022-07-16 13:27:34 - train: epoch 0138, iter [04200, 05004], lr: 0.023046, loss: 2.4141
2022-07-16 13:28:09 - train: epoch 0138, iter [04300, 05004], lr: 0.023033, loss: 2.1318
2022-07-16 13:28:43 - train: epoch 0138, iter [04400, 05004], lr: 0.023019, loss: 2.0362
2022-07-16 13:29:18 - train: epoch 0138, iter [04500, 05004], lr: 0.023005, loss: 2.3323
2022-07-16 13:29:53 - train: epoch 0138, iter [04600, 05004], lr: 0.022992, loss: 2.2001
2022-07-16 13:30:27 - train: epoch 0138, iter [04700, 05004], lr: 0.022978, loss: 1.9838
2022-07-16 13:31:03 - train: epoch 0138, iter [04800, 05004], lr: 0.022965, loss: 2.3404
2022-07-16 13:31:37 - train: epoch 0138, iter [04900, 05004], lr: 0.022951, loss: 2.1064
2022-07-16 13:32:11 - train: epoch 0138, iter [05000, 05004], lr: 0.022938, loss: 2.6271
2022-07-16 13:32:12 - train: epoch 138, train_loss: 2.2495
2022-07-16 13:33:27 - eval: epoch: 138, acc1: 69.254%, acc5: 89.190%, test_loss: 1.2489, per_image_load_time: 0.953ms, per_image_inference_time: 0.476ms
2022-07-16 13:33:27 - until epoch: 138, best_acc1: 69.254%
2022-07-16 13:33:27 - epoch 139 lr: 0.022937
2022-07-16 13:34:07 - train: epoch 0139, iter [00100, 05004], lr: 0.022924, loss: 2.1351
2022-07-16 13:34:42 - train: epoch 0139, iter [00200, 05004], lr: 0.022910, loss: 2.1777
2022-07-16 13:35:16 - train: epoch 0139, iter [00300, 05004], lr: 0.022897, loss: 2.2421
2022-07-16 13:35:50 - train: epoch 0139, iter [00400, 05004], lr: 0.022883, loss: 2.1532
2022-07-16 13:36:24 - train: epoch 0139, iter [00500, 05004], lr: 0.022870, loss: 2.3068
2022-07-16 13:36:59 - train: epoch 0139, iter [00600, 05004], lr: 0.022856, loss: 2.1793
2022-07-16 13:37:33 - train: epoch 0139, iter [00700, 05004], lr: 0.022842, loss: 2.2079
2022-07-16 13:38:07 - train: epoch 0139, iter [00800, 05004], lr: 0.022829, loss: 2.4373
2022-07-16 13:38:42 - train: epoch 0139, iter [00900, 05004], lr: 0.022815, loss: 2.6544
2022-07-16 13:39:15 - train: epoch 0139, iter [01000, 05004], lr: 0.022802, loss: 1.9359
2022-07-16 13:39:51 - train: epoch 0139, iter [01100, 05004], lr: 0.022788, loss: 1.9401
2022-07-16 13:40:25 - train: epoch 0139, iter [01200, 05004], lr: 0.022775, loss: 2.1500
2022-07-16 13:40:59 - train: epoch 0139, iter [01300, 05004], lr: 0.022761, loss: 2.3222
2022-07-16 13:41:34 - train: epoch 0139, iter [01400, 05004], lr: 0.022748, loss: 2.3458
2022-07-16 13:42:09 - train: epoch 0139, iter [01500, 05004], lr: 0.022734, loss: 2.2919
2022-07-16 13:42:43 - train: epoch 0139, iter [01600, 05004], lr: 0.022721, loss: 1.9914
2022-07-16 13:43:17 - train: epoch 0139, iter [01700, 05004], lr: 0.022707, loss: 2.2692
2022-07-16 13:43:52 - train: epoch 0139, iter [01800, 05004], lr: 0.022694, loss: 2.1791
2022-07-16 13:44:26 - train: epoch 0139, iter [01900, 05004], lr: 0.022680, loss: 2.4212
2022-07-16 13:45:00 - train: epoch 0139, iter [02000, 05004], lr: 0.022667, loss: 2.4672
2022-07-16 13:45:35 - train: epoch 0139, iter [02100, 05004], lr: 0.022654, loss: 2.0490
2022-07-16 13:46:09 - train: epoch 0139, iter [02200, 05004], lr: 0.022640, loss: 2.3101
2022-07-16 13:46:44 - train: epoch 0139, iter [02300, 05004], lr: 0.022627, loss: 2.3945
2022-07-16 13:47:19 - train: epoch 0139, iter [02400, 05004], lr: 0.022613, loss: 2.0915
2022-07-16 13:47:54 - train: epoch 0139, iter [02500, 05004], lr: 0.022600, loss: 2.5252
2022-07-16 13:48:28 - train: epoch 0139, iter [02600, 05004], lr: 0.022586, loss: 2.1358
2022-07-16 13:49:03 - train: epoch 0139, iter [02700, 05004], lr: 0.022573, loss: 2.1195
2022-07-16 13:49:37 - train: epoch 0139, iter [02800, 05004], lr: 0.022559, loss: 2.2506
2022-07-16 13:50:12 - train: epoch 0139, iter [02900, 05004], lr: 0.022546, loss: 2.4065
2022-07-16 13:50:47 - train: epoch 0139, iter [03000, 05004], lr: 0.022532, loss: 2.4997
2022-07-16 13:51:22 - train: epoch 0139, iter [03100, 05004], lr: 0.022519, loss: 2.3448
2022-07-16 13:51:57 - train: epoch 0139, iter [03200, 05004], lr: 0.022505, loss: 1.9647
2022-07-16 13:52:32 - train: epoch 0139, iter [03300, 05004], lr: 0.022492, loss: 2.1303
2022-07-16 13:53:06 - train: epoch 0139, iter [03400, 05004], lr: 0.022479, loss: 2.0060
2022-07-16 13:53:40 - train: epoch 0139, iter [03500, 05004], lr: 0.022465, loss: 2.1527
2022-07-16 13:54:16 - train: epoch 0139, iter [03600, 05004], lr: 0.022452, loss: 2.2470
2022-07-16 13:54:50 - train: epoch 0139, iter [03700, 05004], lr: 0.022438, loss: 2.2287
2022-07-16 13:55:26 - train: epoch 0139, iter [03800, 05004], lr: 0.022425, loss: 2.3543
2022-07-16 13:56:01 - train: epoch 0139, iter [03900, 05004], lr: 0.022411, loss: 2.2676
2022-07-16 13:56:36 - train: epoch 0139, iter [04000, 05004], lr: 0.022398, loss: 2.1909
2022-07-16 13:57:11 - train: epoch 0139, iter [04100, 05004], lr: 0.022385, loss: 2.4422
2022-07-16 13:57:45 - train: epoch 0139, iter [04200, 05004], lr: 0.022371, loss: 2.5341
2022-07-16 13:58:19 - train: epoch 0139, iter [04300, 05004], lr: 0.022358, loss: 2.0949
2022-07-16 13:58:53 - train: epoch 0139, iter [04400, 05004], lr: 0.022344, loss: 2.2720
2022-07-16 13:59:28 - train: epoch 0139, iter [04500, 05004], lr: 0.022331, loss: 2.2731
2022-07-16 14:00:03 - train: epoch 0139, iter [04600, 05004], lr: 0.022317, loss: 2.3736
2022-07-16 14:00:37 - train: epoch 0139, iter [04700, 05004], lr: 0.022304, loss: 2.1233
2022-07-16 14:01:12 - train: epoch 0139, iter [04800, 05004], lr: 0.022291, loss: 2.1594
2022-07-16 14:01:46 - train: epoch 0139, iter [04900, 05004], lr: 0.022277, loss: 2.5341
2022-07-16 14:02:19 - train: epoch 0139, iter [05000, 05004], lr: 0.022264, loss: 2.1677
2022-07-16 14:02:20 - train: epoch 139, train_loss: 2.2379
2022-07-16 14:03:36 - eval: epoch: 139, acc1: 69.288%, acc5: 89.254%, test_loss: 1.2472, per_image_load_time: 1.580ms, per_image_inference_time: 0.498ms
2022-07-16 14:03:36 - until epoch: 139, best_acc1: 69.288%
2022-07-16 14:03:36 - epoch 140 lr: 0.022263
2022-07-16 14:04:15 - train: epoch 0140, iter [00100, 05004], lr: 0.022250, loss: 2.3737
2022-07-16 14:04:50 - train: epoch 0140, iter [00200, 05004], lr: 0.022237, loss: 2.5602
2022-07-16 14:05:24 - train: epoch 0140, iter [00300, 05004], lr: 0.022223, loss: 2.2486
2022-07-16 14:05:59 - train: epoch 0140, iter [00400, 05004], lr: 0.022210, loss: 2.3377
2022-07-16 14:06:34 - train: epoch 0140, iter [00500, 05004], lr: 0.022196, loss: 1.9822
2022-07-16 14:07:08 - train: epoch 0140, iter [00600, 05004], lr: 0.022183, loss: 2.1702
2022-07-16 14:07:42 - train: epoch 0140, iter [00700, 05004], lr: 0.022170, loss: 1.9745
2022-07-16 14:08:17 - train: epoch 0140, iter [00800, 05004], lr: 0.022156, loss: 2.2746
2022-07-16 14:08:52 - train: epoch 0140, iter [00900, 05004], lr: 0.022143, loss: 2.1557
2022-07-16 14:09:26 - train: epoch 0140, iter [01000, 05004], lr: 0.022130, loss: 1.9886
2022-07-16 14:10:01 - train: epoch 0140, iter [01100, 05004], lr: 0.022116, loss: 2.2014
2022-07-16 14:10:36 - train: epoch 0140, iter [01200, 05004], lr: 0.022103, loss: 2.4037
2022-07-16 14:11:10 - train: epoch 0140, iter [01300, 05004], lr: 0.022089, loss: 2.2811
2022-07-16 14:11:44 - train: epoch 0140, iter [01400, 05004], lr: 0.022076, loss: 2.2671
2022-07-16 14:12:18 - train: epoch 0140, iter [01500, 05004], lr: 0.022063, loss: 2.3537
2022-07-16 14:12:53 - train: epoch 0140, iter [01600, 05004], lr: 0.022049, loss: 2.1540
2022-07-16 14:13:28 - train: epoch 0140, iter [01700, 05004], lr: 0.022036, loss: 2.0533
2022-07-16 14:14:02 - train: epoch 0140, iter [01800, 05004], lr: 0.022023, loss: 2.4392
2022-07-16 14:14:37 - train: epoch 0140, iter [01900, 05004], lr: 0.022009, loss: 2.2916
2022-07-16 14:15:12 - train: epoch 0140, iter [02000, 05004], lr: 0.021996, loss: 2.0140
2022-07-16 14:15:47 - train: epoch 0140, iter [02100, 05004], lr: 0.021983, loss: 2.3541
2022-07-16 14:16:23 - train: epoch 0140, iter [02200, 05004], lr: 0.021969, loss: 2.2418
2022-07-16 14:16:57 - train: epoch 0140, iter [02300, 05004], lr: 0.021956, loss: 2.0503
2022-07-16 14:17:32 - train: epoch 0140, iter [02400, 05004], lr: 0.021943, loss: 2.2385
2022-07-16 14:18:06 - train: epoch 0140, iter [02500, 05004], lr: 0.021929, loss: 2.1242
2022-07-16 14:18:41 - train: epoch 0140, iter [02600, 05004], lr: 0.021916, loss: 2.2247
2022-07-16 14:19:16 - train: epoch 0140, iter [02700, 05004], lr: 0.021903, loss: 2.2831
2022-07-16 14:19:50 - train: epoch 0140, iter [02800, 05004], lr: 0.021889, loss: 2.1524
2022-07-16 14:20:25 - train: epoch 0140, iter [02900, 05004], lr: 0.021876, loss: 2.1616
2022-07-16 14:21:00 - train: epoch 0140, iter [03000, 05004], lr: 0.021863, loss: 2.3531
2022-07-16 14:21:34 - train: epoch 0140, iter [03100, 05004], lr: 0.021850, loss: 2.1383
2022-07-16 14:22:09 - train: epoch 0140, iter [03200, 05004], lr: 0.021836, loss: 2.2535
2022-07-16 14:22:44 - train: epoch 0140, iter [03300, 05004], lr: 0.021823, loss: 2.3591
2022-07-16 14:23:18 - train: epoch 0140, iter [03400, 05004], lr: 0.021810, loss: 2.4134
2022-07-16 14:23:53 - train: epoch 0140, iter [03500, 05004], lr: 0.021796, loss: 2.4804
2022-07-16 14:24:27 - train: epoch 0140, iter [03600, 05004], lr: 0.021783, loss: 2.2964
2022-07-16 14:25:02 - train: epoch 0140, iter [03700, 05004], lr: 0.021770, loss: 2.4271
2022-07-16 14:25:36 - train: epoch 0140, iter [03800, 05004], lr: 0.021756, loss: 2.2560
2022-07-16 14:26:11 - train: epoch 0140, iter [03900, 05004], lr: 0.021743, loss: 2.2245
2022-07-16 14:26:45 - train: epoch 0140, iter [04000, 05004], lr: 0.021730, loss: 2.3140
2022-07-16 14:27:19 - train: epoch 0140, iter [04100, 05004], lr: 0.021717, loss: 2.2205
2022-07-16 14:27:54 - train: epoch 0140, iter [04200, 05004], lr: 0.021703, loss: 1.9973
2022-07-16 14:28:29 - train: epoch 0140, iter [04300, 05004], lr: 0.021690, loss: 2.4980
2022-07-16 14:29:03 - train: epoch 0140, iter [04400, 05004], lr: 0.021677, loss: 2.4289
2022-07-16 14:29:38 - train: epoch 0140, iter [04500, 05004], lr: 0.021664, loss: 2.4631
2022-07-16 14:30:12 - train: epoch 0140, iter [04600, 05004], lr: 0.021650, loss: 2.2605
2022-07-16 14:30:47 - train: epoch 0140, iter [04700, 05004], lr: 0.021637, loss: 2.1954
2022-07-16 14:31:21 - train: epoch 0140, iter [04800, 05004], lr: 0.021624, loss: 2.3850
2022-07-16 14:31:56 - train: epoch 0140, iter [04900, 05004], lr: 0.021611, loss: 2.2662
2022-07-16 14:32:29 - train: epoch 0140, iter [05000, 05004], lr: 0.021597, loss: 2.1633
2022-07-16 14:32:30 - train: epoch 140, train_loss: 2.2367
2022-07-16 14:33:45 - eval: epoch: 140, acc1: 69.494%, acc5: 89.486%, test_loss: 1.2489, per_image_load_time: 2.313ms, per_image_inference_time: 0.484ms
2022-07-16 14:33:45 - until epoch: 140, best_acc1: 69.494%
2022-07-16 14:33:45 - epoch 141 lr: 0.021597
2022-07-16 14:34:26 - train: epoch 0141, iter [00100, 05004], lr: 0.021584, loss: 2.2613
2022-07-16 14:35:01 - train: epoch 0141, iter [00200, 05004], lr: 0.021570, loss: 2.1757
2022-07-16 14:35:35 - train: epoch 0141, iter [00300, 05004], lr: 0.021557, loss: 2.1981
2022-07-16 14:36:10 - train: epoch 0141, iter [00400, 05004], lr: 0.021544, loss: 2.4728
2022-07-16 14:36:44 - train: epoch 0141, iter [00500, 05004], lr: 0.021531, loss: 2.0216
2022-07-16 14:37:19 - train: epoch 0141, iter [00600, 05004], lr: 0.021517, loss: 2.2052
2022-07-16 14:37:53 - train: epoch 0141, iter [00700, 05004], lr: 0.021504, loss: 2.1882
2022-07-16 14:38:27 - train: epoch 0141, iter [00800, 05004], lr: 0.021491, loss: 2.2518
2022-07-16 14:39:02 - train: epoch 0141, iter [00900, 05004], lr: 0.021478, loss: 2.0708
2022-07-16 14:39:37 - train: epoch 0141, iter [01000, 05004], lr: 0.021464, loss: 2.2202
2022-07-16 14:40:12 - train: epoch 0141, iter [01100, 05004], lr: 0.021451, loss: 2.7034
2022-07-16 14:40:46 - train: epoch 0141, iter [01200, 05004], lr: 0.021438, loss: 2.3143
2022-07-16 14:41:20 - train: epoch 0141, iter [01300, 05004], lr: 0.021425, loss: 2.4264
2022-07-16 14:41:55 - train: epoch 0141, iter [01400, 05004], lr: 0.021412, loss: 2.0554
2022-07-16 14:42:30 - train: epoch 0141, iter [01500, 05004], lr: 0.021398, loss: 2.0457
2022-07-16 14:43:04 - train: epoch 0141, iter [01600, 05004], lr: 0.021385, loss: 2.1484
2022-07-16 14:43:38 - train: epoch 0141, iter [01700, 05004], lr: 0.021372, loss: 2.2133
2022-07-16 14:44:14 - train: epoch 0141, iter [01800, 05004], lr: 0.021359, loss: 2.3696
2022-07-16 14:44:47 - train: epoch 0141, iter [01900, 05004], lr: 0.021346, loss: 2.2270
2022-07-16 14:45:22 - train: epoch 0141, iter [02000, 05004], lr: 0.021332, loss: 2.1980
2022-07-16 14:45:57 - train: epoch 0141, iter [02100, 05004], lr: 0.021319, loss: 2.0883
2022-07-16 14:46:32 - train: epoch 0141, iter [02200, 05004], lr: 0.021306, loss: 2.3813
2022-07-16 14:47:06 - train: epoch 0141, iter [02300, 05004], lr: 0.021293, loss: 2.1994
2022-07-16 14:47:41 - train: epoch 0141, iter [02400, 05004], lr: 0.021280, loss: 2.1476
2022-07-16 14:48:15 - train: epoch 0141, iter [02500, 05004], lr: 0.021266, loss: 2.3064
2022-07-16 14:48:50 - train: epoch 0141, iter [02600, 05004], lr: 0.021253, loss: 2.2806
2022-07-16 14:49:24 - train: epoch 0141, iter [02700, 05004], lr: 0.021240, loss: 2.4154
2022-07-16 14:49:59 - train: epoch 0141, iter [02800, 05004], lr: 0.021227, loss: 2.2021
2022-07-16 14:50:34 - train: epoch 0141, iter [02900, 05004], lr: 0.021214, loss: 2.3014
2022-07-16 14:51:09 - train: epoch 0141, iter [03000, 05004], lr: 0.021201, loss: 1.9180
2022-07-16 14:51:44 - train: epoch 0141, iter [03100, 05004], lr: 0.021187, loss: 2.4200
2022-07-16 14:52:18 - train: epoch 0141, iter [03200, 05004], lr: 0.021174, loss: 2.3188
2022-07-16 14:52:53 - train: epoch 0141, iter [03300, 05004], lr: 0.021161, loss: 2.1643
2022-07-16 14:53:27 - train: epoch 0141, iter [03400, 05004], lr: 0.021148, loss: 2.1517
2022-07-16 14:54:02 - train: epoch 0141, iter [03500, 05004], lr: 0.021135, loss: 2.3395
2022-07-16 14:54:36 - train: epoch 0141, iter [03600, 05004], lr: 0.021122, loss: 2.1128
2022-07-16 14:55:10 - train: epoch 0141, iter [03700, 05004], lr: 0.021109, loss: 2.0076
2022-07-16 14:55:45 - train: epoch 0141, iter [03800, 05004], lr: 0.021095, loss: 2.1013
2022-07-16 14:56:19 - train: epoch 0141, iter [03900, 05004], lr: 0.021082, loss: 2.3488
2022-07-16 14:56:53 - train: epoch 0141, iter [04000, 05004], lr: 0.021069, loss: 2.3679
2022-07-16 14:57:27 - train: epoch 0141, iter [04100, 05004], lr: 0.021056, loss: 2.2099
2022-07-16 14:58:02 - train: epoch 0141, iter [04200, 05004], lr: 0.021043, loss: 2.2609
2022-07-16 14:58:37 - train: epoch 0141, iter [04300, 05004], lr: 0.021030, loss: 2.2118
2022-07-16 14:59:11 - train: epoch 0141, iter [04400, 05004], lr: 0.021017, loss: 2.2637
2022-07-16 14:59:45 - train: epoch 0141, iter [04500, 05004], lr: 0.021004, loss: 2.4559
2022-07-16 15:00:19 - train: epoch 0141, iter [04600, 05004], lr: 0.020990, loss: 2.3563
2022-07-16 15:00:54 - train: epoch 0141, iter [04700, 05004], lr: 0.020977, loss: 2.2134
2022-07-16 15:01:29 - train: epoch 0141, iter [04800, 05004], lr: 0.020964, loss: 2.0978
2022-07-16 15:02:03 - train: epoch 0141, iter [04900, 05004], lr: 0.020951, loss: 2.1009
2022-07-16 15:02:36 - train: epoch 0141, iter [05000, 05004], lr: 0.020938, loss: 2.1133
2022-07-16 15:02:37 - train: epoch 141, train_loss: 2.2232
2022-07-16 15:03:52 - eval: epoch: 141, acc1: 68.996%, acc5: 89.418%, test_loss: 1.2479, per_image_load_time: 2.039ms, per_image_inference_time: 0.468ms
2022-07-16 15:03:52 - until epoch: 141, best_acc1: 69.494%
2022-07-16 15:03:52 - epoch 142 lr: 0.020937
2022-07-16 15:04:32 - train: epoch 0142, iter [00100, 05004], lr: 0.020924, loss: 2.4882
2022-07-16 15:05:05 - train: epoch 0142, iter [00200, 05004], lr: 0.020911, loss: 2.1291
2022-07-16 15:05:40 - train: epoch 0142, iter [00300, 05004], lr: 0.020898, loss: 2.2731
2022-07-16 15:06:14 - train: epoch 0142, iter [00400, 05004], lr: 0.020885, loss: 2.1936
2022-07-16 15:06:49 - train: epoch 0142, iter [00500, 05004], lr: 0.020872, loss: 2.2084
2022-07-16 15:07:24 - train: epoch 0142, iter [00600, 05004], lr: 0.020859, loss: 2.1587
2022-07-16 15:07:58 - train: epoch 0142, iter [00700, 05004], lr: 0.020846, loss: 2.4825
2022-07-16 15:08:33 - train: epoch 0142, iter [00800, 05004], lr: 0.020833, loss: 2.0475
2022-07-16 15:09:07 - train: epoch 0142, iter [00900, 05004], lr: 0.020820, loss: 1.9519
2022-07-16 15:09:41 - train: epoch 0142, iter [01000, 05004], lr: 0.020807, loss: 2.4428
2022-07-16 15:10:15 - train: epoch 0142, iter [01100, 05004], lr: 0.020794, loss: 2.0145
2022-07-16 15:10:49 - train: epoch 0142, iter [01200, 05004], lr: 0.020781, loss: 2.2519
2022-07-16 15:11:24 - train: epoch 0142, iter [01300, 05004], lr: 0.020767, loss: 2.0520
2022-07-16 15:11:59 - train: epoch 0142, iter [01400, 05004], lr: 0.020754, loss: 1.8596
2022-07-16 15:12:33 - train: epoch 0142, iter [01500, 05004], lr: 0.020741, loss: 2.5577
2022-07-16 15:13:08 - train: epoch 0142, iter [01600, 05004], lr: 0.020728, loss: 2.2566
2022-07-16 15:13:42 - train: epoch 0142, iter [01700, 05004], lr: 0.020715, loss: 2.0262
2022-07-16 15:14:16 - train: epoch 0142, iter [01800, 05004], lr: 0.020702, loss: 2.4444
2022-07-16 15:14:51 - train: epoch 0142, iter [01900, 05004], lr: 0.020689, loss: 2.4517
2022-07-16 15:15:25 - train: epoch 0142, iter [02000, 05004], lr: 0.020676, loss: 2.3149
2022-07-16 15:15:59 - train: epoch 0142, iter [02100, 05004], lr: 0.020663, loss: 2.4242
2022-07-16 15:16:33 - train: epoch 0142, iter [02200, 05004], lr: 0.020650, loss: 2.3334
2022-07-16 15:17:08 - train: epoch 0142, iter [02300, 05004], lr: 0.020637, loss: 2.2641
2022-07-16 15:17:43 - train: epoch 0142, iter [02400, 05004], lr: 0.020624, loss: 2.0870
2022-07-16 15:18:17 - train: epoch 0142, iter [02500, 05004], lr: 0.020611, loss: 2.3027
2022-07-16 15:18:51 - train: epoch 0142, iter [02600, 05004], lr: 0.020598, loss: 2.1191
2022-07-16 15:19:25 - train: epoch 0142, iter [02700, 05004], lr: 0.020585, loss: 2.3129
2022-07-16 15:20:00 - train: epoch 0142, iter [02800, 05004], lr: 0.020572, loss: 2.2549
2022-07-16 15:20:34 - train: epoch 0142, iter [02900, 05004], lr: 0.020559, loss: 2.1479
2022-07-16 15:21:09 - train: epoch 0142, iter [03000, 05004], lr: 0.020546, loss: 2.2064
2022-07-16 15:21:43 - train: epoch 0142, iter [03100, 05004], lr: 0.020533, loss: 2.3993
2022-07-16 15:22:17 - train: epoch 0142, iter [03200, 05004], lr: 0.020520, loss: 2.3392
2022-07-16 15:22:52 - train: epoch 0142, iter [03300, 05004], lr: 0.020507, loss: 2.1619
2022-07-16 15:23:26 - train: epoch 0142, iter [03400, 05004], lr: 0.020494, loss: 2.1971
2022-07-16 15:24:01 - train: epoch 0142, iter [03500, 05004], lr: 0.020481, loss: 2.0171
2022-07-16 15:24:35 - train: epoch 0142, iter [03600, 05004], lr: 0.020468, loss: 2.1013
2022-07-16 15:25:09 - train: epoch 0142, iter [03700, 05004], lr: 0.020455, loss: 2.4377
2022-07-16 15:25:44 - train: epoch 0142, iter [03800, 05004], lr: 0.020442, loss: 2.2977
2022-07-16 15:26:19 - train: epoch 0142, iter [03900, 05004], lr: 0.020429, loss: 2.4563
2022-07-16 15:26:52 - train: epoch 0142, iter [04000, 05004], lr: 0.020416, loss: 2.2746
2022-07-16 15:27:26 - train: epoch 0142, iter [04100, 05004], lr: 0.020403, loss: 2.3892
2022-07-16 15:28:02 - train: epoch 0142, iter [04200, 05004], lr: 0.020390, loss: 2.2014
2022-07-16 15:28:36 - train: epoch 0142, iter [04300, 05004], lr: 0.020377, loss: 2.1769
2022-07-16 15:29:11 - train: epoch 0142, iter [04400, 05004], lr: 0.020364, loss: 2.1184
2022-07-16 15:29:45 - train: epoch 0142, iter [04500, 05004], lr: 0.020351, loss: 2.2395
2022-07-16 15:30:21 - train: epoch 0142, iter [04600, 05004], lr: 0.020338, loss: 2.3453
2022-07-16 15:30:54 - train: epoch 0142, iter [04700, 05004], lr: 0.020325, loss: 2.0659
2022-07-16 15:31:29 - train: epoch 0142, iter [04800, 05004], lr: 0.020312, loss: 1.9326
2022-07-16 15:32:02 - train: epoch 0142, iter [04900, 05004], lr: 0.020299, loss: 2.0565
2022-07-16 15:32:35 - train: epoch 0142, iter [05000, 05004], lr: 0.020286, loss: 1.9638
2022-07-16 15:32:36 - train: epoch 142, train_loss: 2.2090
2022-07-16 15:33:50 - eval: epoch: 142, acc1: 69.544%, acc5: 89.576%, test_loss: 1.2283, per_image_load_time: 2.176ms, per_image_inference_time: 0.475ms
2022-07-16 15:33:51 - until epoch: 142, best_acc1: 69.544%
2022-07-16 15:33:51 - epoch 143 lr: 0.020286
2022-07-16 15:34:30 - train: epoch 0143, iter [00100, 05004], lr: 0.020273, loss: 2.0370
2022-07-16 15:35:06 - train: epoch 0143, iter [00200, 05004], lr: 0.020260, loss: 1.8239
2022-07-16 15:35:38 - train: epoch 0143, iter [00300, 05004], lr: 0.020247, loss: 2.1393
2022-07-16 15:36:13 - train: epoch 0143, iter [00400, 05004], lr: 0.020234, loss: 1.8975
2022-07-16 15:36:47 - train: epoch 0143, iter [00500, 05004], lr: 0.020221, loss: 2.1573
2022-07-16 15:37:21 - train: epoch 0143, iter [00600, 05004], lr: 0.020208, loss: 2.1797
2022-07-16 15:37:55 - train: epoch 0143, iter [00700, 05004], lr: 0.020195, loss: 2.2241
2022-07-16 15:38:29 - train: epoch 0143, iter [00800, 05004], lr: 0.020182, loss: 2.6142
2022-07-16 15:39:02 - train: epoch 0143, iter [00900, 05004], lr: 0.020169, loss: 2.3672
2022-07-16 15:39:37 - train: epoch 0143, iter [01000, 05004], lr: 0.020157, loss: 2.3200
2022-07-16 15:40:11 - train: epoch 0143, iter [01100, 05004], lr: 0.020144, loss: 2.3379
2022-07-16 15:40:45 - train: epoch 0143, iter [01200, 05004], lr: 0.020131, loss: 2.4899
2022-07-16 15:41:19 - train: epoch 0143, iter [01300, 05004], lr: 0.020118, loss: 2.2565
2022-07-16 15:41:53 - train: epoch 0143, iter [01400, 05004], lr: 0.020105, loss: 2.4129
2022-07-16 15:42:27 - train: epoch 0143, iter [01500, 05004], lr: 0.020092, loss: 2.4978
2022-07-16 15:43:01 - train: epoch 0143, iter [01600, 05004], lr: 0.020079, loss: 2.0702
2022-07-16 15:43:35 - train: epoch 0143, iter [01700, 05004], lr: 0.020066, loss: 2.3093
2022-07-16 15:44:10 - train: epoch 0143, iter [01800, 05004], lr: 0.020053, loss: 2.2704
2022-07-16 15:44:44 - train: epoch 0143, iter [01900, 05004], lr: 0.020040, loss: 2.1184
2022-07-16 15:45:18 - train: epoch 0143, iter [02000, 05004], lr: 0.020028, loss: 2.3559
2022-07-16 15:45:53 - train: epoch 0143, iter [02100, 05004], lr: 0.020015, loss: 1.8852
2022-07-16 15:46:27 - train: epoch 0143, iter [02200, 05004], lr: 0.020002, loss: 2.4004
2022-07-16 15:47:00 - train: epoch 0143, iter [02300, 05004], lr: 0.019989, loss: 2.2301
2022-07-16 15:47:34 - train: epoch 0143, iter [02400, 05004], lr: 0.019976, loss: 2.2555
2022-07-16 15:48:08 - train: epoch 0143, iter [02500, 05004], lr: 0.019963, loss: 2.2009
2022-07-16 15:48:43 - train: epoch 0143, iter [02600, 05004], lr: 0.019950, loss: 2.0044
2022-07-16 15:49:16 - train: epoch 0143, iter [02700, 05004], lr: 0.019937, loss: 2.0058
2022-07-16 15:49:50 - train: epoch 0143, iter [02800, 05004], lr: 0.019925, loss: 2.1679
2022-07-16 15:50:25 - train: epoch 0143, iter [02900, 05004], lr: 0.019912, loss: 2.4672
2022-07-16 15:50:57 - train: epoch 0143, iter [03000, 05004], lr: 0.019899, loss: 2.3192
2022-07-16 15:51:32 - train: epoch 0143, iter [03100, 05004], lr: 0.019886, loss: 1.9435
2022-07-16 15:52:07 - train: epoch 0143, iter [03200, 05004], lr: 0.019873, loss: 2.3248
2022-07-16 15:52:42 - train: epoch 0143, iter [03300, 05004], lr: 0.019860, loss: 1.7670
2022-07-16 15:53:15 - train: epoch 0143, iter [03400, 05004], lr: 0.019847, loss: 2.2030
2022-07-16 15:53:50 - train: epoch 0143, iter [03500, 05004], lr: 0.019835, loss: 2.1907
2022-07-16 15:54:24 - train: epoch 0143, iter [03600, 05004], lr: 0.019822, loss: 2.2662
2022-07-16 15:54:58 - train: epoch 0143, iter [03700, 05004], lr: 0.019809, loss: 2.2444
2022-07-16 15:55:32 - train: epoch 0143, iter [03800, 05004], lr: 0.019796, loss: 1.8887
2022-07-16 15:56:07 - train: epoch 0143, iter [03900, 05004], lr: 0.019783, loss: 2.2016
2022-07-16 15:56:41 - train: epoch 0143, iter [04000, 05004], lr: 0.019770, loss: 2.1613
2022-07-16 15:57:16 - train: epoch 0143, iter [04100, 05004], lr: 0.019758, loss: 2.3148
2022-07-16 15:57:50 - train: epoch 0143, iter [04200, 05004], lr: 0.019745, loss: 2.2756
2022-07-16 15:58:24 - train: epoch 0143, iter [04300, 05004], lr: 0.019732, loss: 2.5216
2022-07-16 15:58:58 - train: epoch 0143, iter [04400, 05004], lr: 0.019719, loss: 2.2849
2022-07-16 15:59:33 - train: epoch 0143, iter [04500, 05004], lr: 0.019706, loss: 2.1967
2022-07-16 16:00:07 - train: epoch 0143, iter [04600, 05004], lr: 0.019694, loss: 2.2208
2022-07-16 16:00:42 - train: epoch 0143, iter [04700, 05004], lr: 0.019681, loss: 2.1803
2022-07-16 16:01:16 - train: epoch 0143, iter [04800, 05004], lr: 0.019668, loss: 2.2611
2022-07-16 16:01:51 - train: epoch 0143, iter [04900, 05004], lr: 0.019655, loss: 2.0130
2022-07-16 16:02:23 - train: epoch 0143, iter [05000, 05004], lr: 0.019642, loss: 2.0133
2022-07-16 16:02:24 - train: epoch 143, train_loss: 2.2001
2022-07-16 16:03:39 - eval: epoch: 143, acc1: 69.546%, acc5: 89.452%, test_loss: 1.2364, per_image_load_time: 1.701ms, per_image_inference_time: 0.463ms
2022-07-16 16:03:39 - until epoch: 143, best_acc1: 69.546%
2022-07-16 16:03:39 - epoch 144 lr: 0.019642
2022-07-16 16:04:20 - train: epoch 0144, iter [00100, 05004], lr: 0.019629, loss: 2.0233
2022-07-16 16:04:54 - train: epoch 0144, iter [00200, 05004], lr: 0.019616, loss: 2.1976
2022-07-16 16:05:30 - train: epoch 0144, iter [00300, 05004], lr: 0.019604, loss: 2.3676
2022-07-16 16:06:02 - train: epoch 0144, iter [00400, 05004], lr: 0.019591, loss: 2.2829
2022-07-16 16:06:37 - train: epoch 0144, iter [00500, 05004], lr: 0.019578, loss: 2.6061
2022-07-16 16:07:13 - train: epoch 0144, iter [00600, 05004], lr: 0.019565, loss: 2.6031
2022-07-16 16:07:46 - train: epoch 0144, iter [00700, 05004], lr: 0.019552, loss: 2.1115
2022-07-16 16:08:20 - train: epoch 0144, iter [00800, 05004], lr: 0.019540, loss: 2.4921
2022-07-16 16:08:55 - train: epoch 0144, iter [00900, 05004], lr: 0.019527, loss: 1.9390
2022-07-16 16:09:29 - train: epoch 0144, iter [01000, 05004], lr: 0.019514, loss: 1.9417
2022-07-16 16:10:04 - train: epoch 0144, iter [01100, 05004], lr: 0.019501, loss: 2.0752
2022-07-16 16:10:38 - train: epoch 0144, iter [01200, 05004], lr: 0.019489, loss: 2.2214
2022-07-16 16:11:13 - train: epoch 0144, iter [01300, 05004], lr: 0.019476, loss: 2.3529
2022-07-16 16:11:47 - train: epoch 0144, iter [01400, 05004], lr: 0.019463, loss: 2.3169
2022-07-16 16:12:21 - train: epoch 0144, iter [01500, 05004], lr: 0.019450, loss: 2.0654
2022-07-16 16:12:56 - train: epoch 0144, iter [01600, 05004], lr: 0.019438, loss: 2.0553
2022-07-16 16:13:29 - train: epoch 0144, iter [01700, 05004], lr: 0.019425, loss: 2.2311
2022-07-16 16:14:04 - train: epoch 0144, iter [01800, 05004], lr: 0.019412, loss: 2.1997
2022-07-16 16:14:38 - train: epoch 0144, iter [01900, 05004], lr: 0.019399, loss: 2.2382
2022-07-16 16:15:12 - train: epoch 0144, iter [02000, 05004], lr: 0.019387, loss: 2.2068
2022-07-16 16:15:46 - train: epoch 0144, iter [02100, 05004], lr: 0.019374, loss: 2.3166
2022-07-16 16:16:20 - train: epoch 0144, iter [02200, 05004], lr: 0.019361, loss: 1.9440
2022-07-16 16:16:54 - train: epoch 0144, iter [02300, 05004], lr: 0.019349, loss: 1.9675
2022-07-16 16:17:29 - train: epoch 0144, iter [02400, 05004], lr: 0.019336, loss: 2.3675
2022-07-16 16:18:03 - train: epoch 0144, iter [02500, 05004], lr: 0.019323, loss: 1.9625
2022-07-16 16:18:38 - train: epoch 0144, iter [02600, 05004], lr: 0.019310, loss: 2.2134
2022-07-16 16:19:12 - train: epoch 0144, iter [02700, 05004], lr: 0.019298, loss: 2.0628
2022-07-16 16:19:46 - train: epoch 0144, iter [02800, 05004], lr: 0.019285, loss: 1.9379
2022-07-16 16:20:19 - train: epoch 0144, iter [02900, 05004], lr: 0.019272, loss: 2.1524
2022-07-16 16:20:54 - train: epoch 0144, iter [03000, 05004], lr: 0.019260, loss: 2.5646
2022-07-16 16:21:28 - train: epoch 0144, iter [03100, 05004], lr: 0.019247, loss: 2.0042
2022-07-16 16:22:02 - train: epoch 0144, iter [03200, 05004], lr: 0.019234, loss: 2.1929
2022-07-16 16:22:36 - train: epoch 0144, iter [03300, 05004], lr: 0.019221, loss: 2.5960
2022-07-16 16:23:10 - train: epoch 0144, iter [03400, 05004], lr: 0.019209, loss: 2.1236
2022-07-16 16:23:44 - train: epoch 0144, iter [03500, 05004], lr: 0.019196, loss: 2.4397
2022-07-16 16:24:19 - train: epoch 0144, iter [03600, 05004], lr: 0.019183, loss: 2.1683
2022-07-16 16:24:52 - train: epoch 0144, iter [03700, 05004], lr: 0.019171, loss: 1.9689
2022-07-16 16:25:27 - train: epoch 0144, iter [03800, 05004], lr: 0.019158, loss: 2.4497
2022-07-16 16:26:01 - train: epoch 0144, iter [03900, 05004], lr: 0.019145, loss: 1.9477
2022-07-16 16:26:35 - train: epoch 0144, iter [04000, 05004], lr: 0.019133, loss: 2.1281
2022-07-16 16:27:10 - train: epoch 0144, iter [04100, 05004], lr: 0.019120, loss: 2.5367
2022-07-16 16:27:45 - train: epoch 0144, iter [04200, 05004], lr: 0.019107, loss: 2.5110
2022-07-16 16:28:18 - train: epoch 0144, iter [04300, 05004], lr: 0.019095, loss: 2.2591
2022-07-16 16:28:52 - train: epoch 0144, iter [04400, 05004], lr: 0.019082, loss: 2.2144
2022-07-16 16:29:27 - train: epoch 0144, iter [04500, 05004], lr: 0.019069, loss: 2.0187
2022-07-16 16:30:02 - train: epoch 0144, iter [04600, 05004], lr: 0.019057, loss: 2.3005
2022-07-16 16:30:37 - train: epoch 0144, iter [04700, 05004], lr: 0.019044, loss: 2.1886
2022-07-16 16:31:11 - train: epoch 0144, iter [04800, 05004], lr: 0.019032, loss: 2.3048
2022-07-16 16:31:46 - train: epoch 0144, iter [04900, 05004], lr: 0.019019, loss: 2.3533
2022-07-16 16:32:19 - train: epoch 0144, iter [05000, 05004], lr: 0.019006, loss: 2.1514
2022-07-16 16:32:20 - train: epoch 144, train_loss: 2.1925
2022-07-16 16:33:35 - eval: epoch: 144, acc1: 69.780%, acc5: 89.842%, test_loss: 1.2143, per_image_load_time: 1.242ms, per_image_inference_time: 0.459ms
2022-07-16 16:33:35 - until epoch: 144, best_acc1: 69.780%
2022-07-16 16:33:35 - epoch 145 lr: 0.019006
2022-07-16 16:34:14 - train: epoch 0145, iter [00100, 05004], lr: 0.018993, loss: 2.1267
2022-07-16 16:34:48 - train: epoch 0145, iter [00200, 05004], lr: 0.018981, loss: 2.1159
2022-07-16 16:35:22 - train: epoch 0145, iter [00300, 05004], lr: 0.018968, loss: 2.0266
2022-07-16 16:35:56 - train: epoch 0145, iter [00400, 05004], lr: 0.018955, loss: 2.3126
2022-07-16 16:36:31 - train: epoch 0145, iter [00500, 05004], lr: 0.018943, loss: 2.4484
2022-07-16 16:37:05 - train: epoch 0145, iter [00600, 05004], lr: 0.018930, loss: 2.2526
2022-07-16 16:37:39 - train: epoch 0145, iter [00700, 05004], lr: 0.018917, loss: 2.2934
2022-07-16 16:38:13 - train: epoch 0145, iter [00800, 05004], lr: 0.018905, loss: 2.1253
2022-07-16 16:38:48 - train: epoch 0145, iter [00900, 05004], lr: 0.018892, loss: 1.8434
2022-07-16 16:39:21 - train: epoch 0145, iter [01000, 05004], lr: 0.018880, loss: 2.0645
2022-07-16 16:39:56 - train: epoch 0145, iter [01100, 05004], lr: 0.018867, loss: 2.1906
2022-07-16 16:40:30 - train: epoch 0145, iter [01200, 05004], lr: 0.018854, loss: 2.2353
2022-07-16 16:41:05 - train: epoch 0145, iter [01300, 05004], lr: 0.018842, loss: 2.1691
2022-07-16 16:41:38 - train: epoch 0145, iter [01400, 05004], lr: 0.018829, loss: 1.9378
2022-07-16 16:42:13 - train: epoch 0145, iter [01500, 05004], lr: 0.018817, loss: 2.1484
2022-07-16 16:42:46 - train: epoch 0145, iter [01600, 05004], lr: 0.018804, loss: 2.1843
2022-07-16 16:43:21 - train: epoch 0145, iter [01700, 05004], lr: 0.018792, loss: 1.9910
2022-07-16 16:43:55 - train: epoch 0145, iter [01800, 05004], lr: 0.018779, loss: 2.0839
2022-07-16 16:44:29 - train: epoch 0145, iter [01900, 05004], lr: 0.018766, loss: 2.1495
2022-07-16 16:45:04 - train: epoch 0145, iter [02000, 05004], lr: 0.018754, loss: 1.9470
2022-07-16 16:45:38 - train: epoch 0145, iter [02100, 05004], lr: 0.018741, loss: 2.4034
2022-07-16 16:46:12 - train: epoch 0145, iter [02200, 05004], lr: 0.018729, loss: 2.2290
2022-07-16 16:46:46 - train: epoch 0145, iter [02300, 05004], lr: 0.018716, loss: 2.1801
2022-07-16 16:47:20 - train: epoch 0145, iter [02400, 05004], lr: 0.018704, loss: 2.3641
2022-07-16 16:47:54 - train: epoch 0145, iter [02500, 05004], lr: 0.018691, loss: 2.1267
2022-07-16 16:48:29 - train: epoch 0145, iter [02600, 05004], lr: 0.018678, loss: 2.0722
2022-07-16 16:49:03 - train: epoch 0145, iter [02700, 05004], lr: 0.018666, loss: 2.5206
2022-07-16 16:49:38 - train: epoch 0145, iter [02800, 05004], lr: 0.018653, loss: 2.3011
2022-07-16 16:50:12 - train: epoch 0145, iter [02900, 05004], lr: 0.018641, loss: 2.0810
2022-07-16 16:50:47 - train: epoch 0145, iter [03000, 05004], lr: 0.018628, loss: 2.1038
2022-07-16 16:51:21 - train: epoch 0145, iter [03100, 05004], lr: 0.018616, loss: 2.4043
2022-07-16 16:51:55 - train: epoch 0145, iter [03200, 05004], lr: 0.018603, loss: 2.1724
2022-07-16 16:52:29 - train: epoch 0145, iter [03300, 05004], lr: 0.018591, loss: 2.3937
2022-07-16 16:53:04 - train: epoch 0145, iter [03400, 05004], lr: 0.018578, loss: 1.8661
2022-07-16 16:53:39 - train: epoch 0145, iter [03500, 05004], lr: 0.018566, loss: 2.0971
2022-07-16 16:54:13 - train: epoch 0145, iter [03600, 05004], lr: 0.018553, loss: 2.0270
2022-07-16 16:54:47 - train: epoch 0145, iter [03700, 05004], lr: 0.018541, loss: 2.0868
2022-07-16 16:55:22 - train: epoch 0145, iter [03800, 05004], lr: 0.018528, loss: 2.3165
2022-07-16 16:55:57 - train: epoch 0145, iter [03900, 05004], lr: 0.018516, loss: 2.4644
2022-07-16 16:56:30 - train: epoch 0145, iter [04000, 05004], lr: 0.018503, loss: 2.3634
2022-07-16 16:57:04 - train: epoch 0145, iter [04100, 05004], lr: 0.018491, loss: 2.2425
2022-07-16 16:57:39 - train: epoch 0145, iter [04200, 05004], lr: 0.018478, loss: 2.3648
2022-07-16 16:58:13 - train: epoch 0145, iter [04300, 05004], lr: 0.018466, loss: 2.1217
2022-07-16 16:58:47 - train: epoch 0145, iter [04400, 05004], lr: 0.018453, loss: 2.4419
2022-07-16 16:59:22 - train: epoch 0145, iter [04500, 05004], lr: 0.018441, loss: 2.4170
2022-07-16 16:59:56 - train: epoch 0145, iter [04600, 05004], lr: 0.018428, loss: 2.1001
2022-07-16 17:00:31 - train: epoch 0145, iter [04700, 05004], lr: 0.018416, loss: 2.0365
2022-07-16 17:01:04 - train: epoch 0145, iter [04800, 05004], lr: 0.018403, loss: 2.0589
2022-07-16 17:01:40 - train: epoch 0145, iter [04900, 05004], lr: 0.018391, loss: 2.3783
2022-07-16 17:02:13 - train: epoch 0145, iter [05000, 05004], lr: 0.018378, loss: 2.1489
2022-07-16 17:02:14 - train: epoch 145, train_loss: 2.1816
2022-07-16 17:03:29 - eval: epoch: 145, acc1: 69.818%, acc5: 89.776%, test_loss: 1.2218, per_image_load_time: 2.338ms, per_image_inference_time: 0.439ms
2022-07-16 17:03:30 - until epoch: 145, best_acc1: 69.818%
2022-07-16 17:03:30 - epoch 146 lr: 0.018378
2022-07-16 17:04:10 - train: epoch 0146, iter [00100, 05004], lr: 0.018365, loss: 1.7294
2022-07-16 17:04:43 - train: epoch 0146, iter [00200, 05004], lr: 0.018353, loss: 2.1837
2022-07-16 17:05:17 - train: epoch 0146, iter [00300, 05004], lr: 0.018340, loss: 2.0580
2022-07-16 17:05:52 - train: epoch 0146, iter [00400, 05004], lr: 0.018328, loss: 2.2692
2022-07-16 17:06:27 - train: epoch 0146, iter [00500, 05004], lr: 0.018315, loss: 1.8948
2022-07-16 17:07:01 - train: epoch 0146, iter [00600, 05004], lr: 0.018303, loss: 2.3905
2022-07-16 17:07:36 - train: epoch 0146, iter [00700, 05004], lr: 0.018291, loss: 2.2258
2022-07-16 17:08:11 - train: epoch 0146, iter [00800, 05004], lr: 0.018278, loss: 2.1029
2022-07-16 17:08:45 - train: epoch 0146, iter [00900, 05004], lr: 0.018266, loss: 2.4963
2022-07-16 17:09:19 - train: epoch 0146, iter [01000, 05004], lr: 0.018253, loss: 2.2529
2022-07-16 17:09:52 - train: epoch 0146, iter [01100, 05004], lr: 0.018241, loss: 2.2781
2022-07-16 17:10:27 - train: epoch 0146, iter [01200, 05004], lr: 0.018228, loss: 2.0567
2022-07-16 17:11:01 - train: epoch 0146, iter [01300, 05004], lr: 0.018216, loss: 1.9397
2022-07-16 17:11:36 - train: epoch 0146, iter [01400, 05004], lr: 0.018203, loss: 2.2111
2022-07-16 17:12:09 - train: epoch 0146, iter [01500, 05004], lr: 0.018191, loss: 2.2349
2022-07-16 17:12:44 - train: epoch 0146, iter [01600, 05004], lr: 0.018179, loss: 2.2357
2022-07-16 17:13:18 - train: epoch 0146, iter [01700, 05004], lr: 0.018166, loss: 2.2518
2022-07-16 17:13:53 - train: epoch 0146, iter [01800, 05004], lr: 0.018154, loss: 2.0530
2022-07-16 17:14:26 - train: epoch 0146, iter [01900, 05004], lr: 0.018141, loss: 2.2504
2022-07-16 17:15:01 - train: epoch 0146, iter [02000, 05004], lr: 0.018129, loss: 1.9656
2022-07-16 17:15:35 - train: epoch 0146, iter [02100, 05004], lr: 0.018117, loss: 1.9850
2022-07-16 17:16:09 - train: epoch 0146, iter [02200, 05004], lr: 0.018104, loss: 2.1458
2022-07-16 17:16:44 - train: epoch 0146, iter [02300, 05004], lr: 0.018092, loss: 1.9558
2022-07-16 17:17:18 - train: epoch 0146, iter [02400, 05004], lr: 0.018079, loss: 2.3731
2022-07-16 17:17:52 - train: epoch 0146, iter [02500, 05004], lr: 0.018067, loss: 2.1809
2022-07-16 17:18:27 - train: epoch 0146, iter [02600, 05004], lr: 0.018055, loss: 2.1492
2022-07-16 17:19:01 - train: epoch 0146, iter [02700, 05004], lr: 0.018042, loss: 2.3954
2022-07-16 17:19:35 - train: epoch 0146, iter [02800, 05004], lr: 0.018030, loss: 1.8819
2022-07-16 17:20:09 - train: epoch 0146, iter [02900, 05004], lr: 0.018017, loss: 2.1926
2022-07-16 17:20:43 - train: epoch 0146, iter [03000, 05004], lr: 0.018005, loss: 2.1754
2022-07-16 17:21:18 - train: epoch 0146, iter [03100, 05004], lr: 0.017993, loss: 2.4002
2022-07-16 17:21:52 - train: epoch 0146, iter [03200, 05004], lr: 0.017980, loss: 2.0620
2022-07-16 17:22:27 - train: epoch 0146, iter [03300, 05004], lr: 0.017968, loss: 2.1579
2022-07-16 17:23:01 - train: epoch 0146, iter [03400, 05004], lr: 0.017956, loss: 1.8996
2022-07-16 17:23:35 - train: epoch 0146, iter [03500, 05004], lr: 0.017943, loss: 2.2079
2022-07-16 17:24:09 - train: epoch 0146, iter [03600, 05004], lr: 0.017931, loss: 2.4510
2022-07-16 17:24:43 - train: epoch 0146, iter [03700, 05004], lr: 0.017919, loss: 2.1179
2022-07-16 17:25:17 - train: epoch 0146, iter [03800, 05004], lr: 0.017906, loss: 2.2666
2022-07-16 17:25:52 - train: epoch 0146, iter [03900, 05004], lr: 0.017894, loss: 1.9985
2022-07-16 17:26:27 - train: epoch 0146, iter [04000, 05004], lr: 0.017882, loss: 2.2927
2022-07-16 17:27:00 - train: epoch 0146, iter [04100, 05004], lr: 0.017869, loss: 2.2664
2022-07-16 17:27:35 - train: epoch 0146, iter [04200, 05004], lr: 0.017857, loss: 1.8652
2022-07-16 17:28:09 - train: epoch 0146, iter [04300, 05004], lr: 0.017845, loss: 2.0752
2022-07-16 17:28:44 - train: epoch 0146, iter [04400, 05004], lr: 0.017832, loss: 2.4311
2022-07-16 17:29:17 - train: epoch 0146, iter [04500, 05004], lr: 0.017820, loss: 2.3096
2022-07-16 17:29:51 - train: epoch 0146, iter [04600, 05004], lr: 0.017808, loss: 2.1361
2022-07-16 17:30:26 - train: epoch 0146, iter [04700, 05004], lr: 0.017795, loss: 2.1584
2022-07-16 17:31:02 - train: epoch 0146, iter [04800, 05004], lr: 0.017783, loss: 2.4367
2022-07-16 17:31:35 - train: epoch 0146, iter [04900, 05004], lr: 0.017771, loss: 2.3299
2022-07-16 17:32:09 - train: epoch 0146, iter [05000, 05004], lr: 0.017758, loss: 2.2217
2022-07-16 17:32:10 - train: epoch 146, train_loss: 2.1735
2022-07-16 17:33:24 - eval: epoch: 146, acc1: 70.890%, acc5: 90.326%, test_loss: 1.1672, per_image_load_time: 1.274ms, per_image_inference_time: 0.463ms
2022-07-16 17:33:24 - until epoch: 146, best_acc1: 70.890%
2022-07-16 17:33:24 - epoch 147 lr: 0.017758
2022-07-16 17:34:04 - train: epoch 0147, iter [00100, 05004], lr: 0.017746, loss: 2.0828
2022-07-16 17:34:38 - train: epoch 0147, iter [00200, 05004], lr: 0.017733, loss: 1.9260
2022-07-16 17:35:13 - train: epoch 0147, iter [00300, 05004], lr: 0.017721, loss: 2.3506
2022-07-16 17:35:47 - train: epoch 0147, iter [00400, 05004], lr: 0.017709, loss: 2.1656
2022-07-16 17:36:21 - train: epoch 0147, iter [00500, 05004], lr: 0.017696, loss: 2.2273
2022-07-16 17:36:55 - train: epoch 0147, iter [00600, 05004], lr: 0.017684, loss: 2.3593
2022-07-16 17:37:29 - train: epoch 0147, iter [00700, 05004], lr: 0.017672, loss: 2.0027
2022-07-16 17:38:04 - train: epoch 0147, iter [00800, 05004], lr: 0.017660, loss: 2.1982
2022-07-16 17:38:38 - train: epoch 0147, iter [00900, 05004], lr: 0.017647, loss: 1.9644
2022-07-16 17:39:12 - train: epoch 0147, iter [01000, 05004], lr: 0.017635, loss: 2.0340
2022-07-16 17:39:47 - train: epoch 0147, iter [01100, 05004], lr: 0.017623, loss: 2.3718
2022-07-16 17:40:21 - train: epoch 0147, iter [01200, 05004], lr: 0.017610, loss: 2.2107
2022-07-16 17:40:55 - train: epoch 0147, iter [01300, 05004], lr: 0.017598, loss: 2.3558
2022-07-16 17:41:28 - train: epoch 0147, iter [01400, 05004], lr: 0.017586, loss: 2.4009
2022-07-16 17:42:02 - train: epoch 0147, iter [01500, 05004], lr: 0.017574, loss: 2.3263
2022-07-16 17:42:36 - train: epoch 0147, iter [01600, 05004], lr: 0.017561, loss: 2.1868
2022-07-16 17:43:10 - train: epoch 0147, iter [01700, 05004], lr: 0.017549, loss: 2.0090
2022-07-16 17:43:45 - train: epoch 0147, iter [01800, 05004], lr: 0.017537, loss: 2.3650
2022-07-16 17:44:20 - train: epoch 0147, iter [01900, 05004], lr: 0.017525, loss: 2.1323
2022-07-16 17:44:54 - train: epoch 0147, iter [02000, 05004], lr: 0.017512, loss: 2.0981
2022-07-16 17:45:28 - train: epoch 0147, iter [02100, 05004], lr: 0.017500, loss: 2.0167
2022-07-16 17:46:02 - train: epoch 0147, iter [02200, 05004], lr: 0.017488, loss: 2.2858
2022-07-16 17:46:37 - train: epoch 0147, iter [02300, 05004], lr: 0.017476, loss: 2.1788
2022-07-16 17:47:11 - train: epoch 0147, iter [02400, 05004], lr: 0.017464, loss: 2.2822
2022-07-16 17:47:46 - train: epoch 0147, iter [02500, 05004], lr: 0.017451, loss: 2.6428
2022-07-16 17:48:20 - train: epoch 0147, iter [02600, 05004], lr: 0.017439, loss: 2.1850
2022-07-16 17:48:55 - train: epoch 0147, iter [02700, 05004], lr: 0.017427, loss: 1.9878
2022-07-16 17:49:29 - train: epoch 0147, iter [02800, 05004], lr: 0.017415, loss: 2.2495
2022-07-16 17:50:05 - train: epoch 0147, iter [02900, 05004], lr: 0.017402, loss: 2.1672
2022-07-16 17:50:38 - train: epoch 0147, iter [03000, 05004], lr: 0.017390, loss: 2.0361
2022-07-16 17:51:12 - train: epoch 0147, iter [03100, 05004], lr: 0.017378, loss: 2.3654
2022-07-16 17:51:46 - train: epoch 0147, iter [03200, 05004], lr: 0.017366, loss: 2.3661
2022-07-16 17:52:21 - train: epoch 0147, iter [03300, 05004], lr: 0.017354, loss: 2.2939
2022-07-16 17:52:56 - train: epoch 0147, iter [03400, 05004], lr: 0.017341, loss: 2.3055
2022-07-16 17:53:31 - train: epoch 0147, iter [03500, 05004], lr: 0.017329, loss: 1.8995
2022-07-16 17:54:06 - train: epoch 0147, iter [03600, 05004], lr: 0.017317, loss: 2.0434
2022-07-16 17:54:41 - train: epoch 0147, iter [03700, 05004], lr: 0.017305, loss: 2.2868
2022-07-16 17:55:15 - train: epoch 0147, iter [03800, 05004], lr: 0.017293, loss: 2.2346
2022-07-16 17:55:49 - train: epoch 0147, iter [03900, 05004], lr: 0.017281, loss: 2.2289
2022-07-16 17:56:24 - train: epoch 0147, iter [04000, 05004], lr: 0.017268, loss: 2.3502
2022-07-16 17:56:57 - train: epoch 0147, iter [04100, 05004], lr: 0.017256, loss: 2.4887
2022-07-16 17:57:31 - train: epoch 0147, iter [04200, 05004], lr: 0.017244, loss: 2.2765
2022-07-16 17:58:06 - train: epoch 0147, iter [04300, 05004], lr: 0.017232, loss: 2.0897
2022-07-16 17:58:41 - train: epoch 0147, iter [04400, 05004], lr: 0.017220, loss: 2.0459
2022-07-16 17:59:15 - train: epoch 0147, iter [04500, 05004], lr: 0.017208, loss: 2.0857
2022-07-16 17:59:50 - train: epoch 0147, iter [04600, 05004], lr: 0.017195, loss: 2.3924
2022-07-16 18:00:24 - train: epoch 0147, iter [04700, 05004], lr: 0.017183, loss: 2.4571
2022-07-16 18:00:59 - train: epoch 0147, iter [04800, 05004], lr: 0.017171, loss: 2.2614
2022-07-16 18:01:33 - train: epoch 0147, iter [04900, 05004], lr: 0.017159, loss: 2.0641
2022-07-16 18:02:06 - train: epoch 0147, iter [05000, 05004], lr: 0.017147, loss: 2.0213
2022-07-16 18:02:07 - train: epoch 147, train_loss: 2.1581
2022-07-16 18:03:21 - eval: epoch: 147, acc1: 70.222%, acc5: 90.042%, test_loss: 1.1893, per_image_load_time: 2.421ms, per_image_inference_time: 0.443ms
2022-07-16 18:03:21 - until epoch: 147, best_acc1: 70.890%
2022-07-16 18:03:21 - epoch 148 lr: 0.017146
2022-07-16 18:04:01 - train: epoch 0148, iter [00100, 05004], lr: 0.017134, loss: 2.4453
2022-07-16 18:04:35 - train: epoch 0148, iter [00200, 05004], lr: 0.017122, loss: 2.3577
2022-07-16 18:05:09 - train: epoch 0148, iter [00300, 05004], lr: 0.017110, loss: 1.8739
2022-07-16 18:05:43 - train: epoch 0148, iter [00400, 05004], lr: 0.017098, loss: 1.9695
2022-07-16 18:06:17 - train: epoch 0148, iter [00500, 05004], lr: 0.017086, loss: 1.9878
2022-07-16 18:06:52 - train: epoch 0148, iter [00600, 05004], lr: 0.017074, loss: 1.8855
2022-07-16 18:07:26 - train: epoch 0148, iter [00700, 05004], lr: 0.017062, loss: 2.1925
2022-07-16 18:08:01 - train: epoch 0148, iter [00800, 05004], lr: 0.017049, loss: 2.3372
2022-07-16 18:08:35 - train: epoch 0148, iter [00900, 05004], lr: 0.017037, loss: 2.0186
2022-07-16 18:09:09 - train: epoch 0148, iter [01000, 05004], lr: 0.017025, loss: 2.3493
2022-07-16 18:09:44 - train: epoch 0148, iter [01100, 05004], lr: 0.017013, loss: 1.9188
2022-07-16 18:10:18 - train: epoch 0148, iter [01200, 05004], lr: 0.017001, loss: 1.8739
2022-07-16 18:10:52 - train: epoch 0148, iter [01300, 05004], lr: 0.016989, loss: 2.2627
2022-07-16 18:11:27 - train: epoch 0148, iter [01400, 05004], lr: 0.016977, loss: 2.1221
2022-07-16 18:12:01 - train: epoch 0148, iter [01500, 05004], lr: 0.016965, loss: 2.0372
2022-07-16 18:12:35 - train: epoch 0148, iter [01600, 05004], lr: 0.016953, loss: 1.9732
2022-07-16 18:13:10 - train: epoch 0148, iter [01700, 05004], lr: 0.016941, loss: 2.0864
2022-07-16 18:13:44 - train: epoch 0148, iter [01800, 05004], lr: 0.016929, loss: 2.0942
2022-07-16 18:14:19 - train: epoch 0148, iter [01900, 05004], lr: 0.016916, loss: 2.3156
2022-07-16 18:14:53 - train: epoch 0148, iter [02000, 05004], lr: 0.016904, loss: 2.0256
2022-07-16 18:15:27 - train: epoch 0148, iter [02100, 05004], lr: 0.016892, loss: 1.8857
2022-07-16 18:16:01 - train: epoch 0148, iter [02200, 05004], lr: 0.016880, loss: 1.9109
2022-07-16 18:16:36 - train: epoch 0148, iter [02300, 05004], lr: 0.016868, loss: 2.4414
2022-07-16 18:17:10 - train: epoch 0148, iter [02400, 05004], lr: 0.016856, loss: 1.9004
2022-07-16 18:17:45 - train: epoch 0148, iter [02500, 05004], lr: 0.016844, loss: 2.0376
2022-07-16 18:18:19 - train: epoch 0148, iter [02600, 05004], lr: 0.016832, loss: 2.1787
2022-07-16 18:18:54 - train: epoch 0148, iter [02700, 05004], lr: 0.016820, loss: 1.9950
2022-07-16 18:19:27 - train: epoch 0148, iter [02800, 05004], lr: 0.016808, loss: 2.2731
2022-07-16 18:20:02 - train: epoch 0148, iter [02900, 05004], lr: 0.016796, loss: 2.4319
2022-07-16 18:20:37 - train: epoch 0148, iter [03000, 05004], lr: 0.016784, loss: 2.2149
2022-07-16 18:21:11 - train: epoch 0148, iter [03100, 05004], lr: 0.016772, loss: 2.1504
2022-07-16 18:21:45 - train: epoch 0148, iter [03200, 05004], lr: 0.016760, loss: 1.8163
2022-07-16 18:22:19 - train: epoch 0148, iter [03300, 05004], lr: 0.016748, loss: 2.2435
2022-07-16 18:22:53 - train: epoch 0148, iter [03400, 05004], lr: 0.016736, loss: 2.2190
2022-07-16 18:23:28 - train: epoch 0148, iter [03500, 05004], lr: 0.016724, loss: 2.0223
2022-07-16 18:24:02 - train: epoch 0148, iter [03600, 05004], lr: 0.016712, loss: 2.1538
2022-07-16 18:24:36 - train: epoch 0148, iter [03700, 05004], lr: 0.016700, loss: 2.4042
2022-07-16 18:25:10 - train: epoch 0148, iter [03800, 05004], lr: 0.016688, loss: 2.2036
2022-07-16 18:25:45 - train: epoch 0148, iter [03900, 05004], lr: 0.016676, loss: 2.3522
2022-07-16 18:26:20 - train: epoch 0148, iter [04000, 05004], lr: 0.016664, loss: 2.3379
2022-07-16 18:26:53 - train: epoch 0148, iter [04100, 05004], lr: 0.016652, loss: 2.1283
2022-07-16 18:27:28 - train: epoch 0148, iter [04200, 05004], lr: 0.016640, loss: 2.0203
2022-07-16 18:28:02 - train: epoch 0148, iter [04300, 05004], lr: 0.016628, loss: 2.0311
2022-07-16 18:28:37 - train: epoch 0148, iter [04400, 05004], lr: 0.016616, loss: 1.9030
2022-07-16 18:29:10 - train: epoch 0148, iter [04500, 05004], lr: 0.016604, loss: 2.2672
2022-07-16 18:29:44 - train: epoch 0148, iter [04600, 05004], lr: 0.016592, loss: 2.1059
2022-07-16 18:30:18 - train: epoch 0148, iter [04700, 05004], lr: 0.016580, loss: 2.2293
2022-07-16 18:30:53 - train: epoch 0148, iter [04800, 05004], lr: 0.016568, loss: 2.1854
2022-07-16 18:31:27 - train: epoch 0148, iter [04900, 05004], lr: 0.016556, loss: 2.4195
2022-07-16 18:32:00 - train: epoch 0148, iter [05000, 05004], lr: 0.016544, loss: 2.3199
2022-07-16 18:32:01 - train: epoch 148, train_loss: 2.1493
2022-07-16 18:33:16 - eval: epoch: 148, acc1: 70.176%, acc5: 89.882%, test_loss: 1.2035, per_image_load_time: 2.425ms, per_image_inference_time: 0.471ms
2022-07-16 18:33:16 - until epoch: 148, best_acc1: 70.890%
2022-07-16 18:40:01 - epoch 149 lr: 0.016543
2022-07-16 18:40:43 - train: epoch 0149, iter [00100, 05004], lr: 0.016532, loss: 2.1225
2022-07-16 18:41:17 - train: epoch 0149, iter [00200, 05004], lr: 0.016520, loss: 1.8821
2022-07-16 18:41:53 - train: epoch 0149, iter [00300, 05004], lr: 0.016508, loss: 2.1153
2022-07-16 18:42:28 - train: epoch 0149, iter [00400, 05004], lr: 0.016496, loss: 1.5805
2022-07-16 18:43:03 - train: epoch 0149, iter [00500, 05004], lr: 0.016484, loss: 2.1353
2022-07-16 18:43:38 - train: epoch 0149, iter [00600, 05004], lr: 0.016472, loss: 2.0469
2022-07-16 18:44:12 - train: epoch 0149, iter [00700, 05004], lr: 0.016460, loss: 2.3497
2022-07-16 18:44:46 - train: epoch 0149, iter [00800, 05004], lr: 0.016448, loss: 1.7884
2022-07-16 18:45:21 - train: epoch 0149, iter [00900, 05004], lr: 0.016436, loss: 2.2915
2022-07-16 18:45:54 - train: epoch 0149, iter [01000, 05004], lr: 0.016424, loss: 2.1239
2022-07-16 18:46:29 - train: epoch 0149, iter [01100, 05004], lr: 0.016412, loss: 1.8915
2022-07-16 18:47:02 - train: epoch 0149, iter [01200, 05004], lr: 0.016400, loss: 1.9233
2022-07-16 18:47:36 - train: epoch 0149, iter [01300, 05004], lr: 0.016388, loss: 2.3906
2022-07-16 18:48:09 - train: epoch 0149, iter [01400, 05004], lr: 0.016376, loss: 2.2376
2022-07-16 18:48:43 - train: epoch 0149, iter [01500, 05004], lr: 0.016364, loss: 1.9859
2022-07-16 18:49:18 - train: epoch 0149, iter [01600, 05004], lr: 0.016353, loss: 2.3754
2022-07-16 18:49:51 - train: epoch 0149, iter [01700, 05004], lr: 0.016341, loss: 2.1746
2022-07-16 18:50:24 - train: epoch 0149, iter [01800, 05004], lr: 0.016329, loss: 2.0793
2022-07-16 18:50:58 - train: epoch 0149, iter [01900, 05004], lr: 0.016317, loss: 1.8786
2022-07-16 18:51:32 - train: epoch 0149, iter [02000, 05004], lr: 0.016305, loss: 2.1028
2022-07-16 18:52:06 - train: epoch 0149, iter [02100, 05004], lr: 0.016293, loss: 1.9823
2022-07-16 18:52:39 - train: epoch 0149, iter [02200, 05004], lr: 0.016281, loss: 1.9467
2022-07-16 18:53:13 - train: epoch 0149, iter [02300, 05004], lr: 0.016269, loss: 1.9814
2022-07-16 18:53:47 - train: epoch 0149, iter [02400, 05004], lr: 0.016257, loss: 2.0813
2022-07-16 18:54:20 - train: epoch 0149, iter [02500, 05004], lr: 0.016245, loss: 2.3734
2022-07-16 18:54:54 - train: epoch 0149, iter [02600, 05004], lr: 0.016234, loss: 2.1964
2022-07-16 18:55:27 - train: epoch 0149, iter [02700, 05004], lr: 0.016222, loss: 2.2734
2022-07-16 18:56:01 - train: epoch 0149, iter [02800, 05004], lr: 0.016210, loss: 1.9474
2022-07-16 18:56:34 - train: epoch 0149, iter [02900, 05004], lr: 0.016198, loss: 1.9242
2022-07-16 18:57:08 - train: epoch 0149, iter [03000, 05004], lr: 0.016186, loss: 2.1280
2022-07-16 18:57:42 - train: epoch 0149, iter [03100, 05004], lr: 0.016174, loss: 2.0906
2022-07-16 18:58:16 - train: epoch 0149, iter [03200, 05004], lr: 0.016162, loss: 2.3471
2022-07-16 18:58:49 - train: epoch 0149, iter [03300, 05004], lr: 0.016151, loss: 2.2901
2022-07-16 18:59:23 - train: epoch 0149, iter [03400, 05004], lr: 0.016139, loss: 2.0929
2022-07-16 18:59:56 - train: epoch 0149, iter [03500, 05004], lr: 0.016127, loss: 2.5217
2022-07-16 19:00:30 - train: epoch 0149, iter [03600, 05004], lr: 0.016115, loss: 1.7246
2022-07-16 19:01:04 - train: epoch 0149, iter [03700, 05004], lr: 0.016103, loss: 2.0353
2022-07-16 19:01:38 - train: epoch 0149, iter [03800, 05004], lr: 0.016091, loss: 1.9507
2022-07-16 19:02:12 - train: epoch 0149, iter [03900, 05004], lr: 0.016080, loss: 2.3121
2022-07-16 19:02:46 - train: epoch 0149, iter [04000, 05004], lr: 0.016068, loss: 2.1341
2022-07-16 19:03:19 - train: epoch 0149, iter [04100, 05004], lr: 0.016056, loss: 1.9989
2022-07-16 19:03:53 - train: epoch 0149, iter [04200, 05004], lr: 0.016044, loss: 1.7632
2022-07-16 19:04:26 - train: epoch 0149, iter [04300, 05004], lr: 0.016032, loss: 2.0730
2022-07-16 19:05:01 - train: epoch 0149, iter [04400, 05004], lr: 0.016020, loss: 2.5428
2022-07-16 19:05:35 - train: epoch 0149, iter [04500, 05004], lr: 0.016009, loss: 1.7413
2022-07-16 19:06:09 - train: epoch 0149, iter [04600, 05004], lr: 0.015997, loss: 2.0594
2022-07-16 19:06:43 - train: epoch 0149, iter [04700, 05004], lr: 0.015985, loss: 2.2830
2022-07-16 19:07:16 - train: epoch 0149, iter [04800, 05004], lr: 0.015973, loss: 2.3167
2022-07-16 19:07:50 - train: epoch 0149, iter [04900, 05004], lr: 0.015961, loss: 2.0308
2022-07-16 19:08:22 - train: epoch 0149, iter [05000, 05004], lr: 0.015950, loss: 2.3583
2022-07-16 19:08:23 - train: epoch 149, train_loss: 2.1375
2022-07-16 19:09:37 - eval: epoch: 149, acc1: 70.742%, acc5: 90.276%, test_loss: 1.1708, per_image_load_time: 1.424ms, per_image_inference_time: 0.448ms
2022-07-16 19:09:38 - until epoch: 149, best_acc1: 70.890%
2022-07-16 19:09:38 - epoch 150 lr: 0.015949
2022-07-16 19:10:16 - train: epoch 0150, iter [00100, 05004], lr: 0.015937, loss: 1.9232
2022-07-16 19:10:50 - train: epoch 0150, iter [00200, 05004], lr: 0.015926, loss: 2.2388
2022-07-16 19:11:24 - train: epoch 0150, iter [00300, 05004], lr: 0.015914, loss: 1.6592
2022-07-16 19:11:58 - train: epoch 0150, iter [00400, 05004], lr: 0.015902, loss: 2.0022
2022-07-16 19:12:33 - train: epoch 0150, iter [00500, 05004], lr: 0.015890, loss: 2.1412
2022-07-16 19:13:06 - train: epoch 0150, iter [00600, 05004], lr: 0.015879, loss: 2.0720
2022-07-16 19:13:41 - train: epoch 0150, iter [00700, 05004], lr: 0.015867, loss: 1.8843
2022-07-16 19:14:14 - train: epoch 0150, iter [00800, 05004], lr: 0.015855, loss: 2.2250
2022-07-16 19:14:49 - train: epoch 0150, iter [00900, 05004], lr: 0.015843, loss: 2.1897
2022-07-16 19:15:23 - train: epoch 0150, iter [01000, 05004], lr: 0.015832, loss: 2.1189
2022-07-16 19:15:58 - train: epoch 0150, iter [01100, 05004], lr: 0.015820, loss: 2.2590
2022-07-16 19:16:31 - train: epoch 0150, iter [01200, 05004], lr: 0.015808, loss: 2.0382
2022-07-16 19:17:06 - train: epoch 0150, iter [01300, 05004], lr: 0.015796, loss: 2.4629
2022-07-16 19:17:40 - train: epoch 0150, iter [01400, 05004], lr: 0.015785, loss: 2.0032
2022-07-16 19:18:14 - train: epoch 0150, iter [01500, 05004], lr: 0.015773, loss: 2.3805
2022-07-16 19:18:49 - train: epoch 0150, iter [01600, 05004], lr: 0.015761, loss: 1.7752
2022-07-16 19:19:22 - train: epoch 0150, iter [01700, 05004], lr: 0.015749, loss: 2.3153
2022-07-16 19:19:56 - train: epoch 0150, iter [01800, 05004], lr: 0.015738, loss: 2.1275
2022-07-16 19:20:30 - train: epoch 0150, iter [01900, 05004], lr: 0.015726, loss: 1.9117
2022-07-16 19:21:04 - train: epoch 0150, iter [02000, 05004], lr: 0.015714, loss: 2.1111
2022-07-16 19:21:39 - train: epoch 0150, iter [02100, 05004], lr: 0.015702, loss: 1.7750
2022-07-16 19:22:13 - train: epoch 0150, iter [02200, 05004], lr: 0.015691, loss: 2.1776
2022-07-16 19:22:47 - train: epoch 0150, iter [02300, 05004], lr: 0.015679, loss: 2.3617
2022-07-16 19:23:22 - train: epoch 0150, iter [02400, 05004], lr: 0.015667, loss: 1.8352
2022-07-16 19:23:56 - train: epoch 0150, iter [02500, 05004], lr: 0.015656, loss: 2.0714
2022-07-16 19:24:29 - train: epoch 0150, iter [02600, 05004], lr: 0.015644, loss: 2.1239
2022-07-16 19:25:03 - train: epoch 0150, iter [02700, 05004], lr: 0.015632, loss: 1.7505
2022-07-16 19:25:37 - train: epoch 0150, iter [02800, 05004], lr: 0.015621, loss: 2.2865
2022-07-16 19:26:11 - train: epoch 0150, iter [02900, 05004], lr: 0.015609, loss: 2.2761
2022-07-16 19:26:45 - train: epoch 0150, iter [03000, 05004], lr: 0.015597, loss: 1.8663
2022-07-16 19:27:20 - train: epoch 0150, iter [03100, 05004], lr: 0.015585, loss: 2.1425
2022-07-16 19:27:54 - train: epoch 0150, iter [03200, 05004], lr: 0.015574, loss: 2.3396
2022-07-16 19:28:29 - train: epoch 0150, iter [03300, 05004], lr: 0.015562, loss: 2.3168
2022-07-16 19:29:04 - train: epoch 0150, iter [03400, 05004], lr: 0.015550, loss: 2.1104
2022-07-16 19:29:37 - train: epoch 0150, iter [03500, 05004], lr: 0.015539, loss: 2.2233
2022-07-16 19:30:11 - train: epoch 0150, iter [03600, 05004], lr: 0.015527, loss: 2.3579
2022-07-16 19:30:46 - train: epoch 0150, iter [03700, 05004], lr: 0.015515, loss: 2.0611
2022-07-16 19:31:20 - train: epoch 0150, iter [03800, 05004], lr: 0.015504, loss: 1.9685
2022-07-16 19:31:54 - train: epoch 0150, iter [03900, 05004], lr: 0.015492, loss: 1.9914
2022-07-16 19:32:28 - train: epoch 0150, iter [04000, 05004], lr: 0.015481, loss: 1.8777
2022-07-16 19:33:03 - train: epoch 0150, iter [04100, 05004], lr: 0.015469, loss: 1.9175
2022-07-16 19:33:36 - train: epoch 0150, iter [04200, 05004], lr: 0.015457, loss: 2.1642
2022-07-16 19:34:11 - train: epoch 0150, iter [04300, 05004], lr: 0.015446, loss: 2.1236
2022-07-16 19:34:44 - train: epoch 0150, iter [04400, 05004], lr: 0.015434, loss: 2.3096
2022-07-16 19:35:18 - train: epoch 0150, iter [04500, 05004], lr: 0.015422, loss: 1.9577
2022-07-16 19:35:52 - train: epoch 0150, iter [04600, 05004], lr: 0.015411, loss: 2.1428
2022-07-16 19:36:26 - train: epoch 0150, iter [04700, 05004], lr: 0.015399, loss: 2.0234
2022-07-16 19:37:00 - train: epoch 0150, iter [04800, 05004], lr: 0.015387, loss: 2.1708
2022-07-16 19:37:34 - train: epoch 0150, iter [04900, 05004], lr: 0.015376, loss: 2.1327
2022-07-16 19:38:06 - train: epoch 0150, iter [05000, 05004], lr: 0.015364, loss: 2.3316
2022-07-16 19:38:08 - train: epoch 150, train_loss: 2.1318
2022-07-16 19:39:22 - eval: epoch: 150, acc1: 70.976%, acc5: 90.434%, test_loss: 1.1672, per_image_load_time: 2.407ms, per_image_inference_time: 0.449ms
2022-07-16 19:39:22 - until epoch: 150, best_acc1: 70.976%
2022-07-16 19:39:22 - epoch 151 lr: 0.015364
2022-07-16 19:40:01 - train: epoch 0151, iter [00100, 05004], lr: 0.015352, loss: 2.1870
2022-07-16 19:40:36 - train: epoch 0151, iter [00200, 05004], lr: 0.015341, loss: 1.9725
2022-07-16 19:41:10 - train: epoch 0151, iter [00300, 05004], lr: 0.015329, loss: 2.1855
2022-07-16 19:41:45 - train: epoch 0151, iter [00400, 05004], lr: 0.015317, loss: 1.8691
2022-07-16 19:42:19 - train: epoch 0151, iter [00500, 05004], lr: 0.015306, loss: 2.0886
2022-07-16 19:42:53 - train: epoch 0151, iter [00600, 05004], lr: 0.015294, loss: 1.9801
2022-07-16 19:43:29 - train: epoch 0151, iter [00700, 05004], lr: 0.015283, loss: 2.1969
2022-07-16 19:44:02 - train: epoch 0151, iter [00800, 05004], lr: 0.015271, loss: 2.0807
2022-07-16 19:44:36 - train: epoch 0151, iter [00900, 05004], lr: 0.015259, loss: 2.1481
2022-07-16 19:45:11 - train: epoch 0151, iter [01000, 05004], lr: 0.015248, loss: 2.0082
2022-07-16 19:45:45 - train: epoch 0151, iter [01100, 05004], lr: 0.015236, loss: 1.9314
2022-07-16 19:46:20 - train: epoch 0151, iter [01200, 05004], lr: 0.015225, loss: 2.2566
2022-07-16 19:46:54 - train: epoch 0151, iter [01300, 05004], lr: 0.015213, loss: 1.9041
2022-07-16 19:47:29 - train: epoch 0151, iter [01400, 05004], lr: 0.015202, loss: 2.0902
2022-07-16 19:48:03 - train: epoch 0151, iter [01500, 05004], lr: 0.015190, loss: 2.1876
2022-07-16 19:48:37 - train: epoch 0151, iter [01600, 05004], lr: 0.015178, loss: 1.9723
2022-07-16 19:49:11 - train: epoch 0151, iter [01700, 05004], lr: 0.015167, loss: 2.2079
2022-07-16 19:49:46 - train: epoch 0151, iter [01800, 05004], lr: 0.015155, loss: 2.2543
2022-07-16 19:50:20 - train: epoch 0151, iter [01900, 05004], lr: 0.015144, loss: 2.3287
2022-07-16 19:50:54 - train: epoch 0151, iter [02000, 05004], lr: 0.015132, loss: 2.4880
2022-07-16 19:51:28 - train: epoch 0151, iter [02100, 05004], lr: 0.015121, loss: 1.7756
2022-07-16 19:52:02 - train: epoch 0151, iter [02200, 05004], lr: 0.015109, loss: 2.1689
2022-07-16 19:52:37 - train: epoch 0151, iter [02300, 05004], lr: 0.015098, loss: 2.1623
2022-07-16 19:53:11 - train: epoch 0151, iter [02400, 05004], lr: 0.015086, loss: 1.9210
2022-07-16 19:53:47 - train: epoch 0151, iter [02500, 05004], lr: 0.015075, loss: 2.1222
2022-07-16 19:54:21 - train: epoch 0151, iter [02600, 05004], lr: 0.015063, loss: 2.3460
2022-07-16 19:54:54 - train: epoch 0151, iter [02700, 05004], lr: 0.015052, loss: 1.9559
2022-07-16 19:55:29 - train: epoch 0151, iter [02800, 05004], lr: 0.015040, loss: 2.1443
2022-07-16 19:56:03 - train: epoch 0151, iter [02900, 05004], lr: 0.015029, loss: 2.2032
2022-07-16 19:56:37 - train: epoch 0151, iter [03000, 05004], lr: 0.015017, loss: 2.0691
2022-07-16 19:57:12 - train: epoch 0151, iter [03100, 05004], lr: 0.015006, loss: 2.0848
2022-07-16 19:57:46 - train: epoch 0151, iter [03200, 05004], lr: 0.014994, loss: 2.0198
2022-07-16 19:58:20 - train: epoch 0151, iter [03300, 05004], lr: 0.014983, loss: 2.0426
2022-07-16 19:58:55 - train: epoch 0151, iter [03400, 05004], lr: 0.014971, loss: 2.1832
2022-07-16 19:59:30 - train: epoch 0151, iter [03500, 05004], lr: 0.014960, loss: 2.1703
2022-07-16 20:00:04 - train: epoch 0151, iter [03600, 05004], lr: 0.014948, loss: 2.0912
2022-07-16 20:00:39 - train: epoch 0151, iter [03700, 05004], lr: 0.014937, loss: 2.0208
2022-07-16 20:01:12 - train: epoch 0151, iter [03800, 05004], lr: 0.014925, loss: 2.3246
2022-07-16 20:01:47 - train: epoch 0151, iter [03900, 05004], lr: 0.014914, loss: 2.2411
2022-07-16 20:02:21 - train: epoch 0151, iter [04000, 05004], lr: 0.014902, loss: 2.1052
2022-07-16 20:02:56 - train: epoch 0151, iter [04100, 05004], lr: 0.014891, loss: 2.2772
2022-07-16 20:03:30 - train: epoch 0151, iter [04200, 05004], lr: 0.014879, loss: 2.0846
2022-07-16 20:04:04 - train: epoch 0151, iter [04300, 05004], lr: 0.014868, loss: 2.4600
2022-07-16 20:04:39 - train: epoch 0151, iter [04400, 05004], lr: 0.014856, loss: 1.9566
2022-07-16 20:05:13 - train: epoch 0151, iter [04500, 05004], lr: 0.014845, loss: 1.8744
2022-07-16 20:05:48 - train: epoch 0151, iter [04600, 05004], lr: 0.014834, loss: 1.8444
2022-07-16 20:06:23 - train: epoch 0151, iter [04700, 05004], lr: 0.014822, loss: 1.8761
2022-07-16 20:06:57 - train: epoch 0151, iter [04800, 05004], lr: 0.014811, loss: 2.0513
2022-07-16 20:07:31 - train: epoch 0151, iter [04900, 05004], lr: 0.014799, loss: 1.8464
2022-07-16 20:08:05 - train: epoch 0151, iter [05000, 05004], lr: 0.014788, loss: 1.9929
2022-07-16 20:08:06 - train: epoch 151, train_loss: 2.1164
2022-07-16 20:09:20 - eval: epoch: 151, acc1: 71.282%, acc5: 90.424%, test_loss: 1.1603, per_image_load_time: 2.435ms, per_image_inference_time: 0.449ms
2022-07-16 20:09:21 - until epoch: 151, best_acc1: 71.282%
2022-07-16 20:09:21 - epoch 152 lr: 0.014787
2022-07-16 20:10:00 - train: epoch 0152, iter [00100, 05004], lr: 0.014776, loss: 2.2442
2022-07-16 20:10:35 - train: epoch 0152, iter [00200, 05004], lr: 0.014764, loss: 2.0452
2022-07-16 20:11:08 - train: epoch 0152, iter [00300, 05004], lr: 0.014753, loss: 2.4037
2022-07-16 20:11:43 - train: epoch 0152, iter [00400, 05004], lr: 0.014742, loss: 2.0123
2022-07-16 20:12:17 - train: epoch 0152, iter [00500, 05004], lr: 0.014730, loss: 2.1107
2022-07-16 20:12:52 - train: epoch 0152, iter [00600, 05004], lr: 0.014719, loss: 2.1900
2022-07-16 20:13:26 - train: epoch 0152, iter [00700, 05004], lr: 0.014707, loss: 1.7863
2022-07-16 20:14:00 - train: epoch 0152, iter [00800, 05004], lr: 0.014696, loss: 2.0398
2022-07-16 20:14:35 - train: epoch 0152, iter [00900, 05004], lr: 0.014685, loss: 2.3584
2022-07-16 20:15:08 - train: epoch 0152, iter [01000, 05004], lr: 0.014673, loss: 1.9172
2022-07-16 20:15:43 - train: epoch 0152, iter [01100, 05004], lr: 0.014662, loss: 1.8322
2022-07-16 20:16:16 - train: epoch 0152, iter [01200, 05004], lr: 0.014650, loss: 2.1954
2022-07-16 20:16:51 - train: epoch 0152, iter [01300, 05004], lr: 0.014639, loss: 1.9870
2022-07-16 20:17:25 - train: epoch 0152, iter [01400, 05004], lr: 0.014628, loss: 2.1477
2022-07-16 20:17:59 - train: epoch 0152, iter [01500, 05004], lr: 0.014616, loss: 1.9962
2022-07-16 20:18:33 - train: epoch 0152, iter [01600, 05004], lr: 0.014605, loss: 2.1246
2022-07-16 20:19:08 - train: epoch 0152, iter [01700, 05004], lr: 0.014594, loss: 1.9483
2022-07-16 20:19:42 - train: epoch 0152, iter [01800, 05004], lr: 0.014582, loss: 1.9008
2022-07-16 20:20:16 - train: epoch 0152, iter [01900, 05004], lr: 0.014571, loss: 2.0083
2022-07-16 20:20:50 - train: epoch 0152, iter [02000, 05004], lr: 0.014560, loss: 2.3037
2022-07-16 20:21:24 - train: epoch 0152, iter [02100, 05004], lr: 0.014548, loss: 2.0745
2022-07-16 20:21:58 - train: epoch 0152, iter [02200, 05004], lr: 0.014537, loss: 2.4007
2022-07-16 20:22:32 - train: epoch 0152, iter [02300, 05004], lr: 0.014525, loss: 2.1213
2022-07-16 20:23:07 - train: epoch 0152, iter [02400, 05004], lr: 0.014514, loss: 2.0645
2022-07-16 20:23:41 - train: epoch 0152, iter [02500, 05004], lr: 0.014503, loss: 2.2504
2022-07-16 20:24:15 - train: epoch 0152, iter [02600, 05004], lr: 0.014491, loss: 2.2197
2022-07-16 20:24:50 - train: epoch 0152, iter [02700, 05004], lr: 0.014480, loss: 2.1915
2022-07-16 20:25:24 - train: epoch 0152, iter [02800, 05004], lr: 0.014469, loss: 1.9555
2022-07-16 20:25:58 - train: epoch 0152, iter [02900, 05004], lr: 0.014457, loss: 2.3933
2022-07-16 20:26:33 - train: epoch 0152, iter [03000, 05004], lr: 0.014446, loss: 2.0686
2022-07-16 20:27:06 - train: epoch 0152, iter [03100, 05004], lr: 0.014435, loss: 2.2432
2022-07-16 20:27:41 - train: epoch 0152, iter [03200, 05004], lr: 0.014424, loss: 1.8771
2022-07-16 20:28:15 - train: epoch 0152, iter [03300, 05004], lr: 0.014412, loss: 2.1137
2022-07-16 20:28:51 - train: epoch 0152, iter [03400, 05004], lr: 0.014401, loss: 2.3789
2022-07-16 20:29:24 - train: epoch 0152, iter [03500, 05004], lr: 0.014390, loss: 2.0459
2022-07-16 20:29:59 - train: epoch 0152, iter [03600, 05004], lr: 0.014378, loss: 2.0509
2022-07-16 20:30:33 - train: epoch 0152, iter [03700, 05004], lr: 0.014367, loss: 1.7278
2022-07-16 20:31:07 - train: epoch 0152, iter [03800, 05004], lr: 0.014356, loss: 2.4491
2022-07-16 20:31:43 - train: epoch 0152, iter [03900, 05004], lr: 0.014344, loss: 2.3563
2022-07-16 20:32:17 - train: epoch 0152, iter [04000, 05004], lr: 0.014333, loss: 1.7332
2022-07-16 20:32:50 - train: epoch 0152, iter [04100, 05004], lr: 0.014322, loss: 2.0832
2022-07-16 20:33:25 - train: epoch 0152, iter [04200, 05004], lr: 0.014311, loss: 2.1556
2022-07-16 20:34:00 - train: epoch 0152, iter [04300, 05004], lr: 0.014299, loss: 1.9995
2022-07-16 20:34:35 - train: epoch 0152, iter [04400, 05004], lr: 0.014288, loss: 1.9659
2022-07-16 20:35:10 - train: epoch 0152, iter [04500, 05004], lr: 0.014277, loss: 1.8477
2022-07-16 20:35:44 - train: epoch 0152, iter [04600, 05004], lr: 0.014266, loss: 2.0702
2022-07-16 20:36:18 - train: epoch 0152, iter [04700, 05004], lr: 0.014254, loss: 2.1563
2022-07-16 20:36:52 - train: epoch 0152, iter [04800, 05004], lr: 0.014243, loss: 2.1006
2022-07-16 20:37:27 - train: epoch 0152, iter [04900, 05004], lr: 0.014232, loss: 2.0893
2022-07-16 20:38:00 - train: epoch 0152, iter [05000, 05004], lr: 0.014221, loss: 1.9537
2022-07-16 20:38:01 - train: epoch 152, train_loss: 2.1077
2022-07-16 20:39:15 - eval: epoch: 152, acc1: 71.582%, acc5: 90.762%, test_loss: 1.1365, per_image_load_time: 2.118ms, per_image_inference_time: 0.475ms
2022-07-16 20:39:15 - until epoch: 152, best_acc1: 71.582%
2022-07-16 20:39:15 - epoch 153 lr: 0.014220
2022-07-16 20:39:54 - train: epoch 0153, iter [00100, 05004], lr: 0.014209, loss: 2.1555
2022-07-16 20:40:28 - train: epoch 0153, iter [00200, 05004], lr: 0.014198, loss: 1.9678
2022-07-16 20:41:03 - train: epoch 0153, iter [00300, 05004], lr: 0.014186, loss: 2.0947
2022-07-16 20:41:36 - train: epoch 0153, iter [00400, 05004], lr: 0.014175, loss: 1.7436
2022-07-16 20:42:11 - train: epoch 0153, iter [00500, 05004], lr: 0.014164, loss: 2.4308
2022-07-16 20:42:45 - train: epoch 0153, iter [00600, 05004], lr: 0.014153, loss: 2.0419
2022-07-16 20:43:20 - train: epoch 0153, iter [00700, 05004], lr: 0.014141, loss: 2.0511
2022-07-16 20:43:54 - train: epoch 0153, iter [00800, 05004], lr: 0.014130, loss: 2.1493
2022-07-16 20:44:28 - train: epoch 0153, iter [00900, 05004], lr: 0.014119, loss: 2.2004
2022-07-16 20:45:02 - train: epoch 0153, iter [01000, 05004], lr: 0.014108, loss: 2.0049
2022-07-16 20:45:36 - train: epoch 0153, iter [01100, 05004], lr: 0.014097, loss: 2.1321
2022-07-16 20:46:10 - train: epoch 0153, iter [01200, 05004], lr: 0.014085, loss: 1.9348
2022-07-16 20:46:44 - train: epoch 0153, iter [01300, 05004], lr: 0.014074, loss: 1.9934
2022-07-16 20:47:19 - train: epoch 0153, iter [01400, 05004], lr: 0.014063, loss: 2.1301
2022-07-16 20:47:53 - train: epoch 0153, iter [01500, 05004], lr: 0.014052, loss: 2.0315
2022-07-16 20:48:28 - train: epoch 0153, iter [01600, 05004], lr: 0.014041, loss: 2.0818
2022-07-16 20:49:02 - train: epoch 0153, iter [01700, 05004], lr: 0.014029, loss: 2.2660
2022-07-16 20:49:36 - train: epoch 0153, iter [01800, 05004], lr: 0.014018, loss: 1.9292
2022-07-16 20:50:10 - train: epoch 0153, iter [01900, 05004], lr: 0.014007, loss: 2.2082
2022-07-16 20:50:45 - train: epoch 0153, iter [02000, 05004], lr: 0.013996, loss: 1.8653
2022-07-16 20:51:19 - train: epoch 0153, iter [02100, 05004], lr: 0.013985, loss: 2.0667
2022-07-16 20:51:53 - train: epoch 0153, iter [02200, 05004], lr: 0.013974, loss: 1.9721
2022-07-16 20:52:28 - train: epoch 0153, iter [02300, 05004], lr: 0.013962, loss: 2.1965
2022-07-16 20:53:02 - train: epoch 0153, iter [02400, 05004], lr: 0.013951, loss: 1.9585
2022-07-16 20:53:36 - train: epoch 0153, iter [02500, 05004], lr: 0.013940, loss: 2.0044
2022-07-16 20:54:11 - train: epoch 0153, iter [02600, 05004], lr: 0.013929, loss: 2.1895
2022-07-16 20:54:45 - train: epoch 0153, iter [02700, 05004], lr: 0.013918, loss: 2.1557
2022-07-16 20:55:19 - train: epoch 0153, iter [02800, 05004], lr: 0.013907, loss: 2.1839
2022-07-16 20:55:54 - train: epoch 0153, iter [02900, 05004], lr: 0.013896, loss: 2.0968
2022-07-16 20:56:29 - train: epoch 0153, iter [03000, 05004], lr: 0.013884, loss: 2.3529
2022-07-16 20:57:04 - train: epoch 0153, iter [03100, 05004], lr: 0.013873, loss: 2.2081
2022-07-16 20:57:38 - train: epoch 0153, iter [03200, 05004], lr: 0.013862, loss: 2.1256
2022-07-16 20:58:12 - train: epoch 0153, iter [03300, 05004], lr: 0.013851, loss: 2.1754
2022-07-16 20:58:47 - train: epoch 0153, iter [03400, 05004], lr: 0.013840, loss: 1.9824
2022-07-16 20:59:22 - train: epoch 0153, iter [03500, 05004], lr: 0.013829, loss: 2.2203
2022-07-16 20:59:56 - train: epoch 0153, iter [03600, 05004], lr: 0.013818, loss: 2.0546
2022-07-16 21:00:31 - train: epoch 0153, iter [03700, 05004], lr: 0.013807, loss: 2.1320
2022-07-16 21:01:05 - train: epoch 0153, iter [03800, 05004], lr: 0.013795, loss: 2.0557
2022-07-16 21:01:39 - train: epoch 0153, iter [03900, 05004], lr: 0.013784, loss: 1.9267
2022-07-16 21:02:13 - train: epoch 0153, iter [04000, 05004], lr: 0.013773, loss: 2.2051
2022-07-16 21:02:48 - train: epoch 0153, iter [04100, 05004], lr: 0.013762, loss: 2.2887
2022-07-16 21:03:22 - train: epoch 0153, iter [04200, 05004], lr: 0.013751, loss: 2.2538
2022-07-16 21:03:57 - train: epoch 0153, iter [04300, 05004], lr: 0.013740, loss: 1.9183
2022-07-16 21:04:31 - train: epoch 0153, iter [04400, 05004], lr: 0.013729, loss: 2.2530
2022-07-16 21:05:05 - train: epoch 0153, iter [04500, 05004], lr: 0.013718, loss: 2.0013
2022-07-16 21:05:40 - train: epoch 0153, iter [04600, 05004], lr: 0.013707, loss: 2.2120
2022-07-16 21:06:14 - train: epoch 0153, iter [04700, 05004], lr: 0.013696, loss: 2.3321
2022-07-16 21:06:49 - train: epoch 0153, iter [04800, 05004], lr: 0.013685, loss: 2.2785
2022-07-16 21:07:24 - train: epoch 0153, iter [04900, 05004], lr: 0.013674, loss: 2.3034
2022-07-16 21:07:57 - train: epoch 0153, iter [05000, 05004], lr: 0.013662, loss: 1.9127
2022-07-16 21:07:58 - train: epoch 153, train_loss: 2.0961
2022-07-16 21:09:12 - eval: epoch: 153, acc1: 71.014%, acc5: 90.456%, test_loss: 1.1650, per_image_load_time: 2.422ms, per_image_inference_time: 0.436ms
2022-07-16 21:09:13 - until epoch: 153, best_acc1: 71.582%
2022-07-16 21:09:13 - epoch 154 lr: 0.013662
2022-07-16 21:09:53 - train: epoch 0154, iter [00100, 05004], lr: 0.013651, loss: 1.8511
2022-07-16 21:10:27 - train: epoch 0154, iter [00200, 05004], lr: 0.013640, loss: 1.8769
2022-07-16 21:11:01 - train: epoch 0154, iter [00300, 05004], lr: 0.013629, loss: 2.1452
2022-07-16 21:11:36 - train: epoch 0154, iter [00400, 05004], lr: 0.013618, loss: 1.9717
2022-07-16 21:12:09 - train: epoch 0154, iter [00500, 05004], lr: 0.013607, loss: 1.9528
2022-07-16 21:12:43 - train: epoch 0154, iter [00600, 05004], lr: 0.013596, loss: 1.9709
2022-07-16 21:13:17 - train: epoch 0154, iter [00700, 05004], lr: 0.013585, loss: 2.2328
2022-07-16 21:13:51 - train: epoch 0154, iter [00800, 05004], lr: 0.013574, loss: 1.9724
2022-07-16 21:14:26 - train: epoch 0154, iter [00900, 05004], lr: 0.013563, loss: 1.9490
2022-07-16 21:15:00 - train: epoch 0154, iter [01000, 05004], lr: 0.013552, loss: 2.2900
2022-07-16 21:15:34 - train: epoch 0154, iter [01100, 05004], lr: 0.013541, loss: 2.2713
2022-07-16 21:16:08 - train: epoch 0154, iter [01200, 05004], lr: 0.013530, loss: 2.0655
2022-07-16 21:16:42 - train: epoch 0154, iter [01300, 05004], lr: 0.013519, loss: 2.0745
2022-07-16 21:17:15 - train: epoch 0154, iter [01400, 05004], lr: 0.013508, loss: 1.8911
2022-07-16 21:17:50 - train: epoch 0154, iter [01500, 05004], lr: 0.013497, loss: 1.9399
2022-07-16 21:18:24 - train: epoch 0154, iter [01600, 05004], lr: 0.013486, loss: 1.9093
2022-07-16 21:18:59 - train: epoch 0154, iter [01700, 05004], lr: 0.013475, loss: 2.1340
2022-07-16 21:19:33 - train: epoch 0154, iter [01800, 05004], lr: 0.013464, loss: 2.0265
2022-07-16 21:20:07 - train: epoch 0154, iter [01900, 05004], lr: 0.013453, loss: 2.1881
2022-07-16 21:20:41 - train: epoch 0154, iter [02000, 05004], lr: 0.013442, loss: 2.0128
2022-07-16 21:21:16 - train: epoch 0154, iter [02100, 05004], lr: 0.013431, loss: 2.1111
2022-07-16 21:21:50 - train: epoch 0154, iter [02200, 05004], lr: 0.013420, loss: 1.9455
2022-07-16 21:22:26 - train: epoch 0154, iter [02300, 05004], lr: 0.013409, loss: 2.2288
2022-07-16 21:22:59 - train: epoch 0154, iter [02400, 05004], lr: 0.013398, loss: 2.0356
2022-07-16 21:23:33 - train: epoch 0154, iter [02500, 05004], lr: 0.013387, loss: 2.0841
2022-07-16 21:24:08 - train: epoch 0154, iter [02600, 05004], lr: 0.013376, loss: 1.9079
2022-07-16 21:24:43 - train: epoch 0154, iter [02700, 05004], lr: 0.013365, loss: 2.1936
2022-07-16 21:25:18 - train: epoch 0154, iter [02800, 05004], lr: 0.013354, loss: 2.2430
2022-07-16 21:25:53 - train: epoch 0154, iter [02900, 05004], lr: 0.013343, loss: 2.0287
2022-07-16 21:26:27 - train: epoch 0154, iter [03000, 05004], lr: 0.013332, loss: 2.2921
2022-07-16 21:27:02 - train: epoch 0154, iter [03100, 05004], lr: 0.013321, loss: 1.9855
2022-07-16 21:27:36 - train: epoch 0154, iter [03200, 05004], lr: 0.013310, loss: 1.8325
2022-07-16 21:28:12 - train: epoch 0154, iter [03300, 05004], lr: 0.013299, loss: 2.1239
2022-07-16 21:28:46 - train: epoch 0154, iter [03400, 05004], lr: 0.013288, loss: 2.0418
2022-07-16 21:29:21 - train: epoch 0154, iter [03500, 05004], lr: 0.013277, loss: 2.0205
2022-07-16 21:29:56 - train: epoch 0154, iter [03600, 05004], lr: 0.013266, loss: 2.0393
2022-07-16 21:30:30 - train: epoch 0154, iter [03700, 05004], lr: 0.013256, loss: 2.3837
2022-07-16 21:31:04 - train: epoch 0154, iter [03800, 05004], lr: 0.013245, loss: 2.1682
2022-07-16 21:31:38 - train: epoch 0154, iter [03900, 05004], lr: 0.013234, loss: 2.1891
2022-07-16 21:32:13 - train: epoch 0154, iter [04000, 05004], lr: 0.013223, loss: 2.2271
2022-07-16 21:32:48 - train: epoch 0154, iter [04100, 05004], lr: 0.013212, loss: 2.0591
2022-07-16 21:33:23 - train: epoch 0154, iter [04200, 05004], lr: 0.013201, loss: 1.9552
2022-07-16 21:33:56 - train: epoch 0154, iter [04300, 05004], lr: 0.013190, loss: 2.1694
2022-07-16 21:34:33 - train: epoch 0154, iter [04400, 05004], lr: 0.013179, loss: 2.2524
2022-07-16 21:35:06 - train: epoch 0154, iter [04500, 05004], lr: 0.013168, loss: 2.0579
2022-07-16 21:35:41 - train: epoch 0154, iter [04600, 05004], lr: 0.013157, loss: 2.2027
2022-07-16 21:36:15 - train: epoch 0154, iter [04700, 05004], lr: 0.013147, loss: 2.2554
2022-07-16 21:36:50 - train: epoch 0154, iter [04800, 05004], lr: 0.013136, loss: 2.3788
2022-07-16 21:37:24 - train: epoch 0154, iter [04900, 05004], lr: 0.013125, loss: 2.6654
2022-07-16 21:37:57 - train: epoch 0154, iter [05000, 05004], lr: 0.013114, loss: 1.9577
2022-07-16 21:37:58 - train: epoch 154, train_loss: 2.0880
2022-07-16 21:39:13 - eval: epoch: 154, acc1: 71.898%, acc5: 90.856%, test_loss: 1.1342, per_image_load_time: 2.411ms, per_image_inference_time: 0.470ms
2022-07-16 21:39:13 - until epoch: 154, best_acc1: 71.898%
2022-07-16 21:39:13 - epoch 155 lr: 0.013113
2022-07-16 21:39:52 - train: epoch 0155, iter [00100, 05004], lr: 0.013103, loss: 2.1667
2022-07-16 21:40:27 - train: epoch 0155, iter [00200, 05004], lr: 0.013092, loss: 2.1389
2022-07-16 21:41:01 - train: epoch 0155, iter [00300, 05004], lr: 0.013081, loss: 2.0268
2022-07-16 21:41:35 - train: epoch 0155, iter [00400, 05004], lr: 0.013070, loss: 2.1710
2022-07-16 21:42:08 - train: epoch 0155, iter [00500, 05004], lr: 0.013059, loss: 2.1787
2022-07-16 21:42:43 - train: epoch 0155, iter [00600, 05004], lr: 0.013048, loss: 2.0822
2022-07-16 21:43:16 - train: epoch 0155, iter [00700, 05004], lr: 0.013037, loss: 2.0393
2022-07-16 21:43:51 - train: epoch 0155, iter [00800, 05004], lr: 0.013027, loss: 2.1167
2022-07-16 21:44:24 - train: epoch 0155, iter [00900, 05004], lr: 0.013016, loss: 2.1104
2022-07-16 21:44:58 - train: epoch 0155, iter [01000, 05004], lr: 0.013005, loss: 2.1334
2022-07-16 21:45:32 - train: epoch 0155, iter [01100, 05004], lr: 0.012994, loss: 1.8702
2022-07-16 21:46:05 - train: epoch 0155, iter [01200, 05004], lr: 0.012983, loss: 1.7697
2022-07-16 21:46:38 - train: epoch 0155, iter [01300, 05004], lr: 0.012973, loss: 2.2261
2022-07-16 21:47:12 - train: epoch 0155, iter [01400, 05004], lr: 0.012962, loss: 2.0257
2022-07-16 21:47:47 - train: epoch 0155, iter [01500, 05004], lr: 0.012951, loss: 2.0319
2022-07-16 21:48:20 - train: epoch 0155, iter [01600, 05004], lr: 0.012940, loss: 2.0678
2022-07-16 21:48:54 - train: epoch 0155, iter [01700, 05004], lr: 0.012929, loss: 1.9943
2022-07-16 21:49:28 - train: epoch 0155, iter [01800, 05004], lr: 0.012918, loss: 1.9283
2022-07-16 21:50:02 - train: epoch 0155, iter [01900, 05004], lr: 0.012908, loss: 1.7411
2022-07-16 21:50:36 - train: epoch 0155, iter [02000, 05004], lr: 0.012897, loss: 2.2307
2022-07-16 21:51:10 - train: epoch 0155, iter [02100, 05004], lr: 0.012886, loss: 2.3290
2022-07-16 21:51:44 - train: epoch 0155, iter [02200, 05004], lr: 0.012875, loss: 1.9072
2022-07-16 21:52:18 - train: epoch 0155, iter [02300, 05004], lr: 0.012865, loss: 1.8576
2022-07-16 21:52:52 - train: epoch 0155, iter [02400, 05004], lr: 0.012854, loss: 1.9069
2022-07-16 21:53:27 - train: epoch 0155, iter [02500, 05004], lr: 0.012843, loss: 2.0778
2022-07-16 21:54:00 - train: epoch 0155, iter [02600, 05004], lr: 0.012832, loss: 1.9498
2022-07-16 21:54:34 - train: epoch 0155, iter [02700, 05004], lr: 0.012821, loss: 2.2650
2022-07-16 21:55:08 - train: epoch 0155, iter [02800, 05004], lr: 0.012811, loss: 1.7902
2022-07-16 21:55:42 - train: epoch 0155, iter [02900, 05004], lr: 0.012800, loss: 2.0361
2022-07-16 21:56:16 - train: epoch 0155, iter [03000, 05004], lr: 0.012789, loss: 1.8475
2022-07-16 21:56:50 - train: epoch 0155, iter [03100, 05004], lr: 0.012778, loss: 2.0422
2022-07-16 21:57:24 - train: epoch 0155, iter [03200, 05004], lr: 0.012768, loss: 2.2962
2022-07-16 21:57:59 - train: epoch 0155, iter [03300, 05004], lr: 0.012757, loss: 2.2076
2022-07-16 21:58:33 - train: epoch 0155, iter [03400, 05004], lr: 0.012746, loss: 1.9441
2022-07-16 21:59:06 - train: epoch 0155, iter [03500, 05004], lr: 0.012735, loss: 2.0464
2022-07-16 21:59:40 - train: epoch 0155, iter [03600, 05004], lr: 0.012725, loss: 2.1035
2022-07-16 22:00:14 - train: epoch 0155, iter [03700, 05004], lr: 0.012714, loss: 1.9863
2022-07-16 22:00:48 - train: epoch 0155, iter [03800, 05004], lr: 0.012703, loss: 2.0793
2022-07-16 22:01:23 - train: epoch 0155, iter [03900, 05004], lr: 0.012693, loss: 2.1408
2022-07-16 22:01:57 - train: epoch 0155, iter [04000, 05004], lr: 0.012682, loss: 2.0799
2022-07-16 22:02:31 - train: epoch 0155, iter [04100, 05004], lr: 0.012671, loss: 1.9470
2022-07-16 22:03:04 - train: epoch 0155, iter [04200, 05004], lr: 0.012660, loss: 2.1521
2022-07-16 22:03:38 - train: epoch 0155, iter [04300, 05004], lr: 0.012650, loss: 2.2504
2022-07-16 22:04:13 - train: epoch 0155, iter [04400, 05004], lr: 0.012639, loss: 1.8642
2022-07-16 22:04:47 - train: epoch 0155, iter [04500, 05004], lr: 0.012628, loss: 1.9990
2022-07-16 22:05:21 - train: epoch 0155, iter [04600, 05004], lr: 0.012618, loss: 2.0913
2022-07-16 22:05:56 - train: epoch 0155, iter [04700, 05004], lr: 0.012607, loss: 2.3336
2022-07-16 22:06:29 - train: epoch 0155, iter [04800, 05004], lr: 0.012596, loss: 2.3507
2022-07-16 22:07:04 - train: epoch 0155, iter [04900, 05004], lr: 0.012586, loss: 2.1308
2022-07-16 22:07:36 - train: epoch 0155, iter [05000, 05004], lr: 0.012575, loss: 2.1057
2022-07-16 22:07:37 - train: epoch 155, train_loss: 2.0750
2022-07-16 22:08:51 - eval: epoch: 155, acc1: 70.974%, acc5: 90.438%, test_loss: 1.1663, per_image_load_time: 2.422ms, per_image_inference_time: 0.454ms
2022-07-16 22:08:52 - until epoch: 155, best_acc1: 71.898%
2022-07-16 22:08:52 - epoch 156 lr: 0.012574
2022-07-16 22:09:31 - train: epoch 0156, iter [00100, 05004], lr: 0.012564, loss: 2.3592
2022-07-16 22:10:06 - train: epoch 0156, iter [00200, 05004], lr: 0.012553, loss: 1.9256
2022-07-16 22:10:40 - train: epoch 0156, iter [00300, 05004], lr: 0.012542, loss: 1.9359
2022-07-16 22:11:14 - train: epoch 0156, iter [00400, 05004], lr: 0.012532, loss: 2.0645
2022-07-16 22:11:48 - train: epoch 0156, iter [00500, 05004], lr: 0.012521, loss: 2.1586
2022-07-16 22:12:21 - train: epoch 0156, iter [00600, 05004], lr: 0.012510, loss: 1.7941
2022-07-16 22:12:56 - train: epoch 0156, iter [00700, 05004], lr: 0.012500, loss: 1.7653
2022-07-16 22:13:30 - train: epoch 0156, iter [00800, 05004], lr: 0.012489, loss: 2.1342
2022-07-16 22:14:04 - train: epoch 0156, iter [00900, 05004], lr: 0.012479, loss: 2.3530
2022-07-16 22:14:39 - train: epoch 0156, iter [01000, 05004], lr: 0.012468, loss: 2.0774
2022-07-16 22:15:12 - train: epoch 0156, iter [01100, 05004], lr: 0.012457, loss: 1.9667
2022-07-16 22:15:45 - train: epoch 0156, iter [01200, 05004], lr: 0.012447, loss: 1.8327
2022-07-16 22:16:21 - train: epoch 0156, iter [01300, 05004], lr: 0.012436, loss: 2.1640
2022-07-16 22:16:55 - train: epoch 0156, iter [01400, 05004], lr: 0.012425, loss: 2.2173
2022-07-16 22:17:29 - train: epoch 0156, iter [01500, 05004], lr: 0.012415, loss: 2.0036
2022-07-16 22:18:03 - train: epoch 0156, iter [01600, 05004], lr: 0.012404, loss: 1.8911
2022-07-16 22:18:37 - train: epoch 0156, iter [01700, 05004], lr: 0.012394, loss: 1.9287
2022-07-16 22:19:10 - train: epoch 0156, iter [01800, 05004], lr: 0.012383, loss: 2.1911
2022-07-16 22:19:45 - train: epoch 0156, iter [01900, 05004], lr: 0.012372, loss: 1.9132
2022-07-16 22:20:19 - train: epoch 0156, iter [02000, 05004], lr: 0.012362, loss: 1.9098
2022-07-16 22:20:52 - train: epoch 0156, iter [02100, 05004], lr: 0.012351, loss: 2.1083
2022-07-16 22:21:27 - train: epoch 0156, iter [02200, 05004], lr: 0.012341, loss: 1.9424
2022-07-16 22:22:01 - train: epoch 0156, iter [02300, 05004], lr: 0.012330, loss: 2.1789
2022-07-16 22:22:35 - train: epoch 0156, iter [02400, 05004], lr: 0.012319, loss: 2.0143
2022-07-16 22:23:09 - train: epoch 0156, iter [02500, 05004], lr: 0.012309, loss: 2.1661
2022-07-16 22:23:42 - train: epoch 0156, iter [02600, 05004], lr: 0.012298, loss: 2.0587
2022-07-16 22:24:17 - train: epoch 0156, iter [02700, 05004], lr: 0.012288, loss: 1.9282
2022-07-16 22:24:51 - train: epoch 0156, iter [02800, 05004], lr: 0.012277, loss: 2.2493
2022-07-16 22:25:25 - train: epoch 0156, iter [02900, 05004], lr: 0.012267, loss: 1.8750
2022-07-16 22:25:59 - train: epoch 0156, iter [03000, 05004], lr: 0.012256, loss: 2.0915
2022-07-16 22:26:33 - train: epoch 0156, iter [03100, 05004], lr: 0.012245, loss: 1.7386
2022-07-16 22:27:07 - train: epoch 0156, iter [03200, 05004], lr: 0.012235, loss: 2.2557
2022-07-16 22:27:41 - train: epoch 0156, iter [03300, 05004], lr: 0.012224, loss: 2.2553
2022-07-16 22:28:16 - train: epoch 0156, iter [03400, 05004], lr: 0.012214, loss: 1.6673
2022-07-16 22:28:50 - train: epoch 0156, iter [03500, 05004], lr: 0.012203, loss: 2.0594
2022-07-16 22:29:24 - train: epoch 0156, iter [03600, 05004], lr: 0.012193, loss: 2.5326
2022-07-16 22:29:57 - train: epoch 0156, iter [03700, 05004], lr: 0.012182, loss: 1.9502
2022-07-16 22:30:31 - train: epoch 0156, iter [03800, 05004], lr: 0.012172, loss: 2.2324
2022-07-16 22:31:05 - train: epoch 0156, iter [03900, 05004], lr: 0.012161, loss: 1.8060
2022-07-16 22:31:40 - train: epoch 0156, iter [04000, 05004], lr: 0.012151, loss: 1.9310
2022-07-16 22:32:14 - train: epoch 0156, iter [04100, 05004], lr: 0.012140, loss: 2.1884
2022-07-16 22:32:48 - train: epoch 0156, iter [04200, 05004], lr: 0.012130, loss: 2.1380
2022-07-16 22:33:22 - train: epoch 0156, iter [04300, 05004], lr: 0.012119, loss: 1.8972
2022-07-16 22:33:57 - train: epoch 0156, iter [04400, 05004], lr: 0.012109, loss: 1.9778
2022-07-16 22:34:31 - train: epoch 0156, iter [04500, 05004], lr: 0.012098, loss: 2.1934
2022-07-16 22:35:04 - train: epoch 0156, iter [04600, 05004], lr: 0.012088, loss: 2.1954
2022-07-16 22:35:38 - train: epoch 0156, iter [04700, 05004], lr: 0.012077, loss: 2.0782
2022-07-16 22:36:12 - train: epoch 0156, iter [04800, 05004], lr: 0.012067, loss: 2.1664
2022-07-16 22:36:46 - train: epoch 0156, iter [04900, 05004], lr: 0.012056, loss: 2.4339
2022-07-16 22:37:19 - train: epoch 0156, iter [05000, 05004], lr: 0.012046, loss: 2.1318
2022-07-16 22:37:21 - train: epoch 156, train_loss: 2.0642
2022-07-16 22:38:35 - eval: epoch: 156, acc1: 71.662%, acc5: 90.568%, test_loss: 1.1450, per_image_load_time: 2.420ms, per_image_inference_time: 0.475ms
2022-07-16 22:38:35 - until epoch: 156, best_acc1: 71.898%
2022-07-16 22:38:35 - epoch 157 lr: 0.012045
2022-07-16 22:39:15 - train: epoch 0157, iter [00100, 05004], lr: 0.012035, loss: 1.7989
2022-07-16 22:39:49 - train: epoch 0157, iter [00200, 05004], lr: 0.012024, loss: 1.9608
2022-07-16 22:40:23 - train: epoch 0157, iter [00300, 05004], lr: 0.012014, loss: 2.0006
2022-07-16 22:40:57 - train: epoch 0157, iter [00400, 05004], lr: 0.012003, loss: 2.2802
2022-07-16 22:41:31 - train: epoch 0157, iter [00500, 05004], lr: 0.011993, loss: 2.2827
2022-07-16 22:42:06 - train: epoch 0157, iter [00600, 05004], lr: 0.011982, loss: 2.1317
2022-07-16 22:42:40 - train: epoch 0157, iter [00700, 05004], lr: 0.011972, loss: 2.0452
2022-07-16 22:43:15 - train: epoch 0157, iter [00800, 05004], lr: 0.011961, loss: 1.8962
2022-07-16 22:43:49 - train: epoch 0157, iter [00900, 05004], lr: 0.011951, loss: 2.1699
2022-07-16 22:44:22 - train: epoch 0157, iter [01000, 05004], lr: 0.011941, loss: 1.9877
2022-07-16 22:44:57 - train: epoch 0157, iter [01100, 05004], lr: 0.011930, loss: 1.9855
2022-07-16 22:45:31 - train: epoch 0157, iter [01200, 05004], lr: 0.011920, loss: 2.1663
2022-07-16 22:46:05 - train: epoch 0157, iter [01300, 05004], lr: 0.011909, loss: 2.1333
2022-07-16 22:46:39 - train: epoch 0157, iter [01400, 05004], lr: 0.011899, loss: 1.9041
2022-07-16 22:47:14 - train: epoch 0157, iter [01500, 05004], lr: 0.011888, loss: 2.1717
2022-07-16 22:47:48 - train: epoch 0157, iter [01600, 05004], lr: 0.011878, loss: 2.0864
2022-07-16 22:48:22 - train: epoch 0157, iter [01700, 05004], lr: 0.011868, loss: 1.9396
2022-07-16 22:48:55 - train: epoch 0157, iter [01800, 05004], lr: 0.011857, loss: 1.6620
2022-07-16 22:49:30 - train: epoch 0157, iter [01900, 05004], lr: 0.011847, loss: 2.1316
2022-07-16 22:50:05 - train: epoch 0157, iter [02000, 05004], lr: 0.011836, loss: 2.3369
2022-07-16 22:50:39 - train: epoch 0157, iter [02100, 05004], lr: 0.011826, loss: 2.1851
2022-07-16 22:51:13 - train: epoch 0157, iter [02200, 05004], lr: 0.011816, loss: 1.7922
2022-07-16 22:51:47 - train: epoch 0157, iter [02300, 05004], lr: 0.011805, loss: 1.8734
2022-07-16 22:52:21 - train: epoch 0157, iter [02400, 05004], lr: 0.011795, loss: 2.0794
2022-07-16 22:52:55 - train: epoch 0157, iter [02500, 05004], lr: 0.011784, loss: 1.7748
2022-07-16 22:53:29 - train: epoch 0157, iter [02600, 05004], lr: 0.011774, loss: 2.0246
2022-07-16 22:54:03 - train: epoch 0157, iter [02700, 05004], lr: 0.011764, loss: 2.0549
2022-07-16 22:54:38 - train: epoch 0157, iter [02800, 05004], lr: 0.011753, loss: 1.9888
2022-07-16 22:55:11 - train: epoch 0157, iter [02900, 05004], lr: 0.011743, loss: 1.9691
2022-07-16 22:55:46 - train: epoch 0157, iter [03000, 05004], lr: 0.011733, loss: 2.0300
2022-07-16 22:56:21 - train: epoch 0157, iter [03100, 05004], lr: 0.011722, loss: 1.9067
2022-07-16 22:56:55 - train: epoch 0157, iter [03200, 05004], lr: 0.011712, loss: 1.9080
2022-07-16 22:57:30 - train: epoch 0157, iter [03300, 05004], lr: 0.011702, loss: 1.9433
2022-07-16 22:58:04 - train: epoch 0157, iter [03400, 05004], lr: 0.011691, loss: 1.9532
2022-07-16 22:58:39 - train: epoch 0157, iter [03500, 05004], lr: 0.011681, loss: 2.1131
2022-07-16 22:59:13 - train: epoch 0157, iter [03600, 05004], lr: 0.011670, loss: 2.1690
2022-07-16 22:59:47 - train: epoch 0157, iter [03700, 05004], lr: 0.011660, loss: 2.0984
2022-07-16 23:00:22 - train: epoch 0157, iter [03800, 05004], lr: 0.011650, loss: 2.1511
2022-07-16 23:00:56 - train: epoch 0157, iter [03900, 05004], lr: 0.011639, loss: 2.0569
2022-07-16 23:01:30 - train: epoch 0157, iter [04000, 05004], lr: 0.011629, loss: 1.9787
2022-07-16 23:02:05 - train: epoch 0157, iter [04100, 05004], lr: 0.011619, loss: 2.0476
2022-07-16 23:02:40 - train: epoch 0157, iter [04200, 05004], lr: 0.011609, loss: 1.9090
2022-07-16 23:03:14 - train: epoch 0157, iter [04300, 05004], lr: 0.011598, loss: 2.1831
2022-07-16 23:03:49 - train: epoch 0157, iter [04400, 05004], lr: 0.011588, loss: 2.0689
2022-07-16 23:04:23 - train: epoch 0157, iter [04500, 05004], lr: 0.011578, loss: 2.2613
2022-07-16 23:04:57 - train: epoch 0157, iter [04600, 05004], lr: 0.011567, loss: 2.3509
2022-07-16 23:05:32 - train: epoch 0157, iter [04700, 05004], lr: 0.011557, loss: 2.1697
2022-07-16 23:06:05 - train: epoch 0157, iter [04800, 05004], lr: 0.011547, loss: 2.0252
2022-07-16 23:06:40 - train: epoch 0157, iter [04900, 05004], lr: 0.011536, loss: 1.7297
2022-07-16 23:07:13 - train: epoch 0157, iter [05000, 05004], lr: 0.011526, loss: 1.9789
2022-07-16 23:07:14 - train: epoch 157, train_loss: 2.0517
2022-07-16 23:08:29 - eval: epoch: 157, acc1: 72.266%, acc5: 90.928%, test_loss: 1.1145, per_image_load_time: 2.442ms, per_image_inference_time: 0.454ms
2022-07-16 23:08:29 - until epoch: 157, best_acc1: 72.266%
2022-07-16 23:08:29 - epoch 158 lr: 0.011526
2022-07-16 23:09:09 - train: epoch 0158, iter [00100, 05004], lr: 0.011515, loss: 2.0244
2022-07-16 23:09:44 - train: epoch 0158, iter [00200, 05004], lr: 0.011505, loss: 1.8382
2022-07-16 23:10:17 - train: epoch 0158, iter [00300, 05004], lr: 0.011495, loss: 2.0032
2022-07-16 23:10:51 - train: epoch 0158, iter [00400, 05004], lr: 0.011485, loss: 1.7122
2022-07-16 23:11:25 - train: epoch 0158, iter [00500, 05004], lr: 0.011474, loss: 1.9513
2022-07-16 23:12:00 - train: epoch 0158, iter [00600, 05004], lr: 0.011464, loss: 1.9332
2022-07-16 23:12:34 - train: epoch 0158, iter [00700, 05004], lr: 0.011454, loss: 2.2063
2022-07-16 23:13:08 - train: epoch 0158, iter [00800, 05004], lr: 0.011444, loss: 1.9434
2022-07-16 23:13:42 - train: epoch 0158, iter [00900, 05004], lr: 0.011433, loss: 2.1293
2022-07-16 23:14:16 - train: epoch 0158, iter [01000, 05004], lr: 0.011423, loss: 1.9388
2022-07-16 23:14:49 - train: epoch 0158, iter [01100, 05004], lr: 0.011413, loss: 1.8963
2022-07-16 23:15:23 - train: epoch 0158, iter [01200, 05004], lr: 0.011403, loss: 1.9859
2022-07-16 23:15:58 - train: epoch 0158, iter [01300, 05004], lr: 0.011392, loss: 2.0891
2022-07-16 23:16:32 - train: epoch 0158, iter [01400, 05004], lr: 0.011382, loss: 1.9723
2022-07-16 23:17:05 - train: epoch 0158, iter [01500, 05004], lr: 0.011372, loss: 2.2025
2022-07-16 23:17:39 - train: epoch 0158, iter [01600, 05004], lr: 0.011362, loss: 2.0778
2022-07-16 23:18:13 - train: epoch 0158, iter [01700, 05004], lr: 0.011352, loss: 1.9720
2022-07-16 23:18:47 - train: epoch 0158, iter [01800, 05004], lr: 0.011341, loss: 1.9844
2022-07-16 23:19:22 - train: epoch 0158, iter [01900, 05004], lr: 0.011331, loss: 1.9011
2022-07-16 23:19:56 - train: epoch 0158, iter [02000, 05004], lr: 0.011321, loss: 1.8939
2022-07-16 23:20:29 - train: epoch 0158, iter [02100, 05004], lr: 0.011311, loss: 2.2516
2022-07-16 23:21:03 - train: epoch 0158, iter [02200, 05004], lr: 0.011301, loss: 1.9879
2022-07-16 23:21:37 - train: epoch 0158, iter [02300, 05004], lr: 0.011290, loss: 2.4088
2022-07-16 23:22:11 - train: epoch 0158, iter [02400, 05004], lr: 0.011280, loss: 1.9669
2022-07-16 23:22:45 - train: epoch 0158, iter [02500, 05004], lr: 0.011270, loss: 1.9401
2022-07-16 23:23:19 - train: epoch 0158, iter [02600, 05004], lr: 0.011260, loss: 2.0521
2022-07-16 23:23:53 - train: epoch 0158, iter [02700, 05004], lr: 0.011250, loss: 2.2287
2022-07-16 23:24:27 - train: epoch 0158, iter [02800, 05004], lr: 0.011239, loss: 2.1552
2022-07-16 23:25:00 - train: epoch 0158, iter [02900, 05004], lr: 0.011229, loss: 2.3334
2022-07-16 23:25:35 - train: epoch 0158, iter [03000, 05004], lr: 0.011219, loss: 1.8599
2022-07-16 23:26:10 - train: epoch 0158, iter [03100, 05004], lr: 0.011209, loss: 2.2187
2022-07-16 23:26:44 - train: epoch 0158, iter [03200, 05004], lr: 0.011199, loss: 1.5787
2022-07-16 23:27:18 - train: epoch 0158, iter [03300, 05004], lr: 0.011189, loss: 2.0019
2022-07-16 23:27:52 - train: epoch 0158, iter [03400, 05004], lr: 0.011178, loss: 2.0626
2022-07-16 23:28:26 - train: epoch 0158, iter [03500, 05004], lr: 0.011168, loss: 2.0636
2022-07-16 23:29:00 - train: epoch 0158, iter [03600, 05004], lr: 0.011158, loss: 2.1722
2022-07-16 23:29:33 - train: epoch 0158, iter [03700, 05004], lr: 0.011148, loss: 1.9464
2022-07-16 23:30:08 - train: epoch 0158, iter [03800, 05004], lr: 0.011138, loss: 2.2037
2022-07-16 23:30:42 - train: epoch 0158, iter [03900, 05004], lr: 0.011128, loss: 1.8315
2022-07-16 23:31:17 - train: epoch 0158, iter [04000, 05004], lr: 0.011118, loss: 2.2761
2022-07-16 23:31:51 - train: epoch 0158, iter [04100, 05004], lr: 0.011108, loss: 2.1560
2022-07-16 23:32:25 - train: epoch 0158, iter [04200, 05004], lr: 0.011097, loss: 1.9485
2022-07-16 23:32:59 - train: epoch 0158, iter [04300, 05004], lr: 0.011087, loss: 2.2534
2022-07-16 23:33:33 - train: epoch 0158, iter [04400, 05004], lr: 0.011077, loss: 1.8976
2022-07-16 23:34:07 - train: epoch 0158, iter [04500, 05004], lr: 0.011067, loss: 1.8109
2022-07-16 23:34:41 - train: epoch 0158, iter [04600, 05004], lr: 0.011057, loss: 1.9500
2022-07-16 23:35:16 - train: epoch 0158, iter [04700, 05004], lr: 0.011047, loss: 1.9227
2022-07-16 23:35:50 - train: epoch 0158, iter [04800, 05004], lr: 0.011037, loss: 2.1747
2022-07-16 23:36:23 - train: epoch 0158, iter [04900, 05004], lr: 0.011027, loss: 2.0449
2022-07-16 23:36:56 - train: epoch 0158, iter [05000, 05004], lr: 0.011017, loss: 1.9367
2022-07-16 23:36:57 - train: epoch 158, train_loss: 2.0400
2022-07-16 23:38:12 - eval: epoch: 158, acc1: 72.688%, acc5: 91.334%, test_loss: 1.0881, per_image_load_time: 2.417ms, per_image_inference_time: 0.480ms
2022-07-16 23:38:12 - until epoch: 158, best_acc1: 72.688%
2022-07-16 23:38:12 - epoch 159 lr: 0.011016
2022-07-16 23:38:52 - train: epoch 0159, iter [00100, 05004], lr: 0.011006, loss: 1.9425
2022-07-16 23:39:26 - train: epoch 0159, iter [00200, 05004], lr: 0.010996, loss: 1.8044
2022-07-16 23:40:01 - train: epoch 0159, iter [00300, 05004], lr: 0.010986, loss: 1.9643
2022-07-16 23:40:36 - train: epoch 0159, iter [00400, 05004], lr: 0.010976, loss: 2.0434
2022-07-16 23:41:10 - train: epoch 0159, iter [00500, 05004], lr: 0.010966, loss: 2.0318
2022-07-16 23:41:44 - train: epoch 0159, iter [00600, 05004], lr: 0.010956, loss: 1.7302
2022-07-16 23:42:19 - train: epoch 0159, iter [00700, 05004], lr: 0.010946, loss: 1.9921
2022-07-16 23:42:53 - train: epoch 0159, iter [00800, 05004], lr: 0.010936, loss: 1.7804
2022-07-16 23:43:27 - train: epoch 0159, iter [00900, 05004], lr: 0.010926, loss: 1.7685
2022-07-16 23:44:02 - train: epoch 0159, iter [01000, 05004], lr: 0.010916, loss: 1.9773
2022-07-16 23:44:36 - train: epoch 0159, iter [01100, 05004], lr: 0.010906, loss: 2.1506
2022-07-16 23:45:11 - train: epoch 0159, iter [01200, 05004], lr: 0.010896, loss: 2.0060
2022-07-16 23:45:44 - train: epoch 0159, iter [01300, 05004], lr: 0.010886, loss: 2.4040
2022-07-16 23:46:20 - train: epoch 0159, iter [01400, 05004], lr: 0.010876, loss: 1.7793
2022-07-16 23:46:53 - train: epoch 0159, iter [01500, 05004], lr: 0.010866, loss: 2.2273
2022-07-16 23:47:28 - train: epoch 0159, iter [01600, 05004], lr: 0.010856, loss: 2.0803
2022-07-16 23:48:03 - train: epoch 0159, iter [01700, 05004], lr: 0.010846, loss: 1.7793
2022-07-16 23:48:37 - train: epoch 0159, iter [01800, 05004], lr: 0.010835, loss: 1.9819
2022-07-16 23:49:11 - train: epoch 0159, iter [01900, 05004], lr: 0.010825, loss: 1.9773
2022-07-16 23:49:45 - train: epoch 0159, iter [02000, 05004], lr: 0.010815, loss: 1.8779
2022-07-16 23:50:19 - train: epoch 0159, iter [02100, 05004], lr: 0.010805, loss: 1.8878
2022-07-16 23:50:54 - train: epoch 0159, iter [02200, 05004], lr: 0.010795, loss: 1.9093
2022-07-16 23:51:28 - train: epoch 0159, iter [02300, 05004], lr: 0.010786, loss: 1.8323
2022-07-16 23:52:02 - train: epoch 0159, iter [02400, 05004], lr: 0.010776, loss: 1.8934
2022-07-16 23:52:37 - train: epoch 0159, iter [02500, 05004], lr: 0.010766, loss: 1.7436
2022-07-16 23:53:13 - train: epoch 0159, iter [02600, 05004], lr: 0.010756, loss: 1.9578
2022-07-16 23:53:46 - train: epoch 0159, iter [02700, 05004], lr: 0.010746, loss: 1.8497
2022-07-16 23:54:21 - train: epoch 0159, iter [02800, 05004], lr: 0.010736, loss: 1.9796
2022-07-16 23:54:56 - train: epoch 0159, iter [02900, 05004], lr: 0.010726, loss: 2.1534
2022-07-16 23:55:30 - train: epoch 0159, iter [03000, 05004], lr: 0.010716, loss: 2.0076
2022-07-16 23:56:04 - train: epoch 0159, iter [03100, 05004], lr: 0.010706, loss: 1.9351
2022-07-16 23:56:39 - train: epoch 0159, iter [03200, 05004], lr: 0.010696, loss: 2.0731
2022-07-16 23:57:14 - train: epoch 0159, iter [03300, 05004], lr: 0.010686, loss: 2.3131
2022-07-16 23:57:48 - train: epoch 0159, iter [03400, 05004], lr: 0.010676, loss: 1.9891
2022-07-16 23:58:23 - train: epoch 0159, iter [03500, 05004], lr: 0.010666, loss: 2.1281
2022-07-16 23:58:57 - train: epoch 0159, iter [03600, 05004], lr: 0.010656, loss: 1.9487
2022-07-16 23:59:31 - train: epoch 0159, iter [03700, 05004], lr: 0.010646, loss: 2.1698
2022-07-17 00:00:06 - train: epoch 0159, iter [03800, 05004], lr: 0.010636, loss: 2.1943
2022-07-17 00:00:40 - train: epoch 0159, iter [03900, 05004], lr: 0.010626, loss: 2.0391
2022-07-17 00:01:14 - train: epoch 0159, iter [04000, 05004], lr: 0.010616, loss: 2.4024
2022-07-17 00:01:48 - train: epoch 0159, iter [04100, 05004], lr: 0.010606, loss: 2.1247
2022-07-17 00:02:23 - train: epoch 0159, iter [04200, 05004], lr: 0.010596, loss: 2.1417
2022-07-17 00:02:58 - train: epoch 0159, iter [04300, 05004], lr: 0.010587, loss: 1.9279
2022-07-17 00:03:32 - train: epoch 0159, iter [04400, 05004], lr: 0.010577, loss: 1.9328
2022-07-17 00:04:07 - train: epoch 0159, iter [04500, 05004], lr: 0.010567, loss: 2.1701
2022-07-17 00:04:41 - train: epoch 0159, iter [04600, 05004], lr: 0.010557, loss: 2.3514
2022-07-17 00:05:15 - train: epoch 0159, iter [04700, 05004], lr: 0.010547, loss: 1.9730
2022-07-17 00:05:49 - train: epoch 0159, iter [04800, 05004], lr: 0.010537, loss: 2.3808
2022-07-17 00:06:23 - train: epoch 0159, iter [04900, 05004], lr: 0.010527, loss: 2.0764
2022-07-17 00:06:56 - train: epoch 0159, iter [05000, 05004], lr: 0.010517, loss: 1.9364
2022-07-17 00:06:57 - train: epoch 159, train_loss: 2.0268
2022-07-17 00:08:12 - eval: epoch: 159, acc1: 72.134%, acc5: 90.994%, test_loss: 1.1150, per_image_load_time: 2.418ms, per_image_inference_time: 0.464ms
2022-07-17 00:08:12 - until epoch: 159, best_acc1: 72.688%
2022-07-17 00:08:12 - epoch 160 lr: 0.010517
2022-07-17 00:08:51 - train: epoch 0160, iter [00100, 05004], lr: 0.010507, loss: 2.0021
2022-07-17 00:09:25 - train: epoch 0160, iter [00200, 05004], lr: 0.010497, loss: 2.1515
2022-07-17 00:09:59 - train: epoch 0160, iter [00300, 05004], lr: 0.010487, loss: 1.9993
2022-07-17 00:10:34 - train: epoch 0160, iter [00400, 05004], lr: 0.010477, loss: 1.7791
2022-07-17 00:11:09 - train: epoch 0160, iter [00500, 05004], lr: 0.010468, loss: 1.8846
2022-07-17 00:11:43 - train: epoch 0160, iter [00600, 05004], lr: 0.010458, loss: 2.0450
2022-07-17 00:12:17 - train: epoch 0160, iter [00700, 05004], lr: 0.010448, loss: 1.8966
2022-07-17 00:12:52 - train: epoch 0160, iter [00800, 05004], lr: 0.010438, loss: 2.0303
2022-07-17 00:13:26 - train: epoch 0160, iter [00900, 05004], lr: 0.010428, loss: 2.3205
2022-07-17 00:14:00 - train: epoch 0160, iter [01000, 05004], lr: 0.010418, loss: 2.1022
2022-07-17 00:14:36 - train: epoch 0160, iter [01100, 05004], lr: 0.010409, loss: 1.9270
2022-07-17 00:15:10 - train: epoch 0160, iter [01200, 05004], lr: 0.010399, loss: 2.1106
2022-07-17 00:15:44 - train: epoch 0160, iter [01300, 05004], lr: 0.010389, loss: 1.8602
2022-07-17 00:16:20 - train: epoch 0160, iter [01400, 05004], lr: 0.010379, loss: 2.2901
2022-07-17 00:16:54 - train: epoch 0160, iter [01500, 05004], lr: 0.010369, loss: 2.0262
2022-07-17 00:17:28 - train: epoch 0160, iter [01600, 05004], lr: 0.010359, loss: 1.9114
2022-07-17 00:18:02 - train: epoch 0160, iter [01700, 05004], lr: 0.010350, loss: 1.8923
2022-07-17 00:18:37 - train: epoch 0160, iter [01800, 05004], lr: 0.010340, loss: 2.1009
2022-07-17 00:19:12 - train: epoch 0160, iter [01900, 05004], lr: 0.010330, loss: 2.2003
2022-07-17 00:19:46 - train: epoch 0160, iter [02000, 05004], lr: 0.010320, loss: 2.0346
2022-07-17 00:20:20 - train: epoch 0160, iter [02100, 05004], lr: 0.010310, loss: 1.9531
2022-07-17 00:20:55 - train: epoch 0160, iter [02200, 05004], lr: 0.010301, loss: 2.0524
2022-07-17 00:21:29 - train: epoch 0160, iter [02300, 05004], lr: 0.010291, loss: 1.6734
2022-07-17 00:22:02 - train: epoch 0160, iter [02400, 05004], lr: 0.010281, loss: 1.8240
2022-07-17 00:22:37 - train: epoch 0160, iter [02500, 05004], lr: 0.010271, loss: 1.9448
2022-07-17 00:23:10 - train: epoch 0160, iter [02600, 05004], lr: 0.010262, loss: 1.9001
2022-07-17 00:23:45 - train: epoch 0160, iter [02700, 05004], lr: 0.010252, loss: 2.0479
2022-07-17 00:24:20 - train: epoch 0160, iter [02800, 05004], lr: 0.010242, loss: 2.3162
2022-07-17 00:24:54 - train: epoch 0160, iter [02900, 05004], lr: 0.010232, loss: 2.1219
2022-07-17 00:25:28 - train: epoch 0160, iter [03000, 05004], lr: 0.010222, loss: 2.0024
2022-07-17 00:26:02 - train: epoch 0160, iter [03100, 05004], lr: 0.010213, loss: 2.2623
2022-07-17 00:26:37 - train: epoch 0160, iter [03200, 05004], lr: 0.010203, loss: 1.8666
2022-07-17 00:27:11 - train: epoch 0160, iter [03300, 05004], lr: 0.010193, loss: 1.9275
2022-07-17 00:27:45 - train: epoch 0160, iter [03400, 05004], lr: 0.010184, loss: 2.1694
2022-07-17 00:28:20 - train: epoch 0160, iter [03500, 05004], lr: 0.010174, loss: 2.0301
2022-07-17 00:28:54 - train: epoch 0160, iter [03600, 05004], lr: 0.010164, loss: 2.0544
2022-07-17 00:29:28 - train: epoch 0160, iter [03700, 05004], lr: 0.010154, loss: 1.9827
2022-07-17 00:30:02 - train: epoch 0160, iter [03800, 05004], lr: 0.010145, loss: 2.1393
2022-07-17 00:30:38 - train: epoch 0160, iter [03900, 05004], lr: 0.010135, loss: 2.0589
2022-07-17 00:31:11 - train: epoch 0160, iter [04000, 05004], lr: 0.010125, loss: 1.9998
2022-07-17 00:31:45 - train: epoch 0160, iter [04100, 05004], lr: 0.010115, loss: 2.0396
2022-07-17 00:32:20 - train: epoch 0160, iter [04200, 05004], lr: 0.010106, loss: 1.8085
2022-07-17 00:32:54 - train: epoch 0160, iter [04300, 05004], lr: 0.010096, loss: 2.0960
2022-07-17 00:33:28 - train: epoch 0160, iter [04400, 05004], lr: 0.010086, loss: 2.0452
2022-07-17 00:34:02 - train: epoch 0160, iter [04500, 05004], lr: 0.010077, loss: 2.0935
2022-07-17 00:34:37 - train: epoch 0160, iter [04600, 05004], lr: 0.010067, loss: 2.0885
2022-07-17 00:35:11 - train: epoch 0160, iter [04700, 05004], lr: 0.010057, loss: 2.0288
2022-07-17 00:35:45 - train: epoch 0160, iter [04800, 05004], lr: 0.010048, loss: 2.0430
2022-07-17 00:36:19 - train: epoch 0160, iter [04900, 05004], lr: 0.010038, loss: 1.9771
2022-07-17 00:36:53 - train: epoch 0160, iter [05000, 05004], lr: 0.010028, loss: 1.9176
2022-07-17 00:36:54 - train: epoch 160, train_loss: 2.0155
2022-07-17 00:38:08 - eval: epoch: 160, acc1: 72.692%, acc5: 91.124%, test_loss: 1.0913, per_image_load_time: 2.414ms, per_image_inference_time: 0.453ms
2022-07-17 00:38:08 - until epoch: 160, best_acc1: 72.692%
2022-07-17 00:38:08 - epoch 161 lr: 0.010028
2022-07-17 00:38:48 - train: epoch 0161, iter [00100, 05004], lr: 0.010018, loss: 1.9298
2022-07-17 00:39:22 - train: epoch 0161, iter [00200, 05004], lr: 0.010009, loss: 1.9018
2022-07-17 00:39:56 - train: epoch 0161, iter [00300, 05004], lr: 0.009999, loss: 1.7940
2022-07-17 00:40:30 - train: epoch 0161, iter [00400, 05004], lr: 0.009989, loss: 1.5911
2022-07-17 00:41:04 - train: epoch 0161, iter [00500, 05004], lr: 0.009980, loss: 1.6274
2022-07-17 00:41:37 - train: epoch 0161, iter [00600, 05004], lr: 0.009970, loss: 2.1787
2022-07-17 00:42:11 - train: epoch 0161, iter [00700, 05004], lr: 0.009960, loss: 2.1205
2022-07-17 00:42:45 - train: epoch 0161, iter [00800, 05004], lr: 0.009951, loss: 2.0599
2022-07-17 00:43:19 - train: epoch 0161, iter [00900, 05004], lr: 0.009941, loss: 1.9737
2022-07-17 00:43:52 - train: epoch 0161, iter [01000, 05004], lr: 0.009931, loss: 2.1309
2022-07-17 00:44:26 - train: epoch 0161, iter [01100, 05004], lr: 0.009922, loss: 1.9857
2022-07-17 00:44:59 - train: epoch 0161, iter [01200, 05004], lr: 0.009912, loss: 1.9900
2022-07-17 00:45:34 - train: epoch 0161, iter [01300, 05004], lr: 0.009902, loss: 2.2054
2022-07-17 00:46:07 - train: epoch 0161, iter [01400, 05004], lr: 0.009893, loss: 1.9150
2022-07-17 00:46:41 - train: epoch 0161, iter [01500, 05004], lr: 0.009883, loss: 1.9959
2022-07-17 00:47:16 - train: epoch 0161, iter [01600, 05004], lr: 0.009874, loss: 1.9401
2022-07-17 00:47:50 - train: epoch 0161, iter [01700, 05004], lr: 0.009864, loss: 2.3210
2022-07-17 00:48:23 - train: epoch 0161, iter [01800, 05004], lr: 0.009854, loss: 2.1641
2022-07-17 00:48:57 - train: epoch 0161, iter [01900, 05004], lr: 0.009845, loss: 2.0128
2022-07-17 00:49:30 - train: epoch 0161, iter [02000, 05004], lr: 0.009835, loss: 1.8247
2022-07-17 00:50:04 - train: epoch 0161, iter [02100, 05004], lr: 0.009826, loss: 2.2738
2022-07-17 00:50:38 - train: epoch 0161, iter [02200, 05004], lr: 0.009816, loss: 1.9937
2022-07-17 00:51:12 - train: epoch 0161, iter [02300, 05004], lr: 0.009807, loss: 1.6929
2022-07-17 00:51:46 - train: epoch 0161, iter [02400, 05004], lr: 0.009797, loss: 1.9736
2022-07-17 00:52:20 - train: epoch 0161, iter [02500, 05004], lr: 0.009787, loss: 2.0084
2022-07-17 00:52:54 - train: epoch 0161, iter [02600, 05004], lr: 0.009778, loss: 2.3128
2022-07-17 00:53:29 - train: epoch 0161, iter [02700, 05004], lr: 0.009768, loss: 1.8368
2022-07-17 00:54:02 - train: epoch 0161, iter [02800, 05004], lr: 0.009759, loss: 1.8637
2022-07-17 00:54:36 - train: epoch 0161, iter [02900, 05004], lr: 0.009749, loss: 1.8268
2022-07-17 00:55:11 - train: epoch 0161, iter [03000, 05004], lr: 0.009740, loss: 1.8503
2022-07-17 00:55:45 - train: epoch 0161, iter [03100, 05004], lr: 0.009730, loss: 1.9177
2022-07-17 00:56:19 - train: epoch 0161, iter [03200, 05004], lr: 0.009721, loss: 2.0080
2022-07-17 00:56:54 - train: epoch 0161, iter [03300, 05004], lr: 0.009711, loss: 2.0843
2022-07-17 00:57:27 - train: epoch 0161, iter [03400, 05004], lr: 0.009701, loss: 1.7718
2022-07-17 00:58:00 - train: epoch 0161, iter [03500, 05004], lr: 0.009692, loss: 1.9561
2022-07-17 00:58:35 - train: epoch 0161, iter [03600, 05004], lr: 0.009682, loss: 2.1607
2022-07-17 00:59:10 - train: epoch 0161, iter [03700, 05004], lr: 0.009673, loss: 1.8275
2022-07-17 00:59:44 - train: epoch 0161, iter [03800, 05004], lr: 0.009663, loss: 2.1254
2022-07-17 01:00:18 - train: epoch 0161, iter [03900, 05004], lr: 0.009654, loss: 2.0573
2022-07-17 01:00:52 - train: epoch 0161, iter [04000, 05004], lr: 0.009644, loss: 2.0623
2022-07-17 01:01:26 - train: epoch 0161, iter [04100, 05004], lr: 0.009635, loss: 1.9326
2022-07-17 01:02:00 - train: epoch 0161, iter [04200, 05004], lr: 0.009625, loss: 2.2298
2022-07-17 01:02:33 - train: epoch 0161, iter [04300, 05004], lr: 0.009616, loss: 2.1765
2022-07-17 01:03:08 - train: epoch 0161, iter [04400, 05004], lr: 0.009606, loss: 2.2132
2022-07-17 01:03:42 - train: epoch 0161, iter [04500, 05004], lr: 0.009597, loss: 2.0327
2022-07-17 01:04:16 - train: epoch 0161, iter [04600, 05004], lr: 0.009587, loss: 2.2311
2022-07-17 01:04:51 - train: epoch 0161, iter [04700, 05004], lr: 0.009578, loss: 2.0394
2022-07-17 01:05:25 - train: epoch 0161, iter [04800, 05004], lr: 0.009568, loss: 2.0792
2022-07-17 01:05:58 - train: epoch 0161, iter [04900, 05004], lr: 0.009559, loss: 1.5796
2022-07-17 01:06:31 - train: epoch 0161, iter [05000, 05004], lr: 0.009550, loss: 1.9778
2022-07-17 01:06:32 - train: epoch 161, train_loss: 2.0032
2022-07-17 01:07:47 - eval: epoch: 161, acc1: 72.592%, acc5: 91.142%, test_loss: 1.1023, per_image_load_time: 2.463ms, per_image_inference_time: 0.439ms
2022-07-17 01:07:48 - until epoch: 161, best_acc1: 72.692%
2022-07-17 01:07:48 - epoch 162 lr: 0.009549
2022-07-17 01:08:28 - train: epoch 0162, iter [00100, 05004], lr: 0.009540, loss: 1.8017
2022-07-17 01:09:02 - train: epoch 0162, iter [00200, 05004], lr: 0.009530, loss: 1.7628
2022-07-17 01:09:36 - train: epoch 0162, iter [00300, 05004], lr: 0.009521, loss: 1.8619
2022-07-17 01:10:10 - train: epoch 0162, iter [00400, 05004], lr: 0.009511, loss: 2.2707
2022-07-17 01:10:45 - train: epoch 0162, iter [00500, 05004], lr: 0.009502, loss: 1.8724
2022-07-17 01:11:20 - train: epoch 0162, iter [00600, 05004], lr: 0.009492, loss: 1.8963
2022-07-17 01:11:54 - train: epoch 0162, iter [00700, 05004], lr: 0.009483, loss: 1.8743
2022-07-17 01:12:28 - train: epoch 0162, iter [00800, 05004], lr: 0.009474, loss: 2.1094
2022-07-17 01:13:02 - train: epoch 0162, iter [00900, 05004], lr: 0.009464, loss: 1.8954
2022-07-17 01:13:37 - train: epoch 0162, iter [01000, 05004], lr: 0.009455, loss: 1.8360
2022-07-17 01:14:12 - train: epoch 0162, iter [01100, 05004], lr: 0.009445, loss: 2.1158
2022-07-17 01:14:46 - train: epoch 0162, iter [01200, 05004], lr: 0.009436, loss: 2.1293
2022-07-17 01:15:20 - train: epoch 0162, iter [01300, 05004], lr: 0.009426, loss: 2.0299
2022-07-17 01:15:55 - train: epoch 0162, iter [01400, 05004], lr: 0.009417, loss: 2.0419
2022-07-17 01:16:30 - train: epoch 0162, iter [01500, 05004], lr: 0.009408, loss: 1.8905
2022-07-17 01:17:05 - train: epoch 0162, iter [01600, 05004], lr: 0.009398, loss: 1.9379
2022-07-17 01:17:39 - train: epoch 0162, iter [01700, 05004], lr: 0.009389, loss: 1.8561
2022-07-17 01:18:13 - train: epoch 0162, iter [01800, 05004], lr: 0.009380, loss: 1.8348
2022-07-17 01:18:48 - train: epoch 0162, iter [01900, 05004], lr: 0.009370, loss: 2.0248
2022-07-17 01:19:22 - train: epoch 0162, iter [02000, 05004], lr: 0.009361, loss: 1.9305
2022-07-17 01:19:57 - train: epoch 0162, iter [02100, 05004], lr: 0.009351, loss: 2.0544
2022-07-17 01:20:30 - train: epoch 0162, iter [02200, 05004], lr: 0.009342, loss: 1.6704
2022-07-17 01:21:05 - train: epoch 0162, iter [02300, 05004], lr: 0.009333, loss: 1.8766
2022-07-17 01:21:38 - train: epoch 0162, iter [02400, 05004], lr: 0.009323, loss: 1.9920
2022-07-17 01:22:12 - train: epoch 0162, iter [02500, 05004], lr: 0.009314, loss: 2.1421
2022-07-17 01:22:47 - train: epoch 0162, iter [02600, 05004], lr: 0.009305, loss: 2.0686
2022-07-17 01:23:20 - train: epoch 0162, iter [02700, 05004], lr: 0.009295, loss: 2.0011
2022-07-17 01:23:54 - train: epoch 0162, iter [02800, 05004], lr: 0.009286, loss: 1.9575
2022-07-17 01:24:29 - train: epoch 0162, iter [02900, 05004], lr: 0.009277, loss: 2.0071
2022-07-17 01:25:03 - train: epoch 0162, iter [03000, 05004], lr: 0.009267, loss: 2.0872
2022-07-17 01:25:38 - train: epoch 0162, iter [03100, 05004], lr: 0.009258, loss: 2.1504
2022-07-17 01:26:11 - train: epoch 0162, iter [03200, 05004], lr: 0.009249, loss: 1.9286
2022-07-17 01:26:45 - train: epoch 0162, iter [03300, 05004], lr: 0.009239, loss: 2.0852
2022-07-17 01:27:20 - train: epoch 0162, iter [03400, 05004], lr: 0.009230, loss: 2.0238
2022-07-17 01:27:53 - train: epoch 0162, iter [03500, 05004], lr: 0.009221, loss: 2.0849
2022-07-17 01:28:28 - train: epoch 0162, iter [03600, 05004], lr: 0.009211, loss: 2.2496
2022-07-17 01:29:02 - train: epoch 0162, iter [03700, 05004], lr: 0.009202, loss: 2.0538
2022-07-17 01:29:36 - train: epoch 0162, iter [03800, 05004], lr: 0.009193, loss: 1.8154
2022-07-17 01:30:10 - train: epoch 0162, iter [03900, 05004], lr: 0.009183, loss: 2.2103
2022-07-17 01:30:44 - train: epoch 0162, iter [04000, 05004], lr: 0.009174, loss: 1.9085
2022-07-17 01:31:19 - train: epoch 0162, iter [04100, 05004], lr: 0.009165, loss: 2.1911
2022-07-17 01:31:53 - train: epoch 0162, iter [04200, 05004], lr: 0.009155, loss: 2.1033
2022-07-17 01:32:27 - train: epoch 0162, iter [04300, 05004], lr: 0.009146, loss: 1.7218
2022-07-17 01:33:01 - train: epoch 0162, iter [04400, 05004], lr: 0.009137, loss: 1.9535
2022-07-17 01:33:36 - train: epoch 0162, iter [04500, 05004], lr: 0.009128, loss: 1.8842
2022-07-17 01:34:10 - train: epoch 0162, iter [04600, 05004], lr: 0.009118, loss: 2.0590
2022-07-17 01:34:45 - train: epoch 0162, iter [04700, 05004], lr: 0.009109, loss: 2.0145
2022-07-17 01:35:19 - train: epoch 0162, iter [04800, 05004], lr: 0.009100, loss: 2.0797
2022-07-17 01:35:53 - train: epoch 0162, iter [04900, 05004], lr: 0.009091, loss: 2.1912
2022-07-17 01:36:26 - train: epoch 0162, iter [05000, 05004], lr: 0.009081, loss: 2.0840
2022-07-17 01:36:27 - train: epoch 162, train_loss: 1.9893
2022-07-17 01:37:42 - eval: epoch: 162, acc1: 73.088%, acc5: 91.592%, test_loss: 1.0790, per_image_load_time: 2.435ms, per_image_inference_time: 0.452ms
2022-07-17 01:37:42 - until epoch: 162, best_acc1: 73.088%
2022-07-17 01:37:42 - epoch 163 lr: 0.009081
2022-07-17 01:38:21 - train: epoch 0163, iter [00100, 05004], lr: 0.009072, loss: 2.0383
2022-07-17 01:38:55 - train: epoch 0163, iter [00200, 05004], lr: 0.009062, loss: 1.9170
2022-07-17 01:39:30 - train: epoch 0163, iter [00300, 05004], lr: 0.009053, loss: 1.8870
2022-07-17 01:40:04 - train: epoch 0163, iter [00400, 05004], lr: 0.009044, loss: 2.1534
2022-07-17 01:40:38 - train: epoch 0163, iter [00500, 05004], lr: 0.009035, loss: 2.1946
2022-07-17 01:41:12 - train: epoch 0163, iter [00600, 05004], lr: 0.009026, loss: 2.0368
2022-07-17 01:41:45 - train: epoch 0163, iter [00700, 05004], lr: 0.009016, loss: 1.8617
2022-07-17 01:42:20 - train: epoch 0163, iter [00800, 05004], lr: 0.009007, loss: 1.9727
2022-07-17 01:42:53 - train: epoch 0163, iter [00900, 05004], lr: 0.008998, loss: 2.1929
2022-07-17 01:43:28 - train: epoch 0163, iter [01000, 05004], lr: 0.008989, loss: 1.9901
2022-07-17 01:44:01 - train: epoch 0163, iter [01100, 05004], lr: 0.008979, loss: 1.9834
2022-07-17 01:44:35 - train: epoch 0163, iter [01200, 05004], lr: 0.008970, loss: 1.9308
2022-07-17 01:45:09 - train: epoch 0163, iter [01300, 05004], lr: 0.008961, loss: 1.8491
2022-07-17 01:45:43 - train: epoch 0163, iter [01400, 05004], lr: 0.008952, loss: 1.8427
2022-07-17 01:46:17 - train: epoch 0163, iter [01500, 05004], lr: 0.008943, loss: 2.3370
2022-07-17 01:46:51 - train: epoch 0163, iter [01600, 05004], lr: 0.008933, loss: 1.7994
2022-07-17 01:47:26 - train: epoch 0163, iter [01700, 05004], lr: 0.008924, loss: 2.0316
2022-07-17 01:48:00 - train: epoch 0163, iter [01800, 05004], lr: 0.008915, loss: 1.8861
2022-07-17 01:48:33 - train: epoch 0163, iter [01900, 05004], lr: 0.008906, loss: 1.8138
2022-07-17 01:49:07 - train: epoch 0163, iter [02000, 05004], lr: 0.008897, loss: 2.0356
2022-07-17 01:49:41 - train: epoch 0163, iter [02100, 05004], lr: 0.008888, loss: 1.8920
2022-07-17 01:50:15 - train: epoch 0163, iter [02200, 05004], lr: 0.008878, loss: 1.9903
2022-07-17 01:50:49 - train: epoch 0163, iter [02300, 05004], lr: 0.008869, loss: 2.1452
2022-07-17 01:51:23 - train: epoch 0163, iter [02400, 05004], lr: 0.008860, loss: 2.0863
2022-07-17 01:51:57 - train: epoch 0163, iter [02500, 05004], lr: 0.008851, loss: 2.1110
2022-07-17 01:52:32 - train: epoch 0163, iter [02600, 05004], lr: 0.008842, loss: 1.9966
2022-07-17 01:53:06 - train: epoch 0163, iter [02700, 05004], lr: 0.008833, loss: 1.9524
2022-07-17 01:53:40 - train: epoch 0163, iter [02800, 05004], lr: 0.008824, loss: 1.9457
2022-07-17 01:54:14 - train: epoch 0163, iter [02900, 05004], lr: 0.008814, loss: 1.9385
2022-07-17 01:54:48 - train: epoch 0163, iter [03000, 05004], lr: 0.008805, loss: 1.9509
2022-07-17 01:55:22 - train: epoch 0163, iter [03100, 05004], lr: 0.008796, loss: 1.8125
2022-07-17 01:55:56 - train: epoch 0163, iter [03200, 05004], lr: 0.008787, loss: 1.9597
2022-07-17 01:56:30 - train: epoch 0163, iter [03300, 05004], lr: 0.008778, loss: 2.0592
2022-07-17 01:57:04 - train: epoch 0163, iter [03400, 05004], lr: 0.008769, loss: 2.2005
2022-07-17 01:57:39 - train: epoch 0163, iter [03500, 05004], lr: 0.008760, loss: 2.0233
2022-07-17 01:58:13 - train: epoch 0163, iter [03600, 05004], lr: 0.008751, loss: 1.4813
2022-07-17 01:58:47 - train: epoch 0163, iter [03700, 05004], lr: 0.008742, loss: 1.9870
2022-07-17 01:59:22 - train: epoch 0163, iter [03800, 05004], lr: 0.008732, loss: 1.8984
2022-07-17 01:59:55 - train: epoch 0163, iter [03900, 05004], lr: 0.008723, loss: 1.9716
2022-07-17 02:00:29 - train: epoch 0163, iter [04000, 05004], lr: 0.008714, loss: 1.9675
2022-07-17 02:01:04 - train: epoch 0163, iter [04100, 05004], lr: 0.008705, loss: 1.9868
2022-07-17 02:01:38 - train: epoch 0163, iter [04200, 05004], lr: 0.008696, loss: 1.7517
2022-07-17 02:02:12 - train: epoch 0163, iter [04300, 05004], lr: 0.008687, loss: 2.1070
2022-07-17 02:02:46 - train: epoch 0163, iter [04400, 05004], lr: 0.008678, loss: 2.1447
2022-07-17 02:03:21 - train: epoch 0163, iter [04500, 05004], lr: 0.008669, loss: 1.8308
2022-07-17 02:03:56 - train: epoch 0163, iter [04600, 05004], lr: 0.008660, loss: 1.7503
2022-07-17 02:04:30 - train: epoch 0163, iter [04700, 05004], lr: 0.008651, loss: 1.9551
2022-07-17 02:05:04 - train: epoch 0163, iter [04800, 05004], lr: 0.008642, loss: 2.1752
2022-07-17 02:05:38 - train: epoch 0163, iter [04900, 05004], lr: 0.008633, loss: 2.0644
2022-07-17 02:06:11 - train: epoch 0163, iter [05000, 05004], lr: 0.008624, loss: 1.9019
2022-07-17 02:06:12 - train: epoch 163, train_loss: 1.9803
2022-07-17 02:07:28 - eval: epoch: 163, acc1: 72.698%, acc5: 91.194%, test_loss: 1.0953, per_image_load_time: 2.475ms, per_image_inference_time: 0.457ms
2022-07-17 02:07:28 - until epoch: 163, best_acc1: 73.088%
2022-07-17 02:07:28 - epoch 164 lr: 0.008623
2022-07-17 02:08:08 - train: epoch 0164, iter [00100, 05004], lr: 0.008614, loss: 1.8578
2022-07-17 02:08:41 - train: epoch 0164, iter [00200, 05004], lr: 0.008605, loss: 1.9344
2022-07-17 02:09:15 - train: epoch 0164, iter [00300, 05004], lr: 0.008596, loss: 2.2310
2022-07-17 02:09:50 - train: epoch 0164, iter [00400, 05004], lr: 0.008587, loss: 1.8587
2022-07-17 02:10:25 - train: epoch 0164, iter [00500, 05004], lr: 0.008578, loss: 1.8885
2022-07-17 02:10:59 - train: epoch 0164, iter [00600, 05004], lr: 0.008569, loss: 2.0077
2022-07-17 02:11:33 - train: epoch 0164, iter [00700, 05004], lr: 0.008560, loss: 2.3370
2022-07-17 02:12:07 - train: epoch 0164, iter [00800, 05004], lr: 0.008551, loss: 2.2489
2022-07-17 02:12:41 - train: epoch 0164, iter [00900, 05004], lr: 0.008542, loss: 1.6889
2022-07-17 02:13:15 - train: epoch 0164, iter [01000, 05004], lr: 0.008533, loss: 2.0956
2022-07-17 02:13:49 - train: epoch 0164, iter [01100, 05004], lr: 0.008524, loss: 2.0086
2022-07-17 02:14:24 - train: epoch 0164, iter [01200, 05004], lr: 0.008515, loss: 2.0015
2022-07-17 02:14:58 - train: epoch 0164, iter [01300, 05004], lr: 0.008506, loss: 1.7691
2022-07-17 02:15:33 - train: epoch 0164, iter [01400, 05004], lr: 0.008497, loss: 1.7607
2022-07-17 02:16:07 - train: epoch 0164, iter [01500, 05004], lr: 0.008488, loss: 2.3132
2022-07-17 02:16:40 - train: epoch 0164, iter [01600, 05004], lr: 0.008479, loss: 2.2114
2022-07-17 02:17:14 - train: epoch 0164, iter [01700, 05004], lr: 0.008470, loss: 2.0545
2022-07-17 02:17:50 - train: epoch 0164, iter [01800, 05004], lr: 0.008461, loss: 1.8077
2022-07-17 02:18:24 - train: epoch 0164, iter [01900, 05004], lr: 0.008452, loss: 2.0869
2022-07-17 02:18:58 - train: epoch 0164, iter [02000, 05004], lr: 0.008443, loss: 1.6905
2022-07-17 02:19:32 - train: epoch 0164, iter [02100, 05004], lr: 0.008435, loss: 2.0697
2022-07-17 02:20:07 - train: epoch 0164, iter [02200, 05004], lr: 0.008426, loss: 2.2278
2022-07-17 02:20:42 - train: epoch 0164, iter [02300, 05004], lr: 0.008417, loss: 2.2982
2022-07-17 02:21:16 - train: epoch 0164, iter [02400, 05004], lr: 0.008408, loss: 1.9288
2022-07-17 02:21:50 - train: epoch 0164, iter [02500, 05004], lr: 0.008399, loss: 2.0047
2022-07-17 02:22:25 - train: epoch 0164, iter [02600, 05004], lr: 0.008390, loss: 2.0259
2022-07-17 02:22:59 - train: epoch 0164, iter [02700, 05004], lr: 0.008381, loss: 1.9396
2022-07-17 02:23:34 - train: epoch 0164, iter [02800, 05004], lr: 0.008372, loss: 2.1720
2022-07-17 02:24:07 - train: epoch 0164, iter [02900, 05004], lr: 0.008363, loss: 1.9368
2022-07-17 02:24:43 - train: epoch 0164, iter [03000, 05004], lr: 0.008354, loss: 2.0270
2022-07-17 02:25:18 - train: epoch 0164, iter [03100, 05004], lr: 0.008345, loss: 1.6349
2022-07-17 02:25:52 - train: epoch 0164, iter [03200, 05004], lr: 0.008336, loss: 2.2232
2022-07-17 02:26:27 - train: epoch 0164, iter [03300, 05004], lr: 0.008327, loss: 1.9514
2022-07-17 02:27:01 - train: epoch 0164, iter [03400, 05004], lr: 0.008319, loss: 2.0018
2022-07-17 02:27:36 - train: epoch 0164, iter [03500, 05004], lr: 0.008310, loss: 2.1108
2022-07-17 02:28:11 - train: epoch 0164, iter [03600, 05004], lr: 0.008301, loss: 2.0702
2022-07-17 02:28:46 - train: epoch 0164, iter [03700, 05004], lr: 0.008292, loss: 1.8663
2022-07-17 02:29:20 - train: epoch 0164, iter [03800, 05004], lr: 0.008283, loss: 1.9034
2022-07-17 02:29:55 - train: epoch 0164, iter [03900, 05004], lr: 0.008274, loss: 1.8789
2022-07-17 02:30:30 - train: epoch 0164, iter [04000, 05004], lr: 0.008265, loss: 2.0007
2022-07-17 02:31:04 - train: epoch 0164, iter [04100, 05004], lr: 0.008256, loss: 1.7199
2022-07-17 02:31:38 - train: epoch 0164, iter [04200, 05004], lr: 0.008248, loss: 2.2779
2022-07-17 02:32:13 - train: epoch 0164, iter [04300, 05004], lr: 0.008239, loss: 1.9733
2022-07-17 02:32:48 - train: epoch 0164, iter [04400, 05004], lr: 0.008230, loss: 1.7650
2022-07-17 02:33:23 - train: epoch 0164, iter [04500, 05004], lr: 0.008221, loss: 1.9646
2022-07-17 02:33:57 - train: epoch 0164, iter [04600, 05004], lr: 0.008212, loss: 2.0367
2022-07-17 02:34:31 - train: epoch 0164, iter [04700, 05004], lr: 0.008203, loss: 2.0885
2022-07-17 02:35:05 - train: epoch 0164, iter [04800, 05004], lr: 0.008194, loss: 1.7950
2022-07-17 02:35:40 - train: epoch 0164, iter [04900, 05004], lr: 0.008186, loss: 1.9019
2022-07-17 02:36:13 - train: epoch 0164, iter [05000, 05004], lr: 0.008177, loss: 2.1375
2022-07-17 02:36:14 - train: epoch 164, train_loss: 1.9691
2022-07-17 02:37:30 - eval: epoch: 164, acc1: 73.460%, acc5: 91.652%, test_loss: 1.0561, per_image_load_time: 2.329ms, per_image_inference_time: 0.483ms
2022-07-17 02:37:30 - until epoch: 164, best_acc1: 73.460%
2022-07-17 02:37:30 - epoch 165 lr: 0.008176
2022-07-17 02:38:10 - train: epoch 0165, iter [00100, 05004], lr: 0.008168, loss: 2.1074
2022-07-17 02:38:44 - train: epoch 0165, iter [00200, 05004], lr: 0.008159, loss: 1.9634
2022-07-17 02:39:18 - train: epoch 0165, iter [00300, 05004], lr: 0.008150, loss: 1.9143
2022-07-17 02:39:53 - train: epoch 0165, iter [00400, 05004], lr: 0.008141, loss: 2.0812
2022-07-17 02:40:28 - train: epoch 0165, iter [00500, 05004], lr: 0.008132, loss: 2.0115
2022-07-17 02:41:02 - train: epoch 0165, iter [00600, 05004], lr: 0.008124, loss: 2.0106
2022-07-17 02:41:37 - train: epoch 0165, iter [00700, 05004], lr: 0.008115, loss: 2.1571
2022-07-17 02:42:10 - train: epoch 0165, iter [00800, 05004], lr: 0.008106, loss: 1.8138
2022-07-17 02:42:45 - train: epoch 0165, iter [00900, 05004], lr: 0.008097, loss: 1.8083
2022-07-17 02:43:19 - train: epoch 0165, iter [01000, 05004], lr: 0.008088, loss: 1.8490
2022-07-17 02:43:54 - train: epoch 0165, iter [01100, 05004], lr: 0.008080, loss: 1.9330
2022-07-17 02:44:28 - train: epoch 0165, iter [01200, 05004], lr: 0.008071, loss: 2.0982
2022-07-17 02:45:02 - train: epoch 0165, iter [01300, 05004], lr: 0.008062, loss: 2.0008
2022-07-17 02:45:37 - train: epoch 0165, iter [01400, 05004], lr: 0.008053, loss: 2.1581
2022-07-17 02:46:11 - train: epoch 0165, iter [01500, 05004], lr: 0.008045, loss: 1.8336
2022-07-17 02:46:46 - train: epoch 0165, iter [01600, 05004], lr: 0.008036, loss: 2.1713
2022-07-17 02:47:21 - train: epoch 0165, iter [01700, 05004], lr: 0.008027, loss: 2.1001
2022-07-17 02:47:55 - train: epoch 0165, iter [01800, 05004], lr: 0.008018, loss: 1.8949
2022-07-17 02:48:30 - train: epoch 0165, iter [01900, 05004], lr: 0.008010, loss: 1.7976
2022-07-17 02:49:05 - train: epoch 0165, iter [02000, 05004], lr: 0.008001, loss: 2.3062
2022-07-17 02:49:39 - train: epoch 0165, iter [02100, 05004], lr: 0.007992, loss: 1.8675
2022-07-17 02:50:14 - train: epoch 0165, iter [02200, 05004], lr: 0.007983, loss: 1.9981
2022-07-17 02:50:48 - train: epoch 0165, iter [02300, 05004], lr: 0.007975, loss: 1.9501
2022-07-17 02:51:23 - train: epoch 0165, iter [02400, 05004], lr: 0.007966, loss: 2.0832
2022-07-17 02:51:58 - train: epoch 0165, iter [02500, 05004], lr: 0.007957, loss: 1.8081
2022-07-17 02:52:32 - train: epoch 0165, iter [02600, 05004], lr: 0.007949, loss: 2.0814
2022-07-17 02:53:06 - train: epoch 0165, iter [02700, 05004], lr: 0.007940, loss: 1.8066
2022-07-17 02:53:40 - train: epoch 0165, iter [02800, 05004], lr: 0.007931, loss: 2.2257
2022-07-17 02:54:16 - train: epoch 0165, iter [02900, 05004], lr: 0.007922, loss: 2.3168
2022-07-17 02:54:49 - train: epoch 0165, iter [03000, 05004], lr: 0.007914, loss: 2.0017
2022-07-17 02:55:25 - train: epoch 0165, iter [03100, 05004], lr: 0.007905, loss: 1.7284
2022-07-17 02:55:59 - train: epoch 0165, iter [03200, 05004], lr: 0.007896, loss: 1.6727
2022-07-17 02:56:32 - train: epoch 0165, iter [03300, 05004], lr: 0.007888, loss: 1.9454
2022-07-17 02:57:07 - train: epoch 0165, iter [03400, 05004], lr: 0.007879, loss: 2.4074
2022-07-17 02:57:42 - train: epoch 0165, iter [03500, 05004], lr: 0.007870, loss: 2.0295
2022-07-17 02:58:16 - train: epoch 0165, iter [03600, 05004], lr: 0.007862, loss: 2.0788
2022-07-17 02:58:51 - train: epoch 0165, iter [03700, 05004], lr: 0.007853, loss: 1.7867
2022-07-17 02:59:26 - train: epoch 0165, iter [03800, 05004], lr: 0.007844, loss: 1.7856
2022-07-17 03:00:00 - train: epoch 0165, iter [03900, 05004], lr: 0.007836, loss: 1.7294
2022-07-17 03:00:34 - train: epoch 0165, iter [04000, 05004], lr: 0.007827, loss: 1.6944
2022-07-17 03:01:09 - train: epoch 0165, iter [04100, 05004], lr: 0.007818, loss: 2.0862
2022-07-17 03:01:43 - train: epoch 0165, iter [04200, 05004], lr: 0.007810, loss: 2.1562
2022-07-17 03:02:18 - train: epoch 0165, iter [04300, 05004], lr: 0.007801, loss: 1.9277
2022-07-17 03:02:53 - train: epoch 0165, iter [04400, 05004], lr: 0.007793, loss: 1.8560
2022-07-17 03:03:27 - train: epoch 0165, iter [04500, 05004], lr: 0.007784, loss: 1.8000
2022-07-17 03:04:02 - train: epoch 0165, iter [04600, 05004], lr: 0.007775, loss: 1.9559
2022-07-17 03:04:36 - train: epoch 0165, iter [04700, 05004], lr: 0.007767, loss: 1.7828
2022-07-17 03:05:10 - train: epoch 0165, iter [04800, 05004], lr: 0.007758, loss: 1.8305
2022-07-17 03:05:45 - train: epoch 0165, iter [04900, 05004], lr: 0.007749, loss: 1.9188
2022-07-17 03:06:18 - train: epoch 0165, iter [05000, 05004], lr: 0.007741, loss: 1.6875
2022-07-17 03:06:19 - train: epoch 165, train_loss: 1.9579
2022-07-17 03:07:34 - eval: epoch: 165, acc1: 74.072%, acc5: 92.010%, test_loss: 1.0403, per_image_load_time: 2.412ms, per_image_inference_time: 0.469ms
2022-07-17 03:07:34 - until epoch: 165, best_acc1: 74.072%
2022-07-17 03:07:34 - epoch 166 lr: 0.007740
2022-07-17 03:08:13 - train: epoch 0166, iter [00100, 05004], lr: 0.007732, loss: 1.8953
2022-07-17 03:08:47 - train: epoch 0166, iter [00200, 05004], lr: 0.007723, loss: 2.0095
2022-07-17 03:09:22 - train: epoch 0166, iter [00300, 05004], lr: 0.007715, loss: 1.9720
2022-07-17 03:09:55 - train: epoch 0166, iter [00400, 05004], lr: 0.007706, loss: 1.9911
2022-07-17 03:10:30 - train: epoch 0166, iter [00500, 05004], lr: 0.007698, loss: 1.7858
2022-07-17 03:11:04 - train: epoch 0166, iter [00600, 05004], lr: 0.007689, loss: 2.0168
2022-07-17 03:11:38 - train: epoch 0166, iter [00700, 05004], lr: 0.007680, loss: 1.8351
2022-07-17 03:12:12 - train: epoch 0166, iter [00800, 05004], lr: 0.007672, loss: 2.2719
2022-07-17 03:12:46 - train: epoch 0166, iter [00900, 05004], lr: 0.007663, loss: 1.9898
2022-07-17 03:13:20 - train: epoch 0166, iter [01000, 05004], lr: 0.007655, loss: 1.7719
2022-07-17 03:13:54 - train: epoch 0166, iter [01100, 05004], lr: 0.007646, loss: 2.1438
2022-07-17 03:14:29 - train: epoch 0166, iter [01200, 05004], lr: 0.007638, loss: 2.1183
2022-07-17 03:15:02 - train: epoch 0166, iter [01300, 05004], lr: 0.007629, loss: 2.2565
2022-07-17 03:15:37 - train: epoch 0166, iter [01400, 05004], lr: 0.007620, loss: 2.1195
2022-07-17 03:16:10 - train: epoch 0166, iter [01500, 05004], lr: 0.007612, loss: 1.9589
2022-07-17 03:16:46 - train: epoch 0166, iter [01600, 05004], lr: 0.007603, loss: 1.9285
2022-07-17 03:17:19 - train: epoch 0166, iter [01700, 05004], lr: 0.007595, loss: 1.9431
2022-07-17 03:17:53 - train: epoch 0166, iter [01800, 05004], lr: 0.007586, loss: 1.5396
2022-07-17 03:18:27 - train: epoch 0166, iter [01900, 05004], lr: 0.007578, loss: 1.9913
2022-07-17 03:19:01 - train: epoch 0166, iter [02000, 05004], lr: 0.007569, loss: 1.8292
2022-07-17 03:19:34 - train: epoch 0166, iter [02100, 05004], lr: 0.007561, loss: 1.9981
2022-07-17 03:20:09 - train: epoch 0166, iter [02200, 05004], lr: 0.007552, loss: 1.8017
2022-07-17 03:20:42 - train: epoch 0166, iter [02300, 05004], lr: 0.007544, loss: 1.9051
2022-07-17 03:21:16 - train: epoch 0166, iter [02400, 05004], lr: 0.007535, loss: 2.0819
2022-07-17 03:21:51 - train: epoch 0166, iter [02500, 05004], lr: 0.007527, loss: 1.8079
2022-07-17 03:22:25 - train: epoch 0166, iter [02600, 05004], lr: 0.007518, loss: 1.8929
2022-07-17 03:22:59 - train: epoch 0166, iter [02700, 05004], lr: 0.007510, loss: 2.0377
2022-07-17 03:23:33 - train: epoch 0166, iter [02800, 05004], lr: 0.007501, loss: 2.0003
2022-07-17 03:24:07 - train: epoch 0166, iter [02900, 05004], lr: 0.007493, loss: 2.0609
2022-07-17 03:24:42 - train: epoch 0166, iter [03000, 05004], lr: 0.007484, loss: 1.9520
2022-07-17 03:25:16 - train: epoch 0166, iter [03100, 05004], lr: 0.007476, loss: 1.9981
2022-07-17 03:25:50 - train: epoch 0166, iter [03200, 05004], lr: 0.007467, loss: 1.8533
2022-07-17 03:26:24 - train: epoch 0166, iter [03300, 05004], lr: 0.007459, loss: 2.1335
2022-07-17 03:26:58 - train: epoch 0166, iter [03400, 05004], lr: 0.007451, loss: 2.1619
2022-07-17 03:27:32 - train: epoch 0166, iter [03500, 05004], lr: 0.007442, loss: 1.8759
2022-07-17 03:28:06 - train: epoch 0166, iter [03600, 05004], lr: 0.007434, loss: 1.8589
2022-07-17 03:28:41 - train: epoch 0166, iter [03700, 05004], lr: 0.007425, loss: 1.8835
2022-07-17 03:29:15 - train: epoch 0166, iter [03800, 05004], lr: 0.007417, loss: 1.9986
2022-07-17 03:29:49 - train: epoch 0166, iter [03900, 05004], lr: 0.007408, loss: 2.0816
2022-07-17 03:30:22 - train: epoch 0166, iter [04000, 05004], lr: 0.007400, loss: 2.0867
2022-07-17 03:30:56 - train: epoch 0166, iter [04100, 05004], lr: 0.007391, loss: 1.9400
2022-07-17 03:31:32 - train: epoch 0166, iter [04200, 05004], lr: 0.007383, loss: 1.8664
2022-07-17 03:32:05 - train: epoch 0166, iter [04300, 05004], lr: 0.007375, loss: 1.9311
2022-07-17 03:32:39 - train: epoch 0166, iter [04400, 05004], lr: 0.007366, loss: 1.8592
2022-07-17 03:33:12 - train: epoch 0166, iter [04500, 05004], lr: 0.007358, loss: 2.0829
2022-07-17 03:33:47 - train: epoch 0166, iter [04600, 05004], lr: 0.007349, loss: 2.0674
2022-07-17 03:34:20 - train: epoch 0166, iter [04700, 05004], lr: 0.007341, loss: 2.0261
2022-07-17 03:34:54 - train: epoch 0166, iter [04800, 05004], lr: 0.007333, loss: 1.8695
2022-07-17 03:35:28 - train: epoch 0166, iter [04900, 05004], lr: 0.007324, loss: 1.9009
2022-07-17 03:36:01 - train: epoch 0166, iter [05000, 05004], lr: 0.007316, loss: 1.7206
2022-07-17 03:36:02 - train: epoch 166, train_loss: 1.9435
2022-07-17 03:37:17 - eval: epoch: 166, acc1: 73.692%, acc5: 91.788%, test_loss: 1.0452, per_image_load_time: 2.414ms, per_image_inference_time: 0.472ms
2022-07-17 03:37:18 - until epoch: 166, best_acc1: 74.072%
2022-07-17 03:37:18 - epoch 167 lr: 0.007315
2022-07-17 03:37:58 - train: epoch 0167, iter [00100, 05004], lr: 0.007307, loss: 1.7710
2022-07-17 03:38:31 - train: epoch 0167, iter [00200, 05004], lr: 0.007299, loss: 1.9419
2022-07-17 03:39:05 - train: epoch 0167, iter [00300, 05004], lr: 0.007290, loss: 1.9046
2022-07-17 03:39:39 - train: epoch 0167, iter [00400, 05004], lr: 0.007282, loss: 1.6575
2022-07-17 03:40:14 - train: epoch 0167, iter [00500, 05004], lr: 0.007274, loss: 1.7438
2022-07-17 03:40:48 - train: epoch 0167, iter [00600, 05004], lr: 0.007265, loss: 2.0612
2022-07-17 03:41:20 - train: epoch 0167, iter [00700, 05004], lr: 0.007257, loss: 1.9660
2022-07-17 03:41:55 - train: epoch 0167, iter [00800, 05004], lr: 0.007249, loss: 1.9589
2022-07-17 03:42:29 - train: epoch 0167, iter [00900, 05004], lr: 0.007240, loss: 2.1589
2022-07-17 03:43:03 - train: epoch 0167, iter [01000, 05004], lr: 0.007232, loss: 1.9626
2022-07-17 03:43:37 - train: epoch 0167, iter [01100, 05004], lr: 0.007224, loss: 1.8036
2022-07-17 03:44:11 - train: epoch 0167, iter [01200, 05004], lr: 0.007215, loss: 1.9244
2022-07-17 03:44:45 - train: epoch 0167, iter [01300, 05004], lr: 0.007207, loss: 1.9845
2022-07-17 03:45:18 - train: epoch 0167, iter [01400, 05004], lr: 0.007199, loss: 1.7621
2022-07-17 03:45:52 - train: epoch 0167, iter [01500, 05004], lr: 0.007190, loss: 2.0841
2022-07-17 03:46:26 - train: epoch 0167, iter [01600, 05004], lr: 0.007182, loss: 1.9734
2022-07-17 03:46:59 - train: epoch 0167, iter [01700, 05004], lr: 0.007174, loss: 2.1581
2022-07-17 03:47:34 - train: epoch 0167, iter [01800, 05004], lr: 0.007165, loss: 2.0709
2022-07-17 03:48:07 - train: epoch 0167, iter [01900, 05004], lr: 0.007157, loss: 2.2357
2022-07-17 03:48:42 - train: epoch 0167, iter [02000, 05004], lr: 0.007149, loss: 1.7862
2022-07-17 03:49:15 - train: epoch 0167, iter [02100, 05004], lr: 0.007140, loss: 1.9257
2022-07-17 03:49:49 - train: epoch 0167, iter [02200, 05004], lr: 0.007132, loss: 1.7873
2022-07-17 03:50:23 - train: epoch 0167, iter [02300, 05004], lr: 0.007124, loss: 2.0602
2022-07-17 03:50:57 - train: epoch 0167, iter [02400, 05004], lr: 0.007116, loss: 1.9868
2022-07-17 03:51:32 - train: epoch 0167, iter [02500, 05004], lr: 0.007107, loss: 1.8355
2022-07-17 03:52:06 - train: epoch 0167, iter [02600, 05004], lr: 0.007099, loss: 1.8122
2022-07-17 03:52:40 - train: epoch 0167, iter [02700, 05004], lr: 0.007091, loss: 2.2238
2022-07-17 03:53:14 - train: epoch 0167, iter [02800, 05004], lr: 0.007082, loss: 1.7453
2022-07-17 03:53:48 - train: epoch 0167, iter [02900, 05004], lr: 0.007074, loss: 1.6868
2022-07-17 03:54:22 - train: epoch 0167, iter [03000, 05004], lr: 0.007066, loss: 2.0711
2022-07-17 03:54:56 - train: epoch 0167, iter [03100, 05004], lr: 0.007058, loss: 1.9340
2022-07-17 03:55:30 - train: epoch 0167, iter [03200, 05004], lr: 0.007049, loss: 2.0100
2022-07-17 03:56:04 - train: epoch 0167, iter [03300, 05004], lr: 0.007041, loss: 1.9178
2022-07-17 03:56:38 - train: epoch 0167, iter [03400, 05004], lr: 0.007033, loss: 1.4406
2022-07-17 03:57:13 - train: epoch 0167, iter [03500, 05004], lr: 0.007025, loss: 1.9754
2022-07-17 03:57:46 - train: epoch 0167, iter [03600, 05004], lr: 0.007017, loss: 1.9060
2022-07-17 03:58:20 - train: epoch 0167, iter [03700, 05004], lr: 0.007008, loss: 1.9954
2022-07-17 03:58:55 - train: epoch 0167, iter [03800, 05004], lr: 0.007000, loss: 1.9255
2022-07-17 03:59:29 - train: epoch 0167, iter [03900, 05004], lr: 0.006992, loss: 1.7568
2022-07-17 04:00:03 - train: epoch 0167, iter [04000, 05004], lr: 0.006984, loss: 2.0341
2022-07-17 04:00:37 - train: epoch 0167, iter [04100, 05004], lr: 0.006975, loss: 1.8999
2022-07-17 04:01:10 - train: epoch 0167, iter [04200, 05004], lr: 0.006967, loss: 2.2103
2022-07-17 04:01:44 - train: epoch 0167, iter [04300, 05004], lr: 0.006959, loss: 1.9117
2022-07-17 04:02:18 - train: epoch 0167, iter [04400, 05004], lr: 0.006951, loss: 1.8004
2022-07-17 04:02:53 - train: epoch 0167, iter [04500, 05004], lr: 0.006943, loss: 1.7377
2022-07-17 04:03:27 - train: epoch 0167, iter [04600, 05004], lr: 0.006935, loss: 1.7041
2022-07-17 04:04:00 - train: epoch 0167, iter [04700, 05004], lr: 0.006926, loss: 2.1016
2022-07-17 04:04:34 - train: epoch 0167, iter [04800, 05004], lr: 0.006918, loss: 1.5692
2022-07-17 04:05:08 - train: epoch 0167, iter [04900, 05004], lr: 0.006910, loss: 2.0507
2022-07-17 04:05:41 - train: epoch 0167, iter [05000, 05004], lr: 0.006902, loss: 1.9328
2022-07-17 04:05:42 - train: epoch 167, train_loss: 1.9288
2022-07-17 04:06:57 - eval: epoch: 167, acc1: 74.030%, acc5: 92.118%, test_loss: 1.0304, per_image_load_time: 2.411ms, per_image_inference_time: 0.459ms
2022-07-17 04:06:57 - until epoch: 167, best_acc1: 74.072%
2022-07-17 04:06:57 - epoch 168 lr: 0.006901
2022-07-17 04:07:36 - train: epoch 0168, iter [00100, 05004], lr: 0.006893, loss: 1.6054
2022-07-17 04:08:11 - train: epoch 0168, iter [00200, 05004], lr: 0.006885, loss: 1.8583
2022-07-17 04:08:45 - train: epoch 0168, iter [00300, 05004], lr: 0.006877, loss: 1.9798
2022-07-17 04:09:18 - train: epoch 0168, iter [00400, 05004], lr: 0.006869, loss: 1.7196
2022-07-17 04:09:52 - train: epoch 0168, iter [00500, 05004], lr: 0.006861, loss: 2.0302
2022-07-17 04:10:27 - train: epoch 0168, iter [00600, 05004], lr: 0.006853, loss: 2.1201
2022-07-17 04:11:00 - train: epoch 0168, iter [00700, 05004], lr: 0.006844, loss: 2.0429
2022-07-17 04:11:35 - train: epoch 0168, iter [00800, 05004], lr: 0.006836, loss: 1.9319
2022-07-17 04:12:08 - train: epoch 0168, iter [00900, 05004], lr: 0.006828, loss: 1.8997
2022-07-17 04:12:43 - train: epoch 0168, iter [01000, 05004], lr: 0.006820, loss: 1.7141
2022-07-17 04:13:17 - train: epoch 0168, iter [01100, 05004], lr: 0.006812, loss: 2.1011
2022-07-17 04:13:51 - train: epoch 0168, iter [01200, 05004], lr: 0.006804, loss: 2.0566
2022-07-17 04:14:25 - train: epoch 0168, iter [01300, 05004], lr: 0.006796, loss: 1.5664
2022-07-17 04:15:00 - train: epoch 0168, iter [01400, 05004], lr: 0.006788, loss: 1.9698
2022-07-17 04:15:34 - train: epoch 0168, iter [01500, 05004], lr: 0.006780, loss: 1.8349
2022-07-17 04:16:08 - train: epoch 0168, iter [01600, 05004], lr: 0.006772, loss: 1.8063
2022-07-17 04:16:42 - train: epoch 0168, iter [01700, 05004], lr: 0.006763, loss: 1.9116
2022-07-17 04:17:16 - train: epoch 0168, iter [01800, 05004], lr: 0.006755, loss: 2.0282
2022-07-17 04:17:50 - train: epoch 0168, iter [01900, 05004], lr: 0.006747, loss: 1.9385
2022-07-17 04:18:24 - train: epoch 0168, iter [02000, 05004], lr: 0.006739, loss: 1.6778
2022-07-17 04:18:59 - train: epoch 0168, iter [02100, 05004], lr: 0.006731, loss: 1.9675
2022-07-17 04:19:33 - train: epoch 0168, iter [02200, 05004], lr: 0.006723, loss: 1.8639
2022-07-17 04:20:08 - train: epoch 0168, iter [02300, 05004], lr: 0.006715, loss: 1.8068
2022-07-17 04:20:42 - train: epoch 0168, iter [02400, 05004], lr: 0.006707, loss: 1.8024
2022-07-17 04:21:15 - train: epoch 0168, iter [02500, 05004], lr: 0.006699, loss: 1.9258
2022-07-17 04:21:50 - train: epoch 0168, iter [02600, 05004], lr: 0.006691, loss: 1.7280
2022-07-17 04:22:24 - train: epoch 0168, iter [02700, 05004], lr: 0.006683, loss: 1.9445
2022-07-17 04:22:58 - train: epoch 0168, iter [02800, 05004], lr: 0.006675, loss: 1.9965
2022-07-17 04:23:33 - train: epoch 0168, iter [02900, 05004], lr: 0.006667, loss: 1.9963
2022-07-17 04:24:07 - train: epoch 0168, iter [03000, 05004], lr: 0.006659, loss: 1.8138
2022-07-17 04:24:42 - train: epoch 0168, iter [03100, 05004], lr: 0.006651, loss: 1.8907
2022-07-17 04:25:16 - train: epoch 0168, iter [03200, 05004], lr: 0.006643, loss: 1.6532
2022-07-17 04:25:51 - train: epoch 0168, iter [03300, 05004], lr: 0.006635, loss: 1.8109
2022-07-17 04:26:25 - train: epoch 0168, iter [03400, 05004], lr: 0.006627, loss: 2.1602
2022-07-17 04:26:58 - train: epoch 0168, iter [03500, 05004], lr: 0.006619, loss: 1.9064
2022-07-17 04:27:33 - train: epoch 0168, iter [03600, 05004], lr: 0.006611, loss: 2.0560
2022-07-17 04:28:07 - train: epoch 0168, iter [03700, 05004], lr: 0.006603, loss: 1.8916
2022-07-17 04:28:42 - train: epoch 0168, iter [03800, 05004], lr: 0.006595, loss: 1.8818
2022-07-17 04:29:16 - train: epoch 0168, iter [03900, 05004], lr: 0.006587, loss: 1.9716
2022-07-17 04:29:50 - train: epoch 0168, iter [04000, 05004], lr: 0.006579, loss: 2.1750
2022-07-17 04:30:25 - train: epoch 0168, iter [04100, 05004], lr: 0.006571, loss: 2.0659
2022-07-17 04:30:59 - train: epoch 0168, iter [04200, 05004], lr: 0.006563, loss: 1.9236
2022-07-17 04:31:33 - train: epoch 0168, iter [04300, 05004], lr: 0.006555, loss: 2.0094
2022-07-17 04:32:08 - train: epoch 0168, iter [04400, 05004], lr: 0.006547, loss: 2.0895
2022-07-17 04:32:43 - train: epoch 0168, iter [04500, 05004], lr: 0.006539, loss: 2.3957
2022-07-17 04:33:18 - train: epoch 0168, iter [04600, 05004], lr: 0.006531, loss: 1.9795
2022-07-17 04:33:52 - train: epoch 0168, iter [04700, 05004], lr: 0.006523, loss: 1.8920
2022-07-17 04:34:26 - train: epoch 0168, iter [04800, 05004], lr: 0.006515, loss: 1.8281
2022-07-17 04:35:00 - train: epoch 0168, iter [04900, 05004], lr: 0.006507, loss: 2.0134
2022-07-17 04:35:33 - train: epoch 0168, iter [05000, 05004], lr: 0.006499, loss: 2.0882
2022-07-17 04:35:34 - train: epoch 168, train_loss: 1.9133
2022-07-17 04:36:48 - eval: epoch: 168, acc1: 74.448%, acc5: 92.208%, test_loss: 1.0146, per_image_load_time: 2.395ms, per_image_inference_time: 0.482ms
2022-07-17 04:36:49 - until epoch: 168, best_acc1: 74.448%
2022-07-17 04:36:49 - epoch 169 lr: 0.006499
2022-07-17 04:37:28 - train: epoch 0169, iter [00100, 05004], lr: 0.006491, loss: 1.8186
2022-07-17 04:38:02 - train: epoch 0169, iter [00200, 05004], lr: 0.006483, loss: 1.9224
2022-07-17 04:38:35 - train: epoch 0169, iter [00300, 05004], lr: 0.006475, loss: 1.9280
2022-07-17 04:39:10 - train: epoch 0169, iter [00400, 05004], lr: 0.006467, loss: 1.8076
2022-07-17 04:39:43 - train: epoch 0169, iter [00500, 05004], lr: 0.006459, loss: 1.8631
2022-07-17 04:40:18 - train: epoch 0169, iter [00600, 05004], lr: 0.006451, loss: 2.0423
2022-07-17 04:40:52 - train: epoch 0169, iter [00700, 05004], lr: 0.006443, loss: 2.1043
2022-07-17 04:41:26 - train: epoch 0169, iter [00800, 05004], lr: 0.006435, loss: 1.8406
2022-07-17 04:42:00 - train: epoch 0169, iter [00900, 05004], lr: 0.006428, loss: 2.0494
2022-07-17 04:42:34 - train: epoch 0169, iter [01000, 05004], lr: 0.006420, loss: 1.8282
2022-07-17 04:43:07 - train: epoch 0169, iter [01100, 05004], lr: 0.006412, loss: 2.0140
2022-07-17 04:43:42 - train: epoch 0169, iter [01200, 05004], lr: 0.006404, loss: 1.8392
2022-07-17 04:44:16 - train: epoch 0169, iter [01300, 05004], lr: 0.006396, loss: 1.7475
2022-07-17 04:44:51 - train: epoch 0169, iter [01400, 05004], lr: 0.006388, loss: 2.2731
2022-07-17 04:45:25 - train: epoch 0169, iter [01500, 05004], lr: 0.006380, loss: 1.8797
2022-07-17 04:45:59 - train: epoch 0169, iter [01600, 05004], lr: 0.006372, loss: 1.7584
2022-07-17 04:46:32 - train: epoch 0169, iter [01700, 05004], lr: 0.006364, loss: 1.7480
2022-07-17 04:47:07 - train: epoch 0169, iter [01800, 05004], lr: 0.006357, loss: 2.0369
2022-07-17 04:47:41 - train: epoch 0169, iter [01900, 05004], lr: 0.006349, loss: 1.8378
2022-07-17 04:48:16 - train: epoch 0169, iter [02000, 05004], lr: 0.006341, loss: 2.1599
2022-07-17 04:48:50 - train: epoch 0169, iter [02100, 05004], lr: 0.006333, loss: 2.1176
2022-07-17 04:49:24 - train: epoch 0169, iter [02200, 05004], lr: 0.006325, loss: 2.1851
2022-07-17 04:49:58 - train: epoch 0169, iter [02300, 05004], lr: 0.006317, loss: 2.1868
2022-07-17 04:50:32 - train: epoch 0169, iter [02400, 05004], lr: 0.006310, loss: 2.0868
2022-07-17 04:51:06 - train: epoch 0169, iter [02500, 05004], lr: 0.006302, loss: 1.9780
2022-07-17 04:51:40 - train: epoch 0169, iter [02600, 05004], lr: 0.006294, loss: 1.6936
2022-07-17 04:52:15 - train: epoch 0169, iter [02700, 05004], lr: 0.006286, loss: 1.5267
2022-07-17 04:52:49 - train: epoch 0169, iter [02800, 05004], lr: 0.006278, loss: 1.7392
2022-07-17 04:53:23 - train: epoch 0169, iter [02900, 05004], lr: 0.006270, loss: 1.9652
2022-07-17 04:53:57 - train: epoch 0169, iter [03000, 05004], lr: 0.006263, loss: 1.7299
2022-07-17 04:54:32 - train: epoch 0169, iter [03100, 05004], lr: 0.006255, loss: 2.0671
2022-07-17 04:55:07 - train: epoch 0169, iter [03200, 05004], lr: 0.006247, loss: 2.0898
2022-07-17 04:55:41 - train: epoch 0169, iter [03300, 05004], lr: 0.006239, loss: 1.9844
2022-07-17 04:56:15 - train: epoch 0169, iter [03400, 05004], lr: 0.006232, loss: 1.8165
2022-07-17 04:56:50 - train: epoch 0169, iter [03500, 05004], lr: 0.006224, loss: 1.9596
2022-07-17 04:57:24 - train: epoch 0169, iter [03600, 05004], lr: 0.006216, loss: 1.9083
2022-07-17 04:57:58 - train: epoch 0169, iter [03700, 05004], lr: 0.006208, loss: 1.8629
2022-07-17 04:58:33 - train: epoch 0169, iter [03800, 05004], lr: 0.006200, loss: 1.7087
2022-07-17 04:59:07 - train: epoch 0169, iter [03900, 05004], lr: 0.006193, loss: 1.6758
2022-07-17 04:59:43 - train: epoch 0169, iter [04000, 05004], lr: 0.006185, loss: 1.8080
2022-07-17 05:00:17 - train: epoch 0169, iter [04100, 05004], lr: 0.006177, loss: 1.6224
2022-07-17 05:00:51 - train: epoch 0169, iter [04200, 05004], lr: 0.006169, loss: 2.1276
2022-07-17 05:01:26 - train: epoch 0169, iter [04300, 05004], lr: 0.006162, loss: 1.7587
2022-07-17 05:02:01 - train: epoch 0169, iter [04400, 05004], lr: 0.006154, loss: 2.0249
2022-07-17 05:02:35 - train: epoch 0169, iter [04500, 05004], lr: 0.006146, loss: 2.1622
2022-07-17 05:03:09 - train: epoch 0169, iter [04600, 05004], lr: 0.006138, loss: 1.8885
2022-07-17 05:03:43 - train: epoch 0169, iter [04700, 05004], lr: 0.006131, loss: 2.0469
2022-07-17 05:04:17 - train: epoch 0169, iter [04800, 05004], lr: 0.006123, loss: 1.8615
2022-07-17 05:04:52 - train: epoch 0169, iter [04900, 05004], lr: 0.006115, loss: 1.7228
2022-07-17 05:05:25 - train: epoch 0169, iter [05000, 05004], lr: 0.006108, loss: 2.0587
2022-07-17 05:05:26 - train: epoch 169, train_loss: 1.9045
2022-07-17 05:06:41 - eval: epoch: 169, acc1: 74.418%, acc5: 92.262%, test_loss: 1.0196, per_image_load_time: 2.431ms, per_image_inference_time: 0.448ms
2022-07-17 05:06:41 - until epoch: 169, best_acc1: 74.448%
2022-07-17 05:06:41 - epoch 170 lr: 0.006107
2022-07-17 05:07:20 - train: epoch 0170, iter [00100, 05004], lr: 0.006100, loss: 2.0055
2022-07-17 05:07:55 - train: epoch 0170, iter [00200, 05004], lr: 0.006092, loss: 2.0441
2022-07-17 05:08:29 - train: epoch 0170, iter [00300, 05004], lr: 0.006084, loss: 1.9144
2022-07-17 05:09:03 - train: epoch 0170, iter [00400, 05004], lr: 0.006076, loss: 1.7898
2022-07-17 05:09:38 - train: epoch 0170, iter [00500, 05004], lr: 0.006069, loss: 2.1385
2022-07-17 05:10:12 - train: epoch 0170, iter [00600, 05004], lr: 0.006061, loss: 1.9034
2022-07-17 05:10:46 - train: epoch 0170, iter [00700, 05004], lr: 0.006053, loss: 1.9230
2022-07-17 05:11:21 - train: epoch 0170, iter [00800, 05004], lr: 0.006046, loss: 1.8473
2022-07-17 05:11:55 - train: epoch 0170, iter [00900, 05004], lr: 0.006038, loss: 1.9651
2022-07-17 05:12:29 - train: epoch 0170, iter [01000, 05004], lr: 0.006030, loss: 1.6442
2022-07-17 05:13:03 - train: epoch 0170, iter [01100, 05004], lr: 0.006023, loss: 1.9809
2022-07-17 05:13:37 - train: epoch 0170, iter [01200, 05004], lr: 0.006015, loss: 2.1528
2022-07-17 05:14:11 - train: epoch 0170, iter [01300, 05004], lr: 0.006007, loss: 1.8075
2022-07-17 05:14:46 - train: epoch 0170, iter [01400, 05004], lr: 0.006000, loss: 2.0008
2022-07-17 05:15:20 - train: epoch 0170, iter [01500, 05004], lr: 0.005992, loss: 2.0510
2022-07-17 05:15:54 - train: epoch 0170, iter [01600, 05004], lr: 0.005985, loss: 2.0044
2022-07-17 05:16:29 - train: epoch 0170, iter [01700, 05004], lr: 0.005977, loss: 1.9501
2022-07-17 05:17:02 - train: epoch 0170, iter [01800, 05004], lr: 0.005969, loss: 1.7708
2022-07-17 05:17:37 - train: epoch 0170, iter [01900, 05004], lr: 0.005962, loss: 1.9165
2022-07-17 05:18:11 - train: epoch 0170, iter [02000, 05004], lr: 0.005954, loss: 1.7219
2022-07-17 05:18:45 - train: epoch 0170, iter [02100, 05004], lr: 0.005946, loss: 1.8577
2022-07-17 05:19:19 - train: epoch 0170, iter [02200, 05004], lr: 0.005939, loss: 1.9374
2022-07-17 05:19:54 - train: epoch 0170, iter [02300, 05004], lr: 0.005931, loss: 2.1594
2022-07-17 05:20:28 - train: epoch 0170, iter [02400, 05004], lr: 0.005924, loss: 1.8994
2022-07-17 05:21:03 - train: epoch 0170, iter [02500, 05004], lr: 0.005916, loss: 1.9479
2022-07-17 05:21:36 - train: epoch 0170, iter [02600, 05004], lr: 0.005908, loss: 2.0536
2022-07-17 05:22:10 - train: epoch 0170, iter [02700, 05004], lr: 0.005901, loss: 1.7281
2022-07-17 05:22:46 - train: epoch 0170, iter [02800, 05004], lr: 0.005893, loss: 1.9371
2022-07-17 05:23:20 - train: epoch 0170, iter [02900, 05004], lr: 0.005886, loss: 1.9390
2022-07-17 05:23:55 - train: epoch 0170, iter [03000, 05004], lr: 0.005878, loss: 1.9250
2022-07-17 05:24:29 - train: epoch 0170, iter [03100, 05004], lr: 0.005870, loss: 1.8559
2022-07-17 05:25:03 - train: epoch 0170, iter [03200, 05004], lr: 0.005863, loss: 2.0278
2022-07-17 05:25:38 - train: epoch 0170, iter [03300, 05004], lr: 0.005855, loss: 1.7459
2022-07-17 05:26:12 - train: epoch 0170, iter [03400, 05004], lr: 0.005848, loss: 1.8829
2022-07-17 05:26:46 - train: epoch 0170, iter [03500, 05004], lr: 0.005840, loss: 2.1754
2022-07-17 05:27:21 - train: epoch 0170, iter [03600, 05004], lr: 0.005833, loss: 1.7788
2022-07-17 05:27:55 - train: epoch 0170, iter [03700, 05004], lr: 0.005825, loss: 1.7693
2022-07-17 05:28:30 - train: epoch 0170, iter [03800, 05004], lr: 0.005818, loss: 2.1310
2022-07-17 05:29:04 - train: epoch 0170, iter [03900, 05004], lr: 0.005810, loss: 2.0413
2022-07-17 05:29:37 - train: epoch 0170, iter [04000, 05004], lr: 0.005803, loss: 1.6150
2022-07-17 05:30:12 - train: epoch 0170, iter [04100, 05004], lr: 0.005795, loss: 2.0903
2022-07-17 05:30:46 - train: epoch 0170, iter [04200, 05004], lr: 0.005787, loss: 1.6867
2022-07-17 05:31:21 - train: epoch 0170, iter [04300, 05004], lr: 0.005780, loss: 2.0071
2022-07-17 05:31:55 - train: epoch 0170, iter [04400, 05004], lr: 0.005772, loss: 1.7152
2022-07-17 05:32:30 - train: epoch 0170, iter [04500, 05004], lr: 0.005765, loss: 1.9753
2022-07-17 05:33:04 - train: epoch 0170, iter [04600, 05004], lr: 0.005757, loss: 1.7456
2022-07-17 05:33:39 - train: epoch 0170, iter [04700, 05004], lr: 0.005750, loss: 1.9202
2022-07-17 05:34:13 - train: epoch 0170, iter [04800, 05004], lr: 0.005742, loss: 2.2939
2022-07-17 05:34:47 - train: epoch 0170, iter [04900, 05004], lr: 0.005735, loss: 1.7799
2022-07-17 05:35:21 - train: epoch 0170, iter [05000, 05004], lr: 0.005727, loss: 1.6781
2022-07-17 05:35:22 - train: epoch 170, train_loss: 1.8896
2022-07-17 05:36:37 - eval: epoch: 170, acc1: 74.572%, acc5: 92.436%, test_loss: 1.0092, per_image_load_time: 2.405ms, per_image_inference_time: 0.476ms
2022-07-17 05:36:37 - until epoch: 170, best_acc1: 74.572%
2022-07-17 05:36:37 - epoch 171 lr: 0.005727
2022-07-17 05:37:16 - train: epoch 0171, iter [00100, 05004], lr: 0.005720, loss: 1.7286
2022-07-17 05:37:50 - train: epoch 0171, iter [00200, 05004], lr: 0.005712, loss: 1.7761
2022-07-17 05:38:25 - train: epoch 0171, iter [00300, 05004], lr: 0.005705, loss: 1.9015
2022-07-17 05:39:00 - train: epoch 0171, iter [00400, 05004], lr: 0.005697, loss: 1.7909
2022-07-17 05:39:34 - train: epoch 0171, iter [00500, 05004], lr: 0.005690, loss: 1.8667
2022-07-17 05:40:07 - train: epoch 0171, iter [00600, 05004], lr: 0.005682, loss: 1.6491
2022-07-17 05:40:41 - train: epoch 0171, iter [00700, 05004], lr: 0.005675, loss: 1.9445
2022-07-17 05:41:16 - train: epoch 0171, iter [00800, 05004], lr: 0.005667, loss: 1.9447
2022-07-17 05:41:50 - train: epoch 0171, iter [00900, 05004], lr: 0.005660, loss: 1.5388
2022-07-17 05:42:24 - train: epoch 0171, iter [01000, 05004], lr: 0.005653, loss: 1.8780
2022-07-17 05:42:58 - train: epoch 0171, iter [01100, 05004], lr: 0.005645, loss: 2.2342
2022-07-17 05:43:32 - train: epoch 0171, iter [01200, 05004], lr: 0.005638, loss: 1.7805
2022-07-17 05:44:07 - train: epoch 0171, iter [01300, 05004], lr: 0.005630, loss: 1.8724
2022-07-17 05:44:42 - train: epoch 0171, iter [01400, 05004], lr: 0.005623, loss: 1.7612
2022-07-17 05:45:16 - train: epoch 0171, iter [01500, 05004], lr: 0.005615, loss: 1.6755
2022-07-17 05:45:50 - train: epoch 0171, iter [01600, 05004], lr: 0.005608, loss: 1.7663
2022-07-17 05:46:24 - train: epoch 0171, iter [01700, 05004], lr: 0.005601, loss: 1.9177
2022-07-17 05:46:58 - train: epoch 0171, iter [01800, 05004], lr: 0.005593, loss: 1.6250
2022-07-17 05:47:32 - train: epoch 0171, iter [01900, 05004], lr: 0.005586, loss: 2.1428
2022-07-17 05:48:06 - train: epoch 0171, iter [02000, 05004], lr: 0.005578, loss: 1.9236
2022-07-17 05:48:41 - train: epoch 0171, iter [02100, 05004], lr: 0.005571, loss: 1.7687
2022-07-17 05:49:15 - train: epoch 0171, iter [02200, 05004], lr: 0.005564, loss: 1.7919
2022-07-17 05:49:49 - train: epoch 0171, iter [02300, 05004], lr: 0.005556, loss: 2.0386
2022-07-17 05:50:24 - train: epoch 0171, iter [02400, 05004], lr: 0.005549, loss: 1.6724
2022-07-17 05:50:57 - train: epoch 0171, iter [02500, 05004], lr: 0.005542, loss: 2.4687
2022-07-17 05:51:32 - train: epoch 0171, iter [02600, 05004], lr: 0.005534, loss: 2.0225
2022-07-17 05:52:06 - train: epoch 0171, iter [02700, 05004], lr: 0.005527, loss: 1.8548
2022-07-17 05:52:40 - train: epoch 0171, iter [02800, 05004], lr: 0.005520, loss: 1.8116
2022-07-17 05:53:15 - train: epoch 0171, iter [02900, 05004], lr: 0.005512, loss: 1.9914
2022-07-17 05:53:48 - train: epoch 0171, iter [03000, 05004], lr: 0.005505, loss: 1.9797
2022-07-17 05:54:23 - train: epoch 0171, iter [03100, 05004], lr: 0.005497, loss: 1.8958
2022-07-17 05:54:57 - train: epoch 0171, iter [03200, 05004], lr: 0.005490, loss: 1.8110
2022-07-17 05:55:31 - train: epoch 0171, iter [03300, 05004], lr: 0.005483, loss: 1.8984
2022-07-17 05:56:06 - train: epoch 0171, iter [03400, 05004], lr: 0.005476, loss: 1.6786
2022-07-17 05:56:40 - train: epoch 0171, iter [03500, 05004], lr: 0.005468, loss: 1.8481
2022-07-17 05:57:15 - train: epoch 0171, iter [03600, 05004], lr: 0.005461, loss: 1.9959
2022-07-17 05:57:49 - train: epoch 0171, iter [03700, 05004], lr: 0.005454, loss: 1.8834
2022-07-17 05:58:24 - train: epoch 0171, iter [03800, 05004], lr: 0.005446, loss: 1.8690
2022-07-17 05:58:59 - train: epoch 0171, iter [03900, 05004], lr: 0.005439, loss: 1.8989
2022-07-17 05:59:33 - train: epoch 0171, iter [04000, 05004], lr: 0.005432, loss: 1.8105
2022-07-17 06:00:07 - train: epoch 0171, iter [04100, 05004], lr: 0.005424, loss: 1.8347
2022-07-17 06:00:42 - train: epoch 0171, iter [04200, 05004], lr: 0.005417, loss: 1.9056
2022-07-17 06:01:17 - train: epoch 0171, iter [04300, 05004], lr: 0.005410, loss: 1.9159
2022-07-17 06:01:51 - train: epoch 0171, iter [04400, 05004], lr: 0.005402, loss: 1.7672
2022-07-17 06:02:26 - train: epoch 0171, iter [04500, 05004], lr: 0.005395, loss: 2.0136
2022-07-17 06:03:00 - train: epoch 0171, iter [04600, 05004], lr: 0.005388, loss: 1.6547
2022-07-17 06:03:34 - train: epoch 0171, iter [04700, 05004], lr: 0.005381, loss: 2.1454
2022-07-17 06:04:09 - train: epoch 0171, iter [04800, 05004], lr: 0.005373, loss: 1.9124
2022-07-17 06:04:43 - train: epoch 0171, iter [04900, 05004], lr: 0.005366, loss: 1.7431
2022-07-17 06:05:16 - train: epoch 0171, iter [05000, 05004], lr: 0.005359, loss: 2.0904
2022-07-17 06:05:18 - train: epoch 171, train_loss: 1.8753
2022-07-17 06:06:31 - eval: epoch: 171, acc1: 74.724%, acc5: 92.280%, test_loss: 1.0088, per_image_load_time: 2.271ms, per_image_inference_time: 0.483ms
2022-07-17 06:06:32 - until epoch: 171, best_acc1: 74.724%
2022-07-17 06:06:32 - epoch 172 lr: 0.005359
2022-07-17 06:07:11 - train: epoch 0172, iter [00100, 05004], lr: 0.005351, loss: 1.7351
2022-07-17 06:07:45 - train: epoch 0172, iter [00200, 05004], lr: 0.005344, loss: 1.7456
2022-07-17 06:08:20 - train: epoch 0172, iter [00300, 05004], lr: 0.005337, loss: 2.1621
2022-07-17 06:08:54 - train: epoch 0172, iter [00400, 05004], lr: 0.005330, loss: 1.7920
2022-07-17 06:09:28 - train: epoch 0172, iter [00500, 05004], lr: 0.005322, loss: 1.7659
2022-07-17 06:10:02 - train: epoch 0172, iter [00600, 05004], lr: 0.005315, loss: 1.6552
2022-07-17 06:10:36 - train: epoch 0172, iter [00700, 05004], lr: 0.005308, loss: 1.8895
2022-07-17 06:11:11 - train: epoch 0172, iter [00800, 05004], lr: 0.005301, loss: 1.7390
2022-07-17 06:11:44 - train: epoch 0172, iter [00900, 05004], lr: 0.005294, loss: 1.5928
2022-07-17 06:12:18 - train: epoch 0172, iter [01000, 05004], lr: 0.005286, loss: 1.7484
2022-07-17 06:12:53 - train: epoch 0172, iter [01100, 05004], lr: 0.005279, loss: 1.9051
2022-07-17 06:13:27 - train: epoch 0172, iter [01200, 05004], lr: 0.005272, loss: 2.0155
2022-07-17 06:14:00 - train: epoch 0172, iter [01300, 05004], lr: 0.005265, loss: 1.8124
2022-07-17 06:14:35 - train: epoch 0172, iter [01400, 05004], lr: 0.005258, loss: 2.1138
2022-07-17 06:15:09 - train: epoch 0172, iter [01500, 05004], lr: 0.005250, loss: 1.7146
2022-07-17 06:15:43 - train: epoch 0172, iter [01600, 05004], lr: 0.005243, loss: 1.9249
2022-07-17 06:16:17 - train: epoch 0172, iter [01700, 05004], lr: 0.005236, loss: 1.7722
2022-07-17 06:16:52 - train: epoch 0172, iter [01800, 05004], lr: 0.005229, loss: 2.1903
2022-07-17 06:17:26 - train: epoch 0172, iter [01900, 05004], lr: 0.005222, loss: 1.8333
2022-07-17 06:18:02 - train: epoch 0172, iter [02000, 05004], lr: 0.005215, loss: 1.8642
2022-07-17 06:18:35 - train: epoch 0172, iter [02100, 05004], lr: 0.005207, loss: 1.7270
2022-07-17 06:19:10 - train: epoch 0172, iter [02200, 05004], lr: 0.005200, loss: 1.8509
2022-07-17 06:19:44 - train: epoch 0172, iter [02300, 05004], lr: 0.005193, loss: 1.8884
2022-07-17 06:20:19 - train: epoch 0172, iter [02400, 05004], lr: 0.005186, loss: 1.8340
2022-07-17 06:20:54 - train: epoch 0172, iter [02500, 05004], lr: 0.005179, loss: 1.8528
2022-07-17 06:21:27 - train: epoch 0172, iter [02600, 05004], lr: 0.005172, loss: 1.9076
2022-07-17 06:22:02 - train: epoch 0172, iter [02700, 05004], lr: 0.005165, loss: 1.8737
2022-07-17 06:22:37 - train: epoch 0172, iter [02800, 05004], lr: 0.005157, loss: 1.7741
2022-07-17 06:23:11 - train: epoch 0172, iter [02900, 05004], lr: 0.005150, loss: 1.7341
2022-07-17 06:23:45 - train: epoch 0172, iter [03000, 05004], lr: 0.005143, loss: 1.7562
2022-07-17 06:24:19 - train: epoch 0172, iter [03100, 05004], lr: 0.005136, loss: 1.9595
2022-07-17 06:24:54 - train: epoch 0172, iter [03200, 05004], lr: 0.005129, loss: 1.9991
2022-07-17 06:25:27 - train: epoch 0172, iter [03300, 05004], lr: 0.005122, loss: 2.1424
2022-07-17 06:26:02 - train: epoch 0172, iter [03400, 05004], lr: 0.005115, loss: 2.2809
2022-07-17 06:26:36 - train: epoch 0172, iter [03500, 05004], lr: 0.005108, loss: 1.7137
2022-07-17 06:27:11 - train: epoch 0172, iter [03600, 05004], lr: 0.005101, loss: 1.9332
2022-07-17 06:27:45 - train: epoch 0172, iter [03700, 05004], lr: 0.005094, loss: 1.5490
2022-07-17 06:28:19 - train: epoch 0172, iter [03800, 05004], lr: 0.005086, loss: 2.1327
2022-07-17 06:28:54 - train: epoch 0172, iter [03900, 05004], lr: 0.005079, loss: 1.7467
2022-07-17 06:29:29 - train: epoch 0172, iter [04000, 05004], lr: 0.005072, loss: 1.8651
2022-07-17 06:30:03 - train: epoch 0172, iter [04100, 05004], lr: 0.005065, loss: 1.7925
2022-07-17 06:30:37 - train: epoch 0172, iter [04200, 05004], lr: 0.005058, loss: 2.0986
2022-07-17 06:31:12 - train: epoch 0172, iter [04300, 05004], lr: 0.005051, loss: 1.9378
2022-07-17 06:31:46 - train: epoch 0172, iter [04400, 05004], lr: 0.005044, loss: 2.0016
2022-07-17 06:32:21 - train: epoch 0172, iter [04500, 05004], lr: 0.005037, loss: 1.9852
2022-07-17 06:32:56 - train: epoch 0172, iter [04600, 05004], lr: 0.005030, loss: 2.1018
2022-07-17 06:33:30 - train: epoch 0172, iter [04700, 05004], lr: 0.005023, loss: 1.8810
2022-07-17 06:34:04 - train: epoch 0172, iter [04800, 05004], lr: 0.005016, loss: 2.2608
2022-07-17 06:34:38 - train: epoch 0172, iter [04900, 05004], lr: 0.005009, loss: 2.0547
2022-07-17 06:35:12 - train: epoch 0172, iter [05000, 05004], lr: 0.005002, loss: 1.7820
2022-07-17 06:35:13 - train: epoch 172, train_loss: 1.8638
2022-07-17 06:36:27 - eval: epoch: 172, acc1: 74.824%, acc5: 92.358%, test_loss: 1.0035, per_image_load_time: 2.361ms, per_image_inference_time: 0.465ms
2022-07-17 06:36:27 - until epoch: 172, best_acc1: 74.824%
2022-07-17 06:36:27 - epoch 173 lr: 0.005002
2022-07-17 06:37:06 - train: epoch 0173, iter [00100, 05004], lr: 0.004995, loss: 1.9272
2022-07-17 06:37:40 - train: epoch 0173, iter [00200, 05004], lr: 0.004988, loss: 1.8122
2022-07-17 06:38:14 - train: epoch 0173, iter [00300, 05004], lr: 0.004981, loss: 1.6718
2022-07-17 06:38:49 - train: epoch 0173, iter [00400, 05004], lr: 0.004974, loss: 1.6497
2022-07-17 06:39:23 - train: epoch 0173, iter [00500, 05004], lr: 0.004967, loss: 1.8343
2022-07-17 06:39:56 - train: epoch 0173, iter [00600, 05004], lr: 0.004960, loss: 1.9295
2022-07-17 06:40:30 - train: epoch 0173, iter [00700, 05004], lr: 0.004953, loss: 1.7533
2022-07-17 06:41:04 - train: epoch 0173, iter [00800, 05004], lr: 0.004946, loss: 2.0439
2022-07-17 06:41:38 - train: epoch 0173, iter [00900, 05004], lr: 0.004939, loss: 1.6817
2022-07-17 06:42:12 - train: epoch 0173, iter [01000, 05004], lr: 0.004932, loss: 1.9876
2022-07-17 06:42:46 - train: epoch 0173, iter [01100, 05004], lr: 0.004925, loss: 1.8780
2022-07-17 06:43:20 - train: epoch 0173, iter [01200, 05004], lr: 0.004918, loss: 1.7936
2022-07-17 06:43:53 - train: epoch 0173, iter [01300, 05004], lr: 0.004911, loss: 1.9551
2022-07-17 06:44:27 - train: epoch 0173, iter [01400, 05004], lr: 0.004904, loss: 1.8038
2022-07-17 06:45:02 - train: epoch 0173, iter [01500, 05004], lr: 0.004897, loss: 1.7867
2022-07-17 06:45:36 - train: epoch 0173, iter [01600, 05004], lr: 0.004890, loss: 1.6340
2022-07-17 06:46:10 - train: epoch 0173, iter [01700, 05004], lr: 0.004883, loss: 1.9039
2022-07-17 06:46:44 - train: epoch 0173, iter [01800, 05004], lr: 0.004876, loss: 1.9152
2022-07-17 06:47:18 - train: epoch 0173, iter [01900, 05004], lr: 0.004869, loss: 1.7257
2022-07-17 06:47:52 - train: epoch 0173, iter [02000, 05004], lr: 0.004862, loss: 1.7498
2022-07-17 06:48:27 - train: epoch 0173, iter [02100, 05004], lr: 0.004855, loss: 1.4825
2022-07-17 06:49:01 - train: epoch 0173, iter [02200, 05004], lr: 0.004848, loss: 1.9515
2022-07-17 06:49:35 - train: epoch 0173, iter [02300, 05004], lr: 0.004841, loss: 1.9441
2022-07-17 06:50:09 - train: epoch 0173, iter [02400, 05004], lr: 0.004835, loss: 1.8019
2022-07-17 06:50:44 - train: epoch 0173, iter [02500, 05004], lr: 0.004828, loss: 1.6544
2022-07-17 06:51:17 - train: epoch 0173, iter [02600, 05004], lr: 0.004821, loss: 2.0124
2022-07-17 06:51:52 - train: epoch 0173, iter [02700, 05004], lr: 0.004814, loss: 1.9052
2022-07-17 06:52:26 - train: epoch 0173, iter [02800, 05004], lr: 0.004807, loss: 1.6373
2022-07-17 06:53:00 - train: epoch 0173, iter [02900, 05004], lr: 0.004800, loss: 1.6585
2022-07-17 06:53:35 - train: epoch 0173, iter [03000, 05004], lr: 0.004793, loss: 1.7600
2022-07-17 06:54:09 - train: epoch 0173, iter [03100, 05004], lr: 0.004786, loss: 2.0335
2022-07-17 06:54:42 - train: epoch 0173, iter [03200, 05004], lr: 0.004779, loss: 1.9792
2022-07-17 06:55:17 - train: epoch 0173, iter [03300, 05004], lr: 0.004773, loss: 1.8751
2022-07-17 06:55:51 - train: epoch 0173, iter [03400, 05004], lr: 0.004766, loss: 2.1611
2022-07-17 06:56:25 - train: epoch 0173, iter [03500, 05004], lr: 0.004759, loss: 2.0231
2022-07-17 06:56:59 - train: epoch 0173, iter [03600, 05004], lr: 0.004752, loss: 1.7642
2022-07-17 06:57:34 - train: epoch 0173, iter [03700, 05004], lr: 0.004745, loss: 2.0923
2022-07-17 06:58:08 - train: epoch 0173, iter [03800, 05004], lr: 0.004738, loss: 2.0257
2022-07-17 06:58:43 - train: epoch 0173, iter [03900, 05004], lr: 0.004731, loss: 1.9154
2022-07-17 06:59:16 - train: epoch 0173, iter [04000, 05004], lr: 0.004725, loss: 1.7810
2022-07-17 06:59:51 - train: epoch 0173, iter [04100, 05004], lr: 0.004718, loss: 1.9572
2022-07-17 07:00:25 - train: epoch 0173, iter [04200, 05004], lr: 0.004711, loss: 1.7804
2022-07-17 07:00:58 - train: epoch 0173, iter [04300, 05004], lr: 0.004704, loss: 1.8271
2022-07-17 07:01:33 - train: epoch 0173, iter [04400, 05004], lr: 0.004697, loss: 2.1041
2022-07-17 07:02:07 - train: epoch 0173, iter [04500, 05004], lr: 0.004691, loss: 1.7748
2022-07-17 07:02:42 - train: epoch 0173, iter [04600, 05004], lr: 0.004684, loss: 1.9605
2022-07-17 07:03:16 - train: epoch 0173, iter [04700, 05004], lr: 0.004677, loss: 1.8323
2022-07-17 07:03:50 - train: epoch 0173, iter [04800, 05004], lr: 0.004670, loss: 1.8215
2022-07-17 07:04:25 - train: epoch 0173, iter [04900, 05004], lr: 0.004663, loss: 1.7292
2022-07-17 07:04:58 - train: epoch 0173, iter [05000, 05004], lr: 0.004657, loss: 1.6403
2022-07-17 07:04:59 - train: epoch 173, train_loss: 1.8473
2022-07-17 07:06:13 - eval: epoch: 173, acc1: 75.130%, acc5: 92.598%, test_loss: 0.9818, per_image_load_time: 2.389ms, per_image_inference_time: 0.431ms
2022-07-17 07:06:13 - until epoch: 173, best_acc1: 75.130%
2022-07-17 07:06:13 - epoch 174 lr: 0.004656
2022-07-17 07:06:52 - train: epoch 0174, iter [00100, 05004], lr: 0.004650, loss: 1.9886
2022-07-17 07:07:27 - train: epoch 0174, iter [00200, 05004], lr: 0.004643, loss: 1.9152
2022-07-17 07:08:01 - train: epoch 0174, iter [00300, 05004], lr: 0.004636, loss: 1.7333
2022-07-17 07:08:35 - train: epoch 0174, iter [00400, 05004], lr: 0.004629, loss: 1.9766
2022-07-17 07:09:10 - train: epoch 0174, iter [00500, 05004], lr: 0.004622, loss: 1.7439
2022-07-17 07:09:44 - train: epoch 0174, iter [00600, 05004], lr: 0.004616, loss: 1.8649
2022-07-17 07:10:18 - train: epoch 0174, iter [00700, 05004], lr: 0.004609, loss: 1.6841
2022-07-17 07:10:52 - train: epoch 0174, iter [00800, 05004], lr: 0.004602, loss: 1.9103
2022-07-17 07:11:26 - train: epoch 0174, iter [00900, 05004], lr: 0.004595, loss: 1.6796
2022-07-17 07:12:01 - train: epoch 0174, iter [01000, 05004], lr: 0.004589, loss: 1.9762
2022-07-17 07:12:36 - train: epoch 0174, iter [01100, 05004], lr: 0.004582, loss: 2.0354
2022-07-17 07:13:09 - train: epoch 0174, iter [01200, 05004], lr: 0.004575, loss: 2.0951
2022-07-17 07:13:44 - train: epoch 0174, iter [01300, 05004], lr: 0.004568, loss: 1.8294
2022-07-17 07:14:19 - train: epoch 0174, iter [01400, 05004], lr: 0.004562, loss: 2.0001
2022-07-17 07:14:54 - train: epoch 0174, iter [01500, 05004], lr: 0.004555, loss: 1.8966
2022-07-17 07:15:28 - train: epoch 0174, iter [01600, 05004], lr: 0.004548, loss: 1.8708
2022-07-17 07:16:03 - train: epoch 0174, iter [01700, 05004], lr: 0.004542, loss: 1.6897
2022-07-17 07:16:38 - train: epoch 0174, iter [01800, 05004], lr: 0.004535, loss: 1.7708
2022-07-17 07:17:12 - train: epoch 0174, iter [01900, 05004], lr: 0.004528, loss: 1.7846
2022-07-17 07:17:47 - train: epoch 0174, iter [02000, 05004], lr: 0.004522, loss: 2.0706
2022-07-17 07:18:22 - train: epoch 0174, iter [02100, 05004], lr: 0.004515, loss: 2.0371
2022-07-17 07:18:56 - train: epoch 0174, iter [02200, 05004], lr: 0.004508, loss: 1.8325
2022-07-17 07:19:32 - train: epoch 0174, iter [02300, 05004], lr: 0.004502, loss: 2.1386
2022-07-17 07:20:06 - train: epoch 0174, iter [02400, 05004], lr: 0.004495, loss: 1.8052
2022-07-17 07:20:41 - train: epoch 0174, iter [02500, 05004], lr: 0.004488, loss: 1.8747
2022-07-17 07:21:16 - train: epoch 0174, iter [02600, 05004], lr: 0.004481, loss: 1.5036
2022-07-17 07:21:51 - train: epoch 0174, iter [02700, 05004], lr: 0.004475, loss: 1.6609
2022-07-17 07:22:26 - train: epoch 0174, iter [02800, 05004], lr: 0.004468, loss: 1.7415
2022-07-17 07:23:00 - train: epoch 0174, iter [02900, 05004], lr: 0.004462, loss: 1.8251
2022-07-17 07:23:34 - train: epoch 0174, iter [03000, 05004], lr: 0.004455, loss: 1.5644
2022-07-17 07:24:09 - train: epoch 0174, iter [03100, 05004], lr: 0.004448, loss: 1.7805
2022-07-17 07:24:43 - train: epoch 0174, iter [03200, 05004], lr: 0.004442, loss: 1.8326
2022-07-17 07:25:18 - train: epoch 0174, iter [03300, 05004], lr: 0.004435, loss: 2.0208
2022-07-17 07:25:53 - train: epoch 0174, iter [03400, 05004], lr: 0.004428, loss: 1.8651
2022-07-17 07:26:27 - train: epoch 0174, iter [03500, 05004], lr: 0.004422, loss: 1.7848
2022-07-17 07:27:02 - train: epoch 0174, iter [03600, 05004], lr: 0.004415, loss: 1.5665
2022-07-17 07:27:36 - train: epoch 0174, iter [03700, 05004], lr: 0.004409, loss: 1.8064
2022-07-17 07:28:11 - train: epoch 0174, iter [03800, 05004], lr: 0.004402, loss: 1.7364
2022-07-17 07:28:46 - train: epoch 0174, iter [03900, 05004], lr: 0.004395, loss: 2.0310
2022-07-17 07:29:20 - train: epoch 0174, iter [04000, 05004], lr: 0.004389, loss: 1.6846
2022-07-17 07:29:55 - train: epoch 0174, iter [04100, 05004], lr: 0.004382, loss: 1.7776
2022-07-17 07:30:29 - train: epoch 0174, iter [04200, 05004], lr: 0.004376, loss: 1.6649
2022-07-17 07:31:04 - train: epoch 0174, iter [04300, 05004], lr: 0.004369, loss: 1.8345
2022-07-17 07:31:38 - train: epoch 0174, iter [04400, 05004], lr: 0.004362, loss: 1.8533
2022-07-17 07:32:12 - train: epoch 0174, iter [04500, 05004], lr: 0.004356, loss: 2.0355
2022-07-17 07:32:48 - train: epoch 0174, iter [04600, 05004], lr: 0.004349, loss: 1.9460
2022-07-17 07:33:22 - train: epoch 0174, iter [04700, 05004], lr: 0.004343, loss: 2.0753
2022-07-17 07:33:56 - train: epoch 0174, iter [04800, 05004], lr: 0.004336, loss: 1.9613
2022-07-17 07:34:31 - train: epoch 0174, iter [04900, 05004], lr: 0.004330, loss: 1.7316
2022-07-17 07:35:05 - train: epoch 0174, iter [05000, 05004], lr: 0.004323, loss: 1.8854
2022-07-17 07:35:06 - train: epoch 174, train_loss: 1.8393
2022-07-17 07:36:21 - eval: epoch: 174, acc1: 75.114%, acc5: 92.582%, test_loss: 0.9898, per_image_load_time: 2.426ms, per_image_inference_time: 0.474ms
2022-07-17 07:36:21 - until epoch: 174, best_acc1: 75.130%
2022-07-17 07:36:21 - epoch 175 lr: 0.004323
2022-07-17 07:37:01 - train: epoch 0175, iter [00100, 05004], lr: 0.004316, loss: 1.8739
2022-07-17 07:37:34 - train: epoch 0175, iter [00200, 05004], lr: 0.004310, loss: 1.8047
2022-07-17 07:38:09 - train: epoch 0175, iter [00300, 05004], lr: 0.004303, loss: 1.8520
2022-07-17 07:38:42 - train: epoch 0175, iter [00400, 05004], lr: 0.004297, loss: 1.9904
2022-07-17 07:39:17 - train: epoch 0175, iter [00500, 05004], lr: 0.004290, loss: 1.7748
2022-07-17 07:39:51 - train: epoch 0175, iter [00600, 05004], lr: 0.004284, loss: 1.7372
2022-07-17 07:40:26 - train: epoch 0175, iter [00700, 05004], lr: 0.004277, loss: 1.9330
2022-07-17 07:40:59 - train: epoch 0175, iter [00800, 05004], lr: 0.004270, loss: 2.0252
2022-07-17 07:41:33 - train: epoch 0175, iter [00900, 05004], lr: 0.004264, loss: 1.9664
2022-07-17 07:42:07 - train: epoch 0175, iter [01000, 05004], lr: 0.004257, loss: 2.0423
2022-07-17 07:42:42 - train: epoch 0175, iter [01100, 05004], lr: 0.004251, loss: 1.7986
2022-07-17 07:43:16 - train: epoch 0175, iter [01200, 05004], lr: 0.004244, loss: 1.8031
2022-07-17 07:43:50 - train: epoch 0175, iter [01300, 05004], lr: 0.004238, loss: 1.8923
2022-07-17 07:44:24 - train: epoch 0175, iter [01400, 05004], lr: 0.004232, loss: 1.6467
2022-07-17 07:44:59 - train: epoch 0175, iter [01500, 05004], lr: 0.004225, loss: 1.8875
2022-07-17 07:45:33 - train: epoch 0175, iter [01600, 05004], lr: 0.004219, loss: 1.5950
2022-07-17 07:46:08 - train: epoch 0175, iter [01700, 05004], lr: 0.004212, loss: 1.9724
2022-07-17 07:46:42 - train: epoch 0175, iter [01800, 05004], lr: 0.004206, loss: 1.8982
2022-07-17 07:47:16 - train: epoch 0175, iter [01900, 05004], lr: 0.004199, loss: 1.7128
2022-07-17 07:47:51 - train: epoch 0175, iter [02000, 05004], lr: 0.004193, loss: 1.6038
2022-07-17 07:48:26 - train: epoch 0175, iter [02100, 05004], lr: 0.004186, loss: 1.8682
2022-07-17 07:49:01 - train: epoch 0175, iter [02200, 05004], lr: 0.004180, loss: 1.5422
2022-07-17 07:49:35 - train: epoch 0175, iter [02300, 05004], lr: 0.004173, loss: 1.7753
2022-07-17 07:50:10 - train: epoch 0175, iter [02400, 05004], lr: 0.004167, loss: 2.0762
2022-07-17 07:50:44 - train: epoch 0175, iter [02500, 05004], lr: 0.004161, loss: 1.9263
2022-07-17 07:51:18 - train: epoch 0175, iter [02600, 05004], lr: 0.004154, loss: 2.0525
2022-07-17 07:51:52 - train: epoch 0175, iter [02700, 05004], lr: 0.004148, loss: 1.7199
2022-07-17 07:52:27 - train: epoch 0175, iter [02800, 05004], lr: 0.004141, loss: 1.9035
2022-07-17 07:53:01 - train: epoch 0175, iter [02900, 05004], lr: 0.004135, loss: 1.9908
2022-07-17 07:53:35 - train: epoch 0175, iter [03000, 05004], lr: 0.004128, loss: 1.7293
2022-07-17 07:54:10 - train: epoch 0175, iter [03100, 05004], lr: 0.004122, loss: 1.6801
2022-07-17 07:54:45 - train: epoch 0175, iter [03200, 05004], lr: 0.004116, loss: 1.6974
2022-07-17 07:55:19 - train: epoch 0175, iter [03300, 05004], lr: 0.004109, loss: 2.0095
2022-07-17 07:55:53 - train: epoch 0175, iter [03400, 05004], lr: 0.004103, loss: 2.2186
2022-07-17 07:56:29 - train: epoch 0175, iter [03500, 05004], lr: 0.004096, loss: 1.6955
2022-07-17 07:57:04 - train: epoch 0175, iter [03600, 05004], lr: 0.004090, loss: 1.8349
2022-07-17 07:57:38 - train: epoch 0175, iter [03700, 05004], lr: 0.004084, loss: 1.8781
2022-07-17 07:58:12 - train: epoch 0175, iter [03800, 05004], lr: 0.004077, loss: 1.7673
2022-07-17 07:58:47 - train: epoch 0175, iter [03900, 05004], lr: 0.004071, loss: 1.7385
2022-07-17 07:59:21 - train: epoch 0175, iter [04000, 05004], lr: 0.004065, loss: 2.0567
2022-07-17 07:59:56 - train: epoch 0175, iter [04100, 05004], lr: 0.004058, loss: 1.6109
2022-07-17 08:00:31 - train: epoch 0175, iter [04200, 05004], lr: 0.004052, loss: 1.7073
2022-07-17 08:01:06 - train: epoch 0175, iter [04300, 05004], lr: 0.004046, loss: 1.9540
2022-07-17 08:01:40 - train: epoch 0175, iter [04400, 05004], lr: 0.004039, loss: 1.9492
2022-07-17 08:02:15 - train: epoch 0175, iter [04500, 05004], lr: 0.004033, loss: 1.9475
2022-07-17 08:02:50 - train: epoch 0175, iter [04600, 05004], lr: 0.004027, loss: 1.7895
2022-07-17 08:03:24 - train: epoch 0175, iter [04700, 05004], lr: 0.004020, loss: 1.8476
2022-07-17 08:03:58 - train: epoch 0175, iter [04800, 05004], lr: 0.004014, loss: 2.0060
2022-07-17 08:04:33 - train: epoch 0175, iter [04900, 05004], lr: 0.004008, loss: 1.9295
2022-07-17 08:05:07 - train: epoch 0175, iter [05000, 05004], lr: 0.004001, loss: 1.9940
2022-07-17 08:05:08 - train: epoch 175, train_loss: 1.8238
2022-07-17 08:06:23 - eval: epoch: 175, acc1: 75.804%, acc5: 92.796%, test_loss: 0.9681, per_image_load_time: 2.432ms, per_image_inference_time: 0.481ms
2022-07-17 08:06:24 - until epoch: 175, best_acc1: 75.804%
2022-07-17 08:06:24 - epoch 176 lr: 0.004001
2022-07-17 08:07:04 - train: epoch 0176, iter [00100, 05004], lr: 0.003995, loss: 1.6492
2022-07-17 08:07:37 - train: epoch 0176, iter [00200, 05004], lr: 0.003988, loss: 1.8122
2022-07-17 08:08:12 - train: epoch 0176, iter [00300, 05004], lr: 0.003982, loss: 2.1018
2022-07-17 08:08:46 - train: epoch 0176, iter [00400, 05004], lr: 0.003976, loss: 1.6097
2022-07-17 08:09:20 - train: epoch 0176, iter [00500, 05004], lr: 0.003970, loss: 1.7604
2022-07-17 08:09:55 - train: epoch 0176, iter [00600, 05004], lr: 0.003963, loss: 1.7605
2022-07-17 08:10:29 - train: epoch 0176, iter [00700, 05004], lr: 0.003957, loss: 1.8002
2022-07-17 08:11:03 - train: epoch 0176, iter [00800, 05004], lr: 0.003951, loss: 1.9169
2022-07-17 08:11:38 - train: epoch 0176, iter [00900, 05004], lr: 0.003944, loss: 1.6691
2022-07-17 08:12:13 - train: epoch 0176, iter [01000, 05004], lr: 0.003938, loss: 1.7673
2022-07-17 08:12:47 - train: epoch 0176, iter [01100, 05004], lr: 0.003932, loss: 1.5270
2022-07-17 08:13:21 - train: epoch 0176, iter [01200, 05004], lr: 0.003926, loss: 1.6225
2022-07-17 08:13:55 - train: epoch 0176, iter [01300, 05004], lr: 0.003919, loss: 2.1839
2022-07-17 08:14:30 - train: epoch 0176, iter [01400, 05004], lr: 0.003913, loss: 1.7685
2022-07-17 08:15:05 - train: epoch 0176, iter [01500, 05004], lr: 0.003907, loss: 1.6075
2022-07-17 08:15:39 - train: epoch 0176, iter [01600, 05004], lr: 0.003901, loss: 1.8102
2022-07-17 08:16:13 - train: epoch 0176, iter [01700, 05004], lr: 0.003894, loss: 1.7703
2022-07-17 08:16:48 - train: epoch 0176, iter [01800, 05004], lr: 0.003888, loss: 1.8541
2022-07-17 08:17:22 - train: epoch 0176, iter [01900, 05004], lr: 0.003882, loss: 2.0872
2022-07-17 08:17:57 - train: epoch 0176, iter [02000, 05004], lr: 0.003876, loss: 1.6775
2022-07-17 08:18:31 - train: epoch 0176, iter [02100, 05004], lr: 0.003870, loss: 1.9897
2022-07-17 08:19:05 - train: epoch 0176, iter [02200, 05004], lr: 0.003863, loss: 1.8938
2022-07-17 08:19:41 - train: epoch 0176, iter [02300, 05004], lr: 0.003857, loss: 1.8177
2022-07-17 08:20:15 - train: epoch 0176, iter [02400, 05004], lr: 0.003851, loss: 1.8764
2022-07-17 08:20:50 - train: epoch 0176, iter [02500, 05004], lr: 0.003845, loss: 1.9209
2022-07-17 08:21:25 - train: epoch 0176, iter [02600, 05004], lr: 0.003839, loss: 1.6259
2022-07-17 08:22:00 - train: epoch 0176, iter [02700, 05004], lr: 0.003832, loss: 1.9065
2022-07-17 08:22:34 - train: epoch 0176, iter [02800, 05004], lr: 0.003826, loss: 1.9326
2022-07-17 08:23:09 - train: epoch 0176, iter [02900, 05004], lr: 0.003820, loss: 1.9682
2022-07-17 08:23:43 - train: epoch 0176, iter [03000, 05004], lr: 0.003814, loss: 1.7928
2022-07-17 08:24:18 - train: epoch 0176, iter [03100, 05004], lr: 0.003808, loss: 1.6276
2022-07-17 08:24:52 - train: epoch 0176, iter [03200, 05004], lr: 0.003802, loss: 1.8926
2022-07-17 08:25:27 - train: epoch 0176, iter [03300, 05004], lr: 0.003795, loss: 2.0914
2022-07-17 08:26:02 - train: epoch 0176, iter [03400, 05004], lr: 0.003789, loss: 1.7073
2022-07-17 08:26:36 - train: epoch 0176, iter [03500, 05004], lr: 0.003783, loss: 1.6497
2022-07-17 08:27:11 - train: epoch 0176, iter [03600, 05004], lr: 0.003777, loss: 2.0189
2022-07-17 08:27:45 - train: epoch 0176, iter [03700, 05004], lr: 0.003771, loss: 1.6659
2022-07-17 08:28:19 - train: epoch 0176, iter [03800, 05004], lr: 0.003765, loss: 1.7742
2022-07-17 08:28:53 - train: epoch 0176, iter [03900, 05004], lr: 0.003759, loss: 1.8284
2022-07-17 08:29:28 - train: epoch 0176, iter [04000, 05004], lr: 0.003752, loss: 1.8927
2022-07-17 08:30:02 - train: epoch 0176, iter [04100, 05004], lr: 0.003746, loss: 1.7717
2022-07-17 08:30:38 - train: epoch 0176, iter [04200, 05004], lr: 0.003740, loss: 1.8449
2022-07-17 08:31:12 - train: epoch 0176, iter [04300, 05004], lr: 0.003734, loss: 1.7928
2022-07-17 08:31:46 - train: epoch 0176, iter [04400, 05004], lr: 0.003728, loss: 1.6854
2022-07-17 08:32:21 - train: epoch 0176, iter [04500, 05004], lr: 0.003722, loss: 1.7293
2022-07-17 08:32:55 - train: epoch 0176, iter [04600, 05004], lr: 0.003716, loss: 1.8274
2022-07-17 08:33:30 - train: epoch 0176, iter [04700, 05004], lr: 0.003710, loss: 1.8101
2022-07-17 08:34:05 - train: epoch 0176, iter [04800, 05004], lr: 0.003704, loss: 1.8207
2022-07-17 08:34:39 - train: epoch 0176, iter [04900, 05004], lr: 0.003698, loss: 1.7881
2022-07-17 08:35:13 - train: epoch 0176, iter [05000, 05004], lr: 0.003692, loss: 1.6319
2022-07-17 08:35:14 - train: epoch 176, train_loss: 1.8052
2022-07-17 08:36:29 - eval: epoch: 176, acc1: 75.416%, acc5: 92.780%, test_loss: 0.9753, per_image_load_time: 2.441ms, per_image_inference_time: 0.454ms
2022-07-17 08:36:29 - until epoch: 176, best_acc1: 75.804%
2022-07-17 08:36:29 - epoch 177 lr: 0.003691
2022-07-17 08:37:09 - train: epoch 0177, iter [00100, 05004], lr: 0.003685, loss: 1.5616
2022-07-17 08:37:44 - train: epoch 0177, iter [00200, 05004], lr: 0.003679, loss: 1.9333
2022-07-17 08:38:18 - train: epoch 0177, iter [00300, 05004], lr: 0.003673, loss: 2.0000
2022-07-17 08:38:53 - train: epoch 0177, iter [00400, 05004], lr: 0.003667, loss: 1.6815
2022-07-17 08:39:28 - train: epoch 0177, iter [00500, 05004], lr: 0.003661, loss: 1.9823
2022-07-17 08:40:03 - train: epoch 0177, iter [00600, 05004], lr: 0.003655, loss: 1.8447
2022-07-17 08:40:37 - train: epoch 0177, iter [00700, 05004], lr: 0.003649, loss: 1.7623
2022-07-17 08:41:11 - train: epoch 0177, iter [00800, 05004], lr: 0.003643, loss: 1.8250
2022-07-17 08:41:45 - train: epoch 0177, iter [00900, 05004], lr: 0.003637, loss: 2.1434
2022-07-17 08:42:18 - train: epoch 0177, iter [01000, 05004], lr: 0.003631, loss: 1.7583
2022-07-17 08:42:53 - train: epoch 0177, iter [01100, 05004], lr: 0.003625, loss: 2.0443
2022-07-17 08:43:27 - train: epoch 0177, iter [01200, 05004], lr: 0.003619, loss: 1.6653
2022-07-17 08:44:02 - train: epoch 0177, iter [01300, 05004], lr: 0.003613, loss: 1.6080
2022-07-17 08:44:36 - train: epoch 0177, iter [01400, 05004], lr: 0.003607, loss: 1.9495
2022-07-17 08:45:10 - train: epoch 0177, iter [01500, 05004], lr: 0.003601, loss: 2.1164
2022-07-17 08:45:45 - train: epoch 0177, iter [01600, 05004], lr: 0.003595, loss: 2.0169
2022-07-17 08:46:20 - train: epoch 0177, iter [01700, 05004], lr: 0.003589, loss: 2.1706
2022-07-17 08:46:54 - train: epoch 0177, iter [01800, 05004], lr: 0.003583, loss: 1.9231
2022-07-17 08:47:29 - train: epoch 0177, iter [01900, 05004], lr: 0.003577, loss: 1.7598
2022-07-17 08:48:03 - train: epoch 0177, iter [02000, 05004], lr: 0.003571, loss: 1.8064
2022-07-17 08:48:38 - train: epoch 0177, iter [02100, 05004], lr: 0.003565, loss: 1.7222
2022-07-17 08:49:13 - train: epoch 0177, iter [02200, 05004], lr: 0.003559, loss: 1.7860
2022-07-17 08:49:47 - train: epoch 0177, iter [02300, 05004], lr: 0.003553, loss: 1.7388
2022-07-17 08:50:22 - train: epoch 0177, iter [02400, 05004], lr: 0.003547, loss: 1.8863
2022-07-17 08:50:56 - train: epoch 0177, iter [02500, 05004], lr: 0.003541, loss: 1.6512
2022-07-17 08:51:30 - train: epoch 0177, iter [02600, 05004], lr: 0.003535, loss: 1.7787
2022-07-17 08:52:05 - train: epoch 0177, iter [02700, 05004], lr: 0.003529, loss: 1.8931
2022-07-17 08:52:40 - train: epoch 0177, iter [02800, 05004], lr: 0.003523, loss: 1.8399
2022-07-17 08:53:15 - train: epoch 0177, iter [02900, 05004], lr: 0.003517, loss: 1.9072
2022-07-17 08:53:49 - train: epoch 0177, iter [03000, 05004], lr: 0.003511, loss: 1.5304
2022-07-17 08:54:25 - train: epoch 0177, iter [03100, 05004], lr: 0.003505, loss: 1.7309
2022-07-17 08:54:59 - train: epoch 0177, iter [03200, 05004], lr: 0.003499, loss: 1.8886
2022-07-17 08:55:33 - train: epoch 0177, iter [03300, 05004], lr: 0.003494, loss: 1.6009
2022-07-17 08:56:08 - train: epoch 0177, iter [03400, 05004], lr: 0.003488, loss: 1.6405
2022-07-17 08:56:43 - train: epoch 0177, iter [03500, 05004], lr: 0.003482, loss: 1.6555
2022-07-17 08:57:18 - train: epoch 0177, iter [03600, 05004], lr: 0.003476, loss: 1.7888
2022-07-17 08:57:53 - train: epoch 0177, iter [03700, 05004], lr: 0.003470, loss: 1.9457
2022-07-17 08:58:27 - train: epoch 0177, iter [03800, 05004], lr: 0.003464, loss: 1.7141
2022-07-17 08:59:02 - train: epoch 0177, iter [03900, 05004], lr: 0.003458, loss: 1.9578
2022-07-17 08:59:37 - train: epoch 0177, iter [04000, 05004], lr: 0.003452, loss: 1.7847
2022-07-17 09:00:11 - train: epoch 0177, iter [04100, 05004], lr: 0.003446, loss: 1.8788
2022-07-17 09:00:46 - train: epoch 0177, iter [04200, 05004], lr: 0.003441, loss: 2.0820
2022-07-17 09:01:21 - train: epoch 0177, iter [04300, 05004], lr: 0.003435, loss: 1.8313
2022-07-17 09:01:56 - train: epoch 0177, iter [04400, 05004], lr: 0.003429, loss: 1.6093
2022-07-17 09:02:30 - train: epoch 0177, iter [04500, 05004], lr: 0.003423, loss: 1.8006
2022-07-17 09:03:05 - train: epoch 0177, iter [04600, 05004], lr: 0.003417, loss: 1.9586
2022-07-17 09:03:40 - train: epoch 0177, iter [04700, 05004], lr: 0.003411, loss: 1.6870
2022-07-17 09:04:14 - train: epoch 0177, iter [04800, 05004], lr: 0.003405, loss: 1.6525
2022-07-17 09:04:50 - train: epoch 0177, iter [04900, 05004], lr: 0.003400, loss: 1.5861
2022-07-17 09:05:23 - train: epoch 0177, iter [05000, 05004], lr: 0.003394, loss: 1.9380
2022-07-17 09:05:24 - train: epoch 177, train_loss: 1.7937
2022-07-17 09:06:39 - eval: epoch: 177, acc1: 75.662%, acc5: 92.884%, test_loss: 0.9619, per_image_load_time: 2.228ms, per_image_inference_time: 0.494ms
2022-07-17 09:06:39 - until epoch: 177, best_acc1: 75.804%
2022-07-17 09:06:39 - epoch 178 lr: 0.003393
2022-07-17 09:07:19 - train: epoch 0178, iter [00100, 05004], lr: 0.003388, loss: 1.6128
2022-07-17 09:07:54 - train: epoch 0178, iter [00200, 05004], lr: 0.003382, loss: 1.7226
2022-07-17 09:08:28 - train: epoch 0178, iter [00300, 05004], lr: 0.003376, loss: 1.7539
2022-07-17 09:09:02 - train: epoch 0178, iter [00400, 05004], lr: 0.003370, loss: 1.6854
2022-07-17 09:09:37 - train: epoch 0178, iter [00500, 05004], lr: 0.003364, loss: 1.9241
2022-07-17 09:10:11 - train: epoch 0178, iter [00600, 05004], lr: 0.003359, loss: 1.7893
2022-07-17 09:10:46 - train: epoch 0178, iter [00700, 05004], lr: 0.003353, loss: 1.8396
2022-07-17 09:11:20 - train: epoch 0178, iter [00800, 05004], lr: 0.003347, loss: 1.7341
2022-07-17 09:11:54 - train: epoch 0178, iter [00900, 05004], lr: 0.003341, loss: 1.7952
2022-07-17 09:12:29 - train: epoch 0178, iter [01000, 05004], lr: 0.003335, loss: 1.4640
2022-07-17 09:13:03 - train: epoch 0178, iter [01100, 05004], lr: 0.003330, loss: 1.8633
2022-07-17 09:13:37 - train: epoch 0178, iter [01200, 05004], lr: 0.003324, loss: 1.8202
2022-07-17 09:14:11 - train: epoch 0178, iter [01300, 05004], lr: 0.003318, loss: 1.9354
2022-07-17 09:14:46 - train: epoch 0178, iter [01400, 05004], lr: 0.003312, loss: 1.5433
2022-07-17 09:15:20 - train: epoch 0178, iter [01500, 05004], lr: 0.003307, loss: 1.8252
2022-07-17 09:15:55 - train: epoch 0178, iter [01600, 05004], lr: 0.003301, loss: 1.7590
2022-07-17 09:16:30 - train: epoch 0178, iter [01700, 05004], lr: 0.003295, loss: 1.8130
2022-07-17 09:17:04 - train: epoch 0178, iter [01800, 05004], lr: 0.003289, loss: 1.6392
2022-07-17 09:17:39 - train: epoch 0178, iter [01900, 05004], lr: 0.003284, loss: 1.5348
2022-07-17 09:18:14 - train: epoch 0178, iter [02000, 05004], lr: 0.003278, loss: 1.8963
2022-07-17 09:18:48 - train: epoch 0178, iter [02100, 05004], lr: 0.003272, loss: 1.8279
2022-07-17 09:19:22 - train: epoch 0178, iter [02200, 05004], lr: 0.003266, loss: 1.6912
2022-07-17 09:19:56 - train: epoch 0178, iter [02300, 05004], lr: 0.003261, loss: 1.7441
2022-07-17 09:20:31 - train: epoch 0178, iter [02400, 05004], lr: 0.003255, loss: 1.7901
2022-07-17 09:21:06 - train: epoch 0178, iter [02500, 05004], lr: 0.003249, loss: 1.6954
2022-07-17 09:21:40 - train: epoch 0178, iter [02600, 05004], lr: 0.003244, loss: 1.6744
2022-07-17 09:22:15 - train: epoch 0178, iter [02700, 05004], lr: 0.003238, loss: 1.7439
2022-07-17 09:22:50 - train: epoch 0178, iter [02800, 05004], lr: 0.003232, loss: 1.6308
2022-07-17 09:23:25 - train: epoch 0178, iter [02900, 05004], lr: 0.003227, loss: 2.0311
2022-07-17 09:23:59 - train: epoch 0178, iter [03000, 05004], lr: 0.003221, loss: 1.6938
2022-07-17 09:24:34 - train: epoch 0178, iter [03100, 05004], lr: 0.003215, loss: 1.8318
2022-07-17 09:25:08 - train: epoch 0178, iter [03200, 05004], lr: 0.003209, loss: 1.9481
2022-07-17 09:25:43 - train: epoch 0178, iter [03300, 05004], lr: 0.003204, loss: 1.7091
2022-07-17 09:26:17 - train: epoch 0178, iter [03400, 05004], lr: 0.003198, loss: 1.6897
2022-07-17 09:26:51 - train: epoch 0178, iter [03500, 05004], lr: 0.003192, loss: 1.7570
2022-07-17 09:27:26 - train: epoch 0178, iter [03600, 05004], lr: 0.003187, loss: 1.8897
2022-07-17 09:28:00 - train: epoch 0178, iter [03700, 05004], lr: 0.003181, loss: 1.9293
2022-07-17 09:28:35 - train: epoch 0178, iter [03800, 05004], lr: 0.003176, loss: 1.6916
2022-07-17 09:29:10 - train: epoch 0178, iter [03900, 05004], lr: 0.003170, loss: 1.7947
2022-07-17 09:29:45 - train: epoch 0178, iter [04000, 05004], lr: 0.003164, loss: 1.7271
2022-07-17 09:30:19 - train: epoch 0178, iter [04100, 05004], lr: 0.003159, loss: 1.7405
2022-07-17 09:30:55 - train: epoch 0178, iter [04200, 05004], lr: 0.003153, loss: 1.5844
2022-07-17 09:31:30 - train: epoch 0178, iter [04300, 05004], lr: 0.003147, loss: 1.5883
2022-07-17 09:32:05 - train: epoch 0178, iter [04400, 05004], lr: 0.003142, loss: 1.7850
2022-07-17 09:32:40 - train: epoch 0178, iter [04500, 05004], lr: 0.003136, loss: 1.8951
2022-07-17 09:33:15 - train: epoch 0178, iter [04600, 05004], lr: 0.003130, loss: 1.9174
2022-07-17 09:33:49 - train: epoch 0178, iter [04700, 05004], lr: 0.003125, loss: 1.6729
2022-07-17 09:34:24 - train: epoch 0178, iter [04800, 05004], lr: 0.003119, loss: 1.7399
2022-07-17 09:34:59 - train: epoch 0178, iter [04900, 05004], lr: 0.003114, loss: 1.8371
2022-07-17 09:35:32 - train: epoch 0178, iter [05000, 05004], lr: 0.003108, loss: 1.7967
2022-07-17 09:35:33 - train: epoch 178, train_loss: 1.7812
2022-07-17 09:36:48 - eval: epoch: 178, acc1: 75.812%, acc5: 92.924%, test_loss: 0.9589, per_image_load_time: 1.425ms, per_image_inference_time: 0.485ms
2022-07-17 09:36:49 - until epoch: 178, best_acc1: 75.812%
2022-07-17 09:36:49 - epoch 179 lr: 0.003108
2022-07-17 09:37:28 - train: epoch 0179, iter [00100, 05004], lr: 0.003102, loss: 2.2295
2022-07-17 09:38:02 - train: epoch 0179, iter [00200, 05004], lr: 0.003097, loss: 1.7951
2022-07-17 09:38:37 - train: epoch 0179, iter [00300, 05004], lr: 0.003091, loss: 1.8518
2022-07-17 09:39:12 - train: epoch 0179, iter [00400, 05004], lr: 0.003086, loss: 1.8450
2022-07-17 09:39:47 - train: epoch 0179, iter [00500, 05004], lr: 0.003080, loss: 1.8181
2022-07-17 09:40:21 - train: epoch 0179, iter [00600, 05004], lr: 0.003074, loss: 1.7160
2022-07-17 09:40:56 - train: epoch 0179, iter [00700, 05004], lr: 0.003069, loss: 1.7465
2022-07-17 09:41:30 - train: epoch 0179, iter [00800, 05004], lr: 0.003063, loss: 1.8305
2022-07-17 09:42:05 - train: epoch 0179, iter [00900, 05004], lr: 0.003058, loss: 1.7905
2022-07-17 09:42:40 - train: epoch 0179, iter [01000, 05004], lr: 0.003052, loss: 1.7393
2022-07-17 09:43:14 - train: epoch 0179, iter [01100, 05004], lr: 0.003047, loss: 1.8820
2022-07-17 09:43:49 - train: epoch 0179, iter [01200, 05004], lr: 0.003041, loss: 1.5751
2022-07-17 09:44:24 - train: epoch 0179, iter [01300, 05004], lr: 0.003036, loss: 1.7543
2022-07-17 09:44:59 - train: epoch 0179, iter [01400, 05004], lr: 0.003030, loss: 1.8229
2022-07-17 09:45:33 - train: epoch 0179, iter [01500, 05004], lr: 0.003025, loss: 1.6171
2022-07-17 09:46:07 - train: epoch 0179, iter [01600, 05004], lr: 0.003019, loss: 1.7708
2022-07-17 09:46:41 - train: epoch 0179, iter [01700, 05004], lr: 0.003014, loss: 1.7804
2022-07-17 09:47:16 - train: epoch 0179, iter [01800, 05004], lr: 0.003008, loss: 1.8928
2022-07-17 09:47:50 - train: epoch 0179, iter [01900, 05004], lr: 0.003003, loss: 1.8979
2022-07-17 09:48:25 - train: epoch 0179, iter [02000, 05004], lr: 0.002997, loss: 2.1287
2022-07-17 09:49:00 - train: epoch 0179, iter [02100, 05004], lr: 0.002992, loss: 1.8517
2022-07-17 09:49:34 - train: epoch 0179, iter [02200, 05004], lr: 0.002986, loss: 1.6349
2022-07-17 09:50:10 - train: epoch 0179, iter [02300, 05004], lr: 0.002981, loss: 1.5883
2022-07-17 09:50:44 - train: epoch 0179, iter [02400, 05004], lr: 0.002975, loss: 1.6624
2022-07-17 09:51:19 - train: epoch 0179, iter [02500, 05004], lr: 0.002970, loss: 1.8437
2022-07-17 09:51:53 - train: epoch 0179, iter [02600, 05004], lr: 0.002964, loss: 1.8745
2022-07-17 09:52:28 - train: epoch 0179, iter [02700, 05004], lr: 0.002959, loss: 1.7713
2022-07-17 09:53:03 - train: epoch 0179, iter [02800, 05004], lr: 0.002953, loss: 2.0401
2022-07-17 09:53:38 - train: epoch 0179, iter [02900, 05004], lr: 0.002948, loss: 1.7979
2022-07-17 09:54:13 - train: epoch 0179, iter [03000, 05004], lr: 0.002942, loss: 1.7160
2022-07-17 09:54:48 - train: epoch 0179, iter [03100, 05004], lr: 0.002937, loss: 1.5572
2022-07-17 09:55:23 - train: epoch 0179, iter [03200, 05004], lr: 0.002932, loss: 1.7745
2022-07-17 09:55:58 - train: epoch 0179, iter [03300, 05004], lr: 0.002926, loss: 1.8126
2022-07-17 09:56:32 - train: epoch 0179, iter [03400, 05004], lr: 0.002921, loss: 1.8513
2022-07-17 09:57:07 - train: epoch 0179, iter [03500, 05004], lr: 0.002915, loss: 1.6330
2022-07-17 09:57:42 - train: epoch 0179, iter [03600, 05004], lr: 0.002910, loss: 2.0821
2022-07-17 09:58:16 - train: epoch 0179, iter [03700, 05004], lr: 0.002904, loss: 1.8447
2022-07-17 09:58:51 - train: epoch 0179, iter [03800, 05004], lr: 0.002899, loss: 1.7702
2022-07-17 09:59:25 - train: epoch 0179, iter [03900, 05004], lr: 0.002894, loss: 1.8889
2022-07-17 10:00:00 - train: epoch 0179, iter [04000, 05004], lr: 0.002888, loss: 1.9589
2022-07-17 10:00:36 - train: epoch 0179, iter [04100, 05004], lr: 0.002883, loss: 1.6496
2022-07-17 10:01:10 - train: epoch 0179, iter [04200, 05004], lr: 0.002878, loss: 1.7765
2022-07-17 10:01:45 - train: epoch 0179, iter [04300, 05004], lr: 0.002872, loss: 2.2222
2022-07-17 10:02:20 - train: epoch 0179, iter [04400, 05004], lr: 0.002867, loss: 1.9246
2022-07-17 10:02:54 - train: epoch 0179, iter [04500, 05004], lr: 0.002861, loss: 1.8185
2022-07-17 10:03:29 - train: epoch 0179, iter [04600, 05004], lr: 0.002856, loss: 1.5926
2022-07-17 10:04:04 - train: epoch 0179, iter [04700, 05004], lr: 0.002851, loss: 1.7257
2022-07-17 10:04:40 - train: epoch 0179, iter [04800, 05004], lr: 0.002845, loss: 1.9172
2022-07-17 10:05:13 - train: epoch 0179, iter [04900, 05004], lr: 0.002840, loss: 1.8194
2022-07-17 10:05:47 - train: epoch 0179, iter [05000, 05004], lr: 0.002835, loss: 1.6432
2022-07-17 10:05:48 - train: epoch 179, train_loss: 1.7681
2022-07-17 10:07:04 - eval: epoch: 179, acc1: 76.200%, acc5: 93.102%, test_loss: 0.9479, per_image_load_time: 2.445ms, per_image_inference_time: 0.479ms
2022-07-17 10:07:04 - until epoch: 179, best_acc1: 76.200%
2022-07-17 10:07:04 - epoch 180 lr: 0.002834
2022-07-17 10:07:43 - train: epoch 0180, iter [00100, 05004], lr: 0.002829, loss: 1.9280
2022-07-17 10:08:18 - train: epoch 0180, iter [00200, 05004], lr: 0.002824, loss: 1.8964
2022-07-17 10:08:52 - train: epoch 0180, iter [00300, 05004], lr: 0.002818, loss: 1.8072
2022-07-17 10:09:26 - train: epoch 0180, iter [00400, 05004], lr: 0.002813, loss: 1.9328
2022-07-17 10:10:01 - train: epoch 0180, iter [00500, 05004], lr: 0.002808, loss: 2.0151
2022-07-17 10:10:36 - train: epoch 0180, iter [00600, 05004], lr: 0.002802, loss: 1.6503
2022-07-17 10:11:10 - train: epoch 0180, iter [00700, 05004], lr: 0.002797, loss: 1.4544
2022-07-17 10:11:45 - train: epoch 0180, iter [00800, 05004], lr: 0.002792, loss: 1.6841
2022-07-17 10:12:19 - train: epoch 0180, iter [00900, 05004], lr: 0.002787, loss: 1.8728
2022-07-17 10:12:54 - train: epoch 0180, iter [01000, 05004], lr: 0.002781, loss: 1.6098
2022-07-17 10:13:28 - train: epoch 0180, iter [01100, 05004], lr: 0.002776, loss: 1.8172
2022-07-17 10:14:03 - train: epoch 0180, iter [01200, 05004], lr: 0.002771, loss: 1.4953
2022-07-17 10:14:38 - train: epoch 0180, iter [01300, 05004], lr: 0.002765, loss: 1.8427
2022-07-17 10:15:13 - train: epoch 0180, iter [01400, 05004], lr: 0.002760, loss: 1.7314
2022-07-17 10:15:48 - train: epoch 0180, iter [01500, 05004], lr: 0.002755, loss: 1.7614
2022-07-17 10:16:23 - train: epoch 0180, iter [01600, 05004], lr: 0.002750, loss: 1.8023
2022-07-17 10:16:57 - train: epoch 0180, iter [01700, 05004], lr: 0.002744, loss: 1.6810
2022-07-17 10:17:32 - train: epoch 0180, iter [01800, 05004], lr: 0.002739, loss: 1.8518
2022-07-17 10:18:07 - train: epoch 0180, iter [01900, 05004], lr: 0.002734, loss: 1.8706
2022-07-17 10:18:41 - train: epoch 0180, iter [02000, 05004], lr: 0.002729, loss: 1.9015
2022-07-17 10:19:16 - train: epoch 0180, iter [02100, 05004], lr: 0.002723, loss: 1.6389
2022-07-17 10:19:51 - train: epoch 0180, iter [02200, 05004], lr: 0.002718, loss: 1.7462
2022-07-17 10:20:25 - train: epoch 0180, iter [02300, 05004], lr: 0.002713, loss: 1.8519
2022-07-17 10:21:01 - train: epoch 0180, iter [02400, 05004], lr: 0.002708, loss: 1.8051
2022-07-17 10:21:35 - train: epoch 0180, iter [02500, 05004], lr: 0.002702, loss: 1.6348
2022-07-17 10:22:09 - train: epoch 0180, iter [02600, 05004], lr: 0.002697, loss: 1.5203
2022-07-17 10:22:43 - train: epoch 0180, iter [02700, 05004], lr: 0.002692, loss: 1.6737
2022-07-17 10:23:18 - train: epoch 0180, iter [02800, 05004], lr: 0.002687, loss: 1.6076
2022-07-17 10:23:52 - train: epoch 0180, iter [02900, 05004], lr: 0.002682, loss: 1.6876
2022-07-17 10:24:26 - train: epoch 0180, iter [03000, 05004], lr: 0.002676, loss: 1.7410
2022-07-17 10:25:01 - train: epoch 0180, iter [03100, 05004], lr: 0.002671, loss: 1.7228
2022-07-17 10:25:36 - train: epoch 0180, iter [03200, 05004], lr: 0.002666, loss: 1.7357
2022-07-17 10:26:10 - train: epoch 0180, iter [03300, 05004], lr: 0.002661, loss: 2.0542
2022-07-17 10:26:45 - train: epoch 0180, iter [03400, 05004], lr: 0.002656, loss: 1.8703
2022-07-17 10:27:19 - train: epoch 0180, iter [03500, 05004], lr: 0.002650, loss: 1.6043
2022-07-17 10:27:54 - train: epoch 0180, iter [03600, 05004], lr: 0.002645, loss: 1.7217
2022-07-17 10:28:29 - train: epoch 0180, iter [03700, 05004], lr: 0.002640, loss: 1.9082
2022-07-17 10:29:03 - train: epoch 0180, iter [03800, 05004], lr: 0.002635, loss: 1.6581
2022-07-17 10:29:38 - train: epoch 0180, iter [03900, 05004], lr: 0.002630, loss: 1.7376
2022-07-17 10:30:13 - train: epoch 0180, iter [04000, 05004], lr: 0.002625, loss: 1.7772
2022-07-17 10:30:47 - train: epoch 0180, iter [04100, 05004], lr: 0.002619, loss: 1.9200
2022-07-17 10:31:22 - train: epoch 0180, iter [04200, 05004], lr: 0.002614, loss: 1.6989
2022-07-17 10:31:58 - train: epoch 0180, iter [04300, 05004], lr: 0.002609, loss: 1.9283
2022-07-17 10:32:31 - train: epoch 0180, iter [04400, 05004], lr: 0.002604, loss: 1.8879
2022-07-17 10:33:05 - train: epoch 0180, iter [04500, 05004], lr: 0.002599, loss: 1.7741
2022-07-17 10:33:41 - train: epoch 0180, iter [04600, 05004], lr: 0.002594, loss: 1.6864
2022-07-17 10:34:15 - train: epoch 0180, iter [04700, 05004], lr: 0.002589, loss: 1.7366
2022-07-17 10:34:50 - train: epoch 0180, iter [04800, 05004], lr: 0.002584, loss: 1.4694
2022-07-17 10:35:25 - train: epoch 0180, iter [04900, 05004], lr: 0.002578, loss: 1.6703
2022-07-17 10:35:58 - train: epoch 0180, iter [05000, 05004], lr: 0.002573, loss: 1.4831
2022-07-17 10:35:59 - train: epoch 180, train_loss: 1.7560
2022-07-17 10:37:14 - eval: epoch: 180, acc1: 76.000%, acc5: 93.170%, test_loss: 0.9409, per_image_load_time: 2.042ms, per_image_inference_time: 0.469ms
2022-07-17 10:37:14 - until epoch: 180, best_acc1: 76.200%
2022-07-17 10:37:14 - epoch 181 lr: 0.002573
2022-07-17 10:37:54 - train: epoch 0181, iter [00100, 05004], lr: 0.002568, loss: 1.8514
2022-07-17 10:38:28 - train: epoch 0181, iter [00200, 05004], lr: 0.002563, loss: 1.6886
2022-07-17 10:39:03 - train: epoch 0181, iter [00300, 05004], lr: 0.002558, loss: 1.8927
2022-07-17 10:39:37 - train: epoch 0181, iter [00400, 05004], lr: 0.002553, loss: 1.4801
2022-07-17 10:40:12 - train: epoch 0181, iter [00500, 05004], lr: 0.002548, loss: 1.5516
2022-07-17 10:40:46 - train: epoch 0181, iter [00600, 05004], lr: 0.002543, loss: 1.5833
2022-07-17 10:41:21 - train: epoch 0181, iter [00700, 05004], lr: 0.002538, loss: 1.4609
2022-07-17 10:41:55 - train: epoch 0181, iter [00800, 05004], lr: 0.002533, loss: 1.5213
2022-07-17 10:42:30 - train: epoch 0181, iter [00900, 05004], lr: 0.002527, loss: 1.8465
2022-07-17 10:43:04 - train: epoch 0181, iter [01000, 05004], lr: 0.002522, loss: 1.6673
2022-07-17 10:43:39 - train: epoch 0181, iter [01100, 05004], lr: 0.002517, loss: 1.7181
2022-07-17 10:44:14 - train: epoch 0181, iter [01200, 05004], lr: 0.002512, loss: 1.7695
2022-07-17 10:44:48 - train: epoch 0181, iter [01300, 05004], lr: 0.002507, loss: 1.9577
2022-07-17 10:45:23 - train: epoch 0181, iter [01400, 05004], lr: 0.002502, loss: 1.6180
2022-07-17 10:45:57 - train: epoch 0181, iter [01500, 05004], lr: 0.002497, loss: 1.8873
2022-07-17 10:46:31 - train: epoch 0181, iter [01600, 05004], lr: 0.002492, loss: 1.7031
2022-07-17 10:47:06 - train: epoch 0181, iter [01700, 05004], lr: 0.002487, loss: 1.5543
2022-07-17 10:47:41 - train: epoch 0181, iter [01800, 05004], lr: 0.002482, loss: 1.8090
2022-07-17 10:48:16 - train: epoch 0181, iter [01900, 05004], lr: 0.002477, loss: 1.6700
2022-07-17 10:48:50 - train: epoch 0181, iter [02000, 05004], lr: 0.002472, loss: 1.8369
2022-07-17 10:49:25 - train: epoch 0181, iter [02100, 05004], lr: 0.002467, loss: 1.7127
2022-07-17 10:49:59 - train: epoch 0181, iter [02200, 05004], lr: 0.002462, loss: 1.5727
2022-07-17 10:50:34 - train: epoch 0181, iter [02300, 05004], lr: 0.002457, loss: 1.9090
2022-07-17 10:51:08 - train: epoch 0181, iter [02400, 05004], lr: 0.002452, loss: 1.6620
2022-07-17 10:51:42 - train: epoch 0181, iter [02500, 05004], lr: 0.002447, loss: 1.8335
2022-07-17 10:52:17 - train: epoch 0181, iter [02600, 05004], lr: 0.002442, loss: 1.7982
2022-07-17 10:52:52 - train: epoch 0181, iter [02700, 05004], lr: 0.002437, loss: 1.6747
2022-07-17 10:53:26 - train: epoch 0181, iter [02800, 05004], lr: 0.002432, loss: 1.6327
2022-07-17 10:54:02 - train: epoch 0181, iter [02900, 05004], lr: 0.002427, loss: 1.7847
2022-07-17 10:54:35 - train: epoch 0181, iter [03000, 05004], lr: 0.002422, loss: 1.8896
2022-07-17 10:55:10 - train: epoch 0181, iter [03100, 05004], lr: 0.002418, loss: 1.7737
2022-07-17 10:55:44 - train: epoch 0181, iter [03200, 05004], lr: 0.002413, loss: 1.8084
2022-07-17 10:56:20 - train: epoch 0181, iter [03300, 05004], lr: 0.002408, loss: 1.8170
2022-07-17 10:56:53 - train: epoch 0181, iter [03400, 05004], lr: 0.002403, loss: 1.8829
2022-07-17 10:57:28 - train: epoch 0181, iter [03500, 05004], lr: 0.002398, loss: 1.8412
2022-07-17 10:58:03 - train: epoch 0181, iter [03600, 05004], lr: 0.002393, loss: 1.9240
2022-07-17 10:58:38 - train: epoch 0181, iter [03700, 05004], lr: 0.002388, loss: 1.7933
2022-07-17 10:59:13 - train: epoch 0181, iter [03800, 05004], lr: 0.002383, loss: 1.6784
2022-07-17 10:59:47 - train: epoch 0181, iter [03900, 05004], lr: 0.002378, loss: 2.0911
2022-07-17 11:00:22 - train: epoch 0181, iter [04000, 05004], lr: 0.002373, loss: 1.7356
2022-07-17 11:00:56 - train: epoch 0181, iter [04100, 05004], lr: 0.002368, loss: 1.7807
2022-07-17 11:01:30 - train: epoch 0181, iter [04200, 05004], lr: 0.002363, loss: 1.9132
2022-07-17 11:02:05 - train: epoch 0181, iter [04300, 05004], lr: 0.002359, loss: 2.1819
2022-07-17 11:02:40 - train: epoch 0181, iter [04400, 05004], lr: 0.002354, loss: 1.7625
2022-07-17 11:03:15 - train: epoch 0181, iter [04500, 05004], lr: 0.002349, loss: 1.8681
2022-07-17 11:03:50 - train: epoch 0181, iter [04600, 05004], lr: 0.002344, loss: 1.9172
2022-07-17 11:04:25 - train: epoch 0181, iter [04700, 05004], lr: 0.002339, loss: 1.7613
2022-07-17 11:04:59 - train: epoch 0181, iter [04800, 05004], lr: 0.002334, loss: 1.5051
2022-07-17 11:05:35 - train: epoch 0181, iter [04900, 05004], lr: 0.002329, loss: 1.7925
2022-07-17 11:06:08 - train: epoch 0181, iter [05000, 05004], lr: 0.002324, loss: 1.8271
2022-07-17 11:06:09 - train: epoch 181, train_loss: 1.7426
2022-07-17 11:07:25 - eval: epoch: 181, acc1: 76.384%, acc5: 93.146%, test_loss: 0.9378, per_image_load_time: 1.781ms, per_image_inference_time: 0.483ms
2022-07-17 11:07:25 - until epoch: 181, best_acc1: 76.384%
2022-07-17 11:07:25 - epoch 182 lr: 0.002324
2022-07-17 11:08:04 - train: epoch 0182, iter [00100, 05004], lr: 0.002319, loss: 1.5106
2022-07-17 11:08:39 - train: epoch 0182, iter [00200, 05004], lr: 0.002315, loss: 1.9767
2022-07-17 11:09:13 - train: epoch 0182, iter [00300, 05004], lr: 0.002310, loss: 1.7646
2022-07-17 11:09:47 - train: epoch 0182, iter [00400, 05004], lr: 0.002305, loss: 1.7272
2022-07-17 11:10:21 - train: epoch 0182, iter [00500, 05004], lr: 0.002300, loss: 1.8344
2022-07-17 11:10:56 - train: epoch 0182, iter [00600, 05004], lr: 0.002295, loss: 1.8311
2022-07-17 11:11:30 - train: epoch 0182, iter [00700, 05004], lr: 0.002290, loss: 1.8179
2022-07-17 11:12:04 - train: epoch 0182, iter [00800, 05004], lr: 0.002286, loss: 1.7167
2022-07-17 11:12:39 - train: epoch 0182, iter [00900, 05004], lr: 0.002281, loss: 1.8909
2022-07-17 11:13:13 - train: epoch 0182, iter [01000, 05004], lr: 0.002276, loss: 2.1211
2022-07-17 11:13:47 - train: epoch 0182, iter [01100, 05004], lr: 0.002271, loss: 2.0223
2022-07-17 11:14:22 - train: epoch 0182, iter [01200, 05004], lr: 0.002266, loss: 1.5899
2022-07-17 11:14:57 - train: epoch 0182, iter [01300, 05004], lr: 0.002262, loss: 1.7100
2022-07-17 11:15:31 - train: epoch 0182, iter [01400, 05004], lr: 0.002257, loss: 1.6114
2022-07-17 11:16:06 - train: epoch 0182, iter [01500, 05004], lr: 0.002252, loss: 1.7727
2022-07-17 11:16:41 - train: epoch 0182, iter [01600, 05004], lr: 0.002247, loss: 1.6442
2022-07-17 11:17:14 - train: epoch 0182, iter [01700, 05004], lr: 0.002243, loss: 1.7805
2022-07-17 11:17:49 - train: epoch 0182, iter [01800, 05004], lr: 0.002238, loss: 1.8529
2022-07-17 11:18:23 - train: epoch 0182, iter [01900, 05004], lr: 0.002233, loss: 1.7424
2022-07-17 11:18:58 - train: epoch 0182, iter [02000, 05004], lr: 0.002228, loss: 1.8718
2022-07-17 11:19:33 - train: epoch 0182, iter [02100, 05004], lr: 0.002223, loss: 1.6266
2022-07-17 11:20:07 - train: epoch 0182, iter [02200, 05004], lr: 0.002219, loss: 1.5126
2022-07-17 11:20:42 - train: epoch 0182, iter [02300, 05004], lr: 0.002214, loss: 1.6392
2022-07-17 11:21:17 - train: epoch 0182, iter [02400, 05004], lr: 0.002209, loss: 1.8411
2022-07-17 11:21:51 - train: epoch 0182, iter [02500, 05004], lr: 0.002205, loss: 1.6081
2022-07-17 11:22:26 - train: epoch 0182, iter [02600, 05004], lr: 0.002200, loss: 1.5057
2022-07-17 11:23:01 - train: epoch 0182, iter [02700, 05004], lr: 0.002195, loss: 1.7510
2022-07-17 11:23:35 - train: epoch 0182, iter [02800, 05004], lr: 0.002190, loss: 1.8399
2022-07-17 11:24:10 - train: epoch 0182, iter [02900, 05004], lr: 0.002186, loss: 1.5529
2022-07-17 11:24:44 - train: epoch 0182, iter [03000, 05004], lr: 0.002181, loss: 1.6721
2022-07-17 11:25:18 - train: epoch 0182, iter [03100, 05004], lr: 0.002176, loss: 1.6006
2022-07-17 11:25:53 - train: epoch 0182, iter [03200, 05004], lr: 0.002172, loss: 1.7347
2022-07-17 11:26:28 - train: epoch 0182, iter [03300, 05004], lr: 0.002167, loss: 1.8764
2022-07-17 11:27:03 - train: epoch 0182, iter [03400, 05004], lr: 0.002162, loss: 1.7475
2022-07-17 11:27:37 - train: epoch 0182, iter [03500, 05004], lr: 0.002158, loss: 1.7269
2022-07-17 11:28:11 - train: epoch 0182, iter [03600, 05004], lr: 0.002153, loss: 1.7476
2022-07-17 11:28:47 - train: epoch 0182, iter [03700, 05004], lr: 0.002148, loss: 1.5608
2022-07-17 11:29:21 - train: epoch 0182, iter [03800, 05004], lr: 0.002143, loss: 1.8051
2022-07-17 11:29:56 - train: epoch 0182, iter [03900, 05004], lr: 0.002139, loss: 1.7202
2022-07-17 11:30:31 - train: epoch 0182, iter [04000, 05004], lr: 0.002134, loss: 1.8636
2022-07-17 11:31:05 - train: epoch 0182, iter [04100, 05004], lr: 0.002130, loss: 1.7767
2022-07-17 11:31:41 - train: epoch 0182, iter [04200, 05004], lr: 0.002125, loss: 1.7357
2022-07-17 11:32:15 - train: epoch 0182, iter [04300, 05004], lr: 0.002120, loss: 1.6832
2022-07-17 11:32:49 - train: epoch 0182, iter [04400, 05004], lr: 0.002116, loss: 1.5129
2022-07-17 11:33:24 - train: epoch 0182, iter [04500, 05004], lr: 0.002111, loss: 1.7250
2022-07-17 11:33:59 - train: epoch 0182, iter [04600, 05004], lr: 0.002106, loss: 1.7541
2022-07-17 11:34:34 - train: epoch 0182, iter [04700, 05004], lr: 0.002102, loss: 1.6758
2022-07-17 11:35:08 - train: epoch 0182, iter [04800, 05004], lr: 0.002097, loss: 1.8156
2022-07-17 11:35:42 - train: epoch 0182, iter [04900, 05004], lr: 0.002092, loss: 1.6986
2022-07-17 11:36:15 - train: epoch 0182, iter [05000, 05004], lr: 0.002088, loss: 1.7031
2022-07-17 11:36:16 - train: epoch 182, train_loss: 1.7315
2022-07-17 11:37:30 - eval: epoch: 182, acc1: 76.520%, acc5: 93.238%, test_loss: 0.9276, per_image_load_time: 1.623ms, per_image_inference_time: 0.466ms
2022-07-17 11:37:31 - until epoch: 182, best_acc1: 76.520%
2022-07-17 11:37:31 - epoch 183 lr: 0.002088
2022-07-17 11:38:10 - train: epoch 0183, iter [00100, 05004], lr: 0.002083, loss: 1.8989
2022-07-17 11:38:44 - train: epoch 0183, iter [00200, 05004], lr: 0.002079, loss: 1.7940
2022-07-17 11:39:19 - train: epoch 0183, iter [00300, 05004], lr: 0.002074, loss: 1.6432
2022-07-17 11:39:53 - train: epoch 0183, iter [00400, 05004], lr: 0.002069, loss: 1.7979
2022-07-17 11:40:27 - train: epoch 0183, iter [00500, 05004], lr: 0.002065, loss: 1.7543
2022-07-17 11:41:01 - train: epoch 0183, iter [00600, 05004], lr: 0.002060, loss: 1.4818
2022-07-17 11:41:35 - train: epoch 0183, iter [00700, 05004], lr: 0.002056, loss: 1.6594
2022-07-17 11:42:09 - train: epoch 0183, iter [00800, 05004], lr: 0.002051, loss: 1.7449
2022-07-17 11:42:43 - train: epoch 0183, iter [00900, 05004], lr: 0.002046, loss: 1.6883
2022-07-17 11:43:17 - train: epoch 0183, iter [01000, 05004], lr: 0.002042, loss: 1.8186
2022-07-17 11:43:51 - train: epoch 0183, iter [01100, 05004], lr: 0.002037, loss: 1.9611
2022-07-17 11:44:26 - train: epoch 0183, iter [01200, 05004], lr: 0.002033, loss: 1.7176
2022-07-17 11:45:01 - train: epoch 0183, iter [01300, 05004], lr: 0.002028, loss: 1.6235
2022-07-17 11:45:35 - train: epoch 0183, iter [01400, 05004], lr: 0.002024, loss: 1.7530
2022-07-17 11:46:09 - train: epoch 0183, iter [01500, 05004], lr: 0.002019, loss: 1.4801
2022-07-17 11:46:44 - train: epoch 0183, iter [01600, 05004], lr: 0.002015, loss: 1.8023
2022-07-17 11:47:19 - train: epoch 0183, iter [01700, 05004], lr: 0.002010, loss: 1.5112
2022-07-17 11:47:53 - train: epoch 0183, iter [01800, 05004], lr: 0.002006, loss: 1.4044
2022-07-17 11:48:27 - train: epoch 0183, iter [01900, 05004], lr: 0.002001, loss: 1.7782
2022-07-17 11:49:02 - train: epoch 0183, iter [02000, 05004], lr: 0.001997, loss: 1.3563
2022-07-17 11:49:36 - train: epoch 0183, iter [02100, 05004], lr: 0.001992, loss: 1.7521
2022-07-17 11:50:10 - train: epoch 0183, iter [02200, 05004], lr: 0.001988, loss: 1.9031
2022-07-17 11:50:45 - train: epoch 0183, iter [02300, 05004], lr: 0.001983, loss: 1.7700
2022-07-17 11:51:19 - train: epoch 0183, iter [02400, 05004], lr: 0.001979, loss: 1.9143
2022-07-17 11:51:54 - train: epoch 0183, iter [02500, 05004], lr: 0.001974, loss: 1.6022
2022-07-17 11:52:28 - train: epoch 0183, iter [02600, 05004], lr: 0.001970, loss: 1.6093
2022-07-17 11:53:03 - train: epoch 0183, iter [02700, 05004], lr: 0.001965, loss: 1.9830
2022-07-17 11:53:37 - train: epoch 0183, iter [02800, 05004], lr: 0.001961, loss: 1.6033
2022-07-17 11:54:12 - train: epoch 0183, iter [02900, 05004], lr: 0.001956, loss: 1.9287
2022-07-17 11:54:46 - train: epoch 0183, iter [03000, 05004], lr: 0.001952, loss: 1.8369
2022-07-17 11:55:21 - train: epoch 0183, iter [03100, 05004], lr: 0.001947, loss: 1.3212
2022-07-17 11:55:55 - train: epoch 0183, iter [03200, 05004], lr: 0.001943, loss: 1.7076
2022-07-17 11:56:29 - train: epoch 0183, iter [03300, 05004], lr: 0.001939, loss: 1.6799
2022-07-17 11:57:04 - train: epoch 0183, iter [03400, 05004], lr: 0.001934, loss: 1.6737
2022-07-17 11:57:39 - train: epoch 0183, iter [03500, 05004], lr: 0.001930, loss: 1.8943
2022-07-17 11:58:13 - train: epoch 0183, iter [03600, 05004], lr: 0.001925, loss: 1.7225
2022-07-17 11:58:47 - train: epoch 0183, iter [03700, 05004], lr: 0.001921, loss: 1.8667
2022-07-17 11:59:22 - train: epoch 0183, iter [03800, 05004], lr: 0.001916, loss: 1.5007
2022-07-17 11:59:57 - train: epoch 0183, iter [03900, 05004], lr: 0.001912, loss: 1.5523
2022-07-17 12:00:32 - train: epoch 0183, iter [04000, 05004], lr: 0.001908, loss: 1.7545
2022-07-17 12:01:06 - train: epoch 0183, iter [04100, 05004], lr: 0.001903, loss: 1.6346
2022-07-17 12:01:41 - train: epoch 0183, iter [04200, 05004], lr: 0.001899, loss: 1.6804
2022-07-17 12:02:14 - train: epoch 0183, iter [04300, 05004], lr: 0.001894, loss: 1.7580
2022-07-17 12:02:49 - train: epoch 0183, iter [04400, 05004], lr: 0.001890, loss: 1.5721
2022-07-17 12:03:24 - train: epoch 0183, iter [04500, 05004], lr: 0.001886, loss: 1.7299
2022-07-17 12:03:59 - train: epoch 0183, iter [04600, 05004], lr: 0.001881, loss: 1.7747
2022-07-17 12:04:33 - train: epoch 0183, iter [04700, 05004], lr: 0.001877, loss: 1.6517
2022-07-17 12:05:09 - train: epoch 0183, iter [04800, 05004], lr: 0.001872, loss: 1.8039
2022-07-17 12:05:43 - train: epoch 0183, iter [04900, 05004], lr: 0.001868, loss: 1.6744
2022-07-17 12:06:16 - train: epoch 0183, iter [05000, 05004], lr: 0.001864, loss: 1.6059
2022-07-17 12:06:17 - train: epoch 183, train_loss: 1.7155
2022-07-17 12:07:33 - eval: epoch: 183, acc1: 76.626%, acc5: 93.312%, test_loss: 0.9288, per_image_load_time: 2.449ms, per_image_inference_time: 0.478ms
2022-07-17 12:07:33 - until epoch: 183, best_acc1: 76.626%
2022-07-17 12:07:33 - epoch 184 lr: 0.001864
2022-07-17 12:08:12 - train: epoch 0184, iter [00100, 05004], lr: 0.001859, loss: 1.7567
2022-07-17 12:08:47 - train: epoch 0184, iter [00200, 05004], lr: 0.001855, loss: 1.8102
2022-07-17 12:09:21 - train: epoch 0184, iter [00300, 05004], lr: 0.001851, loss: 1.3056
2022-07-17 12:09:57 - train: epoch 0184, iter [00400, 05004], lr: 0.001846, loss: 1.6794
2022-07-17 12:10:31 - train: epoch 0184, iter [00500, 05004], lr: 0.001842, loss: 1.8563
2022-07-17 12:11:05 - train: epoch 0184, iter [00600, 05004], lr: 0.001838, loss: 1.8239
2022-07-17 12:11:39 - train: epoch 0184, iter [00700, 05004], lr: 0.001833, loss: 1.5405
2022-07-17 12:12:14 - train: epoch 0184, iter [00800, 05004], lr: 0.001829, loss: 1.2852
2022-07-17 12:12:48 - train: epoch 0184, iter [00900, 05004], lr: 0.001825, loss: 1.5515
2022-07-17 12:13:22 - train: epoch 0184, iter [01000, 05004], lr: 0.001820, loss: 1.5008
2022-07-17 12:13:56 - train: epoch 0184, iter [01100, 05004], lr: 0.001816, loss: 1.6597
2022-07-17 12:14:30 - train: epoch 0184, iter [01200, 05004], lr: 0.001812, loss: 1.9428
2022-07-17 12:15:05 - train: epoch 0184, iter [01300, 05004], lr: 0.001807, loss: 1.5722
2022-07-17 12:15:39 - train: epoch 0184, iter [01400, 05004], lr: 0.001803, loss: 1.7204
2022-07-17 12:16:14 - train: epoch 0184, iter [01500, 05004], lr: 0.001799, loss: 1.5853
2022-07-17 12:16:49 - train: epoch 0184, iter [01600, 05004], lr: 0.001795, loss: 1.9733
2022-07-17 12:17:24 - train: epoch 0184, iter [01700, 05004], lr: 0.001790, loss: 1.6282
2022-07-17 12:17:58 - train: epoch 0184, iter [01800, 05004], lr: 0.001786, loss: 2.1560
2022-07-17 12:18:33 - train: epoch 0184, iter [01900, 05004], lr: 0.001782, loss: 1.7562
2022-07-17 12:19:08 - train: epoch 0184, iter [02000, 05004], lr: 0.001778, loss: 1.6454
2022-07-17 12:19:42 - train: epoch 0184, iter [02100, 05004], lr: 0.001773, loss: 1.4711
2022-07-17 12:20:16 - train: epoch 0184, iter [02200, 05004], lr: 0.001769, loss: 1.4841
2022-07-17 12:20:52 - train: epoch 0184, iter [02300, 05004], lr: 0.001765, loss: 2.0894
2022-07-17 12:21:26 - train: epoch 0184, iter [02400, 05004], lr: 0.001761, loss: 1.8785
2022-07-17 12:22:00 - train: epoch 0184, iter [02500, 05004], lr: 0.001756, loss: 1.4909
2022-07-17 12:22:35 - train: epoch 0184, iter [02600, 05004], lr: 0.001752, loss: 1.6312
2022-07-17 12:23:09 - train: epoch 0184, iter [02700, 05004], lr: 0.001748, loss: 1.7033
2022-07-17 12:23:44 - train: epoch 0184, iter [02800, 05004], lr: 0.001744, loss: 1.6188
2022-07-17 12:24:19 - train: epoch 0184, iter [02900, 05004], lr: 0.001739, loss: 1.7964
2022-07-17 12:24:53 - train: epoch 0184, iter [03000, 05004], lr: 0.001735, loss: 1.5488
2022-07-17 12:25:28 - train: epoch 0184, iter [03100, 05004], lr: 0.001731, loss: 1.5515
2022-07-17 12:26:02 - train: epoch 0184, iter [03200, 05004], lr: 0.001727, loss: 1.8438
2022-07-17 12:26:37 - train: epoch 0184, iter [03300, 05004], lr: 0.001723, loss: 1.7596
2022-07-17 12:27:11 - train: epoch 0184, iter [03400, 05004], lr: 0.001718, loss: 1.9660
2022-07-17 12:27:46 - train: epoch 0184, iter [03500, 05004], lr: 0.001714, loss: 1.8602
2022-07-17 12:28:21 - train: epoch 0184, iter [03600, 05004], lr: 0.001710, loss: 1.8140
2022-07-17 12:28:56 - train: epoch 0184, iter [03700, 05004], lr: 0.001706, loss: 1.7564
2022-07-17 12:29:31 - train: epoch 0184, iter [03800, 05004], lr: 0.001702, loss: 1.5629
2022-07-17 12:30:05 - train: epoch 0184, iter [03900, 05004], lr: 0.001698, loss: 1.7869
2022-07-17 12:30:40 - train: epoch 0184, iter [04000, 05004], lr: 0.001693, loss: 1.5121
2022-07-17 12:31:13 - train: epoch 0184, iter [04100, 05004], lr: 0.001689, loss: 1.9301
2022-07-17 12:31:47 - train: epoch 0184, iter [04200, 05004], lr: 0.001685, loss: 1.6170
2022-07-17 12:32:22 - train: epoch 0184, iter [04300, 05004], lr: 0.001681, loss: 1.9090
2022-07-17 12:32:56 - train: epoch 0184, iter [04400, 05004], lr: 0.001677, loss: 1.6668
2022-07-17 12:33:30 - train: epoch 0184, iter [04500, 05004], lr: 0.001673, loss: 1.9364
2022-07-17 12:34:04 - train: epoch 0184, iter [04600, 05004], lr: 0.001669, loss: 1.7984
2022-07-17 12:34:38 - train: epoch 0184, iter [04700, 05004], lr: 0.001664, loss: 1.6283
2022-07-17 12:35:13 - train: epoch 0184, iter [04800, 05004], lr: 0.001660, loss: 1.6927
2022-07-17 12:35:46 - train: epoch 0184, iter [04900, 05004], lr: 0.001656, loss: 1.5406
2022-07-17 12:36:19 - train: epoch 0184, iter [05000, 05004], lr: 0.001652, loss: 1.4927
2022-07-17 12:36:20 - train: epoch 184, train_loss: 1.7061
2022-07-17 12:37:35 - eval: epoch: 184, acc1: 76.814%, acc5: 93.304%, test_loss: 0.9270, per_image_load_time: 2.406ms, per_image_inference_time: 0.479ms
2022-07-17 12:37:36 - until epoch: 184, best_acc1: 76.814%
2022-07-17 12:37:36 - epoch 185 lr: 0.001652
2022-07-17 12:38:15 - train: epoch 0185, iter [00100, 05004], lr: 0.001648, loss: 1.5533
2022-07-17 12:38:49 - train: epoch 0185, iter [00200, 05004], lr: 0.001644, loss: 1.4791
2022-07-17 12:39:23 - train: epoch 0185, iter [00300, 05004], lr: 0.001640, loss: 1.6420
2022-07-17 12:39:58 - train: epoch 0185, iter [00400, 05004], lr: 0.001636, loss: 1.5575
2022-07-17 12:40:31 - train: epoch 0185, iter [00500, 05004], lr: 0.001632, loss: 1.6064
2022-07-17 12:41:06 - train: epoch 0185, iter [00600, 05004], lr: 0.001627, loss: 1.6879
2022-07-17 12:41:40 - train: epoch 0185, iter [00700, 05004], lr: 0.001623, loss: 1.8611
2022-07-17 12:42:15 - train: epoch 0185, iter [00800, 05004], lr: 0.001619, loss: 1.8287
2022-07-17 12:42:49 - train: epoch 0185, iter [00900, 05004], lr: 0.001615, loss: 1.7678
2022-07-17 12:43:24 - train: epoch 0185, iter [01000, 05004], lr: 0.001611, loss: 1.8396
2022-07-17 12:43:58 - train: epoch 0185, iter [01100, 05004], lr: 0.001607, loss: 1.6588
2022-07-17 12:44:32 - train: epoch 0185, iter [01200, 05004], lr: 0.001603, loss: 1.7898
2022-07-17 12:45:08 - train: epoch 0185, iter [01300, 05004], lr: 0.001599, loss: 1.6228
2022-07-17 12:45:42 - train: epoch 0185, iter [01400, 05004], lr: 0.001595, loss: 1.5680
2022-07-17 12:46:17 - train: epoch 0185, iter [01500, 05004], lr: 0.001591, loss: 1.6237
2022-07-17 12:46:50 - train: epoch 0185, iter [01600, 05004], lr: 0.001587, loss: 1.6357
2022-07-17 12:47:25 - train: epoch 0185, iter [01700, 05004], lr: 0.001583, loss: 1.7876
2022-07-17 12:48:00 - train: epoch 0185, iter [01800, 05004], lr: 0.001579, loss: 1.4835
2022-07-17 12:48:35 - train: epoch 0185, iter [01900, 05004], lr: 0.001575, loss: 1.8842
2022-07-17 12:49:10 - train: epoch 0185, iter [02000, 05004], lr: 0.001571, loss: 1.7849
2022-07-17 12:49:45 - train: epoch 0185, iter [02100, 05004], lr: 0.001567, loss: 1.6721
2022-07-17 12:50:19 - train: epoch 0185, iter [02200, 05004], lr: 0.001563, loss: 1.6032
2022-07-17 12:50:53 - train: epoch 0185, iter [02300, 05004], lr: 0.001559, loss: 1.5392
2022-07-17 12:51:28 - train: epoch 0185, iter [02400, 05004], lr: 0.001555, loss: 1.6834
2022-07-17 12:52:03 - train: epoch 0185, iter [02500, 05004], lr: 0.001551, loss: 1.9134
2022-07-17 12:52:37 - train: epoch 0185, iter [02600, 05004], lr: 0.001547, loss: 1.5919
2022-07-17 12:53:11 - train: epoch 0185, iter [02700, 05004], lr: 0.001543, loss: 1.7390
2022-07-17 12:53:45 - train: epoch 0185, iter [02800, 05004], lr: 0.001539, loss: 1.3909
2022-07-17 12:54:20 - train: epoch 0185, iter [02900, 05004], lr: 0.001535, loss: 1.7808
2022-07-17 12:54:54 - train: epoch 0185, iter [03000, 05004], lr: 0.001531, loss: 1.7228
2022-07-17 12:55:29 - train: epoch 0185, iter [03100, 05004], lr: 0.001527, loss: 1.8578
2022-07-17 12:56:03 - train: epoch 0185, iter [03200, 05004], lr: 0.001523, loss: 1.7340
2022-07-17 12:56:39 - train: epoch 0185, iter [03300, 05004], lr: 0.001519, loss: 1.7062
2022-07-17 12:57:13 - train: epoch 0185, iter [03400, 05004], lr: 0.001515, loss: 1.8264
2022-07-17 12:57:48 - train: epoch 0185, iter [03500, 05004], lr: 0.001511, loss: 1.7115
2022-07-17 12:58:22 - train: epoch 0185, iter [03600, 05004], lr: 0.001507, loss: 1.6060
2022-07-17 12:58:56 - train: epoch 0185, iter [03700, 05004], lr: 0.001504, loss: 1.4826
2022-07-17 12:59:32 - train: epoch 0185, iter [03800, 05004], lr: 0.001500, loss: 1.6050
2022-07-17 13:00:06 - train: epoch 0185, iter [03900, 05004], lr: 0.001496, loss: 1.3425
2022-07-17 13:00:40 - train: epoch 0185, iter [04000, 05004], lr: 0.001492, loss: 1.8225
2022-07-17 13:01:14 - train: epoch 0185, iter [04100, 05004], lr: 0.001488, loss: 1.8962
2022-07-17 13:01:48 - train: epoch 0185, iter [04200, 05004], lr: 0.001484, loss: 1.5938
2022-07-17 13:02:23 - train: epoch 0185, iter [04300, 05004], lr: 0.001480, loss: 1.7869
2022-07-17 13:02:58 - train: epoch 0185, iter [04400, 05004], lr: 0.001476, loss: 1.7605
2022-07-17 13:03:33 - train: epoch 0185, iter [04500, 05004], lr: 0.001472, loss: 1.7469
2022-07-17 13:04:08 - train: epoch 0185, iter [04600, 05004], lr: 0.001469, loss: 1.9462
2022-07-17 13:04:42 - train: epoch 0185, iter [04700, 05004], lr: 0.001465, loss: 1.6232
2022-07-17 13:05:16 - train: epoch 0185, iter [04800, 05004], lr: 0.001461, loss: 1.7166
2022-07-17 13:05:51 - train: epoch 0185, iter [04900, 05004], lr: 0.001457, loss: 1.7438
2022-07-17 13:06:24 - train: epoch 0185, iter [05000, 05004], lr: 0.001453, loss: 1.5225
2022-07-17 13:06:26 - train: epoch 185, train_loss: 1.6952
2022-07-17 13:07:41 - eval: epoch: 185, acc1: 76.822%, acc5: 93.526%, test_loss: 0.9141, per_image_load_time: 1.733ms, per_image_inference_time: 0.494ms
2022-07-17 13:07:41 - until epoch: 185, best_acc1: 76.822%
2022-07-17 13:07:41 - epoch 186 lr: 0.001453
2022-07-17 13:08:20 - train: epoch 0186, iter [00100, 05004], lr: 0.001449, loss: 1.7735
2022-07-17 13:08:55 - train: epoch 0186, iter [00200, 05004], lr: 0.001445, loss: 1.7355
2022-07-17 13:09:29 - train: epoch 0186, iter [00300, 05004], lr: 0.001441, loss: 1.6810
2022-07-17 13:10:03 - train: epoch 0186, iter [00400, 05004], lr: 0.001438, loss: 1.4861
2022-07-17 13:10:38 - train: epoch 0186, iter [00500, 05004], lr: 0.001434, loss: 2.0699
2022-07-17 13:11:13 - train: epoch 0186, iter [00600, 05004], lr: 0.001430, loss: 1.7982
2022-07-17 13:11:46 - train: epoch 0186, iter [00700, 05004], lr: 0.001426, loss: 1.7884
2022-07-17 13:12:21 - train: epoch 0186, iter [00800, 05004], lr: 0.001422, loss: 1.7609
2022-07-17 13:12:56 - train: epoch 0186, iter [00900, 05004], lr: 0.001418, loss: 1.8096
2022-07-17 13:13:30 - train: epoch 0186, iter [01000, 05004], lr: 0.001415, loss: 1.6207
2022-07-17 13:14:05 - train: epoch 0186, iter [01100, 05004], lr: 0.001411, loss: 1.6923
2022-07-17 13:14:39 - train: epoch 0186, iter [01200, 05004], lr: 0.001407, loss: 1.5619
2022-07-17 13:15:13 - train: epoch 0186, iter [01300, 05004], lr: 0.001403, loss: 1.4415
2022-07-17 13:15:48 - train: epoch 0186, iter [01400, 05004], lr: 0.001399, loss: 1.5886
2022-07-17 13:16:22 - train: epoch 0186, iter [01500, 05004], lr: 0.001396, loss: 1.8546
2022-07-17 13:16:57 - train: epoch 0186, iter [01600, 05004], lr: 0.001392, loss: 1.5102
2022-07-17 13:17:31 - train: epoch 0186, iter [01700, 05004], lr: 0.001388, loss: 1.7323
2022-07-17 13:18:06 - train: epoch 0186, iter [01800, 05004], lr: 0.001384, loss: 1.7753
2022-07-17 13:18:40 - train: epoch 0186, iter [01900, 05004], lr: 0.001381, loss: 1.6671
2022-07-17 13:19:15 - train: epoch 0186, iter [02000, 05004], lr: 0.001377, loss: 1.6010
2022-07-17 13:19:49 - train: epoch 0186, iter [02100, 05004], lr: 0.001373, loss: 1.7418
2022-07-17 13:20:24 - train: epoch 0186, iter [02200, 05004], lr: 0.001369, loss: 1.7405
2022-07-17 13:20:58 - train: epoch 0186, iter [02300, 05004], lr: 0.001366, loss: 1.6520
2022-07-17 13:21:32 - train: epoch 0186, iter [02400, 05004], lr: 0.001362, loss: 1.5175
2022-07-17 13:22:07 - train: epoch 0186, iter [02500, 05004], lr: 0.001358, loss: 1.7106
2022-07-17 13:22:42 - train: epoch 0186, iter [02600, 05004], lr: 0.001354, loss: 1.5427
2022-07-17 13:23:16 - train: epoch 0186, iter [02700, 05004], lr: 0.001351, loss: 1.8564
2022-07-17 13:23:51 - train: epoch 0186, iter [02800, 05004], lr: 0.001347, loss: 1.6024
2022-07-17 13:24:25 - train: epoch 0186, iter [02900, 05004], lr: 0.001343, loss: 1.6424
2022-07-17 13:24:59 - train: epoch 0186, iter [03000, 05004], lr: 0.001340, loss: 1.7118
2022-07-17 13:25:34 - train: epoch 0186, iter [03100, 05004], lr: 0.001336, loss: 1.5555
2022-07-17 13:26:09 - train: epoch 0186, iter [03200, 05004], lr: 0.001332, loss: 1.8140
2022-07-17 13:26:43 - train: epoch 0186, iter [03300, 05004], lr: 0.001329, loss: 1.7728
2022-07-17 13:27:18 - train: epoch 0186, iter [03400, 05004], lr: 0.001325, loss: 1.7883
2022-07-17 13:27:52 - train: epoch 0186, iter [03500, 05004], lr: 0.001321, loss: 1.5619
2022-07-17 13:28:26 - train: epoch 0186, iter [03600, 05004], lr: 0.001317, loss: 1.7003
2022-07-17 13:29:02 - train: epoch 0186, iter [03700, 05004], lr: 0.001314, loss: 1.8551
2022-07-17 13:29:36 - train: epoch 0186, iter [03800, 05004], lr: 0.001310, loss: 1.5574
2022-07-17 13:30:10 - train: epoch 0186, iter [03900, 05004], lr: 0.001306, loss: 1.8218
2022-07-17 13:30:45 - train: epoch 0186, iter [04000, 05004], lr: 0.001303, loss: 1.5040
2022-07-17 13:31:19 - train: epoch 0186, iter [04100, 05004], lr: 0.001299, loss: 1.6234
2022-07-17 13:31:54 - train: epoch 0186, iter [04200, 05004], lr: 0.001296, loss: 1.8185
2022-07-17 13:32:29 - train: epoch 0186, iter [04300, 05004], lr: 0.001292, loss: 1.8257
2022-07-17 13:33:03 - train: epoch 0186, iter [04400, 05004], lr: 0.001288, loss: 1.6010
2022-07-17 13:33:38 - train: epoch 0186, iter [04500, 05004], lr: 0.001285, loss: 1.7092
2022-07-17 13:34:12 - train: epoch 0186, iter [04600, 05004], lr: 0.001281, loss: 1.5662
2022-07-17 13:34:47 - train: epoch 0186, iter [04700, 05004], lr: 0.001277, loss: 1.8501
2022-07-17 13:35:22 - train: epoch 0186, iter [04800, 05004], lr: 0.001274, loss: 1.7327
2022-07-17 13:35:56 - train: epoch 0186, iter [04900, 05004], lr: 0.001270, loss: 1.6076
2022-07-17 13:36:29 - train: epoch 0186, iter [05000, 05004], lr: 0.001267, loss: 1.9627
2022-07-17 13:36:30 - train: epoch 186, train_loss: 1.6829
2022-07-17 13:37:45 - eval: epoch: 186, acc1: 77.114%, acc5: 93.528%, test_loss: 0.9126, per_image_load_time: 2.419ms, per_image_inference_time: 0.467ms
2022-07-17 13:37:45 - until epoch: 186, best_acc1: 77.114%
2022-07-17 13:37:45 - epoch 187 lr: 0.001266
2022-07-17 13:38:25 - train: epoch 0187, iter [00100, 05004], lr: 0.001263, loss: 1.8266
2022-07-17 13:38:59 - train: epoch 0187, iter [00200, 05004], lr: 0.001259, loss: 1.3439
2022-07-17 13:39:33 - train: epoch 0187, iter [00300, 05004], lr: 0.001256, loss: 1.5120
2022-07-17 13:40:07 - train: epoch 0187, iter [00400, 05004], lr: 0.001252, loss: 1.7872
2022-07-17 13:40:41 - train: epoch 0187, iter [00500, 05004], lr: 0.001249, loss: 1.5265
2022-07-17 13:41:16 - train: epoch 0187, iter [00600, 05004], lr: 0.001245, loss: 1.8187
2022-07-17 13:41:50 - train: epoch 0187, iter [00700, 05004], lr: 0.001241, loss: 1.9284
2022-07-17 13:42:25 - train: epoch 0187, iter [00800, 05004], lr: 0.001238, loss: 2.0846
2022-07-17 13:42:59 - train: epoch 0187, iter [00900, 05004], lr: 0.001234, loss: 1.7821
2022-07-17 13:43:34 - train: epoch 0187, iter [01000, 05004], lr: 0.001231, loss: 1.7156
2022-07-17 13:44:08 - train: epoch 0187, iter [01100, 05004], lr: 0.001227, loss: 1.9360
2022-07-17 13:44:43 - train: epoch 0187, iter [01200, 05004], lr: 0.001224, loss: 1.9747
2022-07-17 13:45:17 - train: epoch 0187, iter [01300, 05004], lr: 0.001220, loss: 1.7642
2022-07-17 13:45:51 - train: epoch 0187, iter [01400, 05004], lr: 0.001217, loss: 1.8570
2022-07-17 13:46:26 - train: epoch 0187, iter [01500, 05004], lr: 0.001213, loss: 1.6245
2022-07-17 13:47:01 - train: epoch 0187, iter [01600, 05004], lr: 0.001209, loss: 1.5925
2022-07-17 13:47:35 - train: epoch 0187, iter [01700, 05004], lr: 0.001206, loss: 1.6525
2022-07-17 13:48:10 - train: epoch 0187, iter [01800, 05004], lr: 0.001202, loss: 1.5476
2022-07-17 13:48:44 - train: epoch 0187, iter [01900, 05004], lr: 0.001199, loss: 1.7565
2022-07-17 13:49:18 - train: epoch 0187, iter [02000, 05004], lr: 0.001195, loss: 1.4524
2022-07-17 13:49:53 - train: epoch 0187, iter [02100, 05004], lr: 0.001192, loss: 1.9219
2022-07-17 13:50:28 - train: epoch 0187, iter [02200, 05004], lr: 0.001188, loss: 1.6701
2022-07-17 13:51:02 - train: epoch 0187, iter [02300, 05004], lr: 0.001185, loss: 1.6374
2022-07-17 13:51:37 - train: epoch 0187, iter [02400, 05004], lr: 0.001181, loss: 1.7681
2022-07-17 13:52:12 - train: epoch 0187, iter [02500, 05004], lr: 0.001178, loss: 1.5586
2022-07-17 13:52:46 - train: epoch 0187, iter [02600, 05004], lr: 0.001175, loss: 1.5864
2022-07-17 13:53:21 - train: epoch 0187, iter [02700, 05004], lr: 0.001171, loss: 1.7607
2022-07-17 13:53:56 - train: epoch 0187, iter [02800, 05004], lr: 0.001168, loss: 1.7494
2022-07-17 13:54:29 - train: epoch 0187, iter [02900, 05004], lr: 0.001164, loss: 1.5031
2022-07-17 13:55:05 - train: epoch 0187, iter [03000, 05004], lr: 0.001161, loss: 1.7568
2022-07-17 13:55:40 - train: epoch 0187, iter [03100, 05004], lr: 0.001157, loss: 1.5962
2022-07-17 13:56:14 - train: epoch 0187, iter [03200, 05004], lr: 0.001154, loss: 1.5337
2022-07-17 13:56:49 - train: epoch 0187, iter [03300, 05004], lr: 0.001150, loss: 1.7793
2022-07-17 13:57:24 - train: epoch 0187, iter [03400, 05004], lr: 0.001147, loss: 1.6894
2022-07-17 13:57:59 - train: epoch 0187, iter [03500, 05004], lr: 0.001144, loss: 1.5188
2022-07-17 13:58:33 - train: epoch 0187, iter [03600, 05004], lr: 0.001140, loss: 1.7789
2022-07-17 13:59:08 - train: epoch 0187, iter [03700, 05004], lr: 0.001137, loss: 1.5109
2022-07-17 13:59:42 - train: epoch 0187, iter [03800, 05004], lr: 0.001133, loss: 1.8744
2022-07-17 14:00:17 - train: epoch 0187, iter [03900, 05004], lr: 0.001130, loss: 1.5073
2022-07-17 14:00:51 - train: epoch 0187, iter [04000, 05004], lr: 0.001126, loss: 1.8420
2022-07-17 14:01:27 - train: epoch 0187, iter [04100, 05004], lr: 0.001123, loss: 1.6710
2022-07-17 14:02:01 - train: epoch 0187, iter [04200, 05004], lr: 0.001120, loss: 1.8298
2022-07-17 14:02:36 - train: epoch 0187, iter [04300, 05004], lr: 0.001116, loss: 1.5503
2022-07-17 14:03:10 - train: epoch 0187, iter [04400, 05004], lr: 0.001113, loss: 1.5863
2022-07-17 14:03:45 - train: epoch 0187, iter [04500, 05004], lr: 0.001110, loss: 1.4486
2022-07-17 14:04:20 - train: epoch 0187, iter [04600, 05004], lr: 0.001106, loss: 1.5457
2022-07-17 14:04:55 - train: epoch 0187, iter [04700, 05004], lr: 0.001103, loss: 1.3867
2022-07-17 14:05:30 - train: epoch 0187, iter [04800, 05004], lr: 0.001099, loss: 1.7162
2022-07-17 14:06:04 - train: epoch 0187, iter [04900, 05004], lr: 0.001096, loss: 1.5853
2022-07-17 14:06:38 - train: epoch 0187, iter [05000, 05004], lr: 0.001093, loss: 1.3866
2022-07-17 14:06:39 - train: epoch 187, train_loss: 1.6703
2022-07-17 14:07:54 - eval: epoch: 187, acc1: 77.144%, acc5: 93.566%, test_loss: 0.9069, per_image_load_time: 1.678ms, per_image_inference_time: 0.473ms
2022-07-17 14:07:55 - until epoch: 187, best_acc1: 77.144%
2022-07-17 14:07:55 - epoch 188 lr: 0.001093
2022-07-17 14:08:33 - train: epoch 0188, iter [00100, 05004], lr: 0.001089, loss: 1.5523
2022-07-17 14:09:08 - train: epoch 0188, iter [00200, 05004], lr: 0.001086, loss: 1.7827
2022-07-17 14:09:42 - train: epoch 0188, iter [00300, 05004], lr: 0.001083, loss: 1.7069
2022-07-17 14:10:17 - train: epoch 0188, iter [00400, 05004], lr: 0.001079, loss: 1.7343
2022-07-17 14:10:51 - train: epoch 0188, iter [00500, 05004], lr: 0.001076, loss: 1.5994
2022-07-17 14:11:26 - train: epoch 0188, iter [00600, 05004], lr: 0.001073, loss: 1.5322
2022-07-17 14:12:00 - train: epoch 0188, iter [00700, 05004], lr: 0.001069, loss: 1.6399
2022-07-17 14:12:35 - train: epoch 0188, iter [00800, 05004], lr: 0.001066, loss: 1.6906
2022-07-17 14:13:09 - train: epoch 0188, iter [00900, 05004], lr: 0.001063, loss: 1.8881
2022-07-17 14:13:44 - train: epoch 0188, iter [01000, 05004], lr: 0.001059, loss: 1.4542
2022-07-17 14:14:19 - train: epoch 0188, iter [01100, 05004], lr: 0.001056, loss: 1.6504
2022-07-17 14:14:54 - train: epoch 0188, iter [01200, 05004], lr: 0.001053, loss: 1.7214
2022-07-17 14:15:29 - train: epoch 0188, iter [01300, 05004], lr: 0.001050, loss: 1.6137
2022-07-17 14:16:03 - train: epoch 0188, iter [01400, 05004], lr: 0.001046, loss: 1.5121
2022-07-17 14:16:39 - train: epoch 0188, iter [01500, 05004], lr: 0.001043, loss: 1.5896
2022-07-17 14:17:12 - train: epoch 0188, iter [01600, 05004], lr: 0.001040, loss: 1.6397
2022-07-17 14:17:47 - train: epoch 0188, iter [01700, 05004], lr: 0.001036, loss: 1.6695
2022-07-17 14:18:21 - train: epoch 0188, iter [01800, 05004], lr: 0.001033, loss: 1.7762
2022-07-17 14:18:56 - train: epoch 0188, iter [01900, 05004], lr: 0.001030, loss: 1.6055
2022-07-17 14:19:30 - train: epoch 0188, iter [02000, 05004], lr: 0.001027, loss: 1.5964
2022-07-17 14:20:05 - train: epoch 0188, iter [02100, 05004], lr: 0.001023, loss: 1.5752
2022-07-17 14:20:40 - train: epoch 0188, iter [02200, 05004], lr: 0.001020, loss: 1.6471
2022-07-17 14:21:14 - train: epoch 0188, iter [02300, 05004], lr: 0.001017, loss: 1.5365
2022-07-17 14:21:49 - train: epoch 0188, iter [02400, 05004], lr: 0.001014, loss: 1.5802
2022-07-17 14:22:23 - train: epoch 0188, iter [02500, 05004], lr: 0.001011, loss: 1.8359
2022-07-17 14:22:58 - train: epoch 0188, iter [02600, 05004], lr: 0.001007, loss: 1.6307
2022-07-17 14:23:32 - train: epoch 0188, iter [02700, 05004], lr: 0.001004, loss: 1.7886
2022-07-17 14:24:07 - train: epoch 0188, iter [02800, 05004], lr: 0.001001, loss: 1.6362
2022-07-17 14:24:41 - train: epoch 0188, iter [02900, 05004], lr: 0.000998, loss: 1.5817
2022-07-17 14:25:15 - train: epoch 0188, iter [03000, 05004], lr: 0.000994, loss: 1.7931
2022-07-17 14:25:50 - train: epoch 0188, iter [03100, 05004], lr: 0.000991, loss: 1.4585
2022-07-17 14:26:25 - train: epoch 0188, iter [03200, 05004], lr: 0.000988, loss: 1.7908
2022-07-17 14:27:00 - train: epoch 0188, iter [03300, 05004], lr: 0.000985, loss: 1.9018
2022-07-17 14:27:34 - train: epoch 0188, iter [03400, 05004], lr: 0.000982, loss: 1.7960
2022-07-17 14:28:09 - train: epoch 0188, iter [03500, 05004], lr: 0.000979, loss: 1.6577
2022-07-17 14:28:43 - train: epoch 0188, iter [03600, 05004], lr: 0.000975, loss: 1.6782
2022-07-17 14:29:18 - train: epoch 0188, iter [03700, 05004], lr: 0.000972, loss: 1.5726
2022-07-17 14:29:53 - train: epoch 0188, iter [03800, 05004], lr: 0.000969, loss: 1.5082
2022-07-17 14:30:27 - train: epoch 0188, iter [03900, 05004], lr: 0.000966, loss: 1.6403
2022-07-17 14:31:02 - train: epoch 0188, iter [04000, 05004], lr: 0.000963, loss: 1.8851
2022-07-17 14:31:37 - train: epoch 0188, iter [04100, 05004], lr: 0.000960, loss: 1.6296
2022-07-17 14:32:11 - train: epoch 0188, iter [04200, 05004], lr: 0.000957, loss: 1.5536
2022-07-17 14:32:46 - train: epoch 0188, iter [04300, 05004], lr: 0.000953, loss: 1.8949
2022-07-17 14:33:20 - train: epoch 0188, iter [04400, 05004], lr: 0.000950, loss: 1.8609
2022-07-17 14:33:55 - train: epoch 0188, iter [04500, 05004], lr: 0.000947, loss: 1.5211
2022-07-17 14:34:30 - train: epoch 0188, iter [04600, 05004], lr: 0.000944, loss: 1.7798
2022-07-17 14:35:04 - train: epoch 0188, iter [04700, 05004], lr: 0.000941, loss: 1.3659
2022-07-17 14:35:39 - train: epoch 0188, iter [04800, 05004], lr: 0.000938, loss: 1.7166
2022-07-17 14:36:13 - train: epoch 0188, iter [04900, 05004], lr: 0.000935, loss: 1.5872
2022-07-17 14:36:46 - train: epoch 0188, iter [05000, 05004], lr: 0.000932, loss: 1.3185
2022-07-17 14:36:47 - train: epoch 188, train_loss: 1.6622
2022-07-17 14:38:03 - eval: epoch: 188, acc1: 77.288%, acc5: 93.610%, test_loss: 0.9010, per_image_load_time: 2.408ms, per_image_inference_time: 0.474ms
2022-07-17 14:38:03 - until epoch: 188, best_acc1: 77.288%
2022-07-17 14:38:03 - epoch 189 lr: 0.000931
2022-07-17 14:38:43 - train: epoch 0189, iter [00100, 05004], lr: 0.000928, loss: 1.8852
2022-07-17 14:39:17 - train: epoch 0189, iter [00200, 05004], lr: 0.000925, loss: 1.6793
2022-07-17 14:39:51 - train: epoch 0189, iter [00300, 05004], lr: 0.000922, loss: 1.5110
2022-07-17 14:40:25 - train: epoch 0189, iter [00400, 05004], lr: 0.000919, loss: 1.3770
2022-07-17 14:40:59 - train: epoch 0189, iter [00500, 05004], lr: 0.000916, loss: 1.5198
2022-07-17 14:41:34 - train: epoch 0189, iter [00600, 05004], lr: 0.000913, loss: 1.5265
2022-07-17 14:42:08 - train: epoch 0189, iter [00700, 05004], lr: 0.000910, loss: 1.6560
2022-07-17 14:42:42 - train: epoch 0189, iter [00800, 05004], lr: 0.000907, loss: 1.4296
2022-07-17 14:43:17 - train: epoch 0189, iter [00900, 05004], lr: 0.000904, loss: 1.7903
2022-07-17 14:43:51 - train: epoch 0189, iter [01000, 05004], lr: 0.000901, loss: 1.9567
2022-07-17 14:44:25 - train: epoch 0189, iter [01100, 05004], lr: 0.000898, loss: 1.3897
2022-07-17 14:44:59 - train: epoch 0189, iter [01200, 05004], lr: 0.000895, loss: 1.4967
2022-07-17 14:45:35 - train: epoch 0189, iter [01300, 05004], lr: 0.000892, loss: 1.8293
2022-07-17 14:46:09 - train: epoch 0189, iter [01400, 05004], lr: 0.000889, loss: 1.7625
2022-07-17 14:46:43 - train: epoch 0189, iter [01500, 05004], lr: 0.000886, loss: 1.7293
2022-07-17 14:47:18 - train: epoch 0189, iter [01600, 05004], lr: 0.000883, loss: 1.5507
2022-07-17 14:47:52 - train: epoch 0189, iter [01700, 05004], lr: 0.000880, loss: 1.6564
2022-07-17 14:48:26 - train: epoch 0189, iter [01800, 05004], lr: 0.000877, loss: 1.5959
2022-07-17 14:49:01 - train: epoch 0189, iter [01900, 05004], lr: 0.000874, loss: 1.5458
2022-07-17 14:49:35 - train: epoch 0189, iter [02000, 05004], lr: 0.000871, loss: 1.5769
2022-07-17 14:50:10 - train: epoch 0189, iter [02100, 05004], lr: 0.000868, loss: 1.7836
2022-07-17 14:50:44 - train: epoch 0189, iter [02200, 05004], lr: 0.000865, loss: 1.5913
2022-07-17 14:51:18 - train: epoch 0189, iter [02300, 05004], lr: 0.000862, loss: 1.7150
2022-07-17 14:51:53 - train: epoch 0189, iter [02400, 05004], lr: 0.000859, loss: 1.6984
2022-07-17 14:52:27 - train: epoch 0189, iter [02500, 05004], lr: 0.000856, loss: 1.5607
2022-07-17 14:53:02 - train: epoch 0189, iter [02600, 05004], lr: 0.000853, loss: 1.6374
2022-07-17 14:53:36 - train: epoch 0189, iter [02700, 05004], lr: 0.000850, loss: 1.7216
2022-07-17 14:54:10 - train: epoch 0189, iter [02800, 05004], lr: 0.000847, loss: 1.5634
2022-07-17 14:54:45 - train: epoch 0189, iter [02900, 05004], lr: 0.000844, loss: 1.6085
2022-07-17 14:55:20 - train: epoch 0189, iter [03000, 05004], lr: 0.000841, loss: 1.3769
2022-07-17 14:55:55 - train: epoch 0189, iter [03100, 05004], lr: 0.000838, loss: 1.5190
2022-07-17 14:56:29 - train: epoch 0189, iter [03200, 05004], lr: 0.000835, loss: 1.7804
2022-07-17 14:57:03 - train: epoch 0189, iter [03300, 05004], lr: 0.000832, loss: 1.4448
2022-07-17 14:57:38 - train: epoch 0189, iter [03400, 05004], lr: 0.000829, loss: 1.4744
2022-07-17 14:58:13 - train: epoch 0189, iter [03500, 05004], lr: 0.000826, loss: 1.4564
2022-07-17 14:58:47 - train: epoch 0189, iter [03600, 05004], lr: 0.000823, loss: 1.8860
2022-07-17 14:59:22 - train: epoch 0189, iter [03700, 05004], lr: 0.000821, loss: 1.6883
2022-07-17 14:59:56 - train: epoch 0189, iter [03800, 05004], lr: 0.000818, loss: 1.5244
2022-07-17 15:00:31 - train: epoch 0189, iter [03900, 05004], lr: 0.000815, loss: 1.6885
2022-07-17 15:01:05 - train: epoch 0189, iter [04000, 05004], lr: 0.000812, loss: 1.6388
2022-07-17 15:01:40 - train: epoch 0189, iter [04100, 05004], lr: 0.000809, loss: 1.6389
2022-07-17 15:02:14 - train: epoch 0189, iter [04200, 05004], lr: 0.000806, loss: 1.6183
2022-07-17 15:02:50 - train: epoch 0189, iter [04300, 05004], lr: 0.000803, loss: 1.6505
2022-07-17 15:03:24 - train: epoch 0189, iter [04400, 05004], lr: 0.000800, loss: 1.8628
2022-07-17 15:04:00 - train: epoch 0189, iter [04500, 05004], lr: 0.000797, loss: 1.7886
2022-07-17 15:04:34 - train: epoch 0189, iter [04600, 05004], lr: 0.000795, loss: 1.7278
2022-07-17 15:05:08 - train: epoch 0189, iter [04700, 05004], lr: 0.000792, loss: 1.6348
2022-07-17 15:05:43 - train: epoch 0189, iter [04800, 05004], lr: 0.000789, loss: 1.5673
2022-07-17 15:06:18 - train: epoch 0189, iter [04900, 05004], lr: 0.000786, loss: 1.6658
2022-07-17 15:06:51 - train: epoch 0189, iter [05000, 05004], lr: 0.000783, loss: 1.5180
2022-07-17 15:06:52 - train: epoch 189, train_loss: 1.6502
2022-07-17 15:08:08 - eval: epoch: 189, acc1: 77.270%, acc5: 93.600%, test_loss: 0.9015, per_image_load_time: 2.447ms, per_image_inference_time: 0.484ms
2022-07-17 15:08:08 - until epoch: 189, best_acc1: 77.288%
2022-07-17 15:08:08 - epoch 190 lr: 0.000783
2022-07-17 15:08:47 - train: epoch 0190, iter [00100, 05004], lr: 0.000780, loss: 1.7274
2022-07-17 15:09:23 - train: epoch 0190, iter [00200, 05004], lr: 0.000777, loss: 1.6198
2022-07-17 15:09:56 - train: epoch 0190, iter [00300, 05004], lr: 0.000775, loss: 1.5974
2022-07-17 15:10:31 - train: epoch 0190, iter [00400, 05004], lr: 0.000772, loss: 1.7555
2022-07-17 15:11:05 - train: epoch 0190, iter [00500, 05004], lr: 0.000769, loss: 1.7534
2022-07-17 15:11:39 - train: epoch 0190, iter [00600, 05004], lr: 0.000766, loss: 2.0803
2022-07-17 15:12:13 - train: epoch 0190, iter [00700, 05004], lr: 0.000763, loss: 1.9236
2022-07-17 15:12:48 - train: epoch 0190, iter [00800, 05004], lr: 0.000761, loss: 1.5979
2022-07-17 15:13:23 - train: epoch 0190, iter [00900, 05004], lr: 0.000758, loss: 1.5471
2022-07-17 15:13:58 - train: epoch 0190, iter [01000, 05004], lr: 0.000755, loss: 1.7431
2022-07-17 15:14:31 - train: epoch 0190, iter [01100, 05004], lr: 0.000752, loss: 1.5931
2022-07-17 15:15:06 - train: epoch 0190, iter [01200, 05004], lr: 0.000749, loss: 1.5047
2022-07-17 15:15:40 - train: epoch 0190, iter [01300, 05004], lr: 0.000747, loss: 1.6272
2022-07-17 15:16:15 - train: epoch 0190, iter [01400, 05004], lr: 0.000744, loss: 1.7193
2022-07-17 15:16:49 - train: epoch 0190, iter [01500, 05004], lr: 0.000741, loss: 1.6429
2022-07-17 15:17:24 - train: epoch 0190, iter [01600, 05004], lr: 0.000738, loss: 1.5298
2022-07-17 15:17:58 - train: epoch 0190, iter [01700, 05004], lr: 0.000736, loss: 1.5874
2022-07-17 15:18:33 - train: epoch 0190, iter [01800, 05004], lr: 0.000733, loss: 1.5723
2022-07-17 15:19:08 - train: epoch 0190, iter [01900, 05004], lr: 0.000730, loss: 1.6649
2022-07-17 15:19:42 - train: epoch 0190, iter [02000, 05004], lr: 0.000727, loss: 1.4446
2022-07-17 15:20:17 - train: epoch 0190, iter [02100, 05004], lr: 0.000725, loss: 1.6440
2022-07-17 15:20:51 - train: epoch 0190, iter [02200, 05004], lr: 0.000722, loss: 1.8017
2022-07-17 15:21:26 - train: epoch 0190, iter [02300, 05004], lr: 0.000719, loss: 1.8297
2022-07-17 15:22:00 - train: epoch 0190, iter [02400, 05004], lr: 0.000716, loss: 1.8301
2022-07-17 15:22:35 - train: epoch 0190, iter [02500, 05004], lr: 0.000714, loss: 1.3554
2022-07-17 15:23:10 - train: epoch 0190, iter [02600, 05004], lr: 0.000711, loss: 1.4741
2022-07-17 15:23:45 - train: epoch 0190, iter [02700, 05004], lr: 0.000708, loss: 1.3272
2022-07-17 15:24:19 - train: epoch 0190, iter [02800, 05004], lr: 0.000706, loss: 1.5863
2022-07-17 15:24:53 - train: epoch 0190, iter [02900, 05004], lr: 0.000703, loss: 1.9756
2022-07-17 15:25:28 - train: epoch 0190, iter [03000, 05004], lr: 0.000700, loss: 1.5882
2022-07-17 15:26:02 - train: epoch 0190, iter [03100, 05004], lr: 0.000698, loss: 1.8005
2022-07-17 15:26:37 - train: epoch 0190, iter [03200, 05004], lr: 0.000695, loss: 1.6963
2022-07-17 15:27:11 - train: epoch 0190, iter [03300, 05004], lr: 0.000692, loss: 1.6342
2022-07-17 15:27:46 - train: epoch 0190, iter [03400, 05004], lr: 0.000690, loss: 1.6766
2022-07-17 15:28:21 - train: epoch 0190, iter [03500, 05004], lr: 0.000687, loss: 1.7337
2022-07-17 15:28:55 - train: epoch 0190, iter [03600, 05004], lr: 0.000684, loss: 1.5667
2022-07-17 15:29:30 - train: epoch 0190, iter [03700, 05004], lr: 0.000682, loss: 1.6438
2022-07-17 15:30:05 - train: epoch 0190, iter [03800, 05004], lr: 0.000679, loss: 1.6483
2022-07-17 15:30:39 - train: epoch 0190, iter [03900, 05004], lr: 0.000676, loss: 1.6952
2022-07-17 15:31:14 - train: epoch 0190, iter [04000, 05004], lr: 0.000674, loss: 1.5738
2022-07-17 15:31:49 - train: epoch 0190, iter [04100, 05004], lr: 0.000671, loss: 1.5781
2022-07-17 15:32:24 - train: epoch 0190, iter [04200, 05004], lr: 0.000668, loss: 1.6988
2022-07-17 15:32:58 - train: epoch 0190, iter [04300, 05004], lr: 0.000666, loss: 1.7309
2022-07-17 15:33:33 - train: epoch 0190, iter [04400, 05004], lr: 0.000663, loss: 1.7285
2022-07-17 15:34:08 - train: epoch 0190, iter [04500, 05004], lr: 0.000661, loss: 1.6984
2022-07-17 15:34:42 - train: epoch 0190, iter [04600, 05004], lr: 0.000658, loss: 1.7794
2022-07-17 15:35:17 - train: epoch 0190, iter [04700, 05004], lr: 0.000655, loss: 1.7822
2022-07-17 15:35:52 - train: epoch 0190, iter [04800, 05004], lr: 0.000653, loss: 1.5802
2022-07-17 15:36:27 - train: epoch 0190, iter [04900, 05004], lr: 0.000650, loss: 2.0185
2022-07-17 15:37:00 - train: epoch 0190, iter [05000, 05004], lr: 0.000648, loss: 1.7904
2022-07-17 15:37:01 - train: epoch 190, train_loss: 1.6461
2022-07-17 15:38:17 - eval: epoch: 190, acc1: 77.576%, acc5: 93.674%, test_loss: 0.8969, per_image_load_time: 2.399ms, per_image_inference_time: 0.472ms
2022-07-17 15:38:17 - until epoch: 190, best_acc1: 77.576%
2022-07-17 15:38:17 - epoch 191 lr: 0.000647
2022-07-17 15:38:57 - train: epoch 0191, iter [00100, 05004], lr: 0.000645, loss: 1.7643
2022-07-17 15:39:30 - train: epoch 0191, iter [00200, 05004], lr: 0.000642, loss: 1.5345
2022-07-17 15:40:06 - train: epoch 0191, iter [00300, 05004], lr: 0.000640, loss: 1.7028
2022-07-17 15:40:40 - train: epoch 0191, iter [00400, 05004], lr: 0.000637, loss: 1.9931
2022-07-17 15:41:14 - train: epoch 0191, iter [00500, 05004], lr: 0.000635, loss: 1.8251
2022-07-17 15:41:48 - train: epoch 0191, iter [00600, 05004], lr: 0.000632, loss: 1.7405
2022-07-17 15:42:22 - train: epoch 0191, iter [00700, 05004], lr: 0.000630, loss: 1.5845
2022-07-17 15:42:57 - train: epoch 0191, iter [00800, 05004], lr: 0.000627, loss: 1.7762
2022-07-17 15:43:30 - train: epoch 0191, iter [00900, 05004], lr: 0.000624, loss: 1.4938
2022-07-17 15:44:05 - train: epoch 0191, iter [01000, 05004], lr: 0.000622, loss: 1.8494
2022-07-17 15:44:40 - train: epoch 0191, iter [01100, 05004], lr: 0.000619, loss: 1.6404
2022-07-17 15:45:15 - train: epoch 0191, iter [01200, 05004], lr: 0.000617, loss: 1.9798
2022-07-17 15:45:50 - train: epoch 0191, iter [01300, 05004], lr: 0.000614, loss: 1.5839
2022-07-17 15:46:24 - train: epoch 0191, iter [01400, 05004], lr: 0.000612, loss: 1.4971
2022-07-17 15:46:59 - train: epoch 0191, iter [01500, 05004], lr: 0.000609, loss: 1.6920
2022-07-17 15:47:33 - train: epoch 0191, iter [01600, 05004], lr: 0.000607, loss: 1.8012
2022-07-17 15:48:08 - train: epoch 0191, iter [01700, 05004], lr: 0.000604, loss: 1.9187
2022-07-17 15:48:42 - train: epoch 0191, iter [01800, 05004], lr: 0.000602, loss: 1.4008
2022-07-17 15:49:17 - train: epoch 0191, iter [01900, 05004], lr: 0.000599, loss: 1.5863
2022-07-17 15:49:52 - train: epoch 0191, iter [02000, 05004], lr: 0.000597, loss: 1.5383
2022-07-17 15:50:26 - train: epoch 0191, iter [02100, 05004], lr: 0.000594, loss: 1.7620
2022-07-17 15:51:01 - train: epoch 0191, iter [02200, 05004], lr: 0.000592, loss: 1.6940
2022-07-17 15:51:35 - train: epoch 0191, iter [02300, 05004], lr: 0.000589, loss: 1.3434
2022-07-17 15:52:10 - train: epoch 0191, iter [02400, 05004], lr: 0.000587, loss: 1.7153
2022-07-17 15:52:44 - train: epoch 0191, iter [02500, 05004], lr: 0.000585, loss: 1.5924
2022-07-17 15:53:19 - train: epoch 0191, iter [02600, 05004], lr: 0.000582, loss: 1.5586
2022-07-17 15:53:55 - train: epoch 0191, iter [02700, 05004], lr: 0.000580, loss: 1.4444
2022-07-17 15:54:30 - train: epoch 0191, iter [02800, 05004], lr: 0.000577, loss: 2.0080
2022-07-17 15:55:04 - train: epoch 0191, iter [02900, 05004], lr: 0.000575, loss: 1.5524
2022-07-17 15:55:39 - train: epoch 0191, iter [03000, 05004], lr: 0.000572, loss: 1.5629
2022-07-17 15:56:13 - train: epoch 0191, iter [03100, 05004], lr: 0.000570, loss: 1.6760
2022-07-17 15:56:48 - train: epoch 0191, iter [03200, 05004], lr: 0.000567, loss: 1.7424
2022-07-17 15:57:23 - train: epoch 0191, iter [03300, 05004], lr: 0.000565, loss: 1.8222
2022-07-17 15:57:57 - train: epoch 0191, iter [03400, 05004], lr: 0.000563, loss: 1.6417
2022-07-17 15:58:32 - train: epoch 0191, iter [03500, 05004], lr: 0.000560, loss: 1.5619
2022-07-17 15:59:06 - train: epoch 0191, iter [03600, 05004], lr: 0.000558, loss: 1.6681
2022-07-17 15:59:41 - train: epoch 0191, iter [03700, 05004], lr: 0.000555, loss: 1.4591
2022-07-17 16:00:16 - train: epoch 0191, iter [03800, 05004], lr: 0.000553, loss: 1.7766
2022-07-17 16:00:51 - train: epoch 0191, iter [03900, 05004], lr: 0.000551, loss: 1.3005
2022-07-17 16:01:26 - train: epoch 0191, iter [04000, 05004], lr: 0.000548, loss: 1.5448
2022-07-17 16:02:00 - train: epoch 0191, iter [04100, 05004], lr: 0.000546, loss: 1.5496
2022-07-17 16:02:35 - train: epoch 0191, iter [04200, 05004], lr: 0.000544, loss: 1.5645
2022-07-17 16:03:09 - train: epoch 0191, iter [04300, 05004], lr: 0.000541, loss: 1.6499
2022-07-17 16:03:43 - train: epoch 0191, iter [04400, 05004], lr: 0.000539, loss: 1.7101
2022-07-17 16:04:17 - train: epoch 0191, iter [04500, 05004], lr: 0.000536, loss: 1.7045
2022-07-17 16:04:52 - train: epoch 0191, iter [04600, 05004], lr: 0.000534, loss: 1.5588
2022-07-17 16:05:27 - train: epoch 0191, iter [04700, 05004], lr: 0.000532, loss: 1.3169
2022-07-17 16:06:01 - train: epoch 0191, iter [04800, 05004], lr: 0.000529, loss: 1.3459
2022-07-17 16:06:37 - train: epoch 0191, iter [04900, 05004], lr: 0.000527, loss: 1.8839
2022-07-17 16:07:09 - train: epoch 0191, iter [05000, 05004], lr: 0.000525, loss: 1.4749
2022-07-17 16:07:10 - train: epoch 191, train_loss: 1.6375
2022-07-17 16:08:25 - eval: epoch: 191, acc1: 77.502%, acc5: 93.752%, test_loss: 0.8924, per_image_load_time: 2.410ms, per_image_inference_time: 0.479ms
2022-07-17 16:08:26 - until epoch: 191, best_acc1: 77.576%
2022-07-17 16:08:26 - epoch 192 lr: 0.000525
2022-07-17 16:09:05 - train: epoch 0192, iter [00100, 05004], lr: 0.000522, loss: 1.8916
2022-07-17 16:09:39 - train: epoch 0192, iter [00200, 05004], lr: 0.000520, loss: 1.7369
2022-07-17 16:10:14 - train: epoch 0192, iter [00300, 05004], lr: 0.000518, loss: 1.4103
2022-07-17 16:10:48 - train: epoch 0192, iter [00400, 05004], lr: 0.000515, loss: 1.6961
2022-07-17 16:11:22 - train: epoch 0192, iter [00500, 05004], lr: 0.000513, loss: 1.7251
2022-07-17 16:11:57 - train: epoch 0192, iter [00600, 05004], lr: 0.000511, loss: 1.7626
2022-07-17 16:12:30 - train: epoch 0192, iter [00700, 05004], lr: 0.000509, loss: 1.9718
2022-07-17 16:13:05 - train: epoch 0192, iter [00800, 05004], lr: 0.000506, loss: 1.7922
2022-07-17 16:13:39 - train: epoch 0192, iter [00900, 05004], lr: 0.000504, loss: 1.6811
2022-07-17 16:14:14 - train: epoch 0192, iter [01000, 05004], lr: 0.000502, loss: 1.5097
2022-07-17 16:14:48 - train: epoch 0192, iter [01100, 05004], lr: 0.000499, loss: 1.7964
2022-07-17 16:15:24 - train: epoch 0192, iter [01200, 05004], lr: 0.000497, loss: 1.5892
2022-07-17 16:15:58 - train: epoch 0192, iter [01300, 05004], lr: 0.000495, loss: 1.4909
2022-07-17 16:16:32 - train: epoch 0192, iter [01400, 05004], lr: 0.000493, loss: 1.5841
2022-07-17 16:17:06 - train: epoch 0192, iter [01500, 05004], lr: 0.000490, loss: 1.6874
2022-07-17 16:17:41 - train: epoch 0192, iter [01600, 05004], lr: 0.000488, loss: 1.6205
2022-07-17 16:18:16 - train: epoch 0192, iter [01700, 05004], lr: 0.000486, loss: 1.4119
2022-07-17 16:18:50 - train: epoch 0192, iter [01800, 05004], lr: 0.000484, loss: 1.6496
2022-07-17 16:19:24 - train: epoch 0192, iter [01900, 05004], lr: 0.000481, loss: 1.5918
2022-07-17 16:19:59 - train: epoch 0192, iter [02000, 05004], lr: 0.000479, loss: 1.6584
2022-07-17 16:20:33 - train: epoch 0192, iter [02100, 05004], lr: 0.000477, loss: 1.7073
2022-07-17 16:21:08 - train: epoch 0192, iter [02200, 05004], lr: 0.000475, loss: 1.5251
2022-07-17 16:21:43 - train: epoch 0192, iter [02300, 05004], lr: 0.000473, loss: 1.6577
2022-07-17 16:22:17 - train: epoch 0192, iter [02400, 05004], lr: 0.000470, loss: 1.6650
2022-07-17 16:22:52 - train: epoch 0192, iter [02500, 05004], lr: 0.000468, loss: 1.8376
2022-07-17 16:23:26 - train: epoch 0192, iter [02600, 05004], lr: 0.000466, loss: 1.8427
2022-07-17 16:24:01 - train: epoch 0192, iter [02700, 05004], lr: 0.000464, loss: 1.5680
2022-07-17 16:24:35 - train: epoch 0192, iter [02800, 05004], lr: 0.000462, loss: 1.6418
2022-07-17 16:25:09 - train: epoch 0192, iter [02900, 05004], lr: 0.000459, loss: 1.6485
2022-07-17 16:25:44 - train: epoch 0192, iter [03000, 05004], lr: 0.000457, loss: 1.6835
2022-07-17 16:26:18 - train: epoch 0192, iter [03100, 05004], lr: 0.000455, loss: 1.7150
2022-07-17 16:26:53 - train: epoch 0192, iter [03200, 05004], lr: 0.000453, loss: 1.6372
2022-07-17 16:27:27 - train: epoch 0192, iter [03300, 05004], lr: 0.000451, loss: 1.8419
2022-07-17 16:28:02 - train: epoch 0192, iter [03400, 05004], lr: 0.000449, loss: 1.9601
2022-07-17 16:28:37 - train: epoch 0192, iter [03500, 05004], lr: 0.000446, loss: 1.3034
2022-07-17 16:29:12 - train: epoch 0192, iter [03600, 05004], lr: 0.000444, loss: 1.6017
2022-07-17 16:29:46 - train: epoch 0192, iter [03700, 05004], lr: 0.000442, loss: 1.7682
2022-07-17 16:30:20 - train: epoch 0192, iter [03800, 05004], lr: 0.000440, loss: 1.4539
2022-07-17 16:30:55 - train: epoch 0192, iter [03900, 05004], lr: 0.000438, loss: 1.7840
2022-07-17 16:31:28 - train: epoch 0192, iter [04000, 05004], lr: 0.000436, loss: 1.7083
2022-07-17 16:32:03 - train: epoch 0192, iter [04100, 05004], lr: 0.000434, loss: 1.8098
2022-07-17 16:32:38 - train: epoch 0192, iter [04200, 05004], lr: 0.000432, loss: 1.8670
2022-07-17 16:33:13 - train: epoch 0192, iter [04300, 05004], lr: 0.000429, loss: 1.3745
2022-07-17 16:33:47 - train: epoch 0192, iter [04400, 05004], lr: 0.000427, loss: 1.6072
2022-07-17 16:34:22 - train: epoch 0192, iter [04500, 05004], lr: 0.000425, loss: 1.7987
2022-07-17 16:34:56 - train: epoch 0192, iter [04600, 05004], lr: 0.000423, loss: 1.6471
2022-07-17 16:35:32 - train: epoch 0192, iter [04700, 05004], lr: 0.000421, loss: 1.4253
2022-07-17 16:36:06 - train: epoch 0192, iter [04800, 05004], lr: 0.000419, loss: 1.6705
2022-07-17 16:36:41 - train: epoch 0192, iter [04900, 05004], lr: 0.000417, loss: 1.5270
2022-07-17 16:37:14 - train: epoch 0192, iter [05000, 05004], lr: 0.000415, loss: 1.4235
2022-07-17 16:37:15 - train: epoch 192, train_loss: 1.6314
2022-07-17 16:38:29 - eval: epoch: 192, acc1: 77.676%, acc5: 93.700%, test_loss: 0.8938, per_image_load_time: 2.365ms, per_image_inference_time: 0.446ms
2022-07-17 16:38:29 - until epoch: 192, best_acc1: 77.676%
2022-07-17 16:38:29 - epoch 193 lr: 0.000415
2022-07-17 16:39:08 - train: epoch 0193, iter [00100, 05004], lr: 0.000413, loss: 1.6185
2022-07-17 16:39:42 - train: epoch 0193, iter [00200, 05004], lr: 0.000411, loss: 1.6158
2022-07-17 16:40:16 - train: epoch 0193, iter [00300, 05004], lr: 0.000409, loss: 1.6208
2022-07-17 16:40:50 - train: epoch 0193, iter [00400, 05004], lr: 0.000406, loss: 1.7758
2022-07-17 16:41:23 - train: epoch 0193, iter [00500, 05004], lr: 0.000404, loss: 1.5800
2022-07-17 16:41:57 - train: epoch 0193, iter [00600, 05004], lr: 0.000402, loss: 1.6090
2022-07-17 16:42:31 - train: epoch 0193, iter [00700, 05004], lr: 0.000400, loss: 1.7518
2022-07-17 16:43:05 - train: epoch 0193, iter [00800, 05004], lr: 0.000398, loss: 1.6363
2022-07-17 16:43:39 - train: epoch 0193, iter [00900, 05004], lr: 0.000396, loss: 1.4556
2022-07-17 16:44:12 - train: epoch 0193, iter [01000, 05004], lr: 0.000394, loss: 1.5597
2022-07-17 16:44:47 - train: epoch 0193, iter [01100, 05004], lr: 0.000392, loss: 1.6112
2022-07-17 16:45:21 - train: epoch 0193, iter [01200, 05004], lr: 0.000390, loss: 1.7717
2022-07-17 16:45:55 - train: epoch 0193, iter [01300, 05004], lr: 0.000388, loss: 1.7376
2022-07-17 16:46:29 - train: epoch 0193, iter [01400, 05004], lr: 0.000386, loss: 1.5320
2022-07-17 16:47:03 - train: epoch 0193, iter [01500, 05004], lr: 0.000384, loss: 1.4439
2022-07-17 16:47:36 - train: epoch 0193, iter [01600, 05004], lr: 0.000382, loss: 1.3406
2022-07-17 16:48:10 - train: epoch 0193, iter [01700, 05004], lr: 0.000380, loss: 1.3855
2022-07-17 16:48:44 - train: epoch 0193, iter [01800, 05004], lr: 0.000378, loss: 1.5917
2022-07-17 16:49:18 - train: epoch 0193, iter [01900, 05004], lr: 0.000376, loss: 1.3702
2022-07-17 16:49:52 - train: epoch 0193, iter [02000, 05004], lr: 0.000374, loss: 1.6941
2022-07-17 16:50:26 - train: epoch 0193, iter [02100, 05004], lr: 0.000372, loss: 1.5357
2022-07-17 16:51:00 - train: epoch 0193, iter [02200, 05004], lr: 0.000370, loss: 1.4816
2022-07-17 16:51:34 - train: epoch 0193, iter [02300, 05004], lr: 0.000368, loss: 1.7173
2022-07-17 16:52:09 - train: epoch 0193, iter [02400, 05004], lr: 0.000367, loss: 1.4906
2022-07-17 16:52:42 - train: epoch 0193, iter [02500, 05004], lr: 0.000365, loss: 1.5913
2022-07-17 16:53:16 - train: epoch 0193, iter [02600, 05004], lr: 0.000363, loss: 1.5557
2022-07-17 16:53:50 - train: epoch 0193, iter [02700, 05004], lr: 0.000361, loss: 1.5932
2022-07-17 16:54:24 - train: epoch 0193, iter [02800, 05004], lr: 0.000359, loss: 1.7069
2022-07-17 16:54:58 - train: epoch 0193, iter [02900, 05004], lr: 0.000357, loss: 1.6236
2022-07-17 16:55:31 - train: epoch 0193, iter [03000, 05004], lr: 0.000355, loss: 1.4397
2022-07-17 16:56:05 - train: epoch 0193, iter [03100, 05004], lr: 0.000353, loss: 1.7513
2022-07-17 16:56:39 - train: epoch 0193, iter [03200, 05004], lr: 0.000351, loss: 1.8268
2022-07-17 16:57:12 - train: epoch 0193, iter [03300, 05004], lr: 0.000349, loss: 2.0506
2022-07-17 16:57:47 - train: epoch 0193, iter [03400, 05004], lr: 0.000347, loss: 1.4611
2022-07-17 16:58:20 - train: epoch 0193, iter [03500, 05004], lr: 0.000345, loss: 1.9126
2022-07-17 16:58:54 - train: epoch 0193, iter [03600, 05004], lr: 0.000344, loss: 1.7973
2022-07-17 16:59:28 - train: epoch 0193, iter [03700, 05004], lr: 0.000342, loss: 1.3345
2022-07-17 17:00:02 - train: epoch 0193, iter [03800, 05004], lr: 0.000340, loss: 1.3756
2022-07-17 17:00:36 - train: epoch 0193, iter [03900, 05004], lr: 0.000338, loss: 1.5072
2022-07-17 17:01:10 - train: epoch 0193, iter [04000, 05004], lr: 0.000336, loss: 1.5012
2022-07-17 17:01:43 - train: epoch 0193, iter [04100, 05004], lr: 0.000334, loss: 1.7135
2022-07-17 17:02:18 - train: epoch 0193, iter [04200, 05004], lr: 0.000332, loss: 1.4966
2022-07-17 17:02:51 - train: epoch 0193, iter [04300, 05004], lr: 0.000331, loss: 1.6597
2022-07-17 17:03:26 - train: epoch 0193, iter [04400, 05004], lr: 0.000329, loss: 1.4590
2022-07-17 17:04:00 - train: epoch 0193, iter [04500, 05004], lr: 0.000327, loss: 1.4359
2022-07-17 17:04:33 - train: epoch 0193, iter [04600, 05004], lr: 0.000325, loss: 1.8076
2022-07-17 17:05:07 - train: epoch 0193, iter [04700, 05004], lr: 0.000323, loss: 1.6258
2022-07-17 17:05:41 - train: epoch 0193, iter [04800, 05004], lr: 0.000321, loss: 1.8220
2022-07-17 17:06:15 - train: epoch 0193, iter [04900, 05004], lr: 0.000320, loss: 1.6335
2022-07-17 17:06:49 - train: epoch 0193, iter [05000, 05004], lr: 0.000318, loss: 1.6779
2022-07-17 17:06:50 - train: epoch 193, train_loss: 1.6250
2022-07-17 17:08:05 - eval: epoch: 193, acc1: 77.634%, acc5: 93.724%, test_loss: 0.8913, per_image_load_time: 2.431ms, per_image_inference_time: 0.471ms
2022-07-17 17:08:05 - until epoch: 193, best_acc1: 77.676%
2022-07-17 17:08:05 - epoch 194 lr: 0.000318
2022-07-17 17:08:44 - train: epoch 0194, iter [00100, 05004], lr: 0.000316, loss: 1.6455
2022-07-17 17:09:19 - train: epoch 0194, iter [00200, 05004], lr: 0.000314, loss: 1.7555
2022-07-17 17:09:53 - train: epoch 0194, iter [00300, 05004], lr: 0.000312, loss: 1.6048
2022-07-17 17:10:27 - train: epoch 0194, iter [00400, 05004], lr: 0.000310, loss: 1.5112
2022-07-17 17:11:02 - train: epoch 0194, iter [00500, 05004], lr: 0.000309, loss: 1.6456
2022-07-17 17:11:36 - train: epoch 0194, iter [00600, 05004], lr: 0.000307, loss: 1.4401
2022-07-17 17:12:11 - train: epoch 0194, iter [00700, 05004], lr: 0.000305, loss: 1.5192
2022-07-17 17:12:45 - train: epoch 0194, iter [00800, 05004], lr: 0.000303, loss: 1.5232
2022-07-17 17:13:19 - train: epoch 0194, iter [00900, 05004], lr: 0.000302, loss: 1.5090
2022-07-17 17:13:53 - train: epoch 0194, iter [01000, 05004], lr: 0.000300, loss: 1.3875
2022-07-17 17:14:27 - train: epoch 0194, iter [01100, 05004], lr: 0.000298, loss: 1.5430
2022-07-17 17:15:01 - train: epoch 0194, iter [01200, 05004], lr: 0.000296, loss: 1.4121
2022-07-17 17:15:34 - train: epoch 0194, iter [01300, 05004], lr: 0.000295, loss: 1.7148
2022-07-17 17:16:08 - train: epoch 0194, iter [01400, 05004], lr: 0.000293, loss: 1.5949
2022-07-17 17:16:42 - train: epoch 0194, iter [01500, 05004], lr: 0.000291, loss: 1.5767
2022-07-17 17:17:16 - train: epoch 0194, iter [01600, 05004], lr: 0.000289, loss: 1.8380
2022-07-17 17:17:49 - train: epoch 0194, iter [01700, 05004], lr: 0.000288, loss: 1.6562
2022-07-17 17:18:24 - train: epoch 0194, iter [01800, 05004], lr: 0.000286, loss: 1.6963
2022-07-17 17:18:58 - train: epoch 0194, iter [01900, 05004], lr: 0.000284, loss: 1.6436
2022-07-17 17:19:32 - train: epoch 0194, iter [02000, 05004], lr: 0.000282, loss: 1.9921
2022-07-17 17:20:05 - train: epoch 0194, iter [02100, 05004], lr: 0.000281, loss: 1.7663
2022-07-17 17:20:40 - train: epoch 0194, iter [02200, 05004], lr: 0.000279, loss: 1.4755
2022-07-17 17:21:13 - train: epoch 0194, iter [02300, 05004], lr: 0.000277, loss: 1.4199
2022-07-17 17:21:47 - train: epoch 0194, iter [02400, 05004], lr: 0.000276, loss: 1.4654
2022-07-17 17:22:20 - train: epoch 0194, iter [02500, 05004], lr: 0.000274, loss: 1.7223
2022-07-17 17:22:54 - train: epoch 0194, iter [02600, 05004], lr: 0.000272, loss: 1.5457
2022-07-17 17:23:28 - train: epoch 0194, iter [02700, 05004], lr: 0.000271, loss: 1.4987
2022-07-17 17:24:03 - train: epoch 0194, iter [02800, 05004], lr: 0.000269, loss: 1.7936
2022-07-17 17:24:36 - train: epoch 0194, iter [02900, 05004], lr: 0.000267, loss: 1.8879
2022-07-17 17:25:11 - train: epoch 0194, iter [03000, 05004], lr: 0.000266, loss: 1.5452
2022-07-17 17:25:45 - train: epoch 0194, iter [03100, 05004], lr: 0.000264, loss: 1.5662
2022-07-17 17:26:19 - train: epoch 0194, iter [03200, 05004], lr: 0.000262, loss: 1.2849
2022-07-17 17:26:52 - train: epoch 0194, iter [03300, 05004], lr: 0.000261, loss: 1.4541
2022-07-17 17:27:27 - train: epoch 0194, iter [03400, 05004], lr: 0.000259, loss: 1.5244
2022-07-17 17:28:01 - train: epoch 0194, iter [03500, 05004], lr: 0.000257, loss: 1.5558
2022-07-17 17:28:35 - train: epoch 0194, iter [03600, 05004], lr: 0.000256, loss: 1.4224
2022-07-17 17:29:08 - train: epoch 0194, iter [03700, 05004], lr: 0.000254, loss: 1.3742
2022-07-17 17:29:42 - train: epoch 0194, iter [03800, 05004], lr: 0.000252, loss: 1.4517
2022-07-17 17:30:16 - train: epoch 0194, iter [03900, 05004], lr: 0.000251, loss: 1.7832
2022-07-17 17:30:50 - train: epoch 0194, iter [04000, 05004], lr: 0.000249, loss: 1.3959
2022-07-17 17:31:24 - train: epoch 0194, iter [04100, 05004], lr: 0.000248, loss: 1.3812
2022-07-17 17:31:57 - train: epoch 0194, iter [04200, 05004], lr: 0.000246, loss: 1.5736
2022-07-17 17:32:31 - train: epoch 0194, iter [04300, 05004], lr: 0.000244, loss: 1.7814
2022-07-17 17:33:05 - train: epoch 0194, iter [04400, 05004], lr: 0.000243, loss: 1.5257
2022-07-17 17:33:39 - train: epoch 0194, iter [04500, 05004], lr: 0.000241, loss: 1.5900
2022-07-17 17:34:13 - train: epoch 0194, iter [04600, 05004], lr: 0.000240, loss: 1.7837
2022-07-17 17:34:46 - train: epoch 0194, iter [04700, 05004], lr: 0.000238, loss: 1.7452
2022-07-17 17:35:20 - train: epoch 0194, iter [04800, 05004], lr: 0.000237, loss: 1.6022
2022-07-17 17:35:54 - train: epoch 0194, iter [04900, 05004], lr: 0.000235, loss: 1.8172
2022-07-17 17:36:27 - train: epoch 0194, iter [05000, 05004], lr: 0.000233, loss: 1.5925
2022-07-17 17:36:28 - train: epoch 194, train_loss: 1.6161
2022-07-17 17:37:43 - eval: epoch: 194, acc1: 77.766%, acc5: 93.846%, test_loss: 0.8879, per_image_load_time: 2.439ms, per_image_inference_time: 0.471ms
2022-07-17 17:37:43 - until epoch: 194, best_acc1: 77.766%
2022-07-17 17:37:43 - epoch 195 lr: 0.000233
2022-07-17 17:38:22 - train: epoch 0195, iter [00100, 05004], lr: 0.000232, loss: 1.5251
2022-07-17 17:38:57 - train: epoch 0195, iter [00200, 05004], lr: 0.000230, loss: 1.5766
2022-07-17 17:39:31 - train: epoch 0195, iter [00300, 05004], lr: 0.000229, loss: 1.4533
2022-07-17 17:40:06 - train: epoch 0195, iter [00400, 05004], lr: 0.000227, loss: 1.5615
2022-07-17 17:40:40 - train: epoch 0195, iter [00500, 05004], lr: 0.000226, loss: 1.5602
2022-07-17 17:41:14 - train: epoch 0195, iter [00600, 05004], lr: 0.000224, loss: 1.7245
2022-07-17 17:41:49 - train: epoch 0195, iter [00700, 05004], lr: 0.000223, loss: 1.7507
2022-07-17 17:42:24 - train: epoch 0195, iter [00800, 05004], lr: 0.000221, loss: 1.4315
2022-07-17 17:42:58 - train: epoch 0195, iter [00900, 05004], lr: 0.000220, loss: 1.6075
2022-07-17 17:43:32 - train: epoch 0195, iter [01000, 05004], lr: 0.000218, loss: 1.3971
2022-07-17 17:44:06 - train: epoch 0195, iter [01100, 05004], lr: 0.000217, loss: 1.2798
2022-07-17 17:44:40 - train: epoch 0195, iter [01200, 05004], lr: 0.000215, loss: 1.5892
2022-07-17 17:45:15 - train: epoch 0195, iter [01300, 05004], lr: 0.000214, loss: 1.6767
2022-07-17 17:45:50 - train: epoch 0195, iter [01400, 05004], lr: 0.000212, loss: 1.6567
2022-07-17 17:46:23 - train: epoch 0195, iter [01500, 05004], lr: 0.000211, loss: 1.3685
2022-07-17 17:46:58 - train: epoch 0195, iter [01600, 05004], lr: 0.000209, loss: 1.5723
2022-07-17 17:47:32 - train: epoch 0195, iter [01700, 05004], lr: 0.000208, loss: 1.7428
2022-07-17 17:48:07 - train: epoch 0195, iter [01800, 05004], lr: 0.000206, loss: 1.5942
2022-07-17 17:48:41 - train: epoch 0195, iter [01900, 05004], lr: 0.000205, loss: 1.3975
2022-07-17 17:49:15 - train: epoch 0195, iter [02000, 05004], lr: 0.000203, loss: 1.2685
2022-07-17 17:49:49 - train: epoch 0195, iter [02100, 05004], lr: 0.000202, loss: 1.5803
2022-07-17 17:50:24 - train: epoch 0195, iter [02200, 05004], lr: 0.000200, loss: 1.4935
2022-07-17 17:50:58 - train: epoch 0195, iter [02300, 05004], lr: 0.000199, loss: 1.6038
2022-07-17 17:51:32 - train: epoch 0195, iter [02400, 05004], lr: 0.000198, loss: 1.4426
2022-07-17 17:52:07 - train: epoch 0195, iter [02500, 05004], lr: 0.000196, loss: 1.7853
2022-07-17 17:52:41 - train: epoch 0195, iter [02600, 05004], lr: 0.000195, loss: 1.6104
2022-07-17 17:53:16 - train: epoch 0195, iter [02700, 05004], lr: 0.000193, loss: 1.7198
2022-07-17 17:53:50 - train: epoch 0195, iter [02800, 05004], lr: 0.000192, loss: 1.5770
2022-07-17 17:54:24 - train: epoch 0195, iter [02900, 05004], lr: 0.000191, loss: 1.6517
2022-07-17 17:54:59 - train: epoch 0195, iter [03000, 05004], lr: 0.000189, loss: 1.7945
2022-07-17 17:55:33 - train: epoch 0195, iter [03100, 05004], lr: 0.000188, loss: 1.6226
2022-07-17 17:56:07 - train: epoch 0195, iter [03200, 05004], lr: 0.000186, loss: 1.5818
2022-07-17 17:56:42 - train: epoch 0195, iter [03300, 05004], lr: 0.000185, loss: 1.6601
2022-07-17 17:57:16 - train: epoch 0195, iter [03400, 05004], lr: 0.000184, loss: 1.7823
2022-07-17 17:57:51 - train: epoch 0195, iter [03500, 05004], lr: 0.000182, loss: 1.5494
2022-07-17 17:58:24 - train: epoch 0195, iter [03600, 05004], lr: 0.000181, loss: 1.5778
2022-07-17 17:58:58 - train: epoch 0195, iter [03700, 05004], lr: 0.000179, loss: 1.6565
2022-07-17 17:59:33 - train: epoch 0195, iter [03800, 05004], lr: 0.000178, loss: 1.4966
2022-07-17 18:00:07 - train: epoch 0195, iter [03900, 05004], lr: 0.000177, loss: 1.7940
2022-07-17 18:00:42 - train: epoch 0195, iter [04000, 05004], lr: 0.000175, loss: 1.8568
2022-07-17 18:01:16 - train: epoch 0195, iter [04100, 05004], lr: 0.000174, loss: 1.6653
2022-07-17 18:01:50 - train: epoch 0195, iter [04200, 05004], lr: 0.000173, loss: 1.5492
2022-07-17 18:02:24 - train: epoch 0195, iter [04300, 05004], lr: 0.000171, loss: 1.8570
2022-07-17 18:02:58 - train: epoch 0195, iter [04400, 05004], lr: 0.000170, loss: 1.4378
2022-07-17 18:03:33 - train: epoch 0195, iter [04500, 05004], lr: 0.000169, loss: 1.7149
2022-07-17 18:04:07 - train: epoch 0195, iter [04600, 05004], lr: 0.000167, loss: 1.6801
2022-07-17 18:04:41 - train: epoch 0195, iter [04700, 05004], lr: 0.000166, loss: 1.6081
2022-07-17 18:05:15 - train: epoch 0195, iter [04800, 05004], lr: 0.000165, loss: 1.7572
2022-07-17 18:05:50 - train: epoch 0195, iter [04900, 05004], lr: 0.000163, loss: 1.5508
2022-07-17 18:06:23 - train: epoch 0195, iter [05000, 05004], lr: 0.000162, loss: 1.6247
2022-07-17 18:06:24 - train: epoch 195, train_loss: 1.6132
2022-07-17 18:07:39 - eval: epoch: 195, acc1: 77.666%, acc5: 93.784%, test_loss: 0.8864, per_image_load_time: 2.424ms, per_image_inference_time: 0.447ms
2022-07-17 18:07:39 - until epoch: 195, best_acc1: 77.766%
2022-07-17 18:07:39 - epoch 196 lr: 0.000162
2022-07-17 18:08:18 - train: epoch 0196, iter [00100, 05004], lr: 0.000161, loss: 1.7866
2022-07-17 18:08:52 - train: epoch 0196, iter [00200, 05004], lr: 0.000160, loss: 1.9816
2022-07-17 18:09:27 - train: epoch 0196, iter [00300, 05004], lr: 0.000158, loss: 1.4807
2022-07-17 18:10:01 - train: epoch 0196, iter [00400, 05004], lr: 0.000157, loss: 1.4597
2022-07-17 18:10:36 - train: epoch 0196, iter [00500, 05004], lr: 0.000156, loss: 1.5688
2022-07-17 18:11:09 - train: epoch 0196, iter [00600, 05004], lr: 0.000154, loss: 1.6388
2022-07-17 18:11:43 - train: epoch 0196, iter [00700, 05004], lr: 0.000153, loss: 1.7537
2022-07-17 18:12:17 - train: epoch 0196, iter [00800, 05004], lr: 0.000152, loss: 1.8061
2022-07-17 18:12:51 - train: epoch 0196, iter [00900, 05004], lr: 0.000151, loss: 1.8734
2022-07-17 18:13:25 - train: epoch 0196, iter [01000, 05004], lr: 0.000149, loss: 1.6557
2022-07-17 18:13:59 - train: epoch 0196, iter [01100, 05004], lr: 0.000148, loss: 1.7464
2022-07-17 18:14:33 - train: epoch 0196, iter [01200, 05004], lr: 0.000147, loss: 1.5880
2022-07-17 18:15:07 - train: epoch 0196, iter [01300, 05004], lr: 0.000146, loss: 1.5889
2022-07-17 18:15:41 - train: epoch 0196, iter [01400, 05004], lr: 0.000145, loss: 1.6157
2022-07-17 18:16:15 - train: epoch 0196, iter [01500, 05004], lr: 0.000143, loss: 1.6245
2022-07-17 18:16:49 - train: epoch 0196, iter [01600, 05004], lr: 0.000142, loss: 1.5780
2022-07-17 18:17:23 - train: epoch 0196, iter [01700, 05004], lr: 0.000141, loss: 1.7401
2022-07-17 18:17:57 - train: epoch 0196, iter [01800, 05004], lr: 0.000140, loss: 1.7527
2022-07-17 18:18:31 - train: epoch 0196, iter [01900, 05004], lr: 0.000138, loss: 1.6511
2022-07-17 18:19:04 - train: epoch 0196, iter [02000, 05004], lr: 0.000137, loss: 1.7433
2022-07-17 18:19:39 - train: epoch 0196, iter [02100, 05004], lr: 0.000136, loss: 1.8017
2022-07-17 18:20:13 - train: epoch 0196, iter [02200, 05004], lr: 0.000135, loss: 1.4432
2022-07-17 18:20:47 - train: epoch 0196, iter [02300, 05004], lr: 0.000134, loss: 1.9252
2022-07-17 18:21:21 - train: epoch 0196, iter [02400, 05004], lr: 0.000133, loss: 1.3872
2022-07-17 18:21:55 - train: epoch 0196, iter [02500, 05004], lr: 0.000131, loss: 1.5467
2022-07-17 18:22:29 - train: epoch 0196, iter [02600, 05004], lr: 0.000130, loss: 1.6301
2022-07-17 18:23:04 - train: epoch 0196, iter [02700, 05004], lr: 0.000129, loss: 1.8026
2022-07-17 18:23:37 - train: epoch 0196, iter [02800, 05004], lr: 0.000128, loss: 1.6114
2022-07-17 18:24:11 - train: epoch 0196, iter [02900, 05004], lr: 0.000127, loss: 1.6802
2022-07-17 18:24:45 - train: epoch 0196, iter [03000, 05004], lr: 0.000126, loss: 1.7214
2022-07-17 18:25:19 - train: epoch 0196, iter [03100, 05004], lr: 0.000124, loss: 1.5900
2022-07-17 18:25:53 - train: epoch 0196, iter [03200, 05004], lr: 0.000123, loss: 1.6388
2022-07-17 18:26:27 - train: epoch 0196, iter [03300, 05004], lr: 0.000122, loss: 1.5496
2022-07-17 18:27:02 - train: epoch 0196, iter [03400, 05004], lr: 0.000121, loss: 1.5648
2022-07-17 18:27:36 - train: epoch 0196, iter [03500, 05004], lr: 0.000120, loss: 1.5132
2022-07-17 18:28:10 - train: epoch 0196, iter [03600, 05004], lr: 0.000119, loss: 1.7866
2022-07-17 18:28:44 - train: epoch 0196, iter [03700, 05004], lr: 0.000118, loss: 1.4035
2022-07-17 18:29:18 - train: epoch 0196, iter [03800, 05004], lr: 0.000117, loss: 1.4437
2022-07-17 18:29:53 - train: epoch 0196, iter [03900, 05004], lr: 0.000116, loss: 1.6109
2022-07-17 18:30:27 - train: epoch 0196, iter [04000, 05004], lr: 0.000114, loss: 1.4398
2022-07-17 18:31:02 - train: epoch 0196, iter [04100, 05004], lr: 0.000113, loss: 1.6166
2022-07-17 18:31:36 - train: epoch 0196, iter [04200, 05004], lr: 0.000112, loss: 1.9095
2022-07-17 18:32:10 - train: epoch 0196, iter [04300, 05004], lr: 0.000111, loss: 1.7711
2022-07-17 18:32:44 - train: epoch 0196, iter [04400, 05004], lr: 0.000110, loss: 1.8276
2022-07-17 18:33:19 - train: epoch 0196, iter [04500, 05004], lr: 0.000109, loss: 1.6123
2022-07-17 18:33:53 - train: epoch 0196, iter [04600, 05004], lr: 0.000108, loss: 1.5010
2022-07-17 18:34:28 - train: epoch 0196, iter [04700, 05004], lr: 0.000107, loss: 1.8161
2022-07-17 18:35:02 - train: epoch 0196, iter [04800, 05004], lr: 0.000106, loss: 1.5889
