2022-07-17 18:35:36 - train: epoch 0196, iter [04900, 05004], lr: 0.000105, loss: 1.7646
2022-07-17 18:36:09 - train: epoch 0196, iter [05000, 05004], lr: 0.000104, loss: 1.5064
2022-07-17 18:36:10 - train: epoch 196, train_loss: 1.6099
2022-07-17 18:37:24 - eval: epoch: 196, acc1: 77.804%, acc5: 93.790%, test_loss: 0.8836, per_image_load_time: 2.395ms, per_image_inference_time: 0.452ms
2022-07-17 18:37:25 - until epoch: 196, best_acc1: 77.804%
2022-07-17 18:37:25 - epoch 197 lr: 0.000104
2022-07-17 18:38:04 - train: epoch 0197, iter [00100, 05004], lr: 0.000103, loss: 1.6257
2022-07-17 18:38:38 - train: epoch 0197, iter [00200, 05004], lr: 0.000102, loss: 1.7117
2022-07-17 18:39:11 - train: epoch 0197, iter [00300, 05004], lr: 0.000101, loss: 1.6134
2022-07-17 18:39:45 - train: epoch 0197, iter [00400, 05004], lr: 0.000100, loss: 1.6325
2022-07-17 18:40:19 - train: epoch 0197, iter [00500, 05004], lr: 0.000099, loss: 1.5006
2022-07-17 18:40:52 - train: epoch 0197, iter [00600, 05004], lr: 0.000098, loss: 1.7081
2022-07-17 18:41:26 - train: epoch 0197, iter [00700, 05004], lr: 0.000097, loss: 1.6947
2022-07-17 18:42:00 - train: epoch 0197, iter [00800, 05004], lr: 0.000096, loss: 1.6537
2022-07-17 18:42:34 - train: epoch 0197, iter [00900, 05004], lr: 0.000095, loss: 1.3665
2022-07-17 18:43:07 - train: epoch 0197, iter [01000, 05004], lr: 0.000094, loss: 1.4057
2022-07-17 18:43:41 - train: epoch 0197, iter [01100, 05004], lr: 0.000093, loss: 1.4056
2022-07-17 18:44:14 - train: epoch 0197, iter [01200, 05004], lr: 0.000092, loss: 1.7295
2022-07-17 18:44:50 - train: epoch 0197, iter [01300, 05004], lr: 0.000091, loss: 1.3897
2022-07-17 18:45:24 - train: epoch 0197, iter [01400, 05004], lr: 0.000090, loss: 1.5659
2022-07-17 18:45:57 - train: epoch 0197, iter [01500, 05004], lr: 0.000089, loss: 1.6896
2022-07-17 18:46:32 - train: epoch 0197, iter [01600, 05004], lr: 0.000088, loss: 1.2415
2022-07-17 18:47:05 - train: epoch 0197, iter [01700, 05004], lr: 0.000087, loss: 1.5558
2022-07-17 18:47:39 - train: epoch 0197, iter [01800, 05004], lr: 0.000086, loss: 1.4469
2022-07-17 18:48:13 - train: epoch 0197, iter [01900, 05004], lr: 0.000085, loss: 1.5547
2022-07-17 18:48:47 - train: epoch 0197, iter [02000, 05004], lr: 0.000084, loss: 1.7052
2022-07-17 18:49:21 - train: epoch 0197, iter [02100, 05004], lr: 0.000083, loss: 1.7895
2022-07-17 18:49:55 - train: epoch 0197, iter [02200, 05004], lr: 0.000082, loss: 1.1537
2022-07-17 18:50:28 - train: epoch 0197, iter [02300, 05004], lr: 0.000081, loss: 1.5210
2022-07-17 18:51:03 - train: epoch 0197, iter [02400, 05004], lr: 0.000080, loss: 1.6868
2022-07-17 18:51:37 - train: epoch 0197, iter [02500, 05004], lr: 0.000079, loss: 1.4496
2022-07-17 18:52:11 - train: epoch 0197, iter [02600, 05004], lr: 0.000079, loss: 1.9591
2022-07-17 18:52:46 - train: epoch 0197, iter [02700, 05004], lr: 0.000078, loss: 1.4987
2022-07-17 18:53:19 - train: epoch 0197, iter [02800, 05004], lr: 0.000077, loss: 1.5576
2022-07-17 18:53:54 - train: epoch 0197, iter [02900, 05004], lr: 0.000076, loss: 1.5312
2022-07-17 18:54:28 - train: epoch 0197, iter [03000, 05004], lr: 0.000075, loss: 1.3380
2022-07-17 18:55:03 - train: epoch 0197, iter [03100, 05004], lr: 0.000074, loss: 1.7082
2022-07-17 18:55:37 - train: epoch 0197, iter [03200, 05004], lr: 0.000073, loss: 1.6740
2022-07-17 18:56:11 - train: epoch 0197, iter [03300, 05004], lr: 0.000072, loss: 1.6228
2022-07-17 18:56:44 - train: epoch 0197, iter [03400, 05004], lr: 0.000072, loss: 1.7550
2022-07-17 18:57:19 - train: epoch 0197, iter [03500, 05004], lr: 0.000071, loss: 1.7400
2022-07-17 18:57:53 - train: epoch 0197, iter [03600, 05004], lr: 0.000070, loss: 1.5891
2022-07-17 18:58:27 - train: epoch 0197, iter [03700, 05004], lr: 0.000069, loss: 1.9091
2022-07-17 18:59:02 - train: epoch 0197, iter [03800, 05004], lr: 0.000068, loss: 1.8558
2022-07-17 18:59:36 - train: epoch 0197, iter [03900, 05004], lr: 0.000067, loss: 1.7147
2022-07-17 19:00:10 - train: epoch 0197, iter [04000, 05004], lr: 0.000066, loss: 1.8501
2022-07-17 19:00:45 - train: epoch 0197, iter [04100, 05004], lr: 0.000066, loss: 1.5298
2022-07-17 19:01:19 - train: epoch 0197, iter [04200, 05004], lr: 0.000065, loss: 1.7402
2022-07-17 19:01:53 - train: epoch 0197, iter [04300, 05004], lr: 0.000064, loss: 1.7398
2022-07-17 19:02:27 - train: epoch 0197, iter [04400, 05004], lr: 0.000063, loss: 1.8155
2022-07-17 19:03:01 - train: epoch 0197, iter [04500, 05004], lr: 0.000062, loss: 1.4505
2022-07-17 19:03:35 - train: epoch 0197, iter [04600, 05004], lr: 0.000062, loss: 1.6594
2022-07-17 19:04:09 - train: epoch 0197, iter [04700, 05004], lr: 0.000061, loss: 1.4447
2022-07-17 19:04:43 - train: epoch 0197, iter [04800, 05004], lr: 0.000060, loss: 1.3683
2022-07-17 19:05:17 - train: epoch 0197, iter [04900, 05004], lr: 0.000059, loss: 1.6780
2022-07-17 19:05:50 - train: epoch 0197, iter [05000, 05004], lr: 0.000058, loss: 1.8072
2022-07-17 19:05:51 - train: epoch 197, train_loss: 1.6102
2022-07-17 19:07:06 - eval: epoch: 197, acc1: 77.846%, acc5: 93.880%, test_loss: 0.8836, per_image_load_time: 1.351ms, per_image_inference_time: 0.476ms
2022-07-17 19:07:07 - until epoch: 197, best_acc1: 77.846%
2022-07-17 19:07:07 - epoch 198 lr: 0.000058
2022-07-17 19:07:47 - train: epoch 0198, iter [00100, 05004], lr: 0.000058, loss: 1.6557
2022-07-17 19:08:20 - train: epoch 0198, iter [00200, 05004], lr: 0.000057, loss: 1.4068
2022-07-17 19:08:54 - train: epoch 0198, iter [00300, 05004], lr: 0.000056, loss: 1.6126
2022-07-17 19:09:29 - train: epoch 0198, iter [00400, 05004], lr: 0.000055, loss: 1.6861
2022-07-17 19:10:03 - train: epoch 0198, iter [00500, 05004], lr: 0.000055, loss: 1.5571
2022-07-17 19:10:37 - train: epoch 0198, iter [00600, 05004], lr: 0.000054, loss: 1.7698
2022-07-17 19:11:11 - train: epoch 0198, iter [00700, 05004], lr: 0.000053, loss: 1.5035
2022-07-17 19:11:45 - train: epoch 0198, iter [00800, 05004], lr: 0.000052, loss: 1.4855
2022-07-17 19:12:20 - train: epoch 0198, iter [00900, 05004], lr: 0.000052, loss: 1.7890
2022-07-17 19:12:54 - train: epoch 0198, iter [01000, 05004], lr: 0.000051, loss: 1.6274
2022-07-17 19:13:28 - train: epoch 0198, iter [01100, 05004], lr: 0.000050, loss: 1.8095
2022-07-17 19:14:02 - train: epoch 0198, iter [01200, 05004], lr: 0.000049, loss: 1.5231
2022-07-17 19:14:37 - train: epoch 0198, iter [01300, 05004], lr: 0.000049, loss: 1.8563
2022-07-17 19:15:12 - train: epoch 0198, iter [01400, 05004], lr: 0.000048, loss: 1.7062
2022-07-17 19:15:47 - train: epoch 0198, iter [01500, 05004], lr: 0.000047, loss: 1.5548
2022-07-17 19:16:21 - train: epoch 0198, iter [01600, 05004], lr: 0.000047, loss: 1.6468
2022-07-17 19:16:55 - train: epoch 0198, iter [01700, 05004], lr: 0.000046, loss: 1.8312
2022-07-17 19:17:30 - train: epoch 0198, iter [01800, 05004], lr: 0.000045, loss: 1.6665
2022-07-17 19:18:05 - train: epoch 0198, iter [01900, 05004], lr: 0.000045, loss: 1.5866
2022-07-17 19:18:39 - train: epoch 0198, iter [02000, 05004], lr: 0.000044, loss: 1.5541
2022-07-17 19:19:13 - train: epoch 0198, iter [02100, 05004], lr: 0.000043, loss: 1.4813
2022-07-17 19:19:48 - train: epoch 0198, iter [02200, 05004], lr: 0.000043, loss: 1.4470
2022-07-17 19:20:22 - train: epoch 0198, iter [02300, 05004], lr: 0.000042, loss: 1.3180
2022-07-17 19:20:57 - train: epoch 0198, iter [02400, 05004], lr: 0.000041, loss: 1.5298
2022-07-17 19:21:31 - train: epoch 0198, iter [02500, 05004], lr: 0.000041, loss: 1.6427
2022-07-17 19:22:05 - train: epoch 0198, iter [02600, 05004], lr: 0.000040, loss: 1.7360
2022-07-17 19:22:39 - train: epoch 0198, iter [02700, 05004], lr: 0.000039, loss: 1.6871
2022-07-17 19:23:13 - train: epoch 0198, iter [02800, 05004], lr: 0.000039, loss: 1.6812
2022-07-17 19:23:47 - train: epoch 0198, iter [02900, 05004], lr: 0.000038, loss: 1.5104
2022-07-17 19:24:22 - train: epoch 0198, iter [03000, 05004], lr: 0.000037, loss: 1.6944
2022-07-17 19:24:55 - train: epoch 0198, iter [03100, 05004], lr: 0.000037, loss: 1.6050
2022-07-17 19:25:29 - train: epoch 0198, iter [03200, 05004], lr: 0.000036, loss: 1.7047
2022-07-17 19:26:04 - train: epoch 0198, iter [03300, 05004], lr: 0.000036, loss: 1.7083
2022-07-17 19:26:38 - train: epoch 0198, iter [03400, 05004], lr: 0.000035, loss: 1.5286
2022-07-17 19:27:12 - train: epoch 0198, iter [03500, 05004], lr: 0.000034, loss: 1.5243
2022-07-17 19:27:46 - train: epoch 0198, iter [03600, 05004], lr: 0.000034, loss: 1.2414
2022-07-17 19:28:21 - train: epoch 0198, iter [03700, 05004], lr: 0.000033, loss: 1.6360
2022-07-17 19:28:55 - train: epoch 0198, iter [03800, 05004], lr: 0.000033, loss: 1.3006
2022-07-17 19:29:30 - train: epoch 0198, iter [03900, 05004], lr: 0.000032, loss: 1.7142
2022-07-17 19:30:04 - train: epoch 0198, iter [04000, 05004], lr: 0.000031, loss: 1.6597
2022-07-17 19:30:38 - train: epoch 0198, iter [04100, 05004], lr: 0.000031, loss: 1.9821
2022-07-17 19:31:12 - train: epoch 0198, iter [04200, 05004], lr: 0.000030, loss: 1.5563
2022-07-17 19:31:46 - train: epoch 0198, iter [04300, 05004], lr: 0.000030, loss: 1.5018
2022-07-17 19:32:20 - train: epoch 0198, iter [04400, 05004], lr: 0.000029, loss: 1.6693
2022-07-17 19:32:55 - train: epoch 0198, iter [04500, 05004], lr: 0.000029, loss: 1.6192
2022-07-17 19:33:28 - train: epoch 0198, iter [04600, 05004], lr: 0.000028, loss: 1.6700
2022-07-17 19:34:03 - train: epoch 0198, iter [04700, 05004], lr: 0.000028, loss: 1.6774
2022-07-17 19:34:37 - train: epoch 0198, iter [04800, 05004], lr: 0.000027, loss: 1.5960
2022-07-17 19:35:12 - train: epoch 0198, iter [04900, 05004], lr: 0.000026, loss: 1.5626
2022-07-17 19:35:45 - train: epoch 0198, iter [05000, 05004], lr: 0.000026, loss: 1.7764
2022-07-17 19:35:46 - train: epoch 198, train_loss: 1.6057
2022-07-17 19:37:00 - eval: epoch: 198, acc1: 77.742%, acc5: 93.834%, test_loss: 0.8854, per_image_load_time: 1.210ms, per_image_inference_time: 0.470ms
2022-07-17 19:37:00 - until epoch: 198, best_acc1: 77.846%
2022-07-17 19:37:00 - epoch 199 lr: 0.000026
2022-07-17 19:37:40 - train: epoch 0199, iter [00100, 05004], lr: 0.000025, loss: 1.7268
2022-07-17 19:38:14 - train: epoch 0199, iter [00200, 05004], lr: 0.000025, loss: 1.3440
2022-07-17 19:38:48 - train: epoch 0199, iter [00300, 05004], lr: 0.000024, loss: 1.7890
2022-07-17 19:39:23 - train: epoch 0199, iter [00400, 05004], lr: 0.000024, loss: 1.8004
2022-07-17 19:39:56 - train: epoch 0199, iter [00500, 05004], lr: 0.000023, loss: 1.7057
2022-07-17 19:40:31 - train: epoch 0199, iter [00600, 05004], lr: 0.000023, loss: 1.6291
2022-07-17 19:41:04 - train: epoch 0199, iter [00700, 05004], lr: 0.000022, loss: 1.2879
2022-07-17 19:41:39 - train: epoch 0199, iter [00800, 05004], lr: 0.000022, loss: 1.7989
2022-07-17 19:42:13 - train: epoch 0199, iter [00900, 05004], lr: 0.000021, loss: 1.6357
2022-07-17 19:42:47 - train: epoch 0199, iter [01000, 05004], lr: 0.000021, loss: 1.4985
2022-07-17 19:43:22 - train: epoch 0199, iter [01100, 05004], lr: 0.000021, loss: 1.7011
2022-07-17 19:43:54 - train: epoch 0199, iter [01200, 05004], lr: 0.000020, loss: 1.6598
2022-07-17 19:44:28 - train: epoch 0199, iter [01300, 05004], lr: 0.000020, loss: 1.5479
2022-07-17 19:45:03 - train: epoch 0199, iter [01400, 05004], lr: 0.000019, loss: 1.4553
2022-07-17 19:45:37 - train: epoch 0199, iter [01500, 05004], lr: 0.000019, loss: 1.7814
2022-07-17 19:46:12 - train: epoch 0199, iter [01600, 05004], lr: 0.000018, loss: 1.8199
2022-07-17 19:46:45 - train: epoch 0199, iter [01700, 05004], lr: 0.000018, loss: 1.6578
2022-07-17 19:47:19 - train: epoch 0199, iter [01800, 05004], lr: 0.000017, loss: 1.7964
2022-07-17 19:47:53 - train: epoch 0199, iter [01900, 05004], lr: 0.000017, loss: 1.8495
2022-07-17 19:48:27 - train: epoch 0199, iter [02000, 05004], lr: 0.000017, loss: 1.7150
2022-07-17 19:49:01 - train: epoch 0199, iter [02100, 05004], lr: 0.000016, loss: 1.5986
2022-07-17 19:49:36 - train: epoch 0199, iter [02200, 05004], lr: 0.000016, loss: 1.6239
2022-07-17 19:50:09 - train: epoch 0199, iter [02300, 05004], lr: 0.000015, loss: 1.7641
2022-07-17 19:50:43 - train: epoch 0199, iter [02400, 05004], lr: 0.000015, loss: 1.8915
2022-07-17 19:51:17 - train: epoch 0199, iter [02500, 05004], lr: 0.000015, loss: 1.3459
2022-07-17 19:51:51 - train: epoch 0199, iter [02600, 05004], lr: 0.000014, loss: 1.7686
2022-07-17 19:52:25 - train: epoch 0199, iter [02700, 05004], lr: 0.000014, loss: 1.7773
2022-07-17 19:52:59 - train: epoch 0199, iter [02800, 05004], lr: 0.000013, loss: 1.7204
2022-07-17 19:53:33 - train: epoch 0199, iter [02900, 05004], lr: 0.000013, loss: 1.7894
2022-07-17 19:54:08 - train: epoch 0199, iter [03000, 05004], lr: 0.000013, loss: 1.6178
2022-07-17 19:54:42 - train: epoch 0199, iter [03100, 05004], lr: 0.000012, loss: 1.5913
2022-07-17 19:55:16 - train: epoch 0199, iter [03200, 05004], lr: 0.000012, loss: 1.6685
2022-07-17 19:55:50 - train: epoch 0199, iter [03300, 05004], lr: 0.000012, loss: 1.8507
2022-07-17 19:56:24 - train: epoch 0199, iter [03400, 05004], lr: 0.000011, loss: 1.7822
2022-07-17 19:56:58 - train: epoch 0199, iter [03500, 05004], lr: 0.000011, loss: 1.6123
2022-07-17 19:57:32 - train: epoch 0199, iter [03600, 05004], lr: 0.000011, loss: 1.5166
2022-07-17 19:58:06 - train: epoch 0199, iter [03700, 05004], lr: 0.000010, loss: 1.5080
2022-07-17 19:58:40 - train: epoch 0199, iter [03800, 05004], lr: 0.000010, loss: 1.5300
2022-07-17 19:59:15 - train: epoch 0199, iter [03900, 05004], lr: 0.000010, loss: 1.5895
2022-07-17 19:59:49 - train: epoch 0199, iter [04000, 05004], lr: 0.000009, loss: 1.3399
2022-07-17 20:00:23 - train: epoch 0199, iter [04100, 05004], lr: 0.000009, loss: 1.4798
2022-07-17 20:00:57 - train: epoch 0199, iter [04200, 05004], lr: 0.000009, loss: 1.5978
2022-07-17 20:01:31 - train: epoch 0199, iter [04300, 05004], lr: 0.000008, loss: 1.6959
2022-07-17 20:02:05 - train: epoch 0199, iter [04400, 05004], lr: 0.000008, loss: 1.7136
2022-07-17 20:02:39 - train: epoch 0199, iter [04500, 05004], lr: 0.000008, loss: 1.5750
2022-07-17 20:03:14 - train: epoch 0199, iter [04600, 05004], lr: 0.000008, loss: 1.7786
2022-07-17 20:03:48 - train: epoch 0199, iter [04700, 05004], lr: 0.000007, loss: 1.4073
2022-07-17 20:04:23 - train: epoch 0199, iter [04800, 05004], lr: 0.000007, loss: 1.4318
2022-07-17 20:04:57 - train: epoch 0199, iter [04900, 05004], lr: 0.000007, loss: 1.6879
2022-07-17 20:05:29 - train: epoch 0199, iter [05000, 05004], lr: 0.000006, loss: 1.4177
2022-07-17 20:05:30 - train: epoch 199, train_loss: 1.6040
2022-07-17 20:06:44 - eval: epoch: 199, acc1: 77.816%, acc5: 93.818%, test_loss: 0.8847, per_image_load_time: 1.587ms, per_image_inference_time: 0.475ms
2022-07-17 20:06:45 - until epoch: 199, best_acc1: 77.846%
2022-07-17 20:06:45 - epoch 200 lr: 0.000006
2022-07-17 20:07:24 - train: epoch 0200, iter [00100, 05004], lr: 0.000006, loss: 1.5030
2022-07-17 20:07:59 - train: epoch 0200, iter [00200, 05004], lr: 0.000006, loss: 1.8093
2022-07-17 20:08:32 - train: epoch 0200, iter [00300, 05004], lr: 0.000006, loss: 1.7240
2022-07-17 20:09:06 - train: epoch 0200, iter [00400, 05004], lr: 0.000005, loss: 1.8242
2022-07-17 20:09:39 - train: epoch 0200, iter [00500, 05004], lr: 0.000005, loss: 1.3743
2022-07-17 20:10:14 - train: epoch 0200, iter [00600, 05004], lr: 0.000005, loss: 1.8972
2022-07-17 20:10:47 - train: epoch 0200, iter [00700, 05004], lr: 0.000005, loss: 1.6142
2022-07-17 20:11:21 - train: epoch 0200, iter [00800, 05004], lr: 0.000005, loss: 1.3915
2022-07-17 20:11:55 - train: epoch 0200, iter [00900, 05004], lr: 0.000004, loss: 1.6730
2022-07-17 20:12:28 - train: epoch 0200, iter [01000, 05004], lr: 0.000004, loss: 1.4972
2022-07-17 20:13:03 - train: epoch 0200, iter [01100, 05004], lr: 0.000004, loss: 1.6882
2022-07-17 20:13:37 - train: epoch 0200, iter [01200, 05004], lr: 0.000004, loss: 1.5993
2022-07-17 20:14:11 - train: epoch 0200, iter [01300, 05004], lr: 0.000004, loss: 1.1962
2022-07-17 20:14:44 - train: epoch 0200, iter [01400, 05004], lr: 0.000003, loss: 1.8268
2022-07-17 20:15:18 - train: epoch 0200, iter [01500, 05004], lr: 0.000003, loss: 1.4561
2022-07-17 20:15:52 - train: epoch 0200, iter [01600, 05004], lr: 0.000003, loss: 1.5015
2022-07-17 20:16:26 - train: epoch 0200, iter [01700, 05004], lr: 0.000003, loss: 1.7441
2022-07-17 20:17:00 - train: epoch 0200, iter [01800, 05004], lr: 0.000003, loss: 2.0684
2022-07-17 20:17:34 - train: epoch 0200, iter [01900, 05004], lr: 0.000002, loss: 1.5071
2022-07-17 20:18:09 - train: epoch 0200, iter [02000, 05004], lr: 0.000002, loss: 1.7476
2022-07-17 20:18:42 - train: epoch 0200, iter [02100, 05004], lr: 0.000002, loss: 1.5989
2022-07-17 20:19:18 - train: epoch 0200, iter [02200, 05004], lr: 0.000002, loss: 1.6920
2022-07-17 20:19:51 - train: epoch 0200, iter [02300, 05004], lr: 0.000002, loss: 1.6432
2022-07-17 20:20:25 - train: epoch 0200, iter [02400, 05004], lr: 0.000002, loss: 1.4451
2022-07-17 20:20:59 - train: epoch 0200, iter [02500, 05004], lr: 0.000002, loss: 1.5990
2022-07-17 20:21:34 - train: epoch 0200, iter [02600, 05004], lr: 0.000001, loss: 1.4419
2022-07-17 20:22:09 - train: epoch 0200, iter [02700, 05004], lr: 0.000001, loss: 1.4495
2022-07-17 20:22:42 - train: epoch 0200, iter [02800, 05004], lr: 0.000001, loss: 1.5416
2022-07-17 20:23:16 - train: epoch 0200, iter [02900, 05004], lr: 0.000001, loss: 1.5979
2022-07-17 20:23:50 - train: epoch 0200, iter [03000, 05004], lr: 0.000001, loss: 1.6310
2022-07-17 20:24:23 - train: epoch 0200, iter [03100, 05004], lr: 0.000001, loss: 1.6613
2022-07-17 20:24:57 - train: epoch 0200, iter [03200, 05004], lr: 0.000001, loss: 1.7056
2022-07-17 20:25:31 - train: epoch 0200, iter [03300, 05004], lr: 0.000001, loss: 1.6778
2022-07-17 20:26:05 - train: epoch 0200, iter [03400, 05004], lr: 0.000001, loss: 1.4813
2022-07-17 20:26:38 - train: epoch 0200, iter [03500, 05004], lr: 0.000001, loss: 1.4590
2022-07-17 20:27:13 - train: epoch 0200, iter [03600, 05004], lr: 0.000001, loss: 1.4814
2022-07-17 20:27:46 - train: epoch 0200, iter [03700, 05004], lr: 0.000000, loss: 1.5693
2022-07-17 20:28:21 - train: epoch 0200, iter [03800, 05004], lr: 0.000000, loss: 1.4693
2022-07-17 20:28:54 - train: epoch 0200, iter [03900, 05004], lr: 0.000000, loss: 1.5242
2022-07-17 20:29:28 - train: epoch 0200, iter [04000, 05004], lr: 0.000000, loss: 1.6653
2022-07-17 20:30:02 - train: epoch 0200, iter [04100, 05004], lr: 0.000000, loss: 1.4128
2022-07-17 20:30:36 - train: epoch 0200, iter [04200, 05004], lr: 0.000000, loss: 1.7957
2022-07-17 20:31:09 - train: epoch 0200, iter [04300, 05004], lr: 0.000000, loss: 1.7231
2022-07-17 20:31:43 - train: epoch 0200, iter [04400, 05004], lr: 0.000000, loss: 1.5491
2022-07-17 20:32:17 - train: epoch 0200, iter [04500, 05004], lr: 0.000000, loss: 1.6254
2022-07-17 20:32:51 - train: epoch 0200, iter [04600, 05004], lr: 0.000000, loss: 1.6414
2022-07-17 20:33:25 - train: epoch 0200, iter [04700, 05004], lr: 0.000000, loss: 1.8263
2022-07-17 20:33:59 - train: epoch 0200, iter [04800, 05004], lr: 0.000000, loss: 1.7809
2022-07-17 20:34:33 - train: epoch 0200, iter [04900, 05004], lr: 0.000000, loss: 1.5622
2022-07-17 20:35:07 - train: epoch 0200, iter [05000, 05004], lr: 0.000000, loss: 1.8128
2022-07-17 20:35:08 - train: epoch 200, train_loss: 1.6007
2022-07-17 20:36:22 - eval: epoch: 200, acc1: 77.714%, acc5: 93.806%, test_loss: 0.8832, per_image_load_time: 2.336ms, per_image_inference_time: 0.492ms
2022-07-17 20:36:22 - until epoch: 200, best_acc1: 77.846%
2022-07-17 20:36:22 - train done. model: resnet50, train time: 99.627 hours, best_acc1: 77.846%
