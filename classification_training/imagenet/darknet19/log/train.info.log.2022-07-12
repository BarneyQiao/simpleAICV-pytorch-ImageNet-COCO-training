2022-07-12 23:24:53 - network: darknet19
2022-07-12 23:24:53 - num_classes: 1000
2022-07-12 23:24:53 - input_image_size: 256
2022-07-12 23:24:53 - scale: 1.1428571428571428
2022-07-12 23:24:53 - trained_model_path: 
2022-07-12 23:24:53 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-07-12 23:24:53 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-07-12 23:24:53 - train_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7fee35414700>
2022-07-12 23:24:53 - test_dataset: <simpleAICV.classification.datasets.ilsvrc2012dataset.ILSVRC2012Dataset object at 0x7fee354149d0>
2022-07-12 23:24:53 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fee35414a00>
2022-07-12 23:24:53 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fee35414a60>
2022-07-12 23:24:53 - seed: 0
2022-07-12 23:24:53 - batch_size: 256
2022-07-12 23:24:53 - num_workers: 16
2022-07-12 23:24:53 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0001, 'no_weight_decay_layer_name_list': []})
2022-07-12 23:24:53 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [30, 60, 90]})
2022-07-12 23:24:53 - epochs: 100
2022-07-12 23:24:53 - print_interval: 100
2022-07-12 23:24:53 - accumulation_steps: 1
2022-07-12 23:24:53 - sync_bn: False
2022-07-12 23:24:53 - apex: True
2022-07-12 23:24:53 - use_ema_model: False
2022-07-12 23:24:53 - ema_model_decay: 0.9999
2022-07-12 23:24:53 - gpus_type: NVIDIA RTX A5000
2022-07-12 23:24:53 - gpus_num: 2
2022-07-12 23:24:53 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7fedfe74bfb0>
2022-07-12 23:24:53 - --------------------parameters--------------------
2022-07-12 23:24:53 - name: layer1.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer1.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer1.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer2.Darknet19Block.0.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer2.Darknet19Block.0.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer2.Darknet19Block.0.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer3.Darknet19Block.0.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer3.Darknet19Block.0.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer3.Darknet19Block.0.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer3.Darknet19Block.1.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer3.Darknet19Block.1.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer3.Darknet19Block.1.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer3.Darknet19Block.2.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer3.Darknet19Block.2.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer3.Darknet19Block.2.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer4.Darknet19Block.0.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer4.Darknet19Block.0.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer4.Darknet19Block.0.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer4.Darknet19Block.1.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer4.Darknet19Block.1.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer4.Darknet19Block.1.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer4.Darknet19Block.2.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer4.Darknet19Block.2.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer4.Darknet19Block.2.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.0.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.0.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.0.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.1.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.1.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.1.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.2.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.2.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.2.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.3.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.3.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.3.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.4.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.4.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer5.Darknet19Block.4.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.0.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.0.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.0.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.1.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.1.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.1.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.2.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.2.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.2.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.3.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.3.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.3.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.4.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.4.layer.1.weight, grad: True
2022-07-12 23:24:53 - name: layer6.Darknet19Block.4.layer.1.bias, grad: True
2022-07-12 23:24:53 - name: layer7.layer.0.weight, grad: True
2022-07-12 23:24:53 - name: layer7.layer.0.bias, grad: True
2022-07-12 23:24:53 - --------------------buffers--------------------
2022-07-12 23:24:53 - name: layer1.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer1.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer1.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer2.Darknet19Block.0.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer2.Darknet19Block.0.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer2.Darknet19Block.0.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer3.Darknet19Block.0.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer3.Darknet19Block.0.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer3.Darknet19Block.0.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer3.Darknet19Block.1.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer3.Darknet19Block.1.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer3.Darknet19Block.1.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer3.Darknet19Block.2.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer3.Darknet19Block.2.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer3.Darknet19Block.2.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer4.Darknet19Block.0.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer4.Darknet19Block.0.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer4.Darknet19Block.0.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer4.Darknet19Block.1.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer4.Darknet19Block.1.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer4.Darknet19Block.1.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer4.Darknet19Block.2.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer4.Darknet19Block.2.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer4.Darknet19Block.2.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.0.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.0.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.0.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.1.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.1.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.1.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.2.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.2.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.2.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.3.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.3.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.3.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.4.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.4.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer5.Darknet19Block.4.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.0.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.0.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.0.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.1.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.1.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.1.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.2.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.2.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.2.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.3.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.3.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.3.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.4.layer.1.running_mean, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.4.layer.1.running_var, grad: False
2022-07-12 23:24:53 - name: layer6.Darknet19Block.4.layer.1.num_batches_tracked, grad: False
2022-07-12 23:24:53 - -----------no weight decay layers--------------
2022-07-12 23:24:53 - name: layer1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer2.Darknet19Block.0.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer2.Darknet19Block.0.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer3.Darknet19Block.0.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer3.Darknet19Block.0.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer3.Darknet19Block.1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer3.Darknet19Block.1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer3.Darknet19Block.2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer3.Darknet19Block.2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer4.Darknet19Block.0.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer4.Darknet19Block.0.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer4.Darknet19Block.1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer4.Darknet19Block.1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer4.Darknet19Block.2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer4.Darknet19Block.2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.0.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.0.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.4.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.4.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.0.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.0.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.4.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.4.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer7.layer.0.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-12 23:24:53 - -------------weight decay layers---------------
2022-07-12 23:24:53 - name: layer1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer2.Darknet19Block.0.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer3.Darknet19Block.0.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer3.Darknet19Block.1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer3.Darknet19Block.2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer4.Darknet19Block.0.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer4.Darknet19Block.1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer4.Darknet19Block.2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.0.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer5.Darknet19Block.4.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.0.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.1.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.2.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.3.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer6.Darknet19Block.4.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - name: layer7.layer.0.weight, weight_decay: 0.0001, lr_scale: not setting!
2022-07-12 23:24:53 - epoch 001 lr: 0.100000
2022-07-12 23:25:32 - train: epoch 0001, iter [00100, 05004], lr: 0.100000, loss: 6.7994
2022-07-12 23:26:06 - train: epoch 0001, iter [00200, 05004], lr: 0.100000, loss: 6.4258
2022-07-12 23:26:40 - train: epoch 0001, iter [00300, 05004], lr: 0.100000, loss: 6.3234
2022-07-12 23:27:13 - train: epoch 0001, iter [00400, 05004], lr: 0.100000, loss: 6.1612
2022-07-12 23:27:48 - train: epoch 0001, iter [00500, 05004], lr: 0.100000, loss: 6.0066
2022-07-12 23:28:22 - train: epoch 0001, iter [00600, 05004], lr: 0.100000, loss: 5.7154
2022-07-12 23:28:55 - train: epoch 0001, iter [00700, 05004], lr: 0.100000, loss: 5.6817
2022-07-12 23:29:28 - train: epoch 0001, iter [00800, 05004], lr: 0.100000, loss: 5.6823
2022-07-12 23:30:00 - train: epoch 0001, iter [00900, 05004], lr: 0.100000, loss: 5.6146
2022-07-12 23:30:35 - train: epoch 0001, iter [01000, 05004], lr: 0.100000, loss: 5.4317
2022-07-12 23:31:07 - train: epoch 0001, iter [01100, 05004], lr: 0.100000, loss: 5.4957
2022-07-12 23:31:41 - train: epoch 0001, iter [01200, 05004], lr: 0.100000, loss: 5.2023
2022-07-12 23:32:13 - train: epoch 0001, iter [01300, 05004], lr: 0.100000, loss: 5.1921
2022-07-12 23:32:46 - train: epoch 0001, iter [01400, 05004], lr: 0.100000, loss: 5.2174
2022-07-12 23:33:19 - train: epoch 0001, iter [01500, 05004], lr: 0.100000, loss: 5.0372
2022-07-12 23:33:52 - train: epoch 0001, iter [01600, 05004], lr: 0.100000, loss: 5.1431
2022-07-12 23:34:25 - train: epoch 0001, iter [01700, 05004], lr: 0.100000, loss: 5.0300
2022-07-12 23:34:57 - train: epoch 0001, iter [01800, 05004], lr: 0.100000, loss: 5.0549
2022-07-12 23:35:30 - train: epoch 0001, iter [01900, 05004], lr: 0.100000, loss: 4.8300
2022-07-12 23:36:03 - train: epoch 0001, iter [02000, 05004], lr: 0.100000, loss: 4.7921
2022-07-12 23:36:36 - train: epoch 0001, iter [02100, 05004], lr: 0.100000, loss: 4.6489
2022-07-12 23:37:08 - train: epoch 0001, iter [02200, 05004], lr: 0.100000, loss: 4.7476
2022-07-12 23:37:41 - train: epoch 0001, iter [02300, 05004], lr: 0.100000, loss: 4.6145
2022-07-12 23:38:14 - train: epoch 0001, iter [02400, 05004], lr: 0.100000, loss: 4.6486
2022-07-12 23:38:48 - train: epoch 0001, iter [02500, 05004], lr: 0.100000, loss: 4.6820
2022-07-12 23:39:20 - train: epoch 0001, iter [02600, 05004], lr: 0.100000, loss: 4.6962
2022-07-12 23:39:54 - train: epoch 0001, iter [02700, 05004], lr: 0.100000, loss: 4.7874
2022-07-12 23:40:27 - train: epoch 0001, iter [02800, 05004], lr: 0.100000, loss: 4.4218
2022-07-12 23:41:00 - train: epoch 0001, iter [02900, 05004], lr: 0.100000, loss: 4.3103
2022-07-12 23:41:33 - train: epoch 0001, iter [03000, 05004], lr: 0.100000, loss: 4.5273
2022-07-12 23:42:07 - train: epoch 0001, iter [03100, 05004], lr: 0.100000, loss: 4.4925
2022-07-12 23:42:39 - train: epoch 0001, iter [03200, 05004], lr: 0.100000, loss: 4.4150
2022-07-12 23:43:12 - train: epoch 0001, iter [03300, 05004], lr: 0.100000, loss: 4.1239
2022-07-12 23:43:46 - train: epoch 0001, iter [03400, 05004], lr: 0.100000, loss: 4.2635
2022-07-12 23:44:19 - train: epoch 0001, iter [03500, 05004], lr: 0.100000, loss: 4.2698
2022-07-12 23:44:52 - train: epoch 0001, iter [03600, 05004], lr: 0.100000, loss: 4.3084
2022-07-12 23:45:25 - train: epoch 0001, iter [03700, 05004], lr: 0.100000, loss: 4.3654
2022-07-12 23:46:00 - train: epoch 0001, iter [03800, 05004], lr: 0.100000, loss: 4.0190
2022-07-12 23:46:32 - train: epoch 0001, iter [03900, 05004], lr: 0.100000, loss: 4.2995
2022-07-12 23:47:05 - train: epoch 0001, iter [04000, 05004], lr: 0.100000, loss: 4.0659
2022-07-12 23:47:39 - train: epoch 0001, iter [04100, 05004], lr: 0.100000, loss: 4.2059
2022-07-12 23:48:12 - train: epoch 0001, iter [04200, 05004], lr: 0.100000, loss: 4.0057
2022-07-12 23:48:45 - train: epoch 0001, iter [04300, 05004], lr: 0.100000, loss: 4.0315
2022-07-12 23:49:18 - train: epoch 0001, iter [04400, 05004], lr: 0.100000, loss: 3.8270
2022-07-12 23:49:51 - train: epoch 0001, iter [04500, 05004], lr: 0.100000, loss: 4.0285
2022-07-12 23:50:25 - train: epoch 0001, iter [04600, 05004], lr: 0.100000, loss: 4.2040
2022-07-12 23:50:58 - train: epoch 0001, iter [04700, 05004], lr: 0.100000, loss: 4.0093
2022-07-12 23:51:32 - train: epoch 0001, iter [04800, 05004], lr: 0.100000, loss: 4.2473
2022-07-12 23:52:05 - train: epoch 0001, iter [04900, 05004], lr: 0.100000, loss: 3.8538
2022-07-12 23:52:37 - train: epoch 0001, iter [05000, 05004], lr: 0.100000, loss: 3.8096
2022-07-12 23:52:38 - train: epoch 001, train_loss: 4.7970
2022-07-12 23:53:52 - eval: epoch: 001, acc1: 21.652%, acc5: 45.114%, test_loss: 3.8489, per_image_load_time: 2.217ms, per_image_inference_time: 0.291ms
2022-07-12 23:53:52 - until epoch: 001, best_acc1: 21.652%
2022-07-12 23:53:52 - epoch 002 lr: 0.100000
2022-07-12 23:54:30 - train: epoch 0002, iter [00100, 05004], lr: 0.100000, loss: 3.9217
2022-07-12 23:55:04 - train: epoch 0002, iter [00200, 05004], lr: 0.100000, loss: 3.7552
2022-07-12 23:55:37 - train: epoch 0002, iter [00300, 05004], lr: 0.100000, loss: 3.9449
2022-07-12 23:56:09 - train: epoch 0002, iter [00400, 05004], lr: 0.100000, loss: 4.0036
2022-07-12 23:56:42 - train: epoch 0002, iter [00500, 05004], lr: 0.100000, loss: 3.6920
2022-07-12 23:57:15 - train: epoch 0002, iter [00600, 05004], lr: 0.100000, loss: 3.6139
2022-07-12 23:57:47 - train: epoch 0002, iter [00700, 05004], lr: 0.100000, loss: 3.8564
2022-07-12 23:58:21 - train: epoch 0002, iter [00800, 05004], lr: 0.100000, loss: 3.5356
2022-07-12 23:58:53 - train: epoch 0002, iter [00900, 05004], lr: 0.100000, loss: 3.5554
2022-07-12 23:59:27 - train: epoch 0002, iter [01000, 05004], lr: 0.100000, loss: 3.9080
2022-07-13 00:00:00 - train: epoch 0002, iter [01100, 05004], lr: 0.100000, loss: 3.8109
2022-07-13 00:00:33 - train: epoch 0002, iter [01200, 05004], lr: 0.100000, loss: 3.7227
2022-07-13 00:01:06 - train: epoch 0002, iter [01300, 05004], lr: 0.100000, loss: 3.5947
2022-07-13 00:01:39 - train: epoch 0002, iter [01400, 05004], lr: 0.100000, loss: 3.7805
2022-07-13 00:02:12 - train: epoch 0002, iter [01500, 05004], lr: 0.100000, loss: 3.7982
2022-07-13 00:02:45 - train: epoch 0002, iter [01600, 05004], lr: 0.100000, loss: 3.6248
2022-07-13 00:03:19 - train: epoch 0002, iter [01700, 05004], lr: 0.100000, loss: 3.5689
2022-07-13 00:03:52 - train: epoch 0002, iter [01800, 05004], lr: 0.100000, loss: 3.6206
2022-07-13 00:04:25 - train: epoch 0002, iter [01900, 05004], lr: 0.100000, loss: 3.4670
2022-07-13 00:04:59 - train: epoch 0002, iter [02000, 05004], lr: 0.100000, loss: 3.2707
2022-07-13 00:05:32 - train: epoch 0002, iter [02100, 05004], lr: 0.100000, loss: 3.5189
2022-07-13 00:06:06 - train: epoch 0002, iter [02200, 05004], lr: 0.100000, loss: 3.2660
2022-07-13 00:06:39 - train: epoch 0002, iter [02300, 05004], lr: 0.100000, loss: 3.5268
2022-07-13 00:07:13 - train: epoch 0002, iter [02400, 05004], lr: 0.100000, loss: 3.3581
2022-07-13 00:07:47 - train: epoch 0002, iter [02500, 05004], lr: 0.100000, loss: 3.2908
2022-07-13 00:08:19 - train: epoch 0002, iter [02600, 05004], lr: 0.100000, loss: 3.3298
2022-07-13 00:08:53 - train: epoch 0002, iter [02700, 05004], lr: 0.100000, loss: 3.5373
2022-07-13 00:09:25 - train: epoch 0002, iter [02800, 05004], lr: 0.100000, loss: 3.4902
2022-07-13 00:09:59 - train: epoch 0002, iter [02900, 05004], lr: 0.100000, loss: 3.4045
2022-07-13 00:10:32 - train: epoch 0002, iter [03000, 05004], lr: 0.100000, loss: 3.2554
2022-07-13 00:11:05 - train: epoch 0002, iter [03100, 05004], lr: 0.100000, loss: 3.3993
2022-07-13 00:11:39 - train: epoch 0002, iter [03200, 05004], lr: 0.100000, loss: 3.4668
2022-07-13 00:12:13 - train: epoch 0002, iter [03300, 05004], lr: 0.100000, loss: 3.3049
2022-07-13 00:12:46 - train: epoch 0002, iter [03400, 05004], lr: 0.100000, loss: 3.5092
2022-07-13 00:13:20 - train: epoch 0002, iter [03500, 05004], lr: 0.100000, loss: 3.2518
2022-07-13 00:13:53 - train: epoch 0002, iter [03600, 05004], lr: 0.100000, loss: 3.3667
2022-07-13 00:14:27 - train: epoch 0002, iter [03700, 05004], lr: 0.100000, loss: 3.4709
2022-07-13 00:15:00 - train: epoch 0002, iter [03800, 05004], lr: 0.100000, loss: 3.1483
2022-07-13 00:15:34 - train: epoch 0002, iter [03900, 05004], lr: 0.100000, loss: 3.3112
2022-07-13 00:16:08 - train: epoch 0002, iter [04000, 05004], lr: 0.100000, loss: 3.2522
2022-07-13 00:16:42 - train: epoch 0002, iter [04100, 05004], lr: 0.100000, loss: 3.4099
2022-07-13 00:17:15 - train: epoch 0002, iter [04200, 05004], lr: 0.100000, loss: 3.1537
2022-07-13 00:17:48 - train: epoch 0002, iter [04300, 05004], lr: 0.100000, loss: 3.3228
2022-07-13 00:18:23 - train: epoch 0002, iter [04400, 05004], lr: 0.100000, loss: 3.1339
2022-07-13 00:18:55 - train: epoch 0002, iter [04500, 05004], lr: 0.100000, loss: 3.1153
2022-07-13 00:19:29 - train: epoch 0002, iter [04600, 05004], lr: 0.100000, loss: 3.2659
2022-07-13 00:20:02 - train: epoch 0002, iter [04700, 05004], lr: 0.100000, loss: 3.3425
2022-07-13 00:20:36 - train: epoch 0002, iter [04800, 05004], lr: 0.100000, loss: 3.2318
2022-07-13 00:21:10 - train: epoch 0002, iter [04900, 05004], lr: 0.100000, loss: 3.1390
2022-07-13 00:21:42 - train: epoch 0002, iter [05000, 05004], lr: 0.100000, loss: 3.0727
2022-07-13 00:21:42 - train: epoch 002, train_loss: 3.4951
2022-07-13 00:22:56 - eval: epoch: 002, acc1: 33.572%, acc5: 60.360%, test_loss: 3.0571, per_image_load_time: 2.572ms, per_image_inference_time: 0.286ms
2022-07-13 00:22:57 - until epoch: 002, best_acc1: 33.572%
2022-07-13 00:22:57 - epoch 003 lr: 0.100000
2022-07-13 00:23:35 - train: epoch 0003, iter [00100, 05004], lr: 0.100000, loss: 3.3444
2022-07-13 00:24:09 - train: epoch 0003, iter [00200, 05004], lr: 0.100000, loss: 3.1756
2022-07-13 00:24:43 - train: epoch 0003, iter [00300, 05004], lr: 0.100000, loss: 3.1510
2022-07-13 00:25:16 - train: epoch 0003, iter [00400, 05004], lr: 0.100000, loss: 3.2859
2022-07-13 00:25:48 - train: epoch 0003, iter [00500, 05004], lr: 0.100000, loss: 3.3736
2022-07-13 00:26:22 - train: epoch 0003, iter [00600, 05004], lr: 0.100000, loss: 3.0924
2022-07-13 00:26:54 - train: epoch 0003, iter [00700, 05004], lr: 0.100000, loss: 3.3174
2022-07-13 00:27:28 - train: epoch 0003, iter [00800, 05004], lr: 0.100000, loss: 3.3323
2022-07-13 00:28:01 - train: epoch 0003, iter [00900, 05004], lr: 0.100000, loss: 3.1381
2022-07-13 00:28:35 - train: epoch 0003, iter [01000, 05004], lr: 0.100000, loss: 3.1231
2022-07-13 00:29:07 - train: epoch 0003, iter [01100, 05004], lr: 0.100000, loss: 3.1001
2022-07-13 00:29:41 - train: epoch 0003, iter [01200, 05004], lr: 0.100000, loss: 2.9617
2022-07-13 00:30:14 - train: epoch 0003, iter [01300, 05004], lr: 0.100000, loss: 3.1009
2022-07-13 00:30:48 - train: epoch 0003, iter [01400, 05004], lr: 0.100000, loss: 3.1161
2022-07-13 00:31:21 - train: epoch 0003, iter [01500, 05004], lr: 0.100000, loss: 3.2670
2022-07-13 00:31:54 - train: epoch 0003, iter [01600, 05004], lr: 0.100000, loss: 3.0027
2022-07-13 00:32:27 - train: epoch 0003, iter [01700, 05004], lr: 0.100000, loss: 2.9801
2022-07-13 00:33:00 - train: epoch 0003, iter [01800, 05004], lr: 0.100000, loss: 2.9742
2022-07-13 00:33:34 - train: epoch 0003, iter [01900, 05004], lr: 0.100000, loss: 3.1761
2022-07-13 00:34:06 - train: epoch 0003, iter [02000, 05004], lr: 0.100000, loss: 3.3058
2022-07-13 00:34:40 - train: epoch 0003, iter [02100, 05004], lr: 0.100000, loss: 3.3835
2022-07-13 00:35:13 - train: epoch 0003, iter [02200, 05004], lr: 0.100000, loss: 3.5822
2022-07-13 00:35:47 - train: epoch 0003, iter [02300, 05004], lr: 0.100000, loss: 3.0853
2022-07-13 00:36:19 - train: epoch 0003, iter [02400, 05004], lr: 0.100000, loss: 3.0000
2022-07-13 00:36:53 - train: epoch 0003, iter [02500, 05004], lr: 0.100000, loss: 3.1423
2022-07-13 00:37:26 - train: epoch 0003, iter [02600, 05004], lr: 0.100000, loss: 3.1057
2022-07-13 00:38:00 - train: epoch 0003, iter [02700, 05004], lr: 0.100000, loss: 3.3870
2022-07-13 00:38:34 - train: epoch 0003, iter [02800, 05004], lr: 0.100000, loss: 2.9019
2022-07-13 00:39:08 - train: epoch 0003, iter [02900, 05004], lr: 0.100000, loss: 3.0716
2022-07-13 00:39:40 - train: epoch 0003, iter [03000, 05004], lr: 0.100000, loss: 3.2858
2022-07-13 00:40:14 - train: epoch 0003, iter [03100, 05004], lr: 0.100000, loss: 3.2352
2022-07-13 00:40:47 - train: epoch 0003, iter [03200, 05004], lr: 0.100000, loss: 3.0163
2022-07-13 00:41:20 - train: epoch 0003, iter [03300, 05004], lr: 0.100000, loss: 3.0294
2022-07-13 00:41:53 - train: epoch 0003, iter [03400, 05004], lr: 0.100000, loss: 3.1539
2022-07-13 00:42:27 - train: epoch 0003, iter [03500, 05004], lr: 0.100000, loss: 2.9075
2022-07-13 00:43:00 - train: epoch 0003, iter [03600, 05004], lr: 0.100000, loss: 2.8523
2022-07-13 00:43:35 - train: epoch 0003, iter [03700, 05004], lr: 0.100000, loss: 3.0455
2022-07-13 00:44:08 - train: epoch 0003, iter [03800, 05004], lr: 0.100000, loss: 3.0048
2022-07-13 00:44:41 - train: epoch 0003, iter [03900, 05004], lr: 0.100000, loss: 3.1999
2022-07-13 00:45:15 - train: epoch 0003, iter [04000, 05004], lr: 0.100000, loss: 3.0525
2022-07-13 00:45:48 - train: epoch 0003, iter [04100, 05004], lr: 0.100000, loss: 3.0122
2022-07-13 00:46:22 - train: epoch 0003, iter [04200, 05004], lr: 0.100000, loss: 2.9923
2022-07-13 00:46:55 - train: epoch 0003, iter [04300, 05004], lr: 0.100000, loss: 2.6284
2022-07-13 00:47:29 - train: epoch 0003, iter [04400, 05004], lr: 0.100000, loss: 2.9115
2022-07-13 00:48:02 - train: epoch 0003, iter [04500, 05004], lr: 0.100000, loss: 3.0033
2022-07-13 00:48:36 - train: epoch 0003, iter [04600, 05004], lr: 0.100000, loss: 2.9508
2022-07-13 00:49:09 - train: epoch 0003, iter [04700, 05004], lr: 0.100000, loss: 2.8474
2022-07-13 00:49:43 - train: epoch 0003, iter [04800, 05004], lr: 0.100000, loss: 3.0135
2022-07-13 00:50:16 - train: epoch 0003, iter [04900, 05004], lr: 0.100000, loss: 3.0393
2022-07-13 00:50:49 - train: epoch 0003, iter [05000, 05004], lr: 0.100000, loss: 2.9974
2022-07-13 00:50:50 - train: epoch 003, train_loss: 3.0627
2022-07-13 00:52:04 - eval: epoch: 003, acc1: 41.156%, acc5: 67.638%, test_loss: 2.6413, per_image_load_time: 1.968ms, per_image_inference_time: 0.305ms
2022-07-13 00:52:04 - until epoch: 003, best_acc1: 41.156%
2022-07-13 00:52:04 - epoch 004 lr: 0.100000
2022-07-13 00:52:42 - train: epoch 0004, iter [00100, 05004], lr: 0.100000, loss: 2.9352
2022-07-13 00:53:15 - train: epoch 0004, iter [00200, 05004], lr: 0.100000, loss: 2.8104
2022-07-13 00:53:48 - train: epoch 0004, iter [00300, 05004], lr: 0.100000, loss: 2.9440
2022-07-13 00:54:22 - train: epoch 0004, iter [00400, 05004], lr: 0.100000, loss: 2.8893
2022-07-13 00:54:55 - train: epoch 0004, iter [00500, 05004], lr: 0.100000, loss: 2.7440
2022-07-13 00:55:28 - train: epoch 0004, iter [00600, 05004], lr: 0.100000, loss: 3.0896
2022-07-13 00:56:01 - train: epoch 0004, iter [00700, 05004], lr: 0.100000, loss: 2.9626
2022-07-13 00:56:34 - train: epoch 0004, iter [00800, 05004], lr: 0.100000, loss: 2.6587
2022-07-13 00:57:07 - train: epoch 0004, iter [00900, 05004], lr: 0.100000, loss: 2.6042
2022-07-13 00:57:41 - train: epoch 0004, iter [01000, 05004], lr: 0.100000, loss: 2.8641
2022-07-13 00:58:14 - train: epoch 0004, iter [01100, 05004], lr: 0.100000, loss: 2.9915
2022-07-13 00:58:48 - train: epoch 0004, iter [01200, 05004], lr: 0.100000, loss: 2.6091
2022-07-13 00:59:21 - train: epoch 0004, iter [01300, 05004], lr: 0.100000, loss: 2.7614
2022-07-13 00:59:54 - train: epoch 0004, iter [01400, 05004], lr: 0.100000, loss: 2.9379
2022-07-13 01:00:28 - train: epoch 0004, iter [01500, 05004], lr: 0.100000, loss: 2.9053
2022-07-13 01:01:01 - train: epoch 0004, iter [01600, 05004], lr: 0.100000, loss: 2.6740
2022-07-13 01:01:35 - train: epoch 0004, iter [01700, 05004], lr: 0.100000, loss: 3.0088
2022-07-13 01:02:08 - train: epoch 0004, iter [01800, 05004], lr: 0.100000, loss: 2.9778
2022-07-13 01:02:42 - train: epoch 0004, iter [01900, 05004], lr: 0.100000, loss: 2.9108
2022-07-13 01:03:17 - train: epoch 0004, iter [02000, 05004], lr: 0.100000, loss: 2.9441
2022-07-13 01:03:49 - train: epoch 0004, iter [02100, 05004], lr: 0.100000, loss: 2.9519
2022-07-13 01:04:22 - train: epoch 0004, iter [02200, 05004], lr: 0.100000, loss: 2.8195
2022-07-13 01:04:55 - train: epoch 0004, iter [02300, 05004], lr: 0.100000, loss: 2.6855
2022-07-13 01:05:29 - train: epoch 0004, iter [02400, 05004], lr: 0.100000, loss: 2.7558
2022-07-13 01:06:03 - train: epoch 0004, iter [02500, 05004], lr: 0.100000, loss: 2.7492
2022-07-13 01:06:35 - train: epoch 0004, iter [02600, 05004], lr: 0.100000, loss: 2.9164
2022-07-13 01:07:09 - train: epoch 0004, iter [02700, 05004], lr: 0.100000, loss: 2.6512
2022-07-13 01:07:44 - train: epoch 0004, iter [02800, 05004], lr: 0.100000, loss: 2.8639
2022-07-13 01:08:16 - train: epoch 0004, iter [02900, 05004], lr: 0.100000, loss: 2.6874
2022-07-13 01:08:50 - train: epoch 0004, iter [03000, 05004], lr: 0.100000, loss: 2.7782
2022-07-13 01:09:23 - train: epoch 0004, iter [03100, 05004], lr: 0.100000, loss: 2.9258
2022-07-13 01:09:56 - train: epoch 0004, iter [03200, 05004], lr: 0.100000, loss: 2.7175
2022-07-13 01:10:29 - train: epoch 0004, iter [03300, 05004], lr: 0.100000, loss: 3.0323
2022-07-13 01:11:02 - train: epoch 0004, iter [03400, 05004], lr: 0.100000, loss: 2.8676
2022-07-13 01:11:36 - train: epoch 0004, iter [03500, 05004], lr: 0.100000, loss: 2.8525
2022-07-13 01:12:09 - train: epoch 0004, iter [03600, 05004], lr: 0.100000, loss: 2.6249
2022-07-13 01:12:43 - train: epoch 0004, iter [03700, 05004], lr: 0.100000, loss: 2.7490
2022-07-13 01:13:17 - train: epoch 0004, iter [03800, 05004], lr: 0.100000, loss: 2.7078
2022-07-13 01:13:49 - train: epoch 0004, iter [03900, 05004], lr: 0.100000, loss: 2.7647
2022-07-13 01:14:23 - train: epoch 0004, iter [04000, 05004], lr: 0.100000, loss: 2.4744
2022-07-13 01:14:56 - train: epoch 0004, iter [04100, 05004], lr: 0.100000, loss: 2.8074
2022-07-13 01:15:29 - train: epoch 0004, iter [04200, 05004], lr: 0.100000, loss: 2.6487
2022-07-13 01:16:03 - train: epoch 0004, iter [04300, 05004], lr: 0.100000, loss: 2.5794
2022-07-13 01:16:35 - train: epoch 0004, iter [04400, 05004], lr: 0.100000, loss: 2.5873
2022-07-13 01:17:09 - train: epoch 0004, iter [04500, 05004], lr: 0.100000, loss: 2.2779
2022-07-13 01:17:42 - train: epoch 0004, iter [04600, 05004], lr: 0.100000, loss: 2.7474
2022-07-13 01:18:16 - train: epoch 0004, iter [04700, 05004], lr: 0.100000, loss: 2.6806
2022-07-13 01:18:50 - train: epoch 0004, iter [04800, 05004], lr: 0.100000, loss: 2.6352
2022-07-13 01:19:23 - train: epoch 0004, iter [04900, 05004], lr: 0.100000, loss: 2.7524
2022-07-13 01:19:54 - train: epoch 0004, iter [05000, 05004], lr: 0.100000, loss: 2.8040
2022-07-13 01:19:55 - train: epoch 004, train_loss: 2.8379
2022-07-13 01:21:10 - eval: epoch: 004, acc1: 43.594%, acc5: 70.140%, test_loss: 2.5150, per_image_load_time: 2.497ms, per_image_inference_time: 0.295ms
2022-07-13 01:21:11 - until epoch: 004, best_acc1: 43.594%
2022-07-13 01:21:11 - epoch 005 lr: 0.100000
2022-07-13 01:21:49 - train: epoch 0005, iter [00100, 05004], lr: 0.100000, loss: 2.7917
2022-07-13 01:22:22 - train: epoch 0005, iter [00200, 05004], lr: 0.100000, loss: 2.7436
2022-07-13 01:22:55 - train: epoch 0005, iter [00300, 05004], lr: 0.100000, loss: 2.8861
2022-07-13 01:23:27 - train: epoch 0005, iter [00400, 05004], lr: 0.100000, loss: 2.7241
2022-07-13 01:24:00 - train: epoch 0005, iter [00500, 05004], lr: 0.100000, loss: 2.5481
2022-07-13 01:24:33 - train: epoch 0005, iter [00600, 05004], lr: 0.100000, loss: 2.6590
2022-07-13 01:25:06 - train: epoch 0005, iter [00700, 05004], lr: 0.100000, loss: 2.8090
2022-07-13 01:25:39 - train: epoch 0005, iter [00800, 05004], lr: 0.100000, loss: 2.8575
2022-07-13 01:26:12 - train: epoch 0005, iter [00900, 05004], lr: 0.100000, loss: 2.6865
2022-07-13 01:26:45 - train: epoch 0005, iter [01000, 05004], lr: 0.100000, loss: 2.9272
2022-07-13 01:27:18 - train: epoch 0005, iter [01100, 05004], lr: 0.100000, loss: 2.8171
2022-07-13 01:27:51 - train: epoch 0005, iter [01200, 05004], lr: 0.100000, loss: 2.7684
2022-07-13 01:28:25 - train: epoch 0005, iter [01300, 05004], lr: 0.100000, loss: 2.7831
2022-07-13 01:28:57 - train: epoch 0005, iter [01400, 05004], lr: 0.100000, loss: 2.7667
2022-07-13 01:29:31 - train: epoch 0005, iter [01500, 05004], lr: 0.100000, loss: 2.6535
2022-07-13 01:30:05 - train: epoch 0005, iter [01600, 05004], lr: 0.100000, loss: 2.5659
2022-07-13 01:30:37 - train: epoch 0005, iter [01700, 05004], lr: 0.100000, loss: 2.6041
2022-07-13 01:31:11 - train: epoch 0005, iter [01800, 05004], lr: 0.100000, loss: 2.7020
2022-07-13 01:31:44 - train: epoch 0005, iter [01900, 05004], lr: 0.100000, loss: 2.6578
2022-07-13 01:32:18 - train: epoch 0005, iter [02000, 05004], lr: 0.100000, loss: 2.7100
2022-07-13 01:32:51 - train: epoch 0005, iter [02100, 05004], lr: 0.100000, loss: 2.4528
2022-07-13 01:33:24 - train: epoch 0005, iter [02200, 05004], lr: 0.100000, loss: 2.4941
2022-07-13 01:33:58 - train: epoch 0005, iter [02300, 05004], lr: 0.100000, loss: 2.4665
2022-07-13 01:34:31 - train: epoch 0005, iter [02400, 05004], lr: 0.100000, loss: 2.6874
2022-07-13 01:35:05 - train: epoch 0005, iter [02500, 05004], lr: 0.100000, loss: 2.8328
2022-07-13 01:35:38 - train: epoch 0005, iter [02600, 05004], lr: 0.100000, loss: 2.9503
2022-07-13 01:36:13 - train: epoch 0005, iter [02700, 05004], lr: 0.100000, loss: 2.8003
2022-07-13 01:36:46 - train: epoch 0005, iter [02800, 05004], lr: 0.100000, loss: 2.6591
2022-07-13 01:37:19 - train: epoch 0005, iter [02900, 05004], lr: 0.100000, loss: 2.5706
2022-07-13 01:37:52 - train: epoch 0005, iter [03000, 05004], lr: 0.100000, loss: 2.6268
2022-07-13 01:38:26 - train: epoch 0005, iter [03100, 05004], lr: 0.100000, loss: 2.7205
2022-07-13 01:38:59 - train: epoch 0005, iter [03200, 05004], lr: 0.100000, loss: 2.8502
2022-07-13 01:39:33 - train: epoch 0005, iter [03300, 05004], lr: 0.100000, loss: 2.5175
2022-07-13 01:40:07 - train: epoch 0005, iter [03400, 05004], lr: 0.100000, loss: 2.7241
2022-07-13 01:40:40 - train: epoch 0005, iter [03500, 05004], lr: 0.100000, loss: 2.6681
2022-07-13 01:41:13 - train: epoch 0005, iter [03600, 05004], lr: 0.100000, loss: 2.7310
2022-07-13 01:41:46 - train: epoch 0005, iter [03700, 05004], lr: 0.100000, loss: 2.5438
2022-07-13 01:42:21 - train: epoch 0005, iter [03800, 05004], lr: 0.100000, loss: 2.4279
2022-07-13 01:42:53 - train: epoch 0005, iter [03900, 05004], lr: 0.100000, loss: 2.9538
2022-07-13 01:43:28 - train: epoch 0005, iter [04000, 05004], lr: 0.100000, loss: 2.7022
2022-07-13 01:44:01 - train: epoch 0005, iter [04100, 05004], lr: 0.100000, loss: 2.5187
2022-07-13 01:44:34 - train: epoch 0005, iter [04200, 05004], lr: 0.100000, loss: 2.7420
2022-07-13 01:45:08 - train: epoch 0005, iter [04300, 05004], lr: 0.100000, loss: 2.4738
2022-07-13 01:45:42 - train: epoch 0005, iter [04400, 05004], lr: 0.100000, loss: 2.7835
2022-07-13 01:46:16 - train: epoch 0005, iter [04500, 05004], lr: 0.100000, loss: 2.6985
2022-07-13 01:46:49 - train: epoch 0005, iter [04600, 05004], lr: 0.100000, loss: 2.5474
2022-07-13 01:47:24 - train: epoch 0005, iter [04700, 05004], lr: 0.100000, loss: 2.3537
2022-07-13 01:47:56 - train: epoch 0005, iter [04800, 05004], lr: 0.100000, loss: 2.4779
2022-07-13 01:48:31 - train: epoch 0005, iter [04900, 05004], lr: 0.100000, loss: 2.8613
2022-07-13 01:49:02 - train: epoch 0005, iter [05000, 05004], lr: 0.100000, loss: 2.5720
2022-07-13 01:49:03 - train: epoch 005, train_loss: 2.6992
2022-07-13 01:50:18 - eval: epoch: 005, acc1: 45.568%, acc5: 72.486%, test_loss: 2.3854, per_image_load_time: 2.397ms, per_image_inference_time: 0.315ms
2022-07-13 01:50:18 - until epoch: 005, best_acc1: 45.568%
2022-07-13 01:50:18 - epoch 006 lr: 0.100000
2022-07-13 01:50:57 - train: epoch 0006, iter [00100, 05004], lr: 0.100000, loss: 2.6508
2022-07-13 01:51:30 - train: epoch 0006, iter [00200, 05004], lr: 0.100000, loss: 2.7194
2022-07-13 01:52:03 - train: epoch 0006, iter [00300, 05004], lr: 0.100000, loss: 2.4181
2022-07-13 01:52:37 - train: epoch 0006, iter [00400, 05004], lr: 0.100000, loss: 2.8103
2022-07-13 01:53:10 - train: epoch 0006, iter [00500, 05004], lr: 0.100000, loss: 2.6138
2022-07-13 01:53:43 - train: epoch 0006, iter [00600, 05004], lr: 0.100000, loss: 2.5957
2022-07-13 01:54:17 - train: epoch 0006, iter [00700, 05004], lr: 0.100000, loss: 2.6923
2022-07-13 01:54:51 - train: epoch 0006, iter [00800, 05004], lr: 0.100000, loss: 2.6146
2022-07-13 01:55:23 - train: epoch 0006, iter [00900, 05004], lr: 0.100000, loss: 2.3843
2022-07-13 01:55:56 - train: epoch 0006, iter [01000, 05004], lr: 0.100000, loss: 2.5969
2022-07-13 01:56:30 - train: epoch 0006, iter [01100, 05004], lr: 0.100000, loss: 2.5233
2022-07-13 01:57:03 - train: epoch 0006, iter [01200, 05004], lr: 0.100000, loss: 2.6155
2022-07-13 01:57:36 - train: epoch 0006, iter [01300, 05004], lr: 0.100000, loss: 2.7443
2022-07-13 01:58:10 - train: epoch 0006, iter [01400, 05004], lr: 0.100000, loss: 2.7174
2022-07-13 01:58:43 - train: epoch 0006, iter [01500, 05004], lr: 0.100000, loss: 2.8028
2022-07-13 01:59:16 - train: epoch 0006, iter [01600, 05004], lr: 0.100000, loss: 2.4202
2022-07-13 01:59:49 - train: epoch 0006, iter [01700, 05004], lr: 0.100000, loss: 2.6931
2022-07-13 02:00:23 - train: epoch 0006, iter [01800, 05004], lr: 0.100000, loss: 2.6822
2022-07-13 02:00:57 - train: epoch 0006, iter [01900, 05004], lr: 0.100000, loss: 2.5577
2022-07-13 02:01:29 - train: epoch 0006, iter [02000, 05004], lr: 0.100000, loss: 2.8482
2022-07-13 02:02:03 - train: epoch 0006, iter [02100, 05004], lr: 0.100000, loss: 2.6690
2022-07-13 02:02:36 - train: epoch 0006, iter [02200, 05004], lr: 0.100000, loss: 2.3854
2022-07-13 02:03:09 - train: epoch 0006, iter [02300, 05004], lr: 0.100000, loss: 2.4008
2022-07-13 02:03:43 - train: epoch 0006, iter [02400, 05004], lr: 0.100000, loss: 2.5771
2022-07-13 02:04:16 - train: epoch 0006, iter [02500, 05004], lr: 0.100000, loss: 2.8230
2022-07-13 02:04:51 - train: epoch 0006, iter [02600, 05004], lr: 0.100000, loss: 2.5347
2022-07-13 02:05:24 - train: epoch 0006, iter [02700, 05004], lr: 0.100000, loss: 2.6381
2022-07-13 02:05:58 - train: epoch 0006, iter [02800, 05004], lr: 0.100000, loss: 2.6035
2022-07-13 02:06:30 - train: epoch 0006, iter [02900, 05004], lr: 0.100000, loss: 2.8272
2022-07-13 02:07:04 - train: epoch 0006, iter [03000, 05004], lr: 0.100000, loss: 2.5533
2022-07-13 02:07:37 - train: epoch 0006, iter [03100, 05004], lr: 0.100000, loss: 2.5195
2022-07-13 02:08:11 - train: epoch 0006, iter [03200, 05004], lr: 0.100000, loss: 2.5486
2022-07-13 02:08:43 - train: epoch 0006, iter [03300, 05004], lr: 0.100000, loss: 2.4957
2022-07-13 02:09:17 - train: epoch 0006, iter [03400, 05004], lr: 0.100000, loss: 2.7565
2022-07-13 02:09:50 - train: epoch 0006, iter [03500, 05004], lr: 0.100000, loss: 2.6614
2022-07-13 02:10:24 - train: epoch 0006, iter [03600, 05004], lr: 0.100000, loss: 2.5843
2022-07-13 02:10:56 - train: epoch 0006, iter [03700, 05004], lr: 0.100000, loss: 2.4915
2022-07-13 02:11:31 - train: epoch 0006, iter [03800, 05004], lr: 0.100000, loss: 2.4399
2022-07-13 02:12:03 - train: epoch 0006, iter [03900, 05004], lr: 0.100000, loss: 2.5801
2022-07-13 02:12:36 - train: epoch 0006, iter [04000, 05004], lr: 0.100000, loss: 2.9488
2022-07-13 02:13:09 - train: epoch 0006, iter [04100, 05004], lr: 0.100000, loss: 2.5029
2022-07-13 02:13:43 - train: epoch 0006, iter [04200, 05004], lr: 0.100000, loss: 2.3798
2022-07-13 02:14:17 - train: epoch 0006, iter [04300, 05004], lr: 0.100000, loss: 2.5729
2022-07-13 02:14:50 - train: epoch 0006, iter [04400, 05004], lr: 0.100000, loss: 2.6228
2022-07-13 02:15:24 - train: epoch 0006, iter [04500, 05004], lr: 0.100000, loss: 2.5665
2022-07-13 02:15:57 - train: epoch 0006, iter [04600, 05004], lr: 0.100000, loss: 2.6352
2022-07-13 02:16:31 - train: epoch 0006, iter [04700, 05004], lr: 0.100000, loss: 2.5762
2022-07-13 02:17:03 - train: epoch 0006, iter [04800, 05004], lr: 0.100000, loss: 2.6639
2022-07-13 02:17:37 - train: epoch 0006, iter [04900, 05004], lr: 0.100000, loss: 2.5957
2022-07-13 02:18:10 - train: epoch 0006, iter [05000, 05004], lr: 0.100000, loss: 2.3998
2022-07-13 02:18:11 - train: epoch 006, train_loss: 2.6094
2022-07-13 02:19:26 - eval: epoch: 006, acc1: 46.388%, acc5: 72.672%, test_loss: 2.3628, per_image_load_time: 2.171ms, per_image_inference_time: 0.307ms
2022-07-13 02:19:26 - until epoch: 006, best_acc1: 46.388%
2022-07-13 02:19:26 - epoch 007 lr: 0.100000
2022-07-13 02:20:04 - train: epoch 0007, iter [00100, 05004], lr: 0.100000, loss: 2.4089
2022-07-13 02:20:38 - train: epoch 0007, iter [00200, 05004], lr: 0.100000, loss: 2.7618
2022-07-13 02:21:11 - train: epoch 0007, iter [00300, 05004], lr: 0.100000, loss: 2.8827
2022-07-13 02:21:44 - train: epoch 0007, iter [00400, 05004], lr: 0.100000, loss: 2.6579
2022-07-13 02:22:18 - train: epoch 0007, iter [00500, 05004], lr: 0.100000, loss: 2.4774
2022-07-13 02:22:51 - train: epoch 0007, iter [00600, 05004], lr: 0.100000, loss: 2.7439
2022-07-13 02:23:24 - train: epoch 0007, iter [00700, 05004], lr: 0.100000, loss: 2.5345
2022-07-13 02:23:57 - train: epoch 0007, iter [00800, 05004], lr: 0.100000, loss: 2.5938
2022-07-13 02:24:31 - train: epoch 0007, iter [00900, 05004], lr: 0.100000, loss: 2.5031
2022-07-13 02:25:03 - train: epoch 0007, iter [01000, 05004], lr: 0.100000, loss: 2.6128
2022-07-13 02:25:37 - train: epoch 0007, iter [01100, 05004], lr: 0.100000, loss: 2.3886
2022-07-13 02:26:10 - train: epoch 0007, iter [01200, 05004], lr: 0.100000, loss: 2.5188
2022-07-13 02:26:43 - train: epoch 0007, iter [01300, 05004], lr: 0.100000, loss: 2.5403
2022-07-13 02:27:15 - train: epoch 0007, iter [01400, 05004], lr: 0.100000, loss: 2.6317
2022-07-13 02:27:49 - train: epoch 0007, iter [01500, 05004], lr: 0.100000, loss: 2.7030
2022-07-13 02:28:23 - train: epoch 0007, iter [01600, 05004], lr: 0.100000, loss: 2.5315
2022-07-13 02:28:55 - train: epoch 0007, iter [01700, 05004], lr: 0.100000, loss: 2.5807
2022-07-13 02:29:29 - train: epoch 0007, iter [01800, 05004], lr: 0.100000, loss: 2.4824
2022-07-13 02:30:03 - train: epoch 0007, iter [01900, 05004], lr: 0.100000, loss: 2.5972
2022-07-13 02:30:36 - train: epoch 0007, iter [02000, 05004], lr: 0.100000, loss: 2.2648
2022-07-13 02:31:09 - train: epoch 0007, iter [02100, 05004], lr: 0.100000, loss: 2.7903
2022-07-13 02:31:43 - train: epoch 0007, iter [02200, 05004], lr: 0.100000, loss: 2.4533
2022-07-13 02:32:16 - train: epoch 0007, iter [02300, 05004], lr: 0.100000, loss: 2.5775
2022-07-13 02:32:50 - train: epoch 0007, iter [02400, 05004], lr: 0.100000, loss: 2.5200
2022-07-13 02:33:23 - train: epoch 0007, iter [02500, 05004], lr: 0.100000, loss: 2.4759
2022-07-13 02:33:56 - train: epoch 0007, iter [02600, 05004], lr: 0.100000, loss: 2.5526
2022-07-13 02:34:30 - train: epoch 0007, iter [02700, 05004], lr: 0.100000, loss: 2.4508
2022-07-13 02:35:03 - train: epoch 0007, iter [02800, 05004], lr: 0.100000, loss: 2.4938
2022-07-13 02:35:37 - train: epoch 0007, iter [02900, 05004], lr: 0.100000, loss: 2.4988
2022-07-13 02:36:10 - train: epoch 0007, iter [03000, 05004], lr: 0.100000, loss: 2.5997
2022-07-13 02:36:44 - train: epoch 0007, iter [03100, 05004], lr: 0.100000, loss: 2.4391
2022-07-13 02:37:17 - train: epoch 0007, iter [03200, 05004], lr: 0.100000, loss: 2.5235
2022-07-13 02:37:51 - train: epoch 0007, iter [03300, 05004], lr: 0.100000, loss: 2.8006
2022-07-13 02:38:23 - train: epoch 0007, iter [03400, 05004], lr: 0.100000, loss: 2.3959
2022-07-13 02:38:57 - train: epoch 0007, iter [03500, 05004], lr: 0.100000, loss: 2.6134
2022-07-13 02:39:31 - train: epoch 0007, iter [03600, 05004], lr: 0.100000, loss: 2.3845
2022-07-13 02:40:04 - train: epoch 0007, iter [03700, 05004], lr: 0.100000, loss: 2.6203
2022-07-13 02:40:38 - train: epoch 0007, iter [03800, 05004], lr: 0.100000, loss: 2.7935
2022-07-13 02:41:10 - train: epoch 0007, iter [03900, 05004], lr: 0.100000, loss: 2.4041
2022-07-13 02:41:45 - train: epoch 0007, iter [04000, 05004], lr: 0.100000, loss: 2.5916
2022-07-13 02:42:18 - train: epoch 0007, iter [04100, 05004], lr: 0.100000, loss: 2.4440
2022-07-13 02:42:52 - train: epoch 0007, iter [04200, 05004], lr: 0.100000, loss: 2.4162
2022-07-13 02:43:24 - train: epoch 0007, iter [04300, 05004], lr: 0.100000, loss: 2.7156
2022-07-13 02:43:58 - train: epoch 0007, iter [04400, 05004], lr: 0.100000, loss: 2.3714
2022-07-13 02:44:31 - train: epoch 0007, iter [04500, 05004], lr: 0.100000, loss: 2.7082
2022-07-13 02:45:04 - train: epoch 0007, iter [04600, 05004], lr: 0.100000, loss: 2.7430
2022-07-13 02:45:38 - train: epoch 0007, iter [04700, 05004], lr: 0.100000, loss: 2.6838
2022-07-13 02:46:12 - train: epoch 0007, iter [04800, 05004], lr: 0.100000, loss: 2.6680
2022-07-13 02:46:45 - train: epoch 0007, iter [04900, 05004], lr: 0.100000, loss: 2.5536
2022-07-13 02:47:17 - train: epoch 0007, iter [05000, 05004], lr: 0.100000, loss: 2.4908
2022-07-13 02:47:18 - train: epoch 007, train_loss: 2.5427
2022-07-13 02:48:33 - eval: epoch: 007, acc1: 48.746%, acc5: 75.240%, test_loss: 2.2112, per_image_load_time: 2.494ms, per_image_inference_time: 0.306ms
2022-07-13 02:48:33 - until epoch: 007, best_acc1: 48.746%
2022-07-13 02:48:33 - epoch 008 lr: 0.100000
2022-07-13 02:49:12 - train: epoch 0008, iter [00100, 05004], lr: 0.100000, loss: 2.5167
2022-07-13 02:49:45 - train: epoch 0008, iter [00200, 05004], lr: 0.100000, loss: 2.5627
2022-07-13 02:50:18 - train: epoch 0008, iter [00300, 05004], lr: 0.100000, loss: 2.2606
2022-07-13 02:50:51 - train: epoch 0008, iter [00400, 05004], lr: 0.100000, loss: 2.2818
2022-07-13 02:51:25 - train: epoch 0008, iter [00500, 05004], lr: 0.100000, loss: 2.3437
2022-07-13 02:51:58 - train: epoch 0008, iter [00600, 05004], lr: 0.100000, loss: 2.4960
2022-07-13 02:52:31 - train: epoch 0008, iter [00700, 05004], lr: 0.100000, loss: 2.8449
2022-07-13 02:53:04 - train: epoch 0008, iter [00800, 05004], lr: 0.100000, loss: 2.2624
2022-07-13 02:53:37 - train: epoch 0008, iter [00900, 05004], lr: 0.100000, loss: 2.4676
2022-07-13 02:54:11 - train: epoch 0008, iter [01000, 05004], lr: 0.100000, loss: 2.5328
2022-07-13 02:54:44 - train: epoch 0008, iter [01100, 05004], lr: 0.100000, loss: 2.2959
2022-07-13 02:55:17 - train: epoch 0008, iter [01200, 05004], lr: 0.100000, loss: 2.2971
2022-07-13 02:55:51 - train: epoch 0008, iter [01300, 05004], lr: 0.100000, loss: 2.5879
2022-07-13 02:56:24 - train: epoch 0008, iter [01400, 05004], lr: 0.100000, loss: 2.4879
2022-07-13 02:56:57 - train: epoch 0008, iter [01500, 05004], lr: 0.100000, loss: 2.5528
2022-07-13 02:57:31 - train: epoch 0008, iter [01600, 05004], lr: 0.100000, loss: 2.5266
2022-07-13 02:58:05 - train: epoch 0008, iter [01700, 05004], lr: 0.100000, loss: 2.4706
2022-07-13 02:58:37 - train: epoch 0008, iter [01800, 05004], lr: 0.100000, loss: 2.6680
2022-07-13 02:59:10 - train: epoch 0008, iter [01900, 05004], lr: 0.100000, loss: 2.3680
2022-07-13 02:59:44 - train: epoch 0008, iter [02000, 05004], lr: 0.100000, loss: 2.4545
2022-07-13 03:00:17 - train: epoch 0008, iter [02100, 05004], lr: 0.100000, loss: 2.4638
2022-07-13 03:00:51 - train: epoch 0008, iter [02200, 05004], lr: 0.100000, loss: 2.3242
2022-07-13 03:01:24 - train: epoch 0008, iter [02300, 05004], lr: 0.100000, loss: 2.6146
2022-07-13 03:01:57 - train: epoch 0008, iter [02400, 05004], lr: 0.100000, loss: 2.3640
2022-07-13 03:02:31 - train: epoch 0008, iter [02500, 05004], lr: 0.100000, loss: 2.4856
2022-07-13 03:03:04 - train: epoch 0008, iter [02600, 05004], lr: 0.100000, loss: 2.6531
2022-07-13 03:03:37 - train: epoch 0008, iter [02700, 05004], lr: 0.100000, loss: 2.6373
2022-07-13 03:04:11 - train: epoch 0008, iter [02800, 05004], lr: 0.100000, loss: 2.5731
2022-07-13 03:04:44 - train: epoch 0008, iter [02900, 05004], lr: 0.100000, loss: 2.4219
2022-07-13 03:05:18 - train: epoch 0008, iter [03000, 05004], lr: 0.100000, loss: 2.5645
2022-07-13 03:05:50 - train: epoch 0008, iter [03100, 05004], lr: 0.100000, loss: 2.4988
2022-07-13 03:06:24 - train: epoch 0008, iter [03200, 05004], lr: 0.100000, loss: 2.7123
2022-07-13 03:06:57 - train: epoch 0008, iter [03300, 05004], lr: 0.100000, loss: 2.6946
2022-07-13 03:07:30 - train: epoch 0008, iter [03400, 05004], lr: 0.100000, loss: 2.7017
2022-07-13 03:08:05 - train: epoch 0008, iter [03500, 05004], lr: 0.100000, loss: 2.4116
2022-07-13 03:08:38 - train: epoch 0008, iter [03600, 05004], lr: 0.100000, loss: 2.6452
2022-07-13 03:09:11 - train: epoch 0008, iter [03700, 05004], lr: 0.100000, loss: 2.3739
2022-07-13 03:09:45 - train: epoch 0008, iter [03800, 05004], lr: 0.100000, loss: 2.4193
2022-07-13 03:10:18 - train: epoch 0008, iter [03900, 05004], lr: 0.100000, loss: 2.6659
2022-07-13 03:10:52 - train: epoch 0008, iter [04000, 05004], lr: 0.100000, loss: 2.7430
2022-07-13 03:11:26 - train: epoch 0008, iter [04100, 05004], lr: 0.100000, loss: 2.4440
2022-07-13 03:11:59 - train: epoch 0008, iter [04200, 05004], lr: 0.100000, loss: 2.4750
2022-07-13 03:12:33 - train: epoch 0008, iter [04300, 05004], lr: 0.100000, loss: 2.2483
2022-07-13 03:13:07 - train: epoch 0008, iter [04400, 05004], lr: 0.100000, loss: 2.5513
2022-07-13 03:13:40 - train: epoch 0008, iter [04500, 05004], lr: 0.100000, loss: 2.7491
2022-07-13 03:14:13 - train: epoch 0008, iter [04600, 05004], lr: 0.100000, loss: 2.6784
2022-07-13 03:14:47 - train: epoch 0008, iter [04700, 05004], lr: 0.100000, loss: 2.4026
2022-07-13 03:15:21 - train: epoch 0008, iter [04800, 05004], lr: 0.100000, loss: 2.5552
2022-07-13 03:15:53 - train: epoch 0008, iter [04900, 05004], lr: 0.100000, loss: 2.5147
2022-07-13 03:16:26 - train: epoch 0008, iter [05000, 05004], lr: 0.100000, loss: 2.4595
2022-07-13 03:16:27 - train: epoch 008, train_loss: 2.4926
2022-07-13 03:17:42 - eval: epoch: 008, acc1: 49.674%, acc5: 75.896%, test_loss: 2.1754, per_image_load_time: 2.561ms, per_image_inference_time: 0.299ms
2022-07-13 03:17:42 - until epoch: 008, best_acc1: 49.674%
2022-07-13 03:17:42 - epoch 009 lr: 0.100000
2022-07-13 03:18:22 - train: epoch 0009, iter [00100, 05004], lr: 0.100000, loss: 2.1741
2022-07-13 03:18:55 - train: epoch 0009, iter [00200, 05004], lr: 0.100000, loss: 2.3291
2022-07-13 03:19:28 - train: epoch 0009, iter [00300, 05004], lr: 0.100000, loss: 2.2661
2022-07-13 03:20:01 - train: epoch 0009, iter [00400, 05004], lr: 0.100000, loss: 2.6109
2022-07-13 03:20:34 - train: epoch 0009, iter [00500, 05004], lr: 0.100000, loss: 2.5014
2022-07-13 03:21:08 - train: epoch 0009, iter [00600, 05004], lr: 0.100000, loss: 2.4504
2022-07-13 03:21:42 - train: epoch 0009, iter [00700, 05004], lr: 0.100000, loss: 2.3210
2022-07-13 03:22:14 - train: epoch 0009, iter [00800, 05004], lr: 0.100000, loss: 2.3592
2022-07-13 03:22:47 - train: epoch 0009, iter [00900, 05004], lr: 0.100000, loss: 2.3618
2022-07-13 03:23:21 - train: epoch 0009, iter [01000, 05004], lr: 0.100000, loss: 2.3203
2022-07-13 03:23:54 - train: epoch 0009, iter [01100, 05004], lr: 0.100000, loss: 2.7346
2022-07-13 03:24:27 - train: epoch 0009, iter [01200, 05004], lr: 0.100000, loss: 2.5404
2022-07-13 03:25:00 - train: epoch 0009, iter [01300, 05004], lr: 0.100000, loss: 2.6784
2022-07-13 03:25:33 - train: epoch 0009, iter [01400, 05004], lr: 0.100000, loss: 2.0919
2022-07-13 03:26:07 - train: epoch 0009, iter [01500, 05004], lr: 0.100000, loss: 2.3904
2022-07-13 03:26:40 - train: epoch 0009, iter [01600, 05004], lr: 0.100000, loss: 2.4933
2022-07-13 03:27:14 - train: epoch 0009, iter [01700, 05004], lr: 0.100000, loss: 2.6827
2022-07-13 03:27:48 - train: epoch 0009, iter [01800, 05004], lr: 0.100000, loss: 2.3662
2022-07-13 03:28:21 - train: epoch 0009, iter [01900, 05004], lr: 0.100000, loss: 2.2211
2022-07-13 03:28:55 - train: epoch 0009, iter [02000, 05004], lr: 0.100000, loss: 2.1910
2022-07-13 03:29:28 - train: epoch 0009, iter [02100, 05004], lr: 0.100000, loss: 2.4454
2022-07-13 03:30:02 - train: epoch 0009, iter [02200, 05004], lr: 0.100000, loss: 2.5569
2022-07-13 03:30:35 - train: epoch 0009, iter [02300, 05004], lr: 0.100000, loss: 2.2489
2022-07-13 03:31:08 - train: epoch 0009, iter [02400, 05004], lr: 0.100000, loss: 2.4400
2022-07-13 03:31:42 - train: epoch 0009, iter [02500, 05004], lr: 0.100000, loss: 2.3944
2022-07-13 03:32:15 - train: epoch 0009, iter [02600, 05004], lr: 0.100000, loss: 2.4166
2022-07-13 03:32:49 - train: epoch 0009, iter [02700, 05004], lr: 0.100000, loss: 2.3541
2022-07-13 03:33:22 - train: epoch 0009, iter [02800, 05004], lr: 0.100000, loss: 2.5083
2022-07-13 03:33:56 - train: epoch 0009, iter [02900, 05004], lr: 0.100000, loss: 2.1613
2022-07-13 03:34:30 - train: epoch 0009, iter [03000, 05004], lr: 0.100000, loss: 2.3185
2022-07-13 03:35:04 - train: epoch 0009, iter [03100, 05004], lr: 0.100000, loss: 2.5556
2022-07-13 03:35:37 - train: epoch 0009, iter [03200, 05004], lr: 0.100000, loss: 2.5087
2022-07-13 03:36:10 - train: epoch 0009, iter [03300, 05004], lr: 0.100000, loss: 2.5450
2022-07-13 03:36:44 - train: epoch 0009, iter [03400, 05004], lr: 0.100000, loss: 2.6292
2022-07-13 03:37:18 - train: epoch 0009, iter [03500, 05004], lr: 0.100000, loss: 2.6476
2022-07-13 03:37:50 - train: epoch 0009, iter [03600, 05004], lr: 0.100000, loss: 2.3246
2022-07-13 03:38:25 - train: epoch 0009, iter [03700, 05004], lr: 0.100000, loss: 2.5750
2022-07-13 03:38:57 - train: epoch 0009, iter [03800, 05004], lr: 0.100000, loss: 2.6085
2022-07-13 03:39:30 - train: epoch 0009, iter [03900, 05004], lr: 0.100000, loss: 2.0288
2022-07-13 03:40:04 - train: epoch 0009, iter [04000, 05004], lr: 0.100000, loss: 2.6745
2022-07-13 03:40:38 - train: epoch 0009, iter [04100, 05004], lr: 0.100000, loss: 2.4734
2022-07-13 03:41:12 - train: epoch 0009, iter [04200, 05004], lr: 0.100000, loss: 2.4329
2022-07-13 03:41:45 - train: epoch 0009, iter [04300, 05004], lr: 0.100000, loss: 2.4873
2022-07-13 03:42:19 - train: epoch 0009, iter [04400, 05004], lr: 0.100000, loss: 2.3844
2022-07-13 03:42:52 - train: epoch 0009, iter [04500, 05004], lr: 0.100000, loss: 2.3895
2022-07-13 03:43:26 - train: epoch 0009, iter [04600, 05004], lr: 0.100000, loss: 2.5126
2022-07-13 03:44:00 - train: epoch 0009, iter [04700, 05004], lr: 0.100000, loss: 2.6210
2022-07-13 03:44:33 - train: epoch 0009, iter [04800, 05004], lr: 0.100000, loss: 2.7037
2022-07-13 03:45:07 - train: epoch 0009, iter [04900, 05004], lr: 0.100000, loss: 2.4790
2022-07-13 03:45:39 - train: epoch 0009, iter [05000, 05004], lr: 0.100000, loss: 2.3425
2022-07-13 03:45:40 - train: epoch 009, train_loss: 2.4537
2022-07-13 03:46:55 - eval: epoch: 009, acc1: 51.258%, acc5: 76.822%, test_loss: 2.1074, per_image_load_time: 2.278ms, per_image_inference_time: 0.295ms
2022-07-13 03:46:55 - until epoch: 009, best_acc1: 51.258%
2022-07-13 03:46:55 - epoch 010 lr: 0.100000
2022-07-13 03:47:34 - train: epoch 0010, iter [00100, 05004], lr: 0.100000, loss: 2.3813
2022-07-13 03:48:08 - train: epoch 0010, iter [00200, 05004], lr: 0.100000, loss: 2.6088
2022-07-13 03:48:40 - train: epoch 0010, iter [00300, 05004], lr: 0.100000, loss: 2.4540
2022-07-13 03:49:15 - train: epoch 0010, iter [00400, 05004], lr: 0.100000, loss: 2.4748
2022-07-13 03:49:47 - train: epoch 0010, iter [00500, 05004], lr: 0.100000, loss: 2.3102
2022-07-13 03:50:20 - train: epoch 0010, iter [00600, 05004], lr: 0.100000, loss: 2.5459
2022-07-13 03:50:54 - train: epoch 0010, iter [00700, 05004], lr: 0.100000, loss: 2.5654
2022-07-13 03:51:26 - train: epoch 0010, iter [00800, 05004], lr: 0.100000, loss: 2.2989
2022-07-13 03:51:59 - train: epoch 0010, iter [00900, 05004], lr: 0.100000, loss: 2.1906
2022-07-13 03:52:32 - train: epoch 0010, iter [01000, 05004], lr: 0.100000, loss: 2.1976
2022-07-13 03:53:06 - train: epoch 0010, iter [01100, 05004], lr: 0.100000, loss: 2.4590
2022-07-13 03:53:39 - train: epoch 0010, iter [01200, 05004], lr: 0.100000, loss: 2.2837
2022-07-13 03:54:12 - train: epoch 0010, iter [01300, 05004], lr: 0.100000, loss: 2.2778
2022-07-13 03:54:46 - train: epoch 0010, iter [01400, 05004], lr: 0.100000, loss: 2.3750
2022-07-13 03:55:20 - train: epoch 0010, iter [01500, 05004], lr: 0.100000, loss: 2.2387
2022-07-13 03:55:53 - train: epoch 0010, iter [01600, 05004], lr: 0.100000, loss: 2.4912
2022-07-13 03:56:26 - train: epoch 0010, iter [01700, 05004], lr: 0.100000, loss: 2.6620
2022-07-13 03:57:00 - train: epoch 0010, iter [01800, 05004], lr: 0.100000, loss: 2.4091
2022-07-13 03:57:32 - train: epoch 0010, iter [01900, 05004], lr: 0.100000, loss: 2.4406
2022-07-13 03:58:06 - train: epoch 0010, iter [02000, 05004], lr: 0.100000, loss: 2.5138
2022-07-13 03:58:38 - train: epoch 0010, iter [02100, 05004], lr: 0.100000, loss: 2.3895
2022-07-13 03:59:12 - train: epoch 0010, iter [02200, 05004], lr: 0.100000, loss: 2.5782
2022-07-13 03:59:44 - train: epoch 0010, iter [02300, 05004], lr: 0.100000, loss: 2.6667
2022-07-13 04:00:18 - train: epoch 0010, iter [02400, 05004], lr: 0.100000, loss: 2.5582
2022-07-13 04:00:52 - train: epoch 0010, iter [02500, 05004], lr: 0.100000, loss: 2.3609
2022-07-13 04:01:27 - train: epoch 0010, iter [02600, 05004], lr: 0.100000, loss: 2.5552
2022-07-13 04:01:59 - train: epoch 0010, iter [02700, 05004], lr: 0.100000, loss: 2.3267
2022-07-13 04:02:32 - train: epoch 0010, iter [02800, 05004], lr: 0.100000, loss: 2.5039
2022-07-13 04:03:06 - train: epoch 0010, iter [02900, 05004], lr: 0.100000, loss: 2.5726
2022-07-13 04:03:39 - train: epoch 0010, iter [03000, 05004], lr: 0.100000, loss: 2.2970
2022-07-13 04:04:12 - train: epoch 0010, iter [03100, 05004], lr: 0.100000, loss: 2.6820
2022-07-13 04:04:46 - train: epoch 0010, iter [03200, 05004], lr: 0.100000, loss: 2.3771
2022-07-13 04:05:19 - train: epoch 0010, iter [03300, 05004], lr: 0.100000, loss: 2.6320
2022-07-13 04:05:52 - train: epoch 0010, iter [03400, 05004], lr: 0.100000, loss: 2.6249
2022-07-13 04:06:25 - train: epoch 0010, iter [03500, 05004], lr: 0.100000, loss: 2.6390
2022-07-13 04:06:59 - train: epoch 0010, iter [03600, 05004], lr: 0.100000, loss: 2.6371
2022-07-13 04:07:31 - train: epoch 0010, iter [03700, 05004], lr: 0.100000, loss: 2.2171
2022-07-13 04:08:05 - train: epoch 0010, iter [03800, 05004], lr: 0.100000, loss: 2.4982
2022-07-13 04:08:38 - train: epoch 0010, iter [03900, 05004], lr: 0.100000, loss: 2.1208
2022-07-13 04:09:12 - train: epoch 0010, iter [04000, 05004], lr: 0.100000, loss: 2.3507
2022-07-13 04:09:45 - train: epoch 0010, iter [04100, 05004], lr: 0.100000, loss: 2.2613
2022-07-13 04:10:18 - train: epoch 0010, iter [04200, 05004], lr: 0.100000, loss: 2.4980
2022-07-13 04:10:51 - train: epoch 0010, iter [04300, 05004], lr: 0.100000, loss: 2.5235
2022-07-13 04:11:25 - train: epoch 0010, iter [04400, 05004], lr: 0.100000, loss: 2.4006
2022-07-13 04:11:58 - train: epoch 0010, iter [04500, 05004], lr: 0.100000, loss: 2.2043
2022-07-13 04:12:31 - train: epoch 0010, iter [04600, 05004], lr: 0.100000, loss: 2.5046
2022-07-13 04:13:04 - train: epoch 0010, iter [04700, 05004], lr: 0.100000, loss: 2.5532
2022-07-13 04:13:38 - train: epoch 0010, iter [04800, 05004], lr: 0.100000, loss: 2.3676
2022-07-13 04:14:11 - train: epoch 0010, iter [04900, 05004], lr: 0.100000, loss: 2.2400
2022-07-13 04:14:43 - train: epoch 0010, iter [05000, 05004], lr: 0.100000, loss: 2.1428
2022-07-13 04:14:44 - train: epoch 010, train_loss: 2.4226
2022-07-13 04:15:59 - eval: epoch: 010, acc1: 50.008%, acc5: 75.686%, test_loss: 2.1661, per_image_load_time: 2.250ms, per_image_inference_time: 0.309ms
2022-07-13 04:15:59 - until epoch: 010, best_acc1: 51.258%
2022-07-13 04:15:59 - epoch 011 lr: 0.100000
2022-07-13 04:16:37 - train: epoch 0011, iter [00100, 05004], lr: 0.100000, loss: 2.2183
2022-07-13 04:17:11 - train: epoch 0011, iter [00200, 05004], lr: 0.100000, loss: 2.4488
2022-07-13 04:17:44 - train: epoch 0011, iter [00300, 05004], lr: 0.100000, loss: 2.0941
2022-07-13 04:18:17 - train: epoch 0011, iter [00400, 05004], lr: 0.100000, loss: 2.4090
2022-07-13 04:18:50 - train: epoch 0011, iter [00500, 05004], lr: 0.100000, loss: 2.3548
2022-07-13 04:19:23 - train: epoch 0011, iter [00600, 05004], lr: 0.100000, loss: 2.4572
2022-07-13 04:19:58 - train: epoch 0011, iter [00700, 05004], lr: 0.100000, loss: 2.4882
2022-07-13 04:20:30 - train: epoch 0011, iter [00800, 05004], lr: 0.100000, loss: 2.4085
2022-07-13 04:21:04 - train: epoch 0011, iter [00900, 05004], lr: 0.100000, loss: 2.4944
2022-07-13 04:21:37 - train: epoch 0011, iter [01000, 05004], lr: 0.100000, loss: 2.4024
2022-07-13 04:22:09 - train: epoch 0011, iter [01100, 05004], lr: 0.100000, loss: 2.3641
2022-07-13 04:22:43 - train: epoch 0011, iter [01200, 05004], lr: 0.100000, loss: 2.6743
2022-07-13 04:23:16 - train: epoch 0011, iter [01300, 05004], lr: 0.100000, loss: 2.6023
2022-07-13 04:23:50 - train: epoch 0011, iter [01400, 05004], lr: 0.100000, loss: 2.4565
2022-07-13 04:24:23 - train: epoch 0011, iter [01500, 05004], lr: 0.100000, loss: 2.2405
2022-07-13 04:24:55 - train: epoch 0011, iter [01600, 05004], lr: 0.100000, loss: 2.4221
2022-07-13 04:25:30 - train: epoch 0011, iter [01700, 05004], lr: 0.100000, loss: 2.5509
2022-07-13 04:26:02 - train: epoch 0011, iter [01800, 05004], lr: 0.100000, loss: 2.2714
2022-07-13 04:26:36 - train: epoch 0011, iter [01900, 05004], lr: 0.100000, loss: 2.2336
2022-07-13 04:27:10 - train: epoch 0011, iter [02000, 05004], lr: 0.100000, loss: 2.4701
2022-07-13 04:27:42 - train: epoch 0011, iter [02100, 05004], lr: 0.100000, loss: 2.4562
2022-07-13 04:28:16 - train: epoch 0011, iter [02200, 05004], lr: 0.100000, loss: 2.2714
2022-07-13 04:28:49 - train: epoch 0011, iter [02300, 05004], lr: 0.100000, loss: 2.5852
2022-07-13 04:29:22 - train: epoch 0011, iter [02400, 05004], lr: 0.100000, loss: 2.2413
2022-07-13 04:29:55 - train: epoch 0011, iter [02500, 05004], lr: 0.100000, loss: 2.6851
2022-07-13 04:30:29 - train: epoch 0011, iter [02600, 05004], lr: 0.100000, loss: 2.4709
2022-07-13 04:31:03 - train: epoch 0011, iter [02700, 05004], lr: 0.100000, loss: 2.5320
2022-07-13 04:31:36 - train: epoch 0011, iter [02800, 05004], lr: 0.100000, loss: 1.9513
2022-07-13 04:32:09 - train: epoch 0011, iter [02900, 05004], lr: 0.100000, loss: 2.4605
2022-07-13 04:32:43 - train: epoch 0011, iter [03000, 05004], lr: 0.100000, loss: 2.6292
2022-07-13 04:33:15 - train: epoch 0011, iter [03100, 05004], lr: 0.100000, loss: 2.5134
2022-07-13 04:33:49 - train: epoch 0011, iter [03200, 05004], lr: 0.100000, loss: 2.2624
2022-07-13 04:34:22 - train: epoch 0011, iter [03300, 05004], lr: 0.100000, loss: 2.3939
2022-07-13 04:34:56 - train: epoch 0011, iter [03400, 05004], lr: 0.100000, loss: 2.3352
2022-07-13 04:35:29 - train: epoch 0011, iter [03500, 05004], lr: 0.100000, loss: 2.4146
2022-07-13 04:36:02 - train: epoch 0011, iter [03600, 05004], lr: 0.100000, loss: 2.4934
2022-07-13 04:36:35 - train: epoch 0011, iter [03700, 05004], lr: 0.100000, loss: 2.4877
2022-07-13 04:37:08 - train: epoch 0011, iter [03800, 05004], lr: 0.100000, loss: 2.1318
2022-07-13 04:37:41 - train: epoch 0011, iter [03900, 05004], lr: 0.100000, loss: 2.4809
2022-07-13 04:38:15 - train: epoch 0011, iter [04000, 05004], lr: 0.100000, loss: 2.3166
2022-07-13 04:38:48 - train: epoch 0011, iter [04100, 05004], lr: 0.100000, loss: 2.1576
2022-07-13 04:39:21 - train: epoch 0011, iter [04200, 05004], lr: 0.100000, loss: 2.3474
2022-07-13 04:39:55 - train: epoch 0011, iter [04300, 05004], lr: 0.100000, loss: 2.4589
2022-07-13 04:40:28 - train: epoch 0011, iter [04400, 05004], lr: 0.100000, loss: 2.3327
2022-07-13 04:41:01 - train: epoch 0011, iter [04500, 05004], lr: 0.100000, loss: 2.2048
2022-07-13 04:41:35 - train: epoch 0011, iter [04600, 05004], lr: 0.100000, loss: 2.2869
2022-07-13 04:42:09 - train: epoch 0011, iter [04700, 05004], lr: 0.100000, loss: 2.1879
2022-07-13 04:42:42 - train: epoch 0011, iter [04800, 05004], lr: 0.100000, loss: 2.2756
2022-07-13 04:43:15 - train: epoch 0011, iter [04900, 05004], lr: 0.100000, loss: 2.1451
2022-07-13 04:43:47 - train: epoch 0011, iter [05000, 05004], lr: 0.100000, loss: 2.4227
2022-07-13 04:43:48 - train: epoch 011, train_loss: 2.3966
2022-07-13 04:45:02 - eval: epoch: 011, acc1: 51.248%, acc5: 77.022%, test_loss: 2.1009, per_image_load_time: 2.467ms, per_image_inference_time: 0.302ms
2022-07-13 04:45:03 - until epoch: 011, best_acc1: 51.258%
2022-07-13 04:45:03 - epoch 012 lr: 0.100000
2022-07-13 04:45:41 - train: epoch 0012, iter [00100, 05004], lr: 0.100000, loss: 2.2394
2022-07-13 04:46:14 - train: epoch 0012, iter [00200, 05004], lr: 0.100000, loss: 2.2939
2022-07-13 04:46:48 - train: epoch 0012, iter [00300, 05004], lr: 0.100000, loss: 2.3737
2022-07-13 04:47:22 - train: epoch 0012, iter [00400, 05004], lr: 0.100000, loss: 2.4480
2022-07-13 04:47:54 - train: epoch 0012, iter [00500, 05004], lr: 0.100000, loss: 2.5747
2022-07-13 04:48:28 - train: epoch 0012, iter [00600, 05004], lr: 0.100000, loss: 2.0843
2022-07-13 04:49:02 - train: epoch 0012, iter [00700, 05004], lr: 0.100000, loss: 2.1076
2022-07-13 04:49:35 - train: epoch 0012, iter [00800, 05004], lr: 0.100000, loss: 2.3517
2022-07-13 04:50:09 - train: epoch 0012, iter [00900, 05004], lr: 0.100000, loss: 2.5106
2022-07-13 04:50:42 - train: epoch 0012, iter [01000, 05004], lr: 0.100000, loss: 2.2002
2022-07-13 04:51:15 - train: epoch 0012, iter [01100, 05004], lr: 0.100000, loss: 2.6787
2022-07-13 04:51:48 - train: epoch 0012, iter [01200, 05004], lr: 0.100000, loss: 2.3109
2022-07-13 04:52:22 - train: epoch 0012, iter [01300, 05004], lr: 0.100000, loss: 2.3093
2022-07-13 04:52:54 - train: epoch 0012, iter [01400, 05004], lr: 0.100000, loss: 2.4842
2022-07-13 04:53:28 - train: epoch 0012, iter [01500, 05004], lr: 0.100000, loss: 2.2899
2022-07-13 04:54:01 - train: epoch 0012, iter [01600, 05004], lr: 0.100000, loss: 2.3119
2022-07-13 04:54:35 - train: epoch 0012, iter [01700, 05004], lr: 0.100000, loss: 2.2460
2022-07-13 04:55:07 - train: epoch 0012, iter [01800, 05004], lr: 0.100000, loss: 2.3782
2022-07-13 04:55:42 - train: epoch 0012, iter [01900, 05004], lr: 0.100000, loss: 2.3748
2022-07-13 04:56:15 - train: epoch 0012, iter [02000, 05004], lr: 0.100000, loss: 2.5215
2022-07-13 04:56:49 - train: epoch 0012, iter [02100, 05004], lr: 0.100000, loss: 2.2444
2022-07-13 04:57:21 - train: epoch 0012, iter [02200, 05004], lr: 0.100000, loss: 2.6230
2022-07-13 04:57:55 - train: epoch 0012, iter [02300, 05004], lr: 0.100000, loss: 2.4156
2022-07-13 04:58:28 - train: epoch 0012, iter [02400, 05004], lr: 0.100000, loss: 2.4106
2022-07-13 04:59:02 - train: epoch 0012, iter [02500, 05004], lr: 0.100000, loss: 2.2418
2022-07-13 04:59:35 - train: epoch 0012, iter [02600, 05004], lr: 0.100000, loss: 2.2452
2022-07-13 05:00:09 - train: epoch 0012, iter [02700, 05004], lr: 0.100000, loss: 2.3222
2022-07-13 05:00:42 - train: epoch 0012, iter [02800, 05004], lr: 0.100000, loss: 2.3902
2022-07-13 05:01:16 - train: epoch 0012, iter [02900, 05004], lr: 0.100000, loss: 2.2066
2022-07-13 05:01:49 - train: epoch 0012, iter [03000, 05004], lr: 0.100000, loss: 2.4233
2022-07-13 05:02:22 - train: epoch 0012, iter [03100, 05004], lr: 0.100000, loss: 2.5890
2022-07-13 05:02:56 - train: epoch 0012, iter [03200, 05004], lr: 0.100000, loss: 2.0197
2022-07-13 05:03:29 - train: epoch 0012, iter [03300, 05004], lr: 0.100000, loss: 2.3990
2022-07-13 05:04:02 - train: epoch 0012, iter [03400, 05004], lr: 0.100000, loss: 2.3638
2022-07-13 05:04:36 - train: epoch 0012, iter [03500, 05004], lr: 0.100000, loss: 2.5645
2022-07-13 05:05:09 - train: epoch 0012, iter [03600, 05004], lr: 0.100000, loss: 2.4421
2022-07-13 05:05:42 - train: epoch 0012, iter [03700, 05004], lr: 0.100000, loss: 2.2668
2022-07-13 05:06:15 - train: epoch 0012, iter [03800, 05004], lr: 0.100000, loss: 2.3974
2022-07-13 05:06:49 - train: epoch 0012, iter [03900, 05004], lr: 0.100000, loss: 2.3587
2022-07-13 05:07:22 - train: epoch 0012, iter [04000, 05004], lr: 0.100000, loss: 2.2869
2022-07-13 05:07:56 - train: epoch 0012, iter [04100, 05004], lr: 0.100000, loss: 2.2315
2022-07-13 05:08:30 - train: epoch 0012, iter [04200, 05004], lr: 0.100000, loss: 2.2125
2022-07-13 05:09:04 - train: epoch 0012, iter [04300, 05004], lr: 0.100000, loss: 2.4908
2022-07-13 05:09:37 - train: epoch 0012, iter [04400, 05004], lr: 0.100000, loss: 2.2604
2022-07-13 05:10:11 - train: epoch 0012, iter [04500, 05004], lr: 0.100000, loss: 2.3031
2022-07-13 05:10:44 - train: epoch 0012, iter [04600, 05004], lr: 0.100000, loss: 2.6489
2022-07-13 05:11:17 - train: epoch 0012, iter [04700, 05004], lr: 0.100000, loss: 2.3791
2022-07-13 05:11:51 - train: epoch 0012, iter [04800, 05004], lr: 0.100000, loss: 2.4423
2022-07-13 05:12:25 - train: epoch 0012, iter [04900, 05004], lr: 0.100000, loss: 2.3856
2022-07-13 05:12:56 - train: epoch 0012, iter [05000, 05004], lr: 0.100000, loss: 2.1107
2022-07-13 05:12:57 - train: epoch 012, train_loss: 2.3755
2022-07-13 05:14:12 - eval: epoch: 012, acc1: 52.640%, acc5: 78.098%, test_loss: 2.0299, per_image_load_time: 1.545ms, per_image_inference_time: 0.301ms
2022-07-13 05:14:13 - until epoch: 012, best_acc1: 52.640%
2022-07-13 05:14:13 - epoch 013 lr: 0.100000
2022-07-13 05:14:51 - train: epoch 0013, iter [00100, 05004], lr: 0.100000, loss: 2.1539
2022-07-13 05:15:25 - train: epoch 0013, iter [00200, 05004], lr: 0.100000, loss: 2.4440
2022-07-13 05:15:59 - train: epoch 0013, iter [00300, 05004], lr: 0.100000, loss: 2.3606
2022-07-13 05:16:31 - train: epoch 0013, iter [00400, 05004], lr: 0.100000, loss: 2.2451
2022-07-13 05:17:05 - train: epoch 0013, iter [00500, 05004], lr: 0.100000, loss: 2.3387
2022-07-13 05:17:38 - train: epoch 0013, iter [00600, 05004], lr: 0.100000, loss: 2.4517
2022-07-13 05:18:12 - train: epoch 0013, iter [00700, 05004], lr: 0.100000, loss: 2.2443
2022-07-13 05:18:44 - train: epoch 0013, iter [00800, 05004], lr: 0.100000, loss: 2.3532
2022-07-13 05:19:17 - train: epoch 0013, iter [00900, 05004], lr: 0.100000, loss: 2.3438
2022-07-13 05:19:51 - train: epoch 0013, iter [01000, 05004], lr: 0.100000, loss: 2.4854
2022-07-13 05:20:24 - train: epoch 0013, iter [01100, 05004], lr: 0.100000, loss: 2.4016
2022-07-13 05:20:58 - train: epoch 0013, iter [01200, 05004], lr: 0.100000, loss: 2.5096
2022-07-13 05:21:30 - train: epoch 0013, iter [01300, 05004], lr: 0.100000, loss: 2.3832
2022-07-13 05:22:04 - train: epoch 0013, iter [01400, 05004], lr: 0.100000, loss: 2.1973
2022-07-13 05:22:37 - train: epoch 0013, iter [01500, 05004], lr: 0.100000, loss: 2.5477
2022-07-13 05:23:10 - train: epoch 0013, iter [01600, 05004], lr: 0.100000, loss: 2.0621
2022-07-13 05:23:43 - train: epoch 0013, iter [01700, 05004], lr: 0.100000, loss: 2.3884
2022-07-13 05:24:17 - train: epoch 0013, iter [01800, 05004], lr: 0.100000, loss: 2.3279
2022-07-13 05:24:51 - train: epoch 0013, iter [01900, 05004], lr: 0.100000, loss: 2.4262
2022-07-13 05:25:24 - train: epoch 0013, iter [02000, 05004], lr: 0.100000, loss: 2.6706
2022-07-13 05:25:57 - train: epoch 0013, iter [02100, 05004], lr: 0.100000, loss: 2.6959
2022-07-13 05:26:30 - train: epoch 0013, iter [02200, 05004], lr: 0.100000, loss: 2.2993
2022-07-13 05:27:03 - train: epoch 0013, iter [02300, 05004], lr: 0.100000, loss: 2.4248
2022-07-13 05:27:37 - train: epoch 0013, iter [02400, 05004], lr: 0.100000, loss: 2.3118
2022-07-13 05:28:10 - train: epoch 0013, iter [02500, 05004], lr: 0.100000, loss: 2.2254
2022-07-13 05:28:44 - train: epoch 0013, iter [02600, 05004], lr: 0.100000, loss: 2.2349
2022-07-13 05:29:18 - train: epoch 0013, iter [02700, 05004], lr: 0.100000, loss: 2.2558
2022-07-13 05:29:51 - train: epoch 0013, iter [02800, 05004], lr: 0.100000, loss: 2.2938
2022-07-13 05:30:24 - train: epoch 0013, iter [02900, 05004], lr: 0.100000, loss: 2.4704
2022-07-13 05:30:58 - train: epoch 0013, iter [03000, 05004], lr: 0.100000, loss: 2.2614
2022-07-13 05:31:31 - train: epoch 0013, iter [03100, 05004], lr: 0.100000, loss: 2.2335
2022-07-13 05:32:05 - train: epoch 0013, iter [03200, 05004], lr: 0.100000, loss: 2.4535
2022-07-13 05:32:39 - train: epoch 0013, iter [03300, 05004], lr: 0.100000, loss: 2.1196
2022-07-13 05:33:11 - train: epoch 0013, iter [03400, 05004], lr: 0.100000, loss: 2.3249
2022-07-13 05:33:46 - train: epoch 0013, iter [03500, 05004], lr: 0.100000, loss: 2.2327
2022-07-13 05:34:19 - train: epoch 0013, iter [03600, 05004], lr: 0.100000, loss: 2.6154
2022-07-13 05:34:53 - train: epoch 0013, iter [03700, 05004], lr: 0.100000, loss: 2.2133
2022-07-13 05:35:26 - train: epoch 0013, iter [03800, 05004], lr: 0.100000, loss: 2.5923
2022-07-13 05:35:59 - train: epoch 0013, iter [03900, 05004], lr: 0.100000, loss: 2.4532
2022-07-13 05:36:33 - train: epoch 0013, iter [04000, 05004], lr: 0.100000, loss: 2.3820
2022-07-13 05:37:06 - train: epoch 0013, iter [04100, 05004], lr: 0.100000, loss: 2.3914
2022-07-13 05:37:40 - train: epoch 0013, iter [04200, 05004], lr: 0.100000, loss: 2.3025
2022-07-13 05:38:14 - train: epoch 0013, iter [04300, 05004], lr: 0.100000, loss: 2.4037
2022-07-13 05:38:47 - train: epoch 0013, iter [04400, 05004], lr: 0.100000, loss: 2.2438
2022-07-13 05:39:21 - train: epoch 0013, iter [04500, 05004], lr: 0.100000, loss: 2.3783
2022-07-13 05:39:54 - train: epoch 0013, iter [04600, 05004], lr: 0.100000, loss: 2.3660
2022-07-13 05:40:28 - train: epoch 0013, iter [04700, 05004], lr: 0.100000, loss: 2.5211
2022-07-13 05:41:02 - train: epoch 0013, iter [04800, 05004], lr: 0.100000, loss: 2.4741
2022-07-13 05:41:35 - train: epoch 0013, iter [04900, 05004], lr: 0.100000, loss: 2.3946
2022-07-13 05:42:07 - train: epoch 0013, iter [05000, 05004], lr: 0.100000, loss: 2.5512
2022-07-13 05:42:08 - train: epoch 013, train_loss: 2.3593
2022-07-13 05:43:24 - eval: epoch: 013, acc1: 52.618%, acc5: 77.950%, test_loss: 2.0443, per_image_load_time: 2.035ms, per_image_inference_time: 0.306ms
2022-07-13 05:43:24 - until epoch: 013, best_acc1: 52.640%
2022-07-13 05:43:24 - epoch 014 lr: 0.100000
2022-07-13 05:44:02 - train: epoch 0014, iter [00100, 05004], lr: 0.100000, loss: 2.3398
2022-07-13 05:44:37 - train: epoch 0014, iter [00200, 05004], lr: 0.100000, loss: 2.3442
2022-07-13 05:45:09 - train: epoch 0014, iter [00300, 05004], lr: 0.100000, loss: 2.0399
2022-07-13 05:45:43 - train: epoch 0014, iter [00400, 05004], lr: 0.100000, loss: 2.2156
2022-07-13 05:46:17 - train: epoch 0014, iter [00500, 05004], lr: 0.100000, loss: 2.2552
2022-07-13 05:46:50 - train: epoch 0014, iter [00600, 05004], lr: 0.100000, loss: 2.4235
2022-07-13 05:47:23 - train: epoch 0014, iter [00700, 05004], lr: 0.100000, loss: 2.2516
2022-07-13 05:47:58 - train: epoch 0014, iter [00800, 05004], lr: 0.100000, loss: 2.4265
2022-07-13 05:48:30 - train: epoch 0014, iter [00900, 05004], lr: 0.100000, loss: 2.2725
2022-07-13 05:49:04 - train: epoch 0014, iter [01000, 05004], lr: 0.100000, loss: 2.4560
2022-07-13 05:49:37 - train: epoch 0014, iter [01100, 05004], lr: 0.100000, loss: 2.2154
2022-07-13 05:50:11 - train: epoch 0014, iter [01200, 05004], lr: 0.100000, loss: 2.4012
2022-07-13 05:50:44 - train: epoch 0014, iter [01300, 05004], lr: 0.100000, loss: 2.3318
2022-07-13 05:51:17 - train: epoch 0014, iter [01400, 05004], lr: 0.100000, loss: 2.3468
2022-07-13 05:51:51 - train: epoch 0014, iter [01500, 05004], lr: 0.100000, loss: 2.5697
2022-07-13 05:52:24 - train: epoch 0014, iter [01600, 05004], lr: 0.100000, loss: 2.2879
2022-07-13 05:52:58 - train: epoch 0014, iter [01700, 05004], lr: 0.100000, loss: 2.5563
2022-07-13 05:53:32 - train: epoch 0014, iter [01800, 05004], lr: 0.100000, loss: 2.5333
2022-07-13 05:54:04 - train: epoch 0014, iter [01900, 05004], lr: 0.100000, loss: 2.1899
2022-07-13 05:54:38 - train: epoch 0014, iter [02000, 05004], lr: 0.100000, loss: 2.2373
2022-07-13 05:55:11 - train: epoch 0014, iter [02100, 05004], lr: 0.100000, loss: 2.5141
2022-07-13 05:55:45 - train: epoch 0014, iter [02200, 05004], lr: 0.100000, loss: 2.3497
2022-07-13 05:56:18 - train: epoch 0014, iter [02300, 05004], lr: 0.100000, loss: 2.2982
2022-07-13 05:56:51 - train: epoch 0014, iter [02400, 05004], lr: 0.100000, loss: 2.5328
2022-07-13 05:57:25 - train: epoch 0014, iter [02500, 05004], lr: 0.100000, loss: 2.3338
2022-07-13 05:57:58 - train: epoch 0014, iter [02600, 05004], lr: 0.100000, loss: 2.3277
2022-07-13 05:58:32 - train: epoch 0014, iter [02700, 05004], lr: 0.100000, loss: 2.3181
2022-07-13 05:59:05 - train: epoch 0014, iter [02800, 05004], lr: 0.100000, loss: 2.5934
2022-07-13 05:59:39 - train: epoch 0014, iter [02900, 05004], lr: 0.100000, loss: 2.2131
2022-07-13 06:00:12 - train: epoch 0014, iter [03000, 05004], lr: 0.100000, loss: 2.4040
2022-07-13 06:00:46 - train: epoch 0014, iter [03100, 05004], lr: 0.100000, loss: 2.0775
2022-07-13 06:01:19 - train: epoch 0014, iter [03200, 05004], lr: 0.100000, loss: 2.3586
2022-07-13 06:01:53 - train: epoch 0014, iter [03300, 05004], lr: 0.100000, loss: 2.1486
2022-07-13 06:02:26 - train: epoch 0014, iter [03400, 05004], lr: 0.100000, loss: 2.2780
2022-07-13 06:03:00 - train: epoch 0014, iter [03500, 05004], lr: 0.100000, loss: 2.2141
2022-07-13 06:03:33 - train: epoch 0014, iter [03600, 05004], lr: 0.100000, loss: 2.2089
2022-07-13 06:04:07 - train: epoch 0014, iter [03700, 05004], lr: 0.100000, loss: 2.2818
2022-07-13 06:04:39 - train: epoch 0014, iter [03800, 05004], lr: 0.100000, loss: 2.4962
2022-07-13 06:05:14 - train: epoch 0014, iter [03900, 05004], lr: 0.100000, loss: 2.2071
2022-07-13 06:05:47 - train: epoch 0014, iter [04000, 05004], lr: 0.100000, loss: 2.5216
2022-07-13 06:06:22 - train: epoch 0014, iter [04100, 05004], lr: 0.100000, loss: 2.3348
2022-07-13 06:06:55 - train: epoch 0014, iter [04200, 05004], lr: 0.100000, loss: 2.1828
2022-07-13 06:07:30 - train: epoch 0014, iter [04300, 05004], lr: 0.100000, loss: 2.2689
2022-07-13 06:08:02 - train: epoch 0014, iter [04400, 05004], lr: 0.100000, loss: 2.2301
2022-07-13 06:08:37 - train: epoch 0014, iter [04500, 05004], lr: 0.100000, loss: 2.4223
2022-07-13 06:09:10 - train: epoch 0014, iter [04600, 05004], lr: 0.100000, loss: 2.2537
2022-07-13 06:09:44 - train: epoch 0014, iter [04700, 05004], lr: 0.100000, loss: 2.1836
2022-07-13 06:10:17 - train: epoch 0014, iter [04800, 05004], lr: 0.100000, loss: 2.4038
2022-07-13 06:10:50 - train: epoch 0014, iter [04900, 05004], lr: 0.100000, loss: 2.0961
2022-07-13 06:11:22 - train: epoch 0014, iter [05000, 05004], lr: 0.100000, loss: 2.3451
2022-07-13 06:11:23 - train: epoch 014, train_loss: 2.3426
2022-07-13 06:12:37 - eval: epoch: 014, acc1: 51.258%, acc5: 77.050%, test_loss: 2.1036, per_image_load_time: 2.348ms, per_image_inference_time: 0.306ms
2022-07-13 06:12:37 - until epoch: 014, best_acc1: 52.640%
2022-07-13 06:12:37 - epoch 015 lr: 0.100000
2022-07-13 06:13:16 - train: epoch 0015, iter [00100, 05004], lr: 0.100000, loss: 2.0379
2022-07-13 06:13:50 - train: epoch 0015, iter [00200, 05004], lr: 0.100000, loss: 2.5321
2022-07-13 06:14:22 - train: epoch 0015, iter [00300, 05004], lr: 0.100000, loss: 2.5742
2022-07-13 06:14:56 - train: epoch 0015, iter [00400, 05004], lr: 0.100000, loss: 2.3433
2022-07-13 06:15:29 - train: epoch 0015, iter [00500, 05004], lr: 0.100000, loss: 2.2537
2022-07-13 06:16:02 - train: epoch 0015, iter [00600, 05004], lr: 0.100000, loss: 2.5181
2022-07-13 06:16:35 - train: epoch 0015, iter [00700, 05004], lr: 0.100000, loss: 2.2841
2022-07-13 06:17:09 - train: epoch 0015, iter [00800, 05004], lr: 0.100000, loss: 2.0099
2022-07-13 06:17:42 - train: epoch 0015, iter [00900, 05004], lr: 0.100000, loss: 2.2235
2022-07-13 06:18:15 - train: epoch 0015, iter [01000, 05004], lr: 0.100000, loss: 2.4949
2022-07-13 06:18:48 - train: epoch 0015, iter [01100, 05004], lr: 0.100000, loss: 2.2617
2022-07-13 06:19:22 - train: epoch 0015, iter [01200, 05004], lr: 0.100000, loss: 2.2769
2022-07-13 06:19:55 - train: epoch 0015, iter [01300, 05004], lr: 0.100000, loss: 2.6093
2022-07-13 06:20:29 - train: epoch 0015, iter [01400, 05004], lr: 0.100000, loss: 2.2242
2022-07-13 06:21:02 - train: epoch 0015, iter [01500, 05004], lr: 0.100000, loss: 2.1072
2022-07-13 06:21:36 - train: epoch 0015, iter [01600, 05004], lr: 0.100000, loss: 2.2754
2022-07-13 06:22:09 - train: epoch 0015, iter [01700, 05004], lr: 0.100000, loss: 2.5626
2022-07-13 06:22:42 - train: epoch 0015, iter [01800, 05004], lr: 0.100000, loss: 2.2224
2022-07-13 06:23:16 - train: epoch 0015, iter [01900, 05004], lr: 0.100000, loss: 2.2054
2022-07-13 06:23:49 - train: epoch 0015, iter [02000, 05004], lr: 0.100000, loss: 2.3268
2022-07-13 06:24:22 - train: epoch 0015, iter [02100, 05004], lr: 0.100000, loss: 2.1807
2022-07-13 06:24:56 - train: epoch 0015, iter [02200, 05004], lr: 0.100000, loss: 2.6046
2022-07-13 06:25:30 - train: epoch 0015, iter [02300, 05004], lr: 0.100000, loss: 2.1921
2022-07-13 06:26:03 - train: epoch 0015, iter [02400, 05004], lr: 0.100000, loss: 2.2908
2022-07-13 06:26:36 - train: epoch 0015, iter [02500, 05004], lr: 0.100000, loss: 2.4142
2022-07-13 06:27:10 - train: epoch 0015, iter [02600, 05004], lr: 0.100000, loss: 2.1278
2022-07-13 06:27:43 - train: epoch 0015, iter [02700, 05004], lr: 0.100000, loss: 2.4142
2022-07-13 06:28:17 - train: epoch 0015, iter [02800, 05004], lr: 0.100000, loss: 2.3548
2022-07-13 06:28:49 - train: epoch 0015, iter [02900, 05004], lr: 0.100000, loss: 2.2395
2022-07-13 06:29:23 - train: epoch 0015, iter [03000, 05004], lr: 0.100000, loss: 2.1537
2022-07-13 06:29:57 - train: epoch 0015, iter [03100, 05004], lr: 0.100000, loss: 2.2417
2022-07-13 06:30:30 - train: epoch 0015, iter [03200, 05004], lr: 0.100000, loss: 2.2828
2022-07-13 06:31:03 - train: epoch 0015, iter [03300, 05004], lr: 0.100000, loss: 2.1617
2022-07-13 06:31:38 - train: epoch 0015, iter [03400, 05004], lr: 0.100000, loss: 2.3072
2022-07-13 06:32:10 - train: epoch 0015, iter [03500, 05004], lr: 0.100000, loss: 2.4899
2022-07-13 06:32:44 - train: epoch 0015, iter [03600, 05004], lr: 0.100000, loss: 2.3706
2022-07-13 06:33:17 - train: epoch 0015, iter [03700, 05004], lr: 0.100000, loss: 2.3226
2022-07-13 06:33:51 - train: epoch 0015, iter [03800, 05004], lr: 0.100000, loss: 2.2972
2022-07-13 06:34:25 - train: epoch 0015, iter [03900, 05004], lr: 0.100000, loss: 2.5000
2022-07-13 06:34:58 - train: epoch 0015, iter [04000, 05004], lr: 0.100000, loss: 2.3884
2022-07-13 06:35:32 - train: epoch 0015, iter [04100, 05004], lr: 0.100000, loss: 2.6743
2022-07-13 06:36:05 - train: epoch 0015, iter [04200, 05004], lr: 0.100000, loss: 2.0581
2022-07-13 06:36:38 - train: epoch 0015, iter [04300, 05004], lr: 0.100000, loss: 2.4153
2022-07-13 06:37:11 - train: epoch 0015, iter [04400, 05004], lr: 0.100000, loss: 2.3631
2022-07-13 06:37:45 - train: epoch 0015, iter [04500, 05004], lr: 0.100000, loss: 2.3221
2022-07-13 06:38:19 - train: epoch 0015, iter [04600, 05004], lr: 0.100000, loss: 2.2024
2022-07-13 06:38:52 - train: epoch 0015, iter [04700, 05004], lr: 0.100000, loss: 2.4261
2022-07-13 06:39:26 - train: epoch 0015, iter [04800, 05004], lr: 0.100000, loss: 2.4078
2022-07-13 06:39:59 - train: epoch 0015, iter [04900, 05004], lr: 0.100000, loss: 2.3916
2022-07-13 06:40:31 - train: epoch 0015, iter [05000, 05004], lr: 0.100000, loss: 2.3595
2022-07-13 06:40:32 - train: epoch 015, train_loss: 2.3313
2022-07-13 06:41:46 - eval: epoch: 015, acc1: 53.150%, acc5: 78.270%, test_loss: 2.0139, per_image_load_time: 2.245ms, per_image_inference_time: 0.298ms
2022-07-13 06:41:47 - until epoch: 015, best_acc1: 53.150%
2022-07-13 06:41:47 - epoch 016 lr: 0.100000
2022-07-13 06:42:25 - train: epoch 0016, iter [00100, 05004], lr: 0.100000, loss: 2.3597
2022-07-13 06:42:58 - train: epoch 0016, iter [00200, 05004], lr: 0.100000, loss: 2.1679
2022-07-13 06:43:32 - train: epoch 0016, iter [00300, 05004], lr: 0.100000, loss: 2.3154
2022-07-13 06:44:05 - train: epoch 0016, iter [00400, 05004], lr: 0.100000, loss: 2.5471
2022-07-13 06:44:38 - train: epoch 0016, iter [00500, 05004], lr: 0.100000, loss: 2.0231
2022-07-13 06:45:12 - train: epoch 0016, iter [00600, 05004], lr: 0.100000, loss: 2.3641
2022-07-13 06:45:45 - train: epoch 0016, iter [00700, 05004], lr: 0.100000, loss: 2.0656
2022-07-13 06:46:19 - train: epoch 0016, iter [00800, 05004], lr: 0.100000, loss: 2.3266
2022-07-13 06:46:51 - train: epoch 0016, iter [00900, 05004], lr: 0.100000, loss: 2.4132
2022-07-13 06:47:24 - train: epoch 0016, iter [01000, 05004], lr: 0.100000, loss: 2.2009
2022-07-13 06:47:57 - train: epoch 0016, iter [01100, 05004], lr: 0.100000, loss: 2.1680
2022-07-13 06:48:31 - train: epoch 0016, iter [01200, 05004], lr: 0.100000, loss: 2.1766
2022-07-13 06:49:05 - train: epoch 0016, iter [01300, 05004], lr: 0.100000, loss: 2.5186
2022-07-13 06:49:38 - train: epoch 0016, iter [01400, 05004], lr: 0.100000, loss: 2.2338
2022-07-13 06:50:12 - train: epoch 0016, iter [01500, 05004], lr: 0.100000, loss: 2.4292
2022-07-13 06:50:45 - train: epoch 0016, iter [01600, 05004], lr: 0.100000, loss: 2.4793
2022-07-13 06:51:18 - train: epoch 0016, iter [01700, 05004], lr: 0.100000, loss: 2.2140
2022-07-13 06:51:51 - train: epoch 0016, iter [01800, 05004], lr: 0.100000, loss: 2.2208
2022-07-13 06:52:24 - train: epoch 0016, iter [01900, 05004], lr: 0.100000, loss: 2.3333
2022-07-13 06:52:58 - train: epoch 0016, iter [02000, 05004], lr: 0.100000, loss: 2.0138
2022-07-13 06:53:31 - train: epoch 0016, iter [02100, 05004], lr: 0.100000, loss: 2.4883
2022-07-13 06:54:05 - train: epoch 0016, iter [02200, 05004], lr: 0.100000, loss: 2.2035
2022-07-13 06:54:38 - train: epoch 0016, iter [02300, 05004], lr: 0.100000, loss: 2.5201
2022-07-13 06:55:11 - train: epoch 0016, iter [02400, 05004], lr: 0.100000, loss: 2.4432
2022-07-13 06:55:44 - train: epoch 0016, iter [02500, 05004], lr: 0.100000, loss: 2.2889
2022-07-13 06:56:17 - train: epoch 0016, iter [02600, 05004], lr: 0.100000, loss: 2.5003
2022-07-13 06:56:51 - train: epoch 0016, iter [02700, 05004], lr: 0.100000, loss: 2.2778
2022-07-13 06:57:24 - train: epoch 0016, iter [02800, 05004], lr: 0.100000, loss: 2.1885
2022-07-13 06:57:58 - train: epoch 0016, iter [02900, 05004], lr: 0.100000, loss: 2.3804
2022-07-13 06:58:31 - train: epoch 0016, iter [03000, 05004], lr: 0.100000, loss: 2.6222
2022-07-13 06:59:05 - train: epoch 0016, iter [03100, 05004], lr: 0.100000, loss: 2.5100
2022-07-13 06:59:38 - train: epoch 0016, iter [03200, 05004], lr: 0.100000, loss: 2.4762
2022-07-13 07:00:12 - train: epoch 0016, iter [03300, 05004], lr: 0.100000, loss: 2.4351
2022-07-13 07:00:45 - train: epoch 0016, iter [03400, 05004], lr: 0.100000, loss: 2.3268
2022-07-13 07:01:19 - train: epoch 0016, iter [03500, 05004], lr: 0.100000, loss: 2.3062
2022-07-13 07:01:53 - train: epoch 0016, iter [03600, 05004], lr: 0.100000, loss: 2.2501
2022-07-13 07:02:27 - train: epoch 0016, iter [03700, 05004], lr: 0.100000, loss: 2.3524
2022-07-13 07:03:00 - train: epoch 0016, iter [03800, 05004], lr: 0.100000, loss: 2.6216
2022-07-13 07:03:34 - train: epoch 0016, iter [03900, 05004], lr: 0.100000, loss: 2.3263
2022-07-13 07:04:07 - train: epoch 0016, iter [04000, 05004], lr: 0.100000, loss: 2.4684
2022-07-13 07:04:40 - train: epoch 0016, iter [04100, 05004], lr: 0.100000, loss: 2.1901
2022-07-13 07:05:14 - train: epoch 0016, iter [04200, 05004], lr: 0.100000, loss: 2.3897
2022-07-13 07:05:48 - train: epoch 0016, iter [04300, 05004], lr: 0.100000, loss: 2.1776
2022-07-13 07:06:21 - train: epoch 0016, iter [04400, 05004], lr: 0.100000, loss: 2.3019
2022-07-13 07:06:54 - train: epoch 0016, iter [04500, 05004], lr: 0.100000, loss: 2.4145
2022-07-13 07:07:27 - train: epoch 0016, iter [04600, 05004], lr: 0.100000, loss: 2.2680
2022-07-13 07:08:02 - train: epoch 0016, iter [04700, 05004], lr: 0.100000, loss: 2.5698
2022-07-13 07:08:35 - train: epoch 0016, iter [04800, 05004], lr: 0.100000, loss: 2.3298
2022-07-13 07:09:09 - train: epoch 0016, iter [04900, 05004], lr: 0.100000, loss: 2.3372
2022-07-13 07:09:41 - train: epoch 0016, iter [05000, 05004], lr: 0.100000, loss: 2.3286
2022-07-13 07:09:41 - train: epoch 016, train_loss: 2.3178
2022-07-13 07:10:57 - eval: epoch: 016, acc1: 51.780%, acc5: 77.752%, test_loss: 2.0602, per_image_load_time: 2.570ms, per_image_inference_time: 0.291ms
2022-07-13 07:10:57 - until epoch: 016, best_acc1: 53.150%
2022-07-13 07:10:57 - epoch 017 lr: 0.100000
2022-07-13 07:11:35 - train: epoch 0017, iter [00100, 05004], lr: 0.100000, loss: 2.2000
2022-07-13 07:12:09 - train: epoch 0017, iter [00200, 05004], lr: 0.100000, loss: 2.3616
2022-07-13 07:12:42 - train: epoch 0017, iter [00300, 05004], lr: 0.100000, loss: 2.6284
2022-07-13 07:13:17 - train: epoch 0017, iter [00400, 05004], lr: 0.100000, loss: 2.1947
2022-07-13 07:13:50 - train: epoch 0017, iter [00500, 05004], lr: 0.100000, loss: 2.2942
2022-07-13 07:14:23 - train: epoch 0017, iter [00600, 05004], lr: 0.100000, loss: 2.6991
2022-07-13 07:14:57 - train: epoch 0017, iter [00700, 05004], lr: 0.100000, loss: 2.3375
2022-07-13 07:15:30 - train: epoch 0017, iter [00800, 05004], lr: 0.100000, loss: 2.2688
2022-07-13 07:16:03 - train: epoch 0017, iter [00900, 05004], lr: 0.100000, loss: 2.3098
2022-07-13 07:16:37 - train: epoch 0017, iter [01000, 05004], lr: 0.100000, loss: 2.2596
2022-07-13 07:17:09 - train: epoch 0017, iter [01100, 05004], lr: 0.100000, loss: 2.6297
2022-07-13 07:17:43 - train: epoch 0017, iter [01200, 05004], lr: 0.100000, loss: 2.5456
2022-07-13 07:18:16 - train: epoch 0017, iter [01300, 05004], lr: 0.100000, loss: 2.3891
2022-07-13 07:18:50 - train: epoch 0017, iter [01400, 05004], lr: 0.100000, loss: 2.3790
2022-07-13 07:19:22 - train: epoch 0017, iter [01500, 05004], lr: 0.100000, loss: 2.0575
2022-07-13 07:19:56 - train: epoch 0017, iter [01600, 05004], lr: 0.100000, loss: 2.0575
2022-07-13 07:20:30 - train: epoch 0017, iter [01700, 05004], lr: 0.100000, loss: 2.3469
2022-07-13 07:21:03 - train: epoch 0017, iter [01800, 05004], lr: 0.100000, loss: 2.2516
2022-07-13 07:21:37 - train: epoch 0017, iter [01900, 05004], lr: 0.100000, loss: 2.0847
2022-07-13 07:22:10 - train: epoch 0017, iter [02000, 05004], lr: 0.100000, loss: 2.2996
2022-07-13 07:22:43 - train: epoch 0017, iter [02100, 05004], lr: 0.100000, loss: 2.3160
2022-07-13 07:23:17 - train: epoch 0017, iter [02200, 05004], lr: 0.100000, loss: 2.2514
2022-07-13 07:23:49 - train: epoch 0017, iter [02300, 05004], lr: 0.100000, loss: 2.1608
2022-07-13 07:24:23 - train: epoch 0017, iter [02400, 05004], lr: 0.100000, loss: 2.1882
2022-07-13 07:24:57 - train: epoch 0017, iter [02500, 05004], lr: 0.100000, loss: 2.5721
2022-07-13 07:25:30 - train: epoch 0017, iter [02600, 05004], lr: 0.100000, loss: 2.2037
2022-07-13 07:26:04 - train: epoch 0017, iter [02700, 05004], lr: 0.100000, loss: 2.2423
2022-07-13 07:26:36 - train: epoch 0017, iter [02800, 05004], lr: 0.100000, loss: 2.6031
2022-07-13 07:27:10 - train: epoch 0017, iter [02900, 05004], lr: 0.100000, loss: 2.5408
2022-07-13 07:27:44 - train: epoch 0017, iter [03000, 05004], lr: 0.100000, loss: 2.1533
2022-07-13 07:28:17 - train: epoch 0017, iter [03100, 05004], lr: 0.100000, loss: 2.3661
2022-07-13 07:28:50 - train: epoch 0017, iter [03200, 05004], lr: 0.100000, loss: 2.2581
2022-07-13 07:29:23 - train: epoch 0017, iter [03300, 05004], lr: 0.100000, loss: 2.3795
2022-07-13 07:29:58 - train: epoch 0017, iter [03400, 05004], lr: 0.100000, loss: 2.1004
2022-07-13 07:30:31 - train: epoch 0017, iter [03500, 05004], lr: 0.100000, loss: 2.3053
2022-07-13 07:31:04 - train: epoch 0017, iter [03600, 05004], lr: 0.100000, loss: 2.5475
2022-07-13 07:31:37 - train: epoch 0017, iter [03700, 05004], lr: 0.100000, loss: 2.3243
2022-07-13 07:32:11 - train: epoch 0017, iter [03800, 05004], lr: 0.100000, loss: 2.5600
2022-07-13 07:32:44 - train: epoch 0017, iter [03900, 05004], lr: 0.100000, loss: 2.1454
2022-07-13 07:33:18 - train: epoch 0017, iter [04000, 05004], lr: 0.100000, loss: 2.1753
2022-07-13 07:33:52 - train: epoch 0017, iter [04100, 05004], lr: 0.100000, loss: 2.3232
2022-07-13 07:34:24 - train: epoch 0017, iter [04200, 05004], lr: 0.100000, loss: 2.1395
2022-07-13 07:34:58 - train: epoch 0017, iter [04300, 05004], lr: 0.100000, loss: 2.3164
2022-07-13 07:35:32 - train: epoch 0017, iter [04400, 05004], lr: 0.100000, loss: 2.1727
2022-07-13 07:36:05 - train: epoch 0017, iter [04500, 05004], lr: 0.100000, loss: 2.3909
2022-07-13 07:36:38 - train: epoch 0017, iter [04600, 05004], lr: 0.100000, loss: 2.3183
2022-07-13 07:37:12 - train: epoch 0017, iter [04700, 05004], lr: 0.100000, loss: 2.4160
2022-07-13 07:37:45 - train: epoch 0017, iter [04800, 05004], lr: 0.100000, loss: 2.5456
2022-07-13 07:38:19 - train: epoch 0017, iter [04900, 05004], lr: 0.100000, loss: 2.2202
2022-07-13 07:38:51 - train: epoch 0017, iter [05000, 05004], lr: 0.100000, loss: 1.9991
2022-07-13 07:38:52 - train: epoch 017, train_loss: 2.3094
2022-07-13 07:40:06 - eval: epoch: 017, acc1: 53.876%, acc5: 79.408%, test_loss: 1.9677, per_image_load_time: 2.508ms, per_image_inference_time: 0.311ms
2022-07-13 07:40:07 - until epoch: 017, best_acc1: 53.876%
2022-07-13 07:40:07 - epoch 018 lr: 0.100000
2022-07-13 07:40:45 - train: epoch 0018, iter [00100, 05004], lr: 0.100000, loss: 2.2208
2022-07-13 07:41:19 - train: epoch 0018, iter [00200, 05004], lr: 0.100000, loss: 2.2707
2022-07-13 07:41:53 - train: epoch 0018, iter [00300, 05004], lr: 0.100000, loss: 2.3893
2022-07-13 07:42:26 - train: epoch 0018, iter [00400, 05004], lr: 0.100000, loss: 2.4859
2022-07-13 07:42:59 - train: epoch 0018, iter [00500, 05004], lr: 0.100000, loss: 2.2380
2022-07-13 07:43:33 - train: epoch 0018, iter [00600, 05004], lr: 0.100000, loss: 2.3879
2022-07-13 07:44:07 - train: epoch 0018, iter [00700, 05004], lr: 0.100000, loss: 2.0806
2022-07-13 07:44:39 - train: epoch 0018, iter [00800, 05004], lr: 0.100000, loss: 2.2682
2022-07-13 07:45:13 - train: epoch 0018, iter [00900, 05004], lr: 0.100000, loss: 2.3754
2022-07-13 07:45:46 - train: epoch 0018, iter [01000, 05004], lr: 0.100000, loss: 2.0734
2022-07-13 07:46:19 - train: epoch 0018, iter [01100, 05004], lr: 0.100000, loss: 2.6368
2022-07-13 07:46:52 - train: epoch 0018, iter [01200, 05004], lr: 0.100000, loss: 2.4187
2022-07-13 07:47:26 - train: epoch 0018, iter [01300, 05004], lr: 0.100000, loss: 2.6421
2022-07-13 07:47:59 - train: epoch 0018, iter [01400, 05004], lr: 0.100000, loss: 2.3169
2022-07-13 07:48:32 - train: epoch 0018, iter [01500, 05004], lr: 0.100000, loss: 2.5476
2022-07-13 07:49:06 - train: epoch 0018, iter [01600, 05004], lr: 0.100000, loss: 2.3029
2022-07-13 07:49:39 - train: epoch 0018, iter [01700, 05004], lr: 0.100000, loss: 2.1938
2022-07-13 07:50:13 - train: epoch 0018, iter [01800, 05004], lr: 0.100000, loss: 2.0658
2022-07-13 07:50:47 - train: epoch 0018, iter [01900, 05004], lr: 0.100000, loss: 2.3095
2022-07-13 07:51:21 - train: epoch 0018, iter [02000, 05004], lr: 0.100000, loss: 2.5440
2022-07-13 07:51:54 - train: epoch 0018, iter [02100, 05004], lr: 0.100000, loss: 2.4087
2022-07-13 07:52:27 - train: epoch 0018, iter [02200, 05004], lr: 0.100000, loss: 2.3547
2022-07-13 07:53:01 - train: epoch 0018, iter [02300, 05004], lr: 0.100000, loss: 2.3884
2022-07-13 07:53:34 - train: epoch 0018, iter [02400, 05004], lr: 0.100000, loss: 2.1388
2022-07-13 07:54:08 - train: epoch 0018, iter [02500, 05004], lr: 0.100000, loss: 2.0269
2022-07-13 07:54:40 - train: epoch 0018, iter [02600, 05004], lr: 0.100000, loss: 2.1076
2022-07-13 07:55:14 - train: epoch 0018, iter [02700, 05004], lr: 0.100000, loss: 2.4916
2022-07-13 07:55:47 - train: epoch 0018, iter [02800, 05004], lr: 0.100000, loss: 2.0637
2022-07-13 07:56:21 - train: epoch 0018, iter [02900, 05004], lr: 0.100000, loss: 2.3278
2022-07-13 07:56:54 - train: epoch 0018, iter [03000, 05004], lr: 0.100000, loss: 2.2338
2022-07-13 07:57:28 - train: epoch 0018, iter [03100, 05004], lr: 0.100000, loss: 2.6404
2022-07-13 07:58:01 - train: epoch 0018, iter [03200, 05004], lr: 0.100000, loss: 2.1137
2022-07-13 07:58:35 - train: epoch 0018, iter [03300, 05004], lr: 0.100000, loss: 2.2574
2022-07-13 07:59:08 - train: epoch 0018, iter [03400, 05004], lr: 0.100000, loss: 2.2980
2022-07-13 07:59:41 - train: epoch 0018, iter [03500, 05004], lr: 0.100000, loss: 2.5558
2022-07-13 08:00:15 - train: epoch 0018, iter [03600, 05004], lr: 0.100000, loss: 2.4662
2022-07-13 08:00:49 - train: epoch 0018, iter [03700, 05004], lr: 0.100000, loss: 2.7521
2022-07-13 08:01:22 - train: epoch 0018, iter [03800, 05004], lr: 0.100000, loss: 2.2949
2022-07-13 08:01:56 - train: epoch 0018, iter [03900, 05004], lr: 0.100000, loss: 2.3338
2022-07-13 08:02:31 - train: epoch 0018, iter [04000, 05004], lr: 0.100000, loss: 2.1869
2022-07-13 08:03:04 - train: epoch 0018, iter [04100, 05004], lr: 0.100000, loss: 2.2597
2022-07-13 08:03:37 - train: epoch 0018, iter [04200, 05004], lr: 0.100000, loss: 2.3271
2022-07-13 08:04:11 - train: epoch 0018, iter [04300, 05004], lr: 0.100000, loss: 2.1003
2022-07-13 08:04:44 - train: epoch 0018, iter [04400, 05004], lr: 0.100000, loss: 2.4635
2022-07-13 08:05:18 - train: epoch 0018, iter [04500, 05004], lr: 0.100000, loss: 2.2591
2022-07-13 08:05:52 - train: epoch 0018, iter [04600, 05004], lr: 0.100000, loss: 2.1067
2022-07-13 08:06:25 - train: epoch 0018, iter [04700, 05004], lr: 0.100000, loss: 2.5434
2022-07-13 08:06:58 - train: epoch 0018, iter [04800, 05004], lr: 0.100000, loss: 2.4459
2022-07-13 08:07:32 - train: epoch 0018, iter [04900, 05004], lr: 0.100000, loss: 2.3020
2022-07-13 08:08:04 - train: epoch 0018, iter [05000, 05004], lr: 0.100000, loss: 2.5148
2022-07-13 08:08:05 - train: epoch 018, train_loss: 2.2990
2022-07-13 08:09:20 - eval: epoch: 018, acc1: 54.330%, acc5: 79.366%, test_loss: 1.9501, per_image_load_time: 2.588ms, per_image_inference_time: 0.313ms
2022-07-13 08:09:21 - until epoch: 018, best_acc1: 54.330%
2022-07-13 08:09:21 - epoch 019 lr: 0.100000
2022-07-13 08:10:00 - train: epoch 0019, iter [00100, 05004], lr: 0.100000, loss: 2.0187
2022-07-13 08:10:32 - train: epoch 0019, iter [00200, 05004], lr: 0.100000, loss: 2.3683
2022-07-13 08:11:06 - train: epoch 0019, iter [00300, 05004], lr: 0.100000, loss: 2.3716
2022-07-13 08:11:39 - train: epoch 0019, iter [00400, 05004], lr: 0.100000, loss: 2.2583
2022-07-13 08:12:13 - train: epoch 0019, iter [00500, 05004], lr: 0.100000, loss: 2.2393
2022-07-13 08:12:46 - train: epoch 0019, iter [00600, 05004], lr: 0.100000, loss: 2.1517
2022-07-13 08:13:19 - train: epoch 0019, iter [00700, 05004], lr: 0.100000, loss: 2.0652
2022-07-13 08:13:52 - train: epoch 0019, iter [00800, 05004], lr: 0.100000, loss: 2.4843
2022-07-13 08:14:25 - train: epoch 0019, iter [00900, 05004], lr: 0.100000, loss: 2.1881
2022-07-13 08:14:59 - train: epoch 0019, iter [01000, 05004], lr: 0.100000, loss: 2.5375
2022-07-13 08:15:32 - train: epoch 0019, iter [01100, 05004], lr: 0.100000, loss: 2.0501
2022-07-13 08:16:06 - train: epoch 0019, iter [01200, 05004], lr: 0.100000, loss: 2.3277
2022-07-13 08:16:39 - train: epoch 0019, iter [01300, 05004], lr: 0.100000, loss: 2.5381
2022-07-13 08:17:12 - train: epoch 0019, iter [01400, 05004], lr: 0.100000, loss: 2.2616
2022-07-13 08:17:46 - train: epoch 0019, iter [01500, 05004], lr: 0.100000, loss: 2.6608
2022-07-13 08:18:19 - train: epoch 0019, iter [01600, 05004], lr: 0.100000, loss: 2.3243
2022-07-13 08:18:53 - train: epoch 0019, iter [01700, 05004], lr: 0.100000, loss: 2.4195
2022-07-13 08:19:26 - train: epoch 0019, iter [01800, 05004], lr: 0.100000, loss: 2.2664
2022-07-13 08:19:59 - train: epoch 0019, iter [01900, 05004], lr: 0.100000, loss: 2.4859
2022-07-13 08:20:33 - train: epoch 0019, iter [02000, 05004], lr: 0.100000, loss: 2.2505
2022-07-13 08:21:06 - train: epoch 0019, iter [02100, 05004], lr: 0.100000, loss: 2.1522
2022-07-13 08:21:39 - train: epoch 0019, iter [02200, 05004], lr: 0.100000, loss: 2.2960
2022-07-13 08:22:13 - train: epoch 0019, iter [02300, 05004], lr: 0.100000, loss: 2.2339
2022-07-13 08:22:46 - train: epoch 0019, iter [02400, 05004], lr: 0.100000, loss: 2.4030
2022-07-13 08:23:20 - train: epoch 0019, iter [02500, 05004], lr: 0.100000, loss: 2.2785
2022-07-13 08:23:53 - train: epoch 0019, iter [02600, 05004], lr: 0.100000, loss: 2.2764
2022-07-13 08:24:27 - train: epoch 0019, iter [02700, 05004], lr: 0.100000, loss: 2.4270
2022-07-13 08:25:00 - train: epoch 0019, iter [02800, 05004], lr: 0.100000, loss: 2.3907
2022-07-13 08:25:34 - train: epoch 0019, iter [02900, 05004], lr: 0.100000, loss: 2.3202
2022-07-13 08:26:08 - train: epoch 0019, iter [03000, 05004], lr: 0.100000, loss: 2.5219
2022-07-13 08:26:41 - train: epoch 0019, iter [03100, 05004], lr: 0.100000, loss: 2.4360
2022-07-13 08:27:14 - train: epoch 0019, iter [03200, 05004], lr: 0.100000, loss: 1.9354
2022-07-13 08:27:49 - train: epoch 0019, iter [03300, 05004], lr: 0.100000, loss: 2.2157
2022-07-13 08:28:21 - train: epoch 0019, iter [03400, 05004], lr: 0.100000, loss: 2.3749
2022-07-13 08:28:55 - train: epoch 0019, iter [03500, 05004], lr: 0.100000, loss: 2.2873
2022-07-13 08:29:27 - train: epoch 0019, iter [03600, 05004], lr: 0.100000, loss: 2.0972
2022-07-13 08:30:01 - train: epoch 0019, iter [03700, 05004], lr: 0.100000, loss: 2.3855
2022-07-13 08:30:34 - train: epoch 0019, iter [03800, 05004], lr: 0.100000, loss: 2.4231
2022-07-13 08:31:08 - train: epoch 0019, iter [03900, 05004], lr: 0.100000, loss: 2.2090
2022-07-13 08:31:41 - train: epoch 0019, iter [04000, 05004], lr: 0.100000, loss: 2.1166
2022-07-13 08:32:15 - train: epoch 0019, iter [04100, 05004], lr: 0.100000, loss: 2.3718
2022-07-13 08:32:48 - train: epoch 0019, iter [04200, 05004], lr: 0.100000, loss: 2.2118
2022-07-13 08:33:21 - train: epoch 0019, iter [04300, 05004], lr: 0.100000, loss: 2.2223
2022-07-13 08:33:55 - train: epoch 0019, iter [04400, 05004], lr: 0.100000, loss: 2.3458
2022-07-13 08:34:29 - train: epoch 0019, iter [04500, 05004], lr: 0.100000, loss: 2.6146
2022-07-13 08:35:02 - train: epoch 0019, iter [04600, 05004], lr: 0.100000, loss: 2.2104
2022-07-13 08:35:35 - train: epoch 0019, iter [04700, 05004], lr: 0.100000, loss: 2.2442
2022-07-13 08:36:09 - train: epoch 0019, iter [04800, 05004], lr: 0.100000, loss: 2.3523
2022-07-13 08:36:41 - train: epoch 0019, iter [04900, 05004], lr: 0.100000, loss: 2.3745
2022-07-13 08:37:13 - train: epoch 0019, iter [05000, 05004], lr: 0.100000, loss: 2.3197
2022-07-13 08:37:14 - train: epoch 019, train_loss: 2.2944
2022-07-13 08:38:31 - eval: epoch: 019, acc1: 54.578%, acc5: 79.476%, test_loss: 1.9458, per_image_load_time: 2.621ms, per_image_inference_time: 0.296ms
2022-07-13 08:38:31 - until epoch: 019, best_acc1: 54.578%
2022-07-13 08:38:31 - epoch 020 lr: 0.100000
2022-07-13 08:39:09 - train: epoch 0020, iter [00100, 05004], lr: 0.100000, loss: 2.3137
2022-07-13 08:39:43 - train: epoch 0020, iter [00200, 05004], lr: 0.100000, loss: 1.9364
2022-07-13 08:40:16 - train: epoch 0020, iter [00300, 05004], lr: 0.100000, loss: 2.2475
2022-07-13 08:40:50 - train: epoch 0020, iter [00400, 05004], lr: 0.100000, loss: 2.0126
2022-07-13 08:41:23 - train: epoch 0020, iter [00500, 05004], lr: 0.100000, loss: 2.2577
2022-07-13 08:41:56 - train: epoch 0020, iter [00600, 05004], lr: 0.100000, loss: 2.5234
2022-07-13 08:42:30 - train: epoch 0020, iter [00700, 05004], lr: 0.100000, loss: 2.1314
2022-07-13 08:43:04 - train: epoch 0020, iter [00800, 05004], lr: 0.100000, loss: 2.5490
2022-07-13 08:43:36 - train: epoch 0020, iter [00900, 05004], lr: 0.100000, loss: 2.5347
2022-07-13 08:44:09 - train: epoch 0020, iter [01000, 05004], lr: 0.100000, loss: 2.3669
2022-07-13 08:44:43 - train: epoch 0020, iter [01100, 05004], lr: 0.100000, loss: 2.1837
2022-07-13 08:45:15 - train: epoch 0020, iter [01200, 05004], lr: 0.100000, loss: 2.0760
2022-07-13 08:45:49 - train: epoch 0020, iter [01300, 05004], lr: 0.100000, loss: 2.1736
2022-07-13 08:46:22 - train: epoch 0020, iter [01400, 05004], lr: 0.100000, loss: 2.3586
2022-07-13 08:46:55 - train: epoch 0020, iter [01500, 05004], lr: 0.100000, loss: 2.4406
2022-07-13 08:47:28 - train: epoch 0020, iter [01600, 05004], lr: 0.100000, loss: 2.2359
2022-07-13 08:48:01 - train: epoch 0020, iter [01700, 05004], lr: 0.100000, loss: 1.9844
2022-07-13 08:48:35 - train: epoch 0020, iter [01800, 05004], lr: 0.100000, loss: 2.2624
2022-07-13 08:49:08 - train: epoch 0020, iter [01900, 05004], lr: 0.100000, loss: 2.0770
2022-07-13 08:49:41 - train: epoch 0020, iter [02000, 05004], lr: 0.100000, loss: 2.2311
2022-07-13 08:50:14 - train: epoch 0020, iter [02100, 05004], lr: 0.100000, loss: 2.4972
2022-07-13 08:50:48 - train: epoch 0020, iter [02200, 05004], lr: 0.100000, loss: 2.2059
2022-07-13 08:51:21 - train: epoch 0020, iter [02300, 05004], lr: 0.100000, loss: 2.1531
2022-07-13 08:51:55 - train: epoch 0020, iter [02400, 05004], lr: 0.100000, loss: 2.4809
2022-07-13 08:52:27 - train: epoch 0020, iter [02500, 05004], lr: 0.100000, loss: 2.1165
2022-07-13 08:53:01 - train: epoch 0020, iter [02600, 05004], lr: 0.100000, loss: 2.0966
2022-07-13 08:53:34 - train: epoch 0020, iter [02700, 05004], lr: 0.100000, loss: 2.4620
2022-07-13 08:54:08 - train: epoch 0020, iter [02800, 05004], lr: 0.100000, loss: 2.3025
2022-07-13 08:54:41 - train: epoch 0020, iter [02900, 05004], lr: 0.100000, loss: 2.4704
2022-07-13 08:55:14 - train: epoch 0020, iter [03000, 05004], lr: 0.100000, loss: 2.2184
2022-07-13 08:55:47 - train: epoch 0020, iter [03100, 05004], lr: 0.100000, loss: 2.3147
2022-07-13 08:56:20 - train: epoch 0020, iter [03200, 05004], lr: 0.100000, loss: 2.3938
2022-07-13 08:56:53 - train: epoch 0020, iter [03300, 05004], lr: 0.100000, loss: 2.1672
2022-07-13 08:57:27 - train: epoch 0020, iter [03400, 05004], lr: 0.100000, loss: 2.3573
2022-07-13 08:58:00 - train: epoch 0020, iter [03500, 05004], lr: 0.100000, loss: 2.1203
2022-07-13 08:58:34 - train: epoch 0020, iter [03600, 05004], lr: 0.100000, loss: 2.2618
2022-07-13 08:59:07 - train: epoch 0020, iter [03700, 05004], lr: 0.100000, loss: 2.2247
2022-07-13 08:59:40 - train: epoch 0020, iter [03800, 05004], lr: 0.100000, loss: 2.3709
2022-07-13 09:00:13 - train: epoch 0020, iter [03900, 05004], lr: 0.100000, loss: 2.3754
2022-07-13 09:00:47 - train: epoch 0020, iter [04000, 05004], lr: 0.100000, loss: 2.1584
2022-07-13 09:01:20 - train: epoch 0020, iter [04100, 05004], lr: 0.100000, loss: 2.2219
2022-07-13 09:01:54 - train: epoch 0020, iter [04200, 05004], lr: 0.100000, loss: 2.1804
2022-07-13 09:02:26 - train: epoch 0020, iter [04300, 05004], lr: 0.100000, loss: 2.3442
2022-07-13 09:03:01 - train: epoch 0020, iter [04400, 05004], lr: 0.100000, loss: 2.2988
2022-07-13 09:03:34 - train: epoch 0020, iter [04500, 05004], lr: 0.100000, loss: 2.3972
2022-07-13 09:04:07 - train: epoch 0020, iter [04600, 05004], lr: 0.100000, loss: 2.4420
2022-07-13 09:04:41 - train: epoch 0020, iter [04700, 05004], lr: 0.100000, loss: 2.0570
2022-07-13 09:05:14 - train: epoch 0020, iter [04800, 05004], lr: 0.100000, loss: 2.2815
2022-07-13 09:05:48 - train: epoch 0020, iter [04900, 05004], lr: 0.100000, loss: 2.3426
2022-07-13 09:06:20 - train: epoch 0020, iter [05000, 05004], lr: 0.100000, loss: 2.0186
2022-07-13 09:06:21 - train: epoch 020, train_loss: 2.2816
2022-07-13 09:07:36 - eval: epoch: 020, acc1: 54.252%, acc5: 79.232%, test_loss: 1.9638, per_image_load_time: 2.538ms, per_image_inference_time: 0.306ms
2022-07-13 09:07:36 - until epoch: 020, best_acc1: 54.578%
2022-07-13 09:07:36 - epoch 021 lr: 0.100000
2022-07-13 09:08:15 - train: epoch 0021, iter [00100, 05004], lr: 0.100000, loss: 2.1154
2022-07-13 09:08:48 - train: epoch 0021, iter [00200, 05004], lr: 0.100000, loss: 2.1835
2022-07-13 09:09:21 - train: epoch 0021, iter [00300, 05004], lr: 0.100000, loss: 1.9516
2022-07-13 09:09:55 - train: epoch 0021, iter [00400, 05004], lr: 0.100000, loss: 2.4018
2022-07-13 09:10:28 - train: epoch 0021, iter [00500, 05004], lr: 0.100000, loss: 2.2116
2022-07-13 09:11:02 - train: epoch 0021, iter [00600, 05004], lr: 0.100000, loss: 2.1707
2022-07-13 09:11:35 - train: epoch 0021, iter [00700, 05004], lr: 0.100000, loss: 2.0583
2022-07-13 09:12:08 - train: epoch 0021, iter [00800, 05004], lr: 0.100000, loss: 2.4474
2022-07-13 09:12:42 - train: epoch 0021, iter [00900, 05004], lr: 0.100000, loss: 2.2492
2022-07-13 09:13:15 - train: epoch 0021, iter [01000, 05004], lr: 0.100000, loss: 2.1134
2022-07-13 09:13:48 - train: epoch 0021, iter [01100, 05004], lr: 0.100000, loss: 2.2068
2022-07-13 09:14:21 - train: epoch 0021, iter [01200, 05004], lr: 0.100000, loss: 2.2060
2022-07-13 09:14:56 - train: epoch 0021, iter [01300, 05004], lr: 0.100000, loss: 2.2057
2022-07-13 09:15:28 - train: epoch 0021, iter [01400, 05004], lr: 0.100000, loss: 2.2110
2022-07-13 09:16:02 - train: epoch 0021, iter [01500, 05004], lr: 0.100000, loss: 2.0850
2022-07-13 09:16:35 - train: epoch 0021, iter [01600, 05004], lr: 0.100000, loss: 2.2466
2022-07-13 09:17:08 - train: epoch 0021, iter [01700, 05004], lr: 0.100000, loss: 2.3912
2022-07-13 09:17:41 - train: epoch 0021, iter [01800, 05004], lr: 0.100000, loss: 2.1965
2022-07-13 09:18:16 - train: epoch 0021, iter [01900, 05004], lr: 0.100000, loss: 2.3898
2022-07-13 09:18:48 - train: epoch 0021, iter [02000, 05004], lr: 0.100000, loss: 2.4235
2022-07-13 09:19:22 - train: epoch 0021, iter [02100, 05004], lr: 0.100000, loss: 2.0336
2022-07-13 09:19:55 - train: epoch 0021, iter [02200, 05004], lr: 0.100000, loss: 2.2821
2022-07-13 09:20:28 - train: epoch 0021, iter [02300, 05004], lr: 0.100000, loss: 2.1288
2022-07-13 09:21:01 - train: epoch 0021, iter [02400, 05004], lr: 0.100000, loss: 2.0803
2022-07-13 09:21:35 - train: epoch 0021, iter [02500, 05004], lr: 0.100000, loss: 2.1741
2022-07-13 09:22:09 - train: epoch 0021, iter [02600, 05004], lr: 0.100000, loss: 2.4194
2022-07-13 09:22:42 - train: epoch 0021, iter [02700, 05004], lr: 0.100000, loss: 2.2356
2022-07-13 09:23:16 - train: epoch 0021, iter [02800, 05004], lr: 0.100000, loss: 2.1444
2022-07-13 09:23:50 - train: epoch 0021, iter [02900, 05004], lr: 0.100000, loss: 2.1661
2022-07-13 09:24:23 - train: epoch 0021, iter [03000, 05004], lr: 0.100000, loss: 2.4637
2022-07-13 09:24:57 - train: epoch 0021, iter [03100, 05004], lr: 0.100000, loss: 2.3914
2022-07-13 09:25:31 - train: epoch 0021, iter [03200, 05004], lr: 0.100000, loss: 2.3390
2022-07-13 09:26:04 - train: epoch 0021, iter [03300, 05004], lr: 0.100000, loss: 2.6268
2022-07-13 09:26:37 - train: epoch 0021, iter [03400, 05004], lr: 0.100000, loss: 2.4656
2022-07-13 09:27:11 - train: epoch 0021, iter [03500, 05004], lr: 0.100000, loss: 2.1255
2022-07-13 09:27:44 - train: epoch 0021, iter [03600, 05004], lr: 0.100000, loss: 2.2859
2022-07-13 09:28:17 - train: epoch 0021, iter [03700, 05004], lr: 0.100000, loss: 2.3086
2022-07-13 09:28:51 - train: epoch 0021, iter [03800, 05004], lr: 0.100000, loss: 2.1556
2022-07-13 09:29:25 - train: epoch 0021, iter [03900, 05004], lr: 0.100000, loss: 2.2320
2022-07-13 09:29:58 - train: epoch 0021, iter [04000, 05004], lr: 0.100000, loss: 2.4302
2022-07-13 09:30:31 - train: epoch 0021, iter [04100, 05004], lr: 0.100000, loss: 2.2041
2022-07-13 09:31:05 - train: epoch 0021, iter [04200, 05004], lr: 0.100000, loss: 2.2458
2022-07-13 09:31:38 - train: epoch 0021, iter [04300, 05004], lr: 0.100000, loss: 2.2843
2022-07-13 09:32:12 - train: epoch 0021, iter [04400, 05004], lr: 0.100000, loss: 2.3045
2022-07-13 09:32:46 - train: epoch 0021, iter [04500, 05004], lr: 0.100000, loss: 2.4477
2022-07-13 09:33:19 - train: epoch 0021, iter [04600, 05004], lr: 0.100000, loss: 2.1664
2022-07-13 09:33:53 - train: epoch 0021, iter [04700, 05004], lr: 0.100000, loss: 2.4239
2022-07-13 09:34:26 - train: epoch 0021, iter [04800, 05004], lr: 0.100000, loss: 2.4609
2022-07-13 09:35:00 - train: epoch 0021, iter [04900, 05004], lr: 0.100000, loss: 2.1598
2022-07-13 09:35:32 - train: epoch 0021, iter [05000, 05004], lr: 0.100000, loss: 2.2978
2022-07-13 09:35:33 - train: epoch 021, train_loss: 2.2778
2022-07-13 09:36:47 - eval: epoch: 021, acc1: 53.390%, acc5: 78.710%, test_loss: 1.9962, per_image_load_time: 1.969ms, per_image_inference_time: 0.304ms
2022-07-13 09:36:48 - until epoch: 021, best_acc1: 54.578%
2022-07-13 09:36:48 - epoch 022 lr: 0.100000
2022-07-13 09:37:26 - train: epoch 0022, iter [00100, 05004], lr: 0.100000, loss: 2.0774
2022-07-13 09:37:59 - train: epoch 0022, iter [00200, 05004], lr: 0.100000, loss: 2.0606
2022-07-13 09:38:33 - train: epoch 0022, iter [00300, 05004], lr: 0.100000, loss: 1.9760
2022-07-13 09:39:05 - train: epoch 0022, iter [00400, 05004], lr: 0.100000, loss: 2.0470
2022-07-13 09:39:38 - train: epoch 0022, iter [00500, 05004], lr: 0.100000, loss: 2.2894
2022-07-13 09:40:11 - train: epoch 0022, iter [00600, 05004], lr: 0.100000, loss: 2.3520
2022-07-13 09:40:45 - train: epoch 0022, iter [00700, 05004], lr: 0.100000, loss: 2.3381
2022-07-13 09:41:18 - train: epoch 0022, iter [00800, 05004], lr: 0.100000, loss: 2.2882
2022-07-13 09:41:51 - train: epoch 0022, iter [00900, 05004], lr: 0.100000, loss: 2.4868
2022-07-13 09:42:24 - train: epoch 0022, iter [01000, 05004], lr: 0.100000, loss: 2.2602
2022-07-13 09:42:56 - train: epoch 0022, iter [01100, 05004], lr: 0.100000, loss: 2.2686
2022-07-13 09:43:31 - train: epoch 0022, iter [01200, 05004], lr: 0.100000, loss: 1.9371
2022-07-13 09:44:03 - train: epoch 0022, iter [01300, 05004], lr: 0.100000, loss: 2.3256
2022-07-13 09:44:36 - train: epoch 0022, iter [01400, 05004], lr: 0.100000, loss: 2.2962
2022-07-13 09:45:10 - train: epoch 0022, iter [01500, 05004], lr: 0.100000, loss: 2.1198
2022-07-13 09:45:42 - train: epoch 0022, iter [01600, 05004], lr: 0.100000, loss: 2.1672
2022-07-13 09:46:16 - train: epoch 0022, iter [01700, 05004], lr: 0.100000, loss: 1.9589
2022-07-13 09:46:49 - train: epoch 0022, iter [01800, 05004], lr: 0.100000, loss: 2.5319
2022-07-13 09:47:22 - train: epoch 0022, iter [01900, 05004], lr: 0.100000, loss: 2.0964
2022-07-13 09:47:55 - train: epoch 0022, iter [02000, 05004], lr: 0.100000, loss: 2.2626
2022-07-13 09:48:28 - train: epoch 0022, iter [02100, 05004], lr: 0.100000, loss: 2.3366
2022-07-13 09:49:00 - train: epoch 0022, iter [02200, 05004], lr: 0.100000, loss: 2.1310
2022-07-13 09:49:34 - train: epoch 0022, iter [02300, 05004], lr: 0.100000, loss: 2.4406
2022-07-13 09:50:07 - train: epoch 0022, iter [02400, 05004], lr: 0.100000, loss: 2.3609
2022-07-13 09:50:41 - train: epoch 0022, iter [02500, 05004], lr: 0.100000, loss: 2.2044
2022-07-13 09:51:13 - train: epoch 0022, iter [02600, 05004], lr: 0.100000, loss: 2.1395
2022-07-13 09:51:47 - train: epoch 0022, iter [02700, 05004], lr: 0.100000, loss: 2.1172
2022-07-13 09:52:20 - train: epoch 0022, iter [02800, 05004], lr: 0.100000, loss: 2.5594
2022-07-13 09:52:53 - train: epoch 0022, iter [02900, 05004], lr: 0.100000, loss: 2.0570
2022-07-13 09:53:26 - train: epoch 0022, iter [03000, 05004], lr: 0.100000, loss: 2.2836
2022-07-13 09:54:00 - train: epoch 0022, iter [03100, 05004], lr: 0.100000, loss: 2.3451
2022-07-13 09:54:32 - train: epoch 0022, iter [03200, 05004], lr: 0.100000, loss: 2.4049
2022-07-13 09:55:06 - train: epoch 0022, iter [03300, 05004], lr: 0.100000, loss: 2.2997
2022-07-13 09:55:39 - train: epoch 0022, iter [03400, 05004], lr: 0.100000, loss: 2.0107
2022-07-13 09:56:13 - train: epoch 0022, iter [03500, 05004], lr: 0.100000, loss: 2.3295
2022-07-13 09:56:46 - train: epoch 0022, iter [03600, 05004], lr: 0.100000, loss: 2.4083
2022-07-13 09:57:20 - train: epoch 0022, iter [03700, 05004], lr: 0.100000, loss: 2.4332
2022-07-13 09:57:53 - train: epoch 0022, iter [03800, 05004], lr: 0.100000, loss: 2.4411
2022-07-13 09:58:26 - train: epoch 0022, iter [03900, 05004], lr: 0.100000, loss: 2.3473
2022-07-13 09:59:00 - train: epoch 0022, iter [04000, 05004], lr: 0.100000, loss: 2.3582
2022-07-13 09:59:33 - train: epoch 0022, iter [04100, 05004], lr: 0.100000, loss: 2.2280
2022-07-13 10:00:06 - train: epoch 0022, iter [04200, 05004], lr: 0.100000, loss: 2.2689
2022-07-13 10:00:40 - train: epoch 0022, iter [04300, 05004], lr: 0.100000, loss: 2.5221
2022-07-13 10:01:13 - train: epoch 0022, iter [04400, 05004], lr: 0.100000, loss: 2.4102
2022-07-13 10:01:47 - train: epoch 0022, iter [04500, 05004], lr: 0.100000, loss: 2.2692
2022-07-13 10:02:21 - train: epoch 0022, iter [04600, 05004], lr: 0.100000, loss: 2.4520
2022-07-13 10:02:54 - train: epoch 0022, iter [04700, 05004], lr: 0.100000, loss: 2.4131
2022-07-13 10:03:27 - train: epoch 0022, iter [04800, 05004], lr: 0.100000, loss: 2.0508
2022-07-13 10:04:00 - train: epoch 0022, iter [04900, 05004], lr: 0.100000, loss: 2.0496
2022-07-13 10:04:32 - train: epoch 0022, iter [05000, 05004], lr: 0.100000, loss: 2.2057
2022-07-13 10:04:33 - train: epoch 022, train_loss: 2.2720
2022-07-13 10:05:48 - eval: epoch: 022, acc1: 54.260%, acc5: 79.192%, test_loss: 1.9634, per_image_load_time: 2.570ms, per_image_inference_time: 0.279ms
2022-07-13 10:05:48 - until epoch: 022, best_acc1: 54.578%
2022-07-13 10:05:48 - epoch 023 lr: 0.100000
2022-07-13 10:06:26 - train: epoch 0023, iter [00100, 05004], lr: 0.100000, loss: 2.1807
2022-07-13 10:07:00 - train: epoch 0023, iter [00200, 05004], lr: 0.100000, loss: 1.9307
2022-07-13 10:07:33 - train: epoch 0023, iter [00300, 05004], lr: 0.100000, loss: 2.1500
2022-07-13 10:08:07 - train: epoch 0023, iter [00400, 05004], lr: 0.100000, loss: 2.2999
2022-07-13 10:08:40 - train: epoch 0023, iter [00500, 05004], lr: 0.100000, loss: 2.3046
2022-07-13 10:09:13 - train: epoch 0023, iter [00600, 05004], lr: 0.100000, loss: 2.1325
2022-07-13 10:09:47 - train: epoch 0023, iter [00700, 05004], lr: 0.100000, loss: 2.0081
2022-07-13 10:10:20 - train: epoch 0023, iter [00800, 05004], lr: 0.100000, loss: 2.1664
2022-07-13 10:10:53 - train: epoch 0023, iter [00900, 05004], lr: 0.100000, loss: 2.2735
2022-07-13 10:11:27 - train: epoch 0023, iter [01000, 05004], lr: 0.100000, loss: 2.1833
2022-07-13 10:12:00 - train: epoch 0023, iter [01100, 05004], lr: 0.100000, loss: 2.4322
2022-07-13 10:12:34 - train: epoch 0023, iter [01200, 05004], lr: 0.100000, loss: 2.0534
2022-07-13 10:13:06 - train: epoch 0023, iter [01300, 05004], lr: 0.100000, loss: 2.2616
2022-07-13 10:13:40 - train: epoch 0023, iter [01400, 05004], lr: 0.100000, loss: 2.1790
2022-07-13 10:14:13 - train: epoch 0023, iter [01500, 05004], lr: 0.100000, loss: 2.0355
2022-07-13 10:14:47 - train: epoch 0023, iter [01600, 05004], lr: 0.100000, loss: 2.1605
2022-07-13 10:15:20 - train: epoch 0023, iter [01700, 05004], lr: 0.100000, loss: 2.4062
2022-07-13 10:15:53 - train: epoch 0023, iter [01800, 05004], lr: 0.100000, loss: 2.1495
2022-07-13 10:16:26 - train: epoch 0023, iter [01900, 05004], lr: 0.100000, loss: 2.2644
2022-07-13 10:17:00 - train: epoch 0023, iter [02000, 05004], lr: 0.100000, loss: 1.8461
2022-07-13 10:17:33 - train: epoch 0023, iter [02100, 05004], lr: 0.100000, loss: 2.4303
2022-07-13 10:18:06 - train: epoch 0023, iter [02200, 05004], lr: 0.100000, loss: 2.0381
2022-07-13 10:18:40 - train: epoch 0023, iter [02300, 05004], lr: 0.100000, loss: 2.1580
2022-07-13 10:19:13 - train: epoch 0023, iter [02400, 05004], lr: 0.100000, loss: 2.1948
2022-07-13 10:19:47 - train: epoch 0023, iter [02500, 05004], lr: 0.100000, loss: 2.4290
2022-07-13 10:20:20 - train: epoch 0023, iter [02600, 05004], lr: 0.100000, loss: 2.4194
2022-07-13 10:20:54 - train: epoch 0023, iter [02700, 05004], lr: 0.100000, loss: 2.0996
2022-07-13 10:21:27 - train: epoch 0023, iter [02800, 05004], lr: 0.100000, loss: 2.2662
2022-07-13 10:22:02 - train: epoch 0023, iter [02900, 05004], lr: 0.100000, loss: 2.3066
2022-07-13 10:22:35 - train: epoch 0023, iter [03000, 05004], lr: 0.100000, loss: 2.5088
2022-07-13 10:23:08 - train: epoch 0023, iter [03100, 05004], lr: 0.100000, loss: 2.4192
2022-07-13 10:23:43 - train: epoch 0023, iter [03200, 05004], lr: 0.100000, loss: 2.3831
2022-07-13 10:24:15 - train: epoch 0023, iter [03300, 05004], lr: 0.100000, loss: 2.3594
2022-07-13 10:24:49 - train: epoch 0023, iter [03400, 05004], lr: 0.100000, loss: 2.3841
2022-07-13 10:25:22 - train: epoch 0023, iter [03500, 05004], lr: 0.100000, loss: 2.1519
2022-07-13 10:25:55 - train: epoch 0023, iter [03600, 05004], lr: 0.100000, loss: 2.1129
2022-07-13 10:26:30 - train: epoch 0023, iter [03700, 05004], lr: 0.100000, loss: 2.3447
2022-07-13 10:27:03 - train: epoch 0023, iter [03800, 05004], lr: 0.100000, loss: 2.2841
2022-07-13 10:27:36 - train: epoch 0023, iter [03900, 05004], lr: 0.100000, loss: 2.2602
2022-07-13 10:28:09 - train: epoch 0023, iter [04000, 05004], lr: 0.100000, loss: 2.3102
2022-07-13 10:28:43 - train: epoch 0023, iter [04100, 05004], lr: 0.100000, loss: 2.1665
2022-07-13 10:29:17 - train: epoch 0023, iter [04200, 05004], lr: 0.100000, loss: 2.0974
2022-07-13 10:29:49 - train: epoch 0023, iter [04300, 05004], lr: 0.100000, loss: 2.0056
2022-07-13 10:30:23 - train: epoch 0023, iter [04400, 05004], lr: 0.100000, loss: 2.1275
2022-07-13 10:30:57 - train: epoch 0023, iter [04500, 05004], lr: 0.100000, loss: 2.1378
2022-07-13 10:31:30 - train: epoch 0023, iter [04600, 05004], lr: 0.100000, loss: 2.2314
2022-07-13 10:32:03 - train: epoch 0023, iter [04700, 05004], lr: 0.100000, loss: 2.1079
2022-07-13 10:32:37 - train: epoch 0023, iter [04800, 05004], lr: 0.100000, loss: 2.1666
2022-07-13 10:33:11 - train: epoch 0023, iter [04900, 05004], lr: 0.100000, loss: 2.1626
2022-07-13 10:33:42 - train: epoch 0023, iter [05000, 05004], lr: 0.100000, loss: 2.3515
2022-07-13 10:33:43 - train: epoch 023, train_loss: 2.2653
2022-07-13 10:34:58 - eval: epoch: 023, acc1: 54.086%, acc5: 79.172%, test_loss: 1.9722, per_image_load_time: 2.524ms, per_image_inference_time: 0.299ms
2022-07-13 10:34:58 - until epoch: 023, best_acc1: 54.578%
2022-07-13 10:34:58 - epoch 024 lr: 0.100000
2022-07-13 10:35:37 - train: epoch 0024, iter [00100, 05004], lr: 0.100000, loss: 2.1596
2022-07-13 10:36:11 - train: epoch 0024, iter [00200, 05004], lr: 0.100000, loss: 2.2703
2022-07-13 10:36:44 - train: epoch 0024, iter [00300, 05004], lr: 0.100000, loss: 2.1975
2022-07-13 10:37:17 - train: epoch 0024, iter [00400, 05004], lr: 0.100000, loss: 2.3208
2022-07-13 10:37:51 - train: epoch 0024, iter [00500, 05004], lr: 0.100000, loss: 2.1245
2022-07-13 10:38:24 - train: epoch 0024, iter [00600, 05004], lr: 0.100000, loss: 2.0983
2022-07-13 10:38:57 - train: epoch 0024, iter [00700, 05004], lr: 0.100000, loss: 2.1901
2022-07-13 10:39:30 - train: epoch 0024, iter [00800, 05004], lr: 0.100000, loss: 2.1297
2022-07-13 10:40:04 - train: epoch 0024, iter [00900, 05004], lr: 0.100000, loss: 2.2715
2022-07-13 10:40:37 - train: epoch 0024, iter [01000, 05004], lr: 0.100000, loss: 2.2197
2022-07-13 10:41:10 - train: epoch 0024, iter [01100, 05004], lr: 0.100000, loss: 1.9663
2022-07-13 10:41:44 - train: epoch 0024, iter [01200, 05004], lr: 0.100000, loss: 2.0945
2022-07-13 10:42:18 - train: epoch 0024, iter [01300, 05004], lr: 0.100000, loss: 2.6862
2022-07-13 10:42:51 - train: epoch 0024, iter [01400, 05004], lr: 0.100000, loss: 2.1604
2022-07-13 10:43:24 - train: epoch 0024, iter [01500, 05004], lr: 0.100000, loss: 2.4549
2022-07-13 10:43:58 - train: epoch 0024, iter [01600, 05004], lr: 0.100000, loss: 2.3846
2022-07-13 10:44:31 - train: epoch 0024, iter [01700, 05004], lr: 0.100000, loss: 2.3523
2022-07-13 10:45:05 - train: epoch 0024, iter [01800, 05004], lr: 0.100000, loss: 2.5236
2022-07-13 10:45:37 - train: epoch 0024, iter [01900, 05004], lr: 0.100000, loss: 2.0519
2022-07-13 10:46:11 - train: epoch 0024, iter [02000, 05004], lr: 0.100000, loss: 2.2660
2022-07-13 10:46:45 - train: epoch 0024, iter [02100, 05004], lr: 0.100000, loss: 2.1690
2022-07-13 10:47:19 - train: epoch 0024, iter [02200, 05004], lr: 0.100000, loss: 1.9624
2022-07-13 10:47:51 - train: epoch 0024, iter [02300, 05004], lr: 0.100000, loss: 2.2094
2022-07-13 10:48:25 - train: epoch 0024, iter [02400, 05004], lr: 0.100000, loss: 2.2497
2022-07-13 10:48:59 - train: epoch 0024, iter [02500, 05004], lr: 0.100000, loss: 2.1973
2022-07-13 10:49:32 - train: epoch 0024, iter [02600, 05004], lr: 0.100000, loss: 2.1803
2022-07-13 10:50:05 - train: epoch 0024, iter [02700, 05004], lr: 0.100000, loss: 2.4516
2022-07-13 10:50:39 - train: epoch 0024, iter [02800, 05004], lr: 0.100000, loss: 2.3574
2022-07-13 10:51:12 - train: epoch 0024, iter [02900, 05004], lr: 0.100000, loss: 2.3766
2022-07-13 10:51:46 - train: epoch 0024, iter [03000, 05004], lr: 0.100000, loss: 2.1046
2022-07-13 10:52:19 - train: epoch 0024, iter [03100, 05004], lr: 0.100000, loss: 2.1696
2022-07-13 10:52:53 - train: epoch 0024, iter [03200, 05004], lr: 0.100000, loss: 2.3622
2022-07-13 10:53:26 - train: epoch 0024, iter [03300, 05004], lr: 0.100000, loss: 1.9827
2022-07-13 10:54:00 - train: epoch 0024, iter [03400, 05004], lr: 0.100000, loss: 2.3772
2022-07-13 10:54:34 - train: epoch 0024, iter [03500, 05004], lr: 0.100000, loss: 2.1698
2022-07-13 10:55:07 - train: epoch 0024, iter [03600, 05004], lr: 0.100000, loss: 2.3017
2022-07-13 10:55:41 - train: epoch 0024, iter [03700, 05004], lr: 0.100000, loss: 2.2394
2022-07-13 10:56:15 - train: epoch 0024, iter [03800, 05004], lr: 0.100000, loss: 2.5723
2022-07-13 10:56:47 - train: epoch 0024, iter [03900, 05004], lr: 0.100000, loss: 2.2423
2022-07-13 10:57:20 - train: epoch 0024, iter [04000, 05004], lr: 0.100000, loss: 2.2259
2022-07-13 10:57:54 - train: epoch 0024, iter [04100, 05004], lr: 0.100000, loss: 2.1546
2022-07-13 10:58:28 - train: epoch 0024, iter [04200, 05004], lr: 0.100000, loss: 2.3135
2022-07-13 10:59:02 - train: epoch 0024, iter [04300, 05004], lr: 0.100000, loss: 2.1981
2022-07-13 10:59:35 - train: epoch 0024, iter [04400, 05004], lr: 0.100000, loss: 2.2361
2022-07-13 11:00:09 - train: epoch 0024, iter [04500, 05004], lr: 0.100000, loss: 2.1030
2022-07-13 11:00:42 - train: epoch 0024, iter [04600, 05004], lr: 0.100000, loss: 2.3015
2022-07-13 11:01:16 - train: epoch 0024, iter [04700, 05004], lr: 0.100000, loss: 2.2410
2022-07-13 11:01:50 - train: epoch 0024, iter [04800, 05004], lr: 0.100000, loss: 2.1476
2022-07-13 11:02:22 - train: epoch 0024, iter [04900, 05004], lr: 0.100000, loss: 2.3855
2022-07-13 11:02:54 - train: epoch 0024, iter [05000, 05004], lr: 0.100000, loss: 2.4589
2022-07-13 11:02:55 - train: epoch 024, train_loss: 2.2613
2022-07-13 11:04:10 - eval: epoch: 024, acc1: 54.076%, acc5: 79.336%, test_loss: 1.9605, per_image_load_time: 2.587ms, per_image_inference_time: 0.296ms
2022-07-13 11:04:10 - until epoch: 024, best_acc1: 54.578%
2022-07-13 11:04:10 - epoch 025 lr: 0.100000
2022-07-13 11:04:48 - train: epoch 0025, iter [00100, 05004], lr: 0.100000, loss: 2.1207
2022-07-13 11:05:22 - train: epoch 0025, iter [00200, 05004], lr: 0.100000, loss: 1.9888
2022-07-13 11:05:56 - train: epoch 0025, iter [00300, 05004], lr: 0.100000, loss: 2.0788
2022-07-13 11:06:29 - train: epoch 0025, iter [00400, 05004], lr: 0.100000, loss: 2.1362
2022-07-13 11:07:02 - train: epoch 0025, iter [00500, 05004], lr: 0.100000, loss: 2.1216
2022-07-13 11:07:36 - train: epoch 0025, iter [00600, 05004], lr: 0.100000, loss: 2.2204
2022-07-13 11:08:08 - train: epoch 0025, iter [00700, 05004], lr: 0.100000, loss: 2.2168
2022-07-13 11:08:42 - train: epoch 0025, iter [00800, 05004], lr: 0.100000, loss: 2.3165
2022-07-13 11:09:15 - train: epoch 0025, iter [00900, 05004], lr: 0.100000, loss: 2.1500
2022-07-13 11:09:49 - train: epoch 0025, iter [01000, 05004], lr: 0.100000, loss: 2.1835
2022-07-13 11:10:21 - train: epoch 0025, iter [01100, 05004], lr: 0.100000, loss: 2.1296
2022-07-13 11:10:55 - train: epoch 0025, iter [01200, 05004], lr: 0.100000, loss: 2.2407
2022-07-13 11:11:29 - train: epoch 0025, iter [01300, 05004], lr: 0.100000, loss: 2.2330
2022-07-13 11:12:01 - train: epoch 0025, iter [01400, 05004], lr: 0.100000, loss: 2.3339
2022-07-13 11:12:35 - train: epoch 0025, iter [01500, 05004], lr: 0.100000, loss: 2.1151
2022-07-13 11:13:07 - train: epoch 0025, iter [01600, 05004], lr: 0.100000, loss: 1.9396
2022-07-13 11:13:41 - train: epoch 0025, iter [01700, 05004], lr: 0.100000, loss: 2.1780
2022-07-13 11:14:14 - train: epoch 0025, iter [01800, 05004], lr: 0.100000, loss: 2.0110
2022-07-13 11:14:46 - train: epoch 0025, iter [01900, 05004], lr: 0.100000, loss: 2.0886
2022-07-13 11:15:20 - train: epoch 0025, iter [02000, 05004], lr: 0.100000, loss: 2.2675
2022-07-13 11:15:53 - train: epoch 0025, iter [02100, 05004], lr: 0.100000, loss: 2.0634
2022-07-13 11:16:27 - train: epoch 0025, iter [02200, 05004], lr: 0.100000, loss: 2.2705
2022-07-13 11:17:00 - train: epoch 0025, iter [02300, 05004], lr: 0.100000, loss: 2.3303
2022-07-13 11:17:33 - train: epoch 0025, iter [02400, 05004], lr: 0.100000, loss: 2.0839
2022-07-13 11:18:08 - train: epoch 0025, iter [02500, 05004], lr: 0.100000, loss: 2.3592
2022-07-13 11:18:41 - train: epoch 0025, iter [02600, 05004], lr: 0.100000, loss: 2.2583
2022-07-13 11:19:15 - train: epoch 0025, iter [02700, 05004], lr: 0.100000, loss: 2.2567
2022-07-13 11:19:47 - train: epoch 0025, iter [02800, 05004], lr: 0.100000, loss: 2.1786
2022-07-13 11:20:21 - train: epoch 0025, iter [02900, 05004], lr: 0.100000, loss: 2.3779
2022-07-13 11:20:55 - train: epoch 0025, iter [03000, 05004], lr: 0.100000, loss: 2.4927
2022-07-13 11:21:28 - train: epoch 0025, iter [03100, 05004], lr: 0.100000, loss: 2.2265
2022-07-13 11:22:02 - train: epoch 0025, iter [03200, 05004], lr: 0.100000, loss: 2.4340
2022-07-13 11:22:35 - train: epoch 0025, iter [03300, 05004], lr: 0.100000, loss: 2.2580
2022-07-13 11:23:09 - train: epoch 0025, iter [03400, 05004], lr: 0.100000, loss: 2.3927
2022-07-13 11:23:42 - train: epoch 0025, iter [03500, 05004], lr: 0.100000, loss: 2.0998
2022-07-13 11:24:15 - train: epoch 0025, iter [03600, 05004], lr: 0.100000, loss: 2.3636
2022-07-13 11:24:49 - train: epoch 0025, iter [03700, 05004], lr: 0.100000, loss: 2.2315
2022-07-13 11:25:22 - train: epoch 0025, iter [03800, 05004], lr: 0.100000, loss: 2.3147
2022-07-13 11:25:55 - train: epoch 0025, iter [03900, 05004], lr: 0.100000, loss: 2.4408
2022-07-13 11:26:29 - train: epoch 0025, iter [04000, 05004], lr: 0.100000, loss: 2.3710
2022-07-13 11:27:03 - train: epoch 0025, iter [04100, 05004], lr: 0.100000, loss: 2.5063
2022-07-13 11:27:36 - train: epoch 0025, iter [04200, 05004], lr: 0.100000, loss: 2.2419
2022-07-13 11:28:10 - train: epoch 0025, iter [04300, 05004], lr: 0.100000, loss: 2.0398
2022-07-13 11:28:44 - train: epoch 0025, iter [04400, 05004], lr: 0.100000, loss: 2.1656
2022-07-13 11:29:17 - train: epoch 0025, iter [04500, 05004], lr: 0.100000, loss: 2.1465
2022-07-13 11:29:51 - train: epoch 0025, iter [04600, 05004], lr: 0.100000, loss: 2.2367
2022-07-13 11:30:24 - train: epoch 0025, iter [04700, 05004], lr: 0.100000, loss: 2.1899
2022-07-13 11:30:58 - train: epoch 0025, iter [04800, 05004], lr: 0.100000, loss: 2.0822
2022-07-13 11:31:31 - train: epoch 0025, iter [04900, 05004], lr: 0.100000, loss: 2.1814
2022-07-13 11:32:03 - train: epoch 0025, iter [05000, 05004], lr: 0.100000, loss: 2.4614
2022-07-13 11:32:04 - train: epoch 025, train_loss: 2.2558
2022-07-13 11:33:18 - eval: epoch: 025, acc1: 54.560%, acc5: 79.748%, test_loss: 1.9427, per_image_load_time: 2.549ms, per_image_inference_time: 0.290ms
2022-07-13 11:33:19 - until epoch: 025, best_acc1: 54.578%
2022-07-13 11:33:19 - epoch 026 lr: 0.100000
2022-07-13 11:33:58 - train: epoch 0026, iter [00100, 05004], lr: 0.100000, loss: 1.9741
2022-07-13 11:34:31 - train: epoch 0026, iter [00200, 05004], lr: 0.100000, loss: 1.9912
2022-07-13 11:35:05 - train: epoch 0026, iter [00300, 05004], lr: 0.100000, loss: 2.2252
2022-07-13 11:35:37 - train: epoch 0026, iter [00400, 05004], lr: 0.100000, loss: 2.1915
2022-07-13 11:36:11 - train: epoch 0026, iter [00500, 05004], lr: 0.100000, loss: 2.2541
2022-07-13 11:36:44 - train: epoch 0026, iter [00600, 05004], lr: 0.100000, loss: 2.3784
2022-07-13 11:37:17 - train: epoch 0026, iter [00700, 05004], lr: 0.100000, loss: 2.1872
2022-07-13 11:37:51 - train: epoch 0026, iter [00800, 05004], lr: 0.100000, loss: 1.9631
2022-07-13 11:38:24 - train: epoch 0026, iter [00900, 05004], lr: 0.100000, loss: 2.6413
2022-07-13 11:38:57 - train: epoch 0026, iter [01000, 05004], lr: 0.100000, loss: 2.1727
2022-07-13 11:39:30 - train: epoch 0026, iter [01100, 05004], lr: 0.100000, loss: 2.2063
2022-07-13 11:40:04 - train: epoch 0026, iter [01200, 05004], lr: 0.100000, loss: 2.2954
2022-07-13 11:40:37 - train: epoch 0026, iter [01300, 05004], lr: 0.100000, loss: 2.1065
2022-07-13 11:41:11 - train: epoch 0026, iter [01400, 05004], lr: 0.100000, loss: 2.3856
2022-07-13 11:41:44 - train: epoch 0026, iter [01500, 05004], lr: 0.100000, loss: 2.3252
2022-07-13 11:42:17 - train: epoch 0026, iter [01600, 05004], lr: 0.100000, loss: 2.5043
2022-07-13 11:42:51 - train: epoch 0026, iter [01700, 05004], lr: 0.100000, loss: 2.2064
2022-07-13 11:43:24 - train: epoch 0026, iter [01800, 05004], lr: 0.100000, loss: 2.4104
2022-07-13 11:43:58 - train: epoch 0026, iter [01900, 05004], lr: 0.100000, loss: 2.5867
2022-07-13 11:44:31 - train: epoch 0026, iter [02000, 05004], lr: 0.100000, loss: 2.3680
2022-07-13 11:45:05 - train: epoch 0026, iter [02100, 05004], lr: 0.100000, loss: 2.4150
2022-07-13 11:45:38 - train: epoch 0026, iter [02200, 05004], lr: 0.100000, loss: 2.2881
2022-07-13 11:46:12 - train: epoch 0026, iter [02300, 05004], lr: 0.100000, loss: 2.1519
2022-07-13 11:46:45 - train: epoch 0026, iter [02400, 05004], lr: 0.100000, loss: 2.5294
2022-07-13 11:47:19 - train: epoch 0026, iter [02500, 05004], lr: 0.100000, loss: 2.4730
2022-07-13 11:47:52 - train: epoch 0026, iter [02600, 05004], lr: 0.100000, loss: 2.2900
2022-07-13 11:48:26 - train: epoch 0026, iter [02700, 05004], lr: 0.100000, loss: 2.1238
2022-07-13 11:48:59 - train: epoch 0026, iter [02800, 05004], lr: 0.100000, loss: 2.0237
2022-07-13 11:49:33 - train: epoch 0026, iter [02900, 05004], lr: 0.100000, loss: 2.4101
2022-07-13 11:50:06 - train: epoch 0026, iter [03000, 05004], lr: 0.100000, loss: 2.1798
2022-07-13 11:50:39 - train: epoch 0026, iter [03100, 05004], lr: 0.100000, loss: 2.2215
2022-07-13 11:51:13 - train: epoch 0026, iter [03200, 05004], lr: 0.100000, loss: 2.3181
2022-07-13 11:51:46 - train: epoch 0026, iter [03300, 05004], lr: 0.100000, loss: 2.0885
2022-07-13 11:52:19 - train: epoch 0026, iter [03400, 05004], lr: 0.100000, loss: 2.5232
2022-07-13 11:52:53 - train: epoch 0026, iter [03500, 05004], lr: 0.100000, loss: 2.2798
2022-07-13 11:53:26 - train: epoch 0026, iter [03600, 05004], lr: 0.100000, loss: 2.1728
2022-07-13 11:54:00 - train: epoch 0026, iter [03700, 05004], lr: 0.100000, loss: 2.3396
2022-07-13 11:54:34 - train: epoch 0026, iter [03800, 05004], lr: 0.100000, loss: 2.3874
2022-07-13 11:55:07 - train: epoch 0026, iter [03900, 05004], lr: 0.100000, loss: 2.3080
2022-07-13 11:55:40 - train: epoch 0026, iter [04000, 05004], lr: 0.100000, loss: 2.3939
2022-07-13 11:56:14 - train: epoch 0026, iter [04100, 05004], lr: 0.100000, loss: 2.3424
2022-07-13 11:56:47 - train: epoch 0026, iter [04200, 05004], lr: 0.100000, loss: 2.3851
2022-07-13 11:57:21 - train: epoch 0026, iter [04300, 05004], lr: 0.100000, loss: 2.4183
2022-07-13 11:57:54 - train: epoch 0026, iter [04400, 05004], lr: 0.100000, loss: 2.3330
2022-07-13 11:58:28 - train: epoch 0026, iter [04500, 05004], lr: 0.100000, loss: 2.4377
2022-07-13 11:59:01 - train: epoch 0026, iter [04600, 05004], lr: 0.100000, loss: 2.2382
2022-07-13 11:59:35 - train: epoch 0026, iter [04700, 05004], lr: 0.100000, loss: 2.2428
2022-07-13 12:00:08 - train: epoch 0026, iter [04800, 05004], lr: 0.100000, loss: 2.2133
2022-07-13 12:00:41 - train: epoch 0026, iter [04900, 05004], lr: 0.100000, loss: 2.2305
2022-07-13 12:01:13 - train: epoch 0026, iter [05000, 05004], lr: 0.100000, loss: 2.5015
2022-07-13 12:01:13 - train: epoch 026, train_loss: 2.2514
2022-07-13 12:02:28 - eval: epoch: 026, acc1: 53.594%, acc5: 78.690%, test_loss: 1.9935, per_image_load_time: 1.990ms, per_image_inference_time: 0.299ms
2022-07-13 12:02:28 - until epoch: 026, best_acc1: 54.578%
2022-07-13 12:02:28 - epoch 027 lr: 0.100000
2022-07-13 12:03:07 - train: epoch 0027, iter [00100, 05004], lr: 0.100000, loss: 2.2923
2022-07-13 12:03:40 - train: epoch 0027, iter [00200, 05004], lr: 0.100000, loss: 2.1564
2022-07-13 12:04:13 - train: epoch 0027, iter [00300, 05004], lr: 0.100000, loss: 2.3714
2022-07-13 12:04:48 - train: epoch 0027, iter [00400, 05004], lr: 0.100000, loss: 2.3673
2022-07-13 12:05:20 - train: epoch 0027, iter [00500, 05004], lr: 0.100000, loss: 2.3146
2022-07-13 12:05:54 - train: epoch 0027, iter [00600, 05004], lr: 0.100000, loss: 2.5433
2022-07-13 12:06:27 - train: epoch 0027, iter [00700, 05004], lr: 0.100000, loss: 2.5011
2022-07-13 12:07:00 - train: epoch 0027, iter [00800, 05004], lr: 0.100000, loss: 2.2590
2022-07-13 12:07:33 - train: epoch 0027, iter [00900, 05004], lr: 0.100000, loss: 2.1799
2022-07-13 12:08:07 - train: epoch 0027, iter [01000, 05004], lr: 0.100000, loss: 2.2435
2022-07-13 12:08:40 - train: epoch 0027, iter [01100, 05004], lr: 0.100000, loss: 2.2273
2022-07-13 12:09:14 - train: epoch 0027, iter [01200, 05004], lr: 0.100000, loss: 2.6768
2022-07-13 12:09:47 - train: epoch 0027, iter [01300, 05004], lr: 0.100000, loss: 2.3749
2022-07-13 12:10:21 - train: epoch 0027, iter [01400, 05004], lr: 0.100000, loss: 2.4602
2022-07-13 12:10:54 - train: epoch 0027, iter [01500, 05004], lr: 0.100000, loss: 2.3685
2022-07-13 12:11:27 - train: epoch 0027, iter [01600, 05004], lr: 0.100000, loss: 2.3262
2022-07-13 12:12:00 - train: epoch 0027, iter [01700, 05004], lr: 0.100000, loss: 2.3513
2022-07-13 12:12:33 - train: epoch 0027, iter [01800, 05004], lr: 0.100000, loss: 2.2064
2022-07-13 12:13:06 - train: epoch 0027, iter [01900, 05004], lr: 0.100000, loss: 2.2717
2022-07-13 12:13:40 - train: epoch 0027, iter [02000, 05004], lr: 0.100000, loss: 2.2156
2022-07-13 12:14:13 - train: epoch 0027, iter [02100, 05004], lr: 0.100000, loss: 2.5107
2022-07-13 12:14:47 - train: epoch 0027, iter [02200, 05004], lr: 0.100000, loss: 2.3887
2022-07-13 12:15:20 - train: epoch 0027, iter [02300, 05004], lr: 0.100000, loss: 2.4623
2022-07-13 12:15:54 - train: epoch 0027, iter [02400, 05004], lr: 0.100000, loss: 2.1804
2022-07-13 12:16:26 - train: epoch 0027, iter [02500, 05004], lr: 0.100000, loss: 1.9984
2022-07-13 12:17:00 - train: epoch 0027, iter [02600, 05004], lr: 0.100000, loss: 2.5266
2022-07-13 12:17:33 - train: epoch 0027, iter [02700, 05004], lr: 0.100000, loss: 2.1765
2022-07-13 12:18:07 - train: epoch 0027, iter [02800, 05004], lr: 0.100000, loss: 2.4468
2022-07-13 12:18:39 - train: epoch 0027, iter [02900, 05004], lr: 0.100000, loss: 2.3955
2022-07-13 12:19:14 - train: epoch 0027, iter [03000, 05004], lr: 0.100000, loss: 2.0469
2022-07-13 12:19:47 - train: epoch 0027, iter [03100, 05004], lr: 0.100000, loss: 2.1094
2022-07-13 12:20:21 - train: epoch 0027, iter [03200, 05004], lr: 0.100000, loss: 2.1167
2022-07-13 12:20:53 - train: epoch 0027, iter [03300, 05004], lr: 0.100000, loss: 2.3236
2022-07-13 12:21:27 - train: epoch 0027, iter [03400, 05004], lr: 0.100000, loss: 2.1882
2022-07-13 12:22:01 - train: epoch 0027, iter [03500, 05004], lr: 0.100000, loss: 2.4934
2022-07-13 12:22:34 - train: epoch 0027, iter [03600, 05004], lr: 0.100000, loss: 2.0849
2022-07-13 12:23:07 - train: epoch 0027, iter [03700, 05004], lr: 0.100000, loss: 2.0526
2022-07-13 12:23:40 - train: epoch 0027, iter [03800, 05004], lr: 0.100000, loss: 2.0134
2022-07-13 12:24:14 - train: epoch 0027, iter [03900, 05004], lr: 0.100000, loss: 2.0544
2022-07-13 12:24:47 - train: epoch 0027, iter [04000, 05004], lr: 0.100000, loss: 2.3912
2022-07-13 12:25:20 - train: epoch 0027, iter [04100, 05004], lr: 0.100000, loss: 2.2743
2022-07-13 12:25:54 - train: epoch 0027, iter [04200, 05004], lr: 0.100000, loss: 2.3332
2022-07-13 12:26:28 - train: epoch 0027, iter [04300, 05004], lr: 0.100000, loss: 2.1443
2022-07-13 12:27:02 - train: epoch 0027, iter [04400, 05004], lr: 0.100000, loss: 2.3138
2022-07-13 12:27:34 - train: epoch 0027, iter [04500, 05004], lr: 0.100000, loss: 2.0184
2022-07-13 12:28:08 - train: epoch 0027, iter [04600, 05004], lr: 0.100000, loss: 2.1941
2022-07-13 12:28:42 - train: epoch 0027, iter [04700, 05004], lr: 0.100000, loss: 2.2495
2022-07-13 12:29:15 - train: epoch 0027, iter [04800, 05004], lr: 0.100000, loss: 2.3822
2022-07-13 12:29:49 - train: epoch 0027, iter [04900, 05004], lr: 0.100000, loss: 2.3355
2022-07-13 12:30:20 - train: epoch 0027, iter [05000, 05004], lr: 0.100000, loss: 1.9938
2022-07-13 12:30:21 - train: epoch 027, train_loss: 2.2481
2022-07-13 12:31:35 - eval: epoch: 027, acc1: 54.870%, acc5: 79.524%, test_loss: 1.9334, per_image_load_time: 2.548ms, per_image_inference_time: 0.295ms
2022-07-13 12:31:36 - until epoch: 027, best_acc1: 54.870%
2022-07-13 12:31:36 - epoch 028 lr: 0.100000
2022-07-13 12:32:15 - train: epoch 0028, iter [00100, 05004], lr: 0.100000, loss: 2.0235
2022-07-13 12:32:48 - train: epoch 0028, iter [00200, 05004], lr: 0.100000, loss: 2.2188
2022-07-13 12:33:21 - train: epoch 0028, iter [00300, 05004], lr: 0.100000, loss: 2.1860
2022-07-13 12:33:55 - train: epoch 0028, iter [00400, 05004], lr: 0.100000, loss: 2.1156
2022-07-13 12:34:27 - train: epoch 0028, iter [00500, 05004], lr: 0.100000, loss: 2.2324
2022-07-13 12:35:01 - train: epoch 0028, iter [00600, 05004], lr: 0.100000, loss: 2.3254
2022-07-13 12:35:34 - train: epoch 0028, iter [00700, 05004], lr: 0.100000, loss: 2.5055
2022-07-13 12:36:07 - train: epoch 0028, iter [00800, 05004], lr: 0.100000, loss: 1.9072
2022-07-13 12:36:40 - train: epoch 0028, iter [00900, 05004], lr: 0.100000, loss: 2.0217
2022-07-13 12:37:13 - train: epoch 0028, iter [01000, 05004], lr: 0.100000, loss: 2.3013
2022-07-13 12:37:47 - train: epoch 0028, iter [01100, 05004], lr: 0.100000, loss: 2.2907
2022-07-13 12:38:20 - train: epoch 0028, iter [01200, 05004], lr: 0.100000, loss: 1.9903
2022-07-13 12:38:54 - train: epoch 0028, iter [01300, 05004], lr: 0.100000, loss: 2.2381
2022-07-13 12:39:27 - train: epoch 0028, iter [01400, 05004], lr: 0.100000, loss: 2.5776
2022-07-13 12:40:01 - train: epoch 0028, iter [01500, 05004], lr: 0.100000, loss: 2.2246
2022-07-13 12:40:33 - train: epoch 0028, iter [01600, 05004], lr: 0.100000, loss: 2.1921
2022-07-13 12:41:07 - train: epoch 0028, iter [01700, 05004], lr: 0.100000, loss: 2.2133
2022-07-13 12:41:40 - train: epoch 0028, iter [01800, 05004], lr: 0.100000, loss: 2.1339
2022-07-13 12:42:14 - train: epoch 0028, iter [01900, 05004], lr: 0.100000, loss: 2.2903
2022-07-13 12:42:48 - train: epoch 0028, iter [02000, 05004], lr: 0.100000, loss: 2.4369
2022-07-13 12:43:21 - train: epoch 0028, iter [02100, 05004], lr: 0.100000, loss: 2.3169
2022-07-13 12:43:54 - train: epoch 0028, iter [02200, 05004], lr: 0.100000, loss: 2.3612
2022-07-13 12:44:28 - train: epoch 0028, iter [02300, 05004], lr: 0.100000, loss: 2.4080
2022-07-13 12:45:02 - train: epoch 0028, iter [02400, 05004], lr: 0.100000, loss: 2.3924
2022-07-13 12:45:35 - train: epoch 0028, iter [02500, 05004], lr: 0.100000, loss: 2.2728
2022-07-13 12:46:07 - train: epoch 0028, iter [02600, 05004], lr: 0.100000, loss: 2.0088
2022-07-13 12:46:41 - train: epoch 0028, iter [02700, 05004], lr: 0.100000, loss: 2.2921
2022-07-13 12:47:14 - train: epoch 0028, iter [02800, 05004], lr: 0.100000, loss: 2.2765
2022-07-13 12:47:49 - train: epoch 0028, iter [02900, 05004], lr: 0.100000, loss: 2.2414
2022-07-13 12:48:22 - train: epoch 0028, iter [03000, 05004], lr: 0.100000, loss: 2.3360
2022-07-13 12:48:56 - train: epoch 0028, iter [03100, 05004], lr: 0.100000, loss: 2.4025
2022-07-13 12:49:30 - train: epoch 0028, iter [03200, 05004], lr: 0.100000, loss: 2.2087
2022-07-13 12:50:03 - train: epoch 0028, iter [03300, 05004], lr: 0.100000, loss: 2.3108
2022-07-13 12:50:37 - train: epoch 0028, iter [03400, 05004], lr: 0.100000, loss: 2.3043
2022-07-13 12:51:10 - train: epoch 0028, iter [03500, 05004], lr: 0.100000, loss: 2.1592
2022-07-13 12:51:43 - train: epoch 0028, iter [03600, 05004], lr: 0.100000, loss: 2.0531
2022-07-13 12:52:17 - train: epoch 0028, iter [03700, 05004], lr: 0.100000, loss: 2.1609
2022-07-13 12:52:50 - train: epoch 0028, iter [03800, 05004], lr: 0.100000, loss: 1.9837
2022-07-13 12:53:24 - train: epoch 0028, iter [03900, 05004], lr: 0.100000, loss: 2.1619
2022-07-13 12:53:58 - train: epoch 0028, iter [04000, 05004], lr: 0.100000, loss: 2.3845
2022-07-13 12:54:31 - train: epoch 0028, iter [04100, 05004], lr: 0.100000, loss: 2.3111
2022-07-13 12:55:05 - train: epoch 0028, iter [04200, 05004], lr: 0.100000, loss: 2.4326
2022-07-13 12:55:38 - train: epoch 0028, iter [04300, 05004], lr: 0.100000, loss: 2.1703
2022-07-13 12:56:12 - train: epoch 0028, iter [04400, 05004], lr: 0.100000, loss: 2.1900
2022-07-13 12:56:45 - train: epoch 0028, iter [04500, 05004], lr: 0.100000, loss: 2.1591
2022-07-13 12:57:20 - train: epoch 0028, iter [04600, 05004], lr: 0.100000, loss: 2.3182
2022-07-13 12:57:52 - train: epoch 0028, iter [04700, 05004], lr: 0.100000, loss: 2.2505
2022-07-13 12:58:26 - train: epoch 0028, iter [04800, 05004], lr: 0.100000, loss: 2.1705
2022-07-13 12:58:59 - train: epoch 0028, iter [04900, 05004], lr: 0.100000, loss: 2.1829
2022-07-13 12:59:32 - train: epoch 0028, iter [05000, 05004], lr: 0.100000, loss: 2.2275
2022-07-13 12:59:33 - train: epoch 028, train_loss: 2.2416
2022-07-13 13:00:48 - eval: epoch: 028, acc1: 54.642%, acc5: 79.456%, test_loss: 1.9494, per_image_load_time: 1.533ms, per_image_inference_time: 0.294ms
2022-07-13 13:00:48 - until epoch: 028, best_acc1: 54.870%
2022-07-13 13:00:48 - epoch 029 lr: 0.100000
2022-07-13 13:01:27 - train: epoch 0029, iter [00100, 05004], lr: 0.100000, loss: 2.3101
2022-07-13 13:02:01 - train: epoch 0029, iter [00200, 05004], lr: 0.100000, loss: 2.2251
2022-07-13 13:02:34 - train: epoch 0029, iter [00300, 05004], lr: 0.100000, loss: 2.2746
2022-07-13 13:03:07 - train: epoch 0029, iter [00400, 05004], lr: 0.100000, loss: 2.1760
2022-07-13 13:03:41 - train: epoch 0029, iter [00500, 05004], lr: 0.100000, loss: 2.2251
2022-07-13 13:04:14 - train: epoch 0029, iter [00600, 05004], lr: 0.100000, loss: 2.4778
2022-07-13 13:04:47 - train: epoch 0029, iter [00700, 05004], lr: 0.100000, loss: 1.7071
2022-07-13 13:05:20 - train: epoch 0029, iter [00800, 05004], lr: 0.100000, loss: 2.3662
2022-07-13 13:05:54 - train: epoch 0029, iter [00900, 05004], lr: 0.100000, loss: 2.0996
2022-07-13 13:06:28 - train: epoch 0029, iter [01000, 05004], lr: 0.100000, loss: 2.0293
2022-07-13 13:07:00 - train: epoch 0029, iter [01100, 05004], lr: 0.100000, loss: 2.1720
2022-07-13 13:07:35 - train: epoch 0029, iter [01200, 05004], lr: 0.100000, loss: 2.3362
2022-07-13 13:08:07 - train: epoch 0029, iter [01300, 05004], lr: 0.100000, loss: 2.0957
2022-07-13 13:08:41 - train: epoch 0029, iter [01400, 05004], lr: 0.100000, loss: 2.4705
2022-07-13 13:09:14 - train: epoch 0029, iter [01500, 05004], lr: 0.100000, loss: 2.3193
2022-07-13 13:09:48 - train: epoch 0029, iter [01600, 05004], lr: 0.100000, loss: 2.1699
2022-07-13 13:10:21 - train: epoch 0029, iter [01700, 05004], lr: 0.100000, loss: 2.2142
2022-07-13 13:10:54 - train: epoch 0029, iter [01800, 05004], lr: 0.100000, loss: 2.4556
2022-07-13 13:11:27 - train: epoch 0029, iter [01900, 05004], lr: 0.100000, loss: 2.0755
2022-07-13 13:12:01 - train: epoch 0029, iter [02000, 05004], lr: 0.100000, loss: 2.3958
2022-07-13 13:12:34 - train: epoch 0029, iter [02100, 05004], lr: 0.100000, loss: 2.1866
2022-07-13 13:13:08 - train: epoch 0029, iter [02200, 05004], lr: 0.100000, loss: 2.3142
2022-07-13 13:13:41 - train: epoch 0029, iter [02300, 05004], lr: 0.100000, loss: 2.2959
2022-07-13 13:14:15 - train: epoch 0029, iter [02400, 05004], lr: 0.100000, loss: 2.1092
2022-07-13 13:14:48 - train: epoch 0029, iter [02500, 05004], lr: 0.100000, loss: 2.1003
2022-07-13 13:15:22 - train: epoch 0029, iter [02600, 05004], lr: 0.100000, loss: 2.3152
2022-07-13 13:15:55 - train: epoch 0029, iter [02700, 05004], lr: 0.100000, loss: 2.1753
2022-07-13 13:16:29 - train: epoch 0029, iter [02800, 05004], lr: 0.100000, loss: 2.1808
2022-07-13 13:17:02 - train: epoch 0029, iter [02900, 05004], lr: 0.100000, loss: 2.1962
2022-07-13 13:17:36 - train: epoch 0029, iter [03000, 05004], lr: 0.100000, loss: 2.3820
2022-07-13 13:18:10 - train: epoch 0029, iter [03100, 05004], lr: 0.100000, loss: 2.2848
2022-07-13 13:18:43 - train: epoch 0029, iter [03200, 05004], lr: 0.100000, loss: 2.2251
2022-07-13 13:19:17 - train: epoch 0029, iter [03300, 05004], lr: 0.100000, loss: 2.1080
2022-07-13 13:19:50 - train: epoch 0029, iter [03400, 05004], lr: 0.100000, loss: 2.0664
2022-07-13 13:20:24 - train: epoch 0029, iter [03500, 05004], lr: 0.100000, loss: 2.3853
2022-07-13 13:20:56 - train: epoch 0029, iter [03600, 05004], lr: 0.100000, loss: 2.1633
2022-07-13 13:21:31 - train: epoch 0029, iter [03700, 05004], lr: 0.100000, loss: 2.1881
2022-07-13 13:22:03 - train: epoch 0029, iter [03800, 05004], lr: 0.100000, loss: 2.2394
2022-07-13 13:22:37 - train: epoch 0029, iter [03900, 05004], lr: 0.100000, loss: 2.1395
2022-07-13 13:23:11 - train: epoch 0029, iter [04000, 05004], lr: 0.100000, loss: 2.1853
2022-07-13 13:23:45 - train: epoch 0029, iter [04100, 05004], lr: 0.100000, loss: 2.1651
2022-07-13 13:24:18 - train: epoch 0029, iter [04200, 05004], lr: 0.100000, loss: 2.1622
2022-07-13 13:24:51 - train: epoch 0029, iter [04300, 05004], lr: 0.100000, loss: 2.3091
2022-07-13 13:25:25 - train: epoch 0029, iter [04400, 05004], lr: 0.100000, loss: 2.1963
2022-07-13 13:25:58 - train: epoch 0029, iter [04500, 05004], lr: 0.100000, loss: 2.2855
2022-07-13 13:26:31 - train: epoch 0029, iter [04600, 05004], lr: 0.100000, loss: 2.4539
2022-07-13 13:27:05 - train: epoch 0029, iter [04700, 05004], lr: 0.100000, loss: 2.0573
2022-07-13 13:27:39 - train: epoch 0029, iter [04800, 05004], lr: 0.100000, loss: 2.2524
2022-07-13 13:28:12 - train: epoch 0029, iter [04900, 05004], lr: 0.100000, loss: 2.6387
2022-07-13 13:28:44 - train: epoch 0029, iter [05000, 05004], lr: 0.100000, loss: 2.1183
2022-07-13 13:28:45 - train: epoch 029, train_loss: 2.2389
2022-07-13 13:29:59 - eval: epoch: 029, acc1: 54.468%, acc5: 79.540%, test_loss: 1.9442, per_image_load_time: 2.568ms, per_image_inference_time: 0.309ms
2022-07-13 13:30:00 - until epoch: 029, best_acc1: 54.870%
2022-07-13 13:30:00 - epoch 030 lr: 0.100000
2022-07-13 13:30:38 - train: epoch 0030, iter [00100, 05004], lr: 0.100000, loss: 2.3475
2022-07-13 13:31:11 - train: epoch 0030, iter [00200, 05004], lr: 0.100000, loss: 2.2808
2022-07-13 13:31:44 - train: epoch 0030, iter [00300, 05004], lr: 0.100000, loss: 2.0873
2022-07-13 13:32:18 - train: epoch 0030, iter [00400, 05004], lr: 0.100000, loss: 1.9332
2022-07-13 13:32:51 - train: epoch 0030, iter [00500, 05004], lr: 0.100000, loss: 2.4034
2022-07-13 13:33:24 - train: epoch 0030, iter [00600, 05004], lr: 0.100000, loss: 2.0254
2022-07-13 13:33:58 - train: epoch 0030, iter [00700, 05004], lr: 0.100000, loss: 2.2241
2022-07-13 13:34:32 - train: epoch 0030, iter [00800, 05004], lr: 0.100000, loss: 2.3259
2022-07-13 13:35:05 - train: epoch 0030, iter [00900, 05004], lr: 0.100000, loss: 2.1912
2022-07-13 13:35:38 - train: epoch 0030, iter [01000, 05004], lr: 0.100000, loss: 1.9896
2022-07-13 13:36:12 - train: epoch 0030, iter [01100, 05004], lr: 0.100000, loss: 2.0009
2022-07-13 13:36:45 - train: epoch 0030, iter [01200, 05004], lr: 0.100000, loss: 2.1434
2022-07-13 13:37:20 - train: epoch 0030, iter [01300, 05004], lr: 0.100000, loss: 2.0015
2022-07-13 13:37:53 - train: epoch 0030, iter [01400, 05004], lr: 0.100000, loss: 2.0425
2022-07-13 13:38:27 - train: epoch 0030, iter [01500, 05004], lr: 0.100000, loss: 2.2099
2022-07-13 13:39:00 - train: epoch 0030, iter [01600, 05004], lr: 0.100000, loss: 2.1828
2022-07-13 13:39:33 - train: epoch 0030, iter [01700, 05004], lr: 0.100000, loss: 2.5134
2022-07-13 13:40:06 - train: epoch 0030, iter [01800, 05004], lr: 0.100000, loss: 2.2804
2022-07-13 13:40:40 - train: epoch 0030, iter [01900, 05004], lr: 0.100000, loss: 2.4635
2022-07-13 13:41:12 - train: epoch 0030, iter [02000, 05004], lr: 0.100000, loss: 2.2389
2022-07-13 13:41:46 - train: epoch 0030, iter [02100, 05004], lr: 0.100000, loss: 2.4325
2022-07-13 13:42:19 - train: epoch 0030, iter [02200, 05004], lr: 0.100000, loss: 2.1974
2022-07-13 13:42:53 - train: epoch 0030, iter [02300, 05004], lr: 0.100000, loss: 2.2224
2022-07-13 13:43:26 - train: epoch 0030, iter [02400, 05004], lr: 0.100000, loss: 2.3790
2022-07-13 13:43:59 - train: epoch 0030, iter [02500, 05004], lr: 0.100000, loss: 2.2302
2022-07-13 13:44:33 - train: epoch 0030, iter [02600, 05004], lr: 0.100000, loss: 2.1687
2022-07-13 13:45:06 - train: epoch 0030, iter [02700, 05004], lr: 0.100000, loss: 2.1741
2022-07-13 13:45:40 - train: epoch 0030, iter [02800, 05004], lr: 0.100000, loss: 2.2728
2022-07-13 13:46:13 - train: epoch 0030, iter [02900, 05004], lr: 0.100000, loss: 2.3155
2022-07-13 13:46:46 - train: epoch 0030, iter [03000, 05004], lr: 0.100000, loss: 2.4777
2022-07-13 13:47:19 - train: epoch 0030, iter [03100, 05004], lr: 0.100000, loss: 2.2010
2022-07-13 13:47:53 - train: epoch 0030, iter [03200, 05004], lr: 0.100000, loss: 2.1830
2022-07-13 13:48:26 - train: epoch 0030, iter [03300, 05004], lr: 0.100000, loss: 2.5087
2022-07-13 13:49:00 - train: epoch 0030, iter [03400, 05004], lr: 0.100000, loss: 2.3626
2022-07-13 13:49:34 - train: epoch 0030, iter [03500, 05004], lr: 0.100000, loss: 2.2323
2022-07-13 13:50:07 - train: epoch 0030, iter [03600, 05004], lr: 0.100000, loss: 2.0874
2022-07-13 13:50:40 - train: epoch 0030, iter [03700, 05004], lr: 0.100000, loss: 2.2339
2022-07-13 13:51:13 - train: epoch 0030, iter [03800, 05004], lr: 0.100000, loss: 2.4456
2022-07-13 13:51:47 - train: epoch 0030, iter [03900, 05004], lr: 0.100000, loss: 2.2180
2022-07-13 13:52:21 - train: epoch 0030, iter [04000, 05004], lr: 0.100000, loss: 2.0430
2022-07-13 13:52:54 - train: epoch 0030, iter [04100, 05004], lr: 0.100000, loss: 2.1308
2022-07-13 13:53:28 - train: epoch 0030, iter [04200, 05004], lr: 0.100000, loss: 2.4857
2022-07-13 13:54:01 - train: epoch 0030, iter [04300, 05004], lr: 0.100000, loss: 2.2325
2022-07-13 13:54:34 - train: epoch 0030, iter [04400, 05004], lr: 0.100000, loss: 2.2501
2022-07-13 13:55:08 - train: epoch 0030, iter [04500, 05004], lr: 0.100000, loss: 2.5235
2022-07-13 13:55:41 - train: epoch 0030, iter [04600, 05004], lr: 0.100000, loss: 1.9073
2022-07-13 13:56:15 - train: epoch 0030, iter [04700, 05004], lr: 0.100000, loss: 2.2402
2022-07-13 13:56:48 - train: epoch 0030, iter [04800, 05004], lr: 0.100000, loss: 2.2910
2022-07-13 13:57:23 - train: epoch 0030, iter [04900, 05004], lr: 0.100000, loss: 2.4497
2022-07-13 13:57:54 - train: epoch 0030, iter [05000, 05004], lr: 0.100000, loss: 2.3479
2022-07-13 13:57:56 - train: epoch 030, train_loss: 2.2386
2022-07-13 13:59:09 - eval: epoch: 030, acc1: 54.974%, acc5: 79.886%, test_loss: 1.9251, per_image_load_time: 1.628ms, per_image_inference_time: 0.308ms
2022-07-13 13:59:10 - until epoch: 030, best_acc1: 54.974%
2022-07-13 13:59:10 - epoch 031 lr: 0.010000
2022-07-13 13:59:48 - train: epoch 0031, iter [00100, 05004], lr: 0.010000, loss: 2.1550
2022-07-13 14:00:23 - train: epoch 0031, iter [00200, 05004], lr: 0.010000, loss: 1.8695
2022-07-13 14:00:55 - train: epoch 0031, iter [00300, 05004], lr: 0.010000, loss: 1.8950
2022-07-13 14:01:29 - train: epoch 0031, iter [00400, 05004], lr: 0.010000, loss: 1.9237
2022-07-13 14:02:01 - train: epoch 0031, iter [00500, 05004], lr: 0.010000, loss: 1.7865
2022-07-13 14:02:35 - train: epoch 0031, iter [00600, 05004], lr: 0.010000, loss: 1.7654
2022-07-13 14:03:08 - train: epoch 0031, iter [00700, 05004], lr: 0.010000, loss: 1.7466
2022-07-13 14:03:41 - train: epoch 0031, iter [00800, 05004], lr: 0.010000, loss: 1.6563
2022-07-13 14:04:14 - train: epoch 0031, iter [00900, 05004], lr: 0.010000, loss: 1.6623
2022-07-13 14:04:48 - train: epoch 0031, iter [01000, 05004], lr: 0.010000, loss: 1.9872
2022-07-13 14:05:20 - train: epoch 0031, iter [01100, 05004], lr: 0.010000, loss: 1.9508
2022-07-13 14:05:54 - train: epoch 0031, iter [01200, 05004], lr: 0.010000, loss: 1.6732
2022-07-13 14:06:27 - train: epoch 0031, iter [01300, 05004], lr: 0.010000, loss: 1.5223
2022-07-13 14:07:01 - train: epoch 0031, iter [01400, 05004], lr: 0.010000, loss: 1.7615
2022-07-13 14:07:34 - train: epoch 0031, iter [01500, 05004], lr: 0.010000, loss: 1.8159
2022-07-13 14:08:07 - train: epoch 0031, iter [01600, 05004], lr: 0.010000, loss: 1.6073
2022-07-13 14:08:40 - train: epoch 0031, iter [01700, 05004], lr: 0.010000, loss: 1.6982
2022-07-13 14:09:14 - train: epoch 0031, iter [01800, 05004], lr: 0.010000, loss: 1.6028
2022-07-13 14:09:47 - train: epoch 0031, iter [01900, 05004], lr: 0.010000, loss: 1.7717
2022-07-13 14:10:20 - train: epoch 0031, iter [02000, 05004], lr: 0.010000, loss: 1.7796
2022-07-13 14:10:54 - train: epoch 0031, iter [02100, 05004], lr: 0.010000, loss: 1.5309
2022-07-13 14:11:27 - train: epoch 0031, iter [02200, 05004], lr: 0.010000, loss: 1.5127
2022-07-13 14:12:01 - train: epoch 0031, iter [02300, 05004], lr: 0.010000, loss: 1.5256
2022-07-13 14:12:34 - train: epoch 0031, iter [02400, 05004], lr: 0.010000, loss: 1.6601
2022-07-13 14:13:07 - train: epoch 0031, iter [02500, 05004], lr: 0.010000, loss: 1.6750
2022-07-13 14:13:41 - train: epoch 0031, iter [02600, 05004], lr: 0.010000, loss: 1.6449
2022-07-13 14:14:15 - train: epoch 0031, iter [02700, 05004], lr: 0.010000, loss: 1.6131
2022-07-13 14:14:48 - train: epoch 0031, iter [02800, 05004], lr: 0.010000, loss: 1.9827
2022-07-13 14:15:21 - train: epoch 0031, iter [02900, 05004], lr: 0.010000, loss: 1.7717
2022-07-13 14:15:54 - train: epoch 0031, iter [03000, 05004], lr: 0.010000, loss: 1.7436
2022-07-13 14:16:27 - train: epoch 0031, iter [03100, 05004], lr: 0.010000, loss: 1.5450
2022-07-13 14:17:01 - train: epoch 0031, iter [03200, 05004], lr: 0.010000, loss: 1.7585
2022-07-13 14:17:35 - train: epoch 0031, iter [03300, 05004], lr: 0.010000, loss: 1.7269
2022-07-13 14:18:08 - train: epoch 0031, iter [03400, 05004], lr: 0.010000, loss: 1.8482
2022-07-13 14:18:41 - train: epoch 0031, iter [03500, 05004], lr: 0.010000, loss: 1.7787
2022-07-13 14:19:16 - train: epoch 0031, iter [03600, 05004], lr: 0.010000, loss: 1.7380
2022-07-13 14:19:49 - train: epoch 0031, iter [03700, 05004], lr: 0.010000, loss: 1.6906
2022-07-13 14:20:22 - train: epoch 0031, iter [03800, 05004], lr: 0.010000, loss: 1.5322
2022-07-13 14:20:56 - train: epoch 0031, iter [03900, 05004], lr: 0.010000, loss: 1.5466
2022-07-13 14:21:30 - train: epoch 0031, iter [04000, 05004], lr: 0.010000, loss: 1.5563
2022-07-13 14:22:03 - train: epoch 0031, iter [04100, 05004], lr: 0.010000, loss: 1.6234
2022-07-13 14:22:37 - train: epoch 0031, iter [04200, 05004], lr: 0.010000, loss: 1.6375
2022-07-13 14:23:10 - train: epoch 0031, iter [04300, 05004], lr: 0.010000, loss: 1.5861
2022-07-13 14:23:45 - train: epoch 0031, iter [04400, 05004], lr: 0.010000, loss: 1.7717
2022-07-13 14:24:18 - train: epoch 0031, iter [04500, 05004], lr: 0.010000, loss: 1.7517
2022-07-13 14:24:51 - train: epoch 0031, iter [04600, 05004], lr: 0.010000, loss: 1.6548
2022-07-13 14:25:24 - train: epoch 0031, iter [04700, 05004], lr: 0.010000, loss: 1.6774
2022-07-13 14:25:58 - train: epoch 0031, iter [04800, 05004], lr: 0.010000, loss: 1.5641
2022-07-13 14:26:32 - train: epoch 0031, iter [04900, 05004], lr: 0.010000, loss: 1.5557
2022-07-13 14:27:04 - train: epoch 0031, iter [05000, 05004], lr: 0.010000, loss: 1.5771
2022-07-13 14:27:05 - train: epoch 031, train_loss: 1.7080
2022-07-13 14:28:20 - eval: epoch: 031, acc1: 67.308%, acc5: 87.666%, test_loss: 1.3474, per_image_load_time: 1.733ms, per_image_inference_time: 0.277ms
2022-07-13 14:28:20 - until epoch: 031, best_acc1: 67.308%
2022-07-13 14:28:20 - epoch 032 lr: 0.010000
2022-07-13 14:28:59 - train: epoch 0032, iter [00100, 05004], lr: 0.010000, loss: 1.5755
2022-07-13 14:29:33 - train: epoch 0032, iter [00200, 05004], lr: 0.010000, loss: 1.7018
2022-07-13 14:30:06 - train: epoch 0032, iter [00300, 05004], lr: 0.010000, loss: 1.6118
2022-07-13 14:30:40 - train: epoch 0032, iter [00400, 05004], lr: 0.010000, loss: 1.7548
2022-07-13 14:31:13 - train: epoch 0032, iter [00500, 05004], lr: 0.010000, loss: 1.6622
2022-07-13 14:31:46 - train: epoch 0032, iter [00600, 05004], lr: 0.010000, loss: 1.6520
2022-07-13 14:32:19 - train: epoch 0032, iter [00700, 05004], lr: 0.010000, loss: 1.6363
2022-07-13 14:32:51 - train: epoch 0032, iter [00800, 05004], lr: 0.010000, loss: 1.6492
2022-07-13 14:33:25 - train: epoch 0032, iter [00900, 05004], lr: 0.010000, loss: 1.6058
2022-07-13 14:33:59 - train: epoch 0032, iter [01000, 05004], lr: 0.010000, loss: 1.6845
2022-07-13 14:34:32 - train: epoch 0032, iter [01100, 05004], lr: 0.010000, loss: 1.7408
2022-07-13 14:35:05 - train: epoch 0032, iter [01200, 05004], lr: 0.010000, loss: 1.6027
2022-07-13 14:35:38 - train: epoch 0032, iter [01300, 05004], lr: 0.010000, loss: 1.5185
2022-07-13 14:36:12 - train: epoch 0032, iter [01400, 05004], lr: 0.010000, loss: 1.6257
2022-07-13 14:36:45 - train: epoch 0032, iter [01500, 05004], lr: 0.010000, loss: 1.5922
2022-07-13 14:37:19 - train: epoch 0032, iter [01600, 05004], lr: 0.010000, loss: 1.7127
2022-07-13 14:37:52 - train: epoch 0032, iter [01700, 05004], lr: 0.010000, loss: 1.6873
2022-07-13 14:38:25 - train: epoch 0032, iter [01800, 05004], lr: 0.010000, loss: 1.9453
2022-07-13 14:38:57 - train: epoch 0032, iter [01900, 05004], lr: 0.010000, loss: 1.4733
2022-07-13 14:39:32 - train: epoch 0032, iter [02000, 05004], lr: 0.010000, loss: 1.5676
2022-07-13 14:40:05 - train: epoch 0032, iter [02100, 05004], lr: 0.010000, loss: 1.5069
2022-07-13 14:40:38 - train: epoch 0032, iter [02200, 05004], lr: 0.010000, loss: 1.4012
2022-07-13 14:41:11 - train: epoch 0032, iter [02300, 05004], lr: 0.010000, loss: 1.7109
2022-07-13 14:41:46 - train: epoch 0032, iter [02400, 05004], lr: 0.010000, loss: 1.5473
2022-07-13 14:42:18 - train: epoch 0032, iter [02500, 05004], lr: 0.010000, loss: 1.6944
2022-07-13 14:42:53 - train: epoch 0032, iter [02600, 05004], lr: 0.010000, loss: 1.4211
2022-07-13 14:43:26 - train: epoch 0032, iter [02700, 05004], lr: 0.010000, loss: 1.5663
2022-07-13 14:43:59 - train: epoch 0032, iter [02800, 05004], lr: 0.010000, loss: 1.6631
2022-07-13 14:44:33 - train: epoch 0032, iter [02900, 05004], lr: 0.010000, loss: 1.4286
2022-07-13 14:45:07 - train: epoch 0032, iter [03000, 05004], lr: 0.010000, loss: 1.3963
2022-07-13 14:45:40 - train: epoch 0032, iter [03100, 05004], lr: 0.010000, loss: 1.5994
2022-07-13 14:46:13 - train: epoch 0032, iter [03200, 05004], lr: 0.010000, loss: 1.5672
2022-07-13 14:46:47 - train: epoch 0032, iter [03300, 05004], lr: 0.010000, loss: 1.4434
2022-07-13 14:47:20 - train: epoch 0032, iter [03400, 05004], lr: 0.010000, loss: 1.3648
2022-07-13 14:47:54 - train: epoch 0032, iter [03500, 05004], lr: 0.010000, loss: 1.5960
2022-07-13 14:48:27 - train: epoch 0032, iter [03600, 05004], lr: 0.010000, loss: 1.6845
2022-07-13 14:49:01 - train: epoch 0032, iter [03700, 05004], lr: 0.010000, loss: 1.6276
2022-07-13 14:49:34 - train: epoch 0032, iter [03800, 05004], lr: 0.010000, loss: 1.3992
2022-07-13 14:50:09 - train: epoch 0032, iter [03900, 05004], lr: 0.010000, loss: 1.7208
2022-07-13 14:50:42 - train: epoch 0032, iter [04000, 05004], lr: 0.010000, loss: 1.4448
2022-07-13 14:51:16 - train: epoch 0032, iter [04100, 05004], lr: 0.010000, loss: 1.5475
2022-07-13 14:51:48 - train: epoch 0032, iter [04200, 05004], lr: 0.010000, loss: 1.3859
2022-07-13 14:52:22 - train: epoch 0032, iter [04300, 05004], lr: 0.010000, loss: 1.8261
2022-07-13 14:52:56 - train: epoch 0032, iter [04400, 05004], lr: 0.010000, loss: 1.4695
2022-07-13 14:53:29 - train: epoch 0032, iter [04500, 05004], lr: 0.010000, loss: 1.7645
2022-07-13 14:54:02 - train: epoch 0032, iter [04600, 05004], lr: 0.010000, loss: 1.4999
2022-07-13 14:54:36 - train: epoch 0032, iter [04700, 05004], lr: 0.010000, loss: 1.7152
2022-07-13 14:55:09 - train: epoch 0032, iter [04800, 05004], lr: 0.010000, loss: 1.3810
2022-07-13 14:55:43 - train: epoch 0032, iter [04900, 05004], lr: 0.010000, loss: 1.7616
2022-07-13 14:56:15 - train: epoch 0032, iter [05000, 05004], lr: 0.010000, loss: 1.6105
2022-07-13 14:56:16 - train: epoch 032, train_loss: 1.5798
2022-07-13 14:57:31 - eval: epoch: 032, acc1: 68.202%, acc5: 88.402%, test_loss: 1.2994, per_image_load_time: 2.558ms, per_image_inference_time: 0.298ms
2022-07-13 14:57:32 - until epoch: 032, best_acc1: 68.202%
2022-07-13 14:57:32 - epoch 033 lr: 0.010000
2022-07-13 14:58:10 - train: epoch 0033, iter [00100, 05004], lr: 0.010000, loss: 1.4132
2022-07-13 14:58:44 - train: epoch 0033, iter [00200, 05004], lr: 0.010000, loss: 1.6303
2022-07-13 14:59:17 - train: epoch 0033, iter [00300, 05004], lr: 0.010000, loss: 1.4603
2022-07-13 14:59:51 - train: epoch 0033, iter [00400, 05004], lr: 0.010000, loss: 1.4470
2022-07-13 15:00:24 - train: epoch 0033, iter [00500, 05004], lr: 0.010000, loss: 1.5730
2022-07-13 15:00:57 - train: epoch 0033, iter [00600, 05004], lr: 0.010000, loss: 1.4090
2022-07-13 15:01:30 - train: epoch 0033, iter [00700, 05004], lr: 0.010000, loss: 1.6993
2022-07-13 15:02:05 - train: epoch 0033, iter [00800, 05004], lr: 0.010000, loss: 1.6211
2022-07-13 15:02:38 - train: epoch 0033, iter [00900, 05004], lr: 0.010000, loss: 1.6080
2022-07-13 15:03:11 - train: epoch 0033, iter [01000, 05004], lr: 0.010000, loss: 1.6081
2022-07-13 15:03:45 - train: epoch 0033, iter [01100, 05004], lr: 0.010000, loss: 1.4082
2022-07-13 15:04:18 - train: epoch 0033, iter [01200, 05004], lr: 0.010000, loss: 1.5321
2022-07-13 15:04:51 - train: epoch 0033, iter [01300, 05004], lr: 0.010000, loss: 1.3784
2022-07-13 15:05:25 - train: epoch 0033, iter [01400, 05004], lr: 0.010000, loss: 1.7170
2022-07-13 15:05:59 - train: epoch 0033, iter [01500, 05004], lr: 0.010000, loss: 1.7312
2022-07-13 15:06:32 - train: epoch 0033, iter [01600, 05004], lr: 0.010000, loss: 1.6080
2022-07-13 15:07:05 - train: epoch 0033, iter [01700, 05004], lr: 0.010000, loss: 1.3287
2022-07-13 15:07:38 - train: epoch 0033, iter [01800, 05004], lr: 0.010000, loss: 1.7563
2022-07-13 15:08:11 - train: epoch 0033, iter [01900, 05004], lr: 0.010000, loss: 1.5748
2022-07-13 15:08:45 - train: epoch 0033, iter [02000, 05004], lr: 0.010000, loss: 1.4853
2022-07-13 15:09:18 - train: epoch 0033, iter [02100, 05004], lr: 0.010000, loss: 1.5555
2022-07-13 15:09:52 - train: epoch 0033, iter [02200, 05004], lr: 0.010000, loss: 1.5835
2022-07-13 15:10:25 - train: epoch 0033, iter [02300, 05004], lr: 0.010000, loss: 1.3861
2022-07-13 15:10:59 - train: epoch 0033, iter [02400, 05004], lr: 0.010000, loss: 1.7602
2022-07-13 15:11:31 - train: epoch 0033, iter [02500, 05004], lr: 0.010000, loss: 1.5128
2022-07-13 15:12:05 - train: epoch 0033, iter [02600, 05004], lr: 0.010000, loss: 1.4132
2022-07-13 15:12:38 - train: epoch 0033, iter [02700, 05004], lr: 0.010000, loss: 1.6428
2022-07-13 15:13:11 - train: epoch 0033, iter [02800, 05004], lr: 0.010000, loss: 1.4647
2022-07-13 15:13:45 - train: epoch 0033, iter [02900, 05004], lr: 0.010000, loss: 1.6877
2022-07-13 15:14:18 - train: epoch 0033, iter [03000, 05004], lr: 0.010000, loss: 1.5825
2022-07-13 15:14:52 - train: epoch 0033, iter [03100, 05004], lr: 0.010000, loss: 1.5435
2022-07-13 15:15:26 - train: epoch 0033, iter [03200, 05004], lr: 0.010000, loss: 1.5185
2022-07-13 15:15:59 - train: epoch 0033, iter [03300, 05004], lr: 0.010000, loss: 1.5558
2022-07-13 15:16:33 - train: epoch 0033, iter [03400, 05004], lr: 0.010000, loss: 1.4311
2022-07-13 15:17:05 - train: epoch 0033, iter [03500, 05004], lr: 0.010000, loss: 1.5165
2022-07-13 15:17:39 - train: epoch 0033, iter [03600, 05004], lr: 0.010000, loss: 1.7987
2022-07-13 15:18:13 - train: epoch 0033, iter [03700, 05004], lr: 0.010000, loss: 1.4302
2022-07-13 15:18:45 - train: epoch 0033, iter [03800, 05004], lr: 0.010000, loss: 1.4048
2022-07-13 15:19:19 - train: epoch 0033, iter [03900, 05004], lr: 0.010000, loss: 1.5842
2022-07-13 15:19:52 - train: epoch 0033, iter [04000, 05004], lr: 0.010000, loss: 1.5817
2022-07-13 15:20:26 - train: epoch 0033, iter [04100, 05004], lr: 0.010000, loss: 1.4571
2022-07-13 15:20:59 - train: epoch 0033, iter [04200, 05004], lr: 0.010000, loss: 1.4041
2022-07-13 15:21:33 - train: epoch 0033, iter [04300, 05004], lr: 0.010000, loss: 1.6964
2022-07-13 15:22:06 - train: epoch 0033, iter [04400, 05004], lr: 0.010000, loss: 1.6407
2022-07-13 15:22:40 - train: epoch 0033, iter [04500, 05004], lr: 0.010000, loss: 1.7632
2022-07-13 15:23:13 - train: epoch 0033, iter [04600, 05004], lr: 0.010000, loss: 1.5408
2022-07-13 15:23:46 - train: epoch 0033, iter [04700, 05004], lr: 0.010000, loss: 1.3946
2022-07-13 15:24:19 - train: epoch 0033, iter [04800, 05004], lr: 0.010000, loss: 1.8461
2022-07-13 15:24:54 - train: epoch 0033, iter [04900, 05004], lr: 0.010000, loss: 1.3520
2022-07-13 15:25:25 - train: epoch 0033, iter [05000, 05004], lr: 0.010000, loss: 1.4433
2022-07-13 15:25:26 - train: epoch 033, train_loss: 1.5286
2022-07-13 15:26:42 - eval: epoch: 033, acc1: 68.880%, acc5: 88.598%, test_loss: 1.2763, per_image_load_time: 2.567ms, per_image_inference_time: 0.290ms
2022-07-13 15:26:42 - until epoch: 033, best_acc1: 68.880%
2022-07-13 15:26:42 - epoch 034 lr: 0.010000
2022-07-13 15:27:21 - train: epoch 0034, iter [00100, 05004], lr: 0.010000, loss: 1.4100
2022-07-13 15:27:54 - train: epoch 0034, iter [00200, 05004], lr: 0.010000, loss: 1.4573
2022-07-13 15:28:27 - train: epoch 0034, iter [00300, 05004], lr: 0.010000, loss: 1.5564
2022-07-13 15:29:00 - train: epoch 0034, iter [00400, 05004], lr: 0.010000, loss: 1.2796
2022-07-13 15:29:34 - train: epoch 0034, iter [00500, 05004], lr: 0.010000, loss: 1.5200
2022-07-13 15:30:07 - train: epoch 0034, iter [00600, 05004], lr: 0.010000, loss: 1.7030
2022-07-13 15:30:39 - train: epoch 0034, iter [00700, 05004], lr: 0.010000, loss: 1.4915
2022-07-13 15:31:12 - train: epoch 0034, iter [00800, 05004], lr: 0.010000, loss: 1.5121
2022-07-13 15:31:46 - train: epoch 0034, iter [00900, 05004], lr: 0.010000, loss: 1.4021
2022-07-13 15:32:19 - train: epoch 0034, iter [01000, 05004], lr: 0.010000, loss: 1.4118
2022-07-13 15:32:53 - train: epoch 0034, iter [01100, 05004], lr: 0.010000, loss: 1.4319
2022-07-13 15:33:26 - train: epoch 0034, iter [01200, 05004], lr: 0.010000, loss: 1.4936
2022-07-13 15:33:59 - train: epoch 0034, iter [01300, 05004], lr: 0.010000, loss: 1.5137
2022-07-13 15:34:32 - train: epoch 0034, iter [01400, 05004], lr: 0.010000, loss: 1.5411
2022-07-13 15:35:06 - train: epoch 0034, iter [01500, 05004], lr: 0.010000, loss: 1.4326
2022-07-13 15:35:39 - train: epoch 0034, iter [01600, 05004], lr: 0.010000, loss: 1.4399
2022-07-13 15:36:13 - train: epoch 0034, iter [01700, 05004], lr: 0.010000, loss: 1.4192
2022-07-13 15:36:45 - train: epoch 0034, iter [01800, 05004], lr: 0.010000, loss: 1.6713
2022-07-13 15:37:19 - train: epoch 0034, iter [01900, 05004], lr: 0.010000, loss: 1.5422
2022-07-13 15:37:52 - train: epoch 0034, iter [02000, 05004], lr: 0.010000, loss: 1.6118
2022-07-13 15:38:26 - train: epoch 0034, iter [02100, 05004], lr: 0.010000, loss: 1.7269
2022-07-13 15:38:59 - train: epoch 0034, iter [02200, 05004], lr: 0.010000, loss: 1.4303
2022-07-13 15:39:33 - train: epoch 0034, iter [02300, 05004], lr: 0.010000, loss: 1.6777
2022-07-13 15:40:06 - train: epoch 0034, iter [02400, 05004], lr: 0.010000, loss: 1.3430
2022-07-13 15:40:40 - train: epoch 0034, iter [02500, 05004], lr: 0.010000, loss: 1.4933
2022-07-13 15:41:12 - train: epoch 0034, iter [02600, 05004], lr: 0.010000, loss: 1.5552
2022-07-13 15:41:46 - train: epoch 0034, iter [02700, 05004], lr: 0.010000, loss: 1.5793
2022-07-13 15:42:18 - train: epoch 0034, iter [02800, 05004], lr: 0.010000, loss: 1.3719
2022-07-13 15:42:52 - train: epoch 0034, iter [02900, 05004], lr: 0.010000, loss: 1.2580
2022-07-13 15:43:26 - train: epoch 0034, iter [03000, 05004], lr: 0.010000, loss: 1.3693
2022-07-13 15:43:59 - train: epoch 0034, iter [03100, 05004], lr: 0.010000, loss: 1.3142
2022-07-13 15:44:33 - train: epoch 0034, iter [03200, 05004], lr: 0.010000, loss: 1.4842
2022-07-13 15:45:07 - train: epoch 0034, iter [03300, 05004], lr: 0.010000, loss: 1.4071
2022-07-13 15:45:39 - train: epoch 0034, iter [03400, 05004], lr: 0.010000, loss: 1.5446
2022-07-13 15:46:13 - train: epoch 0034, iter [03500, 05004], lr: 0.010000, loss: 1.3036
2022-07-13 15:46:47 - train: epoch 0034, iter [03600, 05004], lr: 0.010000, loss: 1.2856
2022-07-13 15:47:21 - train: epoch 0034, iter [03700, 05004], lr: 0.010000, loss: 1.4083
2022-07-13 15:47:53 - train: epoch 0034, iter [03800, 05004], lr: 0.010000, loss: 1.4191
2022-07-13 15:48:27 - train: epoch 0034, iter [03900, 05004], lr: 0.010000, loss: 1.6004
2022-07-13 15:49:00 - train: epoch 0034, iter [04000, 05004], lr: 0.010000, loss: 1.2777
2022-07-13 15:49:34 - train: epoch 0034, iter [04100, 05004], lr: 0.010000, loss: 1.5217
2022-07-13 15:50:08 - train: epoch 0034, iter [04200, 05004], lr: 0.010000, loss: 1.4218
2022-07-13 15:50:41 - train: epoch 0034, iter [04300, 05004], lr: 0.010000, loss: 1.4579
2022-07-13 15:51:14 - train: epoch 0034, iter [04400, 05004], lr: 0.010000, loss: 1.4699
2022-07-13 15:51:48 - train: epoch 0034, iter [04500, 05004], lr: 0.010000, loss: 1.7288
2022-07-13 15:52:21 - train: epoch 0034, iter [04600, 05004], lr: 0.010000, loss: 1.6139
2022-07-13 15:52:55 - train: epoch 0034, iter [04700, 05004], lr: 0.010000, loss: 1.4591
2022-07-13 15:53:28 - train: epoch 0034, iter [04800, 05004], lr: 0.010000, loss: 1.4223
2022-07-13 15:54:02 - train: epoch 0034, iter [04900, 05004], lr: 0.010000, loss: 1.4870
2022-07-13 15:54:34 - train: epoch 0034, iter [05000, 05004], lr: 0.010000, loss: 1.3411
2022-07-13 15:54:35 - train: epoch 034, train_loss: 1.4982
2022-07-13 15:55:50 - eval: epoch: 034, acc1: 69.152%, acc5: 88.826%, test_loss: 1.2611, per_image_load_time: 2.614ms, per_image_inference_time: 0.289ms
2022-07-13 15:55:51 - until epoch: 034, best_acc1: 69.152%
2022-07-13 15:55:51 - epoch 035 lr: 0.010000
2022-07-13 15:56:29 - train: epoch 0035, iter [00100, 05004], lr: 0.010000, loss: 1.3546
2022-07-13 15:57:02 - train: epoch 0035, iter [00200, 05004], lr: 0.010000, loss: 1.2514
2022-07-13 15:57:36 - train: epoch 0035, iter [00300, 05004], lr: 0.010000, loss: 1.6415
2022-07-13 15:58:09 - train: epoch 0035, iter [00400, 05004], lr: 0.010000, loss: 1.4526
2022-07-13 15:58:43 - train: epoch 0035, iter [00500, 05004], lr: 0.010000, loss: 1.5771
2022-07-13 15:59:16 - train: epoch 0035, iter [00600, 05004], lr: 0.010000, loss: 1.4008
2022-07-13 15:59:50 - train: epoch 0035, iter [00700, 05004], lr: 0.010000, loss: 1.4215
2022-07-13 16:00:23 - train: epoch 0035, iter [00800, 05004], lr: 0.010000, loss: 1.4140
2022-07-13 16:00:56 - train: epoch 0035, iter [00900, 05004], lr: 0.010000, loss: 1.6594
2022-07-13 16:01:30 - train: epoch 0035, iter [01000, 05004], lr: 0.010000, loss: 1.6348
2022-07-13 16:02:03 - train: epoch 0035, iter [01100, 05004], lr: 0.010000, loss: 1.7070
2022-07-13 16:02:36 - train: epoch 0035, iter [01200, 05004], lr: 0.010000, loss: 1.3365
2022-07-13 16:03:10 - train: epoch 0035, iter [01300, 05004], lr: 0.010000, loss: 1.5623
2022-07-13 16:03:43 - train: epoch 0035, iter [01400, 05004], lr: 0.010000, loss: 1.4530
2022-07-13 16:04:17 - train: epoch 0035, iter [01500, 05004], lr: 0.010000, loss: 1.5416
2022-07-13 16:04:50 - train: epoch 0035, iter [01600, 05004], lr: 0.010000, loss: 1.4259
2022-07-13 16:05:23 - train: epoch 0035, iter [01700, 05004], lr: 0.010000, loss: 1.3505
2022-07-13 16:05:56 - train: epoch 0035, iter [01800, 05004], lr: 0.010000, loss: 1.5396
2022-07-13 16:06:30 - train: epoch 0035, iter [01900, 05004], lr: 0.010000, loss: 1.4740
2022-07-13 16:07:03 - train: epoch 0035, iter [02000, 05004], lr: 0.010000, loss: 1.4490
2022-07-13 16:07:37 - train: epoch 0035, iter [02100, 05004], lr: 0.010000, loss: 1.4723
2022-07-13 16:08:10 - train: epoch 0035, iter [02200, 05004], lr: 0.010000, loss: 1.5279
2022-07-13 16:08:44 - train: epoch 0035, iter [02300, 05004], lr: 0.010000, loss: 1.5644
2022-07-13 16:09:17 - train: epoch 0035, iter [02400, 05004], lr: 0.010000, loss: 1.5426
2022-07-13 16:09:50 - train: epoch 0035, iter [02500, 05004], lr: 0.010000, loss: 1.3426
2022-07-13 16:10:23 - train: epoch 0035, iter [02600, 05004], lr: 0.010000, loss: 1.6950
2022-07-13 16:10:57 - train: epoch 0035, iter [02700, 05004], lr: 0.010000, loss: 1.6407
2022-07-13 16:11:30 - train: epoch 0035, iter [02800, 05004], lr: 0.010000, loss: 1.4004
2022-07-13 16:12:03 - train: epoch 0035, iter [02900, 05004], lr: 0.010000, loss: 1.4656
2022-07-13 16:12:36 - train: epoch 0035, iter [03000, 05004], lr: 0.010000, loss: 1.6349
2022-07-13 16:13:10 - train: epoch 0035, iter [03100, 05004], lr: 0.010000, loss: 1.5003
2022-07-13 16:13:43 - train: epoch 0035, iter [03200, 05004], lr: 0.010000, loss: 1.3856
2022-07-13 16:14:17 - train: epoch 0035, iter [03300, 05004], lr: 0.010000, loss: 1.4430
2022-07-13 16:14:50 - train: epoch 0035, iter [03400, 05004], lr: 0.010000, loss: 1.4275
2022-07-13 16:15:23 - train: epoch 0035, iter [03500, 05004], lr: 0.010000, loss: 1.2330
2022-07-13 16:15:57 - train: epoch 0035, iter [03600, 05004], lr: 0.010000, loss: 1.4795
2022-07-13 16:16:30 - train: epoch 0035, iter [03700, 05004], lr: 0.010000, loss: 1.3318
2022-07-13 16:17:04 - train: epoch 0035, iter [03800, 05004], lr: 0.010000, loss: 1.5411
2022-07-13 16:17:37 - train: epoch 0035, iter [03900, 05004], lr: 0.010000, loss: 1.5595
2022-07-13 16:18:11 - train: epoch 0035, iter [04000, 05004], lr: 0.010000, loss: 1.2595
2022-07-13 16:18:44 - train: epoch 0035, iter [04100, 05004], lr: 0.010000, loss: 1.8142
2022-07-13 16:19:18 - train: epoch 0035, iter [04200, 05004], lr: 0.010000, loss: 1.5062
2022-07-13 16:19:51 - train: epoch 0035, iter [04300, 05004], lr: 0.010000, loss: 1.5499
2022-07-13 16:20:25 - train: epoch 0035, iter [04400, 05004], lr: 0.010000, loss: 1.4766
2022-07-13 16:20:57 - train: epoch 0035, iter [04500, 05004], lr: 0.010000, loss: 1.5636
2022-07-13 16:21:31 - train: epoch 0035, iter [04600, 05004], lr: 0.010000, loss: 1.4259
2022-07-13 16:22:04 - train: epoch 0035, iter [04700, 05004], lr: 0.010000, loss: 1.6402
2022-07-13 16:22:37 - train: epoch 0035, iter [04800, 05004], lr: 0.010000, loss: 1.6652
2022-07-13 16:23:11 - train: epoch 0035, iter [04900, 05004], lr: 0.010000, loss: 1.4366
2022-07-13 16:23:43 - train: epoch 0035, iter [05000, 05004], lr: 0.010000, loss: 1.2877
2022-07-13 16:23:44 - train: epoch 035, train_loss: 1.4777
2022-07-13 16:25:00 - eval: epoch: 035, acc1: 69.246%, acc5: 89.014%, test_loss: 1.2548, per_image_load_time: 2.555ms, per_image_inference_time: 0.311ms
2022-07-13 16:25:00 - until epoch: 035, best_acc1: 69.246%
2022-07-13 16:25:00 - epoch 036 lr: 0.010000
2022-07-13 16:25:39 - train: epoch 0036, iter [00100, 05004], lr: 0.010000, loss: 1.6195
2022-07-13 16:26:11 - train: epoch 0036, iter [00200, 05004], lr: 0.010000, loss: 1.2084
2022-07-13 16:26:45 - train: epoch 0036, iter [00300, 05004], lr: 0.010000, loss: 1.4368
2022-07-13 16:27:19 - train: epoch 0036, iter [00400, 05004], lr: 0.010000, loss: 1.5088
2022-07-13 16:27:52 - train: epoch 0036, iter [00500, 05004], lr: 0.010000, loss: 1.4447
2022-07-13 16:28:27 - train: epoch 0036, iter [00600, 05004], lr: 0.010000, loss: 1.4159
2022-07-13 16:28:59 - train: epoch 0036, iter [00700, 05004], lr: 0.010000, loss: 1.3516
2022-07-13 16:29:33 - train: epoch 0036, iter [00800, 05004], lr: 0.010000, loss: 1.2569
2022-07-13 16:30:06 - train: epoch 0036, iter [00900, 05004], lr: 0.010000, loss: 1.4147
2022-07-13 16:30:39 - train: epoch 0036, iter [01000, 05004], lr: 0.010000, loss: 1.4405
2022-07-13 16:31:13 - train: epoch 0036, iter [01100, 05004], lr: 0.010000, loss: 1.4837
2022-07-13 16:31:46 - train: epoch 0036, iter [01200, 05004], lr: 0.010000, loss: 1.5056
2022-07-13 16:32:20 - train: epoch 0036, iter [01300, 05004], lr: 0.010000, loss: 1.4975
2022-07-13 16:32:54 - train: epoch 0036, iter [01400, 05004], lr: 0.010000, loss: 1.6003
2022-07-13 16:33:27 - train: epoch 0036, iter [01500, 05004], lr: 0.010000, loss: 1.6334
2022-07-13 16:34:01 - train: epoch 0036, iter [01600, 05004], lr: 0.010000, loss: 1.3847
2022-07-13 16:34:34 - train: epoch 0036, iter [01700, 05004], lr: 0.010000, loss: 1.4249
2022-07-13 16:35:08 - train: epoch 0036, iter [01800, 05004], lr: 0.010000, loss: 1.3543
2022-07-13 16:35:41 - train: epoch 0036, iter [01900, 05004], lr: 0.010000, loss: 1.4473
2022-07-13 16:36:15 - train: epoch 0036, iter [02000, 05004], lr: 0.010000, loss: 1.4697
2022-07-13 16:36:48 - train: epoch 0036, iter [02100, 05004], lr: 0.010000, loss: 1.4580
2022-07-13 16:37:22 - train: epoch 0036, iter [02200, 05004], lr: 0.010000, loss: 1.3869
2022-07-13 16:37:55 - train: epoch 0036, iter [02300, 05004], lr: 0.010000, loss: 1.6149
2022-07-13 16:38:29 - train: epoch 0036, iter [02400, 05004], lr: 0.010000, loss: 1.5757
2022-07-13 16:39:02 - train: epoch 0036, iter [02500, 05004], lr: 0.010000, loss: 1.2988
2022-07-13 16:39:36 - train: epoch 0036, iter [02600, 05004], lr: 0.010000, loss: 1.4520
2022-07-13 16:40:09 - train: epoch 0036, iter [02700, 05004], lr: 0.010000, loss: 1.3852
2022-07-13 16:40:43 - train: epoch 0036, iter [02800, 05004], lr: 0.010000, loss: 1.3270
2022-07-13 16:41:16 - train: epoch 0036, iter [02900, 05004], lr: 0.010000, loss: 1.3061
2022-07-13 16:41:50 - train: epoch 0036, iter [03000, 05004], lr: 0.010000, loss: 1.5633
2022-07-13 16:42:23 - train: epoch 0036, iter [03100, 05004], lr: 0.010000, loss: 1.4565
2022-07-13 16:42:56 - train: epoch 0036, iter [03200, 05004], lr: 0.010000, loss: 1.5197
2022-07-13 16:43:30 - train: epoch 0036, iter [03300, 05004], lr: 0.010000, loss: 1.3543
2022-07-13 16:44:04 - train: epoch 0036, iter [03400, 05004], lr: 0.010000, loss: 1.3587
2022-07-13 16:44:36 - train: epoch 0036, iter [03500, 05004], lr: 0.010000, loss: 1.4765
2022-07-13 16:45:10 - train: epoch 0036, iter [03600, 05004], lr: 0.010000, loss: 1.5744
2022-07-13 16:45:43 - train: epoch 0036, iter [03700, 05004], lr: 0.010000, loss: 1.5138
2022-07-13 16:46:17 - train: epoch 0036, iter [03800, 05004], lr: 0.010000, loss: 1.3268
2022-07-13 16:46:50 - train: epoch 0036, iter [03900, 05004], lr: 0.010000, loss: 1.4469
2022-07-13 16:47:24 - train: epoch 0036, iter [04000, 05004], lr: 0.010000, loss: 1.5312
2022-07-13 16:47:58 - train: epoch 0036, iter [04100, 05004], lr: 0.010000, loss: 1.3658
2022-07-13 16:48:31 - train: epoch 0036, iter [04200, 05004], lr: 0.010000, loss: 1.3517
2022-07-13 16:49:04 - train: epoch 0036, iter [04300, 05004], lr: 0.010000, loss: 1.3678
2022-07-13 16:49:37 - train: epoch 0036, iter [04400, 05004], lr: 0.010000, loss: 1.5437
2022-07-13 16:50:11 - train: epoch 0036, iter [04500, 05004], lr: 0.010000, loss: 1.2216
2022-07-13 16:50:45 - train: epoch 0036, iter [04600, 05004], lr: 0.010000, loss: 1.3694
2022-07-13 16:51:18 - train: epoch 0036, iter [04700, 05004], lr: 0.010000, loss: 1.4395
2022-07-13 16:51:52 - train: epoch 0036, iter [04800, 05004], lr: 0.010000, loss: 1.5059
2022-07-13 16:52:25 - train: epoch 0036, iter [04900, 05004], lr: 0.010000, loss: 1.5096
2022-07-13 16:52:57 - train: epoch 0036, iter [05000, 05004], lr: 0.010000, loss: 1.4194
2022-07-13 16:52:58 - train: epoch 036, train_loss: 1.4607
2022-07-13 16:54:12 - eval: epoch: 036, acc1: 69.408%, acc5: 89.012%, test_loss: 1.2539, per_image_load_time: 2.554ms, per_image_inference_time: 0.297ms
2022-07-13 16:54:13 - until epoch: 036, best_acc1: 69.408%
2022-07-13 16:54:13 - epoch 037 lr: 0.010000
2022-07-13 16:54:52 - train: epoch 0037, iter [00100, 05004], lr: 0.010000, loss: 1.2199
2022-07-13 16:55:24 - train: epoch 0037, iter [00200, 05004], lr: 0.010000, loss: 1.1980
2022-07-13 16:55:59 - train: epoch 0037, iter [00300, 05004], lr: 0.010000, loss: 1.3885
2022-07-13 16:56:32 - train: epoch 0037, iter [00400, 05004], lr: 0.010000, loss: 1.5979
2022-07-13 16:57:05 - train: epoch 0037, iter [00500, 05004], lr: 0.010000, loss: 1.3491
2022-07-13 16:57:38 - train: epoch 0037, iter [00600, 05004], lr: 0.010000, loss: 1.4730
2022-07-13 16:58:11 - train: epoch 0037, iter [00700, 05004], lr: 0.010000, loss: 1.5408
2022-07-13 16:58:44 - train: epoch 0037, iter [00800, 05004], lr: 0.010000, loss: 1.3853
2022-07-13 16:59:18 - train: epoch 0037, iter [00900, 05004], lr: 0.010000, loss: 1.6930
2022-07-13 16:59:51 - train: epoch 0037, iter [01000, 05004], lr: 0.010000, loss: 1.3974
2022-07-13 17:00:25 - train: epoch 0037, iter [01100, 05004], lr: 0.010000, loss: 1.4645
2022-07-13 17:00:58 - train: epoch 0037, iter [01200, 05004], lr: 0.010000, loss: 1.4443
2022-07-13 17:01:31 - train: epoch 0037, iter [01300, 05004], lr: 0.010000, loss: 1.4737
2022-07-13 17:02:05 - train: epoch 0037, iter [01400, 05004], lr: 0.010000, loss: 1.4563
2022-07-13 17:02:38 - train: epoch 0037, iter [01500, 05004], lr: 0.010000, loss: 1.3737
2022-07-13 17:03:11 - train: epoch 0037, iter [01600, 05004], lr: 0.010000, loss: 1.2625
2022-07-13 17:03:44 - train: epoch 0037, iter [01700, 05004], lr: 0.010000, loss: 1.6972
2022-07-13 17:04:17 - train: epoch 0037, iter [01800, 05004], lr: 0.010000, loss: 1.6174
2022-07-13 17:04:51 - train: epoch 0037, iter [01900, 05004], lr: 0.010000, loss: 1.5312
2022-07-13 17:05:24 - train: epoch 0037, iter [02000, 05004], lr: 0.010000, loss: 1.4259
2022-07-13 17:05:59 - train: epoch 0037, iter [02100, 05004], lr: 0.010000, loss: 1.4635
2022-07-13 17:06:32 - train: epoch 0037, iter [02200, 05004], lr: 0.010000, loss: 1.4211
2022-07-13 17:07:05 - train: epoch 0037, iter [02300, 05004], lr: 0.010000, loss: 1.3202
2022-07-13 17:07:38 - train: epoch 0037, iter [02400, 05004], lr: 0.010000, loss: 1.4108
2022-07-13 17:08:11 - train: epoch 0037, iter [02500, 05004], lr: 0.010000, loss: 1.3659
2022-07-13 17:08:45 - train: epoch 0037, iter [02600, 05004], lr: 0.010000, loss: 1.6557
2022-07-13 17:09:19 - train: epoch 0037, iter [02700, 05004], lr: 0.010000, loss: 1.6481
2022-07-13 17:09:52 - train: epoch 0037, iter [02800, 05004], lr: 0.010000, loss: 1.4965
2022-07-13 17:10:25 - train: epoch 0037, iter [02900, 05004], lr: 0.010000, loss: 1.5546
2022-07-13 17:10:58 - train: epoch 0037, iter [03000, 05004], lr: 0.010000, loss: 1.5934
2022-07-13 17:11:32 - train: epoch 0037, iter [03100, 05004], lr: 0.010000, loss: 1.3750
2022-07-13 17:12:06 - train: epoch 0037, iter [03200, 05004], lr: 0.010000, loss: 1.5411
2022-07-13 17:12:39 - train: epoch 0037, iter [03300, 05004], lr: 0.010000, loss: 1.3581
2022-07-13 17:13:12 - train: epoch 0037, iter [03400, 05004], lr: 0.010000, loss: 1.3216
2022-07-13 17:13:46 - train: epoch 0037, iter [03500, 05004], lr: 0.010000, loss: 1.4688
2022-07-13 17:14:19 - train: epoch 0037, iter [03600, 05004], lr: 0.010000, loss: 1.5563
2022-07-13 17:14:53 - train: epoch 0037, iter [03700, 05004], lr: 0.010000, loss: 1.5483
2022-07-13 17:15:26 - train: epoch 0037, iter [03800, 05004], lr: 0.010000, loss: 1.3860
2022-07-13 17:15:59 - train: epoch 0037, iter [03900, 05004], lr: 0.010000, loss: 1.6231
2022-07-13 17:16:33 - train: epoch 0037, iter [04000, 05004], lr: 0.010000, loss: 1.3726
2022-07-13 17:17:06 - train: epoch 0037, iter [04100, 05004], lr: 0.010000, loss: 1.5292
2022-07-13 17:17:40 - train: epoch 0037, iter [04200, 05004], lr: 0.010000, loss: 1.6368
2022-07-13 17:18:14 - train: epoch 0037, iter [04300, 05004], lr: 0.010000, loss: 1.4752
2022-07-13 17:18:48 - train: epoch 0037, iter [04400, 05004], lr: 0.010000, loss: 1.3781
2022-07-13 17:19:21 - train: epoch 0037, iter [04500, 05004], lr: 0.010000, loss: 1.4026
2022-07-13 17:19:54 - train: epoch 0037, iter [04600, 05004], lr: 0.010000, loss: 1.4859
2022-07-13 17:20:28 - train: epoch 0037, iter [04700, 05004], lr: 0.010000, loss: 1.4598
2022-07-13 17:21:01 - train: epoch 0037, iter [04800, 05004], lr: 0.010000, loss: 1.4845
2022-07-13 17:21:35 - train: epoch 0037, iter [04900, 05004], lr: 0.010000, loss: 1.5257
2022-07-13 17:22:07 - train: epoch 0037, iter [05000, 05004], lr: 0.010000, loss: 1.4923
2022-07-13 17:22:08 - train: epoch 037, train_loss: 1.4527
2022-07-13 17:23:22 - eval: epoch: 037, acc1: 69.408%, acc5: 89.126%, test_loss: 1.2422, per_image_load_time: 2.228ms, per_image_inference_time: 0.314ms
2022-07-13 17:23:23 - until epoch: 037, best_acc1: 69.408%
2022-07-13 17:23:23 - epoch 038 lr: 0.010000
2022-07-13 17:24:01 - train: epoch 0038, iter [00100, 05004], lr: 0.010000, loss: 1.4369
2022-07-13 17:24:35 - train: epoch 0038, iter [00200, 05004], lr: 0.010000, loss: 1.2044
2022-07-13 17:25:08 - train: epoch 0038, iter [00300, 05004], lr: 0.010000, loss: 1.1538
2022-07-13 17:25:42 - train: epoch 0038, iter [00400, 05004], lr: 0.010000, loss: 1.3468
2022-07-13 17:26:15 - train: epoch 0038, iter [00500, 05004], lr: 0.010000, loss: 1.3749
2022-07-13 17:26:49 - train: epoch 0038, iter [00600, 05004], lr: 0.010000, loss: 1.4943
2022-07-13 17:27:22 - train: epoch 0038, iter [00700, 05004], lr: 0.010000, loss: 1.3107
2022-07-13 17:27:56 - train: epoch 0038, iter [00800, 05004], lr: 0.010000, loss: 1.2966
2022-07-13 17:28:29 - train: epoch 0038, iter [00900, 05004], lr: 0.010000, loss: 1.4669
2022-07-13 17:29:02 - train: epoch 0038, iter [01000, 05004], lr: 0.010000, loss: 1.6516
2022-07-13 17:29:35 - train: epoch 0038, iter [01100, 05004], lr: 0.010000, loss: 1.3764
2022-07-13 17:30:09 - train: epoch 0038, iter [01200, 05004], lr: 0.010000, loss: 1.4516
2022-07-13 17:30:42 - train: epoch 0038, iter [01300, 05004], lr: 0.010000, loss: 1.4995
2022-07-13 17:31:16 - train: epoch 0038, iter [01400, 05004], lr: 0.010000, loss: 1.5761
2022-07-13 17:31:49 - train: epoch 0038, iter [01500, 05004], lr: 0.010000, loss: 1.5046
2022-07-13 17:32:23 - train: epoch 0038, iter [01600, 05004], lr: 0.010000, loss: 1.5363
2022-07-13 17:32:56 - train: epoch 0038, iter [01700, 05004], lr: 0.010000, loss: 1.6270
2022-07-13 17:33:29 - train: epoch 0038, iter [01800, 05004], lr: 0.010000, loss: 1.5713
2022-07-13 17:34:02 - train: epoch 0038, iter [01900, 05004], lr: 0.010000, loss: 1.4235
2022-07-13 17:34:35 - train: epoch 0038, iter [02000, 05004], lr: 0.010000, loss: 1.4565
2022-07-13 17:35:09 - train: epoch 0038, iter [02100, 05004], lr: 0.010000, loss: 1.4160
2022-07-13 17:35:42 - train: epoch 0038, iter [02200, 05004], lr: 0.010000, loss: 1.3388
2022-07-13 17:36:16 - train: epoch 0038, iter [02300, 05004], lr: 0.010000, loss: 1.5708
2022-07-13 17:36:50 - train: epoch 0038, iter [02400, 05004], lr: 0.010000, loss: 1.6422
2022-07-13 17:37:23 - train: epoch 0038, iter [02500, 05004], lr: 0.010000, loss: 1.3479
2022-07-13 17:37:56 - train: epoch 0038, iter [02600, 05004], lr: 0.010000, loss: 1.4749
2022-07-13 17:38:30 - train: epoch 0038, iter [02700, 05004], lr: 0.010000, loss: 1.5183
2022-07-13 17:39:03 - train: epoch 0038, iter [02800, 05004], lr: 0.010000, loss: 1.6101
2022-07-13 17:39:36 - train: epoch 0038, iter [02900, 05004], lr: 0.010000, loss: 1.5446
2022-07-13 17:40:10 - train: epoch 0038, iter [03000, 05004], lr: 0.010000, loss: 1.4662
2022-07-13 17:40:43 - train: epoch 0038, iter [03100, 05004], lr: 0.010000, loss: 1.4784
2022-07-13 17:41:17 - train: epoch 0038, iter [03200, 05004], lr: 0.010000, loss: 1.0880
2022-07-13 17:41:50 - train: epoch 0038, iter [03300, 05004], lr: 0.010000, loss: 1.3026
2022-07-13 17:42:23 - train: epoch 0038, iter [03400, 05004], lr: 0.010000, loss: 1.3528
2022-07-13 17:42:57 - train: epoch 0038, iter [03500, 05004], lr: 0.010000, loss: 1.5129
2022-07-13 17:43:31 - train: epoch 0038, iter [03600, 05004], lr: 0.010000, loss: 1.5456
2022-07-13 17:44:04 - train: epoch 0038, iter [03700, 05004], lr: 0.010000, loss: 1.2192
2022-07-13 17:44:37 - train: epoch 0038, iter [03800, 05004], lr: 0.010000, loss: 1.5450
2022-07-13 17:45:11 - train: epoch 0038, iter [03900, 05004], lr: 0.010000, loss: 1.3886
2022-07-13 17:45:45 - train: epoch 0038, iter [04000, 05004], lr: 0.010000, loss: 1.4365
2022-07-13 17:46:17 - train: epoch 0038, iter [04100, 05004], lr: 0.010000, loss: 1.4327
2022-07-13 17:46:51 - train: epoch 0038, iter [04200, 05004], lr: 0.010000, loss: 1.2915
2022-07-13 17:47:25 - train: epoch 0038, iter [04300, 05004], lr: 0.010000, loss: 1.6362
2022-07-13 17:47:59 - train: epoch 0038, iter [04400, 05004], lr: 0.010000, loss: 1.5291
2022-07-13 17:48:30 - train: epoch 0038, iter [04500, 05004], lr: 0.010000, loss: 1.6046
2022-07-13 17:49:05 - train: epoch 0038, iter [04600, 05004], lr: 0.010000, loss: 1.5514
2022-07-13 17:49:39 - train: epoch 0038, iter [04700, 05004], lr: 0.010000, loss: 1.2854
2022-07-13 17:50:12 - train: epoch 0038, iter [04800, 05004], lr: 0.010000, loss: 1.4821
2022-07-13 17:50:46 - train: epoch 0038, iter [04900, 05004], lr: 0.010000, loss: 1.5005
2022-07-13 17:51:18 - train: epoch 0038, iter [05000, 05004], lr: 0.010000, loss: 1.1658
2022-07-13 17:51:19 - train: epoch 038, train_loss: 1.4444
2022-07-13 17:52:34 - eval: epoch: 038, acc1: 69.476%, acc5: 89.180%, test_loss: 1.2430, per_image_load_time: 2.228ms, per_image_inference_time: 0.312ms
2022-07-13 17:52:34 - until epoch: 038, best_acc1: 69.476%
2022-07-13 17:52:34 - epoch 039 lr: 0.010000
2022-07-13 17:53:12 - train: epoch 0039, iter [00100, 05004], lr: 0.010000, loss: 1.5185
2022-07-13 17:53:46 - train: epoch 0039, iter [00200, 05004], lr: 0.010000, loss: 1.6007
2022-07-13 17:54:19 - train: epoch 0039, iter [00300, 05004], lr: 0.010000, loss: 1.2341
2022-07-13 17:54:53 - train: epoch 0039, iter [00400, 05004], lr: 0.010000, loss: 1.4392
2022-07-13 17:55:26 - train: epoch 0039, iter [00500, 05004], lr: 0.010000, loss: 1.3573
2022-07-13 17:55:59 - train: epoch 0039, iter [00600, 05004], lr: 0.010000, loss: 1.3940
2022-07-13 17:56:33 - train: epoch 0039, iter [00700, 05004], lr: 0.010000, loss: 1.6540
2022-07-13 17:57:06 - train: epoch 0039, iter [00800, 05004], lr: 0.010000, loss: 1.3973
2022-07-13 17:57:39 - train: epoch 0039, iter [00900, 05004], lr: 0.010000, loss: 1.4857
2022-07-13 17:58:12 - train: epoch 0039, iter [01000, 05004], lr: 0.010000, loss: 1.3175
2022-07-13 17:58:46 - train: epoch 0039, iter [01100, 05004], lr: 0.010000, loss: 1.4746
2022-07-13 17:59:18 - train: epoch 0039, iter [01200, 05004], lr: 0.010000, loss: 1.5553
2022-07-13 17:59:52 - train: epoch 0039, iter [01300, 05004], lr: 0.010000, loss: 1.6462
2022-07-13 18:00:25 - train: epoch 0039, iter [01400, 05004], lr: 0.010000, loss: 1.3818
2022-07-13 18:00:58 - train: epoch 0039, iter [01500, 05004], lr: 0.010000, loss: 1.4282
2022-07-13 18:01:31 - train: epoch 0039, iter [01600, 05004], lr: 0.010000, loss: 1.5126
2022-07-13 18:02:04 - train: epoch 0039, iter [01700, 05004], lr: 0.010000, loss: 1.1810
2022-07-13 18:02:37 - train: epoch 0039, iter [01800, 05004], lr: 0.010000, loss: 1.3871
2022-07-13 18:03:11 - train: epoch 0039, iter [01900, 05004], lr: 0.010000, loss: 1.2064
2022-07-13 18:03:44 - train: epoch 0039, iter [02000, 05004], lr: 0.010000, loss: 1.3349
2022-07-13 18:04:18 - train: epoch 0039, iter [02100, 05004], lr: 0.010000, loss: 1.4689
2022-07-13 18:04:51 - train: epoch 0039, iter [02200, 05004], lr: 0.010000, loss: 1.4179
2022-07-13 18:05:24 - train: epoch 0039, iter [02300, 05004], lr: 0.010000, loss: 1.6956
2022-07-13 18:05:57 - train: epoch 0039, iter [02400, 05004], lr: 0.010000, loss: 1.5791
2022-07-13 18:06:30 - train: epoch 0039, iter [02500, 05004], lr: 0.010000, loss: 1.3645
2022-07-13 18:07:03 - train: epoch 0039, iter [02600, 05004], lr: 0.010000, loss: 1.4139
2022-07-13 18:07:37 - train: epoch 0039, iter [02700, 05004], lr: 0.010000, loss: 1.5598
2022-07-13 18:08:10 - train: epoch 0039, iter [02800, 05004], lr: 0.010000, loss: 1.3040
2022-07-13 18:08:43 - train: epoch 0039, iter [02900, 05004], lr: 0.010000, loss: 1.2608
2022-07-13 18:09:17 - train: epoch 0039, iter [03000, 05004], lr: 0.010000, loss: 1.5671
2022-07-13 18:09:50 - train: epoch 0039, iter [03100, 05004], lr: 0.010000, loss: 1.3524
2022-07-13 18:10:23 - train: epoch 0039, iter [03200, 05004], lr: 0.010000, loss: 1.4209
2022-07-13 18:10:56 - train: epoch 0039, iter [03300, 05004], lr: 0.010000, loss: 1.4589
2022-07-13 18:11:30 - train: epoch 0039, iter [03400, 05004], lr: 0.010000, loss: 1.5208
2022-07-13 18:12:03 - train: epoch 0039, iter [03500, 05004], lr: 0.010000, loss: 1.5919
2022-07-13 18:12:37 - train: epoch 0039, iter [03600, 05004], lr: 0.010000, loss: 1.5528
2022-07-13 18:13:09 - train: epoch 0039, iter [03700, 05004], lr: 0.010000, loss: 1.4732
2022-07-13 18:13:43 - train: epoch 0039, iter [03800, 05004], lr: 0.010000, loss: 1.2317
2022-07-13 18:14:16 - train: epoch 0039, iter [03900, 05004], lr: 0.010000, loss: 1.6001
2022-07-13 18:14:50 - train: epoch 0039, iter [04000, 05004], lr: 0.010000, loss: 1.4158
2022-07-13 18:15:23 - train: epoch 0039, iter [04100, 05004], lr: 0.010000, loss: 1.5038
2022-07-13 18:15:56 - train: epoch 0039, iter [04200, 05004], lr: 0.010000, loss: 1.4849
2022-07-13 18:16:30 - train: epoch 0039, iter [04300, 05004], lr: 0.010000, loss: 1.3883
2022-07-13 18:17:03 - train: epoch 0039, iter [04400, 05004], lr: 0.010000, loss: 1.1623
2022-07-13 18:17:37 - train: epoch 0039, iter [04500, 05004], lr: 0.010000, loss: 1.3643
2022-07-13 18:18:10 - train: epoch 0039, iter [04600, 05004], lr: 0.010000, loss: 1.7051
2022-07-13 18:18:44 - train: epoch 0039, iter [04700, 05004], lr: 0.010000, loss: 1.3610
2022-07-13 18:19:18 - train: epoch 0039, iter [04800, 05004], lr: 0.010000, loss: 1.5352
2022-07-13 18:19:50 - train: epoch 0039, iter [04900, 05004], lr: 0.010000, loss: 1.3794
2022-07-13 18:20:23 - train: epoch 0039, iter [05000, 05004], lr: 0.010000, loss: 1.3292
2022-07-13 18:20:24 - train: epoch 039, train_loss: 1.4399
2022-07-13 18:21:39 - eval: epoch: 039, acc1: 69.078%, acc5: 89.086%, test_loss: 1.2516, per_image_load_time: 2.530ms, per_image_inference_time: 0.297ms
2022-07-13 18:21:39 - until epoch: 039, best_acc1: 69.476%
2022-07-13 18:21:39 - epoch 040 lr: 0.010000
2022-07-13 18:22:18 - train: epoch 0040, iter [00100, 05004], lr: 0.010000, loss: 1.6293
2022-07-13 18:22:51 - train: epoch 0040, iter [00200, 05004], lr: 0.010000, loss: 1.6555
2022-07-13 18:23:26 - train: epoch 0040, iter [00300, 05004], lr: 0.010000, loss: 1.5111
2022-07-13 18:23:58 - train: epoch 0040, iter [00400, 05004], lr: 0.010000, loss: 1.4299
2022-07-13 18:24:31 - train: epoch 0040, iter [00500, 05004], lr: 0.010000, loss: 1.2914
2022-07-13 18:25:05 - train: epoch 0040, iter [00600, 05004], lr: 0.010000, loss: 1.5224
2022-07-13 18:25:38 - train: epoch 0040, iter [00700, 05004], lr: 0.010000, loss: 1.5175
2022-07-13 18:26:11 - train: epoch 0040, iter [00800, 05004], lr: 0.010000, loss: 1.6246
2022-07-13 18:26:45 - train: epoch 0040, iter [00900, 05004], lr: 0.010000, loss: 1.3721
2022-07-13 18:27:18 - train: epoch 0040, iter [01000, 05004], lr: 0.010000, loss: 1.1161
2022-07-13 18:27:51 - train: epoch 0040, iter [01100, 05004], lr: 0.010000, loss: 1.3556
2022-07-13 18:28:24 - train: epoch 0040, iter [01200, 05004], lr: 0.010000, loss: 1.3423
2022-07-13 18:28:58 - train: epoch 0040, iter [01300, 05004], lr: 0.010000, loss: 1.3090
2022-07-13 18:29:31 - train: epoch 0040, iter [01400, 05004], lr: 0.010000, loss: 1.3818
2022-07-13 18:30:04 - train: epoch 0040, iter [01500, 05004], lr: 0.010000, loss: 1.6606
2022-07-13 18:30:37 - train: epoch 0040, iter [01600, 05004], lr: 0.010000, loss: 1.4659
2022-07-13 18:31:11 - train: epoch 0040, iter [01700, 05004], lr: 0.010000, loss: 1.5676
2022-07-13 18:31:45 - train: epoch 0040, iter [01800, 05004], lr: 0.010000, loss: 1.3142
2022-07-13 18:32:18 - train: epoch 0040, iter [01900, 05004], lr: 0.010000, loss: 1.3701
2022-07-13 18:32:51 - train: epoch 0040, iter [02000, 05004], lr: 0.010000, loss: 1.5301
2022-07-13 18:33:25 - train: epoch 0040, iter [02100, 05004], lr: 0.010000, loss: 1.3274
2022-07-13 18:33:58 - train: epoch 0040, iter [02200, 05004], lr: 0.010000, loss: 1.2420
2022-07-13 18:34:31 - train: epoch 0040, iter [02300, 05004], lr: 0.010000, loss: 1.3887
2022-07-13 18:35:04 - train: epoch 0040, iter [02400, 05004], lr: 0.010000, loss: 1.4211
2022-07-13 18:35:38 - train: epoch 0040, iter [02500, 05004], lr: 0.010000, loss: 1.4808
2022-07-13 18:36:11 - train: epoch 0040, iter [02600, 05004], lr: 0.010000, loss: 1.3225
2022-07-13 18:36:44 - train: epoch 0040, iter [02700, 05004], lr: 0.010000, loss: 1.5151
2022-07-13 18:37:18 - train: epoch 0040, iter [02800, 05004], lr: 0.010000, loss: 1.4893
2022-07-13 18:37:51 - train: epoch 0040, iter [02900, 05004], lr: 0.010000, loss: 1.6623
2022-07-13 18:38:24 - train: epoch 0040, iter [03000, 05004], lr: 0.010000, loss: 1.5780
2022-07-13 18:38:58 - train: epoch 0040, iter [03100, 05004], lr: 0.010000, loss: 1.3582
2022-07-13 18:39:31 - train: epoch 0040, iter [03200, 05004], lr: 0.010000, loss: 1.5350
2022-07-13 18:40:04 - train: epoch 0040, iter [03300, 05004], lr: 0.010000, loss: 1.4279
2022-07-13 18:40:37 - train: epoch 0040, iter [03400, 05004], lr: 0.010000, loss: 1.4568
2022-07-13 18:41:11 - train: epoch 0040, iter [03500, 05004], lr: 0.010000, loss: 1.4453
2022-07-13 18:41:44 - train: epoch 0040, iter [03600, 05004], lr: 0.010000, loss: 1.4288
2022-07-13 18:42:18 - train: epoch 0040, iter [03700, 05004], lr: 0.010000, loss: 1.4798
2022-07-13 18:42:52 - train: epoch 0040, iter [03800, 05004], lr: 0.010000, loss: 1.3114
2022-07-13 18:43:24 - train: epoch 0040, iter [03900, 05004], lr: 0.010000, loss: 1.5473
2022-07-13 18:43:58 - train: epoch 0040, iter [04000, 05004], lr: 0.010000, loss: 1.5307
2022-07-13 18:44:31 - train: epoch 0040, iter [04100, 05004], lr: 0.010000, loss: 1.4659
2022-07-13 18:45:05 - train: epoch 0040, iter [04200, 05004], lr: 0.010000, loss: 1.3679
2022-07-13 18:45:38 - train: epoch 0040, iter [04300, 05004], lr: 0.010000, loss: 1.4618
2022-07-13 18:46:12 - train: epoch 0040, iter [04400, 05004], lr: 0.010000, loss: 1.5335
2022-07-13 18:46:45 - train: epoch 0040, iter [04500, 05004], lr: 0.010000, loss: 1.2412
2022-07-13 18:47:18 - train: epoch 0040, iter [04600, 05004], lr: 0.010000, loss: 1.4405
2022-07-13 18:47:53 - train: epoch 0040, iter [04700, 05004], lr: 0.010000, loss: 1.4306
2022-07-13 18:48:25 - train: epoch 0040, iter [04800, 05004], lr: 0.010000, loss: 1.4367
2022-07-13 18:48:59 - train: epoch 0040, iter [04900, 05004], lr: 0.010000, loss: 1.5298
2022-07-13 18:49:31 - train: epoch 0040, iter [05000, 05004], lr: 0.010000, loss: 1.5202
2022-07-13 18:49:32 - train: epoch 040, train_loss: 1.4350
2022-07-13 18:50:46 - eval: epoch: 040, acc1: 69.246%, acc5: 89.152%, test_loss: 1.2510, per_image_load_time: 2.040ms, per_image_inference_time: 0.307ms
2022-07-13 18:50:46 - until epoch: 040, best_acc1: 69.476%
2022-07-13 18:50:46 - epoch 041 lr: 0.010000
2022-07-13 18:51:25 - train: epoch 0041, iter [00100, 05004], lr: 0.010000, loss: 1.5982
2022-07-13 18:51:58 - train: epoch 0041, iter [00200, 05004], lr: 0.010000, loss: 1.5244
2022-07-13 18:52:31 - train: epoch 0041, iter [00300, 05004], lr: 0.010000, loss: 1.3999
2022-07-13 18:53:05 - train: epoch 0041, iter [00400, 05004], lr: 0.010000, loss: 1.4773
2022-07-13 18:53:38 - train: epoch 0041, iter [00500, 05004], lr: 0.010000, loss: 1.2609
2022-07-13 18:54:11 - train: epoch 0041, iter [00600, 05004], lr: 0.010000, loss: 1.5907
2022-07-13 18:54:44 - train: epoch 0041, iter [00700, 05004], lr: 0.010000, loss: 1.3334
2022-07-13 18:55:18 - train: epoch 0041, iter [00800, 05004], lr: 0.010000, loss: 1.2066
2022-07-13 18:55:52 - train: epoch 0041, iter [00900, 05004], lr: 0.010000, loss: 1.2395
2022-07-13 18:56:24 - train: epoch 0041, iter [01000, 05004], lr: 0.010000, loss: 1.6187
2022-07-13 18:56:59 - train: epoch 0041, iter [01100, 05004], lr: 0.010000, loss: 1.3234
2022-07-13 18:57:31 - train: epoch 0041, iter [01200, 05004], lr: 0.010000, loss: 1.2190
2022-07-13 18:58:04 - train: epoch 0041, iter [01300, 05004], lr: 0.010000, loss: 1.4326
2022-07-13 18:58:37 - train: epoch 0041, iter [01400, 05004], lr: 0.010000, loss: 1.4564
2022-07-13 18:59:11 - train: epoch 0041, iter [01500, 05004], lr: 0.010000, loss: 1.7517
2022-07-13 18:59:44 - train: epoch 0041, iter [01600, 05004], lr: 0.010000, loss: 1.2848
2022-07-13 19:00:17 - train: epoch 0041, iter [01700, 05004], lr: 0.010000, loss: 1.5227
2022-07-13 19:00:50 - train: epoch 0041, iter [01800, 05004], lr: 0.010000, loss: 1.3660
2022-07-13 19:01:24 - train: epoch 0041, iter [01900, 05004], lr: 0.010000, loss: 1.5735
2022-07-13 19:01:57 - train: epoch 0041, iter [02000, 05004], lr: 0.010000, loss: 1.3715
2022-07-13 19:02:31 - train: epoch 0041, iter [02100, 05004], lr: 0.010000, loss: 1.2149
2022-07-13 19:03:04 - train: epoch 0041, iter [02200, 05004], lr: 0.010000, loss: 1.3790
2022-07-13 19:03:38 - train: epoch 0041, iter [02300, 05004], lr: 0.010000, loss: 1.1551
2022-07-13 19:04:10 - train: epoch 0041, iter [02400, 05004], lr: 0.010000, loss: 1.6187
2022-07-13 19:04:44 - train: epoch 0041, iter [02500, 05004], lr: 0.010000, loss: 1.3212
2022-07-13 19:05:17 - train: epoch 0041, iter [02600, 05004], lr: 0.010000, loss: 1.6595
2022-07-13 19:05:51 - train: epoch 0041, iter [02700, 05004], lr: 0.010000, loss: 1.5980
2022-07-13 19:06:24 - train: epoch 0041, iter [02800, 05004], lr: 0.010000, loss: 1.4661
2022-07-13 19:06:58 - train: epoch 0041, iter [02900, 05004], lr: 0.010000, loss: 1.5918
2022-07-13 19:07:31 - train: epoch 0041, iter [03000, 05004], lr: 0.010000, loss: 1.4891
2022-07-13 19:08:05 - train: epoch 0041, iter [03100, 05004], lr: 0.010000, loss: 1.5870
2022-07-13 19:08:38 - train: epoch 0041, iter [03200, 05004], lr: 0.010000, loss: 1.4148
2022-07-13 19:09:11 - train: epoch 0041, iter [03300, 05004], lr: 0.010000, loss: 1.2667
2022-07-13 19:09:45 - train: epoch 0041, iter [03400, 05004], lr: 0.010000, loss: 1.3611
2022-07-13 19:10:19 - train: epoch 0041, iter [03500, 05004], lr: 0.010000, loss: 1.5626
2022-07-13 19:10:52 - train: epoch 0041, iter [03600, 05004], lr: 0.010000, loss: 1.4892
2022-07-13 19:11:25 - train: epoch 0041, iter [03700, 05004], lr: 0.010000, loss: 1.4015
2022-07-13 19:11:57 - train: epoch 0041, iter [03800, 05004], lr: 0.010000, loss: 1.4675
2022-07-13 19:12:31 - train: epoch 0041, iter [03900, 05004], lr: 0.010000, loss: 1.5004
2022-07-13 19:13:05 - train: epoch 0041, iter [04000, 05004], lr: 0.010000, loss: 1.3128
2022-07-13 19:13:38 - train: epoch 0041, iter [04100, 05004], lr: 0.010000, loss: 1.4775
2022-07-13 19:14:11 - train: epoch 0041, iter [04200, 05004], lr: 0.010000, loss: 1.3269
2022-07-13 19:14:46 - train: epoch 0041, iter [04300, 05004], lr: 0.010000, loss: 1.5036
2022-07-13 19:15:19 - train: epoch 0041, iter [04400, 05004], lr: 0.010000, loss: 1.3354
2022-07-13 19:15:52 - train: epoch 0041, iter [04500, 05004], lr: 0.010000, loss: 1.5622
2022-07-13 19:16:25 - train: epoch 0041, iter [04600, 05004], lr: 0.010000, loss: 1.5490
2022-07-13 19:16:59 - train: epoch 0041, iter [04700, 05004], lr: 0.010000, loss: 1.5916
2022-07-13 19:17:32 - train: epoch 0041, iter [04800, 05004], lr: 0.010000, loss: 1.4534
2022-07-13 19:18:05 - train: epoch 0041, iter [04900, 05004], lr: 0.010000, loss: 1.4293
2022-07-13 19:18:38 - train: epoch 0041, iter [05000, 05004], lr: 0.010000, loss: 1.5195
2022-07-13 19:18:39 - train: epoch 041, train_loss: 1.4360
2022-07-13 19:19:54 - eval: epoch: 041, acc1: 69.180%, acc5: 89.008%, test_loss: 1.2536, per_image_load_time: 2.595ms, per_image_inference_time: 0.297ms
2022-07-13 19:19:54 - until epoch: 041, best_acc1: 69.476%
2022-07-13 19:19:54 - epoch 042 lr: 0.010000
2022-07-13 19:20:32 - train: epoch 0042, iter [00100, 05004], lr: 0.010000, loss: 1.1475
2022-07-13 19:21:07 - train: epoch 0042, iter [00200, 05004], lr: 0.010000, loss: 1.5435
2022-07-13 19:21:40 - train: epoch 0042, iter [00300, 05004], lr: 0.010000, loss: 1.4709
2022-07-13 19:22:14 - train: epoch 0042, iter [00400, 05004], lr: 0.010000, loss: 1.1120
2022-07-13 19:22:46 - train: epoch 0042, iter [00500, 05004], lr: 0.010000, loss: 1.4948
2022-07-13 19:23:20 - train: epoch 0042, iter [00600, 05004], lr: 0.010000, loss: 1.2910
2022-07-13 19:23:53 - train: epoch 0042, iter [00700, 05004], lr: 0.010000, loss: 1.3707
2022-07-13 19:24:27 - train: epoch 0042, iter [00800, 05004], lr: 0.010000, loss: 1.2620
2022-07-13 19:24:59 - train: epoch 0042, iter [00900, 05004], lr: 0.010000, loss: 1.6813
2022-07-13 19:25:32 - train: epoch 0042, iter [01000, 05004], lr: 0.010000, loss: 1.5156
2022-07-13 19:26:06 - train: epoch 0042, iter [01100, 05004], lr: 0.010000, loss: 1.2850
2022-07-13 19:26:40 - train: epoch 0042, iter [01200, 05004], lr: 0.010000, loss: 1.3337
2022-07-13 19:27:12 - train: epoch 0042, iter [01300, 05004], lr: 0.010000, loss: 1.4133
2022-07-13 19:27:46 - train: epoch 0042, iter [01400, 05004], lr: 0.010000, loss: 1.7572
2022-07-13 19:28:19 - train: epoch 0042, iter [01500, 05004], lr: 0.010000, loss: 1.3107
2022-07-13 19:28:53 - train: epoch 0042, iter [01600, 05004], lr: 0.010000, loss: 1.4271
2022-07-13 19:29:27 - train: epoch 0042, iter [01700, 05004], lr: 0.010000, loss: 1.3718
2022-07-13 19:29:59 - train: epoch 0042, iter [01800, 05004], lr: 0.010000, loss: 1.3582
2022-07-13 19:30:33 - train: epoch 0042, iter [01900, 05004], lr: 0.010000, loss: 1.4463
2022-07-13 19:31:06 - train: epoch 0042, iter [02000, 05004], lr: 0.010000, loss: 1.2977
2022-07-13 19:31:39 - train: epoch 0042, iter [02100, 05004], lr: 0.010000, loss: 1.2442
2022-07-13 19:32:13 - train: epoch 0042, iter [02200, 05004], lr: 0.010000, loss: 1.3077
2022-07-13 19:32:45 - train: epoch 0042, iter [02300, 05004], lr: 0.010000, loss: 1.3949
2022-07-13 19:33:20 - train: epoch 0042, iter [02400, 05004], lr: 0.010000, loss: 1.6768
2022-07-13 19:33:52 - train: epoch 0042, iter [02500, 05004], lr: 0.010000, loss: 1.5863
2022-07-13 19:34:26 - train: epoch 0042, iter [02600, 05004], lr: 0.010000, loss: 1.4752
2022-07-13 19:34:59 - train: epoch 0042, iter [02700, 05004], lr: 0.010000, loss: 1.3103
2022-07-13 19:35:32 - train: epoch 0042, iter [02800, 05004], lr: 0.010000, loss: 1.3708
2022-07-13 19:36:05 - train: epoch 0042, iter [02900, 05004], lr: 0.010000, loss: 1.5128
2022-07-13 19:36:40 - train: epoch 0042, iter [03000, 05004], lr: 0.010000, loss: 1.5033
2022-07-13 19:37:13 - train: epoch 0042, iter [03100, 05004], lr: 0.010000, loss: 1.4233
2022-07-13 19:37:46 - train: epoch 0042, iter [03200, 05004], lr: 0.010000, loss: 1.5624
2022-07-13 19:38:19 - train: epoch 0042, iter [03300, 05004], lr: 0.010000, loss: 1.6010
2022-07-13 19:38:53 - train: epoch 0042, iter [03400, 05004], lr: 0.010000, loss: 1.3577
2022-07-13 19:39:26 - train: epoch 0042, iter [03500, 05004], lr: 0.010000, loss: 1.4295
2022-07-13 19:39:59 - train: epoch 0042, iter [03600, 05004], lr: 0.010000, loss: 1.6705
2022-07-13 19:40:33 - train: epoch 0042, iter [03700, 05004], lr: 0.010000, loss: 1.4170
2022-07-13 19:41:06 - train: epoch 0042, iter [03800, 05004], lr: 0.010000, loss: 1.2852
2022-07-13 19:41:39 - train: epoch 0042, iter [03900, 05004], lr: 0.010000, loss: 1.3671
2022-07-13 19:42:13 - train: epoch 0042, iter [04000, 05004], lr: 0.010000, loss: 1.4715
2022-07-13 19:42:46 - train: epoch 0042, iter [04100, 05004], lr: 0.010000, loss: 1.6368
2022-07-13 19:43:21 - train: epoch 0042, iter [04200, 05004], lr: 0.010000, loss: 1.4644
2022-07-13 19:43:54 - train: epoch 0042, iter [04300, 05004], lr: 0.010000, loss: 1.2560
2022-07-13 19:44:27 - train: epoch 0042, iter [04400, 05004], lr: 0.010000, loss: 1.4213
2022-07-13 19:45:01 - train: epoch 0042, iter [04500, 05004], lr: 0.010000, loss: 1.4850
2022-07-13 19:45:35 - train: epoch 0042, iter [04600, 05004], lr: 0.010000, loss: 1.6767
2022-07-13 19:46:08 - train: epoch 0042, iter [04700, 05004], lr: 0.010000, loss: 1.2727
2022-07-13 19:46:41 - train: epoch 0042, iter [04800, 05004], lr: 0.010000, loss: 1.5023
2022-07-13 19:47:16 - train: epoch 0042, iter [04900, 05004], lr: 0.010000, loss: 1.4978
2022-07-13 19:47:47 - train: epoch 0042, iter [05000, 05004], lr: 0.010000, loss: 1.3161
2022-07-13 19:47:48 - train: epoch 042, train_loss: 1.4331
2022-07-13 19:49:03 - eval: epoch: 042, acc1: 69.166%, acc5: 88.952%, test_loss: 1.2586, per_image_load_time: 1.847ms, per_image_inference_time: 0.301ms
2022-07-13 19:49:04 - until epoch: 042, best_acc1: 69.476%
2022-07-13 19:49:04 - epoch 043 lr: 0.010000
2022-07-13 19:49:42 - train: epoch 0043, iter [00100, 05004], lr: 0.010000, loss: 1.4067
2022-07-13 19:50:15 - train: epoch 0043, iter [00200, 05004], lr: 0.010000, loss: 1.5049
2022-07-13 19:50:49 - train: epoch 0043, iter [00300, 05004], lr: 0.010000, loss: 1.1249
2022-07-13 19:51:22 - train: epoch 0043, iter [00400, 05004], lr: 0.010000, loss: 1.3268
2022-07-13 19:51:55 - train: epoch 0043, iter [00500, 05004], lr: 0.010000, loss: 1.3791
2022-07-13 19:52:28 - train: epoch 0043, iter [00600, 05004], lr: 0.010000, loss: 1.3947
2022-07-13 19:53:02 - train: epoch 0043, iter [00700, 05004], lr: 0.010000, loss: 1.5242
2022-07-13 19:53:35 - train: epoch 0043, iter [00800, 05004], lr: 0.010000, loss: 1.6458
2022-07-13 19:54:07 - train: epoch 0043, iter [00900, 05004], lr: 0.010000, loss: 1.3254
2022-07-13 19:54:41 - train: epoch 0043, iter [01000, 05004], lr: 0.010000, loss: 1.5879
2022-07-13 19:55:14 - train: epoch 0043, iter [01100, 05004], lr: 0.010000, loss: 1.5131
2022-07-13 19:55:48 - train: epoch 0043, iter [01200, 05004], lr: 0.010000, loss: 1.5385
2022-07-13 19:56:21 - train: epoch 0043, iter [01300, 05004], lr: 0.010000, loss: 1.5292
2022-07-13 19:56:55 - train: epoch 0043, iter [01400, 05004], lr: 0.010000, loss: 1.3908
2022-07-13 19:57:28 - train: epoch 0043, iter [01500, 05004], lr: 0.010000, loss: 1.2850
2022-07-13 19:58:02 - train: epoch 0043, iter [01600, 05004], lr: 0.010000, loss: 1.4348
2022-07-13 19:58:35 - train: epoch 0043, iter [01700, 05004], lr: 0.010000, loss: 1.5018
2022-07-13 19:59:08 - train: epoch 0043, iter [01800, 05004], lr: 0.010000, loss: 1.4958
2022-07-13 19:59:42 - train: epoch 0043, iter [01900, 05004], lr: 0.010000, loss: 1.4036
2022-07-13 20:00:16 - train: epoch 0043, iter [02000, 05004], lr: 0.010000, loss: 1.2718
2022-07-13 20:00:49 - train: epoch 0043, iter [02100, 05004], lr: 0.010000, loss: 1.4070
2022-07-13 20:01:22 - train: epoch 0043, iter [02200, 05004], lr: 0.010000, loss: 1.5168
2022-07-13 20:01:55 - train: epoch 0043, iter [02300, 05004], lr: 0.010000, loss: 1.5686
2022-07-13 20:02:29 - train: epoch 0043, iter [02400, 05004], lr: 0.010000, loss: 1.3162
2022-07-13 20:03:02 - train: epoch 0043, iter [02500, 05004], lr: 0.010000, loss: 1.6034
2022-07-13 20:03:35 - train: epoch 0043, iter [02600, 05004], lr: 0.010000, loss: 1.1790
2022-07-13 20:04:08 - train: epoch 0043, iter [02700, 05004], lr: 0.010000, loss: 1.4675
2022-07-13 20:04:42 - train: epoch 0043, iter [02800, 05004], lr: 0.010000, loss: 1.3734
2022-07-13 20:05:15 - train: epoch 0043, iter [02900, 05004], lr: 0.010000, loss: 1.4618
2022-07-13 20:05:49 - train: epoch 0043, iter [03000, 05004], lr: 0.010000, loss: 1.6154
2022-07-13 20:06:22 - train: epoch 0043, iter [03100, 05004], lr: 0.010000, loss: 1.6441
2022-07-13 20:06:56 - train: epoch 0043, iter [03200, 05004], lr: 0.010000, loss: 1.4911
2022-07-13 20:07:29 - train: epoch 0043, iter [03300, 05004], lr: 0.010000, loss: 1.5806
2022-07-13 20:08:02 - train: epoch 0043, iter [03400, 05004], lr: 0.010000, loss: 1.4343
2022-07-13 20:08:37 - train: epoch 0043, iter [03500, 05004], lr: 0.010000, loss: 1.4756
2022-07-13 20:09:10 - train: epoch 0043, iter [03600, 05004], lr: 0.010000, loss: 1.4513
2022-07-13 20:09:43 - train: epoch 0043, iter [03700, 05004], lr: 0.010000, loss: 1.4256
2022-07-13 20:10:16 - train: epoch 0043, iter [03800, 05004], lr: 0.010000, loss: 1.5944
2022-07-13 20:10:50 - train: epoch 0043, iter [03900, 05004], lr: 0.010000, loss: 1.6356
2022-07-13 20:11:23 - train: epoch 0043, iter [04000, 05004], lr: 0.010000, loss: 1.4865
2022-07-13 20:11:57 - train: epoch 0043, iter [04100, 05004], lr: 0.010000, loss: 1.7258
2022-07-13 20:12:30 - train: epoch 0043, iter [04200, 05004], lr: 0.010000, loss: 1.4506
2022-07-13 20:13:04 - train: epoch 0043, iter [04300, 05004], lr: 0.010000, loss: 1.4631
2022-07-13 20:13:38 - train: epoch 0043, iter [04400, 05004], lr: 0.010000, loss: 1.4109
2022-07-13 20:14:11 - train: epoch 0043, iter [04500, 05004], lr: 0.010000, loss: 1.4064
2022-07-13 20:14:45 - train: epoch 0043, iter [04600, 05004], lr: 0.010000, loss: 1.4403
2022-07-13 20:15:17 - train: epoch 0043, iter [04700, 05004], lr: 0.010000, loss: 1.3441
2022-07-13 20:15:52 - train: epoch 0043, iter [04800, 05004], lr: 0.010000, loss: 1.4182
2022-07-13 20:16:25 - train: epoch 0043, iter [04900, 05004], lr: 0.010000, loss: 1.3121
2022-07-13 20:16:57 - train: epoch 0043, iter [05000, 05004], lr: 0.010000, loss: 1.3633
2022-07-13 20:16:58 - train: epoch 043, train_loss: 1.4306
2022-07-13 20:18:13 - eval: epoch: 043, acc1: 69.176%, acc5: 88.936%, test_loss: 1.2514, per_image_load_time: 2.383ms, per_image_inference_time: 0.295ms
2022-07-13 20:18:13 - until epoch: 043, best_acc1: 69.476%
2022-07-13 20:18:13 - epoch 044 lr: 0.010000
2022-07-13 20:18:52 - train: epoch 0044, iter [00100, 05004], lr: 0.010000, loss: 1.4011
2022-07-13 20:19:25 - train: epoch 0044, iter [00200, 05004], lr: 0.010000, loss: 1.3934
2022-07-13 20:19:59 - train: epoch 0044, iter [00300, 05004], lr: 0.010000, loss: 1.4983
2022-07-13 20:20:32 - train: epoch 0044, iter [00400, 05004], lr: 0.010000, loss: 1.1820
2022-07-13 20:21:05 - train: epoch 0044, iter [00500, 05004], lr: 0.010000, loss: 1.3580
2022-07-13 20:21:38 - train: epoch 0044, iter [00600, 05004], lr: 0.010000, loss: 1.2341
2022-07-13 20:22:11 - train: epoch 0044, iter [00700, 05004], lr: 0.010000, loss: 1.1698
2022-07-13 20:22:44 - train: epoch 0044, iter [00800, 05004], lr: 0.010000, loss: 1.3513
2022-07-13 20:23:17 - train: epoch 0044, iter [00900, 05004], lr: 0.010000, loss: 1.3814
2022-07-13 20:23:51 - train: epoch 0044, iter [01000, 05004], lr: 0.010000, loss: 1.4094
2022-07-13 20:24:23 - train: epoch 0044, iter [01100, 05004], lr: 0.010000, loss: 1.3775
2022-07-13 20:24:58 - train: epoch 0044, iter [01200, 05004], lr: 0.010000, loss: 1.3434
2022-07-13 20:25:30 - train: epoch 0044, iter [01300, 05004], lr: 0.010000, loss: 1.4807
2022-07-13 20:26:04 - train: epoch 0044, iter [01400, 05004], lr: 0.010000, loss: 1.2984
2022-07-13 20:26:37 - train: epoch 0044, iter [01500, 05004], lr: 0.010000, loss: 1.4108
2022-07-13 20:27:11 - train: epoch 0044, iter [01600, 05004], lr: 0.010000, loss: 1.4358
2022-07-13 20:27:44 - train: epoch 0044, iter [01700, 05004], lr: 0.010000, loss: 1.4295
2022-07-13 20:28:17 - train: epoch 0044, iter [01800, 05004], lr: 0.010000, loss: 1.4461
2022-07-13 20:28:49 - train: epoch 0044, iter [01900, 05004], lr: 0.010000, loss: 1.5903
2022-07-13 20:29:23 - train: epoch 0044, iter [02000, 05004], lr: 0.010000, loss: 1.2701
2022-07-13 20:29:56 - train: epoch 0044, iter [02100, 05004], lr: 0.010000, loss: 1.6376
2022-07-13 20:30:30 - train: epoch 0044, iter [02200, 05004], lr: 0.010000, loss: 1.4099
2022-07-13 20:31:03 - train: epoch 0044, iter [02300, 05004], lr: 0.010000, loss: 1.5507
2022-07-13 20:31:37 - train: epoch 0044, iter [02400, 05004], lr: 0.010000, loss: 1.4370
2022-07-13 20:32:09 - train: epoch 0044, iter [02500, 05004], lr: 0.010000, loss: 1.4724
2022-07-13 20:32:43 - train: epoch 0044, iter [02600, 05004], lr: 0.010000, loss: 1.3783
2022-07-13 20:33:16 - train: epoch 0044, iter [02700, 05004], lr: 0.010000, loss: 1.5407
2022-07-13 20:33:49 - train: epoch 0044, iter [02800, 05004], lr: 0.010000, loss: 1.2602
2022-07-13 20:34:23 - train: epoch 0044, iter [02900, 05004], lr: 0.010000, loss: 1.2653
2022-07-13 20:34:56 - train: epoch 0044, iter [03000, 05004], lr: 0.010000, loss: 1.2812
2022-07-13 20:35:30 - train: epoch 0044, iter [03100, 05004], lr: 0.010000, loss: 1.4511
2022-07-13 20:36:02 - train: epoch 0044, iter [03200, 05004], lr: 0.010000, loss: 1.1492
2022-07-13 20:36:36 - train: epoch 0044, iter [03300, 05004], lr: 0.010000, loss: 1.3812
2022-07-13 20:37:09 - train: epoch 0044, iter [03400, 05004], lr: 0.010000, loss: 1.6994
2022-07-13 20:37:43 - train: epoch 0044, iter [03500, 05004], lr: 0.010000, loss: 1.2502
2022-07-13 20:38:16 - train: epoch 0044, iter [03600, 05004], lr: 0.010000, loss: 1.6832
2022-07-13 20:38:49 - train: epoch 0044, iter [03700, 05004], lr: 0.010000, loss: 1.5925
2022-07-13 20:39:23 - train: epoch 0044, iter [03800, 05004], lr: 0.010000, loss: 1.1218
2022-07-13 20:39:56 - train: epoch 0044, iter [03900, 05004], lr: 0.010000, loss: 1.6025
2022-07-13 20:40:29 - train: epoch 0044, iter [04000, 05004], lr: 0.010000, loss: 1.5589
2022-07-13 20:41:03 - train: epoch 0044, iter [04100, 05004], lr: 0.010000, loss: 1.2857
2022-07-13 20:41:36 - train: epoch 0044, iter [04200, 05004], lr: 0.010000, loss: 1.5436
2022-07-13 20:42:09 - train: epoch 0044, iter [04300, 05004], lr: 0.010000, loss: 1.6377
2022-07-13 20:42:43 - train: epoch 0044, iter [04400, 05004], lr: 0.010000, loss: 1.3528
2022-07-13 20:43:15 - train: epoch 0044, iter [04500, 05004], lr: 0.010000, loss: 1.4853
2022-07-13 20:43:49 - train: epoch 0044, iter [04600, 05004], lr: 0.010000, loss: 1.5744
2022-07-13 20:44:22 - train: epoch 0044, iter [04700, 05004], lr: 0.010000, loss: 1.4767
2022-07-13 20:44:56 - train: epoch 0044, iter [04800, 05004], lr: 0.010000, loss: 1.6393
2022-07-13 20:45:29 - train: epoch 0044, iter [04900, 05004], lr: 0.010000, loss: 1.3647
2022-07-13 20:46:01 - train: epoch 0044, iter [05000, 05004], lr: 0.010000, loss: 1.5451
2022-07-13 20:46:02 - train: epoch 044, train_loss: 1.4322
2022-07-13 20:47:17 - eval: epoch: 044, acc1: 68.872%, acc5: 89.008%, test_loss: 1.2561, per_image_load_time: 1.547ms, per_image_inference_time: 0.317ms
2022-07-13 20:47:17 - until epoch: 044, best_acc1: 69.476%
2022-07-13 20:47:17 - epoch 045 lr: 0.010000
2022-07-13 20:47:56 - train: epoch 0045, iter [00100, 05004], lr: 0.010000, loss: 1.3003
2022-07-13 20:48:29 - train: epoch 0045, iter [00200, 05004], lr: 0.010000, loss: 1.3609
2022-07-13 20:49:03 - train: epoch 0045, iter [00300, 05004], lr: 0.010000, loss: 1.5703
2022-07-13 20:49:35 - train: epoch 0045, iter [00400, 05004], lr: 0.010000, loss: 1.2822
2022-07-13 20:50:09 - train: epoch 0045, iter [00500, 05004], lr: 0.010000, loss: 1.6483
2022-07-13 20:50:42 - train: epoch 0045, iter [00600, 05004], lr: 0.010000, loss: 1.4401
2022-07-13 20:51:16 - train: epoch 0045, iter [00700, 05004], lr: 0.010000, loss: 1.1504
2022-07-13 20:51:48 - train: epoch 0045, iter [00800, 05004], lr: 0.010000, loss: 1.4297
2022-07-13 20:52:22 - train: epoch 0045, iter [00900, 05004], lr: 0.010000, loss: 1.4471
2022-07-13 20:52:55 - train: epoch 0045, iter [01000, 05004], lr: 0.010000, loss: 1.4129
2022-07-13 20:53:29 - train: epoch 0045, iter [01100, 05004], lr: 0.010000, loss: 1.5745
2022-07-13 20:54:01 - train: epoch 0045, iter [01200, 05004], lr: 0.010000, loss: 1.5626
2022-07-13 20:54:34 - train: epoch 0045, iter [01300, 05004], lr: 0.010000, loss: 1.5060
2022-07-13 20:55:08 - train: epoch 0045, iter [01400, 05004], lr: 0.010000, loss: 1.4378
2022-07-13 20:55:41 - train: epoch 0045, iter [01500, 05004], lr: 0.010000, loss: 1.5763
2022-07-13 20:56:14 - train: epoch 0045, iter [01600, 05004], lr: 0.010000, loss: 1.4114
2022-07-13 20:56:48 - train: epoch 0045, iter [01700, 05004], lr: 0.010000, loss: 1.3203
2022-07-13 20:57:21 - train: epoch 0045, iter [01800, 05004], lr: 0.010000, loss: 1.3282
2022-07-13 20:57:54 - train: epoch 0045, iter [01900, 05004], lr: 0.010000, loss: 1.5320
2022-07-13 20:58:27 - train: epoch 0045, iter [02000, 05004], lr: 0.010000, loss: 1.4751
2022-07-13 20:59:01 - train: epoch 0045, iter [02100, 05004], lr: 0.010000, loss: 1.5495
2022-07-13 20:59:34 - train: epoch 0045, iter [02200, 05004], lr: 0.010000, loss: 1.4998
2022-07-13 21:00:08 - train: epoch 0045, iter [02300, 05004], lr: 0.010000, loss: 1.2736
2022-07-13 21:00:40 - train: epoch 0045, iter [02400, 05004], lr: 0.010000, loss: 1.5774
2022-07-13 21:01:14 - train: epoch 0045, iter [02500, 05004], lr: 0.010000, loss: 1.4301
2022-07-13 21:01:47 - train: epoch 0045, iter [02600, 05004], lr: 0.010000, loss: 1.3482
2022-07-13 21:02:21 - train: epoch 0045, iter [02700, 05004], lr: 0.010000, loss: 1.2831
2022-07-13 21:02:54 - train: epoch 0045, iter [02800, 05004], lr: 0.010000, loss: 1.4137
2022-07-13 21:03:27 - train: epoch 0045, iter [02900, 05004], lr: 0.010000, loss: 1.5794
2022-07-13 21:04:00 - train: epoch 0045, iter [03000, 05004], lr: 0.010000, loss: 1.6670
2022-07-13 21:04:34 - train: epoch 0045, iter [03100, 05004], lr: 0.010000, loss: 1.3779
2022-07-13 21:05:08 - train: epoch 0045, iter [03200, 05004], lr: 0.010000, loss: 1.5341
2022-07-13 21:05:41 - train: epoch 0045, iter [03300, 05004], lr: 0.010000, loss: 1.5260
2022-07-13 21:06:15 - train: epoch 0045, iter [03400, 05004], lr: 0.010000, loss: 1.2872
2022-07-13 21:06:49 - train: epoch 0045, iter [03500, 05004], lr: 0.010000, loss: 1.6188
2022-07-13 21:07:22 - train: epoch 0045, iter [03600, 05004], lr: 0.010000, loss: 1.4341
2022-07-13 21:07:55 - train: epoch 0045, iter [03700, 05004], lr: 0.010000, loss: 1.3439
2022-07-13 21:08:28 - train: epoch 0045, iter [03800, 05004], lr: 0.010000, loss: 1.2384
2022-07-13 21:09:02 - train: epoch 0045, iter [03900, 05004], lr: 0.010000, loss: 1.5863
2022-07-13 21:09:34 - train: epoch 0045, iter [04000, 05004], lr: 0.010000, loss: 1.5063
2022-07-13 21:10:08 - train: epoch 0045, iter [04100, 05004], lr: 0.010000, loss: 1.2895
2022-07-13 21:10:42 - train: epoch 0045, iter [04200, 05004], lr: 0.010000, loss: 1.5701
2022-07-13 21:11:15 - train: epoch 0045, iter [04300, 05004], lr: 0.010000, loss: 1.6090
2022-07-13 21:11:48 - train: epoch 0045, iter [04400, 05004], lr: 0.010000, loss: 1.5739
2022-07-13 21:12:22 - train: epoch 0045, iter [04500, 05004], lr: 0.010000, loss: 1.3458
2022-07-13 21:12:55 - train: epoch 0045, iter [04600, 05004], lr: 0.010000, loss: 1.6462
2022-07-13 21:13:28 - train: epoch 0045, iter [04700, 05004], lr: 0.010000, loss: 1.5187
2022-07-13 21:14:03 - train: epoch 0045, iter [04800, 05004], lr: 0.010000, loss: 1.3323
2022-07-13 21:14:35 - train: epoch 0045, iter [04900, 05004], lr: 0.010000, loss: 1.3923
2022-07-13 21:15:08 - train: epoch 0045, iter [05000, 05004], lr: 0.010000, loss: 1.3745
2022-07-13 21:15:09 - train: epoch 045, train_loss: 1.4274
2022-07-13 21:16:23 - eval: epoch: 045, acc1: 68.896%, acc5: 89.164%, test_loss: 1.2649, per_image_load_time: 1.417ms, per_image_inference_time: 0.291ms
2022-07-13 21:16:23 - until epoch: 045, best_acc1: 69.476%
2022-07-13 21:16:23 - epoch 046 lr: 0.010000
2022-07-13 21:17:01 - train: epoch 0046, iter [00100, 05004], lr: 0.010000, loss: 1.0941
2022-07-13 21:17:35 - train: epoch 0046, iter [00200, 05004], lr: 0.010000, loss: 1.2888
2022-07-13 21:18:08 - train: epoch 0046, iter [00300, 05004], lr: 0.010000, loss: 1.4073
2022-07-13 21:18:42 - train: epoch 0046, iter [00400, 05004], lr: 0.010000, loss: 1.5381
2022-07-13 21:19:14 - train: epoch 0046, iter [00500, 05004], lr: 0.010000, loss: 1.1959
2022-07-13 21:19:48 - train: epoch 0046, iter [00600, 05004], lr: 0.010000, loss: 1.4497
2022-07-13 21:20:20 - train: epoch 0046, iter [00700, 05004], lr: 0.010000, loss: 1.3852
2022-07-13 21:20:54 - train: epoch 0046, iter [00800, 05004], lr: 0.010000, loss: 1.5204
2022-07-13 21:21:27 - train: epoch 0046, iter [00900, 05004], lr: 0.010000, loss: 1.4923
2022-07-13 21:22:00 - train: epoch 0046, iter [01000, 05004], lr: 0.010000, loss: 1.2220
2022-07-13 21:22:33 - train: epoch 0046, iter [01100, 05004], lr: 0.010000, loss: 1.4202
2022-07-13 21:23:07 - train: epoch 0046, iter [01200, 05004], lr: 0.010000, loss: 1.4982
2022-07-13 21:23:41 - train: epoch 0046, iter [01300, 05004], lr: 0.010000, loss: 1.3586
2022-07-13 21:24:14 - train: epoch 0046, iter [01400, 05004], lr: 0.010000, loss: 1.5756
2022-07-13 21:24:47 - train: epoch 0046, iter [01500, 05004], lr: 0.010000, loss: 1.3777
2022-07-13 21:25:21 - train: epoch 0046, iter [01600, 05004], lr: 0.010000, loss: 1.3940
2022-07-13 21:25:55 - train: epoch 0046, iter [01700, 05004], lr: 0.010000, loss: 1.3058
2022-07-13 21:26:27 - train: epoch 0046, iter [01800, 05004], lr: 0.010000, loss: 1.4685
2022-07-13 21:27:01 - train: epoch 0046, iter [01900, 05004], lr: 0.010000, loss: 1.2381
2022-07-13 21:27:35 - train: epoch 0046, iter [02000, 05004], lr: 0.010000, loss: 1.4084
2022-07-13 21:28:08 - train: epoch 0046, iter [02100, 05004], lr: 0.010000, loss: 1.5365
2022-07-13 21:28:41 - train: epoch 0046, iter [02200, 05004], lr: 0.010000, loss: 1.2676
2022-07-13 21:29:15 - train: epoch 0046, iter [02300, 05004], lr: 0.010000, loss: 1.5416
2022-07-13 21:29:48 - train: epoch 0046, iter [02400, 05004], lr: 0.010000, loss: 1.4951
2022-07-13 21:30:21 - train: epoch 0046, iter [02500, 05004], lr: 0.010000, loss: 1.5609
2022-07-13 21:30:55 - train: epoch 0046, iter [02600, 05004], lr: 0.010000, loss: 1.5447
2022-07-13 21:31:28 - train: epoch 0046, iter [02700, 05004], lr: 0.010000, loss: 1.3643
2022-07-13 21:32:01 - train: epoch 0046, iter [02800, 05004], lr: 0.010000, loss: 1.2927
2022-07-13 21:32:35 - train: epoch 0046, iter [02900, 05004], lr: 0.010000, loss: 1.4374
2022-07-13 21:33:08 - train: epoch 0046, iter [03000, 05004], lr: 0.010000, loss: 1.3206
2022-07-13 21:33:42 - train: epoch 0046, iter [03100, 05004], lr: 0.010000, loss: 1.3048
2022-07-13 21:34:14 - train: epoch 0046, iter [03200, 05004], lr: 0.010000, loss: 1.7176
2022-07-13 21:34:49 - train: epoch 0046, iter [03300, 05004], lr: 0.010000, loss: 1.4284
2022-07-13 21:35:21 - train: epoch 0046, iter [03400, 05004], lr: 0.010000, loss: 1.4479
2022-07-13 21:35:56 - train: epoch 0046, iter [03500, 05004], lr: 0.010000, loss: 1.5100
2022-07-13 21:36:28 - train: epoch 0046, iter [03600, 05004], lr: 0.010000, loss: 1.2861
2022-07-13 21:37:01 - train: epoch 0046, iter [03700, 05004], lr: 0.010000, loss: 1.2925
2022-07-13 21:37:35 - train: epoch 0046, iter [03800, 05004], lr: 0.010000, loss: 1.5673
2022-07-13 21:38:09 - train: epoch 0046, iter [03900, 05004], lr: 0.010000, loss: 1.4626
2022-07-13 21:38:42 - train: epoch 0046, iter [04000, 05004], lr: 0.010000, loss: 1.2979
2022-07-13 21:39:15 - train: epoch 0046, iter [04100, 05004], lr: 0.010000, loss: 1.6281
2022-07-13 21:39:49 - train: epoch 0046, iter [04200, 05004], lr: 0.010000, loss: 1.3500
2022-07-13 21:40:22 - train: epoch 0046, iter [04300, 05004], lr: 0.010000, loss: 1.6536
2022-07-13 21:40:56 - train: epoch 0046, iter [04400, 05004], lr: 0.010000, loss: 1.5104
2022-07-13 21:41:29 - train: epoch 0046, iter [04500, 05004], lr: 0.010000, loss: 1.3216
2022-07-13 21:42:03 - train: epoch 0046, iter [04600, 05004], lr: 0.010000, loss: 1.4731
2022-07-13 21:42:36 - train: epoch 0046, iter [04700, 05004], lr: 0.010000, loss: 1.2659
2022-07-13 21:43:09 - train: epoch 0046, iter [04800, 05004], lr: 0.010000, loss: 1.4339
2022-07-13 21:43:42 - train: epoch 0046, iter [04900, 05004], lr: 0.010000, loss: 1.4662
2022-07-13 21:44:15 - train: epoch 0046, iter [05000, 05004], lr: 0.010000, loss: 1.4100
2022-07-13 21:44:16 - train: epoch 046, train_loss: 1.4269
2022-07-13 21:45:31 - eval: epoch: 046, acc1: 68.836%, acc5: 89.024%, test_loss: 1.2636, per_image_load_time: 2.014ms, per_image_inference_time: 0.300ms
2022-07-13 21:45:31 - until epoch: 046, best_acc1: 69.476%
2022-07-13 21:45:31 - epoch 047 lr: 0.010000
2022-07-13 21:46:09 - train: epoch 0047, iter [00100, 05004], lr: 0.010000, loss: 1.3783
2022-07-13 21:46:43 - train: epoch 0047, iter [00200, 05004], lr: 0.010000, loss: 1.4993
2022-07-13 21:47:17 - train: epoch 0047, iter [00300, 05004], lr: 0.010000, loss: 1.2858
2022-07-13 21:47:49 - train: epoch 0047, iter [00400, 05004], lr: 0.010000, loss: 1.2210
2022-07-13 21:48:24 - train: epoch 0047, iter [00500, 05004], lr: 0.010000, loss: 1.5399
2022-07-13 21:48:56 - train: epoch 0047, iter [00600, 05004], lr: 0.010000, loss: 1.3731
2022-07-13 21:49:30 - train: epoch 0047, iter [00700, 05004], lr: 0.010000, loss: 1.5873
2022-07-13 21:50:03 - train: epoch 0047, iter [00800, 05004], lr: 0.010000, loss: 1.2506
2022-07-13 21:50:35 - train: epoch 0047, iter [00900, 05004], lr: 0.010000, loss: 1.5058
2022-07-13 21:51:09 - train: epoch 0047, iter [01000, 05004], lr: 0.010000, loss: 1.5416
2022-07-13 21:51:42 - train: epoch 0047, iter [01100, 05004], lr: 0.010000, loss: 1.5049
2022-07-13 21:52:15 - train: epoch 0047, iter [01200, 05004], lr: 0.010000, loss: 1.3513
2022-07-13 21:52:49 - train: epoch 0047, iter [01300, 05004], lr: 0.010000, loss: 1.3896
2022-07-13 21:53:22 - train: epoch 0047, iter [01400, 05004], lr: 0.010000, loss: 1.4483
2022-07-13 21:53:55 - train: epoch 0047, iter [01500, 05004], lr: 0.010000, loss: 1.3563
2022-07-13 21:54:29 - train: epoch 0047, iter [01600, 05004], lr: 0.010000, loss: 1.3689
2022-07-13 21:55:02 - train: epoch 0047, iter [01700, 05004], lr: 0.010000, loss: 1.1642
2022-07-13 21:55:35 - train: epoch 0047, iter [01800, 05004], lr: 0.010000, loss: 1.3434
2022-07-13 21:56:09 - train: epoch 0047, iter [01900, 05004], lr: 0.010000, loss: 1.4038
2022-07-13 21:56:43 - train: epoch 0047, iter [02000, 05004], lr: 0.010000, loss: 1.3353
2022-07-13 21:57:15 - train: epoch 0047, iter [02100, 05004], lr: 0.010000, loss: 1.6355
2022-07-13 21:57:49 - train: epoch 0047, iter [02200, 05004], lr: 0.010000, loss: 1.5486
2022-07-13 21:58:22 - train: epoch 0047, iter [02300, 05004], lr: 0.010000, loss: 1.4240
2022-07-13 21:58:55 - train: epoch 0047, iter [02400, 05004], lr: 0.010000, loss: 1.2388
2022-07-13 21:59:28 - train: epoch 0047, iter [02500, 05004], lr: 0.010000, loss: 1.4498
2022-07-13 22:00:02 - train: epoch 0047, iter [02600, 05004], lr: 0.010000, loss: 1.7204
2022-07-13 22:00:36 - train: epoch 0047, iter [02700, 05004], lr: 0.010000, loss: 1.4332
2022-07-13 22:01:08 - train: epoch 0047, iter [02800, 05004], lr: 0.010000, loss: 1.6701
2022-07-13 22:01:43 - train: epoch 0047, iter [02900, 05004], lr: 0.010000, loss: 1.4739
2022-07-13 22:02:15 - train: epoch 0047, iter [03000, 05004], lr: 0.010000, loss: 1.5487
2022-07-13 22:02:49 - train: epoch 0047, iter [03100, 05004], lr: 0.010000, loss: 1.3584
2022-07-13 22:03:22 - train: epoch 0047, iter [03200, 05004], lr: 0.010000, loss: 1.6584
2022-07-13 22:03:56 - train: epoch 0047, iter [03300, 05004], lr: 0.010000, loss: 1.2267
2022-07-13 22:04:30 - train: epoch 0047, iter [03400, 05004], lr: 0.010000, loss: 1.3953
2022-07-13 22:05:03 - train: epoch 0047, iter [03500, 05004], lr: 0.010000, loss: 1.6000
2022-07-13 22:05:36 - train: epoch 0047, iter [03600, 05004], lr: 0.010000, loss: 1.4746
2022-07-13 22:06:10 - train: epoch 0047, iter [03700, 05004], lr: 0.010000, loss: 1.5055
2022-07-13 22:06:43 - train: epoch 0047, iter [03800, 05004], lr: 0.010000, loss: 1.4002
2022-07-13 22:07:18 - train: epoch 0047, iter [03900, 05004], lr: 0.010000, loss: 1.3785
2022-07-13 22:07:50 - train: epoch 0047, iter [04000, 05004], lr: 0.010000, loss: 1.5363
2022-07-13 22:08:24 - train: epoch 0047, iter [04100, 05004], lr: 0.010000, loss: 1.4880
2022-07-13 22:08:57 - train: epoch 0047, iter [04200, 05004], lr: 0.010000, loss: 1.4762
2022-07-13 22:09:31 - train: epoch 0047, iter [04300, 05004], lr: 0.010000, loss: 1.2846
2022-07-13 22:10:05 - train: epoch 0047, iter [04400, 05004], lr: 0.010000, loss: 1.4655
2022-07-13 22:10:38 - train: epoch 0047, iter [04500, 05004], lr: 0.010000, loss: 1.6118
2022-07-13 22:11:11 - train: epoch 0047, iter [04600, 05004], lr: 0.010000, loss: 1.5038
2022-07-13 22:11:45 - train: epoch 0047, iter [04700, 05004], lr: 0.010000, loss: 1.4491
2022-07-13 22:12:19 - train: epoch 0047, iter [04800, 05004], lr: 0.010000, loss: 1.3505
2022-07-13 22:12:52 - train: epoch 0047, iter [04900, 05004], lr: 0.010000, loss: 1.5342
2022-07-13 22:13:25 - train: epoch 0047, iter [05000, 05004], lr: 0.010000, loss: 1.3875
2022-07-13 22:13:25 - train: epoch 047, train_loss: 1.4265
2022-07-13 22:14:40 - eval: epoch: 047, acc1: 69.218%, acc5: 89.170%, test_loss: 1.2533, per_image_load_time: 2.459ms, per_image_inference_time: 0.299ms
2022-07-13 22:14:41 - until epoch: 047, best_acc1: 69.476%
2022-07-13 22:14:41 - epoch 048 lr: 0.010000
2022-07-13 22:15:19 - train: epoch 0048, iter [00100, 05004], lr: 0.010000, loss: 1.6253
2022-07-13 22:15:53 - train: epoch 0048, iter [00200, 05004], lr: 0.010000, loss: 1.8330
2022-07-13 22:16:27 - train: epoch 0048, iter [00300, 05004], lr: 0.010000, loss: 1.3497
2022-07-13 22:16:59 - train: epoch 0048, iter [00400, 05004], lr: 0.010000, loss: 1.3931
2022-07-13 22:17:33 - train: epoch 0048, iter [00500, 05004], lr: 0.010000, loss: 1.3020
2022-07-13 22:18:06 - train: epoch 0048, iter [00600, 05004], lr: 0.010000, loss: 1.4585
2022-07-13 22:18:40 - train: epoch 0048, iter [00700, 05004], lr: 0.010000, loss: 1.4728
2022-07-13 22:19:13 - train: epoch 0048, iter [00800, 05004], lr: 0.010000, loss: 1.4411
2022-07-13 22:19:46 - train: epoch 0048, iter [00900, 05004], lr: 0.010000, loss: 1.5204
2022-07-13 22:20:19 - train: epoch 0048, iter [01000, 05004], lr: 0.010000, loss: 1.4164
2022-07-13 22:20:54 - train: epoch 0048, iter [01100, 05004], lr: 0.010000, loss: 1.4251
2022-07-13 22:21:26 - train: epoch 0048, iter [01200, 05004], lr: 0.010000, loss: 1.5127
2022-07-13 22:22:00 - train: epoch 0048, iter [01300, 05004], lr: 0.010000, loss: 1.1887
2022-07-13 22:22:33 - train: epoch 0048, iter [01400, 05004], lr: 0.010000, loss: 1.2782
2022-07-13 22:23:06 - train: epoch 0048, iter [01500, 05004], lr: 0.010000, loss: 1.5055
2022-07-13 22:23:39 - train: epoch 0048, iter [01600, 05004], lr: 0.010000, loss: 1.3049
2022-07-13 22:24:13 - train: epoch 0048, iter [01700, 05004], lr: 0.010000, loss: 1.5684
2022-07-13 22:24:46 - train: epoch 0048, iter [01800, 05004], lr: 0.010000, loss: 1.4698
2022-07-13 22:25:20 - train: epoch 0048, iter [01900, 05004], lr: 0.010000, loss: 1.4914
2022-07-13 22:25:53 - train: epoch 0048, iter [02000, 05004], lr: 0.010000, loss: 1.6339
2022-07-13 22:26:27 - train: epoch 0048, iter [02100, 05004], lr: 0.010000, loss: 1.3968
2022-07-13 22:27:00 - train: epoch 0048, iter [02200, 05004], lr: 0.010000, loss: 1.5683
2022-07-13 22:27:33 - train: epoch 0048, iter [02300, 05004], lr: 0.010000, loss: 1.3054
2022-07-13 22:28:07 - train: epoch 0048, iter [02400, 05004], lr: 0.010000, loss: 1.5866
2022-07-13 22:28:40 - train: epoch 0048, iter [02500, 05004], lr: 0.010000, loss: 1.4049
2022-07-13 22:29:14 - train: epoch 0048, iter [02600, 05004], lr: 0.010000, loss: 1.6442
2022-07-13 22:29:47 - train: epoch 0048, iter [02700, 05004], lr: 0.010000, loss: 1.6105
2022-07-13 22:30:20 - train: epoch 0048, iter [02800, 05004], lr: 0.010000, loss: 1.3804
2022-07-13 22:30:54 - train: epoch 0048, iter [02900, 05004], lr: 0.010000, loss: 1.6095
2022-07-13 22:31:27 - train: epoch 0048, iter [03000, 05004], lr: 0.010000, loss: 1.3521
2022-07-13 22:32:01 - train: epoch 0048, iter [03100, 05004], lr: 0.010000, loss: 1.3345
2022-07-13 22:32:34 - train: epoch 0048, iter [03200, 05004], lr: 0.010000, loss: 1.3332
2022-07-13 22:33:08 - train: epoch 0048, iter [03300, 05004], lr: 0.010000, loss: 1.6565
2022-07-13 22:33:41 - train: epoch 0048, iter [03400, 05004], lr: 0.010000, loss: 1.4260
2022-07-13 22:34:15 - train: epoch 0048, iter [03500, 05004], lr: 0.010000, loss: 1.6285
2022-07-13 22:34:48 - train: epoch 0048, iter [03600, 05004], lr: 0.010000, loss: 1.4857
2022-07-13 22:35:22 - train: epoch 0048, iter [03700, 05004], lr: 0.010000, loss: 1.5111
2022-07-13 22:35:55 - train: epoch 0048, iter [03800, 05004], lr: 0.010000, loss: 1.3928
2022-07-13 22:36:29 - train: epoch 0048, iter [03900, 05004], lr: 0.010000, loss: 1.6113
2022-07-13 22:37:02 - train: epoch 0048, iter [04000, 05004], lr: 0.010000, loss: 1.1754
2022-07-13 22:37:36 - train: epoch 0048, iter [04100, 05004], lr: 0.010000, loss: 1.5724
2022-07-13 22:38:09 - train: epoch 0048, iter [04200, 05004], lr: 0.010000, loss: 1.3378
2022-07-13 22:38:42 - train: epoch 0048, iter [04300, 05004], lr: 0.010000, loss: 1.4517
2022-07-13 22:39:16 - train: epoch 0048, iter [04400, 05004], lr: 0.010000, loss: 1.2672
2022-07-13 22:39:50 - train: epoch 0048, iter [04500, 05004], lr: 0.010000, loss: 1.4679
2022-07-13 22:40:24 - train: epoch 0048, iter [04600, 05004], lr: 0.010000, loss: 1.3166
2022-07-13 22:40:57 - train: epoch 0048, iter [04700, 05004], lr: 0.010000, loss: 1.5352
2022-07-13 22:41:31 - train: epoch 0048, iter [04800, 05004], lr: 0.010000, loss: 1.7637
2022-07-13 22:42:05 - train: epoch 0048, iter [04900, 05004], lr: 0.010000, loss: 1.4524
2022-07-13 22:42:36 - train: epoch 0048, iter [05000, 05004], lr: 0.010000, loss: 1.4424
2022-07-13 22:42:37 - train: epoch 048, train_loss: 1.4277
2022-07-13 22:43:51 - eval: epoch: 048, acc1: 68.924%, acc5: 88.794%, test_loss: 1.2700, per_image_load_time: 2.537ms, per_image_inference_time: 0.305ms
2022-07-13 22:43:52 - until epoch: 048, best_acc1: 69.476%
2022-07-13 22:43:52 - epoch 049 lr: 0.010000
2022-07-13 22:44:31 - train: epoch 0049, iter [00100, 05004], lr: 0.010000, loss: 1.5963
2022-07-13 22:45:04 - train: epoch 0049, iter [00200, 05004], lr: 0.010000, loss: 1.3438
2022-07-13 22:45:37 - train: epoch 0049, iter [00300, 05004], lr: 0.010000, loss: 1.4782
2022-07-13 22:46:11 - train: epoch 0049, iter [00400, 05004], lr: 0.010000, loss: 1.5134
2022-07-13 22:46:43 - train: epoch 0049, iter [00500, 05004], lr: 0.010000, loss: 1.4167
2022-07-13 22:47:17 - train: epoch 0049, iter [00600, 05004], lr: 0.010000, loss: 1.4161
2022-07-13 22:47:51 - train: epoch 0049, iter [00700, 05004], lr: 0.010000, loss: 1.4905
2022-07-13 22:48:24 - train: epoch 0049, iter [00800, 05004], lr: 0.010000, loss: 1.7490
2022-07-13 22:48:57 - train: epoch 0049, iter [00900, 05004], lr: 0.010000, loss: 1.2995
2022-07-13 22:49:30 - train: epoch 0049, iter [01000, 05004], lr: 0.010000, loss: 1.4222
2022-07-13 22:50:04 - train: epoch 0049, iter [01100, 05004], lr: 0.010000, loss: 1.3281
2022-07-13 22:50:38 - train: epoch 0049, iter [01200, 05004], lr: 0.010000, loss: 1.2501
2022-07-13 22:51:11 - train: epoch 0049, iter [01300, 05004], lr: 0.010000, loss: 1.5635
2022-07-13 22:51:45 - train: epoch 0049, iter [01400, 05004], lr: 0.010000, loss: 1.5525
2022-07-13 22:52:17 - train: epoch 0049, iter [01500, 05004], lr: 0.010000, loss: 1.3132
2022-07-13 22:52:52 - train: epoch 0049, iter [01600, 05004], lr: 0.010000, loss: 1.5488
2022-07-13 22:53:24 - train: epoch 0049, iter [01700, 05004], lr: 0.010000, loss: 1.5229
2022-07-13 22:53:58 - train: epoch 0049, iter [01800, 05004], lr: 0.010000, loss: 1.2521
2022-07-13 22:54:31 - train: epoch 0049, iter [01900, 05004], lr: 0.010000, loss: 1.3811
2022-07-13 22:55:04 - train: epoch 0049, iter [02000, 05004], lr: 0.010000, loss: 1.3468
2022-07-13 22:55:38 - train: epoch 0049, iter [02100, 05004], lr: 0.010000, loss: 1.3676
2022-07-13 22:56:11 - train: epoch 0049, iter [02200, 05004], lr: 0.010000, loss: 1.4211
2022-07-13 22:56:44 - train: epoch 0049, iter [02300, 05004], lr: 0.010000, loss: 1.3230
2022-07-13 22:57:18 - train: epoch 0049, iter [02400, 05004], lr: 0.010000, loss: 1.4901
2022-07-13 22:57:51 - train: epoch 0049, iter [02500, 05004], lr: 0.010000, loss: 1.4865
2022-07-13 22:58:25 - train: epoch 0049, iter [02600, 05004], lr: 0.010000, loss: 1.4514
2022-07-13 22:58:58 - train: epoch 0049, iter [02700, 05004], lr: 0.010000, loss: 1.2717
2022-07-13 22:59:32 - train: epoch 0049, iter [02800, 05004], lr: 0.010000, loss: 1.4054
2022-07-13 23:00:06 - train: epoch 0049, iter [02900, 05004], lr: 0.010000, loss: 1.5438
2022-07-13 23:00:40 - train: epoch 0049, iter [03000, 05004], lr: 0.010000, loss: 1.6991
2022-07-13 23:01:13 - train: epoch 0049, iter [03100, 05004], lr: 0.010000, loss: 1.4508
2022-07-13 23:01:46 - train: epoch 0049, iter [03200, 05004], lr: 0.010000, loss: 1.4339
2022-07-13 23:02:20 - train: epoch 0049, iter [03300, 05004], lr: 0.010000, loss: 1.4296
2022-07-13 23:02:53 - train: epoch 0049, iter [03400, 05004], lr: 0.010000, loss: 1.5440
2022-07-13 23:03:26 - train: epoch 0049, iter [03500, 05004], lr: 0.010000, loss: 1.4927
2022-07-13 23:04:00 - train: epoch 0049, iter [03600, 05004], lr: 0.010000, loss: 1.6367
2022-07-13 23:04:32 - train: epoch 0049, iter [03700, 05004], lr: 0.010000, loss: 1.4174
2022-07-13 23:05:07 - train: epoch 0049, iter [03800, 05004], lr: 0.010000, loss: 1.6006
2022-07-13 23:05:40 - train: epoch 0049, iter [03900, 05004], lr: 0.010000, loss: 1.6546
2022-07-13 23:06:14 - train: epoch 0049, iter [04000, 05004], lr: 0.010000, loss: 1.4648
2022-07-13 23:06:47 - train: epoch 0049, iter [04100, 05004], lr: 0.010000, loss: 1.3260
2022-07-13 23:07:20 - train: epoch 0049, iter [04200, 05004], lr: 0.010000, loss: 1.4428
2022-07-13 23:07:55 - train: epoch 0049, iter [04300, 05004], lr: 0.010000, loss: 1.7029
2022-07-13 23:08:28 - train: epoch 0049, iter [04400, 05004], lr: 0.010000, loss: 1.3664
2022-07-13 23:09:02 - train: epoch 0049, iter [04500, 05004], lr: 0.010000, loss: 1.3344
2022-07-13 23:09:34 - train: epoch 0049, iter [04600, 05004], lr: 0.010000, loss: 1.5448
2022-07-13 23:10:08 - train: epoch 0049, iter [04700, 05004], lr: 0.010000, loss: 1.6629
2022-07-13 23:10:42 - train: epoch 0049, iter [04800, 05004], lr: 0.010000, loss: 1.2259
2022-07-13 23:11:15 - train: epoch 0049, iter [04900, 05004], lr: 0.010000, loss: 1.2435
2022-07-13 23:11:47 - train: epoch 0049, iter [05000, 05004], lr: 0.010000, loss: 1.3553
2022-07-13 23:11:48 - train: epoch 049, train_loss: 1.4223
2022-07-13 23:13:02 - eval: epoch: 049, acc1: 69.098%, acc5: 89.036%, test_loss: 1.2560, per_image_load_time: 2.217ms, per_image_inference_time: 0.308ms
2022-07-13 23:13:03 - until epoch: 049, best_acc1: 69.476%
2022-07-13 23:13:03 - epoch 050 lr: 0.010000
2022-07-13 23:13:42 - train: epoch 0050, iter [00100, 05004], lr: 0.010000, loss: 1.5075
2022-07-13 23:14:14 - train: epoch 0050, iter [00200, 05004], lr: 0.010000, loss: 1.3550
2022-07-13 23:14:48 - train: epoch 0050, iter [00300, 05004], lr: 0.010000, loss: 1.3780
2022-07-13 23:15:22 - train: epoch 0050, iter [00400, 05004], lr: 0.010000, loss: 1.3711
2022-07-13 23:15:55 - train: epoch 0050, iter [00500, 05004], lr: 0.010000, loss: 1.5269
2022-07-13 23:16:28 - train: epoch 0050, iter [00600, 05004], lr: 0.010000, loss: 1.4689
2022-07-13 23:17:01 - train: epoch 0050, iter [00700, 05004], lr: 0.010000, loss: 1.2609
2022-07-13 23:17:35 - train: epoch 0050, iter [00800, 05004], lr: 0.010000, loss: 1.1838
2022-07-13 23:18:08 - train: epoch 0050, iter [00900, 05004], lr: 0.010000, loss: 1.2979
2022-07-13 23:18:42 - train: epoch 0050, iter [01000, 05004], lr: 0.010000, loss: 1.5368
2022-07-13 23:19:15 - train: epoch 0050, iter [01100, 05004], lr: 0.010000, loss: 1.5234
2022-07-13 23:19:48 - train: epoch 0050, iter [01200, 05004], lr: 0.010000, loss: 1.4683
2022-07-13 23:20:21 - train: epoch 0050, iter [01300, 05004], lr: 0.010000, loss: 1.2402
2022-07-13 23:20:54 - train: epoch 0050, iter [01400, 05004], lr: 0.010000, loss: 1.4800
2022-07-13 23:21:27 - train: epoch 0050, iter [01500, 05004], lr: 0.010000, loss: 1.4510
2022-07-13 23:22:01 - train: epoch 0050, iter [01600, 05004], lr: 0.010000, loss: 1.3838
2022-07-13 23:22:35 - train: epoch 0050, iter [01700, 05004], lr: 0.010000, loss: 1.4919
2022-07-13 23:23:08 - train: epoch 0050, iter [01800, 05004], lr: 0.010000, loss: 1.3798
2022-07-13 23:23:42 - train: epoch 0050, iter [01900, 05004], lr: 0.010000, loss: 1.3482
2022-07-13 23:24:15 - train: epoch 0050, iter [02000, 05004], lr: 0.010000, loss: 1.4308
2022-07-13 23:24:48 - train: epoch 0050, iter [02100, 05004], lr: 0.010000, loss: 1.1354
