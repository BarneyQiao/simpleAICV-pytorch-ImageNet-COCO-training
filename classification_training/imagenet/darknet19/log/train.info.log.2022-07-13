2022-07-13 23:25:22 - train: epoch 0050, iter [02200, 05004], lr: 0.010000, loss: 1.4935
2022-07-13 23:25:56 - train: epoch 0050, iter [02300, 05004], lr: 0.010000, loss: 1.3581
2022-07-13 23:26:30 - train: epoch 0050, iter [02400, 05004], lr: 0.010000, loss: 1.3743
2022-07-13 23:27:03 - train: epoch 0050, iter [02500, 05004], lr: 0.010000, loss: 1.4503
2022-07-13 23:27:36 - train: epoch 0050, iter [02600, 05004], lr: 0.010000, loss: 1.3036
2022-07-13 23:28:10 - train: epoch 0050, iter [02700, 05004], lr: 0.010000, loss: 1.4581
2022-07-13 23:28:43 - train: epoch 0050, iter [02800, 05004], lr: 0.010000, loss: 1.6568
2022-07-13 23:29:17 - train: epoch 0050, iter [02900, 05004], lr: 0.010000, loss: 1.5618
2022-07-13 23:29:50 - train: epoch 0050, iter [03000, 05004], lr: 0.010000, loss: 1.5028
2022-07-13 23:30:24 - train: epoch 0050, iter [03100, 05004], lr: 0.010000, loss: 1.3642
2022-07-13 23:30:57 - train: epoch 0050, iter [03200, 05004], lr: 0.010000, loss: 1.3645
2022-07-13 23:31:31 - train: epoch 0050, iter [03300, 05004], lr: 0.010000, loss: 1.3905
2022-07-13 23:32:05 - train: epoch 0050, iter [03400, 05004], lr: 0.010000, loss: 1.3340
2022-07-13 23:32:38 - train: epoch 0050, iter [03500, 05004], lr: 0.010000, loss: 1.4311
2022-07-13 23:33:12 - train: epoch 0050, iter [03600, 05004], lr: 0.010000, loss: 1.4172
2022-07-13 23:33:45 - train: epoch 0050, iter [03700, 05004], lr: 0.010000, loss: 1.4249
2022-07-13 23:34:18 - train: epoch 0050, iter [03800, 05004], lr: 0.010000, loss: 1.2118
2022-07-13 23:34:51 - train: epoch 0050, iter [03900, 05004], lr: 0.010000, loss: 1.2274
2022-07-13 23:35:25 - train: epoch 0050, iter [04000, 05004], lr: 0.010000, loss: 1.5553
2022-07-13 23:35:59 - train: epoch 0050, iter [04100, 05004], lr: 0.010000, loss: 1.3638
2022-07-13 23:36:32 - train: epoch 0050, iter [04200, 05004], lr: 0.010000, loss: 1.4142
2022-07-13 23:37:05 - train: epoch 0050, iter [04300, 05004], lr: 0.010000, loss: 1.3528
2022-07-13 23:37:39 - train: epoch 0050, iter [04400, 05004], lr: 0.010000, loss: 1.3750
2022-07-13 23:38:13 - train: epoch 0050, iter [04500, 05004], lr: 0.010000, loss: 1.3842
2022-07-13 23:38:46 - train: epoch 0050, iter [04600, 05004], lr: 0.010000, loss: 1.3807
2022-07-13 23:39:19 - train: epoch 0050, iter [04700, 05004], lr: 0.010000, loss: 1.5017
2022-07-13 23:39:52 - train: epoch 0050, iter [04800, 05004], lr: 0.010000, loss: 1.1671
2022-07-13 23:40:26 - train: epoch 0050, iter [04900, 05004], lr: 0.010000, loss: 1.2749
2022-07-13 23:40:58 - train: epoch 0050, iter [05000, 05004], lr: 0.010000, loss: 1.3828
2022-07-13 23:40:59 - train: epoch 050, train_loss: 1.4189
2022-07-13 23:42:14 - eval: epoch: 050, acc1: 69.100%, acc5: 89.254%, test_loss: 1.2574, per_image_load_time: 2.537ms, per_image_inference_time: 0.285ms
2022-07-13 23:42:14 - until epoch: 050, best_acc1: 69.476%
2022-07-13 23:42:14 - epoch 051 lr: 0.010000
2022-07-13 23:42:54 - train: epoch 0051, iter [00100, 05004], lr: 0.010000, loss: 1.4584
2022-07-13 23:43:26 - train: epoch 0051, iter [00200, 05004], lr: 0.010000, loss: 1.7330
2022-07-13 23:44:00 - train: epoch 0051, iter [00300, 05004], lr: 0.010000, loss: 1.4965
2022-07-13 23:44:33 - train: epoch 0051, iter [00400, 05004], lr: 0.010000, loss: 1.2627
2022-07-13 23:45:07 - train: epoch 0051, iter [00500, 05004], lr: 0.010000, loss: 1.4474
2022-07-13 23:45:39 - train: epoch 0051, iter [00600, 05004], lr: 0.010000, loss: 1.3663
2022-07-13 23:46:13 - train: epoch 0051, iter [00700, 05004], lr: 0.010000, loss: 1.2899
2022-07-13 23:46:45 - train: epoch 0051, iter [00800, 05004], lr: 0.010000, loss: 1.6262
2022-07-13 23:47:19 - train: epoch 0051, iter [00900, 05004], lr: 0.010000, loss: 1.2743
2022-07-13 23:47:52 - train: epoch 0051, iter [01000, 05004], lr: 0.010000, loss: 1.6726
2022-07-13 23:48:25 - train: epoch 0051, iter [01100, 05004], lr: 0.010000, loss: 1.6016
2022-07-13 23:48:59 - train: epoch 0051, iter [01200, 05004], lr: 0.010000, loss: 1.3642
2022-07-13 23:49:31 - train: epoch 0051, iter [01300, 05004], lr: 0.010000, loss: 1.1039
2022-07-13 23:50:05 - train: epoch 0051, iter [01400, 05004], lr: 0.010000, loss: 1.3360
2022-07-13 23:50:38 - train: epoch 0051, iter [01500, 05004], lr: 0.010000, loss: 1.3480
2022-07-13 23:51:11 - train: epoch 0051, iter [01600, 05004], lr: 0.010000, loss: 1.3020
2022-07-13 23:51:45 - train: epoch 0051, iter [01700, 05004], lr: 0.010000, loss: 1.4635
2022-07-13 23:52:18 - train: epoch 0051, iter [01800, 05004], lr: 0.010000, loss: 1.4969
2022-07-13 23:52:51 - train: epoch 0051, iter [01900, 05004], lr: 0.010000, loss: 1.1806
2022-07-13 23:53:24 - train: epoch 0051, iter [02000, 05004], lr: 0.010000, loss: 1.4096
2022-07-13 23:53:58 - train: epoch 0051, iter [02100, 05004], lr: 0.010000, loss: 1.4139
2022-07-13 23:54:32 - train: epoch 0051, iter [02200, 05004], lr: 0.010000, loss: 1.4447
2022-07-13 23:55:04 - train: epoch 0051, iter [02300, 05004], lr: 0.010000, loss: 1.4040
2022-07-13 23:55:38 - train: epoch 0051, iter [02400, 05004], lr: 0.010000, loss: 1.4756
2022-07-13 23:56:11 - train: epoch 0051, iter [02500, 05004], lr: 0.010000, loss: 1.3683
2022-07-13 23:56:45 - train: epoch 0051, iter [02600, 05004], lr: 0.010000, loss: 1.3201
2022-07-13 23:57:17 - train: epoch 0051, iter [02700, 05004], lr: 0.010000, loss: 1.4539
2022-07-13 23:57:51 - train: epoch 0051, iter [02800, 05004], lr: 0.010000, loss: 1.3080
2022-07-13 23:58:24 - train: epoch 0051, iter [02900, 05004], lr: 0.010000, loss: 1.3716
2022-07-13 23:58:58 - train: epoch 0051, iter [03000, 05004], lr: 0.010000, loss: 1.3417
2022-07-13 23:59:31 - train: epoch 0051, iter [03100, 05004], lr: 0.010000, loss: 1.2917
2022-07-14 00:00:05 - train: epoch 0051, iter [03200, 05004], lr: 0.010000, loss: 1.4182
2022-07-14 00:00:38 - train: epoch 0051, iter [03300, 05004], lr: 0.010000, loss: 1.5753
2022-07-14 00:01:12 - train: epoch 0051, iter [03400, 05004], lr: 0.010000, loss: 1.4452
2022-07-14 00:01:45 - train: epoch 0051, iter [03500, 05004], lr: 0.010000, loss: 1.3161
2022-07-14 00:02:18 - train: epoch 0051, iter [03600, 05004], lr: 0.010000, loss: 1.3948
2022-07-14 00:02:52 - train: epoch 0051, iter [03700, 05004], lr: 0.010000, loss: 1.5948
2022-07-14 00:03:24 - train: epoch 0051, iter [03800, 05004], lr: 0.010000, loss: 1.3640
2022-07-14 00:03:58 - train: epoch 0051, iter [03900, 05004], lr: 0.010000, loss: 1.3978
2022-07-14 00:04:31 - train: epoch 0051, iter [04000, 05004], lr: 0.010000, loss: 1.3859
2022-07-14 00:05:05 - train: epoch 0051, iter [04100, 05004], lr: 0.010000, loss: 1.5313
2022-07-14 00:05:38 - train: epoch 0051, iter [04200, 05004], lr: 0.010000, loss: 1.7557
2022-07-14 00:06:10 - train: epoch 0051, iter [04300, 05004], lr: 0.010000, loss: 1.3344
2022-07-14 00:06:44 - train: epoch 0051, iter [04400, 05004], lr: 0.010000, loss: 1.3634
2022-07-14 00:07:17 - train: epoch 0051, iter [04500, 05004], lr: 0.010000, loss: 1.2935
2022-07-14 00:07:51 - train: epoch 0051, iter [04600, 05004], lr: 0.010000, loss: 1.4900
2022-07-14 00:08:23 - train: epoch 0051, iter [04700, 05004], lr: 0.010000, loss: 1.3757
2022-07-14 00:08:57 - train: epoch 0051, iter [04800, 05004], lr: 0.010000, loss: 1.3671
2022-07-14 00:09:30 - train: epoch 0051, iter [04900, 05004], lr: 0.010000, loss: 1.5694
2022-07-14 00:10:02 - train: epoch 0051, iter [05000, 05004], lr: 0.010000, loss: 1.3854
2022-07-14 00:10:03 - train: epoch 051, train_loss: 1.4177
2022-07-14 00:11:19 - eval: epoch: 051, acc1: 68.610%, acc5: 88.676%, test_loss: 1.2791, per_image_load_time: 1.905ms, per_image_inference_time: 0.293ms
2022-07-14 00:11:19 - until epoch: 051, best_acc1: 69.476%
2022-07-14 00:11:19 - epoch 052 lr: 0.010000
2022-07-14 00:11:57 - train: epoch 0052, iter [00100, 05004], lr: 0.010000, loss: 1.2921
2022-07-14 00:12:32 - train: epoch 0052, iter [00200, 05004], lr: 0.010000, loss: 1.4679
2022-07-14 00:13:05 - train: epoch 0052, iter [00300, 05004], lr: 0.010000, loss: 1.5433
2022-07-14 00:13:37 - train: epoch 0052, iter [00400, 05004], lr: 0.010000, loss: 1.4544
2022-07-14 00:14:12 - train: epoch 0052, iter [00500, 05004], lr: 0.010000, loss: 1.5058
2022-07-14 00:14:45 - train: epoch 0052, iter [00600, 05004], lr: 0.010000, loss: 1.2023
2022-07-14 00:15:18 - train: epoch 0052, iter [00700, 05004], lr: 0.010000, loss: 1.4305
2022-07-14 00:15:51 - train: epoch 0052, iter [00800, 05004], lr: 0.010000, loss: 1.3684
2022-07-14 00:16:25 - train: epoch 0052, iter [00900, 05004], lr: 0.010000, loss: 1.4686
2022-07-14 00:16:57 - train: epoch 0052, iter [01000, 05004], lr: 0.010000, loss: 1.6635
2022-07-14 00:17:30 - train: epoch 0052, iter [01100, 05004], lr: 0.010000, loss: 1.3738
2022-07-14 00:18:05 - train: epoch 0052, iter [01200, 05004], lr: 0.010000, loss: 1.2535
2022-07-14 00:18:37 - train: epoch 0052, iter [01300, 05004], lr: 0.010000, loss: 1.3529
2022-07-14 00:19:10 - train: epoch 0052, iter [01400, 05004], lr: 0.010000, loss: 1.6895
2022-07-14 00:19:44 - train: epoch 0052, iter [01500, 05004], lr: 0.010000, loss: 1.2390
2022-07-14 00:20:17 - train: epoch 0052, iter [01600, 05004], lr: 0.010000, loss: 1.3754
2022-07-14 00:20:50 - train: epoch 0052, iter [01700, 05004], lr: 0.010000, loss: 1.1872
2022-07-14 00:21:23 - train: epoch 0052, iter [01800, 05004], lr: 0.010000, loss: 1.2337
2022-07-14 00:21:56 - train: epoch 0052, iter [01900, 05004], lr: 0.010000, loss: 1.4012
2022-07-14 00:22:30 - train: epoch 0052, iter [02000, 05004], lr: 0.010000, loss: 1.4460
2022-07-14 00:23:03 - train: epoch 0052, iter [02100, 05004], lr: 0.010000, loss: 1.2638
2022-07-14 00:23:37 - train: epoch 0052, iter [02200, 05004], lr: 0.010000, loss: 1.5190
2022-07-14 00:24:10 - train: epoch 0052, iter [02300, 05004], lr: 0.010000, loss: 1.2361
2022-07-14 00:24:44 - train: epoch 0052, iter [02400, 05004], lr: 0.010000, loss: 1.2075
2022-07-14 00:25:18 - train: epoch 0052, iter [02500, 05004], lr: 0.010000, loss: 1.2418
2022-07-14 00:25:51 - train: epoch 0052, iter [02600, 05004], lr: 0.010000, loss: 1.1810
2022-07-14 00:26:23 - train: epoch 0052, iter [02700, 05004], lr: 0.010000, loss: 1.3121
2022-07-14 00:26:57 - train: epoch 0052, iter [02800, 05004], lr: 0.010000, loss: 1.4650
2022-07-14 00:27:31 - train: epoch 0052, iter [02900, 05004], lr: 0.010000, loss: 1.2830
2022-07-14 00:28:04 - train: epoch 0052, iter [03000, 05004], lr: 0.010000, loss: 1.4297
2022-07-14 00:28:37 - train: epoch 0052, iter [03100, 05004], lr: 0.010000, loss: 1.4841
2022-07-14 00:29:11 - train: epoch 0052, iter [03200, 05004], lr: 0.010000, loss: 1.5069
2022-07-14 00:29:44 - train: epoch 0052, iter [03300, 05004], lr: 0.010000, loss: 1.4410
2022-07-14 00:30:17 - train: epoch 0052, iter [03400, 05004], lr: 0.010000, loss: 1.5187
2022-07-14 00:30:51 - train: epoch 0052, iter [03500, 05004], lr: 0.010000, loss: 1.4495
2022-07-14 00:31:24 - train: epoch 0052, iter [03600, 05004], lr: 0.010000, loss: 1.5269
2022-07-14 00:31:58 - train: epoch 0052, iter [03700, 05004], lr: 0.010000, loss: 1.6516
2022-07-14 00:32:31 - train: epoch 0052, iter [03800, 05004], lr: 0.010000, loss: 1.3629
2022-07-14 00:33:05 - train: epoch 0052, iter [03900, 05004], lr: 0.010000, loss: 1.4075
2022-07-14 00:33:37 - train: epoch 0052, iter [04000, 05004], lr: 0.010000, loss: 1.5254
2022-07-14 00:34:11 - train: epoch 0052, iter [04100, 05004], lr: 0.010000, loss: 1.2244
2022-07-14 00:34:45 - train: epoch 0052, iter [04200, 05004], lr: 0.010000, loss: 1.2939
2022-07-14 00:35:18 - train: epoch 0052, iter [04300, 05004], lr: 0.010000, loss: 1.4337
2022-07-14 00:35:52 - train: epoch 0052, iter [04400, 05004], lr: 0.010000, loss: 1.5132
2022-07-14 00:36:25 - train: epoch 0052, iter [04500, 05004], lr: 0.010000, loss: 1.3074
2022-07-14 00:36:58 - train: epoch 0052, iter [04600, 05004], lr: 0.010000, loss: 1.4976
2022-07-14 00:37:31 - train: epoch 0052, iter [04700, 05004], lr: 0.010000, loss: 1.4616
2022-07-14 00:38:05 - train: epoch 0052, iter [04800, 05004], lr: 0.010000, loss: 1.1836
2022-07-14 00:38:39 - train: epoch 0052, iter [04900, 05004], lr: 0.010000, loss: 1.2554
2022-07-14 00:39:10 - train: epoch 0052, iter [05000, 05004], lr: 0.010000, loss: 1.4725
2022-07-14 00:39:11 - train: epoch 052, train_loss: 1.4156
2022-07-14 00:40:26 - eval: epoch: 052, acc1: 69.088%, acc5: 89.086%, test_loss: 1.2602, per_image_load_time: 1.508ms, per_image_inference_time: 0.320ms
2022-07-14 00:40:26 - until epoch: 052, best_acc1: 69.476%
2022-07-14 00:40:26 - epoch 053 lr: 0.010000
2022-07-14 00:41:04 - train: epoch 0053, iter [00100, 05004], lr: 0.010000, loss: 1.3378
2022-07-14 00:41:39 - train: epoch 0053, iter [00200, 05004], lr: 0.010000, loss: 1.6758
2022-07-14 00:42:11 - train: epoch 0053, iter [00300, 05004], lr: 0.010000, loss: 1.3998
2022-07-14 00:42:45 - train: epoch 0053, iter [00400, 05004], lr: 0.010000, loss: 1.3604
2022-07-14 00:43:18 - train: epoch 0053, iter [00500, 05004], lr: 0.010000, loss: 1.4545
2022-07-14 00:43:51 - train: epoch 0053, iter [00600, 05004], lr: 0.010000, loss: 1.3799
2022-07-14 00:44:24 - train: epoch 0053, iter [00700, 05004], lr: 0.010000, loss: 1.1650
2022-07-14 00:44:58 - train: epoch 0053, iter [00800, 05004], lr: 0.010000, loss: 1.5501
2022-07-14 00:45:30 - train: epoch 0053, iter [00900, 05004], lr: 0.010000, loss: 1.3054
2022-07-14 00:46:04 - train: epoch 0053, iter [01000, 05004], lr: 0.010000, loss: 1.3681
2022-07-14 00:46:37 - train: epoch 0053, iter [01100, 05004], lr: 0.010000, loss: 1.3868
2022-07-14 00:47:10 - train: epoch 0053, iter [01200, 05004], lr: 0.010000, loss: 1.3367
2022-07-14 00:47:42 - train: epoch 0053, iter [01300, 05004], lr: 0.010000, loss: 1.5260
2022-07-14 00:48:17 - train: epoch 0053, iter [01400, 05004], lr: 0.010000, loss: 1.7202
2022-07-14 00:48:50 - train: epoch 0053, iter [01500, 05004], lr: 0.010000, loss: 1.4323
2022-07-14 00:49:24 - train: epoch 0053, iter [01600, 05004], lr: 0.010000, loss: 1.6237
2022-07-14 00:49:56 - train: epoch 0053, iter [01700, 05004], lr: 0.010000, loss: 1.6371
2022-07-14 00:50:30 - train: epoch 0053, iter [01800, 05004], lr: 0.010000, loss: 1.6148
2022-07-14 00:51:04 - train: epoch 0053, iter [01900, 05004], lr: 0.010000, loss: 1.1845
2022-07-14 00:51:37 - train: epoch 0053, iter [02000, 05004], lr: 0.010000, loss: 1.4180
2022-07-14 00:52:10 - train: epoch 0053, iter [02100, 05004], lr: 0.010000, loss: 1.4376
2022-07-14 00:52:43 - train: epoch 0053, iter [02200, 05004], lr: 0.010000, loss: 1.2853
2022-07-14 00:53:16 - train: epoch 0053, iter [02300, 05004], lr: 0.010000, loss: 1.3511
2022-07-14 00:53:50 - train: epoch 0053, iter [02400, 05004], lr: 0.010000, loss: 1.4188
2022-07-14 00:54:23 - train: epoch 0053, iter [02500, 05004], lr: 0.010000, loss: 1.5766
2022-07-14 00:54:57 - train: epoch 0053, iter [02600, 05004], lr: 0.010000, loss: 1.4179
2022-07-14 00:55:30 - train: epoch 0053, iter [02700, 05004], lr: 0.010000, loss: 1.6755
2022-07-14 00:56:03 - train: epoch 0053, iter [02800, 05004], lr: 0.010000, loss: 1.5119
2022-07-14 00:56:37 - train: epoch 0053, iter [02900, 05004], lr: 0.010000, loss: 1.2838
2022-07-14 00:57:10 - train: epoch 0053, iter [03000, 05004], lr: 0.010000, loss: 1.2261
2022-07-14 00:57:43 - train: epoch 0053, iter [03100, 05004], lr: 0.010000, loss: 1.5355
2022-07-14 00:58:17 - train: epoch 0053, iter [03200, 05004], lr: 0.010000, loss: 1.6418
2022-07-14 00:58:51 - train: epoch 0053, iter [03300, 05004], lr: 0.010000, loss: 1.3980
2022-07-14 00:59:23 - train: epoch 0053, iter [03400, 05004], lr: 0.010000, loss: 1.5522
2022-07-14 00:59:57 - train: epoch 0053, iter [03500, 05004], lr: 0.010000, loss: 1.5262
2022-07-14 01:00:31 - train: epoch 0053, iter [03600, 05004], lr: 0.010000, loss: 1.4662
2022-07-14 01:01:03 - train: epoch 0053, iter [03700, 05004], lr: 0.010000, loss: 1.5623
2022-07-14 01:01:38 - train: epoch 0053, iter [03800, 05004], lr: 0.010000, loss: 1.3931
2022-07-14 01:02:11 - train: epoch 0053, iter [03900, 05004], lr: 0.010000, loss: 1.5674
2022-07-14 01:02:44 - train: epoch 0053, iter [04000, 05004], lr: 0.010000, loss: 1.4552
2022-07-14 01:03:17 - train: epoch 0053, iter [04100, 05004], lr: 0.010000, loss: 1.5956
2022-07-14 01:03:51 - train: epoch 0053, iter [04200, 05004], lr: 0.010000, loss: 1.5330
2022-07-14 01:04:24 - train: epoch 0053, iter [04300, 05004], lr: 0.010000, loss: 1.7419
2022-07-14 01:04:58 - train: epoch 0053, iter [04400, 05004], lr: 0.010000, loss: 1.3512
2022-07-14 01:05:31 - train: epoch 0053, iter [04500, 05004], lr: 0.010000, loss: 1.5180
2022-07-14 01:06:06 - train: epoch 0053, iter [04600, 05004], lr: 0.010000, loss: 1.3667
2022-07-14 01:06:38 - train: epoch 0053, iter [04700, 05004], lr: 0.010000, loss: 1.6541
2022-07-14 01:07:11 - train: epoch 0053, iter [04800, 05004], lr: 0.010000, loss: 1.5490
2022-07-14 01:07:44 - train: epoch 0053, iter [04900, 05004], lr: 0.010000, loss: 1.3164
2022-07-14 01:08:17 - train: epoch 0053, iter [05000, 05004], lr: 0.010000, loss: 1.3222
2022-07-14 01:08:18 - train: epoch 053, train_loss: 1.4133
2022-07-14 01:09:34 - eval: epoch: 053, acc1: 68.848%, acc5: 88.978%, test_loss: 1.2643, per_image_load_time: 2.610ms, per_image_inference_time: 0.290ms
2022-07-14 01:09:34 - until epoch: 053, best_acc1: 69.476%
2022-07-14 01:09:34 - epoch 054 lr: 0.010000
2022-07-14 01:10:13 - train: epoch 0054, iter [00100, 05004], lr: 0.010000, loss: 1.2474
2022-07-14 01:10:46 - train: epoch 0054, iter [00200, 05004], lr: 0.010000, loss: 1.7967
2022-07-14 01:11:20 - train: epoch 0054, iter [00300, 05004], lr: 0.010000, loss: 1.3703
2022-07-14 01:11:53 - train: epoch 0054, iter [00400, 05004], lr: 0.010000, loss: 1.3028
2022-07-14 01:12:27 - train: epoch 0054, iter [00500, 05004], lr: 0.010000, loss: 1.4493
2022-07-14 01:12:59 - train: epoch 0054, iter [00600, 05004], lr: 0.010000, loss: 1.3092
2022-07-14 01:13:32 - train: epoch 0054, iter [00700, 05004], lr: 0.010000, loss: 1.4519
2022-07-14 01:14:05 - train: epoch 0054, iter [00800, 05004], lr: 0.010000, loss: 1.5534
2022-07-14 01:14:39 - train: epoch 0054, iter [00900, 05004], lr: 0.010000, loss: 1.2327
2022-07-14 01:15:11 - train: epoch 0054, iter [01000, 05004], lr: 0.010000, loss: 1.2267
2022-07-14 01:15:44 - train: epoch 0054, iter [01100, 05004], lr: 0.010000, loss: 1.2404
2022-07-14 01:16:18 - train: epoch 0054, iter [01200, 05004], lr: 0.010000, loss: 1.5035
2022-07-14 01:16:51 - train: epoch 0054, iter [01300, 05004], lr: 0.010000, loss: 1.4074
2022-07-14 01:17:24 - train: epoch 0054, iter [01400, 05004], lr: 0.010000, loss: 1.4127
2022-07-14 01:17:57 - train: epoch 0054, iter [01500, 05004], lr: 0.010000, loss: 1.3864
2022-07-14 01:18:31 - train: epoch 0054, iter [01600, 05004], lr: 0.010000, loss: 1.0506
2022-07-14 01:19:04 - train: epoch 0054, iter [01700, 05004], lr: 0.010000, loss: 1.3665
2022-07-14 01:19:37 - train: epoch 0054, iter [01800, 05004], lr: 0.010000, loss: 1.4258
2022-07-14 01:20:11 - train: epoch 0054, iter [01900, 05004], lr: 0.010000, loss: 1.8270
2022-07-14 01:20:43 - train: epoch 0054, iter [02000, 05004], lr: 0.010000, loss: 1.4393
2022-07-14 01:21:17 - train: epoch 0054, iter [02100, 05004], lr: 0.010000, loss: 1.2185
2022-07-14 01:21:50 - train: epoch 0054, iter [02200, 05004], lr: 0.010000, loss: 1.4029
2022-07-14 01:22:23 - train: epoch 0054, iter [02300, 05004], lr: 0.010000, loss: 1.3774
2022-07-14 01:22:57 - train: epoch 0054, iter [02400, 05004], lr: 0.010000, loss: 1.2870
2022-07-14 01:23:31 - train: epoch 0054, iter [02500, 05004], lr: 0.010000, loss: 1.4694
2022-07-14 01:24:03 - train: epoch 0054, iter [02600, 05004], lr: 0.010000, loss: 1.3790
2022-07-14 01:24:38 - train: epoch 0054, iter [02700, 05004], lr: 0.010000, loss: 1.4915
2022-07-14 01:25:10 - train: epoch 0054, iter [02800, 05004], lr: 0.010000, loss: 1.7168
2022-07-14 01:25:44 - train: epoch 0054, iter [02900, 05004], lr: 0.010000, loss: 1.2897
2022-07-14 01:26:17 - train: epoch 0054, iter [03000, 05004], lr: 0.010000, loss: 1.5894
2022-07-14 01:26:50 - train: epoch 0054, iter [03100, 05004], lr: 0.010000, loss: 1.3818
2022-07-14 01:27:24 - train: epoch 0054, iter [03200, 05004], lr: 0.010000, loss: 1.6171
2022-07-14 01:27:57 - train: epoch 0054, iter [03300, 05004], lr: 0.010000, loss: 1.3745
2022-07-14 01:28:31 - train: epoch 0054, iter [03400, 05004], lr: 0.010000, loss: 1.4454
2022-07-14 01:29:04 - train: epoch 0054, iter [03500, 05004], lr: 0.010000, loss: 1.4824
2022-07-14 01:29:38 - train: epoch 0054, iter [03600, 05004], lr: 0.010000, loss: 1.3571
2022-07-14 01:30:12 - train: epoch 0054, iter [03700, 05004], lr: 0.010000, loss: 1.3080
2022-07-14 01:30:45 - train: epoch 0054, iter [03800, 05004], lr: 0.010000, loss: 1.4867
2022-07-14 01:31:18 - train: epoch 0054, iter [03900, 05004], lr: 0.010000, loss: 1.3848
2022-07-14 01:31:52 - train: epoch 0054, iter [04000, 05004], lr: 0.010000, loss: 1.2554
2022-07-14 01:32:26 - train: epoch 0054, iter [04100, 05004], lr: 0.010000, loss: 1.4447
2022-07-14 01:32:59 - train: epoch 0054, iter [04200, 05004], lr: 0.010000, loss: 1.4194
2022-07-14 01:33:33 - train: epoch 0054, iter [04300, 05004], lr: 0.010000, loss: 1.4363
2022-07-14 01:34:06 - train: epoch 0054, iter [04400, 05004], lr: 0.010000, loss: 1.3175
2022-07-14 01:34:39 - train: epoch 0054, iter [04500, 05004], lr: 0.010000, loss: 1.2770
2022-07-14 01:35:13 - train: epoch 0054, iter [04600, 05004], lr: 0.010000, loss: 1.4691
2022-07-14 01:35:46 - train: epoch 0054, iter [04700, 05004], lr: 0.010000, loss: 1.5190
2022-07-14 01:36:19 - train: epoch 0054, iter [04800, 05004], lr: 0.010000, loss: 1.5773
2022-07-14 01:36:54 - train: epoch 0054, iter [04900, 05004], lr: 0.010000, loss: 1.2294
2022-07-14 01:37:26 - train: epoch 0054, iter [05000, 05004], lr: 0.010000, loss: 1.4416
2022-07-14 01:37:27 - train: epoch 054, train_loss: 1.4129
2022-07-14 01:38:42 - eval: epoch: 054, acc1: 68.796%, acc5: 88.954%, test_loss: 1.2743, per_image_load_time: 1.937ms, per_image_inference_time: 0.320ms
2022-07-14 01:38:42 - until epoch: 054, best_acc1: 69.476%
2022-07-14 01:38:42 - epoch 055 lr: 0.010000
2022-07-14 01:39:21 - train: epoch 0055, iter [00100, 05004], lr: 0.010000, loss: 1.3357
2022-07-14 01:39:54 - train: epoch 0055, iter [00200, 05004], lr: 0.010000, loss: 1.2412
2022-07-14 01:40:27 - train: epoch 0055, iter [00300, 05004], lr: 0.010000, loss: 1.2373
2022-07-14 01:41:00 - train: epoch 0055, iter [00400, 05004], lr: 0.010000, loss: 1.4207
2022-07-14 01:41:34 - train: epoch 0055, iter [00500, 05004], lr: 0.010000, loss: 1.2489
2022-07-14 01:42:07 - train: epoch 0055, iter [00600, 05004], lr: 0.010000, loss: 1.2978
2022-07-14 01:42:41 - train: epoch 0055, iter [00700, 05004], lr: 0.010000, loss: 1.5458
2022-07-14 01:43:13 - train: epoch 0055, iter [00800, 05004], lr: 0.010000, loss: 1.2492
2022-07-14 01:43:48 - train: epoch 0055, iter [00900, 05004], lr: 0.010000, loss: 1.4505
2022-07-14 01:44:20 - train: epoch 0055, iter [01000, 05004], lr: 0.010000, loss: 1.3936
2022-07-14 01:44:54 - train: epoch 0055, iter [01100, 05004], lr: 0.010000, loss: 1.3373
2022-07-14 01:45:27 - train: epoch 0055, iter [01200, 05004], lr: 0.010000, loss: 1.3864
2022-07-14 01:46:00 - train: epoch 0055, iter [01300, 05004], lr: 0.010000, loss: 1.5385
2022-07-14 01:46:33 - train: epoch 0055, iter [01400, 05004], lr: 0.010000, loss: 1.3040
2022-07-14 01:47:06 - train: epoch 0055, iter [01500, 05004], lr: 0.010000, loss: 1.4335
2022-07-14 01:47:40 - train: epoch 0055, iter [01600, 05004], lr: 0.010000, loss: 1.4513
2022-07-14 01:48:13 - train: epoch 0055, iter [01700, 05004], lr: 0.010000, loss: 1.4642
2022-07-14 01:48:47 - train: epoch 0055, iter [01800, 05004], lr: 0.010000, loss: 1.4845
2022-07-14 01:49:20 - train: epoch 0055, iter [01900, 05004], lr: 0.010000, loss: 1.5320
2022-07-14 01:49:54 - train: epoch 0055, iter [02000, 05004], lr: 0.010000, loss: 1.4156
2022-07-14 01:50:27 - train: epoch 0055, iter [02100, 05004], lr: 0.010000, loss: 1.1482
2022-07-14 01:51:00 - train: epoch 0055, iter [02200, 05004], lr: 0.010000, loss: 1.5624
2022-07-14 01:51:33 - train: epoch 0055, iter [02300, 05004], lr: 0.010000, loss: 1.3912
2022-07-14 01:52:06 - train: epoch 0055, iter [02400, 05004], lr: 0.010000, loss: 1.2887
2022-07-14 01:52:39 - train: epoch 0055, iter [02500, 05004], lr: 0.010000, loss: 1.3671
2022-07-14 01:53:14 - train: epoch 0055, iter [02600, 05004], lr: 0.010000, loss: 1.3059
2022-07-14 01:53:47 - train: epoch 0055, iter [02700, 05004], lr: 0.010000, loss: 1.1975
2022-07-14 01:54:21 - train: epoch 0055, iter [02800, 05004], lr: 0.010000, loss: 1.3846
2022-07-14 01:54:54 - train: epoch 0055, iter [02900, 05004], lr: 0.010000, loss: 1.5195
2022-07-14 01:55:28 - train: epoch 0055, iter [03000, 05004], lr: 0.010000, loss: 1.2788
2022-07-14 01:56:01 - train: epoch 0055, iter [03100, 05004], lr: 0.010000, loss: 1.4358
2022-07-14 01:56:34 - train: epoch 0055, iter [03200, 05004], lr: 0.010000, loss: 1.3180
2022-07-14 01:57:08 - train: epoch 0055, iter [03300, 05004], lr: 0.010000, loss: 1.2324
2022-07-14 01:57:41 - train: epoch 0055, iter [03400, 05004], lr: 0.010000, loss: 1.3233
2022-07-14 01:58:14 - train: epoch 0055, iter [03500, 05004], lr: 0.010000, loss: 1.2152
2022-07-14 01:58:49 - train: epoch 0055, iter [03600, 05004], lr: 0.010000, loss: 1.4253
2022-07-14 01:59:21 - train: epoch 0055, iter [03700, 05004], lr: 0.010000, loss: 1.3967
2022-07-14 01:59:55 - train: epoch 0055, iter [03800, 05004], lr: 0.010000, loss: 1.4523
2022-07-14 02:00:28 - train: epoch 0055, iter [03900, 05004], lr: 0.010000, loss: 1.7311
2022-07-14 02:01:02 - train: epoch 0055, iter [04000, 05004], lr: 0.010000, loss: 1.5282
2022-07-14 02:01:35 - train: epoch 0055, iter [04100, 05004], lr: 0.010000, loss: 1.4149
2022-07-14 02:02:09 - train: epoch 0055, iter [04200, 05004], lr: 0.010000, loss: 1.3496
2022-07-14 02:02:42 - train: epoch 0055, iter [04300, 05004], lr: 0.010000, loss: 1.5086
2022-07-14 02:03:16 - train: epoch 0055, iter [04400, 05004], lr: 0.010000, loss: 1.6543
2022-07-14 02:03:49 - train: epoch 0055, iter [04500, 05004], lr: 0.010000, loss: 1.4063
2022-07-14 02:04:24 - train: epoch 0055, iter [04600, 05004], lr: 0.010000, loss: 1.5776
2022-07-14 02:04:57 - train: epoch 0055, iter [04700, 05004], lr: 0.010000, loss: 1.2949
2022-07-14 02:05:30 - train: epoch 0055, iter [04800, 05004], lr: 0.010000, loss: 1.5069
2022-07-14 02:06:04 - train: epoch 0055, iter [04900, 05004], lr: 0.010000, loss: 1.3782
2022-07-14 02:06:36 - train: epoch 0055, iter [05000, 05004], lr: 0.010000, loss: 1.5533
2022-07-14 02:06:37 - train: epoch 055, train_loss: 1.4085
2022-07-14 02:07:52 - eval: epoch: 055, acc1: 69.224%, acc5: 89.038%, test_loss: 1.2512, per_image_load_time: 2.130ms, per_image_inference_time: 0.306ms
2022-07-14 02:07:52 - until epoch: 055, best_acc1: 69.476%
2022-07-14 02:07:52 - epoch 056 lr: 0.010000
2022-07-14 02:08:30 - train: epoch 0056, iter [00100, 05004], lr: 0.010000, loss: 1.6162
2022-07-14 02:09:03 - train: epoch 0056, iter [00200, 05004], lr: 0.010000, loss: 1.4766
2022-07-14 02:09:37 - train: epoch 0056, iter [00300, 05004], lr: 0.010000, loss: 1.3504
2022-07-14 02:10:10 - train: epoch 0056, iter [00400, 05004], lr: 0.010000, loss: 1.3315
2022-07-14 02:10:44 - train: epoch 0056, iter [00500, 05004], lr: 0.010000, loss: 1.2658
2022-07-14 02:11:17 - train: epoch 0056, iter [00600, 05004], lr: 0.010000, loss: 1.3470
2022-07-14 02:11:50 - train: epoch 0056, iter [00700, 05004], lr: 0.010000, loss: 1.4284
2022-07-14 02:12:23 - train: epoch 0056, iter [00800, 05004], lr: 0.010000, loss: 1.5670
2022-07-14 02:12:57 - train: epoch 0056, iter [00900, 05004], lr: 0.010000, loss: 1.4357
2022-07-14 02:13:30 - train: epoch 0056, iter [01000, 05004], lr: 0.010000, loss: 1.3224
2022-07-14 02:14:03 - train: epoch 0056, iter [01100, 05004], lr: 0.010000, loss: 1.3014
2022-07-14 02:14:37 - train: epoch 0056, iter [01200, 05004], lr: 0.010000, loss: 1.3223
2022-07-14 02:15:10 - train: epoch 0056, iter [01300, 05004], lr: 0.010000, loss: 1.5208
2022-07-14 02:15:43 - train: epoch 0056, iter [01400, 05004], lr: 0.010000, loss: 1.2722
2022-07-14 02:16:16 - train: epoch 0056, iter [01500, 05004], lr: 0.010000, loss: 1.6159
2022-07-14 02:16:49 - train: epoch 0056, iter [01600, 05004], lr: 0.010000, loss: 1.2931
2022-07-14 02:17:22 - train: epoch 0056, iter [01700, 05004], lr: 0.010000, loss: 1.4586
2022-07-14 02:17:56 - train: epoch 0056, iter [01800, 05004], lr: 0.010000, loss: 1.5963
2022-07-14 02:18:29 - train: epoch 0056, iter [01900, 05004], lr: 0.010000, loss: 1.3649
2022-07-14 02:19:03 - train: epoch 0056, iter [02000, 05004], lr: 0.010000, loss: 1.4673
2022-07-14 02:19:36 - train: epoch 0056, iter [02100, 05004], lr: 0.010000, loss: 1.3476
2022-07-14 02:20:10 - train: epoch 0056, iter [02200, 05004], lr: 0.010000, loss: 1.5513
2022-07-14 02:20:43 - train: epoch 0056, iter [02300, 05004], lr: 0.010000, loss: 1.4786
2022-07-14 02:21:15 - train: epoch 0056, iter [02400, 05004], lr: 0.010000, loss: 1.3402
2022-07-14 02:21:49 - train: epoch 0056, iter [02500, 05004], lr: 0.010000, loss: 1.5622
2022-07-14 02:22:22 - train: epoch 0056, iter [02600, 05004], lr: 0.010000, loss: 1.3452
2022-07-14 02:22:56 - train: epoch 0056, iter [02700, 05004], lr: 0.010000, loss: 1.4463
2022-07-14 02:23:29 - train: epoch 0056, iter [02800, 05004], lr: 0.010000, loss: 1.4183
2022-07-14 02:24:02 - train: epoch 0056, iter [02900, 05004], lr: 0.010000, loss: 1.5782
2022-07-14 02:24:36 - train: epoch 0056, iter [03000, 05004], lr: 0.010000, loss: 1.5399
2022-07-14 02:25:10 - train: epoch 0056, iter [03100, 05004], lr: 0.010000, loss: 1.2524
2022-07-14 02:25:43 - train: epoch 0056, iter [03200, 05004], lr: 0.010000, loss: 1.2036
2022-07-14 02:26:16 - train: epoch 0056, iter [03300, 05004], lr: 0.010000, loss: 1.6591
2022-07-14 02:26:50 - train: epoch 0056, iter [03400, 05004], lr: 0.010000, loss: 1.3931
2022-07-14 02:27:23 - train: epoch 0056, iter [03500, 05004], lr: 0.010000, loss: 1.3251
2022-07-14 02:27:57 - train: epoch 0056, iter [03600, 05004], lr: 0.010000, loss: 1.1910
2022-07-14 02:28:31 - train: epoch 0056, iter [03700, 05004], lr: 0.010000, loss: 1.2770
2022-07-14 02:29:04 - train: epoch 0056, iter [03800, 05004], lr: 0.010000, loss: 1.2576
2022-07-14 02:29:37 - train: epoch 0056, iter [03900, 05004], lr: 0.010000, loss: 1.5859
2022-07-14 02:30:11 - train: epoch 0056, iter [04000, 05004], lr: 0.010000, loss: 1.4038
2022-07-14 02:30:44 - train: epoch 0056, iter [04100, 05004], lr: 0.010000, loss: 1.5918
2022-07-14 02:31:18 - train: epoch 0056, iter [04200, 05004], lr: 0.010000, loss: 1.4195
2022-07-14 02:31:52 - train: epoch 0056, iter [04300, 05004], lr: 0.010000, loss: 1.3737
2022-07-14 02:32:25 - train: epoch 0056, iter [04400, 05004], lr: 0.010000, loss: 1.5403
2022-07-14 02:32:58 - train: epoch 0056, iter [04500, 05004], lr: 0.010000, loss: 1.4252
2022-07-14 02:33:31 - train: epoch 0056, iter [04600, 05004], lr: 0.010000, loss: 1.5431
2022-07-14 02:34:05 - train: epoch 0056, iter [04700, 05004], lr: 0.010000, loss: 1.5182
2022-07-14 02:34:38 - train: epoch 0056, iter [04800, 05004], lr: 0.010000, loss: 1.5856
2022-07-14 02:35:12 - train: epoch 0056, iter [04900, 05004], lr: 0.010000, loss: 1.3816
2022-07-14 02:35:43 - train: epoch 0056, iter [05000, 05004], lr: 0.010000, loss: 1.6160
2022-07-14 02:35:44 - train: epoch 056, train_loss: 1.4042
2022-07-14 02:36:59 - eval: epoch: 056, acc1: 69.220%, acc5: 89.154%, test_loss: 1.2552, per_image_load_time: 2.585ms, per_image_inference_time: 0.295ms
2022-07-14 02:37:00 - until epoch: 056, best_acc1: 69.476%
2022-07-14 02:37:00 - epoch 057 lr: 0.010000
2022-07-14 02:37:39 - train: epoch 0057, iter [00100, 05004], lr: 0.010000, loss: 1.5025
2022-07-14 02:38:12 - train: epoch 0057, iter [00200, 05004], lr: 0.010000, loss: 1.3266
2022-07-14 02:38:45 - train: epoch 0057, iter [00300, 05004], lr: 0.010000, loss: 1.2266
2022-07-14 02:39:19 - train: epoch 0057, iter [00400, 05004], lr: 0.010000, loss: 1.3866
2022-07-14 02:39:52 - train: epoch 0057, iter [00500, 05004], lr: 0.010000, loss: 1.1330
2022-07-14 02:40:25 - train: epoch 0057, iter [00600, 05004], lr: 0.010000, loss: 1.5900
2022-07-14 02:40:58 - train: epoch 0057, iter [00700, 05004], lr: 0.010000, loss: 1.1997
2022-07-14 02:41:31 - train: epoch 0057, iter [00800, 05004], lr: 0.010000, loss: 1.4376
2022-07-14 02:42:04 - train: epoch 0057, iter [00900, 05004], lr: 0.010000, loss: 1.4629
2022-07-14 02:42:37 - train: epoch 0057, iter [01000, 05004], lr: 0.010000, loss: 1.2594
2022-07-14 02:43:10 - train: epoch 0057, iter [01100, 05004], lr: 0.010000, loss: 1.3194
2022-07-14 02:43:43 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 1.3212
2022-07-14 02:44:16 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 1.3849
2022-07-14 02:44:49 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 1.4654
2022-07-14 02:45:21 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 1.5351
2022-07-14 02:45:55 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 1.5719
2022-07-14 02:46:28 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 1.5878
2022-07-14 02:47:02 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 1.4687
2022-07-14 02:47:35 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 1.2596
2022-07-14 02:48:08 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 1.3985
2022-07-14 02:48:42 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 1.3855
2022-07-14 02:49:15 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 1.3831
2022-07-14 02:49:49 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 1.3733
2022-07-14 02:50:22 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 1.3032
2022-07-14 02:50:55 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 1.4318
2022-07-14 02:51:28 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 1.2738
2022-07-14 02:52:02 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 1.1583
2022-07-14 02:52:35 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 1.1196
2022-07-14 02:53:08 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 1.4208
2022-07-14 02:53:42 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 1.4578
2022-07-14 02:54:15 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 1.6120
2022-07-14 02:54:49 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 1.4700
2022-07-14 02:55:22 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 1.3760
2022-07-14 02:55:55 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 1.3668
2022-07-14 02:56:29 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 1.4846
2022-07-14 02:57:02 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 1.3497
2022-07-14 02:57:36 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 1.3592
2022-07-14 02:58:09 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 1.3149
2022-07-14 02:58:43 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 1.5218
2022-07-14 02:59:16 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 1.3112
2022-07-14 02:59:50 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 1.4674
2022-07-14 03:00:23 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 1.4572
2022-07-14 03:00:56 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 1.3464
2022-07-14 03:01:30 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 1.4129
2022-07-14 03:02:03 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 1.5105
2022-07-14 03:02:37 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 1.4056
2022-07-14 03:03:10 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 1.3409
2022-07-14 03:03:45 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 1.6517
2022-07-14 03:04:17 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 1.5928
2022-07-14 03:04:49 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 1.5472
2022-07-14 03:04:50 - train: epoch 057, train_loss: 1.4018
2022-07-14 03:06:05 - eval: epoch: 057, acc1: 69.214%, acc5: 89.160%, test_loss: 1.2598, per_image_load_time: 2.439ms, per_image_inference_time: 0.303ms
2022-07-14 03:06:05 - until epoch: 057, best_acc1: 69.476%
2022-07-14 03:06:05 - epoch 058 lr: 0.010000
2022-07-14 03:06:43 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 1.3696
2022-07-14 03:07:18 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 1.1395
2022-07-14 03:07:51 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 1.4976
2022-07-14 03:08:24 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 1.4108
2022-07-14 03:08:57 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 1.2465
2022-07-14 03:09:31 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 1.5221
2022-07-14 03:10:04 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 1.3989
2022-07-14 03:10:38 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 1.2829
2022-07-14 03:11:10 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 1.2984
2022-07-14 03:11:44 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 1.4887
2022-07-14 03:12:17 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 1.2526
2022-07-14 03:12:51 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 1.3308
2022-07-14 03:13:23 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 1.3834
2022-07-14 03:13:57 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 1.4065
2022-07-14 03:14:30 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 1.3736
2022-07-14 03:15:04 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 1.3908
2022-07-14 03:15:36 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 1.6185
2022-07-14 03:16:10 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 1.3928
2022-07-14 03:16:43 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 1.4995
2022-07-14 03:17:17 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 1.5243
2022-07-14 03:17:50 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 1.2413
2022-07-14 03:18:24 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 1.1745
2022-07-14 03:18:57 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 1.3659
2022-07-14 03:19:31 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 1.3705
2022-07-14 03:20:04 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 1.5676
2022-07-14 03:20:38 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 1.3207
2022-07-14 03:21:11 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 1.5978
2022-07-14 03:21:45 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 1.1143
2022-07-14 03:22:18 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 1.2976
2022-07-14 03:22:52 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 1.4995
2022-07-14 03:23:24 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 1.2703
2022-07-14 03:23:58 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 1.2453
2022-07-14 03:24:31 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 1.3840
2022-07-14 03:25:05 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 1.3959
2022-07-14 03:25:38 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 1.2751
2022-07-14 03:26:12 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 1.3055
2022-07-14 03:26:44 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 1.4090
2022-07-14 03:27:18 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 1.4966
2022-07-14 03:27:52 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 1.4131
2022-07-14 03:28:25 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 1.5677
2022-07-14 03:28:59 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 1.5827
2022-07-14 03:29:32 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 1.2156
2022-07-14 03:30:06 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 1.6524
2022-07-14 03:30:39 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 1.1774
2022-07-14 03:31:12 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 1.4788
2022-07-14 03:31:46 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 1.2780
2022-07-14 03:32:20 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 1.4819
2022-07-14 03:32:53 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 1.4930
2022-07-14 03:33:27 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 1.3059
2022-07-14 03:33:59 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 1.3512
2022-07-14 03:34:00 - train: epoch 058, train_loss: 1.3978
2022-07-14 03:35:14 - eval: epoch: 058, acc1: 69.264%, acc5: 89.254%, test_loss: 1.2552, per_image_load_time: 2.552ms, per_image_inference_time: 0.293ms
2022-07-14 03:35:15 - until epoch: 058, best_acc1: 69.476%
2022-07-14 03:35:15 - epoch 059 lr: 0.010000
2022-07-14 03:35:53 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 1.6158
2022-07-14 03:36:27 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 1.3486
2022-07-14 03:37:00 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 1.4235
2022-07-14 03:37:33 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 1.3885
2022-07-14 03:38:07 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 1.5726
2022-07-14 03:38:40 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 1.2914
2022-07-14 03:39:14 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 1.3284
2022-07-14 03:39:47 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 1.3926
2022-07-14 03:40:20 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 1.3354
2022-07-14 03:40:53 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 1.3219
2022-07-14 03:41:26 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 1.5966
2022-07-14 03:41:59 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 1.1994
2022-07-14 03:42:32 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 1.5122
2022-07-14 03:43:05 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 1.5898
2022-07-14 03:43:40 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 1.4807
2022-07-14 03:44:12 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 1.3272
2022-07-14 03:44:47 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 1.5078
2022-07-14 03:45:19 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 1.4604
2022-07-14 03:45:53 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 1.4927
2022-07-14 03:46:26 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 1.3136
2022-07-14 03:47:00 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 1.5649
2022-07-14 03:47:33 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 1.4805
2022-07-14 03:48:06 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 1.3486
2022-07-14 03:48:40 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 1.5141
2022-07-14 03:49:13 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 1.4675
2022-07-14 03:49:47 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 1.4115
2022-07-14 03:50:20 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 1.3784
2022-07-14 03:50:54 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 1.6116
2022-07-14 03:51:27 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 1.3458
2022-07-14 03:52:00 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 1.7615
2022-07-14 03:52:33 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 1.3649
2022-07-14 03:53:08 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 1.4170
2022-07-14 03:53:41 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 1.4583
2022-07-14 03:54:14 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 1.7915
2022-07-14 03:54:49 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 1.2676
2022-07-14 03:55:21 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 1.3801
2022-07-14 03:55:55 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 1.4066
2022-07-14 03:56:28 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 1.4059
2022-07-14 03:57:02 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 1.3556
2022-07-14 03:57:35 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 1.7548
2022-07-14 03:58:08 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 1.4171
2022-07-14 03:58:41 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 1.5129
2022-07-14 03:59:16 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 1.6327
2022-07-14 03:59:49 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 1.6055
2022-07-14 04:00:23 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 1.4856
2022-07-14 04:00:56 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 1.3497
2022-07-14 04:01:29 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 1.4000
2022-07-14 04:02:02 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 1.2488
2022-07-14 04:02:37 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 1.5527
2022-07-14 04:03:08 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 1.5704
2022-07-14 04:03:09 - train: epoch 059, train_loss: 1.3965
2022-07-14 04:04:24 - eval: epoch: 059, acc1: 68.734%, acc5: 88.788%, test_loss: 1.2733, per_image_load_time: 1.376ms, per_image_inference_time: 0.309ms
2022-07-14 04:04:24 - until epoch: 059, best_acc1: 69.476%
2022-07-14 04:04:24 - epoch 060 lr: 0.010000
2022-07-14 04:05:02 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 1.2236
2022-07-14 04:05:36 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 1.4848
2022-07-14 04:06:09 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 1.4311
2022-07-14 04:06:42 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 1.4314
2022-07-14 04:07:16 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 1.5155
2022-07-14 04:07:49 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 1.5139
2022-07-14 04:08:22 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 1.4380
2022-07-14 04:08:56 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 1.5723
2022-07-14 04:09:29 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 1.1706
2022-07-14 04:10:03 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 1.1049
2022-07-14 04:10:35 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 1.1731
2022-07-14 04:11:09 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 1.2847
2022-07-14 04:11:43 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 1.2883
2022-07-14 04:12:15 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 1.4231
2022-07-14 04:12:49 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 1.3466
2022-07-14 04:13:22 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 1.3667
2022-07-14 04:13:55 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 1.2600
2022-07-14 04:14:29 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 1.4369
2022-07-14 04:15:02 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 1.5938
2022-07-14 04:15:36 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 1.3297
2022-07-14 04:16:09 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 1.4001
2022-07-14 04:16:42 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 1.4337
2022-07-14 04:17:16 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 1.2267
2022-07-14 04:17:50 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 1.3361
2022-07-14 04:18:23 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 1.4523
2022-07-14 04:18:57 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 1.4834
2022-07-14 04:19:29 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 1.4289
2022-07-14 04:20:03 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 1.3295
2022-07-14 04:20:37 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 1.5372
2022-07-14 04:21:11 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 1.6120
2022-07-14 04:21:43 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 1.3721
2022-07-14 04:22:18 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 1.3774
2022-07-14 04:22:51 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 1.2039
2022-07-14 04:23:25 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 1.3905
2022-07-14 04:23:58 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 1.3851
2022-07-14 04:24:31 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 1.3642
2022-07-14 04:25:04 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 1.4442
2022-07-14 04:25:37 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 1.3846
2022-07-14 04:26:11 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 1.8413
2022-07-14 04:26:45 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 1.3229
2022-07-14 04:27:18 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 1.5400
2022-07-14 04:27:53 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 1.5062
2022-07-14 04:28:25 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 1.3855
2022-07-14 04:28:59 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 1.6113
2022-07-14 04:29:32 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 1.3725
2022-07-14 04:30:06 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 1.3537
2022-07-14 04:30:40 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 1.4467
2022-07-14 04:31:13 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 1.1960
2022-07-14 04:31:46 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 1.4068
2022-07-14 04:32:18 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 1.3823
2022-07-14 04:32:19 - train: epoch 060, train_loss: 1.3935
2022-07-14 04:33:34 - eval: epoch: 060, acc1: 69.100%, acc5: 89.102%, test_loss: 1.2588, per_image_load_time: 2.283ms, per_image_inference_time: 0.313ms
2022-07-14 04:33:34 - until epoch: 060, best_acc1: 69.476%
2022-07-14 04:33:34 - epoch 061 lr: 0.001000
2022-07-14 04:34:12 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 1.2542
2022-07-14 04:34:47 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 1.3347
2022-07-14 04:35:19 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 1.0950
2022-07-14 04:35:53 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 1.5190
2022-07-14 04:36:26 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 1.2933
2022-07-14 04:36:59 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 1.2467
2022-07-14 04:37:33 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 1.0572
2022-07-14 04:38:06 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 1.2783
2022-07-14 04:38:39 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 1.0607
2022-07-14 04:39:13 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 1.0646
2022-07-14 04:39:47 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 1.0957
2022-07-14 04:40:20 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 1.2491
2022-07-14 04:40:53 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 1.2376
2022-07-14 04:41:27 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 1.1710
2022-07-14 04:42:00 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 1.3026
2022-07-14 04:42:33 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 1.0931
2022-07-14 04:43:06 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 1.2401
2022-07-14 04:43:40 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 1.2260
2022-07-14 04:44:13 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 1.3582
2022-07-14 04:44:47 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 1.1254
2022-07-14 04:45:20 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 1.5620
2022-07-14 04:45:53 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 1.0698
2022-07-14 04:46:26 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 1.2019
2022-07-14 04:46:59 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 0.9332
2022-07-14 04:47:33 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 1.0990
2022-07-14 04:48:07 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 1.3542
2022-07-14 04:48:40 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 1.3402
2022-07-14 04:49:13 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 1.1641
2022-07-14 04:49:47 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 1.2991
2022-07-14 04:50:21 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 1.0916
2022-07-14 04:50:54 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 1.3628
2022-07-14 04:51:28 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 1.2065
2022-07-14 04:52:00 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 1.1563
2022-07-14 04:52:34 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 0.9966
2022-07-14 04:53:07 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 1.2268
2022-07-14 04:53:41 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 1.1556
2022-07-14 04:54:14 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 1.3139
2022-07-14 04:54:48 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 1.2160
2022-07-14 04:55:22 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 1.2034
2022-07-14 04:55:55 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 1.2223
2022-07-14 04:56:28 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 1.3880
2022-07-14 04:57:01 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 1.0592
2022-07-14 04:57:35 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 1.2703
2022-07-14 04:58:08 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 1.1893
2022-07-14 04:58:42 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 1.0944
2022-07-14 04:59:15 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 1.3387
2022-07-14 04:59:48 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 1.1903
2022-07-14 05:00:22 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 1.1476
2022-07-14 05:00:55 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 1.3264
2022-07-14 05:01:26 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 1.2237
2022-07-14 05:01:27 - train: epoch 061, train_loss: 1.2008
2022-07-14 05:02:42 - eval: epoch: 061, acc1: 72.622%, acc5: 90.928%, test_loss: 1.1055, per_image_load_time: 2.551ms, per_image_inference_time: 0.299ms
2022-07-14 05:02:42 - until epoch: 061, best_acc1: 72.622%
2022-07-14 05:02:42 - epoch 062 lr: 0.001000
2022-07-14 05:03:21 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 1.2245
2022-07-14 05:03:54 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 1.1934
2022-07-14 05:04:28 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 1.1189
2022-07-14 05:05:01 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 0.9805
2022-07-14 05:05:34 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 0.9968
2022-07-14 05:06:07 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 1.0737
2022-07-14 05:06:40 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 1.3648
2022-07-14 05:07:13 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 1.1541
2022-07-14 05:07:46 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 1.1265
2022-07-14 05:08:20 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 1.2435
2022-07-14 05:08:53 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 1.0478
2022-07-14 05:09:27 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 1.3352
2022-07-14 05:10:00 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 1.1946
2022-07-14 05:10:33 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 1.1433
2022-07-14 05:11:07 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 1.1857
2022-07-14 05:11:40 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 1.2795
2022-07-14 05:12:13 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 1.2287
2022-07-14 05:12:47 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 1.1003
2022-07-14 05:13:20 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 1.1534
2022-07-14 05:13:54 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 1.0255
2022-07-14 05:14:27 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 1.2949
2022-07-14 05:15:01 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 1.0197
2022-07-14 05:15:34 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 1.1328
2022-07-14 05:16:08 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 1.0472
2022-07-14 05:16:41 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 1.2102
2022-07-14 05:17:14 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 1.0463
2022-07-14 05:17:48 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 1.2037
2022-07-14 05:18:21 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 1.1899
2022-07-14 05:18:54 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 1.2126
2022-07-14 05:19:28 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 1.2138
2022-07-14 05:20:01 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 1.2177
2022-07-14 05:20:35 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 0.9982
2022-07-14 05:21:07 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 1.3529
2022-07-14 05:21:41 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 1.1551
2022-07-14 05:22:14 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 1.1589
2022-07-14 05:22:48 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 1.2137
2022-07-14 05:23:21 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 1.1103
2022-07-14 05:23:55 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 1.1279
2022-07-14 05:24:28 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 1.1000
2022-07-14 05:25:02 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 0.9849
2022-07-14 05:25:35 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 1.1648
2022-07-14 05:26:08 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 0.9540
2022-07-14 05:26:41 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 1.1143
2022-07-14 05:27:15 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 1.1183
2022-07-14 05:27:48 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 1.0530
2022-07-14 05:28:22 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 0.9484
2022-07-14 05:28:57 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 1.1142
2022-07-14 05:29:30 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 1.1268
2022-07-14 05:30:03 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 1.0631
2022-07-14 05:30:35 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 1.2039
2022-07-14 05:30:36 - train: epoch 062, train_loss: 1.1483
2022-07-14 05:31:51 - eval: epoch: 062, acc1: 72.912%, acc5: 91.220%, test_loss: 1.0883, per_image_load_time: 2.110ms, per_image_inference_time: 0.299ms
2022-07-14 05:31:51 - until epoch: 062, best_acc1: 72.912%
2022-07-14 05:31:51 - epoch 063 lr: 0.001000
2022-07-14 05:32:30 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 1.0906
2022-07-14 05:33:03 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 1.0358
2022-07-14 05:33:36 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 1.3638
2022-07-14 05:34:09 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 1.1684
2022-07-14 05:34:43 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 1.0544
2022-07-14 05:35:16 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 1.1996
2022-07-14 05:35:49 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 1.0469
2022-07-14 05:36:22 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 1.1173
2022-07-14 05:36:55 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 1.1549
2022-07-14 05:37:28 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 1.1878
2022-07-14 05:38:01 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 1.0280
2022-07-14 05:38:34 - train: epoch 0063, iter [01200, 05004], lr: 0.001000, loss: 1.0189
2022-07-14 05:39:07 - train: epoch 0063, iter [01300, 05004], lr: 0.001000, loss: 1.1627
2022-07-14 05:39:41 - train: epoch 0063, iter [01400, 05004], lr: 0.001000, loss: 1.3816
2022-07-14 05:40:14 - train: epoch 0063, iter [01500, 05004], lr: 0.001000, loss: 1.1911
2022-07-14 05:40:47 - train: epoch 0063, iter [01600, 05004], lr: 0.001000, loss: 1.0920
2022-07-14 05:41:20 - train: epoch 0063, iter [01700, 05004], lr: 0.001000, loss: 0.9913
2022-07-14 05:41:52 - train: epoch 0063, iter [01800, 05004], lr: 0.001000, loss: 1.2458
2022-07-14 05:42:26 - train: epoch 0063, iter [01900, 05004], lr: 0.001000, loss: 1.1854
2022-07-14 05:42:59 - train: epoch 0063, iter [02000, 05004], lr: 0.001000, loss: 1.0212
2022-07-14 05:43:32 - train: epoch 0063, iter [02100, 05004], lr: 0.001000, loss: 0.9822
2022-07-14 05:44:05 - train: epoch 0063, iter [02200, 05004], lr: 0.001000, loss: 1.4313
2022-07-14 05:44:39 - train: epoch 0063, iter [02300, 05004], lr: 0.001000, loss: 1.1710
2022-07-14 05:45:12 - train: epoch 0063, iter [02400, 05004], lr: 0.001000, loss: 1.2571
2022-07-14 05:45:46 - train: epoch 0063, iter [02500, 05004], lr: 0.001000, loss: 1.1853
2022-07-14 05:46:19 - train: epoch 0063, iter [02600, 05004], lr: 0.001000, loss: 1.0740
2022-07-14 05:46:52 - train: epoch 0063, iter [02700, 05004], lr: 0.001000, loss: 1.3989
2022-07-14 05:47:25 - train: epoch 0063, iter [02800, 05004], lr: 0.001000, loss: 1.1446
2022-07-14 05:47:59 - train: epoch 0063, iter [02900, 05004], lr: 0.001000, loss: 1.0844
2022-07-14 05:48:31 - train: epoch 0063, iter [03000, 05004], lr: 0.001000, loss: 1.2073
2022-07-14 05:49:06 - train: epoch 0063, iter [03100, 05004], lr: 0.001000, loss: 1.4538
2022-07-14 05:49:38 - train: epoch 0063, iter [03200, 05004], lr: 0.001000, loss: 1.1679
2022-07-14 05:50:12 - train: epoch 0063, iter [03300, 05004], lr: 0.001000, loss: 1.1456
2022-07-14 05:50:45 - train: epoch 0063, iter [03400, 05004], lr: 0.001000, loss: 0.8576
2022-07-14 05:51:19 - train: epoch 0063, iter [03500, 05004], lr: 0.001000, loss: 1.2085
2022-07-14 05:51:51 - train: epoch 0063, iter [03600, 05004], lr: 0.001000, loss: 0.9991
2022-07-14 05:52:25 - train: epoch 0063, iter [03700, 05004], lr: 0.001000, loss: 1.2512
2022-07-14 05:52:59 - train: epoch 0063, iter [03800, 05004], lr: 0.001000, loss: 1.3594
2022-07-14 05:53:32 - train: epoch 0063, iter [03900, 05004], lr: 0.001000, loss: 0.8515
2022-07-14 05:54:05 - train: epoch 0063, iter [04000, 05004], lr: 0.001000, loss: 0.9686
2022-07-14 05:54:39 - train: epoch 0063, iter [04100, 05004], lr: 0.001000, loss: 1.2055
2022-07-14 05:55:12 - train: epoch 0063, iter [04200, 05004], lr: 0.001000, loss: 1.0746
2022-07-14 05:55:45 - train: epoch 0063, iter [04300, 05004], lr: 0.001000, loss: 1.3060
2022-07-14 05:56:19 - train: epoch 0063, iter [04400, 05004], lr: 0.001000, loss: 1.1155
2022-07-14 05:56:52 - train: epoch 0063, iter [04500, 05004], lr: 0.001000, loss: 1.0538
2022-07-14 05:57:25 - train: epoch 0063, iter [04600, 05004], lr: 0.001000, loss: 1.0611
2022-07-14 05:57:59 - train: epoch 0063, iter [04700, 05004], lr: 0.001000, loss: 0.9443
2022-07-14 05:58:32 - train: epoch 0063, iter [04800, 05004], lr: 0.001000, loss: 1.0682
2022-07-14 05:59:06 - train: epoch 0063, iter [04900, 05004], lr: 0.001000, loss: 1.1306
2022-07-14 05:59:38 - train: epoch 0063, iter [05000, 05004], lr: 0.001000, loss: 1.0539
2022-07-14 05:59:39 - train: epoch 063, train_loss: 1.1291
2022-07-14 06:00:54 - eval: epoch: 063, acc1: 73.192%, acc5: 91.302%, test_loss: 1.0819, per_image_load_time: 2.611ms, per_image_inference_time: 0.293ms
2022-07-14 06:00:54 - until epoch: 063, best_acc1: 73.192%
2022-07-14 06:00:54 - epoch 064 lr: 0.001000
2022-07-14 06:01:32 - train: epoch 0064, iter [00100, 05004], lr: 0.001000, loss: 1.0759
2022-07-14 06:02:06 - train: epoch 0064, iter [00200, 05004], lr: 0.001000, loss: 1.1365
2022-07-14 06:02:39 - train: epoch 0064, iter [00300, 05004], lr: 0.001000, loss: 1.0041
2022-07-14 06:03:13 - train: epoch 0064, iter [00400, 05004], lr: 0.001000, loss: 1.2399
2022-07-14 06:03:46 - train: epoch 0064, iter [00500, 05004], lr: 0.001000, loss: 0.9952
2022-07-14 06:04:19 - train: epoch 0064, iter [00600, 05004], lr: 0.001000, loss: 1.2676
2022-07-14 06:04:52 - train: epoch 0064, iter [00700, 05004], lr: 0.001000, loss: 1.2167
2022-07-14 06:05:26 - train: epoch 0064, iter [00800, 05004], lr: 0.001000, loss: 1.0230
2022-07-14 06:05:59 - train: epoch 0064, iter [00900, 05004], lr: 0.001000, loss: 1.0977
2022-07-14 06:06:32 - train: epoch 0064, iter [01000, 05004], lr: 0.001000, loss: 1.1530
2022-07-14 06:07:05 - train: epoch 0064, iter [01100, 05004], lr: 0.001000, loss: 0.9714
2022-07-14 06:07:38 - train: epoch 0064, iter [01200, 05004], lr: 0.001000, loss: 0.9872
2022-07-14 06:08:12 - train: epoch 0064, iter [01300, 05004], lr: 0.001000, loss: 1.1989
2022-07-14 06:08:45 - train: epoch 0064, iter [01400, 05004], lr: 0.001000, loss: 1.3567
2022-07-14 06:09:19 - train: epoch 0064, iter [01500, 05004], lr: 0.001000, loss: 1.1955
2022-07-14 06:09:52 - train: epoch 0064, iter [01600, 05004], lr: 0.001000, loss: 1.0226
2022-07-14 06:10:25 - train: epoch 0064, iter [01700, 05004], lr: 0.001000, loss: 0.9471
2022-07-14 06:10:59 - train: epoch 0064, iter [01800, 05004], lr: 0.001000, loss: 1.0083
2022-07-14 06:11:32 - train: epoch 0064, iter [01900, 05004], lr: 0.001000, loss: 1.0355
2022-07-14 06:12:05 - train: epoch 0064, iter [02000, 05004], lr: 0.001000, loss: 1.0458
2022-07-14 06:12:39 - train: epoch 0064, iter [02100, 05004], lr: 0.001000, loss: 1.1063
2022-07-14 06:13:12 - train: epoch 0064, iter [02200, 05004], lr: 0.001000, loss: 1.1682
2022-07-14 06:13:45 - train: epoch 0064, iter [02300, 05004], lr: 0.001000, loss: 1.3035
2022-07-14 06:14:18 - train: epoch 0064, iter [02400, 05004], lr: 0.001000, loss: 1.1141
2022-07-14 06:14:52 - train: epoch 0064, iter [02500, 05004], lr: 0.001000, loss: 0.9735
2022-07-14 06:15:25 - train: epoch 0064, iter [02600, 05004], lr: 0.001000, loss: 0.9979
2022-07-14 06:15:59 - train: epoch 0064, iter [02700, 05004], lr: 0.001000, loss: 1.1385
2022-07-14 06:16:32 - train: epoch 0064, iter [02800, 05004], lr: 0.001000, loss: 1.0234
2022-07-14 06:17:05 - train: epoch 0064, iter [02900, 05004], lr: 0.001000, loss: 1.2501
2022-07-14 06:17:39 - train: epoch 0064, iter [03000, 05004], lr: 0.001000, loss: 1.1417
2022-07-14 06:18:12 - train: epoch 0064, iter [03100, 05004], lr: 0.001000, loss: 1.0251
2022-07-14 06:18:46 - train: epoch 0064, iter [03200, 05004], lr: 0.001000, loss: 1.1150
2022-07-14 06:19:19 - train: epoch 0064, iter [03300, 05004], lr: 0.001000, loss: 1.0720
2022-07-14 06:19:53 - train: epoch 0064, iter [03400, 05004], lr: 0.001000, loss: 1.2112
2022-07-14 06:20:26 - train: epoch 0064, iter [03500, 05004], lr: 0.001000, loss: 0.9934
2022-07-14 06:21:00 - train: epoch 0064, iter [03600, 05004], lr: 0.001000, loss: 1.0534
2022-07-14 06:21:32 - train: epoch 0064, iter [03700, 05004], lr: 0.001000, loss: 0.7934
2022-07-14 06:22:07 - train: epoch 0064, iter [03800, 05004], lr: 0.001000, loss: 1.2686
2022-07-14 06:22:40 - train: epoch 0064, iter [03900, 05004], lr: 0.001000, loss: 0.9479
2022-07-14 06:23:14 - train: epoch 0064, iter [04000, 05004], lr: 0.001000, loss: 0.9868
2022-07-14 06:23:46 - train: epoch 0064, iter [04100, 05004], lr: 0.001000, loss: 1.1333
2022-07-14 06:24:20 - train: epoch 0064, iter [04200, 05004], lr: 0.001000, loss: 1.0220
2022-07-14 06:24:53 - train: epoch 0064, iter [04300, 05004], lr: 0.001000, loss: 1.2725
2022-07-14 06:25:27 - train: epoch 0064, iter [04400, 05004], lr: 0.001000, loss: 1.1746
2022-07-14 06:26:00 - train: epoch 0064, iter [04500, 05004], lr: 0.001000, loss: 1.0219
2022-07-14 06:26:33 - train: epoch 0064, iter [04600, 05004], lr: 0.001000, loss: 1.3580
2022-07-14 06:27:08 - train: epoch 0064, iter [04700, 05004], lr: 0.001000, loss: 1.4989
2022-07-14 06:27:41 - train: epoch 0064, iter [04800, 05004], lr: 0.001000, loss: 1.0157
2022-07-14 06:28:14 - train: epoch 0064, iter [04900, 05004], lr: 0.001000, loss: 1.3338
2022-07-14 06:28:46 - train: epoch 0064, iter [05000, 05004], lr: 0.001000, loss: 1.0344
2022-07-14 06:28:47 - train: epoch 064, train_loss: 1.1154
2022-07-14 06:30:02 - eval: epoch: 064, acc1: 73.262%, acc5: 91.322%, test_loss: 1.0771, per_image_load_time: 2.531ms, per_image_inference_time: 0.301ms
2022-07-14 06:30:02 - until epoch: 064, best_acc1: 73.262%
2022-07-14 06:30:02 - epoch 065 lr: 0.001000
2022-07-14 06:30:41 - train: epoch 0065, iter [00100, 05004], lr: 0.001000, loss: 1.2345
2022-07-14 06:31:15 - train: epoch 0065, iter [00200, 05004], lr: 0.001000, loss: 1.1133
2022-07-14 06:31:47 - train: epoch 0065, iter [00300, 05004], lr: 0.001000, loss: 1.1024
2022-07-14 06:32:20 - train: epoch 0065, iter [00400, 05004], lr: 0.001000, loss: 1.2376
2022-07-14 06:32:54 - train: epoch 0065, iter [00500, 05004], lr: 0.001000, loss: 1.0714
2022-07-14 06:33:27 - train: epoch 0065, iter [00600, 05004], lr: 0.001000, loss: 1.2072
2022-07-14 06:34:00 - train: epoch 0065, iter [00700, 05004], lr: 0.001000, loss: 1.0134
2022-07-14 06:34:34 - train: epoch 0065, iter [00800, 05004], lr: 0.001000, loss: 1.1010
2022-07-14 06:35:07 - train: epoch 0065, iter [00900, 05004], lr: 0.001000, loss: 1.0407
2022-07-14 06:35:41 - train: epoch 0065, iter [01000, 05004], lr: 0.001000, loss: 1.0988
2022-07-14 06:36:13 - train: epoch 0065, iter [01100, 05004], lr: 0.001000, loss: 1.0775
2022-07-14 06:36:47 - train: epoch 0065, iter [01200, 05004], lr: 0.001000, loss: 1.3189
2022-07-14 06:37:21 - train: epoch 0065, iter [01300, 05004], lr: 0.001000, loss: 1.0305
2022-07-14 06:37:53 - train: epoch 0065, iter [01400, 05004], lr: 0.001000, loss: 0.9133
2022-07-14 06:38:27 - train: epoch 0065, iter [01500, 05004], lr: 0.001000, loss: 1.0374
2022-07-14 06:39:00 - train: epoch 0065, iter [01600, 05004], lr: 0.001000, loss: 1.0137
2022-07-14 06:39:34 - train: epoch 0065, iter [01700, 05004], lr: 0.001000, loss: 1.0922
2022-07-14 06:40:07 - train: epoch 0065, iter [01800, 05004], lr: 0.001000, loss: 0.9952
2022-07-14 06:40:40 - train: epoch 0065, iter [01900, 05004], lr: 0.001000, loss: 0.9686
2022-07-14 06:41:14 - train: epoch 0065, iter [02000, 05004], lr: 0.001000, loss: 1.0832
2022-07-14 06:41:47 - train: epoch 0065, iter [02100, 05004], lr: 0.001000, loss: 1.0476
2022-07-14 06:42:21 - train: epoch 0065, iter [02200, 05004], lr: 0.001000, loss: 1.2593
2022-07-14 06:42:54 - train: epoch 0065, iter [02300, 05004], lr: 0.001000, loss: 1.0295
2022-07-14 06:43:27 - train: epoch 0065, iter [02400, 05004], lr: 0.001000, loss: 1.0676
2022-07-14 06:44:00 - train: epoch 0065, iter [02500, 05004], lr: 0.001000, loss: 1.0539
2022-07-14 06:44:34 - train: epoch 0065, iter [02600, 05004], lr: 0.001000, loss: 1.2203
2022-07-14 06:45:08 - train: epoch 0065, iter [02700, 05004], lr: 0.001000, loss: 1.2203
2022-07-14 06:45:41 - train: epoch 0065, iter [02800, 05004], lr: 0.001000, loss: 1.0019
2022-07-14 06:46:14 - train: epoch 0065, iter [02900, 05004], lr: 0.001000, loss: 1.1410
2022-07-14 06:46:46 - train: epoch 0065, iter [03000, 05004], lr: 0.001000, loss: 1.0252
2022-07-14 06:47:21 - train: epoch 0065, iter [03100, 05004], lr: 0.001000, loss: 1.1436
2022-07-14 06:47:53 - train: epoch 0065, iter [03200, 05004], lr: 0.001000, loss: 1.1682
2022-07-14 06:48:27 - train: epoch 0065, iter [03300, 05004], lr: 0.001000, loss: 1.0437
2022-07-14 06:49:00 - train: epoch 0065, iter [03400, 05004], lr: 0.001000, loss: 1.0225
2022-07-14 06:49:34 - train: epoch 0065, iter [03500, 05004], lr: 0.001000, loss: 1.3207
2022-07-14 06:50:08 - train: epoch 0065, iter [03600, 05004], lr: 0.001000, loss: 1.1498
2022-07-14 06:50:42 - train: epoch 0065, iter [03700, 05004], lr: 0.001000, loss: 1.0254
2022-07-14 06:51:15 - train: epoch 0065, iter [03800, 05004], lr: 0.001000, loss: 0.9722
2022-07-14 06:51:48 - train: epoch 0065, iter [03900, 05004], lr: 0.001000, loss: 1.1662
2022-07-14 06:52:21 - train: epoch 0065, iter [04000, 05004], lr: 0.001000, loss: 1.1105
2022-07-14 06:52:56 - train: epoch 0065, iter [04100, 05004], lr: 0.001000, loss: 1.0337
2022-07-14 06:53:28 - train: epoch 0065, iter [04200, 05004], lr: 0.001000, loss: 1.1480
2022-07-14 06:54:02 - train: epoch 0065, iter [04300, 05004], lr: 0.001000, loss: 1.0425
2022-07-14 06:54:36 - train: epoch 0065, iter [04400, 05004], lr: 0.001000, loss: 1.0447
2022-07-14 06:55:09 - train: epoch 0065, iter [04500, 05004], lr: 0.001000, loss: 1.0745
2022-07-14 06:55:42 - train: epoch 0065, iter [04600, 05004], lr: 0.001000, loss: 1.1361
2022-07-14 06:56:16 - train: epoch 0065, iter [04700, 05004], lr: 0.001000, loss: 1.1509
2022-07-14 06:56:49 - train: epoch 0065, iter [04800, 05004], lr: 0.001000, loss: 0.8858
2022-07-14 06:57:24 - train: epoch 0065, iter [04900, 05004], lr: 0.001000, loss: 1.0793
2022-07-14 06:57:55 - train: epoch 0065, iter [05000, 05004], lr: 0.001000, loss: 1.1749
2022-07-14 06:57:56 - train: epoch 065, train_loss: 1.1037
2022-07-14 06:59:10 - eval: epoch: 065, acc1: 73.262%, acc5: 91.354%, test_loss: 1.0768, per_image_load_time: 2.553ms, per_image_inference_time: 0.307ms
2022-07-14 06:59:10 - until epoch: 065, best_acc1: 73.262%
2022-07-14 06:59:10 - epoch 066 lr: 0.001000
2022-07-14 06:59:49 - train: epoch 0066, iter [00100, 05004], lr: 0.001000, loss: 0.9893
2022-07-14 07:00:22 - train: epoch 0066, iter [00200, 05004], lr: 0.001000, loss: 1.2653
2022-07-14 07:00:56 - train: epoch 0066, iter [00300, 05004], lr: 0.001000, loss: 0.8808
2022-07-14 07:01:29 - train: epoch 0066, iter [00400, 05004], lr: 0.001000, loss: 0.9018
2022-07-14 07:02:03 - train: epoch 0066, iter [00500, 05004], lr: 0.001000, loss: 1.1620
2022-07-14 07:02:36 - train: epoch 0066, iter [00600, 05004], lr: 0.001000, loss: 1.0737
2022-07-14 07:03:09 - train: epoch 0066, iter [00700, 05004], lr: 0.001000, loss: 1.0612
2022-07-14 07:03:43 - train: epoch 0066, iter [00800, 05004], lr: 0.001000, loss: 1.3733
2022-07-14 07:04:16 - train: epoch 0066, iter [00900, 05004], lr: 0.001000, loss: 1.2239
2022-07-14 07:04:49 - train: epoch 0066, iter [01000, 05004], lr: 0.001000, loss: 1.2099
2022-07-14 07:05:22 - train: epoch 0066, iter [01100, 05004], lr: 0.001000, loss: 1.1521
2022-07-14 07:05:55 - train: epoch 0066, iter [01200, 05004], lr: 0.001000, loss: 1.1702
2022-07-14 07:06:30 - train: epoch 0066, iter [01300, 05004], lr: 0.001000, loss: 1.0904
2022-07-14 07:07:02 - train: epoch 0066, iter [01400, 05004], lr: 0.001000, loss: 0.9289
2022-07-14 07:07:36 - train: epoch 0066, iter [01500, 05004], lr: 0.001000, loss: 1.2009
2022-07-14 07:08:09 - train: epoch 0066, iter [01600, 05004], lr: 0.001000, loss: 1.1044
2022-07-14 07:08:43 - train: epoch 0066, iter [01700, 05004], lr: 0.001000, loss: 1.0134
2022-07-14 07:09:16 - train: epoch 0066, iter [01800, 05004], lr: 0.001000, loss: 0.9685
2022-07-14 07:09:49 - train: epoch 0066, iter [01900, 05004], lr: 0.001000, loss: 1.2489
2022-07-14 07:10:23 - train: epoch 0066, iter [02000, 05004], lr: 0.001000, loss: 1.2265
2022-07-14 07:10:56 - train: epoch 0066, iter [02100, 05004], lr: 0.001000, loss: 1.1381
2022-07-14 07:11:29 - train: epoch 0066, iter [02200, 05004], lr: 0.001000, loss: 1.0155
2022-07-14 07:12:03 - train: epoch 0066, iter [02300, 05004], lr: 0.001000, loss: 1.2512
2022-07-14 07:12:36 - train: epoch 0066, iter [02400, 05004], lr: 0.001000, loss: 0.9712
2022-07-14 07:13:10 - train: epoch 0066, iter [02500, 05004], lr: 0.001000, loss: 1.0647
2022-07-14 07:13:42 - train: epoch 0066, iter [02600, 05004], lr: 0.001000, loss: 0.9908
2022-07-14 07:14:17 - train: epoch 0066, iter [02700, 05004], lr: 0.001000, loss: 1.2573
2022-07-14 07:14:50 - train: epoch 0066, iter [02800, 05004], lr: 0.001000, loss: 1.2478
2022-07-14 07:15:24 - train: epoch 0066, iter [02900, 05004], lr: 0.001000, loss: 1.0840
2022-07-14 07:15:57 - train: epoch 0066, iter [03000, 05004], lr: 0.001000, loss: 1.0360
2022-07-14 07:16:30 - train: epoch 0066, iter [03100, 05004], lr: 0.001000, loss: 1.1794
2022-07-14 07:17:04 - train: epoch 0066, iter [03200, 05004], lr: 0.001000, loss: 0.8856
2022-07-14 07:17:38 - train: epoch 0066, iter [03300, 05004], lr: 0.001000, loss: 1.0351
2022-07-14 07:18:11 - train: epoch 0066, iter [03400, 05004], lr: 0.001000, loss: 1.3129
2022-07-14 07:18:45 - train: epoch 0066, iter [03500, 05004], lr: 0.001000, loss: 1.1617
2022-07-14 07:19:19 - train: epoch 0066, iter [03600, 05004], lr: 0.001000, loss: 1.1753
2022-07-14 07:19:52 - train: epoch 0066, iter [03700, 05004], lr: 0.001000, loss: 1.1868
2022-07-14 07:20:25 - train: epoch 0066, iter [03800, 05004], lr: 0.001000, loss: 0.9352
2022-07-14 07:20:59 - train: epoch 0066, iter [03900, 05004], lr: 0.001000, loss: 0.9661
2022-07-14 07:21:32 - train: epoch 0066, iter [04000, 05004], lr: 0.001000, loss: 1.2483
2022-07-14 07:22:06 - train: epoch 0066, iter [04100, 05004], lr: 0.001000, loss: 0.9521
2022-07-14 07:22:38 - train: epoch 0066, iter [04200, 05004], lr: 0.001000, loss: 0.8305
2022-07-14 07:23:12 - train: epoch 0066, iter [04300, 05004], lr: 0.001000, loss: 0.9642
2022-07-14 07:23:45 - train: epoch 0066, iter [04400, 05004], lr: 0.001000, loss: 1.0551
2022-07-14 07:24:19 - train: epoch 0066, iter [04500, 05004], lr: 0.001000, loss: 1.0550
2022-07-14 07:24:53 - train: epoch 0066, iter [04600, 05004], lr: 0.001000, loss: 1.2702
2022-07-14 07:25:26 - train: epoch 0066, iter [04700, 05004], lr: 0.001000, loss: 1.0958
2022-07-14 07:25:59 - train: epoch 0066, iter [04800, 05004], lr: 0.001000, loss: 1.0240
2022-07-14 07:26:32 - train: epoch 0066, iter [04900, 05004], lr: 0.001000, loss: 1.0701
2022-07-14 07:27:05 - train: epoch 0066, iter [05000, 05004], lr: 0.001000, loss: 0.9869
2022-07-14 07:27:05 - train: epoch 066, train_loss: 1.0960
2022-07-14 07:28:20 - eval: epoch: 066, acc1: 73.274%, acc5: 91.400%, test_loss: 1.0725, per_image_load_time: 2.570ms, per_image_inference_time: 0.298ms
2022-07-14 07:28:21 - until epoch: 066, best_acc1: 73.274%
2022-07-14 07:28:21 - epoch 067 lr: 0.001000
2022-07-14 07:28:59 - train: epoch 0067, iter [00100, 05004], lr: 0.001000, loss: 1.0114
2022-07-14 07:29:33 - train: epoch 0067, iter [00200, 05004], lr: 0.001000, loss: 1.0485
2022-07-14 07:30:06 - train: epoch 0067, iter [00300, 05004], lr: 0.001000, loss: 1.4262
2022-07-14 07:30:39 - train: epoch 0067, iter [00400, 05004], lr: 0.001000, loss: 1.0891
2022-07-14 07:31:13 - train: epoch 0067, iter [00500, 05004], lr: 0.001000, loss: 1.0678
2022-07-14 07:31:46 - train: epoch 0067, iter [00600, 05004], lr: 0.001000, loss: 1.0602
2022-07-14 07:32:19 - train: epoch 0067, iter [00700, 05004], lr: 0.001000, loss: 1.1610
2022-07-14 07:32:53 - train: epoch 0067, iter [00800, 05004], lr: 0.001000, loss: 1.1159
2022-07-14 07:33:26 - train: epoch 0067, iter [00900, 05004], lr: 0.001000, loss: 1.1458
2022-07-14 07:33:59 - train: epoch 0067, iter [01000, 05004], lr: 0.001000, loss: 0.9643
2022-07-14 07:34:32 - train: epoch 0067, iter [01100, 05004], lr: 0.001000, loss: 1.1452
2022-07-14 07:35:06 - train: epoch 0067, iter [01200, 05004], lr: 0.001000, loss: 1.0679
2022-07-14 07:35:38 - train: epoch 0067, iter [01300, 05004], lr: 0.001000, loss: 1.2329
2022-07-14 07:36:12 - train: epoch 0067, iter [01400, 05004], lr: 0.001000, loss: 1.0415
2022-07-14 07:36:45 - train: epoch 0067, iter [01500, 05004], lr: 0.001000, loss: 1.1061
2022-07-14 07:37:19 - train: epoch 0067, iter [01600, 05004], lr: 0.001000, loss: 1.0414
2022-07-14 07:37:51 - train: epoch 0067, iter [01700, 05004], lr: 0.001000, loss: 0.9652
2022-07-14 07:38:25 - train: epoch 0067, iter [01800, 05004], lr: 0.001000, loss: 1.2573
2022-07-14 07:38:58 - train: epoch 0067, iter [01900, 05004], lr: 0.001000, loss: 1.0027
2022-07-14 07:39:31 - train: epoch 0067, iter [02000, 05004], lr: 0.001000, loss: 1.2065
2022-07-14 07:40:04 - train: epoch 0067, iter [02100, 05004], lr: 0.001000, loss: 0.9546
2022-07-14 07:40:38 - train: epoch 0067, iter [02200, 05004], lr: 0.001000, loss: 1.0750
2022-07-14 07:41:11 - train: epoch 0067, iter [02300, 05004], lr: 0.001000, loss: 1.0418
2022-07-14 07:41:45 - train: epoch 0067, iter [02400, 05004], lr: 0.001000, loss: 1.0577
2022-07-14 07:42:18 - train: epoch 0067, iter [02500, 05004], lr: 0.001000, loss: 0.9923
2022-07-14 07:42:51 - train: epoch 0067, iter [02600, 05004], lr: 0.001000, loss: 0.9270
2022-07-14 07:43:25 - train: epoch 0067, iter [02700, 05004], lr: 0.001000, loss: 0.9753
2022-07-14 07:43:59 - train: epoch 0067, iter [02800, 05004], lr: 0.001000, loss: 1.1907
2022-07-14 07:44:32 - train: epoch 0067, iter [02900, 05004], lr: 0.001000, loss: 1.1167
2022-07-14 07:45:05 - train: epoch 0067, iter [03000, 05004], lr: 0.001000, loss: 1.0312
2022-07-14 07:45:39 - train: epoch 0067, iter [03100, 05004], lr: 0.001000, loss: 0.8969
2022-07-14 07:46:12 - train: epoch 0067, iter [03200, 05004], lr: 0.001000, loss: 1.1869
2022-07-14 07:46:46 - train: epoch 0067, iter [03300, 05004], lr: 0.001000, loss: 0.9057
2022-07-14 07:47:19 - train: epoch 0067, iter [03400, 05004], lr: 0.001000, loss: 1.0955
2022-07-14 07:47:53 - train: epoch 0067, iter [03500, 05004], lr: 0.001000, loss: 0.9923
2022-07-14 07:48:27 - train: epoch 0067, iter [03600, 05004], lr: 0.001000, loss: 1.0964
2022-07-14 07:49:00 - train: epoch 0067, iter [03700, 05004], lr: 0.001000, loss: 1.2193
2022-07-14 07:49:33 - train: epoch 0067, iter [03800, 05004], lr: 0.001000, loss: 1.0760
2022-07-14 07:50:06 - train: epoch 0067, iter [03900, 05004], lr: 0.001000, loss: 1.1202
2022-07-14 07:50:40 - train: epoch 0067, iter [04000, 05004], lr: 0.001000, loss: 1.2413
2022-07-14 07:51:13 - train: epoch 0067, iter [04100, 05004], lr: 0.001000, loss: 1.2844
2022-07-14 07:51:47 - train: epoch 0067, iter [04200, 05004], lr: 0.001000, loss: 1.2850
2022-07-14 07:52:21 - train: epoch 0067, iter [04300, 05004], lr: 0.001000, loss: 0.9494
2022-07-14 07:52:54 - train: epoch 0067, iter [04400, 05004], lr: 0.001000, loss: 1.1234
2022-07-14 07:53:28 - train: epoch 0067, iter [04500, 05004], lr: 0.001000, loss: 1.0405
2022-07-14 07:54:01 - train: epoch 0067, iter [04600, 05004], lr: 0.001000, loss: 0.8087
2022-07-14 07:54:35 - train: epoch 0067, iter [04700, 05004], lr: 0.001000, loss: 1.0517
2022-07-14 07:55:08 - train: epoch 0067, iter [04800, 05004], lr: 0.001000, loss: 0.8302
2022-07-14 07:55:43 - train: epoch 0067, iter [04900, 05004], lr: 0.001000, loss: 1.1442
2022-07-14 07:56:14 - train: epoch 0067, iter [05000, 05004], lr: 0.001000, loss: 1.1136
2022-07-14 07:56:15 - train: epoch 067, train_loss: 1.0870
2022-07-14 07:57:29 - eval: epoch: 067, acc1: 73.312%, acc5: 91.426%, test_loss: 1.0715, per_image_load_time: 1.983ms, per_image_inference_time: 0.308ms
2022-07-14 07:57:30 - until epoch: 067, best_acc1: 73.312%
2022-07-14 07:57:30 - epoch 068 lr: 0.001000
2022-07-14 07:58:08 - train: epoch 0068, iter [00100, 05004], lr: 0.001000, loss: 1.2194
2022-07-14 07:58:42 - train: epoch 0068, iter [00200, 05004], lr: 0.001000, loss: 1.0382
2022-07-14 07:59:15 - train: epoch 0068, iter [00300, 05004], lr: 0.001000, loss: 1.1535
2022-07-14 07:59:48 - train: epoch 0068, iter [00400, 05004], lr: 0.001000, loss: 1.1034
2022-07-14 08:00:20 - train: epoch 0068, iter [00500, 05004], lr: 0.001000, loss: 1.0493
2022-07-14 08:00:54 - train: epoch 0068, iter [00600, 05004], lr: 0.001000, loss: 1.0962
2022-07-14 08:01:28 - train: epoch 0068, iter [00700, 05004], lr: 0.001000, loss: 1.3028
2022-07-14 08:02:01 - train: epoch 0068, iter [00800, 05004], lr: 0.001000, loss: 1.0438
2022-07-14 08:02:34 - train: epoch 0068, iter [00900, 05004], lr: 0.001000, loss: 0.9543
2022-07-14 08:03:07 - train: epoch 0068, iter [01000, 05004], lr: 0.001000, loss: 1.1560
2022-07-14 08:03:40 - train: epoch 0068, iter [01100, 05004], lr: 0.001000, loss: 1.2648
2022-07-14 08:04:14 - train: epoch 0068, iter [01200, 05004], lr: 0.001000, loss: 0.9556
2022-07-14 08:04:47 - train: epoch 0068, iter [01300, 05004], lr: 0.001000, loss: 0.9420
2022-07-14 08:05:21 - train: epoch 0068, iter [01400, 05004], lr: 0.001000, loss: 1.1038
2022-07-14 08:05:53 - train: epoch 0068, iter [01500, 05004], lr: 0.001000, loss: 1.2018
2022-07-14 08:06:27 - train: epoch 0068, iter [01600, 05004], lr: 0.001000, loss: 1.1025
2022-07-14 08:07:01 - train: epoch 0068, iter [01700, 05004], lr: 0.001000, loss: 1.2227
2022-07-14 08:07:35 - train: epoch 0068, iter [01800, 05004], lr: 0.001000, loss: 1.1624
2022-07-14 08:08:07 - train: epoch 0068, iter [01900, 05004], lr: 0.001000, loss: 1.1652
2022-07-14 08:08:42 - train: epoch 0068, iter [02000, 05004], lr: 0.001000, loss: 1.0967
2022-07-14 08:09:15 - train: epoch 0068, iter [02100, 05004], lr: 0.001000, loss: 1.0381
2022-07-14 08:09:48 - train: epoch 0068, iter [02200, 05004], lr: 0.001000, loss: 1.0992
2022-07-14 08:10:22 - train: epoch 0068, iter [02300, 05004], lr: 0.001000, loss: 0.9542
2022-07-14 08:10:55 - train: epoch 0068, iter [02400, 05004], lr: 0.001000, loss: 1.1834
2022-07-14 08:11:28 - train: epoch 0068, iter [02500, 05004], lr: 0.001000, loss: 1.0623
2022-07-14 08:12:02 - train: epoch 0068, iter [02600, 05004], lr: 0.001000, loss: 1.1759
2022-07-14 08:12:35 - train: epoch 0068, iter [02700, 05004], lr: 0.001000, loss: 1.1440
2022-07-14 08:13:09 - train: epoch 0068, iter [02800, 05004], lr: 0.001000, loss: 1.2580
2022-07-14 08:13:43 - train: epoch 0068, iter [02900, 05004], lr: 0.001000, loss: 1.1589
2022-07-14 08:14:17 - train: epoch 0068, iter [03000, 05004], lr: 0.001000, loss: 1.2594
2022-07-14 08:14:50 - train: epoch 0068, iter [03100, 05004], lr: 0.001000, loss: 0.9011
2022-07-14 08:15:23 - train: epoch 0068, iter [03200, 05004], lr: 0.001000, loss: 1.1983
2022-07-14 08:15:57 - train: epoch 0068, iter [03300, 05004], lr: 0.001000, loss: 1.0754
2022-07-14 08:16:30 - train: epoch 0068, iter [03400, 05004], lr: 0.001000, loss: 0.9478
2022-07-14 08:17:03 - train: epoch 0068, iter [03500, 05004], lr: 0.001000, loss: 1.1690
2022-07-14 08:17:37 - train: epoch 0068, iter [03600, 05004], lr: 0.001000, loss: 1.0331
2022-07-14 08:18:10 - train: epoch 0068, iter [03700, 05004], lr: 0.001000, loss: 1.2107
2022-07-14 08:18:44 - train: epoch 0068, iter [03800, 05004], lr: 0.001000, loss: 1.2696
2022-07-14 08:19:18 - train: epoch 0068, iter [03900, 05004], lr: 0.001000, loss: 1.2197
2022-07-14 08:19:51 - train: epoch 0068, iter [04000, 05004], lr: 0.001000, loss: 1.0371
2022-07-14 08:20:25 - train: epoch 0068, iter [04100, 05004], lr: 0.001000, loss: 0.8590
2022-07-14 08:20:58 - train: epoch 0068, iter [04200, 05004], lr: 0.001000, loss: 1.2181
2022-07-14 08:21:32 - train: epoch 0068, iter [04300, 05004], lr: 0.001000, loss: 1.1357
2022-07-14 08:22:04 - train: epoch 0068, iter [04400, 05004], lr: 0.001000, loss: 1.0421
2022-07-14 08:22:37 - train: epoch 0068, iter [04500, 05004], lr: 0.001000, loss: 1.1624
2022-07-14 08:23:11 - train: epoch 0068, iter [04600, 05004], lr: 0.001000, loss: 1.2661
2022-07-14 08:23:45 - train: epoch 0068, iter [04700, 05004], lr: 0.001000, loss: 1.3533
2022-07-14 08:24:18 - train: epoch 0068, iter [04800, 05004], lr: 0.001000, loss: 1.1880
2022-07-14 08:24:52 - train: epoch 0068, iter [04900, 05004], lr: 0.001000, loss: 1.2157
2022-07-14 08:25:24 - train: epoch 0068, iter [05000, 05004], lr: 0.001000, loss: 1.0428
2022-07-14 08:25:24 - train: epoch 068, train_loss: 1.0816
2022-07-14 08:26:40 - eval: epoch: 068, acc1: 73.454%, acc5: 91.492%, test_loss: 1.0664, per_image_load_time: 2.556ms, per_image_inference_time: 0.296ms
2022-07-14 08:26:40 - until epoch: 068, best_acc1: 73.454%
2022-07-14 08:26:40 - epoch 069 lr: 0.001000
2022-07-14 08:27:18 - train: epoch 0069, iter [00100, 05004], lr: 0.001000, loss: 1.2905
2022-07-14 08:27:52 - train: epoch 0069, iter [00200, 05004], lr: 0.001000, loss: 1.1811
2022-07-14 08:28:25 - train: epoch 0069, iter [00300, 05004], lr: 0.001000, loss: 1.1380
2022-07-14 08:28:58 - train: epoch 0069, iter [00400, 05004], lr: 0.001000, loss: 1.0593
2022-07-14 08:29:32 - train: epoch 0069, iter [00500, 05004], lr: 0.001000, loss: 0.9517
2022-07-14 08:30:05 - train: epoch 0069, iter [00600, 05004], lr: 0.001000, loss: 0.9466
2022-07-14 08:30:39 - train: epoch 0069, iter [00700, 05004], lr: 0.001000, loss: 1.0567
2022-07-14 08:31:11 - train: epoch 0069, iter [00800, 05004], lr: 0.001000, loss: 1.0626
2022-07-14 08:31:44 - train: epoch 0069, iter [00900, 05004], lr: 0.001000, loss: 1.0082
2022-07-14 08:32:17 - train: epoch 0069, iter [01000, 05004], lr: 0.001000, loss: 0.9983
2022-07-14 08:32:51 - train: epoch 0069, iter [01100, 05004], lr: 0.001000, loss: 1.0730
2022-07-14 08:33:24 - train: epoch 0069, iter [01200, 05004], lr: 0.001000, loss: 1.0752
2022-07-14 08:33:57 - train: epoch 0069, iter [01300, 05004], lr: 0.001000, loss: 1.2735
2022-07-14 08:34:31 - train: epoch 0069, iter [01400, 05004], lr: 0.001000, loss: 1.1498
2022-07-14 08:35:03 - train: epoch 0069, iter [01500, 05004], lr: 0.001000, loss: 1.0853
2022-07-14 08:35:37 - train: epoch 0069, iter [01600, 05004], lr: 0.001000, loss: 1.1699
2022-07-14 08:36:11 - train: epoch 0069, iter [01700, 05004], lr: 0.001000, loss: 1.0356
2022-07-14 08:36:45 - train: epoch 0069, iter [01800, 05004], lr: 0.001000, loss: 0.8882
2022-07-14 08:37:17 - train: epoch 0069, iter [01900, 05004], lr: 0.001000, loss: 0.9659
2022-07-14 08:37:52 - train: epoch 0069, iter [02000, 05004], lr: 0.001000, loss: 0.8863
2022-07-14 08:38:24 - train: epoch 0069, iter [02100, 05004], lr: 0.001000, loss: 1.1738
2022-07-14 08:38:58 - train: epoch 0069, iter [02200, 05004], lr: 0.001000, loss: 1.1146
2022-07-14 08:39:32 - train: epoch 0069, iter [02300, 05004], lr: 0.001000, loss: 1.1158
2022-07-14 08:40:04 - train: epoch 0069, iter [02400, 05004], lr: 0.001000, loss: 1.1510
2022-07-14 08:40:38 - train: epoch 0069, iter [02500, 05004], lr: 0.001000, loss: 1.0676
2022-07-14 08:41:11 - train: epoch 0069, iter [02600, 05004], lr: 0.001000, loss: 1.1522
2022-07-14 08:41:45 - train: epoch 0069, iter [02700, 05004], lr: 0.001000, loss: 1.2712
2022-07-14 08:42:18 - train: epoch 0069, iter [02800, 05004], lr: 0.001000, loss: 1.2683
2022-07-14 08:42:52 - train: epoch 0069, iter [02900, 05004], lr: 0.001000, loss: 0.9346
2022-07-14 08:43:25 - train: epoch 0069, iter [03000, 05004], lr: 0.001000, loss: 0.9695
2022-07-14 08:43:58 - train: epoch 0069, iter [03100, 05004], lr: 0.001000, loss: 0.9943
2022-07-14 08:44:32 - train: epoch 0069, iter [03200, 05004], lr: 0.001000, loss: 0.9807
2022-07-14 08:45:05 - train: epoch 0069, iter [03300, 05004], lr: 0.001000, loss: 1.0164
2022-07-14 08:45:39 - train: epoch 0069, iter [03400, 05004], lr: 0.001000, loss: 0.9336
2022-07-14 08:46:12 - train: epoch 0069, iter [03500, 05004], lr: 0.001000, loss: 0.9582
2022-07-14 08:46:45 - train: epoch 0069, iter [03600, 05004], lr: 0.001000, loss: 0.9962
2022-07-14 08:47:18 - train: epoch 0069, iter [03700, 05004], lr: 0.001000, loss: 1.1943
2022-07-14 08:47:53 - train: epoch 0069, iter [03800, 05004], lr: 0.001000, loss: 1.1270
2022-07-14 08:48:26 - train: epoch 0069, iter [03900, 05004], lr: 0.001000, loss: 1.1473
2022-07-14 08:48:59 - train: epoch 0069, iter [04000, 05004], lr: 0.001000, loss: 1.1722
2022-07-14 08:49:32 - train: epoch 0069, iter [04100, 05004], lr: 0.001000, loss: 1.2507
2022-07-14 08:50:05 - train: epoch 0069, iter [04200, 05004], lr: 0.001000, loss: 0.9065
2022-07-14 08:50:39 - train: epoch 0069, iter [04300, 05004], lr: 0.001000, loss: 1.0376
2022-07-14 08:51:13 - train: epoch 0069, iter [04400, 05004], lr: 0.001000, loss: 1.0920
2022-07-14 08:51:46 - train: epoch 0069, iter [04500, 05004], lr: 0.001000, loss: 1.0542
2022-07-14 08:52:19 - train: epoch 0069, iter [04600, 05004], lr: 0.001000, loss: 1.2680
2022-07-14 08:52:52 - train: epoch 0069, iter [04700, 05004], lr: 0.001000, loss: 1.0690
2022-07-14 08:53:26 - train: epoch 0069, iter [04800, 05004], lr: 0.001000, loss: 1.0683
2022-07-14 08:54:00 - train: epoch 0069, iter [04900, 05004], lr: 0.001000, loss: 0.9988
2022-07-14 08:54:31 - train: epoch 0069, iter [05000, 05004], lr: 0.001000, loss: 1.1501
2022-07-14 08:54:32 - train: epoch 069, train_loss: 1.0741
2022-07-14 08:55:47 - eval: epoch: 069, acc1: 73.564%, acc5: 91.468%, test_loss: 1.0679, per_image_load_time: 2.261ms, per_image_inference_time: 0.304ms
2022-07-14 08:55:47 - until epoch: 069, best_acc1: 73.564%
2022-07-14 08:55:47 - epoch 070 lr: 0.001000
2022-07-14 08:56:25 - train: epoch 0070, iter [00100, 05004], lr: 0.001000, loss: 1.1325
2022-07-14 08:56:58 - train: epoch 0070, iter [00200, 05004], lr: 0.001000, loss: 1.1420
2022-07-14 08:57:32 - train: epoch 0070, iter [00300, 05004], lr: 0.001000, loss: 1.1852
2022-07-14 08:58:06 - train: epoch 0070, iter [00400, 05004], lr: 0.001000, loss: 0.9915
2022-07-14 08:58:38 - train: epoch 0070, iter [00500, 05004], lr: 0.001000, loss: 1.1550
2022-07-14 08:59:13 - train: epoch 0070, iter [00600, 05004], lr: 0.001000, loss: 0.9659
2022-07-14 08:59:45 - train: epoch 0070, iter [00700, 05004], lr: 0.001000, loss: 1.0109
2022-07-14 09:00:19 - train: epoch 0070, iter [00800, 05004], lr: 0.001000, loss: 0.9533
2022-07-14 09:00:52 - train: epoch 0070, iter [00900, 05004], lr: 0.001000, loss: 1.1675
2022-07-14 09:01:25 - train: epoch 0070, iter [01000, 05004], lr: 0.001000, loss: 0.9522
2022-07-14 09:01:59 - train: epoch 0070, iter [01100, 05004], lr: 0.001000, loss: 1.3184
2022-07-14 09:02:33 - train: epoch 0070, iter [01200, 05004], lr: 0.001000, loss: 0.8833
2022-07-14 09:03:05 - train: epoch 0070, iter [01300, 05004], lr: 0.001000, loss: 1.0505
2022-07-14 09:03:40 - train: epoch 0070, iter [01400, 05004], lr: 0.001000, loss: 1.0532
2022-07-14 09:04:12 - train: epoch 0070, iter [01500, 05004], lr: 0.001000, loss: 0.9449
2022-07-14 09:04:46 - train: epoch 0070, iter [01600, 05004], lr: 0.001000, loss: 1.1489
2022-07-14 09:05:19 - train: epoch 0070, iter [01700, 05004], lr: 0.001000, loss: 1.1601
2022-07-14 09:05:53 - train: epoch 0070, iter [01800, 05004], lr: 0.001000, loss: 1.0384
2022-07-14 09:06:26 - train: epoch 0070, iter [01900, 05004], lr: 0.001000, loss: 0.9982
2022-07-14 09:06:59 - train: epoch 0070, iter [02000, 05004], lr: 0.001000, loss: 1.0419
2022-07-14 09:07:33 - train: epoch 0070, iter [02100, 05004], lr: 0.001000, loss: 1.1500
2022-07-14 09:08:07 - train: epoch 0070, iter [02200, 05004], lr: 0.001000, loss: 1.1231
2022-07-14 09:08:40 - train: epoch 0070, iter [02300, 05004], lr: 0.001000, loss: 1.0560
2022-07-14 09:09:14 - train: epoch 0070, iter [02400, 05004], lr: 0.001000, loss: 1.1797
2022-07-14 09:09:47 - train: epoch 0070, iter [02500, 05004], lr: 0.001000, loss: 1.1030
2022-07-14 09:10:21 - train: epoch 0070, iter [02600, 05004], lr: 0.001000, loss: 1.0804
2022-07-14 09:10:53 - train: epoch 0070, iter [02700, 05004], lr: 0.001000, loss: 0.9834
2022-07-14 09:11:27 - train: epoch 0070, iter [02800, 05004], lr: 0.001000, loss: 1.1557
2022-07-14 09:12:00 - train: epoch 0070, iter [02900, 05004], lr: 0.001000, loss: 1.2156
2022-07-14 09:12:34 - train: epoch 0070, iter [03000, 05004], lr: 0.001000, loss: 0.9973
2022-07-14 09:13:07 - train: epoch 0070, iter [03100, 05004], lr: 0.001000, loss: 1.0404
2022-07-14 09:13:41 - train: epoch 0070, iter [03200, 05004], lr: 0.001000, loss: 1.2014
2022-07-14 09:14:14 - train: epoch 0070, iter [03300, 05004], lr: 0.001000, loss: 0.9712
2022-07-14 09:14:47 - train: epoch 0070, iter [03400, 05004], lr: 0.001000, loss: 1.0793
2022-07-14 09:15:21 - train: epoch 0070, iter [03500, 05004], lr: 0.001000, loss: 0.9840
2022-07-14 09:15:55 - train: epoch 0070, iter [03600, 05004], lr: 0.001000, loss: 1.1913
2022-07-14 09:16:28 - train: epoch 0070, iter [03700, 05004], lr: 0.001000, loss: 1.0595
2022-07-14 09:17:02 - train: epoch 0070, iter [03800, 05004], lr: 0.001000, loss: 1.0216
2022-07-14 09:17:35 - train: epoch 0070, iter [03900, 05004], lr: 0.001000, loss: 0.9402
2022-07-14 09:18:08 - train: epoch 0070, iter [04000, 05004], lr: 0.001000, loss: 0.9074
2022-07-14 09:18:41 - train: epoch 0070, iter [04100, 05004], lr: 0.001000, loss: 1.0093
2022-07-14 09:19:15 - train: epoch 0070, iter [04200, 05004], lr: 0.001000, loss: 1.1094
2022-07-14 09:19:49 - train: epoch 0070, iter [04300, 05004], lr: 0.001000, loss: 0.9930
2022-07-14 09:20:22 - train: epoch 0070, iter [04400, 05004], lr: 0.001000, loss: 1.1445
2022-07-14 09:20:55 - train: epoch 0070, iter [04500, 05004], lr: 0.001000, loss: 1.0863
2022-07-14 09:21:29 - train: epoch 0070, iter [04600, 05004], lr: 0.001000, loss: 1.1379
2022-07-14 09:22:03 - train: epoch 0070, iter [04700, 05004], lr: 0.001000, loss: 1.2038
2022-07-14 09:22:36 - train: epoch 0070, iter [04800, 05004], lr: 0.001000, loss: 1.0905
2022-07-14 09:23:10 - train: epoch 0070, iter [04900, 05004], lr: 0.001000, loss: 1.1312
2022-07-14 09:23:42 - train: epoch 0070, iter [05000, 05004], lr: 0.001000, loss: 1.0330
2022-07-14 09:23:43 - train: epoch 070, train_loss: 1.0696
2022-07-14 09:24:58 - eval: epoch: 070, acc1: 73.480%, acc5: 91.506%, test_loss: 1.0647, per_image_load_time: 2.551ms, per_image_inference_time: 0.300ms
2022-07-14 09:24:58 - until epoch: 070, best_acc1: 73.564%
2022-07-14 09:24:58 - epoch 071 lr: 0.001000
2022-07-14 09:25:37 - train: epoch 0071, iter [00100, 05004], lr: 0.001000, loss: 0.9804
2022-07-14 09:26:10 - train: epoch 0071, iter [00200, 05004], lr: 0.001000, loss: 1.0376
2022-07-14 09:26:44 - train: epoch 0071, iter [00300, 05004], lr: 0.001000, loss: 0.9587
2022-07-14 09:27:17 - train: epoch 0071, iter [00400, 05004], lr: 0.001000, loss: 1.1575
2022-07-14 09:27:50 - train: epoch 0071, iter [00500, 05004], lr: 0.001000, loss: 1.0692
2022-07-14 09:28:23 - train: epoch 0071, iter [00600, 05004], lr: 0.001000, loss: 1.1309
2022-07-14 09:28:56 - train: epoch 0071, iter [00700, 05004], lr: 0.001000, loss: 1.1096
2022-07-14 09:29:29 - train: epoch 0071, iter [00800, 05004], lr: 0.001000, loss: 1.0045
2022-07-14 09:30:03 - train: epoch 0071, iter [00900, 05004], lr: 0.001000, loss: 1.0737
2022-07-14 09:30:35 - train: epoch 0071, iter [01000, 05004], lr: 0.001000, loss: 1.1243
2022-07-14 09:31:09 - train: epoch 0071, iter [01100, 05004], lr: 0.001000, loss: 1.2248
2022-07-14 09:31:42 - train: epoch 0071, iter [01200, 05004], lr: 0.001000, loss: 1.0379
2022-07-14 09:32:16 - train: epoch 0071, iter [01300, 05004], lr: 0.001000, loss: 1.0198
2022-07-14 09:32:49 - train: epoch 0071, iter [01400, 05004], lr: 0.001000, loss: 1.1157
2022-07-14 09:33:22 - train: epoch 0071, iter [01500, 05004], lr: 0.001000, loss: 0.8541
2022-07-14 09:33:55 - train: epoch 0071, iter [01600, 05004], lr: 0.001000, loss: 1.0563
2022-07-14 09:34:29 - train: epoch 0071, iter [01700, 05004], lr: 0.001000, loss: 1.0428
2022-07-14 09:35:02 - train: epoch 0071, iter [01800, 05004], lr: 0.001000, loss: 1.0791
2022-07-14 09:35:36 - train: epoch 0071, iter [01900, 05004], lr: 0.001000, loss: 0.9771
2022-07-14 09:36:09 - train: epoch 0071, iter [02000, 05004], lr: 0.001000, loss: 1.1189
2022-07-14 09:36:43 - train: epoch 0071, iter [02100, 05004], lr: 0.001000, loss: 0.8856
2022-07-14 09:37:16 - train: epoch 0071, iter [02200, 05004], lr: 0.001000, loss: 1.0007
2022-07-14 09:37:50 - train: epoch 0071, iter [02300, 05004], lr: 0.001000, loss: 1.0072
2022-07-14 09:38:22 - train: epoch 0071, iter [02400, 05004], lr: 0.001000, loss: 1.0182
2022-07-14 09:38:56 - train: epoch 0071, iter [02500, 05004], lr: 0.001000, loss: 1.1790
2022-07-14 09:39:30 - train: epoch 0071, iter [02600, 05004], lr: 0.001000, loss: 0.9710
2022-07-14 09:40:02 - train: epoch 0071, iter [02700, 05004], lr: 0.001000, loss: 1.0539
2022-07-14 09:40:36 - train: epoch 0071, iter [02800, 05004], lr: 0.001000, loss: 1.1549
2022-07-14 09:41:10 - train: epoch 0071, iter [02900, 05004], lr: 0.001000, loss: 1.0801
2022-07-14 09:41:44 - train: epoch 0071, iter [03000, 05004], lr: 0.001000, loss: 1.1363
2022-07-14 09:42:17 - train: epoch 0071, iter [03100, 05004], lr: 0.001000, loss: 1.0399
2022-07-14 09:42:50 - train: epoch 0071, iter [03200, 05004], lr: 0.001000, loss: 0.9276
2022-07-14 09:43:24 - train: epoch 0071, iter [03300, 05004], lr: 0.001000, loss: 0.9471
2022-07-14 09:43:58 - train: epoch 0071, iter [03400, 05004], lr: 0.001000, loss: 1.0036
2022-07-14 09:44:30 - train: epoch 0071, iter [03500, 05004], lr: 0.001000, loss: 1.1116
2022-07-14 09:45:04 - train: epoch 0071, iter [03600, 05004], lr: 0.001000, loss: 1.2114
2022-07-14 09:45:37 - train: epoch 0071, iter [03700, 05004], lr: 0.001000, loss: 0.9868
2022-07-14 09:46:11 - train: epoch 0071, iter [03800, 05004], lr: 0.001000, loss: 1.0939
2022-07-14 09:46:45 - train: epoch 0071, iter [03900, 05004], lr: 0.001000, loss: 1.1586
2022-07-14 09:47:19 - train: epoch 0071, iter [04000, 05004], lr: 0.001000, loss: 1.2596
2022-07-14 09:47:51 - train: epoch 0071, iter [04100, 05004], lr: 0.001000, loss: 1.0643
2022-07-14 09:48:25 - train: epoch 0071, iter [04200, 05004], lr: 0.001000, loss: 1.2908
2022-07-14 09:48:58 - train: epoch 0071, iter [04300, 05004], lr: 0.001000, loss: 1.1050
2022-07-14 09:49:31 - train: epoch 0071, iter [04400, 05004], lr: 0.001000, loss: 1.0531
2022-07-14 09:50:04 - train: epoch 0071, iter [04500, 05004], lr: 0.001000, loss: 1.0010
2022-07-14 09:50:38 - train: epoch 0071, iter [04600, 05004], lr: 0.001000, loss: 1.2308
2022-07-14 09:51:12 - train: epoch 0071, iter [04700, 05004], lr: 0.001000, loss: 0.9409
2022-07-14 09:51:45 - train: epoch 0071, iter [04800, 05004], lr: 0.001000, loss: 0.9766
2022-07-14 09:52:19 - train: epoch 0071, iter [04900, 05004], lr: 0.001000, loss: 0.8150
2022-07-14 09:52:50 - train: epoch 0071, iter [05000, 05004], lr: 0.001000, loss: 0.9878
2022-07-14 09:52:51 - train: epoch 071, train_loss: 1.0637
2022-07-14 09:54:06 - eval: epoch: 071, acc1: 73.496%, acc5: 91.508%, test_loss: 1.0651, per_image_load_time: 2.593ms, per_image_inference_time: 0.291ms
2022-07-14 09:54:06 - until epoch: 071, best_acc1: 73.564%
2022-07-14 09:54:06 - epoch 072 lr: 0.001000
2022-07-14 09:54:45 - train: epoch 0072, iter [00100, 05004], lr: 0.001000, loss: 1.1480
2022-07-14 09:55:19 - train: epoch 0072, iter [00200, 05004], lr: 0.001000, loss: 0.9817
2022-07-14 09:55:52 - train: epoch 0072, iter [00300, 05004], lr: 0.001000, loss: 0.9883
2022-07-14 09:56:26 - train: epoch 0072, iter [00400, 05004], lr: 0.001000, loss: 1.0451
2022-07-14 09:56:58 - train: epoch 0072, iter [00500, 05004], lr: 0.001000, loss: 0.9746
2022-07-14 09:57:32 - train: epoch 0072, iter [00600, 05004], lr: 0.001000, loss: 1.0106
2022-07-14 09:58:04 - train: epoch 0072, iter [00700, 05004], lr: 0.001000, loss: 1.0656
2022-07-14 09:58:37 - train: epoch 0072, iter [00800, 05004], lr: 0.001000, loss: 1.2297
2022-07-14 09:59:11 - train: epoch 0072, iter [00900, 05004], lr: 0.001000, loss: 1.0139
2022-07-14 09:59:44 - train: epoch 0072, iter [01000, 05004], lr: 0.001000, loss: 1.0289
2022-07-14 10:00:18 - train: epoch 0072, iter [01100, 05004], lr: 0.001000, loss: 1.0191
2022-07-14 10:00:50 - train: epoch 0072, iter [01200, 05004], lr: 0.001000, loss: 0.9271
2022-07-14 10:01:24 - train: epoch 0072, iter [01300, 05004], lr: 0.001000, loss: 1.0477
2022-07-14 10:01:56 - train: epoch 0072, iter [01400, 05004], lr: 0.001000, loss: 1.1586
2022-07-14 10:02:30 - train: epoch 0072, iter [01500, 05004], lr: 0.001000, loss: 0.9943
2022-07-14 10:03:03 - train: epoch 0072, iter [01600, 05004], lr: 0.001000, loss: 1.1458
2022-07-14 10:03:37 - train: epoch 0072, iter [01700, 05004], lr: 0.001000, loss: 0.9998
2022-07-14 10:04:10 - train: epoch 0072, iter [01800, 05004], lr: 0.001000, loss: 0.9445
2022-07-14 10:04:43 - train: epoch 0072, iter [01900, 05004], lr: 0.001000, loss: 0.9799
2022-07-14 10:05:16 - train: epoch 0072, iter [02000, 05004], lr: 0.001000, loss: 1.1528
2022-07-14 10:05:50 - train: epoch 0072, iter [02100, 05004], lr: 0.001000, loss: 1.1337
2022-07-14 10:06:23 - train: epoch 0072, iter [02200, 05004], lr: 0.001000, loss: 1.0522
2022-07-14 10:06:56 - train: epoch 0072, iter [02300, 05004], lr: 0.001000, loss: 1.1938
2022-07-14 10:07:30 - train: epoch 0072, iter [02400, 05004], lr: 0.001000, loss: 1.0140
2022-07-14 10:08:03 - train: epoch 0072, iter [02500, 05004], lr: 0.001000, loss: 0.9293
2022-07-14 10:08:37 - train: epoch 0072, iter [02600, 05004], lr: 0.001000, loss: 0.8684
2022-07-14 10:09:09 - train: epoch 0072, iter [02700, 05004], lr: 0.001000, loss: 1.1314
2022-07-14 10:09:43 - train: epoch 0072, iter [02800, 05004], lr: 0.001000, loss: 1.0969
2022-07-14 10:10:17 - train: epoch 0072, iter [02900, 05004], lr: 0.001000, loss: 0.9090
2022-07-14 10:10:50 - train: epoch 0072, iter [03000, 05004], lr: 0.001000, loss: 1.1058
2022-07-14 10:11:24 - train: epoch 0072, iter [03100, 05004], lr: 0.001000, loss: 1.1263
2022-07-14 10:11:57 - train: epoch 0072, iter [03200, 05004], lr: 0.001000, loss: 1.0284
2022-07-14 10:12:31 - train: epoch 0072, iter [03300, 05004], lr: 0.001000, loss: 0.9967
2022-07-14 10:13:04 - train: epoch 0072, iter [03400, 05004], lr: 0.001000, loss: 1.1812
2022-07-14 10:13:38 - train: epoch 0072, iter [03500, 05004], lr: 0.001000, loss: 1.1178
2022-07-14 10:14:10 - train: epoch 0072, iter [03600, 05004], lr: 0.001000, loss: 0.8938
2022-07-14 10:14:43 - train: epoch 0072, iter [03700, 05004], lr: 0.001000, loss: 1.1225
2022-07-14 10:15:17 - train: epoch 0072, iter [03800, 05004], lr: 0.001000, loss: 1.0995
2022-07-14 10:15:50 - train: epoch 0072, iter [03900, 05004], lr: 0.001000, loss: 1.2317
2022-07-14 10:16:23 - train: epoch 0072, iter [04000, 05004], lr: 0.001000, loss: 0.9791
2022-07-14 10:16:57 - train: epoch 0072, iter [04100, 05004], lr: 0.001000, loss: 1.1780
2022-07-14 10:17:31 - train: epoch 0072, iter [04200, 05004], lr: 0.001000, loss: 1.1174
2022-07-14 10:18:05 - train: epoch 0072, iter [04300, 05004], lr: 0.001000, loss: 1.0919
2022-07-14 10:18:38 - train: epoch 0072, iter [04400, 05004], lr: 0.001000, loss: 0.9128
2022-07-14 10:19:11 - train: epoch 0072, iter [04500, 05004], lr: 0.001000, loss: 1.1910
2022-07-14 10:19:44 - train: epoch 0072, iter [04600, 05004], lr: 0.001000, loss: 1.0736
2022-07-14 10:20:18 - train: epoch 0072, iter [04700, 05004], lr: 0.001000, loss: 0.9963
2022-07-14 10:20:52 - train: epoch 0072, iter [04800, 05004], lr: 0.001000, loss: 1.2217
2022-07-14 10:21:25 - train: epoch 0072, iter [04900, 05004], lr: 0.001000, loss: 1.1733
2022-07-14 10:21:57 - train: epoch 0072, iter [05000, 05004], lr: 0.001000, loss: 1.0764
2022-07-14 10:21:58 - train: epoch 072, train_loss: 1.0606
2022-07-14 10:23:12 - eval: epoch: 072, acc1: 73.332%, acc5: 91.462%, test_loss: 1.0672, per_image_load_time: 2.272ms, per_image_inference_time: 0.311ms
2022-07-14 10:23:13 - until epoch: 072, best_acc1: 73.564%
2022-07-14 10:23:13 - epoch 073 lr: 0.001000
2022-07-14 10:23:51 - train: epoch 0073, iter [00100, 05004], lr: 0.001000, loss: 1.2747
2022-07-14 10:24:25 - train: epoch 0073, iter [00200, 05004], lr: 0.001000, loss: 1.1077
2022-07-14 10:24:59 - train: epoch 0073, iter [00300, 05004], lr: 0.001000, loss: 1.1608
2022-07-14 10:25:32 - train: epoch 0073, iter [00400, 05004], lr: 0.001000, loss: 0.8250
2022-07-14 10:26:05 - train: epoch 0073, iter [00500, 05004], lr: 0.001000, loss: 0.9714
2022-07-14 10:26:38 - train: epoch 0073, iter [00600, 05004], lr: 0.001000, loss: 0.9531
2022-07-14 10:27:11 - train: epoch 0073, iter [00700, 05004], lr: 0.001000, loss: 1.0828
2022-07-14 10:27:45 - train: epoch 0073, iter [00800, 05004], lr: 0.001000, loss: 1.0432
2022-07-14 10:28:18 - train: epoch 0073, iter [00900, 05004], lr: 0.001000, loss: 0.8213
2022-07-14 10:28:52 - train: epoch 0073, iter [01000, 05004], lr: 0.001000, loss: 0.8662
2022-07-14 10:29:25 - train: epoch 0073, iter [01100, 05004], lr: 0.001000, loss: 1.1068
2022-07-14 10:29:57 - train: epoch 0073, iter [01200, 05004], lr: 0.001000, loss: 1.0636
2022-07-14 10:30:31 - train: epoch 0073, iter [01300, 05004], lr: 0.001000, loss: 1.0350
2022-07-14 10:31:05 - train: epoch 0073, iter [01400, 05004], lr: 0.001000, loss: 0.9636
2022-07-14 10:31:38 - train: epoch 0073, iter [01500, 05004], lr: 0.001000, loss: 1.0042
2022-07-14 10:32:11 - train: epoch 0073, iter [01600, 05004], lr: 0.001000, loss: 1.0290
2022-07-14 10:32:44 - train: epoch 0073, iter [01700, 05004], lr: 0.001000, loss: 1.3102
2022-07-14 10:33:17 - train: epoch 0073, iter [01800, 05004], lr: 0.001000, loss: 0.9748
2022-07-14 10:33:50 - train: epoch 0073, iter [01900, 05004], lr: 0.001000, loss: 1.1210
2022-07-14 10:34:24 - train: epoch 0073, iter [02000, 05004], lr: 0.001000, loss: 0.8783
2022-07-14 10:34:57 - train: epoch 0073, iter [02100, 05004], lr: 0.001000, loss: 1.0556
2022-07-14 10:35:31 - train: epoch 0073, iter [02200, 05004], lr: 0.001000, loss: 1.2240
2022-07-14 10:36:04 - train: epoch 0073, iter [02300, 05004], lr: 0.001000, loss: 1.1903
2022-07-14 10:36:37 - train: epoch 0073, iter [02400, 05004], lr: 0.001000, loss: 0.9974
2022-07-14 10:37:10 - train: epoch 0073, iter [02500, 05004], lr: 0.001000, loss: 1.1831
2022-07-14 10:37:44 - train: epoch 0073, iter [02600, 05004], lr: 0.001000, loss: 1.0561
2022-07-14 10:38:17 - train: epoch 0073, iter [02700, 05004], lr: 0.001000, loss: 1.1362
2022-07-14 10:38:51 - train: epoch 0073, iter [02800, 05004], lr: 0.001000, loss: 1.1377
2022-07-14 10:39:24 - train: epoch 0073, iter [02900, 05004], lr: 0.001000, loss: 1.1638
2022-07-14 10:39:58 - train: epoch 0073, iter [03000, 05004], lr: 0.001000, loss: 0.8762
2022-07-14 10:40:30 - train: epoch 0073, iter [03100, 05004], lr: 0.001000, loss: 0.9692
2022-07-14 10:41:03 - train: epoch 0073, iter [03200, 05004], lr: 0.001000, loss: 0.9280
2022-07-14 10:41:37 - train: epoch 0073, iter [03300, 05004], lr: 0.001000, loss: 1.0855
2022-07-14 10:42:11 - train: epoch 0073, iter [03400, 05004], lr: 0.001000, loss: 1.0889
2022-07-14 10:42:44 - train: epoch 0073, iter [03500, 05004], lr: 0.001000, loss: 1.1012
2022-07-14 10:43:17 - train: epoch 0073, iter [03600, 05004], lr: 0.001000, loss: 0.8954
2022-07-14 10:43:50 - train: epoch 0073, iter [03700, 05004], lr: 0.001000, loss: 1.0354
2022-07-14 10:44:23 - train: epoch 0073, iter [03800, 05004], lr: 0.001000, loss: 1.2917
2022-07-14 10:44:57 - train: epoch 0073, iter [03900, 05004], lr: 0.001000, loss: 1.0517
2022-07-14 10:45:31 - train: epoch 0073, iter [04000, 05004], lr: 0.001000, loss: 1.0846
2022-07-14 10:46:04 - train: epoch 0073, iter [04100, 05004], lr: 0.001000, loss: 0.9851
2022-07-14 10:46:37 - train: epoch 0073, iter [04200, 05004], lr: 0.001000, loss: 1.0822
2022-07-14 10:47:10 - train: epoch 0073, iter [04300, 05004], lr: 0.001000, loss: 1.0710
2022-07-14 10:47:44 - train: epoch 0073, iter [04400, 05004], lr: 0.001000, loss: 1.2232
2022-07-14 10:48:17 - train: epoch 0073, iter [04500, 05004], lr: 0.001000, loss: 0.9745
2022-07-14 10:48:50 - train: epoch 0073, iter [04600, 05004], lr: 0.001000, loss: 1.2779
2022-07-14 10:49:24 - train: epoch 0073, iter [04700, 05004], lr: 0.001000, loss: 0.9020
2022-07-14 10:49:57 - train: epoch 0073, iter [04800, 05004], lr: 0.001000, loss: 1.1923
2022-07-14 10:50:30 - train: epoch 0073, iter [04900, 05004], lr: 0.001000, loss: 0.8558
2022-07-14 10:51:02 - train: epoch 0073, iter [05000, 05004], lr: 0.001000, loss: 1.1078
2022-07-14 10:51:03 - train: epoch 073, train_loss: 1.0567
2022-07-14 10:52:18 - eval: epoch: 073, acc1: 73.544%, acc5: 91.596%, test_loss: 1.0644, per_image_load_time: 1.291ms, per_image_inference_time: 0.307ms
2022-07-14 10:52:18 - until epoch: 073, best_acc1: 73.564%
2022-07-14 10:52:18 - epoch 074 lr: 0.001000
2022-07-14 10:52:57 - train: epoch 0074, iter [00100, 05004], lr: 0.001000, loss: 0.9666
2022-07-14 10:53:30 - train: epoch 0074, iter [00200, 05004], lr: 0.001000, loss: 1.1236
2022-07-14 10:54:03 - train: epoch 0074, iter [00300, 05004], lr: 0.001000, loss: 1.1488
2022-07-14 10:54:37 - train: epoch 0074, iter [00400, 05004], lr: 0.001000, loss: 1.1800
2022-07-14 10:55:10 - train: epoch 0074, iter [00500, 05004], lr: 0.001000, loss: 1.0791
2022-07-14 10:55:43 - train: epoch 0074, iter [00600, 05004], lr: 0.001000, loss: 1.0545
2022-07-14 10:56:15 - train: epoch 0074, iter [00700, 05004], lr: 0.001000, loss: 1.0745
2022-07-14 10:56:50 - train: epoch 0074, iter [00800, 05004], lr: 0.001000, loss: 1.2583
2022-07-14 10:57:22 - train: epoch 0074, iter [00900, 05004], lr: 0.001000, loss: 1.0144
2022-07-14 10:57:56 - train: epoch 0074, iter [01000, 05004], lr: 0.001000, loss: 1.0974
2022-07-14 10:58:28 - train: epoch 0074, iter [01100, 05004], lr: 0.001000, loss: 1.2025
2022-07-14 10:59:02 - train: epoch 0074, iter [01200, 05004], lr: 0.001000, loss: 0.9945
2022-07-14 10:59:35 - train: epoch 0074, iter [01300, 05004], lr: 0.001000, loss: 1.1148
2022-07-14 11:00:09 - train: epoch 0074, iter [01400, 05004], lr: 0.001000, loss: 0.9848
2022-07-14 11:00:41 - train: epoch 0074, iter [01500, 05004], lr: 0.001000, loss: 1.0672
2022-07-14 11:01:15 - train: epoch 0074, iter [01600, 05004], lr: 0.001000, loss: 0.8505
2022-07-14 11:01:49 - train: epoch 0074, iter [01700, 05004], lr: 0.001000, loss: 1.0152
2022-07-14 11:02:23 - train: epoch 0074, iter [01800, 05004], lr: 0.001000, loss: 1.3777
2022-07-14 11:02:56 - train: epoch 0074, iter [01900, 05004], lr: 0.001000, loss: 1.0921
2022-07-14 11:03:30 - train: epoch 0074, iter [02000, 05004], lr: 0.001000, loss: 0.7706
2022-07-14 11:04:03 - train: epoch 0074, iter [02100, 05004], lr: 0.001000, loss: 1.0114
2022-07-14 11:04:36 - train: epoch 0074, iter [02200, 05004], lr: 0.001000, loss: 1.3064
2022-07-14 11:05:09 - train: epoch 0074, iter [02300, 05004], lr: 0.001000, loss: 1.1686
2022-07-14 11:05:43 - train: epoch 0074, iter [02400, 05004], lr: 0.001000, loss: 1.1408
2022-07-14 11:06:15 - train: epoch 0074, iter [02500, 05004], lr: 0.001000, loss: 0.9844
2022-07-14 11:06:49 - train: epoch 0074, iter [02600, 05004], lr: 0.001000, loss: 0.8228
2022-07-14 11:07:22 - train: epoch 0074, iter [02700, 05004], lr: 0.001000, loss: 1.0128
2022-07-14 11:07:56 - train: epoch 0074, iter [02800, 05004], lr: 0.001000, loss: 1.3122
2022-07-14 11:08:30 - train: epoch 0074, iter [02900, 05004], lr: 0.001000, loss: 0.9853
2022-07-14 11:09:02 - train: epoch 0074, iter [03000, 05004], lr: 0.001000, loss: 1.1196
2022-07-14 11:09:36 - train: epoch 0074, iter [03100, 05004], lr: 0.001000, loss: 1.0743
2022-07-14 11:10:09 - train: epoch 0074, iter [03200, 05004], lr: 0.001000, loss: 0.9789
2022-07-14 11:10:42 - train: epoch 0074, iter [03300, 05004], lr: 0.001000, loss: 1.1446
2022-07-14 11:11:16 - train: epoch 0074, iter [03400, 05004], lr: 0.001000, loss: 1.0967
2022-07-14 11:11:49 - train: epoch 0074, iter [03500, 05004], lr: 0.001000, loss: 0.9245
2022-07-14 11:12:23 - train: epoch 0074, iter [03600, 05004], lr: 0.001000, loss: 1.0320
2022-07-14 11:12:57 - train: epoch 0074, iter [03700, 05004], lr: 0.001000, loss: 1.0925
2022-07-14 11:13:30 - train: epoch 0074, iter [03800, 05004], lr: 0.001000, loss: 1.0099
2022-07-14 11:14:04 - train: epoch 0074, iter [03900, 05004], lr: 0.001000, loss: 0.8860
2022-07-14 11:14:37 - train: epoch 0074, iter [04000, 05004], lr: 0.001000, loss: 1.0184
2022-07-14 11:15:10 - train: epoch 0074, iter [04100, 05004], lr: 0.001000, loss: 1.2557
2022-07-14 11:15:44 - train: epoch 0074, iter [04200, 05004], lr: 0.001000, loss: 1.0551
2022-07-14 11:16:18 - train: epoch 0074, iter [04300, 05004], lr: 0.001000, loss: 1.0289
2022-07-14 11:16:52 - train: epoch 0074, iter [04400, 05004], lr: 0.001000, loss: 0.8338
2022-07-14 11:17:25 - train: epoch 0074, iter [04500, 05004], lr: 0.001000, loss: 0.8880
2022-07-14 11:17:58 - train: epoch 0074, iter [04600, 05004], lr: 0.001000, loss: 1.1710
2022-07-14 11:18:32 - train: epoch 0074, iter [04700, 05004], lr: 0.001000, loss: 1.0533
2022-07-14 11:19:05 - train: epoch 0074, iter [04800, 05004], lr: 0.001000, loss: 1.1018
2022-07-14 11:19:38 - train: epoch 0074, iter [04900, 05004], lr: 0.001000, loss: 1.3107
2022-07-14 11:20:11 - train: epoch 0074, iter [05000, 05004], lr: 0.001000, loss: 1.0708
2022-07-14 11:20:12 - train: epoch 074, train_loss: 1.0511
2022-07-14 11:21:26 - eval: epoch: 074, acc1: 73.596%, acc5: 91.584%, test_loss: 1.0614, per_image_load_time: 2.398ms, per_image_inference_time: 0.318ms
2022-07-14 11:21:27 - until epoch: 074, best_acc1: 73.596%
2022-07-14 11:21:27 - epoch 075 lr: 0.001000
2022-07-14 11:22:06 - train: epoch 0075, iter [00100, 05004], lr: 0.001000, loss: 1.0823
2022-07-14 11:22:38 - train: epoch 0075, iter [00200, 05004], lr: 0.001000, loss: 1.0536
2022-07-14 11:23:12 - train: epoch 0075, iter [00300, 05004], lr: 0.001000, loss: 1.0608
2022-07-14 11:23:45 - train: epoch 0075, iter [00400, 05004], lr: 0.001000, loss: 1.0299
2022-07-14 11:24:19 - train: epoch 0075, iter [00500, 05004], lr: 0.001000, loss: 0.8996
2022-07-14 11:24:51 - train: epoch 0075, iter [00600, 05004], lr: 0.001000, loss: 0.9312
2022-07-14 11:25:25 - train: epoch 0075, iter [00700, 05004], lr: 0.001000, loss: 1.2074
2022-07-14 11:25:58 - train: epoch 0075, iter [00800, 05004], lr: 0.001000, loss: 1.1573
2022-07-14 11:26:31 - train: epoch 0075, iter [00900, 05004], lr: 0.001000, loss: 1.1846
2022-07-14 11:27:04 - train: epoch 0075, iter [01000, 05004], lr: 0.001000, loss: 0.8682
2022-07-14 11:27:38 - train: epoch 0075, iter [01100, 05004], lr: 0.001000, loss: 1.0893
2022-07-14 11:28:10 - train: epoch 0075, iter [01200, 05004], lr: 0.001000, loss: 1.0288
2022-07-14 11:28:44 - train: epoch 0075, iter [01300, 05004], lr: 0.001000, loss: 0.9520
2022-07-14 11:29:16 - train: epoch 0075, iter [01400, 05004], lr: 0.001000, loss: 1.0640
2022-07-14 11:29:50 - train: epoch 0075, iter [01500, 05004], lr: 0.001000, loss: 1.2347
2022-07-14 11:30:23 - train: epoch 0075, iter [01600, 05004], lr: 0.001000, loss: 0.7892
2022-07-14 11:30:56 - train: epoch 0075, iter [01700, 05004], lr: 0.001000, loss: 1.0130
2022-07-14 11:31:29 - train: epoch 0075, iter [01800, 05004], lr: 0.001000, loss: 1.0061
2022-07-14 11:32:03 - train: epoch 0075, iter [01900, 05004], lr: 0.001000, loss: 0.9235
2022-07-14 11:32:35 - train: epoch 0075, iter [02000, 05004], lr: 0.001000, loss: 1.0460
2022-07-14 11:33:09 - train: epoch 0075, iter [02100, 05004], lr: 0.001000, loss: 0.9751
2022-07-14 11:33:43 - train: epoch 0075, iter [02200, 05004], lr: 0.001000, loss: 1.0864
2022-07-14 11:34:15 - train: epoch 0075, iter [02300, 05004], lr: 0.001000, loss: 1.0313
2022-07-14 11:34:49 - train: epoch 0075, iter [02400, 05004], lr: 0.001000, loss: 1.0634
2022-07-14 11:35:22 - train: epoch 0075, iter [02500, 05004], lr: 0.001000, loss: 1.0989
2022-07-14 11:35:56 - train: epoch 0075, iter [02600, 05004], lr: 0.001000, loss: 1.0360
2022-07-14 11:36:29 - train: epoch 0075, iter [02700, 05004], lr: 0.001000, loss: 0.8503
2022-07-14 11:37:03 - train: epoch 0075, iter [02800, 05004], lr: 0.001000, loss: 1.0171
2022-07-14 11:37:36 - train: epoch 0075, iter [02900, 05004], lr: 0.001000, loss: 1.1536
2022-07-14 11:38:10 - train: epoch 0075, iter [03000, 05004], lr: 0.001000, loss: 1.1496
2022-07-14 11:38:43 - train: epoch 0075, iter [03100, 05004], lr: 0.001000, loss: 1.0680
2022-07-14 11:39:16 - train: epoch 0075, iter [03200, 05004], lr: 0.001000, loss: 1.0315
2022-07-14 11:39:50 - train: epoch 0075, iter [03300, 05004], lr: 0.001000, loss: 1.0850
2022-07-14 11:40:24 - train: epoch 0075, iter [03400, 05004], lr: 0.001000, loss: 0.8189
2022-07-14 11:40:56 - train: epoch 0075, iter [03500, 05004], lr: 0.001000, loss: 0.9380
2022-07-14 11:41:31 - train: epoch 0075, iter [03600, 05004], lr: 0.001000, loss: 1.0041
2022-07-14 11:42:03 - train: epoch 0075, iter [03700, 05004], lr: 0.001000, loss: 1.1410
2022-07-14 11:42:37 - train: epoch 0075, iter [03800, 05004], lr: 0.001000, loss: 0.9805
2022-07-14 11:43:10 - train: epoch 0075, iter [03900, 05004], lr: 0.001000, loss: 1.1910
2022-07-14 11:43:44 - train: epoch 0075, iter [04000, 05004], lr: 0.001000, loss: 0.9664
2022-07-14 11:44:17 - train: epoch 0075, iter [04100, 05004], lr: 0.001000, loss: 0.7840
2022-07-14 11:44:50 - train: epoch 0075, iter [04200, 05004], lr: 0.001000, loss: 1.1280
2022-07-14 11:45:23 - train: epoch 0075, iter [04300, 05004], lr: 0.001000, loss: 1.2336
2022-07-14 11:45:57 - train: epoch 0075, iter [04400, 05004], lr: 0.001000, loss: 0.9165
2022-07-14 11:46:31 - train: epoch 0075, iter [04500, 05004], lr: 0.001000, loss: 1.1220
2022-07-14 11:47:04 - train: epoch 0075, iter [04600, 05004], lr: 0.001000, loss: 0.8483
2022-07-14 11:47:38 - train: epoch 0075, iter [04700, 05004], lr: 0.001000, loss: 1.1472
2022-07-14 11:48:12 - train: epoch 0075, iter [04800, 05004], lr: 0.001000, loss: 1.1358
2022-07-14 11:48:45 - train: epoch 0075, iter [04900, 05004], lr: 0.001000, loss: 0.9361
2022-07-14 11:49:17 - train: epoch 0075, iter [05000, 05004], lr: 0.001000, loss: 1.1883
2022-07-14 11:49:18 - train: epoch 075, train_loss: 1.0488
2022-07-14 11:50:32 - eval: epoch: 075, acc1: 73.644%, acc5: 91.510%, test_loss: 1.0626, per_image_load_time: 2.510ms, per_image_inference_time: 0.314ms
2022-07-14 11:50:32 - until epoch: 075, best_acc1: 73.644%
2022-07-14 11:50:32 - epoch 076 lr: 0.001000
2022-07-14 11:51:11 - train: epoch 0076, iter [00100, 05004], lr: 0.001000, loss: 0.8941
2022-07-14 11:51:45 - train: epoch 0076, iter [00200, 05004], lr: 0.001000, loss: 1.1039
2022-07-14 11:52:19 - train: epoch 0076, iter [00300, 05004], lr: 0.001000, loss: 1.1413
2022-07-14 11:52:52 - train: epoch 0076, iter [00400, 05004], lr: 0.001000, loss: 1.1619
2022-07-14 11:53:25 - train: epoch 0076, iter [00500, 05004], lr: 0.001000, loss: 1.0395
2022-07-14 11:53:58 - train: epoch 0076, iter [00600, 05004], lr: 0.001000, loss: 1.0214
2022-07-14 11:54:32 - train: epoch 0076, iter [00700, 05004], lr: 0.001000, loss: 1.0839
2022-07-14 11:55:05 - train: epoch 0076, iter [00800, 05004], lr: 0.001000, loss: 0.9669
2022-07-14 11:55:39 - train: epoch 0076, iter [00900, 05004], lr: 0.001000, loss: 0.8386
2022-07-14 11:56:12 - train: epoch 0076, iter [01000, 05004], lr: 0.001000, loss: 0.9671
2022-07-14 11:56:46 - train: epoch 0076, iter [01100, 05004], lr: 0.001000, loss: 0.9378
2022-07-14 11:57:19 - train: epoch 0076, iter [01200, 05004], lr: 0.001000, loss: 0.9676
2022-07-14 11:57:53 - train: epoch 0076, iter [01300, 05004], lr: 0.001000, loss: 1.0475
2022-07-14 11:58:26 - train: epoch 0076, iter [01400, 05004], lr: 0.001000, loss: 0.9280
2022-07-14 11:58:59 - train: epoch 0076, iter [01500, 05004], lr: 0.001000, loss: 0.9299
2022-07-14 11:59:33 - train: epoch 0076, iter [01600, 05004], lr: 0.001000, loss: 0.9242
2022-07-14 12:00:06 - train: epoch 0076, iter [01700, 05004], lr: 0.001000, loss: 1.0182
2022-07-14 12:00:39 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 0.8709
2022-07-14 12:01:13 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 1.1560
2022-07-14 12:01:46 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 1.1172
2022-07-14 12:02:19 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 1.0914
2022-07-14 12:02:52 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 1.3482
2022-07-14 12:03:25 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 1.0541
2022-07-14 12:03:59 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 1.1612
2022-07-14 12:04:33 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 1.0660
2022-07-14 12:05:06 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 1.2836
2022-07-14 12:05:38 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 1.0962
2022-07-14 12:06:12 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 1.0389
2022-07-14 12:06:46 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 1.1543
2022-07-14 12:07:19 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 0.9230
2022-07-14 12:07:53 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 1.1363
2022-07-14 12:08:25 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 1.0899
2022-07-14 12:08:59 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 1.0111
2022-07-14 12:09:32 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 1.1400
2022-07-14 12:10:06 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 0.9816
2022-07-14 12:10:38 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 1.0299
2022-07-14 12:11:12 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 0.9390
2022-07-14 12:11:46 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 0.9357
2022-07-14 12:12:19 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 0.9411
2022-07-14 12:12:53 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 1.0267
2022-07-14 12:13:25 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 0.9020
2022-07-14 12:13:59 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 1.2704
2022-07-14 12:14:33 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 1.0710
2022-07-14 12:15:06 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 1.0970
2022-07-14 12:15:38 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 1.0134
2022-07-14 12:16:12 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 1.0098
2022-07-14 12:16:46 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 1.0624
2022-07-14 12:17:19 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 0.8993
2022-07-14 12:17:53 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 1.0725
2022-07-14 12:18:24 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 1.0238
2022-07-14 12:18:25 - train: epoch 076, train_loss: 1.0454
2022-07-14 12:19:40 - eval: epoch: 076, acc1: 73.552%, acc5: 91.512%, test_loss: 1.0623, per_image_load_time: 2.534ms, per_image_inference_time: 0.293ms
2022-07-14 12:19:40 - until epoch: 076, best_acc1: 73.644%
2022-07-14 12:19:40 - epoch 077 lr: 0.001000
2022-07-14 12:20:19 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 1.2027
2022-07-14 12:20:52 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 1.1270
2022-07-14 12:21:25 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 0.7918
2022-07-14 12:21:58 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 1.1989
2022-07-14 12:22:30 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 0.8997
2022-07-14 12:23:04 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 0.8732
2022-07-14 12:23:37 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 1.0935
2022-07-14 12:24:10 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 1.1496
2022-07-14 12:24:44 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 1.1794
2022-07-14 12:25:17 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 0.8900
2022-07-14 12:25:50 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 0.9921
2022-07-14 12:26:23 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 1.1679
2022-07-14 12:26:57 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 0.8785
2022-07-14 12:27:30 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 1.1472
2022-07-14 12:28:04 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 0.9568
2022-07-14 12:28:37 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 1.0959
2022-07-14 12:29:10 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 1.3089
2022-07-14 12:29:44 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 0.9068
2022-07-14 12:30:17 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 1.0026
2022-07-14 12:30:49 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 0.9230
2022-07-14 12:31:23 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 1.0903
2022-07-14 12:31:57 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 1.1298
2022-07-14 12:32:31 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 1.1615
2022-07-14 12:33:03 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 0.9587
2022-07-14 12:33:37 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 1.1397
2022-07-14 12:34:11 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 0.8298
2022-07-14 12:34:45 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 1.1217
2022-07-14 12:35:19 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 1.1620
2022-07-14 12:35:51 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 1.3280
2022-07-14 12:36:24 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 0.8846
2022-07-14 12:36:58 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 1.0316
2022-07-14 12:37:31 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 1.1364
2022-07-14 12:38:05 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 0.9230
2022-07-14 12:38:38 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 1.1355
2022-07-14 12:39:12 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 0.8885
2022-07-14 12:39:46 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 0.9950
2022-07-14 12:40:19 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 1.0405
2022-07-14 12:40:52 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 1.0536
2022-07-14 12:41:26 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 1.1670
2022-07-14 12:42:00 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 0.9915
2022-07-14 12:42:33 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 1.2392
2022-07-14 12:43:07 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 1.1733
2022-07-14 12:43:39 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 0.9344
2022-07-14 12:44:13 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 1.0144
2022-07-14 12:44:47 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 1.1181
2022-07-14 12:45:20 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 0.9543
2022-07-14 12:45:54 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 0.8370
2022-07-14 12:46:27 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 1.0200
2022-07-14 12:47:01 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 1.1535
2022-07-14 12:47:33 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 1.1713
2022-07-14 12:47:34 - train: epoch 077, train_loss: 1.0402
2022-07-14 12:48:49 - eval: epoch: 077, acc1: 73.536%, acc5: 91.546%, test_loss: 1.0631, per_image_load_time: 1.628ms, per_image_inference_time: 0.295ms
2022-07-14 12:48:49 - until epoch: 077, best_acc1: 73.644%
2022-07-14 12:48:49 - epoch 078 lr: 0.001000
2022-07-14 12:49:27 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 0.9677
2022-07-14 12:50:01 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 1.1437
2022-07-14 12:50:34 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 1.1282
2022-07-14 12:51:08 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 1.1068
2022-07-14 12:51:40 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 1.0560
2022-07-14 12:52:14 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 1.0511
2022-07-14 12:52:47 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 1.2104
2022-07-14 12:53:20 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 1.1470
2022-07-14 12:53:54 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 1.1420
2022-07-14 12:54:27 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 1.0512
2022-07-14 12:55:01 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 0.8421
2022-07-14 12:55:34 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 0.7512
2022-07-14 12:56:07 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 1.0927
2022-07-14 12:56:41 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 0.9345
2022-07-14 12:57:13 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 1.0492
2022-07-14 12:57:47 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 1.0891
2022-07-14 12:58:21 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 0.9536
2022-07-14 12:58:54 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 0.9494
2022-07-14 12:59:27 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 0.8859
2022-07-14 13:00:01 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 0.9144
2022-07-14 13:00:34 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 1.2012
2022-07-14 13:01:07 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 0.9584
2022-07-14 13:01:41 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 1.1040
2022-07-14 13:02:14 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 0.9740
2022-07-14 13:02:47 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 1.0560
2022-07-14 13:03:21 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 0.9509
2022-07-14 13:03:54 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 1.0609
2022-07-14 13:04:28 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 1.0468
2022-07-14 13:05:01 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 0.9073
2022-07-14 13:05:35 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 1.0231
2022-07-14 13:06:07 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 1.1054
2022-07-14 13:06:42 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 1.0113
2022-07-14 13:07:14 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 1.0553
2022-07-14 13:07:49 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 1.0659
2022-07-14 13:08:22 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 1.0162
2022-07-14 13:08:56 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 1.0312
2022-07-14 13:09:29 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 0.9133
2022-07-14 13:10:02 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 1.0896
2022-07-14 13:10:35 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 1.0079
2022-07-14 13:11:09 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 0.9606
2022-07-14 13:11:43 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 1.1501
2022-07-14 13:12:17 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 1.1468
2022-07-14 13:12:49 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 1.0624
2022-07-14 13:13:24 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 1.0413
2022-07-14 13:13:56 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 1.1719
2022-07-14 13:14:30 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 0.9084
2022-07-14 13:15:03 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 1.0678
2022-07-14 13:15:36 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 1.2410
2022-07-14 13:16:10 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 1.0579
2022-07-14 13:16:42 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 1.0397
2022-07-14 13:16:43 - train: epoch 078, train_loss: 1.0342
2022-07-14 13:17:57 - eval: epoch: 078, acc1: 73.424%, acc5: 91.632%, test_loss: 1.0632, per_image_load_time: 2.419ms, per_image_inference_time: 0.296ms
2022-07-14 13:17:57 - until epoch: 078, best_acc1: 73.644%
2022-07-14 13:17:57 - epoch 079 lr: 0.001000
2022-07-14 13:18:36 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 0.9728
2022-07-14 13:19:09 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 1.0047
2022-07-14 13:19:42 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 1.0433
2022-07-14 13:20:16 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 1.0675
2022-07-14 13:20:50 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 1.0879
2022-07-14 13:21:22 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 0.9257
2022-07-14 13:21:56 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 0.9200
2022-07-14 13:22:29 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 1.0999
2022-07-14 13:23:03 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 0.9794
2022-07-14 13:23:36 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 0.9548
2022-07-14 13:24:09 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 1.0531
2022-07-14 13:24:43 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 1.3173
2022-07-14 13:25:16 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 0.9448
2022-07-14 13:25:50 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 0.9172
2022-07-14 13:26:23 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 0.9092
2022-07-14 13:26:57 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 0.9526
2022-07-14 13:27:30 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 1.0433
2022-07-14 13:28:04 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 0.9453
2022-07-14 13:28:36 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 1.0987
2022-07-14 13:29:10 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 1.1259
2022-07-14 13:29:43 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 0.9940
2022-07-14 13:30:16 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 1.0897
2022-07-14 13:30:50 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 0.9647
2022-07-14 13:31:23 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 1.0455
2022-07-14 13:31:56 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 1.0186
2022-07-14 13:32:29 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 0.9408
2022-07-14 13:33:03 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 0.9152
2022-07-14 13:33:37 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 0.9859
2022-07-14 13:34:10 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 0.8784
2022-07-14 13:34:43 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 1.0577
2022-07-14 13:35:17 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 1.1040
2022-07-14 13:35:49 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 1.2025
2022-07-14 13:36:24 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 1.0624
2022-07-14 13:36:58 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 0.8341
2022-07-14 13:37:31 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 1.2053
2022-07-14 13:38:04 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 0.9914
2022-07-14 13:38:38 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 0.9671
2022-07-14 13:39:11 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 1.1270
2022-07-14 13:39:44 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 0.9336
2022-07-14 13:40:18 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 0.8838
2022-07-14 13:40:51 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 1.2442
2022-07-14 13:41:25 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 0.9148
2022-07-14 13:41:57 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 0.7736
2022-07-14 13:42:31 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 1.1946
2022-07-14 13:43:05 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 1.1887
2022-07-14 13:43:38 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 1.1343
2022-07-14 13:44:11 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 1.0832
2022-07-14 13:44:45 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 1.1307
2022-07-14 13:45:18 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 1.1938
2022-07-14 13:45:50 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 0.9805
2022-07-14 13:45:51 - train: epoch 079, train_loss: 1.0325
2022-07-14 13:47:06 - eval: epoch: 079, acc1: 73.514%, acc5: 91.574%, test_loss: 1.0631, per_image_load_time: 1.903ms, per_image_inference_time: 0.302ms
2022-07-14 13:47:06 - until epoch: 079, best_acc1: 73.644%
2022-07-14 13:47:06 - epoch 080 lr: 0.001000
2022-07-14 13:47:44 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 0.9062
2022-07-14 13:48:18 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 0.9368
2022-07-14 13:48:52 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 1.0510
2022-07-14 13:49:25 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 0.8381
2022-07-14 13:49:59 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 1.1268
2022-07-14 13:50:31 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 0.9487
2022-07-14 13:51:05 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 0.9665
2022-07-14 13:51:38 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 0.8568
2022-07-14 13:52:11 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 1.0891
2022-07-14 13:52:44 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 0.9943
2022-07-14 13:53:18 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 1.0733
2022-07-14 13:53:51 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 1.0348
2022-07-14 13:54:24 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 0.9540
2022-07-14 13:54:58 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 1.0310
2022-07-14 13:55:31 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 0.8925
2022-07-14 13:56:04 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 0.9059
2022-07-14 13:56:38 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 1.1238
2022-07-14 13:57:10 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 1.1264
2022-07-14 13:57:44 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 1.0305
2022-07-14 13:58:17 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 1.1263
2022-07-14 13:58:50 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 1.0032
2022-07-14 13:59:23 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 1.0574
2022-07-14 13:59:57 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 0.9178
2022-07-14 14:00:30 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 0.9559
2022-07-14 14:01:03 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 1.0018
2022-07-14 14:01:37 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 1.0113
2022-07-14 14:02:10 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 1.1861
2022-07-14 14:02:44 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 1.1617
2022-07-14 14:03:17 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 0.9115
2022-07-14 14:03:50 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 1.0740
2022-07-14 14:04:24 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 1.2456
2022-07-14 14:04:57 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 0.6906
2022-07-14 14:05:31 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 1.0248
2022-07-14 14:06:05 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 0.9206
2022-07-14 14:06:39 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 0.8470
2022-07-14 14:07:12 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 1.0992
2022-07-14 14:07:45 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 0.9526
2022-07-14 14:08:18 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 1.0819
2022-07-14 14:08:51 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 0.9772
2022-07-14 14:09:24 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 1.1323
2022-07-14 14:09:58 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 1.1385
2022-07-14 14:10:31 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 0.9644
2022-07-14 14:11:05 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 1.0966
2022-07-14 14:11:37 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 1.0783
2022-07-14 14:12:12 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 0.9348
2022-07-14 14:12:45 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 1.0920
2022-07-14 14:13:18 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 1.0175
2022-07-14 14:13:51 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 1.0916
2022-07-14 14:14:26 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 1.1529
2022-07-14 14:14:57 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 0.8723
2022-07-14 14:14:58 - train: epoch 080, train_loss: 1.0310
2022-07-14 14:16:12 - eval: epoch: 080, acc1: 73.524%, acc5: 91.514%, test_loss: 1.0633, per_image_load_time: 1.936ms, per_image_inference_time: 0.304ms
2022-07-14 14:16:13 - until epoch: 080, best_acc1: 73.644%
2022-07-14 14:16:13 - epoch 081 lr: 0.001000
2022-07-14 14:16:51 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 0.8824
2022-07-14 14:17:25 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 1.1419
2022-07-14 14:17:58 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 0.9903
2022-07-14 14:18:31 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 1.1067
2022-07-14 14:19:04 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 1.0840
2022-07-14 14:19:38 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 1.0045
2022-07-14 14:20:11 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 0.9632
2022-07-14 14:20:44 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 1.1279
2022-07-14 14:21:18 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 0.8365
2022-07-14 14:21:50 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 0.9981
2022-07-14 14:22:24 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 0.9874
2022-07-14 14:22:57 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 1.0362
2022-07-14 14:23:30 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 0.9043
2022-07-14 14:24:04 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 0.7126
2022-07-14 14:24:37 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 1.1207
2022-07-14 14:25:10 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 1.0152
2022-07-14 14:25:43 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 1.1749
2022-07-14 14:26:17 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 0.9504
2022-07-14 14:26:50 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 1.0173
2022-07-14 14:27:23 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 1.1039
2022-07-14 14:27:57 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 1.0119
2022-07-14 14:28:30 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 1.0868
2022-07-14 14:29:04 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 0.9962
2022-07-14 14:29:36 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 0.9673
2022-07-14 14:30:10 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 1.2219
2022-07-14 14:30:43 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 1.0737
2022-07-14 14:31:17 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 0.9663
2022-07-14 14:31:49 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 0.9459
2022-07-14 14:32:24 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 0.9426
2022-07-14 14:32:56 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 1.0210
2022-07-14 14:33:30 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 0.9343
2022-07-14 14:34:04 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 1.0374
2022-07-14 14:34:38 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 1.0703
2022-07-14 14:35:10 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 1.1088
2022-07-14 14:35:44 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 0.9748
2022-07-14 14:36:17 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 0.9591
2022-07-14 14:36:51 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 1.2567
2022-07-14 14:37:24 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 0.9368
2022-07-14 14:37:57 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 1.0708
2022-07-14 14:38:31 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 0.8101
2022-07-14 14:39:04 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 1.0939
2022-07-14 14:39:38 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 1.0445
2022-07-14 14:40:12 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 1.0210
2022-07-14 14:40:44 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 1.1392
2022-07-14 14:41:17 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 1.0578
2022-07-14 14:41:50 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 0.9685
2022-07-14 14:42:24 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 1.0236
2022-07-14 14:42:56 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 1.0105
2022-07-14 14:43:31 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 1.1332
2022-07-14 14:44:02 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 0.8192
2022-07-14 14:44:03 - train: epoch 081, train_loss: 1.0281
2022-07-14 14:45:18 - eval: epoch: 081, acc1: 73.564%, acc5: 91.566%, test_loss: 1.0622, per_image_load_time: 2.564ms, per_image_inference_time: 0.293ms
2022-07-14 14:45:19 - until epoch: 081, best_acc1: 73.644%
2022-07-14 14:45:19 - epoch 082 lr: 0.001000
2022-07-14 14:45:57 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 0.8653
2022-07-14 14:46:30 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 0.9029
2022-07-14 14:47:03 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 1.1674
2022-07-14 14:47:37 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 1.1201
2022-07-14 14:48:09 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 1.0293
2022-07-14 14:48:43 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 0.9226
2022-07-14 14:49:16 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 1.1516
2022-07-14 14:49:49 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 1.0438
2022-07-14 14:50:23 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 1.1054
2022-07-14 14:50:57 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 1.1232
2022-07-14 14:51:29 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 1.2226
2022-07-14 14:52:03 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 1.0208
2022-07-14 14:52:36 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 1.2035
2022-07-14 14:53:09 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 1.0142
2022-07-14 14:53:43 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 0.9315
2022-07-14 14:54:17 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 1.0865
2022-07-14 14:54:50 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 0.9896
2022-07-14 14:55:23 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 0.9978
2022-07-14 14:55:56 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 0.9148
2022-07-14 14:56:30 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 0.8070
2022-07-14 14:57:04 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 0.9509
2022-07-14 14:57:37 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 1.1303
2022-07-14 14:58:11 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 1.1158
2022-07-14 14:58:43 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 1.0756
2022-07-14 14:59:16 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 0.8808
2022-07-14 14:59:50 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 0.9150
2022-07-14 15:00:23 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 0.9173
2022-07-14 15:00:57 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 0.8808
2022-07-14 15:01:31 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 0.9781
2022-07-14 15:02:04 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 0.9503
2022-07-14 15:02:37 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 0.9486
2022-07-14 15:03:10 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 1.2304
2022-07-14 15:03:44 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 0.9445
2022-07-14 15:04:17 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 0.9749
2022-07-14 15:04:50 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 0.9645
2022-07-14 15:05:24 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 0.9007
2022-07-14 15:05:57 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 1.0179
2022-07-14 15:06:30 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 1.2081
2022-07-14 15:07:04 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 1.0771
2022-07-14 15:07:37 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 1.1764
2022-07-14 15:08:10 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 1.0327
2022-07-14 15:08:43 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 1.1457
2022-07-14 15:09:17 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 0.8885
2022-07-14 15:09:50 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 0.9619
2022-07-14 15:10:23 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 1.1082
2022-07-14 15:10:56 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 1.0464
2022-07-14 15:11:30 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 0.9439
2022-07-14 15:12:03 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 0.8604
2022-07-14 15:12:36 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 0.9311
2022-07-14 15:13:08 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 0.9873
2022-07-14 15:13:09 - train: epoch 082, train_loss: 1.0236
2022-07-14 15:14:24 - eval: epoch: 082, acc1: 73.596%, acc5: 91.572%, test_loss: 1.0630, per_image_load_time: 1.191ms, per_image_inference_time: 0.298ms
2022-07-14 15:14:24 - until epoch: 082, best_acc1: 73.644%
2022-07-14 15:14:24 - epoch 083 lr: 0.001000
2022-07-14 15:15:03 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 0.8818
2022-07-14 15:15:37 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 0.9347
2022-07-14 15:16:09 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 1.0320
2022-07-14 15:16:43 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 1.2252
2022-07-14 15:17:16 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 0.9232
2022-07-14 15:17:51 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 0.8818
2022-07-14 15:18:23 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 0.9119
2022-07-14 15:18:57 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 0.9949
2022-07-14 15:19:30 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 1.0189
2022-07-14 15:20:03 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 1.1387
2022-07-14 15:20:36 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 1.0103
2022-07-14 15:21:10 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 0.9015
2022-07-14 15:21:44 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 0.8492
2022-07-14 15:22:17 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 1.0780
2022-07-14 15:22:50 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 0.9181
2022-07-14 15:23:23 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 1.0693
2022-07-14 15:23:57 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 1.1124
2022-07-14 15:24:30 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 1.2189
2022-07-14 15:25:04 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 0.8559
2022-07-14 15:25:37 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 0.7674
2022-07-14 15:26:10 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 0.9799
2022-07-14 15:26:43 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 0.9822
2022-07-14 15:27:16 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 1.0974
2022-07-14 15:27:50 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 1.0506
2022-07-14 15:28:23 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 1.0457
2022-07-14 15:28:57 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 0.9644
2022-07-14 15:29:29 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 0.9689
2022-07-14 15:30:03 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 0.9660
2022-07-14 15:30:36 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 0.9389
2022-07-14 15:31:09 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 1.1790
2022-07-14 15:31:43 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 0.9046
2022-07-14 15:32:16 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 0.9364
2022-07-14 15:32:49 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 1.2419
2022-07-14 15:33:23 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 1.1469
2022-07-14 15:33:56 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 1.0995
2022-07-14 15:34:30 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 1.0499
2022-07-14 15:35:02 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 1.0372
2022-07-14 15:35:37 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 0.9163
2022-07-14 15:36:10 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 0.9985
2022-07-14 15:36:44 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 1.1500
2022-07-14 15:37:18 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 1.0425
2022-07-14 15:37:51 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 1.2540
2022-07-14 15:38:24 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 1.0044
2022-07-14 15:38:57 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 0.8551
2022-07-14 15:39:31 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 1.1025
2022-07-14 15:40:05 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 1.0463
2022-07-14 15:40:38 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 1.1805
2022-07-14 15:41:11 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 1.0979
2022-07-14 15:41:44 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 1.3037
2022-07-14 15:42:17 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 1.1435
2022-07-14 15:42:18 - train: epoch 083, train_loss: 1.0216
2022-07-14 15:43:32 - eval: epoch: 083, acc1: 73.664%, acc5: 91.530%, test_loss: 1.0615, per_image_load_time: 1.715ms, per_image_inference_time: 0.303ms
2022-07-14 15:43:32 - until epoch: 083, best_acc1: 73.664%
2022-07-14 15:43:32 - epoch 084 lr: 0.001000
2022-07-14 15:44:11 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 1.0175
2022-07-14 15:44:44 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 1.1327
2022-07-14 15:45:17 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 0.8327
2022-07-14 15:45:51 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 1.0788
2022-07-14 15:46:24 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 1.0044
2022-07-14 15:46:58 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 1.1580
2022-07-14 15:47:31 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 1.0488
2022-07-14 15:48:04 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 1.1483
2022-07-14 15:48:37 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 1.0550
2022-07-14 15:49:10 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 1.0307
2022-07-14 15:49:44 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 0.9549
2022-07-14 15:50:17 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 1.1572
2022-07-14 15:50:50 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 0.9556
2022-07-14 15:51:24 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 1.0655
2022-07-14 15:51:56 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 1.0704
2022-07-14 15:52:31 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 0.9100
2022-07-14 15:53:04 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 1.0909
2022-07-14 15:53:37 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 1.0348
2022-07-14 15:54:11 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 1.1076
2022-07-14 15:54:44 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 1.1149
2022-07-14 15:55:18 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 0.9496
2022-07-14 15:55:51 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 0.8043
2022-07-14 15:56:24 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 1.0325
2022-07-14 15:56:58 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 0.9360
2022-07-14 15:57:31 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 1.1429
2022-07-14 15:58:04 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 1.1338
2022-07-14 15:58:38 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 1.0227
2022-07-14 15:59:11 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 1.1340
2022-07-14 15:59:44 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 1.0058
2022-07-14 16:00:18 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 0.9921
2022-07-14 16:00:50 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 0.8711
2022-07-14 16:01:24 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 0.9394
2022-07-14 16:01:58 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 1.0731
2022-07-14 16:02:32 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 0.9566
2022-07-14 16:03:04 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 0.7733
2022-07-14 16:03:38 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 1.0730
2022-07-14 16:04:11 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 1.0193
2022-07-14 16:04:45 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 1.2040
2022-07-14 16:05:18 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 1.1535
2022-07-14 16:05:51 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 1.0629
2022-07-14 16:06:25 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 1.0851
2022-07-14 16:06:58 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 1.0813
2022-07-14 16:07:31 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 1.0032
2022-07-14 16:08:05 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 1.2460
2022-07-14 16:08:37 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 0.9703
2022-07-14 16:09:11 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 1.0178
2022-07-14 16:09:45 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 1.2821
2022-07-14 16:10:17 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 0.8883
2022-07-14 16:10:51 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 0.9111
2022-07-14 16:11:23 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 1.1386
2022-07-14 16:11:24 - train: epoch 084, train_loss: 1.0183
2022-07-14 16:12:38 - eval: epoch: 084, acc1: 73.576%, acc5: 91.538%, test_loss: 1.0625, per_image_load_time: 2.528ms, per_image_inference_time: 0.311ms
2022-07-14 16:12:39 - until epoch: 084, best_acc1: 73.664%
2022-07-14 16:12:39 - epoch 085 lr: 0.001000
2022-07-14 16:13:18 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 0.9550
2022-07-14 16:13:50 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 0.8350
2022-07-14 16:14:24 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 1.0961
2022-07-14 16:14:58 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 0.9091
2022-07-14 16:15:31 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 1.2483
2022-07-14 16:16:03 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 0.8403
2022-07-14 16:16:36 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 0.8953
2022-07-14 16:17:09 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 0.8696
2022-07-14 16:17:43 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 0.9237
2022-07-14 16:18:16 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 1.0027
2022-07-14 16:18:49 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 1.0349
2022-07-14 16:19:23 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 0.9265
2022-07-14 16:19:56 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 1.0860
2022-07-14 16:20:29 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 1.0792
2022-07-14 16:21:04 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 0.9211
2022-07-14 16:21:36 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 0.9732
2022-07-14 16:22:10 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 1.2463
2022-07-14 16:22:43 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 0.9051
2022-07-14 16:23:17 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 0.9039
2022-07-14 16:23:50 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 0.9383
2022-07-14 16:24:24 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 0.8059
2022-07-14 16:24:57 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 1.0350
2022-07-14 16:25:31 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 0.7865
2022-07-14 16:26:03 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 1.1157
2022-07-14 16:26:36 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 1.2328
2022-07-14 16:27:10 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 1.1367
2022-07-14 16:27:43 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 0.9546
2022-07-14 16:28:17 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 1.0685
2022-07-14 16:28:51 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 1.1573
2022-07-14 16:29:24 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 1.1501
2022-07-14 16:29:57 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 0.9620
2022-07-14 16:30:31 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 0.9606
2022-07-14 16:31:03 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 1.0590
2022-07-14 16:31:37 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 1.1055
2022-07-14 16:32:11 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 1.0534
2022-07-14 16:32:44 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 1.0232
2022-07-14 16:33:17 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 0.8897
2022-07-14 16:33:51 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 1.0367
2022-07-14 16:34:24 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 0.9580
2022-07-14 16:34:58 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 1.3231
2022-07-14 16:35:31 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 1.0194
2022-07-14 16:36:04 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 1.1020
2022-07-14 16:36:37 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 0.9159
2022-07-14 16:37:11 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 0.9162
2022-07-14 16:37:44 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 1.1488
2022-07-14 16:38:17 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 1.0541
2022-07-14 16:38:51 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 1.2602
2022-07-14 16:39:25 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 0.9080
2022-07-14 16:39:58 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 0.9559
2022-07-14 16:40:30 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 0.9829
2022-07-14 16:40:31 - train: epoch 085, train_loss: 1.0178
2022-07-14 16:41:46 - eval: epoch: 085, acc1: 73.640%, acc5: 91.588%, test_loss: 1.0674, per_image_load_time: 2.507ms, per_image_inference_time: 0.298ms
2022-07-14 16:41:46 - until epoch: 085, best_acc1: 73.664%
2022-07-14 16:41:46 - epoch 086 lr: 0.001000
2022-07-14 16:42:25 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 0.9162
2022-07-14 16:42:58 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 0.8788
2022-07-14 16:43:32 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 1.1759
2022-07-14 16:44:05 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 1.0550
2022-07-14 16:44:39 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 1.0029
2022-07-14 16:45:12 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 0.9783
2022-07-14 16:45:46 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 0.9218
2022-07-14 16:46:18 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 1.1404
2022-07-14 16:46:52 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 1.1214
2022-07-14 16:47:25 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 1.0559
2022-07-14 16:47:59 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 1.0547
2022-07-14 16:48:32 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 0.8868
2022-07-14 16:49:05 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 1.0593
2022-07-14 16:49:37 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 0.8853
2022-07-14 16:50:11 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 0.9406
2022-07-14 16:50:44 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 1.1127
2022-07-14 16:51:18 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 0.9368
2022-07-14 16:51:51 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 1.0506
2022-07-14 16:52:24 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 1.1768
2022-07-14 16:52:58 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 1.0729
2022-07-14 16:53:31 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 0.8679
2022-07-14 16:54:05 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 1.0331
2022-07-14 16:54:37 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 0.9811
2022-07-14 16:55:11 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 0.8271
2022-07-14 16:55:45 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 0.9846
2022-07-14 16:56:18 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 1.0191
2022-07-14 16:56:51 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 0.9148
2022-07-14 16:57:25 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 1.1430
2022-07-14 16:57:58 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 0.8794
2022-07-14 16:58:32 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 1.0985
2022-07-14 16:59:05 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 1.0208
2022-07-14 16:59:39 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 1.0568
2022-07-14 17:00:12 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 1.1642
2022-07-14 17:00:46 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 1.0901
2022-07-14 17:01:19 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 1.0287
2022-07-14 17:01:53 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 1.0533
2022-07-14 17:02:27 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 1.1325
2022-07-14 17:03:00 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 0.9912
2022-07-14 17:03:33 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 1.0512
2022-07-14 17:04:06 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 1.0957
2022-07-14 17:04:40 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 0.9834
2022-07-14 17:05:13 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 1.1655
2022-07-14 17:05:47 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 1.0711
2022-07-14 17:06:21 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 0.9825
2022-07-14 17:06:54 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 0.9250
2022-07-14 17:07:28 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 0.9500
2022-07-14 17:08:00 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 1.0560
2022-07-14 17:08:34 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 1.0878
2022-07-14 17:09:08 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 1.0815
2022-07-14 17:09:40 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 1.0528
2022-07-14 17:09:41 - train: epoch 086, train_loss: 1.0127
2022-07-14 17:10:56 - eval: epoch: 086, acc1: 73.576%, acc5: 91.576%, test_loss: 1.0706, per_image_load_time: 2.312ms, per_image_inference_time: 0.307ms
2022-07-14 17:10:56 - until epoch: 086, best_acc1: 73.664%
2022-07-14 17:10:56 - epoch 087 lr: 0.001000
2022-07-14 17:11:34 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 1.0778
2022-07-14 17:12:08 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 0.9463
2022-07-14 17:12:42 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 1.2025
2022-07-14 17:13:14 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 1.1789
2022-07-14 17:13:48 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 0.8304
2022-07-14 17:14:21 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 1.0021
2022-07-14 17:14:54 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 0.7910
2022-07-14 17:15:28 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 1.1734
2022-07-14 17:16:02 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 1.1288
2022-07-14 17:16:35 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 1.0055
2022-07-14 17:17:08 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 1.0351
2022-07-14 17:17:42 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 1.0395
2022-07-14 17:18:15 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 1.1585
2022-07-14 17:18:49 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 1.0449
2022-07-14 17:19:22 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 0.8939
2022-07-14 17:19:56 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 0.8623
2022-07-14 17:20:29 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 1.0844
2022-07-14 17:21:03 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 1.0489
2022-07-14 17:21:36 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 1.0800
2022-07-14 17:22:09 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 1.0539
2022-07-14 17:22:43 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 1.0469
2022-07-14 17:23:16 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 1.0044
2022-07-14 17:23:50 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 1.0622
2022-07-14 17:24:24 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 0.9716
2022-07-14 17:24:57 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 0.9244
2022-07-14 17:25:30 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 1.0385
2022-07-14 17:26:03 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 0.9308
2022-07-14 17:26:38 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 0.8613
2022-07-14 17:27:11 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 0.9483
2022-07-14 17:27:44 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 0.9658
2022-07-14 17:28:17 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 1.0400
2022-07-14 17:28:51 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 0.9399
2022-07-14 17:29:25 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 1.0767
2022-07-14 17:29:57 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 1.0440
2022-07-14 17:30:31 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 0.8884
2022-07-14 17:31:04 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 0.8544
2022-07-14 17:31:38 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 0.9302
2022-07-14 17:32:11 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 0.9578
2022-07-14 17:32:45 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 1.0092
2022-07-14 17:33:18 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 1.0573
2022-07-14 17:33:51 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 1.1194
2022-07-14 17:34:25 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 1.0184
2022-07-14 17:34:58 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 1.0541
2022-07-14 17:35:31 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 1.1114
2022-07-14 17:36:05 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 1.1448
2022-07-14 17:36:38 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 0.9788
2022-07-14 17:37:11 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 1.0180
2022-07-14 17:37:45 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 0.9296
2022-07-14 17:38:18 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 0.9338
2022-07-14 17:38:51 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 1.0278
2022-07-14 17:38:51 - train: epoch 087, train_loss: 1.0104
2022-07-14 17:40:06 - eval: epoch: 087, acc1: 73.646%, acc5: 91.538%, test_loss: 1.0676, per_image_load_time: 2.286ms, per_image_inference_time: 0.309ms
2022-07-14 17:40:06 - until epoch: 087, best_acc1: 73.664%
2022-07-14 17:40:06 - epoch 088 lr: 0.001000
2022-07-14 17:40:44 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 1.0012
2022-07-14 17:41:18 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 0.9738
2022-07-14 17:41:50 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 1.0702
2022-07-14 17:42:24 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 1.0072
2022-07-14 17:42:56 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 0.8742
2022-07-14 17:43:30 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 1.0332
2022-07-14 17:44:04 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 0.9976
2022-07-14 17:44:37 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 1.0095
2022-07-14 17:45:10 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 1.0364
2022-07-14 17:45:43 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 0.9891
2022-07-14 17:46:16 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 0.9913
2022-07-14 17:46:50 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 0.9832
2022-07-14 17:47:24 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 1.1106
2022-07-14 17:47:56 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 0.9452
2022-07-14 17:48:30 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 1.0986
2022-07-14 17:49:03 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 0.8157
2022-07-14 17:49:36 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 1.0007
2022-07-14 17:50:10 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 0.9867
2022-07-14 17:50:43 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 1.0738
2022-07-14 17:51:16 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 0.8542
2022-07-14 17:51:49 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 0.9672
2022-07-14 17:52:23 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 0.9907
2022-07-14 17:52:56 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 0.8229
2022-07-14 17:53:29 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 1.1068
2022-07-14 17:54:03 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 1.0773
2022-07-14 17:54:37 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 1.1654
2022-07-14 17:55:11 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 1.0614
2022-07-14 17:55:43 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 0.9735
2022-07-14 17:56:17 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 1.0003
2022-07-14 17:56:50 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 1.1262
2022-07-14 17:57:23 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 0.9589
2022-07-14 17:57:56 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 0.8939
2022-07-14 17:58:30 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 0.9690
2022-07-14 17:59:03 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 0.8693
2022-07-14 17:59:38 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 0.9471
2022-07-14 18:00:10 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 1.1293
2022-07-14 18:00:43 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 1.0975
2022-07-14 18:01:17 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 1.0175
2022-07-14 18:01:50 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 1.1265
2022-07-14 18:02:24 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 0.8549
2022-07-14 18:02:58 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 1.0088
2022-07-14 18:03:30 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 1.1720
2022-07-14 18:04:05 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 0.9224
2022-07-14 18:04:38 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 1.0039
2022-07-14 18:05:11 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 1.0119
2022-07-14 18:05:44 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 1.1324
2022-07-14 18:06:18 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 1.0059
2022-07-14 18:06:52 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 0.8913
2022-07-14 18:07:26 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 0.8135
2022-07-14 18:07:57 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 1.0515
2022-07-14 18:07:58 - train: epoch 088, train_loss: 1.0078
2022-07-14 18:09:13 - eval: epoch: 088, acc1: 73.698%, acc5: 91.544%, test_loss: 1.0657, per_image_load_time: 2.551ms, per_image_inference_time: 0.301ms
2022-07-14 18:09:13 - until epoch: 088, best_acc1: 73.698%
2022-07-14 18:09:13 - epoch 089 lr: 0.001000
2022-07-14 18:09:52 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 1.2125
2022-07-14 18:10:25 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 0.8374
2022-07-14 18:10:58 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 0.9798
2022-07-14 18:11:32 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 0.9640
2022-07-14 18:12:04 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 0.9779
2022-07-14 18:12:38 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 0.9520
2022-07-14 18:13:11 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 1.1583
2022-07-14 18:13:43 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 1.1289
2022-07-14 18:14:16 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 1.0631
2022-07-14 18:14:50 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 1.1680
2022-07-14 18:15:23 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 0.9910
2022-07-14 18:15:55 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 1.0900
2022-07-14 18:16:29 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 0.9981
2022-07-14 18:17:02 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 1.0266
2022-07-14 18:17:35 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 0.9425
2022-07-14 18:18:09 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 0.9406
2022-07-14 18:18:43 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 1.0673
2022-07-14 18:19:16 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 1.0477
2022-07-14 18:19:49 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 0.9175
2022-07-14 18:20:22 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 1.0257
2022-07-14 18:20:56 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 1.1029
2022-07-14 18:21:28 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 1.0044
2022-07-14 18:22:03 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 0.8933
2022-07-14 18:22:36 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 1.0059
2022-07-14 18:23:09 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 0.9881
2022-07-14 18:23:43 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 1.0405
2022-07-14 18:24:16 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 0.8831
2022-07-14 18:24:49 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 1.0240
2022-07-14 18:25:22 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 0.9815
2022-07-14 18:25:56 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 1.0467
2022-07-14 18:26:29 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 1.0702
2022-07-14 18:27:02 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 1.0517
2022-07-14 18:27:36 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 1.0752
2022-07-14 18:28:10 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 1.0377
2022-07-14 18:28:43 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 0.8035
2022-07-14 18:29:16 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 0.9278
2022-07-14 18:29:49 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 1.1666
2022-07-14 18:30:23 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 0.9228
2022-07-14 18:30:57 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 1.0996
2022-07-14 18:31:31 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 0.8697
2022-07-14 18:32:04 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 1.2475
2022-07-14 18:32:37 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 0.9846
2022-07-14 18:33:11 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 0.9873
2022-07-14 18:33:43 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 0.9708
2022-07-14 18:34:17 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 0.8486
2022-07-14 18:34:51 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 1.0000
2022-07-14 18:35:24 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 1.0712
2022-07-14 18:35:57 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 1.0281
2022-07-14 18:36:31 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 0.9614
2022-07-14 18:37:03 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 0.7659
2022-07-14 18:37:04 - train: epoch 089, train_loss: 1.0078
2022-07-14 18:38:18 - eval: epoch: 089, acc1: 73.570%, acc5: 91.572%, test_loss: 1.0657, per_image_load_time: 2.523ms, per_image_inference_time: 0.287ms
2022-07-14 18:38:18 - until epoch: 089, best_acc1: 73.698%
2022-07-14 18:38:18 - epoch 090 lr: 0.001000
2022-07-14 18:38:57 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 1.1109
2022-07-14 18:39:30 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 0.9934
2022-07-14 18:40:03 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 0.8733
2022-07-14 18:40:36 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 0.9590
2022-07-14 18:41:09 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 1.0526
2022-07-14 18:41:42 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 1.1253
2022-07-14 18:42:16 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 0.9856
2022-07-14 18:42:49 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 0.9919
2022-07-14 18:43:23 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 0.9539
2022-07-14 18:43:56 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 0.8860
2022-07-14 18:44:29 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 1.0577
2022-07-14 18:45:01 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 0.9592
2022-07-14 18:45:35 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 1.1864
2022-07-14 18:46:07 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 0.8671
2022-07-14 18:46:40 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 1.1774
2022-07-14 18:47:14 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 0.9501
2022-07-14 18:47:47 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 0.8865
2022-07-14 18:48:19 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 0.8504
2022-07-14 18:48:52 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 0.9066
2022-07-14 18:49:27 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 1.0616
2022-07-14 18:49:59 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 1.1398
2022-07-14 18:50:32 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 1.0758
2022-07-14 18:51:05 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 1.1683
2022-07-14 18:51:38 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 0.9888
2022-07-14 18:52:12 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 1.0822
2022-07-14 18:52:45 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 1.0619
2022-07-14 18:53:18 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 0.9405
2022-07-14 18:53:51 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 1.0162
2022-07-14 18:54:24 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 0.9602
2022-07-14 18:54:57 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 1.0199
2022-07-14 18:55:31 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 0.8434
2022-07-14 18:56:05 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 0.9611
2022-07-14 18:56:37 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 1.1052
2022-07-14 18:57:11 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 0.8596
2022-07-14 18:57:44 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 0.9099
2022-07-14 18:58:18 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 0.9306
2022-07-14 18:58:51 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 1.0565
2022-07-14 18:59:24 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 0.9968
2022-07-14 18:59:57 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 0.8158
2022-07-14 19:00:31 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 1.0550
2022-07-14 19:01:05 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 1.2264
2022-07-14 19:01:38 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 1.0615
2022-07-14 19:02:12 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 1.0790
2022-07-14 19:02:45 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 0.9781
2022-07-14 19:03:18 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 0.9576
2022-07-14 19:03:51 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 0.9577
2022-07-14 19:04:25 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 0.8873
2022-07-14 19:04:58 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 1.0578
2022-07-14 19:05:32 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 0.9512
2022-07-14 19:06:04 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 1.0124
2022-07-14 19:06:05 - train: epoch 090, train_loss: 1.0045
2022-07-14 19:07:20 - eval: epoch: 090, acc1: 73.496%, acc5: 91.434%, test_loss: 1.0692, per_image_load_time: 2.622ms, per_image_inference_time: 0.296ms
2022-07-14 19:07:20 - until epoch: 090, best_acc1: 73.698%
2022-07-14 19:07:20 - epoch 091 lr: 0.000100
2022-07-14 19:07:58 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 0.9140
2022-07-14 19:08:31 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 0.9283
2022-07-14 19:09:06 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 0.9849
2022-07-14 19:09:39 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 0.9075
2022-07-14 19:10:12 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 0.9773
2022-07-14 19:10:45 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 0.9441
2022-07-14 19:11:18 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 0.9339
2022-07-14 19:11:51 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 0.8471
2022-07-14 19:12:25 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 1.0469
2022-07-14 19:12:58 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 0.9591
2022-07-14 19:13:31 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 0.8270
2022-07-14 19:14:04 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 1.0635
2022-07-14 19:14:38 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 0.9151
2022-07-14 19:15:11 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 1.0107
2022-07-14 19:15:44 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 0.9292
2022-07-14 19:16:18 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 1.0421
2022-07-14 19:16:51 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 1.0219
2022-07-14 19:17:25 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 0.9668
2022-07-14 19:17:58 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 0.8652
2022-07-14 19:18:31 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 0.9348
2022-07-14 19:19:04 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 0.7528
2022-07-14 19:19:37 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 1.0517
2022-07-14 19:20:11 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 1.1008
2022-07-14 19:20:44 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 0.9130
2022-07-14 19:21:18 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 0.9838
2022-07-14 19:21:51 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 0.8431
2022-07-14 19:22:24 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 0.8852
2022-07-14 19:22:57 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 0.9647
2022-07-14 19:23:31 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 1.1230
2022-07-14 19:24:04 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 1.0266
2022-07-14 19:24:37 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 0.8991
2022-07-14 19:25:10 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 1.0232
2022-07-14 19:25:43 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 0.8788
2022-07-14 19:26:17 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 0.8749
2022-07-14 19:26:50 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 1.0571
2022-07-14 19:27:23 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 0.8958
2022-07-14 19:27:57 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 1.0017
2022-07-14 19:28:30 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 0.9790
2022-07-14 19:29:03 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 0.9838
2022-07-14 19:29:37 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 1.0374
2022-07-14 19:30:10 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 1.0373
2022-07-14 19:30:43 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 1.0369
2022-07-14 19:31:16 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 1.0508
2022-07-14 19:31:50 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 0.8554
2022-07-14 19:32:23 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 0.9003
2022-07-14 19:32:56 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 0.9731
2022-07-14 19:33:30 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 0.9378
2022-07-14 19:34:03 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 1.0567
2022-07-14 19:34:37 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 0.8904
2022-07-14 19:35:08 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 1.1144
2022-07-14 19:35:09 - train: epoch 091, train_loss: 0.9741
2022-07-14 19:36:24 - eval: epoch: 091, acc1: 73.854%, acc5: 91.698%, test_loss: 1.0510, per_image_load_time: 2.585ms, per_image_inference_time: 0.320ms
2022-07-14 19:36:25 - until epoch: 091, best_acc1: 73.854%
2022-07-14 19:36:25 - epoch 092 lr: 0.000100
2022-07-14 19:37:03 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 0.9831
2022-07-14 19:37:37 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 1.0371
2022-07-14 19:38:10 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 0.9148
2022-07-14 19:38:44 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 0.7646
2022-07-14 19:39:17 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 1.1122
2022-07-14 19:39:50 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 1.0171
2022-07-14 19:40:23 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 0.9588
2022-07-14 19:40:57 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 1.0140
2022-07-14 19:41:30 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 0.9744
2022-07-14 19:42:03 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 1.1838
2022-07-14 19:42:36 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 0.8743
2022-07-14 19:43:10 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 0.8699
2022-07-14 19:43:43 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 0.9272
2022-07-14 19:44:17 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 0.8973
2022-07-14 19:44:50 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 0.8707
2022-07-14 19:45:24 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 0.9841
2022-07-14 19:45:57 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 1.0728
2022-07-14 19:46:31 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 0.9175
2022-07-14 19:47:04 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 0.8452
2022-07-14 19:47:39 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 0.8647
2022-07-14 19:48:11 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 0.9514
2022-07-14 19:48:44 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 0.9839
2022-07-14 19:49:18 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 0.9742
2022-07-14 19:49:52 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 0.8812
2022-07-14 19:50:24 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 0.9291
2022-07-14 19:50:59 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 1.1000
2022-07-14 19:51:32 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 1.0121
2022-07-14 19:52:07 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 0.8911
2022-07-14 19:52:40 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 0.9485
2022-07-14 19:53:14 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 0.9494
2022-07-14 19:53:46 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 0.9820
2022-07-14 19:54:21 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 0.7555
2022-07-14 19:54:54 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 0.9772
2022-07-14 19:55:28 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 1.1470
2022-07-14 19:56:00 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 0.8177
2022-07-14 19:56:33 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 0.9054
2022-07-14 19:57:07 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 0.8425
2022-07-14 19:57:41 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 1.1683
2022-07-14 19:58:14 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 0.9635
2022-07-14 19:58:48 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 1.0925
2022-07-14 19:59:21 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 0.8289
2022-07-14 19:59:55 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 0.8863
2022-07-14 20:00:29 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 0.9944
2022-07-14 20:01:02 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 0.8425
2022-07-14 20:01:35 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 0.8997
2022-07-14 20:02:09 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 0.8913
2022-07-14 20:02:41 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 0.6722
2022-07-14 20:03:15 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 0.8640
2022-07-14 20:03:48 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 0.9752
2022-07-14 20:04:20 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 1.1126
2022-07-14 20:04:21 - train: epoch 092, train_loss: 0.9661
2022-07-14 20:05:35 - eval: epoch: 092, acc1: 73.854%, acc5: 91.696%, test_loss: 1.0508, per_image_load_time: 2.550ms, per_image_inference_time: 0.313ms
2022-07-14 20:05:36 - until epoch: 092, best_acc1: 73.854%
2022-07-14 20:05:36 - epoch 093 lr: 0.000100
2022-07-14 20:06:14 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 0.8964
2022-07-14 20:06:47 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 0.8709
2022-07-14 20:07:21 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 0.9039
2022-07-14 20:07:54 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 0.9253
2022-07-14 20:08:28 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 1.0892
2022-07-14 20:09:01 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 0.9266
2022-07-14 20:09:35 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 0.9991
2022-07-14 20:10:07 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 0.8777
2022-07-14 20:10:41 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 0.8942
2022-07-14 20:11:14 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.8619
2022-07-14 20:11:47 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 0.9272
2022-07-14 20:12:21 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 0.8177
2022-07-14 20:12:54 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 0.9535
2022-07-14 20:13:27 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 0.9925
2022-07-14 20:14:00 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 1.1998
2022-07-14 20:14:33 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 1.0387
2022-07-14 20:15:07 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 0.8895
2022-07-14 20:15:39 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 1.0409
2022-07-14 20:16:13 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 0.9584
2022-07-14 20:16:45 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 0.8336
2022-07-14 20:17:19 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 0.8710
2022-07-14 20:17:52 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 1.0793
2022-07-14 20:18:26 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 0.9199
2022-07-14 20:18:59 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 0.8848
2022-07-14 20:19:33 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 0.9630
2022-07-14 20:20:06 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 1.1233
2022-07-14 20:20:40 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 0.8380
2022-07-14 20:21:13 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 0.8933
2022-07-14 20:21:47 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 0.9412
2022-07-14 20:22:19 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 0.9097
2022-07-14 20:22:54 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 1.1467
2022-07-14 20:23:26 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 0.8826
2022-07-14 20:24:00 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 1.0446
2022-07-14 20:24:34 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 1.1718
2022-07-14 20:25:07 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 0.6961
2022-07-14 20:25:40 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 1.0279
2022-07-14 20:26:14 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 0.8291
2022-07-14 20:26:47 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 0.8278
2022-07-14 20:27:20 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 1.0348
2022-07-14 20:27:54 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 1.2312
2022-07-14 20:28:27 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 1.0871
2022-07-14 20:29:00 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 1.0292
2022-07-14 20:29:34 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 1.0995
2022-07-14 20:30:07 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 0.9636
2022-07-14 20:30:40 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 0.9679
2022-07-14 20:31:14 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 0.8147
2022-07-14 20:31:48 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 1.1517
2022-07-14 20:32:21 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 1.0365
2022-07-14 20:32:55 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 1.0923
2022-07-14 20:33:27 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 0.9414
2022-07-14 20:33:28 - train: epoch 093, train_loss: 0.9627
2022-07-14 20:34:43 - eval: epoch: 093, acc1: 73.960%, acc5: 91.672%, test_loss: 1.0477, per_image_load_time: 2.546ms, per_image_inference_time: 0.299ms
2022-07-14 20:34:43 - until epoch: 093, best_acc1: 73.960%
2022-07-14 20:34:43 - epoch 094 lr: 0.000100
2022-07-14 20:35:21 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 0.9338
2022-07-14 20:35:55 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 1.0150
2022-07-14 20:36:28 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 1.0168
2022-07-14 20:37:02 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 1.1094
2022-07-14 20:37:36 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 0.8234
2022-07-14 20:38:10 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 0.8571
2022-07-14 20:38:43 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 1.0226
2022-07-14 20:39:16 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 0.8725
2022-07-14 20:39:48 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 0.8966
2022-07-14 20:40:22 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 0.9607
2022-07-14 20:40:54 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 0.9996
2022-07-14 20:41:28 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 0.9827
2022-07-14 20:42:02 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 1.0237
2022-07-14 20:42:34 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 0.8826
2022-07-14 20:43:07 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 1.0831
2022-07-14 20:43:40 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 1.2802
2022-07-14 20:44:14 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 0.9377
2022-07-14 20:44:48 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 0.9414
2022-07-14 20:45:21 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 1.0126
2022-07-14 20:45:54 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 0.7653
2022-07-14 20:46:27 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 1.0362
2022-07-14 20:47:01 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 0.7901
2022-07-14 20:47:33 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 0.8538
2022-07-14 20:48:07 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 0.9196
2022-07-14 20:48:40 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 0.9122
2022-07-14 20:49:14 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 0.7937
2022-07-14 20:49:47 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 0.8771
2022-07-14 20:50:21 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 0.9541
2022-07-14 20:50:53 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 0.9408
2022-07-14 20:51:26 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 0.9137
2022-07-14 20:52:00 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 1.1339
2022-07-14 20:52:32 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 0.9641
2022-07-14 20:53:06 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 0.9081
2022-07-14 20:53:39 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 1.0295
2022-07-14 20:54:14 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 1.0614
2022-07-14 20:54:47 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 0.9758
2022-07-14 20:55:20 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 1.1524
2022-07-14 20:55:53 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 0.8796
2022-07-14 20:56:27 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 0.9054
2022-07-14 20:57:00 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 1.0926
2022-07-14 20:57:34 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 1.1242
2022-07-14 20:58:07 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 0.7903
2022-07-14 20:58:41 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 1.0752
2022-07-14 20:59:14 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 1.0813
2022-07-14 20:59:48 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 0.9872
2022-07-14 21:00:21 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 1.0412
2022-07-14 21:00:55 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 0.9463
2022-07-14 21:01:28 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 0.9453
2022-07-14 21:02:02 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 0.9127
2022-07-14 21:02:34 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 0.7985
2022-07-14 21:02:35 - train: epoch 094, train_loss: 0.9615
2022-07-14 21:03:50 - eval: epoch: 094, acc1: 73.950%, acc5: 91.690%, test_loss: 1.0479, per_image_load_time: 2.552ms, per_image_inference_time: 0.298ms
2022-07-14 21:03:50 - until epoch: 094, best_acc1: 73.960%
2022-07-14 21:03:50 - epoch 095 lr: 0.000100
2022-07-14 21:04:29 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 0.8928
2022-07-14 21:05:03 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 1.0792
2022-07-14 21:05:36 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 0.8949
2022-07-14 21:06:10 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 0.9773
2022-07-14 21:06:43 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 1.0016
2022-07-14 21:07:16 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 0.9433
2022-07-14 21:07:48 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 1.0866
2022-07-14 21:08:23 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 1.0695
2022-07-14 21:08:56 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 1.1547
2022-07-14 21:09:29 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 1.0598
2022-07-14 21:10:02 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 0.7895
2022-07-14 21:10:35 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 0.8625
2022-07-14 21:11:08 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 0.8963
2022-07-14 21:11:42 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 1.0711
2022-07-14 21:12:15 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 1.0284
2022-07-14 21:12:48 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.6583
2022-07-14 21:13:22 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 0.9852
2022-07-14 21:13:54 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 1.0138
2022-07-14 21:14:27 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 0.9457
2022-07-14 21:15:00 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 0.9425
2022-07-14 21:15:34 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 0.8751
2022-07-14 21:16:08 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 0.7393
2022-07-14 21:16:42 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 0.9842
2022-07-14 21:17:15 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 1.0122
2022-07-14 21:17:49 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 0.8837
2022-07-14 21:18:22 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 0.9342
2022-07-14 21:18:55 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 1.0022
2022-07-14 21:19:29 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 0.8633
2022-07-14 21:20:03 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 0.8317
2022-07-14 21:20:35 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 1.0327
2022-07-14 21:21:10 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 1.1529
2022-07-14 21:21:42 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 0.9612
2022-07-14 21:22:16 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 1.0707
2022-07-14 21:22:50 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 0.9000
2022-07-14 21:23:23 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 0.8568
2022-07-14 21:23:56 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 0.9383
2022-07-14 21:24:30 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 0.8746
2022-07-14 21:25:03 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 0.7746
2022-07-14 21:25:37 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 0.9796
2022-07-14 21:26:10 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 0.7751
2022-07-14 21:26:43 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 0.9777
2022-07-14 21:27:16 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 0.7956
2022-07-14 21:27:50 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 1.0045
2022-07-14 21:28:23 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 0.9653
2022-07-14 21:28:57 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 0.8322
2022-07-14 21:29:29 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 0.9946
2022-07-14 21:30:03 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 0.8932
2022-07-14 21:30:37 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 1.0147
2022-07-14 21:31:10 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 0.9190
2022-07-14 21:31:42 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 0.7845
2022-07-14 21:31:43 - train: epoch 095, train_loss: 0.9612
2022-07-14 21:32:57 - eval: epoch: 095, acc1: 73.928%, acc5: 91.694%, test_loss: 1.0483, per_image_load_time: 2.205ms, per_image_inference_time: 0.309ms
2022-07-14 21:32:57 - until epoch: 095, best_acc1: 73.960%
2022-07-14 21:32:57 - epoch 096 lr: 0.000100
2022-07-14 21:33:35 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 0.9498
2022-07-14 21:34:09 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 1.0293
2022-07-14 21:34:42 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 1.0471
2022-07-14 21:35:15 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 0.8018
2022-07-14 21:35:49 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 0.9088
2022-07-14 21:36:22 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 1.0353
2022-07-14 21:36:56 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 0.8426
2022-07-14 21:37:30 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 0.9606
2022-07-14 21:38:02 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 0.8536
2022-07-14 21:38:36 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 0.9238
2022-07-14 21:39:09 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 0.9807
2022-07-14 21:39:43 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 0.9425
2022-07-14 21:40:16 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 1.0105
2022-07-14 21:40:50 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 0.9677
2022-07-14 21:41:23 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 0.8058
2022-07-14 21:41:56 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 0.7631
2022-07-14 21:42:30 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 1.0013
2022-07-14 21:43:03 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 1.0375
2022-07-14 21:43:37 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 1.0390
2022-07-14 21:44:09 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 0.8757
2022-07-14 21:44:43 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 0.9894
2022-07-14 21:45:17 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.8265
2022-07-14 21:45:50 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 0.8960
2022-07-14 21:46:24 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 0.8497
2022-07-14 21:46:57 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 0.8961
2022-07-14 21:47:31 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 0.9412
2022-07-14 21:48:04 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 0.9428
2022-07-14 21:48:38 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 1.0683
2022-07-14 21:49:12 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 0.9785
2022-07-14 21:49:45 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 0.9169
2022-07-14 21:50:19 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 0.9710
2022-07-14 21:50:52 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 0.9370
2022-07-14 21:51:26 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 1.0918
2022-07-14 21:51:59 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 0.7388
2022-07-14 21:52:32 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 0.8515
2022-07-14 21:53:07 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 0.8485
2022-07-14 21:53:39 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 1.0222
2022-07-14 21:54:12 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 0.9798
2022-07-14 21:54:46 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 0.7794
2022-07-14 21:55:20 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 0.7794
2022-07-14 21:55:54 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 0.8950
2022-07-14 21:56:26 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 1.0026
2022-07-14 21:57:00 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.7058
2022-07-14 21:57:33 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 0.9626
2022-07-14 21:58:08 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 0.9205
2022-07-14 21:58:39 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 0.9563
2022-07-14 21:59:14 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 0.8941
2022-07-14 21:59:48 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 1.0590
2022-07-14 22:00:21 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 1.1523
2022-07-14 22:00:53 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 0.9004
2022-07-14 22:00:54 - train: epoch 096, train_loss: 0.9574
2022-07-14 22:02:08 - eval: epoch: 096, acc1: 73.984%, acc5: 91.708%, test_loss: 1.0472, per_image_load_time: 2.524ms, per_image_inference_time: 0.291ms
2022-07-14 22:02:09 - until epoch: 096, best_acc1: 73.984%
2022-07-14 22:02:09 - epoch 097 lr: 0.000100
2022-07-14 22:02:48 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 1.0408
2022-07-14 22:03:21 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 0.7486
2022-07-14 22:03:54 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 1.0047
2022-07-14 22:04:28 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 1.2569
2022-07-14 22:05:01 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 0.9825
2022-07-14 22:05:35 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 1.1230
2022-07-14 22:06:08 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 0.9595
2022-07-14 22:06:41 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.7936
2022-07-14 22:07:15 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 0.7840
2022-07-14 22:07:48 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 0.8927
2022-07-14 22:08:21 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 0.8405
2022-07-14 22:08:54 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 0.9060
2022-07-14 22:09:28 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 0.8599
2022-07-14 22:10:02 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 0.9017
2022-07-14 22:10:34 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 0.9847
2022-07-14 22:11:09 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 0.9408
2022-07-14 22:11:41 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 0.8954
2022-07-14 22:12:15 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 1.0150
2022-07-14 22:12:48 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 1.0218
2022-07-14 22:13:21 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 0.8704
2022-07-14 22:13:54 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 0.9769
2022-07-14 22:14:28 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 1.0950
2022-07-14 22:15:01 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 0.8397
2022-07-14 22:15:34 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 1.0143
2022-07-14 22:16:07 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 0.9906
2022-07-14 22:16:41 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 1.0849
2022-07-14 22:17:14 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 0.8315
2022-07-14 22:17:47 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 0.8451
2022-07-14 22:18:21 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 1.0984
2022-07-14 22:18:53 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 1.0113
2022-07-14 22:19:27 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 0.8836
2022-07-14 22:20:01 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 1.0186
2022-07-14 22:20:34 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 1.0818
2022-07-14 22:21:07 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 1.0642
2022-07-14 22:21:40 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 1.0312
2022-07-14 22:22:15 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 0.9815
2022-07-14 22:22:48 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 0.7890
2022-07-14 22:23:22 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 0.8225
2022-07-14 22:23:54 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 0.9330
2022-07-14 22:24:27 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 1.0020
2022-07-14 22:25:01 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 0.9426
2022-07-14 22:25:34 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 0.9613
2022-07-14 22:26:08 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 0.8113
2022-07-14 22:26:41 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 0.9552
2022-07-14 22:27:15 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 0.9856
2022-07-14 22:27:48 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 1.0389
2022-07-14 22:28:22 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 0.9135
2022-07-14 22:28:55 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 0.9097
2022-07-14 22:29:29 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 1.1571
2022-07-14 22:30:01 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 0.9590
2022-07-14 22:30:02 - train: epoch 097, train_loss: 0.9579
2022-07-14 22:31:17 - eval: epoch: 097, acc1: 74.028%, acc5: 91.708%, test_loss: 1.0460, per_image_load_time: 2.573ms, per_image_inference_time: 0.309ms
2022-07-14 22:31:17 - until epoch: 097, best_acc1: 74.028%
2022-07-14 22:31:17 - epoch 098 lr: 0.000100
2022-07-14 22:31:56 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 0.9711
2022-07-14 22:32:30 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 1.0603
2022-07-14 22:33:04 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 1.1742
2022-07-14 22:33:37 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 0.8744
2022-07-14 22:34:10 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 0.9295
2022-07-14 22:34:43 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 1.0133
2022-07-14 22:35:17 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 0.9366
2022-07-14 22:35:49 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 0.9623
2022-07-14 22:36:23 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 0.9509
2022-07-14 22:36:57 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 0.8371
2022-07-14 22:37:31 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 0.7961
2022-07-14 22:38:03 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 0.8815
2022-07-14 22:38:36 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 1.0029
2022-07-14 22:39:09 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 0.9722
2022-07-14 22:39:43 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 0.9348
2022-07-14 22:40:16 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 0.9816
2022-07-14 22:40:51 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 0.9771
2022-07-14 22:41:23 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 0.9286
2022-07-14 22:41:58 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 0.8921
2022-07-14 22:42:30 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 1.0091
2022-07-14 22:43:04 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 0.8608
2022-07-14 22:43:37 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 0.9535
2022-07-14 22:44:10 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 0.9150
2022-07-14 22:44:44 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 0.9664
2022-07-14 22:45:18 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 1.1068
2022-07-14 22:45:51 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 0.9034
2022-07-14 22:46:24 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 0.9751
2022-07-14 22:46:57 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 0.8837
2022-07-14 22:47:31 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 0.9712
2022-07-14 22:48:05 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 0.8861
2022-07-14 22:48:38 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 0.9095
2022-07-14 22:49:12 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 0.8326
2022-07-14 22:49:45 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 0.7816
2022-07-14 22:50:18 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 0.9441
2022-07-14 22:50:51 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 0.9183
2022-07-14 22:51:24 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 1.2026
2022-07-14 22:51:58 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 0.9866
2022-07-14 22:52:31 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 0.9887
2022-07-14 22:53:04 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 0.8529
2022-07-14 22:53:38 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 1.0532
2022-07-14 22:54:11 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 1.0905
2022-07-14 22:54:45 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 0.9039
2022-07-14 22:55:19 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 0.8469
2022-07-14 22:55:52 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 1.1078
2022-07-14 22:56:26 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 1.0899
2022-07-14 22:57:00 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 1.0562
2022-07-14 22:57:32 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 0.9628
2022-07-14 22:58:05 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 0.7261
2022-07-14 22:58:39 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 0.9806
2022-07-14 22:59:11 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 1.0492
2022-07-14 22:59:12 - train: epoch 098, train_loss: 0.9549
2022-07-14 23:00:27 - eval: epoch: 098, acc1: 73.958%, acc5: 91.692%, test_loss: 1.0460, per_image_load_time: 2.580ms, per_image_inference_time: 0.297ms
2022-07-14 23:00:27 - until epoch: 098, best_acc1: 74.028%
2022-07-14 23:00:27 - epoch 099 lr: 0.000100
2022-07-14 23:01:05 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 0.7945
2022-07-14 23:01:39 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 0.8252
2022-07-14 23:02:11 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 0.9581
2022-07-14 23:02:46 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 1.0780
2022-07-14 23:03:20 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 1.0506
2022-07-14 23:03:52 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 0.9031
2022-07-14 23:04:26 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 0.9437
2022-07-14 23:04:59 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 0.9869
2022-07-14 23:05:31 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 0.8952
2022-07-14 23:06:05 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 1.0216
2022-07-14 23:06:39 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 0.9415
2022-07-14 23:07:12 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 0.8554
2022-07-14 23:07:46 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 1.0127
2022-07-14 23:08:19 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 1.0318
2022-07-14 23:08:53 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 0.8220
2022-07-14 23:09:25 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 1.1779
2022-07-14 23:09:59 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 0.9121
2022-07-14 23:10:32 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 0.9354
2022-07-14 23:11:06 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 1.0284
2022-07-14 23:11:39 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 0.8429
2022-07-14 23:12:13 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 0.8109
2022-07-14 23:12:47 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 0.9692
2022-07-14 23:13:20 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 0.9862
2022-07-14 23:13:53 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 1.1145
2022-07-14 23:14:26 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 0.8962
2022-07-14 23:15:01 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 0.8633
2022-07-14 23:15:34 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 0.9953
2022-07-14 23:16:08 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 1.0983
2022-07-14 23:16:41 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 0.9085
2022-07-14 23:17:14 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 1.0226
2022-07-14 23:17:48 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 0.9188
2022-07-14 23:18:21 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 1.0491
2022-07-14 23:18:55 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 0.8728
2022-07-14 23:19:28 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 1.0038
2022-07-14 23:20:02 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 1.0315
2022-07-14 23:20:35 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 0.8573
2022-07-14 23:21:09 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 0.7833
2022-07-14 23:21:42 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 1.1057
2022-07-14 23:22:16 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 0.9791
2022-07-14 23:22:49 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 1.0975
2022-07-14 23:23:24 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 0.8176
2022-07-14 23:23:57 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 0.9388
2022-07-14 23:24:31 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 0.9749
2022-07-14 23:25:04 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 0.9849
