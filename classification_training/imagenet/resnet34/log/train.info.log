2022-07-03 18:07:54 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 1.2385
2022-07-03 18:08:27 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 1.3806
2022-07-03 18:09:00 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 1.3148
2022-07-03 18:09:33 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 1.5592
2022-07-03 18:10:06 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 1.4482
2022-07-03 18:10:39 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 1.4513
2022-07-03 18:11:13 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 1.5152
2022-07-03 18:11:46 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 1.2235
2022-07-03 18:12:18 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 1.5006
2022-07-03 18:12:52 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 1.2591
2022-07-03 18:13:24 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 1.3372
2022-07-03 18:13:58 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 1.3963
2022-07-03 18:14:31 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 1.3951
2022-07-03 18:15:04 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 1.3866
2022-07-03 18:15:38 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 1.3190
2022-07-03 18:16:12 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 1.2259
2022-07-03 18:16:44 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 1.1277
2022-07-03 18:17:17 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 1.4077
2022-07-03 18:17:51 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 1.5936
2022-07-03 18:18:22 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 1.5369
2022-07-03 18:18:57 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 1.4130
2022-07-03 18:19:30 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 1.2527
2022-07-03 18:20:03 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 1.3868
2022-07-03 18:20:37 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 1.5004
2022-07-03 18:21:10 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 1.4594
2022-07-03 18:21:43 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 1.4269
2022-07-03 18:22:16 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 1.4233
2022-07-03 18:22:49 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 1.5130
2022-07-03 18:23:22 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 1.3385
2022-07-03 18:23:55 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 1.2871
2022-07-03 18:24:29 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 1.3151
2022-07-03 18:25:02 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 1.2721
2022-07-03 18:25:36 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 1.4918
2022-07-03 18:26:09 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 1.4855
2022-07-03 18:26:41 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 1.2224
2022-07-03 18:27:15 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 1.5405
2022-07-03 18:27:49 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 1.6320
2022-07-03 18:28:22 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 1.5198
2022-07-03 18:28:53 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 1.4578
2022-07-03 18:28:54 - train: epoch 057, train_loss: 1.3793
2022-07-03 18:30:08 - eval: epoch: 057, acc1: 68.370%, acc5: 88.726%, test_loss: 1.2864, per_image_load_time: 2.205ms, per_image_inference_time: 0.272ms
2022-07-03 18:30:09 - until epoch: 057, best_acc1: 69.192%
2022-07-03 18:30:09 - epoch 058 lr: 0.010000
2022-07-03 18:30:46 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 1.2868
2022-07-03 18:31:19 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 1.2481
2022-07-03 18:31:52 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 1.3435
2022-07-03 18:32:25 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 1.1622
2022-07-03 18:32:57 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 1.2036
2022-07-03 18:33:31 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 1.6340
2022-07-03 18:34:04 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 1.3622
2022-07-03 18:34:36 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 1.3511
2022-07-03 18:35:09 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 1.2609
2022-07-03 18:35:42 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 1.1944
2022-07-03 18:36:15 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 1.1008
2022-07-03 18:36:48 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 1.4355
2022-07-03 18:37:22 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 1.5067
2022-07-03 18:37:54 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 1.4720
2022-07-03 18:38:28 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 1.4066
2022-07-03 18:39:00 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 1.4916
2022-07-03 18:39:34 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 1.4601
2022-07-03 18:40:06 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 1.6426
2022-07-03 18:40:40 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 1.4764
2022-07-03 18:41:12 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 1.5136
2022-07-03 18:41:46 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 1.3583
2022-07-03 18:42:19 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 1.2795
2022-07-03 18:42:53 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 1.3767
2022-07-03 18:43:26 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 1.5293
2022-07-03 18:43:59 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 1.4833
2022-07-03 18:44:31 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 1.4239
2022-07-03 18:45:05 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 1.6349
2022-07-03 18:45:38 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 1.3190
2022-07-03 18:46:11 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 1.1835
2022-07-03 18:46:44 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 1.4576
2022-07-03 18:47:17 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 1.3032
2022-07-03 18:47:51 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 1.1868
2022-07-03 18:48:24 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 1.2242
2022-07-03 18:48:57 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 1.4492
2022-07-03 18:49:30 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 1.3816
2022-07-03 18:50:03 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 1.3220
2022-07-03 18:50:36 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 1.4811
2022-07-03 18:51:10 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 1.2846
2022-07-03 18:51:43 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 1.2336
2022-07-03 18:52:16 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 1.4702
2022-07-03 18:52:50 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 1.3939
2022-07-03 18:53:22 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 1.3675
2022-07-03 18:53:56 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 1.4858
2022-07-03 18:54:30 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 1.3072
2022-07-03 18:55:03 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 1.2688
2022-07-03 18:55:38 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 1.3285
2022-07-03 18:56:10 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 1.5074
2022-07-03 18:56:43 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 1.3484
2022-07-03 18:57:17 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 1.3196
2022-07-03 18:57:48 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 1.2781
2022-07-03 18:57:49 - train: epoch 058, train_loss: 1.3787
2022-07-03 18:59:03 - eval: epoch: 058, acc1: 68.480%, acc5: 88.662%, test_loss: 1.2795, per_image_load_time: 2.097ms, per_image_inference_time: 0.266ms
2022-07-03 18:59:03 - until epoch: 058, best_acc1: 69.192%
2022-07-03 18:59:03 - epoch 059 lr: 0.010000
2022-07-03 18:59:42 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 1.3753
2022-07-03 19:00:15 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 1.2993
2022-07-03 19:00:47 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 1.2358
2022-07-03 19:01:20 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 1.5740
2022-07-03 19:01:54 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 1.2859
2022-07-03 19:02:25 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 1.2228
2022-07-03 19:02:58 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 1.2900
2022-07-03 19:03:32 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 1.3998
2022-07-03 19:04:04 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 1.3930
2022-07-03 19:04:38 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 1.4559
2022-07-03 19:05:11 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 1.6593
2022-07-03 19:05:44 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 1.3039
2022-07-03 19:06:17 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 1.5775
2022-07-03 19:06:51 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 1.5078
2022-07-03 19:07:23 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 1.4475
2022-07-03 19:07:57 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 1.2515
2022-07-03 19:08:30 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 1.2145
2022-07-03 19:09:03 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 1.2664
2022-07-03 19:09:36 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 1.2905
2022-07-03 19:10:09 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 1.1776
2022-07-03 19:10:42 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 1.5261
2022-07-03 19:11:15 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 1.4664
2022-07-03 19:11:48 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 1.3873
2022-07-03 19:12:21 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 1.4839
2022-07-03 19:12:54 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 1.6438
2022-07-03 19:13:26 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 1.4032
2022-07-03 19:14:00 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 1.3579
2022-07-03 19:14:33 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 1.5915
2022-07-03 19:15:06 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 1.2614
2022-07-03 19:15:40 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 1.7102
2022-07-03 19:16:12 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 1.1844
2022-07-03 19:16:46 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 1.4243
2022-07-03 19:17:19 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 1.4007
2022-07-03 19:17:53 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 1.6674
2022-07-03 19:18:26 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 1.3864
2022-07-03 19:18:59 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 1.6149
2022-07-03 19:19:33 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 1.3001
2022-07-03 19:20:05 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 1.3400
2022-07-03 19:20:39 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 1.2573
2022-07-03 19:21:12 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 1.5784
2022-07-03 19:21:45 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 1.4455
2022-07-03 19:22:19 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 1.4993
2022-07-03 19:22:52 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 1.3797
2022-07-03 19:23:26 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 1.4529
2022-07-03 19:23:58 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 1.6941
2022-07-03 19:24:30 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 1.4740
2022-07-03 19:25:04 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 1.3873
2022-07-03 19:25:37 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 1.2257
2022-07-03 19:26:11 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 1.3299
2022-07-03 19:26:42 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 1.4648
2022-07-03 19:26:42 - train: epoch 059, train_loss: 1.3776
2022-07-03 19:27:56 - eval: epoch: 059, acc1: 68.176%, acc5: 88.680%, test_loss: 1.2927, per_image_load_time: 2.585ms, per_image_inference_time: 0.267ms
2022-07-03 19:27:56 - until epoch: 059, best_acc1: 69.192%
2022-07-03 19:27:56 - epoch 060 lr: 0.010000
2022-07-03 19:28:34 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 1.4160
2022-07-03 19:29:07 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 1.2826
2022-07-03 19:29:39 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 1.2035
2022-07-03 19:30:12 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 1.5051
2022-07-03 19:30:45 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 1.5400
2022-07-03 19:31:19 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 1.5145
2022-07-03 19:31:51 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 1.3045
2022-07-03 19:32:24 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 1.4570
2022-07-03 19:32:58 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 1.4367
2022-07-03 19:33:31 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 0.8882
2022-07-03 19:34:04 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 1.3683
2022-07-03 19:34:38 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 1.3657
2022-07-03 19:35:10 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 1.1750
2022-07-03 19:35:42 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 1.5539
2022-07-03 19:36:15 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 1.3953
2022-07-03 19:36:49 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 1.4119
2022-07-03 19:37:21 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 1.3192
2022-07-03 19:37:55 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 1.4173
2022-07-03 19:38:28 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 1.5737
2022-07-03 19:39:02 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 1.3052
2022-07-03 19:39:34 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 1.5127
2022-07-03 19:40:08 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 1.6719
2022-07-03 19:40:40 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 1.2105
2022-07-03 19:41:14 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 1.3814
2022-07-03 19:41:47 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 1.3940
2022-07-03 19:42:21 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 1.3518
2022-07-03 19:42:53 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 1.2993
2022-07-03 19:43:26 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 1.3616
2022-07-03 19:44:00 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 1.3063
2022-07-03 19:44:33 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 1.2746
2022-07-03 19:45:06 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 1.4853
2022-07-03 19:45:39 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 1.5125
2022-07-03 19:46:12 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 1.1004
2022-07-03 19:46:45 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 1.3742
2022-07-03 19:47:18 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 1.3253
2022-07-03 19:47:51 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 1.3659
2022-07-03 19:48:23 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 1.5389
2022-07-03 19:48:57 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 1.4096
2022-07-03 19:49:30 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 1.4224
2022-07-03 19:50:03 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 1.3392
2022-07-03 19:50:37 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 1.6422
2022-07-03 19:51:09 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 1.5744
2022-07-03 19:51:42 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 1.2081
2022-07-03 19:52:17 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 1.4665
2022-07-03 19:52:49 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 1.5820
2022-07-03 19:53:22 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 1.2048
2022-07-03 19:53:57 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 1.3466
2022-07-03 19:54:29 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 1.2680
2022-07-03 19:55:03 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 1.2870
2022-07-03 19:55:35 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 1.5307
2022-07-03 19:55:36 - train: epoch 060, train_loss: 1.3745
2022-07-03 19:56:49 - eval: epoch: 060, acc1: 69.148%, acc5: 89.018%, test_loss: 1.2549, per_image_load_time: 2.603ms, per_image_inference_time: 0.260ms
2022-07-03 19:56:49 - until epoch: 060, best_acc1: 69.192%
2022-07-03 19:56:49 - epoch 061 lr: 0.001000
2022-07-03 19:57:27 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 1.1210
2022-07-03 19:58:00 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 1.3077
2022-07-03 19:58:32 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 1.1951
2022-07-03 19:59:05 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 1.3846
2022-07-03 19:59:38 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 1.1027
2022-07-03 20:00:11 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 1.2607
2022-07-03 20:00:44 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 1.2043
2022-07-03 20:01:17 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 1.2839
2022-07-03 20:01:50 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 1.1007
2022-07-03 20:02:24 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 1.2030
2022-07-03 20:02:57 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 1.0642
2022-07-03 20:03:29 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 1.2015
2022-07-03 20:04:03 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 1.1297
2022-07-03 20:04:36 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 1.0577
2022-07-03 20:05:09 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 1.2776
2022-07-03 20:05:43 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 1.1130
2022-07-03 20:06:15 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 1.2103
2022-07-03 20:06:49 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 1.2915
2022-07-03 20:07:22 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 1.3556
2022-07-03 20:07:55 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 1.1702
2022-07-03 20:08:28 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 1.3226
2022-07-03 20:09:01 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 1.0983
2022-07-03 20:09:34 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 1.2686
2022-07-03 20:10:07 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 1.1365
2022-07-03 20:10:41 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 1.3323
2022-07-03 20:11:13 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 1.3045
2022-07-03 20:11:47 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 1.2928
2022-07-03 20:12:19 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 1.1744
2022-07-03 20:12:53 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 1.3118
2022-07-03 20:13:26 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 1.1699
2022-07-03 20:14:00 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 1.1923
2022-07-03 20:14:32 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 1.1415
2022-07-03 20:15:05 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 1.2222
2022-07-03 20:15:38 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 1.0837
2022-07-03 20:16:12 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 1.3260
2022-07-03 20:16:45 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 1.3194
2022-07-03 20:17:18 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 1.0639
2022-07-03 20:17:51 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 1.0984
2022-07-03 20:18:25 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 1.1745
2022-07-03 20:18:58 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 1.2694
2022-07-03 20:19:31 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 1.2828
2022-07-03 20:20:05 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 1.1592
2022-07-03 20:20:37 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 1.1760
2022-07-03 20:21:11 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 1.1606
2022-07-03 20:21:43 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 1.0884
2022-07-03 20:22:18 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 1.1437
2022-07-03 20:22:50 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 1.3413
2022-07-03 20:23:24 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 1.1622
2022-07-03 20:23:57 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 1.0031
2022-07-03 20:24:28 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 1.1513
2022-07-03 20:24:29 - train: epoch 061, train_loss: 1.2008
2022-07-03 20:25:42 - eval: epoch: 061, acc1: 72.016%, acc5: 90.666%, test_loss: 1.1211, per_image_load_time: 2.423ms, per_image_inference_time: 0.260ms
2022-07-03 20:25:42 - until epoch: 061, best_acc1: 72.016%
2022-07-03 20:25:42 - epoch 062 lr: 0.001000
2022-07-03 20:26:20 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 1.3204
2022-07-03 20:26:53 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 1.5504
2022-07-03 20:27:26 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 1.0818
2022-07-03 20:28:00 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 1.3088
2022-07-03 20:28:32 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 1.1153
2022-07-03 20:29:05 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 1.0165
2022-07-03 20:29:39 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 1.1901
2022-07-03 20:30:12 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 1.0621
2022-07-03 20:30:45 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 1.1753
2022-07-03 20:31:17 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 1.4091
2022-07-03 20:31:51 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 1.0960
2022-07-03 20:32:23 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 1.2109
2022-07-03 20:32:57 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 1.0264
2022-07-03 20:33:30 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 1.0652
2022-07-03 20:34:04 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 1.1835
2022-07-03 20:34:36 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 1.3922
2022-07-03 20:35:10 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 1.0912
2022-07-03 20:35:43 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 0.8763
2022-07-03 20:36:17 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 0.9171
2022-07-03 20:36:50 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 1.1651
2022-07-03 20:37:24 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 1.3243
2022-07-03 20:37:57 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 1.0316
2022-07-03 20:38:32 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 1.1466
2022-07-03 20:39:04 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 1.1597
2022-07-03 20:39:38 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 1.2631
2022-07-03 20:40:11 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 1.1060
2022-07-03 20:40:44 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 1.0626
2022-07-03 20:41:17 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 1.2993
2022-07-03 20:41:51 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 1.0936
2022-07-03 20:42:24 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 1.1796
2022-07-03 20:42:58 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 1.2626
2022-07-03 20:43:31 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 0.9901
2022-07-03 20:44:04 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 1.2405
2022-07-03 20:44:37 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 1.1605
2022-07-03 20:45:10 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 1.0882
2022-07-03 20:45:43 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 1.2913
2022-07-03 20:46:18 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 1.2600
2022-07-03 20:46:50 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 1.0683
2022-07-03 20:47:23 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 1.3185
2022-07-03 20:47:56 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 0.9902
2022-07-03 20:48:30 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 1.1090
2022-07-03 20:49:03 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 1.1215
2022-07-03 20:49:36 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 1.0621
2022-07-03 20:50:09 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 1.0125
2022-07-03 20:50:43 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 1.0586
2022-07-03 20:51:15 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 1.1238
2022-07-03 20:51:49 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 1.2010
2022-07-03 20:52:22 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 1.2532
2022-07-03 20:52:56 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 1.2128
2022-07-03 20:53:27 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 1.3175
2022-07-03 20:53:28 - train: epoch 062, train_loss: 1.1501
2022-07-03 20:54:41 - eval: epoch: 062, acc1: 72.442%, acc5: 90.846%, test_loss: 1.1059, per_image_load_time: 2.553ms, per_image_inference_time: 0.298ms
2022-07-03 20:54:41 - until epoch: 062, best_acc1: 72.442%
2022-07-03 20:54:41 - epoch 063 lr: 0.001000
2022-07-03 20:55:18 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 1.3016
2022-07-03 20:55:52 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 1.1466
2022-07-03 20:56:25 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 1.0592
2022-07-03 20:56:57 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 1.1552
2022-07-03 20:57:30 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 1.0545
2022-07-03 20:58:03 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 1.1528
2022-07-03 20:58:37 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 1.0874
2022-07-03 20:59:08 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 1.0328
2022-07-03 20:59:41 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 1.2165
2022-07-03 21:00:15 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 1.2085
2022-07-03 21:00:47 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 0.9752
2022-07-03 21:01:21 - train: epoch 0063, iter [01200, 05004], lr: 0.001000, loss: 1.2257
2022-07-03 21:01:54 - train: epoch 0063, iter [01300, 05004], lr: 0.001000, loss: 0.9315
2022-07-03 21:02:27 - train: epoch 0063, iter [01400, 05004], lr: 0.001000, loss: 1.2887
2022-07-03 21:03:01 - train: epoch 0063, iter [01500, 05004], lr: 0.001000, loss: 1.0920
2022-07-03 21:03:34 - train: epoch 0063, iter [01600, 05004], lr: 0.001000, loss: 1.0268
2022-07-03 21:04:07 - train: epoch 0063, iter [01700, 05004], lr: 0.001000, loss: 1.0220
2022-07-03 21:04:41 - train: epoch 0063, iter [01800, 05004], lr: 0.001000, loss: 1.1311
2022-07-03 21:05:14 - train: epoch 0063, iter [01900, 05004], lr: 0.001000, loss: 1.1880
2022-07-03 21:05:48 - train: epoch 0063, iter [02000, 05004], lr: 0.001000, loss: 0.9017
2022-07-03 21:06:20 - train: epoch 0063, iter [02100, 05004], lr: 0.001000, loss: 1.1322
2022-07-03 21:06:53 - train: epoch 0063, iter [02200, 05004], lr: 0.001000, loss: 1.3558
2022-07-03 21:07:27 - train: epoch 0063, iter [02300, 05004], lr: 0.001000, loss: 1.2765
2022-07-03 21:08:01 - train: epoch 0063, iter [02400, 05004], lr: 0.001000, loss: 1.0872
2022-07-03 21:08:33 - train: epoch 0063, iter [02500, 05004], lr: 0.001000, loss: 1.1164
2022-07-03 21:09:07 - train: epoch 0063, iter [02600, 05004], lr: 0.001000, loss: 1.1828
2022-07-03 21:09:40 - train: epoch 0063, iter [02700, 05004], lr: 0.001000, loss: 1.1411
2022-07-03 21:10:14 - train: epoch 0063, iter [02800, 05004], lr: 0.001000, loss: 1.2450
2022-07-03 21:10:48 - train: epoch 0063, iter [02900, 05004], lr: 0.001000, loss: 1.3083
2022-07-03 21:11:20 - train: epoch 0063, iter [03000, 05004], lr: 0.001000, loss: 1.2598
2022-07-03 21:11:54 - train: epoch 0063, iter [03100, 05004], lr: 0.001000, loss: 1.3152
2022-07-03 21:12:26 - train: epoch 0063, iter [03200, 05004], lr: 0.001000, loss: 1.1878
2022-07-03 21:13:00 - train: epoch 0063, iter [03300, 05004], lr: 0.001000, loss: 0.9520
2022-07-03 21:13:33 - train: epoch 0063, iter [03400, 05004], lr: 0.001000, loss: 0.9445
2022-07-03 21:14:07 - train: epoch 0063, iter [03500, 05004], lr: 0.001000, loss: 1.3184
2022-07-03 21:14:39 - train: epoch 0063, iter [03600, 05004], lr: 0.001000, loss: 1.2402
2022-07-03 21:15:14 - train: epoch 0063, iter [03700, 05004], lr: 0.001000, loss: 1.2392
2022-07-03 21:15:46 - train: epoch 0063, iter [03800, 05004], lr: 0.001000, loss: 1.2106
2022-07-03 21:16:20 - train: epoch 0063, iter [03900, 05004], lr: 0.001000, loss: 1.0799
2022-07-03 21:16:53 - train: epoch 0063, iter [04000, 05004], lr: 0.001000, loss: 0.9975
2022-07-03 21:17:27 - train: epoch 0063, iter [04100, 05004], lr: 0.001000, loss: 1.1933
2022-07-03 21:18:00 - train: epoch 0063, iter [04200, 05004], lr: 0.001000, loss: 1.1042
2022-07-03 21:18:33 - train: epoch 0063, iter [04300, 05004], lr: 0.001000, loss: 1.2119
2022-07-03 21:19:06 - train: epoch 0063, iter [04400, 05004], lr: 0.001000, loss: 1.2266
2022-07-03 21:19:40 - train: epoch 0063, iter [04500, 05004], lr: 0.001000, loss: 1.2171
2022-07-03 21:20:13 - train: epoch 0063, iter [04600, 05004], lr: 0.001000, loss: 1.0057
2022-07-03 21:20:46 - train: epoch 0063, iter [04700, 05004], lr: 0.001000, loss: 1.0854
2022-07-03 21:21:19 - train: epoch 0063, iter [04800, 05004], lr: 0.001000, loss: 1.0321
2022-07-03 21:21:53 - train: epoch 0063, iter [04900, 05004], lr: 0.001000, loss: 1.1248
2022-07-03 21:22:24 - train: epoch 0063, iter [05000, 05004], lr: 0.001000, loss: 1.1261
2022-07-03 21:22:25 - train: epoch 063, train_loss: 1.1276
2022-07-03 21:23:39 - eval: epoch: 063, acc1: 72.558%, acc5: 90.930%, test_loss: 1.0975, per_image_load_time: 2.480ms, per_image_inference_time: 0.274ms
2022-07-03 21:23:39 - until epoch: 063, best_acc1: 72.558%
2022-07-03 21:23:39 - epoch 064 lr: 0.001000
2022-07-03 21:24:16 - train: epoch 0064, iter [00100, 05004], lr: 0.001000, loss: 0.9822
2022-07-03 21:24:50 - train: epoch 0064, iter [00200, 05004], lr: 0.001000, loss: 1.1644
2022-07-03 21:25:22 - train: epoch 0064, iter [00300, 05004], lr: 0.001000, loss: 1.0253
2022-07-03 21:25:55 - train: epoch 0064, iter [00400, 05004], lr: 0.001000, loss: 1.0975
2022-07-03 21:26:27 - train: epoch 0064, iter [00500, 05004], lr: 0.001000, loss: 1.1679
2022-07-03 21:27:01 - train: epoch 0064, iter [00600, 05004], lr: 0.001000, loss: 1.1247
2022-07-03 21:27:34 - train: epoch 0064, iter [00700, 05004], lr: 0.001000, loss: 1.3650
2022-07-03 21:28:07 - train: epoch 0064, iter [00800, 05004], lr: 0.001000, loss: 1.0057
2022-07-03 21:28:39 - train: epoch 0064, iter [00900, 05004], lr: 0.001000, loss: 1.0230
2022-07-03 21:29:13 - train: epoch 0064, iter [01000, 05004], lr: 0.001000, loss: 0.9946
2022-07-03 21:29:46 - train: epoch 0064, iter [01100, 05004], lr: 0.001000, loss: 1.1129
2022-07-03 21:30:19 - train: epoch 0064, iter [01200, 05004], lr: 0.001000, loss: 1.0829
2022-07-03 21:30:53 - train: epoch 0064, iter [01300, 05004], lr: 0.001000, loss: 1.1005
2022-07-03 21:31:24 - train: epoch 0064, iter [01400, 05004], lr: 0.001000, loss: 1.1632
2022-07-03 21:31:58 - train: epoch 0064, iter [01500, 05004], lr: 0.001000, loss: 1.2375
2022-07-03 21:32:32 - train: epoch 0064, iter [01600, 05004], lr: 0.001000, loss: 0.9644
2022-07-03 21:33:04 - train: epoch 0064, iter [01700, 05004], lr: 0.001000, loss: 1.1581
2022-07-03 21:33:39 - train: epoch 0064, iter [01800, 05004], lr: 0.001000, loss: 1.0574
2022-07-03 21:34:11 - train: epoch 0064, iter [01900, 05004], lr: 0.001000, loss: 1.2244
2022-07-03 21:34:45 - train: epoch 0064, iter [02000, 05004], lr: 0.001000, loss: 0.9849
2022-07-03 21:35:18 - train: epoch 0064, iter [02100, 05004], lr: 0.001000, loss: 1.2089
2022-07-03 21:35:50 - train: epoch 0064, iter [02200, 05004], lr: 0.001000, loss: 1.1254
2022-07-03 21:36:23 - train: epoch 0064, iter [02300, 05004], lr: 0.001000, loss: 1.3060
2022-07-03 21:36:56 - train: epoch 0064, iter [02400, 05004], lr: 0.001000, loss: 1.0355
2022-07-03 21:37:29 - train: epoch 0064, iter [02500, 05004], lr: 0.001000, loss: 1.0032
2022-07-03 21:38:03 - train: epoch 0064, iter [02600, 05004], lr: 0.001000, loss: 1.0557
2022-07-03 21:38:36 - train: epoch 0064, iter [02700, 05004], lr: 0.001000, loss: 1.1276
2022-07-03 21:39:10 - train: epoch 0064, iter [02800, 05004], lr: 0.001000, loss: 1.2145
2022-07-03 21:39:42 - train: epoch 0064, iter [02900, 05004], lr: 0.001000, loss: 1.0616
2022-07-03 21:40:16 - train: epoch 0064, iter [03000, 05004], lr: 0.001000, loss: 1.0353
2022-07-03 21:40:49 - train: epoch 0064, iter [03100, 05004], lr: 0.001000, loss: 1.0473
2022-07-03 21:41:23 - train: epoch 0064, iter [03200, 05004], lr: 0.001000, loss: 1.0363
2022-07-03 21:41:56 - train: epoch 0064, iter [03300, 05004], lr: 0.001000, loss: 1.0370
2022-07-03 21:42:29 - train: epoch 0064, iter [03400, 05004], lr: 0.001000, loss: 1.2121
2022-07-03 21:43:02 - train: epoch 0064, iter [03500, 05004], lr: 0.001000, loss: 1.1141
2022-07-03 21:43:36 - train: epoch 0064, iter [03600, 05004], lr: 0.001000, loss: 1.0638
2022-07-03 21:44:09 - train: epoch 0064, iter [03700, 05004], lr: 0.001000, loss: 0.8212
2022-07-03 21:44:42 - train: epoch 0064, iter [03800, 05004], lr: 0.001000, loss: 1.2275
2022-07-03 21:45:16 - train: epoch 0064, iter [03900, 05004], lr: 0.001000, loss: 0.9258
2022-07-03 21:45:49 - train: epoch 0064, iter [04000, 05004], lr: 0.001000, loss: 1.1280
2022-07-03 21:46:22 - train: epoch 0064, iter [04100, 05004], lr: 0.001000, loss: 1.0691
2022-07-03 21:46:55 - train: epoch 0064, iter [04200, 05004], lr: 0.001000, loss: 1.1374
2022-07-03 21:47:30 - train: epoch 0064, iter [04300, 05004], lr: 0.001000, loss: 1.2854
2022-07-03 21:48:02 - train: epoch 0064, iter [04400, 05004], lr: 0.001000, loss: 1.0717
2022-07-03 21:48:36 - train: epoch 0064, iter [04500, 05004], lr: 0.001000, loss: 1.1788
2022-07-03 21:49:09 - train: epoch 0064, iter [04600, 05004], lr: 0.001000, loss: 1.2231
2022-07-03 21:49:43 - train: epoch 0064, iter [04700, 05004], lr: 0.001000, loss: 1.2374
2022-07-03 21:50:16 - train: epoch 0064, iter [04800, 05004], lr: 0.001000, loss: 1.1037
2022-07-03 21:50:48 - train: epoch 0064, iter [04900, 05004], lr: 0.001000, loss: 1.1634
2022-07-03 21:51:20 - train: epoch 0064, iter [05000, 05004], lr: 0.001000, loss: 1.0203
2022-07-03 21:51:21 - train: epoch 064, train_loss: 1.1138
2022-07-03 21:52:35 - eval: epoch: 064, acc1: 72.838%, acc5: 91.040%, test_loss: 1.0931, per_image_load_time: 2.570ms, per_image_inference_time: 0.284ms
2022-07-03 21:52:35 - until epoch: 064, best_acc1: 72.838%
2022-07-03 21:52:35 - epoch 065 lr: 0.001000
2022-07-03 21:53:14 - train: epoch 0065, iter [00100, 05004], lr: 0.001000, loss: 0.9621
2022-07-03 21:53:47 - train: epoch 0065, iter [00200, 05004], lr: 0.001000, loss: 1.1784
2022-07-03 21:54:20 - train: epoch 0065, iter [00300, 05004], lr: 0.001000, loss: 1.0643
2022-07-03 21:54:53 - train: epoch 0065, iter [00400, 05004], lr: 0.001000, loss: 1.1655
2022-07-03 21:55:25 - train: epoch 0065, iter [00500, 05004], lr: 0.001000, loss: 1.3904
2022-07-03 21:55:59 - train: epoch 0065, iter [00600, 05004], lr: 0.001000, loss: 1.1208
2022-07-03 21:56:32 - train: epoch 0065, iter [00700, 05004], lr: 0.001000, loss: 1.0559
2022-07-03 21:57:04 - train: epoch 0065, iter [00800, 05004], lr: 0.001000, loss: 1.0435
2022-07-03 21:57:38 - train: epoch 0065, iter [00900, 05004], lr: 0.001000, loss: 1.1752
2022-07-03 21:58:10 - train: epoch 0065, iter [01000, 05004], lr: 0.001000, loss: 1.0313
2022-07-03 21:58:43 - train: epoch 0065, iter [01100, 05004], lr: 0.001000, loss: 0.9022
2022-07-03 21:59:16 - train: epoch 0065, iter [01200, 05004], lr: 0.001000, loss: 1.3426
2022-07-03 21:59:49 - train: epoch 0065, iter [01300, 05004], lr: 0.001000, loss: 1.1158
2022-07-03 22:00:22 - train: epoch 0065, iter [01400, 05004], lr: 0.001000, loss: 1.0463
2022-07-03 22:00:57 - train: epoch 0065, iter [01500, 05004], lr: 0.001000, loss: 1.1885
2022-07-03 22:01:30 - train: epoch 0065, iter [01600, 05004], lr: 0.001000, loss: 1.3751
2022-07-03 22:02:02 - train: epoch 0065, iter [01700, 05004], lr: 0.001000, loss: 1.2141
2022-07-03 22:02:36 - train: epoch 0065, iter [01800, 05004], lr: 0.001000, loss: 1.0807
2022-07-03 22:03:09 - train: epoch 0065, iter [01900, 05004], lr: 0.001000, loss: 0.8753
2022-07-03 22:03:44 - train: epoch 0065, iter [02000, 05004], lr: 0.001000, loss: 1.1116
2022-07-03 22:04:17 - train: epoch 0065, iter [02100, 05004], lr: 0.001000, loss: 1.1476
2022-07-03 22:04:51 - train: epoch 0065, iter [02200, 05004], lr: 0.001000, loss: 1.0688
2022-07-03 22:05:23 - train: epoch 0065, iter [02300, 05004], lr: 0.001000, loss: 1.1727
2022-07-03 22:05:57 - train: epoch 0065, iter [02400, 05004], lr: 0.001000, loss: 1.1283
2022-07-03 22:06:29 - train: epoch 0065, iter [02500, 05004], lr: 0.001000, loss: 0.9387
2022-07-03 22:07:03 - train: epoch 0065, iter [02600, 05004], lr: 0.001000, loss: 1.3336
2022-07-03 22:07:36 - train: epoch 0065, iter [02700, 05004], lr: 0.001000, loss: 1.1198
2022-07-03 22:08:09 - train: epoch 0065, iter [02800, 05004], lr: 0.001000, loss: 1.1420
2022-07-03 22:08:42 - train: epoch 0065, iter [02900, 05004], lr: 0.001000, loss: 1.1188
2022-07-03 22:09:15 - train: epoch 0065, iter [03000, 05004], lr: 0.001000, loss: 1.0996
2022-07-03 22:09:49 - train: epoch 0065, iter [03100, 05004], lr: 0.001000, loss: 1.0151
2022-07-03 22:10:22 - train: epoch 0065, iter [03200, 05004], lr: 0.001000, loss: 1.0779
2022-07-03 22:10:56 - train: epoch 0065, iter [03300, 05004], lr: 0.001000, loss: 1.2600
2022-07-03 22:11:28 - train: epoch 0065, iter [03400, 05004], lr: 0.001000, loss: 1.0356
2022-07-03 22:12:02 - train: epoch 0065, iter [03500, 05004], lr: 0.001000, loss: 1.2561
2022-07-03 22:12:36 - train: epoch 0065, iter [03600, 05004], lr: 0.001000, loss: 1.1725
2022-07-03 22:13:09 - train: epoch 0065, iter [03700, 05004], lr: 0.001000, loss: 0.9796
2022-07-03 22:13:42 - train: epoch 0065, iter [03800, 05004], lr: 0.001000, loss: 1.0743
2022-07-03 22:14:15 - train: epoch 0065, iter [03900, 05004], lr: 0.001000, loss: 1.2140
2022-07-03 22:14:49 - train: epoch 0065, iter [04000, 05004], lr: 0.001000, loss: 1.2692
2022-07-03 22:15:22 - train: epoch 0065, iter [04100, 05004], lr: 0.001000, loss: 1.0785
2022-07-03 22:15:55 - train: epoch 0065, iter [04200, 05004], lr: 0.001000, loss: 1.2958
2022-07-03 22:16:28 - train: epoch 0065, iter [04300, 05004], lr: 0.001000, loss: 1.0633
2022-07-03 22:17:02 - train: epoch 0065, iter [04400, 05004], lr: 0.001000, loss: 1.1770
2022-07-03 22:17:35 - train: epoch 0065, iter [04500, 05004], lr: 0.001000, loss: 1.0683
2022-07-03 22:18:08 - train: epoch 0065, iter [04600, 05004], lr: 0.001000, loss: 1.1701
2022-07-03 22:18:42 - train: epoch 0065, iter [04700, 05004], lr: 0.001000, loss: 1.2055
2022-07-03 22:19:14 - train: epoch 0065, iter [04800, 05004], lr: 0.001000, loss: 0.7996
2022-07-03 22:19:48 - train: epoch 0065, iter [04900, 05004], lr: 0.001000, loss: 1.2373
2022-07-03 22:20:20 - train: epoch 0065, iter [05000, 05004], lr: 0.001000, loss: 1.1968
2022-07-03 22:20:21 - train: epoch 065, train_loss: 1.1028
2022-07-03 22:21:34 - eval: epoch: 065, acc1: 72.796%, acc5: 91.010%, test_loss: 1.0894, per_image_load_time: 2.585ms, per_image_inference_time: 0.278ms
2022-07-03 22:21:35 - until epoch: 065, best_acc1: 72.838%
2022-07-03 22:21:35 - epoch 066 lr: 0.001000
2022-07-03 22:22:13 - train: epoch 0066, iter [00100, 05004], lr: 0.001000, loss: 1.1707
2022-07-03 22:22:46 - train: epoch 0066, iter [00200, 05004], lr: 0.001000, loss: 1.2637
2022-07-03 22:23:19 - train: epoch 0066, iter [00300, 05004], lr: 0.001000, loss: 1.1127
2022-07-03 22:23:52 - train: epoch 0066, iter [00400, 05004], lr: 0.001000, loss: 1.1174
2022-07-03 22:24:25 - train: epoch 0066, iter [00500, 05004], lr: 0.001000, loss: 1.1545
2022-07-03 22:24:59 - train: epoch 0066, iter [00600, 05004], lr: 0.001000, loss: 0.9458
2022-07-03 22:25:31 - train: epoch 0066, iter [00700, 05004], lr: 0.001000, loss: 1.0932
2022-07-03 22:26:04 - train: epoch 0066, iter [00800, 05004], lr: 0.001000, loss: 1.2440
2022-07-03 22:26:38 - train: epoch 0066, iter [00900, 05004], lr: 0.001000, loss: 0.9614
2022-07-03 22:27:11 - train: epoch 0066, iter [01000, 05004], lr: 0.001000, loss: 1.1517
2022-07-03 22:27:44 - train: epoch 0066, iter [01100, 05004], lr: 0.001000, loss: 1.1113
2022-07-03 22:28:17 - train: epoch 0066, iter [01200, 05004], lr: 0.001000, loss: 1.1856
2022-07-03 22:28:50 - train: epoch 0066, iter [01300, 05004], lr: 0.001000, loss: 1.0143
2022-07-03 22:29:23 - train: epoch 0066, iter [01400, 05004], lr: 0.001000, loss: 0.9453
2022-07-03 22:29:56 - train: epoch 0066, iter [01500, 05004], lr: 0.001000, loss: 1.0821
2022-07-03 22:30:29 - train: epoch 0066, iter [01600, 05004], lr: 0.001000, loss: 1.2511
2022-07-03 22:31:03 - train: epoch 0066, iter [01700, 05004], lr: 0.001000, loss: 1.1068
2022-07-03 22:31:36 - train: epoch 0066, iter [01800, 05004], lr: 0.001000, loss: 0.9785
2022-07-03 22:32:09 - train: epoch 0066, iter [01900, 05004], lr: 0.001000, loss: 1.2869
2022-07-03 22:32:43 - train: epoch 0066, iter [02000, 05004], lr: 0.001000, loss: 0.9576
2022-07-03 22:33:15 - train: epoch 0066, iter [02100, 05004], lr: 0.001000, loss: 1.1447
2022-07-03 22:33:48 - train: epoch 0066, iter [02200, 05004], lr: 0.001000, loss: 0.9401
2022-07-03 22:34:22 - train: epoch 0066, iter [02300, 05004], lr: 0.001000, loss: 1.2109
2022-07-03 22:34:55 - train: epoch 0066, iter [02400, 05004], lr: 0.001000, loss: 1.1025
2022-07-03 22:35:28 - train: epoch 0066, iter [02500, 05004], lr: 0.001000, loss: 1.0606
2022-07-03 22:36:01 - train: epoch 0066, iter [02600, 05004], lr: 0.001000, loss: 1.0741
2022-07-03 22:36:35 - train: epoch 0066, iter [02700, 05004], lr: 0.001000, loss: 1.2003
2022-07-03 22:37:07 - train: epoch 0066, iter [02800, 05004], lr: 0.001000, loss: 1.1728
2022-07-03 22:37:42 - train: epoch 0066, iter [02900, 05004], lr: 0.001000, loss: 1.0910
2022-07-03 22:38:14 - train: epoch 0066, iter [03000, 05004], lr: 0.001000, loss: 1.1559
2022-07-03 22:38:48 - train: epoch 0066, iter [03100, 05004], lr: 0.001000, loss: 1.1477
2022-07-03 22:39:20 - train: epoch 0066, iter [03200, 05004], lr: 0.001000, loss: 1.1205
2022-07-03 22:39:54 - train: epoch 0066, iter [03300, 05004], lr: 0.001000, loss: 1.1430
2022-07-03 22:40:27 - train: epoch 0066, iter [03400, 05004], lr: 0.001000, loss: 1.0152
2022-07-03 22:41:00 - train: epoch 0066, iter [03500, 05004], lr: 0.001000, loss: 1.1299
2022-07-03 22:41:34 - train: epoch 0066, iter [03600, 05004], lr: 0.001000, loss: 1.1000
2022-07-03 22:42:06 - train: epoch 0066, iter [03700, 05004], lr: 0.001000, loss: 1.0300
2022-07-03 22:42:39 - train: epoch 0066, iter [03800, 05004], lr: 0.001000, loss: 0.9937
2022-07-03 22:43:12 - train: epoch 0066, iter [03900, 05004], lr: 0.001000, loss: 1.3112
2022-07-03 22:43:45 - train: epoch 0066, iter [04000, 05004], lr: 0.001000, loss: 1.1298
2022-07-03 22:44:19 - train: epoch 0066, iter [04100, 05004], lr: 0.001000, loss: 0.9851
2022-07-03 22:44:52 - train: epoch 0066, iter [04200, 05004], lr: 0.001000, loss: 0.9124
2022-07-03 22:45:26 - train: epoch 0066, iter [04300, 05004], lr: 0.001000, loss: 1.0434
2022-07-03 22:45:58 - train: epoch 0066, iter [04400, 05004], lr: 0.001000, loss: 1.0285
2022-07-03 22:46:31 - train: epoch 0066, iter [04500, 05004], lr: 0.001000, loss: 1.0763
2022-07-03 22:47:05 - train: epoch 0066, iter [04600, 05004], lr: 0.001000, loss: 1.4045
2022-07-03 22:47:38 - train: epoch 0066, iter [04700, 05004], lr: 0.001000, loss: 0.9976
2022-07-03 22:48:12 - train: epoch 0066, iter [04800, 05004], lr: 0.001000, loss: 1.0678
2022-07-03 22:48:46 - train: epoch 0066, iter [04900, 05004], lr: 0.001000, loss: 0.9921
2022-07-03 22:49:17 - train: epoch 0066, iter [05000, 05004], lr: 0.001000, loss: 0.9200
2022-07-03 22:49:18 - train: epoch 066, train_loss: 1.0927
2022-07-03 22:50:31 - eval: epoch: 066, acc1: 72.830%, acc5: 91.100%, test_loss: 1.0875, per_image_load_time: 2.559ms, per_image_inference_time: 0.271ms
2022-07-03 22:50:31 - until epoch: 066, best_acc1: 72.838%
2022-07-03 22:50:31 - epoch 067 lr: 0.001000
2022-07-03 22:51:08 - train: epoch 0067, iter [00100, 05004], lr: 0.001000, loss: 0.9430
2022-07-03 22:51:42 - train: epoch 0067, iter [00200, 05004], lr: 0.001000, loss: 1.2041
2022-07-03 22:52:14 - train: epoch 0067, iter [00300, 05004], lr: 0.001000, loss: 1.3141
2022-07-03 22:52:48 - train: epoch 0067, iter [00400, 05004], lr: 0.001000, loss: 1.0320
2022-07-03 22:53:20 - train: epoch 0067, iter [00500, 05004], lr: 0.001000, loss: 0.9104
2022-07-03 22:53:54 - train: epoch 0067, iter [00600, 05004], lr: 0.001000, loss: 1.0747
2022-07-03 22:54:27 - train: epoch 0067, iter [00700, 05004], lr: 0.001000, loss: 0.9535
2022-07-03 22:54:59 - train: epoch 0067, iter [00800, 05004], lr: 0.001000, loss: 1.0020
2022-07-03 22:55:33 - train: epoch 0067, iter [00900, 05004], lr: 0.001000, loss: 1.1969
2022-07-03 22:56:05 - train: epoch 0067, iter [01000, 05004], lr: 0.001000, loss: 1.0272
2022-07-03 22:56:37 - train: epoch 0067, iter [01100, 05004], lr: 0.001000, loss: 1.0313
2022-07-03 22:57:11 - train: epoch 0067, iter [01200, 05004], lr: 0.001000, loss: 1.1043
2022-07-03 22:57:44 - train: epoch 0067, iter [01300, 05004], lr: 0.001000, loss: 1.1389
2022-07-03 22:58:17 - train: epoch 0067, iter [01400, 05004], lr: 0.001000, loss: 1.2063
2022-07-03 22:58:49 - train: epoch 0067, iter [01500, 05004], lr: 0.001000, loss: 1.0001
2022-07-03 22:59:23 - train: epoch 0067, iter [01600, 05004], lr: 0.001000, loss: 1.2726
2022-07-03 22:59:56 - train: epoch 0067, iter [01700, 05004], lr: 0.001000, loss: 1.0533
2022-07-03 23:00:29 - train: epoch 0067, iter [01800, 05004], lr: 0.001000, loss: 1.1716
2022-07-03 23:01:01 - train: epoch 0067, iter [01900, 05004], lr: 0.001000, loss: 1.1548
2022-07-03 23:01:34 - train: epoch 0067, iter [02000, 05004], lr: 0.001000, loss: 1.0218
2022-07-03 23:02:08 - train: epoch 0067, iter [02100, 05004], lr: 0.001000, loss: 0.9056
2022-07-03 23:02:40 - train: epoch 0067, iter [02200, 05004], lr: 0.001000, loss: 1.1046
2022-07-03 23:03:14 - train: epoch 0067, iter [02300, 05004], lr: 0.001000, loss: 1.2437
2022-07-03 23:03:45 - train: epoch 0067, iter [02400, 05004], lr: 0.001000, loss: 1.0685
2022-07-03 23:04:19 - train: epoch 0067, iter [02500, 05004], lr: 0.001000, loss: 1.0902
2022-07-03 23:04:52 - train: epoch 0067, iter [02600, 05004], lr: 0.001000, loss: 1.0741
2022-07-03 23:05:25 - train: epoch 0067, iter [02700, 05004], lr: 0.001000, loss: 1.0452
2022-07-03 23:05:59 - train: epoch 0067, iter [02800, 05004], lr: 0.001000, loss: 1.4715
2022-07-03 23:06:32 - train: epoch 0067, iter [02900, 05004], lr: 0.001000, loss: 1.0998
2022-07-03 23:07:05 - train: epoch 0067, iter [03000, 05004], lr: 0.001000, loss: 1.1749
2022-07-03 23:07:39 - train: epoch 0067, iter [03100, 05004], lr: 0.001000, loss: 0.9047
2022-07-03 23:08:11 - train: epoch 0067, iter [03200, 05004], lr: 0.001000, loss: 1.1062
2022-07-03 23:08:45 - train: epoch 0067, iter [03300, 05004], lr: 0.001000, loss: 0.9914
2022-07-03 23:09:18 - train: epoch 0067, iter [03400, 05004], lr: 0.001000, loss: 1.0671
2022-07-03 23:09:52 - train: epoch 0067, iter [03500, 05004], lr: 0.001000, loss: 1.2269
2022-07-03 23:10:25 - train: epoch 0067, iter [03600, 05004], lr: 0.001000, loss: 1.0666
2022-07-03 23:10:57 - train: epoch 0067, iter [03700, 05004], lr: 0.001000, loss: 1.3014
2022-07-03 23:11:30 - train: epoch 0067, iter [03800, 05004], lr: 0.001000, loss: 1.1781
2022-07-03 23:12:05 - train: epoch 0067, iter [03900, 05004], lr: 0.001000, loss: 1.2867
2022-07-03 23:12:37 - train: epoch 0067, iter [04000, 05004], lr: 0.001000, loss: 1.0248
2022-07-03 23:13:11 - train: epoch 0067, iter [04100, 05004], lr: 0.001000, loss: 1.0558
2022-07-03 23:13:43 - train: epoch 0067, iter [04200, 05004], lr: 0.001000, loss: 1.2400
2022-07-03 23:14:17 - train: epoch 0067, iter [04300, 05004], lr: 0.001000, loss: 0.8949
2022-07-03 23:14:50 - train: epoch 0067, iter [04400, 05004], lr: 0.001000, loss: 0.8771
2022-07-03 23:15:23 - train: epoch 0067, iter [04500, 05004], lr: 0.001000, loss: 1.1517
2022-07-03 23:15:57 - train: epoch 0067, iter [04600, 05004], lr: 0.001000, loss: 0.8989
2022-07-03 23:16:30 - train: epoch 0067, iter [04700, 05004], lr: 0.001000, loss: 1.0215
2022-07-03 23:17:02 - train: epoch 0067, iter [04800, 05004], lr: 0.001000, loss: 0.8388
2022-07-03 23:17:36 - train: epoch 0067, iter [04900, 05004], lr: 0.001000, loss: 0.9878
2022-07-03 23:18:08 - train: epoch 0067, iter [05000, 05004], lr: 0.001000, loss: 1.0551
2022-07-03 23:18:09 - train: epoch 067, train_loss: 1.0848
2022-07-03 23:19:22 - eval: epoch: 067, acc1: 72.936%, acc5: 91.036%, test_loss: 1.0887, per_image_load_time: 2.576ms, per_image_inference_time: 0.271ms
2022-07-03 23:19:23 - until epoch: 067, best_acc1: 72.936%
2022-07-03 23:19:23 - epoch 068 lr: 0.001000
2022-07-03 23:20:00 - train: epoch 0068, iter [00100, 05004], lr: 0.001000, loss: 1.1505
2022-07-03 23:20:34 - train: epoch 0068, iter [00200, 05004], lr: 0.001000, loss: 1.2463
2022-07-03 23:21:06 - train: epoch 0068, iter [00300, 05004], lr: 0.001000, loss: 1.1479
2022-07-03 23:21:39 - train: epoch 0068, iter [00400, 05004], lr: 0.001000, loss: 1.0920
2022-07-03 23:22:12 - train: epoch 0068, iter [00500, 05004], lr: 0.001000, loss: 1.1231
2022-07-03 23:22:45 - train: epoch 0068, iter [00600, 05004], lr: 0.001000, loss: 0.9738
2022-07-03 23:23:17 - train: epoch 0068, iter [00700, 05004], lr: 0.001000, loss: 1.1730
2022-07-03 23:23:50 - train: epoch 0068, iter [00800, 05004], lr: 0.001000, loss: 0.9321
2022-07-03 23:24:24 - train: epoch 0068, iter [00900, 05004], lr: 0.001000, loss: 1.1217
2022-07-03 23:24:56 - train: epoch 0068, iter [01000, 05004], lr: 0.001000, loss: 1.0764
2022-07-03 23:25:29 - train: epoch 0068, iter [01100, 05004], lr: 0.001000, loss: 1.1512
2022-07-03 23:26:02 - train: epoch 0068, iter [01200, 05004], lr: 0.001000, loss: 0.9938
2022-07-03 23:26:35 - train: epoch 0068, iter [01300, 05004], lr: 0.001000, loss: 1.1181
2022-07-03 23:27:09 - train: epoch 0068, iter [01400, 05004], lr: 0.001000, loss: 1.1294
2022-07-03 23:27:41 - train: epoch 0068, iter [01500, 05004], lr: 0.001000, loss: 1.1395
2022-07-03 23:28:14 - train: epoch 0068, iter [01600, 05004], lr: 0.001000, loss: 1.0897
2022-07-03 23:28:48 - train: epoch 0068, iter [01700, 05004], lr: 0.001000, loss: 1.0219
2022-07-03 23:29:22 - train: epoch 0068, iter [01800, 05004], lr: 0.001000, loss: 1.2839
2022-07-03 23:29:54 - train: epoch 0068, iter [01900, 05004], lr: 0.001000, loss: 1.0149
2022-07-03 23:30:27 - train: epoch 0068, iter [02000, 05004], lr: 0.001000, loss: 0.8115
2022-07-03 23:30:59 - train: epoch 0068, iter [02100, 05004], lr: 0.001000, loss: 1.2485
2022-07-03 23:31:34 - train: epoch 0068, iter [02200, 05004], lr: 0.001000, loss: 1.1179
2022-07-03 23:32:07 - train: epoch 0068, iter [02300, 05004], lr: 0.001000, loss: 0.9779
2022-07-03 23:32:40 - train: epoch 0068, iter [02400, 05004], lr: 0.001000, loss: 0.9799
2022-07-03 23:33:13 - train: epoch 0068, iter [02500, 05004], lr: 0.001000, loss: 1.1136
2022-07-03 23:33:47 - train: epoch 0068, iter [02600, 05004], lr: 0.001000, loss: 0.9796
2022-07-03 23:34:19 - train: epoch 0068, iter [02700, 05004], lr: 0.001000, loss: 1.0058
2022-07-03 23:34:53 - train: epoch 0068, iter [02800, 05004], lr: 0.001000, loss: 1.1786
2022-07-03 23:35:26 - train: epoch 0068, iter [02900, 05004], lr: 0.001000, loss: 1.1245
2022-07-03 23:35:59 - train: epoch 0068, iter [03000, 05004], lr: 0.001000, loss: 1.2249
2022-07-03 23:36:32 - train: epoch 0068, iter [03100, 05004], lr: 0.001000, loss: 0.8612
2022-07-03 23:37:06 - train: epoch 0068, iter [03200, 05004], lr: 0.001000, loss: 1.0535
2022-07-03 23:37:39 - train: epoch 0068, iter [03300, 05004], lr: 0.001000, loss: 1.1716
2022-07-03 23:38:12 - train: epoch 0068, iter [03400, 05004], lr: 0.001000, loss: 0.9576
2022-07-03 23:38:44 - train: epoch 0068, iter [03500, 05004], lr: 0.001000, loss: 1.0709
2022-07-03 23:39:19 - train: epoch 0068, iter [03600, 05004], lr: 0.001000, loss: 1.0303
2022-07-03 23:39:52 - train: epoch 0068, iter [03700, 05004], lr: 0.001000, loss: 1.1078
2022-07-03 23:40:25 - train: epoch 0068, iter [03800, 05004], lr: 0.001000, loss: 1.0562
2022-07-03 23:40:58 - train: epoch 0068, iter [03900, 05004], lr: 0.001000, loss: 1.1424
2022-07-03 23:41:31 - train: epoch 0068, iter [04000, 05004], lr: 0.001000, loss: 1.1522
2022-07-03 23:42:04 - train: epoch 0068, iter [04100, 05004], lr: 0.001000, loss: 0.8564
2022-07-03 23:42:38 - train: epoch 0068, iter [04200, 05004], lr: 0.001000, loss: 0.9873
2022-07-03 23:43:11 - train: epoch 0068, iter [04300, 05004], lr: 0.001000, loss: 0.9778
2022-07-03 23:43:44 - train: epoch 0068, iter [04400, 05004], lr: 0.001000, loss: 1.1161
2022-07-03 23:44:17 - train: epoch 0068, iter [04500, 05004], lr: 0.001000, loss: 0.9987
2022-07-03 23:44:51 - train: epoch 0068, iter [04600, 05004], lr: 0.001000, loss: 1.1027
2022-07-03 23:45:25 - train: epoch 0068, iter [04700, 05004], lr: 0.001000, loss: 1.1052
2022-07-03 23:45:58 - train: epoch 0068, iter [04800, 05004], lr: 0.001000, loss: 1.1662
2022-07-03 23:46:31 - train: epoch 0068, iter [04900, 05004], lr: 0.001000, loss: 1.0556
2022-07-03 23:47:02 - train: epoch 0068, iter [05000, 05004], lr: 0.001000, loss: 0.9495
2022-07-03 23:47:03 - train: epoch 068, train_loss: 1.0772
2022-07-03 23:48:16 - eval: epoch: 068, acc1: 72.980%, acc5: 91.114%, test_loss: 1.0856, per_image_load_time: 2.544ms, per_image_inference_time: 0.293ms
2022-07-03 23:48:16 - until epoch: 068, best_acc1: 72.980%
2022-07-03 23:48:16 - epoch 069 lr: 0.001000
2022-07-03 23:48:54 - train: epoch 0069, iter [00100, 05004], lr: 0.001000, loss: 1.1191
2022-07-03 23:49:27 - train: epoch 0069, iter [00200, 05004], lr: 0.001000, loss: 0.9994
2022-07-03 23:50:00 - train: epoch 0069, iter [00300, 05004], lr: 0.001000, loss: 1.0036
2022-07-03 23:50:33 - train: epoch 0069, iter [00400, 05004], lr: 0.001000, loss: 1.1149
2022-07-03 23:51:07 - train: epoch 0069, iter [00500, 05004], lr: 0.001000, loss: 1.0638
2022-07-03 23:51:39 - train: epoch 0069, iter [00600, 05004], lr: 0.001000, loss: 0.9655
2022-07-03 23:52:12 - train: epoch 0069, iter [00700, 05004], lr: 0.001000, loss: 1.0367
2022-07-03 23:52:44 - train: epoch 0069, iter [00800, 05004], lr: 0.001000, loss: 1.1012
2022-07-03 23:53:18 - train: epoch 0069, iter [00900, 05004], lr: 0.001000, loss: 0.9329
2022-07-03 23:53:51 - train: epoch 0069, iter [01000, 05004], lr: 0.001000, loss: 1.0921
2022-07-03 23:54:24 - train: epoch 0069, iter [01100, 05004], lr: 0.001000, loss: 1.0883
2022-07-03 23:54:57 - train: epoch 0069, iter [01200, 05004], lr: 0.001000, loss: 1.1038
2022-07-03 23:55:30 - train: epoch 0069, iter [01300, 05004], lr: 0.001000, loss: 1.1656
2022-07-03 23:56:03 - train: epoch 0069, iter [01400, 05004], lr: 0.001000, loss: 1.1373
2022-07-03 23:56:35 - train: epoch 0069, iter [01500, 05004], lr: 0.001000, loss: 1.0756
2022-07-03 23:57:10 - train: epoch 0069, iter [01600, 05004], lr: 0.001000, loss: 1.2158
2022-07-03 23:57:42 - train: epoch 0069, iter [01700, 05004], lr: 0.001000, loss: 1.0007
2022-07-03 23:58:15 - train: epoch 0069, iter [01800, 05004], lr: 0.001000, loss: 1.0159
2022-07-03 23:58:48 - train: epoch 0069, iter [01900, 05004], lr: 0.001000, loss: 1.0397
2022-07-03 23:59:21 - train: epoch 0069, iter [02000, 05004], lr: 0.001000, loss: 1.0523
2022-07-03 23:59:54 - train: epoch 0069, iter [02100, 05004], lr: 0.001000, loss: 1.0509
2022-07-04 00:00:27 - train: epoch 0069, iter [02200, 05004], lr: 0.001000, loss: 1.1336
2022-07-04 00:01:00 - train: epoch 0069, iter [02300, 05004], lr: 0.001000, loss: 1.0657
2022-07-04 00:01:34 - train: epoch 0069, iter [02400, 05004], lr: 0.001000, loss: 1.2256
2022-07-04 00:02:07 - train: epoch 0069, iter [02500, 05004], lr: 0.001000, loss: 0.8474
2022-07-04 00:02:40 - train: epoch 0069, iter [02600, 05004], lr: 0.001000, loss: 1.1157
2022-07-04 00:03:13 - train: epoch 0069, iter [02700, 05004], lr: 0.001000, loss: 1.3144
2022-07-04 00:03:46 - train: epoch 0069, iter [02800, 05004], lr: 0.001000, loss: 1.2723
2022-07-04 00:04:19 - train: epoch 0069, iter [02900, 05004], lr: 0.001000, loss: 1.0919
2022-07-04 00:04:53 - train: epoch 0069, iter [03000, 05004], lr: 0.001000, loss: 1.1426
2022-07-04 00:05:26 - train: epoch 0069, iter [03100, 05004], lr: 0.001000, loss: 1.1150
2022-07-04 00:05:59 - train: epoch 0069, iter [03200, 05004], lr: 0.001000, loss: 1.1537
2022-07-04 00:06:32 - train: epoch 0069, iter [03300, 05004], lr: 0.001000, loss: 1.0017
2022-07-04 00:07:06 - train: epoch 0069, iter [03400, 05004], lr: 0.001000, loss: 1.1368
2022-07-04 00:07:39 - train: epoch 0069, iter [03500, 05004], lr: 0.001000, loss: 1.0704
2022-07-04 00:08:13 - train: epoch 0069, iter [03600, 05004], lr: 0.001000, loss: 1.0156
2022-07-04 00:08:46 - train: epoch 0069, iter [03700, 05004], lr: 0.001000, loss: 1.0133
2022-07-04 00:09:20 - train: epoch 0069, iter [03800, 05004], lr: 0.001000, loss: 1.1938
2022-07-04 00:09:53 - train: epoch 0069, iter [03900, 05004], lr: 0.001000, loss: 1.0524
2022-07-04 00:10:26 - train: epoch 0069, iter [04000, 05004], lr: 0.001000, loss: 1.1351
2022-07-04 00:10:59 - train: epoch 0069, iter [04100, 05004], lr: 0.001000, loss: 0.9967
2022-07-04 00:11:32 - train: epoch 0069, iter [04200, 05004], lr: 0.001000, loss: 1.0273
2022-07-04 00:12:05 - train: epoch 0069, iter [04300, 05004], lr: 0.001000, loss: 1.0262
2022-07-04 00:12:39 - train: epoch 0069, iter [04400, 05004], lr: 0.001000, loss: 1.1167
2022-07-04 00:13:12 - train: epoch 0069, iter [04500, 05004], lr: 0.001000, loss: 1.2059
2022-07-04 00:13:45 - train: epoch 0069, iter [04600, 05004], lr: 0.001000, loss: 1.0730
2022-07-04 00:14:18 - train: epoch 0069, iter [04700, 05004], lr: 0.001000, loss: 1.0228
2022-07-04 00:14:52 - train: epoch 0069, iter [04800, 05004], lr: 0.001000, loss: 1.1847
2022-07-04 00:15:25 - train: epoch 0069, iter [04900, 05004], lr: 0.001000, loss: 0.9179
2022-07-04 00:15:57 - train: epoch 0069, iter [05000, 05004], lr: 0.001000, loss: 1.0671
2022-07-04 00:15:58 - train: epoch 069, train_loss: 1.0731
2022-07-04 00:17:10 - eval: epoch: 069, acc1: 73.100%, acc5: 91.080%, test_loss: 1.0870, per_image_load_time: 2.283ms, per_image_inference_time: 0.276ms
2022-07-04 00:17:11 - until epoch: 069, best_acc1: 73.100%
2022-07-04 00:17:11 - epoch 070 lr: 0.001000
2022-07-04 00:17:49 - train: epoch 0070, iter [00100, 05004], lr: 0.001000, loss: 0.9574
2022-07-04 00:18:22 - train: epoch 0070, iter [00200, 05004], lr: 0.001000, loss: 1.1853
2022-07-04 00:18:55 - train: epoch 0070, iter [00300, 05004], lr: 0.001000, loss: 1.1160
2022-07-04 00:19:27 - train: epoch 0070, iter [00400, 05004], lr: 0.001000, loss: 0.9758
2022-07-04 00:20:01 - train: epoch 0070, iter [00500, 05004], lr: 0.001000, loss: 1.2106
2022-07-04 00:20:34 - train: epoch 0070, iter [00600, 05004], lr: 0.001000, loss: 1.1360
2022-07-04 00:21:06 - train: epoch 0070, iter [00700, 05004], lr: 0.001000, loss: 0.9656
2022-07-04 00:21:40 - train: epoch 0070, iter [00800, 05004], lr: 0.001000, loss: 1.0342
2022-07-04 00:22:13 - train: epoch 0070, iter [00900, 05004], lr: 0.001000, loss: 1.0147
2022-07-04 00:22:46 - train: epoch 0070, iter [01000, 05004], lr: 0.001000, loss: 0.8928
2022-07-04 00:23:19 - train: epoch 0070, iter [01100, 05004], lr: 0.001000, loss: 1.3073
2022-07-04 00:23:53 - train: epoch 0070, iter [01200, 05004], lr: 0.001000, loss: 1.0570
2022-07-04 00:24:25 - train: epoch 0070, iter [01300, 05004], lr: 0.001000, loss: 1.1860
2022-07-04 00:24:58 - train: epoch 0070, iter [01400, 05004], lr: 0.001000, loss: 0.9009
2022-07-04 00:25:31 - train: epoch 0070, iter [01500, 05004], lr: 0.001000, loss: 1.1300
2022-07-04 00:26:04 - train: epoch 0070, iter [01600, 05004], lr: 0.001000, loss: 1.1037
2022-07-04 00:26:37 - train: epoch 0070, iter [01700, 05004], lr: 0.001000, loss: 1.1598
2022-07-04 00:27:10 - train: epoch 0070, iter [01800, 05004], lr: 0.001000, loss: 0.9550
2022-07-04 00:27:43 - train: epoch 0070, iter [01900, 05004], lr: 0.001000, loss: 1.0193
2022-07-04 00:28:16 - train: epoch 0070, iter [02000, 05004], lr: 0.001000, loss: 1.0525
2022-07-04 00:28:49 - train: epoch 0070, iter [02100, 05004], lr: 0.001000, loss: 1.1542
2022-07-04 00:29:22 - train: epoch 0070, iter [02200, 05004], lr: 0.001000, loss: 0.9777
2022-07-04 00:29:55 - train: epoch 0070, iter [02300, 05004], lr: 0.001000, loss: 1.3435
2022-07-04 00:30:28 - train: epoch 0070, iter [02400, 05004], lr: 0.001000, loss: 1.1842
2022-07-04 00:31:01 - train: epoch 0070, iter [02500, 05004], lr: 0.001000, loss: 1.1249
2022-07-04 00:31:35 - train: epoch 0070, iter [02600, 05004], lr: 0.001000, loss: 1.0397
2022-07-04 00:32:08 - train: epoch 0070, iter [02700, 05004], lr: 0.001000, loss: 1.0810
2022-07-04 00:32:41 - train: epoch 0070, iter [02800, 05004], lr: 0.001000, loss: 1.2120
2022-07-04 00:33:14 - train: epoch 0070, iter [02900, 05004], lr: 0.001000, loss: 1.1310
2022-07-04 00:33:47 - train: epoch 0070, iter [03000, 05004], lr: 0.001000, loss: 0.8494
2022-07-04 00:34:20 - train: epoch 0070, iter [03100, 05004], lr: 0.001000, loss: 0.8741
2022-07-04 00:34:53 - train: epoch 0070, iter [03200, 05004], lr: 0.001000, loss: 1.1337
2022-07-04 00:35:26 - train: epoch 0070, iter [03300, 05004], lr: 0.001000, loss: 0.9539
2022-07-04 00:35:59 - train: epoch 0070, iter [03400, 05004], lr: 0.001000, loss: 1.2163
2022-07-04 00:36:33 - train: epoch 0070, iter [03500, 05004], lr: 0.001000, loss: 1.1258
2022-07-04 00:37:06 - train: epoch 0070, iter [03600, 05004], lr: 0.001000, loss: 1.0348
2022-07-04 00:37:40 - train: epoch 0070, iter [03700, 05004], lr: 0.001000, loss: 1.1600
2022-07-04 00:38:13 - train: epoch 0070, iter [03800, 05004], lr: 0.001000, loss: 1.0369
2022-07-04 00:38:46 - train: epoch 0070, iter [03900, 05004], lr: 0.001000, loss: 0.8900
2022-07-04 00:39:18 - train: epoch 0070, iter [04000, 05004], lr: 0.001000, loss: 0.9379
2022-07-04 00:39:52 - train: epoch 0070, iter [04100, 05004], lr: 0.001000, loss: 1.0802
2022-07-04 00:40:25 - train: epoch 0070, iter [04200, 05004], lr: 0.001000, loss: 0.9987
2022-07-04 00:40:58 - train: epoch 0070, iter [04300, 05004], lr: 0.001000, loss: 0.9039
2022-07-04 00:41:31 - train: epoch 0070, iter [04400, 05004], lr: 0.001000, loss: 1.0981
2022-07-04 00:42:05 - train: epoch 0070, iter [04500, 05004], lr: 0.001000, loss: 0.8332
2022-07-04 00:42:38 - train: epoch 0070, iter [04600, 05004], lr: 0.001000, loss: 0.8889
2022-07-04 00:43:12 - train: epoch 0070, iter [04700, 05004], lr: 0.001000, loss: 1.0845
2022-07-04 00:43:43 - train: epoch 0070, iter [04800, 05004], lr: 0.001000, loss: 1.0178
2022-07-04 00:44:17 - train: epoch 0070, iter [04900, 05004], lr: 0.001000, loss: 1.2068
2022-07-04 00:44:48 - train: epoch 0070, iter [05000, 05004], lr: 0.001000, loss: 1.1078
2022-07-04 00:44:49 - train: epoch 070, train_loss: 1.0674
2022-07-04 00:46:02 - eval: epoch: 070, acc1: 73.036%, acc5: 91.120%, test_loss: 1.0794, per_image_load_time: 2.538ms, per_image_inference_time: 0.294ms
2022-07-04 00:46:02 - until epoch: 070, best_acc1: 73.100%
2022-07-04 00:46:02 - epoch 071 lr: 0.001000
2022-07-04 00:46:40 - train: epoch 0071, iter [00100, 05004], lr: 0.001000, loss: 0.9139
2022-07-04 00:47:13 - train: epoch 0071, iter [00200, 05004], lr: 0.001000, loss: 0.9223
2022-07-04 00:47:46 - train: epoch 0071, iter [00300, 05004], lr: 0.001000, loss: 1.1051
2022-07-04 00:48:19 - train: epoch 0071, iter [00400, 05004], lr: 0.001000, loss: 0.9603
2022-07-04 00:48:51 - train: epoch 0071, iter [00500, 05004], lr: 0.001000, loss: 1.0790
2022-07-04 00:49:24 - train: epoch 0071, iter [00600, 05004], lr: 0.001000, loss: 1.0721
2022-07-04 00:49:57 - train: epoch 0071, iter [00700, 05004], lr: 0.001000, loss: 1.1303
2022-07-04 00:50:29 - train: epoch 0071, iter [00800, 05004], lr: 0.001000, loss: 1.1858
2022-07-04 00:51:03 - train: epoch 0071, iter [00900, 05004], lr: 0.001000, loss: 1.1770
2022-07-04 00:51:36 - train: epoch 0071, iter [01000, 05004], lr: 0.001000, loss: 1.0041
2022-07-04 00:52:09 - train: epoch 0071, iter [01100, 05004], lr: 0.001000, loss: 1.3117
2022-07-04 00:52:41 - train: epoch 0071, iter [01200, 05004], lr: 0.001000, loss: 1.1378
2022-07-04 00:53:16 - train: epoch 0071, iter [01300, 05004], lr: 0.001000, loss: 0.9641
2022-07-04 00:53:48 - train: epoch 0071, iter [01400, 05004], lr: 0.001000, loss: 0.9463
2022-07-04 00:54:21 - train: epoch 0071, iter [01500, 05004], lr: 0.001000, loss: 0.8506
2022-07-04 00:54:54 - train: epoch 0071, iter [01600, 05004], lr: 0.001000, loss: 0.9881
2022-07-04 00:55:27 - train: epoch 0071, iter [01700, 05004], lr: 0.001000, loss: 0.8839
2022-07-04 00:56:01 - train: epoch 0071, iter [01800, 05004], lr: 0.001000, loss: 1.2402
2022-07-04 00:56:33 - train: epoch 0071, iter [01900, 05004], lr: 0.001000, loss: 1.0412
2022-07-04 00:57:07 - train: epoch 0071, iter [02000, 05004], lr: 0.001000, loss: 1.1234
2022-07-04 00:57:40 - train: epoch 0071, iter [02100, 05004], lr: 0.001000, loss: 0.9864
2022-07-04 00:58:13 - train: epoch 0071, iter [02200, 05004], lr: 0.001000, loss: 0.8954
2022-07-04 00:58:47 - train: epoch 0071, iter [02300, 05004], lr: 0.001000, loss: 0.9944
2022-07-04 00:59:19 - train: epoch 0071, iter [02400, 05004], lr: 0.001000, loss: 0.8891
2022-07-04 00:59:53 - train: epoch 0071, iter [02500, 05004], lr: 0.001000, loss: 1.2048
2022-07-04 01:00:26 - train: epoch 0071, iter [02600, 05004], lr: 0.001000, loss: 0.9899
2022-07-04 01:00:58 - train: epoch 0071, iter [02700, 05004], lr: 0.001000, loss: 1.0120
2022-07-04 01:01:32 - train: epoch 0071, iter [02800, 05004], lr: 0.001000, loss: 1.1144
2022-07-04 01:02:04 - train: epoch 0071, iter [02900, 05004], lr: 0.001000, loss: 1.1162
2022-07-04 01:02:39 - train: epoch 0071, iter [03000, 05004], lr: 0.001000, loss: 1.1261
2022-07-04 01:03:11 - train: epoch 0071, iter [03100, 05004], lr: 0.001000, loss: 1.1860
2022-07-04 01:03:44 - train: epoch 0071, iter [03200, 05004], lr: 0.001000, loss: 1.0631
2022-07-04 01:04:17 - train: epoch 0071, iter [03300, 05004], lr: 0.001000, loss: 1.0707
2022-07-04 01:04:51 - train: epoch 0071, iter [03400, 05004], lr: 0.001000, loss: 0.9260
2022-07-04 01:05:24 - train: epoch 0071, iter [03500, 05004], lr: 0.001000, loss: 1.0863
2022-07-04 01:05:57 - train: epoch 0071, iter [03600, 05004], lr: 0.001000, loss: 1.0749
2022-07-04 01:06:30 - train: epoch 0071, iter [03700, 05004], lr: 0.001000, loss: 1.1004
2022-07-04 01:07:04 - train: epoch 0071, iter [03800, 05004], lr: 0.001000, loss: 0.9895
2022-07-04 01:07:36 - train: epoch 0071, iter [03900, 05004], lr: 0.001000, loss: 0.9415
2022-07-04 01:08:10 - train: epoch 0071, iter [04000, 05004], lr: 0.001000, loss: 1.0611
2022-07-04 01:08:43 - train: epoch 0071, iter [04100, 05004], lr: 0.001000, loss: 1.2430
2022-07-04 01:09:16 - train: epoch 0071, iter [04200, 05004], lr: 0.001000, loss: 1.2374
2022-07-04 01:09:50 - train: epoch 0071, iter [04300, 05004], lr: 0.001000, loss: 0.8646
2022-07-04 01:10:22 - train: epoch 0071, iter [04400, 05004], lr: 0.001000, loss: 1.0589
2022-07-04 01:10:55 - train: epoch 0071, iter [04500, 05004], lr: 0.001000, loss: 1.0350
2022-07-04 01:11:29 - train: epoch 0071, iter [04600, 05004], lr: 0.001000, loss: 1.1695
2022-07-04 01:12:03 - train: epoch 0071, iter [04700, 05004], lr: 0.001000, loss: 0.9492
2022-07-04 01:12:36 - train: epoch 0071, iter [04800, 05004], lr: 0.001000, loss: 0.7942
2022-07-04 01:13:10 - train: epoch 0071, iter [04900, 05004], lr: 0.001000, loss: 1.1945
2022-07-04 01:13:41 - train: epoch 0071, iter [05000, 05004], lr: 0.001000, loss: 0.9115
2022-07-04 01:13:42 - train: epoch 071, train_loss: 1.0616
2022-07-04 01:14:55 - eval: epoch: 071, acc1: 73.134%, acc5: 91.214%, test_loss: 1.0771, per_image_load_time: 2.569ms, per_image_inference_time: 0.275ms
2022-07-04 01:14:55 - until epoch: 071, best_acc1: 73.134%
2022-07-04 01:14:55 - epoch 072 lr: 0.001000
2022-07-04 01:15:34 - train: epoch 0072, iter [00100, 05004], lr: 0.001000, loss: 1.0624
2022-07-04 01:16:06 - train: epoch 0072, iter [00200, 05004], lr: 0.001000, loss: 1.1067
2022-07-04 01:16:39 - train: epoch 0072, iter [00300, 05004], lr: 0.001000, loss: 0.9371
2022-07-04 01:17:11 - train: epoch 0072, iter [00400, 05004], lr: 0.001000, loss: 1.1068
2022-07-04 01:17:44 - train: epoch 0072, iter [00500, 05004], lr: 0.001000, loss: 0.9586
2022-07-04 01:18:18 - train: epoch 0072, iter [00600, 05004], lr: 0.001000, loss: 1.1084
2022-07-04 01:18:51 - train: epoch 0072, iter [00700, 05004], lr: 0.001000, loss: 1.0825
2022-07-04 01:19:23 - train: epoch 0072, iter [00800, 05004], lr: 0.001000, loss: 1.2385
2022-07-04 01:19:56 - train: epoch 0072, iter [00900, 05004], lr: 0.001000, loss: 1.0409
2022-07-04 01:20:29 - train: epoch 0072, iter [01000, 05004], lr: 0.001000, loss: 0.9613
2022-07-04 01:21:02 - train: epoch 0072, iter [01100, 05004], lr: 0.001000, loss: 1.1223
2022-07-04 01:21:35 - train: epoch 0072, iter [01200, 05004], lr: 0.001000, loss: 0.9208
2022-07-04 01:22:08 - train: epoch 0072, iter [01300, 05004], lr: 0.001000, loss: 1.1125
2022-07-04 01:22:41 - train: epoch 0072, iter [01400, 05004], lr: 0.001000, loss: 1.1203
2022-07-04 01:23:15 - train: epoch 0072, iter [01500, 05004], lr: 0.001000, loss: 1.1507
2022-07-04 01:23:47 - train: epoch 0072, iter [01600, 05004], lr: 0.001000, loss: 1.1022
2022-07-04 01:24:21 - train: epoch 0072, iter [01700, 05004], lr: 0.001000, loss: 1.0484
2022-07-04 01:24:53 - train: epoch 0072, iter [01800, 05004], lr: 0.001000, loss: 1.0523
2022-07-04 01:25:27 - train: epoch 0072, iter [01900, 05004], lr: 0.001000, loss: 1.2031
2022-07-04 01:26:00 - train: epoch 0072, iter [02000, 05004], lr: 0.001000, loss: 1.0449
2022-07-04 01:26:34 - train: epoch 0072, iter [02100, 05004], lr: 0.001000, loss: 1.2119
2022-07-04 01:27:07 - train: epoch 0072, iter [02200, 05004], lr: 0.001000, loss: 1.0171
2022-07-04 01:27:41 - train: epoch 0072, iter [02300, 05004], lr: 0.001000, loss: 1.0786
2022-07-04 01:28:13 - train: epoch 0072, iter [02400, 05004], lr: 0.001000, loss: 1.1552
2022-07-04 01:28:46 - train: epoch 0072, iter [02500, 05004], lr: 0.001000, loss: 1.0347
2022-07-04 01:29:19 - train: epoch 0072, iter [02600, 05004], lr: 0.001000, loss: 1.2079
2022-07-04 01:29:53 - train: epoch 0072, iter [02700, 05004], lr: 0.001000, loss: 1.1712
2022-07-04 01:30:27 - train: epoch 0072, iter [02800, 05004], lr: 0.001000, loss: 1.0754
2022-07-04 01:31:00 - train: epoch 0072, iter [02900, 05004], lr: 0.001000, loss: 1.0846
2022-07-04 01:31:33 - train: epoch 0072, iter [03000, 05004], lr: 0.001000, loss: 1.0221
2022-07-04 01:32:06 - train: epoch 0072, iter [03100, 05004], lr: 0.001000, loss: 1.0158
2022-07-04 01:32:39 - train: epoch 0072, iter [03200, 05004], lr: 0.001000, loss: 1.0329
2022-07-04 01:33:13 - train: epoch 0072, iter [03300, 05004], lr: 0.001000, loss: 1.1341
2022-07-04 01:33:46 - train: epoch 0072, iter [03400, 05004], lr: 0.001000, loss: 1.0273
2022-07-04 01:34:19 - train: epoch 0072, iter [03500, 05004], lr: 0.001000, loss: 1.1190
2022-07-04 01:34:52 - train: epoch 0072, iter [03600, 05004], lr: 0.001000, loss: 1.1237
2022-07-04 01:35:25 - train: epoch 0072, iter [03700, 05004], lr: 0.001000, loss: 1.0423
2022-07-04 01:35:58 - train: epoch 0072, iter [03800, 05004], lr: 0.001000, loss: 1.0212
2022-07-04 01:36:31 - train: epoch 0072, iter [03900, 05004], lr: 0.001000, loss: 0.9652
2022-07-04 01:37:04 - train: epoch 0072, iter [04000, 05004], lr: 0.001000, loss: 0.9723
2022-07-04 01:37:38 - train: epoch 0072, iter [04100, 05004], lr: 0.001000, loss: 1.0918
2022-07-04 01:38:11 - train: epoch 0072, iter [04200, 05004], lr: 0.001000, loss: 0.9320
2022-07-04 01:38:45 - train: epoch 0072, iter [04300, 05004], lr: 0.001000, loss: 1.0151
2022-07-04 01:39:18 - train: epoch 0072, iter [04400, 05004], lr: 0.001000, loss: 1.1168
2022-07-04 01:39:51 - train: epoch 0072, iter [04500, 05004], lr: 0.001000, loss: 0.9958
2022-07-04 01:40:24 - train: epoch 0072, iter [04600, 05004], lr: 0.001000, loss: 0.9254
2022-07-04 01:40:58 - train: epoch 0072, iter [04700, 05004], lr: 0.001000, loss: 1.0923
2022-07-04 01:41:30 - train: epoch 0072, iter [04800, 05004], lr: 0.001000, loss: 1.3507
2022-07-04 01:42:04 - train: epoch 0072, iter [04900, 05004], lr: 0.001000, loss: 0.9861
2022-07-04 01:42:36 - train: epoch 0072, iter [05000, 05004], lr: 0.001000, loss: 0.9485
2022-07-04 01:42:36 - train: epoch 072, train_loss: 1.0565
2022-07-04 01:43:50 - eval: epoch: 072, acc1: 73.138%, acc5: 91.262%, test_loss: 1.0780, per_image_load_time: 2.585ms, per_image_inference_time: 0.273ms
2022-07-04 01:43:50 - until epoch: 072, best_acc1: 73.138%
2022-07-04 01:43:50 - epoch 073 lr: 0.001000
2022-07-04 01:44:28 - train: epoch 0073, iter [00100, 05004], lr: 0.001000, loss: 1.2320
2022-07-04 01:45:01 - train: epoch 0073, iter [00200, 05004], lr: 0.001000, loss: 1.0236
2022-07-04 01:45:33 - train: epoch 0073, iter [00300, 05004], lr: 0.001000, loss: 1.1312
2022-07-04 01:46:07 - train: epoch 0073, iter [00400, 05004], lr: 0.001000, loss: 0.8514
2022-07-04 01:46:40 - train: epoch 0073, iter [00500, 05004], lr: 0.001000, loss: 0.9257
2022-07-04 01:47:12 - train: epoch 0073, iter [00600, 05004], lr: 0.001000, loss: 1.0548
2022-07-04 01:47:46 - train: epoch 0073, iter [00700, 05004], lr: 0.001000, loss: 1.0595
2022-07-04 01:48:18 - train: epoch 0073, iter [00800, 05004], lr: 0.001000, loss: 1.0667
2022-07-04 01:48:52 - train: epoch 0073, iter [00900, 05004], lr: 0.001000, loss: 1.0674
2022-07-04 01:49:24 - train: epoch 0073, iter [01000, 05004], lr: 0.001000, loss: 1.0955
2022-07-04 01:49:58 - train: epoch 0073, iter [01100, 05004], lr: 0.001000, loss: 1.2386
2022-07-04 01:50:31 - train: epoch 0073, iter [01200, 05004], lr: 0.001000, loss: 1.0424
2022-07-04 01:51:03 - train: epoch 0073, iter [01300, 05004], lr: 0.001000, loss: 1.2660
2022-07-04 01:51:36 - train: epoch 0073, iter [01400, 05004], lr: 0.001000, loss: 1.1199
2022-07-04 01:52:10 - train: epoch 0073, iter [01500, 05004], lr: 0.001000, loss: 1.0044
2022-07-04 01:52:42 - train: epoch 0073, iter [01600, 05004], lr: 0.001000, loss: 0.9217
2022-07-04 01:53:15 - train: epoch 0073, iter [01700, 05004], lr: 0.001000, loss: 1.2748
2022-07-04 01:53:49 - train: epoch 0073, iter [01800, 05004], lr: 0.001000, loss: 0.9242
2022-07-04 01:54:21 - train: epoch 0073, iter [01900, 05004], lr: 0.001000, loss: 1.0939
2022-07-04 01:54:55 - train: epoch 0073, iter [02000, 05004], lr: 0.001000, loss: 0.9352
2022-07-04 01:55:28 - train: epoch 0073, iter [02100, 05004], lr: 0.001000, loss: 1.1032
2022-07-04 01:56:02 - train: epoch 0073, iter [02200, 05004], lr: 0.001000, loss: 1.1027
2022-07-04 01:56:35 - train: epoch 0073, iter [02300, 05004], lr: 0.001000, loss: 1.0779
2022-07-04 01:57:08 - train: epoch 0073, iter [02400, 05004], lr: 0.001000, loss: 1.2009
2022-07-04 01:57:42 - train: epoch 0073, iter [02500, 05004], lr: 0.001000, loss: 0.9295
2022-07-04 01:58:15 - train: epoch 0073, iter [02600, 05004], lr: 0.001000, loss: 1.0766
2022-07-04 01:58:49 - train: epoch 0073, iter [02700, 05004], lr: 0.001000, loss: 1.0867
2022-07-04 01:59:22 - train: epoch 0073, iter [02800, 05004], lr: 0.001000, loss: 1.0922
2022-07-04 01:59:55 - train: epoch 0073, iter [02900, 05004], lr: 0.001000, loss: 1.1833
2022-07-04 02:00:28 - train: epoch 0073, iter [03000, 05004], lr: 0.001000, loss: 0.8927
2022-07-04 02:01:01 - train: epoch 0073, iter [03100, 05004], lr: 0.001000, loss: 0.9721
2022-07-04 02:01:34 - train: epoch 0073, iter [03200, 05004], lr: 0.001000, loss: 0.9122
2022-07-04 02:02:07 - train: epoch 0073, iter [03300, 05004], lr: 0.001000, loss: 0.8204
2022-07-04 02:02:41 - train: epoch 0073, iter [03400, 05004], lr: 0.001000, loss: 1.0866
2022-07-04 02:03:14 - train: epoch 0073, iter [03500, 05004], lr: 0.001000, loss: 0.9846
2022-07-04 02:03:47 - train: epoch 0073, iter [03600, 05004], lr: 0.001000, loss: 0.9505
2022-07-04 02:04:21 - train: epoch 0073, iter [03700, 05004], lr: 0.001000, loss: 1.0439
2022-07-04 02:04:54 - train: epoch 0073, iter [03800, 05004], lr: 0.001000, loss: 1.1519
2022-07-04 02:05:26 - train: epoch 0073, iter [03900, 05004], lr: 0.001000, loss: 0.8442
2022-07-04 02:06:00 - train: epoch 0073, iter [04000, 05004], lr: 0.001000, loss: 1.2486
2022-07-04 02:06:33 - train: epoch 0073, iter [04100, 05004], lr: 0.001000, loss: 1.0713
2022-07-04 02:07:07 - train: epoch 0073, iter [04200, 05004], lr: 0.001000, loss: 1.1290
2022-07-04 02:07:39 - train: epoch 0073, iter [04300, 05004], lr: 0.001000, loss: 1.1865
2022-07-04 02:08:13 - train: epoch 0073, iter [04400, 05004], lr: 0.001000, loss: 1.1713
2022-07-04 02:08:47 - train: epoch 0073, iter [04500, 05004], lr: 0.001000, loss: 0.8863
2022-07-04 02:09:20 - train: epoch 0073, iter [04600, 05004], lr: 0.001000, loss: 1.3256
2022-07-04 02:09:53 - train: epoch 0073, iter [04700, 05004], lr: 0.001000, loss: 0.8543
2022-07-04 02:10:25 - train: epoch 0073, iter [04800, 05004], lr: 0.001000, loss: 0.9425
2022-07-04 02:11:00 - train: epoch 0073, iter [04900, 05004], lr: 0.001000, loss: 0.9680
2022-07-04 02:11:31 - train: epoch 0073, iter [05000, 05004], lr: 0.001000, loss: 1.0665
2022-07-04 02:11:32 - train: epoch 073, train_loss: 1.0518
2022-07-04 02:12:46 - eval: epoch: 073, acc1: 73.170%, acc5: 91.264%, test_loss: 1.0780, per_image_load_time: 2.602ms, per_image_inference_time: 0.274ms
2022-07-04 02:12:46 - until epoch: 073, best_acc1: 73.170%
2022-07-04 02:12:46 - epoch 074 lr: 0.001000
2022-07-04 02:13:24 - train: epoch 0074, iter [00100, 05004], lr: 0.001000, loss: 1.0160
2022-07-04 02:13:58 - train: epoch 0074, iter [00200, 05004], lr: 0.001000, loss: 1.1962
2022-07-04 02:14:30 - train: epoch 0074, iter [00300, 05004], lr: 0.001000, loss: 0.9705
2022-07-04 02:15:03 - train: epoch 0074, iter [00400, 05004], lr: 0.001000, loss: 1.2554
2022-07-04 02:15:35 - train: epoch 0074, iter [00500, 05004], lr: 0.001000, loss: 1.0333
2022-07-04 02:16:09 - train: epoch 0074, iter [00600, 05004], lr: 0.001000, loss: 1.0202
2022-07-04 02:16:42 - train: epoch 0074, iter [00700, 05004], lr: 0.001000, loss: 0.9606
2022-07-04 02:17:15 - train: epoch 0074, iter [00800, 05004], lr: 0.001000, loss: 1.1428
2022-07-04 02:17:48 - train: epoch 0074, iter [00900, 05004], lr: 0.001000, loss: 1.0907
2022-07-04 02:18:21 - train: epoch 0074, iter [01000, 05004], lr: 0.001000, loss: 1.3247
2022-07-04 02:18:53 - train: epoch 0074, iter [01100, 05004], lr: 0.001000, loss: 0.9672
2022-07-04 02:19:27 - train: epoch 0074, iter [01200, 05004], lr: 0.001000, loss: 1.0828
2022-07-04 02:19:59 - train: epoch 0074, iter [01300, 05004], lr: 0.001000, loss: 1.0274
2022-07-04 02:20:33 - train: epoch 0074, iter [01400, 05004], lr: 0.001000, loss: 0.9478
2022-07-04 02:21:06 - train: epoch 0074, iter [01500, 05004], lr: 0.001000, loss: 1.0335
2022-07-04 02:21:39 - train: epoch 0074, iter [01600, 05004], lr: 0.001000, loss: 0.8429
2022-07-04 02:22:11 - train: epoch 0074, iter [01700, 05004], lr: 0.001000, loss: 1.1123
2022-07-04 02:22:45 - train: epoch 0074, iter [01800, 05004], lr: 0.001000, loss: 1.1658
2022-07-04 02:23:19 - train: epoch 0074, iter [01900, 05004], lr: 0.001000, loss: 1.2136
2022-07-04 02:23:51 - train: epoch 0074, iter [02000, 05004], lr: 0.001000, loss: 0.9028
2022-07-04 02:24:25 - train: epoch 0074, iter [02100, 05004], lr: 0.001000, loss: 0.9745
2022-07-04 02:24:58 - train: epoch 0074, iter [02200, 05004], lr: 0.001000, loss: 1.3152
2022-07-04 02:25:31 - train: epoch 0074, iter [02300, 05004], lr: 0.001000, loss: 0.9852
2022-07-04 02:26:04 - train: epoch 0074, iter [02400, 05004], lr: 0.001000, loss: 1.0812
2022-07-04 02:26:36 - train: epoch 0074, iter [02500, 05004], lr: 0.001000, loss: 1.0911
2022-07-04 02:27:09 - train: epoch 0074, iter [02600, 05004], lr: 0.001000, loss: 0.9275
2022-07-04 02:27:42 - train: epoch 0074, iter [02700, 05004], lr: 0.001000, loss: 1.1907
2022-07-04 02:28:16 - train: epoch 0074, iter [02800, 05004], lr: 0.001000, loss: 1.2674
2022-07-04 02:28:49 - train: epoch 0074, iter [02900, 05004], lr: 0.001000, loss: 0.8784
2022-07-04 02:29:22 - train: epoch 0074, iter [03000, 05004], lr: 0.001000, loss: 1.2136
2022-07-04 02:29:55 - train: epoch 0074, iter [03100, 05004], lr: 0.001000, loss: 1.0356
2022-07-04 02:30:28 - train: epoch 0074, iter [03200, 05004], lr: 0.001000, loss: 0.9784
2022-07-04 02:31:01 - train: epoch 0074, iter [03300, 05004], lr: 0.001000, loss: 1.1309
2022-07-04 02:31:34 - train: epoch 0074, iter [03400, 05004], lr: 0.001000, loss: 1.0928
2022-07-04 02:32:07 - train: epoch 0074, iter [03500, 05004], lr: 0.001000, loss: 1.0686
2022-07-04 02:32:41 - train: epoch 0074, iter [03600, 05004], lr: 0.001000, loss: 1.2365
2022-07-04 02:33:14 - train: epoch 0074, iter [03700, 05004], lr: 0.001000, loss: 1.0166
2022-07-04 02:33:47 - train: epoch 0074, iter [03800, 05004], lr: 0.001000, loss: 0.9569
2022-07-04 02:34:20 - train: epoch 0074, iter [03900, 05004], lr: 0.001000, loss: 0.9292
2022-07-04 02:34:54 - train: epoch 0074, iter [04000, 05004], lr: 0.001000, loss: 1.1266
2022-07-04 02:35:26 - train: epoch 0074, iter [04100, 05004], lr: 0.001000, loss: 1.0558
2022-07-04 02:36:00 - train: epoch 0074, iter [04200, 05004], lr: 0.001000, loss: 0.9381
2022-07-04 02:36:32 - train: epoch 0074, iter [04300, 05004], lr: 0.001000, loss: 0.9357
2022-07-04 02:37:06 - train: epoch 0074, iter [04400, 05004], lr: 0.001000, loss: 0.9832
2022-07-04 02:37:39 - train: epoch 0074, iter [04500, 05004], lr: 0.001000, loss: 1.0730
2022-07-04 02:38:13 - train: epoch 0074, iter [04600, 05004], lr: 0.001000, loss: 1.1471
2022-07-04 02:38:46 - train: epoch 0074, iter [04700, 05004], lr: 0.001000, loss: 0.9722
2022-07-04 02:39:19 - train: epoch 0074, iter [04800, 05004], lr: 0.001000, loss: 1.0613
2022-07-04 02:39:52 - train: epoch 0074, iter [04900, 05004], lr: 0.001000, loss: 1.1875
2022-07-04 02:40:24 - train: epoch 0074, iter [05000, 05004], lr: 0.001000, loss: 1.1912
2022-07-04 02:40:25 - train: epoch 074, train_loss: 1.0501
2022-07-04 02:41:38 - eval: epoch: 074, acc1: 73.304%, acc5: 91.204%, test_loss: 1.0790, per_image_load_time: 2.555ms, per_image_inference_time: 0.294ms
2022-07-04 02:41:39 - until epoch: 074, best_acc1: 73.304%
2022-07-04 02:41:39 - epoch 075 lr: 0.001000
2022-07-04 02:42:17 - train: epoch 0075, iter [00100, 05004], lr: 0.001000, loss: 1.2082
2022-07-04 02:42:51 - train: epoch 0075, iter [00200, 05004], lr: 0.001000, loss: 0.9933
2022-07-04 02:43:22 - train: epoch 0075, iter [00300, 05004], lr: 0.001000, loss: 1.1851
2022-07-04 02:43:56 - train: epoch 0075, iter [00400, 05004], lr: 0.001000, loss: 0.8632
2022-07-04 02:44:29 - train: epoch 0075, iter [00500, 05004], lr: 0.001000, loss: 1.1081
2022-07-04 02:45:02 - train: epoch 0075, iter [00600, 05004], lr: 0.001000, loss: 1.0771
2022-07-04 02:45:35 - train: epoch 0075, iter [00700, 05004], lr: 0.001000, loss: 1.3323
2022-07-04 02:46:07 - train: epoch 0075, iter [00800, 05004], lr: 0.001000, loss: 1.0368
2022-07-04 02:46:41 - train: epoch 0075, iter [00900, 05004], lr: 0.001000, loss: 1.0228
2022-07-04 02:47:13 - train: epoch 0075, iter [01000, 05004], lr: 0.001000, loss: 0.9479
2022-07-04 02:47:47 - train: epoch 0075, iter [01100, 05004], lr: 0.001000, loss: 1.1466
2022-07-04 02:48:19 - train: epoch 0075, iter [01200, 05004], lr: 0.001000, loss: 0.9978
2022-07-04 02:48:53 - train: epoch 0075, iter [01300, 05004], lr: 0.001000, loss: 1.0279
2022-07-04 02:49:25 - train: epoch 0075, iter [01400, 05004], lr: 0.001000, loss: 1.0458
2022-07-04 02:49:59 - train: epoch 0075, iter [01500, 05004], lr: 0.001000, loss: 1.0224
2022-07-04 02:50:31 - train: epoch 0075, iter [01600, 05004], lr: 0.001000, loss: 1.0069
2022-07-04 02:51:05 - train: epoch 0075, iter [01700, 05004], lr: 0.001000, loss: 1.0601
2022-07-04 02:51:37 - train: epoch 0075, iter [01800, 05004], lr: 0.001000, loss: 1.0189
2022-07-04 02:52:11 - train: epoch 0075, iter [01900, 05004], lr: 0.001000, loss: 1.0972
2022-07-04 02:52:44 - train: epoch 0075, iter [02000, 05004], lr: 0.001000, loss: 0.9578
2022-07-04 02:53:17 - train: epoch 0075, iter [02100, 05004], lr: 0.001000, loss: 1.2503
2022-07-04 02:53:49 - train: epoch 0075, iter [02200, 05004], lr: 0.001000, loss: 0.9748
2022-07-04 02:54:22 - train: epoch 0075, iter [02300, 05004], lr: 0.001000, loss: 0.9713
2022-07-04 02:54:56 - train: epoch 0075, iter [02400, 05004], lr: 0.001000, loss: 1.2505
2022-07-04 02:55:28 - train: epoch 0075, iter [02500, 05004], lr: 0.001000, loss: 0.9270
2022-07-04 02:56:01 - train: epoch 0075, iter [02600, 05004], lr: 0.001000, loss: 1.1435
2022-07-04 02:56:35 - train: epoch 0075, iter [02700, 05004], lr: 0.001000, loss: 1.0728
2022-07-04 02:57:07 - train: epoch 0075, iter [02800, 05004], lr: 0.001000, loss: 0.8749
2022-07-04 02:57:40 - train: epoch 0075, iter [02900, 05004], lr: 0.001000, loss: 1.1761
2022-07-04 02:58:13 - train: epoch 0075, iter [03000, 05004], lr: 0.001000, loss: 1.2033
2022-07-04 02:58:46 - train: epoch 0075, iter [03100, 05004], lr: 0.001000, loss: 1.0271
2022-07-04 02:59:19 - train: epoch 0075, iter [03200, 05004], lr: 0.001000, loss: 0.8774
2022-07-04 02:59:53 - train: epoch 0075, iter [03300, 05004], lr: 0.001000, loss: 1.0482
2022-07-04 03:00:25 - train: epoch 0075, iter [03400, 05004], lr: 0.001000, loss: 0.9878
2022-07-04 03:00:58 - train: epoch 0075, iter [03500, 05004], lr: 0.001000, loss: 1.0153
2022-07-04 03:01:31 - train: epoch 0075, iter [03600, 05004], lr: 0.001000, loss: 1.0994
2022-07-04 03:02:04 - train: epoch 0075, iter [03700, 05004], lr: 0.001000, loss: 1.0694
2022-07-04 03:02:38 - train: epoch 0075, iter [03800, 05004], lr: 0.001000, loss: 0.9736
2022-07-04 03:03:11 - train: epoch 0075, iter [03900, 05004], lr: 0.001000, loss: 0.9798
2022-07-04 03:03:44 - train: epoch 0075, iter [04000, 05004], lr: 0.001000, loss: 1.0395
2022-07-04 03:04:17 - train: epoch 0075, iter [04100, 05004], lr: 0.001000, loss: 0.9635
2022-07-04 03:04:50 - train: epoch 0075, iter [04200, 05004], lr: 0.001000, loss: 0.8972
2022-07-04 03:05:23 - train: epoch 0075, iter [04300, 05004], lr: 0.001000, loss: 1.1750
2022-07-04 03:05:56 - train: epoch 0075, iter [04400, 05004], lr: 0.001000, loss: 1.0133
2022-07-04 03:06:29 - train: epoch 0075, iter [04500, 05004], lr: 0.001000, loss: 1.0528
2022-07-04 03:07:03 - train: epoch 0075, iter [04600, 05004], lr: 0.001000, loss: 0.9728
2022-07-04 03:07:35 - train: epoch 0075, iter [04700, 05004], lr: 0.001000, loss: 1.3212
2022-07-04 03:08:08 - train: epoch 0075, iter [04800, 05004], lr: 0.001000, loss: 1.0729
2022-07-04 03:08:41 - train: epoch 0075, iter [04900, 05004], lr: 0.001000, loss: 0.9405
2022-07-04 03:09:12 - train: epoch 0075, iter [05000, 05004], lr: 0.001000, loss: 0.9086
2022-07-04 03:09:13 - train: epoch 075, train_loss: 1.0439
2022-07-04 03:10:27 - eval: epoch: 075, acc1: 73.318%, acc5: 91.144%, test_loss: 1.0785, per_image_load_time: 2.588ms, per_image_inference_time: 0.263ms
2022-07-04 03:10:27 - until epoch: 075, best_acc1: 73.318%
2022-07-04 03:10:27 - epoch 076 lr: 0.001000
2022-07-04 03:11:05 - train: epoch 0076, iter [00100, 05004], lr: 0.001000, loss: 1.0743
2022-07-04 03:11:38 - train: epoch 0076, iter [00200, 05004], lr: 0.001000, loss: 0.9844
2022-07-04 03:12:11 - train: epoch 0076, iter [00300, 05004], lr: 0.001000, loss: 1.0798
2022-07-04 03:12:43 - train: epoch 0076, iter [00400, 05004], lr: 0.001000, loss: 1.1399
2022-07-04 03:13:16 - train: epoch 0076, iter [00500, 05004], lr: 0.001000, loss: 1.0242
2022-07-04 03:13:49 - train: epoch 0076, iter [00600, 05004], lr: 0.001000, loss: 0.9959
2022-07-04 03:14:22 - train: epoch 0076, iter [00700, 05004], lr: 0.001000, loss: 0.9512
2022-07-04 03:14:56 - train: epoch 0076, iter [00800, 05004], lr: 0.001000, loss: 1.0562
2022-07-04 03:15:29 - train: epoch 0076, iter [00900, 05004], lr: 0.001000, loss: 0.8260
2022-07-04 03:16:02 - train: epoch 0076, iter [01000, 05004], lr: 0.001000, loss: 1.0325
2022-07-04 03:16:35 - train: epoch 0076, iter [01100, 05004], lr: 0.001000, loss: 0.8553
2022-07-04 03:17:08 - train: epoch 0076, iter [01200, 05004], lr: 0.001000, loss: 1.0276
2022-07-04 03:17:41 - train: epoch 0076, iter [01300, 05004], lr: 0.001000, loss: 1.1101
2022-07-04 03:18:14 - train: epoch 0076, iter [01400, 05004], lr: 0.001000, loss: 0.8799
2022-07-04 03:18:48 - train: epoch 0076, iter [01500, 05004], lr: 0.001000, loss: 1.0508
2022-07-04 03:19:21 - train: epoch 0076, iter [01600, 05004], lr: 0.001000, loss: 1.1411
2022-07-04 03:19:54 - train: epoch 0076, iter [01700, 05004], lr: 0.001000, loss: 1.0375
2022-07-04 03:20:27 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 0.9746
2022-07-04 03:21:00 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 1.1116
2022-07-04 03:21:33 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 1.0515
2022-07-04 03:22:06 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 1.0833
2022-07-04 03:22:39 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 1.0084
2022-07-04 03:23:13 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 0.9427
2022-07-04 03:23:45 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 1.2400
2022-07-04 03:24:19 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 1.0806
2022-07-04 03:24:51 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 1.2475
2022-07-04 03:25:24 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 1.1812
2022-07-04 03:25:57 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 0.8552
2022-07-04 03:26:31 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 1.0210
2022-07-04 03:27:05 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 0.9107
2022-07-04 03:27:37 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 1.0922
2022-07-04 03:28:10 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 0.9550
2022-07-04 03:28:43 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 1.0738
2022-07-04 03:29:16 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 1.0751
2022-07-04 03:29:50 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 0.8696
2022-07-04 03:30:24 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 1.0616
2022-07-04 03:30:57 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 1.0445
2022-07-04 03:31:30 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 0.9885
2022-07-04 03:32:04 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 0.9390
2022-07-04 03:32:36 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 0.9844
2022-07-04 03:33:11 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 1.1281
2022-07-04 03:33:44 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 1.1788
2022-07-04 03:34:17 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 1.0590
2022-07-04 03:34:50 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 1.0785
2022-07-04 03:35:23 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 1.0001
2022-07-04 03:35:56 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 0.9827
2022-07-04 03:36:30 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 1.3415
2022-07-04 03:37:04 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 0.8961
2022-07-04 03:37:36 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 1.0558
2022-07-04 03:38:09 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 1.0237
2022-07-04 03:38:10 - train: epoch 076, train_loss: 1.0376
2022-07-04 03:39:23 - eval: epoch: 076, acc1: 73.294%, acc5: 91.290%, test_loss: 1.0771, per_image_load_time: 2.575ms, per_image_inference_time: 0.263ms
2022-07-04 03:39:24 - until epoch: 076, best_acc1: 73.318%
2022-07-04 03:39:24 - epoch 077 lr: 0.001000
2022-07-04 03:40:02 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 1.2269
2022-07-04 03:40:35 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 1.0587
2022-07-04 03:41:08 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 0.9449
2022-07-04 03:41:40 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 1.0523
2022-07-04 03:42:13 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 0.9199
2022-07-04 03:42:46 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 0.8758
2022-07-04 03:43:18 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 1.0035
2022-07-04 03:43:52 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 1.1712
2022-07-04 03:44:25 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 1.2290
2022-07-04 03:44:57 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 0.9410
2022-07-04 03:45:31 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 1.0255
2022-07-04 03:46:04 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 1.3169
2022-07-04 03:46:38 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 0.9293
2022-07-04 03:47:10 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 0.9593
2022-07-04 03:47:44 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 1.0925
2022-07-04 03:48:17 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 0.9494
2022-07-04 03:48:50 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 1.0555
2022-07-04 03:49:23 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 0.8821
2022-07-04 03:49:55 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 0.8885
2022-07-04 03:50:29 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 0.8724
2022-07-04 03:51:02 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 1.0557
2022-07-04 03:51:36 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 0.9863
2022-07-04 03:52:09 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 1.1103
2022-07-04 03:52:42 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 0.9058
2022-07-04 03:53:14 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 1.0377
2022-07-04 03:53:48 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 0.8037
2022-07-04 03:54:20 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 1.1569
2022-07-04 03:54:54 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 1.1325
2022-07-04 03:55:27 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 1.0278
2022-07-04 03:56:00 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 0.9554
2022-07-04 03:56:34 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 0.9187
2022-07-04 03:57:06 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 1.1682
2022-07-04 03:57:40 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 1.0891
2022-07-04 03:58:13 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 0.9864
2022-07-04 03:58:47 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 0.8998
2022-07-04 03:59:21 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 0.7612
2022-07-04 03:59:53 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 0.9893
2022-07-04 04:00:27 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 0.8176
2022-07-04 04:01:00 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 1.0062
2022-07-04 04:01:33 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 1.1635
2022-07-04 04:02:06 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 1.0257
2022-07-04 04:02:40 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 1.1050
2022-07-04 04:03:12 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 1.0791
2022-07-04 04:03:46 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 1.1414
2022-07-04 04:04:19 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 1.0947
2022-07-04 04:04:53 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 1.0929
2022-07-04 04:05:25 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 0.9262
2022-07-04 04:05:59 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 1.0192
2022-07-04 04:06:32 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 1.1699
2022-07-04 04:07:03 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 1.1190
2022-07-04 04:07:03 - train: epoch 077, train_loss: 1.0345
2022-07-04 04:08:17 - eval: epoch: 077, acc1: 73.068%, acc5: 91.200%, test_loss: 1.0797, per_image_load_time: 2.577ms, per_image_inference_time: 0.273ms
2022-07-04 04:08:17 - until epoch: 077, best_acc1: 73.318%
2022-07-04 04:08:17 - epoch 078 lr: 0.001000
2022-07-04 04:08:55 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 1.0007
2022-07-04 04:09:28 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 1.2617
2022-07-04 04:10:00 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 1.1227
2022-07-04 04:10:35 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 0.9816
2022-07-04 04:11:07 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 1.0064
2022-07-04 04:11:40 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 0.8805
2022-07-04 04:12:12 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 1.1568
2022-07-04 04:12:45 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 1.2567
2022-07-04 04:13:18 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 1.0398
2022-07-04 04:13:51 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 1.1368
2022-07-04 04:14:24 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 0.8676
2022-07-04 04:14:57 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 0.9250
2022-07-04 04:15:30 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 1.1156
2022-07-04 04:16:03 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 0.8372
2022-07-04 04:16:36 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 1.1160
2022-07-04 04:17:09 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 1.1107
2022-07-04 04:17:42 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 1.0839
2022-07-04 04:18:15 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 0.9661
2022-07-04 04:18:49 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 1.0135
2022-07-04 04:19:22 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 1.0850
2022-07-04 04:19:55 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 1.1619
2022-07-04 04:20:28 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 0.9152
2022-07-04 04:21:01 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 1.1456
2022-07-04 04:21:34 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 1.1102
2022-07-04 04:22:08 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 1.0455
2022-07-04 04:22:41 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 0.9380
2022-07-04 04:23:14 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 1.0401
2022-07-04 04:23:48 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 0.9300
2022-07-04 04:24:21 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 1.1159
2022-07-04 04:24:54 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 0.9032
2022-07-04 04:25:28 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 1.0970
2022-07-04 04:26:01 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 0.9468
2022-07-04 04:26:34 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 1.0885
2022-07-04 04:27:07 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 0.8925
2022-07-04 04:27:41 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 1.1820
2022-07-04 04:28:14 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 1.1659
2022-07-04 04:28:48 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 1.0467
2022-07-04 04:29:20 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 1.0182
2022-07-04 04:29:55 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 1.1053
2022-07-04 04:30:27 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 1.0771
2022-07-04 04:31:01 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 1.0297
2022-07-04 04:31:34 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 1.1491
2022-07-04 04:32:06 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 1.0638
2022-07-04 04:32:41 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 1.0128
2022-07-04 04:33:14 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 1.0895
2022-07-04 04:33:47 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 0.9961
2022-07-04 04:34:21 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 1.0027
2022-07-04 04:34:54 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 1.0903
2022-07-04 04:35:26 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 0.9847
2022-07-04 04:35:59 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 0.9936
2022-07-04 04:36:00 - train: epoch 078, train_loss: 1.0324
2022-07-04 04:37:13 - eval: epoch: 078, acc1: 73.178%, acc5: 91.190%, test_loss: 1.0816, per_image_load_time: 2.585ms, per_image_inference_time: 0.273ms
2022-07-04 04:37:13 - until epoch: 078, best_acc1: 73.318%
2022-07-04 04:37:13 - epoch 079 lr: 0.001000
2022-07-04 04:37:51 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 1.0246
2022-07-04 04:38:25 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 0.8886
2022-07-04 04:38:57 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 1.1364
2022-07-04 04:39:30 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 0.9407
2022-07-04 04:40:03 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 0.9591
2022-07-04 04:40:36 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 0.9570
2022-07-04 04:41:09 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 0.9078
2022-07-04 04:41:42 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 1.1436
2022-07-04 04:42:15 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 0.9917
2022-07-04 04:42:49 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 1.0162
2022-07-04 04:43:21 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 0.9912
2022-07-04 04:43:54 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 1.0926
2022-07-04 04:44:27 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 1.1486
2022-07-04 04:45:00 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 1.0370
2022-07-04 04:45:34 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 1.0680
2022-07-04 04:46:08 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 0.7654
2022-07-04 04:46:41 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 1.0149
2022-07-04 04:47:14 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 0.9500
2022-07-04 04:47:48 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 1.2273
2022-07-04 04:48:20 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 1.1278
2022-07-04 04:48:54 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 0.8623
2022-07-04 04:49:28 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 1.0269
2022-07-04 04:50:01 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 0.9968
2022-07-04 04:50:33 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 0.9387
2022-07-04 04:51:06 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 1.0302
2022-07-04 04:51:39 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 0.9861
2022-07-04 04:52:13 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 0.9635
2022-07-04 04:52:46 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 0.8376
2022-07-04 04:53:20 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 1.0532
2022-07-04 04:53:53 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 1.1930
2022-07-04 04:54:26 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 1.0932
2022-07-04 04:54:58 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 1.1837
2022-07-04 04:55:32 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 0.9730
2022-07-04 04:56:06 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 1.0757
2022-07-04 04:56:38 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 0.9793
2022-07-04 04:57:12 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 0.8787
2022-07-04 04:57:45 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 1.0073
2022-07-04 04:58:19 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 1.1665
2022-07-04 04:58:52 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 0.9144
2022-07-04 04:59:25 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 0.8865
2022-07-04 04:59:58 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 0.9674
2022-07-04 05:00:32 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 1.0263
2022-07-04 05:01:04 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 0.8854
2022-07-04 05:01:38 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 1.0583
2022-07-04 05:02:11 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 1.0187
2022-07-04 05:02:45 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 1.0720
2022-07-04 05:03:17 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 0.9444
2022-07-04 05:03:52 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 1.3305
2022-07-04 05:04:25 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 1.0814
2022-07-04 05:04:57 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 0.8758
2022-07-04 05:04:58 - train: epoch 079, train_loss: 1.0272
2022-07-04 05:06:11 - eval: epoch: 079, acc1: 73.328%, acc5: 91.294%, test_loss: 1.0795, per_image_load_time: 2.437ms, per_image_inference_time: 0.294ms
2022-07-04 05:06:12 - until epoch: 079, best_acc1: 73.328%
2022-07-04 05:06:12 - epoch 080 lr: 0.001000
2022-07-04 05:06:49 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 1.1399
2022-07-04 05:07:23 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 0.9295
2022-07-04 05:07:56 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 1.0588
2022-07-04 05:08:27 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 0.9517
2022-07-04 05:09:01 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 0.8692
2022-07-04 05:09:34 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 1.2157
2022-07-04 05:10:08 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 1.0654
2022-07-04 05:10:40 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 0.7534
2022-07-04 05:11:12 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 1.0116
2022-07-04 05:11:46 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 0.9748
2022-07-04 05:12:19 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 0.9637
2022-07-04 05:12:53 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 0.9804
2022-07-04 05:13:25 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 1.0227
2022-07-04 05:13:58 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 0.9236
2022-07-04 05:14:31 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 0.9629
2022-07-04 05:15:05 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 0.8410
2022-07-04 05:15:38 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 1.2418
2022-07-04 05:16:12 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 0.9539
2022-07-04 05:16:44 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 1.0408
2022-07-04 05:17:18 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 1.0022
2022-07-04 05:17:50 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 1.2754
2022-07-04 05:18:23 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 0.9894
2022-07-04 05:18:56 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 0.9936
2022-07-04 05:19:30 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 1.1781
2022-07-04 05:20:03 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 0.7507
2022-07-04 05:20:37 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 1.0425
2022-07-04 05:21:10 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 1.0334
2022-07-04 05:21:43 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 0.9477
2022-07-04 05:22:16 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 1.0363
2022-07-04 05:22:50 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 1.0879
2022-07-04 05:23:23 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 1.1389
2022-07-04 05:23:56 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 0.8481
2022-07-04 05:24:29 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 1.1027
2022-07-04 05:25:03 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 1.1302
2022-07-04 05:25:35 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 1.1141
2022-07-04 05:26:09 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 0.9586
2022-07-04 05:26:42 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 0.9524
2022-07-04 05:27:15 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 1.1669
2022-07-04 05:27:48 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 1.0588
2022-07-04 05:28:22 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 1.1382
2022-07-04 05:28:54 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 1.2017
2022-07-04 05:29:28 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 0.9853
2022-07-04 05:30:00 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 1.1963
2022-07-04 05:30:34 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 0.9904
2022-07-04 05:31:07 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 0.9611
2022-07-04 05:31:40 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 1.0198
2022-07-04 05:32:13 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 1.0881
2022-07-04 05:32:46 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 1.1877
2022-07-04 05:33:19 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 1.1937
2022-07-04 05:33:51 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 1.0028
2022-07-04 05:33:52 - train: epoch 080, train_loss: 1.0266
2022-07-04 05:35:05 - eval: epoch: 080, acc1: 73.332%, acc5: 91.284%, test_loss: 1.0804, per_image_load_time: 2.583ms, per_image_inference_time: 0.262ms
2022-07-04 05:35:06 - until epoch: 080, best_acc1: 73.332%
2022-07-04 05:35:06 - epoch 081 lr: 0.001000
2022-07-04 05:35:44 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 0.8554
2022-07-04 05:36:16 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 0.8372
2022-07-04 05:36:50 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 0.9604
2022-07-04 05:37:22 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 1.1454
2022-07-04 05:37:55 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 1.0023
2022-07-04 05:38:28 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 1.0058
2022-07-04 05:39:01 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 0.8442
2022-07-04 05:39:34 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 1.2059
2022-07-04 05:40:07 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 1.0746
2022-07-04 05:40:40 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 0.9123
2022-07-04 05:41:13 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 0.9236
2022-07-04 05:41:47 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 0.9791
2022-07-04 05:42:20 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 1.0632
2022-07-04 05:42:53 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 0.7570
2022-07-04 05:43:27 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 1.3615
2022-07-04 05:44:00 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 0.8987
2022-07-04 05:44:33 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 0.9877
2022-07-04 05:45:07 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 1.0696
2022-07-04 05:45:40 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 1.0972
2022-07-04 05:46:13 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 1.1003
2022-07-04 05:46:47 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 1.0018
2022-07-04 05:47:20 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 1.0094
2022-07-04 05:47:52 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 0.8568
2022-07-04 05:48:26 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 0.9698
2022-07-04 05:48:59 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 1.0701
2022-07-04 05:49:32 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 0.9472
2022-07-04 05:50:05 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 1.0915
2022-07-04 05:50:39 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 1.0305
2022-07-04 05:51:12 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 1.0320
2022-07-04 05:51:45 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 1.0122
2022-07-04 05:52:19 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 0.8959
2022-07-04 05:52:52 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 0.9162
2022-07-04 05:53:26 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 1.0417
2022-07-04 05:53:58 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 1.0777
2022-07-04 05:54:31 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 0.9461
2022-07-04 05:55:05 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 0.8177
2022-07-04 05:55:39 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 1.0639
2022-07-04 05:56:11 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 0.9347
2022-07-04 05:56:45 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 1.0121
2022-07-04 05:57:18 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 0.9322
2022-07-04 05:57:51 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 0.9846
2022-07-04 05:58:24 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 0.9945
2022-07-04 05:58:58 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 1.1272
2022-07-04 05:59:31 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 0.9974
2022-07-04 06:00:03 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 1.0099
2022-07-04 06:00:36 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 1.0721
2022-07-04 06:01:10 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 1.0951
2022-07-04 06:01:43 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 1.1251
2022-07-04 06:02:16 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 1.0372
2022-07-04 06:02:48 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 0.9324
2022-07-04 06:02:49 - train: epoch 081, train_loss: 1.0215
2022-07-04 06:04:02 - eval: epoch: 081, acc1: 73.224%, acc5: 91.242%, test_loss: 1.0813, per_image_load_time: 2.487ms, per_image_inference_time: 0.274ms
2022-07-04 06:04:02 - until epoch: 081, best_acc1: 73.332%
2022-07-04 06:04:02 - epoch 082 lr: 0.001000
2022-07-04 06:04:40 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 0.9508
2022-07-04 06:05:14 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 0.9572
2022-07-04 06:05:48 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 1.0035
2022-07-04 06:06:21 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 1.0851
2022-07-04 06:06:54 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 0.9937
2022-07-04 06:07:26 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 0.9583
2022-07-04 06:07:59 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 0.9924
2022-07-04 06:08:32 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 1.1287
2022-07-04 06:09:05 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 0.9775
2022-07-04 06:09:39 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 0.8763
2022-07-04 06:10:11 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 1.1628
2022-07-04 06:10:44 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 1.1866
2022-07-04 06:11:18 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 1.0503
2022-07-04 06:11:51 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 0.8102
2022-07-04 06:12:24 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 1.0463
2022-07-04 06:12:58 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 0.9740
2022-07-04 06:13:32 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 0.9327
2022-07-04 06:14:04 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 0.8880
2022-07-04 06:14:38 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 0.9581
2022-07-04 06:15:11 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 0.7423
2022-07-04 06:15:45 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 0.9913
2022-07-04 06:16:18 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 0.9906
2022-07-04 06:16:52 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 1.0139
2022-07-04 06:17:24 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 1.1325
2022-07-04 06:17:58 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 1.0552
2022-07-04 06:18:30 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 0.7979
2022-07-04 06:19:05 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 0.8739
2022-07-04 06:19:38 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 0.9659
2022-07-04 06:20:12 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 0.9477
2022-07-04 06:20:45 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 0.8964
2022-07-04 06:21:18 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 1.1277
2022-07-04 06:21:51 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 1.0886
2022-07-04 06:22:25 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 1.0127
2022-07-04 06:22:59 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 1.0163
2022-07-04 06:23:32 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 0.8841
2022-07-04 06:24:04 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 0.9545
2022-07-04 06:24:38 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 0.9599
2022-07-04 06:25:11 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 1.1098
2022-07-04 06:25:45 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 1.0141
2022-07-04 06:26:18 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 1.1849
2022-07-04 06:26:51 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 1.1777
2022-07-04 06:27:25 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 1.1347
2022-07-04 06:27:58 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 1.0196
2022-07-04 06:28:31 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 0.9338
2022-07-04 06:29:04 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 0.9592
2022-07-04 06:29:38 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 1.0438
2022-07-04 06:30:12 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 1.0153
2022-07-04 06:30:44 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 0.9628
2022-07-04 06:31:18 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 1.0540
2022-07-04 06:31:49 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 0.9821
2022-07-04 06:31:50 - train: epoch 082, train_loss: 1.0187
2022-07-04 06:33:03 - eval: epoch: 082, acc1: 73.276%, acc5: 91.284%, test_loss: 1.0809, per_image_load_time: 2.199ms, per_image_inference_time: 0.273ms
2022-07-04 06:33:03 - until epoch: 082, best_acc1: 73.332%
2022-07-04 06:33:03 - epoch 083 lr: 0.001000
2022-07-04 06:33:41 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 1.0155
2022-07-04 06:34:15 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 0.8388
2022-07-04 06:34:47 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 1.0971
2022-07-04 06:35:20 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 1.0125
2022-07-04 06:35:53 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 1.1735
2022-07-04 06:36:26 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 0.8406
2022-07-04 06:36:59 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 0.8537
2022-07-04 06:37:31 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 1.0574
2022-07-04 06:38:05 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 1.0705
2022-07-04 06:38:38 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 0.9211
2022-07-04 06:39:11 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 1.0185
2022-07-04 06:39:45 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 0.9535
2022-07-04 06:40:17 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 1.2290
2022-07-04 06:40:50 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 1.1896
2022-07-04 06:41:24 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 0.7948
2022-07-04 06:41:57 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 1.0021
2022-07-04 06:42:30 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 0.9717
2022-07-04 06:43:02 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 1.1717
2022-07-04 06:43:35 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 0.9828
2022-07-04 06:44:09 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 0.7517
2022-07-04 06:44:43 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 1.0770
2022-07-04 06:45:15 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 0.7510
2022-07-04 06:45:48 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 0.9953
2022-07-04 06:46:22 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 0.8818
2022-07-04 06:46:55 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 0.9093
2022-07-04 06:47:28 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 1.1032
2022-07-04 06:48:01 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 0.9508
2022-07-04 06:48:34 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 0.9845
2022-07-04 06:49:07 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 1.0500
2022-07-04 06:49:41 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 1.1305
2022-07-04 06:50:13 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 1.0540
2022-07-04 06:50:47 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 1.0405
2022-07-04 06:51:21 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 1.2752
2022-07-04 06:51:54 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 0.8164
2022-07-04 06:52:27 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 0.9754
2022-07-04 06:53:00 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 0.9473
2022-07-04 06:53:33 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 0.8751
2022-07-04 06:54:07 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 0.9062
2022-07-04 06:54:40 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 1.0800
2022-07-04 06:55:13 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 1.0331
2022-07-04 06:55:46 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 1.0802
2022-07-04 06:56:19 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 1.4247
2022-07-04 06:56:52 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 0.9519
2022-07-04 06:57:25 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 1.0350
2022-07-04 06:57:59 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 1.0203
2022-07-04 06:58:32 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 1.0199
2022-07-04 06:59:05 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 1.3083
2022-07-04 06:59:38 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 1.0810
2022-07-04 07:00:13 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 1.0462
2022-07-04 07:00:43 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 1.1324
2022-07-04 07:00:44 - train: epoch 083, train_loss: 1.0142
2022-07-04 07:01:57 - eval: epoch: 083, acc1: 73.318%, acc5: 91.362%, test_loss: 1.0819, per_image_load_time: 2.474ms, per_image_inference_time: 0.275ms
2022-07-04 07:01:58 - until epoch: 083, best_acc1: 73.332%
2022-07-04 07:01:58 - epoch 084 lr: 0.001000
2022-07-04 07:02:36 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 1.0461
2022-07-04 07:03:09 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 1.0497
2022-07-04 07:03:41 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 0.9387
2022-07-04 07:04:15 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 0.8782
2022-07-04 07:04:47 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 1.0382
2022-07-04 07:05:20 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 1.0065
2022-07-04 07:05:52 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 1.1462
2022-07-04 07:06:26 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 1.1353
2022-07-04 07:06:58 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 1.0101
2022-07-04 07:07:31 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 1.0400
2022-07-04 07:08:04 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 0.9536
2022-07-04 07:08:37 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 1.2172
2022-07-04 07:09:10 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 1.1687
2022-07-04 07:09:43 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 1.0209
2022-07-04 07:10:16 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 1.1884
2022-07-04 07:10:49 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 0.9052
2022-07-04 07:11:22 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 1.1493
2022-07-04 07:11:55 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 0.9647
2022-07-04 07:12:29 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 1.0681
2022-07-04 07:13:01 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 0.9441
2022-07-04 07:13:34 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 0.8368
2022-07-04 07:14:08 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 0.9853
2022-07-04 07:14:41 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 0.9000
2022-07-04 07:15:15 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 1.0337
2022-07-04 07:15:48 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 0.9713
2022-07-04 07:16:20 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 0.8060
2022-07-04 07:16:53 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 1.0573
2022-07-04 07:17:27 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 1.0162
2022-07-04 07:18:01 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 1.0631
2022-07-04 07:18:34 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 1.1446
2022-07-04 07:19:07 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 0.9199
2022-07-04 07:19:40 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 0.8375
2022-07-04 07:20:13 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 1.0177
2022-07-04 07:20:48 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 0.8925
2022-07-04 07:21:20 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 0.9676
2022-07-04 07:21:53 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 0.9572
2022-07-04 07:22:26 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 1.0746
2022-07-04 07:23:00 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 1.0779
2022-07-04 07:23:33 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 1.2486
2022-07-04 07:24:07 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 1.0389
2022-07-04 07:24:39 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 0.8770
2022-07-04 07:25:12 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 1.1776
2022-07-04 07:25:45 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 1.0602
2022-07-04 07:26:19 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 1.2275
2022-07-04 07:26:53 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 1.1033
2022-07-04 07:27:26 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 1.0711
2022-07-04 07:27:58 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 0.8800
2022-07-04 07:28:32 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 0.8565
2022-07-04 07:29:05 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 0.9116
2022-07-04 07:29:37 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 1.1306
2022-07-04 07:29:38 - train: epoch 084, train_loss: 1.0138
2022-07-04 07:30:51 - eval: epoch: 084, acc1: 73.368%, acc5: 91.326%, test_loss: 1.0811, per_image_load_time: 2.534ms, per_image_inference_time: 0.293ms
2022-07-04 07:30:51 - until epoch: 084, best_acc1: 73.368%
2022-07-04 07:30:51 - epoch 085 lr: 0.001000
2022-07-04 07:31:29 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 0.9417
2022-07-04 07:32:02 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 0.9556
2022-07-04 07:32:34 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 1.0281
2022-07-04 07:33:08 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 1.0229
2022-07-04 07:33:40 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 1.1485
2022-07-04 07:34:13 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 0.7515
2022-07-04 07:34:46 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 0.9254
2022-07-04 07:35:20 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 0.8979
2022-07-04 07:35:52 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 0.8726
2022-07-04 07:36:24 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 0.9838
2022-07-04 07:36:58 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 0.9877
2022-07-04 07:37:31 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 1.0258
2022-07-04 07:38:04 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 1.0177
2022-07-04 07:38:38 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 0.9724
2022-07-04 07:39:10 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 1.0003
2022-07-04 07:39:43 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 0.9237
2022-07-04 07:40:17 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 1.2423
2022-07-04 07:40:49 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 0.6627
2022-07-04 07:41:23 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 0.8619
2022-07-04 07:41:56 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 0.9081
2022-07-04 07:42:29 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 0.8411
2022-07-04 07:43:02 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 0.8473
2022-07-04 07:43:36 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 0.8988
2022-07-04 07:44:09 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 0.9625
2022-07-04 07:44:42 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 1.1865
2022-07-04 07:45:15 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 1.0539
2022-07-04 07:45:48 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 0.8576
2022-07-04 07:46:21 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 0.9937
2022-07-04 07:46:55 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 1.1067
2022-07-04 07:47:28 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 1.1501
2022-07-04 07:48:01 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 0.9860
2022-07-04 07:48:34 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 0.9432
2022-07-04 07:49:08 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 0.9778
2022-07-04 07:49:41 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 1.0820
2022-07-04 07:50:14 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 1.1247
2022-07-04 07:50:48 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 1.0627
2022-07-04 07:51:22 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 0.7505
2022-07-04 07:51:55 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 1.0948
2022-07-04 07:52:28 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 0.9574
2022-07-04 07:53:01 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 1.0564
2022-07-04 07:53:34 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 1.1584
2022-07-04 07:54:08 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 1.1274
2022-07-04 07:54:41 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 1.0164
2022-07-04 07:55:15 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 0.9735
2022-07-04 07:55:48 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 1.0879
2022-07-04 07:56:20 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 0.9930
2022-07-04 07:56:54 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 1.2170
2022-07-04 07:57:28 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 0.8370
2022-07-04 07:58:00 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 1.0129
2022-07-04 07:58:32 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 0.8496
2022-07-04 07:58:33 - train: epoch 085, train_loss: 1.0115
2022-07-04 07:59:46 - eval: epoch: 085, acc1: 73.244%, acc5: 91.294%, test_loss: 1.0816, per_image_load_time: 2.585ms, per_image_inference_time: 0.275ms
2022-07-04 07:59:47 - until epoch: 085, best_acc1: 73.368%
2022-07-04 23:03:10 - epoch 086 lr: 0.001000
2022-07-04 23:03:48 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 1.0218
2022-07-04 23:04:20 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 0.8586
2022-07-04 23:04:54 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 1.1398
2022-07-04 23:05:26 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 1.1674
2022-07-04 23:06:00 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 0.9224
2022-07-04 23:06:32 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 1.0581
2022-07-04 23:07:05 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 0.8293
2022-07-04 23:07:39 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 0.8577
2022-07-04 23:08:11 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 0.9128
2022-07-04 23:08:44 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 1.0566
2022-07-04 23:09:17 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 0.9395
2022-07-04 23:09:51 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 1.1289
2022-07-04 23:10:23 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 0.9691
2022-07-04 23:10:57 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 1.0997
2022-07-04 23:11:30 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 0.8218
2022-07-04 23:12:03 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 0.8775
2022-07-04 23:12:36 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 1.1326
2022-07-04 23:13:09 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 1.1879
2022-07-04 23:13:42 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 1.0205
2022-07-04 23:14:15 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 0.9387
2022-07-04 23:14:48 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 0.8736
2022-07-04 23:15:22 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 0.8930
2022-07-04 23:15:54 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 1.0211
2022-07-04 23:16:28 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 1.2124
2022-07-04 23:17:01 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 1.0977
2022-07-04 23:17:34 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 0.9709
2022-07-04 23:18:06 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 0.9217
2022-07-04 23:18:40 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 1.1829
2022-07-04 23:19:12 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 0.8482
2022-07-04 23:19:46 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 0.8202
2022-07-04 23:20:20 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 0.9728
2022-07-04 23:20:53 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 1.1329
2022-07-04 23:21:27 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 1.0820
2022-07-04 23:21:59 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 1.0821
2022-07-04 23:22:33 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 1.1388
2022-07-04 23:23:06 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 1.1924
2022-07-04 23:23:40 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 1.1062
2022-07-04 23:24:11 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 0.9755
2022-07-04 23:24:46 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 0.8947
2022-07-04 23:25:19 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 1.0985
2022-07-04 23:25:52 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 0.8923
2022-07-04 23:26:26 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 0.9570
2022-07-04 23:26:59 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 0.9576
2022-07-04 23:27:32 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 1.0053
2022-07-04 23:28:06 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 0.8555
2022-07-04 23:28:40 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 0.9646
2022-07-04 23:29:12 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 1.0733
2022-07-04 23:29:47 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 0.9447
2022-07-04 23:30:19 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 1.1135
2022-07-04 23:30:51 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 1.0946
2022-07-04 23:30:52 - train: epoch 086, train_loss: 1.0079
2022-07-04 23:32:06 - eval: epoch: 086, acc1: 73.264%, acc5: 91.212%, test_loss: 1.0847, per_image_load_time: 2.577ms, per_image_inference_time: 0.271ms
2022-07-04 23:32:06 - until epoch: 086, best_acc1: 73.368%
2022-07-04 23:32:06 - epoch 087 lr: 0.001000
2022-07-04 23:32:44 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 1.0785
2022-07-04 23:33:17 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 0.8785
2022-07-04 23:33:50 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 0.9480
2022-07-04 23:34:23 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 0.9782
2022-07-04 23:34:56 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 0.8619
2022-07-04 23:35:29 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 0.9087
2022-07-04 23:36:01 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 0.9053
2022-07-04 23:36:35 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 0.9343
2022-07-04 23:37:09 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 0.8468
2022-07-04 23:37:42 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 0.8998
2022-07-04 23:38:15 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 0.9856
2022-07-04 23:38:48 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 0.9733
2022-07-04 23:39:22 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 1.2655
2022-07-04 23:39:55 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 0.7734
2022-07-04 23:40:28 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 0.8916
2022-07-04 23:41:01 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 0.8335
2022-07-04 23:41:35 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 1.1644
2022-07-04 23:42:08 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 1.1971
2022-07-04 23:42:41 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 1.0621
2022-07-04 23:43:14 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 1.1234
2022-07-04 23:43:47 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 0.9014
2022-07-04 23:44:21 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 1.2299
2022-07-04 23:44:53 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 1.2103
2022-07-04 23:45:26 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 1.0276
2022-07-04 23:46:00 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 1.0188
2022-07-04 23:46:33 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 0.9230
2022-07-04 23:47:07 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 0.8506
2022-07-04 23:47:40 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 0.8670
2022-07-04 23:48:12 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 0.8745
2022-07-04 23:48:46 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 0.9442
2022-07-04 23:49:20 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 1.0387
2022-07-04 23:49:53 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 0.9934
2022-07-04 23:50:26 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 0.9371
2022-07-04 23:50:59 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 0.9965
2022-07-04 23:51:32 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 0.8951
2022-07-04 23:52:06 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 0.8228
2022-07-04 23:52:39 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 0.7528
2022-07-04 23:53:11 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 0.9309
2022-07-04 23:53:45 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 0.8950
2022-07-04 23:54:18 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 0.9425
2022-07-04 23:54:52 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 0.9839
2022-07-04 23:55:24 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 1.1268
2022-07-04 23:55:59 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 1.0455
2022-07-04 23:56:31 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 0.9862
2022-07-04 23:57:05 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 1.0248
2022-07-04 23:57:38 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 1.0422
2022-07-04 23:58:12 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 1.0140
2022-07-04 23:58:45 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 0.9425
2022-07-04 23:59:19 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 0.8827
2022-07-04 23:59:50 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 1.0126
2022-07-04 23:59:50 - train: epoch 087, train_loss: 1.0071
2022-07-05 00:01:04 - eval: epoch: 087, acc1: 73.420%, acc5: 91.330%, test_loss: 1.0808, per_image_load_time: 2.449ms, per_image_inference_time: 0.261ms
2022-07-05 00:01:04 - until epoch: 087, best_acc1: 73.420%
2022-07-05 00:01:04 - epoch 088 lr: 0.001000
2022-07-05 00:01:43 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 1.0532
2022-07-05 00:02:15 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 1.1089
2022-07-05 00:02:48 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 1.0654
2022-07-05 00:03:21 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 1.1235
2022-07-05 00:03:54 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 1.0662
2022-07-05 00:04:26 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 0.9696
2022-07-05 00:05:00 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 1.0045
2022-07-05 00:05:33 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 1.1011
2022-07-05 00:06:06 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 0.9787
2022-07-05 00:06:39 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 0.9856
2022-07-05 00:07:12 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 0.9034
2022-07-05 00:07:45 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 1.1452
2022-07-05 00:08:19 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 1.1310
2022-07-05 00:08:52 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 0.9511
2022-07-05 00:09:26 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 1.1187
2022-07-05 00:09:58 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 0.9747
2022-07-05 00:10:33 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 1.0258
2022-07-05 00:11:06 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 0.8857
2022-07-05 00:11:40 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 1.0241
2022-07-05 00:12:12 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 0.8103
2022-07-05 00:12:46 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 0.9012
2022-07-05 00:13:19 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 1.0272
2022-07-05 00:13:52 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 0.9545
2022-07-05 00:14:25 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 1.0898
2022-07-05 00:14:58 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 1.2090
2022-07-05 00:15:32 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 1.0758
2022-07-05 00:16:05 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 1.0514
2022-07-05 00:16:39 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 1.0280
2022-07-05 00:17:12 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 0.8921
2022-07-05 00:17:45 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 1.0701
2022-07-05 00:18:19 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 0.8995
2022-07-05 00:18:51 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 0.8556
2022-07-05 00:19:25 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 0.9576
2022-07-05 00:19:58 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 0.7942
2022-07-05 00:20:32 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 0.8739
2022-07-05 00:21:05 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 0.9697
2022-07-05 00:21:38 - train: epoch 0088, iter [03700, 05004], lr: 0.001000, loss: 1.0992
2022-07-05 00:22:13 - train: epoch 0088, iter [03800, 05004], lr: 0.001000, loss: 1.0635
2022-07-05 00:22:45 - train: epoch 0088, iter [03900, 05004], lr: 0.001000, loss: 0.9860
2022-07-05 00:23:19 - train: epoch 0088, iter [04000, 05004], lr: 0.001000, loss: 0.9850
2022-07-05 00:23:51 - train: epoch 0088, iter [04100, 05004], lr: 0.001000, loss: 0.8984
2022-07-05 00:24:24 - train: epoch 0088, iter [04200, 05004], lr: 0.001000, loss: 0.8354
2022-07-05 00:24:58 - train: epoch 0088, iter [04300, 05004], lr: 0.001000, loss: 1.1138
2022-07-05 00:25:31 - train: epoch 0088, iter [04400, 05004], lr: 0.001000, loss: 1.1087
2022-07-05 00:26:05 - train: epoch 0088, iter [04500, 05004], lr: 0.001000, loss: 0.9998
2022-07-05 00:26:38 - train: epoch 0088, iter [04600, 05004], lr: 0.001000, loss: 1.1019
2022-07-05 00:27:11 - train: epoch 0088, iter [04700, 05004], lr: 0.001000, loss: 1.1204
2022-07-05 00:27:45 - train: epoch 0088, iter [04800, 05004], lr: 0.001000, loss: 1.2209
2022-07-05 00:28:18 - train: epoch 0088, iter [04900, 05004], lr: 0.001000, loss: 0.9570
2022-07-05 00:28:49 - train: epoch 0088, iter [05000, 05004], lr: 0.001000, loss: 0.8863
2022-07-05 00:28:51 - train: epoch 088, train_loss: 1.0033
2022-07-05 00:30:04 - eval: epoch: 088, acc1: 73.458%, acc5: 91.370%, test_loss: 1.0783, per_image_load_time: 2.592ms, per_image_inference_time: 0.256ms
2022-07-05 00:30:05 - until epoch: 088, best_acc1: 73.458%
2022-07-05 00:30:05 - epoch 089 lr: 0.001000
2022-07-05 00:30:43 - train: epoch 0089, iter [00100, 05004], lr: 0.001000, loss: 0.9274
2022-07-05 00:31:16 - train: epoch 0089, iter [00200, 05004], lr: 0.001000, loss: 0.9263
2022-07-05 00:31:49 - train: epoch 0089, iter [00300, 05004], lr: 0.001000, loss: 1.0311
2022-07-05 00:32:21 - train: epoch 0089, iter [00400, 05004], lr: 0.001000, loss: 1.0329
2022-07-05 00:32:54 - train: epoch 0089, iter [00500, 05004], lr: 0.001000, loss: 0.9121
2022-07-05 00:33:25 - train: epoch 0089, iter [00600, 05004], lr: 0.001000, loss: 1.0981
2022-07-05 00:33:59 - train: epoch 0089, iter [00700, 05004], lr: 0.001000, loss: 0.9581
2022-07-05 00:34:32 - train: epoch 0089, iter [00800, 05004], lr: 0.001000, loss: 1.2233
2022-07-05 00:35:05 - train: epoch 0089, iter [00900, 05004], lr: 0.001000, loss: 0.7832
2022-07-05 00:35:38 - train: epoch 0089, iter [01000, 05004], lr: 0.001000, loss: 1.1042
2022-07-05 00:36:11 - train: epoch 0089, iter [01100, 05004], lr: 0.001000, loss: 0.9116
2022-07-05 00:36:44 - train: epoch 0089, iter [01200, 05004], lr: 0.001000, loss: 1.1504
2022-07-05 00:37:17 - train: epoch 0089, iter [01300, 05004], lr: 0.001000, loss: 0.8670
2022-07-05 00:37:51 - train: epoch 0089, iter [01400, 05004], lr: 0.001000, loss: 1.1132
2022-07-05 00:38:24 - train: epoch 0089, iter [01500, 05004], lr: 0.001000, loss: 0.9201
2022-07-05 00:38:57 - train: epoch 0089, iter [01600, 05004], lr: 0.001000, loss: 0.8327
2022-07-05 00:39:31 - train: epoch 0089, iter [01700, 05004], lr: 0.001000, loss: 1.0531
2022-07-05 00:40:04 - train: epoch 0089, iter [01800, 05004], lr: 0.001000, loss: 0.8724
2022-07-05 00:40:36 - train: epoch 0089, iter [01900, 05004], lr: 0.001000, loss: 0.9412
2022-07-05 00:41:11 - train: epoch 0089, iter [02000, 05004], lr: 0.001000, loss: 0.9364
2022-07-05 00:41:43 - train: epoch 0089, iter [02100, 05004], lr: 0.001000, loss: 1.0039
2022-07-05 00:42:17 - train: epoch 0089, iter [02200, 05004], lr: 0.001000, loss: 1.1539
2022-07-05 00:42:50 - train: epoch 0089, iter [02300, 05004], lr: 0.001000, loss: 0.8929
2022-07-05 00:43:23 - train: epoch 0089, iter [02400, 05004], lr: 0.001000, loss: 1.0379
2022-07-05 00:43:57 - train: epoch 0089, iter [02500, 05004], lr: 0.001000, loss: 1.1673
2022-07-05 00:44:30 - train: epoch 0089, iter [02600, 05004], lr: 0.001000, loss: 0.8757
2022-07-05 00:45:02 - train: epoch 0089, iter [02700, 05004], lr: 0.001000, loss: 0.9260
2022-07-05 00:45:36 - train: epoch 0089, iter [02800, 05004], lr: 0.001000, loss: 0.9657
2022-07-05 00:46:09 - train: epoch 0089, iter [02900, 05004], lr: 0.001000, loss: 0.9825
2022-07-05 00:46:43 - train: epoch 0089, iter [03000, 05004], lr: 0.001000, loss: 0.8772
2022-07-05 00:47:16 - train: epoch 0089, iter [03100, 05004], lr: 0.001000, loss: 0.9300
2022-07-05 00:47:49 - train: epoch 0089, iter [03200, 05004], lr: 0.001000, loss: 1.1073
2022-07-05 00:48:22 - train: epoch 0089, iter [03300, 05004], lr: 0.001000, loss: 1.0637
2022-07-05 00:48:55 - train: epoch 0089, iter [03400, 05004], lr: 0.001000, loss: 1.1353
2022-07-05 00:49:28 - train: epoch 0089, iter [03500, 05004], lr: 0.001000, loss: 0.7171
2022-07-05 00:50:01 - train: epoch 0089, iter [03600, 05004], lr: 0.001000, loss: 0.8744
2022-07-05 00:50:35 - train: epoch 0089, iter [03700, 05004], lr: 0.001000, loss: 0.9284
2022-07-05 00:51:08 - train: epoch 0089, iter [03800, 05004], lr: 0.001000, loss: 1.0056
2022-07-05 00:51:42 - train: epoch 0089, iter [03900, 05004], lr: 0.001000, loss: 1.1125
2022-07-05 00:52:15 - train: epoch 0089, iter [04000, 05004], lr: 0.001000, loss: 0.9887
2022-07-05 00:52:48 - train: epoch 0089, iter [04100, 05004], lr: 0.001000, loss: 1.0856
2022-07-05 00:53:22 - train: epoch 0089, iter [04200, 05004], lr: 0.001000, loss: 1.1115
2022-07-05 00:53:55 - train: epoch 0089, iter [04300, 05004], lr: 0.001000, loss: 1.0189
2022-07-05 00:54:28 - train: epoch 0089, iter [04400, 05004], lr: 0.001000, loss: 0.9681
2022-07-05 00:55:01 - train: epoch 0089, iter [04500, 05004], lr: 0.001000, loss: 0.8670
2022-07-05 00:55:34 - train: epoch 0089, iter [04600, 05004], lr: 0.001000, loss: 0.9702
2022-07-05 00:56:08 - train: epoch 0089, iter [04700, 05004], lr: 0.001000, loss: 1.0641
2022-07-05 00:56:41 - train: epoch 0089, iter [04800, 05004], lr: 0.001000, loss: 0.9437
2022-07-05 00:57:14 - train: epoch 0089, iter [04900, 05004], lr: 0.001000, loss: 1.0572
2022-07-05 00:57:46 - train: epoch 0089, iter [05000, 05004], lr: 0.001000, loss: 0.8724
2022-07-05 00:57:47 - train: epoch 089, train_loss: 1.0008
2022-07-05 00:59:01 - eval: epoch: 089, acc1: 73.252%, acc5: 91.244%, test_loss: 1.0794, per_image_load_time: 2.534ms, per_image_inference_time: 0.275ms
2022-07-05 00:59:01 - until epoch: 089, best_acc1: 73.458%
2022-07-05 00:59:01 - epoch 090 lr: 0.001000
2022-07-05 00:59:39 - train: epoch 0090, iter [00100, 05004], lr: 0.001000, loss: 0.9277
2022-07-05 01:00:12 - train: epoch 0090, iter [00200, 05004], lr: 0.001000, loss: 1.0960
2022-07-05 01:00:44 - train: epoch 0090, iter [00300, 05004], lr: 0.001000, loss: 0.9172
2022-07-05 01:01:18 - train: epoch 0090, iter [00400, 05004], lr: 0.001000, loss: 1.1339
2022-07-05 01:01:51 - train: epoch 0090, iter [00500, 05004], lr: 0.001000, loss: 0.9943
2022-07-05 01:02:24 - train: epoch 0090, iter [00600, 05004], lr: 0.001000, loss: 1.1076
2022-07-05 01:02:57 - train: epoch 0090, iter [00700, 05004], lr: 0.001000, loss: 1.0539
2022-07-05 01:03:30 - train: epoch 0090, iter [00800, 05004], lr: 0.001000, loss: 1.0536
2022-07-05 01:04:04 - train: epoch 0090, iter [00900, 05004], lr: 0.001000, loss: 0.9019
2022-07-05 01:04:37 - train: epoch 0090, iter [01000, 05004], lr: 0.001000, loss: 0.9449
2022-07-05 01:05:11 - train: epoch 0090, iter [01100, 05004], lr: 0.001000, loss: 1.1227
2022-07-05 01:05:43 - train: epoch 0090, iter [01200, 05004], lr: 0.001000, loss: 0.9062
2022-07-05 01:06:17 - train: epoch 0090, iter [01300, 05004], lr: 0.001000, loss: 1.0166
2022-07-05 01:06:50 - train: epoch 0090, iter [01400, 05004], lr: 0.001000, loss: 1.0673
2022-07-05 01:07:23 - train: epoch 0090, iter [01500, 05004], lr: 0.001000, loss: 1.0495
2022-07-05 01:07:56 - train: epoch 0090, iter [01600, 05004], lr: 0.001000, loss: 0.9202
2022-07-05 01:08:29 - train: epoch 0090, iter [01700, 05004], lr: 0.001000, loss: 0.9634
2022-07-05 01:09:02 - train: epoch 0090, iter [01800, 05004], lr: 0.001000, loss: 0.9027
2022-07-05 01:09:35 - train: epoch 0090, iter [01900, 05004], lr: 0.001000, loss: 0.9154
2022-07-05 01:10:09 - train: epoch 0090, iter [02000, 05004], lr: 0.001000, loss: 0.9738
2022-07-05 01:10:41 - train: epoch 0090, iter [02100, 05004], lr: 0.001000, loss: 1.1261
2022-07-05 01:11:14 - train: epoch 0090, iter [02200, 05004], lr: 0.001000, loss: 1.0554
2022-07-05 01:11:48 - train: epoch 0090, iter [02300, 05004], lr: 0.001000, loss: 0.9333
2022-07-05 01:12:21 - train: epoch 0090, iter [02400, 05004], lr: 0.001000, loss: 0.9798
2022-07-05 01:12:55 - train: epoch 0090, iter [02500, 05004], lr: 0.001000, loss: 1.0687
2022-07-05 01:13:28 - train: epoch 0090, iter [02600, 05004], lr: 0.001000, loss: 0.9294
2022-07-05 01:14:01 - train: epoch 0090, iter [02700, 05004], lr: 0.001000, loss: 0.8684
2022-07-05 01:14:34 - train: epoch 0090, iter [02800, 05004], lr: 0.001000, loss: 0.9350
2022-07-05 01:15:07 - train: epoch 0090, iter [02900, 05004], lr: 0.001000, loss: 1.0858
2022-07-05 01:15:41 - train: epoch 0090, iter [03000, 05004], lr: 0.001000, loss: 0.8791
2022-07-05 01:16:15 - train: epoch 0090, iter [03100, 05004], lr: 0.001000, loss: 0.8775
2022-07-05 01:16:48 - train: epoch 0090, iter [03200, 05004], lr: 0.001000, loss: 0.7930
2022-07-05 01:17:20 - train: epoch 0090, iter [03300, 05004], lr: 0.001000, loss: 1.1005
2022-07-05 01:17:54 - train: epoch 0090, iter [03400, 05004], lr: 0.001000, loss: 0.9286
2022-07-05 01:18:26 - train: epoch 0090, iter [03500, 05004], lr: 0.001000, loss: 0.8815
2022-07-05 01:19:00 - train: epoch 0090, iter [03600, 05004], lr: 0.001000, loss: 0.9132
2022-07-05 01:19:33 - train: epoch 0090, iter [03700, 05004], lr: 0.001000, loss: 1.0263
2022-07-05 01:20:07 - train: epoch 0090, iter [03800, 05004], lr: 0.001000, loss: 1.0982
2022-07-05 01:20:40 - train: epoch 0090, iter [03900, 05004], lr: 0.001000, loss: 1.0077
2022-07-05 01:21:13 - train: epoch 0090, iter [04000, 05004], lr: 0.001000, loss: 1.0315
2022-07-05 01:21:46 - train: epoch 0090, iter [04100, 05004], lr: 0.001000, loss: 1.2463
2022-07-05 01:22:21 - train: epoch 0090, iter [04200, 05004], lr: 0.001000, loss: 1.0141
2022-07-05 01:22:53 - train: epoch 0090, iter [04300, 05004], lr: 0.001000, loss: 1.0974
2022-07-05 01:23:27 - train: epoch 0090, iter [04400, 05004], lr: 0.001000, loss: 1.0773
2022-07-05 01:24:01 - train: epoch 0090, iter [04500, 05004], lr: 0.001000, loss: 1.0991
2022-07-05 01:24:34 - train: epoch 0090, iter [04600, 05004], lr: 0.001000, loss: 1.2214
2022-07-05 01:25:07 - train: epoch 0090, iter [04700, 05004], lr: 0.001000, loss: 0.9197
2022-07-05 01:25:41 - train: epoch 0090, iter [04800, 05004], lr: 0.001000, loss: 1.0235
2022-07-05 01:26:14 - train: epoch 0090, iter [04900, 05004], lr: 0.001000, loss: 0.9129
2022-07-05 01:26:45 - train: epoch 0090, iter [05000, 05004], lr: 0.001000, loss: 0.9491
2022-07-05 01:26:46 - train: epoch 090, train_loss: 0.9980
2022-07-05 01:27:59 - eval: epoch: 090, acc1: 73.230%, acc5: 91.258%, test_loss: 1.0818, per_image_load_time: 2.245ms, per_image_inference_time: 0.291ms
2022-07-05 01:27:59 - until epoch: 090, best_acc1: 73.458%
2022-07-05 01:27:59 - epoch 091 lr: 0.000100
2022-07-05 01:28:38 - train: epoch 0091, iter [00100, 05004], lr: 0.000100, loss: 1.0404
2022-07-05 01:29:11 - train: epoch 0091, iter [00200, 05004], lr: 0.000100, loss: 1.0154
2022-07-05 01:29:44 - train: epoch 0091, iter [00300, 05004], lr: 0.000100, loss: 0.8921
2022-07-05 01:30:16 - train: epoch 0091, iter [00400, 05004], lr: 0.000100, loss: 1.1889
2022-07-05 01:30:49 - train: epoch 0091, iter [00500, 05004], lr: 0.000100, loss: 0.9184
2022-07-05 01:31:22 - train: epoch 0091, iter [00600, 05004], lr: 0.000100, loss: 0.9174
2022-07-05 01:31:54 - train: epoch 0091, iter [00700, 05004], lr: 0.000100, loss: 1.1870
2022-07-05 01:32:28 - train: epoch 0091, iter [00800, 05004], lr: 0.000100, loss: 0.8061
2022-07-05 01:33:01 - train: epoch 0091, iter [00900, 05004], lr: 0.000100, loss: 1.1466
2022-07-05 01:33:34 - train: epoch 0091, iter [01000, 05004], lr: 0.000100, loss: 0.8914
2022-07-05 01:34:08 - train: epoch 0091, iter [01100, 05004], lr: 0.000100, loss: 0.9381
2022-07-05 01:34:41 - train: epoch 0091, iter [01200, 05004], lr: 0.000100, loss: 1.0109
2022-07-05 01:35:15 - train: epoch 0091, iter [01300, 05004], lr: 0.000100, loss: 0.9499
2022-07-05 01:35:47 - train: epoch 0091, iter [01400, 05004], lr: 0.000100, loss: 1.0806
2022-07-05 01:36:21 - train: epoch 0091, iter [01500, 05004], lr: 0.000100, loss: 0.8941
2022-07-05 01:36:54 - train: epoch 0091, iter [01600, 05004], lr: 0.000100, loss: 1.0289
2022-07-05 01:37:28 - train: epoch 0091, iter [01700, 05004], lr: 0.000100, loss: 0.9486
2022-07-05 01:38:01 - train: epoch 0091, iter [01800, 05004], lr: 0.000100, loss: 0.9524
2022-07-05 01:38:35 - train: epoch 0091, iter [01900, 05004], lr: 0.000100, loss: 1.0065
2022-07-05 01:39:08 - train: epoch 0091, iter [02000, 05004], lr: 0.000100, loss: 0.8894
2022-07-05 01:39:41 - train: epoch 0091, iter [02100, 05004], lr: 0.000100, loss: 0.9883
2022-07-05 01:40:14 - train: epoch 0091, iter [02200, 05004], lr: 0.000100, loss: 1.2529
2022-07-05 01:40:47 - train: epoch 0091, iter [02300, 05004], lr: 0.000100, loss: 0.9742
2022-07-05 01:41:21 - train: epoch 0091, iter [02400, 05004], lr: 0.000100, loss: 1.0421
2022-07-05 01:41:55 - train: epoch 0091, iter [02500, 05004], lr: 0.000100, loss: 1.0690
2022-07-05 01:42:28 - train: epoch 0091, iter [02600, 05004], lr: 0.000100, loss: 0.9117
2022-07-05 01:43:02 - train: epoch 0091, iter [02700, 05004], lr: 0.000100, loss: 1.0531
2022-07-05 01:43:34 - train: epoch 0091, iter [02800, 05004], lr: 0.000100, loss: 1.2119
2022-07-05 01:44:08 - train: epoch 0091, iter [02900, 05004], lr: 0.000100, loss: 1.1467
2022-07-05 01:44:42 - train: epoch 0091, iter [03000, 05004], lr: 0.000100, loss: 1.1073
2022-07-05 01:45:15 - train: epoch 0091, iter [03100, 05004], lr: 0.000100, loss: 0.9313
2022-07-05 01:45:48 - train: epoch 0091, iter [03200, 05004], lr: 0.000100, loss: 0.9495
2022-07-05 01:46:20 - train: epoch 0091, iter [03300, 05004], lr: 0.000100, loss: 0.8371
2022-07-05 01:46:54 - train: epoch 0091, iter [03400, 05004], lr: 0.000100, loss: 0.9018
2022-07-05 01:47:28 - train: epoch 0091, iter [03500, 05004], lr: 0.000100, loss: 0.9357
2022-07-05 01:48:01 - train: epoch 0091, iter [03600, 05004], lr: 0.000100, loss: 0.9965
2022-07-05 01:48:35 - train: epoch 0091, iter [03700, 05004], lr: 0.000100, loss: 1.0685
2022-07-05 01:49:08 - train: epoch 0091, iter [03800, 05004], lr: 0.000100, loss: 1.1738
2022-07-05 01:49:41 - train: epoch 0091, iter [03900, 05004], lr: 0.000100, loss: 0.9079
2022-07-05 01:50:15 - train: epoch 0091, iter [04000, 05004], lr: 0.000100, loss: 0.9414
2022-07-05 01:50:47 - train: epoch 0091, iter [04100, 05004], lr: 0.000100, loss: 0.9093
2022-07-05 01:51:20 - train: epoch 0091, iter [04200, 05004], lr: 0.000100, loss: 0.8527
2022-07-05 01:51:54 - train: epoch 0091, iter [04300, 05004], lr: 0.000100, loss: 0.9005
2022-07-05 01:52:27 - train: epoch 0091, iter [04400, 05004], lr: 0.000100, loss: 0.9521
2022-07-05 01:53:01 - train: epoch 0091, iter [04500, 05004], lr: 0.000100, loss: 1.0643
2022-07-05 01:53:34 - train: epoch 0091, iter [04600, 05004], lr: 0.000100, loss: 0.9004
2022-07-05 01:54:08 - train: epoch 0091, iter [04700, 05004], lr: 0.000100, loss: 1.1195
2022-07-05 01:54:42 - train: epoch 0091, iter [04800, 05004], lr: 0.000100, loss: 0.9280
2022-07-05 01:55:15 - train: epoch 0091, iter [04900, 05004], lr: 0.000100, loss: 1.0529
2022-07-05 01:55:46 - train: epoch 0091, iter [05000, 05004], lr: 0.000100, loss: 1.0396
2022-07-05 01:55:47 - train: epoch 091, train_loss: 0.9751
2022-07-05 01:56:59 - eval: epoch: 091, acc1: 73.518%, acc5: 91.474%, test_loss: 1.0691, per_image_load_time: 2.114ms, per_image_inference_time: 0.300ms
2022-07-05 01:57:00 - until epoch: 091, best_acc1: 73.518%
2022-07-05 01:57:00 - epoch 092 lr: 0.000100
2022-07-05 01:57:38 - train: epoch 0092, iter [00100, 05004], lr: 0.000100, loss: 0.8150
2022-07-05 01:58:11 - train: epoch 0092, iter [00200, 05004], lr: 0.000100, loss: 0.9463
2022-07-05 01:58:43 - train: epoch 0092, iter [00300, 05004], lr: 0.000100, loss: 1.1968
2022-07-05 01:59:17 - train: epoch 0092, iter [00400, 05004], lr: 0.000100, loss: 1.0100
2022-07-05 01:59:49 - train: epoch 0092, iter [00500, 05004], lr: 0.000100, loss: 1.0626
2022-07-05 02:00:22 - train: epoch 0092, iter [00600, 05004], lr: 0.000100, loss: 0.9973
2022-07-05 02:00:56 - train: epoch 0092, iter [00700, 05004], lr: 0.000100, loss: 1.0015
2022-07-05 02:01:29 - train: epoch 0092, iter [00800, 05004], lr: 0.000100, loss: 0.9292
2022-07-05 02:02:02 - train: epoch 0092, iter [00900, 05004], lr: 0.000100, loss: 1.0790
2022-07-05 02:02:35 - train: epoch 0092, iter [01000, 05004], lr: 0.000100, loss: 0.8487
2022-07-05 02:03:09 - train: epoch 0092, iter [01100, 05004], lr: 0.000100, loss: 0.8712
2022-07-05 02:03:41 - train: epoch 0092, iter [01200, 05004], lr: 0.000100, loss: 1.0649
2022-07-05 02:04:15 - train: epoch 0092, iter [01300, 05004], lr: 0.000100, loss: 0.8888
2022-07-05 02:04:47 - train: epoch 0092, iter [01400, 05004], lr: 0.000100, loss: 0.9213
2022-07-05 02:05:21 - train: epoch 0092, iter [01500, 05004], lr: 0.000100, loss: 0.8019
2022-07-05 02:05:53 - train: epoch 0092, iter [01600, 05004], lr: 0.000100, loss: 0.7995
2022-07-05 02:06:27 - train: epoch 0092, iter [01700, 05004], lr: 0.000100, loss: 1.1555
2022-07-05 02:07:01 - train: epoch 0092, iter [01800, 05004], lr: 0.000100, loss: 1.0445
2022-07-05 02:07:33 - train: epoch 0092, iter [01900, 05004], lr: 0.000100, loss: 0.8020
2022-07-05 02:08:07 - train: epoch 0092, iter [02000, 05004], lr: 0.000100, loss: 0.9081
2022-07-05 02:08:40 - train: epoch 0092, iter [02100, 05004], lr: 0.000100, loss: 1.0040
2022-07-05 02:09:12 - train: epoch 0092, iter [02200, 05004], lr: 0.000100, loss: 0.8031
2022-07-05 02:09:46 - train: epoch 0092, iter [02300, 05004], lr: 0.000100, loss: 0.9708
2022-07-05 02:10:18 - train: epoch 0092, iter [02400, 05004], lr: 0.000100, loss: 0.8989
2022-07-05 02:10:52 - train: epoch 0092, iter [02500, 05004], lr: 0.000100, loss: 0.8751
2022-07-05 02:11:25 - train: epoch 0092, iter [02600, 05004], lr: 0.000100, loss: 1.0283
2022-07-05 02:11:59 - train: epoch 0092, iter [02700, 05004], lr: 0.000100, loss: 1.0599
2022-07-05 02:12:32 - train: epoch 0092, iter [02800, 05004], lr: 0.000100, loss: 0.9309
2022-07-05 02:13:05 - train: epoch 0092, iter [02900, 05004], lr: 0.000100, loss: 1.1999
2022-07-05 02:13:38 - train: epoch 0092, iter [03000, 05004], lr: 0.000100, loss: 0.9433
2022-07-05 02:14:12 - train: epoch 0092, iter [03100, 05004], lr: 0.000100, loss: 1.0871
2022-07-05 02:14:45 - train: epoch 0092, iter [03200, 05004], lr: 0.000100, loss: 0.8767
2022-07-05 02:15:19 - train: epoch 0092, iter [03300, 05004], lr: 0.000100, loss: 1.0442
2022-07-05 02:15:51 - train: epoch 0092, iter [03400, 05004], lr: 0.000100, loss: 1.1904
2022-07-05 02:16:25 - train: epoch 0092, iter [03500, 05004], lr: 0.000100, loss: 0.9970
2022-07-05 02:16:58 - train: epoch 0092, iter [03600, 05004], lr: 0.000100, loss: 1.0528
2022-07-05 02:17:32 - train: epoch 0092, iter [03700, 05004], lr: 0.000100, loss: 0.8312
2022-07-05 02:18:05 - train: epoch 0092, iter [03800, 05004], lr: 0.000100, loss: 1.0215
2022-07-05 02:18:38 - train: epoch 0092, iter [03900, 05004], lr: 0.000100, loss: 1.1815
2022-07-05 02:19:11 - train: epoch 0092, iter [04000, 05004], lr: 0.000100, loss: 1.0100
2022-07-05 02:19:44 - train: epoch 0092, iter [04100, 05004], lr: 0.000100, loss: 0.9495
2022-07-05 02:20:18 - train: epoch 0092, iter [04200, 05004], lr: 0.000100, loss: 1.0947
2022-07-05 02:20:50 - train: epoch 0092, iter [04300, 05004], lr: 0.000100, loss: 1.1158
2022-07-05 02:21:24 - train: epoch 0092, iter [04400, 05004], lr: 0.000100, loss: 1.0022
2022-07-05 02:21:58 - train: epoch 0092, iter [04500, 05004], lr: 0.000100, loss: 0.9868
2022-07-05 02:22:32 - train: epoch 0092, iter [04600, 05004], lr: 0.000100, loss: 1.0161
2022-07-05 02:23:04 - train: epoch 0092, iter [04700, 05004], lr: 0.000100, loss: 0.8222
2022-07-05 02:23:38 - train: epoch 0092, iter [04800, 05004], lr: 0.000100, loss: 1.0034
2022-07-05 02:24:11 - train: epoch 0092, iter [04900, 05004], lr: 0.000100, loss: 0.9401
2022-07-05 02:24:43 - train: epoch 0092, iter [05000, 05004], lr: 0.000100, loss: 0.9902
2022-07-05 02:24:44 - train: epoch 092, train_loss: 0.9668
2022-07-05 02:25:57 - eval: epoch: 092, acc1: 73.602%, acc5: 91.458%, test_loss: 1.0694, per_image_load_time: 2.575ms, per_image_inference_time: 0.259ms
2022-07-05 02:25:58 - until epoch: 092, best_acc1: 73.602%
2022-07-05 02:25:58 - epoch 093 lr: 0.000100
2022-07-05 02:26:35 - train: epoch 0093, iter [00100, 05004], lr: 0.000100, loss: 0.8984
2022-07-05 02:27:09 - train: epoch 0093, iter [00200, 05004], lr: 0.000100, loss: 0.9678
2022-07-05 02:27:42 - train: epoch 0093, iter [00300, 05004], lr: 0.000100, loss: 0.9539
2022-07-05 02:28:15 - train: epoch 0093, iter [00400, 05004], lr: 0.000100, loss: 1.0264
2022-07-05 02:28:48 - train: epoch 0093, iter [00500, 05004], lr: 0.000100, loss: 1.0088
2022-07-05 02:29:22 - train: epoch 0093, iter [00600, 05004], lr: 0.000100, loss: 1.0724
2022-07-05 02:29:54 - train: epoch 0093, iter [00700, 05004], lr: 0.000100, loss: 0.9819
2022-07-05 02:30:27 - train: epoch 0093, iter [00800, 05004], lr: 0.000100, loss: 0.9251
2022-07-05 02:31:00 - train: epoch 0093, iter [00900, 05004], lr: 0.000100, loss: 0.9174
2022-07-05 02:31:33 - train: epoch 0093, iter [01000, 05004], lr: 0.000100, loss: 0.8243
2022-07-05 02:32:06 - train: epoch 0093, iter [01100, 05004], lr: 0.000100, loss: 0.9110
2022-07-05 02:32:39 - train: epoch 0093, iter [01200, 05004], lr: 0.000100, loss: 1.0132
2022-07-05 02:33:12 - train: epoch 0093, iter [01300, 05004], lr: 0.000100, loss: 0.8882
2022-07-05 02:33:46 - train: epoch 0093, iter [01400, 05004], lr: 0.000100, loss: 0.9090
2022-07-05 02:34:19 - train: epoch 0093, iter [01500, 05004], lr: 0.000100, loss: 1.1501
2022-07-05 02:34:52 - train: epoch 0093, iter [01600, 05004], lr: 0.000100, loss: 0.9246
2022-07-05 02:35:26 - train: epoch 0093, iter [01700, 05004], lr: 0.000100, loss: 0.8757
2022-07-05 02:35:59 - train: epoch 0093, iter [01800, 05004], lr: 0.000100, loss: 1.0876
2022-07-05 02:36:31 - train: epoch 0093, iter [01900, 05004], lr: 0.000100, loss: 0.8355
2022-07-05 02:37:04 - train: epoch 0093, iter [02000, 05004], lr: 0.000100, loss: 0.7370
2022-07-05 02:37:38 - train: epoch 0093, iter [02100, 05004], lr: 0.000100, loss: 1.0157
2022-07-05 02:38:11 - train: epoch 0093, iter [02200, 05004], lr: 0.000100, loss: 1.0833
2022-07-05 02:38:45 - train: epoch 0093, iter [02300, 05004], lr: 0.000100, loss: 1.0387
2022-07-05 02:39:17 - train: epoch 0093, iter [02400, 05004], lr: 0.000100, loss: 0.9137
2022-07-05 02:39:51 - train: epoch 0093, iter [02500, 05004], lr: 0.000100, loss: 1.1178
2022-07-05 02:40:24 - train: epoch 0093, iter [02600, 05004], lr: 0.000100, loss: 1.1770
2022-07-05 02:40:58 - train: epoch 0093, iter [02700, 05004], lr: 0.000100, loss: 0.9558
2022-07-05 02:41:32 - train: epoch 0093, iter [02800, 05004], lr: 0.000100, loss: 0.9317
2022-07-05 02:42:05 - train: epoch 0093, iter [02900, 05004], lr: 0.000100, loss: 0.8160
2022-07-05 02:42:38 - train: epoch 0093, iter [03000, 05004], lr: 0.000100, loss: 0.8359
2022-07-05 02:43:13 - train: epoch 0093, iter [03100, 05004], lr: 0.000100, loss: 1.0745
2022-07-05 02:43:46 - train: epoch 0093, iter [03200, 05004], lr: 0.000100, loss: 0.7387
2022-07-05 02:44:19 - train: epoch 0093, iter [03300, 05004], lr: 0.000100, loss: 1.0643
2022-07-05 02:44:53 - train: epoch 0093, iter [03400, 05004], lr: 0.000100, loss: 1.2333
2022-07-05 02:45:25 - train: epoch 0093, iter [03500, 05004], lr: 0.000100, loss: 0.8574
2022-07-05 02:45:59 - train: epoch 0093, iter [03600, 05004], lr: 0.000100, loss: 1.0131
2022-07-05 02:46:32 - train: epoch 0093, iter [03700, 05004], lr: 0.000100, loss: 0.9849
2022-07-05 02:47:05 - train: epoch 0093, iter [03800, 05004], lr: 0.000100, loss: 0.7880
2022-07-05 02:47:39 - train: epoch 0093, iter [03900, 05004], lr: 0.000100, loss: 0.9590
2022-07-05 02:48:12 - train: epoch 0093, iter [04000, 05004], lr: 0.000100, loss: 1.1282
2022-07-05 02:48:44 - train: epoch 0093, iter [04100, 05004], lr: 0.000100, loss: 1.1270
2022-07-05 02:49:18 - train: epoch 0093, iter [04200, 05004], lr: 0.000100, loss: 0.9941
2022-07-05 02:49:51 - train: epoch 0093, iter [04300, 05004], lr: 0.000100, loss: 0.9500
2022-07-05 02:50:25 - train: epoch 0093, iter [04400, 05004], lr: 0.000100, loss: 0.9724
2022-07-05 02:50:58 - train: epoch 0093, iter [04500, 05004], lr: 0.000100, loss: 1.0278
2022-07-05 02:51:32 - train: epoch 0093, iter [04600, 05004], lr: 0.000100, loss: 0.9140
2022-07-05 02:52:05 - train: epoch 0093, iter [04700, 05004], lr: 0.000100, loss: 1.1994
2022-07-05 02:52:38 - train: epoch 0093, iter [04800, 05004], lr: 0.000100, loss: 0.9033
2022-07-05 02:53:11 - train: epoch 0093, iter [04900, 05004], lr: 0.000100, loss: 1.1559
2022-07-05 02:53:43 - train: epoch 0093, iter [05000, 05004], lr: 0.000100, loss: 0.9471
2022-07-05 02:53:44 - train: epoch 093, train_loss: 0.9671
2022-07-05 02:54:58 - eval: epoch: 093, acc1: 73.602%, acc5: 91.426%, test_loss: 1.0684, per_image_load_time: 2.587ms, per_image_inference_time: 0.260ms
2022-07-05 02:54:58 - until epoch: 093, best_acc1: 73.602%
2022-07-05 02:54:58 - epoch 094 lr: 0.000100
2022-07-05 02:55:35 - train: epoch 0094, iter [00100, 05004], lr: 0.000100, loss: 0.9110
2022-07-05 02:56:09 - train: epoch 0094, iter [00200, 05004], lr: 0.000100, loss: 0.9627
2022-07-05 02:56:42 - train: epoch 0094, iter [00300, 05004], lr: 0.000100, loss: 0.8908
2022-07-05 02:57:15 - train: epoch 0094, iter [00400, 05004], lr: 0.000100, loss: 1.0141
2022-07-05 02:57:48 - train: epoch 0094, iter [00500, 05004], lr: 0.000100, loss: 0.8350
2022-07-05 02:58:21 - train: epoch 0094, iter [00600, 05004], lr: 0.000100, loss: 0.9461
2022-07-05 02:58:54 - train: epoch 0094, iter [00700, 05004], lr: 0.000100, loss: 0.9784
2022-07-05 02:59:27 - train: epoch 0094, iter [00800, 05004], lr: 0.000100, loss: 0.9316
2022-07-05 02:59:59 - train: epoch 0094, iter [00900, 05004], lr: 0.000100, loss: 1.0210
2022-07-05 03:00:32 - train: epoch 0094, iter [01000, 05004], lr: 0.000100, loss: 0.9930
2022-07-05 03:01:05 - train: epoch 0094, iter [01100, 05004], lr: 0.000100, loss: 1.1074
2022-07-05 03:01:38 - train: epoch 0094, iter [01200, 05004], lr: 0.000100, loss: 0.9990
2022-07-05 03:02:12 - train: epoch 0094, iter [01300, 05004], lr: 0.000100, loss: 0.9404
2022-07-05 03:02:44 - train: epoch 0094, iter [01400, 05004], lr: 0.000100, loss: 0.9933
2022-07-05 03:03:18 - train: epoch 0094, iter [01500, 05004], lr: 0.000100, loss: 1.1981
2022-07-05 03:03:50 - train: epoch 0094, iter [01600, 05004], lr: 0.000100, loss: 1.1554
2022-07-05 03:04:23 - train: epoch 0094, iter [01700, 05004], lr: 0.000100, loss: 0.9945
2022-07-05 03:04:56 - train: epoch 0094, iter [01800, 05004], lr: 0.000100, loss: 0.9128
2022-07-05 03:05:29 - train: epoch 0094, iter [01900, 05004], lr: 0.000100, loss: 0.8994
2022-07-05 03:06:02 - train: epoch 0094, iter [02000, 05004], lr: 0.000100, loss: 0.8473
2022-07-05 03:06:34 - train: epoch 0094, iter [02100, 05004], lr: 0.000100, loss: 0.8268
2022-07-05 03:07:08 - train: epoch 0094, iter [02200, 05004], lr: 0.000100, loss: 1.0524
2022-07-05 03:07:41 - train: epoch 0094, iter [02300, 05004], lr: 0.000100, loss: 0.8491
2022-07-05 03:08:14 - train: epoch 0094, iter [02400, 05004], lr: 0.000100, loss: 0.8741
2022-07-05 03:08:48 - train: epoch 0094, iter [02500, 05004], lr: 0.000100, loss: 0.9032
2022-07-05 03:09:21 - train: epoch 0094, iter [02600, 05004], lr: 0.000100, loss: 1.0178
2022-07-05 03:09:55 - train: epoch 0094, iter [02700, 05004], lr: 0.000100, loss: 0.9899
2022-07-05 03:10:28 - train: epoch 0094, iter [02800, 05004], lr: 0.000100, loss: 1.1311
2022-07-05 03:11:01 - train: epoch 0094, iter [02900, 05004], lr: 0.000100, loss: 0.8951
2022-07-05 03:11:35 - train: epoch 0094, iter [03000, 05004], lr: 0.000100, loss: 0.8477
2022-07-05 03:12:07 - train: epoch 0094, iter [03100, 05004], lr: 0.000100, loss: 1.0927
2022-07-05 03:12:41 - train: epoch 0094, iter [03200, 05004], lr: 0.000100, loss: 1.0345
2022-07-05 03:13:15 - train: epoch 0094, iter [03300, 05004], lr: 0.000100, loss: 0.9884
2022-07-05 03:13:49 - train: epoch 0094, iter [03400, 05004], lr: 0.000100, loss: 1.0873
2022-07-05 03:14:21 - train: epoch 0094, iter [03500, 05004], lr: 0.000100, loss: 0.9818
2022-07-05 03:14:55 - train: epoch 0094, iter [03600, 05004], lr: 0.000100, loss: 0.8877
2022-07-05 03:15:28 - train: epoch 0094, iter [03700, 05004], lr: 0.000100, loss: 0.9345
2022-07-05 03:16:02 - train: epoch 0094, iter [03800, 05004], lr: 0.000100, loss: 0.9695
2022-07-05 03:16:35 - train: epoch 0094, iter [03900, 05004], lr: 0.000100, loss: 0.9250
2022-07-05 03:17:08 - train: epoch 0094, iter [04000, 05004], lr: 0.000100, loss: 0.9175
2022-07-05 03:17:41 - train: epoch 0094, iter [04100, 05004], lr: 0.000100, loss: 0.9108
2022-07-05 03:18:14 - train: epoch 0094, iter [04200, 05004], lr: 0.000100, loss: 1.0235
2022-07-05 03:18:47 - train: epoch 0094, iter [04300, 05004], lr: 0.000100, loss: 1.0614
2022-07-05 03:19:20 - train: epoch 0094, iter [04400, 05004], lr: 0.000100, loss: 0.9864
2022-07-05 03:19:54 - train: epoch 0094, iter [04500, 05004], lr: 0.000100, loss: 0.9456
2022-07-05 03:20:27 - train: epoch 0094, iter [04600, 05004], lr: 0.000100, loss: 1.0075
2022-07-05 03:21:00 - train: epoch 0094, iter [04700, 05004], lr: 0.000100, loss: 1.0234
2022-07-05 03:21:34 - train: epoch 0094, iter [04800, 05004], lr: 0.000100, loss: 0.7992
2022-07-05 03:22:07 - train: epoch 0094, iter [04900, 05004], lr: 0.000100, loss: 1.1253
2022-07-05 03:22:38 - train: epoch 0094, iter [05000, 05004], lr: 0.000100, loss: 0.8052
2022-07-05 03:22:39 - train: epoch 094, train_loss: 0.9623
2022-07-05 03:23:52 - eval: epoch: 094, acc1: 73.666%, acc5: 91.440%, test_loss: 1.0661, per_image_load_time: 2.595ms, per_image_inference_time: 0.250ms
2022-07-05 03:23:53 - until epoch: 094, best_acc1: 73.666%
2022-07-05 03:23:53 - epoch 095 lr: 0.000100
2022-07-05 03:24:30 - train: epoch 0095, iter [00100, 05004], lr: 0.000100, loss: 0.9625
2022-07-05 03:25:04 - train: epoch 0095, iter [00200, 05004], lr: 0.000100, loss: 0.8681
2022-07-05 03:25:36 - train: epoch 0095, iter [00300, 05004], lr: 0.000100, loss: 0.8853
2022-07-05 03:26:09 - train: epoch 0095, iter [00400, 05004], lr: 0.000100, loss: 0.9185
2022-07-05 03:26:43 - train: epoch 0095, iter [00500, 05004], lr: 0.000100, loss: 1.0118
2022-07-05 03:27:16 - train: epoch 0095, iter [00600, 05004], lr: 0.000100, loss: 1.0046
2022-07-05 03:27:48 - train: epoch 0095, iter [00700, 05004], lr: 0.000100, loss: 1.0892
2022-07-05 03:28:23 - train: epoch 0095, iter [00800, 05004], lr: 0.000100, loss: 0.8337
2022-07-05 03:28:56 - train: epoch 0095, iter [00900, 05004], lr: 0.000100, loss: 1.0761
2022-07-05 03:29:28 - train: epoch 0095, iter [01000, 05004], lr: 0.000100, loss: 0.9783
2022-07-05 03:30:01 - train: epoch 0095, iter [01100, 05004], lr: 0.000100, loss: 0.9475
2022-07-05 03:30:35 - train: epoch 0095, iter [01200, 05004], lr: 0.000100, loss: 0.8748
2022-07-05 03:31:08 - train: epoch 0095, iter [01300, 05004], lr: 0.000100, loss: 0.9372
2022-07-05 03:31:41 - train: epoch 0095, iter [01400, 05004], lr: 0.000100, loss: 0.9392
2022-07-05 03:32:13 - train: epoch 0095, iter [01500, 05004], lr: 0.000100, loss: 0.8078
2022-07-05 03:32:47 - train: epoch 0095, iter [01600, 05004], lr: 0.000100, loss: 0.7067
2022-07-05 03:33:20 - train: epoch 0095, iter [01700, 05004], lr: 0.000100, loss: 0.9482
2022-07-05 03:33:53 - train: epoch 0095, iter [01800, 05004], lr: 0.000100, loss: 1.0720
2022-07-05 03:34:27 - train: epoch 0095, iter [01900, 05004], lr: 0.000100, loss: 0.7480
2022-07-05 03:35:00 - train: epoch 0095, iter [02000, 05004], lr: 0.000100, loss: 0.9804
2022-07-05 03:35:33 - train: epoch 0095, iter [02100, 05004], lr: 0.000100, loss: 1.0463
2022-07-05 03:36:06 - train: epoch 0095, iter [02200, 05004], lr: 0.000100, loss: 0.7930
2022-07-05 03:36:39 - train: epoch 0095, iter [02300, 05004], lr: 0.000100, loss: 0.9872
2022-07-05 03:37:13 - train: epoch 0095, iter [02400, 05004], lr: 0.000100, loss: 0.9247
2022-07-05 03:37:45 - train: epoch 0095, iter [02500, 05004], lr: 0.000100, loss: 0.7678
2022-07-05 03:38:18 - train: epoch 0095, iter [02600, 05004], lr: 0.000100, loss: 0.9119
2022-07-05 03:38:51 - train: epoch 0095, iter [02700, 05004], lr: 0.000100, loss: 0.8973
2022-07-05 03:39:24 - train: epoch 0095, iter [02800, 05004], lr: 0.000100, loss: 0.8709
2022-07-05 03:39:57 - train: epoch 0095, iter [02900, 05004], lr: 0.000100, loss: 0.9685
2022-07-05 03:40:31 - train: epoch 0095, iter [03000, 05004], lr: 0.000100, loss: 1.1442
2022-07-05 03:41:04 - train: epoch 0095, iter [03100, 05004], lr: 0.000100, loss: 0.9093
2022-07-05 03:41:37 - train: epoch 0095, iter [03200, 05004], lr: 0.000100, loss: 0.9160
2022-07-05 03:42:09 - train: epoch 0095, iter [03300, 05004], lr: 0.000100, loss: 0.9192
2022-07-05 03:42:43 - train: epoch 0095, iter [03400, 05004], lr: 0.000100, loss: 0.8236
2022-07-05 03:43:16 - train: epoch 0095, iter [03500, 05004], lr: 0.000100, loss: 0.7472
2022-07-05 03:43:49 - train: epoch 0095, iter [03600, 05004], lr: 0.000100, loss: 0.7872
2022-07-05 03:44:23 - train: epoch 0095, iter [03700, 05004], lr: 0.000100, loss: 1.0459
2022-07-05 03:44:56 - train: epoch 0095, iter [03800, 05004], lr: 0.000100, loss: 0.8964
2022-07-05 03:45:30 - train: epoch 0095, iter [03900, 05004], lr: 0.000100, loss: 1.1105
2022-07-05 03:46:03 - train: epoch 0095, iter [04000, 05004], lr: 0.000100, loss: 0.9032
2022-07-05 03:46:36 - train: epoch 0095, iter [04100, 05004], lr: 0.000100, loss: 0.7976
2022-07-05 03:47:10 - train: epoch 0095, iter [04200, 05004], lr: 0.000100, loss: 0.8965
2022-07-05 03:47:42 - train: epoch 0095, iter [04300, 05004], lr: 0.000100, loss: 0.9829
2022-07-05 03:48:17 - train: epoch 0095, iter [04400, 05004], lr: 0.000100, loss: 1.0476
2022-07-05 03:48:50 - train: epoch 0095, iter [04500, 05004], lr: 0.000100, loss: 0.7610
2022-07-05 03:49:23 - train: epoch 0095, iter [04600, 05004], lr: 0.000100, loss: 0.8570
2022-07-05 03:49:56 - train: epoch 0095, iter [04700, 05004], lr: 0.000100, loss: 0.9180
2022-07-05 03:50:30 - train: epoch 0095, iter [04800, 05004], lr: 0.000100, loss: 1.0911
2022-07-05 03:51:03 - train: epoch 0095, iter [04900, 05004], lr: 0.000100, loss: 0.8675
2022-07-05 03:51:34 - train: epoch 0095, iter [05000, 05004], lr: 0.000100, loss: 0.9251
2022-07-05 03:51:35 - train: epoch 095, train_loss: 0.9600
2022-07-05 03:52:48 - eval: epoch: 095, acc1: 73.664%, acc5: 91.460%, test_loss: 1.0664, per_image_load_time: 2.535ms, per_image_inference_time: 0.290ms
2022-07-05 03:52:48 - until epoch: 095, best_acc1: 73.666%
2022-07-05 03:52:48 - epoch 096 lr: 0.000100
2022-07-05 03:53:26 - train: epoch 0096, iter [00100, 05004], lr: 0.000100, loss: 1.0132
2022-07-05 03:53:58 - train: epoch 0096, iter [00200, 05004], lr: 0.000100, loss: 1.0537
2022-07-05 03:54:31 - train: epoch 0096, iter [00300, 05004], lr: 0.000100, loss: 0.8846
2022-07-05 03:55:05 - train: epoch 0096, iter [00400, 05004], lr: 0.000100, loss: 0.7725
2022-07-05 03:55:37 - train: epoch 0096, iter [00500, 05004], lr: 0.000100, loss: 0.9434
2022-07-05 03:56:10 - train: epoch 0096, iter [00600, 05004], lr: 0.000100, loss: 1.1191
2022-07-05 03:56:43 - train: epoch 0096, iter [00700, 05004], lr: 0.000100, loss: 0.7837
2022-07-05 03:57:16 - train: epoch 0096, iter [00800, 05004], lr: 0.000100, loss: 0.8374
2022-07-05 03:57:48 - train: epoch 0096, iter [00900, 05004], lr: 0.000100, loss: 1.0723
2022-07-05 03:58:21 - train: epoch 0096, iter [01000, 05004], lr: 0.000100, loss: 0.9706
2022-07-05 03:58:54 - train: epoch 0096, iter [01100, 05004], lr: 0.000100, loss: 1.1641
2022-07-05 03:59:28 - train: epoch 0096, iter [01200, 05004], lr: 0.000100, loss: 0.9561
2022-07-05 04:00:00 - train: epoch 0096, iter [01300, 05004], lr: 0.000100, loss: 1.0313
2022-07-05 04:00:33 - train: epoch 0096, iter [01400, 05004], lr: 0.000100, loss: 0.9507
2022-07-05 04:01:06 - train: epoch 0096, iter [01500, 05004], lr: 0.000100, loss: 0.9180
2022-07-05 04:01:39 - train: epoch 0096, iter [01600, 05004], lr: 0.000100, loss: 0.8897
2022-07-05 04:02:12 - train: epoch 0096, iter [01700, 05004], lr: 0.000100, loss: 0.9489
2022-07-05 04:02:45 - train: epoch 0096, iter [01800, 05004], lr: 0.000100, loss: 1.0421
2022-07-05 04:03:19 - train: epoch 0096, iter [01900, 05004], lr: 0.000100, loss: 1.0347
2022-07-05 04:03:52 - train: epoch 0096, iter [02000, 05004], lr: 0.000100, loss: 0.9563
2022-07-05 04:04:25 - train: epoch 0096, iter [02100, 05004], lr: 0.000100, loss: 0.9321
2022-07-05 04:04:58 - train: epoch 0096, iter [02200, 05004], lr: 0.000100, loss: 0.7588
2022-07-05 04:05:31 - train: epoch 0096, iter [02300, 05004], lr: 0.000100, loss: 0.9155
2022-07-05 04:06:03 - train: epoch 0096, iter [02400, 05004], lr: 0.000100, loss: 0.9118
2022-07-05 04:06:37 - train: epoch 0096, iter [02500, 05004], lr: 0.000100, loss: 0.8945
2022-07-05 04:07:10 - train: epoch 0096, iter [02600, 05004], lr: 0.000100, loss: 0.7418
2022-07-05 04:07:43 - train: epoch 0096, iter [02700, 05004], lr: 0.000100, loss: 1.1041
2022-07-05 04:08:16 - train: epoch 0096, iter [02800, 05004], lr: 0.000100, loss: 0.9777
2022-07-05 04:08:49 - train: epoch 0096, iter [02900, 05004], lr: 0.000100, loss: 1.0734
2022-07-05 04:09:22 - train: epoch 0096, iter [03000, 05004], lr: 0.000100, loss: 1.0170
2022-07-05 04:09:56 - train: epoch 0096, iter [03100, 05004], lr: 0.000100, loss: 0.9657
2022-07-05 04:10:30 - train: epoch 0096, iter [03200, 05004], lr: 0.000100, loss: 0.9366
2022-07-05 04:11:03 - train: epoch 0096, iter [03300, 05004], lr: 0.000100, loss: 1.0635
2022-07-05 04:11:35 - train: epoch 0096, iter [03400, 05004], lr: 0.000100, loss: 0.9092
2022-07-05 04:12:09 - train: epoch 0096, iter [03500, 05004], lr: 0.000100, loss: 0.8883
2022-07-05 04:12:42 - train: epoch 0096, iter [03600, 05004], lr: 0.000100, loss: 0.7947
2022-07-05 04:13:15 - train: epoch 0096, iter [03700, 05004], lr: 0.000100, loss: 1.0178
2022-07-05 04:13:48 - train: epoch 0096, iter [03800, 05004], lr: 0.000100, loss: 0.8751
2022-07-05 04:14:21 - train: epoch 0096, iter [03900, 05004], lr: 0.000100, loss: 0.8356
2022-07-05 04:14:54 - train: epoch 0096, iter [04000, 05004], lr: 0.000100, loss: 1.1348
2022-07-05 04:15:27 - train: epoch 0096, iter [04100, 05004], lr: 0.000100, loss: 0.9078
2022-07-05 04:16:00 - train: epoch 0096, iter [04200, 05004], lr: 0.000100, loss: 1.1267
2022-07-05 04:16:33 - train: epoch 0096, iter [04300, 05004], lr: 0.000100, loss: 0.8868
2022-07-05 04:17:06 - train: epoch 0096, iter [04400, 05004], lr: 0.000100, loss: 0.7218
2022-07-05 04:17:40 - train: epoch 0096, iter [04500, 05004], lr: 0.000100, loss: 0.9134
2022-07-05 04:18:12 - train: epoch 0096, iter [04600, 05004], lr: 0.000100, loss: 1.0275
2022-07-05 04:18:46 - train: epoch 0096, iter [04700, 05004], lr: 0.000100, loss: 0.9956
2022-07-05 04:19:19 - train: epoch 0096, iter [04800, 05004], lr: 0.000100, loss: 0.9973
2022-07-05 04:19:51 - train: epoch 0096, iter [04900, 05004], lr: 0.000100, loss: 1.1168
2022-07-05 04:20:23 - train: epoch 0096, iter [05000, 05004], lr: 0.000100, loss: 0.9611
2022-07-05 04:20:24 - train: epoch 096, train_loss: 0.9588
2022-07-05 04:21:38 - eval: epoch: 096, acc1: 73.688%, acc5: 91.438%, test_loss: 1.0661, per_image_load_time: 2.568ms, per_image_inference_time: 0.258ms
2022-07-05 04:21:38 - until epoch: 096, best_acc1: 73.688%
2022-07-05 04:21:38 - epoch 097 lr: 0.000100
2022-07-05 04:22:16 - train: epoch 0097, iter [00100, 05004], lr: 0.000100, loss: 0.8708
2022-07-05 04:22:49 - train: epoch 0097, iter [00200, 05004], lr: 0.000100, loss: 1.0698
2022-07-05 04:23:22 - train: epoch 0097, iter [00300, 05004], lr: 0.000100, loss: 0.9147
2022-07-05 04:23:55 - train: epoch 0097, iter [00400, 05004], lr: 0.000100, loss: 1.1890
2022-07-05 04:24:28 - train: epoch 0097, iter [00500, 05004], lr: 0.000100, loss: 0.9638
2022-07-05 04:25:01 - train: epoch 0097, iter [00600, 05004], lr: 0.000100, loss: 1.1109
2022-07-05 04:25:34 - train: epoch 0097, iter [00700, 05004], lr: 0.000100, loss: 0.7209
2022-07-05 04:26:06 - train: epoch 0097, iter [00800, 05004], lr: 0.000100, loss: 0.8776
2022-07-05 04:26:40 - train: epoch 0097, iter [00900, 05004], lr: 0.000100, loss: 0.9579
2022-07-05 04:27:13 - train: epoch 0097, iter [01000, 05004], lr: 0.000100, loss: 1.0653
2022-07-05 04:27:46 - train: epoch 0097, iter [01100, 05004], lr: 0.000100, loss: 0.8586
2022-07-05 04:28:19 - train: epoch 0097, iter [01200, 05004], lr: 0.000100, loss: 1.0083
2022-07-05 04:28:52 - train: epoch 0097, iter [01300, 05004], lr: 0.000100, loss: 1.0453
2022-07-05 04:29:26 - train: epoch 0097, iter [01400, 05004], lr: 0.000100, loss: 0.9698
2022-07-05 04:29:58 - train: epoch 0097, iter [01500, 05004], lr: 0.000100, loss: 0.9074
2022-07-05 04:30:32 - train: epoch 0097, iter [01600, 05004], lr: 0.000100, loss: 0.8812
2022-07-05 04:31:04 - train: epoch 0097, iter [01700, 05004], lr: 0.000100, loss: 0.9489
2022-07-05 04:31:38 - train: epoch 0097, iter [01800, 05004], lr: 0.000100, loss: 0.9939
2022-07-05 04:32:11 - train: epoch 0097, iter [01900, 05004], lr: 0.000100, loss: 1.0605
2022-07-05 04:32:44 - train: epoch 0097, iter [02000, 05004], lr: 0.000100, loss: 0.7964
2022-07-05 04:33:17 - train: epoch 0097, iter [02100, 05004], lr: 0.000100, loss: 0.9108
2022-07-05 04:33:50 - train: epoch 0097, iter [02200, 05004], lr: 0.000100, loss: 0.9304
2022-07-05 04:34:24 - train: epoch 0097, iter [02300, 05004], lr: 0.000100, loss: 0.9409
2022-07-05 04:34:58 - train: epoch 0097, iter [02400, 05004], lr: 0.000100, loss: 0.8997
2022-07-05 04:35:30 - train: epoch 0097, iter [02500, 05004], lr: 0.000100, loss: 1.0056
2022-07-05 04:36:04 - train: epoch 0097, iter [02600, 05004], lr: 0.000100, loss: 1.0181
2022-07-05 04:36:37 - train: epoch 0097, iter [02700, 05004], lr: 0.000100, loss: 0.8200
2022-07-05 04:37:11 - train: epoch 0097, iter [02800, 05004], lr: 0.000100, loss: 0.9596
2022-07-05 04:37:44 - train: epoch 0097, iter [02900, 05004], lr: 0.000100, loss: 0.9246
2022-07-05 04:38:17 - train: epoch 0097, iter [03000, 05004], lr: 0.000100, loss: 1.1612
2022-07-05 04:38:50 - train: epoch 0097, iter [03100, 05004], lr: 0.000100, loss: 0.9986
2022-07-05 04:39:23 - train: epoch 0097, iter [03200, 05004], lr: 0.000100, loss: 0.8894
2022-07-05 04:39:57 - train: epoch 0097, iter [03300, 05004], lr: 0.000100, loss: 0.9332
2022-07-05 04:40:30 - train: epoch 0097, iter [03400, 05004], lr: 0.000100, loss: 1.2123
2022-07-05 04:41:03 - train: epoch 0097, iter [03500, 05004], lr: 0.000100, loss: 1.0897
2022-07-05 04:41:37 - train: epoch 0097, iter [03600, 05004], lr: 0.000100, loss: 0.9370
2022-07-05 04:42:10 - train: epoch 0097, iter [03700, 05004], lr: 0.000100, loss: 1.0054
2022-07-05 04:42:43 - train: epoch 0097, iter [03800, 05004], lr: 0.000100, loss: 0.8479
2022-07-05 04:43:16 - train: epoch 0097, iter [03900, 05004], lr: 0.000100, loss: 0.8620
2022-07-05 04:43:49 - train: epoch 0097, iter [04000, 05004], lr: 0.000100, loss: 1.0068
2022-07-05 04:44:22 - train: epoch 0097, iter [04100, 05004], lr: 0.000100, loss: 0.8247
2022-07-05 04:44:55 - train: epoch 0097, iter [04200, 05004], lr: 0.000100, loss: 0.8732
2022-07-05 04:45:29 - train: epoch 0097, iter [04300, 05004], lr: 0.000100, loss: 0.9167
2022-07-05 04:46:03 - train: epoch 0097, iter [04400, 05004], lr: 0.000100, loss: 0.9012
2022-07-05 04:46:36 - train: epoch 0097, iter [04500, 05004], lr: 0.000100, loss: 1.0723
2022-07-05 04:47:09 - train: epoch 0097, iter [04600, 05004], lr: 0.000100, loss: 0.8015
2022-07-05 04:47:42 - train: epoch 0097, iter [04700, 05004], lr: 0.000100, loss: 0.9022
2022-07-05 04:48:16 - train: epoch 0097, iter [04800, 05004], lr: 0.000100, loss: 0.9920
2022-07-05 04:48:50 - train: epoch 0097, iter [04900, 05004], lr: 0.000100, loss: 1.1161
2022-07-05 04:49:21 - train: epoch 0097, iter [05000, 05004], lr: 0.000100, loss: 0.8218
2022-07-05 04:49:22 - train: epoch 097, train_loss: 0.9577
2022-07-05 04:50:35 - eval: epoch: 097, acc1: 73.712%, acc5: 91.504%, test_loss: 1.0644, per_image_load_time: 2.565ms, per_image_inference_time: 0.264ms
2022-07-05 04:50:35 - until epoch: 097, best_acc1: 73.712%
2022-07-05 04:50:35 - epoch 098 lr: 0.000100
2022-07-05 04:51:14 - train: epoch 0098, iter [00100, 05004], lr: 0.000100, loss: 1.0055
2022-07-05 04:51:46 - train: epoch 0098, iter [00200, 05004], lr: 0.000100, loss: 1.0182
2022-07-05 04:52:19 - train: epoch 0098, iter [00300, 05004], lr: 0.000100, loss: 1.1828
2022-07-05 04:52:52 - train: epoch 0098, iter [00400, 05004], lr: 0.000100, loss: 0.8436
2022-07-05 04:53:25 - train: epoch 0098, iter [00500, 05004], lr: 0.000100, loss: 0.8673
2022-07-05 04:53:57 - train: epoch 0098, iter [00600, 05004], lr: 0.000100, loss: 0.9404
2022-07-05 04:54:31 - train: epoch 0098, iter [00700, 05004], lr: 0.000100, loss: 0.9049
2022-07-05 04:55:04 - train: epoch 0098, iter [00800, 05004], lr: 0.000100, loss: 1.1219
2022-07-05 04:55:37 - train: epoch 0098, iter [00900, 05004], lr: 0.000100, loss: 0.9446
2022-07-05 04:56:10 - train: epoch 0098, iter [01000, 05004], lr: 0.000100, loss: 0.8866
2022-07-05 04:56:42 - train: epoch 0098, iter [01100, 05004], lr: 0.000100, loss: 0.8195
2022-07-05 04:57:16 - train: epoch 0098, iter [01200, 05004], lr: 0.000100, loss: 1.1072
2022-07-05 04:57:49 - train: epoch 0098, iter [01300, 05004], lr: 0.000100, loss: 0.9055
2022-07-05 04:58:22 - train: epoch 0098, iter [01400, 05004], lr: 0.000100, loss: 0.9002
2022-07-05 04:58:55 - train: epoch 0098, iter [01500, 05004], lr: 0.000100, loss: 0.9023
2022-07-05 04:59:28 - train: epoch 0098, iter [01600, 05004], lr: 0.000100, loss: 0.8466
2022-07-05 05:00:02 - train: epoch 0098, iter [01700, 05004], lr: 0.000100, loss: 1.0779
2022-07-05 05:00:36 - train: epoch 0098, iter [01800, 05004], lr: 0.000100, loss: 1.0666
2022-07-05 05:01:08 - train: epoch 0098, iter [01900, 05004], lr: 0.000100, loss: 0.7509
2022-07-05 05:01:41 - train: epoch 0098, iter [02000, 05004], lr: 0.000100, loss: 1.0239
2022-07-05 05:02:14 - train: epoch 0098, iter [02100, 05004], lr: 0.000100, loss: 0.9942
2022-07-05 05:02:48 - train: epoch 0098, iter [02200, 05004], lr: 0.000100, loss: 0.9145
2022-07-05 05:03:21 - train: epoch 0098, iter [02300, 05004], lr: 0.000100, loss: 0.8932
2022-07-05 05:03:53 - train: epoch 0098, iter [02400, 05004], lr: 0.000100, loss: 0.9165
2022-07-05 05:04:27 - train: epoch 0098, iter [02500, 05004], lr: 0.000100, loss: 0.9973
2022-07-05 05:05:00 - train: epoch 0098, iter [02600, 05004], lr: 0.000100, loss: 1.0525
2022-07-05 05:05:33 - train: epoch 0098, iter [02700, 05004], lr: 0.000100, loss: 1.0413
2022-07-05 05:06:07 - train: epoch 0098, iter [02800, 05004], lr: 0.000100, loss: 0.9645
2022-07-05 05:06:40 - train: epoch 0098, iter [02900, 05004], lr: 0.000100, loss: 1.0390
2022-07-05 05:07:14 - train: epoch 0098, iter [03000, 05004], lr: 0.000100, loss: 0.7791
2022-07-05 05:07:47 - train: epoch 0098, iter [03100, 05004], lr: 0.000100, loss: 0.9448
2022-07-05 05:08:20 - train: epoch 0098, iter [03200, 05004], lr: 0.000100, loss: 0.8989
2022-07-05 05:08:53 - train: epoch 0098, iter [03300, 05004], lr: 0.000100, loss: 0.9238
2022-07-05 05:09:26 - train: epoch 0098, iter [03400, 05004], lr: 0.000100, loss: 1.0676
2022-07-05 05:09:59 - train: epoch 0098, iter [03500, 05004], lr: 0.000100, loss: 1.0421
2022-07-05 05:10:33 - train: epoch 0098, iter [03600, 05004], lr: 0.000100, loss: 1.0974
2022-07-05 05:11:06 - train: epoch 0098, iter [03700, 05004], lr: 0.000100, loss: 0.9674
2022-07-05 05:11:39 - train: epoch 0098, iter [03800, 05004], lr: 0.000100, loss: 0.9169
2022-07-05 05:12:13 - train: epoch 0098, iter [03900, 05004], lr: 0.000100, loss: 0.8470
2022-07-05 05:12:46 - train: epoch 0098, iter [04000, 05004], lr: 0.000100, loss: 0.9924
2022-07-05 05:13:20 - train: epoch 0098, iter [04100, 05004], lr: 0.000100, loss: 1.0107
2022-07-05 05:13:53 - train: epoch 0098, iter [04200, 05004], lr: 0.000100, loss: 0.8199
2022-07-05 05:14:26 - train: epoch 0098, iter [04300, 05004], lr: 0.000100, loss: 0.8324
2022-07-05 05:15:00 - train: epoch 0098, iter [04400, 05004], lr: 0.000100, loss: 1.0326
2022-07-05 05:15:32 - train: epoch 0098, iter [04500, 05004], lr: 0.000100, loss: 0.8736
2022-07-05 05:16:06 - train: epoch 0098, iter [04600, 05004], lr: 0.000100, loss: 1.0481
2022-07-05 05:16:40 - train: epoch 0098, iter [04700, 05004], lr: 0.000100, loss: 0.9128
2022-07-05 05:17:13 - train: epoch 0098, iter [04800, 05004], lr: 0.000100, loss: 0.9813
2022-07-05 05:17:46 - train: epoch 0098, iter [04900, 05004], lr: 0.000100, loss: 0.9868
2022-07-05 05:18:18 - train: epoch 0098, iter [05000, 05004], lr: 0.000100, loss: 0.9736
2022-07-05 05:18:19 - train: epoch 098, train_loss: 0.9577
2022-07-05 05:19:32 - eval: epoch: 098, acc1: 73.690%, acc5: 91.444%, test_loss: 1.0649, per_image_load_time: 2.564ms, per_image_inference_time: 0.263ms
2022-07-05 05:19:33 - until epoch: 098, best_acc1: 73.712%
2022-07-05 05:19:33 - epoch 099 lr: 0.000100
2022-07-05 05:20:11 - train: epoch 0099, iter [00100, 05004], lr: 0.000100, loss: 1.1358
2022-07-05 05:20:44 - train: epoch 0099, iter [00200, 05004], lr: 0.000100, loss: 0.9044
2022-07-05 05:21:17 - train: epoch 0099, iter [00300, 05004], lr: 0.000100, loss: 0.7780
2022-07-05 05:21:51 - train: epoch 0099, iter [00400, 05004], lr: 0.000100, loss: 0.9494
2022-07-05 05:22:23 - train: epoch 0099, iter [00500, 05004], lr: 0.000100, loss: 1.0652
2022-07-05 05:22:55 - train: epoch 0099, iter [00600, 05004], lr: 0.000100, loss: 0.9636
2022-07-05 05:23:29 - train: epoch 0099, iter [00700, 05004], lr: 0.000100, loss: 1.0295
2022-07-05 05:24:01 - train: epoch 0099, iter [00800, 05004], lr: 0.000100, loss: 0.9902
2022-07-05 05:24:34 - train: epoch 0099, iter [00900, 05004], lr: 0.000100, loss: 0.9326
2022-07-05 05:25:08 - train: epoch 0099, iter [01000, 05004], lr: 0.000100, loss: 0.9042
2022-07-05 05:25:41 - train: epoch 0099, iter [01100, 05004], lr: 0.000100, loss: 0.9940
2022-07-05 05:26:14 - train: epoch 0099, iter [01200, 05004], lr: 0.000100, loss: 0.7840
2022-07-05 05:26:48 - train: epoch 0099, iter [01300, 05004], lr: 0.000100, loss: 1.0463
2022-07-05 05:27:21 - train: epoch 0099, iter [01400, 05004], lr: 0.000100, loss: 1.0126
2022-07-05 05:27:54 - train: epoch 0099, iter [01500, 05004], lr: 0.000100, loss: 0.9716
2022-07-05 05:28:27 - train: epoch 0099, iter [01600, 05004], lr: 0.000100, loss: 0.9474
2022-07-05 05:28:59 - train: epoch 0099, iter [01700, 05004], lr: 0.000100, loss: 0.9339
2022-07-05 05:29:33 - train: epoch 0099, iter [01800, 05004], lr: 0.000100, loss: 0.9151
2022-07-05 05:30:05 - train: epoch 0099, iter [01900, 05004], lr: 0.000100, loss: 1.0218
2022-07-05 05:30:39 - train: epoch 0099, iter [02000, 05004], lr: 0.000100, loss: 0.8538
2022-07-05 05:31:11 - train: epoch 0099, iter [02100, 05004], lr: 0.000100, loss: 0.8628
2022-07-05 05:31:45 - train: epoch 0099, iter [02200, 05004], lr: 0.000100, loss: 0.9607
2022-07-05 05:32:18 - train: epoch 0099, iter [02300, 05004], lr: 0.000100, loss: 0.9256
2022-07-05 05:32:51 - train: epoch 0099, iter [02400, 05004], lr: 0.000100, loss: 1.2138
2022-07-05 05:33:25 - train: epoch 0099, iter [02500, 05004], lr: 0.000100, loss: 1.0050
2022-07-05 05:33:58 - train: epoch 0099, iter [02600, 05004], lr: 0.000100, loss: 0.9628
2022-07-05 05:34:31 - train: epoch 0099, iter [02700, 05004], lr: 0.000100, loss: 0.9599
2022-07-05 05:35:04 - train: epoch 0099, iter [02800, 05004], lr: 0.000100, loss: 1.0540
2022-07-05 05:35:39 - train: epoch 0099, iter [02900, 05004], lr: 0.000100, loss: 0.7691
2022-07-05 05:36:12 - train: epoch 0099, iter [03000, 05004], lr: 0.000100, loss: 1.0476
2022-07-05 05:36:45 - train: epoch 0099, iter [03100, 05004], lr: 0.000100, loss: 0.8416
2022-07-05 05:37:18 - train: epoch 0099, iter [03200, 05004], lr: 0.000100, loss: 0.9371
2022-07-05 05:37:52 - train: epoch 0099, iter [03300, 05004], lr: 0.000100, loss: 0.8298
2022-07-05 05:38:24 - train: epoch 0099, iter [03400, 05004], lr: 0.000100, loss: 0.9156
2022-07-05 05:38:58 - train: epoch 0099, iter [03500, 05004], lr: 0.000100, loss: 1.0270
2022-07-05 05:39:31 - train: epoch 0099, iter [03600, 05004], lr: 0.000100, loss: 0.9075
2022-07-05 05:40:03 - train: epoch 0099, iter [03700, 05004], lr: 0.000100, loss: 0.8336
2022-07-05 05:40:37 - train: epoch 0099, iter [03800, 05004], lr: 0.000100, loss: 0.9590
2022-07-05 05:41:10 - train: epoch 0099, iter [03900, 05004], lr: 0.000100, loss: 0.8271
2022-07-05 05:41:43 - train: epoch 0099, iter [04000, 05004], lr: 0.000100, loss: 1.0023
2022-07-05 05:42:16 - train: epoch 0099, iter [04100, 05004], lr: 0.000100, loss: 0.7295
2022-07-05 05:42:51 - train: epoch 0099, iter [04200, 05004], lr: 0.000100, loss: 1.0132
2022-07-05 05:43:23 - train: epoch 0099, iter [04300, 05004], lr: 0.000100, loss: 1.2339
2022-07-05 05:43:57 - train: epoch 0099, iter [04400, 05004], lr: 0.000100, loss: 0.8452
2022-07-05 05:44:29 - train: epoch 0099, iter [04500, 05004], lr: 0.000100, loss: 1.0421
2022-07-05 05:45:03 - train: epoch 0099, iter [04600, 05004], lr: 0.000100, loss: 0.9490
2022-07-05 05:45:36 - train: epoch 0099, iter [04700, 05004], lr: 0.000100, loss: 0.9458
2022-07-05 05:46:10 - train: epoch 0099, iter [04800, 05004], lr: 0.000100, loss: 0.9137
2022-07-05 05:46:43 - train: epoch 0099, iter [04900, 05004], lr: 0.000100, loss: 0.9636
2022-07-05 05:47:15 - train: epoch 0099, iter [05000, 05004], lr: 0.000100, loss: 0.9516
2022-07-05 05:47:16 - train: epoch 099, train_loss: 0.9578
2022-07-05 05:48:30 - eval: epoch: 099, acc1: 73.752%, acc5: 91.454%, test_loss: 1.0640, per_image_load_time: 2.556ms, per_image_inference_time: 0.261ms
2022-07-05 05:48:31 - until epoch: 099, best_acc1: 73.752%
2022-07-05 05:48:31 - epoch 100 lr: 0.000100
2022-07-05 05:49:09 - train: epoch 0100, iter [00100, 05004], lr: 0.000100, loss: 0.9432
2022-07-05 05:49:42 - train: epoch 0100, iter [00200, 05004], lr: 0.000100, loss: 1.0296
2022-07-05 05:50:14 - train: epoch 0100, iter [00300, 05004], lr: 0.000100, loss: 0.9118
2022-07-05 05:50:47 - train: epoch 0100, iter [00400, 05004], lr: 0.000100, loss: 0.8463
2022-07-05 05:51:19 - train: epoch 0100, iter [00500, 05004], lr: 0.000100, loss: 0.8954
2022-07-05 05:51:52 - train: epoch 0100, iter [00600, 05004], lr: 0.000100, loss: 1.2454
2022-07-05 05:52:26 - train: epoch 0100, iter [00700, 05004], lr: 0.000100, loss: 0.8317
2022-07-05 05:52:59 - train: epoch 0100, iter [00800, 05004], lr: 0.000100, loss: 1.0642
2022-07-05 05:53:32 - train: epoch 0100, iter [00900, 05004], lr: 0.000100, loss: 0.8007
2022-07-05 05:54:05 - train: epoch 0100, iter [01000, 05004], lr: 0.000100, loss: 0.9936
2022-07-05 05:54:38 - train: epoch 0100, iter [01100, 05004], lr: 0.000100, loss: 0.7961
2022-07-05 05:55:11 - train: epoch 0100, iter [01200, 05004], lr: 0.000100, loss: 1.0606
2022-07-05 05:55:43 - train: epoch 0100, iter [01300, 05004], lr: 0.000100, loss: 0.9491
2022-07-05 05:56:17 - train: epoch 0100, iter [01400, 05004], lr: 0.000100, loss: 0.9118
2022-07-05 05:56:49 - train: epoch 0100, iter [01500, 05004], lr: 0.000100, loss: 0.9970
2022-07-05 05:57:23 - train: epoch 0100, iter [01600, 05004], lr: 0.000100, loss: 0.9470
2022-07-05 05:57:56 - train: epoch 0100, iter [01700, 05004], lr: 0.000100, loss: 0.9503
2022-07-05 05:58:29 - train: epoch 0100, iter [01800, 05004], lr: 0.000100, loss: 0.8579
2022-07-05 05:59:02 - train: epoch 0100, iter [01900, 05004], lr: 0.000100, loss: 0.9222
2022-07-05 05:59:36 - train: epoch 0100, iter [02000, 05004], lr: 0.000100, loss: 1.1697
2022-07-05 06:00:09 - train: epoch 0100, iter [02100, 05004], lr: 0.000100, loss: 0.9592
2022-07-05 06:00:42 - train: epoch 0100, iter [02200, 05004], lr: 0.000100, loss: 0.7927
2022-07-05 06:01:15 - train: epoch 0100, iter [02300, 05004], lr: 0.000100, loss: 0.8106
2022-07-05 06:01:49 - train: epoch 0100, iter [02400, 05004], lr: 0.000100, loss: 1.1818
2022-07-05 06:02:22 - train: epoch 0100, iter [02500, 05004], lr: 0.000100, loss: 1.0179
2022-07-05 06:02:55 - train: epoch 0100, iter [02600, 05004], lr: 0.000100, loss: 0.8422
2022-07-05 06:03:28 - train: epoch 0100, iter [02700, 05004], lr: 0.000100, loss: 1.1241
2022-07-05 06:04:01 - train: epoch 0100, iter [02800, 05004], lr: 0.000100, loss: 0.8113
2022-07-05 06:04:35 - train: epoch 0100, iter [02900, 05004], lr: 0.000100, loss: 1.1390
2022-07-05 06:05:08 - train: epoch 0100, iter [03000, 05004], lr: 0.000100, loss: 0.8518
2022-07-05 06:05:41 - train: epoch 0100, iter [03100, 05004], lr: 0.000100, loss: 0.9225
2022-07-05 06:06:14 - train: epoch 0100, iter [03200, 05004], lr: 0.000100, loss: 0.8677
2022-07-05 06:06:47 - train: epoch 0100, iter [03300, 05004], lr: 0.000100, loss: 0.8827
2022-07-05 06:07:21 - train: epoch 0100, iter [03400, 05004], lr: 0.000100, loss: 0.9805
2022-07-05 06:07:53 - train: epoch 0100, iter [03500, 05004], lr: 0.000100, loss: 0.7722
2022-07-05 06:08:27 - train: epoch 0100, iter [03600, 05004], lr: 0.000100, loss: 0.8793
2022-07-05 06:09:00 - train: epoch 0100, iter [03700, 05004], lr: 0.000100, loss: 0.9807
2022-07-05 06:09:33 - train: epoch 0100, iter [03800, 05004], lr: 0.000100, loss: 0.9087
2022-07-05 06:10:06 - train: epoch 0100, iter [03900, 05004], lr: 0.000100, loss: 1.1031
2022-07-05 06:10:40 - train: epoch 0100, iter [04000, 05004], lr: 0.000100, loss: 0.9583
2022-07-05 06:11:14 - train: epoch 0100, iter [04100, 05004], lr: 0.000100, loss: 1.1576
2022-07-05 06:11:46 - train: epoch 0100, iter [04200, 05004], lr: 0.000100, loss: 0.9936
2022-07-05 06:12:20 - train: epoch 0100, iter [04300, 05004], lr: 0.000100, loss: 1.0091
2022-07-05 06:12:52 - train: epoch 0100, iter [04400, 05004], lr: 0.000100, loss: 0.9913
2022-07-05 06:13:26 - train: epoch 0100, iter [04500, 05004], lr: 0.000100, loss: 0.9479
2022-07-05 06:14:00 - train: epoch 0100, iter [04600, 05004], lr: 0.000100, loss: 0.8896
2022-07-05 06:14:33 - train: epoch 0100, iter [04700, 05004], lr: 0.000100, loss: 1.1011
2022-07-05 06:15:07 - train: epoch 0100, iter [04800, 05004], lr: 0.000100, loss: 0.9346
2022-07-05 06:15:39 - train: epoch 0100, iter [04900, 05004], lr: 0.000100, loss: 0.9948
2022-07-05 06:16:10 - train: epoch 0100, iter [05000, 05004], lr: 0.000100, loss: 1.1274
2022-07-05 06:16:11 - train: epoch 100, train_loss: 0.9554
2022-07-05 06:17:26 - eval: epoch: 100, acc1: 73.702%, acc5: 91.482%, test_loss: 1.0646, per_image_load_time: 2.620ms, per_image_inference_time: 0.282ms
2022-07-05 06:17:26 - until epoch: 100, best_acc1: 73.752%
2022-07-05 06:17:26 - train done. model: resnet34, train time: 48.221 hours, best_acc1: 73.752%
