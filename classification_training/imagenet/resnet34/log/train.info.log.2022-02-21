2022-02-21 05:09:16 - train: epoch 0044, iter [03600, 05004], lr: 0.010000, loss: 1.6267
2022-02-21 05:09:53 - train: epoch 0044, iter [03700, 05004], lr: 0.010000, loss: 1.6093
2022-02-21 05:10:30 - train: epoch 0044, iter [03800, 05004], lr: 0.010000, loss: 1.2693
2022-02-21 05:11:07 - train: epoch 0044, iter [03900, 05004], lr: 0.010000, loss: 1.5900
2022-02-21 05:11:44 - train: epoch 0044, iter [04000, 05004], lr: 0.010000, loss: 1.6975
2022-02-21 05:12:21 - train: epoch 0044, iter [04100, 05004], lr: 0.010000, loss: 1.4256
2022-02-21 05:12:58 - train: epoch 0044, iter [04200, 05004], lr: 0.010000, loss: 1.5378
2022-02-21 05:13:34 - train: epoch 0044, iter [04300, 05004], lr: 0.010000, loss: 1.6294
2022-02-21 05:14:12 - train: epoch 0044, iter [04400, 05004], lr: 0.010000, loss: 1.3875
2022-02-21 05:14:49 - train: epoch 0044, iter [04500, 05004], lr: 0.010000, loss: 1.5559
2022-02-21 05:15:26 - train: epoch 0044, iter [04600, 05004], lr: 0.010000, loss: 1.3992
2022-02-21 05:16:04 - train: epoch 0044, iter [04700, 05004], lr: 0.010000, loss: 1.5701
2022-02-21 05:16:41 - train: epoch 0044, iter [04800, 05004], lr: 0.010000, loss: 1.7146
2022-02-21 05:17:17 - train: epoch 0044, iter [04900, 05004], lr: 0.010000, loss: 1.3489
2022-02-21 05:17:52 - train: epoch 0044, iter [05000, 05004], lr: 0.010000, loss: 1.5354
2022-02-21 05:17:54 - train: epoch 044, train_loss: 1.4823
2022-02-21 05:19:17 - eval: epoch: 044, acc1: 67.628%, acc5: 88.484%, test_loss: 1.3073, per_image_load_time: 2.955ms, per_image_inference_time: 0.269ms
2022-02-21 05:19:18 - until epoch: 044, best_acc1: 68.392%
2022-02-21 05:19:18 - epoch 045 lr: 0.010000000000000002
2022-02-21 05:20:00 - train: epoch 0045, iter [00100, 05004], lr: 0.010000, loss: 1.3647
2022-02-21 05:20:37 - train: epoch 0045, iter [00200, 05004], lr: 0.010000, loss: 1.4791
2022-02-21 05:21:14 - train: epoch 0045, iter [00300, 05004], lr: 0.010000, loss: 1.5257
2022-02-21 05:21:51 - train: epoch 0045, iter [00400, 05004], lr: 0.010000, loss: 1.3916
2022-02-21 05:22:29 - train: epoch 0045, iter [00500, 05004], lr: 0.010000, loss: 1.5184
2022-02-21 05:23:07 - train: epoch 0045, iter [00600, 05004], lr: 0.010000, loss: 1.5498
2022-02-21 05:23:44 - train: epoch 0045, iter [00700, 05004], lr: 0.010000, loss: 1.2396
2022-02-21 05:24:20 - train: epoch 0045, iter [00800, 05004], lr: 0.010000, loss: 1.3548
2022-02-21 05:24:57 - train: epoch 0045, iter [00900, 05004], lr: 0.010000, loss: 1.5257
2022-02-21 05:25:35 - train: epoch 0045, iter [01000, 05004], lr: 0.010000, loss: 1.3488
2022-02-21 05:26:12 - train: epoch 0045, iter [01100, 05004], lr: 0.010000, loss: 1.5815
2022-02-21 05:26:50 - train: epoch 0045, iter [01200, 05004], lr: 0.010000, loss: 1.5942
2022-02-21 05:27:27 - train: epoch 0045, iter [01300, 05004], lr: 0.010000, loss: 1.5807
2022-02-21 05:28:04 - train: epoch 0045, iter [01400, 05004], lr: 0.010000, loss: 1.5235
2022-02-21 05:28:42 - train: epoch 0045, iter [01500, 05004], lr: 0.010000, loss: 1.5093
2022-02-21 05:29:18 - train: epoch 0045, iter [01600, 05004], lr: 0.010000, loss: 1.3692
2022-02-21 05:29:56 - train: epoch 0045, iter [01700, 05004], lr: 0.010000, loss: 1.4068
2022-02-21 05:30:33 - train: epoch 0045, iter [01800, 05004], lr: 0.010000, loss: 1.3876
2022-02-21 05:31:11 - train: epoch 0045, iter [01900, 05004], lr: 0.010000, loss: 1.5524
2022-02-21 05:31:47 - train: epoch 0045, iter [02000, 05004], lr: 0.010000, loss: 1.6232
2022-02-21 05:32:25 - train: epoch 0045, iter [02100, 05004], lr: 0.010000, loss: 1.5409
2022-02-21 05:33:02 - train: epoch 0045, iter [02200, 05004], lr: 0.010000, loss: 1.5437
2022-02-21 05:33:40 - train: epoch 0045, iter [02300, 05004], lr: 0.010000, loss: 1.2976
2022-02-21 05:34:17 - train: epoch 0045, iter [02400, 05004], lr: 0.010000, loss: 1.6485
2022-02-21 05:34:53 - train: epoch 0045, iter [02500, 05004], lr: 0.010000, loss: 1.5313
2022-02-21 05:35:31 - train: epoch 0045, iter [02600, 05004], lr: 0.010000, loss: 1.4256
2022-02-21 05:36:08 - train: epoch 0045, iter [02700, 05004], lr: 0.010000, loss: 1.3061
2022-02-21 05:36:46 - train: epoch 0045, iter [02800, 05004], lr: 0.010000, loss: 1.4932
2022-02-21 05:37:22 - train: epoch 0045, iter [02900, 05004], lr: 0.010000, loss: 1.5854
2022-02-21 05:38:00 - train: epoch 0045, iter [03000, 05004], lr: 0.010000, loss: 1.7640
2022-02-21 05:38:36 - train: epoch 0045, iter [03100, 05004], lr: 0.010000, loss: 1.4797
2022-02-21 05:39:13 - train: epoch 0045, iter [03200, 05004], lr: 0.010000, loss: 1.5891
2022-02-21 05:39:51 - train: epoch 0045, iter [03300, 05004], lr: 0.010000, loss: 1.5060
2022-02-21 05:40:28 - train: epoch 0045, iter [03400, 05004], lr: 0.010000, loss: 1.3042
2022-02-21 05:41:05 - train: epoch 0045, iter [03500, 05004], lr: 0.010000, loss: 1.6549
2022-02-21 05:41:42 - train: epoch 0045, iter [03600, 05004], lr: 0.010000, loss: 1.6076
2022-02-21 05:42:19 - train: epoch 0045, iter [03700, 05004], lr: 0.010000, loss: 1.4398
2022-02-21 05:42:56 - train: epoch 0045, iter [03800, 05004], lr: 0.010000, loss: 1.2625
2022-02-21 05:43:34 - train: epoch 0045, iter [03900, 05004], lr: 0.010000, loss: 1.5784
2022-02-21 05:44:11 - train: epoch 0045, iter [04000, 05004], lr: 0.010000, loss: 1.6000
2022-02-21 05:44:48 - train: epoch 0045, iter [04100, 05004], lr: 0.010000, loss: 1.4793
2022-02-21 05:45:25 - train: epoch 0045, iter [04200, 05004], lr: 0.010000, loss: 1.5905
2022-02-21 05:46:02 - train: epoch 0045, iter [04300, 05004], lr: 0.010000, loss: 1.6308
2022-02-21 05:46:39 - train: epoch 0045, iter [04400, 05004], lr: 0.010000, loss: 1.5954
2022-02-21 05:47:17 - train: epoch 0045, iter [04500, 05004], lr: 0.010000, loss: 1.3720
2022-02-21 05:47:53 - train: epoch 0045, iter [04600, 05004], lr: 0.010000, loss: 1.5447
2022-02-21 05:48:32 - train: epoch 0045, iter [04700, 05004], lr: 0.010000, loss: 1.5145
2022-02-21 05:49:08 - train: epoch 0045, iter [04800, 05004], lr: 0.010000, loss: 1.3942
2022-02-21 05:49:45 - train: epoch 0045, iter [04900, 05004], lr: 0.010000, loss: 1.4494
2022-02-21 05:50:21 - train: epoch 0045, iter [05000, 05004], lr: 0.010000, loss: 1.4379
2022-02-21 05:50:22 - train: epoch 045, train_loss: 1.4781
2022-02-21 05:51:45 - eval: epoch: 045, acc1: 67.044%, acc5: 88.212%, test_loss: 1.3194, per_image_load_time: 2.880ms, per_image_inference_time: 0.314ms
2022-02-21 05:51:45 - until epoch: 045, best_acc1: 68.392%
2022-02-21 05:51:45 - epoch 046 lr: 0.010000000000000002
2022-02-21 05:52:27 - train: epoch 0046, iter [00100, 05004], lr: 0.010000, loss: 1.1975
2022-02-21 05:53:04 - train: epoch 0046, iter [00200, 05004], lr: 0.010000, loss: 1.3362
2022-02-21 05:53:42 - train: epoch 0046, iter [00300, 05004], lr: 0.010000, loss: 1.5798
2022-02-21 05:54:20 - train: epoch 0046, iter [00400, 05004], lr: 0.010000, loss: 1.5631
2022-02-21 05:54:57 - train: epoch 0046, iter [00500, 05004], lr: 0.010000, loss: 1.2674
2022-02-21 05:55:34 - train: epoch 0046, iter [00600, 05004], lr: 0.010000, loss: 1.5931
2022-02-21 05:56:10 - train: epoch 0046, iter [00700, 05004], lr: 0.010000, loss: 1.4767
2022-02-21 05:56:47 - train: epoch 0046, iter [00800, 05004], lr: 0.010000, loss: 1.5664
2022-02-21 05:57:24 - train: epoch 0046, iter [00900, 05004], lr: 0.010000, loss: 1.5482
2022-02-21 05:58:01 - train: epoch 0046, iter [01000, 05004], lr: 0.010000, loss: 1.2448
2022-02-21 05:58:38 - train: epoch 0046, iter [01100, 05004], lr: 0.010000, loss: 1.5233
2022-02-21 05:59:15 - train: epoch 0046, iter [01200, 05004], lr: 0.010000, loss: 1.4636
2022-02-21 05:59:52 - train: epoch 0046, iter [01300, 05004], lr: 0.010000, loss: 1.4491
2022-02-21 06:00:30 - train: epoch 0046, iter [01400, 05004], lr: 0.010000, loss: 1.6779
2022-02-21 06:01:06 - train: epoch 0046, iter [01500, 05004], lr: 0.010000, loss: 1.4138
2022-02-21 06:01:45 - train: epoch 0046, iter [01600, 05004], lr: 0.010000, loss: 1.4926
2022-02-21 06:02:21 - train: epoch 0046, iter [01700, 05004], lr: 0.010000, loss: 1.3917
2022-02-21 06:02:58 - train: epoch 0046, iter [01800, 05004], lr: 0.010000, loss: 1.4207
2022-02-21 06:03:35 - train: epoch 0046, iter [01900, 05004], lr: 0.010000, loss: 1.3529
2022-02-21 06:04:12 - train: epoch 0046, iter [02000, 05004], lr: 0.010000, loss: 1.3788
2022-02-21 06:04:50 - train: epoch 0046, iter [02100, 05004], lr: 0.010000, loss: 1.5598
2022-02-21 06:05:28 - train: epoch 0046, iter [02200, 05004], lr: 0.010000, loss: 1.2832
2022-02-21 06:06:04 - train: epoch 0046, iter [02300, 05004], lr: 0.010000, loss: 1.6084
2022-02-21 06:06:41 - train: epoch 0046, iter [02400, 05004], lr: 0.010000, loss: 1.4282
2022-02-21 06:07:18 - train: epoch 0046, iter [02500, 05004], lr: 0.010000, loss: 1.4923
2022-02-21 06:07:57 - train: epoch 0046, iter [02600, 05004], lr: 0.010000, loss: 1.5434
2022-02-21 06:08:34 - train: epoch 0046, iter [02700, 05004], lr: 0.010000, loss: 1.3858
2022-02-21 06:09:11 - train: epoch 0046, iter [02800, 05004], lr: 0.010000, loss: 1.3673
2022-02-21 06:09:48 - train: epoch 0046, iter [02900, 05004], lr: 0.010000, loss: 1.4477
2022-02-21 06:10:25 - train: epoch 0046, iter [03000, 05004], lr: 0.010000, loss: 1.3308
2022-02-21 06:11:02 - train: epoch 0046, iter [03100, 05004], lr: 0.010000, loss: 1.3336
2022-02-21 06:11:40 - train: epoch 0046, iter [03200, 05004], lr: 0.010000, loss: 1.7646
2022-02-21 06:12:17 - train: epoch 0046, iter [03300, 05004], lr: 0.010000, loss: 1.5229
2022-02-21 06:12:53 - train: epoch 0046, iter [03400, 05004], lr: 0.010000, loss: 1.5232
2022-02-21 06:13:30 - train: epoch 0046, iter [03500, 05004], lr: 0.010000, loss: 1.4838
2022-02-21 06:14:07 - train: epoch 0046, iter [03600, 05004], lr: 0.010000, loss: 1.4636
2022-02-21 06:14:45 - train: epoch 0046, iter [03700, 05004], lr: 0.010000, loss: 1.3698
2022-02-21 06:15:22 - train: epoch 0046, iter [03800, 05004], lr: 0.010000, loss: 1.6314
2022-02-21 06:16:00 - train: epoch 0046, iter [03900, 05004], lr: 0.010000, loss: 1.5415
2022-02-21 06:16:36 - train: epoch 0046, iter [04000, 05004], lr: 0.010000, loss: 1.3221
2022-02-21 06:17:13 - train: epoch 0046, iter [04100, 05004], lr: 0.010000, loss: 1.6494
2022-02-21 06:17:51 - train: epoch 0046, iter [04200, 05004], lr: 0.010000, loss: 1.4651
2022-02-21 06:18:28 - train: epoch 0046, iter [04300, 05004], lr: 0.010000, loss: 1.6476
2022-02-21 06:19:05 - train: epoch 0046, iter [04400, 05004], lr: 0.010000, loss: 1.5391
2022-02-21 06:19:43 - train: epoch 0046, iter [04500, 05004], lr: 0.010000, loss: 1.3593
2022-02-21 06:20:21 - train: epoch 0046, iter [04600, 05004], lr: 0.010000, loss: 1.5660
2022-02-21 06:20:58 - train: epoch 0046, iter [04700, 05004], lr: 0.010000, loss: 1.4338
2022-02-21 06:21:35 - train: epoch 0046, iter [04800, 05004], lr: 0.010000, loss: 1.5330
2022-02-21 06:22:11 - train: epoch 0046, iter [04900, 05004], lr: 0.010000, loss: 1.5134
2022-02-21 06:22:47 - train: epoch 0046, iter [05000, 05004], lr: 0.010000, loss: 1.4614
2022-02-21 06:22:48 - train: epoch 046, train_loss: 1.4781
2022-02-21 06:24:11 - eval: epoch: 046, acc1: 67.858%, acc5: 88.604%, test_loss: 1.2941, per_image_load_time: 2.970ms, per_image_inference_time: 0.281ms
2022-02-21 06:24:12 - until epoch: 046, best_acc1: 68.392%
2022-02-21 06:24:12 - epoch 047 lr: 0.010000000000000002
2022-02-21 06:24:54 - train: epoch 0047, iter [00100, 05004], lr: 0.010000, loss: 1.4001
2022-02-21 06:25:30 - train: epoch 0047, iter [00200, 05004], lr: 0.010000, loss: 1.6286
2022-02-21 06:26:09 - train: epoch 0047, iter [00300, 05004], lr: 0.010000, loss: 1.3599
2022-02-21 06:26:46 - train: epoch 0047, iter [00400, 05004], lr: 0.010000, loss: 1.3787
2022-02-21 06:27:23 - train: epoch 0047, iter [00500, 05004], lr: 0.010000, loss: 1.5139
2022-02-21 06:27:59 - train: epoch 0047, iter [00600, 05004], lr: 0.010000, loss: 1.5326
2022-02-21 06:28:36 - train: epoch 0047, iter [00700, 05004], lr: 0.010000, loss: 1.5709
2022-02-21 06:29:14 - train: epoch 0047, iter [00800, 05004], lr: 0.010000, loss: 1.2797
2022-02-21 06:29:50 - train: epoch 0047, iter [00900, 05004], lr: 0.010000, loss: 1.7083
2022-02-21 06:30:28 - train: epoch 0047, iter [01000, 05004], lr: 0.010000, loss: 1.4786
2022-02-21 06:31:05 - train: epoch 0047, iter [01100, 05004], lr: 0.010000, loss: 1.5454
2022-02-21 06:31:42 - train: epoch 0047, iter [01200, 05004], lr: 0.010000, loss: 1.4753
2022-02-21 06:32:19 - train: epoch 0047, iter [01300, 05004], lr: 0.010000, loss: 1.5404
2022-02-21 06:32:58 - train: epoch 0047, iter [01400, 05004], lr: 0.010000, loss: 1.4677
2022-02-21 06:33:34 - train: epoch 0047, iter [01500, 05004], lr: 0.010000, loss: 1.4579
2022-02-21 06:34:11 - train: epoch 0047, iter [01600, 05004], lr: 0.010000, loss: 1.3692
2022-02-21 06:34:48 - train: epoch 0047, iter [01700, 05004], lr: 0.010000, loss: 1.2882
2022-02-21 06:35:25 - train: epoch 0047, iter [01800, 05004], lr: 0.010000, loss: 1.4364
2022-02-21 06:36:03 - train: epoch 0047, iter [01900, 05004], lr: 0.010000, loss: 1.4399
2022-02-21 06:36:39 - train: epoch 0047, iter [02000, 05004], lr: 0.010000, loss: 1.4595
2022-02-21 06:37:17 - train: epoch 0047, iter [02100, 05004], lr: 0.010000, loss: 1.5488
2022-02-21 06:37:56 - train: epoch 0047, iter [02200, 05004], lr: 0.010000, loss: 1.6268
2022-02-21 06:38:31 - train: epoch 0047, iter [02300, 05004], lr: 0.010000, loss: 1.4332
2022-02-21 06:39:09 - train: epoch 0047, iter [02400, 05004], lr: 0.010000, loss: 1.3742
2022-02-21 06:39:46 - train: epoch 0047, iter [02500, 05004], lr: 0.010000, loss: 1.4876
2022-02-21 06:40:23 - train: epoch 0047, iter [02600, 05004], lr: 0.010000, loss: 1.7413
2022-02-21 06:41:00 - train: epoch 0047, iter [02700, 05004], lr: 0.010000, loss: 1.5433
2022-02-21 06:41:38 - train: epoch 0047, iter [02800, 05004], lr: 0.010000, loss: 1.6378
2022-02-21 06:42:16 - train: epoch 0047, iter [02900, 05004], lr: 0.010000, loss: 1.4660
2022-02-21 06:42:53 - train: epoch 0047, iter [03000, 05004], lr: 0.010000, loss: 1.6055
2022-02-21 06:43:31 - train: epoch 0047, iter [03100, 05004], lr: 0.010000, loss: 1.4129
2022-02-21 06:44:07 - train: epoch 0047, iter [03200, 05004], lr: 0.010000, loss: 1.7732
2022-02-21 06:44:45 - train: epoch 0047, iter [03300, 05004], lr: 0.010000, loss: 1.3816
2022-02-21 06:45:21 - train: epoch 0047, iter [03400, 05004], lr: 0.010000, loss: 1.4990
2022-02-21 06:45:58 - train: epoch 0047, iter [03500, 05004], lr: 0.010000, loss: 1.7199
2022-02-21 06:46:35 - train: epoch 0047, iter [03600, 05004], lr: 0.010000, loss: 1.5398
2022-02-21 06:47:13 - train: epoch 0047, iter [03700, 05004], lr: 0.010000, loss: 1.5722
2022-02-21 06:47:49 - train: epoch 0047, iter [03800, 05004], lr: 0.010000, loss: 1.5286
2022-02-21 06:48:27 - train: epoch 0047, iter [03900, 05004], lr: 0.010000, loss: 1.4760
2022-02-21 06:49:04 - train: epoch 0047, iter [04000, 05004], lr: 0.010000, loss: 1.4540
2022-02-21 06:49:41 - train: epoch 0047, iter [04100, 05004], lr: 0.010000, loss: 1.5519
2022-02-21 06:50:18 - train: epoch 0047, iter [04200, 05004], lr: 0.010000, loss: 1.5090
2022-02-21 06:50:56 - train: epoch 0047, iter [04300, 05004], lr: 0.010000, loss: 1.3358
2022-02-21 06:51:33 - train: epoch 0047, iter [04400, 05004], lr: 0.010000, loss: 1.4584
2022-02-21 06:52:09 - train: epoch 0047, iter [04500, 05004], lr: 0.010000, loss: 1.6305
2022-02-21 06:52:45 - train: epoch 0047, iter [04600, 05004], lr: 0.010000, loss: 1.5226
2022-02-21 06:53:23 - train: epoch 0047, iter [04700, 05004], lr: 0.010000, loss: 1.5554
2022-02-21 06:53:59 - train: epoch 0047, iter [04800, 05004], lr: 0.010000, loss: 1.3733
2022-02-21 06:54:38 - train: epoch 0047, iter [04900, 05004], lr: 0.010000, loss: 1.5765
2022-02-21 06:55:13 - train: epoch 0047, iter [05000, 05004], lr: 0.010000, loss: 1.4399
2022-02-21 06:55:14 - train: epoch 047, train_loss: 1.4794
2022-02-21 06:56:36 - eval: epoch: 047, acc1: 67.700%, acc5: 88.216%, test_loss: 1.3095, per_image_load_time: 2.922ms, per_image_inference_time: 0.306ms
2022-02-21 06:56:37 - until epoch: 047, best_acc1: 68.392%
2022-02-21 06:56:37 - epoch 048 lr: 0.010000000000000002
2022-02-21 06:57:19 - train: epoch 0048, iter [00100, 05004], lr: 0.010000, loss: 1.6838
2022-02-21 06:57:57 - train: epoch 0048, iter [00200, 05004], lr: 0.010000, loss: 1.7751
2022-02-21 06:58:34 - train: epoch 0048, iter [00300, 05004], lr: 0.010000, loss: 1.3929
2022-02-21 06:59:11 - train: epoch 0048, iter [00400, 05004], lr: 0.010000, loss: 1.4860
2022-02-21 06:59:49 - train: epoch 0048, iter [00500, 05004], lr: 0.010000, loss: 1.2684
2022-02-21 07:00:26 - train: epoch 0048, iter [00600, 05004], lr: 0.010000, loss: 1.4677
2022-02-21 07:01:03 - train: epoch 0048, iter [00700, 05004], lr: 0.010000, loss: 1.4906
2022-02-21 07:01:40 - train: epoch 0048, iter [00800, 05004], lr: 0.010000, loss: 1.4756
2022-02-21 07:02:17 - train: epoch 0048, iter [00900, 05004], lr: 0.010000, loss: 1.6128
2022-02-21 07:02:55 - train: epoch 0048, iter [01000, 05004], lr: 0.010000, loss: 1.4884
2022-02-21 07:03:32 - train: epoch 0048, iter [01100, 05004], lr: 0.010000, loss: 1.4614
2022-02-21 07:04:08 - train: epoch 0048, iter [01200, 05004], lr: 0.010000, loss: 1.6024
2022-02-21 07:04:46 - train: epoch 0048, iter [01300, 05004], lr: 0.010000, loss: 1.2132
2022-02-21 07:05:24 - train: epoch 0048, iter [01400, 05004], lr: 0.010000, loss: 1.4402
2022-02-21 07:06:00 - train: epoch 0048, iter [01500, 05004], lr: 0.010000, loss: 1.4953
2022-02-21 07:06:35 - train: epoch 0048, iter [01600, 05004], lr: 0.010000, loss: 1.4014
2022-02-21 07:07:09 - train: epoch 0048, iter [01700, 05004], lr: 0.010000, loss: 1.6775
2022-02-21 07:07:48 - train: epoch 0048, iter [01800, 05004], lr: 0.010000, loss: 1.4671
2022-02-21 07:08:28 - train: epoch 0048, iter [01900, 05004], lr: 0.010000, loss: 1.4695
2022-02-21 07:09:05 - train: epoch 0048, iter [02000, 05004], lr: 0.010000, loss: 1.6626
2022-02-21 07:09:42 - train: epoch 0048, iter [02100, 05004], lr: 0.010000, loss: 1.5011
2022-02-21 07:10:20 - train: epoch 0048, iter [02200, 05004], lr: 0.010000, loss: 1.7124
2022-02-21 07:10:57 - train: epoch 0048, iter [02300, 05004], lr: 0.010000, loss: 1.3127
2022-02-21 07:11:34 - train: epoch 0048, iter [02400, 05004], lr: 0.010000, loss: 1.6110
2022-02-21 07:12:10 - train: epoch 0048, iter [02500, 05004], lr: 0.010000, loss: 1.4514
2022-02-21 07:12:49 - train: epoch 0048, iter [02600, 05004], lr: 0.010000, loss: 1.7627
2022-02-21 07:13:25 - train: epoch 0048, iter [02700, 05004], lr: 0.010000, loss: 1.6504
2022-02-21 07:14:02 - train: epoch 0048, iter [02800, 05004], lr: 0.010000, loss: 1.3851
2022-02-21 07:14:39 - train: epoch 0048, iter [02900, 05004], lr: 0.010000, loss: 1.5963
2022-02-21 07:15:17 - train: epoch 0048, iter [03000, 05004], lr: 0.010000, loss: 1.4947
2022-02-21 07:15:54 - train: epoch 0048, iter [03100, 05004], lr: 0.010000, loss: 1.4225
2022-02-21 07:16:32 - train: epoch 0048, iter [03200, 05004], lr: 0.010000, loss: 1.3153
2022-02-21 07:17:08 - train: epoch 0048, iter [03300, 05004], lr: 0.010000, loss: 1.6180
2022-02-21 07:17:45 - train: epoch 0048, iter [03400, 05004], lr: 0.010000, loss: 1.3992
2022-02-21 07:18:22 - train: epoch 0048, iter [03500, 05004], lr: 0.010000, loss: 1.7429
2022-02-21 07:19:00 - train: epoch 0048, iter [03600, 05004], lr: 0.010000, loss: 1.4656
2022-02-21 07:19:37 - train: epoch 0048, iter [03700, 05004], lr: 0.010000, loss: 1.5937
2022-02-21 07:20:14 - train: epoch 0048, iter [03800, 05004], lr: 0.010000, loss: 1.5335
2022-02-21 07:20:51 - train: epoch 0048, iter [03900, 05004], lr: 0.010000, loss: 1.6320
2022-02-21 07:21:29 - train: epoch 0048, iter [04000, 05004], lr: 0.010000, loss: 1.2305
2022-02-21 07:22:06 - train: epoch 0048, iter [04100, 05004], lr: 0.010000, loss: 1.6627
2022-02-21 07:22:43 - train: epoch 0048, iter [04200, 05004], lr: 0.010000, loss: 1.4582
2022-02-21 07:23:20 - train: epoch 0048, iter [04300, 05004], lr: 0.010000, loss: 1.4706
2022-02-21 07:23:58 - train: epoch 0048, iter [04400, 05004], lr: 0.010000, loss: 1.3746
2022-02-21 07:24:33 - train: epoch 0048, iter [04500, 05004], lr: 0.010000, loss: 1.5251
2022-02-21 07:25:11 - train: epoch 0048, iter [04600, 05004], lr: 0.010000, loss: 1.4856
2022-02-21 07:25:48 - train: epoch 0048, iter [04700, 05004], lr: 0.010000, loss: 1.5457
2022-02-21 07:26:26 - train: epoch 0048, iter [04800, 05004], lr: 0.010000, loss: 1.8727
2022-02-21 07:27:04 - train: epoch 0048, iter [04900, 05004], lr: 0.010000, loss: 1.5397
2022-02-21 07:27:39 - train: epoch 0048, iter [05000, 05004], lr: 0.010000, loss: 1.5190
2022-02-21 07:27:40 - train: epoch 048, train_loss: 1.4812
2022-02-21 07:29:03 - eval: epoch: 048, acc1: 67.276%, acc5: 88.166%, test_loss: 1.3179, per_image_load_time: 2.932ms, per_image_inference_time: 0.298ms
2022-02-21 07:29:04 - until epoch: 048, best_acc1: 68.392%
2022-02-21 07:29:04 - epoch 049 lr: 0.010000000000000002
2022-02-21 07:29:46 - train: epoch 0049, iter [00100, 05004], lr: 0.010000, loss: 1.6748
2022-02-21 07:30:23 - train: epoch 0049, iter [00200, 05004], lr: 0.010000, loss: 1.4350
2022-02-21 07:31:01 - train: epoch 0049, iter [00300, 05004], lr: 0.010000, loss: 1.5579
2022-02-21 07:31:38 - train: epoch 0049, iter [00400, 05004], lr: 0.010000, loss: 1.4798
2022-02-21 07:32:15 - train: epoch 0049, iter [00500, 05004], lr: 0.010000, loss: 1.4569
2022-02-21 07:32:51 - train: epoch 0049, iter [00600, 05004], lr: 0.010000, loss: 1.4443
2022-02-21 07:33:30 - train: epoch 0049, iter [00700, 05004], lr: 0.010000, loss: 1.4964
2022-02-21 07:34:06 - train: epoch 0049, iter [00800, 05004], lr: 0.010000, loss: 1.7390
2022-02-21 07:34:44 - train: epoch 0049, iter [00900, 05004], lr: 0.010000, loss: 1.3485
2022-02-21 07:35:20 - train: epoch 0049, iter [01000, 05004], lr: 0.010000, loss: 1.5189
2022-02-21 07:35:58 - train: epoch 0049, iter [01100, 05004], lr: 0.010000, loss: 1.4311
2022-02-21 07:36:35 - train: epoch 0049, iter [01200, 05004], lr: 0.010000, loss: 1.2314
2022-02-21 07:37:14 - train: epoch 0049, iter [01300, 05004], lr: 0.010000, loss: 1.6198
2022-02-21 07:37:50 - train: epoch 0049, iter [01400, 05004], lr: 0.010000, loss: 1.6469
2022-02-21 07:38:27 - train: epoch 0049, iter [01500, 05004], lr: 0.010000, loss: 1.4064
2022-02-21 07:39:03 - train: epoch 0049, iter [01600, 05004], lr: 0.010000, loss: 1.6412
2022-02-21 07:39:41 - train: epoch 0049, iter [01700, 05004], lr: 0.010000, loss: 1.5717
2022-02-21 07:40:18 - train: epoch 0049, iter [01800, 05004], lr: 0.010000, loss: 1.3658
2022-02-21 07:40:54 - train: epoch 0049, iter [01900, 05004], lr: 0.010000, loss: 1.5272
2022-02-21 07:41:32 - train: epoch 0049, iter [02000, 05004], lr: 0.010000, loss: 1.3810
2022-02-21 07:42:08 - train: epoch 0049, iter [02100, 05004], lr: 0.010000, loss: 1.3844
2022-02-21 07:42:46 - train: epoch 0049, iter [02200, 05004], lr: 0.010000, loss: 1.4547
2022-02-21 07:43:22 - train: epoch 0049, iter [02300, 05004], lr: 0.010000, loss: 1.4209
2022-02-21 07:44:00 - train: epoch 0049, iter [02400, 05004], lr: 0.010000, loss: 1.6000
2022-02-21 07:44:37 - train: epoch 0049, iter [02500, 05004], lr: 0.010000, loss: 1.5134
2022-02-21 07:45:15 - train: epoch 0049, iter [02600, 05004], lr: 0.010000, loss: 1.4883
2022-02-21 07:45:51 - train: epoch 0049, iter [02700, 05004], lr: 0.010000, loss: 1.2914
2022-02-21 07:46:28 - train: epoch 0049, iter [02800, 05004], lr: 0.010000, loss: 1.4238
2022-02-21 07:47:05 - train: epoch 0049, iter [02900, 05004], lr: 0.010000, loss: 1.5928
2022-02-21 07:47:43 - train: epoch 0049, iter [03000, 05004], lr: 0.010000, loss: 1.5205
2022-02-21 07:48:21 - train: epoch 0049, iter [03100, 05004], lr: 0.010000, loss: 1.4721
2022-02-21 07:48:57 - train: epoch 0049, iter [03200, 05004], lr: 0.010000, loss: 1.4864
2022-02-21 07:49:34 - train: epoch 0049, iter [03300, 05004], lr: 0.010000, loss: 1.5601
2022-02-21 07:50:11 - train: epoch 0049, iter [03400, 05004], lr: 0.010000, loss: 1.5793
2022-02-21 07:50:49 - train: epoch 0049, iter [03500, 05004], lr: 0.010000, loss: 1.4899
2022-02-21 07:51:25 - train: epoch 0049, iter [03600, 05004], lr: 0.010000, loss: 1.6439
2022-02-21 07:52:02 - train: epoch 0049, iter [03700, 05004], lr: 0.010000, loss: 1.5600
2022-02-21 07:52:42 - train: epoch 0049, iter [03800, 05004], lr: 0.010000, loss: 1.6015
2022-02-21 07:53:17 - train: epoch 0049, iter [03900, 05004], lr: 0.010000, loss: 1.6595
2022-02-21 07:53:55 - train: epoch 0049, iter [04000, 05004], lr: 0.010000, loss: 1.4474
2022-02-21 07:54:31 - train: epoch 0049, iter [04100, 05004], lr: 0.010000, loss: 1.3798
2022-02-21 07:55:09 - train: epoch 0049, iter [04200, 05004], lr: 0.010000, loss: 1.4971
2022-02-21 07:55:46 - train: epoch 0049, iter [04300, 05004], lr: 0.010000, loss: 1.6839
2022-02-21 07:56:22 - train: epoch 0049, iter [04400, 05004], lr: 0.010000, loss: 1.4464
2022-02-21 07:57:00 - train: epoch 0049, iter [04500, 05004], lr: 0.010000, loss: 1.5008
2022-02-21 07:57:37 - train: epoch 0049, iter [04600, 05004], lr: 0.010000, loss: 1.5906
2022-02-21 07:58:14 - train: epoch 0049, iter [04700, 05004], lr: 0.010000, loss: 1.7121
2022-02-21 07:58:52 - train: epoch 0049, iter [04800, 05004], lr: 0.010000, loss: 1.3375
2022-02-21 07:59:29 - train: epoch 0049, iter [04900, 05004], lr: 0.010000, loss: 1.3347
2022-02-21 08:00:04 - train: epoch 0049, iter [05000, 05004], lr: 0.010000, loss: 1.4112
2022-02-21 08:00:05 - train: epoch 049, train_loss: 1.4759
2022-02-21 08:01:29 - eval: epoch: 049, acc1: 67.854%, acc5: 88.366%, test_loss: 1.3020, per_image_load_time: 2.950ms, per_image_inference_time: 0.291ms
2022-02-21 08:01:30 - until epoch: 049, best_acc1: 68.392%
2022-02-21 08:01:30 - epoch 050 lr: 0.010000000000000002
2022-02-21 08:02:12 - train: epoch 0050, iter [00100, 05004], lr: 0.010000, loss: 1.5838
2022-02-21 08:02:49 - train: epoch 0050, iter [00200, 05004], lr: 0.010000, loss: 1.4255
2022-02-21 08:03:26 - train: epoch 0050, iter [00300, 05004], lr: 0.010000, loss: 1.4083
2022-02-21 08:04:03 - train: epoch 0050, iter [00400, 05004], lr: 0.010000, loss: 1.3117
2022-02-21 08:04:41 - train: epoch 0050, iter [00500, 05004], lr: 0.010000, loss: 1.4884
2022-02-21 08:05:19 - train: epoch 0050, iter [00600, 05004], lr: 0.010000, loss: 1.5968
2022-02-21 08:05:55 - train: epoch 0050, iter [00700, 05004], lr: 0.010000, loss: 1.3151
2022-02-21 08:06:33 - train: epoch 0050, iter [00800, 05004], lr: 0.010000, loss: 1.2402
2022-02-21 08:07:09 - train: epoch 0050, iter [00900, 05004], lr: 0.010000, loss: 1.2986
2022-02-21 08:07:46 - train: epoch 0050, iter [01000, 05004], lr: 0.010000, loss: 1.5710
2022-02-21 08:08:23 - train: epoch 0050, iter [01100, 05004], lr: 0.010000, loss: 1.4838
2022-02-21 08:09:01 - train: epoch 0050, iter [01200, 05004], lr: 0.010000, loss: 1.4820
2022-02-21 08:09:38 - train: epoch 0050, iter [01300, 05004], lr: 0.010000, loss: 1.2703
2022-02-21 08:10:16 - train: epoch 0050, iter [01400, 05004], lr: 0.010000, loss: 1.4484
2022-02-21 08:10:52 - train: epoch 0050, iter [01500, 05004], lr: 0.010000, loss: 1.5238
2022-02-21 08:11:30 - train: epoch 0050, iter [01600, 05004], lr: 0.010000, loss: 1.4279
2022-02-21 08:12:07 - train: epoch 0050, iter [01700, 05004], lr: 0.010000, loss: 1.5229
2022-02-21 08:12:45 - train: epoch 0050, iter [01800, 05004], lr: 0.010000, loss: 1.4440
2022-02-21 08:13:21 - train: epoch 0050, iter [01900, 05004], lr: 0.010000, loss: 1.4301
2022-02-21 08:13:58 - train: epoch 0050, iter [02000, 05004], lr: 0.010000, loss: 1.5259
2022-02-21 08:14:35 - train: epoch 0050, iter [02100, 05004], lr: 0.010000, loss: 1.2548
2022-02-21 08:15:13 - train: epoch 0050, iter [02200, 05004], lr: 0.010000, loss: 1.5990
2022-02-21 08:15:50 - train: epoch 0050, iter [02300, 05004], lr: 0.010000, loss: 1.4117
2022-02-21 08:16:28 - train: epoch 0050, iter [02400, 05004], lr: 0.010000, loss: 1.4847
2022-02-21 08:17:05 - train: epoch 0050, iter [02500, 05004], lr: 0.010000, loss: 1.5814
2022-02-21 08:17:42 - train: epoch 0050, iter [02600, 05004], lr: 0.010000, loss: 1.3428
2022-02-21 08:18:18 - train: epoch 0050, iter [02700, 05004], lr: 0.010000, loss: 1.5275
2022-02-21 08:18:56 - train: epoch 0050, iter [02800, 05004], lr: 0.010000, loss: 1.6219
2022-02-21 08:19:33 - train: epoch 0050, iter [02900, 05004], lr: 0.010000, loss: 1.7021
2022-02-21 08:20:11 - train: epoch 0050, iter [03000, 05004], lr: 0.010000, loss: 1.5954
2022-02-21 08:20:47 - train: epoch 0050, iter [03100, 05004], lr: 0.010000, loss: 1.3062
2022-02-21 08:21:24 - train: epoch 0050, iter [03200, 05004], lr: 0.010000, loss: 1.4581
2022-02-21 08:22:02 - train: epoch 0050, iter [03300, 05004], lr: 0.010000, loss: 1.3772
2022-02-21 08:22:40 - train: epoch 0050, iter [03400, 05004], lr: 0.010000, loss: 1.4245
2022-02-21 08:23:17 - train: epoch 0050, iter [03500, 05004], lr: 0.010000, loss: 1.3610
2022-02-21 08:23:55 - train: epoch 0050, iter [03600, 05004], lr: 0.010000, loss: 1.4375
2022-02-21 08:24:31 - train: epoch 0050, iter [03700, 05004], lr: 0.010000, loss: 1.5818
2022-02-21 08:25:08 - train: epoch 0050, iter [03800, 05004], lr: 0.010000, loss: 1.2417
2022-02-21 08:25:45 - train: epoch 0050, iter [03900, 05004], lr: 0.010000, loss: 1.3246
2022-02-21 08:26:24 - train: epoch 0050, iter [04000, 05004], lr: 0.010000, loss: 1.5792
2022-02-21 08:27:00 - train: epoch 0050, iter [04100, 05004], lr: 0.010000, loss: 1.3933
2022-02-21 08:27:38 - train: epoch 0050, iter [04200, 05004], lr: 0.010000, loss: 1.4547
2022-02-21 08:28:15 - train: epoch 0050, iter [04300, 05004], lr: 0.010000, loss: 1.3785
2022-02-21 08:28:52 - train: epoch 0050, iter [04400, 05004], lr: 0.010000, loss: 1.3707
2022-02-21 08:29:29 - train: epoch 0050, iter [04500, 05004], lr: 0.010000, loss: 1.3020
2022-02-21 08:30:06 - train: epoch 0050, iter [04600, 05004], lr: 0.010000, loss: 1.4206
2022-02-21 08:30:42 - train: epoch 0050, iter [04700, 05004], lr: 0.010000, loss: 1.4247
2022-02-21 08:31:18 - train: epoch 0050, iter [04800, 05004], lr: 0.010000, loss: 1.2574
2022-02-21 08:31:56 - train: epoch 0050, iter [04900, 05004], lr: 0.010000, loss: 1.2756
2022-02-21 08:32:32 - train: epoch 0050, iter [05000, 05004], lr: 0.010000, loss: 1.4029
2022-02-21 08:32:33 - train: epoch 050, train_loss: 1.4738
2022-02-21 08:33:56 - eval: epoch: 050, acc1: 67.546%, acc5: 88.180%, test_loss: 1.3116, per_image_load_time: 2.931ms, per_image_inference_time: 0.265ms
2022-02-21 08:33:56 - until epoch: 050, best_acc1: 68.392%
2022-02-21 08:33:56 - epoch 051 lr: 0.010000000000000002
2022-02-21 08:34:39 - train: epoch 0051, iter [00100, 05004], lr: 0.010000, loss: 1.6067
2022-02-21 08:35:16 - train: epoch 0051, iter [00200, 05004], lr: 0.010000, loss: 1.9029
2022-02-21 08:35:53 - train: epoch 0051, iter [00300, 05004], lr: 0.010000, loss: 1.5873
2022-02-21 08:36:31 - train: epoch 0051, iter [00400, 05004], lr: 0.010000, loss: 1.2859
2022-02-21 08:37:08 - train: epoch 0051, iter [00500, 05004], lr: 0.010000, loss: 1.4664
2022-02-21 08:37:44 - train: epoch 0051, iter [00600, 05004], lr: 0.010000, loss: 1.4601
2022-02-21 08:38:22 - train: epoch 0051, iter [00700, 05004], lr: 0.010000, loss: 1.3330
2022-02-21 08:38:59 - train: epoch 0051, iter [00800, 05004], lr: 0.010000, loss: 1.6967
2022-02-21 08:39:37 - train: epoch 0051, iter [00900, 05004], lr: 0.010000, loss: 1.2713
2022-02-21 08:40:14 - train: epoch 0051, iter [01000, 05004], lr: 0.010000, loss: 1.7120
2022-02-21 08:40:51 - train: epoch 0051, iter [01100, 05004], lr: 0.010000, loss: 1.6441
2022-02-21 08:41:29 - train: epoch 0051, iter [01200, 05004], lr: 0.010000, loss: 1.4235
2022-02-21 08:42:05 - train: epoch 0051, iter [01300, 05004], lr: 0.010000, loss: 1.1389
2022-02-21 08:42:43 - train: epoch 0051, iter [01400, 05004], lr: 0.010000, loss: 1.3757
2022-02-21 08:43:20 - train: epoch 0051, iter [01500, 05004], lr: 0.010000, loss: 1.4281
2022-02-21 08:43:58 - train: epoch 0051, iter [01600, 05004], lr: 0.010000, loss: 1.3428
2022-02-21 08:44:35 - train: epoch 0051, iter [01700, 05004], lr: 0.010000, loss: 1.6256
2022-02-21 08:45:12 - train: epoch 0051, iter [01800, 05004], lr: 0.010000, loss: 1.4423
2022-02-21 08:45:49 - train: epoch 0051, iter [01900, 05004], lr: 0.010000, loss: 1.2672
2022-02-21 08:46:26 - train: epoch 0051, iter [02000, 05004], lr: 0.010000, loss: 1.5091
2022-02-21 08:47:03 - train: epoch 0051, iter [02100, 05004], lr: 0.010000, loss: 1.4655
2022-02-21 08:47:41 - train: epoch 0051, iter [02200, 05004], lr: 0.010000, loss: 1.4169
2022-02-21 08:48:17 - train: epoch 0051, iter [02300, 05004], lr: 0.010000, loss: 1.5440
2022-02-21 08:48:54 - train: epoch 0051, iter [02400, 05004], lr: 0.010000, loss: 1.5906
2022-02-21 08:49:31 - train: epoch 0051, iter [02500, 05004], lr: 0.010000, loss: 1.3658
2022-02-21 08:50:09 - train: epoch 0051, iter [02600, 05004], lr: 0.010000, loss: 1.3563
2022-02-21 08:50:46 - train: epoch 0051, iter [02700, 05004], lr: 0.010000, loss: 1.5861
2022-02-21 08:51:24 - train: epoch 0051, iter [02800, 05004], lr: 0.010000, loss: 1.3446
2022-02-21 08:52:00 - train: epoch 0051, iter [02900, 05004], lr: 0.010000, loss: 1.4920
2022-02-21 08:52:37 - train: epoch 0051, iter [03000, 05004], lr: 0.010000, loss: 1.3433
2022-02-21 08:53:14 - train: epoch 0051, iter [03100, 05004], lr: 0.010000, loss: 1.4423
2022-02-21 08:53:52 - train: epoch 0051, iter [03200, 05004], lr: 0.010000, loss: 1.4231
2022-02-21 08:54:29 - train: epoch 0051, iter [03300, 05004], lr: 0.010000, loss: 1.5761
2022-02-21 08:55:07 - train: epoch 0051, iter [03400, 05004], lr: 0.010000, loss: 1.5268
2022-02-21 08:55:44 - train: epoch 0051, iter [03500, 05004], lr: 0.010000, loss: 1.4125
2022-02-21 08:56:21 - train: epoch 0051, iter [03600, 05004], lr: 0.010000, loss: 1.4333
2022-02-21 08:56:58 - train: epoch 0051, iter [03700, 05004], lr: 0.010000, loss: 1.5767
2022-02-21 08:57:36 - train: epoch 0051, iter [03800, 05004], lr: 0.010000, loss: 1.4977
2022-02-21 08:58:13 - train: epoch 0051, iter [03900, 05004], lr: 0.010000, loss: 1.5446
2022-02-21 08:58:50 - train: epoch 0051, iter [04000, 05004], lr: 0.010000, loss: 1.5065
2022-02-21 08:59:27 - train: epoch 0051, iter [04100, 05004], lr: 0.010000, loss: 1.5476
2022-02-21 09:00:04 - train: epoch 0051, iter [04200, 05004], lr: 0.010000, loss: 1.7818
2022-02-21 09:00:41 - train: epoch 0051, iter [04300, 05004], lr: 0.010000, loss: 1.3740
2022-02-21 09:01:18 - train: epoch 0051, iter [04400, 05004], lr: 0.010000, loss: 1.5591
2022-02-21 09:01:55 - train: epoch 0051, iter [04500, 05004], lr: 0.010000, loss: 1.2515
2022-02-21 09:02:33 - train: epoch 0051, iter [04600, 05004], lr: 0.010000, loss: 1.5706
2022-02-21 09:03:10 - train: epoch 0051, iter [04700, 05004], lr: 0.010000, loss: 1.5802
2022-02-21 09:03:48 - train: epoch 0051, iter [04800, 05004], lr: 0.010000, loss: 1.5064
2022-02-21 09:04:25 - train: epoch 0051, iter [04900, 05004], lr: 0.010000, loss: 1.5658
2022-02-21 09:05:00 - train: epoch 0051, iter [05000, 05004], lr: 0.010000, loss: 1.3968
2022-02-21 09:05:01 - train: epoch 051, train_loss: 1.4740
2022-02-21 09:06:24 - eval: epoch: 051, acc1: 67.624%, acc5: 88.218%, test_loss: 1.3079, per_image_load_time: 2.944ms, per_image_inference_time: 0.288ms
2022-02-21 09:06:25 - until epoch: 051, best_acc1: 68.392%
2022-02-21 09:06:25 - epoch 052 lr: 0.010000000000000002
2022-02-21 09:07:07 - train: epoch 0052, iter [00100, 05004], lr: 0.010000, loss: 1.3072
2022-02-21 09:07:45 - train: epoch 0052, iter [00200, 05004], lr: 0.010000, loss: 1.4320
2022-02-21 09:08:23 - train: epoch 0052, iter [00300, 05004], lr: 0.010000, loss: 1.6260
2022-02-21 09:09:00 - train: epoch 0052, iter [00400, 05004], lr: 0.010000, loss: 1.5091
2022-02-21 09:09:37 - train: epoch 0052, iter [00500, 05004], lr: 0.010000, loss: 1.6369
2022-02-21 09:10:14 - train: epoch 0052, iter [00600, 05004], lr: 0.010000, loss: 1.2969
2022-02-21 09:10:51 - train: epoch 0052, iter [00700, 05004], lr: 0.010000, loss: 1.4849
2022-02-21 09:11:29 - train: epoch 0052, iter [00800, 05004], lr: 0.010000, loss: 1.4999
2022-02-21 09:12:03 - train: epoch 0052, iter [00900, 05004], lr: 0.010000, loss: 1.5586
2022-02-21 09:12:38 - train: epoch 0052, iter [01000, 05004], lr: 0.010000, loss: 1.6275
2022-02-21 09:13:16 - train: epoch 0052, iter [01100, 05004], lr: 0.010000, loss: 1.4646
2022-02-21 09:13:55 - train: epoch 0052, iter [01200, 05004], lr: 0.010000, loss: 1.2799
2022-02-21 09:14:32 - train: epoch 0052, iter [01300, 05004], lr: 0.010000, loss: 1.4288
2022-02-21 09:15:09 - train: epoch 0052, iter [01400, 05004], lr: 0.010000, loss: 1.7858
2022-02-21 09:15:46 - train: epoch 0052, iter [01500, 05004], lr: 0.010000, loss: 1.3604
2022-02-21 09:16:24 - train: epoch 0052, iter [01600, 05004], lr: 0.010000, loss: 1.3121
2022-02-21 09:17:00 - train: epoch 0052, iter [01700, 05004], lr: 0.010000, loss: 1.2706
2022-02-21 09:17:37 - train: epoch 0052, iter [01800, 05004], lr: 0.010000, loss: 1.3456
2022-02-21 09:18:14 - train: epoch 0052, iter [01900, 05004], lr: 0.010000, loss: 1.4673
2022-02-21 09:18:52 - train: epoch 0052, iter [02000, 05004], lr: 0.010000, loss: 1.6044
2022-02-21 09:19:28 - train: epoch 0052, iter [02100, 05004], lr: 0.010000, loss: 1.3101
2022-02-21 09:20:06 - train: epoch 0052, iter [02200, 05004], lr: 0.010000, loss: 1.5108
2022-02-21 09:20:43 - train: epoch 0052, iter [02300, 05004], lr: 0.010000, loss: 1.2874
2022-02-21 09:21:21 - train: epoch 0052, iter [02400, 05004], lr: 0.010000, loss: 1.2800
2022-02-21 09:21:57 - train: epoch 0052, iter [02500, 05004], lr: 0.010000, loss: 1.3604
2022-02-21 09:22:36 - train: epoch 0052, iter [02600, 05004], lr: 0.010000, loss: 1.2110
2022-02-21 09:23:11 - train: epoch 0052, iter [02700, 05004], lr: 0.010000, loss: 1.4156
2022-02-21 09:23:49 - train: epoch 0052, iter [02800, 05004], lr: 0.010000, loss: 1.5450
2022-02-21 09:24:27 - train: epoch 0052, iter [02900, 05004], lr: 0.010000, loss: 1.2860
2022-02-21 09:25:04 - train: epoch 0052, iter [03000, 05004], lr: 0.010000, loss: 1.4395
2022-02-21 09:25:41 - train: epoch 0052, iter [03100, 05004], lr: 0.010000, loss: 1.4636
2022-02-21 09:26:18 - train: epoch 0052, iter [03200, 05004], lr: 0.010000, loss: 1.6122
2022-02-21 09:26:56 - train: epoch 0052, iter [03300, 05004], lr: 0.010000, loss: 1.4902
2022-02-21 09:27:32 - train: epoch 0052, iter [03400, 05004], lr: 0.010000, loss: 1.6207
2022-02-21 09:28:10 - train: epoch 0052, iter [03500, 05004], lr: 0.010000, loss: 1.5175
2022-02-21 09:28:46 - train: epoch 0052, iter [03600, 05004], lr: 0.010000, loss: 1.5669
2022-02-21 09:29:23 - train: epoch 0052, iter [03700, 05004], lr: 0.010000, loss: 1.6308
2022-02-21 09:30:01 - train: epoch 0052, iter [03800, 05004], lr: 0.010000, loss: 1.3645
2022-02-21 09:30:39 - train: epoch 0052, iter [03900, 05004], lr: 0.010000, loss: 1.4464
2022-02-21 09:31:15 - train: epoch 0052, iter [04000, 05004], lr: 0.010000, loss: 1.6256
2022-02-21 09:31:53 - train: epoch 0052, iter [04100, 05004], lr: 0.010000, loss: 1.2570
2022-02-21 09:32:30 - train: epoch 0052, iter [04200, 05004], lr: 0.010000, loss: 1.3745
2022-02-21 09:33:06 - train: epoch 0052, iter [04300, 05004], lr: 0.010000, loss: 1.5371
2022-02-21 09:33:44 - train: epoch 0052, iter [04400, 05004], lr: 0.010000, loss: 1.4790
2022-02-21 09:34:20 - train: epoch 0052, iter [04500, 05004], lr: 0.010000, loss: 1.3465
2022-02-21 09:34:59 - train: epoch 0052, iter [04600, 05004], lr: 0.010000, loss: 1.5089
2022-02-21 09:35:36 - train: epoch 0052, iter [04700, 05004], lr: 0.010000, loss: 1.5589
2022-02-21 09:36:13 - train: epoch 0052, iter [04800, 05004], lr: 0.010000, loss: 1.2690
2022-02-21 09:36:50 - train: epoch 0052, iter [04900, 05004], lr: 0.010000, loss: 1.4179
2022-02-21 09:37:26 - train: epoch 0052, iter [05000, 05004], lr: 0.010000, loss: 1.4731
2022-02-21 09:37:27 - train: epoch 052, train_loss: 1.4705
2022-02-21 09:38:50 - eval: epoch: 052, acc1: 67.424%, acc5: 88.140%, test_loss: 1.3165, per_image_load_time: 2.944ms, per_image_inference_time: 0.276ms
2022-02-21 09:38:51 - until epoch: 052, best_acc1: 68.392%
2022-02-21 09:38:51 - epoch 053 lr: 0.010000000000000002
2022-02-21 09:39:33 - train: epoch 0053, iter [00100, 05004], lr: 0.010000, loss: 1.4472
2022-02-21 09:40:11 - train: epoch 0053, iter [00200, 05004], lr: 0.010000, loss: 1.6891
2022-02-21 09:40:48 - train: epoch 0053, iter [00300, 05004], lr: 0.010000, loss: 1.5146
2022-02-21 09:41:25 - train: epoch 0053, iter [00400, 05004], lr: 0.010000, loss: 1.5283
2022-02-21 09:42:02 - train: epoch 0053, iter [00500, 05004], lr: 0.010000, loss: 1.5744
2022-02-21 09:42:40 - train: epoch 0053, iter [00600, 05004], lr: 0.010000, loss: 1.4766
2022-02-21 09:43:16 - train: epoch 0053, iter [00700, 05004], lr: 0.010000, loss: 1.3362
2022-02-21 09:43:54 - train: epoch 0053, iter [00800, 05004], lr: 0.010000, loss: 1.5388
2022-02-21 09:44:31 - train: epoch 0053, iter [00900, 05004], lr: 0.010000, loss: 1.3693
2022-02-21 09:45:09 - train: epoch 0053, iter [01000, 05004], lr: 0.010000, loss: 1.3084
2022-02-21 09:45:45 - train: epoch 0053, iter [01100, 05004], lr: 0.010000, loss: 1.4878
2022-02-21 09:46:22 - train: epoch 0053, iter [01200, 05004], lr: 0.010000, loss: 1.4298
2022-02-21 09:46:57 - train: epoch 0053, iter [01300, 05004], lr: 0.010000, loss: 1.4969
2022-02-21 09:47:36 - train: epoch 0053, iter [01400, 05004], lr: 0.010000, loss: 1.6819
2022-02-21 09:48:13 - train: epoch 0053, iter [01500, 05004], lr: 0.010000, loss: 1.4329
2022-02-21 09:48:49 - train: epoch 0053, iter [01600, 05004], lr: 0.010000, loss: 1.6742
2022-02-21 09:49:27 - train: epoch 0053, iter [01700, 05004], lr: 0.010000, loss: 1.6261
2022-02-21 09:50:04 - train: epoch 0053, iter [01800, 05004], lr: 0.010000, loss: 1.6416
2022-02-21 09:50:42 - train: epoch 0053, iter [01900, 05004], lr: 0.010000, loss: 1.2465
2022-02-21 09:51:19 - train: epoch 0053, iter [02000, 05004], lr: 0.010000, loss: 1.4686
2022-02-21 09:51:56 - train: epoch 0053, iter [02100, 05004], lr: 0.010000, loss: 1.4844
2022-02-21 09:52:33 - train: epoch 0053, iter [02200, 05004], lr: 0.010000, loss: 1.3936
2022-02-21 09:53:10 - train: epoch 0053, iter [02300, 05004], lr: 0.010000, loss: 1.4701
2022-02-21 09:53:48 - train: epoch 0053, iter [02400, 05004], lr: 0.010000, loss: 1.4543
2022-02-21 09:54:26 - train: epoch 0053, iter [02500, 05004], lr: 0.010000, loss: 1.7023
2022-02-21 09:55:02 - train: epoch 0053, iter [02600, 05004], lr: 0.010000, loss: 1.4423
2022-02-21 09:55:40 - train: epoch 0053, iter [02700, 05004], lr: 0.010000, loss: 1.7943
2022-02-21 09:56:17 - train: epoch 0053, iter [02800, 05004], lr: 0.010000, loss: 1.6092
2022-02-21 09:56:54 - train: epoch 0053, iter [02900, 05004], lr: 0.010000, loss: 1.2221
2022-02-21 09:57:32 - train: epoch 0053, iter [03000, 05004], lr: 0.010000, loss: 1.2615
2022-02-21 09:58:10 - train: epoch 0053, iter [03100, 05004], lr: 0.010000, loss: 1.5919
2022-02-21 09:58:47 - train: epoch 0053, iter [03200, 05004], lr: 0.010000, loss: 1.6852
2022-02-21 09:59:24 - train: epoch 0053, iter [03300, 05004], lr: 0.010000, loss: 1.3967
2022-02-21 10:00:01 - train: epoch 0053, iter [03400, 05004], lr: 0.010000, loss: 1.5884
2022-02-21 10:00:39 - train: epoch 0053, iter [03500, 05004], lr: 0.010000, loss: 1.5809
2022-02-21 10:01:16 - train: epoch 0053, iter [03600, 05004], lr: 0.010000, loss: 1.4969
2022-02-21 10:01:53 - train: epoch 0053, iter [03700, 05004], lr: 0.010000, loss: 1.7202
2022-02-21 10:02:29 - train: epoch 0053, iter [03800, 05004], lr: 0.010000, loss: 1.4261
2022-02-21 10:03:07 - train: epoch 0053, iter [03900, 05004], lr: 0.010000, loss: 1.6764
2022-02-21 10:03:44 - train: epoch 0053, iter [04000, 05004], lr: 0.010000, loss: 1.5781
2022-02-21 10:04:22 - train: epoch 0053, iter [04100, 05004], lr: 0.010000, loss: 1.5778
2022-02-21 10:04:58 - train: epoch 0053, iter [04200, 05004], lr: 0.010000, loss: 1.4628
2022-02-21 10:05:36 - train: epoch 0053, iter [04300, 05004], lr: 0.010000, loss: 1.6468
2022-02-21 10:06:12 - train: epoch 0053, iter [04400, 05004], lr: 0.010000, loss: 1.4037
2022-02-21 10:06:51 - train: epoch 0053, iter [04500, 05004], lr: 0.010000, loss: 1.5858
2022-02-21 10:07:27 - train: epoch 0053, iter [04600, 05004], lr: 0.010000, loss: 1.3564
2022-02-21 10:08:04 - train: epoch 0053, iter [04700, 05004], lr: 0.010000, loss: 1.6605
2022-02-21 10:08:42 - train: epoch 0053, iter [04800, 05004], lr: 0.010000, loss: 1.6321
2022-02-21 10:09:18 - train: epoch 0053, iter [04900, 05004], lr: 0.010000, loss: 1.2458
2022-02-21 10:09:52 - train: epoch 0053, iter [05000, 05004], lr: 0.010000, loss: 1.4229
2022-02-21 10:09:53 - train: epoch 053, train_loss: 1.4690
2022-02-21 10:11:16 - eval: epoch: 053, acc1: 67.472%, acc5: 88.276%, test_loss: 1.3109, per_image_load_time: 2.919ms, per_image_inference_time: 0.281ms
2022-02-21 10:11:16 - until epoch: 053, best_acc1: 68.392%
2022-02-21 10:11:16 - epoch 054 lr: 0.010000000000000002
2022-02-21 10:11:59 - train: epoch 0054, iter [00100, 05004], lr: 0.010000, loss: 1.2761
2022-02-21 10:12:37 - train: epoch 0054, iter [00200, 05004], lr: 0.010000, loss: 1.8186
2022-02-21 10:13:13 - train: epoch 0054, iter [00300, 05004], lr: 0.010000, loss: 1.4791
2022-02-21 10:13:50 - train: epoch 0054, iter [00400, 05004], lr: 0.010000, loss: 1.2626
2022-02-21 10:14:27 - train: epoch 0054, iter [00500, 05004], lr: 0.010000, loss: 1.4919
2022-02-21 10:15:05 - train: epoch 0054, iter [00600, 05004], lr: 0.010000, loss: 1.4016
2022-02-21 10:15:43 - train: epoch 0054, iter [00700, 05004], lr: 0.010000, loss: 1.5011
2022-02-21 10:16:21 - train: epoch 0054, iter [00800, 05004], lr: 0.010000, loss: 1.5424
2022-02-21 10:16:58 - train: epoch 0054, iter [00900, 05004], lr: 0.010000, loss: 1.1946
2022-02-21 10:17:35 - train: epoch 0054, iter [01000, 05004], lr: 0.010000, loss: 1.2219
2022-02-21 10:18:12 - train: epoch 0054, iter [01100, 05004], lr: 0.010000, loss: 1.2975
2022-02-21 10:18:49 - train: epoch 0054, iter [01200, 05004], lr: 0.010000, loss: 1.4896
2022-02-21 10:19:27 - train: epoch 0054, iter [01300, 05004], lr: 0.010000, loss: 1.3177
2022-02-21 10:20:04 - train: epoch 0054, iter [01400, 05004], lr: 0.010000, loss: 1.5190
2022-02-21 10:20:41 - train: epoch 0054, iter [01500, 05004], lr: 0.010000, loss: 1.4568
2022-02-21 10:21:17 - train: epoch 0054, iter [01600, 05004], lr: 0.010000, loss: 1.0888
2022-02-21 10:21:55 - train: epoch 0054, iter [01700, 05004], lr: 0.010000, loss: 1.5244
2022-02-21 10:22:34 - train: epoch 0054, iter [01800, 05004], lr: 0.010000, loss: 1.4991
2022-02-21 10:23:10 - train: epoch 0054, iter [01900, 05004], lr: 0.010000, loss: 1.7743
2022-02-21 10:23:47 - train: epoch 0054, iter [02000, 05004], lr: 0.010000, loss: 1.4740
2022-02-21 10:24:25 - train: epoch 0054, iter [02100, 05004], lr: 0.010000, loss: 1.1723
2022-02-21 10:25:02 - train: epoch 0054, iter [02200, 05004], lr: 0.010000, loss: 1.4698
2022-02-21 10:25:38 - train: epoch 0054, iter [02300, 05004], lr: 0.010000, loss: 1.4738
2022-02-21 10:26:17 - train: epoch 0054, iter [02400, 05004], lr: 0.010000, loss: 1.3610
2022-02-21 10:26:53 - train: epoch 0054, iter [02500, 05004], lr: 0.010000, loss: 1.5294
2022-02-21 10:27:30 - train: epoch 0054, iter [02600, 05004], lr: 0.010000, loss: 1.4402
2022-02-21 10:28:07 - train: epoch 0054, iter [02700, 05004], lr: 0.010000, loss: 1.5074
2022-02-21 10:28:44 - train: epoch 0054, iter [02800, 05004], lr: 0.010000, loss: 1.7413
2022-02-21 10:29:21 - train: epoch 0054, iter [02900, 05004], lr: 0.010000, loss: 1.3105
2022-02-21 10:29:58 - train: epoch 0054, iter [03000, 05004], lr: 0.010000, loss: 1.5457
2022-02-21 10:30:34 - train: epoch 0054, iter [03100, 05004], lr: 0.010000, loss: 1.4526
2022-02-21 10:31:11 - train: epoch 0054, iter [03200, 05004], lr: 0.010000, loss: 1.7194
2022-02-21 10:31:48 - train: epoch 0054, iter [03300, 05004], lr: 0.010000, loss: 1.3884
2022-02-21 10:32:26 - train: epoch 0054, iter [03400, 05004], lr: 0.010000, loss: 1.5712
2022-02-21 10:33:03 - train: epoch 0054, iter [03500, 05004], lr: 0.010000, loss: 1.5086
2022-02-21 10:33:41 - train: epoch 0054, iter [03600, 05004], lr: 0.010000, loss: 1.3678
2022-02-21 10:34:18 - train: epoch 0054, iter [03700, 05004], lr: 0.010000, loss: 1.4277
2022-02-21 10:34:56 - train: epoch 0054, iter [03800, 05004], lr: 0.010000, loss: 1.4296
2022-02-21 10:35:33 - train: epoch 0054, iter [03900, 05004], lr: 0.010000, loss: 1.4615
2022-02-21 10:36:10 - train: epoch 0054, iter [04000, 05004], lr: 0.010000, loss: 1.3254
2022-02-21 10:36:47 - train: epoch 0054, iter [04100, 05004], lr: 0.010000, loss: 1.5747
2022-02-21 10:37:25 - train: epoch 0054, iter [04200, 05004], lr: 0.010000, loss: 1.5009
2022-02-21 10:38:02 - train: epoch 0054, iter [04300, 05004], lr: 0.010000, loss: 1.4134
2022-02-21 10:38:40 - train: epoch 0054, iter [04400, 05004], lr: 0.010000, loss: 1.3103
2022-02-21 10:39:17 - train: epoch 0054, iter [04500, 05004], lr: 0.010000, loss: 1.3305
2022-02-21 10:39:55 - train: epoch 0054, iter [04600, 05004], lr: 0.010000, loss: 1.3892
2022-02-21 10:40:32 - train: epoch 0054, iter [04700, 05004], lr: 0.010000, loss: 1.7000
2022-02-21 10:41:10 - train: epoch 0054, iter [04800, 05004], lr: 0.010000, loss: 1.5462
2022-02-21 10:41:47 - train: epoch 0054, iter [04900, 05004], lr: 0.010000, loss: 1.3114
2022-02-21 10:42:23 - train: epoch 0054, iter [05000, 05004], lr: 0.010000, loss: 1.5505
2022-02-21 10:42:24 - train: epoch 054, train_loss: 1.4692
2022-02-21 10:43:47 - eval: epoch: 054, acc1: 67.644%, acc5: 88.438%, test_loss: 1.3020, per_image_load_time: 2.922ms, per_image_inference_time: 0.307ms
2022-02-21 10:43:48 - until epoch: 054, best_acc1: 68.392%
2022-02-21 10:43:48 - epoch 055 lr: 0.010000000000000002
2022-02-21 10:44:31 - train: epoch 0055, iter [00100, 05004], lr: 0.010000, loss: 1.4011
2022-02-21 10:45:07 - train: epoch 0055, iter [00200, 05004], lr: 0.010000, loss: 1.4958
2022-02-21 10:45:45 - train: epoch 0055, iter [00300, 05004], lr: 0.010000, loss: 1.2683
2022-02-21 10:46:23 - train: epoch 0055, iter [00400, 05004], lr: 0.010000, loss: 1.3927
2022-02-21 10:46:59 - train: epoch 0055, iter [00500, 05004], lr: 0.010000, loss: 1.3137
2022-02-21 10:47:37 - train: epoch 0055, iter [00600, 05004], lr: 0.010000, loss: 1.3656
2022-02-21 10:48:15 - train: epoch 0055, iter [00700, 05004], lr: 0.010000, loss: 1.6444
2022-02-21 10:48:51 - train: epoch 0055, iter [00800, 05004], lr: 0.010000, loss: 1.2676
2022-02-21 10:49:28 - train: epoch 0055, iter [00900, 05004], lr: 0.010000, loss: 1.4816
2022-02-21 10:50:05 - train: epoch 0055, iter [01000, 05004], lr: 0.010000, loss: 1.4842
2022-02-21 10:50:42 - train: epoch 0055, iter [01100, 05004], lr: 0.010000, loss: 1.3730
2022-02-21 10:51:20 - train: epoch 0055, iter [01200, 05004], lr: 0.010000, loss: 1.4506
2022-02-21 10:51:56 - train: epoch 0055, iter [01300, 05004], lr: 0.010000, loss: 1.5814
2022-02-21 10:52:34 - train: epoch 0055, iter [01400, 05004], lr: 0.010000, loss: 1.3562
2022-02-21 10:53:11 - train: epoch 0055, iter [01500, 05004], lr: 0.010000, loss: 1.4490
2022-02-21 10:53:49 - train: epoch 0055, iter [01600, 05004], lr: 0.010000, loss: 1.5301
2022-02-21 10:54:26 - train: epoch 0055, iter [01700, 05004], lr: 0.010000, loss: 1.5309
2022-02-21 10:55:04 - train: epoch 0055, iter [01800, 05004], lr: 0.010000, loss: 1.4590
2022-02-21 10:55:40 - train: epoch 0055, iter [01900, 05004], lr: 0.010000, loss: 1.4708
2022-02-21 10:56:18 - train: epoch 0055, iter [02000, 05004], lr: 0.010000, loss: 1.4242
2022-02-21 10:56:55 - train: epoch 0055, iter [02100, 05004], lr: 0.010000, loss: 1.2312
2022-02-21 10:57:32 - train: epoch 0055, iter [02200, 05004], lr: 0.010000, loss: 1.6250
2022-02-21 10:58:10 - train: epoch 0055, iter [02300, 05004], lr: 0.010000, loss: 1.4239
2022-02-21 10:58:47 - train: epoch 0055, iter [02400, 05004], lr: 0.010000, loss: 1.3171
2022-02-21 10:59:25 - train: epoch 0055, iter [02500, 05004], lr: 0.010000, loss: 1.5776
2022-02-21 11:00:02 - train: epoch 0055, iter [02600, 05004], lr: 0.010000, loss: 1.4036
2022-02-21 11:00:40 - train: epoch 0055, iter [02700, 05004], lr: 0.010000, loss: 1.2886
2022-02-21 11:01:16 - train: epoch 0055, iter [02800, 05004], lr: 0.010000, loss: 1.4401
2022-02-21 11:01:54 - train: epoch 0055, iter [02900, 05004], lr: 0.010000, loss: 1.5630
2022-02-21 11:02:31 - train: epoch 0055, iter [03000, 05004], lr: 0.010000, loss: 1.3960
2022-02-21 11:03:08 - train: epoch 0055, iter [03100, 05004], lr: 0.010000, loss: 1.5134
2022-02-21 11:03:46 - train: epoch 0055, iter [03200, 05004], lr: 0.010000, loss: 1.3255
2022-02-21 11:04:22 - train: epoch 0055, iter [03300, 05004], lr: 0.010000, loss: 1.3081
2022-02-21 11:05:01 - train: epoch 0055, iter [03400, 05004], lr: 0.010000, loss: 1.3987
2022-02-21 11:05:38 - train: epoch 0055, iter [03500, 05004], lr: 0.010000, loss: 1.2350
2022-02-21 11:06:15 - train: epoch 0055, iter [03600, 05004], lr: 0.010000, loss: 1.4817
2022-02-21 11:06:52 - train: epoch 0055, iter [03700, 05004], lr: 0.010000, loss: 1.4586
2022-02-21 11:07:29 - train: epoch 0055, iter [03800, 05004], lr: 0.010000, loss: 1.5483
2022-02-21 11:08:05 - train: epoch 0055, iter [03900, 05004], lr: 0.010000, loss: 1.7922
2022-02-21 11:08:43 - train: epoch 0055, iter [04000, 05004], lr: 0.010000, loss: 1.4987
2022-02-21 11:09:20 - train: epoch 0055, iter [04100, 05004], lr: 0.010000, loss: 1.4974
2022-02-21 11:09:58 - train: epoch 0055, iter [04200, 05004], lr: 0.010000, loss: 1.4738
2022-02-21 11:10:35 - train: epoch 0055, iter [04300, 05004], lr: 0.010000, loss: 1.5411
2022-02-21 11:11:12 - train: epoch 0055, iter [04400, 05004], lr: 0.010000, loss: 1.7229
2022-02-21 11:11:50 - train: epoch 0055, iter [04500, 05004], lr: 0.010000, loss: 1.4829
2022-02-21 11:12:28 - train: epoch 0055, iter [04600, 05004], lr: 0.010000, loss: 1.6550
2022-02-21 11:13:05 - train: epoch 0055, iter [04700, 05004], lr: 0.010000, loss: 1.3387
2022-02-21 11:13:42 - train: epoch 0055, iter [04800, 05004], lr: 0.010000, loss: 1.5254
2022-02-21 11:14:19 - train: epoch 0055, iter [04900, 05004], lr: 0.010000, loss: 1.3852
2022-02-21 11:14:56 - train: epoch 0055, iter [05000, 05004], lr: 0.010000, loss: 1.5368
2022-02-21 11:14:57 - train: epoch 055, train_loss: 1.4644
2022-02-21 11:16:21 - eval: epoch: 055, acc1: 68.062%, acc5: 88.324%, test_loss: 1.2991, per_image_load_time: 2.975ms, per_image_inference_time: 0.287ms
2022-02-21 11:16:22 - until epoch: 055, best_acc1: 68.392%
2022-02-21 11:16:22 - epoch 056 lr: 0.010000000000000002
2022-02-21 11:17:04 - train: epoch 0056, iter [00100, 05004], lr: 0.010000, loss: 1.5380
2022-02-21 11:17:40 - train: epoch 0056, iter [00200, 05004], lr: 0.010000, loss: 1.6772
2022-02-21 11:18:14 - train: epoch 0056, iter [00300, 05004], lr: 0.010000, loss: 1.4498
2022-02-21 11:18:53 - train: epoch 0056, iter [00400, 05004], lr: 0.010000, loss: 1.4657
2022-02-21 11:19:33 - train: epoch 0056, iter [00500, 05004], lr: 0.010000, loss: 1.3566
2022-02-21 11:20:11 - train: epoch 0056, iter [00600, 05004], lr: 0.010000, loss: 1.4668
2022-02-21 11:20:48 - train: epoch 0056, iter [00700, 05004], lr: 0.010000, loss: 1.4766
2022-02-21 11:21:25 - train: epoch 0056, iter [00800, 05004], lr: 0.010000, loss: 1.6399
2022-02-21 11:22:02 - train: epoch 0056, iter [00900, 05004], lr: 0.010000, loss: 1.5522
2022-02-21 11:22:39 - train: epoch 0056, iter [01000, 05004], lr: 0.010000, loss: 1.4318
2022-02-21 11:23:16 - train: epoch 0056, iter [01100, 05004], lr: 0.010000, loss: 1.3243
2022-02-21 11:23:53 - train: epoch 0056, iter [01200, 05004], lr: 0.010000, loss: 1.3079
2022-02-21 11:24:29 - train: epoch 0056, iter [01300, 05004], lr: 0.010000, loss: 1.5343
2022-02-21 11:25:07 - train: epoch 0056, iter [01400, 05004], lr: 0.010000, loss: 1.3853
2022-02-21 11:25:45 - train: epoch 0056, iter [01500, 05004], lr: 0.010000, loss: 1.6755
2022-02-21 11:26:22 - train: epoch 0056, iter [01600, 05004], lr: 0.010000, loss: 1.3555
2022-02-21 11:27:00 - train: epoch 0056, iter [01700, 05004], lr: 0.010000, loss: 1.6196
2022-02-21 11:27:36 - train: epoch 0056, iter [01800, 05004], lr: 0.010000, loss: 1.6809
2022-02-21 11:28:13 - train: epoch 0056, iter [01900, 05004], lr: 0.010000, loss: 1.4476
2022-02-21 11:28:50 - train: epoch 0056, iter [02000, 05004], lr: 0.010000, loss: 1.5429
2022-02-21 11:29:28 - train: epoch 0056, iter [02100, 05004], lr: 0.010000, loss: 1.4462
2022-02-21 11:30:05 - train: epoch 0056, iter [02200, 05004], lr: 0.010000, loss: 1.6267
2022-02-21 11:30:43 - train: epoch 0056, iter [02300, 05004], lr: 0.010000, loss: 1.6413
2022-02-21 11:31:18 - train: epoch 0056, iter [02400, 05004], lr: 0.010000, loss: 1.4399
2022-02-21 11:31:57 - train: epoch 0056, iter [02500, 05004], lr: 0.010000, loss: 1.5946
2022-02-21 11:32:33 - train: epoch 0056, iter [02600, 05004], lr: 0.010000, loss: 1.3490
2022-02-21 11:33:11 - train: epoch 0056, iter [02700, 05004], lr: 0.010000, loss: 1.4595
2022-02-21 11:33:49 - train: epoch 0056, iter [02800, 05004], lr: 0.010000, loss: 1.3611
2022-02-21 11:34:26 - train: epoch 0056, iter [02900, 05004], lr: 0.010000, loss: 1.6391
2022-02-21 11:35:04 - train: epoch 0056, iter [03000, 05004], lr: 0.010000, loss: 1.5746
2022-02-21 11:35:41 - train: epoch 0056, iter [03100, 05004], lr: 0.010000, loss: 1.3435
2022-02-21 11:36:18 - train: epoch 0056, iter [03200, 05004], lr: 0.010000, loss: 1.3538
2022-02-21 11:36:55 - train: epoch 0056, iter [03300, 05004], lr: 0.010000, loss: 1.6709
2022-02-21 11:37:32 - train: epoch 0056, iter [03400, 05004], lr: 0.010000, loss: 1.4599
2022-02-21 11:38:09 - train: epoch 0056, iter [03500, 05004], lr: 0.010000, loss: 1.5035
2022-02-21 11:38:46 - train: epoch 0056, iter [03600, 05004], lr: 0.010000, loss: 1.2740
2022-02-21 11:39:23 - train: epoch 0056, iter [03700, 05004], lr: 0.010000, loss: 1.2927
2022-02-21 11:40:00 - train: epoch 0056, iter [03800, 05004], lr: 0.010000, loss: 1.3511
2022-02-21 11:40:37 - train: epoch 0056, iter [03900, 05004], lr: 0.010000, loss: 1.6288
2022-02-21 11:41:14 - train: epoch 0056, iter [04000, 05004], lr: 0.010000, loss: 1.4408
2022-02-21 11:41:52 - train: epoch 0056, iter [04100, 05004], lr: 0.010000, loss: 1.7032
2022-02-21 11:42:30 - train: epoch 0056, iter [04200, 05004], lr: 0.010000, loss: 1.4374
2022-02-21 11:43:07 - train: epoch 0056, iter [04300, 05004], lr: 0.010000, loss: 1.3774
2022-02-21 11:43:45 - train: epoch 0056, iter [04400, 05004], lr: 0.010000, loss: 1.5662
2022-02-21 11:44:22 - train: epoch 0056, iter [04500, 05004], lr: 0.010000, loss: 1.4536
2022-02-21 11:44:59 - train: epoch 0056, iter [04600, 05004], lr: 0.010000, loss: 1.4384
2022-02-21 11:45:36 - train: epoch 0056, iter [04700, 05004], lr: 0.010000, loss: 1.5798
2022-02-21 11:46:14 - train: epoch 0056, iter [04800, 05004], lr: 0.010000, loss: 1.6524
2022-02-21 11:46:52 - train: epoch 0056, iter [04900, 05004], lr: 0.010000, loss: 1.4589
2022-02-21 11:47:28 - train: epoch 0056, iter [05000, 05004], lr: 0.010000, loss: 1.4810
2022-02-21 11:47:29 - train: epoch 056, train_loss: 1.4618
2022-02-21 11:48:53 - eval: epoch: 056, acc1: 67.746%, acc5: 88.622%, test_loss: 1.2963, per_image_load_time: 2.972ms, per_image_inference_time: 0.287ms
2022-02-21 11:48:53 - until epoch: 056, best_acc1: 68.392%
2022-02-21 11:48:53 - epoch 057 lr: 0.010000000000000002
2022-02-21 11:49:34 - train: epoch 0057, iter [00100, 05004], lr: 0.010000, loss: 1.5881
2022-02-21 11:50:12 - train: epoch 0057, iter [00200, 05004], lr: 0.010000, loss: 1.3812
2022-02-21 11:50:49 - train: epoch 0057, iter [00300, 05004], lr: 0.010000, loss: 1.2946
2022-02-21 11:51:28 - train: epoch 0057, iter [00400, 05004], lr: 0.010000, loss: 1.3542
2022-02-21 11:52:05 - train: epoch 0057, iter [00500, 05004], lr: 0.010000, loss: 1.2449
2022-02-21 11:52:42 - train: epoch 0057, iter [00600, 05004], lr: 0.010000, loss: 1.5843
2022-02-21 11:53:20 - train: epoch 0057, iter [00700, 05004], lr: 0.010000, loss: 1.2406
2022-02-21 11:53:57 - train: epoch 0057, iter [00800, 05004], lr: 0.010000, loss: 1.4845
2022-02-21 11:54:35 - train: epoch 0057, iter [00900, 05004], lr: 0.010000, loss: 1.4887
2022-02-21 11:55:13 - train: epoch 0057, iter [01000, 05004], lr: 0.010000, loss: 1.3742
2022-02-21 11:55:51 - train: epoch 0057, iter [01100, 05004], lr: 0.010000, loss: 1.3946
2022-02-21 11:56:29 - train: epoch 0057, iter [01200, 05004], lr: 0.010000, loss: 1.4175
2022-02-21 11:57:06 - train: epoch 0057, iter [01300, 05004], lr: 0.010000, loss: 1.4440
2022-02-21 11:57:43 - train: epoch 0057, iter [01400, 05004], lr: 0.010000, loss: 1.5694
2022-02-21 11:58:20 - train: epoch 0057, iter [01500, 05004], lr: 0.010000, loss: 1.6185
2022-02-21 11:58:58 - train: epoch 0057, iter [01600, 05004], lr: 0.010000, loss: 1.6350
2022-02-21 11:59:35 - train: epoch 0057, iter [01700, 05004], lr: 0.010000, loss: 1.6138
2022-02-21 12:00:12 - train: epoch 0057, iter [01800, 05004], lr: 0.010000, loss: 1.5020
2022-02-21 12:00:50 - train: epoch 0057, iter [01900, 05004], lr: 0.010000, loss: 1.3726
2022-02-21 12:01:27 - train: epoch 0057, iter [02000, 05004], lr: 0.010000, loss: 1.5221
2022-02-21 12:02:05 - train: epoch 0057, iter [02100, 05004], lr: 0.010000, loss: 1.5192
2022-02-21 12:02:41 - train: epoch 0057, iter [02200, 05004], lr: 0.010000, loss: 1.5809
2022-02-21 12:03:20 - train: epoch 0057, iter [02300, 05004], lr: 0.010000, loss: 1.4044
2022-02-21 12:03:57 - train: epoch 0057, iter [02400, 05004], lr: 0.010000, loss: 1.3571
2022-02-21 12:04:35 - train: epoch 0057, iter [02500, 05004], lr: 0.010000, loss: 1.4876
2022-02-21 12:05:14 - train: epoch 0057, iter [02600, 05004], lr: 0.010000, loss: 1.3640
2022-02-21 12:05:50 - train: epoch 0057, iter [02700, 05004], lr: 0.010000, loss: 1.2499
2022-02-21 12:06:28 - train: epoch 0057, iter [02800, 05004], lr: 0.010000, loss: 1.1192
2022-02-21 12:07:06 - train: epoch 0057, iter [02900, 05004], lr: 0.010000, loss: 1.6159
2022-02-21 12:07:44 - train: epoch 0057, iter [03000, 05004], lr: 0.010000, loss: 1.4947
2022-02-21 12:08:22 - train: epoch 0057, iter [03100, 05004], lr: 0.010000, loss: 1.6111
2022-02-21 12:08:59 - train: epoch 0057, iter [03200, 05004], lr: 0.010000, loss: 1.5520
2022-02-21 12:09:37 - train: epoch 0057, iter [03300, 05004], lr: 0.010000, loss: 1.4511
2022-02-21 12:10:14 - train: epoch 0057, iter [03400, 05004], lr: 0.010000, loss: 1.4867
2022-02-21 12:10:52 - train: epoch 0057, iter [03500, 05004], lr: 0.010000, loss: 1.4930
2022-02-21 12:11:29 - train: epoch 0057, iter [03600, 05004], lr: 0.010000, loss: 1.4181
2022-02-21 12:12:07 - train: epoch 0057, iter [03700, 05004], lr: 0.010000, loss: 1.4172
2022-02-21 12:12:44 - train: epoch 0057, iter [03800, 05004], lr: 0.010000, loss: 1.3561
2022-02-21 12:13:23 - train: epoch 0057, iter [03900, 05004], lr: 0.010000, loss: 1.6332
2022-02-21 12:13:59 - train: epoch 0057, iter [04000, 05004], lr: 0.010000, loss: 1.4593
2022-02-21 12:14:37 - train: epoch 0057, iter [04100, 05004], lr: 0.010000, loss: 1.5785
2022-02-21 12:15:13 - train: epoch 0057, iter [04200, 05004], lr: 0.010000, loss: 1.5614
2022-02-21 12:15:50 - train: epoch 0057, iter [04300, 05004], lr: 0.010000, loss: 1.3869
2022-02-21 12:16:28 - train: epoch 0057, iter [04400, 05004], lr: 0.010000, loss: 1.4529
2022-02-21 12:17:05 - train: epoch 0057, iter [04500, 05004], lr: 0.010000, loss: 1.5807
2022-02-21 12:17:42 - train: epoch 0057, iter [04600, 05004], lr: 0.010000, loss: 1.6903
2022-02-21 12:18:20 - train: epoch 0057, iter [04700, 05004], lr: 0.010000, loss: 1.2985
2022-02-21 12:18:58 - train: epoch 0057, iter [04800, 05004], lr: 0.010000, loss: 1.7506
2022-02-21 12:19:34 - train: epoch 0057, iter [04900, 05004], lr: 0.010000, loss: 1.7120
2022-02-21 12:20:10 - train: epoch 0057, iter [05000, 05004], lr: 0.010000, loss: 1.6522
2022-02-21 12:20:11 - train: epoch 057, train_loss: 1.4609
2022-02-21 12:21:35 - eval: epoch: 057, acc1: 68.006%, acc5: 88.530%, test_loss: 1.2989, per_image_load_time: 2.933ms, per_image_inference_time: 0.314ms
2022-02-21 12:21:36 - until epoch: 057, best_acc1: 68.392%
2022-02-21 12:21:36 - epoch 058 lr: 0.010000000000000002
2022-02-21 12:22:17 - train: epoch 0058, iter [00100, 05004], lr: 0.010000, loss: 1.4171
2022-02-21 12:22:55 - train: epoch 0058, iter [00200, 05004], lr: 0.010000, loss: 1.2009
2022-02-21 12:23:32 - train: epoch 0058, iter [00300, 05004], lr: 0.010000, loss: 1.4471
2022-02-21 12:24:09 - train: epoch 0058, iter [00400, 05004], lr: 0.010000, loss: 1.4436
2022-02-21 12:24:47 - train: epoch 0058, iter [00500, 05004], lr: 0.010000, loss: 1.3616
2022-02-21 12:25:25 - train: epoch 0058, iter [00600, 05004], lr: 0.010000, loss: 1.5654
2022-02-21 12:26:03 - train: epoch 0058, iter [00700, 05004], lr: 0.010000, loss: 1.4450
2022-02-21 12:26:39 - train: epoch 0058, iter [00800, 05004], lr: 0.010000, loss: 1.3100
2022-02-21 12:27:17 - train: epoch 0058, iter [00900, 05004], lr: 0.010000, loss: 1.3236
2022-02-21 12:27:53 - train: epoch 0058, iter [01000, 05004], lr: 0.010000, loss: 1.5344
2022-02-21 12:28:32 - train: epoch 0058, iter [01100, 05004], lr: 0.010000, loss: 1.2922
2022-02-21 12:29:10 - train: epoch 0058, iter [01200, 05004], lr: 0.010000, loss: 1.3797
2022-02-21 12:29:46 - train: epoch 0058, iter [01300, 05004], lr: 0.010000, loss: 1.5904
2022-02-21 12:30:25 - train: epoch 0058, iter [01400, 05004], lr: 0.010000, loss: 1.4669
2022-02-21 12:31:00 - train: epoch 0058, iter [01500, 05004], lr: 0.010000, loss: 1.4033
2022-02-21 12:31:38 - train: epoch 0058, iter [01600, 05004], lr: 0.010000, loss: 1.4327
2022-02-21 12:32:16 - train: epoch 0058, iter [01700, 05004], lr: 0.010000, loss: 1.5652
2022-02-21 12:32:53 - train: epoch 0058, iter [01800, 05004], lr: 0.010000, loss: 1.5176
2022-02-21 12:33:30 - train: epoch 0058, iter [01900, 05004], lr: 0.010000, loss: 1.6187
2022-02-21 12:34:06 - train: epoch 0058, iter [02000, 05004], lr: 0.010000, loss: 1.4911
2022-02-21 12:34:44 - train: epoch 0058, iter [02100, 05004], lr: 0.010000, loss: 1.3227
2022-02-21 12:35:22 - train: epoch 0058, iter [02200, 05004], lr: 0.010000, loss: 1.2187
2022-02-21 12:35:59 - train: epoch 0058, iter [02300, 05004], lr: 0.010000, loss: 1.3561
2022-02-21 12:36:37 - train: epoch 0058, iter [02400, 05004], lr: 0.010000, loss: 1.4850
2022-02-21 12:37:14 - train: epoch 0058, iter [02500, 05004], lr: 0.010000, loss: 1.5520
2022-02-21 12:37:51 - train: epoch 0058, iter [02600, 05004], lr: 0.010000, loss: 1.3281
2022-02-21 12:38:29 - train: epoch 0058, iter [02700, 05004], lr: 0.010000, loss: 1.6529
2022-02-21 12:39:07 - train: epoch 0058, iter [02800, 05004], lr: 0.010000, loss: 1.2061
2022-02-21 12:39:44 - train: epoch 0058, iter [02900, 05004], lr: 0.010000, loss: 1.3447
2022-02-21 12:40:21 - train: epoch 0058, iter [03000, 05004], lr: 0.010000, loss: 1.5512
2022-02-21 12:40:58 - train: epoch 0058, iter [03100, 05004], lr: 0.010000, loss: 1.3994
2022-02-21 12:41:36 - train: epoch 0058, iter [03200, 05004], lr: 0.010000, loss: 1.2770
2022-02-21 12:42:13 - train: epoch 0058, iter [03300, 05004], lr: 0.010000, loss: 1.4012
2022-02-21 12:42:51 - train: epoch 0058, iter [03400, 05004], lr: 0.010000, loss: 1.3114
2022-02-21 12:43:29 - train: epoch 0058, iter [03500, 05004], lr: 0.010000, loss: 1.4626
2022-02-21 12:44:05 - train: epoch 0058, iter [03600, 05004], lr: 0.010000, loss: 1.3549
2022-02-21 12:44:43 - train: epoch 0058, iter [03700, 05004], lr: 0.010000, loss: 1.4507
2022-02-21 12:45:19 - train: epoch 0058, iter [03800, 05004], lr: 0.010000, loss: 1.4977
2022-02-21 12:45:57 - train: epoch 0058, iter [03900, 05004], lr: 0.010000, loss: 1.4559
2022-02-21 12:46:35 - train: epoch 0058, iter [04000, 05004], lr: 0.010000, loss: 1.6216
2022-02-21 12:47:13 - train: epoch 0058, iter [04100, 05004], lr: 0.010000, loss: 1.5344
2022-02-21 12:47:51 - train: epoch 0058, iter [04200, 05004], lr: 0.010000, loss: 1.2791
2022-02-21 12:48:30 - train: epoch 0058, iter [04300, 05004], lr: 0.010000, loss: 1.7688
2022-02-21 12:49:08 - train: epoch 0058, iter [04400, 05004], lr: 0.010000, loss: 1.2547
2022-02-21 12:49:46 - train: epoch 0058, iter [04500, 05004], lr: 0.010000, loss: 1.4919
2022-02-21 12:50:24 - train: epoch 0058, iter [04600, 05004], lr: 0.010000, loss: 1.2888
2022-02-21 12:51:04 - train: epoch 0058, iter [04700, 05004], lr: 0.010000, loss: 1.5311
2022-02-21 12:51:45 - train: epoch 0058, iter [04800, 05004], lr: 0.010000, loss: 1.5927
2022-02-21 12:52:26 - train: epoch 0058, iter [04900, 05004], lr: 0.010000, loss: 1.3955
2022-02-21 12:53:02 - train: epoch 0058, iter [05000, 05004], lr: 0.010000, loss: 1.3801
2022-02-21 12:53:03 - train: epoch 058, train_loss: 1.4574
2022-02-21 12:54:26 - eval: epoch: 058, acc1: 68.458%, acc5: 88.802%, test_loss: 1.2708, per_image_load_time: 2.953ms, per_image_inference_time: 0.261ms
2022-02-21 12:54:27 - until epoch: 058, best_acc1: 68.458%
2022-02-21 12:54:27 - epoch 059 lr: 0.010000000000000002
2022-02-21 12:55:09 - train: epoch 0059, iter [00100, 05004], lr: 0.010000, loss: 1.5888
2022-02-21 12:55:47 - train: epoch 0059, iter [00200, 05004], lr: 0.010000, loss: 1.4715
2022-02-21 12:56:24 - train: epoch 0059, iter [00300, 05004], lr: 0.010000, loss: 1.4516
2022-02-21 12:57:01 - train: epoch 0059, iter [00400, 05004], lr: 0.010000, loss: 1.4552
2022-02-21 12:57:38 - train: epoch 0059, iter [00500, 05004], lr: 0.010000, loss: 1.6912
2022-02-21 12:58:14 - train: epoch 0059, iter [00600, 05004], lr: 0.010000, loss: 1.3324
2022-02-21 12:58:52 - train: epoch 0059, iter [00700, 05004], lr: 0.010000, loss: 1.3695
2022-02-21 12:59:28 - train: epoch 0059, iter [00800, 05004], lr: 0.010000, loss: 1.5103
2022-02-21 13:00:06 - train: epoch 0059, iter [00900, 05004], lr: 0.010000, loss: 1.4248
2022-02-21 13:00:43 - train: epoch 0059, iter [01000, 05004], lr: 0.010000, loss: 1.5132
2022-02-21 13:01:20 - train: epoch 0059, iter [01100, 05004], lr: 0.010000, loss: 1.6620
2022-02-21 13:01:56 - train: epoch 0059, iter [01200, 05004], lr: 0.010000, loss: 1.2383
2022-02-21 13:02:33 - train: epoch 0059, iter [01300, 05004], lr: 0.010000, loss: 1.5945
2022-02-21 13:03:11 - train: epoch 0059, iter [01400, 05004], lr: 0.010000, loss: 1.5100
2022-02-21 13:03:48 - train: epoch 0059, iter [01500, 05004], lr: 0.010000, loss: 1.5013
2022-02-21 13:04:24 - train: epoch 0059, iter [01600, 05004], lr: 0.010000, loss: 1.3142
2022-02-21 13:05:01 - train: epoch 0059, iter [01700, 05004], lr: 0.010000, loss: 1.5629
2022-02-21 13:05:38 - train: epoch 0059, iter [01800, 05004], lr: 0.010000, loss: 1.4258
2022-02-21 13:06:16 - train: epoch 0059, iter [01900, 05004], lr: 0.010000, loss: 1.5588
2022-02-21 13:06:52 - train: epoch 0059, iter [02000, 05004], lr: 0.010000, loss: 1.3568
2022-02-21 13:07:30 - train: epoch 0059, iter [02100, 05004], lr: 0.010000, loss: 1.6478
2022-02-21 13:08:07 - train: epoch 0059, iter [02200, 05004], lr: 0.010000, loss: 1.6677
2022-02-21 13:08:44 - train: epoch 0059, iter [02300, 05004], lr: 0.010000, loss: 1.3617
2022-02-21 13:09:22 - train: epoch 0059, iter [02400, 05004], lr: 0.010000, loss: 1.6241
2022-02-21 13:09:59 - train: epoch 0059, iter [02500, 05004], lr: 0.010000, loss: 1.5173
2022-02-21 13:10:36 - train: epoch 0059, iter [02600, 05004], lr: 0.010000, loss: 1.4368
2022-02-21 13:11:12 - train: epoch 0059, iter [02700, 05004], lr: 0.010000, loss: 1.4047
2022-02-21 13:11:50 - train: epoch 0059, iter [02800, 05004], lr: 0.010000, loss: 1.6412
2022-02-21 13:12:26 - train: epoch 0059, iter [02900, 05004], lr: 0.010000, loss: 1.3955
2022-02-21 13:13:05 - train: epoch 0059, iter [03000, 05004], lr: 0.010000, loss: 1.9276
2022-02-21 13:13:42 - train: epoch 0059, iter [03100, 05004], lr: 0.010000, loss: 1.3016
2022-02-21 13:14:20 - train: epoch 0059, iter [03200, 05004], lr: 0.010000, loss: 1.3592
2022-02-21 13:14:57 - train: epoch 0059, iter [03300, 05004], lr: 0.010000, loss: 1.4532
2022-02-21 13:15:33 - train: epoch 0059, iter [03400, 05004], lr: 0.010000, loss: 1.8395
2022-02-21 13:16:11 - train: epoch 0059, iter [03500, 05004], lr: 0.010000, loss: 1.2442
2022-02-21 13:16:47 - train: epoch 0059, iter [03600, 05004], lr: 0.010000, loss: 1.4184
2022-02-21 13:17:24 - train: epoch 0059, iter [03700, 05004], lr: 0.010000, loss: 1.2778
2022-02-21 13:18:02 - train: epoch 0059, iter [03800, 05004], lr: 0.010000, loss: 1.5621
2022-02-21 13:18:40 - train: epoch 0059, iter [03900, 05004], lr: 0.010000, loss: 1.2625
2022-02-21 13:19:17 - train: epoch 0059, iter [04000, 05004], lr: 0.010000, loss: 1.7806
2022-02-21 13:19:54 - train: epoch 0059, iter [04100, 05004], lr: 0.010000, loss: 1.4329
2022-02-21 13:20:31 - train: epoch 0059, iter [04200, 05004], lr: 0.010000, loss: 1.4694
2022-02-21 13:21:08 - train: epoch 0059, iter [04300, 05004], lr: 0.010000, loss: 1.6312
2022-02-21 13:21:46 - train: epoch 0059, iter [04400, 05004], lr: 0.010000, loss: 1.7041
2022-02-21 13:22:23 - train: epoch 0059, iter [04500, 05004], lr: 0.010000, loss: 1.5175
2022-02-21 13:22:59 - train: epoch 0059, iter [04600, 05004], lr: 0.010000, loss: 1.4595
2022-02-21 13:23:35 - train: epoch 0059, iter [04700, 05004], lr: 0.010000, loss: 1.4740
2022-02-21 13:24:09 - train: epoch 0059, iter [04800, 05004], lr: 0.010000, loss: 1.4002
2022-02-21 13:24:47 - train: epoch 0059, iter [04900, 05004], lr: 0.010000, loss: 1.6317
2022-02-21 13:25:23 - train: epoch 0059, iter [05000, 05004], lr: 0.010000, loss: 1.6202
2022-02-21 13:25:25 - train: epoch 059, train_loss: 1.4564
2022-02-21 13:26:48 - eval: epoch: 059, acc1: 67.976%, acc5: 88.616%, test_loss: 1.2881, per_image_load_time: 2.759ms, per_image_inference_time: 0.307ms
2022-02-21 13:26:49 - until epoch: 059, best_acc1: 68.458%
2022-02-21 13:26:49 - epoch 060 lr: 0.010000000000000002
2022-02-21 13:27:31 - train: epoch 0060, iter [00100, 05004], lr: 0.010000, loss: 1.3827
2022-02-21 13:28:09 - train: epoch 0060, iter [00200, 05004], lr: 0.010000, loss: 1.6340
2022-02-21 13:28:45 - train: epoch 0060, iter [00300, 05004], lr: 0.010000, loss: 1.4766
2022-02-21 13:29:21 - train: epoch 0060, iter [00400, 05004], lr: 0.010000, loss: 1.5222
2022-02-21 13:30:00 - train: epoch 0060, iter [00500, 05004], lr: 0.010000, loss: 1.6694
2022-02-21 13:30:36 - train: epoch 0060, iter [00600, 05004], lr: 0.010000, loss: 1.6429
2022-02-21 13:31:14 - train: epoch 0060, iter [00700, 05004], lr: 0.010000, loss: 1.5169
2022-02-21 13:31:52 - train: epoch 0060, iter [00800, 05004], lr: 0.010000, loss: 1.5986
2022-02-21 13:32:30 - train: epoch 0060, iter [00900, 05004], lr: 0.010000, loss: 1.1735
2022-02-21 13:33:07 - train: epoch 0060, iter [01000, 05004], lr: 0.010000, loss: 1.1085
2022-02-21 13:33:44 - train: epoch 0060, iter [01100, 05004], lr: 0.010000, loss: 1.2941
2022-02-21 13:34:23 - train: epoch 0060, iter [01200, 05004], lr: 0.010000, loss: 1.3547
2022-02-21 13:35:00 - train: epoch 0060, iter [01300, 05004], lr: 0.010000, loss: 1.3978
2022-02-21 13:35:36 - train: epoch 0060, iter [01400, 05004], lr: 0.010000, loss: 1.4836
2022-02-21 13:36:14 - train: epoch 0060, iter [01500, 05004], lr: 0.010000, loss: 1.5228
2022-02-21 13:36:52 - train: epoch 0060, iter [01600, 05004], lr: 0.010000, loss: 1.5286
2022-02-21 13:37:29 - train: epoch 0060, iter [01700, 05004], lr: 0.010000, loss: 1.3711
2022-02-21 13:38:06 - train: epoch 0060, iter [01800, 05004], lr: 0.010000, loss: 1.4891
2022-02-21 13:38:44 - train: epoch 0060, iter [01900, 05004], lr: 0.010000, loss: 1.5361
2022-02-21 13:39:22 - train: epoch 0060, iter [02000, 05004], lr: 0.010000, loss: 1.4239
2022-02-21 13:39:59 - train: epoch 0060, iter [02100, 05004], lr: 0.010000, loss: 1.4777
2022-02-21 13:40:36 - train: epoch 0060, iter [02200, 05004], lr: 0.010000, loss: 1.5109
2022-02-21 13:41:14 - train: epoch 0060, iter [02300, 05004], lr: 0.010000, loss: 1.2986
2022-02-21 13:41:51 - train: epoch 0060, iter [02400, 05004], lr: 0.010000, loss: 1.4064
2022-02-21 13:42:27 - train: epoch 0060, iter [02500, 05004], lr: 0.010000, loss: 1.4267
2022-02-21 13:43:06 - train: epoch 0060, iter [02600, 05004], lr: 0.010000, loss: 1.5399
2022-02-21 13:43:44 - train: epoch 0060, iter [02700, 05004], lr: 0.010000, loss: 1.4060
2022-02-21 13:44:20 - train: epoch 0060, iter [02800, 05004], lr: 0.010000, loss: 1.4113
2022-02-21 13:44:58 - train: epoch 0060, iter [02900, 05004], lr: 0.010000, loss: 1.4858
2022-02-21 13:45:35 - train: epoch 0060, iter [03000, 05004], lr: 0.010000, loss: 1.5950
2022-02-21 13:46:14 - train: epoch 0060, iter [03100, 05004], lr: 0.010000, loss: 1.5442
2022-02-21 13:46:51 - train: epoch 0060, iter [03200, 05004], lr: 0.010000, loss: 1.3454
2022-02-21 13:47:27 - train: epoch 0060, iter [03300, 05004], lr: 0.010000, loss: 1.3420
2022-02-21 13:48:06 - train: epoch 0060, iter [03400, 05004], lr: 0.010000, loss: 1.4208
2022-02-21 13:48:43 - train: epoch 0060, iter [03500, 05004], lr: 0.010000, loss: 1.4890
2022-02-21 13:49:21 - train: epoch 0060, iter [03600, 05004], lr: 0.010000, loss: 1.4678
2022-02-21 13:49:58 - train: epoch 0060, iter [03700, 05004], lr: 0.010000, loss: 1.5293
2022-02-21 13:50:36 - train: epoch 0060, iter [03800, 05004], lr: 0.010000, loss: 1.4393
2022-02-21 13:51:12 - train: epoch 0060, iter [03900, 05004], lr: 0.010000, loss: 1.7871
2022-02-21 13:51:50 - train: epoch 0060, iter [04000, 05004], lr: 0.010000, loss: 1.4166
2022-02-21 13:52:27 - train: epoch 0060, iter [04100, 05004], lr: 0.010000, loss: 1.6389
2022-02-21 13:53:05 - train: epoch 0060, iter [04200, 05004], lr: 0.010000, loss: 1.6312
2022-02-21 13:53:43 - train: epoch 0060, iter [04300, 05004], lr: 0.010000, loss: 1.4826
2022-02-21 13:54:19 - train: epoch 0060, iter [04400, 05004], lr: 0.010000, loss: 1.5032
2022-02-21 13:54:58 - train: epoch 0060, iter [04500, 05004], lr: 0.010000, loss: 1.4469
2022-02-21 13:55:35 - train: epoch 0060, iter [04600, 05004], lr: 0.010000, loss: 1.3404
2022-02-21 13:56:13 - train: epoch 0060, iter [04700, 05004], lr: 0.010000, loss: 1.4921
2022-02-21 13:56:51 - train: epoch 0060, iter [04800, 05004], lr: 0.010000, loss: 1.3214
2022-02-21 13:57:28 - train: epoch 0060, iter [04900, 05004], lr: 0.010000, loss: 1.3634
2022-02-21 13:58:03 - train: epoch 0060, iter [05000, 05004], lr: 0.010000, loss: 1.4377
2022-02-21 13:58:04 - train: epoch 060, train_loss: 1.4528
2022-02-21 13:59:28 - eval: epoch: 060, acc1: 67.552%, acc5: 88.464%, test_loss: 1.3001, per_image_load_time: 2.948ms, per_image_inference_time: 0.291ms
2022-02-21 13:59:29 - until epoch: 060, best_acc1: 68.458%
2022-02-21 13:59:29 - epoch 061 lr: 0.0010000000000000002
2022-02-21 14:00:12 - train: epoch 0061, iter [00100, 05004], lr: 0.001000, loss: 1.2646
2022-02-21 14:00:48 - train: epoch 0061, iter [00200, 05004], lr: 0.001000, loss: 1.4445
2022-02-21 14:01:26 - train: epoch 0061, iter [00300, 05004], lr: 0.001000, loss: 1.0929
2022-02-21 14:02:03 - train: epoch 0061, iter [00400, 05004], lr: 0.001000, loss: 1.6264
2022-02-21 14:02:41 - train: epoch 0061, iter [00500, 05004], lr: 0.001000, loss: 1.3506
2022-02-21 14:03:18 - train: epoch 0061, iter [00600, 05004], lr: 0.001000, loss: 1.3764
2022-02-21 14:03:56 - train: epoch 0061, iter [00700, 05004], lr: 0.001000, loss: 1.0166
2022-02-21 14:04:33 - train: epoch 0061, iter [00800, 05004], lr: 0.001000, loss: 1.3899
2022-02-21 14:05:11 - train: epoch 0061, iter [00900, 05004], lr: 0.001000, loss: 1.1896
2022-02-21 14:05:49 - train: epoch 0061, iter [01000, 05004], lr: 0.001000, loss: 1.1195
2022-02-21 14:06:26 - train: epoch 0061, iter [01100, 05004], lr: 0.001000, loss: 1.1099
2022-02-21 14:07:04 - train: epoch 0061, iter [01200, 05004], lr: 0.001000, loss: 1.2218
2022-02-21 14:07:41 - train: epoch 0061, iter [01300, 05004], lr: 0.001000, loss: 1.2634
2022-02-21 14:08:18 - train: epoch 0061, iter [01400, 05004], lr: 0.001000, loss: 1.1986
2022-02-21 14:08:55 - train: epoch 0061, iter [01500, 05004], lr: 0.001000, loss: 1.3496
2022-02-21 14:09:33 - train: epoch 0061, iter [01600, 05004], lr: 0.001000, loss: 1.0377
2022-02-21 14:10:10 - train: epoch 0061, iter [01700, 05004], lr: 0.001000, loss: 1.2194
2022-02-21 14:10:49 - train: epoch 0061, iter [01800, 05004], lr: 0.001000, loss: 1.2692
2022-02-21 14:11:25 - train: epoch 0061, iter [01900, 05004], lr: 0.001000, loss: 1.3926
2022-02-21 14:12:03 - train: epoch 0061, iter [02000, 05004], lr: 0.001000, loss: 1.2055
2022-02-21 14:12:39 - train: epoch 0061, iter [02100, 05004], lr: 0.001000, loss: 1.5850
2022-02-21 14:13:17 - train: epoch 0061, iter [02200, 05004], lr: 0.001000, loss: 1.1952
2022-02-21 14:13:55 - train: epoch 0061, iter [02300, 05004], lr: 0.001000, loss: 1.2788
2022-02-21 14:14:32 - train: epoch 0061, iter [02400, 05004], lr: 0.001000, loss: 0.9805
2022-02-21 14:15:10 - train: epoch 0061, iter [02500, 05004], lr: 0.001000, loss: 1.1531
2022-02-21 14:15:47 - train: epoch 0061, iter [02600, 05004], lr: 0.001000, loss: 1.3161
2022-02-21 14:16:25 - train: epoch 0061, iter [02700, 05004], lr: 0.001000, loss: 1.4184
2022-02-21 14:17:02 - train: epoch 0061, iter [02800, 05004], lr: 0.001000, loss: 1.2472
2022-02-21 14:17:40 - train: epoch 0061, iter [02900, 05004], lr: 0.001000, loss: 1.3422
2022-02-21 14:18:18 - train: epoch 0061, iter [03000, 05004], lr: 0.001000, loss: 1.1890
2022-02-21 14:18:55 - train: epoch 0061, iter [03100, 05004], lr: 0.001000, loss: 1.4045
2022-02-21 14:19:32 - train: epoch 0061, iter [03200, 05004], lr: 0.001000, loss: 1.2929
2022-02-21 14:20:10 - train: epoch 0061, iter [03300, 05004], lr: 0.001000, loss: 1.2099
2022-02-21 14:20:47 - train: epoch 0061, iter [03400, 05004], lr: 0.001000, loss: 1.0589
2022-02-21 14:21:25 - train: epoch 0061, iter [03500, 05004], lr: 0.001000, loss: 1.2847
2022-02-21 14:22:02 - train: epoch 0061, iter [03600, 05004], lr: 0.001000, loss: 1.2416
2022-02-21 14:22:40 - train: epoch 0061, iter [03700, 05004], lr: 0.001000, loss: 1.2970
2022-02-21 14:23:16 - train: epoch 0061, iter [03800, 05004], lr: 0.001000, loss: 1.2803
2022-02-21 14:23:53 - train: epoch 0061, iter [03900, 05004], lr: 0.001000, loss: 1.2250
2022-02-21 14:24:30 - train: epoch 0061, iter [04000, 05004], lr: 0.001000, loss: 1.2886
2022-02-21 14:25:08 - train: epoch 0061, iter [04100, 05004], lr: 0.001000, loss: 1.3747
2022-02-21 14:25:46 - train: epoch 0061, iter [04200, 05004], lr: 0.001000, loss: 1.1121
2022-02-21 14:26:21 - train: epoch 0061, iter [04300, 05004], lr: 0.001000, loss: 1.3113
2022-02-21 14:26:58 - train: epoch 0061, iter [04400, 05004], lr: 0.001000, loss: 1.2642
2022-02-21 14:27:38 - train: epoch 0061, iter [04500, 05004], lr: 0.001000, loss: 1.2063
2022-02-21 14:28:14 - train: epoch 0061, iter [04600, 05004], lr: 0.001000, loss: 1.3965
2022-02-21 14:28:52 - train: epoch 0061, iter [04700, 05004], lr: 0.001000, loss: 1.1826
2022-02-21 14:29:29 - train: epoch 0061, iter [04800, 05004], lr: 0.001000, loss: 1.2144
2022-02-21 14:30:07 - train: epoch 0061, iter [04900, 05004], lr: 0.001000, loss: 1.3683
2022-02-21 14:30:42 - train: epoch 0061, iter [05000, 05004], lr: 0.001000, loss: 1.2644
2022-02-21 14:30:43 - train: epoch 061, train_loss: 1.2538
2022-02-21 14:32:07 - eval: epoch: 061, acc1: 72.036%, acc5: 90.780%, test_loss: 1.1108, per_image_load_time: 2.880ms, per_image_inference_time: 0.283ms
2022-02-21 14:32:07 - until epoch: 061, best_acc1: 72.036%
2022-02-21 14:32:07 - epoch 062 lr: 0.0010000000000000002
2022-02-21 14:32:50 - train: epoch 0062, iter [00100, 05004], lr: 0.001000, loss: 1.2587
2022-02-21 14:33:26 - train: epoch 0062, iter [00200, 05004], lr: 0.001000, loss: 1.2465
2022-02-21 14:34:04 - train: epoch 0062, iter [00300, 05004], lr: 0.001000, loss: 1.1816
2022-02-21 14:34:42 - train: epoch 0062, iter [00400, 05004], lr: 0.001000, loss: 1.0953
2022-02-21 14:35:19 - train: epoch 0062, iter [00500, 05004], lr: 0.001000, loss: 1.0901
2022-02-21 14:35:56 - train: epoch 0062, iter [00600, 05004], lr: 0.001000, loss: 1.1290
2022-02-21 14:36:33 - train: epoch 0062, iter [00700, 05004], lr: 0.001000, loss: 1.3955
2022-02-21 14:37:10 - train: epoch 0062, iter [00800, 05004], lr: 0.001000, loss: 1.2476
2022-02-21 14:37:48 - train: epoch 0062, iter [00900, 05004], lr: 0.001000, loss: 1.1140
2022-02-21 14:38:25 - train: epoch 0062, iter [01000, 05004], lr: 0.001000, loss: 1.3136
2022-02-21 14:39:02 - train: epoch 0062, iter [01100, 05004], lr: 0.001000, loss: 1.0933
2022-02-21 14:39:41 - train: epoch 0062, iter [01200, 05004], lr: 0.001000, loss: 1.4701
2022-02-21 14:40:18 - train: epoch 0062, iter [01300, 05004], lr: 0.001000, loss: 1.3104
2022-02-21 14:40:55 - train: epoch 0062, iter [01400, 05004], lr: 0.001000, loss: 1.1896
2022-02-21 14:41:33 - train: epoch 0062, iter [01500, 05004], lr: 0.001000, loss: 1.2723
2022-02-21 14:42:10 - train: epoch 0062, iter [01600, 05004], lr: 0.001000, loss: 1.3556
2022-02-21 14:42:49 - train: epoch 0062, iter [01700, 05004], lr: 0.001000, loss: 1.2705
2022-02-21 14:43:26 - train: epoch 0062, iter [01800, 05004], lr: 0.001000, loss: 1.1475
2022-02-21 14:44:04 - train: epoch 0062, iter [01900, 05004], lr: 0.001000, loss: 1.1850
2022-02-21 14:44:41 - train: epoch 0062, iter [02000, 05004], lr: 0.001000, loss: 1.0884
2022-02-21 14:45:20 - train: epoch 0062, iter [02100, 05004], lr: 0.001000, loss: 1.3986
2022-02-21 14:45:57 - train: epoch 0062, iter [02200, 05004], lr: 0.001000, loss: 1.1048
2022-02-21 14:46:35 - train: epoch 0062, iter [02300, 05004], lr: 0.001000, loss: 1.2486
2022-02-21 14:47:12 - train: epoch 0062, iter [02400, 05004], lr: 0.001000, loss: 1.1555
2022-02-21 14:47:50 - train: epoch 0062, iter [02500, 05004], lr: 0.001000, loss: 1.1955
2022-02-21 14:48:27 - train: epoch 0062, iter [02600, 05004], lr: 0.001000, loss: 1.0874
2022-02-21 14:49:04 - train: epoch 0062, iter [02700, 05004], lr: 0.001000, loss: 1.1824
2022-02-21 14:49:40 - train: epoch 0062, iter [02800, 05004], lr: 0.001000, loss: 1.2667
2022-02-21 14:50:17 - train: epoch 0062, iter [02900, 05004], lr: 0.001000, loss: 1.2619
2022-02-21 14:50:54 - train: epoch 0062, iter [03000, 05004], lr: 0.001000, loss: 1.2998
2022-02-21 14:51:32 - train: epoch 0062, iter [03100, 05004], lr: 0.001000, loss: 1.2163
2022-02-21 14:52:10 - train: epoch 0062, iter [03200, 05004], lr: 0.001000, loss: 1.0640
2022-02-21 14:52:47 - train: epoch 0062, iter [03300, 05004], lr: 0.001000, loss: 1.3427
2022-02-21 14:53:24 - train: epoch 0062, iter [03400, 05004], lr: 0.001000, loss: 1.3440
2022-02-21 14:54:02 - train: epoch 0062, iter [03500, 05004], lr: 0.001000, loss: 1.3044
2022-02-21 14:54:38 - train: epoch 0062, iter [03600, 05004], lr: 0.001000, loss: 1.2685
2022-02-21 14:55:16 - train: epoch 0062, iter [03700, 05004], lr: 0.001000, loss: 1.1852
2022-02-21 14:55:54 - train: epoch 0062, iter [03800, 05004], lr: 0.001000, loss: 1.1517
2022-02-21 14:56:31 - train: epoch 0062, iter [03900, 05004], lr: 0.001000, loss: 1.2221
2022-02-21 14:57:09 - train: epoch 0062, iter [04000, 05004], lr: 0.001000, loss: 1.0497
2022-02-21 14:57:47 - train: epoch 0062, iter [04100, 05004], lr: 0.001000, loss: 1.2666
2022-02-21 14:58:24 - train: epoch 0062, iter [04200, 05004], lr: 0.001000, loss: 0.9986
2022-02-21 14:59:02 - train: epoch 0062, iter [04300, 05004], lr: 0.001000, loss: 1.1886
2022-02-21 14:59:39 - train: epoch 0062, iter [04400, 05004], lr: 0.001000, loss: 1.1181
2022-02-21 15:00:17 - train: epoch 0062, iter [04500, 05004], lr: 0.001000, loss: 1.0448
2022-02-21 15:00:54 - train: epoch 0062, iter [04600, 05004], lr: 0.001000, loss: 0.9691
2022-02-21 15:01:32 - train: epoch 0062, iter [04700, 05004], lr: 0.001000, loss: 1.1896
2022-02-21 15:02:10 - train: epoch 0062, iter [04800, 05004], lr: 0.001000, loss: 1.1360
2022-02-21 15:02:47 - train: epoch 0062, iter [04900, 05004], lr: 0.001000, loss: 1.1271
2022-02-21 15:03:23 - train: epoch 0062, iter [05000, 05004], lr: 0.001000, loss: 1.2973
2022-02-21 15:03:24 - train: epoch 062, train_loss: 1.2005
2022-02-21 15:04:49 - eval: epoch: 062, acc1: 72.330%, acc5: 90.942%, test_loss: 1.0953, per_image_load_time: 2.998ms, per_image_inference_time: 0.279ms
2022-02-21 15:04:50 - until epoch: 062, best_acc1: 72.330%
2022-02-21 15:04:50 - epoch 063 lr: 0.0010000000000000002
2022-02-21 15:05:32 - train: epoch 0063, iter [00100, 05004], lr: 0.001000, loss: 1.1661
2022-02-21 15:06:10 - train: epoch 0063, iter [00200, 05004], lr: 0.001000, loss: 1.1124
2022-02-21 15:06:48 - train: epoch 0063, iter [00300, 05004], lr: 0.001000, loss: 1.3576
2022-02-21 15:07:25 - train: epoch 0063, iter [00400, 05004], lr: 0.001000, loss: 1.2588
2022-02-21 15:08:03 - train: epoch 0063, iter [00500, 05004], lr: 0.001000, loss: 1.0806
2022-02-21 15:08:40 - train: epoch 0063, iter [00600, 05004], lr: 0.001000, loss: 1.2839
2022-02-21 15:09:18 - train: epoch 0063, iter [00700, 05004], lr: 0.001000, loss: 1.1496
2022-02-21 15:09:56 - train: epoch 0063, iter [00800, 05004], lr: 0.001000, loss: 1.2372
2022-02-21 15:10:33 - train: epoch 0063, iter [00900, 05004], lr: 0.001000, loss: 1.1691
2022-02-21 15:11:11 - train: epoch 0063, iter [01000, 05004], lr: 0.001000, loss: 1.2678
2022-02-21 15:11:47 - train: epoch 0063, iter [01100, 05004], lr: 0.001000, loss: 1.0793
2022-02-21 15:12:26 - train: epoch 0063, iter [01200, 05004], lr: 0.001000, loss: 1.1142
2022-02-21 15:13:04 - train: epoch 0063, iter [01300, 05004], lr: 0.001000, loss: 1.2219
2022-02-21 15:13:41 - train: epoch 0063, iter [01400, 05004], lr: 0.001000, loss: 1.4949
2022-02-21 15:14:20 - train: epoch 0063, iter [01500, 05004], lr: 0.001000, loss: 1.2494
2022-02-21 15:14:57 - train: epoch 0063, iter [01600, 05004], lr: 0.001000, loss: 1.0985
2022-02-21 15:15:34 - train: epoch 0063, iter [01700, 05004], lr: 0.001000, loss: 1.0567
2022-02-21 15:16:12 - train: epoch 0063, iter [01800, 05004], lr: 0.001000, loss: 1.3465
2022-02-21 15:16:49 - train: epoch 0063, iter [01900, 05004], lr: 0.001000, loss: 1.2982
2022-02-21 15:17:27 - train: epoch 0063, iter [02000, 05004], lr: 0.001000, loss: 1.1430
2022-02-21 15:18:03 - train: epoch 0063, iter [02100, 05004], lr: 0.001000, loss: 1.0721
2022-02-21 15:18:41 - train: epoch 0063, iter [02200, 05004], lr: 0.001000, loss: 1.4991
2022-02-21 15:19:18 - train: epoch 0063, iter [02300, 05004], lr: 0.001000, loss: 1.2822
2022-02-21 15:19:56 - train: epoch 0063, iter [02400, 05004], lr: 0.001000, loss: 1.3551
2022-02-21 15:20:34 - train: epoch 0063, iter [02500, 05004], lr: 0.001000, loss: 1.2150
2022-02-21 15:21:11 - train: epoch 0063, iter [02600, 05004], lr: 0.001000, loss: 1.1232
2022-02-21 15:21:49 - train: epoch 0063, iter [02700, 05004], lr: 0.001000, loss: 1.3621
2022-02-21 15:22:26 - train: epoch 0063, iter [02800, 05004], lr: 0.001000, loss: 1.1851
2022-02-21 15:23:05 - train: epoch 0063, iter [02900, 05004], lr: 0.001000, loss: 1.1976
2022-02-21 15:23:45 - train: epoch 0063, iter [03000, 05004], lr: 0.001000, loss: 1.2950
2022-02-21 15:24:26 - train: epoch 0063, iter [03100, 05004], lr: 0.001000, loss: 1.5338
2022-02-21 15:25:06 - train: epoch 0063, iter [03200, 05004], lr: 0.001000, loss: 1.2634
2022-02-21 15:25:44 - train: epoch 0063, iter [03300, 05004], lr: 0.001000, loss: 1.0977
2022-02-21 15:26:22 - train: epoch 0063, iter [03400, 05004], lr: 0.001000, loss: 0.9382
2022-02-21 15:26:59 - train: epoch 0063, iter [03500, 05004], lr: 0.001000, loss: 1.2516
2022-02-21 15:27:36 - train: epoch 0063, iter [03600, 05004], lr: 0.001000, loss: 1.0603
2022-02-21 15:28:12 - train: epoch 0063, iter [03700, 05004], lr: 0.001000, loss: 1.3742
2022-02-21 15:28:46 - train: epoch 0063, iter [03800, 05004], lr: 0.001000, loss: 1.3983
2022-02-21 15:29:24 - train: epoch 0063, iter [03900, 05004], lr: 0.001000, loss: 0.8909
2022-02-21 15:30:03 - train: epoch 0063, iter [04000, 05004], lr: 0.001000, loss: 0.9257
2022-02-21 15:30:42 - train: epoch 0063, iter [04100, 05004], lr: 0.001000, loss: 1.3525
2022-02-21 15:31:18 - train: epoch 0063, iter [04200, 05004], lr: 0.001000, loss: 1.0656
2022-02-21 15:31:55 - train: epoch 0063, iter [04300, 05004], lr: 0.001000, loss: 1.2893
2022-02-21 15:32:33 - train: epoch 0063, iter [04400, 05004], lr: 0.001000, loss: 1.1886
2022-02-21 15:33:10 - train: epoch 0063, iter [04500, 05004], lr: 0.001000, loss: 1.0394
2022-02-21 15:33:51 - train: epoch 0063, iter [04600, 05004], lr: 0.001000, loss: 1.1341
2022-02-21 15:34:31 - train: epoch 0063, iter [04700, 05004], lr: 0.001000, loss: 1.1039
2022-02-21 15:35:12 - train: epoch 0063, iter [04800, 05004], lr: 0.001000, loss: 1.1218
2022-02-21 15:35:50 - train: epoch 0063, iter [04900, 05004], lr: 0.001000, loss: 1.1216
2022-02-21 15:36:26 - train: epoch 0063, iter [05000, 05004], lr: 0.001000, loss: 1.0978
2022-02-21 15:36:27 - train: epoch 063, train_loss: 1.1804
2022-02-21 15:37:49 - eval: epoch: 063, acc1: 72.694%, acc5: 91.128%, test_loss: 1.0866, per_image_load_time: 2.908ms, per_image_inference_time: 0.285ms
2022-02-21 15:37:50 - until epoch: 063, best_acc1: 72.694%
2022-02-21 15:37:50 - epoch 064 lr: 0.0010000000000000002
2022-02-21 15:38:33 - train: epoch 0064, iter [00100, 05004], lr: 0.001000, loss: 1.0745
2022-02-21 15:39:10 - train: epoch 0064, iter [00200, 05004], lr: 0.001000, loss: 1.2189
2022-02-21 15:39:48 - train: epoch 0064, iter [00300, 05004], lr: 0.001000, loss: 1.0371
2022-02-21 15:40:25 - train: epoch 0064, iter [00400, 05004], lr: 0.001000, loss: 1.2903
2022-02-21 15:41:02 - train: epoch 0064, iter [00500, 05004], lr: 0.001000, loss: 1.0855
2022-02-21 15:41:39 - train: epoch 0064, iter [00600, 05004], lr: 0.001000, loss: 1.4167
2022-02-21 15:42:17 - train: epoch 0064, iter [00700, 05004], lr: 0.001000, loss: 1.2843
2022-02-21 15:42:54 - train: epoch 0064, iter [00800, 05004], lr: 0.001000, loss: 1.0601
2022-02-21 15:43:31 - train: epoch 0064, iter [00900, 05004], lr: 0.001000, loss: 1.1417
2022-02-21 15:44:09 - train: epoch 0064, iter [01000, 05004], lr: 0.001000, loss: 1.1175
2022-02-21 15:44:46 - train: epoch 0064, iter [01100, 05004], lr: 0.001000, loss: 1.0311
2022-02-21 15:45:23 - train: epoch 0064, iter [01200, 05004], lr: 0.001000, loss: 1.0301
2022-02-21 15:46:03 - train: epoch 0064, iter [01300, 05004], lr: 0.001000, loss: 1.1929
2022-02-21 15:46:39 - train: epoch 0064, iter [01400, 05004], lr: 0.001000, loss: 1.4126
2022-02-21 15:47:16 - train: epoch 0064, iter [01500, 05004], lr: 0.001000, loss: 1.2267
2022-02-21 15:47:52 - train: epoch 0064, iter [01600, 05004], lr: 0.001000, loss: 1.1047
2022-02-21 15:48:31 - train: epoch 0064, iter [01700, 05004], lr: 0.001000, loss: 1.0333
2022-02-21 15:49:07 - train: epoch 0064, iter [01800, 05004], lr: 0.001000, loss: 1.0317
2022-02-21 15:49:45 - train: epoch 0064, iter [01900, 05004], lr: 0.001000, loss: 1.1023
2022-02-21 15:50:22 - train: epoch 0064, iter [02000, 05004], lr: 0.001000, loss: 1.1385
2022-02-21 15:50:59 - train: epoch 0064, iter [02100, 05004], lr: 0.001000, loss: 1.2312
2022-02-21 15:51:36 - train: epoch 0064, iter [02200, 05004], lr: 0.001000, loss: 1.2202
2022-02-21 15:52:14 - train: epoch 0064, iter [02300, 05004], lr: 0.001000, loss: 1.2970
2022-02-21 15:52:50 - train: epoch 0064, iter [02400, 05004], lr: 0.001000, loss: 1.0882
2022-02-21 15:53:28 - train: epoch 0064, iter [02500, 05004], lr: 0.001000, loss: 0.9821
2022-02-21 15:54:05 - train: epoch 0064, iter [02600, 05004], lr: 0.001000, loss: 1.0828
2022-02-21 15:54:43 - train: epoch 0064, iter [02700, 05004], lr: 0.001000, loss: 1.1821
2022-02-21 15:55:20 - train: epoch 0064, iter [02800, 05004], lr: 0.001000, loss: 1.0184
2022-02-21 15:55:57 - train: epoch 0064, iter [02900, 05004], lr: 0.001000, loss: 1.3495
2022-02-21 15:56:35 - train: epoch 0064, iter [03000, 05004], lr: 0.001000, loss: 1.2540
2022-02-21 15:57:12 - train: epoch 0064, iter [03100, 05004], lr: 0.001000, loss: 1.1059
2022-02-21 15:57:49 - train: epoch 0064, iter [03200, 05004], lr: 0.001000, loss: 1.1967
2022-02-21 15:58:25 - train: epoch 0064, iter [03300, 05004], lr: 0.001000, loss: 1.1122
2022-02-21 15:59:03 - train: epoch 0064, iter [03400, 05004], lr: 0.001000, loss: 1.3046
2022-02-21 15:59:41 - train: epoch 0064, iter [03500, 05004], lr: 0.001000, loss: 1.0309
2022-02-21 16:00:20 - train: epoch 0064, iter [03600, 05004], lr: 0.001000, loss: 1.0832
2022-02-21 16:00:57 - train: epoch 0064, iter [03700, 05004], lr: 0.001000, loss: 0.8799
2022-02-21 16:01:35 - train: epoch 0064, iter [03800, 05004], lr: 0.001000, loss: 1.3516
2022-02-21 16:02:12 - train: epoch 0064, iter [03900, 05004], lr: 0.001000, loss: 1.0097
2022-02-21 16:02:50 - train: epoch 0064, iter [04000, 05004], lr: 0.001000, loss: 1.0243
2022-02-21 16:03:27 - train: epoch 0064, iter [04100, 05004], lr: 0.001000, loss: 1.2526
2022-02-21 16:04:05 - train: epoch 0064, iter [04200, 05004], lr: 0.001000, loss: 1.0709
2022-02-21 16:04:44 - train: epoch 0064, iter [04300, 05004], lr: 0.001000, loss: 1.4109
2022-02-21 16:05:25 - train: epoch 0064, iter [04400, 05004], lr: 0.001000, loss: 1.1538
2022-02-21 16:06:07 - train: epoch 0064, iter [04500, 05004], lr: 0.001000, loss: 1.0300
2022-02-21 16:06:45 - train: epoch 0064, iter [04600, 05004], lr: 0.001000, loss: 1.2918
2022-02-21 16:07:24 - train: epoch 0064, iter [04700, 05004], lr: 0.001000, loss: 1.5398
2022-02-21 16:08:03 - train: epoch 0064, iter [04800, 05004], lr: 0.001000, loss: 1.1196
2022-02-21 16:08:42 - train: epoch 0064, iter [04900, 05004], lr: 0.001000, loss: 1.3611
2022-02-21 16:09:20 - train: epoch 0064, iter [05000, 05004], lr: 0.001000, loss: 1.0382
2022-02-21 16:09:21 - train: epoch 064, train_loss: 1.1660
2022-02-21 16:10:49 - eval: epoch: 064, acc1: 72.756%, acc5: 91.174%, test_loss: 1.0814, per_image_load_time: 2.197ms, per_image_inference_time: 0.297ms
2022-02-21 16:10:50 - until epoch: 064, best_acc1: 72.756%
2022-02-21 16:10:50 - epoch 065 lr: 0.0010000000000000002
2022-02-21 16:11:35 - train: epoch 0065, iter [00100, 05004], lr: 0.001000, loss: 1.2587
2022-02-21 16:12:17 - train: epoch 0065, iter [00200, 05004], lr: 0.001000, loss: 1.1661
2022-02-21 16:13:00 - train: epoch 0065, iter [00300, 05004], lr: 0.001000, loss: 1.1925
2022-02-21 16:13:47 - train: epoch 0065, iter [00400, 05004], lr: 0.001000, loss: 1.2473
2022-02-21 16:14:25 - train: epoch 0065, iter [00500, 05004], lr: 0.001000, loss: 1.1318
2022-02-21 16:15:02 - train: epoch 0065, iter [00600, 05004], lr: 0.001000, loss: 1.2702
2022-02-21 16:15:41 - train: epoch 0065, iter [00700, 05004], lr: 0.001000, loss: 1.0573
2022-02-21 16:16:17 - train: epoch 0065, iter [00800, 05004], lr: 0.001000, loss: 1.1199
2022-02-21 16:16:55 - train: epoch 0065, iter [00900, 05004], lr: 0.001000, loss: 1.1453
2022-02-21 16:17:32 - train: epoch 0065, iter [01000, 05004], lr: 0.001000, loss: 1.1437
2022-02-21 16:18:10 - train: epoch 0065, iter [01100, 05004], lr: 0.001000, loss: 1.0645
2022-02-21 16:18:47 - train: epoch 0065, iter [01200, 05004], lr: 0.001000, loss: 1.3336
2022-02-21 16:19:25 - train: epoch 0065, iter [01300, 05004], lr: 0.001000, loss: 1.1156
2022-02-21 16:20:01 - train: epoch 0065, iter [01400, 05004], lr: 0.001000, loss: 0.9319
2022-02-21 16:20:39 - train: epoch 0065, iter [01500, 05004], lr: 0.001000, loss: 1.1331
2022-02-21 16:21:16 - train: epoch 0065, iter [01600, 05004], lr: 0.001000, loss: 1.1492
2022-02-21 16:21:53 - train: epoch 0065, iter [01700, 05004], lr: 0.001000, loss: 1.0872
2022-02-21 16:22:31 - train: epoch 0065, iter [01800, 05004], lr: 0.001000, loss: 1.0459
2022-02-21 16:23:10 - train: epoch 0065, iter [01900, 05004], lr: 0.001000, loss: 1.0433
2022-02-21 16:23:47 - train: epoch 0065, iter [02000, 05004], lr: 0.001000, loss: 1.1442
2022-02-21 16:24:25 - train: epoch 0065, iter [02100, 05004], lr: 0.001000, loss: 1.0695
2022-02-21 16:25:04 - train: epoch 0065, iter [02200, 05004], lr: 0.001000, loss: 1.3100
2022-02-21 16:25:43 - train: epoch 0065, iter [02300, 05004], lr: 0.001000, loss: 1.0667
2022-02-21 16:26:20 - train: epoch 0065, iter [02400, 05004], lr: 0.001000, loss: 1.0707
2022-02-21 16:27:00 - train: epoch 0065, iter [02500, 05004], lr: 0.001000, loss: 1.1987
2022-02-21 16:27:38 - train: epoch 0065, iter [02600, 05004], lr: 0.001000, loss: 1.2235
2022-02-21 16:28:16 - train: epoch 0065, iter [02700, 05004], lr: 0.001000, loss: 1.1934
2022-02-21 16:28:54 - train: epoch 0065, iter [02800, 05004], lr: 0.001000, loss: 1.0395
2022-02-21 16:29:31 - train: epoch 0065, iter [02900, 05004], lr: 0.001000, loss: 1.2545
2022-02-21 16:30:09 - train: epoch 0065, iter [03000, 05004], lr: 0.001000, loss: 0.9615
2022-02-21 16:30:48 - train: epoch 0065, iter [03100, 05004], lr: 0.001000, loss: 1.2356
2022-02-21 16:31:25 - train: epoch 0065, iter [03200, 05004], lr: 0.001000, loss: 1.3055
2022-02-21 16:32:03 - train: epoch 0065, iter [03300, 05004], lr: 0.001000, loss: 1.1478
2022-02-21 16:32:40 - train: epoch 0065, iter [03400, 05004], lr: 0.001000, loss: 0.9611
2022-02-21 16:33:18 - train: epoch 0065, iter [03500, 05004], lr: 0.001000, loss: 1.3061
2022-02-21 16:33:56 - train: epoch 0065, iter [03600, 05004], lr: 0.001000, loss: 1.2379
2022-02-21 16:34:34 - train: epoch 0065, iter [03700, 05004], lr: 0.001000, loss: 1.0463
2022-02-21 16:35:12 - train: epoch 0065, iter [03800, 05004], lr: 0.001000, loss: 0.9971
2022-02-21 16:35:50 - train: epoch 0065, iter [03900, 05004], lr: 0.001000, loss: 1.2113
2022-02-21 16:36:29 - train: epoch 0065, iter [04000, 05004], lr: 0.001000, loss: 1.2344
2022-02-21 16:37:07 - train: epoch 0065, iter [04100, 05004], lr: 0.001000, loss: 1.0798
2022-02-21 16:37:45 - train: epoch 0065, iter [04200, 05004], lr: 0.001000, loss: 1.1720
2022-02-21 16:38:23 - train: epoch 0065, iter [04300, 05004], lr: 0.001000, loss: 1.0765
2022-02-21 16:39:01 - train: epoch 0065, iter [04400, 05004], lr: 0.001000, loss: 1.1323
2022-02-21 16:39:38 - train: epoch 0065, iter [04500, 05004], lr: 0.001000, loss: 1.1502
2022-02-21 16:40:16 - train: epoch 0065, iter [04600, 05004], lr: 0.001000, loss: 1.1751
2022-02-21 16:40:55 - train: epoch 0065, iter [04700, 05004], lr: 0.001000, loss: 1.1820
2022-02-21 16:41:33 - train: epoch 0065, iter [04800, 05004], lr: 0.001000, loss: 0.9496
2022-02-21 16:42:11 - train: epoch 0065, iter [04900, 05004], lr: 0.001000, loss: 1.0990
2022-02-21 16:42:47 - train: epoch 0065, iter [05000, 05004], lr: 0.001000, loss: 1.2090
2022-02-21 16:42:48 - train: epoch 065, train_loss: 1.1536
2022-02-21 16:44:13 - eval: epoch: 065, acc1: 72.868%, acc5: 91.220%, test_loss: 1.0800, per_image_load_time: 3.021ms, per_image_inference_time: 0.275ms
2022-02-21 16:44:14 - until epoch: 065, best_acc1: 72.868%
2022-02-21 16:44:14 - epoch 066 lr: 0.0010000000000000002
2022-02-21 16:44:56 - train: epoch 0066, iter [00100, 05004], lr: 0.001000, loss: 1.0236
2022-02-21 16:45:32 - train: epoch 0066, iter [00200, 05004], lr: 0.001000, loss: 1.3093
2022-02-21 16:46:11 - train: epoch 0066, iter [00300, 05004], lr: 0.001000, loss: 1.0149
2022-02-21 16:46:48 - train: epoch 0066, iter [00400, 05004], lr: 0.001000, loss: 0.9249
2022-02-21 16:47:25 - train: epoch 0066, iter [00500, 05004], lr: 0.001000, loss: 1.2208
2022-02-21 16:48:03 - train: epoch 0066, iter [00600, 05004], lr: 0.001000, loss: 1.1657
2022-02-21 16:48:40 - train: epoch 0066, iter [00700, 05004], lr: 0.001000, loss: 1.0671
2022-02-21 16:49:17 - train: epoch 0066, iter [00800, 05004], lr: 0.001000, loss: 1.3829
2022-02-21 16:49:54 - train: epoch 0066, iter [00900, 05004], lr: 0.001000, loss: 1.2002
2022-02-21 16:50:32 - train: epoch 0066, iter [01000, 05004], lr: 0.001000, loss: 1.2147
2022-02-21 16:51:09 - train: epoch 0066, iter [01100, 05004], lr: 0.001000, loss: 1.1955
2022-02-21 16:51:48 - train: epoch 0066, iter [01200, 05004], lr: 0.001000, loss: 1.2728
2022-02-21 16:52:26 - train: epoch 0066, iter [01300, 05004], lr: 0.001000, loss: 1.2832
2022-02-21 16:53:04 - train: epoch 0066, iter [01400, 05004], lr: 0.001000, loss: 0.9951
2022-02-21 16:53:41 - train: epoch 0066, iter [01500, 05004], lr: 0.001000, loss: 1.1473
2022-02-21 16:54:19 - train: epoch 0066, iter [01600, 05004], lr: 0.001000, loss: 1.1636
2022-02-21 16:54:58 - train: epoch 0066, iter [01700, 05004], lr: 0.001000, loss: 1.0557
2022-02-21 16:55:36 - train: epoch 0066, iter [01800, 05004], lr: 0.001000, loss: 0.9972
2022-02-21 16:56:14 - train: epoch 0066, iter [01900, 05004], lr: 0.001000, loss: 1.4284
2022-02-21 16:56:52 - train: epoch 0066, iter [02000, 05004], lr: 0.001000, loss: 1.2016
2022-02-21 16:57:29 - train: epoch 0066, iter [02100, 05004], lr: 0.001000, loss: 1.1793
2022-02-21 16:58:06 - train: epoch 0066, iter [02200, 05004], lr: 0.001000, loss: 1.0989
2022-02-21 16:58:44 - train: epoch 0066, iter [02300, 05004], lr: 0.001000, loss: 1.3251
2022-02-21 16:59:22 - train: epoch 0066, iter [02400, 05004], lr: 0.001000, loss: 1.0345
2022-02-21 17:00:00 - train: epoch 0066, iter [02500, 05004], lr: 0.001000, loss: 1.1134
2022-02-21 17:00:37 - train: epoch 0066, iter [02600, 05004], lr: 0.001000, loss: 1.0601
2022-02-21 17:01:15 - train: epoch 0066, iter [02700, 05004], lr: 0.001000, loss: 1.3352
2022-02-21 17:01:52 - train: epoch 0066, iter [02800, 05004], lr: 0.001000, loss: 1.2736
2022-02-21 17:02:30 - train: epoch 0066, iter [02900, 05004], lr: 0.001000, loss: 1.0642
2022-02-21 17:03:07 - train: epoch 0066, iter [03000, 05004], lr: 0.001000, loss: 1.1152
2022-02-21 17:03:45 - train: epoch 0066, iter [03100, 05004], lr: 0.001000, loss: 1.3273
2022-02-21 17:04:22 - train: epoch 0066, iter [03200, 05004], lr: 0.001000, loss: 0.9844
2022-02-21 17:05:00 - train: epoch 0066, iter [03300, 05004], lr: 0.001000, loss: 1.0321
2022-02-21 17:05:37 - train: epoch 0066, iter [03400, 05004], lr: 0.001000, loss: 1.3266
2022-02-21 17:06:15 - train: epoch 0066, iter [03500, 05004], lr: 0.001000, loss: 1.1657
2022-02-21 17:06:52 - train: epoch 0066, iter [03600, 05004], lr: 0.001000, loss: 1.2143
2022-02-21 17:07:30 - train: epoch 0066, iter [03700, 05004], lr: 0.001000, loss: 1.2330
2022-02-21 17:08:07 - train: epoch 0066, iter [03800, 05004], lr: 0.001000, loss: 1.0202
2022-02-21 17:08:45 - train: epoch 0066, iter [03900, 05004], lr: 0.001000, loss: 1.0182
2022-02-21 17:09:22 - train: epoch 0066, iter [04000, 05004], lr: 0.001000, loss: 1.3013
2022-02-21 17:10:00 - train: epoch 0066, iter [04100, 05004], lr: 0.001000, loss: 1.0019
2022-02-21 17:10:37 - train: epoch 0066, iter [04200, 05004], lr: 0.001000, loss: 0.8727
2022-02-21 17:11:16 - train: epoch 0066, iter [04300, 05004], lr: 0.001000, loss: 1.0180
2022-02-21 17:11:52 - train: epoch 0066, iter [04400, 05004], lr: 0.001000, loss: 1.1169
2022-02-21 17:12:29 - train: epoch 0066, iter [04500, 05004], lr: 0.001000, loss: 1.1699
2022-02-21 17:13:07 - train: epoch 0066, iter [04600, 05004], lr: 0.001000, loss: 1.2997
2022-02-21 17:13:44 - train: epoch 0066, iter [04700, 05004], lr: 0.001000, loss: 1.0151
2022-02-21 17:14:22 - train: epoch 0066, iter [04800, 05004], lr: 0.001000, loss: 1.1653
2022-02-21 17:14:59 - train: epoch 0066, iter [04900, 05004], lr: 0.001000, loss: 1.0817
2022-02-21 17:15:34 - train: epoch 0066, iter [05000, 05004], lr: 0.001000, loss: 1.1035
2022-02-21 17:15:35 - train: epoch 066, train_loss: 1.1441
2022-02-21 17:16:58 - eval: epoch: 066, acc1: 72.822%, acc5: 91.300%, test_loss: 1.0769, per_image_load_time: 2.935ms, per_image_inference_time: 0.292ms
2022-02-21 17:16:58 - until epoch: 066, best_acc1: 72.868%
2022-02-21 17:16:58 - epoch 067 lr: 0.0010000000000000002
2022-02-21 17:17:42 - train: epoch 0067, iter [00100, 05004], lr: 0.001000, loss: 1.0047
2022-02-21 17:18:21 - train: epoch 0067, iter [00200, 05004], lr: 0.001000, loss: 1.1050
2022-02-21 17:18:59 - train: epoch 0067, iter [00300, 05004], lr: 0.001000, loss: 1.3860
2022-02-21 17:19:36 - train: epoch 0067, iter [00400, 05004], lr: 0.001000, loss: 1.2019
2022-02-21 17:20:14 - train: epoch 0067, iter [00500, 05004], lr: 0.001000, loss: 1.1125
2022-02-21 17:20:52 - train: epoch 0067, iter [00600, 05004], lr: 0.001000, loss: 1.0374
2022-02-21 17:21:30 - train: epoch 0067, iter [00700, 05004], lr: 0.001000, loss: 1.2195
2022-02-21 17:22:09 - train: epoch 0067, iter [00800, 05004], lr: 0.001000, loss: 1.1746
2022-02-21 17:22:50 - train: epoch 0067, iter [00900, 05004], lr: 0.001000, loss: 1.2026
2022-02-21 17:23:31 - train: epoch 0067, iter [01000, 05004], lr: 0.001000, loss: 0.9344
2022-02-21 17:24:11 - train: epoch 0067, iter [01100, 05004], lr: 0.001000, loss: 1.0871
2022-02-21 17:24:48 - train: epoch 0067, iter [01200, 05004], lr: 0.001000, loss: 1.1537
2022-02-21 17:25:25 - train: epoch 0067, iter [01300, 05004], lr: 0.001000, loss: 1.2839
2022-02-21 17:26:03 - train: epoch 0067, iter [01400, 05004], lr: 0.001000, loss: 1.1651
2022-02-21 17:26:39 - train: epoch 0067, iter [01500, 05004], lr: 0.001000, loss: 1.2152
2022-02-21 17:27:17 - train: epoch 0067, iter [01600, 05004], lr: 0.001000, loss: 1.1992
2022-02-21 17:27:54 - train: epoch 0067, iter [01700, 05004], lr: 0.001000, loss: 1.0497
2022-02-21 17:28:32 - train: epoch 0067, iter [01800, 05004], lr: 0.001000, loss: 1.2927
2022-02-21 17:29:09 - train: epoch 0067, iter [01900, 05004], lr: 0.001000, loss: 1.0155
2022-02-21 17:29:47 - train: epoch 0067, iter [02000, 05004], lr: 0.001000, loss: 1.3595
2022-02-21 17:30:24 - train: epoch 0067, iter [02100, 05004], lr: 0.001000, loss: 0.9805
2022-02-21 17:31:02 - train: epoch 0067, iter [02200, 05004], lr: 0.001000, loss: 1.2109
2022-02-21 17:31:40 - train: epoch 0067, iter [02300, 05004], lr: 0.001000, loss: 1.1489
2022-02-21 17:32:17 - train: epoch 0067, iter [02400, 05004], lr: 0.001000, loss: 1.1398
2022-02-21 17:32:51 - train: epoch 0067, iter [02500, 05004], lr: 0.001000, loss: 1.0391
2022-02-21 17:33:27 - train: epoch 0067, iter [02600, 05004], lr: 0.001000, loss: 1.0305
2022-02-21 17:34:05 - train: epoch 0067, iter [02700, 05004], lr: 0.001000, loss: 1.0067
2022-02-21 17:34:45 - train: epoch 0067, iter [02800, 05004], lr: 0.001000, loss: 1.2533
2022-02-21 17:35:22 - train: epoch 0067, iter [02900, 05004], lr: 0.001000, loss: 1.0381
2022-02-21 17:35:59 - train: epoch 0067, iter [03000, 05004], lr: 0.001000, loss: 1.1085
2022-02-21 17:36:37 - train: epoch 0067, iter [03100, 05004], lr: 0.001000, loss: 0.9167
2022-02-21 17:37:15 - train: epoch 0067, iter [03200, 05004], lr: 0.001000, loss: 1.2809
2022-02-21 17:37:51 - train: epoch 0067, iter [03300, 05004], lr: 0.001000, loss: 1.0145
2022-02-21 17:38:29 - train: epoch 0067, iter [03400, 05004], lr: 0.001000, loss: 1.0993
2022-02-21 17:39:07 - train: epoch 0067, iter [03500, 05004], lr: 0.001000, loss: 0.9983
2022-02-21 17:39:45 - train: epoch 0067, iter [03600, 05004], lr: 0.001000, loss: 1.0568
2022-02-21 17:40:22 - train: epoch 0067, iter [03700, 05004], lr: 0.001000, loss: 1.3588
2022-02-21 17:40:59 - train: epoch 0067, iter [03800, 05004], lr: 0.001000, loss: 1.1153
2022-02-21 17:41:36 - train: epoch 0067, iter [03900, 05004], lr: 0.001000, loss: 1.1922
2022-02-21 17:42:13 - train: epoch 0067, iter [04000, 05004], lr: 0.001000, loss: 1.3099
2022-02-21 17:42:51 - train: epoch 0067, iter [04100, 05004], lr: 0.001000, loss: 1.2557
2022-02-21 17:43:29 - train: epoch 0067, iter [04200, 05004], lr: 0.001000, loss: 1.3380
2022-02-21 17:44:07 - train: epoch 0067, iter [04300, 05004], lr: 0.001000, loss: 0.9688
2022-02-21 17:44:45 - train: epoch 0067, iter [04400, 05004], lr: 0.001000, loss: 1.1314
2022-02-21 17:45:21 - train: epoch 0067, iter [04500, 05004], lr: 0.001000, loss: 1.0509
2022-02-21 17:45:59 - train: epoch 0067, iter [04600, 05004], lr: 0.001000, loss: 0.9038
2022-02-21 17:46:38 - train: epoch 0067, iter [04700, 05004], lr: 0.001000, loss: 1.0838
2022-02-21 17:47:14 - train: epoch 0067, iter [04800, 05004], lr: 0.001000, loss: 0.9693
2022-02-21 17:47:53 - train: epoch 0067, iter [04900, 05004], lr: 0.001000, loss: 1.0358
2022-02-21 17:48:28 - train: epoch 0067, iter [05000, 05004], lr: 0.001000, loss: 1.2470
2022-02-21 17:48:29 - train: epoch 067, train_loss: 1.1360
2022-02-21 17:49:52 - eval: epoch: 067, acc1: 72.970%, acc5: 91.312%, test_loss: 1.0725, per_image_load_time: 2.517ms, per_image_inference_time: 0.310ms
2022-02-21 17:49:52 - until epoch: 067, best_acc1: 72.970%
2022-02-21 17:49:52 - epoch 068 lr: 0.0010000000000000002
2022-02-21 17:50:35 - train: epoch 0068, iter [00100, 05004], lr: 0.001000, loss: 1.2668
2022-02-21 17:51:13 - train: epoch 0068, iter [00200, 05004], lr: 0.001000, loss: 1.1782
2022-02-21 17:51:50 - train: epoch 0068, iter [00300, 05004], lr: 0.001000, loss: 1.2390
2022-02-21 17:52:28 - train: epoch 0068, iter [00400, 05004], lr: 0.001000, loss: 1.1973
2022-02-21 17:53:05 - train: epoch 0068, iter [00500, 05004], lr: 0.001000, loss: 1.1177
2022-02-21 17:53:43 - train: epoch 0068, iter [00600, 05004], lr: 0.001000, loss: 1.0715
2022-02-21 17:54:20 - train: epoch 0068, iter [00700, 05004], lr: 0.001000, loss: 1.4268
2022-02-21 17:54:58 - train: epoch 0068, iter [00800, 05004], lr: 0.001000, loss: 1.0477
2022-02-21 17:55:35 - train: epoch 0068, iter [00900, 05004], lr: 0.001000, loss: 1.0373
2022-02-21 17:56:12 - train: epoch 0068, iter [01000, 05004], lr: 0.001000, loss: 1.1005
2022-02-21 17:56:49 - train: epoch 0068, iter [01100, 05004], lr: 0.001000, loss: 1.2832
2022-02-21 17:57:25 - train: epoch 0068, iter [01200, 05004], lr: 0.001000, loss: 1.0027
2022-02-21 17:58:05 - train: epoch 0068, iter [01300, 05004], lr: 0.001000, loss: 0.9682
2022-02-21 17:58:43 - train: epoch 0068, iter [01400, 05004], lr: 0.001000, loss: 1.1600
2022-02-21 17:59:21 - train: epoch 0068, iter [01500, 05004], lr: 0.001000, loss: 1.2787
2022-02-21 17:59:58 - train: epoch 0068, iter [01600, 05004], lr: 0.001000, loss: 1.1683
2022-02-21 18:00:36 - train: epoch 0068, iter [01700, 05004], lr: 0.001000, loss: 1.3064
2022-02-21 18:01:13 - train: epoch 0068, iter [01800, 05004], lr: 0.001000, loss: 1.1490
2022-02-21 18:01:51 - train: epoch 0068, iter [01900, 05004], lr: 0.001000, loss: 1.1790
2022-02-21 18:02:27 - train: epoch 0068, iter [02000, 05004], lr: 0.001000, loss: 1.1943
2022-02-21 18:03:05 - train: epoch 0068, iter [02100, 05004], lr: 0.001000, loss: 1.0978
2022-02-21 18:03:43 - train: epoch 0068, iter [02200, 05004], lr: 0.001000, loss: 1.2318
2022-02-21 18:04:20 - train: epoch 0068, iter [02300, 05004], lr: 0.001000, loss: 0.9984
2022-02-21 18:04:58 - train: epoch 0068, iter [02400, 05004], lr: 0.001000, loss: 1.2321
2022-02-21 18:05:36 - train: epoch 0068, iter [02500, 05004], lr: 0.001000, loss: 1.1291
2022-02-21 18:06:14 - train: epoch 0068, iter [02600, 05004], lr: 0.001000, loss: 1.0384
2022-02-21 18:06:52 - train: epoch 0068, iter [02700, 05004], lr: 0.001000, loss: 1.2497
2022-02-21 18:07:29 - train: epoch 0068, iter [02800, 05004], lr: 0.001000, loss: 1.3319
2022-02-21 18:08:06 - train: epoch 0068, iter [02900, 05004], lr: 0.001000, loss: 1.2162
2022-02-21 18:08:43 - train: epoch 0068, iter [03000, 05004], lr: 0.001000, loss: 1.3341
2022-02-21 18:09:21 - train: epoch 0068, iter [03100, 05004], lr: 0.001000, loss: 1.0026
2022-02-21 18:09:59 - train: epoch 0068, iter [03200, 05004], lr: 0.001000, loss: 1.2374
2022-02-21 18:10:38 - train: epoch 0068, iter [03300, 05004], lr: 0.001000, loss: 1.1145
2022-02-21 18:11:14 - train: epoch 0068, iter [03400, 05004], lr: 0.001000, loss: 1.0391
2022-02-21 18:11:53 - train: epoch 0068, iter [03500, 05004], lr: 0.001000, loss: 1.1876
2022-02-21 18:12:29 - train: epoch 0068, iter [03600, 05004], lr: 0.001000, loss: 1.0622
2022-02-21 18:13:08 - train: epoch 0068, iter [03700, 05004], lr: 0.001000, loss: 1.2091
2022-02-21 18:13:45 - train: epoch 0068, iter [03800, 05004], lr: 0.001000, loss: 1.2024
2022-02-21 18:14:22 - train: epoch 0068, iter [03900, 05004], lr: 0.001000, loss: 1.1473
2022-02-21 18:15:00 - train: epoch 0068, iter [04000, 05004], lr: 0.001000, loss: 1.0853
2022-02-21 18:15:38 - train: epoch 0068, iter [04100, 05004], lr: 0.001000, loss: 0.9906
2022-02-21 18:16:15 - train: epoch 0068, iter [04200, 05004], lr: 0.001000, loss: 1.3486
2022-02-21 18:16:53 - train: epoch 0068, iter [04300, 05004], lr: 0.001000, loss: 1.2337
2022-02-21 18:17:31 - train: epoch 0068, iter [04400, 05004], lr: 0.001000, loss: 1.1089
2022-02-21 18:18:09 - train: epoch 0068, iter [04500, 05004], lr: 0.001000, loss: 1.1404
2022-02-21 18:18:47 - train: epoch 0068, iter [04600, 05004], lr: 0.001000, loss: 1.2284
2022-02-21 18:19:25 - train: epoch 0068, iter [04700, 05004], lr: 0.001000, loss: 1.4001
2022-02-21 18:20:03 - train: epoch 0068, iter [04800, 05004], lr: 0.001000, loss: 1.1891
2022-02-21 18:20:41 - train: epoch 0068, iter [04900, 05004], lr: 0.001000, loss: 1.2762
2022-02-21 18:21:16 - train: epoch 0068, iter [05000, 05004], lr: 0.001000, loss: 1.0819
2022-02-21 18:21:17 - train: epoch 068, train_loss: 1.1291
2022-02-21 18:22:39 - eval: epoch: 068, acc1: 73.144%, acc5: 91.370%, test_loss: 1.0673, per_image_load_time: 2.816ms, per_image_inference_time: 0.285ms
2022-02-21 18:22:40 - until epoch: 068, best_acc1: 73.144%
2022-02-21 18:22:40 - epoch 069 lr: 0.0010000000000000002
2022-02-21 18:23:22 - train: epoch 0069, iter [00100, 05004], lr: 0.001000, loss: 1.3221
2022-02-21 18:23:59 - train: epoch 0069, iter [00200, 05004], lr: 0.001000, loss: 1.2350
2022-02-21 18:24:36 - train: epoch 0069, iter [00300, 05004], lr: 0.001000, loss: 1.1996
2022-02-21 18:25:13 - train: epoch 0069, iter [00400, 05004], lr: 0.001000, loss: 1.0539
2022-02-21 18:25:51 - train: epoch 0069, iter [00500, 05004], lr: 0.001000, loss: 1.0260
2022-02-21 18:26:27 - train: epoch 0069, iter [00600, 05004], lr: 0.001000, loss: 1.0096
2022-02-21 18:27:05 - train: epoch 0069, iter [00700, 05004], lr: 0.001000, loss: 1.1252
2022-02-21 18:27:42 - train: epoch 0069, iter [00800, 05004], lr: 0.001000, loss: 1.1519
2022-02-21 18:28:20 - train: epoch 0069, iter [00900, 05004], lr: 0.001000, loss: 0.9924
2022-02-21 18:28:58 - train: epoch 0069, iter [01000, 05004], lr: 0.001000, loss: 1.1174
2022-02-21 18:29:34 - train: epoch 0069, iter [01100, 05004], lr: 0.001000, loss: 1.1447
2022-02-21 18:30:11 - train: epoch 0069, iter [01200, 05004], lr: 0.001000, loss: 1.1174
2022-02-21 18:30:48 - train: epoch 0069, iter [01300, 05004], lr: 0.001000, loss: 1.3806
2022-02-21 18:31:24 - train: epoch 0069, iter [01400, 05004], lr: 0.001000, loss: 1.1654
2022-02-21 18:32:02 - train: epoch 0069, iter [01500, 05004], lr: 0.001000, loss: 1.1648
2022-02-21 18:32:39 - train: epoch 0069, iter [01600, 05004], lr: 0.001000, loss: 1.2166
2022-02-21 18:33:17 - train: epoch 0069, iter [01700, 05004], lr: 0.001000, loss: 1.1454
2022-02-21 18:33:54 - train: epoch 0069, iter [01800, 05004], lr: 0.001000, loss: 0.9629
2022-02-21 18:34:31 - train: epoch 0069, iter [01900, 05004], lr: 0.001000, loss: 1.0056
2022-02-21 18:35:07 - train: epoch 0069, iter [02000, 05004], lr: 0.001000, loss: 0.9277
2022-02-21 18:35:44 - train: epoch 0069, iter [02100, 05004], lr: 0.001000, loss: 1.2092
2022-02-21 18:36:22 - train: epoch 0069, iter [02200, 05004], lr: 0.001000, loss: 1.1329
2022-02-21 18:36:59 - train: epoch 0069, iter [02300, 05004], lr: 0.001000, loss: 1.1308
2022-02-21 18:37:36 - train: epoch 0069, iter [02400, 05004], lr: 0.001000, loss: 1.2272
2022-02-21 18:38:13 - train: epoch 0069, iter [02500, 05004], lr: 0.001000, loss: 1.0658
2022-02-21 18:38:49 - train: epoch 0069, iter [02600, 05004], lr: 0.001000, loss: 1.2098
2022-02-21 18:39:27 - train: epoch 0069, iter [02700, 05004], lr: 0.001000, loss: 1.3475
2022-02-21 18:40:03 - train: epoch 0069, iter [02800, 05004], lr: 0.001000, loss: 1.3739
2022-02-21 18:40:40 - train: epoch 0069, iter [02900, 05004], lr: 0.001000, loss: 1.0031
2022-02-21 18:41:17 - train: epoch 0069, iter [03000, 05004], lr: 0.001000, loss: 1.0707
2022-02-21 18:41:54 - train: epoch 0069, iter [03100, 05004], lr: 0.001000, loss: 0.9988
2022-02-21 18:42:31 - train: epoch 0069, iter [03200, 05004], lr: 0.001000, loss: 1.0138
2022-02-21 18:43:08 - train: epoch 0069, iter [03300, 05004], lr: 0.001000, loss: 0.9712
2022-02-21 18:43:45 - train: epoch 0069, iter [03400, 05004], lr: 0.001000, loss: 0.9567
2022-02-21 18:44:21 - train: epoch 0069, iter [03500, 05004], lr: 0.001000, loss: 1.0703
2022-02-21 18:44:59 - train: epoch 0069, iter [03600, 05004], lr: 0.001000, loss: 1.0747
2022-02-21 18:45:35 - train: epoch 0069, iter [03700, 05004], lr: 0.001000, loss: 1.1659
2022-02-21 18:46:13 - train: epoch 0069, iter [03800, 05004], lr: 0.001000, loss: 1.2234
2022-02-21 18:46:49 - train: epoch 0069, iter [03900, 05004], lr: 0.001000, loss: 1.2209
2022-02-21 18:47:26 - train: epoch 0069, iter [04000, 05004], lr: 0.001000, loss: 1.2430
2022-02-21 18:48:02 - train: epoch 0069, iter [04100, 05004], lr: 0.001000, loss: 1.2258
2022-02-21 18:48:39 - train: epoch 0069, iter [04200, 05004], lr: 0.001000, loss: 0.9549
2022-02-21 18:49:16 - train: epoch 0069, iter [04300, 05004], lr: 0.001000, loss: 1.1130
2022-02-21 18:49:53 - train: epoch 0069, iter [04400, 05004], lr: 0.001000, loss: 1.1698
2022-02-21 18:50:30 - train: epoch 0069, iter [04500, 05004], lr: 0.001000, loss: 1.1837
2022-02-21 18:51:07 - train: epoch 0069, iter [04600, 05004], lr: 0.001000, loss: 1.3317
2022-02-21 18:51:45 - train: epoch 0069, iter [04700, 05004], lr: 0.001000, loss: 1.1899
2022-02-21 18:52:23 - train: epoch 0069, iter [04800, 05004], lr: 0.001000, loss: 1.1152
2022-02-21 18:53:00 - train: epoch 0069, iter [04900, 05004], lr: 0.001000, loss: 1.0345
2022-02-21 18:53:35 - train: epoch 0069, iter [05000, 05004], lr: 0.001000, loss: 1.2049
2022-02-21 18:53:36 - train: epoch 069, train_loss: 1.1210
2022-02-21 18:54:59 - eval: epoch: 069, acc1: 73.082%, acc5: 91.382%, test_loss: 1.0701, per_image_load_time: 2.861ms, per_image_inference_time: 0.297ms
2022-02-21 18:55:00 - until epoch: 069, best_acc1: 73.144%
2022-02-21 18:55:00 - epoch 070 lr: 0.0010000000000000002
2022-02-21 18:55:43 - train: epoch 0070, iter [00100, 05004], lr: 0.001000, loss: 1.2205
2022-02-21 18:56:20 - train: epoch 0070, iter [00200, 05004], lr: 0.001000, loss: 1.1718
2022-02-21 18:56:58 - train: epoch 0070, iter [00300, 05004], lr: 0.001000, loss: 1.2493
2022-02-21 18:57:35 - train: epoch 0070, iter [00400, 05004], lr: 0.001000, loss: 1.0638
2022-02-21 18:58:13 - train: epoch 0070, iter [00500, 05004], lr: 0.001000, loss: 1.1980
2022-02-21 18:58:52 - train: epoch 0070, iter [00600, 05004], lr: 0.001000, loss: 1.0144
2022-02-21 18:59:29 - train: epoch 0070, iter [00700, 05004], lr: 0.001000, loss: 1.0846
2022-02-21 19:00:06 - train: epoch 0070, iter [00800, 05004], lr: 0.001000, loss: 1.0357
2022-02-21 19:00:43 - train: epoch 0070, iter [00900, 05004], lr: 0.001000, loss: 1.1862
2022-02-21 19:01:21 - train: epoch 0070, iter [01000, 05004], lr: 0.001000, loss: 1.0253
2022-02-21 19:01:58 - train: epoch 0070, iter [01100, 05004], lr: 0.001000, loss: 1.4696
2022-02-21 19:02:35 - train: epoch 0070, iter [01200, 05004], lr: 0.001000, loss: 0.9162
2022-02-21 19:03:12 - train: epoch 0070, iter [01300, 05004], lr: 0.001000, loss: 1.0655
2022-02-21 19:03:49 - train: epoch 0070, iter [01400, 05004], lr: 0.001000, loss: 1.1220
2022-02-21 19:04:27 - train: epoch 0070, iter [01500, 05004], lr: 0.001000, loss: 0.9600
2022-02-21 19:05:04 - train: epoch 0070, iter [01600, 05004], lr: 0.001000, loss: 1.2373
2022-02-21 19:05:42 - train: epoch 0070, iter [01700, 05004], lr: 0.001000, loss: 1.2382
2022-02-21 19:06:18 - train: epoch 0070, iter [01800, 05004], lr: 0.001000, loss: 1.0734
2022-02-21 19:06:55 - train: epoch 0070, iter [01900, 05004], lr: 0.001000, loss: 1.0883
2022-02-21 19:07:33 - train: epoch 0070, iter [02000, 05004], lr: 0.001000, loss: 1.1740
2022-02-21 19:08:10 - train: epoch 0070, iter [02100, 05004], lr: 0.001000, loss: 1.1559
2022-02-21 19:08:48 - train: epoch 0070, iter [02200, 05004], lr: 0.001000, loss: 1.1106
2022-02-21 19:09:27 - train: epoch 0070, iter [02300, 05004], lr: 0.001000, loss: 1.1186
2022-02-21 19:10:04 - train: epoch 0070, iter [02400, 05004], lr: 0.001000, loss: 1.2534
2022-02-21 19:10:42 - train: epoch 0070, iter [02500, 05004], lr: 0.001000, loss: 1.1502
2022-02-21 19:11:19 - train: epoch 0070, iter [02600, 05004], lr: 0.001000, loss: 1.0772
2022-02-21 19:11:56 - train: epoch 0070, iter [02700, 05004], lr: 0.001000, loss: 1.0762
2022-02-21 19:12:34 - train: epoch 0070, iter [02800, 05004], lr: 0.001000, loss: 1.2087
2022-02-21 19:13:11 - train: epoch 0070, iter [02900, 05004], lr: 0.001000, loss: 1.2901
2022-02-21 19:13:49 - train: epoch 0070, iter [03000, 05004], lr: 0.001000, loss: 1.1112
2022-02-21 19:14:26 - train: epoch 0070, iter [03100, 05004], lr: 0.001000, loss: 1.0950
2022-02-21 19:15:03 - train: epoch 0070, iter [03200, 05004], lr: 0.001000, loss: 1.2762
2022-02-21 19:15:41 - train: epoch 0070, iter [03300, 05004], lr: 0.001000, loss: 1.0783
2022-02-21 19:16:19 - train: epoch 0070, iter [03400, 05004], lr: 0.001000, loss: 1.1245
2022-02-21 19:16:57 - train: epoch 0070, iter [03500, 05004], lr: 0.001000, loss: 1.1572
2022-02-21 19:17:34 - train: epoch 0070, iter [03600, 05004], lr: 0.001000, loss: 1.1605
2022-02-21 19:18:13 - train: epoch 0070, iter [03700, 05004], lr: 0.001000, loss: 1.1934
2022-02-21 19:18:49 - train: epoch 0070, iter [03800, 05004], lr: 0.001000, loss: 1.1047
2022-02-21 19:19:27 - train: epoch 0070, iter [03900, 05004], lr: 0.001000, loss: 1.0470
2022-02-21 19:20:05 - train: epoch 0070, iter [04000, 05004], lr: 0.001000, loss: 0.9464
2022-02-21 19:20:42 - train: epoch 0070, iter [04100, 05004], lr: 0.001000, loss: 0.9961
2022-02-21 19:21:20 - train: epoch 0070, iter [04200, 05004], lr: 0.001000, loss: 1.1376
2022-02-21 19:21:58 - train: epoch 0070, iter [04300, 05004], lr: 0.001000, loss: 1.0792
2022-02-21 19:22:35 - train: epoch 0070, iter [04400, 05004], lr: 0.001000, loss: 1.2405
2022-02-21 19:23:13 - train: epoch 0070, iter [04500, 05004], lr: 0.001000, loss: 1.1152
2022-02-21 19:23:52 - train: epoch 0070, iter [04600, 05004], lr: 0.001000, loss: 1.2612
2022-02-21 19:24:28 - train: epoch 0070, iter [04700, 05004], lr: 0.001000, loss: 1.1725
2022-02-21 19:25:07 - train: epoch 0070, iter [04800, 05004], lr: 0.001000, loss: 1.1763
2022-02-21 19:25:45 - train: epoch 0070, iter [04900, 05004], lr: 0.001000, loss: 1.1754
2022-02-21 19:26:21 - train: epoch 0070, iter [05000, 05004], lr: 0.001000, loss: 1.0508
2022-02-21 19:26:22 - train: epoch 070, train_loss: 1.1170
2022-02-21 19:27:47 - eval: epoch: 070, acc1: 73.164%, acc5: 91.354%, test_loss: 1.0664, per_image_load_time: 3.024ms, per_image_inference_time: 0.289ms
2022-02-21 19:27:48 - until epoch: 070, best_acc1: 73.164%
2022-02-21 19:27:48 - epoch 071 lr: 0.0010000000000000002
2022-02-21 19:28:30 - train: epoch 0071, iter [00100, 05004], lr: 0.001000, loss: 0.9573
2022-02-21 19:29:09 - train: epoch 0071, iter [00200, 05004], lr: 0.001000, loss: 1.0615
2022-02-21 19:29:46 - train: epoch 0071, iter [00300, 05004], lr: 0.001000, loss: 1.0024
2022-02-21 19:30:24 - train: epoch 0071, iter [00400, 05004], lr: 0.001000, loss: 1.1709
2022-02-21 19:31:01 - train: epoch 0071, iter [00500, 05004], lr: 0.001000, loss: 1.1299
2022-02-21 19:31:38 - train: epoch 0071, iter [00600, 05004], lr: 0.001000, loss: 1.1817
2022-02-21 19:32:15 - train: epoch 0071, iter [00700, 05004], lr: 0.001000, loss: 1.2671
2022-02-21 19:32:53 - train: epoch 0071, iter [00800, 05004], lr: 0.001000, loss: 1.1432
2022-02-21 19:33:31 - train: epoch 0071, iter [00900, 05004], lr: 0.001000, loss: 1.1309
2022-02-21 19:34:08 - train: epoch 0071, iter [01000, 05004], lr: 0.001000, loss: 1.1904
2022-02-21 19:34:46 - train: epoch 0071, iter [01100, 05004], lr: 0.001000, loss: 1.3244
2022-02-21 19:35:23 - train: epoch 0071, iter [01200, 05004], lr: 0.001000, loss: 1.0610
2022-02-21 19:36:02 - train: epoch 0071, iter [01300, 05004], lr: 0.001000, loss: 1.0927
2022-02-21 19:36:39 - train: epoch 0071, iter [01400, 05004], lr: 0.001000, loss: 1.0591
2022-02-21 19:37:17 - train: epoch 0071, iter [01500, 05004], lr: 0.001000, loss: 0.8902
2022-02-21 19:37:52 - train: epoch 0071, iter [01600, 05004], lr: 0.001000, loss: 1.0183
2022-02-21 19:38:26 - train: epoch 0071, iter [01700, 05004], lr: 0.001000, loss: 1.1615
2022-02-21 19:39:04 - train: epoch 0071, iter [01800, 05004], lr: 0.001000, loss: 1.0704
2022-02-21 19:39:43 - train: epoch 0071, iter [01900, 05004], lr: 0.001000, loss: 1.0044
2022-02-21 19:40:23 - train: epoch 0071, iter [02000, 05004], lr: 0.001000, loss: 1.1819
2022-02-21 19:41:01 - train: epoch 0071, iter [02100, 05004], lr: 0.001000, loss: 0.9706
2022-02-21 19:41:40 - train: epoch 0071, iter [02200, 05004], lr: 0.001000, loss: 0.9903
2022-02-21 19:42:16 - train: epoch 0071, iter [02300, 05004], lr: 0.001000, loss: 1.0102
2022-02-21 19:42:54 - train: epoch 0071, iter [02400, 05004], lr: 0.001000, loss: 1.0430
2022-02-21 19:43:31 - train: epoch 0071, iter [02500, 05004], lr: 0.001000, loss: 1.2230
2022-02-21 19:44:09 - train: epoch 0071, iter [02600, 05004], lr: 0.001000, loss: 0.9715
2022-02-21 19:44:46 - train: epoch 0071, iter [02700, 05004], lr: 0.001000, loss: 1.1090
2022-02-21 19:45:24 - train: epoch 0071, iter [02800, 05004], lr: 0.001000, loss: 1.1519
2022-02-21 19:46:02 - train: epoch 0071, iter [02900, 05004], lr: 0.001000, loss: 1.1640
2022-02-21 19:46:40 - train: epoch 0071, iter [03000, 05004], lr: 0.001000, loss: 1.1694
2022-02-21 19:47:17 - train: epoch 0071, iter [03100, 05004], lr: 0.001000, loss: 1.0939
2022-02-21 19:47:55 - train: epoch 0071, iter [03200, 05004], lr: 0.001000, loss: 1.0066
2022-02-21 19:48:34 - train: epoch 0071, iter [03300, 05004], lr: 0.001000, loss: 0.9484
2022-02-21 19:49:11 - train: epoch 0071, iter [03400, 05004], lr: 0.001000, loss: 1.0941
2022-02-21 19:49:49 - train: epoch 0071, iter [03500, 05004], lr: 0.001000, loss: 1.1719
2022-02-21 19:50:27 - train: epoch 0071, iter [03600, 05004], lr: 0.001000, loss: 1.2972
2022-02-21 19:51:05 - train: epoch 0071, iter [03700, 05004], lr: 0.001000, loss: 1.1107
2022-02-21 19:51:43 - train: epoch 0071, iter [03800, 05004], lr: 0.001000, loss: 1.0992
2022-02-21 19:52:22 - train: epoch 0071, iter [03900, 05004], lr: 0.001000, loss: 1.2095
2022-02-21 19:52:59 - train: epoch 0071, iter [04000, 05004], lr: 0.001000, loss: 1.3126
2022-02-21 19:53:36 - train: epoch 0071, iter [04100, 05004], lr: 0.001000, loss: 1.0644
2022-02-21 19:54:14 - train: epoch 0071, iter [04200, 05004], lr: 0.001000, loss: 1.2937
2022-02-21 19:54:51 - train: epoch 0071, iter [04300, 05004], lr: 0.001000, loss: 1.1758
2022-02-21 19:55:29 - train: epoch 0071, iter [04400, 05004], lr: 0.001000, loss: 1.1953
2022-02-21 19:56:07 - train: epoch 0071, iter [04500, 05004], lr: 0.001000, loss: 1.0937
2022-02-21 19:56:44 - train: epoch 0071, iter [04600, 05004], lr: 0.001000, loss: 1.2191
2022-02-21 19:57:21 - train: epoch 0071, iter [04700, 05004], lr: 0.001000, loss: 0.9715
2022-02-21 19:58:00 - train: epoch 0071, iter [04800, 05004], lr: 0.001000, loss: 0.9850
2022-02-21 19:58:38 - train: epoch 0071, iter [04900, 05004], lr: 0.001000, loss: 0.8387
2022-02-21 19:59:13 - train: epoch 0071, iter [05000, 05004], lr: 0.001000, loss: 0.9889
2022-02-21 19:59:15 - train: epoch 071, train_loss: 1.1108
2022-02-21 20:00:38 - eval: epoch: 071, acc1: 73.302%, acc5: 91.468%, test_loss: 1.0651, per_image_load_time: 0.989ms, per_image_inference_time: 0.262ms
2022-02-21 20:00:39 - until epoch: 071, best_acc1: 73.302%
2022-02-21 20:00:39 - epoch 072 lr: 0.0010000000000000002
2022-02-21 20:01:21 - train: epoch 0072, iter [00100, 05004], lr: 0.001000, loss: 1.2454
2022-02-21 20:01:58 - train: epoch 0072, iter [00200, 05004], lr: 0.001000, loss: 0.9657
2022-02-21 20:02:34 - train: epoch 0072, iter [00300, 05004], lr: 0.001000, loss: 1.0851
2022-02-21 20:03:13 - train: epoch 0072, iter [00400, 05004], lr: 0.001000, loss: 1.1497
2022-02-21 20:03:49 - train: epoch 0072, iter [00500, 05004], lr: 0.001000, loss: 1.0375
2022-02-21 20:04:26 - train: epoch 0072, iter [00600, 05004], lr: 0.001000, loss: 1.0765
2022-02-21 20:05:04 - train: epoch 0072, iter [00700, 05004], lr: 0.001000, loss: 1.1323
2022-02-21 20:05:42 - train: epoch 0072, iter [00800, 05004], lr: 0.001000, loss: 1.2903
2022-02-21 20:06:20 - train: epoch 0072, iter [00900, 05004], lr: 0.001000, loss: 0.9906
2022-02-21 20:06:57 - train: epoch 0072, iter [01000, 05004], lr: 0.001000, loss: 1.1219
2022-02-21 20:07:35 - train: epoch 0072, iter [01100, 05004], lr: 0.001000, loss: 1.1254
2022-02-21 20:08:13 - train: epoch 0072, iter [01200, 05004], lr: 0.001000, loss: 1.0398
2022-02-21 20:08:51 - train: epoch 0072, iter [01300, 05004], lr: 0.001000, loss: 1.1064
2022-02-21 20:09:28 - train: epoch 0072, iter [01400, 05004], lr: 0.001000, loss: 1.0644
2022-02-21 20:10:04 - train: epoch 0072, iter [01500, 05004], lr: 0.001000, loss: 0.9765
2022-02-21 20:10:43 - train: epoch 0072, iter [01600, 05004], lr: 0.001000, loss: 1.1607
2022-02-21 20:11:20 - train: epoch 0072, iter [01700, 05004], lr: 0.001000, loss: 1.0496
2022-02-21 20:11:58 - train: epoch 0072, iter [01800, 05004], lr: 0.001000, loss: 0.9978
2022-02-21 20:12:35 - train: epoch 0072, iter [01900, 05004], lr: 0.001000, loss: 1.0515
2022-02-21 20:13:14 - train: epoch 0072, iter [02000, 05004], lr: 0.001000, loss: 1.1963
2022-02-21 20:13:51 - train: epoch 0072, iter [02100, 05004], lr: 0.001000, loss: 1.1060
2022-02-21 20:14:29 - train: epoch 0072, iter [02200, 05004], lr: 0.001000, loss: 1.1197
2022-02-21 20:15:05 - train: epoch 0072, iter [02300, 05004], lr: 0.001000, loss: 1.2256
2022-02-21 20:15:43 - train: epoch 0072, iter [02400, 05004], lr: 0.001000, loss: 1.0618
2022-02-21 20:16:21 - train: epoch 0072, iter [02500, 05004], lr: 0.001000, loss: 0.9347
2022-02-21 20:16:59 - train: epoch 0072, iter [02600, 05004], lr: 0.001000, loss: 0.9109
2022-02-21 20:17:35 - train: epoch 0072, iter [02700, 05004], lr: 0.001000, loss: 1.0934
2022-02-21 20:18:13 - train: epoch 0072, iter [02800, 05004], lr: 0.001000, loss: 1.1660
2022-02-21 20:18:49 - train: epoch 0072, iter [02900, 05004], lr: 0.001000, loss: 1.0318
2022-02-21 20:19:28 - train: epoch 0072, iter [03000, 05004], lr: 0.001000, loss: 1.0469
2022-02-21 20:20:05 - train: epoch 0072, iter [03100, 05004], lr: 0.001000, loss: 1.2205
2022-02-21 20:20:43 - train: epoch 0072, iter [03200, 05004], lr: 0.001000, loss: 1.0743
2022-02-21 20:21:20 - train: epoch 0072, iter [03300, 05004], lr: 0.001000, loss: 1.0519
2022-02-21 20:21:56 - train: epoch 0072, iter [03400, 05004], lr: 0.001000, loss: 1.1089
2022-02-21 20:22:34 - train: epoch 0072, iter [03500, 05004], lr: 0.001000, loss: 1.1117
2022-02-21 20:23:12 - train: epoch 0072, iter [03600, 05004], lr: 0.001000, loss: 1.0337
2022-02-21 20:23:49 - train: epoch 0072, iter [03700, 05004], lr: 0.001000, loss: 1.1839
2022-02-21 20:24:26 - train: epoch 0072, iter [03800, 05004], lr: 0.001000, loss: 1.1101
2022-02-21 20:25:03 - train: epoch 0072, iter [03900, 05004], lr: 0.001000, loss: 1.2000
2022-02-21 20:25:41 - train: epoch 0072, iter [04000, 05004], lr: 0.001000, loss: 1.0592
2022-02-21 20:26:19 - train: epoch 0072, iter [04100, 05004], lr: 0.001000, loss: 1.2311
2022-02-21 20:26:57 - train: epoch 0072, iter [04200, 05004], lr: 0.001000, loss: 1.1502
2022-02-21 20:27:35 - train: epoch 0072, iter [04300, 05004], lr: 0.001000, loss: 1.0714
2022-02-21 20:28:12 - train: epoch 0072, iter [04400, 05004], lr: 0.001000, loss: 0.9816
2022-02-21 20:28:49 - train: epoch 0072, iter [04500, 05004], lr: 0.001000, loss: 1.1358
2022-02-21 20:29:27 - train: epoch 0072, iter [04600, 05004], lr: 0.001000, loss: 1.0561
2022-02-21 20:30:03 - train: epoch 0072, iter [04700, 05004], lr: 0.001000, loss: 1.1114
2022-02-21 20:30:43 - train: epoch 0072, iter [04800, 05004], lr: 0.001000, loss: 1.2724
2022-02-21 20:31:22 - train: epoch 0072, iter [04900, 05004], lr: 0.001000, loss: 1.1382
2022-02-21 20:32:01 - train: epoch 0072, iter [05000, 05004], lr: 0.001000, loss: 1.0541
2022-02-21 20:32:02 - train: epoch 072, train_loss: 1.1068
2022-02-21 20:33:37 - eval: epoch: 072, acc1: 73.218%, acc5: 91.412%, test_loss: 1.0665, per_image_load_time: 0.862ms, per_image_inference_time: 0.261ms
2022-02-21 20:33:38 - until epoch: 072, best_acc1: 73.302%
2022-02-21 20:33:38 - epoch 073 lr: 0.0010000000000000002
2022-02-21 20:34:21 - train: epoch 0073, iter [00100, 05004], lr: 0.001000, loss: 1.3248
2022-02-21 20:34:58 - train: epoch 0073, iter [00200, 05004], lr: 0.001000, loss: 1.1169
2022-02-21 20:35:35 - train: epoch 0073, iter [00300, 05004], lr: 0.001000, loss: 1.1687
2022-02-21 20:36:12 - train: epoch 0073, iter [00400, 05004], lr: 0.001000, loss: 0.8803
2022-02-21 20:36:50 - train: epoch 0073, iter [00500, 05004], lr: 0.001000, loss: 0.9946
2022-02-21 20:37:28 - train: epoch 0073, iter [00600, 05004], lr: 0.001000, loss: 1.0483
2022-02-21 20:38:05 - train: epoch 0073, iter [00700, 05004], lr: 0.001000, loss: 1.1481
2022-02-21 20:38:43 - train: epoch 0073, iter [00800, 05004], lr: 0.001000, loss: 0.9109
2022-02-21 20:39:19 - train: epoch 0073, iter [00900, 05004], lr: 0.001000, loss: 0.9187
2022-02-21 20:39:58 - train: epoch 0073, iter [01000, 05004], lr: 0.001000, loss: 0.9709
2022-02-21 20:40:34 - train: epoch 0073, iter [01100, 05004], lr: 0.001000, loss: 1.1637
2022-02-21 20:41:13 - train: epoch 0073, iter [01200, 05004], lr: 0.001000, loss: 1.0833
2022-02-21 20:41:50 - train: epoch 0073, iter [01300, 05004], lr: 0.001000, loss: 1.0076
2022-02-21 20:42:25 - train: epoch 0073, iter [01400, 05004], lr: 0.001000, loss: 1.1229
2022-02-21 20:43:03 - train: epoch 0073, iter [01500, 05004], lr: 0.001000, loss: 1.0527
2022-02-21 20:43:38 - train: epoch 0073, iter [01600, 05004], lr: 0.001000, loss: 1.0927
2022-02-21 20:44:15 - train: epoch 0073, iter [01700, 05004], lr: 0.001000, loss: 1.2996
2022-02-21 20:44:52 - train: epoch 0073, iter [01800, 05004], lr: 0.001000, loss: 0.9148
2022-02-21 20:45:28 - train: epoch 0073, iter [01900, 05004], lr: 0.001000, loss: 1.1589
2022-02-21 20:46:04 - train: epoch 0073, iter [02000, 05004], lr: 0.001000, loss: 0.8666
2022-02-21 20:46:41 - train: epoch 0073, iter [02100, 05004], lr: 0.001000, loss: 1.1170
2022-02-21 20:47:17 - train: epoch 0073, iter [02200, 05004], lr: 0.001000, loss: 1.2776
2022-02-21 20:47:55 - train: epoch 0073, iter [02300, 05004], lr: 0.001000, loss: 1.1875
2022-02-21 20:48:31 - train: epoch 0073, iter [02400, 05004], lr: 0.001000, loss: 1.0791
2022-02-21 20:49:08 - train: epoch 0073, iter [02500, 05004], lr: 0.001000, loss: 1.1898
2022-02-21 20:49:45 - train: epoch 0073, iter [02600, 05004], lr: 0.001000, loss: 1.1218
2022-02-21 20:50:22 - train: epoch 0073, iter [02700, 05004], lr: 0.001000, loss: 1.1791
2022-02-21 20:50:58 - train: epoch 0073, iter [02800, 05004], lr: 0.001000, loss: 1.1257
2022-02-21 20:51:36 - train: epoch 0073, iter [02900, 05004], lr: 0.001000, loss: 1.2370
2022-02-21 20:52:13 - train: epoch 0073, iter [03000, 05004], lr: 0.001000, loss: 0.9199
2022-02-21 20:52:51 - train: epoch 0073, iter [03100, 05004], lr: 0.001000, loss: 1.0501
2022-02-21 20:53:28 - train: epoch 0073, iter [03200, 05004], lr: 0.001000, loss: 0.9931
2022-02-21 20:54:06 - train: epoch 0073, iter [03300, 05004], lr: 0.001000, loss: 1.0380
2022-02-21 20:54:42 - train: epoch 0073, iter [03400, 05004], lr: 0.001000, loss: 1.1092
2022-02-21 20:55:20 - train: epoch 0073, iter [03500, 05004], lr: 0.001000, loss: 1.0948
2022-02-21 20:55:57 - train: epoch 0073, iter [03600, 05004], lr: 0.001000, loss: 0.9927
2022-02-21 20:56:35 - train: epoch 0073, iter [03700, 05004], lr: 0.001000, loss: 1.1531
2022-02-21 20:57:12 - train: epoch 0073, iter [03800, 05004], lr: 0.001000, loss: 1.3118
2022-02-21 20:57:50 - train: epoch 0073, iter [03900, 05004], lr: 0.001000, loss: 1.1631
2022-02-21 20:58:28 - train: epoch 0073, iter [04000, 05004], lr: 0.001000, loss: 1.1806
2022-02-21 20:59:05 - train: epoch 0073, iter [04100, 05004], lr: 0.001000, loss: 1.0285
2022-02-21 20:59:42 - train: epoch 0073, iter [04200, 05004], lr: 0.001000, loss: 1.1839
2022-02-21 21:00:20 - train: epoch 0073, iter [04300, 05004], lr: 0.001000, loss: 1.1284
2022-02-21 21:00:56 - train: epoch 0073, iter [04400, 05004], lr: 0.001000, loss: 1.2242
2022-02-21 21:01:34 - train: epoch 0073, iter [04500, 05004], lr: 0.001000, loss: 1.0540
2022-02-21 21:02:11 - train: epoch 0073, iter [04600, 05004], lr: 0.001000, loss: 1.2942
2022-02-21 21:02:49 - train: epoch 0073, iter [04700, 05004], lr: 0.001000, loss: 0.8783
2022-02-21 21:03:26 - train: epoch 0073, iter [04800, 05004], lr: 0.001000, loss: 1.2346
2022-02-21 21:04:04 - train: epoch 0073, iter [04900, 05004], lr: 0.001000, loss: 0.9312
2022-02-21 21:04:40 - train: epoch 0073, iter [05000, 05004], lr: 0.001000, loss: 1.1851
2022-02-21 21:04:41 - train: epoch 073, train_loss: 1.1023
2022-02-21 21:06:08 - eval: epoch: 073, acc1: 73.112%, acc5: 91.448%, test_loss: 1.0651, per_image_load_time: 0.904ms, per_image_inference_time: 0.249ms
2022-02-21 21:06:09 - until epoch: 073, best_acc1: 73.302%
2022-02-21 21:06:09 - epoch 074 lr: 0.0010000000000000002
2022-02-21 21:06:54 - train: epoch 0074, iter [00100, 05004], lr: 0.001000, loss: 1.0245
2022-02-21 21:07:32 - train: epoch 0074, iter [00200, 05004], lr: 0.001000, loss: 1.1075
2022-02-21 21:08:09 - train: epoch 0074, iter [00300, 05004], lr: 0.001000, loss: 1.1473
2022-02-21 21:08:47 - train: epoch 0074, iter [00400, 05004], lr: 0.001000, loss: 1.2425
2022-02-21 21:09:25 - train: epoch 0074, iter [00500, 05004], lr: 0.001000, loss: 1.1639
2022-02-21 21:10:02 - train: epoch 0074, iter [00600, 05004], lr: 0.001000, loss: 1.1761
2022-02-21 21:10:40 - train: epoch 0074, iter [00700, 05004], lr: 0.001000, loss: 1.1478
2022-02-21 21:11:18 - train: epoch 0074, iter [00800, 05004], lr: 0.001000, loss: 1.3372
2022-02-21 21:11:55 - train: epoch 0074, iter [00900, 05004], lr: 0.001000, loss: 1.1107
2022-02-21 21:12:33 - train: epoch 0074, iter [01000, 05004], lr: 0.001000, loss: 1.2244
2022-02-21 21:13:11 - train: epoch 0074, iter [01100, 05004], lr: 0.001000, loss: 1.1951
2022-02-21 21:13:48 - train: epoch 0074, iter [01200, 05004], lr: 0.001000, loss: 1.0335
2022-02-21 21:14:27 - train: epoch 0074, iter [01300, 05004], lr: 0.001000, loss: 1.2061
2022-02-21 21:15:04 - train: epoch 0074, iter [01400, 05004], lr: 0.001000, loss: 1.0169
2022-02-21 21:15:43 - train: epoch 0074, iter [01500, 05004], lr: 0.001000, loss: 1.0903
2022-02-21 21:16:20 - train: epoch 0074, iter [01600, 05004], lr: 0.001000, loss: 0.9019
2022-02-21 21:16:58 - train: epoch 0074, iter [01700, 05004], lr: 0.001000, loss: 1.2824
2022-02-21 21:17:35 - train: epoch 0074, iter [01800, 05004], lr: 0.001000, loss: 1.4284
2022-02-21 21:18:13 - train: epoch 0074, iter [01900, 05004], lr: 0.001000, loss: 1.2489
2022-02-21 21:18:52 - train: epoch 0074, iter [02000, 05004], lr: 0.001000, loss: 0.8282
2022-02-21 21:19:30 - train: epoch 0074, iter [02100, 05004], lr: 0.001000, loss: 1.1064
2022-02-21 21:20:07 - train: epoch 0074, iter [02200, 05004], lr: 0.001000, loss: 1.3791
2022-02-21 21:20:45 - train: epoch 0074, iter [02300, 05004], lr: 0.001000, loss: 1.1838
2022-02-21 21:21:23 - train: epoch 0074, iter [02400, 05004], lr: 0.001000, loss: 1.1579
2022-02-21 21:22:05 - train: epoch 0074, iter [02500, 05004], lr: 0.001000, loss: 0.9772
2022-02-21 21:22:45 - train: epoch 0074, iter [02600, 05004], lr: 0.001000, loss: 0.9134
2022-02-21 21:23:25 - train: epoch 0074, iter [02700, 05004], lr: 0.001000, loss: 1.0231
2022-02-21 21:24:03 - train: epoch 0074, iter [02800, 05004], lr: 0.001000, loss: 1.3250
2022-02-21 21:24:42 - train: epoch 0074, iter [02900, 05004], lr: 0.001000, loss: 1.0579
2022-02-21 21:25:21 - train: epoch 0074, iter [03000, 05004], lr: 0.001000, loss: 1.1596
2022-02-21 21:25:59 - train: epoch 0074, iter [03100, 05004], lr: 0.001000, loss: 1.0623
2022-02-21 21:26:36 - train: epoch 0074, iter [03200, 05004], lr: 0.001000, loss: 1.0250
2022-02-21 21:27:17 - train: epoch 0074, iter [03300, 05004], lr: 0.001000, loss: 1.1696
2022-02-21 21:27:56 - train: epoch 0074, iter [03400, 05004], lr: 0.001000, loss: 1.1248
2022-02-21 21:28:38 - train: epoch 0074, iter [03500, 05004], lr: 0.001000, loss: 0.9778
2022-02-21 21:29:20 - train: epoch 0074, iter [03600, 05004], lr: 0.001000, loss: 1.1659
2022-02-21 21:30:00 - train: epoch 0074, iter [03700, 05004], lr: 0.001000, loss: 1.1066
2022-02-21 21:30:38 - train: epoch 0074, iter [03800, 05004], lr: 0.001000, loss: 1.1282
2022-02-21 21:31:14 - train: epoch 0074, iter [03900, 05004], lr: 0.001000, loss: 0.9414
2022-02-21 21:31:51 - train: epoch 0074, iter [04000, 05004], lr: 0.001000, loss: 1.0632
2022-02-21 21:32:28 - train: epoch 0074, iter [04100, 05004], lr: 0.001000, loss: 1.2926
2022-02-21 21:33:07 - train: epoch 0074, iter [04200, 05004], lr: 0.001000, loss: 1.0147
2022-02-21 21:33:44 - train: epoch 0074, iter [04300, 05004], lr: 0.001000, loss: 1.1004
2022-02-21 21:34:22 - train: epoch 0074, iter [04400, 05004], lr: 0.001000, loss: 0.9996
2022-02-21 21:34:59 - train: epoch 0074, iter [04500, 05004], lr: 0.001000, loss: 0.9139
2022-02-21 21:35:36 - train: epoch 0074, iter [04600, 05004], lr: 0.001000, loss: 1.2094
2022-02-21 21:36:13 - train: epoch 0074, iter [04700, 05004], lr: 0.001000, loss: 1.1914
2022-02-21 21:36:51 - train: epoch 0074, iter [04800, 05004], lr: 0.001000, loss: 1.0610
2022-02-21 21:37:29 - train: epoch 0074, iter [04900, 05004], lr: 0.001000, loss: 1.3005
2022-02-21 21:38:04 - train: epoch 0074, iter [05000, 05004], lr: 0.001000, loss: 1.1184
2022-02-21 21:38:05 - train: epoch 074, train_loss: 1.0971
2022-02-21 21:39:29 - eval: epoch: 074, acc1: 73.268%, acc5: 91.446%, test_loss: 1.0636, per_image_load_time: 1.142ms, per_image_inference_time: 0.256ms
2022-02-21 21:39:30 - until epoch: 074, best_acc1: 73.302%
2022-02-21 21:39:30 - epoch 075 lr: 0.0010000000000000002
2022-02-21 21:40:14 - train: epoch 0075, iter [00100, 05004], lr: 0.001000, loss: 1.1855
2022-02-21 21:40:52 - train: epoch 0075, iter [00200, 05004], lr: 0.001000, loss: 1.0967
2022-02-21 21:41:30 - train: epoch 0075, iter [00300, 05004], lr: 0.001000, loss: 1.0237
2022-02-21 21:42:07 - train: epoch 0075, iter [00400, 05004], lr: 0.001000, loss: 1.1141
2022-02-21 21:42:44 - train: epoch 0075, iter [00500, 05004], lr: 0.001000, loss: 0.9204
2022-02-21 21:43:22 - train: epoch 0075, iter [00600, 05004], lr: 0.001000, loss: 0.9976
2022-02-21 21:43:58 - train: epoch 0075, iter [00700, 05004], lr: 0.001000, loss: 1.1824
2022-02-21 21:44:35 - train: epoch 0075, iter [00800, 05004], lr: 0.001000, loss: 1.2463
2022-02-21 21:45:14 - train: epoch 0075, iter [00900, 05004], lr: 0.001000, loss: 1.2943
2022-02-21 21:45:51 - train: epoch 0075, iter [01000, 05004], lr: 0.001000, loss: 0.9002
2022-02-21 21:46:28 - train: epoch 0075, iter [01100, 05004], lr: 0.001000, loss: 1.1643
2022-02-21 21:47:06 - train: epoch 0075, iter [01200, 05004], lr: 0.001000, loss: 1.1165
2022-02-21 21:47:44 - train: epoch 0075, iter [01300, 05004], lr: 0.001000, loss: 0.9532
2022-02-21 21:48:18 - train: epoch 0075, iter [01400, 05004], lr: 0.001000, loss: 1.0490
2022-02-21 21:48:54 - train: epoch 0075, iter [01500, 05004], lr: 0.001000, loss: 1.2441
2022-02-21 21:49:32 - train: epoch 0075, iter [01600, 05004], lr: 0.001000, loss: 0.8730
2022-02-21 21:50:10 - train: epoch 0075, iter [01700, 05004], lr: 0.001000, loss: 1.0112
2022-02-21 21:50:48 - train: epoch 0075, iter [01800, 05004], lr: 0.001000, loss: 1.1135
2022-02-21 21:51:25 - train: epoch 0075, iter [01900, 05004], lr: 0.001000, loss: 0.9193
2022-02-21 21:52:03 - train: epoch 0075, iter [02000, 05004], lr: 0.001000, loss: 1.1907
2022-02-21 21:52:40 - train: epoch 0075, iter [02100, 05004], lr: 0.001000, loss: 0.9875
2022-02-21 21:53:19 - train: epoch 0075, iter [02200, 05004], lr: 0.001000, loss: 1.1637
2022-02-21 21:53:55 - train: epoch 0075, iter [02300, 05004], lr: 0.001000, loss: 1.0764
2022-02-21 21:54:34 - train: epoch 0075, iter [02400, 05004], lr: 0.001000, loss: 1.1239
2022-02-21 21:55:12 - train: epoch 0075, iter [02500, 05004], lr: 0.001000, loss: 1.1438
2022-02-21 21:55:51 - train: epoch 0075, iter [02600, 05004], lr: 0.001000, loss: 1.0671
2022-02-21 21:56:30 - train: epoch 0075, iter [02700, 05004], lr: 0.001000, loss: 0.9081
2022-02-21 21:57:08 - train: epoch 0075, iter [02800, 05004], lr: 0.001000, loss: 1.0213
2022-02-21 21:57:45 - train: epoch 0075, iter [02900, 05004], lr: 0.001000, loss: 1.1772
2022-02-21 21:58:24 - train: epoch 0075, iter [03000, 05004], lr: 0.001000, loss: 1.2548
2022-02-21 21:59:01 - train: epoch 0075, iter [03100, 05004], lr: 0.001000, loss: 1.1635
2022-02-21 21:59:39 - train: epoch 0075, iter [03200, 05004], lr: 0.001000, loss: 1.0951
2022-02-21 22:00:16 - train: epoch 0075, iter [03300, 05004], lr: 0.001000, loss: 1.2124
2022-02-21 22:00:53 - train: epoch 0075, iter [03400, 05004], lr: 0.001000, loss: 0.8435
2022-02-21 22:01:30 - train: epoch 0075, iter [03500, 05004], lr: 0.001000, loss: 0.9845
2022-02-21 22:02:08 - train: epoch 0075, iter [03600, 05004], lr: 0.001000, loss: 1.1255
2022-02-21 22:02:45 - train: epoch 0075, iter [03700, 05004], lr: 0.001000, loss: 1.1552
2022-02-21 22:03:23 - train: epoch 0075, iter [03800, 05004], lr: 0.001000, loss: 1.0946
2022-02-21 22:04:01 - train: epoch 0075, iter [03900, 05004], lr: 0.001000, loss: 1.2892
2022-02-21 22:04:39 - train: epoch 0075, iter [04000, 05004], lr: 0.001000, loss: 0.9550
2022-02-21 22:05:17 - train: epoch 0075, iter [04100, 05004], lr: 0.001000, loss: 0.8328
2022-02-21 22:05:54 - train: epoch 0075, iter [04200, 05004], lr: 0.001000, loss: 1.2216
2022-02-21 22:06:31 - train: epoch 0075, iter [04300, 05004], lr: 0.001000, loss: 1.2371
2022-02-21 22:07:10 - train: epoch 0075, iter [04400, 05004], lr: 0.001000, loss: 0.9469
2022-02-21 22:07:48 - train: epoch 0075, iter [04500, 05004], lr: 0.001000, loss: 1.1573
2022-02-21 22:08:26 - train: epoch 0075, iter [04600, 05004], lr: 0.001000, loss: 0.9342
2022-02-21 22:09:04 - train: epoch 0075, iter [04700, 05004], lr: 0.001000, loss: 1.1957
2022-02-21 22:09:41 - train: epoch 0075, iter [04800, 05004], lr: 0.001000, loss: 1.0972
2022-02-21 22:10:19 - train: epoch 0075, iter [04900, 05004], lr: 0.001000, loss: 0.9131
2022-02-21 22:10:55 - train: epoch 0075, iter [05000, 05004], lr: 0.001000, loss: 1.2166
2022-02-21 22:10:56 - train: epoch 075, train_loss: 1.0945
2022-02-21 22:12:21 - eval: epoch: 075, acc1: 73.338%, acc5: 91.500%, test_loss: 1.0628, per_image_load_time: 0.975ms, per_image_inference_time: 0.269ms
2022-02-21 22:12:22 - until epoch: 075, best_acc1: 73.338%
2022-02-21 22:12:22 - epoch 076 lr: 0.0010000000000000002
2022-02-21 22:13:05 - train: epoch 0076, iter [00100, 05004], lr: 0.001000, loss: 0.9251
2022-02-21 22:13:43 - train: epoch 0076, iter [00200, 05004], lr: 0.001000, loss: 1.1192
2022-02-21 22:14:22 - train: epoch 0076, iter [00300, 05004], lr: 0.001000, loss: 1.2013
2022-02-21 22:14:59 - train: epoch 0076, iter [00400, 05004], lr: 0.001000, loss: 1.2068
2022-02-21 22:15:38 - train: epoch 0076, iter [00500, 05004], lr: 0.001000, loss: 1.0978
2022-02-21 22:16:15 - train: epoch 0076, iter [00600, 05004], lr: 0.001000, loss: 1.0368
2022-02-21 22:16:54 - train: epoch 0076, iter [00700, 05004], lr: 0.001000, loss: 1.1059
2022-02-21 22:17:33 - train: epoch 0076, iter [00800, 05004], lr: 0.001000, loss: 1.0746
2022-02-21 22:18:09 - train: epoch 0076, iter [00900, 05004], lr: 0.001000, loss: 1.0019
2022-02-21 22:18:48 - train: epoch 0076, iter [01000, 05004], lr: 0.001000, loss: 0.9390
2022-02-21 22:19:25 - train: epoch 0076, iter [01100, 05004], lr: 0.001000, loss: 0.9585
2022-02-21 22:20:02 - train: epoch 0076, iter [01200, 05004], lr: 0.001000, loss: 1.0821
2022-02-21 22:20:41 - train: epoch 0076, iter [01300, 05004], lr: 0.001000, loss: 1.1658
2022-02-21 22:21:19 - train: epoch 0076, iter [01400, 05004], lr: 0.001000, loss: 1.0296
2022-02-21 22:21:57 - train: epoch 0076, iter [01500, 05004], lr: 0.001000, loss: 1.0175
2022-02-21 22:22:35 - train: epoch 0076, iter [01600, 05004], lr: 0.001000, loss: 1.0506
2022-02-21 22:23:13 - train: epoch 0076, iter [01700, 05004], lr: 0.001000, loss: 1.0294
2022-02-21 22:23:52 - train: epoch 0076, iter [01800, 05004], lr: 0.001000, loss: 0.8797
2022-02-21 22:24:30 - train: epoch 0076, iter [01900, 05004], lr: 0.001000, loss: 1.1928
2022-02-21 22:25:09 - train: epoch 0076, iter [02000, 05004], lr: 0.001000, loss: 1.0679
2022-02-21 22:25:46 - train: epoch 0076, iter [02100, 05004], lr: 0.001000, loss: 1.1521
2022-02-21 22:26:25 - train: epoch 0076, iter [02200, 05004], lr: 0.001000, loss: 1.2177
2022-02-21 22:27:03 - train: epoch 0076, iter [02300, 05004], lr: 0.001000, loss: 1.0405
2022-02-21 22:27:43 - train: epoch 0076, iter [02400, 05004], lr: 0.001000, loss: 1.2486
2022-02-21 22:28:20 - train: epoch 0076, iter [02500, 05004], lr: 0.001000, loss: 0.9685
2022-02-21 22:28:57 - train: epoch 0076, iter [02600, 05004], lr: 0.001000, loss: 1.2202
2022-02-21 22:29:35 - train: epoch 0076, iter [02700, 05004], lr: 0.001000, loss: 1.1922
2022-02-21 22:30:14 - train: epoch 0076, iter [02800, 05004], lr: 0.001000, loss: 1.0129
2022-02-21 22:30:52 - train: epoch 0076, iter [02900, 05004], lr: 0.001000, loss: 1.0769
2022-02-21 22:31:30 - train: epoch 0076, iter [03000, 05004], lr: 0.001000, loss: 0.9433
2022-02-21 22:32:09 - train: epoch 0076, iter [03100, 05004], lr: 0.001000, loss: 1.1587
2022-02-21 22:32:48 - train: epoch 0076, iter [03200, 05004], lr: 0.001000, loss: 1.2066
2022-02-21 22:33:28 - train: epoch 0076, iter [03300, 05004], lr: 0.001000, loss: 1.1061
2022-02-21 22:34:06 - train: epoch 0076, iter [03400, 05004], lr: 0.001000, loss: 1.1779
2022-02-21 22:34:45 - train: epoch 0076, iter [03500, 05004], lr: 0.001000, loss: 0.9827
2022-02-21 22:35:24 - train: epoch 0076, iter [03600, 05004], lr: 0.001000, loss: 1.0654
2022-02-21 22:36:02 - train: epoch 0076, iter [03700, 05004], lr: 0.001000, loss: 0.9735
2022-02-21 22:36:42 - train: epoch 0076, iter [03800, 05004], lr: 0.001000, loss: 0.8957
2022-02-21 22:37:20 - train: epoch 0076, iter [03900, 05004], lr: 0.001000, loss: 0.9899
2022-02-21 22:37:59 - train: epoch 0076, iter [04000, 05004], lr: 0.001000, loss: 1.0519
2022-02-21 22:38:36 - train: epoch 0076, iter [04100, 05004], lr: 0.001000, loss: 1.0077
2022-02-21 22:39:15 - train: epoch 0076, iter [04200, 05004], lr: 0.001000, loss: 1.2704
2022-02-21 22:39:54 - train: epoch 0076, iter [04300, 05004], lr: 0.001000, loss: 1.1249
2022-02-21 22:40:33 - train: epoch 0076, iter [04400, 05004], lr: 0.001000, loss: 1.0293
2022-02-21 22:41:11 - train: epoch 0076, iter [04500, 05004], lr: 0.001000, loss: 1.0480
2022-02-21 22:41:50 - train: epoch 0076, iter [04600, 05004], lr: 0.001000, loss: 1.0182
2022-02-21 22:42:30 - train: epoch 0076, iter [04700, 05004], lr: 0.001000, loss: 1.1791
2022-02-21 22:43:07 - train: epoch 0076, iter [04800, 05004], lr: 0.001000, loss: 0.9621
2022-02-21 22:43:48 - train: epoch 0076, iter [04900, 05004], lr: 0.001000, loss: 1.1014
2022-02-21 22:44:25 - train: epoch 0076, iter [05000, 05004], lr: 0.001000, loss: 1.1096
2022-02-21 22:44:26 - train: epoch 076, train_loss: 1.0899
2022-02-21 22:45:51 - eval: epoch: 076, acc1: 73.264%, acc5: 91.506%, test_loss: 1.0627, per_image_load_time: 1.203ms, per_image_inference_time: 0.290ms
2022-02-21 22:45:51 - until epoch: 076, best_acc1: 73.338%
2022-02-21 22:45:51 - epoch 077 lr: 0.0010000000000000002
2022-02-21 22:46:35 - train: epoch 0077, iter [00100, 05004], lr: 0.001000, loss: 1.1406
2022-02-21 22:47:14 - train: epoch 0077, iter [00200, 05004], lr: 0.001000, loss: 1.1311
2022-02-21 22:47:52 - train: epoch 0077, iter [00300, 05004], lr: 0.001000, loss: 0.9360
2022-02-21 22:48:32 - train: epoch 0077, iter [00400, 05004], lr: 0.001000, loss: 1.2589
2022-02-21 22:49:10 - train: epoch 0077, iter [00500, 05004], lr: 0.001000, loss: 0.9377
2022-02-21 22:49:49 - train: epoch 0077, iter [00600, 05004], lr: 0.001000, loss: 0.8937
2022-02-21 22:50:28 - train: epoch 0077, iter [00700, 05004], lr: 0.001000, loss: 1.0849
2022-02-21 22:51:06 - train: epoch 0077, iter [00800, 05004], lr: 0.001000, loss: 1.2306
2022-02-21 22:51:45 - train: epoch 0077, iter [00900, 05004], lr: 0.001000, loss: 1.1850
2022-02-21 22:52:24 - train: epoch 0077, iter [01000, 05004], lr: 0.001000, loss: 0.8698
2022-02-21 22:53:03 - train: epoch 0077, iter [01100, 05004], lr: 0.001000, loss: 1.0530
2022-02-21 22:53:42 - train: epoch 0077, iter [01200, 05004], lr: 0.001000, loss: 1.1362
2022-02-21 22:54:21 - train: epoch 0077, iter [01300, 05004], lr: 0.001000, loss: 0.8891
2022-02-21 22:54:59 - train: epoch 0077, iter [01400, 05004], lr: 0.001000, loss: 1.2431
2022-02-21 22:55:38 - train: epoch 0077, iter [01500, 05004], lr: 0.001000, loss: 0.9600
2022-02-21 22:56:17 - train: epoch 0077, iter [01600, 05004], lr: 0.001000, loss: 1.1313
2022-02-21 22:56:56 - train: epoch 0077, iter [01700, 05004], lr: 0.001000, loss: 1.3017
2022-02-21 22:57:34 - train: epoch 0077, iter [01800, 05004], lr: 0.001000, loss: 1.0077
2022-02-21 22:58:14 - train: epoch 0077, iter [01900, 05004], lr: 0.001000, loss: 1.0599
2022-02-21 22:58:52 - train: epoch 0077, iter [02000, 05004], lr: 0.001000, loss: 0.9923
2022-02-21 22:59:31 - train: epoch 0077, iter [02100, 05004], lr: 0.001000, loss: 1.0894
2022-02-21 23:00:10 - train: epoch 0077, iter [02200, 05004], lr: 0.001000, loss: 1.1212
2022-02-21 23:00:48 - train: epoch 0077, iter [02300, 05004], lr: 0.001000, loss: 1.2702
2022-02-21 23:01:26 - train: epoch 0077, iter [02400, 05004], lr: 0.001000, loss: 1.0508
2022-02-21 23:02:05 - train: epoch 0077, iter [02500, 05004], lr: 0.001000, loss: 1.3188
2022-02-21 23:02:43 - train: epoch 0077, iter [02600, 05004], lr: 0.001000, loss: 0.8232
2022-02-21 23:03:22 - train: epoch 0077, iter [02700, 05004], lr: 0.001000, loss: 1.0567
2022-02-21 23:03:59 - train: epoch 0077, iter [02800, 05004], lr: 0.001000, loss: 1.2021
2022-02-21 23:04:37 - train: epoch 0077, iter [02900, 05004], lr: 0.001000, loss: 1.4163
2022-02-21 23:05:15 - train: epoch 0077, iter [03000, 05004], lr: 0.001000, loss: 0.9851
2022-02-21 23:05:53 - train: epoch 0077, iter [03100, 05004], lr: 0.001000, loss: 1.0373
2022-02-21 23:06:32 - train: epoch 0077, iter [03200, 05004], lr: 0.001000, loss: 1.1711
2022-02-21 23:07:10 - train: epoch 0077, iter [03300, 05004], lr: 0.001000, loss: 1.0222
2022-02-21 23:07:47 - train: epoch 0077, iter [03400, 05004], lr: 0.001000, loss: 1.2895
2022-02-21 23:08:27 - train: epoch 0077, iter [03500, 05004], lr: 0.001000, loss: 1.0064
2022-02-21 23:09:05 - train: epoch 0077, iter [03600, 05004], lr: 0.001000, loss: 1.0533
2022-02-21 23:09:43 - train: epoch 0077, iter [03700, 05004], lr: 0.001000, loss: 1.1327
2022-02-21 23:10:21 - train: epoch 0077, iter [03800, 05004], lr: 0.001000, loss: 1.1022
2022-02-21 23:10:59 - train: epoch 0077, iter [03900, 05004], lr: 0.001000, loss: 1.1492
2022-02-21 23:11:37 - train: epoch 0077, iter [04000, 05004], lr: 0.001000, loss: 1.0718
2022-02-21 23:12:14 - train: epoch 0077, iter [04100, 05004], lr: 0.001000, loss: 1.2195
2022-02-21 23:12:52 - train: epoch 0077, iter [04200, 05004], lr: 0.001000, loss: 1.1771
2022-02-21 23:13:29 - train: epoch 0077, iter [04300, 05004], lr: 0.001000, loss: 0.9839
2022-02-21 23:14:08 - train: epoch 0077, iter [04400, 05004], lr: 0.001000, loss: 1.0508
2022-02-21 23:14:46 - train: epoch 0077, iter [04500, 05004], lr: 0.001000, loss: 1.1957
2022-02-21 23:15:23 - train: epoch 0077, iter [04600, 05004], lr: 0.001000, loss: 1.0382
2022-02-21 23:16:01 - train: epoch 0077, iter [04700, 05004], lr: 0.001000, loss: 0.8457
2022-02-21 23:16:39 - train: epoch 0077, iter [04800, 05004], lr: 0.001000, loss: 1.0981
2022-02-21 23:17:16 - train: epoch 0077, iter [04900, 05004], lr: 0.001000, loss: 1.2543
2022-02-21 23:17:52 - train: epoch 0077, iter [05000, 05004], lr: 0.001000, loss: 1.3203
2022-02-21 23:17:54 - train: epoch 077, train_loss: 1.0848
2022-02-21 23:19:17 - eval: epoch: 077, acc1: 73.412%, acc5: 91.498%, test_loss: 1.0637, per_image_load_time: 1.714ms, per_image_inference_time: 0.278ms
2022-02-21 23:19:18 - until epoch: 077, best_acc1: 73.412%
2022-02-21 23:19:18 - epoch 078 lr: 0.0010000000000000002
2022-02-21 23:20:01 - train: epoch 0078, iter [00100, 05004], lr: 0.001000, loss: 1.0707
2022-02-21 23:20:39 - train: epoch 0078, iter [00200, 05004], lr: 0.001000, loss: 1.2466
2022-02-21 23:21:16 - train: epoch 0078, iter [00300, 05004], lr: 0.001000, loss: 1.1722
2022-02-21 23:21:55 - train: epoch 0078, iter [00400, 05004], lr: 0.001000, loss: 1.1539
2022-02-21 23:22:33 - train: epoch 0078, iter [00500, 05004], lr: 0.001000, loss: 1.0110
2022-02-21 23:23:11 - train: epoch 0078, iter [00600, 05004], lr: 0.001000, loss: 1.0381
2022-02-21 23:23:49 - train: epoch 0078, iter [00700, 05004], lr: 0.001000, loss: 1.2030
2022-02-21 23:24:27 - train: epoch 0078, iter [00800, 05004], lr: 0.001000, loss: 1.2834
2022-02-21 23:25:05 - train: epoch 0078, iter [00900, 05004], lr: 0.001000, loss: 1.0820
2022-02-21 23:25:43 - train: epoch 0078, iter [01000, 05004], lr: 0.001000, loss: 1.1648
2022-02-21 23:26:20 - train: epoch 0078, iter [01100, 05004], lr: 0.001000, loss: 0.8996
2022-02-21 23:26:58 - train: epoch 0078, iter [01200, 05004], lr: 0.001000, loss: 0.8996
2022-02-21 23:27:37 - train: epoch 0078, iter [01300, 05004], lr: 0.001000, loss: 1.1489
2022-02-21 23:28:14 - train: epoch 0078, iter [01400, 05004], lr: 0.001000, loss: 1.0002
2022-02-21 23:28:51 - train: epoch 0078, iter [01500, 05004], lr: 0.001000, loss: 0.9604
2022-02-21 23:29:29 - train: epoch 0078, iter [01600, 05004], lr: 0.001000, loss: 1.2135
2022-02-21 23:30:07 - train: epoch 0078, iter [01700, 05004], lr: 0.001000, loss: 1.0304
2022-02-21 23:30:47 - train: epoch 0078, iter [01800, 05004], lr: 0.001000, loss: 1.0591
2022-02-21 23:31:23 - train: epoch 0078, iter [01900, 05004], lr: 0.001000, loss: 0.9308
2022-02-21 23:32:02 - train: epoch 0078, iter [02000, 05004], lr: 0.001000, loss: 0.9128
2022-02-21 23:32:39 - train: epoch 0078, iter [02100, 05004], lr: 0.001000, loss: 1.3150
2022-02-21 23:33:18 - train: epoch 0078, iter [02200, 05004], lr: 0.001000, loss: 1.0639
2022-02-21 23:33:56 - train: epoch 0078, iter [02300, 05004], lr: 0.001000, loss: 1.1695
2022-02-21 23:34:34 - train: epoch 0078, iter [02400, 05004], lr: 0.001000, loss: 1.0715
2022-02-21 23:35:12 - train: epoch 0078, iter [02500, 05004], lr: 0.001000, loss: 1.0394
2022-02-21 23:35:49 - train: epoch 0078, iter [02600, 05004], lr: 0.001000, loss: 1.0088
2022-02-21 23:36:28 - train: epoch 0078, iter [02700, 05004], lr: 0.001000, loss: 1.0513
2022-02-21 23:37:05 - train: epoch 0078, iter [02800, 05004], lr: 0.001000, loss: 1.1320
2022-02-21 23:37:45 - train: epoch 0078, iter [02900, 05004], lr: 0.001000, loss: 1.0063
2022-02-21 23:38:21 - train: epoch 0078, iter [03000, 05004], lr: 0.001000, loss: 1.0627
2022-02-21 23:38:59 - train: epoch 0078, iter [03100, 05004], lr: 0.001000, loss: 1.2014
2022-02-21 23:39:35 - train: epoch 0078, iter [03200, 05004], lr: 0.001000, loss: 1.0889
2022-02-21 23:40:13 - train: epoch 0078, iter [03300, 05004], lr: 0.001000, loss: 1.1616
2022-02-21 23:40:50 - train: epoch 0078, iter [03400, 05004], lr: 0.001000, loss: 1.0781
2022-02-21 23:41:28 - train: epoch 0078, iter [03500, 05004], lr: 0.001000, loss: 1.0919
2022-02-21 23:42:04 - train: epoch 0078, iter [03600, 05004], lr: 0.001000, loss: 1.0873
2022-02-21 23:42:41 - train: epoch 0078, iter [03700, 05004], lr: 0.001000, loss: 0.9667
2022-02-21 23:43:18 - train: epoch 0078, iter [03800, 05004], lr: 0.001000, loss: 1.1247
2022-02-21 23:43:56 - train: epoch 0078, iter [03900, 05004], lr: 0.001000, loss: 1.1127
2022-02-21 23:44:33 - train: epoch 0078, iter [04000, 05004], lr: 0.001000, loss: 1.0086
2022-02-21 23:45:10 - train: epoch 0078, iter [04100, 05004], lr: 0.001000, loss: 1.1874
2022-02-21 23:45:47 - train: epoch 0078, iter [04200, 05004], lr: 0.001000, loss: 1.2449
2022-02-21 23:46:24 - train: epoch 0078, iter [04300, 05004], lr: 0.001000, loss: 1.1861
2022-02-21 23:47:02 - train: epoch 0078, iter [04400, 05004], lr: 0.001000, loss: 1.0338
2022-02-21 23:47:39 - train: epoch 0078, iter [04500, 05004], lr: 0.001000, loss: 1.2138
2022-02-21 23:48:18 - train: epoch 0078, iter [04600, 05004], lr: 0.001000, loss: 0.9685
2022-02-21 23:48:55 - train: epoch 0078, iter [04700, 05004], lr: 0.001000, loss: 1.1172
2022-02-21 23:49:33 - train: epoch 0078, iter [04800, 05004], lr: 0.001000, loss: 1.2500
2022-02-21 23:50:12 - train: epoch 0078, iter [04900, 05004], lr: 0.001000, loss: 1.0888
2022-02-21 23:50:47 - train: epoch 0078, iter [05000, 05004], lr: 0.001000, loss: 1.1116
2022-02-21 23:50:48 - train: epoch 078, train_loss: 1.0790
2022-02-21 23:52:12 - eval: epoch: 078, acc1: 73.178%, acc5: 91.428%, test_loss: 1.0632, per_image_load_time: 0.924ms, per_image_inference_time: 0.254ms
2022-02-21 23:52:12 - until epoch: 078, best_acc1: 73.412%
2022-02-21 23:52:12 - epoch 079 lr: 0.0010000000000000002
2022-02-21 23:52:55 - train: epoch 0079, iter [00100, 05004], lr: 0.001000, loss: 1.0106
2022-02-21 23:53:33 - train: epoch 0079, iter [00200, 05004], lr: 0.001000, loss: 0.9549
2022-02-21 23:54:11 - train: epoch 0079, iter [00300, 05004], lr: 0.001000, loss: 1.1370
2022-02-21 23:54:49 - train: epoch 0079, iter [00400, 05004], lr: 0.001000, loss: 1.1453
2022-02-21 23:55:26 - train: epoch 0079, iter [00500, 05004], lr: 0.001000, loss: 1.1416
2022-02-21 23:56:04 - train: epoch 0079, iter [00600, 05004], lr: 0.001000, loss: 0.9626
2022-02-21 23:56:41 - train: epoch 0079, iter [00700, 05004], lr: 0.001000, loss: 1.0256
2022-02-21 23:57:17 - train: epoch 0079, iter [00800, 05004], lr: 0.001000, loss: 1.1248
2022-02-21 23:57:53 - train: epoch 0079, iter [00900, 05004], lr: 0.001000, loss: 1.0596
2022-02-21 23:58:33 - train: epoch 0079, iter [01000, 05004], lr: 0.001000, loss: 1.0288
2022-02-21 23:59:12 - train: epoch 0079, iter [01100, 05004], lr: 0.001000, loss: 1.2140
2022-02-21 23:59:51 - train: epoch 0079, iter [01200, 05004], lr: 0.001000, loss: 1.3382
2022-02-22 00:00:29 - train: epoch 0079, iter [01300, 05004], lr: 0.001000, loss: 0.9531
2022-02-22 00:01:06 - train: epoch 0079, iter [01400, 05004], lr: 0.001000, loss: 1.0263
2022-02-22 00:01:45 - train: epoch 0079, iter [01500, 05004], lr: 0.001000, loss: 1.0008
2022-02-22 00:02:22 - train: epoch 0079, iter [01600, 05004], lr: 0.001000, loss: 0.9702
2022-02-22 00:03:01 - train: epoch 0079, iter [01700, 05004], lr: 0.001000, loss: 1.0282
2022-02-22 00:03:38 - train: epoch 0079, iter [01800, 05004], lr: 0.001000, loss: 1.0229
2022-02-22 00:04:16 - train: epoch 0079, iter [01900, 05004], lr: 0.001000, loss: 1.1949
2022-02-22 00:04:52 - train: epoch 0079, iter [02000, 05004], lr: 0.001000, loss: 1.2059
2022-02-22 00:05:29 - train: epoch 0079, iter [02100, 05004], lr: 0.001000, loss: 0.9433
2022-02-22 00:06:07 - train: epoch 0079, iter [02200, 05004], lr: 0.001000, loss: 1.1142
2022-02-22 00:06:45 - train: epoch 0079, iter [02300, 05004], lr: 0.001000, loss: 0.9790
2022-02-22 00:07:21 - train: epoch 0079, iter [02400, 05004], lr: 0.001000, loss: 1.1056
2022-02-22 00:07:59 - train: epoch 0079, iter [02500, 05004], lr: 0.001000, loss: 1.0632
2022-02-22 00:08:36 - train: epoch 0079, iter [02600, 05004], lr: 0.001000, loss: 1.0571
2022-02-22 00:09:13 - train: epoch 0079, iter [02700, 05004], lr: 0.001000, loss: 0.9151
2022-02-22 00:09:50 - train: epoch 0079, iter [02800, 05004], lr: 0.001000, loss: 0.9609
2022-02-22 00:10:28 - train: epoch 0079, iter [02900, 05004], lr: 0.001000, loss: 0.9601
2022-02-22 00:11:05 - train: epoch 0079, iter [03000, 05004], lr: 0.001000, loss: 1.1515
2022-02-22 00:11:42 - train: epoch 0079, iter [03100, 05004], lr: 0.001000, loss: 1.0681
2022-02-22 00:12:19 - train: epoch 0079, iter [03200, 05004], lr: 0.001000, loss: 1.2924
2022-02-22 00:12:56 - train: epoch 0079, iter [03300, 05004], lr: 0.001000, loss: 1.0137
2022-02-22 00:13:35 - train: epoch 0079, iter [03400, 05004], lr: 0.001000, loss: 0.9451
2022-02-22 00:14:12 - train: epoch 0079, iter [03500, 05004], lr: 0.001000, loss: 1.2558
2022-02-22 00:14:50 - train: epoch 0079, iter [03600, 05004], lr: 0.001000, loss: 0.9971
2022-02-22 00:15:27 - train: epoch 0079, iter [03700, 05004], lr: 0.001000, loss: 0.9359
2022-02-22 00:16:05 - train: epoch 0079, iter [03800, 05004], lr: 0.001000, loss: 1.1133
2022-02-22 00:16:42 - train: epoch 0079, iter [03900, 05004], lr: 0.001000, loss: 1.0006
2022-02-22 00:17:19 - train: epoch 0079, iter [04000, 05004], lr: 0.001000, loss: 0.8952
2022-02-22 00:17:57 - train: epoch 0079, iter [04100, 05004], lr: 0.001000, loss: 1.1856
2022-02-22 00:18:34 - train: epoch 0079, iter [04200, 05004], lr: 0.001000, loss: 0.9556
2022-02-22 00:19:12 - train: epoch 0079, iter [04300, 05004], lr: 0.001000, loss: 0.8881
2022-02-22 00:19:48 - train: epoch 0079, iter [04400, 05004], lr: 0.001000, loss: 1.2629
2022-02-22 00:20:26 - train: epoch 0079, iter [04500, 05004], lr: 0.001000, loss: 1.1800
2022-02-22 00:21:04 - train: epoch 0079, iter [04600, 05004], lr: 0.001000, loss: 1.2246
2022-02-22 00:21:41 - train: epoch 0079, iter [04700, 05004], lr: 0.001000, loss: 1.0225
2022-02-22 00:22:19 - train: epoch 0079, iter [04800, 05004], lr: 0.001000, loss: 1.1753
2022-02-22 00:22:57 - train: epoch 0079, iter [04900, 05004], lr: 0.001000, loss: 1.2133
2022-02-22 00:23:33 - train: epoch 0079, iter [05000, 05004], lr: 0.001000, loss: 0.9749
2022-02-22 00:23:34 - train: epoch 079, train_loss: 1.0776
2022-02-22 00:24:57 - eval: epoch: 079, acc1: 73.336%, acc5: 91.522%, test_loss: 1.0612, per_image_load_time: 2.509ms, per_image_inference_time: 0.299ms
2022-02-22 00:24:58 - until epoch: 079, best_acc1: 73.412%
2022-02-22 00:24:58 - epoch 080 lr: 0.0010000000000000002
2022-02-22 00:25:41 - train: epoch 0080, iter [00100, 05004], lr: 0.001000, loss: 0.9337
2022-02-22 00:26:18 - train: epoch 0080, iter [00200, 05004], lr: 0.001000, loss: 1.0119
2022-02-22 00:26:56 - train: epoch 0080, iter [00300, 05004], lr: 0.001000, loss: 1.1682
2022-02-22 00:27:34 - train: epoch 0080, iter [00400, 05004], lr: 0.001000, loss: 0.9072
2022-02-22 00:28:11 - train: epoch 0080, iter [00500, 05004], lr: 0.001000, loss: 1.1463
2022-02-22 00:28:49 - train: epoch 0080, iter [00600, 05004], lr: 0.001000, loss: 0.9678
2022-02-22 00:29:28 - train: epoch 0080, iter [00700, 05004], lr: 0.001000, loss: 0.9986
2022-02-22 00:30:05 - train: epoch 0080, iter [00800, 05004], lr: 0.001000, loss: 0.9452
2022-02-22 00:30:42 - train: epoch 0080, iter [00900, 05004], lr: 0.001000, loss: 1.0885
2022-02-22 00:31:20 - train: epoch 0080, iter [01000, 05004], lr: 0.001000, loss: 1.0109
2022-02-22 00:31:58 - train: epoch 0080, iter [01100, 05004], lr: 0.001000, loss: 1.1095
2022-02-22 00:32:35 - train: epoch 0080, iter [01200, 05004], lr: 0.001000, loss: 1.0529
2022-02-22 00:33:13 - train: epoch 0080, iter [01300, 05004], lr: 0.001000, loss: 0.9959
2022-02-22 00:33:53 - train: epoch 0080, iter [01400, 05004], lr: 0.001000, loss: 1.0577
2022-02-22 00:34:30 - train: epoch 0080, iter [01500, 05004], lr: 0.001000, loss: 0.9674
2022-02-22 00:35:08 - train: epoch 0080, iter [01600, 05004], lr: 0.001000, loss: 0.9489
2022-02-22 00:35:45 - train: epoch 0080, iter [01700, 05004], lr: 0.001000, loss: 1.1377
2022-02-22 00:36:23 - train: epoch 0080, iter [01800, 05004], lr: 0.001000, loss: 1.1647
2022-02-22 00:37:00 - train: epoch 0080, iter [01900, 05004], lr: 0.001000, loss: 1.1066
2022-02-22 00:37:39 - train: epoch 0080, iter [02000, 05004], lr: 0.001000, loss: 1.2009
2022-02-22 00:38:17 - train: epoch 0080, iter [02100, 05004], lr: 0.001000, loss: 1.0795
2022-02-22 00:38:55 - train: epoch 0080, iter [02200, 05004], lr: 0.001000, loss: 1.1436
2022-02-22 00:39:32 - train: epoch 0080, iter [02300, 05004], lr: 0.001000, loss: 0.9927
2022-02-22 00:40:10 - train: epoch 0080, iter [02400, 05004], lr: 0.001000, loss: 1.0124
2022-02-22 00:40:48 - train: epoch 0080, iter [02500, 05004], lr: 0.001000, loss: 1.0163
2022-02-22 00:41:26 - train: epoch 0080, iter [02600, 05004], lr: 0.001000, loss: 0.9534
2022-02-22 00:42:04 - train: epoch 0080, iter [02700, 05004], lr: 0.001000, loss: 1.2175
2022-02-22 00:42:43 - train: epoch 0080, iter [02800, 05004], lr: 0.001000, loss: 1.1648
2022-02-22 00:43:20 - train: epoch 0080, iter [02900, 05004], lr: 0.001000, loss: 0.9436
2022-02-22 00:43:59 - train: epoch 0080, iter [03000, 05004], lr: 0.001000, loss: 0.9949
2022-02-22 00:44:37 - train: epoch 0080, iter [03100, 05004], lr: 0.001000, loss: 1.2476
2022-02-22 00:45:15 - train: epoch 0080, iter [03200, 05004], lr: 0.001000, loss: 0.7379
2022-02-22 00:45:53 - train: epoch 0080, iter [03300, 05004], lr: 0.001000, loss: 1.0113
2022-02-22 00:46:29 - train: epoch 0080, iter [03400, 05004], lr: 0.001000, loss: 1.0242
2022-02-22 00:47:08 - train: epoch 0080, iter [03500, 05004], lr: 0.001000, loss: 0.8586
2022-02-22 00:47:45 - train: epoch 0080, iter [03600, 05004], lr: 0.001000, loss: 1.0471
2022-02-22 00:48:23 - train: epoch 0080, iter [03700, 05004], lr: 0.001000, loss: 1.0562
2022-02-22 00:49:00 - train: epoch 0080, iter [03800, 05004], lr: 0.001000, loss: 1.1305
2022-02-22 00:49:37 - train: epoch 0080, iter [03900, 05004], lr: 0.001000, loss: 0.9975
2022-02-22 00:50:14 - train: epoch 0080, iter [04000, 05004], lr: 0.001000, loss: 1.2288
2022-02-22 00:50:53 - train: epoch 0080, iter [04100, 05004], lr: 0.001000, loss: 1.1486
2022-02-22 00:51:30 - train: epoch 0080, iter [04200, 05004], lr: 0.001000, loss: 1.0730
2022-02-22 00:52:07 - train: epoch 0080, iter [04300, 05004], lr: 0.001000, loss: 1.1808
2022-02-22 00:52:44 - train: epoch 0080, iter [04400, 05004], lr: 0.001000, loss: 1.1392
2022-02-22 00:53:21 - train: epoch 0080, iter [04500, 05004], lr: 0.001000, loss: 0.9933
2022-02-22 00:53:58 - train: epoch 0080, iter [04600, 05004], lr: 0.001000, loss: 1.1276
2022-02-22 00:54:35 - train: epoch 0080, iter [04700, 05004], lr: 0.001000, loss: 1.0648
2022-02-22 00:55:12 - train: epoch 0080, iter [04800, 05004], lr: 0.001000, loss: 1.1093
2022-02-22 00:55:50 - train: epoch 0080, iter [04900, 05004], lr: 0.001000, loss: 1.2337
2022-02-22 00:56:25 - train: epoch 0080, iter [05000, 05004], lr: 0.001000, loss: 0.8159
2022-02-22 00:56:26 - train: epoch 080, train_loss: 1.0758
2022-02-22 00:57:49 - eval: epoch: 080, acc1: 73.458%, acc5: 91.500%, test_loss: 1.0608, per_image_load_time: 1.447ms, per_image_inference_time: 0.290ms
2022-02-22 00:57:49 - until epoch: 080, best_acc1: 73.458%
2022-02-22 00:57:49 - epoch 081 lr: 0.0010000000000000002
2022-02-22 00:58:32 - train: epoch 0081, iter [00100, 05004], lr: 0.001000, loss: 0.9313
2022-02-22 00:59:10 - train: epoch 0081, iter [00200, 05004], lr: 0.001000, loss: 1.1641
2022-02-22 00:59:47 - train: epoch 0081, iter [00300, 05004], lr: 0.001000, loss: 1.0179
2022-02-22 01:00:24 - train: epoch 0081, iter [00400, 05004], lr: 0.001000, loss: 1.1653
2022-02-22 01:01:00 - train: epoch 0081, iter [00500, 05004], lr: 0.001000, loss: 1.2104
2022-02-22 01:01:39 - train: epoch 0081, iter [00600, 05004], lr: 0.001000, loss: 1.1019
2022-02-22 01:02:16 - train: epoch 0081, iter [00700, 05004], lr: 0.001000, loss: 0.9837
2022-02-22 01:02:54 - train: epoch 0081, iter [00800, 05004], lr: 0.001000, loss: 1.1573
2022-02-22 01:03:31 - train: epoch 0081, iter [00900, 05004], lr: 0.001000, loss: 0.9827
2022-02-22 01:04:08 - train: epoch 0081, iter [01000, 05004], lr: 0.001000, loss: 1.0722
2022-02-22 01:04:45 - train: epoch 0081, iter [01100, 05004], lr: 0.001000, loss: 1.0154
2022-02-22 01:05:22 - train: epoch 0081, iter [01200, 05004], lr: 0.001000, loss: 1.1043
2022-02-22 01:05:59 - train: epoch 0081, iter [01300, 05004], lr: 0.001000, loss: 0.9955
2022-02-22 01:06:36 - train: epoch 0081, iter [01400, 05004], lr: 0.001000, loss: 0.8056
2022-02-22 01:07:13 - train: epoch 0081, iter [01500, 05004], lr: 0.001000, loss: 1.1405
2022-02-22 01:07:48 - train: epoch 0081, iter [01600, 05004], lr: 0.001000, loss: 0.9903
2022-02-22 01:08:26 - train: epoch 0081, iter [01700, 05004], lr: 0.001000, loss: 1.0995
2022-02-22 01:09:04 - train: epoch 0081, iter [01800, 05004], lr: 0.001000, loss: 0.9070
2022-02-22 01:09:41 - train: epoch 0081, iter [01900, 05004], lr: 0.001000, loss: 1.0017
2022-02-22 01:10:18 - train: epoch 0081, iter [02000, 05004], lr: 0.001000, loss: 1.1239
2022-02-22 01:10:56 - train: epoch 0081, iter [02100, 05004], lr: 0.001000, loss: 1.0249
2022-02-22 01:11:32 - train: epoch 0081, iter [02200, 05004], lr: 0.001000, loss: 1.1067
2022-02-22 01:12:10 - train: epoch 0081, iter [02300, 05004], lr: 0.001000, loss: 1.0199
2022-02-22 01:12:48 - train: epoch 0081, iter [02400, 05004], lr: 0.001000, loss: 0.9987
2022-02-22 01:13:25 - train: epoch 0081, iter [02500, 05004], lr: 0.001000, loss: 1.2528
2022-02-22 01:14:03 - train: epoch 0081, iter [02600, 05004], lr: 0.001000, loss: 1.1491
2022-02-22 01:14:41 - train: epoch 0081, iter [02700, 05004], lr: 0.001000, loss: 1.1053
2022-02-22 01:15:17 - train: epoch 0081, iter [02800, 05004], lr: 0.001000, loss: 0.9777
2022-02-22 01:15:55 - train: epoch 0081, iter [02900, 05004], lr: 0.001000, loss: 0.9809
2022-02-22 01:16:32 - train: epoch 0081, iter [03000, 05004], lr: 0.001000, loss: 1.1203
2022-02-22 01:17:10 - train: epoch 0081, iter [03100, 05004], lr: 0.001000, loss: 1.0057
2022-02-22 01:17:47 - train: epoch 0081, iter [03200, 05004], lr: 0.001000, loss: 1.0232
2022-02-22 01:18:25 - train: epoch 0081, iter [03300, 05004], lr: 0.001000, loss: 1.1516
2022-02-22 01:19:01 - train: epoch 0081, iter [03400, 05004], lr: 0.001000, loss: 1.1584
2022-02-22 01:19:40 - train: epoch 0081, iter [03500, 05004], lr: 0.001000, loss: 1.1793
2022-02-22 01:20:17 - train: epoch 0081, iter [03600, 05004], lr: 0.001000, loss: 0.9009
2022-02-22 01:20:55 - train: epoch 0081, iter [03700, 05004], lr: 0.001000, loss: 1.2422
2022-02-22 01:21:31 - train: epoch 0081, iter [03800, 05004], lr: 0.001000, loss: 0.9070
2022-02-22 01:22:09 - train: epoch 0081, iter [03900, 05004], lr: 0.001000, loss: 1.1538
2022-02-22 01:22:47 - train: epoch 0081, iter [04000, 05004], lr: 0.001000, loss: 0.8502
2022-02-22 01:23:24 - train: epoch 0081, iter [04100, 05004], lr: 0.001000, loss: 1.1235
2022-02-22 01:24:01 - train: epoch 0081, iter [04200, 05004], lr: 0.001000, loss: 1.0339
2022-02-22 01:24:39 - train: epoch 0081, iter [04300, 05004], lr: 0.001000, loss: 1.0761
2022-02-22 01:25:17 - train: epoch 0081, iter [04400, 05004], lr: 0.001000, loss: 1.1371
2022-02-22 01:25:54 - train: epoch 0081, iter [04500, 05004], lr: 0.001000, loss: 1.1321
2022-02-22 01:26:32 - train: epoch 0081, iter [04600, 05004], lr: 0.001000, loss: 0.9981
2022-02-22 01:27:09 - train: epoch 0081, iter [04700, 05004], lr: 0.001000, loss: 1.1448
2022-02-22 01:27:47 - train: epoch 0081, iter [04800, 05004], lr: 0.001000, loss: 1.1627
2022-02-22 01:28:25 - train: epoch 0081, iter [04900, 05004], lr: 0.001000, loss: 1.0590
2022-02-22 01:29:01 - train: epoch 0081, iter [05000, 05004], lr: 0.001000, loss: 0.8563
2022-02-22 01:29:02 - train: epoch 081, train_loss: 1.0729
2022-02-22 01:30:26 - eval: epoch: 081, acc1: 73.236%, acc5: 91.480%, test_loss: 1.0607, per_image_load_time: 1.289ms, per_image_inference_time: 0.280ms
2022-02-22 01:30:27 - until epoch: 081, best_acc1: 73.458%
2022-02-22 01:30:27 - epoch 082 lr: 0.0010000000000000002
2022-02-22 01:31:10 - train: epoch 0082, iter [00100, 05004], lr: 0.001000, loss: 0.8278
2022-02-22 01:31:48 - train: epoch 0082, iter [00200, 05004], lr: 0.001000, loss: 0.9926
2022-02-22 01:32:26 - train: epoch 0082, iter [00300, 05004], lr: 0.001000, loss: 1.1269
2022-02-22 01:33:03 - train: epoch 0082, iter [00400, 05004], lr: 0.001000, loss: 1.1412
2022-02-22 01:33:40 - train: epoch 0082, iter [00500, 05004], lr: 0.001000, loss: 1.0937
2022-02-22 01:34:18 - train: epoch 0082, iter [00600, 05004], lr: 0.001000, loss: 1.0013
2022-02-22 01:34:56 - train: epoch 0082, iter [00700, 05004], lr: 0.001000, loss: 1.1586
2022-02-22 01:35:33 - train: epoch 0082, iter [00800, 05004], lr: 0.001000, loss: 1.0741
2022-02-22 01:36:11 - train: epoch 0082, iter [00900, 05004], lr: 0.001000, loss: 1.1819
2022-02-22 01:36:49 - train: epoch 0082, iter [01000, 05004], lr: 0.001000, loss: 1.1394
2022-02-22 01:37:26 - train: epoch 0082, iter [01100, 05004], lr: 0.001000, loss: 1.2271
2022-02-22 01:38:04 - train: epoch 0082, iter [01200, 05004], lr: 0.001000, loss: 1.0521
2022-02-22 01:38:42 - train: epoch 0082, iter [01300, 05004], lr: 0.001000, loss: 1.2392
2022-02-22 01:39:19 - train: epoch 0082, iter [01400, 05004], lr: 0.001000, loss: 0.9587
2022-02-22 01:39:58 - train: epoch 0082, iter [01500, 05004], lr: 0.001000, loss: 0.9825
2022-02-22 01:40:34 - train: epoch 0082, iter [01600, 05004], lr: 0.001000, loss: 1.0776
2022-02-22 01:41:12 - train: epoch 0082, iter [01700, 05004], lr: 0.001000, loss: 1.0500
2022-02-22 01:41:49 - train: epoch 0082, iter [01800, 05004], lr: 0.001000, loss: 1.0158
2022-02-22 01:42:28 - train: epoch 0082, iter [01900, 05004], lr: 0.001000, loss: 1.0574
2022-02-22 01:43:05 - train: epoch 0082, iter [02000, 05004], lr: 0.001000, loss: 0.9460
2022-02-22 01:43:43 - train: epoch 0082, iter [02100, 05004], lr: 0.001000, loss: 0.9749
2022-02-22 01:44:20 - train: epoch 0082, iter [02200, 05004], lr: 0.001000, loss: 1.1550
2022-02-22 01:44:58 - train: epoch 0082, iter [02300, 05004], lr: 0.001000, loss: 1.0778
2022-02-22 01:45:35 - train: epoch 0082, iter [02400, 05004], lr: 0.001000, loss: 1.2524
2022-02-22 01:46:13 - train: epoch 0082, iter [02500, 05004], lr: 0.001000, loss: 1.0148
2022-02-22 01:46:51 - train: epoch 0082, iter [02600, 05004], lr: 0.001000, loss: 1.0596
2022-02-22 01:47:28 - train: epoch 0082, iter [02700, 05004], lr: 0.001000, loss: 0.9092
2022-02-22 01:48:06 - train: epoch 0082, iter [02800, 05004], lr: 0.001000, loss: 0.9795
2022-02-22 01:48:42 - train: epoch 0082, iter [02900, 05004], lr: 0.001000, loss: 0.9633
2022-02-22 01:49:21 - train: epoch 0082, iter [03000, 05004], lr: 0.001000, loss: 0.9856
2022-02-22 01:49:57 - train: epoch 0082, iter [03100, 05004], lr: 0.001000, loss: 1.0385
2022-02-22 01:50:36 - train: epoch 0082, iter [03200, 05004], lr: 0.001000, loss: 1.2252
2022-02-22 01:51:12 - train: epoch 0082, iter [03300, 05004], lr: 0.001000, loss: 1.0272
2022-02-22 01:51:50 - train: epoch 0082, iter [03400, 05004], lr: 0.001000, loss: 1.0431
2022-02-22 01:52:27 - train: epoch 0082, iter [03500, 05004], lr: 0.001000, loss: 1.0099
2022-02-22 01:53:05 - train: epoch 0082, iter [03600, 05004], lr: 0.001000, loss: 1.0235
2022-02-22 01:53:42 - train: epoch 0082, iter [03700, 05004], lr: 0.001000, loss: 0.9606
2022-02-22 01:54:19 - train: epoch 0082, iter [03800, 05004], lr: 0.001000, loss: 1.3341
2022-02-22 01:54:57 - train: epoch 0082, iter [03900, 05004], lr: 0.001000, loss: 1.1633
2022-02-22 01:55:33 - train: epoch 0082, iter [04000, 05004], lr: 0.001000, loss: 1.1664
2022-02-22 01:56:11 - train: epoch 0082, iter [04100, 05004], lr: 0.001000, loss: 0.9681
2022-02-22 01:56:48 - train: epoch 0082, iter [04200, 05004], lr: 0.001000, loss: 1.1740
2022-02-22 01:57:26 - train: epoch 0082, iter [04300, 05004], lr: 0.001000, loss: 0.8588
2022-02-22 01:58:04 - train: epoch 0082, iter [04400, 05004], lr: 0.001000, loss: 1.0036
2022-02-22 01:58:41 - train: epoch 0082, iter [04500, 05004], lr: 0.001000, loss: 1.0810
2022-02-22 01:59:18 - train: epoch 0082, iter [04600, 05004], lr: 0.001000, loss: 1.1720
2022-02-22 01:59:55 - train: epoch 0082, iter [04700, 05004], lr: 0.001000, loss: 0.9705
2022-02-22 02:00:33 - train: epoch 0082, iter [04800, 05004], lr: 0.001000, loss: 0.9748
2022-02-22 02:01:10 - train: epoch 0082, iter [04900, 05004], lr: 0.001000, loss: 0.9267
2022-02-22 02:01:45 - train: epoch 0082, iter [05000, 05004], lr: 0.001000, loss: 1.0958
2022-02-22 02:01:47 - train: epoch 082, train_loss: 1.0686
2022-02-22 02:03:09 - eval: epoch: 082, acc1: 73.398%, acc5: 91.402%, test_loss: 1.0599, per_image_load_time: 1.563ms, per_image_inference_time: 0.283ms
2022-02-22 02:03:10 - until epoch: 082, best_acc1: 73.458%
2022-02-22 02:03:10 - epoch 083 lr: 0.0010000000000000002
2022-02-22 02:03:52 - train: epoch 0083, iter [00100, 05004], lr: 0.001000, loss: 1.0524
2022-02-22 02:04:31 - train: epoch 0083, iter [00200, 05004], lr: 0.001000, loss: 0.9758
2022-02-22 02:05:08 - train: epoch 0083, iter [00300, 05004], lr: 0.001000, loss: 1.1417
2022-02-22 02:05:42 - train: epoch 0083, iter [00400, 05004], lr: 0.001000, loss: 1.2326
2022-02-22 02:06:15 - train: epoch 0083, iter [00500, 05004], lr: 0.001000, loss: 1.0332
2022-02-22 02:06:54 - train: epoch 0083, iter [00600, 05004], lr: 0.001000, loss: 0.9803
2022-02-22 02:07:34 - train: epoch 0083, iter [00700, 05004], lr: 0.001000, loss: 0.9577
2022-02-22 02:08:12 - train: epoch 0083, iter [00800, 05004], lr: 0.001000, loss: 1.0025
2022-02-22 02:08:49 - train: epoch 0083, iter [00900, 05004], lr: 0.001000, loss: 1.1362
2022-02-22 02:09:26 - train: epoch 0083, iter [01000, 05004], lr: 0.001000, loss: 1.2116
2022-02-22 02:10:04 - train: epoch 0083, iter [01100, 05004], lr: 0.001000, loss: 1.1004
2022-02-22 02:10:43 - train: epoch 0083, iter [01200, 05004], lr: 0.001000, loss: 1.0105
2022-02-22 02:11:19 - train: epoch 0083, iter [01300, 05004], lr: 0.001000, loss: 0.8888
2022-02-22 02:11:57 - train: epoch 0083, iter [01400, 05004], lr: 0.001000, loss: 1.0901
2022-02-22 02:12:34 - train: epoch 0083, iter [01500, 05004], lr: 0.001000, loss: 0.9941
2022-02-22 02:13:12 - train: epoch 0083, iter [01600, 05004], lr: 0.001000, loss: 1.0585
2022-02-22 02:13:49 - train: epoch 0083, iter [01700, 05004], lr: 0.001000, loss: 1.2294
2022-02-22 02:14:26 - train: epoch 0083, iter [01800, 05004], lr: 0.001000, loss: 1.2244
2022-02-22 02:15:04 - train: epoch 0083, iter [01900, 05004], lr: 0.001000, loss: 0.8629
2022-02-22 02:15:41 - train: epoch 0083, iter [02000, 05004], lr: 0.001000, loss: 0.7659
2022-02-22 02:16:18 - train: epoch 0083, iter [02100, 05004], lr: 0.001000, loss: 0.9727
2022-02-22 02:16:57 - train: epoch 0083, iter [02200, 05004], lr: 0.001000, loss: 1.0521
2022-02-22 02:17:33 - train: epoch 0083, iter [02300, 05004], lr: 0.001000, loss: 1.1069
2022-02-22 02:18:11 - train: epoch 0083, iter [02400, 05004], lr: 0.001000, loss: 1.0306
2022-02-22 02:18:48 - train: epoch 0083, iter [02500, 05004], lr: 0.001000, loss: 1.1000
2022-02-22 02:19:25 - train: epoch 0083, iter [02600, 05004], lr: 0.001000, loss: 0.9261
2022-02-22 02:20:02 - train: epoch 0083, iter [02700, 05004], lr: 0.001000, loss: 1.0821
2022-02-22 02:20:39 - train: epoch 0083, iter [02800, 05004], lr: 0.001000, loss: 0.9819
2022-02-22 02:21:17 - train: epoch 0083, iter [02900, 05004], lr: 0.001000, loss: 1.0201
2022-02-22 02:21:54 - train: epoch 0083, iter [03000, 05004], lr: 0.001000, loss: 1.2286
2022-02-22 02:22:32 - train: epoch 0083, iter [03100, 05004], lr: 0.001000, loss: 0.8998
2022-02-22 02:23:08 - train: epoch 0083, iter [03200, 05004], lr: 0.001000, loss: 0.9808
2022-02-22 02:23:46 - train: epoch 0083, iter [03300, 05004], lr: 0.001000, loss: 1.3033
2022-02-22 02:24:23 - train: epoch 0083, iter [03400, 05004], lr: 0.001000, loss: 1.1504
2022-02-22 02:25:01 - train: epoch 0083, iter [03500, 05004], lr: 0.001000, loss: 1.1630
2022-02-22 02:25:38 - train: epoch 0083, iter [03600, 05004], lr: 0.001000, loss: 1.0898
2022-02-22 02:26:16 - train: epoch 0083, iter [03700, 05004], lr: 0.001000, loss: 1.0905
2022-02-22 02:26:53 - train: epoch 0083, iter [03800, 05004], lr: 0.001000, loss: 0.9845
2022-02-22 02:27:31 - train: epoch 0083, iter [03900, 05004], lr: 0.001000, loss: 1.0680
2022-02-22 02:28:07 - train: epoch 0083, iter [04000, 05004], lr: 0.001000, loss: 1.2258
2022-02-22 02:28:46 - train: epoch 0083, iter [04100, 05004], lr: 0.001000, loss: 1.0974
2022-02-22 02:29:23 - train: epoch 0083, iter [04200, 05004], lr: 0.001000, loss: 1.2969
2022-02-22 02:30:00 - train: epoch 0083, iter [04300, 05004], lr: 0.001000, loss: 1.0369
2022-02-22 02:30:37 - train: epoch 0083, iter [04400, 05004], lr: 0.001000, loss: 0.9110
2022-02-22 02:31:15 - train: epoch 0083, iter [04500, 05004], lr: 0.001000, loss: 1.1518
2022-02-22 02:31:52 - train: epoch 0083, iter [04600, 05004], lr: 0.001000, loss: 1.1787
2022-02-22 02:32:31 - train: epoch 0083, iter [04700, 05004], lr: 0.001000, loss: 1.1775
2022-02-22 02:33:08 - train: epoch 0083, iter [04800, 05004], lr: 0.001000, loss: 1.1476
2022-02-22 02:33:45 - train: epoch 0083, iter [04900, 05004], lr: 0.001000, loss: 1.3931
2022-02-22 02:34:20 - train: epoch 0083, iter [05000, 05004], lr: 0.001000, loss: 1.2345
2022-02-22 02:34:21 - train: epoch 083, train_loss: 1.0675
2022-02-22 02:35:44 - eval: epoch: 083, acc1: 73.460%, acc5: 91.382%, test_loss: 1.0622, per_image_load_time: 1.022ms, per_image_inference_time: 0.280ms
2022-02-22 02:35:45 - until epoch: 083, best_acc1: 73.460%
2022-02-22 02:35:45 - epoch 084 lr: 0.0010000000000000002
2022-02-22 02:36:28 - train: epoch 0084, iter [00100, 05004], lr: 0.001000, loss: 0.9931
2022-02-22 02:37:06 - train: epoch 0084, iter [00200, 05004], lr: 0.001000, loss: 1.0405
2022-02-22 02:37:43 - train: epoch 0084, iter [00300, 05004], lr: 0.001000, loss: 0.8982
2022-02-22 02:38:19 - train: epoch 0084, iter [00400, 05004], lr: 0.001000, loss: 1.0769
2022-02-22 02:38:57 - train: epoch 0084, iter [00500, 05004], lr: 0.001000, loss: 1.0538
2022-02-22 02:39:36 - train: epoch 0084, iter [00600, 05004], lr: 0.001000, loss: 1.2091
2022-02-22 02:40:12 - train: epoch 0084, iter [00700, 05004], lr: 0.001000, loss: 1.1250
2022-02-22 02:40:50 - train: epoch 0084, iter [00800, 05004], lr: 0.001000, loss: 1.1622
2022-02-22 02:41:27 - train: epoch 0084, iter [00900, 05004], lr: 0.001000, loss: 1.0550
2022-02-22 02:42:05 - train: epoch 0084, iter [01000, 05004], lr: 0.001000, loss: 1.1834
2022-02-22 02:42:41 - train: epoch 0084, iter [01100, 05004], lr: 0.001000, loss: 0.9838
2022-02-22 02:43:19 - train: epoch 0084, iter [01200, 05004], lr: 0.001000, loss: 1.3441
2022-02-22 02:43:56 - train: epoch 0084, iter [01300, 05004], lr: 0.001000, loss: 1.0171
2022-02-22 02:44:34 - train: epoch 0084, iter [01400, 05004], lr: 0.001000, loss: 1.1153
2022-02-22 02:45:10 - train: epoch 0084, iter [01500, 05004], lr: 0.001000, loss: 1.1231
2022-02-22 02:45:48 - train: epoch 0084, iter [01600, 05004], lr: 0.001000, loss: 0.9922
2022-02-22 02:46:27 - train: epoch 0084, iter [01700, 05004], lr: 0.001000, loss: 1.1975
2022-02-22 02:47:04 - train: epoch 0084, iter [01800, 05004], lr: 0.001000, loss: 1.0597
2022-02-22 02:47:41 - train: epoch 0084, iter [01900, 05004], lr: 0.001000, loss: 1.1072
2022-02-22 02:48:18 - train: epoch 0084, iter [02000, 05004], lr: 0.001000, loss: 1.0986
2022-02-22 02:48:55 - train: epoch 0084, iter [02100, 05004], lr: 0.001000, loss: 0.9407
2022-02-22 02:49:32 - train: epoch 0084, iter [02200, 05004], lr: 0.001000, loss: 0.9504
2022-02-22 02:50:10 - train: epoch 0084, iter [02300, 05004], lr: 0.001000, loss: 1.0659
2022-02-22 02:50:46 - train: epoch 0084, iter [02400, 05004], lr: 0.001000, loss: 0.9688
2022-02-22 02:51:24 - train: epoch 0084, iter [02500, 05004], lr: 0.001000, loss: 1.1536
2022-02-22 02:52:01 - train: epoch 0084, iter [02600, 05004], lr: 0.001000, loss: 1.1530
2022-02-22 02:52:38 - train: epoch 0084, iter [02700, 05004], lr: 0.001000, loss: 1.0552
2022-02-22 02:53:17 - train: epoch 0084, iter [02800, 05004], lr: 0.001000, loss: 1.1356
2022-02-22 02:53:55 - train: epoch 0084, iter [02900, 05004], lr: 0.001000, loss: 1.0128
2022-02-22 02:54:32 - train: epoch 0084, iter [03000, 05004], lr: 0.001000, loss: 1.0713
2022-02-22 02:55:10 - train: epoch 0084, iter [03100, 05004], lr: 0.001000, loss: 0.9255
2022-02-22 02:55:46 - train: epoch 0084, iter [03200, 05004], lr: 0.001000, loss: 0.9918
2022-02-22 02:56:24 - train: epoch 0084, iter [03300, 05004], lr: 0.001000, loss: 1.0754
2022-02-22 02:57:02 - train: epoch 0084, iter [03400, 05004], lr: 0.001000, loss: 0.9606
2022-02-22 02:57:39 - train: epoch 0084, iter [03500, 05004], lr: 0.001000, loss: 0.8911
2022-02-22 02:58:16 - train: epoch 0084, iter [03600, 05004], lr: 0.001000, loss: 1.0017
2022-02-22 02:58:54 - train: epoch 0084, iter [03700, 05004], lr: 0.001000, loss: 1.1270
2022-02-22 02:59:31 - train: epoch 0084, iter [03800, 05004], lr: 0.001000, loss: 1.2633
2022-02-22 03:00:09 - train: epoch 0084, iter [03900, 05004], lr: 0.001000, loss: 1.1077
2022-02-22 03:00:47 - train: epoch 0084, iter [04000, 05004], lr: 0.001000, loss: 1.1847
2022-02-22 03:01:25 - train: epoch 0084, iter [04100, 05004], lr: 0.001000, loss: 1.1856
2022-02-22 03:02:02 - train: epoch 0084, iter [04200, 05004], lr: 0.001000, loss: 1.1483
2022-02-22 03:02:39 - train: epoch 0084, iter [04300, 05004], lr: 0.001000, loss: 1.0790
2022-02-22 03:03:18 - train: epoch 0084, iter [04400, 05004], lr: 0.001000, loss: 1.3011
2022-02-22 03:03:55 - train: epoch 0084, iter [04500, 05004], lr: 0.001000, loss: 1.0272
2022-02-22 03:04:33 - train: epoch 0084, iter [04600, 05004], lr: 0.001000, loss: 0.9899
2022-02-22 03:05:10 - train: epoch 0084, iter [04700, 05004], lr: 0.001000, loss: 1.3050
2022-02-22 03:05:47 - train: epoch 0084, iter [04800, 05004], lr: 0.001000, loss: 0.9854
2022-02-22 03:06:24 - train: epoch 0084, iter [04900, 05004], lr: 0.001000, loss: 0.8938
2022-02-22 03:07:00 - train: epoch 0084, iter [05000, 05004], lr: 0.001000, loss: 1.1561
2022-02-22 03:07:01 - train: epoch 084, train_loss: 1.0629
2022-02-22 03:08:23 - eval: epoch: 084, acc1: 73.318%, acc5: 91.510%, test_loss: 1.0590, per_image_load_time: 1.059ms, per_image_inference_time: 0.280ms
2022-02-22 03:08:24 - until epoch: 084, best_acc1: 73.460%
2022-02-22 03:08:24 - epoch 085 lr: 0.0010000000000000002
2022-02-22 03:09:06 - train: epoch 0085, iter [00100, 05004], lr: 0.001000, loss: 0.9137
2022-02-22 03:09:43 - train: epoch 0085, iter [00200, 05004], lr: 0.001000, loss: 0.8275
2022-02-22 03:10:21 - train: epoch 0085, iter [00300, 05004], lr: 0.001000, loss: 1.1205
2022-02-22 03:10:58 - train: epoch 0085, iter [00400, 05004], lr: 0.001000, loss: 0.9472
2022-02-22 03:11:37 - train: epoch 0085, iter [00500, 05004], lr: 0.001000, loss: 1.2424
2022-02-22 03:12:13 - train: epoch 0085, iter [00600, 05004], lr: 0.001000, loss: 0.8421
2022-02-22 03:12:51 - train: epoch 0085, iter [00700, 05004], lr: 0.001000, loss: 0.8503
2022-02-22 03:13:29 - train: epoch 0085, iter [00800, 05004], lr: 0.001000, loss: 0.9854
2022-02-22 03:14:05 - train: epoch 0085, iter [00900, 05004], lr: 0.001000, loss: 1.0200
2022-02-22 03:14:43 - train: epoch 0085, iter [01000, 05004], lr: 0.001000, loss: 1.1254
2022-02-22 03:15:19 - train: epoch 0085, iter [01100, 05004], lr: 0.001000, loss: 1.0620
2022-02-22 03:15:57 - train: epoch 0085, iter [01200, 05004], lr: 0.001000, loss: 0.9954
2022-02-22 03:16:34 - train: epoch 0085, iter [01300, 05004], lr: 0.001000, loss: 1.0991
2022-02-22 03:17:12 - train: epoch 0085, iter [01400, 05004], lr: 0.001000, loss: 1.1664
2022-02-22 03:17:50 - train: epoch 0085, iter [01500, 05004], lr: 0.001000, loss: 0.8289
2022-02-22 03:18:28 - train: epoch 0085, iter [01600, 05004], lr: 0.001000, loss: 1.0125
2022-02-22 03:19:05 - train: epoch 0085, iter [01700, 05004], lr: 0.001000, loss: 1.2404
2022-02-22 03:19:41 - train: epoch 0085, iter [01800, 05004], lr: 0.001000, loss: 0.9664
2022-02-22 03:20:19 - train: epoch 0085, iter [01900, 05004], lr: 0.001000, loss: 0.9263
2022-02-22 03:20:56 - train: epoch 0085, iter [02000, 05004], lr: 0.001000, loss: 1.0430
2022-02-22 03:21:34 - train: epoch 0085, iter [02100, 05004], lr: 0.001000, loss: 0.8828
2022-02-22 03:22:12 - train: epoch 0085, iter [02200, 05004], lr: 0.001000, loss: 1.1167
2022-02-22 03:22:49 - train: epoch 0085, iter [02300, 05004], lr: 0.001000, loss: 0.8856
2022-02-22 03:23:25 - train: epoch 0085, iter [02400, 05004], lr: 0.001000, loss: 1.1061
2022-02-22 03:24:03 - train: epoch 0085, iter [02500, 05004], lr: 0.001000, loss: 1.2608
2022-02-22 03:24:41 - train: epoch 0085, iter [02600, 05004], lr: 0.001000, loss: 1.1047
2022-02-22 03:25:19 - train: epoch 0085, iter [02700, 05004], lr: 0.001000, loss: 0.9409
2022-02-22 03:25:57 - train: epoch 0085, iter [02800, 05004], lr: 0.001000, loss: 1.0632
2022-02-22 03:26:35 - train: epoch 0085, iter [02900, 05004], lr: 0.001000, loss: 1.2220
2022-02-22 03:27:12 - train: epoch 0085, iter [03000, 05004], lr: 0.001000, loss: 1.2617
2022-02-22 03:27:49 - train: epoch 0085, iter [03100, 05004], lr: 0.001000, loss: 1.0013
2022-02-22 03:28:28 - train: epoch 0085, iter [03200, 05004], lr: 0.001000, loss: 1.0238
2022-02-22 03:29:04 - train: epoch 0085, iter [03300, 05004], lr: 0.001000, loss: 1.0929
2022-02-22 03:29:42 - train: epoch 0085, iter [03400, 05004], lr: 0.001000, loss: 1.1624
2022-02-22 03:30:20 - train: epoch 0085, iter [03500, 05004], lr: 0.001000, loss: 1.1574
2022-02-22 03:30:57 - train: epoch 0085, iter [03600, 05004], lr: 0.001000, loss: 1.0890
2022-02-22 03:31:35 - train: epoch 0085, iter [03700, 05004], lr: 0.001000, loss: 0.9432
2022-02-22 03:32:11 - train: epoch 0085, iter [03800, 05004], lr: 0.001000, loss: 1.0165
2022-02-22 03:32:49 - train: epoch 0085, iter [03900, 05004], lr: 0.001000, loss: 0.9900
2022-02-22 03:33:27 - train: epoch 0085, iter [04000, 05004], lr: 0.001000, loss: 1.3661
2022-02-22 03:34:04 - train: epoch 0085, iter [04100, 05004], lr: 0.001000, loss: 1.1460
2022-02-22 03:34:41 - train: epoch 0085, iter [04200, 05004], lr: 0.001000, loss: 1.0276
2022-02-22 03:35:19 - train: epoch 0085, iter [04300, 05004], lr: 0.001000, loss: 1.0249
2022-02-22 03:35:56 - train: epoch 0085, iter [04400, 05004], lr: 0.001000, loss: 1.0212
2022-02-22 03:36:34 - train: epoch 0085, iter [04500, 05004], lr: 0.001000, loss: 1.0886
2022-02-22 03:37:11 - train: epoch 0085, iter [04600, 05004], lr: 0.001000, loss: 1.1908
2022-02-22 03:37:49 - train: epoch 0085, iter [04700, 05004], lr: 0.001000, loss: 1.2504
2022-02-22 03:38:26 - train: epoch 0085, iter [04800, 05004], lr: 0.001000, loss: 0.9420
2022-02-22 03:39:03 - train: epoch 0085, iter [04900, 05004], lr: 0.001000, loss: 1.0914
2022-02-22 03:39:39 - train: epoch 0085, iter [05000, 05004], lr: 0.001000, loss: 1.0039
2022-02-22 03:39:40 - train: epoch 085, train_loss: 1.0617
2022-02-22 03:41:02 - eval: epoch: 085, acc1: 73.344%, acc5: 91.548%, test_loss: 1.0625, per_image_load_time: 1.665ms, per_image_inference_time: 0.275ms
2022-02-22 03:41:03 - until epoch: 085, best_acc1: 73.460%
2022-02-22 03:41:03 - epoch 086 lr: 0.0010000000000000002
2022-02-22 03:41:45 - train: epoch 0086, iter [00100, 05004], lr: 0.001000, loss: 0.9697
2022-02-22 03:42:23 - train: epoch 0086, iter [00200, 05004], lr: 0.001000, loss: 0.9303
2022-02-22 03:43:01 - train: epoch 0086, iter [00300, 05004], lr: 0.001000, loss: 1.0888
2022-02-22 03:43:38 - train: epoch 0086, iter [00400, 05004], lr: 0.001000, loss: 1.0939
2022-02-22 03:44:17 - train: epoch 0086, iter [00500, 05004], lr: 0.001000, loss: 1.0305
2022-02-22 03:44:53 - train: epoch 0086, iter [00600, 05004], lr: 0.001000, loss: 1.0224
2022-02-22 03:45:31 - train: epoch 0086, iter [00700, 05004], lr: 0.001000, loss: 0.9688
2022-02-22 03:46:08 - train: epoch 0086, iter [00800, 05004], lr: 0.001000, loss: 1.2098
2022-02-22 03:46:47 - train: epoch 0086, iter [00900, 05004], lr: 0.001000, loss: 1.1934
2022-02-22 03:47:22 - train: epoch 0086, iter [01000, 05004], lr: 0.001000, loss: 1.0898
2022-02-22 03:48:00 - train: epoch 0086, iter [01100, 05004], lr: 0.001000, loss: 1.0901
2022-02-22 03:48:38 - train: epoch 0086, iter [01200, 05004], lr: 0.001000, loss: 0.9551
2022-02-22 03:49:15 - train: epoch 0086, iter [01300, 05004], lr: 0.001000, loss: 1.1802
2022-02-22 03:49:54 - train: epoch 0086, iter [01400, 05004], lr: 0.001000, loss: 0.8960
2022-02-22 03:50:31 - train: epoch 0086, iter [01500, 05004], lr: 0.001000, loss: 0.8783
2022-02-22 03:51:08 - train: epoch 0086, iter [01600, 05004], lr: 0.001000, loss: 1.1192
2022-02-22 03:51:46 - train: epoch 0086, iter [01700, 05004], lr: 0.001000, loss: 1.0169
2022-02-22 03:52:22 - train: epoch 0086, iter [01800, 05004], lr: 0.001000, loss: 1.0089
2022-02-22 03:52:59 - train: epoch 0086, iter [01900, 05004], lr: 0.001000, loss: 1.1875
2022-02-22 03:53:37 - train: epoch 0086, iter [02000, 05004], lr: 0.001000, loss: 1.1291
2022-02-22 03:54:15 - train: epoch 0086, iter [02100, 05004], lr: 0.001000, loss: 0.9891
2022-02-22 03:54:53 - train: epoch 0086, iter [02200, 05004], lr: 0.001000, loss: 1.0995
2022-02-22 03:55:29 - train: epoch 0086, iter [02300, 05004], lr: 0.001000, loss: 1.0632
2022-02-22 03:56:07 - train: epoch 0086, iter [02400, 05004], lr: 0.001000, loss: 0.8978
2022-02-22 03:56:44 - train: epoch 0086, iter [02500, 05004], lr: 0.001000, loss: 1.0211
2022-02-22 03:57:22 - train: epoch 0086, iter [02600, 05004], lr: 0.001000, loss: 1.1333
2022-02-22 03:57:58 - train: epoch 0086, iter [02700, 05004], lr: 0.001000, loss: 0.9281
2022-02-22 03:58:36 - train: epoch 0086, iter [02800, 05004], lr: 0.001000, loss: 1.2275
2022-02-22 03:59:13 - train: epoch 0086, iter [02900, 05004], lr: 0.001000, loss: 0.9350
2022-02-22 03:59:50 - train: epoch 0086, iter [03000, 05004], lr: 0.001000, loss: 1.0828
2022-02-22 04:00:28 - train: epoch 0086, iter [03100, 05004], lr: 0.001000, loss: 1.0054
2022-02-22 04:01:05 - train: epoch 0086, iter [03200, 05004], lr: 0.001000, loss: 1.1382
2022-02-22 04:01:42 - train: epoch 0086, iter [03300, 05004], lr: 0.001000, loss: 1.1419
2022-02-22 04:02:20 - train: epoch 0086, iter [03400, 05004], lr: 0.001000, loss: 1.1819
2022-02-22 04:02:57 - train: epoch 0086, iter [03500, 05004], lr: 0.001000, loss: 1.0485
2022-02-22 04:03:34 - train: epoch 0086, iter [03600, 05004], lr: 0.001000, loss: 1.0486
2022-02-22 04:04:13 - train: epoch 0086, iter [03700, 05004], lr: 0.001000, loss: 1.1964
2022-02-22 04:04:49 - train: epoch 0086, iter [03800, 05004], lr: 0.001000, loss: 1.0682
2022-02-22 04:05:27 - train: epoch 0086, iter [03900, 05004], lr: 0.001000, loss: 1.1774
2022-02-22 04:06:04 - train: epoch 0086, iter [04000, 05004], lr: 0.001000, loss: 1.0905
2022-02-22 04:06:41 - train: epoch 0086, iter [04100, 05004], lr: 0.001000, loss: 1.1426
2022-02-22 04:07:19 - train: epoch 0086, iter [04200, 05004], lr: 0.001000, loss: 1.1216
2022-02-22 04:07:56 - train: epoch 0086, iter [04300, 05004], lr: 0.001000, loss: 1.0918
2022-02-22 04:08:34 - train: epoch 0086, iter [04400, 05004], lr: 0.001000, loss: 1.0041
2022-02-22 04:09:11 - train: epoch 0086, iter [04500, 05004], lr: 0.001000, loss: 0.9905
2022-02-22 04:09:48 - train: epoch 0086, iter [04600, 05004], lr: 0.001000, loss: 0.9928
2022-02-22 04:10:26 - train: epoch 0086, iter [04700, 05004], lr: 0.001000, loss: 1.0417
2022-02-22 04:11:04 - train: epoch 0086, iter [04800, 05004], lr: 0.001000, loss: 1.1055
2022-02-22 04:11:41 - train: epoch 0086, iter [04900, 05004], lr: 0.001000, loss: 1.0981
2022-02-22 04:12:17 - train: epoch 0086, iter [05000, 05004], lr: 0.001000, loss: 1.0420
2022-02-22 04:12:18 - train: epoch 086, train_loss: 1.0582
2022-02-22 04:13:37 - eval: epoch: 086, acc1: 73.328%, acc5: 91.498%, test_loss: 1.0616, per_image_load_time: 0.960ms, per_image_inference_time: 0.283ms
2022-02-22 04:13:38 - until epoch: 086, best_acc1: 73.460%
2022-02-22 04:13:38 - epoch 087 lr: 0.0010000000000000002
2022-02-22 04:14:18 - train: epoch 0087, iter [00100, 05004], lr: 0.001000, loss: 1.1477
2022-02-22 04:14:56 - train: epoch 0087, iter [00200, 05004], lr: 0.001000, loss: 0.9286
2022-02-22 04:15:36 - train: epoch 0087, iter [00300, 05004], lr: 0.001000, loss: 1.1180
2022-02-22 04:16:13 - train: epoch 0087, iter [00400, 05004], lr: 0.001000, loss: 1.2495
2022-02-22 04:16:51 - train: epoch 0087, iter [00500, 05004], lr: 0.001000, loss: 0.8338
2022-02-22 04:17:29 - train: epoch 0087, iter [00600, 05004], lr: 0.001000, loss: 1.0728
2022-02-22 04:18:06 - train: epoch 0087, iter [00700, 05004], lr: 0.001000, loss: 0.8150
2022-02-22 04:18:45 - train: epoch 0087, iter [00800, 05004], lr: 0.001000, loss: 1.1618
2022-02-22 04:19:22 - train: epoch 0087, iter [00900, 05004], lr: 0.001000, loss: 1.0804
2022-02-22 04:19:59 - train: epoch 0087, iter [01000, 05004], lr: 0.001000, loss: 0.9959
2022-02-22 04:20:35 - train: epoch 0087, iter [01100, 05004], lr: 0.001000, loss: 1.0339
2022-02-22 04:21:13 - train: epoch 0087, iter [01200, 05004], lr: 0.001000, loss: 1.1616
2022-02-22 04:21:52 - train: epoch 0087, iter [01300, 05004], lr: 0.001000, loss: 1.1097
2022-02-22 04:22:29 - train: epoch 0087, iter [01400, 05004], lr: 0.001000, loss: 1.0357
2022-02-22 04:23:06 - train: epoch 0087, iter [01500, 05004], lr: 0.001000, loss: 0.9227
2022-02-22 04:23:43 - train: epoch 0087, iter [01600, 05004], lr: 0.001000, loss: 0.9224
2022-02-22 04:24:20 - train: epoch 0087, iter [01700, 05004], lr: 0.001000, loss: 1.2530
2022-02-22 04:24:58 - train: epoch 0087, iter [01800, 05004], lr: 0.001000, loss: 1.0601
2022-02-22 04:25:35 - train: epoch 0087, iter [01900, 05004], lr: 0.001000, loss: 1.1516
2022-02-22 04:26:13 - train: epoch 0087, iter [02000, 05004], lr: 0.001000, loss: 1.0592
2022-02-22 04:26:50 - train: epoch 0087, iter [02100, 05004], lr: 0.001000, loss: 1.1624
2022-02-22 04:27:27 - train: epoch 0087, iter [02200, 05004], lr: 0.001000, loss: 1.0996
2022-02-22 04:28:06 - train: epoch 0087, iter [02300, 05004], lr: 0.001000, loss: 1.1734
2022-02-22 04:28:42 - train: epoch 0087, iter [02400, 05004], lr: 0.001000, loss: 1.0620
2022-02-22 04:29:20 - train: epoch 0087, iter [02500, 05004], lr: 0.001000, loss: 1.0343
2022-02-22 04:29:55 - train: epoch 0087, iter [02600, 05004], lr: 0.001000, loss: 1.1129
2022-02-22 04:30:32 - train: epoch 0087, iter [02700, 05004], lr: 0.001000, loss: 1.0181
2022-02-22 04:31:10 - train: epoch 0087, iter [02800, 05004], lr: 0.001000, loss: 0.8952
2022-02-22 04:31:47 - train: epoch 0087, iter [02900, 05004], lr: 0.001000, loss: 0.9563
2022-02-22 04:32:25 - train: epoch 0087, iter [03000, 05004], lr: 0.001000, loss: 1.0450
2022-02-22 04:33:02 - train: epoch 0087, iter [03100, 05004], lr: 0.001000, loss: 1.0516
2022-02-22 04:33:40 - train: epoch 0087, iter [03200, 05004], lr: 0.001000, loss: 1.0521
2022-02-22 04:34:18 - train: epoch 0087, iter [03300, 05004], lr: 0.001000, loss: 1.0182
2022-02-22 04:34:54 - train: epoch 0087, iter [03400, 05004], lr: 0.001000, loss: 1.1523
2022-02-22 04:35:32 - train: epoch 0087, iter [03500, 05004], lr: 0.001000, loss: 0.9670
2022-02-22 04:36:09 - train: epoch 0087, iter [03600, 05004], lr: 0.001000, loss: 0.9442
2022-02-22 04:36:47 - train: epoch 0087, iter [03700, 05004], lr: 0.001000, loss: 1.0242
2022-02-22 04:37:23 - train: epoch 0087, iter [03800, 05004], lr: 0.001000, loss: 1.0092
2022-02-22 04:38:01 - train: epoch 0087, iter [03900, 05004], lr: 0.001000, loss: 1.1112
2022-02-22 04:38:38 - train: epoch 0087, iter [04000, 05004], lr: 0.001000, loss: 1.1454
2022-02-22 04:39:15 - train: epoch 0087, iter [04100, 05004], lr: 0.001000, loss: 1.1581
2022-02-22 04:39:53 - train: epoch 0087, iter [04200, 05004], lr: 0.001000, loss: 1.1378
2022-02-22 04:40:31 - train: epoch 0087, iter [04300, 05004], lr: 0.001000, loss: 1.0764
2022-02-22 04:41:08 - train: epoch 0087, iter [04400, 05004], lr: 0.001000, loss: 1.1382
2022-02-22 04:41:45 - train: epoch 0087, iter [04500, 05004], lr: 0.001000, loss: 1.2174
2022-02-22 04:42:22 - train: epoch 0087, iter [04600, 05004], lr: 0.001000, loss: 1.1023
2022-02-22 04:42:59 - train: epoch 0087, iter [04700, 05004], lr: 0.001000, loss: 1.0049
2022-02-22 04:43:38 - train: epoch 0087, iter [04800, 05004], lr: 0.001000, loss: 1.0513
2022-02-22 04:44:14 - train: epoch 0087, iter [04900, 05004], lr: 0.001000, loss: 0.9748
2022-02-22 04:44:51 - train: epoch 0087, iter [05000, 05004], lr: 0.001000, loss: 1.0290
2022-02-22 04:44:52 - train: epoch 087, train_loss: 1.0557
2022-02-22 04:46:15 - eval: epoch: 087, acc1: 73.464%, acc5: 91.508%, test_loss: 1.0579, per_image_load_time: 1.316ms, per_image_inference_time: 0.280ms
2022-02-22 04:46:16 - until epoch: 087, best_acc1: 73.464%
2022-02-22 04:46:16 - epoch 088 lr: 0.0010000000000000002
2022-02-22 04:46:59 - train: epoch 0088, iter [00100, 05004], lr: 0.001000, loss: 1.0680
2022-02-22 04:47:36 - train: epoch 0088, iter [00200, 05004], lr: 0.001000, loss: 0.9788
2022-02-22 04:48:12 - train: epoch 0088, iter [00300, 05004], lr: 0.001000, loss: 1.1318
2022-02-22 04:48:51 - train: epoch 0088, iter [00400, 05004], lr: 0.001000, loss: 1.0830
2022-02-22 04:49:27 - train: epoch 0088, iter [00500, 05004], lr: 0.001000, loss: 0.9404
2022-02-22 04:50:06 - train: epoch 0088, iter [00600, 05004], lr: 0.001000, loss: 1.0198
2022-02-22 04:50:43 - train: epoch 0088, iter [00700, 05004], lr: 0.001000, loss: 1.0488
2022-02-22 04:51:20 - train: epoch 0088, iter [00800, 05004], lr: 0.001000, loss: 1.0793
2022-02-22 04:51:57 - train: epoch 0088, iter [00900, 05004], lr: 0.001000, loss: 1.1177
2022-02-22 04:52:34 - train: epoch 0088, iter [01000, 05004], lr: 0.001000, loss: 0.9988
2022-02-22 04:53:13 - train: epoch 0088, iter [01100, 05004], lr: 0.001000, loss: 1.0310
2022-02-22 04:53:50 - train: epoch 0088, iter [01200, 05004], lr: 0.001000, loss: 1.0125
2022-02-22 04:54:28 - train: epoch 0088, iter [01300, 05004], lr: 0.001000, loss: 1.1691
2022-02-22 04:55:04 - train: epoch 0088, iter [01400, 05004], lr: 0.001000, loss: 1.0549
2022-02-22 04:55:42 - train: epoch 0088, iter [01500, 05004], lr: 0.001000, loss: 1.0459
2022-02-22 04:56:18 - train: epoch 0088, iter [01600, 05004], lr: 0.001000, loss: 0.8586
2022-02-22 04:56:56 - train: epoch 0088, iter [01700, 05004], lr: 0.001000, loss: 1.1286
2022-02-22 04:57:35 - train: epoch 0088, iter [01800, 05004], lr: 0.001000, loss: 1.0218
2022-02-22 04:58:12 - train: epoch 0088, iter [01900, 05004], lr: 0.001000, loss: 1.0771
2022-02-22 04:58:49 - train: epoch 0088, iter [02000, 05004], lr: 0.001000, loss: 0.9849
2022-02-22 04:59:26 - train: epoch 0088, iter [02100, 05004], lr: 0.001000, loss: 1.0561
2022-02-22 05:00:03 - train: epoch 0088, iter [02200, 05004], lr: 0.001000, loss: 0.9131
2022-02-22 05:00:40 - train: epoch 0088, iter [02300, 05004], lr: 0.001000, loss: 0.8585
2022-02-22 05:01:19 - train: epoch 0088, iter [02400, 05004], lr: 0.001000, loss: 1.1156
2022-02-22 05:01:56 - train: epoch 0088, iter [02500, 05004], lr: 0.001000, loss: 1.1301
2022-02-22 05:02:32 - train: epoch 0088, iter [02600, 05004], lr: 0.001000, loss: 1.1394
2022-02-22 05:03:10 - train: epoch 0088, iter [02700, 05004], lr: 0.001000, loss: 1.1220
2022-02-22 05:03:48 - train: epoch 0088, iter [02800, 05004], lr: 0.001000, loss: 1.0654
2022-02-22 05:04:26 - train: epoch 0088, iter [02900, 05004], lr: 0.001000, loss: 1.0164
2022-02-22 05:05:03 - train: epoch 0088, iter [03000, 05004], lr: 0.001000, loss: 1.1705
2022-02-22 05:05:40 - train: epoch 0088, iter [03100, 05004], lr: 0.001000, loss: 1.0034
2022-02-22 05:06:18 - train: epoch 0088, iter [03200, 05004], lr: 0.001000, loss: 0.9354
2022-02-22 05:06:55 - train: epoch 0088, iter [03300, 05004], lr: 0.001000, loss: 1.0201
2022-02-22 05:07:33 - train: epoch 0088, iter [03400, 05004], lr: 0.001000, loss: 0.9061
2022-02-22 05:08:10 - train: epoch 0088, iter [03500, 05004], lr: 0.001000, loss: 1.0016
2022-02-22 05:08:49 - train: epoch 0088, iter [03600, 05004], lr: 0.001000, loss: 1.0465
