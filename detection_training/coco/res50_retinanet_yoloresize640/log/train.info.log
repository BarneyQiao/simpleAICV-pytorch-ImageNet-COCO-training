2022-04-23 20:13:23 - network: resnet50_retinanet
2022-04-23 20:13:23 - num_classes: 80
2022-04-23 20:13:23 - input_image_size: [640, 640]
2022-04-23 20:13:23 - backbone_pretrained_path: /root/code/simpleAICV-pytorch-ImageNet-COCO-training/pretrained_models/resnet/resnet50-acc76.322.pth
2022-04-23 20:13:23 - trained_model_path: 
2022-04-23 20:13:23 - criterion: RetinaLoss()
2022-04-23 20:13:23 - decoder: <simpleAICV.detection.decode.RetinaDecoder object at 0x7f7f61b26970>
2022-04-23 20:13:23 - train_dataset: <simpleAICV.detection.datasets.cocodataset.CocoDetection object at 0x7f7f61b26cd0>
2022-04-23 20:13:23 - val_dataset: <simpleAICV.detection.datasets.cocodataset.CocoDetection object at 0x7f7f6cb8eee0>
2022-04-23 20:13:23 - collater: <simpleAICV.detection.common.DetectionCollater object at 0x7f7f6cb8eeb0>
2022-04-23 20:13:23 - seed: 0
2022-04-23 20:13:23 - batch_size: 32
2022-04-23 20:13:23 - num_workers: 4
2022-04-23 20:13:23 - optimizer: ('AdamW', {'lr': 0.0001, 'weight_decay': 0.001})
2022-04-23 20:13:23 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [8, 12]})
2022-04-23 20:13:23 - epochs: 13
2022-04-23 20:13:23 - eval_epoch: [1, 3, 5, 8, 10, 12, 13]
2022-04-23 20:13:23 - print_interval: 100
2022-04-23 20:13:23 - eval_type: COCO
2022-04-23 20:13:23 - eval_voc_iou_threshold_list: [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]
2022-04-23 20:13:23 - save_model_metric: IoU=0.50:0.95,area=all,maxDets=100,mAP
2022-04-23 20:13:23 - sync_bn: False
2022-04-23 20:13:23 - apex: True
2022-04-23 20:13:23 - gpus_type: NVIDIA RTX A5000
2022-04-23 20:13:23 - gpus_num: 2
2022-04-23 20:13:23 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f7f2a1ddd30>
2022-04-23 20:13:23 - --------------------parameters--------------------
2022-04-23 20:13:23 - name: backbone.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.0.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.0.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.0.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.0.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.0.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.0.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.0.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.0.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.0.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.0.downsample_conv.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.0.downsample_conv.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.0.downsample_conv.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.1.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.1.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.1.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.1.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.1.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.1.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.1.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.1.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.1.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.2.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.2.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.2.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.2.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.2.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.2.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.2.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.2.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer1.2.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.0.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.0.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.0.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.0.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.0.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.0.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.0.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.0.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.0.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.0.downsample_conv.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.0.downsample_conv.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.0.downsample_conv.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.1.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.1.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.1.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.1.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.1.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.1.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.1.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.1.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.1.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.2.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.2.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.2.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.2.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.2.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.2.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.2.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.2.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.2.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.3.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.3.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.3.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.3.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.3.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.3.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.3.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.3.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer2.3.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.0.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.0.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.0.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.0.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.0.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.0.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.0.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.0.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.0.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.0.downsample_conv.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.0.downsample_conv.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.0.downsample_conv.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.1.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.1.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.1.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.1.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.1.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.1.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.1.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.1.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.1.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.2.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.2.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.2.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.2.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.2.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.2.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.2.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.2.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.2.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.3.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.3.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.3.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.3.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.3.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.3.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.3.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.3.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.3.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.4.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.4.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.4.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.4.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.4.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.4.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.4.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.4.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.4.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.5.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.5.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.5.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.5.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.5.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.5.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.5.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.5.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer3.5.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.0.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.0.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.0.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.0.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.0.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.0.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.0.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.0.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.0.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.0.downsample_conv.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.0.downsample_conv.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.0.downsample_conv.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.1.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.1.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.1.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.1.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.1.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.1.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.1.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.1.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.1.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.2.conv1.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.2.conv1.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.2.conv1.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.2.conv2.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.2.conv2.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.2.conv2.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.2.conv3.layer.0.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.2.conv3.layer.1.weight, grad: True
2022-04-23 20:13:23 - name: backbone.layer4.2.conv3.layer.1.bias, grad: True
2022-04-23 20:13:23 - name: fpn.P3_1.weight, grad: True
2022-04-23 20:13:23 - name: fpn.P3_1.bias, grad: True
2022-04-23 20:13:23 - name: fpn.P3_2.weight, grad: True
2022-04-23 20:13:23 - name: fpn.P3_2.bias, grad: True
2022-04-23 20:13:23 - name: fpn.P4_1.weight, grad: True
2022-04-23 20:13:23 - name: fpn.P4_1.bias, grad: True
2022-04-23 20:13:23 - name: fpn.P4_2.weight, grad: True
2022-04-23 20:13:23 - name: fpn.P4_2.bias, grad: True
2022-04-23 20:13:23 - name: fpn.P5_1.weight, grad: True
2022-04-23 20:13:23 - name: fpn.P5_1.bias, grad: True
2022-04-23 20:13:23 - name: fpn.P5_2.weight, grad: True
2022-04-23 20:13:23 - name: fpn.P5_2.bias, grad: True
2022-04-23 20:13:23 - name: fpn.P6.weight, grad: True
2022-04-23 20:13:23 - name: fpn.P6.bias, grad: True
2022-04-23 20:13:23 - name: fpn.P7.1.weight, grad: True
2022-04-23 20:13:23 - name: fpn.P7.1.bias, grad: True
2022-04-23 20:13:23 - name: cls_head.cls_head.0.weight, grad: True
2022-04-23 20:13:23 - name: cls_head.cls_head.0.bias, grad: True
2022-04-23 20:13:23 - name: cls_head.cls_head.2.weight, grad: True
2022-04-23 20:13:23 - name: cls_head.cls_head.2.bias, grad: True
2022-04-23 20:13:23 - name: cls_head.cls_head.4.weight, grad: True
2022-04-23 20:13:23 - name: cls_head.cls_head.4.bias, grad: True
2022-04-23 20:13:23 - name: cls_head.cls_head.6.weight, grad: True
2022-04-23 20:13:23 - name: cls_head.cls_head.6.bias, grad: True
2022-04-23 20:13:23 - name: cls_head.cls_out.weight, grad: True
2022-04-23 20:13:23 - name: cls_head.cls_out.bias, grad: True
2022-04-23 20:13:23 - name: reg_head.reg_head.0.weight, grad: True
2022-04-23 20:13:23 - name: reg_head.reg_head.0.bias, grad: True
2022-04-23 20:13:23 - name: reg_head.reg_head.2.weight, grad: True
2022-04-23 20:13:23 - name: reg_head.reg_head.2.bias, grad: True
2022-04-23 20:13:23 - name: reg_head.reg_head.4.weight, grad: True
2022-04-23 20:13:23 - name: reg_head.reg_head.4.bias, grad: True
2022-04-23 20:13:23 - name: reg_head.reg_head.6.weight, grad: True
2022-04-23 20:13:23 - name: reg_head.reg_head.6.bias, grad: True
2022-04-23 20:13:23 - name: reg_head.reg_out.weight, grad: True
2022-04-23 20:13:23 - name: reg_head.reg_out.bias, grad: True
2022-04-23 20:13:23 - --------------------buffers--------------------
2022-04-23 20:13:23 - name: backbone.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.0.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.0.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.0.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.0.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.0.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.0.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.0.downsample_conv.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.1.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.1.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.1.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.1.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.1.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.1.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.2.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.2.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.2.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.2.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.2.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.2.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer1.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.0.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.0.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.0.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.0.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.0.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.0.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.1.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.1.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.1.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.1.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.1.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.1.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.2.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.2.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.2.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.2.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.2.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.2.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.3.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.3.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.3.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.3.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.3.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.3.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer2.3.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.0.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.0.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.0.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.0.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.0.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.0.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.1.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.1.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.1.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.1.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.1.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.1.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.2.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.2.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.2.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.2.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.2.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.2.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.3.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.3.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.3.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.3.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.3.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.3.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.3.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.4.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.4.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.4.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.4.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.4.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.4.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.4.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.5.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.5.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.5.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.5.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.5.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.5.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer3.5.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.0.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.0.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.0.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.0.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.0.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.0.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.1.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.1.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.1.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.1.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.1.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.1.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.2.conv1.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.2.conv1.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.2.conv2.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.2.conv2.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.2.conv3.layer.1.running_mean, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.2.conv3.layer.1.running_var, grad: False
2022-04-23 20:13:23 - name: backbone.layer4.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-23 20:13:23 - epoch 001 lr: 0.0001
2022-04-23 20:14:02 - train: epoch 0001, iter [00100, 03664], lr: 0.000100, total_loss: 1.1330, cls_loss: 0.7500, reg_loss: 0.3831
2022-04-23 20:14:40 - train: epoch 0001, iter [00200, 03664], lr: 0.000100, total_loss: 1.1512, cls_loss: 0.7915, reg_loss: 0.3597
2022-04-23 20:15:19 - train: epoch 0001, iter [00300, 03664], lr: 0.000100, total_loss: 0.9391, cls_loss: 0.6282, reg_loss: 0.3109
2022-04-23 20:15:59 - train: epoch 0001, iter [00400, 03664], lr: 0.000100, total_loss: 0.9346, cls_loss: 0.6256, reg_loss: 0.3090
2022-04-23 20:16:37 - train: epoch 0001, iter [00500, 03664], lr: 0.000100, total_loss: 0.8896, cls_loss: 0.5939, reg_loss: 0.2957
2022-04-23 20:17:14 - train: epoch 0001, iter [00600, 03664], lr: 0.000100, total_loss: 0.8659, cls_loss: 0.5912, reg_loss: 0.2747
2022-04-23 20:17:56 - train: epoch 0001, iter [00700, 03664], lr: 0.000100, total_loss: 0.7912, cls_loss: 0.5117, reg_loss: 0.2794
2022-04-23 20:18:34 - train: epoch 0001, iter [00800, 03664], lr: 0.000100, total_loss: 0.8209, cls_loss: 0.5236, reg_loss: 0.2973
2022-04-23 20:19:11 - train: epoch 0001, iter [00900, 03664], lr: 0.000100, total_loss: 0.7949, cls_loss: 0.5356, reg_loss: 0.2593
2022-04-23 20:19:49 - train: epoch 0001, iter [01000, 03664], lr: 0.000100, total_loss: 0.7735, cls_loss: 0.4863, reg_loss: 0.2872
2022-04-23 20:20:30 - train: epoch 0001, iter [01100, 03664], lr: 0.000100, total_loss: 0.6872, cls_loss: 0.4241, reg_loss: 0.2631
2022-04-23 20:21:08 - train: epoch 0001, iter [01200, 03664], lr: 0.000100, total_loss: 0.7416, cls_loss: 0.4915, reg_loss: 0.2501
2022-04-23 20:21:45 - train: epoch 0001, iter [01300, 03664], lr: 0.000100, total_loss: 0.7695, cls_loss: 0.5121, reg_loss: 0.2574
2022-04-23 20:22:23 - train: epoch 0001, iter [01400, 03664], lr: 0.000100, total_loss: 0.7093, cls_loss: 0.4761, reg_loss: 0.2332
2022-04-23 20:23:05 - train: epoch 0001, iter [01500, 03664], lr: 0.000100, total_loss: 0.6575, cls_loss: 0.4148, reg_loss: 0.2426
2022-04-23 20:23:42 - train: epoch 0001, iter [01600, 03664], lr: 0.000100, total_loss: 0.6995, cls_loss: 0.4482, reg_loss: 0.2513
2022-04-23 20:24:20 - train: epoch 0001, iter [01700, 03664], lr: 0.000100, total_loss: 0.6935, cls_loss: 0.4366, reg_loss: 0.2569
2022-04-23 20:24:59 - train: epoch 0001, iter [01800, 03664], lr: 0.000100, total_loss: 0.6974, cls_loss: 0.4611, reg_loss: 0.2362
2022-04-23 20:25:39 - train: epoch 0001, iter [01900, 03664], lr: 0.000100, total_loss: 0.6727, cls_loss: 0.4215, reg_loss: 0.2513
2022-04-23 20:26:16 - train: epoch 0001, iter [02000, 03664], lr: 0.000100, total_loss: 0.6440, cls_loss: 0.3990, reg_loss: 0.2449
2022-04-23 20:26:54 - train: epoch 0001, iter [02100, 03664], lr: 0.000100, total_loss: 0.6596, cls_loss: 0.4129, reg_loss: 0.2468
2022-04-23 20:27:35 - train: epoch 0001, iter [02200, 03664], lr: 0.000100, total_loss: 0.6625, cls_loss: 0.3997, reg_loss: 0.2628
2022-04-23 20:28:12 - train: epoch 0001, iter [02300, 03664], lr: 0.000100, total_loss: 0.6636, cls_loss: 0.4113, reg_loss: 0.2523
2022-04-23 20:28:50 - train: epoch 0001, iter [02400, 03664], lr: 0.000100, total_loss: 0.6590, cls_loss: 0.4136, reg_loss: 0.2455
2022-04-23 20:29:29 - train: epoch 0001, iter [02500, 03664], lr: 0.000100, total_loss: 0.5717, cls_loss: 0.3422, reg_loss: 0.2296
2022-04-23 20:30:09 - train: epoch 0001, iter [02600, 03664], lr: 0.000100, total_loss: 0.6610, cls_loss: 0.4121, reg_loss: 0.2490
2022-04-23 20:30:46 - train: epoch 0001, iter [02700, 03664], lr: 0.000100, total_loss: 0.6189, cls_loss: 0.3842, reg_loss: 0.2347
2022-04-23 20:31:25 - train: epoch 0001, iter [02800, 03664], lr: 0.000100, total_loss: 0.6529, cls_loss: 0.4337, reg_loss: 0.2192
2022-04-23 20:32:04 - train: epoch 0001, iter [02900, 03664], lr: 0.000100, total_loss: 0.6386, cls_loss: 0.3982, reg_loss: 0.2404
2022-04-23 20:32:42 - train: epoch 0001, iter [03000, 03664], lr: 0.000100, total_loss: 0.6318, cls_loss: 0.3878, reg_loss: 0.2440
2022-04-23 20:33:19 - train: epoch 0001, iter [03100, 03664], lr: 0.000100, total_loss: 0.6118, cls_loss: 0.3859, reg_loss: 0.2259
2022-04-23 20:33:59 - train: epoch 0001, iter [03200, 03664], lr: 0.000100, total_loss: 0.5825, cls_loss: 0.3593, reg_loss: 0.2231
2022-04-23 20:34:38 - train: epoch 0001, iter [03300, 03664], lr: 0.000100, total_loss: 0.6184, cls_loss: 0.3772, reg_loss: 0.2412
2022-04-23 20:35:15 - train: epoch 0001, iter [03400, 03664], lr: 0.000100, total_loss: 0.6074, cls_loss: 0.3679, reg_loss: 0.2395
2022-04-23 20:35:55 - train: epoch 0001, iter [03500, 03664], lr: 0.000100, total_loss: 0.6297, cls_loss: 0.3926, reg_loss: 0.2371
2022-04-23 20:36:34 - train: epoch 0001, iter [03600, 03664], lr: 0.000100, total_loss: 0.6582, cls_loss: 0.4172, reg_loss: 0.2410
2022-04-23 20:36:59 - train: epoch 001, train_loss: 0.7419
2022-04-23 20:41:23 - eval: epoch: 001
per_image_load_time: 1.631ms
per_image_inference_time: 43.889ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 16.31783838139606
IoU=0.50,area=all,maxDets=100,mAP: 28.141297193180147
IoU=0.75,area=all,maxDets=100,mAP: 16.631130421553276
IoU=0.50:0.95,area=small,maxDets=100,mAP: 5.9145050307913465
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 18.830254717939916
IoU=0.50:0.95,area=large,maxDets=100,mAP: 22.693682409850286
IoU=0.50:0.95,area=all,maxDets=1,mAR: 16.514351513799078
IoU=0.50:0.95,area=all,maxDets=10,mAR: 25.311902094606882
IoU=0.50:0.95,area=all,maxDets=100,mAR: 26.466915095371334
IoU=0.50:0.95,area=small,maxDets=100,mAR: 8.027767127460477
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 29.82871699294764
IoU=0.50:0.95,area=large,maxDets=100,mAR: 36.721577297364135

2022-04-23 20:41:23 - until epoch: 001, best_metric: 16.318%
2022-04-23 20:41:23 - epoch 002 lr: 0.0001
2022-04-23 20:42:05 - train: epoch 0002, iter [00100, 03664], lr: 0.000100, total_loss: 0.6925, cls_loss: 0.4502, reg_loss: 0.2422
2022-04-23 20:42:45 - train: epoch 0002, iter [00200, 03664], lr: 0.000100, total_loss: 0.5363, cls_loss: 0.3317, reg_loss: 0.2046
2022-04-23 20:43:23 - train: epoch 0002, iter [00300, 03664], lr: 0.000100, total_loss: 0.5463, cls_loss: 0.3180, reg_loss: 0.2283
2022-04-23 20:44:03 - train: epoch 0002, iter [00400, 03664], lr: 0.000100, total_loss: 0.5720, cls_loss: 0.3507, reg_loss: 0.2213
2022-04-23 20:44:40 - train: epoch 0002, iter [00500, 03664], lr: 0.000100, total_loss: 0.5782, cls_loss: 0.3503, reg_loss: 0.2278
2022-04-23 20:45:20 - train: epoch 0002, iter [00600, 03664], lr: 0.000100, total_loss: 0.5787, cls_loss: 0.3556, reg_loss: 0.2231
2022-04-23 20:45:59 - train: epoch 0002, iter [00700, 03664], lr: 0.000100, total_loss: 0.6478, cls_loss: 0.3991, reg_loss: 0.2488
2022-04-23 20:46:37 - train: epoch 0002, iter [00800, 03664], lr: 0.000100, total_loss: 0.6296, cls_loss: 0.3874, reg_loss: 0.2421
2022-04-23 20:47:16 - train: epoch 0002, iter [00900, 03664], lr: 0.000100, total_loss: 0.5996, cls_loss: 0.3576, reg_loss: 0.2421
2022-04-23 20:47:53 - train: epoch 0002, iter [01000, 03664], lr: 0.000100, total_loss: 0.5879, cls_loss: 0.3581, reg_loss: 0.2298
2022-04-23 20:48:33 - train: epoch 0002, iter [01100, 03664], lr: 0.000100, total_loss: 0.5931, cls_loss: 0.3760, reg_loss: 0.2170
2022-04-23 20:49:10 - train: epoch 0002, iter [01200, 03664], lr: 0.000100, total_loss: 0.7345, cls_loss: 0.4848, reg_loss: 0.2497
2022-04-23 20:49:50 - train: epoch 0002, iter [01300, 03664], lr: 0.000100, total_loss: 0.5472, cls_loss: 0.3200, reg_loss: 0.2272
2022-04-23 20:50:29 - train: epoch 0002, iter [01400, 03664], lr: 0.000100, total_loss: 0.5618, cls_loss: 0.3379, reg_loss: 0.2239
2022-04-23 20:51:07 - train: epoch 0002, iter [01500, 03664], lr: 0.000100, total_loss: 0.5243, cls_loss: 0.3205, reg_loss: 0.2038
2022-04-23 20:51:45 - train: epoch 0002, iter [01600, 03664], lr: 0.000100, total_loss: 0.5919, cls_loss: 0.3735, reg_loss: 0.2184
2022-04-23 20:52:25 - train: epoch 0002, iter [01700, 03664], lr: 0.000100, total_loss: 0.6339, cls_loss: 0.4054, reg_loss: 0.2286
2022-04-23 20:53:02 - train: epoch 0002, iter [01800, 03664], lr: 0.000100, total_loss: 0.5791, cls_loss: 0.3496, reg_loss: 0.2295
2022-04-23 20:53:42 - train: epoch 0002, iter [01900, 03664], lr: 0.000100, total_loss: 0.5868, cls_loss: 0.3581, reg_loss: 0.2287
2022-04-23 20:54:22 - train: epoch 0002, iter [02000, 03664], lr: 0.000100, total_loss: 0.5397, cls_loss: 0.3201, reg_loss: 0.2196
2022-04-23 20:55:00 - train: epoch 0002, iter [02100, 03664], lr: 0.000100, total_loss: 0.5808, cls_loss: 0.3582, reg_loss: 0.2226
2022-04-23 20:55:38 - train: epoch 0002, iter [02200, 03664], lr: 0.000100, total_loss: 0.5114, cls_loss: 0.2962, reg_loss: 0.2152
2022-04-23 20:56:18 - train: epoch 0002, iter [02300, 03664], lr: 0.000100, total_loss: 0.6155, cls_loss: 0.3835, reg_loss: 0.2320
2022-04-23 20:56:58 - train: epoch 0002, iter [02400, 03664], lr: 0.000100, total_loss: 0.5029, cls_loss: 0.3089, reg_loss: 0.1940
2022-04-23 20:57:36 - train: epoch 0002, iter [02500, 03664], lr: 0.000100, total_loss: 0.5045, cls_loss: 0.2936, reg_loss: 0.2109
2022-04-23 20:58:16 - train: epoch 0002, iter [02600, 03664], lr: 0.000100, total_loss: 0.5108, cls_loss: 0.3101, reg_loss: 0.2007
2022-04-23 20:58:54 - train: epoch 0002, iter [02700, 03664], lr: 0.000100, total_loss: 0.5419, cls_loss: 0.3310, reg_loss: 0.2109
2022-04-23 20:59:33 - train: epoch 0002, iter [02800, 03664], lr: 0.000100, total_loss: 0.5891, cls_loss: 0.3630, reg_loss: 0.2261
2022-04-23 21:00:11 - train: epoch 0002, iter [02900, 03664], lr: 0.000100, total_loss: 0.6121, cls_loss: 0.3846, reg_loss: 0.2275
2022-04-23 21:00:51 - train: epoch 0002, iter [03000, 03664], lr: 0.000100, total_loss: 0.5397, cls_loss: 0.3202, reg_loss: 0.2195
2022-04-23 21:01:29 - train: epoch 0002, iter [03100, 03664], lr: 0.000100, total_loss: 0.5359, cls_loss: 0.3130, reg_loss: 0.2229
2022-04-23 21:02:09 - train: epoch 0002, iter [03200, 03664], lr: 0.000100, total_loss: 0.5765, cls_loss: 0.3661, reg_loss: 0.2104
2022-04-23 21:02:47 - train: epoch 0002, iter [03300, 03664], lr: 0.000100, total_loss: 0.5551, cls_loss: 0.3404, reg_loss: 0.2147
2022-04-23 21:03:27 - train: epoch 0002, iter [03400, 03664], lr: 0.000100, total_loss: 0.5328, cls_loss: 0.3216, reg_loss: 0.2112
2022-04-23 21:04:07 - train: epoch 0002, iter [03500, 03664], lr: 0.000100, total_loss: 0.5828, cls_loss: 0.3641, reg_loss: 0.2186
2022-04-23 21:04:45 - train: epoch 0002, iter [03600, 03664], lr: 0.000100, total_loss: 0.5128, cls_loss: 0.3129, reg_loss: 0.1999
2022-04-23 21:05:10 - train: epoch 002, train_loss: 0.5682
2022-04-23 21:05:11 - until epoch: 002, best_metric: 16.318%
2022-04-23 21:05:11 - epoch 003 lr: 0.0001
2022-04-23 21:05:50 - train: epoch 0003, iter [00100, 03664], lr: 0.000100, total_loss: 0.5229, cls_loss: 0.3121, reg_loss: 0.2108
2022-04-23 21:06:28 - train: epoch 0003, iter [00200, 03664], lr: 0.000100, total_loss: 0.6077, cls_loss: 0.3802, reg_loss: 0.2275
2022-04-23 21:07:07 - train: epoch 0003, iter [00300, 03664], lr: 0.000100, total_loss: 0.5483, cls_loss: 0.3022, reg_loss: 0.2461
2022-04-23 21:07:45 - train: epoch 0003, iter [00400, 03664], lr: 0.000100, total_loss: 0.5733, cls_loss: 0.3419, reg_loss: 0.2314
2022-04-23 21:08:23 - train: epoch 0003, iter [00500, 03664], lr: 0.000100, total_loss: 0.5970, cls_loss: 0.3499, reg_loss: 0.2471
2022-04-23 21:09:00 - train: epoch 0003, iter [00600, 03664], lr: 0.000100, total_loss: 0.4616, cls_loss: 0.2678, reg_loss: 0.1938
2022-04-23 21:09:39 - train: epoch 0003, iter [00700, 03664], lr: 0.000100, total_loss: 0.5788, cls_loss: 0.3734, reg_loss: 0.2054
2022-04-23 21:10:18 - train: epoch 0003, iter [00800, 03664], lr: 0.000100, total_loss: 0.5611, cls_loss: 0.3382, reg_loss: 0.2229
2022-04-23 21:10:56 - train: epoch 0003, iter [00900, 03664], lr: 0.000100, total_loss: 0.5248, cls_loss: 0.3177, reg_loss: 0.2071
2022-04-23 21:11:35 - train: epoch 0003, iter [01000, 03664], lr: 0.000100, total_loss: 0.4920, cls_loss: 0.2898, reg_loss: 0.2022
2022-04-23 21:12:14 - train: epoch 0003, iter [01100, 03664], lr: 0.000100, total_loss: 0.4610, cls_loss: 0.2693, reg_loss: 0.1917
2022-04-23 21:12:51 - train: epoch 0003, iter [01200, 03664], lr: 0.000100, total_loss: 0.5205, cls_loss: 0.3068, reg_loss: 0.2137
2022-04-23 21:13:29 - train: epoch 0003, iter [01300, 03664], lr: 0.000100, total_loss: 0.5066, cls_loss: 0.2977, reg_loss: 0.2089
2022-04-23 21:14:08 - train: epoch 0003, iter [01400, 03664], lr: 0.000100, total_loss: 0.4604, cls_loss: 0.2704, reg_loss: 0.1900
2022-04-23 21:14:48 - train: epoch 0003, iter [01500, 03664], lr: 0.000100, total_loss: 0.5232, cls_loss: 0.3062, reg_loss: 0.2170
2022-04-23 21:15:25 - train: epoch 0003, iter [01600, 03664], lr: 0.000100, total_loss: 0.4806, cls_loss: 0.2746, reg_loss: 0.2060
2022-04-23 21:16:05 - train: epoch 0003, iter [01700, 03664], lr: 0.000100, total_loss: 0.4991, cls_loss: 0.3023, reg_loss: 0.1968
2022-04-23 21:16:44 - train: epoch 0003, iter [01800, 03664], lr: 0.000100, total_loss: 0.5265, cls_loss: 0.3278, reg_loss: 0.1987
2022-04-23 21:17:21 - train: epoch 0003, iter [01900, 03664], lr: 0.000100, total_loss: 0.6045, cls_loss: 0.3770, reg_loss: 0.2275
2022-04-23 21:17:59 - train: epoch 0003, iter [02000, 03664], lr: 0.000100, total_loss: 0.4585, cls_loss: 0.2663, reg_loss: 0.1922
2022-04-23 21:18:39 - train: epoch 0003, iter [02100, 03664], lr: 0.000100, total_loss: 0.5473, cls_loss: 0.3249, reg_loss: 0.2224
2022-04-23 21:19:18 - train: epoch 0003, iter [02200, 03664], lr: 0.000100, total_loss: 0.5148, cls_loss: 0.3003, reg_loss: 0.2145
2022-04-23 21:19:55 - train: epoch 0003, iter [02300, 03664], lr: 0.000100, total_loss: 0.5735, cls_loss: 0.3527, reg_loss: 0.2208
2022-04-23 21:20:34 - train: epoch 0003, iter [02400, 03664], lr: 0.000100, total_loss: 0.4879, cls_loss: 0.2925, reg_loss: 0.1954
2022-04-23 21:21:13 - train: epoch 0003, iter [02500, 03664], lr: 0.000100, total_loss: 0.5208, cls_loss: 0.3202, reg_loss: 0.2006
2022-04-23 21:21:51 - train: epoch 0003, iter [02600, 03664], lr: 0.000100, total_loss: 0.4929, cls_loss: 0.2959, reg_loss: 0.1970
2022-04-23 21:22:30 - train: epoch 0003, iter [02700, 03664], lr: 0.000100, total_loss: 0.4958, cls_loss: 0.2985, reg_loss: 0.1973
2022-04-23 21:23:09 - train: epoch 0003, iter [02800, 03664], lr: 0.000100, total_loss: 0.5318, cls_loss: 0.3224, reg_loss: 0.2093
2022-04-23 21:23:47 - train: epoch 0003, iter [02900, 03664], lr: 0.000100, total_loss: 0.5153, cls_loss: 0.3011, reg_loss: 0.2142
2022-04-23 21:24:24 - train: epoch 0003, iter [03000, 03664], lr: 0.000100, total_loss: 0.5279, cls_loss: 0.3101, reg_loss: 0.2179
2022-04-23 21:25:03 - train: epoch 0003, iter [03100, 03664], lr: 0.000100, total_loss: 0.5168, cls_loss: 0.2926, reg_loss: 0.2242
2022-04-23 21:25:42 - train: epoch 0003, iter [03200, 03664], lr: 0.000100, total_loss: 0.4304, cls_loss: 0.2553, reg_loss: 0.1751
2022-04-23 21:26:19 - train: epoch 0003, iter [03300, 03664], lr: 0.000100, total_loss: 0.5018, cls_loss: 0.3068, reg_loss: 0.1950
2022-04-23 21:26:58 - train: epoch 0003, iter [03400, 03664], lr: 0.000100, total_loss: 0.4756, cls_loss: 0.2796, reg_loss: 0.1960
2022-04-23 21:27:36 - train: epoch 0003, iter [03500, 03664], lr: 0.000100, total_loss: 0.5232, cls_loss: 0.3060, reg_loss: 0.2171
2022-04-23 21:28:15 - train: epoch 0003, iter [03600, 03664], lr: 0.000100, total_loss: 0.4950, cls_loss: 0.3006, reg_loss: 0.1943
2022-04-23 21:28:39 - train: epoch 003, train_loss: 0.5199
2022-04-23 21:32:45 - eval: epoch: 003
per_image_load_time: 1.621ms
per_image_inference_time: 40.916ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 24.094196530290397
IoU=0.50,area=all,maxDets=100,mAP: 38.26413477828461
IoU=0.75,area=all,maxDets=100,mAP: 25.444448116276842
IoU=0.50:0.95,area=small,maxDets=100,mAP: 8.940798860063571
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 27.80900693269597
IoU=0.50:0.95,area=large,maxDets=100,mAP: 34.14246385297407
IoU=0.50:0.95,area=all,maxDets=1,mAR: 22.15617863584836
IoU=0.50:0.95,area=all,maxDets=10,mAR: 33.3557633449885
IoU=0.50:0.95,area=all,maxDets=100,mAR: 34.68864124263165
IoU=0.50:0.95,area=small,maxDets=100,mAR: 11.817261833013173
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 39.77601636748138
IoU=0.50:0.95,area=large,maxDets=100,mAR: 48.62335717336051

2022-04-23 21:32:46 - until epoch: 003, best_metric: 24.094%
2022-04-23 21:32:46 - epoch 004 lr: 0.0001
2022-04-23 21:33:26 - train: epoch 0004, iter [00100, 03664], lr: 0.000100, total_loss: 0.5790, cls_loss: 0.3446, reg_loss: 0.2344
2022-04-23 21:34:06 - train: epoch 0004, iter [00200, 03664], lr: 0.000100, total_loss: 0.4471, cls_loss: 0.2646, reg_loss: 0.1824
2022-04-23 21:34:43 - train: epoch 0004, iter [00300, 03664], lr: 0.000100, total_loss: 0.5503, cls_loss: 0.3254, reg_loss: 0.2248
2022-04-23 21:35:20 - train: epoch 0004, iter [00400, 03664], lr: 0.000100, total_loss: 0.5359, cls_loss: 0.3189, reg_loss: 0.2169
2022-04-23 21:36:01 - train: epoch 0004, iter [00500, 03664], lr: 0.000100, total_loss: 0.5191, cls_loss: 0.3205, reg_loss: 0.1986
2022-04-23 21:36:37 - train: epoch 0004, iter [00600, 03664], lr: 0.000100, total_loss: 0.4593, cls_loss: 0.2663, reg_loss: 0.1929
2022-04-23 21:37:14 - train: epoch 0004, iter [00700, 03664], lr: 0.000100, total_loss: 0.4399, cls_loss: 0.2685, reg_loss: 0.1714
2022-04-23 21:37:55 - train: epoch 0004, iter [00800, 03664], lr: 0.000100, total_loss: 0.4963, cls_loss: 0.2952, reg_loss: 0.2011
2022-04-23 21:38:32 - train: epoch 0004, iter [00900, 03664], lr: 0.000100, total_loss: 0.5131, cls_loss: 0.3189, reg_loss: 0.1942
2022-04-23 21:39:09 - train: epoch 0004, iter [01000, 03664], lr: 0.000100, total_loss: 0.5123, cls_loss: 0.3182, reg_loss: 0.1941
2022-04-23 21:39:46 - train: epoch 0004, iter [01100, 03664], lr: 0.000100, total_loss: 0.4486, cls_loss: 0.2613, reg_loss: 0.1872
2022-04-23 21:40:25 - train: epoch 0004, iter [01200, 03664], lr: 0.000100, total_loss: 0.4963, cls_loss: 0.2988, reg_loss: 0.1975
2022-04-23 21:41:02 - train: epoch 0004, iter [01300, 03664], lr: 0.000100, total_loss: 0.5068, cls_loss: 0.3072, reg_loss: 0.1996
2022-04-23 21:41:41 - train: epoch 0004, iter [01400, 03664], lr: 0.000100, total_loss: 0.5693, cls_loss: 0.3347, reg_loss: 0.2346
2022-04-23 21:42:18 - train: epoch 0004, iter [01500, 03664], lr: 0.000100, total_loss: 0.4702, cls_loss: 0.2626, reg_loss: 0.2075
2022-04-23 21:42:57 - train: epoch 0004, iter [01600, 03664], lr: 0.000100, total_loss: 0.3963, cls_loss: 0.2224, reg_loss: 0.1739
2022-04-23 21:43:34 - train: epoch 0004, iter [01700, 03664], lr: 0.000100, total_loss: 0.5633, cls_loss: 0.3506, reg_loss: 0.2128
2022-04-23 21:44:13 - train: epoch 0004, iter [01800, 03664], lr: 0.000100, total_loss: 0.4910, cls_loss: 0.2859, reg_loss: 0.2051
2022-04-23 21:44:50 - train: epoch 0004, iter [01900, 03664], lr: 0.000100, total_loss: 0.4873, cls_loss: 0.3050, reg_loss: 0.1823
2022-04-23 21:45:28 - train: epoch 0004, iter [02000, 03664], lr: 0.000100, total_loss: 0.4111, cls_loss: 0.2324, reg_loss: 0.1786
2022-04-23 21:46:07 - train: epoch 0004, iter [02100, 03664], lr: 0.000100, total_loss: 0.4343, cls_loss: 0.2548, reg_loss: 0.1796
2022-04-23 21:46:44 - train: epoch 0004, iter [02200, 03664], lr: 0.000100, total_loss: 0.5037, cls_loss: 0.3007, reg_loss: 0.2030
2022-04-23 21:47:21 - train: epoch 0004, iter [02300, 03664], lr: 0.000100, total_loss: 0.4301, cls_loss: 0.2520, reg_loss: 0.1781
2022-04-23 21:48:00 - train: epoch 0004, iter [02400, 03664], lr: 0.000100, total_loss: 0.4852, cls_loss: 0.2821, reg_loss: 0.2031
2022-04-23 21:48:39 - train: epoch 0004, iter [02500, 03664], lr: 0.000100, total_loss: 0.4503, cls_loss: 0.2585, reg_loss: 0.1918
2022-04-23 21:49:16 - train: epoch 0004, iter [02600, 03664], lr: 0.000100, total_loss: 0.4241, cls_loss: 0.2357, reg_loss: 0.1884
2022-04-23 21:49:53 - train: epoch 0004, iter [02700, 03664], lr: 0.000100, total_loss: 0.4890, cls_loss: 0.2927, reg_loss: 0.1963
2022-04-23 21:50:31 - train: epoch 0004, iter [02800, 03664], lr: 0.000100, total_loss: 0.4544, cls_loss: 0.2567, reg_loss: 0.1976
2022-04-23 21:51:10 - train: epoch 0004, iter [02900, 03664], lr: 0.000100, total_loss: 0.4576, cls_loss: 0.2572, reg_loss: 0.2004
2022-04-23 21:51:47 - train: epoch 0004, iter [03000, 03664], lr: 0.000100, total_loss: 0.4421, cls_loss: 0.2608, reg_loss: 0.1813
2022-04-23 21:52:26 - train: epoch 0004, iter [03100, 03664], lr: 0.000100, total_loss: 0.5133, cls_loss: 0.3116, reg_loss: 0.2017
2022-04-23 21:53:05 - train: epoch 0004, iter [03200, 03664], lr: 0.000100, total_loss: 0.5679, cls_loss: 0.3366, reg_loss: 0.2313
2022-04-23 21:53:42 - train: epoch 0004, iter [03300, 03664], lr: 0.000100, total_loss: 0.4314, cls_loss: 0.2514, reg_loss: 0.1800
2022-04-23 21:54:19 - train: epoch 0004, iter [03400, 03664], lr: 0.000100, total_loss: 0.5817, cls_loss: 0.3828, reg_loss: 0.1989
2022-04-23 21:54:59 - train: epoch 0004, iter [03500, 03664], lr: 0.000100, total_loss: 0.5451, cls_loss: 0.3330, reg_loss: 0.2121
2022-04-23 21:55:36 - train: epoch 0004, iter [03600, 03664], lr: 0.000100, total_loss: 0.4925, cls_loss: 0.2923, reg_loss: 0.2003
2022-04-23 21:56:00 - train: epoch 004, train_loss: 0.4919
2022-04-23 21:56:01 - until epoch: 004, best_metric: 24.094%
2022-04-23 21:56:01 - epoch 005 lr: 0.0001
2022-04-23 21:56:39 - train: epoch 0005, iter [00100, 03664], lr: 0.000100, total_loss: 0.4436, cls_loss: 0.2438, reg_loss: 0.1998
2022-04-23 21:57:19 - train: epoch 0005, iter [00200, 03664], lr: 0.000100, total_loss: 0.4622, cls_loss: 0.2701, reg_loss: 0.1921
2022-04-23 21:57:58 - train: epoch 0005, iter [00300, 03664], lr: 0.000100, total_loss: 0.4007, cls_loss: 0.2250, reg_loss: 0.1756
2022-04-23 21:58:36 - train: epoch 0005, iter [00400, 03664], lr: 0.000100, total_loss: 0.4510, cls_loss: 0.2650, reg_loss: 0.1860
2022-04-23 21:59:15 - train: epoch 0005, iter [00500, 03664], lr: 0.000100, total_loss: 0.4352, cls_loss: 0.2366, reg_loss: 0.1985
2022-04-23 21:59:54 - train: epoch 0005, iter [00600, 03664], lr: 0.000100, total_loss: 0.4732, cls_loss: 0.2803, reg_loss: 0.1929
2022-04-23 22:00:32 - train: epoch 0005, iter [00700, 03664], lr: 0.000100, total_loss: 0.4153, cls_loss: 0.2321, reg_loss: 0.1832
2022-04-23 22:01:09 - train: epoch 0005, iter [00800, 03664], lr: 0.000100, total_loss: 0.4944, cls_loss: 0.2832, reg_loss: 0.2112
2022-04-23 22:01:48 - train: epoch 0005, iter [00900, 03664], lr: 0.000100, total_loss: 0.4434, cls_loss: 0.2611, reg_loss: 0.1824
2022-04-23 22:02:27 - train: epoch 0005, iter [01000, 03664], lr: 0.000100, total_loss: 0.5142, cls_loss: 0.3276, reg_loss: 0.1867
2022-04-23 22:03:04 - train: epoch 0005, iter [01100, 03664], lr: 0.000100, total_loss: 0.4291, cls_loss: 0.2537, reg_loss: 0.1755
2022-04-23 22:03:43 - train: epoch 0005, iter [01200, 03664], lr: 0.000100, total_loss: 0.5095, cls_loss: 0.3024, reg_loss: 0.2071
2022-04-23 22:04:23 - train: epoch 0005, iter [01300, 03664], lr: 0.000100, total_loss: 0.4270, cls_loss: 0.2525, reg_loss: 0.1745
2022-04-23 22:05:00 - train: epoch 0005, iter [01400, 03664], lr: 0.000100, total_loss: 0.4339, cls_loss: 0.2476, reg_loss: 0.1863
2022-04-23 22:05:38 - train: epoch 0005, iter [01500, 03664], lr: 0.000100, total_loss: 0.4719, cls_loss: 0.2841, reg_loss: 0.1878
2022-04-23 22:06:19 - train: epoch 0005, iter [01600, 03664], lr: 0.000100, total_loss: 0.4362, cls_loss: 0.2511, reg_loss: 0.1851
2022-04-23 22:06:57 - train: epoch 0005, iter [01700, 03664], lr: 0.000100, total_loss: 0.4154, cls_loss: 0.2283, reg_loss: 0.1872
2022-04-23 22:07:35 - train: epoch 0005, iter [01800, 03664], lr: 0.000100, total_loss: 0.5175, cls_loss: 0.3098, reg_loss: 0.2077
2022-04-23 22:08:13 - train: epoch 0005, iter [01900, 03664], lr: 0.000100, total_loss: 0.4768, cls_loss: 0.2820, reg_loss: 0.1948
2022-04-23 22:08:54 - train: epoch 0005, iter [02000, 03664], lr: 0.000100, total_loss: 0.5579, cls_loss: 0.3367, reg_loss: 0.2212
2022-04-23 22:09:31 - train: epoch 0005, iter [02100, 03664], lr: 0.000100, total_loss: 0.4624, cls_loss: 0.2673, reg_loss: 0.1951
2022-04-23 22:10:10 - train: epoch 0005, iter [02200, 03664], lr: 0.000100, total_loss: 0.4887, cls_loss: 0.2850, reg_loss: 0.2036
2022-04-23 22:10:49 - train: epoch 0005, iter [02300, 03664], lr: 0.000100, total_loss: 0.4824, cls_loss: 0.2817, reg_loss: 0.2007
2022-04-23 22:11:29 - train: epoch 0005, iter [02400, 03664], lr: 0.000100, total_loss: 0.4823, cls_loss: 0.2757, reg_loss: 0.2066
2022-04-23 22:12:07 - train: epoch 0005, iter [02500, 03664], lr: 0.000100, total_loss: 0.4779, cls_loss: 0.2990, reg_loss: 0.1789
2022-04-23 22:12:46 - train: epoch 0005, iter [02600, 03664], lr: 0.000100, total_loss: 0.5211, cls_loss: 0.3004, reg_loss: 0.2206
2022-04-23 22:13:27 - train: epoch 0005, iter [02700, 03664], lr: 0.000100, total_loss: 0.4584, cls_loss: 0.2873, reg_loss: 0.1711
2022-04-23 22:14:05 - train: epoch 0005, iter [02800, 03664], lr: 0.000100, total_loss: 0.4466, cls_loss: 0.2657, reg_loss: 0.1808
2022-04-23 22:14:44 - train: epoch 0005, iter [02900, 03664], lr: 0.000100, total_loss: 0.4772, cls_loss: 0.2764, reg_loss: 0.2007
2022-04-23 22:15:23 - train: epoch 0005, iter [03000, 03664], lr: 0.000100, total_loss: 0.4929, cls_loss: 0.2913, reg_loss: 0.2016
2022-04-23 22:16:02 - train: epoch 0005, iter [03100, 03664], lr: 0.000100, total_loss: 0.4576, cls_loss: 0.2496, reg_loss: 0.2080
2022-04-23 22:16:39 - train: epoch 0005, iter [03200, 03664], lr: 0.000100, total_loss: 0.4359, cls_loss: 0.2557, reg_loss: 0.1802
2022-04-23 22:17:16 - train: epoch 0005, iter [03300, 03664], lr: 0.000100, total_loss: 0.4647, cls_loss: 0.2681, reg_loss: 0.1966
2022-04-23 22:17:58 - train: epoch 0005, iter [03400, 03664], lr: 0.000100, total_loss: 0.4311, cls_loss: 0.2513, reg_loss: 0.1797
2022-04-23 22:18:35 - train: epoch 0005, iter [03500, 03664], lr: 0.000100, total_loss: 0.4756, cls_loss: 0.2812, reg_loss: 0.1944
2022-04-23 22:19:12 - train: epoch 0005, iter [03600, 03664], lr: 0.000100, total_loss: 0.4519, cls_loss: 0.2630, reg_loss: 0.1889
2022-04-23 22:19:37 - train: epoch 005, train_loss: 0.4707
2022-04-23 22:23:32 - eval: epoch: 005
per_image_load_time: 1.493ms
per_image_inference_time: 38.853ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 26.823755484714436
IoU=0.50,area=all,maxDets=100,mAP: 41.7516693623286
IoU=0.75,area=all,maxDets=100,mAP: 28.43546554378822
IoU=0.50:0.95,area=small,maxDets=100,mAP: 10.973726322036555
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 31.059522521580814
IoU=0.50:0.95,area=large,maxDets=100,mAP: 38.141195393718554
IoU=0.50:0.95,area=all,maxDets=1,mAR: 24.004305008460726
IoU=0.50:0.95,area=all,maxDets=10,mAR: 36.19429288644906
IoU=0.50:0.95,area=all,maxDets=100,mAR: 37.73744791626929
IoU=0.50:0.95,area=small,maxDets=100,mAR: 14.32253814671057
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 43.741032874038424
IoU=0.50:0.95,area=large,maxDets=100,mAR: 52.58848155040896

2022-04-23 22:23:33 - until epoch: 005, best_metric: 26.824%
2022-04-23 22:23:33 - epoch 006 lr: 0.0001
2022-04-23 22:24:16 - train: epoch 0006, iter [00100, 03664], lr: 0.000100, total_loss: 0.4702, cls_loss: 0.2632, reg_loss: 0.2070
2022-04-23 22:24:53 - train: epoch 0006, iter [00200, 03664], lr: 0.000100, total_loss: 0.4339, cls_loss: 0.2575, reg_loss: 0.1764
2022-04-23 22:25:30 - train: epoch 0006, iter [00300, 03664], lr: 0.000100, total_loss: 0.4581, cls_loss: 0.2708, reg_loss: 0.1874
2022-04-23 22:26:08 - train: epoch 0006, iter [00400, 03664], lr: 0.000100, total_loss: 0.4563, cls_loss: 0.2753, reg_loss: 0.1811
2022-04-23 22:26:49 - train: epoch 0006, iter [00500, 03664], lr: 0.000100, total_loss: 0.4985, cls_loss: 0.2852, reg_loss: 0.2133
2022-04-23 22:27:26 - train: epoch 0006, iter [00600, 03664], lr: 0.000100, total_loss: 0.4489, cls_loss: 0.2476, reg_loss: 0.2013
2022-04-23 22:28:03 - train: epoch 0006, iter [00700, 03664], lr: 0.000100, total_loss: 0.4345, cls_loss: 0.2448, reg_loss: 0.1897
2022-04-23 22:28:40 - train: epoch 0006, iter [00800, 03664], lr: 0.000100, total_loss: 0.4403, cls_loss: 0.2512, reg_loss: 0.1891
2022-04-23 22:29:18 - train: epoch 0006, iter [00900, 03664], lr: 0.000100, total_loss: 0.4196, cls_loss: 0.2320, reg_loss: 0.1876
2022-04-23 22:29:57 - train: epoch 0006, iter [01000, 03664], lr: 0.000100, total_loss: 0.5240, cls_loss: 0.3144, reg_loss: 0.2096
2022-04-23 22:30:35 - train: epoch 0006, iter [01100, 03664], lr: 0.000100, total_loss: 0.4630, cls_loss: 0.2666, reg_loss: 0.1965
2022-04-23 22:31:12 - train: epoch 0006, iter [01200, 03664], lr: 0.000100, total_loss: 0.4243, cls_loss: 0.2444, reg_loss: 0.1799
2022-04-23 22:31:52 - train: epoch 0006, iter [01300, 03664], lr: 0.000100, total_loss: 0.4018, cls_loss: 0.2302, reg_loss: 0.1716
2022-04-23 22:32:30 - train: epoch 0006, iter [01400, 03664], lr: 0.000100, total_loss: 0.4207, cls_loss: 0.2354, reg_loss: 0.1853
2022-04-23 22:33:07 - train: epoch 0006, iter [01500, 03664], lr: 0.000100, total_loss: 0.4627, cls_loss: 0.2749, reg_loss: 0.1878
2022-04-23 22:33:47 - train: epoch 0006, iter [01600, 03664], lr: 0.000100, total_loss: 0.4211, cls_loss: 0.2499, reg_loss: 0.1713
2022-04-23 22:34:25 - train: epoch 0006, iter [01700, 03664], lr: 0.000100, total_loss: 0.4667, cls_loss: 0.2651, reg_loss: 0.2016
2022-04-23 22:35:02 - train: epoch 0006, iter [01800, 03664], lr: 0.000100, total_loss: 0.4350, cls_loss: 0.2597, reg_loss: 0.1753
2022-04-23 22:35:39 - train: epoch 0006, iter [01900, 03664], lr: 0.000100, total_loss: 0.4869, cls_loss: 0.2906, reg_loss: 0.1963
2022-04-23 22:36:20 - train: epoch 0006, iter [02000, 03664], lr: 0.000100, total_loss: 0.5054, cls_loss: 0.3058, reg_loss: 0.1996
2022-04-23 22:36:57 - train: epoch 0006, iter [02100, 03664], lr: 0.000100, total_loss: 0.3878, cls_loss: 0.2305, reg_loss: 0.1573
2022-04-23 22:37:34 - train: epoch 0006, iter [02200, 03664], lr: 0.000100, total_loss: 0.4338, cls_loss: 0.2608, reg_loss: 0.1730
2022-04-23 22:38:11 - train: epoch 0006, iter [02300, 03664], lr: 0.000100, total_loss: 0.4203, cls_loss: 0.2339, reg_loss: 0.1863
2022-04-23 22:38:52 - train: epoch 0006, iter [02400, 03664], lr: 0.000100, total_loss: 0.4466, cls_loss: 0.2606, reg_loss: 0.1860
2022-04-23 22:39:29 - train: epoch 0006, iter [02500, 03664], lr: 0.000100, total_loss: 0.4762, cls_loss: 0.2705, reg_loss: 0.2057
2022-04-23 22:40:06 - train: epoch 0006, iter [02600, 03664], lr: 0.000100, total_loss: 0.4694, cls_loss: 0.2610, reg_loss: 0.2084
2022-04-23 22:40:45 - train: epoch 0006, iter [02700, 03664], lr: 0.000100, total_loss: 0.4767, cls_loss: 0.2879, reg_loss: 0.1888
2022-04-23 22:41:24 - train: epoch 0006, iter [02800, 03664], lr: 0.000100, total_loss: 0.4903, cls_loss: 0.2847, reg_loss: 0.2056
2022-04-23 22:42:01 - train: epoch 0006, iter [02900, 03664], lr: 0.000100, total_loss: 0.4293, cls_loss: 0.2521, reg_loss: 0.1772
2022-04-23 22:42:39 - train: epoch 0006, iter [03000, 03664], lr: 0.000100, total_loss: 0.4444, cls_loss: 0.2641, reg_loss: 0.1804
2022-04-23 22:43:18 - train: epoch 0006, iter [03100, 03664], lr: 0.000100, total_loss: 0.4996, cls_loss: 0.2962, reg_loss: 0.2034
2022-04-23 22:43:57 - train: epoch 0006, iter [03200, 03664], lr: 0.000100, total_loss: 0.4758, cls_loss: 0.2965, reg_loss: 0.1794
2022-04-23 22:44:34 - train: epoch 0006, iter [03300, 03664], lr: 0.000100, total_loss: 0.4975, cls_loss: 0.3031, reg_loss: 0.1943
2022-04-23 22:45:11 - train: epoch 0006, iter [03400, 03664], lr: 0.000100, total_loss: 0.4776, cls_loss: 0.2836, reg_loss: 0.1940
2022-04-23 22:45:51 - train: epoch 0006, iter [03500, 03664], lr: 0.000100, total_loss: 0.4291, cls_loss: 0.2358, reg_loss: 0.1933
2022-04-23 22:46:30 - train: epoch 0006, iter [03600, 03664], lr: 0.000100, total_loss: 0.4903, cls_loss: 0.2906, reg_loss: 0.1997
2022-04-23 22:46:54 - train: epoch 006, train_loss: 0.4548
2022-04-23 22:46:55 - until epoch: 006, best_metric: 26.824%
2022-04-23 22:46:55 - epoch 007 lr: 0.0001
2022-04-23 22:47:34 - train: epoch 0007, iter [00100, 03664], lr: 0.000100, total_loss: 0.3966, cls_loss: 0.2239, reg_loss: 0.1727
2022-04-23 22:48:14 - train: epoch 0007, iter [00200, 03664], lr: 0.000100, total_loss: 0.4764, cls_loss: 0.2832, reg_loss: 0.1932
2022-04-23 22:48:51 - train: epoch 0007, iter [00300, 03664], lr: 0.000100, total_loss: 0.4342, cls_loss: 0.2433, reg_loss: 0.1909
2022-04-23 22:49:29 - train: epoch 0007, iter [00400, 03664], lr: 0.000100, total_loss: 0.4622, cls_loss: 0.2821, reg_loss: 0.1801
2022-04-23 22:50:08 - train: epoch 0007, iter [00500, 03664], lr: 0.000100, total_loss: 0.4388, cls_loss: 0.2425, reg_loss: 0.1963
2022-04-23 22:50:47 - train: epoch 0007, iter [00600, 03664], lr: 0.000100, total_loss: 0.4024, cls_loss: 0.2304, reg_loss: 0.1720
2022-04-23 22:51:24 - train: epoch 0007, iter [00700, 03664], lr: 0.000100, total_loss: 0.4544, cls_loss: 0.2617, reg_loss: 0.1927
2022-04-23 22:52:02 - train: epoch 0007, iter [00800, 03664], lr: 0.000100, total_loss: 0.4118, cls_loss: 0.2393, reg_loss: 0.1725
2022-04-23 22:52:41 - train: epoch 0007, iter [00900, 03664], lr: 0.000100, total_loss: 0.4471, cls_loss: 0.2740, reg_loss: 0.1731
2022-04-23 22:53:20 - train: epoch 0007, iter [01000, 03664], lr: 0.000100, total_loss: 0.4617, cls_loss: 0.2628, reg_loss: 0.1989
2022-04-23 22:53:58 - train: epoch 0007, iter [01100, 03664], lr: 0.000100, total_loss: 0.4506, cls_loss: 0.2798, reg_loss: 0.1708
2022-04-23 22:54:36 - train: epoch 0007, iter [01200, 03664], lr: 0.000100, total_loss: 0.4444, cls_loss: 0.2433, reg_loss: 0.2012
2022-04-23 22:55:16 - train: epoch 0007, iter [01300, 03664], lr: 0.000100, total_loss: 0.4013, cls_loss: 0.2205, reg_loss: 0.1807
2022-04-23 22:55:53 - train: epoch 0007, iter [01400, 03664], lr: 0.000100, total_loss: 0.4257, cls_loss: 0.2474, reg_loss: 0.1783
2022-04-23 22:56:31 - train: epoch 0007, iter [01500, 03664], lr: 0.000100, total_loss: 0.4720, cls_loss: 0.2738, reg_loss: 0.1981
2022-04-23 22:57:10 - train: epoch 0007, iter [01600, 03664], lr: 0.000100, total_loss: 0.4696, cls_loss: 0.2556, reg_loss: 0.2140
2022-04-23 22:57:50 - train: epoch 0007, iter [01700, 03664], lr: 0.000100, total_loss: 0.4463, cls_loss: 0.2643, reg_loss: 0.1820
2022-04-23 22:58:28 - train: epoch 0007, iter [01800, 03664], lr: 0.000100, total_loss: 0.4438, cls_loss: 0.2563, reg_loss: 0.1875
2022-04-23 22:59:05 - train: epoch 0007, iter [01900, 03664], lr: 0.000100, total_loss: 0.4831, cls_loss: 0.2918, reg_loss: 0.1913
2022-04-23 22:59:44 - train: epoch 0007, iter [02000, 03664], lr: 0.000100, total_loss: 0.4730, cls_loss: 0.2820, reg_loss: 0.1911
2022-04-23 23:00:23 - train: epoch 0007, iter [02100, 03664], lr: 0.000100, total_loss: 0.4757, cls_loss: 0.2727, reg_loss: 0.2030
2022-04-23 23:01:00 - train: epoch 0007, iter [02200, 03664], lr: 0.000100, total_loss: 0.4552, cls_loss: 0.2679, reg_loss: 0.1873
2022-04-23 23:01:39 - train: epoch 0007, iter [02300, 03664], lr: 0.000100, total_loss: 0.4569, cls_loss: 0.2596, reg_loss: 0.1973
2022-04-23 23:02:17 - train: epoch 0007, iter [02400, 03664], lr: 0.000100, total_loss: 0.3989, cls_loss: 0.2233, reg_loss: 0.1757
2022-04-23 23:02:57 - train: epoch 0007, iter [02500, 03664], lr: 0.000100, total_loss: 0.4249, cls_loss: 0.2419, reg_loss: 0.1829
2022-04-23 23:03:34 - train: epoch 0007, iter [02600, 03664], lr: 0.000100, total_loss: 0.4720, cls_loss: 0.2771, reg_loss: 0.1949
2022-04-23 23:04:14 - train: epoch 0007, iter [02700, 03664], lr: 0.000100, total_loss: 0.4787, cls_loss: 0.2888, reg_loss: 0.1899
2022-04-23 23:04:52 - train: epoch 0007, iter [02800, 03664], lr: 0.000100, total_loss: 0.4569, cls_loss: 0.2552, reg_loss: 0.2017
2022-04-23 23:05:31 - train: epoch 0007, iter [02900, 03664], lr: 0.000100, total_loss: 0.5071, cls_loss: 0.2898, reg_loss: 0.2173
2022-04-23 23:06:08 - train: epoch 0007, iter [03000, 03664], lr: 0.000100, total_loss: 0.4317, cls_loss: 0.2448, reg_loss: 0.1869
2022-04-23 23:06:47 - train: epoch 0007, iter [03100, 03664], lr: 0.000100, total_loss: 0.4034, cls_loss: 0.2271, reg_loss: 0.1763
2022-04-23 23:07:26 - train: epoch 0007, iter [03200, 03664], lr: 0.000100, total_loss: 0.4454, cls_loss: 0.2572, reg_loss: 0.1882
2022-04-23 23:08:03 - train: epoch 0007, iter [03300, 03664], lr: 0.000100, total_loss: 0.4468, cls_loss: 0.2439, reg_loss: 0.2029
2022-04-23 23:08:43 - train: epoch 0007, iter [03400, 03664], lr: 0.000100, total_loss: 0.4334, cls_loss: 0.2411, reg_loss: 0.1924
2022-04-23 23:09:21 - train: epoch 0007, iter [03500, 03664], lr: 0.000100, total_loss: 0.4263, cls_loss: 0.2463, reg_loss: 0.1800
2022-04-23 23:10:01 - train: epoch 0007, iter [03600, 03664], lr: 0.000100, total_loss: 0.5066, cls_loss: 0.2990, reg_loss: 0.2076
2022-04-23 23:10:25 - train: epoch 007, train_loss: 0.4421
2022-04-23 23:10:26 - until epoch: 007, best_metric: 26.824%
2022-04-23 23:10:26 - epoch 008 lr: 0.0001
2022-04-23 23:11:06 - train: epoch 0008, iter [00100, 03664], lr: 0.000100, total_loss: 0.4635, cls_loss: 0.2633, reg_loss: 0.2003
2022-04-23 23:11:44 - train: epoch 0008, iter [00200, 03664], lr: 0.000100, total_loss: 0.3967, cls_loss: 0.2213, reg_loss: 0.1755
2022-04-23 23:12:23 - train: epoch 0008, iter [00300, 03664], lr: 0.000100, total_loss: 0.4722, cls_loss: 0.2888, reg_loss: 0.1834
2022-04-23 23:13:01 - train: epoch 0008, iter [00400, 03664], lr: 0.000100, total_loss: 0.4435, cls_loss: 0.2599, reg_loss: 0.1836
2022-04-23 23:13:40 - train: epoch 0008, iter [00500, 03664], lr: 0.000100, total_loss: 0.4065, cls_loss: 0.2398, reg_loss: 0.1667
2022-04-23 23:14:18 - train: epoch 0008, iter [00600, 03664], lr: 0.000100, total_loss: 0.3713, cls_loss: 0.1971, reg_loss: 0.1741
2022-04-23 23:14:57 - train: epoch 0008, iter [00700, 03664], lr: 0.000100, total_loss: 0.4664, cls_loss: 0.2862, reg_loss: 0.1802
2022-04-23 23:15:35 - train: epoch 0008, iter [00800, 03664], lr: 0.000100, total_loss: 0.3933, cls_loss: 0.2271, reg_loss: 0.1662
2022-04-23 23:16:14 - train: epoch 0008, iter [00900, 03664], lr: 0.000100, total_loss: 0.4386, cls_loss: 0.2387, reg_loss: 0.1999
2022-04-23 23:16:54 - train: epoch 0008, iter [01000, 03664], lr: 0.000100, total_loss: 0.4102, cls_loss: 0.2239, reg_loss: 0.1863
2022-04-23 23:17:32 - train: epoch 0008, iter [01100, 03664], lr: 0.000100, total_loss: 0.4121, cls_loss: 0.2382, reg_loss: 0.1739
2022-04-23 23:18:10 - train: epoch 0008, iter [01200, 03664], lr: 0.000100, total_loss: 0.3982, cls_loss: 0.2325, reg_loss: 0.1656
2022-04-23 23:18:51 - train: epoch 0008, iter [01300, 03664], lr: 0.000100, total_loss: 0.4131, cls_loss: 0.2434, reg_loss: 0.1698
2022-04-23 23:19:28 - train: epoch 0008, iter [01400, 03664], lr: 0.000100, total_loss: 0.4687, cls_loss: 0.2730, reg_loss: 0.1957
2022-04-23 23:20:05 - train: epoch 0008, iter [01500, 03664], lr: 0.000100, total_loss: 0.3902, cls_loss: 0.2131, reg_loss: 0.1771
2022-04-23 23:20:44 - train: epoch 0008, iter [01600, 03664], lr: 0.000100, total_loss: 0.4197, cls_loss: 0.2277, reg_loss: 0.1920
2022-04-23 23:21:24 - train: epoch 0008, iter [01700, 03664], lr: 0.000100, total_loss: 0.4356, cls_loss: 0.2473, reg_loss: 0.1883
2022-04-23 23:22:01 - train: epoch 0008, iter [01800, 03664], lr: 0.000100, total_loss: 0.4209, cls_loss: 0.2354, reg_loss: 0.1855
2022-04-23 23:22:39 - train: epoch 0008, iter [01900, 03664], lr: 0.000100, total_loss: 0.3844, cls_loss: 0.2228, reg_loss: 0.1616
2022-04-23 23:23:19 - train: epoch 0008, iter [02000, 03664], lr: 0.000100, total_loss: 0.4218, cls_loss: 0.2408, reg_loss: 0.1810
2022-04-23 23:23:58 - train: epoch 0008, iter [02100, 03664], lr: 0.000100, total_loss: 0.4273, cls_loss: 0.2573, reg_loss: 0.1700
2022-04-23 23:24:36 - train: epoch 0008, iter [02200, 03664], lr: 0.000100, total_loss: 0.4228, cls_loss: 0.2336, reg_loss: 0.1892
2022-04-23 23:25:13 - train: epoch 0008, iter [02300, 03664], lr: 0.000100, total_loss: 0.4417, cls_loss: 0.2584, reg_loss: 0.1834
2022-04-23 23:25:55 - train: epoch 0008, iter [02400, 03664], lr: 0.000100, total_loss: 0.3991, cls_loss: 0.2152, reg_loss: 0.1839
2022-04-23 23:26:32 - train: epoch 0008, iter [02500, 03664], lr: 0.000100, total_loss: 0.4582, cls_loss: 0.2713, reg_loss: 0.1869
2022-04-23 23:27:10 - train: epoch 0008, iter [02600, 03664], lr: 0.000100, total_loss: 0.4138, cls_loss: 0.2329, reg_loss: 0.1809
2022-04-23 23:27:50 - train: epoch 0008, iter [02700, 03664], lr: 0.000100, total_loss: 0.4025, cls_loss: 0.2489, reg_loss: 0.1537
2022-04-23 23:28:29 - train: epoch 0008, iter [02800, 03664], lr: 0.000100, total_loss: 0.4277, cls_loss: 0.2463, reg_loss: 0.1814
2022-04-23 23:29:07 - train: epoch 0008, iter [02900, 03664], lr: 0.000100, total_loss: 0.5226, cls_loss: 0.2803, reg_loss: 0.2423
2022-04-23 23:29:44 - train: epoch 0008, iter [03000, 03664], lr: 0.000100, total_loss: 0.4531, cls_loss: 0.2499, reg_loss: 0.2032
2022-04-23 23:30:25 - train: epoch 0008, iter [03100, 03664], lr: 0.000100, total_loss: 0.4773, cls_loss: 0.3002, reg_loss: 0.1771
2022-04-23 23:31:03 - train: epoch 0008, iter [03200, 03664], lr: 0.000100, total_loss: 0.4370, cls_loss: 0.2514, reg_loss: 0.1856
2022-04-23 23:31:40 - train: epoch 0008, iter [03300, 03664], lr: 0.000100, total_loss: 0.4580, cls_loss: 0.2604, reg_loss: 0.1976
2022-04-23 23:32:20 - train: epoch 0008, iter [03400, 03664], lr: 0.000100, total_loss: 0.4426, cls_loss: 0.2646, reg_loss: 0.1780
2022-04-23 23:32:59 - train: epoch 0008, iter [03500, 03664], lr: 0.000100, total_loss: 0.4237, cls_loss: 0.2423, reg_loss: 0.1814
2022-04-23 23:33:37 - train: epoch 0008, iter [03600, 03664], lr: 0.000100, total_loss: 0.4101, cls_loss: 0.2427, reg_loss: 0.1675
2022-04-23 23:34:02 - train: epoch 008, train_loss: 0.4313
2022-04-23 23:38:15 - eval: epoch: 008
per_image_load_time: 1.605ms
per_image_inference_time: 42.151ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 29.160565029269947
IoU=0.50,area=all,maxDets=100,mAP: 44.62575031874785
IoU=0.75,area=all,maxDets=100,mAP: 30.987280559938498
IoU=0.50:0.95,area=small,maxDets=100,mAP: 11.522775730701477
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 33.45438333303583
IoU=0.50:0.95,area=large,maxDets=100,mAP: 42.43673032577604
IoU=0.50:0.95,area=all,maxDets=1,mAR: 25.333745845813137
IoU=0.50:0.95,area=all,maxDets=10,mAR: 38.18061880464566
IoU=0.50:0.95,area=all,maxDets=100,mAR: 39.751713312141575
IoU=0.50:0.95,area=small,maxDets=100,mAR: 15.873307069697074
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 46.2481191528798
IoU=0.50:0.95,area=large,maxDets=100,mAR: 56.64841567013883

2022-04-23 23:38:16 - until epoch: 008, best_metric: 29.161%
2022-04-23 23:38:16 - epoch 009 lr: 1e-05
2022-04-23 23:38:58 - train: epoch 0009, iter [00100, 03664], lr: 0.000010, total_loss: 0.4044, cls_loss: 0.2318, reg_loss: 0.1726
2022-04-23 23:39:38 - train: epoch 0009, iter [00200, 03664], lr: 0.000010, total_loss: 0.3756, cls_loss: 0.2096, reg_loss: 0.1660
2022-04-23 23:40:15 - train: epoch 0009, iter [00300, 03664], lr: 0.000010, total_loss: 0.4227, cls_loss: 0.2426, reg_loss: 0.1801
2022-04-23 23:40:53 - train: epoch 0009, iter [00400, 03664], lr: 0.000010, total_loss: 0.4087, cls_loss: 0.2368, reg_loss: 0.1719
2022-04-23 23:41:33 - train: epoch 0009, iter [00500, 03664], lr: 0.000010, total_loss: 0.4076, cls_loss: 0.2340, reg_loss: 0.1736
2022-04-23 23:42:13 - train: epoch 0009, iter [00600, 03664], lr: 0.000010, total_loss: 0.4273, cls_loss: 0.2337, reg_loss: 0.1936
2022-04-23 23:42:52 - train: epoch 0009, iter [00700, 03664], lr: 0.000010, total_loss: 0.4344, cls_loss: 0.2373, reg_loss: 0.1972
2022-04-23 23:43:30 - train: epoch 0009, iter [00800, 03664], lr: 0.000010, total_loss: 0.4064, cls_loss: 0.2292, reg_loss: 0.1772
2022-04-23 23:44:11 - train: epoch 0009, iter [00900, 03664], lr: 0.000010, total_loss: 0.3595, cls_loss: 0.2018, reg_loss: 0.1577
2022-04-23 23:44:51 - train: epoch 0009, iter [01000, 03664], lr: 0.000010, total_loss: 0.4156, cls_loss: 0.2262, reg_loss: 0.1894
2022-04-23 23:45:29 - train: epoch 0009, iter [01100, 03664], lr: 0.000010, total_loss: 0.4654, cls_loss: 0.2792, reg_loss: 0.1862
2022-04-23 23:46:07 - train: epoch 0009, iter [01200, 03664], lr: 0.000010, total_loss: 0.4366, cls_loss: 0.2385, reg_loss: 0.1982
2022-04-23 23:46:50 - train: epoch 0009, iter [01300, 03664], lr: 0.000010, total_loss: 0.3905, cls_loss: 0.2028, reg_loss: 0.1877
2022-04-23 23:47:29 - train: epoch 0009, iter [01400, 03664], lr: 0.000010, total_loss: 0.4106, cls_loss: 0.2130, reg_loss: 0.1976
2022-04-23 23:48:07 - train: epoch 0009, iter [01500, 03664], lr: 0.000010, total_loss: 0.3114, cls_loss: 0.1623, reg_loss: 0.1491
2022-04-23 23:48:45 - train: epoch 0009, iter [01600, 03664], lr: 0.000010, total_loss: 0.3537, cls_loss: 0.1738, reg_loss: 0.1799
2022-04-23 23:49:27 - train: epoch 0009, iter [01700, 03664], lr: 0.000010, total_loss: 0.4009, cls_loss: 0.2271, reg_loss: 0.1738
2022-04-23 23:50:05 - train: epoch 0009, iter [01800, 03664], lr: 0.000010, total_loss: 0.3430, cls_loss: 0.1913, reg_loss: 0.1516
2022-04-23 23:50:44 - train: epoch 0009, iter [01900, 03664], lr: 0.000010, total_loss: 0.3632, cls_loss: 0.2033, reg_loss: 0.1598
2022-04-23 23:51:24 - train: epoch 0009, iter [02000, 03664], lr: 0.000010, total_loss: 0.4267, cls_loss: 0.2341, reg_loss: 0.1926
2022-04-23 23:52:04 - train: epoch 0009, iter [02100, 03664], lr: 0.000010, total_loss: 0.3721, cls_loss: 0.1969, reg_loss: 0.1752
2022-04-23 23:52:42 - train: epoch 0009, iter [02200, 03664], lr: 0.000010, total_loss: 0.3354, cls_loss: 0.1850, reg_loss: 0.1504
2022-04-23 23:53:20 - train: epoch 0009, iter [02300, 03664], lr: 0.000010, total_loss: 0.3685, cls_loss: 0.2036, reg_loss: 0.1649
2022-04-23 23:54:03 - train: epoch 0009, iter [02400, 03664], lr: 0.000010, total_loss: 0.3297, cls_loss: 0.1727, reg_loss: 0.1570
2022-04-23 23:54:42 - train: epoch 0009, iter [02500, 03664], lr: 0.000010, total_loss: 0.3874, cls_loss: 0.2013, reg_loss: 0.1861
2022-04-23 23:55:21 - train: epoch 0009, iter [02600, 03664], lr: 0.000010, total_loss: 0.3969, cls_loss: 0.2154, reg_loss: 0.1815
2022-04-23 23:55:59 - train: epoch 0009, iter [02700, 03664], lr: 0.000010, total_loss: 0.3830, cls_loss: 0.2200, reg_loss: 0.1630
2022-04-23 23:56:42 - train: epoch 0009, iter [02800, 03664], lr: 0.000010, total_loss: 0.3432, cls_loss: 0.1798, reg_loss: 0.1634
2022-04-23 23:57:21 - train: epoch 0009, iter [02900, 03664], lr: 0.000010, total_loss: 0.4031, cls_loss: 0.2179, reg_loss: 0.1852
2022-04-23 23:57:59 - train: epoch 0009, iter [03000, 03664], lr: 0.000010, total_loss: 0.3599, cls_loss: 0.1992, reg_loss: 0.1607
2022-04-23 23:58:40 - train: epoch 0009, iter [03100, 03664], lr: 0.000010, total_loss: 0.4086, cls_loss: 0.2159, reg_loss: 0.1927
2022-04-23 23:59:21 - train: epoch 0009, iter [03200, 03664], lr: 0.000010, total_loss: 0.3793, cls_loss: 0.2035, reg_loss: 0.1757
2022-04-24 00:00:00 - train: epoch 0009, iter [03300, 03664], lr: 0.000010, total_loss: 0.4662, cls_loss: 0.2679, reg_loss: 0.1983
2022-04-24 00:00:41 - train: epoch 0009, iter [03400, 03664], lr: 0.000010, total_loss: 0.3335, cls_loss: 0.1840, reg_loss: 0.1494
2022-04-24 00:01:22 - train: epoch 0009, iter [03500, 03664], lr: 0.000010, total_loss: 0.4443, cls_loss: 0.2454, reg_loss: 0.1989
2022-04-24 00:02:01 - train: epoch 0009, iter [03600, 03664], lr: 0.000010, total_loss: 0.3219, cls_loss: 0.1813, reg_loss: 0.1406
2022-04-24 00:02:26 - train: epoch 009, train_loss: 0.3873
2022-04-24 00:02:27 - until epoch: 009, best_metric: 29.161%
2022-04-24 00:02:27 - epoch 010 lr: 1e-05
2022-04-24 00:03:08 - train: epoch 0010, iter [00100, 03664], lr: 0.000010, total_loss: 0.3765, cls_loss: 0.2053, reg_loss: 0.1712
2022-04-24 00:03:50 - train: epoch 0010, iter [00200, 03664], lr: 0.000010, total_loss: 0.3700, cls_loss: 0.2003, reg_loss: 0.1696
2022-04-24 00:04:28 - train: epoch 0010, iter [00300, 03664], lr: 0.000010, total_loss: 0.4029, cls_loss: 0.2206, reg_loss: 0.1823
2022-04-24 00:05:06 - train: epoch 0010, iter [00400, 03664], lr: 0.000010, total_loss: 0.3768, cls_loss: 0.2134, reg_loss: 0.1634
2022-04-24 00:05:46 - train: epoch 0010, iter [00500, 03664], lr: 0.000010, total_loss: 0.3519, cls_loss: 0.1938, reg_loss: 0.1580
2022-04-24 00:06:28 - train: epoch 0010, iter [00600, 03664], lr: 0.000010, total_loss: 0.3521, cls_loss: 0.1963, reg_loss: 0.1558
2022-04-24 00:07:06 - train: epoch 0010, iter [00700, 03664], lr: 0.000010, total_loss: 0.4427, cls_loss: 0.2444, reg_loss: 0.1984
2022-04-24 00:07:47 - train: epoch 0010, iter [00800, 03664], lr: 0.000010, total_loss: 0.3766, cls_loss: 0.2006, reg_loss: 0.1760
2022-04-24 00:08:25 - train: epoch 0010, iter [00900, 03664], lr: 0.000010, total_loss: 0.3623, cls_loss: 0.1981, reg_loss: 0.1643
2022-04-24 00:09:07 - train: epoch 0010, iter [01000, 03664], lr: 0.000010, total_loss: 0.3832, cls_loss: 0.2133, reg_loss: 0.1699
2022-04-24 00:09:46 - train: epoch 0010, iter [01100, 03664], lr: 0.000010, total_loss: 0.3221, cls_loss: 0.1600, reg_loss: 0.1621
2022-04-24 00:10:27 - train: epoch 0010, iter [01200, 03664], lr: 0.000010, total_loss: 0.4049, cls_loss: 0.2142, reg_loss: 0.1907
2022-04-24 00:11:08 - train: epoch 0010, iter [01300, 03664], lr: 0.000010, total_loss: 0.4615, cls_loss: 0.2669, reg_loss: 0.1946
2022-04-24 00:11:46 - train: epoch 0010, iter [01400, 03664], lr: 0.000010, total_loss: 0.3561, cls_loss: 0.1938, reg_loss: 0.1622
2022-04-24 00:12:27 - train: epoch 0010, iter [01500, 03664], lr: 0.000010, total_loss: 0.4004, cls_loss: 0.2109, reg_loss: 0.1895
2022-04-24 00:13:05 - train: epoch 0010, iter [01600, 03664], lr: 0.000010, total_loss: 0.3868, cls_loss: 0.2155, reg_loss: 0.1713
2022-04-24 00:13:46 - train: epoch 0010, iter [01700, 03664], lr: 0.000010, total_loss: 0.3592, cls_loss: 0.2074, reg_loss: 0.1518
2022-04-24 00:14:25 - train: epoch 0010, iter [01800, 03664], lr: 0.000010, total_loss: 0.3493, cls_loss: 0.1888, reg_loss: 0.1606
2022-04-24 00:15:05 - train: epoch 0010, iter [01900, 03664], lr: 0.000010, total_loss: 0.3369, cls_loss: 0.1766, reg_loss: 0.1603
2022-04-24 00:15:44 - train: epoch 0010, iter [02000, 03664], lr: 0.000010, total_loss: 0.3928, cls_loss: 0.2129, reg_loss: 0.1800
2022-04-24 00:16:25 - train: epoch 0010, iter [02100, 03664], lr: 0.000010, total_loss: 0.3604, cls_loss: 0.2004, reg_loss: 0.1601
2022-04-24 00:17:04 - train: epoch 0010, iter [02200, 03664], lr: 0.000010, total_loss: 0.3806, cls_loss: 0.1994, reg_loss: 0.1812
2022-04-24 00:17:44 - train: epoch 0010, iter [02300, 03664], lr: 0.000010, total_loss: 0.3610, cls_loss: 0.1902, reg_loss: 0.1708
2022-04-24 00:18:22 - train: epoch 0010, iter [02400, 03664], lr: 0.000010, total_loss: 0.4228, cls_loss: 0.2435, reg_loss: 0.1792
2022-04-24 00:19:03 - train: epoch 0010, iter [02500, 03664], lr: 0.000010, total_loss: 0.4231, cls_loss: 0.2206, reg_loss: 0.2026
2022-04-24 00:19:43 - train: epoch 0010, iter [02600, 03664], lr: 0.000010, total_loss: 0.3295, cls_loss: 0.1838, reg_loss: 0.1457
2022-04-24 00:20:22 - train: epoch 0010, iter [02700, 03664], lr: 0.000010, total_loss: 0.3541, cls_loss: 0.1972, reg_loss: 0.1569
2022-04-24 00:21:03 - train: epoch 0010, iter [02800, 03664], lr: 0.000010, total_loss: 0.3680, cls_loss: 0.2088, reg_loss: 0.1592
2022-04-24 00:21:41 - train: epoch 0010, iter [02900, 03664], lr: 0.000010, total_loss: 0.3124, cls_loss: 0.1537, reg_loss: 0.1587
2022-04-24 00:22:21 - train: epoch 0010, iter [03000, 03664], lr: 0.000010, total_loss: 0.4404, cls_loss: 0.2597, reg_loss: 0.1807
2022-04-24 00:23:00 - train: epoch 0010, iter [03100, 03664], lr: 0.000010, total_loss: 0.3345, cls_loss: 0.1797, reg_loss: 0.1548
2022-04-24 00:23:41 - train: epoch 0010, iter [03200, 03664], lr: 0.000010, total_loss: 0.4154, cls_loss: 0.2392, reg_loss: 0.1763
2022-04-24 00:24:21 - train: epoch 0010, iter [03300, 03664], lr: 0.000010, total_loss: 0.3505, cls_loss: 0.1829, reg_loss: 0.1675
2022-04-24 00:25:00 - train: epoch 0010, iter [03400, 03664], lr: 0.000010, total_loss: 0.3518, cls_loss: 0.1809, reg_loss: 0.1709
2022-04-24 00:25:40 - train: epoch 0010, iter [03500, 03664], lr: 0.000010, total_loss: 0.3561, cls_loss: 0.1955, reg_loss: 0.1607
2022-04-24 00:26:19 - train: epoch 0010, iter [03600, 03664], lr: 0.000010, total_loss: 0.3726, cls_loss: 0.2178, reg_loss: 0.1548
2022-04-24 00:26:45 - train: epoch 010, train_loss: 0.3760
2022-04-24 00:31:33 - eval: epoch: 010
per_image_load_time: 1.788ms
per_image_inference_time: 49.595ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 32.314978168783334
IoU=0.50,area=all,maxDets=100,mAP: 48.5063240479329
IoU=0.75,area=all,maxDets=100,mAP: 34.407424584893924
IoU=0.50:0.95,area=small,maxDets=100,mAP: 13.56708112684377
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 37.6873792570379
IoU=0.50:0.95,area=large,maxDets=100,mAP: 46.99475866187524
IoU=0.50:0.95,area=all,maxDets=1,mAR: 27.31007359765875
IoU=0.50:0.95,area=all,maxDets=10,mAR: 40.86221906640733
IoU=0.50:0.95,area=all,maxDets=100,mAR: 42.524867795943614
IoU=0.50:0.95,area=small,maxDets=100,mAR: 18.297440674960093
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 49.797038952289284
IoU=0.50:0.95,area=large,maxDets=100,mAR: 60.04685721563645

2022-04-24 00:31:34 - until epoch: 010, best_metric: 32.315%
2022-04-24 00:31:34 - epoch 011 lr: 1e-05
2022-04-24 00:32:19 - train: epoch 0011, iter [00100, 03664], lr: 0.000010, total_loss: 0.3219, cls_loss: 0.1700, reg_loss: 0.1519
2022-04-24 00:32:57 - train: epoch 0011, iter [00200, 03664], lr: 0.000010, total_loss: 0.3549, cls_loss: 0.1807, reg_loss: 0.1742
2022-04-24 00:33:39 - train: epoch 0011, iter [00300, 03664], lr: 0.000010, total_loss: 0.3991, cls_loss: 0.2163, reg_loss: 0.1828
2022-04-24 00:34:17 - train: epoch 0011, iter [00400, 03664], lr: 0.000010, total_loss: 0.3462, cls_loss: 0.1719, reg_loss: 0.1742
2022-04-24 00:34:58 - train: epoch 0011, iter [00500, 03664], lr: 0.000010, total_loss: 0.3869, cls_loss: 0.2179, reg_loss: 0.1690
2022-04-24 00:35:37 - train: epoch 0011, iter [00600, 03664], lr: 0.000010, total_loss: 0.3333, cls_loss: 0.1813, reg_loss: 0.1520
2022-04-24 00:36:18 - train: epoch 0011, iter [00700, 03664], lr: 0.000010, total_loss: 0.4098, cls_loss: 0.2211, reg_loss: 0.1887
2022-04-24 00:36:56 - train: epoch 0011, iter [00800, 03664], lr: 0.000010, total_loss: 0.4169, cls_loss: 0.2304, reg_loss: 0.1865
2022-04-24 00:37:37 - train: epoch 0011, iter [00900, 03664], lr: 0.000010, total_loss: 0.3380, cls_loss: 0.1828, reg_loss: 0.1552
2022-04-24 00:38:17 - train: epoch 0011, iter [01000, 03664], lr: 0.000010, total_loss: 0.3835, cls_loss: 0.2051, reg_loss: 0.1784
2022-04-24 00:38:56 - train: epoch 0011, iter [01100, 03664], lr: 0.000010, total_loss: 0.3520, cls_loss: 0.1869, reg_loss: 0.1651
2022-04-24 00:39:34 - train: epoch 0011, iter [01200, 03664], lr: 0.000010, total_loss: 0.3605, cls_loss: 0.1967, reg_loss: 0.1639
2022-04-24 00:40:16 - train: epoch 0011, iter [01300, 03664], lr: 0.000010, total_loss: 0.3339, cls_loss: 0.1756, reg_loss: 0.1584
2022-04-24 00:40:55 - train: epoch 0011, iter [01400, 03664], lr: 0.000010, total_loss: 0.3470, cls_loss: 0.1920, reg_loss: 0.1550
2022-04-24 00:41:33 - train: epoch 0011, iter [01500, 03664], lr: 0.000010, total_loss: 0.3832, cls_loss: 0.2093, reg_loss: 0.1739
2022-04-24 00:42:12 - train: epoch 0011, iter [01600, 03664], lr: 0.000010, total_loss: 0.4223, cls_loss: 0.2367, reg_loss: 0.1856
2022-04-24 00:42:55 - train: epoch 0011, iter [01700, 03664], lr: 0.000010, total_loss: 0.3547, cls_loss: 0.1881, reg_loss: 0.1666
2022-04-24 00:43:33 - train: epoch 0011, iter [01800, 03664], lr: 0.000010, total_loss: 0.3475, cls_loss: 0.1873, reg_loss: 0.1601
2022-04-24 00:44:12 - train: epoch 0011, iter [01900, 03664], lr: 0.000010, total_loss: 0.4131, cls_loss: 0.2468, reg_loss: 0.1663
2022-04-24 00:44:54 - train: epoch 0011, iter [02000, 03664], lr: 0.000010, total_loss: 0.3374, cls_loss: 0.1677, reg_loss: 0.1696
2022-04-24 00:45:32 - train: epoch 0011, iter [02100, 03664], lr: 0.000010, total_loss: 0.3581, cls_loss: 0.1803, reg_loss: 0.1778
2022-04-24 00:46:10 - train: epoch 0011, iter [02200, 03664], lr: 0.000010, total_loss: 0.4029, cls_loss: 0.2176, reg_loss: 0.1854
2022-04-24 00:46:48 - train: epoch 0011, iter [02300, 03664], lr: 0.000010, total_loss: 0.3626, cls_loss: 0.1993, reg_loss: 0.1633
2022-04-24 00:47:30 - train: epoch 0011, iter [02400, 03664], lr: 0.000010, total_loss: 0.3649, cls_loss: 0.2071, reg_loss: 0.1578
2022-04-24 00:48:09 - train: epoch 0011, iter [02500, 03664], lr: 0.000010, total_loss: 0.4251, cls_loss: 0.2397, reg_loss: 0.1855
2022-04-24 00:48:48 - train: epoch 0011, iter [02600, 03664], lr: 0.000010, total_loss: 0.3680, cls_loss: 0.1961, reg_loss: 0.1720
2022-04-24 00:49:26 - train: epoch 0011, iter [02700, 03664], lr: 0.000010, total_loss: 0.3355, cls_loss: 0.1825, reg_loss: 0.1530
2022-04-24 00:50:09 - train: epoch 0011, iter [02800, 03664], lr: 0.000010, total_loss: 0.4457, cls_loss: 0.2502, reg_loss: 0.1955
2022-04-24 00:50:47 - train: epoch 0011, iter [02900, 03664], lr: 0.000010, total_loss: 0.3918, cls_loss: 0.2191, reg_loss: 0.1726
2022-04-24 00:51:26 - train: epoch 0011, iter [03000, 03664], lr: 0.000010, total_loss: 0.3361, cls_loss: 0.1736, reg_loss: 0.1625
2022-04-24 00:52:08 - train: epoch 0011, iter [03100, 03664], lr: 0.000010, total_loss: 0.3407, cls_loss: 0.1812, reg_loss: 0.1595
2022-04-24 00:52:46 - train: epoch 0011, iter [03200, 03664], lr: 0.000010, total_loss: 0.3651, cls_loss: 0.2065, reg_loss: 0.1586
2022-04-24 00:53:24 - train: epoch 0011, iter [03300, 03664], lr: 0.000010, total_loss: 0.4073, cls_loss: 0.2062, reg_loss: 0.2011
2022-04-24 00:54:01 - train: epoch 0011, iter [03400, 03664], lr: 0.000010, total_loss: 0.4296, cls_loss: 0.2282, reg_loss: 0.2013
2022-04-24 00:54:44 - train: epoch 0011, iter [03500, 03664], lr: 0.000010, total_loss: 0.4420, cls_loss: 0.2412, reg_loss: 0.2008
2022-04-24 00:55:22 - train: epoch 0011, iter [03600, 03664], lr: 0.000010, total_loss: 0.3930, cls_loss: 0.2027, reg_loss: 0.1902
2022-04-24 00:55:47 - train: epoch 011, train_loss: 0.3707
2022-04-24 00:55:47 - until epoch: 011, best_metric: 32.315%
2022-04-24 00:55:47 - epoch 012 lr: 1e-05
2022-04-24 00:56:26 - train: epoch 0012, iter [00100, 03664], lr: 0.000010, total_loss: 0.3767, cls_loss: 0.2078, reg_loss: 0.1689
2022-04-24 00:57:08 - train: epoch 0012, iter [00200, 03664], lr: 0.000010, total_loss: 0.3798, cls_loss: 0.2036, reg_loss: 0.1762
2022-04-24 00:57:45 - train: epoch 0012, iter [00300, 03664], lr: 0.000010, total_loss: 0.3739, cls_loss: 0.1999, reg_loss: 0.1740
2022-04-24 00:58:22 - train: epoch 0012, iter [00400, 03664], lr: 0.000010, total_loss: 0.3914, cls_loss: 0.2133, reg_loss: 0.1780
2022-04-24 00:59:03 - train: epoch 0012, iter [00500, 03664], lr: 0.000010, total_loss: 0.3969, cls_loss: 0.2212, reg_loss: 0.1758
2022-04-24 00:59:40 - train: epoch 0012, iter [00600, 03664], lr: 0.000010, total_loss: 0.3427, cls_loss: 0.1883, reg_loss: 0.1544
2022-04-24 01:00:18 - train: epoch 0012, iter [00700, 03664], lr: 0.000010, total_loss: 0.3632, cls_loss: 0.1931, reg_loss: 0.1701
2022-04-24 01:00:59 - train: epoch 0012, iter [00800, 03664], lr: 0.000010, total_loss: 0.3081, cls_loss: 0.1682, reg_loss: 0.1399
2022-04-24 01:01:37 - train: epoch 0012, iter [00900, 03664], lr: 0.000010, total_loss: 0.3839, cls_loss: 0.2111, reg_loss: 0.1727
2022-04-24 01:02:14 - train: epoch 0012, iter [01000, 03664], lr: 0.000010, total_loss: 0.3625, cls_loss: 0.1957, reg_loss: 0.1668
2022-04-24 01:02:53 - train: epoch 0012, iter [01100, 03664], lr: 0.000010, total_loss: 0.4018, cls_loss: 0.2236, reg_loss: 0.1782
2022-04-24 01:03:33 - train: epoch 0012, iter [01200, 03664], lr: 0.000010, total_loss: 0.3020, cls_loss: 0.1537, reg_loss: 0.1483
2022-04-24 01:04:10 - train: epoch 0012, iter [01300, 03664], lr: 0.000010, total_loss: 0.3687, cls_loss: 0.1965, reg_loss: 0.1722
2022-04-24 01:04:46 - train: epoch 0012, iter [01400, 03664], lr: 0.000010, total_loss: 0.4231, cls_loss: 0.2308, reg_loss: 0.1923
2022-04-24 01:05:26 - train: epoch 0012, iter [01500, 03664], lr: 0.000010, total_loss: 0.3221, cls_loss: 0.1685, reg_loss: 0.1537
2022-04-24 01:06:05 - train: epoch 0012, iter [01600, 03664], lr: 0.000010, total_loss: 0.4145, cls_loss: 0.2507, reg_loss: 0.1639
2022-04-24 01:06:43 - train: epoch 0012, iter [01700, 03664], lr: 0.000010, total_loss: 0.3335, cls_loss: 0.1621, reg_loss: 0.1714
2022-04-24 01:07:23 - train: epoch 0012, iter [01800, 03664], lr: 0.000010, total_loss: 0.3983, cls_loss: 0.2010, reg_loss: 0.1973
2022-04-24 01:08:00 - train: epoch 0012, iter [01900, 03664], lr: 0.000010, total_loss: 0.3014, cls_loss: 0.1627, reg_loss: 0.1387
2022-04-24 01:08:40 - train: epoch 0012, iter [02000, 03664], lr: 0.000010, total_loss: 0.3764, cls_loss: 0.2078, reg_loss: 0.1686
2022-04-24 01:09:18 - train: epoch 0012, iter [02100, 03664], lr: 0.000010, total_loss: 0.3181, cls_loss: 0.1668, reg_loss: 0.1513
2022-04-24 01:09:58 - train: epoch 0012, iter [02200, 03664], lr: 0.000010, total_loss: 0.3896, cls_loss: 0.2040, reg_loss: 0.1856
2022-04-24 01:10:38 - train: epoch 0012, iter [02300, 03664], lr: 0.000010, total_loss: 0.3563, cls_loss: 0.1926, reg_loss: 0.1637
2022-04-24 01:11:16 - train: epoch 0012, iter [02400, 03664], lr: 0.000010, total_loss: 0.3123, cls_loss: 0.1642, reg_loss: 0.1481
2022-04-24 01:11:55 - train: epoch 0012, iter [02500, 03664], lr: 0.000010, total_loss: 0.3307, cls_loss: 0.1721, reg_loss: 0.1586
2022-04-24 01:12:34 - train: epoch 0012, iter [02600, 03664], lr: 0.000010, total_loss: 0.4372, cls_loss: 0.2406, reg_loss: 0.1965
2022-04-24 01:13:14 - train: epoch 0012, iter [02700, 03664], lr: 0.000010, total_loss: 0.3722, cls_loss: 0.1977, reg_loss: 0.1745
2022-04-24 01:13:52 - train: epoch 0012, iter [02800, 03664], lr: 0.000010, total_loss: 0.3839, cls_loss: 0.2126, reg_loss: 0.1713
2022-04-24 01:14:32 - train: epoch 0012, iter [02900, 03664], lr: 0.000010, total_loss: 0.3333, cls_loss: 0.1775, reg_loss: 0.1558
2022-04-24 01:15:10 - train: epoch 0012, iter [03000, 03664], lr: 0.000010, total_loss: 0.3686, cls_loss: 0.1996, reg_loss: 0.1690
2022-04-24 01:15:49 - train: epoch 0012, iter [03100, 03664], lr: 0.000010, total_loss: 0.3633, cls_loss: 0.1898, reg_loss: 0.1735
2022-04-24 01:16:27 - train: epoch 0012, iter [03200, 03664], lr: 0.000010, total_loss: 0.3728, cls_loss: 0.2156, reg_loss: 0.1571
2022-04-24 01:17:07 - train: epoch 0012, iter [03300, 03664], lr: 0.000010, total_loss: 0.3579, cls_loss: 0.1965, reg_loss: 0.1614
2022-04-24 01:17:44 - train: epoch 0012, iter [03400, 03664], lr: 0.000010, total_loss: 0.3787, cls_loss: 0.2106, reg_loss: 0.1681
2022-04-24 01:18:24 - train: epoch 0012, iter [03500, 03664], lr: 0.000010, total_loss: 0.3625, cls_loss: 0.2052, reg_loss: 0.1573
2022-04-24 01:19:02 - train: epoch 0012, iter [03600, 03664], lr: 0.000010, total_loss: 0.3700, cls_loss: 0.1899, reg_loss: 0.1801
2022-04-24 01:19:27 - train: epoch 012, train_loss: 0.3667
2022-04-24 01:23:34 - eval: epoch: 012
per_image_load_time: 1.607ms
per_image_inference_time: 41.428ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 32.641797926403534
IoU=0.50,area=all,maxDets=100,mAP: 49.05073997065125
IoU=0.75,area=all,maxDets=100,mAP: 34.9551595652398
IoU=0.50:0.95,area=small,maxDets=100,mAP: 14.34125902700262
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 37.88352736945522
IoU=0.50:0.95,area=large,maxDets=100,mAP: 47.444824797827444
IoU=0.50:0.95,area=all,maxDets=1,mAR: 27.5094846700876
IoU=0.50:0.95,area=all,maxDets=10,mAR: 41.162372458888996
IoU=0.50:0.95,area=all,maxDets=100,mAR: 42.91780092001417
IoU=0.50:0.95,area=small,maxDets=100,mAR: 18.84001027632213
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 49.97551562260053
IoU=0.50:0.95,area=large,maxDets=100,mAR: 60.78668119967175

2022-04-24 01:23:35 - until epoch: 012, best_metric: 32.642%
2022-04-24 01:23:35 - epoch 013 lr: 1.0000000000000002e-06
2022-04-24 01:24:23 - train: epoch 0013, iter [00100, 03664], lr: 0.000001, total_loss: 0.3658, cls_loss: 0.1973, reg_loss: 0.1686
2022-04-24 01:25:01 - train: epoch 0013, iter [00200, 03664], lr: 0.000001, total_loss: 0.3546, cls_loss: 0.1833, reg_loss: 0.1712
2022-04-24 01:25:42 - train: epoch 0013, iter [00300, 03664], lr: 0.000001, total_loss: 0.3545, cls_loss: 0.1775, reg_loss: 0.1770
2022-04-24 01:26:20 - train: epoch 0013, iter [00400, 03664], lr: 0.000001, total_loss: 0.3573, cls_loss: 0.1936, reg_loss: 0.1637
2022-04-24 01:26:58 - train: epoch 0013, iter [00500, 03664], lr: 0.000001, total_loss: 0.3386, cls_loss: 0.1894, reg_loss: 0.1491
2022-04-24 01:27:39 - train: epoch 0013, iter [00600, 03664], lr: 0.000001, total_loss: 0.3639, cls_loss: 0.1992, reg_loss: 0.1647
2022-04-24 01:28:19 - train: epoch 0013, iter [00700, 03664], lr: 0.000001, total_loss: 0.3372, cls_loss: 0.1739, reg_loss: 0.1632
2022-04-24 01:28:57 - train: epoch 0013, iter [00800, 03664], lr: 0.000001, total_loss: 0.3551, cls_loss: 0.1820, reg_loss: 0.1731
2022-04-24 01:29:38 - train: epoch 0013, iter [00900, 03664], lr: 0.000001, total_loss: 0.3497, cls_loss: 0.1829, reg_loss: 0.1668
2022-04-24 01:30:17 - train: epoch 0013, iter [01000, 03664], lr: 0.000001, total_loss: 0.3789, cls_loss: 0.1999, reg_loss: 0.1790
2022-04-24 01:30:56 - train: epoch 0013, iter [01100, 03664], lr: 0.000001, total_loss: 0.3696, cls_loss: 0.1898, reg_loss: 0.1799
2022-04-24 01:31:34 - train: epoch 0013, iter [01200, 03664], lr: 0.000001, total_loss: 0.3749, cls_loss: 0.2165, reg_loss: 0.1584
2022-04-24 01:32:15 - train: epoch 0013, iter [01300, 03664], lr: 0.000001, total_loss: 0.3547, cls_loss: 0.1919, reg_loss: 0.1628
2022-04-24 01:32:55 - train: epoch 0013, iter [01400, 03664], lr: 0.000001, total_loss: 0.3620, cls_loss: 0.1918, reg_loss: 0.1702
2022-04-24 01:33:33 - train: epoch 0013, iter [01500, 03664], lr: 0.000001, total_loss: 0.4384, cls_loss: 0.2419, reg_loss: 0.1966
2022-04-24 01:34:12 - train: epoch 0013, iter [01600, 03664], lr: 0.000001, total_loss: 0.3883, cls_loss: 0.2166, reg_loss: 0.1717
2022-04-24 01:34:55 - train: epoch 0013, iter [01700, 03664], lr: 0.000001, total_loss: 0.3336, cls_loss: 0.1745, reg_loss: 0.1591
2022-04-24 01:35:34 - train: epoch 0013, iter [01800, 03664], lr: 0.000001, total_loss: 0.3365, cls_loss: 0.1747, reg_loss: 0.1619
2022-04-24 01:36:12 - train: epoch 0013, iter [01900, 03664], lr: 0.000001, total_loss: 0.4180, cls_loss: 0.2262, reg_loss: 0.1918
2022-04-24 01:36:54 - train: epoch 0013, iter [02000, 03664], lr: 0.000001, total_loss: 0.3203, cls_loss: 0.1599, reg_loss: 0.1604
2022-04-24 01:37:34 - train: epoch 0013, iter [02100, 03664], lr: 0.000001, total_loss: 0.3973, cls_loss: 0.2214, reg_loss: 0.1760
2022-04-24 01:38:12 - train: epoch 0013, iter [02200, 03664], lr: 0.000001, total_loss: 0.3951, cls_loss: 0.2223, reg_loss: 0.1728
2022-04-24 01:38:51 - train: epoch 0013, iter [02300, 03664], lr: 0.000001, total_loss: 0.3939, cls_loss: 0.2132, reg_loss: 0.1807
2022-04-24 01:39:34 - train: epoch 0013, iter [02400, 03664], lr: 0.000001, total_loss: 0.3904, cls_loss: 0.2246, reg_loss: 0.1658
2022-04-24 01:40:13 - train: epoch 0013, iter [02500, 03664], lr: 0.000001, total_loss: 0.3510, cls_loss: 0.1856, reg_loss: 0.1654
2022-04-24 01:40:52 - train: epoch 0013, iter [02600, 03664], lr: 0.000001, total_loss: 0.3264, cls_loss: 0.1752, reg_loss: 0.1512
2022-04-24 01:41:30 - train: epoch 0013, iter [02700, 03664], lr: 0.000001, total_loss: 0.3437, cls_loss: 0.1882, reg_loss: 0.1555
2022-04-24 01:42:13 - train: epoch 0013, iter [02800, 03664], lr: 0.000001, total_loss: 0.3642, cls_loss: 0.1951, reg_loss: 0.1691
2022-04-24 01:42:51 - train: epoch 0013, iter [02900, 03664], lr: 0.000001, total_loss: 0.3177, cls_loss: 0.1645, reg_loss: 0.1531
2022-04-24 01:43:30 - train: epoch 0013, iter [03000, 03664], lr: 0.000001, total_loss: 0.3956, cls_loss: 0.2159, reg_loss: 0.1797
2022-04-24 01:44:13 - train: epoch 0013, iter [03100, 03664], lr: 0.000001, total_loss: 0.3055, cls_loss: 0.1609, reg_loss: 0.1446
2022-04-24 01:44:51 - train: epoch 0013, iter [03200, 03664], lr: 0.000001, total_loss: 0.3812, cls_loss: 0.2000, reg_loss: 0.1812
2022-04-24 01:45:30 - train: epoch 0013, iter [03300, 03664], lr: 0.000001, total_loss: 0.3644, cls_loss: 0.1999, reg_loss: 0.1645
2022-04-24 01:46:08 - train: epoch 0013, iter [03400, 03664], lr: 0.000001, total_loss: 0.4808, cls_loss: 0.2616, reg_loss: 0.2192
2022-04-24 01:46:50 - train: epoch 0013, iter [03500, 03664], lr: 0.000001, total_loss: 0.2887, cls_loss: 0.1498, reg_loss: 0.1389
2022-04-24 01:47:29 - train: epoch 0013, iter [03600, 03664], lr: 0.000001, total_loss: 0.3180, cls_loss: 0.1622, reg_loss: 0.1558
2022-04-24 01:47:54 - train: epoch 013, train_loss: 0.3609
2022-04-24 01:52:41 - eval: epoch: 013
per_image_load_time: 1.842ms
per_image_inference_time: 49.279ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 32.97228044314884
IoU=0.50,area=all,maxDets=100,mAP: 49.53048017727383
IoU=0.75,area=all,maxDets=100,mAP: 35.28434033957132
IoU=0.50:0.95,area=small,maxDets=100,mAP: 14.461260382632055
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 38.20766116877541
IoU=0.50:0.95,area=large,maxDets=100,mAP: 47.95056593010364
IoU=0.50:0.95,area=all,maxDets=1,mAR: 27.62780297200446
IoU=0.50:0.95,area=all,maxDets=10,mAR: 41.417772279503154
IoU=0.50:0.95,area=all,maxDets=100,mAR: 43.11227091015644
IoU=0.50:0.95,area=small,maxDets=100,mAR: 18.891354257065256
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 50.04633285085114
IoU=0.50:0.95,area=large,maxDets=100,mAR: 61.21002483654618

2022-04-24 01:52:42 - until epoch: 013, best_metric: 32.972%
2022-04-24 01:52:42 - train done. model: resnet50_retinanet, train time: 5.653 hours, best_metric: 32.972%
