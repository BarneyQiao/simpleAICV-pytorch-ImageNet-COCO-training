2022-07-24 14:59:48 - network: resnet50_retinanet
2022-07-24 14:59:48 - num_classes: 80
2022-07-24 14:59:48 - input_image_size: [640, 640]
2022-07-24 14:59:48 - backbone_pretrained_path: /root/code/SimpleAICV-ImageNet-CIFAR-COCO-VOC-training/pretrained_models/resnet/resnet50-acc76.264.pth
2022-07-24 14:59:48 - trained_model_path: 
2022-07-24 14:59:48 - train_criterion: RetinaLoss()
2022-07-24 14:59:48 - test_criterion: RetinaLoss()
2022-07-24 14:59:48 - decoder: <simpleAICV.detection.decode.RetinaDecoder object at 0x7f624001f460>
2022-07-24 14:59:48 - train_dataset: <simpleAICV.detection.datasets.cocodataset.CocoDetection object at 0x7f624001f7c0>
2022-07-24 14:59:48 - test_dataset: <simpleAICV.detection.datasets.cocodataset.CocoDetection object at 0x7f622c03acd0>
2022-07-24 14:59:48 - train_collater: <simpleAICV.detection.common.DetectionCollater object at 0x7f622c03aca0>
2022-07-24 14:59:48 - test_collater: <simpleAICV.detection.common.DetectionCollater object at 0x7f622c03ac40>
2022-07-24 14:59:48 - seed: 0
2022-07-24 14:59:48 - batch_size: 32
2022-07-24 14:59:48 - num_workers: 16
2022-07-24 14:59:48 - optimizer: ('AdamW', {'lr': 0.0001, 'global_weight_decay': False, 'weight_decay': 0.001, 'no_weight_decay_layer_name_list': []})
2022-07-24 14:59:48 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [8, 12]})
2022-07-24 14:59:48 - epochs: 13
2022-07-24 14:59:48 - print_interval: 100
2022-07-24 14:59:48 - accumulation_steps: 1
2022-07-24 14:59:48 - eval_type: COCO
2022-07-24 14:59:48 - eval_epoch: [1, 3, 5, 8, 10, 12, 13]
2022-07-24 14:59:48 - eval_voc_iou_threshold_list: [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]
2022-07-24 14:59:48 - save_model_metric: IoU=0.50:0.95,area=all,maxDets=100,mAP
2022-07-24 14:59:48 - sync_bn: False
2022-07-24 14:59:48 - apex: True
2022-07-24 14:59:48 - use_ema_model: False
2022-07-24 14:59:48 - ema_model_decay: 0.9999
2022-07-24 14:59:48 - gpus_type: NVIDIA RTX A5000
2022-07-24 14:59:48 - gpus_num: 2
2022-07-24 14:59:48 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f620102dc70>
2022-07-24 14:59:48 - --------------------parameters--------------------
2022-07-24 14:59:48 - name: backbone.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.0.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.0.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.0.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.0.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.0.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.0.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.0.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.0.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.0.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.0.downsample_conv.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.0.downsample_conv.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.0.downsample_conv.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.1.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.1.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.1.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.1.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.1.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.1.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.1.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.1.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.1.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.2.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.2.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.2.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.2.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.2.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.2.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.2.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.2.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer1.2.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.0.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.0.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.0.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.0.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.0.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.0.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.0.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.0.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.0.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.0.downsample_conv.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.0.downsample_conv.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.0.downsample_conv.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.1.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.1.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.1.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.1.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.1.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.1.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.1.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.1.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.1.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.2.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.2.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.2.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.2.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.2.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.2.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.2.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.2.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.2.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.3.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.3.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.3.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.3.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.3.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.3.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.3.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.3.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer2.3.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.0.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.0.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.0.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.0.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.0.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.0.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.0.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.0.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.0.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.0.downsample_conv.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.0.downsample_conv.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.0.downsample_conv.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.1.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.1.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.1.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.1.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.1.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.1.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.1.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.1.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.1.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.2.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.2.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.2.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.2.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.2.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.2.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.2.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.2.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.2.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.3.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.3.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.3.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.3.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.3.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.3.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.3.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.3.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.3.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.4.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.4.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.4.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.4.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.4.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.4.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.4.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.4.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.4.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.5.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.5.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.5.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.5.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.5.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.5.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.5.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.5.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer3.5.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.0.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.0.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.0.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.0.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.0.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.0.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.0.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.0.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.0.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.0.downsample_conv.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.0.downsample_conv.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.0.downsample_conv.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.1.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.1.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.1.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.1.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.1.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.1.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.1.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.1.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.1.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.2.conv1.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.2.conv1.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.2.conv1.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.2.conv2.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.2.conv2.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.2.conv2.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.2.conv3.layer.0.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.2.conv3.layer.1.weight, grad: True
2022-07-24 14:59:48 - name: backbone.layer4.2.conv3.layer.1.bias, grad: True
2022-07-24 14:59:48 - name: fpn.P3_1.weight, grad: True
2022-07-24 14:59:48 - name: fpn.P3_1.bias, grad: True
2022-07-24 14:59:48 - name: fpn.P3_2.weight, grad: True
2022-07-24 14:59:48 - name: fpn.P3_2.bias, grad: True
2022-07-24 14:59:48 - name: fpn.P4_1.weight, grad: True
2022-07-24 14:59:48 - name: fpn.P4_1.bias, grad: True
2022-07-24 14:59:48 - name: fpn.P4_2.weight, grad: True
2022-07-24 14:59:48 - name: fpn.P4_2.bias, grad: True
2022-07-24 14:59:48 - name: fpn.P5_1.weight, grad: True
2022-07-24 14:59:48 - name: fpn.P5_1.bias, grad: True
2022-07-24 14:59:48 - name: fpn.P5_2.weight, grad: True
2022-07-24 14:59:48 - name: fpn.P5_2.bias, grad: True
2022-07-24 14:59:48 - name: fpn.P6.weight, grad: True
2022-07-24 14:59:48 - name: fpn.P6.bias, grad: True
2022-07-24 14:59:48 - name: fpn.P7.1.weight, grad: True
2022-07-24 14:59:48 - name: fpn.P7.1.bias, grad: True
2022-07-24 14:59:48 - name: cls_head.cls_head.0.weight, grad: True
2022-07-24 14:59:48 - name: cls_head.cls_head.0.bias, grad: True
2022-07-24 14:59:48 - name: cls_head.cls_head.2.weight, grad: True
2022-07-24 14:59:48 - name: cls_head.cls_head.2.bias, grad: True
2022-07-24 14:59:48 - name: cls_head.cls_head.4.weight, grad: True
2022-07-24 14:59:48 - name: cls_head.cls_head.4.bias, grad: True
2022-07-24 14:59:48 - name: cls_head.cls_head.6.weight, grad: True
2022-07-24 14:59:48 - name: cls_head.cls_head.6.bias, grad: True
2022-07-24 14:59:48 - name: cls_head.cls_out.weight, grad: True
2022-07-24 14:59:48 - name: cls_head.cls_out.bias, grad: True
2022-07-24 14:59:48 - name: reg_head.reg_head.0.weight, grad: True
2022-07-24 14:59:48 - name: reg_head.reg_head.0.bias, grad: True
2022-07-24 14:59:48 - name: reg_head.reg_head.2.weight, grad: True
2022-07-24 14:59:48 - name: reg_head.reg_head.2.bias, grad: True
2022-07-24 14:59:48 - name: reg_head.reg_head.4.weight, grad: True
2022-07-24 14:59:48 - name: reg_head.reg_head.4.bias, grad: True
2022-07-24 14:59:48 - name: reg_head.reg_head.6.weight, grad: True
2022-07-24 14:59:48 - name: reg_head.reg_head.6.bias, grad: True
2022-07-24 14:59:48 - name: reg_head.reg_out.weight, grad: True
2022-07-24 14:59:48 - name: reg_head.reg_out.bias, grad: True
2022-07-24 14:59:48 - --------------------buffers--------------------
2022-07-24 14:59:48 - name: backbone.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.0.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.0.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.0.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.0.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.0.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.0.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.0.downsample_conv.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.1.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.1.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.1.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.1.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.1.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.1.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.2.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.2.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.2.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.2.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.2.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.2.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer1.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.0.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.0.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.0.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.0.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.0.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.0.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.1.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.1.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.1.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.1.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.1.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.1.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.2.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.2.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.2.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.2.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.2.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.2.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.3.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.3.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.3.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.3.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.3.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.3.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer2.3.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.0.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.0.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.0.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.0.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.0.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.0.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.1.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.1.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.1.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.1.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.1.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.1.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.2.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.2.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.2.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.2.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.2.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.2.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.3.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.3.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.3.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.3.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.3.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.3.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.3.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.4.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.4.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.4.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.4.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.4.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.4.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.4.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.5.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.5.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.5.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.5.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.5.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.5.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer3.5.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.0.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.0.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.0.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.0.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.0.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.0.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.0.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.1.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.1.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.1.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.1.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.1.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.1.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.1.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.2.conv1.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.2.conv1.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.2.conv2.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.2.conv2.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.2.conv3.layer.1.running_mean, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.2.conv3.layer.1.running_var, grad: False
2022-07-24 14:59:48 - name: backbone.layer4.2.conv3.layer.1.num_batches_tracked, grad: False
2022-07-24 14:59:48 - -----------no weight decay layers--------------
2022-07-24 14:59:48 - name: backbone.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.3.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.3.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.3.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.3.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.3.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.3.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.3.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.3.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.3.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.3.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.3.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.3.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.4.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.4.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.4.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.4.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.4.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.4.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.5.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.5.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.5.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.5.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.5.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.5.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P3_1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P3_2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P4_1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P4_2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P5_1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P5_2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P6.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P7.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: cls_head.cls_head.0.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: cls_head.cls_head.2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: cls_head.cls_head.4.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: cls_head.cls_head.6.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: cls_head.cls_out.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: reg_head.reg_head.0.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: reg_head.reg_head.2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: reg_head.reg_head.4.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: reg_head.reg_head.6.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - name: reg_head.reg_out.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-24 14:59:48 - -------------weight decay layers---------------
2022-07-24 14:59:48 - name: backbone.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.0.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.0.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.0.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.0.downsample_conv.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.1.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.1.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.1.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.2.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.2.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer1.2.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.0.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.0.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.0.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.1.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.1.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.1.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.2.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.2.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.2.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.3.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.3.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer2.3.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.0.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.0.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.0.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.1.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.1.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.1.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.2.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.2.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.2.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.3.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.3.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.3.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.4.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.4.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.4.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.5.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.5.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer3.5.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.0.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.0.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.0.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.1.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.1.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.1.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.2.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.2.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: backbone.layer4.2.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P3_1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P3_2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P4_1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P4_2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P5_1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P5_2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P6.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: fpn.P7.1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: cls_head.cls_head.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: cls_head.cls_head.2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: cls_head.cls_head.4.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: cls_head.cls_head.6.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: cls_head.cls_out.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: reg_head.reg_head.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: reg_head.reg_head.2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: reg_head.reg_head.4.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: reg_head.reg_head.6.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - name: reg_head.reg_out.weight, weight_decay: 0.001, lr_scale: not setting!
2022-07-24 14:59:48 - epoch 001 lr: 0.000100
2022-07-24 15:00:33 - train: epoch 0001, iter [00100, 03664], lr: 0.000100, total_loss: 1.1222, cls_loss: 0.7593, reg_loss: 0.3628, 
2022-07-24 15:01:13 - train: epoch 0001, iter [00200, 03664], lr: 0.000100, total_loss: 1.0447, cls_loss: 0.7255, reg_loss: 0.3192, 
2022-07-24 15:01:58 - train: epoch 0001, iter [00300, 03664], lr: 0.000100, total_loss: 0.8676, cls_loss: 0.5874, reg_loss: 0.2801, 
2022-07-24 15:02:38 - train: epoch 0001, iter [00400, 03664], lr: 0.000100, total_loss: 0.8900, cls_loss: 0.6005, reg_loss: 0.2895, 
2022-07-24 15:03:17 - train: epoch 0001, iter [00500, 03664], lr: 0.000100, total_loss: 0.8023, cls_loss: 0.5212, reg_loss: 0.2811, 
2022-07-24 15:03:57 - train: epoch 0001, iter [00600, 03664], lr: 0.000100, total_loss: 0.8429, cls_loss: 0.5732, reg_loss: 0.2697, 
2022-07-24 15:04:42 - train: epoch 0001, iter [00700, 03664], lr: 0.000100, total_loss: 0.7532, cls_loss: 0.4738, reg_loss: 0.2794, 
2022-07-24 15:05:21 - train: epoch 0001, iter [00800, 03664], lr: 0.000100, total_loss: 0.7908, cls_loss: 0.5052, reg_loss: 0.2857, 
2022-07-24 15:06:01 - train: epoch 0001, iter [00900, 03664], lr: 0.000100, total_loss: 0.7673, cls_loss: 0.5090, reg_loss: 0.2583, 
2022-07-24 15:06:47 - train: epoch 0001, iter [01000, 03664], lr: 0.000100, total_loss: 0.7321, cls_loss: 0.4577, reg_loss: 0.2743, 
2022-07-24 15:07:26 - train: epoch 0001, iter [01100, 03664], lr: 0.000100, total_loss: 0.6550, cls_loss: 0.4015, reg_loss: 0.2535, 
2022-07-24 15:08:06 - train: epoch 0001, iter [01200, 03664], lr: 0.000100, total_loss: 0.6755, cls_loss: 0.4428, reg_loss: 0.2327, 
2022-07-24 15:08:49 - train: epoch 0001, iter [01300, 03664], lr: 0.000100, total_loss: 0.7256, cls_loss: 0.4734, reg_loss: 0.2522, 
2022-07-24 15:09:31 - train: epoch 0001, iter [01400, 03664], lr: 0.000100, total_loss: 0.6632, cls_loss: 0.4396, reg_loss: 0.2236, 
2022-07-24 15:10:11 - train: epoch 0001, iter [01500, 03664], lr: 0.000100, total_loss: 0.6474, cls_loss: 0.4146, reg_loss: 0.2329, 
2022-07-24 15:10:51 - train: epoch 0001, iter [01600, 03664], lr: 0.000100, total_loss: 0.6768, cls_loss: 0.4235, reg_loss: 0.2533, 
2022-07-24 15:11:36 - train: epoch 0001, iter [01700, 03664], lr: 0.000100, total_loss: 0.6681, cls_loss: 0.4225, reg_loss: 0.2456, 
2022-07-24 15:12:16 - train: epoch 0001, iter [01800, 03664], lr: 0.000100, total_loss: 0.6930, cls_loss: 0.4715, reg_loss: 0.2215, 
2022-07-24 15:12:55 - train: epoch 0001, iter [01900, 03664], lr: 0.000100, total_loss: 0.6670, cls_loss: 0.4253, reg_loss: 0.2417, 
2022-07-24 15:13:40 - train: epoch 0001, iter [02000, 03664], lr: 0.000100, total_loss: 0.6257, cls_loss: 0.3791, reg_loss: 0.2467, 
2022-07-24 15:14:20 - train: epoch 0001, iter [02100, 03664], lr: 0.000100, total_loss: 0.6481, cls_loss: 0.4064, reg_loss: 0.2417, 
2022-07-24 15:15:00 - train: epoch 0001, iter [02200, 03664], lr: 0.000100, total_loss: 0.6402, cls_loss: 0.3897, reg_loss: 0.2505, 
2022-07-24 15:15:42 - train: epoch 0001, iter [02300, 03664], lr: 0.000100, total_loss: 0.6668, cls_loss: 0.4161, reg_loss: 0.2507, 
2022-07-24 15:16:24 - train: epoch 0001, iter [02400, 03664], lr: 0.000100, total_loss: 0.6342, cls_loss: 0.3889, reg_loss: 0.2454, 
2022-07-24 15:17:04 - train: epoch 0001, iter [02500, 03664], lr: 0.000100, total_loss: 0.5612, cls_loss: 0.3408, reg_loss: 0.2205, 
2022-07-24 15:17:44 - train: epoch 0001, iter [02600, 03664], lr: 0.000100, total_loss: 0.6494, cls_loss: 0.4078, reg_loss: 0.2416, 
2022-07-24 15:18:28 - train: epoch 0001, iter [02700, 03664], lr: 0.000100, total_loss: 0.5812, cls_loss: 0.3537, reg_loss: 0.2275, 
2022-07-24 15:19:08 - train: epoch 0001, iter [02800, 03664], lr: 0.000100, total_loss: 0.5978, cls_loss: 0.3886, reg_loss: 0.2092, 
2022-07-24 15:19:48 - train: epoch 0001, iter [02900, 03664], lr: 0.000100, total_loss: 0.6119, cls_loss: 0.3819, reg_loss: 0.2300, 
2022-07-24 15:20:33 - train: epoch 0001, iter [03000, 03664], lr: 0.000100, total_loss: 0.6069, cls_loss: 0.3705, reg_loss: 0.2364, 
2022-07-24 15:21:13 - train: epoch 0001, iter [03100, 03664], lr: 0.000100, total_loss: 0.5849, cls_loss: 0.3616, reg_loss: 0.2233, 
2022-07-24 15:21:53 - train: epoch 0001, iter [03200, 03664], lr: 0.000100, total_loss: 0.5936, cls_loss: 0.3761, reg_loss: 0.2174, 
2022-07-24 15:22:37 - train: epoch 0001, iter [03300, 03664], lr: 0.000100, total_loss: 0.5927, cls_loss: 0.3573, reg_loss: 0.2354, 
2022-07-24 15:23:17 - train: epoch 0001, iter [03400, 03664], lr: 0.000100, total_loss: 0.5878, cls_loss: 0.3573, reg_loss: 0.2305, 
2022-07-24 15:23:57 - train: epoch 0001, iter [03500, 03664], lr: 0.000100, total_loss: 0.6206, cls_loss: 0.3843, reg_loss: 0.2363, 
2022-07-24 15:24:37 - train: epoch 0001, iter [03600, 03664], lr: 0.000100, total_loss: 0.6080, cls_loss: 0.3718, reg_loss: 0.2362, 
2022-07-24 15:25:08 - train: epoch 001, train_loss: 0.7068
2022-07-24 15:30:07 - eval: epoch: 001
test_loss: 0.5832
per_image_load_time: 2.586ms
per_image_inference_time: 50.008ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 19.077877681003798
IoU=0.50,area=all,maxDets=100,mAP: 32.046552790983355
IoU=0.75,area=all,maxDets=100,mAP: 19.63686967482813
IoU=0.50:0.95,area=small,maxDets=100,mAP: 6.943074782917091
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 22.148524626261626
IoU=0.50:0.95,area=large,maxDets=100,mAP: 27.307351111152155
IoU=0.50:0.95,area=all,maxDets=1,mAR: 18.59517378370843
IoU=0.50:0.95,area=all,maxDets=10,mAR: 28.387748866782868
IoU=0.50:0.95,area=all,maxDets=100,mAR: 29.65197743486863
IoU=0.50:0.95,area=small,maxDets=100,mAR: 9.549011977254656
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 34.012582917630056
IoU=0.50:0.95,area=large,maxDets=100,mAR: 41.452165423712046

2022-07-24 15:30:07 - until epoch: 001, best_metric: 19.078%
2022-07-24 15:30:07 - epoch 002 lr: 0.000100
2022-07-24 15:30:54 - train: epoch 0002, iter [00100, 03664], lr: 0.000100, total_loss: 0.6273, cls_loss: 0.4026, reg_loss: 0.2247, 
2022-07-24 15:31:34 - train: epoch 0002, iter [00200, 03664], lr: 0.000100, total_loss: 0.5150, cls_loss: 0.3181, reg_loss: 0.1969, 
2022-07-24 15:32:15 - train: epoch 0002, iter [00300, 03664], lr: 0.000100, total_loss: 0.5348, cls_loss: 0.3221, reg_loss: 0.2127, 
2022-07-24 15:32:57 - train: epoch 0002, iter [00400, 03664], lr: 0.000100, total_loss: 0.5776, cls_loss: 0.3546, reg_loss: 0.2230, 
2022-07-24 15:33:40 - train: epoch 0002, iter [00500, 03664], lr: 0.000100, total_loss: 0.5409, cls_loss: 0.3288, reg_loss: 0.2121, 
2022-07-24 15:34:20 - train: epoch 0002, iter [00600, 03664], lr: 0.000100, total_loss: 0.5505, cls_loss: 0.3409, reg_loss: 0.2096, 
2022-07-24 15:35:00 - train: epoch 0002, iter [00700, 03664], lr: 0.000100, total_loss: 0.6078, cls_loss: 0.3651, reg_loss: 0.2427, 
2022-07-24 15:35:44 - train: epoch 0002, iter [00800, 03664], lr: 0.000100, total_loss: 0.6276, cls_loss: 0.3885, reg_loss: 0.2391, 
2022-07-24 15:36:24 - train: epoch 0002, iter [00900, 03664], lr: 0.000100, total_loss: 0.5601, cls_loss: 0.3374, reg_loss: 0.2226, 
2022-07-24 15:37:04 - train: epoch 0002, iter [01000, 03664], lr: 0.000100, total_loss: 0.5384, cls_loss: 0.3215, reg_loss: 0.2168, 
2022-07-24 15:37:48 - train: epoch 0002, iter [01100, 03664], lr: 0.000100, total_loss: 0.5537, cls_loss: 0.3368, reg_loss: 0.2169, 
2022-07-24 15:38:28 - train: epoch 0002, iter [01200, 03664], lr: 0.000100, total_loss: 0.6739, cls_loss: 0.4383, reg_loss: 0.2356, 
2022-07-24 15:39:07 - train: epoch 0002, iter [01300, 03664], lr: 0.000100, total_loss: 0.5285, cls_loss: 0.3088, reg_loss: 0.2197, 
2022-07-24 15:39:49 - train: epoch 0002, iter [01400, 03664], lr: 0.000100, total_loss: 0.5431, cls_loss: 0.3337, reg_loss: 0.2094, 
2022-07-24 15:40:30 - train: epoch 0002, iter [01500, 03664], lr: 0.000100, total_loss: 0.5292, cls_loss: 0.3276, reg_loss: 0.2017, 
2022-07-24 15:41:10 - train: epoch 0002, iter [01600, 03664], lr: 0.000100, total_loss: 0.5621, cls_loss: 0.3530, reg_loss: 0.2091, 
2022-07-24 15:41:50 - train: epoch 0002, iter [01700, 03664], lr: 0.000100, total_loss: 0.5858, cls_loss: 0.3646, reg_loss: 0.2212, 
2022-07-24 15:42:33 - train: epoch 0002, iter [01800, 03664], lr: 0.000100, total_loss: 0.5631, cls_loss: 0.3402, reg_loss: 0.2229, 
2022-07-24 15:43:13 - train: epoch 0002, iter [01900, 03664], lr: 0.000100, total_loss: 0.5809, cls_loss: 0.3550, reg_loss: 0.2259, 
2022-07-24 15:43:52 - train: epoch 0002, iter [02000, 03664], lr: 0.000100, total_loss: 0.5111, cls_loss: 0.3016, reg_loss: 0.2095, 
2022-07-24 15:44:35 - train: epoch 0002, iter [02100, 03664], lr: 0.000100, total_loss: 0.5775, cls_loss: 0.3640, reg_loss: 0.2135, 
2022-07-24 15:45:15 - train: epoch 0002, iter [02200, 03664], lr: 0.000100, total_loss: 0.5155, cls_loss: 0.3017, reg_loss: 0.2138, 
2022-07-24 15:45:55 - train: epoch 0002, iter [02300, 03664], lr: 0.000100, total_loss: 0.5962, cls_loss: 0.3786, reg_loss: 0.2175, 
2022-07-24 15:46:36 - train: epoch 0002, iter [02400, 03664], lr: 0.000100, total_loss: 0.4845, cls_loss: 0.2929, reg_loss: 0.1916, 
2022-07-24 15:47:18 - train: epoch 0002, iter [02500, 03664], lr: 0.000100, total_loss: 0.5270, cls_loss: 0.3111, reg_loss: 0.2159, 
2022-07-24 15:47:57 - train: epoch 0002, iter [02600, 03664], lr: 0.000100, total_loss: 0.4692, cls_loss: 0.2793, reg_loss: 0.1898, 
2022-07-24 15:48:37 - train: epoch 0002, iter [02700, 03664], lr: 0.000100, total_loss: 0.5281, cls_loss: 0.3231, reg_loss: 0.2050, 
2022-07-24 15:49:20 - train: epoch 0002, iter [02800, 03664], lr: 0.000100, total_loss: 0.5700, cls_loss: 0.3526, reg_loss: 0.2174, 
2022-07-24 15:50:01 - train: epoch 0002, iter [02900, 03664], lr: 0.000100, total_loss: 0.5716, cls_loss: 0.3568, reg_loss: 0.2148, 
2022-07-24 15:50:40 - train: epoch 0002, iter [03000, 03664], lr: 0.000100, total_loss: 0.5523, cls_loss: 0.3365, reg_loss: 0.2159, 
2022-07-24 15:51:24 - train: epoch 0002, iter [03100, 03664], lr: 0.000100, total_loss: 0.4867, cls_loss: 0.2765, reg_loss: 0.2102, 
2022-07-24 15:52:04 - train: epoch 0002, iter [03200, 03664], lr: 0.000100, total_loss: 0.5563, cls_loss: 0.3538, reg_loss: 0.2025, 
2022-07-24 15:52:44 - train: epoch 0002, iter [03300, 03664], lr: 0.000100, total_loss: 0.5605, cls_loss: 0.3551, reg_loss: 0.2053, 
2022-07-24 15:53:25 - train: epoch 0002, iter [03400, 03664], lr: 0.000100, total_loss: 0.5732, cls_loss: 0.3447, reg_loss: 0.2284, 
2022-07-24 15:54:07 - train: epoch 0002, iter [03500, 03664], lr: 0.000100, total_loss: 0.5525, cls_loss: 0.3480, reg_loss: 0.2045, 
2022-07-24 15:54:46 - train: epoch 0002, iter [03600, 03664], lr: 0.000100, total_loss: 0.5098, cls_loss: 0.3176, reg_loss: 0.1922, 
2022-07-24 15:55:12 - train: epoch 002, train_loss: 0.5474
2022-07-24 15:55:13 - until epoch: 002, best_metric: 19.078%
2022-07-24 15:55:13 - epoch 003 lr: 0.000100
2022-07-24 15:56:02 - train: epoch 0003, iter [00100, 03664], lr: 0.000100, total_loss: 0.5029, cls_loss: 0.2976, reg_loss: 0.2053, 
2022-07-24 15:56:42 - train: epoch 0003, iter [00200, 03664], lr: 0.000100, total_loss: 0.5591, cls_loss: 0.3426, reg_loss: 0.2166, 
2022-07-24 15:57:22 - train: epoch 0003, iter [00300, 03664], lr: 0.000100, total_loss: 0.5487, cls_loss: 0.3070, reg_loss: 0.2417, 
2022-07-24 15:58:03 - train: epoch 0003, iter [00400, 03664], lr: 0.000100, total_loss: 0.5505, cls_loss: 0.3281, reg_loss: 0.2223, 
2022-07-24 15:58:45 - train: epoch 0003, iter [00500, 03664], lr: 0.000100, total_loss: 0.5820, cls_loss: 0.3452, reg_loss: 0.2368, 
2022-07-24 15:59:25 - train: epoch 0003, iter [00600, 03664], lr: 0.000100, total_loss: 0.4542, cls_loss: 0.2550, reg_loss: 0.1991, 
2022-07-24 16:00:04 - train: epoch 0003, iter [00700, 03664], lr: 0.000100, total_loss: 0.5587, cls_loss: 0.3564, reg_loss: 0.2023, 
2022-07-24 16:00:48 - train: epoch 0003, iter [00800, 03664], lr: 0.000100, total_loss: 0.5529, cls_loss: 0.3262, reg_loss: 0.2267, 
2022-07-24 16:01:28 - train: epoch 0003, iter [00900, 03664], lr: 0.000100, total_loss: 0.5100, cls_loss: 0.3053, reg_loss: 0.2047, 
2022-07-24 16:02:07 - train: epoch 0003, iter [01000, 03664], lr: 0.000100, total_loss: 0.5113, cls_loss: 0.3034, reg_loss: 0.2079, 
2022-07-24 16:02:49 - train: epoch 0003, iter [01100, 03664], lr: 0.000100, total_loss: 0.4545, cls_loss: 0.2655, reg_loss: 0.1890, 
2022-07-24 16:03:31 - train: epoch 0003, iter [01200, 03664], lr: 0.000100, total_loss: 0.4945, cls_loss: 0.2923, reg_loss: 0.2022, 
2022-07-24 16:04:10 - train: epoch 0003, iter [01300, 03664], lr: 0.000100, total_loss: 0.5104, cls_loss: 0.3087, reg_loss: 0.2016, 
2022-07-24 16:04:50 - train: epoch 0003, iter [01400, 03664], lr: 0.000100, total_loss: 0.4482, cls_loss: 0.2586, reg_loss: 0.1895, 
2022-07-24 16:05:34 - train: epoch 0003, iter [01500, 03664], lr: 0.000100, total_loss: 0.5125, cls_loss: 0.2981, reg_loss: 0.2145, 
2022-07-24 16:06:14 - train: epoch 0003, iter [01600, 03664], lr: 0.000100, total_loss: 0.4689, cls_loss: 0.2634, reg_loss: 0.2054, 
2022-07-24 16:06:54 - train: epoch 0003, iter [01700, 03664], lr: 0.000100, total_loss: 0.4660, cls_loss: 0.2845, reg_loss: 0.1815, 
2022-07-24 16:07:38 - train: epoch 0003, iter [01800, 03664], lr: 0.000100, total_loss: 0.5269, cls_loss: 0.3311, reg_loss: 0.1958, 
2022-07-24 16:08:17 - train: epoch 0003, iter [01900, 03664], lr: 0.000100, total_loss: 0.5628, cls_loss: 0.3469, reg_loss: 0.2159, 
2022-07-24 16:08:57 - train: epoch 0003, iter [02000, 03664], lr: 0.000100, total_loss: 0.4593, cls_loss: 0.2649, reg_loss: 0.1944, 
2022-07-24 16:09:38 - train: epoch 0003, iter [02100, 03664], lr: 0.000100, total_loss: 0.5287, cls_loss: 0.3116, reg_loss: 0.2171, 
2022-07-24 16:10:20 - train: epoch 0003, iter [02200, 03664], lr: 0.000100, total_loss: 0.5312, cls_loss: 0.3128, reg_loss: 0.2184, 
2022-07-24 16:11:00 - train: epoch 0003, iter [02300, 03664], lr: 0.000100, total_loss: 0.5154, cls_loss: 0.3036, reg_loss: 0.2118, 
2022-07-24 16:11:41 - train: epoch 0003, iter [02400, 03664], lr: 0.000100, total_loss: 0.4918, cls_loss: 0.2987, reg_loss: 0.1932, 
2022-07-24 16:12:23 - train: epoch 0003, iter [02500, 03664], lr: 0.000100, total_loss: 0.4604, cls_loss: 0.2743, reg_loss: 0.1861, 
2022-07-24 16:13:03 - train: epoch 0003, iter [02600, 03664], lr: 0.000100, total_loss: 0.4457, cls_loss: 0.2641, reg_loss: 0.1816, 
2022-07-24 16:13:43 - train: epoch 0003, iter [02700, 03664], lr: 0.000100, total_loss: 0.4567, cls_loss: 0.2709, reg_loss: 0.1859, 
2022-07-24 16:14:26 - train: epoch 0003, iter [02800, 03664], lr: 0.000100, total_loss: 0.5151, cls_loss: 0.3124, reg_loss: 0.2027, 
2022-07-24 16:15:06 - train: epoch 0003, iter [02900, 03664], lr: 0.000100, total_loss: 0.4755, cls_loss: 0.2680, reg_loss: 0.2076, 
2022-07-24 16:15:46 - train: epoch 0003, iter [03000, 03664], lr: 0.000100, total_loss: 0.5079, cls_loss: 0.2963, reg_loss: 0.2115, 
2022-07-24 16:16:29 - train: epoch 0003, iter [03100, 03664], lr: 0.000100, total_loss: 0.5357, cls_loss: 0.3196, reg_loss: 0.2161, 
2022-07-24 16:17:09 - train: epoch 0003, iter [03200, 03664], lr: 0.000100, total_loss: 0.4454, cls_loss: 0.2671, reg_loss: 0.1783, 
2022-07-24 16:17:49 - train: epoch 0003, iter [03300, 03664], lr: 0.000100, total_loss: 0.4766, cls_loss: 0.2863, reg_loss: 0.1903, 
2022-07-24 16:18:30 - train: epoch 0003, iter [03400, 03664], lr: 0.000100, total_loss: 0.4945, cls_loss: 0.2962, reg_loss: 0.1983, 
2022-07-24 16:19:12 - train: epoch 0003, iter [03500, 03664], lr: 0.000100, total_loss: 0.5070, cls_loss: 0.2971, reg_loss: 0.2099, 
2022-07-24 16:19:52 - train: epoch 0003, iter [03600, 03664], lr: 0.000100, total_loss: 0.4971, cls_loss: 0.3079, reg_loss: 0.1893, 
2022-07-24 16:20:18 - train: epoch 003, train_loss: 0.5021
2022-07-24 16:24:45 - eval: epoch: 003
test_loss: 0.0000
per_image_load_time: 2.208ms
per_image_inference_time: 44.552ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 25.588888478342326
IoU=0.50,area=all,maxDets=100,mAP: 40.20382302207807
IoU=0.75,area=all,maxDets=100,mAP: 27.130418880156565
IoU=0.50:0.95,area=small,maxDets=100,mAP: 9.840327810017675
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 28.966829298196622
IoU=0.50:0.95,area=large,maxDets=100,mAP: 38.210089277014355
IoU=0.50:0.95,area=all,maxDets=1,mAR: 22.930875525041614
IoU=0.50:0.95,area=all,maxDets=10,mAR: 34.49331628114806
IoU=0.50:0.95,area=all,maxDets=100,mAR: 35.81843417389243
IoU=0.50:0.95,area=small,maxDets=100,mAR: 13.02795487794343
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 40.71903223582365
IoU=0.50:0.95,area=large,maxDets=100,mAR: 52.03064464094509

2022-07-24 16:24:46 - until epoch: 003, best_metric: 25.589%
2022-07-24 16:24:46 - epoch 004 lr: 0.000100
2022-07-24 16:25:37 - train: epoch 0004, iter [00100, 03664], lr: 0.000100, total_loss: 0.5263, cls_loss: 0.3027, reg_loss: 0.2237, 
2022-07-24 16:26:19 - train: epoch 0004, iter [00200, 03664], lr: 0.000100, total_loss: 0.4363, cls_loss: 0.2619, reg_loss: 0.1744, 
2022-07-24 16:27:00 - train: epoch 0004, iter [00300, 03664], lr: 0.000100, total_loss: 0.5080, cls_loss: 0.2913, reg_loss: 0.2166, 
2022-07-24 16:27:41 - train: epoch 0004, iter [00400, 03664], lr: 0.000100, total_loss: 0.5247, cls_loss: 0.3178, reg_loss: 0.2069, 
2022-07-24 16:28:21 - train: epoch 0004, iter [00500, 03664], lr: 0.000100, total_loss: 0.4749, cls_loss: 0.2797, reg_loss: 0.1953, 
2022-07-24 16:29:04 - train: epoch 0004, iter [00600, 03664], lr: 0.000100, total_loss: 0.4526, cls_loss: 0.2625, reg_loss: 0.1902, 
2022-07-24 16:29:44 - train: epoch 0004, iter [00700, 03664], lr: 0.000100, total_loss: 0.4381, cls_loss: 0.2742, reg_loss: 0.1638, 
2022-07-24 16:30:25 - train: epoch 0004, iter [00800, 03664], lr: 0.000100, total_loss: 0.4706, cls_loss: 0.2723, reg_loss: 0.1983, 
2022-07-24 16:31:07 - train: epoch 0004, iter [00900, 03664], lr: 0.000100, total_loss: 0.5047, cls_loss: 0.3108, reg_loss: 0.1939, 
2022-07-24 16:31:46 - train: epoch 0004, iter [01000, 03664], lr: 0.000100, total_loss: 0.4858, cls_loss: 0.3014, reg_loss: 0.1845, 
2022-07-24 16:32:28 - train: epoch 0004, iter [01100, 03664], lr: 0.000100, total_loss: 0.4595, cls_loss: 0.2737, reg_loss: 0.1858, 
2022-07-24 16:33:09 - train: epoch 0004, iter [01200, 03664], lr: 0.000100, total_loss: 0.4691, cls_loss: 0.2731, reg_loss: 0.1960, 
2022-07-24 16:33:49 - train: epoch 0004, iter [01300, 03664], lr: 0.000100, total_loss: 0.4998, cls_loss: 0.3076, reg_loss: 0.1922, 
2022-07-24 16:34:31 - train: epoch 0004, iter [01400, 03664], lr: 0.000100, total_loss: 0.5580, cls_loss: 0.3280, reg_loss: 0.2299, 
2022-07-24 16:35:11 - train: epoch 0004, iter [01500, 03664], lr: 0.000100, total_loss: 0.4582, cls_loss: 0.2580, reg_loss: 0.2003, 
2022-07-24 16:35:52 - train: epoch 0004, iter [01600, 03664], lr: 0.000100, total_loss: 0.3748, cls_loss: 0.2073, reg_loss: 0.1676, 
2022-07-24 16:36:32 - train: epoch 0004, iter [01700, 03664], lr: 0.000100, total_loss: 0.5172, cls_loss: 0.3203, reg_loss: 0.1968, 
2022-07-24 16:37:14 - train: epoch 0004, iter [01800, 03664], lr: 0.000100, total_loss: 0.4837, cls_loss: 0.2791, reg_loss: 0.2045, 
2022-07-24 16:37:55 - train: epoch 0004, iter [01900, 03664], lr: 0.000100, total_loss: 0.4714, cls_loss: 0.2936, reg_loss: 0.1779, 
2022-07-24 16:38:35 - train: epoch 0004, iter [02000, 03664], lr: 0.000100, total_loss: 0.4016, cls_loss: 0.2304, reg_loss: 0.1712, 
2022-07-24 16:39:17 - train: epoch 0004, iter [02100, 03664], lr: 0.000100, total_loss: 0.4005, cls_loss: 0.2353, reg_loss: 0.1651, 
2022-07-24 16:39:57 - train: epoch 0004, iter [02200, 03664], lr: 0.000100, total_loss: 0.4612, cls_loss: 0.2731, reg_loss: 0.1881, 
2022-07-24 16:40:38 - train: epoch 0004, iter [02300, 03664], lr: 0.000100, total_loss: 0.4185, cls_loss: 0.2415, reg_loss: 0.1770, 
2022-07-24 16:41:18 - train: epoch 0004, iter [02400, 03664], lr: 0.000100, total_loss: 0.4605, cls_loss: 0.2641, reg_loss: 0.1964, 
2022-07-24 16:42:00 - train: epoch 0004, iter [02500, 03664], lr: 0.000100, total_loss: 0.4363, cls_loss: 0.2444, reg_loss: 0.1919, 
2022-07-24 16:42:41 - train: epoch 0004, iter [02600, 03664], lr: 0.000100, total_loss: 0.4011, cls_loss: 0.2217, reg_loss: 0.1794, 
2022-07-24 16:43:21 - train: epoch 0004, iter [02700, 03664], lr: 0.000100, total_loss: 0.5173, cls_loss: 0.3238, reg_loss: 0.1935, 
2022-07-24 16:44:03 - train: epoch 0004, iter [02800, 03664], lr: 0.000100, total_loss: 0.4703, cls_loss: 0.2693, reg_loss: 0.2010, 
2022-07-24 16:44:44 - train: epoch 0004, iter [02900, 03664], lr: 0.000100, total_loss: 0.4289, cls_loss: 0.2394, reg_loss: 0.1894, 
2022-07-24 16:45:24 - train: epoch 0004, iter [03000, 03664], lr: 0.000100, total_loss: 0.4196, cls_loss: 0.2482, reg_loss: 0.1714, 
2022-07-24 16:46:06 - train: epoch 0004, iter [03100, 03664], lr: 0.000100, total_loss: 0.4704, cls_loss: 0.2801, reg_loss: 0.1903, 
2022-07-24 16:46:46 - train: epoch 0004, iter [03200, 03664], lr: 0.000100, total_loss: 0.4961, cls_loss: 0.2756, reg_loss: 0.2205, 
2022-07-24 16:47:28 - train: epoch 0004, iter [03300, 03664], lr: 0.000100, total_loss: 0.4203, cls_loss: 0.2421, reg_loss: 0.1782, 
2022-07-24 16:48:10 - train: epoch 0004, iter [03400, 03664], lr: 0.000100, total_loss: 0.5729, cls_loss: 0.3696, reg_loss: 0.2033, 
2022-07-24 16:48:49 - train: epoch 0004, iter [03500, 03664], lr: 0.000100, total_loss: 0.5406, cls_loss: 0.3338, reg_loss: 0.2068, 
2022-07-24 16:49:31 - train: epoch 0004, iter [03600, 03664], lr: 0.000100, total_loss: 0.4654, cls_loss: 0.2723, reg_loss: 0.1931, 
2022-07-24 16:49:57 - train: epoch 004, train_loss: 0.4745
2022-07-24 16:49:58 - until epoch: 004, best_metric: 25.589%
2022-07-24 16:49:58 - epoch 005 lr: 0.000100
2022-07-24 16:50:45 - train: epoch 0005, iter [00100, 03664], lr: 0.000100, total_loss: 0.4357, cls_loss: 0.2391, reg_loss: 0.1966, 
2022-07-24 16:51:25 - train: epoch 0005, iter [00200, 03664], lr: 0.000100, total_loss: 0.4382, cls_loss: 0.2557, reg_loss: 0.1825, 
2022-07-24 16:52:08 - train: epoch 0005, iter [00300, 03664], lr: 0.000100, total_loss: 0.3802, cls_loss: 0.2112, reg_loss: 0.1691, 
2022-07-24 16:52:52 - train: epoch 0005, iter [00400, 03664], lr: 0.000100, total_loss: 0.4534, cls_loss: 0.2698, reg_loss: 0.1836, 
2022-07-24 16:53:33 - train: epoch 0005, iter [00500, 03664], lr: 0.000100, total_loss: 0.4160, cls_loss: 0.2268, reg_loss: 0.1892, 
2022-07-24 16:54:16 - train: epoch 0005, iter [00600, 03664], lr: 0.000100, total_loss: 0.4604, cls_loss: 0.2690, reg_loss: 0.1914, 
2022-07-24 16:54:57 - train: epoch 0005, iter [00700, 03664], lr: 0.000100, total_loss: 0.4140, cls_loss: 0.2408, reg_loss: 0.1732, 
2022-07-24 16:55:40 - train: epoch 0005, iter [00800, 03664], lr: 0.000100, total_loss: 0.4933, cls_loss: 0.2894, reg_loss: 0.2039, 
2022-07-24 16:56:23 - train: epoch 0005, iter [00900, 03664], lr: 0.000100, total_loss: 0.4438, cls_loss: 0.2596, reg_loss: 0.1842, 
2022-07-24 16:57:03 - train: epoch 0005, iter [01000, 03664], lr: 0.000100, total_loss: 0.5187, cls_loss: 0.3238, reg_loss: 0.1949, 
2022-07-24 16:57:46 - train: epoch 0005, iter [01100, 03664], lr: 0.000100, total_loss: 0.4001, cls_loss: 0.2275, reg_loss: 0.1726, 
2022-07-24 16:58:26 - train: epoch 0005, iter [01200, 03664], lr: 0.000100, total_loss: 0.4679, cls_loss: 0.2733, reg_loss: 0.1946, 
2022-07-24 16:59:08 - train: epoch 0005, iter [01300, 03664], lr: 0.000100, total_loss: 0.3963, cls_loss: 0.2320, reg_loss: 0.1644, 
2022-07-24 16:59:51 - train: epoch 0005, iter [01400, 03664], lr: 0.000100, total_loss: 0.4092, cls_loss: 0.2232, reg_loss: 0.1860, 
2022-07-24 17:00:31 - train: epoch 0005, iter [01500, 03664], lr: 0.000100, total_loss: 0.4440, cls_loss: 0.2570, reg_loss: 0.1871, 
2022-07-24 17:01:14 - train: epoch 0005, iter [01600, 03664], lr: 0.000100, total_loss: 0.4126, cls_loss: 0.2308, reg_loss: 0.1818, 
2022-07-24 17:01:55 - train: epoch 0005, iter [01700, 03664], lr: 0.000100, total_loss: 0.4216, cls_loss: 0.2398, reg_loss: 0.1818, 
2022-07-24 17:02:38 - train: epoch 0005, iter [01800, 03664], lr: 0.000100, total_loss: 0.5085, cls_loss: 0.3001, reg_loss: 0.2084, 
2022-07-24 17:03:20 - train: epoch 0005, iter [01900, 03664], lr: 0.000100, total_loss: 0.4481, cls_loss: 0.2516, reg_loss: 0.1965, 
2022-07-24 17:04:00 - train: epoch 0005, iter [02000, 03664], lr: 0.000100, total_loss: 0.5200, cls_loss: 0.3028, reg_loss: 0.2172, 
2022-07-24 17:04:43 - train: epoch 0005, iter [02100, 03664], lr: 0.000100, total_loss: 0.4695, cls_loss: 0.2726, reg_loss: 0.1969, 
2022-07-24 17:05:26 - train: epoch 0005, iter [02200, 03664], lr: 0.000100, total_loss: 0.4613, cls_loss: 0.2699, reg_loss: 0.1914, 
2022-07-24 17:06:06 - train: epoch 0005, iter [02300, 03664], lr: 0.000100, total_loss: 0.4720, cls_loss: 0.2691, reg_loss: 0.2029, 
2022-07-24 17:06:49 - train: epoch 0005, iter [02400, 03664], lr: 0.000100, total_loss: 0.4746, cls_loss: 0.2758, reg_loss: 0.1988, 
2022-07-24 17:07:29 - train: epoch 0005, iter [02500, 03664], lr: 0.000100, total_loss: 0.4742, cls_loss: 0.2822, reg_loss: 0.1921, 
2022-07-24 17:08:12 - train: epoch 0005, iter [02600, 03664], lr: 0.000100, total_loss: 0.5048, cls_loss: 0.2852, reg_loss: 0.2196, 
2022-07-24 17:08:52 - train: epoch 0005, iter [02700, 03664], lr: 0.000100, total_loss: 0.4491, cls_loss: 0.2784, reg_loss: 0.1707, 
2022-07-24 17:09:35 - train: epoch 0005, iter [02800, 03664], lr: 0.000100, total_loss: 0.4277, cls_loss: 0.2437, reg_loss: 0.1841, 
2022-07-24 17:10:18 - train: epoch 0005, iter [02900, 03664], lr: 0.000100, total_loss: 0.4857, cls_loss: 0.2873, reg_loss: 0.1984, 
2022-07-24 17:10:58 - train: epoch 0005, iter [03000, 03664], lr: 0.000100, total_loss: 0.5046, cls_loss: 0.3036, reg_loss: 0.2011, 
2022-07-24 17:11:41 - train: epoch 0005, iter [03100, 03664], lr: 0.000100, total_loss: 0.4487, cls_loss: 0.2426, reg_loss: 0.2060, 
2022-07-24 17:12:21 - train: epoch 0005, iter [03200, 03664], lr: 0.000100, total_loss: 0.4309, cls_loss: 0.2486, reg_loss: 0.1823, 
2022-07-24 17:13:04 - train: epoch 0005, iter [03300, 03664], lr: 0.000100, total_loss: 0.4393, cls_loss: 0.2517, reg_loss: 0.1876, 
2022-07-24 17:13:46 - train: epoch 0005, iter [03400, 03664], lr: 0.000100, total_loss: 0.4035, cls_loss: 0.2268, reg_loss: 0.1766, 
2022-07-24 17:14:26 - train: epoch 0005, iter [03500, 03664], lr: 0.000100, total_loss: 0.4843, cls_loss: 0.2945, reg_loss: 0.1898, 
2022-07-24 17:15:09 - train: epoch 0005, iter [03600, 03664], lr: 0.000100, total_loss: 0.4556, cls_loss: 0.2670, reg_loss: 0.1886, 
2022-07-24 17:15:35 - train: epoch 005, train_loss: 0.4538
2022-07-24 17:19:45 - eval: epoch: 005
test_loss: 0.0000
per_image_load_time: 2.730ms
per_image_inference_time: 40.522ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 28.076753428269964
IoU=0.50,area=all,maxDets=100,mAP: 43.341364772917665
IoU=0.75,area=all,maxDets=100,mAP: 30.01593255894564
IoU=0.50:0.95,area=small,maxDets=100,mAP: 11.23429118528637
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 32.94490614749072
IoU=0.50:0.95,area=large,maxDets=100,mAP: 41.235539343661046
IoU=0.50:0.95,area=all,maxDets=1,mAR: 24.475738951691984
IoU=0.50:0.95,area=all,maxDets=10,mAR: 37.03948636659322
IoU=0.50:0.95,area=all,maxDets=100,mAR: 38.52291254416947
IoU=0.50:0.95,area=small,maxDets=100,mAR: 15.35009304142346
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 45.101914344414894
IoU=0.50:0.95,area=large,maxDets=100,mAR: 54.51818795719401

2022-07-24 17:19:46 - until epoch: 005, best_metric: 28.077%
2022-07-24 17:19:46 - epoch 006 lr: 0.000100
2022-07-24 17:20:44 - train: epoch 0006, iter [00100, 03664], lr: 0.000100, total_loss: 0.4315, cls_loss: 0.2334, reg_loss: 0.1981, 
2022-07-24 17:21:26 - train: epoch 0006, iter [00200, 03664], lr: 0.000100, total_loss: 0.4196, cls_loss: 0.2456, reg_loss: 0.1740, 
2022-07-24 17:22:06 - train: epoch 0006, iter [00300, 03664], lr: 0.000100, total_loss: 0.4756, cls_loss: 0.2833, reg_loss: 0.1923, 
2022-07-24 17:22:49 - train: epoch 0006, iter [00400, 03664], lr: 0.000100, total_loss: 0.3979, cls_loss: 0.2339, reg_loss: 0.1640, 
2022-07-24 17:23:32 - train: epoch 0006, iter [00500, 03664], lr: 0.000100, total_loss: 0.4660, cls_loss: 0.2602, reg_loss: 0.2058, 
2022-07-24 17:24:11 - train: epoch 0006, iter [00600, 03664], lr: 0.000100, total_loss: 0.4481, cls_loss: 0.2431, reg_loss: 0.2049, 
2022-07-24 17:24:51 - train: epoch 0006, iter [00700, 03664], lr: 0.000100, total_loss: 0.4507, cls_loss: 0.2628, reg_loss: 0.1879, 
2022-07-24 17:25:33 - train: epoch 0006, iter [00800, 03664], lr: 0.000100, total_loss: 0.4480, cls_loss: 0.2602, reg_loss: 0.1878, 
2022-07-24 17:26:15 - train: epoch 0006, iter [00900, 03664], lr: 0.000100, total_loss: 0.4351, cls_loss: 0.2404, reg_loss: 0.1947, 
2022-07-24 17:26:54 - train: epoch 0006, iter [01000, 03664], lr: 0.000100, total_loss: 0.4811, cls_loss: 0.2840, reg_loss: 0.1970, 
2022-07-24 17:27:36 - train: epoch 0006, iter [01100, 03664], lr: 0.000100, total_loss: 0.4262, cls_loss: 0.2385, reg_loss: 0.1876, 
2022-07-24 17:28:18 - train: epoch 0006, iter [01200, 03664], lr: 0.000100, total_loss: 0.4045, cls_loss: 0.2255, reg_loss: 0.1790, 
2022-07-24 17:28:58 - train: epoch 0006, iter [01300, 03664], lr: 0.000100, total_loss: 0.3728, cls_loss: 0.2044, reg_loss: 0.1684, 
2022-07-24 17:29:39 - train: epoch 0006, iter [01400, 03664], lr: 0.000100, total_loss: 0.4217, cls_loss: 0.2360, reg_loss: 0.1857, 
2022-07-24 17:30:22 - train: epoch 0006, iter [01500, 03664], lr: 0.000100, total_loss: 0.4228, cls_loss: 0.2504, reg_loss: 0.1724, 
2022-07-24 17:31:02 - train: epoch 0006, iter [01600, 03664], lr: 0.000100, total_loss: 0.4253, cls_loss: 0.2524, reg_loss: 0.1729, 
2022-07-24 17:31:41 - train: epoch 0006, iter [01700, 03664], lr: 0.000100, total_loss: 0.4554, cls_loss: 0.2618, reg_loss: 0.1936, 
2022-07-24 17:32:23 - train: epoch 0006, iter [01800, 03664], lr: 0.000100, total_loss: 0.4425, cls_loss: 0.2733, reg_loss: 0.1692, 
2022-07-24 17:33:05 - train: epoch 0006, iter [01900, 03664], lr: 0.000100, total_loss: 0.4630, cls_loss: 0.2707, reg_loss: 0.1923, 
2022-07-24 17:33:45 - train: epoch 0006, iter [02000, 03664], lr: 0.000100, total_loss: 0.5093, cls_loss: 0.3030, reg_loss: 0.2063, 
2022-07-24 17:34:27 - train: epoch 0006, iter [02100, 03664], lr: 0.000100, total_loss: 0.3921, cls_loss: 0.2361, reg_loss: 0.1560, 
2022-07-24 17:35:09 - train: epoch 0006, iter [02200, 03664], lr: 0.000100, total_loss: 0.4504, cls_loss: 0.2799, reg_loss: 0.1705, 
2022-07-24 17:35:49 - train: epoch 0006, iter [02300, 03664], lr: 0.000100, total_loss: 0.3982, cls_loss: 0.2207, reg_loss: 0.1776, 
2022-07-24 17:36:31 - train: epoch 0006, iter [02400, 03664], lr: 0.000100, total_loss: 0.4326, cls_loss: 0.2562, reg_loss: 0.1764, 
2022-07-24 17:37:12 - train: epoch 0006, iter [02500, 03664], lr: 0.000100, total_loss: 0.4618, cls_loss: 0.2637, reg_loss: 0.1981, 
2022-07-24 17:37:52 - train: epoch 0006, iter [02600, 03664], lr: 0.000100, total_loss: 0.4417, cls_loss: 0.2458, reg_loss: 0.1960, 
2022-07-24 17:38:32 - train: epoch 0006, iter [02700, 03664], lr: 0.000100, total_loss: 0.4871, cls_loss: 0.3037, reg_loss: 0.1835, 
2022-07-24 17:39:13 - train: epoch 0006, iter [02800, 03664], lr: 0.000100, total_loss: 0.4502, cls_loss: 0.2528, reg_loss: 0.1974, 
2022-07-24 17:39:55 - train: epoch 0006, iter [02900, 03664], lr: 0.000100, total_loss: 0.4270, cls_loss: 0.2530, reg_loss: 0.1740, 
2022-07-24 17:40:35 - train: epoch 0006, iter [03000, 03664], lr: 0.000100, total_loss: 0.4162, cls_loss: 0.2361, reg_loss: 0.1802, 
2022-07-24 17:41:17 - train: epoch 0006, iter [03100, 03664], lr: 0.000100, total_loss: 0.5025, cls_loss: 0.3056, reg_loss: 0.1969, 
2022-07-24 17:41:59 - train: epoch 0006, iter [03200, 03664], lr: 0.000100, total_loss: 0.4693, cls_loss: 0.2915, reg_loss: 0.1779, 
2022-07-24 17:42:38 - train: epoch 0006, iter [03300, 03664], lr: 0.000100, total_loss: 0.4815, cls_loss: 0.2883, reg_loss: 0.1931, 
2022-07-24 17:43:18 - train: epoch 0006, iter [03400, 03664], lr: 0.000100, total_loss: 0.4756, cls_loss: 0.2800, reg_loss: 0.1956, 
2022-07-24 17:44:00 - train: epoch 0006, iter [03500, 03664], lr: 0.000100, total_loss: 0.4294, cls_loss: 0.2402, reg_loss: 0.1893, 
2022-07-24 17:44:42 - train: epoch 0006, iter [03600, 03664], lr: 0.000100, total_loss: 0.4727, cls_loss: 0.2804, reg_loss: 0.1924, 
2022-07-24 17:45:08 - train: epoch 006, train_loss: 0.4376
2022-07-24 17:45:09 - until epoch: 006, best_metric: 28.077%
2022-07-24 17:45:09 - epoch 007 lr: 0.000100
2022-07-24 17:45:56 - train: epoch 0007, iter [00100, 03664], lr: 0.000100, total_loss: 0.3805, cls_loss: 0.2221, reg_loss: 0.1584, 
2022-07-24 17:46:39 - train: epoch 0007, iter [00200, 03664], lr: 0.000100, total_loss: 0.4431, cls_loss: 0.2504, reg_loss: 0.1927, 
2022-07-24 17:47:19 - train: epoch 0007, iter [00300, 03664], lr: 0.000100, total_loss: 0.4171, cls_loss: 0.2356, reg_loss: 0.1816, 
2022-07-24 17:47:59 - train: epoch 0007, iter [00400, 03664], lr: 0.000100, total_loss: 0.4464, cls_loss: 0.2679, reg_loss: 0.1785, 
2022-07-24 17:48:41 - train: epoch 0007, iter [00500, 03664], lr: 0.000100, total_loss: 0.4176, cls_loss: 0.2315, reg_loss: 0.1860, 
2022-07-24 17:49:23 - train: epoch 0007, iter [00600, 03664], lr: 0.000100, total_loss: 0.3855, cls_loss: 0.2255, reg_loss: 0.1599, 
2022-07-24 17:50:03 - train: epoch 0007, iter [00700, 03664], lr: 0.000100, total_loss: 0.4267, cls_loss: 0.2486, reg_loss: 0.1780, 
2022-07-24 17:50:45 - train: epoch 0007, iter [00800, 03664], lr: 0.000100, total_loss: 0.3995, cls_loss: 0.2305, reg_loss: 0.1690, 
2022-07-24 17:51:27 - train: epoch 0007, iter [00900, 03664], lr: 0.000100, total_loss: 0.4352, cls_loss: 0.2602, reg_loss: 0.1750, 
2022-07-24 17:52:07 - train: epoch 0007, iter [01000, 03664], lr: 0.000100, total_loss: 0.4183, cls_loss: 0.2363, reg_loss: 0.1820, 
2022-07-24 17:52:49 - train: epoch 0007, iter [01100, 03664], lr: 0.000100, total_loss: 0.4464, cls_loss: 0.2720, reg_loss: 0.1744, 
2022-07-24 17:53:31 - train: epoch 0007, iter [01200, 03664], lr: 0.000100, total_loss: 0.4321, cls_loss: 0.2365, reg_loss: 0.1956, 
2022-07-24 17:54:11 - train: epoch 0007, iter [01300, 03664], lr: 0.000100, total_loss: 0.3755, cls_loss: 0.1998, reg_loss: 0.1758, 
2022-07-24 17:54:50 - train: epoch 0007, iter [01400, 03664], lr: 0.000100, total_loss: 0.3882, cls_loss: 0.2214, reg_loss: 0.1668, 
2022-07-24 17:55:32 - train: epoch 0007, iter [01500, 03664], lr: 0.000100, total_loss: 0.4769, cls_loss: 0.2787, reg_loss: 0.1982, 
2022-07-24 17:56:14 - train: epoch 0007, iter [01600, 03664], lr: 0.000100, total_loss: 0.4489, cls_loss: 0.2425, reg_loss: 0.2064, 
2022-07-24 17:56:54 - train: epoch 0007, iter [01700, 03664], lr: 0.000100, total_loss: 0.4153, cls_loss: 0.2432, reg_loss: 0.1721, 
2022-07-24 17:57:36 - train: epoch 0007, iter [01800, 03664], lr: 0.000100, total_loss: 0.4263, cls_loss: 0.2493, reg_loss: 0.1769, 
2022-07-24 17:58:18 - train: epoch 0007, iter [01900, 03664], lr: 0.000100, total_loss: 0.4610, cls_loss: 0.2759, reg_loss: 0.1851, 
2022-07-24 17:58:57 - train: epoch 0007, iter [02000, 03664], lr: 0.000100, total_loss: 0.4447, cls_loss: 0.2559, reg_loss: 0.1888, 
2022-07-24 17:59:40 - train: epoch 0007, iter [02100, 03664], lr: 0.000100, total_loss: 0.4576, cls_loss: 0.2642, reg_loss: 0.1934, 
2022-07-24 18:00:21 - train: epoch 0007, iter [02200, 03664], lr: 0.000100, total_loss: 0.4235, cls_loss: 0.2352, reg_loss: 0.1883, 
2022-07-24 18:01:01 - train: epoch 0007, iter [02300, 03664], lr: 0.000100, total_loss: 0.4522, cls_loss: 0.2615, reg_loss: 0.1907, 
2022-07-24 18:01:41 - train: epoch 0007, iter [02400, 03664], lr: 0.000100, total_loss: 0.4082, cls_loss: 0.2378, reg_loss: 0.1704, 
2022-07-24 18:02:23 - train: epoch 0007, iter [02500, 03664], lr: 0.000100, total_loss: 0.4251, cls_loss: 0.2347, reg_loss: 0.1904, 
2022-07-24 18:03:05 - train: epoch 0007, iter [02600, 03664], lr: 0.000100, total_loss: 0.4165, cls_loss: 0.2352, reg_loss: 0.1813, 
2022-07-24 18:03:45 - train: epoch 0007, iter [02700, 03664], lr: 0.000100, total_loss: 0.4631, cls_loss: 0.2746, reg_loss: 0.1885, 
2022-07-24 18:04:27 - train: epoch 0007, iter [02800, 03664], lr: 0.000100, total_loss: 0.4084, cls_loss: 0.2166, reg_loss: 0.1918, 
2022-07-24 18:05:09 - train: epoch 0007, iter [02900, 03664], lr: 0.000100, total_loss: 0.5048, cls_loss: 0.2907, reg_loss: 0.2141, 
2022-07-24 18:05:49 - train: epoch 0007, iter [03000, 03664], lr: 0.000100, total_loss: 0.4364, cls_loss: 0.2433, reg_loss: 0.1931, 
2022-07-24 18:06:28 - train: epoch 0007, iter [03100, 03664], lr: 0.000100, total_loss: 0.3846, cls_loss: 0.2155, reg_loss: 0.1691, 
2022-07-24 18:07:13 - train: epoch 0007, iter [03200, 03664], lr: 0.000100, total_loss: 0.4204, cls_loss: 0.2340, reg_loss: 0.1864, 
2022-07-24 18:07:53 - train: epoch 0007, iter [03300, 03664], lr: 0.000100, total_loss: 0.4441, cls_loss: 0.2418, reg_loss: 0.2023, 
2022-07-24 18:08:32 - train: epoch 0007, iter [03400, 03664], lr: 0.000100, total_loss: 0.4081, cls_loss: 0.2245, reg_loss: 0.1836, 
2022-07-24 18:09:14 - train: epoch 0007, iter [03500, 03664], lr: 0.000100, total_loss: 0.4379, cls_loss: 0.2481, reg_loss: 0.1898, 
2022-07-24 18:09:56 - train: epoch 0007, iter [03600, 03664], lr: 0.000100, total_loss: 0.4522, cls_loss: 0.2571, reg_loss: 0.1951, 
2022-07-24 18:10:22 - train: epoch 007, train_loss: 0.4244
2022-07-24 18:10:23 - until epoch: 007, best_metric: 28.077%
2022-07-24 18:10:23 - epoch 008 lr: 0.000100
2022-07-24 18:11:08 - train: epoch 0008, iter [00100, 03664], lr: 0.000100, total_loss: 0.4651, cls_loss: 0.2635, reg_loss: 0.2015, 
2022-07-24 18:11:53 - train: epoch 0008, iter [00200, 03664], lr: 0.000100, total_loss: 0.3920, cls_loss: 0.2196, reg_loss: 0.1724, 
2022-07-24 18:12:32 - train: epoch 0008, iter [00300, 03664], lr: 0.000100, total_loss: 0.4585, cls_loss: 0.2727, reg_loss: 0.1858, 
2022-07-24 18:13:11 - train: epoch 0008, iter [00400, 03664], lr: 0.000100, total_loss: 0.3976, cls_loss: 0.2175, reg_loss: 0.1801, 
2022-07-24 18:13:53 - train: epoch 0008, iter [00500, 03664], lr: 0.000100, total_loss: 0.4126, cls_loss: 0.2443, reg_loss: 0.1683, 
2022-07-24 18:14:35 - train: epoch 0008, iter [00600, 03664], lr: 0.000100, total_loss: 0.3518, cls_loss: 0.1851, reg_loss: 0.1667, 
2022-07-24 18:15:15 - train: epoch 0008, iter [00700, 03664], lr: 0.000100, total_loss: 0.4029, cls_loss: 0.2253, reg_loss: 0.1776, 
2022-07-24 18:15:56 - train: epoch 0008, iter [00800, 03664], lr: 0.000100, total_loss: 0.3755, cls_loss: 0.2131, reg_loss: 0.1623, 
2022-07-24 18:16:37 - train: epoch 0008, iter [00900, 03664], lr: 0.000100, total_loss: 0.4105, cls_loss: 0.2219, reg_loss: 0.1886, 
2022-07-24 18:17:17 - train: epoch 0008, iter [01000, 03664], lr: 0.000100, total_loss: 0.4161, cls_loss: 0.2285, reg_loss: 0.1876, 
2022-07-24 18:17:56 - train: epoch 0008, iter [01100, 03664], lr: 0.000100, total_loss: 0.4274, cls_loss: 0.2503, reg_loss: 0.1771, 
2022-07-24 18:18:39 - train: epoch 0008, iter [01200, 03664], lr: 0.000100, total_loss: 0.3965, cls_loss: 0.2261, reg_loss: 0.1704, 
2022-07-24 18:19:19 - train: epoch 0008, iter [01300, 03664], lr: 0.000100, total_loss: 0.3868, cls_loss: 0.2216, reg_loss: 0.1652, 
2022-07-24 18:19:59 - train: epoch 0008, iter [01400, 03664], lr: 0.000100, total_loss: 0.4475, cls_loss: 0.2619, reg_loss: 0.1856, 
2022-07-24 18:20:41 - train: epoch 0008, iter [01500, 03664], lr: 0.000100, total_loss: 0.3688, cls_loss: 0.1982, reg_loss: 0.1706, 
2022-07-24 18:21:23 - train: epoch 0008, iter [01600, 03664], lr: 0.000100, total_loss: 0.4072, cls_loss: 0.2257, reg_loss: 0.1814, 
2022-07-24 18:22:03 - train: epoch 0008, iter [01700, 03664], lr: 0.000100, total_loss: 0.4530, cls_loss: 0.2605, reg_loss: 0.1925, 
2022-07-24 18:22:45 - train: epoch 0008, iter [01800, 03664], lr: 0.000100, total_loss: 0.3872, cls_loss: 0.2096, reg_loss: 0.1776, 
2022-07-24 18:23:26 - train: epoch 0008, iter [01900, 03664], lr: 0.000100, total_loss: 0.3462, cls_loss: 0.1824, reg_loss: 0.1639, 
2022-07-24 18:24:06 - train: epoch 0008, iter [02000, 03664], lr: 0.000100, total_loss: 0.3968, cls_loss: 0.2274, reg_loss: 0.1694, 
2022-07-24 18:24:46 - train: epoch 0008, iter [02100, 03664], lr: 0.000100, total_loss: 0.4296, cls_loss: 0.2622, reg_loss: 0.1674, 
2022-07-24 18:25:30 - train: epoch 0008, iter [02200, 03664], lr: 0.000100, total_loss: 0.3935, cls_loss: 0.2166, reg_loss: 0.1770, 
2022-07-24 18:26:10 - train: epoch 0008, iter [02300, 03664], lr: 0.000100, total_loss: 0.4104, cls_loss: 0.2349, reg_loss: 0.1755, 
2022-07-24 18:26:50 - train: epoch 0008, iter [02400, 03664], lr: 0.000100, total_loss: 0.3986, cls_loss: 0.2161, reg_loss: 0.1824, 
2022-07-24 18:27:32 - train: epoch 0008, iter [02500, 03664], lr: 0.000100, total_loss: 0.4495, cls_loss: 0.2594, reg_loss: 0.1901, 
2022-07-24 18:28:14 - train: epoch 0008, iter [02600, 03664], lr: 0.000100, total_loss: 0.3755, cls_loss: 0.2025, reg_loss: 0.1730, 
2022-07-24 18:28:54 - train: epoch 0008, iter [02700, 03664], lr: 0.000100, total_loss: 0.3839, cls_loss: 0.2366, reg_loss: 0.1473, 
2022-07-24 18:29:34 - train: epoch 0008, iter [02800, 03664], lr: 0.000100, total_loss: 0.3913, cls_loss: 0.2246, reg_loss: 0.1667, 
2022-07-24 18:30:18 - train: epoch 0008, iter [02900, 03664], lr: 0.000100, total_loss: 0.5038, cls_loss: 0.2725, reg_loss: 0.2313, 
2022-07-24 18:30:58 - train: epoch 0008, iter [03000, 03664], lr: 0.000100, total_loss: 0.4317, cls_loss: 0.2373, reg_loss: 0.1945, 
2022-07-24 18:31:38 - train: epoch 0008, iter [03100, 03664], lr: 0.000100, total_loss: 0.4742, cls_loss: 0.2884, reg_loss: 0.1858, 
2022-07-24 18:32:23 - train: epoch 0008, iter [03200, 03664], lr: 0.000100, total_loss: 0.4109, cls_loss: 0.2351, reg_loss: 0.1758, 
2022-07-24 18:33:03 - train: epoch 0008, iter [03300, 03664], lr: 0.000100, total_loss: 0.4474, cls_loss: 0.2501, reg_loss: 0.1973, 
2022-07-24 18:33:43 - train: epoch 0008, iter [03400, 03664], lr: 0.000100, total_loss: 0.4640, cls_loss: 0.2875, reg_loss: 0.1765, 
2022-07-24 18:34:25 - train: epoch 0008, iter [03500, 03664], lr: 0.000100, total_loss: 0.3803, cls_loss: 0.2098, reg_loss: 0.1705, 
2022-07-24 18:35:07 - train: epoch 0008, iter [03600, 03664], lr: 0.000100, total_loss: 0.3944, cls_loss: 0.2301, reg_loss: 0.1644, 
2022-07-24 18:35:33 - train: epoch 008, train_loss: 0.4134
2022-07-24 18:39:53 - eval: epoch: 008
test_loss: 0.0000
per_image_load_time: 2.081ms
per_image_inference_time: 43.253ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 29.92117094911027
IoU=0.50,area=all,maxDets=100,mAP: 45.83690616285431
IoU=0.75,area=all,maxDets=100,mAP: 31.908496459697172
IoU=0.50:0.95,area=small,maxDets=100,mAP: 11.598196325573669
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 35.26753174600184
IoU=0.50:0.95,area=large,maxDets=100,mAP: 44.41046104947209
IoU=0.50:0.95,area=all,maxDets=1,mAR: 25.877571534693487
IoU=0.50:0.95,area=all,maxDets=10,mAR: 38.65948405779017
IoU=0.50:0.95,area=all,maxDets=100,mAR: 40.19031305157045
IoU=0.50:0.95,area=small,maxDets=100,mAR: 15.769736311566893
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 47.46209597534662
IoU=0.50:0.95,area=large,maxDets=100,mAR: 57.717210266201334

2022-07-24 18:39:54 - until epoch: 008, best_metric: 29.921%
2022-07-24 18:39:54 - epoch 009 lr: 0.000010
2022-07-24 18:40:43 - train: epoch 0009, iter [00100, 03664], lr: 0.000010, total_loss: 0.3403, cls_loss: 0.1831, reg_loss: 0.1572, 
2022-07-24 18:41:23 - train: epoch 0009, iter [00200, 03664], lr: 0.000010, total_loss: 0.3466, cls_loss: 0.1891, reg_loss: 0.1575, 
2022-07-24 18:42:04 - train: epoch 0009, iter [00300, 03664], lr: 0.000010, total_loss: 0.3997, cls_loss: 0.2197, reg_loss: 0.1800, 
2022-07-24 18:42:46 - train: epoch 0009, iter [00400, 03664], lr: 0.000010, total_loss: 0.4043, cls_loss: 0.2366, reg_loss: 0.1677, 
2022-07-24 18:43:25 - train: epoch 0009, iter [00500, 03664], lr: 0.000010, total_loss: 0.3633, cls_loss: 0.2037, reg_loss: 0.1596, 
2022-07-24 18:44:07 - train: epoch 0009, iter [00600, 03664], lr: 0.000010, total_loss: 0.3968, cls_loss: 0.2127, reg_loss: 0.1841, 
2022-07-24 18:44:48 - train: epoch 0009, iter [00700, 03664], lr: 0.000010, total_loss: 0.3990, cls_loss: 0.2091, reg_loss: 0.1899, 
2022-07-24 18:45:27 - train: epoch 0009, iter [00800, 03664], lr: 0.000010, total_loss: 0.3757, cls_loss: 0.2070, reg_loss: 0.1688, 
2022-07-24 18:46:07 - train: epoch 0009, iter [00900, 03664], lr: 0.000010, total_loss: 0.3525, cls_loss: 0.1953, reg_loss: 0.1571, 
2022-07-24 18:46:48 - train: epoch 0009, iter [01000, 03664], lr: 0.000010, total_loss: 0.3874, cls_loss: 0.2067, reg_loss: 0.1807, 
2022-07-24 18:47:29 - train: epoch 0009, iter [01100, 03664], lr: 0.000010, total_loss: 0.4595, cls_loss: 0.2679, reg_loss: 0.1916, 
2022-07-24 18:48:09 - train: epoch 0009, iter [01200, 03664], lr: 0.000010, total_loss: 0.3777, cls_loss: 0.2020, reg_loss: 0.1757, 
2022-07-24 18:48:50 - train: epoch 0009, iter [01300, 03664], lr: 0.000010, total_loss: 0.3671, cls_loss: 0.1970, reg_loss: 0.1702, 
2022-07-24 18:49:31 - train: epoch 0009, iter [01400, 03664], lr: 0.000010, total_loss: 0.3839, cls_loss: 0.1941, reg_loss: 0.1898, 
2022-07-24 18:50:10 - train: epoch 0009, iter [01500, 03664], lr: 0.000010, total_loss: 0.3144, cls_loss: 0.1666, reg_loss: 0.1478, 
2022-07-24 18:50:52 - train: epoch 0009, iter [01600, 03664], lr: 0.000010, total_loss: 0.3217, cls_loss: 0.1553, reg_loss: 0.1664, 
2022-07-24 18:51:33 - train: epoch 0009, iter [01700, 03664], lr: 0.000010, total_loss: 0.3736, cls_loss: 0.2028, reg_loss: 0.1708, 
2022-07-24 18:52:13 - train: epoch 0009, iter [01800, 03664], lr: 0.000010, total_loss: 0.3157, cls_loss: 0.1681, reg_loss: 0.1476, 
2022-07-24 18:52:52 - train: epoch 0009, iter [01900, 03664], lr: 0.000010, total_loss: 0.3265, cls_loss: 0.1815, reg_loss: 0.1449, 
2022-07-24 18:53:34 - train: epoch 0009, iter [02000, 03664], lr: 0.000010, total_loss: 0.4036, cls_loss: 0.2240, reg_loss: 0.1796, 
2022-07-24 18:54:15 - train: epoch 0009, iter [02100, 03664], lr: 0.000010, total_loss: 0.3679, cls_loss: 0.1964, reg_loss: 0.1715, 
2022-07-24 18:54:54 - train: epoch 0009, iter [02200, 03664], lr: 0.000010, total_loss: 0.3556, cls_loss: 0.2025, reg_loss: 0.1531, 
2022-07-24 18:55:35 - train: epoch 0009, iter [02300, 03664], lr: 0.000010, total_loss: 0.3680, cls_loss: 0.2009, reg_loss: 0.1671, 
2022-07-24 18:56:17 - train: epoch 0009, iter [02400, 03664], lr: 0.000010, total_loss: 0.3218, cls_loss: 0.1695, reg_loss: 0.1523, 
2022-07-24 18:56:56 - train: epoch 0009, iter [02500, 03664], lr: 0.000010, total_loss: 0.3703, cls_loss: 0.1897, reg_loss: 0.1806, 
2022-07-24 18:57:37 - train: epoch 0009, iter [02600, 03664], lr: 0.000010, total_loss: 0.3571, cls_loss: 0.1925, reg_loss: 0.1646, 
2022-07-24 18:58:16 - train: epoch 0009, iter [02700, 03664], lr: 0.000010, total_loss: 0.4054, cls_loss: 0.2444, reg_loss: 0.1610, 
2022-07-24 18:58:57 - train: epoch 0009, iter [02800, 03664], lr: 0.000010, total_loss: 0.3227, cls_loss: 0.1698, reg_loss: 0.1529, 
2022-07-24 18:59:37 - train: epoch 0009, iter [02900, 03664], lr: 0.000010, total_loss: 0.3648, cls_loss: 0.1895, reg_loss: 0.1753, 
2022-07-24 19:00:18 - train: epoch 0009, iter [03000, 03664], lr: 0.000010, total_loss: 0.3369, cls_loss: 0.1811, reg_loss: 0.1558, 
2022-07-24 19:01:00 - train: epoch 0009, iter [03100, 03664], lr: 0.000010, total_loss: 0.3919, cls_loss: 0.2044, reg_loss: 0.1875, 
2022-07-24 19:01:40 - train: epoch 0009, iter [03200, 03664], lr: 0.000010, total_loss: 0.3523, cls_loss: 0.1821, reg_loss: 0.1702, 
2022-07-24 19:02:21 - train: epoch 0009, iter [03300, 03664], lr: 0.000010, total_loss: 0.4351, cls_loss: 0.2462, reg_loss: 0.1889, 
2022-07-24 19:03:03 - train: epoch 0009, iter [03400, 03664], lr: 0.000010, total_loss: 0.3356, cls_loss: 0.1879, reg_loss: 0.1477, 
2022-07-24 19:03:42 - train: epoch 0009, iter [03500, 03664], lr: 0.000010, total_loss: 0.4356, cls_loss: 0.2452, reg_loss: 0.1904, 
2022-07-24 19:04:24 - train: epoch 0009, iter [03600, 03664], lr: 0.000010, total_loss: 0.3117, cls_loss: 0.1637, reg_loss: 0.1479, 
2022-07-24 19:04:50 - train: epoch 009, train_loss: 0.3668
2022-07-24 19:04:51 - until epoch: 009, best_metric: 29.921%
2022-07-24 19:04:51 - epoch 010 lr: 0.000010
2022-07-24 19:05:38 - train: epoch 0010, iter [00100, 03664], lr: 0.000010, total_loss: 0.3442, cls_loss: 0.1893, reg_loss: 0.1549, 
2022-07-24 19:06:17 - train: epoch 0010, iter [00200, 03664], lr: 0.000010, total_loss: 0.3708, cls_loss: 0.2017, reg_loss: 0.1690, 
2022-07-24 19:06:59 - train: epoch 0010, iter [00300, 03664], lr: 0.000010, total_loss: 0.3776, cls_loss: 0.2055, reg_loss: 0.1721, 
2022-07-24 19:07:40 - train: epoch 0010, iter [00400, 03664], lr: 0.000010, total_loss: 0.3756, cls_loss: 0.2075, reg_loss: 0.1680, 
2022-07-24 19:08:19 - train: epoch 0010, iter [00500, 03664], lr: 0.000010, total_loss: 0.3202, cls_loss: 0.1729, reg_loss: 0.1473, 
2022-07-24 19:09:01 - train: epoch 0010, iter [00600, 03664], lr: 0.000010, total_loss: 0.3328, cls_loss: 0.1825, reg_loss: 0.1503, 
2022-07-24 19:09:42 - train: epoch 0010, iter [00700, 03664], lr: 0.000010, total_loss: 0.4023, cls_loss: 0.2161, reg_loss: 0.1862, 
2022-07-24 19:10:22 - train: epoch 0010, iter [00800, 03664], lr: 0.000010, total_loss: 0.3375, cls_loss: 0.1752, reg_loss: 0.1622, 
2022-07-24 19:11:01 - train: epoch 0010, iter [00900, 03664], lr: 0.000010, total_loss: 0.3441, cls_loss: 0.1850, reg_loss: 0.1591, 
2022-07-24 19:11:43 - train: epoch 0010, iter [01000, 03664], lr: 0.000010, total_loss: 0.3737, cls_loss: 0.2064, reg_loss: 0.1673, 
2022-07-24 19:12:24 - train: epoch 0010, iter [01100, 03664], lr: 0.000010, total_loss: 0.3348, cls_loss: 0.1648, reg_loss: 0.1700, 
2022-07-24 19:13:03 - train: epoch 0010, iter [01200, 03664], lr: 0.000010, total_loss: 0.3763, cls_loss: 0.1915, reg_loss: 0.1848, 
2022-07-24 19:13:45 - train: epoch 0010, iter [01300, 03664], lr: 0.000010, total_loss: 0.3946, cls_loss: 0.2165, reg_loss: 0.1782, 
2022-07-24 19:14:26 - train: epoch 0010, iter [01400, 03664], lr: 0.000010, total_loss: 0.3370, cls_loss: 0.1793, reg_loss: 0.1577, 
2022-07-24 19:15:05 - train: epoch 0010, iter [01500, 03664], lr: 0.000010, total_loss: 0.4093, cls_loss: 0.2205, reg_loss: 0.1888, 
2022-07-24 19:15:47 - train: epoch 0010, iter [01600, 03664], lr: 0.000010, total_loss: 0.3874, cls_loss: 0.2170, reg_loss: 0.1703, 
2022-07-24 19:16:26 - train: epoch 0010, iter [01700, 03664], lr: 0.000010, total_loss: 0.3379, cls_loss: 0.1974, reg_loss: 0.1405, 
2022-07-24 19:17:08 - train: epoch 0010, iter [01800, 03664], lr: 0.000010, total_loss: 0.3310, cls_loss: 0.1734, reg_loss: 0.1576, 
2022-07-24 19:17:47 - train: epoch 0010, iter [01900, 03664], lr: 0.000010, total_loss: 0.3012, cls_loss: 0.1558, reg_loss: 0.1454, 
2022-07-24 19:18:28 - train: epoch 0010, iter [02000, 03664], lr: 0.000010, total_loss: 0.3724, cls_loss: 0.1936, reg_loss: 0.1788, 
2022-07-24 19:19:10 - train: epoch 0010, iter [02100, 03664], lr: 0.000010, total_loss: 0.3437, cls_loss: 0.1914, reg_loss: 0.1523, 
2022-07-24 19:19:49 - train: epoch 0010, iter [02200, 03664], lr: 0.000010, total_loss: 0.3563, cls_loss: 0.1874, reg_loss: 0.1689, 
2022-07-24 19:20:30 - train: epoch 0010, iter [02300, 03664], lr: 0.000010, total_loss: 0.3589, cls_loss: 0.1791, reg_loss: 0.1798, 
2022-07-24 19:21:12 - train: epoch 0010, iter [02400, 03664], lr: 0.000010, total_loss: 0.4241, cls_loss: 0.2405, reg_loss: 0.1836, 
2022-07-24 19:21:52 - train: epoch 0010, iter [02500, 03664], lr: 0.000010, total_loss: 0.4165, cls_loss: 0.2154, reg_loss: 0.2010, 
2022-07-24 19:22:33 - train: epoch 0010, iter [02600, 03664], lr: 0.000010, total_loss: 0.3046, cls_loss: 0.1611, reg_loss: 0.1435, 
2022-07-24 19:23:12 - train: epoch 0010, iter [02700, 03664], lr: 0.000010, total_loss: 0.3433, cls_loss: 0.1891, reg_loss: 0.1541, 
2022-07-24 19:23:54 - train: epoch 0010, iter [02800, 03664], lr: 0.000010, total_loss: 0.3500, cls_loss: 0.1872, reg_loss: 0.1628, 
2022-07-24 19:24:33 - train: epoch 0010, iter [02900, 03664], lr: 0.000010, total_loss: 0.3250, cls_loss: 0.1637, reg_loss: 0.1614, 
2022-07-24 19:25:15 - train: epoch 0010, iter [03000, 03664], lr: 0.000010, total_loss: 0.3837, cls_loss: 0.2225, reg_loss: 0.1612, 
2022-07-24 19:25:56 - train: epoch 0010, iter [03100, 03664], lr: 0.000010, total_loss: 0.3216, cls_loss: 0.1633, reg_loss: 0.1583, 
2022-07-24 19:26:36 - train: epoch 0010, iter [03200, 03664], lr: 0.000010, total_loss: 0.3929, cls_loss: 0.2223, reg_loss: 0.1706, 
2022-07-24 19:27:17 - train: epoch 0010, iter [03300, 03664], lr: 0.000010, total_loss: 0.3274, cls_loss: 0.1728, reg_loss: 0.1546, 
2022-07-24 19:27:58 - train: epoch 0010, iter [03400, 03664], lr: 0.000010, total_loss: 0.3221, cls_loss: 0.1587, reg_loss: 0.1634, 
2022-07-24 19:28:38 - train: epoch 0010, iter [03500, 03664], lr: 0.000010, total_loss: 0.3298, cls_loss: 0.1832, reg_loss: 0.1467, 
2022-07-24 19:29:20 - train: epoch 0010, iter [03600, 03664], lr: 0.000010, total_loss: 0.3814, cls_loss: 0.2278, reg_loss: 0.1536, 
2022-07-24 19:29:46 - train: epoch 010, train_loss: 0.3545
2022-07-24 19:33:54 - eval: epoch: 010
test_loss: 0.0000
per_image_load_time: 2.197ms
per_image_inference_time: 40.963ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 33.009939483957446
IoU=0.50,area=all,maxDets=100,mAP: 49.5135532922633
IoU=0.75,area=all,maxDets=100,mAP: 35.094182674845975
IoU=0.50:0.95,area=small,maxDets=100,mAP: 13.239372794268231
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 38.63355600363544
IoU=0.50:0.95,area=large,maxDets=100,mAP: 48.7331044908791
IoU=0.50:0.95,area=all,maxDets=1,mAR: 27.790519671568692
IoU=0.50:0.95,area=all,maxDets=10,mAR: 41.56304936491739
IoU=0.50:0.95,area=all,maxDets=100,mAR: 43.146253982904405
IoU=0.50:0.95,area=small,maxDets=100,mAR: 17.39194479719674
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 50.46641105695437
IoU=0.50:0.95,area=large,maxDets=100,mAR: 61.24640101061923

2022-07-24 19:33:54 - until epoch: 010, best_metric: 33.010%
2022-07-24 19:33:54 - epoch 011 lr: 0.000010
2022-07-24 19:35:03 - train: epoch 0011, iter [00100, 03664], lr: 0.000010, total_loss: 0.3045, cls_loss: 0.1542, reg_loss: 0.1503, 
2022-07-24 19:35:45 - train: epoch 0011, iter [00200, 03664], lr: 0.000010, total_loss: 0.3556, cls_loss: 0.1882, reg_loss: 0.1674, 
2022-07-24 19:36:25 - train: epoch 0011, iter [00300, 03664], lr: 0.000010, total_loss: 0.3568, cls_loss: 0.1910, reg_loss: 0.1658, 
2022-07-24 19:37:04 - train: epoch 0011, iter [00400, 03664], lr: 0.000010, total_loss: 0.3392, cls_loss: 0.1678, reg_loss: 0.1714, 
2022-07-24 19:37:46 - train: epoch 0011, iter [00500, 03664], lr: 0.000010, total_loss: 0.3553, cls_loss: 0.1976, reg_loss: 0.1578, 
2022-07-24 19:38:28 - train: epoch 0011, iter [00600, 03664], lr: 0.000010, total_loss: 0.3073, cls_loss: 0.1635, reg_loss: 0.1437, 
2022-07-24 19:39:07 - train: epoch 0011, iter [00700, 03664], lr: 0.000010, total_loss: 0.4043, cls_loss: 0.2241, reg_loss: 0.1802, 
2022-07-24 19:39:47 - train: epoch 0011, iter [00800, 03664], lr: 0.000010, total_loss: 0.3778, cls_loss: 0.2030, reg_loss: 0.1749, 
2022-07-24 19:40:31 - train: epoch 0011, iter [00900, 03664], lr: 0.000010, total_loss: 0.3414, cls_loss: 0.1816, reg_loss: 0.1598, 
2022-07-24 19:41:10 - train: epoch 0011, iter [01000, 03664], lr: 0.000010, total_loss: 0.3627, cls_loss: 0.1905, reg_loss: 0.1722, 
2022-07-24 19:41:49 - train: epoch 0011, iter [01100, 03664], lr: 0.000010, total_loss: 0.3421, cls_loss: 0.1750, reg_loss: 0.1672, 
2022-07-24 19:42:32 - train: epoch 0011, iter [01200, 03664], lr: 0.000010, total_loss: 0.3327, cls_loss: 0.1784, reg_loss: 0.1544, 
2022-07-24 19:43:12 - train: epoch 0011, iter [01300, 03664], lr: 0.000010, total_loss: 0.3334, cls_loss: 0.1810, reg_loss: 0.1524, 
2022-07-24 19:43:51 - train: epoch 0011, iter [01400, 03664], lr: 0.000010, total_loss: 0.3141, cls_loss: 0.1632, reg_loss: 0.1509, 
2022-07-24 19:44:32 - train: epoch 0011, iter [01500, 03664], lr: 0.000010, total_loss: 0.3570, cls_loss: 0.1900, reg_loss: 0.1670, 
2022-07-24 19:45:13 - train: epoch 0011, iter [01600, 03664], lr: 0.000010, total_loss: 0.3760, cls_loss: 0.2018, reg_loss: 0.1742, 
2022-07-24 19:45:53 - train: epoch 0011, iter [01700, 03664], lr: 0.000010, total_loss: 0.3567, cls_loss: 0.1891, reg_loss: 0.1676, 
2022-07-24 19:46:32 - train: epoch 0011, iter [01800, 03664], lr: 0.000010, total_loss: 0.2945, cls_loss: 0.1526, reg_loss: 0.1419, 
2022-07-24 19:47:15 - train: epoch 0011, iter [01900, 03664], lr: 0.000010, total_loss: 0.4081, cls_loss: 0.2325, reg_loss: 0.1756, 
2022-07-24 19:47:55 - train: epoch 0011, iter [02000, 03664], lr: 0.000010, total_loss: 0.3258, cls_loss: 0.1589, reg_loss: 0.1669, 
2022-07-24 19:48:34 - train: epoch 0011, iter [02100, 03664], lr: 0.000010, total_loss: 0.3154, cls_loss: 0.1538, reg_loss: 0.1616, 
2022-07-24 19:49:17 - train: epoch 0011, iter [02200, 03664], lr: 0.000010, total_loss: 0.3701, cls_loss: 0.1914, reg_loss: 0.1787, 
2022-07-24 19:49:57 - train: epoch 0011, iter [02300, 03664], lr: 0.000010, total_loss: 0.3211, cls_loss: 0.1654, reg_loss: 0.1558, 
2022-07-24 19:50:36 - train: epoch 0011, iter [02400, 03664], lr: 0.000010, total_loss: 0.3671, cls_loss: 0.2063, reg_loss: 0.1607, 
2022-07-24 19:51:17 - train: epoch 0011, iter [02500, 03664], lr: 0.000010, total_loss: 0.3921, cls_loss: 0.2172, reg_loss: 0.1749, 
2022-07-24 19:51:58 - train: epoch 0011, iter [02600, 03664], lr: 0.000010, total_loss: 0.3569, cls_loss: 0.1920, reg_loss: 0.1650, 
2022-07-24 19:52:37 - train: epoch 0011, iter [02700, 03664], lr: 0.000010, total_loss: 0.3251, cls_loss: 0.1772, reg_loss: 0.1478, 
2022-07-24 19:53:17 - train: epoch 0011, iter [02800, 03664], lr: 0.000010, total_loss: 0.4179, cls_loss: 0.2263, reg_loss: 0.1917, 
2022-07-24 19:54:00 - train: epoch 0011, iter [02900, 03664], lr: 0.000010, total_loss: 0.3470, cls_loss: 0.1858, reg_loss: 0.1612, 
2022-07-24 19:54:39 - train: epoch 0011, iter [03000, 03664], lr: 0.000010, total_loss: 0.3428, cls_loss: 0.1724, reg_loss: 0.1705, 
2022-07-24 19:55:18 - train: epoch 0011, iter [03100, 03664], lr: 0.000010, total_loss: 0.3517, cls_loss: 0.1932, reg_loss: 0.1585, 
2022-07-24 19:55:59 - train: epoch 0011, iter [03200, 03664], lr: 0.000010, total_loss: 0.3495, cls_loss: 0.1903, reg_loss: 0.1591, 
2022-07-24 19:56:40 - train: epoch 0011, iter [03300, 03664], lr: 0.000010, total_loss: 0.3847, cls_loss: 0.1905, reg_loss: 0.1941, 
2022-07-24 19:57:20 - train: epoch 0011, iter [03400, 03664], lr: 0.000010, total_loss: 0.3878, cls_loss: 0.2047, reg_loss: 0.1831, 
2022-07-24 19:58:01 - train: epoch 0011, iter [03500, 03664], lr: 0.000010, total_loss: 0.4178, cls_loss: 0.2249, reg_loss: 0.1929, 
2022-07-24 19:58:42 - train: epoch 0011, iter [03600, 03664], lr: 0.000010, total_loss: 0.3580, cls_loss: 0.1818, reg_loss: 0.1761, 
2022-07-24 19:59:08 - train: epoch 011, train_loss: 0.3485
2022-07-24 19:59:08 - until epoch: 011, best_metric: 33.010%
2022-07-24 19:59:08 - epoch 012 lr: 0.000010
2022-07-24 19:59:53 - train: epoch 0012, iter [00100, 03664], lr: 0.000010, total_loss: 0.3679, cls_loss: 0.2004, reg_loss: 0.1675, 
2022-07-24 20:00:34 - train: epoch 0012, iter [00200, 03664], lr: 0.000010, total_loss: 0.3402, cls_loss: 0.1729, reg_loss: 0.1673, 
2022-07-24 20:01:16 - train: epoch 0012, iter [00300, 03664], lr: 0.000010, total_loss: 0.3675, cls_loss: 0.1971, reg_loss: 0.1704, 
2022-07-24 20:01:55 - train: epoch 0012, iter [00400, 03664], lr: 0.000010, total_loss: 0.3763, cls_loss: 0.2101, reg_loss: 0.1662, 
2022-07-24 20:02:36 - train: epoch 0012, iter [00500, 03664], lr: 0.000010, total_loss: 0.3621, cls_loss: 0.1948, reg_loss: 0.1673, 
2022-07-24 20:03:18 - train: epoch 0012, iter [00600, 03664], lr: 0.000010, total_loss: 0.3278, cls_loss: 0.1810, reg_loss: 0.1468, 
2022-07-24 20:03:57 - train: epoch 0012, iter [00700, 03664], lr: 0.000010, total_loss: 0.3337, cls_loss: 0.1750, reg_loss: 0.1587, 
2022-07-24 20:04:38 - train: epoch 0012, iter [00800, 03664], lr: 0.000010, total_loss: 0.2780, cls_loss: 0.1431, reg_loss: 0.1349, 
2022-07-24 20:05:19 - train: epoch 0012, iter [00900, 03664], lr: 0.000010, total_loss: 0.3626, cls_loss: 0.1996, reg_loss: 0.1630, 
2022-07-24 20:05:59 - train: epoch 0012, iter [01000, 03664], lr: 0.000010, total_loss: 0.3463, cls_loss: 0.1840, reg_loss: 0.1623, 
2022-07-24 20:06:38 - train: epoch 0012, iter [01100, 03664], lr: 0.000010, total_loss: 0.3628, cls_loss: 0.1961, reg_loss: 0.1667, 
2022-07-24 20:07:21 - train: epoch 0012, iter [01200, 03664], lr: 0.000010, total_loss: 0.2723, cls_loss: 0.1380, reg_loss: 0.1343, 
2022-07-24 20:08:00 - train: epoch 0012, iter [01300, 03664], lr: 0.000010, total_loss: 0.3696, cls_loss: 0.2001, reg_loss: 0.1695, 
2022-07-24 20:08:40 - train: epoch 0012, iter [01400, 03664], lr: 0.000010, total_loss: 0.4125, cls_loss: 0.2289, reg_loss: 0.1836, 
2022-07-24 20:09:21 - train: epoch 0012, iter [01500, 03664], lr: 0.000010, total_loss: 0.2960, cls_loss: 0.1482, reg_loss: 0.1478, 
2022-07-24 20:10:03 - train: epoch 0012, iter [01600, 03664], lr: 0.000010, total_loss: 0.3890, cls_loss: 0.2242, reg_loss: 0.1648, 
2022-07-24 20:10:42 - train: epoch 0012, iter [01700, 03664], lr: 0.000010, total_loss: 0.3235, cls_loss: 0.1579, reg_loss: 0.1656, 
2022-07-24 20:11:22 - train: epoch 0012, iter [01800, 03664], lr: 0.000010, total_loss: 0.3781, cls_loss: 0.1933, reg_loss: 0.1848, 
2022-07-24 20:12:05 - train: epoch 0012, iter [01900, 03664], lr: 0.000010, total_loss: 0.2661, cls_loss: 0.1352, reg_loss: 0.1310, 
2022-07-24 20:12:44 - train: epoch 0012, iter [02000, 03664], lr: 0.000010, total_loss: 0.3601, cls_loss: 0.1922, reg_loss: 0.1679, 
2022-07-24 20:13:24 - train: epoch 0012, iter [02100, 03664], lr: 0.000010, total_loss: 0.2983, cls_loss: 0.1505, reg_loss: 0.1478, 
2022-07-24 20:14:05 - train: epoch 0012, iter [02200, 03664], lr: 0.000010, total_loss: 0.3678, cls_loss: 0.1897, reg_loss: 0.1781, 
2022-07-24 20:14:46 - train: epoch 0012, iter [02300, 03664], lr: 0.000010, total_loss: 0.3429, cls_loss: 0.1818, reg_loss: 0.1611, 
2022-07-24 20:15:25 - train: epoch 0012, iter [02400, 03664], lr: 0.000010, total_loss: 0.2944, cls_loss: 0.1470, reg_loss: 0.1473, 
2022-07-24 20:16:06 - train: epoch 0012, iter [02500, 03664], lr: 0.000010, total_loss: 0.2877, cls_loss: 0.1412, reg_loss: 0.1464, 
2022-07-24 20:16:48 - train: epoch 0012, iter [02600, 03664], lr: 0.000010, total_loss: 0.4103, cls_loss: 0.2205, reg_loss: 0.1898, 
2022-07-24 20:17:27 - train: epoch 0012, iter [02700, 03664], lr: 0.000010, total_loss: 0.3415, cls_loss: 0.1836, reg_loss: 0.1578, 
2022-07-24 20:18:07 - train: epoch 0012, iter [02800, 03664], lr: 0.000010, total_loss: 0.3406, cls_loss: 0.1789, reg_loss: 0.1617, 
2022-07-24 20:18:50 - train: epoch 0012, iter [02900, 03664], lr: 0.000010, total_loss: 0.3245, cls_loss: 0.1665, reg_loss: 0.1581, 
2022-07-24 20:19:29 - train: epoch 0012, iter [03000, 03664], lr: 0.000010, total_loss: 0.3333, cls_loss: 0.1733, reg_loss: 0.1600, 
2022-07-24 20:20:09 - train: epoch 0012, iter [03100, 03664], lr: 0.000010, total_loss: 0.3343, cls_loss: 0.1682, reg_loss: 0.1662, 
2022-07-24 20:20:50 - train: epoch 0012, iter [03200, 03664], lr: 0.000010, total_loss: 0.3024, cls_loss: 0.1640, reg_loss: 0.1384, 
2022-07-24 20:21:31 - train: epoch 0012, iter [03300, 03664], lr: 0.000010, total_loss: 0.3389, cls_loss: 0.1831, reg_loss: 0.1558, 
2022-07-24 20:22:10 - train: epoch 0012, iter [03400, 03664], lr: 0.000010, total_loss: 0.3498, cls_loss: 0.1898, reg_loss: 0.1600, 
2022-07-24 20:22:51 - train: epoch 0012, iter [03500, 03664], lr: 0.000010, total_loss: 0.3121, cls_loss: 0.1680, reg_loss: 0.1441, 
2022-07-24 20:23:33 - train: epoch 0012, iter [03600, 03664], lr: 0.000010, total_loss: 0.3526, cls_loss: 0.1852, reg_loss: 0.1674, 
2022-07-24 20:23:59 - train: epoch 012, train_loss: 0.3437
2022-07-24 20:28:08 - eval: epoch: 012
test_loss: 0.0000
per_image_load_time: 2.086ms
per_image_inference_time: 41.322ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 33.22888218700799
IoU=0.50,area=all,maxDets=100,mAP: 49.71611267380184
IoU=0.75,area=all,maxDets=100,mAP: 35.260738255222975
IoU=0.50:0.95,area=small,maxDets=100,mAP: 14.0645010716996
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 38.92131668775057
IoU=0.50:0.95,area=large,maxDets=100,mAP: 48.62647411637507
IoU=0.50:0.95,area=all,maxDets=1,mAR: 27.9414895759656
IoU=0.50:0.95,area=all,maxDets=10,mAR: 41.5978699634374
IoU=0.50:0.95,area=all,maxDets=100,mAR: 43.186022229832645
IoU=0.50:0.95,area=small,maxDets=100,mAR: 18.02050884676829
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 50.3068339352653
IoU=0.50:0.95,area=large,maxDets=100,mAR: 61.20344835487348

2022-07-24 20:28:08 - until epoch: 012, best_metric: 33.229%
2022-07-24 20:28:08 - epoch 013 lr: 0.000001
2022-07-24 20:29:17 - train: epoch 0013, iter [00100, 03664], lr: 0.000001, total_loss: 0.3462, cls_loss: 0.1869, reg_loss: 0.1593, 
2022-07-24 20:29:57 - train: epoch 0013, iter [00200, 03664], lr: 0.000001, total_loss: 0.3251, cls_loss: 0.1666, reg_loss: 0.1585, 
2022-07-24 20:30:38 - train: epoch 0013, iter [00300, 03664], lr: 0.000001, total_loss: 0.3359, cls_loss: 0.1636, reg_loss: 0.1723, 
2022-07-24 20:31:17 - train: epoch 0013, iter [00400, 03664], lr: 0.000001, total_loss: 0.3221, cls_loss: 0.1708, reg_loss: 0.1513, 
2022-07-24 20:31:59 - train: epoch 0013, iter [00500, 03664], lr: 0.000001, total_loss: 0.2942, cls_loss: 0.1487, reg_loss: 0.1455, 
2022-07-24 20:32:38 - train: epoch 0013, iter [00600, 03664], lr: 0.000001, total_loss: 0.3430, cls_loss: 0.1812, reg_loss: 0.1618, 
2022-07-24 20:33:19 - train: epoch 0013, iter [00700, 03664], lr: 0.000001, total_loss: 0.2890, cls_loss: 0.1472, reg_loss: 0.1418, 
2022-07-24 20:34:01 - train: epoch 0013, iter [00800, 03664], lr: 0.000001, total_loss: 0.3136, cls_loss: 0.1483, reg_loss: 0.1653, 
2022-07-24 20:34:40 - train: epoch 0013, iter [00900, 03664], lr: 0.000001, total_loss: 0.3207, cls_loss: 0.1639, reg_loss: 0.1567, 
2022-07-24 20:35:21 - train: epoch 0013, iter [01000, 03664], lr: 0.000001, total_loss: 0.3410, cls_loss: 0.1781, reg_loss: 0.1629, 
2022-07-24 20:36:01 - train: epoch 0013, iter [01100, 03664], lr: 0.000001, total_loss: 0.3480, cls_loss: 0.1785, reg_loss: 0.1695, 
2022-07-24 20:36:42 - train: epoch 0013, iter [01200, 03664], lr: 0.000001, total_loss: 0.3179, cls_loss: 0.1633, reg_loss: 0.1546, 
2022-07-24 20:37:23 - train: epoch 0013, iter [01300, 03664], lr: 0.000001, total_loss: 0.3345, cls_loss: 0.1744, reg_loss: 0.1602, 
2022-07-24 20:38:02 - train: epoch 0013, iter [01400, 03664], lr: 0.000001, total_loss: 0.3503, cls_loss: 0.1886, reg_loss: 0.1618, 
2022-07-24 20:38:44 - train: epoch 0013, iter [01500, 03664], lr: 0.000001, total_loss: 0.3854, cls_loss: 0.2016, reg_loss: 0.1839, 
2022-07-24 20:39:23 - train: epoch 0013, iter [01600, 03664], lr: 0.000001, total_loss: 0.3526, cls_loss: 0.1961, reg_loss: 0.1565, 
2022-07-24 20:40:04 - train: epoch 0013, iter [01700, 03664], lr: 0.000001, total_loss: 0.3242, cls_loss: 0.1657, reg_loss: 0.1585, 
2022-07-24 20:40:45 - train: epoch 0013, iter [01800, 03664], lr: 0.000001, total_loss: 0.3199, cls_loss: 0.1635, reg_loss: 0.1563, 
2022-07-24 20:41:25 - train: epoch 0013, iter [01900, 03664], lr: 0.000001, total_loss: 0.3920, cls_loss: 0.2075, reg_loss: 0.1845, 
2022-07-24 20:42:06 - train: epoch 0013, iter [02000, 03664], lr: 0.000001, total_loss: 0.2851, cls_loss: 0.1321, reg_loss: 0.1530, 
2022-07-24 20:42:45 - train: epoch 0013, iter [02100, 03664], lr: 0.000001, total_loss: 0.3688, cls_loss: 0.1987, reg_loss: 0.1701, 
2022-07-24 20:43:27 - train: epoch 0013, iter [02200, 03664], lr: 0.000001, total_loss: 0.3488, cls_loss: 0.1903, reg_loss: 0.1585, 
2022-07-24 20:44:08 - train: epoch 0013, iter [02300, 03664], lr: 0.000001, total_loss: 0.3609, cls_loss: 0.1866, reg_loss: 0.1743, 
2022-07-24 20:44:47 - train: epoch 0013, iter [02400, 03664], lr: 0.000001, total_loss: 0.3440, cls_loss: 0.1894, reg_loss: 0.1545, 
2022-07-24 20:45:29 - train: epoch 0013, iter [02500, 03664], lr: 0.000001, total_loss: 0.3307, cls_loss: 0.1786, reg_loss: 0.1521, 
2022-07-24 20:46:08 - train: epoch 0013, iter [02600, 03664], lr: 0.000001, total_loss: 0.3454, cls_loss: 0.1791, reg_loss: 0.1663, 
2022-07-24 20:46:49 - train: epoch 0013, iter [02700, 03664], lr: 0.000001, total_loss: 0.3199, cls_loss: 0.1667, reg_loss: 0.1532, 
2022-07-24 20:47:31 - train: epoch 0013, iter [02800, 03664], lr: 0.000001, total_loss: 0.3548, cls_loss: 0.1878, reg_loss: 0.1670, 
2022-07-24 20:48:10 - train: epoch 0013, iter [02900, 03664], lr: 0.000001, total_loss: 0.3068, cls_loss: 0.1565, reg_loss: 0.1503, 
2022-07-24 20:48:51 - train: epoch 0013, iter [03000, 03664], lr: 0.000001, total_loss: 0.3466, cls_loss: 0.1851, reg_loss: 0.1614, 
2022-07-24 20:49:30 - train: epoch 0013, iter [03100, 03664], lr: 0.000001, total_loss: 0.2741, cls_loss: 0.1382, reg_loss: 0.1360, 
2022-07-24 20:50:12 - train: epoch 0013, iter [03200, 03664], lr: 0.000001, total_loss: 0.3506, cls_loss: 0.1876, reg_loss: 0.1631, 
2022-07-24 20:50:53 - train: epoch 0013, iter [03300, 03664], lr: 0.000001, total_loss: 0.3240, cls_loss: 0.1703, reg_loss: 0.1537, 
2022-07-24 20:51:32 - train: epoch 0013, iter [03400, 03664], lr: 0.000001, total_loss: 0.4226, cls_loss: 0.2254, reg_loss: 0.1972, 
2022-07-24 20:52:13 - train: epoch 0013, iter [03500, 03664], lr: 0.000001, total_loss: 0.2639, cls_loss: 0.1295, reg_loss: 0.1344, 
2022-07-24 20:52:53 - train: epoch 0013, iter [03600, 03664], lr: 0.000001, total_loss: 0.2707, cls_loss: 0.1237, reg_loss: 0.1470, 
2022-07-24 20:53:21 - train: epoch 013, train_loss: 0.3364
2022-07-24 20:57:34 - eval: epoch: 013
test_loss: 0.0000
per_image_load_time: 2.048ms
per_image_inference_time: 42.625ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 33.49334544999651
IoU=0.50,area=all,maxDets=100,mAP: 50.108061449552764
IoU=0.75,area=all,maxDets=100,mAP: 35.57078622425402
IoU=0.50:0.95,area=small,maxDets=100,mAP: 14.513009934293175
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 39.1888328925247
IoU=0.50:0.95,area=large,maxDets=100,mAP: 48.70717792534379
IoU=0.50:0.95,area=all,maxDets=1,mAR: 28.117197130268544
IoU=0.50:0.95,area=all,maxDets=10,mAR: 41.97749114713842
IoU=0.50:0.95,area=all,maxDets=100,mAR: 43.552673398771645
IoU=0.50:0.95,area=small,maxDets=100,mAR: 19.016258277032165
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 50.90622225981565
IoU=0.50:0.95,area=large,maxDets=100,mAR: 61.44126308637159

2022-07-24 20:57:35 - until epoch: 013, best_metric: 33.493%
2022-07-24 20:57:35 - train done. model: resnet50_retinanet, train time: 5.960 hours, best_metric: 33.493%
