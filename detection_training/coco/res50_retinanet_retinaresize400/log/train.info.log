2022-04-24 02:31:24 - network: resnet50_retinanet
2022-04-24 02:31:24 - num_classes: 80
2022-04-24 02:31:24 - input_image_size: [400, 667]
2022-04-24 02:31:24 - backbone_pretrained_path: /root/code/simpleAICV-pytorch-ImageNet-COCO-training/pretrained_models/resnet/resnet50-acc76.322.pth
2022-04-24 02:31:24 - trained_model_path: 
2022-04-24 02:31:24 - criterion: RetinaLoss()
2022-04-24 02:31:24 - decoder: <simpleAICV.detection.decode.RetinaDecoder object at 0x7f4ffc62b970>
2022-04-24 02:31:24 - train_dataset: <simpleAICV.detection.datasets.cocodataset.CocoDetection object at 0x7f4ffc62bca0>
2022-04-24 02:31:24 - val_dataset: <simpleAICV.detection.datasets.cocodataset.CocoDetection object at 0x7f50135a3fa0>
2022-04-24 02:31:24 - collater: <simpleAICV.detection.common.DetectionCollater object at 0x7f50135a3ee0>
2022-04-24 02:31:24 - seed: 0
2022-04-24 02:31:24 - batch_size: 32
2022-04-24 02:31:24 - num_workers: 4
2022-04-24 02:31:24 - optimizer: ('AdamW', {'lr': 0.0001, 'weight_decay': 0.001})
2022-04-24 02:31:24 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [8, 12]})
2022-04-24 02:31:24 - epochs: 13
2022-04-24 02:31:24 - eval_epoch: [1, 3, 5, 8, 10, 12, 13]
2022-04-24 02:31:24 - print_interval: 100
2022-04-24 02:31:24 - eval_type: COCO
2022-04-24 02:31:24 - eval_voc_iou_threshold_list: [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]
2022-04-24 02:31:24 - save_model_metric: IoU=0.50:0.95,area=all,maxDets=100,mAP
2022-04-24 02:31:24 - sync_bn: False
2022-04-24 02:31:24 - apex: True
2022-04-24 02:31:24 - gpus_type: NVIDIA RTX A5000
2022-04-24 02:31:24 - gpus_num: 2
2022-04-24 02:31:24 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f4fd21dd8b0>
2022-04-24 02:31:24 - --------------------parameters--------------------
2022-04-24 02:31:24 - name: backbone.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.0.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.0.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.0.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.0.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.0.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.0.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.0.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.0.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.0.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.0.downsample_conv.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.0.downsample_conv.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.0.downsample_conv.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.1.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.1.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.1.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.1.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.1.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.1.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.1.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.1.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.1.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.2.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.2.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.2.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.2.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.2.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.2.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.2.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.2.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer1.2.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.0.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.0.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.0.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.0.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.0.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.0.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.0.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.0.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.0.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.0.downsample_conv.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.0.downsample_conv.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.0.downsample_conv.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.1.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.1.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.1.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.1.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.1.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.1.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.1.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.1.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.1.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.2.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.2.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.2.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.2.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.2.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.2.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.2.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.2.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.2.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.3.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.3.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.3.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.3.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.3.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.3.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.3.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.3.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer2.3.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.0.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.0.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.0.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.0.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.0.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.0.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.0.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.0.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.0.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.0.downsample_conv.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.0.downsample_conv.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.0.downsample_conv.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.1.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.1.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.1.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.1.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.1.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.1.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.1.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.1.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.1.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.2.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.2.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.2.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.2.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.2.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.2.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.2.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.2.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.2.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.3.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.3.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.3.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.3.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.3.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.3.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.3.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.3.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.3.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.4.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.4.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.4.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.4.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.4.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.4.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.4.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.4.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.4.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.5.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.5.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.5.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.5.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.5.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.5.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.5.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.5.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer3.5.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.0.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.0.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.0.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.0.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.0.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.0.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.0.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.0.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.0.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.0.downsample_conv.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.0.downsample_conv.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.0.downsample_conv.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.1.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.1.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.1.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.1.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.1.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.1.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.1.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.1.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.1.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.2.conv1.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.2.conv1.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.2.conv1.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.2.conv2.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.2.conv2.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.2.conv2.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.2.conv3.layer.0.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.2.conv3.layer.1.weight, grad: True
2022-04-24 02:31:24 - name: backbone.layer4.2.conv3.layer.1.bias, grad: True
2022-04-24 02:31:24 - name: fpn.P3_1.weight, grad: True
2022-04-24 02:31:24 - name: fpn.P3_1.bias, grad: True
2022-04-24 02:31:24 - name: fpn.P3_2.weight, grad: True
2022-04-24 02:31:24 - name: fpn.P3_2.bias, grad: True
2022-04-24 02:31:24 - name: fpn.P4_1.weight, grad: True
2022-04-24 02:31:24 - name: fpn.P4_1.bias, grad: True
2022-04-24 02:31:24 - name: fpn.P4_2.weight, grad: True
2022-04-24 02:31:24 - name: fpn.P4_2.bias, grad: True
2022-04-24 02:31:24 - name: fpn.P5_1.weight, grad: True
2022-04-24 02:31:24 - name: fpn.P5_1.bias, grad: True
2022-04-24 02:31:24 - name: fpn.P5_2.weight, grad: True
2022-04-24 02:31:24 - name: fpn.P5_2.bias, grad: True
2022-04-24 02:31:24 - name: fpn.P6.weight, grad: True
2022-04-24 02:31:24 - name: fpn.P6.bias, grad: True
2022-04-24 02:31:24 - name: fpn.P7.1.weight, grad: True
2022-04-24 02:31:24 - name: fpn.P7.1.bias, grad: True
2022-04-24 02:31:24 - name: cls_head.cls_head.0.weight, grad: True
2022-04-24 02:31:24 - name: cls_head.cls_head.0.bias, grad: True
2022-04-24 02:31:24 - name: cls_head.cls_head.2.weight, grad: True
2022-04-24 02:31:24 - name: cls_head.cls_head.2.bias, grad: True
2022-04-24 02:31:24 - name: cls_head.cls_head.4.weight, grad: True
2022-04-24 02:31:24 - name: cls_head.cls_head.4.bias, grad: True
2022-04-24 02:31:24 - name: cls_head.cls_head.6.weight, grad: True
2022-04-24 02:31:24 - name: cls_head.cls_head.6.bias, grad: True
2022-04-24 02:31:24 - name: cls_head.cls_out.weight, grad: True
2022-04-24 02:31:24 - name: cls_head.cls_out.bias, grad: True
2022-04-24 02:31:24 - name: reg_head.reg_head.0.weight, grad: True
2022-04-24 02:31:24 - name: reg_head.reg_head.0.bias, grad: True
2022-04-24 02:31:24 - name: reg_head.reg_head.2.weight, grad: True
2022-04-24 02:31:24 - name: reg_head.reg_head.2.bias, grad: True
2022-04-24 02:31:24 - name: reg_head.reg_head.4.weight, grad: True
2022-04-24 02:31:24 - name: reg_head.reg_head.4.bias, grad: True
2022-04-24 02:31:24 - name: reg_head.reg_head.6.weight, grad: True
2022-04-24 02:31:24 - name: reg_head.reg_head.6.bias, grad: True
2022-04-24 02:31:24 - name: reg_head.reg_out.weight, grad: True
2022-04-24 02:31:24 - name: reg_head.reg_out.bias, grad: True
2022-04-24 02:31:24 - --------------------buffers--------------------
2022-04-24 02:31:24 - name: backbone.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.0.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.0.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.0.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.0.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.0.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.0.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.0.downsample_conv.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.1.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.1.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.1.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.1.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.1.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.1.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.2.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.2.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.2.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.2.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.2.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.2.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer1.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.0.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.0.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.0.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.0.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.0.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.0.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.1.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.1.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.1.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.1.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.1.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.1.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.2.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.2.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.2.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.2.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.2.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.2.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.3.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.3.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.3.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.3.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.3.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.3.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer2.3.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.0.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.0.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.0.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.0.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.0.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.0.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.1.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.1.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.1.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.1.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.1.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.1.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.2.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.2.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.2.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.2.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.2.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.2.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.3.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.3.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.3.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.3.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.3.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.3.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.3.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.4.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.4.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.4.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.4.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.4.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.4.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.4.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.5.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.5.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.5.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.5.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.5.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.5.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer3.5.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.0.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.0.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.0.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.0.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.0.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.0.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.1.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.1.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.1.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.1.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.1.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.1.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.2.conv1.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.2.conv1.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.2.conv2.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.2.conv2.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.2.conv3.layer.1.running_mean, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.2.conv3.layer.1.running_var, grad: False
2022-04-24 02:31:24 - name: backbone.layer4.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-24 02:31:24 - epoch 001 lr: 0.0001
2022-04-24 02:32:05 - train: epoch 0001, iter [00100, 03664], lr: 0.000100, total_loss: 1.1789, cls_loss: 0.7893, reg_loss: 0.3896
2022-04-24 02:32:46 - train: epoch 0001, iter [00200, 03664], lr: 0.000100, total_loss: 1.0715, cls_loss: 0.7282, reg_loss: 0.3433
2022-04-24 02:33:29 - train: epoch 0001, iter [00300, 03664], lr: 0.000100, total_loss: 0.9603, cls_loss: 0.6515, reg_loss: 0.3089
2022-04-24 02:34:11 - train: epoch 0001, iter [00400, 03664], lr: 0.000100, total_loss: 0.9234, cls_loss: 0.6090, reg_loss: 0.3144
2022-04-24 02:34:52 - train: epoch 0001, iter [00500, 03664], lr: 0.000100, total_loss: 0.8476, cls_loss: 0.5505, reg_loss: 0.2971
2022-04-24 02:35:34 - train: epoch 0001, iter [00600, 03664], lr: 0.000100, total_loss: 0.8725, cls_loss: 0.5929, reg_loss: 0.2796
2022-04-24 02:36:16 - train: epoch 0001, iter [00700, 03664], lr: 0.000100, total_loss: 0.7867, cls_loss: 0.5011, reg_loss: 0.2856
2022-04-24 02:36:58 - train: epoch 0001, iter [00800, 03664], lr: 0.000100, total_loss: 0.8200, cls_loss: 0.5220, reg_loss: 0.2980
2022-04-24 02:37:39 - train: epoch 0001, iter [00900, 03664], lr: 0.000100, total_loss: 0.8254, cls_loss: 0.5494, reg_loss: 0.2761
2022-04-24 02:38:26 - train: epoch 0001, iter [01000, 03664], lr: 0.000100, total_loss: 0.8107, cls_loss: 0.5211, reg_loss: 0.2896
2022-04-24 02:39:07 - train: epoch 0001, iter [01100, 03664], lr: 0.000100, total_loss: 0.6922, cls_loss: 0.4291, reg_loss: 0.2632
2022-04-24 02:39:49 - train: epoch 0001, iter [01200, 03664], lr: 0.000100, total_loss: 0.7470, cls_loss: 0.4991, reg_loss: 0.2479
2022-04-24 02:40:33 - train: epoch 0001, iter [01300, 03664], lr: 0.000100, total_loss: 0.7366, cls_loss: 0.4759, reg_loss: 0.2607
2022-04-24 02:41:13 - train: epoch 0001, iter [01400, 03664], lr: 0.000100, total_loss: 0.6755, cls_loss: 0.4329, reg_loss: 0.2425
2022-04-24 02:41:54 - train: epoch 0001, iter [01500, 03664], lr: 0.000100, total_loss: 0.6516, cls_loss: 0.4135, reg_loss: 0.2381
2022-04-24 02:42:37 - train: epoch 0001, iter [01600, 03664], lr: 0.000100, total_loss: 0.6888, cls_loss: 0.4338, reg_loss: 0.2549
2022-04-24 02:43:19 - train: epoch 0001, iter [01700, 03664], lr: 0.000100, total_loss: 0.6984, cls_loss: 0.4489, reg_loss: 0.2495
2022-04-24 02:44:00 - train: epoch 0001, iter [01800, 03664], lr: 0.000100, total_loss: 0.7338, cls_loss: 0.4938, reg_loss: 0.2400
2022-04-24 02:44:41 - train: epoch 0001, iter [01900, 03664], lr: 0.000100, total_loss: 0.6752, cls_loss: 0.4246, reg_loss: 0.2507
2022-04-24 02:45:25 - train: epoch 0001, iter [02000, 03664], lr: 0.000100, total_loss: 0.6450, cls_loss: 0.3975, reg_loss: 0.2475
2022-04-24 02:46:05 - train: epoch 0001, iter [02100, 03664], lr: 0.000100, total_loss: 0.6473, cls_loss: 0.3985, reg_loss: 0.2488
2022-04-24 02:46:47 - train: epoch 0001, iter [02200, 03664], lr: 0.000100, total_loss: 0.6599, cls_loss: 0.3993, reg_loss: 0.2606
2022-04-24 02:47:31 - train: epoch 0001, iter [02300, 03664], lr: 0.000100, total_loss: 0.6590, cls_loss: 0.4093, reg_loss: 0.2496
2022-04-24 02:48:12 - train: epoch 0001, iter [02400, 03664], lr: 0.000100, total_loss: 0.6650, cls_loss: 0.4144, reg_loss: 0.2506
2022-04-24 02:48:53 - train: epoch 0001, iter [02500, 03664], lr: 0.000100, total_loss: 0.5655, cls_loss: 0.3434, reg_loss: 0.2221
2022-04-24 02:49:37 - train: epoch 0001, iter [02600, 03664], lr: 0.000100, total_loss: 0.6521, cls_loss: 0.4085, reg_loss: 0.2436
2022-04-24 02:50:18 - train: epoch 0001, iter [02700, 03664], lr: 0.000100, total_loss: 0.6032, cls_loss: 0.3736, reg_loss: 0.2296
2022-04-24 02:50:59 - train: epoch 0001, iter [02800, 03664], lr: 0.000100, total_loss: 0.6545, cls_loss: 0.4361, reg_loss: 0.2184
2022-04-24 02:51:42 - train: epoch 0001, iter [02900, 03664], lr: 0.000100, total_loss: 0.6137, cls_loss: 0.3739, reg_loss: 0.2398
2022-04-24 02:52:25 - train: epoch 0001, iter [03000, 03664], lr: 0.000100, total_loss: 0.5998, cls_loss: 0.3643, reg_loss: 0.2355
2022-04-24 02:53:06 - train: epoch 0001, iter [03100, 03664], lr: 0.000100, total_loss: 0.5788, cls_loss: 0.3565, reg_loss: 0.2223
2022-04-24 02:53:47 - train: epoch 0001, iter [03200, 03664], lr: 0.000100, total_loss: 0.6256, cls_loss: 0.4000, reg_loss: 0.2256
2022-04-24 02:54:31 - train: epoch 0001, iter [03300, 03664], lr: 0.000100, total_loss: 0.6061, cls_loss: 0.3635, reg_loss: 0.2427
2022-04-24 02:55:13 - train: epoch 0001, iter [03400, 03664], lr: 0.000100, total_loss: 0.5866, cls_loss: 0.3521, reg_loss: 0.2345
2022-04-24 02:55:53 - train: epoch 0001, iter [03500, 03664], lr: 0.000100, total_loss: 0.5949, cls_loss: 0.3553, reg_loss: 0.2396
2022-04-24 02:56:38 - train: epoch 0001, iter [03600, 03664], lr: 0.000100, total_loss: 0.6263, cls_loss: 0.3881, reg_loss: 0.2381
2022-04-24 02:57:05 - train: epoch 001, train_loss: 0.7393
2022-04-24 03:01:16 - eval: epoch: 001
per_image_load_time: 1.706ms
per_image_inference_time: 41.517ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 16.983756777210644
IoU=0.50,area=all,maxDets=100,mAP: 29.006209668588124
IoU=0.75,area=all,maxDets=100,mAP: 17.14097249263081
IoU=0.50:0.95,area=small,maxDets=100,mAP: 5.110672807745955
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 18.945355778037285
IoU=0.50:0.95,area=large,maxDets=100,mAP: 25.714956782950104
IoU=0.50:0.95,area=all,maxDets=1,mAR: 17.292719967313296
IoU=0.50:0.95,area=all,maxDets=10,mAR: 25.878631683899407
IoU=0.50:0.95,area=all,maxDets=100,mAR: 27.01468908724835
IoU=0.50:0.95,area=small,maxDets=100,mAR: 6.667757747928911
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 30.870822612368514
IoU=0.50:0.95,area=large,maxDets=100,mAR: 39.89635346825792

2022-04-24 03:01:16 - until epoch: 001, best_metric: 16.984%
2022-04-24 03:01:16 - epoch 002 lr: 0.0001
2022-04-24 03:02:16 - train: epoch 0002, iter [00100, 03664], lr: 0.000100, total_loss: 0.6441, cls_loss: 0.4142, reg_loss: 0.2299
2022-04-24 03:02:59 - train: epoch 0002, iter [00200, 03664], lr: 0.000100, total_loss: 0.5360, cls_loss: 0.3355, reg_loss: 0.2005
2022-04-24 03:03:39 - train: epoch 0002, iter [00300, 03664], lr: 0.000100, total_loss: 0.5372, cls_loss: 0.3133, reg_loss: 0.2239
2022-04-24 03:04:23 - train: epoch 0002, iter [00400, 03664], lr: 0.000100, total_loss: 0.6241, cls_loss: 0.3948, reg_loss: 0.2292
2022-04-24 03:05:05 - train: epoch 0002, iter [00500, 03664], lr: 0.000100, total_loss: 0.5759, cls_loss: 0.3481, reg_loss: 0.2278
2022-04-24 03:05:46 - train: epoch 0002, iter [00600, 03664], lr: 0.000100, total_loss: 0.5601, cls_loss: 0.3467, reg_loss: 0.2134
2022-04-24 03:06:29 - train: epoch 0002, iter [00700, 03664], lr: 0.000100, total_loss: 0.6378, cls_loss: 0.3887, reg_loss: 0.2491
2022-04-24 03:07:10 - train: epoch 0002, iter [00800, 03664], lr: 0.000100, total_loss: 0.6198, cls_loss: 0.3816, reg_loss: 0.2382
2022-04-24 03:07:53 - train: epoch 0002, iter [00900, 03664], lr: 0.000100, total_loss: 0.5616, cls_loss: 0.3367, reg_loss: 0.2249
2022-04-24 03:08:36 - train: epoch 0002, iter [01000, 03664], lr: 0.000100, total_loss: 0.5604, cls_loss: 0.3393, reg_loss: 0.2211
2022-04-24 03:09:16 - train: epoch 0002, iter [01100, 03664], lr: 0.000100, total_loss: 0.6000, cls_loss: 0.3786, reg_loss: 0.2214
2022-04-24 03:10:00 - train: epoch 0002, iter [01200, 03664], lr: 0.000100, total_loss: 0.7370, cls_loss: 0.4969, reg_loss: 0.2401
2022-04-24 03:10:40 - train: epoch 0002, iter [01300, 03664], lr: 0.000100, total_loss: 0.5468, cls_loss: 0.3219, reg_loss: 0.2249
2022-04-24 03:11:23 - train: epoch 0002, iter [01400, 03664], lr: 0.000100, total_loss: 0.5584, cls_loss: 0.3380, reg_loss: 0.2204
2022-04-24 03:12:06 - train: epoch 0002, iter [01500, 03664], lr: 0.000100, total_loss: 0.5306, cls_loss: 0.3284, reg_loss: 0.2022
2022-04-24 03:12:47 - train: epoch 0002, iter [01600, 03664], lr: 0.000100, total_loss: 0.5756, cls_loss: 0.3564, reg_loss: 0.2192
2022-04-24 03:13:30 - train: epoch 0002, iter [01700, 03664], lr: 0.000100, total_loss: 0.5988, cls_loss: 0.3707, reg_loss: 0.2281
2022-04-24 03:14:11 - train: epoch 0002, iter [01800, 03664], lr: 0.000100, total_loss: 0.5638, cls_loss: 0.3385, reg_loss: 0.2253
2022-04-24 03:14:54 - train: epoch 0002, iter [01900, 03664], lr: 0.000100, total_loss: 0.5816, cls_loss: 0.3585, reg_loss: 0.2231
2022-04-24 03:15:36 - train: epoch 0002, iter [02000, 03664], lr: 0.000100, total_loss: 0.5245, cls_loss: 0.3033, reg_loss: 0.2212
2022-04-24 03:16:17 - train: epoch 0002, iter [02100, 03664], lr: 0.000100, total_loss: 0.5556, cls_loss: 0.3373, reg_loss: 0.2184
2022-04-24 03:17:00 - train: epoch 0002, iter [02200, 03664], lr: 0.000100, total_loss: 0.5109, cls_loss: 0.3006, reg_loss: 0.2103
2022-04-24 03:17:41 - train: epoch 0002, iter [02300, 03664], lr: 0.000100, total_loss: 0.6488, cls_loss: 0.4178, reg_loss: 0.2311
2022-04-24 03:18:24 - train: epoch 0002, iter [02400, 03664], lr: 0.000100, total_loss: 0.5113, cls_loss: 0.3162, reg_loss: 0.1950
2022-04-24 03:19:08 - train: epoch 0002, iter [02500, 03664], lr: 0.000100, total_loss: 0.5307, cls_loss: 0.3138, reg_loss: 0.2169
2022-04-24 03:19:48 - train: epoch 0002, iter [02600, 03664], lr: 0.000100, total_loss: 0.4809, cls_loss: 0.2825, reg_loss: 0.1984
2022-04-24 03:20:31 - train: epoch 0002, iter [02700, 03664], lr: 0.000100, total_loss: 0.5377, cls_loss: 0.3283, reg_loss: 0.2094
2022-04-24 03:21:15 - train: epoch 0002, iter [02800, 03664], lr: 0.000100, total_loss: 0.6044, cls_loss: 0.3842, reg_loss: 0.2202
2022-04-24 03:21:55 - train: epoch 0002, iter [02900, 03664], lr: 0.000100, total_loss: 0.6139, cls_loss: 0.3913, reg_loss: 0.2226
2022-04-24 03:22:38 - train: epoch 0002, iter [03000, 03664], lr: 0.000100, total_loss: 0.5251, cls_loss: 0.3117, reg_loss: 0.2134
2022-04-24 03:23:18 - train: epoch 0002, iter [03100, 03664], lr: 0.000100, total_loss: 0.5206, cls_loss: 0.2997, reg_loss: 0.2209
2022-04-24 03:24:01 - train: epoch 0002, iter [03200, 03664], lr: 0.000100, total_loss: 0.5661, cls_loss: 0.3588, reg_loss: 0.2072
2022-04-24 03:24:42 - train: epoch 0002, iter [03300, 03664], lr: 0.000100, total_loss: 0.5595, cls_loss: 0.3467, reg_loss: 0.2128
2022-04-24 03:25:25 - train: epoch 0002, iter [03400, 03664], lr: 0.000100, total_loss: 0.5785, cls_loss: 0.3555, reg_loss: 0.2230
2022-04-24 03:26:07 - train: epoch 0002, iter [03500, 03664], lr: 0.000100, total_loss: 0.5561, cls_loss: 0.3467, reg_loss: 0.2094
2022-04-24 03:26:47 - train: epoch 0002, iter [03600, 03664], lr: 0.000100, total_loss: 0.5164, cls_loss: 0.3216, reg_loss: 0.1948
2022-04-24 03:27:16 - train: epoch 002, train_loss: 0.5620
2022-04-24 03:27:17 - until epoch: 002, best_metric: 16.984%
2022-04-24 03:27:17 - epoch 003 lr: 0.0001
2022-04-24 03:27:58 - train: epoch 0003, iter [00100, 03664], lr: 0.000100, total_loss: 0.5067, cls_loss: 0.3020, reg_loss: 0.2048
2022-04-24 03:28:41 - train: epoch 0003, iter [00200, 03664], lr: 0.000100, total_loss: 0.5906, cls_loss: 0.3600, reg_loss: 0.2306
2022-04-24 03:29:22 - train: epoch 0003, iter [00300, 03664], lr: 0.000100, total_loss: 0.5488, cls_loss: 0.3088, reg_loss: 0.2401
2022-04-24 03:30:05 - train: epoch 0003, iter [00400, 03664], lr: 0.000100, total_loss: 0.5577, cls_loss: 0.3334, reg_loss: 0.2243
2022-04-24 03:30:48 - train: epoch 0003, iter [00500, 03664], lr: 0.000100, total_loss: 0.5928, cls_loss: 0.3514, reg_loss: 0.2414
2022-04-24 03:31:29 - train: epoch 0003, iter [00600, 03664], lr: 0.000100, total_loss: 0.4628, cls_loss: 0.2575, reg_loss: 0.2053
2022-04-24 03:32:12 - train: epoch 0003, iter [00700, 03664], lr: 0.000100, total_loss: 0.5560, cls_loss: 0.3492, reg_loss: 0.2068
2022-04-24 03:32:55 - train: epoch 0003, iter [00800, 03664], lr: 0.000100, total_loss: 0.5750, cls_loss: 0.3446, reg_loss: 0.2304
2022-04-24 03:33:36 - train: epoch 0003, iter [00900, 03664], lr: 0.000100, total_loss: 0.5452, cls_loss: 0.3343, reg_loss: 0.2109
2022-04-24 03:34:17 - train: epoch 0003, iter [01000, 03664], lr: 0.000100, total_loss: 0.5110, cls_loss: 0.3048, reg_loss: 0.2062
2022-04-24 03:35:00 - train: epoch 0003, iter [01100, 03664], lr: 0.000100, total_loss: 0.4424, cls_loss: 0.2643, reg_loss: 0.1781
2022-04-24 03:35:43 - train: epoch 0003, iter [01200, 03664], lr: 0.000100, total_loss: 0.5219, cls_loss: 0.3169, reg_loss: 0.2050
2022-04-24 03:36:24 - train: epoch 0003, iter [01300, 03664], lr: 0.000100, total_loss: 0.5337, cls_loss: 0.3224, reg_loss: 0.2113
2022-04-24 03:37:07 - train: epoch 0003, iter [01400, 03664], lr: 0.000100, total_loss: 0.4689, cls_loss: 0.2755, reg_loss: 0.1934
2022-04-24 03:37:49 - train: epoch 0003, iter [01500, 03664], lr: 0.000100, total_loss: 0.5285, cls_loss: 0.3106, reg_loss: 0.2179
2022-04-24 03:38:30 - train: epoch 0003, iter [01600, 03664], lr: 0.000100, total_loss: 0.4792, cls_loss: 0.2639, reg_loss: 0.2153
2022-04-24 03:39:12 - train: epoch 0003, iter [01700, 03664], lr: 0.000100, total_loss: 0.4595, cls_loss: 0.2692, reg_loss: 0.1903
2022-04-24 03:39:55 - train: epoch 0003, iter [01800, 03664], lr: 0.000100, total_loss: 0.5170, cls_loss: 0.3197, reg_loss: 0.1973
2022-04-24 03:40:35 - train: epoch 0003, iter [01900, 03664], lr: 0.000100, total_loss: 0.5637, cls_loss: 0.3388, reg_loss: 0.2249
2022-04-24 03:41:15 - train: epoch 0003, iter [02000, 03664], lr: 0.000100, total_loss: 0.4512, cls_loss: 0.2658, reg_loss: 0.1854
2022-04-24 03:41:58 - train: epoch 0003, iter [02100, 03664], lr: 0.000100, total_loss: 0.5407, cls_loss: 0.3214, reg_loss: 0.2193
2022-04-24 03:42:41 - train: epoch 0003, iter [02200, 03664], lr: 0.000100, total_loss: 0.5198, cls_loss: 0.3039, reg_loss: 0.2160
2022-04-24 03:43:21 - train: epoch 0003, iter [02300, 03664], lr: 0.000100, total_loss: 0.5576, cls_loss: 0.3319, reg_loss: 0.2257
2022-04-24 03:44:04 - train: epoch 0003, iter [02400, 03664], lr: 0.000100, total_loss: 0.4939, cls_loss: 0.2929, reg_loss: 0.2010
2022-04-24 03:44:47 - train: epoch 0003, iter [02500, 03664], lr: 0.000100, total_loss: 0.5301, cls_loss: 0.3292, reg_loss: 0.2009
2022-04-24 03:45:27 - train: epoch 0003, iter [02600, 03664], lr: 0.000100, total_loss: 0.4585, cls_loss: 0.2710, reg_loss: 0.1875
2022-04-24 03:46:07 - train: epoch 0003, iter [02700, 03664], lr: 0.000100, total_loss: 0.4749, cls_loss: 0.2865, reg_loss: 0.1884
2022-04-24 03:46:52 - train: epoch 0003, iter [02800, 03664], lr: 0.000100, total_loss: 0.5124, cls_loss: 0.3056, reg_loss: 0.2068
2022-04-24 03:47:32 - train: epoch 0003, iter [02900, 03664], lr: 0.000100, total_loss: 0.4940, cls_loss: 0.2790, reg_loss: 0.2150
2022-04-24 03:48:12 - train: epoch 0003, iter [03000, 03664], lr: 0.000100, total_loss: 0.5067, cls_loss: 0.2946, reg_loss: 0.2121
2022-04-24 03:48:57 - train: epoch 0003, iter [03100, 03664], lr: 0.000100, total_loss: 0.5030, cls_loss: 0.2915, reg_loss: 0.2114
2022-04-24 03:49:38 - train: epoch 0003, iter [03200, 03664], lr: 0.000100, total_loss: 0.4518, cls_loss: 0.2778, reg_loss: 0.1740
2022-04-24 03:50:18 - train: epoch 0003, iter [03300, 03664], lr: 0.000100, total_loss: 0.4849, cls_loss: 0.2952, reg_loss: 0.1898
2022-04-24 03:51:01 - train: epoch 0003, iter [03400, 03664], lr: 0.000100, total_loss: 0.4855, cls_loss: 0.2816, reg_loss: 0.2039
2022-04-24 03:51:44 - train: epoch 0003, iter [03500, 03664], lr: 0.000100, total_loss: 0.5235, cls_loss: 0.3027, reg_loss: 0.2207
2022-04-24 03:52:24 - train: epoch 0003, iter [03600, 03664], lr: 0.000100, total_loss: 0.4929, cls_loss: 0.2986, reg_loss: 0.1943
2022-04-24 03:52:51 - train: epoch 003, train_loss: 0.5129
2022-04-24 03:57:06 - eval: epoch: 003
per_image_load_time: 1.738ms
per_image_inference_time: 42.475ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 24.2289783007465
IoU=0.50,area=all,maxDets=100,mAP: 38.140551342943695
IoU=0.75,area=all,maxDets=100,mAP: 25.617034928816494
IoU=0.50:0.95,area=small,maxDets=100,mAP: 7.773850649937238
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 27.274839058531374
IoU=0.50:0.95,area=large,maxDets=100,mAP: 37.48026041132982
IoU=0.50:0.95,area=all,maxDets=1,mAR: 21.88660506569333
IoU=0.50:0.95,area=all,maxDets=10,mAR: 32.73018426486811
IoU=0.50:0.95,area=all,maxDets=100,mAR: 33.97801756434926
IoU=0.50:0.95,area=small,maxDets=100,mAR: 9.575996938014745
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 38.979959247384116
IoU=0.50:0.95,area=large,maxDets=100,mAR: 51.14008479330789

2022-04-24 03:57:07 - until epoch: 003, best_metric: 24.229%
2022-04-24 03:57:07 - epoch 004 lr: 0.0001
2022-04-24 03:57:51 - train: epoch 0004, iter [00100, 03664], lr: 0.000100, total_loss: 0.5401, cls_loss: 0.3127, reg_loss: 0.2274
2022-04-24 03:58:34 - train: epoch 0004, iter [00200, 03664], lr: 0.000100, total_loss: 0.4219, cls_loss: 0.2504, reg_loss: 0.1715
2022-04-24 03:59:14 - train: epoch 0004, iter [00300, 03664], lr: 0.000100, total_loss: 0.5075, cls_loss: 0.2875, reg_loss: 0.2200
2022-04-24 03:59:56 - train: epoch 0004, iter [00400, 03664], lr: 0.000100, total_loss: 0.5347, cls_loss: 0.3295, reg_loss: 0.2052
2022-04-24 04:00:39 - train: epoch 0004, iter [00500, 03664], lr: 0.000100, total_loss: 0.4858, cls_loss: 0.2827, reg_loss: 0.2032
2022-04-24 04:01:20 - train: epoch 0004, iter [00600, 03664], lr: 0.000100, total_loss: 0.4601, cls_loss: 0.2651, reg_loss: 0.1950
2022-04-24 04:02:00 - train: epoch 0004, iter [00700, 03664], lr: 0.000100, total_loss: 0.4370, cls_loss: 0.2673, reg_loss: 0.1698
2022-04-24 04:02:44 - train: epoch 0004, iter [00800, 03664], lr: 0.000100, total_loss: 0.4824, cls_loss: 0.2788, reg_loss: 0.2036
2022-04-24 04:03:24 - train: epoch 0004, iter [00900, 03664], lr: 0.000100, total_loss: 0.5180, cls_loss: 0.3121, reg_loss: 0.2059
2022-04-24 04:04:04 - train: epoch 0004, iter [01000, 03664], lr: 0.000100, total_loss: 0.4921, cls_loss: 0.3034, reg_loss: 0.1887
2022-04-24 04:04:47 - train: epoch 0004, iter [01100, 03664], lr: 0.000100, total_loss: 0.4486, cls_loss: 0.2639, reg_loss: 0.1847
2022-04-24 04:05:29 - train: epoch 0004, iter [01200, 03664], lr: 0.000100, total_loss: 0.4790, cls_loss: 0.2806, reg_loss: 0.1985
2022-04-24 04:06:08 - train: epoch 0004, iter [01300, 03664], lr: 0.000100, total_loss: 0.5026, cls_loss: 0.3089, reg_loss: 0.1937
2022-04-24 04:06:50 - train: epoch 0004, iter [01400, 03664], lr: 0.000100, total_loss: 0.5649, cls_loss: 0.3375, reg_loss: 0.2274
2022-04-24 04:07:33 - train: epoch 0004, iter [01500, 03664], lr: 0.000100, total_loss: 0.4511, cls_loss: 0.2590, reg_loss: 0.1921
2022-04-24 04:08:13 - train: epoch 0004, iter [01600, 03664], lr: 0.000100, total_loss: 0.4198, cls_loss: 0.2388, reg_loss: 0.1810
2022-04-24 04:08:55 - train: epoch 0004, iter [01700, 03664], lr: 0.000100, total_loss: 0.5422, cls_loss: 0.3395, reg_loss: 0.2027
2022-04-24 04:09:37 - train: epoch 0004, iter [01800, 03664], lr: 0.000100, total_loss: 0.4959, cls_loss: 0.2899, reg_loss: 0.2060
2022-04-24 04:10:17 - train: epoch 0004, iter [01900, 03664], lr: 0.000100, total_loss: 0.4551, cls_loss: 0.2776, reg_loss: 0.1775
2022-04-24 04:10:57 - train: epoch 0004, iter [02000, 03664], lr: 0.000100, total_loss: 0.4145, cls_loss: 0.2352, reg_loss: 0.1794
2022-04-24 04:11:41 - train: epoch 0004, iter [02100, 03664], lr: 0.000100, total_loss: 0.4414, cls_loss: 0.2648, reg_loss: 0.1766
2022-04-24 04:12:21 - train: epoch 0004, iter [02200, 03664], lr: 0.000100, total_loss: 0.4742, cls_loss: 0.2780, reg_loss: 0.1962
2022-04-24 04:13:01 - train: epoch 0004, iter [02300, 03664], lr: 0.000100, total_loss: 0.4239, cls_loss: 0.2430, reg_loss: 0.1810
2022-04-24 04:13:43 - train: epoch 0004, iter [02400, 03664], lr: 0.000100, total_loss: 0.4980, cls_loss: 0.2932, reg_loss: 0.2048
2022-04-24 04:14:25 - train: epoch 0004, iter [02500, 03664], lr: 0.000100, total_loss: 0.4726, cls_loss: 0.2715, reg_loss: 0.2012
2022-04-24 04:15:05 - train: epoch 0004, iter [02600, 03664], lr: 0.000100, total_loss: 0.4180, cls_loss: 0.2303, reg_loss: 0.1876
2022-04-24 04:15:47 - train: epoch 0004, iter [02700, 03664], lr: 0.000100, total_loss: 0.5137, cls_loss: 0.3131, reg_loss: 0.2005
2022-04-24 04:16:30 - train: epoch 0004, iter [02800, 03664], lr: 0.000100, total_loss: 0.4681, cls_loss: 0.2671, reg_loss: 0.2010
2022-04-24 04:17:10 - train: epoch 0004, iter [02900, 03664], lr: 0.000100, total_loss: 0.4325, cls_loss: 0.2345, reg_loss: 0.1980
2022-04-24 04:17:50 - train: epoch 0004, iter [03000, 03664], lr: 0.000100, total_loss: 0.4164, cls_loss: 0.2466, reg_loss: 0.1698
2022-04-24 04:18:34 - train: epoch 0004, iter [03100, 03664], lr: 0.000100, total_loss: 0.5043, cls_loss: 0.3017, reg_loss: 0.2026
2022-04-24 04:19:14 - train: epoch 0004, iter [03200, 03664], lr: 0.000100, total_loss: 0.5341, cls_loss: 0.3064, reg_loss: 0.2277
2022-04-24 04:19:55 - train: epoch 0004, iter [03300, 03664], lr: 0.000100, total_loss: 0.4359, cls_loss: 0.2525, reg_loss: 0.1833
2022-04-24 04:20:38 - train: epoch 0004, iter [03400, 03664], lr: 0.000100, total_loss: 0.5676, cls_loss: 0.3689, reg_loss: 0.1987
2022-04-24 04:21:18 - train: epoch 0004, iter [03500, 03664], lr: 0.000100, total_loss: 0.5375, cls_loss: 0.3314, reg_loss: 0.2061
2022-04-24 04:21:58 - train: epoch 0004, iter [03600, 03664], lr: 0.000100, total_loss: 0.4827, cls_loss: 0.2941, reg_loss: 0.1886
2022-04-24 04:22:24 - train: epoch 004, train_loss: 0.4834
2022-04-24 04:22:25 - until epoch: 004, best_metric: 24.229%
2022-04-24 04:22:25 - epoch 005 lr: 0.0001
2022-04-24 04:23:10 - train: epoch 0005, iter [00100, 03664], lr: 0.000100, total_loss: 0.4442, cls_loss: 0.2477, reg_loss: 0.1964
2022-04-24 04:23:50 - train: epoch 0005, iter [00200, 03664], lr: 0.000100, total_loss: 0.4620, cls_loss: 0.2760, reg_loss: 0.1860
2022-04-24 04:24:31 - train: epoch 0005, iter [00300, 03664], lr: 0.000100, total_loss: 0.4086, cls_loss: 0.2277, reg_loss: 0.1809
2022-04-24 04:25:15 - train: epoch 0005, iter [00400, 03664], lr: 0.000100, total_loss: 0.4603, cls_loss: 0.2771, reg_loss: 0.1832
2022-04-24 04:25:55 - train: epoch 0005, iter [00500, 03664], lr: 0.000100, total_loss: 0.4307, cls_loss: 0.2315, reg_loss: 0.1992
2022-04-24 04:26:36 - train: epoch 0005, iter [00600, 03664], lr: 0.000100, total_loss: 0.4420, cls_loss: 0.2493, reg_loss: 0.1927
2022-04-24 04:27:18 - train: epoch 0005, iter [00700, 03664], lr: 0.000100, total_loss: 0.4428, cls_loss: 0.2654, reg_loss: 0.1773
2022-04-24 04:28:00 - train: epoch 0005, iter [00800, 03664], lr: 0.000100, total_loss: 0.4846, cls_loss: 0.2838, reg_loss: 0.2008
2022-04-24 04:28:41 - train: epoch 0005, iter [00900, 03664], lr: 0.000100, total_loss: 0.4418, cls_loss: 0.2544, reg_loss: 0.1874
2022-04-24 04:29:21 - train: epoch 0005, iter [01000, 03664], lr: 0.000100, total_loss: 0.5079, cls_loss: 0.3131, reg_loss: 0.1948
2022-04-24 04:30:05 - train: epoch 0005, iter [01100, 03664], lr: 0.000100, total_loss: 0.3979, cls_loss: 0.2169, reg_loss: 0.1811
2022-04-24 04:30:46 - train: epoch 0005, iter [01200, 03664], lr: 0.000100, total_loss: 0.4699, cls_loss: 0.2745, reg_loss: 0.1954
2022-04-24 04:31:26 - train: epoch 0005, iter [01300, 03664], lr: 0.000100, total_loss: 0.4382, cls_loss: 0.2664, reg_loss: 0.1718
2022-04-24 04:32:10 - train: epoch 0005, iter [01400, 03664], lr: 0.000100, total_loss: 0.4258, cls_loss: 0.2427, reg_loss: 0.1831
2022-04-24 04:32:50 - train: epoch 0005, iter [01500, 03664], lr: 0.000100, total_loss: 0.4349, cls_loss: 0.2578, reg_loss: 0.1771
2022-04-24 04:33:31 - train: epoch 0005, iter [01600, 03664], lr: 0.000100, total_loss: 0.4355, cls_loss: 0.2459, reg_loss: 0.1895
2022-04-24 04:34:11 - train: epoch 0005, iter [01700, 03664], lr: 0.000100, total_loss: 0.4322, cls_loss: 0.2494, reg_loss: 0.1828
2022-04-24 04:34:55 - train: epoch 0005, iter [01800, 03664], lr: 0.000100, total_loss: 0.4852, cls_loss: 0.2867, reg_loss: 0.1986
2022-04-24 04:35:36 - train: epoch 0005, iter [01900, 03664], lr: 0.000100, total_loss: 0.4708, cls_loss: 0.2694, reg_loss: 0.2014
2022-04-24 04:36:17 - train: epoch 0005, iter [02000, 03664], lr: 0.000100, total_loss: 0.5563, cls_loss: 0.3349, reg_loss: 0.2214
2022-04-24 04:37:01 - train: epoch 0005, iter [02100, 03664], lr: 0.000100, total_loss: 0.4630, cls_loss: 0.2650, reg_loss: 0.1980
2022-04-24 04:37:41 - train: epoch 0005, iter [02200, 03664], lr: 0.000100, total_loss: 0.4905, cls_loss: 0.3040, reg_loss: 0.1865
2022-04-24 04:38:21 - train: epoch 0005, iter [02300, 03664], lr: 0.000100, total_loss: 0.4675, cls_loss: 0.2772, reg_loss: 0.1903
2022-04-24 04:39:06 - train: epoch 0005, iter [02400, 03664], lr: 0.000100, total_loss: 0.4860, cls_loss: 0.2711, reg_loss: 0.2148
2022-04-24 04:39:46 - train: epoch 0005, iter [02500, 03664], lr: 0.000100, total_loss: 0.4740, cls_loss: 0.2954, reg_loss: 0.1786
2022-04-24 04:40:27 - train: epoch 0005, iter [02600, 03664], lr: 0.000100, total_loss: 0.5131, cls_loss: 0.2977, reg_loss: 0.2154
2022-04-24 04:41:09 - train: epoch 0005, iter [02700, 03664], lr: 0.000100, total_loss: 0.4495, cls_loss: 0.2733, reg_loss: 0.1762
2022-04-24 04:41:52 - train: epoch 0005, iter [02800, 03664], lr: 0.000100, total_loss: 0.4406, cls_loss: 0.2592, reg_loss: 0.1814
2022-04-24 04:42:32 - train: epoch 0005, iter [02900, 03664], lr: 0.000100, total_loss: 0.5005, cls_loss: 0.2968, reg_loss: 0.2036
2022-04-24 04:43:13 - train: epoch 0005, iter [03000, 03664], lr: 0.000100, total_loss: 0.4861, cls_loss: 0.2871, reg_loss: 0.1990
2022-04-24 04:43:57 - train: epoch 0005, iter [03100, 03664], lr: 0.000100, total_loss: 0.4552, cls_loss: 0.2449, reg_loss: 0.2103
2022-04-24 04:44:37 - train: epoch 0005, iter [03200, 03664], lr: 0.000100, total_loss: 0.4366, cls_loss: 0.2522, reg_loss: 0.1844
2022-04-24 04:45:17 - train: epoch 0005, iter [03300, 03664], lr: 0.000100, total_loss: 0.4599, cls_loss: 0.2650, reg_loss: 0.1949
2022-04-24 04:46:01 - train: epoch 0005, iter [03400, 03664], lr: 0.000100, total_loss: 0.4094, cls_loss: 0.2282, reg_loss: 0.1812
2022-04-24 04:46:42 - train: epoch 0005, iter [03500, 03664], lr: 0.000100, total_loss: 0.4984, cls_loss: 0.2998, reg_loss: 0.1985
2022-04-24 04:47:22 - train: epoch 0005, iter [03600, 03664], lr: 0.000100, total_loss: 0.4469, cls_loss: 0.2619, reg_loss: 0.1850
2022-04-24 04:47:50 - train: epoch 005, train_loss: 0.4614
2022-04-24 04:51:54 - eval: epoch: 005
per_image_load_time: 1.695ms
per_image_inference_time: 40.437ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 26.486396227047678
IoU=0.50,area=all,maxDets=100,mAP: 40.71010905393315
IoU=0.75,area=all,maxDets=100,mAP: 28.125397088216886
IoU=0.50:0.95,area=small,maxDets=100,mAP: 8.576762542448963
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 30.92825739106822
IoU=0.50:0.95,area=large,maxDets=100,mAP: 40.95672286245297
IoU=0.50:0.95,area=all,maxDets=1,mAR: 23.66281069526834
IoU=0.50:0.95,area=all,maxDets=10,mAR: 35.25487589796295
IoU=0.50:0.95,area=all,maxDets=100,mAR: 36.496306523307226
IoU=0.50:0.95,area=small,maxDets=100,mAR: 10.732541987632036
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 42.9875675859085
IoU=0.50:0.95,area=large,maxDets=100,mAR: 54.52696448799947

2022-04-24 04:51:55 - until epoch: 005, best_metric: 26.486%
2022-04-24 04:51:55 - epoch 006 lr: 0.0001
2022-04-24 04:52:36 - train: epoch 0006, iter [00100, 03664], lr: 0.000100, total_loss: 0.4323, cls_loss: 0.2396, reg_loss: 0.1927
2022-04-24 04:53:16 - train: epoch 0006, iter [00200, 03664], lr: 0.000100, total_loss: 0.4295, cls_loss: 0.2513, reg_loss: 0.1783
2022-04-24 04:53:56 - train: epoch 0006, iter [00300, 03664], lr: 0.000100, total_loss: 0.4788, cls_loss: 0.2831, reg_loss: 0.1957
2022-04-24 04:54:37 - train: epoch 0006, iter [00400, 03664], lr: 0.000100, total_loss: 0.3947, cls_loss: 0.2263, reg_loss: 0.1684
2022-04-24 04:55:17 - train: epoch 0006, iter [00500, 03664], lr: 0.000100, total_loss: 0.4866, cls_loss: 0.2818, reg_loss: 0.2048
2022-04-24 04:56:01 - train: epoch 0006, iter [00600, 03664], lr: 0.000100, total_loss: 0.4395, cls_loss: 0.2443, reg_loss: 0.1952
2022-04-24 04:56:41 - train: epoch 0006, iter [00700, 03664], lr: 0.000100, total_loss: 0.4691, cls_loss: 0.2762, reg_loss: 0.1930
2022-04-24 04:57:22 - train: epoch 0006, iter [00800, 03664], lr: 0.000100, total_loss: 0.4668, cls_loss: 0.2787, reg_loss: 0.1881
2022-04-24 04:58:05 - train: epoch 0006, iter [00900, 03664], lr: 0.000100, total_loss: 0.4271, cls_loss: 0.2383, reg_loss: 0.1888
2022-04-24 04:58:46 - train: epoch 0006, iter [01000, 03664], lr: 0.000100, total_loss: 0.4897, cls_loss: 0.2885, reg_loss: 0.2011
2022-04-24 04:59:26 - train: epoch 0006, iter [01100, 03664], lr: 0.000100, total_loss: 0.4441, cls_loss: 0.2503, reg_loss: 0.1938
2022-04-24 05:00:10 - train: epoch 0006, iter [01200, 03664], lr: 0.000100, total_loss: 0.3888, cls_loss: 0.2175, reg_loss: 0.1713
2022-04-24 05:00:50 - train: epoch 0006, iter [01300, 03664], lr: 0.000100, total_loss: 0.3727, cls_loss: 0.2015, reg_loss: 0.1712
2022-04-24 05:01:30 - train: epoch 0006, iter [01400, 03664], lr: 0.000100, total_loss: 0.4298, cls_loss: 0.2399, reg_loss: 0.1899
2022-04-24 05:02:10 - train: epoch 0006, iter [01500, 03664], lr: 0.000100, total_loss: 0.4567, cls_loss: 0.2740, reg_loss: 0.1827
2022-04-24 05:02:54 - train: epoch 0006, iter [01600, 03664], lr: 0.000100, total_loss: 0.4099, cls_loss: 0.2360, reg_loss: 0.1739
2022-04-24 05:03:34 - train: epoch 0006, iter [01700, 03664], lr: 0.000100, total_loss: 0.4448, cls_loss: 0.2511, reg_loss: 0.1937
2022-04-24 05:04:15 - train: epoch 0006, iter [01800, 03664], lr: 0.000100, total_loss: 0.4426, cls_loss: 0.2654, reg_loss: 0.1773
2022-04-24 05:04:57 - train: epoch 0006, iter [01900, 03664], lr: 0.000100, total_loss: 0.4600, cls_loss: 0.2718, reg_loss: 0.1883
2022-04-24 05:05:37 - train: epoch 0006, iter [02000, 03664], lr: 0.000100, total_loss: 0.5186, cls_loss: 0.3163, reg_loss: 0.2024
2022-04-24 05:06:17 - train: epoch 0006, iter [02100, 03664], lr: 0.000100, total_loss: 0.3735, cls_loss: 0.2211, reg_loss: 0.1525
2022-04-24 05:07:01 - train: epoch 0006, iter [02200, 03664], lr: 0.000100, total_loss: 0.4075, cls_loss: 0.2412, reg_loss: 0.1662
2022-04-24 05:07:42 - train: epoch 0006, iter [02300, 03664], lr: 0.000100, total_loss: 0.4017, cls_loss: 0.2226, reg_loss: 0.1791
2022-04-24 05:08:22 - train: epoch 0006, iter [02400, 03664], lr: 0.000100, total_loss: 0.4613, cls_loss: 0.2732, reg_loss: 0.1881
2022-04-24 05:09:02 - train: epoch 0006, iter [02500, 03664], lr: 0.000100, total_loss: 0.4570, cls_loss: 0.2532, reg_loss: 0.2038
2022-04-24 05:09:46 - train: epoch 0006, iter [02600, 03664], lr: 0.000100, total_loss: 0.4474, cls_loss: 0.2416, reg_loss: 0.2058
2022-04-24 05:10:26 - train: epoch 0006, iter [02700, 03664], lr: 0.000100, total_loss: 0.4838, cls_loss: 0.2937, reg_loss: 0.1901
2022-04-24 05:11:07 - train: epoch 0006, iter [02800, 03664], lr: 0.000100, total_loss: 0.4525, cls_loss: 0.2548, reg_loss: 0.1977
2022-04-24 05:11:51 - train: epoch 0006, iter [02900, 03664], lr: 0.000100, total_loss: 0.4234, cls_loss: 0.2451, reg_loss: 0.1783
2022-04-24 05:12:31 - train: epoch 0006, iter [03000, 03664], lr: 0.000100, total_loss: 0.4305, cls_loss: 0.2511, reg_loss: 0.1794
2022-04-24 05:13:12 - train: epoch 0006, iter [03100, 03664], lr: 0.000100, total_loss: 0.5183, cls_loss: 0.3126, reg_loss: 0.2057
2022-04-24 05:13:56 - train: epoch 0006, iter [03200, 03664], lr: 0.000100, total_loss: 0.4776, cls_loss: 0.2923, reg_loss: 0.1853
2022-04-24 05:14:36 - train: epoch 0006, iter [03300, 03664], lr: 0.000100, total_loss: 0.4883, cls_loss: 0.2996, reg_loss: 0.1887
2022-04-24 05:15:16 - train: epoch 0006, iter [03400, 03664], lr: 0.000100, total_loss: 0.4628, cls_loss: 0.2684, reg_loss: 0.1945
2022-04-24 05:15:58 - train: epoch 0006, iter [03500, 03664], lr: 0.000100, total_loss: 0.4398, cls_loss: 0.2452, reg_loss: 0.1946
2022-04-24 05:16:40 - train: epoch 0006, iter [03600, 03664], lr: 0.000100, total_loss: 0.4782, cls_loss: 0.2824, reg_loss: 0.1958
2022-04-24 05:17:07 - train: epoch 006, train_loss: 0.4441
2022-04-24 05:17:08 - until epoch: 006, best_metric: 26.486%
2022-04-24 05:17:08 - epoch 007 lr: 0.0001
2022-04-24 05:17:50 - train: epoch 0007, iter [00100, 03664], lr: 0.000100, total_loss: 0.3811, cls_loss: 0.2158, reg_loss: 0.1653
2022-04-24 05:18:35 - train: epoch 0007, iter [00200, 03664], lr: 0.000100, total_loss: 0.4468, cls_loss: 0.2539, reg_loss: 0.1929
2022-04-24 05:19:15 - train: epoch 0007, iter [00300, 03664], lr: 0.000100, total_loss: 0.4014, cls_loss: 0.2156, reg_loss: 0.1858
2022-04-24 05:19:55 - train: epoch 0007, iter [00400, 03664], lr: 0.000100, total_loss: 0.4495, cls_loss: 0.2570, reg_loss: 0.1925
2022-04-24 05:20:38 - train: epoch 0007, iter [00500, 03664], lr: 0.000100, total_loss: 0.4255, cls_loss: 0.2311, reg_loss: 0.1943
2022-04-24 05:21:19 - train: epoch 0007, iter [00600, 03664], lr: 0.000100, total_loss: 0.4099, cls_loss: 0.2466, reg_loss: 0.1633
2022-04-24 05:21:59 - train: epoch 0007, iter [00700, 03664], lr: 0.000100, total_loss: 0.4250, cls_loss: 0.2439, reg_loss: 0.1811
2022-04-24 05:22:42 - train: epoch 0007, iter [00800, 03664], lr: 0.000100, total_loss: 0.4137, cls_loss: 0.2401, reg_loss: 0.1736
2022-04-24 05:23:24 - train: epoch 0007, iter [00900, 03664], lr: 0.000100, total_loss: 0.4340, cls_loss: 0.2566, reg_loss: 0.1774
2022-04-24 05:24:04 - train: epoch 0007, iter [01000, 03664], lr: 0.000100, total_loss: 0.4344, cls_loss: 0.2433, reg_loss: 0.1911
2022-04-24 05:24:44 - train: epoch 0007, iter [01100, 03664], lr: 0.000100, total_loss: 0.4502, cls_loss: 0.2685, reg_loss: 0.1817
2022-04-24 05:25:28 - train: epoch 0007, iter [01200, 03664], lr: 0.000100, total_loss: 0.4388, cls_loss: 0.2482, reg_loss: 0.1906
2022-04-24 05:26:09 - train: epoch 0007, iter [01300, 03664], lr: 0.000100, total_loss: 0.4169, cls_loss: 0.2297, reg_loss: 0.1872
2022-04-24 05:26:49 - train: epoch 0007, iter [01400, 03664], lr: 0.000100, total_loss: 0.4168, cls_loss: 0.2431, reg_loss: 0.1737
2022-04-24 05:27:35 - train: epoch 0007, iter [01500, 03664], lr: 0.000100, total_loss: 0.4579, cls_loss: 0.2618, reg_loss: 0.1961
2022-04-24 05:28:15 - train: epoch 0007, iter [01600, 03664], lr: 0.000100, total_loss: 0.4559, cls_loss: 0.2431, reg_loss: 0.2129
2022-04-24 05:28:56 - train: epoch 0007, iter [01700, 03664], lr: 0.000100, total_loss: 0.4181, cls_loss: 0.2462, reg_loss: 0.1718
2022-04-24 05:29:41 - train: epoch 0007, iter [01800, 03664], lr: 0.000100, total_loss: 0.4340, cls_loss: 0.2511, reg_loss: 0.1828
2022-04-24 05:30:22 - train: epoch 0007, iter [01900, 03664], lr: 0.000100, total_loss: 0.4786, cls_loss: 0.2895, reg_loss: 0.1891
2022-04-24 05:31:02 - train: epoch 0007, iter [02000, 03664], lr: 0.000100, total_loss: 0.4432, cls_loss: 0.2583, reg_loss: 0.1849
2022-04-24 05:31:45 - train: epoch 0007, iter [02100, 03664], lr: 0.000100, total_loss: 0.4636, cls_loss: 0.2711, reg_loss: 0.1926
2022-04-24 05:32:28 - train: epoch 0007, iter [02200, 03664], lr: 0.000100, total_loss: 0.4539, cls_loss: 0.2604, reg_loss: 0.1935
2022-04-24 05:33:08 - train: epoch 0007, iter [02300, 03664], lr: 0.000100, total_loss: 0.4554, cls_loss: 0.2650, reg_loss: 0.1904
2022-04-24 05:33:49 - train: epoch 0007, iter [02400, 03664], lr: 0.000100, total_loss: 0.4346, cls_loss: 0.2616, reg_loss: 0.1730
2022-04-24 05:34:34 - train: epoch 0007, iter [02500, 03664], lr: 0.000100, total_loss: 0.4126, cls_loss: 0.2228, reg_loss: 0.1898
2022-04-24 05:35:15 - train: epoch 0007, iter [02600, 03664], lr: 0.000100, total_loss: 0.4371, cls_loss: 0.2490, reg_loss: 0.1880
2022-04-24 05:35:56 - train: epoch 0007, iter [02700, 03664], lr: 0.000100, total_loss: 0.4669, cls_loss: 0.2789, reg_loss: 0.1880
2022-04-24 05:36:41 - train: epoch 0007, iter [02800, 03664], lr: 0.000100, total_loss: 0.4094, cls_loss: 0.2188, reg_loss: 0.1906
2022-04-24 05:37:22 - train: epoch 0007, iter [02900, 03664], lr: 0.000100, total_loss: 0.5146, cls_loss: 0.2913, reg_loss: 0.2234
2022-04-24 05:38:02 - train: epoch 0007, iter [03000, 03664], lr: 0.000100, total_loss: 0.4406, cls_loss: 0.2494, reg_loss: 0.1913
2022-04-24 05:38:44 - train: epoch 0007, iter [03100, 03664], lr: 0.000100, total_loss: 0.3928, cls_loss: 0.2218, reg_loss: 0.1709
2022-04-24 05:39:28 - train: epoch 0007, iter [03200, 03664], lr: 0.000100, total_loss: 0.4273, cls_loss: 0.2434, reg_loss: 0.1839
2022-04-24 05:40:08 - train: epoch 0007, iter [03300, 03664], lr: 0.000100, total_loss: 0.4458, cls_loss: 0.2471, reg_loss: 0.1987
2022-04-24 05:40:49 - train: epoch 0007, iter [03400, 03664], lr: 0.000100, total_loss: 0.4001, cls_loss: 0.2186, reg_loss: 0.1815
2022-04-24 05:41:34 - train: epoch 0007, iter [03500, 03664], lr: 0.000100, total_loss: 0.4326, cls_loss: 0.2465, reg_loss: 0.1861
2022-04-24 05:42:14 - train: epoch 0007, iter [03600, 03664], lr: 0.000100, total_loss: 0.4574, cls_loss: 0.2565, reg_loss: 0.2009
2022-04-24 05:42:41 - train: epoch 007, train_loss: 0.4302
2022-04-24 05:42:42 - until epoch: 007, best_metric: 26.486%
2022-04-24 05:42:42 - epoch 008 lr: 0.0001
2022-04-24 05:43:29 - train: epoch 0008, iter [00100, 03664], lr: 0.000100, total_loss: 0.4550, cls_loss: 0.2559, reg_loss: 0.1991
2022-04-24 05:44:09 - train: epoch 0008, iter [00200, 03664], lr: 0.000100, total_loss: 0.3989, cls_loss: 0.2282, reg_loss: 0.1707
2022-04-24 05:44:50 - train: epoch 0008, iter [00300, 03664], lr: 0.000100, total_loss: 0.4558, cls_loss: 0.2727, reg_loss: 0.1831
2022-04-24 05:45:30 - train: epoch 0008, iter [00400, 03664], lr: 0.000100, total_loss: 0.4169, cls_loss: 0.2308, reg_loss: 0.1861
2022-04-24 05:46:15 - train: epoch 0008, iter [00500, 03664], lr: 0.000100, total_loss: 0.4109, cls_loss: 0.2474, reg_loss: 0.1635
2022-04-24 05:46:55 - train: epoch 0008, iter [00600, 03664], lr: 0.000100, total_loss: 0.3718, cls_loss: 0.2017, reg_loss: 0.1701
2022-04-24 05:47:35 - train: epoch 0008, iter [00700, 03664], lr: 0.000100, total_loss: 0.4142, cls_loss: 0.2339, reg_loss: 0.1803
2022-04-24 05:48:19 - train: epoch 0008, iter [00800, 03664], lr: 0.000100, total_loss: 0.3988, cls_loss: 0.2353, reg_loss: 0.1635
2022-04-24 05:49:00 - train: epoch 0008, iter [00900, 03664], lr: 0.000100, total_loss: 0.4210, cls_loss: 0.2341, reg_loss: 0.1869
2022-04-24 05:49:40 - train: epoch 0008, iter [01000, 03664], lr: 0.000100, total_loss: 0.4118, cls_loss: 0.2251, reg_loss: 0.1867
2022-04-24 05:50:25 - train: epoch 0008, iter [01100, 03664], lr: 0.000100, total_loss: 0.4351, cls_loss: 0.2567, reg_loss: 0.1785
2022-04-24 05:51:06 - train: epoch 0008, iter [01200, 03664], lr: 0.000100, total_loss: 0.3980, cls_loss: 0.2396, reg_loss: 0.1584
2022-04-24 05:51:46 - train: epoch 0008, iter [01300, 03664], lr: 0.000100, total_loss: 0.4037, cls_loss: 0.2320, reg_loss: 0.1716
2022-04-24 05:52:28 - train: epoch 0008, iter [01400, 03664], lr: 0.000100, total_loss: 0.4619, cls_loss: 0.2665, reg_loss: 0.1954
2022-04-24 05:53:10 - train: epoch 0008, iter [01500, 03664], lr: 0.000100, total_loss: 0.3790, cls_loss: 0.2060, reg_loss: 0.1730
2022-04-24 05:53:51 - train: epoch 0008, iter [01600, 03664], lr: 0.000100, total_loss: 0.4107, cls_loss: 0.2255, reg_loss: 0.1852
2022-04-24 05:54:34 - train: epoch 0008, iter [01700, 03664], lr: 0.000100, total_loss: 0.4303, cls_loss: 0.2429, reg_loss: 0.1873
2022-04-24 05:55:16 - train: epoch 0008, iter [01800, 03664], lr: 0.000100, total_loss: 0.4159, cls_loss: 0.2318, reg_loss: 0.1841
2022-04-24 05:55:57 - train: epoch 0008, iter [01900, 03664], lr: 0.000100, total_loss: 0.3697, cls_loss: 0.2178, reg_loss: 0.1519
2022-04-24 05:56:39 - train: epoch 0008, iter [02000, 03664], lr: 0.000100, total_loss: 0.3924, cls_loss: 0.2205, reg_loss: 0.1720
2022-04-24 05:57:21 - train: epoch 0008, iter [02100, 03664], lr: 0.000100, total_loss: 0.4379, cls_loss: 0.2688, reg_loss: 0.1691
2022-04-24 05:58:02 - train: epoch 0008, iter [02200, 03664], lr: 0.000100, total_loss: 0.4231, cls_loss: 0.2337, reg_loss: 0.1894
2022-04-24 05:58:42 - train: epoch 0008, iter [02300, 03664], lr: 0.000100, total_loss: 0.3970, cls_loss: 0.2255, reg_loss: 0.1715
2022-04-24 05:59:24 - train: epoch 0008, iter [02400, 03664], lr: 0.000100, total_loss: 0.4071, cls_loss: 0.2223, reg_loss: 0.1848
2022-04-24 06:00:07 - train: epoch 0008, iter [02500, 03664], lr: 0.000100, total_loss: 0.4503, cls_loss: 0.2656, reg_loss: 0.1847
2022-04-24 06:00:47 - train: epoch 0008, iter [02600, 03664], lr: 0.000100, total_loss: 0.3956, cls_loss: 0.2195, reg_loss: 0.1762
2022-04-24 06:01:30 - train: epoch 0008, iter [02700, 03664], lr: 0.000100, total_loss: 0.3774, cls_loss: 0.2247, reg_loss: 0.1526
2022-04-24 06:02:12 - train: epoch 0008, iter [02800, 03664], lr: 0.000100, total_loss: 0.3846, cls_loss: 0.2118, reg_loss: 0.1728
2022-04-24 06:02:53 - train: epoch 0008, iter [02900, 03664], lr: 0.000100, total_loss: 0.4954, cls_loss: 0.2662, reg_loss: 0.2293
2022-04-24 06:03:35 - train: epoch 0008, iter [03000, 03664], lr: 0.000100, total_loss: 0.4452, cls_loss: 0.2533, reg_loss: 0.1919
2022-04-24 06:04:18 - train: epoch 0008, iter [03100, 03664], lr: 0.000100, total_loss: 0.4875, cls_loss: 0.2968, reg_loss: 0.1907
2022-04-24 06:04:58 - train: epoch 0008, iter [03200, 03664], lr: 0.000100, total_loss: 0.4482, cls_loss: 0.2658, reg_loss: 0.1824
2022-04-24 06:05:42 - train: epoch 0008, iter [03300, 03664], lr: 0.000100, total_loss: 0.4546, cls_loss: 0.2550, reg_loss: 0.1996
2022-04-24 06:06:24 - train: epoch 0008, iter [03400, 03664], lr: 0.000100, total_loss: 0.4337, cls_loss: 0.2642, reg_loss: 0.1696
2022-04-24 06:07:04 - train: epoch 0008, iter [03500, 03664], lr: 0.000100, total_loss: 0.3891, cls_loss: 0.2138, reg_loss: 0.1753
2022-04-24 06:07:44 - train: epoch 0008, iter [03600, 03664], lr: 0.000100, total_loss: 0.3837, cls_loss: 0.2123, reg_loss: 0.1714
2022-04-24 06:08:13 - train: epoch 008, train_loss: 0.4187
2022-04-24 06:12:32 - eval: epoch: 008
per_image_load_time: 2.254ms
per_image_inference_time: 42.187ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 28.954360788112645
IoU=0.50,area=all,maxDets=100,mAP: 43.96791308440285
IoU=0.75,area=all,maxDets=100,mAP: 30.91350335056202
IoU=0.50:0.95,area=small,maxDets=100,mAP: 9.939143069666233
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 33.623787609383456
IoU=0.50:0.95,area=large,maxDets=100,mAP: 44.611555559843026
IoU=0.50:0.95,area=all,maxDets=1,mAR: 25.049562648704395
IoU=0.50:0.95,area=all,maxDets=10,mAR: 37.27367750397736
IoU=0.50:0.95,area=all,maxDets=100,mAR: 38.64881581920921
IoU=0.50:0.95,area=small,maxDets=100,mAR: 12.64053279851772
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 45.479467210842984
IoU=0.50:0.95,area=large,maxDets=100,mAR: 58.34837726061611

2022-04-24 06:12:33 - until epoch: 008, best_metric: 28.954%
2022-04-24 06:12:33 - epoch 009 lr: 1e-05
2022-04-24 06:13:17 - train: epoch 0009, iter [00100, 03664], lr: 0.000010, total_loss: 0.3617, cls_loss: 0.1991, reg_loss: 0.1626
2022-04-24 06:13:57 - train: epoch 0009, iter [00200, 03664], lr: 0.000010, total_loss: 0.3597, cls_loss: 0.1944, reg_loss: 0.1654
2022-04-24 06:14:38 - train: epoch 0009, iter [00300, 03664], lr: 0.000010, total_loss: 0.4066, cls_loss: 0.2240, reg_loss: 0.1825
2022-04-24 06:15:20 - train: epoch 0009, iter [00400, 03664], lr: 0.000010, total_loss: 0.4296, cls_loss: 0.2470, reg_loss: 0.1826
2022-04-24 06:16:03 - train: epoch 0009, iter [00500, 03664], lr: 0.000010, total_loss: 0.3776, cls_loss: 0.2125, reg_loss: 0.1651
2022-04-24 06:16:43 - train: epoch 0009, iter [00600, 03664], lr: 0.000010, total_loss: 0.4135, cls_loss: 0.2229, reg_loss: 0.1906
2022-04-24 06:17:23 - train: epoch 0009, iter [00700, 03664], lr: 0.000010, total_loss: 0.4040, cls_loss: 0.2117, reg_loss: 0.1923
2022-04-24 06:18:05 - train: epoch 0009, iter [00800, 03664], lr: 0.000010, total_loss: 0.3973, cls_loss: 0.2244, reg_loss: 0.1729
2022-04-24 06:18:47 - train: epoch 0009, iter [00900, 03664], lr: 0.000010, total_loss: 0.3520, cls_loss: 0.1969, reg_loss: 0.1551
2022-04-24 06:19:28 - train: epoch 0009, iter [01000, 03664], lr: 0.000010, total_loss: 0.3837, cls_loss: 0.2011, reg_loss: 0.1825
2022-04-24 06:20:10 - train: epoch 0009, iter [01100, 03664], lr: 0.000010, total_loss: 0.4350, cls_loss: 0.2476, reg_loss: 0.1874
2022-04-24 06:20:53 - train: epoch 0009, iter [01200, 03664], lr: 0.000010, total_loss: 0.3986, cls_loss: 0.2139, reg_loss: 0.1847
2022-04-24 06:21:33 - train: epoch 0009, iter [01300, 03664], lr: 0.000010, total_loss: 0.3650, cls_loss: 0.1928, reg_loss: 0.1722
2022-04-24 06:22:15 - train: epoch 0009, iter [01400, 03664], lr: 0.000010, total_loss: 0.3960, cls_loss: 0.2021, reg_loss: 0.1939
2022-04-24 06:22:58 - train: epoch 0009, iter [01500, 03664], lr: 0.000010, total_loss: 0.3156, cls_loss: 0.1673, reg_loss: 0.1483
2022-04-24 06:23:38 - train: epoch 0009, iter [01600, 03664], lr: 0.000010, total_loss: 0.3342, cls_loss: 0.1605, reg_loss: 0.1737
2022-04-24 06:24:18 - train: epoch 0009, iter [01700, 03664], lr: 0.000010, total_loss: 0.3695, cls_loss: 0.2037, reg_loss: 0.1658
2022-04-24 06:25:02 - train: epoch 0009, iter [01800, 03664], lr: 0.000010, total_loss: 0.3121, cls_loss: 0.1629, reg_loss: 0.1492
2022-04-24 06:25:43 - train: epoch 0009, iter [01900, 03664], lr: 0.000010, total_loss: 0.3392, cls_loss: 0.1939, reg_loss: 0.1453
2022-04-24 06:26:23 - train: epoch 0009, iter [02000, 03664], lr: 0.000010, total_loss: 0.3984, cls_loss: 0.2177, reg_loss: 0.1807
2022-04-24 06:27:07 - train: epoch 0009, iter [02100, 03664], lr: 0.000010, total_loss: 0.3754, cls_loss: 0.1992, reg_loss: 0.1762
2022-04-24 06:27:48 - train: epoch 0009, iter [02200, 03664], lr: 0.000010, total_loss: 0.3731, cls_loss: 0.2077, reg_loss: 0.1654
2022-04-24 06:28:29 - train: epoch 0009, iter [02300, 03664], lr: 0.000010, total_loss: 0.3685, cls_loss: 0.1987, reg_loss: 0.1699
2022-04-24 06:29:14 - train: epoch 0009, iter [02400, 03664], lr: 0.000010, total_loss: 0.3220, cls_loss: 0.1675, reg_loss: 0.1545
2022-04-24 06:29:54 - train: epoch 0009, iter [02500, 03664], lr: 0.000010, total_loss: 0.3701, cls_loss: 0.1953, reg_loss: 0.1748
2022-04-24 06:30:34 - train: epoch 0009, iter [02600, 03664], lr: 0.000010, total_loss: 0.3525, cls_loss: 0.1832, reg_loss: 0.1693
2022-04-24 06:31:14 - train: epoch 0009, iter [02700, 03664], lr: 0.000010, total_loss: 0.3807, cls_loss: 0.2198, reg_loss: 0.1609
2022-04-24 06:31:58 - train: epoch 0009, iter [02800, 03664], lr: 0.000010, total_loss: 0.3408, cls_loss: 0.1738, reg_loss: 0.1670
2022-04-24 06:32:38 - train: epoch 0009, iter [02900, 03664], lr: 0.000010, total_loss: 0.3825, cls_loss: 0.2004, reg_loss: 0.1821
2022-04-24 06:33:19 - train: epoch 0009, iter [03000, 03664], lr: 0.000010, total_loss: 0.3621, cls_loss: 0.1975, reg_loss: 0.1646
2022-04-24 06:34:03 - train: epoch 0009, iter [03100, 03664], lr: 0.000010, total_loss: 0.3923, cls_loss: 0.2023, reg_loss: 0.1900
2022-04-24 06:34:43 - train: epoch 0009, iter [03200, 03664], lr: 0.000010, total_loss: 0.3696, cls_loss: 0.1985, reg_loss: 0.1711
2022-04-24 06:35:23 - train: epoch 0009, iter [03300, 03664], lr: 0.000010, total_loss: 0.4575, cls_loss: 0.2624, reg_loss: 0.1951
2022-04-24 06:36:07 - train: epoch 0009, iter [03400, 03664], lr: 0.000010, total_loss: 0.3231, cls_loss: 0.1793, reg_loss: 0.1438
2022-04-24 06:36:47 - train: epoch 0009, iter [03500, 03664], lr: 0.000010, total_loss: 0.4136, cls_loss: 0.2229, reg_loss: 0.1908
2022-04-24 06:37:28 - train: epoch 0009, iter [03600, 03664], lr: 0.000010, total_loss: 0.3138, cls_loss: 0.1672, reg_loss: 0.1465
2022-04-24 06:37:55 - train: epoch 009, train_loss: 0.3725
2022-04-24 06:37:55 - until epoch: 009, best_metric: 28.954%
2022-04-24 06:37:55 - epoch 010 lr: 1e-05
2022-04-24 06:38:41 - train: epoch 0010, iter [00100, 03664], lr: 0.000010, total_loss: 0.3231, cls_loss: 0.1712, reg_loss: 0.1519
2022-04-24 06:39:21 - train: epoch 0010, iter [00200, 03664], lr: 0.000010, total_loss: 0.3793, cls_loss: 0.2068, reg_loss: 0.1726
2022-04-24 06:40:01 - train: epoch 0010, iter [00300, 03664], lr: 0.000010, total_loss: 0.3872, cls_loss: 0.2057, reg_loss: 0.1815
2022-04-24 06:40:45 - train: epoch 0010, iter [00400, 03664], lr: 0.000010, total_loss: 0.3885, cls_loss: 0.2173, reg_loss: 0.1712
2022-04-24 06:41:25 - train: epoch 0010, iter [00500, 03664], lr: 0.000010, total_loss: 0.3405, cls_loss: 0.1862, reg_loss: 0.1543
2022-04-24 06:42:06 - train: epoch 0010, iter [00600, 03664], lr: 0.000010, total_loss: 0.3352, cls_loss: 0.1847, reg_loss: 0.1505
2022-04-24 06:42:48 - train: epoch 0010, iter [00700, 03664], lr: 0.000010, total_loss: 0.4030, cls_loss: 0.2240, reg_loss: 0.1790
2022-04-24 06:43:31 - train: epoch 0010, iter [00800, 03664], lr: 0.000010, total_loss: 0.3698, cls_loss: 0.2008, reg_loss: 0.1690
2022-04-24 06:44:11 - train: epoch 0010, iter [00900, 03664], lr: 0.000010, total_loss: 0.3582, cls_loss: 0.1947, reg_loss: 0.1636
2022-04-24 06:44:51 - train: epoch 0010, iter [01000, 03664], lr: 0.000010, total_loss: 0.3841, cls_loss: 0.2136, reg_loss: 0.1705
2022-04-24 06:45:35 - train: epoch 0010, iter [01100, 03664], lr: 0.000010, total_loss: 0.3046, cls_loss: 0.1407, reg_loss: 0.1639
2022-04-24 06:46:16 - train: epoch 0010, iter [01200, 03664], lr: 0.000010, total_loss: 0.3772, cls_loss: 0.1914, reg_loss: 0.1857
2022-04-24 06:46:56 - train: epoch 0010, iter [01300, 03664], lr: 0.000010, total_loss: 0.4125, cls_loss: 0.2282, reg_loss: 0.1843
2022-04-24 06:47:40 - train: epoch 0010, iter [01400, 03664], lr: 0.000010, total_loss: 0.3570, cls_loss: 0.1986, reg_loss: 0.1585
2022-04-24 06:48:21 - train: epoch 0010, iter [01500, 03664], lr: 0.000010, total_loss: 0.4027, cls_loss: 0.2165, reg_loss: 0.1862
2022-04-24 06:49:01 - train: epoch 0010, iter [01600, 03664], lr: 0.000010, total_loss: 0.3964, cls_loss: 0.2212, reg_loss: 0.1752
2022-04-24 06:49:43 - train: epoch 0010, iter [01700, 03664], lr: 0.000010, total_loss: 0.3381, cls_loss: 0.1939, reg_loss: 0.1442
2022-04-24 06:50:26 - train: epoch 0010, iter [01800, 03664], lr: 0.000010, total_loss: 0.3616, cls_loss: 0.2009, reg_loss: 0.1607
2022-04-24 06:51:06 - train: epoch 0010, iter [01900, 03664], lr: 0.000010, total_loss: 0.3200, cls_loss: 0.1698, reg_loss: 0.1502
2022-04-24 06:51:48 - train: epoch 0010, iter [02000, 03664], lr: 0.000010, total_loss: 0.3837, cls_loss: 0.2044, reg_loss: 0.1793
2022-04-24 06:52:30 - train: epoch 0010, iter [02100, 03664], lr: 0.000010, total_loss: 0.3365, cls_loss: 0.1814, reg_loss: 0.1551
2022-04-24 06:53:09 - train: epoch 0010, iter [02200, 03664], lr: 0.000010, total_loss: 0.3515, cls_loss: 0.1866, reg_loss: 0.1649
2022-04-24 06:53:50 - train: epoch 0010, iter [02300, 03664], lr: 0.000010, total_loss: 0.3499, cls_loss: 0.1790, reg_loss: 0.1709
2022-04-24 06:54:32 - train: epoch 0010, iter [02400, 03664], lr: 0.000010, total_loss: 0.4202, cls_loss: 0.2394, reg_loss: 0.1808
2022-04-24 06:55:14 - train: epoch 0010, iter [02500, 03664], lr: 0.000010, total_loss: 0.4138, cls_loss: 0.2113, reg_loss: 0.2025
2022-04-24 06:55:54 - train: epoch 0010, iter [02600, 03664], lr: 0.000010, total_loss: 0.2953, cls_loss: 0.1549, reg_loss: 0.1404
2022-04-24 06:56:37 - train: epoch 0010, iter [02700, 03664], lr: 0.000010, total_loss: 0.3579, cls_loss: 0.2014, reg_loss: 0.1565
2022-04-24 06:57:18 - train: epoch 0010, iter [02800, 03664], lr: 0.000010, total_loss: 0.3403, cls_loss: 0.1845, reg_loss: 0.1558
2022-04-24 06:57:58 - train: epoch 0010, iter [02900, 03664], lr: 0.000010, total_loss: 0.3110, cls_loss: 0.1543, reg_loss: 0.1566
2022-04-24 06:58:41 - train: epoch 0010, iter [03000, 03664], lr: 0.000010, total_loss: 0.4115, cls_loss: 0.2356, reg_loss: 0.1759
2022-04-24 06:59:21 - train: epoch 0010, iter [03100, 03664], lr: 0.000010, total_loss: 0.3389, cls_loss: 0.1842, reg_loss: 0.1547
2022-04-24 07:00:04 - train: epoch 0010, iter [03200, 03664], lr: 0.000010, total_loss: 0.3826, cls_loss: 0.2114, reg_loss: 0.1712
2022-04-24 07:00:46 - train: epoch 0010, iter [03300, 03664], lr: 0.000010, total_loss: 0.3462, cls_loss: 0.1877, reg_loss: 0.1585
2022-04-24 07:01:26 - train: epoch 0010, iter [03400, 03664], lr: 0.000010, total_loss: 0.3338, cls_loss: 0.1619, reg_loss: 0.1719
2022-04-24 07:02:09 - train: epoch 0010, iter [03500, 03664], lr: 0.000010, total_loss: 0.3236, cls_loss: 0.1795, reg_loss: 0.1441
2022-04-24 07:02:49 - train: epoch 0010, iter [03600, 03664], lr: 0.000010, total_loss: 0.3586, cls_loss: 0.2043, reg_loss: 0.1542
2022-04-24 07:03:17 - train: epoch 010, train_loss: 0.3604
2022-04-24 07:07:25 - eval: epoch: 010
per_image_load_time: 2.201ms
per_image_inference_time: 41.118ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 31.7654435321212
IoU=0.50,area=all,maxDets=100,mAP: 47.7175614259656
IoU=0.75,area=all,maxDets=100,mAP: 34.11506518324081
IoU=0.50:0.95,area=small,maxDets=100,mAP: 11.811383774144737
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 36.78405535825128
IoU=0.50:0.95,area=large,maxDets=100,mAP: 49.50580573416356
IoU=0.50:0.95,area=all,maxDets=1,mAR: 26.9416192754067
IoU=0.50:0.95,area=all,maxDets=10,mAR: 39.922369915599106
IoU=0.50:0.95,area=all,maxDets=100,mAR: 41.44702449662694
IoU=0.50:0.95,area=small,maxDets=100,mAR: 14.922253906735719
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 48.96944170703385
IoU=0.50:0.95,area=large,maxDets=100,mAR: 62.96213241233327

2022-04-24 07:07:26 - until epoch: 010, best_metric: 31.765%
2022-04-24 07:07:26 - epoch 011 lr: 1e-05
2022-04-24 07:08:07 - train: epoch 0011, iter [00100, 03664], lr: 0.000010, total_loss: 0.3258, cls_loss: 0.1705, reg_loss: 0.1553
2022-04-24 07:08:48 - train: epoch 0011, iter [00200, 03664], lr: 0.000010, total_loss: 0.3499, cls_loss: 0.1761, reg_loss: 0.1737
2022-04-24 07:09:28 - train: epoch 0011, iter [00300, 03664], lr: 0.000010, total_loss: 0.3644, cls_loss: 0.1891, reg_loss: 0.1754
2022-04-24 07:10:10 - train: epoch 0011, iter [00400, 03664], lr: 0.000010, total_loss: 0.3436, cls_loss: 0.1715, reg_loss: 0.1720
2022-04-24 07:10:52 - train: epoch 0011, iter [00500, 03664], lr: 0.000010, total_loss: 0.3919, cls_loss: 0.2211, reg_loss: 0.1708
2022-04-24 07:11:32 - train: epoch 0011, iter [00600, 03664], lr: 0.000010, total_loss: 0.3246, cls_loss: 0.1828, reg_loss: 0.1417
2022-04-24 07:12:14 - train: epoch 0011, iter [00700, 03664], lr: 0.000010, total_loss: 0.3922, cls_loss: 0.2115, reg_loss: 0.1807
2022-04-24 07:12:57 - train: epoch 0011, iter [00800, 03664], lr: 0.000010, total_loss: 0.3973, cls_loss: 0.2175, reg_loss: 0.1799
2022-04-24 07:13:38 - train: epoch 0011, iter [00900, 03664], lr: 0.000010, total_loss: 0.3278, cls_loss: 0.1653, reg_loss: 0.1624
2022-04-24 07:14:21 - train: epoch 0011, iter [01000, 03664], lr: 0.000010, total_loss: 0.3554, cls_loss: 0.1857, reg_loss: 0.1697
2022-04-24 07:15:03 - train: epoch 0011, iter [01100, 03664], lr: 0.000010, total_loss: 0.3288, cls_loss: 0.1662, reg_loss: 0.1625
2022-04-24 07:15:43 - train: epoch 0011, iter [01200, 03664], lr: 0.000010, total_loss: 0.3371, cls_loss: 0.1790, reg_loss: 0.1582
2022-04-24 07:16:25 - train: epoch 0011, iter [01300, 03664], lr: 0.000010, total_loss: 0.3111, cls_loss: 0.1604, reg_loss: 0.1508
2022-04-24 07:17:07 - train: epoch 0011, iter [01400, 03664], lr: 0.000010, total_loss: 0.3330, cls_loss: 0.1798, reg_loss: 0.1532
2022-04-24 07:17:47 - train: epoch 0011, iter [01500, 03664], lr: 0.000010, total_loss: 0.3632, cls_loss: 0.1968, reg_loss: 0.1663
2022-04-24 07:18:29 - train: epoch 0011, iter [01600, 03664], lr: 0.000010, total_loss: 0.3881, cls_loss: 0.2135, reg_loss: 0.1747
2022-04-24 07:19:10 - train: epoch 0011, iter [01700, 03664], lr: 0.000010, total_loss: 0.3402, cls_loss: 0.1798, reg_loss: 0.1604
2022-04-24 07:19:51 - train: epoch 0011, iter [01800, 03664], lr: 0.000010, total_loss: 0.3145, cls_loss: 0.1691, reg_loss: 0.1454
2022-04-24 07:20:34 - train: epoch 0011, iter [01900, 03664], lr: 0.000010, total_loss: 0.3881, cls_loss: 0.2146, reg_loss: 0.1734
2022-04-24 07:21:14 - train: epoch 0011, iter [02000, 03664], lr: 0.000010, total_loss: 0.3268, cls_loss: 0.1677, reg_loss: 0.1591
2022-04-24 07:21:56 - train: epoch 0011, iter [02100, 03664], lr: 0.000010, total_loss: 0.3320, cls_loss: 0.1654, reg_loss: 0.1665
2022-04-24 07:22:37 - train: epoch 0011, iter [02200, 03664], lr: 0.000010, total_loss: 0.3705, cls_loss: 0.1947, reg_loss: 0.1758
2022-04-24 07:23:19 - train: epoch 0011, iter [02300, 03664], lr: 0.000010, total_loss: 0.3432, cls_loss: 0.1793, reg_loss: 0.1639
2022-04-24 07:24:01 - train: epoch 0011, iter [02400, 03664], lr: 0.000010, total_loss: 0.3441, cls_loss: 0.1897, reg_loss: 0.1544
2022-04-24 07:24:41 - train: epoch 0011, iter [02500, 03664], lr: 0.000010, total_loss: 0.4036, cls_loss: 0.2213, reg_loss: 0.1823
2022-04-24 07:25:23 - train: epoch 0011, iter [02600, 03664], lr: 0.000010, total_loss: 0.3597, cls_loss: 0.1971, reg_loss: 0.1626
2022-04-24 07:26:05 - train: epoch 0011, iter [02700, 03664], lr: 0.000010, total_loss: 0.3411, cls_loss: 0.1868, reg_loss: 0.1542
2022-04-24 07:26:45 - train: epoch 0011, iter [02800, 03664], lr: 0.000010, total_loss: 0.4259, cls_loss: 0.2315, reg_loss: 0.1944
2022-04-24 07:27:27 - train: epoch 0011, iter [02900, 03664], lr: 0.000010, total_loss: 0.3945, cls_loss: 0.2227, reg_loss: 0.1718
2022-04-24 07:28:07 - train: epoch 0011, iter [03000, 03664], lr: 0.000010, total_loss: 0.3333, cls_loss: 0.1643, reg_loss: 0.1690
2022-04-24 07:28:49 - train: epoch 0011, iter [03100, 03664], lr: 0.000010, total_loss: 0.3371, cls_loss: 0.1853, reg_loss: 0.1518
2022-04-24 07:29:30 - train: epoch 0011, iter [03200, 03664], lr: 0.000010, total_loss: 0.3583, cls_loss: 0.1995, reg_loss: 0.1589
2022-04-24 07:30:12 - train: epoch 0011, iter [03300, 03664], lr: 0.000010, total_loss: 0.3864, cls_loss: 0.1912, reg_loss: 0.1952
2022-04-24 07:30:54 - train: epoch 0011, iter [03400, 03664], lr: 0.000010, total_loss: 0.3893, cls_loss: 0.2086, reg_loss: 0.1807
2022-04-24 07:31:35 - train: epoch 0011, iter [03500, 03664], lr: 0.000010, total_loss: 0.4229, cls_loss: 0.2257, reg_loss: 0.1972
2022-04-24 07:32:17 - train: epoch 0011, iter [03600, 03664], lr: 0.000010, total_loss: 0.3833, cls_loss: 0.1974, reg_loss: 0.1859
2022-04-24 07:32:43 - train: epoch 011, train_loss: 0.3545
2022-04-24 07:32:44 - until epoch: 011, best_metric: 31.765%
2022-04-24 07:32:44 - epoch 012 lr: 1e-05
2022-04-24 07:33:28 - train: epoch 0012, iter [00100, 03664], lr: 0.000010, total_loss: 0.3530, cls_loss: 0.1884, reg_loss: 0.1646
2022-04-24 07:34:09 - train: epoch 0012, iter [00200, 03664], lr: 0.000010, total_loss: 0.3549, cls_loss: 0.1887, reg_loss: 0.1662
2022-04-24 07:34:51 - train: epoch 0012, iter [00300, 03664], lr: 0.000010, total_loss: 0.3718, cls_loss: 0.1986, reg_loss: 0.1732
2022-04-24 07:35:33 - train: epoch 0012, iter [00400, 03664], lr: 0.000010, total_loss: 0.3886, cls_loss: 0.2170, reg_loss: 0.1715
2022-04-24 07:36:13 - train: epoch 0012, iter [00500, 03664], lr: 0.000010, total_loss: 0.3557, cls_loss: 0.1852, reg_loss: 0.1705
2022-04-24 07:36:56 - train: epoch 0012, iter [00600, 03664], lr: 0.000010, total_loss: 0.3334, cls_loss: 0.1861, reg_loss: 0.1473
2022-04-24 07:37:38 - train: epoch 0012, iter [00700, 03664], lr: 0.000010, total_loss: 0.3400, cls_loss: 0.1806, reg_loss: 0.1595
2022-04-24 07:38:18 - train: epoch 0012, iter [00800, 03664], lr: 0.000010, total_loss: 0.3021, cls_loss: 0.1616, reg_loss: 0.1405
2022-04-24 07:39:00 - train: epoch 0012, iter [00900, 03664], lr: 0.000010, total_loss: 0.3716, cls_loss: 0.2006, reg_loss: 0.1710
2022-04-24 07:39:41 - train: epoch 0012, iter [01000, 03664], lr: 0.000010, total_loss: 0.3502, cls_loss: 0.1880, reg_loss: 0.1622
2022-04-24 07:40:22 - train: epoch 0012, iter [01100, 03664], lr: 0.000010, total_loss: 0.3718, cls_loss: 0.1953, reg_loss: 0.1765
2022-04-24 07:41:03 - train: epoch 0012, iter [01200, 03664], lr: 0.000010, total_loss: 0.2944, cls_loss: 0.1503, reg_loss: 0.1441
2022-04-24 07:41:45 - train: epoch 0012, iter [01300, 03664], lr: 0.000010, total_loss: 0.3480, cls_loss: 0.1826, reg_loss: 0.1654
2022-04-24 07:42:27 - train: epoch 0012, iter [01400, 03664], lr: 0.000010, total_loss: 0.4162, cls_loss: 0.2262, reg_loss: 0.1900
2022-04-24 07:43:07 - train: epoch 0012, iter [01500, 03664], lr: 0.000010, total_loss: 0.2992, cls_loss: 0.1507, reg_loss: 0.1485
2022-04-24 07:43:50 - train: epoch 0012, iter [01600, 03664], lr: 0.000010, total_loss: 0.3727, cls_loss: 0.2133, reg_loss: 0.1594
2022-04-24 07:44:32 - train: epoch 0012, iter [01700, 03664], lr: 0.000010, total_loss: 0.3219, cls_loss: 0.1534, reg_loss: 0.1684
2022-04-24 07:45:12 - train: epoch 0012, iter [01800, 03664], lr: 0.000010, total_loss: 0.3870, cls_loss: 0.1986, reg_loss: 0.1884
2022-04-24 07:45:54 - train: epoch 0012, iter [01900, 03664], lr: 0.000010, total_loss: 0.2941, cls_loss: 0.1597, reg_loss: 0.1344
2022-04-24 07:46:35 - train: epoch 0012, iter [02000, 03664], lr: 0.000010, total_loss: 0.3683, cls_loss: 0.2052, reg_loss: 0.1631
2022-04-24 07:47:17 - train: epoch 0012, iter [02100, 03664], lr: 0.000010, total_loss: 0.2764, cls_loss: 0.1387, reg_loss: 0.1377
2022-04-24 07:47:57 - train: epoch 0012, iter [02200, 03664], lr: 0.000010, total_loss: 0.3675, cls_loss: 0.1901, reg_loss: 0.1774
2022-04-24 07:48:39 - train: epoch 0012, iter [02300, 03664], lr: 0.000010, total_loss: 0.3429, cls_loss: 0.1829, reg_loss: 0.1600
2022-04-24 07:49:21 - train: epoch 0012, iter [02400, 03664], lr: 0.000010, total_loss: 0.2989, cls_loss: 0.1494, reg_loss: 0.1495
2022-04-24 07:50:01 - train: epoch 0012, iter [02500, 03664], lr: 0.000010, total_loss: 0.2992, cls_loss: 0.1490, reg_loss: 0.1502
2022-04-24 07:50:43 - train: epoch 0012, iter [02600, 03664], lr: 0.000010, total_loss: 0.4267, cls_loss: 0.2311, reg_loss: 0.1956
2022-04-24 07:51:25 - train: epoch 0012, iter [02700, 03664], lr: 0.000010, total_loss: 0.3598, cls_loss: 0.1902, reg_loss: 0.1696
2022-04-24 07:52:05 - train: epoch 0012, iter [02800, 03664], lr: 0.000010, total_loss: 0.3455, cls_loss: 0.1839, reg_loss: 0.1615
2022-04-24 07:52:47 - train: epoch 0012, iter [02900, 03664], lr: 0.000010, total_loss: 0.3265, cls_loss: 0.1652, reg_loss: 0.1613
2022-04-24 07:53:27 - train: epoch 0012, iter [03000, 03664], lr: 0.000010, total_loss: 0.3408, cls_loss: 0.1781, reg_loss: 0.1627
2022-04-24 07:54:10 - train: epoch 0012, iter [03100, 03664], lr: 0.000010, total_loss: 0.3496, cls_loss: 0.1821, reg_loss: 0.1675
2022-04-24 07:54:53 - train: epoch 0012, iter [03200, 03664], lr: 0.000010, total_loss: 0.3281, cls_loss: 0.1774, reg_loss: 0.1507
2022-04-24 07:55:33 - train: epoch 0012, iter [03300, 03664], lr: 0.000010, total_loss: 0.3372, cls_loss: 0.1852, reg_loss: 0.1520
2022-04-24 07:56:15 - train: epoch 0012, iter [03400, 03664], lr: 0.000010, total_loss: 0.3535, cls_loss: 0.1886, reg_loss: 0.1650
2022-04-24 07:56:55 - train: epoch 0012, iter [03500, 03664], lr: 0.000010, total_loss: 0.3386, cls_loss: 0.1837, reg_loss: 0.1549
2022-04-24 07:57:38 - train: epoch 0012, iter [03600, 03664], lr: 0.000010, total_loss: 0.3595, cls_loss: 0.1907, reg_loss: 0.1688
2022-04-24 07:58:04 - train: epoch 012, train_loss: 0.3503
2022-04-24 08:02:15 - eval: epoch: 012
per_image_load_time: 1.821ms
per_image_inference_time: 41.978ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 31.922303735417117
IoU=0.50,area=all,maxDets=100,mAP: 47.84016108278385
IoU=0.75,area=all,maxDets=100,mAP: 34.28171974535832
IoU=0.50:0.95,area=small,maxDets=100,mAP: 11.679980347685582
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 37.00863896986328
IoU=0.50:0.95,area=large,maxDets=100,mAP: 49.41518733091216
IoU=0.50:0.95,area=all,maxDets=1,mAR: 26.99913602654616
IoU=0.50:0.95,area=all,maxDets=10,mAR: 39.89739321741914
IoU=0.50:0.95,area=all,maxDets=100,mAR: 41.412496898748095
IoU=0.50:0.95,area=small,maxDets=100,mAR: 14.957184211209986
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 48.99432049319523
IoU=0.50:0.95,area=large,maxDets=100,mAR: 62.164181059199386

2022-04-24 08:02:15 - until epoch: 012, best_metric: 31.922%
2022-04-24 08:02:15 - epoch 013 lr: 1.0000000000000002e-06
2022-04-24 08:02:57 - train: epoch 0013, iter [00100, 03664], lr: 0.000001, total_loss: 0.3384, cls_loss: 0.1767, reg_loss: 0.1617
2022-04-24 08:03:37 - train: epoch 0013, iter [00200, 03664], lr: 0.000001, total_loss: 0.3319, cls_loss: 0.1648, reg_loss: 0.1670
2022-04-24 08:04:17 - train: epoch 0013, iter [00300, 03664], lr: 0.000001, total_loss: 0.3337, cls_loss: 0.1564, reg_loss: 0.1774
2022-04-24 08:04:59 - train: epoch 0013, iter [00400, 03664], lr: 0.000001, total_loss: 0.3433, cls_loss: 0.1847, reg_loss: 0.1587
2022-04-24 08:05:40 - train: epoch 0013, iter [00500, 03664], lr: 0.000001, total_loss: 0.3059, cls_loss: 0.1591, reg_loss: 0.1468
2022-04-24 08:06:22 - train: epoch 0013, iter [00600, 03664], lr: 0.000001, total_loss: 0.3683, cls_loss: 0.2019, reg_loss: 0.1664
2022-04-24 08:07:03 - train: epoch 0013, iter [00700, 03664], lr: 0.000001, total_loss: 0.3033, cls_loss: 0.1519, reg_loss: 0.1514
2022-04-24 08:07:45 - train: epoch 0013, iter [00800, 03664], lr: 0.000001, total_loss: 0.3227, cls_loss: 0.1538, reg_loss: 0.1689
2022-04-24 08:08:28 - train: epoch 0013, iter [00900, 03664], lr: 0.000001, total_loss: 0.3270, cls_loss: 0.1720, reg_loss: 0.1550
2022-04-24 08:09:08 - train: epoch 0013, iter [01000, 03664], lr: 0.000001, total_loss: 0.3596, cls_loss: 0.1869, reg_loss: 0.1726
2022-04-24 08:09:50 - train: epoch 0013, iter [01100, 03664], lr: 0.000001, total_loss: 0.3463, cls_loss: 0.1773, reg_loss: 0.1691
2022-04-24 08:10:33 - train: epoch 0013, iter [01200, 03664], lr: 0.000001, total_loss: 0.3475, cls_loss: 0.1896, reg_loss: 0.1579
2022-04-24 08:11:14 - train: epoch 0013, iter [01300, 03664], lr: 0.000001, total_loss: 0.3411, cls_loss: 0.1869, reg_loss: 0.1543
2022-04-24 08:11:56 - train: epoch 0013, iter [01400, 03664], lr: 0.000001, total_loss: 0.3602, cls_loss: 0.1881, reg_loss: 0.1722
2022-04-24 08:12:39 - train: epoch 0013, iter [01500, 03664], lr: 0.000001, total_loss: 0.4023, cls_loss: 0.2135, reg_loss: 0.1888
2022-04-24 08:13:19 - train: epoch 0013, iter [01600, 03664], lr: 0.000001, total_loss: 0.3385, cls_loss: 0.1803, reg_loss: 0.1582
2022-04-24 08:14:01 - train: epoch 0013, iter [01700, 03664], lr: 0.000001, total_loss: 0.3323, cls_loss: 0.1760, reg_loss: 0.1563
2022-04-24 08:14:41 - train: epoch 0013, iter [01800, 03664], lr: 0.000001, total_loss: 0.3076, cls_loss: 0.1542, reg_loss: 0.1534
2022-04-24 08:15:22 - train: epoch 0013, iter [01900, 03664], lr: 0.000001, total_loss: 0.4023, cls_loss: 0.2114, reg_loss: 0.1909
2022-04-24 08:16:05 - train: epoch 0013, iter [02000, 03664], lr: 0.000001, total_loss: 0.3174, cls_loss: 0.1556, reg_loss: 0.1618
2022-04-24 08:16:45 - train: epoch 0013, iter [02100, 03664], lr: 0.000001, total_loss: 0.3664, cls_loss: 0.1984, reg_loss: 0.1680
2022-04-24 08:17:27 - train: epoch 0013, iter [02200, 03664], lr: 0.000001, total_loss: 0.3674, cls_loss: 0.2043, reg_loss: 0.1631
2022-04-24 08:18:07 - train: epoch 0013, iter [02300, 03664], lr: 0.000001, total_loss: 0.3583, cls_loss: 0.1871, reg_loss: 0.1712
2022-04-24 08:18:49 - train: epoch 0013, iter [02400, 03664], lr: 0.000001, total_loss: 0.3644, cls_loss: 0.2048, reg_loss: 0.1596
2022-04-24 08:19:31 - train: epoch 0013, iter [02500, 03664], lr: 0.000001, total_loss: 0.3363, cls_loss: 0.1799, reg_loss: 0.1564
2022-04-24 08:20:12 - train: epoch 0013, iter [02600, 03664], lr: 0.000001, total_loss: 0.3430, cls_loss: 0.1803, reg_loss: 0.1627
2022-04-24 08:20:54 - train: epoch 0013, iter [02700, 03664], lr: 0.000001, total_loss: 0.3489, cls_loss: 0.1888, reg_loss: 0.1601
2022-04-24 08:21:35 - train: epoch 0013, iter [02800, 03664], lr: 0.000001, total_loss: 0.3612, cls_loss: 0.1882, reg_loss: 0.1730
2022-04-24 08:22:17 - train: epoch 0013, iter [02900, 03664], lr: 0.000001, total_loss: 0.3063, cls_loss: 0.1583, reg_loss: 0.1480
2022-04-24 08:22:59 - train: epoch 0013, iter [03000, 03664], lr: 0.000001, total_loss: 0.3618, cls_loss: 0.1912, reg_loss: 0.1706
2022-04-24 08:23:39 - train: epoch 0013, iter [03100, 03664], lr: 0.000001, total_loss: 0.2891, cls_loss: 0.1493, reg_loss: 0.1398
2022-04-24 08:24:21 - train: epoch 0013, iter [03200, 03664], lr: 0.000001, total_loss: 0.3813, cls_loss: 0.2057, reg_loss: 0.1756
2022-04-24 08:25:03 - train: epoch 0013, iter [03300, 03664], lr: 0.000001, total_loss: 0.3347, cls_loss: 0.1780, reg_loss: 0.1567
2022-04-24 08:25:44 - train: epoch 0013, iter [03400, 03664], lr: 0.000001, total_loss: 0.4238, cls_loss: 0.2265, reg_loss: 0.1973
2022-04-24 08:26:24 - train: epoch 0013, iter [03500, 03664], lr: 0.000001, total_loss: 0.2987, cls_loss: 0.1558, reg_loss: 0.1429
2022-04-24 08:27:07 - train: epoch 0013, iter [03600, 03664], lr: 0.000001, total_loss: 0.3007, cls_loss: 0.1539, reg_loss: 0.1468
2022-04-24 08:27:35 - train: epoch 013, train_loss: 0.3434
2022-04-24 08:31:39 - eval: epoch: 013
per_image_load_time: 1.858ms
per_image_inference_time: 40.668ms
IoU=0.50:0.95,area=all,maxDets=100,mAP: 32.07342075646459
IoU=0.50,area=all,maxDets=100,mAP: 48.15000279376302
IoU=0.75,area=all,maxDets=100,mAP: 34.395942673362086
IoU=0.50:0.95,area=small,maxDets=100,mAP: 11.860813537653344
IoU=0.50:0.95,area=medium,maxDets=100,mAP: 37.279482431232125
IoU=0.50:0.95,area=large,maxDets=100,mAP: 49.62769309023207
IoU=0.50:0.95,area=all,maxDets=1,mAR: 27.120219748713737
IoU=0.50:0.95,area=all,maxDets=10,mAR: 39.975185062337324
IoU=0.50:0.95,area=all,maxDets=100,mAR: 41.49456861458755
IoU=0.50:0.95,area=small,maxDets=100,mAR: 14.999783820569796
IoU=0.50:0.95,area=medium,maxDets=100,mAR: 49.024446155647226
IoU=0.50:0.95,area=large,maxDets=100,mAR: 62.49445068869605

2022-04-24 08:31:39 - until epoch: 013, best_metric: 32.073%
2022-04-24 08:31:39 - train done. model: resnet50_retinanet, train time: 6.002 hours, best_metric: 32.073%
