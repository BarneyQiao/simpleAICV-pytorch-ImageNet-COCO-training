2022-04-30 16:01:19 - network: resnet50_fcos
2022-04-30 16:01:19 - num_classes: 20
2022-04-30 16:01:19 - input_image_size: [400, 667]
2022-04-30 16:01:19 - backbone_pretrained_path: /root/code/simpleAICV-pytorch-ImageNet-COCO-training/pretrained_models/resnet/resnet50-acc76.322.pth
2022-04-30 16:01:19 - trained_model_path: 
2022-04-30 16:01:19 - criterion: FCOSLoss()
2022-04-30 16:01:19 - decoder: <simpleAICV.detection.decode.FCOSDecoder object at 0x7fba2c21fd30>
2022-04-30 16:01:19 - train_dataset: <simpleAICV.detection.datasets.vocdataset.VocDetection object at 0x7fba2c227100>
2022-04-30 16:01:19 - val_dataset: <simpleAICV.detection.datasets.vocdataset.VocDetection object at 0x7fba2c2271f0>
2022-04-30 16:01:19 - collater: <simpleAICV.detection.common.DetectionCollater object at 0x7fba2c227190>
2022-04-30 16:01:19 - seed: 0
2022-04-30 16:01:19 - batch_size: 32
2022-04-30 16:01:19 - num_workers: 4
2022-04-30 16:01:19 - optimizer: ('AdamW', {'lr': 0.0001, 'weight_decay': 0.001})
2022-04-30 16:01:19 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [8, 12]})
2022-04-30 16:01:19 - epochs: 13
2022-04-30 16:01:19 - eval_epoch: [1, 3, 5, 8, 10, 12, 13]
2022-04-30 16:01:19 - print_interval: 100
2022-04-30 16:01:19 - eval_type: VOC
2022-04-30 16:01:19 - eval_voc_iou_threshold_list: [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]
2022-04-30 16:01:19 - save_model_metric: IoU=0.50,area=all,maxDets=100,mAP
2022-04-30 16:01:19 - sync_bn: False
2022-04-30 16:01:19 - apex: True
2022-04-30 16:01:19 - gpus_type: NVIDIA RTX A5000
2022-04-30 16:01:19 - gpus_num: 2
2022-04-30 16:01:19 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7fba26122eb0>
2022-04-30 16:01:19 - --------------------parameters--------------------
2022-04-30 16:01:19 - name: scales, grad: True
2022-04-30 16:01:19 - name: backbone.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.0.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.0.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.0.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.0.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.0.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.0.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.0.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.0.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.0.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.0.downsample_conv.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.0.downsample_conv.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.0.downsample_conv.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.1.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.1.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.1.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.1.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.1.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.1.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.1.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.1.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.1.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.2.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.2.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.2.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.2.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.2.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.2.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.2.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.2.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer1.2.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.0.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.0.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.0.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.0.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.0.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.0.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.0.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.0.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.0.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.0.downsample_conv.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.0.downsample_conv.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.0.downsample_conv.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.1.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.1.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.1.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.1.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.1.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.1.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.1.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.1.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.1.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.2.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.2.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.2.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.2.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.2.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.2.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.2.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.2.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.2.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.3.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.3.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.3.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.3.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.3.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.3.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.3.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.3.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer2.3.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.0.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.0.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.0.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.0.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.0.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.0.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.0.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.0.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.0.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.0.downsample_conv.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.0.downsample_conv.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.0.downsample_conv.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.1.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.1.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.1.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.1.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.1.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.1.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.1.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.1.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.1.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.2.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.2.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.2.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.2.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.2.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.2.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.2.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.2.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.2.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.3.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.3.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.3.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.3.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.3.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.3.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.3.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.3.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.3.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.4.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.4.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.4.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.4.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.4.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.4.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.4.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.4.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.4.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.5.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.5.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.5.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.5.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.5.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.5.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.5.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.5.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer3.5.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.0.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.0.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.0.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.0.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.0.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.0.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.0.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.0.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.0.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.0.downsample_conv.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.0.downsample_conv.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.0.downsample_conv.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.1.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.1.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.1.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.1.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.1.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.1.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.1.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.1.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.1.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.2.conv1.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.2.conv1.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.2.conv1.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.2.conv2.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.2.conv2.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.2.conv2.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.2.conv3.layer.0.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.2.conv3.layer.1.weight, grad: True
2022-04-30 16:01:19 - name: backbone.layer4.2.conv3.layer.1.bias, grad: True
2022-04-30 16:01:19 - name: fpn.P3_1.weight, grad: True
2022-04-30 16:01:19 - name: fpn.P3_1.bias, grad: True
2022-04-30 16:01:19 - name: fpn.P3_2.weight, grad: True
2022-04-30 16:01:19 - name: fpn.P3_2.bias, grad: True
2022-04-30 16:01:19 - name: fpn.P4_1.weight, grad: True
2022-04-30 16:01:19 - name: fpn.P4_1.bias, grad: True
2022-04-30 16:01:19 - name: fpn.P4_2.weight, grad: True
2022-04-30 16:01:19 - name: fpn.P4_2.bias, grad: True
2022-04-30 16:01:19 - name: fpn.P5_1.weight, grad: True
2022-04-30 16:01:19 - name: fpn.P5_1.bias, grad: True
2022-04-30 16:01:19 - name: fpn.P5_2.weight, grad: True
2022-04-30 16:01:19 - name: fpn.P5_2.bias, grad: True
2022-04-30 16:01:19 - name: fpn.P6.weight, grad: True
2022-04-30 16:01:19 - name: fpn.P6.bias, grad: True
2022-04-30 16:01:19 - name: fpn.P7.1.weight, grad: True
2022-04-30 16:01:19 - name: fpn.P7.1.bias, grad: True
2022-04-30 16:01:19 - name: clsregcnt_head.cls_head.0.weight, grad: True
2022-04-30 16:01:19 - name: clsregcnt_head.cls_head.1.weight, grad: True
2022-04-30 16:01:19 - name: clsregcnt_head.cls_head.1.bias, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.cls_head.3.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.cls_head.4.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.cls_head.4.bias, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.cls_head.6.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.cls_head.7.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.cls_head.7.bias, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.cls_head.9.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.cls_head.10.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.cls_head.10.bias, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.reg_head.0.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.reg_head.1.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.reg_head.1.bias, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.reg_head.3.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.reg_head.4.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.reg_head.4.bias, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.reg_head.6.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.reg_head.7.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.reg_head.7.bias, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.reg_head.9.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.reg_head.10.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.reg_head.10.bias, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.cls_out.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.cls_out.bias, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.reg_out.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.reg_out.bias, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.center_out.weight, grad: True
2022-04-30 16:01:20 - name: clsregcnt_head.center_out.bias, grad: True
2022-04-30 16:01:20 - --------------------buffers--------------------
2022-04-30 16:01:20 - name: backbone.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.0.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.0.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.0.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.0.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.0.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.0.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.0.downsample_conv.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.1.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.1.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.1.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.1.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.1.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.1.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.2.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.2.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.2.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.2.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.2.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.2.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer1.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.0.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.0.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.0.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.0.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.0.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.0.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.1.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.1.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.1.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.1.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.1.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.1.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.2.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.2.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.2.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.2.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.2.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.2.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.3.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.3.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.3.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.3.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.3.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.3.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer2.3.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.0.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.0.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.0.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.0.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.0.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.0.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.1.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.1.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.1.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.1.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.1.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.1.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.2.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.2.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.2.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.2.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.2.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.2.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.3.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.3.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.3.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.3.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.3.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.3.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.3.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.4.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.4.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.4.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.4.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.4.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.4.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.4.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.5.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.5.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.5.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.5.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.5.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.5.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer3.5.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.0.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.0.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.0.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.0.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.0.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.0.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.1.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.1.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.1.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.1.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.1.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.1.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.2.conv1.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.2.conv1.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.2.conv2.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.2.conv2.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.2.conv3.layer.1.running_mean, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.2.conv3.layer.1.running_var, grad: False
2022-04-30 16:01:20 - name: backbone.layer4.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 16:01:20 - epoch 001 lr: 0.0001
2022-04-30 16:01:58 - train: epoch 0001, iter [00100, 00517], lr: 0.000100, total_loss: 1.3983, cls_loss: 0.4996, reg_loss: 0.2709, center_ness_loss: 0.6278
2022-04-30 16:02:36 - train: epoch 0001, iter [00200, 00517], lr: 0.000100, total_loss: 1.2155, cls_loss: 0.3803, reg_loss: 0.2331, center_ness_loss: 0.6022
2022-04-30 16:03:15 - train: epoch 0001, iter [00300, 00517], lr: 0.000100, total_loss: 1.1687, cls_loss: 0.3427, reg_loss: 0.2229, center_ness_loss: 0.6032
2022-04-30 16:03:53 - train: epoch 0001, iter [00400, 00517], lr: 0.000100, total_loss: 1.1395, cls_loss: 0.3322, reg_loss: 0.2024, center_ness_loss: 0.6049
2022-04-30 16:04:31 - train: epoch 0001, iter [00500, 00517], lr: 0.000100, total_loss: 1.1327, cls_loss: 0.3261, reg_loss: 0.2027, center_ness_loss: 0.6039
2022-04-30 16:04:37 - train: epoch 001, train_loss: 1.3141
2022-04-30 16:10:56 - eval: epoch: 001
per_image_load_time: 1.772ms
per_image_inference_time: 18.640ms
IoU=0.50,area=all,maxDets=100,mAP: 47.125972865426654
IoU=0.55,area=all,maxDets=100,mAP: 43.009671406647456
IoU=0.60,area=all,maxDets=100,mAP: 38.27893026678745
IoU=0.65,area=all,maxDets=100,mAP: 31.019717671876514
IoU=0.70,area=all,maxDets=100,mAP: 21.769860425103747
IoU=0.75,area=all,maxDets=100,mAP: 12.011475391974475
IoU=0.80,area=all,maxDets=100,mAP: 4.264842790086726
IoU=0.85,area=all,maxDets=100,mAP: 0.8860558510843404
IoU=0.90,area=all,maxDets=100,mAP: 0.14484722980767736
IoU=0.95,area=all,maxDets=100,mAP: 0.0046605687500796255
IoU=0.50,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 52.01931897502538), (1, 63.8216780954199), (2, 51.565190575515786), (3, 38.388999185297614), (4, 29.76683873842669), (5, 63.89176158139105), (6, 69.22000588521257), (7, 70.88401215949042), (8, 32.87610923840331), (9, 1.1362342850750404), (10, 47.01036016028033), (11, 54.625045137403404), (12, 19.873449120363382), (13, 47.148869008491026), (14, 63.21380215330689), (15, 25.46862790037987), (16, 33.52642188525044), (17, 56.778350031949486), (18, 57.91792311870607), (19, 63.386460073144505)])
IoU=0.55,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 47.34567298685419), (1, 57.52030354622112), (2, 47.84288160614234), (3, 28.53315595866992), (4, 25.479076536298393), (5, 58.25333866388601), (6, 66.02512056233634), (7, 66.94877768786607), (8, 29.143955998317384), (9, 0.8829747446197418), (10, 41.73939326151366), (11, 50.19469554324072), (12, 15.542694773206561), (13, 42.77605275410613), (14, 57.57348003834617), (15, 22.754091236120047), (16, 32.1986453251327), (17, 54.298245736530305), (18, 54.192733822360815), (19, 60.94813735118056)])
IoU=0.60,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 40.76157021406108), (1, 52.9688682510699), (2, 42.29672772290207), (3, 24.107858190514523), (4, 20.873223288485175), (5, 55.54105467992385), (6, 60.691838400219375), (7, 61.52009369149161), (8, 25.70127294877686), (9, 0.7650273224043717), (10, 36.52397735201296), (11, 45.41996584468009), (12, 11.009911467524395), (13, 35.754931984599985), (14, 48.34832186043127), (15, 19.096117795752182), (16, 28.191965448844847), (17, 52.97856866738066), (18, 47.051564247898405), (19, 55.975745956775484)])
IoU=0.65,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 29.626908730072), (1, 40.51800176277671), (2, 33.38736574045049), (3, 19.162007053425402), (4, 14.372371513252341), (5, 50.423983896131666), (6, 53.20943801135374), (7, 52.43132701477591), (8, 18.93790704431796), (9, 0.7650273224043717), (10, 29.73859932204456), (11, 35.833741345345416), (12, 7.967574847779654), (13, 28.183291190635256), (14, 37.66673285410749), (15, 12.623863166266357), (16, 25.816499445719863), (17, 45.938474851136455), (18, 35.12128257491792), (19, 48.66995575061684)])
IoU=0.70,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 22.260343630105282), (1, 24.595931510271633), (2, 18.009390939478703), (3, 12.58776597289281), (4, 8.794406642894204), (5, 37.0426815744875), (6, 42.317962283171504), (7, 37.769324735034395), (8, 13.352259338362446), (9, 0.5737704918032788), (10, 23.002315047676507), (11, 23.29937052417579), (12, 4.551172912230738), (13, 21.64676846463522), (14, 25.050755460619044), (15, 7.866386696014763), (16, 20.486475964140848), (17, 36.88062968802455), (18, 20.54901232430522), (19, 34.76048430175046)])
IoU=0.75,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 10.766296800524819), (1, 14.358383616490464), (2, 7.861802484871023), (3, 6.173339062822734), (4, 4.231824558560617), (5, 26.44303515472067), (6, 25.506588717985622), (7, 21.357490819397523), (8, 6.15056425248965), (9, 0.4098360655737705), (10, 12.477023263177221), (11, 11.798088070071856), (12, 1.4398523027701509), (13, 11.27931837308036), (14, 12.734959229263653), (15, 3.492251490584676), (16, 12.068500696709359), (17, 21.058775082500823), (18, 8.046012419293254), (19, 22.57556537860123)])
IoU=0.80,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 3.17476741766535), (1, 2.489313244833371), (2, 2.416592561930799), (3, 2.6848874148084265), (4, 0.8743104933315506), (5, 13.120786195403644), (6, 9.758286559475874), (7, 8.241751388234723), (8, 2.0952195825255195), (9, 0.0), (10, 5.04026633788609), (11, 3.69224480812988), (12, 0.4256702627461949), (13, 3.676847139597883), (14, 4.145207828676681), (15, 1.1395943766195227), (16, 5.558729775396535), (17, 6.724659209913744), (18, 1.5312072957771778), (19, 8.506513908781553)])
IoU=0.85,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 0.32508250896079216), (1, 0.5083023165830687), (2, 0.7326343321398422), (3, 0.05720782736757681), (4, 0.21172594145492585), (5, 1.9001585262308052), (6, 1.818953334974153), (7, 1.3851698926202423), (8, 0.7999437134731278), (9, 0.0), (10, 1.1726435250402425), (11, 0.6645235134735261), (12, 0.11128340302568977), (13, 0.5802047206814144), (14, 0.7652673604734219), (15, 0.3006136211071754), (16, 1.7355728536921502), (17, 2.227591504532141), (18, 0.1002635791271514), (19, 2.323974546729362)])
IoU=0.90,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 0.010170353419781338), (1, 0.03607117534246979), (2, 0.05036209307743249), (3, 0.010863661053775122), (4, 0.016130382803748497), (5, 0.5844970633703028), (6, 0.09473339129830657), (7, 0.07527015810014401), (8, 0.18507709602482164), (9, 0.0), (10, 0.32605654821942043), (11, 0.048891182437976244), (12, 0.003420908593322386), (13, 0.08418134733924207), (14, 0.0596626534532725), (15, 0.007778522790872373), (16, 0.16212043400537818), (17, 0.7277376081092418), (18, 0.003517269215245344), (19, 0.4104027474987939)])
IoU=0.95,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 0.0), (1, 0.0), (2, 0.0022694262890341323), (3, 0.0), (4, 0.000559631538594989), (5, 0.050754980332445125), (6, 0.0008910529374550143), (7, 0.004161817304642485), (8, 0.00031123560535325237), (9, 0.0), (10, 0.0001457330811179476), (11, 0.0), (12, 0.0), (13, 0.0), (14, 0.00032541126392382936), (15, 0.0005541341574627622), (16, 0.0), (17, 0.026994196247806718), (18, 0.0), (19, 0.006243756243756245)])

2022-04-30 16:10:57 - until epoch: 001, best_metric: 47.126%
2022-04-30 16:10:57 - epoch 002 lr: 0.0001
2022-04-30 16:11:35 - train: epoch 0002, iter [00100, 00517], lr: 0.000100, total_loss: 1.1820, cls_loss: 0.3788, reg_loss: 0.1921, center_ness_loss: 0.6111
2022-04-30 16:12:13 - train: epoch 0002, iter [00200, 00517], lr: 0.000100, total_loss: 1.1059, cls_loss: 0.3152, reg_loss: 0.1827, center_ness_loss: 0.6080
2022-04-30 16:12:50 - train: epoch 0002, iter [00300, 00517], lr: 0.000100, total_loss: 1.1246, cls_loss: 0.3157, reg_loss: 0.1986, center_ness_loss: 0.6103
2022-04-30 16:13:28 - train: epoch 0002, iter [00400, 00517], lr: 0.000100, total_loss: 1.1075, cls_loss: 0.2954, reg_loss: 0.2039, center_ness_loss: 0.6082
2022-04-30 16:14:07 - train: epoch 0002, iter [00500, 00517], lr: 0.000100, total_loss: 1.0689, cls_loss: 0.3010, reg_loss: 0.1723, center_ness_loss: 0.5956
2022-04-30 16:14:13 - train: epoch 002, train_loss: 1.1198
2022-04-30 16:14:14 - until epoch: 002, best_metric: 47.126%
2022-04-30 16:14:14 - epoch 003 lr: 0.0001
2022-04-30 16:14:53 - train: epoch 0003, iter [00100, 00517], lr: 0.000100, total_loss: 1.1128, cls_loss: 0.3131, reg_loss: 0.1930, center_ness_loss: 0.6066
2022-04-30 16:15:30 - train: epoch 0003, iter [00200, 00517], lr: 0.000100, total_loss: 1.0571, cls_loss: 0.2960, reg_loss: 0.1659, center_ness_loss: 0.5952
2022-04-30 16:16:08 - train: epoch 0003, iter [00300, 00517], lr: 0.000100, total_loss: 1.0314, cls_loss: 0.2650, reg_loss: 0.1640, center_ness_loss: 0.6024
2022-04-30 16:16:45 - train: epoch 0003, iter [00400, 00517], lr: 0.000100, total_loss: 1.0861, cls_loss: 0.2984, reg_loss: 0.1820, center_ness_loss: 0.6057
2022-04-30 16:17:22 - train: epoch 0003, iter [00500, 00517], lr: 0.000100, total_loss: 1.0241, cls_loss: 0.2468, reg_loss: 0.1739, center_ness_loss: 0.6033
2022-04-30 16:17:29 - train: epoch 003, train_loss: 1.0596
2022-04-30 16:23:37 - eval: epoch: 003
per_image_load_time: 1.921ms
per_image_inference_time: 16.246ms
IoU=0.50,area=all,maxDets=100,mAP: 66.0661890626343
IoU=0.55,area=all,maxDets=100,mAP: 62.92315959004161
IoU=0.60,area=all,maxDets=100,mAP: 58.18740605519529
IoU=0.65,area=all,maxDets=100,mAP: 51.64230161716976
IoU=0.70,area=all,maxDets=100,mAP: 42.50737434016667
IoU=0.75,area=all,maxDets=100,mAP: 31.212751021137954
IoU=0.80,area=all,maxDets=100,mAP: 18.66967290494942
IoU=0.85,area=all,maxDets=100,mAP: 7.471356258280485
IoU=0.90,area=all,maxDets=100,mAP: 1.8227977691061787
IoU=0.95,area=all,maxDets=100,mAP: 0.27945086787946904
IoU=0.50,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 73.91110595511947), (1, 75.97980134736216), (2, 66.2975023168858), (3, 53.30809678769063), (4, 53.62053545301051), (5, 77.20516694515153), (6, 81.88995353228825), (7, 81.32773635727389), (8, 45.044586710744184), (9, 62.13372592401672), (10, 55.62410490619012), (11, 77.74868264823587), (12, 76.31009709657974), (13, 68.62992363646858), (14, 78.5979511217194), (15, 37.77943760853875), (16, 63.57510929992556), (17, 57.66567976794621), (18, 62.66001721749453), (19, 72.01456662004423)])
IoU=0.55,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 69.80839712396502), (1, 72.54260035749643), (2, 61.895447735991006), (3, 47.74989293637183), (4, 51.49341763748069), (5, 75.07100666799937), (6, 79.66207848534803), (7, 78.20405893067829), (8, 41.62344736877274), (9, 59.21422544536139), (10, 53.60414400961003), (11, 75.80432525032418), (12, 72.71412889056528), (13, 66.79025042421864), (14, 74.57293988016932), (15, 33.77822602589439), (16, 60.96542286885717), (17, 55.84100731669207), (18, 55.83003565083033), (19, 71.29813879420598)])
IoU=0.60,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 65.35972816623372), (1, 66.8526874511765), (2, 56.39007641377886), (3, 35.15413189676296), (4, 47.25988354129028), (5, 71.70170954577945), (6, 75.54100857867793), (7, 73.86489513123878), (8, 37.078302126791236), (9, 56.197361730264085), (10, 51.092881392354315), (11, 71.99815856639881), (12, 65.5828991135826), (13, 63.60510949367839), (14, 67.97436810724919), (15, 28.37451762156487), (16, 58.15170351164225), (17, 53.076889687329796), (18, 50.248561532565496), (19, 68.2432474955462)])
IoU=0.65,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 55.238380237170716), (1, 62.15412728738391), (2, 50.05634572635474), (3, 26.64154958512138), (4, 40.30289079802899), (5, 66.54622059703745), (6, 70.53360215112055), (7, 64.37059600696212), (8, 30.66499649770986), (9, 52.723116373802995), (10, 45.77087654343943), (11, 66.38411335063317), (12, 57.743845263969696), (13, 58.83014662170664), (14, 57.483135195201605), (15, 21.982109231619297), (16, 50.49243779618132), (17, 49.33485730401049), (18, 42.33797009418975), (19, 63.254715681751165)])
IoU=0.70,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 45.173558194592175), (1, 52.172510365198974), (2, 37.7562108734819), (3, 18.90347445766922), (4, 31.570812327582843), (5, 59.375136425106554), (6, 59.2570529594886), (7, 53.76387351674457), (8, 22.81169014112544), (9, 46.140755561973116), (10, 40.80060846243968), (11, 56.62444937175077), (12, 40.857634835634485), (13, 53.182785349989516), (14, 44.638987481812954), (15, 16.166984600763325), (16, 45.795842698627325), (17, 39.94213260546092), (18, 28.048932389863662), (19, 57.1640541840275)])
IoU=0.75,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 31.600941707148433), (1, 39.94530920052174), (2, 25.11093010575941), (3, 11.948738613729578), (4, 21.18620259539691), (5, 45.9620456986799), (6, 44.562884036611635), (7, 32.71787139177172), (8, 14.548800475409674), (9, 35.99174944499512), (10, 33.718591451951575), (11, 42.776198221757475), (12, 27.923589598742815), (13, 38.07000468589353), (14, 31.365694045358193), (15, 9.360852504167053), (16, 36.88909827532834), (17, 33.65150902387046), (18, 18.720935830692163), (19, 48.20307351497346)])
IoU=0.80,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 20.266201155906373), (1, 21.911340088457454), (2, 16.420880089755112), (3, 5.345712825804039), (4, 9.125855643457374), (5, 23.1186934847636), (6, 25.303379593029153), (7, 19.382217258079265), (8, 7.833679813683982), (9, 23.954097395602748), (10, 24.556029733942808), (11, 26.410261834370797), (12, 13.724469286103226), (13, 20.906700598384663), (14, 16.716238444870942), (15, 5.092285144548622), (16, 23.755454153498146), (17, 23.661180309562567), (18, 12.837688994943692), (19, 33.071092250223906)])
IoU=0.85,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 6.632206148229125), (1, 8.53515442108006), (2, 5.411404075905405), (3, 2.1905476618588597), (4, 1.8879823668387308), (5, 7.604445668920112), (6, 8.226062524223792), (7, 9.81251684139346), (8, 2.323667993850136), (9, 8.404591222239391), (10, 17.19013196637535), (11, 9.626145414140439), (12, 5.115972043033967), (13, 9.592071287183163), (14, 6.501867915757718), (15, 1.3992728446225462), (16, 11.2810176298829), (17, 10.217867570006632), (18, 4.236477048590429), (19, 13.2377225214775)])
IoU=0.90,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 1.5300410959808168), (1, 1.7005595967517364), (2, 0.7941460854482024), (3, 0.40176654278763335), (4, 0.24842791648247664), (5, 1.0797232239377395), (6, 1.4157056118488978), (7, 3.1316384849076653), (8, 0.5715015215655709), (9, 1.4954004697879155), (10, 9.885619926120356), (11, 2.191095377572739), (12, 0.7116285373997002), (13, 1.6778252666009206), (14, 1.2282019480999746), (15, 0.1805500516273467), (16, 2.5122779594344293), (17, 2.1456418662085786), (18, 1.828947053054026), (19, 1.7252568465068534)])
IoU=0.95,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 0.08243564188472793), (1, 0.3223081751133645), (2, 0.011935482712019782), (3, 0.07790236774761247), (4, 0.0015229972586049345), (5, 0.15031710732229636), (6, 0.06122801788782559), (7, 0.35535392784650555), (8, 0.0021262661202265183), (9, 0.09236291597875268), (10, 3.1924769197920875), (11, 0.1796668506384097), (12, 0.05190174189832776), (13, 0.022258592471358432), (14, 0.06177948159744374), (15, 0.005731922398589064), (16, 0.4132231404958678), (17, 0.25761016916620505), (18, 0.23557335813590197), (19, 0.011302281123252992)])

2022-04-30 16:23:38 - until epoch: 003, best_metric: 66.066%
2022-04-30 16:23:38 - epoch 004 lr: 0.0001
2022-04-30 16:24:16 - train: epoch 0004, iter [00100, 00517], lr: 0.000100, total_loss: 0.9931, cls_loss: 0.2422, reg_loss: 0.1568, center_ness_loss: 0.5941
2022-04-30 16:24:54 - train: epoch 0004, iter [00200, 00517], lr: 0.000100, total_loss: 0.9899, cls_loss: 0.2291, reg_loss: 0.1562, center_ness_loss: 0.6046
2022-04-30 16:25:31 - train: epoch 0004, iter [00300, 00517], lr: 0.000100, total_loss: 1.0251, cls_loss: 0.2763, reg_loss: 0.1557, center_ness_loss: 0.5931
2022-04-30 16:26:09 - train: epoch 0004, iter [00400, 00517], lr: 0.000100, total_loss: 0.9815, cls_loss: 0.2472, reg_loss: 0.1430, center_ness_loss: 0.5913
2022-04-30 16:26:47 - train: epoch 0004, iter [00500, 00517], lr: 0.000100, total_loss: 0.9354, cls_loss: 0.2041, reg_loss: 0.1361, center_ness_loss: 0.5952
2022-04-30 16:26:53 - train: epoch 004, train_loss: 1.0208
2022-04-30 16:26:54 - until epoch: 004, best_metric: 66.066%
2022-04-30 16:26:54 - epoch 005 lr: 0.0001
2022-04-30 16:27:32 - train: epoch 0005, iter [00100, 00517], lr: 0.000100, total_loss: 1.0466, cls_loss: 0.2871, reg_loss: 0.1624, center_ness_loss: 0.5971
2022-04-30 16:28:10 - train: epoch 0005, iter [00200, 00517], lr: 0.000100, total_loss: 0.9902, cls_loss: 0.2433, reg_loss: 0.1570, center_ness_loss: 0.5900
2022-04-30 16:28:47 - train: epoch 0005, iter [00300, 00517], lr: 0.000100, total_loss: 0.9463, cls_loss: 0.2185, reg_loss: 0.1338, center_ness_loss: 0.5940
2022-04-30 16:29:24 - train: epoch 0005, iter [00400, 00517], lr: 0.000100, total_loss: 0.9664, cls_loss: 0.2254, reg_loss: 0.1373, center_ness_loss: 0.6036
2022-04-30 16:30:02 - train: epoch 0005, iter [00500, 00517], lr: 0.000100, total_loss: 1.0056, cls_loss: 0.2434, reg_loss: 0.1526, center_ness_loss: 0.6096
2022-04-30 16:30:09 - train: epoch 005, train_loss: 0.9930
2022-04-30 16:36:16 - eval: epoch: 005
per_image_load_time: 1.882ms
per_image_inference_time: 16.271ms
IoU=0.50,area=all,maxDets=100,mAP: 69.6576683972315
IoU=0.55,area=all,maxDets=100,mAP: 67.12225687487783
IoU=0.60,area=all,maxDets=100,mAP: 63.88725750456746
IoU=0.65,area=all,maxDets=100,mAP: 58.91724980186693
IoU=0.70,area=all,maxDets=100,mAP: 51.42765365559508
IoU=0.75,area=all,maxDets=100,mAP: 40.462064843948795
IoU=0.80,area=all,maxDets=100,mAP: 28.47527470602187
IoU=0.85,area=all,maxDets=100,mAP: 14.227807290004282
IoU=0.90,area=all,maxDets=100,mAP: 2.892268921505767
IoU=0.95,area=all,maxDets=100,mAP: 0.06794026016444663
IoU=0.50,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 73.43902938336652), (1, 79.27455287270955), (2, 70.78236461126721), (3, 49.6350353484607), (4, 59.621791282865864), (5, 77.39340743220924), (6, 84.57026274361444), (7, 84.59680098045581), (8, 50.745451355630166), (9, 59.29325029226027), (10, 66.72384902678054), (11, 82.51936716600129), (12, 76.45081031049902), (13, 72.37585531981674), (14, 81.18137659749746), (15, 47.68058861959975), (16, 70.00718014171012), (17, 60.114085940108886), (18, 75.72962998651795), (19, 71.01867853325872)])
IoU=0.55,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 70.47309131821831), (1, 76.11956501151053), (2, 67.33197876803048), (3, 46.16756336922781), (4, 55.51027597962418), (5, 76.4433245479043), (6, 82.16087652109437), (7, 83.10413935698651), (8, 47.76156232995202), (9, 57.6036766400017), (10, 62.859957488222484), (11, 80.15058528295445), (12, 74.24040289771506), (13, 69.68856546249245), (14, 77.62914574401316), (15, 42.786143969399006), (16, 68.876627238079), (17, 59.125814679935694), (18, 73.63593715605091), (19, 70.7759037361443)])
IoU=0.60,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 66.27043427749648), (1, 73.40152582261649), (2, 63.435391350710205), (3, 42.864579728893645), (4, 52.192921889144195), (5, 74.23688528852523), (6, 78.86297039946348), (7, 80.11042978059463), (8, 42.78696842942152), (9, 55.17084227420146), (10, 59.88509635654191), (11, 76.93978488906293), (12, 70.96367585091241), (13, 67.18701639033642), (14, 71.93468239419956), (15, 39.16958835584891), (16, 65.96580387906253), (17, 57.52141418738586), (18, 69.06848744951503), (19, 69.77665109741636)])
IoU=0.65,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 60.67012204053811), (1, 66.52627726578856), (2, 58.21552487890189), (3, 36.201130770320454), (4, 45.51982497652545), (5, 70.70875326587513), (6, 73.74681938260146), (7, 75.22309785893182), (8, 39.001847344860415), (9, 51.15684291752718), (10, 55.8172400561663), (11, 70.70912711430587), (12, 66.50338739845525), (13, 60.95162157264985), (14, 63.11639669854685), (15, 35.44089250789614), (16, 63.56413665761945), (17, 56.149066414383405), (18, 63.411114010730074), (19, 65.71177290471529)])
IoU=0.70,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 52.6119365523317), (1, 59.32570458074791), (2, 49.70120110656181), (3, 31.008388234507496), (4, 35.22035510160728), (5, 66.99054981362976), (6, 67.94542354816598), (7, 65.88973099495578), (8, 32.132951182732725), (9, 47.73563011627291), (10, 47.27560033795784), (11, 63.4476724591007), (12, 53.29554318351999), (13, 51.56471652482144), (14, 50.964362386894), (15, 26.93079869303661), (16, 58.42801779575906), (17, 52.538847462171745), (18, 53.340256969165665), (19, 62.20538606796128)])
IoU=0.75,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 38.973619348899255), (1, 48.89158052844338), (2, 36.977565824393466), (3, 21.918930313358054), (4, 21.412857723889914), (5, 62.33119469924889), (6, 58.79080456972625), (7, 50.289565754096756), (8, 23.141333670282382), (9, 41.05361480936003), (10, 36.50902744610553), (11, 50.15701523537497), (12, 39.03741785284469), (13, 37.20392650456272), (14, 37.09401760420909), (15, 17.231665431104883), (16, 49.87270231484941), (17, 45.29962491721704), (18, 41.608083529416106), (19, 51.446748801593124)])
IoU=0.80,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 29.24728670096014), (1, 35.92140058163261), (2, 24.908229908188524), (3, 10.291486374172251), (4, 10.15671489545893), (5, 54.30735042426665), (6, 46.93295727122877), (7, 28.49816838763205), (8, 13.389269503532256), (9, 30.525725607620206), (10, 26.932866559829144), (11, 30.128264310888618), (12, 31.495051364593124), (13, 25.75971714546913), (14, 21.390860526197024), (15, 8.784168916362376), (16, 41.156905747407066), (17, 34.44204135404039), (18, 26.625913351391016), (19, 38.61111518956717)])
IoU=0.85,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 15.285211645630408), (1, 17.475543633818628), (2, 10.6936476276743), (3, 3.4145408784473954), (4, 2.5120347367232814), (5, 34.69000285452735), (6, 29.538099759115678), (7, 10.898174553502008), (8, 4.53217135718132), (9, 14.32890394151856), (10, 17.409527593703633), (11, 14.322408666973885), (12, 15.158436930002248), (13, 10.347523957445306), (14, 7.370429474257842), (15, 2.7172249028761923), (16, 25.30523781259505), (17, 14.344720483717705), (18, 16.42573671464009), (19, 17.786568275734794)])
IoU=0.90,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 3.1465800339093706), (1, 3.9024590628865923), (2, 1.2752866737562467), (3, 0.6873128371757482), (4, 0.26968536091000606), (5, 4.504696309987452), (6, 7.262653398502911), (7, 1.7851550008322048), (8, 0.6095726264045263), (9, 3.586517322141843), (10, 6.9357431176198485), (11, 2.467538157704796), (12, 2.050535963883877), (13, 1.2801540892901502), (14, 0.8462733924066873), (15, 0.22441790300000375), (16, 5.2738241468123155), (17, 4.042968910009756), (18, 6.033581999317902), (19, 1.660422123563112)])
IoU=0.95,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 0.22838915470494414), (1, 0.07560833883054165), (2, 0.014037868750690305), (3, 0.0041247736881512495), (4, 7.973807636675049e-05), (5, 0.07544911929952569), (6, 0.09206131737438153), (7, 0.03256277917638597), (8, 0.012794729937982878), (9, 0.013220518244315176), (10, 0.2734672329542833), (11, 0.0032816926611556004), (12, 0.03380662609871535), (13, 0.32891966251076693), (14, 0.0047979864272915465), (15, 0.005593191095017163), (16, 0.10209042294603793), (17, 0.030164939478710143), (18, 0.009193590753874442), (19, 0.019161520279794876)])

2022-04-30 16:36:16 - until epoch: 005, best_metric: 69.658%
2022-04-30 16:36:16 - epoch 006 lr: 0.0001
2022-04-30 16:37:01 - train: epoch 0006, iter [00100, 00517], lr: 0.000100, total_loss: 1.0079, cls_loss: 0.2494, reg_loss: 0.1646, center_ness_loss: 0.5940
2022-04-30 16:37:39 - train: epoch 0006, iter [00200, 00517], lr: 0.000100, total_loss: 0.9313, cls_loss: 0.2106, reg_loss: 0.1261, center_ness_loss: 0.5946
2022-04-30 16:38:16 - train: epoch 0006, iter [00300, 00517], lr: 0.000100, total_loss: 0.9481, cls_loss: 0.2005, reg_loss: 0.1416, center_ness_loss: 0.6060
2022-04-30 16:38:53 - train: epoch 0006, iter [00400, 00517], lr: 0.000100, total_loss: 0.9511, cls_loss: 0.2240, reg_loss: 0.1379, center_ness_loss: 0.5892
2022-04-30 16:39:31 - train: epoch 0006, iter [00500, 00517], lr: 0.000100, total_loss: 0.9302, cls_loss: 0.2030, reg_loss: 0.1333, center_ness_loss: 0.5939
2022-04-30 16:39:38 - train: epoch 006, train_loss: 0.9685
2022-04-30 16:39:39 - until epoch: 006, best_metric: 69.658%
2022-04-30 16:39:39 - epoch 007 lr: 0.0001
2022-04-30 16:40:17 - train: epoch 0007, iter [00100, 00517], lr: 0.000100, total_loss: 0.9394, cls_loss: 0.2010, reg_loss: 0.1408, center_ness_loss: 0.5975
2022-04-30 16:40:54 - train: epoch 0007, iter [00200, 00517], lr: 0.000100, total_loss: 0.9379, cls_loss: 0.2182, reg_loss: 0.1262, center_ness_loss: 0.5934
2022-04-30 16:41:32 - train: epoch 0007, iter [00300, 00517], lr: 0.000100, total_loss: 0.8994, cls_loss: 0.1859, reg_loss: 0.1155, center_ness_loss: 0.5981
2022-04-30 16:42:09 - train: epoch 0007, iter [00400, 00517], lr: 0.000100, total_loss: 0.9553, cls_loss: 0.2117, reg_loss: 0.1469, center_ness_loss: 0.5967
2022-04-30 16:42:46 - train: epoch 0007, iter [00500, 00517], lr: 0.000100, total_loss: 0.9632, cls_loss: 0.2176, reg_loss: 0.1503, center_ness_loss: 0.5952
2022-04-30 16:42:53 - train: epoch 007, train_loss: 0.9503
2022-04-30 16:42:54 - until epoch: 007, best_metric: 69.658%
2022-04-30 16:42:54 - epoch 008 lr: 0.0001
2022-04-30 16:43:32 - train: epoch 0008, iter [00100, 00517], lr: 0.000100, total_loss: 0.9074, cls_loss: 0.1824, reg_loss: 0.1288, center_ness_loss: 0.5962
2022-04-30 16:44:10 - train: epoch 0008, iter [00200, 00517], lr: 0.000100, total_loss: 0.8814, cls_loss: 0.1634, reg_loss: 0.1259, center_ness_loss: 0.5922
2022-04-30 16:44:47 - train: epoch 0008, iter [00300, 00517], lr: 0.000100, total_loss: 0.9625, cls_loss: 0.2160, reg_loss: 0.1510, center_ness_loss: 0.5954
2022-04-30 16:45:25 - train: epoch 0008, iter [00400, 00517], lr: 0.000100, total_loss: 0.9076, cls_loss: 0.1958, reg_loss: 0.1210, center_ness_loss: 0.5908
2022-04-30 16:46:02 - train: epoch 0008, iter [00500, 00517], lr: 0.000100, total_loss: 0.9302, cls_loss: 0.1866, reg_loss: 0.1359, center_ness_loss: 0.6077
2022-04-30 16:46:09 - train: epoch 008, train_loss: 0.9364
2022-04-30 16:52:19 - eval: epoch: 008
per_image_load_time: 2.020ms
per_image_inference_time: 14.394ms
IoU=0.50,area=all,maxDets=100,mAP: 73.58686581622032
IoU=0.55,area=all,maxDets=100,mAP: 71.47875540471209
IoU=0.60,area=all,maxDets=100,mAP: 68.45090155958454
IoU=0.65,area=all,maxDets=100,mAP: 63.613209915774654
IoU=0.70,area=all,maxDets=100,mAP: 57.17016165339409
IoU=0.75,area=all,maxDets=100,mAP: 47.24836116600086
IoU=0.80,area=all,maxDets=100,mAP: 34.416159737931416
IoU=0.85,area=all,maxDets=100,mAP: 17.46852846952547
IoU=0.90,area=all,maxDets=100,mAP: 3.933459090799078
IoU=0.95,area=all,maxDets=100,mAP: 0.2044882718525122
IoU=0.50,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 79.76414879609021), (1, 80.38778778335605), (2, 74.16039973394663), (3, 62.419949593513856), (4, 62.46391948812683), (5, 80.51758727604494), (6, 86.71913696870799), (7, 71.58269649833603), (8, 54.590389667026294), (9, 81.14400187186834), (10, 63.98091562629131), (11, 74.47784626860786), (12, 81.90826989569283), (13, 82.10504967922364), (14, 83.54163898208135), (15, 51.6470964297315), (16, 77.0701472682922), (17, 64.15251732313709), (18, 81.29298083482006), (19, 77.8108363395114)])
IoU=0.55,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 76.22846954144447), (1, 77.85702190251989), (2, 72.77018610289893), (3, 58.083735266226924), (4, 60.09715280596091), (5, 79.4367102638867), (6, 85.0466139320242), (7, 69.64290713580861), (8, 52.486228293964196), (9, 80.34184844230758), (10, 62.50226376375523), (11, 73.26011301462992), (12, 80.39000143473105), (13, 80.36151703314968), (14, 79.65168476835771), (15, 46.08352875877752), (16, 75.40442780491688), (17, 63.03434799308069), (18, 79.86165520145315), (19, 77.03469463434739)])
IoU=0.60,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 72.1005091706768), (1, 75.56502241305256), (2, 69.86164149328269), (3, 54.0975347998734), (4, 56.23853387420319), (5, 76.60654101193852), (6, 82.78277347197222), (7, 67.8892508144983), (8, 49.69925456681224), (9, 77.73094535194414), (10, 60.05410560302549), (11, 70.48853724581637), (12, 76.15497259513538), (13, 76.49457337549718), (14, 74.79352883820384), (15, 41.06544823701504), (16, 72.79381422365799), (17, 61.23444152339586), (18, 77.77824158621016), (19, 75.58836099547929)])
IoU=0.65,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 66.2668254493851), (1, 72.09844716547462), (2, 63.55141952183839), (3, 43.77866417105591), (4, 50.95768645948792), (5, 75.21105764898634), (6, 78.4533622638933), (7, 64.9742042688987), (8, 43.671498085973646), (9, 73.89755547081876), (10, 57.5939417067235), (11, 65.93384405436235), (12, 70.04109015616736), (13, 71.7124148193753), (14, 67.7100321238689), (15, 33.827175061133374), (16, 70.56954672695703), (17, 56.346592510431435), (18, 73.16891079738461), (19, 72.49992985327629)])
IoU=0.70,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 61.48269489530731), (1, 66.44969179319808), (2, 54.047684935596095), (3, 36.79108927935707), (4, 43.743237184865016), (5, 73.14781480716309), (6, 72.53388689274342), (7, 60.38333956249375), (8, 37.412990027353246), (9, 68.13280408344633), (10, 50.40625335101539), (11, 61.61916155086682), (12, 58.6357111179763), (13, 64.08416642144495), (14, 57.8454804603141), (15, 25.68413072275711), (16, 64.62378089999933), (17, 52.93615399047581), (18, 66.25834380973245), (19, 67.18481728177599)])
IoU=0.75,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 49.82635116406014), (1, 54.70265733762765), (2, 42.23727792352502), (3, 28.408535588301188), (4, 31.036706709340724), (5, 67.34418730318733), (6, 64.1639270240618), (7, 52.67108059521712), (8, 29.111885647654145), (9, 55.97512573905594), (10, 41.843984826807244), (11, 50.604127949082), (12, 47.573446517158054), (13, 56.20975674212338), (14, 43.503430798115545), (15, 17.48796527248666), (16, 53.03367271238844), (17, 47.67672506851076), (18, 54.058061182489915), (19, 57.49831721882401)])
IoU=0.80,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 37.29199281263742), (1, 39.032086122103784), (2, 29.516884426245817), (3, 18.326696495600604), (4, 16.642016298270768), (5, 62.3936374324255), (6, 51.50598173879071), (7, 37.79133305916781), (8, 18.41875092697377), (9, 41.98668880000241), (10, 26.759796344475255), (11, 36.11383381294926), (12, 34.35789796753093), (13, 35.70040413968296), (14, 28.32223392467375), (15, 9.564575424044792), (16, 42.34376174003566), (17, 41.679063803519895), (18, 38.04406790069282), (19, 42.531491588804435)])
IoU=0.85,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 19.827901065426012), (1, 19.20055045945518), (2, 12.993088529311219), (3, 5.898970674460631), (4, 3.829440840291877), (5, 34.042899690443214), (6, 30.322247865201074), (7, 22.14211198305257), (8, 8.4269778859616), (9, 19.3256888394234), (10, 12.98784257232536), (11, 22.265891672478357), (12, 16.589027040724154), (13, 17.74315464445419), (14, 13.217001142160287), (15, 3.1717254150868026), (16, 24.480736811664443), (17, 28.650648843803506), (18, 15.596680946844419), (19, 18.657982467941135)])
IoU=0.90,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 3.6059018214539584), (1, 4.755050503953735), (2, 2.8551422245206743), (3, 1.3441297989386318), (4, 0.4078142646652085), (5, 6.652174390040019), (6, 6.609292194779388), (7, 5.403828077835317), (8, 1.5342968182128267), (9, 3.4730359700116495), (10, 4.326355924114809), (11, 5.897550381615948), (12, 3.3595258374437895), (13, 3.6390497090504486), (14, 3.207701145233767), (15, 1.1401843918687717), (16, 5.363842416278508), (17, 9.003813046179534), (18, 3.9477200201905287), (19, 2.142772879594032)])
IoU=0.95,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 0.26553234662046016), (1, 0.23770931549625274), (2, 0.07251853484788355), (3, 0.054840596665691715), (4, 0.02785203154759534), (5, 0.3438172897031311), (6, 0.29638489821806846), (7, 0.5487001291365395), (8, 0.03616826493416768), (9, 0.11620604962692092), (10, 0.24465249740365058), (11, 0.2900526225222805), (12, 0.0660131529017174), (13, 0.34688446524776023), (14, 0.10734490729653887), (15, 0.028494477460577684), (16, 0.08099173553719008), (17, 0.4247365196472728), (18, 0.162897638543243), (19, 0.3379679636933022)])

2022-04-30 16:52:19 - until epoch: 008, best_metric: 73.587%
2022-04-30 16:52:19 - epoch 009 lr: 1e-05
2022-04-30 16:52:58 - train: epoch 0009, iter [00100, 00517], lr: 0.000010, total_loss: 0.8769, cls_loss: 0.1665, reg_loss: 0.1236, center_ness_loss: 0.5868
2022-04-30 16:53:35 - train: epoch 0009, iter [00200, 00517], lr: 0.000010, total_loss: 0.8756, cls_loss: 0.1698, reg_loss: 0.1172, center_ness_loss: 0.5887
2022-04-30 16:54:13 - train: epoch 0009, iter [00300, 00517], lr: 0.000010, total_loss: 0.8530, cls_loss: 0.1587, reg_loss: 0.1089, center_ness_loss: 0.5855
2022-04-30 16:54:50 - train: epoch 0009, iter [00400, 00517], lr: 0.000010, total_loss: 0.9224, cls_loss: 0.1765, reg_loss: 0.1328, center_ness_loss: 0.6130
2022-04-30 16:55:28 - train: epoch 0009, iter [00500, 00517], lr: 0.000010, total_loss: 0.8456, cls_loss: 0.1302, reg_loss: 0.1140, center_ness_loss: 0.6013
2022-04-30 16:55:34 - train: epoch 009, train_loss: 0.8766
2022-04-30 16:55:35 - until epoch: 009, best_metric: 73.587%
2022-04-30 16:55:35 - epoch 010 lr: 1e-05
2022-04-30 16:56:13 - train: epoch 0010, iter [00100, 00517], lr: 0.000010, total_loss: 0.8808, cls_loss: 0.1673, reg_loss: 0.1151, center_ness_loss: 0.5984
2022-04-30 16:56:51 - train: epoch 0010, iter [00200, 00517], lr: 0.000010, total_loss: 0.8246, cls_loss: 0.1312, reg_loss: 0.1011, center_ness_loss: 0.5924
2022-04-30 16:57:28 - train: epoch 0010, iter [00300, 00517], lr: 0.000010, total_loss: 0.8317, cls_loss: 0.1370, reg_loss: 0.1046, center_ness_loss: 0.5901
2022-04-30 16:58:05 - train: epoch 0010, iter [00400, 00517], lr: 0.000010, total_loss: 0.8327, cls_loss: 0.1367, reg_loss: 0.1071, center_ness_loss: 0.5888
2022-04-30 16:58:44 - train: epoch 0010, iter [00500, 00517], lr: 0.000010, total_loss: 0.8798, cls_loss: 0.1597, reg_loss: 0.1270, center_ness_loss: 0.5931
2022-04-30 16:58:50 - train: epoch 010, train_loss: 0.8618
2022-04-30 17:05:03 - eval: epoch: 010
per_image_load_time: 1.923ms
per_image_inference_time: 15.573ms
IoU=0.50,area=all,maxDets=100,mAP: 79.40996964128277
IoU=0.55,area=all,maxDets=100,mAP: 77.55314873741857
IoU=0.60,area=all,maxDets=100,mAP: 74.64934949018506
IoU=0.65,area=all,maxDets=100,mAP: 70.19561106233968
IoU=0.70,area=all,maxDets=100,mAP: 63.951622708688525
IoU=0.75,area=all,maxDets=100,mAP: 55.822183193780276
IoU=0.80,area=all,maxDets=100,mAP: 44.33183528508044
IoU=0.85,area=all,maxDets=100,mAP: 30.129714739940106
IoU=0.90,area=all,maxDets=100,mAP: 13.142736495898138
IoU=0.95,area=all,maxDets=100,mAP: 1.5331451013872925
IoU=0.50,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 84.23822244950281), (1, 87.60247319317571), (2, 82.29703476397874), (3, 72.5380778977723), (4, 68.16508699767749), (5, 85.02873849258503), (6, 89.22368308207484), (7, 91.44037933302857), (8, 60.02288684366969), (9, 83.32255191984463), (10, 68.15231046366502), (11, 86.33742076972774), (12, 85.93853568634135), (13, 82.90136607470109), (14, 85.63241879604486), (15, 53.378623563906714), (16, 83.5805842121029), (17, 69.46332463501297), (18, 87.94955524654857), (19, 80.98611840429454)])
IoU=0.55,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 81.06075492695952), (1, 85.51117741643881), (2, 79.58515596261928), (3, 69.77235989292939), (4, 66.2334989530313), (5, 84.22950360993508), (6, 87.4497511620793), (7, 90.3897406449963), (8, 57.24609629042865), (9, 81.78170986135964), (10, 67.31703092230063), (11, 85.35759734919296), (12, 84.70748327902653), (13, 80.84867987110025), (14, 82.64196633293967), (15, 49.67786087473165), (16, 82.86106722904833), (17, 68.53995107551208), (18, 85.54019873100648), (19, 80.31139036273531)])
IoU=0.60,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 77.69184742521098), (1, 83.45373676212621), (2, 76.30523321027862), (3, 64.43781881654589), (4, 61.37429838380528), (5, 82.47045298305923), (6, 85.49743541724845), (7, 87.91410369780527), (8, 54.992654676350895), (9, 78.7910192125325), (10, 65.0662551354516), (11, 83.39178957962775), (12, 81.75472980133164), (13, 77.0884747826308), (14, 78.57767301169127), (15, 44.716659270383985), (16, 80.49444496104262), (17, 67.497606324352), (18, 82.94313792491512), (19, 78.52761842731098)])
IoU=0.65,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 71.37301452948938), (1, 78.96990641996062), (2, 71.50240088454294), (3, 56.44290976338129), (4, 56.3845236822845), (5, 81.99955448488639), (6, 81.74662998665602), (7, 84.99329793706636), (8, 49.84912177969683), (9, 74.01873192193216), (10, 61.01016279245021), (11, 79.3733311584949), (12, 74.22358095396616), (13, 73.38801356825199), (14, 72.70011551137894), (15, 39.11197732463233), (16, 75.52329130634428), (17, 64.77976593816706), (18, 80.44243086061611), (19, 76.07946044259559)])
IoU=0.70,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 65.7123121373493), (1, 71.22458447545637), (2, 62.01953230298578), (3, 47.10233924647979), (4, 50.57567717945566), (5, 79.7915090090014), (6, 76.3646705432564), (7, 79.92510049997826), (8, 42.61261260776637), (9, 67.69540496012809), (10, 54.78958115370482), (11, 73.68417657465581), (12, 66.29156158435654), (13, 67.68968964258639), (14, 63.93068246510825), (15, 32.034288842934565), (16, 69.56699435337195), (17, 61.74584229466197), (18, 74.68277662993853), (19, 71.59311767059454)])
IoU=0.75,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 58.72768175883937), (1, 64.05499072787875), (2, 51.43978216318643), (3, 35.97663678066573), (4, 37.580441052070576), (5, 77.63063673277463), (6, 69.59582688845471), (7, 74.79843112286669), (8, 34.21787249411003), (9, 60.54927063637903), (10, 47.94863467133774), (11, 64.98758405345362), (12, 58.40645610834556), (13, 58.02102346707818), (14, 50.95176301458304), (15, 21.390830415560995), (16, 63.00084571387984), (17, 56.80106379147423), (18, 63.84186623630639), (19, 66.52202604635991)])
IoU=0.80,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 47.6529267396815), (1, 49.639399182895886), (2, 39.38074276020943), (3, 24.918793714051883), (4, 25.470093966338553), (5, 71.18659352839857), (6, 61.1389717010638), (7, 60.092195524101875), (8, 23.84646881611471), (9, 50.453273559436404), (10, 37.19444440788553), (11, 52.394290835976044), (12, 44.61419966315586), (13, 44.00126176051199), (14, 35.97670740122268), (15, 12.72164314327133), (16, 53.1401973774883), (17, 48.09113108858578), (18, 51.481458161523975), (19, 53.24191236969455)])
IoU=0.85,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 37.52531315655626), (1, 33.122966736736416), (2, 26.14407524974198), (3, 13.044008414935588), (4, 9.945043968280967), (5, 60.227424231639844), (6, 47.90266125559679), (7, 43.93966262665249), (8, 13.220663805885788), (9, 31.298837825605517), (10, 24.85806750501014), (11, 38.99426619894386), (12, 29.204758125357632), (13, 23.201951914379716), (14, 20.88725625042833), (15, 6.333749651471829), (16, 37.54867985985438), (17, 35.885341812427676), (18, 35.15310921389065), (19, 34.15645699540634)])
IoU=0.90,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 12.734652775236238), (1, 15.003460608704355), (2, 9.708703841464837), (3, 4.518724528264298), (4, 2.119488620390933), (5, 38.52911360081197), (6, 25.293724288250473), (7, 23.164841052781206), (8, 4.5062795609256305), (9, 11.748878756112784), (10, 13.404311751010459), (11, 18.1534974493792), (12, 11.246208773301761), (13, 7.9731838525371135), (14, 7.441387671201366), (15, 1.511497704871366), (16, 14.464032608894628), (17, 18.994295579336924), (18, 9.907172892267436), (19, 12.43127400221978)])
IoU=0.95,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 0.9180911331686238), (1, 1.3193313881103448), (2, 0.8872416112719936), (3, 0.12067271241753587), (4, 0.18939729031726923), (5, 8.301424947561573), (6, 3.184863904135332), (7, 3.4086624747161216), (8, 0.1847099486548644), (9, 1.4175360209350532), (10, 2.209618573853569), (11, 1.4700677676123888), (12, 0.9319326814364444), (13, 0.12418576898214906), (14, 0.7233193711230003), (15, 0.054255888309674545), (16, 1.2675665604911948), (17, 2.8646587157163546), (18, 0.5007651339190389), (19, 0.5846001350133299)])

2022-04-30 17:05:04 - until epoch: 010, best_metric: 79.410%
2022-04-30 17:05:04 - epoch 011 lr: 1e-05
2022-04-30 17:05:42 - train: epoch 0011, iter [00100, 00517], lr: 0.000010, total_loss: 0.8919, cls_loss: 0.1605, reg_loss: 0.1267, center_ness_loss: 0.6047
2022-04-30 17:06:20 - train: epoch 0011, iter [00200, 00517], lr: 0.000010, total_loss: 0.8694, cls_loss: 0.1585, reg_loss: 0.1164, center_ness_loss: 0.5945
2022-04-30 17:06:57 - train: epoch 0011, iter [00300, 00517], lr: 0.000010, total_loss: 0.8792, cls_loss: 0.1623, reg_loss: 0.1151, center_ness_loss: 0.6018
2022-04-30 17:07:35 - train: epoch 0011, iter [00400, 00517], lr: 0.000010, total_loss: 0.8492, cls_loss: 0.1461, reg_loss: 0.1066, center_ness_loss: 0.5965
2022-04-30 17:08:12 - train: epoch 0011, iter [00500, 00517], lr: 0.000010, total_loss: 0.8503, cls_loss: 0.1512, reg_loss: 0.1127, center_ness_loss: 0.5864
2022-04-30 17:08:19 - train: epoch 011, train_loss: 0.8541
2022-04-30 17:08:20 - until epoch: 011, best_metric: 79.410%
2022-04-30 17:08:20 - epoch 012 lr: 1e-05
2022-04-30 17:08:58 - train: epoch 0012, iter [00100, 00517], lr: 0.000010, total_loss: 0.8549, cls_loss: 0.1498, reg_loss: 0.1132, center_ness_loss: 0.5920
2022-04-30 17:09:36 - train: epoch 0012, iter [00200, 00517], lr: 0.000010, total_loss: 0.8189, cls_loss: 0.1381, reg_loss: 0.1033, center_ness_loss: 0.5774
2022-04-30 17:10:13 - train: epoch 0012, iter [00300, 00517], lr: 0.000010, total_loss: 0.8447, cls_loss: 0.1488, reg_loss: 0.1069, center_ness_loss: 0.5889
2022-04-30 17:10:51 - train: epoch 0012, iter [00400, 00517], lr: 0.000010, total_loss: 0.9285, cls_loss: 0.1831, reg_loss: 0.1433, center_ness_loss: 0.6022
2022-04-30 17:11:28 - train: epoch 0012, iter [00500, 00517], lr: 0.000010, total_loss: 0.8677, cls_loss: 0.1620, reg_loss: 0.1156, center_ness_loss: 0.5901
2022-04-30 17:11:35 - train: epoch 012, train_loss: 0.8475
2022-04-30 17:17:54 - eval: epoch: 012
per_image_load_time: 2.002ms
per_image_inference_time: 15.427ms
IoU=0.50,area=all,maxDets=100,mAP: 79.80046739774006
IoU=0.55,area=all,maxDets=100,mAP: 78.15441633713631
IoU=0.60,area=all,maxDets=100,mAP: 75.30699105841724
IoU=0.65,area=all,maxDets=100,mAP: 70.91031068997047
IoU=0.70,area=all,maxDets=100,mAP: 64.86646182055415
IoU=0.75,area=all,maxDets=100,mAP: 55.91824835822238
IoU=0.80,area=all,maxDets=100,mAP: 44.82753900462127
IoU=0.85,area=all,maxDets=100,mAP: 30.337724851944706
IoU=0.90,area=all,maxDets=100,mAP: 13.483914913690246
IoU=0.95,area=all,maxDets=100,mAP: 1.2497864644147516
IoU=0.50,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 84.4968639237806), (1, 87.57085213418458), (2, 81.97885349179093), (3, 72.19149279338615), (4, 68.18424851723476), (5, 84.87403970565084), (6, 89.48663777608638), (7, 90.7688046447295), (8, 59.56711643314983), (9, 85.3095283160275), (10, 67.62025210442613), (11, 86.8961040531595), (12, 85.85736952721878), (13, 83.53883519145779), (14, 86.26155850217664), (15, 56.145770907184975), (16, 84.85773040906989), (17, 71.32629243562783), (18, 87.62596680413132), (19, 81.45103028432703)])
IoU=0.55,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 81.82160935553088), (1, 86.58274179874306), (2, 80.19487132567652), (3, 70.20578160563772), (4, 66.36787444565954), (5, 84.30017852298121), (6, 88.28572679378645), (7, 89.72226820611566), (8, 57.34406972863205), (9, 83.62738347732912), (10, 66.11640725141841), (11, 85.90260069102646), (12, 84.74397335666907), (13, 82.10034951055766), (14, 83.28269286883369), (15, 50.979661985768175), (16, 83.84337848998743), (17, 70.6651730078369), (18, 86.2821557884958), (19, 80.71942853204052)])
IoU=0.60,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 79.16510031783251), (1, 83.87800034868175), (2, 76.89784555450596), (3, 65.89031967740793), (4, 62.74534576324014), (5, 81.59052201053633), (6, 86.04102420469167), (7, 87.09871147414918), (8, 54.396410836548604), (9, 80.14429473765317), (10, 65.05569491280512), (11, 83.31428601270963), (12, 82.93158750847137), (13, 77.95473474047859), (14, 79.17940980506339), (15, 45.98442352726788), (16, 81.62443937169242), (17, 69.38819455603216), (18, 83.69556948528334), (19, 79.16390632329333)])
IoU=0.65,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 71.99762217779964), (1, 79.42775431810574), (2, 72.6413511280656), (3, 57.25697128269876), (4, 57.907478041761884), (5, 80.60058605147566), (6, 82.17782837811292), (7, 84.49728464055288), (8, 49.258795386261035), (9, 77.60759109248396), (10, 60.566949383658994), (11, 80.01747757862074), (12, 73.91201868891922), (13, 74.94604517517551), (14, 72.94462476571726), (15, 39.62515159346122), (16, 78.32300108309732), (17, 66.76919178056902), (18, 81.47743357772497), (19, 76.25105767514722)])
IoU=0.70,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 67.05156989038788), (1, 72.1182054759722), (2, 62.90940096085072), (3, 47.178717774840905), (4, 49.66065503629224), (5, 78.5394438818906), (6, 76.78856080717435), (7, 80.9777097697651), (8, 43.2243327624808), (9, 72.5518150703849), (10, 55.77673594644141), (11, 75.37630145758773), (12, 66.47643964298027), (13, 68.95939972232719), (14, 64.79542187974562), (15, 34.143671124565174), (16, 70.5178064994824), (17, 63.606788519042176), (18, 73.39853512503886), (19, 73.27772506383269)])
IoU=0.75,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 57.90452662064345), (1, 62.32489879945848), (2, 53.12250874336581), (3, 34.02528573040291), (4, 39.193721717249275), (5, 77.46726501943137), (6, 68.71867082276088), (7, 74.58041632277283), (8, 34.03130977362022), (9, 63.325420101898835), (10, 44.96179521223039), (11, 66.10943692671502), (12, 58.812358405654486), (13, 59.56655469065566), (14, 51.66138680204953), (15, 21.2733828175709), (16, 62.474687998542144), (17, 57.57458766174093), (18, 65.48705900684327), (19, 65.74969399084114)])
IoU=0.80,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 48.66367258778158), (1, 49.259116524865156), (2, 38.386722175452626), (3, 25.374064166462162), (4, 25.05674957294588), (5, 71.40364632491409), (6, 60.76696736206356), (7, 61.452539988198595), (8, 24.948651913730814), (9, 52.3300284969048), (10, 36.85961867215994), (11, 53.743559510093654), (12, 46.68061397234178), (13, 43.65265833727741), (14, 36.690387170524716), (15, 13.811239143759208), (16, 54.56685893306913), (17, 49.110049874842446), (18, 50.255196533401225), (19, 53.53843883163665)])
IoU=0.85,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 36.00867355042266), (1, 30.625100179252705), (2, 25.410367916268754), (3, 13.232083057716931), (4, 11.095359111112371), (5, 60.862711611061805), (6, 48.70902206432003), (7, 44.66572123031988), (8, 14.8690965944959), (9, 35.610986922114726), (10, 24.51199629696386), (11, 40.05001983183883), (12, 28.928365554936097), (13, 24.997909861635335), (14, 20.03868197988773), (15, 6.920132263080026), (16, 34.79977128041432), (17, 38.0245256508604), (18, 35.76370969536842), (19, 31.630262386823432)])
IoU=0.90,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 15.568225887787134), (1, 13.611253219142643), (2, 9.610545212059687), (3, 5.819153122418505), (4, 1.7276922822200609), (5, 40.13103451486351), (6, 26.768698457267202), (7, 23.112314866809154), (8, 4.601106406115624), (9, 14.14780266013602), (10, 13.517391601740842), (11, 18.127072953278017), (12, 10.652051361456522), (13, 9.158695884863812), (14, 6.940473501029603), (15, 1.573502316940397), (16, 11.978730284642923), (17, 20.252098715943948), (18, 14.292460084570536), (19, 8.087994940518742)])
IoU=0.95,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 0.7337321659041205), (1, 0.7912850810942207), (2, 0.5352047433347024), (3, 0.45399788892943616), (4, 0.19207736037789638), (5, 4.660068098427265), (6, 3.6246212762782735), (7, 2.5129535162718275), (8, 0.12635209081529353), (9, 1.4529311767904134), (10, 2.2463113235694387), (11, 1.086246009471471), (12, 0.6427710078099201), (13, 0.318848172780757), (14, 0.3803412487077972), (15, 0.16209374176470356), (16, 2.72809059839724), (17, 0.9514280516645441), (18, 0.8833004715155597), (19, 0.5130752643901492)])

2022-04-30 17:17:54 - until epoch: 012, best_metric: 79.800%
2022-04-30 17:17:54 - epoch 013 lr: 1.0000000000000002e-06
2022-04-30 17:18:32 - train: epoch 0013, iter [00100, 00517], lr: 0.000001, total_loss: 0.8369, cls_loss: 0.1331, reg_loss: 0.1115, center_ness_loss: 0.5923
2022-04-30 17:19:10 - train: epoch 0013, iter [00200, 00517], lr: 0.000001, total_loss: 0.8482, cls_loss: 0.1633, reg_loss: 0.1019, center_ness_loss: 0.5829
2022-04-30 17:19:47 - train: epoch 0013, iter [00300, 00517], lr: 0.000001, total_loss: 0.8425, cls_loss: 0.1465, reg_loss: 0.1134, center_ness_loss: 0.5826
2022-04-30 17:20:24 - train: epoch 0013, iter [00400, 00517], lr: 0.000001, total_loss: 0.8485, cls_loss: 0.1490, reg_loss: 0.1121, center_ness_loss: 0.5873
2022-04-30 17:21:02 - train: epoch 0013, iter [00500, 00517], lr: 0.000001, total_loss: 0.8728, cls_loss: 0.1569, reg_loss: 0.1196, center_ness_loss: 0.5963
2022-04-30 17:21:09 - train: epoch 013, train_loss: 0.8411
2022-04-30 17:27:24 - eval: epoch: 013
per_image_load_time: 1.996ms
per_image_inference_time: 14.618ms
IoU=0.50,area=all,maxDets=100,mAP: 79.8753973506295
IoU=0.55,area=all,maxDets=100,mAP: 78.16541815836891
IoU=0.60,area=all,maxDets=100,mAP: 75.58938529777679
IoU=0.65,area=all,maxDets=100,mAP: 71.09808116960203
IoU=0.70,area=all,maxDets=100,mAP: 64.87564280191152
IoU=0.75,area=all,maxDets=100,mAP: 56.751732011579904
IoU=0.80,area=all,maxDets=100,mAP: 45.54335138650485
IoU=0.85,area=all,maxDets=100,mAP: 31.074592999484082
IoU=0.90,area=all,maxDets=100,mAP: 14.442747104668594
IoU=0.95,area=all,maxDets=100,mAP: 1.6508470152248744
IoU=0.50,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 84.56345477269616), (1, 87.71305513257695), (2, 80.78802066678116), (3, 71.85934794604427), (4, 68.50629151262734), (5, 84.87058767467555), (6, 89.30448565232871), (7, 90.89840700485301), (8, 59.80527010770156), (9, 85.5318885881689), (10, 68.78756801411079), (11, 87.80362184557701), (12, 86.20283053152825), (13, 83.28656707352286), (14, 86.29833762200414), (15, 55.77416578123919), (16, 84.87168779987815), (17, 70.72729420217458), (18, 87.8441907187837), (19, 82.07087436531785)])
IoU=0.55,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 80.79028103220806), (1, 85.94281859489534), (2, 78.93073403208876), (3, 69.95393482336308), (4, 66.6350110009024), (5, 84.18908474327745), (6, 87.99124903643465), (7, 89.27525064519897), (8, 57.3803568133599), (9, 84.74474290691703), (10, 68.17164161693881), (11, 87.11461790009609), (12, 84.83622145270824), (13, 81.95703612641216), (14, 83.04714211161226), (15, 51.45807157996896), (16, 83.79014752944009), (17, 70.11898157674035), (18, 86.18498810429239), (19, 80.79605154052338)])
IoU=0.60,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 77.68537863478056), (1, 84.33263573401557), (2, 76.79089097875793), (3, 66.00552816084175), (4, 62.38574655187745), (5, 82.50218432276719), (6, 86.56236246396509), (7, 86.30635870751478), (8, 54.961257651000416), (9, 81.18930134333934), (10, 66.55798166583682), (11, 85.28725626175174), (12, 82.88343377507161), (13, 78.63533694211785), (14, 79.10201797101718), (15, 45.551046486511105), (16, 81.95687542352907), (17, 68.65176650679297), (18, 84.0700274185615), (19, 80.37031895548597)])
IoU=0.65,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 71.84588503337356), (1, 80.71460304448867), (2, 71.79406344695755), (3, 59.45813334453043), (4, 57.67256823666991), (5, 81.03196669174017), (6, 82.38450228140634), (7, 84.5660368270665), (8, 49.37388614810976), (9, 76.51060360083198), (10, 61.657921824148076), (11, 81.11782822474719), (12, 73.81296190363899), (13, 74.65249681095419), (14, 73.39854879579939), (15, 40.261322527714924), (16, 77.6587579195875), (17, 65.95959857154011), (18, 81.03667725003574), (19, 77.05326090869976)])
IoU=0.70,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 67.00240440351091), (1, 71.91951262818318), (2, 62.13179419964826), (3, 48.0653992799103), (4, 49.61897341977893), (5, 78.55890294955567), (6, 76.96848329038484), (7, 79.00626488623999), (8, 42.496403621315665), (9, 71.76802347532568), (10, 57.32867913509985), (11, 77.66314806160734), (12, 65.58461106481873), (13, 69.42017592899614), (14, 64.89435897061402), (15, 33.49539654890596), (16, 71.16330753804105), (17, 63.12890839716276), (18, 74.04811756524113), (19, 73.24999067389001)])
IoU=0.75,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 59.852174936133906), (1, 63.58149839443779), (2, 52.57809457932468), (3, 35.762847096637394), (4, 39.68078926500643), (5, 76.99318221705983), (6, 68.85545452731155), (7, 73.42804744379319), (8, 34.45973351305465), (9, 64.91259738918058), (10, 46.320480608928094), (11, 68.71453315915417), (12, 59.686068777203126), (13, 60.23187139478212), (14, 52.34723335046445), (15, 22.366550823583797), (16, 63.67516782821352), (17, 57.76330564108119), (18, 67.47079890100525), (19, 66.35421038524268)])
IoU=0.80,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 49.054762884471664), (1, 50.30786542418), (2, 37.5404160545121), (3, 25.578063028406884), (4, 25.276495910280122), (5, 70.67814052610952), (6, 61.425983106494144), (7, 61.82877556089862), (8, 24.520295414560962), (9, 50.069129908840004), (10, 39.0697259989434), (11, 57.99281231559501), (12, 45.3295525256739), (13, 47.60148257619995), (14, 37.46092830555876), (15, 13.823849054596602), (16, 53.634396088887584), (17, 50.57731503361327), (18, 53.2481350149701), (19, 55.84890299730447)])
IoU=0.85,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 38.16110778318361), (1, 30.728764584739704), (2, 23.68654943127759), (3, 12.576682081087817), (4, 11.665945209233337), (5, 60.43538792387517), (6, 48.65533504270405), (7, 45.58573254173066), (8, 14.48003217860338), (9, 36.26119534904259), (10, 26.029712592311178), (11, 40.04130374633043), (12, 30.661226901377535), (13, 27.122182327724374), (14, 21.48504866376288), (15, 6.595320002121058), (16, 38.23703265216284), (17, 37.192563147502135), (18, 37.6943003635366), (19, 34.19643746737468)])
IoU=0.90,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 14.795018827112674), (1, 14.12979235730175), (2, 9.170444564834806), (3, 6.015980646403203), (4, 2.6417191148193377), (5, 41.39572016438356), (6, 27.595254759726256), (7, 25.833928463295774), (8, 5.210671366280369), (9, 17.475397545858062), (10, 13.727322253609382), (11, 18.834542029779293), (12, 12.358872771898127), (13, 9.88716322335575), (14, 7.956034679993823), (15, 1.883288794990341), (16, 13.077775977858428), (17, 21.884808406267112), (18, 13.793511870323517), (19, 11.187694275280373)])
IoU=0.95,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 0.9479351274059205), (1, 1.8337959344843409), (2, 0.7221345038121237), (3, 0.7560976407674976), (4, 0.22276466431256983), (5, 7.937884310085675), (6, 3.9924961355047723), (7, 3.1321119611706036), (8, 0.17506922440472955), (9, 1.1064996517466377), (10, 3.2425942058031993), (11, 1.3052113754897134), (12, 1.1173457953845733), (13, 0.13404512125739745), (14, 0.6372988974750077), (15, 0.08763406695427038), (16, 2.241621222694518), (17, 2.171434946939363), (18, 0.5277915223486723), (19, 0.7251739964558997)])

2022-04-30 17:27:24 - until epoch: 013, best_metric: 79.875%
2022-04-30 17:27:24 - train done. model: resnet50_fcos, train time: 1.432 hours, best_metric: 79.875%
