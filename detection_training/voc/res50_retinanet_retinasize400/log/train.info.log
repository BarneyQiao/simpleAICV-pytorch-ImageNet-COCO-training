2022-04-30 12:55:17 - network: resnet50_retinanet
2022-04-30 12:55:17 - num_classes: 20
2022-04-30 12:55:17 - input_image_size: [400, 667]
2022-04-30 12:55:17 - backbone_pretrained_path: /root/code/simpleAICV-pytorch-ImageNet-COCO-training/pretrained_models/resnet/resnet50-acc76.322.pth
2022-04-30 12:55:17 - trained_model_path: 
2022-04-30 12:55:17 - criterion: RetinaLoss()
2022-04-30 12:55:17 - decoder: <simpleAICV.detection.decode.RetinaDecoder object at 0x7fc453320b80>
2022-04-30 12:55:17 - train_dataset: <simpleAICV.detection.datasets.vocdataset.VocDetection object at 0x7fc453320ee0>
2022-04-30 12:55:17 - val_dataset: <simpleAICV.detection.datasets.vocdataset.VocDetection object at 0x7fc453320fd0>
2022-04-30 12:55:17 - collater: <simpleAICV.detection.common.DetectionCollater object at 0x7fc453320f70>
2022-04-30 12:55:17 - seed: 0
2022-04-30 12:55:17 - batch_size: 32
2022-04-30 12:55:17 - num_workers: 4
2022-04-30 12:55:17 - optimizer: ('AdamW', {'lr': 0.0001, 'weight_decay': 0.001})
2022-04-30 12:55:17 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [8, 12]})
2022-04-30 12:55:17 - epochs: 13
2022-04-30 12:55:17 - eval_epoch: [1, 3, 5, 8, 10, 12, 13]
2022-04-30 12:55:17 - print_interval: 100
2022-04-30 12:55:17 - eval_type: VOC
2022-04-30 12:55:17 - eval_voc_iou_threshold_list: [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]
2022-04-30 12:55:17 - save_model_metric: IoU=0.50,area=all,maxDets=100,mAP
2022-04-30 12:55:17 - sync_bn: False
2022-04-30 12:55:17 - apex: True
2022-04-30 12:55:17 - gpus_type: NVIDIA RTX A5000
2022-04-30 12:55:17 - gpus_num: 2
2022-04-30 12:55:17 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7fc451eeb670>
2022-04-30 12:55:17 - --------------------parameters--------------------
2022-04-30 12:55:17 - name: backbone.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.0.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.0.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.0.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.0.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.0.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.0.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.0.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.0.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.0.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.0.downsample_conv.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.0.downsample_conv.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.0.downsample_conv.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.1.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.1.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.1.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.1.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.1.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.1.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.1.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.1.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.1.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.2.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.2.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.2.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.2.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.2.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.2.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.2.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.2.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer1.2.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.0.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.0.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.0.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.0.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.0.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.0.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.0.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.0.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.0.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.0.downsample_conv.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.0.downsample_conv.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.0.downsample_conv.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.1.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.1.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.1.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.1.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.1.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.1.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.1.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.1.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.1.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.2.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.2.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.2.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.2.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.2.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.2.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.2.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.2.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.2.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.3.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.3.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.3.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.3.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.3.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.3.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.3.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.3.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer2.3.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.0.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.0.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.0.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.0.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.0.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.0.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.0.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.0.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.0.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.0.downsample_conv.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.0.downsample_conv.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.0.downsample_conv.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.1.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.1.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.1.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.1.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.1.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.1.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.1.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.1.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.1.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.2.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.2.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.2.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.2.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.2.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.2.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.2.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.2.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.2.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.3.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.3.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.3.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.3.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.3.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.3.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.3.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.3.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.3.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.4.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.4.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.4.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.4.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.4.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.4.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.4.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.4.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.4.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.5.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.5.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.5.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.5.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.5.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.5.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.5.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.5.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer3.5.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.0.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.0.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.0.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.0.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.0.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.0.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.0.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.0.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.0.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.0.downsample_conv.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.0.downsample_conv.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.0.downsample_conv.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.1.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.1.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.1.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.1.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.1.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.1.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.1.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.1.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.1.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.2.conv1.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.2.conv1.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.2.conv1.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.2.conv2.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.2.conv2.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.2.conv2.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.2.conv3.layer.0.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.2.conv3.layer.1.weight, grad: True
2022-04-30 12:55:17 - name: backbone.layer4.2.conv3.layer.1.bias, grad: True
2022-04-30 12:55:17 - name: fpn.P3_1.weight, grad: True
2022-04-30 12:55:17 - name: fpn.P3_1.bias, grad: True
2022-04-30 12:55:17 - name: fpn.P3_2.weight, grad: True
2022-04-30 12:55:17 - name: fpn.P3_2.bias, grad: True
2022-04-30 12:55:17 - name: fpn.P4_1.weight, grad: True
2022-04-30 12:55:17 - name: fpn.P4_1.bias, grad: True
2022-04-30 12:55:17 - name: fpn.P4_2.weight, grad: True
2022-04-30 12:55:17 - name: fpn.P4_2.bias, grad: True
2022-04-30 12:55:17 - name: fpn.P5_1.weight, grad: True
2022-04-30 12:55:17 - name: fpn.P5_1.bias, grad: True
2022-04-30 12:55:17 - name: fpn.P5_2.weight, grad: True
2022-04-30 12:55:17 - name: fpn.P5_2.bias, grad: True
2022-04-30 12:55:17 - name: fpn.P6.weight, grad: True
2022-04-30 12:55:17 - name: fpn.P6.bias, grad: True
2022-04-30 12:55:17 - name: fpn.P7.1.weight, grad: True
2022-04-30 12:55:17 - name: fpn.P7.1.bias, grad: True
2022-04-30 12:55:17 - name: cls_head.cls_head.0.weight, grad: True
2022-04-30 12:55:17 - name: cls_head.cls_head.0.bias, grad: True
2022-04-30 12:55:17 - name: cls_head.cls_head.2.weight, grad: True
2022-04-30 12:55:17 - name: cls_head.cls_head.2.bias, grad: True
2022-04-30 12:55:17 - name: cls_head.cls_head.4.weight, grad: True
2022-04-30 12:55:17 - name: cls_head.cls_head.4.bias, grad: True
2022-04-30 12:55:17 - name: cls_head.cls_head.6.weight, grad: True
2022-04-30 12:55:17 - name: cls_head.cls_head.6.bias, grad: True
2022-04-30 12:55:17 - name: cls_head.cls_out.weight, grad: True
2022-04-30 12:55:17 - name: cls_head.cls_out.bias, grad: True
2022-04-30 12:55:17 - name: reg_head.reg_head.0.weight, grad: True
2022-04-30 12:55:17 - name: reg_head.reg_head.0.bias, grad: True
2022-04-30 12:55:17 - name: reg_head.reg_head.2.weight, grad: True
2022-04-30 12:55:17 - name: reg_head.reg_head.2.bias, grad: True
2022-04-30 12:55:17 - name: reg_head.reg_head.4.weight, grad: True
2022-04-30 12:55:17 - name: reg_head.reg_head.4.bias, grad: True
2022-04-30 12:55:17 - name: reg_head.reg_head.6.weight, grad: True
2022-04-30 12:55:17 - name: reg_head.reg_head.6.bias, grad: True
2022-04-30 12:55:17 - name: reg_head.reg_out.weight, grad: True
2022-04-30 12:55:17 - name: reg_head.reg_out.bias, grad: True
2022-04-30 12:55:17 - --------------------buffers--------------------
2022-04-30 12:55:17 - name: backbone.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.0.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.0.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.0.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.0.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.0.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.0.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.0.downsample_conv.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.1.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.1.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.1.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.1.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.1.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.1.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.2.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.2.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.2.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.2.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.2.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.2.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer1.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.0.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.0.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.0.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.0.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.0.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.0.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.1.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.1.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.1.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.1.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.1.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.1.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.2.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.2.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.2.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.2.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.2.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.2.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.3.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.3.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.3.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.3.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.3.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.3.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer2.3.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.0.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.0.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.0.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.0.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.0.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.0.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.1.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.1.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.1.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.1.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.1.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.1.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.2.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.2.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.2.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.2.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.2.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.2.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.3.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.3.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.3.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.3.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.3.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.3.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.3.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.4.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.4.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.4.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.4.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.4.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.4.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.4.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.5.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.5.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.5.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.5.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.5.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.5.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer3.5.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.0.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.0.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.0.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.0.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.0.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.0.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.0.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.1.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.1.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.1.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.1.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.1.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.1.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.1.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.2.conv1.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.2.conv1.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.2.conv2.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.2.conv2.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.2.conv3.layer.1.running_mean, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.2.conv3.layer.1.running_var, grad: False
2022-04-30 12:55:17 - name: backbone.layer4.2.conv3.layer.1.num_batches_tracked, grad: False
2022-04-30 12:55:17 - epoch 001 lr: 0.0001
2022-04-30 12:55:51 - train: epoch 0001, iter [00100, 00517], lr: 0.000100, total_loss: 0.9796, cls_loss: 0.6384, reg_loss: 0.3412
2022-04-30 12:56:24 - train: epoch 0001, iter [00200, 00517], lr: 0.000100, total_loss: 0.8012, cls_loss: 0.5032, reg_loss: 0.2980
2022-04-30 12:56:58 - train: epoch 0001, iter [00300, 00517], lr: 0.000100, total_loss: 0.7399, cls_loss: 0.4564, reg_loss: 0.2835
2022-04-30 12:57:32 - train: epoch 0001, iter [00400, 00517], lr: 0.000100, total_loss: 0.7529, cls_loss: 0.4613, reg_loss: 0.2915
2022-04-30 12:58:06 - train: epoch 0001, iter [00500, 00517], lr: 0.000100, total_loss: 0.6278, cls_loss: 0.3715, reg_loss: 0.2562
2022-04-30 12:58:12 - train: epoch 001, train_loss: 0.8644
2022-04-30 13:01:14 - eval: epoch: 001
per_image_load_time: 1.570ms
per_image_inference_time: 20.029ms
IoU=0.50,area=all,maxDets=100,mAP: 24.580532617090935
IoU=0.55,area=all,maxDets=100,mAP: 22.16418286679156
IoU=0.60,area=all,maxDets=100,mAP: 19.6492142328492
IoU=0.65,area=all,maxDets=100,mAP: 16.183373842103407
IoU=0.70,area=all,maxDets=100,mAP: 12.557810159698265
IoU=0.75,area=all,maxDets=100,mAP: 8.468714468764354
IoU=0.80,area=all,maxDets=100,mAP: 4.561942841130147
IoU=0.85,area=all,maxDets=100,mAP: 1.5273347948240033
IoU=0.90,area=all,maxDets=100,mAP: 0.3561636090901192
IoU=0.95,area=all,maxDets=100,mAP: 0.016602683963814525
IoU=0.50,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 40.28071205190965), (1, 15.713578331659491), (2, 39.03486809386599), (3, 4.218561028585706), (4, 10.642155164872639), (5, 26.961761191567952), (6, 63.68600742808896), (7, 50.30928200393364), (8, 24.704043031095885), (9, 0.0), (10, 13.263212702021047), (11, 29.75120366849426), (12, 7.437963432622693), (13, 3.912513819332055), (14, 60.81174792822856), (15, 12.446422341161107), (16, 0.05165289256198347), (17, 11.160053293058997), (18, 20.643006175254424), (19, 56.58190776350369)])
IoU=0.55,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 37.94313215695143), (1, 12.785178000706676), (2, 35.45669115872604), (3, 3.369744202025249), (4, 7.443621454519855), (5, 25.44645529752013), (6, 60.38191111499791), (7, 48.276429611052244), (8, 21.30499319677594), (9, 0.0), (10, 8.92606706111514), (11, 26.694461180336702), (12, 5.827610779864287), (13, 2.9799207468820224), (14, 55.193811071656306), (15, 9.823687365895243), (16, 0.0), (17, 9.741136458516094), (18, 18.231396935156322), (19, 53.45740954313359)])
IoU=0.60,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 33.591772529660076), (1, 10.888356171583334), (2, 31.7368131440641), (3, 2.2150059666392963), (4, 4.036405108664084), (5, 24.015571524789138), (6, 56.845056990243734), (7, 44.43350986386261), (8, 16.977646099818877), (9, 0.0), (10, 7.674156494973891), (11, 24.26849922407736), (12, 4.485398907132413), (13, 2.5997254865609425), (14, 46.593526125933934), (15, 7.290488419350605), (16, 0.0), (17, 8.3540461830461), (18, 16.97763577900271), (19, 50.000670637580846)])
IoU=0.65,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 27.591711967661105), (1, 6.42719059797639), (2, 26.308816076836695), (3, 1.0158208842625966), (4, 2.0818396254655007), (5, 21.55268352605365), (6, 49.973919458448215), (7, 38.670368849402145), (8, 11.85821185188586), (9, 0.0), (10, 6.009978660806489), (11, 17.581628549984536), (12, 3.8223536831818055), (13, 1.4257527017790967), (14, 36.65669492978626), (15, 5.213413703135934), (16, 0.0), (17, 8.200307877407226), (18, 15.06870104228426), (19, 44.20808285571033)])
IoU=0.70,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 21.86770156866405), (1, 4.48260243827871), (2, 20.640828710475436), (3, 0.6604476406947098), (4, 1.0014608864567014), (5, 20.2189935919573), (6, 41.49702993058215), (7, 30.302567392391488), (8, 7.342955812606833), (9, 0.0), (10, 4.64286633131182), (11, 11.224242428076197), (12, 3.125599330732945), (13, 1.3151388695692494), (14, 25.342255312450213), (15, 2.6781118318144266), (16, 0.0), (17, 6.652382096545247), (18, 13.9714041646327), (19, 34.189614856725136)])
IoU=0.75,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 10.11553511985782), (1, 2.3980434936568757), (2, 13.750893237982803), (3, 0.5614559434365606), (4, 0.42763872472960524), (5, 18.050081450433396), (6, 31.802636562555044), (7, 23.10098455654485), (8, 4.043776844550888), (9, 0.0), (10, 3.6908267063118103), (11, 6.7907245201113655), (12, 1.890657792727344), (13, 0.8978253813696851), (14, 15.49058635557513), (15, 1.5119312721591183), (16, 0.0), (17, 5.526567781221588), (18, 8.904503531688047), (19, 20.419620100375134)])
IoU=0.80,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 4.812945677370557), (1, 1.1832571190493746), (2, 6.557079690831309), (3, 0.21722682178796676), (4, 0.05582287085475764), (5, 12.144310185818819), (6, 18.9038683483558), (7, 14.507583637062988), (8, 2.1648456854633507), (9, 0.0), (10, 2.9114772919759475), (11, 2.7583332495292012), (12, 1.4012039275050807), (13, 0.728937728937729), (14, 8.556102561047549), (15, 0.42965114788391406), (16, 0.0), (17, 2.616875442785997), (18, 3.858290963993443), (19, 7.431044472349171)])
IoU=0.85,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 0.6702798414767205), (1, 0.495423566631218), (2, 1.5623897532759254), (3, 0.191527042285647), (4, 0.0035291131026782743), (5, 5.284074862647143), (6, 7.43411673632242), (7, 5.79679432109258), (8, 0.6062171432454719), (9, 0.0), (10, 0.6386504698028548), (11, 0.6600587902490962), (12, 0.4814717878252524), (13, 0.41025641025641024), (14, 3.5467247879881816), (15, 0.2631318946737445), (16, 0.0), (17, 0.5245288989462864), (18, 0.33384052702855205), (19, 1.6436799496298793)])
IoU=0.90,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 0.042322178060319314), (1, 0.11256537066535145), (2, 0.2619152180372227), (3, 0.19073392360830274), (4, 0.0003780489649019341), (5, 1.0590077682926036), (6, 1.2610186319508527), (7, 2.3782664032332934), (8, 0.1552679057482549), (9, 0.0), (10, 0.05144575770367242), (11, 0.08413990252304941), (12, 0.3211629479377958), (13, 0.10256410256410256), (14, 0.7441114291655031), (15, 0.16645572408067705), (16, 0.0), (17, 0.0760528535758226), (18, 0.09305943931465373), (19, 0.022804576376004946)])
IoU=0.95,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 0.00041548513082588056), (1, 0.00036231490237424957), (2, 0.0002563116749967961), (3, 0.0), (4, 0.0003780489649019341), (5, 0.07412898443291327), (6, 0.03274211160615313), (7, 0.07358763220579143), (8, 0.002698687466126493), (9, 0.0), (10, 0.0), (11, 0.005253073651638805), (12, 0.0), (13, 0.0), (14, 0.017507265236045965), (15, 0.10416666666666667), (16, 0.0), (17, 0.0), (18, 0.020557097337855892), (19, 0.0)])

2022-04-30 13:01:15 - until epoch: 001, best_metric: 24.581%
2022-04-30 13:01:15 - epoch 002 lr: 0.0001
2022-04-30 13:01:49 - train: epoch 0002, iter [00100, 00517], lr: 0.000100, total_loss: 0.6058, cls_loss: 0.3811, reg_loss: 0.2246
2022-04-30 13:02:23 - train: epoch 0002, iter [00200, 00517], lr: 0.000100, total_loss: 0.5979, cls_loss: 0.3558, reg_loss: 0.2422
2022-04-30 13:02:56 - train: epoch 0002, iter [00300, 00517], lr: 0.000100, total_loss: 0.5807, cls_loss: 0.3296, reg_loss: 0.2511
2022-04-30 13:03:29 - train: epoch 0002, iter [00400, 00517], lr: 0.000100, total_loss: 0.5594, cls_loss: 0.2999, reg_loss: 0.2595
2022-04-30 13:04:03 - train: epoch 0002, iter [00500, 00517], lr: 0.000100, total_loss: 0.5054, cls_loss: 0.2922, reg_loss: 0.2132
2022-04-30 13:04:09 - train: epoch 002, train_loss: 0.5944
2022-04-30 13:04:10 - until epoch: 002, best_metric: 24.581%
2022-04-30 13:04:10 - epoch 003 lr: 0.0001
2022-04-30 13:04:44 - train: epoch 0003, iter [00100, 00517], lr: 0.000100, total_loss: 0.5556, cls_loss: 0.3099, reg_loss: 0.2457
2022-04-30 13:05:18 - train: epoch 0003, iter [00200, 00517], lr: 0.000100, total_loss: 0.4799, cls_loss: 0.2661, reg_loss: 0.2138
2022-04-30 13:05:52 - train: epoch 0003, iter [00300, 00517], lr: 0.000100, total_loss: 0.5053, cls_loss: 0.2744, reg_loss: 0.2309
2022-04-30 13:06:25 - train: epoch 0003, iter [00400, 00517], lr: 0.000100, total_loss: 0.5493, cls_loss: 0.3118, reg_loss: 0.2375
2022-04-30 13:06:59 - train: epoch 0003, iter [00500, 00517], lr: 0.000100, total_loss: 0.4534, cls_loss: 0.2350, reg_loss: 0.2184
2022-04-30 13:07:05 - train: epoch 003, train_loss: 0.5008
2022-04-30 13:10:19 - eval: epoch: 003
per_image_load_time: 1.943ms
per_image_inference_time: 22.587ms
IoU=0.50,area=all,maxDets=100,mAP: 64.08105483332841
IoU=0.55,area=all,maxDets=100,mAP: 60.9707985649606
IoU=0.60,area=all,maxDets=100,mAP: 57.16485668427231
IoU=0.65,area=all,maxDets=100,mAP: 52.34545309511899
IoU=0.70,area=all,maxDets=100,mAP: 44.7332714389057
IoU=0.75,area=all,maxDets=100,mAP: 36.566591394334395
IoU=0.80,area=all,maxDets=100,mAP: 27.162531213005963
IoU=0.85,area=all,maxDets=100,mAP: 16.109651709987507
IoU=0.90,area=all,maxDets=100,mAP: 5.33189060185472
IoU=0.95,area=all,maxDets=100,mAP: 0.4544066737559017
IoU=0.50,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 70.19743756054115), (1, 75.62131018465813), (2, 74.92698119667833), (3, 48.21518697662282), (4, 52.493803174146045), (5, 67.28698926773903), (6, 80.83482279301137), (7, 84.11137161829905), (8, 44.01322486124414), (9, 29.387866671447192), (10, 55.19440117773681), (11, 81.55416758644678), (12, 63.605375487910045), (13, 71.8931544959564), (14, 77.664073458516), (15, 37.27609412426675), (16, 63.807695709758626), (17, 58.37892759835071), (18, 73.24810995130973), (19, 71.91010277192906)])
IoU=0.55,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 67.2788382167082), (1, 73.60379220394316), (2, 70.62998592367369), (3, 43.50945882470919), (4, 49.3983622881789), (5, 65.5784316034188), (6, 79.02496582571585), (7, 82.10979810678727), (8, 40.60412507153192), (9, 25.76485369831334), (10, 53.72518738531442), (11, 79.10116628482335), (12, 60.11203428662244), (13, 67.5124985706368), (14, 73.63592511851994), (15, 32.083823531834135), (16, 61.53664316424622), (17, 54.45153043853098), (18, 69.43756852501011), (19, 70.3169822306934)])
IoU=0.60,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 61.70029466029177), (1, 69.70037873428831), (2, 67.90075501006243), (3, 36.31799907932734), (4, 44.681659527761674), (5, 63.89050554006359), (6, 75.64289169924965), (7, 78.88542407425112), (8, 37.5015397202754), (9, 23.202728447759615), (10, 50.77608387682693), (11, 76.09210355381096), (12, 54.204234073353), (13, 64.23587209212498), (14, 67.50286566270464), (15, 27.3726542045158), (16, 58.437746337633925), (17, 52.77646665821063), (18, 63.09062776722255), (19, 69.38430296571185)])
IoU=0.65,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 57.54533708339365), (1, 62.967726650214715), (2, 62.444979508138445), (3, 31.139480913458527), (4, 37.52775688549966), (5, 61.232404771075856), (6, 70.96091482608674), (7, 75.57576035481361), (8, 31.51932692430587), (9, 18.870735670745315), (10, 45.21655902601987), (11, 70.24807999895548), (12, 46.78748419259709), (13, 59.90219775459396), (14, 59.310154225125224), (15, 22.114796050218995), (16, 55.34518711500838), (17, 51.48730887874202), (18, 59.63754188660955), (19, 67.07532918677677)])
IoU=0.70,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 47.450344326685304), (1, 55.09733330700539), (2, 52.88289019187241), (3, 24.906259033466817), (4, 25.855275772717825), (5, 58.22000541114636), (6, 65.25437849461993), (7, 65.53422853066144), (8, 24.10365993870926), (9, 15.260296270732546), (10, 38.41002302526335), (11, 61.56082753569605), (12, 38.27261247166967), (13, 52.55447455415915), (14, 47.231977839661035), (15, 17.150693496575105), (16, 50.82032246620175), (17, 43.45360403064614), (18, 49.418188519228714), (19, 61.22803356139581)])
IoU=0.75,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 35.98089084416315), (1, 46.82098948115446), (2, 41.85426983474754), (3, 19.441604769034253), (4, 16.08848182872835), (5, 54.74479733930637), (6, 57.86648742122998), (7, 56.28853460931581), (8, 15.336649835566481), (9, 14.033672609844757), (10, 30.513746071173575), (11, 51.55946726556926), (12, 27.93692776614377), (13, 42.45274772550942), (14, 34.43480639604941), (15, 10.004529681854976), (16, 46.42505675806982), (17, 38.180184223793134), (18, 37.816779973341276), (19, 53.551203452092146)])
IoU=0.80,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 26.564956636126368), (1, 34.7987658589343), (2, 26.35999447014999), (3, 15.334168825756683), (4, 7.670500740636312), (5, 50.31970873166092), (6, 46.918689958011285), (7, 39.89835433256846), (8, 8.710586625993619), (9, 9.884476135026505), (10, 26.24884517282176), (11, 40.5496103468146), (12, 19.357934080421334), (13, 31.335183474695548), (14, 22.214278849960014), (15, 6.063855107639615), (16, 35.55878232204287), (17, 29.571272989693732), (18, 26.12045108036159), (19, 39.77020852080374)])
IoU=0.85,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 12.792433490202756), (1, 20.135704651622497), (2, 13.176362682948476), (3, 7.7623677680398515), (4, 2.8143083317238298), (5, 35.64318578517692), (6, 32.094798074442586), (7, 29.156699936566643), (8, 3.300403461480031), (9, 4.102177024734191), (10, 17.198619092971075), (11, 26.808244872652665), (12, 8.254758943887218), (13, 15.098515355542377), (14, 10.714523772357017), (15, 3.3102254092629004), (16, 19.54188780425094), (17, 20.199849151836098), (18, 16.84406337252172), (19, 23.24390521753031)])
IoU=0.90,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 4.039606795288156), (1, 5.752843174723695), (2, 3.374830467921639), (3, 1.0604119544432462), (4, 0.5543855073088604), (5, 11.680803727958478), (6, 14.07761987471937), (7, 15.568401477481897), (8, 0.7863319955648356), (9, 1.7944923387012022), (10, 7.906996361085761), (11, 9.484721529432186), (12, 1.9067778377985998), (13, 2.7027653824666973), (14, 2.702192047618177), (15, 1.2723108268182064), (16, 3.25406100922229), (17, 8.369255529097117), (18, 5.255745432152746), (19, 5.0932587672912435)])
IoU=0.95,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 0.5096873990890451), (1, 0.5650721931558441), (2, 0.4471992414591004), (3, 0.21566378980827652), (4, 0.015971893142982717), (5, 0.6862426304378729), (6, 0.955563778551154), (7, 2.091022555949138), (8, 0.03129278660273849), (9, 0.0), (10, 0.8429126250861781), (11, 0.573544340775464), (12, 0.056478937564710466), (13, 0.36688635261271263), (14, 0.1784374251065976), (15, 0.379008104298802), (16, 0.11344146872347106), (17, 0.5208987230343877), (18, 0.3760798904105343), (19, 0.1627293393090254)])

2022-04-30 13:10:20 - until epoch: 003, best_metric: 64.081%
2022-04-30 13:10:20 - epoch 004 lr: 0.0001
2022-04-30 13:10:55 - train: epoch 0004, iter [00100, 00517], lr: 0.000100, total_loss: 0.4329, cls_loss: 0.2375, reg_loss: 0.1954
2022-04-30 13:11:29 - train: epoch 0004, iter [00200, 00517], lr: 0.000100, total_loss: 0.4134, cls_loss: 0.2199, reg_loss: 0.1935
2022-04-30 13:12:02 - train: epoch 0004, iter [00300, 00517], lr: 0.000100, total_loss: 0.4177, cls_loss: 0.2285, reg_loss: 0.1891
2022-04-30 13:12:36 - train: epoch 0004, iter [00400, 00517], lr: 0.000100, total_loss: 0.3853, cls_loss: 0.2159, reg_loss: 0.1694
2022-04-30 13:13:10 - train: epoch 0004, iter [00500, 00517], lr: 0.000100, total_loss: 0.3526, cls_loss: 0.1775, reg_loss: 0.1751
2022-04-30 13:13:16 - train: epoch 004, train_loss: 0.4491
2022-04-30 13:13:16 - until epoch: 004, best_metric: 64.081%
2022-04-30 13:13:16 - epoch 005 lr: 0.0001
2022-04-30 13:13:51 - train: epoch 0005, iter [00100, 00517], lr: 0.000100, total_loss: 0.4600, cls_loss: 0.2521, reg_loss: 0.2078
2022-04-30 13:14:24 - train: epoch 0005, iter [00200, 00517], lr: 0.000100, total_loss: 0.4129, cls_loss: 0.2310, reg_loss: 0.1819
2022-04-30 13:14:58 - train: epoch 0005, iter [00300, 00517], lr: 0.000100, total_loss: 0.3917, cls_loss: 0.2090, reg_loss: 0.1828
2022-04-30 13:15:32 - train: epoch 0005, iter [00400, 00517], lr: 0.000100, total_loss: 0.3514, cls_loss: 0.1869, reg_loss: 0.1646
2022-04-30 13:16:05 - train: epoch 0005, iter [00500, 00517], lr: 0.000100, total_loss: 0.4416, cls_loss: 0.2308, reg_loss: 0.2109
2022-04-30 13:16:11 - train: epoch 005, train_loss: 0.4134
2022-04-30 13:19:07 - eval: epoch: 005
per_image_load_time: 1.528ms
per_image_inference_time: 19.328ms
IoU=0.50,area=all,maxDets=100,mAP: 69.09332841509429
IoU=0.55,area=all,maxDets=100,mAP: 66.61013463003457
IoU=0.60,area=all,maxDets=100,mAP: 63.30677057054989
IoU=0.65,area=all,maxDets=100,mAP: 58.14503512641151
IoU=0.70,area=all,maxDets=100,mAP: 51.26056566131689
IoU=0.75,area=all,maxDets=100,mAP: 43.34556438091944
IoU=0.80,area=all,maxDets=100,mAP: 32.99779351508755
IoU=0.85,area=all,maxDets=100,mAP: 21.350537026960343
IoU=0.90,area=all,maxDets=100,mAP: 9.70109672271868
IoU=0.95,area=all,maxDets=100,mAP: 1.4423294744751165
IoU=0.50,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 71.64558153320885), (1, 60.624934299118664), (2, 73.8524610430231), (3, 51.10499578020479), (4, 58.40543343283755), (5, 78.58937356783183), (6, 84.68247225031735), (7, 85.58104814577219), (8, 50.327722687426714), (9, 66.36713376514909), (10, 63.5216983508199), (11, 80.9875986803197), (12, 74.33731733913108), (13, 70.61172623366174), (14, 81.57155308895538), (15, 44.23451781118429), (16, 71.4598438396149), (17, 61.87022687800382), (18, 77.87803408121341), (19, 74.21289549409131)])
IoU=0.55,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 70.16467856151888), (1, 58.49575611008824), (2, 70.47581041480453), (3, 45.207921346366994), (4, 53.98778557965297), (5, 77.33645388318165), (6, 83.14088261875038), (7, 84.20658080883491), (8, 47.10755829534751), (9, 65.1042821641425), (10, 60.933754784025965), (11, 78.38439539583655), (12, 73.42961172808523), (13, 67.2200379491559), (14, 77.5889523742788), (15, 39.98052128701078), (16, 69.48831381006295), (17, 60.63797606247594), (18, 76.00612673875685), (19, 73.3052926883137)])
IoU=0.60,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 65.5154761306753), (1, 54.44619787191809), (2, 67.84186395398191), (3, 41.74913241756346), (4, 48.47832803840383), (5, 75.57279573014748), (6, 81.18283085556453), (7, 81.55053242518817), (8, 43.643276487853264), (9, 61.85478282806985), (10, 59.42820369403028), (11, 75.44498317708108), (12, 66.39088354011264), (13, 63.8287260924589), (14, 71.68166312616181), (15, 36.36657357890142), (16, 68.5430248492186), (17, 58.8054748534093), (18, 73.1105509276438), (19, 70.70011083261392)])
IoU=0.65,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 60.99703564270159), (1, 48.618267244215225), (2, 61.06550615724928), (3, 36.91443423144488), (4, 43.262669997378225), (5, 73.15350773999558), (6, 76.89935793748937), (7, 77.2835792298715), (8, 39.54041852099818), (9, 55.05060131874323), (10, 52.66420706253887), (11, 71.18299511177133), (12, 60.35067651386732), (13, 57.04502249273068), (14, 63.78135765734909), (15, 30.406107189903764), (16, 65.13252357474693), (17, 54.212425930088116), (18, 67.38412140223724), (19, 67.95588757290969)])
IoU=0.70,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 54.53181257983133), (1, 44.946687801244224), (2, 48.94700212155657), (3, 27.69560772211736), (4, 35.13268267519128), (5, 69.2429168452053), (6, 70.94734442284111), (7, 71.7530835972555), (8, 32.105815915552036), (9, 48.37724639769724), (10, 46.73422957987589), (11, 64.34391674131378), (12, 51.291081091876), (13, 52.523133109258154), (14, 54.000773846298664), (15, 24.564532980977518), (16, 58.16863535062027), (17, 49.102586809547375), (18, 57.46910608953338), (19, 63.33311754854466)])
IoU=0.75,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 48.35932145500732), (1, 38.35822270734782), (2, 39.82843656860342), (3, 20.590952585522366), (4, 24.59160479167817), (5, 64.94783788896913), (6, 64.64364839297517), (7, 59.1672172553219), (8, 22.91572834201884), (9, 40.363754997188174), (10, 36.65604627967175), (11, 56.877861780697025), (12, 40.35485299393277), (13, 44.90936262514783), (14, 41.31105516483575), (15, 15.872390964572942), (16, 52.906334734937154), (17, 45.735513426733455), (18, 49.73661875239004), (19, 58.78452591083783)])
IoU=0.80,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 38.6375487562992), (1, 29.717880882993263), (2, 28.30128078436681), (3, 15.61178528281308), (4, 12.63319648975234), (5, 54.384953840739925), (6, 52.8742961505812), (7, 49.398190256808974), (8, 14.251853890218676), (9, 30.59562118469946), (10, 27.424770307362127), (11, 45.76183048635356), (12, 29.625596604602617), (13, 31.644073877870575), (14, 27.849751687232242), (15, 8.604143518494231), (16, 43.50009186526405), (17, 36.169664135569214), (18, 36.051259710709175), (19, 46.91808058902043)])
IoU=0.85,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 24.41426291664552), (1, 20.534063394780556), (2, 17.971188666041378), (3, 9.728310268355134), (4, 4.957972027870623), (5, 43.71485592833429), (6, 40.88494012711489), (7, 36.32734688361558), (8, 6.1259374998374945), (9, 15.963766229015624), (10, 19.957072516004683), (11, 27.091296441954338), (12, 20.96580373406786), (13, 13.826698348748865), (14, 14.24899330172317), (15, 4.072152727869258), (16, 27.651166997213934), (17, 23.407428710508498), (18, 24.74184365585257), (19, 30.425640163652623)])
IoU=0.90,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 11.890513486945139), (1, 9.811285990431033), (2, 5.677783875019773), (3, 6.186833777122632), (4, 1.07285397561455), (5, 29.043135355740823), (6, 22.040092409767748), (7, 19.566241277908585), (8, 1.292830679358523), (9, 6.726326436369641), (10, 11.477887336287715), (11, 11.721647956979053), (12, 6.640542617331052), (13, 3.367377705681898), (14, 4.869110340472176), (15, 0.8152805376826553), (16, 10.115434096997413), (17, 10.855811693862737), (18, 12.750146016022748), (19, 8.100798888777732)])
IoU=0.95,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 2.588165040806119), (1, 1.8792026404265472), (2, 0.8911655229816742), (3, 0.9381476694122346), (4, 0.008227658991182414), (5, 4.183581402018545), (6, 3.107957199887808), (7, 3.6601388451305983), (8, 0.018878958365462287), (9, 0.27762878445059047), (10, 4.595706594026536), (11, 0.9637796208433684), (12, 0.15652634351480063), (13, 0.30561775649908457), (14, 0.2908009868852218), (15, 0.006812532130748557), (16, 0.44432595752243853), (17, 2.8611667768897875), (18, 1.1680715824666963), (19, 0.5006876162528812)])

2022-04-30 13:19:07 - until epoch: 005, best_metric: 69.093%
2022-04-30 13:19:07 - epoch 006 lr: 0.0001
2022-04-30 13:19:41 - train: epoch 0006, iter [00100, 00517], lr: 0.000100, total_loss: 0.4540, cls_loss: 0.2441, reg_loss: 0.2099
2022-04-30 13:20:15 - train: epoch 0006, iter [00200, 00517], lr: 0.000100, total_loss: 0.3562, cls_loss: 0.1961, reg_loss: 0.1602
2022-04-30 13:20:49 - train: epoch 0006, iter [00300, 00517], lr: 0.000100, total_loss: 0.3410, cls_loss: 0.1727, reg_loss: 0.1683
2022-04-30 13:21:24 - train: epoch 0006, iter [00400, 00517], lr: 0.000100, total_loss: 0.4188, cls_loss: 0.2230, reg_loss: 0.1958
2022-04-30 13:21:58 - train: epoch 0006, iter [00500, 00517], lr: 0.000100, total_loss: 0.3212, cls_loss: 0.1536, reg_loss: 0.1676
2022-04-30 13:22:04 - train: epoch 006, train_loss: 0.3864
2022-04-30 13:22:04 - until epoch: 006, best_metric: 69.093%
2022-04-30 13:22:04 - epoch 007 lr: 0.0001
2022-04-30 13:22:39 - train: epoch 0007, iter [00100, 00517], lr: 0.000100, total_loss: 0.4120, cls_loss: 0.2210, reg_loss: 0.1910
2022-04-30 13:23:13 - train: epoch 0007, iter [00200, 00517], lr: 0.000100, total_loss: 0.3529, cls_loss: 0.1825, reg_loss: 0.1704
2022-04-30 13:23:47 - train: epoch 0007, iter [00300, 00517], lr: 0.000100, total_loss: 0.3268, cls_loss: 0.1558, reg_loss: 0.1710
2022-04-30 13:24:20 - train: epoch 0007, iter [00400, 00517], lr: 0.000100, total_loss: 0.4021, cls_loss: 0.1965, reg_loss: 0.2056
2022-04-30 13:24:54 - train: epoch 0007, iter [00500, 00517], lr: 0.000100, total_loss: 0.3522, cls_loss: 0.1717, reg_loss: 0.1804
2022-04-30 13:25:00 - train: epoch 007, train_loss: 0.3648
2022-04-30 13:25:00 - until epoch: 007, best_metric: 69.093%
2022-04-30 13:25:00 - epoch 008 lr: 0.0001
2022-04-30 13:25:35 - train: epoch 0008, iter [00100, 00517], lr: 0.000100, total_loss: 0.2771, cls_loss: 0.1218, reg_loss: 0.1553
2022-04-30 13:26:09 - train: epoch 0008, iter [00200, 00517], lr: 0.000100, total_loss: 0.3097, cls_loss: 0.1451, reg_loss: 0.1646
2022-04-30 13:26:43 - train: epoch 0008, iter [00300, 00517], lr: 0.000100, total_loss: 0.3810, cls_loss: 0.1885, reg_loss: 0.1925
2022-04-30 13:27:18 - train: epoch 0008, iter [00400, 00517], lr: 0.000100, total_loss: 0.2928, cls_loss: 0.1271, reg_loss: 0.1657
2022-04-30 13:27:52 - train: epoch 0008, iter [00500, 00517], lr: 0.000100, total_loss: 0.3375, cls_loss: 0.1643, reg_loss: 0.1732
2022-04-30 13:27:58 - train: epoch 008, train_loss: 0.3452
2022-04-30 13:30:19 - eval: epoch: 008
per_image_load_time: 1.532ms
per_image_inference_time: 15.422ms
IoU=0.50,area=all,maxDets=100,mAP: 75.49802140920829
IoU=0.55,area=all,maxDets=100,mAP: 73.17514416810899
IoU=0.60,area=all,maxDets=100,mAP: 69.95714344349507
IoU=0.65,area=all,maxDets=100,mAP: 65.55801428621626
IoU=0.70,area=all,maxDets=100,mAP: 58.711017346617226
IoU=0.75,area=all,maxDets=100,mAP: 51.11157011608775
IoU=0.80,area=all,maxDets=100,mAP: 40.38624722432253
IoU=0.85,area=all,maxDets=100,mAP: 27.523748172898472
IoU=0.90,area=all,maxDets=100,mAP: 12.440125139250332
IoU=0.95,area=all,maxDets=100,mAP: 1.5114075366479112
IoU=0.50,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 77.64412199543148), (1, 82.46175189782137), (2, 77.39450623957887), (3, 61.1164213318929), (4, 62.67122097558413), (5, 83.58491046176377), (6, 87.4050148101952), (7, 87.69092245010874), (8, 56.802875173801624), (9, 75.64392828321542), (10, 71.33972319976627), (11, 82.63787117894164), (12, 85.10058968055776), (13, 78.48661571445432), (14, 83.24287837245924), (15, 48.15627265316876), (16, 77.35552022227152), (17, 70.0145068773248), (18, 83.23609059998421), (19, 77.97468606584408)])
IoU=0.55,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 75.53228857686408), (1, 80.72331796866969), (2, 73.92193580053237), (3, 58.392229240761175), (4, 59.75792038772247), (5, 81.74001962807269), (6, 86.27218725164039), (7, 86.2958208590817), (8, 52.55021805198127), (9, 71.819190581675), (10, 69.17662983817141), (11, 80.07361696339046), (12, 84.01208088227172), (13, 76.25475193298657), (14, 79.72315872743627), (15, 45.027529327313665), (16, 75.07577100387459), (17, 68.91859857155266), (18, 81.08498052659651), (19, 77.15063724158531)])
IoU=0.60,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 71.80286313047985), (1, 77.24513652305147), (2, 71.3137049277443), (3, 54.16984363403491), (4, 55.10605417966048), (5, 80.18235023630285), (6, 84.11190712636122), (7, 83.8839973332861), (8, 47.82626697901835), (9, 70.42616039829875), (10, 63.27649399705633), (11, 76.75801354201117), (12, 79.11623578867086), (13, 71.83327110243346), (14, 74.53136828982561), (15, 39.917470914274766), (16, 73.34571397417646), (17, 67.90972536262767), (18, 79.65992335018886), (19, 76.7263680803978)])
IoU=0.65,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 68.77835178023528), (1, 70.64766197680213), (2, 64.70536782202426), (3, 49.479473150742464), (4, 50.001349550132154), (5, 77.68904647808353), (6, 80.12485516269471), (7, 82.12716443658339), (8, 42.709102241928), (9, 68.4246820428048), (10, 57.67362288516773), (11, 72.07692663058106), (12, 71.87057067951702), (13, 68.68778737987611), (14, 66.58614816025121), (15, 34.92859633089683), (16, 70.97206218661591), (17, 65.06349172301609), (18, 75.43599802014532), (19, 73.17802708622763)])
IoU=0.70,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 62.107053193294526), (1, 64.42613126796768), (2, 55.83556977826544), (3, 40.83971731085711), (4, 42.714360623971), (5, 75.16358837479027), (6, 74.71795826114254), (7, 74.33573557717379), (8, 34.066836640068345), (9, 60.33008411568621), (10, 49.57370027728173), (11, 64.52973165353104), (12, 62.19115811458625), (13, 63.534803643426116), (14, 57.16954807559678), (15, 28.179592383124298), (16, 66.35483810428373), (17, 61.69021364950957), (18, 70.45772813952809), (19, 66.00199774825974)])
IoU=0.75,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 55.34616037102042), (1, 56.53646167983204), (2, 45.123277229961225), (3, 31.847213390162953), (4, 32.578151292297306), (5, 71.05784217277964), (6, 68.42576365807345), (7, 66.87467027484392), (8, 26.755335316123396), (9, 52.77704205481963), (10, 40.73755435317688), (11, 56.657956996749405), (12, 53.69848617128214), (13, 57.223040287413255), (14, 44.333814996720946), (15, 21.824722301099026), (16, 58.51175638181261), (17, 58.120782343889665), (18, 63.80959454401574), (19, 59.99177650568137)])
IoU=0.80,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 44.99375456123496), (1, 47.00937193097373), (2, 34.167914455235305), (3, 16.894933514993507), (4, 19.513033772003702), (5, 65.5159282517708), (6, 59.98704817179775), (7, 57.4208751292821), (8, 17.588804076651403), (9, 43.50265105566409), (10, 30.85204728383169), (11, 48.54132600444758), (12, 43.45558229138282), (13, 43.63965495264001), (14, 28.823952605198222), (15, 13.98980525651955), (16, 45.41203381307377), (17, 48.2097023646581), (18, 50.435436813950844), (19, 47.77108818114077)])
IoU=0.85,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 32.445490909946784), (1, 32.06971195935491), (2, 20.61047301614356), (3, 10.377224347993344), (4, 7.153416652018957), (5, 54.70119389740178), (6, 48.22435016741334), (7, 43.523585672136655), (8, 8.425516777097355), (9, 28.9285686843395), (10, 23.93953853456407), (11, 33.971494414774604), (12, 30.917047173663438), (13, 25.435136754001086), (14, 14.125531729084756), (15, 5.969799612533586), (16, 28.142000501429177), (17, 34.13932209601875), (18, 37.73962763948135), (19, 29.635932918572472)])
IoU=0.90,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 16.619374943665505), (1, 12.615547585143611), (2, 8.008351909241131), (3, 2.6536634413731846), (4, 1.1711894620930594), (5, 37.390762565517576), (6, 26.02360127874356), (7, 25.378557329163094), (8, 1.9123900222622046), (9, 11.871083411445264), (10, 12.474365643292998), (11, 15.440177356939333), (12, 12.854931781704792), (13, 8.428141577647285), (14, 3.4539825861314517), (15, 0.4849343168523319), (16, 10.753366111015602), (17, 17.31485999429443), (18, 15.975187958903755), (19, 7.97803350957654)])
IoU=0.95,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 2.834425790969875), (1, 1.2006812156862687), (2, 0.6823389283905419), (3, 0.1251584283903676), (4, 0.0374906614170652), (5, 4.610310048418927), (6, 2.876989918753252), (7, 6.73072486344809), (8, 0.019113811349937462), (9, 1.3101194297653587), (10, 1.8904528592680214), (11, 1.6850706835289817), (12, 1.454554155429233), (13, 0.9030266286015263), (14, 0.2056370472999985), (15, 0.026194988939025998), (16, 0.9396237009338455), (17, 1.331099776549583), (18, 1.107613336251305), (19, 0.25752445956702225)])

2022-04-30 13:30:20 - until epoch: 008, best_metric: 75.498%
2022-04-30 13:30:20 - epoch 009 lr: 1e-05
2022-04-30 13:31:00 - train: epoch 0009, iter [00100, 00517], lr: 0.000010, total_loss: 0.2862, cls_loss: 0.1182, reg_loss: 0.1680
2022-04-30 13:31:34 - train: epoch 0009, iter [00200, 00517], lr: 0.000010, total_loss: 0.2620, cls_loss: 0.1088, reg_loss: 0.1532
2022-04-30 13:32:08 - train: epoch 0009, iter [00300, 00517], lr: 0.000010, total_loss: 0.2440, cls_loss: 0.0983, reg_loss: 0.1456
2022-04-30 13:32:42 - train: epoch 0009, iter [00400, 00517], lr: 0.000010, total_loss: 0.3336, cls_loss: 0.1588, reg_loss: 0.1748
2022-04-30 13:33:16 - train: epoch 0009, iter [00500, 00517], lr: 0.000010, total_loss: 0.2299, cls_loss: 0.0918, reg_loss: 0.1381
2022-04-30 13:33:22 - train: epoch 009, train_loss: 0.2845
2022-04-30 13:33:23 - until epoch: 009, best_metric: 75.498%
2022-04-30 13:33:23 - epoch 010 lr: 1e-05
2022-04-30 13:33:57 - train: epoch 0010, iter [00100, 00517], lr: 0.000010, total_loss: 0.3283, cls_loss: 0.1617, reg_loss: 0.1666
2022-04-30 13:34:32 - train: epoch 0010, iter [00200, 00517], lr: 0.000010, total_loss: 0.2301, cls_loss: 0.0949, reg_loss: 0.1352
2022-04-30 13:35:06 - train: epoch 0010, iter [00300, 00517], lr: 0.000010, total_loss: 0.2513, cls_loss: 0.1038, reg_loss: 0.1475
2022-04-30 13:35:40 - train: epoch 0010, iter [00400, 00517], lr: 0.000010, total_loss: 0.2716, cls_loss: 0.1128, reg_loss: 0.1588
2022-04-30 13:36:14 - train: epoch 0010, iter [00500, 00517], lr: 0.000010, total_loss: 0.2727, cls_loss: 0.1146, reg_loss: 0.1581
2022-04-30 13:36:20 - train: epoch 010, train_loss: 0.2680
2022-04-30 13:38:36 - eval: epoch: 010
per_image_load_time: 1.478ms
per_image_inference_time: 15.938ms
IoU=0.50,area=all,maxDets=100,mAP: 79.1818303976788
IoU=0.55,area=all,maxDets=100,mAP: 77.41386379673352
IoU=0.60,area=all,maxDets=100,mAP: 74.72823471253035
IoU=0.65,area=all,maxDets=100,mAP: 70.60535301768383
IoU=0.70,area=all,maxDets=100,mAP: 64.50161775977594
IoU=0.75,area=all,maxDets=100,mAP: 56.42245960266839
IoU=0.80,area=all,maxDets=100,mAP: 47.259394901857
IoU=0.85,area=all,maxDets=100,mAP: 34.59944795298814
IoU=0.90,area=all,maxDets=100,mAP: 18.172349241248018
IoU=0.95,area=all,maxDets=100,mAP: 3.358337448219441
IoU=0.50,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 82.163716029267), (1, 88.67071956750193), (2, 82.34876114758718), (3, 70.26985387198111), (4, 65.33253551763943), (5, 84.99266361625804), (6, 88.63619692180139), (7, 91.98372232925055), (8, 60.25341362663179), (9, 83.29740663858749), (10, 70.69105480323769), (11, 89.03434785415591), (12, 86.62889921041229), (13, 84.59801887879313), (14, 84.94578820893331), (15, 53.400557323977), (16, 79.71174586440817), (17, 70.99353153809581), (18, 84.83119950608742), (19, 80.8524754989696)])
IoU=0.55,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 80.93423418194999), (1, 87.462766808859), (2, 80.93125228374149), (3, 66.92082678701577), (4, 61.80311962039092), (5, 84.99266361625804), (6, 87.58314596774242), (7, 91.41087399542339), (8, 57.44959983140638), (9, 82.26652563006547), (10, 70.34050699744994), (11, 87.05446788790908), (12, 85.82686425099169), (13, 83.10231954750019), (14, 81.49484651998027), (15, 48.65477246348028), (16, 77.81339586532303), (17, 68.84833132342867), (18, 83.79479305627831), (19, 79.59196929947635)])
IoU=0.60,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 77.06673374011288), (1, 84.6691763874702), (2, 77.90397257533908), (3, 61.83036605632899), (4, 59.34445998702227), (5, 82.22442287038083), (6, 85.35343050022767), (7, 89.90065578338142), (8, 54.50745569787261), (9, 80.51940562360254), (10, 68.01349816796855), (11, 85.40483109561073), (12, 83.06221262954622), (13, 80.1746126403563), (14, 77.15382174735088), (15, 44.36955395471455), (16, 75.64068061539236), (17, 66.68835369249224), (18, 82.18249624023628), (19, 78.55455424520055)])
IoU=0.65,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 72.59465118010053), (1, 79.1944977289126), (2, 72.52804827198318), (3, 53.560905977561745), (4, 53.51689669889055), (5, 81.01802152557977), (6, 81.80969861935566), (7, 86.97641134267478), (8, 48.741865814282484), (9, 78.57917828796536), (10, 62.351420909666466), (11, 81.32181092993285), (12, 77.82074834967271), (13, 75.29875723652623), (14, 70.89903575980635), (15, 40.602599437696426), (16, 73.53269294188529), (17, 63.25874006036653), (18, 80.80493512165314), (19, 77.69614415916386)])
IoU=0.70,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 67.73913195224888), (1, 71.12476332833447), (2, 63.12895431699884), (3, 45.98554140863298), (4, 47.724746389710155), (5, 77.41021147832195), (6, 76.61310831077581), (7, 82.71247671877049), (8, 39.63954511204976), (9, 69.69451389488025), (10, 56.537068760230504), (11, 76.6610331931236), (12, 68.60510915250232), (13, 68.27144791718112), (14, 62.65128298901428), (15, 34.065400730288545), (16, 69.02625377782844), (17, 60.46726512609952), (18, 77.7561942725296), (19, 74.21830636599711)])
IoU=0.75,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 60.597097635679134), (1, 64.54202884810829), (2, 52.531492342516906), (3, 37.854896102048976), (4, 36.67664549115388), (5, 73.88834075851472), (6, 70.26827758247339), (7, 72.90006430717698), (8, 33.02613974957433), (9, 66.72888212990856), (10, 44.46476916500918), (11, 70.26680004969505), (12, 59.274995880943834), (13, 58.945093054786966), (14, 50.406126457122056), (15, 24.875093094298144), (16, 60.613606552061924), (17, 58.00438755903035), (18, 65.18070538635624), (19, 67.40374990690901)])
IoU=0.80,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 54.32982432719231), (1, 52.46571806807654), (2, 42.37472419688436), (3, 31.055317056597293), (4, 22.98804813548425), (5, 69.39958225735616), (6, 63.144271242225884), (7, 64.2987951951848), (8, 23.450997461348145), (9, 55.71029661392002), (10, 38.28235312899596), (11, 58.83458443524773), (12, 53.017489125830274), (13, 47.688949396307166), (14, 38.13428498088457), (15, 15.172768187162292), (16, 50.58614569129759), (17, 50.865996916722956), (18, 56.00869290457802), (19, 57.3790587158438)])
IoU=0.85,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 41.40665238578583), (1, 39.25581414866425), (2, 29.811913970638233), (3, 19.45509960316186), (4, 13.864226163667299), (5, 59.59882252986143), (6, 50.80888536438781), (7, 55.94537724932469), (8, 11.502265412232326), (9, 39.231657168932955), (10, 29.04977945034134), (11, 46.97046738805467), (12, 39.100329515220736), (13, 31.69814666517132), (14, 22.766841879849615), (15, 6.876873947331418), (16, 37.72100405799806), (17, 37.29512856316261), (18, 40.967348046755), (19, 38.66232554922159)])
IoU=0.90,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 23.111537973986486), (1, 19.352540379099608), (2, 15.213455110065194), (3, 9.785539347273717), (4, 3.540509099362379), (5, 45.8678966724876), (6, 32.6160757575077), (7, 33.14011381724353), (8, 3.648813358402155), (9, 19.95637084042336), (10, 17.182760934544845), (11, 24.076493388430702), (12, 22.375708027258693), (13, 12.847084454194151), (14, 8.888142026470828), (15, 1.434705366780603), (16, 18.165963226229533), (17, 18.860218833581587), (18, 19.369439749022483), (19, 14.013616462595275)])
IoU=0.95,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 3.1627764639704647), (1, 3.801786248680782), (2, 2.766047563043463), (3, 0.18432066682673096), (4, 0.5352166761819319), (5, 9.9156758071494), (6, 7.0681965488855205), (7, 9.475622475203457), (8, 0.2970370751512205), (9, 3.4870007759567376), (10, 7.13225981898314), (11, 3.5489668273666584), (12, 3.6563587417529604), (13, 1.1699929539937741), (14, 0.9901206331258384), (15, 0.14474538266359827), (16, 2.937795647485247), (17, 2.9555151856710538), (18, 2.2210663907165062), (19, 1.7162470815803181)])

2022-04-30 13:38:36 - until epoch: 010, best_metric: 79.182%
2022-04-30 13:38:36 - epoch 011 lr: 1e-05
2022-04-30 13:39:11 - train: epoch 0011, iter [00100, 00517], lr: 0.000010, total_loss: 0.3248, cls_loss: 0.1402, reg_loss: 0.1845
2022-04-30 13:39:45 - train: epoch 0011, iter [00200, 00517], lr: 0.000010, total_loss: 0.2792, cls_loss: 0.1164, reg_loss: 0.1628
2022-04-30 13:40:19 - train: epoch 0011, iter [00300, 00517], lr: 0.000010, total_loss: 0.3116, cls_loss: 0.1407, reg_loss: 0.1709
2022-04-30 13:40:52 - train: epoch 0011, iter [00400, 00517], lr: 0.000010, total_loss: 0.2415, cls_loss: 0.1002, reg_loss: 0.1414
2022-04-30 13:41:26 - train: epoch 0011, iter [00500, 00517], lr: 0.000010, total_loss: 0.2730, cls_loss: 0.1208, reg_loss: 0.1522
2022-04-30 13:41:32 - train: epoch 011, train_loss: 0.2614
2022-04-30 13:41:33 - until epoch: 011, best_metric: 79.182%
2022-04-30 13:41:33 - epoch 012 lr: 1e-05
2022-04-30 13:42:07 - train: epoch 0012, iter [00100, 00517], lr: 0.000010, total_loss: 0.2507, cls_loss: 0.1010, reg_loss: 0.1497
2022-04-30 13:42:41 - train: epoch 0012, iter [00200, 00517], lr: 0.000010, total_loss: 0.2343, cls_loss: 0.0969, reg_loss: 0.1374
2022-04-30 13:43:15 - train: epoch 0012, iter [00300, 00517], lr: 0.000010, total_loss: 0.2105, cls_loss: 0.0860, reg_loss: 0.1245
2022-04-30 13:43:48 - train: epoch 0012, iter [00400, 00517], lr: 0.000010, total_loss: 0.3162, cls_loss: 0.1263, reg_loss: 0.1899
2022-04-30 13:44:22 - train: epoch 0012, iter [00500, 00517], lr: 0.000010, total_loss: 0.2742, cls_loss: 0.1175, reg_loss: 0.1567
2022-04-30 13:44:28 - train: epoch 012, train_loss: 0.2533
2022-04-30 13:46:43 - eval: epoch: 012
per_image_load_time: 1.633ms
per_image_inference_time: 15.823ms
IoU=0.50,area=all,maxDets=100,mAP: 79.69497381608296
IoU=0.55,area=all,maxDets=100,mAP: 77.62624054159978
IoU=0.60,area=all,maxDets=100,mAP: 75.13006176456925
IoU=0.65,area=all,maxDets=100,mAP: 70.91983012736549
IoU=0.70,area=all,maxDets=100,mAP: 64.9561047272467
IoU=0.75,area=all,maxDets=100,mAP: 57.25908898227201
IoU=0.80,area=all,maxDets=100,mAP: 47.96141436360449
IoU=0.85,area=all,maxDets=100,mAP: 35.40064548839655
IoU=0.90,area=all,maxDets=100,mAP: 19.29077562727398
IoU=0.95,area=all,maxDets=100,mAP: 3.421211193914462
IoU=0.50,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 82.61770849564644), (1, 88.38349757756474), (2, 83.22206819330485), (3, 72.09175571011329), (4, 65.39439616334441), (5, 85.29152017901056), (6, 88.70386584899069), (7, 90.6332617409783), (8, 60.284991856032875), (9, 83.86387968111417), (10, 72.50913113465406), (11, 89.74684248948638), (12, 85.31316480239217), (13, 84.5889133442704), (14, 85.52742472836964), (15, 55.17601009262273), (16, 80.24804079801781), (17, 72.55660395127627), (18, 85.41164641717867), (19, 82.3347531172909)])
IoU=0.55,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 80.47398899025094), (1, 85.88419363917271), (2, 80.77634356702849), (3, 68.72207524441937), (4, 62.2129977254798), (5, 84.01971940580847), (6, 87.7965346581013), (7, 90.0054907785071), (8, 56.7425835241987), (9, 81.77091291926163), (10, 71.00700155805217), (11, 88.55523347792112), (12, 84.84865040153655), (13, 81.78006757089621), (14, 82.30760887054191), (15, 50.67299162325058), (16, 78.84631556279501), (17, 70.8635796874054), (18, 83.91443469524629), (19, 81.32408693212182)])
IoU=0.60,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 78.0876352066459), (1, 82.5452367261749), (2, 77.57007839023831), (3, 64.18364881130873), (4, 59.00822426499659), (5, 82.05188492836598), (6, 85.9904232036603), (7, 88.08217764046485), (8, 53.76182738129496), (9, 80.90737149186604), (10, 69.79758472660032), (11, 86.05550352468698), (12, 81.31367963667925), (13, 79.43873099894037), (14, 78.04351829844771), (15, 45.72153962375624), (16, 77.85818338236297), (17, 69.05244849230951), (18, 82.65668997463698), (19, 80.47484858794844)])
IoU=0.65,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 73.37761400088378), (1, 78.23023497283035), (2, 71.43751015233451), (3, 56.149928238935274), (4, 54.57544982170106), (5, 79.96378993650247), (6, 81.76462334650898), (7, 86.26832594688234), (8, 48.718946609130334), (9, 78.30522260562809), (10, 62.838924348260846), (11, 82.50060816568734), (12, 76.15858790515941), (13, 75.84216803019551), (14, 71.28914517513951), (15, 40.33328559280302), (16, 74.58827395563985), (17, 66.50971414976097), (18, 80.65098848760155), (19, 78.89326110572455)])
IoU=0.70,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 67.42982142093385), (1, 71.00225719082623), (2, 62.74767897215918), (3, 48.00674472320048), (4, 47.91532396008426), (5, 77.28646777074735), (6, 77.73639654126087), (7, 81.21330425283642), (8, 40.766188274518676), (9, 70.5483511261471), (10, 55.8064822041697), (11, 78.44157764069293), (12, 70.59589328716464), (13, 68.10582178135175), (14, 63.01081964799015), (15, 34.288246145939866), (16, 71.03812519973066), (17, 62.87291072247837), (18, 75.77008264881265), (19, 74.53960103388893)])
IoU=0.75,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 61.68108018786245), (1, 63.122238182538496), (2, 53.4850576455107), (3, 39.103865890678414), (4, 36.5516657190978), (5, 74.56118715100047), (6, 70.71890805949066), (7, 73.31867574994455), (8, 32.86557154070509), (9, 64.93716029664587), (10, 47.9227131945943), (11, 70.77202280696181), (12, 58.773261291213444), (13, 62.11141083506463), (14, 51.10085907160015), (15, 24.51280772113651), (16, 62.39445768871388), (17, 60.640808210206785), (18, 67.91009697217012), (19, 68.69793143030441)])
IoU=0.80,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 56.333199000586816), (1, 52.96023929187981), (2, 40.68095523667521), (3, 30.438025024958115), (4, 23.031940473385408), (5, 70.73565754788842), (6, 62.643821057596405), (7, 67.30932980586822), (8, 21.899060111074835), (9, 54.13326772008631), (10, 40.391980682049436), (11, 62.6253866595894), (12, 49.898007890247996), (13, 48.760871202824404), (14, 38.216923900019985), (15, 15.865107041520176), (16, 50.21511304105586), (17, 53.93677306425949), (18, 59.020030346208664), (19, 60.132598174314936)])
IoU=0.85,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 41.07561408925524), (1, 38.36482125655768), (2, 30.428063842886555), (3, 19.871195149055968), (4, 12.069419804820553), (5, 60.62032143968601), (6, 51.547698091037006), (7, 55.841361844813676), (8, 11.78673780595564), (9, 38.04556873643643), (10, 27.415216892068873), (11, 48.26393315823904), (12, 39.50469933397317), (13, 33.8678070331077), (14, 23.38433256528375), (15, 6.830215715599039), (16, 40.83819612213437), (17, 45.066257377747505), (18, 43.46934433749725), (19, 39.72210517177556)])
IoU=0.90,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 25.301287863536043), (1, 21.33161188360285), (2, 17.314351952450615), (3, 9.239263320975976), (4, 3.8340788618460233), (5, 48.905439443392126), (6, 34.29355404900234), (7, 33.91904747527788), (8, 4.168409465589436), (9, 18.46642724889644), (10, 15.953038119142498), (11, 27.4048248886662), (12, 19.763987312427215), (13, 14.329423789254156), (14, 9.660432568739624), (15, 2.20175617570292), (16, 20.238173020901034), (17, 22.837920693019708), (18, 20.324139930082712), (19, 16.32834448297371)])
IoU=0.95,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 5.964653838333768), (1, 1.4627116112323344), (2, 3.3483389292463), (3, 0.2253024548818339), (4, 0.4732004929973336), (5, 12.208573052804782), (6, 7.080830557876896), (7, 8.864873882543392), (8, 0.2136450573819873), (9, 2.881337514855844), (10, 4.5981392062823), (11, 3.9715523061528133), (12, 3.68833768365018), (13, 1.3328235243926987), (14, 1.2301418651646596), (15, 0.21453765197835406), (16, 2.972681748641385), (17, 3.334897403972266), (18, 2.8412370611793083), (19, 1.5164080347207884)])

2022-04-30 13:46:43 - until epoch: 012, best_metric: 79.695%
2022-04-30 13:46:43 - epoch 013 lr: 1.0000000000000002e-06
2022-04-30 13:47:18 - train: epoch 0013, iter [00100, 00517], lr: 0.000001, total_loss: 0.2645, cls_loss: 0.1116, reg_loss: 0.1530
2022-04-30 13:47:52 - train: epoch 0013, iter [00200, 00517], lr: 0.000001, total_loss: 0.2347, cls_loss: 0.1000, reg_loss: 0.1347
2022-04-30 13:48:26 - train: epoch 0013, iter [00300, 00517], lr: 0.000001, total_loss: 0.2448, cls_loss: 0.0955, reg_loss: 0.1493
2022-04-30 13:49:00 - train: epoch 0013, iter [00400, 00517], lr: 0.000001, total_loss: 0.2793, cls_loss: 0.1144, reg_loss: 0.1648
2022-04-30 13:49:33 - train: epoch 0013, iter [00500, 00517], lr: 0.000001, total_loss: 0.2534, cls_loss: 0.1038, reg_loss: 0.1496
2022-04-30 13:49:39 - train: epoch 013, train_loss: 0.2468
2022-04-30 13:51:50 - eval: epoch: 013
per_image_load_time: 1.560ms
per_image_inference_time: 15.352ms
IoU=0.50,area=all,maxDets=100,mAP: 79.78329573799758
IoU=0.55,area=all,maxDets=100,mAP: 77.88480686637027
IoU=0.60,area=all,maxDets=100,mAP: 75.29119813205531
IoU=0.65,area=all,maxDets=100,mAP: 71.11378032284468
IoU=0.70,area=all,maxDets=100,mAP: 65.31691351245078
IoU=0.75,area=all,maxDets=100,mAP: 57.62433397185695
IoU=0.80,area=all,maxDets=100,mAP: 48.247317654182346
IoU=0.85,area=all,maxDets=100,mAP: 35.864358347238614
IoU=0.90,area=all,maxDets=100,mAP: 19.311557415087726
IoU=0.95,area=all,maxDets=100,mAP: 3.9138953683156927
IoU=0.50,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 82.87370143577758), (1, 87.9890362141632), (2, 83.59690431405143), (3, 71.53956957276277), (4, 66.30228672365733), (5, 86.29997744547934), (6, 88.71923348599272), (7, 92.02244149222622), (8, 60.65782160455059), (9, 81.95143825642323), (10, 72.75873041733965), (11, 89.58665193495585), (12, 85.71666355551399), (13, 85.37777869318575), (14, 85.87759963171496), (15, 54.566215318316594), (16, 80.24785646892872), (17, 71.45017151124281), (18, 85.48734036024037), (19, 82.64449632342865)])
IoU=0.55,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 80.57302786298686), (1, 86.41299192714963), (2, 81.21894544293853), (3, 68.84300779715548), (4, 63.32955329630322), (5, 84.52221554715493), (6, 87.58623202717978), (7, 91.28639025979895), (8, 57.47714953303809), (9, 80.42772732174606), (10, 71.60304734794062), (11, 88.2206340843211), (12, 85.14548108486089), (13, 83.27074112766411), (14, 82.59936286309915), (15, 50.978171333491964), (16, 78.15699354890798), (17, 70.43513221888479), (18, 84.23215536380931), (19, 81.3771773389739)])
IoU=0.60,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 77.35833270000599), (1, 83.43403773560645), (2, 77.98042823595375), (3, 63.54492492481476), (4, 59.664735397072576), (5, 82.77595938947975), (6, 85.98353530423464), (7, 89.77433885119605), (8, 54.29982256184612), (9, 79.37447885632822), (10, 69.31468239446703), (11, 86.56960533293503), (12, 82.11662246594858), (13, 80.71787333547415), (14, 78.43216983285768), (15, 46.64644926299881), (16, 76.64802655916168), (17, 68.40757417275428), (18, 82.86044539692594), (19, 79.91991993104477)])
IoU=0.65,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 73.55994326651954), (1, 78.21996989993478), (2, 72.02473084758093), (3, 56.04035512098927), (4, 54.62150846657163), (5, 81.44754749191156), (6, 82.01223664139827), (7, 87.11574233065613), (8, 48.44334761310763), (9, 77.4033984963438), (10, 65.36299058602289), (11, 82.40566092492007), (12, 76.71797690990817), (13, 76.57639241602844), (14, 72.21848885130606), (15, 40.577651459637366), (16, 74.1244808748385), (17, 64.74325944960412), (18, 80.6924905443757), (19, 77.96743426523834)])
IoU=0.70,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 68.04267629825533), (1, 71.57210157934976), (2, 62.467086090299105), (3, 48.485033171949254), (4, 47.724095978940255), (5, 78.68133836262928), (6, 77.21791479270891), (7, 83.18904912094615), (8, 41.16226809098603), (9, 70.91374328084004), (10, 56.363645066195936), (11, 77.40387173904428), (12, 72.33460738013014), (13, 70.23894975781896), (14, 63.89698922108712), (15, 34.016611332429804), (16, 70.82363348453137), (17, 61.18361704221355), (18, 75.5196304680753), (19, 75.1014079905848)])
IoU=0.75,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 62.31888054608463), (1, 63.28725349184765), (2, 54.25816350644803), (3, 38.44899632992177), (4, 38.334407298277846), (5, 75.89404163606996), (6, 71.52281211170477), (7, 75.7391360663525), (8, 32.68856641209356), (9, 64.38842441525604), (10, 48.193327007619544), (11, 70.22317030292973), (12, 60.55309261423416), (13, 62.539726635978155), (14, 52.06703753289401), (15, 24.269315389172558), (16, 61.82809877952402), (17, 58.64846651729485), (18, 69.15106163894077), (19, 68.13270120449452)])
IoU=0.80,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 56.467180517162284), (1, 54.7488708988187), (2, 42.54352174995677), (3, 30.98913440390524), (4, 23.754530239246186), (5, 71.38140932276191), (6, 63.6992009590736), (7, 68.25736011500706), (8, 22.793487870463778), (9, 51.686231919306046), (10, 41.03804928817602), (11, 60.76286367009893), (12, 51.47606748217514), (13, 50.92138502805743), (14, 38.861734685550374), (15, 15.879238599570972), (16, 50.22766647215251), (17, 51.550448663625495), (18, 57.06982728484971), (19, 60.838143913688846)])
IoU=0.85,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 42.832869393357356), (1, 39.18997378269291), (2, 30.75851286330745), (3, 20.242483222769195), (4, 14.74538572357605), (5, 61.83227704521479), (6, 51.6517688178349), (7, 56.72832948721307), (8, 12.097702833011958), (9, 36.14709587736568), (10, 30.00539714137485), (11, 48.73620337025065), (12, 40.23491117461659), (13, 34.33049903470483), (14, 23.750118625226214), (15, 7.310815313568986), (16, 40.07120446655744), (17, 46.046087478137466), (18, 41.04969833463484), (19, 39.525832959356954)])
IoU=0.90,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 24.954560304023275), (1, 20.997202776755312), (2, 18.21863314475392), (3, 9.790978907176292), (4, 3.7374356484341407), (5, 47.325432098414566), (6, 34.9179271714305), (7, 35.50214072091397), (8, 4.456962002092571), (9, 16.28295482165931), (10, 17.474925668447124), (11, 27.576781936403616), (12, 20.790310935810176), (13, 12.605645482484274), (14, 9.571432134868846), (15, 2.2668955625921354), (16, 19.866593786865984), (17, 20.633936826694043), (18, 21.424932442743465), (19, 17.83546592919099)])
IoU=0.95,area=all,maxDets=100,per_class_ap: OrderedDict([(0, 7.421719567237249), (1, 3.80396662044547), (2, 2.752115727375416), (3, 0.49716104172307307), (4, 0.23311589321799556), (5, 13.718435678662594), (6, 7.544562971992972), (7, 10.204329847631639), (8, 0.5172900590510662), (9, 3.597326090612099), (10, 5.4147592990298214), (11, 3.399840806613836), (12, 3.945474523573071), (13, 1.2210427295971473), (14, 1.2436056658010153), (15, 0.19474783623556632), (16, 3.242231361749991), (17, 3.3528821666903887), (18, 3.925245739059835), (19, 2.048053740013617)])

2022-04-30 13:51:51 - until epoch: 013, best_metric: 79.783%
2022-04-30 13:51:51 - train done. model: resnet50_retinanet, train time: 0.940 hours, best_metric: 79.783%
