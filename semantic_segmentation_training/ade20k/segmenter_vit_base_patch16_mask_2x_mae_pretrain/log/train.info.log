2022-10-15 23:54:19 - network: segmenter_vit_base_patch16_mask
2022-10-15 23:54:19 - input_image_size: 512
2022-10-15 23:54:19 - num_classes: 150
2022-10-15 23:54:19 - reduce_zero_label: True
2022-10-15 23:54:19 - ignore_index: 255
2022-10-15 23:54:19 - backbone_pretrained_path: /root/code/SimpleAICV-ImageNet-CIFAR-COCO-VOC-training/pretrained_models/masked_image_modeling_training/vit/mae-vit-base-patch16-224-epoch400-pretrain-model-loss0.388_encoder.pth
2022-10-15 23:54:19 - trained_model_path: 
2022-10-15 23:54:19 - loss_list: ['CELoss']
2022-10-15 23:54:19 - train_criterion: {'CELoss': CELoss(
  (softmax): Softmax(dim=-1)
)}
2022-10-15 23:54:19 - loss_name: CELoss
2022-10-15 23:54:19 - test_criterion: CELoss(
  (softmax): Softmax(dim=-1)
)
2022-10-15 23:54:19 - train_dataset: <simpleAICV.semantic_segmentation.datasets.ade20kdataset.ADE20KSemanticSegmentation object at 0x7f623c097100>
2022-10-15 23:54:19 - test_dataset: <simpleAICV.semantic_segmentation.datasets.ade20kdataset.ADE20KSemanticSegmentation object at 0x7f623c090eb0>
2022-10-15 23:54:19 - train_collater: <simpleAICV.semantic_segmentation.common.AlignResizeSemanticSegmentationCollater object at 0x7f623c090f10>
2022-10-15 23:54:19 - test_collater: <simpleAICV.semantic_segmentation.common.AlignResizeSemanticSegmentationCollater object at 0x7f623c090df0>
2022-10-15 23:54:19 - seed: 0
2022-10-15 23:54:19 - batch_size: 8
2022-10-15 23:54:19 - num_workers: 20
2022-10-15 23:54:19 - accumulation_steps: 1
2022-10-15 23:54:19 - optimizer: ('AdamW', {'lr': 0.0001, 'global_weight_decay': False, 'weight_decay': 0.001, 'no_weight_decay_layer_name_list': []})
2022-10-15 23:54:19 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [80, 110]})
2022-10-15 23:54:19 - epochs: 128
2022-10-15 23:54:19 - eval_epoch: [1, 0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125]
2022-10-15 23:54:19 - i: 127
2022-10-15 23:54:19 - print_interval: 100
2022-10-15 23:54:19 - save_model_metric: mean_iou
2022-10-15 23:54:19 - sync_bn: False
2022-10-15 23:54:19 - apex: True
2022-10-15 23:54:19 - use_ema_model: False
2022-10-15 23:54:19 - ema_model_decay: 0.9999
2022-10-15 23:54:19 - gpus_type: NVIDIA RTX A5000
2022-10-15 23:54:19 - gpus_num: 2
2022-10-15 23:54:19 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f623c084f70>
2022-10-15 23:54:19 - --------------------parameters--------------------
2022-10-15 23:54:19 - name: backbone.cls_token, grad: True
2022-10-15 23:54:19 - name: backbone.position_encoding, grad: True
2022-10-15 23:54:19 - name: backbone.patch_embedding.conv.weight, grad: True
2022-10-15 23:54:19 - name: backbone.patch_embedding.conv.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.0.norm1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.0.norm1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.0.attention.qkv_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.0.attention.qkv_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.0.attention.out_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.0.attention.out_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.0.norm2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.0.norm2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.0.feed_forward.fc1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.0.feed_forward.fc1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.0.feed_forward.fc2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.0.feed_forward.fc2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.1.norm1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.1.norm1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.1.attention.qkv_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.1.attention.qkv_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.1.attention.out_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.1.attention.out_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.1.norm2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.1.norm2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.1.feed_forward.fc1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.1.feed_forward.fc1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.1.feed_forward.fc2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.1.feed_forward.fc2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.2.norm1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.2.norm1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.2.attention.qkv_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.2.attention.qkv_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.2.attention.out_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.2.attention.out_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.2.norm2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.2.norm2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.2.feed_forward.fc1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.2.feed_forward.fc1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.2.feed_forward.fc2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.2.feed_forward.fc2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.3.norm1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.3.norm1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.3.attention.qkv_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.3.attention.qkv_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.3.attention.out_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.3.attention.out_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.3.norm2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.3.norm2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.3.feed_forward.fc1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.3.feed_forward.fc1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.3.feed_forward.fc2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.3.feed_forward.fc2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.4.norm1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.4.norm1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.4.attention.qkv_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.4.attention.qkv_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.4.attention.out_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.4.attention.out_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.4.norm2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.4.norm2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.4.feed_forward.fc1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.4.feed_forward.fc1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.4.feed_forward.fc2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.4.feed_forward.fc2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.5.norm1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.5.norm1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.5.attention.qkv_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.5.attention.qkv_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.5.attention.out_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.5.attention.out_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.5.norm2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.5.norm2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.5.feed_forward.fc1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.5.feed_forward.fc1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.5.feed_forward.fc2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.5.feed_forward.fc2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.6.norm1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.6.norm1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.6.attention.qkv_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.6.attention.qkv_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.6.attention.out_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.6.attention.out_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.6.norm2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.6.norm2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.6.feed_forward.fc1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.6.feed_forward.fc1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.6.feed_forward.fc2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.6.feed_forward.fc2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.7.norm1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.7.norm1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.7.attention.qkv_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.7.attention.qkv_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.7.attention.out_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.7.attention.out_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.7.norm2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.7.norm2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.7.feed_forward.fc1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.7.feed_forward.fc1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.7.feed_forward.fc2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.7.feed_forward.fc2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.8.norm1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.8.norm1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.8.attention.qkv_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.8.attention.qkv_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.8.attention.out_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.8.attention.out_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.8.norm2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.8.norm2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.8.feed_forward.fc1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.8.feed_forward.fc1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.8.feed_forward.fc2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.8.feed_forward.fc2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.9.norm1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.9.norm1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.9.attention.qkv_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.9.attention.qkv_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.9.attention.out_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.9.attention.out_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.9.norm2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.9.norm2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.9.feed_forward.fc1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.9.feed_forward.fc1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.9.feed_forward.fc2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.9.feed_forward.fc2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.10.norm1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.10.norm1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.10.attention.qkv_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.10.attention.qkv_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.10.attention.out_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.10.attention.out_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.10.norm2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.10.norm2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.10.feed_forward.fc1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.10.feed_forward.fc1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.10.feed_forward.fc2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.10.feed_forward.fc2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.11.norm1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.11.norm1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.11.attention.qkv_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.11.attention.qkv_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.11.attention.out_linear.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.11.attention.out_linear.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.11.norm2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.11.norm2.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.11.feed_forward.fc1.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.11.feed_forward.fc1.bias, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.11.feed_forward.fc2.weight, grad: True
2022-10-15 23:54:19 - name: backbone.blocks.11.feed_forward.fc2.bias, grad: True
2022-10-15 23:54:19 - name: head.cls_embedding, grad: True
2022-10-15 23:54:19 - name: head.proj_patch, grad: True
2022-10-15 23:54:19 - name: head.proj_classes, grad: True
2022-10-15 23:54:19 - name: head.blocks.0.norm1.weight, grad: True
2022-10-15 23:54:19 - name: head.blocks.0.norm1.bias, grad: True
2022-10-15 23:54:19 - name: head.blocks.0.attention.qkv_linear.weight, grad: True
2022-10-15 23:54:19 - name: head.blocks.0.attention.qkv_linear.bias, grad: True
2022-10-15 23:54:19 - name: head.blocks.0.attention.out_linear.weight, grad: True
2022-10-15 23:54:19 - name: head.blocks.0.attention.out_linear.bias, grad: True
2022-10-15 23:54:19 - name: head.blocks.0.norm2.weight, grad: True
2022-10-15 23:54:19 - name: head.blocks.0.norm2.bias, grad: True
2022-10-15 23:54:19 - name: head.blocks.0.feed_forward.fc1.weight, grad: True
2022-10-15 23:54:19 - name: head.blocks.0.feed_forward.fc1.bias, grad: True
2022-10-15 23:54:19 - name: head.blocks.0.feed_forward.fc2.weight, grad: True
2022-10-15 23:54:19 - name: head.blocks.0.feed_forward.fc2.bias, grad: True
2022-10-15 23:54:19 - name: head.blocks.1.norm1.weight, grad: True
2022-10-15 23:54:19 - name: head.blocks.1.norm1.bias, grad: True
2022-10-15 23:54:19 - name: head.blocks.1.attention.qkv_linear.weight, grad: True
2022-10-15 23:54:19 - name: head.blocks.1.attention.qkv_linear.bias, grad: True
2022-10-15 23:54:19 - name: head.blocks.1.attention.out_linear.weight, grad: True
2022-10-15 23:54:19 - name: head.blocks.1.attention.out_linear.bias, grad: True
2022-10-15 23:54:19 - name: head.blocks.1.norm2.weight, grad: True
2022-10-15 23:54:19 - name: head.blocks.1.norm2.bias, grad: True
2022-10-15 23:54:19 - name: head.blocks.1.feed_forward.fc1.weight, grad: True
2022-10-15 23:54:19 - name: head.blocks.1.feed_forward.fc1.bias, grad: True
2022-10-15 23:54:19 - name: head.blocks.1.feed_forward.fc2.weight, grad: True
2022-10-15 23:54:19 - name: head.blocks.1.feed_forward.fc2.bias, grad: True
2022-10-15 23:54:19 - name: head.block_norm.weight, grad: True
2022-10-15 23:54:19 - name: head.block_norm.bias, grad: True
2022-10-15 23:54:19 - name: head.decoder_linear.weight, grad: True
2022-10-15 23:54:19 - name: head.decoder_linear.bias, grad: True
2022-10-15 23:54:19 - name: head.mask_norm.weight, grad: True
2022-10-15 23:54:19 - name: head.mask_norm.bias, grad: True
2022-10-15 23:54:19 - --------------------buffers--------------------
2022-10-15 23:54:19 - -----------no weight decay layers--------------
2022-10-15 23:54:19 - name: backbone.patch_embedding.conv.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.2.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.2.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.2.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.2.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.2.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.2.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.2.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.2.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.3.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.3.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.3.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.3.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.3.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.3.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.3.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.3.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.4.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.4.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.4.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.4.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.4.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.4.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.4.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.4.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.5.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.5.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.5.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.5.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.5.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.5.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.5.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.5.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.6.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.6.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.6.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.6.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.6.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.6.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.6.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.6.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.7.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.7.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.7.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.7.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.7.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.7.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.7.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.7.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.8.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.8.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.8.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.8.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.8.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.8.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.8.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.8.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.9.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.9.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.9.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.9.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.9.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.9.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.9.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.9.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.10.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.10.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.10.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.10.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.10.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.10.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.10.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.10.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.11.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.11.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.11.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.11.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.11.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.11.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.11.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.11.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.0.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.0.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.0.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.0.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.0.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.0.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.0.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.0.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.1.norm1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.1.norm1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.1.attention.qkv_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.1.attention.out_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.1.norm2.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.1.norm2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.1.feed_forward.fc1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.1.feed_forward.fc2.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.block_norm.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.block_norm.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.decoder_linear.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.mask_norm.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.mask_norm.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-15 23:54:19 - -------------weight decay layers---------------
2022-10-15 23:54:19 - name: backbone.cls_token, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.position_encoding, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.patch_embedding.conv.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.0.attention.qkv_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.0.attention.out_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.0.feed_forward.fc1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.0.feed_forward.fc2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.1.attention.qkv_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.1.attention.out_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.1.feed_forward.fc1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.1.feed_forward.fc2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.2.attention.qkv_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.2.attention.out_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.2.feed_forward.fc1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.2.feed_forward.fc2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.3.attention.qkv_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.3.attention.out_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.3.feed_forward.fc1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.3.feed_forward.fc2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.4.attention.qkv_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.4.attention.out_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.4.feed_forward.fc1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.4.feed_forward.fc2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.5.attention.qkv_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.5.attention.out_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.5.feed_forward.fc1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.5.feed_forward.fc2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.6.attention.qkv_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.6.attention.out_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.6.feed_forward.fc1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.6.feed_forward.fc2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.7.attention.qkv_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.7.attention.out_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.7.feed_forward.fc1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.7.feed_forward.fc2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.8.attention.qkv_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.8.attention.out_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.8.feed_forward.fc1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.8.feed_forward.fc2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.9.attention.qkv_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.9.attention.out_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.9.feed_forward.fc1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.9.feed_forward.fc2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.10.attention.qkv_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.10.attention.out_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.10.feed_forward.fc1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.10.feed_forward.fc2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.11.attention.qkv_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.11.attention.out_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.11.feed_forward.fc1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: backbone.blocks.11.feed_forward.fc2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.cls_embedding, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.proj_patch, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.proj_classes, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.0.attention.qkv_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.0.attention.out_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.0.feed_forward.fc1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.0.feed_forward.fc2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.1.attention.qkv_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.1.attention.out_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.1.feed_forward.fc1.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.blocks.1.feed_forward.fc2.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - name: head.decoder_linear.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-15 23:54:19 - epoch 001 lr: 0.000100
2022-10-15 23:54:57 - train: epoch 0001, iter [00100, 02526], lr: 0.000100, loss: 3.6737, CELoss: 3.6737, 
2022-10-15 23:55:31 - train: epoch 0001, iter [00200, 02526], lr: 0.000100, loss: 3.4325, CELoss: 3.4325, 
2022-10-15 23:56:05 - train: epoch 0001, iter [00300, 02526], lr: 0.000100, loss: 3.4040, CELoss: 3.4040, 
2022-10-15 23:56:39 - train: epoch 0001, iter [00400, 02526], lr: 0.000100, loss: 3.6242, CELoss: 3.6242, 
2022-10-15 23:57:12 - train: epoch 0001, iter [00500, 02526], lr: 0.000100, loss: 3.8056, CELoss: 3.8056, 
2022-10-15 23:57:46 - train: epoch 0001, iter [00600, 02526], lr: 0.000100, loss: 3.1317, CELoss: 3.1317, 
2022-10-15 23:58:20 - train: epoch 0001, iter [00700, 02526], lr: 0.000100, loss: 2.4633, CELoss: 2.4633, 
2022-10-15 23:58:53 - train: epoch 0001, iter [00800, 02526], lr: 0.000100, loss: 2.5881, CELoss: 2.5881, 
2022-10-15 23:59:27 - train: epoch 0001, iter [00900, 02526], lr: 0.000100, loss: 2.0620, CELoss: 2.0620, 
2022-10-16 00:00:01 - train: epoch 0001, iter [01000, 02526], lr: 0.000100, loss: 2.7241, CELoss: 2.7241, 
2022-10-16 00:00:34 - train: epoch 0001, iter [01100, 02526], lr: 0.000100, loss: 1.8193, CELoss: 1.8193, 
2022-10-16 00:01:08 - train: epoch 0001, iter [01200, 02526], lr: 0.000100, loss: 2.7268, CELoss: 2.7268, 
2022-10-16 00:01:41 - train: epoch 0001, iter [01300, 02526], lr: 0.000100, loss: 2.7927, CELoss: 2.7927, 
2022-10-16 00:02:15 - train: epoch 0001, iter [01400, 02526], lr: 0.000100, loss: 2.3285, CELoss: 2.3285, 
2022-10-16 00:02:49 - train: epoch 0001, iter [01500, 02526], lr: 0.000100, loss: 1.7765, CELoss: 1.7765, 
2022-10-16 00:03:22 - train: epoch 0001, iter [01600, 02526], lr: 0.000100, loss: 1.4883, CELoss: 1.4883, 
2022-10-16 00:03:56 - train: epoch 0001, iter [01700, 02526], lr: 0.000100, loss: 2.0186, CELoss: 2.0186, 
2022-10-16 00:04:29 - train: epoch 0001, iter [01800, 02526], lr: 0.000100, loss: 1.6740, CELoss: 1.6740, 
2022-10-16 00:05:03 - train: epoch 0001, iter [01900, 02526], lr: 0.000100, loss: 1.7941, CELoss: 1.7941, 
2022-10-16 00:05:37 - train: epoch 0001, iter [02000, 02526], lr: 0.000100, loss: 1.7761, CELoss: 1.7761, 
2022-10-16 00:06:10 - train: epoch 0001, iter [02100, 02526], lr: 0.000100, loss: 2.3448, CELoss: 2.3448, 
2022-10-16 00:06:44 - train: epoch 0001, iter [02200, 02526], lr: 0.000100, loss: 1.7384, CELoss: 1.7384, 
2022-10-16 00:07:17 - train: epoch 0001, iter [02300, 02526], lr: 0.000100, loss: 1.7064, CELoss: 1.7064, 
2022-10-16 00:07:51 - train: epoch 0001, iter [02400, 02526], lr: 0.000100, loss: 1.6745, CELoss: 1.6745, 
2022-10-16 00:08:24 - train: epoch 0001, iter [02500, 02526], lr: 0.000100, loss: 1.9128, CELoss: 1.9128, 
2022-10-16 00:08:34 - train: epoch 001, train_loss: 2.4387
2022-10-16 00:09:25 - eval: epoch: 001
test_loss: 1.7003348502516746
per_image_load_time: 1.009ms
per_image_inference_time: 18.226ms
exist_num_class: 150.0
mean_precision: 14.423955528874934
mean_recall: 9.29454402246782
mean_iou: 6.317592683159193
mean_dice: 8.989220834915395

2022-10-16 00:09:27 - until epoch: 001, best_metric: 6.318%
2022-10-16 00:09:27 - epoch 002 lr: 0.000100
2022-10-16 00:10:03 - train: epoch 0002, iter [00100, 02526], lr: 0.000100, loss: 2.3943, CELoss: 2.3943, 
2022-10-16 00:10:36 - train: epoch 0002, iter [00200, 02526], lr: 0.000100, loss: 1.3128, CELoss: 1.3128, 
2022-10-16 00:11:09 - train: epoch 0002, iter [00300, 02526], lr: 0.000100, loss: 1.6174, CELoss: 1.6174, 
2022-10-16 00:11:43 - train: epoch 0002, iter [00400, 02526], lr: 0.000100, loss: 1.3787, CELoss: 1.3787, 
2022-10-16 00:12:16 - train: epoch 0002, iter [00500, 02526], lr: 0.000100, loss: 2.0204, CELoss: 2.0204, 
2022-10-16 00:12:50 - train: epoch 0002, iter [00600, 02526], lr: 0.000100, loss: 1.9165, CELoss: 1.9165, 
2022-10-16 00:13:23 - train: epoch 0002, iter [00700, 02526], lr: 0.000100, loss: 2.8527, CELoss: 2.8527, 
2022-10-16 00:13:57 - train: epoch 0002, iter [00800, 02526], lr: 0.000100, loss: 1.7019, CELoss: 1.7019, 
2022-10-16 00:14:30 - train: epoch 0002, iter [00900, 02526], lr: 0.000100, loss: 1.8165, CELoss: 1.8165, 
2022-10-16 00:15:04 - train: epoch 0002, iter [01000, 02526], lr: 0.000100, loss: 1.3795, CELoss: 1.3795, 
2022-10-16 00:15:37 - train: epoch 0002, iter [01100, 02526], lr: 0.000100, loss: 1.6280, CELoss: 1.6280, 
2022-10-16 00:16:11 - train: epoch 0002, iter [01200, 02526], lr: 0.000100, loss: 1.6306, CELoss: 1.6306, 
2022-10-16 00:16:44 - train: epoch 0002, iter [01300, 02526], lr: 0.000100, loss: 1.6332, CELoss: 1.6332, 
2022-10-16 00:17:18 - train: epoch 0002, iter [01400, 02526], lr: 0.000100, loss: 1.0806, CELoss: 1.0806, 
2022-10-16 00:17:51 - train: epoch 0002, iter [01500, 02526], lr: 0.000100, loss: 1.9389, CELoss: 1.9389, 
2022-10-16 00:18:25 - train: epoch 0002, iter [01600, 02526], lr: 0.000100, loss: 1.2001, CELoss: 1.2001, 
2022-10-16 00:18:58 - train: epoch 0002, iter [01700, 02526], lr: 0.000100, loss: 1.4382, CELoss: 1.4382, 
2022-10-16 00:19:31 - train: epoch 0002, iter [01800, 02526], lr: 0.000100, loss: 1.4208, CELoss: 1.4208, 
2022-10-16 00:20:04 - train: epoch 0002, iter [01900, 02526], lr: 0.000100, loss: 1.6462, CELoss: 1.6462, 
2022-10-16 00:20:38 - train: epoch 0002, iter [02000, 02526], lr: 0.000100, loss: 1.6488, CELoss: 1.6488, 
2022-10-16 00:21:12 - train: epoch 0002, iter [02100, 02526], lr: 0.000100, loss: 1.8241, CELoss: 1.8241, 
2022-10-16 00:21:45 - train: epoch 0002, iter [02200, 02526], lr: 0.000100, loss: 1.4254, CELoss: 1.4254, 
2022-10-16 00:22:19 - train: epoch 0002, iter [02300, 02526], lr: 0.000100, loss: 1.5330, CELoss: 1.5330, 
2022-10-16 00:22:52 - train: epoch 0002, iter [02400, 02526], lr: 0.000100, loss: 2.0637, CELoss: 2.0637, 
2022-10-16 00:23:26 - train: epoch 0002, iter [02500, 02526], lr: 0.000100, loss: 1.6383, CELoss: 1.6383, 
2022-10-16 00:23:36 - train: epoch 002, train_loss: 1.6294
2022-10-16 00:23:38 - until epoch: 002, best_metric: 6.318%
2022-10-16 00:23:38 - epoch 003 lr: 0.000100
2022-10-16 00:24:15 - train: epoch 0003, iter [00100, 02526], lr: 0.000100, loss: 1.3544, CELoss: 1.3544, 
2022-10-16 00:24:48 - train: epoch 0003, iter [00200, 02526], lr: 0.000100, loss: 2.1316, CELoss: 2.1316, 
2022-10-16 00:25:22 - train: epoch 0003, iter [00300, 02526], lr: 0.000100, loss: 1.9453, CELoss: 1.9453, 
2022-10-16 00:25:56 - train: epoch 0003, iter [00400, 02526], lr: 0.000100, loss: 1.2334, CELoss: 1.2334, 
2022-10-16 00:26:29 - train: epoch 0003, iter [00500, 02526], lr: 0.000100, loss: 1.4180, CELoss: 1.4180, 
2022-10-16 00:27:03 - train: epoch 0003, iter [00600, 02526], lr: 0.000100, loss: 0.9706, CELoss: 0.9706, 
2022-10-16 00:27:37 - train: epoch 0003, iter [00700, 02526], lr: 0.000100, loss: 1.2431, CELoss: 1.2431, 
2022-10-16 00:28:11 - train: epoch 0003, iter [00800, 02526], lr: 0.000100, loss: 1.3198, CELoss: 1.3198, 
2022-10-16 00:28:44 - train: epoch 0003, iter [00900, 02526], lr: 0.000100, loss: 1.0751, CELoss: 1.0751, 
2022-10-16 00:29:18 - train: epoch 0003, iter [01000, 02526], lr: 0.000100, loss: 1.0771, CELoss: 1.0771, 
2022-10-16 00:29:51 - train: epoch 0003, iter [01100, 02526], lr: 0.000100, loss: 1.7708, CELoss: 1.7708, 
2022-10-16 00:30:25 - train: epoch 0003, iter [01200, 02526], lr: 0.000100, loss: 1.3713, CELoss: 1.3713, 
2022-10-16 00:30:58 - train: epoch 0003, iter [01300, 02526], lr: 0.000100, loss: 1.1536, CELoss: 1.1536, 
2022-10-16 00:31:32 - train: epoch 0003, iter [01400, 02526], lr: 0.000100, loss: 1.1365, CELoss: 1.1365, 
2022-10-16 00:32:06 - train: epoch 0003, iter [01500, 02526], lr: 0.000100, loss: 1.1878, CELoss: 1.1878, 
2022-10-16 00:32:39 - train: epoch 0003, iter [01600, 02526], lr: 0.000100, loss: 1.5318, CELoss: 1.5318, 
2022-10-16 00:33:13 - train: epoch 0003, iter [01700, 02526], lr: 0.000100, loss: 1.3265, CELoss: 1.3265, 
2022-10-16 00:33:46 - train: epoch 0003, iter [01800, 02526], lr: 0.000100, loss: 1.0102, CELoss: 1.0102, 
2022-10-16 00:34:20 - train: epoch 0003, iter [01900, 02526], lr: 0.000100, loss: 1.5189, CELoss: 1.5189, 
2022-10-16 00:34:53 - train: epoch 0003, iter [02000, 02526], lr: 0.000100, loss: 2.1334, CELoss: 2.1334, 
2022-10-16 00:35:26 - train: epoch 0003, iter [02100, 02526], lr: 0.000100, loss: 1.2752, CELoss: 1.2752, 
2022-10-16 00:36:00 - train: epoch 0003, iter [02200, 02526], lr: 0.000100, loss: 1.6744, CELoss: 1.6744, 
2022-10-16 00:36:33 - train: epoch 0003, iter [02300, 02526], lr: 0.000100, loss: 1.4334, CELoss: 1.4334, 
2022-10-16 00:37:07 - train: epoch 0003, iter [02400, 02526], lr: 0.000100, loss: 1.5578, CELoss: 1.5578, 
2022-10-16 00:37:41 - train: epoch 0003, iter [02500, 02526], lr: 0.000100, loss: 1.9573, CELoss: 1.9573, 
2022-10-16 00:37:50 - train: epoch 003, train_loss: 1.4026
2022-10-16 00:37:53 - until epoch: 003, best_metric: 6.318%
2022-10-16 00:37:53 - epoch 004 lr: 0.000100
2022-10-16 00:38:28 - train: epoch 0004, iter [00100, 02526], lr: 0.000100, loss: 1.6649, CELoss: 1.6649, 
2022-10-16 00:39:02 - train: epoch 0004, iter [00200, 02526], lr: 0.000100, loss: 1.2791, CELoss: 1.2791, 
2022-10-16 00:39:36 - train: epoch 0004, iter [00300, 02526], lr: 0.000100, loss: 0.5422, CELoss: 0.5422, 
2022-10-16 00:40:09 - train: epoch 0004, iter [00400, 02526], lr: 0.000100, loss: 1.6650, CELoss: 1.6650, 
2022-10-16 00:40:43 - train: epoch 0004, iter [00500, 02526], lr: 0.000100, loss: 0.7605, CELoss: 0.7605, 
2022-10-16 00:41:17 - train: epoch 0004, iter [00600, 02526], lr: 0.000100, loss: 1.7484, CELoss: 1.7484, 
2022-10-16 00:41:50 - train: epoch 0004, iter [00700, 02526], lr: 0.000100, loss: 1.3625, CELoss: 1.3625, 
2022-10-16 00:42:24 - train: epoch 0004, iter [00800, 02526], lr: 0.000100, loss: 1.2435, CELoss: 1.2435, 
2022-10-16 00:42:57 - train: epoch 0004, iter [00900, 02526], lr: 0.000100, loss: 1.0464, CELoss: 1.0464, 
2022-10-16 00:43:30 - train: epoch 0004, iter [01000, 02526], lr: 0.000100, loss: 1.9148, CELoss: 1.9148, 
2022-10-16 00:44:04 - train: epoch 0004, iter [01100, 02526], lr: 0.000100, loss: 1.6486, CELoss: 1.6486, 
2022-10-16 00:44:37 - train: epoch 0004, iter [01200, 02526], lr: 0.000100, loss: 1.6251, CELoss: 1.6251, 
2022-10-16 00:45:11 - train: epoch 0004, iter [01300, 02526], lr: 0.000100, loss: 1.6852, CELoss: 1.6852, 
2022-10-16 00:45:44 - train: epoch 0004, iter [01400, 02526], lr: 0.000100, loss: 1.9135, CELoss: 1.9135, 
2022-10-16 00:46:18 - train: epoch 0004, iter [01500, 02526], lr: 0.000100, loss: 0.9034, CELoss: 0.9034, 
2022-10-16 00:46:52 - train: epoch 0004, iter [01600, 02526], lr: 0.000100, loss: 1.2921, CELoss: 1.2921, 
2022-10-16 00:47:25 - train: epoch 0004, iter [01700, 02526], lr: 0.000100, loss: 1.7704, CELoss: 1.7704, 
2022-10-16 00:47:58 - train: epoch 0004, iter [01800, 02526], lr: 0.000100, loss: 2.4289, CELoss: 2.4289, 
2022-10-16 00:48:32 - train: epoch 0004, iter [01900, 02526], lr: 0.000100, loss: 1.4395, CELoss: 1.4395, 
2022-10-16 00:49:06 - train: epoch 0004, iter [02000, 02526], lr: 0.000100, loss: 1.3072, CELoss: 1.3072, 
2022-10-16 00:49:39 - train: epoch 0004, iter [02100, 02526], lr: 0.000100, loss: 0.9678, CELoss: 0.9678, 
2022-10-16 00:50:13 - train: epoch 0004, iter [02200, 02526], lr: 0.000100, loss: 0.9517, CELoss: 0.9517, 
2022-10-16 00:50:46 - train: epoch 0004, iter [02300, 02526], lr: 0.000100, loss: 0.7365, CELoss: 0.7365, 
2022-10-16 00:51:20 - train: epoch 0004, iter [02400, 02526], lr: 0.000100, loss: 1.1929, CELoss: 1.1929, 
2022-10-16 00:51:53 - train: epoch 0004, iter [02500, 02526], lr: 0.000100, loss: 0.8590, CELoss: 0.8590, 
2022-10-16 00:52:03 - train: epoch 004, train_loss: 1.2853
2022-10-16 00:52:05 - until epoch: 004, best_metric: 6.318%
2022-10-16 00:52:05 - epoch 005 lr: 0.000100
2022-10-16 00:52:41 - train: epoch 0005, iter [00100, 02526], lr: 0.000100, loss: 1.1471, CELoss: 1.1471, 
2022-10-16 00:53:15 - train: epoch 0005, iter [00200, 02526], lr: 0.000100, loss: 1.7022, CELoss: 1.7022, 
2022-10-16 00:53:48 - train: epoch 0005, iter [00300, 02526], lr: 0.000100, loss: 1.3467, CELoss: 1.3467, 
2022-10-16 00:54:21 - train: epoch 0005, iter [00400, 02526], lr: 0.000100, loss: 1.0513, CELoss: 1.0513, 
2022-10-16 00:54:55 - train: epoch 0005, iter [00500, 02526], lr: 0.000100, loss: 0.7298, CELoss: 0.7298, 
2022-10-16 00:55:28 - train: epoch 0005, iter [00600, 02526], lr: 0.000100, loss: 1.3742, CELoss: 1.3742, 
2022-10-16 00:56:01 - train: epoch 0005, iter [00700, 02526], lr: 0.000100, loss: 1.4890, CELoss: 1.4890, 
2022-10-16 00:56:35 - train: epoch 0005, iter [00800, 02526], lr: 0.000100, loss: 1.4958, CELoss: 1.4958, 
2022-10-16 00:57:09 - train: epoch 0005, iter [00900, 02526], lr: 0.000100, loss: 0.7733, CELoss: 0.7733, 
2022-10-16 00:57:42 - train: epoch 0005, iter [01000, 02526], lr: 0.000100, loss: 1.8487, CELoss: 1.8487, 
2022-10-16 00:58:16 - train: epoch 0005, iter [01100, 02526], lr: 0.000100, loss: 1.6769, CELoss: 1.6769, 
2022-10-16 00:58:49 - train: epoch 0005, iter [01200, 02526], lr: 0.000100, loss: 1.2270, CELoss: 1.2270, 
2022-10-16 00:59:22 - train: epoch 0005, iter [01300, 02526], lr: 0.000100, loss: 1.3034, CELoss: 1.3034, 
2022-10-16 00:59:56 - train: epoch 0005, iter [01400, 02526], lr: 0.000100, loss: 1.2680, CELoss: 1.2680, 
2022-10-16 01:00:29 - train: epoch 0005, iter [01500, 02526], lr: 0.000100, loss: 1.8462, CELoss: 1.8462, 
2022-10-16 01:01:02 - train: epoch 0005, iter [01600, 02526], lr: 0.000100, loss: 1.0353, CELoss: 1.0353, 
2022-10-16 01:01:36 - train: epoch 0005, iter [01700, 02526], lr: 0.000100, loss: 1.2011, CELoss: 1.2011, 
2022-10-16 01:02:09 - train: epoch 0005, iter [01800, 02526], lr: 0.000100, loss: 0.5841, CELoss: 0.5841, 
2022-10-16 01:02:42 - train: epoch 0005, iter [01900, 02526], lr: 0.000100, loss: 1.3444, CELoss: 1.3444, 
2022-10-16 01:03:16 - train: epoch 0005, iter [02000, 02526], lr: 0.000100, loss: 1.0165, CELoss: 1.0165, 
2022-10-16 01:03:49 - train: epoch 0005, iter [02100, 02526], lr: 0.000100, loss: 1.3906, CELoss: 1.3906, 
2022-10-16 01:04:23 - train: epoch 0005, iter [02200, 02526], lr: 0.000100, loss: 1.1354, CELoss: 1.1354, 
2022-10-16 01:04:56 - train: epoch 0005, iter [02300, 02526], lr: 0.000100, loss: 0.9822, CELoss: 0.9822, 
2022-10-16 01:05:30 - train: epoch 0005, iter [02400, 02526], lr: 0.000100, loss: 1.1269, CELoss: 1.1269, 
2022-10-16 01:06:03 - train: epoch 0005, iter [02500, 02526], lr: 0.000100, loss: 1.1076, CELoss: 1.1076, 
2022-10-16 01:06:14 - train: epoch 005, train_loss: 1.2090
2022-10-16 01:07:04 - eval: epoch: 005
test_loss: 1.1493262653648852
per_image_load_time: 1.045ms
per_image_inference_time: 18.276ms
exist_num_class: 150.0
mean_precision: 39.17715593948618
mean_recall: 26.97511309540786
mean_iou: 19.264759627594362
mean_dice: 28.002927256272216

2022-10-16 01:07:07 - until epoch: 005, best_metric: 19.265%
2022-10-16 01:07:07 - epoch 006 lr: 0.000100
2022-10-16 01:07:43 - train: epoch 0006, iter [00100, 02526], lr: 0.000100, loss: 1.0165, CELoss: 1.0165, 
2022-10-16 01:08:17 - train: epoch 0006, iter [00200, 02526], lr: 0.000100, loss: 0.9562, CELoss: 0.9562, 
2022-10-16 01:08:50 - train: epoch 0006, iter [00300, 02526], lr: 0.000100, loss: 0.9867, CELoss: 0.9867, 
2022-10-16 01:09:24 - train: epoch 0006, iter [00400, 02526], lr: 0.000100, loss: 0.7670, CELoss: 0.7670, 
2022-10-16 01:09:57 - train: epoch 0006, iter [00500, 02526], lr: 0.000100, loss: 1.5371, CELoss: 1.5371, 
2022-10-16 01:10:30 - train: epoch 0006, iter [00600, 02526], lr: 0.000100, loss: 1.3846, CELoss: 1.3846, 
2022-10-16 01:11:03 - train: epoch 0006, iter [00700, 02526], lr: 0.000100, loss: 0.9745, CELoss: 0.9745, 
2022-10-16 01:11:37 - train: epoch 0006, iter [00800, 02526], lr: 0.000100, loss: 1.1336, CELoss: 1.1336, 
2022-10-16 01:12:11 - train: epoch 0006, iter [00900, 02526], lr: 0.000100, loss: 0.9255, CELoss: 0.9255, 
2022-10-16 01:12:44 - train: epoch 0006, iter [01000, 02526], lr: 0.000100, loss: 1.3461, CELoss: 1.3461, 
2022-10-16 01:13:18 - train: epoch 0006, iter [01100, 02526], lr: 0.000100, loss: 1.2379, CELoss: 1.2379, 
2022-10-16 01:13:51 - train: epoch 0006, iter [01200, 02526], lr: 0.000100, loss: 1.1941, CELoss: 1.1941, 
2022-10-16 01:14:24 - train: epoch 0006, iter [01300, 02526], lr: 0.000100, loss: 1.2872, CELoss: 1.2872, 
2022-10-16 01:14:58 - train: epoch 0006, iter [01400, 02526], lr: 0.000100, loss: 1.0698, CELoss: 1.0698, 
2022-10-16 01:15:31 - train: epoch 0006, iter [01500, 02526], lr: 0.000100, loss: 1.2364, CELoss: 1.2364, 
2022-10-16 01:16:05 - train: epoch 0006, iter [01600, 02526], lr: 0.000100, loss: 1.5352, CELoss: 1.5352, 
2022-10-16 01:16:38 - train: epoch 0006, iter [01700, 02526], lr: 0.000100, loss: 1.7943, CELoss: 1.7943, 
2022-10-16 01:17:12 - train: epoch 0006, iter [01800, 02526], lr: 0.000100, loss: 1.0394, CELoss: 1.0394, 
2022-10-16 01:17:45 - train: epoch 0006, iter [01900, 02526], lr: 0.000100, loss: 1.6859, CELoss: 1.6859, 
2022-10-16 01:18:19 - train: epoch 0006, iter [02000, 02526], lr: 0.000100, loss: 0.7038, CELoss: 0.7038, 
2022-10-16 01:18:52 - train: epoch 0006, iter [02100, 02526], lr: 0.000100, loss: 1.3356, CELoss: 1.3356, 
2022-10-16 01:19:26 - train: epoch 0006, iter [02200, 02526], lr: 0.000100, loss: 0.9048, CELoss: 0.9048, 
2022-10-16 01:19:59 - train: epoch 0006, iter [02300, 02526], lr: 0.000100, loss: 1.2252, CELoss: 1.2252, 
2022-10-16 01:20:32 - train: epoch 0006, iter [02400, 02526], lr: 0.000100, loss: 0.9803, CELoss: 0.9803, 
2022-10-16 01:21:06 - train: epoch 0006, iter [02500, 02526], lr: 0.000100, loss: 1.7725, CELoss: 1.7725, 
2022-10-16 01:21:16 - train: epoch 006, train_loss: 1.1484
2022-10-16 01:21:18 - until epoch: 006, best_metric: 19.265%
2022-10-16 01:21:18 - epoch 007 lr: 0.000100
2022-10-16 01:21:54 - train: epoch 0007, iter [00100, 02526], lr: 0.000100, loss: 0.9401, CELoss: 0.9401, 
2022-10-16 01:22:27 - train: epoch 0007, iter [00200, 02526], lr: 0.000100, loss: 1.1568, CELoss: 1.1568, 
2022-10-16 01:23:00 - train: epoch 0007, iter [00300, 02526], lr: 0.000100, loss: 0.8309, CELoss: 0.8309, 
2022-10-16 01:23:34 - train: epoch 0007, iter [00400, 02526], lr: 0.000100, loss: 1.2627, CELoss: 1.2627, 
2022-10-16 01:24:08 - train: epoch 0007, iter [00500, 02526], lr: 0.000100, loss: 0.8733, CELoss: 0.8733, 
2022-10-16 01:24:41 - train: epoch 0007, iter [00600, 02526], lr: 0.000100, loss: 0.8909, CELoss: 0.8909, 
2022-10-16 01:25:15 - train: epoch 0007, iter [00700, 02526], lr: 0.000100, loss: 0.8718, CELoss: 0.8718, 
2022-10-16 01:25:49 - train: epoch 0007, iter [00800, 02526], lr: 0.000100, loss: 1.0378, CELoss: 1.0378, 
2022-10-16 01:26:22 - train: epoch 0007, iter [00900, 02526], lr: 0.000100, loss: 0.8286, CELoss: 0.8286, 
2022-10-16 01:26:56 - train: epoch 0007, iter [01000, 02526], lr: 0.000100, loss: 1.3617, CELoss: 1.3617, 
2022-10-16 01:27:29 - train: epoch 0007, iter [01100, 02526], lr: 0.000100, loss: 1.2512, CELoss: 1.2512, 
2022-10-16 01:28:03 - train: epoch 0007, iter [01200, 02526], lr: 0.000100, loss: 0.9372, CELoss: 0.9372, 
2022-10-16 01:28:36 - train: epoch 0007, iter [01300, 02526], lr: 0.000100, loss: 1.0944, CELoss: 1.0944, 
2022-10-16 01:29:10 - train: epoch 0007, iter [01400, 02526], lr: 0.000100, loss: 1.1432, CELoss: 1.1432, 
2022-10-16 01:29:43 - train: epoch 0007, iter [01500, 02526], lr: 0.000100, loss: 1.1321, CELoss: 1.1321, 
2022-10-16 01:30:17 - train: epoch 0007, iter [01600, 02526], lr: 0.000100, loss: 1.1072, CELoss: 1.1072, 
2022-10-16 01:30:50 - train: epoch 0007, iter [01700, 02526], lr: 0.000100, loss: 1.5810, CELoss: 1.5810, 
2022-10-16 01:31:24 - train: epoch 0007, iter [01800, 02526], lr: 0.000100, loss: 0.7976, CELoss: 0.7976, 
2022-10-16 01:31:57 - train: epoch 0007, iter [01900, 02526], lr: 0.000100, loss: 1.0809, CELoss: 1.0809, 
2022-10-16 01:32:31 - train: epoch 0007, iter [02000, 02526], lr: 0.000100, loss: 0.8398, CELoss: 0.8398, 
2022-10-16 01:33:04 - train: epoch 0007, iter [02100, 02526], lr: 0.000100, loss: 0.5724, CELoss: 0.5724, 
2022-10-16 01:33:38 - train: epoch 0007, iter [02200, 02526], lr: 0.000100, loss: 1.3454, CELoss: 1.3454, 
2022-10-16 01:34:11 - train: epoch 0007, iter [02300, 02526], lr: 0.000100, loss: 1.4899, CELoss: 1.4899, 
2022-10-16 01:34:45 - train: epoch 0007, iter [02400, 02526], lr: 0.000100, loss: 0.6933, CELoss: 0.6933, 
2022-10-16 01:35:18 - train: epoch 0007, iter [02500, 02526], lr: 0.000100, loss: 1.1619, CELoss: 1.1619, 
2022-10-16 01:35:28 - train: epoch 007, train_loss: 1.1071
2022-10-16 01:35:30 - until epoch: 007, best_metric: 19.265%
2022-10-16 01:35:30 - epoch 008 lr: 0.000100
2022-10-16 01:36:06 - train: epoch 0008, iter [00100, 02526], lr: 0.000100, loss: 0.7296, CELoss: 0.7296, 
2022-10-16 01:36:39 - train: epoch 0008, iter [00200, 02526], lr: 0.000100, loss: 1.1373, CELoss: 1.1373, 
2022-10-16 01:37:13 - train: epoch 0008, iter [00300, 02526], lr: 0.000100, loss: 0.6861, CELoss: 0.6861, 
2022-10-16 01:37:47 - train: epoch 0008, iter [00400, 02526], lr: 0.000100, loss: 0.7880, CELoss: 0.7880, 
2022-10-16 01:38:20 - train: epoch 0008, iter [00500, 02526], lr: 0.000100, loss: 0.9301, CELoss: 0.9301, 
2022-10-16 01:38:54 - train: epoch 0008, iter [00600, 02526], lr: 0.000100, loss: 1.3073, CELoss: 1.3073, 
2022-10-16 01:39:27 - train: epoch 0008, iter [00700, 02526], lr: 0.000100, loss: 1.5168, CELoss: 1.5168, 
2022-10-16 01:40:01 - train: epoch 0008, iter [00800, 02526], lr: 0.000100, loss: 1.1890, CELoss: 1.1890, 
2022-10-16 01:40:34 - train: epoch 0008, iter [00900, 02526], lr: 0.000100, loss: 1.3693, CELoss: 1.3693, 
2022-10-16 01:41:08 - train: epoch 0008, iter [01000, 02526], lr: 0.000100, loss: 1.6625, CELoss: 1.6625, 
2022-10-16 01:41:42 - train: epoch 0008, iter [01100, 02526], lr: 0.000100, loss: 1.0641, CELoss: 1.0641, 
2022-10-16 01:42:15 - train: epoch 0008, iter [01200, 02526], lr: 0.000100, loss: 1.5457, CELoss: 1.5457, 
2022-10-16 01:42:49 - train: epoch 0008, iter [01300, 02526], lr: 0.000100, loss: 0.6365, CELoss: 0.6365, 
2022-10-16 01:43:22 - train: epoch 0008, iter [01400, 02526], lr: 0.000100, loss: 1.2462, CELoss: 1.2462, 
2022-10-16 01:43:56 - train: epoch 0008, iter [01500, 02526], lr: 0.000100, loss: 0.7617, CELoss: 0.7617, 
2022-10-16 01:44:29 - train: epoch 0008, iter [01600, 02526], lr: 0.000100, loss: 1.0608, CELoss: 1.0608, 
2022-10-16 01:45:03 - train: epoch 0008, iter [01700, 02526], lr: 0.000100, loss: 1.0217, CELoss: 1.0217, 
2022-10-16 01:45:36 - train: epoch 0008, iter [01800, 02526], lr: 0.000100, loss: 0.8289, CELoss: 0.8289, 
2022-10-16 01:46:10 - train: epoch 0008, iter [01900, 02526], lr: 0.000100, loss: 0.9625, CELoss: 0.9625, 
2022-10-16 01:46:43 - train: epoch 0008, iter [02000, 02526], lr: 0.000100, loss: 1.6346, CELoss: 1.6346, 
2022-10-16 01:47:17 - train: epoch 0008, iter [02100, 02526], lr: 0.000100, loss: 1.2507, CELoss: 1.2507, 
2022-10-16 01:47:50 - train: epoch 0008, iter [02200, 02526], lr: 0.000100, loss: 0.9534, CELoss: 0.9534, 
2022-10-16 01:48:24 - train: epoch 0008, iter [02300, 02526], lr: 0.000100, loss: 1.1369, CELoss: 1.1369, 
2022-10-16 01:48:57 - train: epoch 0008, iter [02400, 02526], lr: 0.000100, loss: 0.9179, CELoss: 0.9179, 
2022-10-16 01:49:31 - train: epoch 0008, iter [02500, 02526], lr: 0.000100, loss: 0.7959, CELoss: 0.7959, 
2022-10-16 01:49:41 - train: epoch 008, train_loss: 1.0639
2022-10-16 01:49:43 - until epoch: 008, best_metric: 19.265%
2022-10-16 01:49:43 - epoch 009 lr: 0.000100
2022-10-16 01:50:18 - train: epoch 0009, iter [00100, 02526], lr: 0.000100, loss: 0.8347, CELoss: 0.8347, 
2022-10-16 01:50:52 - train: epoch 0009, iter [00200, 02526], lr: 0.000100, loss: 0.6148, CELoss: 0.6148, 
2022-10-16 01:51:26 - train: epoch 0009, iter [00300, 02526], lr: 0.000100, loss: 1.0713, CELoss: 1.0713, 
2022-10-16 01:51:59 - train: epoch 0009, iter [00400, 02526], lr: 0.000100, loss: 0.8549, CELoss: 0.8549, 
2022-10-16 01:52:33 - train: epoch 0009, iter [00500, 02526], lr: 0.000100, loss: 0.9652, CELoss: 0.9652, 
2022-10-16 01:53:07 - train: epoch 0009, iter [00600, 02526], lr: 0.000100, loss: 0.8740, CELoss: 0.8740, 
2022-10-16 01:53:40 - train: epoch 0009, iter [00700, 02526], lr: 0.000100, loss: 0.9327, CELoss: 0.9327, 
2022-10-16 01:54:13 - train: epoch 0009, iter [00800, 02526], lr: 0.000100, loss: 1.2167, CELoss: 1.2167, 
2022-10-16 01:54:46 - train: epoch 0009, iter [00900, 02526], lr: 0.000100, loss: 0.7431, CELoss: 0.7431, 
2022-10-16 01:55:20 - train: epoch 0009, iter [01000, 02526], lr: 0.000100, loss: 1.4311, CELoss: 1.4311, 
2022-10-16 01:55:53 - train: epoch 0009, iter [01100, 02526], lr: 0.000100, loss: 0.8673, CELoss: 0.8673, 
2022-10-16 01:56:27 - train: epoch 0009, iter [01200, 02526], lr: 0.000100, loss: 1.0474, CELoss: 1.0474, 
2022-10-16 01:57:00 - train: epoch 0009, iter [01300, 02526], lr: 0.000100, loss: 1.1208, CELoss: 1.1208, 
2022-10-16 01:57:34 - train: epoch 0009, iter [01400, 02526], lr: 0.000100, loss: 0.7324, CELoss: 0.7324, 
2022-10-16 01:58:07 - train: epoch 0009, iter [01500, 02526], lr: 0.000100, loss: 1.1561, CELoss: 1.1561, 
2022-10-16 01:58:41 - train: epoch 0009, iter [01600, 02526], lr: 0.000100, loss: 1.1105, CELoss: 1.1105, 
2022-10-16 01:59:15 - train: epoch 0009, iter [01700, 02526], lr: 0.000100, loss: 0.8692, CELoss: 0.8692, 
2022-10-16 01:59:48 - train: epoch 0009, iter [01800, 02526], lr: 0.000100, loss: 0.7209, CELoss: 0.7209, 
2022-10-16 02:00:22 - train: epoch 0009, iter [01900, 02526], lr: 0.000100, loss: 0.6889, CELoss: 0.6889, 
2022-10-16 02:00:55 - train: epoch 0009, iter [02000, 02526], lr: 0.000100, loss: 0.7109, CELoss: 0.7109, 
2022-10-16 02:01:29 - train: epoch 0009, iter [02100, 02526], lr: 0.000100, loss: 1.1388, CELoss: 1.1388, 
2022-10-16 02:02:03 - train: epoch 0009, iter [02200, 02526], lr: 0.000100, loss: 0.9500, CELoss: 0.9500, 
2022-10-16 02:02:36 - train: epoch 0009, iter [02300, 02526], lr: 0.000100, loss: 0.7734, CELoss: 0.7734, 
2022-10-16 02:03:10 - train: epoch 0009, iter [02400, 02526], lr: 0.000100, loss: 0.9988, CELoss: 0.9988, 
2022-10-16 02:03:43 - train: epoch 0009, iter [02500, 02526], lr: 0.000100, loss: 1.0429, CELoss: 1.0429, 
2022-10-16 02:03:53 - train: epoch 009, train_loss: 1.0399
2022-10-16 02:03:55 - until epoch: 009, best_metric: 19.265%
2022-10-16 02:03:55 - epoch 010 lr: 0.000100
2022-10-16 02:04:31 - train: epoch 0010, iter [00100, 02526], lr: 0.000100, loss: 1.0447, CELoss: 1.0447, 
2022-10-16 02:05:05 - train: epoch 0010, iter [00200, 02526], lr: 0.000100, loss: 0.8318, CELoss: 0.8318, 
2022-10-16 02:05:38 - train: epoch 0010, iter [00300, 02526], lr: 0.000100, loss: 0.8106, CELoss: 0.8106, 
2022-10-16 02:06:12 - train: epoch 0010, iter [00400, 02526], lr: 0.000100, loss: 1.0164, CELoss: 1.0164, 
2022-10-16 02:06:46 - train: epoch 0010, iter [00500, 02526], lr: 0.000100, loss: 0.8004, CELoss: 0.8004, 
2022-10-16 02:07:19 - train: epoch 0010, iter [00600, 02526], lr: 0.000100, loss: 1.1576, CELoss: 1.1576, 
2022-10-16 02:07:52 - train: epoch 0010, iter [00700, 02526], lr: 0.000100, loss: 1.5479, CELoss: 1.5479, 
2022-10-16 02:08:26 - train: epoch 0010, iter [00800, 02526], lr: 0.000100, loss: 0.9470, CELoss: 0.9470, 
2022-10-16 02:09:00 - train: epoch 0010, iter [00900, 02526], lr: 0.000100, loss: 0.8909, CELoss: 0.8909, 
2022-10-16 02:09:34 - train: epoch 0010, iter [01000, 02526], lr: 0.000100, loss: 0.9230, CELoss: 0.9230, 
2022-10-16 02:10:07 - train: epoch 0010, iter [01100, 02526], lr: 0.000100, loss: 0.7113, CELoss: 0.7113, 
2022-10-16 02:10:40 - train: epoch 0010, iter [01200, 02526], lr: 0.000100, loss: 0.9848, CELoss: 0.9848, 
2022-10-16 02:11:14 - train: epoch 0010, iter [01300, 02526], lr: 0.000100, loss: 0.7973, CELoss: 0.7973, 
2022-10-16 02:11:47 - train: epoch 0010, iter [01400, 02526], lr: 0.000100, loss: 1.1485, CELoss: 1.1485, 
2022-10-16 02:12:21 - train: epoch 0010, iter [01500, 02526], lr: 0.000100, loss: 0.6172, CELoss: 0.6172, 
2022-10-16 02:12:54 - train: epoch 0010, iter [01600, 02526], lr: 0.000100, loss: 0.6681, CELoss: 0.6681, 
2022-10-16 02:13:28 - train: epoch 0010, iter [01700, 02526], lr: 0.000100, loss: 0.5912, CELoss: 0.5912, 
2022-10-16 02:14:02 - train: epoch 0010, iter [01800, 02526], lr: 0.000100, loss: 0.9108, CELoss: 0.9108, 
2022-10-16 02:14:35 - train: epoch 0010, iter [01900, 02526], lr: 0.000100, loss: 1.0747, CELoss: 1.0747, 
2022-10-16 02:15:08 - train: epoch 0010, iter [02000, 02526], lr: 0.000100, loss: 0.5822, CELoss: 0.5822, 
2022-10-16 02:15:42 - train: epoch 0010, iter [02100, 02526], lr: 0.000100, loss: 1.4256, CELoss: 1.4256, 
2022-10-16 02:16:15 - train: epoch 0010, iter [02200, 02526], lr: 0.000100, loss: 0.8367, CELoss: 0.8367, 
2022-10-16 02:16:49 - train: epoch 0010, iter [02300, 02526], lr: 0.000100, loss: 0.9606, CELoss: 0.9606, 
2022-10-16 02:17:22 - train: epoch 0010, iter [02400, 02526], lr: 0.000100, loss: 1.8821, CELoss: 1.8821, 
2022-10-16 02:17:55 - train: epoch 0010, iter [02500, 02526], lr: 0.000100, loss: 1.3198, CELoss: 1.3198, 
2022-10-16 02:18:05 - train: epoch 010, train_loss: 1.0026
2022-10-16 02:18:55 - eval: epoch: 010
test_loss: 1.0332449833750725
per_image_load_time: 1.043ms
per_image_inference_time: 18.276ms
exist_num_class: 150.0
mean_precision: 48.990994447193245
mean_recall: 33.620882019176
mean_iou: 24.930547004253228
mean_dice: 35.727658509538365

2022-10-16 02:18:59 - until epoch: 010, best_metric: 24.931%
2022-10-16 02:18:59 - epoch 011 lr: 0.000100
2022-10-16 02:19:34 - train: epoch 0011, iter [00100, 02526], lr: 0.000100, loss: 0.7411, CELoss: 0.7411, 
2022-10-16 02:20:07 - train: epoch 0011, iter [00200, 02526], lr: 0.000100, loss: 1.1417, CELoss: 1.1417, 
2022-10-16 02:20:41 - train: epoch 0011, iter [00300, 02526], lr: 0.000100, loss: 0.6677, CELoss: 0.6677, 
2022-10-16 02:21:14 - train: epoch 0011, iter [00400, 02526], lr: 0.000100, loss: 0.9928, CELoss: 0.9928, 
2022-10-16 02:21:48 - train: epoch 0011, iter [00500, 02526], lr: 0.000100, loss: 1.5798, CELoss: 1.5798, 
2022-10-16 02:22:21 - train: epoch 0011, iter [00600, 02526], lr: 0.000100, loss: 0.9128, CELoss: 0.9128, 
2022-10-16 02:22:55 - train: epoch 0011, iter [00700, 02526], lr: 0.000100, loss: 0.6669, CELoss: 0.6669, 
2022-10-16 02:23:28 - train: epoch 0011, iter [00800, 02526], lr: 0.000100, loss: 1.2895, CELoss: 1.2895, 
2022-10-16 02:24:02 - train: epoch 0011, iter [00900, 02526], lr: 0.000100, loss: 1.0745, CELoss: 1.0745, 
2022-10-16 02:24:35 - train: epoch 0011, iter [01000, 02526], lr: 0.000100, loss: 0.8483, CELoss: 0.8483, 
2022-10-16 02:25:09 - train: epoch 0011, iter [01100, 02526], lr: 0.000100, loss: 1.1518, CELoss: 1.1518, 
2022-10-16 02:25:42 - train: epoch 0011, iter [01200, 02526], lr: 0.000100, loss: 1.1454, CELoss: 1.1454, 
2022-10-16 02:26:16 - train: epoch 0011, iter [01300, 02526], lr: 0.000100, loss: 0.8033, CELoss: 0.8033, 
2022-10-16 02:26:49 - train: epoch 0011, iter [01400, 02526], lr: 0.000100, loss: 1.3461, CELoss: 1.3461, 
2022-10-16 02:27:23 - train: epoch 0011, iter [01500, 02526], lr: 0.000100, loss: 1.0017, CELoss: 1.0017, 
2022-10-16 02:27:57 - train: epoch 0011, iter [01600, 02526], lr: 0.000100, loss: 0.7644, CELoss: 0.7644, 
2022-10-16 02:28:30 - train: epoch 0011, iter [01700, 02526], lr: 0.000100, loss: 1.2893, CELoss: 1.2893, 
2022-10-16 02:29:04 - train: epoch 0011, iter [01800, 02526], lr: 0.000100, loss: 1.0347, CELoss: 1.0347, 
2022-10-16 02:29:37 - train: epoch 0011, iter [01900, 02526], lr: 0.000100, loss: 0.9632, CELoss: 0.9632, 
2022-10-16 02:30:10 - train: epoch 0011, iter [02000, 02526], lr: 0.000100, loss: 1.0365, CELoss: 1.0365, 
2022-10-16 02:30:44 - train: epoch 0011, iter [02100, 02526], lr: 0.000100, loss: 0.9859, CELoss: 0.9859, 
2022-10-16 02:31:18 - train: epoch 0011, iter [02200, 02526], lr: 0.000100, loss: 1.1420, CELoss: 1.1420, 
2022-10-16 02:31:51 - train: epoch 0011, iter [02300, 02526], lr: 0.000100, loss: 1.1509, CELoss: 1.1509, 
2022-10-16 02:32:24 - train: epoch 0011, iter [02400, 02526], lr: 0.000100, loss: 1.1903, CELoss: 1.1903, 
2022-10-16 02:32:58 - train: epoch 0011, iter [02500, 02526], lr: 0.000100, loss: 0.7752, CELoss: 0.7752, 
2022-10-16 02:33:08 - train: epoch 011, train_loss: 0.9709
2022-10-16 02:33:10 - until epoch: 011, best_metric: 24.931%
2022-10-16 02:33:10 - epoch 012 lr: 0.000100
2022-10-16 02:33:45 - train: epoch 0012, iter [00100, 02526], lr: 0.000100, loss: 0.8699, CELoss: 0.8699, 
2022-10-16 02:34:19 - train: epoch 0012, iter [00200, 02526], lr: 0.000100, loss: 0.9149, CELoss: 0.9149, 
2022-10-16 02:34:52 - train: epoch 0012, iter [00300, 02526], lr: 0.000100, loss: 1.1825, CELoss: 1.1825, 
2022-10-16 02:35:26 - train: epoch 0012, iter [00400, 02526], lr: 0.000100, loss: 1.1724, CELoss: 1.1724, 
2022-10-16 02:35:59 - train: epoch 0012, iter [00500, 02526], lr: 0.000100, loss: 1.1622, CELoss: 1.1622, 
2022-10-16 02:36:33 - train: epoch 0012, iter [00600, 02526], lr: 0.000100, loss: 0.8192, CELoss: 0.8192, 
2022-10-16 02:37:06 - train: epoch 0012, iter [00700, 02526], lr: 0.000100, loss: 0.8220, CELoss: 0.8220, 
2022-10-16 02:37:40 - train: epoch 0012, iter [00800, 02526], lr: 0.000100, loss: 0.8910, CELoss: 0.8910, 
2022-10-16 02:38:13 - train: epoch 0012, iter [00900, 02526], lr: 0.000100, loss: 0.9084, CELoss: 0.9084, 
2022-10-16 02:38:47 - train: epoch 0012, iter [01000, 02526], lr: 0.000100, loss: 0.6938, CELoss: 0.6938, 
2022-10-16 02:39:20 - train: epoch 0012, iter [01100, 02526], lr: 0.000100, loss: 1.3868, CELoss: 1.3868, 
2022-10-16 02:39:54 - train: epoch 0012, iter [01200, 02526], lr: 0.000100, loss: 0.8448, CELoss: 0.8448, 
2022-10-16 02:40:27 - train: epoch 0012, iter [01300, 02526], lr: 0.000100, loss: 0.8322, CELoss: 0.8322, 
2022-10-16 02:41:01 - train: epoch 0012, iter [01400, 02526], lr: 0.000100, loss: 0.5050, CELoss: 0.5050, 
2022-10-16 02:41:34 - train: epoch 0012, iter [01500, 02526], lr: 0.000100, loss: 1.2594, CELoss: 1.2594, 
2022-10-16 02:42:08 - train: epoch 0012, iter [01600, 02526], lr: 0.000100, loss: 0.7997, CELoss: 0.7997, 
2022-10-16 02:42:41 - train: epoch 0012, iter [01700, 02526], lr: 0.000100, loss: 0.9805, CELoss: 0.9805, 
2022-10-16 02:43:14 - train: epoch 0012, iter [01800, 02526], lr: 0.000100, loss: 0.7780, CELoss: 0.7780, 
2022-10-16 02:43:48 - train: epoch 0012, iter [01900, 02526], lr: 0.000100, loss: 1.2083, CELoss: 1.2083, 
2022-10-16 02:44:21 - train: epoch 0012, iter [02000, 02526], lr: 0.000100, loss: 0.7873, CELoss: 0.7873, 
2022-10-16 02:44:55 - train: epoch 0012, iter [02100, 02526], lr: 0.000100, loss: 0.9021, CELoss: 0.9021, 
2022-10-16 02:45:28 - train: epoch 0012, iter [02200, 02526], lr: 0.000100, loss: 0.7293, CELoss: 0.7293, 
2022-10-16 02:46:02 - train: epoch 0012, iter [02300, 02526], lr: 0.000100, loss: 0.6575, CELoss: 0.6575, 
2022-10-16 02:46:35 - train: epoch 0012, iter [02400, 02526], lr: 0.000100, loss: 1.5225, CELoss: 1.5225, 
2022-10-16 02:47:09 - train: epoch 0012, iter [02500, 02526], lr: 0.000100, loss: 0.7611, CELoss: 0.7611, 
2022-10-16 02:47:19 - train: epoch 012, train_loss: 0.9508
2022-10-16 02:47:21 - until epoch: 012, best_metric: 24.931%
2022-10-16 02:47:21 - epoch 013 lr: 0.000100
2022-10-16 02:47:57 - train: epoch 0013, iter [00100, 02526], lr: 0.000100, loss: 0.9289, CELoss: 0.9289, 
2022-10-16 02:48:30 - train: epoch 0013, iter [00200, 02526], lr: 0.000100, loss: 0.9367, CELoss: 0.9367, 
2022-10-16 02:49:04 - train: epoch 0013, iter [00300, 02526], lr: 0.000100, loss: 0.7417, CELoss: 0.7417, 
2022-10-16 02:49:37 - train: epoch 0013, iter [00400, 02526], lr: 0.000100, loss: 0.9264, CELoss: 0.9264, 
2022-10-16 02:50:11 - train: epoch 0013, iter [00500, 02526], lr: 0.000100, loss: 1.2974, CELoss: 1.2974, 
2022-10-16 02:50:45 - train: epoch 0013, iter [00600, 02526], lr: 0.000100, loss: 1.0410, CELoss: 1.0410, 
2022-10-16 02:51:18 - train: epoch 0013, iter [00700, 02526], lr: 0.000100, loss: 0.5314, CELoss: 0.5314, 
2022-10-16 02:51:52 - train: epoch 0013, iter [00800, 02526], lr: 0.000100, loss: 0.6910, CELoss: 0.6910, 
2022-10-16 02:52:25 - train: epoch 0013, iter [00900, 02526], lr: 0.000100, loss: 0.8928, CELoss: 0.8928, 
2022-10-16 02:52:59 - train: epoch 0013, iter [01000, 02526], lr: 0.000100, loss: 1.1961, CELoss: 1.1961, 
2022-10-16 02:53:32 - train: epoch 0013, iter [01100, 02526], lr: 0.000100, loss: 1.1325, CELoss: 1.1325, 
2022-10-16 02:54:05 - train: epoch 0013, iter [01200, 02526], lr: 0.000100, loss: 0.7601, CELoss: 0.7601, 
2022-10-16 02:54:39 - train: epoch 0013, iter [01300, 02526], lr: 0.000100, loss: 0.7273, CELoss: 0.7273, 
2022-10-16 02:55:12 - train: epoch 0013, iter [01400, 02526], lr: 0.000100, loss: 1.1174, CELoss: 1.1174, 
2022-10-16 02:55:46 - train: epoch 0013, iter [01500, 02526], lr: 0.000100, loss: 1.4427, CELoss: 1.4427, 
2022-10-16 02:56:20 - train: epoch 0013, iter [01600, 02526], lr: 0.000100, loss: 0.7795, CELoss: 0.7795, 
2022-10-16 02:56:54 - train: epoch 0013, iter [01700, 02526], lr: 0.000100, loss: 1.0154, CELoss: 1.0154, 
2022-10-16 02:57:27 - train: epoch 0013, iter [01800, 02526], lr: 0.000100, loss: 1.2766, CELoss: 1.2766, 
2022-10-16 02:58:00 - train: epoch 0013, iter [01900, 02526], lr: 0.000100, loss: 0.9012, CELoss: 0.9012, 
2022-10-16 02:58:33 - train: epoch 0013, iter [02000, 02526], lr: 0.000100, loss: 0.8632, CELoss: 0.8632, 
2022-10-16 02:59:07 - train: epoch 0013, iter [02100, 02526], lr: 0.000100, loss: 0.9137, CELoss: 0.9137, 
2022-10-16 02:59:40 - train: epoch 0013, iter [02200, 02526], lr: 0.000100, loss: 0.7658, CELoss: 0.7658, 
2022-10-16 03:00:14 - train: epoch 0013, iter [02300, 02526], lr: 0.000100, loss: 0.7499, CELoss: 0.7499, 
2022-10-16 03:00:47 - train: epoch 0013, iter [02400, 02526], lr: 0.000100, loss: 0.7458, CELoss: 0.7458, 
2022-10-16 03:01:20 - train: epoch 0013, iter [02500, 02526], lr: 0.000100, loss: 0.8252, CELoss: 0.8252, 
2022-10-16 03:01:31 - train: epoch 013, train_loss: 0.9308
2022-10-16 03:01:32 - until epoch: 013, best_metric: 24.931%
2022-10-16 03:01:32 - epoch 014 lr: 0.000100
2022-10-16 03:02:09 - train: epoch 0014, iter [00100, 02526], lr: 0.000100, loss: 0.8986, CELoss: 0.8986, 
2022-10-16 03:02:42 - train: epoch 0014, iter [00200, 02526], lr: 0.000100, loss: 1.0641, CELoss: 1.0641, 
2022-10-16 03:03:16 - train: epoch 0014, iter [00300, 02526], lr: 0.000100, loss: 0.7757, CELoss: 0.7757, 
2022-10-16 03:03:49 - train: epoch 0014, iter [00400, 02526], lr: 0.000100, loss: 0.6674, CELoss: 0.6674, 
2022-10-16 03:04:23 - train: epoch 0014, iter [00500, 02526], lr: 0.000100, loss: 0.7109, CELoss: 0.7109, 
2022-10-16 03:04:56 - train: epoch 0014, iter [00600, 02526], lr: 0.000100, loss: 1.4604, CELoss: 1.4604, 
2022-10-16 03:05:29 - train: epoch 0014, iter [00700, 02526], lr: 0.000100, loss: 1.4270, CELoss: 1.4270, 
2022-10-16 03:06:03 - train: epoch 0014, iter [00800, 02526], lr: 0.000100, loss: 0.8706, CELoss: 0.8706, 
2022-10-16 03:06:37 - train: epoch 0014, iter [00900, 02526], lr: 0.000100, loss: 0.5337, CELoss: 0.5337, 
2022-10-16 03:07:10 - train: epoch 0014, iter [01000, 02526], lr: 0.000100, loss: 0.5661, CELoss: 0.5661, 
2022-10-16 03:07:44 - train: epoch 0014, iter [01100, 02526], lr: 0.000100, loss: 0.8259, CELoss: 0.8259, 
2022-10-16 03:08:17 - train: epoch 0014, iter [01200, 02526], lr: 0.000100, loss: 1.2568, CELoss: 1.2568, 
2022-10-16 03:08:50 - train: epoch 0014, iter [01300, 02526], lr: 0.000100, loss: 1.0908, CELoss: 1.0908, 
2022-10-16 03:09:24 - train: epoch 0014, iter [01400, 02526], lr: 0.000100, loss: 1.0258, CELoss: 1.0258, 
2022-10-16 03:09:57 - train: epoch 0014, iter [01500, 02526], lr: 0.000100, loss: 0.6907, CELoss: 0.6907, 
2022-10-16 03:10:31 - train: epoch 0014, iter [01600, 02526], lr: 0.000100, loss: 0.7632, CELoss: 0.7632, 
2022-10-16 03:11:04 - train: epoch 0014, iter [01700, 02526], lr: 0.000100, loss: 1.6202, CELoss: 1.6202, 
2022-10-16 03:11:38 - train: epoch 0014, iter [01800, 02526], lr: 0.000100, loss: 1.1869, CELoss: 1.1869, 
2022-10-16 03:12:12 - train: epoch 0014, iter [01900, 02526], lr: 0.000100, loss: 1.1954, CELoss: 1.1954, 
2022-10-16 03:12:45 - train: epoch 0014, iter [02000, 02526], lr: 0.000100, loss: 0.9583, CELoss: 0.9583, 
2022-10-16 03:13:19 - train: epoch 0014, iter [02100, 02526], lr: 0.000100, loss: 0.8882, CELoss: 0.8882, 
2022-10-16 03:13:52 - train: epoch 0014, iter [02200, 02526], lr: 0.000100, loss: 0.7446, CELoss: 0.7446, 
2022-10-16 03:14:26 - train: epoch 0014, iter [02300, 02526], lr: 0.000100, loss: 1.1097, CELoss: 1.1097, 
2022-10-16 03:14:59 - train: epoch 0014, iter [02400, 02526], lr: 0.000100, loss: 1.2022, CELoss: 1.2022, 
2022-10-16 03:15:33 - train: epoch 0014, iter [02500, 02526], lr: 0.000100, loss: 0.9232, CELoss: 0.9232, 
2022-10-16 03:15:43 - train: epoch 014, train_loss: 0.9155
2022-10-16 03:15:45 - until epoch: 014, best_metric: 24.931%
2022-10-16 03:15:45 - epoch 015 lr: 0.000100
2022-10-16 03:16:20 - train: epoch 0015, iter [00100, 02526], lr: 0.000100, loss: 0.6394, CELoss: 0.6394, 
2022-10-16 03:16:54 - train: epoch 0015, iter [00200, 02526], lr: 0.000100, loss: 1.0299, CELoss: 1.0299, 
2022-10-16 03:17:28 - train: epoch 0015, iter [00300, 02526], lr: 0.000100, loss: 0.7454, CELoss: 0.7454, 
2022-10-16 03:18:01 - train: epoch 0015, iter [00400, 02526], lr: 0.000100, loss: 0.9610, CELoss: 0.9610, 
2022-10-16 03:18:35 - train: epoch 0015, iter [00500, 02526], lr: 0.000100, loss: 1.3565, CELoss: 1.3565, 
2022-10-16 03:19:08 - train: epoch 0015, iter [00600, 02526], lr: 0.000100, loss: 0.9693, CELoss: 0.9693, 
2022-10-16 03:19:42 - train: epoch 0015, iter [00700, 02526], lr: 0.000100, loss: 0.8796, CELoss: 0.8796, 
2022-10-16 03:20:16 - train: epoch 0015, iter [00800, 02526], lr: 0.000100, loss: 0.6786, CELoss: 0.6786, 
2022-10-16 03:20:49 - train: epoch 0015, iter [00900, 02526], lr: 0.000100, loss: 0.8528, CELoss: 0.8528, 
2022-10-16 03:21:22 - train: epoch 0015, iter [01000, 02526], lr: 0.000100, loss: 1.3093, CELoss: 1.3093, 
2022-10-16 03:21:56 - train: epoch 0015, iter [01100, 02526], lr: 0.000100, loss: 0.6105, CELoss: 0.6105, 
2022-10-16 03:22:29 - train: epoch 0015, iter [01200, 02526], lr: 0.000100, loss: 0.8341, CELoss: 0.8341, 
2022-10-16 03:23:03 - train: epoch 0015, iter [01300, 02526], lr: 0.000100, loss: 1.0791, CELoss: 1.0791, 
2022-10-16 03:23:37 - train: epoch 0015, iter [01400, 02526], lr: 0.000100, loss: 0.8797, CELoss: 0.8797, 
2022-10-16 03:24:10 - train: epoch 0015, iter [01500, 02526], lr: 0.000100, loss: 1.0290, CELoss: 1.0290, 
2022-10-16 03:24:43 - train: epoch 0015, iter [01600, 02526], lr: 0.000100, loss: 0.8211, CELoss: 0.8211, 
2022-10-16 03:25:17 - train: epoch 0015, iter [01700, 02526], lr: 0.000100, loss: 0.5113, CELoss: 0.5113, 
2022-10-16 03:25:51 - train: epoch 0015, iter [01800, 02526], lr: 0.000100, loss: 1.1213, CELoss: 1.1213, 
2022-10-16 03:26:24 - train: epoch 0015, iter [01900, 02526], lr: 0.000100, loss: 0.6511, CELoss: 0.6511, 
2022-10-16 03:26:58 - train: epoch 0015, iter [02000, 02526], lr: 0.000100, loss: 0.9754, CELoss: 0.9754, 
2022-10-16 03:27:32 - train: epoch 0015, iter [02100, 02526], lr: 0.000100, loss: 1.3297, CELoss: 1.3297, 
2022-10-16 03:28:05 - train: epoch 0015, iter [02200, 02526], lr: 0.000100, loss: 0.5462, CELoss: 0.5462, 
2022-10-16 03:28:39 - train: epoch 0015, iter [02300, 02526], lr: 0.000100, loss: 1.0498, CELoss: 1.0498, 
2022-10-16 03:29:12 - train: epoch 0015, iter [02400, 02526], lr: 0.000100, loss: 1.1249, CELoss: 1.1249, 
2022-10-16 03:29:46 - train: epoch 0015, iter [02500, 02526], lr: 0.000100, loss: 0.5735, CELoss: 0.5735, 
2022-10-16 03:29:56 - train: epoch 015, train_loss: 0.8893
2022-10-16 03:30:46 - eval: epoch: 015
test_loss: 0.9499402649700641
per_image_load_time: 1.083ms
per_image_inference_time: 18.261ms
exist_num_class: 150.0
mean_precision: 50.45318669640034
mean_recall: 37.54871390817484
mean_iou: 28.364884931249158
mean_dice: 39.53906059780098

2022-10-16 03:30:49 - until epoch: 015, best_metric: 28.365%
2022-10-16 03:30:49 - epoch 016 lr: 0.000100
2022-10-16 03:31:25 - train: epoch 0016, iter [00100, 02526], lr: 0.000100, loss: 0.5398, CELoss: 0.5398, 
2022-10-16 03:31:59 - train: epoch 0016, iter [00200, 02526], lr: 0.000100, loss: 0.8575, CELoss: 0.8575, 
2022-10-16 03:32:32 - train: epoch 0016, iter [00300, 02526], lr: 0.000100, loss: 0.6893, CELoss: 0.6893, 
2022-10-16 03:33:06 - train: epoch 0016, iter [00400, 02526], lr: 0.000100, loss: 0.6203, CELoss: 0.6203, 
2022-10-16 03:33:39 - train: epoch 0016, iter [00500, 02526], lr: 0.000100, loss: 0.6434, CELoss: 0.6434, 
2022-10-16 03:34:13 - train: epoch 0016, iter [00600, 02526], lr: 0.000100, loss: 1.0692, CELoss: 1.0692, 
2022-10-16 03:34:47 - train: epoch 0016, iter [00700, 02526], lr: 0.000100, loss: 0.4754, CELoss: 0.4754, 
2022-10-16 03:35:20 - train: epoch 0016, iter [00800, 02526], lr: 0.000100, loss: 0.6601, CELoss: 0.6601, 
2022-10-16 03:35:53 - train: epoch 0016, iter [00900, 02526], lr: 0.000100, loss: 1.2796, CELoss: 1.2796, 
2022-10-16 03:36:27 - train: epoch 0016, iter [01000, 02526], lr: 0.000100, loss: 0.7344, CELoss: 0.7344, 
2022-10-16 03:37:00 - train: epoch 0016, iter [01100, 02526], lr: 0.000100, loss: 1.5043, CELoss: 1.5043, 
2022-10-16 03:37:33 - train: epoch 0016, iter [01200, 02526], lr: 0.000100, loss: 1.5148, CELoss: 1.5148, 
2022-10-16 03:38:07 - train: epoch 0016, iter [01300, 02526], lr: 0.000100, loss: 0.5934, CELoss: 0.5934, 
2022-10-16 03:38:41 - train: epoch 0016, iter [01400, 02526], lr: 0.000100, loss: 1.1190, CELoss: 1.1190, 
2022-10-16 03:39:14 - train: epoch 0016, iter [01500, 02526], lr: 0.000100, loss: 0.8195, CELoss: 0.8195, 
2022-10-16 03:39:47 - train: epoch 0016, iter [01600, 02526], lr: 0.000100, loss: 0.8042, CELoss: 0.8042, 
2022-10-16 03:40:21 - train: epoch 0016, iter [01700, 02526], lr: 0.000100, loss: 0.7797, CELoss: 0.7797, 
2022-10-16 03:40:54 - train: epoch 0016, iter [01800, 02526], lr: 0.000100, loss: 0.9535, CELoss: 0.9535, 
2022-10-16 03:41:28 - train: epoch 0016, iter [01900, 02526], lr: 0.000100, loss: 1.1194, CELoss: 1.1194, 
2022-10-16 03:42:01 - train: epoch 0016, iter [02000, 02526], lr: 0.000100, loss: 0.6352, CELoss: 0.6352, 
2022-10-16 03:42:35 - train: epoch 0016, iter [02100, 02526], lr: 0.000100, loss: 0.5818, CELoss: 0.5818, 
2022-10-16 03:43:09 - train: epoch 0016, iter [02200, 02526], lr: 0.000100, loss: 0.9750, CELoss: 0.9750, 
2022-10-16 03:43:42 - train: epoch 0016, iter [02300, 02526], lr: 0.000100, loss: 0.7522, CELoss: 0.7522, 
2022-10-16 03:44:16 - train: epoch 0016, iter [02400, 02526], lr: 0.000100, loss: 0.6902, CELoss: 0.6902, 
2022-10-16 03:44:49 - train: epoch 0016, iter [02500, 02526], lr: 0.000100, loss: 1.5198, CELoss: 1.5198, 
2022-10-16 03:44:59 - train: epoch 016, train_loss: 0.8895
2022-10-16 03:45:01 - until epoch: 016, best_metric: 28.365%
2022-10-16 03:45:01 - epoch 017 lr: 0.000100
2022-10-16 03:45:36 - train: epoch 0017, iter [00100, 02526], lr: 0.000100, loss: 0.7072, CELoss: 0.7072, 
2022-10-16 03:46:10 - train: epoch 0017, iter [00200, 02526], lr: 0.000100, loss: 0.5896, CELoss: 0.5896, 
2022-10-16 03:46:43 - train: epoch 0017, iter [00300, 02526], lr: 0.000100, loss: 0.5676, CELoss: 0.5676, 
2022-10-16 03:47:16 - train: epoch 0017, iter [00400, 02526], lr: 0.000100, loss: 0.8066, CELoss: 0.8066, 
2022-10-16 03:47:50 - train: epoch 0017, iter [00500, 02526], lr: 0.000100, loss: 0.8956, CELoss: 0.8956, 
2022-10-16 03:48:23 - train: epoch 0017, iter [00600, 02526], lr: 0.000100, loss: 0.8196, CELoss: 0.8196, 
2022-10-16 03:48:56 - train: epoch 0017, iter [00700, 02526], lr: 0.000100, loss: 0.5285, CELoss: 0.5285, 
2022-10-16 03:49:30 - train: epoch 0017, iter [00800, 02526], lr: 0.000100, loss: 0.4626, CELoss: 0.4626, 
2022-10-16 03:50:03 - train: epoch 0017, iter [00900, 02526], lr: 0.000100, loss: 1.6168, CELoss: 1.6168, 
2022-10-16 03:50:37 - train: epoch 0017, iter [01000, 02526], lr: 0.000100, loss: 0.5946, CELoss: 0.5946, 
2022-10-16 03:51:11 - train: epoch 0017, iter [01100, 02526], lr: 0.000100, loss: 0.7100, CELoss: 0.7100, 
2022-10-16 03:51:44 - train: epoch 0017, iter [01200, 02526], lr: 0.000100, loss: 0.7085, CELoss: 0.7085, 
2022-10-16 03:52:17 - train: epoch 0017, iter [01300, 02526], lr: 0.000100, loss: 1.7247, CELoss: 1.7247, 
2022-10-16 03:52:51 - train: epoch 0017, iter [01400, 02526], lr: 0.000100, loss: 0.9571, CELoss: 0.9571, 
2022-10-16 03:53:24 - train: epoch 0017, iter [01500, 02526], lr: 0.000100, loss: 1.0808, CELoss: 1.0808, 
2022-10-16 03:53:57 - train: epoch 0017, iter [01600, 02526], lr: 0.000100, loss: 0.4127, CELoss: 0.4127, 
2022-10-16 03:54:31 - train: epoch 0017, iter [01700, 02526], lr: 0.000100, loss: 1.1693, CELoss: 1.1693, 
2022-10-16 03:55:04 - train: epoch 0017, iter [01800, 02526], lr: 0.000100, loss: 0.8057, CELoss: 0.8057, 
2022-10-16 03:55:38 - train: epoch 0017, iter [01900, 02526], lr: 0.000100, loss: 0.8820, CELoss: 0.8820, 
2022-10-16 03:56:11 - train: epoch 0017, iter [02000, 02526], lr: 0.000100, loss: 0.5609, CELoss: 0.5609, 
2022-10-16 03:56:45 - train: epoch 0017, iter [02100, 02526], lr: 0.000100, loss: 0.8769, CELoss: 0.8769, 
2022-10-16 03:57:19 - train: epoch 0017, iter [02200, 02526], lr: 0.000100, loss: 0.9103, CELoss: 0.9103, 
2022-10-16 03:57:52 - train: epoch 0017, iter [02300, 02526], lr: 0.000100, loss: 0.7243, CELoss: 0.7243, 
2022-10-16 03:58:26 - train: epoch 0017, iter [02400, 02526], lr: 0.000100, loss: 0.4239, CELoss: 0.4239, 
2022-10-16 03:59:00 - train: epoch 0017, iter [02500, 02526], lr: 0.000100, loss: 0.7291, CELoss: 0.7291, 
2022-10-16 03:59:09 - train: epoch 017, train_loss: 0.8648
2022-10-16 03:59:12 - until epoch: 017, best_metric: 28.365%
2022-10-16 03:59:12 - epoch 018 lr: 0.000100
2022-10-16 03:59:48 - train: epoch 0018, iter [00100, 02526], lr: 0.000100, loss: 0.9225, CELoss: 0.9225, 
2022-10-16 04:00:21 - train: epoch 0018, iter [00200, 02526], lr: 0.000100, loss: 0.8803, CELoss: 0.8803, 
2022-10-16 04:00:55 - train: epoch 0018, iter [00300, 02526], lr: 0.000100, loss: 0.8103, CELoss: 0.8103, 
2022-10-16 04:01:28 - train: epoch 0018, iter [00400, 02526], lr: 0.000100, loss: 0.7366, CELoss: 0.7366, 
2022-10-16 04:02:01 - train: epoch 0018, iter [00500, 02526], lr: 0.000100, loss: 0.8837, CELoss: 0.8837, 
2022-10-16 04:02:35 - train: epoch 0018, iter [00600, 02526], lr: 0.000100, loss: 0.8247, CELoss: 0.8247, 
2022-10-16 04:03:08 - train: epoch 0018, iter [00700, 02526], lr: 0.000100, loss: 0.6346, CELoss: 0.6346, 
2022-10-16 04:03:42 - train: epoch 0018, iter [00800, 02526], lr: 0.000100, loss: 0.9099, CELoss: 0.9099, 
2022-10-16 04:04:15 - train: epoch 0018, iter [00900, 02526], lr: 0.000100, loss: 0.6870, CELoss: 0.6870, 
2022-10-16 04:04:49 - train: epoch 0018, iter [01000, 02526], lr: 0.000100, loss: 0.6732, CELoss: 0.6732, 
2022-10-16 04:05:22 - train: epoch 0018, iter [01100, 02526], lr: 0.000100, loss: 1.0944, CELoss: 1.0944, 
2022-10-16 04:05:56 - train: epoch 0018, iter [01200, 02526], lr: 0.000100, loss: 0.6900, CELoss: 0.6900, 
2022-10-16 04:06:29 - train: epoch 0018, iter [01300, 02526], lr: 0.000100, loss: 0.7382, CELoss: 0.7382, 
2022-10-16 04:07:03 - train: epoch 0018, iter [01400, 02526], lr: 0.000100, loss: 1.7380, CELoss: 1.7380, 
2022-10-16 04:07:36 - train: epoch 0018, iter [01500, 02526], lr: 0.000100, loss: 0.4262, CELoss: 0.4262, 
2022-10-16 04:08:09 - train: epoch 0018, iter [01600, 02526], lr: 0.000100, loss: 0.8416, CELoss: 0.8416, 
2022-10-16 04:08:43 - train: epoch 0018, iter [01700, 02526], lr: 0.000100, loss: 0.9467, CELoss: 0.9467, 
2022-10-16 04:09:16 - train: epoch 0018, iter [01800, 02526], lr: 0.000100, loss: 0.7519, CELoss: 0.7519, 
2022-10-16 04:09:49 - train: epoch 0018, iter [01900, 02526], lr: 0.000100, loss: 0.8751, CELoss: 0.8751, 
2022-10-16 04:10:23 - train: epoch 0018, iter [02000, 02526], lr: 0.000100, loss: 0.7136, CELoss: 0.7136, 
2022-10-16 04:10:56 - train: epoch 0018, iter [02100, 02526], lr: 0.000100, loss: 1.0181, CELoss: 1.0181, 
2022-10-16 04:11:29 - train: epoch 0018, iter [02200, 02526], lr: 0.000100, loss: 0.8633, CELoss: 0.8633, 
2022-10-16 04:12:03 - train: epoch 0018, iter [02300, 02526], lr: 0.000100, loss: 0.7308, CELoss: 0.7308, 
2022-10-16 04:12:36 - train: epoch 0018, iter [02400, 02526], lr: 0.000100, loss: 1.1374, CELoss: 1.1374, 
2022-10-16 04:13:09 - train: epoch 0018, iter [02500, 02526], lr: 0.000100, loss: 1.1290, CELoss: 1.1290, 
2022-10-16 04:13:19 - train: epoch 018, train_loss: 0.8430
2022-10-16 04:13:21 - until epoch: 018, best_metric: 28.365%
2022-10-16 04:13:21 - epoch 019 lr: 0.000100
2022-10-16 04:13:57 - train: epoch 0019, iter [00100, 02526], lr: 0.000100, loss: 0.9943, CELoss: 0.9943, 
2022-10-16 04:14:31 - train: epoch 0019, iter [00200, 02526], lr: 0.000100, loss: 1.3947, CELoss: 1.3947, 
2022-10-16 04:15:04 - train: epoch 0019, iter [00300, 02526], lr: 0.000100, loss: 1.0160, CELoss: 1.0160, 
2022-10-16 04:15:37 - train: epoch 0019, iter [00400, 02526], lr: 0.000100, loss: 0.6298, CELoss: 0.6298, 
2022-10-16 04:16:11 - train: epoch 0019, iter [00500, 02526], lr: 0.000100, loss: 0.7872, CELoss: 0.7872, 
2022-10-16 04:16:45 - train: epoch 0019, iter [00600, 02526], lr: 0.000100, loss: 1.4476, CELoss: 1.4476, 
2022-10-16 04:17:18 - train: epoch 0019, iter [00700, 02526], lr: 0.000100, loss: 1.1850, CELoss: 1.1850, 
2022-10-16 04:17:52 - train: epoch 0019, iter [00800, 02526], lr: 0.000100, loss: 1.4453, CELoss: 1.4453, 
2022-10-16 04:18:25 - train: epoch 0019, iter [00900, 02526], lr: 0.000100, loss: 0.7930, CELoss: 0.7930, 
2022-10-16 04:18:58 - train: epoch 0019, iter [01000, 02526], lr: 0.000100, loss: 0.6012, CELoss: 0.6012, 
2022-10-16 04:19:31 - train: epoch 0019, iter [01100, 02526], lr: 0.000100, loss: 1.3660, CELoss: 1.3660, 
2022-10-16 04:20:05 - train: epoch 0019, iter [01200, 02526], lr: 0.000100, loss: 0.8570, CELoss: 0.8570, 
2022-10-16 04:20:38 - train: epoch 0019, iter [01300, 02526], lr: 0.000100, loss: 0.4970, CELoss: 0.4970, 
2022-10-16 04:21:11 - train: epoch 0019, iter [01400, 02526], lr: 0.000100, loss: 0.5740, CELoss: 0.5740, 
2022-10-16 04:21:45 - train: epoch 0019, iter [01500, 02526], lr: 0.000100, loss: 1.1482, CELoss: 1.1482, 
2022-10-16 04:22:19 - train: epoch 0019, iter [01600, 02526], lr: 0.000100, loss: 0.5541, CELoss: 0.5541, 
2022-10-16 04:22:52 - train: epoch 0019, iter [01700, 02526], lr: 0.000100, loss: 0.6795, CELoss: 0.6795, 
2022-10-16 04:23:26 - train: epoch 0019, iter [01800, 02526], lr: 0.000100, loss: 0.7281, CELoss: 0.7281, 
2022-10-16 04:23:59 - train: epoch 0019, iter [01900, 02526], lr: 0.000100, loss: 0.7973, CELoss: 0.7973, 
2022-10-16 04:24:32 - train: epoch 0019, iter [02000, 02526], lr: 0.000100, loss: 0.5949, CELoss: 0.5949, 
2022-10-16 04:25:06 - train: epoch 0019, iter [02100, 02526], lr: 0.000100, loss: 0.9345, CELoss: 0.9345, 
2022-10-16 04:25:39 - train: epoch 0019, iter [02200, 02526], lr: 0.000100, loss: 0.3395, CELoss: 0.3395, 
2022-10-16 04:26:12 - train: epoch 0019, iter [02300, 02526], lr: 0.000100, loss: 0.6586, CELoss: 0.6586, 
2022-10-16 04:26:46 - train: epoch 0019, iter [02400, 02526], lr: 0.000100, loss: 0.6162, CELoss: 0.6162, 
2022-10-16 04:27:19 - train: epoch 0019, iter [02500, 02526], lr: 0.000100, loss: 1.2225, CELoss: 1.2225, 
2022-10-16 04:27:29 - train: epoch 019, train_loss: 0.8332
2022-10-16 04:27:31 - until epoch: 019, best_metric: 28.365%
2022-10-16 04:27:31 - epoch 020 lr: 0.000100
2022-10-16 04:28:07 - train: epoch 0020, iter [00100, 02526], lr: 0.000100, loss: 0.8469, CELoss: 0.8469, 
2022-10-16 04:28:41 - train: epoch 0020, iter [00200, 02526], lr: 0.000100, loss: 0.6411, CELoss: 0.6411, 
2022-10-16 04:29:14 - train: epoch 0020, iter [00300, 02526], lr: 0.000100, loss: 0.7454, CELoss: 0.7454, 
2022-10-16 04:29:48 - train: epoch 0020, iter [00400, 02526], lr: 0.000100, loss: 0.5018, CELoss: 0.5018, 
2022-10-16 04:30:21 - train: epoch 0020, iter [00500, 02526], lr: 0.000100, loss: 0.9364, CELoss: 0.9364, 
2022-10-16 04:30:54 - train: epoch 0020, iter [00600, 02526], lr: 0.000100, loss: 1.2491, CELoss: 1.2491, 
2022-10-16 04:31:28 - train: epoch 0020, iter [00700, 02526], lr: 0.000100, loss: 1.0853, CELoss: 1.0853, 
2022-10-16 04:32:01 - train: epoch 0020, iter [00800, 02526], lr: 0.000100, loss: 0.5104, CELoss: 0.5104, 
2022-10-16 04:32:35 - train: epoch 0020, iter [00900, 02526], lr: 0.000100, loss: 1.1026, CELoss: 1.1026, 
2022-10-16 04:33:09 - train: epoch 0020, iter [01000, 02526], lr: 0.000100, loss: 0.9195, CELoss: 0.9195, 
2022-10-16 04:33:42 - train: epoch 0020, iter [01100, 02526], lr: 0.000100, loss: 0.5777, CELoss: 0.5777, 
2022-10-16 04:34:16 - train: epoch 0020, iter [01200, 02526], lr: 0.000100, loss: 0.5494, CELoss: 0.5494, 
2022-10-16 04:34:49 - train: epoch 0020, iter [01300, 02526], lr: 0.000100, loss: 0.6123, CELoss: 0.6123, 
2022-10-16 04:35:23 - train: epoch 0020, iter [01400, 02526], lr: 0.000100, loss: 0.6598, CELoss: 0.6598, 
2022-10-16 04:35:56 - train: epoch 0020, iter [01500, 02526], lr: 0.000100, loss: 1.2646, CELoss: 1.2646, 
2022-10-16 04:36:30 - train: epoch 0020, iter [01600, 02526], lr: 0.000100, loss: 1.3331, CELoss: 1.3331, 
2022-10-16 04:37:03 - train: epoch 0020, iter [01700, 02526], lr: 0.000100, loss: 0.6286, CELoss: 0.6286, 
2022-10-16 04:37:37 - train: epoch 0020, iter [01800, 02526], lr: 0.000100, loss: 0.9620, CELoss: 0.9620, 
2022-10-16 04:38:11 - train: epoch 0020, iter [01900, 02526], lr: 0.000100, loss: 0.8786, CELoss: 0.8786, 
2022-10-16 04:38:44 - train: epoch 0020, iter [02000, 02526], lr: 0.000100, loss: 0.9517, CELoss: 0.9517, 
2022-10-16 04:39:17 - train: epoch 0020, iter [02100, 02526], lr: 0.000100, loss: 0.6734, CELoss: 0.6734, 
2022-10-16 04:39:51 - train: epoch 0020, iter [02200, 02526], lr: 0.000100, loss: 0.7139, CELoss: 0.7139, 
2022-10-16 04:40:24 - train: epoch 0020, iter [02300, 02526], lr: 0.000100, loss: 0.7792, CELoss: 0.7792, 
2022-10-16 04:40:58 - train: epoch 0020, iter [02400, 02526], lr: 0.000100, loss: 0.6035, CELoss: 0.6035, 
2022-10-16 04:41:31 - train: epoch 0020, iter [02500, 02526], lr: 0.000100, loss: 0.6590, CELoss: 0.6590, 
2022-10-16 04:41:41 - train: epoch 020, train_loss: 0.8154
2022-10-16 04:42:32 - eval: epoch: 020
test_loss: 0.9132214210629463
per_image_load_time: 1.067ms
per_image_inference_time: 18.236ms
exist_num_class: 150.0
mean_precision: 52.691385124202995
mean_recall: 39.48237816976133
mean_iou: 29.52880722084783
mean_dice: 41.278071121145594

2022-10-16 04:42:35 - until epoch: 020, best_metric: 29.529%
2022-10-16 04:42:35 - epoch 021 lr: 0.000100
2022-10-16 04:43:10 - train: epoch 0021, iter [00100, 02526], lr: 0.000100, loss: 0.5767, CELoss: 0.5767, 
2022-10-16 04:43:44 - train: epoch 0021, iter [00200, 02526], lr: 0.000100, loss: 0.6172, CELoss: 0.6172, 
2022-10-16 04:44:17 - train: epoch 0021, iter [00300, 02526], lr: 0.000100, loss: 0.4577, CELoss: 0.4577, 
2022-10-16 04:44:51 - train: epoch 0021, iter [00400, 02526], lr: 0.000100, loss: 0.5418, CELoss: 0.5418, 
2022-10-16 04:45:24 - train: epoch 0021, iter [00500, 02526], lr: 0.000100, loss: 0.7583, CELoss: 0.7583, 
2022-10-16 04:45:58 - train: epoch 0021, iter [00600, 02526], lr: 0.000100, loss: 0.7843, CELoss: 0.7843, 
2022-10-16 04:46:32 - train: epoch 0021, iter [00700, 02526], lr: 0.000100, loss: 0.5643, CELoss: 0.5643, 
2022-10-16 04:47:05 - train: epoch 0021, iter [00800, 02526], lr: 0.000100, loss: 1.0657, CELoss: 1.0657, 
2022-10-16 04:47:39 - train: epoch 0021, iter [00900, 02526], lr: 0.000100, loss: 0.7974, CELoss: 0.7974, 
2022-10-16 04:48:12 - train: epoch 0021, iter [01000, 02526], lr: 0.000100, loss: 0.5848, CELoss: 0.5848, 
2022-10-16 04:48:45 - train: epoch 0021, iter [01100, 02526], lr: 0.000100, loss: 0.6068, CELoss: 0.6068, 
2022-10-16 04:49:19 - train: epoch 0021, iter [01200, 02526], lr: 0.000100, loss: 0.8177, CELoss: 0.8177, 
2022-10-16 04:49:52 - train: epoch 0021, iter [01300, 02526], lr: 0.000100, loss: 0.7308, CELoss: 0.7308, 
2022-10-16 04:50:25 - train: epoch 0021, iter [01400, 02526], lr: 0.000100, loss: 1.0445, CELoss: 1.0445, 
2022-10-16 04:50:59 - train: epoch 0021, iter [01500, 02526], lr: 0.000100, loss: 0.5671, CELoss: 0.5671, 
2022-10-16 04:51:32 - train: epoch 0021, iter [01600, 02526], lr: 0.000100, loss: 0.7648, CELoss: 0.7648, 
2022-10-16 04:52:06 - train: epoch 0021, iter [01700, 02526], lr: 0.000100, loss: 0.7088, CELoss: 0.7088, 
2022-10-16 04:52:39 - train: epoch 0021, iter [01800, 02526], lr: 0.000100, loss: 0.6105, CELoss: 0.6105, 
2022-10-16 04:53:13 - train: epoch 0021, iter [01900, 02526], lr: 0.000100, loss: 1.2502, CELoss: 1.2502, 
2022-10-16 04:53:46 - train: epoch 0021, iter [02000, 02526], lr: 0.000100, loss: 0.7440, CELoss: 0.7440, 
2022-10-16 04:54:20 - train: epoch 0021, iter [02100, 02526], lr: 0.000100, loss: 0.8206, CELoss: 0.8206, 
2022-10-16 04:54:53 - train: epoch 0021, iter [02200, 02526], lr: 0.000100, loss: 0.5433, CELoss: 0.5433, 
2022-10-16 04:55:27 - train: epoch 0021, iter [02300, 02526], lr: 0.000100, loss: 1.1240, CELoss: 1.1240, 
2022-10-16 04:56:01 - train: epoch 0021, iter [02400, 02526], lr: 0.000100, loss: 0.9216, CELoss: 0.9216, 
2022-10-16 04:56:34 - train: epoch 0021, iter [02500, 02526], lr: 0.000100, loss: 1.2261, CELoss: 1.2261, 
2022-10-16 04:56:43 - train: epoch 021, train_loss: 0.7955
2022-10-16 04:56:46 - until epoch: 021, best_metric: 29.529%
2022-10-16 04:56:46 - epoch 022 lr: 0.000100
2022-10-16 04:57:21 - train: epoch 0022, iter [00100, 02526], lr: 0.000100, loss: 0.8171, CELoss: 0.8171, 
2022-10-16 04:57:55 - train: epoch 0022, iter [00200, 02526], lr: 0.000100, loss: 0.8490, CELoss: 0.8490, 
2022-10-16 04:58:29 - train: epoch 0022, iter [00300, 02526], lr: 0.000100, loss: 0.6613, CELoss: 0.6613, 
2022-10-16 04:59:02 - train: epoch 0022, iter [00400, 02526], lr: 0.000100, loss: 0.7047, CELoss: 0.7047, 
2022-10-16 04:59:36 - train: epoch 0022, iter [00500, 02526], lr: 0.000100, loss: 0.7383, CELoss: 0.7383, 
2022-10-16 05:00:09 - train: epoch 0022, iter [00600, 02526], lr: 0.000100, loss: 0.7479, CELoss: 0.7479, 
2022-10-16 05:00:43 - train: epoch 0022, iter [00700, 02526], lr: 0.000100, loss: 0.5497, CELoss: 0.5497, 
2022-10-16 05:01:16 - train: epoch 0022, iter [00800, 02526], lr: 0.000100, loss: 0.5739, CELoss: 0.5739, 
2022-10-16 05:01:50 - train: epoch 0022, iter [00900, 02526], lr: 0.000100, loss: 0.6415, CELoss: 0.6415, 
2022-10-16 05:02:23 - train: epoch 0022, iter [01000, 02526], lr: 0.000100, loss: 0.9896, CELoss: 0.9896, 
2022-10-16 05:02:57 - train: epoch 0022, iter [01100, 02526], lr: 0.000100, loss: 1.1896, CELoss: 1.1896, 
2022-10-16 05:03:31 - train: epoch 0022, iter [01200, 02526], lr: 0.000100, loss: 0.8221, CELoss: 0.8221, 
2022-10-16 05:04:04 - train: epoch 0022, iter [01300, 02526], lr: 0.000100, loss: 1.3426, CELoss: 1.3426, 
2022-10-16 05:04:38 - train: epoch 0022, iter [01400, 02526], lr: 0.000100, loss: 0.5896, CELoss: 0.5896, 
2022-10-16 05:05:11 - train: epoch 0022, iter [01500, 02526], lr: 0.000100, loss: 0.9476, CELoss: 0.9476, 
2022-10-16 05:05:45 - train: epoch 0022, iter [01600, 02526], lr: 0.000100, loss: 0.9991, CELoss: 0.9991, 
2022-10-16 05:06:18 - train: epoch 0022, iter [01700, 02526], lr: 0.000100, loss: 0.9346, CELoss: 0.9346, 
2022-10-16 05:06:52 - train: epoch 0022, iter [01800, 02526], lr: 0.000100, loss: 0.7310, CELoss: 0.7310, 
2022-10-16 05:07:25 - train: epoch 0022, iter [01900, 02526], lr: 0.000100, loss: 0.9448, CELoss: 0.9448, 
2022-10-16 05:07:59 - train: epoch 0022, iter [02000, 02526], lr: 0.000100, loss: 0.6109, CELoss: 0.6109, 
2022-10-16 05:08:32 - train: epoch 0022, iter [02100, 02526], lr: 0.000100, loss: 0.6921, CELoss: 0.6921, 
2022-10-16 05:09:05 - train: epoch 0022, iter [02200, 02526], lr: 0.000100, loss: 0.3676, CELoss: 0.3676, 
2022-10-16 05:09:39 - train: epoch 0022, iter [02300, 02526], lr: 0.000100, loss: 1.0056, CELoss: 1.0056, 
2022-10-16 05:10:13 - train: epoch 0022, iter [02400, 02526], lr: 0.000100, loss: 1.1011, CELoss: 1.1011, 
2022-10-16 05:10:46 - train: epoch 0022, iter [02500, 02526], lr: 0.000100, loss: 0.4721, CELoss: 0.4721, 
2022-10-16 05:10:56 - train: epoch 022, train_loss: 0.7946
2022-10-16 05:10:59 - until epoch: 022, best_metric: 29.529%
2022-10-16 05:10:59 - epoch 023 lr: 0.000100
2022-10-16 05:11:34 - train: epoch 0023, iter [00100, 02526], lr: 0.000100, loss: 0.6112, CELoss: 0.6112, 
2022-10-16 05:12:08 - train: epoch 0023, iter [00200, 02526], lr: 0.000100, loss: 0.5464, CELoss: 0.5464, 
2022-10-16 05:12:41 - train: epoch 0023, iter [00300, 02526], lr: 0.000100, loss: 0.8553, CELoss: 0.8553, 
2022-10-16 05:13:15 - train: epoch 0023, iter [00400, 02526], lr: 0.000100, loss: 0.5209, CELoss: 0.5209, 
2022-10-16 05:13:48 - train: epoch 0023, iter [00500, 02526], lr: 0.000100, loss: 0.6683, CELoss: 0.6683, 
2022-10-16 05:14:22 - train: epoch 0023, iter [00600, 02526], lr: 0.000100, loss: 0.6213, CELoss: 0.6213, 
2022-10-16 05:14:55 - train: epoch 0023, iter [00700, 02526], lr: 0.000100, loss: 0.8890, CELoss: 0.8890, 
2022-10-16 05:15:29 - train: epoch 0023, iter [00800, 02526], lr: 0.000100, loss: 0.8542, CELoss: 0.8542, 
2022-10-16 05:16:03 - train: epoch 0023, iter [00900, 02526], lr: 0.000100, loss: 0.6722, CELoss: 0.6722, 
2022-10-16 05:16:36 - train: epoch 0023, iter [01000, 02526], lr: 0.000100, loss: 0.6018, CELoss: 0.6018, 
2022-10-16 05:17:10 - train: epoch 0023, iter [01100, 02526], lr: 0.000100, loss: 0.6361, CELoss: 0.6361, 
2022-10-16 05:17:43 - train: epoch 0023, iter [01200, 02526], lr: 0.000100, loss: 0.9268, CELoss: 0.9268, 
2022-10-16 05:18:17 - train: epoch 0023, iter [01300, 02526], lr: 0.000100, loss: 0.5320, CELoss: 0.5320, 
2022-10-16 05:18:50 - train: epoch 0023, iter [01400, 02526], lr: 0.000100, loss: 0.8207, CELoss: 0.8207, 
2022-10-16 05:19:24 - train: epoch 0023, iter [01500, 02526], lr: 0.000100, loss: 0.7256, CELoss: 0.7256, 
2022-10-16 05:19:57 - train: epoch 0023, iter [01600, 02526], lr: 0.000100, loss: 0.7949, CELoss: 0.7949, 
2022-10-16 05:20:31 - train: epoch 0023, iter [01700, 02526], lr: 0.000100, loss: 0.8027, CELoss: 0.8027, 
2022-10-16 05:21:05 - train: epoch 0023, iter [01800, 02526], lr: 0.000100, loss: 0.5682, CELoss: 0.5682, 
2022-10-16 05:21:38 - train: epoch 0023, iter [01900, 02526], lr: 0.000100, loss: 0.6776, CELoss: 0.6776, 
2022-10-16 05:22:12 - train: epoch 0023, iter [02000, 02526], lr: 0.000100, loss: 0.5685, CELoss: 0.5685, 
2022-10-16 05:22:45 - train: epoch 0023, iter [02100, 02526], lr: 0.000100, loss: 0.6882, CELoss: 0.6882, 
2022-10-16 05:23:19 - train: epoch 0023, iter [02200, 02526], lr: 0.000100, loss: 1.1303, CELoss: 1.1303, 
2022-10-16 05:23:53 - train: epoch 0023, iter [02300, 02526], lr: 0.000100, loss: 1.0512, CELoss: 1.0512, 
2022-10-16 05:24:27 - train: epoch 0023, iter [02400, 02526], lr: 0.000100, loss: 0.8657, CELoss: 0.8657, 
2022-10-16 05:25:00 - train: epoch 0023, iter [02500, 02526], lr: 0.000100, loss: 0.6243, CELoss: 0.6243, 
2022-10-16 05:25:10 - train: epoch 023, train_loss: 0.7749
2022-10-16 05:25:12 - until epoch: 023, best_metric: 29.529%
2022-10-16 05:25:12 - epoch 024 lr: 0.000100
2022-10-16 05:25:48 - train: epoch 0024, iter [00100, 02526], lr: 0.000100, loss: 0.6501, CELoss: 0.6501, 
2022-10-16 05:26:21 - train: epoch 0024, iter [00200, 02526], lr: 0.000100, loss: 0.3340, CELoss: 0.3340, 
2022-10-16 05:26:55 - train: epoch 0024, iter [00300, 02526], lr: 0.000100, loss: 0.8101, CELoss: 0.8101, 
2022-10-16 05:27:28 - train: epoch 0024, iter [00400, 02526], lr: 0.000100, loss: 0.8959, CELoss: 0.8959, 
2022-10-16 05:28:02 - train: epoch 0024, iter [00500, 02526], lr: 0.000100, loss: 0.8653, CELoss: 0.8653, 
2022-10-16 05:28:35 - train: epoch 0024, iter [00600, 02526], lr: 0.000100, loss: 0.9210, CELoss: 0.9210, 
2022-10-16 05:29:09 - train: epoch 0024, iter [00700, 02526], lr: 0.000100, loss: 1.5769, CELoss: 1.5769, 
2022-10-16 05:29:42 - train: epoch 0024, iter [00800, 02526], lr: 0.000100, loss: 0.9779, CELoss: 0.9779, 
2022-10-16 05:30:16 - train: epoch 0024, iter [00900, 02526], lr: 0.000100, loss: 0.8210, CELoss: 0.8210, 
2022-10-16 05:30:49 - train: epoch 0024, iter [01000, 02526], lr: 0.000100, loss: 0.7293, CELoss: 0.7293, 
2022-10-16 05:31:23 - train: epoch 0024, iter [01100, 02526], lr: 0.000100, loss: 0.9794, CELoss: 0.9794, 
2022-10-16 05:31:56 - train: epoch 0024, iter [01200, 02526], lr: 0.000100, loss: 0.8395, CELoss: 0.8395, 
2022-10-16 05:32:30 - train: epoch 0024, iter [01300, 02526], lr: 0.000100, loss: 0.6056, CELoss: 0.6056, 
2022-10-16 05:33:03 - train: epoch 0024, iter [01400, 02526], lr: 0.000100, loss: 0.7751, CELoss: 0.7751, 
2022-10-16 05:33:37 - train: epoch 0024, iter [01500, 02526], lr: 0.000100, loss: 0.5559, CELoss: 0.5559, 
2022-10-16 05:34:10 - train: epoch 0024, iter [01600, 02526], lr: 0.000100, loss: 1.3874, CELoss: 1.3874, 
2022-10-16 05:34:44 - train: epoch 0024, iter [01700, 02526], lr: 0.000100, loss: 0.6393, CELoss: 0.6393, 
2022-10-16 05:35:17 - train: epoch 0024, iter [01800, 02526], lr: 0.000100, loss: 0.4522, CELoss: 0.4522, 
2022-10-16 05:35:51 - train: epoch 0024, iter [01900, 02526], lr: 0.000100, loss: 0.6936, CELoss: 0.6936, 
2022-10-16 05:36:24 - train: epoch 0024, iter [02000, 02526], lr: 0.000100, loss: 1.5627, CELoss: 1.5627, 
2022-10-16 05:36:58 - train: epoch 0024, iter [02100, 02526], lr: 0.000100, loss: 1.0893, CELoss: 1.0893, 
2022-10-16 05:37:31 - train: epoch 0024, iter [02200, 02526], lr: 0.000100, loss: 0.4028, CELoss: 0.4028, 
2022-10-16 05:38:04 - train: epoch 0024, iter [02300, 02526], lr: 0.000100, loss: 0.8272, CELoss: 0.8272, 
2022-10-16 05:38:38 - train: epoch 0024, iter [02400, 02526], lr: 0.000100, loss: 0.8944, CELoss: 0.8944, 
2022-10-16 05:39:11 - train: epoch 0024, iter [02500, 02526], lr: 0.000100, loss: 0.6973, CELoss: 0.6973, 
2022-10-16 05:39:21 - train: epoch 024, train_loss: 0.7632
2022-10-16 05:39:23 - until epoch: 024, best_metric: 29.529%
2022-10-16 05:39:23 - epoch 025 lr: 0.000100
2022-10-16 05:39:59 - train: epoch 0025, iter [00100, 02526], lr: 0.000100, loss: 0.5909, CELoss: 0.5909, 
2022-10-16 05:40:33 - train: epoch 0025, iter [00200, 02526], lr: 0.000100, loss: 1.5869, CELoss: 1.5869, 
2022-10-16 05:41:06 - train: epoch 0025, iter [00300, 02526], lr: 0.000100, loss: 0.9252, CELoss: 0.9252, 
2022-10-16 05:41:40 - train: epoch 0025, iter [00400, 02526], lr: 0.000100, loss: 0.4246, CELoss: 0.4246, 
2022-10-16 05:42:13 - train: epoch 0025, iter [00500, 02526], lr: 0.000100, loss: 0.4257, CELoss: 0.4257, 
2022-10-16 05:42:46 - train: epoch 0025, iter [00600, 02526], lr: 0.000100, loss: 0.7923, CELoss: 0.7923, 
2022-10-16 05:43:20 - train: epoch 0025, iter [00700, 02526], lr: 0.000100, loss: 0.7245, CELoss: 0.7245, 
2022-10-16 05:43:54 - train: epoch 0025, iter [00800, 02526], lr: 0.000100, loss: 0.5642, CELoss: 0.5642, 
2022-10-16 05:44:27 - train: epoch 0025, iter [00900, 02526], lr: 0.000100, loss: 0.4950, CELoss: 0.4950, 
2022-10-16 05:45:01 - train: epoch 0025, iter [01000, 02526], lr: 0.000100, loss: 0.8282, CELoss: 0.8282, 
2022-10-16 05:45:34 - train: epoch 0025, iter [01100, 02526], lr: 0.000100, loss: 1.1316, CELoss: 1.1316, 
2022-10-16 05:46:08 - train: epoch 0025, iter [01200, 02526], lr: 0.000100, loss: 0.6510, CELoss: 0.6510, 
2022-10-16 05:46:41 - train: epoch 0025, iter [01300, 02526], lr: 0.000100, loss: 0.7458, CELoss: 0.7458, 
2022-10-16 05:47:15 - train: epoch 0025, iter [01400, 02526], lr: 0.000100, loss: 0.7426, CELoss: 0.7426, 
2022-10-16 05:47:48 - train: epoch 0025, iter [01500, 02526], lr: 0.000100, loss: 0.8689, CELoss: 0.8689, 
2022-10-16 05:48:21 - train: epoch 0025, iter [01600, 02526], lr: 0.000100, loss: 0.7504, CELoss: 0.7504, 
2022-10-16 05:48:55 - train: epoch 0025, iter [01700, 02526], lr: 0.000100, loss: 0.6313, CELoss: 0.6313, 
2022-10-16 05:49:28 - train: epoch 0025, iter [01800, 02526], lr: 0.000100, loss: 0.6198, CELoss: 0.6198, 
2022-10-16 05:50:02 - train: epoch 0025, iter [01900, 02526], lr: 0.000100, loss: 1.1017, CELoss: 1.1017, 
2022-10-16 05:50:36 - train: epoch 0025, iter [02000, 02526], lr: 0.000100, loss: 0.4417, CELoss: 0.4417, 
2022-10-16 05:51:09 - train: epoch 0025, iter [02100, 02526], lr: 0.000100, loss: 0.7602, CELoss: 0.7602, 
2022-10-16 05:51:43 - train: epoch 0025, iter [02200, 02526], lr: 0.000100, loss: 0.7585, CELoss: 0.7585, 
2022-10-16 05:52:16 - train: epoch 0025, iter [02300, 02526], lr: 0.000100, loss: 0.7472, CELoss: 0.7472, 
2022-10-16 05:52:50 - train: epoch 0025, iter [02400, 02526], lr: 0.000100, loss: 0.7323, CELoss: 0.7323, 
2022-10-16 05:53:23 - train: epoch 0025, iter [02500, 02526], lr: 0.000100, loss: 0.9373, CELoss: 0.9373, 
2022-10-16 05:53:33 - train: epoch 025, train_loss: 0.7523
2022-10-16 05:54:24 - eval: epoch: 025
test_loss: 0.9147235359847545
per_image_load_time: 1.102ms
per_image_inference_time: 18.281ms
exist_num_class: 150.0
mean_precision: 50.891202777801354
mean_recall: 40.37294217123228
mean_iou: 29.80748678717727
mean_dice: 41.759397872618656

2022-10-16 05:54:27 - until epoch: 025, best_metric: 29.807%
2022-10-16 05:54:27 - epoch 026 lr: 0.000100
2022-10-16 05:55:03 - train: epoch 0026, iter [00100, 02526], lr: 0.000100, loss: 1.2393, CELoss: 1.2393, 
2022-10-16 05:55:36 - train: epoch 0026, iter [00200, 02526], lr: 0.000100, loss: 0.5768, CELoss: 0.5768, 
2022-10-16 05:56:10 - train: epoch 0026, iter [00300, 02526], lr: 0.000100, loss: 1.2411, CELoss: 1.2411, 
2022-10-16 05:56:43 - train: epoch 0026, iter [00400, 02526], lr: 0.000100, loss: 0.6569, CELoss: 0.6569, 
2022-10-16 05:57:16 - train: epoch 0026, iter [00500, 02526], lr: 0.000100, loss: 0.8369, CELoss: 0.8369, 
2022-10-16 05:57:50 - train: epoch 0026, iter [00600, 02526], lr: 0.000100, loss: 0.7324, CELoss: 0.7324, 
2022-10-16 05:58:23 - train: epoch 0026, iter [00700, 02526], lr: 0.000100, loss: 0.7107, CELoss: 0.7107, 
2022-10-16 05:58:56 - train: epoch 0026, iter [00800, 02526], lr: 0.000100, loss: 0.6293, CELoss: 0.6293, 
2022-10-16 05:59:29 - train: epoch 0026, iter [00900, 02526], lr: 0.000100, loss: 0.4579, CELoss: 0.4579, 
2022-10-16 06:00:03 - train: epoch 0026, iter [01000, 02526], lr: 0.000100, loss: 1.2258, CELoss: 1.2258, 
2022-10-16 06:00:37 - train: epoch 0026, iter [01100, 02526], lr: 0.000100, loss: 1.0205, CELoss: 1.0205, 
2022-10-16 06:01:10 - train: epoch 0026, iter [01200, 02526], lr: 0.000100, loss: 0.9725, CELoss: 0.9725, 
2022-10-16 06:01:44 - train: epoch 0026, iter [01300, 02526], lr: 0.000100, loss: 1.0825, CELoss: 1.0825, 
2022-10-16 06:02:17 - train: epoch 0026, iter [01400, 02526], lr: 0.000100, loss: 0.7695, CELoss: 0.7695, 
2022-10-16 06:02:50 - train: epoch 0026, iter [01500, 02526], lr: 0.000100, loss: 0.8160, CELoss: 0.8160, 
2022-10-16 06:03:24 - train: epoch 0026, iter [01600, 02526], lr: 0.000100, loss: 0.6801, CELoss: 0.6801, 
2022-10-16 06:03:58 - train: epoch 0026, iter [01700, 02526], lr: 0.000100, loss: 0.6788, CELoss: 0.6788, 
2022-10-16 06:04:31 - train: epoch 0026, iter [01800, 02526], lr: 0.000100, loss: 0.6438, CELoss: 0.6438, 
2022-10-16 06:05:05 - train: epoch 0026, iter [01900, 02526], lr: 0.000100, loss: 0.5728, CELoss: 0.5728, 
2022-10-16 06:05:38 - train: epoch 0026, iter [02000, 02526], lr: 0.000100, loss: 0.7647, CELoss: 0.7647, 
2022-10-16 06:06:12 - train: epoch 0026, iter [02100, 02526], lr: 0.000100, loss: 1.1333, CELoss: 1.1333, 
2022-10-16 06:06:45 - train: epoch 0026, iter [02200, 02526], lr: 0.000100, loss: 0.7786, CELoss: 0.7786, 
2022-10-16 06:07:18 - train: epoch 0026, iter [02300, 02526], lr: 0.000100, loss: 0.8643, CELoss: 0.8643, 
2022-10-16 06:07:52 - train: epoch 0026, iter [02400, 02526], lr: 0.000100, loss: 0.5809, CELoss: 0.5809, 
2022-10-16 06:08:25 - train: epoch 0026, iter [02500, 02526], lr: 0.000100, loss: 1.8428, CELoss: 1.8428, 
2022-10-16 06:08:35 - train: epoch 026, train_loss: 0.7355
2022-10-16 06:08:36 - until epoch: 026, best_metric: 29.807%
2022-10-16 06:08:36 - epoch 027 lr: 0.000100
2022-10-16 06:09:12 - train: epoch 0027, iter [00100, 02526], lr: 0.000100, loss: 1.4869, CELoss: 1.4869, 
2022-10-16 06:09:46 - train: epoch 0027, iter [00200, 02526], lr: 0.000100, loss: 0.8778, CELoss: 0.8778, 
2022-10-16 06:10:19 - train: epoch 0027, iter [00300, 02526], lr: 0.000100, loss: 0.6033, CELoss: 0.6033, 
2022-10-16 06:10:52 - train: epoch 0027, iter [00400, 02526], lr: 0.000100, loss: 0.5862, CELoss: 0.5862, 
2022-10-16 06:11:26 - train: epoch 0027, iter [00500, 02526], lr: 0.000100, loss: 0.8999, CELoss: 0.8999, 
2022-10-16 06:11:59 - train: epoch 0027, iter [00600, 02526], lr: 0.000100, loss: 0.7148, CELoss: 0.7148, 
2022-10-16 06:12:33 - train: epoch 0027, iter [00700, 02526], lr: 0.000100, loss: 0.8875, CELoss: 0.8875, 
2022-10-16 06:13:06 - train: epoch 0027, iter [00800, 02526], lr: 0.000100, loss: 0.8114, CELoss: 0.8114, 
2022-10-16 06:13:40 - train: epoch 0027, iter [00900, 02526], lr: 0.000100, loss: 0.4953, CELoss: 0.4953, 
2022-10-16 06:14:13 - train: epoch 0027, iter [01000, 02526], lr: 0.000100, loss: 1.0042, CELoss: 1.0042, 
2022-10-16 06:14:47 - train: epoch 0027, iter [01100, 02526], lr: 0.000100, loss: 0.5606, CELoss: 0.5606, 
2022-10-16 06:15:21 - train: epoch 0027, iter [01200, 02526], lr: 0.000100, loss: 0.9008, CELoss: 0.9008, 
2022-10-16 06:15:54 - train: epoch 0027, iter [01300, 02526], lr: 0.000100, loss: 0.5815, CELoss: 0.5815, 
2022-10-16 06:16:28 - train: epoch 0027, iter [01400, 02526], lr: 0.000100, loss: 0.5518, CELoss: 0.5518, 
2022-10-16 06:17:01 - train: epoch 0027, iter [01500, 02526], lr: 0.000100, loss: 0.5374, CELoss: 0.5374, 
2022-10-16 06:17:35 - train: epoch 0027, iter [01600, 02526], lr: 0.000100, loss: 0.6355, CELoss: 0.6355, 
2022-10-16 06:18:08 - train: epoch 0027, iter [01700, 02526], lr: 0.000100, loss: 0.3908, CELoss: 0.3908, 
2022-10-16 06:18:42 - train: epoch 0027, iter [01800, 02526], lr: 0.000100, loss: 0.8056, CELoss: 0.8056, 
2022-10-16 06:19:15 - train: epoch 0027, iter [01900, 02526], lr: 0.000100, loss: 0.5339, CELoss: 0.5339, 
2022-10-16 06:19:48 - train: epoch 0027, iter [02000, 02526], lr: 0.000100, loss: 0.5627, CELoss: 0.5627, 
2022-10-16 06:20:22 - train: epoch 0027, iter [02100, 02526], lr: 0.000100, loss: 0.5587, CELoss: 0.5587, 
2022-10-16 06:20:55 - train: epoch 0027, iter [02200, 02526], lr: 0.000100, loss: 0.8846, CELoss: 0.8846, 
2022-10-16 06:21:29 - train: epoch 0027, iter [02300, 02526], lr: 0.000100, loss: 1.6588, CELoss: 1.6588, 
2022-10-16 06:22:03 - train: epoch 0027, iter [02400, 02526], lr: 0.000100, loss: 0.8625, CELoss: 0.8625, 
2022-10-16 06:22:36 - train: epoch 0027, iter [02500, 02526], lr: 0.000100, loss: 1.1603, CELoss: 1.1603, 
2022-10-16 06:22:46 - train: epoch 027, train_loss: 0.7368
2022-10-16 06:22:48 - until epoch: 027, best_metric: 29.807%
2022-10-16 06:22:48 - epoch 028 lr: 0.000100
2022-10-16 06:23:24 - train: epoch 0028, iter [00100, 02526], lr: 0.000100, loss: 1.0000, CELoss: 1.0000, 
2022-10-16 06:23:58 - train: epoch 0028, iter [00200, 02526], lr: 0.000100, loss: 0.8177, CELoss: 0.8177, 
2022-10-16 06:24:31 - train: epoch 0028, iter [00300, 02526], lr: 0.000100, loss: 0.6214, CELoss: 0.6214, 
2022-10-16 06:25:04 - train: epoch 0028, iter [00400, 02526], lr: 0.000100, loss: 1.0145, CELoss: 1.0145, 
2022-10-16 06:25:37 - train: epoch 0028, iter [00500, 02526], lr: 0.000100, loss: 0.4587, CELoss: 0.4587, 
2022-10-16 06:26:11 - train: epoch 0028, iter [00600, 02526], lr: 0.000100, loss: 0.5058, CELoss: 0.5058, 
2022-10-16 06:26:44 - train: epoch 0028, iter [00700, 02526], lr: 0.000100, loss: 0.7387, CELoss: 0.7387, 
2022-10-16 06:27:18 - train: epoch 0028, iter [00800, 02526], lr: 0.000100, loss: 0.4404, CELoss: 0.4404, 
2022-10-16 06:27:51 - train: epoch 0028, iter [00900, 02526], lr: 0.000100, loss: 0.8375, CELoss: 0.8375, 
2022-10-16 06:28:25 - train: epoch 0028, iter [01000, 02526], lr: 0.000100, loss: 1.3565, CELoss: 1.3565, 
2022-10-16 06:28:58 - train: epoch 0028, iter [01100, 02526], lr: 0.000100, loss: 0.5297, CELoss: 0.5297, 
2022-10-16 06:29:32 - train: epoch 0028, iter [01200, 02526], lr: 0.000100, loss: 0.4855, CELoss: 0.4855, 
2022-10-16 06:30:05 - train: epoch 0028, iter [01300, 02526], lr: 0.000100, loss: 0.8883, CELoss: 0.8883, 
2022-10-16 06:30:39 - train: epoch 0028, iter [01400, 02526], lr: 0.000100, loss: 0.8301, CELoss: 0.8301, 
2022-10-16 06:31:12 - train: epoch 0028, iter [01500, 02526], lr: 0.000100, loss: 0.5685, CELoss: 0.5685, 
2022-10-16 06:31:46 - train: epoch 0028, iter [01600, 02526], lr: 0.000100, loss: 0.5140, CELoss: 0.5140, 
2022-10-16 06:32:19 - train: epoch 0028, iter [01700, 02526], lr: 0.000100, loss: 1.0133, CELoss: 1.0133, 
2022-10-16 06:32:53 - train: epoch 0028, iter [01800, 02526], lr: 0.000100, loss: 0.4885, CELoss: 0.4885, 
2022-10-16 06:33:26 - train: epoch 0028, iter [01900, 02526], lr: 0.000100, loss: 0.6740, CELoss: 0.6740, 
2022-10-16 06:34:00 - train: epoch 0028, iter [02000, 02526], lr: 0.000100, loss: 0.8538, CELoss: 0.8538, 
2022-10-16 06:34:33 - train: epoch 0028, iter [02100, 02526], lr: 0.000100, loss: 0.7612, CELoss: 0.7612, 
2022-10-16 06:35:07 - train: epoch 0028, iter [02200, 02526], lr: 0.000100, loss: 0.8570, CELoss: 0.8570, 
2022-10-16 06:35:40 - train: epoch 0028, iter [02300, 02526], lr: 0.000100, loss: 0.8806, CELoss: 0.8806, 
2022-10-16 06:36:14 - train: epoch 0028, iter [02400, 02526], lr: 0.000100, loss: 0.6046, CELoss: 0.6046, 
2022-10-16 06:36:47 - train: epoch 0028, iter [02500, 02526], lr: 0.000100, loss: 0.6161, CELoss: 0.6161, 
2022-10-16 06:36:57 - train: epoch 028, train_loss: 0.7261
2022-10-16 06:37:00 - until epoch: 028, best_metric: 29.807%
2022-10-16 06:37:00 - epoch 029 lr: 0.000100
2022-10-16 06:37:36 - train: epoch 0029, iter [00100, 02526], lr: 0.000100, loss: 0.5175, CELoss: 0.5175, 
2022-10-16 06:38:09 - train: epoch 0029, iter [00200, 02526], lr: 0.000100, loss: 0.4947, CELoss: 0.4947, 
2022-10-16 06:38:43 - train: epoch 0029, iter [00300, 02526], lr: 0.000100, loss: 0.4392, CELoss: 0.4392, 
2022-10-16 06:39:17 - train: epoch 0029, iter [00400, 02526], lr: 0.000100, loss: 0.9814, CELoss: 0.9814, 
2022-10-16 06:39:50 - train: epoch 0029, iter [00500, 02526], lr: 0.000100, loss: 0.6819, CELoss: 0.6819, 
2022-10-16 06:40:23 - train: epoch 0029, iter [00600, 02526], lr: 0.000100, loss: 0.6187, CELoss: 0.6187, 
2022-10-16 06:40:57 - train: epoch 0029, iter [00700, 02526], lr: 0.000100, loss: 0.6026, CELoss: 0.6026, 
2022-10-16 06:41:30 - train: epoch 0029, iter [00800, 02526], lr: 0.000100, loss: 0.3140, CELoss: 0.3140, 
2022-10-16 06:42:04 - train: epoch 0029, iter [00900, 02526], lr: 0.000100, loss: 0.4222, CELoss: 0.4222, 
2022-10-16 06:42:37 - train: epoch 0029, iter [01000, 02526], lr: 0.000100, loss: 0.8671, CELoss: 0.8671, 
2022-10-16 06:43:11 - train: epoch 0029, iter [01100, 02526], lr: 0.000100, loss: 0.9376, CELoss: 0.9376, 
2022-10-16 06:43:44 - train: epoch 0029, iter [01200, 02526], lr: 0.000100, loss: 1.4407, CELoss: 1.4407, 
2022-10-16 06:44:18 - train: epoch 0029, iter [01300, 02526], lr: 0.000100, loss: 0.9444, CELoss: 0.9444, 
2022-10-16 06:44:51 - train: epoch 0029, iter [01400, 02526], lr: 0.000100, loss: 0.4110, CELoss: 0.4110, 
2022-10-16 06:45:25 - train: epoch 0029, iter [01500, 02526], lr: 0.000100, loss: 0.5651, CELoss: 0.5651, 
2022-10-16 06:45:59 - train: epoch 0029, iter [01600, 02526], lr: 0.000100, loss: 0.4745, CELoss: 0.4745, 
2022-10-16 06:46:32 - train: epoch 0029, iter [01700, 02526], lr: 0.000100, loss: 0.7994, CELoss: 0.7994, 
2022-10-16 06:47:06 - train: epoch 0029, iter [01800, 02526], lr: 0.000100, loss: 1.0459, CELoss: 1.0459, 
2022-10-16 06:47:39 - train: epoch 0029, iter [01900, 02526], lr: 0.000100, loss: 0.4699, CELoss: 0.4699, 
2022-10-16 06:48:13 - train: epoch 0029, iter [02000, 02526], lr: 0.000100, loss: 0.7629, CELoss: 0.7629, 
2022-10-16 06:48:47 - train: epoch 0029, iter [02100, 02526], lr: 0.000100, loss: 0.5043, CELoss: 0.5043, 
2022-10-16 06:49:20 - train: epoch 0029, iter [02200, 02526], lr: 0.000100, loss: 0.7070, CELoss: 0.7070, 
2022-10-16 06:49:54 - train: epoch 0029, iter [02300, 02526], lr: 0.000100, loss: 0.7384, CELoss: 0.7384, 
2022-10-16 06:50:27 - train: epoch 0029, iter [02400, 02526], lr: 0.000100, loss: 0.9911, CELoss: 0.9911, 
2022-10-16 06:51:00 - train: epoch 0029, iter [02500, 02526], lr: 0.000100, loss: 0.6931, CELoss: 0.6931, 
2022-10-16 06:51:10 - train: epoch 029, train_loss: 0.7055
2022-10-16 06:51:12 - until epoch: 029, best_metric: 29.807%
2022-10-16 06:51:12 - epoch 030 lr: 0.000100
2022-10-16 06:51:47 - train: epoch 0030, iter [00100, 02526], lr: 0.000100, loss: 0.5835, CELoss: 0.5835, 
2022-10-16 06:52:21 - train: epoch 0030, iter [00200, 02526], lr: 0.000100, loss: 0.4514, CELoss: 0.4514, 
2022-10-16 06:52:55 - train: epoch 0030, iter [00300, 02526], lr: 0.000100, loss: 0.4333, CELoss: 0.4333, 
2022-10-16 06:53:28 - train: epoch 0030, iter [00400, 02526], lr: 0.000100, loss: 0.6518, CELoss: 0.6518, 
2022-10-16 06:54:02 - train: epoch 0030, iter [00500, 02526], lr: 0.000100, loss: 0.3808, CELoss: 0.3808, 
2022-10-16 06:54:35 - train: epoch 0030, iter [00600, 02526], lr: 0.000100, loss: 0.5140, CELoss: 0.5140, 
2022-10-16 06:55:09 - train: epoch 0030, iter [00700, 02526], lr: 0.000100, loss: 0.8989, CELoss: 0.8989, 
2022-10-16 06:55:42 - train: epoch 0030, iter [00800, 02526], lr: 0.000100, loss: 0.5032, CELoss: 0.5032, 
2022-10-16 06:56:16 - train: epoch 0030, iter [00900, 02526], lr: 0.000100, loss: 1.3590, CELoss: 1.3590, 
2022-10-16 06:56:49 - train: epoch 0030, iter [01000, 02526], lr: 0.000100, loss: 0.8744, CELoss: 0.8744, 
2022-10-16 06:57:22 - train: epoch 0030, iter [01100, 02526], lr: 0.000100, loss: 0.5172, CELoss: 0.5172, 
2022-10-16 06:57:56 - train: epoch 0030, iter [01200, 02526], lr: 0.000100, loss: 0.9643, CELoss: 0.9643, 
2022-10-16 06:58:29 - train: epoch 0030, iter [01300, 02526], lr: 0.000100, loss: 1.0469, CELoss: 1.0469, 
2022-10-16 06:59:03 - train: epoch 0030, iter [01400, 02526], lr: 0.000100, loss: 0.3144, CELoss: 0.3144, 
2022-10-16 06:59:36 - train: epoch 0030, iter [01500, 02526], lr: 0.000100, loss: 0.7275, CELoss: 0.7275, 
2022-10-16 07:00:10 - train: epoch 0030, iter [01600, 02526], lr: 0.000100, loss: 0.5849, CELoss: 0.5849, 
2022-10-16 07:00:43 - train: epoch 0030, iter [01700, 02526], lr: 0.000100, loss: 0.8094, CELoss: 0.8094, 
2022-10-16 07:01:17 - train: epoch 0030, iter [01800, 02526], lr: 0.000100, loss: 0.4594, CELoss: 0.4594, 
2022-10-16 07:01:50 - train: epoch 0030, iter [01900, 02526], lr: 0.000100, loss: 0.6679, CELoss: 0.6679, 
2022-10-16 07:02:24 - train: epoch 0030, iter [02000, 02526], lr: 0.000100, loss: 0.8795, CELoss: 0.8795, 
2022-10-16 07:02:58 - train: epoch 0030, iter [02100, 02526], lr: 0.000100, loss: 0.6155, CELoss: 0.6155, 
2022-10-16 07:03:31 - train: epoch 0030, iter [02200, 02526], lr: 0.000100, loss: 1.2188, CELoss: 1.2188, 
2022-10-16 07:04:05 - train: epoch 0030, iter [02300, 02526], lr: 0.000100, loss: 0.7997, CELoss: 0.7997, 
2022-10-16 07:04:38 - train: epoch 0030, iter [02400, 02526], lr: 0.000100, loss: 0.7054, CELoss: 0.7054, 
2022-10-16 07:05:11 - train: epoch 0030, iter [02500, 02526], lr: 0.000100, loss: 0.7129, CELoss: 0.7129, 
2022-10-16 07:05:22 - train: epoch 030, train_loss: 0.7013
2022-10-16 07:06:12 - eval: epoch: 030
test_loss: 0.8840916360020638
per_image_load_time: 1.026ms
per_image_inference_time: 18.370ms
exist_num_class: 150.0
mean_precision: 54.77575852661407
mean_recall: 42.1585222404647
mean_iou: 32.357099880110376
mean_dice: 44.88877006185501

2022-10-16 07:06:16 - until epoch: 030, best_metric: 32.357%
2022-10-16 07:06:16 - epoch 031 lr: 0.000100
2022-10-16 07:06:51 - train: epoch 0031, iter [00100, 02526], lr: 0.000100, loss: 0.5408, CELoss: 0.5408, 
2022-10-16 07:07:24 - train: epoch 0031, iter [00200, 02526], lr: 0.000100, loss: 0.6440, CELoss: 0.6440, 
2022-10-16 07:07:58 - train: epoch 0031, iter [00300, 02526], lr: 0.000100, loss: 0.6452, CELoss: 0.6452, 
2022-10-16 07:08:31 - train: epoch 0031, iter [00400, 02526], lr: 0.000100, loss: 0.6076, CELoss: 0.6076, 
2022-10-16 07:09:05 - train: epoch 0031, iter [00500, 02526], lr: 0.000100, loss: 1.6243, CELoss: 1.6243, 
2022-10-16 07:09:39 - train: epoch 0031, iter [00600, 02526], lr: 0.000100, loss: 1.0756, CELoss: 1.0756, 
2022-10-16 07:10:12 - train: epoch 0031, iter [00700, 02526], lr: 0.000100, loss: 0.7268, CELoss: 0.7268, 
2022-10-16 07:10:46 - train: epoch 0031, iter [00800, 02526], lr: 0.000100, loss: 0.7847, CELoss: 0.7847, 
2022-10-16 07:11:20 - train: epoch 0031, iter [00900, 02526], lr: 0.000100, loss: 0.5731, CELoss: 0.5731, 
2022-10-16 07:11:53 - train: epoch 0031, iter [01000, 02526], lr: 0.000100, loss: 0.7878, CELoss: 0.7878, 
2022-10-16 07:12:27 - train: epoch 0031, iter [01100, 02526], lr: 0.000100, loss: 0.6706, CELoss: 0.6706, 
2022-10-16 07:13:00 - train: epoch 0031, iter [01200, 02526], lr: 0.000100, loss: 0.5733, CELoss: 0.5733, 
2022-10-16 07:13:34 - train: epoch 0031, iter [01300, 02526], lr: 0.000100, loss: 0.6509, CELoss: 0.6509, 
2022-10-16 07:14:07 - train: epoch 0031, iter [01400, 02526], lr: 0.000100, loss: 0.3494, CELoss: 0.3494, 
2022-10-16 07:14:41 - train: epoch 0031, iter [01500, 02526], lr: 0.000100, loss: 0.6465, CELoss: 0.6465, 
2022-10-16 07:15:14 - train: epoch 0031, iter [01600, 02526], lr: 0.000100, loss: 0.8036, CELoss: 0.8036, 
2022-10-16 07:15:48 - train: epoch 0031, iter [01700, 02526], lr: 0.000100, loss: 0.3488, CELoss: 0.3488, 
2022-10-16 07:16:22 - train: epoch 0031, iter [01800, 02526], lr: 0.000100, loss: 0.5934, CELoss: 0.5934, 
2022-10-16 07:16:55 - train: epoch 0031, iter [01900, 02526], lr: 0.000100, loss: 0.5832, CELoss: 0.5832, 
2022-10-16 07:17:29 - train: epoch 0031, iter [02000, 02526], lr: 0.000100, loss: 0.5049, CELoss: 0.5049, 
2022-10-16 07:18:02 - train: epoch 0031, iter [02100, 02526], lr: 0.000100, loss: 0.7313, CELoss: 0.7313, 
2022-10-16 07:18:36 - train: epoch 0031, iter [02200, 02526], lr: 0.000100, loss: 0.5244, CELoss: 0.5244, 
2022-10-16 07:19:09 - train: epoch 0031, iter [02300, 02526], lr: 0.000100, loss: 1.0730, CELoss: 1.0730, 
2022-10-16 07:19:43 - train: epoch 0031, iter [02400, 02526], lr: 0.000100, loss: 0.6708, CELoss: 0.6708, 
2022-10-16 07:20:16 - train: epoch 0031, iter [02500, 02526], lr: 0.000100, loss: 0.8194, CELoss: 0.8194, 
2022-10-16 07:20:26 - train: epoch 031, train_loss: 0.6926
2022-10-16 07:20:28 - until epoch: 031, best_metric: 32.357%
2022-10-16 07:20:28 - epoch 032 lr: 0.000100
2022-10-16 07:21:04 - train: epoch 0032, iter [00100, 02526], lr: 0.000100, loss: 0.5186, CELoss: 0.5186, 
2022-10-16 07:21:38 - train: epoch 0032, iter [00200, 02526], lr: 0.000100, loss: 0.4613, CELoss: 0.4613, 
2022-10-16 07:22:11 - train: epoch 0032, iter [00300, 02526], lr: 0.000100, loss: 0.5808, CELoss: 0.5808, 
2022-10-16 07:22:45 - train: epoch 0032, iter [00400, 02526], lr: 0.000100, loss: 0.4952, CELoss: 0.4952, 
2022-10-16 07:23:18 - train: epoch 0032, iter [00500, 02526], lr: 0.000100, loss: 0.5236, CELoss: 0.5236, 
2022-10-16 07:23:51 - train: epoch 0032, iter [00600, 02526], lr: 0.000100, loss: 0.4841, CELoss: 0.4841, 
2022-10-16 07:24:25 - train: epoch 0032, iter [00700, 02526], lr: 0.000100, loss: 0.7630, CELoss: 0.7630, 
2022-10-16 07:24:58 - train: epoch 0032, iter [00800, 02526], lr: 0.000100, loss: 0.7075, CELoss: 0.7075, 
2022-10-16 07:25:32 - train: epoch 0032, iter [00900, 02526], lr: 0.000100, loss: 0.8864, CELoss: 0.8864, 
2022-10-16 07:26:05 - train: epoch 0032, iter [01000, 02526], lr: 0.000100, loss: 0.3984, CELoss: 0.3984, 
2022-10-16 07:26:39 - train: epoch 0032, iter [01100, 02526], lr: 0.000100, loss: 0.7243, CELoss: 0.7243, 
2022-10-16 07:27:12 - train: epoch 0032, iter [01200, 02526], lr: 0.000100, loss: 0.2716, CELoss: 0.2716, 
2022-10-16 07:27:46 - train: epoch 0032, iter [01300, 02526], lr: 0.000100, loss: 0.4188, CELoss: 0.4188, 
2022-10-16 07:28:20 - train: epoch 0032, iter [01400, 02526], lr: 0.000100, loss: 0.7996, CELoss: 0.7996, 
2022-10-16 07:28:53 - train: epoch 0032, iter [01500, 02526], lr: 0.000100, loss: 0.6937, CELoss: 0.6937, 
2022-10-16 07:29:27 - train: epoch 0032, iter [01600, 02526], lr: 0.000100, loss: 0.7007, CELoss: 0.7007, 
2022-10-16 07:30:01 - train: epoch 0032, iter [01700, 02526], lr: 0.000100, loss: 0.8903, CELoss: 0.8903, 
2022-10-16 07:30:34 - train: epoch 0032, iter [01800, 02526], lr: 0.000100, loss: 0.7286, CELoss: 0.7286, 
2022-10-16 07:31:07 - train: epoch 0032, iter [01900, 02526], lr: 0.000100, loss: 1.0105, CELoss: 1.0105, 
2022-10-16 07:31:41 - train: epoch 0032, iter [02000, 02526], lr: 0.000100, loss: 0.8983, CELoss: 0.8983, 
2022-10-16 07:32:14 - train: epoch 0032, iter [02100, 02526], lr: 0.000100, loss: 0.5589, CELoss: 0.5589, 
2022-10-16 07:32:48 - train: epoch 0032, iter [02200, 02526], lr: 0.000100, loss: 0.6488, CELoss: 0.6488, 
2022-10-16 07:33:21 - train: epoch 0032, iter [02300, 02526], lr: 0.000100, loss: 1.1828, CELoss: 1.1828, 
2022-10-16 07:33:54 - train: epoch 0032, iter [02400, 02526], lr: 0.000100, loss: 0.4709, CELoss: 0.4709, 
2022-10-16 07:34:28 - train: epoch 0032, iter [02500, 02526], lr: 0.000100, loss: 0.5409, CELoss: 0.5409, 
2022-10-16 07:34:38 - train: epoch 032, train_loss: 0.6880
2022-10-16 07:34:39 - until epoch: 032, best_metric: 32.357%
2022-10-16 07:34:39 - epoch 033 lr: 0.000100
2022-10-16 07:35:15 - train: epoch 0033, iter [00100, 02526], lr: 0.000100, loss: 0.7727, CELoss: 0.7727, 
2022-10-16 07:35:48 - train: epoch 0033, iter [00200, 02526], lr: 0.000100, loss: 0.5317, CELoss: 0.5317, 
2022-10-16 07:36:22 - train: epoch 0033, iter [00300, 02526], lr: 0.000100, loss: 1.0095, CELoss: 1.0095, 
2022-10-16 07:36:55 - train: epoch 0033, iter [00400, 02526], lr: 0.000100, loss: 0.5135, CELoss: 0.5135, 
2022-10-16 07:37:29 - train: epoch 0033, iter [00500, 02526], lr: 0.000100, loss: 0.7536, CELoss: 0.7536, 
2022-10-16 07:38:03 - train: epoch 0033, iter [00600, 02526], lr: 0.000100, loss: 0.7367, CELoss: 0.7367, 
2022-10-16 07:38:36 - train: epoch 0033, iter [00700, 02526], lr: 0.000100, loss: 1.1474, CELoss: 1.1474, 
2022-10-16 07:39:09 - train: epoch 0033, iter [00800, 02526], lr: 0.000100, loss: 0.5684, CELoss: 0.5684, 
2022-10-16 07:39:43 - train: epoch 0033, iter [00900, 02526], lr: 0.000100, loss: 0.4955, CELoss: 0.4955, 
2022-10-16 07:40:16 - train: epoch 0033, iter [01000, 02526], lr: 0.000100, loss: 0.5040, CELoss: 0.5040, 
2022-10-16 07:40:50 - train: epoch 0033, iter [01100, 02526], lr: 0.000100, loss: 0.4643, CELoss: 0.4643, 
2022-10-16 07:41:24 - train: epoch 0033, iter [01200, 02526], lr: 0.000100, loss: 0.4274, CELoss: 0.4274, 
2022-10-16 07:41:57 - train: epoch 0033, iter [01300, 02526], lr: 0.000100, loss: 0.4867, CELoss: 0.4867, 
2022-10-16 07:42:31 - train: epoch 0033, iter [01400, 02526], lr: 0.000100, loss: 0.5989, CELoss: 0.5989, 
2022-10-16 07:43:04 - train: epoch 0033, iter [01500, 02526], lr: 0.000100, loss: 0.6126, CELoss: 0.6126, 
2022-10-16 07:43:37 - train: epoch 0033, iter [01600, 02526], lr: 0.000100, loss: 0.7968, CELoss: 0.7968, 
2022-10-16 07:44:11 - train: epoch 0033, iter [01700, 02526], lr: 0.000100, loss: 0.7648, CELoss: 0.7648, 
2022-10-16 07:44:44 - train: epoch 0033, iter [01800, 02526], lr: 0.000100, loss: 0.9359, CELoss: 0.9359, 
2022-10-16 07:45:18 - train: epoch 0033, iter [01900, 02526], lr: 0.000100, loss: 0.5064, CELoss: 0.5064, 
2022-10-16 07:45:52 - train: epoch 0033, iter [02000, 02526], lr: 0.000100, loss: 0.6672, CELoss: 0.6672, 
2022-10-16 07:46:25 - train: epoch 0033, iter [02100, 02526], lr: 0.000100, loss: 0.6622, CELoss: 0.6622, 
2022-10-16 07:46:58 - train: epoch 0033, iter [02200, 02526], lr: 0.000100, loss: 0.7831, CELoss: 0.7831, 
2022-10-16 07:47:32 - train: epoch 0033, iter [02300, 02526], lr: 0.000100, loss: 0.7497, CELoss: 0.7497, 
2022-10-16 07:48:06 - train: epoch 0033, iter [02400, 02526], lr: 0.000100, loss: 0.4959, CELoss: 0.4959, 
2022-10-16 07:48:39 - train: epoch 0033, iter [02500, 02526], lr: 0.000100, loss: 0.6179, CELoss: 0.6179, 
2022-10-16 07:48:49 - train: epoch 033, train_loss: 0.6701
2022-10-16 07:48:51 - until epoch: 033, best_metric: 32.357%
2022-10-16 07:48:51 - epoch 034 lr: 0.000100
2022-10-16 07:49:27 - train: epoch 0034, iter [00100, 02526], lr: 0.000100, loss: 0.8364, CELoss: 0.8364, 
2022-10-16 07:50:00 - train: epoch 0034, iter [00200, 02526], lr: 0.000100, loss: 0.3613, CELoss: 0.3613, 
2022-10-16 07:50:34 - train: epoch 0034, iter [00300, 02526], lr: 0.000100, loss: 1.1134, CELoss: 1.1134, 
2022-10-16 07:51:07 - train: epoch 0034, iter [00400, 02526], lr: 0.000100, loss: 0.6839, CELoss: 0.6839, 
2022-10-16 07:51:41 - train: epoch 0034, iter [00500, 02526], lr: 0.000100, loss: 0.9079, CELoss: 0.9079, 
2022-10-16 07:52:14 - train: epoch 0034, iter [00600, 02526], lr: 0.000100, loss: 0.5993, CELoss: 0.5993, 
2022-10-16 07:52:48 - train: epoch 0034, iter [00700, 02526], lr: 0.000100, loss: 0.4768, CELoss: 0.4768, 
2022-10-16 07:53:22 - train: epoch 0034, iter [00800, 02526], lr: 0.000100, loss: 0.4033, CELoss: 0.4033, 
2022-10-16 07:53:55 - train: epoch 0034, iter [00900, 02526], lr: 0.000100, loss: 0.5291, CELoss: 0.5291, 
2022-10-16 07:54:28 - train: epoch 0034, iter [01000, 02526], lr: 0.000100, loss: 0.3718, CELoss: 0.3718, 
2022-10-16 07:55:02 - train: epoch 0034, iter [01100, 02526], lr: 0.000100, loss: 0.7831, CELoss: 0.7831, 
2022-10-16 07:55:36 - train: epoch 0034, iter [01200, 02526], lr: 0.000100, loss: 0.3826, CELoss: 0.3826, 
2022-10-16 07:56:09 - train: epoch 0034, iter [01300, 02526], lr: 0.000100, loss: 0.4050, CELoss: 0.4050, 
2022-10-16 07:56:43 - train: epoch 0034, iter [01400, 02526], lr: 0.000100, loss: 0.8610, CELoss: 0.8610, 
2022-10-16 07:57:17 - train: epoch 0034, iter [01500, 02526], lr: 0.000100, loss: 0.4530, CELoss: 0.4530, 
2022-10-16 07:57:50 - train: epoch 0034, iter [01600, 02526], lr: 0.000100, loss: 0.8033, CELoss: 0.8033, 
2022-10-16 07:58:24 - train: epoch 0034, iter [01700, 02526], lr: 0.000100, loss: 0.8076, CELoss: 0.8076, 
2022-10-16 07:58:58 - train: epoch 0034, iter [01800, 02526], lr: 0.000100, loss: 0.7826, CELoss: 0.7826, 
2022-10-16 07:59:31 - train: epoch 0034, iter [01900, 02526], lr: 0.000100, loss: 0.6113, CELoss: 0.6113, 
2022-10-16 08:00:05 - train: epoch 0034, iter [02000, 02526], lr: 0.000100, loss: 0.7710, CELoss: 0.7710, 
2022-10-16 08:00:38 - train: epoch 0034, iter [02100, 02526], lr: 0.000100, loss: 0.7320, CELoss: 0.7320, 
2022-10-16 08:01:11 - train: epoch 0034, iter [02200, 02526], lr: 0.000100, loss: 0.7478, CELoss: 0.7478, 
2022-10-16 08:01:45 - train: epoch 0034, iter [02300, 02526], lr: 0.000100, loss: 0.5921, CELoss: 0.5921, 
2022-10-16 08:02:18 - train: epoch 0034, iter [02400, 02526], lr: 0.000100, loss: 0.9908, CELoss: 0.9908, 
2022-10-16 08:02:51 - train: epoch 0034, iter [02500, 02526], lr: 0.000100, loss: 0.5367, CELoss: 0.5367, 
2022-10-16 08:03:01 - train: epoch 034, train_loss: 0.6676
2022-10-16 08:03:03 - until epoch: 034, best_metric: 32.357%
2022-10-16 08:03:03 - epoch 035 lr: 0.000100
2022-10-16 08:03:39 - train: epoch 0035, iter [00100, 02526], lr: 0.000100, loss: 0.7003, CELoss: 0.7003, 
2022-10-16 08:04:12 - train: epoch 0035, iter [00200, 02526], lr: 0.000100, loss: 1.1943, CELoss: 1.1943, 
2022-10-16 08:04:45 - train: epoch 0035, iter [00300, 02526], lr: 0.000100, loss: 0.8001, CELoss: 0.8001, 
2022-10-16 08:05:19 - train: epoch 0035, iter [00400, 02526], lr: 0.000100, loss: 0.7762, CELoss: 0.7762, 
2022-10-16 08:05:52 - train: epoch 0035, iter [00500, 02526], lr: 0.000100, loss: 0.5693, CELoss: 0.5693, 
2022-10-16 08:06:26 - train: epoch 0035, iter [00600, 02526], lr: 0.000100, loss: 0.8155, CELoss: 0.8155, 
2022-10-16 08:06:59 - train: epoch 0035, iter [00700, 02526], lr: 0.000100, loss: 0.4734, CELoss: 0.4734, 
2022-10-16 08:07:33 - train: epoch 0035, iter [00800, 02526], lr: 0.000100, loss: 0.6368, CELoss: 0.6368, 
2022-10-16 08:08:06 - train: epoch 0035, iter [00900, 02526], lr: 0.000100, loss: 1.0759, CELoss: 1.0759, 
2022-10-16 08:08:40 - train: epoch 0035, iter [01000, 02526], lr: 0.000100, loss: 1.0883, CELoss: 1.0883, 
2022-10-16 08:09:13 - train: epoch 0035, iter [01100, 02526], lr: 0.000100, loss: 0.2856, CELoss: 0.2856, 
2022-10-16 08:09:47 - train: epoch 0035, iter [01200, 02526], lr: 0.000100, loss: 0.7072, CELoss: 0.7072, 
2022-10-16 08:10:20 - train: epoch 0035, iter [01300, 02526], lr: 0.000100, loss: 0.3687, CELoss: 0.3687, 
2022-10-16 08:10:54 - train: epoch 0035, iter [01400, 02526], lr: 0.000100, loss: 0.3227, CELoss: 0.3227, 
2022-10-16 08:11:27 - train: epoch 0035, iter [01500, 02526], lr: 0.000100, loss: 0.3539, CELoss: 0.3539, 
2022-10-16 08:12:00 - train: epoch 0035, iter [01600, 02526], lr: 0.000100, loss: 0.9816, CELoss: 0.9816, 
2022-10-16 08:12:34 - train: epoch 0035, iter [01700, 02526], lr: 0.000100, loss: 0.4481, CELoss: 0.4481, 
2022-10-16 08:13:07 - train: epoch 0035, iter [01800, 02526], lr: 0.000100, loss: 1.2537, CELoss: 1.2537, 
2022-10-16 08:13:40 - train: epoch 0035, iter [01900, 02526], lr: 0.000100, loss: 0.5509, CELoss: 0.5509, 
2022-10-16 08:14:14 - train: epoch 0035, iter [02000, 02526], lr: 0.000100, loss: 0.4812, CELoss: 0.4812, 
2022-10-16 08:14:47 - train: epoch 0035, iter [02100, 02526], lr: 0.000100, loss: 0.5646, CELoss: 0.5646, 
2022-10-16 08:15:21 - train: epoch 0035, iter [02200, 02526], lr: 0.000100, loss: 0.8353, CELoss: 0.8353, 
2022-10-16 08:15:55 - train: epoch 0035, iter [02300, 02526], lr: 0.000100, loss: 0.5670, CELoss: 0.5670, 
2022-10-16 08:16:28 - train: epoch 0035, iter [02400, 02526], lr: 0.000100, loss: 0.3811, CELoss: 0.3811, 
2022-10-16 08:17:02 - train: epoch 0035, iter [02500, 02526], lr: 0.000100, loss: 0.4730, CELoss: 0.4730, 
2022-10-16 08:17:12 - train: epoch 035, train_loss: 0.6636
2022-10-16 08:18:02 - eval: epoch: 035
test_loss: 0.8978505247235298
per_image_load_time: 1.072ms
per_image_inference_time: 18.288ms
exist_num_class: 150.0
mean_precision: 54.45273517790517
mean_recall: 45.309922576531264
mean_iou: 33.91106744490775
mean_dice: 46.76061230837893

2022-10-16 08:18:05 - until epoch: 035, best_metric: 33.911%
2022-10-16 08:18:05 - epoch 036 lr: 0.000100
2022-10-16 08:18:40 - train: epoch 0036, iter [00100, 02526], lr: 0.000100, loss: 0.6713, CELoss: 0.6713, 
2022-10-16 08:19:14 - train: epoch 0036, iter [00200, 02526], lr: 0.000100, loss: 0.8009, CELoss: 0.8009, 
2022-10-16 08:19:47 - train: epoch 0036, iter [00300, 02526], lr: 0.000100, loss: 0.8427, CELoss: 0.8427, 
2022-10-16 08:20:21 - train: epoch 0036, iter [00400, 02526], lr: 0.000100, loss: 0.6032, CELoss: 0.6032, 
2022-10-16 08:20:54 - train: epoch 0036, iter [00500, 02526], lr: 0.000100, loss: 0.8709, CELoss: 0.8709, 
2022-10-16 08:21:28 - train: epoch 0036, iter [00600, 02526], lr: 0.000100, loss: 0.6078, CELoss: 0.6078, 
2022-10-16 08:22:01 - train: epoch 0036, iter [00700, 02526], lr: 0.000100, loss: 0.5127, CELoss: 0.5127, 
2022-10-16 08:22:35 - train: epoch 0036, iter [00800, 02526], lr: 0.000100, loss: 0.6415, CELoss: 0.6415, 
2022-10-16 08:23:08 - train: epoch 0036, iter [00900, 02526], lr: 0.000100, loss: 0.8872, CELoss: 0.8872, 
2022-10-16 08:23:42 - train: epoch 0036, iter [01000, 02526], lr: 0.000100, loss: 0.6540, CELoss: 0.6540, 
2022-10-16 08:24:15 - train: epoch 0036, iter [01100, 02526], lr: 0.000100, loss: 0.9147, CELoss: 0.9147, 
2022-10-16 08:24:49 - train: epoch 0036, iter [01200, 02526], lr: 0.000100, loss: 0.5833, CELoss: 0.5833, 
2022-10-16 08:25:23 - train: epoch 0036, iter [01300, 02526], lr: 0.000100, loss: 0.7557, CELoss: 0.7557, 
2022-10-16 08:25:56 - train: epoch 0036, iter [01400, 02526], lr: 0.000100, loss: 0.6005, CELoss: 0.6005, 
2022-10-16 08:26:30 - train: epoch 0036, iter [01500, 02526], lr: 0.000100, loss: 0.8996, CELoss: 0.8996, 
2022-10-16 08:27:04 - train: epoch 0036, iter [01600, 02526], lr: 0.000100, loss: 0.6016, CELoss: 0.6016, 
2022-10-16 08:27:37 - train: epoch 0036, iter [01700, 02526], lr: 0.000100, loss: 0.6065, CELoss: 0.6065, 
2022-10-16 08:28:10 - train: epoch 0036, iter [01800, 02526], lr: 0.000100, loss: 0.5647, CELoss: 0.5647, 
2022-10-16 08:28:44 - train: epoch 0036, iter [01900, 02526], lr: 0.000100, loss: 0.4372, CELoss: 0.4372, 
2022-10-16 08:29:17 - train: epoch 0036, iter [02000, 02526], lr: 0.000100, loss: 0.5806, CELoss: 0.5806, 
2022-10-16 08:29:50 - train: epoch 0036, iter [02100, 02526], lr: 0.000100, loss: 0.4260, CELoss: 0.4260, 
2022-10-16 08:30:24 - train: epoch 0036, iter [02200, 02526], lr: 0.000100, loss: 0.6773, CELoss: 0.6773, 
2022-10-16 08:30:57 - train: epoch 0036, iter [02300, 02526], lr: 0.000100, loss: 0.5380, CELoss: 0.5380, 
2022-10-16 08:31:31 - train: epoch 0036, iter [02400, 02526], lr: 0.000100, loss: 0.8945, CELoss: 0.8945, 
2022-10-16 08:32:04 - train: epoch 0036, iter [02500, 02526], lr: 0.000100, loss: 0.5816, CELoss: 0.5816, 
2022-10-16 08:32:14 - train: epoch 036, train_loss: 0.6571
2022-10-16 08:32:16 - until epoch: 036, best_metric: 33.911%
2022-10-16 08:32:16 - epoch 037 lr: 0.000100
2022-10-16 08:32:52 - train: epoch 0037, iter [00100, 02526], lr: 0.000100, loss: 0.4924, CELoss: 0.4924, 
2022-10-16 08:33:25 - train: epoch 0037, iter [00200, 02526], lr: 0.000100, loss: 0.5416, CELoss: 0.5416, 
2022-10-16 08:33:59 - train: epoch 0037, iter [00300, 02526], lr: 0.000100, loss: 0.8590, CELoss: 0.8590, 
2022-10-16 08:34:32 - train: epoch 0037, iter [00400, 02526], lr: 0.000100, loss: 0.3501, CELoss: 0.3501, 
2022-10-16 08:35:06 - train: epoch 0037, iter [00500, 02526], lr: 0.000100, loss: 0.8405, CELoss: 0.8405, 
2022-10-16 08:35:39 - train: epoch 0037, iter [00600, 02526], lr: 0.000100, loss: 1.2478, CELoss: 1.2478, 
2022-10-16 08:36:13 - train: epoch 0037, iter [00700, 02526], lr: 0.000100, loss: 0.5686, CELoss: 0.5686, 
2022-10-16 08:36:46 - train: epoch 0037, iter [00800, 02526], lr: 0.000100, loss: 0.5428, CELoss: 0.5428, 
2022-10-16 08:37:20 - train: epoch 0037, iter [00900, 02526], lr: 0.000100, loss: 0.4320, CELoss: 0.4320, 
2022-10-16 08:37:53 - train: epoch 0037, iter [01000, 02526], lr: 0.000100, loss: 0.6714, CELoss: 0.6714, 
2022-10-16 08:38:27 - train: epoch 0037, iter [01100, 02526], lr: 0.000100, loss: 0.5728, CELoss: 0.5728, 
2022-10-16 08:39:01 - train: epoch 0037, iter [01200, 02526], lr: 0.000100, loss: 0.6514, CELoss: 0.6514, 
2022-10-16 08:39:34 - train: epoch 0037, iter [01300, 02526], lr: 0.000100, loss: 0.7120, CELoss: 0.7120, 
2022-10-16 08:40:08 - train: epoch 0037, iter [01400, 02526], lr: 0.000100, loss: 0.6984, CELoss: 0.6984, 
2022-10-16 08:40:41 - train: epoch 0037, iter [01500, 02526], lr: 0.000100, loss: 0.4554, CELoss: 0.4554, 
2022-10-16 08:41:15 - train: epoch 0037, iter [01600, 02526], lr: 0.000100, loss: 0.5187, CELoss: 0.5187, 
2022-10-16 08:41:48 - train: epoch 0037, iter [01700, 02526], lr: 0.000100, loss: 0.8602, CELoss: 0.8602, 
2022-10-16 08:42:21 - train: epoch 0037, iter [01800, 02526], lr: 0.000100, loss: 0.4989, CELoss: 0.4989, 
2022-10-16 08:42:55 - train: epoch 0037, iter [01900, 02526], lr: 0.000100, loss: 0.8637, CELoss: 0.8637, 
2022-10-16 08:43:28 - train: epoch 0037, iter [02000, 02526], lr: 0.000100, loss: 0.6557, CELoss: 0.6557, 
2022-10-16 08:44:02 - train: epoch 0037, iter [02100, 02526], lr: 0.000100, loss: 0.6711, CELoss: 0.6711, 
2022-10-16 08:44:35 - train: epoch 0037, iter [02200, 02526], lr: 0.000100, loss: 0.6602, CELoss: 0.6602, 
2022-10-16 08:45:08 - train: epoch 0037, iter [02300, 02526], lr: 0.000100, loss: 0.7445, CELoss: 0.7445, 
2022-10-16 08:45:42 - train: epoch 0037, iter [02400, 02526], lr: 0.000100, loss: 0.6736, CELoss: 0.6736, 
2022-10-16 08:46:15 - train: epoch 0037, iter [02500, 02526], lr: 0.000100, loss: 0.6538, CELoss: 0.6538, 
2022-10-16 08:46:25 - train: epoch 037, train_loss: 0.6397
2022-10-16 08:46:27 - until epoch: 037, best_metric: 33.911%
2022-10-16 08:46:27 - epoch 038 lr: 0.000100
2022-10-16 08:47:03 - train: epoch 0038, iter [00100, 02526], lr: 0.000100, loss: 0.5192, CELoss: 0.5192, 
2022-10-16 08:47:36 - train: epoch 0038, iter [00200, 02526], lr: 0.000100, loss: 0.4212, CELoss: 0.4212, 
2022-10-16 08:48:10 - train: epoch 0038, iter [00300, 02526], lr: 0.000100, loss: 0.5811, CELoss: 0.5811, 
2022-10-16 08:48:44 - train: epoch 0038, iter [00400, 02526], lr: 0.000100, loss: 0.3357, CELoss: 0.3357, 
2022-10-16 08:49:17 - train: epoch 0038, iter [00500, 02526], lr: 0.000100, loss: 0.5879, CELoss: 0.5879, 
2022-10-16 08:49:51 - train: epoch 0038, iter [00600, 02526], lr: 0.000100, loss: 0.6114, CELoss: 0.6114, 
2022-10-16 08:50:24 - train: epoch 0038, iter [00700, 02526], lr: 0.000100, loss: 0.5866, CELoss: 0.5866, 
2022-10-16 08:50:57 - train: epoch 0038, iter [00800, 02526], lr: 0.000100, loss: 0.4182, CELoss: 0.4182, 
2022-10-16 08:51:31 - train: epoch 0038, iter [00900, 02526], lr: 0.000100, loss: 0.6849, CELoss: 0.6849, 
2022-10-16 08:52:04 - train: epoch 0038, iter [01000, 02526], lr: 0.000100, loss: 0.8676, CELoss: 0.8676, 
2022-10-16 08:52:38 - train: epoch 0038, iter [01100, 02526], lr: 0.000100, loss: 0.6742, CELoss: 0.6742, 
2022-10-16 08:53:11 - train: epoch 0038, iter [01200, 02526], lr: 0.000100, loss: 0.8424, CELoss: 0.8424, 
2022-10-16 08:53:44 - train: epoch 0038, iter [01300, 02526], lr: 0.000100, loss: 0.5049, CELoss: 0.5049, 
2022-10-16 08:54:18 - train: epoch 0038, iter [01400, 02526], lr: 0.000100, loss: 0.9101, CELoss: 0.9101, 
2022-10-16 08:54:51 - train: epoch 0038, iter [01500, 02526], lr: 0.000100, loss: 0.6582, CELoss: 0.6582, 
2022-10-16 08:55:25 - train: epoch 0038, iter [01600, 02526], lr: 0.000100, loss: 0.5247, CELoss: 0.5247, 
2022-10-16 08:55:58 - train: epoch 0038, iter [01700, 02526], lr: 0.000100, loss: 0.6086, CELoss: 0.6086, 
2022-10-16 08:56:32 - train: epoch 0038, iter [01800, 02526], lr: 0.000100, loss: 0.5161, CELoss: 0.5161, 
2022-10-16 08:57:05 - train: epoch 0038, iter [01900, 02526], lr: 0.000100, loss: 0.8914, CELoss: 0.8914, 
2022-10-16 08:57:39 - train: epoch 0038, iter [02000, 02526], lr: 0.000100, loss: 0.4325, CELoss: 0.4325, 
2022-10-16 08:58:12 - train: epoch 0038, iter [02100, 02526], lr: 0.000100, loss: 0.7322, CELoss: 0.7322, 
2022-10-16 08:58:46 - train: epoch 0038, iter [02200, 02526], lr: 0.000100, loss: 0.4788, CELoss: 0.4788, 
2022-10-16 08:59:20 - train: epoch 0038, iter [02300, 02526], lr: 0.000100, loss: 0.4079, CELoss: 0.4079, 
2022-10-16 08:59:53 - train: epoch 0038, iter [02400, 02526], lr: 0.000100, loss: 0.5928, CELoss: 0.5928, 
2022-10-16 09:00:26 - train: epoch 0038, iter [02500, 02526], lr: 0.000100, loss: 0.6904, CELoss: 0.6904, 
2022-10-16 09:00:36 - train: epoch 038, train_loss: 0.6351
2022-10-16 09:00:38 - until epoch: 038, best_metric: 33.911%
2022-10-16 09:00:38 - epoch 039 lr: 0.000100
2022-10-16 09:01:14 - train: epoch 0039, iter [00100, 02526], lr: 0.000100, loss: 0.7353, CELoss: 0.7353, 
2022-10-16 09:01:48 - train: epoch 0039, iter [00200, 02526], lr: 0.000100, loss: 0.3079, CELoss: 0.3079, 
2022-10-16 09:02:21 - train: epoch 0039, iter [00300, 02526], lr: 0.000100, loss: 0.8491, CELoss: 0.8491, 
2022-10-16 09:02:54 - train: epoch 0039, iter [00400, 02526], lr: 0.000100, loss: 0.6627, CELoss: 0.6627, 
2022-10-16 09:03:28 - train: epoch 0039, iter [00500, 02526], lr: 0.000100, loss: 0.6935, CELoss: 0.6935, 
2022-10-16 09:04:01 - train: epoch 0039, iter [00600, 02526], lr: 0.000100, loss: 0.6806, CELoss: 0.6806, 
2022-10-16 09:04:34 - train: epoch 0039, iter [00700, 02526], lr: 0.000100, loss: 0.7199, CELoss: 0.7199, 
2022-10-16 09:05:08 - train: epoch 0039, iter [00800, 02526], lr: 0.000100, loss: 0.5502, CELoss: 0.5502, 
2022-10-16 09:05:41 - train: epoch 0039, iter [00900, 02526], lr: 0.000100, loss: 0.7639, CELoss: 0.7639, 
2022-10-16 09:06:15 - train: epoch 0039, iter [01000, 02526], lr: 0.000100, loss: 0.6611, CELoss: 0.6611, 
2022-10-16 09:06:48 - train: epoch 0039, iter [01100, 02526], lr: 0.000100, loss: 0.4897, CELoss: 0.4897, 
2022-10-16 09:07:22 - train: epoch 0039, iter [01200, 02526], lr: 0.000100, loss: 0.4974, CELoss: 0.4974, 
2022-10-16 09:07:55 - train: epoch 0039, iter [01300, 02526], lr: 0.000100, loss: 1.3076, CELoss: 1.3076, 
2022-10-16 09:08:28 - train: epoch 0039, iter [01400, 02526], lr: 0.000100, loss: 0.5105, CELoss: 0.5105, 
2022-10-16 09:09:02 - train: epoch 0039, iter [01500, 02526], lr: 0.000100, loss: 0.6200, CELoss: 0.6200, 
2022-10-16 09:09:36 - train: epoch 0039, iter [01600, 02526], lr: 0.000100, loss: 0.4793, CELoss: 0.4793, 
2022-10-16 09:10:09 - train: epoch 0039, iter [01700, 02526], lr: 0.000100, loss: 0.6281, CELoss: 0.6281, 
2022-10-16 09:10:43 - train: epoch 0039, iter [01800, 02526], lr: 0.000100, loss: 0.5359, CELoss: 0.5359, 
2022-10-16 09:11:16 - train: epoch 0039, iter [01900, 02526], lr: 0.000100, loss: 0.6255, CELoss: 0.6255, 
2022-10-16 09:11:50 - train: epoch 0039, iter [02000, 02526], lr: 0.000100, loss: 0.9543, CELoss: 0.9543, 
2022-10-16 09:12:24 - train: epoch 0039, iter [02100, 02526], lr: 0.000100, loss: 1.2323, CELoss: 1.2323, 
2022-10-16 09:12:57 - train: epoch 0039, iter [02200, 02526], lr: 0.000100, loss: 0.7035, CELoss: 0.7035, 
2022-10-16 09:13:31 - train: epoch 0039, iter [02300, 02526], lr: 0.000100, loss: 0.9544, CELoss: 0.9544, 
2022-10-16 09:14:04 - train: epoch 0039, iter [02400, 02526], lr: 0.000100, loss: 0.4148, CELoss: 0.4148, 
2022-10-16 09:14:37 - train: epoch 0039, iter [02500, 02526], lr: 0.000100, loss: 0.9254, CELoss: 0.9254, 
2022-10-16 09:14:47 - train: epoch 039, train_loss: 0.6342
2022-10-16 09:14:50 - until epoch: 039, best_metric: 33.911%
2022-10-16 09:14:50 - epoch 040 lr: 0.000100
2022-10-16 09:15:25 - train: epoch 0040, iter [00100, 02526], lr: 0.000100, loss: 0.4541, CELoss: 0.4541, 
2022-10-16 09:15:59 - train: epoch 0040, iter [00200, 02526], lr: 0.000100, loss: 0.5185, CELoss: 0.5185, 
2022-10-16 09:16:32 - train: epoch 0040, iter [00300, 02526], lr: 0.000100, loss: 0.8032, CELoss: 0.8032, 
2022-10-16 09:17:06 - train: epoch 0040, iter [00400, 02526], lr: 0.000100, loss: 0.5924, CELoss: 0.5924, 
2022-10-16 09:17:39 - train: epoch 0040, iter [00500, 02526], lr: 0.000100, loss: 0.7265, CELoss: 0.7265, 
2022-10-16 09:18:13 - train: epoch 0040, iter [00600, 02526], lr: 0.000100, loss: 0.5447, CELoss: 0.5447, 
2022-10-16 09:18:46 - train: epoch 0040, iter [00700, 02526], lr: 0.000100, loss: 1.4570, CELoss: 1.4570, 
2022-10-16 09:19:20 - train: epoch 0040, iter [00800, 02526], lr: 0.000100, loss: 0.5311, CELoss: 0.5311, 
2022-10-16 09:19:53 - train: epoch 0040, iter [00900, 02526], lr: 0.000100, loss: 0.6515, CELoss: 0.6515, 
2022-10-16 09:20:27 - train: epoch 0040, iter [01000, 02526], lr: 0.000100, loss: 1.1110, CELoss: 1.1110, 
2022-10-16 09:21:00 - train: epoch 0040, iter [01100, 02526], lr: 0.000100, loss: 0.4159, CELoss: 0.4159, 
2022-10-16 09:21:33 - train: epoch 0040, iter [01200, 02526], lr: 0.000100, loss: 0.8211, CELoss: 0.8211, 
2022-10-16 09:22:07 - train: epoch 0040, iter [01300, 02526], lr: 0.000100, loss: 0.3458, CELoss: 0.3458, 
2022-10-16 09:22:41 - train: epoch 0040, iter [01400, 02526], lr: 0.000100, loss: 1.0652, CELoss: 1.0652, 
2022-10-16 09:23:14 - train: epoch 0040, iter [01500, 02526], lr: 0.000100, loss: 0.4529, CELoss: 0.4529, 
2022-10-16 09:23:48 - train: epoch 0040, iter [01600, 02526], lr: 0.000100, loss: 0.6785, CELoss: 0.6785, 
2022-10-16 09:24:21 - train: epoch 0040, iter [01700, 02526], lr: 0.000100, loss: 0.7682, CELoss: 0.7682, 
2022-10-16 09:24:54 - train: epoch 0040, iter [01800, 02526], lr: 0.000100, loss: 0.8759, CELoss: 0.8759, 
2022-10-16 09:25:28 - train: epoch 0040, iter [01900, 02526], lr: 0.000100, loss: 0.4933, CELoss: 0.4933, 
2022-10-16 09:26:01 - train: epoch 0040, iter [02000, 02526], lr: 0.000100, loss: 0.5383, CELoss: 0.5383, 
2022-10-16 09:26:35 - train: epoch 0040, iter [02100, 02526], lr: 0.000100, loss: 0.5435, CELoss: 0.5435, 
2022-10-16 09:27:09 - train: epoch 0040, iter [02200, 02526], lr: 0.000100, loss: 0.3713, CELoss: 0.3713, 
2022-10-16 09:27:42 - train: epoch 0040, iter [02300, 02526], lr: 0.000100, loss: 0.8392, CELoss: 0.8392, 
2022-10-16 09:28:16 - train: epoch 0040, iter [02400, 02526], lr: 0.000100, loss: 0.4539, CELoss: 0.4539, 
2022-10-16 09:28:49 - train: epoch 0040, iter [02500, 02526], lr: 0.000100, loss: 0.5236, CELoss: 0.5236, 
2022-10-16 09:28:59 - train: epoch 040, train_loss: 0.6185
2022-10-16 09:29:50 - eval: epoch: 040
test_loss: 0.9125317482054234
per_image_load_time: 1.069ms
per_image_inference_time: 18.282ms
exist_num_class: 150.0
mean_precision: 54.31842712024326
mean_recall: 45.262185743513655
mean_iou: 33.97094607654578
mean_dice: 46.867130497176305

2022-10-16 09:29:53 - until epoch: 040, best_metric: 33.971%
2022-10-16 09:29:53 - epoch 041 lr: 0.000100
2022-10-16 09:30:29 - train: epoch 0041, iter [00100, 02526], lr: 0.000100, loss: 0.9699, CELoss: 0.9699, 
2022-10-16 09:31:02 - train: epoch 0041, iter [00200, 02526], lr: 0.000100, loss: 0.6112, CELoss: 0.6112, 
2022-10-16 09:31:36 - train: epoch 0041, iter [00300, 02526], lr: 0.000100, loss: 0.6233, CELoss: 0.6233, 
2022-10-16 09:32:09 - train: epoch 0041, iter [00400, 02526], lr: 0.000100, loss: 0.4589, CELoss: 0.4589, 
2022-10-16 09:32:43 - train: epoch 0041, iter [00500, 02526], lr: 0.000100, loss: 0.8500, CELoss: 0.8500, 
2022-10-16 09:33:16 - train: epoch 0041, iter [00600, 02526], lr: 0.000100, loss: 0.3575, CELoss: 0.3575, 
2022-10-16 09:33:50 - train: epoch 0041, iter [00700, 02526], lr: 0.000100, loss: 0.4632, CELoss: 0.4632, 
2022-10-16 09:34:23 - train: epoch 0041, iter [00800, 02526], lr: 0.000100, loss: 0.4982, CELoss: 0.4982, 
2022-10-16 09:34:56 - train: epoch 0041, iter [00900, 02526], lr: 0.000100, loss: 0.4884, CELoss: 0.4884, 
2022-10-16 09:35:30 - train: epoch 0041, iter [01000, 02526], lr: 0.000100, loss: 0.5458, CELoss: 0.5458, 
2022-10-16 09:36:04 - train: epoch 0041, iter [01100, 02526], lr: 0.000100, loss: 0.7328, CELoss: 0.7328, 
2022-10-16 09:36:37 - train: epoch 0041, iter [01200, 02526], lr: 0.000100, loss: 0.7666, CELoss: 0.7666, 
2022-10-16 09:37:11 - train: epoch 0041, iter [01300, 02526], lr: 0.000100, loss: 0.5349, CELoss: 0.5349, 
2022-10-16 09:37:44 - train: epoch 0041, iter [01400, 02526], lr: 0.000100, loss: 0.5187, CELoss: 0.5187, 
2022-10-16 09:38:17 - train: epoch 0041, iter [01500, 02526], lr: 0.000100, loss: 0.6601, CELoss: 0.6601, 
2022-10-16 09:38:51 - train: epoch 0041, iter [01600, 02526], lr: 0.000100, loss: 0.4344, CELoss: 0.4344, 
2022-10-16 09:39:25 - train: epoch 0041, iter [01700, 02526], lr: 0.000100, loss: 0.5005, CELoss: 0.5005, 
2022-10-16 09:39:58 - train: epoch 0041, iter [01800, 02526], lr: 0.000100, loss: 0.4678, CELoss: 0.4678, 
2022-10-16 09:40:31 - train: epoch 0041, iter [01900, 02526], lr: 0.000100, loss: 0.5835, CELoss: 0.5835, 
2022-10-16 09:41:05 - train: epoch 0041, iter [02000, 02526], lr: 0.000100, loss: 0.6450, CELoss: 0.6450, 
2022-10-16 09:41:38 - train: epoch 0041, iter [02100, 02526], lr: 0.000100, loss: 0.4983, CELoss: 0.4983, 
2022-10-16 09:42:12 - train: epoch 0041, iter [02200, 02526], lr: 0.000100, loss: 0.4650, CELoss: 0.4650, 
2022-10-16 09:42:45 - train: epoch 0041, iter [02300, 02526], lr: 0.000100, loss: 0.7740, CELoss: 0.7740, 
2022-10-16 09:43:19 - train: epoch 0041, iter [02400, 02526], lr: 0.000100, loss: 0.4039, CELoss: 0.4039, 
2022-10-16 09:43:52 - train: epoch 0041, iter [02500, 02526], lr: 0.000100, loss: 0.4933, CELoss: 0.4933, 
2022-10-16 09:44:02 - train: epoch 041, train_loss: 0.6136
2022-10-16 09:44:05 - until epoch: 041, best_metric: 33.971%
2022-10-16 09:44:05 - epoch 042 lr: 0.000100
2022-10-16 09:44:40 - train: epoch 0042, iter [00100, 02526], lr: 0.000100, loss: 0.7210, CELoss: 0.7210, 
2022-10-16 09:45:14 - train: epoch 0042, iter [00200, 02526], lr: 0.000100, loss: 0.4785, CELoss: 0.4785, 
2022-10-16 09:45:48 - train: epoch 0042, iter [00300, 02526], lr: 0.000100, loss: 0.5712, CELoss: 0.5712, 
2022-10-16 09:46:21 - train: epoch 0042, iter [00400, 02526], lr: 0.000100, loss: 0.7198, CELoss: 0.7198, 
2022-10-16 09:46:55 - train: epoch 0042, iter [00500, 02526], lr: 0.000100, loss: 1.0919, CELoss: 1.0919, 
2022-10-16 09:47:29 - train: epoch 0042, iter [00600, 02526], lr: 0.000100, loss: 0.6584, CELoss: 0.6584, 
2022-10-16 09:48:02 - train: epoch 0042, iter [00700, 02526], lr: 0.000100, loss: 0.3806, CELoss: 0.3806, 
2022-10-16 09:48:35 - train: epoch 0042, iter [00800, 02526], lr: 0.000100, loss: 0.2973, CELoss: 0.2973, 
2022-10-16 09:49:09 - train: epoch 0042, iter [00900, 02526], lr: 0.000100, loss: 0.6204, CELoss: 0.6204, 
2022-10-16 09:49:42 - train: epoch 0042, iter [01000, 02526], lr: 0.000100, loss: 0.6826, CELoss: 0.6826, 
2022-10-16 09:50:16 - train: epoch 0042, iter [01100, 02526], lr: 0.000100, loss: 0.4318, CELoss: 0.4318, 
2022-10-16 09:50:50 - train: epoch 0042, iter [01200, 02526], lr: 0.000100, loss: 0.7985, CELoss: 0.7985, 
2022-10-16 09:51:23 - train: epoch 0042, iter [01300, 02526], lr: 0.000100, loss: 0.4858, CELoss: 0.4858, 
2022-10-16 09:51:57 - train: epoch 0042, iter [01400, 02526], lr: 0.000100, loss: 0.5093, CELoss: 0.5093, 
2022-10-16 09:52:30 - train: epoch 0042, iter [01500, 02526], lr: 0.000100, loss: 1.0335, CELoss: 1.0335, 
2022-10-16 09:53:04 - train: epoch 0042, iter [01600, 02526], lr: 0.000100, loss: 0.8668, CELoss: 0.8668, 
2022-10-16 09:53:37 - train: epoch 0042, iter [01700, 02526], lr: 0.000100, loss: 0.6909, CELoss: 0.6909, 
2022-10-16 09:54:11 - train: epoch 0042, iter [01800, 02526], lr: 0.000100, loss: 0.7906, CELoss: 0.7906, 
2022-10-16 09:54:44 - train: epoch 0042, iter [01900, 02526], lr: 0.000100, loss: 0.7423, CELoss: 0.7423, 
2022-10-16 09:55:18 - train: epoch 0042, iter [02000, 02526], lr: 0.000100, loss: 0.8445, CELoss: 0.8445, 
2022-10-16 09:55:51 - train: epoch 0042, iter [02100, 02526], lr: 0.000100, loss: 0.6092, CELoss: 0.6092, 
2022-10-16 09:56:24 - train: epoch 0042, iter [02200, 02526], lr: 0.000100, loss: 0.7155, CELoss: 0.7155, 
2022-10-16 09:56:58 - train: epoch 0042, iter [02300, 02526], lr: 0.000100, loss: 0.6962, CELoss: 0.6962, 
2022-10-16 09:57:31 - train: epoch 0042, iter [02400, 02526], lr: 0.000100, loss: 0.4529, CELoss: 0.4529, 
2022-10-16 09:58:04 - train: epoch 0042, iter [02500, 02526], lr: 0.000100, loss: 0.4959, CELoss: 0.4959, 
2022-10-16 09:58:14 - train: epoch 042, train_loss: 0.6100
2022-10-16 09:58:16 - until epoch: 042, best_metric: 33.971%
2022-10-16 09:58:16 - epoch 043 lr: 0.000100
2022-10-16 09:58:52 - train: epoch 0043, iter [00100, 02526], lr: 0.000100, loss: 0.4304, CELoss: 0.4304, 
2022-10-16 09:59:25 - train: epoch 0043, iter [00200, 02526], lr: 0.000100, loss: 0.4089, CELoss: 0.4089, 
2022-10-16 09:59:59 - train: epoch 0043, iter [00300, 02526], lr: 0.000100, loss: 0.7291, CELoss: 0.7291, 
2022-10-16 10:00:33 - train: epoch 0043, iter [00400, 02526], lr: 0.000100, loss: 0.3650, CELoss: 0.3650, 
2022-10-16 10:01:06 - train: epoch 0043, iter [00500, 02526], lr: 0.000100, loss: 0.6641, CELoss: 0.6641, 
2022-10-16 10:01:40 - train: epoch 0043, iter [00600, 02526], lr: 0.000100, loss: 0.6007, CELoss: 0.6007, 
2022-10-16 10:02:13 - train: epoch 0043, iter [00700, 02526], lr: 0.000100, loss: 0.4439, CELoss: 0.4439, 
2022-10-16 10:02:47 - train: epoch 0043, iter [00800, 02526], lr: 0.000100, loss: 0.5801, CELoss: 0.5801, 
2022-10-16 10:03:20 - train: epoch 0043, iter [00900, 02526], lr: 0.000100, loss: 0.5380, CELoss: 0.5380, 
2022-10-16 10:03:54 - train: epoch 0043, iter [01000, 02526], lr: 0.000100, loss: 0.5233, CELoss: 0.5233, 
2022-10-16 10:04:27 - train: epoch 0043, iter [01100, 02526], lr: 0.000100, loss: 0.6670, CELoss: 0.6670, 
2022-10-16 10:05:01 - train: epoch 0043, iter [01200, 02526], lr: 0.000100, loss: 0.7715, CELoss: 0.7715, 
2022-10-16 10:05:34 - train: epoch 0043, iter [01300, 02526], lr: 0.000100, loss: 0.4819, CELoss: 0.4819, 
2022-10-16 10:06:08 - train: epoch 0043, iter [01400, 02526], lr: 0.000100, loss: 0.8817, CELoss: 0.8817, 
2022-10-16 10:06:42 - train: epoch 0043, iter [01500, 02526], lr: 0.000100, loss: 0.8213, CELoss: 0.8213, 
2022-10-16 10:07:15 - train: epoch 0043, iter [01600, 02526], lr: 0.000100, loss: 0.2993, CELoss: 0.2993, 
2022-10-16 10:07:49 - train: epoch 0043, iter [01700, 02526], lr: 0.000100, loss: 0.3838, CELoss: 0.3838, 
2022-10-16 10:08:23 - train: epoch 0043, iter [01800, 02526], lr: 0.000100, loss: 0.4096, CELoss: 0.4096, 
2022-10-16 10:08:56 - train: epoch 0043, iter [01900, 02526], lr: 0.000100, loss: 0.4220, CELoss: 0.4220, 
2022-10-16 10:09:29 - train: epoch 0043, iter [02000, 02526], lr: 0.000100, loss: 0.4561, CELoss: 0.4561, 
2022-10-16 10:10:03 - train: epoch 0043, iter [02100, 02526], lr: 0.000100, loss: 0.4971, CELoss: 0.4971, 
2022-10-16 10:10:36 - train: epoch 0043, iter [02200, 02526], lr: 0.000100, loss: 0.6007, CELoss: 0.6007, 
2022-10-16 10:11:10 - train: epoch 0043, iter [02300, 02526], lr: 0.000100, loss: 0.7296, CELoss: 0.7296, 
2022-10-16 10:11:43 - train: epoch 0043, iter [02400, 02526], lr: 0.000100, loss: 0.7959, CELoss: 0.7959, 
2022-10-16 10:12:17 - train: epoch 0043, iter [02500, 02526], lr: 0.000100, loss: 0.3728, CELoss: 0.3728, 
2022-10-16 10:12:27 - train: epoch 043, train_loss: 0.6089
2022-10-16 10:12:29 - until epoch: 043, best_metric: 33.971%
2022-10-16 10:12:29 - epoch 044 lr: 0.000100
2022-10-16 10:13:05 - train: epoch 0044, iter [00100, 02526], lr: 0.000100, loss: 0.4597, CELoss: 0.4597, 
2022-10-16 10:13:39 - train: epoch 0044, iter [00200, 02526], lr: 0.000100, loss: 0.4016, CELoss: 0.4016, 
2022-10-16 10:14:12 - train: epoch 0044, iter [00300, 02526], lr: 0.000100, loss: 0.5807, CELoss: 0.5807, 
2022-10-16 10:14:45 - train: epoch 0044, iter [00400, 02526], lr: 0.000100, loss: 0.4729, CELoss: 0.4729, 
2022-10-16 10:15:19 - train: epoch 0044, iter [00500, 02526], lr: 0.000100, loss: 0.7687, CELoss: 0.7687, 
2022-10-16 10:15:53 - train: epoch 0044, iter [00600, 02526], lr: 0.000100, loss: 0.8263, CELoss: 0.8263, 
2022-10-16 10:16:26 - train: epoch 0044, iter [00700, 02526], lr: 0.000100, loss: 0.7268, CELoss: 0.7268, 
2022-10-16 10:17:00 - train: epoch 0044, iter [00800, 02526], lr: 0.000100, loss: 0.6067, CELoss: 0.6067, 
2022-10-16 10:17:33 - train: epoch 0044, iter [00900, 02526], lr: 0.000100, loss: 0.4616, CELoss: 0.4616, 
2022-10-16 10:18:07 - train: epoch 0044, iter [01000, 02526], lr: 0.000100, loss: 0.5529, CELoss: 0.5529, 
2022-10-16 10:18:40 - train: epoch 0044, iter [01100, 02526], lr: 0.000100, loss: 0.6053, CELoss: 0.6053, 
2022-10-16 10:19:14 - train: epoch 0044, iter [01200, 02526], lr: 0.000100, loss: 0.8573, CELoss: 0.8573, 
2022-10-16 10:19:47 - train: epoch 0044, iter [01300, 02526], lr: 0.000100, loss: 0.4368, CELoss: 0.4368, 
2022-10-16 10:20:21 - train: epoch 0044, iter [01400, 02526], lr: 0.000100, loss: 0.6821, CELoss: 0.6821, 
2022-10-16 10:20:54 - train: epoch 0044, iter [01500, 02526], lr: 0.000100, loss: 0.4420, CELoss: 0.4420, 
2022-10-16 10:21:28 - train: epoch 0044, iter [01600, 02526], lr: 0.000100, loss: 0.8014, CELoss: 0.8014, 
2022-10-16 10:22:02 - train: epoch 0044, iter [01700, 02526], lr: 0.000100, loss: 0.4895, CELoss: 0.4895, 
2022-10-16 10:22:35 - train: epoch 0044, iter [01800, 02526], lr: 0.000100, loss: 0.6064, CELoss: 0.6064, 
2022-10-16 10:23:08 - train: epoch 0044, iter [01900, 02526], lr: 0.000100, loss: 0.7048, CELoss: 0.7048, 
2022-10-16 10:23:41 - train: epoch 0044, iter [02000, 02526], lr: 0.000100, loss: 0.6594, CELoss: 0.6594, 
2022-10-16 10:24:15 - train: epoch 0044, iter [02100, 02526], lr: 0.000100, loss: 0.9456, CELoss: 0.9456, 
2022-10-16 10:24:49 - train: epoch 0044, iter [02200, 02526], lr: 0.000100, loss: 0.7142, CELoss: 0.7142, 
2022-10-16 10:25:23 - train: epoch 0044, iter [02300, 02526], lr: 0.000100, loss: 0.6286, CELoss: 0.6286, 
2022-10-16 10:25:56 - train: epoch 0044, iter [02400, 02526], lr: 0.000100, loss: 0.3721, CELoss: 0.3721, 
2022-10-16 10:26:30 - train: epoch 0044, iter [02500, 02526], lr: 0.000100, loss: 1.1067, CELoss: 1.1067, 
2022-10-16 10:26:40 - train: epoch 044, train_loss: 0.5966
2022-10-16 10:26:42 - until epoch: 044, best_metric: 33.971%
2022-10-16 10:26:42 - epoch 045 lr: 0.000100
2022-10-16 10:27:18 - train: epoch 0045, iter [00100, 02526], lr: 0.000100, loss: 0.4377, CELoss: 0.4377, 
2022-10-16 10:27:51 - train: epoch 0045, iter [00200, 02526], lr: 0.000100, loss: 0.4529, CELoss: 0.4529, 
2022-10-16 10:28:25 - train: epoch 0045, iter [00300, 02526], lr: 0.000100, loss: 0.8358, CELoss: 0.8358, 
2022-10-16 10:28:58 - train: epoch 0045, iter [00400, 02526], lr: 0.000100, loss: 0.3670, CELoss: 0.3670, 
2022-10-16 10:29:32 - train: epoch 0045, iter [00500, 02526], lr: 0.000100, loss: 0.6121, CELoss: 0.6121, 
2022-10-16 10:30:06 - train: epoch 0045, iter [00600, 02526], lr: 0.000100, loss: 0.5292, CELoss: 0.5292, 
2022-10-16 10:30:40 - train: epoch 0045, iter [00700, 02526], lr: 0.000100, loss: 0.4946, CELoss: 0.4946, 
2022-10-16 10:31:13 - train: epoch 0045, iter [00800, 02526], lr: 0.000100, loss: 0.7217, CELoss: 0.7217, 
2022-10-16 10:31:47 - train: epoch 0045, iter [00900, 02526], lr: 0.000100, loss: 0.7984, CELoss: 0.7984, 
2022-10-16 10:32:20 - train: epoch 0045, iter [01000, 02526], lr: 0.000100, loss: 0.5871, CELoss: 0.5871, 
2022-10-16 10:32:53 - train: epoch 0045, iter [01100, 02526], lr: 0.000100, loss: 0.8756, CELoss: 0.8756, 
2022-10-16 10:33:27 - train: epoch 0045, iter [01200, 02526], lr: 0.000100, loss: 0.8964, CELoss: 0.8964, 
2022-10-16 10:34:01 - train: epoch 0045, iter [01300, 02526], lr: 0.000100, loss: 0.5461, CELoss: 0.5461, 
2022-10-16 10:34:34 - train: epoch 0045, iter [01400, 02526], lr: 0.000100, loss: 0.3650, CELoss: 0.3650, 
2022-10-16 10:35:08 - train: epoch 0045, iter [01500, 02526], lr: 0.000100, loss: 0.5922, CELoss: 0.5922, 
2022-10-16 10:35:41 - train: epoch 0045, iter [01600, 02526], lr: 0.000100, loss: 0.5158, CELoss: 0.5158, 
2022-10-16 10:36:15 - train: epoch 0045, iter [01700, 02526], lr: 0.000100, loss: 0.3499, CELoss: 0.3499, 
2022-10-16 10:36:49 - train: epoch 0045, iter [01800, 02526], lr: 0.000100, loss: 1.0126, CELoss: 1.0126, 
2022-10-16 10:37:22 - train: epoch 0045, iter [01900, 02526], lr: 0.000100, loss: 0.5831, CELoss: 0.5831, 
2022-10-16 10:37:56 - train: epoch 0045, iter [02000, 02526], lr: 0.000100, loss: 0.5862, CELoss: 0.5862, 
2022-10-16 10:38:29 - train: epoch 0045, iter [02100, 02526], lr: 0.000100, loss: 0.8331, CELoss: 0.8331, 
2022-10-16 10:39:02 - train: epoch 0045, iter [02200, 02526], lr: 0.000100, loss: 0.6658, CELoss: 0.6658, 
2022-10-16 10:39:36 - train: epoch 0045, iter [02300, 02526], lr: 0.000100, loss: 0.4708, CELoss: 0.4708, 
2022-10-16 10:40:10 - train: epoch 0045, iter [02400, 02526], lr: 0.000100, loss: 0.3875, CELoss: 0.3875, 
2022-10-16 10:40:43 - train: epoch 0045, iter [02500, 02526], lr: 0.000100, loss: 1.1105, CELoss: 1.1105, 
2022-10-16 10:40:53 - train: epoch 045, train_loss: 0.5885
2022-10-16 10:41:44 - eval: epoch: 045
test_loss: 0.8850507092177868
per_image_load_time: 1.050ms
per_image_inference_time: 18.249ms
exist_num_class: 150.0
mean_precision: 58.951444538785765
mean_recall: 44.14664277988235
mean_iou: 34.43750018597098
mean_dice: 47.69217878067976

2022-10-16 10:41:47 - until epoch: 045, best_metric: 34.438%
2022-10-16 10:41:47 - epoch 046 lr: 0.000100
2022-10-16 10:42:23 - train: epoch 0046, iter [00100, 02526], lr: 0.000100, loss: 0.5019, CELoss: 0.5019, 
2022-10-16 10:42:56 - train: epoch 0046, iter [00200, 02526], lr: 0.000100, loss: 0.5804, CELoss: 0.5804, 
2022-10-16 10:43:30 - train: epoch 0046, iter [00300, 02526], lr: 0.000100, loss: 0.3901, CELoss: 0.3901, 
2022-10-16 10:44:03 - train: epoch 0046, iter [00400, 02526], lr: 0.000100, loss: 0.6766, CELoss: 0.6766, 
2022-10-16 10:44:37 - train: epoch 0046, iter [00500, 02526], lr: 0.000100, loss: 0.3609, CELoss: 0.3609, 
2022-10-16 10:45:10 - train: epoch 0046, iter [00600, 02526], lr: 0.000100, loss: 0.5264, CELoss: 0.5264, 
2022-10-16 10:45:44 - train: epoch 0046, iter [00700, 02526], lr: 0.000100, loss: 0.5787, CELoss: 0.5787, 
2022-10-16 10:46:17 - train: epoch 0046, iter [00800, 02526], lr: 0.000100, loss: 0.4821, CELoss: 0.4821, 
2022-10-16 10:46:51 - train: epoch 0046, iter [00900, 02526], lr: 0.000100, loss: 0.4093, CELoss: 0.4093, 
2022-10-16 10:47:24 - train: epoch 0046, iter [01000, 02526], lr: 0.000100, loss: 0.4603, CELoss: 0.4603, 
2022-10-16 10:47:58 - train: epoch 0046, iter [01100, 02526], lr: 0.000100, loss: 0.8928, CELoss: 0.8928, 
2022-10-16 10:48:32 - train: epoch 0046, iter [01200, 02526], lr: 0.000100, loss: 0.5976, CELoss: 0.5976, 
2022-10-16 10:49:05 - train: epoch 0046, iter [01300, 02526], lr: 0.000100, loss: 0.3132, CELoss: 0.3132, 
2022-10-16 10:49:39 - train: epoch 0046, iter [01400, 02526], lr: 0.000100, loss: 0.5408, CELoss: 0.5408, 
2022-10-16 10:50:12 - train: epoch 0046, iter [01500, 02526], lr: 0.000100, loss: 0.4888, CELoss: 0.4888, 
2022-10-16 10:50:45 - train: epoch 0046, iter [01600, 02526], lr: 0.000100, loss: 0.5791, CELoss: 0.5791, 
2022-10-16 10:51:19 - train: epoch 0046, iter [01700, 02526], lr: 0.000100, loss: 0.3833, CELoss: 0.3833, 
2022-10-16 10:51:52 - train: epoch 0046, iter [01800, 02526], lr: 0.000100, loss: 0.6332, CELoss: 0.6332, 
2022-10-16 10:52:25 - train: epoch 0046, iter [01900, 02526], lr: 0.000100, loss: 0.4995, CELoss: 0.4995, 
2022-10-16 10:52:59 - train: epoch 0046, iter [02000, 02526], lr: 0.000100, loss: 0.6118, CELoss: 0.6118, 
2022-10-16 10:53:32 - train: epoch 0046, iter [02100, 02526], lr: 0.000100, loss: 0.5352, CELoss: 0.5352, 
2022-10-16 10:54:06 - train: epoch 0046, iter [02200, 02526], lr: 0.000100, loss: 0.7019, CELoss: 0.7019, 
2022-10-16 10:54:39 - train: epoch 0046, iter [02300, 02526], lr: 0.000100, loss: 0.4303, CELoss: 0.4303, 
2022-10-16 10:55:13 - train: epoch 0046, iter [02400, 02526], lr: 0.000100, loss: 0.6267, CELoss: 0.6267, 
2022-10-16 10:55:46 - train: epoch 0046, iter [02500, 02526], lr: 0.000100, loss: 0.4646, CELoss: 0.4646, 
2022-10-16 10:55:56 - train: epoch 046, train_loss: 0.5838
2022-10-16 10:55:58 - until epoch: 046, best_metric: 34.438%
2022-10-16 10:55:58 - epoch 047 lr: 0.000100
2022-10-16 10:56:34 - train: epoch 0047, iter [00100, 02526], lr: 0.000100, loss: 0.8662, CELoss: 0.8662, 
2022-10-16 10:57:07 - train: epoch 0047, iter [00200, 02526], lr: 0.000100, loss: 0.5026, CELoss: 0.5026, 
2022-10-16 10:57:41 - train: epoch 0047, iter [00300, 02526], lr: 0.000100, loss: 0.6261, CELoss: 0.6261, 
2022-10-16 10:58:14 - train: epoch 0047, iter [00400, 02526], lr: 0.000100, loss: 0.5625, CELoss: 0.5625, 
2022-10-16 10:58:48 - train: epoch 0047, iter [00500, 02526], lr: 0.000100, loss: 0.4150, CELoss: 0.4150, 
2022-10-16 10:59:21 - train: epoch 0047, iter [00600, 02526], lr: 0.000100, loss: 0.6514, CELoss: 0.6514, 
2022-10-16 10:59:54 - train: epoch 0047, iter [00700, 02526], lr: 0.000100, loss: 0.4192, CELoss: 0.4192, 
2022-10-16 11:00:28 - train: epoch 0047, iter [00800, 02526], lr: 0.000100, loss: 0.6117, CELoss: 0.6117, 
2022-10-16 11:01:02 - train: epoch 0047, iter [00900, 02526], lr: 0.000100, loss: 0.3249, CELoss: 0.3249, 
2022-10-16 11:01:35 - train: epoch 0047, iter [01000, 02526], lr: 0.000100, loss: 0.4403, CELoss: 0.4403, 
2022-10-16 11:02:09 - train: epoch 0047, iter [01100, 02526], lr: 0.000100, loss: 0.3008, CELoss: 0.3008, 
2022-10-16 11:02:42 - train: epoch 0047, iter [01200, 02526], lr: 0.000100, loss: 0.3896, CELoss: 0.3896, 
2022-10-16 11:03:15 - train: epoch 0047, iter [01300, 02526], lr: 0.000100, loss: 0.8653, CELoss: 0.8653, 
2022-10-16 11:03:49 - train: epoch 0047, iter [01400, 02526], lr: 0.000100, loss: 0.8020, CELoss: 0.8020, 
2022-10-16 11:04:22 - train: epoch 0047, iter [01500, 02526], lr: 0.000100, loss: 0.4958, CELoss: 0.4958, 
2022-10-16 11:04:56 - train: epoch 0047, iter [01600, 02526], lr: 0.000100, loss: 0.7810, CELoss: 0.7810, 
2022-10-16 11:05:30 - train: epoch 0047, iter [01700, 02526], lr: 0.000100, loss: 0.9907, CELoss: 0.9907, 
2022-10-16 11:06:03 - train: epoch 0047, iter [01800, 02526], lr: 0.000100, loss: 0.7644, CELoss: 0.7644, 
2022-10-16 11:06:37 - train: epoch 0047, iter [01900, 02526], lr: 0.000100, loss: 0.3752, CELoss: 0.3752, 
2022-10-16 11:07:10 - train: epoch 0047, iter [02000, 02526], lr: 0.000100, loss: 0.3905, CELoss: 0.3905, 
2022-10-16 11:07:44 - train: epoch 0047, iter [02100, 02526], lr: 0.000100, loss: 0.4273, CELoss: 0.4273, 
2022-10-16 11:08:17 - train: epoch 0047, iter [02200, 02526], lr: 0.000100, loss: 0.6570, CELoss: 0.6570, 
2022-10-16 11:08:51 - train: epoch 0047, iter [02300, 02526], lr: 0.000100, loss: 0.5282, CELoss: 0.5282, 
2022-10-16 11:09:24 - train: epoch 0047, iter [02400, 02526], lr: 0.000100, loss: 0.8325, CELoss: 0.8325, 
2022-10-16 11:09:58 - train: epoch 0047, iter [02500, 02526], lr: 0.000100, loss: 0.7468, CELoss: 0.7468, 
2022-10-16 11:10:08 - train: epoch 047, train_loss: 0.5797
2022-10-16 11:10:10 - until epoch: 047, best_metric: 34.438%
2022-10-16 11:10:10 - epoch 048 lr: 0.000100
2022-10-16 11:10:46 - train: epoch 0048, iter [00100, 02526], lr: 0.000100, loss: 0.2873, CELoss: 0.2873, 
2022-10-16 11:11:19 - train: epoch 0048, iter [00200, 02526], lr: 0.000100, loss: 0.4654, CELoss: 0.4654, 
2022-10-16 11:11:53 - train: epoch 0048, iter [00300, 02526], lr: 0.000100, loss: 0.8204, CELoss: 0.8204, 
2022-10-16 11:12:26 - train: epoch 0048, iter [00400, 02526], lr: 0.000100, loss: 0.5267, CELoss: 0.5267, 
2022-10-16 11:13:00 - train: epoch 0048, iter [00500, 02526], lr: 0.000100, loss: 0.4661, CELoss: 0.4661, 
2022-10-16 11:13:34 - train: epoch 0048, iter [00600, 02526], lr: 0.000100, loss: 0.9391, CELoss: 0.9391, 
2022-10-16 11:14:07 - train: epoch 0048, iter [00700, 02526], lr: 0.000100, loss: 0.7187, CELoss: 0.7187, 
2022-10-16 11:14:41 - train: epoch 0048, iter [00800, 02526], lr: 0.000100, loss: 0.6760, CELoss: 0.6760, 
2022-10-16 11:15:15 - train: epoch 0048, iter [00900, 02526], lr: 0.000100, loss: 0.6202, CELoss: 0.6202, 
2022-10-16 11:15:49 - train: epoch 0048, iter [01000, 02526], lr: 0.000100, loss: 0.4681, CELoss: 0.4681, 
2022-10-16 11:16:24 - train: epoch 0048, iter [01100, 02526], lr: 0.000100, loss: 0.4780, CELoss: 0.4780, 
2022-10-16 11:16:57 - train: epoch 0048, iter [01200, 02526], lr: 0.000100, loss: 0.4908, CELoss: 0.4908, 
2022-10-16 11:17:31 - train: epoch 0048, iter [01300, 02526], lr: 0.000100, loss: 0.4246, CELoss: 0.4246, 
2022-10-16 11:18:04 - train: epoch 0048, iter [01400, 02526], lr: 0.000100, loss: 0.9057, CELoss: 0.9057, 
2022-10-16 11:18:38 - train: epoch 0048, iter [01500, 02526], lr: 0.000100, loss: 0.5047, CELoss: 0.5047, 
2022-10-16 11:19:11 - train: epoch 0048, iter [01600, 02526], lr: 0.000100, loss: 0.6160, CELoss: 0.6160, 
2022-10-16 11:19:45 - train: epoch 0048, iter [01700, 02526], lr: 0.000100, loss: 0.3679, CELoss: 0.3679, 
2022-10-16 11:20:18 - train: epoch 0048, iter [01800, 02526], lr: 0.000100, loss: 0.6745, CELoss: 0.6745, 
2022-10-16 11:20:52 - train: epoch 0048, iter [01900, 02526], lr: 0.000100, loss: 0.7044, CELoss: 0.7044, 
2022-10-16 11:21:25 - train: epoch 0048, iter [02000, 02526], lr: 0.000100, loss: 0.7737, CELoss: 0.7737, 
2022-10-16 11:21:59 - train: epoch 0048, iter [02100, 02526], lr: 0.000100, loss: 0.5552, CELoss: 0.5552, 
2022-10-16 11:22:32 - train: epoch 0048, iter [02200, 02526], lr: 0.000100, loss: 0.3382, CELoss: 0.3382, 
2022-10-16 11:23:05 - train: epoch 0048, iter [02300, 02526], lr: 0.000100, loss: 0.4110, CELoss: 0.4110, 
2022-10-16 11:23:39 - train: epoch 0048, iter [02400, 02526], lr: 0.000100, loss: 0.7337, CELoss: 0.7337, 
2022-10-16 11:24:13 - train: epoch 0048, iter [02500, 02526], lr: 0.000100, loss: 0.6436, CELoss: 0.6436, 
2022-10-16 11:24:23 - train: epoch 048, train_loss: 0.5722
2022-10-16 11:24:25 - until epoch: 048, best_metric: 34.438%
2022-10-16 11:24:25 - epoch 049 lr: 0.000100
2022-10-16 11:25:01 - train: epoch 0049, iter [00100, 02526], lr: 0.000100, loss: 0.6774, CELoss: 0.6774, 
2022-10-16 11:25:34 - train: epoch 0049, iter [00200, 02526], lr: 0.000100, loss: 0.4071, CELoss: 0.4071, 
2022-10-16 11:26:08 - train: epoch 0049, iter [00300, 02526], lr: 0.000100, loss: 1.0380, CELoss: 1.0380, 
2022-10-16 11:26:41 - train: epoch 0049, iter [00400, 02526], lr: 0.000100, loss: 0.7189, CELoss: 0.7189, 
2022-10-16 11:27:15 - train: epoch 0049, iter [00500, 02526], lr: 0.000100, loss: 0.4620, CELoss: 0.4620, 
2022-10-16 11:27:49 - train: epoch 0049, iter [00600, 02526], lr: 0.000100, loss: 0.5834, CELoss: 0.5834, 
2022-10-16 11:28:22 - train: epoch 0049, iter [00700, 02526], lr: 0.000100, loss: 0.5216, CELoss: 0.5216, 
2022-10-16 11:28:56 - train: epoch 0049, iter [00800, 02526], lr: 0.000100, loss: 0.4442, CELoss: 0.4442, 
2022-10-16 11:29:29 - train: epoch 0049, iter [00900, 02526], lr: 0.000100, loss: 0.5348, CELoss: 0.5348, 
2022-10-16 11:30:03 - train: epoch 0049, iter [01000, 02526], lr: 0.000100, loss: 0.3368, CELoss: 0.3368, 
2022-10-16 11:30:36 - train: epoch 0049, iter [01100, 02526], lr: 0.000100, loss: 0.4902, CELoss: 0.4902, 
2022-10-16 11:31:09 - train: epoch 0049, iter [01200, 02526], lr: 0.000100, loss: 0.4500, CELoss: 0.4500, 
2022-10-16 11:31:43 - train: epoch 0049, iter [01300, 02526], lr: 0.000100, loss: 0.5872, CELoss: 0.5872, 
2022-10-16 11:32:17 - train: epoch 0049, iter [01400, 02526], lr: 0.000100, loss: 0.5033, CELoss: 0.5033, 
2022-10-16 11:32:50 - train: epoch 0049, iter [01500, 02526], lr: 0.000100, loss: 0.4713, CELoss: 0.4713, 
2022-10-16 11:33:23 - train: epoch 0049, iter [01600, 02526], lr: 0.000100, loss: 0.5759, CELoss: 0.5759, 
2022-10-16 11:33:57 - train: epoch 0049, iter [01700, 02526], lr: 0.000100, loss: 1.0539, CELoss: 1.0539, 
2022-10-16 11:34:30 - train: epoch 0049, iter [01800, 02526], lr: 0.000100, loss: 0.3390, CELoss: 0.3390, 
2022-10-16 11:35:04 - train: epoch 0049, iter [01900, 02526], lr: 0.000100, loss: 0.2954, CELoss: 0.2954, 
2022-10-16 11:35:38 - train: epoch 0049, iter [02000, 02526], lr: 0.000100, loss: 0.3665, CELoss: 0.3665, 
2022-10-16 11:36:11 - train: epoch 0049, iter [02100, 02526], lr: 0.000100, loss: 0.6585, CELoss: 0.6585, 
2022-10-16 11:36:45 - train: epoch 0049, iter [02200, 02526], lr: 0.000100, loss: 0.4949, CELoss: 0.4949, 
2022-10-16 11:37:18 - train: epoch 0049, iter [02300, 02526], lr: 0.000100, loss: 0.4060, CELoss: 0.4060, 
2022-10-16 11:37:51 - train: epoch 0049, iter [02400, 02526], lr: 0.000100, loss: 0.5750, CELoss: 0.5750, 
2022-10-16 11:38:25 - train: epoch 0049, iter [02500, 02526], lr: 0.000100, loss: 0.7780, CELoss: 0.7780, 
2022-10-16 11:38:35 - train: epoch 049, train_loss: 0.5687
2022-10-16 11:38:37 - until epoch: 049, best_metric: 34.438%
2022-10-16 11:38:37 - epoch 050 lr: 0.000100
2022-10-16 11:39:12 - train: epoch 0050, iter [00100, 02526], lr: 0.000100, loss: 0.6355, CELoss: 0.6355, 
2022-10-16 11:39:46 - train: epoch 0050, iter [00200, 02526], lr: 0.000100, loss: 0.3795, CELoss: 0.3795, 
2022-10-16 11:40:20 - train: epoch 0050, iter [00300, 02526], lr: 0.000100, loss: 0.3941, CELoss: 0.3941, 
2022-10-16 11:40:54 - train: epoch 0050, iter [00400, 02526], lr: 0.000100, loss: 0.7703, CELoss: 0.7703, 
2022-10-16 11:41:27 - train: epoch 0050, iter [00500, 02526], lr: 0.000100, loss: 0.8103, CELoss: 0.8103, 
2022-10-16 11:42:01 - train: epoch 0050, iter [00600, 02526], lr: 0.000100, loss: 0.6726, CELoss: 0.6726, 
2022-10-16 11:42:34 - train: epoch 0050, iter [00700, 02526], lr: 0.000100, loss: 0.5688, CELoss: 0.5688, 
2022-10-16 11:43:08 - train: epoch 0050, iter [00800, 02526], lr: 0.000100, loss: 0.5456, CELoss: 0.5456, 
2022-10-16 11:43:41 - train: epoch 0050, iter [00900, 02526], lr: 0.000100, loss: 0.3936, CELoss: 0.3936, 
2022-10-16 11:44:14 - train: epoch 0050, iter [01000, 02526], lr: 0.000100, loss: 0.7834, CELoss: 0.7834, 
2022-10-16 11:44:48 - train: epoch 0050, iter [01100, 02526], lr: 0.000100, loss: 0.9152, CELoss: 0.9152, 
2022-10-16 11:45:21 - train: epoch 0050, iter [01200, 02526], lr: 0.000100, loss: 0.4774, CELoss: 0.4774, 
2022-10-16 11:45:55 - train: epoch 0050, iter [01300, 02526], lr: 0.000100, loss: 0.3363, CELoss: 0.3363, 
2022-10-16 11:46:28 - train: epoch 0050, iter [01400, 02526], lr: 0.000100, loss: 0.4799, CELoss: 0.4799, 
2022-10-16 11:47:02 - train: epoch 0050, iter [01500, 02526], lr: 0.000100, loss: 0.4846, CELoss: 0.4846, 
2022-10-16 11:47:36 - train: epoch 0050, iter [01600, 02526], lr: 0.000100, loss: 0.5836, CELoss: 0.5836, 
2022-10-16 11:48:09 - train: epoch 0050, iter [01700, 02526], lr: 0.000100, loss: 0.2927, CELoss: 0.2927, 
2022-10-16 11:48:43 - train: epoch 0050, iter [01800, 02526], lr: 0.000100, loss: 0.4996, CELoss: 0.4996, 
2022-10-16 11:49:17 - train: epoch 0050, iter [01900, 02526], lr: 0.000100, loss: 0.5447, CELoss: 0.5447, 
2022-10-16 11:49:50 - train: epoch 0050, iter [02000, 02526], lr: 0.000100, loss: 0.5909, CELoss: 0.5909, 
2022-10-16 11:50:24 - train: epoch 0050, iter [02100, 02526], lr: 0.000100, loss: 0.5956, CELoss: 0.5956, 
2022-10-16 11:50:57 - train: epoch 0050, iter [02200, 02526], lr: 0.000100, loss: 0.6027, CELoss: 0.6027, 
2022-10-16 11:51:30 - train: epoch 0050, iter [02300, 02526], lr: 0.000100, loss: 0.4677, CELoss: 0.4677, 
2022-10-16 11:52:04 - train: epoch 0050, iter [02400, 02526], lr: 0.000100, loss: 0.8281, CELoss: 0.8281, 
2022-10-16 11:52:37 - train: epoch 0050, iter [02500, 02526], lr: 0.000100, loss: 0.5384, CELoss: 0.5384, 
2022-10-16 11:52:47 - train: epoch 050, train_loss: 0.5639
2022-10-16 11:53:38 - eval: epoch: 050
test_loss: 0.8637258397340775
per_image_load_time: 1.084ms
per_image_inference_time: 18.290ms
exist_num_class: 150.0
mean_precision: 57.409507373966726
mean_recall: 45.46431644474005
mean_iou: 35.13850121059013
mean_dice: 48.31814319398364

2022-10-16 11:53:41 - until epoch: 050, best_metric: 35.139%
2022-10-16 11:53:41 - epoch 051 lr: 0.000100
2022-10-16 11:54:17 - train: epoch 0051, iter [00100, 02526], lr: 0.000100, loss: 0.4456, CELoss: 0.4456, 
2022-10-16 11:54:50 - train: epoch 0051, iter [00200, 02526], lr: 0.000100, loss: 0.3610, CELoss: 0.3610, 
2022-10-16 11:55:24 - train: epoch 0051, iter [00300, 02526], lr: 0.000100, loss: 0.2610, CELoss: 0.2610, 
2022-10-16 11:55:57 - train: epoch 0051, iter [00400, 02526], lr: 0.000100, loss: 0.5935, CELoss: 0.5935, 
2022-10-16 11:56:31 - train: epoch 0051, iter [00500, 02526], lr: 0.000100, loss: 0.4421, CELoss: 0.4421, 
2022-10-16 11:57:05 - train: epoch 0051, iter [00600, 02526], lr: 0.000100, loss: 0.5818, CELoss: 0.5818, 
2022-10-16 11:57:38 - train: epoch 0051, iter [00700, 02526], lr: 0.000100, loss: 0.4681, CELoss: 0.4681, 
2022-10-16 11:58:11 - train: epoch 0051, iter [00800, 02526], lr: 0.000100, loss: 0.6969, CELoss: 0.6969, 
2022-10-16 11:58:45 - train: epoch 0051, iter [00900, 02526], lr: 0.000100, loss: 0.4671, CELoss: 0.4671, 
2022-10-16 11:59:18 - train: epoch 0051, iter [01000, 02526], lr: 0.000100, loss: 0.6325, CELoss: 0.6325, 
2022-10-16 11:59:52 - train: epoch 0051, iter [01100, 02526], lr: 0.000100, loss: 0.4883, CELoss: 0.4883, 
2022-10-16 12:00:25 - train: epoch 0051, iter [01200, 02526], lr: 0.000100, loss: 0.3832, CELoss: 0.3832, 
2022-10-16 12:00:59 - train: epoch 0051, iter [01300, 02526], lr: 0.000100, loss: 0.5555, CELoss: 0.5555, 
2022-10-16 12:01:32 - train: epoch 0051, iter [01400, 02526], lr: 0.000100, loss: 0.5142, CELoss: 0.5142, 
2022-10-16 12:02:06 - train: epoch 0051, iter [01500, 02526], lr: 0.000100, loss: 0.4024, CELoss: 0.4024, 
2022-10-16 12:02:39 - train: epoch 0051, iter [01600, 02526], lr: 0.000100, loss: 0.4210, CELoss: 0.4210, 
2022-10-16 12:03:13 - train: epoch 0051, iter [01700, 02526], lr: 0.000100, loss: 0.5950, CELoss: 0.5950, 
2022-10-16 12:03:46 - train: epoch 0051, iter [01800, 02526], lr: 0.000100, loss: 0.6330, CELoss: 0.6330, 
2022-10-16 12:04:19 - train: epoch 0051, iter [01900, 02526], lr: 0.000100, loss: 0.5112, CELoss: 0.5112, 
2022-10-16 12:04:53 - train: epoch 0051, iter [02000, 02526], lr: 0.000100, loss: 0.4976, CELoss: 0.4976, 
2022-10-16 12:05:26 - train: epoch 0051, iter [02100, 02526], lr: 0.000100, loss: 0.7561, CELoss: 0.7561, 
2022-10-16 12:06:00 - train: epoch 0051, iter [02200, 02526], lr: 0.000100, loss: 0.5786, CELoss: 0.5786, 
2022-10-16 12:06:33 - train: epoch 0051, iter [02300, 02526], lr: 0.000100, loss: 0.6133, CELoss: 0.6133, 
2022-10-16 12:07:07 - train: epoch 0051, iter [02400, 02526], lr: 0.000100, loss: 0.4977, CELoss: 0.4977, 
2022-10-16 12:07:40 - train: epoch 0051, iter [02500, 02526], lr: 0.000100, loss: 0.6023, CELoss: 0.6023, 
2022-10-16 12:07:50 - train: epoch 051, train_loss: 0.5607
2022-10-16 12:07:53 - until epoch: 051, best_metric: 35.139%
2022-10-16 12:07:53 - epoch 052 lr: 0.000100
2022-10-16 12:08:28 - train: epoch 0052, iter [00100, 02526], lr: 0.000100, loss: 0.5289, CELoss: 0.5289, 
2022-10-16 12:09:02 - train: epoch 0052, iter [00200, 02526], lr: 0.000100, loss: 0.5527, CELoss: 0.5527, 
2022-10-16 12:09:35 - train: epoch 0052, iter [00300, 02526], lr: 0.000100, loss: 0.5115, CELoss: 0.5115, 
2022-10-16 12:10:08 - train: epoch 0052, iter [00400, 02526], lr: 0.000100, loss: 0.4313, CELoss: 0.4313, 
2022-10-16 12:10:42 - train: epoch 0052, iter [00500, 02526], lr: 0.000100, loss: 0.4046, CELoss: 0.4046, 
2022-10-16 12:11:15 - train: epoch 0052, iter [00600, 02526], lr: 0.000100, loss: 0.5831, CELoss: 0.5831, 
2022-10-16 12:11:49 - train: epoch 0052, iter [00700, 02526], lr: 0.000100, loss: 0.4817, CELoss: 0.4817, 
2022-10-16 12:12:22 - train: epoch 0052, iter [00800, 02526], lr: 0.000100, loss: 0.5001, CELoss: 0.5001, 
2022-10-16 12:12:56 - train: epoch 0052, iter [00900, 02526], lr: 0.000100, loss: 0.4866, CELoss: 0.4866, 
2022-10-16 12:13:29 - train: epoch 0052, iter [01000, 02526], lr: 0.000100, loss: 0.5966, CELoss: 0.5966, 
2022-10-16 12:14:03 - train: epoch 0052, iter [01100, 02526], lr: 0.000100, loss: 0.2856, CELoss: 0.2856, 
2022-10-16 12:14:36 - train: epoch 0052, iter [01200, 02526], lr: 0.000100, loss: 0.3692, CELoss: 0.3692, 
2022-10-16 12:15:09 - train: epoch 0052, iter [01300, 02526], lr: 0.000100, loss: 0.8236, CELoss: 0.8236, 
2022-10-16 12:15:43 - train: epoch 0052, iter [01400, 02526], lr: 0.000100, loss: 0.6548, CELoss: 0.6548, 
2022-10-16 12:16:17 - train: epoch 0052, iter [01500, 02526], lr: 0.000100, loss: 0.5659, CELoss: 0.5659, 
2022-10-16 12:16:50 - train: epoch 0052, iter [01600, 02526], lr: 0.000100, loss: 0.4843, CELoss: 0.4843, 
2022-10-16 12:17:23 - train: epoch 0052, iter [01700, 02526], lr: 0.000100, loss: 0.3372, CELoss: 0.3372, 
2022-10-16 12:17:57 - train: epoch 0052, iter [01800, 02526], lr: 0.000100, loss: 0.9409, CELoss: 0.9409, 
2022-10-16 12:18:30 - train: epoch 0052, iter [01900, 02526], lr: 0.000100, loss: 0.3177, CELoss: 0.3177, 
2022-10-16 12:19:04 - train: epoch 0052, iter [02000, 02526], lr: 0.000100, loss: 0.3517, CELoss: 0.3517, 
2022-10-16 12:19:37 - train: epoch 0052, iter [02100, 02526], lr: 0.000100, loss: 0.4567, CELoss: 0.4567, 
2022-10-16 12:20:11 - train: epoch 0052, iter [02200, 02526], lr: 0.000100, loss: 0.3565, CELoss: 0.3565, 
2022-10-16 12:20:44 - train: epoch 0052, iter [02300, 02526], lr: 0.000100, loss: 0.7570, CELoss: 0.7570, 
2022-10-16 12:21:18 - train: epoch 0052, iter [02400, 02526], lr: 0.000100, loss: 0.6105, CELoss: 0.6105, 
2022-10-16 12:21:51 - train: epoch 0052, iter [02500, 02526], lr: 0.000100, loss: 0.4475, CELoss: 0.4475, 
2022-10-16 12:22:01 - train: epoch 052, train_loss: 0.5484
2022-10-16 12:22:03 - until epoch: 052, best_metric: 35.139%
2022-10-16 12:22:03 - epoch 053 lr: 0.000100
2022-10-16 12:22:39 - train: epoch 0053, iter [00100, 02526], lr: 0.000100, loss: 0.9594, CELoss: 0.9594, 
2022-10-16 12:23:13 - train: epoch 0053, iter [00200, 02526], lr: 0.000100, loss: 0.3554, CELoss: 0.3554, 
2022-10-16 12:23:46 - train: epoch 0053, iter [00300, 02526], lr: 0.000100, loss: 0.4097, CELoss: 0.4097, 
2022-10-16 12:24:19 - train: epoch 0053, iter [00400, 02526], lr: 0.000100, loss: 0.3747, CELoss: 0.3747, 
2022-10-16 12:24:53 - train: epoch 0053, iter [00500, 02526], lr: 0.000100, loss: 0.4525, CELoss: 0.4525, 
2022-10-16 12:25:27 - train: epoch 0053, iter [00600, 02526], lr: 0.000100, loss: 0.2199, CELoss: 0.2199, 
2022-10-16 12:26:00 - train: epoch 0053, iter [00700, 02526], lr: 0.000100, loss: 0.7421, CELoss: 0.7421, 
2022-10-16 12:26:33 - train: epoch 0053, iter [00800, 02526], lr: 0.000100, loss: 0.4685, CELoss: 0.4685, 
2022-10-16 12:27:07 - train: epoch 0053, iter [00900, 02526], lr: 0.000100, loss: 0.4394, CELoss: 0.4394, 
2022-10-16 12:27:40 - train: epoch 0053, iter [01000, 02526], lr: 0.000100, loss: 0.3966, CELoss: 0.3966, 
2022-10-16 12:28:14 - train: epoch 0053, iter [01100, 02526], lr: 0.000100, loss: 0.3413, CELoss: 0.3413, 
2022-10-16 12:28:47 - train: epoch 0053, iter [01200, 02526], lr: 0.000100, loss: 0.7314, CELoss: 0.7314, 
2022-10-16 12:29:21 - train: epoch 0053, iter [01300, 02526], lr: 0.000100, loss: 0.8261, CELoss: 0.8261, 
2022-10-16 12:29:55 - train: epoch 0053, iter [01400, 02526], lr: 0.000100, loss: 0.7391, CELoss: 0.7391, 
2022-10-16 12:30:29 - train: epoch 0053, iter [01500, 02526], lr: 0.000100, loss: 0.3959, CELoss: 0.3959, 
2022-10-16 12:31:02 - train: epoch 0053, iter [01600, 02526], lr: 0.000100, loss: 0.6514, CELoss: 0.6514, 
2022-10-16 12:31:36 - train: epoch 0053, iter [01700, 02526], lr: 0.000100, loss: 0.5994, CELoss: 0.5994, 
2022-10-16 12:32:09 - train: epoch 0053, iter [01800, 02526], lr: 0.000100, loss: 0.4073, CELoss: 0.4073, 
2022-10-16 12:32:42 - train: epoch 0053, iter [01900, 02526], lr: 0.000100, loss: 0.6234, CELoss: 0.6234, 
2022-10-16 12:33:16 - train: epoch 0053, iter [02000, 02526], lr: 0.000100, loss: 0.3765, CELoss: 0.3765, 
2022-10-16 12:33:50 - train: epoch 0053, iter [02100, 02526], lr: 0.000100, loss: 0.4724, CELoss: 0.4724, 
2022-10-16 12:34:23 - train: epoch 0053, iter [02200, 02526], lr: 0.000100, loss: 0.3516, CELoss: 0.3516, 
2022-10-16 12:34:56 - train: epoch 0053, iter [02300, 02526], lr: 0.000100, loss: 0.3133, CELoss: 0.3133, 
2022-10-16 12:35:30 - train: epoch 0053, iter [02400, 02526], lr: 0.000100, loss: 0.5426, CELoss: 0.5426, 
2022-10-16 12:36:03 - train: epoch 0053, iter [02500, 02526], lr: 0.000100, loss: 0.5975, CELoss: 0.5975, 
2022-10-16 12:36:13 - train: epoch 053, train_loss: 0.5447
2022-10-16 12:36:16 - until epoch: 053, best_metric: 35.139%
2022-10-16 12:36:16 - epoch 054 lr: 0.000100
2022-10-16 12:36:52 - train: epoch 0054, iter [00100, 02526], lr: 0.000100, loss: 0.5221, CELoss: 0.5221, 
2022-10-16 12:37:25 - train: epoch 0054, iter [00200, 02526], lr: 0.000100, loss: 0.3673, CELoss: 0.3673, 
2022-10-16 12:37:59 - train: epoch 0054, iter [00300, 02526], lr: 0.000100, loss: 0.6250, CELoss: 0.6250, 
2022-10-16 12:38:32 - train: epoch 0054, iter [00400, 02526], lr: 0.000100, loss: 0.5814, CELoss: 0.5814, 
2022-10-16 12:39:06 - train: epoch 0054, iter [00500, 02526], lr: 0.000100, loss: 0.5267, CELoss: 0.5267, 
2022-10-16 12:39:40 - train: epoch 0054, iter [00600, 02526], lr: 0.000100, loss: 1.3980, CELoss: 1.3980, 
2022-10-16 12:40:13 - train: epoch 0054, iter [00700, 02526], lr: 0.000100, loss: 0.6261, CELoss: 0.6261, 
2022-10-16 12:40:47 - train: epoch 0054, iter [00800, 02526], lr: 0.000100, loss: 0.5375, CELoss: 0.5375, 
2022-10-16 12:41:20 - train: epoch 0054, iter [00900, 02526], lr: 0.000100, loss: 0.3225, CELoss: 0.3225, 
2022-10-16 12:41:54 - train: epoch 0054, iter [01000, 02526], lr: 0.000100, loss: 0.4698, CELoss: 0.4698, 
2022-10-16 12:42:27 - train: epoch 0054, iter [01100, 02526], lr: 0.000100, loss: 0.4122, CELoss: 0.4122, 
2022-10-16 12:43:01 - train: epoch 0054, iter [01200, 02526], lr: 0.000100, loss: 0.5414, CELoss: 0.5414, 
2022-10-16 12:43:34 - train: epoch 0054, iter [01300, 02526], lr: 0.000100, loss: 0.5685, CELoss: 0.5685, 
2022-10-16 12:44:08 - train: epoch 0054, iter [01400, 02526], lr: 0.000100, loss: 0.3867, CELoss: 0.3867, 
2022-10-16 12:44:41 - train: epoch 0054, iter [01500, 02526], lr: 0.000100, loss: 0.3991, CELoss: 0.3991, 
2022-10-16 12:45:15 - train: epoch 0054, iter [01600, 02526], lr: 0.000100, loss: 0.4619, CELoss: 0.4619, 
2022-10-16 12:45:48 - train: epoch 0054, iter [01700, 02526], lr: 0.000100, loss: 0.1780, CELoss: 0.1780, 
2022-10-16 12:46:22 - train: epoch 0054, iter [01800, 02526], lr: 0.000100, loss: 0.3011, CELoss: 0.3011, 
2022-10-16 12:46:55 - train: epoch 0054, iter [01900, 02526], lr: 0.000100, loss: 0.7205, CELoss: 0.7205, 
2022-10-16 12:47:29 - train: epoch 0054, iter [02000, 02526], lr: 0.000100, loss: 0.5212, CELoss: 0.5212, 
2022-10-16 12:48:02 - train: epoch 0054, iter [02100, 02526], lr: 0.000100, loss: 0.2677, CELoss: 0.2677, 
2022-10-16 12:48:36 - train: epoch 0054, iter [02200, 02526], lr: 0.000100, loss: 0.4100, CELoss: 0.4100, 
2022-10-16 12:49:09 - train: epoch 0054, iter [02300, 02526], lr: 0.000100, loss: 0.7454, CELoss: 0.7454, 
2022-10-16 12:49:43 - train: epoch 0054, iter [02400, 02526], lr: 0.000100, loss: 0.6585, CELoss: 0.6585, 
2022-10-16 12:50:16 - train: epoch 0054, iter [02500, 02526], lr: 0.000100, loss: 0.6984, CELoss: 0.6984, 
2022-10-16 12:50:26 - train: epoch 054, train_loss: 0.5357
2022-10-16 12:50:27 - until epoch: 054, best_metric: 35.139%
2022-10-16 12:50:27 - epoch 055 lr: 0.000100
2022-10-16 12:51:03 - train: epoch 0055, iter [00100, 02526], lr: 0.000100, loss: 0.4393, CELoss: 0.4393, 
2022-10-16 12:51:36 - train: epoch 0055, iter [00200, 02526], lr: 0.000100, loss: 0.5303, CELoss: 0.5303, 
2022-10-16 12:52:10 - train: epoch 0055, iter [00300, 02526], lr: 0.000100, loss: 0.3823, CELoss: 0.3823, 
2022-10-16 12:52:44 - train: epoch 0055, iter [00400, 02526], lr: 0.000100, loss: 0.4828, CELoss: 0.4828, 
2022-10-16 12:53:17 - train: epoch 0055, iter [00500, 02526], lr: 0.000100, loss: 0.4198, CELoss: 0.4198, 
2022-10-16 12:53:51 - train: epoch 0055, iter [00600, 02526], lr: 0.000100, loss: 0.4408, CELoss: 0.4408, 
2022-10-16 12:54:24 - train: epoch 0055, iter [00700, 02526], lr: 0.000100, loss: 0.3261, CELoss: 0.3261, 
2022-10-16 12:54:58 - train: epoch 0055, iter [00800, 02526], lr: 0.000100, loss: 0.7404, CELoss: 0.7404, 
2022-10-16 12:55:31 - train: epoch 0055, iter [00900, 02526], lr: 0.000100, loss: 0.7551, CELoss: 0.7551, 
2022-10-16 12:56:05 - train: epoch 0055, iter [01000, 02526], lr: 0.000100, loss: 0.6645, CELoss: 0.6645, 
2022-10-16 12:56:38 - train: epoch 0055, iter [01100, 02526], lr: 0.000100, loss: 0.5560, CELoss: 0.5560, 
2022-10-16 12:57:12 - train: epoch 0055, iter [01200, 02526], lr: 0.000100, loss: 0.6009, CELoss: 0.6009, 
2022-10-16 12:57:45 - train: epoch 0055, iter [01300, 02526], lr: 0.000100, loss: 0.4560, CELoss: 0.4560, 
2022-10-16 12:58:19 - train: epoch 0055, iter [01400, 02526], lr: 0.000100, loss: 0.3215, CELoss: 0.3215, 
2022-10-16 12:58:52 - train: epoch 0055, iter [01500, 02526], lr: 0.000100, loss: 0.6621, CELoss: 0.6621, 
2022-10-16 12:59:26 - train: epoch 0055, iter [01600, 02526], lr: 0.000100, loss: 0.4484, CELoss: 0.4484, 
2022-10-16 12:59:59 - train: epoch 0055, iter [01700, 02526], lr: 0.000100, loss: 0.4243, CELoss: 0.4243, 
2022-10-16 13:00:33 - train: epoch 0055, iter [01800, 02526], lr: 0.000100, loss: 0.3890, CELoss: 0.3890, 
2022-10-16 13:01:06 - train: epoch 0055, iter [01900, 02526], lr: 0.000100, loss: 0.4137, CELoss: 0.4137, 
2022-10-16 13:01:40 - train: epoch 0055, iter [02000, 02526], lr: 0.000100, loss: 0.4107, CELoss: 0.4107, 
2022-10-16 13:02:13 - train: epoch 0055, iter [02100, 02526], lr: 0.000100, loss: 0.5769, CELoss: 0.5769, 
2022-10-16 13:02:47 - train: epoch 0055, iter [02200, 02526], lr: 0.000100, loss: 0.5290, CELoss: 0.5290, 
2022-10-16 13:03:20 - train: epoch 0055, iter [02300, 02526], lr: 0.000100, loss: 0.7948, CELoss: 0.7948, 
2022-10-16 13:03:54 - train: epoch 0055, iter [02400, 02526], lr: 0.000100, loss: 0.6409, CELoss: 0.6409, 
2022-10-16 13:04:27 - train: epoch 0055, iter [02500, 02526], lr: 0.000100, loss: 0.4485, CELoss: 0.4485, 
2022-10-16 13:04:37 - train: epoch 055, train_loss: 0.5356
2022-10-16 13:05:28 - eval: epoch: 055
test_loss: 0.9177025759220123
per_image_load_time: 1.180ms
per_image_inference_time: 18.296ms
exist_num_class: 150.0
mean_precision: 55.818417802527584
mean_recall: 45.495839097179086
mean_iou: 34.36937149528698
mean_dice: 47.573793647287246

2022-10-16 13:05:30 - until epoch: 055, best_metric: 35.139%
2022-10-16 13:05:30 - epoch 056 lr: 0.000100
2022-10-16 13:06:06 - train: epoch 0056, iter [00100, 02526], lr: 0.000100, loss: 0.3568, CELoss: 0.3568, 
2022-10-16 13:06:39 - train: epoch 0056, iter [00200, 02526], lr: 0.000100, loss: 0.6098, CELoss: 0.6098, 
2022-10-16 13:07:13 - train: epoch 0056, iter [00300, 02526], lr: 0.000100, loss: 0.2960, CELoss: 0.2960, 
2022-10-16 13:07:46 - train: epoch 0056, iter [00400, 02526], lr: 0.000100, loss: 0.6194, CELoss: 0.6194, 
2022-10-16 13:08:20 - train: epoch 0056, iter [00500, 02526], lr: 0.000100, loss: 0.5939, CELoss: 0.5939, 
2022-10-16 13:08:53 - train: epoch 0056, iter [00600, 02526], lr: 0.000100, loss: 0.5379, CELoss: 0.5379, 
2022-10-16 13:09:26 - train: epoch 0056, iter [00700, 02526], lr: 0.000100, loss: 0.8030, CELoss: 0.8030, 
2022-10-16 13:10:00 - train: epoch 0056, iter [00800, 02526], lr: 0.000100, loss: 0.3534, CELoss: 0.3534, 
2022-10-16 13:10:33 - train: epoch 0056, iter [00900, 02526], lr: 0.000100, loss: 0.5030, CELoss: 0.5030, 
2022-10-16 13:11:07 - train: epoch 0056, iter [01000, 02526], lr: 0.000100, loss: 1.0408, CELoss: 1.0408, 
2022-10-16 13:11:40 - train: epoch 0056, iter [01100, 02526], lr: 0.000100, loss: 0.7880, CELoss: 0.7880, 
2022-10-16 13:12:14 - train: epoch 0056, iter [01200, 02526], lr: 0.000100, loss: 0.3964, CELoss: 0.3964, 
2022-10-16 13:12:48 - train: epoch 0056, iter [01300, 02526], lr: 0.000100, loss: 0.6114, CELoss: 0.6114, 
2022-10-16 13:13:21 - train: epoch 0056, iter [01400, 02526], lr: 0.000100, loss: 0.5522, CELoss: 0.5522, 
2022-10-16 13:13:54 - train: epoch 0056, iter [01500, 02526], lr: 0.000100, loss: 0.5417, CELoss: 0.5417, 
2022-10-16 13:14:28 - train: epoch 0056, iter [01600, 02526], lr: 0.000100, loss: 0.5026, CELoss: 0.5026, 
2022-10-16 13:15:01 - train: epoch 0056, iter [01700, 02526], lr: 0.000100, loss: 0.6110, CELoss: 0.6110, 
2022-10-16 13:15:35 - train: epoch 0056, iter [01800, 02526], lr: 0.000100, loss: 0.3921, CELoss: 0.3921, 
2022-10-16 13:16:08 - train: epoch 0056, iter [01900, 02526], lr: 0.000100, loss: 0.9181, CELoss: 0.9181, 
2022-10-16 13:16:42 - train: epoch 0056, iter [02000, 02526], lr: 0.000100, loss: 0.6839, CELoss: 0.6839, 
2022-10-16 13:17:15 - train: epoch 0056, iter [02100, 02526], lr: 0.000100, loss: 0.4472, CELoss: 0.4472, 
2022-10-16 13:17:49 - train: epoch 0056, iter [02200, 02526], lr: 0.000100, loss: 0.7796, CELoss: 0.7796, 
2022-10-16 13:18:22 - train: epoch 0056, iter [02300, 02526], lr: 0.000100, loss: 0.5123, CELoss: 0.5123, 
2022-10-16 13:18:56 - train: epoch 0056, iter [02400, 02526], lr: 0.000100, loss: 0.2976, CELoss: 0.2976, 
2022-10-16 13:19:29 - train: epoch 0056, iter [02500, 02526], lr: 0.000100, loss: 0.4663, CELoss: 0.4663, 
2022-10-16 13:19:39 - train: epoch 056, train_loss: 0.5394
2022-10-16 13:19:41 - until epoch: 056, best_metric: 35.139%
2022-10-16 13:19:41 - epoch 057 lr: 0.000100
2022-10-16 13:20:17 - train: epoch 0057, iter [00100, 02526], lr: 0.000100, loss: 0.5394, CELoss: 0.5394, 
2022-10-16 13:20:50 - train: epoch 0057, iter [00200, 02526], lr: 0.000100, loss: 0.7271, CELoss: 0.7271, 
2022-10-16 13:21:24 - train: epoch 0057, iter [00300, 02526], lr: 0.000100, loss: 0.6894, CELoss: 0.6894, 
2022-10-16 13:21:58 - train: epoch 0057, iter [00400, 02526], lr: 0.000100, loss: 0.5057, CELoss: 0.5057, 
2022-10-16 13:22:31 - train: epoch 0057, iter [00500, 02526], lr: 0.000100, loss: 0.9141, CELoss: 0.9141, 
2022-10-16 13:23:04 - train: epoch 0057, iter [00600, 02526], lr: 0.000100, loss: 0.5653, CELoss: 0.5653, 
2022-10-16 13:23:38 - train: epoch 0057, iter [00700, 02526], lr: 0.000100, loss: 0.3496, CELoss: 0.3496, 
2022-10-16 13:24:11 - train: epoch 0057, iter [00800, 02526], lr: 0.000100, loss: 0.4272, CELoss: 0.4272, 
2022-10-16 13:24:45 - train: epoch 0057, iter [00900, 02526], lr: 0.000100, loss: 0.5040, CELoss: 0.5040, 
2022-10-16 13:25:18 - train: epoch 0057, iter [01000, 02526], lr: 0.000100, loss: 0.6095, CELoss: 0.6095, 
2022-10-16 13:25:52 - train: epoch 0057, iter [01100, 02526], lr: 0.000100, loss: 0.5402, CELoss: 0.5402, 
2022-10-16 13:26:25 - train: epoch 0057, iter [01200, 02526], lr: 0.000100, loss: 0.4503, CELoss: 0.4503, 
2022-10-16 13:26:59 - train: epoch 0057, iter [01300, 02526], lr: 0.000100, loss: 0.4381, CELoss: 0.4381, 
2022-10-16 13:27:33 - train: epoch 0057, iter [01400, 02526], lr: 0.000100, loss: 0.3987, CELoss: 0.3987, 
2022-10-16 13:28:06 - train: epoch 0057, iter [01500, 02526], lr: 0.000100, loss: 0.7861, CELoss: 0.7861, 
2022-10-16 13:28:39 - train: epoch 0057, iter [01600, 02526], lr: 0.000100, loss: 0.4085, CELoss: 0.4085, 
2022-10-16 13:29:13 - train: epoch 0057, iter [01700, 02526], lr: 0.000100, loss: 1.0887, CELoss: 1.0887, 
2022-10-16 13:29:47 - train: epoch 0057, iter [01800, 02526], lr: 0.000100, loss: 0.8327, CELoss: 0.8327, 
2022-10-16 13:30:20 - train: epoch 0057, iter [01900, 02526], lr: 0.000100, loss: 0.4317, CELoss: 0.4317, 
2022-10-16 13:30:54 - train: epoch 0057, iter [02000, 02526], lr: 0.000100, loss: 0.3442, CELoss: 0.3442, 
2022-10-16 13:31:27 - train: epoch 0057, iter [02100, 02526], lr: 0.000100, loss: 0.3668, CELoss: 0.3668, 
2022-10-16 13:32:00 - train: epoch 0057, iter [02200, 02526], lr: 0.000100, loss: 0.4284, CELoss: 0.4284, 
2022-10-16 13:32:34 - train: epoch 0057, iter [02300, 02526], lr: 0.000100, loss: 0.9027, CELoss: 0.9027, 
2022-10-16 13:33:07 - train: epoch 0057, iter [02400, 02526], lr: 0.000100, loss: 0.3390, CELoss: 0.3390, 
2022-10-16 13:33:41 - train: epoch 0057, iter [02500, 02526], lr: 0.000100, loss: 0.4303, CELoss: 0.4303, 
2022-10-16 13:33:51 - train: epoch 057, train_loss: 0.5269
2022-10-16 13:33:53 - until epoch: 057, best_metric: 35.139%
2022-10-16 13:33:53 - epoch 058 lr: 0.000100
2022-10-16 13:34:29 - train: epoch 0058, iter [00100, 02526], lr: 0.000100, loss: 0.6277, CELoss: 0.6277, 
2022-10-16 13:35:03 - train: epoch 0058, iter [00200, 02526], lr: 0.000100, loss: 0.7198, CELoss: 0.7198, 
2022-10-16 13:35:36 - train: epoch 0058, iter [00300, 02526], lr: 0.000100, loss: 0.8264, CELoss: 0.8264, 
2022-10-16 13:36:10 - train: epoch 0058, iter [00400, 02526], lr: 0.000100, loss: 0.5840, CELoss: 0.5840, 
2022-10-16 13:36:43 - train: epoch 0058, iter [00500, 02526], lr: 0.000100, loss: 0.8880, CELoss: 0.8880, 
2022-10-16 13:37:17 - train: epoch 0058, iter [00600, 02526], lr: 0.000100, loss: 0.3272, CELoss: 0.3272, 
2022-10-16 13:37:50 - train: epoch 0058, iter [00700, 02526], lr: 0.000100, loss: 0.4303, CELoss: 0.4303, 
2022-10-16 13:38:24 - train: epoch 0058, iter [00800, 02526], lr: 0.000100, loss: 0.4678, CELoss: 0.4678, 
2022-10-16 13:38:57 - train: epoch 0058, iter [00900, 02526], lr: 0.000100, loss: 0.3146, CELoss: 0.3146, 
2022-10-16 13:39:31 - train: epoch 0058, iter [01000, 02526], lr: 0.000100, loss: 0.3872, CELoss: 0.3872, 
2022-10-16 13:40:04 - train: epoch 0058, iter [01100, 02526], lr: 0.000100, loss: 0.6615, CELoss: 0.6615, 
2022-10-16 13:40:38 - train: epoch 0058, iter [01200, 02526], lr: 0.000100, loss: 0.5520, CELoss: 0.5520, 
2022-10-16 13:41:11 - train: epoch 0058, iter [01300, 02526], lr: 0.000100, loss: 0.3282, CELoss: 0.3282, 
2022-10-16 13:41:45 - train: epoch 0058, iter [01400, 02526], lr: 0.000100, loss: 0.6952, CELoss: 0.6952, 
2022-10-16 13:42:18 - train: epoch 0058, iter [01500, 02526], lr: 0.000100, loss: 0.7687, CELoss: 0.7687, 
2022-10-16 13:42:51 - train: epoch 0058, iter [01600, 02526], lr: 0.000100, loss: 0.3143, CELoss: 0.3143, 
2022-10-16 13:43:25 - train: epoch 0058, iter [01700, 02526], lr: 0.000100, loss: 0.3979, CELoss: 0.3979, 
2022-10-16 13:43:59 - train: epoch 0058, iter [01800, 02526], lr: 0.000100, loss: 0.3385, CELoss: 0.3385, 
2022-10-16 13:44:33 - train: epoch 0058, iter [01900, 02526], lr: 0.000100, loss: 0.4853, CELoss: 0.4853, 
2022-10-16 13:45:06 - train: epoch 0058, iter [02000, 02526], lr: 0.000100, loss: 0.4013, CELoss: 0.4013, 
2022-10-16 13:45:40 - train: epoch 0058, iter [02100, 02526], lr: 0.000100, loss: 0.3608, CELoss: 0.3608, 
2022-10-16 13:46:13 - train: epoch 0058, iter [02200, 02526], lr: 0.000100, loss: 0.3240, CELoss: 0.3240, 
2022-10-16 13:46:47 - train: epoch 0058, iter [02300, 02526], lr: 0.000100, loss: 0.4028, CELoss: 0.4028, 
2022-10-16 13:47:20 - train: epoch 0058, iter [02400, 02526], lr: 0.000100, loss: 1.0758, CELoss: 1.0758, 
2022-10-16 13:47:53 - train: epoch 0058, iter [02500, 02526], lr: 0.000100, loss: 0.6388, CELoss: 0.6388, 
2022-10-16 13:48:03 - train: epoch 058, train_loss: 0.5200
2022-10-16 13:48:05 - until epoch: 058, best_metric: 35.139%
2022-10-16 13:48:05 - epoch 059 lr: 0.000100
2022-10-16 13:48:41 - train: epoch 0059, iter [00100, 02526], lr: 0.000100, loss: 0.4866, CELoss: 0.4866, 
2022-10-16 13:49:14 - train: epoch 0059, iter [00200, 02526], lr: 0.000100, loss: 0.6059, CELoss: 0.6059, 
2022-10-16 13:49:48 - train: epoch 0059, iter [00300, 02526], lr: 0.000100, loss: 0.6497, CELoss: 0.6497, 
2022-10-16 13:50:21 - train: epoch 0059, iter [00400, 02526], lr: 0.000100, loss: 0.4232, CELoss: 0.4232, 
2022-10-16 13:50:54 - train: epoch 0059, iter [00500, 02526], lr: 0.000100, loss: 0.3744, CELoss: 0.3744, 
2022-10-16 13:51:28 - train: epoch 0059, iter [00600, 02526], lr: 0.000100, loss: 0.3482, CELoss: 0.3482, 
2022-10-16 13:52:01 - train: epoch 0059, iter [00700, 02526], lr: 0.000100, loss: 0.7450, CELoss: 0.7450, 
2022-10-16 13:52:35 - train: epoch 0059, iter [00800, 02526], lr: 0.000100, loss: 0.2682, CELoss: 0.2682, 
2022-10-16 13:53:08 - train: epoch 0059, iter [00900, 02526], lr: 0.000100, loss: 0.6083, CELoss: 0.6083, 
2022-10-16 13:53:41 - train: epoch 0059, iter [01000, 02526], lr: 0.000100, loss: 0.5103, CELoss: 0.5103, 
2022-10-16 13:54:15 - train: epoch 0059, iter [01100, 02526], lr: 0.000100, loss: 0.3120, CELoss: 0.3120, 
2022-10-16 13:54:48 - train: epoch 0059, iter [01200, 02526], lr: 0.000100, loss: 0.8740, CELoss: 0.8740, 
2022-10-16 13:55:22 - train: epoch 0059, iter [01300, 02526], lr: 0.000100, loss: 0.4373, CELoss: 0.4373, 
2022-10-16 13:55:55 - train: epoch 0059, iter [01400, 02526], lr: 0.000100, loss: 0.6512, CELoss: 0.6512, 
2022-10-16 13:56:29 - train: epoch 0059, iter [01500, 02526], lr: 0.000100, loss: 0.3725, CELoss: 0.3725, 
2022-10-16 13:57:02 - train: epoch 0059, iter [01600, 02526], lr: 0.000100, loss: 0.2678, CELoss: 0.2678, 
2022-10-16 13:57:36 - train: epoch 0059, iter [01700, 02526], lr: 0.000100, loss: 0.7522, CELoss: 0.7522, 
2022-10-16 13:58:09 - train: epoch 0059, iter [01800, 02526], lr: 0.000100, loss: 0.4588, CELoss: 0.4588, 
2022-10-16 13:58:43 - train: epoch 0059, iter [01900, 02526], lr: 0.000100, loss: 0.3358, CELoss: 0.3358, 
2022-10-16 13:59:16 - train: epoch 0059, iter [02000, 02526], lr: 0.000100, loss: 0.4571, CELoss: 0.4571, 
2022-10-16 13:59:50 - train: epoch 0059, iter [02100, 02526], lr: 0.000100, loss: 0.4960, CELoss: 0.4960, 
2022-10-16 14:00:23 - train: epoch 0059, iter [02200, 02526], lr: 0.000100, loss: 0.3338, CELoss: 0.3338, 
2022-10-16 14:00:57 - train: epoch 0059, iter [02300, 02526], lr: 0.000100, loss: 0.2604, CELoss: 0.2604, 
2022-10-16 14:01:30 - train: epoch 0059, iter [02400, 02526], lr: 0.000100, loss: 1.0956, CELoss: 1.0956, 
2022-10-16 14:02:04 - train: epoch 0059, iter [02500, 02526], lr: 0.000100, loss: 0.4887, CELoss: 0.4887, 
2022-10-16 14:02:14 - train: epoch 059, train_loss: 0.5171
2022-10-16 14:02:16 - until epoch: 059, best_metric: 35.139%
2022-10-16 14:02:16 - epoch 060 lr: 0.000100
2022-10-16 14:02:51 - train: epoch 0060, iter [00100, 02526], lr: 0.000100, loss: 0.4308, CELoss: 0.4308, 
2022-10-16 14:03:25 - train: epoch 0060, iter [00200, 02526], lr: 0.000100, loss: 0.6493, CELoss: 0.6493, 
2022-10-16 14:03:58 - train: epoch 0060, iter [00300, 02526], lr: 0.000100, loss: 0.8413, CELoss: 0.8413, 
2022-10-16 14:04:32 - train: epoch 0060, iter [00400, 02526], lr: 0.000100, loss: 0.4891, CELoss: 0.4891, 
2022-10-16 14:05:05 - train: epoch 0060, iter [00500, 02526], lr: 0.000100, loss: 0.4297, CELoss: 0.4297, 
2022-10-16 14:05:39 - train: epoch 0060, iter [00600, 02526], lr: 0.000100, loss: 0.4066, CELoss: 0.4066, 
2022-10-16 14:06:12 - train: epoch 0060, iter [00700, 02526], lr: 0.000100, loss: 0.5935, CELoss: 0.5935, 
2022-10-16 14:06:45 - train: epoch 0060, iter [00800, 02526], lr: 0.000100, loss: 0.5239, CELoss: 0.5239, 
2022-10-16 14:07:19 - train: epoch 0060, iter [00900, 02526], lr: 0.000100, loss: 0.3271, CELoss: 0.3271, 
2022-10-16 14:07:52 - train: epoch 0060, iter [01000, 02526], lr: 0.000100, loss: 0.4854, CELoss: 0.4854, 
2022-10-16 14:08:26 - train: epoch 0060, iter [01100, 02526], lr: 0.000100, loss: 0.6146, CELoss: 0.6146, 
2022-10-16 14:08:59 - train: epoch 0060, iter [01200, 02526], lr: 0.000100, loss: 0.4469, CELoss: 0.4469, 
2022-10-16 14:09:33 - train: epoch 0060, iter [01300, 02526], lr: 0.000100, loss: 0.4211, CELoss: 0.4211, 
2022-10-16 14:10:06 - train: epoch 0060, iter [01400, 02526], lr: 0.000100, loss: 0.6477, CELoss: 0.6477, 
2022-10-16 14:10:40 - train: epoch 0060, iter [01500, 02526], lr: 0.000100, loss: 0.4455, CELoss: 0.4455, 
2022-10-16 14:11:13 - train: epoch 0060, iter [01600, 02526], lr: 0.000100, loss: 0.3473, CELoss: 0.3473, 
2022-10-16 14:11:47 - train: epoch 0060, iter [01700, 02526], lr: 0.000100, loss: 0.4998, CELoss: 0.4998, 
2022-10-16 14:12:20 - train: epoch 0060, iter [01800, 02526], lr: 0.000100, loss: 0.4753, CELoss: 0.4753, 
2022-10-16 14:12:54 - train: epoch 0060, iter [01900, 02526], lr: 0.000100, loss: 0.6011, CELoss: 0.6011, 
2022-10-16 14:13:27 - train: epoch 0060, iter [02000, 02526], lr: 0.000100, loss: 0.8729, CELoss: 0.8729, 
2022-10-16 14:14:01 - train: epoch 0060, iter [02100, 02526], lr: 0.000100, loss: 0.4024, CELoss: 0.4024, 
2022-10-16 14:14:34 - train: epoch 0060, iter [02200, 02526], lr: 0.000100, loss: 0.5963, CELoss: 0.5963, 
2022-10-16 14:15:07 - train: epoch 0060, iter [02300, 02526], lr: 0.000100, loss: 0.3859, CELoss: 0.3859, 
2022-10-16 14:15:41 - train: epoch 0060, iter [02400, 02526], lr: 0.000100, loss: 0.4431, CELoss: 0.4431, 
2022-10-16 14:16:14 - train: epoch 0060, iter [02500, 02526], lr: 0.000100, loss: 0.5653, CELoss: 0.5653, 
2022-10-16 14:16:24 - train: epoch 060, train_loss: 0.5154
2022-10-16 14:17:14 - eval: epoch: 060
test_loss: 0.885633329629898
per_image_load_time: 1.057ms
per_image_inference_time: 18.286ms
exist_num_class: 150.0
mean_precision: 55.398232808961346
mean_recall: 47.006708296149725
mean_iou: 35.65320557337655
mean_dice: 48.867204437449125

2022-10-16 14:17:17 - until epoch: 060, best_metric: 35.653%
2022-10-16 14:17:17 - epoch 061 lr: 0.000100
2022-10-16 14:17:53 - train: epoch 0061, iter [00100, 02526], lr: 0.000100, loss: 0.5055, CELoss: 0.5055, 
2022-10-16 14:18:26 - train: epoch 0061, iter [00200, 02526], lr: 0.000100, loss: 0.4670, CELoss: 0.4670, 
2022-10-16 14:19:00 - train: epoch 0061, iter [00300, 02526], lr: 0.000100, loss: 0.4862, CELoss: 0.4862, 
2022-10-16 14:19:33 - train: epoch 0061, iter [00400, 02526], lr: 0.000100, loss: 0.6738, CELoss: 0.6738, 
2022-10-16 14:20:07 - train: epoch 0061, iter [00500, 02526], lr: 0.000100, loss: 0.4411, CELoss: 0.4411, 
2022-10-16 14:20:40 - train: epoch 0061, iter [00600, 02526], lr: 0.000100, loss: 0.4251, CELoss: 0.4251, 
2022-10-16 14:21:14 - train: epoch 0061, iter [00700, 02526], lr: 0.000100, loss: 0.8997, CELoss: 0.8997, 
2022-10-16 14:21:48 - train: epoch 0061, iter [00800, 02526], lr: 0.000100, loss: 0.7969, CELoss: 0.7969, 
2022-10-16 14:22:21 - train: epoch 0061, iter [00900, 02526], lr: 0.000100, loss: 0.6823, CELoss: 0.6823, 
2022-10-16 14:22:54 - train: epoch 0061, iter [01000, 02526], lr: 0.000100, loss: 0.4650, CELoss: 0.4650, 
2022-10-16 14:23:28 - train: epoch 0061, iter [01100, 02526], lr: 0.000100, loss: 0.4619, CELoss: 0.4619, 
2022-10-16 14:24:01 - train: epoch 0061, iter [01200, 02526], lr: 0.000100, loss: 0.4013, CELoss: 0.4013, 
2022-10-16 14:24:35 - train: epoch 0061, iter [01300, 02526], lr: 0.000100, loss: 0.2857, CELoss: 0.2857, 
2022-10-16 14:25:08 - train: epoch 0061, iter [01400, 02526], lr: 0.000100, loss: 0.5499, CELoss: 0.5499, 
2022-10-16 14:25:41 - train: epoch 0061, iter [01500, 02526], lr: 0.000100, loss: 0.6042, CELoss: 0.6042, 
2022-10-16 14:26:15 - train: epoch 0061, iter [01600, 02526], lr: 0.000100, loss: 0.4807, CELoss: 0.4807, 
2022-10-16 14:26:48 - train: epoch 0061, iter [01700, 02526], lr: 0.000100, loss: 0.4115, CELoss: 0.4115, 
2022-10-16 14:27:22 - train: epoch 0061, iter [01800, 02526], lr: 0.000100, loss: 0.6289, CELoss: 0.6289, 
2022-10-16 14:27:55 - train: epoch 0061, iter [01900, 02526], lr: 0.000100, loss: 0.4980, CELoss: 0.4980, 
2022-10-16 14:28:29 - train: epoch 0061, iter [02000, 02526], lr: 0.000100, loss: 0.4367, CELoss: 0.4367, 
2022-10-16 14:29:02 - train: epoch 0061, iter [02100, 02526], lr: 0.000100, loss: 0.6493, CELoss: 0.6493, 
2022-10-16 14:29:36 - train: epoch 0061, iter [02200, 02526], lr: 0.000100, loss: 0.6694, CELoss: 0.6694, 
2022-10-16 14:30:09 - train: epoch 0061, iter [02300, 02526], lr: 0.000100, loss: 0.5046, CELoss: 0.5046, 
2022-10-16 14:30:42 - train: epoch 0061, iter [02400, 02526], lr: 0.000100, loss: 0.6584, CELoss: 0.6584, 
2022-10-16 14:31:16 - train: epoch 0061, iter [02500, 02526], lr: 0.000100, loss: 0.4739, CELoss: 0.4739, 
2022-10-16 14:31:26 - train: epoch 061, train_loss: 0.5069
2022-10-16 14:31:28 - until epoch: 061, best_metric: 35.653%
2022-10-16 14:31:28 - epoch 062 lr: 0.000100
2022-10-16 14:32:04 - train: epoch 0062, iter [00100, 02526], lr: 0.000100, loss: 0.5237, CELoss: 0.5237, 
2022-10-16 14:32:38 - train: epoch 0062, iter [00200, 02526], lr: 0.000100, loss: 0.3646, CELoss: 0.3646, 
2022-10-16 14:33:11 - train: epoch 0062, iter [00300, 02526], lr: 0.000100, loss: 0.4791, CELoss: 0.4791, 
2022-10-16 14:33:44 - train: epoch 0062, iter [00400, 02526], lr: 0.000100, loss: 0.6211, CELoss: 0.6211, 
2022-10-16 14:34:18 - train: epoch 0062, iter [00500, 02526], lr: 0.000100, loss: 0.3658, CELoss: 0.3658, 
2022-10-16 14:34:51 - train: epoch 0062, iter [00600, 02526], lr: 0.000100, loss: 0.5203, CELoss: 0.5203, 
2022-10-16 14:35:24 - train: epoch 0062, iter [00700, 02526], lr: 0.000100, loss: 0.9348, CELoss: 0.9348, 
2022-10-16 14:35:58 - train: epoch 0062, iter [00800, 02526], lr: 0.000100, loss: 0.3979, CELoss: 0.3979, 
2022-10-16 14:36:32 - train: epoch 0062, iter [00900, 02526], lr: 0.000100, loss: 0.5968, CELoss: 0.5968, 
2022-10-16 14:37:05 - train: epoch 0062, iter [01000, 02526], lr: 0.000100, loss: 0.5381, CELoss: 0.5381, 
2022-10-16 14:37:38 - train: epoch 0062, iter [01100, 02526], lr: 0.000100, loss: 0.5352, CELoss: 0.5352, 
2022-10-16 14:38:12 - train: epoch 0062, iter [01200, 02526], lr: 0.000100, loss: 0.4375, CELoss: 0.4375, 
2022-10-16 14:38:45 - train: epoch 0062, iter [01300, 02526], lr: 0.000100, loss: 0.5294, CELoss: 0.5294, 
2022-10-16 14:39:19 - train: epoch 0062, iter [01400, 02526], lr: 0.000100, loss: 0.4906, CELoss: 0.4906, 
2022-10-16 14:39:52 - train: epoch 0062, iter [01500, 02526], lr: 0.000100, loss: 0.4907, CELoss: 0.4907, 
2022-10-16 14:40:26 - train: epoch 0062, iter [01600, 02526], lr: 0.000100, loss: 0.1978, CELoss: 0.1978, 
2022-10-16 14:40:59 - train: epoch 0062, iter [01700, 02526], lr: 0.000100, loss: 0.5325, CELoss: 0.5325, 
2022-10-16 14:41:33 - train: epoch 0062, iter [01800, 02526], lr: 0.000100, loss: 0.4721, CELoss: 0.4721, 
2022-10-16 14:42:07 - train: epoch 0062, iter [01900, 02526], lr: 0.000100, loss: 0.4061, CELoss: 0.4061, 
2022-10-16 14:42:40 - train: epoch 0062, iter [02000, 02526], lr: 0.000100, loss: 0.5810, CELoss: 0.5810, 
2022-10-16 14:43:14 - train: epoch 0062, iter [02100, 02526], lr: 0.000100, loss: 0.6230, CELoss: 0.6230, 
2022-10-16 14:43:47 - train: epoch 0062, iter [02200, 02526], lr: 0.000100, loss: 0.4850, CELoss: 0.4850, 
2022-10-16 14:44:21 - train: epoch 0062, iter [02300, 02526], lr: 0.000100, loss: 0.5505, CELoss: 0.5505, 
2022-10-16 14:44:54 - train: epoch 0062, iter [02400, 02526], lr: 0.000100, loss: 0.5438, CELoss: 0.5438, 
2022-10-16 14:45:27 - train: epoch 0062, iter [02500, 02526], lr: 0.000100, loss: 0.7570, CELoss: 0.7570, 
2022-10-16 14:45:37 - train: epoch 062, train_loss: 0.5065
2022-10-16 14:45:39 - until epoch: 062, best_metric: 35.653%
2022-10-16 14:45:39 - epoch 063 lr: 0.000100
2022-10-16 14:46:14 - train: epoch 0063, iter [00100, 02526], lr: 0.000100, loss: 0.5075, CELoss: 0.5075, 
2022-10-16 14:46:48 - train: epoch 0063, iter [00200, 02526], lr: 0.000100, loss: 0.4775, CELoss: 0.4775, 
2022-10-16 14:47:21 - train: epoch 0063, iter [00300, 02526], lr: 0.000100, loss: 0.4818, CELoss: 0.4818, 
2022-10-16 14:47:55 - train: epoch 0063, iter [00400, 02526], lr: 0.000100, loss: 0.4324, CELoss: 0.4324, 
2022-10-16 14:48:28 - train: epoch 0063, iter [00500, 02526], lr: 0.000100, loss: 0.3229, CELoss: 0.3229, 
2022-10-16 14:49:01 - train: epoch 0063, iter [00600, 02526], lr: 0.000100, loss: 0.6006, CELoss: 0.6006, 
2022-10-16 14:49:35 - train: epoch 0063, iter [00700, 02526], lr: 0.000100, loss: 0.2954, CELoss: 0.2954, 
2022-10-16 14:50:08 - train: epoch 0063, iter [00800, 02526], lr: 0.000100, loss: 0.2223, CELoss: 0.2223, 
2022-10-16 14:50:42 - train: epoch 0063, iter [00900, 02526], lr: 0.000100, loss: 0.5303, CELoss: 0.5303, 
2022-10-16 14:51:15 - train: epoch 0063, iter [01000, 02526], lr: 0.000100, loss: 0.5878, CELoss: 0.5878, 
2022-10-16 14:51:48 - train: epoch 0063, iter [01100, 02526], lr: 0.000100, loss: 0.3948, CELoss: 0.3948, 
2022-10-16 14:52:22 - train: epoch 0063, iter [01200, 02526], lr: 0.000100, loss: 0.4059, CELoss: 0.4059, 
2022-10-16 14:52:55 - train: epoch 0063, iter [01300, 02526], lr: 0.000100, loss: 0.4965, CELoss: 0.4965, 
2022-10-16 14:53:29 - train: epoch 0063, iter [01400, 02526], lr: 0.000100, loss: 0.4362, CELoss: 0.4362, 
2022-10-16 14:54:02 - train: epoch 0063, iter [01500, 02526], lr: 0.000100, loss: 0.6852, CELoss: 0.6852, 
2022-10-16 14:54:35 - train: epoch 0063, iter [01600, 02526], lr: 0.000100, loss: 0.6101, CELoss: 0.6101, 
2022-10-16 14:55:09 - train: epoch 0063, iter [01700, 02526], lr: 0.000100, loss: 0.3141, CELoss: 0.3141, 
2022-10-16 14:55:42 - train: epoch 0063, iter [01800, 02526], lr: 0.000100, loss: 0.5948, CELoss: 0.5948, 
2022-10-16 14:56:16 - train: epoch 0063, iter [01900, 02526], lr: 0.000100, loss: 0.7872, CELoss: 0.7872, 
2022-10-16 14:56:49 - train: epoch 0063, iter [02000, 02526], lr: 0.000100, loss: 0.6075, CELoss: 0.6075, 
2022-10-16 14:57:23 - train: epoch 0063, iter [02100, 02526], lr: 0.000100, loss: 0.5704, CELoss: 0.5704, 
2022-10-16 14:57:57 - train: epoch 0063, iter [02200, 02526], lr: 0.000100, loss: 0.5576, CELoss: 0.5576, 
2022-10-16 14:58:30 - train: epoch 0063, iter [02300, 02526], lr: 0.000100, loss: 0.4695, CELoss: 0.4695, 
2022-10-16 14:59:04 - train: epoch 0063, iter [02400, 02526], lr: 0.000100, loss: 0.6019, CELoss: 0.6019, 
2022-10-16 14:59:37 - train: epoch 0063, iter [02500, 02526], lr: 0.000100, loss: 0.3423, CELoss: 0.3423, 
2022-10-16 14:59:47 - train: epoch 063, train_loss: 0.4980
2022-10-16 14:59:49 - until epoch: 063, best_metric: 35.653%
2022-10-16 14:59:49 - epoch 064 lr: 0.000100
2022-10-16 15:00:25 - train: epoch 0064, iter [00100, 02526], lr: 0.000100, loss: 0.4002, CELoss: 0.4002, 
2022-10-16 15:00:59 - train: epoch 0064, iter [00200, 02526], lr: 0.000100, loss: 0.4212, CELoss: 0.4212, 
2022-10-16 15:01:32 - train: epoch 0064, iter [00300, 02526], lr: 0.000100, loss: 0.4141, CELoss: 0.4141, 
2022-10-16 15:02:05 - train: epoch 0064, iter [00400, 02526], lr: 0.000100, loss: 0.3951, CELoss: 0.3951, 
2022-10-16 15:02:39 - train: epoch 0064, iter [00500, 02526], lr: 0.000100, loss: 0.3980, CELoss: 0.3980, 
2022-10-16 15:03:12 - train: epoch 0064, iter [00600, 02526], lr: 0.000100, loss: 0.4607, CELoss: 0.4607, 
2022-10-16 15:03:46 - train: epoch 0064, iter [00700, 02526], lr: 0.000100, loss: 0.3157, CELoss: 0.3157, 
2022-10-16 15:04:19 - train: epoch 0064, iter [00800, 02526], lr: 0.000100, loss: 0.4183, CELoss: 0.4183, 
2022-10-16 15:04:53 - train: epoch 0064, iter [00900, 02526], lr: 0.000100, loss: 0.5298, CELoss: 0.5298, 
2022-10-16 15:05:26 - train: epoch 0064, iter [01000, 02526], lr: 0.000100, loss: 0.7923, CELoss: 0.7923, 
2022-10-16 15:05:59 - train: epoch 0064, iter [01100, 02526], lr: 0.000100, loss: 0.7065, CELoss: 0.7065, 
2022-10-16 15:06:33 - train: epoch 0064, iter [01200, 02526], lr: 0.000100, loss: 0.4973, CELoss: 0.4973, 
2022-10-16 15:07:06 - train: epoch 0064, iter [01300, 02526], lr: 0.000100, loss: 0.5883, CELoss: 0.5883, 
2022-10-16 15:07:39 - train: epoch 0064, iter [01400, 02526], lr: 0.000100, loss: 0.4815, CELoss: 0.4815, 
2022-10-16 15:08:13 - train: epoch 0064, iter [01500, 02526], lr: 0.000100, loss: 0.3629, CELoss: 0.3629, 
2022-10-16 15:08:46 - train: epoch 0064, iter [01600, 02526], lr: 0.000100, loss: 0.4886, CELoss: 0.4886, 
2022-10-16 15:09:20 - train: epoch 0064, iter [01700, 02526], lr: 0.000100, loss: 0.4420, CELoss: 0.4420, 
2022-10-16 15:09:53 - train: epoch 0064, iter [01800, 02526], lr: 0.000100, loss: 0.4954, CELoss: 0.4954, 
2022-10-16 15:10:27 - train: epoch 0064, iter [01900, 02526], lr: 0.000100, loss: 0.7055, CELoss: 0.7055, 
2022-10-16 15:11:00 - train: epoch 0064, iter [02000, 02526], lr: 0.000100, loss: 0.5007, CELoss: 0.5007, 
2022-10-16 15:11:34 - train: epoch 0064, iter [02100, 02526], lr: 0.000100, loss: 0.5127, CELoss: 0.5127, 
2022-10-16 15:12:07 - train: epoch 0064, iter [02200, 02526], lr: 0.000100, loss: 0.3543, CELoss: 0.3543, 
2022-10-16 15:12:40 - train: epoch 0064, iter [02300, 02526], lr: 0.000100, loss: 0.7247, CELoss: 0.7247, 
2022-10-16 15:13:14 - train: epoch 0064, iter [02400, 02526], lr: 0.000100, loss: 0.7687, CELoss: 0.7687, 
2022-10-16 15:13:47 - train: epoch 0064, iter [02500, 02526], lr: 0.000100, loss: 0.4687, CELoss: 0.4687, 
2022-10-16 15:13:57 - train: epoch 064, train_loss: 0.4979
2022-10-16 15:13:59 - until epoch: 064, best_metric: 35.653%
2022-10-16 15:13:59 - epoch 065 lr: 0.000100
2022-10-16 15:14:35 - train: epoch 0065, iter [00100, 02526], lr: 0.000100, loss: 0.5990, CELoss: 0.5990, 
2022-10-16 15:15:08 - train: epoch 0065, iter [00200, 02526], lr: 0.000100, loss: 0.7059, CELoss: 0.7059, 
2022-10-16 15:15:42 - train: epoch 0065, iter [00300, 02526], lr: 0.000100, loss: 0.4400, CELoss: 0.4400, 
2022-10-16 15:16:16 - train: epoch 0065, iter [00400, 02526], lr: 0.000100, loss: 0.6348, CELoss: 0.6348, 
2022-10-16 15:16:49 - train: epoch 0065, iter [00500, 02526], lr: 0.000100, loss: 0.2669, CELoss: 0.2669, 
2022-10-16 15:17:23 - train: epoch 0065, iter [00600, 02526], lr: 0.000100, loss: 0.5338, CELoss: 0.5338, 
2022-10-16 15:17:56 - train: epoch 0065, iter [00700, 02526], lr: 0.000100, loss: 0.3893, CELoss: 0.3893, 
2022-10-16 15:18:29 - train: epoch 0065, iter [00800, 02526], lr: 0.000100, loss: 0.3879, CELoss: 0.3879, 
2022-10-16 15:19:03 - train: epoch 0065, iter [00900, 02526], lr: 0.000100, loss: 0.5626, CELoss: 0.5626, 
2022-10-16 15:19:37 - train: epoch 0065, iter [01000, 02526], lr: 0.000100, loss: 0.3430, CELoss: 0.3430, 
2022-10-16 15:20:10 - train: epoch 0065, iter [01100, 02526], lr: 0.000100, loss: 0.4234, CELoss: 0.4234, 
2022-10-16 15:20:43 - train: epoch 0065, iter [01200, 02526], lr: 0.000100, loss: 0.4373, CELoss: 0.4373, 
2022-10-16 15:21:17 - train: epoch 0065, iter [01300, 02526], lr: 0.000100, loss: 0.7461, CELoss: 0.7461, 
2022-10-16 15:21:51 - train: epoch 0065, iter [01400, 02526], lr: 0.000100, loss: 0.5836, CELoss: 0.5836, 
2022-10-16 15:22:24 - train: epoch 0065, iter [01500, 02526], lr: 0.000100, loss: 0.4731, CELoss: 0.4731, 
2022-10-16 15:22:58 - train: epoch 0065, iter [01600, 02526], lr: 0.000100, loss: 0.6232, CELoss: 0.6232, 
2022-10-16 15:23:32 - train: epoch 0065, iter [01700, 02526], lr: 0.000100, loss: 0.6805, CELoss: 0.6805, 
2022-10-16 15:24:05 - train: epoch 0065, iter [01800, 02526], lr: 0.000100, loss: 0.4710, CELoss: 0.4710, 
2022-10-16 15:24:38 - train: epoch 0065, iter [01900, 02526], lr: 0.000100, loss: 0.4544, CELoss: 0.4544, 
2022-10-16 15:25:12 - train: epoch 0065, iter [02000, 02526], lr: 0.000100, loss: 0.4751, CELoss: 0.4751, 
2022-10-16 15:25:45 - train: epoch 0065, iter [02100, 02526], lr: 0.000100, loss: 0.4562, CELoss: 0.4562, 
2022-10-16 15:26:18 - train: epoch 0065, iter [02200, 02526], lr: 0.000100, loss: 0.3090, CELoss: 0.3090, 
2022-10-16 15:26:52 - train: epoch 0065, iter [02300, 02526], lr: 0.000100, loss: 0.6275, CELoss: 0.6275, 
2022-10-16 15:27:25 - train: epoch 0065, iter [02400, 02526], lr: 0.000100, loss: 0.5565, CELoss: 0.5565, 
2022-10-16 15:27:58 - train: epoch 0065, iter [02500, 02526], lr: 0.000100, loss: 0.7275, CELoss: 0.7275, 
2022-10-16 15:28:08 - train: epoch 065, train_loss: 0.4903
2022-10-16 15:28:59 - eval: epoch: 065
test_loss: 0.9047107448577881
per_image_load_time: 1.079ms
per_image_inference_time: 18.283ms
exist_num_class: 150.0
mean_precision: 55.9240537609621
mean_recall: 47.16650573078914
mean_iou: 35.72010966897359
mean_dice: 48.983862845420184

2022-10-16 15:29:02 - until epoch: 065, best_metric: 35.720%
2022-10-16 15:29:02 - epoch 066 lr: 0.000100
2022-10-16 15:29:38 - train: epoch 0066, iter [00100, 02526], lr: 0.000100, loss: 0.5742, CELoss: 0.5742, 
2022-10-16 15:30:12 - train: epoch 0066, iter [00200, 02526], lr: 0.000100, loss: 0.3676, CELoss: 0.3676, 
2022-10-16 15:30:45 - train: epoch 0066, iter [00300, 02526], lr: 0.000100, loss: 0.4941, CELoss: 0.4941, 
2022-10-16 15:31:19 - train: epoch 0066, iter [00400, 02526], lr: 0.000100, loss: 0.6377, CELoss: 0.6377, 
2022-10-16 15:31:53 - train: epoch 0066, iter [00500, 02526], lr: 0.000100, loss: 0.4786, CELoss: 0.4786, 
2022-10-16 15:32:26 - train: epoch 0066, iter [00600, 02526], lr: 0.000100, loss: 0.4537, CELoss: 0.4537, 
2022-10-16 15:33:00 - train: epoch 0066, iter [00700, 02526], lr: 0.000100, loss: 0.7283, CELoss: 0.7283, 
2022-10-16 15:33:33 - train: epoch 0066, iter [00800, 02526], lr: 0.000100, loss: 0.4297, CELoss: 0.4297, 
2022-10-16 15:34:06 - train: epoch 0066, iter [00900, 02526], lr: 0.000100, loss: 0.3656, CELoss: 0.3656, 
2022-10-16 15:34:40 - train: epoch 0066, iter [01000, 02526], lr: 0.000100, loss: 0.3601, CELoss: 0.3601, 
2022-10-16 15:35:13 - train: epoch 0066, iter [01100, 02526], lr: 0.000100, loss: 0.2980, CELoss: 0.2980, 
2022-10-16 15:35:47 - train: epoch 0066, iter [01200, 02526], lr: 0.000100, loss: 0.5081, CELoss: 0.5081, 
2022-10-16 15:36:20 - train: epoch 0066, iter [01300, 02526], lr: 0.000100, loss: 0.6460, CELoss: 0.6460, 
2022-10-16 15:36:54 - train: epoch 0066, iter [01400, 02526], lr: 0.000100, loss: 0.3196, CELoss: 0.3196, 
2022-10-16 15:37:27 - train: epoch 0066, iter [01500, 02526], lr: 0.000100, loss: 0.3810, CELoss: 0.3810, 
2022-10-16 15:38:01 - train: epoch 0066, iter [01600, 02526], lr: 0.000100, loss: 0.5738, CELoss: 0.5738, 
2022-10-16 15:38:35 - train: epoch 0066, iter [01700, 02526], lr: 0.000100, loss: 0.3957, CELoss: 0.3957, 
2022-10-16 15:39:09 - train: epoch 0066, iter [01800, 02526], lr: 0.000100, loss: 0.3789, CELoss: 0.3789, 
2022-10-16 15:39:42 - train: epoch 0066, iter [01900, 02526], lr: 0.000100, loss: 0.5120, CELoss: 0.5120, 
2022-10-16 15:40:15 - train: epoch 0066, iter [02000, 02526], lr: 0.000100, loss: 0.3223, CELoss: 0.3223, 
2022-10-16 15:40:49 - train: epoch 0066, iter [02100, 02526], lr: 0.000100, loss: 0.4422, CELoss: 0.4422, 
2022-10-16 15:41:22 - train: epoch 0066, iter [02200, 02526], lr: 0.000100, loss: 0.5906, CELoss: 0.5906, 
2022-10-16 15:41:55 - train: epoch 0066, iter [02300, 02526], lr: 0.000100, loss: 0.5290, CELoss: 0.5290, 
2022-10-16 15:42:29 - train: epoch 0066, iter [02400, 02526], lr: 0.000100, loss: 0.4467, CELoss: 0.4467, 
2022-10-16 15:43:03 - train: epoch 0066, iter [02500, 02526], lr: 0.000100, loss: 0.5866, CELoss: 0.5866, 
2022-10-16 15:43:13 - train: epoch 066, train_loss: 0.4874
2022-10-16 15:43:15 - until epoch: 066, best_metric: 35.720%
2022-10-16 15:43:15 - epoch 067 lr: 0.000100
2022-10-16 15:43:51 - train: epoch 0067, iter [00100, 02526], lr: 0.000100, loss: 0.3741, CELoss: 0.3741, 
2022-10-16 15:44:24 - train: epoch 0067, iter [00200, 02526], lr: 0.000100, loss: 0.4667, CELoss: 0.4667, 
2022-10-16 15:44:57 - train: epoch 0067, iter [00300, 02526], lr: 0.000100, loss: 0.3621, CELoss: 0.3621, 
2022-10-16 15:45:30 - train: epoch 0067, iter [00400, 02526], lr: 0.000100, loss: 0.5489, CELoss: 0.5489, 
2022-10-16 15:46:04 - train: epoch 0067, iter [00500, 02526], lr: 0.000100, loss: 0.5764, CELoss: 0.5764, 
2022-10-16 15:46:37 - train: epoch 0067, iter [00600, 02526], lr: 0.000100, loss: 0.5250, CELoss: 0.5250, 
2022-10-16 15:47:11 - train: epoch 0067, iter [00700, 02526], lr: 0.000100, loss: 0.3332, CELoss: 0.3332, 
2022-10-16 15:47:44 - train: epoch 0067, iter [00800, 02526], lr: 0.000100, loss: 0.5220, CELoss: 0.5220, 
2022-10-16 15:48:18 - train: epoch 0067, iter [00900, 02526], lr: 0.000100, loss: 0.3083, CELoss: 0.3083, 
2022-10-16 15:48:51 - train: epoch 0067, iter [01000, 02526], lr: 0.000100, loss: 0.5549, CELoss: 0.5549, 
2022-10-16 15:49:25 - train: epoch 0067, iter [01100, 02526], lr: 0.000100, loss: 0.4427, CELoss: 0.4427, 
2022-10-16 15:49:58 - train: epoch 0067, iter [01200, 02526], lr: 0.000100, loss: 0.3339, CELoss: 0.3339, 
2022-10-16 15:50:32 - train: epoch 0067, iter [01300, 02526], lr: 0.000100, loss: 0.3271, CELoss: 0.3271, 
2022-10-16 15:51:06 - train: epoch 0067, iter [01400, 02526], lr: 0.000100, loss: 0.6896, CELoss: 0.6896, 
2022-10-16 15:51:39 - train: epoch 0067, iter [01500, 02526], lr: 0.000100, loss: 0.5981, CELoss: 0.5981, 
2022-10-16 15:52:12 - train: epoch 0067, iter [01600, 02526], lr: 0.000100, loss: 0.1904, CELoss: 0.1904, 
2022-10-16 15:52:46 - train: epoch 0067, iter [01700, 02526], lr: 0.000100, loss: 0.3538, CELoss: 0.3538, 
2022-10-16 15:53:19 - train: epoch 0067, iter [01800, 02526], lr: 0.000100, loss: 0.4074, CELoss: 0.4074, 
2022-10-16 15:53:53 - train: epoch 0067, iter [01900, 02526], lr: 0.000100, loss: 0.4865, CELoss: 0.4865, 
2022-10-16 15:54:26 - train: epoch 0067, iter [02000, 02526], lr: 0.000100, loss: 0.6205, CELoss: 0.6205, 
2022-10-16 15:55:00 - train: epoch 0067, iter [02100, 02526], lr: 0.000100, loss: 0.5273, CELoss: 0.5273, 
2022-10-16 15:55:33 - train: epoch 0067, iter [02200, 02526], lr: 0.000100, loss: 0.5047, CELoss: 0.5047, 
2022-10-16 15:56:06 - train: epoch 0067, iter [02300, 02526], lr: 0.000100, loss: 0.3817, CELoss: 0.3817, 
2022-10-16 15:56:40 - train: epoch 0067, iter [02400, 02526], lr: 0.000100, loss: 0.3591, CELoss: 0.3591, 
2022-10-16 15:57:13 - train: epoch 0067, iter [02500, 02526], lr: 0.000100, loss: 0.2296, CELoss: 0.2296, 
2022-10-16 15:57:23 - train: epoch 067, train_loss: 0.4793
2022-10-16 15:57:25 - until epoch: 067, best_metric: 35.720%
2022-10-16 15:57:25 - epoch 068 lr: 0.000100
2022-10-16 15:58:01 - train: epoch 0068, iter [00100, 02526], lr: 0.000100, loss: 0.4536, CELoss: 0.4536, 
2022-10-16 15:58:34 - train: epoch 0068, iter [00200, 02526], lr: 0.000100, loss: 0.4222, CELoss: 0.4222, 
2022-10-16 15:59:08 - train: epoch 0068, iter [00300, 02526], lr: 0.000100, loss: 0.3985, CELoss: 0.3985, 
2022-10-16 15:59:41 - train: epoch 0068, iter [00400, 02526], lr: 0.000100, loss: 0.3515, CELoss: 0.3515, 
2022-10-16 16:00:15 - train: epoch 0068, iter [00500, 02526], lr: 0.000100, loss: 0.3694, CELoss: 0.3694, 
2022-10-16 16:00:48 - train: epoch 0068, iter [00600, 02526], lr: 0.000100, loss: 0.7790, CELoss: 0.7790, 
2022-10-16 16:01:22 - train: epoch 0068, iter [00700, 02526], lr: 0.000100, loss: 0.2769, CELoss: 0.2769, 
2022-10-16 16:01:55 - train: epoch 0068, iter [00800, 02526], lr: 0.000100, loss: 0.2830, CELoss: 0.2830, 
2022-10-16 16:02:29 - train: epoch 0068, iter [00900, 02526], lr: 0.000100, loss: 0.5743, CELoss: 0.5743, 
2022-10-16 16:03:03 - train: epoch 0068, iter [01000, 02526], lr: 0.000100, loss: 0.7080, CELoss: 0.7080, 
2022-10-16 16:03:36 - train: epoch 0068, iter [01100, 02526], lr: 0.000100, loss: 0.4906, CELoss: 0.4906, 
2022-10-16 16:04:10 - train: epoch 0068, iter [01200, 02526], lr: 0.000100, loss: 0.4917, CELoss: 0.4917, 
2022-10-16 16:04:43 - train: epoch 0068, iter [01300, 02526], lr: 0.000100, loss: 0.4664, CELoss: 0.4664, 
2022-10-16 16:05:17 - train: epoch 0068, iter [01400, 02526], lr: 0.000100, loss: 0.4659, CELoss: 0.4659, 
2022-10-16 16:05:50 - train: epoch 0068, iter [01500, 02526], lr: 0.000100, loss: 0.5863, CELoss: 0.5863, 
2022-10-16 16:06:23 - train: epoch 0068, iter [01600, 02526], lr: 0.000100, loss: 0.9334, CELoss: 0.9334, 
2022-10-16 16:06:57 - train: epoch 0068, iter [01700, 02526], lr: 0.000100, loss: 0.5068, CELoss: 0.5068, 
2022-10-16 16:07:31 - train: epoch 0068, iter [01800, 02526], lr: 0.000100, loss: 0.6921, CELoss: 0.6921, 
2022-10-16 16:08:05 - train: epoch 0068, iter [01900, 02526], lr: 0.000100, loss: 0.4114, CELoss: 0.4114, 
2022-10-16 16:08:38 - train: epoch 0068, iter [02000, 02526], lr: 0.000100, loss: 0.5148, CELoss: 0.5148, 
2022-10-16 16:09:11 - train: epoch 0068, iter [02100, 02526], lr: 0.000100, loss: 0.3378, CELoss: 0.3378, 
2022-10-16 16:09:45 - train: epoch 0068, iter [02200, 02526], lr: 0.000100, loss: 0.4286, CELoss: 0.4286, 
2022-10-16 16:10:19 - train: epoch 0068, iter [02300, 02526], lr: 0.000100, loss: 0.4769, CELoss: 0.4769, 
2022-10-16 16:10:52 - train: epoch 0068, iter [02400, 02526], lr: 0.000100, loss: 0.5125, CELoss: 0.5125, 
2022-10-16 16:11:25 - train: epoch 0068, iter [02500, 02526], lr: 0.000100, loss: 0.2438, CELoss: 0.2438, 
2022-10-16 16:11:36 - train: epoch 068, train_loss: 0.4752
2022-10-16 16:11:37 - until epoch: 068, best_metric: 35.720%
2022-10-16 16:11:37 - epoch 069 lr: 0.000100
2022-10-16 16:12:13 - train: epoch 0069, iter [00100, 02526], lr: 0.000100, loss: 0.2979, CELoss: 0.2979, 
2022-10-16 16:12:47 - train: epoch 0069, iter [00200, 02526], lr: 0.000100, loss: 0.3345, CELoss: 0.3345, 
2022-10-16 16:13:21 - train: epoch 0069, iter [00300, 02526], lr: 0.000100, loss: 0.3557, CELoss: 0.3557, 
2022-10-16 16:13:54 - train: epoch 0069, iter [00400, 02526], lr: 0.000100, loss: 0.3394, CELoss: 0.3394, 
2022-10-16 16:14:28 - train: epoch 0069, iter [00500, 02526], lr: 0.000100, loss: 0.3876, CELoss: 0.3876, 
2022-10-16 16:15:01 - train: epoch 0069, iter [00600, 02526], lr: 0.000100, loss: 0.4547, CELoss: 0.4547, 
2022-10-16 16:15:35 - train: epoch 0069, iter [00700, 02526], lr: 0.000100, loss: 0.3746, CELoss: 0.3746, 
2022-10-16 16:16:09 - train: epoch 0069, iter [00800, 02526], lr: 0.000100, loss: 0.3831, CELoss: 0.3831, 
2022-10-16 16:16:42 - train: epoch 0069, iter [00900, 02526], lr: 0.000100, loss: 0.6413, CELoss: 0.6413, 
2022-10-16 16:17:16 - train: epoch 0069, iter [01000, 02526], lr: 0.000100, loss: 0.3305, CELoss: 0.3305, 
2022-10-16 16:17:49 - train: epoch 0069, iter [01100, 02526], lr: 0.000100, loss: 0.5652, CELoss: 0.5652, 
2022-10-16 16:18:22 - train: epoch 0069, iter [01200, 02526], lr: 0.000100, loss: 0.3798, CELoss: 0.3798, 
2022-10-16 16:18:56 - train: epoch 0069, iter [01300, 02526], lr: 0.000100, loss: 0.5204, CELoss: 0.5204, 
2022-10-16 16:19:30 - train: epoch 0069, iter [01400, 02526], lr: 0.000100, loss: 0.4940, CELoss: 0.4940, 
2022-10-16 16:20:03 - train: epoch 0069, iter [01500, 02526], lr: 0.000100, loss: 0.3609, CELoss: 0.3609, 
2022-10-16 16:20:36 - train: epoch 0069, iter [01600, 02526], lr: 0.000100, loss: 0.6917, CELoss: 0.6917, 
2022-10-16 16:21:09 - train: epoch 0069, iter [01700, 02526], lr: 0.000100, loss: 0.3805, CELoss: 0.3805, 
2022-10-16 16:21:43 - train: epoch 0069, iter [01800, 02526], lr: 0.000100, loss: 0.4176, CELoss: 0.4176, 
2022-10-16 16:22:16 - train: epoch 0069, iter [01900, 02526], lr: 0.000100, loss: 0.3307, CELoss: 0.3307, 
2022-10-16 16:22:50 - train: epoch 0069, iter [02000, 02526], lr: 0.000100, loss: 0.6921, CELoss: 0.6921, 
2022-10-16 16:23:23 - train: epoch 0069, iter [02100, 02526], lr: 0.000100, loss: 0.4854, CELoss: 0.4854, 
2022-10-16 16:23:57 - train: epoch 0069, iter [02200, 02526], lr: 0.000100, loss: 0.5071, CELoss: 0.5071, 
2022-10-16 16:24:30 - train: epoch 0069, iter [02300, 02526], lr: 0.000100, loss: 0.4796, CELoss: 0.4796, 
2022-10-16 16:25:03 - train: epoch 0069, iter [02400, 02526], lr: 0.000100, loss: 0.6683, CELoss: 0.6683, 
2022-10-16 16:25:37 - train: epoch 0069, iter [02500, 02526], lr: 0.000100, loss: 0.2945, CELoss: 0.2945, 
2022-10-16 16:25:47 - train: epoch 069, train_loss: 0.4717
2022-10-16 16:25:49 - until epoch: 069, best_metric: 35.720%
2022-10-16 16:25:49 - epoch 070 lr: 0.000100
2022-10-16 16:26:25 - train: epoch 0070, iter [00100, 02526], lr: 0.000100, loss: 0.2415, CELoss: 0.2415, 
2022-10-16 16:26:58 - train: epoch 0070, iter [00200, 02526], lr: 0.000100, loss: 0.3360, CELoss: 0.3360, 
2022-10-16 16:27:31 - train: epoch 0070, iter [00300, 02526], lr: 0.000100, loss: 0.5062, CELoss: 0.5062, 
2022-10-16 16:28:05 - train: epoch 0070, iter [00400, 02526], lr: 0.000100, loss: 0.3278, CELoss: 0.3278, 
2022-10-16 16:28:38 - train: epoch 0070, iter [00500, 02526], lr: 0.000100, loss: 0.3738, CELoss: 0.3738, 
2022-10-16 16:29:12 - train: epoch 0070, iter [00600, 02526], lr: 0.000100, loss: 0.5098, CELoss: 0.5098, 
2022-10-16 16:29:45 - train: epoch 0070, iter [00700, 02526], lr: 0.000100, loss: 0.3168, CELoss: 0.3168, 
2022-10-16 16:30:19 - train: epoch 0070, iter [00800, 02526], lr: 0.000100, loss: 0.4025, CELoss: 0.4025, 
2022-10-16 16:30:52 - train: epoch 0070, iter [00900, 02526], lr: 0.000100, loss: 0.5152, CELoss: 0.5152, 
2022-10-16 16:31:26 - train: epoch 0070, iter [01000, 02526], lr: 0.000100, loss: 0.2883, CELoss: 0.2883, 
2022-10-16 16:31:59 - train: epoch 0070, iter [01100, 02526], lr: 0.000100, loss: 0.3150, CELoss: 0.3150, 
2022-10-16 16:32:32 - train: epoch 0070, iter [01200, 02526], lr: 0.000100, loss: 0.3201, CELoss: 0.3201, 
2022-10-16 16:33:06 - train: epoch 0070, iter [01300, 02526], lr: 0.000100, loss: 0.3815, CELoss: 0.3815, 
2022-10-16 16:33:40 - train: epoch 0070, iter [01400, 02526], lr: 0.000100, loss: 0.5264, CELoss: 0.5264, 
2022-10-16 16:34:13 - train: epoch 0070, iter [01500, 02526], lr: 0.000100, loss: 0.5070, CELoss: 0.5070, 
2022-10-16 16:34:47 - train: epoch 0070, iter [01600, 02526], lr: 0.000100, loss: 0.3193, CELoss: 0.3193, 
2022-10-16 16:35:20 - train: epoch 0070, iter [01700, 02526], lr: 0.000100, loss: 0.3494, CELoss: 0.3494, 
2022-10-16 16:35:54 - train: epoch 0070, iter [01800, 02526], lr: 0.000100, loss: 0.5673, CELoss: 0.5673, 
2022-10-16 16:36:27 - train: epoch 0070, iter [01900, 02526], lr: 0.000100, loss: 0.3511, CELoss: 0.3511, 
2022-10-16 16:37:01 - train: epoch 0070, iter [02000, 02526], lr: 0.000100, loss: 0.7481, CELoss: 0.7481, 
2022-10-16 16:37:34 - train: epoch 0070, iter [02100, 02526], lr: 0.000100, loss: 0.4009, CELoss: 0.4009, 
2022-10-16 16:38:07 - train: epoch 0070, iter [02200, 02526], lr: 0.000100, loss: 0.5907, CELoss: 0.5907, 
2022-10-16 16:38:41 - train: epoch 0070, iter [02300, 02526], lr: 0.000100, loss: 0.3496, CELoss: 0.3496, 
2022-10-16 16:39:14 - train: epoch 0070, iter [02400, 02526], lr: 0.000100, loss: 0.5829, CELoss: 0.5829, 
2022-10-16 16:39:47 - train: epoch 0070, iter [02500, 02526], lr: 0.000100, loss: 0.3756, CELoss: 0.3756, 
2022-10-16 16:39:57 - train: epoch 070, train_loss: 0.4697
2022-10-16 16:40:48 - eval: epoch: 070
test_loss: 0.937922927647829
per_image_load_time: 1.096ms
per_image_inference_time: 18.280ms
exist_num_class: 150.0
mean_precision: 56.74272380805809
mean_recall: 44.9215943319383
mean_iou: 35.101243727513605
mean_dice: 48.12820542363997

2022-10-16 16:40:50 - until epoch: 070, best_metric: 35.720%
2022-10-16 16:40:50 - epoch 071 lr: 0.000100
2022-10-16 16:41:26 - train: epoch 0071, iter [00100, 02526], lr: 0.000100, loss: 0.7451, CELoss: 0.7451, 
2022-10-16 16:42:00 - train: epoch 0071, iter [00200, 02526], lr: 0.000100, loss: 0.4107, CELoss: 0.4107, 
2022-10-16 16:42:33 - train: epoch 0071, iter [00300, 02526], lr: 0.000100, loss: 0.3699, CELoss: 0.3699, 
2022-10-16 16:43:07 - train: epoch 0071, iter [00400, 02526], lr: 0.000100, loss: 0.4359, CELoss: 0.4359, 
2022-10-16 16:43:40 - train: epoch 0071, iter [00500, 02526], lr: 0.000100, loss: 0.3149, CELoss: 0.3149, 
2022-10-16 16:44:14 - train: epoch 0071, iter [00600, 02526], lr: 0.000100, loss: 0.4543, CELoss: 0.4543, 
2022-10-16 16:44:47 - train: epoch 0071, iter [00700, 02526], lr: 0.000100, loss: 0.5129, CELoss: 0.5129, 
2022-10-16 16:45:21 - train: epoch 0071, iter [00800, 02526], lr: 0.000100, loss: 0.3133, CELoss: 0.3133, 
2022-10-16 16:45:54 - train: epoch 0071, iter [00900, 02526], lr: 0.000100, loss: 0.3901, CELoss: 0.3901, 
2022-10-16 16:46:28 - train: epoch 0071, iter [01000, 02526], lr: 0.000100, loss: 0.5173, CELoss: 0.5173, 
2022-10-16 16:47:02 - train: epoch 0071, iter [01100, 02526], lr: 0.000100, loss: 0.5862, CELoss: 0.5862, 
2022-10-16 16:47:35 - train: epoch 0071, iter [01200, 02526], lr: 0.000100, loss: 0.5662, CELoss: 0.5662, 
2022-10-16 16:48:08 - train: epoch 0071, iter [01300, 02526], lr: 0.000100, loss: 0.3773, CELoss: 0.3773, 
2022-10-16 16:48:42 - train: epoch 0071, iter [01400, 02526], lr: 0.000100, loss: 0.3010, CELoss: 0.3010, 
2022-10-16 16:49:16 - train: epoch 0071, iter [01500, 02526], lr: 0.000100, loss: 0.3040, CELoss: 0.3040, 
2022-10-16 16:49:50 - train: epoch 0071, iter [01600, 02526], lr: 0.000100, loss: 0.4335, CELoss: 0.4335, 
2022-10-16 16:50:23 - train: epoch 0071, iter [01700, 02526], lr: 0.000100, loss: 0.4801, CELoss: 0.4801, 
2022-10-16 16:50:56 - train: epoch 0071, iter [01800, 02526], lr: 0.000100, loss: 0.3518, CELoss: 0.3518, 
2022-10-16 16:51:30 - train: epoch 0071, iter [01900, 02526], lr: 0.000100, loss: 0.2917, CELoss: 0.2917, 
2022-10-16 16:52:03 - train: epoch 0071, iter [02000, 02526], lr: 0.000100, loss: 0.4760, CELoss: 0.4760, 
2022-10-16 16:52:37 - train: epoch 0071, iter [02100, 02526], lr: 0.000100, loss: 0.4942, CELoss: 0.4942, 
2022-10-16 16:53:10 - train: epoch 0071, iter [02200, 02526], lr: 0.000100, loss: 0.5318, CELoss: 0.5318, 
2022-10-16 16:53:43 - train: epoch 0071, iter [02300, 02526], lr: 0.000100, loss: 0.5096, CELoss: 0.5096, 
2022-10-16 16:54:17 - train: epoch 0071, iter [02400, 02526], lr: 0.000100, loss: 0.3580, CELoss: 0.3580, 
2022-10-16 16:54:50 - train: epoch 0071, iter [02500, 02526], lr: 0.000100, loss: 0.5831, CELoss: 0.5831, 
2022-10-16 16:55:00 - train: epoch 071, train_loss: 0.4673
2022-10-16 16:55:02 - until epoch: 071, best_metric: 35.720%
2022-10-16 16:55:02 - epoch 072 lr: 0.000100
2022-10-16 16:55:38 - train: epoch 0072, iter [00100, 02526], lr: 0.000100, loss: 0.2311, CELoss: 0.2311, 
2022-10-16 16:56:12 - train: epoch 0072, iter [00200, 02526], lr: 0.000100, loss: 0.4557, CELoss: 0.4557, 
2022-10-16 16:56:45 - train: epoch 0072, iter [00300, 02526], lr: 0.000100, loss: 0.4878, CELoss: 0.4878, 
2022-10-16 16:57:19 - train: epoch 0072, iter [00400, 02526], lr: 0.000100, loss: 0.4923, CELoss: 0.4923, 
2022-10-16 16:57:52 - train: epoch 0072, iter [00500, 02526], lr: 0.000100, loss: 0.4844, CELoss: 0.4844, 
2022-10-16 16:58:26 - train: epoch 0072, iter [00600, 02526], lr: 0.000100, loss: 0.5620, CELoss: 0.5620, 
2022-10-16 16:58:59 - train: epoch 0072, iter [00700, 02526], lr: 0.000100, loss: 0.4319, CELoss: 0.4319, 
2022-10-16 16:59:33 - train: epoch 0072, iter [00800, 02526], lr: 0.000100, loss: 0.4120, CELoss: 0.4120, 
2022-10-16 17:00:06 - train: epoch 0072, iter [00900, 02526], lr: 0.000100, loss: 0.6605, CELoss: 0.6605, 
2022-10-16 17:00:40 - train: epoch 0072, iter [01000, 02526], lr: 0.000100, loss: 0.4133, CELoss: 0.4133, 
2022-10-16 17:01:13 - train: epoch 0072, iter [01100, 02526], lr: 0.000100, loss: 0.2986, CELoss: 0.2986, 
2022-10-16 17:01:47 - train: epoch 0072, iter [01200, 02526], lr: 0.000100, loss: 0.5495, CELoss: 0.5495, 
2022-10-16 17:02:20 - train: epoch 0072, iter [01300, 02526], lr: 0.000100, loss: 0.5439, CELoss: 0.5439, 
2022-10-16 17:02:53 - train: epoch 0072, iter [01400, 02526], lr: 0.000100, loss: 0.5989, CELoss: 0.5989, 
2022-10-16 17:03:27 - train: epoch 0072, iter [01500, 02526], lr: 0.000100, loss: 0.5784, CELoss: 0.5784, 
2022-10-16 17:04:01 - train: epoch 0072, iter [01600, 02526], lr: 0.000100, loss: 0.3205, CELoss: 0.3205, 
2022-10-16 17:04:34 - train: epoch 0072, iter [01700, 02526], lr: 0.000100, loss: 0.3313, CELoss: 0.3313, 
2022-10-16 17:05:08 - train: epoch 0072, iter [01800, 02526], lr: 0.000100, loss: 0.4258, CELoss: 0.4258, 
2022-10-16 17:05:42 - train: epoch 0072, iter [01900, 02526], lr: 0.000100, loss: 0.3393, CELoss: 0.3393, 
2022-10-16 17:06:15 - train: epoch 0072, iter [02000, 02526], lr: 0.000100, loss: 0.4951, CELoss: 0.4951, 
2022-10-16 17:06:49 - train: epoch 0072, iter [02100, 02526], lr: 0.000100, loss: 0.4930, CELoss: 0.4930, 
2022-10-16 17:07:23 - train: epoch 0072, iter [02200, 02526], lr: 0.000100, loss: 0.4309, CELoss: 0.4309, 
2022-10-16 17:07:56 - train: epoch 0072, iter [02300, 02526], lr: 0.000100, loss: 0.3719, CELoss: 0.3719, 
2022-10-16 17:08:30 - train: epoch 0072, iter [02400, 02526], lr: 0.000100, loss: 0.4643, CELoss: 0.4643, 
2022-10-16 17:09:03 - train: epoch 0072, iter [02500, 02526], lr: 0.000100, loss: 0.4827, CELoss: 0.4827, 
2022-10-16 17:09:13 - train: epoch 072, train_loss: 0.4625
2022-10-16 17:09:15 - until epoch: 072, best_metric: 35.720%
2022-10-16 17:09:15 - epoch 073 lr: 0.000100
2022-10-16 17:09:51 - train: epoch 0073, iter [00100, 02526], lr: 0.000100, loss: 0.4005, CELoss: 0.4005, 
2022-10-16 17:10:25 - train: epoch 0073, iter [00200, 02526], lr: 0.000100, loss: 0.5267, CELoss: 0.5267, 
2022-10-16 17:10:58 - train: epoch 0073, iter [00300, 02526], lr: 0.000100, loss: 0.4104, CELoss: 0.4104, 
2022-10-16 17:11:31 - train: epoch 0073, iter [00400, 02526], lr: 0.000100, loss: 0.3108, CELoss: 0.3108, 
2022-10-16 17:12:05 - train: epoch 0073, iter [00500, 02526], lr: 0.000100, loss: 0.4002, CELoss: 0.4002, 
2022-10-16 17:12:39 - train: epoch 0073, iter [00600, 02526], lr: 0.000100, loss: 0.2753, CELoss: 0.2753, 
2022-10-16 17:13:13 - train: epoch 0073, iter [00700, 02526], lr: 0.000100, loss: 0.6447, CELoss: 0.6447, 
2022-10-16 17:13:46 - train: epoch 0073, iter [00800, 02526], lr: 0.000100, loss: 0.4688, CELoss: 0.4688, 
2022-10-16 17:14:20 - train: epoch 0073, iter [00900, 02526], lr: 0.000100, loss: 0.3971, CELoss: 0.3971, 
2022-10-16 17:14:53 - train: epoch 0073, iter [01000, 02526], lr: 0.000100, loss: 0.3794, CELoss: 0.3794, 
2022-10-16 17:15:27 - train: epoch 0073, iter [01100, 02526], lr: 0.000100, loss: 0.7849, CELoss: 0.7849, 
2022-10-16 17:16:01 - train: epoch 0073, iter [01200, 02526], lr: 0.000100, loss: 0.6522, CELoss: 0.6522, 
2022-10-16 17:16:34 - train: epoch 0073, iter [01300, 02526], lr: 0.000100, loss: 0.3365, CELoss: 0.3365, 
2022-10-16 17:17:07 - train: epoch 0073, iter [01400, 02526], lr: 0.000100, loss: 0.4381, CELoss: 0.4381, 
2022-10-16 17:17:41 - train: epoch 0073, iter [01500, 02526], lr: 0.000100, loss: 0.3158, CELoss: 0.3158, 
2022-10-16 17:18:14 - train: epoch 0073, iter [01600, 02526], lr: 0.000100, loss: 0.6976, CELoss: 0.6976, 
2022-10-16 17:18:48 - train: epoch 0073, iter [01700, 02526], lr: 0.000100, loss: 0.4186, CELoss: 0.4186, 
2022-10-16 17:19:22 - train: epoch 0073, iter [01800, 02526], lr: 0.000100, loss: 0.8928, CELoss: 0.8928, 
2022-10-16 17:19:55 - train: epoch 0073, iter [01900, 02526], lr: 0.000100, loss: 0.5824, CELoss: 0.5824, 
2022-10-16 17:20:29 - train: epoch 0073, iter [02000, 02526], lr: 0.000100, loss: 0.3307, CELoss: 0.3307, 
2022-10-16 17:21:02 - train: epoch 0073, iter [02100, 02526], lr: 0.000100, loss: 0.6806, CELoss: 0.6806, 
2022-10-16 17:21:36 - train: epoch 0073, iter [02200, 02526], lr: 0.000100, loss: 0.3196, CELoss: 0.3196, 
2022-10-16 17:22:09 - train: epoch 0073, iter [02300, 02526], lr: 0.000100, loss: 0.3812, CELoss: 0.3812, 
2022-10-16 17:22:43 - train: epoch 0073, iter [02400, 02526], lr: 0.000100, loss: 0.2171, CELoss: 0.2171, 
2022-10-16 17:23:16 - train: epoch 0073, iter [02500, 02526], lr: 0.000100, loss: 0.3632, CELoss: 0.3632, 
2022-10-16 17:23:26 - train: epoch 073, train_loss: 0.4630
2022-10-16 17:23:27 - until epoch: 073, best_metric: 35.720%
2022-10-16 17:23:27 - epoch 074 lr: 0.000100
2022-10-16 17:24:03 - train: epoch 0074, iter [00100, 02526], lr: 0.000100, loss: 0.2956, CELoss: 0.2956, 
2022-10-16 17:24:37 - train: epoch 0074, iter [00200, 02526], lr: 0.000100, loss: 0.4091, CELoss: 0.4091, 
2022-10-16 17:25:10 - train: epoch 0074, iter [00300, 02526], lr: 0.000100, loss: 0.5167, CELoss: 0.5167, 
2022-10-16 17:25:44 - train: epoch 0074, iter [00400, 02526], lr: 0.000100, loss: 0.8155, CELoss: 0.8155, 
2022-10-16 17:26:17 - train: epoch 0074, iter [00500, 02526], lr: 0.000100, loss: 0.3977, CELoss: 0.3977, 
2022-10-16 17:26:51 - train: epoch 0074, iter [00600, 02526], lr: 0.000100, loss: 0.4141, CELoss: 0.4141, 
2022-10-16 17:27:24 - train: epoch 0074, iter [00700, 02526], lr: 0.000100, loss: 0.4423, CELoss: 0.4423, 
2022-10-16 17:27:58 - train: epoch 0074, iter [00800, 02526], lr: 0.000100, loss: 0.6928, CELoss: 0.6928, 
2022-10-16 17:28:31 - train: epoch 0074, iter [00900, 02526], lr: 0.000100, loss: 0.4716, CELoss: 0.4716, 
2022-10-16 17:29:05 - train: epoch 0074, iter [01000, 02526], lr: 0.000100, loss: 0.2959, CELoss: 0.2959, 
2022-10-16 17:29:38 - train: epoch 0074, iter [01100, 02526], lr: 0.000100, loss: 0.6135, CELoss: 0.6135, 
2022-10-16 17:30:12 - train: epoch 0074, iter [01200, 02526], lr: 0.000100, loss: 0.5621, CELoss: 0.5621, 
2022-10-16 17:30:45 - train: epoch 0074, iter [01300, 02526], lr: 0.000100, loss: 0.4622, CELoss: 0.4622, 
2022-10-16 17:31:19 - train: epoch 0074, iter [01400, 02526], lr: 0.000100, loss: 0.3513, CELoss: 0.3513, 
2022-10-16 17:31:53 - train: epoch 0074, iter [01500, 02526], lr: 0.000100, loss: 0.3382, CELoss: 0.3382, 
2022-10-16 17:32:26 - train: epoch 0074, iter [01600, 02526], lr: 0.000100, loss: 0.4829, CELoss: 0.4829, 
2022-10-16 17:33:00 - train: epoch 0074, iter [01700, 02526], lr: 0.000100, loss: 0.4761, CELoss: 0.4761, 
2022-10-16 17:33:33 - train: epoch 0074, iter [01800, 02526], lr: 0.000100, loss: 0.3303, CELoss: 0.3303, 
2022-10-16 17:34:07 - train: epoch 0074, iter [01900, 02526], lr: 0.000100, loss: 0.4668, CELoss: 0.4668, 
2022-10-16 17:34:40 - train: epoch 0074, iter [02000, 02526], lr: 0.000100, loss: 0.5159, CELoss: 0.5159, 
2022-10-16 17:35:14 - train: epoch 0074, iter [02100, 02526], lr: 0.000100, loss: 0.5309, CELoss: 0.5309, 
2022-10-16 17:35:47 - train: epoch 0074, iter [02200, 02526], lr: 0.000100, loss: 0.4750, CELoss: 0.4750, 
2022-10-16 17:36:20 - train: epoch 0074, iter [02300, 02526], lr: 0.000100, loss: 0.4481, CELoss: 0.4481, 
2022-10-16 17:36:54 - train: epoch 0074, iter [02400, 02526], lr: 0.000100, loss: 0.4015, CELoss: 0.4015, 
2022-10-16 17:37:27 - train: epoch 0074, iter [02500, 02526], lr: 0.000100, loss: 0.4327, CELoss: 0.4327, 
2022-10-16 17:37:38 - train: epoch 074, train_loss: 0.4479
2022-10-16 17:37:39 - until epoch: 074, best_metric: 35.720%
2022-10-16 17:37:39 - epoch 075 lr: 0.000100
2022-10-16 17:38:15 - train: epoch 0075, iter [00100, 02526], lr: 0.000100, loss: 0.3966, CELoss: 0.3966, 
2022-10-16 17:38:49 - train: epoch 0075, iter [00200, 02526], lr: 0.000100, loss: 0.2224, CELoss: 0.2224, 
2022-10-16 17:39:22 - train: epoch 0075, iter [00300, 02526], lr: 0.000100, loss: 0.4482, CELoss: 0.4482, 
2022-10-16 17:39:56 - train: epoch 0075, iter [00400, 02526], lr: 0.000100, loss: 0.3675, CELoss: 0.3675, 
2022-10-16 17:40:29 - train: epoch 0075, iter [00500, 02526], lr: 0.000100, loss: 0.2899, CELoss: 0.2899, 
2022-10-16 17:41:03 - train: epoch 0075, iter [00600, 02526], lr: 0.000100, loss: 0.5014, CELoss: 0.5014, 
2022-10-16 17:41:37 - train: epoch 0075, iter [00700, 02526], lr: 0.000100, loss: 0.5558, CELoss: 0.5558, 
2022-10-16 17:42:11 - train: epoch 0075, iter [00800, 02526], lr: 0.000100, loss: 0.4086, CELoss: 0.4086, 
2022-10-16 17:42:44 - train: epoch 0075, iter [00900, 02526], lr: 0.000100, loss: 0.5941, CELoss: 0.5941, 
2022-10-16 17:43:18 - train: epoch 0075, iter [01000, 02526], lr: 0.000100, loss: 0.6246, CELoss: 0.6246, 
2022-10-16 17:43:51 - train: epoch 0075, iter [01100, 02526], lr: 0.000100, loss: 0.3750, CELoss: 0.3750, 
2022-10-16 17:44:25 - train: epoch 0075, iter [01200, 02526], lr: 0.000100, loss: 0.3807, CELoss: 0.3807, 
2022-10-16 17:44:58 - train: epoch 0075, iter [01300, 02526], lr: 0.000100, loss: 0.5825, CELoss: 0.5825, 
2022-10-16 17:45:31 - train: epoch 0075, iter [01400, 02526], lr: 0.000100, loss: 0.9412, CELoss: 0.9412, 
2022-10-16 17:46:05 - train: epoch 0075, iter [01500, 02526], lr: 0.000100, loss: 0.4089, CELoss: 0.4089, 
2022-10-16 17:46:38 - train: epoch 0075, iter [01600, 02526], lr: 0.000100, loss: 0.3632, CELoss: 0.3632, 
2022-10-16 17:47:11 - train: epoch 0075, iter [01700, 02526], lr: 0.000100, loss: 0.2920, CELoss: 0.2920, 
2022-10-16 17:47:45 - train: epoch 0075, iter [01800, 02526], lr: 0.000100, loss: 0.3828, CELoss: 0.3828, 
2022-10-16 17:48:18 - train: epoch 0075, iter [01900, 02526], lr: 0.000100, loss: 0.4173, CELoss: 0.4173, 
2022-10-16 17:48:52 - train: epoch 0075, iter [02000, 02526], lr: 0.000100, loss: 0.2770, CELoss: 0.2770, 
2022-10-16 17:49:25 - train: epoch 0075, iter [02100, 02526], lr: 0.000100, loss: 0.3686, CELoss: 0.3686, 
2022-10-16 17:49:59 - train: epoch 0075, iter [02200, 02526], lr: 0.000100, loss: 0.2682, CELoss: 0.2682, 
2022-10-16 17:50:32 - train: epoch 0075, iter [02300, 02526], lr: 0.000100, loss: 0.4204, CELoss: 0.4204, 
2022-10-16 17:51:06 - train: epoch 0075, iter [02400, 02526], lr: 0.000100, loss: 0.4107, CELoss: 0.4107, 
2022-10-16 17:51:39 - train: epoch 0075, iter [02500, 02526], lr: 0.000100, loss: 0.4636, CELoss: 0.4636, 
2022-10-16 17:51:49 - train: epoch 075, train_loss: 0.4666
2022-10-16 17:52:40 - eval: epoch: 075
test_loss: 0.9171721959710121
per_image_load_time: 1.018ms
per_image_inference_time: 18.323ms
exist_num_class: 150.0
mean_precision: 56.244012435978924
mean_recall: 47.65931319776518
mean_iou: 36.19717147553831
mean_dice: 49.6493094567524

2022-10-16 17:52:43 - until epoch: 075, best_metric: 36.197%
2022-10-16 17:52:43 - epoch 076 lr: 0.000100
2022-10-16 17:53:19 - train: epoch 0076, iter [00100, 02526], lr: 0.000100, loss: 0.3505, CELoss: 0.3505, 
2022-10-16 17:53:52 - train: epoch 0076, iter [00200, 02526], lr: 0.000100, loss: 0.4381, CELoss: 0.4381, 
2022-10-16 17:54:26 - train: epoch 0076, iter [00300, 02526], lr: 0.000100, loss: 0.4966, CELoss: 0.4966, 
2022-10-16 17:54:59 - train: epoch 0076, iter [00400, 02526], lr: 0.000100, loss: 0.3016, CELoss: 0.3016, 
2022-10-16 17:55:33 - train: epoch 0076, iter [00500, 02526], lr: 0.000100, loss: 0.5998, CELoss: 0.5998, 
2022-10-16 17:56:06 - train: epoch 0076, iter [00600, 02526], lr: 0.000100, loss: 0.4167, CELoss: 0.4167, 
2022-10-16 17:56:40 - train: epoch 0076, iter [00700, 02526], lr: 0.000100, loss: 0.7384, CELoss: 0.7384, 
2022-10-16 17:57:13 - train: epoch 0076, iter [00800, 02526], lr: 0.000100, loss: 0.7430, CELoss: 0.7430, 
2022-10-16 17:57:47 - train: epoch 0076, iter [00900, 02526], lr: 0.000100, loss: 0.3710, CELoss: 0.3710, 
2022-10-16 17:58:20 - train: epoch 0076, iter [01000, 02526], lr: 0.000100, loss: 0.2768, CELoss: 0.2768, 
2022-10-16 17:58:53 - train: epoch 0076, iter [01100, 02526], lr: 0.000100, loss: 0.4307, CELoss: 0.4307, 
2022-10-16 17:59:27 - train: epoch 0076, iter [01200, 02526], lr: 0.000100, loss: 0.2611, CELoss: 0.2611, 
2022-10-16 18:00:00 - train: epoch 0076, iter [01300, 02526], lr: 0.000100, loss: 0.4744, CELoss: 0.4744, 
2022-10-16 18:00:34 - train: epoch 0076, iter [01400, 02526], lr: 0.000100, loss: 0.2418, CELoss: 0.2418, 
2022-10-16 18:01:07 - train: epoch 0076, iter [01500, 02526], lr: 0.000100, loss: 0.2857, CELoss: 0.2857, 
2022-10-16 18:01:40 - train: epoch 0076, iter [01600, 02526], lr: 0.000100, loss: 0.3565, CELoss: 0.3565, 
2022-10-16 18:02:13 - train: epoch 0076, iter [01700, 02526], lr: 0.000100, loss: 0.8291, CELoss: 0.8291, 
2022-10-16 18:02:47 - train: epoch 0076, iter [01800, 02526], lr: 0.000100, loss: 0.7971, CELoss: 0.7971, 
2022-10-16 18:03:20 - train: epoch 0076, iter [01900, 02526], lr: 0.000100, loss: 0.3582, CELoss: 0.3582, 
2022-10-16 18:03:54 - train: epoch 0076, iter [02000, 02526], lr: 0.000100, loss: 0.2899, CELoss: 0.2899, 
2022-10-16 18:04:27 - train: epoch 0076, iter [02100, 02526], lr: 0.000100, loss: 0.3024, CELoss: 0.3024, 
2022-10-16 18:05:00 - train: epoch 0076, iter [02200, 02526], lr: 0.000100, loss: 0.3998, CELoss: 0.3998, 
2022-10-16 18:05:34 - train: epoch 0076, iter [02300, 02526], lr: 0.000100, loss: 0.4897, CELoss: 0.4897, 
2022-10-16 18:06:07 - train: epoch 0076, iter [02400, 02526], lr: 0.000100, loss: 0.2972, CELoss: 0.2972, 
2022-10-16 18:06:41 - train: epoch 0076, iter [02500, 02526], lr: 0.000100, loss: 0.3246, CELoss: 0.3246, 
2022-10-16 18:06:51 - train: epoch 076, train_loss: 0.4522
2022-10-16 18:06:54 - until epoch: 076, best_metric: 36.197%
2022-10-16 18:06:54 - epoch 077 lr: 0.000100
2022-10-16 18:07:29 - train: epoch 0077, iter [00100, 02526], lr: 0.000100, loss: 0.4263, CELoss: 0.4263, 
2022-10-16 18:08:02 - train: epoch 0077, iter [00200, 02526], lr: 0.000100, loss: 0.4735, CELoss: 0.4735, 
2022-10-16 18:08:36 - train: epoch 0077, iter [00300, 02526], lr: 0.000100, loss: 0.4006, CELoss: 0.4006, 
2022-10-16 18:09:09 - train: epoch 0077, iter [00400, 02526], lr: 0.000100, loss: 0.4032, CELoss: 0.4032, 
2022-10-16 18:09:42 - train: epoch 0077, iter [00500, 02526], lr: 0.000100, loss: 0.3961, CELoss: 0.3961, 
2022-10-16 18:10:16 - train: epoch 0077, iter [00600, 02526], lr: 0.000100, loss: 0.6995, CELoss: 0.6995, 
2022-10-16 18:10:50 - train: epoch 0077, iter [00700, 02526], lr: 0.000100, loss: 0.4056, CELoss: 0.4056, 
2022-10-16 18:11:23 - train: epoch 0077, iter [00800, 02526], lr: 0.000100, loss: 0.1677, CELoss: 0.1677, 
2022-10-16 18:11:57 - train: epoch 0077, iter [00900, 02526], lr: 0.000100, loss: 0.4771, CELoss: 0.4771, 
2022-10-16 18:12:30 - train: epoch 0077, iter [01000, 02526], lr: 0.000100, loss: 0.6260, CELoss: 0.6260, 
2022-10-16 18:13:04 - train: epoch 0077, iter [01100, 02526], lr: 0.000100, loss: 0.7084, CELoss: 0.7084, 
2022-10-16 18:13:38 - train: epoch 0077, iter [01200, 02526], lr: 0.000100, loss: 0.3160, CELoss: 0.3160, 
2022-10-16 18:14:12 - train: epoch 0077, iter [01300, 02526], lr: 0.000100, loss: 0.3129, CELoss: 0.3129, 
2022-10-16 18:14:45 - train: epoch 0077, iter [01400, 02526], lr: 0.000100, loss: 0.3651, CELoss: 0.3651, 
2022-10-16 18:15:19 - train: epoch 0077, iter [01500, 02526], lr: 0.000100, loss: 0.2858, CELoss: 0.2858, 
2022-10-16 18:15:53 - train: epoch 0077, iter [01600, 02526], lr: 0.000100, loss: 0.4332, CELoss: 0.4332, 
2022-10-16 18:16:27 - train: epoch 0077, iter [01700, 02526], lr: 0.000100, loss: 0.7424, CELoss: 0.7424, 
2022-10-16 18:17:01 - train: epoch 0077, iter [01800, 02526], lr: 0.000100, loss: 0.4395, CELoss: 0.4395, 
2022-10-16 18:17:35 - train: epoch 0077, iter [01900, 02526], lr: 0.000100, loss: 0.4856, CELoss: 0.4856, 
2022-10-16 18:18:08 - train: epoch 0077, iter [02000, 02526], lr: 0.000100, loss: 0.4470, CELoss: 0.4470, 
2022-10-16 18:18:42 - train: epoch 0077, iter [02100, 02526], lr: 0.000100, loss: 0.4204, CELoss: 0.4204, 
2022-10-16 18:19:16 - train: epoch 0077, iter [02200, 02526], lr: 0.000100, loss: 0.5073, CELoss: 0.5073, 
2022-10-16 18:19:49 - train: epoch 0077, iter [02300, 02526], lr: 0.000100, loss: 0.7021, CELoss: 0.7021, 
2022-10-16 18:20:23 - train: epoch 0077, iter [02400, 02526], lr: 0.000100, loss: 0.3627, CELoss: 0.3627, 
2022-10-16 18:20:57 - train: epoch 0077, iter [02500, 02526], lr: 0.000100, loss: 0.3536, CELoss: 0.3536, 
2022-10-16 18:21:07 - train: epoch 077, train_loss: 0.4476
2022-10-16 18:21:09 - until epoch: 077, best_metric: 36.197%
2022-10-16 18:21:09 - epoch 078 lr: 0.000100
2022-10-16 18:21:45 - train: epoch 0078, iter [00100, 02526], lr: 0.000100, loss: 0.3970, CELoss: 0.3970, 
2022-10-16 18:22:19 - train: epoch 0078, iter [00200, 02526], lr: 0.000100, loss: 0.3205, CELoss: 0.3205, 
2022-10-16 18:22:53 - train: epoch 0078, iter [00300, 02526], lr: 0.000100, loss: 0.4268, CELoss: 0.4268, 
2022-10-16 18:23:27 - train: epoch 0078, iter [00400, 02526], lr: 0.000100, loss: 0.3602, CELoss: 0.3602, 
2022-10-16 18:24:01 - train: epoch 0078, iter [00500, 02526], lr: 0.000100, loss: 0.3892, CELoss: 0.3892, 
2022-10-16 18:24:35 - train: epoch 0078, iter [00600, 02526], lr: 0.000100, loss: 0.2935, CELoss: 0.2935, 
2022-10-16 18:25:08 - train: epoch 0078, iter [00700, 02526], lr: 0.000100, loss: 0.4551, CELoss: 0.4551, 
2022-10-16 18:25:42 - train: epoch 0078, iter [00800, 02526], lr: 0.000100, loss: 0.5164, CELoss: 0.5164, 
2022-10-16 18:26:16 - train: epoch 0078, iter [00900, 02526], lr: 0.000100, loss: 0.3144, CELoss: 0.3144, 
2022-10-16 18:26:50 - train: epoch 0078, iter [01000, 02526], lr: 0.000100, loss: 0.5867, CELoss: 0.5867, 
2022-10-16 18:27:24 - train: epoch 0078, iter [01100, 02526], lr: 0.000100, loss: 0.4570, CELoss: 0.4570, 
2022-10-16 18:27:57 - train: epoch 0078, iter [01200, 02526], lr: 0.000100, loss: 0.5008, CELoss: 0.5008, 
2022-10-16 18:28:32 - train: epoch 0078, iter [01300, 02526], lr: 0.000100, loss: 0.5414, CELoss: 0.5414, 
2022-10-16 18:29:05 - train: epoch 0078, iter [01400, 02526], lr: 0.000100, loss: 0.5713, CELoss: 0.5713, 
2022-10-16 18:29:39 - train: epoch 0078, iter [01500, 02526], lr: 0.000100, loss: 0.3081, CELoss: 0.3081, 
2022-10-16 18:30:13 - train: epoch 0078, iter [01600, 02526], lr: 0.000100, loss: 0.3650, CELoss: 0.3650, 
2022-10-16 18:30:47 - train: epoch 0078, iter [01700, 02526], lr: 0.000100, loss: 0.4800, CELoss: 0.4800, 
2022-10-16 18:31:21 - train: epoch 0078, iter [01800, 02526], lr: 0.000100, loss: 0.5157, CELoss: 0.5157, 
2022-10-16 18:31:55 - train: epoch 0078, iter [01900, 02526], lr: 0.000100, loss: 0.5234, CELoss: 0.5234, 
2022-10-16 18:32:29 - train: epoch 0078, iter [02000, 02526], lr: 0.000100, loss: 0.8884, CELoss: 0.8884, 
2022-10-16 18:33:03 - train: epoch 0078, iter [02100, 02526], lr: 0.000100, loss: 0.5111, CELoss: 0.5111, 
2022-10-16 18:33:36 - train: epoch 0078, iter [02200, 02526], lr: 0.000100, loss: 0.3941, CELoss: 0.3941, 
2022-10-16 18:34:10 - train: epoch 0078, iter [02300, 02526], lr: 0.000100, loss: 0.3459, CELoss: 0.3459, 
2022-10-16 18:34:43 - train: epoch 0078, iter [02400, 02526], lr: 0.000100, loss: 0.5576, CELoss: 0.5576, 
2022-10-16 18:35:17 - train: epoch 0078, iter [02500, 02526], lr: 0.000100, loss: 0.5072, CELoss: 0.5072, 
2022-10-16 18:35:27 - train: epoch 078, train_loss: 0.4444
2022-10-16 18:35:30 - until epoch: 078, best_metric: 36.197%
2022-10-16 18:35:30 - epoch 079 lr: 0.000100
2022-10-16 18:36:06 - train: epoch 0079, iter [00100, 02526], lr: 0.000100, loss: 0.2989, CELoss: 0.2989, 
2022-10-16 18:36:39 - train: epoch 0079, iter [00200, 02526], lr: 0.000100, loss: 0.4406, CELoss: 0.4406, 
2022-10-16 18:37:13 - train: epoch 0079, iter [00300, 02526], lr: 0.000100, loss: 0.3268, CELoss: 0.3268, 
2022-10-16 18:37:47 - train: epoch 0079, iter [00400, 02526], lr: 0.000100, loss: 0.3058, CELoss: 0.3058, 
2022-10-16 18:38:21 - train: epoch 0079, iter [00500, 02526], lr: 0.000100, loss: 0.2983, CELoss: 0.2983, 
2022-10-16 18:38:55 - train: epoch 0079, iter [00600, 02526], lr: 0.000100, loss: 0.4216, CELoss: 0.4216, 
2022-10-16 18:39:28 - train: epoch 0079, iter [00700, 02526], lr: 0.000100, loss: 0.3099, CELoss: 0.3099, 
2022-10-16 18:40:02 - train: epoch 0079, iter [00800, 02526], lr: 0.000100, loss: 0.6019, CELoss: 0.6019, 
2022-10-16 18:40:36 - train: epoch 0079, iter [00900, 02526], lr: 0.000100, loss: 0.3670, CELoss: 0.3670, 
2022-10-16 18:41:10 - train: epoch 0079, iter [01000, 02526], lr: 0.000100, loss: 0.4184, CELoss: 0.4184, 
2022-10-16 18:41:44 - train: epoch 0079, iter [01100, 02526], lr: 0.000100, loss: 0.4575, CELoss: 0.4575, 
2022-10-16 18:42:17 - train: epoch 0079, iter [01200, 02526], lr: 0.000100, loss: 0.6226, CELoss: 0.6226, 
2022-10-16 18:42:51 - train: epoch 0079, iter [01300, 02526], lr: 0.000100, loss: 0.4270, CELoss: 0.4270, 
2022-10-16 18:43:25 - train: epoch 0079, iter [01400, 02526], lr: 0.000100, loss: 0.5034, CELoss: 0.5034, 
2022-10-16 18:43:59 - train: epoch 0079, iter [01500, 02526], lr: 0.000100, loss: 0.3400, CELoss: 0.3400, 
2022-10-16 18:44:33 - train: epoch 0079, iter [01600, 02526], lr: 0.000100, loss: 0.6862, CELoss: 0.6862, 
2022-10-16 18:45:07 - train: epoch 0079, iter [01700, 02526], lr: 0.000100, loss: 0.4421, CELoss: 0.4421, 
2022-10-16 18:45:41 - train: epoch 0079, iter [01800, 02526], lr: 0.000100, loss: 0.6638, CELoss: 0.6638, 
2022-10-16 18:46:14 - train: epoch 0079, iter [01900, 02526], lr: 0.000100, loss: 0.4407, CELoss: 0.4407, 
2022-10-16 18:46:48 - train: epoch 0079, iter [02000, 02526], lr: 0.000100, loss: 0.5212, CELoss: 0.5212, 
2022-10-16 18:47:22 - train: epoch 0079, iter [02100, 02526], lr: 0.000100, loss: 0.5852, CELoss: 0.5852, 
2022-10-16 18:47:56 - train: epoch 0079, iter [02200, 02526], lr: 0.000100, loss: 0.5767, CELoss: 0.5767, 
2022-10-16 18:48:29 - train: epoch 0079, iter [02300, 02526], lr: 0.000100, loss: 0.3772, CELoss: 0.3772, 
2022-10-16 18:49:03 - train: epoch 0079, iter [02400, 02526], lr: 0.000100, loss: 0.3554, CELoss: 0.3554, 
2022-10-16 18:49:37 - train: epoch 0079, iter [02500, 02526], lr: 0.000100, loss: 0.4606, CELoss: 0.4606, 
2022-10-16 18:49:47 - train: epoch 079, train_loss: 0.4484
2022-10-16 18:49:49 - until epoch: 079, best_metric: 36.197%
2022-10-16 18:49:49 - epoch 080 lr: 0.000100
2022-10-16 18:50:25 - train: epoch 0080, iter [00100, 02526], lr: 0.000100, loss: 0.6833, CELoss: 0.6833, 
2022-10-16 18:50:59 - train: epoch 0080, iter [00200, 02526], lr: 0.000100, loss: 0.5249, CELoss: 0.5249, 
2022-10-16 18:51:33 - train: epoch 0080, iter [00300, 02526], lr: 0.000100, loss: 0.4383, CELoss: 0.4383, 
2022-10-16 18:52:06 - train: epoch 0080, iter [00400, 02526], lr: 0.000100, loss: 0.5094, CELoss: 0.5094, 
2022-10-16 18:52:40 - train: epoch 0080, iter [00500, 02526], lr: 0.000100, loss: 0.3464, CELoss: 0.3464, 
2022-10-16 18:53:14 - train: epoch 0080, iter [00600, 02526], lr: 0.000100, loss: 0.4012, CELoss: 0.4012, 
2022-10-16 18:53:48 - train: epoch 0080, iter [00700, 02526], lr: 0.000100, loss: 0.4839, CELoss: 0.4839, 
2022-10-16 18:54:22 - train: epoch 0080, iter [00800, 02526], lr: 0.000100, loss: 0.4894, CELoss: 0.4894, 
2022-10-16 18:54:56 - train: epoch 0080, iter [00900, 02526], lr: 0.000100, loss: 0.4813, CELoss: 0.4813, 
2022-10-16 18:55:30 - train: epoch 0080, iter [01000, 02526], lr: 0.000100, loss: 0.3724, CELoss: 0.3724, 
2022-10-16 18:56:03 - train: epoch 0080, iter [01100, 02526], lr: 0.000100, loss: 0.5262, CELoss: 0.5262, 
2022-10-16 18:56:37 - train: epoch 0080, iter [01200, 02526], lr: 0.000100, loss: 0.4420, CELoss: 0.4420, 
2022-10-16 18:57:11 - train: epoch 0080, iter [01300, 02526], lr: 0.000100, loss: 0.4139, CELoss: 0.4139, 
2022-10-16 18:57:45 - train: epoch 0080, iter [01400, 02526], lr: 0.000100, loss: 0.5331, CELoss: 0.5331, 
2022-10-16 18:58:18 - train: epoch 0080, iter [01500, 02526], lr: 0.000100, loss: 0.3217, CELoss: 0.3217, 
2022-10-16 18:58:52 - train: epoch 0080, iter [01600, 02526], lr: 0.000100, loss: 0.3216, CELoss: 0.3216, 
2022-10-16 18:59:26 - train: epoch 0080, iter [01700, 02526], lr: 0.000100, loss: 0.4990, CELoss: 0.4990, 
2022-10-16 19:00:00 - train: epoch 0080, iter [01800, 02526], lr: 0.000100, loss: 0.3582, CELoss: 0.3582, 
2022-10-16 19:00:34 - train: epoch 0080, iter [01900, 02526], lr: 0.000100, loss: 0.4815, CELoss: 0.4815, 
2022-10-16 19:01:08 - train: epoch 0080, iter [02000, 02526], lr: 0.000100, loss: 0.3551, CELoss: 0.3551, 
2022-10-16 19:01:41 - train: epoch 0080, iter [02100, 02526], lr: 0.000100, loss: 0.7210, CELoss: 0.7210, 
2022-10-16 19:02:15 - train: epoch 0080, iter [02200, 02526], lr: 0.000100, loss: 0.4546, CELoss: 0.4546, 
2022-10-16 19:02:49 - train: epoch 0080, iter [02300, 02526], lr: 0.000100, loss: 0.4268, CELoss: 0.4268, 
2022-10-16 19:03:23 - train: epoch 0080, iter [02400, 02526], lr: 0.000100, loss: 0.6112, CELoss: 0.6112, 
2022-10-16 19:03:57 - train: epoch 0080, iter [02500, 02526], lr: 0.000100, loss: 0.5986, CELoss: 0.5986, 
2022-10-16 19:04:06 - train: epoch 080, train_loss: 0.4428
2022-10-16 19:04:57 - eval: epoch: 080
test_loss: 0.8796679226160049
per_image_load_time: 1.139ms
per_image_inference_time: 18.313ms
exist_num_class: 150.0
mean_precision: 57.90468459997134
mean_recall: 46.7926853992912
mean_iou: 35.99145226553656
mean_dice: 49.399370847568264

2022-10-16 19:05:00 - until epoch: 080, best_metric: 36.197%
2022-10-16 19:05:00 - epoch 081 lr: 0.000010
2022-10-16 19:05:36 - train: epoch 0081, iter [00100, 02526], lr: 0.000010, loss: 0.2535, CELoss: 0.2535, 
2022-10-16 19:06:10 - train: epoch 0081, iter [00200, 02526], lr: 0.000010, loss: 0.2991, CELoss: 0.2991, 
2022-10-16 19:06:43 - train: epoch 0081, iter [00300, 02526], lr: 0.000010, loss: 0.3566, CELoss: 0.3566, 
2022-10-16 19:07:17 - train: epoch 0081, iter [00400, 02526], lr: 0.000010, loss: 0.3173, CELoss: 0.3173, 
2022-10-16 19:07:51 - train: epoch 0081, iter [00500, 02526], lr: 0.000010, loss: 0.6035, CELoss: 0.6035, 
2022-10-16 19:08:25 - train: epoch 0081, iter [00600, 02526], lr: 0.000010, loss: 0.5157, CELoss: 0.5157, 
2022-10-16 19:08:59 - train: epoch 0081, iter [00700, 02526], lr: 0.000010, loss: 0.3651, CELoss: 0.3651, 
2022-10-16 19:09:33 - train: epoch 0081, iter [00800, 02526], lr: 0.000010, loss: 0.4708, CELoss: 0.4708, 
2022-10-16 19:10:07 - train: epoch 0081, iter [00900, 02526], lr: 0.000010, loss: 0.3347, CELoss: 0.3347, 
2022-10-16 19:10:40 - train: epoch 0081, iter [01000, 02526], lr: 0.000010, loss: 0.4537, CELoss: 0.4537, 
2022-10-16 19:11:14 - train: epoch 0081, iter [01100, 02526], lr: 0.000010, loss: 0.5817, CELoss: 0.5817, 
2022-10-16 19:11:48 - train: epoch 0081, iter [01200, 02526], lr: 0.000010, loss: 0.3410, CELoss: 0.3410, 
2022-10-16 19:12:22 - train: epoch 0081, iter [01300, 02526], lr: 0.000010, loss: 0.4387, CELoss: 0.4387, 
2022-10-16 19:12:55 - train: epoch 0081, iter [01400, 02526], lr: 0.000010, loss: 0.2253, CELoss: 0.2253, 
2022-10-16 19:13:29 - train: epoch 0081, iter [01500, 02526], lr: 0.000010, loss: 0.6798, CELoss: 0.6798, 
2022-10-16 19:14:03 - train: epoch 0081, iter [01600, 02526], lr: 0.000010, loss: 0.3247, CELoss: 0.3247, 
2022-10-16 19:14:37 - train: epoch 0081, iter [01700, 02526], lr: 0.000010, loss: 0.4848, CELoss: 0.4848, 
2022-10-16 19:15:11 - train: epoch 0081, iter [01800, 02526], lr: 0.000010, loss: 0.4769, CELoss: 0.4769, 
2022-10-16 19:15:44 - train: epoch 0081, iter [01900, 02526], lr: 0.000010, loss: 0.2902, CELoss: 0.2902, 
2022-10-16 19:16:18 - train: epoch 0081, iter [02000, 02526], lr: 0.000010, loss: 0.3594, CELoss: 0.3594, 
2022-10-16 19:16:52 - train: epoch 0081, iter [02100, 02526], lr: 0.000010, loss: 0.3133, CELoss: 0.3133, 
2022-10-16 19:17:26 - train: epoch 0081, iter [02200, 02526], lr: 0.000010, loss: 0.2029, CELoss: 0.2029, 
2022-10-16 19:17:59 - train: epoch 0081, iter [02300, 02526], lr: 0.000010, loss: 0.3776, CELoss: 0.3776, 
2022-10-16 19:18:33 - train: epoch 0081, iter [02400, 02526], lr: 0.000010, loss: 0.4730, CELoss: 0.4730, 
2022-10-16 19:19:07 - train: epoch 0081, iter [02500, 02526], lr: 0.000010, loss: 0.2877, CELoss: 0.2877, 
2022-10-16 19:19:17 - train: epoch 081, train_loss: 0.3866
2022-10-16 19:19:19 - until epoch: 081, best_metric: 36.197%
2022-10-16 19:19:19 - epoch 082 lr: 0.000010
2022-10-16 19:19:55 - train: epoch 0082, iter [00100, 02526], lr: 0.000010, loss: 0.2828, CELoss: 0.2828, 
2022-10-16 19:20:29 - train: epoch 0082, iter [00200, 02526], lr: 0.000010, loss: 0.3773, CELoss: 0.3773, 
2022-10-16 19:21:03 - train: epoch 0082, iter [00300, 02526], lr: 0.000010, loss: 0.2665, CELoss: 0.2665, 
2022-10-16 19:21:36 - train: epoch 0082, iter [00400, 02526], lr: 0.000010, loss: 0.2519, CELoss: 0.2519, 
2022-10-16 19:22:10 - train: epoch 0082, iter [00500, 02526], lr: 0.000010, loss: 0.4198, CELoss: 0.4198, 
2022-10-16 19:22:44 - train: epoch 0082, iter [00600, 02526], lr: 0.000010, loss: 0.2802, CELoss: 0.2802, 
2022-10-16 19:23:18 - train: epoch 0082, iter [00700, 02526], lr: 0.000010, loss: 0.5705, CELoss: 0.5705, 
2022-10-16 19:23:51 - train: epoch 0082, iter [00800, 02526], lr: 0.000010, loss: 0.4127, CELoss: 0.4127, 
2022-10-16 19:24:25 - train: epoch 0082, iter [00900, 02526], lr: 0.000010, loss: 0.2714, CELoss: 0.2714, 
2022-10-16 19:24:59 - train: epoch 0082, iter [01000, 02526], lr: 0.000010, loss: 0.4418, CELoss: 0.4418, 
2022-10-16 19:25:33 - train: epoch 0082, iter [01100, 02526], lr: 0.000010, loss: 0.8904, CELoss: 0.8904, 
2022-10-16 19:26:07 - train: epoch 0082, iter [01200, 02526], lr: 0.000010, loss: 0.3039, CELoss: 0.3039, 
2022-10-16 19:26:41 - train: epoch 0082, iter [01300, 02526], lr: 0.000010, loss: 0.3418, CELoss: 0.3418, 
2022-10-16 19:27:15 - train: epoch 0082, iter [01400, 02526], lr: 0.000010, loss: 0.3945, CELoss: 0.3945, 
2022-10-16 19:27:49 - train: epoch 0082, iter [01500, 02526], lr: 0.000010, loss: 0.1937, CELoss: 0.1937, 
2022-10-16 19:28:22 - train: epoch 0082, iter [01600, 02526], lr: 0.000010, loss: 0.2743, CELoss: 0.2743, 
2022-10-16 19:28:56 - train: epoch 0082, iter [01700, 02526], lr: 0.000010, loss: 0.3589, CELoss: 0.3589, 
2022-10-16 19:29:30 - train: epoch 0082, iter [01800, 02526], lr: 0.000010, loss: 0.4801, CELoss: 0.4801, 
2022-10-16 19:30:04 - train: epoch 0082, iter [01900, 02526], lr: 0.000010, loss: 0.2756, CELoss: 0.2756, 
2022-10-16 19:30:37 - train: epoch 0082, iter [02000, 02526], lr: 0.000010, loss: 0.3301, CELoss: 0.3301, 
2022-10-16 19:31:11 - train: epoch 0082, iter [02100, 02526], lr: 0.000010, loss: 0.5975, CELoss: 0.5975, 
2022-10-16 19:31:45 - train: epoch 0082, iter [02200, 02526], lr: 0.000010, loss: 0.4412, CELoss: 0.4412, 
2022-10-16 19:32:18 - train: epoch 0082, iter [02300, 02526], lr: 0.000010, loss: 0.3381, CELoss: 0.3381, 
2022-10-16 19:32:52 - train: epoch 0082, iter [02400, 02526], lr: 0.000010, loss: 0.4242, CELoss: 0.4242, 
2022-10-16 19:33:25 - train: epoch 0082, iter [02500, 02526], lr: 0.000010, loss: 0.3861, CELoss: 0.3861, 
2022-10-16 19:33:35 - train: epoch 082, train_loss: 0.3573
2022-10-16 19:33:37 - until epoch: 082, best_metric: 36.197%
2022-10-16 19:33:37 - epoch 083 lr: 0.000010
2022-10-16 19:34:13 - train: epoch 0083, iter [00100, 02526], lr: 0.000010, loss: 0.1910, CELoss: 0.1910, 
2022-10-16 19:34:47 - train: epoch 0083, iter [00200, 02526], lr: 0.000010, loss: 0.4007, CELoss: 0.4007, 
2022-10-16 19:35:21 - train: epoch 0083, iter [00300, 02526], lr: 0.000010, loss: 0.2222, CELoss: 0.2222, 
2022-10-16 19:35:54 - train: epoch 0083, iter [00400, 02526], lr: 0.000010, loss: 0.3012, CELoss: 0.3012, 
2022-10-16 19:36:28 - train: epoch 0083, iter [00500, 02526], lr: 0.000010, loss: 0.3260, CELoss: 0.3260, 
2022-10-16 19:37:02 - train: epoch 0083, iter [00600, 02526], lr: 0.000010, loss: 0.1786, CELoss: 0.1786, 
2022-10-16 19:37:35 - train: epoch 0083, iter [00700, 02526], lr: 0.000010, loss: 0.4564, CELoss: 0.4564, 
2022-10-16 19:38:09 - train: epoch 0083, iter [00800, 02526], lr: 0.000010, loss: 0.2480, CELoss: 0.2480, 
2022-10-16 19:38:42 - train: epoch 0083, iter [00900, 02526], lr: 0.000010, loss: 0.2447, CELoss: 0.2447, 
2022-10-16 19:39:16 - train: epoch 0083, iter [01000, 02526], lr: 0.000010, loss: 0.5352, CELoss: 0.5352, 
2022-10-16 19:39:49 - train: epoch 0083, iter [01100, 02526], lr: 0.000010, loss: 0.3172, CELoss: 0.3172, 
2022-10-16 19:40:23 - train: epoch 0083, iter [01200, 02526], lr: 0.000010, loss: 0.3782, CELoss: 0.3782, 
2022-10-16 19:40:57 - train: epoch 0083, iter [01300, 02526], lr: 0.000010, loss: 0.2318, CELoss: 0.2318, 
2022-10-16 19:41:30 - train: epoch 0083, iter [01400, 02526], lr: 0.000010, loss: 0.1697, CELoss: 0.1697, 
2022-10-16 19:42:04 - train: epoch 0083, iter [01500, 02526], lr: 0.000010, loss: 0.3853, CELoss: 0.3853, 
2022-10-16 19:42:38 - train: epoch 0083, iter [01600, 02526], lr: 0.000010, loss: 0.2868, CELoss: 0.2868, 
2022-10-16 19:43:11 - train: epoch 0083, iter [01700, 02526], lr: 0.000010, loss: 0.3815, CELoss: 0.3815, 
2022-10-16 19:43:45 - train: epoch 0083, iter [01800, 02526], lr: 0.000010, loss: 0.2423, CELoss: 0.2423, 
2022-10-16 19:44:18 - train: epoch 0083, iter [01900, 02526], lr: 0.000010, loss: 0.5750, CELoss: 0.5750, 
2022-10-16 19:44:52 - train: epoch 0083, iter [02000, 02526], lr: 0.000010, loss: 0.1812, CELoss: 0.1812, 
2022-10-16 19:45:25 - train: epoch 0083, iter [02100, 02526], lr: 0.000010, loss: 0.5453, CELoss: 0.5453, 
2022-10-16 19:45:59 - train: epoch 0083, iter [02200, 02526], lr: 0.000010, loss: 0.4113, CELoss: 0.4113, 
2022-10-16 19:46:32 - train: epoch 0083, iter [02300, 02526], lr: 0.000010, loss: 0.4779, CELoss: 0.4779, 
2022-10-16 19:47:06 - train: epoch 0083, iter [02400, 02526], lr: 0.000010, loss: 0.3272, CELoss: 0.3272, 
2022-10-16 19:47:40 - train: epoch 0083, iter [02500, 02526], lr: 0.000010, loss: 0.4970, CELoss: 0.4970, 
2022-10-16 19:47:50 - train: epoch 083, train_loss: 0.3464
2022-10-16 19:47:52 - until epoch: 083, best_metric: 36.197%
2022-10-16 19:54:23 - epoch 084 lr: 0.000010
2022-10-16 19:55:01 - train: epoch 0084, iter [00100, 02526], lr: 0.000010, loss: 0.2581, CELoss: 0.2581, 
2022-10-16 19:55:34 - train: epoch 0084, iter [00200, 02526], lr: 0.000010, loss: 0.2185, CELoss: 0.2185, 
2022-10-16 19:56:08 - train: epoch 0084, iter [00300, 02526], lr: 0.000010, loss: 0.3048, CELoss: 0.3048, 
2022-10-16 19:56:42 - train: epoch 0084, iter [00400, 02526], lr: 0.000010, loss: 0.3450, CELoss: 0.3450, 
2022-10-16 19:57:15 - train: epoch 0084, iter [00500, 02526], lr: 0.000010, loss: 0.3121, CELoss: 0.3121, 
2022-10-16 19:57:48 - train: epoch 0084, iter [00600, 02526], lr: 0.000010, loss: 0.3578, CELoss: 0.3578, 
2022-10-16 19:58:22 - train: epoch 0084, iter [00700, 02526], lr: 0.000010, loss: 0.3661, CELoss: 0.3661, 
2022-10-16 19:58:56 - train: epoch 0084, iter [00800, 02526], lr: 0.000010, loss: 0.1264, CELoss: 0.1264, 
2022-10-16 19:59:29 - train: epoch 0084, iter [00900, 02526], lr: 0.000010, loss: 0.4233, CELoss: 0.4233, 
2022-10-16 20:00:03 - train: epoch 0084, iter [01000, 02526], lr: 0.000010, loss: 0.2569, CELoss: 0.2569, 
2022-10-16 20:00:36 - train: epoch 0084, iter [01100, 02526], lr: 0.000010, loss: 0.4566, CELoss: 0.4566, 
2022-10-16 20:01:10 - train: epoch 0084, iter [01200, 02526], lr: 0.000010, loss: 0.3714, CELoss: 0.3714, 
2022-10-16 20:01:43 - train: epoch 0084, iter [01300, 02526], lr: 0.000010, loss: 0.2217, CELoss: 0.2217, 
2022-10-16 20:02:17 - train: epoch 0084, iter [01400, 02526], lr: 0.000010, loss: 0.2840, CELoss: 0.2840, 
2022-10-16 20:02:50 - train: epoch 0084, iter [01500, 02526], lr: 0.000010, loss: 0.2307, CELoss: 0.2307, 
2022-10-16 20:03:23 - train: epoch 0084, iter [01600, 02526], lr: 0.000010, loss: 0.3413, CELoss: 0.3413, 
2022-10-16 20:03:57 - train: epoch 0084, iter [01700, 02526], lr: 0.000010, loss: 0.3126, CELoss: 0.3126, 
2022-10-16 20:04:31 - train: epoch 0084, iter [01800, 02526], lr: 0.000010, loss: 0.3183, CELoss: 0.3183, 
2022-10-16 20:05:04 - train: epoch 0084, iter [01900, 02526], lr: 0.000010, loss: 0.3689, CELoss: 0.3689, 
2022-10-16 20:05:38 - train: epoch 0084, iter [02000, 02526], lr: 0.000010, loss: 0.2342, CELoss: 0.2342, 
2022-10-16 20:06:12 - train: epoch 0084, iter [02100, 02526], lr: 0.000010, loss: 0.3841, CELoss: 0.3841, 
2022-10-16 20:06:45 - train: epoch 0084, iter [02200, 02526], lr: 0.000010, loss: 0.3341, CELoss: 0.3341, 
2022-10-16 20:07:18 - train: epoch 0084, iter [02300, 02526], lr: 0.000010, loss: 0.3324, CELoss: 0.3324, 
2022-10-16 20:07:52 - train: epoch 0084, iter [02400, 02526], lr: 0.000010, loss: 0.3143, CELoss: 0.3143, 
2022-10-16 20:08:25 - train: epoch 0084, iter [02500, 02526], lr: 0.000010, loss: 0.3095, CELoss: 0.3095, 
2022-10-16 20:08:36 - train: epoch 084, train_loss: 0.3375
2022-10-16 20:08:38 - until epoch: 084, best_metric: 36.197%
2022-10-16 20:08:38 - epoch 085 lr: 0.000010
2022-10-16 20:09:14 - train: epoch 0085, iter [00100, 02526], lr: 0.000010, loss: 0.3023, CELoss: 0.3023, 
2022-10-16 20:09:48 - train: epoch 0085, iter [00200, 02526], lr: 0.000010, loss: 0.6702, CELoss: 0.6702, 
2022-10-16 20:10:22 - train: epoch 0085, iter [00300, 02526], lr: 0.000010, loss: 0.2870, CELoss: 0.2870, 
2022-10-16 20:10:56 - train: epoch 0085, iter [00400, 02526], lr: 0.000010, loss: 0.6097, CELoss: 0.6097, 
2022-10-16 20:11:30 - train: epoch 0085, iter [00500, 02526], lr: 0.000010, loss: 0.4309, CELoss: 0.4309, 
2022-10-16 20:12:04 - train: epoch 0085, iter [00600, 02526], lr: 0.000010, loss: 0.2851, CELoss: 0.2851, 
2022-10-16 20:12:37 - train: epoch 0085, iter [00700, 02526], lr: 0.000010, loss: 0.3352, CELoss: 0.3352, 
2022-10-16 20:13:11 - train: epoch 0085, iter [00800, 02526], lr: 0.000010, loss: 0.4106, CELoss: 0.4106, 
2022-10-16 20:13:45 - train: epoch 0085, iter [00900, 02526], lr: 0.000010, loss: 0.2857, CELoss: 0.2857, 
2022-10-16 20:14:18 - train: epoch 0085, iter [01000, 02526], lr: 0.000010, loss: 0.3003, CELoss: 0.3003, 
2022-10-16 20:14:52 - train: epoch 0085, iter [01100, 02526], lr: 0.000010, loss: 0.2743, CELoss: 0.2743, 
2022-10-16 20:15:26 - train: epoch 0085, iter [01200, 02526], lr: 0.000010, loss: 0.2360, CELoss: 0.2360, 
2022-10-16 20:15:59 - train: epoch 0085, iter [01300, 02526], lr: 0.000010, loss: 0.5792, CELoss: 0.5792, 
2022-10-16 20:16:32 - train: epoch 0085, iter [01400, 02526], lr: 0.000010, loss: 0.3879, CELoss: 0.3879, 
2022-10-16 20:17:06 - train: epoch 0085, iter [01500, 02526], lr: 0.000010, loss: 0.2558, CELoss: 0.2558, 
2022-10-16 20:17:39 - train: epoch 0085, iter [01600, 02526], lr: 0.000010, loss: 0.3225, CELoss: 0.3225, 
2022-10-16 20:18:13 - train: epoch 0085, iter [01700, 02526], lr: 0.000010, loss: 0.5743, CELoss: 0.5743, 
2022-10-16 20:18:46 - train: epoch 0085, iter [01800, 02526], lr: 0.000010, loss: 0.3451, CELoss: 0.3451, 
2022-10-16 20:19:20 - train: epoch 0085, iter [01900, 02526], lr: 0.000010, loss: 0.2997, CELoss: 0.2997, 
2022-10-16 20:19:53 - train: epoch 0085, iter [02000, 02526], lr: 0.000010, loss: 0.4372, CELoss: 0.4372, 
2022-10-16 20:20:27 - train: epoch 0085, iter [02100, 02526], lr: 0.000010, loss: 0.3595, CELoss: 0.3595, 
2022-10-16 20:21:00 - train: epoch 0085, iter [02200, 02526], lr: 0.000010, loss: 0.1873, CELoss: 0.1873, 
2022-10-16 20:21:34 - train: epoch 0085, iter [02300, 02526], lr: 0.000010, loss: 0.3464, CELoss: 0.3464, 
2022-10-16 20:22:08 - train: epoch 0085, iter [02400, 02526], lr: 0.000010, loss: 0.2996, CELoss: 0.2996, 
2022-10-16 20:22:41 - train: epoch 0085, iter [02500, 02526], lr: 0.000010, loss: 0.2964, CELoss: 0.2964, 
2022-10-16 20:22:52 - train: epoch 085, train_loss: 0.3333
2022-10-16 20:23:43 - eval: epoch: 085
test_loss: 0.871518697142601
per_image_load_time: 1.667ms
per_image_inference_time: 18.219ms
exist_num_class: 150.0
mean_precision: 59.69628308401844
mean_recall: 49.212856745687795
mean_iou: 38.52043904311084
mean_dice: 52.25707447174703

2022-10-16 20:23:46 - until epoch: 085, best_metric: 38.520%
2022-10-16 20:23:46 - epoch 086 lr: 0.000010
2022-10-16 20:24:22 - train: epoch 0086, iter [00100, 02526], lr: 0.000010, loss: 0.2305, CELoss: 0.2305, 
2022-10-16 20:24:56 - train: epoch 0086, iter [00200, 02526], lr: 0.000010, loss: 0.3224, CELoss: 0.3224, 
2022-10-16 20:25:30 - train: epoch 0086, iter [00300, 02526], lr: 0.000010, loss: 0.3705, CELoss: 0.3705, 
2022-10-16 20:26:03 - train: epoch 0086, iter [00400, 02526], lr: 0.000010, loss: 0.2382, CELoss: 0.2382, 
2022-10-16 20:26:37 - train: epoch 0086, iter [00500, 02526], lr: 0.000010, loss: 0.3420, CELoss: 0.3420, 
2022-10-16 20:27:10 - train: epoch 0086, iter [00600, 02526], lr: 0.000010, loss: 0.3562, CELoss: 0.3562, 
2022-10-16 20:27:44 - train: epoch 0086, iter [00700, 02526], lr: 0.000010, loss: 0.3860, CELoss: 0.3860, 
2022-10-16 20:28:18 - train: epoch 0086, iter [00800, 02526], lr: 0.000010, loss: 0.2778, CELoss: 0.2778, 
2022-10-16 20:28:51 - train: epoch 0086, iter [00900, 02526], lr: 0.000010, loss: 0.3910, CELoss: 0.3910, 
2022-10-16 20:29:25 - train: epoch 0086, iter [01000, 02526], lr: 0.000010, loss: 0.1840, CELoss: 0.1840, 
2022-10-16 20:29:59 - train: epoch 0086, iter [01100, 02526], lr: 0.000010, loss: 0.1895, CELoss: 0.1895, 
2022-10-16 20:30:32 - train: epoch 0086, iter [01200, 02526], lr: 0.000010, loss: 0.3072, CELoss: 0.3072, 
2022-10-16 20:31:06 - train: epoch 0086, iter [01300, 02526], lr: 0.000010, loss: 0.5166, CELoss: 0.5166, 
2022-10-16 20:31:40 - train: epoch 0086, iter [01400, 02526], lr: 0.000010, loss: 0.2917, CELoss: 0.2917, 
2022-10-16 20:32:13 - train: epoch 0086, iter [01500, 02526], lr: 0.000010, loss: 0.3483, CELoss: 0.3483, 
2022-10-16 20:32:47 - train: epoch 0086, iter [01600, 02526], lr: 0.000010, loss: 0.3698, CELoss: 0.3698, 
2022-10-16 20:33:21 - train: epoch 0086, iter [01700, 02526], lr: 0.000010, loss: 0.3931, CELoss: 0.3931, 
2022-10-16 20:33:54 - train: epoch 0086, iter [01800, 02526], lr: 0.000010, loss: 0.3189, CELoss: 0.3189, 
2022-10-16 20:34:28 - train: epoch 0086, iter [01900, 02526], lr: 0.000010, loss: 0.2736, CELoss: 0.2736, 
2022-10-16 20:35:02 - train: epoch 0086, iter [02000, 02526], lr: 0.000010, loss: 0.3846, CELoss: 0.3846, 
2022-10-16 20:35:35 - train: epoch 0086, iter [02100, 02526], lr: 0.000010, loss: 0.3839, CELoss: 0.3839, 
2022-10-16 20:36:09 - train: epoch 0086, iter [02200, 02526], lr: 0.000010, loss: 0.3390, CELoss: 0.3390, 
2022-10-16 20:36:42 - train: epoch 0086, iter [02300, 02526], lr: 0.000010, loss: 0.2498, CELoss: 0.2498, 
2022-10-16 20:37:16 - train: epoch 0086, iter [02400, 02526], lr: 0.000010, loss: 0.3000, CELoss: 0.3000, 
2022-10-16 20:37:49 - train: epoch 0086, iter [02500, 02526], lr: 0.000010, loss: 0.2229, CELoss: 0.2229, 
2022-10-16 20:37:59 - train: epoch 086, train_loss: 0.3282
2022-10-16 20:38:00 - until epoch: 086, best_metric: 38.520%
2022-10-16 20:38:00 - epoch 087 lr: 0.000010
2022-10-16 20:38:37 - train: epoch 0087, iter [00100, 02526], lr: 0.000010, loss: 0.4011, CELoss: 0.4011, 
2022-10-16 20:39:11 - train: epoch 0087, iter [00200, 02526], lr: 0.000010, loss: 0.2423, CELoss: 0.2423, 
2022-10-16 20:39:45 - train: epoch 0087, iter [00300, 02526], lr: 0.000010, loss: 0.3010, CELoss: 0.3010, 
2022-10-16 20:40:19 - train: epoch 0087, iter [00400, 02526], lr: 0.000010, loss: 0.3918, CELoss: 0.3918, 
2022-10-16 20:40:52 - train: epoch 0087, iter [00500, 02526], lr: 0.000010, loss: 0.3195, CELoss: 0.3195, 
2022-10-16 20:41:26 - train: epoch 0087, iter [00600, 02526], lr: 0.000010, loss: 0.3338, CELoss: 0.3338, 
2022-10-16 20:42:00 - train: epoch 0087, iter [00700, 02526], lr: 0.000010, loss: 0.2473, CELoss: 0.2473, 
2022-10-16 20:42:33 - train: epoch 0087, iter [00800, 02526], lr: 0.000010, loss: 0.5161, CELoss: 0.5161, 
2022-10-16 20:43:08 - train: epoch 0087, iter [00900, 02526], lr: 0.000010, loss: 0.5564, CELoss: 0.5564, 
2022-10-16 20:43:42 - train: epoch 0087, iter [01000, 02526], lr: 0.000010, loss: 0.3429, CELoss: 0.3429, 
2022-10-16 20:44:16 - train: epoch 0087, iter [01100, 02526], lr: 0.000010, loss: 0.3815, CELoss: 0.3815, 
2022-10-16 20:44:49 - train: epoch 0087, iter [01200, 02526], lr: 0.000010, loss: 0.3526, CELoss: 0.3526, 
2022-10-16 20:45:23 - train: epoch 0087, iter [01300, 02526], lr: 0.000010, loss: 0.3632, CELoss: 0.3632, 
2022-10-16 20:45:57 - train: epoch 0087, iter [01400, 02526], lr: 0.000010, loss: 0.2926, CELoss: 0.2926, 
2022-10-16 20:46:31 - train: epoch 0087, iter [01500, 02526], lr: 0.000010, loss: 0.3348, CELoss: 0.3348, 
2022-10-16 20:47:04 - train: epoch 0087, iter [01600, 02526], lr: 0.000010, loss: 0.2122, CELoss: 0.2122, 
2022-10-16 20:47:38 - train: epoch 0087, iter [01700, 02526], lr: 0.000010, loss: 0.2610, CELoss: 0.2610, 
2022-10-16 20:48:12 - train: epoch 0087, iter [01800, 02526], lr: 0.000010, loss: 0.3392, CELoss: 0.3392, 
2022-10-16 20:48:46 - train: epoch 0087, iter [01900, 02526], lr: 0.000010, loss: 0.3131, CELoss: 0.3131, 
2022-10-16 20:49:20 - train: epoch 0087, iter [02000, 02526], lr: 0.000010, loss: 0.2463, CELoss: 0.2463, 
2022-10-16 20:49:54 - train: epoch 0087, iter [02100, 02526], lr: 0.000010, loss: 0.1908, CELoss: 0.1908, 
2022-10-16 20:50:28 - train: epoch 0087, iter [02200, 02526], lr: 0.000010, loss: 0.3181, CELoss: 0.3181, 
2022-10-16 20:51:01 - train: epoch 0087, iter [02300, 02526], lr: 0.000010, loss: 0.2192, CELoss: 0.2192, 
2022-10-16 20:51:35 - train: epoch 0087, iter [02400, 02526], lr: 0.000010, loss: 0.2757, CELoss: 0.2757, 
2022-10-16 20:52:09 - train: epoch 0087, iter [02500, 02526], lr: 0.000010, loss: 0.3512, CELoss: 0.3512, 
2022-10-16 20:52:18 - train: epoch 087, train_loss: 0.3236
2022-10-16 20:52:20 - until epoch: 087, best_metric: 38.520%
2022-10-16 20:52:20 - epoch 088 lr: 0.000010
2022-10-16 20:52:58 - train: epoch 0088, iter [00100, 02526], lr: 0.000010, loss: 0.5784, CELoss: 0.5784, 
2022-10-16 20:53:32 - train: epoch 0088, iter [00200, 02526], lr: 0.000010, loss: 0.2780, CELoss: 0.2780, 
2022-10-16 20:54:06 - train: epoch 0088, iter [00300, 02526], lr: 0.000010, loss: 0.2094, CELoss: 0.2094, 
2022-10-16 20:54:40 - train: epoch 0088, iter [00400, 02526], lr: 0.000010, loss: 0.5210, CELoss: 0.5210, 
2022-10-16 20:55:14 - train: epoch 0088, iter [00500, 02526], lr: 0.000010, loss: 0.2474, CELoss: 0.2474, 
2022-10-16 20:55:47 - train: epoch 0088, iter [00600, 02526], lr: 0.000010, loss: 0.3599, CELoss: 0.3599, 
2022-10-16 20:56:21 - train: epoch 0088, iter [00700, 02526], lr: 0.000010, loss: 0.3203, CELoss: 0.3203, 
2022-10-16 20:56:55 - train: epoch 0088, iter [00800, 02526], lr: 0.000010, loss: 0.2374, CELoss: 0.2374, 
2022-10-16 20:57:29 - train: epoch 0088, iter [00900, 02526], lr: 0.000010, loss: 0.2210, CELoss: 0.2210, 
2022-10-16 20:58:02 - train: epoch 0088, iter [01000, 02526], lr: 0.000010, loss: 0.3773, CELoss: 0.3773, 
2022-10-16 20:58:36 - train: epoch 0088, iter [01100, 02526], lr: 0.000010, loss: 0.2785, CELoss: 0.2785, 
2022-10-16 20:59:10 - train: epoch 0088, iter [01200, 02526], lr: 0.000010, loss: 0.3364, CELoss: 0.3364, 
2022-10-16 20:59:44 - train: epoch 0088, iter [01300, 02526], lr: 0.000010, loss: 0.3019, CELoss: 0.3019, 
2022-10-16 21:00:18 - train: epoch 0088, iter [01400, 02526], lr: 0.000010, loss: 0.2655, CELoss: 0.2655, 
2022-10-16 21:00:52 - train: epoch 0088, iter [01500, 02526], lr: 0.000010, loss: 0.1550, CELoss: 0.1550, 
2022-10-16 21:01:26 - train: epoch 0088, iter [01600, 02526], lr: 0.000010, loss: 0.3380, CELoss: 0.3380, 
2022-10-16 21:02:00 - train: epoch 0088, iter [01700, 02526], lr: 0.000010, loss: 0.3004, CELoss: 0.3004, 
2022-10-16 21:02:34 - train: epoch 0088, iter [01800, 02526], lr: 0.000010, loss: 0.2773, CELoss: 0.2773, 
2022-10-16 21:03:08 - train: epoch 0088, iter [01900, 02526], lr: 0.000010, loss: 0.1868, CELoss: 0.1868, 
2022-10-16 21:03:42 - train: epoch 0088, iter [02000, 02526], lr: 0.000010, loss: 0.1949, CELoss: 0.1949, 
2022-10-16 21:04:16 - train: epoch 0088, iter [02100, 02526], lr: 0.000010, loss: 0.2783, CELoss: 0.2783, 
2022-10-16 21:04:50 - train: epoch 0088, iter [02200, 02526], lr: 0.000010, loss: 0.3363, CELoss: 0.3363, 
2022-10-16 21:05:24 - train: epoch 0088, iter [02300, 02526], lr: 0.000010, loss: 0.3647, CELoss: 0.3647, 
2022-10-16 21:05:58 - train: epoch 0088, iter [02400, 02526], lr: 0.000010, loss: 0.1716, CELoss: 0.1716, 
2022-10-16 21:06:31 - train: epoch 0088, iter [02500, 02526], lr: 0.000010, loss: 0.6071, CELoss: 0.6071, 
2022-10-16 21:06:42 - train: epoch 088, train_loss: 0.3173
2022-10-16 21:06:43 - until epoch: 088, best_metric: 38.520%
2022-10-16 21:06:43 - epoch 089 lr: 0.000010
2022-10-16 21:07:20 - train: epoch 0089, iter [00100, 02526], lr: 0.000010, loss: 0.2804, CELoss: 0.2804, 
2022-10-16 21:07:54 - train: epoch 0089, iter [00200, 02526], lr: 0.000010, loss: 0.4136, CELoss: 0.4136, 
2022-10-16 21:08:28 - train: epoch 0089, iter [00300, 02526], lr: 0.000010, loss: 0.3039, CELoss: 0.3039, 
2022-10-16 21:09:02 - train: epoch 0089, iter [00400, 02526], lr: 0.000010, loss: 0.2818, CELoss: 0.2818, 
2022-10-16 21:09:36 - train: epoch 0089, iter [00500, 02526], lr: 0.000010, loss: 0.6386, CELoss: 0.6386, 
2022-10-16 21:10:10 - train: epoch 0089, iter [00600, 02526], lr: 0.000010, loss: 0.2853, CELoss: 0.2853, 
2022-10-16 21:10:44 - train: epoch 0089, iter [00700, 02526], lr: 0.000010, loss: 0.2005, CELoss: 0.2005, 
2022-10-16 21:11:18 - train: epoch 0089, iter [00800, 02526], lr: 0.000010, loss: 0.3093, CELoss: 0.3093, 
2022-10-16 21:11:52 - train: epoch 0089, iter [00900, 02526], lr: 0.000010, loss: 0.2130, CELoss: 0.2130, 
2022-10-16 21:12:25 - train: epoch 0089, iter [01000, 02526], lr: 0.000010, loss: 0.3854, CELoss: 0.3854, 
2022-10-16 21:12:59 - train: epoch 0089, iter [01100, 02526], lr: 0.000010, loss: 0.3366, CELoss: 0.3366, 
2022-10-16 21:13:33 - train: epoch 0089, iter [01200, 02526], lr: 0.000010, loss: 0.3609, CELoss: 0.3609, 
2022-10-16 21:14:07 - train: epoch 0089, iter [01300, 02526], lr: 0.000010, loss: 0.3350, CELoss: 0.3350, 
2022-10-16 21:14:40 - train: epoch 0089, iter [01400, 02526], lr: 0.000010, loss: 0.3832, CELoss: 0.3832, 
2022-10-16 21:15:14 - train: epoch 0089, iter [01500, 02526], lr: 0.000010, loss: 0.3570, CELoss: 0.3570, 
2022-10-16 21:15:48 - train: epoch 0089, iter [01600, 02526], lr: 0.000010, loss: 0.2875, CELoss: 0.2875, 
2022-10-16 21:16:22 - train: epoch 0089, iter [01700, 02526], lr: 0.000010, loss: 0.3171, CELoss: 0.3171, 
2022-10-16 21:16:56 - train: epoch 0089, iter [01800, 02526], lr: 0.000010, loss: 0.4408, CELoss: 0.4408, 
2022-10-16 21:17:30 - train: epoch 0089, iter [01900, 02526], lr: 0.000010, loss: 0.4548, CELoss: 0.4548, 
2022-10-16 21:18:03 - train: epoch 0089, iter [02000, 02526], lr: 0.000010, loss: 0.5296, CELoss: 0.5296, 
2022-10-16 21:18:37 - train: epoch 0089, iter [02100, 02526], lr: 0.000010, loss: 0.4350, CELoss: 0.4350, 
2022-10-16 21:19:11 - train: epoch 0089, iter [02200, 02526], lr: 0.000010, loss: 0.2433, CELoss: 0.2433, 
2022-10-16 21:19:45 - train: epoch 0089, iter [02300, 02526], lr: 0.000010, loss: 0.3121, CELoss: 0.3121, 
2022-10-16 21:20:19 - train: epoch 0089, iter [02400, 02526], lr: 0.000010, loss: 0.2188, CELoss: 0.2188, 
2022-10-16 21:20:53 - train: epoch 0089, iter [02500, 02526], lr: 0.000010, loss: 0.2703, CELoss: 0.2703, 
2022-10-16 21:21:03 - train: epoch 089, train_loss: 0.3162
2022-10-16 21:21:04 - until epoch: 089, best_metric: 38.520%
2022-10-16 21:21:04 - epoch 090 lr: 0.000010
2022-10-16 21:21:41 - train: epoch 0090, iter [00100, 02526], lr: 0.000010, loss: 0.3527, CELoss: 0.3527, 
2022-10-16 21:22:16 - train: epoch 0090, iter [00200, 02526], lr: 0.000010, loss: 0.2927, CELoss: 0.2927, 
2022-10-16 21:22:49 - train: epoch 0090, iter [00300, 02526], lr: 0.000010, loss: 0.2719, CELoss: 0.2719, 
2022-10-16 21:23:23 - train: epoch 0090, iter [00400, 02526], lr: 0.000010, loss: 0.3673, CELoss: 0.3673, 
2022-10-16 21:23:57 - train: epoch 0090, iter [00500, 02526], lr: 0.000010, loss: 0.1848, CELoss: 0.1848, 
2022-10-16 21:24:31 - train: epoch 0090, iter [00600, 02526], lr: 0.000010, loss: 0.1719, CELoss: 0.1719, 
2022-10-16 21:25:05 - train: epoch 0090, iter [00700, 02526], lr: 0.000010, loss: 0.1874, CELoss: 0.1874, 
2022-10-16 21:25:39 - train: epoch 0090, iter [00800, 02526], lr: 0.000010, loss: 0.4429, CELoss: 0.4429, 
2022-10-16 21:26:13 - train: epoch 0090, iter [00900, 02526], lr: 0.000010, loss: 0.2160, CELoss: 0.2160, 
2022-10-16 21:26:47 - train: epoch 0090, iter [01000, 02526], lr: 0.000010, loss: 0.2152, CELoss: 0.2152, 
2022-10-16 21:27:21 - train: epoch 0090, iter [01100, 02526], lr: 0.000010, loss: 0.2911, CELoss: 0.2911, 
2022-10-16 21:27:54 - train: epoch 0090, iter [01200, 02526], lr: 0.000010, loss: 0.3070, CELoss: 0.3070, 
2022-10-16 21:28:28 - train: epoch 0090, iter [01300, 02526], lr: 0.000010, loss: 0.1572, CELoss: 0.1572, 
2022-10-16 21:29:02 - train: epoch 0090, iter [01400, 02526], lr: 0.000010, loss: 0.2825, CELoss: 0.2825, 
2022-10-16 21:29:36 - train: epoch 0090, iter [01500, 02526], lr: 0.000010, loss: 0.3706, CELoss: 0.3706, 
2022-10-16 21:30:10 - train: epoch 0090, iter [01600, 02526], lr: 0.000010, loss: 0.3233, CELoss: 0.3233, 
2022-10-16 21:30:44 - train: epoch 0090, iter [01700, 02526], lr: 0.000010, loss: 0.3822, CELoss: 0.3822, 
2022-10-16 21:31:18 - train: epoch 0090, iter [01800, 02526], lr: 0.000010, loss: 0.2910, CELoss: 0.2910, 
2022-10-16 21:31:51 - train: epoch 0090, iter [01900, 02526], lr: 0.000010, loss: 0.3077, CELoss: 0.3077, 
2022-10-16 21:32:25 - train: epoch 0090, iter [02000, 02526], lr: 0.000010, loss: 0.4049, CELoss: 0.4049, 
2022-10-16 21:32:59 - train: epoch 0090, iter [02100, 02526], lr: 0.000010, loss: 0.2687, CELoss: 0.2687, 
2022-10-16 21:33:33 - train: epoch 0090, iter [02200, 02526], lr: 0.000010, loss: 0.2766, CELoss: 0.2766, 
2022-10-16 21:34:07 - train: epoch 0090, iter [02300, 02526], lr: 0.000010, loss: 0.2243, CELoss: 0.2243, 
2022-10-16 21:34:41 - train: epoch 0090, iter [02400, 02526], lr: 0.000010, loss: 0.2787, CELoss: 0.2787, 
2022-10-16 21:35:14 - train: epoch 0090, iter [02500, 02526], lr: 0.000010, loss: 0.2628, CELoss: 0.2628, 
2022-10-16 21:35:25 - train: epoch 090, train_loss: 0.3163
2022-10-16 21:36:16 - eval: epoch: 090
test_loss: 0.8693881581276656
per_image_load_time: 1.756ms
per_image_inference_time: 18.248ms
exist_num_class: 150.0
mean_precision: 60.490545458012534
mean_recall: 50.102877328415026
mean_iou: 39.54686226372387
mean_dice: 53.326745020326925

2022-10-16 21:36:20 - until epoch: 090, best_metric: 39.547%
2022-10-16 21:36:20 - epoch 091 lr: 0.000010
2022-10-16 21:36:57 - train: epoch 0091, iter [00100, 02526], lr: 0.000010, loss: 0.3151, CELoss: 0.3151, 
2022-10-16 21:37:31 - train: epoch 0091, iter [00200, 02526], lr: 0.000010, loss: 0.2350, CELoss: 0.2350, 
2022-10-16 21:38:05 - train: epoch 0091, iter [00300, 02526], lr: 0.000010, loss: 0.3629, CELoss: 0.3629, 
2022-10-16 21:38:39 - train: epoch 0091, iter [00400, 02526], lr: 0.000010, loss: 0.5384, CELoss: 0.5384, 
2022-10-16 21:39:13 - train: epoch 0091, iter [00500, 02526], lr: 0.000010, loss: 0.2812, CELoss: 0.2812, 
2022-10-16 21:39:46 - train: epoch 0091, iter [00600, 02526], lr: 0.000010, loss: 0.2958, CELoss: 0.2958, 
2022-10-16 21:40:20 - train: epoch 0091, iter [00700, 02526], lr: 0.000010, loss: 0.3239, CELoss: 0.3239, 
2022-10-16 21:40:55 - train: epoch 0091, iter [00800, 02526], lr: 0.000010, loss: 0.4136, CELoss: 0.4136, 
2022-10-16 21:41:28 - train: epoch 0091, iter [00900, 02526], lr: 0.000010, loss: 0.2314, CELoss: 0.2314, 
2022-10-16 21:42:02 - train: epoch 0091, iter [01000, 02526], lr: 0.000010, loss: 0.1666, CELoss: 0.1666, 
2022-10-16 21:42:36 - train: epoch 0091, iter [01100, 02526], lr: 0.000010, loss: 0.2965, CELoss: 0.2965, 
2022-10-16 21:43:10 - train: epoch 0091, iter [01200, 02526], lr: 0.000010, loss: 0.3491, CELoss: 0.3491, 
2022-10-16 21:43:44 - train: epoch 0091, iter [01300, 02526], lr: 0.000010, loss: 0.3767, CELoss: 0.3767, 
2022-10-16 21:44:18 - train: epoch 0091, iter [01400, 02526], lr: 0.000010, loss: 0.2666, CELoss: 0.2666, 
2022-10-16 21:44:51 - train: epoch 0091, iter [01500, 02526], lr: 0.000010, loss: 0.2699, CELoss: 0.2699, 
2022-10-16 21:45:25 - train: epoch 0091, iter [01600, 02526], lr: 0.000010, loss: 0.5316, CELoss: 0.5316, 
2022-10-16 21:45:59 - train: epoch 0091, iter [01700, 02526], lr: 0.000010, loss: 0.3019, CELoss: 0.3019, 
2022-10-16 21:46:33 - train: epoch 0091, iter [01800, 02526], lr: 0.000010, loss: 0.2745, CELoss: 0.2745, 
2022-10-16 21:47:07 - train: epoch 0091, iter [01900, 02526], lr: 0.000010, loss: 0.3533, CELoss: 0.3533, 
2022-10-16 21:47:40 - train: epoch 0091, iter [02000, 02526], lr: 0.000010, loss: 0.2637, CELoss: 0.2637, 
2022-10-16 21:48:14 - train: epoch 0091, iter [02100, 02526], lr: 0.000010, loss: 0.2742, CELoss: 0.2742, 
2022-10-16 21:48:47 - train: epoch 0091, iter [02200, 02526], lr: 0.000010, loss: 0.3877, CELoss: 0.3877, 
2022-10-16 21:49:21 - train: epoch 0091, iter [02300, 02526], lr: 0.000010, loss: 0.1613, CELoss: 0.1613, 
2022-10-16 21:49:55 - train: epoch 0091, iter [02400, 02526], lr: 0.000010, loss: 0.3641, CELoss: 0.3641, 
2022-10-16 21:50:29 - train: epoch 0091, iter [02500, 02526], lr: 0.000010, loss: 0.2816, CELoss: 0.2816, 
2022-10-16 21:50:39 - train: epoch 091, train_loss: 0.3094
2022-10-16 21:50:41 - until epoch: 091, best_metric: 39.547%
2022-10-16 21:50:41 - epoch 092 lr: 0.000010
2022-10-16 21:51:18 - train: epoch 0092, iter [00100, 02526], lr: 0.000010, loss: 0.2426, CELoss: 0.2426, 
2022-10-16 21:51:52 - train: epoch 0092, iter [00200, 02526], lr: 0.000010, loss: 0.1861, CELoss: 0.1861, 
2022-10-16 21:52:26 - train: epoch 0092, iter [00300, 02526], lr: 0.000010, loss: 0.3383, CELoss: 0.3383, 
2022-10-16 21:52:59 - train: epoch 0092, iter [00400, 02526], lr: 0.000010, loss: 0.2040, CELoss: 0.2040, 
2022-10-16 21:53:33 - train: epoch 0092, iter [00500, 02526], lr: 0.000010, loss: 0.2550, CELoss: 0.2550, 
2022-10-16 21:54:07 - train: epoch 0092, iter [00600, 02526], lr: 0.000010, loss: 0.3671, CELoss: 0.3671, 
2022-10-16 21:54:41 - train: epoch 0092, iter [00700, 02526], lr: 0.000010, loss: 0.1997, CELoss: 0.1997, 
2022-10-16 21:55:15 - train: epoch 0092, iter [00800, 02526], lr: 0.000010, loss: 0.1782, CELoss: 0.1782, 
2022-10-16 21:55:48 - train: epoch 0092, iter [00900, 02526], lr: 0.000010, loss: 0.2230, CELoss: 0.2230, 
2022-10-16 21:56:22 - train: epoch 0092, iter [01000, 02526], lr: 0.000010, loss: 0.2537, CELoss: 0.2537, 
2022-10-16 21:56:56 - train: epoch 0092, iter [01100, 02526], lr: 0.000010, loss: 0.1726, CELoss: 0.1726, 
2022-10-16 21:57:29 - train: epoch 0092, iter [01200, 02526], lr: 0.000010, loss: 0.3965, CELoss: 0.3965, 
2022-10-16 21:58:03 - train: epoch 0092, iter [01300, 02526], lr: 0.000010, loss: 0.3497, CELoss: 0.3497, 
2022-10-16 21:58:37 - train: epoch 0092, iter [01400, 02526], lr: 0.000010, loss: 0.4397, CELoss: 0.4397, 
2022-10-16 21:59:10 - train: epoch 0092, iter [01500, 02526], lr: 0.000010, loss: 0.2106, CELoss: 0.2106, 
2022-10-16 21:59:44 - train: epoch 0092, iter [01600, 02526], lr: 0.000010, loss: 0.2942, CELoss: 0.2942, 
2022-10-16 22:00:18 - train: epoch 0092, iter [01700, 02526], lr: 0.000010, loss: 0.2589, CELoss: 0.2589, 
2022-10-16 22:00:51 - train: epoch 0092, iter [01800, 02526], lr: 0.000010, loss: 0.2731, CELoss: 0.2731, 
2022-10-16 22:01:25 - train: epoch 0092, iter [01900, 02526], lr: 0.000010, loss: 0.4949, CELoss: 0.4949, 
2022-10-16 22:01:59 - train: epoch 0092, iter [02000, 02526], lr: 0.000010, loss: 0.4149, CELoss: 0.4149, 
2022-10-16 22:02:33 - train: epoch 0092, iter [02100, 02526], lr: 0.000010, loss: 0.1470, CELoss: 0.1470, 
2022-10-16 22:03:06 - train: epoch 0092, iter [02200, 02526], lr: 0.000010, loss: 0.2363, CELoss: 0.2363, 
2022-10-16 22:03:40 - train: epoch 0092, iter [02300, 02526], lr: 0.000010, loss: 0.2492, CELoss: 0.2492, 
2022-10-16 22:04:14 - train: epoch 0092, iter [02400, 02526], lr: 0.000010, loss: 0.3141, CELoss: 0.3141, 
2022-10-16 22:04:47 - train: epoch 0092, iter [02500, 02526], lr: 0.000010, loss: 0.2952, CELoss: 0.2952, 
2022-10-16 22:04:57 - train: epoch 092, train_loss: 0.3064
2022-10-16 22:04:59 - until epoch: 092, best_metric: 39.547%
2022-10-16 22:04:59 - epoch 093 lr: 0.000010
2022-10-16 22:05:36 - train: epoch 0093, iter [00100, 02526], lr: 0.000010, loss: 0.3367, CELoss: 0.3367, 
2022-10-16 22:06:10 - train: epoch 0093, iter [00200, 02526], lr: 0.000010, loss: 0.2465, CELoss: 0.2465, 
2022-10-16 22:06:44 - train: epoch 0093, iter [00300, 02526], lr: 0.000010, loss: 0.2385, CELoss: 0.2385, 
2022-10-16 22:07:18 - train: epoch 0093, iter [00400, 02526], lr: 0.000010, loss: 0.1928, CELoss: 0.1928, 
2022-10-16 22:07:52 - train: epoch 0093, iter [00500, 02526], lr: 0.000010, loss: 0.1993, CELoss: 0.1993, 
2022-10-16 22:08:25 - train: epoch 0093, iter [00600, 02526], lr: 0.000010, loss: 0.2683, CELoss: 0.2683, 
2022-10-16 22:08:59 - train: epoch 0093, iter [00700, 02526], lr: 0.000010, loss: 0.2605, CELoss: 0.2605, 
2022-10-16 22:09:33 - train: epoch 0093, iter [00800, 02526], lr: 0.000010, loss: 0.2132, CELoss: 0.2132, 
2022-10-16 22:10:07 - train: epoch 0093, iter [00900, 02526], lr: 0.000010, loss: 0.2990, CELoss: 0.2990, 
2022-10-16 22:10:41 - train: epoch 0093, iter [01000, 02526], lr: 0.000010, loss: 0.3170, CELoss: 0.3170, 
2022-10-16 22:11:14 - train: epoch 0093, iter [01100, 02526], lr: 0.000010, loss: 0.5791, CELoss: 0.5791, 
2022-10-16 22:11:48 - train: epoch 0093, iter [01200, 02526], lr: 0.000010, loss: 0.1792, CELoss: 0.1792, 
2022-10-16 22:12:22 - train: epoch 0093, iter [01300, 02526], lr: 0.000010, loss: 0.3450, CELoss: 0.3450, 
2022-10-16 22:12:56 - train: epoch 0093, iter [01400, 02526], lr: 0.000010, loss: 0.2680, CELoss: 0.2680, 
2022-10-16 22:13:30 - train: epoch 0093, iter [01500, 02526], lr: 0.000010, loss: 0.4432, CELoss: 0.4432, 
2022-10-16 22:14:03 - train: epoch 0093, iter [01600, 02526], lr: 0.000010, loss: 0.2126, CELoss: 0.2126, 
2022-10-16 22:14:37 - train: epoch 0093, iter [01700, 02526], lr: 0.000010, loss: 0.2730, CELoss: 0.2730, 
2022-10-16 22:15:10 - train: epoch 0093, iter [01800, 02526], lr: 0.000010, loss: 0.2037, CELoss: 0.2037, 
2022-10-16 22:15:44 - train: epoch 0093, iter [01900, 02526], lr: 0.000010, loss: 0.1642, CELoss: 0.1642, 
2022-10-16 22:16:18 - train: epoch 0093, iter [02000, 02526], lr: 0.000010, loss: 0.3340, CELoss: 0.3340, 
2022-10-16 22:16:51 - train: epoch 0093, iter [02100, 02526], lr: 0.000010, loss: 0.2763, CELoss: 0.2763, 
2022-10-16 22:17:24 - train: epoch 0093, iter [02200, 02526], lr: 0.000010, loss: 0.3746, CELoss: 0.3746, 
2022-10-16 22:17:58 - train: epoch 0093, iter [02300, 02526], lr: 0.000010, loss: 0.4300, CELoss: 0.4300, 
2022-10-16 22:18:31 - train: epoch 0093, iter [02400, 02526], lr: 0.000010, loss: 0.3031, CELoss: 0.3031, 
2022-10-16 22:19:04 - train: epoch 0093, iter [02500, 02526], lr: 0.000010, loss: 0.2738, CELoss: 0.2738, 
2022-10-16 22:19:14 - train: epoch 093, train_loss: 0.3060
2022-10-16 22:19:17 - until epoch: 093, best_metric: 39.547%
2022-10-16 22:19:17 - epoch 094 lr: 0.000010
2022-10-16 22:19:53 - train: epoch 0094, iter [00100, 02526], lr: 0.000010, loss: 0.3725, CELoss: 0.3725, 
2022-10-16 22:20:27 - train: epoch 0094, iter [00200, 02526], lr: 0.000010, loss: 0.2771, CELoss: 0.2771, 
2022-10-16 22:21:00 - train: epoch 0094, iter [00300, 02526], lr: 0.000010, loss: 0.3134, CELoss: 0.3134, 
2022-10-16 22:21:34 - train: epoch 0094, iter [00400, 02526], lr: 0.000010, loss: 0.1946, CELoss: 0.1946, 
2022-10-16 22:22:07 - train: epoch 0094, iter [00500, 02526], lr: 0.000010, loss: 0.4762, CELoss: 0.4762, 
2022-10-16 22:22:40 - train: epoch 0094, iter [00600, 02526], lr: 0.000010, loss: 0.3110, CELoss: 0.3110, 
2022-10-16 22:23:13 - train: epoch 0094, iter [00700, 02526], lr: 0.000010, loss: 0.2431, CELoss: 0.2431, 
2022-10-16 22:23:47 - train: epoch 0094, iter [00800, 02526], lr: 0.000010, loss: 0.2979, CELoss: 0.2979, 
2022-10-16 22:24:21 - train: epoch 0094, iter [00900, 02526], lr: 0.000010, loss: 0.2193, CELoss: 0.2193, 
2022-10-16 22:24:54 - train: epoch 0094, iter [01000, 02526], lr: 0.000010, loss: 0.1804, CELoss: 0.1804, 
2022-10-16 22:25:28 - train: epoch 0094, iter [01100, 02526], lr: 0.000010, loss: 0.4012, CELoss: 0.4012, 
2022-10-16 22:26:01 - train: epoch 0094, iter [01200, 02526], lr: 0.000010, loss: 0.2536, CELoss: 0.2536, 
2022-10-16 22:26:34 - train: epoch 0094, iter [01300, 02526], lr: 0.000010, loss: 0.2277, CELoss: 0.2277, 
2022-10-16 22:27:08 - train: epoch 0094, iter [01400, 02526], lr: 0.000010, loss: 0.1985, CELoss: 0.1985, 
2022-10-16 22:27:41 - train: epoch 0094, iter [01500, 02526], lr: 0.000010, loss: 0.2495, CELoss: 0.2495, 
2022-10-16 22:28:14 - train: epoch 0094, iter [01600, 02526], lr: 0.000010, loss: 0.3282, CELoss: 0.3282, 
2022-10-16 22:28:47 - train: epoch 0094, iter [01700, 02526], lr: 0.000010, loss: 0.3519, CELoss: 0.3519, 
2022-10-16 22:29:21 - train: epoch 0094, iter [01800, 02526], lr: 0.000010, loss: 0.2901, CELoss: 0.2901, 
2022-10-16 22:29:54 - train: epoch 0094, iter [01900, 02526], lr: 0.000010, loss: 0.2387, CELoss: 0.2387, 
2022-10-16 22:30:27 - train: epoch 0094, iter [02000, 02526], lr: 0.000010, loss: 0.2594, CELoss: 0.2594, 
2022-10-16 22:31:01 - train: epoch 0094, iter [02100, 02526], lr: 0.000010, loss: 0.3190, CELoss: 0.3190, 
2022-10-16 22:31:34 - train: epoch 0094, iter [02200, 02526], lr: 0.000010, loss: 0.3128, CELoss: 0.3128, 
2022-10-16 22:32:08 - train: epoch 0094, iter [02300, 02526], lr: 0.000010, loss: 0.3472, CELoss: 0.3472, 
2022-10-16 22:32:41 - train: epoch 0094, iter [02400, 02526], lr: 0.000010, loss: 0.3428, CELoss: 0.3428, 
2022-10-16 22:33:14 - train: epoch 0094, iter [02500, 02526], lr: 0.000010, loss: 0.2017, CELoss: 0.2017, 
2022-10-16 22:33:24 - train: epoch 094, train_loss: 0.3014
2022-10-16 22:33:26 - until epoch: 094, best_metric: 39.547%
2022-10-16 22:33:26 - epoch 095 lr: 0.000010
2022-10-16 22:34:03 - train: epoch 0095, iter [00100, 02526], lr: 0.000010, loss: 0.4133, CELoss: 0.4133, 
2022-10-16 22:34:36 - train: epoch 0095, iter [00200, 02526], lr: 0.000010, loss: 0.2878, CELoss: 0.2878, 
2022-10-16 22:35:10 - train: epoch 0095, iter [00300, 02526], lr: 0.000010, loss: 0.2690, CELoss: 0.2690, 
2022-10-16 22:35:43 - train: epoch 0095, iter [00400, 02526], lr: 0.000010, loss: 0.3679, CELoss: 0.3679, 
2022-10-16 22:36:16 - train: epoch 0095, iter [00500, 02526], lr: 0.000010, loss: 0.5134, CELoss: 0.5134, 
2022-10-16 22:36:50 - train: epoch 0095, iter [00600, 02526], lr: 0.000010, loss: 0.1744, CELoss: 0.1744, 
2022-10-16 22:37:23 - train: epoch 0095, iter [00700, 02526], lr: 0.000010, loss: 0.1505, CELoss: 0.1505, 
2022-10-16 22:37:57 - train: epoch 0095, iter [00800, 02526], lr: 0.000010, loss: 0.2349, CELoss: 0.2349, 
2022-10-16 22:38:30 - train: epoch 0095, iter [00900, 02526], lr: 0.000010, loss: 0.2915, CELoss: 0.2915, 
2022-10-16 22:39:04 - train: epoch 0095, iter [01000, 02526], lr: 0.000010, loss: 0.2274, CELoss: 0.2274, 
2022-10-16 22:39:38 - train: epoch 0095, iter [01100, 02526], lr: 0.000010, loss: 0.2883, CELoss: 0.2883, 
2022-10-16 22:40:11 - train: epoch 0095, iter [01200, 02526], lr: 0.000010, loss: 0.2721, CELoss: 0.2721, 
2022-10-16 22:40:44 - train: epoch 0095, iter [01300, 02526], lr: 0.000010, loss: 0.2424, CELoss: 0.2424, 
2022-10-16 22:41:18 - train: epoch 0095, iter [01400, 02526], lr: 0.000010, loss: 0.4129, CELoss: 0.4129, 
2022-10-16 22:41:51 - train: epoch 0095, iter [01500, 02526], lr: 0.000010, loss: 0.3235, CELoss: 0.3235, 
2022-10-16 22:42:24 - train: epoch 0095, iter [01600, 02526], lr: 0.000010, loss: 0.3850, CELoss: 0.3850, 
2022-10-16 22:42:58 - train: epoch 0095, iter [01700, 02526], lr: 0.000010, loss: 0.3873, CELoss: 0.3873, 
2022-10-16 22:43:31 - train: epoch 0095, iter [01800, 02526], lr: 0.000010, loss: 0.3838, CELoss: 0.3838, 
2022-10-16 22:44:05 - train: epoch 0095, iter [01900, 02526], lr: 0.000010, loss: 0.3285, CELoss: 0.3285, 
2022-10-16 22:44:38 - train: epoch 0095, iter [02000, 02526], lr: 0.000010, loss: 0.2809, CELoss: 0.2809, 
2022-10-16 22:45:12 - train: epoch 0095, iter [02100, 02526], lr: 0.000010, loss: 0.1879, CELoss: 0.1879, 
2022-10-16 22:45:45 - train: epoch 0095, iter [02200, 02526], lr: 0.000010, loss: 0.3359, CELoss: 0.3359, 
2022-10-16 22:46:19 - train: epoch 0095, iter [02300, 02526], lr: 0.000010, loss: 0.2524, CELoss: 0.2524, 
2022-10-16 22:46:52 - train: epoch 0095, iter [02400, 02526], lr: 0.000010, loss: 0.2483, CELoss: 0.2483, 
2022-10-16 22:47:25 - train: epoch 0095, iter [02500, 02526], lr: 0.000010, loss: 0.2878, CELoss: 0.2878, 
2022-10-16 22:47:35 - train: epoch 095, train_loss: 0.2999
2022-10-16 22:48:26 - eval: epoch: 095
test_loss: 0.8767327182590962
per_image_load_time: 1.710ms
per_image_inference_time: 18.211ms
exist_num_class: 150.0
mean_precision: 60.13283745198985
mean_recall: 50.78113120159965
mean_iou: 39.794813898037596
mean_dice: 53.67195027657622

2022-10-16 22:48:29 - until epoch: 095, best_metric: 39.795%
2022-10-16 22:48:29 - epoch 096 lr: 0.000010
2022-10-16 22:49:06 - train: epoch 0096, iter [00100, 02526], lr: 0.000010, loss: 0.2517, CELoss: 0.2517, 
2022-10-16 22:49:39 - train: epoch 0096, iter [00200, 02526], lr: 0.000010, loss: 0.2469, CELoss: 0.2469, 
2022-10-16 22:50:12 - train: epoch 0096, iter [00300, 02526], lr: 0.000010, loss: 0.2479, CELoss: 0.2479, 
2022-10-16 22:50:46 - train: epoch 0096, iter [00400, 02526], lr: 0.000010, loss: 0.2543, CELoss: 0.2543, 
2022-10-16 22:51:20 - train: epoch 0096, iter [00500, 02526], lr: 0.000010, loss: 0.2237, CELoss: 0.2237, 
2022-10-16 22:51:53 - train: epoch 0096, iter [00600, 02526], lr: 0.000010, loss: 0.1955, CELoss: 0.1955, 
2022-10-16 22:52:26 - train: epoch 0096, iter [00700, 02526], lr: 0.000010, loss: 0.2764, CELoss: 0.2764, 
2022-10-16 22:53:00 - train: epoch 0096, iter [00800, 02526], lr: 0.000010, loss: 0.2908, CELoss: 0.2908, 
2022-10-16 22:53:33 - train: epoch 0096, iter [00900, 02526], lr: 0.000010, loss: 0.3271, CELoss: 0.3271, 
2022-10-16 22:54:06 - train: epoch 0096, iter [01000, 02526], lr: 0.000010, loss: 0.4267, CELoss: 0.4267, 
2022-10-16 22:54:40 - train: epoch 0096, iter [01100, 02526], lr: 0.000010, loss: 0.2638, CELoss: 0.2638, 
2022-10-16 22:55:14 - train: epoch 0096, iter [01200, 02526], lr: 0.000010, loss: 0.2555, CELoss: 0.2555, 
2022-10-16 22:55:47 - train: epoch 0096, iter [01300, 02526], lr: 0.000010, loss: 0.4101, CELoss: 0.4101, 
2022-10-16 22:56:21 - train: epoch 0096, iter [01400, 02526], lr: 0.000010, loss: 0.2982, CELoss: 0.2982, 
2022-10-16 22:56:54 - train: epoch 0096, iter [01500, 02526], lr: 0.000010, loss: 0.3417, CELoss: 0.3417, 
2022-10-16 22:57:27 - train: epoch 0096, iter [01600, 02526], lr: 0.000010, loss: 0.3840, CELoss: 0.3840, 
2022-10-16 22:58:01 - train: epoch 0096, iter [01700, 02526], lr: 0.000010, loss: 0.3324, CELoss: 0.3324, 
2022-10-16 22:58:34 - train: epoch 0096, iter [01800, 02526], lr: 0.000010, loss: 0.4780, CELoss: 0.4780, 
2022-10-16 22:59:08 - train: epoch 0096, iter [01900, 02526], lr: 0.000010, loss: 0.5200, CELoss: 0.5200, 
2022-10-16 22:59:41 - train: epoch 0096, iter [02000, 02526], lr: 0.000010, loss: 0.2555, CELoss: 0.2555, 
2022-10-16 23:00:14 - train: epoch 0096, iter [02100, 02526], lr: 0.000010, loss: 0.2288, CELoss: 0.2288, 
2022-10-16 23:00:48 - train: epoch 0096, iter [02200, 02526], lr: 0.000010, loss: 0.3058, CELoss: 0.3058, 
2022-10-16 23:01:21 - train: epoch 0096, iter [02300, 02526], lr: 0.000010, loss: 0.3051, CELoss: 0.3051, 
2022-10-16 23:01:55 - train: epoch 0096, iter [02400, 02526], lr: 0.000010, loss: 0.1683, CELoss: 0.1683, 
2022-10-16 23:02:28 - train: epoch 0096, iter [02500, 02526], lr: 0.000010, loss: 0.5669, CELoss: 0.5669, 
2022-10-16 23:02:38 - train: epoch 096, train_loss: 0.2987
2022-10-16 23:02:40 - until epoch: 096, best_metric: 39.795%
2022-10-16 23:02:40 - epoch 097 lr: 0.000010
2022-10-16 23:03:16 - train: epoch 0097, iter [00100, 02526], lr: 0.000010, loss: 0.2876, CELoss: 0.2876, 
2022-10-16 23:03:50 - train: epoch 0097, iter [00200, 02526], lr: 0.000010, loss: 0.4826, CELoss: 0.4826, 
2022-10-16 23:04:23 - train: epoch 0097, iter [00300, 02526], lr: 0.000010, loss: 0.3849, CELoss: 0.3849, 
2022-10-16 23:04:57 - train: epoch 0097, iter [00400, 02526], lr: 0.000010, loss: 0.1561, CELoss: 0.1561, 
2022-10-16 23:05:30 - train: epoch 0097, iter [00500, 02526], lr: 0.000010, loss: 0.3204, CELoss: 0.3204, 
2022-10-16 23:06:04 - train: epoch 0097, iter [00600, 02526], lr: 0.000010, loss: 0.2522, CELoss: 0.2522, 
2022-10-16 23:06:37 - train: epoch 0097, iter [00700, 02526], lr: 0.000010, loss: 0.2446, CELoss: 0.2446, 
2022-10-16 23:07:10 - train: epoch 0097, iter [00800, 02526], lr: 0.000010, loss: 0.4413, CELoss: 0.4413, 
2022-10-16 23:07:44 - train: epoch 0097, iter [00900, 02526], lr: 0.000010, loss: 0.2318, CELoss: 0.2318, 
2022-10-16 23:08:17 - train: epoch 0097, iter [01000, 02526], lr: 0.000010, loss: 0.2671, CELoss: 0.2671, 
2022-10-16 23:08:51 - train: epoch 0097, iter [01100, 02526], lr: 0.000010, loss: 0.3293, CELoss: 0.3293, 
2022-10-16 23:09:24 - train: epoch 0097, iter [01200, 02526], lr: 0.000010, loss: 0.3735, CELoss: 0.3735, 
2022-10-16 23:09:57 - train: epoch 0097, iter [01300, 02526], lr: 0.000010, loss: 0.1826, CELoss: 0.1826, 
2022-10-16 23:10:31 - train: epoch 0097, iter [01400, 02526], lr: 0.000010, loss: 0.2621, CELoss: 0.2621, 
2022-10-16 23:11:04 - train: epoch 0097, iter [01500, 02526], lr: 0.000010, loss: 0.3458, CELoss: 0.3458, 
2022-10-16 23:11:38 - train: epoch 0097, iter [01600, 02526], lr: 0.000010, loss: 0.2556, CELoss: 0.2556, 
2022-10-16 23:12:11 - train: epoch 0097, iter [01700, 02526], lr: 0.000010, loss: 0.3557, CELoss: 0.3557, 
2022-10-16 23:12:45 - train: epoch 0097, iter [01800, 02526], lr: 0.000010, loss: 0.3576, CELoss: 0.3576, 
2022-10-16 23:13:18 - train: epoch 0097, iter [01900, 02526], lr: 0.000010, loss: 0.1353, CELoss: 0.1353, 
2022-10-16 23:13:51 - train: epoch 0097, iter [02000, 02526], lr: 0.000010, loss: 0.4266, CELoss: 0.4266, 
2022-10-16 23:14:25 - train: epoch 0097, iter [02100, 02526], lr: 0.000010, loss: 0.2784, CELoss: 0.2784, 
2022-10-16 23:14:58 - train: epoch 0097, iter [02200, 02526], lr: 0.000010, loss: 0.2182, CELoss: 0.2182, 
2022-10-16 23:15:31 - train: epoch 0097, iter [02300, 02526], lr: 0.000010, loss: 0.2632, CELoss: 0.2632, 
2022-10-16 23:16:05 - train: epoch 0097, iter [02400, 02526], lr: 0.000010, loss: 0.2366, CELoss: 0.2366, 
2022-10-16 23:16:38 - train: epoch 0097, iter [02500, 02526], lr: 0.000010, loss: 0.2305, CELoss: 0.2305, 
2022-10-16 23:16:48 - train: epoch 097, train_loss: 0.2966
2022-10-16 23:16:51 - until epoch: 097, best_metric: 39.795%
2022-10-16 23:16:51 - epoch 098 lr: 0.000010
2022-10-16 23:17:27 - train: epoch 0098, iter [00100, 02526], lr: 0.000010, loss: 0.2366, CELoss: 0.2366, 
2022-10-16 23:18:01 - train: epoch 0098, iter [00200, 02526], lr: 0.000010, loss: 0.1846, CELoss: 0.1846, 
2022-10-16 23:18:34 - train: epoch 0098, iter [00300, 02526], lr: 0.000010, loss: 0.1738, CELoss: 0.1738, 
2022-10-16 23:19:08 - train: epoch 0098, iter [00400, 02526], lr: 0.000010, loss: 0.2173, CELoss: 0.2173, 
2022-10-16 23:19:41 - train: epoch 0098, iter [00500, 02526], lr: 0.000010, loss: 0.3084, CELoss: 0.3084, 
2022-10-16 23:20:14 - train: epoch 0098, iter [00600, 02526], lr: 0.000010, loss: 0.3299, CELoss: 0.3299, 
2022-10-16 23:20:48 - train: epoch 0098, iter [00700, 02526], lr: 0.000010, loss: 0.2032, CELoss: 0.2032, 
2022-10-16 23:21:21 - train: epoch 0098, iter [00800, 02526], lr: 0.000010, loss: 0.3905, CELoss: 0.3905, 
2022-10-16 23:21:54 - train: epoch 0098, iter [00900, 02526], lr: 0.000010, loss: 0.2750, CELoss: 0.2750, 
2022-10-16 23:22:28 - train: epoch 0098, iter [01000, 02526], lr: 0.000010, loss: 0.2165, CELoss: 0.2165, 
2022-10-16 23:23:01 - train: epoch 0098, iter [01100, 02526], lr: 0.000010, loss: 0.2197, CELoss: 0.2197, 
2022-10-16 23:23:34 - train: epoch 0098, iter [01200, 02526], lr: 0.000010, loss: 0.6005, CELoss: 0.6005, 
2022-10-16 23:24:07 - train: epoch 0098, iter [01300, 02526], lr: 0.000010, loss: 0.3444, CELoss: 0.3444, 
2022-10-16 23:24:41 - train: epoch 0098, iter [01400, 02526], lr: 0.000010, loss: 0.3335, CELoss: 0.3335, 
2022-10-16 23:25:14 - train: epoch 0098, iter [01500, 02526], lr: 0.000010, loss: 0.3647, CELoss: 0.3647, 
2022-10-16 23:25:47 - train: epoch 0098, iter [01600, 02526], lr: 0.000010, loss: 0.2425, CELoss: 0.2425, 
2022-10-16 23:26:21 - train: epoch 0098, iter [01700, 02526], lr: 0.000010, loss: 0.3626, CELoss: 0.3626, 
2022-10-16 23:26:54 - train: epoch 0098, iter [01800, 02526], lr: 0.000010, loss: 0.1342, CELoss: 0.1342, 
2022-10-16 23:27:27 - train: epoch 0098, iter [01900, 02526], lr: 0.000010, loss: 0.2973, CELoss: 0.2973, 
2022-10-16 23:28:01 - train: epoch 0098, iter [02000, 02526], lr: 0.000010, loss: 0.2141, CELoss: 0.2141, 
2022-10-16 23:28:34 - train: epoch 0098, iter [02100, 02526], lr: 0.000010, loss: 0.3539, CELoss: 0.3539, 
2022-10-16 23:29:07 - train: epoch 0098, iter [02200, 02526], lr: 0.000010, loss: 0.2410, CELoss: 0.2410, 
2022-10-16 23:29:41 - train: epoch 0098, iter [02300, 02526], lr: 0.000010, loss: 0.2519, CELoss: 0.2519, 
2022-10-16 23:30:14 - train: epoch 0098, iter [02400, 02526], lr: 0.000010, loss: 0.2491, CELoss: 0.2491, 
2022-10-16 23:30:48 - train: epoch 0098, iter [02500, 02526], lr: 0.000010, loss: 0.1692, CELoss: 0.1692, 
2022-10-16 23:30:58 - train: epoch 098, train_loss: 0.2942
2022-10-16 23:31:00 - until epoch: 098, best_metric: 39.795%
2022-10-16 23:31:00 - epoch 099 lr: 0.000010
2022-10-16 23:31:37 - train: epoch 0099, iter [00100, 02526], lr: 0.000010, loss: 0.3723, CELoss: 0.3723, 
2022-10-16 23:32:10 - train: epoch 0099, iter [00200, 02526], lr: 0.000010, loss: 0.4122, CELoss: 0.4122, 
2022-10-16 23:32:44 - train: epoch 0099, iter [00300, 02526], lr: 0.000010, loss: 0.2503, CELoss: 0.2503, 
2022-10-16 23:33:17 - train: epoch 0099, iter [00400, 02526], lr: 0.000010, loss: 0.2248, CELoss: 0.2248, 
2022-10-16 23:33:50 - train: epoch 0099, iter [00500, 02526], lr: 0.000010, loss: 0.4849, CELoss: 0.4849, 
2022-10-16 23:34:24 - train: epoch 0099, iter [00600, 02526], lr: 0.000010, loss: 0.2380, CELoss: 0.2380, 
2022-10-16 23:34:58 - train: epoch 0099, iter [00700, 02526], lr: 0.000010, loss: 0.2504, CELoss: 0.2504, 
2022-10-16 23:35:31 - train: epoch 0099, iter [00800, 02526], lr: 0.000010, loss: 0.2465, CELoss: 0.2465, 
2022-10-16 23:36:05 - train: epoch 0099, iter [00900, 02526], lr: 0.000010, loss: 0.2827, CELoss: 0.2827, 
2022-10-16 23:36:38 - train: epoch 0099, iter [01000, 02526], lr: 0.000010, loss: 0.2537, CELoss: 0.2537, 
2022-10-16 23:37:12 - train: epoch 0099, iter [01100, 02526], lr: 0.000010, loss: 0.2110, CELoss: 0.2110, 
2022-10-16 23:37:45 - train: epoch 0099, iter [01200, 02526], lr: 0.000010, loss: 0.2829, CELoss: 0.2829, 
2022-10-16 23:38:18 - train: epoch 0099, iter [01300, 02526], lr: 0.000010, loss: 0.1815, CELoss: 0.1815, 
2022-10-16 23:38:52 - train: epoch 0099, iter [01400, 02526], lr: 0.000010, loss: 0.1807, CELoss: 0.1807, 
2022-10-16 23:39:25 - train: epoch 0099, iter [01500, 02526], lr: 0.000010, loss: 0.1662, CELoss: 0.1662, 
2022-10-16 23:39:59 - train: epoch 0099, iter [01600, 02526], lr: 0.000010, loss: 0.2984, CELoss: 0.2984, 
2022-10-16 23:40:32 - train: epoch 0099, iter [01700, 02526], lr: 0.000010, loss: 0.1877, CELoss: 0.1877, 
2022-10-16 23:41:06 - train: epoch 0099, iter [01800, 02526], lr: 0.000010, loss: 0.2122, CELoss: 0.2122, 
2022-10-16 23:41:39 - train: epoch 0099, iter [01900, 02526], lr: 0.000010, loss: 0.2206, CELoss: 0.2206, 
2022-10-16 23:42:13 - train: epoch 0099, iter [02000, 02526], lr: 0.000010, loss: 0.3395, CELoss: 0.3395, 
2022-10-16 23:42:46 - train: epoch 0099, iter [02100, 02526], lr: 0.000010, loss: 0.2532, CELoss: 0.2532, 
2022-10-16 23:43:19 - train: epoch 0099, iter [02200, 02526], lr: 0.000010, loss: 0.2892, CELoss: 0.2892, 
2022-10-16 23:43:53 - train: epoch 0099, iter [02300, 02526], lr: 0.000010, loss: 0.2830, CELoss: 0.2830, 
2022-10-16 23:44:26 - train: epoch 0099, iter [02400, 02526], lr: 0.000010, loss: 0.3038, CELoss: 0.3038, 
2022-10-16 23:44:59 - train: epoch 0099, iter [02500, 02526], lr: 0.000010, loss: 0.3083, CELoss: 0.3083, 
2022-10-16 23:45:09 - train: epoch 099, train_loss: 0.2914
2022-10-16 23:45:12 - until epoch: 099, best_metric: 39.795%
2022-10-16 23:45:12 - epoch 100 lr: 0.000010
2022-10-16 23:45:48 - train: epoch 0100, iter [00100, 02526], lr: 0.000010, loss: 0.3381, CELoss: 0.3381, 
2022-10-16 23:46:22 - train: epoch 0100, iter [00200, 02526], lr: 0.000010, loss: 0.2757, CELoss: 0.2757, 
2022-10-16 23:46:55 - train: epoch 0100, iter [00300, 02526], lr: 0.000010, loss: 0.1920, CELoss: 0.1920, 
2022-10-16 23:47:29 - train: epoch 0100, iter [00400, 02526], lr: 0.000010, loss: 0.3965, CELoss: 0.3965, 
2022-10-16 23:48:02 - train: epoch 0100, iter [00500, 02526], lr: 0.000010, loss: 0.4039, CELoss: 0.4039, 
2022-10-16 23:48:36 - train: epoch 0100, iter [00600, 02526], lr: 0.000010, loss: 0.3139, CELoss: 0.3139, 
2022-10-16 23:49:09 - train: epoch 0100, iter [00700, 02526], lr: 0.000010, loss: 0.3049, CELoss: 0.3049, 
2022-10-16 23:49:43 - train: epoch 0100, iter [00800, 02526], lr: 0.000010, loss: 0.1927, CELoss: 0.1927, 
2022-10-16 23:50:16 - train: epoch 0100, iter [00900, 02526], lr: 0.000010, loss: 0.1834, CELoss: 0.1834, 
2022-10-16 23:50:49 - train: epoch 0100, iter [01000, 02526], lr: 0.000010, loss: 0.2344, CELoss: 0.2344, 
2022-10-16 23:51:23 - train: epoch 0100, iter [01100, 02526], lr: 0.000010, loss: 0.3232, CELoss: 0.3232, 
2022-10-16 23:51:56 - train: epoch 0100, iter [01200, 02526], lr: 0.000010, loss: 0.2305, CELoss: 0.2305, 
2022-10-16 23:52:30 - train: epoch 0100, iter [01300, 02526], lr: 0.000010, loss: 0.3206, CELoss: 0.3206, 
2022-10-16 23:53:03 - train: epoch 0100, iter [01400, 02526], lr: 0.000010, loss: 0.1381, CELoss: 0.1381, 
2022-10-16 23:53:36 - train: epoch 0100, iter [01500, 02526], lr: 0.000010, loss: 0.4251, CELoss: 0.4251, 
2022-10-16 23:54:10 - train: epoch 0100, iter [01600, 02526], lr: 0.000010, loss: 0.2793, CELoss: 0.2793, 
2022-10-16 23:54:44 - train: epoch 0100, iter [01700, 02526], lr: 0.000010, loss: 0.2267, CELoss: 0.2267, 
2022-10-16 23:55:17 - train: epoch 0100, iter [01800, 02526], lr: 0.000010, loss: 0.2132, CELoss: 0.2132, 
2022-10-16 23:55:50 - train: epoch 0100, iter [01900, 02526], lr: 0.000010, loss: 0.3987, CELoss: 0.3987, 
2022-10-16 23:56:24 - train: epoch 0100, iter [02000, 02526], lr: 0.000010, loss: 0.3480, CELoss: 0.3480, 
2022-10-16 23:56:57 - train: epoch 0100, iter [02100, 02526], lr: 0.000010, loss: 0.2338, CELoss: 0.2338, 
2022-10-16 23:57:30 - train: epoch 0100, iter [02200, 02526], lr: 0.000010, loss: 0.2514, CELoss: 0.2514, 
2022-10-16 23:58:03 - train: epoch 0100, iter [02300, 02526], lr: 0.000010, loss: 0.2073, CELoss: 0.2073, 
2022-10-16 23:58:37 - train: epoch 0100, iter [02400, 02526], lr: 0.000010, loss: 0.2270, CELoss: 0.2270, 
2022-10-16 23:59:10 - train: epoch 0100, iter [02500, 02526], lr: 0.000010, loss: 0.2051, CELoss: 0.2051, 
2022-10-16 23:59:20 - train: epoch 100, train_loss: 0.2897
2022-10-17 00:00:12 - eval: epoch: 100
test_loss: 0.8815562577843666
per_image_load_time: 1.689ms
per_image_inference_time: 18.205ms
exist_num_class: 150.0
mean_precision: 60.87306564914855
mean_recall: 50.920873789034005
mean_iou: 40.073113632999174
mean_dice: 53.919118940622745

2022-10-17 00:00:15 - until epoch: 100, best_metric: 40.073%
2022-10-17 00:00:15 - epoch 101 lr: 0.000010
2022-10-17 00:00:51 - train: epoch 0101, iter [00100, 02526], lr: 0.000010, loss: 0.2231, CELoss: 0.2231, 
2022-10-17 00:01:25 - train: epoch 0101, iter [00200, 02526], lr: 0.000010, loss: 0.2396, CELoss: 0.2396, 
2022-10-17 00:01:58 - train: epoch 0101, iter [00300, 02526], lr: 0.000010, loss: 0.3049, CELoss: 0.3049, 
2022-10-17 00:02:31 - train: epoch 0101, iter [00400, 02526], lr: 0.000010, loss: 0.3829, CELoss: 0.3829, 
2022-10-17 00:03:05 - train: epoch 0101, iter [00500, 02526], lr: 0.000010, loss: 0.5112, CELoss: 0.5112, 
2022-10-17 00:03:39 - train: epoch 0101, iter [00600, 02526], lr: 0.000010, loss: 0.3078, CELoss: 0.3078, 
2022-10-17 00:04:12 - train: epoch 0101, iter [00700, 02526], lr: 0.000010, loss: 0.2966, CELoss: 0.2966, 
2022-10-17 00:04:45 - train: epoch 0101, iter [00800, 02526], lr: 0.000010, loss: 0.4543, CELoss: 0.4543, 
2022-10-17 00:05:19 - train: epoch 0101, iter [00900, 02526], lr: 0.000010, loss: 0.1553, CELoss: 0.1553, 
2022-10-17 00:05:52 - train: epoch 0101, iter [01000, 02526], lr: 0.000010, loss: 0.1425, CELoss: 0.1425, 
2022-10-17 00:06:26 - train: epoch 0101, iter [01100, 02526], lr: 0.000010, loss: 0.2507, CELoss: 0.2507, 
2022-10-17 00:06:59 - train: epoch 0101, iter [01200, 02526], lr: 0.000010, loss: 0.3934, CELoss: 0.3934, 
2022-10-17 00:07:33 - train: epoch 0101, iter [01300, 02526], lr: 0.000010, loss: 0.2414, CELoss: 0.2414, 
2022-10-17 00:08:06 - train: epoch 0101, iter [01400, 02526], lr: 0.000010, loss: 0.2249, CELoss: 0.2249, 
2022-10-17 00:08:39 - train: epoch 0101, iter [01500, 02526], lr: 0.000010, loss: 0.1716, CELoss: 0.1716, 
2022-10-17 00:09:13 - train: epoch 0101, iter [01600, 02526], lr: 0.000010, loss: 0.2123, CELoss: 0.2123, 
2022-10-17 00:09:46 - train: epoch 0101, iter [01700, 02526], lr: 0.000010, loss: 0.4302, CELoss: 0.4302, 
2022-10-17 00:10:20 - train: epoch 0101, iter [01800, 02526], lr: 0.000010, loss: 0.1924, CELoss: 0.1924, 
2022-10-17 00:10:53 - train: epoch 0101, iter [01900, 02526], lr: 0.000010, loss: 0.4231, CELoss: 0.4231, 
2022-10-17 00:11:26 - train: epoch 0101, iter [02000, 02526], lr: 0.000010, loss: 0.3829, CELoss: 0.3829, 
2022-10-17 00:11:59 - train: epoch 0101, iter [02100, 02526], lr: 0.000010, loss: 0.3340, CELoss: 0.3340, 
2022-10-17 00:12:33 - train: epoch 0101, iter [02200, 02526], lr: 0.000010, loss: 0.2268, CELoss: 0.2268, 
2022-10-17 00:13:06 - train: epoch 0101, iter [02300, 02526], lr: 0.000010, loss: 0.2460, CELoss: 0.2460, 
2022-10-17 00:13:40 - train: epoch 0101, iter [02400, 02526], lr: 0.000010, loss: 0.2829, CELoss: 0.2829, 
2022-10-17 00:14:13 - train: epoch 0101, iter [02500, 02526], lr: 0.000010, loss: 0.2764, CELoss: 0.2764, 
2022-10-17 00:14:23 - train: epoch 101, train_loss: 0.2903
2022-10-17 00:14:25 - until epoch: 101, best_metric: 40.073%
2022-10-17 00:14:25 - epoch 102 lr: 0.000010
2022-10-17 00:15:02 - train: epoch 0102, iter [00100, 02526], lr: 0.000010, loss: 0.3684, CELoss: 0.3684, 
2022-10-17 00:15:35 - train: epoch 0102, iter [00200, 02526], lr: 0.000010, loss: 0.1220, CELoss: 0.1220, 
2022-10-17 00:16:09 - train: epoch 0102, iter [00300, 02526], lr: 0.000010, loss: 0.3456, CELoss: 0.3456, 
2022-10-17 00:16:43 - train: epoch 0102, iter [00400, 02526], lr: 0.000010, loss: 0.3910, CELoss: 0.3910, 
2022-10-17 00:17:16 - train: epoch 0102, iter [00500, 02526], lr: 0.000010, loss: 0.2915, CELoss: 0.2915, 
2022-10-17 00:17:50 - train: epoch 0102, iter [00600, 02526], lr: 0.000010, loss: 0.2349, CELoss: 0.2349, 
2022-10-17 00:18:23 - train: epoch 0102, iter [00700, 02526], lr: 0.000010, loss: 0.3714, CELoss: 0.3714, 
2022-10-17 00:18:57 - train: epoch 0102, iter [00800, 02526], lr: 0.000010, loss: 0.2589, CELoss: 0.2589, 
2022-10-17 00:19:30 - train: epoch 0102, iter [00900, 02526], lr: 0.000010, loss: 0.1780, CELoss: 0.1780, 
2022-10-17 00:20:03 - train: epoch 0102, iter [01000, 02526], lr: 0.000010, loss: 0.2988, CELoss: 0.2988, 
2022-10-17 00:20:37 - train: epoch 0102, iter [01100, 02526], lr: 0.000010, loss: 0.3329, CELoss: 0.3329, 
2022-10-17 00:21:10 - train: epoch 0102, iter [01200, 02526], lr: 0.000010, loss: 0.3074, CELoss: 0.3074, 
2022-10-17 00:21:44 - train: epoch 0102, iter [01300, 02526], lr: 0.000010, loss: 0.2748, CELoss: 0.2748, 
2022-10-17 00:22:17 - train: epoch 0102, iter [01400, 02526], lr: 0.000010, loss: 0.4093, CELoss: 0.4093, 
2022-10-17 00:22:51 - train: epoch 0102, iter [01500, 02526], lr: 0.000010, loss: 0.3203, CELoss: 0.3203, 
2022-10-17 00:23:24 - train: epoch 0102, iter [01600, 02526], lr: 0.000010, loss: 0.2001, CELoss: 0.2001, 
2022-10-17 00:23:57 - train: epoch 0102, iter [01700, 02526], lr: 0.000010, loss: 0.2154, CELoss: 0.2154, 
2022-10-17 00:24:31 - train: epoch 0102, iter [01800, 02526], lr: 0.000010, loss: 0.2362, CELoss: 0.2362, 
2022-10-17 00:25:04 - train: epoch 0102, iter [01900, 02526], lr: 0.000010, loss: 0.2663, CELoss: 0.2663, 
2022-10-17 00:25:37 - train: epoch 0102, iter [02000, 02526], lr: 0.000010, loss: 0.2691, CELoss: 0.2691, 
2022-10-17 00:26:11 - train: epoch 0102, iter [02100, 02526], lr: 0.000010, loss: 0.2553, CELoss: 0.2553, 
2022-10-17 00:26:44 - train: epoch 0102, iter [02200, 02526], lr: 0.000010, loss: 0.2059, CELoss: 0.2059, 
2022-10-17 00:27:18 - train: epoch 0102, iter [02300, 02526], lr: 0.000010, loss: 0.1621, CELoss: 0.1621, 
2022-10-17 00:27:51 - train: epoch 0102, iter [02400, 02526], lr: 0.000010, loss: 0.2915, CELoss: 0.2915, 
2022-10-17 00:28:24 - train: epoch 0102, iter [02500, 02526], lr: 0.000010, loss: 0.4955, CELoss: 0.4955, 
2022-10-17 00:28:34 - train: epoch 102, train_loss: 0.2873
2022-10-17 00:28:35 - until epoch: 102, best_metric: 40.073%
2022-10-17 00:28:35 - epoch 103 lr: 0.000010
2022-10-17 00:29:12 - train: epoch 0103, iter [00100, 02526], lr: 0.000010, loss: 0.3384, CELoss: 0.3384, 
2022-10-17 00:29:45 - train: epoch 0103, iter [00200, 02526], lr: 0.000010, loss: 0.5403, CELoss: 0.5403, 
2022-10-17 00:30:18 - train: epoch 0103, iter [00300, 02526], lr: 0.000010, loss: 0.3963, CELoss: 0.3963, 
2022-10-17 00:30:52 - train: epoch 0103, iter [00400, 02526], lr: 0.000010, loss: 0.2593, CELoss: 0.2593, 
2022-10-17 00:31:26 - train: epoch 0103, iter [00500, 02526], lr: 0.000010, loss: 0.2600, CELoss: 0.2600, 
2022-10-17 00:31:59 - train: epoch 0103, iter [00600, 02526], lr: 0.000010, loss: 0.3546, CELoss: 0.3546, 
2022-10-17 00:32:32 - train: epoch 0103, iter [00700, 02526], lr: 0.000010, loss: 0.2123, CELoss: 0.2123, 
2022-10-17 00:33:06 - train: epoch 0103, iter [00800, 02526], lr: 0.000010, loss: 0.4730, CELoss: 0.4730, 
2022-10-17 00:33:40 - train: epoch 0103, iter [00900, 02526], lr: 0.000010, loss: 0.2069, CELoss: 0.2069, 
2022-10-17 00:34:13 - train: epoch 0103, iter [01000, 02526], lr: 0.000010, loss: 0.2749, CELoss: 0.2749, 
2022-10-17 00:34:46 - train: epoch 0103, iter [01100, 02526], lr: 0.000010, loss: 0.2008, CELoss: 0.2008, 
2022-10-17 00:35:19 - train: epoch 0103, iter [01200, 02526], lr: 0.000010, loss: 0.2790, CELoss: 0.2790, 
2022-10-17 00:35:53 - train: epoch 0103, iter [01300, 02526], lr: 0.000010, loss: 0.2111, CELoss: 0.2111, 
2022-10-17 00:36:26 - train: epoch 0103, iter [01400, 02526], lr: 0.000010, loss: 0.2718, CELoss: 0.2718, 
2022-10-17 00:37:00 - train: epoch 0103, iter [01500, 02526], lr: 0.000010, loss: 0.1703, CELoss: 0.1703, 
2022-10-17 00:37:33 - train: epoch 0103, iter [01600, 02526], lr: 0.000010, loss: 0.1645, CELoss: 0.1645, 
2022-10-17 00:38:07 - train: epoch 0103, iter [01700, 02526], lr: 0.000010, loss: 0.1454, CELoss: 0.1454, 
2022-10-17 00:38:40 - train: epoch 0103, iter [01800, 02526], lr: 0.000010, loss: 0.3241, CELoss: 0.3241, 
2022-10-17 00:39:13 - train: epoch 0103, iter [01900, 02526], lr: 0.000010, loss: 0.2389, CELoss: 0.2389, 
2022-10-17 00:39:47 - train: epoch 0103, iter [02000, 02526], lr: 0.000010, loss: 0.1477, CELoss: 0.1477, 
2022-10-17 00:40:20 - train: epoch 0103, iter [02100, 02526], lr: 0.000010, loss: 0.4060, CELoss: 0.4060, 
2022-10-17 00:40:54 - train: epoch 0103, iter [02200, 02526], lr: 0.000010, loss: 0.1198, CELoss: 0.1198, 
2022-10-17 00:41:27 - train: epoch 0103, iter [02300, 02526], lr: 0.000010, loss: 0.2479, CELoss: 0.2479, 
2022-10-17 00:42:01 - train: epoch 0103, iter [02400, 02526], lr: 0.000010, loss: 0.4089, CELoss: 0.4089, 
2022-10-17 00:42:35 - train: epoch 0103, iter [02500, 02526], lr: 0.000010, loss: 0.7743, CELoss: 0.7743, 
2022-10-17 00:42:44 - train: epoch 103, train_loss: 0.2857
2022-10-17 00:42:47 - until epoch: 103, best_metric: 40.073%
2022-10-17 00:42:47 - epoch 104 lr: 0.000010
2022-10-17 00:43:23 - train: epoch 0104, iter [00100, 02526], lr: 0.000010, loss: 0.1983, CELoss: 0.1983, 
2022-10-17 00:43:57 - train: epoch 0104, iter [00200, 02526], lr: 0.000010, loss: 0.3854, CELoss: 0.3854, 
2022-10-17 00:44:30 - train: epoch 0104, iter [00300, 02526], lr: 0.000010, loss: 0.2124, CELoss: 0.2124, 
2022-10-17 00:45:04 - train: epoch 0104, iter [00400, 02526], lr: 0.000010, loss: 0.2925, CELoss: 0.2925, 
2022-10-17 00:45:37 - train: epoch 0104, iter [00500, 02526], lr: 0.000010, loss: 0.2479, CELoss: 0.2479, 
2022-10-17 00:46:10 - train: epoch 0104, iter [00600, 02526], lr: 0.000010, loss: 0.3448, CELoss: 0.3448, 
2022-10-17 00:46:44 - train: epoch 0104, iter [00700, 02526], lr: 0.000010, loss: 0.2890, CELoss: 0.2890, 
2022-10-17 00:47:17 - train: epoch 0104, iter [00800, 02526], lr: 0.000010, loss: 0.2504, CELoss: 0.2504, 
2022-10-17 00:47:50 - train: epoch 0104, iter [00900, 02526], lr: 0.000010, loss: 0.2984, CELoss: 0.2984, 
2022-10-17 00:48:24 - train: epoch 0104, iter [01000, 02526], lr: 0.000010, loss: 0.2255, CELoss: 0.2255, 
2022-10-17 00:48:57 - train: epoch 0104, iter [01100, 02526], lr: 0.000010, loss: 0.2360, CELoss: 0.2360, 
2022-10-17 00:49:31 - train: epoch 0104, iter [01200, 02526], lr: 0.000010, loss: 0.2201, CELoss: 0.2201, 
2022-10-17 00:50:04 - train: epoch 0104, iter [01300, 02526], lr: 0.000010, loss: 0.3786, CELoss: 0.3786, 
2022-10-17 00:50:38 - train: epoch 0104, iter [01400, 02526], lr: 0.000010, loss: 0.2996, CELoss: 0.2996, 
2022-10-17 00:51:11 - train: epoch 0104, iter [01500, 02526], lr: 0.000010, loss: 0.2990, CELoss: 0.2990, 
2022-10-17 00:51:45 - train: epoch 0104, iter [01600, 02526], lr: 0.000010, loss: 0.2955, CELoss: 0.2955, 
2022-10-17 00:52:18 - train: epoch 0104, iter [01700, 02526], lr: 0.000010, loss: 0.4116, CELoss: 0.4116, 
2022-10-17 00:52:52 - train: epoch 0104, iter [01800, 02526], lr: 0.000010, loss: 0.2686, CELoss: 0.2686, 
2022-10-17 00:53:25 - train: epoch 0104, iter [01900, 02526], lr: 0.000010, loss: 0.2033, CELoss: 0.2033, 
2022-10-17 00:53:58 - train: epoch 0104, iter [02000, 02526], lr: 0.000010, loss: 0.1937, CELoss: 0.1937, 
2022-10-17 00:54:31 - train: epoch 0104, iter [02100, 02526], lr: 0.000010, loss: 0.2428, CELoss: 0.2428, 
2022-10-17 00:55:05 - train: epoch 0104, iter [02200, 02526], lr: 0.000010, loss: 0.2423, CELoss: 0.2423, 
2022-10-17 00:55:39 - train: epoch 0104, iter [02300, 02526], lr: 0.000010, loss: 0.1943, CELoss: 0.1943, 
2022-10-17 00:56:12 - train: epoch 0104, iter [02400, 02526], lr: 0.000010, loss: 0.2962, CELoss: 0.2962, 
2022-10-17 00:56:46 - train: epoch 0104, iter [02500, 02526], lr: 0.000010, loss: 0.2119, CELoss: 0.2119, 
2022-10-17 00:56:56 - train: epoch 104, train_loss: 0.2857
2022-10-17 00:56:58 - until epoch: 104, best_metric: 40.073%
2022-10-17 00:56:58 - epoch 105 lr: 0.000010
2022-10-17 00:57:35 - train: epoch 0105, iter [00100, 02526], lr: 0.000010, loss: 0.4025, CELoss: 0.4025, 
2022-10-17 00:58:08 - train: epoch 0105, iter [00200, 02526], lr: 0.000010, loss: 0.4633, CELoss: 0.4633, 
2022-10-17 00:58:41 - train: epoch 0105, iter [00300, 02526], lr: 0.000010, loss: 0.3487, CELoss: 0.3487, 
2022-10-17 00:59:14 - train: epoch 0105, iter [00400, 02526], lr: 0.000010, loss: 0.2478, CELoss: 0.2478, 
2022-10-17 00:59:48 - train: epoch 0105, iter [00500, 02526], lr: 0.000010, loss: 0.5341, CELoss: 0.5341, 
2022-10-17 01:00:21 - train: epoch 0105, iter [00600, 02526], lr: 0.000010, loss: 0.4490, CELoss: 0.4490, 
2022-10-17 01:00:55 - train: epoch 0105, iter [00700, 02526], lr: 0.000010, loss: 0.2421, CELoss: 0.2421, 
2022-10-17 01:01:28 - train: epoch 0105, iter [00800, 02526], lr: 0.000010, loss: 0.2242, CELoss: 0.2242, 
2022-10-17 01:02:02 - train: epoch 0105, iter [00900, 02526], lr: 0.000010, loss: 0.3202, CELoss: 0.3202, 
2022-10-17 01:02:35 - train: epoch 0105, iter [01000, 02526], lr: 0.000010, loss: 0.3014, CELoss: 0.3014, 
2022-10-17 01:03:08 - train: epoch 0105, iter [01100, 02526], lr: 0.000010, loss: 0.2323, CELoss: 0.2323, 
2022-10-17 01:03:42 - train: epoch 0105, iter [01200, 02526], lr: 0.000010, loss: 0.2281, CELoss: 0.2281, 
2022-10-17 01:04:16 - train: epoch 0105, iter [01300, 02526], lr: 0.000010, loss: 0.2741, CELoss: 0.2741, 
2022-10-17 01:04:49 - train: epoch 0105, iter [01400, 02526], lr: 0.000010, loss: 0.2652, CELoss: 0.2652, 
2022-10-17 01:05:22 - train: epoch 0105, iter [01500, 02526], lr: 0.000010, loss: 0.2658, CELoss: 0.2658, 
2022-10-17 01:05:55 - train: epoch 0105, iter [01600, 02526], lr: 0.000010, loss: 0.2290, CELoss: 0.2290, 
2022-10-17 01:06:29 - train: epoch 0105, iter [01700, 02526], lr: 0.000010, loss: 0.2029, CELoss: 0.2029, 
2022-10-17 01:07:02 - train: epoch 0105, iter [01800, 02526], lr: 0.000010, loss: 0.3010, CELoss: 0.3010, 
2022-10-17 01:07:35 - train: epoch 0105, iter [01900, 02526], lr: 0.000010, loss: 0.2741, CELoss: 0.2741, 
2022-10-17 01:08:09 - train: epoch 0105, iter [02000, 02526], lr: 0.000010, loss: 0.2737, CELoss: 0.2737, 
2022-10-17 01:08:42 - train: epoch 0105, iter [02100, 02526], lr: 0.000010, loss: 0.2518, CELoss: 0.2518, 
2022-10-17 01:09:15 - train: epoch 0105, iter [02200, 02526], lr: 0.000010, loss: 0.2839, CELoss: 0.2839, 
2022-10-17 01:09:49 - train: epoch 0105, iter [02300, 02526], lr: 0.000010, loss: 0.2370, CELoss: 0.2370, 
2022-10-17 01:10:22 - train: epoch 0105, iter [02400, 02526], lr: 0.000010, loss: 0.3028, CELoss: 0.3028, 
2022-10-17 01:10:56 - train: epoch 0105, iter [02500, 02526], lr: 0.000010, loss: 0.2931, CELoss: 0.2931, 
2022-10-17 01:11:06 - train: epoch 105, train_loss: 0.2843
2022-10-17 01:11:57 - eval: epoch: 105
test_loss: 0.8905872518718243
per_image_load_time: 1.667ms
per_image_inference_time: 18.213ms
exist_num_class: 150.0
mean_precision: 60.94100479611715
mean_recall: 50.87722794302487
mean_iou: 40.22850509853412
mean_dice: 54.049325720418324

2022-10-17 01:12:00 - until epoch: 105, best_metric: 40.229%
2022-10-17 01:12:00 - epoch 106 lr: 0.000010
2022-10-17 01:12:37 - train: epoch 0106, iter [00100, 02526], lr: 0.000010, loss: 0.2921, CELoss: 0.2921, 
2022-10-17 01:13:10 - train: epoch 0106, iter [00200, 02526], lr: 0.000010, loss: 0.2480, CELoss: 0.2480, 
2022-10-17 01:13:44 - train: epoch 0106, iter [00300, 02526], lr: 0.000010, loss: 0.3076, CELoss: 0.3076, 
2022-10-17 01:14:17 - train: epoch 0106, iter [00400, 02526], lr: 0.000010, loss: 0.4461, CELoss: 0.4461, 
2022-10-17 01:14:51 - train: epoch 0106, iter [00500, 02526], lr: 0.000010, loss: 0.2372, CELoss: 0.2372, 
2022-10-17 01:15:24 - train: epoch 0106, iter [00600, 02526], lr: 0.000010, loss: 0.2929, CELoss: 0.2929, 
2022-10-17 01:15:58 - train: epoch 0106, iter [00700, 02526], lr: 0.000010, loss: 0.2485, CELoss: 0.2485, 
2022-10-17 01:16:32 - train: epoch 0106, iter [00800, 02526], lr: 0.000010, loss: 0.2386, CELoss: 0.2386, 
2022-10-17 01:17:05 - train: epoch 0106, iter [00900, 02526], lr: 0.000010, loss: 0.2652, CELoss: 0.2652, 
2022-10-17 01:17:38 - train: epoch 0106, iter [01000, 02526], lr: 0.000010, loss: 0.2134, CELoss: 0.2134, 
2022-10-17 01:18:11 - train: epoch 0106, iter [01100, 02526], lr: 0.000010, loss: 0.2093, CELoss: 0.2093, 
2022-10-17 01:18:45 - train: epoch 0106, iter [01200, 02526], lr: 0.000010, loss: 0.3201, CELoss: 0.3201, 
2022-10-17 01:19:18 - train: epoch 0106, iter [01300, 02526], lr: 0.000010, loss: 0.2083, CELoss: 0.2083, 
2022-10-17 01:19:51 - train: epoch 0106, iter [01400, 02526], lr: 0.000010, loss: 0.2255, CELoss: 0.2255, 
2022-10-17 01:20:25 - train: epoch 0106, iter [01500, 02526], lr: 0.000010, loss: 0.1769, CELoss: 0.1769, 
2022-10-17 01:20:58 - train: epoch 0106, iter [01600, 02526], lr: 0.000010, loss: 0.2604, CELoss: 0.2604, 
2022-10-17 01:21:32 - train: epoch 0106, iter [01700, 02526], lr: 0.000010, loss: 0.1738, CELoss: 0.1738, 
2022-10-17 01:22:06 - train: epoch 0106, iter [01800, 02526], lr: 0.000010, loss: 0.2083, CELoss: 0.2083, 
2022-10-17 01:22:39 - train: epoch 0106, iter [01900, 02526], lr: 0.000010, loss: 0.2240, CELoss: 0.2240, 
2022-10-17 01:23:13 - train: epoch 0106, iter [02000, 02526], lr: 0.000010, loss: 0.2512, CELoss: 0.2512, 
2022-10-17 01:23:46 - train: epoch 0106, iter [02100, 02526], lr: 0.000010, loss: 0.1648, CELoss: 0.1648, 
2022-10-17 01:24:20 - train: epoch 0106, iter [02200, 02526], lr: 0.000010, loss: 0.2439, CELoss: 0.2439, 
2022-10-17 01:24:53 - train: epoch 0106, iter [02300, 02526], lr: 0.000010, loss: 0.2581, CELoss: 0.2581, 
2022-10-17 01:25:27 - train: epoch 0106, iter [02400, 02526], lr: 0.000010, loss: 0.2829, CELoss: 0.2829, 
2022-10-17 01:26:00 - train: epoch 0106, iter [02500, 02526], lr: 0.000010, loss: 0.3709, CELoss: 0.3709, 
2022-10-17 01:26:10 - train: epoch 106, train_loss: 0.2796
2022-10-17 01:26:11 - until epoch: 106, best_metric: 40.229%
2022-10-17 01:26:11 - epoch 107 lr: 0.000010
2022-10-17 01:26:48 - train: epoch 0107, iter [00100, 02526], lr: 0.000010, loss: 0.2860, CELoss: 0.2860, 
2022-10-17 01:27:22 - train: epoch 0107, iter [00200, 02526], lr: 0.000010, loss: 0.3527, CELoss: 0.3527, 
2022-10-17 01:27:55 - train: epoch 0107, iter [00300, 02526], lr: 0.000010, loss: 0.3018, CELoss: 0.3018, 
2022-10-17 01:28:28 - train: epoch 0107, iter [00400, 02526], lr: 0.000010, loss: 0.3043, CELoss: 0.3043, 
2022-10-17 01:29:02 - train: epoch 0107, iter [00500, 02526], lr: 0.000010, loss: 0.1598, CELoss: 0.1598, 
2022-10-17 01:29:35 - train: epoch 0107, iter [00600, 02526], lr: 0.000010, loss: 0.1815, CELoss: 0.1815, 
2022-10-17 01:30:09 - train: epoch 0107, iter [00700, 02526], lr: 0.000010, loss: 0.1642, CELoss: 0.1642, 
2022-10-17 01:30:42 - train: epoch 0107, iter [00800, 02526], lr: 0.000010, loss: 0.2787, CELoss: 0.2787, 
2022-10-17 01:31:16 - train: epoch 0107, iter [00900, 02526], lr: 0.000010, loss: 0.4877, CELoss: 0.4877, 
2022-10-17 01:31:49 - train: epoch 0107, iter [01000, 02526], lr: 0.000010, loss: 0.3017, CELoss: 0.3017, 
2022-10-17 01:32:23 - train: epoch 0107, iter [01100, 02526], lr: 0.000010, loss: 0.2124, CELoss: 0.2124, 
2022-10-17 01:32:56 - train: epoch 0107, iter [01200, 02526], lr: 0.000010, loss: 0.3860, CELoss: 0.3860, 
2022-10-17 01:33:30 - train: epoch 0107, iter [01300, 02526], lr: 0.000010, loss: 0.2255, CELoss: 0.2255, 
2022-10-17 01:34:03 - train: epoch 0107, iter [01400, 02526], lr: 0.000010, loss: 0.3872, CELoss: 0.3872, 
2022-10-17 01:34:37 - train: epoch 0107, iter [01500, 02526], lr: 0.000010, loss: 0.1909, CELoss: 0.1909, 
2022-10-17 01:35:10 - train: epoch 0107, iter [01600, 02526], lr: 0.000010, loss: 0.2742, CELoss: 0.2742, 
2022-10-17 01:35:44 - train: epoch 0107, iter [01700, 02526], lr: 0.000010, loss: 0.3828, CELoss: 0.3828, 
2022-10-17 01:36:17 - train: epoch 0107, iter [01800, 02526], lr: 0.000010, loss: 0.2451, CELoss: 0.2451, 
2022-10-17 01:36:50 - train: epoch 0107, iter [01900, 02526], lr: 0.000010, loss: 0.2266, CELoss: 0.2266, 
2022-10-17 01:37:24 - train: epoch 0107, iter [02000, 02526], lr: 0.000010, loss: 0.1542, CELoss: 0.1542, 
2022-10-17 01:37:57 - train: epoch 0107, iter [02100, 02526], lr: 0.000010, loss: 0.2688, CELoss: 0.2688, 
2022-10-17 01:38:30 - train: epoch 0107, iter [02200, 02526], lr: 0.000010, loss: 0.1341, CELoss: 0.1341, 
2022-10-17 01:39:04 - train: epoch 0107, iter [02300, 02526], lr: 0.000010, loss: 0.3054, CELoss: 0.3054, 
2022-10-17 01:39:37 - train: epoch 0107, iter [02400, 02526], lr: 0.000010, loss: 0.1647, CELoss: 0.1647, 
2022-10-17 01:40:11 - train: epoch 0107, iter [02500, 02526], lr: 0.000010, loss: 0.2286, CELoss: 0.2286, 
2022-10-17 01:40:21 - train: epoch 107, train_loss: 0.2788
2022-10-17 01:40:23 - until epoch: 107, best_metric: 40.229%
2022-10-17 01:40:23 - epoch 108 lr: 0.000010
2022-10-17 01:41:00 - train: epoch 0108, iter [00100, 02526], lr: 0.000010, loss: 0.2634, CELoss: 0.2634, 
2022-10-17 01:41:33 - train: epoch 0108, iter [00200, 02526], lr: 0.000010, loss: 0.2455, CELoss: 0.2455, 
2022-10-17 01:42:07 - train: epoch 0108, iter [00300, 02526], lr: 0.000010, loss: 0.2929, CELoss: 0.2929, 
2022-10-17 01:42:40 - train: epoch 0108, iter [00400, 02526], lr: 0.000010, loss: 0.2846, CELoss: 0.2846, 
2022-10-17 01:43:14 - train: epoch 0108, iter [00500, 02526], lr: 0.000010, loss: 0.2871, CELoss: 0.2871, 
2022-10-17 01:43:47 - train: epoch 0108, iter [00600, 02526], lr: 0.000010, loss: 0.3099, CELoss: 0.3099, 
2022-10-17 01:44:20 - train: epoch 0108, iter [00700, 02526], lr: 0.000010, loss: 0.1366, CELoss: 0.1366, 
2022-10-17 01:44:54 - train: epoch 0108, iter [00800, 02526], lr: 0.000010, loss: 0.2813, CELoss: 0.2813, 
2022-10-17 01:45:27 - train: epoch 0108, iter [00900, 02526], lr: 0.000010, loss: 0.2350, CELoss: 0.2350, 
2022-10-17 01:46:01 - train: epoch 0108, iter [01000, 02526], lr: 0.000010, loss: 0.2939, CELoss: 0.2939, 
2022-10-17 01:46:34 - train: epoch 0108, iter [01100, 02526], lr: 0.000010, loss: 0.2236, CELoss: 0.2236, 
2022-10-17 01:47:08 - train: epoch 0108, iter [01200, 02526], lr: 0.000010, loss: 0.3164, CELoss: 0.3164, 
2022-10-17 01:47:41 - train: epoch 0108, iter [01300, 02526], lr: 0.000010, loss: 0.3471, CELoss: 0.3471, 
2022-10-17 01:48:14 - train: epoch 0108, iter [01400, 02526], lr: 0.000010, loss: 0.3218, CELoss: 0.3218, 
2022-10-17 01:48:48 - train: epoch 0108, iter [01500, 02526], lr: 0.000010, loss: 0.1556, CELoss: 0.1556, 
2022-10-17 01:49:21 - train: epoch 0108, iter [01600, 02526], lr: 0.000010, loss: 0.3506, CELoss: 0.3506, 
2022-10-17 01:49:54 - train: epoch 0108, iter [01700, 02526], lr: 0.000010, loss: 0.2355, CELoss: 0.2355, 
2022-10-17 01:50:28 - train: epoch 0108, iter [01800, 02526], lr: 0.000010, loss: 0.3730, CELoss: 0.3730, 
2022-10-17 01:51:02 - train: epoch 0108, iter [01900, 02526], lr: 0.000010, loss: 0.2845, CELoss: 0.2845, 
2022-10-17 01:51:35 - train: epoch 0108, iter [02000, 02526], lr: 0.000010, loss: 0.3848, CELoss: 0.3848, 
2022-10-17 01:52:08 - train: epoch 0108, iter [02100, 02526], lr: 0.000010, loss: 0.2410, CELoss: 0.2410, 
2022-10-17 01:52:42 - train: epoch 0108, iter [02200, 02526], lr: 0.000010, loss: 0.1496, CELoss: 0.1496, 
2022-10-17 01:53:15 - train: epoch 0108, iter [02300, 02526], lr: 0.000010, loss: 0.2761, CELoss: 0.2761, 
2022-10-17 01:53:49 - train: epoch 0108, iter [02400, 02526], lr: 0.000010, loss: 0.2950, CELoss: 0.2950, 
2022-10-17 01:54:22 - train: epoch 0108, iter [02500, 02526], lr: 0.000010, loss: 0.1872, CELoss: 0.1872, 
2022-10-17 01:54:32 - train: epoch 108, train_loss: 0.2770
2022-10-17 01:54:34 - until epoch: 108, best_metric: 40.229%
2022-10-17 01:54:34 - epoch 109 lr: 0.000010
2022-10-17 01:55:11 - train: epoch 0109, iter [00100, 02526], lr: 0.000010, loss: 0.3449, CELoss: 0.3449, 
2022-10-17 01:55:44 - train: epoch 0109, iter [00200, 02526], lr: 0.000010, loss: 0.1716, CELoss: 0.1716, 
2022-10-17 01:56:18 - train: epoch 0109, iter [00300, 02526], lr: 0.000010, loss: 0.3186, CELoss: 0.3186, 
2022-10-17 01:56:51 - train: epoch 0109, iter [00400, 02526], lr: 0.000010, loss: 0.2137, CELoss: 0.2137, 
2022-10-17 01:57:25 - train: epoch 0109, iter [00500, 02526], lr: 0.000010, loss: 0.2532, CELoss: 0.2532, 
2022-10-17 01:57:58 - train: epoch 0109, iter [00600, 02526], lr: 0.000010, loss: 0.2806, CELoss: 0.2806, 
2022-10-17 01:58:32 - train: epoch 0109, iter [00700, 02526], lr: 0.000010, loss: 0.3850, CELoss: 0.3850, 
2022-10-17 01:59:05 - train: epoch 0109, iter [00800, 02526], lr: 0.000010, loss: 0.1964, CELoss: 0.1964, 
2022-10-17 01:59:38 - train: epoch 0109, iter [00900, 02526], lr: 0.000010, loss: 0.3278, CELoss: 0.3278, 
2022-10-17 02:00:12 - train: epoch 0109, iter [01000, 02526], lr: 0.000010, loss: 0.2061, CELoss: 0.2061, 
2022-10-17 02:00:45 - train: epoch 0109, iter [01100, 02526], lr: 0.000010, loss: 0.2854, CELoss: 0.2854, 
2022-10-17 02:01:18 - train: epoch 0109, iter [01200, 02526], lr: 0.000010, loss: 0.2971, CELoss: 0.2971, 
2022-10-17 02:01:52 - train: epoch 0109, iter [01300, 02526], lr: 0.000010, loss: 0.3426, CELoss: 0.3426, 
2022-10-17 02:02:25 - train: epoch 0109, iter [01400, 02526], lr: 0.000010, loss: 0.3501, CELoss: 0.3501, 
2022-10-17 02:02:59 - train: epoch 0109, iter [01500, 02526], lr: 0.000010, loss: 0.3762, CELoss: 0.3762, 
2022-10-17 02:03:32 - train: epoch 0109, iter [01600, 02526], lr: 0.000010, loss: 0.1954, CELoss: 0.1954, 
2022-10-17 02:04:05 - train: epoch 0109, iter [01700, 02526], lr: 0.000010, loss: 0.1592, CELoss: 0.1592, 
2022-10-17 02:04:38 - train: epoch 0109, iter [01800, 02526], lr: 0.000010, loss: 0.2757, CELoss: 0.2757, 
2022-10-17 02:05:12 - train: epoch 0109, iter [01900, 02526], lr: 0.000010, loss: 0.2671, CELoss: 0.2671, 
2022-10-17 02:05:46 - train: epoch 0109, iter [02000, 02526], lr: 0.000010, loss: 0.3237, CELoss: 0.3237, 
2022-10-17 02:06:19 - train: epoch 0109, iter [02100, 02526], lr: 0.000010, loss: 0.2153, CELoss: 0.2153, 
2022-10-17 02:06:52 - train: epoch 0109, iter [02200, 02526], lr: 0.000010, loss: 0.2203, CELoss: 0.2203, 
2022-10-17 02:07:26 - train: epoch 0109, iter [02300, 02526], lr: 0.000010, loss: 0.2908, CELoss: 0.2908, 
2022-10-17 02:08:00 - train: epoch 0109, iter [02400, 02526], lr: 0.000010, loss: 0.2723, CELoss: 0.2723, 
2022-10-17 02:08:33 - train: epoch 0109, iter [02500, 02526], lr: 0.000010, loss: 0.2506, CELoss: 0.2506, 
2022-10-17 02:08:43 - train: epoch 109, train_loss: 0.2804
2022-10-17 02:08:45 - until epoch: 109, best_metric: 40.229%
2022-10-17 02:08:45 - epoch 110 lr: 0.000010
2022-10-17 02:09:22 - train: epoch 0110, iter [00100, 02526], lr: 0.000010, loss: 0.2274, CELoss: 0.2274, 
2022-10-17 02:09:55 - train: epoch 0110, iter [00200, 02526], lr: 0.000010, loss: 0.2396, CELoss: 0.2396, 
2022-10-17 02:10:29 - train: epoch 0110, iter [00300, 02526], lr: 0.000010, loss: 0.2618, CELoss: 0.2618, 
2022-10-17 02:11:02 - train: epoch 0110, iter [00400, 02526], lr: 0.000010, loss: 0.1925, CELoss: 0.1925, 
2022-10-17 02:11:36 - train: epoch 0110, iter [00500, 02526], lr: 0.000010, loss: 0.2524, CELoss: 0.2524, 
2022-10-17 02:12:09 - train: epoch 0110, iter [00600, 02526], lr: 0.000010, loss: 0.3619, CELoss: 0.3619, 
2022-10-17 02:12:43 - train: epoch 0110, iter [00700, 02526], lr: 0.000010, loss: 0.4040, CELoss: 0.4040, 
2022-10-17 02:13:16 - train: epoch 0110, iter [00800, 02526], lr: 0.000010, loss: 0.2461, CELoss: 0.2461, 
2022-10-17 02:13:50 - train: epoch 0110, iter [00900, 02526], lr: 0.000010, loss: 0.2494, CELoss: 0.2494, 
2022-10-17 02:14:23 - train: epoch 0110, iter [01000, 02526], lr: 0.000010, loss: 0.2508, CELoss: 0.2508, 
2022-10-17 02:14:56 - train: epoch 0110, iter [01100, 02526], lr: 0.000010, loss: 0.2685, CELoss: 0.2685, 
2022-10-17 02:15:30 - train: epoch 0110, iter [01200, 02526], lr: 0.000010, loss: 0.2605, CELoss: 0.2605, 
2022-10-17 02:16:03 - train: epoch 0110, iter [01300, 02526], lr: 0.000010, loss: 0.1433, CELoss: 0.1433, 
2022-10-17 02:16:37 - train: epoch 0110, iter [01400, 02526], lr: 0.000010, loss: 0.3095, CELoss: 0.3095, 
2022-10-17 02:17:10 - train: epoch 0110, iter [01500, 02526], lr: 0.000010, loss: 0.2434, CELoss: 0.2434, 
2022-10-17 02:17:44 - train: epoch 0110, iter [01600, 02526], lr: 0.000010, loss: 0.3832, CELoss: 0.3832, 
2022-10-17 02:18:17 - train: epoch 0110, iter [01700, 02526], lr: 0.000010, loss: 0.2435, CELoss: 0.2435, 
2022-10-17 02:18:51 - train: epoch 0110, iter [01800, 02526], lr: 0.000010, loss: 0.2506, CELoss: 0.2506, 
2022-10-17 02:19:24 - train: epoch 0110, iter [01900, 02526], lr: 0.000010, loss: 0.2787, CELoss: 0.2787, 
2022-10-17 02:19:58 - train: epoch 0110, iter [02000, 02526], lr: 0.000010, loss: 0.2451, CELoss: 0.2451, 
2022-10-17 02:20:31 - train: epoch 0110, iter [02100, 02526], lr: 0.000010, loss: 0.2423, CELoss: 0.2423, 
2022-10-17 02:21:05 - train: epoch 0110, iter [02200, 02526], lr: 0.000010, loss: 0.3088, CELoss: 0.3088, 
2022-10-17 02:21:39 - train: epoch 0110, iter [02300, 02526], lr: 0.000010, loss: 0.1776, CELoss: 0.1776, 
2022-10-17 02:22:12 - train: epoch 0110, iter [02400, 02526], lr: 0.000010, loss: 0.3722, CELoss: 0.3722, 
2022-10-17 02:22:45 - train: epoch 0110, iter [02500, 02526], lr: 0.000010, loss: 0.2105, CELoss: 0.2105, 
2022-10-17 02:22:55 - train: epoch 110, train_loss: 0.2744
2022-10-17 02:23:47 - eval: epoch: 110
test_loss: 0.8971554153859616
per_image_load_time: 1.737ms
per_image_inference_time: 18.217ms
exist_num_class: 150.0
mean_precision: 61.50274741242333
mean_recall: 50.7423039954825
mean_iou: 40.401168124667684
mean_dice: 54.14866236424048

2022-10-17 02:23:50 - until epoch: 110, best_metric: 40.401%
2022-10-17 02:23:50 - epoch 111 lr: 0.000001
2022-10-17 02:24:26 - train: epoch 0111, iter [00100, 02526], lr: 0.000001, loss: 0.2448, CELoss: 0.2448, 
2022-10-17 02:25:00 - train: epoch 0111, iter [00200, 02526], lr: 0.000001, loss: 0.1676, CELoss: 0.1676, 
2022-10-17 02:25:33 - train: epoch 0111, iter [00300, 02526], lr: 0.000001, loss: 0.2638, CELoss: 0.2638, 
2022-10-17 02:26:06 - train: epoch 0111, iter [00400, 02526], lr: 0.000001, loss: 0.2017, CELoss: 0.2017, 
2022-10-17 02:26:40 - train: epoch 0111, iter [00500, 02526], lr: 0.000001, loss: 0.2116, CELoss: 0.2116, 
2022-10-17 02:27:13 - train: epoch 0111, iter [00600, 02526], lr: 0.000001, loss: 0.3486, CELoss: 0.3486, 
2022-10-17 02:27:47 - train: epoch 0111, iter [00700, 02526], lr: 0.000001, loss: 0.1610, CELoss: 0.1610, 
2022-10-17 02:28:20 - train: epoch 0111, iter [00800, 02526], lr: 0.000001, loss: 0.2860, CELoss: 0.2860, 
2022-10-17 02:28:53 - train: epoch 0111, iter [00900, 02526], lr: 0.000001, loss: 0.2952, CELoss: 0.2952, 
2022-10-17 02:29:27 - train: epoch 0111, iter [01000, 02526], lr: 0.000001, loss: 0.1984, CELoss: 0.1984, 
2022-10-17 02:30:00 - train: epoch 0111, iter [01100, 02526], lr: 0.000001, loss: 0.1747, CELoss: 0.1747, 
2022-10-17 02:30:34 - train: epoch 0111, iter [01200, 02526], lr: 0.000001, loss: 0.2404, CELoss: 0.2404, 
2022-10-17 02:31:07 - train: epoch 0111, iter [01300, 02526], lr: 0.000001, loss: 0.2383, CELoss: 0.2383, 
2022-10-17 02:31:41 - train: epoch 0111, iter [01400, 02526], lr: 0.000001, loss: 0.2559, CELoss: 0.2559, 
2022-10-17 02:32:14 - train: epoch 0111, iter [01500, 02526], lr: 0.000001, loss: 0.2029, CELoss: 0.2029, 
2022-10-17 02:32:47 - train: epoch 0111, iter [01600, 02526], lr: 0.000001, loss: 0.2838, CELoss: 0.2838, 
2022-10-17 02:33:20 - train: epoch 0111, iter [01700, 02526], lr: 0.000001, loss: 0.2910, CELoss: 0.2910, 
2022-10-17 02:33:54 - train: epoch 0111, iter [01800, 02526], lr: 0.000001, loss: 0.3624, CELoss: 0.3624, 
2022-10-17 02:34:27 - train: epoch 0111, iter [01900, 02526], lr: 0.000001, loss: 0.2517, CELoss: 0.2517, 
2022-10-17 02:35:00 - train: epoch 0111, iter [02000, 02526], lr: 0.000001, loss: 0.2158, CELoss: 0.2158, 
2022-10-17 02:35:34 - train: epoch 0111, iter [02100, 02526], lr: 0.000001, loss: 0.2127, CELoss: 0.2127, 
2022-10-17 02:36:07 - train: epoch 0111, iter [02200, 02526], lr: 0.000001, loss: 0.2601, CELoss: 0.2601, 
2022-10-17 02:36:40 - train: epoch 0111, iter [02300, 02526], lr: 0.000001, loss: 0.2014, CELoss: 0.2014, 
2022-10-17 02:37:14 - train: epoch 0111, iter [02400, 02526], lr: 0.000001, loss: 0.2270, CELoss: 0.2270, 
2022-10-17 02:37:47 - train: epoch 0111, iter [02500, 02526], lr: 0.000001, loss: 0.2588, CELoss: 0.2588, 
2022-10-17 02:37:58 - train: epoch 111, train_loss: 0.2722
2022-10-17 02:37:59 - until epoch: 111, best_metric: 40.401%
2022-10-17 02:37:59 - epoch 112 lr: 0.000001
2022-10-17 02:38:36 - train: epoch 0112, iter [00100, 02526], lr: 0.000001, loss: 0.2519, CELoss: 0.2519, 
2022-10-17 02:39:10 - train: epoch 0112, iter [00200, 02526], lr: 0.000001, loss: 0.2542, CELoss: 0.2542, 
2022-10-17 02:39:43 - train: epoch 0112, iter [00300, 02526], lr: 0.000001, loss: 0.2099, CELoss: 0.2099, 
2022-10-17 02:40:16 - train: epoch 0112, iter [00400, 02526], lr: 0.000001, loss: 0.3056, CELoss: 0.3056, 
2022-10-17 02:40:50 - train: epoch 0112, iter [00500, 02526], lr: 0.000001, loss: 0.1905, CELoss: 0.1905, 
2022-10-17 02:41:23 - train: epoch 0112, iter [00600, 02526], lr: 0.000001, loss: 0.3188, CELoss: 0.3188, 
2022-10-17 02:41:56 - train: epoch 0112, iter [00700, 02526], lr: 0.000001, loss: 0.2226, CELoss: 0.2226, 
2022-10-17 02:42:30 - train: epoch 0112, iter [00800, 02526], lr: 0.000001, loss: 0.2778, CELoss: 0.2778, 
2022-10-17 02:43:04 - train: epoch 0112, iter [00900, 02526], lr: 0.000001, loss: 0.3306, CELoss: 0.3306, 
2022-10-17 02:43:37 - train: epoch 0112, iter [01000, 02526], lr: 0.000001, loss: 0.3283, CELoss: 0.3283, 
2022-10-17 02:44:10 - train: epoch 0112, iter [01100, 02526], lr: 0.000001, loss: 0.3141, CELoss: 0.3141, 
2022-10-17 02:44:44 - train: epoch 0112, iter [01200, 02526], lr: 0.000001, loss: 0.2802, CELoss: 0.2802, 
2022-10-17 02:45:17 - train: epoch 0112, iter [01300, 02526], lr: 0.000001, loss: 0.2035, CELoss: 0.2035, 
2022-10-17 02:45:50 - train: epoch 0112, iter [01400, 02526], lr: 0.000001, loss: 0.2322, CELoss: 0.2322, 
2022-10-17 02:46:24 - train: epoch 0112, iter [01500, 02526], lr: 0.000001, loss: 0.3305, CELoss: 0.3305, 
2022-10-17 02:46:57 - train: epoch 0112, iter [01600, 02526], lr: 0.000001, loss: 0.3730, CELoss: 0.3730, 
2022-10-17 02:47:31 - train: epoch 0112, iter [01700, 02526], lr: 0.000001, loss: 0.5370, CELoss: 0.5370, 
2022-10-17 02:48:04 - train: epoch 0112, iter [01800, 02526], lr: 0.000001, loss: 0.3681, CELoss: 0.3681, 
2022-10-17 02:48:38 - train: epoch 0112, iter [01900, 02526], lr: 0.000001, loss: 0.3268, CELoss: 0.3268, 
2022-10-17 02:49:11 - train: epoch 0112, iter [02000, 02526], lr: 0.000001, loss: 0.2488, CELoss: 0.2488, 
2022-10-17 02:49:45 - train: epoch 0112, iter [02100, 02526], lr: 0.000001, loss: 0.2575, CELoss: 0.2575, 
2022-10-17 02:50:18 - train: epoch 0112, iter [02200, 02526], lr: 0.000001, loss: 0.3643, CELoss: 0.3643, 
2022-10-17 02:50:52 - train: epoch 0112, iter [02300, 02526], lr: 0.000001, loss: 0.2021, CELoss: 0.2021, 
2022-10-17 02:51:25 - train: epoch 0112, iter [02400, 02526], lr: 0.000001, loss: 0.2779, CELoss: 0.2779, 
2022-10-17 02:51:59 - train: epoch 0112, iter [02500, 02526], lr: 0.000001, loss: 0.7053, CELoss: 0.7053, 
2022-10-17 02:52:08 - train: epoch 112, train_loss: 0.2704
2022-10-17 02:52:10 - until epoch: 112, best_metric: 40.401%
2022-10-17 02:52:10 - epoch 113 lr: 0.000001
2022-10-17 02:52:47 - train: epoch 0113, iter [00100, 02526], lr: 0.000001, loss: 0.2724, CELoss: 0.2724, 
2022-10-17 02:53:20 - train: epoch 0113, iter [00200, 02526], lr: 0.000001, loss: 0.1955, CELoss: 0.1955, 
2022-10-17 02:53:54 - train: epoch 0113, iter [00300, 02526], lr: 0.000001, loss: 0.1629, CELoss: 0.1629, 
2022-10-17 02:54:27 - train: epoch 0113, iter [00400, 02526], lr: 0.000001, loss: 0.2819, CELoss: 0.2819, 
2022-10-17 02:55:01 - train: epoch 0113, iter [00500, 02526], lr: 0.000001, loss: 0.1881, CELoss: 0.1881, 
2022-10-17 02:55:34 - train: epoch 0113, iter [00600, 02526], lr: 0.000001, loss: 0.2053, CELoss: 0.2053, 
2022-10-17 02:56:08 - train: epoch 0113, iter [00700, 02526], lr: 0.000001, loss: 0.3388, CELoss: 0.3388, 
2022-10-17 02:56:41 - train: epoch 0113, iter [00800, 02526], lr: 0.000001, loss: 0.3214, CELoss: 0.3214, 
2022-10-17 02:57:15 - train: epoch 0113, iter [00900, 02526], lr: 0.000001, loss: 0.3931, CELoss: 0.3931, 
2022-10-17 02:57:48 - train: epoch 0113, iter [01000, 02526], lr: 0.000001, loss: 0.4234, CELoss: 0.4234, 
2022-10-17 02:58:22 - train: epoch 0113, iter [01100, 02526], lr: 0.000001, loss: 0.2841, CELoss: 0.2841, 
2022-10-17 02:58:55 - train: epoch 0113, iter [01200, 02526], lr: 0.000001, loss: 0.1421, CELoss: 0.1421, 
2022-10-17 02:59:28 - train: epoch 0113, iter [01300, 02526], lr: 0.000001, loss: 0.2253, CELoss: 0.2253, 
2022-10-17 03:00:02 - train: epoch 0113, iter [01400, 02526], lr: 0.000001, loss: 0.2953, CELoss: 0.2953, 
2022-10-17 03:00:35 - train: epoch 0113, iter [01500, 02526], lr: 0.000001, loss: 0.3117, CELoss: 0.3117, 
2022-10-17 03:01:08 - train: epoch 0113, iter [01600, 02526], lr: 0.000001, loss: 0.2247, CELoss: 0.2247, 
2022-10-17 03:01:41 - train: epoch 0113, iter [01700, 02526], lr: 0.000001, loss: 0.3286, CELoss: 0.3286, 
2022-10-17 03:02:15 - train: epoch 0113, iter [01800, 02526], lr: 0.000001, loss: 0.3094, CELoss: 0.3094, 
2022-10-17 03:02:48 - train: epoch 0113, iter [01900, 02526], lr: 0.000001, loss: 0.3051, CELoss: 0.3051, 
2022-10-17 03:03:21 - train: epoch 0113, iter [02000, 02526], lr: 0.000001, loss: 0.2966, CELoss: 0.2966, 
2022-10-17 03:03:55 - train: epoch 0113, iter [02100, 02526], lr: 0.000001, loss: 0.3048, CELoss: 0.3048, 
2022-10-17 03:04:28 - train: epoch 0113, iter [02200, 02526], lr: 0.000001, loss: 0.2831, CELoss: 0.2831, 
2022-10-17 03:05:02 - train: epoch 0113, iter [02300, 02526], lr: 0.000001, loss: 0.3068, CELoss: 0.3068, 
2022-10-17 03:05:35 - train: epoch 0113, iter [02400, 02526], lr: 0.000001, loss: 0.3313, CELoss: 0.3313, 
2022-10-17 03:06:08 - train: epoch 0113, iter [02500, 02526], lr: 0.000001, loss: 0.3590, CELoss: 0.3590, 
2022-10-17 03:06:18 - train: epoch 113, train_loss: 0.2697
2022-10-17 03:06:20 - until epoch: 113, best_metric: 40.401%
2022-10-17 03:06:20 - epoch 114 lr: 0.000001
2022-10-17 03:06:57 - train: epoch 0114, iter [00100, 02526], lr: 0.000001, loss: 0.1822, CELoss: 0.1822, 
2022-10-17 03:07:31 - train: epoch 0114, iter [00200, 02526], lr: 0.000001, loss: 0.2462, CELoss: 0.2462, 
2022-10-17 03:08:04 - train: epoch 0114, iter [00300, 02526], lr: 0.000001, loss: 0.3562, CELoss: 0.3562, 
2022-10-17 03:08:38 - train: epoch 0114, iter [00400, 02526], lr: 0.000001, loss: 0.1556, CELoss: 0.1556, 
2022-10-17 03:09:11 - train: epoch 0114, iter [00500, 02526], lr: 0.000001, loss: 0.1863, CELoss: 0.1863, 
2022-10-17 03:09:44 - train: epoch 0114, iter [00600, 02526], lr: 0.000001, loss: 0.2838, CELoss: 0.2838, 
2022-10-17 03:10:18 - train: epoch 0114, iter [00700, 02526], lr: 0.000001, loss: 0.4214, CELoss: 0.4214, 
2022-10-17 03:10:51 - train: epoch 0114, iter [00800, 02526], lr: 0.000001, loss: 0.3566, CELoss: 0.3566, 
2022-10-17 03:11:25 - train: epoch 0114, iter [00900, 02526], lr: 0.000001, loss: 0.2978, CELoss: 0.2978, 
2022-10-17 03:11:58 - train: epoch 0114, iter [01000, 02526], lr: 0.000001, loss: 0.2899, CELoss: 0.2899, 
2022-10-17 03:12:31 - train: epoch 0114, iter [01100, 02526], lr: 0.000001, loss: 0.2296, CELoss: 0.2296, 
2022-10-17 03:13:04 - train: epoch 0114, iter [01200, 02526], lr: 0.000001, loss: 0.2862, CELoss: 0.2862, 
2022-10-17 03:13:38 - train: epoch 0114, iter [01300, 02526], lr: 0.000001, loss: 0.3113, CELoss: 0.3113, 
2022-10-17 03:14:11 - train: epoch 0114, iter [01400, 02526], lr: 0.000001, loss: 0.3080, CELoss: 0.3080, 
2022-10-17 03:14:44 - train: epoch 0114, iter [01500, 02526], lr: 0.000001, loss: 0.1628, CELoss: 0.1628, 
2022-10-17 03:15:18 - train: epoch 0114, iter [01600, 02526], lr: 0.000001, loss: 0.1728, CELoss: 0.1728, 
2022-10-17 03:15:51 - train: epoch 0114, iter [01700, 02526], lr: 0.000001, loss: 0.2310, CELoss: 0.2310, 
2022-10-17 03:16:25 - train: epoch 0114, iter [01800, 02526], lr: 0.000001, loss: 0.1800, CELoss: 0.1800, 
2022-10-17 03:16:58 - train: epoch 0114, iter [01900, 02526], lr: 0.000001, loss: 0.2768, CELoss: 0.2768, 
2022-10-17 03:17:32 - train: epoch 0114, iter [02000, 02526], lr: 0.000001, loss: 0.2760, CELoss: 0.2760, 
2022-10-17 03:18:05 - train: epoch 0114, iter [02100, 02526], lr: 0.000001, loss: 0.1970, CELoss: 0.1970, 
2022-10-17 03:18:38 - train: epoch 0114, iter [02200, 02526], lr: 0.000001, loss: 0.2778, CELoss: 0.2778, 
2022-10-17 03:19:12 - train: epoch 0114, iter [02300, 02526], lr: 0.000001, loss: 0.3020, CELoss: 0.3020, 
2022-10-17 03:19:45 - train: epoch 0114, iter [02400, 02526], lr: 0.000001, loss: 0.1629, CELoss: 0.1629, 
2022-10-17 03:20:19 - train: epoch 0114, iter [02500, 02526], lr: 0.000001, loss: 0.2753, CELoss: 0.2753, 
2022-10-17 03:20:29 - train: epoch 114, train_loss: 0.2694
2022-10-17 03:20:31 - until epoch: 114, best_metric: 40.401%
2022-10-17 03:20:31 - epoch 115 lr: 0.000001
2022-10-17 03:21:08 - train: epoch 0115, iter [00100, 02526], lr: 0.000001, loss: 0.2379, CELoss: 0.2379, 
2022-10-17 03:21:42 - train: epoch 0115, iter [00200, 02526], lr: 0.000001, loss: 0.3747, CELoss: 0.3747, 
2022-10-17 03:22:15 - train: epoch 0115, iter [00300, 02526], lr: 0.000001, loss: 0.2831, CELoss: 0.2831, 
2022-10-17 03:22:48 - train: epoch 0115, iter [00400, 02526], lr: 0.000001, loss: 0.2840, CELoss: 0.2840, 
2022-10-17 03:23:22 - train: epoch 0115, iter [00500, 02526], lr: 0.000001, loss: 0.2498, CELoss: 0.2498, 
2022-10-17 03:23:55 - train: epoch 0115, iter [00600, 02526], lr: 0.000001, loss: 0.2574, CELoss: 0.2574, 
2022-10-17 03:24:29 - train: epoch 0115, iter [00700, 02526], lr: 0.000001, loss: 0.3367, CELoss: 0.3367, 
2022-10-17 03:25:02 - train: epoch 0115, iter [00800, 02526], lr: 0.000001, loss: 0.1954, CELoss: 0.1954, 
2022-10-17 03:25:35 - train: epoch 0115, iter [00900, 02526], lr: 0.000001, loss: 0.2561, CELoss: 0.2561, 
2022-10-17 03:26:08 - train: epoch 0115, iter [01000, 02526], lr: 0.000001, loss: 0.2139, CELoss: 0.2139, 
2022-10-17 03:26:42 - train: epoch 0115, iter [01100, 02526], lr: 0.000001, loss: 0.2093, CELoss: 0.2093, 
2022-10-17 03:27:15 - train: epoch 0115, iter [01200, 02526], lr: 0.000001, loss: 0.2414, CELoss: 0.2414, 
2022-10-17 03:27:48 - train: epoch 0115, iter [01300, 02526], lr: 0.000001, loss: 0.2882, CELoss: 0.2882, 
2022-10-17 03:28:22 - train: epoch 0115, iter [01400, 02526], lr: 0.000001, loss: 0.5096, CELoss: 0.5096, 
2022-10-17 03:28:55 - train: epoch 0115, iter [01500, 02526], lr: 0.000001, loss: 0.3389, CELoss: 0.3389, 
2022-10-17 03:29:28 - train: epoch 0115, iter [01600, 02526], lr: 0.000001, loss: 0.2578, CELoss: 0.2578, 
2022-10-17 03:30:02 - train: epoch 0115, iter [01700, 02526], lr: 0.000001, loss: 0.2547, CELoss: 0.2547, 
2022-10-17 03:30:35 - train: epoch 0115, iter [01800, 02526], lr: 0.000001, loss: 0.2616, CELoss: 0.2616, 
2022-10-17 03:31:09 - train: epoch 0115, iter [01900, 02526], lr: 0.000001, loss: 0.2873, CELoss: 0.2873, 
2022-10-17 03:31:42 - train: epoch 0115, iter [02000, 02526], lr: 0.000001, loss: 0.3500, CELoss: 0.3500, 
2022-10-17 03:32:15 - train: epoch 0115, iter [02100, 02526], lr: 0.000001, loss: 0.2754, CELoss: 0.2754, 
2022-10-17 03:32:49 - train: epoch 0115, iter [02200, 02526], lr: 0.000001, loss: 0.2541, CELoss: 0.2541, 
2022-10-17 03:33:23 - train: epoch 0115, iter [02300, 02526], lr: 0.000001, loss: 0.2064, CELoss: 0.2064, 
2022-10-17 03:33:56 - train: epoch 0115, iter [02400, 02526], lr: 0.000001, loss: 0.1968, CELoss: 0.1968, 
2022-10-17 03:34:30 - train: epoch 0115, iter [02500, 02526], lr: 0.000001, loss: 0.3053, CELoss: 0.3053, 
2022-10-17 03:34:40 - train: epoch 115, train_loss: 0.2688
2022-10-17 03:35:31 - eval: epoch: 115
test_loss: 0.8956694334447384
per_image_load_time: 1.751ms
per_image_inference_time: 18.207ms
exist_num_class: 150.0
mean_precision: 61.526017678669746
mean_recall: 51.01965963040178
mean_iou: 40.547286746552196
mean_dice: 54.31966644388062

2022-10-17 03:35:34 - until epoch: 115, best_metric: 40.547%
2022-10-17 03:35:34 - epoch 116 lr: 0.000001
2022-10-17 03:36:10 - train: epoch 0116, iter [00100, 02526], lr: 0.000001, loss: 0.2415, CELoss: 0.2415, 
2022-10-17 03:36:43 - train: epoch 0116, iter [00200, 02526], lr: 0.000001, loss: 0.2851, CELoss: 0.2851, 
2022-10-17 03:37:16 - train: epoch 0116, iter [00300, 02526], lr: 0.000001, loss: 0.2986, CELoss: 0.2986, 
2022-10-17 03:37:50 - train: epoch 0116, iter [00400, 02526], lr: 0.000001, loss: 0.4174, CELoss: 0.4174, 
2022-10-17 03:38:23 - train: epoch 0116, iter [00500, 02526], lr: 0.000001, loss: 0.2433, CELoss: 0.2433, 
2022-10-17 03:38:56 - train: epoch 0116, iter [00600, 02526], lr: 0.000001, loss: 0.2400, CELoss: 0.2400, 
2022-10-17 03:39:30 - train: epoch 0116, iter [00700, 02526], lr: 0.000001, loss: 0.3924, CELoss: 0.3924, 
2022-10-17 03:40:03 - train: epoch 0116, iter [00800, 02526], lr: 0.000001, loss: 0.3765, CELoss: 0.3765, 
2022-10-17 03:40:37 - train: epoch 0116, iter [00900, 02526], lr: 0.000001, loss: 0.2465, CELoss: 0.2465, 
2022-10-17 03:41:10 - train: epoch 0116, iter [01000, 02526], lr: 0.000001, loss: 0.1833, CELoss: 0.1833, 
2022-10-17 03:41:43 - train: epoch 0116, iter [01100, 02526], lr: 0.000001, loss: 0.2475, CELoss: 0.2475, 
2022-10-17 03:42:17 - train: epoch 0116, iter [01200, 02526], lr: 0.000001, loss: 0.6687, CELoss: 0.6687, 
2022-10-17 03:42:50 - train: epoch 0116, iter [01300, 02526], lr: 0.000001, loss: 0.2325, CELoss: 0.2325, 
2022-10-17 03:43:23 - train: epoch 0116, iter [01400, 02526], lr: 0.000001, loss: 0.1227, CELoss: 0.1227, 
2022-10-17 03:43:56 - train: epoch 0116, iter [01500, 02526], lr: 0.000001, loss: 0.3544, CELoss: 0.3544, 
2022-10-17 03:44:30 - train: epoch 0116, iter [01600, 02526], lr: 0.000001, loss: 0.2034, CELoss: 0.2034, 
2022-10-17 03:45:03 - train: epoch 0116, iter [01700, 02526], lr: 0.000001, loss: 0.3709, CELoss: 0.3709, 
2022-10-17 03:45:36 - train: epoch 0116, iter [01800, 02526], lr: 0.000001, loss: 0.2227, CELoss: 0.2227, 
2022-10-17 03:46:10 - train: epoch 0116, iter [01900, 02526], lr: 0.000001, loss: 0.3323, CELoss: 0.3323, 
2022-10-17 03:46:44 - train: epoch 0116, iter [02000, 02526], lr: 0.000001, loss: 0.2861, CELoss: 0.2861, 
2022-10-17 03:47:17 - train: epoch 0116, iter [02100, 02526], lr: 0.000001, loss: 0.2201, CELoss: 0.2201, 
2022-10-17 03:47:51 - train: epoch 0116, iter [02200, 02526], lr: 0.000001, loss: 0.2658, CELoss: 0.2658, 
2022-10-17 03:48:24 - train: epoch 0116, iter [02300, 02526], lr: 0.000001, loss: 0.1483, CELoss: 0.1483, 
2022-10-17 03:48:58 - train: epoch 0116, iter [02400, 02526], lr: 0.000001, loss: 0.1839, CELoss: 0.1839, 
2022-10-17 03:49:31 - train: epoch 0116, iter [02500, 02526], lr: 0.000001, loss: 0.1853, CELoss: 0.1853, 
2022-10-17 03:49:41 - train: epoch 116, train_loss: 0.2668
2022-10-17 03:49:43 - until epoch: 116, best_metric: 40.547%
2022-10-17 03:49:43 - epoch 117 lr: 0.000001
2022-10-17 03:50:19 - train: epoch 0117, iter [00100, 02526], lr: 0.000001, loss: 0.4382, CELoss: 0.4382, 
2022-10-17 03:50:53 - train: epoch 0117, iter [00200, 02526], lr: 0.000001, loss: 0.2729, CELoss: 0.2729, 
2022-10-17 03:51:27 - train: epoch 0117, iter [00300, 02526], lr: 0.000001, loss: 0.2179, CELoss: 0.2179, 
2022-10-17 03:52:01 - train: epoch 0117, iter [00400, 02526], lr: 0.000001, loss: 0.2215, CELoss: 0.2215, 
2022-10-17 03:52:34 - train: epoch 0117, iter [00500, 02526], lr: 0.000001, loss: 0.3342, CELoss: 0.3342, 
2022-10-17 03:53:08 - train: epoch 0117, iter [00600, 02526], lr: 0.000001, loss: 0.2665, CELoss: 0.2665, 
2022-10-17 03:53:41 - train: epoch 0117, iter [00700, 02526], lr: 0.000001, loss: 0.2018, CELoss: 0.2018, 
2022-10-17 03:54:15 - train: epoch 0117, iter [00800, 02526], lr: 0.000001, loss: 0.2756, CELoss: 0.2756, 
2022-10-17 03:54:48 - train: epoch 0117, iter [00900, 02526], lr: 0.000001, loss: 0.2769, CELoss: 0.2769, 
2022-10-17 03:55:21 - train: epoch 0117, iter [01000, 02526], lr: 0.000001, loss: 0.2461, CELoss: 0.2461, 
2022-10-17 03:55:55 - train: epoch 0117, iter [01100, 02526], lr: 0.000001, loss: 0.2587, CELoss: 0.2587, 
2022-10-17 03:56:28 - train: epoch 0117, iter [01200, 02526], lr: 0.000001, loss: 0.2475, CELoss: 0.2475, 
2022-10-17 03:57:01 - train: epoch 0117, iter [01300, 02526], lr: 0.000001, loss: 0.6248, CELoss: 0.6248, 
2022-10-17 03:57:35 - train: epoch 0117, iter [01400, 02526], lr: 0.000001, loss: 0.2937, CELoss: 0.2937, 
2022-10-17 03:58:08 - train: epoch 0117, iter [01500, 02526], lr: 0.000001, loss: 0.1914, CELoss: 0.1914, 
2022-10-17 03:58:42 - train: epoch 0117, iter [01600, 02526], lr: 0.000001, loss: 0.2314, CELoss: 0.2314, 
2022-10-17 03:59:15 - train: epoch 0117, iter [01700, 02526], lr: 0.000001, loss: 0.2389, CELoss: 0.2389, 
2022-10-17 03:59:49 - train: epoch 0117, iter [01800, 02526], lr: 0.000001, loss: 0.2908, CELoss: 0.2908, 
2022-10-17 04:00:22 - train: epoch 0117, iter [01900, 02526], lr: 0.000001, loss: 0.2486, CELoss: 0.2486, 
2022-10-17 04:00:55 - train: epoch 0117, iter [02000, 02526], lr: 0.000001, loss: 0.2763, CELoss: 0.2763, 
2022-10-17 04:01:29 - train: epoch 0117, iter [02100, 02526], lr: 0.000001, loss: 0.3099, CELoss: 0.3099, 
2022-10-17 04:02:03 - train: epoch 0117, iter [02200, 02526], lr: 0.000001, loss: 0.3147, CELoss: 0.3147, 
2022-10-17 04:02:36 - train: epoch 0117, iter [02300, 02526], lr: 0.000001, loss: 0.3781, CELoss: 0.3781, 
2022-10-17 04:03:10 - train: epoch 0117, iter [02400, 02526], lr: 0.000001, loss: 0.1736, CELoss: 0.1736, 
2022-10-17 04:03:43 - train: epoch 0117, iter [02500, 02526], lr: 0.000001, loss: 0.4849, CELoss: 0.4849, 
2022-10-17 04:03:53 - train: epoch 117, train_loss: 0.2673
2022-10-17 04:03:56 - until epoch: 117, best_metric: 40.547%
2022-10-17 04:03:56 - epoch 118 lr: 0.000001
2022-10-17 04:04:32 - train: epoch 0118, iter [00100, 02526], lr: 0.000001, loss: 0.3095, CELoss: 0.3095, 
2022-10-17 04:05:05 - train: epoch 0118, iter [00200, 02526], lr: 0.000001, loss: 0.3918, CELoss: 0.3918, 
2022-10-17 04:05:38 - train: epoch 0118, iter [00300, 02526], lr: 0.000001, loss: 0.1929, CELoss: 0.1929, 
2022-10-17 04:06:12 - train: epoch 0118, iter [00400, 02526], lr: 0.000001, loss: 0.3116, CELoss: 0.3116, 
2022-10-17 04:06:45 - train: epoch 0118, iter [00500, 02526], lr: 0.000001, loss: 0.1966, CELoss: 0.1966, 
2022-10-17 04:07:19 - train: epoch 0118, iter [00600, 02526], lr: 0.000001, loss: 0.2221, CELoss: 0.2221, 
2022-10-17 04:07:52 - train: epoch 0118, iter [00700, 02526], lr: 0.000001, loss: 0.2245, CELoss: 0.2245, 
2022-10-17 04:08:25 - train: epoch 0118, iter [00800, 02526], lr: 0.000001, loss: 0.2114, CELoss: 0.2114, 
2022-10-17 04:08:58 - train: epoch 0118, iter [00900, 02526], lr: 0.000001, loss: 0.2561, CELoss: 0.2561, 
2022-10-17 04:09:32 - train: epoch 0118, iter [01000, 02526], lr: 0.000001, loss: 0.1937, CELoss: 0.1937, 
2022-10-17 04:10:06 - train: epoch 0118, iter [01100, 02526], lr: 0.000001, loss: 0.2213, CELoss: 0.2213, 
2022-10-17 04:10:39 - train: epoch 0118, iter [01200, 02526], lr: 0.000001, loss: 0.1778, CELoss: 0.1778, 
2022-10-17 04:11:13 - train: epoch 0118, iter [01300, 02526], lr: 0.000001, loss: 0.1883, CELoss: 0.1883, 
2022-10-17 04:11:46 - train: epoch 0118, iter [01400, 02526], lr: 0.000001, loss: 0.3708, CELoss: 0.3708, 
2022-10-17 04:12:20 - train: epoch 0118, iter [01500, 02526], lr: 0.000001, loss: 0.1914, CELoss: 0.1914, 
2022-10-17 04:12:53 - train: epoch 0118, iter [01600, 02526], lr: 0.000001, loss: 0.2446, CELoss: 0.2446, 
2022-10-17 04:13:26 - train: epoch 0118, iter [01700, 02526], lr: 0.000001, loss: 0.3293, CELoss: 0.3293, 
2022-10-17 04:14:00 - train: epoch 0118, iter [01800, 02526], lr: 0.000001, loss: 0.2359, CELoss: 0.2359, 
2022-10-17 04:14:33 - train: epoch 0118, iter [01900, 02526], lr: 0.000001, loss: 0.2468, CELoss: 0.2468, 
2022-10-17 04:15:07 - train: epoch 0118, iter [02000, 02526], lr: 0.000001, loss: 0.2128, CELoss: 0.2128, 
2022-10-17 04:15:41 - train: epoch 0118, iter [02100, 02526], lr: 0.000001, loss: 0.3310, CELoss: 0.3310, 
2022-10-17 04:16:14 - train: epoch 0118, iter [02200, 02526], lr: 0.000001, loss: 0.2528, CELoss: 0.2528, 
2022-10-17 04:16:47 - train: epoch 0118, iter [02300, 02526], lr: 0.000001, loss: 0.2126, CELoss: 0.2126, 
2022-10-17 04:17:20 - train: epoch 0118, iter [02400, 02526], lr: 0.000001, loss: 0.2207, CELoss: 0.2207, 
2022-10-17 04:17:54 - train: epoch 0118, iter [02500, 02526], lr: 0.000001, loss: 0.2154, CELoss: 0.2154, 
2022-10-17 04:18:04 - train: epoch 118, train_loss: 0.2689
2022-10-17 04:18:06 - until epoch: 118, best_metric: 40.547%
2022-10-17 04:18:06 - epoch 119 lr: 0.000001
2022-10-17 04:18:43 - train: epoch 0119, iter [00100, 02526], lr: 0.000001, loss: 0.3433, CELoss: 0.3433, 
2022-10-17 04:19:16 - train: epoch 0119, iter [00200, 02526], lr: 0.000001, loss: 0.1816, CELoss: 0.1816, 
2022-10-17 04:19:50 - train: epoch 0119, iter [00300, 02526], lr: 0.000001, loss: 0.2746, CELoss: 0.2746, 
2022-10-17 04:20:23 - train: epoch 0119, iter [00400, 02526], lr: 0.000001, loss: 0.2685, CELoss: 0.2685, 
2022-10-17 04:20:57 - train: epoch 0119, iter [00500, 02526], lr: 0.000001, loss: 0.2985, CELoss: 0.2985, 
2022-10-17 04:21:30 - train: epoch 0119, iter [00600, 02526], lr: 0.000001, loss: 0.2469, CELoss: 0.2469, 
2022-10-17 04:22:03 - train: epoch 0119, iter [00700, 02526], lr: 0.000001, loss: 0.5656, CELoss: 0.5656, 
2022-10-17 04:22:36 - train: epoch 0119, iter [00800, 02526], lr: 0.000001, loss: 0.3038, CELoss: 0.3038, 
2022-10-17 04:23:10 - train: epoch 0119, iter [00900, 02526], lr: 0.000001, loss: 0.2509, CELoss: 0.2509, 
2022-10-17 04:23:43 - train: epoch 0119, iter [01000, 02526], lr: 0.000001, loss: 0.3171, CELoss: 0.3171, 
2022-10-17 04:24:17 - train: epoch 0119, iter [01100, 02526], lr: 0.000001, loss: 0.5293, CELoss: 0.5293, 
2022-10-17 04:24:50 - train: epoch 0119, iter [01200, 02526], lr: 0.000001, loss: 0.1676, CELoss: 0.1676, 
2022-10-17 04:25:23 - train: epoch 0119, iter [01300, 02526], lr: 0.000001, loss: 0.2173, CELoss: 0.2173, 
2022-10-17 04:25:57 - train: epoch 0119, iter [01400, 02526], lr: 0.000001, loss: 0.2805, CELoss: 0.2805, 
2022-10-17 04:26:30 - train: epoch 0119, iter [01500, 02526], lr: 0.000001, loss: 0.4703, CELoss: 0.4703, 
2022-10-17 04:27:03 - train: epoch 0119, iter [01600, 02526], lr: 0.000001, loss: 0.2565, CELoss: 0.2565, 
2022-10-17 04:27:37 - train: epoch 0119, iter [01700, 02526], lr: 0.000001, loss: 0.3540, CELoss: 0.3540, 
2022-10-17 04:28:10 - train: epoch 0119, iter [01800, 02526], lr: 0.000001, loss: 0.1984, CELoss: 0.1984, 
2022-10-17 04:28:44 - train: epoch 0119, iter [01900, 02526], lr: 0.000001, loss: 0.3400, CELoss: 0.3400, 
2022-10-17 04:29:17 - train: epoch 0119, iter [02000, 02526], lr: 0.000001, loss: 0.2233, CELoss: 0.2233, 
2022-10-17 04:29:50 - train: epoch 0119, iter [02100, 02526], lr: 0.000001, loss: 0.2123, CELoss: 0.2123, 
2022-10-17 04:30:24 - train: epoch 0119, iter [02200, 02526], lr: 0.000001, loss: 0.2907, CELoss: 0.2907, 
2022-10-17 04:30:57 - train: epoch 0119, iter [02300, 02526], lr: 0.000001, loss: 0.3147, CELoss: 0.3147, 
2022-10-17 04:31:30 - train: epoch 0119, iter [02400, 02526], lr: 0.000001, loss: 0.3149, CELoss: 0.3149, 
2022-10-17 04:32:03 - train: epoch 0119, iter [02500, 02526], lr: 0.000001, loss: 0.2701, CELoss: 0.2701, 
2022-10-17 04:32:13 - train: epoch 119, train_loss: 0.2690
2022-10-17 04:32:15 - until epoch: 119, best_metric: 40.547%
2022-10-17 04:32:15 - epoch 120 lr: 0.000001
2022-10-17 04:32:52 - train: epoch 0120, iter [00100, 02526], lr: 0.000001, loss: 0.2215, CELoss: 0.2215, 
2022-10-17 04:33:25 - train: epoch 0120, iter [00200, 02526], lr: 0.000001, loss: 0.3583, CELoss: 0.3583, 
2022-10-17 04:33:59 - train: epoch 0120, iter [00300, 02526], lr: 0.000001, loss: 0.2600, CELoss: 0.2600, 
2022-10-17 04:34:32 - train: epoch 0120, iter [00400, 02526], lr: 0.000001, loss: 0.2625, CELoss: 0.2625, 
2022-10-17 04:35:05 - train: epoch 0120, iter [00500, 02526], lr: 0.000001, loss: 0.1001, CELoss: 0.1001, 
2022-10-17 04:35:39 - train: epoch 0120, iter [00600, 02526], lr: 0.000001, loss: 0.2667, CELoss: 0.2667, 
2022-10-17 04:36:13 - train: epoch 0120, iter [00700, 02526], lr: 0.000001, loss: 0.2909, CELoss: 0.2909, 
2022-10-17 04:36:46 - train: epoch 0120, iter [00800, 02526], lr: 0.000001, loss: 0.3594, CELoss: 0.3594, 
2022-10-17 04:37:20 - train: epoch 0120, iter [00900, 02526], lr: 0.000001, loss: 0.1681, CELoss: 0.1681, 
2022-10-17 04:37:53 - train: epoch 0120, iter [01000, 02526], lr: 0.000001, loss: 0.1740, CELoss: 0.1740, 
2022-10-17 04:38:26 - train: epoch 0120, iter [01100, 02526], lr: 0.000001, loss: 0.2949, CELoss: 0.2949, 
2022-10-17 04:39:00 - train: epoch 0120, iter [01200, 02526], lr: 0.000001, loss: 0.2512, CELoss: 0.2512, 
2022-10-17 04:39:33 - train: epoch 0120, iter [01300, 02526], lr: 0.000001, loss: 0.3731, CELoss: 0.3731, 
2022-10-17 04:40:07 - train: epoch 0120, iter [01400, 02526], lr: 0.000001, loss: 0.2869, CELoss: 0.2869, 
2022-10-17 04:40:40 - train: epoch 0120, iter [01500, 02526], lr: 0.000001, loss: 0.2891, CELoss: 0.2891, 
2022-10-17 04:41:14 - train: epoch 0120, iter [01600, 02526], lr: 0.000001, loss: 0.2987, CELoss: 0.2987, 
2022-10-17 04:41:47 - train: epoch 0120, iter [01700, 02526], lr: 0.000001, loss: 0.4012, CELoss: 0.4012, 
2022-10-17 04:42:21 - train: epoch 0120, iter [01800, 02526], lr: 0.000001, loss: 0.2399, CELoss: 0.2399, 
2022-10-17 04:42:54 - train: epoch 0120, iter [01900, 02526], lr: 0.000001, loss: 0.2300, CELoss: 0.2300, 
2022-10-17 04:43:28 - train: epoch 0120, iter [02000, 02526], lr: 0.000001, loss: 0.2822, CELoss: 0.2822, 
2022-10-17 04:44:01 - train: epoch 0120, iter [02100, 02526], lr: 0.000001, loss: 0.3040, CELoss: 0.3040, 
2022-10-17 04:44:34 - train: epoch 0120, iter [02200, 02526], lr: 0.000001, loss: 0.2521, CELoss: 0.2521, 
2022-10-17 04:45:07 - train: epoch 0120, iter [02300, 02526], lr: 0.000001, loss: 0.2051, CELoss: 0.2051, 
2022-10-17 04:45:41 - train: epoch 0120, iter [02400, 02526], lr: 0.000001, loss: 0.2657, CELoss: 0.2657, 
2022-10-17 04:46:14 - train: epoch 0120, iter [02500, 02526], lr: 0.000001, loss: 0.3190, CELoss: 0.3190, 
2022-10-17 04:46:24 - train: epoch 120, train_loss: 0.2672
2022-10-17 04:47:15 - eval: epoch: 120
test_loss: 0.8953375815451146
per_image_load_time: 1.681ms
per_image_inference_time: 18.226ms
exist_num_class: 150.0
mean_precision: 61.23867328870928
mean_recall: 51.12715196940831
mean_iou: 40.58042886241098
mean_dice: 54.3528897038141

2022-10-17 04:47:18 - until epoch: 120, best_metric: 40.580%
2022-10-17 04:47:18 - epoch 121 lr: 0.000001
2022-10-17 04:47:55 - train: epoch 0121, iter [00100, 02526], lr: 0.000001, loss: 0.1650, CELoss: 0.1650, 
2022-10-17 04:48:28 - train: epoch 0121, iter [00200, 02526], lr: 0.000001, loss: 0.1686, CELoss: 0.1686, 
2022-10-17 04:49:01 - train: epoch 0121, iter [00300, 02526], lr: 0.000001, loss: 0.3721, CELoss: 0.3721, 
2022-10-17 04:49:35 - train: epoch 0121, iter [00400, 02526], lr: 0.000001, loss: 0.3013, CELoss: 0.3013, 
2022-10-17 04:50:08 - train: epoch 0121, iter [00500, 02526], lr: 0.000001, loss: 0.2303, CELoss: 0.2303, 
2022-10-17 04:50:42 - train: epoch 0121, iter [00600, 02526], lr: 0.000001, loss: 0.2209, CELoss: 0.2209, 
2022-10-17 04:51:15 - train: epoch 0121, iter [00700, 02526], lr: 0.000001, loss: 0.2512, CELoss: 0.2512, 
2022-10-17 04:51:48 - train: epoch 0121, iter [00800, 02526], lr: 0.000001, loss: 0.2366, CELoss: 0.2366, 
2022-10-17 04:52:22 - train: epoch 0121, iter [00900, 02526], lr: 0.000001, loss: 0.3465, CELoss: 0.3465, 
2022-10-17 04:52:55 - train: epoch 0121, iter [01000, 02526], lr: 0.000001, loss: 0.3423, CELoss: 0.3423, 
2022-10-17 04:53:28 - train: epoch 0121, iter [01100, 02526], lr: 0.000001, loss: 0.2597, CELoss: 0.2597, 
2022-10-17 04:54:02 - train: epoch 0121, iter [01200, 02526], lr: 0.000001, loss: 0.2111, CELoss: 0.2111, 
2022-10-17 04:54:35 - train: epoch 0121, iter [01300, 02526], lr: 0.000001, loss: 0.3211, CELoss: 0.3211, 
2022-10-17 04:55:09 - train: epoch 0121, iter [01400, 02526], lr: 0.000001, loss: 0.2441, CELoss: 0.2441, 
2022-10-17 04:55:42 - train: epoch 0121, iter [01500, 02526], lr: 0.000001, loss: 0.2788, CELoss: 0.2788, 
2022-10-17 04:56:16 - train: epoch 0121, iter [01600, 02526], lr: 0.000001, loss: 0.2392, CELoss: 0.2392, 
2022-10-17 04:56:49 - train: epoch 0121, iter [01700, 02526], lr: 0.000001, loss: 0.2254, CELoss: 0.2254, 
2022-10-17 04:57:23 - train: epoch 0121, iter [01800, 02526], lr: 0.000001, loss: 0.2612, CELoss: 0.2612, 
2022-10-17 04:57:56 - train: epoch 0121, iter [01900, 02526], lr: 0.000001, loss: 0.1877, CELoss: 0.1877, 
2022-10-17 04:58:29 - train: epoch 0121, iter [02000, 02526], lr: 0.000001, loss: 0.3183, CELoss: 0.3183, 
2022-10-17 04:59:03 - train: epoch 0121, iter [02100, 02526], lr: 0.000001, loss: 0.3087, CELoss: 0.3087, 
2022-10-17 04:59:36 - train: epoch 0121, iter [02200, 02526], lr: 0.000001, loss: 0.2036, CELoss: 0.2036, 
2022-10-17 05:00:09 - train: epoch 0121, iter [02300, 02526], lr: 0.000001, loss: 0.2408, CELoss: 0.2408, 
2022-10-17 05:00:43 - train: epoch 0121, iter [02400, 02526], lr: 0.000001, loss: 0.2298, CELoss: 0.2298, 
2022-10-17 05:01:16 - train: epoch 0121, iter [02500, 02526], lr: 0.000001, loss: 0.2797, CELoss: 0.2797, 
2022-10-17 05:01:26 - train: epoch 121, train_loss: 0.2675
2022-10-17 05:01:27 - until epoch: 121, best_metric: 40.580%
2022-10-17 05:01:27 - epoch 122 lr: 0.000001
2022-10-17 05:02:04 - train: epoch 0122, iter [00100, 02526], lr: 0.000001, loss: 0.2763, CELoss: 0.2763, 
2022-10-17 05:02:37 - train: epoch 0122, iter [00200, 02526], lr: 0.000001, loss: 0.2843, CELoss: 0.2843, 
2022-10-17 05:03:10 - train: epoch 0122, iter [00300, 02526], lr: 0.000001, loss: 0.2641, CELoss: 0.2641, 
2022-10-17 05:03:44 - train: epoch 0122, iter [00400, 02526], lr: 0.000001, loss: 0.3315, CELoss: 0.3315, 
2022-10-17 05:04:17 - train: epoch 0122, iter [00500, 02526], lr: 0.000001, loss: 0.2822, CELoss: 0.2822, 
2022-10-17 05:04:50 - train: epoch 0122, iter [00600, 02526], lr: 0.000001, loss: 0.2093, CELoss: 0.2093, 
2022-10-17 05:05:24 - train: epoch 0122, iter [00700, 02526], lr: 0.000001, loss: 0.3479, CELoss: 0.3479, 
2022-10-17 05:05:57 - train: epoch 0122, iter [00800, 02526], lr: 0.000001, loss: 0.2525, CELoss: 0.2525, 
2022-10-17 05:06:31 - train: epoch 0122, iter [00900, 02526], lr: 0.000001, loss: 0.1629, CELoss: 0.1629, 
2022-10-17 05:07:04 - train: epoch 0122, iter [01000, 02526], lr: 0.000001, loss: 0.2714, CELoss: 0.2714, 
2022-10-17 05:07:37 - train: epoch 0122, iter [01100, 02526], lr: 0.000001, loss: 0.3649, CELoss: 0.3649, 
2022-10-17 05:08:11 - train: epoch 0122, iter [01200, 02526], lr: 0.000001, loss: 0.1929, CELoss: 0.1929, 
2022-10-17 05:08:44 - train: epoch 0122, iter [01300, 02526], lr: 0.000001, loss: 0.1988, CELoss: 0.1988, 
2022-10-17 05:09:18 - train: epoch 0122, iter [01400, 02526], lr: 0.000001, loss: 0.3347, CELoss: 0.3347, 
2022-10-17 05:09:51 - train: epoch 0122, iter [01500, 02526], lr: 0.000001, loss: 0.2906, CELoss: 0.2906, 
2022-10-17 05:10:24 - train: epoch 0122, iter [01600, 02526], lr: 0.000001, loss: 0.1649, CELoss: 0.1649, 
2022-10-17 05:10:57 - train: epoch 0122, iter [01700, 02526], lr: 0.000001, loss: 0.3407, CELoss: 0.3407, 
2022-10-17 05:11:31 - train: epoch 0122, iter [01800, 02526], lr: 0.000001, loss: 0.3438, CELoss: 0.3438, 
2022-10-17 05:12:04 - train: epoch 0122, iter [01900, 02526], lr: 0.000001, loss: 0.2584, CELoss: 0.2584, 
2022-10-17 05:12:38 - train: epoch 0122, iter [02000, 02526], lr: 0.000001, loss: 0.3491, CELoss: 0.3491, 
2022-10-17 05:13:11 - train: epoch 0122, iter [02100, 02526], lr: 0.000001, loss: 0.3141, CELoss: 0.3141, 
2022-10-17 05:13:44 - train: epoch 0122, iter [02200, 02526], lr: 0.000001, loss: 0.3475, CELoss: 0.3475, 
2022-10-17 05:14:18 - train: epoch 0122, iter [02300, 02526], lr: 0.000001, loss: 0.3356, CELoss: 0.3356, 
2022-10-17 05:14:51 - train: epoch 0122, iter [02400, 02526], lr: 0.000001, loss: 0.2620, CELoss: 0.2620, 
2022-10-17 05:15:25 - train: epoch 0122, iter [02500, 02526], lr: 0.000001, loss: 0.2894, CELoss: 0.2894, 
2022-10-17 05:15:34 - train: epoch 122, train_loss: 0.2676
2022-10-17 05:15:37 - until epoch: 122, best_metric: 40.580%
2022-10-17 05:15:37 - epoch 123 lr: 0.000001
2022-10-17 05:16:14 - train: epoch 0123, iter [00100, 02526], lr: 0.000001, loss: 0.2032, CELoss: 0.2032, 
2022-10-17 05:16:47 - train: epoch 0123, iter [00200, 02526], lr: 0.000001, loss: 0.2104, CELoss: 0.2104, 
2022-10-17 05:17:21 - train: epoch 0123, iter [00300, 02526], lr: 0.000001, loss: 0.2746, CELoss: 0.2746, 
2022-10-17 05:17:54 - train: epoch 0123, iter [00400, 02526], lr: 0.000001, loss: 0.3075, CELoss: 0.3075, 
2022-10-17 05:18:28 - train: epoch 0123, iter [00500, 02526], lr: 0.000001, loss: 0.2930, CELoss: 0.2930, 
2022-10-17 05:19:01 - train: epoch 0123, iter [00600, 02526], lr: 0.000001, loss: 0.2351, CELoss: 0.2351, 
2022-10-17 05:19:34 - train: epoch 0123, iter [00700, 02526], lr: 0.000001, loss: 0.4550, CELoss: 0.4550, 
2022-10-17 05:20:07 - train: epoch 0123, iter [00800, 02526], lr: 0.000001, loss: 0.3831, CELoss: 0.3831, 
2022-10-17 05:20:41 - train: epoch 0123, iter [00900, 02526], lr: 0.000001, loss: 0.4321, CELoss: 0.4321, 
2022-10-17 05:21:14 - train: epoch 0123, iter [01000, 02526], lr: 0.000001, loss: 0.3332, CELoss: 0.3332, 
2022-10-17 05:21:48 - train: epoch 0123, iter [01100, 02526], lr: 0.000001, loss: 0.2357, CELoss: 0.2357, 
2022-10-17 05:22:21 - train: epoch 0123, iter [01200, 02526], lr: 0.000001, loss: 0.2238, CELoss: 0.2238, 
2022-10-17 05:22:54 - train: epoch 0123, iter [01300, 02526], lr: 0.000001, loss: 0.3703, CELoss: 0.3703, 
2022-10-17 05:23:28 - train: epoch 0123, iter [01400, 02526], lr: 0.000001, loss: 0.1815, CELoss: 0.1815, 
2022-10-17 05:24:01 - train: epoch 0123, iter [01500, 02526], lr: 0.000001, loss: 0.2973, CELoss: 0.2973, 
2022-10-17 05:24:35 - train: epoch 0123, iter [01600, 02526], lr: 0.000001, loss: 0.1393, CELoss: 0.1393, 
2022-10-17 05:25:08 - train: epoch 0123, iter [01700, 02526], lr: 0.000001, loss: 0.3096, CELoss: 0.3096, 
2022-10-17 05:25:42 - train: epoch 0123, iter [01800, 02526], lr: 0.000001, loss: 0.1723, CELoss: 0.1723, 
2022-10-17 05:26:15 - train: epoch 0123, iter [01900, 02526], lr: 0.000001, loss: 0.4160, CELoss: 0.4160, 
2022-10-17 05:26:49 - train: epoch 0123, iter [02000, 02526], lr: 0.000001, loss: 0.1854, CELoss: 0.1854, 
2022-10-17 05:27:22 - train: epoch 0123, iter [02100, 02526], lr: 0.000001, loss: 0.3041, CELoss: 0.3041, 
2022-10-17 05:27:55 - train: epoch 0123, iter [02200, 02526], lr: 0.000001, loss: 0.2491, CELoss: 0.2491, 
2022-10-17 05:28:29 - train: epoch 0123, iter [02300, 02526], lr: 0.000001, loss: 0.3265, CELoss: 0.3265, 
2022-10-17 05:29:02 - train: epoch 0123, iter [02400, 02526], lr: 0.000001, loss: 0.2419, CELoss: 0.2419, 
2022-10-17 05:29:35 - train: epoch 0123, iter [02500, 02526], lr: 0.000001, loss: 0.3713, CELoss: 0.3713, 
2022-10-17 05:29:45 - train: epoch 123, train_loss: 0.2654
2022-10-17 05:29:47 - until epoch: 123, best_metric: 40.580%
2022-10-17 05:29:47 - epoch 124 lr: 0.000001
2022-10-17 05:30:24 - train: epoch 0124, iter [00100, 02526], lr: 0.000001, loss: 0.2644, CELoss: 0.2644, 
2022-10-17 05:30:58 - train: epoch 0124, iter [00200, 02526], lr: 0.000001, loss: 0.2380, CELoss: 0.2380, 
2022-10-17 05:31:31 - train: epoch 0124, iter [00300, 02526], lr: 0.000001, loss: 0.2519, CELoss: 0.2519, 
2022-10-17 05:32:04 - train: epoch 0124, iter [00400, 02526], lr: 0.000001, loss: 0.2744, CELoss: 0.2744, 
2022-10-17 05:32:38 - train: epoch 0124, iter [00500, 02526], lr: 0.000001, loss: 0.2565, CELoss: 0.2565, 
2022-10-17 05:33:11 - train: epoch 0124, iter [00600, 02526], lr: 0.000001, loss: 0.2778, CELoss: 0.2778, 
2022-10-17 05:33:44 - train: epoch 0124, iter [00700, 02526], lr: 0.000001, loss: 0.2996, CELoss: 0.2996, 
2022-10-17 05:34:18 - train: epoch 0124, iter [00800, 02526], lr: 0.000001, loss: 0.2057, CELoss: 0.2057, 
2022-10-17 05:34:52 - train: epoch 0124, iter [00900, 02526], lr: 0.000001, loss: 0.1990, CELoss: 0.1990, 
2022-10-17 05:35:25 - train: epoch 0124, iter [01000, 02526], lr: 0.000001, loss: 0.2084, CELoss: 0.2084, 
2022-10-17 05:35:59 - train: epoch 0124, iter [01100, 02526], lr: 0.000001, loss: 0.2461, CELoss: 0.2461, 
2022-10-17 05:36:32 - train: epoch 0124, iter [01200, 02526], lr: 0.000001, loss: 0.3803, CELoss: 0.3803, 
2022-10-17 05:37:05 - train: epoch 0124, iter [01300, 02526], lr: 0.000001, loss: 0.2884, CELoss: 0.2884, 
2022-10-17 05:37:39 - train: epoch 0124, iter [01400, 02526], lr: 0.000001, loss: 0.2928, CELoss: 0.2928, 
2022-10-17 05:38:12 - train: epoch 0124, iter [01500, 02526], lr: 0.000001, loss: 0.2863, CELoss: 0.2863, 
2022-10-17 05:38:45 - train: epoch 0124, iter [01600, 02526], lr: 0.000001, loss: 0.2778, CELoss: 0.2778, 
2022-10-17 05:39:19 - train: epoch 0124, iter [01700, 02526], lr: 0.000001, loss: 0.2008, CELoss: 0.2008, 
2022-10-17 05:39:52 - train: epoch 0124, iter [01800, 02526], lr: 0.000001, loss: 0.2565, CELoss: 0.2565, 
2022-10-17 05:40:26 - train: epoch 0124, iter [01900, 02526], lr: 0.000001, loss: 0.2978, CELoss: 0.2978, 
2022-10-17 05:40:59 - train: epoch 0124, iter [02000, 02526], lr: 0.000001, loss: 0.2063, CELoss: 0.2063, 
2022-10-17 05:41:32 - train: epoch 0124, iter [02100, 02526], lr: 0.000001, loss: 0.1535, CELoss: 0.1535, 
2022-10-17 05:42:06 - train: epoch 0124, iter [02200, 02526], lr: 0.000001, loss: 0.5317, CELoss: 0.5317, 
2022-10-17 05:42:39 - train: epoch 0124, iter [02300, 02526], lr: 0.000001, loss: 0.1821, CELoss: 0.1821, 
2022-10-17 05:43:13 - train: epoch 0124, iter [02400, 02526], lr: 0.000001, loss: 0.2131, CELoss: 0.2131, 
2022-10-17 05:43:46 - train: epoch 0124, iter [02500, 02526], lr: 0.000001, loss: 0.2482, CELoss: 0.2482, 
2022-10-17 05:43:56 - train: epoch 124, train_loss: 0.2657
2022-10-17 05:43:58 - until epoch: 124, best_metric: 40.580%
2022-10-17 05:43:58 - epoch 125 lr: 0.000001
2022-10-17 05:44:35 - train: epoch 0125, iter [00100, 02526], lr: 0.000001, loss: 0.2580, CELoss: 0.2580, 
2022-10-17 05:45:08 - train: epoch 0125, iter [00200, 02526], lr: 0.000001, loss: 0.2829, CELoss: 0.2829, 
2022-10-17 05:45:41 - train: epoch 0125, iter [00300, 02526], lr: 0.000001, loss: 0.2109, CELoss: 0.2109, 
2022-10-17 05:46:15 - train: epoch 0125, iter [00400, 02526], lr: 0.000001, loss: 0.3559, CELoss: 0.3559, 
2022-10-17 05:46:49 - train: epoch 0125, iter [00500, 02526], lr: 0.000001, loss: 0.3587, CELoss: 0.3587, 
2022-10-17 05:47:22 - train: epoch 0125, iter [00600, 02526], lr: 0.000001, loss: 0.3281, CELoss: 0.3281, 
2022-10-17 05:47:56 - train: epoch 0125, iter [00700, 02526], lr: 0.000001, loss: 0.2176, CELoss: 0.2176, 
2022-10-17 05:48:29 - train: epoch 0125, iter [00800, 02526], lr: 0.000001, loss: 0.2184, CELoss: 0.2184, 
2022-10-17 05:49:02 - train: epoch 0125, iter [00900, 02526], lr: 0.000001, loss: 0.3068, CELoss: 0.3068, 
2022-10-17 05:49:36 - train: epoch 0125, iter [01000, 02526], lr: 0.000001, loss: 0.2963, CELoss: 0.2963, 
2022-10-17 05:50:09 - train: epoch 0125, iter [01100, 02526], lr: 0.000001, loss: 0.1234, CELoss: 0.1234, 
2022-10-17 05:50:42 - train: epoch 0125, iter [01200, 02526], lr: 0.000001, loss: 0.3126, CELoss: 0.3126, 
2022-10-17 05:51:16 - train: epoch 0125, iter [01300, 02526], lr: 0.000001, loss: 0.1631, CELoss: 0.1631, 
2022-10-17 05:51:49 - train: epoch 0125, iter [01400, 02526], lr: 0.000001, loss: 0.2421, CELoss: 0.2421, 
2022-10-17 05:52:23 - train: epoch 0125, iter [01500, 02526], lr: 0.000001, loss: 0.1351, CELoss: 0.1351, 
2022-10-17 05:52:56 - train: epoch 0125, iter [01600, 02526], lr: 0.000001, loss: 0.2977, CELoss: 0.2977, 
2022-10-17 05:53:30 - train: epoch 0125, iter [01700, 02526], lr: 0.000001, loss: 0.2634, CELoss: 0.2634, 
2022-10-17 05:54:03 - train: epoch 0125, iter [01800, 02526], lr: 0.000001, loss: 0.2325, CELoss: 0.2325, 
2022-10-17 05:54:36 - train: epoch 0125, iter [01900, 02526], lr: 0.000001, loss: 0.2988, CELoss: 0.2988, 
2022-10-17 05:55:10 - train: epoch 0125, iter [02000, 02526], lr: 0.000001, loss: 0.2678, CELoss: 0.2678, 
2022-10-17 05:55:43 - train: epoch 0125, iter [02100, 02526], lr: 0.000001, loss: 0.1957, CELoss: 0.1957, 
2022-10-17 05:56:16 - train: epoch 0125, iter [02200, 02526], lr: 0.000001, loss: 0.1425, CELoss: 0.1425, 
2022-10-17 05:56:50 - train: epoch 0125, iter [02300, 02526], lr: 0.000001, loss: 0.2302, CELoss: 0.2302, 
2022-10-17 05:57:23 - train: epoch 0125, iter [02400, 02526], lr: 0.000001, loss: 0.2883, CELoss: 0.2883, 
2022-10-17 05:57:57 - train: epoch 0125, iter [02500, 02526], lr: 0.000001, loss: 0.2457, CELoss: 0.2457, 
2022-10-17 05:58:07 - train: epoch 125, train_loss: 0.2664
2022-10-17 05:58:58 - eval: epoch: 125
test_loss: 0.8953045039474964
per_image_load_time: 1.651ms
per_image_inference_time: 18.198ms
exist_num_class: 150.0
mean_precision: 61.337375029276075
mean_recall: 51.0979642357436
mean_iou: 40.58370860956112
mean_dice: 54.343868100050734

2022-10-17 05:59:01 - until epoch: 125, best_metric: 40.584%
2022-10-17 05:59:01 - epoch 126 lr: 0.000001
2022-10-17 05:59:37 - train: epoch 0126, iter [00100, 02526], lr: 0.000001, loss: 0.1700, CELoss: 0.1700, 
2022-10-17 06:00:11 - train: epoch 0126, iter [00200, 02526], lr: 0.000001, loss: 0.4584, CELoss: 0.4584, 
2022-10-17 06:00:44 - train: epoch 0126, iter [00300, 02526], lr: 0.000001, loss: 0.3249, CELoss: 0.3249, 
2022-10-17 06:01:18 - train: epoch 0126, iter [00400, 02526], lr: 0.000001, loss: 0.1826, CELoss: 0.1826, 
2022-10-17 06:01:51 - train: epoch 0126, iter [00500, 02526], lr: 0.000001, loss: 0.2846, CELoss: 0.2846, 
2022-10-17 06:02:25 - train: epoch 0126, iter [00600, 02526], lr: 0.000001, loss: 0.1528, CELoss: 0.1528, 
2022-10-17 06:02:58 - train: epoch 0126, iter [00700, 02526], lr: 0.000001, loss: 0.2921, CELoss: 0.2921, 
2022-10-17 06:03:32 - train: epoch 0126, iter [00800, 02526], lr: 0.000001, loss: 0.3313, CELoss: 0.3313, 
2022-10-17 06:04:05 - train: epoch 0126, iter [00900, 02526], lr: 0.000001, loss: 0.2523, CELoss: 0.2523, 
2022-10-17 06:04:38 - train: epoch 0126, iter [01000, 02526], lr: 0.000001, loss: 0.1883, CELoss: 0.1883, 
2022-10-17 06:05:12 - train: epoch 0126, iter [01100, 02526], lr: 0.000001, loss: 0.4407, CELoss: 0.4407, 
2022-10-17 06:05:45 - train: epoch 0126, iter [01200, 02526], lr: 0.000001, loss: 0.1928, CELoss: 0.1928, 
2022-10-17 06:06:18 - train: epoch 0126, iter [01300, 02526], lr: 0.000001, loss: 0.3382, CELoss: 0.3382, 
2022-10-17 06:06:51 - train: epoch 0126, iter [01400, 02526], lr: 0.000001, loss: 0.3422, CELoss: 0.3422, 
2022-10-17 06:07:25 - train: epoch 0126, iter [01500, 02526], lr: 0.000001, loss: 0.4667, CELoss: 0.4667, 
2022-10-17 06:07:58 - train: epoch 0126, iter [01600, 02526], lr: 0.000001, loss: 0.4166, CELoss: 0.4166, 
2022-10-17 06:08:32 - train: epoch 0126, iter [01700, 02526], lr: 0.000001, loss: 0.3961, CELoss: 0.3961, 
2022-10-17 06:09:05 - train: epoch 0126, iter [01800, 02526], lr: 0.000001, loss: 0.3095, CELoss: 0.3095, 
2022-10-17 06:09:38 - train: epoch 0126, iter [01900, 02526], lr: 0.000001, loss: 0.3461, CELoss: 0.3461, 
2022-10-17 06:10:12 - train: epoch 0126, iter [02000, 02526], lr: 0.000001, loss: 0.2308, CELoss: 0.2308, 
2022-10-17 06:10:45 - train: epoch 0126, iter [02100, 02526], lr: 0.000001, loss: 0.3644, CELoss: 0.3644, 
2022-10-17 06:11:19 - train: epoch 0126, iter [02200, 02526], lr: 0.000001, loss: 0.2803, CELoss: 0.2803, 
2022-10-17 06:11:52 - train: epoch 0126, iter [02300, 02526], lr: 0.000001, loss: 0.3961, CELoss: 0.3961, 
2022-10-17 06:12:25 - train: epoch 0126, iter [02400, 02526], lr: 0.000001, loss: 0.2075, CELoss: 0.2075, 
2022-10-17 06:12:59 - train: epoch 0126, iter [02500, 02526], lr: 0.000001, loss: 0.2287, CELoss: 0.2287, 
2022-10-17 06:13:09 - train: epoch 126, train_loss: 0.2669
2022-10-17 06:13:11 - until epoch: 126, best_metric: 40.584%
2022-10-17 06:13:11 - epoch 127 lr: 0.000001
2022-10-17 06:13:47 - train: epoch 0127, iter [00100, 02526], lr: 0.000001, loss: 0.2102, CELoss: 0.2102, 
2022-10-17 06:14:20 - train: epoch 0127, iter [00200, 02526], lr: 0.000001, loss: 0.1060, CELoss: 0.1060, 
2022-10-17 06:14:54 - train: epoch 0127, iter [00300, 02526], lr: 0.000001, loss: 0.2425, CELoss: 0.2425, 
2022-10-17 06:15:27 - train: epoch 0127, iter [00400, 02526], lr: 0.000001, loss: 0.4001, CELoss: 0.4001, 
2022-10-17 06:16:00 - train: epoch 0127, iter [00500, 02526], lr: 0.000001, loss: 0.2060, CELoss: 0.2060, 
2022-10-17 06:16:34 - train: epoch 0127, iter [00600, 02526], lr: 0.000001, loss: 0.1645, CELoss: 0.1645, 
2022-10-17 06:17:07 - train: epoch 0127, iter [00700, 02526], lr: 0.000001, loss: 0.1966, CELoss: 0.1966, 
2022-10-17 06:17:41 - train: epoch 0127, iter [00800, 02526], lr: 0.000001, loss: 0.2186, CELoss: 0.2186, 
2022-10-17 06:18:14 - train: epoch 0127, iter [00900, 02526], lr: 0.000001, loss: 0.4090, CELoss: 0.4090, 
2022-10-17 06:18:47 - train: epoch 0127, iter [01000, 02526], lr: 0.000001, loss: 0.2981, CELoss: 0.2981, 
2022-10-17 06:19:21 - train: epoch 0127, iter [01100, 02526], lr: 0.000001, loss: 0.2456, CELoss: 0.2456, 
2022-10-17 06:19:54 - train: epoch 0127, iter [01200, 02526], lr: 0.000001, loss: 0.1288, CELoss: 0.1288, 
2022-10-17 06:20:28 - train: epoch 0127, iter [01300, 02526], lr: 0.000001, loss: 0.2851, CELoss: 0.2851, 
2022-10-17 06:21:01 - train: epoch 0127, iter [01400, 02526], lr: 0.000001, loss: 0.2426, CELoss: 0.2426, 
2022-10-17 06:21:34 - train: epoch 0127, iter [01500, 02526], lr: 0.000001, loss: 0.2124, CELoss: 0.2124, 
2022-10-17 06:22:07 - train: epoch 0127, iter [01600, 02526], lr: 0.000001, loss: 0.2261, CELoss: 0.2261, 
2022-10-17 06:22:41 - train: epoch 0127, iter [01700, 02526], lr: 0.000001, loss: 0.2093, CELoss: 0.2093, 
2022-10-17 06:23:14 - train: epoch 0127, iter [01800, 02526], lr: 0.000001, loss: 0.2158, CELoss: 0.2158, 
2022-10-17 06:23:47 - train: epoch 0127, iter [01900, 02526], lr: 0.000001, loss: 0.2659, CELoss: 0.2659, 
2022-10-17 06:24:21 - train: epoch 0127, iter [02000, 02526], lr: 0.000001, loss: 0.2191, CELoss: 0.2191, 
2022-10-17 06:24:54 - train: epoch 0127, iter [02100, 02526], lr: 0.000001, loss: 0.1766, CELoss: 0.1766, 
2022-10-17 06:25:28 - train: epoch 0127, iter [02200, 02526], lr: 0.000001, loss: 0.2377, CELoss: 0.2377, 
2022-10-17 06:26:02 - train: epoch 0127, iter [02300, 02526], lr: 0.000001, loss: 0.2378, CELoss: 0.2378, 
2022-10-17 06:26:35 - train: epoch 0127, iter [02400, 02526], lr: 0.000001, loss: 0.3244, CELoss: 0.3244, 
2022-10-17 06:27:08 - train: epoch 0127, iter [02500, 02526], lr: 0.000001, loss: 0.3487, CELoss: 0.3487, 
2022-10-17 06:27:18 - train: epoch 127, train_loss: 0.2669
2022-10-17 06:27:21 - until epoch: 127, best_metric: 40.584%
2022-10-17 06:27:21 - epoch 128 lr: 0.000001
2022-10-17 06:27:57 - train: epoch 0128, iter [00100, 02526], lr: 0.000001, loss: 0.2351, CELoss: 0.2351, 
2022-10-17 06:28:31 - train: epoch 0128, iter [00200, 02526], lr: 0.000001, loss: 0.2058, CELoss: 0.2058, 
2022-10-17 06:29:04 - train: epoch 0128, iter [00300, 02526], lr: 0.000001, loss: 0.2232, CELoss: 0.2232, 
2022-10-17 06:29:38 - train: epoch 0128, iter [00400, 02526], lr: 0.000001, loss: 0.3775, CELoss: 0.3775, 
2022-10-17 06:30:11 - train: epoch 0128, iter [00500, 02526], lr: 0.000001, loss: 0.2269, CELoss: 0.2269, 
2022-10-17 06:30:44 - train: epoch 0128, iter [00600, 02526], lr: 0.000001, loss: 0.1432, CELoss: 0.1432, 
2022-10-17 06:31:18 - train: epoch 0128, iter [00700, 02526], lr: 0.000001, loss: 0.2061, CELoss: 0.2061, 
2022-10-17 06:31:51 - train: epoch 0128, iter [00800, 02526], lr: 0.000001, loss: 0.2070, CELoss: 0.2070, 
2022-10-17 06:32:25 - train: epoch 0128, iter [00900, 02526], lr: 0.000001, loss: 0.2422, CELoss: 0.2422, 
2022-10-17 06:32:58 - train: epoch 0128, iter [01000, 02526], lr: 0.000001, loss: 0.2617, CELoss: 0.2617, 
2022-10-17 06:33:31 - train: epoch 0128, iter [01100, 02526], lr: 0.000001, loss: 0.3009, CELoss: 0.3009, 
2022-10-17 06:34:05 - train: epoch 0128, iter [01200, 02526], lr: 0.000001, loss: 0.2249, CELoss: 0.2249, 
2022-10-17 06:34:38 - train: epoch 0128, iter [01300, 02526], lr: 0.000001, loss: 0.3396, CELoss: 0.3396, 
2022-10-17 06:35:11 - train: epoch 0128, iter [01400, 02526], lr: 0.000001, loss: 0.2235, CELoss: 0.2235, 
2022-10-17 06:35:45 - train: epoch 0128, iter [01500, 02526], lr: 0.000001, loss: 0.1794, CELoss: 0.1794, 
2022-10-17 06:36:18 - train: epoch 0128, iter [01600, 02526], lr: 0.000001, loss: 0.2436, CELoss: 0.2436, 
2022-10-17 06:36:51 - train: epoch 0128, iter [01700, 02526], lr: 0.000001, loss: 0.3435, CELoss: 0.3435, 
2022-10-17 06:37:24 - train: epoch 0128, iter [01800, 02526], lr: 0.000001, loss: 0.2589, CELoss: 0.2589, 
2022-10-17 06:37:58 - train: epoch 0128, iter [01900, 02526], lr: 0.000001, loss: 0.2826, CELoss: 0.2826, 
2022-10-17 06:38:31 - train: epoch 0128, iter [02000, 02526], lr: 0.000001, loss: 0.2795, CELoss: 0.2795, 
2022-10-17 06:39:05 - train: epoch 0128, iter [02100, 02526], lr: 0.000001, loss: 0.2996, CELoss: 0.2996, 
2022-10-17 06:39:38 - train: epoch 0128, iter [02200, 02526], lr: 0.000001, loss: 0.2383, CELoss: 0.2383, 
2022-10-17 06:40:11 - train: epoch 0128, iter [02300, 02526], lr: 0.000001, loss: 0.1699, CELoss: 0.1699, 
2022-10-17 06:40:45 - train: epoch 0128, iter [02400, 02526], lr: 0.000001, loss: 0.1782, CELoss: 0.1782, 
2022-10-17 06:41:18 - train: epoch 0128, iter [02500, 02526], lr: 0.000001, loss: 0.2027, CELoss: 0.2027, 
2022-10-17 06:41:28 - train: epoch 128, train_loss: 0.2674
2022-10-17 06:42:20 - eval: epoch: 128
test_loss: 0.8956780407130718
per_image_load_time: 2.034ms
per_image_inference_time: 18.168ms
exist_num_class: 150.0
mean_precision: 61.513118923245294
mean_recall: 51.109474532309655
mean_iou: 40.65242269772203
mean_dice: 54.443230765097645

2022-10-17 06:42:22 - until epoch: 128, best_metric: 40.652%
2022-10-17 06:42:22 - train done. model: segmenter_vit_base_patch16_mask, train time: 30.615 hours, best_metric: 40.652%
