2022-10-19 08:27:43 - network: resnet50backbone_deeplabv3plus
2022-10-19 08:27:43 - input_image_size: 512
2022-10-19 08:27:43 - num_classes: 150
2022-10-19 08:27:43 - reduce_zero_label: True
2022-10-19 08:27:43 - ignore_index: 255
2022-10-19 08:27:43 - backbone_pretrained_path: /root/code/SimpleAICV-ImageNet-CIFAR-COCO-VOC-training/pretrained_models/classification_training/resnet/resnet50-acc76.264.pth
2022-10-19 08:27:43 - trained_model_path: 
2022-10-19 08:27:43 - loss_list: ['CELoss']
2022-10-19 08:27:43 - train_criterion: {'CELoss': CELoss(
  (softmax): Softmax(dim=-1)
)}
2022-10-19 08:27:43 - loss_name: CELoss
2022-10-19 08:27:43 - test_criterion: CELoss(
  (softmax): Softmax(dim=-1)
)
2022-10-19 08:27:43 - train_dataset: <simpleAICV.semantic_segmentation.datasets.ade20kdataset.ADE20KSemanticSegmentation object at 0x7f35a00f20d0>
2022-10-19 08:27:43 - test_dataset: <simpleAICV.semantic_segmentation.datasets.ade20kdataset.ADE20KSemanticSegmentation object at 0x7f35a18bee50>
2022-10-19 08:27:43 - train_collater: <simpleAICV.semantic_segmentation.common.SemanticSegmentationCollater object at 0x7f35a18beeb0>
2022-10-19 08:27:43 - test_collater: <simpleAICV.semantic_segmentation.common.SemanticSegmentationCollater object at 0x7f35a18bed90>
2022-10-19 08:27:43 - seed: 0
2022-10-19 08:27:43 - batch_size: 8
2022-10-19 08:27:43 - num_workers: 20
2022-10-19 08:27:43 - accumulation_steps: 1
2022-10-19 08:27:43 - optimizer: ('AdamW', {'lr': 0.0001, 'global_weight_decay': False, 'weight_decay': 0.001, 'no_weight_decay_layer_name_list': []})
2022-10-19 08:27:43 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.1, 'milestones': [80, 120]})
2022-10-19 08:27:43 - epochs: 128
2022-10-19 08:27:43 - eval_epoch: [1, 0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125]
2022-10-19 08:27:43 - i: 127
2022-10-19 08:27:43 - print_interval: 100
2022-10-19 08:27:43 - save_model_metric: mean_iou
2022-10-19 08:27:43 - sync_bn: False
2022-10-19 08:27:43 - apex: True
2022-10-19 08:27:43 - use_ema_model: False
2022-10-19 08:27:43 - ema_model_decay: 0.9999
2022-10-19 08:27:43 - gpus_type: NVIDIA RTX A5000
2022-10-19 08:27:43 - gpus_num: 2
2022-10-19 08:27:43 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f35a52022f0>
2022-10-19 08:27:43 - --------------------parameters--------------------
2022-10-19 08:27:43 - name: backbone.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.0.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.0.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.0.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.0.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.0.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.0.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.0.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.0.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.0.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.0.downsample_conv.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.0.downsample_conv.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.0.downsample_conv.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.1.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.1.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.1.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.1.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.1.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.1.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.1.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.1.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.1.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.2.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.2.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.2.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.2.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.2.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.2.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.2.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.2.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer1.2.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.0.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.0.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.0.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.0.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.0.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.0.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.0.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.0.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.0.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.0.downsample_conv.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.0.downsample_conv.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.0.downsample_conv.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.1.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.1.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.1.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.1.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.1.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.1.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.1.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.1.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.1.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.2.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.2.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.2.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.2.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.2.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.2.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.2.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.2.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.2.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.3.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.3.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.3.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.3.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.3.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.3.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.3.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.3.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer2.3.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.0.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.0.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.0.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.0.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.0.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.0.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.0.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.0.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.0.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.0.downsample_conv.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.0.downsample_conv.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.0.downsample_conv.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.1.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.1.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.1.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.1.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.1.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.1.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.1.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.1.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.1.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.2.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.2.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.2.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.2.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.2.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.2.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.2.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.2.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.2.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.3.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.3.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.3.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.3.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.3.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.3.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.3.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.3.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.3.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.4.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.4.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.4.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.4.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.4.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.4.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.4.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.4.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.4.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.5.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.5.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.5.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.5.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.5.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.5.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.5.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.5.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer3.5.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.0.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.0.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.0.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.0.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.0.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.0.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.0.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.0.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.0.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.0.downsample_conv.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.0.downsample_conv.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.0.downsample_conv.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.1.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.1.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.1.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.1.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.1.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.1.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.1.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.1.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.1.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.2.conv1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.2.conv1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.2.conv1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.2.conv2.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.2.conv2.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.2.conv2.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.2.conv3.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.2.conv3.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: backbone.layer4.2.conv3.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp0.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp0.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp0.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.0.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.0.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.0.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.0.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.0.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.0.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.0.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.0.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.0.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.aspp.pooling.1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.pooling.1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.pooling.1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.aspp.fuse_conv.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.fuse_conv.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: head.aspp.fuse_conv.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.c1_conv.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: head.c1_conv.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: head.c1_conv.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.0.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.0.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.0.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.0.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.0.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.0.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.1.layer.0.weight, grad: True
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.1.layer.1.weight, grad: True
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.1.layer.1.bias, grad: True
2022-10-19 08:27:43 - name: head.predict_conv.weight, grad: True
2022-10-19 08:27:43 - name: head.predict_conv.bias, grad: True
2022-10-19 08:27:43 - --------------------buffers--------------------
2022-10-19 08:27:43 - name: backbone.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.0.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.0.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.0.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.0.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.0.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.0.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.0.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.0.downsample_conv.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.0.downsample_conv.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.1.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.1.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.1.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.1.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.1.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.1.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.1.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.2.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.2.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.2.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.2.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.2.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.2.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.2.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.2.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer1.2.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.0.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.0.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.0.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.0.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.0.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.0.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.0.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.1.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.1.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.1.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.1.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.1.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.1.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.1.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.2.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.2.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.2.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.2.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.2.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.2.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.2.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.2.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.2.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.3.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.3.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.3.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.3.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.3.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.3.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.3.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.3.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer2.3.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.0.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.0.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.0.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.0.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.0.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.0.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.0.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.1.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.1.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.1.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.1.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.1.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.1.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.1.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.2.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.2.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.2.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.2.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.2.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.2.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.2.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.2.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.2.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.3.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.3.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.3.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.3.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.3.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.3.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.3.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.3.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.3.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.4.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.4.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.4.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.4.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.4.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.4.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.4.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.4.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.4.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.5.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.5.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.5.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.5.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.5.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.5.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.5.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.5.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer3.5.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.0.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.0.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.0.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.0.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.0.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.0.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.0.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.1.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.1.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.1.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.1.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.1.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.1.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.1.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.2.conv1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.2.conv1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.2.conv1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.2.conv2.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.2.conv2.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.2.conv2.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.2.conv3.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.2.conv3.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: backbone.layer4.2.conv3.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp0.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp0.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp0.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.0.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.0.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.0.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.0.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.0.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.0.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.0.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.0.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.0.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: head.aspp.pooling.1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: head.aspp.pooling.1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: head.aspp.pooling.1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: head.aspp.fuse_conv.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: head.aspp.fuse_conv.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: head.aspp.fuse_conv.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: head.c1_conv.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: head.c1_conv.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: head.c1_conv.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.0.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.0.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.0.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.0.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.0.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.0.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.1.layer.1.running_mean, grad: False
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.1.layer.1.running_var, grad: False
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.1.layer.1.num_batches_tracked, grad: False
2022-10-19 08:27:43 - -----------no weight decay layers--------------
2022-10-19 08:27:43 - name: backbone.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.3.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.3.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.3.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.3.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.3.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.3.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.3.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.3.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.3.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.3.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.3.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.3.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.4.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.4.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.4.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.4.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.4.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.4.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.5.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.5.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.5.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.5.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.5.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.5.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.0.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.0.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.1.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.1.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.2.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.2.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.2.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.2.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.2.conv3.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.2.conv3.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp0.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp0.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.0.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.0.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.0.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.0.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.0.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.0.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.pooling.1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.pooling.1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.fuse_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.fuse_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.c1_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.c1_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.0.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.0.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.0.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.0.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.predict_conv.bias, weight_decay: 0.0, lr_scale: not setting!
2022-10-19 08:27:43 - -------------weight decay layers---------------
2022-10-19 08:27:43 - name: backbone.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.0.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.0.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.0.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.0.downsample_conv.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.1.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.1.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.1.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.2.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.2.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer1.2.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.0.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.0.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.0.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.1.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.1.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.1.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.2.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.2.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.2.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.3.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.3.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer2.3.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.0.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.0.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.0.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.1.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.1.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.1.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.2.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.2.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.2.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.3.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.3.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.3.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.4.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.4.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.4.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.5.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.5.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer3.5.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.0.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.0.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.0.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.1.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.1.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.1.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.2.conv1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.2.conv2.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: backbone.layer4.2.conv3.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp0.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.0.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp1.layers.1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.0.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp2.layers.1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.0.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.aspp3.layers.1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.pooling.1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.aspp.fuse_conv.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.c1_conv.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.0.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.fuse_conv.0.layers.1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.0.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.fuse_conv.1.layers.1.layer.0.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - name: head.predict_conv.weight, weight_decay: 0.001, lr_scale: not setting!
2022-10-19 08:27:43 - epoch 001 lr: 0.000100
2022-10-19 08:29:11 - train: epoch 0001, iter [00100, 02526], lr: 0.000100, loss: 3.2145, CELoss: 3.2145, 
2022-10-19 08:30:35 - train: epoch 0001, iter [00200, 02526], lr: 0.000100, loss: 2.3215, CELoss: 2.3215, 
2022-10-19 08:32:00 - train: epoch 0001, iter [00300, 02526], lr: 0.000100, loss: 2.8929, CELoss: 2.8929, 
2022-10-19 08:33:24 - train: epoch 0001, iter [00400, 02526], lr: 0.000100, loss: 2.9733, CELoss: 2.9733, 
2022-10-19 08:34:49 - train: epoch 0001, iter [00500, 02526], lr: 0.000100, loss: 3.6673, CELoss: 3.6673, 
2022-10-19 08:36:13 - train: epoch 0001, iter [00600, 02526], lr: 0.000100, loss: 2.4415, CELoss: 2.4415, 
2022-10-19 08:37:38 - train: epoch 0001, iter [00700, 02526], lr: 0.000100, loss: 2.1081, CELoss: 2.1081, 
2022-10-19 08:39:02 - train: epoch 0001, iter [00800, 02526], lr: 0.000100, loss: 2.5765, CELoss: 2.5765, 
2022-10-19 08:40:27 - train: epoch 0001, iter [00900, 02526], lr: 0.000100, loss: 2.0127, CELoss: 2.0127, 
2022-10-19 08:41:51 - train: epoch 0001, iter [01000, 02526], lr: 0.000100, loss: 2.7672, CELoss: 2.7672, 
2022-10-19 08:43:16 - train: epoch 0001, iter [01100, 02526], lr: 0.000100, loss: 1.7092, CELoss: 1.7092, 
2022-10-19 08:44:41 - train: epoch 0001, iter [01200, 02526], lr: 0.000100, loss: 2.7888, CELoss: 2.7888, 
2022-10-19 08:46:05 - train: epoch 0001, iter [01300, 02526], lr: 0.000100, loss: 3.2817, CELoss: 3.2817, 
2022-10-19 08:47:29 - train: epoch 0001, iter [01400, 02526], lr: 0.000100, loss: 1.7776, CELoss: 1.7776, 
2022-10-19 08:48:54 - train: epoch 0001, iter [01500, 02526], lr: 0.000100, loss: 2.2606, CELoss: 2.2606, 
2022-10-19 08:50:19 - train: epoch 0001, iter [01600, 02526], lr: 0.000100, loss: 1.9518, CELoss: 1.9518, 
2022-10-19 08:51:43 - train: epoch 0001, iter [01700, 02526], lr: 0.000100, loss: 1.9108, CELoss: 1.9108, 
2022-10-19 08:53:08 - train: epoch 0001, iter [01800, 02526], lr: 0.000100, loss: 1.8606, CELoss: 1.8606, 
2022-10-19 08:54:33 - train: epoch 0001, iter [01900, 02526], lr: 0.000100, loss: 2.3748, CELoss: 2.3748, 
2022-10-19 08:55:58 - train: epoch 0001, iter [02000, 02526], lr: 0.000100, loss: 1.7367, CELoss: 1.7367, 
2022-10-19 08:57:22 - train: epoch 0001, iter [02100, 02526], lr: 0.000100, loss: 2.0856, CELoss: 2.0856, 
2022-10-19 08:58:46 - train: epoch 0001, iter [02200, 02526], lr: 0.000100, loss: 1.8039, CELoss: 1.8039, 
2022-10-19 09:00:11 - train: epoch 0001, iter [02300, 02526], lr: 0.000100, loss: 2.1181, CELoss: 2.1181, 
2022-10-19 09:01:35 - train: epoch 0001, iter [02400, 02526], lr: 0.000100, loss: 1.7452, CELoss: 1.7452, 
2022-10-19 09:03:00 - train: epoch 0001, iter [02500, 02526], lr: 0.000100, loss: 2.0552, CELoss: 2.0552, 
2022-10-19 09:03:23 - train: epoch 001, train_loss: 2.3002
2022-10-19 09:06:09 - eval: epoch: 001
test_loss: 1.6637770880460738
per_image_load_time: 1.089ms
per_image_inference_time: 76.895ms
exist_num_class: 150.0
mean_precision: 12.774998108568733
mean_recall: 10.96669573515759
mean_iou: 6.924482526980673
mean_dice: 9.835310364126844

2022-10-19 09:06:10 - until epoch: 001, best_metric: 6.924%
2022-10-19 09:06:10 - epoch 002 lr: 0.000100
2022-10-19 09:07:37 - train: epoch 0002, iter [00100, 02526], lr: 0.000100, loss: 2.3285, CELoss: 2.3285, 
2022-10-19 09:09:01 - train: epoch 0002, iter [00200, 02526], lr: 0.000100, loss: 1.3858, CELoss: 1.3858, 
2022-10-19 09:10:26 - train: epoch 0002, iter [00300, 02526], lr: 0.000100, loss: 2.4009, CELoss: 2.4009, 
2022-10-19 09:11:50 - train: epoch 0002, iter [00400, 02526], lr: 0.000100, loss: 1.9537, CELoss: 1.9537, 
2022-10-19 09:13:14 - train: epoch 0002, iter [00500, 02526], lr: 0.000100, loss: 2.1384, CELoss: 2.1384, 
2022-10-19 09:14:39 - train: epoch 0002, iter [00600, 02526], lr: 0.000100, loss: 2.1433, CELoss: 2.1433, 
2022-10-19 09:16:03 - train: epoch 0002, iter [00700, 02526], lr: 0.000100, loss: 2.4331, CELoss: 2.4331, 
2022-10-19 09:17:28 - train: epoch 0002, iter [00800, 02526], lr: 0.000100, loss: 2.6348, CELoss: 2.6348, 
2022-10-19 09:18:53 - train: epoch 0002, iter [00900, 02526], lr: 0.000100, loss: 2.2913, CELoss: 2.2913, 
2022-10-19 09:20:18 - train: epoch 0002, iter [01000, 02526], lr: 0.000100, loss: 1.4710, CELoss: 1.4710, 
2022-10-19 09:21:43 - train: epoch 0002, iter [01100, 02526], lr: 0.000100, loss: 1.5356, CELoss: 1.5356, 
2022-10-19 09:23:08 - train: epoch 0002, iter [01200, 02526], lr: 0.000100, loss: 1.7693, CELoss: 1.7693, 
2022-10-19 09:24:32 - train: epoch 0002, iter [01300, 02526], lr: 0.000100, loss: 1.7733, CELoss: 1.7733, 
2022-10-19 09:25:57 - train: epoch 0002, iter [01400, 02526], lr: 0.000100, loss: 1.8726, CELoss: 1.8726, 
2022-10-19 09:27:22 - train: epoch 0002, iter [01500, 02526], lr: 0.000100, loss: 1.9796, CELoss: 1.9796, 
2022-10-19 09:28:47 - train: epoch 0002, iter [01600, 02526], lr: 0.000100, loss: 1.3776, CELoss: 1.3776, 
2022-10-19 09:30:12 - train: epoch 0002, iter [01700, 02526], lr: 0.000100, loss: 1.6630, CELoss: 1.6630, 
2022-10-19 09:31:37 - train: epoch 0002, iter [01800, 02526], lr: 0.000100, loss: 1.6278, CELoss: 1.6278, 
2022-10-19 09:33:02 - train: epoch 0002, iter [01900, 02526], lr: 0.000100, loss: 1.7896, CELoss: 1.7896, 
2022-10-19 09:34:27 - train: epoch 0002, iter [02000, 02526], lr: 0.000100, loss: 1.5417, CELoss: 1.5417, 
2022-10-19 09:35:52 - train: epoch 0002, iter [02100, 02526], lr: 0.000100, loss: 1.7671, CELoss: 1.7671, 
2022-10-19 09:37:17 - train: epoch 0002, iter [02200, 02526], lr: 0.000100, loss: 1.8602, CELoss: 1.8602, 
2022-10-19 09:38:43 - train: epoch 0002, iter [02300, 02526], lr: 0.000100, loss: 1.8628, CELoss: 1.8628, 
2022-10-19 09:40:08 - train: epoch 0002, iter [02400, 02526], lr: 0.000100, loss: 2.1157, CELoss: 2.1157, 
2022-10-19 09:41:33 - train: epoch 0002, iter [02500, 02526], lr: 0.000100, loss: 1.7691, CELoss: 1.7691, 
2022-10-19 09:41:56 - train: epoch 002, train_loss: 1.8109
2022-10-19 09:41:57 - until epoch: 002, best_metric: 6.924%
2022-10-19 09:41:57 - epoch 003 lr: 0.000100
2022-10-19 09:43:24 - train: epoch 0003, iter [00100, 02526], lr: 0.000100, loss: 2.0899, CELoss: 2.0899, 
2022-10-19 09:44:49 - train: epoch 0003, iter [00200, 02526], lr: 0.000100, loss: 1.4968, CELoss: 1.4968, 
2022-10-19 09:46:14 - train: epoch 0003, iter [00300, 02526], lr: 0.000100, loss: 2.0782, CELoss: 2.0782, 
2022-10-19 09:47:39 - train: epoch 0003, iter [00400, 02526], lr: 0.000100, loss: 1.2659, CELoss: 1.2659, 
2022-10-19 09:49:04 - train: epoch 0003, iter [00500, 02526], lr: 0.000100, loss: 2.2958, CELoss: 2.2958, 
2022-10-19 09:50:29 - train: epoch 0003, iter [00600, 02526], lr: 0.000100, loss: 1.2412, CELoss: 1.2412, 
2022-10-19 09:51:53 - train: epoch 0003, iter [00700, 02526], lr: 0.000100, loss: 1.6899, CELoss: 1.6899, 
2022-10-19 09:53:18 - train: epoch 0003, iter [00800, 02526], lr: 0.000100, loss: 1.7075, CELoss: 1.7075, 
2022-10-19 09:54:43 - train: epoch 0003, iter [00900, 02526], lr: 0.000100, loss: 1.1563, CELoss: 1.1563, 
2022-10-19 09:56:09 - train: epoch 0003, iter [01000, 02526], lr: 0.000100, loss: 1.8534, CELoss: 1.8534, 
2022-10-19 09:57:34 - train: epoch 0003, iter [01100, 02526], lr: 0.000100, loss: 1.7501, CELoss: 1.7501, 
2022-10-19 09:58:59 - train: epoch 0003, iter [01200, 02526], lr: 0.000100, loss: 1.8654, CELoss: 1.8654, 
2022-10-19 10:00:24 - train: epoch 0003, iter [01300, 02526], lr: 0.000100, loss: 1.3653, CELoss: 1.3653, 
2022-10-19 10:01:50 - train: epoch 0003, iter [01400, 02526], lr: 0.000100, loss: 1.4902, CELoss: 1.4902, 
2022-10-19 10:03:15 - train: epoch 0003, iter [01500, 02526], lr: 0.000100, loss: 1.8082, CELoss: 1.8082, 
2022-10-19 10:04:41 - train: epoch 0003, iter [01600, 02526], lr: 0.000100, loss: 2.1131, CELoss: 2.1131, 
2022-10-19 10:06:06 - train: epoch 0003, iter [01700, 02526], lr: 0.000100, loss: 2.0262, CELoss: 2.0262, 
2022-10-19 10:07:32 - train: epoch 0003, iter [01800, 02526], lr: 0.000100, loss: 1.1784, CELoss: 1.1784, 
2022-10-19 10:08:57 - train: epoch 0003, iter [01900, 02526], lr: 0.000100, loss: 2.0145, CELoss: 2.0145, 
2022-10-19 10:10:22 - train: epoch 0003, iter [02000, 02526], lr: 0.000100, loss: 2.4235, CELoss: 2.4235, 
2022-10-19 10:11:47 - train: epoch 0003, iter [02100, 02526], lr: 0.000100, loss: 1.7181, CELoss: 1.7181, 
2022-10-19 10:13:13 - train: epoch 0003, iter [02200, 02526], lr: 0.000100, loss: 1.4629, CELoss: 1.4629, 
2022-10-19 10:14:38 - train: epoch 0003, iter [02300, 02526], lr: 0.000100, loss: 1.5192, CELoss: 1.5192, 
2022-10-19 10:16:03 - train: epoch 0003, iter [02400, 02526], lr: 0.000100, loss: 1.6339, CELoss: 1.6339, 
2022-10-19 10:17:28 - train: epoch 0003, iter [02500, 02526], lr: 0.000100, loss: 2.1001, CELoss: 2.1001, 
2022-10-19 10:17:51 - train: epoch 003, train_loss: 1.6343
2022-10-19 10:17:52 - until epoch: 003, best_metric: 6.924%
2022-10-19 10:17:52 - epoch 004 lr: 0.000100
2022-10-19 10:19:20 - train: epoch 0004, iter [00100, 02526], lr: 0.000100, loss: 2.1584, CELoss: 2.1584, 
2022-10-19 10:20:44 - train: epoch 0004, iter [00200, 02526], lr: 0.000100, loss: 1.1992, CELoss: 1.1992, 
2022-10-19 10:22:09 - train: epoch 0004, iter [00300, 02526], lr: 0.000100, loss: 0.8866, CELoss: 0.8866, 
2022-10-19 10:23:34 - train: epoch 0004, iter [00400, 02526], lr: 0.000100, loss: 2.0235, CELoss: 2.0235, 
2022-10-19 10:24:59 - train: epoch 0004, iter [00500, 02526], lr: 0.000100, loss: 1.3082, CELoss: 1.3082, 
2022-10-19 10:26:24 - train: epoch 0004, iter [00600, 02526], lr: 0.000100, loss: 2.0766, CELoss: 2.0766, 
2022-10-19 10:27:49 - train: epoch 0004, iter [00700, 02526], lr: 0.000100, loss: 1.4372, CELoss: 1.4372, 
2022-10-19 10:29:14 - train: epoch 0004, iter [00800, 02526], lr: 0.000100, loss: 1.9068, CELoss: 1.9068, 
2022-10-19 10:30:39 - train: epoch 0004, iter [00900, 02526], lr: 0.000100, loss: 1.6669, CELoss: 1.6669, 
2022-10-19 10:32:04 - train: epoch 0004, iter [01000, 02526], lr: 0.000100, loss: 2.0089, CELoss: 2.0089, 
2022-10-19 10:33:29 - train: epoch 0004, iter [01100, 02526], lr: 0.000100, loss: 1.4641, CELoss: 1.4641, 
2022-10-19 10:34:54 - train: epoch 0004, iter [01200, 02526], lr: 0.000100, loss: 1.3853, CELoss: 1.3853, 
2022-10-19 10:36:19 - train: epoch 0004, iter [01300, 02526], lr: 0.000100, loss: 1.4819, CELoss: 1.4819, 
2022-10-19 10:37:44 - train: epoch 0004, iter [01400, 02526], lr: 0.000100, loss: 2.2633, CELoss: 2.2633, 
2022-10-19 10:39:09 - train: epoch 0004, iter [01500, 02526], lr: 0.000100, loss: 1.1231, CELoss: 1.1231, 
2022-10-19 10:40:34 - train: epoch 0004, iter [01600, 02526], lr: 0.000100, loss: 1.4458, CELoss: 1.4458, 
2022-10-19 10:41:59 - train: epoch 0004, iter [01700, 02526], lr: 0.000100, loss: 2.4416, CELoss: 2.4416, 
2022-10-19 10:43:24 - train: epoch 0004, iter [01800, 02526], lr: 0.000100, loss: 2.0724, CELoss: 2.0724, 
2022-10-19 10:44:50 - train: epoch 0004, iter [01900, 02526], lr: 0.000100, loss: 1.4314, CELoss: 1.4314, 
2022-10-19 10:46:14 - train: epoch 0004, iter [02000, 02526], lr: 0.000100, loss: 1.4696, CELoss: 1.4696, 
2022-10-19 10:47:39 - train: epoch 0004, iter [02100, 02526], lr: 0.000100, loss: 1.6425, CELoss: 1.6425, 
2022-10-19 10:49:03 - train: epoch 0004, iter [02200, 02526], lr: 0.000100, loss: 1.3926, CELoss: 1.3926, 
2022-10-19 10:50:28 - train: epoch 0004, iter [02300, 02526], lr: 0.000100, loss: 0.9182, CELoss: 0.9182, 
2022-10-19 10:51:53 - train: epoch 0004, iter [02400, 02526], lr: 0.000100, loss: 1.1413, CELoss: 1.1413, 
2022-10-19 10:53:19 - train: epoch 0004, iter [02500, 02526], lr: 0.000100, loss: 1.1626, CELoss: 1.1626, 
2022-10-19 10:53:42 - train: epoch 004, train_loss: 1.5355
2022-10-19 10:53:43 - until epoch: 004, best_metric: 6.924%
2022-10-19 10:53:43 - epoch 005 lr: 0.000100
2022-10-19 10:55:11 - train: epoch 0005, iter [00100, 02526], lr: 0.000100, loss: 1.4274, CELoss: 1.4274, 
2022-10-19 10:56:35 - train: epoch 0005, iter [00200, 02526], lr: 0.000100, loss: 1.9377, CELoss: 1.9377, 
2022-10-19 10:58:00 - train: epoch 0005, iter [00300, 02526], lr: 0.000100, loss: 0.8966, CELoss: 0.8966, 
2022-10-19 10:59:25 - train: epoch 0005, iter [00400, 02526], lr: 0.000100, loss: 1.4908, CELoss: 1.4908, 
2022-10-19 11:00:50 - train: epoch 0005, iter [00500, 02526], lr: 0.000100, loss: 0.9655, CELoss: 0.9655, 
2022-10-19 11:02:15 - train: epoch 0005, iter [00600, 02526], lr: 0.000100, loss: 1.6126, CELoss: 1.6126, 
2022-10-19 11:03:40 - train: epoch 0005, iter [00700, 02526], lr: 0.000100, loss: 1.7683, CELoss: 1.7683, 
2022-10-19 11:05:05 - train: epoch 0005, iter [00800, 02526], lr: 0.000100, loss: 1.9183, CELoss: 1.9183, 
2022-10-19 11:06:30 - train: epoch 0005, iter [00900, 02526], lr: 0.000100, loss: 1.1789, CELoss: 1.1789, 
2022-10-19 11:07:55 - train: epoch 0005, iter [01000, 02526], lr: 0.000100, loss: 1.4271, CELoss: 1.4271, 
2022-10-19 11:09:21 - train: epoch 0005, iter [01100, 02526], lr: 0.000100, loss: 1.7853, CELoss: 1.7853, 
2022-10-19 11:10:46 - train: epoch 0005, iter [01200, 02526], lr: 0.000100, loss: 1.3607, CELoss: 1.3607, 
2022-10-19 11:12:11 - train: epoch 0005, iter [01300, 02526], lr: 0.000100, loss: 1.3677, CELoss: 1.3677, 
2022-10-19 11:13:36 - train: epoch 0005, iter [01400, 02526], lr: 0.000100, loss: 1.2852, CELoss: 1.2852, 
2022-10-19 11:15:01 - train: epoch 0005, iter [01500, 02526], lr: 0.000100, loss: 2.2057, CELoss: 2.2057, 
2022-10-19 11:16:26 - train: epoch 0005, iter [01600, 02526], lr: 0.000100, loss: 1.5472, CELoss: 1.5472, 
2022-10-19 11:17:51 - train: epoch 0005, iter [01700, 02526], lr: 0.000100, loss: 1.5673, CELoss: 1.5673, 
2022-10-19 11:19:15 - train: epoch 0005, iter [01800, 02526], lr: 0.000100, loss: 0.7330, CELoss: 0.7330, 
2022-10-19 11:20:40 - train: epoch 0005, iter [01900, 02526], lr: 0.000100, loss: 1.2094, CELoss: 1.2094, 
2022-10-19 11:22:05 - train: epoch 0005, iter [02000, 02526], lr: 0.000100, loss: 0.8480, CELoss: 0.8480, 
2022-10-19 11:23:29 - train: epoch 0005, iter [02100, 02526], lr: 0.000100, loss: 2.0463, CELoss: 2.0463, 
2022-10-19 11:24:54 - train: epoch 0005, iter [02200, 02526], lr: 0.000100, loss: 1.1212, CELoss: 1.1212, 
2022-10-19 11:26:19 - train: epoch 0005, iter [02300, 02526], lr: 0.000100, loss: 1.4251, CELoss: 1.4251, 
2022-10-19 11:27:44 - train: epoch 0005, iter [02400, 02526], lr: 0.000100, loss: 1.3260, CELoss: 1.3260, 
2022-10-19 11:29:08 - train: epoch 0005, iter [02500, 02526], lr: 0.000100, loss: 1.2490, CELoss: 1.2490, 
2022-10-19 11:29:32 - train: epoch 005, train_loss: 1.4603
2022-10-19 11:32:18 - eval: epoch: 005
test_loss: 1.3129255378246307
per_image_load_time: 1.051ms
per_image_inference_time: 76.491ms
exist_num_class: 150.0
mean_precision: 31.241471851047685
mean_recall: 23.59429733274033
mean_iou: 15.188545280614402
mean_dice: 22.439792139867105

2022-10-19 11:32:19 - until epoch: 005, best_metric: 15.189%
2022-10-19 11:32:19 - epoch 006 lr: 0.000100
2022-10-19 11:33:47 - train: epoch 0006, iter [00100, 02526], lr: 0.000100, loss: 1.5168, CELoss: 1.5168, 
2022-10-19 11:35:12 - train: epoch 0006, iter [00200, 02526], lr: 0.000100, loss: 1.3472, CELoss: 1.3472, 
2022-10-19 11:36:37 - train: epoch 0006, iter [00300, 02526], lr: 0.000100, loss: 1.0474, CELoss: 1.0474, 
2022-10-19 11:38:02 - train: epoch 0006, iter [00400, 02526], lr: 0.000100, loss: 1.3010, CELoss: 1.3010, 
2022-10-19 11:39:27 - train: epoch 0006, iter [00500, 02526], lr: 0.000100, loss: 1.4283, CELoss: 1.4283, 
2022-10-19 11:40:53 - train: epoch 0006, iter [00600, 02526], lr: 0.000100, loss: 1.5895, CELoss: 1.5895, 
2022-10-19 11:42:18 - train: epoch 0006, iter [00700, 02526], lr: 0.000100, loss: 1.0317, CELoss: 1.0317, 
2022-10-19 11:43:43 - train: epoch 0006, iter [00800, 02526], lr: 0.000100, loss: 1.2594, CELoss: 1.2594, 
2022-10-19 11:45:08 - train: epoch 0006, iter [00900, 02526], lr: 0.000100, loss: 1.2123, CELoss: 1.2123, 
2022-10-19 11:46:33 - train: epoch 0006, iter [01000, 02526], lr: 0.000100, loss: 1.5086, CELoss: 1.5086, 
2022-10-19 11:47:58 - train: epoch 0006, iter [01100, 02526], lr: 0.000100, loss: 1.3448, CELoss: 1.3448, 
2022-10-19 11:49:23 - train: epoch 0006, iter [01200, 02526], lr: 0.000100, loss: 1.4763, CELoss: 1.4763, 
2022-10-19 11:50:48 - train: epoch 0006, iter [01300, 02526], lr: 0.000100, loss: 1.8767, CELoss: 1.8767, 
2022-10-19 11:52:13 - train: epoch 0006, iter [01400, 02526], lr: 0.000100, loss: 1.7439, CELoss: 1.7439, 
2022-10-19 11:53:37 - train: epoch 0006, iter [01500, 02526], lr: 0.000100, loss: 1.6313, CELoss: 1.6313, 
2022-10-19 11:55:01 - train: epoch 0006, iter [01600, 02526], lr: 0.000100, loss: 1.7520, CELoss: 1.7520, 
2022-10-19 11:56:26 - train: epoch 0006, iter [01700, 02526], lr: 0.000100, loss: 1.3606, CELoss: 1.3606, 
2022-10-19 11:57:51 - train: epoch 0006, iter [01800, 02526], lr: 0.000100, loss: 0.9753, CELoss: 0.9753, 
2022-10-19 11:59:15 - train: epoch 0006, iter [01900, 02526], lr: 0.000100, loss: 1.4106, CELoss: 1.4106, 
2022-10-19 12:00:40 - train: epoch 0006, iter [02000, 02526], lr: 0.000100, loss: 0.8501, CELoss: 0.8501, 
2022-10-19 12:02:04 - train: epoch 0006, iter [02100, 02526], lr: 0.000100, loss: 1.5986, CELoss: 1.5986, 
2022-10-19 12:03:30 - train: epoch 0006, iter [02200, 02526], lr: 0.000100, loss: 1.3817, CELoss: 1.3817, 
2022-10-19 12:04:54 - train: epoch 0006, iter [02300, 02526], lr: 0.000100, loss: 1.1079, CELoss: 1.1079, 
2022-10-19 12:06:19 - train: epoch 0006, iter [02400, 02526], lr: 0.000100, loss: 1.1540, CELoss: 1.1540, 
2022-10-19 12:07:44 - train: epoch 0006, iter [02500, 02526], lr: 0.000100, loss: 2.4598, CELoss: 2.4598, 
2022-10-19 12:08:07 - train: epoch 006, train_loss: 1.4126
2022-10-19 12:08:07 - until epoch: 006, best_metric: 15.189%
2022-10-19 12:08:07 - epoch 007 lr: 0.000100
2022-10-19 12:09:35 - train: epoch 0007, iter [00100, 02526], lr: 0.000100, loss: 1.3135, CELoss: 1.3135, 
2022-10-19 12:11:00 - train: epoch 0007, iter [00200, 02526], lr: 0.000100, loss: 0.9676, CELoss: 0.9676, 
2022-10-19 12:12:24 - train: epoch 0007, iter [00300, 02526], lr: 0.000100, loss: 1.3795, CELoss: 1.3795, 
2022-10-19 12:13:49 - train: epoch 0007, iter [00400, 02526], lr: 0.000100, loss: 1.7789, CELoss: 1.7789, 
2022-10-19 12:15:14 - train: epoch 0007, iter [00500, 02526], lr: 0.000100, loss: 1.2477, CELoss: 1.2477, 
2022-10-19 12:16:39 - train: epoch 0007, iter [00600, 02526], lr: 0.000100, loss: 1.4284, CELoss: 1.4284, 
2022-10-19 12:18:05 - train: epoch 0007, iter [00700, 02526], lr: 0.000100, loss: 1.8433, CELoss: 1.8433, 
2022-10-19 12:19:30 - train: epoch 0007, iter [00800, 02526], lr: 0.000100, loss: 1.5410, CELoss: 1.5410, 
2022-10-19 12:20:55 - train: epoch 0007, iter [00900, 02526], lr: 0.000100, loss: 1.0384, CELoss: 1.0384, 
2022-10-19 12:22:20 - train: epoch 0007, iter [01000, 02526], lr: 0.000100, loss: 1.0889, CELoss: 1.0889, 
2022-10-19 12:23:45 - train: epoch 0007, iter [01100, 02526], lr: 0.000100, loss: 1.2943, CELoss: 1.2943, 
2022-10-19 12:25:10 - train: epoch 0007, iter [01200, 02526], lr: 0.000100, loss: 1.4238, CELoss: 1.4238, 
2022-10-19 12:26:35 - train: epoch 0007, iter [01300, 02526], lr: 0.000100, loss: 1.4164, CELoss: 1.4164, 
2022-10-19 12:28:00 - train: epoch 0007, iter [01400, 02526], lr: 0.000100, loss: 1.1377, CELoss: 1.1377, 
2022-10-19 12:29:25 - train: epoch 0007, iter [01500, 02526], lr: 0.000100, loss: 1.2907, CELoss: 1.2907, 
2022-10-19 12:30:50 - train: epoch 0007, iter [01600, 02526], lr: 0.000100, loss: 1.4100, CELoss: 1.4100, 
2022-10-19 12:32:14 - train: epoch 0007, iter [01700, 02526], lr: 0.000100, loss: 1.6327, CELoss: 1.6327, 
2022-10-19 12:33:39 - train: epoch 0007, iter [01800, 02526], lr: 0.000100, loss: 1.7195, CELoss: 1.7195, 
2022-10-19 12:35:04 - train: epoch 0007, iter [01900, 02526], lr: 0.000100, loss: 1.4974, CELoss: 1.4974, 
2022-10-19 12:36:29 - train: epoch 0007, iter [02000, 02526], lr: 0.000100, loss: 1.0956, CELoss: 1.0956, 
2022-10-19 12:37:53 - train: epoch 0007, iter [02100, 02526], lr: 0.000100, loss: 1.2821, CELoss: 1.2821, 
2022-10-19 12:39:18 - train: epoch 0007, iter [02200, 02526], lr: 0.000100, loss: 1.0874, CELoss: 1.0874, 
2022-10-19 12:40:42 - train: epoch 0007, iter [02300, 02526], lr: 0.000100, loss: 1.8155, CELoss: 1.8155, 
2022-10-19 12:42:08 - train: epoch 0007, iter [02400, 02526], lr: 0.000100, loss: 1.1399, CELoss: 1.1399, 
2022-10-19 12:43:33 - train: epoch 0007, iter [02500, 02526], lr: 0.000100, loss: 1.8337, CELoss: 1.8337, 
2022-10-19 12:43:56 - train: epoch 007, train_loss: 1.3787
2022-10-19 12:43:57 - until epoch: 007, best_metric: 15.189%
2022-10-19 12:43:57 - epoch 008 lr: 0.000100
2022-10-19 12:45:24 - train: epoch 0008, iter [00100, 02526], lr: 0.000100, loss: 1.5828, CELoss: 1.5828, 
2022-10-19 12:46:49 - train: epoch 0008, iter [00200, 02526], lr: 0.000100, loss: 1.7418, CELoss: 1.7418, 
2022-10-19 12:48:14 - train: epoch 0008, iter [00300, 02526], lr: 0.000100, loss: 0.7057, CELoss: 0.7057, 
2022-10-19 12:49:39 - train: epoch 0008, iter [00400, 02526], lr: 0.000100, loss: 0.8567, CELoss: 0.8567, 
2022-10-19 12:51:04 - train: epoch 0008, iter [00500, 02526], lr: 0.000100, loss: 1.5096, CELoss: 1.5096, 
2022-10-19 12:52:29 - train: epoch 0008, iter [00600, 02526], lr: 0.000100, loss: 1.5634, CELoss: 1.5634, 
2022-10-19 12:53:54 - train: epoch 0008, iter [00700, 02526], lr: 0.000100, loss: 1.8912, CELoss: 1.8912, 
2022-10-19 12:55:19 - train: epoch 0008, iter [00800, 02526], lr: 0.000100, loss: 1.6839, CELoss: 1.6839, 
2022-10-19 12:56:44 - train: epoch 0008, iter [00900, 02526], lr: 0.000100, loss: 1.3942, CELoss: 1.3942, 
2022-10-19 12:58:09 - train: epoch 0008, iter [01000, 02526], lr: 0.000100, loss: 1.8627, CELoss: 1.8627, 
2022-10-19 12:59:34 - train: epoch 0008, iter [01100, 02526], lr: 0.000100, loss: 1.2322, CELoss: 1.2322, 
2022-10-19 13:00:59 - train: epoch 0008, iter [01200, 02526], lr: 0.000100, loss: 1.3117, CELoss: 1.3117, 
2022-10-19 13:02:24 - train: epoch 0008, iter [01300, 02526], lr: 0.000100, loss: 0.8102, CELoss: 0.8102, 
2022-10-19 13:03:49 - train: epoch 0008, iter [01400, 02526], lr: 0.000100, loss: 1.1491, CELoss: 1.1491, 
2022-10-19 13:05:14 - train: epoch 0008, iter [01500, 02526], lr: 0.000100, loss: 1.0934, CELoss: 1.0934, 
2022-10-19 13:06:39 - train: epoch 0008, iter [01600, 02526], lr: 0.000100, loss: 1.7602, CELoss: 1.7602, 
2022-10-19 13:08:04 - train: epoch 0008, iter [01700, 02526], lr: 0.000100, loss: 0.8890, CELoss: 0.8890, 
2022-10-19 13:09:29 - train: epoch 0008, iter [01800, 02526], lr: 0.000100, loss: 0.8942, CELoss: 0.8942, 
2022-10-19 13:10:54 - train: epoch 0008, iter [01900, 02526], lr: 0.000100, loss: 1.6282, CELoss: 1.6282, 
2022-10-19 13:12:19 - train: epoch 0008, iter [02000, 02526], lr: 0.000100, loss: 1.4808, CELoss: 1.4808, 
2022-10-19 13:13:44 - train: epoch 0008, iter [02100, 02526], lr: 0.000100, loss: 1.0492, CELoss: 1.0492, 
2022-10-19 13:15:09 - train: epoch 0008, iter [02200, 02526], lr: 0.000100, loss: 0.7318, CELoss: 0.7318, 
2022-10-19 13:16:35 - train: epoch 0008, iter [02300, 02526], lr: 0.000100, loss: 1.4202, CELoss: 1.4202, 
2022-10-19 13:18:00 - train: epoch 0008, iter [02400, 02526], lr: 0.000100, loss: 1.3094, CELoss: 1.3094, 
2022-10-19 13:19:25 - train: epoch 0008, iter [02500, 02526], lr: 0.000100, loss: 1.1570, CELoss: 1.1570, 
2022-10-19 13:19:48 - train: epoch 008, train_loss: 1.3297
2022-10-19 13:19:49 - until epoch: 008, best_metric: 15.189%
2022-10-19 13:19:49 - epoch 009 lr: 0.000100
2022-10-19 13:21:16 - train: epoch 0009, iter [00100, 02526], lr: 0.000100, loss: 1.1546, CELoss: 1.1546, 
2022-10-19 13:22:42 - train: epoch 0009, iter [00200, 02526], lr: 0.000100, loss: 1.3205, CELoss: 1.3205, 
2022-10-19 13:24:07 - train: epoch 0009, iter [00300, 02526], lr: 0.000100, loss: 1.5803, CELoss: 1.5803, 
2022-10-19 13:25:32 - train: epoch 0009, iter [00400, 02526], lr: 0.000100, loss: 0.9084, CELoss: 0.9084, 
2022-10-19 13:26:57 - train: epoch 0009, iter [00500, 02526], lr: 0.000100, loss: 1.1498, CELoss: 1.1498, 
2022-10-19 13:28:21 - train: epoch 0009, iter [00600, 02526], lr: 0.000100, loss: 1.4904, CELoss: 1.4904, 
2022-10-19 13:29:46 - train: epoch 0009, iter [00700, 02526], lr: 0.000100, loss: 1.7449, CELoss: 1.7449, 
2022-10-19 13:31:10 - train: epoch 0009, iter [00800, 02526], lr: 0.000100, loss: 1.5492, CELoss: 1.5492, 
2022-10-19 13:32:35 - train: epoch 0009, iter [00900, 02526], lr: 0.000100, loss: 1.1298, CELoss: 1.1298, 
2022-10-19 13:34:00 - train: epoch 0009, iter [01000, 02526], lr: 0.000100, loss: 1.2225, CELoss: 1.2225, 
2022-10-19 13:35:25 - train: epoch 0009, iter [01100, 02526], lr: 0.000100, loss: 1.8217, CELoss: 1.8217, 
2022-10-19 13:36:50 - train: epoch 0009, iter [01200, 02526], lr: 0.000100, loss: 1.4642, CELoss: 1.4642, 
2022-10-19 13:38:15 - train: epoch 0009, iter [01300, 02526], lr: 0.000100, loss: 1.6596, CELoss: 1.6596, 
2022-10-19 13:39:40 - train: epoch 0009, iter [01400, 02526], lr: 0.000100, loss: 0.7443, CELoss: 0.7443, 
2022-10-19 13:41:04 - train: epoch 0009, iter [01500, 02526], lr: 0.000100, loss: 1.0332, CELoss: 1.0332, 
2022-10-19 13:42:30 - train: epoch 0009, iter [01600, 02526], lr: 0.000100, loss: 1.3236, CELoss: 1.3236, 
2022-10-19 13:43:54 - train: epoch 0009, iter [01700, 02526], lr: 0.000100, loss: 1.4206, CELoss: 1.4206, 
2022-10-19 13:45:19 - train: epoch 0009, iter [01800, 02526], lr: 0.000100, loss: 1.0122, CELoss: 1.0122, 
2022-10-19 13:46:44 - train: epoch 0009, iter [01900, 02526], lr: 0.000100, loss: 1.3147, CELoss: 1.3147, 
2022-10-19 13:48:09 - train: epoch 0009, iter [02000, 02526], lr: 0.000100, loss: 0.9502, CELoss: 0.9502, 
2022-10-19 13:49:34 - train: epoch 0009, iter [02100, 02526], lr: 0.000100, loss: 1.3004, CELoss: 1.3004, 
2022-10-19 13:50:59 - train: epoch 0009, iter [02200, 02526], lr: 0.000100, loss: 1.8127, CELoss: 1.8127, 
2022-10-19 13:52:24 - train: epoch 0009, iter [02300, 02526], lr: 0.000100, loss: 1.2365, CELoss: 1.2365, 
2022-10-19 13:53:49 - train: epoch 0009, iter [02400, 02526], lr: 0.000100, loss: 1.2908, CELoss: 1.2908, 
2022-10-19 13:55:14 - train: epoch 0009, iter [02500, 02526], lr: 0.000100, loss: 1.6419, CELoss: 1.6419, 
2022-10-19 13:55:37 - train: epoch 009, train_loss: 1.2981
2022-10-19 13:55:38 - until epoch: 009, best_metric: 15.189%
2022-10-19 13:55:38 - epoch 010 lr: 0.000100
2022-10-19 13:57:05 - train: epoch 0010, iter [00100, 02526], lr: 0.000100, loss: 1.1000, CELoss: 1.1000, 
2022-10-19 13:58:30 - train: epoch 0010, iter [00200, 02526], lr: 0.000100, loss: 1.3526, CELoss: 1.3526, 
2022-10-19 13:59:55 - train: epoch 0010, iter [00300, 02526], lr: 0.000100, loss: 1.3019, CELoss: 1.3019, 
2022-10-19 14:01:21 - train: epoch 0010, iter [00400, 02526], lr: 0.000100, loss: 1.5964, CELoss: 1.5964, 
2022-10-19 14:02:46 - train: epoch 0010, iter [00500, 02526], lr: 0.000100, loss: 1.0440, CELoss: 1.0440, 
2022-10-19 14:04:10 - train: epoch 0010, iter [00600, 02526], lr: 0.000100, loss: 1.5339, CELoss: 1.5339, 
2022-10-19 14:05:35 - train: epoch 0010, iter [00700, 02526], lr: 0.000100, loss: 2.6687, CELoss: 2.6687, 
2022-10-19 14:07:00 - train: epoch 0010, iter [00800, 02526], lr: 0.000100, loss: 1.4744, CELoss: 1.4744, 
2022-10-19 14:08:25 - train: epoch 0010, iter [00900, 02526], lr: 0.000100, loss: 1.0601, CELoss: 1.0601, 
2022-10-19 14:09:50 - train: epoch 0010, iter [01000, 02526], lr: 0.000100, loss: 1.4610, CELoss: 1.4610, 
2022-10-19 14:11:15 - train: epoch 0010, iter [01100, 02526], lr: 0.000100, loss: 1.3144, CELoss: 1.3144, 
2022-10-19 14:12:41 - train: epoch 0010, iter [01200, 02526], lr: 0.000100, loss: 1.5704, CELoss: 1.5704, 
2022-10-19 14:14:05 - train: epoch 0010, iter [01300, 02526], lr: 0.000100, loss: 1.0191, CELoss: 1.0191, 
2022-10-19 14:15:30 - train: epoch 0010, iter [01400, 02526], lr: 0.000100, loss: 1.1125, CELoss: 1.1125, 
2022-10-19 14:16:55 - train: epoch 0010, iter [01500, 02526], lr: 0.000100, loss: 1.1360, CELoss: 1.1360, 
2022-10-19 14:18:20 - train: epoch 0010, iter [01600, 02526], lr: 0.000100, loss: 1.4995, CELoss: 1.4995, 
2022-10-19 14:19:45 - train: epoch 0010, iter [01700, 02526], lr: 0.000100, loss: 1.0923, CELoss: 1.0923, 
2022-10-19 14:21:10 - train: epoch 0010, iter [01800, 02526], lr: 0.000100, loss: 0.9818, CELoss: 0.9818, 
2022-10-19 14:22:35 - train: epoch 0010, iter [01900, 02526], lr: 0.000100, loss: 2.1013, CELoss: 2.1013, 
2022-10-19 14:24:00 - train: epoch 0010, iter [02000, 02526], lr: 0.000100, loss: 0.6877, CELoss: 0.6877, 
2022-10-19 14:25:25 - train: epoch 0010, iter [02100, 02526], lr: 0.000100, loss: 1.0513, CELoss: 1.0513, 
2022-10-19 14:26:50 - train: epoch 0010, iter [02200, 02526], lr: 0.000100, loss: 1.0625, CELoss: 1.0625, 
2022-10-19 14:28:15 - train: epoch 0010, iter [02300, 02526], lr: 0.000100, loss: 0.9268, CELoss: 0.9268, 
2022-10-19 14:29:40 - train: epoch 0010, iter [02400, 02526], lr: 0.000100, loss: 1.5511, CELoss: 1.5511, 
2022-10-19 14:31:04 - train: epoch 0010, iter [02500, 02526], lr: 0.000100, loss: 1.5086, CELoss: 1.5086, 
2022-10-19 14:31:28 - train: epoch 010, train_loss: 1.2630
2022-10-19 14:34:15 - eval: epoch: 010
test_loss: 1.2340627015829086
per_image_load_time: 0.982ms
per_image_inference_time: 76.616ms
exist_num_class: 150.0
mean_precision: 36.74477252433189
mean_recall: 31.376544826690505
mean_iou: 19.737274781278984
mean_dice: 29.131885688463143

2022-10-19 14:34:16 - until epoch: 010, best_metric: 19.737%
2022-10-19 14:34:16 - epoch 011 lr: 0.000100
2022-10-19 14:35:44 - train: epoch 0011, iter [00100, 02526], lr: 0.000100, loss: 1.1500, CELoss: 1.1500, 
2022-10-19 14:37:09 - train: epoch 0011, iter [00200, 02526], lr: 0.000100, loss: 1.3223, CELoss: 1.3223, 
2022-10-19 14:38:33 - train: epoch 0011, iter [00300, 02526], lr: 0.000100, loss: 1.3328, CELoss: 1.3328, 
2022-10-19 14:39:58 - train: epoch 0011, iter [00400, 02526], lr: 0.000100, loss: 1.2860, CELoss: 1.2860, 
2022-10-19 14:41:23 - train: epoch 0011, iter [00500, 02526], lr: 0.000100, loss: 1.4415, CELoss: 1.4415, 
2022-10-19 14:42:49 - train: epoch 0011, iter [00600, 02526], lr: 0.000100, loss: 0.9535, CELoss: 0.9535, 
2022-10-19 14:44:14 - train: epoch 0011, iter [00700, 02526], lr: 0.000100, loss: 0.8113, CELoss: 0.8113, 
2022-10-19 14:45:38 - train: epoch 0011, iter [00800, 02526], lr: 0.000100, loss: 1.4862, CELoss: 1.4862, 
2022-10-19 14:47:04 - train: epoch 0011, iter [00900, 02526], lr: 0.000100, loss: 1.3311, CELoss: 1.3311, 
2022-10-19 14:48:28 - train: epoch 0011, iter [01000, 02526], lr: 0.000100, loss: 1.1387, CELoss: 1.1387, 
2022-10-19 14:49:53 - train: epoch 0011, iter [01100, 02526], lr: 0.000100, loss: 1.1136, CELoss: 1.1136, 
2022-10-19 14:51:18 - train: epoch 0011, iter [01200, 02526], lr: 0.000100, loss: 1.2743, CELoss: 1.2743, 
2022-10-19 14:52:43 - train: epoch 0011, iter [01300, 02526], lr: 0.000100, loss: 0.8493, CELoss: 0.8493, 
2022-10-19 14:54:08 - train: epoch 0011, iter [01400, 02526], lr: 0.000100, loss: 1.1120, CELoss: 1.1120, 
2022-10-19 14:55:34 - train: epoch 0011, iter [01500, 02526], lr: 0.000100, loss: 1.4917, CELoss: 1.4917, 
2022-10-19 14:56:59 - train: epoch 0011, iter [01600, 02526], lr: 0.000100, loss: 0.8476, CELoss: 0.8476, 
2022-10-19 14:58:24 - train: epoch 0011, iter [01700, 02526], lr: 0.000100, loss: 0.9922, CELoss: 0.9922, 
2022-10-19 14:59:49 - train: epoch 0011, iter [01800, 02526], lr: 0.000100, loss: 1.0473, CELoss: 1.0473, 
2022-10-19 15:01:15 - train: epoch 0011, iter [01900, 02526], lr: 0.000100, loss: 1.5225, CELoss: 1.5225, 
2022-10-19 15:02:40 - train: epoch 0011, iter [02000, 02526], lr: 0.000100, loss: 1.8500, CELoss: 1.8500, 
2022-10-19 15:04:05 - train: epoch 0011, iter [02100, 02526], lr: 0.000100, loss: 1.7625, CELoss: 1.7625, 
2022-10-19 15:05:31 - train: epoch 0011, iter [02200, 02526], lr: 0.000100, loss: 1.3623, CELoss: 1.3623, 
2022-10-19 15:06:56 - train: epoch 0011, iter [02300, 02526], lr: 0.000100, loss: 1.4313, CELoss: 1.4313, 
2022-10-19 15:08:21 - train: epoch 0011, iter [02400, 02526], lr: 0.000100, loss: 0.9961, CELoss: 0.9961, 
2022-10-19 15:09:46 - train: epoch 0011, iter [02500, 02526], lr: 0.000100, loss: 0.9834, CELoss: 0.9834, 
2022-10-19 15:10:10 - train: epoch 011, train_loss: 1.2426
2022-10-19 15:10:10 - until epoch: 011, best_metric: 19.737%
2022-10-19 15:10:10 - epoch 012 lr: 0.000100
2022-10-19 15:11:38 - train: epoch 0012, iter [00100, 02526], lr: 0.000100, loss: 1.1806, CELoss: 1.1806, 
2022-10-19 15:13:03 - train: epoch 0012, iter [00200, 02526], lr: 0.000100, loss: 1.4291, CELoss: 1.4291, 
2022-10-19 15:14:29 - train: epoch 0012, iter [00300, 02526], lr: 0.000100, loss: 1.3340, CELoss: 1.3340, 
2022-10-19 15:15:54 - train: epoch 0012, iter [00400, 02526], lr: 0.000100, loss: 1.4961, CELoss: 1.4961, 
2022-10-19 15:17:19 - train: epoch 0012, iter [00500, 02526], lr: 0.000100, loss: 1.7156, CELoss: 1.7156, 
2022-10-19 15:18:44 - train: epoch 0012, iter [00600, 02526], lr: 0.000100, loss: 0.9368, CELoss: 0.9368, 
2022-10-19 15:20:10 - train: epoch 0012, iter [00700, 02526], lr: 0.000100, loss: 1.1244, CELoss: 1.1244, 
2022-10-19 15:21:35 - train: epoch 0012, iter [00800, 02526], lr: 0.000100, loss: 0.9818, CELoss: 0.9818, 
2022-10-19 15:23:00 - train: epoch 0012, iter [00900, 02526], lr: 0.000100, loss: 1.0024, CELoss: 1.0024, 
2022-10-19 15:24:25 - train: epoch 0012, iter [01000, 02526], lr: 0.000100, loss: 0.9721, CELoss: 0.9721, 
2022-10-19 15:25:50 - train: epoch 0012, iter [01100, 02526], lr: 0.000100, loss: 1.3776, CELoss: 1.3776, 
2022-10-19 15:27:16 - train: epoch 0012, iter [01200, 02526], lr: 0.000100, loss: 1.2678, CELoss: 1.2678, 
2022-10-19 15:28:40 - train: epoch 0012, iter [01300, 02526], lr: 0.000100, loss: 1.4012, CELoss: 1.4012, 
2022-10-19 15:30:05 - train: epoch 0012, iter [01400, 02526], lr: 0.000100, loss: 0.6863, CELoss: 0.6863, 
2022-10-19 15:31:30 - train: epoch 0012, iter [01500, 02526], lr: 0.000100, loss: 1.3984, CELoss: 1.3984, 
2022-10-19 15:32:55 - train: epoch 0012, iter [01600, 02526], lr: 0.000100, loss: 1.6968, CELoss: 1.6968, 
2022-10-19 15:34:21 - train: epoch 0012, iter [01700, 02526], lr: 0.000100, loss: 1.2230, CELoss: 1.2230, 
2022-10-19 15:35:46 - train: epoch 0012, iter [01800, 02526], lr: 0.000100, loss: 0.9742, CELoss: 0.9742, 
2022-10-19 15:37:10 - train: epoch 0012, iter [01900, 02526], lr: 0.000100, loss: 1.2709, CELoss: 1.2709, 
2022-10-19 15:38:36 - train: epoch 0012, iter [02000, 02526], lr: 0.000100, loss: 1.4034, CELoss: 1.4034, 
2022-10-19 15:40:01 - train: epoch 0012, iter [02100, 02526], lr: 0.000100, loss: 1.0814, CELoss: 1.0814, 
2022-10-19 15:41:26 - train: epoch 0012, iter [02200, 02526], lr: 0.000100, loss: 0.9862, CELoss: 0.9862, 
2022-10-19 15:42:51 - train: epoch 0012, iter [02300, 02526], lr: 0.000100, loss: 1.7112, CELoss: 1.7112, 
2022-10-19 15:44:17 - train: epoch 0012, iter [02400, 02526], lr: 0.000100, loss: 1.6399, CELoss: 1.6399, 
2022-10-19 15:45:42 - train: epoch 0012, iter [02500, 02526], lr: 0.000100, loss: 0.9248, CELoss: 0.9248, 
2022-10-19 15:46:06 - train: epoch 012, train_loss: 1.2222
2022-10-19 15:46:06 - until epoch: 012, best_metric: 19.737%
2022-10-19 15:46:06 - epoch 013 lr: 0.000100
2022-10-19 15:47:34 - train: epoch 0013, iter [00100, 02526], lr: 0.000100, loss: 1.0680, CELoss: 1.0680, 
2022-10-19 15:48:59 - train: epoch 0013, iter [00200, 02526], lr: 0.000100, loss: 1.8619, CELoss: 1.8619, 
2022-10-19 15:50:25 - train: epoch 0013, iter [00300, 02526], lr: 0.000100, loss: 0.8149, CELoss: 0.8149, 
2022-10-19 15:51:50 - train: epoch 0013, iter [00400, 02526], lr: 0.000100, loss: 1.0338, CELoss: 1.0338, 
2022-10-19 15:53:15 - train: epoch 0013, iter [00500, 02526], lr: 0.000100, loss: 1.3884, CELoss: 1.3884, 
2022-10-19 15:54:40 - train: epoch 0013, iter [00600, 02526], lr: 0.000100, loss: 0.7419, CELoss: 0.7419, 
2022-10-19 15:56:05 - train: epoch 0013, iter [00700, 02526], lr: 0.000100, loss: 1.0568, CELoss: 1.0568, 
2022-10-19 15:57:30 - train: epoch 0013, iter [00800, 02526], lr: 0.000100, loss: 0.9036, CELoss: 0.9036, 
2022-10-19 15:58:55 - train: epoch 0013, iter [00900, 02526], lr: 0.000100, loss: 0.8304, CELoss: 0.8304, 
2022-10-19 16:00:20 - train: epoch 0013, iter [01000, 02526], lr: 0.000100, loss: 1.8378, CELoss: 1.8378, 
2022-10-19 16:01:45 - train: epoch 0013, iter [01100, 02526], lr: 0.000100, loss: 1.0982, CELoss: 1.0982, 
2022-10-19 16:03:10 - train: epoch 0013, iter [01200, 02526], lr: 0.000100, loss: 1.1640, CELoss: 1.1640, 
2022-10-19 16:04:35 - train: epoch 0013, iter [01300, 02526], lr: 0.000100, loss: 1.2380, CELoss: 1.2380, 
2022-10-19 16:06:00 - train: epoch 0013, iter [01400, 02526], lr: 0.000100, loss: 1.0063, CELoss: 1.0063, 
2022-10-19 16:07:25 - train: epoch 0013, iter [01500, 02526], lr: 0.000100, loss: 2.0334, CELoss: 2.0334, 
2022-10-19 16:08:50 - train: epoch 0013, iter [01600, 02526], lr: 0.000100, loss: 1.0019, CELoss: 1.0019, 
2022-10-19 16:10:15 - train: epoch 0013, iter [01700, 02526], lr: 0.000100, loss: 1.8541, CELoss: 1.8541, 
2022-10-19 16:11:40 - train: epoch 0013, iter [01800, 02526], lr: 0.000100, loss: 1.2503, CELoss: 1.2503, 
2022-10-19 16:13:05 - train: epoch 0013, iter [01900, 02526], lr: 0.000100, loss: 0.8743, CELoss: 0.8743, 
2022-10-19 16:14:31 - train: epoch 0013, iter [02000, 02526], lr: 0.000100, loss: 1.2036, CELoss: 1.2036, 
2022-10-19 16:15:55 - train: epoch 0013, iter [02100, 02526], lr: 0.000100, loss: 1.3133, CELoss: 1.3133, 
2022-10-19 16:17:20 - train: epoch 0013, iter [02200, 02526], lr: 0.000100, loss: 1.4860, CELoss: 1.4860, 
2022-10-19 16:18:45 - train: epoch 0013, iter [02300, 02526], lr: 0.000100, loss: 1.0177, CELoss: 1.0177, 
2022-10-19 16:20:11 - train: epoch 0013, iter [02400, 02526], lr: 0.000100, loss: 1.0807, CELoss: 1.0807, 
2022-10-19 16:21:36 - train: epoch 0013, iter [02500, 02526], lr: 0.000100, loss: 1.1842, CELoss: 1.1842, 
2022-10-19 16:21:59 - train: epoch 013, train_loss: 1.1964
2022-10-19 16:22:00 - until epoch: 013, best_metric: 19.737%
2022-10-19 16:22:00 - epoch 014 lr: 0.000100
2022-10-19 16:23:27 - train: epoch 0014, iter [00100, 02526], lr: 0.000100, loss: 0.9101, CELoss: 0.9101, 
2022-10-19 16:24:53 - train: epoch 0014, iter [00200, 02526], lr: 0.000100, loss: 1.2137, CELoss: 1.2137, 
2022-10-19 16:26:18 - train: epoch 0014, iter [00300, 02526], lr: 0.000100, loss: 1.5756, CELoss: 1.5756, 
2022-10-19 16:27:43 - train: epoch 0014, iter [00400, 02526], lr: 0.000100, loss: 0.8520, CELoss: 0.8520, 
2022-10-19 16:29:09 - train: epoch 0014, iter [00500, 02526], lr: 0.000100, loss: 0.8056, CELoss: 0.8056, 
2022-10-19 16:30:34 - train: epoch 0014, iter [00600, 02526], lr: 0.000100, loss: 1.7910, CELoss: 1.7910, 
2022-10-19 16:31:59 - train: epoch 0014, iter [00700, 02526], lr: 0.000100, loss: 1.8949, CELoss: 1.8949, 
2022-10-19 16:33:25 - train: epoch 0014, iter [00800, 02526], lr: 0.000100, loss: 1.1477, CELoss: 1.1477, 
2022-10-19 16:34:50 - train: epoch 0014, iter [00900, 02526], lr: 0.000100, loss: 0.8451, CELoss: 0.8451, 
2022-10-19 16:36:15 - train: epoch 0014, iter [01000, 02526], lr: 0.000100, loss: 0.7773, CELoss: 0.7773, 
2022-10-19 16:37:40 - train: epoch 0014, iter [01100, 02526], lr: 0.000100, loss: 1.1223, CELoss: 1.1223, 
2022-10-19 16:39:06 - train: epoch 0014, iter [01200, 02526], lr: 0.000100, loss: 0.9364, CELoss: 0.9364, 
2022-10-19 16:40:31 - train: epoch 0014, iter [01300, 02526], lr: 0.000100, loss: 1.3852, CELoss: 1.3852, 
2022-10-19 16:41:56 - train: epoch 0014, iter [01400, 02526], lr: 0.000100, loss: 1.1300, CELoss: 1.1300, 
2022-10-19 16:43:21 - train: epoch 0014, iter [01500, 02526], lr: 0.000100, loss: 1.0516, CELoss: 1.0516, 
2022-10-19 16:44:47 - train: epoch 0014, iter [01600, 02526], lr: 0.000100, loss: 1.1180, CELoss: 1.1180, 
2022-10-19 16:46:11 - train: epoch 0014, iter [01700, 02526], lr: 0.000100, loss: 3.0555, CELoss: 3.0555, 
2022-10-19 16:47:36 - train: epoch 0014, iter [01800, 02526], lr: 0.000100, loss: 0.9712, CELoss: 0.9712, 
2022-10-19 16:49:01 - train: epoch 0014, iter [01900, 02526], lr: 0.000100, loss: 1.9838, CELoss: 1.9838, 
2022-10-19 16:50:26 - train: epoch 0014, iter [02000, 02526], lr: 0.000100, loss: 1.3204, CELoss: 1.3204, 
2022-10-19 16:51:51 - train: epoch 0014, iter [02100, 02526], lr: 0.000100, loss: 1.1462, CELoss: 1.1462, 
2022-10-19 16:53:16 - train: epoch 0014, iter [02200, 02526], lr: 0.000100, loss: 1.1003, CELoss: 1.1003, 
2022-10-19 16:54:41 - train: epoch 0014, iter [02300, 02526], lr: 0.000100, loss: 1.2663, CELoss: 1.2663, 
2022-10-19 16:56:07 - train: epoch 0014, iter [02400, 02526], lr: 0.000100, loss: 1.5559, CELoss: 1.5559, 
2022-10-19 16:57:32 - train: epoch 0014, iter [02500, 02526], lr: 0.000100, loss: 1.1671, CELoss: 1.1671, 
2022-10-19 16:57:56 - train: epoch 014, train_loss: 1.1846
2022-10-19 16:57:57 - until epoch: 014, best_metric: 19.737%
2022-10-19 16:57:57 - epoch 015 lr: 0.000100
2022-10-19 16:59:24 - train: epoch 0015, iter [00100, 02526], lr: 0.000100, loss: 1.1319, CELoss: 1.1319, 
2022-10-19 17:00:50 - train: epoch 0015, iter [00200, 02526], lr: 0.000100, loss: 0.9947, CELoss: 0.9947, 
2022-10-19 17:02:15 - train: epoch 0015, iter [00300, 02526], lr: 0.000100, loss: 0.9849, CELoss: 0.9849, 
2022-10-19 17:03:41 - train: epoch 0015, iter [00400, 02526], lr: 0.000100, loss: 1.0988, CELoss: 1.0988, 
2022-10-19 17:05:06 - train: epoch 0015, iter [00500, 02526], lr: 0.000100, loss: 1.3843, CELoss: 1.3843, 
2022-10-19 17:06:31 - train: epoch 0015, iter [00600, 02526], lr: 0.000100, loss: 1.2812, CELoss: 1.2812, 
2022-10-19 17:07:56 - train: epoch 0015, iter [00700, 02526], lr: 0.000100, loss: 0.9371, CELoss: 0.9371, 
2022-10-19 17:09:21 - train: epoch 0015, iter [00800, 02526], lr: 0.000100, loss: 0.9404, CELoss: 0.9404, 
2022-10-19 17:10:47 - train: epoch 0015, iter [00900, 02526], lr: 0.000100, loss: 1.2077, CELoss: 1.2077, 
2022-10-19 17:12:12 - train: epoch 0015, iter [01000, 02526], lr: 0.000100, loss: 1.9091, CELoss: 1.9091, 
2022-10-19 17:13:38 - train: epoch 0015, iter [01100, 02526], lr: 0.000100, loss: 1.0659, CELoss: 1.0659, 
2022-10-19 17:15:03 - train: epoch 0015, iter [01200, 02526], lr: 0.000100, loss: 1.1344, CELoss: 1.1344, 
2022-10-19 17:16:28 - train: epoch 0015, iter [01300, 02526], lr: 0.000100, loss: 1.2677, CELoss: 1.2677, 
2022-10-19 17:17:53 - train: epoch 0015, iter [01400, 02526], lr: 0.000100, loss: 1.4660, CELoss: 1.4660, 
2022-10-19 17:19:18 - train: epoch 0015, iter [01500, 02526], lr: 0.000100, loss: 1.3263, CELoss: 1.3263, 
2022-10-19 17:20:44 - train: epoch 0015, iter [01600, 02526], lr: 0.000100, loss: 0.8666, CELoss: 0.8666, 
2022-10-19 17:22:09 - train: epoch 0015, iter [01700, 02526], lr: 0.000100, loss: 0.7529, CELoss: 0.7529, 
2022-10-19 17:23:34 - train: epoch 0015, iter [01800, 02526], lr: 0.000100, loss: 0.9892, CELoss: 0.9892, 
2022-10-19 17:24:59 - train: epoch 0015, iter [01900, 02526], lr: 0.000100, loss: 1.3320, CELoss: 1.3320, 
2022-10-19 17:26:25 - train: epoch 0015, iter [02000, 02526], lr: 0.000100, loss: 0.7931, CELoss: 0.7931, 
2022-10-19 17:27:50 - train: epoch 0015, iter [02100, 02526], lr: 0.000100, loss: 1.0637, CELoss: 1.0637, 
2022-10-19 17:29:15 - train: epoch 0015, iter [02200, 02526], lr: 0.000100, loss: 1.1275, CELoss: 1.1275, 
2022-10-19 17:30:41 - train: epoch 0015, iter [02300, 02526], lr: 0.000100, loss: 1.1428, CELoss: 1.1428, 
2022-10-19 17:32:06 - train: epoch 0015, iter [02400, 02526], lr: 0.000100, loss: 1.0645, CELoss: 1.0645, 
2022-10-19 17:33:32 - train: epoch 0015, iter [02500, 02526], lr: 0.000100, loss: 0.9539, CELoss: 0.9539, 
2022-10-19 17:33:55 - train: epoch 015, train_loss: 1.1611
2022-10-19 17:36:42 - eval: epoch: 015
test_loss: 1.1107815479934215
per_image_load_time: 1.106ms
per_image_inference_time: 76.797ms
exist_num_class: 150.0
mean_precision: 40.45930932311773
mean_recall: 35.795664195903896
mean_iou: 23.39494681396087
mean_dice: 34.04745221316683

2022-10-19 17:36:43 - until epoch: 015, best_metric: 23.395%
2022-10-19 17:36:43 - epoch 016 lr: 0.000100
2022-10-19 17:38:11 - train: epoch 0016, iter [00100, 02526], lr: 0.000100, loss: 0.9120, CELoss: 0.9120, 
2022-10-19 17:39:36 - train: epoch 0016, iter [00200, 02526], lr: 0.000100, loss: 1.3005, CELoss: 1.3005, 
2022-10-19 17:41:01 - train: epoch 0016, iter [00300, 02526], lr: 0.000100, loss: 1.3874, CELoss: 1.3874, 
2022-10-19 17:42:27 - train: epoch 0016, iter [00400, 02526], lr: 0.000100, loss: 0.9467, CELoss: 0.9467, 
2022-10-19 17:43:52 - train: epoch 0016, iter [00500, 02526], lr: 0.000100, loss: 0.8654, CELoss: 0.8654, 
2022-10-19 17:45:18 - train: epoch 0016, iter [00600, 02526], lr: 0.000100, loss: 1.0557, CELoss: 1.0557, 
2022-10-19 17:46:43 - train: epoch 0016, iter [00700, 02526], lr: 0.000100, loss: 0.7665, CELoss: 0.7665, 
2022-10-19 17:48:08 - train: epoch 0016, iter [00800, 02526], lr: 0.000100, loss: 0.7663, CELoss: 0.7663, 
2022-10-19 17:49:34 - train: epoch 0016, iter [00900, 02526], lr: 0.000100, loss: 1.8303, CELoss: 1.8303, 
2022-10-19 17:50:59 - train: epoch 0016, iter [01000, 02526], lr: 0.000100, loss: 1.1452, CELoss: 1.1452, 
2022-10-19 17:52:25 - train: epoch 0016, iter [01100, 02526], lr: 0.000100, loss: 1.9326, CELoss: 1.9326, 
2022-10-19 17:53:50 - train: epoch 0016, iter [01200, 02526], lr: 0.000100, loss: 2.5457, CELoss: 2.5457, 
2022-10-19 17:55:15 - train: epoch 0016, iter [01300, 02526], lr: 0.000100, loss: 0.8564, CELoss: 0.8564, 
2022-10-19 17:56:40 - train: epoch 0016, iter [01400, 02526], lr: 0.000100, loss: 1.5614, CELoss: 1.5614, 
2022-10-19 17:58:06 - train: epoch 0016, iter [01500, 02526], lr: 0.000100, loss: 1.0856, CELoss: 1.0856, 
2022-10-19 17:59:31 - train: epoch 0016, iter [01600, 02526], lr: 0.000100, loss: 1.2181, CELoss: 1.2181, 
2022-10-19 18:00:56 - train: epoch 0016, iter [01700, 02526], lr: 0.000100, loss: 0.8999, CELoss: 0.8999, 
2022-10-19 18:02:21 - train: epoch 0016, iter [01800, 02526], lr: 0.000100, loss: 0.9882, CELoss: 0.9882, 
2022-10-19 18:03:47 - train: epoch 0016, iter [01900, 02526], lr: 0.000100, loss: 1.0077, CELoss: 1.0077, 
2022-10-19 18:05:12 - train: epoch 0016, iter [02000, 02526], lr: 0.000100, loss: 0.5943, CELoss: 0.5943, 
2022-10-19 18:06:37 - train: epoch 0016, iter [02100, 02526], lr: 0.000100, loss: 1.2792, CELoss: 1.2792, 
2022-10-19 18:08:02 - train: epoch 0016, iter [02200, 02526], lr: 0.000100, loss: 0.7811, CELoss: 0.7811, 
2022-10-19 18:09:28 - train: epoch 0016, iter [02300, 02526], lr: 0.000100, loss: 0.8526, CELoss: 0.8526, 
2022-10-19 18:10:53 - train: epoch 0016, iter [02400, 02526], lr: 0.000100, loss: 1.2078, CELoss: 1.2078, 
2022-10-19 18:12:18 - train: epoch 0016, iter [02500, 02526], lr: 0.000100, loss: 1.4113, CELoss: 1.4113, 
2022-10-19 18:12:42 - train: epoch 016, train_loss: 1.1460
2022-10-19 18:12:43 - until epoch: 016, best_metric: 23.395%
2022-10-19 18:12:43 - epoch 017 lr: 0.000100
2022-10-19 18:14:11 - train: epoch 0017, iter [00100, 02526], lr: 0.000100, loss: 0.8394, CELoss: 0.8394, 
2022-10-19 18:15:36 - train: epoch 0017, iter [00200, 02526], lr: 0.000100, loss: 0.6776, CELoss: 0.6776, 
2022-10-19 18:17:02 - train: epoch 0017, iter [00300, 02526], lr: 0.000100, loss: 0.6116, CELoss: 0.6116, 
2022-10-19 18:18:27 - train: epoch 0017, iter [00400, 02526], lr: 0.000100, loss: 1.1728, CELoss: 1.1728, 
2022-10-19 18:19:52 - train: epoch 0017, iter [00500, 02526], lr: 0.000100, loss: 1.0081, CELoss: 1.0081, 
2022-10-19 18:21:18 - train: epoch 0017, iter [00600, 02526], lr: 0.000100, loss: 1.3475, CELoss: 1.3475, 
2022-10-19 18:22:43 - train: epoch 0017, iter [00700, 02526], lr: 0.000100, loss: 0.7853, CELoss: 0.7853, 
2022-10-19 18:24:08 - train: epoch 0017, iter [00800, 02526], lr: 0.000100, loss: 0.6365, CELoss: 0.6365, 
2022-10-19 18:25:34 - train: epoch 0017, iter [00900, 02526], lr: 0.000100, loss: 1.2402, CELoss: 1.2402, 
2022-10-19 18:26:59 - train: epoch 0017, iter [01000, 02526], lr: 0.000100, loss: 0.8405, CELoss: 0.8405, 
2022-10-19 18:28:25 - train: epoch 0017, iter [01100, 02526], lr: 0.000100, loss: 1.2039, CELoss: 1.2039, 
2022-10-19 18:29:50 - train: epoch 0017, iter [01200, 02526], lr: 0.000100, loss: 0.6997, CELoss: 0.6997, 
2022-10-19 18:31:15 - train: epoch 0017, iter [01300, 02526], lr: 0.000100, loss: 1.7851, CELoss: 1.7851, 
2022-10-19 18:32:41 - train: epoch 0017, iter [01400, 02526], lr: 0.000100, loss: 1.3347, CELoss: 1.3347, 
2022-10-19 18:34:06 - train: epoch 0017, iter [01500, 02526], lr: 0.000100, loss: 1.4684, CELoss: 1.4684, 
2022-10-19 18:35:32 - train: epoch 0017, iter [01600, 02526], lr: 0.000100, loss: 0.6849, CELoss: 0.6849, 
2022-10-19 18:36:57 - train: epoch 0017, iter [01700, 02526], lr: 0.000100, loss: 1.3816, CELoss: 1.3816, 
2022-10-19 18:38:23 - train: epoch 0017, iter [01800, 02526], lr: 0.000100, loss: 1.3135, CELoss: 1.3135, 
2022-10-19 18:39:48 - train: epoch 0017, iter [01900, 02526], lr: 0.000100, loss: 1.5542, CELoss: 1.5542, 
2022-10-19 18:41:14 - train: epoch 0017, iter [02000, 02526], lr: 0.000100, loss: 0.8972, CELoss: 0.8972, 
2022-10-19 18:42:39 - train: epoch 0017, iter [02100, 02526], lr: 0.000100, loss: 0.7032, CELoss: 0.7032, 
2022-10-19 18:44:05 - train: epoch 0017, iter [02200, 02526], lr: 0.000100, loss: 1.0967, CELoss: 1.0967, 
2022-10-19 18:45:30 - train: epoch 0017, iter [02300, 02526], lr: 0.000100, loss: 1.4684, CELoss: 1.4684, 
2022-10-19 18:46:56 - train: epoch 0017, iter [02400, 02526], lr: 0.000100, loss: 0.5985, CELoss: 0.5985, 
2022-10-19 18:48:21 - train: epoch 0017, iter [02500, 02526], lr: 0.000100, loss: 1.4110, CELoss: 1.4110, 
2022-10-19 18:48:45 - train: epoch 017, train_loss: 1.1199
2022-10-19 18:48:45 - until epoch: 017, best_metric: 23.395%
2022-10-19 18:48:45 - epoch 018 lr: 0.000100
2022-10-19 18:50:13 - train: epoch 0018, iter [00100, 02526], lr: 0.000100, loss: 0.9193, CELoss: 0.9193, 
2022-10-19 18:51:38 - train: epoch 0018, iter [00200, 02526], lr: 0.000100, loss: 0.8741, CELoss: 0.8741, 
2022-10-19 18:53:04 - train: epoch 0018, iter [00300, 02526], lr: 0.000100, loss: 1.3379, CELoss: 1.3379, 
2022-10-19 18:54:29 - train: epoch 0018, iter [00400, 02526], lr: 0.000100, loss: 0.8921, CELoss: 0.8921, 
2022-10-19 18:55:54 - train: epoch 0018, iter [00500, 02526], lr: 0.000100, loss: 0.7627, CELoss: 0.7627, 
2022-10-19 18:57:19 - train: epoch 0018, iter [00600, 02526], lr: 0.000100, loss: 0.8657, CELoss: 0.8657, 
2022-10-19 18:58:45 - train: epoch 0018, iter [00700, 02526], lr: 0.000100, loss: 1.4069, CELoss: 1.4069, 
2022-10-19 19:00:10 - train: epoch 0018, iter [00800, 02526], lr: 0.000100, loss: 1.1247, CELoss: 1.1247, 
2022-10-19 19:01:36 - train: epoch 0018, iter [00900, 02526], lr: 0.000100, loss: 0.8162, CELoss: 0.8162, 
2022-10-19 19:03:01 - train: epoch 0018, iter [01000, 02526], lr: 0.000100, loss: 0.8360, CELoss: 0.8360, 
2022-10-19 19:04:26 - train: epoch 0018, iter [01100, 02526], lr: 0.000100, loss: 1.1679, CELoss: 1.1679, 
2022-10-19 19:05:52 - train: epoch 0018, iter [01200, 02526], lr: 0.000100, loss: 1.1641, CELoss: 1.1641, 
2022-10-19 19:07:17 - train: epoch 0018, iter [01300, 02526], lr: 0.000100, loss: 1.1608, CELoss: 1.1608, 
2022-10-19 19:08:42 - train: epoch 0018, iter [01400, 02526], lr: 0.000100, loss: 1.8327, CELoss: 1.8327, 
2022-10-19 19:10:07 - train: epoch 0018, iter [01500, 02526], lr: 0.000100, loss: 0.7906, CELoss: 0.7906, 
2022-10-19 19:11:33 - train: epoch 0018, iter [01600, 02526], lr: 0.000100, loss: 1.1510, CELoss: 1.1510, 
2022-10-19 19:12:58 - train: epoch 0018, iter [01700, 02526], lr: 0.000100, loss: 1.0972, CELoss: 1.0972, 
2022-10-19 19:14:23 - train: epoch 0018, iter [01800, 02526], lr: 0.000100, loss: 0.7736, CELoss: 0.7736, 
2022-10-19 19:15:49 - train: epoch 0018, iter [01900, 02526], lr: 0.000100, loss: 0.9995, CELoss: 0.9995, 
2022-10-19 19:17:14 - train: epoch 0018, iter [02000, 02526], lr: 0.000100, loss: 1.4466, CELoss: 1.4466, 
2022-10-19 19:18:40 - train: epoch 0018, iter [02100, 02526], lr: 0.000100, loss: 1.3908, CELoss: 1.3908, 
2022-10-19 19:20:05 - train: epoch 0018, iter [02200, 02526], lr: 0.000100, loss: 0.9006, CELoss: 0.9006, 
2022-10-19 19:21:30 - train: epoch 0018, iter [02300, 02526], lr: 0.000100, loss: 0.8922, CELoss: 0.8922, 
2022-10-19 19:22:56 - train: epoch 0018, iter [02400, 02526], lr: 0.000100, loss: 1.3213, CELoss: 1.3213, 
2022-10-19 19:24:21 - train: epoch 0018, iter [02500, 02526], lr: 0.000100, loss: 1.7665, CELoss: 1.7665, 
2022-10-19 19:24:44 - train: epoch 018, train_loss: 1.1115
2022-10-19 19:24:45 - until epoch: 018, best_metric: 23.395%
2022-10-19 19:24:45 - epoch 019 lr: 0.000100
2022-10-19 19:26:13 - train: epoch 0019, iter [00100, 02526], lr: 0.000100, loss: 1.0078, CELoss: 1.0078, 
2022-10-19 19:27:39 - train: epoch 0019, iter [00200, 02526], lr: 0.000100, loss: 1.6259, CELoss: 1.6259, 
2022-10-19 19:29:04 - train: epoch 0019, iter [00300, 02526], lr: 0.000100, loss: 1.3660, CELoss: 1.3660, 
2022-10-19 19:30:30 - train: epoch 0019, iter [00400, 02526], lr: 0.000100, loss: 1.2514, CELoss: 1.2514, 
2022-10-19 19:31:55 - train: epoch 0019, iter [00500, 02526], lr: 0.000100, loss: 1.0395, CELoss: 1.0395, 
2022-10-19 19:33:20 - train: epoch 0019, iter [00600, 02526], lr: 0.000100, loss: 1.1149, CELoss: 1.1149, 
2022-10-19 19:34:46 - train: epoch 0019, iter [00700, 02526], lr: 0.000100, loss: 1.8517, CELoss: 1.8517, 
2022-10-19 19:36:11 - train: epoch 0019, iter [00800, 02526], lr: 0.000100, loss: 1.5733, CELoss: 1.5733, 
2022-10-19 19:37:36 - train: epoch 0019, iter [00900, 02526], lr: 0.000100, loss: 1.1484, CELoss: 1.1484, 
2022-10-19 19:39:01 - train: epoch 0019, iter [01000, 02526], lr: 0.000100, loss: 0.9589, CELoss: 0.9589, 
2022-10-19 19:40:27 - train: epoch 0019, iter [01100, 02526], lr: 0.000100, loss: 2.2190, CELoss: 2.2190, 
2022-10-19 19:41:53 - train: epoch 0019, iter [01200, 02526], lr: 0.000100, loss: 0.7192, CELoss: 0.7192, 
2022-10-19 19:43:18 - train: epoch 0019, iter [01300, 02526], lr: 0.000100, loss: 0.7664, CELoss: 0.7664, 
2022-10-19 19:44:43 - train: epoch 0019, iter [01400, 02526], lr: 0.000100, loss: 1.0592, CELoss: 1.0592, 
2022-10-19 19:46:09 - train: epoch 0019, iter [01500, 02526], lr: 0.000100, loss: 1.3986, CELoss: 1.3986, 
2022-10-19 19:47:34 - train: epoch 0019, iter [01600, 02526], lr: 0.000100, loss: 0.9256, CELoss: 0.9256, 
2022-10-19 19:49:00 - train: epoch 0019, iter [01700, 02526], lr: 0.000100, loss: 0.8613, CELoss: 0.8613, 
2022-10-19 19:50:25 - train: epoch 0019, iter [01800, 02526], lr: 0.000100, loss: 1.4723, CELoss: 1.4723, 
2022-10-19 19:51:50 - train: epoch 0019, iter [01900, 02526], lr: 0.000100, loss: 1.1680, CELoss: 1.1680, 
2022-10-19 19:53:15 - train: epoch 0019, iter [02000, 02526], lr: 0.000100, loss: 1.1953, CELoss: 1.1953, 
2022-10-19 19:54:41 - train: epoch 0019, iter [02100, 02526], lr: 0.000100, loss: 0.9896, CELoss: 0.9896, 
2022-10-19 19:56:06 - train: epoch 0019, iter [02200, 02526], lr: 0.000100, loss: 0.7459, CELoss: 0.7459, 
2022-10-19 19:57:32 - train: epoch 0019, iter [02300, 02526], lr: 0.000100, loss: 0.8273, CELoss: 0.8273, 
2022-10-19 19:58:57 - train: epoch 0019, iter [02400, 02526], lr: 0.000100, loss: 0.9887, CELoss: 0.9887, 
2022-10-19 20:00:22 - train: epoch 0019, iter [02500, 02526], lr: 0.000100, loss: 1.1828, CELoss: 1.1828, 
2022-10-19 20:00:46 - train: epoch 019, train_loss: 1.0950
2022-10-19 20:00:46 - until epoch: 019, best_metric: 23.395%
2022-10-19 20:00:46 - epoch 020 lr: 0.000100
2022-10-19 20:02:14 - train: epoch 0020, iter [00100, 02526], lr: 0.000100, loss: 1.0855, CELoss: 1.0855, 
2022-10-19 20:03:39 - train: epoch 0020, iter [00200, 02526], lr: 0.000100, loss: 0.9794, CELoss: 0.9794, 
2022-10-19 20:05:05 - train: epoch 0020, iter [00300, 02526], lr: 0.000100, loss: 1.0478, CELoss: 1.0478, 
2022-10-19 20:06:30 - train: epoch 0020, iter [00400, 02526], lr: 0.000100, loss: 0.8414, CELoss: 0.8414, 
2022-10-19 20:07:56 - train: epoch 0020, iter [00500, 02526], lr: 0.000100, loss: 1.7001, CELoss: 1.7001, 
2022-10-19 20:09:21 - train: epoch 0020, iter [00600, 02526], lr: 0.000100, loss: 1.1403, CELoss: 1.1403, 
2022-10-19 20:10:46 - train: epoch 0020, iter [00700, 02526], lr: 0.000100, loss: 1.6119, CELoss: 1.6119, 
2022-10-19 20:12:12 - train: epoch 0020, iter [00800, 02526], lr: 0.000100, loss: 0.8144, CELoss: 0.8144, 
2022-10-19 20:13:37 - train: epoch 0020, iter [00900, 02526], lr: 0.000100, loss: 1.6650, CELoss: 1.6650, 
2022-10-19 20:15:03 - train: epoch 0020, iter [01000, 02526], lr: 0.000100, loss: 1.3814, CELoss: 1.3814, 
2022-10-19 20:16:28 - train: epoch 0020, iter [01100, 02526], lr: 0.000100, loss: 1.0963, CELoss: 1.0963, 
2022-10-19 20:17:53 - train: epoch 0020, iter [01200, 02526], lr: 0.000100, loss: 0.6958, CELoss: 0.6958, 
2022-10-19 20:19:18 - train: epoch 0020, iter [01300, 02526], lr: 0.000100, loss: 0.8540, CELoss: 0.8540, 
2022-10-19 20:20:44 - train: epoch 0020, iter [01400, 02526], lr: 0.000100, loss: 0.7797, CELoss: 0.7797, 
2022-10-19 20:22:09 - train: epoch 0020, iter [01500, 02526], lr: 0.000100, loss: 1.7397, CELoss: 1.7397, 
2022-10-19 20:23:35 - train: epoch 0020, iter [01600, 02526], lr: 0.000100, loss: 1.1193, CELoss: 1.1193, 
2022-10-19 20:25:00 - train: epoch 0020, iter [01700, 02526], lr: 0.000100, loss: 0.7916, CELoss: 0.7916, 
2022-10-19 20:26:25 - train: epoch 0020, iter [01800, 02526], lr: 0.000100, loss: 0.9770, CELoss: 0.9770, 
2022-10-19 20:27:51 - train: epoch 0020, iter [01900, 02526], lr: 0.000100, loss: 0.7713, CELoss: 0.7713, 
2022-10-19 20:29:16 - train: epoch 0020, iter [02000, 02526], lr: 0.000100, loss: 0.8301, CELoss: 0.8301, 
2022-10-19 20:30:42 - train: epoch 0020, iter [02100, 02526], lr: 0.000100, loss: 1.1684, CELoss: 1.1684, 
2022-10-19 20:32:07 - train: epoch 0020, iter [02200, 02526], lr: 0.000100, loss: 0.7609, CELoss: 0.7609, 
2022-10-19 20:33:33 - train: epoch 0020, iter [02300, 02526], lr: 0.000100, loss: 1.3538, CELoss: 1.3538, 
2022-10-19 20:34:58 - train: epoch 0020, iter [02400, 02526], lr: 0.000100, loss: 0.7561, CELoss: 0.7561, 
2022-10-19 20:36:24 - train: epoch 0020, iter [02500, 02526], lr: 0.000100, loss: 1.0079, CELoss: 1.0079, 
2022-10-19 20:36:47 - train: epoch 020, train_loss: 1.0787
2022-10-19 20:39:34 - eval: epoch: 020
test_loss: 1.0628960149884223
per_image_load_time: 1.113ms
per_image_inference_time: 76.760ms
exist_num_class: 150.0
mean_precision: 45.003392755074124
mean_recall: 38.329020260874664
mean_iou: 25.476490818414874
mean_dice: 36.8269863353487

2022-10-19 20:39:35 - until epoch: 020, best_metric: 25.476%
2022-10-19 20:39:35 - epoch 021 lr: 0.000100
2022-10-19 20:41:03 - train: epoch 0021, iter [00100, 02526], lr: 0.000100, loss: 0.9080, CELoss: 0.9080, 
2022-10-19 20:42:28 - train: epoch 0021, iter [00200, 02526], lr: 0.000100, loss: 1.1849, CELoss: 1.1849, 
2022-10-19 20:43:54 - train: epoch 0021, iter [00300, 02526], lr: 0.000100, loss: 1.0522, CELoss: 1.0522, 
2022-10-19 20:45:19 - train: epoch 0021, iter [00400, 02526], lr: 0.000100, loss: 0.8561, CELoss: 0.8561, 
2022-10-19 20:46:44 - train: epoch 0021, iter [00500, 02526], lr: 0.000100, loss: 1.2382, CELoss: 1.2382, 
2022-10-19 20:48:10 - train: epoch 0021, iter [00600, 02526], lr: 0.000100, loss: 0.7198, CELoss: 0.7198, 
2022-10-19 20:49:35 - train: epoch 0021, iter [00700, 02526], lr: 0.000100, loss: 0.6337, CELoss: 0.6337, 
2022-10-19 20:51:00 - train: epoch 0021, iter [00800, 02526], lr: 0.000100, loss: 1.1750, CELoss: 1.1750, 
2022-10-19 20:52:26 - train: epoch 0021, iter [00900, 02526], lr: 0.000100, loss: 1.0170, CELoss: 1.0170, 
2022-10-19 20:53:52 - train: epoch 0021, iter [01000, 02526], lr: 0.000100, loss: 0.6483, CELoss: 0.6483, 
2022-10-19 20:55:17 - train: epoch 0021, iter [01100, 02526], lr: 0.000100, loss: 1.1413, CELoss: 1.1413, 
2022-10-19 20:56:43 - train: epoch 0021, iter [01200, 02526], lr: 0.000100, loss: 0.9854, CELoss: 0.9854, 
2022-10-19 20:58:08 - train: epoch 0021, iter [01300, 02526], lr: 0.000100, loss: 0.8859, CELoss: 0.8859, 
2022-10-19 20:59:34 - train: epoch 0021, iter [01400, 02526], lr: 0.000100, loss: 1.3286, CELoss: 1.3286, 
2022-10-19 21:00:59 - train: epoch 0021, iter [01500, 02526], lr: 0.000100, loss: 0.5396, CELoss: 0.5396, 
2022-10-19 21:02:24 - train: epoch 0021, iter [01600, 02526], lr: 0.000100, loss: 1.2499, CELoss: 1.2499, 
2022-10-19 21:03:50 - train: epoch 0021, iter [01700, 02526], lr: 0.000100, loss: 0.9668, CELoss: 0.9668, 
2022-10-19 21:05:15 - train: epoch 0021, iter [01800, 02526], lr: 0.000100, loss: 0.8348, CELoss: 0.8348, 
2022-10-19 21:06:41 - train: epoch 0021, iter [01900, 02526], lr: 0.000100, loss: 0.9810, CELoss: 0.9810, 
2022-10-19 21:08:06 - train: epoch 0021, iter [02000, 02526], lr: 0.000100, loss: 1.2523, CELoss: 1.2523, 
2022-10-19 21:09:32 - train: epoch 0021, iter [02100, 02526], lr: 0.000100, loss: 1.3671, CELoss: 1.3671, 
2022-10-19 21:10:57 - train: epoch 0021, iter [02200, 02526], lr: 0.000100, loss: 0.8374, CELoss: 0.8374, 
2022-10-19 21:12:23 - train: epoch 0021, iter [02300, 02526], lr: 0.000100, loss: 1.3810, CELoss: 1.3810, 
2022-10-19 21:13:48 - train: epoch 0021, iter [02400, 02526], lr: 0.000100, loss: 1.5049, CELoss: 1.5049, 
2022-10-19 21:15:13 - train: epoch 0021, iter [02500, 02526], lr: 0.000100, loss: 1.2189, CELoss: 1.2189, 
2022-10-19 21:15:37 - train: epoch 021, train_loss: 1.0593
2022-10-19 21:15:38 - until epoch: 021, best_metric: 25.476%
2022-10-19 21:15:38 - epoch 022 lr: 0.000100
2022-10-19 21:17:06 - train: epoch 0022, iter [00100, 02526], lr: 0.000100, loss: 1.0647, CELoss: 1.0647, 
2022-10-19 21:18:31 - train: epoch 0022, iter [00200, 02526], lr: 0.000100, loss: 1.0039, CELoss: 1.0039, 
2022-10-19 21:19:56 - train: epoch 0022, iter [00300, 02526], lr: 0.000100, loss: 1.0975, CELoss: 1.0975, 
2022-10-19 21:21:21 - train: epoch 0022, iter [00400, 02526], lr: 0.000100, loss: 0.9939, CELoss: 0.9939, 
2022-10-19 21:22:47 - train: epoch 0022, iter [00500, 02526], lr: 0.000100, loss: 0.6785, CELoss: 0.6785, 
2022-10-19 21:24:12 - train: epoch 0022, iter [00600, 02526], lr: 0.000100, loss: 1.1778, CELoss: 1.1778, 
2022-10-19 21:25:38 - train: epoch 0022, iter [00700, 02526], lr: 0.000100, loss: 0.7226, CELoss: 0.7226, 
2022-10-19 21:27:03 - train: epoch 0022, iter [00800, 02526], lr: 0.000100, loss: 0.8470, CELoss: 0.8470, 
2022-10-19 21:28:28 - train: epoch 0022, iter [00900, 02526], lr: 0.000100, loss: 0.6998, CELoss: 0.6998, 
2022-10-19 21:29:54 - train: epoch 0022, iter [01000, 02526], lr: 0.000100, loss: 1.2814, CELoss: 1.2814, 
2022-10-19 21:31:19 - train: epoch 0022, iter [01100, 02526], lr: 0.000100, loss: 1.8074, CELoss: 1.8074, 
2022-10-19 21:32:45 - train: epoch 0022, iter [01200, 02526], lr: 0.000100, loss: 0.8405, CELoss: 0.8405, 
2022-10-19 21:34:10 - train: epoch 0022, iter [01300, 02526], lr: 0.000100, loss: 1.1967, CELoss: 1.1967, 
2022-10-19 21:35:35 - train: epoch 0022, iter [01400, 02526], lr: 0.000100, loss: 0.7377, CELoss: 0.7377, 
2022-10-19 21:37:01 - train: epoch 0022, iter [01500, 02526], lr: 0.000100, loss: 0.8687, CELoss: 0.8687, 
2022-10-19 21:38:26 - train: epoch 0022, iter [01600, 02526], lr: 0.000100, loss: 1.1482, CELoss: 1.1482, 
2022-10-19 21:39:52 - train: epoch 0022, iter [01700, 02526], lr: 0.000100, loss: 0.8740, CELoss: 0.8740, 
2022-10-19 21:41:17 - train: epoch 0022, iter [01800, 02526], lr: 0.000100, loss: 0.9025, CELoss: 0.9025, 
2022-10-19 21:42:42 - train: epoch 0022, iter [01900, 02526], lr: 0.000100, loss: 1.0621, CELoss: 1.0621, 
2022-10-19 21:44:08 - train: epoch 0022, iter [02000, 02526], lr: 0.000100, loss: 0.7693, CELoss: 0.7693, 
2022-10-19 21:45:34 - train: epoch 0022, iter [02100, 02526], lr: 0.000100, loss: 1.3272, CELoss: 1.3272, 
2022-10-19 21:46:59 - train: epoch 0022, iter [02200, 02526], lr: 0.000100, loss: 0.8460, CELoss: 0.8460, 
2022-10-19 21:48:25 - train: epoch 0022, iter [02300, 02526], lr: 0.000100, loss: 0.8488, CELoss: 0.8488, 
2022-10-19 21:49:50 - train: epoch 0022, iter [02400, 02526], lr: 0.000100, loss: 1.2591, CELoss: 1.2591, 
2022-10-19 21:51:16 - train: epoch 0022, iter [02500, 02526], lr: 0.000100, loss: 0.6624, CELoss: 0.6624, 
2022-10-19 21:51:40 - train: epoch 022, train_loss: 1.0636
2022-10-19 21:51:41 - until epoch: 022, best_metric: 25.476%
2022-10-19 21:51:41 - epoch 023 lr: 0.000100
2022-10-19 21:53:09 - train: epoch 0023, iter [00100, 02526], lr: 0.000100, loss: 0.9570, CELoss: 0.9570, 
2022-10-19 21:54:34 - train: epoch 0023, iter [00200, 02526], lr: 0.000100, loss: 0.8003, CELoss: 0.8003, 
2022-10-19 21:56:00 - train: epoch 0023, iter [00300, 02526], lr: 0.000100, loss: 1.1725, CELoss: 1.1725, 
2022-10-19 21:57:25 - train: epoch 0023, iter [00400, 02526], lr: 0.000100, loss: 0.7569, CELoss: 0.7569, 
2022-10-19 21:58:51 - train: epoch 0023, iter [00500, 02526], lr: 0.000100, loss: 0.8051, CELoss: 0.8051, 
2022-10-19 22:00:16 - train: epoch 0023, iter [00600, 02526], lr: 0.000100, loss: 0.5735, CELoss: 0.5735, 
2022-10-19 22:01:42 - train: epoch 0023, iter [00700, 02526], lr: 0.000100, loss: 1.2031, CELoss: 1.2031, 
2022-10-19 22:03:07 - train: epoch 0023, iter [00800, 02526], lr: 0.000100, loss: 1.0900, CELoss: 1.0900, 
2022-10-19 22:04:33 - train: epoch 0023, iter [00900, 02526], lr: 0.000100, loss: 1.1652, CELoss: 1.1652, 
2022-10-19 22:05:58 - train: epoch 0023, iter [01000, 02526], lr: 0.000100, loss: 0.8636, CELoss: 0.8636, 
2022-10-19 22:07:24 - train: epoch 0023, iter [01100, 02526], lr: 0.000100, loss: 0.5455, CELoss: 0.5455, 
2022-10-19 22:08:50 - train: epoch 0023, iter [01200, 02526], lr: 0.000100, loss: 1.9024, CELoss: 1.9024, 
2022-10-19 22:10:15 - train: epoch 0023, iter [01300, 02526], lr: 0.000100, loss: 0.9496, CELoss: 0.9496, 
2022-10-19 22:11:41 - train: epoch 0023, iter [01400, 02526], lr: 0.000100, loss: 1.0143, CELoss: 1.0143, 
2022-10-19 22:13:06 - train: epoch 0023, iter [01500, 02526], lr: 0.000100, loss: 0.8312, CELoss: 0.8312, 
2022-10-19 22:14:32 - train: epoch 0023, iter [01600, 02526], lr: 0.000100, loss: 1.1749, CELoss: 1.1749, 
2022-10-19 22:15:58 - train: epoch 0023, iter [01700, 02526], lr: 0.000100, loss: 1.1363, CELoss: 1.1363, 
2022-10-19 22:17:23 - train: epoch 0023, iter [01800, 02526], lr: 0.000100, loss: 0.7045, CELoss: 0.7045, 
2022-10-19 22:18:48 - train: epoch 0023, iter [01900, 02526], lr: 0.000100, loss: 0.9809, CELoss: 0.9809, 
2022-10-19 22:20:14 - train: epoch 0023, iter [02000, 02526], lr: 0.000100, loss: 1.3995, CELoss: 1.3995, 
2022-10-19 22:21:39 - train: epoch 0023, iter [02100, 02526], lr: 0.000100, loss: 1.0060, CELoss: 1.0060, 
2022-10-19 22:23:05 - train: epoch 0023, iter [02200, 02526], lr: 0.000100, loss: 1.8709, CELoss: 1.8709, 
2022-10-19 22:24:31 - train: epoch 0023, iter [02300, 02526], lr: 0.000100, loss: 1.0355, CELoss: 1.0355, 
2022-10-19 22:25:56 - train: epoch 0023, iter [02400, 02526], lr: 0.000100, loss: 1.2914, CELoss: 1.2914, 
2022-10-19 22:27:21 - train: epoch 0023, iter [02500, 02526], lr: 0.000100, loss: 0.8198, CELoss: 0.8198, 
2022-10-19 22:27:45 - train: epoch 023, train_loss: 1.0443
2022-10-19 22:27:46 - until epoch: 023, best_metric: 25.476%
2022-10-19 22:27:46 - epoch 024 lr: 0.000100
2022-10-19 22:29:13 - train: epoch 0024, iter [00100, 02526], lr: 0.000100, loss: 0.5971, CELoss: 0.5971, 
2022-10-19 22:30:39 - train: epoch 0024, iter [00200, 02526], lr: 0.000100, loss: 0.8387, CELoss: 0.8387, 
2022-10-19 22:32:05 - train: epoch 0024, iter [00300, 02526], lr: 0.000100, loss: 1.6579, CELoss: 1.6579, 
2022-10-19 22:33:30 - train: epoch 0024, iter [00400, 02526], lr: 0.000100, loss: 0.6413, CELoss: 0.6413, 
2022-10-19 22:34:56 - train: epoch 0024, iter [00500, 02526], lr: 0.000100, loss: 1.1310, CELoss: 1.1310, 
2022-10-19 22:36:21 - train: epoch 0024, iter [00600, 02526], lr: 0.000100, loss: 1.1386, CELoss: 1.1386, 
2022-10-19 22:37:46 - train: epoch 0024, iter [00700, 02526], lr: 0.000100, loss: 1.3065, CELoss: 1.3065, 
2022-10-19 22:39:12 - train: epoch 0024, iter [00800, 02526], lr: 0.000100, loss: 0.9931, CELoss: 0.9931, 
2022-10-19 22:40:37 - train: epoch 0024, iter [00900, 02526], lr: 0.000100, loss: 1.0174, CELoss: 1.0174, 
2022-10-19 22:42:03 - train: epoch 0024, iter [01000, 02526], lr: 0.000100, loss: 0.7016, CELoss: 0.7016, 
2022-10-19 22:43:28 - train: epoch 0024, iter [01100, 02526], lr: 0.000100, loss: 1.1083, CELoss: 1.1083, 
2022-10-19 22:44:54 - train: epoch 0024, iter [01200, 02526], lr: 0.000100, loss: 1.2358, CELoss: 1.2358, 
2022-10-19 22:46:19 - train: epoch 0024, iter [01300, 02526], lr: 0.000100, loss: 1.1734, CELoss: 1.1734, 
2022-10-19 22:47:45 - train: epoch 0024, iter [01400, 02526], lr: 0.000100, loss: 0.9226, CELoss: 0.9226, 
2022-10-19 22:49:10 - train: epoch 0024, iter [01500, 02526], lr: 0.000100, loss: 0.8844, CELoss: 0.8844, 
2022-10-19 22:50:36 - train: epoch 0024, iter [01600, 02526], lr: 0.000100, loss: 1.6422, CELoss: 1.6422, 
2022-10-19 22:52:01 - train: epoch 0024, iter [01700, 02526], lr: 0.000100, loss: 0.7988, CELoss: 0.7988, 
2022-10-19 22:53:27 - train: epoch 0024, iter [01800, 02526], lr: 0.000100, loss: 0.9251, CELoss: 0.9251, 
2022-10-19 22:54:53 - train: epoch 0024, iter [01900, 02526], lr: 0.000100, loss: 0.6733, CELoss: 0.6733, 
2022-10-19 22:56:18 - train: epoch 0024, iter [02000, 02526], lr: 0.000100, loss: 1.8122, CELoss: 1.8122, 
2022-10-19 22:57:43 - train: epoch 0024, iter [02100, 02526], lr: 0.000100, loss: 0.9003, CELoss: 0.9003, 
2022-10-19 22:59:09 - train: epoch 0024, iter [02200, 02526], lr: 0.000100, loss: 0.8157, CELoss: 0.8157, 
2022-10-19 23:00:34 - train: epoch 0024, iter [02300, 02526], lr: 0.000100, loss: 1.3688, CELoss: 1.3688, 
2022-10-19 23:01:59 - train: epoch 0024, iter [02400, 02526], lr: 0.000100, loss: 1.1071, CELoss: 1.1071, 
2022-10-19 23:03:24 - train: epoch 0024, iter [02500, 02526], lr: 0.000100, loss: 0.9907, CELoss: 0.9907, 
2022-10-19 23:03:48 - train: epoch 024, train_loss: 1.0344
2022-10-19 23:03:48 - until epoch: 024, best_metric: 25.476%
2022-10-19 23:03:48 - epoch 025 lr: 0.000100
2022-10-19 23:05:16 - train: epoch 0025, iter [00100, 02526], lr: 0.000100, loss: 1.7361, CELoss: 1.7361, 
2022-10-19 23:06:42 - train: epoch 0025, iter [00200, 02526], lr: 0.000100, loss: 1.8634, CELoss: 1.8634, 
2022-10-19 23:08:07 - train: epoch 0025, iter [00300, 02526], lr: 0.000100, loss: 1.1904, CELoss: 1.1904, 
2022-10-19 23:09:32 - train: epoch 0025, iter [00400, 02526], lr: 0.000100, loss: 0.5840, CELoss: 0.5840, 
2022-10-19 23:10:58 - train: epoch 0025, iter [00500, 02526], lr: 0.000100, loss: 1.2736, CELoss: 1.2736, 
2022-10-19 23:12:24 - train: epoch 0025, iter [00600, 02526], lr: 0.000100, loss: 0.8741, CELoss: 0.8741, 
2022-10-19 23:13:49 - train: epoch 0025, iter [00700, 02526], lr: 0.000100, loss: 1.2076, CELoss: 1.2076, 
2022-10-19 23:15:14 - train: epoch 0025, iter [00800, 02526], lr: 0.000100, loss: 0.5422, CELoss: 0.5422, 
2022-10-19 23:16:40 - train: epoch 0025, iter [00900, 02526], lr: 0.000100, loss: 1.1379, CELoss: 1.1379, 
2022-10-19 23:18:05 - train: epoch 0025, iter [01000, 02526], lr: 0.000100, loss: 0.9204, CELoss: 0.9204, 
2022-10-19 23:19:31 - train: epoch 0025, iter [01100, 02526], lr: 0.000100, loss: 1.0017, CELoss: 1.0017, 
2022-10-19 23:20:56 - train: epoch 0025, iter [01200, 02526], lr: 0.000100, loss: 0.8499, CELoss: 0.8499, 
2022-10-19 23:22:22 - train: epoch 0025, iter [01300, 02526], lr: 0.000100, loss: 1.1855, CELoss: 1.1855, 
2022-10-19 23:23:47 - train: epoch 0025, iter [01400, 02526], lr: 0.000100, loss: 1.5203, CELoss: 1.5203, 
2022-10-19 23:25:13 - train: epoch 0025, iter [01500, 02526], lr: 0.000100, loss: 0.9864, CELoss: 0.9864, 
2022-10-19 23:26:39 - train: epoch 0025, iter [01600, 02526], lr: 0.000100, loss: 0.9073, CELoss: 0.9073, 
2022-10-19 23:28:04 - train: epoch 0025, iter [01700, 02526], lr: 0.000100, loss: 1.3626, CELoss: 1.3626, 
2022-10-19 23:29:29 - train: epoch 0025, iter [01800, 02526], lr: 0.000100, loss: 0.8890, CELoss: 0.8890, 
2022-10-19 23:30:55 - train: epoch 0025, iter [01900, 02526], lr: 0.000100, loss: 0.9577, CELoss: 0.9577, 
2022-10-19 23:32:21 - train: epoch 0025, iter [02000, 02526], lr: 0.000100, loss: 0.6489, CELoss: 0.6489, 
2022-10-19 23:33:46 - train: epoch 0025, iter [02100, 02526], lr: 0.000100, loss: 1.0997, CELoss: 1.0997, 
2022-10-19 23:35:12 - train: epoch 0025, iter [02200, 02526], lr: 0.000100, loss: 1.0435, CELoss: 1.0435, 
2022-10-19 23:36:37 - train: epoch 0025, iter [02300, 02526], lr: 0.000100, loss: 0.9268, CELoss: 0.9268, 
2022-10-19 23:38:02 - train: epoch 0025, iter [02400, 02526], lr: 0.000100, loss: 1.2798, CELoss: 1.2798, 
2022-10-19 23:39:28 - train: epoch 0025, iter [02500, 02526], lr: 0.000100, loss: 1.4397, CELoss: 1.4397, 
2022-10-19 23:39:51 - train: epoch 025, train_loss: 1.0248
2022-10-19 23:42:39 - eval: epoch: 025
test_loss: 1.1008669669628144
per_image_load_time: 1.102ms
per_image_inference_time: 76.915ms
exist_num_class: 150.0
mean_precision: 42.90009407056871
mean_recall: 39.01770086173639
mean_iou: 24.9512887240369
mean_dice: 36.33187556867828

2022-10-19 23:42:40 - until epoch: 025, best_metric: 25.476%
2022-10-19 23:42:40 - epoch 026 lr: 0.000100
2022-10-19 23:44:08 - train: epoch 0026, iter [00100, 02526], lr: 0.000100, loss: 1.1236, CELoss: 1.1236, 
2022-10-19 23:45:33 - train: epoch 0026, iter [00200, 02526], lr: 0.000100, loss: 1.3029, CELoss: 1.3029, 
2022-10-19 23:46:59 - train: epoch 0026, iter [00300, 02526], lr: 0.000100, loss: 1.2726, CELoss: 1.2726, 
2022-10-19 23:48:24 - train: epoch 0026, iter [00400, 02526], lr: 0.000100, loss: 0.8879, CELoss: 0.8879, 
2022-10-19 23:49:50 - train: epoch 0026, iter [00500, 02526], lr: 0.000100, loss: 0.6222, CELoss: 0.6222, 
2022-10-19 23:51:15 - train: epoch 0026, iter [00600, 02526], lr: 0.000100, loss: 0.8499, CELoss: 0.8499, 
2022-10-19 23:52:41 - train: epoch 0026, iter [00700, 02526], lr: 0.000100, loss: 0.8311, CELoss: 0.8311, 
2022-10-19 23:54:07 - train: epoch 0026, iter [00800, 02526], lr: 0.000100, loss: 1.0869, CELoss: 1.0869, 
2022-10-19 23:55:32 - train: epoch 0026, iter [00900, 02526], lr: 0.000100, loss: 0.6500, CELoss: 0.6500, 
2022-10-19 23:56:57 - train: epoch 0026, iter [01000, 02526], lr: 0.000100, loss: 1.6470, CELoss: 1.6470, 
2022-10-19 23:58:23 - train: epoch 0026, iter [01100, 02526], lr: 0.000100, loss: 0.7917, CELoss: 0.7917, 
2022-10-19 23:59:48 - train: epoch 0026, iter [01200, 02526], lr: 0.000100, loss: 0.8834, CELoss: 0.8834, 
2022-10-20 00:01:14 - train: epoch 0026, iter [01300, 02526], lr: 0.000100, loss: 0.9300, CELoss: 0.9300, 
2022-10-20 00:02:39 - train: epoch 0026, iter [01400, 02526], lr: 0.000100, loss: 0.7976, CELoss: 0.7976, 
2022-10-20 00:04:05 - train: epoch 0026, iter [01500, 02526], lr: 0.000100, loss: 1.3902, CELoss: 1.3902, 
2022-10-20 00:05:30 - train: epoch 0026, iter [01600, 02526], lr: 0.000100, loss: 0.8235, CELoss: 0.8235, 
2022-10-20 00:06:55 - train: epoch 0026, iter [01700, 02526], lr: 0.000100, loss: 0.8579, CELoss: 0.8579, 
2022-10-20 00:08:21 - train: epoch 0026, iter [01800, 02526], lr: 0.000100, loss: 1.1802, CELoss: 1.1802, 
2022-10-20 00:09:46 - train: epoch 0026, iter [01900, 02526], lr: 0.000100, loss: 1.2267, CELoss: 1.2267, 
2022-10-20 00:11:12 - train: epoch 0026, iter [02000, 02526], lr: 0.000100, loss: 1.1210, CELoss: 1.1210, 
2022-10-20 00:12:37 - train: epoch 0026, iter [02100, 02526], lr: 0.000100, loss: 1.5830, CELoss: 1.5830, 
2022-10-20 00:14:02 - train: epoch 0026, iter [02200, 02526], lr: 0.000100, loss: 0.8372, CELoss: 0.8372, 
2022-10-20 00:15:27 - train: epoch 0026, iter [02300, 02526], lr: 0.000100, loss: 0.8789, CELoss: 0.8789, 
2022-10-20 00:16:53 - train: epoch 0026, iter [02400, 02526], lr: 0.000100, loss: 1.0614, CELoss: 1.0614, 
2022-10-20 00:18:18 - train: epoch 0026, iter [02500, 02526], lr: 0.000100, loss: 1.4516, CELoss: 1.4516, 
2022-10-20 00:18:42 - train: epoch 026, train_loss: 1.0132
2022-10-20 00:18:42 - until epoch: 026, best_metric: 25.476%
2022-10-20 00:18:42 - epoch 027 lr: 0.000100
2022-10-20 00:20:10 - train: epoch 0027, iter [00100, 02526], lr: 0.000100, loss: 1.0399, CELoss: 1.0399, 
2022-10-20 00:21:36 - train: epoch 0027, iter [00200, 02526], lr: 0.000100, loss: 1.7504, CELoss: 1.7504, 
2022-10-20 00:23:01 - train: epoch 0027, iter [00300, 02526], lr: 0.000100, loss: 1.2789, CELoss: 1.2789, 
2022-10-20 00:24:27 - train: epoch 0027, iter [00400, 02526], lr: 0.000100, loss: 0.9656, CELoss: 0.9656, 
2022-10-20 00:25:52 - train: epoch 0027, iter [00500, 02526], lr: 0.000100, loss: 1.2477, CELoss: 1.2477, 
2022-10-20 00:27:18 - train: epoch 0027, iter [00600, 02526], lr: 0.000100, loss: 1.0063, CELoss: 1.0063, 
2022-10-20 00:28:43 - train: epoch 0027, iter [00700, 02526], lr: 0.000100, loss: 0.9961, CELoss: 0.9961, 
2022-10-20 00:30:09 - train: epoch 0027, iter [00800, 02526], lr: 0.000100, loss: 0.7567, CELoss: 0.7567, 
2022-10-20 00:31:34 - train: epoch 0027, iter [00900, 02526], lr: 0.000100, loss: 1.1819, CELoss: 1.1819, 
2022-10-20 00:33:00 - train: epoch 0027, iter [01000, 02526], lr: 0.000100, loss: 0.6691, CELoss: 0.6691, 
2022-10-20 00:34:25 - train: epoch 0027, iter [01100, 02526], lr: 0.000100, loss: 0.9310, CELoss: 0.9310, 
2022-10-20 00:35:51 - train: epoch 0027, iter [01200, 02526], lr: 0.000100, loss: 1.2627, CELoss: 1.2627, 
2022-10-20 00:37:16 - train: epoch 0027, iter [01300, 02526], lr: 0.000100, loss: 1.4869, CELoss: 1.4869, 
2022-10-20 00:38:42 - train: epoch 0027, iter [01400, 02526], lr: 0.000100, loss: 1.4081, CELoss: 1.4081, 
2022-10-20 00:40:07 - train: epoch 0027, iter [01500, 02526], lr: 0.000100, loss: 0.6455, CELoss: 0.6455, 
2022-10-20 00:41:33 - train: epoch 0027, iter [01600, 02526], lr: 0.000100, loss: 0.8968, CELoss: 0.8968, 
2022-10-20 00:42:58 - train: epoch 0027, iter [01700, 02526], lr: 0.000100, loss: 0.7009, CELoss: 0.7009, 
2022-10-20 00:44:23 - train: epoch 0027, iter [01800, 02526], lr: 0.000100, loss: 0.8832, CELoss: 0.8832, 
2022-10-20 00:45:49 - train: epoch 0027, iter [01900, 02526], lr: 0.000100, loss: 0.6535, CELoss: 0.6535, 
2022-10-20 00:47:15 - train: epoch 0027, iter [02000, 02526], lr: 0.000100, loss: 0.6079, CELoss: 0.6079, 
2022-10-20 00:48:40 - train: epoch 0027, iter [02100, 02526], lr: 0.000100, loss: 0.5813, CELoss: 0.5813, 
2022-10-20 00:50:06 - train: epoch 0027, iter [02200, 02526], lr: 0.000100, loss: 1.0882, CELoss: 1.0882, 
2022-10-20 00:51:31 - train: epoch 0027, iter [02300, 02526], lr: 0.000100, loss: 1.5173, CELoss: 1.5173, 
2022-10-20 00:52:57 - train: epoch 0027, iter [02400, 02526], lr: 0.000100, loss: 1.0507, CELoss: 1.0507, 
2022-10-20 00:54:22 - train: epoch 0027, iter [02500, 02526], lr: 0.000100, loss: 1.2260, CELoss: 1.2260, 
2022-10-20 00:54:46 - train: epoch 027, train_loss: 0.9999
2022-10-20 00:54:46 - until epoch: 027, best_metric: 25.476%
2022-10-20 00:54:46 - epoch 028 lr: 0.000100
2022-10-20 00:56:14 - train: epoch 0028, iter [00100, 02526], lr: 0.000100, loss: 1.2296, CELoss: 1.2296, 
2022-10-20 00:57:40 - train: epoch 0028, iter [00200, 02526], lr: 0.000100, loss: 0.9139, CELoss: 0.9139, 
2022-10-20 00:59:05 - train: epoch 0028, iter [00300, 02526], lr: 0.000100, loss: 1.0826, CELoss: 1.0826, 
2022-10-20 01:00:31 - train: epoch 0028, iter [00400, 02526], lr: 0.000100, loss: 1.0163, CELoss: 1.0163, 
2022-10-20 01:01:56 - train: epoch 0028, iter [00500, 02526], lr: 0.000100, loss: 0.9252, CELoss: 0.9252, 
2022-10-20 01:03:22 - train: epoch 0028, iter [00600, 02526], lr: 0.000100, loss: 0.6062, CELoss: 0.6062, 
2022-10-20 01:04:47 - train: epoch 0028, iter [00700, 02526], lr: 0.000100, loss: 0.9385, CELoss: 0.9385, 
2022-10-20 01:06:12 - train: epoch 0028, iter [00800, 02526], lr: 0.000100, loss: 0.9052, CELoss: 0.9052, 
2022-10-20 01:07:38 - train: epoch 0028, iter [00900, 02526], lr: 0.000100, loss: 0.9311, CELoss: 0.9311, 
2022-10-20 01:09:03 - train: epoch 0028, iter [01000, 02526], lr: 0.000100, loss: 1.0951, CELoss: 1.0951, 
2022-10-20 01:10:28 - train: epoch 0028, iter [01100, 02526], lr: 0.000100, loss: 1.2015, CELoss: 1.2015, 
2022-10-20 01:11:53 - train: epoch 0028, iter [01200, 02526], lr: 0.000100, loss: 1.0358, CELoss: 1.0358, 
2022-10-20 01:13:19 - train: epoch 0028, iter [01300, 02526], lr: 0.000100, loss: 0.8318, CELoss: 0.8318, 
2022-10-20 01:14:44 - train: epoch 0028, iter [01400, 02526], lr: 0.000100, loss: 1.1997, CELoss: 1.1997, 
2022-10-20 01:16:09 - train: epoch 0028, iter [01500, 02526], lr: 0.000100, loss: 0.8316, CELoss: 0.8316, 
2022-10-20 01:17:34 - train: epoch 0028, iter [01600, 02526], lr: 0.000100, loss: 0.7311, CELoss: 0.7311, 
2022-10-20 01:18:59 - train: epoch 0028, iter [01700, 02526], lr: 0.000100, loss: 0.7081, CELoss: 0.7081, 
2022-10-20 01:20:25 - train: epoch 0028, iter [01800, 02526], lr: 0.000100, loss: 0.8389, CELoss: 0.8389, 
2022-10-20 01:21:50 - train: epoch 0028, iter [01900, 02526], lr: 0.000100, loss: 0.9708, CELoss: 0.9708, 
2022-10-20 01:23:16 - train: epoch 0028, iter [02000, 02526], lr: 0.000100, loss: 0.9196, CELoss: 0.9196, 
2022-10-20 01:24:41 - train: epoch 0028, iter [02100, 02526], lr: 0.000100, loss: 0.9304, CELoss: 0.9304, 
2022-10-20 01:26:06 - train: epoch 0028, iter [02200, 02526], lr: 0.000100, loss: 0.7841, CELoss: 0.7841, 
2022-10-20 01:27:32 - train: epoch 0028, iter [02300, 02526], lr: 0.000100, loss: 1.4140, CELoss: 1.4140, 
2022-10-20 01:28:57 - train: epoch 0028, iter [02400, 02526], lr: 0.000100, loss: 0.9301, CELoss: 0.9301, 
2022-10-20 01:30:22 - train: epoch 0028, iter [02500, 02526], lr: 0.000100, loss: 0.7742, CELoss: 0.7742, 
2022-10-20 01:30:45 - train: epoch 028, train_loss: 0.9881
2022-10-20 01:30:46 - until epoch: 028, best_metric: 25.476%
2022-10-20 01:30:46 - epoch 029 lr: 0.000100
2022-10-20 01:32:14 - train: epoch 0029, iter [00100, 02526], lr: 0.000100, loss: 1.0388, CELoss: 1.0388, 
2022-10-20 01:33:39 - train: epoch 0029, iter [00200, 02526], lr: 0.000100, loss: 0.6414, CELoss: 0.6414, 
2022-10-20 01:35:05 - train: epoch 0029, iter [00300, 02526], lr: 0.000100, loss: 0.6877, CELoss: 0.6877, 
2022-10-20 01:36:30 - train: epoch 0029, iter [00400, 02526], lr: 0.000100, loss: 1.1526, CELoss: 1.1526, 
2022-10-20 01:37:55 - train: epoch 0029, iter [00500, 02526], lr: 0.000100, loss: 0.9828, CELoss: 0.9828, 
2022-10-20 01:39:20 - train: epoch 0029, iter [00600, 02526], lr: 0.000100, loss: 0.6116, CELoss: 0.6116, 
2022-10-20 01:40:45 - train: epoch 0029, iter [00700, 02526], lr: 0.000100, loss: 1.3120, CELoss: 1.3120, 
2022-10-20 01:42:11 - train: epoch 0029, iter [00800, 02526], lr: 0.000100, loss: 0.5911, CELoss: 0.5911, 
2022-10-20 01:43:36 - train: epoch 0029, iter [00900, 02526], lr: 0.000100, loss: 0.5404, CELoss: 0.5404, 
2022-10-20 01:45:02 - train: epoch 0029, iter [01000, 02526], lr: 0.000100, loss: 1.3655, CELoss: 1.3655, 
2022-10-20 01:46:27 - train: epoch 0029, iter [01100, 02526], lr: 0.000100, loss: 1.0785, CELoss: 1.0785, 
2022-10-20 01:47:53 - train: epoch 0029, iter [01200, 02526], lr: 0.000100, loss: 1.0347, CELoss: 1.0347, 
2022-10-20 01:49:18 - train: epoch 0029, iter [01300, 02526], lr: 0.000100, loss: 1.3121, CELoss: 1.3121, 
2022-10-20 01:50:44 - train: epoch 0029, iter [01400, 02526], lr: 0.000100, loss: 0.6556, CELoss: 0.6556, 
2022-10-20 01:52:09 - train: epoch 0029, iter [01500, 02526], lr: 0.000100, loss: 0.6388, CELoss: 0.6388, 
2022-10-20 01:53:34 - train: epoch 0029, iter [01600, 02526], lr: 0.000100, loss: 0.5362, CELoss: 0.5362, 
2022-10-20 01:54:59 - train: epoch 0029, iter [01700, 02526], lr: 0.000100, loss: 0.8583, CELoss: 0.8583, 
2022-10-20 01:56:25 - train: epoch 0029, iter [01800, 02526], lr: 0.000100, loss: 1.0662, CELoss: 1.0662, 
2022-10-20 01:57:50 - train: epoch 0029, iter [01900, 02526], lr: 0.000100, loss: 0.8653, CELoss: 0.8653, 
2022-10-20 01:59:15 - train: epoch 0029, iter [02000, 02526], lr: 0.000100, loss: 1.0389, CELoss: 1.0389, 
2022-10-20 02:00:41 - train: epoch 0029, iter [02100, 02526], lr: 0.000100, loss: 0.5607, CELoss: 0.5607, 
2022-10-20 02:02:06 - train: epoch 0029, iter [02200, 02526], lr: 0.000100, loss: 0.9932, CELoss: 0.9932, 
2022-10-20 02:03:31 - train: epoch 0029, iter [02300, 02526], lr: 0.000100, loss: 0.6771, CELoss: 0.6771, 
2022-10-20 02:04:56 - train: epoch 0029, iter [02400, 02526], lr: 0.000100, loss: 1.3578, CELoss: 1.3578, 
2022-10-20 02:06:22 - train: epoch 0029, iter [02500, 02526], lr: 0.000100, loss: 1.1931, CELoss: 1.1931, 
2022-10-20 02:06:45 - train: epoch 029, train_loss: 0.9835
2022-10-20 02:06:46 - until epoch: 029, best_metric: 25.476%
2022-10-20 02:06:46 - epoch 030 lr: 0.000100
2022-10-20 02:08:14 - train: epoch 0030, iter [00100, 02526], lr: 0.000100, loss: 0.8254, CELoss: 0.8254, 
2022-10-20 02:09:39 - train: epoch 0030, iter [00200, 02526], lr: 0.000100, loss: 0.6002, CELoss: 0.6002, 
2022-10-20 02:11:04 - train: epoch 0030, iter [00300, 02526], lr: 0.000100, loss: 0.7238, CELoss: 0.7238, 
2022-10-20 02:12:30 - train: epoch 0030, iter [00400, 02526], lr: 0.000100, loss: 0.7576, CELoss: 0.7576, 
2022-10-20 02:13:55 - train: epoch 0030, iter [00500, 02526], lr: 0.000100, loss: 0.5206, CELoss: 0.5206, 
2022-10-20 02:15:20 - train: epoch 0030, iter [00600, 02526], lr: 0.000100, loss: 1.2566, CELoss: 1.2566, 
2022-10-20 02:16:46 - train: epoch 0030, iter [00700, 02526], lr: 0.000100, loss: 1.0817, CELoss: 1.0817, 
2022-10-20 02:18:11 - train: epoch 0030, iter [00800, 02526], lr: 0.000100, loss: 0.6265, CELoss: 0.6265, 
2022-10-20 02:19:37 - train: epoch 0030, iter [00900, 02526], lr: 0.000100, loss: 1.4691, CELoss: 1.4691, 
2022-10-20 02:21:02 - train: epoch 0030, iter [01000, 02526], lr: 0.000100, loss: 1.2384, CELoss: 1.2384, 
2022-10-20 02:22:27 - train: epoch 0030, iter [01100, 02526], lr: 0.000100, loss: 0.9152, CELoss: 0.9152, 
2022-10-20 02:23:53 - train: epoch 0030, iter [01200, 02526], lr: 0.000100, loss: 1.1507, CELoss: 1.1507, 
2022-10-20 02:25:18 - train: epoch 0030, iter [01300, 02526], lr: 0.000100, loss: 0.9768, CELoss: 0.9768, 
2022-10-20 02:26:43 - train: epoch 0030, iter [01400, 02526], lr: 0.000100, loss: 0.4626, CELoss: 0.4626, 
2022-10-20 02:28:08 - train: epoch 0030, iter [01500, 02526], lr: 0.000100, loss: 0.9576, CELoss: 0.9576, 
2022-10-20 02:29:34 - train: epoch 0030, iter [01600, 02526], lr: 0.000100, loss: 0.7251, CELoss: 0.7251, 
2022-10-20 02:30:59 - train: epoch 0030, iter [01700, 02526], lr: 0.000100, loss: 1.1422, CELoss: 1.1422, 
2022-10-20 02:32:24 - train: epoch 0030, iter [01800, 02526], lr: 0.000100, loss: 1.0715, CELoss: 1.0715, 
2022-10-20 02:33:49 - train: epoch 0030, iter [01900, 02526], lr: 0.000100, loss: 0.9948, CELoss: 0.9948, 
2022-10-20 02:35:15 - train: epoch 0030, iter [02000, 02526], lr: 0.000100, loss: 0.8424, CELoss: 0.8424, 
2022-10-20 02:36:40 - train: epoch 0030, iter [02100, 02526], lr: 0.000100, loss: 1.0303, CELoss: 1.0303, 
2022-10-20 02:38:05 - train: epoch 0030, iter [02200, 02526], lr: 0.000100, loss: 1.8396, CELoss: 1.8396, 
2022-10-20 02:39:31 - train: epoch 0030, iter [02300, 02526], lr: 0.000100, loss: 0.8019, CELoss: 0.8019, 
2022-10-20 02:40:56 - train: epoch 0030, iter [02400, 02526], lr: 0.000100, loss: 0.8521, CELoss: 0.8521, 
2022-10-20 02:42:21 - train: epoch 0030, iter [02500, 02526], lr: 0.000100, loss: 1.0283, CELoss: 1.0283, 
2022-10-20 02:42:44 - train: epoch 030, train_loss: 0.9718
2022-10-20 02:45:31 - eval: epoch: 030
test_loss: 1.0305519714355469
per_image_load_time: 1.125ms
per_image_inference_time: 76.667ms
exist_num_class: 150.0
mean_precision: 45.836158055342
mean_recall: 40.689523412863494
mean_iou: 26.541409885640643
mean_dice: 38.71923111685659

2022-10-20 02:45:32 - until epoch: 030, best_metric: 26.541%
2022-10-20 02:45:32 - epoch 031 lr: 0.000100
2022-10-20 02:47:00 - train: epoch 0031, iter [00100, 02526], lr: 0.000100, loss: 0.8172, CELoss: 0.8172, 
2022-10-20 02:48:25 - train: epoch 0031, iter [00200, 02526], lr: 0.000100, loss: 1.0270, CELoss: 1.0270, 
2022-10-20 02:49:51 - train: epoch 0031, iter [00300, 02526], lr: 0.000100, loss: 0.8473, CELoss: 0.8473, 
2022-10-20 02:51:16 - train: epoch 0031, iter [00400, 02526], lr: 0.000100, loss: 0.7552, CELoss: 0.7552, 
2022-10-20 02:52:41 - train: epoch 0031, iter [00500, 02526], lr: 0.000100, loss: 1.4889, CELoss: 1.4889, 
2022-10-20 02:54:06 - train: epoch 0031, iter [00600, 02526], lr: 0.000100, loss: 1.1391, CELoss: 1.1391, 
2022-10-20 02:55:32 - train: epoch 0031, iter [00700, 02526], lr: 0.000100, loss: 1.0336, CELoss: 1.0336, 
2022-10-20 02:56:57 - train: epoch 0031, iter [00800, 02526], lr: 0.000100, loss: 0.9919, CELoss: 0.9919, 
2022-10-20 02:58:22 - train: epoch 0031, iter [00900, 02526], lr: 0.000100, loss: 1.2390, CELoss: 1.2390, 
2022-10-20 02:59:48 - train: epoch 0031, iter [01000, 02526], lr: 0.000100, loss: 0.9450, CELoss: 0.9450, 
2022-10-20 03:01:13 - train: epoch 0031, iter [01100, 02526], lr: 0.000100, loss: 0.8828, CELoss: 0.8828, 
2022-10-20 03:02:38 - train: epoch 0031, iter [01200, 02526], lr: 0.000100, loss: 1.0787, CELoss: 1.0787, 
2022-10-20 03:04:04 - train: epoch 0031, iter [01300, 02526], lr: 0.000100, loss: 1.1653, CELoss: 1.1653, 
2022-10-20 03:05:29 - train: epoch 0031, iter [01400, 02526], lr: 0.000100, loss: 0.5136, CELoss: 0.5136, 
2022-10-20 03:06:55 - train: epoch 0031, iter [01500, 02526], lr: 0.000100, loss: 1.4480, CELoss: 1.4480, 
2022-10-20 03:08:20 - train: epoch 0031, iter [01600, 02526], lr: 0.000100, loss: 1.0159, CELoss: 1.0159, 
2022-10-20 03:09:45 - train: epoch 0031, iter [01700, 02526], lr: 0.000100, loss: 0.9077, CELoss: 0.9077, 
2022-10-20 03:11:11 - train: epoch 0031, iter [01800, 02526], lr: 0.000100, loss: 0.8937, CELoss: 0.8937, 
2022-10-20 03:12:36 - train: epoch 0031, iter [01900, 02526], lr: 0.000100, loss: 0.9496, CELoss: 0.9496, 
2022-10-20 03:14:02 - train: epoch 0031, iter [02000, 02526], lr: 0.000100, loss: 0.6278, CELoss: 0.6278, 
2022-10-20 03:15:27 - train: epoch 0031, iter [02100, 02526], lr: 0.000100, loss: 1.0938, CELoss: 1.0938, 
2022-10-20 03:16:53 - train: epoch 0031, iter [02200, 02526], lr: 0.000100, loss: 0.7603, CELoss: 0.7603, 
2022-10-20 03:18:18 - train: epoch 0031, iter [02300, 02526], lr: 0.000100, loss: 1.1571, CELoss: 1.1571, 
2022-10-20 03:19:43 - train: epoch 0031, iter [02400, 02526], lr: 0.000100, loss: 1.6587, CELoss: 1.6587, 
2022-10-20 03:21:08 - train: epoch 0031, iter [02500, 02526], lr: 0.000100, loss: 1.0784, CELoss: 1.0784, 
2022-10-20 03:21:32 - train: epoch 031, train_loss: 0.9641
2022-10-20 03:21:32 - until epoch: 031, best_metric: 26.541%
2022-10-20 03:21:32 - epoch 032 lr: 0.000100
2022-10-20 03:23:01 - train: epoch 0032, iter [00100, 02526], lr: 0.000100, loss: 0.6829, CELoss: 0.6829, 
2022-10-20 03:24:26 - train: epoch 0032, iter [00200, 02526], lr: 0.000100, loss: 0.7025, CELoss: 0.7025, 
2022-10-20 03:25:51 - train: epoch 0032, iter [00300, 02526], lr: 0.000100, loss: 0.8236, CELoss: 0.8236, 
2022-10-20 03:27:16 - train: epoch 0032, iter [00400, 02526], lr: 0.000100, loss: 0.8926, CELoss: 0.8926, 
2022-10-20 03:28:42 - train: epoch 0032, iter [00500, 02526], lr: 0.000100, loss: 0.7455, CELoss: 0.7455, 
2022-10-20 03:30:07 - train: epoch 0032, iter [00600, 02526], lr: 0.000100, loss: 0.7107, CELoss: 0.7107, 
2022-10-20 03:31:33 - train: epoch 0032, iter [00700, 02526], lr: 0.000100, loss: 0.6710, CELoss: 0.6710, 
2022-10-20 03:32:58 - train: epoch 0032, iter [00800, 02526], lr: 0.000100, loss: 1.1823, CELoss: 1.1823, 
2022-10-20 03:34:23 - train: epoch 0032, iter [00900, 02526], lr: 0.000100, loss: 0.7789, CELoss: 0.7789, 
2022-10-20 03:35:49 - train: epoch 0032, iter [01000, 02526], lr: 0.000100, loss: 0.6910, CELoss: 0.6910, 
2022-10-20 03:37:14 - train: epoch 0032, iter [01100, 02526], lr: 0.000100, loss: 0.6911, CELoss: 0.6911, 
2022-10-20 03:38:39 - train: epoch 0032, iter [01200, 02526], lr: 0.000100, loss: 0.5436, CELoss: 0.5436, 
2022-10-20 03:40:05 - train: epoch 0032, iter [01300, 02526], lr: 0.000100, loss: 0.7135, CELoss: 0.7135, 
2022-10-20 03:41:30 - train: epoch 0032, iter [01400, 02526], lr: 0.000100, loss: 1.1818, CELoss: 1.1818, 
2022-10-20 03:42:55 - train: epoch 0032, iter [01500, 02526], lr: 0.000100, loss: 0.9388, CELoss: 0.9388, 
2022-10-20 03:44:20 - train: epoch 0032, iter [01600, 02526], lr: 0.000100, loss: 0.6909, CELoss: 0.6909, 
2022-10-20 03:45:45 - train: epoch 0032, iter [01700, 02526], lr: 0.000100, loss: 1.0182, CELoss: 1.0182, 
2022-10-20 03:47:11 - train: epoch 0032, iter [01800, 02526], lr: 0.000100, loss: 0.8880, CELoss: 0.8880, 
2022-10-20 03:48:36 - train: epoch 0032, iter [01900, 02526], lr: 0.000100, loss: 0.7666, CELoss: 0.7666, 
2022-10-20 03:50:02 - train: epoch 0032, iter [02000, 02526], lr: 0.000100, loss: 1.4696, CELoss: 1.4696, 
2022-10-20 03:51:27 - train: epoch 0032, iter [02100, 02526], lr: 0.000100, loss: 0.7968, CELoss: 0.7968, 
2022-10-20 03:52:52 - train: epoch 0032, iter [02200, 02526], lr: 0.000100, loss: 0.9685, CELoss: 0.9685, 
2022-10-20 03:54:18 - train: epoch 0032, iter [02300, 02526], lr: 0.000100, loss: 1.2383, CELoss: 1.2383, 
2022-10-20 03:55:43 - train: epoch 0032, iter [02400, 02526], lr: 0.000100, loss: 0.7796, CELoss: 0.7796, 
2022-10-20 03:57:09 - train: epoch 0032, iter [02500, 02526], lr: 0.000100, loss: 0.6070, CELoss: 0.6070, 
2022-10-20 03:57:32 - train: epoch 032, train_loss: 0.9575
2022-10-20 03:57:33 - until epoch: 032, best_metric: 26.541%
2022-10-20 03:57:33 - epoch 033 lr: 0.000100
2022-10-20 03:59:01 - train: epoch 0033, iter [00100, 02526], lr: 0.000100, loss: 0.9162, CELoss: 0.9162, 
2022-10-20 04:00:25 - train: epoch 0033, iter [00200, 02526], lr: 0.000100, loss: 0.8735, CELoss: 0.8735, 
2022-10-20 04:01:51 - train: epoch 0033, iter [00300, 02526], lr: 0.000100, loss: 1.2027, CELoss: 1.2027, 
2022-10-20 04:03:16 - train: epoch 0033, iter [00400, 02526], lr: 0.000100, loss: 0.6133, CELoss: 0.6133, 
2022-10-20 04:04:41 - train: epoch 0033, iter [00500, 02526], lr: 0.000100, loss: 1.0815, CELoss: 1.0815, 
2022-10-20 04:06:06 - train: epoch 0033, iter [00600, 02526], lr: 0.000100, loss: 1.4756, CELoss: 1.4756, 
2022-10-20 04:07:31 - train: epoch 0033, iter [00700, 02526], lr: 0.000100, loss: 1.7208, CELoss: 1.7208, 
2022-10-20 04:08:56 - train: epoch 0033, iter [00800, 02526], lr: 0.000100, loss: 1.1985, CELoss: 1.1985, 
2022-10-20 04:10:21 - train: epoch 0033, iter [00900, 02526], lr: 0.000100, loss: 1.1121, CELoss: 1.1121, 
2022-10-20 04:11:47 - train: epoch 0033, iter [01000, 02526], lr: 0.000100, loss: 0.5480, CELoss: 0.5480, 
2022-10-20 04:13:12 - train: epoch 0033, iter [01100, 02526], lr: 0.000100, loss: 0.5861, CELoss: 0.5861, 
2022-10-20 04:14:37 - train: epoch 0033, iter [01200, 02526], lr: 0.000100, loss: 1.0742, CELoss: 1.0742, 
2022-10-20 04:16:03 - train: epoch 0033, iter [01300, 02526], lr: 0.000100, loss: 0.9312, CELoss: 0.9312, 
2022-10-20 04:17:28 - train: epoch 0033, iter [01400, 02526], lr: 0.000100, loss: 1.7865, CELoss: 1.7865, 
2022-10-20 04:18:54 - train: epoch 0033, iter [01500, 02526], lr: 0.000100, loss: 0.5052, CELoss: 0.5052, 
2022-10-20 04:20:19 - train: epoch 0033, iter [01600, 02526], lr: 0.000100, loss: 1.5132, CELoss: 1.5132, 
2022-10-20 04:21:44 - train: epoch 0033, iter [01700, 02526], lr: 0.000100, loss: 1.4273, CELoss: 1.4273, 
2022-10-20 04:23:10 - train: epoch 0033, iter [01800, 02526], lr: 0.000100, loss: 0.9626, CELoss: 0.9626, 
2022-10-20 04:24:36 - train: epoch 0033, iter [01900, 02526], lr: 0.000100, loss: 0.9938, CELoss: 0.9938, 
2022-10-20 04:26:01 - train: epoch 0033, iter [02000, 02526], lr: 0.000100, loss: 1.1504, CELoss: 1.1504, 
2022-10-20 04:27:26 - train: epoch 0033, iter [02100, 02526], lr: 0.000100, loss: 0.9568, CELoss: 0.9568, 
2022-10-20 04:28:52 - train: epoch 0033, iter [02200, 02526], lr: 0.000100, loss: 1.1800, CELoss: 1.1800, 
2022-10-20 04:30:17 - train: epoch 0033, iter [02300, 02526], lr: 0.000100, loss: 0.7545, CELoss: 0.7545, 
2022-10-20 04:31:42 - train: epoch 0033, iter [02400, 02526], lr: 0.000100, loss: 0.6686, CELoss: 0.6686, 
2022-10-20 04:33:07 - train: epoch 0033, iter [02500, 02526], lr: 0.000100, loss: 0.7001, CELoss: 0.7001, 
2022-10-20 04:33:31 - train: epoch 033, train_loss: 0.9426
2022-10-20 04:33:32 - until epoch: 033, best_metric: 26.541%
2022-10-20 04:33:32 - epoch 034 lr: 0.000100
2022-10-20 04:35:00 - train: epoch 0034, iter [00100, 02526], lr: 0.000100, loss: 0.9243, CELoss: 0.9243, 
2022-10-20 04:36:25 - train: epoch 0034, iter [00200, 02526], lr: 0.000100, loss: 0.5782, CELoss: 0.5782, 
2022-10-20 04:37:50 - train: epoch 0034, iter [00300, 02526], lr: 0.000100, loss: 1.1849, CELoss: 1.1849, 
2022-10-20 04:39:15 - train: epoch 0034, iter [00400, 02526], lr: 0.000100, loss: 1.1633, CELoss: 1.1633, 
2022-10-20 04:40:40 - train: epoch 0034, iter [00500, 02526], lr: 0.000100, loss: 1.1901, CELoss: 1.1901, 
2022-10-20 04:42:06 - train: epoch 0034, iter [00600, 02526], lr: 0.000100, loss: 0.8007, CELoss: 0.8007, 
2022-10-20 04:43:31 - train: epoch 0034, iter [00700, 02526], lr: 0.000100, loss: 0.9695, CELoss: 0.9695, 
2022-10-20 04:44:57 - train: epoch 0034, iter [00800, 02526], lr: 0.000100, loss: 0.9284, CELoss: 0.9284, 
2022-10-20 04:46:22 - train: epoch 0034, iter [00900, 02526], lr: 0.000100, loss: 0.6434, CELoss: 0.6434, 
2022-10-20 04:47:47 - train: epoch 0034, iter [01000, 02526], lr: 0.000100, loss: 0.7059, CELoss: 0.7059, 
2022-10-20 04:49:13 - train: epoch 0034, iter [01100, 02526], lr: 0.000100, loss: 1.1708, CELoss: 1.1708, 
2022-10-20 04:50:38 - train: epoch 0034, iter [01200, 02526], lr: 0.000100, loss: 0.6822, CELoss: 0.6822, 
2022-10-20 04:52:03 - train: epoch 0034, iter [01300, 02526], lr: 0.000100, loss: 1.1281, CELoss: 1.1281, 
2022-10-20 04:53:29 - train: epoch 0034, iter [01400, 02526], lr: 0.000100, loss: 1.6470, CELoss: 1.6470, 
2022-10-20 04:54:54 - train: epoch 0034, iter [01500, 02526], lr: 0.000100, loss: 0.7973, CELoss: 0.7973, 
2022-10-20 04:56:19 - train: epoch 0034, iter [01600, 02526], lr: 0.000100, loss: 1.1080, CELoss: 1.1080, 
2022-10-20 04:57:45 - train: epoch 0034, iter [01700, 02526], lr: 0.000100, loss: 1.3332, CELoss: 1.3332, 
2022-10-20 04:59:10 - train: epoch 0034, iter [01800, 02526], lr: 0.000100, loss: 0.9624, CELoss: 0.9624, 
2022-10-20 05:00:36 - train: epoch 0034, iter [01900, 02526], lr: 0.000100, loss: 0.7656, CELoss: 0.7656, 
2022-10-20 05:02:01 - train: epoch 0034, iter [02000, 02526], lr: 0.000100, loss: 1.0430, CELoss: 1.0430, 
2022-10-20 05:03:26 - train: epoch 0034, iter [02100, 02526], lr: 0.000100, loss: 1.1434, CELoss: 1.1434, 
2022-10-20 05:04:51 - train: epoch 0034, iter [02200, 02526], lr: 0.000100, loss: 0.7454, CELoss: 0.7454, 
2022-10-20 05:06:17 - train: epoch 0034, iter [02300, 02526], lr: 0.000100, loss: 0.8568, CELoss: 0.8568, 
2022-10-20 05:07:42 - train: epoch 0034, iter [02400, 02526], lr: 0.000100, loss: 0.9101, CELoss: 0.9101, 
2022-10-20 05:09:08 - train: epoch 0034, iter [02500, 02526], lr: 0.000100, loss: 0.7276, CELoss: 0.7276, 
2022-10-20 05:09:31 - train: epoch 034, train_loss: 0.9379
2022-10-20 05:09:31 - until epoch: 034, best_metric: 26.541%
2022-10-20 05:09:31 - epoch 035 lr: 0.000100
2022-10-20 05:11:00 - train: epoch 0035, iter [00100, 02526], lr: 0.000100, loss: 0.9000, CELoss: 0.9000, 
2022-10-20 05:12:25 - train: epoch 0035, iter [00200, 02526], lr: 0.000100, loss: 1.1035, CELoss: 1.1035, 
2022-10-20 05:13:50 - train: epoch 0035, iter [00300, 02526], lr: 0.000100, loss: 0.8272, CELoss: 0.8272, 
2022-10-20 05:15:16 - train: epoch 0035, iter [00400, 02526], lr: 0.000100, loss: 1.0041, CELoss: 1.0041, 
2022-10-20 05:16:41 - train: epoch 0035, iter [00500, 02526], lr: 0.000100, loss: 0.7243, CELoss: 0.7243, 
2022-10-20 05:18:06 - train: epoch 0035, iter [00600, 02526], lr: 0.000100, loss: 1.0545, CELoss: 1.0545, 
2022-10-20 05:19:31 - train: epoch 0035, iter [00700, 02526], lr: 0.000100, loss: 0.7150, CELoss: 0.7150, 
2022-10-20 05:20:57 - train: epoch 0035, iter [00800, 02526], lr: 0.000100, loss: 0.8917, CELoss: 0.8917, 
2022-10-20 05:22:22 - train: epoch 0035, iter [00900, 02526], lr: 0.000100, loss: 1.3551, CELoss: 1.3551, 
2022-10-20 05:23:48 - train: epoch 0035, iter [01000, 02526], lr: 0.000100, loss: 1.1445, CELoss: 1.1445, 
2022-10-20 05:25:14 - train: epoch 0035, iter [01100, 02526], lr: 0.000100, loss: 0.4896, CELoss: 0.4896, 
2022-10-20 05:26:39 - train: epoch 0035, iter [01200, 02526], lr: 0.000100, loss: 0.8419, CELoss: 0.8419, 
2022-10-20 05:28:04 - train: epoch 0035, iter [01300, 02526], lr: 0.000100, loss: 0.7288, CELoss: 0.7288, 
2022-10-20 05:29:30 - train: epoch 0035, iter [01400, 02526], lr: 0.000100, loss: 0.5615, CELoss: 0.5615, 
2022-10-20 05:30:55 - train: epoch 0035, iter [01500, 02526], lr: 0.000100, loss: 0.6713, CELoss: 0.6713, 
2022-10-20 05:32:21 - train: epoch 0035, iter [01600, 02526], lr: 0.000100, loss: 1.0264, CELoss: 1.0264, 
2022-10-20 05:33:46 - train: epoch 0035, iter [01700, 02526], lr: 0.000100, loss: 0.8301, CELoss: 0.8301, 
2022-10-20 05:35:12 - train: epoch 0035, iter [01800, 02526], lr: 0.000100, loss: 1.2882, CELoss: 1.2882, 
2022-10-20 05:36:37 - train: epoch 0035, iter [01900, 02526], lr: 0.000100, loss: 0.8611, CELoss: 0.8611, 
2022-10-20 05:38:02 - train: epoch 0035, iter [02000, 02526], lr: 0.000100, loss: 0.9855, CELoss: 0.9855, 
2022-10-20 05:39:28 - train: epoch 0035, iter [02100, 02526], lr: 0.000100, loss: 0.5323, CELoss: 0.5323, 
2022-10-20 05:40:53 - train: epoch 0035, iter [02200, 02526], lr: 0.000100, loss: 1.1350, CELoss: 1.1350, 
2022-10-20 05:42:19 - train: epoch 0035, iter [02300, 02526], lr: 0.000100, loss: 1.1559, CELoss: 1.1559, 
2022-10-20 05:43:44 - train: epoch 0035, iter [02400, 02526], lr: 0.000100, loss: 1.2496, CELoss: 1.2496, 
2022-10-20 05:45:10 - train: epoch 0035, iter [02500, 02526], lr: 0.000100, loss: 0.6233, CELoss: 0.6233, 
2022-10-20 05:45:33 - train: epoch 035, train_loss: 0.9280
2022-10-20 05:48:20 - eval: epoch: 035
test_loss: 1.0052204158008098
per_image_load_time: 1.036ms
per_image_inference_time: 76.825ms
exist_num_class: 150.0
mean_precision: 47.071903104571284
mean_recall: 41.624077033131755
mean_iou: 28.03522059138719
mean_dice: 40.17479198967606

2022-10-20 05:48:21 - until epoch: 035, best_metric: 28.035%
2022-10-20 05:48:21 - epoch 036 lr: 0.000100
2022-10-20 05:49:49 - train: epoch 0036, iter [00100, 02526], lr: 0.000100, loss: 1.2697, CELoss: 1.2697, 
2022-10-20 05:51:14 - train: epoch 0036, iter [00200, 02526], lr: 0.000100, loss: 0.8290, CELoss: 0.8290, 
2022-10-20 05:52:39 - train: epoch 0036, iter [00300, 02526], lr: 0.000100, loss: 1.0638, CELoss: 1.0638, 
2022-10-20 05:54:05 - train: epoch 0036, iter [00400, 02526], lr: 0.000100, loss: 0.8133, CELoss: 0.8133, 
2022-10-20 05:55:30 - train: epoch 0036, iter [00500, 02526], lr: 0.000100, loss: 0.6885, CELoss: 0.6885, 
2022-10-20 05:56:56 - train: epoch 0036, iter [00600, 02526], lr: 0.000100, loss: 0.4662, CELoss: 0.4662, 
2022-10-20 05:58:22 - train: epoch 0036, iter [00700, 02526], lr: 0.000100, loss: 1.0417, CELoss: 1.0417, 
2022-10-20 05:59:47 - train: epoch 0036, iter [00800, 02526], lr: 0.000100, loss: 0.6465, CELoss: 0.6465, 
2022-10-20 06:01:12 - train: epoch 0036, iter [00900, 02526], lr: 0.000100, loss: 1.1383, CELoss: 1.1383, 
2022-10-20 06:02:38 - train: epoch 0036, iter [01000, 02526], lr: 0.000100, loss: 0.6992, CELoss: 0.6992, 
2022-10-20 06:04:03 - train: epoch 0036, iter [01100, 02526], lr: 0.000100, loss: 1.5198, CELoss: 1.5198, 
2022-10-20 06:05:29 - train: epoch 0036, iter [01200, 02526], lr: 0.000100, loss: 0.8915, CELoss: 0.8915, 
2022-10-20 06:06:54 - train: epoch 0036, iter [01300, 02526], lr: 0.000100, loss: 1.0532, CELoss: 1.0532, 
2022-10-20 06:08:20 - train: epoch 0036, iter [01400, 02526], lr: 0.000100, loss: 0.9986, CELoss: 0.9986, 
2022-10-20 06:09:45 - train: epoch 0036, iter [01500, 02526], lr: 0.000100, loss: 1.1799, CELoss: 1.1799, 
2022-10-20 06:11:11 - train: epoch 0036, iter [01600, 02526], lr: 0.000100, loss: 1.2968, CELoss: 1.2968, 
2022-10-20 06:12:36 - train: epoch 0036, iter [01700, 02526], lr: 0.000100, loss: 1.0281, CELoss: 1.0281, 
2022-10-20 06:14:01 - train: epoch 0036, iter [01800, 02526], lr: 0.000100, loss: 1.2616, CELoss: 1.2616, 
2022-10-20 06:15:26 - train: epoch 0036, iter [01900, 02526], lr: 0.000100, loss: 1.0681, CELoss: 1.0681, 
2022-10-20 06:16:52 - train: epoch 0036, iter [02000, 02526], lr: 0.000100, loss: 0.9358, CELoss: 0.9358, 
2022-10-20 06:18:17 - train: epoch 0036, iter [02100, 02526], lr: 0.000100, loss: 0.8197, CELoss: 0.8197, 
2022-10-20 06:19:43 - train: epoch 0036, iter [02200, 02526], lr: 0.000100, loss: 0.7660, CELoss: 0.7660, 
2022-10-20 06:21:08 - train: epoch 0036, iter [02300, 02526], lr: 0.000100, loss: 1.0805, CELoss: 1.0805, 
2022-10-20 06:22:34 - train: epoch 0036, iter [02400, 02526], lr: 0.000100, loss: 1.1118, CELoss: 1.1118, 
2022-10-20 06:23:59 - train: epoch 0036, iter [02500, 02526], lr: 0.000100, loss: 0.6260, CELoss: 0.6260, 
2022-10-20 06:24:22 - train: epoch 036, train_loss: 0.9201
2022-10-20 06:24:23 - until epoch: 036, best_metric: 28.035%
2022-10-20 06:24:23 - epoch 037 lr: 0.000100
2022-10-20 06:25:51 - train: epoch 0037, iter [00100, 02526], lr: 0.000100, loss: 0.5496, CELoss: 0.5496, 
2022-10-20 06:27:16 - train: epoch 0037, iter [00200, 02526], lr: 0.000100, loss: 0.8869, CELoss: 0.8869, 
2022-10-20 06:28:42 - train: epoch 0037, iter [00300, 02526], lr: 0.000100, loss: 0.9437, CELoss: 0.9437, 
2022-10-20 06:30:07 - train: epoch 0037, iter [00400, 02526], lr: 0.000100, loss: 0.6558, CELoss: 0.6558, 
2022-10-20 06:31:32 - train: epoch 0037, iter [00500, 02526], lr: 0.000100, loss: 1.1566, CELoss: 1.1566, 
2022-10-20 06:32:58 - train: epoch 0037, iter [00600, 02526], lr: 0.000100, loss: 1.4769, CELoss: 1.4769, 
2022-10-20 06:34:23 - train: epoch 0037, iter [00700, 02526], lr: 0.000100, loss: 0.5580, CELoss: 0.5580, 
2022-10-20 06:35:49 - train: epoch 0037, iter [00800, 02526], lr: 0.000100, loss: 1.2756, CELoss: 1.2756, 
2022-10-20 06:37:14 - train: epoch 0037, iter [00900, 02526], lr: 0.000100, loss: 0.8261, CELoss: 0.8261, 
2022-10-20 06:38:39 - train: epoch 0037, iter [01000, 02526], lr: 0.000100, loss: 1.0851, CELoss: 1.0851, 
2022-10-20 06:40:05 - train: epoch 0037, iter [01100, 02526], lr: 0.000100, loss: 1.2049, CELoss: 1.2049, 
2022-10-20 06:41:30 - train: epoch 0037, iter [01200, 02526], lr: 0.000100, loss: 0.7829, CELoss: 0.7829, 
2022-10-20 06:42:55 - train: epoch 0037, iter [01300, 02526], lr: 0.000100, loss: 1.1824, CELoss: 1.1824, 
2022-10-20 06:44:21 - train: epoch 0037, iter [01400, 02526], lr: 0.000100, loss: 1.2580, CELoss: 1.2580, 
2022-10-20 06:45:46 - train: epoch 0037, iter [01500, 02526], lr: 0.000100, loss: 1.2724, CELoss: 1.2724, 
2022-10-20 06:47:11 - train: epoch 0037, iter [01600, 02526], lr: 0.000100, loss: 0.7940, CELoss: 0.7940, 
2022-10-20 06:48:37 - train: epoch 0037, iter [01700, 02526], lr: 0.000100, loss: 1.1006, CELoss: 1.1006, 
2022-10-20 06:50:02 - train: epoch 0037, iter [01800, 02526], lr: 0.000100, loss: 0.6777, CELoss: 0.6777, 
2022-10-20 06:51:28 - train: epoch 0037, iter [01900, 02526], lr: 0.000100, loss: 1.0346, CELoss: 1.0346, 
2022-10-20 06:52:53 - train: epoch 0037, iter [02000, 02526], lr: 0.000100, loss: 1.1880, CELoss: 1.1880, 
2022-10-20 06:54:19 - train: epoch 0037, iter [02100, 02526], lr: 0.000100, loss: 0.5645, CELoss: 0.5645, 
2022-10-20 06:55:44 - train: epoch 0037, iter [02200, 02526], lr: 0.000100, loss: 0.7061, CELoss: 0.7061, 
2022-10-20 06:57:10 - train: epoch 0037, iter [02300, 02526], lr: 0.000100, loss: 1.0250, CELoss: 1.0250, 
2022-10-20 06:58:35 - train: epoch 0037, iter [02400, 02526], lr: 0.000100, loss: 2.0677, CELoss: 2.0677, 
2022-10-20 07:00:01 - train: epoch 0037, iter [02500, 02526], lr: 0.000100, loss: 0.7590, CELoss: 0.7590, 
2022-10-20 07:00:24 - train: epoch 037, train_loss: 0.9145
2022-10-20 07:00:25 - until epoch: 037, best_metric: 28.035%
2022-10-20 07:00:25 - epoch 038 lr: 0.000100
2022-10-20 07:01:53 - train: epoch 0038, iter [00100, 02526], lr: 0.000100, loss: 0.7976, CELoss: 0.7976, 
2022-10-20 07:03:19 - train: epoch 0038, iter [00200, 02526], lr: 0.000100, loss: 0.7287, CELoss: 0.7287, 
2022-10-20 07:04:45 - train: epoch 0038, iter [00300, 02526], lr: 0.000100, loss: 0.9882, CELoss: 0.9882, 
2022-10-20 07:06:10 - train: epoch 0038, iter [00400, 02526], lr: 0.000100, loss: 0.7658, CELoss: 0.7658, 
2022-10-20 07:07:35 - train: epoch 0038, iter [00500, 02526], lr: 0.000100, loss: 0.6930, CELoss: 0.6930, 
2022-10-20 07:09:01 - train: epoch 0038, iter [00600, 02526], lr: 0.000100, loss: 0.7138, CELoss: 0.7138, 
2022-10-20 07:10:26 - train: epoch 0038, iter [00700, 02526], lr: 0.000100, loss: 1.3812, CELoss: 1.3812, 
2022-10-20 07:11:52 - train: epoch 0038, iter [00800, 02526], lr: 0.000100, loss: 0.9704, CELoss: 0.9704, 
2022-10-20 07:13:17 - train: epoch 0038, iter [00900, 02526], lr: 0.000100, loss: 1.0248, CELoss: 1.0248, 
2022-10-20 07:14:43 - train: epoch 0038, iter [01000, 02526], lr: 0.000100, loss: 0.5706, CELoss: 0.5706, 
2022-10-20 07:16:08 - train: epoch 0038, iter [01100, 02526], lr: 0.000100, loss: 0.7006, CELoss: 0.7006, 
2022-10-20 07:17:34 - train: epoch 0038, iter [01200, 02526], lr: 0.000100, loss: 1.3517, CELoss: 1.3517, 
2022-10-20 07:18:59 - train: epoch 0038, iter [01300, 02526], lr: 0.000100, loss: 0.6779, CELoss: 0.6779, 
2022-10-20 07:20:24 - train: epoch 0038, iter [01400, 02526], lr: 0.000100, loss: 1.3097, CELoss: 1.3097, 
2022-10-20 07:21:49 - train: epoch 0038, iter [01500, 02526], lr: 0.000100, loss: 1.2889, CELoss: 1.2889, 
2022-10-20 07:23:15 - train: epoch 0038, iter [01600, 02526], lr: 0.000100, loss: 0.8694, CELoss: 0.8694, 
2022-10-20 07:24:40 - train: epoch 0038, iter [01700, 02526], lr: 0.000100, loss: 0.9071, CELoss: 0.9071, 
2022-10-20 07:26:05 - train: epoch 0038, iter [01800, 02526], lr: 0.000100, loss: 0.7494, CELoss: 0.7494, 
2022-10-20 07:27:31 - train: epoch 0038, iter [01900, 02526], lr: 0.000100, loss: 1.2074, CELoss: 1.2074, 
2022-10-20 07:28:56 - train: epoch 0038, iter [02000, 02526], lr: 0.000100, loss: 0.5662, CELoss: 0.5662, 
2022-10-20 07:30:21 - train: epoch 0038, iter [02100, 02526], lr: 0.000100, loss: 1.5647, CELoss: 1.5647, 
2022-10-20 07:31:47 - train: epoch 0038, iter [02200, 02526], lr: 0.000100, loss: 0.8438, CELoss: 0.8438, 
2022-10-20 07:33:12 - train: epoch 0038, iter [02300, 02526], lr: 0.000100, loss: 0.7250, CELoss: 0.7250, 
2022-10-20 07:34:37 - train: epoch 0038, iter [02400, 02526], lr: 0.000100, loss: 0.5240, CELoss: 0.5240, 
2022-10-20 07:36:03 - train: epoch 0038, iter [02500, 02526], lr: 0.000100, loss: 1.1190, CELoss: 1.1190, 
2022-10-20 07:36:26 - train: epoch 038, train_loss: 0.9161
2022-10-20 07:36:26 - until epoch: 038, best_metric: 28.035%
2022-10-20 07:36:26 - epoch 039 lr: 0.000100
2022-10-20 07:37:54 - train: epoch 0039, iter [00100, 02526], lr: 0.000100, loss: 0.9888, CELoss: 0.9888, 
2022-10-20 07:39:19 - train: epoch 0039, iter [00200, 02526], lr: 0.000100, loss: 0.6488, CELoss: 0.6488, 
2022-10-20 07:40:45 - train: epoch 0039, iter [00300, 02526], lr: 0.000100, loss: 0.8209, CELoss: 0.8209, 
2022-10-20 07:42:10 - train: epoch 0039, iter [00400, 02526], lr: 0.000100, loss: 1.1167, CELoss: 1.1167, 
2022-10-20 07:43:35 - train: epoch 0039, iter [00500, 02526], lr: 0.000100, loss: 1.3601, CELoss: 1.3601, 
2022-10-20 07:45:01 - train: epoch 0039, iter [00600, 02526], lr: 0.000100, loss: 0.9791, CELoss: 0.9791, 
2022-10-20 07:46:26 - train: epoch 0039, iter [00700, 02526], lr: 0.000100, loss: 1.2392, CELoss: 1.2392, 
2022-10-20 07:47:51 - train: epoch 0039, iter [00800, 02526], lr: 0.000100, loss: 0.7824, CELoss: 0.7824, 
2022-10-20 07:49:17 - train: epoch 0039, iter [00900, 02526], lr: 0.000100, loss: 1.2205, CELoss: 1.2205, 
2022-10-20 07:50:42 - train: epoch 0039, iter [01000, 02526], lr: 0.000100, loss: 0.9306, CELoss: 0.9306, 
2022-10-20 07:52:07 - train: epoch 0039, iter [01100, 02526], lr: 0.000100, loss: 0.8603, CELoss: 0.8603, 
2022-10-20 07:53:32 - train: epoch 0039, iter [01200, 02526], lr: 0.000100, loss: 0.6068, CELoss: 0.6068, 
2022-10-20 07:54:57 - train: epoch 0039, iter [01300, 02526], lr: 0.000100, loss: 1.8777, CELoss: 1.8777, 
2022-10-20 07:56:22 - train: epoch 0039, iter [01400, 02526], lr: 0.000100, loss: 0.5456, CELoss: 0.5456, 
2022-10-20 07:57:48 - train: epoch 0039, iter [01500, 02526], lr: 0.000100, loss: 0.6134, CELoss: 0.6134, 
2022-10-20 07:59:13 - train: epoch 0039, iter [01600, 02526], lr: 0.000100, loss: 1.2283, CELoss: 1.2283, 
2022-10-20 08:00:38 - train: epoch 0039, iter [01700, 02526], lr: 0.000100, loss: 0.6244, CELoss: 0.6244, 
2022-10-20 08:02:03 - train: epoch 0039, iter [01800, 02526], lr: 0.000100, loss: 0.6647, CELoss: 0.6647, 
2022-10-20 08:03:28 - train: epoch 0039, iter [01900, 02526], lr: 0.000100, loss: 0.5555, CELoss: 0.5555, 
2022-10-20 08:04:53 - train: epoch 0039, iter [02000, 02526], lr: 0.000100, loss: 1.0326, CELoss: 1.0326, 
2022-10-20 08:06:19 - train: epoch 0039, iter [02100, 02526], lr: 0.000100, loss: 1.0377, CELoss: 1.0377, 
2022-10-20 08:07:44 - train: epoch 0039, iter [02200, 02526], lr: 0.000100, loss: 1.0041, CELoss: 1.0041, 
2022-10-20 08:09:09 - train: epoch 0039, iter [02300, 02526], lr: 0.000100, loss: 0.8214, CELoss: 0.8214, 
2022-10-20 08:10:35 - train: epoch 0039, iter [02400, 02526], lr: 0.000100, loss: 0.6615, CELoss: 0.6615, 
2022-10-20 08:12:00 - train: epoch 0039, iter [02500, 02526], lr: 0.000100, loss: 1.5246, CELoss: 1.5246, 
2022-10-20 08:12:23 - train: epoch 039, train_loss: 0.9017
2022-10-20 08:12:24 - until epoch: 039, best_metric: 28.035%
2022-10-20 08:12:24 - epoch 040 lr: 0.000100
2022-10-20 08:13:52 - train: epoch 0040, iter [00100, 02526], lr: 0.000100, loss: 0.6222, CELoss: 0.6222, 
2022-10-20 08:15:17 - train: epoch 0040, iter [00200, 02526], lr: 0.000100, loss: 1.1823, CELoss: 1.1823, 
2022-10-20 08:16:42 - train: epoch 0040, iter [00300, 02526], lr: 0.000100, loss: 0.8432, CELoss: 0.8432, 
2022-10-20 08:18:07 - train: epoch 0040, iter [00400, 02526], lr: 0.000100, loss: 1.4338, CELoss: 1.4338, 
2022-10-20 08:19:33 - train: epoch 0040, iter [00500, 02526], lr: 0.000100, loss: 0.8773, CELoss: 0.8773, 
2022-10-20 08:20:58 - train: epoch 0040, iter [00600, 02526], lr: 0.000100, loss: 0.5958, CELoss: 0.5958, 
2022-10-20 08:22:23 - train: epoch 0040, iter [00700, 02526], lr: 0.000100, loss: 1.4306, CELoss: 1.4306, 
2022-10-20 08:23:48 - train: epoch 0040, iter [00800, 02526], lr: 0.000100, loss: 1.0862, CELoss: 1.0862, 
2022-10-20 08:25:13 - train: epoch 0040, iter [00900, 02526], lr: 0.000100, loss: 0.6795, CELoss: 0.6795, 
2022-10-20 08:26:38 - train: epoch 0040, iter [01000, 02526], lr: 0.000100, loss: 1.0912, CELoss: 1.0912, 
2022-10-20 08:28:04 - train: epoch 0040, iter [01100, 02526], lr: 0.000100, loss: 0.7235, CELoss: 0.7235, 
2022-10-20 08:29:29 - train: epoch 0040, iter [01200, 02526], lr: 0.000100, loss: 0.6786, CELoss: 0.6786, 
2022-10-20 08:30:54 - train: epoch 0040, iter [01300, 02526], lr: 0.000100, loss: 0.3726, CELoss: 0.3726, 
2022-10-20 08:32:19 - train: epoch 0040, iter [01400, 02526], lr: 0.000100, loss: 1.0917, CELoss: 1.0917, 
2022-10-20 08:33:44 - train: epoch 0040, iter [01500, 02526], lr: 0.000100, loss: 0.4598, CELoss: 0.4598, 
2022-10-20 08:35:09 - train: epoch 0040, iter [01600, 02526], lr: 0.000100, loss: 0.7080, CELoss: 0.7080, 
2022-10-20 08:36:34 - train: epoch 0040, iter [01700, 02526], lr: 0.000100, loss: 1.0365, CELoss: 1.0365, 
2022-10-20 08:38:00 - train: epoch 0040, iter [01800, 02526], lr: 0.000100, loss: 0.9347, CELoss: 0.9347, 
2022-10-20 08:39:25 - train: epoch 0040, iter [01900, 02526], lr: 0.000100, loss: 0.7220, CELoss: 0.7220, 
2022-10-20 08:40:51 - train: epoch 0040, iter [02000, 02526], lr: 0.000100, loss: 0.7010, CELoss: 0.7010, 
2022-10-20 08:42:15 - train: epoch 0040, iter [02100, 02526], lr: 0.000100, loss: 0.9128, CELoss: 0.9128, 
2022-10-20 08:43:41 - train: epoch 0040, iter [02200, 02526], lr: 0.000100, loss: 0.4530, CELoss: 0.4530, 
2022-10-20 08:45:06 - train: epoch 0040, iter [02300, 02526], lr: 0.000100, loss: 1.6690, CELoss: 1.6690, 
2022-10-20 08:46:31 - train: epoch 0040, iter [02400, 02526], lr: 0.000100, loss: 0.5630, CELoss: 0.5630, 
2022-10-20 08:47:56 - train: epoch 0040, iter [02500, 02526], lr: 0.000100, loss: 0.6038, CELoss: 0.6038, 
2022-10-20 08:48:20 - train: epoch 040, train_loss: 0.9027
2022-10-20 08:51:07 - eval: epoch: 040
test_loss: 0.9976127958595753
per_image_load_time: 1.155ms
per_image_inference_time: 76.576ms
exist_num_class: 150.0
mean_precision: 47.493785596568635
mean_recall: 43.23720096360495
mean_iou: 28.793314372478278
mean_dice: 41.23016396714434

2022-10-20 08:51:08 - until epoch: 040, best_metric: 28.793%
2022-10-20 08:51:08 - epoch 041 lr: 0.000100
2022-10-20 08:52:35 - train: epoch 0041, iter [00100, 02526], lr: 0.000100, loss: 0.7947, CELoss: 0.7947, 
2022-10-20 08:54:00 - train: epoch 0041, iter [00200, 02526], lr: 0.000100, loss: 1.0104, CELoss: 1.0104, 
2022-10-20 08:55:25 - train: epoch 0041, iter [00300, 02526], lr: 0.000100, loss: 1.3748, CELoss: 1.3748, 
2022-10-20 08:56:50 - train: epoch 0041, iter [00400, 02526], lr: 0.000100, loss: 0.8132, CELoss: 0.8132, 
2022-10-20 08:58:14 - train: epoch 0041, iter [00500, 02526], lr: 0.000100, loss: 0.9202, CELoss: 0.9202, 
2022-10-20 08:59:38 - train: epoch 0041, iter [00600, 02526], lr: 0.000100, loss: 0.6730, CELoss: 0.6730, 
2022-10-20 09:01:02 - train: epoch 0041, iter [00700, 02526], lr: 0.000100, loss: 0.7483, CELoss: 0.7483, 
2022-10-20 09:02:27 - train: epoch 0041, iter [00800, 02526], lr: 0.000100, loss: 0.6859, CELoss: 0.6859, 
2022-10-20 09:03:51 - train: epoch 0041, iter [00900, 02526], lr: 0.000100, loss: 0.8224, CELoss: 0.8224, 
2022-10-20 09:05:16 - train: epoch 0041, iter [01000, 02526], lr: 0.000100, loss: 0.6941, CELoss: 0.6941, 
2022-10-20 09:06:40 - train: epoch 0041, iter [01100, 02526], lr: 0.000100, loss: 0.7484, CELoss: 0.7484, 
2022-10-20 09:08:05 - train: epoch 0041, iter [01200, 02526], lr: 0.000100, loss: 1.2638, CELoss: 1.2638, 
2022-10-20 09:09:29 - train: epoch 0041, iter [01300, 02526], lr: 0.000100, loss: 0.5890, CELoss: 0.5890, 
2022-10-20 09:10:54 - train: epoch 0041, iter [01400, 02526], lr: 0.000100, loss: 1.0552, CELoss: 1.0552, 
2022-10-20 09:12:19 - train: epoch 0041, iter [01500, 02526], lr: 0.000100, loss: 1.0310, CELoss: 1.0310, 
2022-10-20 09:13:43 - train: epoch 0041, iter [01600, 02526], lr: 0.000100, loss: 0.6682, CELoss: 0.6682, 
2022-10-20 09:15:08 - train: epoch 0041, iter [01700, 02526], lr: 0.000100, loss: 0.8797, CELoss: 0.8797, 
2022-10-20 09:16:32 - train: epoch 0041, iter [01800, 02526], lr: 0.000100, loss: 0.6532, CELoss: 0.6532, 
2022-10-20 09:17:57 - train: epoch 0041, iter [01900, 02526], lr: 0.000100, loss: 0.7541, CELoss: 0.7541, 
2022-10-20 09:19:22 - train: epoch 0041, iter [02000, 02526], lr: 0.000100, loss: 0.5641, CELoss: 0.5641, 
2022-10-20 09:20:47 - train: epoch 0041, iter [02100, 02526], lr: 0.000100, loss: 1.1103, CELoss: 1.1103, 
2022-10-20 09:22:11 - train: epoch 0041, iter [02200, 02526], lr: 0.000100, loss: 0.7047, CELoss: 0.7047, 
2022-10-20 09:23:35 - train: epoch 0041, iter [02300, 02526], lr: 0.000100, loss: 1.1750, CELoss: 1.1750, 
2022-10-20 09:25:00 - train: epoch 0041, iter [02400, 02526], lr: 0.000100, loss: 0.7773, CELoss: 0.7773, 
2022-10-20 09:26:25 - train: epoch 0041, iter [02500, 02526], lr: 0.000100, loss: 0.7543, CELoss: 0.7543, 
2022-10-20 09:26:48 - train: epoch 041, train_loss: 0.8910
2022-10-20 09:26:49 - until epoch: 041, best_metric: 28.793%
2022-10-20 09:26:49 - epoch 042 lr: 0.000100
2022-10-20 09:28:16 - train: epoch 0042, iter [00100, 02526], lr: 0.000100, loss: 1.5031, CELoss: 1.5031, 
2022-10-20 09:29:41 - train: epoch 0042, iter [00200, 02526], lr: 0.000100, loss: 0.4149, CELoss: 0.4149, 
2022-10-20 09:31:05 - train: epoch 0042, iter [00300, 02526], lr: 0.000100, loss: 0.7032, CELoss: 0.7032, 
2022-10-20 09:32:30 - train: epoch 0042, iter [00400, 02526], lr: 0.000100, loss: 0.7896, CELoss: 0.7896, 
2022-10-20 09:33:55 - train: epoch 0042, iter [00500, 02526], lr: 0.000100, loss: 0.9204, CELoss: 0.9204, 
2022-10-20 09:35:19 - train: epoch 0042, iter [00600, 02526], lr: 0.000100, loss: 0.8986, CELoss: 0.8986, 
2022-10-20 09:36:43 - train: epoch 0042, iter [00700, 02526], lr: 0.000100, loss: 0.6293, CELoss: 0.6293, 
2022-10-20 09:38:08 - train: epoch 0042, iter [00800, 02526], lr: 0.000100, loss: 0.4987, CELoss: 0.4987, 
2022-10-20 09:39:32 - train: epoch 0042, iter [00900, 02526], lr: 0.000100, loss: 0.8850, CELoss: 0.8850, 
2022-10-20 09:40:57 - train: epoch 0042, iter [01000, 02526], lr: 0.000100, loss: 0.7954, CELoss: 0.7954, 
2022-10-20 09:42:21 - train: epoch 0042, iter [01100, 02526], lr: 0.000100, loss: 0.8622, CELoss: 0.8622, 
2022-10-20 09:43:45 - train: epoch 0042, iter [01200, 02526], lr: 0.000100, loss: 0.8031, CELoss: 0.8031, 
2022-10-20 09:45:10 - train: epoch 0042, iter [01300, 02526], lr: 0.000100, loss: 0.6894, CELoss: 0.6894, 
2022-10-20 09:46:34 - train: epoch 0042, iter [01400, 02526], lr: 0.000100, loss: 0.5934, CELoss: 0.5934, 
2022-10-20 09:47:59 - train: epoch 0042, iter [01500, 02526], lr: 0.000100, loss: 0.8371, CELoss: 0.8371, 
2022-10-20 09:49:23 - train: epoch 0042, iter [01600, 02526], lr: 0.000100, loss: 0.7498, CELoss: 0.7498, 
2022-10-20 09:50:48 - train: epoch 0042, iter [01700, 02526], lr: 0.000100, loss: 0.9820, CELoss: 0.9820, 
2022-10-20 09:52:12 - train: epoch 0042, iter [01800, 02526], lr: 0.000100, loss: 1.1477, CELoss: 1.1477, 
2022-10-20 09:53:36 - train: epoch 0042, iter [01900, 02526], lr: 0.000100, loss: 1.1732, CELoss: 1.1732, 
2022-10-20 09:55:01 - train: epoch 0042, iter [02000, 02526], lr: 0.000100, loss: 0.6690, CELoss: 0.6690, 
2022-10-20 09:56:26 - train: epoch 0042, iter [02100, 02526], lr: 0.000100, loss: 1.0793, CELoss: 1.0793, 
2022-10-20 09:57:50 - train: epoch 0042, iter [02200, 02526], lr: 0.000100, loss: 0.8333, CELoss: 0.8333, 
2022-10-20 09:59:15 - train: epoch 0042, iter [02300, 02526], lr: 0.000100, loss: 0.7816, CELoss: 0.7816, 
2022-10-20 10:00:40 - train: epoch 0042, iter [02400, 02526], lr: 0.000100, loss: 1.1151, CELoss: 1.1151, 
2022-10-20 10:02:04 - train: epoch 0042, iter [02500, 02526], lr: 0.000100, loss: 0.8001, CELoss: 0.8001, 
2022-10-20 10:02:27 - train: epoch 042, train_loss: 0.8914
2022-10-20 10:02:28 - until epoch: 042, best_metric: 28.793%
2022-10-20 10:02:28 - epoch 043 lr: 0.000100
2022-10-20 10:03:55 - train: epoch 0043, iter [00100, 02526], lr: 0.000100, loss: 0.8484, CELoss: 0.8484, 
2022-10-20 10:05:19 - train: epoch 0043, iter [00200, 02526], lr: 0.000100, loss: 0.6319, CELoss: 0.6319, 
2022-10-20 10:06:44 - train: epoch 0043, iter [00300, 02526], lr: 0.000100, loss: 0.6677, CELoss: 0.6677, 
2022-10-20 10:08:08 - train: epoch 0043, iter [00400, 02526], lr: 0.000100, loss: 1.3522, CELoss: 1.3522, 
2022-10-20 10:09:34 - train: epoch 0043, iter [00500, 02526], lr: 0.000100, loss: 1.2564, CELoss: 1.2564, 
2022-10-20 10:10:58 - train: epoch 0043, iter [00600, 02526], lr: 0.000100, loss: 0.9159, CELoss: 0.9159, 
2022-10-20 10:12:23 - train: epoch 0043, iter [00700, 02526], lr: 0.000100, loss: 0.9064, CELoss: 0.9064, 
2022-10-20 10:13:47 - train: epoch 0043, iter [00800, 02526], lr: 0.000100, loss: 0.6970, CELoss: 0.6970, 
2022-10-20 10:15:12 - train: epoch 0043, iter [00900, 02526], lr: 0.000100, loss: 0.6650, CELoss: 0.6650, 
2022-10-20 10:16:37 - train: epoch 0043, iter [01000, 02526], lr: 0.000100, loss: 1.2090, CELoss: 1.2090, 
2022-10-20 10:18:01 - train: epoch 0043, iter [01100, 02526], lr: 0.000100, loss: 1.0115, CELoss: 1.0115, 
2022-10-20 10:19:26 - train: epoch 0043, iter [01200, 02526], lr: 0.000100, loss: 0.9456, CELoss: 0.9456, 
2022-10-20 10:20:50 - train: epoch 0043, iter [01300, 02526], lr: 0.000100, loss: 1.2493, CELoss: 1.2493, 
2022-10-20 10:22:15 - train: epoch 0043, iter [01400, 02526], lr: 0.000100, loss: 1.1020, CELoss: 1.1020, 
2022-10-20 10:23:39 - train: epoch 0043, iter [01500, 02526], lr: 0.000100, loss: 1.8237, CELoss: 1.8237, 
2022-10-20 10:25:04 - train: epoch 0043, iter [01600, 02526], lr: 0.000100, loss: 0.4318, CELoss: 0.4318, 
2022-10-20 10:26:28 - train: epoch 0043, iter [01700, 02526], lr: 0.000100, loss: 0.8189, CELoss: 0.8189, 
2022-10-20 10:27:53 - train: epoch 0043, iter [01800, 02526], lr: 0.000100, loss: 0.7822, CELoss: 0.7822, 
2022-10-20 10:29:18 - train: epoch 0043, iter [01900, 02526], lr: 0.000100, loss: 0.8586, CELoss: 0.8586, 
2022-10-20 10:30:42 - train: epoch 0043, iter [02000, 02526], lr: 0.000100, loss: 1.1189, CELoss: 1.1189, 
2022-10-20 10:32:07 - train: epoch 0043, iter [02100, 02526], lr: 0.000100, loss: 0.8810, CELoss: 0.8810, 
2022-10-20 10:33:31 - train: epoch 0043, iter [02200, 02526], lr: 0.000100, loss: 1.2900, CELoss: 1.2900, 
2022-10-20 10:34:56 - train: epoch 0043, iter [02300, 02526], lr: 0.000100, loss: 0.6016, CELoss: 0.6016, 
2022-10-20 10:36:21 - train: epoch 0043, iter [02400, 02526], lr: 0.000100, loss: 0.8460, CELoss: 0.8460, 
2022-10-20 10:37:45 - train: epoch 0043, iter [02500, 02526], lr: 0.000100, loss: 0.8863, CELoss: 0.8863, 
2022-10-20 10:38:08 - train: epoch 043, train_loss: 0.8770
2022-10-20 10:38:09 - until epoch: 043, best_metric: 28.793%
2022-10-20 10:38:09 - epoch 044 lr: 0.000100
2022-10-20 10:39:37 - train: epoch 0044, iter [00100, 02526], lr: 0.000100, loss: 0.6717, CELoss: 0.6717, 
2022-10-20 10:41:02 - train: epoch 0044, iter [00200, 02526], lr: 0.000100, loss: 0.7650, CELoss: 0.7650, 
2022-10-20 10:42:27 - train: epoch 0044, iter [00300, 02526], lr: 0.000100, loss: 0.7673, CELoss: 0.7673, 
2022-10-20 10:43:52 - train: epoch 0044, iter [00400, 02526], lr: 0.000100, loss: 0.6107, CELoss: 0.6107, 
2022-10-20 10:45:17 - train: epoch 0044, iter [00500, 02526], lr: 0.000100, loss: 0.9746, CELoss: 0.9746, 
2022-10-20 10:46:42 - train: epoch 0044, iter [00600, 02526], lr: 0.000100, loss: 1.0017, CELoss: 1.0017, 
2022-10-20 10:48:07 - train: epoch 0044, iter [00700, 02526], lr: 0.000100, loss: 0.9038, CELoss: 0.9038, 
2022-10-20 10:49:32 - train: epoch 0044, iter [00800, 02526], lr: 0.000100, loss: 0.7886, CELoss: 0.7886, 
2022-10-20 10:50:56 - train: epoch 0044, iter [00900, 02526], lr: 0.000100, loss: 0.8852, CELoss: 0.8852, 
2022-10-20 10:52:21 - train: epoch 0044, iter [01000, 02526], lr: 0.000100, loss: 0.7137, CELoss: 0.7137, 
2022-10-20 10:53:46 - train: epoch 0044, iter [01100, 02526], lr: 0.000100, loss: 0.8900, CELoss: 0.8900, 
2022-10-20 10:55:11 - train: epoch 0044, iter [01200, 02526], lr: 0.000100, loss: 2.0682, CELoss: 2.0682, 
2022-10-20 10:56:36 - train: epoch 0044, iter [01300, 02526], lr: 0.000100, loss: 0.6977, CELoss: 0.6977, 
2022-10-20 10:58:02 - train: epoch 0044, iter [01400, 02526], lr: 0.000100, loss: 0.6510, CELoss: 0.6510, 
2022-10-20 10:59:27 - train: epoch 0044, iter [01500, 02526], lr: 0.000100, loss: 0.6082, CELoss: 0.6082, 
2022-10-20 11:00:52 - train: epoch 0044, iter [01600, 02526], lr: 0.000100, loss: 1.0233, CELoss: 1.0233, 
2022-10-20 11:02:17 - train: epoch 0044, iter [01700, 02526], lr: 0.000100, loss: 0.8835, CELoss: 0.8835, 
2022-10-20 11:03:42 - train: epoch 0044, iter [01800, 02526], lr: 0.000100, loss: 0.8749, CELoss: 0.8749, 
2022-10-20 11:05:07 - train: epoch 0044, iter [01900, 02526], lr: 0.000100, loss: 1.3197, CELoss: 1.3197, 
2022-10-20 11:06:32 - train: epoch 0044, iter [02000, 02526], lr: 0.000100, loss: 0.8529, CELoss: 0.8529, 
2022-10-20 11:07:57 - train: epoch 0044, iter [02100, 02526], lr: 0.000100, loss: 1.4226, CELoss: 1.4226, 
2022-10-20 11:09:23 - train: epoch 0044, iter [02200, 02526], lr: 0.000100, loss: 0.9615, CELoss: 0.9615, 
2022-10-20 11:10:48 - train: epoch 0044, iter [02300, 02526], lr: 0.000100, loss: 0.9471, CELoss: 0.9471, 
2022-10-20 11:12:13 - train: epoch 0044, iter [02400, 02526], lr: 0.000100, loss: 0.6197, CELoss: 0.6197, 
2022-10-20 11:13:39 - train: epoch 0044, iter [02500, 02526], lr: 0.000100, loss: 0.5450, CELoss: 0.5450, 
2022-10-20 11:14:02 - train: epoch 044, train_loss: 0.8720
2022-10-20 11:14:03 - until epoch: 044, best_metric: 28.793%
2022-10-20 11:14:03 - epoch 045 lr: 0.000100
2022-10-20 11:15:30 - train: epoch 0045, iter [00100, 02526], lr: 0.000100, loss: 0.7970, CELoss: 0.7970, 
2022-10-20 11:16:55 - train: epoch 0045, iter [00200, 02526], lr: 0.000100, loss: 0.8462, CELoss: 0.8462, 
2022-10-20 11:18:21 - train: epoch 0045, iter [00300, 02526], lr: 0.000100, loss: 1.0924, CELoss: 1.0924, 
2022-10-20 11:19:46 - train: epoch 0045, iter [00400, 02526], lr: 0.000100, loss: 0.7819, CELoss: 0.7819, 
2022-10-20 11:21:11 - train: epoch 0045, iter [00500, 02526], lr: 0.000100, loss: 0.8918, CELoss: 0.8918, 
2022-10-20 11:22:36 - train: epoch 0045, iter [00600, 02526], lr: 0.000100, loss: 0.8799, CELoss: 0.8799, 
2022-10-20 11:24:01 - train: epoch 0045, iter [00700, 02526], lr: 0.000100, loss: 0.8083, CELoss: 0.8083, 
2022-10-20 11:25:26 - train: epoch 0045, iter [00800, 02526], lr: 0.000100, loss: 0.9462, CELoss: 0.9462, 
2022-10-20 11:26:51 - train: epoch 0045, iter [00900, 02526], lr: 0.000100, loss: 0.7964, CELoss: 0.7964, 
2022-10-20 11:28:16 - train: epoch 0045, iter [01000, 02526], lr: 0.000100, loss: 1.0157, CELoss: 1.0157, 
2022-10-20 11:29:41 - train: epoch 0045, iter [01100, 02526], lr: 0.000100, loss: 1.1148, CELoss: 1.1148, 
2022-10-20 11:31:06 - train: epoch 0045, iter [01200, 02526], lr: 0.000100, loss: 0.8360, CELoss: 0.8360, 
2022-10-20 11:32:31 - train: epoch 0045, iter [01300, 02526], lr: 0.000100, loss: 0.8105, CELoss: 0.8105, 
2022-10-20 11:33:56 - train: epoch 0045, iter [01400, 02526], lr: 0.000100, loss: 0.5541, CELoss: 0.5541, 
2022-10-20 11:35:20 - train: epoch 0045, iter [01500, 02526], lr: 0.000100, loss: 1.7714, CELoss: 1.7714, 
2022-10-20 11:36:45 - train: epoch 0045, iter [01600, 02526], lr: 0.000100, loss: 0.7840, CELoss: 0.7840, 
2022-10-20 11:38:10 - train: epoch 0045, iter [01700, 02526], lr: 0.000100, loss: 0.7282, CELoss: 0.7282, 
2022-10-20 11:39:35 - train: epoch 0045, iter [01800, 02526], lr: 0.000100, loss: 1.1990, CELoss: 1.1990, 
2022-10-20 11:41:00 - train: epoch 0045, iter [01900, 02526], lr: 0.000100, loss: 0.7621, CELoss: 0.7621, 
2022-10-20 11:42:25 - train: epoch 0045, iter [02000, 02526], lr: 0.000100, loss: 1.0880, CELoss: 1.0880, 
2022-10-20 11:43:50 - train: epoch 0045, iter [02100, 02526], lr: 0.000100, loss: 1.2046, CELoss: 1.2046, 
2022-10-20 11:45:14 - train: epoch 0045, iter [02200, 02526], lr: 0.000100, loss: 0.8797, CELoss: 0.8797, 
2022-10-20 11:46:39 - train: epoch 0045, iter [02300, 02526], lr: 0.000100, loss: 0.9716, CELoss: 0.9716, 
2022-10-20 11:48:03 - train: epoch 0045, iter [02400, 02526], lr: 0.000100, loss: 0.6726, CELoss: 0.6726, 
2022-10-20 11:49:29 - train: epoch 0045, iter [02500, 02526], lr: 0.000100, loss: 1.0808, CELoss: 1.0808, 
2022-10-20 11:49:52 - train: epoch 045, train_loss: 0.8668
2022-10-20 11:52:39 - eval: epoch: 045
test_loss: 0.9906626330018043
per_image_load_time: 0.998ms
per_image_inference_time: 76.645ms
exist_num_class: 150.0
mean_precision: 49.44163450522432
mean_recall: 42.745479064380255
mean_iou: 29.32501712358343
mean_dice: 41.93667634395618

2022-10-20 11:52:39 - until epoch: 045, best_metric: 29.325%
2022-10-20 11:52:39 - epoch 046 lr: 0.000100
2022-10-20 11:54:06 - train: epoch 0046, iter [00100, 02526], lr: 0.000100, loss: 1.3470, CELoss: 1.3470, 
2022-10-20 11:55:31 - train: epoch 0046, iter [00200, 02526], lr: 0.000100, loss: 0.6366, CELoss: 0.6366, 
2022-10-20 11:56:56 - train: epoch 0046, iter [00300, 02526], lr: 0.000100, loss: 0.6121, CELoss: 0.6121, 
2022-10-20 11:58:21 - train: epoch 0046, iter [00400, 02526], lr: 0.000100, loss: 0.8901, CELoss: 0.8901, 
2022-10-20 11:59:46 - train: epoch 0046, iter [00500, 02526], lr: 0.000100, loss: 0.6084, CELoss: 0.6084, 
2022-10-20 12:01:11 - train: epoch 0046, iter [00600, 02526], lr: 0.000100, loss: 0.7235, CELoss: 0.7235, 
2022-10-20 12:02:36 - train: epoch 0046, iter [00700, 02526], lr: 0.000100, loss: 0.8183, CELoss: 0.8183, 
2022-10-20 12:04:01 - train: epoch 0046, iter [00800, 02526], lr: 0.000100, loss: 0.9793, CELoss: 0.9793, 
2022-10-20 12:05:26 - train: epoch 0046, iter [00900, 02526], lr: 0.000100, loss: 0.6769, CELoss: 0.6769, 
2022-10-20 12:06:51 - train: epoch 0046, iter [01000, 02526], lr: 0.000100, loss: 1.0017, CELoss: 1.0017, 
2022-10-20 12:08:16 - train: epoch 0046, iter [01100, 02526], lr: 0.000100, loss: 0.8040, CELoss: 0.8040, 
2022-10-20 12:09:41 - train: epoch 0046, iter [01200, 02526], lr: 0.000100, loss: 0.7665, CELoss: 0.7665, 
2022-10-20 12:11:06 - train: epoch 0046, iter [01300, 02526], lr: 0.000100, loss: 0.4789, CELoss: 0.4789, 
2022-10-20 12:12:30 - train: epoch 0046, iter [01400, 02526], lr: 0.000100, loss: 0.6450, CELoss: 0.6450, 
2022-10-20 12:13:55 - train: epoch 0046, iter [01500, 02526], lr: 0.000100, loss: 0.5908, CELoss: 0.5908, 
2022-10-20 12:15:20 - train: epoch 0046, iter [01600, 02526], lr: 0.000100, loss: 0.8032, CELoss: 0.8032, 
2022-10-20 12:16:44 - train: epoch 0046, iter [01700, 02526], lr: 0.000100, loss: 0.6442, CELoss: 0.6442, 
2022-10-20 12:18:10 - train: epoch 0046, iter [01800, 02526], lr: 0.000100, loss: 0.8825, CELoss: 0.8825, 
2022-10-20 12:19:34 - train: epoch 0046, iter [01900, 02526], lr: 0.000100, loss: 0.7005, CELoss: 0.7005, 
2022-10-20 12:20:59 - train: epoch 0046, iter [02000, 02526], lr: 0.000100, loss: 1.0081, CELoss: 1.0081, 
2022-10-20 12:22:23 - train: epoch 0046, iter [02100, 02526], lr: 0.000100, loss: 0.9359, CELoss: 0.9359, 
2022-10-20 12:23:48 - train: epoch 0046, iter [02200, 02526], lr: 0.000100, loss: 0.9360, CELoss: 0.9360, 
2022-10-20 12:25:13 - train: epoch 0046, iter [02300, 02526], lr: 0.000100, loss: 0.8584, CELoss: 0.8584, 
2022-10-20 12:26:38 - train: epoch 0046, iter [02400, 02526], lr: 0.000100, loss: 0.6778, CELoss: 0.6778, 
2022-10-20 12:28:03 - train: epoch 0046, iter [02500, 02526], lr: 0.000100, loss: 0.4491, CELoss: 0.4491, 
2022-10-20 12:28:25 - train: epoch 046, train_loss: 0.8567
2022-10-20 12:28:26 - until epoch: 046, best_metric: 29.325%
2022-10-20 12:28:26 - epoch 047 lr: 0.000100
2022-10-20 12:29:53 - train: epoch 0047, iter [00100, 02526], lr: 0.000100, loss: 1.2141, CELoss: 1.2141, 
2022-10-20 12:31:18 - train: epoch 0047, iter [00200, 02526], lr: 0.000100, loss: 0.9323, CELoss: 0.9323, 
2022-10-20 12:32:43 - train: epoch 0047, iter [00300, 02526], lr: 0.000100, loss: 0.5645, CELoss: 0.5645, 
2022-10-20 12:34:08 - train: epoch 0047, iter [00400, 02526], lr: 0.000100, loss: 0.6237, CELoss: 0.6237, 
2022-10-20 12:35:33 - train: epoch 0047, iter [00500, 02526], lr: 0.000100, loss: 1.2985, CELoss: 1.2985, 
2022-10-20 12:36:58 - train: epoch 0047, iter [00600, 02526], lr: 0.000100, loss: 1.0313, CELoss: 1.0313, 
2022-10-20 12:38:22 - train: epoch 0047, iter [00700, 02526], lr: 0.000100, loss: 0.8589, CELoss: 0.8589, 
2022-10-20 12:39:48 - train: epoch 0047, iter [00800, 02526], lr: 0.000100, loss: 0.7864, CELoss: 0.7864, 
2022-10-20 12:41:13 - train: epoch 0047, iter [00900, 02526], lr: 0.000100, loss: 0.6067, CELoss: 0.6067, 
2022-10-20 12:42:37 - train: epoch 0047, iter [01000, 02526], lr: 0.000100, loss: 0.8138, CELoss: 0.8138, 
2022-10-20 12:44:02 - train: epoch 0047, iter [01100, 02526], lr: 0.000100, loss: 0.4686, CELoss: 0.4686, 
2022-10-20 12:45:27 - train: epoch 0047, iter [01200, 02526], lr: 0.000100, loss: 0.8078, CELoss: 0.8078, 
2022-10-20 12:46:52 - train: epoch 0047, iter [01300, 02526], lr: 0.000100, loss: 1.3664, CELoss: 1.3664, 
2022-10-20 12:48:17 - train: epoch 0047, iter [01400, 02526], lr: 0.000100, loss: 1.0000, CELoss: 1.0000, 
2022-10-20 12:49:42 - train: epoch 0047, iter [01500, 02526], lr: 0.000100, loss: 0.8981, CELoss: 0.8981, 
2022-10-20 12:51:07 - train: epoch 0047, iter [01600, 02526], lr: 0.000100, loss: 0.9169, CELoss: 0.9169, 
2022-10-20 12:52:32 - train: epoch 0047, iter [01700, 02526], lr: 0.000100, loss: 0.6818, CELoss: 0.6818, 
2022-10-20 12:53:57 - train: epoch 0047, iter [01800, 02526], lr: 0.000100, loss: 1.1061, CELoss: 1.1061, 
2022-10-20 12:55:22 - train: epoch 0047, iter [01900, 02526], lr: 0.000100, loss: 0.5165, CELoss: 0.5165, 
2022-10-20 12:56:48 - train: epoch 0047, iter [02000, 02526], lr: 0.000100, loss: 0.8159, CELoss: 0.8159, 
2022-10-20 12:58:13 - train: epoch 0047, iter [02100, 02526], lr: 0.000100, loss: 0.5826, CELoss: 0.5826, 
2022-10-20 12:59:38 - train: epoch 0047, iter [02200, 02526], lr: 0.000100, loss: 0.7752, CELoss: 0.7752, 
2022-10-20 13:01:03 - train: epoch 0047, iter [02300, 02526], lr: 0.000100, loss: 0.5615, CELoss: 0.5615, 
2022-10-20 13:02:28 - train: epoch 0047, iter [02400, 02526], lr: 0.000100, loss: 0.9995, CELoss: 0.9995, 
2022-10-20 13:03:53 - train: epoch 0047, iter [02500, 02526], lr: 0.000100, loss: 1.1620, CELoss: 1.1620, 
2022-10-20 13:04:17 - train: epoch 047, train_loss: 0.8508
2022-10-20 13:04:17 - until epoch: 047, best_metric: 29.325%
2022-10-20 13:04:17 - epoch 048 lr: 0.000100
2022-10-20 13:05:45 - train: epoch 0048, iter [00100, 02526], lr: 0.000100, loss: 0.7111, CELoss: 0.7111, 
2022-10-20 13:07:10 - train: epoch 0048, iter [00200, 02526], lr: 0.000100, loss: 0.6591, CELoss: 0.6591, 
2022-10-20 13:08:35 - train: epoch 0048, iter [00300, 02526], lr: 0.000100, loss: 1.0229, CELoss: 1.0229, 
2022-10-20 13:10:00 - train: epoch 0048, iter [00400, 02526], lr: 0.000100, loss: 0.8256, CELoss: 0.8256, 
2022-10-20 13:11:24 - train: epoch 0048, iter [00500, 02526], lr: 0.000100, loss: 0.6416, CELoss: 0.6416, 
2022-10-20 13:12:49 - train: epoch 0048, iter [00600, 02526], lr: 0.000100, loss: 0.8526, CELoss: 0.8526, 
2022-10-20 13:14:14 - train: epoch 0048, iter [00700, 02526], lr: 0.000100, loss: 0.9216, CELoss: 0.9216, 
2022-10-20 13:15:38 - train: epoch 0048, iter [00800, 02526], lr: 0.000100, loss: 1.1476, CELoss: 1.1476, 
2022-10-20 13:17:03 - train: epoch 0048, iter [00900, 02526], lr: 0.000100, loss: 0.7985, CELoss: 0.7985, 
2022-10-20 13:18:28 - train: epoch 0048, iter [01000, 02526], lr: 0.000100, loss: 0.6291, CELoss: 0.6291, 
2022-10-20 13:19:53 - train: epoch 0048, iter [01100, 02526], lr: 0.000100, loss: 0.8678, CELoss: 0.8678, 
2022-10-20 13:21:18 - train: epoch 0048, iter [01200, 02526], lr: 0.000100, loss: 1.2501, CELoss: 1.2501, 
2022-10-20 13:22:43 - train: epoch 0048, iter [01300, 02526], lr: 0.000100, loss: 0.8642, CELoss: 0.8642, 
2022-10-20 13:24:07 - train: epoch 0048, iter [01400, 02526], lr: 0.000100, loss: 1.0547, CELoss: 1.0547, 
2022-10-20 13:25:33 - train: epoch 0048, iter [01500, 02526], lr: 0.000100, loss: 1.1894, CELoss: 1.1894, 
2022-10-20 13:26:57 - train: epoch 0048, iter [01600, 02526], lr: 0.000100, loss: 0.7824, CELoss: 0.7824, 
2022-10-20 13:28:22 - train: epoch 0048, iter [01700, 02526], lr: 0.000100, loss: 0.6303, CELoss: 0.6303, 
2022-10-20 13:29:47 - train: epoch 0048, iter [01800, 02526], lr: 0.000100, loss: 0.7178, CELoss: 0.7178, 
2022-10-20 13:31:12 - train: epoch 0048, iter [01900, 02526], lr: 0.000100, loss: 1.2477, CELoss: 1.2477, 
2022-10-20 13:32:38 - train: epoch 0048, iter [02000, 02526], lr: 0.000100, loss: 1.1977, CELoss: 1.1977, 
2022-10-20 13:34:02 - train: epoch 0048, iter [02100, 02526], lr: 0.000100, loss: 0.8364, CELoss: 0.8364, 
2022-10-20 13:35:27 - train: epoch 0048, iter [02200, 02526], lr: 0.000100, loss: 0.6633, CELoss: 0.6633, 
2022-10-20 13:36:53 - train: epoch 0048, iter [02300, 02526], lr: 0.000100, loss: 0.7280, CELoss: 0.7280, 
2022-10-20 13:38:17 - train: epoch 0048, iter [02400, 02526], lr: 0.000100, loss: 1.1157, CELoss: 1.1157, 
2022-10-20 13:39:43 - train: epoch 0048, iter [02500, 02526], lr: 0.000100, loss: 1.3867, CELoss: 1.3867, 
2022-10-20 13:40:06 - train: epoch 048, train_loss: 0.8488
2022-10-20 13:40:07 - until epoch: 048, best_metric: 29.325%
2022-10-20 13:40:07 - epoch 049 lr: 0.000100
2022-10-20 13:41:35 - train: epoch 0049, iter [00100, 02526], lr: 0.000100, loss: 0.7009, CELoss: 0.7009, 
2022-10-20 13:43:00 - train: epoch 0049, iter [00200, 02526], lr: 0.000100, loss: 0.8486, CELoss: 0.8486, 
2022-10-20 13:44:24 - train: epoch 0049, iter [00300, 02526], lr: 0.000100, loss: 0.6420, CELoss: 0.6420, 
2022-10-20 13:45:49 - train: epoch 0049, iter [00400, 02526], lr: 0.000100, loss: 1.0887, CELoss: 1.0887, 
2022-10-20 13:47:15 - train: epoch 0049, iter [00500, 02526], lr: 0.000100, loss: 0.7889, CELoss: 0.7889, 
2022-10-20 13:48:40 - train: epoch 0049, iter [00600, 02526], lr: 0.000100, loss: 0.7050, CELoss: 0.7050, 
2022-10-20 13:50:05 - train: epoch 0049, iter [00700, 02526], lr: 0.000100, loss: 0.8033, CELoss: 0.8033, 
2022-10-20 13:51:30 - train: epoch 0049, iter [00800, 02526], lr: 0.000100, loss: 0.7738, CELoss: 0.7738, 
2022-10-20 13:52:55 - train: epoch 0049, iter [00900, 02526], lr: 0.000100, loss: 0.7414, CELoss: 0.7414, 
2022-10-20 13:54:20 - train: epoch 0049, iter [01000, 02526], lr: 0.000100, loss: 0.6471, CELoss: 0.6471, 
2022-10-20 13:55:45 - train: epoch 0049, iter [01100, 02526], lr: 0.000100, loss: 0.7480, CELoss: 0.7480, 
2022-10-20 13:57:10 - train: epoch 0049, iter [01200, 02526], lr: 0.000100, loss: 1.0576, CELoss: 1.0576, 
2022-10-20 13:58:35 - train: epoch 0049, iter [01300, 02526], lr: 0.000100, loss: 1.8845, CELoss: 1.8845, 
2022-10-20 14:00:01 - train: epoch 0049, iter [01400, 02526], lr: 0.000100, loss: 0.7068, CELoss: 0.7068, 
2022-10-20 14:01:26 - train: epoch 0049, iter [01500, 02526], lr: 0.000100, loss: 0.6265, CELoss: 0.6265, 
2022-10-20 14:02:51 - train: epoch 0049, iter [01600, 02526], lr: 0.000100, loss: 0.8247, CELoss: 0.8247, 
2022-10-20 14:04:17 - train: epoch 0049, iter [01700, 02526], lr: 0.000100, loss: 1.0856, CELoss: 1.0856, 
2022-10-20 14:05:42 - train: epoch 0049, iter [01800, 02526], lr: 0.000100, loss: 0.6423, CELoss: 0.6423, 
2022-10-20 14:07:08 - train: epoch 0049, iter [01900, 02526], lr: 0.000100, loss: 0.5364, CELoss: 0.5364, 
2022-10-20 14:08:34 - train: epoch 0049, iter [02000, 02526], lr: 0.000100, loss: 0.7969, CELoss: 0.7969, 
2022-10-20 14:10:00 - train: epoch 0049, iter [02100, 02526], lr: 0.000100, loss: 0.8010, CELoss: 0.8010, 
2022-10-20 14:11:25 - train: epoch 0049, iter [02200, 02526], lr: 0.000100, loss: 0.9301, CELoss: 0.9301, 
2022-10-20 14:12:50 - train: epoch 0049, iter [02300, 02526], lr: 0.000100, loss: 0.7016, CELoss: 0.7016, 
2022-10-20 14:14:15 - train: epoch 0049, iter [02400, 02526], lr: 0.000100, loss: 0.5787, CELoss: 0.5787, 
2022-10-20 14:15:40 - train: epoch 0049, iter [02500, 02526], lr: 0.000100, loss: 0.9173, CELoss: 0.9173, 
2022-10-20 14:16:04 - train: epoch 049, train_loss: 0.8366
2022-10-20 14:16:05 - until epoch: 049, best_metric: 29.325%
2022-10-20 14:16:05 - epoch 050 lr: 0.000100
2022-10-20 14:17:34 - train: epoch 0050, iter [00100, 02526], lr: 0.000100, loss: 0.7815, CELoss: 0.7815, 
2022-10-20 14:18:59 - train: epoch 0050, iter [00200, 02526], lr: 0.000100, loss: 0.6892, CELoss: 0.6892, 
2022-10-20 14:20:25 - train: epoch 0050, iter [00300, 02526], lr: 0.000100, loss: 0.8291, CELoss: 0.8291, 
2022-10-20 14:21:51 - train: epoch 0050, iter [00400, 02526], lr: 0.000100, loss: 1.2358, CELoss: 1.2358, 
2022-10-20 14:23:16 - train: epoch 0050, iter [00500, 02526], lr: 0.000100, loss: 0.9204, CELoss: 0.9204, 
2022-10-20 14:24:42 - train: epoch 0050, iter [00600, 02526], lr: 0.000100, loss: 0.9277, CELoss: 0.9277, 
2022-10-20 14:26:08 - train: epoch 0050, iter [00700, 02526], lr: 0.000100, loss: 1.0081, CELoss: 1.0081, 
2022-10-20 14:27:34 - train: epoch 0050, iter [00800, 02526], lr: 0.000100, loss: 1.3486, CELoss: 1.3486, 
2022-10-20 14:28:59 - train: epoch 0050, iter [00900, 02526], lr: 0.000100, loss: 0.6425, CELoss: 0.6425, 
2022-10-20 14:30:25 - train: epoch 0050, iter [01000, 02526], lr: 0.000100, loss: 0.9060, CELoss: 0.9060, 
2022-10-20 14:31:50 - train: epoch 0050, iter [01100, 02526], lr: 0.000100, loss: 0.7915, CELoss: 0.7915, 
2022-10-20 14:33:15 - train: epoch 0050, iter [01200, 02526], lr: 0.000100, loss: 0.8014, CELoss: 0.8014, 
2022-10-20 14:34:41 - train: epoch 0050, iter [01300, 02526], lr: 0.000100, loss: 1.0430, CELoss: 1.0430, 
2022-10-20 14:36:07 - train: epoch 0050, iter [01400, 02526], lr: 0.000100, loss: 0.6082, CELoss: 0.6082, 
2022-10-20 14:37:32 - train: epoch 0050, iter [01500, 02526], lr: 0.000100, loss: 1.2744, CELoss: 1.2744, 
2022-10-20 14:38:58 - train: epoch 0050, iter [01600, 02526], lr: 0.000100, loss: 0.7152, CELoss: 0.7152, 
2022-10-20 14:40:23 - train: epoch 0050, iter [01700, 02526], lr: 0.000100, loss: 0.8038, CELoss: 0.8038, 
2022-10-20 14:41:49 - train: epoch 0050, iter [01800, 02526], lr: 0.000100, loss: 0.5722, CELoss: 0.5722, 
2022-10-20 14:43:14 - train: epoch 0050, iter [01900, 02526], lr: 0.000100, loss: 0.9364, CELoss: 0.9364, 
2022-10-20 14:44:39 - train: epoch 0050, iter [02000, 02526], lr: 0.000100, loss: 0.8876, CELoss: 0.8876, 
2022-10-20 14:46:04 - train: epoch 0050, iter [02100, 02526], lr: 0.000100, loss: 0.9832, CELoss: 0.9832, 
2022-10-20 14:47:30 - train: epoch 0050, iter [02200, 02526], lr: 0.000100, loss: 0.9994, CELoss: 0.9994, 
2022-10-20 14:48:55 - train: epoch 0050, iter [02300, 02526], lr: 0.000100, loss: 0.6955, CELoss: 0.6955, 
2022-10-20 14:50:20 - train: epoch 0050, iter [02400, 02526], lr: 0.000100, loss: 0.8939, CELoss: 0.8939, 
2022-10-20 14:51:46 - train: epoch 0050, iter [02500, 02526], lr: 0.000100, loss: 0.8209, CELoss: 0.8209, 
2022-10-20 14:52:09 - train: epoch 050, train_loss: 0.8376
2022-10-20 14:55:05 - eval: epoch: 050
test_loss: 0.9710555060207844
per_image_load_time: 1.114ms
per_image_inference_time: 77.134ms
exist_num_class: 150.0
mean_precision: 48.44305943488013
mean_recall: 44.086851653691966
mean_iou: 29.747607695100506
mean_dice: 42.5453915596222

2022-10-20 14:55:06 - until epoch: 050, best_metric: 29.748%
2022-10-20 14:55:06 - epoch 051 lr: 0.000100
2022-10-20 14:56:34 - train: epoch 0051, iter [00100, 02526], lr: 0.000100, loss: 0.9936, CELoss: 0.9936, 
2022-10-20 14:57:59 - train: epoch 0051, iter [00200, 02526], lr: 0.000100, loss: 0.5145, CELoss: 0.5145, 
2022-10-20 14:59:25 - train: epoch 0051, iter [00300, 02526], lr: 0.000100, loss: 0.4808, CELoss: 0.4808, 
2022-10-20 15:00:50 - train: epoch 0051, iter [00400, 02526], lr: 0.000100, loss: 0.7747, CELoss: 0.7747, 
2022-10-20 15:02:15 - train: epoch 0051, iter [00500, 02526], lr: 0.000100, loss: 0.4206, CELoss: 0.4206, 
2022-10-20 15:03:41 - train: epoch 0051, iter [00600, 02526], lr: 0.000100, loss: 1.0725, CELoss: 1.0725, 
2022-10-20 15:05:06 - train: epoch 0051, iter [00700, 02526], lr: 0.000100, loss: 0.3997, CELoss: 0.3997, 
2022-10-20 15:06:31 - train: epoch 0051, iter [00800, 02526], lr: 0.000100, loss: 1.1471, CELoss: 1.1471, 
2022-10-20 15:07:56 - train: epoch 0051, iter [00900, 02526], lr: 0.000100, loss: 0.6970, CELoss: 0.6970, 
2022-10-20 15:09:22 - train: epoch 0051, iter [01000, 02526], lr: 0.000100, loss: 0.9391, CELoss: 0.9391, 
2022-10-20 15:10:47 - train: epoch 0051, iter [01100, 02526], lr: 0.000100, loss: 0.6975, CELoss: 0.6975, 
2022-10-20 15:12:12 - train: epoch 0051, iter [01200, 02526], lr: 0.000100, loss: 0.5860, CELoss: 0.5860, 
2022-10-20 15:13:37 - train: epoch 0051, iter [01300, 02526], lr: 0.000100, loss: 1.3594, CELoss: 1.3594, 
2022-10-20 15:15:03 - train: epoch 0051, iter [01400, 02526], lr: 0.000100, loss: 0.5717, CELoss: 0.5717, 
2022-10-20 15:16:29 - train: epoch 0051, iter [01500, 02526], lr: 0.000100, loss: 0.3261, CELoss: 0.3261, 
2022-10-20 15:17:55 - train: epoch 0051, iter [01600, 02526], lr: 0.000100, loss: 0.6698, CELoss: 0.6698, 
2022-10-20 15:19:20 - train: epoch 0051, iter [01700, 02526], lr: 0.000100, loss: 0.8091, CELoss: 0.8091, 
2022-10-20 15:20:46 - train: epoch 0051, iter [01800, 02526], lr: 0.000100, loss: 0.8413, CELoss: 0.8413, 
2022-10-20 15:22:12 - train: epoch 0051, iter [01900, 02526], lr: 0.000100, loss: 0.7547, CELoss: 0.7547, 
2022-10-20 15:23:37 - train: epoch 0051, iter [02000, 02526], lr: 0.000100, loss: 0.6690, CELoss: 0.6690, 
2022-10-20 15:25:02 - train: epoch 0051, iter [02100, 02526], lr: 0.000100, loss: 1.0941, CELoss: 1.0941, 
2022-10-20 15:26:28 - train: epoch 0051, iter [02200, 02526], lr: 0.000100, loss: 0.6006, CELoss: 0.6006, 
2022-10-20 15:27:53 - train: epoch 0051, iter [02300, 02526], lr: 0.000100, loss: 0.8781, CELoss: 0.8781, 
2022-10-20 15:29:18 - train: epoch 0051, iter [02400, 02526], lr: 0.000100, loss: 0.8285, CELoss: 0.8285, 
2022-10-20 15:30:44 - train: epoch 0051, iter [02500, 02526], lr: 0.000100, loss: 0.8251, CELoss: 0.8251, 
2022-10-20 15:31:07 - train: epoch 051, train_loss: 0.8387
2022-10-20 15:31:08 - until epoch: 051, best_metric: 29.748%
2022-10-20 15:31:08 - epoch 052 lr: 0.000100
2022-10-20 15:32:36 - train: epoch 0052, iter [00100, 02526], lr: 0.000100, loss: 0.8008, CELoss: 0.8008, 
2022-10-20 15:34:01 - train: epoch 0052, iter [00200, 02526], lr: 0.000100, loss: 0.9077, CELoss: 0.9077, 
2022-10-20 15:35:27 - train: epoch 0052, iter [00300, 02526], lr: 0.000100, loss: 0.4965, CELoss: 0.4965, 
2022-10-20 15:36:53 - train: epoch 0052, iter [00400, 02526], lr: 0.000100, loss: 0.8432, CELoss: 0.8432, 
2022-10-20 15:38:18 - train: epoch 0052, iter [00500, 02526], lr: 0.000100, loss: 0.5467, CELoss: 0.5467, 
2022-10-20 15:39:44 - train: epoch 0052, iter [00600, 02526], lr: 0.000100, loss: 0.6795, CELoss: 0.6795, 
2022-10-20 15:41:09 - train: epoch 0052, iter [00700, 02526], lr: 0.000100, loss: 0.7252, CELoss: 0.7252, 
2022-10-20 15:42:35 - train: epoch 0052, iter [00800, 02526], lr: 0.000100, loss: 0.7697, CELoss: 0.7697, 
2022-10-20 15:44:00 - train: epoch 0052, iter [00900, 02526], lr: 0.000100, loss: 1.3756, CELoss: 1.3756, 
2022-10-20 15:45:26 - train: epoch 0052, iter [01000, 02526], lr: 0.000100, loss: 1.1289, CELoss: 1.1289, 
2022-10-20 15:46:50 - train: epoch 0052, iter [01100, 02526], lr: 0.000100, loss: 0.4084, CELoss: 0.4084, 
2022-10-20 15:48:16 - train: epoch 0052, iter [01200, 02526], lr: 0.000100, loss: 0.4648, CELoss: 0.4648, 
2022-10-20 15:49:41 - train: epoch 0052, iter [01300, 02526], lr: 0.000100, loss: 0.8964, CELoss: 0.8964, 
2022-10-20 15:51:07 - train: epoch 0052, iter [01400, 02526], lr: 0.000100, loss: 0.6437, CELoss: 0.6437, 
2022-10-20 15:52:32 - train: epoch 0052, iter [01500, 02526], lr: 0.000100, loss: 0.8419, CELoss: 0.8419, 
2022-10-20 15:53:57 - train: epoch 0052, iter [01600, 02526], lr: 0.000100, loss: 0.7760, CELoss: 0.7760, 
2022-10-20 15:55:23 - train: epoch 0052, iter [01700, 02526], lr: 0.000100, loss: 0.8255, CELoss: 0.8255, 
2022-10-20 15:56:49 - train: epoch 0052, iter [01800, 02526], lr: 0.000100, loss: 0.7651, CELoss: 0.7651, 
2022-10-20 15:58:14 - train: epoch 0052, iter [01900, 02526], lr: 0.000100, loss: 1.2719, CELoss: 1.2719, 
2022-10-20 15:59:40 - train: epoch 0052, iter [02000, 02526], lr: 0.000100, loss: 0.6246, CELoss: 0.6246, 
2022-10-20 16:01:05 - train: epoch 0052, iter [02100, 02526], lr: 0.000100, loss: 0.5218, CELoss: 0.5218, 
2022-10-20 16:02:31 - train: epoch 0052, iter [02200, 02526], lr: 0.000100, loss: 0.9325, CELoss: 0.9325, 
2022-10-20 16:03:56 - train: epoch 0052, iter [02300, 02526], lr: 0.000100, loss: 0.8506, CELoss: 0.8506, 
2022-10-20 16:05:21 - train: epoch 0052, iter [02400, 02526], lr: 0.000100, loss: 0.8918, CELoss: 0.8918, 
2022-10-20 16:06:47 - train: epoch 0052, iter [02500, 02526], lr: 0.000100, loss: 0.6276, CELoss: 0.6276, 
2022-10-20 16:07:10 - train: epoch 052, train_loss: 0.8248
2022-10-20 16:07:11 - until epoch: 052, best_metric: 29.748%
2022-10-20 16:07:11 - epoch 053 lr: 0.000100
2022-10-20 16:08:39 - train: epoch 0053, iter [00100, 02526], lr: 0.000100, loss: 1.4073, CELoss: 1.4073, 
2022-10-20 16:10:04 - train: epoch 0053, iter [00200, 02526], lr: 0.000100, loss: 0.8636, CELoss: 0.8636, 
2022-10-20 16:11:30 - train: epoch 0053, iter [00300, 02526], lr: 0.000100, loss: 0.9418, CELoss: 0.9418, 
2022-10-20 16:12:55 - train: epoch 0053, iter [00400, 02526], lr: 0.000100, loss: 0.5408, CELoss: 0.5408, 
2022-10-20 16:14:21 - train: epoch 0053, iter [00500, 02526], lr: 0.000100, loss: 0.8113, CELoss: 0.8113, 
2022-10-20 16:15:47 - train: epoch 0053, iter [00600, 02526], lr: 0.000100, loss: 0.4476, CELoss: 0.4476, 
2022-10-20 16:17:12 - train: epoch 0053, iter [00700, 02526], lr: 0.000100, loss: 0.7676, CELoss: 0.7676, 
2022-10-20 16:18:38 - train: epoch 0053, iter [00800, 02526], lr: 0.000100, loss: 1.0116, CELoss: 1.0116, 
2022-10-20 16:20:04 - train: epoch 0053, iter [00900, 02526], lr: 0.000100, loss: 0.8733, CELoss: 0.8733, 
2022-10-20 16:21:29 - train: epoch 0053, iter [01000, 02526], lr: 0.000100, loss: 0.7414, CELoss: 0.7414, 
2022-10-20 16:22:54 - train: epoch 0053, iter [01100, 02526], lr: 0.000100, loss: 0.6971, CELoss: 0.6971, 
2022-10-20 16:24:19 - train: epoch 0053, iter [01200, 02526], lr: 0.000100, loss: 0.8186, CELoss: 0.8186, 
2022-10-20 16:25:45 - train: epoch 0053, iter [01300, 02526], lr: 0.000100, loss: 0.4907, CELoss: 0.4907, 
2022-10-20 16:27:10 - train: epoch 0053, iter [01400, 02526], lr: 0.000100, loss: 0.5535, CELoss: 0.5535, 
2022-10-20 16:28:35 - train: epoch 0053, iter [01500, 02526], lr: 0.000100, loss: 0.6057, CELoss: 0.6057, 
2022-10-20 16:30:00 - train: epoch 0053, iter [01600, 02526], lr: 0.000100, loss: 0.6343, CELoss: 0.6343, 
2022-10-20 16:31:26 - train: epoch 0053, iter [01700, 02526], lr: 0.000100, loss: 0.7083, CELoss: 0.7083, 
2022-10-20 16:32:51 - train: epoch 0053, iter [01800, 02526], lr: 0.000100, loss: 0.4100, CELoss: 0.4100, 
2022-10-20 16:34:17 - train: epoch 0053, iter [01900, 02526], lr: 0.000100, loss: 1.0495, CELoss: 1.0495, 
2022-10-20 16:35:43 - train: epoch 0053, iter [02000, 02526], lr: 0.000100, loss: 0.8071, CELoss: 0.8071, 
2022-10-20 16:37:08 - train: epoch 0053, iter [02100, 02526], lr: 0.000100, loss: 0.6874, CELoss: 0.6874, 
2022-10-20 16:38:33 - train: epoch 0053, iter [02200, 02526], lr: 0.000100, loss: 0.4970, CELoss: 0.4970, 
2022-10-20 16:39:59 - train: epoch 0053, iter [02300, 02526], lr: 0.000100, loss: 0.4558, CELoss: 0.4558, 
2022-10-20 16:41:24 - train: epoch 0053, iter [02400, 02526], lr: 0.000100, loss: 0.7931, CELoss: 0.7931, 
2022-10-20 16:42:49 - train: epoch 0053, iter [02500, 02526], lr: 0.000100, loss: 1.1646, CELoss: 1.1646, 
2022-10-20 16:43:12 - train: epoch 053, train_loss: 0.8158
2022-10-20 16:43:13 - until epoch: 053, best_metric: 29.748%
2022-10-20 16:43:13 - epoch 054 lr: 0.000100
2022-10-20 16:44:41 - train: epoch 0054, iter [00100, 02526], lr: 0.000100, loss: 1.4090, CELoss: 1.4090, 
2022-10-20 16:46:06 - train: epoch 0054, iter [00200, 02526], lr: 0.000100, loss: 0.8875, CELoss: 0.8875, 
2022-10-20 16:47:32 - train: epoch 0054, iter [00300, 02526], lr: 0.000100, loss: 1.3598, CELoss: 1.3598, 
2022-10-20 16:48:57 - train: epoch 0054, iter [00400, 02526], lr: 0.000100, loss: 0.8573, CELoss: 0.8573, 
2022-10-20 16:50:23 - train: epoch 0054, iter [00500, 02526], lr: 0.000100, loss: 0.9329, CELoss: 0.9329, 
2022-10-20 16:51:49 - train: epoch 0054, iter [00600, 02526], lr: 0.000100, loss: 0.8734, CELoss: 0.8734, 
2022-10-20 16:53:14 - train: epoch 0054, iter [00700, 02526], lr: 0.000100, loss: 1.1617, CELoss: 1.1617, 
2022-10-20 16:54:40 - train: epoch 0054, iter [00800, 02526], lr: 0.000100, loss: 0.6361, CELoss: 0.6361, 
2022-10-20 16:56:05 - train: epoch 0054, iter [00900, 02526], lr: 0.000100, loss: 0.5578, CELoss: 0.5578, 
2022-10-20 16:57:31 - train: epoch 0054, iter [01000, 02526], lr: 0.000100, loss: 0.6797, CELoss: 0.6797, 
2022-10-20 16:58:56 - train: epoch 0054, iter [01100, 02526], lr: 0.000100, loss: 0.9373, CELoss: 0.9373, 
2022-10-20 17:00:21 - train: epoch 0054, iter [01200, 02526], lr: 0.000100, loss: 0.8824, CELoss: 0.8824, 
2022-10-20 17:01:47 - train: epoch 0054, iter [01300, 02526], lr: 0.000100, loss: 0.6789, CELoss: 0.6789, 
2022-10-20 17:03:12 - train: epoch 0054, iter [01400, 02526], lr: 0.000100, loss: 0.7410, CELoss: 0.7410, 
2022-10-20 17:04:38 - train: epoch 0054, iter [01500, 02526], lr: 0.000100, loss: 0.7094, CELoss: 0.7094, 
2022-10-20 17:06:03 - train: epoch 0054, iter [01600, 02526], lr: 0.000100, loss: 0.8108, CELoss: 0.8108, 
2022-10-20 17:07:28 - train: epoch 0054, iter [01700, 02526], lr: 0.000100, loss: 0.5610, CELoss: 0.5610, 
2022-10-20 17:08:54 - train: epoch 0054, iter [01800, 02526], lr: 0.000100, loss: 0.5650, CELoss: 0.5650, 
2022-10-20 17:10:19 - train: epoch 0054, iter [01900, 02526], lr: 0.000100, loss: 1.3160, CELoss: 1.3160, 
2022-10-20 17:11:45 - train: epoch 0054, iter [02000, 02526], lr: 0.000100, loss: 0.5714, CELoss: 0.5714, 
2022-10-20 17:13:10 - train: epoch 0054, iter [02100, 02526], lr: 0.000100, loss: 0.4329, CELoss: 0.4329, 
2022-10-20 17:14:36 - train: epoch 0054, iter [02200, 02526], lr: 0.000100, loss: 0.5284, CELoss: 0.5284, 
2022-10-20 17:16:02 - train: epoch 0054, iter [02300, 02526], lr: 0.000100, loss: 0.7638, CELoss: 0.7638, 
2022-10-20 17:17:26 - train: epoch 0054, iter [02400, 02526], lr: 0.000100, loss: 1.2454, CELoss: 1.2454, 
2022-10-20 17:18:52 - train: epoch 0054, iter [02500, 02526], lr: 0.000100, loss: 0.7360, CELoss: 0.7360, 
2022-10-20 17:19:15 - train: epoch 054, train_loss: 0.8124
2022-10-20 17:19:16 - until epoch: 054, best_metric: 29.748%
2022-10-20 17:19:16 - epoch 055 lr: 0.000100
2022-10-20 17:20:44 - train: epoch 0055, iter [00100, 02526], lr: 0.000100, loss: 0.9987, CELoss: 0.9987, 
2022-10-20 17:22:09 - train: epoch 0055, iter [00200, 02526], lr: 0.000100, loss: 0.9732, CELoss: 0.9732, 
2022-10-20 17:23:33 - train: epoch 0055, iter [00300, 02526], lr: 0.000100, loss: 1.2026, CELoss: 1.2026, 
2022-10-20 17:24:58 - train: epoch 0055, iter [00400, 02526], lr: 0.000100, loss: 1.0982, CELoss: 1.0982, 
2022-10-20 17:26:24 - train: epoch 0055, iter [00500, 02526], lr: 0.000100, loss: 0.6510, CELoss: 0.6510, 
2022-10-20 17:27:48 - train: epoch 0055, iter [00600, 02526], lr: 0.000100, loss: 1.0107, CELoss: 1.0107, 
2022-10-20 17:29:13 - train: epoch 0055, iter [00700, 02526], lr: 0.000100, loss: 0.5970, CELoss: 0.5970, 
2022-10-20 17:30:38 - train: epoch 0055, iter [00800, 02526], lr: 0.000100, loss: 0.7370, CELoss: 0.7370, 
2022-10-20 17:32:04 - train: epoch 0055, iter [00900, 02526], lr: 0.000100, loss: 0.8149, CELoss: 0.8149, 
2022-10-20 17:33:29 - train: epoch 0055, iter [01000, 02526], lr: 0.000100, loss: 0.9201, CELoss: 0.9201, 
2022-10-20 17:34:54 - train: epoch 0055, iter [01100, 02526], lr: 0.000100, loss: 0.7348, CELoss: 0.7348, 
2022-10-20 17:36:19 - train: epoch 0055, iter [01200, 02526], lr: 0.000100, loss: 0.7607, CELoss: 0.7607, 
2022-10-20 17:37:44 - train: epoch 0055, iter [01300, 02526], lr: 0.000100, loss: 0.8335, CELoss: 0.8335, 
2022-10-20 17:39:09 - train: epoch 0055, iter [01400, 02526], lr: 0.000100, loss: 0.6645, CELoss: 0.6645, 
2022-10-20 17:40:34 - train: epoch 0055, iter [01500, 02526], lr: 0.000100, loss: 0.9227, CELoss: 0.9227, 
2022-10-20 17:41:59 - train: epoch 0055, iter [01600, 02526], lr: 0.000100, loss: 0.7520, CELoss: 0.7520, 
2022-10-20 17:43:24 - train: epoch 0055, iter [01700, 02526], lr: 0.000100, loss: 0.5072, CELoss: 0.5072, 
2022-10-20 17:44:49 - train: epoch 0055, iter [01800, 02526], lr: 0.000100, loss: 1.0339, CELoss: 1.0339, 
2022-10-20 17:46:13 - train: epoch 0055, iter [01900, 02526], lr: 0.000100, loss: 0.5581, CELoss: 0.5581, 
2022-10-20 17:47:38 - train: epoch 0055, iter [02000, 02526], lr: 0.000100, loss: 0.8252, CELoss: 0.8252, 
2022-10-20 17:49:03 - train: epoch 0055, iter [02100, 02526], lr: 0.000100, loss: 0.7445, CELoss: 0.7445, 
2022-10-20 17:50:28 - train: epoch 0055, iter [02200, 02526], lr: 0.000100, loss: 0.6538, CELoss: 0.6538, 
2022-10-20 17:51:53 - train: epoch 0055, iter [02300, 02526], lr: 0.000100, loss: 1.2606, CELoss: 1.2606, 
2022-10-20 17:53:18 - train: epoch 0055, iter [02400, 02526], lr: 0.000100, loss: 0.8503, CELoss: 0.8503, 
2022-10-20 17:54:43 - train: epoch 0055, iter [02500, 02526], lr: 0.000100, loss: 0.4958, CELoss: 0.4958, 
2022-10-20 17:55:06 - train: epoch 055, train_loss: 0.8107
2022-10-20 17:57:53 - eval: epoch: 055
test_loss: 0.9902183822095394
per_image_load_time: 1.246ms
per_image_inference_time: 76.743ms
exist_num_class: 150.0
mean_precision: 47.673872642558
mean_recall: 45.12451496901113
mean_iou: 30.367785466078622
mean_dice: 43.2304234264646

2022-10-20 17:57:54 - until epoch: 055, best_metric: 30.368%
2022-10-20 17:57:54 - epoch 056 lr: 0.000100
2022-10-20 17:59:20 - train: epoch 0056, iter [00100, 02526], lr: 0.000100, loss: 0.4363, CELoss: 0.4363, 
2022-10-20 18:00:45 - train: epoch 0056, iter [00200, 02526], lr: 0.000100, loss: 0.7929, CELoss: 0.7929, 
2022-10-20 18:02:10 - train: epoch 0056, iter [00300, 02526], lr: 0.000100, loss: 0.6175, CELoss: 0.6175, 
2022-10-20 18:03:35 - train: epoch 0056, iter [00400, 02526], lr: 0.000100, loss: 0.5971, CELoss: 0.5971, 
2022-10-20 18:05:00 - train: epoch 0056, iter [00500, 02526], lr: 0.000100, loss: 0.8924, CELoss: 0.8924, 
2022-10-20 18:06:25 - train: epoch 0056, iter [00600, 02526], lr: 0.000100, loss: 1.0647, CELoss: 1.0647, 
2022-10-20 18:07:50 - train: epoch 0056, iter [00700, 02526], lr: 0.000100, loss: 0.9925, CELoss: 0.9925, 
2022-10-20 18:09:16 - train: epoch 0056, iter [00800, 02526], lr: 0.000100, loss: 0.3952, CELoss: 0.3952, 
2022-10-20 18:10:41 - train: epoch 0056, iter [00900, 02526], lr: 0.000100, loss: 0.6371, CELoss: 0.6371, 
2022-10-20 18:12:07 - train: epoch 0056, iter [01000, 02526], lr: 0.000100, loss: 0.9701, CELoss: 0.9701, 
2022-10-20 18:13:32 - train: epoch 0056, iter [01100, 02526], lr: 0.000100, loss: 1.0270, CELoss: 1.0270, 
2022-10-20 18:14:58 - train: epoch 0056, iter [01200, 02526], lr: 0.000100, loss: 0.6845, CELoss: 0.6845, 
2022-10-20 18:16:23 - train: epoch 0056, iter [01300, 02526], lr: 0.000100, loss: 0.8863, CELoss: 0.8863, 
2022-10-20 18:17:49 - train: epoch 0056, iter [01400, 02526], lr: 0.000100, loss: 0.7580, CELoss: 0.7580, 
2022-10-20 18:19:14 - train: epoch 0056, iter [01500, 02526], lr: 0.000100, loss: 0.6275, CELoss: 0.6275, 
2022-10-20 18:20:40 - train: epoch 0056, iter [01600, 02526], lr: 0.000100, loss: 1.0804, CELoss: 1.0804, 
2022-10-20 18:22:05 - train: epoch 0056, iter [01700, 02526], lr: 0.000100, loss: 1.0402, CELoss: 1.0402, 
2022-10-20 18:23:30 - train: epoch 0056, iter [01800, 02526], lr: 0.000100, loss: 0.4623, CELoss: 0.4623, 
2022-10-20 18:24:55 - train: epoch 0056, iter [01900, 02526], lr: 0.000100, loss: 1.2366, CELoss: 1.2366, 
2022-10-20 18:26:20 - train: epoch 0056, iter [02000, 02526], lr: 0.000100, loss: 0.5548, CELoss: 0.5548, 
2022-10-20 18:27:45 - train: epoch 0056, iter [02100, 02526], lr: 0.000100, loss: 0.6704, CELoss: 0.6704, 
2022-10-20 18:29:10 - train: epoch 0056, iter [02200, 02526], lr: 0.000100, loss: 0.8807, CELoss: 0.8807, 
2022-10-20 18:30:36 - train: epoch 0056, iter [02300, 02526], lr: 0.000100, loss: 0.6167, CELoss: 0.6167, 
2022-10-20 18:32:01 - train: epoch 0056, iter [02400, 02526], lr: 0.000100, loss: 1.0222, CELoss: 1.0222, 
2022-10-20 18:33:26 - train: epoch 0056, iter [02500, 02526], lr: 0.000100, loss: 0.5720, CELoss: 0.5720, 
2022-10-20 18:33:50 - train: epoch 056, train_loss: 0.8089
2022-10-20 18:33:50 - until epoch: 056, best_metric: 30.368%
2022-10-20 18:33:50 - epoch 057 lr: 0.000100
2022-10-20 18:35:18 - train: epoch 0057, iter [00100, 02526], lr: 0.000100, loss: 0.9369, CELoss: 0.9369, 
2022-10-20 18:36:43 - train: epoch 0057, iter [00200, 02526], lr: 0.000100, loss: 1.2008, CELoss: 1.2008, 
2022-10-20 18:38:09 - train: epoch 0057, iter [00300, 02526], lr: 0.000100, loss: 1.3794, CELoss: 1.3794, 
2022-10-20 18:39:34 - train: epoch 0057, iter [00400, 02526], lr: 0.000100, loss: 1.0592, CELoss: 1.0592, 
2022-10-20 18:40:59 - train: epoch 0057, iter [00500, 02526], lr: 0.000100, loss: 0.8377, CELoss: 0.8377, 
2022-10-20 18:42:25 - train: epoch 0057, iter [00600, 02526], lr: 0.000100, loss: 0.8559, CELoss: 0.8559, 
2022-10-20 18:43:50 - train: epoch 0057, iter [00700, 02526], lr: 0.000100, loss: 0.5575, CELoss: 0.5575, 
2022-10-20 18:45:15 - train: epoch 0057, iter [00800, 02526], lr: 0.000100, loss: 0.5927, CELoss: 0.5927, 
2022-10-20 18:46:40 - train: epoch 0057, iter [00900, 02526], lr: 0.000100, loss: 0.9531, CELoss: 0.9531, 
2022-10-20 18:48:05 - train: epoch 0057, iter [01000, 02526], lr: 0.000100, loss: 1.0716, CELoss: 1.0716, 
2022-10-20 18:49:31 - train: epoch 0057, iter [01100, 02526], lr: 0.000100, loss: 0.8328, CELoss: 0.8328, 
2022-10-20 18:50:56 - train: epoch 0057, iter [01200, 02526], lr: 0.000100, loss: 1.1670, CELoss: 1.1670, 
2022-10-20 18:52:21 - train: epoch 0057, iter [01300, 02526], lr: 0.000100, loss: 0.8191, CELoss: 0.8191, 
2022-10-20 18:53:46 - train: epoch 0057, iter [01400, 02526], lr: 0.000100, loss: 0.6266, CELoss: 0.6266, 
2022-10-20 18:55:12 - train: epoch 0057, iter [01500, 02526], lr: 0.000100, loss: 1.1059, CELoss: 1.1059, 
2022-10-20 18:56:37 - train: epoch 0057, iter [01600, 02526], lr: 0.000100, loss: 0.6172, CELoss: 0.6172, 
2022-10-20 18:58:01 - train: epoch 0057, iter [01700, 02526], lr: 0.000100, loss: 1.2798, CELoss: 1.2798, 
2022-10-20 18:59:26 - train: epoch 0057, iter [01800, 02526], lr: 0.000100, loss: 1.3942, CELoss: 1.3942, 
2022-10-20 19:00:52 - train: epoch 0057, iter [01900, 02526], lr: 0.000100, loss: 0.5941, CELoss: 0.5941, 
2022-10-20 19:02:17 - train: epoch 0057, iter [02000, 02526], lr: 0.000100, loss: 0.9751, CELoss: 0.9751, 
2022-10-20 19:03:42 - train: epoch 0057, iter [02100, 02526], lr: 0.000100, loss: 0.7452, CELoss: 0.7452, 
2022-10-20 19:05:07 - train: epoch 0057, iter [02200, 02526], lr: 0.000100, loss: 0.7771, CELoss: 0.7771, 
2022-10-20 19:06:31 - train: epoch 0057, iter [02300, 02526], lr: 0.000100, loss: 0.5623, CELoss: 0.5623, 
2022-10-20 19:07:56 - train: epoch 0057, iter [02400, 02526], lr: 0.000100, loss: 0.5677, CELoss: 0.5677, 
2022-10-20 19:09:21 - train: epoch 0057, iter [02500, 02526], lr: 0.000100, loss: 0.5549, CELoss: 0.5549, 
2022-10-20 19:09:44 - train: epoch 057, train_loss: 0.7894
2022-10-20 19:09:45 - until epoch: 057, best_metric: 30.368%
2022-10-20 19:09:45 - epoch 058 lr: 0.000100
2022-10-20 19:11:12 - train: epoch 0058, iter [00100, 02526], lr: 0.000100, loss: 0.9692, CELoss: 0.9692, 
2022-10-20 19:12:37 - train: epoch 0058, iter [00200, 02526], lr: 0.000100, loss: 0.8167, CELoss: 0.8167, 
2022-10-20 19:14:01 - train: epoch 0058, iter [00300, 02526], lr: 0.000100, loss: 0.8124, CELoss: 0.8124, 
2022-10-20 19:15:26 - train: epoch 0058, iter [00400, 02526], lr: 0.000100, loss: 0.9649, CELoss: 0.9649, 
2022-10-20 19:16:51 - train: epoch 0058, iter [00500, 02526], lr: 0.000100, loss: 1.0456, CELoss: 1.0456, 
2022-10-20 19:18:16 - train: epoch 0058, iter [00600, 02526], lr: 0.000100, loss: 0.8733, CELoss: 0.8733, 
2022-10-20 19:19:41 - train: epoch 0058, iter [00700, 02526], lr: 0.000100, loss: 0.5248, CELoss: 0.5248, 
2022-10-20 19:21:05 - train: epoch 0058, iter [00800, 02526], lr: 0.000100, loss: 1.3995, CELoss: 1.3995, 
2022-10-20 19:22:30 - train: epoch 0058, iter [00900, 02526], lr: 0.000100, loss: 0.9800, CELoss: 0.9800, 
2022-10-20 19:23:55 - train: epoch 0058, iter [01000, 02526], lr: 0.000100, loss: 0.7486, CELoss: 0.7486, 
2022-10-20 19:25:20 - train: epoch 0058, iter [01100, 02526], lr: 0.000100, loss: 0.9565, CELoss: 0.9565, 
2022-10-20 19:26:44 - train: epoch 0058, iter [01200, 02526], lr: 0.000100, loss: 0.8995, CELoss: 0.8995, 
2022-10-20 19:28:09 - train: epoch 0058, iter [01300, 02526], lr: 0.000100, loss: 0.8082, CELoss: 0.8082, 
2022-10-20 19:29:34 - train: epoch 0058, iter [01400, 02526], lr: 0.000100, loss: 0.9302, CELoss: 0.9302, 
2022-10-20 19:30:58 - train: epoch 0058, iter [01500, 02526], lr: 0.000100, loss: 0.6069, CELoss: 0.6069, 
2022-10-20 19:32:23 - train: epoch 0058, iter [01600, 02526], lr: 0.000100, loss: 0.5028, CELoss: 0.5028, 
2022-10-20 19:33:48 - train: epoch 0058, iter [01700, 02526], lr: 0.000100, loss: 0.6565, CELoss: 0.6565, 
2022-10-20 19:35:12 - train: epoch 0058, iter [01800, 02526], lr: 0.000100, loss: 0.7747, CELoss: 0.7747, 
2022-10-20 19:36:37 - train: epoch 0058, iter [01900, 02526], lr: 0.000100, loss: 0.6803, CELoss: 0.6803, 
2022-10-20 19:38:02 - train: epoch 0058, iter [02000, 02526], lr: 0.000100, loss: 0.5239, CELoss: 0.5239, 
2022-10-20 19:39:27 - train: epoch 0058, iter [02100, 02526], lr: 0.000100, loss: 0.5425, CELoss: 0.5425, 
2022-10-20 19:40:51 - train: epoch 0058, iter [02200, 02526], lr: 0.000100, loss: 0.7346, CELoss: 0.7346, 
2022-10-20 19:42:16 - train: epoch 0058, iter [02300, 02526], lr: 0.000100, loss: 0.5077, CELoss: 0.5077, 
2022-10-20 19:43:40 - train: epoch 0058, iter [02400, 02526], lr: 0.000100, loss: 0.8999, CELoss: 0.8999, 
2022-10-20 19:45:05 - train: epoch 0058, iter [02500, 02526], lr: 0.000100, loss: 0.7716, CELoss: 0.7716, 
2022-10-20 19:45:28 - train: epoch 058, train_loss: 0.7961
2022-10-20 19:45:28 - until epoch: 058, best_metric: 30.368%
2022-10-20 19:45:28 - epoch 059 lr: 0.000100
2022-10-20 19:46:55 - train: epoch 0059, iter [00100, 02526], lr: 0.000100, loss: 0.5324, CELoss: 0.5324, 
2022-10-20 19:48:20 - train: epoch 0059, iter [00200, 02526], lr: 0.000100, loss: 0.8703, CELoss: 0.8703, 
2022-10-20 19:49:45 - train: epoch 0059, iter [00300, 02526], lr: 0.000100, loss: 1.4975, CELoss: 1.4975, 
2022-10-20 19:51:09 - train: epoch 0059, iter [00400, 02526], lr: 0.000100, loss: 0.8316, CELoss: 0.8316, 
2022-10-20 19:52:34 - train: epoch 0059, iter [00500, 02526], lr: 0.000100, loss: 0.7072, CELoss: 0.7072, 
2022-10-20 19:53:59 - train: epoch 0059, iter [00600, 02526], lr: 0.000100, loss: 0.5535, CELoss: 0.5535, 
2022-10-20 19:55:24 - train: epoch 0059, iter [00700, 02526], lr: 0.000100, loss: 0.9150, CELoss: 0.9150, 
2022-10-20 19:56:49 - train: epoch 0059, iter [00800, 02526], lr: 0.000100, loss: 0.5119, CELoss: 0.5119, 
2022-10-20 19:58:14 - train: epoch 0059, iter [00900, 02526], lr: 0.000100, loss: 0.7940, CELoss: 0.7940, 
2022-10-20 19:59:39 - train: epoch 0059, iter [01000, 02526], lr: 0.000100, loss: 0.5645, CELoss: 0.5645, 
2022-10-20 20:01:03 - train: epoch 0059, iter [01100, 02526], lr: 0.000100, loss: 0.5382, CELoss: 0.5382, 
2022-10-20 20:02:29 - train: epoch 0059, iter [01200, 02526], lr: 0.000100, loss: 1.4390, CELoss: 1.4390, 
2022-10-20 20:03:54 - train: epoch 0059, iter [01300, 02526], lr: 0.000100, loss: 0.7438, CELoss: 0.7438, 
2022-10-20 20:05:19 - train: epoch 0059, iter [01400, 02526], lr: 0.000100, loss: 0.9570, CELoss: 0.9570, 
2022-10-20 20:06:44 - train: epoch 0059, iter [01500, 02526], lr: 0.000100, loss: 0.7828, CELoss: 0.7828, 
2022-10-20 20:08:08 - train: epoch 0059, iter [01600, 02526], lr: 0.000100, loss: 0.5723, CELoss: 0.5723, 
2022-10-20 20:09:33 - train: epoch 0059, iter [01700, 02526], lr: 0.000100, loss: 1.1395, CELoss: 1.1395, 
2022-10-20 20:10:59 - train: epoch 0059, iter [01800, 02526], lr: 0.000100, loss: 0.6697, CELoss: 0.6697, 
2022-10-20 20:12:23 - train: epoch 0059, iter [01900, 02526], lr: 0.000100, loss: 0.7446, CELoss: 0.7446, 
2022-10-20 20:13:48 - train: epoch 0059, iter [02000, 02526], lr: 0.000100, loss: 0.7749, CELoss: 0.7749, 
2022-10-20 20:15:13 - train: epoch 0059, iter [02100, 02526], lr: 0.000100, loss: 0.6536, CELoss: 0.6536, 
2022-10-20 20:16:38 - train: epoch 0059, iter [02200, 02526], lr: 0.000100, loss: 0.8513, CELoss: 0.8513, 
2022-10-20 20:18:03 - train: epoch 0059, iter [02300, 02526], lr: 0.000100, loss: 0.4973, CELoss: 0.4973, 
2022-10-20 20:19:28 - train: epoch 0059, iter [02400, 02526], lr: 0.000100, loss: 0.8841, CELoss: 0.8841, 
2022-10-20 20:20:52 - train: epoch 0059, iter [02500, 02526], lr: 0.000100, loss: 1.3039, CELoss: 1.3039, 
2022-10-20 20:21:15 - train: epoch 059, train_loss: 0.7855
2022-10-20 20:21:16 - until epoch: 059, best_metric: 30.368%
2022-10-20 20:21:16 - epoch 060 lr: 0.000100
2022-10-20 20:22:43 - train: epoch 0060, iter [00100, 02526], lr: 0.000100, loss: 0.7231, CELoss: 0.7231, 
2022-10-20 20:24:07 - train: epoch 0060, iter [00200, 02526], lr: 0.000100, loss: 0.6550, CELoss: 0.6550, 
2022-10-20 20:25:32 - train: epoch 0060, iter [00300, 02526], lr: 0.000100, loss: 1.0213, CELoss: 1.0213, 
2022-10-20 20:26:57 - train: epoch 0060, iter [00400, 02526], lr: 0.000100, loss: 0.7148, CELoss: 0.7148, 
2022-10-20 20:28:21 - train: epoch 0060, iter [00500, 02526], lr: 0.000100, loss: 0.5482, CELoss: 0.5482, 
2022-10-20 20:29:46 - train: epoch 0060, iter [00600, 02526], lr: 0.000100, loss: 0.5508, CELoss: 0.5508, 
2022-10-20 20:31:10 - train: epoch 0060, iter [00700, 02526], lr: 0.000100, loss: 0.8795, CELoss: 0.8795, 
2022-10-20 20:32:35 - train: epoch 0060, iter [00800, 02526], lr: 0.000100, loss: 0.5696, CELoss: 0.5696, 
2022-10-20 20:33:59 - train: epoch 0060, iter [00900, 02526], lr: 0.000100, loss: 0.5288, CELoss: 0.5288, 
2022-10-20 20:35:24 - train: epoch 0060, iter [01000, 02526], lr: 0.000100, loss: 0.6679, CELoss: 0.6679, 
2022-10-20 20:36:49 - train: epoch 0060, iter [01100, 02526], lr: 0.000100, loss: 0.6033, CELoss: 0.6033, 
2022-10-20 20:38:13 - train: epoch 0060, iter [01200, 02526], lr: 0.000100, loss: 0.8411, CELoss: 0.8411, 
2022-10-20 20:39:38 - train: epoch 0060, iter [01300, 02526], lr: 0.000100, loss: 0.7969, CELoss: 0.7969, 
2022-10-20 20:41:02 - train: epoch 0060, iter [01400, 02526], lr: 0.000100, loss: 0.6727, CELoss: 0.6727, 
2022-10-20 20:42:26 - train: epoch 0060, iter [01500, 02526], lr: 0.000100, loss: 0.7721, CELoss: 0.7721, 
2022-10-20 20:43:51 - train: epoch 0060, iter [01600, 02526], lr: 0.000100, loss: 0.5108, CELoss: 0.5108, 
2022-10-20 20:45:15 - train: epoch 0060, iter [01700, 02526], lr: 0.000100, loss: 0.6991, CELoss: 0.6991, 
2022-10-20 20:46:39 - train: epoch 0060, iter [01800, 02526], lr: 0.000100, loss: 0.7254, CELoss: 0.7254, 
2022-10-20 20:48:04 - train: epoch 0060, iter [01900, 02526], lr: 0.000100, loss: 0.7614, CELoss: 0.7614, 
2022-10-20 20:49:28 - train: epoch 0060, iter [02000, 02526], lr: 0.000100, loss: 1.0564, CELoss: 1.0564, 
2022-10-20 20:50:51 - train: epoch 0060, iter [02100, 02526], lr: 0.000100, loss: 0.8708, CELoss: 0.8708, 
2022-10-20 20:52:16 - train: epoch 0060, iter [02200, 02526], lr: 0.000100, loss: 1.0092, CELoss: 1.0092, 
2022-10-20 20:53:41 - train: epoch 0060, iter [02300, 02526], lr: 0.000100, loss: 0.7175, CELoss: 0.7175, 
2022-10-20 20:55:05 - train: epoch 0060, iter [02400, 02526], lr: 0.000100, loss: 0.9902, CELoss: 0.9902, 
2022-10-20 20:56:30 - train: epoch 0060, iter [02500, 02526], lr: 0.000100, loss: 0.9456, CELoss: 0.9456, 
2022-10-20 20:56:53 - train: epoch 060, train_loss: 0.7877
2022-10-20 20:59:39 - eval: epoch: 060
test_loss: 0.9997024406790733
per_image_load_time: 1.318ms
per_image_inference_time: 76.575ms
exist_num_class: 150.0
mean_precision: 48.858861393052976
mean_recall: 43.73976510618862
mean_iou: 30.40129044001297
mean_dice: 43.27779368238014

2022-10-20 20:59:40 - until epoch: 060, best_metric: 30.401%
2022-10-20 20:59:40 - epoch 061 lr: 0.000100
2022-10-20 21:01:07 - train: epoch 0061, iter [00100, 02526], lr: 0.000100, loss: 0.6914, CELoss: 0.6914, 
2022-10-20 21:02:32 - train: epoch 0061, iter [00200, 02526], lr: 0.000100, loss: 0.5608, CELoss: 0.5608, 
2022-10-20 21:03:56 - train: epoch 0061, iter [00300, 02526], lr: 0.000100, loss: 0.5303, CELoss: 0.5303, 
2022-10-20 21:05:20 - train: epoch 0061, iter [00400, 02526], lr: 0.000100, loss: 1.3387, CELoss: 1.3387, 
2022-10-20 21:06:46 - train: epoch 0061, iter [00500, 02526], lr: 0.000100, loss: 0.7807, CELoss: 0.7807, 
2022-10-20 21:08:10 - train: epoch 0061, iter [00600, 02526], lr: 0.000100, loss: 0.6052, CELoss: 0.6052, 
2022-10-20 21:09:35 - train: epoch 0061, iter [00700, 02526], lr: 0.000100, loss: 0.7899, CELoss: 0.7899, 
2022-10-20 21:10:59 - train: epoch 0061, iter [00800, 02526], lr: 0.000100, loss: 0.8921, CELoss: 0.8921, 
2022-10-20 21:12:24 - train: epoch 0061, iter [00900, 02526], lr: 0.000100, loss: 1.0559, CELoss: 1.0559, 
2022-10-20 21:13:49 - train: epoch 0061, iter [01000, 02526], lr: 0.000100, loss: 0.7576, CELoss: 0.7576, 
2022-10-20 21:15:15 - train: epoch 0061, iter [01100, 02526], lr: 0.000100, loss: 0.6321, CELoss: 0.6321, 
2022-10-20 21:16:39 - train: epoch 0061, iter [01200, 02526], lr: 0.000100, loss: 0.7189, CELoss: 0.7189, 
2022-10-20 21:18:04 - train: epoch 0061, iter [01300, 02526], lr: 0.000100, loss: 0.7551, CELoss: 0.7551, 
2022-10-20 21:19:28 - train: epoch 0061, iter [01400, 02526], lr: 0.000100, loss: 0.6026, CELoss: 0.6026, 
2022-10-20 21:20:52 - train: epoch 0061, iter [01500, 02526], lr: 0.000100, loss: 1.5592, CELoss: 1.5592, 
2022-10-20 21:22:16 - train: epoch 0061, iter [01600, 02526], lr: 0.000100, loss: 0.6508, CELoss: 0.6508, 
2022-10-20 21:23:40 - train: epoch 0061, iter [01700, 02526], lr: 0.000100, loss: 0.5270, CELoss: 0.5270, 
2022-10-20 21:25:06 - train: epoch 0061, iter [01800, 02526], lr: 0.000100, loss: 0.3446, CELoss: 0.3446, 
2022-10-20 21:26:30 - train: epoch 0061, iter [01900, 02526], lr: 0.000100, loss: 1.0405, CELoss: 1.0405, 
2022-10-20 21:27:55 - train: epoch 0061, iter [02000, 02526], lr: 0.000100, loss: 0.8989, CELoss: 0.8989, 
2022-10-20 21:29:20 - train: epoch 0061, iter [02100, 02526], lr: 0.000100, loss: 0.9225, CELoss: 0.9225, 
2022-10-20 21:30:45 - train: epoch 0061, iter [02200, 02526], lr: 0.000100, loss: 0.7523, CELoss: 0.7523, 
2022-10-20 21:32:10 - train: epoch 0061, iter [02300, 02526], lr: 0.000100, loss: 0.5846, CELoss: 0.5846, 
2022-10-20 21:33:35 - train: epoch 0061, iter [02400, 02526], lr: 0.000100, loss: 0.6527, CELoss: 0.6527, 
2022-10-20 21:35:00 - train: epoch 0061, iter [02500, 02526], lr: 0.000100, loss: 0.6034, CELoss: 0.6034, 
2022-10-20 21:35:23 - train: epoch 061, train_loss: 0.7796
2022-10-20 21:35:23 - until epoch: 061, best_metric: 30.401%
2022-10-20 21:35:23 - epoch 062 lr: 0.000100
2022-10-20 21:36:50 - train: epoch 0062, iter [00100, 02526], lr: 0.000100, loss: 0.7712, CELoss: 0.7712, 
2022-10-20 21:38:15 - train: epoch 0062, iter [00200, 02526], lr: 0.000100, loss: 0.6508, CELoss: 0.6508, 
2022-10-20 21:39:39 - train: epoch 0062, iter [00300, 02526], lr: 0.000100, loss: 0.5392, CELoss: 0.5392, 
2022-10-20 21:41:04 - train: epoch 0062, iter [00400, 02526], lr: 0.000100, loss: 0.9789, CELoss: 0.9789, 
2022-10-20 21:42:28 - train: epoch 0062, iter [00500, 02526], lr: 0.000100, loss: 0.4313, CELoss: 0.4313, 
2022-10-20 21:43:53 - train: epoch 0062, iter [00600, 02526], lr: 0.000100, loss: 0.8202, CELoss: 0.8202, 
2022-10-20 21:45:17 - train: epoch 0062, iter [00700, 02526], lr: 0.000100, loss: 1.1117, CELoss: 1.1117, 
2022-10-20 21:46:41 - train: epoch 0062, iter [00800, 02526], lr: 0.000100, loss: 0.8307, CELoss: 0.8307, 
2022-10-20 21:48:06 - train: epoch 0062, iter [00900, 02526], lr: 0.000100, loss: 0.8738, CELoss: 0.8738, 
2022-10-20 21:49:31 - train: epoch 0062, iter [01000, 02526], lr: 0.000100, loss: 0.5566, CELoss: 0.5566, 
2022-10-20 21:50:56 - train: epoch 0062, iter [01100, 02526], lr: 0.000100, loss: 0.6565, CELoss: 0.6565, 
2022-10-20 21:52:21 - train: epoch 0062, iter [01200, 02526], lr: 0.000100, loss: 0.4047, CELoss: 0.4047, 
2022-10-20 21:53:46 - train: epoch 0062, iter [01300, 02526], lr: 0.000100, loss: 0.6160, CELoss: 0.6160, 
2022-10-20 21:55:10 - train: epoch 0062, iter [01400, 02526], lr: 0.000100, loss: 0.8945, CELoss: 0.8945, 
2022-10-20 21:56:35 - train: epoch 0062, iter [01500, 02526], lr: 0.000100, loss: 1.2557, CELoss: 1.2557, 
2022-10-20 21:58:00 - train: epoch 0062, iter [01600, 02526], lr: 0.000100, loss: 0.3500, CELoss: 0.3500, 
2022-10-20 21:59:25 - train: epoch 0062, iter [01700, 02526], lr: 0.000100, loss: 0.7036, CELoss: 0.7036, 
2022-10-20 22:00:49 - train: epoch 0062, iter [01800, 02526], lr: 0.000100, loss: 0.5349, CELoss: 0.5349, 
2022-10-20 22:02:14 - train: epoch 0062, iter [01900, 02526], lr: 0.000100, loss: 0.7101, CELoss: 0.7101, 
2022-10-20 22:03:38 - train: epoch 0062, iter [02000, 02526], lr: 0.000100, loss: 0.8956, CELoss: 0.8956, 
2022-10-20 22:05:03 - train: epoch 0062, iter [02100, 02526], lr: 0.000100, loss: 1.2570, CELoss: 1.2570, 
2022-10-20 22:06:27 - train: epoch 0062, iter [02200, 02526], lr: 0.000100, loss: 0.6549, CELoss: 0.6549, 
2022-10-20 22:07:52 - train: epoch 0062, iter [02300, 02526], lr: 0.000100, loss: 0.7078, CELoss: 0.7078, 
2022-10-20 22:09:17 - train: epoch 0062, iter [02400, 02526], lr: 0.000100, loss: 0.8694, CELoss: 0.8694, 
2022-10-20 22:10:41 - train: epoch 0062, iter [02500, 02526], lr: 0.000100, loss: 1.0081, CELoss: 1.0081, 
2022-10-20 22:11:04 - train: epoch 062, train_loss: 0.7734
2022-10-20 22:11:05 - until epoch: 062, best_metric: 30.401%
2022-10-20 22:11:05 - epoch 063 lr: 0.000100
2022-10-20 22:12:32 - train: epoch 0063, iter [00100, 02526], lr: 0.000100, loss: 0.6840, CELoss: 0.6840, 
2022-10-20 22:13:57 - train: epoch 0063, iter [00200, 02526], lr: 0.000100, loss: 0.8867, CELoss: 0.8867, 
2022-10-20 22:15:21 - train: epoch 0063, iter [00300, 02526], lr: 0.000100, loss: 0.6454, CELoss: 0.6454, 
2022-10-20 22:16:45 - train: epoch 0063, iter [00400, 02526], lr: 0.000100, loss: 0.6242, CELoss: 0.6242, 
2022-10-20 22:18:10 - train: epoch 0063, iter [00500, 02526], lr: 0.000100, loss: 0.7433, CELoss: 0.7433, 
2022-10-20 22:19:34 - train: epoch 0063, iter [00600, 02526], lr: 0.000100, loss: 0.6161, CELoss: 0.6161, 
2022-10-20 22:20:59 - train: epoch 0063, iter [00700, 02526], lr: 0.000100, loss: 0.5427, CELoss: 0.5427, 
2022-10-20 22:22:24 - train: epoch 0063, iter [00800, 02526], lr: 0.000100, loss: 0.7200, CELoss: 0.7200, 
2022-10-20 22:23:49 - train: epoch 0063, iter [00900, 02526], lr: 0.000100, loss: 1.4484, CELoss: 1.4484, 
2022-10-20 22:25:14 - train: epoch 0063, iter [01000, 02526], lr: 0.000100, loss: 1.0585, CELoss: 1.0585, 
2022-10-20 22:26:39 - train: epoch 0063, iter [01100, 02526], lr: 0.000100, loss: 0.6294, CELoss: 0.6294, 
2022-10-20 22:28:03 - train: epoch 0063, iter [01200, 02526], lr: 0.000100, loss: 0.7017, CELoss: 0.7017, 
2022-10-20 22:29:28 - train: epoch 0063, iter [01300, 02526], lr: 0.000100, loss: 0.8744, CELoss: 0.8744, 
2022-10-20 22:30:53 - train: epoch 0063, iter [01400, 02526], lr: 0.000100, loss: 0.7341, CELoss: 0.7341, 
2022-10-20 22:32:17 - train: epoch 0063, iter [01500, 02526], lr: 0.000100, loss: 1.0886, CELoss: 1.0886, 
2022-10-20 22:33:43 - train: epoch 0063, iter [01600, 02526], lr: 0.000100, loss: 0.7683, CELoss: 0.7683, 
2022-10-20 22:35:08 - train: epoch 0063, iter [01700, 02526], lr: 0.000100, loss: 0.5659, CELoss: 0.5659, 
2022-10-20 22:36:33 - train: epoch 0063, iter [01800, 02526], lr: 0.000100, loss: 0.7104, CELoss: 0.7104, 
2022-10-20 22:37:57 - train: epoch 0063, iter [01900, 02526], lr: 0.000100, loss: 0.7785, CELoss: 0.7785, 
2022-10-20 22:39:22 - train: epoch 0063, iter [02000, 02526], lr: 0.000100, loss: 0.7904, CELoss: 0.7904, 
2022-10-20 22:40:47 - train: epoch 0063, iter [02100, 02526], lr: 0.000100, loss: 0.7642, CELoss: 0.7642, 
2022-10-20 22:42:13 - train: epoch 0063, iter [02200, 02526], lr: 0.000100, loss: 0.6274, CELoss: 0.6274, 
2022-10-20 22:43:37 - train: epoch 0063, iter [02300, 02526], lr: 0.000100, loss: 0.6630, CELoss: 0.6630, 
2022-10-20 22:45:02 - train: epoch 0063, iter [02400, 02526], lr: 0.000100, loss: 0.8576, CELoss: 0.8576, 
2022-10-20 22:46:26 - train: epoch 0063, iter [02500, 02526], lr: 0.000100, loss: 0.8368, CELoss: 0.8368, 
2022-10-20 22:46:49 - train: epoch 063, train_loss: 0.7746
2022-10-20 22:46:50 - until epoch: 063, best_metric: 30.401%
2022-10-20 22:46:50 - epoch 064 lr: 0.000100
2022-10-20 22:48:17 - train: epoch 0064, iter [00100, 02526], lr: 0.000100, loss: 1.1537, CELoss: 1.1537, 
2022-10-20 22:49:42 - train: epoch 0064, iter [00200, 02526], lr: 0.000100, loss: 0.8256, CELoss: 0.8256, 
2022-10-20 22:51:07 - train: epoch 0064, iter [00300, 02526], lr: 0.000100, loss: 0.8145, CELoss: 0.8145, 
2022-10-20 22:52:33 - train: epoch 0064, iter [00400, 02526], lr: 0.000100, loss: 0.6781, CELoss: 0.6781, 
2022-10-20 22:53:58 - train: epoch 0064, iter [00500, 02526], lr: 0.000100, loss: 0.7253, CELoss: 0.7253, 
2022-10-20 22:55:23 - train: epoch 0064, iter [00600, 02526], lr: 0.000100, loss: 0.8999, CELoss: 0.8999, 
2022-10-20 22:56:48 - train: epoch 0064, iter [00700, 02526], lr: 0.000100, loss: 0.5495, CELoss: 0.5495, 
2022-10-20 22:58:13 - train: epoch 0064, iter [00800, 02526], lr: 0.000100, loss: 0.9779, CELoss: 0.9779, 
2022-10-20 22:59:38 - train: epoch 0064, iter [00900, 02526], lr: 0.000100, loss: 0.7685, CELoss: 0.7685, 
2022-10-20 23:01:03 - train: epoch 0064, iter [01000, 02526], lr: 0.000100, loss: 0.7427, CELoss: 0.7427, 
2022-10-20 23:02:28 - train: epoch 0064, iter [01100, 02526], lr: 0.000100, loss: 1.3910, CELoss: 1.3910, 
2022-10-20 23:03:54 - train: epoch 0064, iter [01200, 02526], lr: 0.000100, loss: 0.5573, CELoss: 0.5573, 
2022-10-20 23:05:18 - train: epoch 0064, iter [01300, 02526], lr: 0.000100, loss: 0.4950, CELoss: 0.4950, 
2022-10-20 23:06:43 - train: epoch 0064, iter [01400, 02526], lr: 0.000100, loss: 0.9513, CELoss: 0.9513, 
2022-10-20 23:08:07 - train: epoch 0064, iter [01500, 02526], lr: 0.000100, loss: 0.7253, CELoss: 0.7253, 
2022-10-20 23:09:33 - train: epoch 0064, iter [01600, 02526], lr: 0.000100, loss: 0.6662, CELoss: 0.6662, 
2022-10-20 23:10:57 - train: epoch 0064, iter [01700, 02526], lr: 0.000100, loss: 0.9070, CELoss: 0.9070, 
2022-10-20 23:12:22 - train: epoch 0064, iter [01800, 02526], lr: 0.000100, loss: 0.6831, CELoss: 0.6831, 
2022-10-20 23:13:47 - train: epoch 0064, iter [01900, 02526], lr: 0.000100, loss: 1.0200, CELoss: 1.0200, 
2022-10-20 23:15:11 - train: epoch 0064, iter [02000, 02526], lr: 0.000100, loss: 0.4538, CELoss: 0.4538, 
2022-10-20 23:16:35 - train: epoch 0064, iter [02100, 02526], lr: 0.000100, loss: 1.2234, CELoss: 1.2234, 
2022-10-20 23:18:00 - train: epoch 0064, iter [02200, 02526], lr: 0.000100, loss: 0.5939, CELoss: 0.5939, 
2022-10-20 23:19:25 - train: epoch 0064, iter [02300, 02526], lr: 0.000100, loss: 0.6927, CELoss: 0.6927, 
2022-10-20 23:20:49 - train: epoch 0064, iter [02400, 02526], lr: 0.000100, loss: 0.8803, CELoss: 0.8803, 
2022-10-20 23:22:14 - train: epoch 0064, iter [02500, 02526], lr: 0.000100, loss: 0.8845, CELoss: 0.8845, 
2022-10-20 23:22:37 - train: epoch 064, train_loss: 0.7596
2022-10-20 23:22:37 - until epoch: 064, best_metric: 30.401%
2022-10-20 23:22:37 - epoch 065 lr: 0.000100
2022-10-20 23:24:05 - train: epoch 0065, iter [00100, 02526], lr: 0.000100, loss: 0.6947, CELoss: 0.6947, 
2022-10-20 23:25:29 - train: epoch 0065, iter [00200, 02526], lr: 0.000100, loss: 0.6516, CELoss: 0.6516, 
2022-10-20 23:26:54 - train: epoch 0065, iter [00300, 02526], lr: 0.000100, loss: 0.4393, CELoss: 0.4393, 
2022-10-20 23:28:18 - train: epoch 0065, iter [00400, 02526], lr: 0.000100, loss: 0.8517, CELoss: 0.8517, 
2022-10-20 23:29:43 - train: epoch 0065, iter [00500, 02526], lr: 0.000100, loss: 0.2653, CELoss: 0.2653, 
2022-10-20 23:31:07 - train: epoch 0065, iter [00600, 02526], lr: 0.000100, loss: 0.8519, CELoss: 0.8519, 
2022-10-20 23:32:31 - train: epoch 0065, iter [00700, 02526], lr: 0.000100, loss: 0.5502, CELoss: 0.5502, 
2022-10-20 23:33:56 - train: epoch 0065, iter [00800, 02526], lr: 0.000100, loss: 0.6159, CELoss: 0.6159, 
2022-10-20 23:35:20 - train: epoch 0065, iter [00900, 02526], lr: 0.000100, loss: 0.9752, CELoss: 0.9752, 
2022-10-20 23:36:45 - train: epoch 0065, iter [01000, 02526], lr: 0.000100, loss: 0.5653, CELoss: 0.5653, 
2022-10-20 23:38:10 - train: epoch 0065, iter [01100, 02526], lr: 0.000100, loss: 0.6723, CELoss: 0.6723, 
2022-10-20 23:39:34 - train: epoch 0065, iter [01200, 02526], lr: 0.000100, loss: 0.5664, CELoss: 0.5664, 
2022-10-20 23:40:59 - train: epoch 0065, iter [01300, 02526], lr: 0.000100, loss: 0.9205, CELoss: 0.9205, 
2022-10-20 23:42:24 - train: epoch 0065, iter [01400, 02526], lr: 0.000100, loss: 0.6100, CELoss: 0.6100, 
2022-10-20 23:43:49 - train: epoch 0065, iter [01500, 02526], lr: 0.000100, loss: 0.6070, CELoss: 0.6070, 
2022-10-20 23:45:13 - train: epoch 0065, iter [01600, 02526], lr: 0.000100, loss: 0.8494, CELoss: 0.8494, 
2022-10-20 23:46:39 - train: epoch 0065, iter [01700, 02526], lr: 0.000100, loss: 0.7874, CELoss: 0.7874, 
2022-10-20 23:48:04 - train: epoch 0065, iter [01800, 02526], lr: 0.000100, loss: 1.0401, CELoss: 1.0401, 
2022-10-20 23:49:28 - train: epoch 0065, iter [01900, 02526], lr: 0.000100, loss: 0.6540, CELoss: 0.6540, 
2022-10-20 23:50:53 - train: epoch 0065, iter [02000, 02526], lr: 0.000100, loss: 0.4392, CELoss: 0.4392, 
2022-10-20 23:52:18 - train: epoch 0065, iter [02100, 02526], lr: 0.000100, loss: 0.7020, CELoss: 0.7020, 
2022-10-20 23:53:43 - train: epoch 0065, iter [02200, 02526], lr: 0.000100, loss: 0.7493, CELoss: 0.7493, 
2022-10-20 23:55:08 - train: epoch 0065, iter [02300, 02526], lr: 0.000100, loss: 0.9661, CELoss: 0.9661, 
2022-10-20 23:56:32 - train: epoch 0065, iter [02400, 02526], lr: 0.000100, loss: 0.5944, CELoss: 0.5944, 
2022-10-20 23:57:57 - train: epoch 0065, iter [02500, 02526], lr: 0.000100, loss: 0.4968, CELoss: 0.4968, 
2022-10-20 23:58:20 - train: epoch 065, train_loss: 0.7656
2022-10-21 00:01:07 - eval: epoch: 065
test_loss: 0.9976665055155755
per_image_load_time: 1.281ms
per_image_inference_time: 76.918ms
exist_num_class: 150.0
mean_precision: 47.802677834752345
mean_recall: 44.36783726177347
mean_iou: 30.096813586246135
mean_dice: 42.92173023094132

2022-10-21 00:01:07 - until epoch: 065, best_metric: 30.401%
2022-10-21 00:01:07 - epoch 066 lr: 0.000100
2022-10-21 00:02:34 - train: epoch 0066, iter [00100, 02526], lr: 0.000100, loss: 0.9437, CELoss: 0.9437, 
2022-10-21 00:03:59 - train: epoch 0066, iter [00200, 02526], lr: 0.000100, loss: 0.6612, CELoss: 0.6612, 
2022-10-21 00:05:24 - train: epoch 0066, iter [00300, 02526], lr: 0.000100, loss: 0.9386, CELoss: 0.9386, 
2022-10-21 00:06:49 - train: epoch 0066, iter [00400, 02526], lr: 0.000100, loss: 0.5915, CELoss: 0.5915, 
2022-10-21 00:08:13 - train: epoch 0066, iter [00500, 02526], lr: 0.000100, loss: 0.8179, CELoss: 0.8179, 
2022-10-21 00:09:38 - train: epoch 0066, iter [00600, 02526], lr: 0.000100, loss: 0.6577, CELoss: 0.6577, 
2022-10-21 00:11:02 - train: epoch 0066, iter [00700, 02526], lr: 0.000100, loss: 0.8510, CELoss: 0.8510, 
2022-10-21 00:12:27 - train: epoch 0066, iter [00800, 02526], lr: 0.000100, loss: 0.8065, CELoss: 0.8065, 
2022-10-21 00:13:51 - train: epoch 0066, iter [00900, 02526], lr: 0.000100, loss: 0.5621, CELoss: 0.5621, 
2022-10-21 00:15:16 - train: epoch 0066, iter [01000, 02526], lr: 0.000100, loss: 1.2013, CELoss: 1.2013, 
2022-10-21 00:16:41 - train: epoch 0066, iter [01100, 02526], lr: 0.000100, loss: 0.4882, CELoss: 0.4882, 
2022-10-21 00:18:05 - train: epoch 0066, iter [01200, 02526], lr: 0.000100, loss: 0.8847, CELoss: 0.8847, 
2022-10-21 00:19:30 - train: epoch 0066, iter [01300, 02526], lr: 0.000100, loss: 0.8278, CELoss: 0.8278, 
2022-10-21 00:20:55 - train: epoch 0066, iter [01400, 02526], lr: 0.000100, loss: 0.6269, CELoss: 0.6269, 
2022-10-21 00:22:19 - train: epoch 0066, iter [01500, 02526], lr: 0.000100, loss: 0.6049, CELoss: 0.6049, 
2022-10-21 00:23:44 - train: epoch 0066, iter [01600, 02526], lr: 0.000100, loss: 0.7896, CELoss: 0.7896, 
2022-10-21 00:25:08 - train: epoch 0066, iter [01700, 02526], lr: 0.000100, loss: 0.5268, CELoss: 0.5268, 
2022-10-21 00:26:33 - train: epoch 0066, iter [01800, 02526], lr: 0.000100, loss: 0.6640, CELoss: 0.6640, 
2022-10-21 00:27:58 - train: epoch 0066, iter [01900, 02526], lr: 0.000100, loss: 0.6727, CELoss: 0.6727, 
2022-10-21 00:29:23 - train: epoch 0066, iter [02000, 02526], lr: 0.000100, loss: 0.6048, CELoss: 0.6048, 
2022-10-21 00:30:47 - train: epoch 0066, iter [02100, 02526], lr: 0.000100, loss: 0.6996, CELoss: 0.6996, 
2022-10-21 00:32:12 - train: epoch 0066, iter [02200, 02526], lr: 0.000100, loss: 1.4634, CELoss: 1.4634, 
2022-10-21 00:33:36 - train: epoch 0066, iter [02300, 02526], lr: 0.000100, loss: 1.2497, CELoss: 1.2497, 
2022-10-21 00:35:01 - train: epoch 0066, iter [02400, 02526], lr: 0.000100, loss: 1.0705, CELoss: 1.0705, 
2022-10-21 00:36:26 - train: epoch 0066, iter [02500, 02526], lr: 0.000100, loss: 0.8631, CELoss: 0.8631, 
2022-10-21 00:36:49 - train: epoch 066, train_loss: 0.7625
2022-10-21 00:36:50 - until epoch: 066, best_metric: 30.401%
2022-10-21 00:36:50 - epoch 067 lr: 0.000100
2022-10-21 00:38:18 - train: epoch 0067, iter [00100, 02526], lr: 0.000100, loss: 0.6859, CELoss: 0.6859, 
2022-10-21 00:39:42 - train: epoch 0067, iter [00200, 02526], lr: 0.000100, loss: 0.5445, CELoss: 0.5445, 
2022-10-21 00:41:07 - train: epoch 0067, iter [00300, 02526], lr: 0.000100, loss: 0.9148, CELoss: 0.9148, 
2022-10-21 00:42:31 - train: epoch 0067, iter [00400, 02526], lr: 0.000100, loss: 0.5461, CELoss: 0.5461, 
2022-10-21 00:43:56 - train: epoch 0067, iter [00500, 02526], lr: 0.000100, loss: 1.0377, CELoss: 1.0377, 
2022-10-21 00:45:21 - train: epoch 0067, iter [00600, 02526], lr: 0.000100, loss: 0.6681, CELoss: 0.6681, 
2022-10-21 00:46:45 - train: epoch 0067, iter [00700, 02526], lr: 0.000100, loss: 0.6229, CELoss: 0.6229, 
2022-10-21 00:48:10 - train: epoch 0067, iter [00800, 02526], lr: 0.000100, loss: 0.7910, CELoss: 0.7910, 
2022-10-21 00:49:35 - train: epoch 0067, iter [00900, 02526], lr: 0.000100, loss: 0.5990, CELoss: 0.5990, 
2022-10-21 00:51:00 - train: epoch 0067, iter [01000, 02526], lr: 0.000100, loss: 0.9559, CELoss: 0.9559, 
2022-10-21 00:52:25 - train: epoch 0067, iter [01100, 02526], lr: 0.000100, loss: 1.2890, CELoss: 1.2890, 
2022-10-21 00:53:50 - train: epoch 0067, iter [01200, 02526], lr: 0.000100, loss: 0.5973, CELoss: 0.5973, 
2022-10-21 00:55:15 - train: epoch 0067, iter [01300, 02526], lr: 0.000100, loss: 0.5103, CELoss: 0.5103, 
2022-10-21 00:56:40 - train: epoch 0067, iter [01400, 02526], lr: 0.000100, loss: 0.9963, CELoss: 0.9963, 
2022-10-21 00:58:04 - train: epoch 0067, iter [01500, 02526], lr: 0.000100, loss: 0.8312, CELoss: 0.8312, 
2022-10-21 00:59:29 - train: epoch 0067, iter [01600, 02526], lr: 0.000100, loss: 0.6915, CELoss: 0.6915, 
2022-10-21 01:00:54 - train: epoch 0067, iter [01700, 02526], lr: 0.000100, loss: 0.7719, CELoss: 0.7719, 
2022-10-21 01:02:18 - train: epoch 0067, iter [01800, 02526], lr: 0.000100, loss: 0.8475, CELoss: 0.8475, 
2022-10-21 01:03:43 - train: epoch 0067, iter [01900, 02526], lr: 0.000100, loss: 0.5910, CELoss: 0.5910, 
2022-10-21 01:05:07 - train: epoch 0067, iter [02000, 02526], lr: 0.000100, loss: 0.9090, CELoss: 0.9090, 
2022-10-21 01:06:31 - train: epoch 0067, iter [02100, 02526], lr: 0.000100, loss: 1.3236, CELoss: 1.3236, 
2022-10-21 01:07:57 - train: epoch 0067, iter [02200, 02526], lr: 0.000100, loss: 1.3763, CELoss: 1.3763, 
2022-10-21 01:09:21 - train: epoch 0067, iter [02300, 02526], lr: 0.000100, loss: 0.6692, CELoss: 0.6692, 
2022-10-21 01:10:46 - train: epoch 0067, iter [02400, 02526], lr: 0.000100, loss: 0.4571, CELoss: 0.4571, 
2022-10-21 01:12:11 - train: epoch 0067, iter [02500, 02526], lr: 0.000100, loss: 0.4205, CELoss: 0.4205, 
2022-10-21 01:12:34 - train: epoch 067, train_loss: 0.7503
2022-10-21 01:12:34 - until epoch: 067, best_metric: 30.401%
2022-10-21 01:12:34 - epoch 068 lr: 0.000100
2022-10-21 01:14:02 - train: epoch 0068, iter [00100, 02526], lr: 0.000100, loss: 0.7992, CELoss: 0.7992, 
2022-10-21 01:15:26 - train: epoch 0068, iter [00200, 02526], lr: 0.000100, loss: 0.4908, CELoss: 0.4908, 
2022-10-21 01:16:51 - train: epoch 0068, iter [00300, 02526], lr: 0.000100, loss: 0.7846, CELoss: 0.7846, 
2022-10-21 01:18:16 - train: epoch 0068, iter [00400, 02526], lr: 0.000100, loss: 0.5257, CELoss: 0.5257, 
2022-10-21 01:19:41 - train: epoch 0068, iter [00500, 02526], lr: 0.000100, loss: 0.9990, CELoss: 0.9990, 
2022-10-21 01:21:05 - train: epoch 0068, iter [00600, 02526], lr: 0.000100, loss: 0.7530, CELoss: 0.7530, 
2022-10-21 01:22:30 - train: epoch 0068, iter [00700, 02526], lr: 0.000100, loss: 0.4382, CELoss: 0.4382, 
2022-10-21 01:23:55 - train: epoch 0068, iter [00800, 02526], lr: 0.000100, loss: 0.4115, CELoss: 0.4115, 
2022-10-21 01:25:19 - train: epoch 0068, iter [00900, 02526], lr: 0.000100, loss: 1.0732, CELoss: 1.0732, 
2022-10-21 01:26:45 - train: epoch 0068, iter [01000, 02526], lr: 0.000100, loss: 0.8198, CELoss: 0.8198, 
2022-10-21 01:28:09 - train: epoch 0068, iter [01100, 02526], lr: 0.000100, loss: 0.5205, CELoss: 0.5205, 
2022-10-21 01:29:33 - train: epoch 0068, iter [01200, 02526], lr: 0.000100, loss: 0.9953, CELoss: 0.9953, 
2022-10-21 01:30:58 - train: epoch 0068, iter [01300, 02526], lr: 0.000100, loss: 0.6930, CELoss: 0.6930, 
2022-10-21 01:32:23 - train: epoch 0068, iter [01400, 02526], lr: 0.000100, loss: 0.6277, CELoss: 0.6277, 
2022-10-21 01:33:48 - train: epoch 0068, iter [01500, 02526], lr: 0.000100, loss: 0.9559, CELoss: 0.9559, 
2022-10-21 01:35:13 - train: epoch 0068, iter [01600, 02526], lr: 0.000100, loss: 1.7023, CELoss: 1.7023, 
2022-10-21 01:36:38 - train: epoch 0068, iter [01700, 02526], lr: 0.000100, loss: 0.7176, CELoss: 0.7176, 
2022-10-21 01:38:03 - train: epoch 0068, iter [01800, 02526], lr: 0.000100, loss: 0.4780, CELoss: 0.4780, 
2022-10-21 01:39:27 - train: epoch 0068, iter [01900, 02526], lr: 0.000100, loss: 0.7984, CELoss: 0.7984, 
2022-10-21 01:40:52 - train: epoch 0068, iter [02000, 02526], lr: 0.000100, loss: 0.9193, CELoss: 0.9193, 
2022-10-21 01:42:16 - train: epoch 0068, iter [02100, 02526], lr: 0.000100, loss: 0.7081, CELoss: 0.7081, 
2022-10-21 01:43:41 - train: epoch 0068, iter [02200, 02526], lr: 0.000100, loss: 0.7089, CELoss: 0.7089, 
2022-10-21 01:45:06 - train: epoch 0068, iter [02300, 02526], lr: 0.000100, loss: 0.4952, CELoss: 0.4952, 
2022-10-21 01:46:30 - train: epoch 0068, iter [02400, 02526], lr: 0.000100, loss: 0.6324, CELoss: 0.6324, 
2022-10-21 01:47:54 - train: epoch 0068, iter [02500, 02526], lr: 0.000100, loss: 0.5583, CELoss: 0.5583, 
2022-10-21 01:48:17 - train: epoch 068, train_loss: 0.7484
2022-10-21 01:48:18 - until epoch: 068, best_metric: 30.401%
2022-10-21 01:48:18 - epoch 069 lr: 0.000100
2022-10-21 01:49:45 - train: epoch 0069, iter [00100, 02526], lr: 0.000100, loss: 0.3385, CELoss: 0.3385, 
2022-10-21 01:51:10 - train: epoch 0069, iter [00200, 02526], lr: 0.000100, loss: 0.7042, CELoss: 0.7042, 
2022-10-21 01:52:34 - train: epoch 0069, iter [00300, 02526], lr: 0.000100, loss: 0.5521, CELoss: 0.5521, 
2022-10-21 01:53:59 - train: epoch 0069, iter [00400, 02526], lr: 0.000100, loss: 0.5885, CELoss: 0.5885, 
2022-10-21 01:55:23 - train: epoch 0069, iter [00500, 02526], lr: 0.000100, loss: 0.6194, CELoss: 0.6194, 
2022-10-21 01:56:48 - train: epoch 0069, iter [00600, 02526], lr: 0.000100, loss: 0.7536, CELoss: 0.7536, 
2022-10-21 01:58:13 - train: epoch 0069, iter [00700, 02526], lr: 0.000100, loss: 0.8596, CELoss: 0.8596, 
2022-10-21 01:59:37 - train: epoch 0069, iter [00800, 02526], lr: 0.000100, loss: 1.0624, CELoss: 1.0624, 
2022-10-21 02:01:02 - train: epoch 0069, iter [00900, 02526], lr: 0.000100, loss: 0.7469, CELoss: 0.7469, 
2022-10-21 02:02:26 - train: epoch 0069, iter [01000, 02526], lr: 0.000100, loss: 0.5789, CELoss: 0.5789, 
2022-10-21 02:03:51 - train: epoch 0069, iter [01100, 02526], lr: 0.000100, loss: 0.4242, CELoss: 0.4242, 
2022-10-21 02:05:16 - train: epoch 0069, iter [01200, 02526], lr: 0.000100, loss: 0.4927, CELoss: 0.4927, 
2022-10-21 02:06:40 - train: epoch 0069, iter [01300, 02526], lr: 0.000100, loss: 0.8316, CELoss: 0.8316, 
2022-10-21 02:08:05 - train: epoch 0069, iter [01400, 02526], lr: 0.000100, loss: 0.5553, CELoss: 0.5553, 
2022-10-21 02:09:30 - train: epoch 0069, iter [01500, 02526], lr: 0.000100, loss: 0.6990, CELoss: 0.6990, 
2022-10-21 02:10:55 - train: epoch 0069, iter [01600, 02526], lr: 0.000100, loss: 1.1598, CELoss: 1.1598, 
2022-10-21 02:12:19 - train: epoch 0069, iter [01700, 02526], lr: 0.000100, loss: 0.5765, CELoss: 0.5765, 
2022-10-21 02:13:44 - train: epoch 0069, iter [01800, 02526], lr: 0.000100, loss: 0.8173, CELoss: 0.8173, 
2022-10-21 02:15:08 - train: epoch 0069, iter [01900, 02526], lr: 0.000100, loss: 0.5781, CELoss: 0.5781, 
2022-10-21 02:16:33 - train: epoch 0069, iter [02000, 02526], lr: 0.000100, loss: 1.1637, CELoss: 1.1637, 
2022-10-21 02:17:57 - train: epoch 0069, iter [02100, 02526], lr: 0.000100, loss: 0.5759, CELoss: 0.5759, 
2022-10-21 02:19:22 - train: epoch 0069, iter [02200, 02526], lr: 0.000100, loss: 0.8219, CELoss: 0.8219, 
2022-10-21 02:20:46 - train: epoch 0069, iter [02300, 02526], lr: 0.000100, loss: 0.8590, CELoss: 0.8590, 
2022-10-21 02:22:11 - train: epoch 0069, iter [02400, 02526], lr: 0.000100, loss: 0.7101, CELoss: 0.7101, 
2022-10-21 02:23:36 - train: epoch 0069, iter [02500, 02526], lr: 0.000100, loss: 0.6267, CELoss: 0.6267, 
2022-10-21 02:23:59 - train: epoch 069, train_loss: 0.7456
2022-10-21 02:23:59 - until epoch: 069, best_metric: 30.401%
2022-10-21 02:23:59 - epoch 070 lr: 0.000100
2022-10-21 02:25:26 - train: epoch 0070, iter [00100, 02526], lr: 0.000100, loss: 0.3945, CELoss: 0.3945, 
2022-10-21 02:26:51 - train: epoch 0070, iter [00200, 02526], lr: 0.000100, loss: 0.6281, CELoss: 0.6281, 
2022-10-21 02:28:16 - train: epoch 0070, iter [00300, 02526], lr: 0.000100, loss: 0.4547, CELoss: 0.4547, 
2022-10-21 02:29:40 - train: epoch 0070, iter [00400, 02526], lr: 0.000100, loss: 0.8571, CELoss: 0.8571, 
2022-10-21 02:31:05 - train: epoch 0070, iter [00500, 02526], lr: 0.000100, loss: 0.5213, CELoss: 0.5213, 
2022-10-21 02:32:30 - train: epoch 0070, iter [00600, 02526], lr: 0.000100, loss: 0.7341, CELoss: 0.7341, 
2022-10-21 02:33:54 - train: epoch 0070, iter [00700, 02526], lr: 0.000100, loss: 0.6885, CELoss: 0.6885, 
2022-10-21 02:35:19 - train: epoch 0070, iter [00800, 02526], lr: 0.000100, loss: 0.3786, CELoss: 0.3786, 
2022-10-21 02:36:44 - train: epoch 0070, iter [00900, 02526], lr: 0.000100, loss: 0.6335, CELoss: 0.6335, 
2022-10-21 02:38:09 - train: epoch 0070, iter [01000, 02526], lr: 0.000100, loss: 0.6314, CELoss: 0.6314, 
2022-10-21 02:39:34 - train: epoch 0070, iter [01100, 02526], lr: 0.000100, loss: 1.3946, CELoss: 1.3946, 
2022-10-21 02:41:00 - train: epoch 0070, iter [01200, 02526], lr: 0.000100, loss: 0.5791, CELoss: 0.5791, 
2022-10-21 02:42:25 - train: epoch 0070, iter [01300, 02526], lr: 0.000100, loss: 0.5532, CELoss: 0.5532, 
2022-10-21 02:43:50 - train: epoch 0070, iter [01400, 02526], lr: 0.000100, loss: 0.5635, CELoss: 0.5635, 
2022-10-21 02:45:16 - train: epoch 0070, iter [01500, 02526], lr: 0.000100, loss: 0.8634, CELoss: 0.8634, 
2022-10-21 02:46:41 - train: epoch 0070, iter [01600, 02526], lr: 0.000100, loss: 0.8658, CELoss: 0.8658, 
2022-10-21 02:48:06 - train: epoch 0070, iter [01700, 02526], lr: 0.000100, loss: 0.8742, CELoss: 0.8742, 
2022-10-21 02:49:32 - train: epoch 0070, iter [01800, 02526], lr: 0.000100, loss: 0.8973, CELoss: 0.8973, 
2022-10-21 02:50:57 - train: epoch 0070, iter [01900, 02526], lr: 0.000100, loss: 0.3549, CELoss: 0.3549, 
2022-10-21 02:52:22 - train: epoch 0070, iter [02000, 02526], lr: 0.000100, loss: 0.9833, CELoss: 0.9833, 
2022-10-21 02:53:47 - train: epoch 0070, iter [02100, 02526], lr: 0.000100, loss: 0.7827, CELoss: 0.7827, 
2022-10-21 02:55:11 - train: epoch 0070, iter [02200, 02526], lr: 0.000100, loss: 0.6408, CELoss: 0.6408, 
2022-10-21 02:56:36 - train: epoch 0070, iter [02300, 02526], lr: 0.000100, loss: 0.5779, CELoss: 0.5779, 
2022-10-21 02:58:00 - train: epoch 0070, iter [02400, 02526], lr: 0.000100, loss: 0.5450, CELoss: 0.5450, 
2022-10-21 02:59:25 - train: epoch 0070, iter [02500, 02526], lr: 0.000100, loss: 0.6878, CELoss: 0.6878, 
2022-10-21 02:59:49 - train: epoch 070, train_loss: 0.7441
2022-10-21 03:02:35 - eval: epoch: 070
test_loss: 0.9983078440725803
per_image_load_time: 1.192ms
per_image_inference_time: 76.752ms
exist_num_class: 150.0
mean_precision: 47.7483994952285
mean_recall: 45.17596927263284
mean_iou: 30.60034368851058
mean_dice: 43.574837499204556

2022-10-21 03:02:36 - until epoch: 070, best_metric: 30.600%
2022-10-21 03:02:36 - epoch 071 lr: 0.000100
2022-10-21 03:04:04 - train: epoch 0071, iter [00100, 02526], lr: 0.000100, loss: 1.1073, CELoss: 1.1073, 
2022-10-21 03:05:29 - train: epoch 0071, iter [00200, 02526], lr: 0.000100, loss: 0.8732, CELoss: 0.8732, 
2022-10-21 03:06:54 - train: epoch 0071, iter [00300, 02526], lr: 0.000100, loss: 0.5876, CELoss: 0.5876, 
2022-10-21 03:08:18 - train: epoch 0071, iter [00400, 02526], lr: 0.000100, loss: 0.7326, CELoss: 0.7326, 
2022-10-21 03:09:44 - train: epoch 0071, iter [00500, 02526], lr: 0.000100, loss: 0.3711, CELoss: 0.3711, 
2022-10-21 03:11:08 - train: epoch 0071, iter [00600, 02526], lr: 0.000100, loss: 1.0301, CELoss: 1.0301, 
2022-10-21 03:12:33 - train: epoch 0071, iter [00700, 02526], lr: 0.000100, loss: 0.5562, CELoss: 0.5562, 
2022-10-21 03:13:58 - train: epoch 0071, iter [00800, 02526], lr: 0.000100, loss: 0.7368, CELoss: 0.7368, 
2022-10-21 03:15:23 - train: epoch 0071, iter [00900, 02526], lr: 0.000100, loss: 0.7286, CELoss: 0.7286, 
2022-10-21 03:16:48 - train: epoch 0071, iter [01000, 02526], lr: 0.000100, loss: 0.6766, CELoss: 0.6766, 
2022-10-21 03:18:12 - train: epoch 0071, iter [01100, 02526], lr: 0.000100, loss: 1.1275, CELoss: 1.1275, 
2022-10-21 03:19:36 - train: epoch 0071, iter [01200, 02526], lr: 0.000100, loss: 1.0026, CELoss: 1.0026, 
2022-10-21 03:21:01 - train: epoch 0071, iter [01300, 02526], lr: 0.000100, loss: 0.7715, CELoss: 0.7715, 
2022-10-21 03:22:26 - train: epoch 0071, iter [01400, 02526], lr: 0.000100, loss: 0.5092, CELoss: 0.5092, 
2022-10-21 03:23:51 - train: epoch 0071, iter [01500, 02526], lr: 0.000100, loss: 0.5490, CELoss: 0.5490, 
2022-10-21 03:25:16 - train: epoch 0071, iter [01600, 02526], lr: 0.000100, loss: 0.7674, CELoss: 0.7674, 
2022-10-21 03:26:41 - train: epoch 0071, iter [01700, 02526], lr: 0.000100, loss: 0.8336, CELoss: 0.8336, 
2022-10-21 03:28:06 - train: epoch 0071, iter [01800, 02526], lr: 0.000100, loss: 0.6666, CELoss: 0.6666, 
2022-10-21 03:29:31 - train: epoch 0071, iter [01900, 02526], lr: 0.000100, loss: 0.5145, CELoss: 0.5145, 
2022-10-21 03:30:56 - train: epoch 0071, iter [02000, 02526], lr: 0.000100, loss: 0.8033, CELoss: 0.8033, 
2022-10-21 03:32:20 - train: epoch 0071, iter [02100, 02526], lr: 0.000100, loss: 0.4479, CELoss: 0.4479, 
2022-10-21 03:33:45 - train: epoch 0071, iter [02200, 02526], lr: 0.000100, loss: 0.7244, CELoss: 0.7244, 
2022-10-21 03:35:10 - train: epoch 0071, iter [02300, 02526], lr: 0.000100, loss: 0.7238, CELoss: 0.7238, 
2022-10-21 03:36:35 - train: epoch 0071, iter [02400, 02526], lr: 0.000100, loss: 0.6422, CELoss: 0.6422, 
2022-10-21 03:38:00 - train: epoch 0071, iter [02500, 02526], lr: 0.000100, loss: 0.5153, CELoss: 0.5153, 
2022-10-21 03:38:23 - train: epoch 071, train_loss: 0.7352
2022-10-21 03:38:24 - until epoch: 071, best_metric: 30.600%
2022-10-21 03:38:24 - epoch 072 lr: 0.000100
2022-10-21 03:39:51 - train: epoch 0072, iter [00100, 02526], lr: 0.000100, loss: 0.3982, CELoss: 0.3982, 
2022-10-21 03:41:16 - train: epoch 0072, iter [00200, 02526], lr: 0.000100, loss: 0.5410, CELoss: 0.5410, 
2022-10-21 03:42:41 - train: epoch 0072, iter [00300, 02526], lr: 0.000100, loss: 0.4506, CELoss: 0.4506, 
2022-10-21 03:44:06 - train: epoch 0072, iter [00400, 02526], lr: 0.000100, loss: 0.8998, CELoss: 0.8998, 
2022-10-21 03:45:31 - train: epoch 0072, iter [00500, 02526], lr: 0.000100, loss: 0.8901, CELoss: 0.8901, 
2022-10-21 03:46:57 - train: epoch 0072, iter [00600, 02526], lr: 0.000100, loss: 0.7178, CELoss: 0.7178, 
2022-10-21 03:48:22 - train: epoch 0072, iter [00700, 02526], lr: 0.000100, loss: 0.8511, CELoss: 0.8511, 
2022-10-21 03:49:47 - train: epoch 0072, iter [00800, 02526], lr: 0.000100, loss: 0.4503, CELoss: 0.4503, 
2022-10-21 03:51:13 - train: epoch 0072, iter [00900, 02526], lr: 0.000100, loss: 0.8488, CELoss: 0.8488, 
2022-10-21 03:52:38 - train: epoch 0072, iter [01000, 02526], lr: 0.000100, loss: 0.7273, CELoss: 0.7273, 
2022-10-21 03:54:03 - train: epoch 0072, iter [01100, 02526], lr: 0.000100, loss: 0.8988, CELoss: 0.8988, 
2022-10-21 03:55:28 - train: epoch 0072, iter [01200, 02526], lr: 0.000100, loss: 0.8517, CELoss: 0.8517, 
2022-10-21 03:56:53 - train: epoch 0072, iter [01300, 02526], lr: 0.000100, loss: 0.9811, CELoss: 0.9811, 
2022-10-21 03:58:18 - train: epoch 0072, iter [01400, 02526], lr: 0.000100, loss: 0.6816, CELoss: 0.6816, 
2022-10-21 03:59:43 - train: epoch 0072, iter [01500, 02526], lr: 0.000100, loss: 0.8981, CELoss: 0.8981, 
2022-10-21 04:01:09 - train: epoch 0072, iter [01600, 02526], lr: 0.000100, loss: 0.5491, CELoss: 0.5491, 
2022-10-21 04:02:33 - train: epoch 0072, iter [01700, 02526], lr: 0.000100, loss: 0.9334, CELoss: 0.9334, 
2022-10-21 04:03:59 - train: epoch 0072, iter [01800, 02526], lr: 0.000100, loss: 0.6604, CELoss: 0.6604, 
2022-10-21 04:05:24 - train: epoch 0072, iter [01900, 02526], lr: 0.000100, loss: 0.8732, CELoss: 0.8732, 
2022-10-21 04:06:49 - train: epoch 0072, iter [02000, 02526], lr: 0.000100, loss: 1.3022, CELoss: 1.3022, 
2022-10-21 04:08:15 - train: epoch 0072, iter [02100, 02526], lr: 0.000100, loss: 0.6948, CELoss: 0.6948, 
2022-10-21 04:09:40 - train: epoch 0072, iter [02200, 02526], lr: 0.000100, loss: 0.8158, CELoss: 0.8158, 
2022-10-21 04:11:05 - train: epoch 0072, iter [02300, 02526], lr: 0.000100, loss: 0.4791, CELoss: 0.4791, 
2022-10-21 04:12:30 - train: epoch 0072, iter [02400, 02526], lr: 0.000100, loss: 0.5752, CELoss: 0.5752, 
2022-10-21 04:13:55 - train: epoch 0072, iter [02500, 02526], lr: 0.000100, loss: 0.6863, CELoss: 0.6863, 
2022-10-21 04:14:18 - train: epoch 072, train_loss: 0.7315
2022-10-21 04:14:19 - until epoch: 072, best_metric: 30.600%
2022-10-21 04:14:19 - epoch 073 lr: 0.000100
2022-10-21 04:15:47 - train: epoch 0073, iter [00100, 02526], lr: 0.000100, loss: 0.8523, CELoss: 0.8523, 
2022-10-21 04:17:13 - train: epoch 0073, iter [00200, 02526], lr: 0.000100, loss: 0.8042, CELoss: 0.8042, 
2022-10-21 04:18:38 - train: epoch 0073, iter [00300, 02526], lr: 0.000100, loss: 0.5682, CELoss: 0.5682, 
2022-10-21 04:20:03 - train: epoch 0073, iter [00400, 02526], lr: 0.000100, loss: 0.5921, CELoss: 0.5921, 
2022-10-21 04:21:28 - train: epoch 0073, iter [00500, 02526], lr: 0.000100, loss: 0.5782, CELoss: 0.5782, 
2022-10-21 04:22:54 - train: epoch 0073, iter [00600, 02526], lr: 0.000100, loss: 0.4187, CELoss: 0.4187, 
2022-10-21 04:24:19 - train: epoch 0073, iter [00700, 02526], lr: 0.000100, loss: 0.7444, CELoss: 0.7444, 
2022-10-21 04:25:44 - train: epoch 0073, iter [00800, 02526], lr: 0.000100, loss: 0.6234, CELoss: 0.6234, 
2022-10-21 04:27:10 - train: epoch 0073, iter [00900, 02526], lr: 0.000100, loss: 0.8493, CELoss: 0.8493, 
2022-10-21 04:28:35 - train: epoch 0073, iter [01000, 02526], lr: 0.000100, loss: 0.4337, CELoss: 0.4337, 
2022-10-21 04:30:01 - train: epoch 0073, iter [01100, 02526], lr: 0.000100, loss: 0.8981, CELoss: 0.8981, 
2022-10-21 04:31:26 - train: epoch 0073, iter [01200, 02526], lr: 0.000100, loss: 0.8144, CELoss: 0.8144, 
2022-10-21 04:32:51 - train: epoch 0073, iter [01300, 02526], lr: 0.000100, loss: 0.5072, CELoss: 0.5072, 
2022-10-21 04:34:16 - train: epoch 0073, iter [01400, 02526], lr: 0.000100, loss: 0.5244, CELoss: 0.5244, 
2022-10-21 04:35:42 - train: epoch 0073, iter [01500, 02526], lr: 0.000100, loss: 0.8859, CELoss: 0.8859, 
2022-10-21 04:37:07 - train: epoch 0073, iter [01600, 02526], lr: 0.000100, loss: 0.5099, CELoss: 0.5099, 
2022-10-21 04:38:32 - train: epoch 0073, iter [01700, 02526], lr: 0.000100, loss: 0.9215, CELoss: 0.9215, 
2022-10-21 04:39:58 - train: epoch 0073, iter [01800, 02526], lr: 0.000100, loss: 0.6749, CELoss: 0.6749, 
2022-10-21 04:41:23 - train: epoch 0073, iter [01900, 02526], lr: 0.000100, loss: 0.5083, CELoss: 0.5083, 
2022-10-21 04:42:49 - train: epoch 0073, iter [02000, 02526], lr: 0.000100, loss: 0.5312, CELoss: 0.5312, 
2022-10-21 04:44:14 - train: epoch 0073, iter [02100, 02526], lr: 0.000100, loss: 1.1626, CELoss: 1.1626, 
2022-10-21 04:45:39 - train: epoch 0073, iter [02200, 02526], lr: 0.000100, loss: 0.5352, CELoss: 0.5352, 
2022-10-21 04:47:04 - train: epoch 0073, iter [02300, 02526], lr: 0.000100, loss: 0.5257, CELoss: 0.5257, 
2022-10-21 04:48:30 - train: epoch 0073, iter [02400, 02526], lr: 0.000100, loss: 0.4588, CELoss: 0.4588, 
2022-10-21 04:49:55 - train: epoch 0073, iter [02500, 02526], lr: 0.000100, loss: 0.5064, CELoss: 0.5064, 
2022-10-21 04:50:18 - train: epoch 073, train_loss: 0.7230
2022-10-21 04:50:19 - until epoch: 073, best_metric: 30.600%
2022-10-21 04:50:19 - epoch 074 lr: 0.000100
2022-10-21 04:51:48 - train: epoch 0074, iter [00100, 02526], lr: 0.000100, loss: 0.5943, CELoss: 0.5943, 
2022-10-21 04:53:13 - train: epoch 0074, iter [00200, 02526], lr: 0.000100, loss: 0.4429, CELoss: 0.4429, 
2022-10-21 04:54:38 - train: epoch 0074, iter [00300, 02526], lr: 0.000100, loss: 0.7270, CELoss: 0.7270, 
2022-10-21 04:56:03 - train: epoch 0074, iter [00400, 02526], lr: 0.000100, loss: 0.7103, CELoss: 0.7103, 
2022-10-21 04:57:28 - train: epoch 0074, iter [00500, 02526], lr: 0.000100, loss: 0.5478, CELoss: 0.5478, 
2022-10-21 04:58:53 - train: epoch 0074, iter [00600, 02526], lr: 0.000100, loss: 0.8679, CELoss: 0.8679, 
2022-10-21 05:00:19 - train: epoch 0074, iter [00700, 02526], lr: 0.000100, loss: 1.0221, CELoss: 1.0221, 
2022-10-21 05:01:44 - train: epoch 0074, iter [00800, 02526], lr: 0.000100, loss: 0.8120, CELoss: 0.8120, 
2022-10-21 05:03:10 - train: epoch 0074, iter [00900, 02526], lr: 0.000100, loss: 0.6532, CELoss: 0.6532, 
2022-10-21 05:04:35 - train: epoch 0074, iter [01000, 02526], lr: 0.000100, loss: 0.4889, CELoss: 0.4889, 
2022-10-21 05:06:00 - train: epoch 0074, iter [01100, 02526], lr: 0.000100, loss: 0.9322, CELoss: 0.9322, 
2022-10-21 05:07:25 - train: epoch 0074, iter [01200, 02526], lr: 0.000100, loss: 0.7771, CELoss: 0.7771, 
2022-10-21 05:08:50 - train: epoch 0074, iter [01300, 02526], lr: 0.000100, loss: 0.3195, CELoss: 0.3195, 
2022-10-21 05:10:15 - train: epoch 0074, iter [01400, 02526], lr: 0.000100, loss: 0.5241, CELoss: 0.5241, 
2022-10-21 05:11:41 - train: epoch 0074, iter [01500, 02526], lr: 0.000100, loss: 0.5280, CELoss: 0.5280, 
2022-10-21 05:13:06 - train: epoch 0074, iter [01600, 02526], lr: 0.000100, loss: 1.0124, CELoss: 1.0124, 
2022-10-21 05:14:31 - train: epoch 0074, iter [01700, 02526], lr: 0.000100, loss: 0.6140, CELoss: 0.6140, 
2022-10-21 05:15:57 - train: epoch 0074, iter [01800, 02526], lr: 0.000100, loss: 0.5188, CELoss: 0.5188, 
2022-10-21 05:17:22 - train: epoch 0074, iter [01900, 02526], lr: 0.000100, loss: 0.7133, CELoss: 0.7133, 
2022-10-21 05:18:47 - train: epoch 0074, iter [02000, 02526], lr: 0.000100, loss: 0.7965, CELoss: 0.7965, 
2022-10-21 05:20:13 - train: epoch 0074, iter [02100, 02526], lr: 0.000100, loss: 0.6620, CELoss: 0.6620, 
2022-10-21 05:21:38 - train: epoch 0074, iter [02200, 02526], lr: 0.000100, loss: 0.9523, CELoss: 0.9523, 
2022-10-21 05:23:03 - train: epoch 0074, iter [02300, 02526], lr: 0.000100, loss: 0.5431, CELoss: 0.5431, 
2022-10-21 05:24:29 - train: epoch 0074, iter [02400, 02526], lr: 0.000100, loss: 1.0239, CELoss: 1.0239, 
2022-10-21 05:25:54 - train: epoch 0074, iter [02500, 02526], lr: 0.000100, loss: 0.8307, CELoss: 0.8307, 
2022-10-21 05:26:17 - train: epoch 074, train_loss: 0.7247
2022-10-21 05:26:18 - until epoch: 074, best_metric: 30.600%
2022-10-21 05:26:18 - epoch 075 lr: 0.000100
2022-10-21 05:27:46 - train: epoch 0075, iter [00100, 02526], lr: 0.000100, loss: 0.6674, CELoss: 0.6674, 
2022-10-21 05:29:11 - train: epoch 0075, iter [00200, 02526], lr: 0.000100, loss: 0.4420, CELoss: 0.4420, 
2022-10-21 05:30:36 - train: epoch 0075, iter [00300, 02526], lr: 0.000100, loss: 0.5844, CELoss: 0.5844, 
2022-10-21 05:32:01 - train: epoch 0075, iter [00400, 02526], lr: 0.000100, loss: 0.5712, CELoss: 0.5712, 
2022-10-21 05:33:27 - train: epoch 0075, iter [00500, 02526], lr: 0.000100, loss: 0.5932, CELoss: 0.5932, 
2022-10-21 05:34:52 - train: epoch 0075, iter [00600, 02526], lr: 0.000100, loss: 0.6035, CELoss: 0.6035, 
2022-10-21 05:36:18 - train: epoch 0075, iter [00700, 02526], lr: 0.000100, loss: 0.7658, CELoss: 0.7658, 
2022-10-21 05:37:43 - train: epoch 0075, iter [00800, 02526], lr: 0.000100, loss: 1.3241, CELoss: 1.3241, 
2022-10-21 05:39:09 - train: epoch 0075, iter [00900, 02526], lr: 0.000100, loss: 0.8433, CELoss: 0.8433, 
2022-10-21 05:40:34 - train: epoch 0075, iter [01000, 02526], lr: 0.000100, loss: 0.8418, CELoss: 0.8418, 
2022-10-21 05:41:59 - train: epoch 0075, iter [01100, 02526], lr: 0.000100, loss: 0.5866, CELoss: 0.5866, 
2022-10-21 05:43:25 - train: epoch 0075, iter [01200, 02526], lr: 0.000100, loss: 0.6084, CELoss: 0.6084, 
2022-10-21 05:44:50 - train: epoch 0075, iter [01300, 02526], lr: 0.000100, loss: 0.7865, CELoss: 0.7865, 
2022-10-21 05:46:15 - train: epoch 0075, iter [01400, 02526], lr: 0.000100, loss: 0.9681, CELoss: 0.9681, 
2022-10-21 05:47:41 - train: epoch 0075, iter [01500, 02526], lr: 0.000100, loss: 0.6585, CELoss: 0.6585, 
2022-10-21 05:49:06 - train: epoch 0075, iter [01600, 02526], lr: 0.000100, loss: 0.6152, CELoss: 0.6152, 
2022-10-21 05:50:31 - train: epoch 0075, iter [01700, 02526], lr: 0.000100, loss: 0.5796, CELoss: 0.5796, 
2022-10-21 05:51:56 - train: epoch 0075, iter [01800, 02526], lr: 0.000100, loss: 0.7078, CELoss: 0.7078, 
2022-10-21 05:53:21 - train: epoch 0075, iter [01900, 02526], lr: 0.000100, loss: 0.7276, CELoss: 0.7276, 
2022-10-21 05:54:47 - train: epoch 0075, iter [02000, 02526], lr: 0.000100, loss: 0.4574, CELoss: 0.4574, 
2022-10-21 05:56:12 - train: epoch 0075, iter [02100, 02526], lr: 0.000100, loss: 0.5432, CELoss: 0.5432, 
2022-10-21 05:57:37 - train: epoch 0075, iter [02200, 02526], lr: 0.000100, loss: 0.8559, CELoss: 0.8559, 
2022-10-21 05:59:02 - train: epoch 0075, iter [02300, 02526], lr: 0.000100, loss: 0.7836, CELoss: 0.7836, 
2022-10-21 06:00:28 - train: epoch 0075, iter [02400, 02526], lr: 0.000100, loss: 0.4715, CELoss: 0.4715, 
2022-10-21 06:01:53 - train: epoch 0075, iter [02500, 02526], lr: 0.000100, loss: 0.6477, CELoss: 0.6477, 
2022-10-21 06:02:17 - train: epoch 075, train_loss: 0.7220
2022-10-21 06:05:03 - eval: epoch: 075
test_loss: 0.9932812159955502
per_image_load_time: 1.405ms
per_image_inference_time: 76.710ms
exist_num_class: 150.0
mean_precision: 47.59272248799787
mean_recall: 45.923237586792986
mean_iou: 30.513237010001752
mean_dice: 43.63472871207882

2022-10-21 06:05:04 - until epoch: 075, best_metric: 30.600%
2022-10-21 06:05:04 - epoch 076 lr: 0.000100
2022-10-21 06:06:33 - train: epoch 0076, iter [00100, 02526], lr: 0.000100, loss: 0.6340, CELoss: 0.6340, 
2022-10-21 06:07:58 - train: epoch 0076, iter [00200, 02526], lr: 0.000100, loss: 0.9008, CELoss: 0.9008, 
2022-10-21 06:09:23 - train: epoch 0076, iter [00300, 02526], lr: 0.000100, loss: 1.1341, CELoss: 1.1341, 
2022-10-21 06:10:48 - train: epoch 0076, iter [00400, 02526], lr: 0.000100, loss: 0.5780, CELoss: 0.5780, 
2022-10-21 06:12:14 - train: epoch 0076, iter [00500, 02526], lr: 0.000100, loss: 0.5313, CELoss: 0.5313, 
2022-10-21 06:13:39 - train: epoch 0076, iter [00600, 02526], lr: 0.000100, loss: 0.7383, CELoss: 0.7383, 
2022-10-21 06:15:04 - train: epoch 0076, iter [00700, 02526], lr: 0.000100, loss: 1.0865, CELoss: 1.0865, 
2022-10-21 06:16:30 - train: epoch 0076, iter [00800, 02526], lr: 0.000100, loss: 1.0326, CELoss: 1.0326, 
2022-10-21 06:17:55 - train: epoch 0076, iter [00900, 02526], lr: 0.000100, loss: 0.7126, CELoss: 0.7126, 
2022-10-21 06:19:20 - train: epoch 0076, iter [01000, 02526], lr: 0.000100, loss: 0.4857, CELoss: 0.4857, 
2022-10-21 06:20:46 - train: epoch 0076, iter [01100, 02526], lr: 0.000100, loss: 1.1194, CELoss: 1.1194, 
2022-10-21 06:22:11 - train: epoch 0076, iter [01200, 02526], lr: 0.000100, loss: 0.3878, CELoss: 0.3878, 
2022-10-21 06:23:36 - train: epoch 0076, iter [01300, 02526], lr: 0.000100, loss: 0.6916, CELoss: 0.6916, 
2022-10-21 06:25:01 - train: epoch 0076, iter [01400, 02526], lr: 0.000100, loss: 0.4278, CELoss: 0.4278, 
2022-10-21 06:26:26 - train: epoch 0076, iter [01500, 02526], lr: 0.000100, loss: 0.6747, CELoss: 0.6747, 
2022-10-21 06:27:51 - train: epoch 0076, iter [01600, 02526], lr: 0.000100, loss: 0.4859, CELoss: 0.4859, 
2022-10-21 06:29:16 - train: epoch 0076, iter [01700, 02526], lr: 0.000100, loss: 0.8950, CELoss: 0.8950, 
2022-10-21 06:30:41 - train: epoch 0076, iter [01800, 02526], lr: 0.000100, loss: 1.3625, CELoss: 1.3625, 
2022-10-21 06:32:07 - train: epoch 0076, iter [01900, 02526], lr: 0.000100, loss: 0.3648, CELoss: 0.3648, 
2022-10-21 06:33:32 - train: epoch 0076, iter [02000, 02526], lr: 0.000100, loss: 0.3982, CELoss: 0.3982, 
2022-10-21 06:34:57 - train: epoch 0076, iter [02100, 02526], lr: 0.000100, loss: 0.9513, CELoss: 0.9513, 
2022-10-21 06:36:22 - train: epoch 0076, iter [02200, 02526], lr: 0.000100, loss: 0.5532, CELoss: 0.5532, 
2022-10-21 06:37:47 - train: epoch 0076, iter [02300, 02526], lr: 0.000100, loss: 1.0970, CELoss: 1.0970, 
2022-10-21 06:39:13 - train: epoch 0076, iter [02400, 02526], lr: 0.000100, loss: 0.4480, CELoss: 0.4480, 
2022-10-21 06:40:38 - train: epoch 0076, iter [02500, 02526], lr: 0.000100, loss: 0.6204, CELoss: 0.6204, 
2022-10-21 06:41:01 - train: epoch 076, train_loss: 0.7217
2022-10-21 06:41:02 - until epoch: 076, best_metric: 30.600%
2022-10-21 06:41:02 - epoch 077 lr: 0.000100
2022-10-21 06:42:30 - train: epoch 0077, iter [00100, 02526], lr: 0.000100, loss: 0.6597, CELoss: 0.6597, 
2022-10-21 06:43:56 - train: epoch 0077, iter [00200, 02526], lr: 0.000100, loss: 1.0675, CELoss: 1.0675, 
2022-10-21 06:45:21 - train: epoch 0077, iter [00300, 02526], lr: 0.000100, loss: 0.5968, CELoss: 0.5968, 
2022-10-21 06:46:46 - train: epoch 0077, iter [00400, 02526], lr: 0.000100, loss: 0.4341, CELoss: 0.4341, 
2022-10-21 06:48:12 - train: epoch 0077, iter [00500, 02526], lr: 0.000100, loss: 0.8777, CELoss: 0.8777, 
2022-10-21 06:49:37 - train: epoch 0077, iter [00600, 02526], lr: 0.000100, loss: 0.9169, CELoss: 0.9169, 
2022-10-21 06:51:02 - train: epoch 0077, iter [00700, 02526], lr: 0.000100, loss: 0.6004, CELoss: 0.6004, 
2022-10-21 06:52:27 - train: epoch 0077, iter [00800, 02526], lr: 0.000100, loss: 0.5989, CELoss: 0.5989, 
2022-10-21 06:53:53 - train: epoch 0077, iter [00900, 02526], lr: 0.000100, loss: 0.8666, CELoss: 0.8666, 
2022-10-21 06:55:18 - train: epoch 0077, iter [01000, 02526], lr: 0.000100, loss: 0.7263, CELoss: 0.7263, 
2022-10-21 06:56:44 - train: epoch 0077, iter [01100, 02526], lr: 0.000100, loss: 0.6515, CELoss: 0.6515, 
2022-10-21 06:58:09 - train: epoch 0077, iter [01200, 02526], lr: 0.000100, loss: 0.6897, CELoss: 0.6897, 
2022-10-21 06:59:35 - train: epoch 0077, iter [01300, 02526], lr: 0.000100, loss: 0.7154, CELoss: 0.7154, 
2022-10-21 07:01:00 - train: epoch 0077, iter [01400, 02526], lr: 0.000100, loss: 0.6245, CELoss: 0.6245, 
2022-10-21 07:02:25 - train: epoch 0077, iter [01500, 02526], lr: 0.000100, loss: 0.5642, CELoss: 0.5642, 
2022-10-21 07:03:51 - train: epoch 0077, iter [01600, 02526], lr: 0.000100, loss: 0.4270, CELoss: 0.4270, 
2022-10-21 07:05:16 - train: epoch 0077, iter [01700, 02526], lr: 0.000100, loss: 1.0230, CELoss: 1.0230, 
2022-10-21 07:06:41 - train: epoch 0077, iter [01800, 02526], lr: 0.000100, loss: 0.5787, CELoss: 0.5787, 
2022-10-21 07:08:07 - train: epoch 0077, iter [01900, 02526], lr: 0.000100, loss: 0.6912, CELoss: 0.6912, 
2022-10-21 07:09:32 - train: epoch 0077, iter [02000, 02526], lr: 0.000100, loss: 0.8567, CELoss: 0.8567, 
2022-10-21 07:10:57 - train: epoch 0077, iter [02100, 02526], lr: 0.000100, loss: 0.8659, CELoss: 0.8659, 
2022-10-21 07:12:23 - train: epoch 0077, iter [02200, 02526], lr: 0.000100, loss: 1.1432, CELoss: 1.1432, 
2022-10-21 07:13:48 - train: epoch 0077, iter [02300, 02526], lr: 0.000100, loss: 0.5964, CELoss: 0.5964, 
2022-10-21 07:15:13 - train: epoch 0077, iter [02400, 02526], lr: 0.000100, loss: 0.7471, CELoss: 0.7471, 
2022-10-21 07:16:38 - train: epoch 0077, iter [02500, 02526], lr: 0.000100, loss: 0.9307, CELoss: 0.9307, 
2022-10-21 07:17:02 - train: epoch 077, train_loss: 0.7134
2022-10-21 07:17:02 - until epoch: 077, best_metric: 30.600%
2022-10-21 07:17:02 - epoch 078 lr: 0.000100
2022-10-21 07:18:30 - train: epoch 0078, iter [00100, 02526], lr: 0.000100, loss: 0.4174, CELoss: 0.4174, 
2022-10-21 07:19:56 - train: epoch 0078, iter [00200, 02526], lr: 0.000100, loss: 0.6152, CELoss: 0.6152, 
2022-10-21 07:21:21 - train: epoch 0078, iter [00300, 02526], lr: 0.000100, loss: 0.5871, CELoss: 0.5871, 
2022-10-21 07:22:46 - train: epoch 0078, iter [00400, 02526], lr: 0.000100, loss: 0.4356, CELoss: 0.4356, 
2022-10-21 07:24:11 - train: epoch 0078, iter [00500, 02526], lr: 0.000100, loss: 0.6977, CELoss: 0.6977, 
2022-10-21 07:25:36 - train: epoch 0078, iter [00600, 02526], lr: 0.000100, loss: 0.7355, CELoss: 0.7355, 
2022-10-21 07:27:02 - train: epoch 0078, iter [00700, 02526], lr: 0.000100, loss: 0.7277, CELoss: 0.7277, 
2022-10-21 07:28:27 - train: epoch 0078, iter [00800, 02526], lr: 0.000100, loss: 0.7618, CELoss: 0.7618, 
2022-10-21 07:29:52 - train: epoch 0078, iter [00900, 02526], lr: 0.000100, loss: 0.4649, CELoss: 0.4649, 
2022-10-21 07:31:17 - train: epoch 0078, iter [01000, 02526], lr: 0.000100, loss: 0.9131, CELoss: 0.9131, 
2022-10-21 07:32:43 - train: epoch 0078, iter [01100, 02526], lr: 0.000100, loss: 0.8120, CELoss: 0.8120, 
2022-10-21 07:34:08 - train: epoch 0078, iter [01200, 02526], lr: 0.000100, loss: 0.5484, CELoss: 0.5484, 
2022-10-21 07:35:34 - train: epoch 0078, iter [01300, 02526], lr: 0.000100, loss: 0.7209, CELoss: 0.7209, 
2022-10-21 07:36:59 - train: epoch 0078, iter [01400, 02526], lr: 0.000100, loss: 0.6941, CELoss: 0.6941, 
2022-10-21 07:38:24 - train: epoch 0078, iter [01500, 02526], lr: 0.000100, loss: 0.4954, CELoss: 0.4954, 
2022-10-21 07:39:49 - train: epoch 0078, iter [01600, 02526], lr: 0.000100, loss: 0.8168, CELoss: 0.8168, 
2022-10-21 07:41:14 - train: epoch 0078, iter [01700, 02526], lr: 0.000100, loss: 0.4816, CELoss: 0.4816, 
2022-10-21 07:42:40 - train: epoch 0078, iter [01800, 02526], lr: 0.000100, loss: 0.6719, CELoss: 0.6719, 
2022-10-21 07:44:05 - train: epoch 0078, iter [01900, 02526], lr: 0.000100, loss: 0.7987, CELoss: 0.7987, 
2022-10-21 07:45:30 - train: epoch 0078, iter [02000, 02526], lr: 0.000100, loss: 0.9680, CELoss: 0.9680, 
2022-10-21 07:46:55 - train: epoch 0078, iter [02100, 02526], lr: 0.000100, loss: 0.8396, CELoss: 0.8396, 
2022-10-21 07:48:21 - train: epoch 0078, iter [02200, 02526], lr: 0.000100, loss: 0.6590, CELoss: 0.6590, 
2022-10-21 07:49:46 - train: epoch 0078, iter [02300, 02526], lr: 0.000100, loss: 0.5288, CELoss: 0.5288, 
2022-10-21 07:51:12 - train: epoch 0078, iter [02400, 02526], lr: 0.000100, loss: 0.5739, CELoss: 0.5739, 
2022-10-21 07:52:37 - train: epoch 0078, iter [02500, 02526], lr: 0.000100, loss: 0.5817, CELoss: 0.5817, 
2022-10-21 07:53:00 - train: epoch 078, train_loss: 0.7116
2022-10-21 07:53:01 - until epoch: 078, best_metric: 30.600%
2022-10-21 07:53:01 - epoch 079 lr: 0.000100
2022-10-21 07:54:29 - train: epoch 0079, iter [00100, 02526], lr: 0.000100, loss: 0.4990, CELoss: 0.4990, 
2022-10-21 07:55:54 - train: epoch 0079, iter [00200, 02526], lr: 0.000100, loss: 0.7710, CELoss: 0.7710, 
2022-10-21 07:57:20 - train: epoch 0079, iter [00300, 02526], lr: 0.000100, loss: 1.0435, CELoss: 1.0435, 
2022-10-21 07:58:45 - train: epoch 0079, iter [00400, 02526], lr: 0.000100, loss: 0.5575, CELoss: 0.5575, 
2022-10-21 08:00:10 - train: epoch 0079, iter [00500, 02526], lr: 0.000100, loss: 0.6262, CELoss: 0.6262, 
2022-10-21 08:01:36 - train: epoch 0079, iter [00600, 02526], lr: 0.000100, loss: 0.7971, CELoss: 0.7971, 
2022-10-21 08:03:01 - train: epoch 0079, iter [00700, 02526], lr: 0.000100, loss: 0.6543, CELoss: 0.6543, 
2022-10-21 08:04:26 - train: epoch 0079, iter [00800, 02526], lr: 0.000100, loss: 1.1340, CELoss: 1.1340, 
2022-10-21 08:05:51 - train: epoch 0079, iter [00900, 02526], lr: 0.000100, loss: 0.4385, CELoss: 0.4385, 
2022-10-21 08:07:16 - train: epoch 0079, iter [01000, 02526], lr: 0.000100, loss: 0.5948, CELoss: 0.5948, 
2022-10-21 08:08:41 - train: epoch 0079, iter [01100, 02526], lr: 0.000100, loss: 0.7090, CELoss: 0.7090, 
2022-10-21 08:10:06 - train: epoch 0079, iter [01200, 02526], lr: 0.000100, loss: 0.8738, CELoss: 0.8738, 
2022-10-21 08:11:32 - train: epoch 0079, iter [01300, 02526], lr: 0.000100, loss: 0.4952, CELoss: 0.4952, 
2022-10-21 08:12:57 - train: epoch 0079, iter [01400, 02526], lr: 0.000100, loss: 0.4853, CELoss: 0.4853, 
2022-10-21 08:14:23 - train: epoch 0079, iter [01500, 02526], lr: 0.000100, loss: 0.7891, CELoss: 0.7891, 
2022-10-21 08:15:48 - train: epoch 0079, iter [01600, 02526], lr: 0.000100, loss: 0.8023, CELoss: 0.8023, 
2022-10-21 08:17:14 - train: epoch 0079, iter [01700, 02526], lr: 0.000100, loss: 0.8324, CELoss: 0.8324, 
2022-10-21 08:18:39 - train: epoch 0079, iter [01800, 02526], lr: 0.000100, loss: 0.5780, CELoss: 0.5780, 
2022-10-21 08:20:05 - train: epoch 0079, iter [01900, 02526], lr: 0.000100, loss: 0.7336, CELoss: 0.7336, 
2022-10-21 08:21:30 - train: epoch 0079, iter [02000, 02526], lr: 0.000100, loss: 0.9557, CELoss: 0.9557, 
2022-10-21 08:22:55 - train: epoch 0079, iter [02100, 02526], lr: 0.000100, loss: 1.0170, CELoss: 1.0170, 
2022-10-21 08:24:20 - train: epoch 0079, iter [02200, 02526], lr: 0.000100, loss: 1.1277, CELoss: 1.1277, 
2022-10-21 08:25:45 - train: epoch 0079, iter [02300, 02526], lr: 0.000100, loss: 0.7981, CELoss: 0.7981, 
2022-10-21 08:27:10 - train: epoch 0079, iter [02400, 02526], lr: 0.000100, loss: 0.7109, CELoss: 0.7109, 
2022-10-21 08:28:36 - train: epoch 0079, iter [02500, 02526], lr: 0.000100, loss: 0.5517, CELoss: 0.5517, 
2022-10-21 08:28:59 - train: epoch 079, train_loss: 0.7082
2022-10-21 08:29:00 - until epoch: 079, best_metric: 30.600%
2022-10-21 08:29:00 - epoch 080 lr: 0.000100
2022-10-21 08:30:28 - train: epoch 0080, iter [00100, 02526], lr: 0.000100, loss: 0.9308, CELoss: 0.9308, 
2022-10-21 08:31:53 - train: epoch 0080, iter [00200, 02526], lr: 0.000100, loss: 1.2041, CELoss: 1.2041, 
2022-10-21 08:33:19 - train: epoch 0080, iter [00300, 02526], lr: 0.000100, loss: 0.7658, CELoss: 0.7658, 
2022-10-21 08:34:44 - train: epoch 0080, iter [00400, 02526], lr: 0.000100, loss: 0.6518, CELoss: 0.6518, 
2022-10-21 08:36:10 - train: epoch 0080, iter [00500, 02526], lr: 0.000100, loss: 0.7232, CELoss: 0.7232, 
2022-10-21 08:37:35 - train: epoch 0080, iter [00600, 02526], lr: 0.000100, loss: 0.6768, CELoss: 0.6768, 
2022-10-21 08:39:00 - train: epoch 0080, iter [00700, 02526], lr: 0.000100, loss: 0.7774, CELoss: 0.7774, 
2022-10-21 08:40:26 - train: epoch 0080, iter [00800, 02526], lr: 0.000100, loss: 0.7349, CELoss: 0.7349, 
2022-10-21 08:41:51 - train: epoch 0080, iter [00900, 02526], lr: 0.000100, loss: 0.8113, CELoss: 0.8113, 
2022-10-21 08:43:16 - train: epoch 0080, iter [01000, 02526], lr: 0.000100, loss: 0.5200, CELoss: 0.5200, 
2022-10-21 08:44:42 - train: epoch 0080, iter [01100, 02526], lr: 0.000100, loss: 1.0311, CELoss: 1.0311, 
2022-10-21 08:46:07 - train: epoch 0080, iter [01200, 02526], lr: 0.000100, loss: 0.5037, CELoss: 0.5037, 
2022-10-21 08:47:33 - train: epoch 0080, iter [01300, 02526], lr: 0.000100, loss: 0.6168, CELoss: 0.6168, 
2022-10-21 08:48:58 - train: epoch 0080, iter [01400, 02526], lr: 0.000100, loss: 0.8891, CELoss: 0.8891, 
2022-10-21 08:50:24 - train: epoch 0080, iter [01500, 02526], lr: 0.000100, loss: 0.6202, CELoss: 0.6202, 
2022-10-21 08:51:49 - train: epoch 0080, iter [01600, 02526], lr: 0.000100, loss: 0.6834, CELoss: 0.6834, 
2022-10-21 08:53:14 - train: epoch 0080, iter [01700, 02526], lr: 0.000100, loss: 0.5662, CELoss: 0.5662, 
2022-10-21 08:54:40 - train: epoch 0080, iter [01800, 02526], lr: 0.000100, loss: 0.7824, CELoss: 0.7824, 
2022-10-21 08:56:05 - train: epoch 0080, iter [01900, 02526], lr: 0.000100, loss: 0.6303, CELoss: 0.6303, 
2022-10-21 08:57:30 - train: epoch 0080, iter [02000, 02526], lr: 0.000100, loss: 0.5017, CELoss: 0.5017, 
2022-10-21 08:58:56 - train: epoch 0080, iter [02100, 02526], lr: 0.000100, loss: 0.9933, CELoss: 0.9933, 
2022-10-21 09:00:21 - train: epoch 0080, iter [02200, 02526], lr: 0.000100, loss: 0.5294, CELoss: 0.5294, 
2022-10-21 09:01:46 - train: epoch 0080, iter [02300, 02526], lr: 0.000100, loss: 0.8160, CELoss: 0.8160, 
2022-10-21 09:03:12 - train: epoch 0080, iter [02400, 02526], lr: 0.000100, loss: 0.7330, CELoss: 0.7330, 
2022-10-21 09:04:37 - train: epoch 0080, iter [02500, 02526], lr: 0.000100, loss: 0.5946, CELoss: 0.5946, 
2022-10-21 09:05:00 - train: epoch 080, train_loss: 0.7089
2022-10-21 09:07:47 - eval: epoch: 080
test_loss: 0.9846914894878864
per_image_load_time: 1.405ms
per_image_inference_time: 76.795ms
exist_num_class: 150.0
mean_precision: 47.5510484875325
mean_recall: 46.23568704673951
mean_iou: 31.226065881943835
mean_dice: 44.2731693046537

2022-10-21 09:07:48 - until epoch: 080, best_metric: 31.226%
2022-10-21 09:07:48 - epoch 081 lr: 0.000010
2022-10-21 09:09:16 - train: epoch 0081, iter [00100, 02526], lr: 0.000010, loss: 0.6940, CELoss: 0.6940, 
2022-10-21 09:10:41 - train: epoch 0081, iter [00200, 02526], lr: 0.000010, loss: 0.6515, CELoss: 0.6515, 
2022-10-21 09:12:06 - train: epoch 0081, iter [00300, 02526], lr: 0.000010, loss: 0.4529, CELoss: 0.4529, 
2022-10-21 09:13:32 - train: epoch 0081, iter [00400, 02526], lr: 0.000010, loss: 0.7353, CELoss: 0.7353, 
2022-10-21 09:14:57 - train: epoch 0081, iter [00500, 02526], lr: 0.000010, loss: 0.8306, CELoss: 0.8306, 
2022-10-21 09:16:22 - train: epoch 0081, iter [00600, 02526], lr: 0.000010, loss: 0.7604, CELoss: 0.7604, 
2022-10-21 09:17:48 - train: epoch 0081, iter [00700, 02526], lr: 0.000010, loss: 0.8153, CELoss: 0.8153, 
2022-10-21 09:19:13 - train: epoch 0081, iter [00800, 02526], lr: 0.000010, loss: 1.5811, CELoss: 1.5811, 
2022-10-21 09:20:38 - train: epoch 0081, iter [00900, 02526], lr: 0.000010, loss: 0.4605, CELoss: 0.4605, 
2022-10-21 09:22:04 - train: epoch 0081, iter [01000, 02526], lr: 0.000010, loss: 0.7097, CELoss: 0.7097, 
2022-10-21 09:23:29 - train: epoch 0081, iter [01100, 02526], lr: 0.000010, loss: 0.7731, CELoss: 0.7731, 
2022-10-21 09:24:55 - train: epoch 0081, iter [01200, 02526], lr: 0.000010, loss: 0.5723, CELoss: 0.5723, 
2022-10-21 09:26:20 - train: epoch 0081, iter [01300, 02526], lr: 0.000010, loss: 0.9693, CELoss: 0.9693, 
2022-10-21 09:27:45 - train: epoch 0081, iter [01400, 02526], lr: 0.000010, loss: 0.3946, CELoss: 0.3946, 
2022-10-21 09:29:11 - train: epoch 0081, iter [01500, 02526], lr: 0.000010, loss: 0.6601, CELoss: 0.6601, 
2022-10-21 09:30:36 - train: epoch 0081, iter [01600, 02526], lr: 0.000010, loss: 0.6419, CELoss: 0.6419, 
2022-10-21 09:32:02 - train: epoch 0081, iter [01700, 02526], lr: 0.000010, loss: 0.5762, CELoss: 0.5762, 
2022-10-21 09:33:27 - train: epoch 0081, iter [01800, 02526], lr: 0.000010, loss: 0.5031, CELoss: 0.5031, 
2022-10-21 09:34:53 - train: epoch 0081, iter [01900, 02526], lr: 0.000010, loss: 0.5630, CELoss: 0.5630, 
2022-10-21 09:36:18 - train: epoch 0081, iter [02000, 02526], lr: 0.000010, loss: 0.3422, CELoss: 0.3422, 
2022-10-21 09:37:44 - train: epoch 0081, iter [02100, 02526], lr: 0.000010, loss: 0.6423, CELoss: 0.6423, 
2022-10-21 09:39:09 - train: epoch 0081, iter [02200, 02526], lr: 0.000010, loss: 0.4360, CELoss: 0.4360, 
2022-10-21 09:40:35 - train: epoch 0081, iter [02300, 02526], lr: 0.000010, loss: 0.5292, CELoss: 0.5292, 
2022-10-21 09:42:00 - train: epoch 0081, iter [02400, 02526], lr: 0.000010, loss: 0.6521, CELoss: 0.6521, 
2022-10-21 09:43:25 - train: epoch 0081, iter [02500, 02526], lr: 0.000010, loss: 0.4191, CELoss: 0.4191, 
2022-10-21 09:43:49 - train: epoch 081, train_loss: 0.6516
2022-10-21 09:43:49 - until epoch: 081, best_metric: 31.226%
2022-10-21 09:43:49 - epoch 082 lr: 0.000010
2022-10-21 09:45:18 - train: epoch 0082, iter [00100, 02526], lr: 0.000010, loss: 0.3693, CELoss: 0.3693, 
2022-10-21 09:46:43 - train: epoch 0082, iter [00200, 02526], lr: 0.000010, loss: 0.4942, CELoss: 0.4942, 
2022-10-21 09:48:09 - train: epoch 0082, iter [00300, 02526], lr: 0.000010, loss: 0.3302, CELoss: 0.3302, 
2022-10-21 09:49:34 - train: epoch 0082, iter [00400, 02526], lr: 0.000010, loss: 0.5676, CELoss: 0.5676, 
2022-10-21 09:50:59 - train: epoch 0082, iter [00500, 02526], lr: 0.000010, loss: 0.9692, CELoss: 0.9692, 
2022-10-21 09:52:25 - train: epoch 0082, iter [00600, 02526], lr: 0.000010, loss: 0.5325, CELoss: 0.5325, 
2022-10-21 09:53:50 - train: epoch 0082, iter [00700, 02526], lr: 0.000010, loss: 0.5845, CELoss: 0.5845, 
2022-10-21 09:55:15 - train: epoch 0082, iter [00800, 02526], lr: 0.000010, loss: 0.6940, CELoss: 0.6940, 
2022-10-21 09:56:41 - train: epoch 0082, iter [00900, 02526], lr: 0.000010, loss: 0.5595, CELoss: 0.5595, 
2022-10-21 09:58:06 - train: epoch 0082, iter [01000, 02526], lr: 0.000010, loss: 0.5906, CELoss: 0.5906, 
2022-10-21 09:59:32 - train: epoch 0082, iter [01100, 02526], lr: 0.000010, loss: 0.8465, CELoss: 0.8465, 
2022-10-21 10:00:57 - train: epoch 0082, iter [01200, 02526], lr: 0.000010, loss: 0.5258, CELoss: 0.5258, 
2022-10-21 10:02:23 - train: epoch 0082, iter [01300, 02526], lr: 0.000010, loss: 0.8476, CELoss: 0.8476, 
2022-10-21 10:03:48 - train: epoch 0082, iter [01400, 02526], lr: 0.000010, loss: 0.7292, CELoss: 0.7292, 
2022-10-21 10:05:14 - train: epoch 0082, iter [01500, 02526], lr: 0.000010, loss: 0.5931, CELoss: 0.5931, 
2022-10-21 10:06:40 - train: epoch 0082, iter [01600, 02526], lr: 0.000010, loss: 0.7768, CELoss: 0.7768, 
2022-10-21 10:08:05 - train: epoch 0082, iter [01700, 02526], lr: 0.000010, loss: 0.5451, CELoss: 0.5451, 
2022-10-21 10:09:30 - train: epoch 0082, iter [01800, 02526], lr: 0.000010, loss: 1.1095, CELoss: 1.1095, 
2022-10-21 10:10:56 - train: epoch 0082, iter [01900, 02526], lr: 0.000010, loss: 0.5621, CELoss: 0.5621, 
2022-10-21 10:12:21 - train: epoch 0082, iter [02000, 02526], lr: 0.000010, loss: 0.2738, CELoss: 0.2738, 
2022-10-21 10:13:47 - train: epoch 0082, iter [02100, 02526], lr: 0.000010, loss: 1.0786, CELoss: 1.0786, 
2022-10-21 10:15:12 - train: epoch 0082, iter [02200, 02526], lr: 0.000010, loss: 0.6366, CELoss: 0.6366, 
2022-10-21 10:16:38 - train: epoch 0082, iter [02300, 02526], lr: 0.000010, loss: 0.5051, CELoss: 0.5051, 
2022-10-21 10:18:03 - train: epoch 0082, iter [02400, 02526], lr: 0.000010, loss: 0.5659, CELoss: 0.5659, 
2022-10-21 10:19:28 - train: epoch 0082, iter [02500, 02526], lr: 0.000010, loss: 0.5882, CELoss: 0.5882, 
2022-10-21 10:19:52 - train: epoch 082, train_loss: 0.6306
2022-10-21 10:19:52 - until epoch: 082, best_metric: 31.226%
2022-10-21 10:19:52 - epoch 083 lr: 0.000010
2022-10-21 10:21:20 - train: epoch 0083, iter [00100, 02526], lr: 0.000010, loss: 0.4801, CELoss: 0.4801, 
2022-10-21 10:22:46 - train: epoch 0083, iter [00200, 02526], lr: 0.000010, loss: 0.4308, CELoss: 0.4308, 
2022-10-21 10:24:11 - train: epoch 0083, iter [00300, 02526], lr: 0.000010, loss: 0.3845, CELoss: 0.3845, 
2022-10-21 10:25:36 - train: epoch 0083, iter [00400, 02526], lr: 0.000010, loss: 0.5004, CELoss: 0.5004, 
2022-10-21 10:27:02 - train: epoch 0083, iter [00500, 02526], lr: 0.000010, loss: 0.7291, CELoss: 0.7291, 
2022-10-21 10:28:27 - train: epoch 0083, iter [00600, 02526], lr: 0.000010, loss: 0.4327, CELoss: 0.4327, 
2022-10-21 10:29:52 - train: epoch 0083, iter [00700, 02526], lr: 0.000010, loss: 0.9839, CELoss: 0.9839, 
2022-10-21 10:31:17 - train: epoch 0083, iter [00800, 02526], lr: 0.000010, loss: 0.2596, CELoss: 0.2596, 
2022-10-21 10:32:42 - train: epoch 0083, iter [00900, 02526], lr: 0.000010, loss: 0.5410, CELoss: 0.5410, 
2022-10-21 10:34:07 - train: epoch 0083, iter [01000, 02526], lr: 0.000010, loss: 0.5495, CELoss: 0.5495, 
2022-10-21 10:35:33 - train: epoch 0083, iter [01100, 02526], lr: 0.000010, loss: 0.4913, CELoss: 0.4913, 
2022-10-21 10:36:58 - train: epoch 0083, iter [01200, 02526], lr: 0.000010, loss: 0.6002, CELoss: 0.6002, 
2022-10-21 10:38:23 - train: epoch 0083, iter [01300, 02526], lr: 0.000010, loss: 0.4586, CELoss: 0.4586, 
2022-10-21 10:39:48 - train: epoch 0083, iter [01400, 02526], lr: 0.000010, loss: 0.7460, CELoss: 0.7460, 
2022-10-21 10:41:13 - train: epoch 0083, iter [01500, 02526], lr: 0.000010, loss: 0.6882, CELoss: 0.6882, 
2022-10-21 10:42:38 - train: epoch 0083, iter [01600, 02526], lr: 0.000010, loss: 0.6338, CELoss: 0.6338, 
2022-10-21 10:44:04 - train: epoch 0083, iter [01700, 02526], lr: 0.000010, loss: 0.5505, CELoss: 0.5505, 
2022-10-21 10:45:29 - train: epoch 0083, iter [01800, 02526], lr: 0.000010, loss: 0.7481, CELoss: 0.7481, 
2022-10-21 10:46:55 - train: epoch 0083, iter [01900, 02526], lr: 0.000010, loss: 0.8210, CELoss: 0.8210, 
2022-10-21 10:48:20 - train: epoch 0083, iter [02000, 02526], lr: 0.000010, loss: 0.4271, CELoss: 0.4271, 
2022-10-21 10:49:45 - train: epoch 0083, iter [02100, 02526], lr: 0.000010, loss: 0.9696, CELoss: 0.9696, 
2022-10-21 10:51:10 - train: epoch 0083, iter [02200, 02526], lr: 0.000010, loss: 0.4647, CELoss: 0.4647, 
2022-10-21 10:52:36 - train: epoch 0083, iter [02300, 02526], lr: 0.000010, loss: 0.7354, CELoss: 0.7354, 
2022-10-21 10:54:01 - train: epoch 0083, iter [02400, 02526], lr: 0.000010, loss: 0.5430, CELoss: 0.5430, 
2022-10-21 10:55:27 - train: epoch 0083, iter [02500, 02526], lr: 0.000010, loss: 0.5879, CELoss: 0.5879, 
2022-10-21 10:55:50 - train: epoch 083, train_loss: 0.6203
2022-10-21 10:55:51 - until epoch: 083, best_metric: 31.226%
2022-10-21 10:55:51 - epoch 084 lr: 0.000010
2022-10-21 10:57:19 - train: epoch 0084, iter [00100, 02526], lr: 0.000010, loss: 0.7029, CELoss: 0.7029, 
2022-10-21 10:58:44 - train: epoch 0084, iter [00200, 02526], lr: 0.000010, loss: 0.5889, CELoss: 0.5889, 
2022-10-21 11:00:10 - train: epoch 0084, iter [00300, 02526], lr: 0.000010, loss: 0.4441, CELoss: 0.4441, 
2022-10-21 11:01:35 - train: epoch 0084, iter [00400, 02526], lr: 0.000010, loss: 1.1094, CELoss: 1.1094, 
2022-10-21 11:03:00 - train: epoch 0084, iter [00500, 02526], lr: 0.000010, loss: 0.5952, CELoss: 0.5952, 
2022-10-21 11:04:26 - train: epoch 0084, iter [00600, 02526], lr: 0.000010, loss: 0.4921, CELoss: 0.4921, 
2022-10-21 11:05:52 - train: epoch 0084, iter [00700, 02526], lr: 0.000010, loss: 0.5244, CELoss: 0.5244, 
2022-10-21 11:07:17 - train: epoch 0084, iter [00800, 02526], lr: 0.000010, loss: 0.3090, CELoss: 0.3090, 
2022-10-21 11:08:42 - train: epoch 0084, iter [00900, 02526], lr: 0.000010, loss: 0.7951, CELoss: 0.7951, 
2022-10-21 11:10:08 - train: epoch 0084, iter [01000, 02526], lr: 0.000010, loss: 0.7801, CELoss: 0.7801, 
2022-10-21 11:11:33 - train: epoch 0084, iter [01100, 02526], lr: 0.000010, loss: 0.8850, CELoss: 0.8850, 
2022-10-21 11:12:58 - train: epoch 0084, iter [01200, 02526], lr: 0.000010, loss: 0.5812, CELoss: 0.5812, 
2022-10-21 11:14:23 - train: epoch 0084, iter [01300, 02526], lr: 0.000010, loss: 0.3394, CELoss: 0.3394, 
2022-10-21 11:15:48 - train: epoch 0084, iter [01400, 02526], lr: 0.000010, loss: 0.5867, CELoss: 0.5867, 
2022-10-21 11:17:13 - train: epoch 0084, iter [01500, 02526], lr: 0.000010, loss: 0.3457, CELoss: 0.3457, 
2022-10-21 11:18:38 - train: epoch 0084, iter [01600, 02526], lr: 0.000010, loss: 0.5245, CELoss: 0.5245, 
2022-10-21 11:20:04 - train: epoch 0084, iter [01700, 02526], lr: 0.000010, loss: 0.4949, CELoss: 0.4949, 
2022-10-21 11:21:29 - train: epoch 0084, iter [01800, 02526], lr: 0.000010, loss: 0.6844, CELoss: 0.6844, 
2022-10-21 11:22:55 - train: epoch 0084, iter [01900, 02526], lr: 0.000010, loss: 0.5562, CELoss: 0.5562, 
2022-10-21 11:24:20 - train: epoch 0084, iter [02000, 02526], lr: 0.000010, loss: 0.4191, CELoss: 0.4191, 
2022-10-21 11:25:46 - train: epoch 0084, iter [02100, 02526], lr: 0.000010, loss: 0.7524, CELoss: 0.7524, 
2022-10-21 11:27:11 - train: epoch 0084, iter [02200, 02526], lr: 0.000010, loss: 0.6595, CELoss: 0.6595, 
2022-10-21 11:28:36 - train: epoch 0084, iter [02300, 02526], lr: 0.000010, loss: 0.3779, CELoss: 0.3779, 
2022-10-21 11:30:02 - train: epoch 0084, iter [02400, 02526], lr: 0.000010, loss: 0.5062, CELoss: 0.5062, 
2022-10-21 11:31:27 - train: epoch 0084, iter [02500, 02526], lr: 0.000010, loss: 0.5483, CELoss: 0.5483, 
2022-10-21 11:31:50 - train: epoch 084, train_loss: 0.6048
2022-10-21 11:31:51 - until epoch: 084, best_metric: 31.226%
2022-10-21 11:31:51 - epoch 085 lr: 0.000010
2022-10-21 11:33:19 - train: epoch 0085, iter [00100, 02526], lr: 0.000010, loss: 0.6252, CELoss: 0.6252, 
2022-10-21 11:34:44 - train: epoch 0085, iter [00200, 02526], lr: 0.000010, loss: 0.8145, CELoss: 0.8145, 
2022-10-21 11:36:09 - train: epoch 0085, iter [00300, 02526], lr: 0.000010, loss: 0.4697, CELoss: 0.4697, 
2022-10-21 11:37:35 - train: epoch 0085, iter [00400, 02526], lr: 0.000010, loss: 0.9246, CELoss: 0.9246, 
2022-10-21 11:39:00 - train: epoch 0085, iter [00500, 02526], lr: 0.000010, loss: 0.5564, CELoss: 0.5564, 
2022-10-21 11:40:26 - train: epoch 0085, iter [00600, 02526], lr: 0.000010, loss: 0.4040, CELoss: 0.4040, 
2022-10-21 11:41:51 - train: epoch 0085, iter [00700, 02526], lr: 0.000010, loss: 0.6034, CELoss: 0.6034, 
2022-10-21 11:43:16 - train: epoch 0085, iter [00800, 02526], lr: 0.000010, loss: 0.8437, CELoss: 0.8437, 
2022-10-21 11:44:41 - train: epoch 0085, iter [00900, 02526], lr: 0.000010, loss: 0.5282, CELoss: 0.5282, 
2022-10-21 11:46:06 - train: epoch 0085, iter [01000, 02526], lr: 0.000010, loss: 0.7647, CELoss: 0.7647, 
2022-10-21 11:47:32 - train: epoch 0085, iter [01100, 02526], lr: 0.000010, loss: 0.5200, CELoss: 0.5200, 
2022-10-21 11:48:57 - train: epoch 0085, iter [01200, 02526], lr: 0.000010, loss: 0.9545, CELoss: 0.9545, 
2022-10-21 11:50:22 - train: epoch 0085, iter [01300, 02526], lr: 0.000010, loss: 0.8924, CELoss: 0.8924, 
2022-10-21 11:51:48 - train: epoch 0085, iter [01400, 02526], lr: 0.000010, loss: 0.6575, CELoss: 0.6575, 
2022-10-21 11:53:13 - train: epoch 0085, iter [01500, 02526], lr: 0.000010, loss: 0.4522, CELoss: 0.4522, 
2022-10-21 11:54:39 - train: epoch 0085, iter [01600, 02526], lr: 0.000010, loss: 0.4272, CELoss: 0.4272, 
2022-10-21 11:56:04 - train: epoch 0085, iter [01700, 02526], lr: 0.000010, loss: 0.9135, CELoss: 0.9135, 
2022-10-21 11:57:30 - train: epoch 0085, iter [01800, 02526], lr: 0.000010, loss: 0.8217, CELoss: 0.8217, 
2022-10-21 11:58:55 - train: epoch 0085, iter [01900, 02526], lr: 0.000010, loss: 0.5010, CELoss: 0.5010, 
2022-10-21 12:00:20 - train: epoch 0085, iter [02000, 02526], lr: 0.000010, loss: 0.7822, CELoss: 0.7822, 
2022-10-21 12:01:45 - train: epoch 0085, iter [02100, 02526], lr: 0.000010, loss: 0.7864, CELoss: 0.7864, 
2022-10-21 12:03:10 - train: epoch 0085, iter [02200, 02526], lr: 0.000010, loss: 0.4135, CELoss: 0.4135, 
2022-10-21 12:04:35 - train: epoch 0085, iter [02300, 02526], lr: 0.000010, loss: 0.5092, CELoss: 0.5092, 
2022-10-21 12:06:01 - train: epoch 0085, iter [02400, 02526], lr: 0.000010, loss: 0.6951, CELoss: 0.6951, 
2022-10-21 12:07:26 - train: epoch 0085, iter [02500, 02526], lr: 0.000010, loss: 0.9194, CELoss: 0.9194, 
2022-10-21 12:07:50 - train: epoch 085, train_loss: 0.6041
2022-10-21 12:10:37 - eval: epoch: 085
test_loss: 0.9350229430496693
per_image_load_time: 1.546ms
per_image_inference_time: 76.887ms
exist_num_class: 150.0
mean_precision: 49.70045439652977
mean_recall: 47.353720964220486
mean_iou: 32.97558762352619
mean_dice: 46.363720778996566

2022-10-21 12:10:38 - until epoch: 085, best_metric: 32.976%
2022-10-21 12:10:38 - epoch 086 lr: 0.000010
2022-10-21 12:12:06 - train: epoch 0086, iter [00100, 02526], lr: 0.000010, loss: 0.3695, CELoss: 0.3695, 
2022-10-21 12:13:31 - train: epoch 0086, iter [00200, 02526], lr: 0.000010, loss: 0.4660, CELoss: 0.4660, 
2022-10-21 12:14:57 - train: epoch 0086, iter [00300, 02526], lr: 0.000010, loss: 0.7696, CELoss: 0.7696, 
2022-10-21 12:16:22 - train: epoch 0086, iter [00400, 02526], lr: 0.000010, loss: 0.4231, CELoss: 0.4231, 
2022-10-21 12:17:47 - train: epoch 0086, iter [00500, 02526], lr: 0.000010, loss: 0.7545, CELoss: 0.7545, 
2022-10-21 12:19:13 - train: epoch 0086, iter [00600, 02526], lr: 0.000010, loss: 0.8511, CELoss: 0.8511, 
2022-10-21 12:20:38 - train: epoch 0086, iter [00700, 02526], lr: 0.000010, loss: 0.7812, CELoss: 0.7812, 
2022-10-21 12:22:03 - train: epoch 0086, iter [00800, 02526], lr: 0.000010, loss: 0.3314, CELoss: 0.3314, 
2022-10-21 12:23:28 - train: epoch 0086, iter [00900, 02526], lr: 0.000010, loss: 0.4677, CELoss: 0.4677, 
2022-10-21 12:24:54 - train: epoch 0086, iter [01000, 02526], lr: 0.000010, loss: 0.5570, CELoss: 0.5570, 
2022-10-21 12:26:19 - train: epoch 0086, iter [01100, 02526], lr: 0.000010, loss: 0.4484, CELoss: 0.4484, 
2022-10-21 12:27:44 - train: epoch 0086, iter [01200, 02526], lr: 0.000010, loss: 0.7631, CELoss: 0.7631, 
2022-10-21 12:29:09 - train: epoch 0086, iter [01300, 02526], lr: 0.000010, loss: 0.9152, CELoss: 0.9152, 
2022-10-21 12:30:35 - train: epoch 0086, iter [01400, 02526], lr: 0.000010, loss: 0.7165, CELoss: 0.7165, 
2022-10-21 12:32:00 - train: epoch 0086, iter [01500, 02526], lr: 0.000010, loss: 0.7167, CELoss: 0.7167, 
2022-10-21 12:33:26 - train: epoch 0086, iter [01600, 02526], lr: 0.000010, loss: 0.5783, CELoss: 0.5783, 
2022-10-21 12:34:51 - train: epoch 0086, iter [01700, 02526], lr: 0.000010, loss: 0.7637, CELoss: 0.7637, 
2022-10-21 12:36:16 - train: epoch 0086, iter [01800, 02526], lr: 0.000010, loss: 0.6911, CELoss: 0.6911, 
2022-10-21 12:37:42 - train: epoch 0086, iter [01900, 02526], lr: 0.000010, loss: 0.4487, CELoss: 0.4487, 
2022-10-21 12:39:07 - train: epoch 0086, iter [02000, 02526], lr: 0.000010, loss: 0.5659, CELoss: 0.5659, 
2022-10-21 12:40:32 - train: epoch 0086, iter [02100, 02526], lr: 0.000010, loss: 0.5953, CELoss: 0.5953, 
2022-10-21 12:41:58 - train: epoch 0086, iter [02200, 02526], lr: 0.000010, loss: 0.5630, CELoss: 0.5630, 
2022-10-21 12:43:23 - train: epoch 0086, iter [02300, 02526], lr: 0.000010, loss: 0.3625, CELoss: 0.3625, 
2022-10-21 12:44:48 - train: epoch 0086, iter [02400, 02526], lr: 0.000010, loss: 0.4295, CELoss: 0.4295, 
2022-10-21 12:46:13 - train: epoch 0086, iter [02500, 02526], lr: 0.000010, loss: 0.5309, CELoss: 0.5309, 
2022-10-21 12:46:36 - train: epoch 086, train_loss: 0.5982
2022-10-21 12:46:37 - until epoch: 086, best_metric: 32.976%
2022-10-21 12:46:37 - epoch 087 lr: 0.000010
2022-10-21 12:48:05 - train: epoch 0087, iter [00100, 02526], lr: 0.000010, loss: 0.6674, CELoss: 0.6674, 
2022-10-21 12:49:31 - train: epoch 0087, iter [00200, 02526], lr: 0.000010, loss: 0.3110, CELoss: 0.3110, 
2022-10-21 12:50:55 - train: epoch 0087, iter [00300, 02526], lr: 0.000010, loss: 0.6631, CELoss: 0.6631, 
2022-10-21 12:52:20 - train: epoch 0087, iter [00400, 02526], lr: 0.000010, loss: 0.7159, CELoss: 0.7159, 
2022-10-21 12:53:46 - train: epoch 0087, iter [00500, 02526], lr: 0.000010, loss: 0.5947, CELoss: 0.5947, 
2022-10-21 12:55:12 - train: epoch 0087, iter [00600, 02526], lr: 0.000010, loss: 0.5395, CELoss: 0.5395, 
2022-10-21 12:56:37 - train: epoch 0087, iter [00700, 02526], lr: 0.000010, loss: 0.5036, CELoss: 0.5036, 
2022-10-21 12:58:02 - train: epoch 0087, iter [00800, 02526], lr: 0.000010, loss: 0.7609, CELoss: 0.7609, 
2022-10-21 12:59:28 - train: epoch 0087, iter [00900, 02526], lr: 0.000010, loss: 0.8197, CELoss: 0.8197, 
2022-10-21 13:00:53 - train: epoch 0087, iter [01000, 02526], lr: 0.000010, loss: 0.6890, CELoss: 0.6890, 
2022-10-21 13:02:18 - train: epoch 0087, iter [01100, 02526], lr: 0.000010, loss: 0.6652, CELoss: 0.6652, 
2022-10-21 13:03:43 - train: epoch 0087, iter [01200, 02526], lr: 0.000010, loss: 0.5275, CELoss: 0.5275, 
2022-10-21 13:05:09 - train: epoch 0087, iter [01300, 02526], lr: 0.000010, loss: 0.5357, CELoss: 0.5357, 
2022-10-21 13:06:34 - train: epoch 0087, iter [01400, 02526], lr: 0.000010, loss: 0.4160, CELoss: 0.4160, 
2022-10-21 13:08:00 - train: epoch 0087, iter [01500, 02526], lr: 0.000010, loss: 0.8793, CELoss: 0.8793, 
2022-10-21 13:09:25 - train: epoch 0087, iter [01600, 02526], lr: 0.000010, loss: 0.5019, CELoss: 0.5019, 
2022-10-21 13:10:50 - train: epoch 0087, iter [01700, 02526], lr: 0.000010, loss: 0.5803, CELoss: 0.5803, 
2022-10-21 13:12:15 - train: epoch 0087, iter [01800, 02526], lr: 0.000010, loss: 0.6622, CELoss: 0.6622, 
2022-10-21 13:13:41 - train: epoch 0087, iter [01900, 02526], lr: 0.000010, loss: 0.8101, CELoss: 0.8101, 
2022-10-21 13:15:06 - train: epoch 0087, iter [02000, 02526], lr: 0.000010, loss: 0.4400, CELoss: 0.4400, 
2022-10-21 13:16:31 - train: epoch 0087, iter [02100, 02526], lr: 0.000010, loss: 0.3621, CELoss: 0.3621, 
2022-10-21 13:17:56 - train: epoch 0087, iter [02200, 02526], lr: 0.000010, loss: 0.9737, CELoss: 0.9737, 
2022-10-21 13:19:22 - train: epoch 0087, iter [02300, 02526], lr: 0.000010, loss: 0.3691, CELoss: 0.3691, 
2022-10-21 13:20:47 - train: epoch 0087, iter [02400, 02526], lr: 0.000010, loss: 0.9852, CELoss: 0.9852, 
2022-10-21 13:22:12 - train: epoch 0087, iter [02500, 02526], lr: 0.000010, loss: 0.4195, CELoss: 0.4195, 
2022-10-21 13:22:36 - train: epoch 087, train_loss: 0.5963
2022-10-21 13:22:36 - until epoch: 087, best_metric: 32.976%
2022-10-21 13:22:36 - epoch 088 lr: 0.000010
2022-10-21 13:24:05 - train: epoch 0088, iter [00100, 02526], lr: 0.000010, loss: 0.6508, CELoss: 0.6508, 
2022-10-21 13:25:30 - train: epoch 0088, iter [00200, 02526], lr: 0.000010, loss: 0.4617, CELoss: 0.4617, 
2022-10-21 13:26:55 - train: epoch 0088, iter [00300, 02526], lr: 0.000010, loss: 0.5332, CELoss: 0.5332, 
2022-10-21 13:28:20 - train: epoch 0088, iter [00400, 02526], lr: 0.000010, loss: 1.2997, CELoss: 1.2997, 
2022-10-21 13:29:46 - train: epoch 0088, iter [00500, 02526], lr: 0.000010, loss: 0.5084, CELoss: 0.5084, 
2022-10-21 13:31:11 - train: epoch 0088, iter [00600, 02526], lr: 0.000010, loss: 0.5803, CELoss: 0.5803, 
2022-10-21 13:32:37 - train: epoch 0088, iter [00700, 02526], lr: 0.000010, loss: 0.5294, CELoss: 0.5294, 
2022-10-21 13:34:02 - train: epoch 0088, iter [00800, 02526], lr: 0.000010, loss: 0.3098, CELoss: 0.3098, 
2022-10-21 13:35:27 - train: epoch 0088, iter [00900, 02526], lr: 0.000010, loss: 0.4293, CELoss: 0.4293, 
2022-10-21 13:36:52 - train: epoch 0088, iter [01000, 02526], lr: 0.000010, loss: 0.5986, CELoss: 0.5986, 
2022-10-21 13:38:18 - train: epoch 0088, iter [01100, 02526], lr: 0.000010, loss: 0.5378, CELoss: 0.5378, 
2022-10-21 13:39:43 - train: epoch 0088, iter [01200, 02526], lr: 0.000010, loss: 0.5504, CELoss: 0.5504, 
2022-10-21 13:41:08 - train: epoch 0088, iter [01300, 02526], lr: 0.000010, loss: 0.5624, CELoss: 0.5624, 
2022-10-21 13:42:34 - train: epoch 0088, iter [01400, 02526], lr: 0.000010, loss: 0.5576, CELoss: 0.5576, 
2022-10-21 13:43:59 - train: epoch 0088, iter [01500, 02526], lr: 0.000010, loss: 0.3494, CELoss: 0.3494, 
2022-10-21 13:45:25 - train: epoch 0088, iter [01600, 02526], lr: 0.000010, loss: 0.5618, CELoss: 0.5618, 
2022-10-21 13:46:50 - train: epoch 0088, iter [01700, 02526], lr: 0.000010, loss: 0.4559, CELoss: 0.4559, 
2022-10-21 13:48:16 - train: epoch 0088, iter [01800, 02526], lr: 0.000010, loss: 0.6287, CELoss: 0.6287, 
2022-10-21 13:49:41 - train: epoch 0088, iter [01900, 02526], lr: 0.000010, loss: 0.3479, CELoss: 0.3479, 
2022-10-21 13:51:06 - train: epoch 0088, iter [02000, 02526], lr: 0.000010, loss: 0.3555, CELoss: 0.3555, 
2022-10-21 13:52:31 - train: epoch 0088, iter [02100, 02526], lr: 0.000010, loss: 0.4964, CELoss: 0.4964, 
2022-10-21 13:53:57 - train: epoch 0088, iter [02200, 02526], lr: 0.000010, loss: 0.7782, CELoss: 0.7782, 
2022-10-21 13:55:22 - train: epoch 0088, iter [02300, 02526], lr: 0.000010, loss: 0.8839, CELoss: 0.8839, 
2022-10-21 13:56:47 - train: epoch 0088, iter [02400, 02526], lr: 0.000010, loss: 0.3479, CELoss: 0.3479, 
2022-10-21 13:58:12 - train: epoch 0088, iter [02500, 02526], lr: 0.000010, loss: 0.5245, CELoss: 0.5245, 
2022-10-21 13:58:36 - train: epoch 088, train_loss: 0.5905
2022-10-21 13:58:36 - until epoch: 088, best_metric: 32.976%
2022-10-21 13:58:36 - epoch 089 lr: 0.000010
2022-10-21 14:00:05 - train: epoch 0089, iter [00100, 02526], lr: 0.000010, loss: 0.6155, CELoss: 0.6155, 
2022-10-21 14:01:30 - train: epoch 0089, iter [00200, 02526], lr: 0.000010, loss: 0.5853, CELoss: 0.5853, 
2022-10-21 14:02:55 - train: epoch 0089, iter [00300, 02526], lr: 0.000010, loss: 0.8579, CELoss: 0.8579, 
2022-10-21 14:04:21 - train: epoch 0089, iter [00400, 02526], lr: 0.000010, loss: 0.3824, CELoss: 0.3824, 
2022-10-21 14:05:46 - train: epoch 0089, iter [00500, 02526], lr: 0.000010, loss: 1.0078, CELoss: 1.0078, 
2022-10-21 14:07:12 - train: epoch 0089, iter [00600, 02526], lr: 0.000010, loss: 0.5246, CELoss: 0.5246, 
2022-10-21 14:08:37 - train: epoch 0089, iter [00700, 02526], lr: 0.000010, loss: 0.5593, CELoss: 0.5593, 
2022-10-21 14:10:02 - train: epoch 0089, iter [00800, 02526], lr: 0.000010, loss: 0.5842, CELoss: 0.5842, 
2022-10-21 14:11:28 - train: epoch 0089, iter [00900, 02526], lr: 0.000010, loss: 0.3945, CELoss: 0.3945, 
2022-10-21 14:12:53 - train: epoch 0089, iter [01000, 02526], lr: 0.000010, loss: 0.5138, CELoss: 0.5138, 
2022-10-21 14:14:18 - train: epoch 0089, iter [01100, 02526], lr: 0.000010, loss: 0.5088, CELoss: 0.5088, 
2022-10-21 14:15:43 - train: epoch 0089, iter [01200, 02526], lr: 0.000010, loss: 0.6195, CELoss: 0.6195, 
2022-10-21 14:17:08 - train: epoch 0089, iter [01300, 02526], lr: 0.000010, loss: 0.6510, CELoss: 0.6510, 
2022-10-21 14:18:34 - train: epoch 0089, iter [01400, 02526], lr: 0.000010, loss: 0.7095, CELoss: 0.7095, 
2022-10-21 14:19:59 - train: epoch 0089, iter [01500, 02526], lr: 0.000010, loss: 0.5941, CELoss: 0.5941, 
2022-10-21 14:21:24 - train: epoch 0089, iter [01600, 02526], lr: 0.000010, loss: 0.5978, CELoss: 0.5978, 
2022-10-21 14:22:49 - train: epoch 0089, iter [01700, 02526], lr: 0.000010, loss: 0.5962, CELoss: 0.5962, 
2022-10-21 14:24:14 - train: epoch 0089, iter [01800, 02526], lr: 0.000010, loss: 0.6800, CELoss: 0.6800, 
2022-10-21 14:25:40 - train: epoch 0089, iter [01900, 02526], lr: 0.000010, loss: 0.6974, CELoss: 0.6974, 
2022-10-21 14:27:05 - train: epoch 0089, iter [02000, 02526], lr: 0.000010, loss: 0.7254, CELoss: 0.7254, 
2022-10-21 14:28:31 - train: epoch 0089, iter [02100, 02526], lr: 0.000010, loss: 0.5997, CELoss: 0.5997, 
2022-10-21 14:29:56 - train: epoch 0089, iter [02200, 02526], lr: 0.000010, loss: 0.4563, CELoss: 0.4563, 
2022-10-21 14:31:22 - train: epoch 0089, iter [02300, 02526], lr: 0.000010, loss: 0.5614, CELoss: 0.5614, 
2022-10-21 14:32:47 - train: epoch 0089, iter [02400, 02526], lr: 0.000010, loss: 0.3274, CELoss: 0.3274, 
2022-10-21 14:34:13 - train: epoch 0089, iter [02500, 02526], lr: 0.000010, loss: 0.3200, CELoss: 0.3200, 
2022-10-21 14:34:36 - train: epoch 089, train_loss: 0.5940
2022-10-21 14:34:37 - until epoch: 089, best_metric: 32.976%
2022-10-21 14:34:37 - epoch 090 lr: 0.000010
2022-10-21 14:36:05 - train: epoch 0090, iter [00100, 02526], lr: 0.000010, loss: 0.5350, CELoss: 0.5350, 
2022-10-21 14:37:30 - train: epoch 0090, iter [00200, 02526], lr: 0.000010, loss: 0.4762, CELoss: 0.4762, 
2022-10-21 14:38:55 - train: epoch 0090, iter [00300, 02526], lr: 0.000010, loss: 0.5512, CELoss: 0.5512, 
2022-10-21 14:40:21 - train: epoch 0090, iter [00400, 02526], lr: 0.000010, loss: 0.5190, CELoss: 0.5190, 
2022-10-21 14:41:46 - train: epoch 0090, iter [00500, 02526], lr: 0.000010, loss: 0.3661, CELoss: 0.3661, 
2022-10-21 14:43:12 - train: epoch 0090, iter [00600, 02526], lr: 0.000010, loss: 0.4332, CELoss: 0.4332, 
2022-10-21 14:44:37 - train: epoch 0090, iter [00700, 02526], lr: 0.000010, loss: 0.5505, CELoss: 0.5505, 
2022-10-21 14:46:02 - train: epoch 0090, iter [00800, 02526], lr: 0.000010, loss: 0.7423, CELoss: 0.7423, 
2022-10-21 14:47:28 - train: epoch 0090, iter [00900, 02526], lr: 0.000010, loss: 0.4693, CELoss: 0.4693, 
2022-10-21 14:48:53 - train: epoch 0090, iter [01000, 02526], lr: 0.000010, loss: 0.4949, CELoss: 0.4949, 
2022-10-21 14:50:19 - train: epoch 0090, iter [01100, 02526], lr: 0.000010, loss: 0.4848, CELoss: 0.4848, 
2022-10-21 14:51:44 - train: epoch 0090, iter [01200, 02526], lr: 0.000010, loss: 0.5361, CELoss: 0.5361, 
2022-10-21 14:53:09 - train: epoch 0090, iter [01300, 02526], lr: 0.000010, loss: 0.3469, CELoss: 0.3469, 
2022-10-21 14:54:35 - train: epoch 0090, iter [01400, 02526], lr: 0.000010, loss: 0.6605, CELoss: 0.6605, 
2022-10-21 14:56:00 - train: epoch 0090, iter [01500, 02526], lr: 0.000010, loss: 0.5295, CELoss: 0.5295, 
2022-10-21 14:57:26 - train: epoch 0090, iter [01600, 02526], lr: 0.000010, loss: 0.4263, CELoss: 0.4263, 
2022-10-21 14:58:51 - train: epoch 0090, iter [01700, 02526], lr: 0.000010, loss: 0.6454, CELoss: 0.6454, 
2022-10-21 15:00:16 - train: epoch 0090, iter [01800, 02526], lr: 0.000010, loss: 0.3993, CELoss: 0.3993, 
2022-10-21 15:01:41 - train: epoch 0090, iter [01900, 02526], lr: 0.000010, loss: 0.6689, CELoss: 0.6689, 
2022-10-21 15:03:07 - train: epoch 0090, iter [02000, 02526], lr: 0.000010, loss: 0.4095, CELoss: 0.4095, 
2022-10-21 15:04:32 - train: epoch 0090, iter [02100, 02526], lr: 0.000010, loss: 0.4314, CELoss: 0.4314, 
2022-10-21 15:05:57 - train: epoch 0090, iter [02200, 02526], lr: 0.000010, loss: 0.4246, CELoss: 0.4246, 
2022-10-21 15:07:22 - train: epoch 0090, iter [02300, 02526], lr: 0.000010, loss: 0.3570, CELoss: 0.3570, 
2022-10-21 15:08:48 - train: epoch 0090, iter [02400, 02526], lr: 0.000010, loss: 0.4159, CELoss: 0.4159, 
2022-10-21 15:10:13 - train: epoch 0090, iter [02500, 02526], lr: 0.000010, loss: 0.6518, CELoss: 0.6518, 
2022-10-21 15:10:36 - train: epoch 090, train_loss: 0.5871
2022-10-21 15:13:24 - eval: epoch: 090
test_loss: 0.9093788394331932
per_image_load_time: 1.496ms
per_image_inference_time: 76.698ms
exist_num_class: 150.0
mean_precision: 50.77201508844923
mean_recall: 47.139072264214704
mean_iou: 33.301833648739645
mean_dice: 46.71459758430486

2022-10-21 15:13:24 - until epoch: 090, best_metric: 33.302%
2022-10-21 15:13:24 - epoch 091 lr: 0.000010
2022-10-21 15:14:53 - train: epoch 0091, iter [00100, 02526], lr: 0.000010, loss: 1.3900, CELoss: 1.3900, 
2022-10-21 15:16:18 - train: epoch 0091, iter [00200, 02526], lr: 0.000010, loss: 0.4158, CELoss: 0.4158, 
2022-10-21 15:17:44 - train: epoch 0091, iter [00300, 02526], lr: 0.000010, loss: 0.5384, CELoss: 0.5384, 
2022-10-21 15:19:09 - train: epoch 0091, iter [00400, 02526], lr: 0.000010, loss: 1.0351, CELoss: 1.0351, 
2022-10-21 15:20:34 - train: epoch 0091, iter [00500, 02526], lr: 0.000010, loss: 0.4087, CELoss: 0.4087, 
2022-10-21 15:21:59 - train: epoch 0091, iter [00600, 02526], lr: 0.000010, loss: 0.3710, CELoss: 0.3710, 
2022-10-21 15:23:25 - train: epoch 0091, iter [00700, 02526], lr: 0.000010, loss: 0.5854, CELoss: 0.5854, 
2022-10-21 15:24:49 - train: epoch 0091, iter [00800, 02526], lr: 0.000010, loss: 0.4532, CELoss: 0.4532, 
2022-10-21 15:26:15 - train: epoch 0091, iter [00900, 02526], lr: 0.000010, loss: 0.3149, CELoss: 0.3149, 
2022-10-21 15:27:40 - train: epoch 0091, iter [01000, 02526], lr: 0.000010, loss: 0.4552, CELoss: 0.4552, 
2022-10-21 15:29:05 - train: epoch 0091, iter [01100, 02526], lr: 0.000010, loss: 0.4092, CELoss: 0.4092, 
2022-10-21 15:30:30 - train: epoch 0091, iter [01200, 02526], lr: 0.000010, loss: 0.6906, CELoss: 0.6906, 
2022-10-21 15:31:56 - train: epoch 0091, iter [01300, 02526], lr: 0.000010, loss: 0.5813, CELoss: 0.5813, 
2022-10-21 15:33:21 - train: epoch 0091, iter [01400, 02526], lr: 0.000010, loss: 0.4987, CELoss: 0.4987, 
2022-10-21 15:34:46 - train: epoch 0091, iter [01500, 02526], lr: 0.000010, loss: 0.4329, CELoss: 0.4329, 
2022-10-21 15:36:11 - train: epoch 0091, iter [01600, 02526], lr: 0.000010, loss: 0.8384, CELoss: 0.8384, 
2022-10-21 15:37:37 - train: epoch 0091, iter [01700, 02526], lr: 0.000010, loss: 0.5119, CELoss: 0.5119, 
2022-10-21 15:39:02 - train: epoch 0091, iter [01800, 02526], lr: 0.000010, loss: 0.6058, CELoss: 0.6058, 
2022-10-21 15:40:27 - train: epoch 0091, iter [01900, 02526], lr: 0.000010, loss: 0.5663, CELoss: 0.5663, 
2022-10-21 15:41:52 - train: epoch 0091, iter [02000, 02526], lr: 0.000010, loss: 0.3821, CELoss: 0.3821, 
2022-10-21 15:43:17 - train: epoch 0091, iter [02100, 02526], lr: 0.000010, loss: 0.5565, CELoss: 0.5565, 
2022-10-21 15:44:43 - train: epoch 0091, iter [02200, 02526], lr: 0.000010, loss: 0.7487, CELoss: 0.7487, 
2022-10-21 15:46:08 - train: epoch 0091, iter [02300, 02526], lr: 0.000010, loss: 0.3901, CELoss: 0.3901, 
2022-10-21 15:47:33 - train: epoch 0091, iter [02400, 02526], lr: 0.000010, loss: 0.5906, CELoss: 0.5906, 
2022-10-21 15:48:58 - train: epoch 0091, iter [02500, 02526], lr: 0.000010, loss: 0.6737, CELoss: 0.6737, 
2022-10-21 15:49:22 - train: epoch 091, train_loss: 0.5817
2022-10-21 15:49:22 - until epoch: 091, best_metric: 33.302%
2022-10-21 15:49:22 - epoch 092 lr: 0.000010
2022-10-21 15:50:50 - train: epoch 0092, iter [00100, 02526], lr: 0.000010, loss: 0.3866, CELoss: 0.3866, 
2022-10-21 15:52:15 - train: epoch 0092, iter [00200, 02526], lr: 0.000010, loss: 0.2220, CELoss: 0.2220, 
2022-10-21 15:53:41 - train: epoch 0092, iter [00300, 02526], lr: 0.000010, loss: 0.6933, CELoss: 0.6933, 
2022-10-21 15:55:06 - train: epoch 0092, iter [00400, 02526], lr: 0.000010, loss: 0.3544, CELoss: 0.3544, 
2022-10-21 15:56:31 - train: epoch 0092, iter [00500, 02526], lr: 0.000010, loss: 0.5826, CELoss: 0.5826, 
2022-10-21 15:57:57 - train: epoch 0092, iter [00600, 02526], lr: 0.000010, loss: 0.8069, CELoss: 0.8069, 
2022-10-21 15:59:22 - train: epoch 0092, iter [00700, 02526], lr: 0.000010, loss: 0.5024, CELoss: 0.5024, 
2022-10-21 16:00:47 - train: epoch 0092, iter [00800, 02526], lr: 0.000010, loss: 0.3854, CELoss: 0.3854, 
2022-10-21 16:02:12 - train: epoch 0092, iter [00900, 02526], lr: 0.000010, loss: 0.3362, CELoss: 0.3362, 
2022-10-21 16:03:38 - train: epoch 0092, iter [01000, 02526], lr: 0.000010, loss: 0.5296, CELoss: 0.5296, 
2022-10-21 16:05:03 - train: epoch 0092, iter [01100, 02526], lr: 0.000010, loss: 0.3872, CELoss: 0.3872, 
2022-10-21 16:06:28 - train: epoch 0092, iter [01200, 02526], lr: 0.000010, loss: 0.6155, CELoss: 0.6155, 
2022-10-21 16:07:54 - train: epoch 0092, iter [01300, 02526], lr: 0.000010, loss: 0.5526, CELoss: 0.5526, 
2022-10-21 16:09:19 - train: epoch 0092, iter [01400, 02526], lr: 0.000010, loss: 0.6105, CELoss: 0.6105, 
2022-10-21 16:10:44 - train: epoch 0092, iter [01500, 02526], lr: 0.000010, loss: 0.4889, CELoss: 0.4889, 
2022-10-21 16:12:09 - train: epoch 0092, iter [01600, 02526], lr: 0.000010, loss: 0.6016, CELoss: 0.6016, 
2022-10-21 16:13:34 - train: epoch 0092, iter [01700, 02526], lr: 0.000010, loss: 0.5318, CELoss: 0.5318, 
2022-10-21 16:15:00 - train: epoch 0092, iter [01800, 02526], lr: 0.000010, loss: 0.8102, CELoss: 0.8102, 
2022-10-21 16:16:25 - train: epoch 0092, iter [01900, 02526], lr: 0.000010, loss: 1.2146, CELoss: 1.2146, 
2022-10-21 16:17:51 - train: epoch 0092, iter [02000, 02526], lr: 0.000010, loss: 0.5687, CELoss: 0.5687, 
2022-10-21 16:19:16 - train: epoch 0092, iter [02100, 02526], lr: 0.000010, loss: 0.3310, CELoss: 0.3310, 
2022-10-21 16:20:41 - train: epoch 0092, iter [02200, 02526], lr: 0.000010, loss: 0.5166, CELoss: 0.5166, 
2022-10-21 16:22:06 - train: epoch 0092, iter [02300, 02526], lr: 0.000010, loss: 0.5771, CELoss: 0.5771, 
2022-10-21 16:23:31 - train: epoch 0092, iter [02400, 02526], lr: 0.000010, loss: 0.5480, CELoss: 0.5480, 
2022-10-21 16:24:57 - train: epoch 0092, iter [02500, 02526], lr: 0.000010, loss: 0.5682, CELoss: 0.5682, 
2022-10-21 16:25:20 - train: epoch 092, train_loss: 0.5773
2022-10-21 16:25:21 - until epoch: 092, best_metric: 33.302%
2022-10-21 16:25:21 - epoch 093 lr: 0.000010
2022-10-21 16:26:49 - train: epoch 0093, iter [00100, 02526], lr: 0.000010, loss: 0.4904, CELoss: 0.4904, 
2022-10-21 16:28:15 - train: epoch 0093, iter [00200, 02526], lr: 0.000010, loss: 0.5418, CELoss: 0.5418, 
2022-10-21 16:29:40 - train: epoch 0093, iter [00300, 02526], lr: 0.000010, loss: 0.5291, CELoss: 0.5291, 
2022-10-21 16:31:05 - train: epoch 0093, iter [00400, 02526], lr: 0.000010, loss: 0.4441, CELoss: 0.4441, 
2022-10-21 16:32:31 - train: epoch 0093, iter [00500, 02526], lr: 0.000010, loss: 0.6296, CELoss: 0.6296, 
2022-10-21 16:33:56 - train: epoch 0093, iter [00600, 02526], lr: 0.000010, loss: 1.0888, CELoss: 1.0888, 
2022-10-21 16:35:22 - train: epoch 0093, iter [00700, 02526], lr: 0.000010, loss: 0.4761, CELoss: 0.4761, 
2022-10-21 16:36:47 - train: epoch 0093, iter [00800, 02526], lr: 0.000010, loss: 0.2528, CELoss: 0.2528, 
2022-10-21 16:38:12 - train: epoch 0093, iter [00900, 02526], lr: 0.000010, loss: 0.7188, CELoss: 0.7188, 
2022-10-21 16:39:38 - train: epoch 0093, iter [01000, 02526], lr: 0.000010, loss: 0.6029, CELoss: 0.6029, 
2022-10-21 16:41:03 - train: epoch 0093, iter [01100, 02526], lr: 0.000010, loss: 0.8164, CELoss: 0.8164, 
2022-10-21 16:42:28 - train: epoch 0093, iter [01200, 02526], lr: 0.000010, loss: 0.4151, CELoss: 0.4151, 
2022-10-21 16:43:54 - train: epoch 0093, iter [01300, 02526], lr: 0.000010, loss: 1.1959, CELoss: 1.1959, 
2022-10-21 16:45:19 - train: epoch 0093, iter [01400, 02526], lr: 0.000010, loss: 0.2728, CELoss: 0.2728, 
2022-10-21 16:46:44 - train: epoch 0093, iter [01500, 02526], lr: 0.000010, loss: 0.8125, CELoss: 0.8125, 
2022-10-21 16:48:09 - train: epoch 0093, iter [01600, 02526], lr: 0.000010, loss: 0.4545, CELoss: 0.4545, 
2022-10-21 16:49:35 - train: epoch 0093, iter [01700, 02526], lr: 0.000010, loss: 0.4970, CELoss: 0.4970, 
2022-10-21 16:51:00 - train: epoch 0093, iter [01800, 02526], lr: 0.000010, loss: 0.4773, CELoss: 0.4773, 
2022-10-21 16:52:25 - train: epoch 0093, iter [01900, 02526], lr: 0.000010, loss: 0.3129, CELoss: 0.3129, 
2022-10-21 16:53:50 - train: epoch 0093, iter [02000, 02526], lr: 0.000010, loss: 0.7133, CELoss: 0.7133, 
2022-10-21 16:55:16 - train: epoch 0093, iter [02100, 02526], lr: 0.000010, loss: 0.5036, CELoss: 0.5036, 
2022-10-21 16:56:41 - train: epoch 0093, iter [02200, 02526], lr: 0.000010, loss: 0.5974, CELoss: 0.5974, 
2022-10-21 16:58:06 - train: epoch 0093, iter [02300, 02526], lr: 0.000010, loss: 0.6776, CELoss: 0.6776, 
2022-10-21 16:59:31 - train: epoch 0093, iter [02400, 02526], lr: 0.000010, loss: 0.4213, CELoss: 0.4213, 
2022-10-21 17:00:57 - train: epoch 0093, iter [02500, 02526], lr: 0.000010, loss: 0.4889, CELoss: 0.4889, 
2022-10-21 17:01:20 - train: epoch 093, train_loss: 0.5781
2022-10-21 17:01:21 - until epoch: 093, best_metric: 33.302%
2022-10-21 17:01:21 - epoch 094 lr: 0.000010
2022-10-21 17:02:49 - train: epoch 0094, iter [00100, 02526], lr: 0.000010, loss: 0.7594, CELoss: 0.7594, 
2022-10-21 17:04:15 - train: epoch 0094, iter [00200, 02526], lr: 0.000010, loss: 0.5914, CELoss: 0.5914, 
2022-10-21 17:05:40 - train: epoch 0094, iter [00300, 02526], lr: 0.000010, loss: 0.4526, CELoss: 0.4526, 
2022-10-21 17:07:05 - train: epoch 0094, iter [00400, 02526], lr: 0.000010, loss: 0.5993, CELoss: 0.5993, 
2022-10-21 17:08:31 - train: epoch 0094, iter [00500, 02526], lr: 0.000010, loss: 0.4744, CELoss: 0.4744, 
2022-10-21 17:09:56 - train: epoch 0094, iter [00600, 02526], lr: 0.000010, loss: 0.5157, CELoss: 0.5157, 
2022-10-21 17:11:22 - train: epoch 0094, iter [00700, 02526], lr: 0.000010, loss: 0.6216, CELoss: 0.6216, 
2022-10-21 17:12:47 - train: epoch 0094, iter [00800, 02526], lr: 0.000010, loss: 0.5301, CELoss: 0.5301, 
2022-10-21 17:14:12 - train: epoch 0094, iter [00900, 02526], lr: 0.000010, loss: 0.5398, CELoss: 0.5398, 
2022-10-21 17:15:38 - train: epoch 0094, iter [01000, 02526], lr: 0.000010, loss: 0.5122, CELoss: 0.5122, 
2022-10-21 17:17:03 - train: epoch 0094, iter [01100, 02526], lr: 0.000010, loss: 0.5440, CELoss: 0.5440, 
2022-10-21 17:18:28 - train: epoch 0094, iter [01200, 02526], lr: 0.000010, loss: 0.4555, CELoss: 0.4555, 
2022-10-21 17:19:53 - train: epoch 0094, iter [01300, 02526], lr: 0.000010, loss: 0.7702, CELoss: 0.7702, 
2022-10-21 17:21:19 - train: epoch 0094, iter [01400, 02526], lr: 0.000010, loss: 0.5033, CELoss: 0.5033, 
2022-10-21 17:22:44 - train: epoch 0094, iter [01500, 02526], lr: 0.000010, loss: 0.7482, CELoss: 0.7482, 
2022-10-21 17:24:10 - train: epoch 0094, iter [01600, 02526], lr: 0.000010, loss: 0.5902, CELoss: 0.5902, 
2022-10-21 17:25:35 - train: epoch 0094, iter [01700, 02526], lr: 0.000010, loss: 1.1711, CELoss: 1.1711, 
2022-10-21 17:27:00 - train: epoch 0094, iter [01800, 02526], lr: 0.000010, loss: 0.6620, CELoss: 0.6620, 
2022-10-21 17:28:25 - train: epoch 0094, iter [01900, 02526], lr: 0.000010, loss: 0.5119, CELoss: 0.5119, 
2022-10-21 17:29:50 - train: epoch 0094, iter [02000, 02526], lr: 0.000010, loss: 0.5087, CELoss: 0.5087, 
2022-10-21 17:31:15 - train: epoch 0094, iter [02100, 02526], lr: 0.000010, loss: 0.6447, CELoss: 0.6447, 
2022-10-21 17:32:41 - train: epoch 0094, iter [02200, 02526], lr: 0.000010, loss: 0.8071, CELoss: 0.8071, 
2022-10-21 17:34:06 - train: epoch 0094, iter [02300, 02526], lr: 0.000010, loss: 0.9852, CELoss: 0.9852, 
2022-10-21 17:35:31 - train: epoch 0094, iter [02400, 02526], lr: 0.000010, loss: 0.6051, CELoss: 0.6051, 
2022-10-21 17:36:56 - train: epoch 0094, iter [02500, 02526], lr: 0.000010, loss: 0.4080, CELoss: 0.4080, 
2022-10-21 17:37:19 - train: epoch 094, train_loss: 0.5760
2022-10-21 17:37:20 - until epoch: 094, best_metric: 33.302%
2022-10-21 17:37:20 - epoch 095 lr: 0.000010
2022-10-21 17:38:48 - train: epoch 0095, iter [00100, 02526], lr: 0.000010, loss: 0.4811, CELoss: 0.4811, 
2022-10-21 17:40:13 - train: epoch 0095, iter [00200, 02526], lr: 0.000010, loss: 0.4837, CELoss: 0.4837, 
2022-10-21 17:41:39 - train: epoch 0095, iter [00300, 02526], lr: 0.000010, loss: 0.5560, CELoss: 0.5560, 
2022-10-21 17:43:04 - train: epoch 0095, iter [00400, 02526], lr: 0.000010, loss: 0.5910, CELoss: 0.5910, 
2022-10-21 17:44:29 - train: epoch 0095, iter [00500, 02526], lr: 0.000010, loss: 0.3912, CELoss: 0.3912, 
2022-10-21 17:45:55 - train: epoch 0095, iter [00600, 02526], lr: 0.000010, loss: 0.3779, CELoss: 0.3779, 
2022-10-21 17:47:20 - train: epoch 0095, iter [00700, 02526], lr: 0.000010, loss: 0.4326, CELoss: 0.4326, 
2022-10-21 17:48:45 - train: epoch 0095, iter [00800, 02526], lr: 0.000010, loss: 0.4280, CELoss: 0.4280, 
2022-10-21 17:50:11 - train: epoch 0095, iter [00900, 02526], lr: 0.000010, loss: 0.4241, CELoss: 0.4241, 
2022-10-21 17:51:35 - train: epoch 0095, iter [01000, 02526], lr: 0.000010, loss: 0.6209, CELoss: 0.6209, 
2022-10-21 17:53:01 - train: epoch 0095, iter [01100, 02526], lr: 0.000010, loss: 0.4634, CELoss: 0.4634, 
2022-10-21 17:54:26 - train: epoch 0095, iter [01200, 02526], lr: 0.000010, loss: 0.5055, CELoss: 0.5055, 
2022-10-21 17:55:51 - train: epoch 0095, iter [01300, 02526], lr: 0.000010, loss: 0.5121, CELoss: 0.5121, 
2022-10-21 17:57:16 - train: epoch 0095, iter [01400, 02526], lr: 0.000010, loss: 0.3328, CELoss: 0.3328, 
2022-10-21 17:58:42 - train: epoch 0095, iter [01500, 02526], lr: 0.000010, loss: 0.7796, CELoss: 0.7796, 
2022-10-21 18:00:07 - train: epoch 0095, iter [01600, 02526], lr: 0.000010, loss: 0.4914, CELoss: 0.4914, 
2022-10-21 18:01:32 - train: epoch 0095, iter [01700, 02526], lr: 0.000010, loss: 0.4600, CELoss: 0.4600, 
2022-10-21 18:02:58 - train: epoch 0095, iter [01800, 02526], lr: 0.000010, loss: 0.6880, CELoss: 0.6880, 
2022-10-21 18:04:23 - train: epoch 0095, iter [01900, 02526], lr: 0.000010, loss: 0.6716, CELoss: 0.6716, 
2022-10-21 18:05:49 - train: epoch 0095, iter [02000, 02526], lr: 0.000010, loss: 0.3680, CELoss: 0.3680, 
2022-10-21 18:07:14 - train: epoch 0095, iter [02100, 02526], lr: 0.000010, loss: 0.3091, CELoss: 0.3091, 
2022-10-21 18:08:39 - train: epoch 0095, iter [02200, 02526], lr: 0.000010, loss: 0.7070, CELoss: 0.7070, 
2022-10-21 18:10:05 - train: epoch 0095, iter [02300, 02526], lr: 0.000010, loss: 0.3877, CELoss: 0.3877, 
2022-10-21 18:11:30 - train: epoch 0095, iter [02400, 02526], lr: 0.000010, loss: 0.5004, CELoss: 0.5004, 
2022-10-21 18:12:56 - train: epoch 0095, iter [02500, 02526], lr: 0.000010, loss: 0.5477, CELoss: 0.5477, 
2022-10-21 18:13:19 - train: epoch 095, train_loss: 0.5732
2022-10-21 18:16:06 - eval: epoch: 095
test_loss: 0.914301902294159
per_image_load_time: 1.392ms
per_image_inference_time: 76.711ms
exist_num_class: 150.0
mean_precision: 50.95928930818222
mean_recall: 47.106269284005315
mean_iou: 33.49809227895289
mean_dice: 46.88619960324402

2022-10-21 18:16:07 - until epoch: 095, best_metric: 33.498%
2022-10-21 18:16:07 - epoch 096 lr: 0.000010
2022-10-21 18:17:34 - train: epoch 0096, iter [00100, 02526], lr: 0.000010, loss: 0.4185, CELoss: 0.4185, 
2022-10-21 18:19:00 - train: epoch 0096, iter [00200, 02526], lr: 0.000010, loss: 0.4725, CELoss: 0.4725, 
2022-10-21 18:20:25 - train: epoch 0096, iter [00300, 02526], lr: 0.000010, loss: 0.6928, CELoss: 0.6928, 
2022-10-21 18:21:51 - train: epoch 0096, iter [00400, 02526], lr: 0.000010, loss: 0.3885, CELoss: 0.3885, 
2022-10-21 18:23:16 - train: epoch 0096, iter [00500, 02526], lr: 0.000010, loss: 0.5823, CELoss: 0.5823, 
2022-10-21 18:24:42 - train: epoch 0096, iter [00600, 02526], lr: 0.000010, loss: 0.3450, CELoss: 0.3450, 
2022-10-21 18:26:07 - train: epoch 0096, iter [00700, 02526], lr: 0.000010, loss: 0.4835, CELoss: 0.4835, 
2022-10-21 18:27:32 - train: epoch 0096, iter [00800, 02526], lr: 0.000010, loss: 0.5206, CELoss: 0.5206, 
2022-10-21 18:28:57 - train: epoch 0096, iter [00900, 02526], lr: 0.000010, loss: 0.8561, CELoss: 0.8561, 
2022-10-21 18:30:23 - train: epoch 0096, iter [01000, 02526], lr: 0.000010, loss: 0.8639, CELoss: 0.8639, 
2022-10-21 18:31:48 - train: epoch 0096, iter [01100, 02526], lr: 0.000010, loss: 0.5366, CELoss: 0.5366, 
2022-10-21 18:33:13 - train: epoch 0096, iter [01200, 02526], lr: 0.000010, loss: 0.4542, CELoss: 0.4542, 
2022-10-21 18:34:39 - train: epoch 0096, iter [01300, 02526], lr: 0.000010, loss: 0.4680, CELoss: 0.4680, 
2022-10-21 18:36:04 - train: epoch 0096, iter [01400, 02526], lr: 0.000010, loss: 0.4508, CELoss: 0.4508, 
2022-10-21 18:37:29 - train: epoch 0096, iter [01500, 02526], lr: 0.000010, loss: 0.8388, CELoss: 0.8388, 
2022-10-21 18:38:54 - train: epoch 0096, iter [01600, 02526], lr: 0.000010, loss: 0.5372, CELoss: 0.5372, 
2022-10-21 18:40:20 - train: epoch 0096, iter [01700, 02526], lr: 0.000010, loss: 0.8069, CELoss: 0.8069, 
2022-10-21 18:41:45 - train: epoch 0096, iter [01800, 02526], lr: 0.000010, loss: 1.0804, CELoss: 1.0804, 
2022-10-21 18:43:10 - train: epoch 0096, iter [01900, 02526], lr: 0.000010, loss: 0.7103, CELoss: 0.7103, 
2022-10-21 18:44:36 - train: epoch 0096, iter [02000, 02526], lr: 0.000010, loss: 0.6665, CELoss: 0.6665, 
2022-10-21 18:46:01 - train: epoch 0096, iter [02100, 02526], lr: 0.000010, loss: 0.4114, CELoss: 0.4114, 
2022-10-21 18:47:26 - train: epoch 0096, iter [02200, 02526], lr: 0.000010, loss: 0.6449, CELoss: 0.6449, 
2022-10-21 18:48:52 - train: epoch 0096, iter [02300, 02526], lr: 0.000010, loss: 0.6138, CELoss: 0.6138, 
2022-10-21 18:50:17 - train: epoch 0096, iter [02400, 02526], lr: 0.000010, loss: 0.4264, CELoss: 0.4264, 
2022-10-21 18:51:43 - train: epoch 0096, iter [02500, 02526], lr: 0.000010, loss: 0.6343, CELoss: 0.6343, 
2022-10-21 18:52:06 - train: epoch 096, train_loss: 0.5771
2022-10-21 18:52:07 - until epoch: 096, best_metric: 33.498%
2022-10-21 18:52:07 - epoch 097 lr: 0.000010
2022-10-21 18:53:35 - train: epoch 0097, iter [00100, 02526], lr: 0.000010, loss: 0.5871, CELoss: 0.5871, 
2022-10-21 18:55:00 - train: epoch 0097, iter [00200, 02526], lr: 0.000010, loss: 0.7988, CELoss: 0.7988, 
2022-10-21 18:56:26 - train: epoch 0097, iter [00300, 02526], lr: 0.000010, loss: 0.8419, CELoss: 0.8419, 
2022-10-21 18:57:51 - train: epoch 0097, iter [00400, 02526], lr: 0.000010, loss: 0.3913, CELoss: 0.3913, 
2022-10-21 18:59:16 - train: epoch 0097, iter [00500, 02526], lr: 0.000010, loss: 0.6305, CELoss: 0.6305, 
2022-10-21 19:00:41 - train: epoch 0097, iter [00600, 02526], lr: 0.000010, loss: 0.4054, CELoss: 0.4054, 
2022-10-21 19:02:06 - train: epoch 0097, iter [00700, 02526], lr: 0.000010, loss: 0.5117, CELoss: 0.5117, 
2022-10-21 19:03:31 - train: epoch 0097, iter [00800, 02526], lr: 0.000010, loss: 0.7328, CELoss: 0.7328, 
2022-10-21 19:04:57 - train: epoch 0097, iter [00900, 02526], lr: 0.000010, loss: 0.4506, CELoss: 0.4506, 
2022-10-21 19:06:22 - train: epoch 0097, iter [01000, 02526], lr: 0.000010, loss: 0.4057, CELoss: 0.4057, 
2022-10-21 19:07:48 - train: epoch 0097, iter [01100, 02526], lr: 0.000010, loss: 1.0261, CELoss: 1.0261, 
2022-10-21 19:09:13 - train: epoch 0097, iter [01200, 02526], lr: 0.000010, loss: 0.4428, CELoss: 0.4428, 
2022-10-21 19:10:38 - train: epoch 0097, iter [01300, 02526], lr: 0.000010, loss: 0.5309, CELoss: 0.5309, 
2022-10-21 19:12:04 - train: epoch 0097, iter [01400, 02526], lr: 0.000010, loss: 0.6887, CELoss: 0.6887, 
2022-10-21 19:13:29 - train: epoch 0097, iter [01500, 02526], lr: 0.000010, loss: 0.4483, CELoss: 0.4483, 
2022-10-21 19:14:54 - train: epoch 0097, iter [01600, 02526], lr: 0.000010, loss: 0.7364, CELoss: 0.7364, 
2022-10-21 19:16:20 - train: epoch 0097, iter [01700, 02526], lr: 0.000010, loss: 0.3958, CELoss: 0.3958, 
2022-10-21 19:17:45 - train: epoch 0097, iter [01800, 02526], lr: 0.000010, loss: 0.6020, CELoss: 0.6020, 
2022-10-21 19:19:10 - train: epoch 0097, iter [01900, 02526], lr: 0.000010, loss: 0.4956, CELoss: 0.4956, 
2022-10-21 19:20:36 - train: epoch 0097, iter [02000, 02526], lr: 0.000010, loss: 0.8796, CELoss: 0.8796, 
2022-10-21 19:22:01 - train: epoch 0097, iter [02100, 02526], lr: 0.000010, loss: 0.5285, CELoss: 0.5285, 
2022-10-21 19:23:27 - train: epoch 0097, iter [02200, 02526], lr: 0.000010, loss: 0.3394, CELoss: 0.3394, 
2022-10-21 19:24:52 - train: epoch 0097, iter [02300, 02526], lr: 0.000010, loss: 0.8217, CELoss: 0.8217, 
2022-10-21 19:26:17 - train: epoch 0097, iter [02400, 02526], lr: 0.000010, loss: 0.6634, CELoss: 0.6634, 
2022-10-21 19:27:43 - train: epoch 0097, iter [02500, 02526], lr: 0.000010, loss: 0.6282, CELoss: 0.6282, 
2022-10-21 19:28:06 - train: epoch 097, train_loss: 0.5706
2022-10-21 19:28:07 - until epoch: 097, best_metric: 33.498%
2022-10-21 19:28:07 - epoch 098 lr: 0.000010
2022-10-21 19:29:36 - train: epoch 0098, iter [00100, 02526], lr: 0.000010, loss: 0.6031, CELoss: 0.6031, 
2022-10-21 19:31:01 - train: epoch 0098, iter [00200, 02526], lr: 0.000010, loss: 0.3255, CELoss: 0.3255, 
2022-10-21 19:32:27 - train: epoch 0098, iter [00300, 02526], lr: 0.000010, loss: 0.5600, CELoss: 0.5600, 
2022-10-21 19:33:52 - train: epoch 0098, iter [00400, 02526], lr: 0.000010, loss: 0.5425, CELoss: 0.5425, 
2022-10-21 19:35:17 - train: epoch 0098, iter [00500, 02526], lr: 0.000010, loss: 0.8079, CELoss: 0.8079, 
2022-10-21 19:36:42 - train: epoch 0098, iter [00600, 02526], lr: 0.000010, loss: 0.4579, CELoss: 0.4579, 
2022-10-21 19:38:07 - train: epoch 0098, iter [00700, 02526], lr: 0.000010, loss: 0.4816, CELoss: 0.4816, 
2022-10-21 19:39:33 - train: epoch 0098, iter [00800, 02526], lr: 0.000010, loss: 0.5529, CELoss: 0.5529, 
2022-10-21 19:40:58 - train: epoch 0098, iter [00900, 02526], lr: 0.000010, loss: 0.3164, CELoss: 0.3164, 
2022-10-21 19:42:24 - train: epoch 0098, iter [01000, 02526], lr: 0.000010, loss: 0.6661, CELoss: 0.6661, 
2022-10-21 19:43:49 - train: epoch 0098, iter [01100, 02526], lr: 0.000010, loss: 0.4191, CELoss: 0.4191, 
2022-10-21 19:45:14 - train: epoch 0098, iter [01200, 02526], lr: 0.000010, loss: 1.0107, CELoss: 1.0107, 
2022-10-21 19:46:39 - train: epoch 0098, iter [01300, 02526], lr: 0.000010, loss: 0.4748, CELoss: 0.4748, 
2022-10-21 19:48:04 - train: epoch 0098, iter [01400, 02526], lr: 0.000010, loss: 0.5694, CELoss: 0.5694, 
2022-10-21 19:49:30 - train: epoch 0098, iter [01500, 02526], lr: 0.000010, loss: 0.5751, CELoss: 0.5751, 
2022-10-21 19:50:55 - train: epoch 0098, iter [01600, 02526], lr: 0.000010, loss: 0.4328, CELoss: 0.4328, 
2022-10-21 19:52:21 - train: epoch 0098, iter [01700, 02526], lr: 0.000010, loss: 0.5053, CELoss: 0.5053, 
2022-10-21 19:53:46 - train: epoch 0098, iter [01800, 02526], lr: 0.000010, loss: 0.5391, CELoss: 0.5391, 
2022-10-21 19:55:12 - train: epoch 0098, iter [01900, 02526], lr: 0.000010, loss: 0.5569, CELoss: 0.5569, 
2022-10-21 19:56:37 - train: epoch 0098, iter [02000, 02526], lr: 0.000010, loss: 0.4086, CELoss: 0.4086, 
2022-10-21 19:58:02 - train: epoch 0098, iter [02100, 02526], lr: 0.000010, loss: 0.5118, CELoss: 0.5118, 
2022-10-21 19:59:28 - train: epoch 0098, iter [02200, 02526], lr: 0.000010, loss: 0.7001, CELoss: 0.7001, 
2022-10-21 20:00:53 - train: epoch 0098, iter [02300, 02526], lr: 0.000010, loss: 0.5435, CELoss: 0.5435, 
2022-10-21 20:02:18 - train: epoch 0098, iter [02400, 02526], lr: 0.000010, loss: 0.5150, CELoss: 0.5150, 
2022-10-21 20:03:44 - train: epoch 0098, iter [02500, 02526], lr: 0.000010, loss: 0.5561, CELoss: 0.5561, 
2022-10-21 20:04:07 - train: epoch 098, train_loss: 0.5653
2022-10-21 20:04:08 - until epoch: 098, best_metric: 33.498%
2022-10-21 20:04:08 - epoch 099 lr: 0.000010
2022-10-21 20:05:35 - train: epoch 0099, iter [00100, 02526], lr: 0.000010, loss: 0.6635, CELoss: 0.6635, 
2022-10-21 20:07:01 - train: epoch 0099, iter [00200, 02526], lr: 0.000010, loss: 0.5349, CELoss: 0.5349, 
2022-10-21 20:08:26 - train: epoch 0099, iter [00300, 02526], lr: 0.000010, loss: 0.5364, CELoss: 0.5364, 
2022-10-21 20:09:51 - train: epoch 0099, iter [00400, 02526], lr: 0.000010, loss: 0.4934, CELoss: 0.4934, 
2022-10-21 20:11:17 - train: epoch 0099, iter [00500, 02526], lr: 0.000010, loss: 0.3972, CELoss: 0.3972, 
2022-10-21 20:12:42 - train: epoch 0099, iter [00600, 02526], lr: 0.000010, loss: 0.3139, CELoss: 0.3139, 
2022-10-21 20:14:07 - train: epoch 0099, iter [00700, 02526], lr: 0.000010, loss: 0.5375, CELoss: 0.5375, 
2022-10-21 20:15:33 - train: epoch 0099, iter [00800, 02526], lr: 0.000010, loss: 0.7793, CELoss: 0.7793, 
2022-10-21 20:16:58 - train: epoch 0099, iter [00900, 02526], lr: 0.000010, loss: 0.5597, CELoss: 0.5597, 
2022-10-21 20:18:23 - train: epoch 0099, iter [01000, 02526], lr: 0.000010, loss: 0.4119, CELoss: 0.4119, 
2022-10-21 20:19:49 - train: epoch 0099, iter [01100, 02526], lr: 0.000010, loss: 0.5111, CELoss: 0.5111, 
2022-10-21 20:21:14 - train: epoch 0099, iter [01200, 02526], lr: 0.000010, loss: 0.5070, CELoss: 0.5070, 
2022-10-21 20:22:40 - train: epoch 0099, iter [01300, 02526], lr: 0.000010, loss: 0.5550, CELoss: 0.5550, 
2022-10-21 20:24:05 - train: epoch 0099, iter [01400, 02526], lr: 0.000010, loss: 0.3541, CELoss: 0.3541, 
2022-10-21 20:25:30 - train: epoch 0099, iter [01500, 02526], lr: 0.000010, loss: 0.2909, CELoss: 0.2909, 
2022-10-21 20:26:55 - train: epoch 0099, iter [01600, 02526], lr: 0.000010, loss: 0.7103, CELoss: 0.7103, 
2022-10-21 20:28:21 - train: epoch 0099, iter [01700, 02526], lr: 0.000010, loss: 0.4606, CELoss: 0.4606, 
2022-10-21 20:29:46 - train: epoch 0099, iter [01800, 02526], lr: 0.000010, loss: 0.3262, CELoss: 0.3262, 
2022-10-21 20:31:11 - train: epoch 0099, iter [01900, 02526], lr: 0.000010, loss: 0.5548, CELoss: 0.5548, 
2022-10-21 20:32:37 - train: epoch 0099, iter [02000, 02526], lr: 0.000010, loss: 0.8672, CELoss: 0.8672, 
2022-10-21 20:34:02 - train: epoch 0099, iter [02100, 02526], lr: 0.000010, loss: 0.4289, CELoss: 0.4289, 
2022-10-21 20:35:27 - train: epoch 0099, iter [02200, 02526], lr: 0.000010, loss: 0.5204, CELoss: 0.5204, 
2022-10-21 20:36:52 - train: epoch 0099, iter [02300, 02526], lr: 0.000010, loss: 0.8630, CELoss: 0.8630, 
2022-10-21 20:38:18 - train: epoch 0099, iter [02400, 02526], lr: 0.000010, loss: 0.7280, CELoss: 0.7280, 
2022-10-21 20:39:43 - train: epoch 0099, iter [02500, 02526], lr: 0.000010, loss: 0.6085, CELoss: 0.6085, 
2022-10-21 20:40:06 - train: epoch 099, train_loss: 0.5621
2022-10-21 20:40:07 - until epoch: 099, best_metric: 33.498%
2022-10-21 20:40:07 - epoch 100 lr: 0.000010
2022-10-21 20:41:36 - train: epoch 0100, iter [00100, 02526], lr: 0.000010, loss: 0.7287, CELoss: 0.7287, 
2022-10-21 20:43:01 - train: epoch 0100, iter [00200, 02526], lr: 0.000010, loss: 0.6811, CELoss: 0.6811, 
2022-10-21 20:44:26 - train: epoch 0100, iter [00300, 02526], lr: 0.000010, loss: 0.4568, CELoss: 0.4568, 
2022-10-21 20:45:51 - train: epoch 0100, iter [00400, 02526], lr: 0.000010, loss: 0.7149, CELoss: 0.7149, 
2022-10-21 20:47:17 - train: epoch 0100, iter [00500, 02526], lr: 0.000010, loss: 0.6526, CELoss: 0.6526, 
2022-10-21 20:48:42 - train: epoch 0100, iter [00600, 02526], lr: 0.000010, loss: 0.8599, CELoss: 0.8599, 
2022-10-21 20:50:07 - train: epoch 0100, iter [00700, 02526], lr: 0.000010, loss: 0.6604, CELoss: 0.6604, 
2022-10-21 20:51:33 - train: epoch 0100, iter [00800, 02526], lr: 0.000010, loss: 0.3806, CELoss: 0.3806, 
2022-10-21 20:52:58 - train: epoch 0100, iter [00900, 02526], lr: 0.000010, loss: 0.2817, CELoss: 0.2817, 
2022-10-21 20:54:24 - train: epoch 0100, iter [01000, 02526], lr: 0.000010, loss: 0.5755, CELoss: 0.5755, 
2022-10-21 20:55:49 - train: epoch 0100, iter [01100, 02526], lr: 0.000010, loss: 0.6217, CELoss: 0.6217, 
2022-10-21 20:57:14 - train: epoch 0100, iter [01200, 02526], lr: 0.000010, loss: 0.6985, CELoss: 0.6985, 
2022-10-21 20:58:40 - train: epoch 0100, iter [01300, 02526], lr: 0.000010, loss: 0.4322, CELoss: 0.4322, 
2022-10-21 21:00:05 - train: epoch 0100, iter [01400, 02526], lr: 0.000010, loss: 0.5766, CELoss: 0.5766, 
2022-10-21 21:01:31 - train: epoch 0100, iter [01500, 02526], lr: 0.000010, loss: 0.7223, CELoss: 0.7223, 
2022-10-21 21:02:56 - train: epoch 0100, iter [01600, 02526], lr: 0.000010, loss: 0.6040, CELoss: 0.6040, 
2022-10-21 21:04:21 - train: epoch 0100, iter [01700, 02526], lr: 0.000010, loss: 0.3702, CELoss: 0.3702, 
2022-10-21 21:05:46 - train: epoch 0100, iter [01800, 02526], lr: 0.000010, loss: 0.6126, CELoss: 0.6126, 
2022-10-21 21:07:12 - train: epoch 0100, iter [01900, 02526], lr: 0.000010, loss: 0.6048, CELoss: 0.6048, 
2022-10-21 21:08:37 - train: epoch 0100, iter [02000, 02526], lr: 0.000010, loss: 0.5093, CELoss: 0.5093, 
2022-10-21 21:10:02 - train: epoch 0100, iter [02100, 02526], lr: 0.000010, loss: 0.5201, CELoss: 0.5201, 
2022-10-21 21:11:28 - train: epoch 0100, iter [02200, 02526], lr: 0.000010, loss: 0.4529, CELoss: 0.4529, 
2022-10-21 21:12:53 - train: epoch 0100, iter [02300, 02526], lr: 0.000010, loss: 0.4546, CELoss: 0.4546, 
2022-10-21 21:14:19 - train: epoch 0100, iter [02400, 02526], lr: 0.000010, loss: 0.3609, CELoss: 0.3609, 
2022-10-21 21:15:44 - train: epoch 0100, iter [02500, 02526], lr: 0.000010, loss: 0.5536, CELoss: 0.5536, 
2022-10-21 21:16:07 - train: epoch 100, train_loss: 0.5646
2022-10-21 21:18:54 - eval: epoch: 100
test_loss: 0.9185904571413994
per_image_load_time: 1.478ms
per_image_inference_time: 76.821ms
exist_num_class: 150.0
mean_precision: 50.852053853125526
mean_recall: 47.20021933602313
mean_iou: 33.772590310214284
mean_dice: 47.18207596468082

2022-10-21 21:18:55 - until epoch: 100, best_metric: 33.773%
2022-10-21 21:18:55 - epoch 101 lr: 0.000010
2022-10-21 21:20:23 - train: epoch 0101, iter [00100, 02526], lr: 0.000010, loss: 0.4785, CELoss: 0.4785, 
2022-10-21 21:21:49 - train: epoch 0101, iter [00200, 02526], lr: 0.000010, loss: 0.4303, CELoss: 0.4303, 
2022-10-21 21:23:14 - train: epoch 0101, iter [00300, 02526], lr: 0.000010, loss: 0.4795, CELoss: 0.4795, 
2022-10-21 21:24:39 - train: epoch 0101, iter [00400, 02526], lr: 0.000010, loss: 0.5775, CELoss: 0.5775, 
2022-10-21 21:26:04 - train: epoch 0101, iter [00500, 02526], lr: 0.000010, loss: 0.6503, CELoss: 0.6503, 
2022-10-21 21:27:30 - train: epoch 0101, iter [00600, 02526], lr: 0.000010, loss: 0.5548, CELoss: 0.5548, 
2022-10-21 21:28:55 - train: epoch 0101, iter [00700, 02526], lr: 0.000010, loss: 0.5758, CELoss: 0.5758, 
2022-10-21 21:30:20 - train: epoch 0101, iter [00800, 02526], lr: 0.000010, loss: 0.8147, CELoss: 0.8147, 
2022-10-21 21:31:46 - train: epoch 0101, iter [00900, 02526], lr: 0.000010, loss: 0.5739, CELoss: 0.5739, 
2022-10-21 21:33:12 - train: epoch 0101, iter [01000, 02526], lr: 0.000010, loss: 0.3051, CELoss: 0.3051, 
2022-10-21 21:34:37 - train: epoch 0101, iter [01100, 02526], lr: 0.000010, loss: 0.3242, CELoss: 0.3242, 
2022-10-21 21:36:02 - train: epoch 0101, iter [01200, 02526], lr: 0.000010, loss: 0.3906, CELoss: 0.3906, 
2022-10-21 21:37:27 - train: epoch 0101, iter [01300, 02526], lr: 0.000010, loss: 0.5628, CELoss: 0.5628, 
2022-10-21 21:38:52 - train: epoch 0101, iter [01400, 02526], lr: 0.000010, loss: 0.4106, CELoss: 0.4106, 
2022-10-21 21:40:17 - train: epoch 0101, iter [01500, 02526], lr: 0.000010, loss: 0.3716, CELoss: 0.3716, 
2022-10-21 21:41:43 - train: epoch 0101, iter [01600, 02526], lr: 0.000010, loss: 0.6277, CELoss: 0.6277, 
2022-10-21 21:43:08 - train: epoch 0101, iter [01700, 02526], lr: 0.000010, loss: 0.7421, CELoss: 0.7421, 
2022-10-21 21:44:33 - train: epoch 0101, iter [01800, 02526], lr: 0.000010, loss: 0.5972, CELoss: 0.5972, 
2022-10-21 21:45:59 - train: epoch 0101, iter [01900, 02526], lr: 0.000010, loss: 0.9171, CELoss: 0.9171, 
2022-10-21 21:47:24 - train: epoch 0101, iter [02000, 02526], lr: 0.000010, loss: 0.8842, CELoss: 0.8842, 
2022-10-21 21:48:49 - train: epoch 0101, iter [02100, 02526], lr: 0.000010, loss: 0.8580, CELoss: 0.8580, 
2022-10-21 21:50:14 - train: epoch 0101, iter [02200, 02526], lr: 0.000010, loss: 0.4193, CELoss: 0.4193, 
2022-10-21 21:51:40 - train: epoch 0101, iter [02300, 02526], lr: 0.000010, loss: 0.3725, CELoss: 0.3725, 
2022-10-21 21:53:05 - train: epoch 0101, iter [02400, 02526], lr: 0.000010, loss: 0.7260, CELoss: 0.7260, 
2022-10-21 21:54:30 - train: epoch 0101, iter [02500, 02526], lr: 0.000010, loss: 0.7076, CELoss: 0.7076, 
2022-10-21 21:54:54 - train: epoch 101, train_loss: 0.5619
2022-10-21 21:54:54 - until epoch: 101, best_metric: 33.773%
2022-10-21 21:54:54 - epoch 102 lr: 0.000010
2022-10-21 21:56:23 - train: epoch 0102, iter [00100, 02526], lr: 0.000010, loss: 0.7977, CELoss: 0.7977, 
2022-10-21 21:57:48 - train: epoch 0102, iter [00200, 02526], lr: 0.000010, loss: 0.2727, CELoss: 0.2727, 
2022-10-21 21:59:13 - train: epoch 0102, iter [00300, 02526], lr: 0.000010, loss: 0.5949, CELoss: 0.5949, 
2022-10-21 22:00:38 - train: epoch 0102, iter [00400, 02526], lr: 0.000010, loss: 0.5931, CELoss: 0.5931, 
2022-10-21 22:02:04 - train: epoch 0102, iter [00500, 02526], lr: 0.000010, loss: 0.8272, CELoss: 0.8272, 
2022-10-21 22:03:29 - train: epoch 0102, iter [00600, 02526], lr: 0.000010, loss: 0.6194, CELoss: 0.6194, 
2022-10-21 22:04:54 - train: epoch 0102, iter [00700, 02526], lr: 0.000010, loss: 0.5597, CELoss: 0.5597, 
2022-10-21 22:06:20 - train: epoch 0102, iter [00800, 02526], lr: 0.000010, loss: 0.3884, CELoss: 0.3884, 
2022-10-21 22:07:45 - train: epoch 0102, iter [00900, 02526], lr: 0.000010, loss: 0.4760, CELoss: 0.4760, 
2022-10-21 22:09:10 - train: epoch 0102, iter [01000, 02526], lr: 0.000010, loss: 0.5172, CELoss: 0.5172, 
2022-10-21 22:10:36 - train: epoch 0102, iter [01100, 02526], lr: 0.000010, loss: 0.6520, CELoss: 0.6520, 
2022-10-21 22:12:01 - train: epoch 0102, iter [01200, 02526], lr: 0.000010, loss: 0.6112, CELoss: 0.6112, 
2022-10-21 22:13:26 - train: epoch 0102, iter [01300, 02526], lr: 0.000010, loss: 0.5981, CELoss: 0.5981, 
2022-10-21 22:14:52 - train: epoch 0102, iter [01400, 02526], lr: 0.000010, loss: 0.6025, CELoss: 0.6025, 
2022-10-21 22:16:17 - train: epoch 0102, iter [01500, 02526], lr: 0.000010, loss: 0.6274, CELoss: 0.6274, 
2022-10-21 22:17:43 - train: epoch 0102, iter [01600, 02526], lr: 0.000010, loss: 0.3875, CELoss: 0.3875, 
2022-10-21 22:19:08 - train: epoch 0102, iter [01700, 02526], lr: 0.000010, loss: 0.6354, CELoss: 0.6354, 
2022-10-21 22:20:33 - train: epoch 0102, iter [01800, 02526], lr: 0.000010, loss: 0.5502, CELoss: 0.5502, 
2022-10-21 22:21:58 - train: epoch 0102, iter [01900, 02526], lr: 0.000010, loss: 0.4092, CELoss: 0.4092, 
2022-10-21 22:23:23 - train: epoch 0102, iter [02000, 02526], lr: 0.000010, loss: 0.8808, CELoss: 0.8808, 
2022-10-21 22:24:49 - train: epoch 0102, iter [02100, 02526], lr: 0.000010, loss: 0.5072, CELoss: 0.5072, 
2022-10-21 22:26:14 - train: epoch 0102, iter [02200, 02526], lr: 0.000010, loss: 0.4686, CELoss: 0.4686, 
2022-10-21 22:27:39 - train: epoch 0102, iter [02300, 02526], lr: 0.000010, loss: 0.6582, CELoss: 0.6582, 
2022-10-21 22:29:04 - train: epoch 0102, iter [02400, 02526], lr: 0.000010, loss: 0.7516, CELoss: 0.7516, 
2022-10-21 22:30:29 - train: epoch 0102, iter [02500, 02526], lr: 0.000010, loss: 0.5231, CELoss: 0.5231, 
2022-10-21 22:30:53 - train: epoch 102, train_loss: 0.5617
2022-10-21 22:30:53 - until epoch: 102, best_metric: 33.773%
2022-10-21 22:30:53 - epoch 103 lr: 0.000010
2022-10-21 22:32:21 - train: epoch 0103, iter [00100, 02526], lr: 0.000010, loss: 0.4285, CELoss: 0.4285, 
2022-10-21 22:33:47 - train: epoch 0103, iter [00200, 02526], lr: 0.000010, loss: 0.5433, CELoss: 0.5433, 
2022-10-21 22:35:12 - train: epoch 0103, iter [00300, 02526], lr: 0.000010, loss: 0.7908, CELoss: 0.7908, 
2022-10-21 22:36:37 - train: epoch 0103, iter [00400, 02526], lr: 0.000010, loss: 0.5570, CELoss: 0.5570, 
2022-10-21 22:38:03 - train: epoch 0103, iter [00500, 02526], lr: 0.000010, loss: 0.4649, CELoss: 0.4649, 
2022-10-21 22:39:28 - train: epoch 0103, iter [00600, 02526], lr: 0.000010, loss: 0.5934, CELoss: 0.5934, 
2022-10-21 22:40:54 - train: epoch 0103, iter [00700, 02526], lr: 0.000010, loss: 0.5147, CELoss: 0.5147, 
2022-10-21 22:42:19 - train: epoch 0103, iter [00800, 02526], lr: 0.000010, loss: 1.1840, CELoss: 1.1840, 
2022-10-21 22:43:45 - train: epoch 0103, iter [00900, 02526], lr: 0.000010, loss: 0.4813, CELoss: 0.4813, 
2022-10-21 22:45:10 - train: epoch 0103, iter [01000, 02526], lr: 0.000010, loss: 0.4054, CELoss: 0.4054, 
2022-10-21 22:46:35 - train: epoch 0103, iter [01100, 02526], lr: 0.000010, loss: 0.5458, CELoss: 0.5458, 
2022-10-21 22:48:01 - train: epoch 0103, iter [01200, 02526], lr: 0.000010, loss: 0.4619, CELoss: 0.4619, 
2022-10-21 22:49:27 - train: epoch 0103, iter [01300, 02526], lr: 0.000010, loss: 0.3671, CELoss: 0.3671, 
2022-10-21 22:50:52 - train: epoch 0103, iter [01400, 02526], lr: 0.000010, loss: 0.5402, CELoss: 0.5402, 
2022-10-21 22:52:17 - train: epoch 0103, iter [01500, 02526], lr: 0.000010, loss: 0.3794, CELoss: 0.3794, 
2022-10-21 22:53:43 - train: epoch 0103, iter [01600, 02526], lr: 0.000010, loss: 0.4266, CELoss: 0.4266, 
2022-10-21 22:55:08 - train: epoch 0103, iter [01700, 02526], lr: 0.000010, loss: 0.3112, CELoss: 0.3112, 
2022-10-21 22:56:33 - train: epoch 0103, iter [01800, 02526], lr: 0.000010, loss: 0.5452, CELoss: 0.5452, 
2022-10-21 22:57:58 - train: epoch 0103, iter [01900, 02526], lr: 0.000010, loss: 0.4052, CELoss: 0.4052, 
2022-10-21 22:59:24 - train: epoch 0103, iter [02000, 02526], lr: 0.000010, loss: 0.4114, CELoss: 0.4114, 
2022-10-21 23:00:49 - train: epoch 0103, iter [02100, 02526], lr: 0.000010, loss: 0.8595, CELoss: 0.8595, 
2022-10-21 23:02:14 - train: epoch 0103, iter [02200, 02526], lr: 0.000010, loss: 0.2579, CELoss: 0.2579, 
2022-10-21 23:03:40 - train: epoch 0103, iter [02300, 02526], lr: 0.000010, loss: 0.4417, CELoss: 0.4417, 
2022-10-21 23:05:05 - train: epoch 0103, iter [02400, 02526], lr: 0.000010, loss: 0.8957, CELoss: 0.8957, 
2022-10-21 23:06:30 - train: epoch 0103, iter [02500, 02526], lr: 0.000010, loss: 0.8668, CELoss: 0.8668, 
2022-10-21 23:06:54 - train: epoch 103, train_loss: 0.5601
2022-10-21 23:06:55 - until epoch: 103, best_metric: 33.773%
2022-10-21 23:06:55 - epoch 104 lr: 0.000010
2022-10-21 23:08:23 - train: epoch 0104, iter [00100, 02526], lr: 0.000010, loss: 0.4724, CELoss: 0.4724, 
2022-10-21 23:09:48 - train: epoch 0104, iter [00200, 02526], lr: 0.000010, loss: 0.9336, CELoss: 0.9336, 
2022-10-21 23:11:14 - train: epoch 0104, iter [00300, 02526], lr: 0.000010, loss: 0.4095, CELoss: 0.4095, 
2022-10-21 23:12:39 - train: epoch 0104, iter [00400, 02526], lr: 0.000010, loss: 0.4763, CELoss: 0.4763, 
2022-10-21 23:14:04 - train: epoch 0104, iter [00500, 02526], lr: 0.000010, loss: 0.7171, CELoss: 0.7171, 
2022-10-21 23:15:30 - train: epoch 0104, iter [00600, 02526], lr: 0.000010, loss: 0.8353, CELoss: 0.8353, 
2022-10-21 23:16:55 - train: epoch 0104, iter [00700, 02526], lr: 0.000010, loss: 0.4613, CELoss: 0.4613, 
2022-10-21 23:18:21 - train: epoch 0104, iter [00800, 02526], lr: 0.000010, loss: 0.2593, CELoss: 0.2593, 
2022-10-21 23:19:46 - train: epoch 0104, iter [00900, 02526], lr: 0.000010, loss: 0.3483, CELoss: 0.3483, 
2022-10-21 23:21:12 - train: epoch 0104, iter [01000, 02526], lr: 0.000010, loss: 0.4519, CELoss: 0.4519, 
2022-10-21 23:22:37 - train: epoch 0104, iter [01100, 02526], lr: 0.000010, loss: 0.3710, CELoss: 0.3710, 
2022-10-21 23:24:02 - train: epoch 0104, iter [01200, 02526], lr: 0.000010, loss: 0.4360, CELoss: 0.4360, 
2022-10-21 23:25:27 - train: epoch 0104, iter [01300, 02526], lr: 0.000010, loss: 1.0267, CELoss: 1.0267, 
2022-10-21 23:26:53 - train: epoch 0104, iter [01400, 02526], lr: 0.000010, loss: 0.6327, CELoss: 0.6327, 
2022-10-21 23:28:18 - train: epoch 0104, iter [01500, 02526], lr: 0.000010, loss: 0.6924, CELoss: 0.6924, 
2022-10-21 23:29:42 - train: epoch 0104, iter [01600, 02526], lr: 0.000010, loss: 0.5483, CELoss: 0.5483, 
2022-10-21 23:31:08 - train: epoch 0104, iter [01700, 02526], lr: 0.000010, loss: 0.6375, CELoss: 0.6375, 
2022-10-21 23:32:33 - train: epoch 0104, iter [01800, 02526], lr: 0.000010, loss: 0.5490, CELoss: 0.5490, 
2022-10-21 23:33:59 - train: epoch 0104, iter [01900, 02526], lr: 0.000010, loss: 0.4678, CELoss: 0.4678, 
2022-10-21 23:35:24 - train: epoch 0104, iter [02000, 02526], lr: 0.000010, loss: 0.5743, CELoss: 0.5743, 
2022-10-21 23:36:49 - train: epoch 0104, iter [02100, 02526], lr: 0.000010, loss: 0.4039, CELoss: 0.4039, 
2022-10-21 23:38:14 - train: epoch 0104, iter [02200, 02526], lr: 0.000010, loss: 0.6097, CELoss: 0.6097, 
2022-10-21 23:39:40 - train: epoch 0104, iter [02300, 02526], lr: 0.000010, loss: 0.4332, CELoss: 0.4332, 
2022-10-21 23:41:05 - train: epoch 0104, iter [02400, 02526], lr: 0.000010, loss: 0.5415, CELoss: 0.5415, 
2022-10-21 23:42:30 - train: epoch 0104, iter [02500, 02526], lr: 0.000010, loss: 0.4670, CELoss: 0.4670, 
2022-10-21 23:42:54 - train: epoch 104, train_loss: 0.5587
2022-10-21 23:42:55 - until epoch: 104, best_metric: 33.773%
2022-10-21 23:42:55 - epoch 105 lr: 0.000010
2022-10-21 23:44:23 - train: epoch 0105, iter [00100, 02526], lr: 0.000010, loss: 0.6429, CELoss: 0.6429, 
2022-10-21 23:45:48 - train: epoch 0105, iter [00200, 02526], lr: 0.000010, loss: 0.9413, CELoss: 0.9413, 
2022-10-21 23:47:13 - train: epoch 0105, iter [00300, 02526], lr: 0.000010, loss: 0.5382, CELoss: 0.5382, 
2022-10-21 23:48:39 - train: epoch 0105, iter [00400, 02526], lr: 0.000010, loss: 0.4310, CELoss: 0.4310, 
2022-10-21 23:50:04 - train: epoch 0105, iter [00500, 02526], lr: 0.000010, loss: 0.8960, CELoss: 0.8960, 
2022-10-21 23:51:30 - train: epoch 0105, iter [00600, 02526], lr: 0.000010, loss: 1.1815, CELoss: 1.1815, 
2022-10-21 23:52:55 - train: epoch 0105, iter [00700, 02526], lr: 0.000010, loss: 0.4033, CELoss: 0.4033, 
2022-10-21 23:54:20 - train: epoch 0105, iter [00800, 02526], lr: 0.000010, loss: 0.5790, CELoss: 0.5790, 
2022-10-21 23:55:46 - train: epoch 0105, iter [00900, 02526], lr: 0.000010, loss: 0.6488, CELoss: 0.6488, 
2022-10-21 23:57:11 - train: epoch 0105, iter [01000, 02526], lr: 0.000010, loss: 0.4980, CELoss: 0.4980, 
2022-10-21 23:58:36 - train: epoch 0105, iter [01100, 02526], lr: 0.000010, loss: 0.5785, CELoss: 0.5785, 
2022-10-22 00:00:02 - train: epoch 0105, iter [01200, 02526], lr: 0.000010, loss: 0.3428, CELoss: 0.3428, 
2022-10-22 00:01:27 - train: epoch 0105, iter [01300, 02526], lr: 0.000010, loss: 0.5394, CELoss: 0.5394, 
2022-10-22 00:02:52 - train: epoch 0105, iter [01400, 02526], lr: 0.000010, loss: 0.4525, CELoss: 0.4525, 
2022-10-22 00:04:18 - train: epoch 0105, iter [01500, 02526], lr: 0.000010, loss: 0.3719, CELoss: 0.3719, 
2022-10-22 00:05:43 - train: epoch 0105, iter [01600, 02526], lr: 0.000010, loss: 0.9822, CELoss: 0.9822, 
2022-10-22 00:07:08 - train: epoch 0105, iter [01700, 02526], lr: 0.000010, loss: 0.5451, CELoss: 0.5451, 
2022-10-22 00:08:34 - train: epoch 0105, iter [01800, 02526], lr: 0.000010, loss: 0.5894, CELoss: 0.5894, 
2022-10-22 00:09:59 - train: epoch 0105, iter [01900, 02526], lr: 0.000010, loss: 0.5822, CELoss: 0.5822, 
2022-10-22 00:11:24 - train: epoch 0105, iter [02000, 02526], lr: 0.000010, loss: 0.7500, CELoss: 0.7500, 
2022-10-22 00:12:50 - train: epoch 0105, iter [02100, 02526], lr: 0.000010, loss: 0.5255, CELoss: 0.5255, 
2022-10-22 00:14:16 - train: epoch 0105, iter [02200, 02526], lr: 0.000010, loss: 0.6101, CELoss: 0.6101, 
2022-10-22 00:15:41 - train: epoch 0105, iter [02300, 02526], lr: 0.000010, loss: 0.3960, CELoss: 0.3960, 
2022-10-22 00:17:06 - train: epoch 0105, iter [02400, 02526], lr: 0.000010, loss: 0.4272, CELoss: 0.4272, 
2022-10-22 00:18:32 - train: epoch 0105, iter [02500, 02526], lr: 0.000010, loss: 0.5441, CELoss: 0.5441, 
2022-10-22 00:18:55 - train: epoch 105, train_loss: 0.5555
2022-10-22 00:21:42 - eval: epoch: 105
test_loss: 0.9167022853195668
per_image_load_time: 1.478ms
per_image_inference_time: 76.961ms
exist_num_class: 150.0
mean_precision: 50.6734115230806
mean_recall: 47.64313364114305
mean_iou: 33.804754090453855
mean_dice: 47.248782342834865

2022-10-22 00:21:43 - until epoch: 105, best_metric: 33.805%
2022-10-22 00:21:43 - epoch 106 lr: 0.000010
2022-10-22 00:23:11 - train: epoch 0106, iter [00100, 02526], lr: 0.000010, loss: 0.3088, CELoss: 0.3088, 
2022-10-22 00:24:37 - train: epoch 0106, iter [00200, 02526], lr: 0.000010, loss: 0.4667, CELoss: 0.4667, 
2022-10-22 00:26:02 - train: epoch 0106, iter [00300, 02526], lr: 0.000010, loss: 0.4124, CELoss: 0.4124, 
2022-10-22 00:27:27 - train: epoch 0106, iter [00400, 02526], lr: 0.000010, loss: 0.8047, CELoss: 0.8047, 
2022-10-22 00:28:53 - train: epoch 0106, iter [00500, 02526], lr: 0.000010, loss: 0.4161, CELoss: 0.4161, 
2022-10-22 00:30:18 - train: epoch 0106, iter [00600, 02526], lr: 0.000010, loss: 0.5578, CELoss: 0.5578, 
2022-10-22 00:31:43 - train: epoch 0106, iter [00700, 02526], lr: 0.000010, loss: 0.4047, CELoss: 0.4047, 
2022-10-22 00:33:08 - train: epoch 0106, iter [00800, 02526], lr: 0.000010, loss: 0.5160, CELoss: 0.5160, 
2022-10-22 00:34:34 - train: epoch 0106, iter [00900, 02526], lr: 0.000010, loss: 0.6167, CELoss: 0.6167, 
2022-10-22 00:35:59 - train: epoch 0106, iter [01000, 02526], lr: 0.000010, loss: 0.6458, CELoss: 0.6458, 
2022-10-22 00:37:25 - train: epoch 0106, iter [01100, 02526], lr: 0.000010, loss: 0.3591, CELoss: 0.3591, 
2022-10-22 00:38:50 - train: epoch 0106, iter [01200, 02526], lr: 0.000010, loss: 0.5568, CELoss: 0.5568, 
2022-10-22 00:40:15 - train: epoch 0106, iter [01300, 02526], lr: 0.000010, loss: 0.4889, CELoss: 0.4889, 
2022-10-22 00:41:40 - train: epoch 0106, iter [01400, 02526], lr: 0.000010, loss: 0.4538, CELoss: 0.4538, 
2022-10-22 00:43:06 - train: epoch 0106, iter [01500, 02526], lr: 0.000010, loss: 0.5915, CELoss: 0.5915, 
2022-10-22 00:44:31 - train: epoch 0106, iter [01600, 02526], lr: 0.000010, loss: 0.5010, CELoss: 0.5010, 
2022-10-22 00:45:57 - train: epoch 0106, iter [01700, 02526], lr: 0.000010, loss: 0.2990, CELoss: 0.2990, 
2022-10-22 00:47:22 - train: epoch 0106, iter [01800, 02526], lr: 0.000010, loss: 0.4465, CELoss: 0.4465, 
2022-10-22 00:48:47 - train: epoch 0106, iter [01900, 02526], lr: 0.000010, loss: 0.4902, CELoss: 0.4902, 
2022-10-22 00:50:12 - train: epoch 0106, iter [02000, 02526], lr: 0.000010, loss: 0.5563, CELoss: 0.5563, 
2022-10-22 00:51:37 - train: epoch 0106, iter [02100, 02526], lr: 0.000010, loss: 0.2874, CELoss: 0.2874, 
2022-10-22 00:53:02 - train: epoch 0106, iter [02200, 02526], lr: 0.000010, loss: 0.5909, CELoss: 0.5909, 
2022-10-22 00:54:28 - train: epoch 0106, iter [02300, 02526], lr: 0.000010, loss: 0.5262, CELoss: 0.5262, 
2022-10-22 00:55:53 - train: epoch 0106, iter [02400, 02526], lr: 0.000010, loss: 0.5016, CELoss: 0.5016, 
2022-10-22 00:57:18 - train: epoch 0106, iter [02500, 02526], lr: 0.000010, loss: 0.9422, CELoss: 0.9422, 
2022-10-22 00:57:41 - train: epoch 106, train_loss: 0.5555
2022-10-22 00:57:42 - until epoch: 106, best_metric: 33.805%
2022-10-22 00:57:42 - epoch 107 lr: 0.000010
2022-10-22 00:59:10 - train: epoch 0107, iter [00100, 02526], lr: 0.000010, loss: 0.4683, CELoss: 0.4683, 
2022-10-22 01:00:36 - train: epoch 0107, iter [00200, 02526], lr: 0.000010, loss: 0.5103, CELoss: 0.5103, 
2022-10-22 01:02:01 - train: epoch 0107, iter [00300, 02526], lr: 0.000010, loss: 0.5505, CELoss: 0.5505, 
2022-10-22 01:03:26 - train: epoch 0107, iter [00400, 02526], lr: 0.000010, loss: 0.5580, CELoss: 0.5580, 
2022-10-22 01:04:52 - train: epoch 0107, iter [00500, 02526], lr: 0.000010, loss: 0.3112, CELoss: 0.3112, 
2022-10-22 01:06:17 - train: epoch 0107, iter [00600, 02526], lr: 0.000010, loss: 0.3951, CELoss: 0.3951, 
2022-10-22 01:07:43 - train: epoch 0107, iter [00700, 02526], lr: 0.000010, loss: 0.7480, CELoss: 0.7480, 
2022-10-22 01:09:08 - train: epoch 0107, iter [00800, 02526], lr: 0.000010, loss: 0.4462, CELoss: 0.4462, 
2022-10-22 01:10:33 - train: epoch 0107, iter [00900, 02526], lr: 0.000010, loss: 0.7016, CELoss: 0.7016, 
2022-10-22 01:11:58 - train: epoch 0107, iter [01000, 02526], lr: 0.000010, loss: 0.4413, CELoss: 0.4413, 
2022-10-22 01:13:24 - train: epoch 0107, iter [01100, 02526], lr: 0.000010, loss: 0.4842, CELoss: 0.4842, 
2022-10-22 01:14:49 - train: epoch 0107, iter [01200, 02526], lr: 0.000010, loss: 0.5193, CELoss: 0.5193, 
2022-10-22 01:16:14 - train: epoch 0107, iter [01300, 02526], lr: 0.000010, loss: 0.8826, CELoss: 0.8826, 
2022-10-22 01:17:40 - train: epoch 0107, iter [01400, 02526], lr: 0.000010, loss: 0.5609, CELoss: 0.5609, 
2022-10-22 01:19:05 - train: epoch 0107, iter [01500, 02526], lr: 0.000010, loss: 0.7104, CELoss: 0.7104, 
2022-10-22 01:20:30 - train: epoch 0107, iter [01600, 02526], lr: 0.000010, loss: 0.4811, CELoss: 0.4811, 
2022-10-22 01:21:56 - train: epoch 0107, iter [01700, 02526], lr: 0.000010, loss: 0.9929, CELoss: 0.9929, 
2022-10-22 01:23:21 - train: epoch 0107, iter [01800, 02526], lr: 0.000010, loss: 0.5686, CELoss: 0.5686, 
2022-10-22 01:24:46 - train: epoch 0107, iter [01900, 02526], lr: 0.000010, loss: 0.4720, CELoss: 0.4720, 
2022-10-22 01:26:11 - train: epoch 0107, iter [02000, 02526], lr: 0.000010, loss: 0.3524, CELoss: 0.3524, 
2022-10-22 01:27:36 - train: epoch 0107, iter [02100, 02526], lr: 0.000010, loss: 0.4495, CELoss: 0.4495, 
2022-10-22 01:29:01 - train: epoch 0107, iter [02200, 02526], lr: 0.000010, loss: 0.2365, CELoss: 0.2365, 
2022-10-22 01:30:27 - train: epoch 0107, iter [02300, 02526], lr: 0.000010, loss: 0.5605, CELoss: 0.5605, 
2022-10-22 01:31:52 - train: epoch 0107, iter [02400, 02526], lr: 0.000010, loss: 0.2468, CELoss: 0.2468, 
2022-10-22 01:33:18 - train: epoch 0107, iter [02500, 02526], lr: 0.000010, loss: 0.3434, CELoss: 0.3434, 
2022-10-22 01:33:41 - train: epoch 107, train_loss: 0.5558
2022-10-22 01:33:42 - until epoch: 107, best_metric: 33.805%
2022-10-22 01:33:42 - epoch 108 lr: 0.000010
2022-10-22 01:35:11 - train: epoch 0108, iter [00100, 02526], lr: 0.000010, loss: 1.4589, CELoss: 1.4589, 
2022-10-22 01:36:36 - train: epoch 0108, iter [00200, 02526], lr: 0.000010, loss: 0.4361, CELoss: 0.4361, 
2022-10-22 01:38:01 - train: epoch 0108, iter [00300, 02526], lr: 0.000010, loss: 0.4871, CELoss: 0.4871, 
2022-10-22 01:39:27 - train: epoch 0108, iter [00400, 02526], lr: 0.000010, loss: 0.7584, CELoss: 0.7584, 
2022-10-22 01:40:52 - train: epoch 0108, iter [00500, 02526], lr: 0.000010, loss: 0.6919, CELoss: 0.6919, 
2022-10-22 01:42:17 - train: epoch 0108, iter [00600, 02526], lr: 0.000010, loss: 0.6322, CELoss: 0.6322, 
2022-10-22 01:43:42 - train: epoch 0108, iter [00700, 02526], lr: 0.000010, loss: 0.3242, CELoss: 0.3242, 
2022-10-22 01:45:07 - train: epoch 0108, iter [00800, 02526], lr: 0.000010, loss: 0.7207, CELoss: 0.7207, 
2022-10-22 01:46:32 - train: epoch 0108, iter [00900, 02526], lr: 0.000010, loss: 0.3333, CELoss: 0.3333, 
2022-10-22 01:47:58 - train: epoch 0108, iter [01000, 02526], lr: 0.000010, loss: 0.2825, CELoss: 0.2825, 
2022-10-22 01:49:23 - train: epoch 0108, iter [01100, 02526], lr: 0.000010, loss: 0.2620, CELoss: 0.2620, 
2022-10-22 01:50:48 - train: epoch 0108, iter [01200, 02526], lr: 0.000010, loss: 0.4921, CELoss: 0.4921, 
2022-10-22 01:52:14 - train: epoch 0108, iter [01300, 02526], lr: 0.000010, loss: 0.3625, CELoss: 0.3625, 
2022-10-22 01:53:39 - train: epoch 0108, iter [01400, 02526], lr: 0.000010, loss: 0.5615, CELoss: 0.5615, 
2022-10-22 01:55:04 - train: epoch 0108, iter [01500, 02526], lr: 0.000010, loss: 0.2738, CELoss: 0.2738, 
2022-10-22 01:56:30 - train: epoch 0108, iter [01600, 02526], lr: 0.000010, loss: 0.5653, CELoss: 0.5653, 
2022-10-22 01:57:55 - train: epoch 0108, iter [01700, 02526], lr: 0.000010, loss: 0.6788, CELoss: 0.6788, 
2022-10-22 01:59:20 - train: epoch 0108, iter [01800, 02526], lr: 0.000010, loss: 0.6437, CELoss: 0.6437, 
2022-10-22 02:00:46 - train: epoch 0108, iter [01900, 02526], lr: 0.000010, loss: 0.5118, CELoss: 0.5118, 
2022-10-22 02:02:11 - train: epoch 0108, iter [02000, 02526], lr: 0.000010, loss: 0.5922, CELoss: 0.5922, 
2022-10-22 02:03:36 - train: epoch 0108, iter [02100, 02526], lr: 0.000010, loss: 0.5516, CELoss: 0.5516, 
2022-10-22 02:05:01 - train: epoch 0108, iter [02200, 02526], lr: 0.000010, loss: 0.5647, CELoss: 0.5647, 
2022-10-22 02:06:26 - train: epoch 0108, iter [02300, 02526], lr: 0.000010, loss: 0.3902, CELoss: 0.3902, 
2022-10-22 02:07:52 - train: epoch 0108, iter [02400, 02526], lr: 0.000010, loss: 0.4912, CELoss: 0.4912, 
2022-10-22 02:09:17 - train: epoch 0108, iter [02500, 02526], lr: 0.000010, loss: 0.5579, CELoss: 0.5579, 
2022-10-22 02:09:40 - train: epoch 108, train_loss: 0.5523
2022-10-22 02:09:41 - until epoch: 108, best_metric: 33.805%
2022-10-22 02:09:41 - epoch 109 lr: 0.000010
2022-10-22 02:11:09 - train: epoch 0109, iter [00100, 02526], lr: 0.000010, loss: 0.6539, CELoss: 0.6539, 
2022-10-22 02:12:34 - train: epoch 0109, iter [00200, 02526], lr: 0.000010, loss: 0.4938, CELoss: 0.4938, 
2022-10-22 02:14:00 - train: epoch 0109, iter [00300, 02526], lr: 0.000010, loss: 0.6017, CELoss: 0.6017, 
2022-10-22 02:15:25 - train: epoch 0109, iter [00400, 02526], lr: 0.000010, loss: 0.3053, CELoss: 0.3053, 
2022-10-22 02:16:50 - train: epoch 0109, iter [00500, 02526], lr: 0.000010, loss: 0.4615, CELoss: 0.4615, 
2022-10-22 02:18:16 - train: epoch 0109, iter [00600, 02526], lr: 0.000010, loss: 0.4903, CELoss: 0.4903, 
2022-10-22 02:19:41 - train: epoch 0109, iter [00700, 02526], lr: 0.000010, loss: 0.8195, CELoss: 0.8195, 
2022-10-22 02:21:06 - train: epoch 0109, iter [00800, 02526], lr: 0.000010, loss: 0.4382, CELoss: 0.4382, 
2022-10-22 02:22:31 - train: epoch 0109, iter [00900, 02526], lr: 0.000010, loss: 0.7410, CELoss: 0.7410, 
2022-10-22 02:23:57 - train: epoch 0109, iter [01000, 02526], lr: 0.000010, loss: 0.5000, CELoss: 0.5000, 
2022-10-22 02:25:22 - train: epoch 0109, iter [01100, 02526], lr: 0.000010, loss: 0.4211, CELoss: 0.4211, 
2022-10-22 02:26:47 - train: epoch 0109, iter [01200, 02526], lr: 0.000010, loss: 0.5949, CELoss: 0.5949, 
2022-10-22 02:28:13 - train: epoch 0109, iter [01300, 02526], lr: 0.000010, loss: 0.5795, CELoss: 0.5795, 
2022-10-22 02:29:38 - train: epoch 0109, iter [01400, 02526], lr: 0.000010, loss: 0.8268, CELoss: 0.8268, 
2022-10-22 02:31:03 - train: epoch 0109, iter [01500, 02526], lr: 0.000010, loss: 0.4817, CELoss: 0.4817, 
2022-10-22 02:32:29 - train: epoch 0109, iter [01600, 02526], lr: 0.000010, loss: 0.5497, CELoss: 0.5497, 
2022-10-22 02:33:54 - train: epoch 0109, iter [01700, 02526], lr: 0.000010, loss: 0.2935, CELoss: 0.2935, 
2022-10-22 02:35:19 - train: epoch 0109, iter [01800, 02526], lr: 0.000010, loss: 0.4318, CELoss: 0.4318, 
2022-10-22 02:36:44 - train: epoch 0109, iter [01900, 02526], lr: 0.000010, loss: 0.8831, CELoss: 0.8831, 
2022-10-22 02:38:09 - train: epoch 0109, iter [02000, 02526], lr: 0.000010, loss: 0.9275, CELoss: 0.9275, 
2022-10-22 02:39:34 - train: epoch 0109, iter [02100, 02526], lr: 0.000010, loss: 0.8788, CELoss: 0.8788, 
2022-10-22 02:41:00 - train: epoch 0109, iter [02200, 02526], lr: 0.000010, loss: 0.3461, CELoss: 0.3461, 
2022-10-22 02:42:26 - train: epoch 0109, iter [02300, 02526], lr: 0.000010, loss: 0.4767, CELoss: 0.4767, 
2022-10-22 02:43:50 - train: epoch 0109, iter [02400, 02526], lr: 0.000010, loss: 0.5259, CELoss: 0.5259, 
2022-10-22 02:45:16 - train: epoch 0109, iter [02500, 02526], lr: 0.000010, loss: 0.4316, CELoss: 0.4316, 
2022-10-22 02:45:39 - train: epoch 109, train_loss: 0.5517
2022-10-22 02:45:40 - until epoch: 109, best_metric: 33.805%
2022-10-22 02:45:40 - epoch 110 lr: 0.000010
2022-10-22 02:47:08 - train: epoch 0110, iter [00100, 02526], lr: 0.000010, loss: 0.4547, CELoss: 0.4547, 
2022-10-22 02:48:33 - train: epoch 0110, iter [00200, 02526], lr: 0.000010, loss: 0.6217, CELoss: 0.6217, 
2022-10-22 02:49:58 - train: epoch 0110, iter [00300, 02526], lr: 0.000010, loss: 0.5074, CELoss: 0.5074, 
2022-10-22 02:51:23 - train: epoch 0110, iter [00400, 02526], lr: 0.000010, loss: 0.3790, CELoss: 0.3790, 
2022-10-22 02:52:48 - train: epoch 0110, iter [00500, 02526], lr: 0.000010, loss: 0.4839, CELoss: 0.4839, 
2022-10-22 02:54:13 - train: epoch 0110, iter [00600, 02526], lr: 0.000010, loss: 0.4299, CELoss: 0.4299, 
2022-10-22 02:55:39 - train: epoch 0110, iter [00700, 02526], lr: 0.000010, loss: 0.6096, CELoss: 0.6096, 
2022-10-22 02:57:03 - train: epoch 0110, iter [00800, 02526], lr: 0.000010, loss: 0.5386, CELoss: 0.5386, 
2022-10-22 02:58:28 - train: epoch 0110, iter [00900, 02526], lr: 0.000010, loss: 0.6168, CELoss: 0.6168, 
2022-10-22 02:59:54 - train: epoch 0110, iter [01000, 02526], lr: 0.000010, loss: 0.4123, CELoss: 0.4123, 
2022-10-22 03:01:19 - train: epoch 0110, iter [01100, 02526], lr: 0.000010, loss: 0.4930, CELoss: 0.4930, 
2022-10-22 03:02:44 - train: epoch 0110, iter [01200, 02526], lr: 0.000010, loss: 0.3391, CELoss: 0.3391, 
2022-10-22 03:04:09 - train: epoch 0110, iter [01300, 02526], lr: 0.000010, loss: 0.3128, CELoss: 0.3128, 
2022-10-22 03:05:35 - train: epoch 0110, iter [01400, 02526], lr: 0.000010, loss: 0.4540, CELoss: 0.4540, 
2022-10-22 03:07:00 - train: epoch 0110, iter [01500, 02526], lr: 0.000010, loss: 0.4231, CELoss: 0.4231, 
2022-10-22 03:08:26 - train: epoch 0110, iter [01600, 02526], lr: 0.000010, loss: 0.5059, CELoss: 0.5059, 
2022-10-22 03:09:51 - train: epoch 0110, iter [01700, 02526], lr: 0.000010, loss: 1.2777, CELoss: 1.2777, 
2022-10-22 03:11:16 - train: epoch 0110, iter [01800, 02526], lr: 0.000010, loss: 0.6884, CELoss: 0.6884, 
2022-10-22 03:12:41 - train: epoch 0110, iter [01900, 02526], lr: 0.000010, loss: 0.6823, CELoss: 0.6823, 
2022-10-22 03:14:07 - train: epoch 0110, iter [02000, 02526], lr: 0.000010, loss: 0.5027, CELoss: 0.5027, 
2022-10-22 03:15:32 - train: epoch 0110, iter [02100, 02526], lr: 0.000010, loss: 0.5996, CELoss: 0.5996, 
2022-10-22 03:16:57 - train: epoch 0110, iter [02200, 02526], lr: 0.000010, loss: 0.6675, CELoss: 0.6675, 
2022-10-22 03:18:22 - train: epoch 0110, iter [02300, 02526], lr: 0.000010, loss: 0.3967, CELoss: 0.3967, 
2022-10-22 03:19:48 - train: epoch 0110, iter [02400, 02526], lr: 0.000010, loss: 0.7452, CELoss: 0.7452, 
2022-10-22 03:21:13 - train: epoch 0110, iter [02500, 02526], lr: 0.000010, loss: 0.5846, CELoss: 0.5846, 
2022-10-22 03:21:36 - train: epoch 110, train_loss: 0.5490
2022-10-22 03:24:24 - eval: epoch: 110
test_loss: 0.9222421205043793
per_image_load_time: 1.695ms
per_image_inference_time: 76.894ms
exist_num_class: 150.0
mean_precision: 50.369194935534736
mean_recall: 47.32128675135127
mean_iou: 33.50158914100174
mean_dice: 46.91183216720459

2022-10-22 03:24:25 - until epoch: 110, best_metric: 33.805%
2022-10-22 03:24:25 - epoch 111 lr: 0.000010
2022-10-22 03:25:53 - train: epoch 0111, iter [00100, 02526], lr: 0.000010, loss: 0.5738, CELoss: 0.5738, 
2022-10-22 03:27:18 - train: epoch 0111, iter [00200, 02526], lr: 0.000010, loss: 0.1774, CELoss: 0.1774, 
2022-10-22 03:28:43 - train: epoch 0111, iter [00300, 02526], lr: 0.000010, loss: 0.7609, CELoss: 0.7609, 
2022-10-22 03:30:09 - train: epoch 0111, iter [00400, 02526], lr: 0.000010, loss: 0.6806, CELoss: 0.6806, 
2022-10-22 03:31:34 - train: epoch 0111, iter [00500, 02526], lr: 0.000010, loss: 0.4078, CELoss: 0.4078, 
2022-10-22 03:32:59 - train: epoch 0111, iter [00600, 02526], lr: 0.000010, loss: 0.5443, CELoss: 0.5443, 
2022-10-22 03:34:25 - train: epoch 0111, iter [00700, 02526], lr: 0.000010, loss: 0.3638, CELoss: 0.3638, 
2022-10-22 03:35:50 - train: epoch 0111, iter [00800, 02526], lr: 0.000010, loss: 0.9496, CELoss: 0.9496, 
2022-10-22 03:37:16 - train: epoch 0111, iter [00900, 02526], lr: 0.000010, loss: 0.5003, CELoss: 0.5003, 
2022-10-22 03:38:41 - train: epoch 0111, iter [01000, 02526], lr: 0.000010, loss: 0.3876, CELoss: 0.3876, 
2022-10-22 03:40:06 - train: epoch 0111, iter [01100, 02526], lr: 0.000010, loss: 0.3625, CELoss: 0.3625, 
2022-10-22 03:41:32 - train: epoch 0111, iter [01200, 02526], lr: 0.000010, loss: 0.5510, CELoss: 0.5510, 
2022-10-22 03:42:57 - train: epoch 0111, iter [01300, 02526], lr: 0.000010, loss: 0.5049, CELoss: 0.5049, 
2022-10-22 03:44:22 - train: epoch 0111, iter [01400, 02526], lr: 0.000010, loss: 0.7451, CELoss: 0.7451, 
2022-10-22 03:45:48 - train: epoch 0111, iter [01500, 02526], lr: 0.000010, loss: 0.3119, CELoss: 0.3119, 
2022-10-22 03:47:13 - train: epoch 0111, iter [01600, 02526], lr: 0.000010, loss: 0.4807, CELoss: 0.4807, 
2022-10-22 03:48:38 - train: epoch 0111, iter [01700, 02526], lr: 0.000010, loss: 0.8190, CELoss: 0.8190, 
2022-10-22 03:50:04 - train: epoch 0111, iter [01800, 02526], lr: 0.000010, loss: 0.5370, CELoss: 0.5370, 
2022-10-22 03:51:29 - train: epoch 0111, iter [01900, 02526], lr: 0.000010, loss: 0.6104, CELoss: 0.6104, 
2022-10-22 03:52:54 - train: epoch 0111, iter [02000, 02526], lr: 0.000010, loss: 0.5784, CELoss: 0.5784, 
2022-10-22 03:54:19 - train: epoch 0111, iter [02100, 02526], lr: 0.000010, loss: 0.4302, CELoss: 0.4302, 
2022-10-22 03:55:44 - train: epoch 0111, iter [02200, 02526], lr: 0.000010, loss: 0.3944, CELoss: 0.3944, 
2022-10-22 03:57:09 - train: epoch 0111, iter [02300, 02526], lr: 0.000010, loss: 0.3810, CELoss: 0.3810, 
2022-10-22 03:58:35 - train: epoch 0111, iter [02400, 02526], lr: 0.000010, loss: 0.5463, CELoss: 0.5463, 
2022-10-22 03:59:59 - train: epoch 0111, iter [02500, 02526], lr: 0.000010, loss: 0.6823, CELoss: 0.6823, 
2022-10-22 04:00:23 - train: epoch 111, train_loss: 0.5491
2022-10-22 04:00:23 - until epoch: 111, best_metric: 33.805%
2022-10-22 04:00:23 - epoch 112 lr: 0.000010
2022-10-22 04:01:51 - train: epoch 0112, iter [00100, 02526], lr: 0.000010, loss: 0.5568, CELoss: 0.5568, 
2022-10-22 04:03:17 - train: epoch 0112, iter [00200, 02526], lr: 0.000010, loss: 0.5136, CELoss: 0.5136, 
2022-10-22 04:04:42 - train: epoch 0112, iter [00300, 02526], lr: 0.000010, loss: 0.3479, CELoss: 0.3479, 
2022-10-22 04:06:07 - train: epoch 0112, iter [00400, 02526], lr: 0.000010, loss: 0.5798, CELoss: 0.5798, 
2022-10-22 04:07:33 - train: epoch 0112, iter [00500, 02526], lr: 0.000010, loss: 0.5906, CELoss: 0.5906, 
2022-10-22 04:08:58 - train: epoch 0112, iter [00600, 02526], lr: 0.000010, loss: 0.3994, CELoss: 0.3994, 
2022-10-22 04:10:23 - train: epoch 0112, iter [00700, 02526], lr: 0.000010, loss: 0.9038, CELoss: 0.9038, 
2022-10-22 04:11:48 - train: epoch 0112, iter [00800, 02526], lr: 0.000010, loss: 0.4557, CELoss: 0.4557, 
2022-10-22 04:13:14 - train: epoch 0112, iter [00900, 02526], lr: 0.000010, loss: 0.7883, CELoss: 0.7883, 
2022-10-22 04:14:39 - train: epoch 0112, iter [01000, 02526], lr: 0.000010, loss: 0.6359, CELoss: 0.6359, 
2022-10-22 04:16:04 - train: epoch 0112, iter [01100, 02526], lr: 0.000010, loss: 0.6404, CELoss: 0.6404, 
2022-10-22 04:17:29 - train: epoch 0112, iter [01200, 02526], lr: 0.000010, loss: 0.7396, CELoss: 0.7396, 
2022-10-22 04:18:55 - train: epoch 0112, iter [01300, 02526], lr: 0.000010, loss: 0.3353, CELoss: 0.3353, 
2022-10-22 04:20:20 - train: epoch 0112, iter [01400, 02526], lr: 0.000010, loss: 0.6492, CELoss: 0.6492, 
2022-10-22 04:21:45 - train: epoch 0112, iter [01500, 02526], lr: 0.000010, loss: 0.7033, CELoss: 0.7033, 
2022-10-22 04:23:10 - train: epoch 0112, iter [01600, 02526], lr: 0.000010, loss: 0.8430, CELoss: 0.8430, 
2022-10-22 04:24:35 - train: epoch 0112, iter [01700, 02526], lr: 0.000010, loss: 0.9803, CELoss: 0.9803, 
2022-10-22 04:26:00 - train: epoch 0112, iter [01800, 02526], lr: 0.000010, loss: 0.7647, CELoss: 0.7647, 
2022-10-22 04:27:25 - train: epoch 0112, iter [01900, 02526], lr: 0.000010, loss: 0.8160, CELoss: 0.8160, 
2022-10-22 04:28:51 - train: epoch 0112, iter [02000, 02526], lr: 0.000010, loss: 0.4154, CELoss: 0.4154, 
2022-10-22 04:30:16 - train: epoch 0112, iter [02100, 02526], lr: 0.000010, loss: 0.4251, CELoss: 0.4251, 
2022-10-22 04:31:41 - train: epoch 0112, iter [02200, 02526], lr: 0.000010, loss: 0.8925, CELoss: 0.8925, 
2022-10-22 04:33:06 - train: epoch 0112, iter [02300, 02526], lr: 0.000010, loss: 0.3977, CELoss: 0.3977, 
2022-10-22 04:34:31 - train: epoch 0112, iter [02400, 02526], lr: 0.000010, loss: 0.6893, CELoss: 0.6893, 
2022-10-22 04:35:56 - train: epoch 0112, iter [02500, 02526], lr: 0.000010, loss: 0.9328, CELoss: 0.9328, 
2022-10-22 04:36:19 - train: epoch 112, train_loss: 0.5434
2022-10-22 04:36:20 - until epoch: 112, best_metric: 33.805%
2022-10-22 04:36:20 - epoch 113 lr: 0.000010
2022-10-22 04:37:49 - train: epoch 0113, iter [00100, 02526], lr: 0.000010, loss: 0.7321, CELoss: 0.7321, 
2022-10-22 04:39:14 - train: epoch 0113, iter [00200, 02526], lr: 0.000010, loss: 0.3919, CELoss: 0.3919, 
2022-10-22 04:40:39 - train: epoch 0113, iter [00300, 02526], lr: 0.000010, loss: 0.3578, CELoss: 0.3578, 
2022-10-22 04:42:05 - train: epoch 0113, iter [00400, 02526], lr: 0.000010, loss: 0.7446, CELoss: 0.7446, 
2022-10-22 04:43:30 - train: epoch 0113, iter [00500, 02526], lr: 0.000010, loss: 0.4947, CELoss: 0.4947, 
2022-10-22 04:44:55 - train: epoch 0113, iter [00600, 02526], lr: 0.000010, loss: 0.5702, CELoss: 0.5702, 
2022-10-22 04:46:20 - train: epoch 0113, iter [00700, 02526], lr: 0.000010, loss: 0.3889, CELoss: 0.3889, 
2022-10-22 04:47:46 - train: epoch 0113, iter [00800, 02526], lr: 0.000010, loss: 0.5703, CELoss: 0.5703, 
2022-10-22 04:49:11 - train: epoch 0113, iter [00900, 02526], lr: 0.000010, loss: 0.7778, CELoss: 0.7778, 
2022-10-22 04:50:37 - train: epoch 0113, iter [01000, 02526], lr: 0.000010, loss: 0.6553, CELoss: 0.6553, 
2022-10-22 04:52:02 - train: epoch 0113, iter [01100, 02526], lr: 0.000010, loss: 0.6704, CELoss: 0.6704, 
2022-10-22 04:53:27 - train: epoch 0113, iter [01200, 02526], lr: 0.000010, loss: 0.5226, CELoss: 0.5226, 
2022-10-22 04:54:52 - train: epoch 0113, iter [01300, 02526], lr: 0.000010, loss: 0.3760, CELoss: 0.3760, 
2022-10-22 04:56:18 - train: epoch 0113, iter [01400, 02526], lr: 0.000010, loss: 0.8395, CELoss: 0.8395, 
2022-10-22 04:57:43 - train: epoch 0113, iter [01500, 02526], lr: 0.000010, loss: 0.6673, CELoss: 0.6673, 
2022-10-22 04:59:08 - train: epoch 0113, iter [01600, 02526], lr: 0.000010, loss: 0.3563, CELoss: 0.3563, 
2022-10-22 05:00:34 - train: epoch 0113, iter [01700, 02526], lr: 0.000010, loss: 0.7122, CELoss: 0.7122, 
2022-10-22 05:01:59 - train: epoch 0113, iter [01800, 02526], lr: 0.000010, loss: 0.6091, CELoss: 0.6091, 
2022-10-22 05:03:25 - train: epoch 0113, iter [01900, 02526], lr: 0.000010, loss: 0.7266, CELoss: 0.7266, 
2022-10-22 05:04:50 - train: epoch 0113, iter [02000, 02526], lr: 0.000010, loss: 0.6911, CELoss: 0.6911, 
2022-10-22 05:06:15 - train: epoch 0113, iter [02100, 02526], lr: 0.000010, loss: 0.7450, CELoss: 0.7450, 
2022-10-22 05:07:41 - train: epoch 0113, iter [02200, 02526], lr: 0.000010, loss: 0.5635, CELoss: 0.5635, 
2022-10-22 05:09:06 - train: epoch 0113, iter [02300, 02526], lr: 0.000010, loss: 0.4492, CELoss: 0.4492, 
2022-10-22 05:10:31 - train: epoch 0113, iter [02400, 02526], lr: 0.000010, loss: 0.7404, CELoss: 0.7404, 
2022-10-22 05:11:56 - train: epoch 0113, iter [02500, 02526], lr: 0.000010, loss: 0.4248, CELoss: 0.4248, 
2022-10-22 05:12:20 - train: epoch 113, train_loss: 0.5454
2022-10-22 05:12:21 - until epoch: 113, best_metric: 33.805%
2022-10-22 05:12:21 - epoch 114 lr: 0.000010
2022-10-22 05:13:49 - train: epoch 0114, iter [00100, 02526], lr: 0.000010, loss: 0.4780, CELoss: 0.4780, 
2022-10-22 05:15:14 - train: epoch 0114, iter [00200, 02526], lr: 0.000010, loss: 0.6488, CELoss: 0.6488, 
2022-10-22 05:16:39 - train: epoch 0114, iter [00300, 02526], lr: 0.000010, loss: 1.2900, CELoss: 1.2900, 
2022-10-22 05:18:04 - train: epoch 0114, iter [00400, 02526], lr: 0.000010, loss: 0.5528, CELoss: 0.5528, 
2022-10-22 05:19:29 - train: epoch 0114, iter [00500, 02526], lr: 0.000010, loss: 0.4377, CELoss: 0.4377, 
2022-10-22 05:20:55 - train: epoch 0114, iter [00600, 02526], lr: 0.000010, loss: 0.5506, CELoss: 0.5506, 
2022-10-22 05:22:20 - train: epoch 0114, iter [00700, 02526], lr: 0.000010, loss: 0.6158, CELoss: 0.6158, 
2022-10-22 05:23:45 - train: epoch 0114, iter [00800, 02526], lr: 0.000010, loss: 0.6897, CELoss: 0.6897, 
2022-10-22 05:25:10 - train: epoch 0114, iter [00900, 02526], lr: 0.000010, loss: 1.0973, CELoss: 1.0973, 
2022-10-22 05:26:35 - train: epoch 0114, iter [01000, 02526], lr: 0.000010, loss: 0.8441, CELoss: 0.8441, 
2022-10-22 05:28:00 - train: epoch 0114, iter [01100, 02526], lr: 0.000010, loss: 0.5644, CELoss: 0.5644, 
2022-10-22 05:29:26 - train: epoch 0114, iter [01200, 02526], lr: 0.000010, loss: 0.6623, CELoss: 0.6623, 
2022-10-22 05:30:51 - train: epoch 0114, iter [01300, 02526], lr: 0.000010, loss: 0.5674, CELoss: 0.5674, 
2022-10-22 05:32:16 - train: epoch 0114, iter [01400, 02526], lr: 0.000010, loss: 0.8224, CELoss: 0.8224, 
2022-10-22 05:33:41 - train: epoch 0114, iter [01500, 02526], lr: 0.000010, loss: 0.6393, CELoss: 0.6393, 
2022-10-22 05:35:06 - train: epoch 0114, iter [01600, 02526], lr: 0.000010, loss: 0.3390, CELoss: 0.3390, 
2022-10-22 05:36:31 - train: epoch 0114, iter [01700, 02526], lr: 0.000010, loss: 0.5190, CELoss: 0.5190, 
2022-10-22 05:37:56 - train: epoch 0114, iter [01800, 02526], lr: 0.000010, loss: 0.3931, CELoss: 0.3931, 
2022-10-22 05:39:21 - train: epoch 0114, iter [01900, 02526], lr: 0.000010, loss: 0.8580, CELoss: 0.8580, 
2022-10-22 05:40:46 - train: epoch 0114, iter [02000, 02526], lr: 0.000010, loss: 0.4280, CELoss: 0.4280, 
2022-10-22 05:42:11 - train: epoch 0114, iter [02100, 02526], lr: 0.000010, loss: 0.3045, CELoss: 0.3045, 
2022-10-22 05:43:37 - train: epoch 0114, iter [02200, 02526], lr: 0.000010, loss: 0.6647, CELoss: 0.6647, 
2022-10-22 05:45:02 - train: epoch 0114, iter [02300, 02526], lr: 0.000010, loss: 0.5213, CELoss: 0.5213, 
2022-10-22 05:46:27 - train: epoch 0114, iter [02400, 02526], lr: 0.000010, loss: 0.4660, CELoss: 0.4660, 
2022-10-22 05:47:52 - train: epoch 0114, iter [02500, 02526], lr: 0.000010, loss: 1.1440, CELoss: 1.1440, 
2022-10-22 05:48:15 - train: epoch 114, train_loss: 0.5450
2022-10-22 05:48:16 - until epoch: 114, best_metric: 33.805%
2022-10-22 05:48:16 - epoch 115 lr: 0.000010
2022-10-22 05:49:44 - train: epoch 0115, iter [00100, 02526], lr: 0.000010, loss: 0.3326, CELoss: 0.3326, 
2022-10-22 05:51:08 - train: epoch 0115, iter [00200, 02526], lr: 0.000010, loss: 0.6611, CELoss: 0.6611, 
2022-10-22 05:52:34 - train: epoch 0115, iter [00300, 02526], lr: 0.000010, loss: 0.5197, CELoss: 0.5197, 
2022-10-22 05:53:59 - train: epoch 0115, iter [00400, 02526], lr: 0.000010, loss: 0.4713, CELoss: 0.4713, 
2022-10-22 05:55:24 - train: epoch 0115, iter [00500, 02526], lr: 0.000010, loss: 0.4017, CELoss: 0.4017, 
2022-10-22 05:56:49 - train: epoch 0115, iter [00600, 02526], lr: 0.000010, loss: 0.4862, CELoss: 0.4862, 
2022-10-22 05:58:14 - train: epoch 0115, iter [00700, 02526], lr: 0.000010, loss: 0.9563, CELoss: 0.9563, 
2022-10-22 05:59:39 - train: epoch 0115, iter [00800, 02526], lr: 0.000010, loss: 0.3429, CELoss: 0.3429, 
2022-10-22 06:01:03 - train: epoch 0115, iter [00900, 02526], lr: 0.000010, loss: 0.4984, CELoss: 0.4984, 
2022-10-22 06:02:29 - train: epoch 0115, iter [01000, 02526], lr: 0.000010, loss: 0.5530, CELoss: 0.5530, 
2022-10-22 06:03:54 - train: epoch 0115, iter [01100, 02526], lr: 0.000010, loss: 0.7295, CELoss: 0.7295, 
2022-10-22 06:05:19 - train: epoch 0115, iter [01200, 02526], lr: 0.000010, loss: 0.6367, CELoss: 0.6367, 
2022-10-22 06:06:44 - train: epoch 0115, iter [01300, 02526], lr: 0.000010, loss: 0.4696, CELoss: 0.4696, 
2022-10-22 06:08:09 - train: epoch 0115, iter [01400, 02526], lr: 0.000010, loss: 0.5065, CELoss: 0.5065, 
2022-10-22 06:09:35 - train: epoch 0115, iter [01500, 02526], lr: 0.000010, loss: 0.7068, CELoss: 0.7068, 
2022-10-22 06:11:00 - train: epoch 0115, iter [01600, 02526], lr: 0.000010, loss: 0.6835, CELoss: 0.6835, 
2022-10-22 06:12:25 - train: epoch 0115, iter [01700, 02526], lr: 0.000010, loss: 0.9958, CELoss: 0.9958, 
2022-10-22 06:13:50 - train: epoch 0115, iter [01800, 02526], lr: 0.000010, loss: 0.5047, CELoss: 0.5047, 
2022-10-22 06:15:15 - train: epoch 0115, iter [01900, 02526], lr: 0.000010, loss: 0.5702, CELoss: 0.5702, 
2022-10-22 06:16:41 - train: epoch 0115, iter [02000, 02526], lr: 0.000010, loss: 0.4587, CELoss: 0.4587, 
2022-10-22 06:18:06 - train: epoch 0115, iter [02100, 02526], lr: 0.000010, loss: 0.5058, CELoss: 0.5058, 
2022-10-22 06:19:31 - train: epoch 0115, iter [02200, 02526], lr: 0.000010, loss: 0.5338, CELoss: 0.5338, 
2022-10-22 06:20:56 - train: epoch 0115, iter [02300, 02526], lr: 0.000010, loss: 0.3869, CELoss: 0.3869, 
2022-10-22 06:22:21 - train: epoch 0115, iter [02400, 02526], lr: 0.000010, loss: 0.3634, CELoss: 0.3634, 
2022-10-22 06:23:46 - train: epoch 0115, iter [02500, 02526], lr: 0.000010, loss: 0.6158, CELoss: 0.6158, 
2022-10-22 06:24:10 - train: epoch 115, train_loss: 0.5381
2022-10-22 06:26:57 - eval: epoch: 115
test_loss: 0.9155490967929363
per_image_load_time: 1.668ms
per_image_inference_time: 76.615ms
exist_num_class: 150.0
mean_precision: 50.887093768947096
mean_recall: 47.22745438832073
mean_iou: 33.716443647099965
mean_dice: 47.18540401398893

2022-10-22 06:26:58 - until epoch: 115, best_metric: 33.805%
2022-10-22 06:26:58 - epoch 116 lr: 0.000010
2022-10-22 06:28:26 - train: epoch 0116, iter [00100, 02526], lr: 0.000010, loss: 0.4345, CELoss: 0.4345, 
2022-10-22 06:29:51 - train: epoch 0116, iter [00200, 02526], lr: 0.000010, loss: 0.4904, CELoss: 0.4904, 
2022-10-22 06:31:16 - train: epoch 0116, iter [00300, 02526], lr: 0.000010, loss: 0.6595, CELoss: 0.6595, 
2022-10-22 06:32:41 - train: epoch 0116, iter [00400, 02526], lr: 0.000010, loss: 0.6554, CELoss: 0.6554, 
2022-10-22 06:34:06 - train: epoch 0116, iter [00500, 02526], lr: 0.000010, loss: 0.3502, CELoss: 0.3502, 
2022-10-22 06:35:31 - train: epoch 0116, iter [00600, 02526], lr: 0.000010, loss: 0.4680, CELoss: 0.4680, 
2022-10-22 06:36:56 - train: epoch 0116, iter [00700, 02526], lr: 0.000010, loss: 1.0797, CELoss: 1.0797, 
2022-10-22 06:38:21 - train: epoch 0116, iter [00800, 02526], lr: 0.000010, loss: 0.7978, CELoss: 0.7978, 
2022-10-22 06:39:46 - train: epoch 0116, iter [00900, 02526], lr: 0.000010, loss: 0.4601, CELoss: 0.4601, 
2022-10-22 06:41:11 - train: epoch 0116, iter [01000, 02526], lr: 0.000010, loss: 0.3328, CELoss: 0.3328, 
2022-10-22 06:42:35 - train: epoch 0116, iter [01100, 02526], lr: 0.000010, loss: 0.6448, CELoss: 0.6448, 
2022-10-22 06:44:00 - train: epoch 0116, iter [01200, 02526], lr: 0.000010, loss: 0.8977, CELoss: 0.8977, 
2022-10-22 06:45:25 - train: epoch 0116, iter [01300, 02526], lr: 0.000010, loss: 0.6704, CELoss: 0.6704, 
2022-10-22 06:46:50 - train: epoch 0116, iter [01400, 02526], lr: 0.000010, loss: 0.4486, CELoss: 0.4486, 
2022-10-22 06:48:15 - train: epoch 0116, iter [01500, 02526], lr: 0.000010, loss: 0.7834, CELoss: 0.7834, 
2022-10-22 06:49:40 - train: epoch 0116, iter [01600, 02526], lr: 0.000010, loss: 0.3441, CELoss: 0.3441, 
2022-10-22 06:51:05 - train: epoch 0116, iter [01700, 02526], lr: 0.000010, loss: 0.3863, CELoss: 0.3863, 
2022-10-22 06:52:30 - train: epoch 0116, iter [01800, 02526], lr: 0.000010, loss: 0.4139, CELoss: 0.4139, 
2022-10-22 06:53:56 - train: epoch 0116, iter [01900, 02526], lr: 0.000010, loss: 0.5032, CELoss: 0.5032, 
2022-10-22 06:55:21 - train: epoch 0116, iter [02000, 02526], lr: 0.000010, loss: 0.4685, CELoss: 0.4685, 
2022-10-22 06:56:46 - train: epoch 0116, iter [02100, 02526], lr: 0.000010, loss: 0.4722, CELoss: 0.4722, 
2022-10-22 06:58:11 - train: epoch 0116, iter [02200, 02526], lr: 0.000010, loss: 0.4104, CELoss: 0.4104, 
2022-10-22 06:59:36 - train: epoch 0116, iter [02300, 02526], lr: 0.000010, loss: 0.3678, CELoss: 0.3678, 
2022-10-22 07:01:01 - train: epoch 0116, iter [02400, 02526], lr: 0.000010, loss: 0.6301, CELoss: 0.6301, 
2022-10-22 07:02:26 - train: epoch 0116, iter [02500, 02526], lr: 0.000010, loss: 0.4142, CELoss: 0.4142, 
2022-10-22 07:02:48 - train: epoch 116, train_loss: 0.5404
2022-10-22 07:02:49 - until epoch: 116, best_metric: 33.805%
2022-10-22 07:02:49 - epoch 117 lr: 0.000010
2022-10-22 07:04:17 - train: epoch 0117, iter [00100, 02526], lr: 0.000010, loss: 0.6906, CELoss: 0.6906, 
2022-10-22 07:05:42 - train: epoch 0117, iter [00200, 02526], lr: 0.000010, loss: 0.8400, CELoss: 0.8400, 
2022-10-22 07:07:07 - train: epoch 0117, iter [00300, 02526], lr: 0.000010, loss: 0.3594, CELoss: 0.3594, 
2022-10-22 07:08:32 - train: epoch 0117, iter [00400, 02526], lr: 0.000010, loss: 0.4718, CELoss: 0.4718, 
2022-10-22 07:09:57 - train: epoch 0117, iter [00500, 02526], lr: 0.000010, loss: 0.6510, CELoss: 0.6510, 
2022-10-22 07:11:22 - train: epoch 0117, iter [00600, 02526], lr: 0.000010, loss: 0.5183, CELoss: 0.5183, 
2022-10-22 07:12:47 - train: epoch 0117, iter [00700, 02526], lr: 0.000010, loss: 0.4419, CELoss: 0.4419, 
2022-10-22 07:14:12 - train: epoch 0117, iter [00800, 02526], lr: 0.000010, loss: 0.3626, CELoss: 0.3626, 
2022-10-22 07:15:37 - train: epoch 0117, iter [00900, 02526], lr: 0.000010, loss: 0.4493, CELoss: 0.4493, 
2022-10-22 07:17:02 - train: epoch 0117, iter [01000, 02526], lr: 0.000010, loss: 0.8402, CELoss: 0.8402, 
2022-10-22 07:18:28 - train: epoch 0117, iter [01100, 02526], lr: 0.000010, loss: 0.6698, CELoss: 0.6698, 
2022-10-22 07:19:53 - train: epoch 0117, iter [01200, 02526], lr: 0.000010, loss: 0.7627, CELoss: 0.7627, 
2022-10-22 07:21:18 - train: epoch 0117, iter [01300, 02526], lr: 0.000010, loss: 0.5163, CELoss: 0.5163, 
2022-10-22 07:22:42 - train: epoch 0117, iter [01400, 02526], lr: 0.000010, loss: 0.5693, CELoss: 0.5693, 
2022-10-22 07:24:08 - train: epoch 0117, iter [01500, 02526], lr: 0.000010, loss: 0.5280, CELoss: 0.5280, 
2022-10-22 07:25:33 - train: epoch 0117, iter [01600, 02526], lr: 0.000010, loss: 0.5412, CELoss: 0.5412, 
2022-10-22 07:26:58 - train: epoch 0117, iter [01700, 02526], lr: 0.000010, loss: 0.5113, CELoss: 0.5113, 
2022-10-22 07:28:23 - train: epoch 0117, iter [01800, 02526], lr: 0.000010, loss: 0.4311, CELoss: 0.4311, 
2022-10-22 07:29:48 - train: epoch 0117, iter [01900, 02526], lr: 0.000010, loss: 0.5281, CELoss: 0.5281, 
2022-10-22 07:31:13 - train: epoch 0117, iter [02000, 02526], lr: 0.000010, loss: 0.6703, CELoss: 0.6703, 
2022-10-22 07:32:38 - train: epoch 0117, iter [02100, 02526], lr: 0.000010, loss: 0.7865, CELoss: 0.7865, 
2022-10-22 07:34:04 - train: epoch 0117, iter [02200, 02526], lr: 0.000010, loss: 0.5678, CELoss: 0.5678, 
2022-10-22 07:35:29 - train: epoch 0117, iter [02300, 02526], lr: 0.000010, loss: 0.3667, CELoss: 0.3667, 
2022-10-22 07:36:53 - train: epoch 0117, iter [02400, 02526], lr: 0.000010, loss: 0.3488, CELoss: 0.3488, 
2022-10-22 07:38:18 - train: epoch 0117, iter [02500, 02526], lr: 0.000010, loss: 0.7889, CELoss: 0.7889, 
2022-10-22 07:38:42 - train: epoch 117, train_loss: 0.5377
2022-10-22 07:38:42 - until epoch: 117, best_metric: 33.805%
2022-10-22 07:38:42 - epoch 118 lr: 0.000010
2022-10-22 07:40:10 - train: epoch 0118, iter [00100, 02526], lr: 0.000010, loss: 0.4474, CELoss: 0.4474, 
2022-10-22 07:41:35 - train: epoch 0118, iter [00200, 02526], lr: 0.000010, loss: 0.4846, CELoss: 0.4846, 
2022-10-22 07:43:00 - train: epoch 0118, iter [00300, 02526], lr: 0.000010, loss: 0.6064, CELoss: 0.6064, 
2022-10-22 07:44:25 - train: epoch 0118, iter [00400, 02526], lr: 0.000010, loss: 0.4664, CELoss: 0.4664, 
2022-10-22 07:45:50 - train: epoch 0118, iter [00500, 02526], lr: 0.000010, loss: 0.3927, CELoss: 0.3927, 
2022-10-22 07:47:15 - train: epoch 0118, iter [00600, 02526], lr: 0.000010, loss: 0.3452, CELoss: 0.3452, 
2022-10-22 07:48:40 - train: epoch 0118, iter [00700, 02526], lr: 0.000010, loss: 0.9630, CELoss: 0.9630, 
2022-10-22 07:50:05 - train: epoch 0118, iter [00800, 02526], lr: 0.000010, loss: 0.8175, CELoss: 0.8175, 
2022-10-22 07:51:31 - train: epoch 0118, iter [00900, 02526], lr: 0.000010, loss: 0.3748, CELoss: 0.3748, 
2022-10-22 07:52:55 - train: epoch 0118, iter [01000, 02526], lr: 0.000010, loss: 0.6164, CELoss: 0.6164, 
2022-10-22 07:54:21 - train: epoch 0118, iter [01100, 02526], lr: 0.000010, loss: 0.4650, CELoss: 0.4650, 
2022-10-22 07:55:46 - train: epoch 0118, iter [01200, 02526], lr: 0.000010, loss: 0.4685, CELoss: 0.4685, 
2022-10-22 07:57:11 - train: epoch 0118, iter [01300, 02526], lr: 0.000010, loss: 0.2631, CELoss: 0.2631, 
2022-10-22 07:58:36 - train: epoch 0118, iter [01400, 02526], lr: 0.000010, loss: 0.5821, CELoss: 0.5821, 
2022-10-22 08:00:00 - train: epoch 0118, iter [01500, 02526], lr: 0.000010, loss: 0.3157, CELoss: 0.3157, 
2022-10-22 08:01:25 - train: epoch 0118, iter [01600, 02526], lr: 0.000010, loss: 0.3972, CELoss: 0.3972, 
2022-10-22 08:02:50 - train: epoch 0118, iter [01700, 02526], lr: 0.000010, loss: 0.5076, CELoss: 0.5076, 
2022-10-22 08:04:15 - train: epoch 0118, iter [01800, 02526], lr: 0.000010, loss: 0.3996, CELoss: 0.3996, 
2022-10-22 08:05:40 - train: epoch 0118, iter [01900, 02526], lr: 0.000010, loss: 0.4748, CELoss: 0.4748, 
2022-10-22 08:07:05 - train: epoch 0118, iter [02000, 02526], lr: 0.000010, loss: 0.4613, CELoss: 0.4613, 
2022-10-22 08:08:30 - train: epoch 0118, iter [02100, 02526], lr: 0.000010, loss: 0.5174, CELoss: 0.5174, 
2022-10-22 08:09:55 - train: epoch 0118, iter [02200, 02526], lr: 0.000010, loss: 0.4515, CELoss: 0.4515, 
2022-10-22 08:11:20 - train: epoch 0118, iter [02300, 02526], lr: 0.000010, loss: 0.4212, CELoss: 0.4212, 
2022-10-22 08:12:46 - train: epoch 0118, iter [02400, 02526], lr: 0.000010, loss: 0.5179, CELoss: 0.5179, 
2022-10-22 08:14:11 - train: epoch 0118, iter [02500, 02526], lr: 0.000010, loss: 0.4431, CELoss: 0.4431, 
2022-10-22 08:14:34 - train: epoch 118, train_loss: 0.5399
2022-10-22 08:14:35 - until epoch: 118, best_metric: 33.805%
2022-10-22 08:14:35 - epoch 119 lr: 0.000010
2022-10-22 08:16:03 - train: epoch 0119, iter [00100, 02526], lr: 0.000010, loss: 0.4931, CELoss: 0.4931, 
2022-10-22 08:17:28 - train: epoch 0119, iter [00200, 02526], lr: 0.000010, loss: 0.3225, CELoss: 0.3225, 
2022-10-22 08:18:53 - train: epoch 0119, iter [00300, 02526], lr: 0.000010, loss: 0.8085, CELoss: 0.8085, 
2022-10-22 08:20:17 - train: epoch 0119, iter [00400, 02526], lr: 0.000010, loss: 0.4591, CELoss: 0.4591, 
2022-10-22 08:21:43 - train: epoch 0119, iter [00500, 02526], lr: 0.000010, loss: 0.6173, CELoss: 0.6173, 
2022-10-22 08:23:07 - train: epoch 0119, iter [00600, 02526], lr: 0.000010, loss: 0.6234, CELoss: 0.6234, 
2022-10-22 08:24:33 - train: epoch 0119, iter [00700, 02526], lr: 0.000010, loss: 0.6015, CELoss: 0.6015, 
2022-10-22 08:25:58 - train: epoch 0119, iter [00800, 02526], lr: 0.000010, loss: 0.4507, CELoss: 0.4507, 
2022-10-22 08:27:23 - train: epoch 0119, iter [00900, 02526], lr: 0.000010, loss: 0.5436, CELoss: 0.5436, 
2022-10-22 08:28:49 - train: epoch 0119, iter [01000, 02526], lr: 0.000010, loss: 0.5600, CELoss: 0.5600, 
2022-10-22 08:30:14 - train: epoch 0119, iter [01100, 02526], lr: 0.000010, loss: 0.5135, CELoss: 0.5135, 
2022-10-22 08:31:39 - train: epoch 0119, iter [01200, 02526], lr: 0.000010, loss: 0.7541, CELoss: 0.7541, 
2022-10-22 08:33:05 - train: epoch 0119, iter [01300, 02526], lr: 0.000010, loss: 0.4584, CELoss: 0.4584, 
2022-10-22 08:34:30 - train: epoch 0119, iter [01400, 02526], lr: 0.000010, loss: 0.3982, CELoss: 0.3982, 
2022-10-22 08:35:55 - train: epoch 0119, iter [01500, 02526], lr: 0.000010, loss: 0.6650, CELoss: 0.6650, 
2022-10-22 08:37:21 - train: epoch 0119, iter [01600, 02526], lr: 0.000010, loss: 0.5740, CELoss: 0.5740, 
2022-10-22 08:38:46 - train: epoch 0119, iter [01700, 02526], lr: 0.000010, loss: 0.6398, CELoss: 0.6398, 
2022-10-22 08:40:12 - train: epoch 0119, iter [01800, 02526], lr: 0.000010, loss: 0.5475, CELoss: 0.5475, 
2022-10-22 08:41:37 - train: epoch 0119, iter [01900, 02526], lr: 0.000010, loss: 0.7854, CELoss: 0.7854, 
2022-10-22 08:43:02 - train: epoch 0119, iter [02000, 02526], lr: 0.000010, loss: 0.4580, CELoss: 0.4580, 
2022-10-22 08:44:27 - train: epoch 0119, iter [02100, 02526], lr: 0.000010, loss: 0.2638, CELoss: 0.2638, 
2022-10-22 08:45:52 - train: epoch 0119, iter [02200, 02526], lr: 0.000010, loss: 0.4189, CELoss: 0.4189, 
2022-10-22 08:47:18 - train: epoch 0119, iter [02300, 02526], lr: 0.000010, loss: 0.8848, CELoss: 0.8848, 
2022-10-22 08:48:43 - train: epoch 0119, iter [02400, 02526], lr: 0.000010, loss: 0.6781, CELoss: 0.6781, 
2022-10-22 08:50:08 - train: epoch 0119, iter [02500, 02526], lr: 0.000010, loss: 0.5859, CELoss: 0.5859, 
2022-10-22 08:50:32 - train: epoch 119, train_loss: 0.5373
2022-10-22 08:50:32 - until epoch: 119, best_metric: 33.805%
2022-10-22 08:50:32 - epoch 120 lr: 0.000010
2022-10-22 08:52:00 - train: epoch 0120, iter [00100, 02526], lr: 0.000010, loss: 0.5602, CELoss: 0.5602, 
2022-10-22 08:53:26 - train: epoch 0120, iter [00200, 02526], lr: 0.000010, loss: 0.5826, CELoss: 0.5826, 
2022-10-22 08:54:51 - train: epoch 0120, iter [00300, 02526], lr: 0.000010, loss: 0.5446, CELoss: 0.5446, 
2022-10-22 08:56:16 - train: epoch 0120, iter [00400, 02526], lr: 0.000010, loss: 0.7079, CELoss: 0.7079, 
2022-10-22 08:57:41 - train: epoch 0120, iter [00500, 02526], lr: 0.000010, loss: 0.4276, CELoss: 0.4276, 
2022-10-22 08:59:07 - train: epoch 0120, iter [00600, 02526], lr: 0.000010, loss: 0.4522, CELoss: 0.4522, 
2022-10-22 09:00:32 - train: epoch 0120, iter [00700, 02526], lr: 0.000010, loss: 0.4744, CELoss: 0.4744, 
2022-10-22 09:01:57 - train: epoch 0120, iter [00800, 02526], lr: 0.000010, loss: 0.6426, CELoss: 0.6426, 
2022-10-22 09:03:23 - train: epoch 0120, iter [00900, 02526], lr: 0.000010, loss: 0.3381, CELoss: 0.3381, 
2022-10-22 09:04:48 - train: epoch 0120, iter [01000, 02526], lr: 0.000010, loss: 0.3420, CELoss: 0.3420, 
2022-10-22 09:06:13 - train: epoch 0120, iter [01100, 02526], lr: 0.000010, loss: 0.7763, CELoss: 0.7763, 
2022-10-22 09:07:39 - train: epoch 0120, iter [01200, 02526], lr: 0.000010, loss: 0.8226, CELoss: 0.8226, 
2022-10-22 09:09:04 - train: epoch 0120, iter [01300, 02526], lr: 0.000010, loss: 0.5176, CELoss: 0.5176, 
2022-10-22 09:10:29 - train: epoch 0120, iter [01400, 02526], lr: 0.000010, loss: 0.6162, CELoss: 0.6162, 
2022-10-22 09:11:54 - train: epoch 0120, iter [01500, 02526], lr: 0.000010, loss: 0.5328, CELoss: 0.5328, 
2022-10-22 09:13:20 - train: epoch 0120, iter [01600, 02526], lr: 0.000010, loss: 0.4510, CELoss: 0.4510, 
2022-10-22 09:14:45 - train: epoch 0120, iter [01700, 02526], lr: 0.000010, loss: 0.8705, CELoss: 0.8705, 
2022-10-22 09:16:10 - train: epoch 0120, iter [01800, 02526], lr: 0.000010, loss: 0.5643, CELoss: 0.5643, 
2022-10-22 09:17:36 - train: epoch 0120, iter [01900, 02526], lr: 0.000010, loss: 0.4724, CELoss: 0.4724, 
2022-10-22 09:19:01 - train: epoch 0120, iter [02000, 02526], lr: 0.000010, loss: 0.4647, CELoss: 0.4647, 
2022-10-22 09:20:27 - train: epoch 0120, iter [02100, 02526], lr: 0.000010, loss: 0.5944, CELoss: 0.5944, 
2022-10-22 09:21:52 - train: epoch 0120, iter [02200, 02526], lr: 0.000010, loss: 0.3476, CELoss: 0.3476, 
2022-10-22 09:23:18 - train: epoch 0120, iter [02300, 02526], lr: 0.000010, loss: 0.4809, CELoss: 0.4809, 
2022-10-22 09:24:43 - train: epoch 0120, iter [02400, 02526], lr: 0.000010, loss: 0.6806, CELoss: 0.6806, 
2022-10-22 09:26:09 - train: epoch 0120, iter [02500, 02526], lr: 0.000010, loss: 0.5890, CELoss: 0.5890, 
2022-10-22 09:26:32 - train: epoch 120, train_loss: 0.5405
2022-10-22 09:29:19 - eval: epoch: 120
test_loss: 0.9168350555002689
per_image_load_time: 1.436ms
per_image_inference_time: 76.728ms
exist_num_class: 150.0
mean_precision: 51.585257873996575
mean_recall: 46.74303712341876
mean_iou: 33.84700321498531
mean_dice: 47.20593409902092

2022-10-22 09:29:20 - until epoch: 120, best_metric: 33.847%
2022-10-22 09:29:20 - epoch 121 lr: 0.000001
2022-10-22 09:30:48 - train: epoch 0121, iter [00100, 02526], lr: 0.000001, loss: 0.4431, CELoss: 0.4431, 
2022-10-22 09:32:14 - train: epoch 0121, iter [00200, 02526], lr: 0.000001, loss: 0.4721, CELoss: 0.4721, 
2022-10-22 09:33:39 - train: epoch 0121, iter [00300, 02526], lr: 0.000001, loss: 0.6169, CELoss: 0.6169, 
2022-10-22 09:35:04 - train: epoch 0121, iter [00400, 02526], lr: 0.000001, loss: 0.5196, CELoss: 0.5196, 
2022-10-22 09:36:30 - train: epoch 0121, iter [00500, 02526], lr: 0.000001, loss: 0.5833, CELoss: 0.5833, 
2022-10-22 09:37:55 - train: epoch 0121, iter [00600, 02526], lr: 0.000001, loss: 0.3160, CELoss: 0.3160, 
2022-10-22 09:39:20 - train: epoch 0121, iter [00700, 02526], lr: 0.000001, loss: 0.5357, CELoss: 0.5357, 
2022-10-22 09:40:46 - train: epoch 0121, iter [00800, 02526], lr: 0.000001, loss: 0.6071, CELoss: 0.6071, 
2022-10-22 09:42:11 - train: epoch 0121, iter [00900, 02526], lr: 0.000001, loss: 0.5750, CELoss: 0.5750, 
2022-10-22 09:43:36 - train: epoch 0121, iter [01000, 02526], lr: 0.000001, loss: 0.4061, CELoss: 0.4061, 
2022-10-22 09:45:02 - train: epoch 0121, iter [01100, 02526], lr: 0.000001, loss: 0.4073, CELoss: 0.4073, 
2022-10-22 09:46:27 - train: epoch 0121, iter [01200, 02526], lr: 0.000001, loss: 0.3945, CELoss: 0.3945, 
2022-10-22 09:47:53 - train: epoch 0121, iter [01300, 02526], lr: 0.000001, loss: 0.5945, CELoss: 0.5945, 
2022-10-22 09:49:18 - train: epoch 0121, iter [01400, 02526], lr: 0.000001, loss: 0.5043, CELoss: 0.5043, 
2022-10-22 09:50:43 - train: epoch 0121, iter [01500, 02526], lr: 0.000001, loss: 0.5662, CELoss: 0.5662, 
2022-10-22 09:52:08 - train: epoch 0121, iter [01600, 02526], lr: 0.000001, loss: 0.5240, CELoss: 0.5240, 
2022-10-22 09:53:34 - train: epoch 0121, iter [01700, 02526], lr: 0.000001, loss: 0.3668, CELoss: 0.3668, 
2022-10-22 09:54:59 - train: epoch 0121, iter [01800, 02526], lr: 0.000001, loss: 0.5095, CELoss: 0.5095, 
2022-10-22 09:56:25 - train: epoch 0121, iter [01900, 02526], lr: 0.000001, loss: 0.3707, CELoss: 0.3707, 
2022-10-22 09:57:50 - train: epoch 0121, iter [02000, 02526], lr: 0.000001, loss: 0.5167, CELoss: 0.5167, 
2022-10-22 09:59:15 - train: epoch 0121, iter [02100, 02526], lr: 0.000001, loss: 0.7058, CELoss: 0.7058, 
2022-10-22 10:00:40 - train: epoch 0121, iter [02200, 02526], lr: 0.000001, loss: 0.3138, CELoss: 0.3138, 
2022-10-22 10:02:06 - train: epoch 0121, iter [02300, 02526], lr: 0.000001, loss: 0.4109, CELoss: 0.4109, 
2022-10-22 10:03:31 - train: epoch 0121, iter [02400, 02526], lr: 0.000001, loss: 0.7115, CELoss: 0.7115, 
2022-10-22 10:04:57 - train: epoch 0121, iter [02500, 02526], lr: 0.000001, loss: 0.5678, CELoss: 0.5678, 
2022-10-22 10:05:20 - train: epoch 121, train_loss: 0.5347
2022-10-22 10:05:21 - until epoch: 121, best_metric: 33.847%
2022-10-22 10:05:21 - epoch 122 lr: 0.000001
2022-10-22 10:06:49 - train: epoch 0122, iter [00100, 02526], lr: 0.000001, loss: 0.6379, CELoss: 0.6379, 
2022-10-22 10:08:15 - train: epoch 0122, iter [00200, 02526], lr: 0.000001, loss: 0.4984, CELoss: 0.4984, 
2022-10-22 10:09:40 - train: epoch 0122, iter [00300, 02526], lr: 0.000001, loss: 0.5315, CELoss: 0.5315, 
2022-10-22 10:11:05 - train: epoch 0122, iter [00400, 02526], lr: 0.000001, loss: 0.5003, CELoss: 0.5003, 
2022-10-22 10:12:31 - train: epoch 0122, iter [00500, 02526], lr: 0.000001, loss: 0.5328, CELoss: 0.5328, 
2022-10-22 10:13:56 - train: epoch 0122, iter [00600, 02526], lr: 0.000001, loss: 0.3962, CELoss: 0.3962, 
2022-10-22 10:15:21 - train: epoch 0122, iter [00700, 02526], lr: 0.000001, loss: 0.7160, CELoss: 0.7160, 
2022-10-22 10:16:47 - train: epoch 0122, iter [00800, 02526], lr: 0.000001, loss: 0.5466, CELoss: 0.5466, 
2022-10-22 10:18:12 - train: epoch 0122, iter [00900, 02526], lr: 0.000001, loss: 0.4044, CELoss: 0.4044, 
2022-10-22 10:19:37 - train: epoch 0122, iter [01000, 02526], lr: 0.000001, loss: 0.5558, CELoss: 0.5558, 
2022-10-22 10:21:03 - train: epoch 0122, iter [01100, 02526], lr: 0.000001, loss: 0.9530, CELoss: 0.9530, 
2022-10-22 10:22:28 - train: epoch 0122, iter [01200, 02526], lr: 0.000001, loss: 0.3518, CELoss: 0.3518, 
2022-10-22 10:23:53 - train: epoch 0122, iter [01300, 02526], lr: 0.000001, loss: 0.3765, CELoss: 0.3765, 
2022-10-22 10:25:19 - train: epoch 0122, iter [01400, 02526], lr: 0.000001, loss: 0.4153, CELoss: 0.4153, 
2022-10-22 10:26:44 - train: epoch 0122, iter [01500, 02526], lr: 0.000001, loss: 0.4930, CELoss: 0.4930, 
2022-10-22 10:28:09 - train: epoch 0122, iter [01600, 02526], lr: 0.000001, loss: 0.3650, CELoss: 0.3650, 
2022-10-22 10:29:35 - train: epoch 0122, iter [01700, 02526], lr: 0.000001, loss: 0.6903, CELoss: 0.6903, 
2022-10-22 10:31:00 - train: epoch 0122, iter [01800, 02526], lr: 0.000001, loss: 0.6909, CELoss: 0.6909, 
2022-10-22 10:32:25 - train: epoch 0122, iter [01900, 02526], lr: 0.000001, loss: 0.5270, CELoss: 0.5270, 
2022-10-22 10:33:51 - train: epoch 0122, iter [02000, 02526], lr: 0.000001, loss: 0.6371, CELoss: 0.6371, 
2022-10-22 10:35:16 - train: epoch 0122, iter [02100, 02526], lr: 0.000001, loss: 0.6174, CELoss: 0.6174, 
2022-10-22 10:36:42 - train: epoch 0122, iter [02200, 02526], lr: 0.000001, loss: 0.6974, CELoss: 0.6974, 
2022-10-22 10:38:07 - train: epoch 0122, iter [02300, 02526], lr: 0.000001, loss: 0.8199, CELoss: 0.8199, 
2022-10-22 10:39:32 - train: epoch 0122, iter [02400, 02526], lr: 0.000001, loss: 0.5461, CELoss: 0.5461, 
2022-10-22 10:40:57 - train: epoch 0122, iter [02500, 02526], lr: 0.000001, loss: 0.6376, CELoss: 0.6376, 
2022-10-22 10:41:21 - train: epoch 122, train_loss: 0.5328
2022-10-22 10:41:21 - until epoch: 122, best_metric: 33.847%
2022-10-22 10:41:21 - epoch 123 lr: 0.000001
2022-10-22 10:42:50 - train: epoch 0123, iter [00100, 02526], lr: 0.000001, loss: 0.4317, CELoss: 0.4317, 
2022-10-22 10:44:15 - train: epoch 0123, iter [00200, 02526], lr: 0.000001, loss: 0.5155, CELoss: 0.5155, 
2022-10-22 10:45:40 - train: epoch 0123, iter [00300, 02526], lr: 0.000001, loss: 0.4993, CELoss: 0.4993, 
2022-10-22 10:47:05 - train: epoch 0123, iter [00400, 02526], lr: 0.000001, loss: 0.6142, CELoss: 0.6142, 
2022-10-22 10:48:30 - train: epoch 0123, iter [00500, 02526], lr: 0.000001, loss: 0.6727, CELoss: 0.6727, 
2022-10-22 10:49:56 - train: epoch 0123, iter [00600, 02526], lr: 0.000001, loss: 0.7273, CELoss: 0.7273, 
2022-10-22 10:51:21 - train: epoch 0123, iter [00700, 02526], lr: 0.000001, loss: 0.5432, CELoss: 0.5432, 
2022-10-22 10:52:47 - train: epoch 0123, iter [00800, 02526], lr: 0.000001, loss: 0.9301, CELoss: 0.9301, 
2022-10-22 10:54:12 - train: epoch 0123, iter [00900, 02526], lr: 0.000001, loss: 0.9267, CELoss: 0.9267, 
2022-10-22 10:55:38 - train: epoch 0123, iter [01000, 02526], lr: 0.000001, loss: 0.8181, CELoss: 0.8181, 
2022-10-22 10:57:03 - train: epoch 0123, iter [01100, 02526], lr: 0.000001, loss: 0.6424, CELoss: 0.6424, 
2022-10-22 10:58:28 - train: epoch 0123, iter [01200, 02526], lr: 0.000001, loss: 0.4004, CELoss: 0.4004, 
2022-10-22 10:59:54 - train: epoch 0123, iter [01300, 02526], lr: 0.000001, loss: 0.6157, CELoss: 0.6157, 
2022-10-22 11:01:19 - train: epoch 0123, iter [01400, 02526], lr: 0.000001, loss: 0.5262, CELoss: 0.5262, 
2022-10-22 11:02:44 - train: epoch 0123, iter [01500, 02526], lr: 0.000001, loss: 0.6789, CELoss: 0.6789, 
2022-10-22 11:04:10 - train: epoch 0123, iter [01600, 02526], lr: 0.000001, loss: 0.3491, CELoss: 0.3491, 
2022-10-22 11:05:35 - train: epoch 0123, iter [01700, 02526], lr: 0.000001, loss: 0.7746, CELoss: 0.7746, 
2022-10-22 11:07:01 - train: epoch 0123, iter [01800, 02526], lr: 0.000001, loss: 0.2417, CELoss: 0.2417, 
2022-10-22 11:08:26 - train: epoch 0123, iter [01900, 02526], lr: 0.000001, loss: 0.5945, CELoss: 0.5945, 
2022-10-22 11:09:52 - train: epoch 0123, iter [02000, 02526], lr: 0.000001, loss: 0.2984, CELoss: 0.2984, 
2022-10-22 11:11:17 - train: epoch 0123, iter [02100, 02526], lr: 0.000001, loss: 0.5519, CELoss: 0.5519, 
2022-10-22 11:12:42 - train: epoch 0123, iter [02200, 02526], lr: 0.000001, loss: 0.6449, CELoss: 0.6449, 
2022-10-22 11:14:08 - train: epoch 0123, iter [02300, 02526], lr: 0.000001, loss: 0.5390, CELoss: 0.5390, 
2022-10-22 11:15:33 - train: epoch 0123, iter [02400, 02526], lr: 0.000001, loss: 0.4055, CELoss: 0.4055, 
2022-10-22 11:16:59 - train: epoch 0123, iter [02500, 02526], lr: 0.000001, loss: 0.8916, CELoss: 0.8916, 
2022-10-22 11:17:22 - train: epoch 123, train_loss: 0.5289
2022-10-22 11:17:23 - until epoch: 123, best_metric: 33.847%
2022-10-22 11:17:23 - epoch 124 lr: 0.000001
2022-10-22 11:18:51 - train: epoch 0124, iter [00100, 02526], lr: 0.000001, loss: 0.4573, CELoss: 0.4573, 
2022-10-22 11:20:16 - train: epoch 0124, iter [00200, 02526], lr: 0.000001, loss: 0.4659, CELoss: 0.4659, 
2022-10-22 11:21:42 - train: epoch 0124, iter [00300, 02526], lr: 0.000001, loss: 0.3422, CELoss: 0.3422, 
2022-10-22 11:23:07 - train: epoch 0124, iter [00400, 02526], lr: 0.000001, loss: 0.6433, CELoss: 0.6433, 
2022-10-22 11:24:33 - train: epoch 0124, iter [00500, 02526], lr: 0.000001, loss: 0.4028, CELoss: 0.4028, 
2022-10-22 11:25:58 - train: epoch 0124, iter [00600, 02526], lr: 0.000001, loss: 0.4990, CELoss: 0.4990, 
2022-10-22 11:27:24 - train: epoch 0124, iter [00700, 02526], lr: 0.000001, loss: 0.6558, CELoss: 0.6558, 
2022-10-22 11:28:49 - train: epoch 0124, iter [00800, 02526], lr: 0.000001, loss: 0.3900, CELoss: 0.3900, 
2022-10-22 11:30:15 - train: epoch 0124, iter [00900, 02526], lr: 0.000001, loss: 0.4847, CELoss: 0.4847, 
2022-10-22 11:31:40 - train: epoch 0124, iter [01000, 02526], lr: 0.000001, loss: 0.4259, CELoss: 0.4259, 
2022-10-22 11:33:06 - train: epoch 0124, iter [01100, 02526], lr: 0.000001, loss: 0.6115, CELoss: 0.6115, 
2022-10-22 11:34:31 - train: epoch 0124, iter [01200, 02526], lr: 0.000001, loss: 0.5611, CELoss: 0.5611, 
2022-10-22 11:35:57 - train: epoch 0124, iter [01300, 02526], lr: 0.000001, loss: 0.4589, CELoss: 0.4589, 
2022-10-22 11:37:22 - train: epoch 0124, iter [01400, 02526], lr: 0.000001, loss: 0.7914, CELoss: 0.7914, 
2022-10-22 11:38:48 - train: epoch 0124, iter [01500, 02526], lr: 0.000001, loss: 0.4224, CELoss: 0.4224, 
2022-10-22 11:40:13 - train: epoch 0124, iter [01600, 02526], lr: 0.000001, loss: 0.6074, CELoss: 0.6074, 
2022-10-22 11:41:38 - train: epoch 0124, iter [01700, 02526], lr: 0.000001, loss: 0.4762, CELoss: 0.4762, 
2022-10-22 11:43:04 - train: epoch 0124, iter [01800, 02526], lr: 0.000001, loss: 0.6822, CELoss: 0.6822, 
2022-10-22 11:44:29 - train: epoch 0124, iter [01900, 02526], lr: 0.000001, loss: 0.4941, CELoss: 0.4941, 
2022-10-22 11:45:55 - train: epoch 0124, iter [02000, 02526], lr: 0.000001, loss: 0.7252, CELoss: 0.7252, 
2022-10-22 11:47:20 - train: epoch 0124, iter [02100, 02526], lr: 0.000001, loss: 0.3496, CELoss: 0.3496, 
2022-10-22 11:48:45 - train: epoch 0124, iter [02200, 02526], lr: 0.000001, loss: 0.4594, CELoss: 0.4594, 
2022-10-22 11:50:11 - train: epoch 0124, iter [02300, 02526], lr: 0.000001, loss: 0.3867, CELoss: 0.3867, 
2022-10-22 11:51:36 - train: epoch 0124, iter [02400, 02526], lr: 0.000001, loss: 0.6248, CELoss: 0.6248, 
2022-10-22 11:53:01 - train: epoch 0124, iter [02500, 02526], lr: 0.000001, loss: 0.4150, CELoss: 0.4150, 
2022-10-22 11:53:25 - train: epoch 124, train_loss: 0.5309
2022-10-22 11:53:26 - until epoch: 124, best_metric: 33.847%
2022-10-22 11:53:26 - epoch 125 lr: 0.000001
2022-10-22 11:54:54 - train: epoch 0125, iter [00100, 02526], lr: 0.000001, loss: 0.6235, CELoss: 0.6235, 
2022-10-22 11:56:19 - train: epoch 0125, iter [00200, 02526], lr: 0.000001, loss: 0.5984, CELoss: 0.5984, 
2022-10-22 11:57:45 - train: epoch 0125, iter [00300, 02526], lr: 0.000001, loss: 0.5542, CELoss: 0.5542, 
2022-10-22 11:59:10 - train: epoch 0125, iter [00400, 02526], lr: 0.000001, loss: 0.5077, CELoss: 0.5077, 
2022-10-22 12:00:36 - train: epoch 0125, iter [00500, 02526], lr: 0.000001, loss: 0.6734, CELoss: 0.6734, 
2022-10-22 12:02:01 - train: epoch 0125, iter [00600, 02526], lr: 0.000001, loss: 0.7077, CELoss: 0.7077, 
2022-10-22 12:03:26 - train: epoch 0125, iter [00700, 02526], lr: 0.000001, loss: 0.4963, CELoss: 0.4963, 
2022-10-22 12:04:51 - train: epoch 0125, iter [00800, 02526], lr: 0.000001, loss: 0.3497, CELoss: 0.3497, 
2022-10-22 12:06:17 - train: epoch 0125, iter [00900, 02526], lr: 0.000001, loss: 0.4105, CELoss: 0.4105, 
2022-10-22 12:07:42 - train: epoch 0125, iter [01000, 02526], lr: 0.000001, loss: 0.5566, CELoss: 0.5566, 
2022-10-22 12:09:07 - train: epoch 0125, iter [01100, 02526], lr: 0.000001, loss: 0.3680, CELoss: 0.3680, 
2022-10-22 12:10:32 - train: epoch 0125, iter [01200, 02526], lr: 0.000001, loss: 0.7417, CELoss: 0.7417, 
2022-10-22 12:11:57 - train: epoch 0125, iter [01300, 02526], lr: 0.000001, loss: 0.3335, CELoss: 0.3335, 
2022-10-22 12:13:23 - train: epoch 0125, iter [01400, 02526], lr: 0.000001, loss: 0.4552, CELoss: 0.4552, 
2022-10-22 12:14:48 - train: epoch 0125, iter [01500, 02526], lr: 0.000001, loss: 0.2500, CELoss: 0.2500, 
2022-10-22 12:16:13 - train: epoch 0125, iter [01600, 02526], lr: 0.000001, loss: 0.5953, CELoss: 0.5953, 
2022-10-22 12:17:38 - train: epoch 0125, iter [01700, 02526], lr: 0.000001, loss: 0.7840, CELoss: 0.7840, 
2022-10-22 12:19:04 - train: epoch 0125, iter [01800, 02526], lr: 0.000001, loss: 0.4267, CELoss: 0.4267, 
2022-10-22 12:20:29 - train: epoch 0125, iter [01900, 02526], lr: 0.000001, loss: 0.5478, CELoss: 0.5478, 
2022-10-22 12:21:55 - train: epoch 0125, iter [02000, 02526], lr: 0.000001, loss: 0.5364, CELoss: 0.5364, 
2022-10-22 12:23:21 - train: epoch 0125, iter [02100, 02526], lr: 0.000001, loss: 0.3103, CELoss: 0.3103, 
2022-10-22 12:24:46 - train: epoch 0125, iter [02200, 02526], lr: 0.000001, loss: 0.4009, CELoss: 0.4009, 
2022-10-22 12:26:12 - train: epoch 0125, iter [02300, 02526], lr: 0.000001, loss: 0.4772, CELoss: 0.4772, 
2022-10-22 12:27:37 - train: epoch 0125, iter [02400, 02526], lr: 0.000001, loss: 0.5127, CELoss: 0.5127, 
2022-10-22 12:29:02 - train: epoch 0125, iter [02500, 02526], lr: 0.000001, loss: 0.5281, CELoss: 0.5281, 
2022-10-22 12:29:26 - train: epoch 125, train_loss: 0.5285
2022-10-22 12:32:14 - eval: epoch: 125
test_loss: 0.9056437716186047
per_image_load_time: 1.513ms
per_image_inference_time: 76.937ms
exist_num_class: 150.0
mean_precision: 50.79238834525718
mean_recall: 47.899944742842415
mean_iou: 34.131618557428155
mean_dice: 47.570483128279236

2022-10-22 12:32:15 - until epoch: 125, best_metric: 34.132%
2022-10-22 12:32:15 - epoch 126 lr: 0.000001
2022-10-22 12:33:43 - train: epoch 0126, iter [00100, 02526], lr: 0.000001, loss: 0.3279, CELoss: 0.3279, 
2022-10-22 12:35:08 - train: epoch 0126, iter [00200, 02526], lr: 0.000001, loss: 0.6423, CELoss: 0.6423, 
2022-10-22 12:36:34 - train: epoch 0126, iter [00300, 02526], lr: 0.000001, loss: 0.5309, CELoss: 0.5309, 
2022-10-22 12:37:59 - train: epoch 0126, iter [00400, 02526], lr: 0.000001, loss: 0.4891, CELoss: 0.4891, 
2022-10-22 12:39:25 - train: epoch 0126, iter [00500, 02526], lr: 0.000001, loss: 0.6608, CELoss: 0.6608, 
2022-10-22 12:40:50 - train: epoch 0126, iter [00600, 02526], lr: 0.000001, loss: 0.3168, CELoss: 0.3168, 
2022-10-22 12:42:16 - train: epoch 0126, iter [00700, 02526], lr: 0.000001, loss: 0.2739, CELoss: 0.2739, 
2022-10-22 12:43:42 - train: epoch 0126, iter [00800, 02526], lr: 0.000001, loss: 0.4639, CELoss: 0.4639, 
2022-10-22 12:45:07 - train: epoch 0126, iter [00900, 02526], lr: 0.000001, loss: 0.4305, CELoss: 0.4305, 
2022-10-22 12:46:32 - train: epoch 0126, iter [01000, 02526], lr: 0.000001, loss: 0.5358, CELoss: 0.5358, 
2022-10-22 12:47:58 - train: epoch 0126, iter [01100, 02526], lr: 0.000001, loss: 0.6247, CELoss: 0.6247, 
2022-10-22 12:49:23 - train: epoch 0126, iter [01200, 02526], lr: 0.000001, loss: 0.9414, CELoss: 0.9414, 
2022-10-22 12:50:49 - train: epoch 0126, iter [01300, 02526], lr: 0.000001, loss: 0.6646, CELoss: 0.6646, 
2022-10-22 12:52:14 - train: epoch 0126, iter [01400, 02526], lr: 0.000001, loss: 0.4782, CELoss: 0.4782, 
2022-10-22 12:53:39 - train: epoch 0126, iter [01500, 02526], lr: 0.000001, loss: 0.5497, CELoss: 0.5497, 
2022-10-22 12:55:05 - train: epoch 0126, iter [01600, 02526], lr: 0.000001, loss: 0.4565, CELoss: 0.4565, 
2022-10-22 12:56:30 - train: epoch 0126, iter [01700, 02526], lr: 0.000001, loss: 0.7319, CELoss: 0.7319, 
2022-10-22 12:57:56 - train: epoch 0126, iter [01800, 02526], lr: 0.000001, loss: 0.4836, CELoss: 0.4836, 
2022-10-22 12:59:21 - train: epoch 0126, iter [01900, 02526], lr: 0.000001, loss: 0.5619, CELoss: 0.5619, 
2022-10-22 13:00:47 - train: epoch 0126, iter [02000, 02526], lr: 0.000001, loss: 0.3740, CELoss: 0.3740, 
2022-10-22 13:02:12 - train: epoch 0126, iter [02100, 02526], lr: 0.000001, loss: 0.5631, CELoss: 0.5631, 
2022-10-22 13:03:37 - train: epoch 0126, iter [02200, 02526], lr: 0.000001, loss: 0.4595, CELoss: 0.4595, 
2022-10-22 13:05:03 - train: epoch 0126, iter [02300, 02526], lr: 0.000001, loss: 0.8484, CELoss: 0.8484, 
2022-10-22 13:06:28 - train: epoch 0126, iter [02400, 02526], lr: 0.000001, loss: 0.3942, CELoss: 0.3942, 
2022-10-22 13:07:54 - train: epoch 0126, iter [02500, 02526], lr: 0.000001, loss: 0.4221, CELoss: 0.4221, 
2022-10-22 13:08:17 - train: epoch 126, train_loss: 0.5303
2022-10-22 13:08:18 - until epoch: 126, best_metric: 34.132%
2022-10-22 13:08:18 - epoch 127 lr: 0.000001
2022-10-22 13:09:46 - train: epoch 0127, iter [00100, 02526], lr: 0.000001, loss: 0.4133, CELoss: 0.4133, 
2022-10-22 13:11:11 - train: epoch 0127, iter [00200, 02526], lr: 0.000001, loss: 0.3097, CELoss: 0.3097, 
2022-10-22 13:12:36 - train: epoch 0127, iter [00300, 02526], lr: 0.000001, loss: 0.6204, CELoss: 0.6204, 
2022-10-22 13:14:02 - train: epoch 0127, iter [00400, 02526], lr: 0.000001, loss: 0.5899, CELoss: 0.5899, 
2022-10-22 13:15:27 - train: epoch 0127, iter [00500, 02526], lr: 0.000001, loss: 0.5831, CELoss: 0.5831, 
2022-10-22 13:16:52 - train: epoch 0127, iter [00600, 02526], lr: 0.000001, loss: 0.5248, CELoss: 0.5248, 
2022-10-22 13:18:18 - train: epoch 0127, iter [00700, 02526], lr: 0.000001, loss: 0.4093, CELoss: 0.4093, 
2022-10-22 13:19:43 - train: epoch 0127, iter [00800, 02526], lr: 0.000001, loss: 0.4509, CELoss: 0.4509, 
2022-10-22 13:21:09 - train: epoch 0127, iter [00900, 02526], lr: 0.000001, loss: 0.5347, CELoss: 0.5347, 
2022-10-22 13:22:34 - train: epoch 0127, iter [01000, 02526], lr: 0.000001, loss: 0.4698, CELoss: 0.4698, 
2022-10-22 13:24:00 - train: epoch 0127, iter [01100, 02526], lr: 0.000001, loss: 0.6397, CELoss: 0.6397, 
2022-10-22 13:25:25 - train: epoch 0127, iter [01200, 02526], lr: 0.000001, loss: 0.3335, CELoss: 0.3335, 
2022-10-22 13:26:50 - train: epoch 0127, iter [01300, 02526], lr: 0.000001, loss: 0.6373, CELoss: 0.6373, 
2022-10-22 13:28:15 - train: epoch 0127, iter [01400, 02526], lr: 0.000001, loss: 0.5755, CELoss: 0.5755, 
2022-10-22 13:29:41 - train: epoch 0127, iter [01500, 02526], lr: 0.000001, loss: 0.6805, CELoss: 0.6805, 
2022-10-22 13:31:06 - train: epoch 0127, iter [01600, 02526], lr: 0.000001, loss: 0.5380, CELoss: 0.5380, 
2022-10-22 13:32:32 - train: epoch 0127, iter [01700, 02526], lr: 0.000001, loss: 0.3133, CELoss: 0.3133, 
2022-10-22 13:33:57 - train: epoch 0127, iter [01800, 02526], lr: 0.000001, loss: 0.3320, CELoss: 0.3320, 
2022-10-22 13:35:23 - train: epoch 0127, iter [01900, 02526], lr: 0.000001, loss: 0.9446, CELoss: 0.9446, 
2022-10-22 13:36:48 - train: epoch 0127, iter [02000, 02526], lr: 0.000001, loss: 0.6102, CELoss: 0.6102, 
2022-10-22 13:38:14 - train: epoch 0127, iter [02100, 02526], lr: 0.000001, loss: 0.4433, CELoss: 0.4433, 
2022-10-22 13:39:39 - train: epoch 0127, iter [02200, 02526], lr: 0.000001, loss: 0.6212, CELoss: 0.6212, 
2022-10-22 13:41:04 - train: epoch 0127, iter [02300, 02526], lr: 0.000001, loss: 0.6700, CELoss: 0.6700, 
2022-10-22 13:42:30 - train: epoch 0127, iter [02400, 02526], lr: 0.000001, loss: 1.0818, CELoss: 1.0818, 
2022-10-22 13:43:55 - train: epoch 0127, iter [02500, 02526], lr: 0.000001, loss: 0.7065, CELoss: 0.7065, 
2022-10-22 13:44:19 - train: epoch 127, train_loss: 0.5288
2022-10-22 13:44:19 - until epoch: 127, best_metric: 34.132%
2022-10-23 09:15:45 - epoch 128 lr: 0.000001
2022-10-23 09:17:13 - train: epoch 0128, iter [00100, 02526], lr: 0.000001, loss: 0.5260, CELoss: 0.5260, 
2022-10-23 09:18:37 - train: epoch 0128, iter [00200, 02526], lr: 0.000001, loss: 0.4112, CELoss: 0.4112, 
2022-10-23 09:20:01 - train: epoch 0128, iter [00300, 02526], lr: 0.000001, loss: 0.4647, CELoss: 0.4647, 
2022-10-23 09:21:25 - train: epoch 0128, iter [00400, 02526], lr: 0.000001, loss: 0.4925, CELoss: 0.4925, 
2022-10-23 09:22:48 - train: epoch 0128, iter [00500, 02526], lr: 0.000001, loss: 0.4543, CELoss: 0.4543, 
2022-10-23 09:24:11 - train: epoch 0128, iter [00600, 02526], lr: 0.000001, loss: 0.3216, CELoss: 0.3216, 
2022-10-23 09:25:35 - train: epoch 0128, iter [00700, 02526], lr: 0.000001, loss: 0.5195, CELoss: 0.5195, 
2022-10-23 09:26:59 - train: epoch 0128, iter [00800, 02526], lr: 0.000001, loss: 0.6045, CELoss: 0.6045, 
2022-10-23 09:28:23 - train: epoch 0128, iter [00900, 02526], lr: 0.000001, loss: 0.4493, CELoss: 0.4493, 
2022-10-23 09:29:46 - train: epoch 0128, iter [01000, 02526], lr: 0.000001, loss: 0.5558, CELoss: 0.5558, 
2022-10-23 09:31:10 - train: epoch 0128, iter [01100, 02526], lr: 0.000001, loss: 0.5101, CELoss: 0.5101, 
2022-10-23 09:32:34 - train: epoch 0128, iter [01200, 02526], lr: 0.000001, loss: 0.4406, CELoss: 0.4406, 
2022-10-23 09:33:58 - train: epoch 0128, iter [01300, 02526], lr: 0.000001, loss: 0.5921, CELoss: 0.5921, 
2022-10-23 09:35:22 - train: epoch 0128, iter [01400, 02526], lr: 0.000001, loss: 0.5690, CELoss: 0.5690, 
2022-10-23 09:36:46 - train: epoch 0128, iter [01500, 02526], lr: 0.000001, loss: 0.3566, CELoss: 0.3566, 
2022-10-23 09:38:10 - train: epoch 0128, iter [01600, 02526], lr: 0.000001, loss: 0.9438, CELoss: 0.9438, 
2022-10-23 09:39:34 - train: epoch 0128, iter [01700, 02526], lr: 0.000001, loss: 0.4912, CELoss: 0.4912, 
2022-10-23 09:40:58 - train: epoch 0128, iter [01800, 02526], lr: 0.000001, loss: 0.5314, CELoss: 0.5314, 
2022-10-23 09:42:22 - train: epoch 0128, iter [01900, 02526], lr: 0.000001, loss: 0.4941, CELoss: 0.4941, 
2022-10-23 09:43:46 - train: epoch 0128, iter [02000, 02526], lr: 0.000001, loss: 0.6592, CELoss: 0.6592, 
2022-10-23 09:45:10 - train: epoch 0128, iter [02100, 02526], lr: 0.000001, loss: 0.5592, CELoss: 0.5592, 
2022-10-23 09:46:33 - train: epoch 0128, iter [02200, 02526], lr: 0.000001, loss: 0.6334, CELoss: 0.6334, 
2022-10-23 09:47:57 - train: epoch 0128, iter [02300, 02526], lr: 0.000001, loss: 0.5452, CELoss: 0.5452, 
2022-10-23 09:49:21 - train: epoch 0128, iter [02400, 02526], lr: 0.000001, loss: 0.3992, CELoss: 0.3992, 
2022-10-23 09:50:44 - train: epoch 0128, iter [02500, 02526], lr: 0.000001, loss: 0.4330, CELoss: 0.4330, 
2022-10-23 09:51:07 - train: epoch 128, train_loss: 0.5280
2022-10-23 09:53:51 - eval: epoch: 128
test_loss: 0.9088365986347199
per_image_load_time: 1.208ms
per_image_inference_time: 75.324ms
exist_num_class: 150.0
mean_precision: 51.519301438489705
mean_recall: 47.355261935929036
mean_iou: 34.05807287285671
mean_dice: 47.50654250155603

2022-10-23 09:53:52 - until epoch: 128, best_metric: 34.132%
2022-10-23 09:53:52 - train done. model: resnet50backbone_deeplabv3plus, train time: 77.889 hours, best_metric: 34.132%
